<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Annulus (mathematics)</title>
    <ns>0</ns>
    <id>356158</id>
    <revision>
      <id>815916873</id>
      <parentid>796618497</parentid>
      <timestamp>2017-12-18T01:33:05Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>both forms exist</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3756">[[Image:Annulus area.svg|right|150px|An annulus]]
[[File:Mamikon_annulus_area_visualisation.svg|thumb|upright|Illustration of Mamikon's [[visual calculus]] method showing that the areas of two annuli with the same chord length are the same regardless of inner and outer radii.&lt;ref&gt;{{cite web|title=The Edge of the Universe: Celebrating Ten Years of Math Horizons|url=https://books.google.com/books?id=I9oVP8TlyqIC&amp;pg=PA70|accessdate=9 May 2017}}&lt;/ref&gt;]]
In [[mathematics]], an '''annulus''' (the [[Latin]] word for "little ring" is ''anulus''/''annulus'', with plural ''anuli''/''annuli'') is a ring-shaped object, a region bounded by two concentric circles. The adjectival form is '''annular''' (as in [[annular eclipse]]).

The open annulus is [[homeomorphism|topologically equivalent]] to both the open [[cylinder (geometry)|cylinder]] {{math|''S''&lt;sup&gt;1&lt;/sup&gt; &amp;times; (0,1)}} and the [[punctured plane]]. Informally, it has the shape of a [[washer (hardware)|hardware washer]].

The area of an annulus is the difference in the areas of the larger [[circle]] of radius {{math|''R''}} and the smaller one of radius {{math|''r''}}:
:&lt;math&gt;A = \pi R^2 - \pi r^2 = \pi\left(R^2 - r^2\right).&lt;/math&gt;

The area of an annulus is determined by the length of the longest [[line segment]] within the annulus, which is the chord tangent to the inner circle, {{math|2''d''}} in the accompanying diagram. That can be shown using the [[Pythagorean theorem]] since this line is [[tangent]] to the smaller circle and perpendicular to its radius at that point, so {{math|''d''}} and {{math|''r''}} are sides of a right-angled triangle with hypotenuse {{math|''R''}}, and the area of the annulus is given by
:&lt;math&gt;A = \pi\left(R^2 - r^2\right) = \pi d^2.&lt;/math&gt;

The area can also be obtained via [[calculus]] by dividing the annulus up into an infinite number of annuli of [[infinitesimal]] width {{math|''dρ''}} and area {{math|2π''ρ dρ''}} and then [[integral|integrating]] from {{math|1=''ρ'' = ''r''}} to {{math|1=''ρ'' = ''R''}}:
:&lt;math&gt;A = \int_r^R\!\! 2\pi\rho\, d\rho = \pi\left(R^2 - r^2\right).&lt;/math&gt;

The area of an annulus sector of angle {{math|''θ''}}, with {{math|''θ''}} measured in radians, is given by
:&lt;math&gt; A = \frac{\theta}{2} \left(R^2 - r^2\right). &lt;/math&gt;

==Complex structure==
In [[complex analysis]] an '''annulus''' {{math|ann(''a''; ''r'', ''R'')}} in the [[complex plane]] is an [[open region]] defined as

:&lt;math&gt; r &lt; |z - a| &lt; R. &lt;/math&gt;

If {{math|''r''}} is {{math|0}}, the region is known as the '''punctured disk''' of radius {{math|''R''}} around the point {{math|''a''}}.

As a subset of the complex [[Plane (mathematics)|plane]], an annulus can be considered as a [[Riemann surface]]. The complex structure of an annulus depends only on the ratio {{math|{{sfrac|''r''|''R''}}}}. Each annulus {{math|ann(''a''; ''r'', ''R'')}} can be [[holomorphic function|holomorphically]] mapped to a standard one centered at the origin and with outer radius 1 by the map
:&lt;math&gt;z \mapsto \frac{z - a}{R}.&lt;/math&gt;

The inner radius is then {{math|{{sfrac|''r''|''R''}} &lt; 1}}.

The [[Hadamard three-circle theorem]] is a statement about the maximum value a holomorphic function may take inside an annulus.

== See also ==
* [[Annulus theorem]] (or conjecture)
* [[Visual calculus#Description]], for an alternative approach to the area of the annulus
* [[Spherical shell]]
* [[Torus]]
* [[List of geometric shapes]]

==References==
&lt;references /&gt;

== External links ==
*[http://www.mathopenref.com/annulus.html Annulus definition and properties] With interactive animation
*[http://www.mathopenref.com/annulusarea.html Area of an annulus, formula] With interactive animation

[[Category:Elementary geometry]]
[[Category:Geometric shapes]]</text>
      <sha1>ple6eomkc7z59klqbpkhu9eekokyrrx</sha1>
    </revision>
  </page>
  <page>
    <title>Antonella Grassi</title>
    <ns>0</ns>
    <id>55728075</id>
    <revision>
      <id>837461219</id>
      <parentid>809085919</parentid>
      <timestamp>2018-04-20T23:54:48Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (1 source from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2632">{{Infobox scientist
| name = Antonella Grassi
| image = 
| birth_date = 
| birth_place = 
| nationality      = 
| fields           = [[Mathematics]]
| workplaces       = [[University of Pennsylvania]]
| alma_mater       = [[Duke University]], 1990
| doctoral_advisor = [[David R. Morrison]]
| known_for        = 
}}

'''Antonella Grassi''' is a mathematician specializing in [[algebraic geometry]] and [[string theory]].  She is a Fellow of the [[American Mathematical Society]].

==Education==
Grassi received her Ph.D. from [[Duke University]] under the supervision of [[David R. Morrison]].  Her dissertation was entitled "Minimal Models of Elliptic Threefolds."&lt;ref name=genealogy&gt;
{{MathGenealogy|id=39289|title=Antonella Grassi}}&lt;/ref&gt;

==Career and Service ==
Grassi is currently Professor of Mathematics at the [[University of Pennsylvania]] in [[Philadelphia]], [[Pennsylvania]].  She has supervised two doctoral students, one at the University of Pennsylvania and the other at [[University of Turin|Università di Torino]] in [[Turin|Torino]].&lt;ref name="genealogy" /&gt; She is an active participant in Women in Math at the University of Pennsylvania.&lt;ref&gt;{{cite web|title=Women in Math at the University of Pennsylvania|url=https://www.math.upenn.edu/about/department-history/women-math-university-pennsylvania|website=www.math.upenn.edu|publisher=University of Pennsylvania|accessdate=6 November 2017}}&lt;/ref&gt;

Grassi has been a leader and mentor in the [[Institute for Advanced Study]] Program for Women in Mathematics; in particular, she organized the 2007 program on Algebraic Geometry and Group Actions.&lt;ref&gt;{{cite web|title=Program History|url=http://www.math.ias.edu/wam/about/history|website=www.math.ias.edu|publisher=Institute for Advanced Study|accessdate=6 November 2017}}&lt;/ref&gt;

==Honors==

Grassi was elected to the 2018 class of fellows of the [[American Mathematical Society]]. Her citation read "For contributions to algebraic geometry and mathematical physics, and for leadership in mentoring programs."&lt;ref&gt;{{cite web|title=Fellows of the American Mathematical Society|url=http://www.ams.org/profession/ams-fellows/new-fellows|website=ams.org|publisher=American Mathematical Society|accessdate=6 November 2017}}&lt;/ref&gt;

==References==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Grassi, Antonella}}
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Living people]]
[[Category:Duke University alumni]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Women mathematicians]]
[[Category:University of Pennsylvania faculty]]</text>
      <sha1>n6dia21m8t0ooyofbylwtrfaasful3o</sha1>
    </revision>
  </page>
  <page>
    <title>Applicable mathematics</title>
    <ns>0</ns>
    <id>6073930</id>
    <redirect title="Applied mathematics" />
    <revision>
      <id>833589040</id>
      <parentid>815165135</parentid>
      <timestamp>2018-04-01T13:46:25Z</timestamp>
      <contributor>
        <username>Klbrain</username>
        <id>11677590</id>
      </contributor>
      <comment>Merge to [[Applied mathematics]] following unopposed 2016 proposal; see [[Talk:Applied mathematics#Applied mathematics &lt;- Applicable mathematics article merger discussion]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="163">#REDIRECT [[Applied mathematics#Applicable mathematics]] {{R from merge}} {{R to section}}

[[Category:Mathematical optimization]]
[[Category:Applied mathematics]]</text>
      <sha1>p2wxwqzf4yovy34913534i7oau0bqof</sha1>
    </revision>
  </page>
  <page>
    <title>Asset allocation</title>
    <ns>0</ns>
    <id>2168889</id>
    <revision>
      <id>865805084</id>
      <parentid>827259597</parentid>
      <timestamp>2018-10-26T08:05:38Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta9)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21705">[[File:Asset Allocation.pdf|thumb|320px|Investment portfolio with a diverse asset allocation]]
'''Asset allocation ''' is the rigorous implementation of an [[investment strategy]] that attempts to balance [[financial risk|risk]] versus reward by adjusting the percentage of each asset in an investment [[Portfolio (finance)|portfolio]] according to the investor's risk tolerance, goals and investment time frame.&lt;ref name="investopedia.com"&gt;{{cite web|url=http://www.investopedia.com/terms/a/assetallocation.asp#ixzz1QTuSzfhn |publisher=Investopedia |title=Asset Allocation Definition |accessdate=27 June 2011}}&lt;/ref&gt; The focus is on the characteristics of the overall portfolio. Such a strategy contrasts with an approach that focuses on individual assets.

==Description==
Many financial experts argue that asset allocation is an important factor in determining returns for an investment portfolio.&lt;ref name="investopedia.com"/&gt;  Asset allocation is based on the principle that different assets perform differently in different market and economic conditions.

A fundamental justification for asset allocation is the notion that different [[asset classes]] offer returns that are not perfectly [[Financial correlation|correlated]], hence [[Diversification (finance)|diversification]] reduces the overall [[Financial risk|risk]] in terms of the variability of returns for a given level of [[expected return]]. Asset diversification has been described as "the only free lunch you will find in the investment game".&lt;ref&gt;{{cite web|url=http://www.fundadvice.com/sound-investing-tv/episodes/sitv-5.3.10.html |publisher=FundAdvice.com |title=Is there really no such thing as a free lunch? |accessdate=2 August 2011 |deadurl=yes |archiveurl=https://web.archive.org/web/20110711054120/http://www.fundadvice.com/sound-investing-tv/episodes/sitv-5.3.10.html |archivedate=11 July 2011 }}&lt;/ref&gt; Academic research has painstakingly explained the importance of asset allocation and the problems of [[active management]] (see [[#Academic studies|academic studies]] section below).

Although risk is reduced as long as [[Financial correlation|correlations]] are not perfect, it is typically forecast (wholly or in part) based on statistical relationships (like correlation and [[variance]]) that existed over some past period. Expectations for return are often derived in the same way.

When such backward-looking approaches are used to forecast future returns or risks using the traditional mean-variance optimization approach to asset allocation of [[modern portfolio theory]] (MPT), the strategy is, in fact, predicting future risks and returns based on history. As there is no guarantee that past relationships will continue in the future, this is one of the "weak links" in traditional asset allocation strategies as derived from MPT. Other, more subtle weaknesses include seemingly minor errors in forecasting leading to recommended allocations that are grossly skewed from investment mandates and/or impractical—often even violating an investment manager's "common sense" understanding of a tenable portfolio-allocation strategy.

&lt;!-- link here --&gt;==Asset classes==
{{see also|Asset classes}}
An asset class is a group of economic resources sharing similar characteristics, such as riskiness and return. There are many types of assets that may or may not be included in an asset allocation strategy.

===Traditional assets===
The "traditional" asset classes are ''stocks'', ''bonds'', and ''cash'':
* [[Stock]]s: value, dividend, growth, or sector-specific (or a "blend" of any two or more of the preceding); large-cap versus mid-cap, small-cap or micro-cap; domestic, foreign (developed), emerging or frontier markets
* [[Bond (finance)|Bonds]] (fixed income securities more generally): investment-grade or junk (high-yield); government or corporate; short-term, intermediate, long-term; domestic, foreign, [[emerging markets]]
* [[Cash]] and cash equivalents (e.g., [[deposit account]], [[money market fund]])
Allocation among these three provides a starting point. Usually included are hybrid instruments such as [[convertible bond]]s and preferred stocks, counting as a mixture of bonds and stocks.

===Alternative assets===
Other alternative assets that may be considered include:
* [[Commodity market|Commodities]]: precious metals, nonferrous metals, agriculture, energy, others.
* Commercial or residential [[real estate]] (also [[Real estate investment trust|REIT]]s)
* Collectibles such as art, coins, or stamps
* [[Insurance]] products ([[Annuity (US financial products)|annuity]], [[life settlement]]s, [[catastrophe bond]]s, personal [[life insurance]] products, etc.)
* [[Derivative (finance)|Derivative]]s such as long-short or market neutral strategies, [[option (finance)|option]]s, collateralized debt, and [[futures contract|futures]]
* Foreign [[currency]]
* [[Venture capital]]
* [[Private equity]]
* [[Distressed securities]]

==Allocation strategy==

There are several types of asset allocation strategies based on investment goals, risk tolerance, time frames and diversification.  The most common forms of asset allocation are: strategic, dynamic, tactical, and core-satellite.

=== Strategic asset allocation ===
The primary goal of a strategic asset allocation is to create an asset mix that seeks to provide the optimal balance between expected risk and return for a long-term investment horizon.&lt;ref name="idzorek1"&gt;[http://corporate.morningstar.com/ib/documents/MethodologyDocuments/IBBAssociates/Commodities.pdf Idzorek, Thomas M., "Strategic Asset Allocation and Commodities", Ibbotson Associates, March 27, 2006]&lt;/ref&gt;  Generally speaking, strategic asset allocation strategies are agnostic to economic environments, i.e., they do not change their allocation postures relative to changing market or economic conditions. 

=== Dynamic asset allocation ===
Dynamic asset allocation is similar to strategic asset allocation in that portfolios are built by allocating to an asset mix that seeks to provide the optimal balance between expected risk and return for a long-term investment horizon.&lt;ref name="idzorek1" /&gt; Like strategic allocation strategies, dynamic strategies largely retain exposure to their original asset classes; however, unlike strategic strategies, dynamic asset allocation portfolios will adjust their postures over time relative to changes in the economic environment.   

=== Tactical asset allocation ===
[[Tactical asset allocation]] is a strategy in which an investor takes a more active approach that tries to position a portfolio into those assets, sectors, or individual stocks that show the most potential for perceived gains.&lt;ref name="blitz1"&gt;Blitz, David and Van Vliet, Pim, "Global Tactical Cross-Asset Allocation: Applying Value and Momentum Across Asset Classes", ''Journal of Portfolio Management'', Forthcoming. Available at SSRN: http://ssrn.com/abstract=1079975&lt;/ref&gt;&lt;ref&gt;Faber, Mebane T., "A Quantitative Approach to Tactical Asset Allocation", ''[[The Journal of Wealth Management]]'', Spring 2007, February 2009 update available at: http://ssrn.com/abstract=962461&lt;/ref&gt; While an original asset mix is formulated much like strategic and dynamic portfolio, tactical strategies are often traded more actively and are free to move entirely in and out of their core asset classes.

=== Core-satellite asset allocation ===
Core-satellite allocation strategies generally contain a 'core' strategic element making up the most significant portion of the portfolio, while applying a dynamic or tactical 'satellite' strategy that makes up a smaller part of the portfolio.  In this way, core-satellite allocation strategies are a hybrid of the strategic and dynamic/tactical allocation strategies mentioned above.&lt;ref&gt;Singleton, J. Clay, ''Core-Satellite Portfolio Management: A Modern Approach for Professionally Managed Funds'', McGraw-Hill 2004&lt;/ref&gt;

==Asset allocation fund==

A fund that holds more than one asset class is called an asset allocation fund. This includes many types such as "balanced fund" and so on.&lt;ref&gt;{{cite web|url=http://www.investopedia.com/terms/a/aaf.asp|title=Asset Allocation Fund Definition &amp;#124; Investopedia}}&lt;/ref&gt;

==Academic studies==
In 1986, [[Gary P. Brinson]], L. Randolph Hood, and [[SEI Investments Company|SEI's]] Gilbert L. Beebower (BHB) published a study about asset allocation of 91 large [[pension fund]]s measured from 1974 to 1983.&lt;ref name="brinson1"&gt;[[Gary P. Brinson]], L. Randolph Hood, and Gilbert L. Beebower, ''Determinants of Portfolio Performance'', The Financial Analysts Journal, July/August 1986.&lt;/ref&gt; They replaced the pension funds' stock, bond, and cash selections with corresponding market indexes.  The indexed quarterly return were found to be higher than pension plan's actual quarterly return. The two quarterly return series' linear [[Financial correlation|correlation]] was measured at 96.7%, with [[Coefficient of determination|shared variance]] of 93.6%.  A 1991 follow-up study by [[Gary P. Brinson|Brinson]], Singer, and Beebower measured a variance of 91.5%.&lt;ref name="bsb"&gt;[[Gary P. Brinson]], Brian D. Singer, and Gilbert L. Beebower, ''Determinants of Portfolio Performance II: An Update'', The Financial Analysts Journal, 47, 3 (1991).&lt;/ref&gt;  The conclusion of the study was that replacing active choices with simple asset classes worked just as well as, if not even better than, professional pension managers.  Also, a small number of asset classes was sufficient for financial planning.  Financial advisors often pointed to this study to support the idea that asset allocation is more important than all other concerns, which the BHB study lumped together as
"[[market timing]]".&lt;ref name="statman"&gt;Meir Statman, ''The 93.6% Question of Financial Advisors'', The Journal of Investing, Spring 2000, Vol. 9, No. 1: pp. 16-20&lt;/ref&gt; One problem with the [[Gary P. Brinson|Brinson]] study was that the cost factor in the two return series was not clearly discussed.  However, in response to a letter to the editor, Hood noted that the returns series were gross of management fees.&lt;ref name="hood"&gt;L. Randolph Hood, Response to Letter to the Editor, The Financial Analysts Journal 62/1, January/February 2006&lt;/ref&gt;

In 1997, William Jahnke initiated debate on this topic, attacking the BHB study in a paper titled “The Asset Allocation Hoax”.&lt;ref name="jahnke"&gt;William Jahnke, “The Asset Allocation Hoax”, ''Journal of Financial Planning'', February 1997&lt;/ref&gt;  The Jahnke discussion appeared in the ''Journal of Financial Planning'' as an opinion piece, not a peer reviewed article. Jahnke's main criticism, still undisputed, was that BHB's use of quarterly data dampens the impact of compounding slight portfolio disparities over time, relative to the benchmark. One could compound 2% and 2.15% quarterly over 20 years and see the sizable difference in cumulative return.  However, the difference is still 15 basis points (hundredths of a percent) per quarter; the difference is one of perception, not fact.

In 2000, [[Roger G. Ibbotson|Ibbotson]] and Kaplan used five asset classes in their study “Does Asset Allocation Policy Explain 40, 90, or 100 Percent of Performance?”&lt;ref name="ibbot1"&gt;Roger G. Ibbotson and Paul D. Kaplan, “Does Asset Allocation Policy Explain 40%, 90%, or 100% of Performance?”,  ''The Financial Analysts Journal'', January/February 2000&lt;/ref&gt; The asset classes included were large-cap US stock, small-cap US stock, non-US stock, US bonds, and cash. Ibbotson and Kaplan examined the 10-year return of 94 US balanced mutual funds versus the corresponding indexed returns. This time, after properly adjusting for the cost of running index funds, the actual returns again failed to beat index returns. The linear correlation between monthly index return series and the actual monthly actual return series was measured at 90.2%, with shared variance of 81.4%. Ibbotson concluded 1) that asset allocation explained 40% of the variation of returns across funds, and 2) that it explained virtually 100% of the level of fund returns. [[Gary Brinson]] has expressed his general agreement with the Ibbotson-Kaplan conclusions.

In both studies, it is misleading to make statements such as "asset allocation explains 93.6% of investment return".&lt;ref name="brown"&gt;James Dean Brown, ''The coefficient of determination'', Shiken: JALT Testing &amp; Evaluation SIG Newsletter, Volume 7, No. 1, March 2003.&lt;/ref&gt; Even "asset allocation explains 93.6% of quarterly performance variance" leaves much to be desired, because the shared variance could be from pension funds' operating structure.&lt;ref name="ibbot1" /&gt;  Hood, however, rejects this interpretation on the grounds that pension plans in particular cannot cross-share risks and that they are explicitly singular entities, rendering shared variance irrelevant.&lt;ref name="hood"/&gt;  The statistics were most helpful when used to demonstrate the similarity of the index return series and the actual return series.

A 2000 paper by Meir Statman found that using the same parameters that explained BHB's 93.6% variance result, a hypothetical financial advisor with perfect foresight in ''tactical'' asset allocation performed 8.1% better per year, yet the strategic asset allocation still explained 89.4% of the variance.&lt;ref name="statman" /&gt;  Thus, explaining variance does not explain performance.  Statman says that strategic asset allocation is movement ''along'' the [[efficient frontier]], whereas tactical asset allocation involves movement ''of'' the efficient frontier.  A more common sense explanation of the Brinson, Hood, and Beebower study is that asset allocation explains more than 90% of the volatility of returns of an overall portfolio, but will not explain the ending results of your portfolio over long periods of time.  Hood notes in his review of the material over 20 years, however, that explaining performance over time is possible with the BHB approach but was not the focus of the original paper.&lt;ref name="hood2"&gt;L. Randolph Hood, ''Determinants of Portfolio Performance – 20 Years Later'', The Financial Analysts Journal 61/5 September/October 2005.&lt;/ref&gt;

Bekkers, Doeswijk and Lam (2009) investigate the diversification benefits for a portfolio by distinguishing ten different investment categories simultaneously in a mean-variance analysis as well as a market portfolio approach. The results suggest that real estate, commodities, and high yield add most value to the traditional asset mix of stocks, bonds, and cash. A study with such a broad coverage of asset classes has not been conducted before, not in the context of determining capital market expectations and performing a [[mean-variance analysis]], neither in assessing the global market portfolio.&lt;ref name="bdl"&gt;Bekkers Niels, Doeswijk Ronald Q. and Lam Trevin, [http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1368689 Strategic Asset Allocation: Determining the Optimal Portfolio with Ten Asset Classes ], ''Journal of Wealth Management, Vol 12, No 3, pp 61-77, 2009''.&lt;/ref&gt;

Doeswijk, Lam and Swinkels (2012) &lt;ref&gt;[http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2170275 Doeswijk Ronald Q., Lam Trevin and Laurens A.P. Swinkels, Strategic Asset Allocation: The Global Multi-Asset Market Portfolio 1959-2011, Working Paper]&lt;/ref&gt;  (2014) &lt;ref&gt;[http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2352932 Doeswijk Ronald Q., Lam Trevin and Laurens A.P. Swinkels, Strategic Asset Allocation: The Global Multi-Asset Market Portfolio 1959-2012, Financial Analysts Journal, 70(2), pp. 26-41, 2014]&lt;/ref&gt; argue that the portfolio of the average investor contains important information for strategic asset allocation purposes. This portfolio shows the relative value of all assets according to the market crowd, which one could interpret as a benchmark or the optimal portfolio for the average investor. The authors determine the market values of equities, private equity, real estate, high yield bonds, emerging debt, non-government bonds, government bonds, inflation linked bonds, commodities, and hedge funds. For this range of assets, they estimate the invested global market portfolio for the period 1990-2012. For the main asset categories equities, real estate, non-government bonds and government bonds they extend the period to 1959-2012.

Doeswijk, Lam and Swinkels (2017) &lt;ref&gt;[https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2978509 Doeswijk Ronald Q., Lam Trevin and Laurens A.P. Swinkels, Historical Returns of the Market Portfolio, Working Paper]&lt;/ref&gt; show that the market portfolio realizes a compounded real return of 4.38% with a standard deviation of 11.6% from 1960 until 2015. In the inflationary period from 1960 to 1979, the compounded real return of the GMP is 2.27%, while this is 5.57% in the disinflationary period from 1980 to 2015. The reward for the average investor is a compounded return of 3.24%-points above the saver’s.  

===Performance indicators===
McGuigan described an examination of funds that were in the top quartile of performance during 1983 to 1993.&lt;ref name="mcguigan"&gt;Thomas P. McGuigan, ''The Difficulty of Selecting Superior Mutual Fund Performance'', Journal of Financial Planning, February 2006.&lt;/ref&gt; During the second measurement period of 1993 to 2003, only 28.57% of the funds remained in the top quartile. 33.33% of the funds dropped to the second quartile.  The rest of the funds dropped to the third or fourth quartile.

In fact, low cost was a more reliable indicator of performance. [[John Bogle|Bogle]] noted that an examination of five-year performance data of large-cap blend funds revealed that the lowest cost quartile funds had the best performance, and the highest cost quartile funds had the worst performance.&lt;ref&gt;[http://johncbogle.com/speeches/JCB_Morningstar_6-97.pdf The Implications of Style Analysis on Mutual Fund Performance Evaluation]&lt;/ref&gt;

==Return versus risk trade-off==
In asset allocation planning, the decision on the amount of [[stock]]s versus [[bond (finance)|bond]]s in one's portfolio is a very important decision.  Simply buying stocks without regard of a possible [[bear market]] can result in [[panic selling]] later. One's true [[risk tolerance]] can be hard to gauge until having experienced a real bear market with money invested in the market.  Finding the proper balance is key.

{| class="wikitable"
! colspan="2"| Cumulative return after inflation from 2000-to-2002 bear market&lt;ref name="table1"&gt;Stock return from a [[Wilshire 5000]] index fund; bond return from a [[Barclays Capital Aggregate Bond Index]] fund; [[inflation]] data from US Treasury Department.&lt;/ref&gt;
|-
| 80% stock / 20% bond || &amp;minus;34.35%
|-
| 70% stock / 30% bond || &amp;minus;25.81%
|-
| 60% stock / 40% bond || &amp;minus;19.99%
|-
| 50% stock / 50% bond || &amp;minus;13.87%
|-
| 40% stock / 60% bond || &amp;minus;7.46%
|-
| 30% stock / 70% bond || &amp;minus;0.74%
|-
| 20% stock / 80% bond || +6.29%
|}

{| class="wikitable"
! colspan="2" | Projected 10-year Cumulative return after inflation &lt;br&gt; (stock return 8% yearly, bond return 4.5% yearly, inflation 3% yearly&lt;ref name="table2"&gt;Input parameters are for illustration purpose only; actual returns will vary.&lt;/ref&gt;
|-
| 80% stock / 20% bond || 52%
|-
| 70% stock / 30% bond || 47%
|-
| 60% stock / 40% bond || 42%
|-
| 50% stock / 50% bond || 38%
|-
| 40% stock / 60% bond || 33%
|-
| 30% stock / 70% bond || 29%
|-
| 20% stock / 80% bond || 24%
|}

The tables show why asset allocation is important. It determines an investor's future return, as well as the [[bear market]] burden that he or she will have to carry successfully to realize the returns.

==Problems with asset allocation==
There are various reasons why asset allocation fails to work.
* Investor behavior is inherently biased. Even though investor chooses an asset allocation, implementation is a challenge. 
* Investors agree to asset allocation, but after some good returns they decide that they really wanted more risk.
* Investors agree to asset allocation, but after some bad returns they decide that they really wanted less risk.
* Investors' risk tolerance is not knowable ahead of time.&lt;ref&gt;[http://pragcap.com/lies-investors-tell-themselves Lies Investors Tell Themselves | Pragmatic Capitalism]&lt;/ref&gt;
* Security selection within asset classes will not necessarily produce a risk profile equal to the asset class.
* The long-run behavior of asset classes does not guarantee their shorter-term behavior.

==See also==
* [[Market portfolio]]
* [[Efficient-market hypothesis]]
* [[Tactical asset allocation]]
* [[Mutual fund]]
* [[Index fund]]
* [[Asset location]]
* [[Performance attribution]]
* [[Economic capital]]
* [[Portfolio optimization]]

==References==
{{reflist|colwidth=30em}}


==External links==
{{wikibooks}}
* [https://www.aistockcharts.com/stock_analysis.htm Stock price correlation analysis with selectable asset class matrix]
* [https://web.archive.org/web/20160308082419/http://www.multiwealth.co.uk/performance Asset allocation performance]
* [http://www.bogleheads.org/wiki/Lazy_Portfolios Model portfolios for buy and hold index investors]
* [http://azul.io/ Analyze your portfolio for its current asset allocation]
* [https://web.archive.org/web/20080129073847/http://www.fulcruminquiry.com/allocation.htm Calculator for determining allocation of retirement assets, and related risk questionnaire]
* [http://sporkforge.com/finance/asset_alloc.php Calculator which determines future asset mix based on differing growth rates and contributions]


{{DEFAULTSORT:Asset Allocation}}
[[Category:Investment management]]
[[Category:Actuarial science]]

{{Use dmy dates|date=June 2013}}</text>
      <sha1>9n0io57wjmope5dzm7rt7dng3jl8n3r</sha1>
    </revision>
  </page>
  <page>
    <title>Atoroidal</title>
    <ns>0</ns>
    <id>1241614</id>
    <revision>
      <id>745454914</id>
      <parentid>606971622</parentid>
      <timestamp>2016-10-21T07:00:07Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3071">In [[mathematics]], an '''atoroidal''' [[3-manifold]] is one that does not contain an essential [[torus]].
There are two major variations in this terminology: a torus may be defined geometrically, as an [[embedding|embedded]], non-[[boundary parallel]],  [[Incompressible surface|incompressible]] [[torus]], or it may be defined algebraically, as a [[subgroup]] &lt;math&gt;\mathbb Z\times\mathbb Z&lt;/math&gt; of its [[fundamental group]] that is not [[Conjugacy_class#Conjugacy_of_subgroups_and_general_subsets|conjugate]] to a peripheral subgroup (i.e. the image of the map on fundamental group induced by an inclusion of a boundary component). The terminology is not standardized, and different authors require atoroidal 3-manifolds to satisfy certain additional restrictions. For instance:
*{{harvtxt|Apanasov|2000}} gives a definition of atoroidality that combines both geometric and algebraic aspects, in terms of maps from a torus to the manifold and the induced maps on the fundamental group. He then notes that for [[Prime decomposition (3-manifold)|irreducible]] [[Boundary-incompressible surface|boundary-incompressible]] 3-manifolds this gives the algebraic definition.&lt;ref&gt;{{citation|title=Conformal Geometry of Discrete Groups and Manifolds|volume=32|series=De Gruyter Expositions in Mathematics|first=Boris N.|last=Apanasov|publisher=Walter de Gruyter|year=2000|isbn=9783110808056|page=294|url=https://books.google.com/books?id=Y-aIVhfbIugC&amp;pg=PA294}}.&lt;/ref&gt;
*{{harvtxt|Otal|2001}} uses the algebraic definition without additional restrictions.&lt;ref&gt;{{citation|title=The Hyperbolization Theorem for Fibered 3-manifolds|volume=7|series=Contemporary Mathematics|first=Jean-Pierre|last=Otal|publisher=American Mathematical Society|year=2001|isbn=9780821821534|page=ix|url=https://books.google.com/books?id=pVObtYVehxIC&amp;pg=PR9}}.&lt;/ref&gt;
*{{harvtxt|Chow|2007}} uses the geometric definition, restricted to irreducible manifolds.&lt;ref&gt;{{citation|title=The Ricci Flow: Geometric aspects|series=Mathematical surveys and monographs|first=Bennett|last=Chow|publisher=American Mathematical Society|year=2007|isbn=9780821839461|page=436|url=https://books.google.com/books?id=T3gqWWbCd60C&amp;pg=PA436}}.&lt;/ref&gt;
*{{harvtxt|Kapovich|2009}} requires the algebraic variant of atoroidal manifolds (which he calls simply atoroidal) to avoid being one of three kinds of [[fiber bundle]]. He makes the same restriction on geometrically atoroidal manifolds (which he calls topologically atoroidal) and in addition requires them to avoid incompressible boundary-parallel embedded [[Klein bottle]]s. With these definitions, the two kinds of atoroidality are equivalent except on certain [[Seifert manifold]]s.&lt;ref&gt;{{citation|title=Hyperbolic Manifolds and Discrete Groups|volume=183|series=Progress in Mathematics|first=Michael|last=Kapovich|publisher=Springer|year=2009|isbn=9780817649135|page=6|url=https://books.google.com/books?id=JRJ8VmfP-hcC&amp;pg=PA6}}.&lt;/ref&gt;

A 3-manifold that is not atoroidal is called '''toroidal'''.

==References==
{{reflist}}

{{geometry-stub}}
[[Category:3-manifolds]]</text>
      <sha1>7l4raz35fg184u3gzv4f5chk45k73cz</sha1>
    </revision>
  </page>
  <page>
    <title>Augmented assignment</title>
    <ns>0</ns>
    <id>1301302</id>
    <revision>
      <id>861120923</id>
      <parentid>827454267</parentid>
      <timestamp>2018-09-25T07:24:15Z</timestamp>
      <contributor>
        <username>Daviddwd</username>
        <id>14327137</id>
      </contributor>
      <comment>/* Supporting languages */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6105">{{Refimprove|date=September 2014}}
'''Augmented assignment''' (or '''compound assignment''') is the name given to certain 
[[Assignment (computer science)|assignment]] [[operator (programming)|operator]]s in certain [[programming languages]] (especially those derived from [[C (programming language)|C]]). An augmented assignment is generally used to replace a statement where an operator takes a [[Variable (programming)|variable]] as one of its arguments and then assigns the result back to the same variable. A simple example is &lt;code&gt;x&amp;nbsp;+= 1&lt;/code&gt; which is expanded to &lt;code&gt;x = x + (1)&lt;/code&gt;. Similar constructions are often available for various binary operators.

In general, in languages offering this feature, most operators that can take a variable as one of their arguments and return a result of the same type have an augmented assignment equivalent that assigns the result back to the variable in place, including arithmetic operators, bitshift operators, and [[bitwise operation|bitwise operators]].

==Discussion==
For example, the following statement or some variation of it can be found in many programs:

 x = x + 1

This means "find the number stored in the variable ''x'', add 1 to it, and store the result of the addition in the variable ''x''."  As simple as this seems, it may have an inefficiency, in that the location of variable ''x'' has to be looked up twice if the [[compiler]] does not recognize that two parts of the expression are identical: ''x'' might be a reference to some array element or other complexity. In comparison, here is the augmented assignment version:

 x += 1

With this version, there is no excuse for a compiler failing to generate code that looks up the location of variable ''x'' just once, and modifies it in place, if of course the machine code supports such a sequence. For instance, if x is a simple variable, the [[machine code]] sequence might be something like
  Load  x
  Add   1
  Store x
and the same code would be generated for both forms. But if there is a special op code, it might be
  MDM   x,1
meaning "Modify Memory" by adding 1 to x, and a decent compiler would generate the same code for both forms. Some machine codes offer INC and DEC operations (to add or subtract one), others might allow constants other than one.

More generally, the form is
 x '''?'''= expression
where the '''?''' stands for some operator (not always '''+'''), and there may be no special op codes to help. There is still the possibility that if ''x'' is a complicated entity the compiler will be encouraged to avoid duplication in accessing ''x'', and of course, if ''x'' is a lengthy name, there will be less typing required. This last was the basis of the similar feature in the [[ALGOL]] compilers offered via the Burroughs B6700 systems, using the tilde symbol to stand for the variable being assigned to, so that
 LongName:=x + sqrt(LongName)*7;
would become
 LongName:=x + sqrt(~)*7;
and so forth. This is more general than just ''x:=~ + 1;'' Producing optimum code would remain the province of the compiler.

==Semantics==
In [[expression-oriented programming language]]s such as C, assignment and augmented assignment are expressions, which have a value. This allows their use in complex expressions. However, this can produce sequences of symbols that are difficult to read or understand, and worse, a mistype can easily produce a different sequence of gibberish that although accepted by the compiler does not produce desired results. In other languages, such as Python, assignment and augmented assignment are statements, not expressions, and thus cannot be used in complex expressions. For example, the following is valid C, but not valid Python:
&lt;source lang=c&gt;
a += b += c
&lt;/source&gt;
As with assignment, in these languages augmented assignment is a form of [[Operator associativity#Right-associativity of assignment operators|right-associative assignment]].

==By language==
===C descendants===
In [[C (programming language)|C]], [[C++]], and [[C_Sharp_(programming_language)|C#]], the assignment operator is '''=''', which is augmented as follows:
{| class="wikitable"
|-
! Operator
! Description
|-
! &lt;tt&gt;+=&lt;/tt&gt;
| Addition
|-
! &lt;tt&gt;-=&lt;/tt&gt;
| Subtraction
|-
! &lt;tt&gt;*=&lt;/tt&gt;
| Multiplication
|-
! &lt;tt&gt;/=&lt;/tt&gt;
| Division
|-
! &lt;tt&gt;%=&lt;/tt&gt;
| Modulus
|-
! &lt;tt&gt;&lt;&lt;=&lt;/tt&gt;
| Left bit shift
|-
! &lt;tt&gt;&gt;&gt;=&lt;/tt&gt;
| Right bit shift
|-
! &lt;tt&gt;&amp;=&lt;/tt&gt;
| Bitwise AND
|-
! &lt;tt&gt;^=&lt;/tt&gt;
| Bitwise exclusive OR
|-
! &lt;tt&gt;&amp;#124;=&lt;/tt&gt;
| Bitwise inclusive OR
|}

Each of these is called a ''compound assignment'' operator in said languages.&lt;ref&gt;{{cite web|title=ISO/IEC 9899:201x Committee Draft April 12, 2011 N1570|url=http://www.iso-9899.info/n1570.html#6.5.16.2}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=Assignment and compound assignment operators|url=http://eel.is/c++draft/expr.ass}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=C# Language Specification|url=http://msdn.microsoft.com/en-us/library/ms228593.aspx|publisher=Microsoft|accessdate=17 March 2014}}&lt;/ref&gt;

==Supporting languages==
The following list, though not complete or all-inclusive, lists some of the major programming languages that support augmented assignment operators.

{{col-begin}}
{{col-break|width=25%}}
* [[AWK]]
* [[C (programming language)|C]]
* [[C++]]
* [[C Sharp (programming language)|C#]]
* [[ColdFusion Markup Language|CFML]]
* [[D (programming language)|D]]
* [[DWScript]]
{{col-break}}
* [[Free Pascal]] (Needs -Sc command line switch)
* [[Go (programming language)|Go]]
* [[Java (programming language)|Java]]
* [[JavaScript]]
* [[Objective-C]]
* [[Perl]]
* [[PHP]]
{{col-break}}
* [[Python (computer language)|Python]]
* [[Ruby (programming language)|Ruby]]
* [[Rust (programming language)|Rust]]
* [[Scala (programming language)|Scala]]
* [[SystemVerilog]]
* [[Swift (programming language)|Swift]]
* [[Visual Basic]]
{{col-end}}

==See also==
* [[Increment and decrement operators]]—special case of augmented assignment, by 1

==References==
{{Reflist}}

{{DEFAULTSORT:Augmented Assignment}}
[[Category:Operators (programming)]]
[[Category:Computer arithmetic]]
[[Category:Assignment operations]]</text>
      <sha1>ccw269tg3gi90tbmwyzgjamz2r7roes</sha1>
    </revision>
  </page>
  <page>
    <title>Boole's syllogistic</title>
    <ns>0</ns>
    <id>49460</id>
    <revision>
      <id>541308032</id>
      <parentid>500197056</parentid>
      <timestamp>2013-02-28T18:41:48Z</timestamp>
      <contributor>
        <username>Legobot</username>
        <id>7304691</id>
      </contributor>
      <minor/>
      <comment>Bot: Migrating langlinks to [[WP:Wikidata]] - [[d:q839405]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2002">{{Unreferenced|date=December 2009}}
[[File:Square of opposition, set diagrams.svg|thumb|Square of opposition&lt;br&gt;In the [[Venn diagram]]s black areas are [[empty set|empty]] and red areas are nonempty.&lt;br&gt;The faded arrows and faded red areas apply in traditional logic.]]
'''[[Boolean logic]]''' is a system of [[syllogism|syllogistic]] [[logic]] invented by 19th-century British mathematician [[George Boole]], which attempts to incorporate the "empty set", that is, a class of non-existent entities, such as round squares, without resorting to uncertain [[truth value]]s.

In Boolean logic, the universal statements "all S is P" and "no S is P" (contraries in the traditional Aristotelian schema) are compossible provided that the set of "S" is the empty set.  "All S is P" is construed to mean that "there is nothing that is both S and not-P"; "no S is P", that "there is nothing that is both S and P".  For example, since there is nothing that is a round square, it is true both that nothing is a round square and purple, and that nothing is a round square and ''not''-purple.  Therefore, both universal statements, that "all round squares are purple" and "no round squares are purple" are true.

Similarly, the [[subcontrary]] relationship is dissolved between the existential statements "some S is P" and "some S is not P".  The former is interpreted as "there is some S such that S is P" and the latter, "there is some S such that S is not P", both of which are clearly false where S is nonexistent.

Thus, the subaltern relationship between universal and existential also does not hold, since for a nonexistent S, "All S is P" is true but does not entail "Some S is P", which is false.  Of the Aristotelian [[square of opposition]], only the contradictory relationships remain intact.

==See also==
* [[Boolean logic]]
* [[Propositional logic]]
* [[list of Boolean algebra topics]]

{{DEFAULTSORT:Boole's Syllogistic}}
[[Category:History of logic]]
[[Category:Term logic]]
[[Category:Syllogism]]</text>
      <sha1>lwrkxdbwye2k7mvd3egxfzx8pfexnn8</sha1>
    </revision>
  </page>
  <page>
    <title>Bunched logic</title>
    <ns>0</ns>
    <id>922464</id>
    <revision>
      <id>869630992</id>
      <parentid>852092343</parentid>
      <timestamp>2018-11-19T20:27:32Z</timestamp>
      <contributor>
        <ip>46.193.67.56</ip>
      </contributor>
      <comment>Corrected mistake</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19807">'''Bunched logic'''&lt;ref name=OP99&gt;{{cite journal|last1=O'Hearn|first1=Peter|last2=Pym|first2=David|title=The Logic of Bunched Implications|journal=Bulletin of Symbolic Logic|date=1999|volume=5|issue=2|pages=215–244|doi=10.2307/421090|url=http://www.cs.ucl.ac.uk/staff/p.ohearn/papers/BI.pdf}}&lt;/ref&gt; is a variety of [[substructural logic]] proposed by [[Peter O'Hearn]] and [[David Pym]]. Bunched logic provides primitives for reasoning about ''resource composition'', which aid in the compositional analysis of computer and other systems. It has category-theoretic and truth-functional semantics which  can be understood in terms of an abstract concept of resource, and a proof theory in which the contexts Γ in an [[Logical consequence|entailment]] judgement Γ ⊢ A are tree-like structures (bunches) rather than lists or (multi)sets as in most [[proof calculi]]. Bunched logic has an associated type theory, and its first application was in providing a way to control the aliasing and other forms of interference in imperative programs.&lt;ref name=OHearn02&gt;{{cite journal|last1=O'Hearn|first1=Peter|title=On Bunched Typing|journal=Journal of Functional Programming|date=2003|volume=13|issue=4|pages=747–796|doi=10.1017/S0956796802004495|url=http://www0.cs.ucl.ac.uk/staff/p.ohearn/papers/BunchedTyping.pdf}}&lt;/ref&gt;
The logic has seen further applications in program verification, where it is the basis of the assertion language of [[separation logic]],&lt;ref name=IO01&gt;{{cite journal|last1=Ishtiaq|first1=Samin|last2=O'Hearn|first2=Peter|title=BI as an assertion language for mutable data structures|journal=POPL|date=2001|volume=28th|pages=14–26|doi=10.1145/373243.375719|url=http://www0.cs.ucl.ac.uk/staff/p.ohearn/papers/bi-assertion-lan.pdf}}&lt;/ref&gt; and in systems modelling, where it provides a way to decompose the resources used by components of a system.&lt;ref name="PymTofts2" /&gt;&lt;ref name=":0" /&gt;&lt;ref name=":1" /&gt;

== Foundations ==

The [[deduction theorem]] of [[classical logic]] relates conjunction and implication:
::&lt;math&gt;A \wedge B \vdash C \quad \mbox{iff} \quad A \vdash B \Rightarrow C &lt;/math&gt;
Bunched logic has two versions of the deduction theorem:
::&lt;math&gt;A * B \vdash C \quad \mbox{iff} \quad A \vdash B {-\!\!*} C  \qquad  \mbox{and also}  \qquad A \wedge B \vdash C \quad \mbox{iff} \quad A \vdash B \Rightarrow C &lt;/math&gt; 
&lt;math&gt;A * B &lt;/math&gt; and &lt;math&gt;B {-\!\!*} C&lt;/math&gt; are forms of conjunction and implication that take resources into account (explained below). In addition to these connectives
bunched logic has a formula, sometimes written I or emp, which is the unit of *. In the original version of bunched logic &lt;math&gt; \wedge &lt;/math&gt; and &lt;math&gt; \Rightarrow &lt;/math&gt; were the connectives from intuitionistic logic, while a boolean variant takes &lt;math&gt; \wedge &lt;/math&gt; and &lt;math&gt; \Rightarrow &lt;/math&gt; (and &lt;math&gt; \neg &lt;/math&gt;) as from traditional boolean logic. Thus, bunched logic is compatible with constructive principles, but is in no way dependent on them.

===Truth-functional Semantics (resource semantics)===
The easiest way to understand these formulae is in terms of its truth-functional semantics. In this semantics a formula is true or false with respect to given resources. 
&lt;math&gt;A*B &lt;/math&gt; asserts that the resource at hand can be decomposed into resources that satisfy &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;. 
&lt;math&gt; B {-\!\!*} C &lt;/math&gt; says that if we compose the resource at hand with additional resource that satisfies &lt;math&gt;B&lt;/math&gt;, then the combined resource satisfies &lt;math&gt;C&lt;/math&gt;. &lt;math&gt; \wedge &lt;/math&gt; and &lt;math&gt; \Rightarrow &lt;/math&gt; have their familiar meanings.

The foundation for this reading of formulae was provided by
a forcing semantics &lt;math&gt; r \models A &lt;/math&gt; advanced by Pym, where the forcing relation means `A holds of resource r`. The semantics is analogous to  Kripke's semantics of intuitionistic or modal logic, but where the elements of the model are regarded as resources which can be composed and decomposed, rather than as possible worlds that are accessible from one another. For example, the forcing semantics for the conjunction is of the form
::&lt;math&gt;r \models A * B \quad \mbox{iff} \quad \exists r_Ar_B.\,r_A \models A,\, r_B \models B,\,\mbox{and}\,r_A \bullet r_B \leq r &lt;/math&gt;
where &lt;math&gt; r_A \bullet r_B &lt;/math&gt; is a way of combining resources and &lt;math&gt; \leq &lt;/math&gt; is a relation of approximation.

This semantics of bunched logic draws on prior work in Relevant Logic (especially the operational semantics of Routley-Meyer), but differs from it by not requiring  &lt;math&gt; r \bullet r  \leq r &lt;/math&gt; and by accepting the semantics of standard intuitionistic or classical versions of &lt;math&gt; \wedge &lt;/math&gt; and &lt;math&gt; \Rightarrow &lt;/math&gt;. The property &lt;math&gt; r \bullet r  \leq r &lt;/math&gt;  is justified when thinking about relevance but denied by considerations of resource; having two copies of a resource is not the same as having one, and in some models (e.g. heap models) &lt;math&gt; r \bullet r &lt;/math&gt; might not even be defined. The standard semantics of  &lt;math&gt; \Rightarrow &lt;/math&gt; (or of negation) is often rejected by relevantists in their bid to escape the `paradoxes of material implication', which are not a problem from the perspective of modelling resources and so not rejected by bunched logic. The semantics is also related to the 'phase semantics' of linear logic, but again is differentiated by accepting the standard (even boolean) semantics of &lt;math&gt; \wedge &lt;/math&gt; and &lt;math&gt; \Rightarrow &lt;/math&gt; which in linear logic is rejected in a bid to be constructive. These considerations are discussed in detail in an article on Resource semantics by Pym, O'Hearn and Yang.&lt;ref name=POY04&gt;{{cite journal|last1=Pym|first1=David|last2=O'Hearn|first2=Peter|last3=Yang|first3=Hongseok|title=Possible worlds and resources: The semantics of BI|journal=Theoretical Computer Science|date=2004|volume=315|issue=1|pages=257–305|doi=10.1016/j.tcs.2003.11.020|url=http://www.cs.ucl.ac.uk/staff/p.ohearn/papers/resource.ps}}&lt;/ref&gt;

===Categorical semantics (doubly closed categories)===
The double version of the deduction theorem of bunched logic has a corresponding category-theoretic structure. Proofs in intuitionistic logic can be interpreted in 
[[cartesian closed]]  categories, that is, categories with finite products satisfying the (natural in A and C) adjunction correspondence relating hom sets:
::&lt;math&gt;Hom(A \wedge B, C) \quad \mbox{is isomorphic to} \quad Hom(A, B \Rightarrow C)  &lt;/math&gt;
Bunched logic can be interpreted in categories possessing two such structures
::a categorical model of bunched logic is a single category possessing two closed structures, one symmetric monoidal closed the other cartesian closed.
A host of categorial models can be given using Day's [[tensor product]] construction.&lt;ref&gt;{{cite journal|last1=Day|first1=Brian|title=On closed categories of functors|journal=Reports of the Midwest Category Seminar IV, Springer Lecture Notes in Mathematics 137|date=1970|pages=1–38|url=https://www.math.rochester.edu/people/faculty/doug/otherpapers/DayReport.pdf}}&lt;/ref&gt;
Additionally, implicational fragment of bunched logic has been given a games semantics.&lt;ref&gt;{{cite journal|last1=McCusker|first1=Guy|last2=Pym|first2=David|title=A Games Model of Bunched Implications|journal=Computer Science Logic, Springer Lecture Notes in Computer Science 4646|date=2007|url=http://www.cs.bath.ac.uk/~gam23/papers/innocentBI.pdf}}&lt;/ref&gt;

===Algebraic semantics===
The algebraic semantics of bunched logic is a special case of its categorical semantics, but is simple to state and can be more approachable.
::an algebraic model of bunched logic is a poset which is a [[Heyting algebra]] and which carries an additional commutative [[residuated lattice]] structure (for the same lattice as the Heyting algebra): that is, an ordered commutative monoid with an associated implication satisfying &lt;math&gt;A * B \leq C \quad \mbox{iff} \quad A \leq B {-\!\!*} C&lt;/math&gt;.
The boolean version of bunched logic has models as follows.
::an algebraic model of boolean bunched logic is a poset which is a [[Boolean algebra]] and which carries an additional residuated commutative monoid structure.

===Proof theory and type theory (bunches)===

The [[proof calculus]] of bunched logic
differs from usual [[sequent calculus|sequent calculi]] in having a tree-like context of [[hypothesis|hypotheses]] instead of a flat list-like structure.  In its sequent-based proof theories, the 
context &lt;math&gt;\Delta &lt;/math&gt; in an entailment judgement &lt;math&gt;\Delta \vdash A &lt;/math&gt;
is a tree whose leaves are propositions and whose internal nodes are labelled with modes of composition corresponding to the two conjunctions. 
The two combining operators, comma and semicolon, are used (for instance) in the introduction rules for the two implications. 
:&lt;math&gt;\frac{\Gamma,A \vdash B}{\Gamma \vdash A{-\!\!*} B}  \qquad \qquad \frac{\Gamma;A \vdash B}{\Gamma \vdash A{\Rightarrow} B} &lt;/math&gt;
The difference between the two composition rules comes from additional rules that apply to them.
* Multiplicative composition &lt;math&gt; \Delta , \Gamma &lt;/math&gt; denies the [[structural rule]]s of weakening and contraction.
* Additive composition &lt;math&gt; \Delta ; \Gamma &lt;/math&gt; admits weakening and contraction of entire bunches.
The structural rules and other operations on bunches are often applied deep within a tree-context, and not only at the top level: it is thus in a sense a calculus of [[deep inference]].

Corresponding to bunched logic is a type theory having two kinds of function type. Following the [[Curry–Howard correspondence]], introduction rules for implications correspond to introduction rules for function types.
:&lt;math&gt;\frac{\Gamma,x:A \vdash M:B}{\Gamma \vdash \lambda x.M: A{-\!\!*} B}  \qquad \qquad \frac{\Gamma;x:A \vdash M: B}{\Gamma \vdash \alpha x.M:A{\Rightarrow} B} &lt;/math&gt;
Here, there are two distinct binders, &lt;math&gt;\lambda&lt;/math&gt; and &lt;math&gt;\alpha&lt;/math&gt;, one for each kind of function type.

The proof theory of bunched logic has an historical debt to the use of bunches in Relevance logic.&lt;ref&gt;{{cite book|last1=Read|first1=Stephen|title=Relevant Logic: A Philosophical Examination of Inference|date=1989|publisher=Wiley-Blackwell}}&lt;/ref&gt; But the bunched structure can in a sense be derived from the categorical and algebraic semantics:
to formulate an introduction rule for &lt;math&gt; {-\!\!*} &lt;/math&gt; we should mimick &lt;math&gt; * &lt;/math&gt; on the left in sequents, and to introduce &lt;math&gt; \Rightarrow&lt;/math&gt; we should mimick &lt;math&gt; \wedge &lt;/math&gt;. This consideration leads to the use of two combining operators.

James Brotherston has done further significant work on a unified proof theory for bunched logic and variants,&lt;ref&gt;{{cite journal|last1=Brotherston|first1=James|title=Bunched logics displayed|journal=Studia Logica|date=2012|volume=100|issue=6|pages=1223–1254|url=http://www0.cs.ucl.ac.uk/staff/J.Brotherston/StudiaLogica12/BL_display_SL_final.pdf}}&lt;/ref&gt; employing [[Nuel Belnap|Belnap]]'s notion of [[structural proof theory|display logic]].&lt;ref&gt;{{cite journal|last1=Belnap|first1=Nuel|journal=Journal of Philosophical Logic|date=1982|volume=11|issue=4|pages=375–417}}&lt;/ref&gt;

Galmiche, Méry, and Pym have provided a comprehensive treatment of bunched logic, including completeness and other meta-theory, based on labelled [[Method_of_analytic_tableaux|tableaux]].&lt;ref&gt;{{Cite journal|url = |title = The Semantics of BI and Resource Tableaux|last = Galmiche|first = Didier|date = 2005|journal = Mathematical Structures in Computer Science|doi = |pmid = |access-date = |last2 = Méry|first2 = Daniel|last3 = Pym|first3 = David|volume = 15|pages = 1033–1088}}&lt;/ref&gt;

== Applications ==

=== Interference control ===

In perhaps the first use of substructural type theory to control resources, [[John C. Reynolds]] showed how to use an affine type theory to control aliasing and other forms of interference in Algol-like programming languages.&lt;ref&gt;{{cite journal|last1=Reynolds|first1=John|title=Syntactic Control of Interference|journal=Fifth Annual ACM Symposium on Principles of Programming Languages|pages=39–46|doi=10.1145/512760.512766}}&lt;/ref&gt; O'Hearn used bunched type theory  to extend Reynolds system by allowing interference and non-interference to be more flexibly mixed.&lt;ref name = "OHearn02" /&gt; This resolved open problems concerning recursion and jumps in Reynolds's system.

=== Separation logic ===

Separation logic is an extension of [[Hoare logic]] which facilitates reasoning about mutable data structures that use pointers.  Following Hoare logic the formulae of separation logic are of the form
&lt;math&gt;\{Pre\} program \{Post\}&lt;/math&gt;, but the preconditions and postconditions are formulae interpreted in a model of bunched logic.
The original version of the logic was based on models as follows:
* &lt;math&gt; Heaps = L \rightharpoonup_f V \qquad &lt;/math&gt; (finite partial functions from locations to values)
* &lt;math&gt; h_0 \bullet h_1 = &lt;/math&gt; union of heaps with disjoint domains, undefined when domains overlap.
It is the undefinedness of the composition on overlapping heaps that models the separation idea. This is a model of the boolean variant of bunched logic.

Separation logic was used originally to prove sequential programs, but then was extended to concurrency using a proof rule
:&lt;math&gt; \frac{\{P_1\} C_1 \{Q_1\} \quad \{P_2\} C_2 \{Q_2\}}{\{P_1 * P_2\} C_1 \parallel C_2 \{Q_1 * Q_2\}}&lt;/math&gt;
that divides the storage accessed by parallel threads.&lt;ref&gt;{{cite journal|last1=O'Hearn|first1=Peter|title=Resources, Concurrency and Local Reasoning|journal=Theoretical Computer Science|date=2007|volume=375|issue=1-3|pages=271–307|doi=10.1016/j.tcs.2006.12.035|url=http://www0.cs.ucl.ac.uk/staff/p.ohearn/papers/concur04.pdf}}&lt;/ref&gt;

Later, the greater generality of the resource semantics was utilized: an abstract version of separation logic works for Hoare triples
where the preconditions and postconditions are formulae interpreted over an arbitrary partial commutative monoid instead of a particular heap model.&lt;ref&gt;{{cite journal|last1=Calcagno|first1=Cristiano|last2=O'Hearn|first2=Peter|last3=Yang|first3=Hongseok|title=Local Action and Abstract Separation Logic|journal=22nd Annual IEEE Symposium on Logic in Computer Science|date=2007|doi=10.1109/LICS.2007.30|url=http://www.cs.ox.ac.uk/people/hongseok.yang/paper/asl-short.pdf}}&lt;/ref&gt; 
By suitable choice of commutative monoid, it was surprisingly found that the proofs rules of abstract versions of concurrent separation logic could be used to reason about interfering concurrent processes, for example by encoding rely-guarantee and trace-based reasoning.&lt;ref&gt;{{cite journal|last1=Dinsdale-Young|first1=Thomas|last2=Birkedal|first2=Lars|last3=Gardner|first3=Philippa|last4=Parkinson|first4=Matthew|last5=Yang|first5=Hongseok|title=Views: Compositional Reasoning for Concurrent Programs|journal=Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages|date=2013|doi=10.1145/2480359.2429104|url=http://research.microsoft.com/pubs/180039/views.pdf}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Sergey|first1=Ilya|last2=Nanevski|first2=Aleksandar|last3=Banerjee|first3=Anindya|title=Specifying and Verifying Concurrent Algorithms with Histories and Subjectivity|journal=24th European Symposium on Programming|date=2015|url=http://ilyasergey.net/papers/histories-esop15.pdf}}&lt;/ref&gt;

Separation logic is the basis of a number of tools for automatic and semi-automatic reasoning about programs, and is used in the Infer program analyzer currently deployed at Facebook.&lt;ref&gt;{{cite web|last1=Calcagno|first1=Cristiano|last2=Distefano|first2=Dino|last3=O'Hearn|first3=Peter|title=Open-sourcing Facebook Infer: Identify bugs before you ship|url=https://code.facebook.com/posts/1648953042007882/open-sourcing-facebook-infer-identify-bugs-before-you-ship/}}&lt;/ref&gt;

=== Resources and processes ===

Bunched logic has been used in connection with the (synchronous) resource-process calculus SCRP&lt;ref name=PymTofts2&gt;{{cite journal|last1=Pym|first1=David|last2=Tofts|first2=Chris|title=A Calculus and logic of resources and processes|journal=Formal Aspects of Computing|date=2006|volume=8|issue=4|pages=495–517|url=http://www0.cs.ucl.ac.uk/staff/D.Pym/pym-tofts-fac-preprint.pdf}}&lt;/ref&gt;&lt;ref name=":0"&gt;{{Cite journal|url = |title = Algebra and Logic for Resource-based Systems Modelling|last = Collinson|first = Matthew|journal = Mathematical Structures in Computer Science|doi = 10.1017/S0960129509990077|pmid = |access-date = |last2 = Pym|first2 = David|year = 2009|volume = 19|pages = 959–1027}}&lt;/ref&gt;&lt;ref name=":1"&gt;{{Cite book|title = A Discipline of Mathematical Systems Modelling|last = Collinson|first = Matthew|publisher = College Publications|year = 2012|isbn = 978-1-904987-50-5|location = London|pages = |last2 = Monahan|first2 = Brian|last3 = Pym|first3 = David}}&lt;/ref&gt; in order to give a (modal) logic which characterizes, in the sense of Hennessey-[[Robin Milner|Milner]], the compositional structure of concurrent systems.

SCRP is notable for interpreting &lt;math&gt; A * B &lt;/math&gt; in terms of ''both'' parallel composition of systems and composition of their associated resources.
The semantic clause of SCRP's process logic that corresponds to separation logic's rule for concurrency asserts that a formula &lt;math&gt; A * B &lt;/math&gt; is true in resource-process state &lt;math&gt; R &lt;/math&gt;,&lt;math&gt; E &lt;/math&gt; just in case there are decompositions of the resource &lt;math&gt;R = S \bullet T&lt;/math&gt; and process 
&lt;math&gt;E&lt;/math&gt; ~ &lt;math&gt;F \times G&lt;/math&gt;, where ~ denotes bisimulation, such that &lt;math&gt;A&lt;/math&gt; is true in the resource-process state &lt;math&gt; S &lt;/math&gt; , &lt;math&gt; F &lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; is true in the resource-process state &lt;math&gt; T &lt;/math&gt; , &lt;math&gt; G &lt;/math&gt;; that is &lt;math&gt; R , E \models A &lt;/math&gt; iff &lt;math&gt; S , F \models A &lt;/math&gt; and &lt;math&gt; T , G \models B &lt;/math&gt;.

The system SCRP &lt;ref name="PymTofts2" /&gt;&lt;ref name=":0" /&gt;&lt;ref name=":1" /&gt; is based directly on bunched logic's resource semantics; that is, on ordered monoids of resource elements. While direct and intuitively appealing, this choice leads to a specific technical problem: the Hennessy-Milner completeness theorem holds only for fragments of the modal logic that exclude the multiplicative implication and multiplicative modalities. This problem is solved by basing resource-process calculus on a resource semantics in which resource elements are combined using two combinators, one corresponding to concurrent composition and one corresponding to choice.&lt;ref&gt;{{Cite journal|url = |title = A Calculus and Logic of Bunched Resources and Processes|last = Anderson|first = Gabrielle|date = 2015|journal = Theoretical Computer Science|doi = 10.1016/j.tcs.2015.11.035|pmid = |access-date = |last2 = Pym|first2 = David}}&lt;/ref&gt;

=== Spatial logics ===

Cardelli, Caires, Gordon and others have investigated a series of logics of process calculi, where a conjunction is interpreted in terms of parallel composition. [References, to add]
Unlike the work of Pym et al. in SCRP, they do not distinguish between parallel composition of systems and composition of resources accessed by the systems.

Their logics are based on instances of the resource semantics which give rise to models of the boolean variant of bunched logic. 
Although these logics give rise to instances of boolean bunched logic, they appear to have been arrived at independently, and in any case have significant additional structure in the way of modalities and binders. Related logics have been proposed as well for modelling XML data.

==See also==
* [[Separation logic]]
* [[Relevance logic]]
* [[Linear logic]]

==References==
{{reflist}}

[[Category:Mathematical logic]]
[[Category:Logic in computer science]]
[[Category:Substructural logic]]</text>
      <sha1>opt3k39aptij5artoiz0f2sbummf4oo</sha1>
    </revision>
  </page>
  <page>
    <title>Cash accumulation equation</title>
    <ns>0</ns>
    <id>7393593</id>
    <revision>
      <id>829725600</id>
      <parentid>829541758</parentid>
      <timestamp>2018-03-10T12:10:25Z</timestamp>
      <contributor>
        <username>Narky Blert</username>
        <id>22041646</id>
      </contributor>
      <comment>dab tag resolved</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4162">{{multiple issues|
{{Underlinked|date=September 2014}}
{{Unreferenced|date=February 2007}}
}}

The '''cash accumulation equation''' is an [[equation]] which calculates how much money will be in a [[bank account]], at any point in time. The account pays [[interest]], and is being fed a steady trickle of money.

== Compound interest ==
We will approach the development of this equation by first considering the simpler case, that of just placing a [[lump sum]] in an account and then making no additions to the sum. With the usual [[notation]], namely
{|
| style="padding-left:2em" |&lt;math&gt;y\,\!&lt;/math&gt;|| = the current sum (dollars)
|-
| style="padding-left:2em" |&lt;math&gt;P\,\!&lt;/math&gt;|| = principal (dollars)
|-
| style="padding-left:2em" |&lt;math&gt;i\,\!&lt;/math&gt;|| = force of interest (per year)
|-
| style="padding-left:2em" |&lt;math&gt;t\,\!&lt;/math&gt;|| = time (years)
|}
the equation is
{{Equation|1=y = Pe^{it}|2 = 1}}
and so the sum of money grows exponentially. Differentiating this we derive
{{Equation|1=\frac{dy}{dt} = iPe^{it}|2= 2}}
and applying the definition of {{mvar|y}} from eqn (1) to eqn (2), yields
{{Equation|1=\frac{dy}{dt} = iy |2 = 3}}
Note that eqn. (1) is a particular solution to the ordinary differential equation in eqn. (3), with {{mvar|y}} equal to {{mvar|P}} at {{mvar|1=t=0}}.

== Cash infeed ==
Having achieved this we are ready to start feeding money into the account, at a rate of &lt;math&gt;F\,\!&lt;/math&gt; dollars/year. This is effected by making a small change to eqn (3) as follows

:&lt;math&gt;dy = iy\,dt + F\,dt&lt;/math&gt;

and accordingly we need to solve the equation

: &lt;math&gt;t = \int\frac{dy}{iy+F}&lt;/math&gt;

From a table of integrals, the solution is

:&lt;math&gt;t = \frac{1}{i}\ln(iy + F) + k&lt;/math&gt;

where &lt;math&gt;k\,\!&lt;/math&gt; is the constant of integration. The initial sum deposited was &lt;math&gt;P\,\!&lt;/math&gt; so we know one point on the curve :

:&lt;math&gt;(t,y) = (0,P)\,\!&lt;/math&gt;

and making this substitution we find that

:&lt;math&gt;k = -\frac{1}{i}\ln(iP + F)&lt;/math&gt;

Using this expression for &lt;math&gt;k\,\!&lt;/math&gt;, and recalling that

:&lt;math&gt;\ln(a) - \ln(b) = \ln\left(\frac{a}{b}\right)&lt;/math&gt;

gives us the solution :

:&lt;math&gt;it = \ln\left(\frac{iy + F}{iP + F}\right)&lt;/math&gt;

This is the neatest form of the cash accumulation equation, as we are calling it, but it not the most useful form. Using the exponential instead of the logarithmic function, the equation can be written out like this :
{{Equation|1=y = Pe^{it} + \frac{F}{i}(e^{it}-1)\mbox{ , }i \ne 0|2=4}}

== First special case ==
From this new perspective, eqn (1) is just a special case of eqn (4) - namely with &lt;math&gt;F = 0\,&lt;/math&gt;.

== Second special case ==
For completeness we will consider the case &lt;math&gt;i = 0\,\!&lt;/math&gt;, and specifically the expression
:&lt;math&gt;\frac{e^{it}-1}{i}\mbox{ , }i = 0\,&lt;/math&gt;
One way of evaluating this is to write out the Maclaurin expansion
:&lt;math&gt;e^{it} = 1 + it + \frac{(it)^2}{2!} + \cdots&lt;/math&gt;
At a glance we can subtract &lt;math&gt;1\,\!&lt;/math&gt; from this series and divide by &lt;math&gt;i\,\!&lt;/math&gt;, to find out that
:&lt;math&gt;\frac{e^{it}-1}{i} = t\mbox{ , }i = 0\,&lt;/math&gt;
With this result the cash accumulation equation now reads
:&lt;math&gt;y = P + Ft\mbox{ , }i = 0\,&lt;/math&gt;
Thus the cash sum just increases linearly, as expected, if no interest is being paid.

== Third special case ==
The only other special case to mention is &lt;math&gt;F = -iP\,\!&lt;/math&gt;. Upon making this substitution, eqn (4) becomes simply
:&lt;math&gt;y = P\,&lt;/math&gt;
Evidently &lt;math&gt;F\,\!&lt;/math&gt; is negative, and money is being withdrawn rather than deposited. Specifically, the interest is being withdrawn as fast as it is being earned.

An alternative interpretation of this special case is that &lt;math&gt;P\,\!&lt;/math&gt; is negative - the account is overdrawn - and money is being fed in at a rate which just meets the interest charges. A force of interest value is always positive.

== External links ==
* [http://www.chtrading.co.uk/cae.pdf an extended version of this article]
* [http://formularium.org/?go=61 try out the equation with you own values]{{dead link|date=November 2016 |bot=InternetArchiveBot |fix-attempted=yes }}

[[Category:Interest|Interest rates]]
[[Category:Mathematical finance]]</text>
      <sha1>q6xw9pgtz4za1wpvzr2vkqwo5zmr34p</sha1>
    </revision>
  </page>
  <page>
    <title>Collusion</title>
    <ns>0</ns>
    <id>162557</id>
    <revision>
      <id>861268330</id>
      <parentid>859830706</parentid>
      <timestamp>2018-09-26T07:09:08Z</timestamp>
      <contributor>
        <ip>2A02:AA10:8102:B580:19C:8290:4D3:55C7</ip>
      </contributor>
      <comment>/* Definition */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8121">{{For|a secret agreement by people to commit something criminally or civilly wrong or illegal|Conspiracy}}
{{other uses}}
{{wiktionary|collude}}
{{Competition law}}
'''Collusion''' is a secret agreement between two or more parties to limit open [[competition]] by deceiving, misleading, or defrauding others of their legal rights, or to obtain an objective forbidden by [[law]] typically by defrauding or gaining an unfair market advantage.  It is an agreement among firms or individuals to divide a market, set prices, limit production or limit opportunities.&lt;ref&gt;{{cite book
 | last = O'Sullivan | first = Arthur
 | authorlink = Arthur O'Sullivan (economist)
 | first2 = Steven M. | last2 = Sheffrin
 | title = Economics: Principles in Action
 | publisher = Pearson Prentice Hall
 | year = 2003
 | location = Upper Saddle River, New Jersey 07458
 | pages = 171
 | isbn = 0-13-063085-3}}&lt;/ref&gt;
It can involve "unions, wage fixing, kickbacks, or misrepresenting the independence of the relationship between the colluding parties".&lt;ref&gt;[http://definitions.uslegal.com/c/collusion/ Collusion Law &amp; Legal Definition]&lt;/ref&gt;  In legal terms, all acts effected&lt;!-- "effect" is used intentionally as a verb meaning "to make or bring about". See dictionary.  --&gt;  by collusion are considered [[void (law)|void]].&lt;ref&gt;Collusion [http://encarta.msn.com/encyclopedia_761571249/Collusion.html]. [https://www.webcitation.org/5kwRA5eiX Archived] 2009-10-31.&lt;/ref&gt;

== Definition ==
In the study of [[economics]] and market [[competition]], collusion takes place within an [[industry]] when rival companies cooperate for their mutual benefit. Collusion most often takes place within the [[market structure]] of [[oligopoly]], where the decision of a few firms to collude can significantly impact the market as a whole. Collusion which is covert, on the other hand, is known as [[tacit collusion]], and is legal.

== Variations ==
According to [[Neoclassical economics|neoclassical price-determination theory]] and [[game theory]], the independence of suppliers forces prices to their minimum, increasing [[Economic efficiency|efficiency]] and decreasing the price determining ability of each individual firm.{{citation needed|date=June 2015}} However, if firms collude to all increase prices, loss of sales is minimized, as consumers lack alternative choices at lower prices.{{citation needed|date=June 2015}} This benefits the colluding firms at the cost of [[Economic efficiency|efficiency]] to society.{{citation needed|date=June 2015}}

One variation of this traditional theory is the theory of [[kinked demand]]. Firms face a kinked demand curve if, when one firm decreases its price, other firms will follow suit in order to maintain sales, and when one firm increases its price, its rivals are unlikely to follow, as they would lose the sales' gains that they would otherwise get by holding prices at the previous level.  Kinked demand potentially fosters [[supra-competitive prices]] because any one firm would receive a reduced benefit from cutting price, as opposed to the benefits accruing under neoclassical theory and certain game theoretic models such as [[Bertrand competition]].{{citation needed|date=June 2015}}

== Indicators ==
Practices that suggest possible collusion include:

* [[Price fixing|Uniform prices]]
* A penalty for price discounts
* Advance notice of price changes
* Information exchange

== Examples ==
Collusion is illegal in the [[United States]], [[Canada]] and most of the [[European Union|EU]] due to [[antitrust]] laws, but implicit collusion in the form of [[price leadership]] and tacit understandings still takes place. Several examples of collusion in the United States include:

* Market division and price-fixing among manufacturers of heavy [[electricity|electrical]] equipment in the 1960s, including [[General Electric]].&lt;ref&gt;{{cite book
| title = Encyclopedia of white-collar &amp; corporate crime
| url = https://books.google.com/books?id=0f7yTNb_V3QC&amp;pg=PA377&amp;lpg=PA377&amp;dq=market+division+collusion+heavy+electrical+equipment++1960}}&lt;/ref&gt;
* An attempt by [[Major League Baseball]] owners to [[Baseball collusion|restrict players' salaries]] in the mid-1980s.
* The sharing of potential contract terms by [[NBA]] free agents in an effort to help a targeted franchise circumvent the salary cap.
* Price fixing within [[food]] manufacturers providing cafeteria food to [[school]]s and the [[military]] in 1993.
* Market division and output determination of livestock feed additive, called [[lysine]], by companies in the US, [[Japan]] and [[South Korea]] in 1996, [[Archer Daniels Midland]] being the most notable of these.&lt;ref&gt;Hunter-Gault, Charlayne (October 15, 1996). "ADM: Who's Next?". MacNeil/Lehrer Newshour (PBS). https://www.pbs.org/newshour/bb/business/october96/adm_10-15.html. Retrieved on 2007-10-17.&lt;/ref&gt;
* [[Glossary of poker terms#C|Chip dumping]] in [[poker]]&lt;ref&gt;T. Hayes, [https://www.lybrary.com/collusion-strategy-and-analysis-for-texas-holdem-p-922246.html "Collusion Strategy and Analysis for Texas Hold'em"], 2017&lt;/ref&gt; or any other card game played for money.

There are many ways that implicit collusion tends to develop:

* The practice of stock analyst conference calls and meetings of industry participants almost necessarily results in tremendous amounts of strategic and price transparency. This allows each firm to see how and why every other firm is pricing their products.
* If the practice of the industry causes more complicated pricing, which is hard for the consumer to understand (such as [[risk-based pricing]], hidden taxes and fees in the wireless industry, negotiable pricing), this can cause competition based on price to be meaningless (because it would be too complicated to explain to the customer in a short advertisement). This causes industries to have essentially the same prices and compete on advertising and image, something theoretically as damaging to consumers as normal price fixing.{{Citation needed|date=September 2011}}
{{See also|Disney litigation}}

== Barriers ==
There can be significant barriers to collusion. In any given industry, these may include:

* The number of firms: As the number of firms in an [[industry]] increases, it is more difficult to successfully organize, collude and communicate.
* Cost and demand differences between firms: If costs vary significantly between firms, it may be impossible to establish a price at which to fix output.
* Cheating: There is considerable incentive to cheat on collusion agreements; although lowering prices might trigger [[price wars]], in the short term the defecting firm may gain considerably. This phenomenon is frequently referred to as "chiseling".
* Potential entry: New firms may enter the industry, establishing a new baseline price and eliminating collusion (though anti-dumping laws and tariffs can prevent foreign companies entering the market).
* Economic recession: An increase in average total cost or a decrease in revenue provides incentive to compete with rival firms in order to secure a larger market share and increased demand.
* Anticollusion legal framework and [[collusive lawsuit]].

== See also ==
* [[Collusive lawsuit]]
* [[Conscious parallelism]]
* [[Corporate crime]]
* [[Baseball collusion]]
* [[Cartel]]

== References ==
===General references===
* Vives, X. (1999) ''Oligopoly pricing'', [[MIT Press]], Cambridge MA (readable; suitable for advanced undergraduates.)
*[[Jean Tirole|Tirole, J.]] (1988) ''The Theory of Industrial Organization'', MIT Press, Cambridge MA  (An organized introduction to industrial organization)
*[[Jean Tirole|Tirole, J.]] (1986), "Hierarchies and Bureaucracies", Journal of Law Economics and Organization, vol. 2, pp.&amp;nbsp;181–214.
*[[Jean Tirole|Tirole, J.]] (1992), "Collusion and the Theory of Organizations", Advances in Economic Theory: Proceedings of the Sixth World Congress of the Econometric Society, ed by J.-J. Laffont. Cambridge: Cambridge University Press, vol.2:151-206.

===Inline citations===
&lt;references/&gt;

{{game theory}}

[[Category:Anti-competitive behaviour]]
[[Category:Game theory]]</text>
      <sha1>9uj65ww6mqbt1i3xhqzzn7qma8movnf</sha1>
    </revision>
  </page>
  <page>
    <title>Conway triangle notation</title>
    <ns>0</ns>
    <id>15910144</id>
    <revision>
      <id>870524598</id>
      <parentid>731748966</parentid>
      <timestamp>2018-11-25T11:10:42Z</timestamp>
      <contributor>
        <username>Ronvdburg</username>
        <id>14087214</id>
      </contributor>
      <comment>Explained where one step comes from.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5507">In [[geometry]], the '''Conway triangle notation''', named after [[John Horton Conway]], allows [[trigonometric functions]] of a [[triangle]] to be managed algebraically. Given a reference triangle whose sides are ''a'', ''b'' and ''c'' and whose corresponding internal [[angle]]s are ''A'', ''B'', and ''C'' then the Conway triangle notation is simply represented as follows:

:&lt;math&gt; S = bc \sin A = ac \sin B = ab \sin C \,&lt;/math&gt;

where ''S'' = 2 &amp;times; area of reference triangle and
 
:&lt;math&gt; S_\varphi = S \cot \varphi .  \,&lt;/math&gt;

in particular

:&lt;math&gt; S_A = S \cot A = bc \cos A= \frac {b^2+c^2-a^2} {2}\,&lt;/math&gt;

:&lt;math&gt; S_B = S \cot B = ac \cos B= \frac {a^2+c^2-b^2} {2}\,&lt;/math&gt;

:&lt;math&gt; S_C = S \cot C = ab \cos C= \frac {a^2+b^2-c^2} {2}\,&lt;/math&gt;

:&lt;math&gt; S_\omega = S \cot \omega = \frac {a^2+b^2+c^2} {2}\,&lt;/math&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; where &lt;math&gt; \omega \,&lt;/math&gt; is the [[Brocard angle]]. The [[law of cosines]] is used: &lt;math&gt;a^2=b^2+c^2-2bc \cos A&lt;/math&gt;.

:&lt;math&gt; S_{\frac {\pi} {3}} = S \cot {\frac {\pi} {3}} = S \frac {\sqrt 3}{3} \,&lt;/math&gt;

:&lt;math&gt; S_{2\varphi} = \frac {S_\varphi^2 - S^2} {2S_\varphi} \quad\quad S_{ \frac {\varphi} {2}} = S_\varphi + \sqrt {S_\varphi^2 + S^2} \,&lt;/math&gt; &amp;nbsp;&amp;nbsp; for values of &amp;nbsp; &lt;math&gt; \varphi &lt;/math&gt;&amp;nbsp; where &amp;nbsp; &lt;math&gt; 0 &lt; \varphi &lt; \pi \, &lt;/math&gt;

:&lt;math&gt; S_{\vartheta + \varphi} = \frac {S_\vartheta S_\varphi - S^2} {S_\vartheta + S_\varphi} \quad\quad S_{\vartheta - \varphi} = \frac {S_\vartheta S_\varphi + S^2} {S_\varphi - S_\vartheta}  \, .&lt;/math&gt;

Furthermore the convention uses a shorthand notation for &lt;math&gt; S_{\vartheta}S_{\varphi}=S_{\vartheta\varphi} \, &lt;/math&gt; and &lt;math&gt; S_{\vartheta}S_{\varphi}S_{\psi}=S_{\vartheta\varphi\psi} \, .&lt;/math&gt;

Hence:

:&lt;math&gt; \sin A = \frac {S} {bc} = \frac {S} {\sqrt {S_A^2 + S^2}} \quad\quad \cos A = \frac {S_A} {bc} = \frac {S_A} {\sqrt {S_A^2 + S^2}} \quad\quad \tan A = \frac {S} {S_A}  \, &lt;/math&gt;

:&lt;math&gt; a^2 = S_B + S_C \quad\quad b^2 = S_A + S_C \quad\quad c^2 = S_A + S_B \, .&lt;/math&gt;

Some important identities:

:&lt;math&gt; \sum_\text{cyclic} S_A = S_A+S_B+S_C = S_\omega \, &lt;/math&gt;

:&lt;math&gt; S^2 = b^2c^2 - S_A^2 = a^2c^2 - S_B^2 = a^2b^2 - S_C^2 \, &lt;/math&gt;

:&lt;math&gt; S_{BC} = S_BS_C = S^2 - a^2S_A \quad\quad S_{AC} = S_AS_C = S^2 - b^2S_B \quad\quad S_{AB} = S_AS_B = S^2 - c^2S_C  \, &lt;/math&gt;

:&lt;math&gt; S_{ABC} = S_AS_BS_C = S^2(S_\omega-4R^2)\quad\quad S_\omega=s^2-r^2-4rR \, &lt;/math&gt;

where ''R'' is the [[circumcenter|circumradius]] and ''abc''&amp;nbsp;=&amp;nbsp;2''SR'' and where ''r'' is the [[incenter]],&amp;nbsp;&amp;nbsp; &lt;math&gt; s= \frac{a+b+c}{2} \, &lt;/math&gt;&amp;nbsp;&amp;nbsp; and&amp;nbsp;&amp;nbsp; &lt;math&gt; a+b+c = \frac {S} {r} \, .&lt;/math&gt;

Some useful trigonometric conversions:

:&lt;math&gt; \sin A \sin B \sin C = \frac {S} {4R^2} \quad\quad \cos A \cos B \cos C = \frac {S_\omega-4R^2} {4R^2} &lt;/math&gt;
:&lt;math&gt; \sum_\text{cyclic} \sin A = \frac {S} {2Rr} = \frac {s}{R} \quad\quad \sum_\text{cyclic} \cos A = \frac {r+R} {R} \quad\quad \sum_\text{cyclic} \tan A = \frac {S}{S_\omega-4R^2}=\tan A \tan B \tan C \, .&lt;/math&gt;


Some useful formulas:

:&lt;math&gt; \sum_\text{cyclic} a^2S_A = a^2S_A + b^2S_B + c^2 S_C = 2S^2 \quad\quad \sum_\text{cyclic} a^4 = 2(S_\omega^2-S^2) \, &lt;/math&gt;

:&lt;math&gt; \sum_\text{cyclic} S_A^2 = S_\omega^2 - 2S^2 \quad\quad  \sum_\text{cyclic} S_{BC} = \sum_\text{cyclic} S_BS_C = S^2 \quad\quad \sum_\text{cyclic} b^2c^2 =  S_\omega^2 + S^2 \, .&lt;/math&gt;

Some examples using Conway triangle notation:

Let ''D'' be the distance between two points P and Q whose [[trilinear coordinates]] are ''p''&lt;sub&gt;''a''&lt;/sub&gt; : ''p''&lt;sub&gt;''b''&lt;/sub&gt; : ''p''&lt;sub&gt;''c''&lt;/sub&gt; and ''q''&lt;sub&gt;''a''&lt;/sub&gt; : ''q''&lt;sub&gt;''b''&lt;/sub&gt; : ''q''&lt;sub&gt;''c''&lt;/sub&gt;. Let ''K''&lt;sub&gt;''p''&lt;/sub&gt; = ''ap''&lt;sub&gt;''a''&lt;/sub&gt; + ''bp''&lt;sub&gt;''b''&lt;/sub&gt; + ''cp''&lt;sub&gt;''c''&lt;/sub&gt; and let ''K''&lt;sub&gt;''q''&lt;/sub&gt; = ''aq''&lt;sub&gt;''a''&lt;/sub&gt; + ''bq''&lt;sub&gt;''b''&lt;/sub&gt; + ''cq''&lt;sub&gt;''c''&lt;/sub&gt;. Then ''D'' is given by the formula:

:&lt;math&gt; D^2= \sum_\text{cyclic} a^2S_A\left(\frac {p_a}{K_p} - \frac {q_a}{K_q}\right)^2 \, .&lt;/math&gt;

Using this formula it is possible to determine OH, the distance between the circumcenter and the [[orthocenter]] as follows:

For the circumcenter ''p''&lt;sub&gt;''a''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''aS''&lt;sub&gt;''A''&lt;/sub&gt; and for the orthocenter ''q''&lt;sub&gt;''a''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''S''&lt;sub&gt;''B''&lt;/sub&gt;''S''&lt;sub&gt;''C''&lt;/sub&gt;/''a''
:&lt;math&gt; K_p= \sum_\text{cyclic} a^2S_A = 2S^2 \quad\quad K_q= \sum_\text{cyclic} S_BS_C = S^2 \, .&lt;/math&gt;

Hence:

:&lt;math&gt;
\begin{align}
D^2 &amp; {} = \sum_\text{cyclic} a^2S_A\left(\frac {aS_A} {2S^2} - \frac {S_BS_C} {aS^2}\right)^2 \\
&amp; {} = \frac {1} {4S^4} \sum_\text{cyclic} a^4S_A^3 - \frac {S_AS_BS_C} {S^4} \sum_\text{cyclic} a^2S_A + \frac {S_AS_BS_C} {S^4} \sum_\text{cyclic} S_BS_C \\
&amp; {} = \frac {1} {4S^4} \sum_\text{cyclic} a^2S_A^2(S^2-S_BS_C) - 2(S_\omega-4R^2) + (S_\omega-4R^2) \\
&amp; {} = \frac {1} {4S^2} \sum_\text{cyclic} a^2S_A^2 - \frac {S_AS_BS_C} {S^4} \sum_\text{cyclic} a^2S_A - (S_\omega-4R^2) \\
&amp; {} = \frac {1} {4S^2} \sum_\text{cyclic} a^2(b^2c^2-S^2) - \frac {1} {2}(S_\omega-4R^2) -(S_\omega-4R^2) \\
&amp; {} = \frac {3a^2b^2c^2} {4S^2} - \frac {1} {4} \sum_\text{cyclic} a^2 - \frac {3} {2}(S_\omega-4R^2) \\
&amp; {} = 3R^2- \frac {1} {2} S_\omega - \frac {3} {2} S_\omega + 6R^2 \\
&amp; {} = 9R^2- 2S_\omega.
\end{align}
&lt;/math&gt;

This gives:

:&lt;math&gt; OH = \sqrt{9R^2- 2S_\omega \,}.&lt;/math&gt;

==References==
* {{mathworld|urlname=ConwayTriangleNotation|title=Conway Triangle Notation}}

[[Category:Triangle geometry]]
[[Category:Trigonometry]]</text>
      <sha1>smb6vmqbvb09btj9cuu04vy4dzmovns</sha1>
    </revision>
  </page>
  <page>
    <title>Economic capital</title>
    <ns>0</ns>
    <id>4223273</id>
    <revision>
      <id>867426557</id>
      <parentid>867381841</parentid>
      <timestamp>2018-11-05T17:15:04Z</timestamp>
      <contributor>
        <username>Zfeinst</username>
        <id>12758922</id>
      </contributor>
      <comment>Undid revision 867381841 by [[Special:Contributions/196.43.178.1|196.43.178.1]] ([[User talk:196.43.178.1|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4523">{{Distinguish|financial capital|financial centre}}
__NOTOC__
In [[finance]], mainly for financial services firms, '''economic capital''' is the amount of [[risk capital]], assessed on a realistic basis, which a firm requires to cover the risks that it is running or collecting as a [[going concern]], such as [[market risk]], [[credit risk]], [[legal risk]], and [[operational risk]].&lt;ref&gt;{{cite web |url=http://riskencyclopedia.com/articles/economic_capital/ |title=Economic Capital |website=Risk Encyclopedia |accessdate=July 10, 2013 }}&lt;/ref&gt; It is the amount of money which is needed to secure survival in a worst-case scenario. Firms and financial services regulators should then aim to hold risk capital of an amount equal at least to economic capital.

Typically, economic capital is calculated by determining the amount of capital that the firm needs to ensure that its realistic [[balance sheet]] stays solvent over a certain time period with a pre-specified probability. Therefore, economic capital is often calculated as [[value at risk]]. The balance sheet, in this case, would be prepared showing market value (rather than book value) of assets and liabilities.

The first accounts of economic capital date back to the ancient [[Phoenicians]], who took rudimentary tallies of frequency and severity of illnesses among rural farmers to gain an intuition of expected losses in productivity. These calculations were advanced by correlations to climate change, political outbreak, and birth rate change.&lt;ref&gt;{{cite web |url=http://www.actuaries.org.uk/documents/b01-using-operational-risk-deliver-shareholder-value-and-meet-regulatory-expectations | title=Economic Capital | website= Institute and Faculty of Actuaries |accessdate=November 16, 2014 }}&lt;/ref&gt;

The concept of economic capital differs from [[regulatory capital]] in the sense that regulatory capital is the mandatory capital the regulators require to be maintained while economic capital is the best estimate of required capital that financial institutions use internally to manage their own risk and to allocate the cost of maintaining regulatory capital among different units within the organization.

==Social science==

In [[social science]], economic capital is distinguished in relation to other types of capital which may not necessarily reflect a [[monetary]] or [[exchange-value]]. These forms of capital include [[natural capital]], [[cultural capital]] and [[social capital]]; the latter two represent a type of power or status that an individual can attain in a [[capitalist]] [[society]] via a formal education or through social ties. Non-economic forms of capital have been variously discussed most famously by sociologist [[Pierre Bourdieu]].

==Notes==
{{Reflist}}

{{Basel II}}
==See also==
* [[Asset allocation]]
* [[Basel I]]
* [[Basel II]]
* [[Capital structure]]
* [[Financial risk management]]
* [[Financial services conglomerate]]
* [[RAROC]], risk-adjusted return on capital
* [[RORAC]], return on risk-adjusted capital
* [[Solvency II]]

==References==
* {{cite book
 | last = Porteous
 | first = Bruce
 |author2=Pradip Tapadar
 | title = Economic Capital and Financial Risk Management for Financial Services Firms and Conglomerates
 | publisher = Palgrave Macmillan
 |date=December 2005
 | isbn = 1-4039-3608-0 }}
* {{cite journal|last1=Porteous|first1=Bruce|last2=Tapadar|first2=Pradip|year=2008|url=http://www.casact.org/library/astin/vol38no1/341.pdf|format=pdf|accessdate=October 11, 2011|title=The Impact of Capital Structure on Economic Capital and Risk Adjusted Performance|journal=ASTIN Bulletin|volume=38|pages=341–380|doi=10.2143/ast.38.1.2030416}}
* {{cite journal|last1=Porteous|first1=Bruce|last2=Tapadar|first2=Pradip|year=2008|title=Asset Allocation to Optimise Life Insurance Annuity Firm Economic Capital and Risk Adjusted Performance|journal=Annals of Actuarial Science|volume=3|pages=187–214|doi=10.1017/s1748499500000506}}

==External links==

* [http://www.fdic.gov/regulations/examinations/supervisory/insights/siwin04/economic_capital.html FDIC.gov], Economic Capital and the Assessment of Capital Adequacy [[Federal Deposit Insurance Corporation]]
* [http://www.bis.org/bcbs/ BIS.org], "Basel Committee, Bank for International Settlements"
* [https://web.archive.org/web/20100327021519/http://www.actuariesindia.org/Presentations/CILA/CILA2009/090827_CILA_Ecocapital.pdf Economic Capital - A Preamble]
* [http://www.ceiops.org/ CEIOPS"]

[[Category:Actuarial science]]
[[Category:Financial risk]]</text>
      <sha1>iykwo38m89182zrqhnwlxtrf3q3drbk</sha1>
    </revision>
  </page>
  <page>
    <title>Energetic space</title>
    <ns>0</ns>
    <id>8364462</id>
    <revision>
      <id>822810489</id>
      <parentid>722532388</parentid>
      <timestamp>2018-01-28T17:01:23Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8232">In [[mathematics]], more precisely in [[functional analysis]], an '''energetic space''' is, intuitively, a subspace of a given [[real number|real]] [[Hilbert space]] equipped with a new "energetic" [[Inner product space|inner product]]. The motivation for the name comes from [[physics]], as in many physical problems the [[energy]] of a system can be expressed in terms of the energetic inner product. An example of this will be given later in the article. 

==Energetic space==
Formally, consider a real Hilbert space &lt;math&gt;X&lt;/math&gt; with the [[Inner product space|inner product]] &lt;math&gt;(\cdot|\cdot)&lt;/math&gt; and the [[norm (mathematics)|norm]] &lt;math&gt;\|\cdot\|&lt;/math&gt;. Let &lt;math&gt;Y&lt;/math&gt; be a linear subspace of &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;B:Y\to X&lt;/math&gt; be a [[strongly monotone]] [[symmetric operator|symmetric]] [[linear operator]], that is, a linear operator satisfying 

* &lt;math&gt;(Bu|v)=(u|Bv)\, &lt;/math&gt; for all &lt;math&gt;u, v&lt;/math&gt; in &lt;math&gt;Y&lt;/math&gt;
* &lt;math&gt;(Bu|u) \ge c\|u\|^2&lt;/math&gt; for some constant &lt;math&gt;c&gt;0&lt;/math&gt; and all &lt;math&gt;u&lt;/math&gt; in &lt;math&gt;Y.&lt;/math&gt;

The '''energetic inner product''' is defined as 
:&lt;math&gt;(u|v)_E =(Bu|v)\,&lt;/math&gt; for all &lt;math&gt;u,v&lt;/math&gt; in &lt;math&gt;Y&lt;/math&gt;
and the '''energetic norm'''{{anchor|energetic norm}} is
:&lt;math&gt;\|u\|_E=(u|u)^\frac{1}{2}_E \, &lt;/math&gt; for all &lt;math&gt;u&lt;/math&gt; in &lt;math&gt;Y.&lt;/math&gt;

The set &lt;math&gt;Y&lt;/math&gt; together with the energetic inner product is a [[pre-Hilbert space]]. The '''energetic space''' &lt;math&gt;X_E&lt;/math&gt; is defined as the [[complete metric space|completion]] of &lt;math&gt;Y&lt;/math&gt; in the energetic norm. &lt;math&gt;X_E&lt;/math&gt; can be considered a subset of the original Hilbert space &lt;math&gt;X,&lt;/math&gt; since any [[Cauchy sequence]] in the energetic norm is also Cauchy in the norm of &lt;math&gt;X&lt;/math&gt; (this follows from the strong monotonicity property of &lt;math&gt;B&lt;/math&gt;). 

The energetic inner product is extended from &lt;math&gt;Y&lt;/math&gt; to &lt;math&gt;X_E&lt;/math&gt; by
: &lt;math&gt; (u|v)_E = \lim_{n\to\infty} (u_n|v_n)_E&lt;/math&gt;
where &lt;math&gt;(u_n)&lt;/math&gt; and &lt;math&gt;(v_n)&lt;/math&gt; are sequences in ''Y'' that converge to points in &lt;math&gt;X_E&lt;/math&gt; in the energetic norm.

==Energetic extension==
The operator &lt;math&gt;B&lt;/math&gt; admits an '''energetic extension''' &lt;math&gt;B_E&lt;/math&gt; 

:&lt;math&gt;B_E:X_E\to X^*_E&lt;/math&gt;

defined on &lt;math&gt;X_E&lt;/math&gt; with values in the [[dual space]] &lt;math&gt;X^*_E&lt;/math&gt; that is given by the formula 

:&lt;math&gt;\langle B_E u | v \rangle_E = (u|v)_E&lt;/math&gt; for all &lt;math&gt;u,v&lt;/math&gt; in &lt;math&gt;X_E.&lt;/math&gt;

Here, &lt;math&gt;\langle \cdot |\cdot \rangle_E&lt;/math&gt; denotes the duality bracket between &lt;math&gt;X^*_E&lt;/math&gt; and &lt;math&gt;X_E,&lt;/math&gt; so &lt;math&gt;\langle B_E u | v \rangle_E&lt;/math&gt; actually denotes  &lt;math&gt;(B_E u)(v).&lt;/math&gt;

If &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;v&lt;/math&gt; are elements in the original subspace &lt;math&gt;Y,&lt;/math&gt; then

:&lt;math&gt;\langle B_E u | v \rangle_E = (u|v)_E = (Bu|v) = \langle u|B|v\rangle&lt;/math&gt;

by the definition of the energetic inner product.  If one views &lt;math&gt;Bu,&lt;/math&gt; which is an element in &lt;math&gt;X,&lt;/math&gt; as an element in the dual &lt;math&gt;X^*&lt;/math&gt; via the [[Riesz representation theorem]], then &lt;math&gt;Bu&lt;/math&gt; will also be in the dual &lt;math&gt;X_E^*&lt;/math&gt; (by the strong monotonicity property of &lt;math&gt;B&lt;/math&gt;). Via these identifications, it follows from the above formula that &lt;math&gt;B_E u= Bu.&lt;/math&gt; In different words, the original operator &lt;math&gt;B:Y\to X&lt;/math&gt; can be viewed as an operator &lt;math&gt;B:Y\to X_E^*,&lt;/math&gt; and then &lt;math&gt;B_E:X_E\to X^*_E&lt;/math&gt; is simply the function extension of &lt;math&gt;B&lt;/math&gt; from &lt;math&gt;Y&lt;/math&gt; to &lt;math&gt;X_E.&lt;/math&gt; &lt;!--- 

I commented out the below text, since it is not clear what norm one uses to talk about convergence and boundedness. I will think more about it. 

That is, &lt;math&gt;B_E&lt;/math&gt; is that [[linear functional]] which acts like ''B'' but has a domain of &lt;math&gt;X_E&lt;/math&gt;—that is, its domain includes all limit points, ''u'', of the domain of ''B'' for which ''Bu&lt;sub&gt;n&lt;/sub&gt;'' is bounded as &lt;math&gt;u_n\to u&lt;/math&gt;.

---&gt;

==An example from physics==
[[File:String illust.svg|right|thumb|A string with fixed endpoints under the influence of a force pointing down.]]
Consider a [[rope|string]]&lt;!-- a piece of wire, so the link to [[rope|string]] is not ambiguous--&gt; whose endpoints are fixed at two points &lt;math&gt;a&lt;b&lt;/math&gt; on the real line   (here viewed as a horizontal line). Let the vertical outer [[force density]] at each point &lt;math&gt;x&lt;/math&gt; &lt;math&gt;(a\le x \le b)&lt;/math&gt; on the string be &lt;math&gt;f(x)\mathbf{e}&lt;/math&gt;, where  &lt;math&gt;\mathbf{e}&lt;/math&gt; is a [[unit vector]] pointing vertically and &lt;math&gt;f:[a, b]\to \mathbb R.&lt;/math&gt; Let &lt;math&gt;u(x)&lt;/math&gt; be the [[Deflection (engineering)|deflection]] of the string at the point &lt;math&gt;x&lt;/math&gt; under the influence of the force. Assuming that the deflection is small, the [[elastic energy]] of the string is 

: &lt;math&gt;\frac{1}{2} \int_a^b\! u'(x)^2\, dx&lt;/math&gt;

and the total [[potential energy]] of the string is

: &lt;math&gt;F(u) = \frac{1}{2} \int_a^b\! u'(x)^2\,dx - \int_a^b\! u(x)f(x)\,dx.&lt;/math&gt;

The deflection &lt;math&gt;u(x)&lt;/math&gt; minimizing the potential energy will satisfy the [[differential equation]]

: &lt;math&gt;-u''=f\,&lt;/math&gt;

with [[boundary conditions]]

:&lt;math&gt;u(a)=u(b)=0.\,&lt;/math&gt;

To study this equation, consider the space &lt;math&gt;X=L^2(a, b), &lt;/math&gt; that is, the [[Lp space]] of all [[square-integrable function]]s &lt;math&gt;u:[a, b]\to \mathbb R&lt;/math&gt; in respect to the [[Lebesgue measure]]. This space is Hilbert in respect to the inner product

: &lt;math&gt;(u|v)=\int_a^b\! u(x)v(x)\,dx,&lt;/math&gt;

with the norm being given by 

: &lt;math&gt;\|u\|=\sqrt{(u|u)}.&lt;/math&gt;

Let &lt;math&gt;Y&lt;/math&gt; be the set of all [[smooth function|twice continuously differentiable functions]] &lt;math&gt;u:[a, b]\to \mathbb R&lt;/math&gt; with the [[boundary conditions]] &lt;math&gt;u(a)=u(b)=0.&lt;/math&gt; Then &lt;math&gt;Y&lt;/math&gt; is a linear subspace of &lt;math&gt;X.&lt;/math&gt;

Consider the operator &lt;math&gt;B:Y\to X&lt;/math&gt; given by the formula

: &lt;math&gt;Bu = -u'',\,&lt;/math&gt;

so the deflection satisfies the equation &lt;math&gt;Bu=f.&lt;/math&gt; Using  [[integration by parts]] and the boundary conditions, one can see that 

: &lt;math&gt;(Bu|v)=-\int_a^b\! u''(x)v(x)\, dx=\int_a^b u'(x)v'(x) = (u|Bv) &lt;/math&gt;

for any &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;v&lt;/math&gt; in &lt;math&gt;Y.&lt;/math&gt; Therefore, &lt;math&gt;B&lt;/math&gt; is a symmetric linear operator. 

&lt;math&gt;B&lt;/math&gt; is also strongly monotone, since, by the [[Friedrichs's inequality]] 

: &lt;math&gt;\|u\|^2 = \int_a^b u^2(x)\, dx \le C \int_a^b u'(x)^2\, dx = C\,(Bu|u)&lt;/math&gt;

for some &lt;math&gt;C&gt;0.&lt;/math&gt;

The energetic space in respect to the operator &lt;math&gt;B&lt;/math&gt; is then the [[Sobolev space]] &lt;math&gt;H^1_0(a, b).&lt;/math&gt; We see that the elastic energy of the string which motivated this study is 

: &lt;math&gt;\frac{1}{2} \int_a^b\! u'(x)^2\, dx = \frac{1}{2} (u|u)_E,&lt;/math&gt;

so it is half of the energetic inner product of &lt;math&gt;u&lt;/math&gt; with itself. 

To calculate the deflection &lt;math&gt;u&lt;/math&gt; minimizing the total potential energy &lt;math&gt;F(u)&lt;/math&gt; of the string, one writes this problem in the form 

:&lt;math&gt;(u|v)_E=(f|v)\,&lt;/math&gt; for all &lt;math&gt;v&lt;/math&gt; in &lt;math&gt;X_E&lt;/math&gt;.

Next, one usually approximates &lt;math&gt;u&lt;/math&gt; by some &lt;math&gt;u_h&lt;/math&gt;, a function in a finite-dimensional subspace of the true solution space. For example, one might let &lt;math&gt;u_h&lt;/math&gt; be a continuous [[piecewise linear function]] in the energetic space, which gives the [[finite element method]]. The approximation &lt;math&gt;u_h&lt;/math&gt; can be computed by solving a [[system of linear equations]].

The energetic norm turns out to be the natural norm in which to measure the error between  &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;u_h&lt;/math&gt;, see [[Céa's lemma]].

==See also==
* [[Inner product space]]
* [[Positive-definite kernel]]

==References==
*{{cite book
 | last       = Zeidler
 | first      = Eberhard
 | title      = Applied functional analysis: applications to mathematical physics
 | publisher  = New York: Springer-Verlag
 | date       = 1995
 | pages      = 
 | isbn       = 0-387-94442-7
}}

*{{cite book
 | last       = Johnson
 | first      = Claes
 | title      = Numerical solution of partial differential equations by the finite element method
 | publisher  = Cambridge University Press
 | date       = 1987
 | pages      = 
 | isbn       = 0-521-34514-6
}}

[[Category:Functional analysis]]
[[Category:Hilbert space]]</text>
      <sha1>e2ja4n838lt4n3l6v3u63nb86hl4v1l</sha1>
    </revision>
  </page>
  <page>
    <title>Frobenius theorem (real division algebras)</title>
    <ns>0</ns>
    <id>3966889</id>
    <revision>
      <id>856762414</id>
      <parentid>856472234</parentid>
      <timestamp>2018-08-27T11:10:27Z</timestamp>
      <contributor>
        <username>Adam Dent</username>
        <id>8381649</id>
      </contributor>
      <minor/>
      <comment>real dimension, specifically</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9207">In [[mathematics]], more specifically in [[abstract algebra]], the '''Frobenius theorem''', proved by [[Ferdinand Georg Frobenius]] in 1877, characterizes the [[finite-dimensional]] [[Associative algebra|associative]] [[division algebra]]s over the [[real number]]s.  According to the theorem, every such algebra is [[isomorphic]] to one of the following:
* {{math|'''R'''}} (the real numbers)
* {{math|'''C'''}} (the [[complex number]]s)
* {{math|'''H'''}} (the [[quaternions]]).
These algebras have real dimension {{math|1, 2}}, and {{math|4}}, respectively.  Of these three algebras, {{math|'''R'''}} and {{math|'''C'''}} are [[commutative]], but {{math|'''H'''}} is not.

==Proof==
The main ingredients for the following proof are the [[Cayley–Hamilton theorem]] and the [[fundamental theorem of algebra]].

===Introducing some notation===
* Let {{math|''D''}} be the division algebra in question.
* We identify the real multiples of {{math|1}} with {{math|'''R'''}}.
* When we write {{math|''a'' ≤ 0}} for an element {{mvar|a}} of {{mvar|D}}, we tacitly assume that {{mvar|a}} is contained in {{math|'''R'''}}.
* We can consider {{mvar|D}} as a finite-dimensional {{math|'''R'''}}-[[vector space]]. Any element {{mvar|d}} of {{mvar|D}} defines an [[endomorphism]] of {{mvar|D}} by left-multiplication, we identify {{mvar|d}} with that endomorphism. Therefore, we can speak about the [[trace (linear algebra)|trace]] of {{mvar|d}}, and its [[characteristic polynomial|characteristic]] and [[Minimal polynomial (linear algebra)|minimal]] [[polynomial]]s.
* For any {{mvar|z}} in {{math|'''C'''}} define the following real quadratic polynomial:
::&lt;math&gt;Q(z; x) = x^2 - 2\operatorname{Re}(z)x + |z|^2 = (x-z)(x-\overline{z}) \in \mathbf{R}[x].&lt;/math&gt;
:Note that if {{math|''z'' ∈ '''C''' ∖ '''R'''}} then {{math|''Q''(''z''; ''x'')}} is irreducible over {{math|'''R'''}}.

===The claim===
The key to the argument is the following

:'''Claim.''' The set {{mvar|V}} of all elements {{mvar|a}} of {{mvar|D}} such that {{math|''a''&lt;sup&gt;2&lt;/sup&gt; ≤ 0}} is a vector subspace of {{mvar|D}} of [[codimension]] {{math|1}}. Moreover {{math|''D'' {{=}} '''R''' ⊕ ''V''}} as {{math|'''R'''}}-vector spaces, which implies that {{mvar|V}} generates {{mvar|D}} as an algebra.

'''Proof of Claim:''' Let {{mvar|m}} be the dimension of {{mvar|D}} as an {{math|'''R'''}}-vector space, and pick {{mvar|a}} in {{mvar|D}} with characteristic polynomial {{math|''p''(''x'')}}. By the fundamental theorem of algebra, we can write

:&lt;math&gt; p(x)= (x-t_1)\cdots(x-t_r) (x-z_1)(x - \overline{z_1}) \cdots (x-z_s)(x - \overline{z_s}), \qquad t_i \in \mathbf{R}, \quad z_j \in \mathbf{C} \backslash \mathbf{R}.&lt;/math&gt;

We can rewrite {{math|''p''(''x'')}} in terms of the polynomials {{math|''Q''(''z''; ''x'')}}:

:&lt;math&gt; p(x)= (x-t_1)\cdots(x-t_r) Q(z_1; x) \cdots Q(z_s; x).&lt;/math&gt;

Since {{math|''z&lt;sub&gt;j&lt;/sub&gt;'' ∈ '''C'''\'''R'''}}, the polynomials {{math|''Q''(''z&lt;sub&gt;j&lt;/sub&gt;''; ''x'')}} are all [[irreducible polynomial|irreducible]] over {{math|'''R'''}}. By the Cayley–Hamilton theorem, {{math|''p''(''a'') {{=}} 0}} and because {{mvar|D}} is a division algebra, it follows that either {{math|''a'' − ''t&lt;sub&gt;i&lt;/sub&gt;'' {{=}} 0}} for some {{mvar|i}} or that {{math|''Q''(''z&lt;sub&gt;j&lt;/sub&gt;''; ''a'') {{=}} 0}} for some {{mvar|j}}. The first case implies that {{mvar|a}} is real. In the second case, it follows that {{math|''Q''(''z&lt;sub&gt;j&lt;/sub&gt;''; ''x'')}} is the minimal polynomial of {{mvar|a}}. Because {{math|''p''(''x'')}} has the same complex roots as the minimal polynomial and because it is real it follows that

:&lt;math&gt; p(x)= Q(z_j; x)^k = \left (x^2 - 2\operatorname{Re}(z_j) x + |z_j|^2 \right )^k &lt;/math&gt;

Since {{math|''p''(''x'')}} is the characteristic polynomial of {{mvar|a}} the coefficient of {{math|''x''&lt;sup&gt;2''k''−1&lt;/sup&gt;}} in {{math|''p''(''x'')}} is {{math|tr(''a'')}} up to a sign. Therefore, we read from the above equation we have: {{math|tr(''a'') {{=}} 0}} if and only if {{math|Re(''z&lt;sub&gt;j&lt;/sub&gt;'') {{=}} 0}}, in other words {{math|tr(''a'') {{=}} 0}} if and only if {{math|''a''&lt;sup&gt;2&lt;/sup&gt; {{=}} −{{!}}''z&lt;sub&gt;j&lt;/sub&gt;''{{!}}&lt;sup&gt;2&lt;/sup&gt; &lt; 0}}.

So {{mvar|V}} is the subset of all {{mvar|a}} with {{math|tr(''a'') {{=}} 0}}. In particular, it is a vector subspace. Moreover, {{mvar|V}} has codimension {{math|1}} since it is the kernel of a non-zero linear form, and note that {{mvar|D}} is the direct sum of {{math|'''R'''}} and {{mvar|V}} as vector spaces.

===The finish===
For {{math|''a'', ''b''}} in {{mvar|V}} define {{math|''B''(''a'', ''b'') {{=}} (−''ab'' − ''ba'')/2}}. Because of the identity {{math|(''a'' + ''b'')&lt;sup&gt;2&lt;/sup&gt; − ''a''&lt;sup&gt;2&lt;/sup&gt; − ''b''&lt;sup&gt;2&lt;/sup&gt; {{=}} ''ab'' + ''ba''}}, it follows that {{math|''B''(''a'', ''b'')}} is real. Furthermore, since {{math|''a''&lt;sup&gt;2&lt;/sup&gt; ≤ 0}}, we have: {{math|''B''(''a'', ''a'') &gt; 0}} for {{math|''a'' ≠ 0}}. Thus {{mvar|B}} is a [[definite bilinear form|positive definite]] [[symmetric bilinear form]], in other words, an [[inner product]] on {{mvar|V}}.

Let {{mvar|W}} be a subspace of {{mvar|V}} that generates {{mvar|D}} as an algebra and which is minimal with respect to this property. Let {{math|''e''&lt;sub&gt;1&lt;/sub&gt;, ..., ''e&lt;sub&gt;n&lt;/sub&gt;''}} be an [[orthonormal basis]] of {{mvar|W}}. With respect to the negative definite bilinear form {{math|−''B''}} these elements satisfy the following relations:

:&lt;math&gt;e_i^2 =-1, \quad e_i e_j = - e_j e_i.&lt;/math&gt;

If {{math|''n'' {{=}} 0}}, then {{mvar|D}} is [[isomorphic]] to {{math|'''R'''}}.

If {{math|''n'' {{=}} 1}}, then {{mvar|D}} is generated by {{math|1}} and {{math|''e''&lt;sub&gt;1&lt;/sub&gt;}} subject to the relation {{math|''e''{{su|b=1|p=2}} {{=}} −1}}. Hence it is isomorphic to {{math|'''C'''}}.

If {{math|''n'' {{=}} 2}}, it has been shown above that {{mvar|D}} is generated by {{math|1, ''e''&lt;sub&gt;1&lt;/sub&gt;, ''e''&lt;sub&gt;2&lt;/sub&gt;}} subject to the relations 
:&lt;math&gt;e_1^2 = e_2^2 =-1, \quad e_1 e_2 = - e_2 e_1, \quad (e_1 e_2)(e_1 e_2) =-1.&lt;/math&gt;
These are precisely the relations for {{math|'''H'''}}.

If {{math|''n'' &gt; 2}}, then {{mvar|D}} cannot be a division algebra.  Assume that {{math|''n'' &gt; 2}}. Let {{math|''u'' {{=}} ''e''&lt;sub&gt;1&lt;/sub&gt;''e''&lt;sub&gt;2&lt;/sub&gt;''e&lt;sub&gt;n&lt;/sub&gt;''}}. It is easy to see that {{math|''u''&lt;sup&gt;2&lt;/sup&gt; {{=}} 1}} (this only works if {{math|''n'' &gt; 2}}). If {{mvar|D}} were a division algebra, {{math|0 {{=}} ''u''&lt;sup&gt;2&lt;/sup&gt; − 1 {{=}} (''u'' − 1)(''u'' + 1)}} implies {{math|''u'' {{=}} ±1}}, which in turn means: {{math|''e&lt;sub&gt;n&lt;/sub&gt;'' {{=}} ∓''e''&lt;sub&gt;1&lt;/sub&gt;''e''&lt;sub&gt;2&lt;/sub&gt;}} and so {{math|''e''&lt;sub&gt;1&lt;/sub&gt;, ..., ''e''&lt;sub&gt;''n''−1&lt;/sub&gt;}} generate {{mvar|D}}. This contradicts the minimality of {{mvar|W}}.

==Remarks and related results==
*The fact that {{mvar|D}} is generated by {{math|''e''&lt;sub&gt;1&lt;/sub&gt;, ..., ''e&lt;sub&gt;n&lt;/sub&gt;''}} subject to the above relations means that {{mvar|D}} is the [[Clifford algebra]] of {{math|'''R'''&lt;sup&gt;''n''&lt;/sup&gt;}}. The last step shows that the only real Clifford algebras which are division algebras are {{math|Cℓ&lt;sup&gt;0&lt;/sup&gt;, Cℓ&lt;sup&gt;1&lt;/sup&gt;}} and {{math|Cℓ&lt;sup&gt;2&lt;/sup&gt;}}.
*As a consequence, the only [[commutative]] division algebras are {{math|'''R'''}} and {{math|'''C'''}}. Also note that {{math|'''H'''}} is not a {{math|'''C'''}}-algebra. If it were, then the center of {{math|'''H'''}} has to contain {{math|'''C'''}}, but the center of {{math|'''H'''}} is {{math|'''R'''}}. Therefore, the only finite-dimensional division algebra over {{math|'''C'''}} is {{math|'''C'''}} itself.
* This theorem is closely related to [[Hurwitz's theorem (normed division algebras)|Hurwitz's theorem]], which states that the only real [[normed division algebra]]s are {{math|'''R''', '''C''', '''H'''}}, and the (non-associative) algebra [[octonions|{{math|'''O'''}}]].
* '''Pontryagin variant.''' If {{mvar|D}} is a [[connected space|connected]], [[locally compact space|locally compact]] division [[topological ring|ring]], then {{math|''D'' {{=}} '''R''', '''C'''}}, or {{math|'''H'''}}.

==References==
* Ray E. Artz (2009) [http://www.math.cmu.edu/~wn0g/noll/qu1.pdf Scalar Algebras and Quaternions], Theorem 7.1 "Frobenius Classification", page 26.
* Ferdinand Georg Frobenius (1878) "[http://commons.wikimedia.org/wiki/File:%C3%9Cber_lineare_Substitutionen_und_bilineare_Formen.djvu Über lineare Substitutionen und bilineare Formen]", ''Journal für die reine und angewandte Mathematik'' 84:1–63 ([[Crelle's Journal]]). Reprinted in ''Gesammelte Abhandlungen'' Band I, pp.&amp;nbsp;343–405.
* Yuri Bahturin (1993) ''Basic Structures of Modern Algebra'', Kluwer Acad. Pub. pp.&amp;nbsp;30–2 {{ISBN|0-7923-2459-5}} .
* [[Leonard Dickson]] (1914) ''Linear Algebras'', [[Cambridge University Press]]. See §11 "Algebra of real quaternions; its unique place among algebras", pages 10 to 12.
* R.S. Palais (1968) "The Classification of Real Division Algebras" [[American Mathematical Monthly]] 75:366–8.
* [[Lev Semenovich Pontryagin]], [[List of publications in mathematics#Topological Groups|Topological Groups]], page 159, 1966.

[[Category:Algebras]]
[[Category:Quaternions]]
[[Category:Theorems in abstract algebra]]
[[Category:Articles containing proofs]]</text>
      <sha1>pkxpkzdznkbnj7vxo3pi5zdfyf5w2pd</sha1>
    </revision>
  </page>
  <page>
    <title>Galois geometry</title>
    <ns>0</ns>
    <id>25197704</id>
    <revision>
      <id>855950397</id>
      <parentid>822569742</parentid>
      <timestamp>2018-08-21T22:39:00Z</timestamp>
      <contributor>
        <username>Rgdboer</username>
        <id>92899</id>
      </contributor>
      <minor/>
      <comment>/* References */ authorlinks</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3765">[[File:Fano plane.svg|thumb|The [[Fano plane]], the [[projective plane]] over the field with two elements, is one of the simplest objects in Galois geometry.]]
'''Galois geometry''' (so named after the 19th century French Mathematician [[Évariste Galois]]) is the branch of [[finite geometry]] that is concerned with [[Algebraic geometry|algebraic]] and [[analytic geometry]] over a [[finite field]] (or ''Galois field'').&lt;ref&gt;SpringerLink&lt;/ref&gt; More narrowly, ''a''&amp;nbsp;Galois geometry may be defined as a [[projective space]] over a finite field.&lt;ref&gt;"Projective spaces over a finite field, otherwise known as Galois geometries, ...", {{Harv|Hirschfeld|Thas|1992}}&lt;/ref&gt;

==Introduction==
Objects of study include [[vector space]]s, [[affine space|affine]] and projective spaces over finite fields and various structures that are contained in them. In particular, [[arc (projective geometry)|arc]]s, [[Oval (projective plane)|oval]]s, [[hyperoval]]s, [[unital (geometry)|unitals]], [[blocking set]]s, [[ovoid]]s, caps, spreads and all finite analogues of structures found in non-finite geometries.

George Conwell gave an early demonstration of Galois geometry in 1910 when he characterized a  solution of [[Kirkman's schoolgirl problem]] as a partition of sets of [[skew lines]] in PG(3,2), the three-dimensional projective geometry over the Galois field [[GF(2)]].&lt;ref&gt;George M. Conwell (1910) "The 3-space PG(3,2) and its Groups", [[Annals of Mathematics]] 11:60–76 {{doi|10.2307/1967582}}&lt;/ref&gt;
Similar to methods of line geometry in space over a field of [[characteristic 0]], Conwell used [[Plücker coordinates]] in PG(5,2) and identified the points representing lines in PG(3,2) as those on the [[Klein quadric]].

In 1955 [[Beniamino Segre]] characterized the ovals for ''q'' odd. [[Segre's theorem]] states that in a Galois geometry of odd order (a projective plane defined over a finite field of odd [[Characteristic (field)|characteristic]]) every oval is a [[conic section|conic]]. At the 1958 [[International Mathematical Congress]] Segre presented a survey of results in Galois geometry known up to then.&lt;ref&gt; {{citation
| last=Segre
| first = Beniamino 
| author-link = Beniamino Segre
| title = On Galois Geometries
| year = 1958
| publisher = [[International Mathematical Union]]
| url = http://www.mathunion.org/ICM/ICM1958/Main/icm1958.0488.0499.ocr.pdf
}}&lt;/ref&gt;

== See also ==
* [[Projective geometry]]
* [[Incidence geometry]]

== Notes ==
{{reflist}}

==References==
{{refbegin}}
* {{Citation
|title=Projective Geometries Over Finite Fields
|first1=J. W. P.
|last1=Hirschfeld
|authorlink=J. W. P. Hirschfeld
|publisher=[[Oxford University Press]]
|year=1979
|isbn=978-0-19-850295-1
|postscript=, emphasizing dimensions one and two.}}
*{{Citation
|title=Finite Projective Spaces of Three Dimensions
|first1=J. W. P.
|last1=Hirschfeld
|publisher=[[Oxford University Press]]
|year=1985
|isbn=0-19-853536-8
|postscript=, dimension 3.
}}
*{{Citation
|title=General Galois Geometries
|first1=J. W. P.
|last1=Hirschfeld
|first2=J. A.
|last2=Thas
|authorlink2=J. A. Thas
|publisher=[[Oxford University Press]]
|year=1992
|isbn=978-0-19-853537-9
|postscript=, treating general dimension.
}}

* {{citation|first1 = Jan| last1 = De Beule | first2 = Leo | last2 = Storme | year = 2011| title = Current Research Topics in Galois Geometry | publisher = Nova Science Publishers| url = https://www.novapublishers.com/catalog/product_info.php?products_id=21439 |isbn = 978-1-61209-523-3}}


{{refend}}

== External links ==
* ''[http://eom.springer.de/g/g110030.htm Galois geometry]'' at Encyclopaedia of Mathematics, SpringerLink



[[Category:Finite geometry]]
[[Category:Finite fields]]
[[Category:Algebraic geometry]]
[[Category:Analytic geometry]]</text>
      <sha1>ccd1a9yi7976px7h8botb31ct8q2nv7</sha1>
    </revision>
  </page>
  <page>
    <title>Graph energy</title>
    <ns>0</ns>
    <id>32688684</id>
    <revision>
      <id>702636594</id>
      <parentid>702592784</parentid>
      <timestamp>2016-01-31T20:18:40Z</timestamp>
      <contributor>
        <username>BD2412</username>
        <id>196446</id>
      </contributor>
      <minor/>
      <comment>Fixing [[Wikipedia:Disambiguation pages with links|links to disambiguation pages]], replaced: [[Graph (mathematics)|graph]]{{dn|date=January 2016}} → [[Graph (discrete mathematics)|graph]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1984">In [[mathematics]], the '''energy''' of a [[Graph (discrete mathematics)|graph]] is the sum of the [[absolute value]]s of the [[eigenvalue]]s of the [[adjacency matrix]] of the graph. This quantity is studied in the context of [[spectral graph theory]].

More precisely, let ''G'' be a graph with ''n'' [[vertex (graph theory)|vertices]]. It is assumed that ''G'' is [[Graph (discrete mathematics)#Simple graph|simple]], that is, it does not contain loops or parallel edges. Let ''A'' be the [[adjacency matrix]] of&amp;nbsp;''G'' and let &lt;math&gt;\lambda_i&lt;/math&gt;, &lt;math&gt; i = 1 , \ldots , n &lt;/math&gt;,  be the eigenvalues of&amp;nbsp;''A''. Then the energy of the graph is defined as:

:&lt;math&gt;E(G) = \sum_{i=1}^n|\lambda_i|.&lt;/math&gt;

== References ==
*{{citation
 | last1 = Cvetković | first1 = Dragoš M.
 | last2 = Doob | first2 = Michael
 | last3 = Sachs | first3 = Horst | author3-link = Horst Sachs
 | isbn = 0-12-195150-2
 | location = New York
 | mr = 572262
 | publisher = Academic Press Inc. [Harcourt Brace Jovanovich Publishers]
 | series = Pure and Applied Mathematics
 | title = Spectra of graphs
 | volume = 87
 | year = 1980}}.
*{{citation
 | last = Gutman | first = Ivan
 | contribution = The energy of a graph
 | mr = 525890
 | pages = 1–22
 | series = Ber. Math.-Statist. Sekt. Forsch. Graz
 | title = 10. Steiermärkisches Mathematisches Symposium (Stift Rein, Graz, 1978)
 | volume = 103
 | year = 1978}}.
*{{citation
 | last = Gutman | first = Ivan
 | contribution = The energy of a graph: old and new results
 | location = Berlin
 | mr = 1851951
 | pages = 196–211
 | publisher = Springer
 | title = Algebraic combinatorics and applications (Gößweinstein, 1999)
 | year = 2001}}.

*{{citation
 | last1 = Li | first1 = Xueliang
 | last2 = Shi | first2 = Yongtang
 | last3 = Gutman | first3 = Ivan
 | isbn = 978-1-4614-4219-6
 | title = Graph Energy
 | location = New York
 | publisher = Springer
 | year = 2012}}.

[[Category:Algebraic graph theory]]



{{combin-stub}}</text>
      <sha1>bmjj384l9oc9e9luy2l7gvy1bf0gw5m</sha1>
    </revision>
  </page>
  <page>
    <title>Graph partition</title>
    <ns>0</ns>
    <id>11973947</id>
    <revision>
      <id>858967829</id>
      <parentid>846610904</parentid>
      <timestamp>2018-09-10T20:41:40Z</timestamp>
      <contributor>
        <username>DannyS712</username>
        <id>34581532</id>
      </contributor>
      <comment>/* Multi-level methods */ Added link to [[Multi-level technique]], an orphan article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27799">In mathematics, the '''graph partition''' problem is defined on data represented in the form of a [[Graph (discrete mathematics)|graph]] ''G'' = (''V'',''E''), with ''V'' vertices and ''E'' edges, such that it is possible to [[partition of a set|partition]] ''G'' into smaller components with specific properties. For instance, a ''k''-way partition divides the vertex set into ''k'' smaller components. A good partition is defined as one in which the number of edges running between separated components is small. Uniform graph partition is a type of graph partitioning problem that consists of dividing a graph into components, such that the components are of about the same size and there are few connections between the components. Important applications of graph partitioning include scientific computing, partitioning various stages of a [[VLSI]] design circuit and task scheduling in multi-processor systems.&lt;ref name="balgraph"&gt;
{{cite journal
 | last1=Andreev |first1=Konstantin
 | last2=Räcke |first2=Harald
 | title = Balanced Graph Partitioning
 | journal = Proceedings of the sixteenth annual ACM symposium on Parallelism in algorithms and architectures
 | year = 2004
 | location = Barcelona, Spain
 | pages = 120–124
 | doi = 10.1145/1007912.1007931
 | isbn = 1-58113-840-7
 }}&lt;/ref&gt; Recently, the graph partition problem has gained importance due to its application for clustering and detection of cliques in social, pathological and biological networks. For a survey on recent trends in computational methods and applications see {{harvtxt|Buluc|Meyerhenke|Safro|Sanders|2013}}.&lt;ref name="recentadvances"&gt;{{citation
 | last1 = Buluc | first1 = Aydin
 | last2 = Meyerhenke | first2 = Henning
 | last3 = Safro | first3 = Ilya
 | last4 = Sanders | first4 = Peter | author4-link = Peter Sanders (computer scientist)
 | last5 = Schulz | first5 = Christian
 | arxiv = 1311.3144
 | title = Recent Advances in Graph Partitioning
 | year = 2013
 | mode = cs1
 | ref = harv| bibcode = 2013arXiv1311.3144B}}&lt;/ref&gt;

== Problem complexity ==

Typically, graph partition problems fall under the category of [[NP-hard]] problems. Solutions to these problems are generally derived using heuristics and approximation algorithms.&lt;ref name=baltrees&gt;
{{cite journal
 | last1=Feldmann |first1=Andreas Emil
 | last2=Foschini |first2=Luca
 | title = Balanced Partitions of Trees and Applications
 | journal = Proceedings of the 29th International Symposium on Theoretical Aspects of Computer Science
 | year = 2012
 | location = Paris, France
 | pages = 100–111
 }}&lt;/ref&gt; However, uniform graph partitioning or a balanced graph partition problem can be shown to be [[NP-complete]] to approximate within any finite factor.&lt;ref name=balgraph /&gt; Even for special graph classes such as trees and grids, no reasonable approximation algorithms exist,&lt;ref name="fastpartition"&gt;
{{cite journal
 | last = Feldmann |first=Andreas Emil
 | title = Fast Balanced Partitioning is Hard, Even on Grids and Trees
 | journal = Proceedings of the 37th International Symposium on Mathematical Foundations of Computer Science
 | year = 2012
 | location = Bratislava, Slovakia
 }}&lt;/ref&gt; unless [[P=NP]]. Grids are a particularly interesting case since they model the graphs resulting from [[Finite element method|Finite Element Model (FEM)]] simulations. When not only the number of edges between the components is approximated, but also the sizes of the components, it can be shown that no reasonable fully polynomial algorithms exist for these graphs.&lt;ref name="fastpartition" /&gt;

==Problem==
Consider a graph ''G'' = (''V'', ''E''), where ''V'' denotes the set of ''n'' vertices and ''E'' the set of edges. For a (''k'',''v'') balanced partition problem, the objective is to partition ''G'' into ''k'' components of at most size ''v'' · (''n''/''k''), while minimizing the capacity of the edges between separate components.&lt;ref name=balgraph /&gt; Also, given ''G'' and an integer ''k'' &gt; 1, partition ''V'' into ''k'' parts (subsets) ''V''&lt;sub&gt;1&lt;/sub&gt;, ''V''&lt;sub&gt;2&lt;/sub&gt;, ..., ''V&lt;sub&gt;k&lt;/sub&gt;'' such that the parts are disjoint and have equal size, and the number of edges with endpoints in different parts is minimized. Such partition problems have been discussed in literature as bicriteria-approximation or resource augmentation approaches. A common extension is to [[hypergraph]]s, where an edge can connect more than two vertices. A hyperedge is not cut if all vertices are in one partition, and cut exactly once otherwise, no matter how many vertices are on each side. This usage is common in [[electronic design automation]].

===Analysis===
For a specific (''k'', 1&amp;nbsp;+&amp;nbsp;''ε'') balanced partition problem, we seek to find a minimum cost partition of ''G'' into ''k'' components with each component containing maximum of (1&amp;nbsp;+&amp;nbsp;''ε'')·(''n''/''k'') nodes. We compare the cost of this approximation algorithm to the cost of a (''k'',1) cut, wherein each of the ''k'' components must have exactly the same size of (''n''/''k'') nodes each, thus being a more restricted problem. Thus,

: &lt;math&gt;\max_i |V_i| \le (1+\varepsilon) \left\lceil\frac{|V|}{k}\right\rceil.&lt;/math&gt;

We already know that (2,1) cut is the minimum bisection problem and it is NP complete.&lt;ref name="minbisect"&gt;
{{cite book
 | last1=Garey |first1=Michael R.
 | last2=Johnson |first2=David S.
 | title = Computers and intractability: A guide to the theory of NP-completeness
 | year = 1979
 | isbn = 0-7167-1044-7
 | publisher = W. H. Freeman &amp; Co.
}}&lt;/ref&gt; Next we assess a 3-partition problem wherein ''n''&amp;nbsp;=&amp;nbsp;3''k'', which is also bounded in polynomial time.&lt;ref name=balgraph /&gt; Now, if we assume that we have an finite approximation algorithm for (''k'',&amp;nbsp;1)-balanced partition, then, either the 3-partition instance can be solved using the balanced (''k'',1) partition in ''G'' or it cannot be solved. If the 3-partition instance can be solved, then (''k'',&amp;nbsp;1)-balanced partitioning problem in ''G'' can be solved without cutting any edge. Otherwise if the 3-partition instance cannot be solved, the optimum (''k'', 1)-balanced partitioning in ''G'' will cut at least one edge. An approximation algorithm with finite approximation factor has to differentiate between these two cases. Hence, it can solve the 3-partition problem which is a contradiction under the assumption that ''P''&amp;nbsp;=&amp;nbsp;''NP''. Thus, it is evident that (''k'',1)-balanced partitioning problem has no polynomial time approximation algorithm with finite approximation factor unless ''P''&amp;nbsp;=&amp;nbsp;''NP''.&lt;ref name=balgraph /&gt;

The [[planar separator theorem]] states that any ''n''-vertex [[planar graph]] can be partitioned into roughly equal parts by the removal of O({{radic|''n''}}) vertices. This is not a partition in the sense described above, because the partition set consists of vertices rather than edges. However, the same result also implies that every planar graph of bounded degree has a balanced cut with O({{radic|''n''}}) edges.

==Graph partition methods==
Since graph partitioning is a hard problem, practical solutions are based on heuristics.  There are two broad categories of methods, local and global. Well known local methods are the [[Kernighan–Lin algorithm]], and [[Fiduccia-Mattheyses algorithm]]s, which were the first effective 2-way cuts by local search strategies. Their major drawback is the arbitrary initial partitioning of the vertex set, which can affect the final solution quality.  Global approaches rely on properties of the entire graph and do not rely on an arbitrary initial partition.  The most common example is spectral partitioning, where a partition is derived from the spectrum of the adjacency matrix.

==Multi-level methods==
{{Main|Multi-level technique}}
A multi-level graph partitioning algorithm works by applying one or more stages.   Each stage reduces the size of
the graph by collapsing vertices and edges, partitions the smaller graph, then maps back and refines this partition of the original graph.&lt;ref&gt;
{{cite conference
 |title=A multilevel algorithm for partitioning graphs
 |last1=Hendrickson |first=B.
 |last2=Leland |first2=R.
 |conference =Proceedings of the 1995 ACM/IEEE conference on Supercomputing
 |page=28
 |year=1995
 |publisher=ACM
}}&lt;/ref&gt; A wide variety of partitioning and refinement methods can be applied within the overall multi-level scheme.  In many cases, this approach can give both fast execution times and very high quality results.  
One widely used example of such an approach is [[METIS]],&lt;ref name=":0"&gt;{{cite journal 
 |title=A fast and high quality multilevel scheme for partitioning irregular graphs
 |last1=Karypis |first1=G.
 |last2=Kumar |first2=V.
 |journal=SIAM Journal on Scientific Computing
 |volume=20
 |issue=1
 |page=359
 |year=1999 
 |doi=10.1137/S1064827595287997
}}&lt;/ref&gt; a graph partitioner, and hMETIS, the corresponding partitioner for hypergraphs.&lt;ref name="hmetis"&gt;
{{cite conference
 |title=Multilevel hypergraph partitioning: application in VLSI domain
 |last1=Karypis |first1=G.
 |last2=Aggarwal |first2=R.
 |last3=Kumar |first3=V.
 |last4=Shekhar |first4=S.
 |conference=Proceedings of the 34th annual Design Automation Conference
 |pages=526–529
 |year=1997
}}&lt;/ref&gt;

==Spectral partitioning and spectral bisection==
Given a graph &lt;math&gt;G=(V,E)&lt;/math&gt; with [[adjacency matrix]] &lt;math&gt;A&lt;/math&gt;, where an entry &lt;math&gt;A_{ij}&lt;/math&gt; implies an edge between node &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt;, and [[degree matrix]] &lt;math&gt;D&lt;/math&gt;, which is a diagonal matrix, where each diagonal entry of a row &lt;math&gt;i&lt;/math&gt;, &lt;math&gt;d_{ii}&lt;/math&gt;, represents the node degree of node &lt;math&gt;i&lt;/math&gt;. The [[Laplacian matrix]] &lt;math&gt;L&lt;/math&gt; is defined as &lt;math&gt;L = D - A&lt;/math&gt;. Now, a ratio-cut partition for graph &lt;math&gt;G = (V, E)&lt;/math&gt; is defined as a partition of &lt;math&gt;V&lt;/math&gt; into disjoint &lt;math&gt;U&lt;/math&gt;, and &lt;math&gt;W&lt;/math&gt;, minimizing the ratio
:&lt;math&gt;\frac{|E(G)\cap(U\times W)|}{|U|\cdot|W|}&lt;/math&gt;
of the number of edges that actually cross this cut to the number of pairs of vertices that could support such edges. Spectral graph partitioning can be motivated&lt;ref&gt;J. Demmel, [https://people.eecs.berkeley.edu/~demmel/cs267/lecture20/lecture20.html], CS267: Notes for Lecture 23, April 9, 1999, Graph Partitioning, Part 2&lt;/ref&gt; by analogy with partitioning of a vibrating string or a mass-spring system.

=== Fiedler eigenvalue and eigenvector ===
In such a scenario, the [[Algebraic connectivity|second smallest eigenvalue]] (&lt;math&gt;\lambda_2&lt;/math&gt;) of &lt;math&gt;L&lt;/math&gt;, yields a ''lower bound'' on the optimal cost (&lt;math&gt;c&lt;/math&gt;) of ratio-cut partition with &lt;math&gt;c\geq \frac{\lambda_2}{n}&lt;/math&gt;. The eigenvector (&lt;math&gt;V_2&lt;/math&gt;) corresponding to &lt;math&gt;\lambda_2&lt;/math&gt;, called the [[Algebraic connectivity#Fiedler vector|''Fiedler vector'']], bisects the graph into only two communities based on the '''''sign''' of the corresponding vector entry''. Division into a larger number of communities can be achieved by repeated ''bisection'' or by using ''multiple eigenvectors'' corresponding to the smallest eigenvalues.&lt;ref name="spectral_nvidia_tr"&gt;
{{cite journal
 | first1=M. |last1=Naumov
 | first2=T. |last2=Moon
 | year = 2016
 | title = Parallel Spectral Graph Partitioning
 | journal = NVIDIA Technical Report
 | volume = nvr-2016-001
 | url = https://research.nvidia.com/publication/parallel-spectral-graph-partitioning
}}&lt;/ref&gt; The examples in Figures 1,2 illustrate the spectral bisection approach.

[[File:Bisected network.jpg|thumb|Figure 1: The graph ''G''&amp;nbsp;=&amp;nbsp;(5,4) is analysed for spectral bisection. The linear combination of the smallest two eigenvectors leads to [1 1 1 1 1]' having an eigen value&amp;nbsp;=&amp;nbsp;0.]]

[[File:Connected graph..jpg|thumb|Figure 2: The graph ''G''&amp;nbsp;=&amp;nbsp;(5,5) illustrates that the Fiedler vector in red bisects the graph into two communities, one with vertices {1,2,3} with positive entries in the vector space, and the other community has vertices {4,5} with negative vector space entries.]]

=== Modularity and ratio-cut ===

Minimum cut partitioning however fails when the number of communities to be partitioned, or the partition sizes are unknown. For instance, optimizing the cut size for free group sizes puts all vertices in the same community. Additionally, cut size may be the wrong thing to minimize since a good division is not just one with small number of edges between communities.  This motivated the use of [[Modularity (networks)|Modularity]] (Q)&lt;ref name="npnas"&gt;
{{cite journal
 | last = Newman | first = M. E. J.
 | year = 2006
 | title = Modularity and community structure in networks
 | journal = PNAS
 | volume = 103
 | issue = 23
 | pages = 8577–8696
 | doi = 10.1073/pnas.0601602103
 | pmid=16723398
 | pmc=1482622
| arxiv = physics/0602124
 | bibcode = 2006PNAS..103.8577N
 }}&lt;/ref&gt; as a metric to optimize a balanced graph partition. The example in Figure 3 illustrates 2 instances of the same graph such that in ''(a)'' modularity (Q) is the partitioning metric and in ''(b)'', ratio-cut is the partitioning metric.

[[File:Graph comparison.jpg|thumb|Figure 3: Weighted graph ''G'' may be partitioned to maximize ''Q'' in (a) or to minimize the ratio-cut in (b). We see that (a) is a better balanced partition, thus motivating the importance of modularity in graph partitioning problems.]]

=== Conductance ===

Another objective function used for graph partitioning is [[Conductance (graph)|Conductance]] which is the ratio between the number of cut edges and the volume of the smallest part. Conductance is related to electrical flows and random walks. The [[Cheeger bound]] guarantees that spectral bisection provides partitions with nearly optimal conductance. The quality of this approximation depends on the second smallest eigenvalue of the Laplacian λ&lt;sub&gt;2&lt;/sub&gt;.

==Other graph partition methods==
Spin models have been used for clustering of multivariate data wherein similarities are translated into coupling strengths.&lt;ref name="potts"&gt;
{{cite journal
 | title = Statistical mechanics of community detection
 | date=July 2006
 | doi = 10.1103/PhysRevE.74.016110
 | last1=Reichardt | first1=Jörg
 | last2=Bornholdt | first2=Stefan
 | issue = 1
 | journal = Phys. Rev. E
 | page=016110
 | volume = 74
| arxiv=cond-mat/0603718| bibcode=2006PhRvE..74a6110R}}&lt;/ref&gt; The properties of ground state spin configuration can be directly interpreted as communities. Thus, a graph is partitioned to minimize the Hamiltonian of the partitioned graph. The [[Hamiltonian mechanics#Mathematical formalism|Hamiltonian]] (H) is derived by assigning the following partition rewards and penalties.
* Reward internal edges between nodes of same group (same spin)
* Penalize missing edges in same group
* Penalize existing edges between different groups
* Reward non-links between different groups.

Additionally, Kernel PCA based Spectral clustering takes a form of least squares Support Vector Machine framework, and hence it becomes possible to project the data entries to a kernel induced feature space that has maximal variance, thus implying a high separation between the projected communities.&lt;ref name="pami"&gt;
{{cite journal
 | first1=Carlos | last1=Alzate
 | first2=Johan A. K. | last2=Suykens
 | title = Multiway Spectral Clustering with Out-of-Sample Extensions through Weighted Kernel PCA
 | journal = IEEE Transactions on Pattern Analysis and Machine Intelligence
 | volume = 32
 | issn = 0162-8828
 | year = 2010
 | pages = 335–347
 | doi=10.1109/TPAMI.2008.292
 | publisher = IEEE Computer Society
 | issue = 2
 | pmid = 20075462
}}&lt;/ref&gt;

Some methods express graph partitioning as a multi-criteria optimization problem which can be solved using local methods expressed in a game theoretic framework where each node makes a decision on the partition it chooses.&lt;ref&gt;Kurve, A.; Griffin, C.; Kesidis G. (2011) "A graph partitioning game for distributed simulation of networks", ''Proceedings of the 2011 International Workshop on Modeling, Analysis, and Control of Complex Networks'': 9–16&lt;/ref&gt;

== Software tools ==

Chaco,&lt;ref name="chaco"&gt;
{{cite journal
 | first = Bruce | last=Hendrickson
 | title = Chaco: Software for Partitioning Graphs
 }}&lt;/ref&gt; due to Hendrickson and Leland, implements the multilevel approach outlined above and basic local search algorithms. 
Moreover, they implement spectral partitioning techniques.

[[METIS]]&lt;ref name=":0"/&gt; is a graph partitioning family by Karypis and Kumar. Among this family, kMetis aims at greater partitioning speed, hMetis,&lt;ref name="hmetis"/&gt; applies to hypergraphs and aims at partition quality, and ParMetis&lt;ref name=":0"/&gt; is a parallel implementation of the Metis graph partitioning algorithm.

PaToH&lt;ref name="patoh"&gt;{{cite conference
 | first1=Ü. | last1=Catalyürek
 | first2=C. | last2=Aykanat
 | title = PaToH: Partitioning Tool for Hypergraphs
 | year=2011
 }}&lt;/ref&gt; is another hypergraph partitioner.

KaHyPar&lt;ref&gt;{{Cite book|url=http://epubs.siam.org/doi/abs/10.1137/1.9781611974317.5|title=2016 Proceedings of the Eighteenth Workshop on Algorithm Engineering and Experiments (ALENEX)|last=Schlag|first=S.|last2=Henne|first2=V.|last3=Heuer|first3=T.|last4=Meyerhenke|first4=H.|last5=Sanders|first5=P.|last6=Schulz|first6=C.|date=2015-12-30|publisher=Society for Industrial and Applied Mathematics|series=Proceedings|pages=53–67|doi=10.1137/1.9781611974317.5}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=http://epubs.siam.org/doi/abs/10.1137/1.9781611974768.3|title=2017 Proceedings of the Ninteenth {{sic|hide=y|reason=spelling error in source}} Workshop on Algorithm Engineering and Experiments (ALENEX)|last=Akhremtsev|first=Y.|last2=Heuer|first2=T.|last3=Sanders|first3=P.|last4=Schlag|first4=S.|date=2017-01-01|publisher=Society for Industrial and Applied Mathematics|series=Proceedings|pages=28–42|doi=10.1137/1.9781611974768.3}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Heuer|first=Tobias|last2=Schlag|first2=Sebastian|date=2017|editor-last=Iliopoulos|editor-first=Costas S.|editor2-last=Pissis|editor2-first=Solon P.|editor3-last=Puglisi|editor3-first=Simon J.|editor4-last=Raman|editor4-first=Rajeev|title=Improving Coarsening Schemes for Hypergraph Partitioning by Exploiting Community Structure|url=http://drops.dagstuhl.de/opus/volltexte/2017/7622|journal=16th International Symposium on Experimental Algorithms (SEA 2017)|series=Leibniz International Proceedings in Informatics (LIPIcs)|location=Dagstuhl, Germany|publisher=Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik|volume=75|pages=21:1–21:19|doi=10.4230/LIPIcs.SEA.2017.21|isbn=9783959770361}}&lt;/ref&gt; is a multilevel hypergraph partitioning framework providing direct k-way and recursive bisection based partitioning algorithms. It instantiates the multilevel approach in its most extreme version, removing only a single vertex in every level of the hierarchy. By using this very fine grained ''n''-level approach combined with strong local search heuristics, it computes solutions of very high quality.

Scotch&lt;ref name="scotch"&gt;{{cite journal
 | first1=C. | last1=Chevalier
 | first2=F. | last2=Pellegrini
 | title = PT-Scotch: A Tool for Efficient Parallel Graph Ordering
 | journal = Parallel Computing
 | volume = 34
 | issue = 6
 | pages = 318–331
 | year=2008
 | doi=10.1016/j.parco.2007.12.001
 | arxiv=0907.1375
 }}&lt;/ref&gt; is graph partitioning framework by Pellegrini. It uses recursive multilevel bisection and includes sequential as well as parallel partitioning techniques.

Jostle&lt;ref name="jostle"&gt;{{cite journal
 | first1=C. | last1=Walshaw
 | first2=M. | last2=Cross
 | title = Mesh Partitioning: A Multilevel Balancing and Refinement Algorithm
 | journal = Journal on Scientific Computing
 | volume = 22
 | issue = 1
 | pages = 63–80
 | year=2000
 | doi=10.1137/s1064827598337373
 }}&lt;/ref&gt; is a sequential and parallel graph partitioning solver developed by Chris Walshaw. 
The commercialized version of this partitioner is known as NetWorks.

Party&lt;ref name="party"&gt;{{cite journal
 | first1=R. | last1=Diekmann
 | first2=R. | last2=Preis
 | first3=F. | last3=Schlimbach
 | first4=C. | last4=Walshaw
 | title = Shape-optimized Mesh Partitioning and Load Balancing for Parallel Adaptive FEM
 | journal = Parallel Computing
 | volume = 26
 | issue = 12
 | pages = 1555–1581
 | year=2000
 | doi=10.1016/s0167-8191(00)00043-0
 }}&lt;/ref&gt; implements the Bubble/shape-optimized framework and the Helpful Sets algorithm.

The software packages DibaP&lt;ref name="dibap"&gt;{{cite journal
 | first1=H. | last1=Meyerhenke
 | first2=B. | last2=Monien
 | first3=T. | last3=Sauerwald
 | title = A New Diffusion-Based Multilevel Algorithm for Computing Graph Partitions
 | journal = Journal of Parallel Computing and Distributed Computing
 | volume = 69
 | issue = 9
 | pages = 750–761
 | year=2008
 | doi=10.1016/j.jpdc.2009.04.005
 }}&lt;/ref&gt; and its MPI-parallel variant PDibaP&lt;ref name="pdibap"&gt;{{cite conference
 | first = H. | last = Meyerhenke
 | title = Shape Optimizing Load Balancing for MPI-Parallel Adaptive Numerical Simulations.
 | conference = 10th DIMACS Implementation Challenge on Graph Partitioning and Graph Clustering
 | pages = 67–82
 | year=2013
 }}&lt;/ref&gt; by Meyerhenke implement the Bubble framework using diffusion; DibaP also uses AMG-based techniques for coarsening and solving linear systems arising in the diffusive approach.

Sanders and Schulz released a graph partitioning package KaHIP&lt;ref name="kahip"&gt;{{cite conference
 | authorlink=Peter Sanders (computer scientist) | first1=P. | last1=Sanders
 | first2=C. | last2=Schulz
 | title = Engineering Multilevel Graph Partitioning Algorithms
 | conference = Proceedings of the 19th European Symposium on Algorithms (ESA)
 | volume = 6942
 | pages = 469–480
 | year=2011
 }}&lt;/ref&gt; (Karlsruhe High Quality Partitioning) that implements for example flow-based methods, more-localized local searches and several parallel and sequential meta-heuristics.

The tools Parkway&lt;ref name="parkway"&gt;{{cite journal
 | first1=A. | last1=Trifunovic
 | first2=W. J. | last2=Knottenbelt
 | title = Parallel Multilevel Algorithms for Hypergraph Partitioning
 | journal = Journal of Parallel and Distributed Computing
 | volume = 68
 | issue = 5
 | pages = 563–581
 | year=2008
 | doi=10.1016/j.jpdc.2007.11.002
 }}&lt;/ref&gt; by Trifunovic and
Knottenbelt as well as Zoltan&lt;ref name="zoltan"&gt;{{cite conference
 | first1=K. | last1=Devine
 | first2=E. | last2=Boman
 | first3=R. | last3=Heaphy
 | first4=R. | last4=Bisseling
 | first5=Ü. | last5=Catalyurek
 | title = Parallel Hypergraph Partitioning for Scientific Computing
 | conference = Proceedings of the 20th International Conference on Parallel and Distributed Processing
 | pages = 124–124
 | year=2006
 }}&lt;/ref&gt; by Devine et al. focus on hypergraph
partitioning.

'''List of free open-source frameworks:'''
{| class="wikitable"
|-
!Name
!License
!Brief info
|-
|Chaco||GPL|| software package implementing spectral techniques and the multilevel approach
|-
|DiBaP||*|| graph partitioning based on multilevel techniques, algebraic multigrid as well as graph based diffusion
|-
|Jostle||*|| multilevel partitioning techniques and diffusive load-balancing, sequential and parallel
|-
|KaHIP||GPL|| several parallel and sequential meta-heuristics, guarantees the balance constraint
|-
|KaHyPar
|GPL
|direct k-way and recursive bisection based multilevel hypergraph partitioning framework
|-
|kMetis||Apache 2.0||graph partitioning package based on multilevel techniques and k-way local search
|-
|Mondriaan||LGPL|| matrix partitioner to partition rectangular sparse matrices 
|-
|PaToH||BSD|| multilevel hypergraph partitioning 
|-
|Parkway||*|| parallel multilevel hypergraph partitioning
|-
|Scotch||CeCILL-C|| implements multilevel recursive bisection as well as diffusion techniques, sequential and parallel
|-
|Zoltan||BSD|| hypergraph partitioning
|}

==References==
&lt;references /&gt;

==External links==
* Chamberlain, Bradford L. (1998). [http://masters.donntu.edu.ua/2006/fvti/krasnokutskaya/library/generals.pdf "Graph Partitioning Algorithms for Distributing Workloads of Parallel Computations"]

== Bibliography ==
* {{cite book|title=Graph Partitioning: Optimisation and Applications|first1=Charles-Edmond |last1=Bichot |first2=Patrick |last2=Siarry |year=2011|publisher=ISTE – Wiley|isbn=978-1848212336|page=384|url=http://cebichot.netne.net/graph_partitioning_book/}} 
* {{cite book|last=Feldmann|first=Andreas Emil|title=Balanced Partitioning of Grids and Related Graphs: A Theoretical Study of Data Distribution in Parallel Finite Element Model Simulations|year=2012|publisher=Cuvillier Verlag|location=Goettingen, Germany|isbn=978-3954041251|page=218|url=https://e-collection.library.ethz.ch/view/eth:5739?q=Balanced%20Partitioning%20of%20Grids%20and%20Related%20Graphs}} An exhaustive analysis of the problem from a theoretical point of view.
* {{cite journal |title=An Efficient Heuristic Procedure for Partitioning Graphs |url=http://www.cs.princeton.edu/~bwk/btl.mirror/new/partitioning.pdf |first1=B. W. |last1=Kernighan |first2=S. |last2=Lin |journal=Bell System Technical Journal |year=1970}}  One of the early fundamental works in the field.  However, performance is O(n&lt;sup&gt;2&lt;/sup&gt;), so it is no longer commonly used.
* {{cite conference |title=A Linear-Time Heuristic for Improving Network Partitions |url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1585498 |first1=C. M. |last1=Fiduccia |first2=R. M. |last2=Mattheyses |conference=Design Automation Conference |year=1982}}  A later variant that is linear time, very commonly used, both by itself and as part of multilevel partitioning, see below.
* {{cite journal |title=A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs |url=http://glaros.dtc.umn.edu/gkhome/node/107 |first1=G. |last1=Karypis |first2=V. |last2=Kumar |journal=Siam Journal on Scientific Computing |year=1999}}  Multi-level partitioning is the current state of the art. This paper also has good explanations of many other methods, and comparisons of the various methods on a wide variety of problems.
* {{cite journal |title=Multilevel hypergraph partitioning: applications in VLSI domain |url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=748202 |last1=Karypis |first1=G. |last2=Aggarwal |first2=R. |last3=Kumar |first3=V. |last4=Shekhar |first4=S. |journal=IEEE Transactions on Very Large Scale Integration (VLSI) Systems |date=March 1999 |volume=7 |issue=1 |pages=69–79 |doi=10.1109/92.748202}}  Graph partitioning (and in particular, hypergraph partitioning) has many applications to IC design.
* {{cite journal |title=Optimization by Simulated Annealing |url=http://www.sciencemag.org/cgi/content/abstract/220/4598/671 |first1=S. |last1=Kirkpatrick |first2=C. D., Jr. |last2=Gelatt |first3=M. P. |last3=Vecchi |journal=Science |date=13 May 1983 |issue=4598 |pages=671–680 |doi= 10.1126/science.220.4598.671 |volume=220 |pmid=17813860|bibcode=1983Sci...220..671K }}  Simulated annealing can be used as well.
* {{cite journal |title=New spectral methods for ratio cut partitioning and clustering |url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=159993 |last1=Hagen |first1=L.  |last2=Kahng |first2=A. B. |journal=IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems |date=September 1992 |volume=11 |issue=9 |pages= 1074–1085 |doi=10.1109/43.159993}}.  There is a whole class of ''spectral partitioning'' methods, which use the Eigenvectors of the Laplacian of the connectivity graph.  You can see [https://web.archive.org/web/20081003192033/http://www.stanford.edu/~dgleich/demos/matlab/spectral/spectral.html a demo of this], using Matlab.

[[Category:NP-complete problems]]
[[Category:Computational problems in graph theory]]</text>
      <sha1>s2a8mctsd76cgts1csjm4uoh2awx438</sha1>
    </revision>
  </page>
  <page>
    <title>Hyperbolic sector</title>
    <ns>0</ns>
    <id>1139926</id>
    <revision>
      <id>828200959</id>
      <parentid>785945022</parentid>
      <timestamp>2018-03-01T03:48:26Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Hyperbolic triangle */√ glyph -&gt; {{radic}} using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5580">[[Image:Hyperbolic sector.svg|200px|right]]

A '''hyperbolic sector''' is a region of the [[Cartesian plane]] {(''x'',''y'')}  bounded by rays from the origin to two points (''a'', 1/''a'') and (''b'', 1/''b'')  and by the [[Hyperbola#Rectangular hyperbola|rectangular hyperbola]] ''xy'' = 1 (or the corresponding region when this hyperbola is rescaled and its [[orientation (geometry)|orientation]] is altered by a [[Rotation (geometry)|rotation]] leaving the center at the origin, as with the [[Unit hyperbola#Parametrization|unit hyperbola]]).

A hyperbolic sector in standard position has ''a'' = 1 and ''b'' &gt; 1 .

Hyperbolic sectors are the basis for the [[hyperbolic function]]s.

==Area==
The [[area]] of a hyperbolic sector in standard position is ln ''b'' .

Proof: Integrate under 1/''x'' from 1 to ''b'', add triangle {(0, 0), (1, 0), (1, 1)}, and subtract triangle {(0, 0), (''b'', 0), (''b'', 1/''b'')}.
&lt;ref&gt;V.G. Ashkinuse &amp; [[Isaak Yaglom]] (1962) ''Ideas and Methods of Affine and Projective Geometry'' (in [[Russian language|Russian]]), page 151, Ministry of Education, Moscow&lt;/ref&gt;

When in standard position, a hyperbolic sector corresponds to a positive [[hyperbolic angle]] at the origin, with the measure of the latter being defined as the area of the former.

==Hyperbolic triangle==
[[File:Cartesian hyperbolic triangle.svg|right|250px|thumb|'''Hyperbolic triangle''' (yellow) and hyperbolic sector (red) corresponding to [[hyperbolic angle]] ''u'', to the  [[rectangular hyperbola]] (equation ''y'' = 1/''x''). The legs of the triangle are {{radic|2}} times the [[Hyperbolic function|hyperbolic cosine and sine functions]].]]

When in standard position, a hyperbolic sector determines a '''hyperbolic triangle''', the [[right triangle]] with one [[vertex (geometry)|vertex]] at the origin, base on the diagonal ray ''y''&amp;nbsp;=&amp;nbsp;''x'', and third vertex on the [[hyperbola]] 
:&lt;math&gt;xy=1,\,&lt;/math&gt;

with the hypotenuse being the segment from the origin to the point (''x, y'') on the hyperbola. The length of the base of this triangle is 
:&lt;math&gt;\sqrt 2 \cosh u,\,&lt;/math&gt;
and the [[altitude (triangle)|altitude]] is 
:&lt;math&gt;\sqrt 2 \sinh u,\,&lt;/math&gt; 
where ''u'' is the appropriate [[hyperbolic angle]].

The analogy between circular and hyperbolic functions was described by [[Augustus De Morgan]] in his ''Trigonometry and Double Algebra'' (1849).&lt;ref&gt;Augustus De Morgan (1849) [https://books.google.com/books?id=7UwEAAAAQAAJ ''Trigonometry and Double Algebra''], Chapter VI: "On the connection of common and hyperbolic trigonometry"&lt;/ref&gt; [[William Burnside]] used such triangles, projecting from a point on the hyperbola ''xy'' = 1 onto the main diagonal, in his article "Note on the addition theorem for hyperbolic functions".&lt;ref&gt;William Burnside (1890) [[Messenger of Mathematics]] 20:145–8, see diagram page 146&lt;/ref&gt;

==Hyperbolic logarithm==
[[Image:hyperbola E.svg|thumb|Unit area when ''b'' = ''e'' as exploited by Euler.]]
{{Main article|natural logarithm}}
Students of [[integral calculus]] know that f(''x'') = ''x''&lt;sup&gt;''p''&lt;/sup&gt; has an algebraic [[antiderivative]] except in the case ''p'' = –1 corresponding to the [[quadrature (mathematics)|quadrature]] of the hyperbola. The other cases are given by [[Cavalieri's quadrature formula]]. Whereas quadrature of the parabola had been accomplished by [[Archimedes]] in the third century BC (in ''[[The Quadrature of the Parabola]]''), the hyperbolic quadrature required the invention in 1647 of a new function: [[Gregoire de Saint-Vincent]] addressed the problem of computing the areas bounded by a hyperbola. His findings led to the natural logarithm function, once called the '''hyperbolic logarithm''' since it is obtained by integrating, or finding the area, under the hyperbola.

Before 1748 and the publication of [[Introduction to the Analysis of the Infinite]], the natural logarithm was known in terms of the area of a hyperbolic sector. [[Leonhard Euler]] changed that when he introduced [[transcendental function]]s such as 10&lt;sup&gt;''x''&lt;/sup&gt;. Euler identified [[e (mathematical constant)|e]] as the value of ''b'' producing a unit of area (under the hyperbola or in a hyperbolic sector in standard position). Then the natural logarithm could be recognized as the [[inverse function]] to the transcendental function e&lt;sup&gt;''x''&lt;/sup&gt;.

==Hyperbolic geometry==
{{Main article|Hyperbolic geometry}}
When [[Felix Klein]] wrote his book on [[non-Euclidean geometry]] in 1928, he provided a foundation for the subject by reference to [[projective geometry]]. To establish hyperbolic measure on a line, he noted that the area of a hyperbolic sector provided visual illustration of the concept.&lt;ref&gt;[[Felix Klein]] (1928) ''Vorlesungen über Nicht-Euklidische Geometrie'', p. 173, figure 113, [[Julius Springer]], Berlin&lt;/ref&gt;

Hyperbolic sectors can also be drawn to the hyperbola &lt;math&gt;y = \sqrt{1 + x^2}&lt;/math&gt;. The area of such hyperbolic sectors has been used to define hyperbolic distance in a geometry [[textbook]].&lt;ref&gt;Jürgen Richter-Gebert (2011) ''Perspectives on Projective Geometry'', p. 385, {{ISBN|9783642172854}} {{MR|id=2791970}}&lt;/ref&gt;

== See also ==
* [[Squeeze mapping]]

==References==
{{reflist}}
* [[Mellen W. Haskell]] (1895) [http://www.ams.org/journals/bull/1895-01-06/S0002-9904-1895-00266-9/S0002-9904-1895-00266-9.pdf On the introduction of the notion of hyperbolic functions] [[Bulletin of the American Mathematical Society]] 1(6):155–9.

[[Category:Area]]
[[Category:Elementary geometry]]
[[Category:Integral calculus]]
[[Category:Logarithms]]</text>
      <sha1>4d1ecrji9cn8spp5dgi5cbo3ibi6q6u</sha1>
    </revision>
  </page>
  <page>
    <title>Hypergeometric function</title>
    <ns>0</ns>
    <id>2055223</id>
    <revision>
      <id>864867636</id>
      <parentid>864831465</parentid>
      <timestamp>2018-10-20T01:21:42Z</timestamp>
      <contributor>
        <username>Joel B. Lewis</username>
        <id>13974845</id>
      </contributor>
      <minor/>
      <comment>/* See also */ avoid unnecessary piping</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="36971">{{dablink| The term "hypergeometric function" sometimes refers to the [[generalized hypergeometric function]]. For other hypergeometric functions see [[#See also|See also]].}}

In [[mathematics]], the Gaussian or ordinary '''hypergeometric function'''  &lt;sub&gt;2&lt;/sub&gt;''F''&lt;sub&gt;1&lt;/sub&gt;(''a'',''b'';''c'';''z'') is a [[Special functions|special function]] represented by the '''hypergeometric series''',  that includes  many other special functions as [[special case|specific]] or [[limiting case (mathematics)|limiting case]]s. It is a solution of a second-order [[linear function|linear]] [[ordinary differential equation]] (ODE). Every second-order linear ODE with three [[regular singular point]]s can be transformed into this equation.

For systematic lists of some of the many thousands of published [[Identity (mathematics)|identities]] involving the hypergeometric function, see the reference works by {{harvtxt | Erdélyi | Magnus | Oberhettinger | Tricomi |1953}} and {{harvtxt | Olde Daalhuis | 2010}}. There is no known system for organizing all of the identities; indeed, there is no known algorithm that can generate all identities; a number of different algorithms are known that generate different series of identities. The theory of the algorithmic discovery of identities remains an active research topic.

==History==
The term "hypergeometric series" was first used by [[John Wallis]] in his 1655 book ''Arithmetica Infinitorum''.

Hypergeometric series were studied by [[Leonhard Euler]], but ''the first full systematic treatment'' was given by {{harvs|txt|authorlink=Carl Friedrich Gauss|first=Carl Friedrich|last=Gauss|year=1813}}.

Studies in the nineteenth century included those of {{harvs|txt|authorlink=Ernst Kummer|first=Ernst|last=Kummer|year=1836}}, and the fundamental characterisation by {{harvs|txt|authorlink=Bernhard Riemann|first=Bernhard|last=Riemann|year=1857}} of the hypergeometric function by means of the differential equation it satisfies.

Riemann showed that the second-order differential equation for  &lt;sub&gt;2&lt;/sub&gt;''F''&lt;sub&gt;1&lt;/sub&gt;(''z''), examined in the complex plane, could be characterised (on the [[Riemann sphere]]) by its three [[regular singularity|regular singularities]].

The cases where the solutions are [[algebraic function]]s were found by [[Hermann Schwarz]] ([[Schwarz's list]]).

==The hypergeometric series==
The hypergeometric function is defined for {{math|{{!}}''z''{{!}} &lt; 1}} by the [[power series]]

:&lt;math&gt;{}_2F_1(a,b;c;z) = \sum_{n=0}^\infty \frac{(a)_n (b)_n}{(c)_n} \frac{z^n}{n!}.&lt;/math&gt;

It is undefined (or infinite) if ''c'' equals a non-positive integer. Here (''q'')&lt;sub&gt;''n''&lt;/sub&gt; is the (rising) [[Pochhammer symbol]], which is defined by:

:&lt;math&gt;(q)_n = \begin{cases}   1   &amp; n = 0 \\
  q(q+1) \cdots (q+n-1) &amp; n &gt; 0
 \end{cases}&lt;/math&gt;

The series terminates if either ''a'' or ''b'' is a nonpositive integer, in which case the function reduces to a polynomial:

:&lt;math&gt;{}_2F_1(-m,b;c;z) = \sum_{n=0}^m (-1)^n \binom{m}{n} \frac{(b)_n}{(c)_n} z^n.&lt;/math&gt;

For complex arguments ''z'' with |''z''|&amp;nbsp;≥&amp;nbsp;1 it can be [[analytic continuation|analytically continued]] along any path in the complex plane that avoids the branch points 1 and infinity.

As {{math|''c'' → −''m''}}, where {{mvar|m}} is a non-negative integer, {{math|&lt;sub&gt;2&lt;/sub&gt;''F''&lt;sub&gt;1&lt;/sub&gt;(''z'') → ∞}}, but if we divide by [[gamma function|{{math|Γ(''c'')}}]], we have a limit:

:&lt;math&gt;\lim_{c\to -m}\frac{{}_2F_1(a,b;c;z)}{\Gamma(c)}=\frac{(a)_{m+1}(b)_{m+1}}{(m+1)!}z^{m+1}{}_2F_1(a+m+1,b+m+1;m+2;z)&lt;/math&gt;

{{math|&lt;sub&gt;2&lt;/sub&gt;''F''&lt;sub&gt;1&lt;/sub&gt;(''z'')}} is the most usual type of [[generalized hypergeometric series]] {{math|''&lt;sub&gt;p&lt;/sub&gt;F&lt;sub&gt;q&lt;/sub&gt;''}}, and is often designated simply {{math|''F''(''z'')}}.

== Differentiation formulas ==
Using the identity &lt;math&gt; (a)_{n+1}=a (a+1)_n&lt;/math&gt;, it is easily shown that

&lt;math&gt;
\frac{d }{dz} \ {}_2F_1(a,b;c;z) = \frac{ab}{c} \ {}_2F_1(a+1,b+1;c+1;z)
&lt;/math&gt;

and more generally,

&lt;math&gt;
\frac{d^n }{dz^n} \ {}_2F_1(a,b;c;z) = \frac{(a)_n (b)_n}{(c)_n} \ {}_2F_1(a+n,b+n;c+n;z)
&lt;/math&gt;

In the special case that &lt;math&gt;c = a + 1&lt;/math&gt;, we have

&lt;math&gt;
\frac{d }{dz} \ {}_2F_1(a,b;a+1;z) = \frac{d }{dz} \ {}_2F_1(b,a;a+1;z) = \frac{a((1-z)^{-b} - {}_2F_1(a,b;1+a;z))}{z}
&lt;/math&gt;

==Special cases==
Many of the common mathematical functions can be expressed in terms of the hypergeometric function, or as limiting cases of it. Some typical examples are

:&lt;math&gt;\ln(1+z) = z\ _2F_1(1,1;2;-z) &lt;/math&gt;
:&lt;math&gt; (1-z)^{-a}  = \ _2F_1(a,1;1;z) &lt;/math&gt;
:&lt;math&gt;\arcsin(z) = z \ _2F_1\bigl(\tfrac{1}{2}, \tfrac{1}{2}; \tfrac{3}{2};z^2\bigr) &lt;/math&gt;

The [[confluent hypergeometric function]] (or Kummer's function) can be given as a limit of the hypergeometric function

:&lt;math&gt;M(a,c,z) = \lim_{b\to \infty}{}_2F_1(a,b;c;b^{-1}z)&lt;/math&gt;

so all functions that are essentially special cases of it, such as [[Bessel functions]], can be expressed as limits of hypergeometric functions. These include most of the commonly used functions of mathematical physics.

[[Legendre function]]s are solutions of a second order differential equation with 3 regular singular points so can be expressed in terms of the hypergeometric function in many ways, for example

:&lt;math&gt;{}_2F_1(a,1-a;c;z) = \Gamma(c)z^{\tfrac{1-c}{2}}(1-z)^{\tfrac{c-1}{2}}P_{-a}^{1-c}(1-2z)&lt;/math&gt;

Several orthogonal polynomials, including [[Jacobi polynomials]] ''P''{{su|p=(α,β)|b=''n''}} and their special cases [[Legendre polynomials]], [[Chebyshev polynomials]], [[Gegenbauer polynomials]] can be written in terms of hypergeometric functions using

:&lt;math&gt;{}_2F_1(-n,\alpha+1+\beta+n;\alpha+1;x) = \frac{n!}{(\alpha+1)_n}P^{(\alpha,\beta)}_n(1-2x)&lt;/math&gt;

Other polynomials that are special cases include [[Krawtchouk polynomials]], [[Meixner polynomials]], [[Meixner–Pollaczek polynomials]].

[[Elliptic modular function]]s can sometimes be expressed as the inverse functions of ratios of hypergeometric functions whose arguments ''a'', ''b'', ''c'' are 1, 1/2, 1/3, ... or 0. For example, if

:&lt;math&gt; \tau = {\rm{i}}\frac{{}_2F_1 \bigl( \frac{1}{2},\frac{1}{2};1;1-z \bigr)}{{}_2F_1 \bigl(\frac{1}{2},\frac{1}{2};1;z \bigr)}&lt;/math&gt;

then

:&lt;math&gt; z = \kappa^2(\tau) = \frac{\theta_2(\tau)^4}{\theta_3(\tau)^4}&lt;/math&gt;

is an elliptic modular function of τ.

[[Incomplete beta function]]s ''B''&lt;sub&gt;''x''&lt;/sub&gt;(''p'',''q'') are related by

:&lt;math&gt; B_x(p,q) = \tfrac{x^p}{p}{}_2F_1(p,1-q;p+1;x)&lt;/math&gt;

The [[complete elliptic integral]]s ''K'' and ''E'' are given by

:&lt;math&gt;K(k) = \tfrac{\pi}{2}\, _2F_1\left(\tfrac{1}{2},\tfrac{1}{2};1;k^2\right)&lt;/math&gt;
:&lt;math&gt;E(k) = \tfrac{\pi}{2}\, _2F_1\left(-\tfrac{1}{2},\tfrac{1}{2};1;k^2\right)&lt;/math&gt;

==The hypergeometric differential equation ==
The hypergeometric function is a solution of Euler's hypergeometric differential equation

:&lt;math&gt;z(1-z)\frac {d^2w}{dz^2} + \left[c-(a+b+1)z \right] \frac {dw}{dz} - ab\,w = 0.&lt;/math&gt;

which has three [[regular singular point]]s: 0,1 and ∞.  The generalization of this equation to three arbitrary regular singular points is given by [[Riemann's differential equation]]. Any second order differential equation with three regular singular points can be converted to the hypergeometric differential equation by a change of variables.

===Solutions at the singular points===
Solutions to the hypergeometric differential equation are built out of the hypergeometric series  &lt;sub&gt;2&lt;/sub&gt;''F''&lt;sub&gt;1&lt;/sub&gt;(''a'',''b'';''c'';''z''). The equation has two [[linearly independent]] solutions. At each of the three singular points 0, 1, ∞, there are usually two special solutions of the form ''x''&lt;sup&gt;''s''&lt;/sup&gt; times a holomorphic function of ''x'', where ''s'' is one of the two roots of the indicial equation and ''x'' is a local variable vanishing at the regular singular point. This gives 3&amp;nbsp;×&amp;nbsp;2&amp;nbsp;=&amp;nbsp;6 special solutions, as follows.

Around the point ''z''&amp;nbsp;=&amp;nbsp;0, two independent solutions are, if ''c'' is not a non-positive integer,

:&lt;math&gt; \, _2F_1(a,b;c;z)&lt;/math&gt;

and, on condition that ''c'' is not an integer,

:&lt;math&gt; z^{1-c} \, _2F_1(1+a-c,1+b-c;2-c;z)&lt;/math&gt;

If ''c'' is a non-positive integer 1−''m'', then the first of these solutions does not exist and must be replaced by &lt;math&gt;z^mF(a+m,b+m;1+m;z).&lt;/math&gt; The second solution does not exist when ''c'' is an integer greater than 1, and is equal to the first solution, or its replacement, when ''c'' is any other integer. So when ''c'' is an integer, a more complicated expression must be used for a second solution, equal to the first solution multiplied by ln(''z''), plus another series in powers of ''z'', involving the [[digamma function]]. See {{harvtxt|Olde Daalhuis|2010}} for details.

Around ''z''&amp;nbsp;=&amp;nbsp;1, if ''c''&amp;nbsp;−&amp;nbsp;''a''&amp;nbsp;−&amp;nbsp;''b'' is not an integer, one has two independent solutions

:&lt;math&gt;\, _2F_1(a,b;1+a+b-c;1-z)&lt;/math&gt;

and

:&lt;math&gt; (1-z)^{c-a-b} \;_2F_1(c-a,c-b;1+c-a-b;1-z)&lt;/math&gt;

Around ''z''&amp;nbsp;=&amp;nbsp;∞, if ''a''&amp;nbsp;−&amp;nbsp;''b'' is not an integer, one has two independent solutions

:&lt;math&gt; z^{-a}\, _2F_1 \left (a,1+a-c;1+a-b; z^{-1} \right)&lt;/math&gt;

and

:&lt;math&gt; z^{-b}\, _2F_1 \left (b,1+b-c;1+b-a; z^{-1} \right ).&lt;/math&gt;

Again, when the conditions of non-integrality are not met, there exist other solutions that are more complicated.

Any 3 of the above 6 solutions satisfy a linear relation as the space of solutions is 2-dimensional, giving ({{su|p=6|b=3}}) =&amp;nbsp;20 linear relations between them called '''connection formulas'''.

===Kummer's 24 solutions===
A second order [[Fuchsian equation]] with ''n'' singular points has a group of symmetries acting (projectively) on its solutions, isomorphic to the [[Coxeter group]] ''D''&lt;sub&gt;''n''&lt;/sub&gt; of order ''n''!2&lt;sup&gt;''n''−1&lt;/sup&gt;. For the hypergeometric equation ''n''=3, so the group is of order 24 and is isomorphic to the symmetric group on 4 points, and was first described by
[[Ernst Kummer|Kummer]].  The isomorphism with the symmetric group is accidental and has no analogue for more than 3 singular points, and it is sometimes better to think of the group as an extension of the symmetric group on 3 points (acting as permutations of the 3 singular points) by a [[Klein 4-group]] (whose elements change the signs of the differences of the exponents at an even number of singular points).  Kummer's group of 24 transformations is generated by the three transformations taking a solution ''F''(''a'',''b'';''c'';''z'') to one of

:&lt;math&gt;(1-z)^{-a} F \left (a,c-b;c; \tfrac{z}{z-1} \right )&lt;/math&gt;
:&lt;math&gt;F(a,b;1+a+b-c;1-z)&lt;/math&gt;
:&lt;math&gt;(1-z)^{-b} F \left(c-a,b;c; \tfrac{z}{z-1} \right )&lt;/math&gt;

which correspond to the transpositions (12), (23), and (34) under an isomorphism with the symmetric group on 4 points 1, 2, 3, 4. (The first and third of these are actually equal to ''F''(''a'',''b'';''c'';''z'') whereas the second is an independent solution to the differential equation.)

Applying Kummer's 24=6×4 transformations to the hypergeometric function gives the 6 = 2×3 solutions above corresponding to each of the 2 possible exponents at each of the 3 singular points, each of which appears 4 times because of the identities

:&lt;math&gt;{}_2F_1(a,b;c;z)  = (1-z)^{c-a-b} \, {}_2F_1(c-a,c-b;c;z) \ \ \  \text{Euler transformation} &lt;/math&gt;
:&lt;math&gt;{}_2F_1(a,b;c;z)  =(1-z)^{-a} \, {}_2F_1(a,c-b;c; \tfrac{z}{z-1})\ \ \  \text{Pfaff transformation} &lt;/math&gt;
:&lt;math&gt;{}_2F_1(a,b;c;z)  =(1-z)^{-b} \, {}_2F_1(c-a,b;c; \tfrac{z}{z-1})\ \ \  \text{Pfaff transformation} &lt;/math&gt;

===Q-form===
The hypergeometric differential equation may be brought into the Q-form

:&lt;math&gt;\frac{d^2u}{dz^2}+Q(z)u(z) = 0&lt;/math&gt;

by making the substitution ''w'' = ''uv'' and eliminating the first-derivative term. One finds that

:&lt;math&gt;Q=\frac{z^2[1-(a-b)^2] +z[2c(a+b-1)-4ab] +c(2-c)}{4z^2(1-z)^2}&lt;/math&gt;

and ''v'' is given by the solution to

:&lt;math&gt;\frac{d}{dz}\log v(z) = - \frac {c-z(a+b+1)}{2z(1-z)} =-\frac{c}{2z}-\frac{1+a+b-c}{2(z-1)}&lt;/math&gt;

which is

:&lt;math&gt;v(z)=z^{-c/2}(1-z)^{(c-a-b-1)/2}.&lt;/math&gt;

The Q-form is significant in its relation to the [[Schwarzian derivative]] {{harv|Hille|1976|pp=307–401}}.

===Schwarz triangle maps===
{{see also|Schwarz triangle function}}
The '''Schwarz triangle maps''' or '''Schwarz ''s''-functions''' are ratios of pairs of solutions.

:&lt;math&gt;s_k(z) = \frac{\phi_k^{(1)}(z)}{\phi_k^{(0)}(z)}&lt;/math&gt;

where ''k'' is one of the points 0, 1, ∞. The notation

:&lt;math&gt;D_k(\lambda,\mu,\nu;z)=s_k(z)&lt;/math&gt;

is also sometimes used. Note that the connection coefficients become [[Möbius transformation]]s on the triangle maps.

Note that each triangle map is [[Regular singular point|regular]] at ''z'' ∈ {0, 1, ∞} respectively, with

:&lt;math&gt;s_0(z)=z^\lambda (1+\mathcal{O}(z))&lt;/math&gt;
:&lt;math&gt;s_1(z)=(1-z)^\mu (1+\mathcal{O}(1-z))&lt;/math&gt;
and
:&lt;math&gt;s_\infty(z)=z^\nu (1+\mathcal{O}(\tfrac{1}{z})).&lt;/math&gt;

In the special case of λ, μ and ν real, with 0&amp;nbsp;&amp;le;&amp;nbsp;λ,μ,ν&amp;nbsp;&amp;lt;&amp;nbsp;1 then the s-maps are [[conformal map]]s of the [[upper half-plane]] '''H''' to triangles on the [[Riemann sphere]], bounded by circular arcs. This mapping is [[Schwarzian derivative#Conformal mapping of circular arc polygons|a generalization]] of the [[Schwarz–Christoffel mapping]] to triangles with circular arcs. The singular points 0,1 and ∞ are sent to the triangle vertices.  The angles of the triangle are πλ, πμ and πν respectively.

Furthermore, in the case of λ=1/''p'', μ=1/''q'' and  ν=1/''r'' for integers ''p'', ''q'', ''r'', then the triangle tiles the sphere, the complex plane or the upper half plane according to whether λ + μ + ν – 1 is positive, zero or negative; and the s-maps are inverse functions of [[automorphic function]]s for the [[triangle group]] &amp;#x3008;''p'',&amp;nbsp;''q'',&amp;nbsp;''r''&amp;#x3009;&amp;nbsp;=&amp;nbsp;Δ(''p'',&amp;nbsp;''q'',&amp;nbsp;''r'').

===Monodromy group===
The monodromy of a hypergeometric equation describes how fundamental solutions change when analytically continued around paths in the ''z'' plane that return to the same point.
That is, when the path winds around a singularity of  &lt;sub&gt;2&lt;/sub&gt;''F''&lt;sub&gt;1&lt;/sub&gt;, the value of the solutions at the endpoint will differ from the starting point.

Two fundamental solutions of the hypergeometric equation are related to each other by a linear transformation; thus the monodromy is a mapping (group homomorphism):

:&lt;math&gt;\pi_1(\mathbf{C}\setminus\{0,1\},z_0) \to \text{GL}(2,\mathbf{C})&lt;/math&gt;

where π&lt;sub&gt;1&lt;/sub&gt; is the [[fundamental group]]. In other words, the monodromy is a two dimensional linear representation of the fundamental group. The [[monodromy group]] of the equation is the image of this map, i.e. the group generated by the monodromy matrices. The monodromy representation of the fundamental group can be computed explicitly in terms of the exponents at the singular points.&lt;ref&gt;{{harvnb|Ince|1944|pages=393–393}}&lt;/ref&gt; If (α, α'), (β, β') and  (γ,γ') are the exponents at 0, 1 and ∞, then, taking ''z''&lt;sub&gt;0&lt;/sub&gt; near 0, the loops around 0 and 1 have monodromy matrices

:&lt;math&gt;g_0=\begin{pmatrix} e^{2\pi i\alpha} &amp; 0\\ 0 &amp; e^{2\pi i\alpha^\prime}\end{pmatrix}\,\,\,&lt;/math&gt; and &lt;math&gt;\,\,\,g_1=\begin{pmatrix} {\mu e^{2\pi i \beta} 
-e^{2\pi i\beta^\prime}\over \mu -1} &amp; {\mu (e^{2\pi i \beta} 
-e^{2\pi i\beta^\prime)}\over (\mu -1)^2}\\e^{2\pi i\beta^\prime} - e^{2\pi i\beta} &amp; {\mu e^{2\pi i \beta^\prime} 
-e^{2\pi i\beta}\over \mu -1}\end{pmatrix},&lt;/math&gt;

where

:&lt;math&gt;\mu = {\sin \pi(\alpha +\beta^\prime +\gamma^\prime) \sin \pi(\alpha^\prime + \beta+\gamma^\prime)\over \sin \pi(\alpha^\prime +  \beta^\prime +\gamma^\prime) \sin \pi(\alpha + \beta +\gamma^\prime)}.&lt;/math&gt;

If 1-''a'', ''c''-''a''-''b'', ''a''-''b'' are non-integer rational numbers with denominators ''k'',''l'',''m'' then the monodromy group is finite if and only if &lt;math&gt;1/k + 1/l + 1/m &gt; 1&lt;/math&gt;, see [[Schwarz's list]] or [[Picard–Vessiot theory|Kovacic's algorithm]].

==Integral formulas==

===Euler type===
If ''B'' is the [[beta function]] then

:&lt;math&gt;\Beta(b,c-b)\,_2F_1(a,b;c;z) = \int_0^1 x^{b-1} (1-x)^{c-b-1}(1-zx)^{-a} \, dx \qquad \real(c) &gt; \real(b) &gt; 0, &lt;/math&gt;

provided that ''z'' is not a real number such that it is greater than or equal to 1. and can be proved by expanding (1&amp;nbsp;−&amp;nbsp;''zx'')&lt;sup&gt;−''a''&lt;/sup&gt; using the binomial theorem and then integrating term by term for ''z'' with absolute value smaller than 1, and by analytic continuation elsewhere.  When ''z'' is a real number greater than or equal to 1, analytic continuation must be used because (1&amp;nbsp;−&amp;nbsp;''zx'') is zero at some point in the support of the integral, so the value of the integral may be ill-defined.  This was given by Euler in 1748 and implies Euler's and Pfaff's hypergeometric transformations.

Other representations, corresponding to other [[principal branch|branches]], are given by taking the same integrand, but taking the path of integration to be a closed [[Pochhammer cycle]] enclosing the singularities in various orders.  Such paths correspond to the [[monodromy]] action.

===Barnes integral===
Barnes used the theory of [[Residue (complex analysis)|residues]]  to evaluate the [[Barnes integral]]

:&lt;math&gt;\frac{1}{2\pi i}\int_{-i\infty}^{i\infty} \frac{\Gamma(a+s)\Gamma(b+s)\Gamma(-s)}{\Gamma(c+s)} (-z)^s \, ds&lt;/math&gt;

as

:&lt;math&gt;\frac{\Gamma(a)\Gamma(b)}{\Gamma(c)}\,_2F_1(a,b;c;z),&lt;/math&gt;

where the contour is drawn to separate the poles 0, 1, 2... from the poles −''a'', −''a''&amp;nbsp;−&amp;nbsp;1,&amp;nbsp;..., −''b'', −''b''&amp;nbsp;−&amp;nbsp;1,&amp;nbsp;...&amp;nbsp;. This is valid as long as z is not a nonnegative real number.

===John transform===
The Gauss hypergeometric function can be written as a [[John transform]] {{harv|Gelfand|Gindikin|Graev|2003|loc=2.1.2}}.

==Gauss' contiguous relations==
The six functions

:&lt;math&gt;{}_2F_1 (a\pm 1,b;c;z), \quad  {}_2F_1 (a,b\pm 1;c;z), \quad {}_2F_1 (a,b;c\pm 1;z)&lt;/math&gt;

are called contiguous to {{math|&lt;sub&gt;2&lt;/sub&gt;''F''&lt;sub&gt;1&lt;/sub&gt;(''a'', ''b''; ''c''; ''z'')}}. Gauss showed that {{math|&lt;sub&gt;2&lt;/sub&gt;''F''&lt;sub&gt;1&lt;/sub&gt;(''a'', ''b''; ''c''; ''z'')}} can be written as a linear combination of any two of its contiguous functions, with rational coefficients in terms of {{math|''a'', ''b'', ''c''}}, and {{mvar|z}}. This gives

:&lt;math&gt; \begin{pmatrix} 6 \\ 2 \end{pmatrix} = 15&lt;/math&gt;

relations, given by identifying any two lines on the right hand side of

:&lt;math&gt;\begin{align}
z\frac{dF}{dz} &amp;= z\frac{ab}{c}F(a+,b+,c+) \\
&amp;=a(F(a+)-F) \\
&amp;=b(F(b+)-F) \\
&amp;=(c-1)(F(c-)-F) \\
&amp;=\frac{(c-a)F(a-)+(a-c+bz)F}{1-z} \\
&amp;=\frac{(c-b)F(b-)+(b-c+az)F}{1-z} \\
&amp;=z\frac{(c-a)(c-b)F(c+)+c(a+b-c)F}{c(1-z)}
\end{align}&lt;/math&gt;

where {{math|''F'' {{=}} &lt;sub&gt;2&lt;/sub&gt;''F''&lt;sub&gt;1&lt;/sub&gt;(''a'', ''b''; ''c''; ''z''), ''F''(''a''+) {{=}} &lt;sub&gt;2&lt;/sub&gt;''F''&lt;sub&gt;1&lt;/sub&gt;(''a'' + 1, ''b''; ''c''; ''z'')}}, and so on. Repeatedly applying these relations gives a linear relation over {{math|'''C'''(z)}} between any three functions of the form

:&lt;math&gt;{}_2F_1 (a+m,b+n;c+l;z),&lt;/math&gt;

where ''m'', ''n'', and ''l'' are integers.

===Gauss' continued fraction===
{{main|Gauss continued fraction}}

Gauss used the contiguous relations to give several ways to write a quotient of two hypergeometric functions as a continued fraction, for example:

:&lt;math&gt;\frac{{}_2F_1(a+1,b;c+1;z)}{{}_2F_1(a,b;c;z)} = \cfrac{1}{1 + \cfrac{\frac{(a-c)b}{c(c+1)} z}{1 + \cfrac{\frac{(b-c-1)(a+1)}{(c+1)(c+2)} z}{1 + \cfrac{\frac{(a-c-1)(b+1)}{(c+2)(c+3)} z}{1 + \cfrac{\frac{(b-c-2)(a+2)}{(c+3)(c+4)} z}{1 + {}\ddots}}}}}&lt;/math&gt;

==Transformation formulas==
Transformation formulas relate two hypergeometric functions at different values of the argument ''z''.

===Fractional linear transformations===
Euler's transformation is
:&lt;math&gt;{}_2F_1 (a,b;c;z) = (1-z)^{c-a-b} {}_2F_1 (c-a, c-b;c ; z).&lt;/math&gt;
It follows by combining the two Pfaff transformations
:&lt;math&gt;{}_2F_1 (a,b;c;z) = (1-z)^{-b} {}_2F_1 \left (b,c-a;c;\tfrac{z}{z-1} \right )&lt;/math&gt;
:&lt;math&gt;{}_2F_1 (a,b;c;z) = (1-z)^{-a} {}_2F_1 \left (a, c-b;c ; \tfrac{z}{z-1} \right )&lt;/math&gt;
which in turn follow from Euler's integral representation. For extension of Euler's first and second transformations, see {{harvtxt|Rathie|Paris|2007}} and {{harvtxt|Rakha|Rathie|2011}}.

===Quadratic  transformations===
If two of the numbers 1&amp;nbsp;−&amp;nbsp;''c'', ''c''&amp;nbsp;−&amp;nbsp;1, ''a''&amp;nbsp;−&amp;nbsp;''b'', ''b''&amp;nbsp;−&amp;nbsp;''a'', ''a''&amp;nbsp;+&amp;nbsp;''b''&amp;nbsp;−&amp;nbsp;''c'', ''c''&amp;nbsp;−&amp;nbsp;''a''&amp;nbsp;−&amp;nbsp;''b'' are equal or one of them is 1/2 then there is a '''quadratic transformation''' of the hypergeometric function, connecting it to a different value of ''z'' related by a quadratic equation. The first examples were given by {{harvtxt|Kummer|1836}}, and a complete list was given by {{harvtxt|Goursat|1881}}. A typical example is

:&lt;math&gt;{}_2F_1(a,b;2b;z) = (1-z)^{-\frac{a}{2}} {}_2F_1 \left (\tfrac{1}{2}a, b-\tfrac{1}{2}a; b+\tfrac{1}{2}; \frac{z^2}{4z-4} \right)&lt;/math&gt;

===Higher order transformations===
If  1−''c'', ''a''−''b'',  ''a''+''b''−''c'' differ by signs or two of them are 1/3 or −1/3 then there is a '''cubic transformation''' of the hypergeometric function, connecting it to a different value of ''z'' related by a cubic equation. The first examples were given by {{harvtxt|Goursat|1881}}. A typical example is

:&lt;math&gt;{}_2F_1 \left (\tfrac{3}{2}a,\tfrac{1}{2}(3a-1);a+\tfrac{1}{2};-\tfrac{z^2}{3} \right) = (1+z)^{1-3a} \, {}_2F_1 \left (a-\tfrac{1}{3}, a; 2a; 2z(3+z^2)(1+z)^{-3} \right )&lt;/math&gt;

There are also some transformations of degree 4 and 6. Transformations of other degrees only exist if ''a'', ''b'', and ''c'' are certain rational numbers {{harv|Vidunas|2005}}.  For example,
:&lt;math&gt;{}_2F_1 \left (\tfrac{1}{4},\tfrac{3}{8};\tfrac{7}{8}; z \right) (z^4-60z^3+134z^2-60z+1)^{1/16}  =
  {}_2F_1 \left (\tfrac{1}{48}, \tfrac{17}{48}; \tfrac{7}{8}; \tfrac{-432 z (z-1)^2 (z+1)^8}{(z^4-60z^3+134z^2-60z+1)^3} \right ).&lt;/math&gt;

==Values at special points ''z''==
See {{harvtxt|Slater|1966|loc=Appendix III}} for a list of summation formulas at special points, most of which also appear in {{harvtxt|Bailey|1935}}.  {{harvtxt | Gessel | Stanton | 1982}} gives further evaluations at more points. {{harvtxt|Koepf|1995}} shows how most of these identities can be verified by computer algorithms.

===Special values at ''z''&amp;nbsp;=&amp;nbsp;1===
Gauss's theorem, named for [[Carl Friedrich Gauss]], is the identity

:&lt;math&gt;{}_2F_1 (a,b;c;1)= \frac{\Gamma(c)\Gamma(c-a-b)}{\Gamma(c-a)\Gamma(c-b)}, \qquad   \Re(c)&gt;\Re(a+b) &lt;/math&gt;

which follows from Euler's integral formula by putting ''z''&amp;nbsp;=&amp;nbsp;1. It includes the [[Vandermonde identity]] as a special case.

For the special case where &lt;math&gt; a=-m &lt;/math&gt;, 
:&lt;math&gt;{}_2F_1 (-m,b;c;1)=\frac{ (c-b)_{m} }{(c)_{m}  } &lt;/math&gt;

[[bilateral hypergeometric series|Dougall's formula]] generalizes this to the [[bilateral hypergeometric series]] at ''z''&amp;nbsp;=&amp;nbsp;1.

===Kummer's theorem (''z''&amp;nbsp;=&amp;nbsp;−1) ===
&lt;span id="Kummer's theorem"&gt;&lt;/span&gt;There are many cases where hypergeometric functions can be evaluated at ''z''&amp;nbsp;=&amp;nbsp;−1 by using a quadratic transformation to change ''z''&amp;nbsp;=&amp;nbsp;−1 to ''z''&amp;nbsp;=&amp;nbsp;1 and then using Gauss's theorem to evaluate the result. A typical example is Kummer's theorem, named for [[Ernst Kummer]]:

:&lt;math&gt;{}_2F_1 (a,b;1+a-b;-1)= \frac{\Gamma(1+a-b)\Gamma(1+\tfrac12a)}{\Gamma(1+a)\Gamma(1+\tfrac12a-b)}&lt;/math&gt;

which follows from Kummer's quadratic transformations

:&lt;math&gt;\begin{align}
_2F_1(a,b;1+a-b;z)&amp;= (1-z)^{-a} \;_2F_1 \left(\frac a 2, \frac{1+a}2-b; 1+a-b; -\frac{4z}{(1-z)^2}\right)\\
&amp;=(1+z)^{-a} \, _2F_1\left(\frac a 2, \frac{a+1}2; 1+a-b; \frac{4z}{(1+z)^2}\right)
\end{align}&lt;/math&gt;

and Gauss's theorem by putting ''z''&amp;nbsp;=&amp;nbsp;−1 in the first identity. For generalization of Kummer's summation, see {{harvtxt | Lavoie | Grondin | Rathie | 1996}}.

===Values at ''z''&amp;nbsp;=&amp;nbsp;1/2===
Gauss's second summation theorem is

:&lt;math&gt;_2F_1 \left(a,b;\tfrac12\left(1+a+b\right);\tfrac12\right) = \frac{\Gamma(\tfrac12)\Gamma(\tfrac12\left(1+a+b\right))}{\Gamma(\tfrac12\left(1+a)\right)\Gamma(\tfrac12\left(1+b\right))}. &lt;/math&gt;

Bailey's theorem is

:&lt;math&gt;_2F_1 \left(a,1-a;c;\tfrac12\right)= \frac{\Gamma(\tfrac12c)\Gamma(\tfrac12\left(1+c\right))}{\Gamma(\tfrac12\left(c+a\right))\Gamma(\tfrac12\left(1+c-a\right))}.&lt;/math&gt;

For generalizations of Gauss's second summation theorem and Bailey's summation theorem, see {{harvtxt | Lavoie| Grondin | Rathie|1996}}.

===Other points===
There are many other formulas giving the hypergeometric function as an algebraic number at special rational values of the parameters, some of which are listed in {{harvtxt | Gessel | Stanton | 1982}} and {{harvtxt|Koepf|1995}}. Some typical examples are given by

:&lt;math&gt;{}_2F_1 \left(a,-a;\tfrac{1}{2};\tfrac{x^2}{4(x-1)} \right )  = \frac{(1-x)^a+(1-x)^{-a}}{2},&lt;/math&gt;

which can be restated as

:&lt;math&gt;T_a(\cos x)={}_2F_1\left(a,-a;\tfrac{1}{2};\tfrac{1}{2}(1-\cos x)\right)=\cos(a x)&lt;/math&gt;

whenever −π &lt; ''x'' &lt; π and ''T'' is the (generalized) [[Chebyshev polynomial]].

==See also==
*[[Appell series]], a 2-variable generalization of hypergeometric series
*[[Basic hypergeometric series]] where the ratio of terms is a periodic function of the index
*[[Bilateral hypergeometric series]] &lt;sub&gt;''p''&lt;/sub&gt;H&lt;sub&gt;''p''&lt;/sub&gt; are similar to generalized hypergeometric series, but summed over all integers
*[[Binomial series]] &lt;sub&gt;1&lt;/sub&gt;F&lt;sub&gt;0&lt;/sub&gt;
*[[Confluent hypergeometric series]] &lt;sub&gt;1&lt;/sub&gt;F&lt;sub&gt;1&lt;/sub&gt;(''a'';''c'';''z'')
*[[Elliptic hypergeometric series]] where the ratio of terms is an elliptic function of the index
*[[Euler hypergeometric integral]], an integral representation of &lt;sub&gt;2&lt;/sub&gt;''F''&lt;sub&gt;1&lt;/sub&gt;
*[[Fox H-function]], an extension of the Meijer G-function
*[[Fox–Wright function]], a generalization of the [[generalized hypergeometric function]]
*[[Frobenius solution to the hypergeometric equation]]
*[[General hypergeometric function]] introduced by [[Israel Gelfand|I. M. Gelfand]]. 
*[[Generalized hypergeometric series]] &lt;sub&gt;''p''&lt;/sub&gt;F&lt;sub&gt;''q''&lt;/sub&gt; where the ratio of terms is a rational function of the index
*[[Geometric series]], where the ratio of  terms is a constant
*[[Heun function]], solutions of second order ODE's with four regular singular points
*[[Horn function]], 34 distinct convergent hypergeometric series in two variables
*[[Humbert series]] 7 hypergeometric functions of 2 variables
*[[Hypergeometric differential equation]], a second-order linear ordinary differential equation
*[[Hypergeometric distribution]], a discrete probability distribution
*[[Hypergeometric function of a matrix argument]], the multivariate generalization of the hypergeometric series
*[[Kampé de Fériet function]], hypergeometric series of two variables
*[[Lauricella hypergeometric series]], hypergeometric series of three variables
*[[MacRobert E-function]], an extension of the generalized hypergeometric series &lt;sub&gt;''p''&lt;/sub&gt;F&lt;sub&gt;''q''&lt;/sub&gt; to the case ''p''&gt;''q''+1.
*[[Meijer G-function]], an extension of the generalized hypergeometric series &lt;sub&gt;''p''&lt;/sub&gt;F&lt;sub&gt;''q''&lt;/sub&gt; to the case ''p''&gt;''q''+1.
*[[Modular hypergeometric series]], a terminating form of the elliptic hypergeometric series
*[[Theta hypergeometric series]], a special sort of elliptic hypergeometric series.
*[[Virasoro conformal block]]s, special functions in [[two-dimensional conformal field theory]] that reduce to hypergeometric functions in some cases.

==References==
{{reflist}}
* {{cite book | last1= Andrews | first1= George E. | authorlink= George Andrews (mathematician) | last2= Askey | first2= Richard | last3= Roy | first3= Ranjan | lastauthoramp= yes | title= Special functions | publisher= Cambridge University Press | year= 1999 | series= Encyclopedia of Mathematics and its Applications | volume= 71 | isbn= 978-0-521-62321-6 | mr= 1688958 | ref= harv}}
* {{cite book | last=Bailey | first=W.N. | year=1935 | title=Generalized Hypergeometric Series |  publisher=Cambridge University Press | url=http://plouffe.fr/simon/math/Bailey%20W.N.%20Generalized%20Hypergeometric%20Series%20%281964%29%28L%29%28T%29%2859s%29.pdf | ref=harv}}
* [[Frits Beukers|Beukers, Frits]] (2002), ''[http://www.math.uu.nl/people/beukers/MRIcourse93.ps Gauss' hypergeometric function]''. (lecture notes reviewing basics, as well as triangle maps and monodromy)
* {{dlmf | first= Adri B. | last= Olde Daalhuis | id= 15}}
* {{cite book | last1= Erdélyi | first1= Arthur | author1-link= Arthur Erdélyi | last2= Magnus | first2= Wilhelm | author2-link= Wilhelm Magnus | last3= Oberhettinger | first3= Fritz | lastauthoramp= yes | last4= Tricomi | first4= Francesco G. | title= Higher transcendental functions | volume= Vol. I | location= New York – Toronto – London | publisher= McGraw–Hill Book Company, Inc. | year= 1953 | isbn= 978-0-89874-206-0 | mr= 0058756 | url= http://apps.nrbook.com/bateman/Vol1.pdf | ref= harv }}
* Gasper, George &amp; [[Mizan Rahman|Rahman, Mizan]] (2004). Basic Hypergeometric Series, 2nd Edition, Encyclopedia of Mathematics and Its Applications, 96, Cambridge University Press, Cambridge. {{ISBN|0-521-83357-4}}.
* {{cite journal | last= Gauss | first= Carl Friedrich | authorlink= Carl Friedrich Gauss | title= Disquisitiones generales circa seriem infinitam &amp;nbsp; &lt;math&gt; 1 + \tfrac {\alpha \beta} {1 \cdot \gamma} ~x + \tfrac {\alpha (\alpha+1) \beta (\beta+1)} {1 \cdot 2 \cdot \gamma (\gamma+1)} ~x~x + \mbox{etc.} &lt;/math&gt; | language= Latin | url= https://books.google.com/books?id=uDMAAAAAQAAJ | location= Göttingen | journal= Commentationes societatis regiae scientarum Gottingensis recentiores | year= 1813 | volume= 2 | ref= harv}} 
* {{cite book | last1= Gelfand | first1= I. M. | last2= Gindikin | first2= S.G. | lastauthoramp= yes | last3= Graev | first3= M.I. | title= Selected topics in integral geometry | origyear= 2000 | url= https://books.google.com/books?isbn=0821829327 | publisher= [[American Mathematical Society]] | location= Providence, R.I. | series= Translations of Mathematical Monographs | year= 2003 | volume= 220 | isbn= 978-0-8218-2932-5 | mr= 2000133 | ref= harv}}
* {{cite journal | last1= Gessel | first1= Ira | lastauthoramp= yes | last2= Stanton | first2= Dennis | title= Strange evaluations of hypergeometric series | journal= SIAM Journal on Mathematical Analysis | year= 1982 | volume= 13 | issue= 2 | pages= 295–308 | issn= 0036-1410 | doi= 10.1137/0513021 | mr= 647127 | ref= harv}}
* {{cite journal |last=Goursat |first=Édouard |authorlink=Édouard Goursat |title=Sur l'équation différentielle linéaire, qui admet pour intégrale la série hypergéométrique |language=French |url=http://www.numdam.org/item?id=ASENS_1881_2_10__S3_0 |accessdate=2008-10-16 |journal=Annales Scientifiques de l'École Normale Supérieure |volume=10 |year=1881 |pages=3–142 |ref=harv }}
* {{cite book | last1= Heckman | first1= Gerrit | last2= Schlichtkrull | first2= Henrik | lastauthoramp= yes | title= Harmonic Analysis and Special Functions on Symmetric Spaces | location= San Diego | publisher= Academic Press | year= 1994 | isbn= 0-12-336170-2 | ref= harv}} (part 1 treats hypergeometric functions on Lie groups)
* {{cite book | last=Hille | first=Einar | year=1976 | title=Ordinary differential equations in the complex domain | publisher=Dover | ISBN=0-486-69620-0 | ref=harv}}
*{{cite book|last=Ince|first=E. L.|authorlink=E. L. Ince|title=Ordinary Differential Equations|publisher= Dover Publications|year= 1944}}
* {{cite book | last= Klein | first= Felix | title= Vorlesungen über die hypergeometrische Funktion | language= German | url= http://resolver.sub.uni-goettingen.de/purl?PPN375394591 | location= Berlin, New York | publisher= Springer-Verlag | year= 1981 | series= Grundlehren der Mathematischen Wissenschaften | volume= 39 | isbn= 978-3-540-10455-1 | mr= 668700 | ref= harv}}
* {{cite journal | last= Koepf | first= Wolfram | title= Algorithms for m-fold hypergeometric summation | year= 1995 | journal= Journal of Symbolic Computation | issn= 0747-7171 | volume= 20 | issue= 4 | pages= 399–417 | mr=1384455 | doi= 10.1006/jsco.1995.1056 | ref= harv}}
* {{cite journal | last= Kummer | first= Ernst Eduard | title= Über die hypergeometrische Reihe&amp;nbsp;&lt;math&gt; 1 + \tfrac {\alpha\cdot \beta} {1 \cdot \gamma} ~x + \tfrac {\alpha (\alpha+1) \beta (\beta+1)} {1 \cdot 2 \cdot \gamma (\gamma+1)} x^2 + \tfrac {\alpha (\alpha+1)(\alpha+2) \beta (\beta+1)(\beta+2)} {1 \cdot 2\cdot 3 \cdot \gamma (\gamma+1)(\gamma+2)} x^3 +\mbox{etc.} &lt;/math&gt; | language= German | url= http://resolver.sub.uni-goettingen.de/purl?GDZPPN00214056X | journal= [[Journal für die reine und angewandte Mathematik]] | year= 1836 | volume= 15 | pages= 39–83, 127–172 | issn= 0075-4102 | ref= harv}}
*{{cite journal | last1=Lavoie | first1=J. L. | last2=Grondin | first2=F. | last3=Rathie | first3=A.K. | year=1996 | title= Generalizations of Whipple's theorem on the sum of a &lt;sub&gt;3&lt;/sub&gt;F&lt;sub&gt;2&lt;/sub&gt; | journal = J. Comput. Appl. Math. | volume=72 | pages=293–300 | ref=harv}}
* {{cite book | last1= Press | first1= W.H. | last2= Teukolsky | first2= S.A. | last3= Vetterling | first3= W.T. | last4= Flannery | first4= B.P. | lastauthoramp= yes | year= 2007 | title= Numerical Recipes: The Art of Scientific Computing | edition= 3rd | publisher= Cambridge University Press | publication-place= New York | isbn= 978-0-521-88068-8 | chapter= Section 6.13. Hypergeometric Functions | chapter-url= http://apps.nrbook.com/empanel/index.html#pg=318 | ref= harv}}
*{{cite journal | last1=Rakha | first1=M.A. | last2=Rathie | first2=Arjun K. | year=2011 | title=Extensions of Euler's type-II transformation and Saalschutz's theorem | journal= Bull. Korean Math. Soc. | volume=48 | issue=1 | pages=151–156 | ref=harv}}
*{{cite journal | last1=Rathie | first1= Arjun K. | last2= Paris | first2=R.B. | year=2007 |title= An extension of the Euler's-type transformation for the 3F2 series | journal= Far East J. Math. Sci. | volume=27 | issue=1 | pages=43–48 | ref=harv}}
* {{cite journal | last= Riemann | first= Bernhard | author-link= Bernhard Riemann | year= 1857 | title= Beiträge zur Theorie der durch die Gauss'sche Reihe ''F(α, β, γ, x)'' darstellbaren Functionen | journal= Abhandlungen der Mathematischen Classe der Königlichen Gesellschaft der Wissenschaften zu Göttingen | language= German | volume= 7 | pages= 3–22 | publisher= Verlag der Dieterichschen Buchhandlung | location= Göttingen | url= http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=GDZPPN002018691 | ref= harv}} (a reprint of this paper can be found in {{cite web|url= http://www.emis.de/classics/Riemann/PFunct.pdf |title=All publications of Riemann }})
* {{cite book | last= Slater | first= Lucy Joan | authorlink= Lucy Joan Slater | title= Confluent hypergeometric functions | location= Cambridge, UK | publisher= Cambridge University Press | year= 1960 | mr= 0107026 | ref= harv}}
* {{cite book | last= Slater | first= Lucy Joan | title= Generalized hypergeometric functions | location= Cambridge, UK | publisher= Cambridge University Press | year= 1966 | isbn= 0-521-06483-X | mr= 0201688 | ref= harv}} (there is a 2008 paperback with {{ISBN|978-0-521-09061-2}})
* {{cite journal | last= Vidunas | first = Raimundas | title = Transformations of some Gauss hypergeometric functions | year = 2005 | journal = Journal of Symbolic Computation | volume = 178 | pages = 473–487 | doi=10.1016/j.cam.2004.09.053 | ref=harv}}
* {{cite book | last= Wall | first= H.S. | title= Analytic Theory of Continued Fractions | publisher= D. Van Nostrand Company, Inc. | year= 1948 | ref= harv}}
* {{cite book | last1= Whittaker | first1= E.T. | last2= Watson | first2= G.N. | lastauthoramp= yes | title= A Course of Modern Analysis | location= Cambridge, UK | publisher= Cambridge University Press | year= 1927 | ref= harv}}
* {{cite book | last= Yoshida | first= Masaaki | title= Hypergeometric Functions, My Love: Modular Interpretations of Configuration Spaces | location= Braunschweig – Wiesbaden | publisher= Friedr. Vieweg &amp; Sohn | year= 1997 | isbn= 3-528-06925-2 | mr= 1453580 | ref= harv}}

==External links==
* {{springer|title=Hypergeometric function|id=p/h048450}}
* John Pearson, [http://people.maths.ox.ac.uk/porterm/research/pearson_final.pdf Computation of Hypergeometric Functions] ([[University of Oxford]], MSc Thesis)
* Marko Petkovsek, Herbert Wilf and Doron Zeilberger, [https://web.archive.org/web/20060129095451/http://www.cis.upenn.edu/~wilf/AeqB.html The book "A = B"] (freely downloadable)
* {{MathWorld |title=Hypergeometric Function |urlname= HypergeometricFunction}}

{{DEFAULTSORT:Hypergeometric Function}}
[[Category:Factorial and binomial topics]]
[[Category:Hypergeometric functions|*]]
[[Category:Ordinary differential equations]]
[[Category:Mathematical series]]</text>
      <sha1>4gvawxzamqyf3m8roo5zsr7ave53vbi</sha1>
    </revision>
  </page>
  <page>
    <title>Implicit graph</title>
    <ns>0</ns>
    <id>24109545</id>
    <revision>
      <id>842563407</id>
      <parentid>841548226</parentid>
      <timestamp>2018-05-23T07:25:09Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20107">In the study of [[graph algorithm]]s, an '''implicit graph representation''' (or more simply '''implicit graph''') is a [[Graph (discrete mathematics)|graph]] whose vertices or edges are not represented as explicit objects in a computer's memory, but rather are determined [[algorithm]]ically from some more concise input.

==Neighborhood representations==
The notion of an implicit graph is common in various [[search algorithm]]s which are described in terms of graphs. In this context, an implicit graph may be  defined as a set of rules to define all [[Neighborhood (graph theory)|neighbors]] for any specified vertex.&lt;ref&gt;{{citation
 | last = Korf | first = Richard E.
 | at = Article 26, 40pp
 | doi = 10.1145/1455248.1455250
 | issue = 6
 | journal = [[Journal of the ACM]]
 | mr = 2477486
 | title = Linear-time disk-based implicit graph search
 | volume = 55
 | year = 2008}}.&lt;/ref&gt; This type of implicit graph representation is analogous to an [[adjacency list]], in that it provides easy access to the neighbors of each vertex. For instance, in searching for a solution to a puzzle such as [[Rubik's Cube]], one may define an implicit graph in which each vertex represents one of the possible states of the cube, and each edge represents a move from one state to another. It is straightforward to generate the neighbors of any vertex by trying all possible moves in the puzzle and determining the states reached by each of these moves; however, an implicit representation is necessary, as the state space of Rubik's Cube is too large to allow an algorithm to list all of its states.&lt;ref&gt;{{citation|last=Korf|first=Richard E.|contribution=Minimizing disk I/O in two-bit breadth-first search|title=Proc. 23rd AAAI Conf. on Artificial Intelligence|year=2008|url=http://www.aaai.org/Papers/AAAI/2008/AAAI08-050.pdf|pages=317–324|quotation=The standard 3&amp;times;3&amp;times;3 Rubik’s Cube contains 4.3252&amp;nbsp;&amp;times;&amp;nbsp;10&lt;sup&gt;19&lt;/sup&gt; states, and is too large to search exhaustively.}}&lt;/ref&gt;

In [[computational complexity theory]], several [[complexity class]]es have been defined in connection with implicit graphs, defined as above by a rule or algorithm for listing the neighbors of a vertex. For instance, [[PPA (complexity)|PPA]] is the class of problems in which one is given as input an undirected implicit graph (in which vertices are {{mvar|n}}-bit binary strings, with a [[polynomial time]] algorithm for listing the neighbors of any vertex) and a vertex of odd degree in the graph, and must find a second vertex of odd degree. By the [[handshaking lemma]], such a vertex exists; finding one is a problem in [[NP (complexity)|NP]], but the problems that can be defined in this way may not necessarily be [[NP-complete]], as it is unknown whether PPA&amp;nbsp;=&amp;nbsp;NP. [[PPAD (complexity)|PPAD]] is an analogous class defined on implicit [[directed graph]]s that has attracted attention in [[algorithmic game theory]] because it contains the problem of computing a [[Nash equilibrium]].&lt;ref&gt;{{citation | first = Christos | last = Papadimitriou | authorlink = Christos Papadimitriou | year = 1994 | title = On the complexity of the parity argument and other inefficient proofs of existence | journal = [[Journal of Computer and System Sciences]] | volume = 48 | issue = 3 | pages = 498–532 | url = http://www.cs.berkeley.edu/~christos/papers/On%20the%20Complexity.pdf | doi = 10.1016/S0022-0000(05)80063-7}}&lt;/ref&gt; The problem of testing [[reachability]] of one vertex to another in an implicit graph may also be used to characterize space-bounded nondeterministic complexity classes including [[NL (complexity)|NL]] (the class of problems that may be characterized by reachability in implicit directed graphs whose vertices are {{math|O(log ''n'')}}-bit bitstrings), [[SL (complexity)|SL]] (the analogous class for undirected graphs), and [[PSPACE]] (the class of problems that may be characterized by reachability in implicit graphs with polynomial-length bitstrings). In this complexity-theoretic context, the vertices of an implicit graph may represent the states of a [[nondeterministic Turing machine]], and the edges may represent possible state transitions, but implicit graphs may also be used to represent many other types of combinatorial structure.&lt;ref&gt;{{citation|title=Descriptive Complexity|contribution=Exercise 3.7 (Everything is a Graph)|first=Neil|last=Immerman|authorlink=Neil Immerman|page=48|url=https://books.google.com/books?id=kWSZ0OWnupkC&amp;pg=PA48|series=Graduate Texts in Computer Science|year=1999|publisher=Springer-Verlag|isbn= 978-0-387-98600-5}}.&lt;/ref&gt; [[PLS (complexity)|PLS]], another complexity class, captures the complexity of finding local optima in an implicit graph.&lt;ref&gt;{{Citation | last1=Yannakakis | first1=Mihalis | author1-link=Mihalis Yannakakis | title=Equilibria, fixed points, and complexity classes | year=2009 | journal=Computer Science Review | volume=3 | issue=2 | pages=71–85 | doi=10.1016/j.cosrev.2009.03.004| arxiv=0802.2831 }}.&lt;/ref&gt;

Implicit graph models have also been used as a form of [[relativization]] in order to prove separations between complexity classes that are stronger than the known separations for non-relativized models. For instance, Childs et al. used neighborhood representations of implicit graphs to define a graph traversal problem that can be solved in polynomial time on a [[quantum computer]] but that requires exponential time to solve on any classical computer.&lt;ref&gt;{{citation
 | last1 = Childs | first1 = Andrew M.
 | last2 = Cleve | first2 = Richard
 | last3 = Deotto | first3 = Enrico
 | last4 = Farhi | first4 = Edward
 | last5 = Gutmann | first5 = Sam
 | last6 = Spielman | first6 = Daniel A.
 | contribution = Exponential algorithmic speedup by a quantum walk
 | doi = 10.1145/780542.780552
 | location = New York
 | mr = 2121062
 | pages = 59–68
 | publisher = ACM
 | title = [[Symposium on Theory of Computing|Proceedings of the Thirty-Fifth Annual ACM Symposium on Theory of Computing]]
 | year = 2003| arxiv = quant-ph/0209131}}.&lt;/ref&gt;

==Adjacency labeling schemes==
In the context of efficient representations of graphs, J. H. Muller defined a ''local structure'' or ''adjacency labeling scheme'' for a graph {{mvar|G}} in a given family {{mvar|F}} of graphs to be an assignment of an {{math|''O''(log ''n'')}}-bit identifier to each vertex of {{mvar|G}}, together with an algorithm (that may depend on {{mvar|F}} but is independent of the individual graph {{mvar|G}}) that takes as input two vertex identifiers and determines whether or not they are the endpoints of an edge in {{mvar|G}}. That is, this type of implicit representation is analogous to an [[adjacency matrix]]: it is straightforward to check whether two vertices are adjacent but finding the neighbors of any vertex may involve looping through all vertices and testing which ones are neighbors.&lt;ref name="muller"&gt;{{citation
 | last = Muller | first = John Harold
 | publisher = Georgia Institute of Technology
 | series = Ph.D. thesis
 | title = Local structure in graph classes
 | year = 1988}}.&lt;/ref&gt;

Graph families with adjacency labeling schemes include:
;Bounded degree graphs: If every vertex in {{mvar|G}} has at most {{mvar|d}} neighbors, one may number the vertices of {{mvar|G}} from 1 to {{mvar|n}} and let the identifier for a vertex be the {{math|(''d'' + 1)}}-tuple of its own number and the numbers of its neighbors. Two vertices are adjacent when the first numbers in their identifiers appear later in the other vertex's identifier. More generally, the same approach can be used to provide an implicit representation for graphs with bounded [[arboricity]] or bounded [[degeneracy (graph theory)|degeneracy]], including the [[planar graph]]s and the graphs in any [[Robertson–Seymour theorem|minor-closed graph family]].&lt;ref name="knr"/&gt;&lt;ref&gt;{{citation
 | last1 = Chrobak | first1 = Marek
 | last2 = Eppstein | first2 = David | author2-link = David Eppstein
 | doi = 10.1016/0304-3975(91)90020-3
 | issue = 2
 | journal = [[Theoretical Computer Science (journal)|Theoretical Computer Science]]
 | pages = 243–266
 | title = Planar orientations with low out-degree and compaction of adjacency matrices
 | url = http://www.ics.uci.edu/~eppstein/pubs/ChrEpp-TCS-91.pdf
 | volume = 86
 | year = 1991}}.&lt;/ref&gt;
;Intersection graphs: An [[interval graph]] is the [[intersection graph]] of a set of [[line segment]]s in the [[real line]]. It may be given an adjacency labeling scheme in which the points that are endpoints of line segments are numbered from 1 to 2''n'' and each vertex of the graph is represented by the numbers of the two endpoints of its corresponding interval. With this representation, one may check whether two vertices are adjacent by comparing the numbers that represent them and verifying that these numbers define overlapping intervals. The same approach works for other geometric intersection graphs including the graphs of bounded [[boxicity]] and the [[circle graph]]s, and subfamilies of these families such as the [[distance-hereditary graph]]s and [[cograph]]s.&lt;ref name="knr"/&gt;&lt;ref name="spinrad"/&gt; However, a geometric intersection graph representation does not always imply the existence of an adjacency labeling scheme, because it may require more than a logarithmic number of bits to specify each geometric object. For instance, representing a graph as a [[unit disk graph]] may require exponentially many bits for the coordinates of the disk centers.&lt;ref&gt;{{citation|url=http://homepages.cwi.nl/~mueller/Papers/SphericityDotproduct.pdf|last1=Kang|first1=Ross J.|last2=Müller|first2=Tobias|title=Sphere and dot product representations of graphs|year=2011}}.&lt;/ref&gt;
;Low-dimensional comparability graphs: The [[comparability graph]] for a [[partially ordered set]] has a vertex for each set element and an edge between two set elements that are related by the partial order. The [[order dimension]] of a partial order is the minimum number of linear orders whose intersection is the given partial order. If a partial order has bounded order dimension, then an adjacency labeling scheme for the vertices in its comparability graph may be defined by labeling each vertex with its position in each of the defining linear orders, and determining that two vertices are adjacent if each corresponding pair of numbers in their labels has the same order relation as each other pair. In particular, this allows for an adjacency labeling scheme for the [[chordal graph|chordal]] [[comparability graph]]s, which come from partial orders of dimension at most four.&lt;ref&gt;{{citation
 | last1 = Ma | first1 = Tze Heng
 | last2 = Spinrad | first2 = Jeremy P.
 | doi = 10.1007/BF00385814
 | issue = 1
 | journal = [[Order (journal)|Order]]
 | mr = 1129614
 | pages = 49–61
 | title = Cycle-free partial orders and chordal comparability graphs
 | volume = 8
 | year = 1991}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last1 = Curtis | first1 = Andrew R.
 | last2 = Izurieta | first2 = Clemente
 | last3 = Joeris | first3 = Benson
 | last4 = Lundberg | first4 = Scott
 | last5 = McConnell | first5 = Ross M.
 | doi = 10.1016/j.dam.2010.01.005
 | issue = 8
 | journal = Discrete Applied Mathematics
 | mr = 2602811
 | pages = 869–875
 | title = An implicit representation of chordal comparability graphs in linear time
 | volume = 158
 | year = 2010}}.&lt;/ref&gt;

===The implicit graph conjecture===
{{unsolved|mathematics|Does every slowly-growing [[Hereditary property#In graph theory|hereditary family of graphs]] have an implicit representation?}}
Not all graph families have local structures. For some families, a simple counting argument proves that adjacency labeling schemes do not exist: only {{math|''O''(''n'' log ''n'')}} bits may be used to represent an entire graph, so a representation of this type can only exist when the number of {{mvar|n}}-vertex graphs in the given family {{mvar|F}} is at most {{math|2&lt;sup&gt;''O''(''n'' log ''n'')&lt;/sup&gt;}}. Graph families that have larger numbers of graphs than this, such as the [[bipartite graph]]s or the [[triangle-free graph]]s, do not have adjacency labeling schemes.&lt;ref name="knr"/&gt;&lt;ref name="spinrad"&gt;{{citation|first=Jeremy P.|last=Spinrad|title=Efficient Graph Representations|year=2003|isbn=0-8218-2815-0|chapter=2. Implicit graph representation|pages=17–30|url=https://books.google.com/books?id=RrtXSKMAmWgC&amp;pg=PA17}}.&lt;/ref&gt; However, even families of graphs in which the number of graphs in the family is small might not have an adjacency labeling scheme; for instance, the family of graphs with fewer edges than vertices has {{math|2&lt;sup&gt;''O''(''n'' log ''n'')&lt;/sup&gt;}} {{mvar|n}}-vertex graphs but does not have an adjacency labeling scheme, because one could transform any given graph into a larger graph in this family by adding a new isolated vertex for each edge, without changing its labelability.&lt;ref name="muller"/&gt;&lt;ref name="spinrad"/&gt; Kannan et al. asked whether having a [[Forbidden graph characterization|forbidden subgraph characterization]] and having at most  {{math|2&lt;sup&gt;''O''(''n'' log ''n'')&lt;/sup&gt;}} {{mvar|n}}-vertex graphs are together enough to guarantee the existence of an adjacency labeling scheme; this question, which Spinrad restated as a conjecture, remains open.&lt;ref name="knr"/&gt;&lt;ref name="spinrad"/&gt;
Among the families of graphs which satisfy the conditions of the conjecture and for which there is no known adjacency labeling scheme are the family of disk graphs and line segment intersection graphs.

===Labeling schemes and induced universal graphs===
If a graph family {{mvar|F}} has an adjacency labeling scheme, then the {{mvar|n}}-vertex graphs in {{mvar|F}} may be represented as [[induced subgraph]]s of a common induced [[universal graph]] of polynomial size, the graph consisting of all possible vertex identifiers. Conversely, if an induced universal graph of this type can be constructed, then the identities of its vertices may be used as labels in an adjacency labeling scheme.&lt;ref name="knr"&gt;{{citation
 | last1 = Kannan | first1 = Sampath
 | last2 = Naor | first2 = Moni | author2-link = Moni Naor
 | last3 = Rudich | first3 = Steven | author3-link = Steven Rudich
 | doi = 10.1137/0405049
 | issue = 4
 | journal = [[SIAM Journal on Discrete Mathematics]]
 | mr = 1186827
 | pages = 596–603
 | title = Implicit representation of graphs
 | volume = 5
 | year = 1992}}.&lt;/ref&gt; For this application of implicit graph representations, it is important that the labels use as few bits as possible, because the number of bits in the labels translates directly into the number of vertices in the induced universal graph. Alstrup and Rauhe showed that any tree has an adjacency labeling scheme with {{math|log&lt;sub&gt;2&lt;/sub&gt; ''n'' + ''O''({{log-star}} ''n'')}} bits per label, from which it follows that any graph with [[arboricity]] ''k'' has a scheme with {{math|''k'' log&lt;sub&gt;2&lt;/sub&gt; ''n'' + ''O''({{log-star}} ''n'')}} bits per label and a universal graph with {{math|''n''&lt;sup&gt;''k''&lt;/sup&gt;2&lt;sup&gt;''O''({{log-star}} ''n'')&lt;/sup&gt;}} vertices. In particular, planar graphs have arboricity at most three, so they have universal graphs with a nearly-cubic number of vertices.&lt;ref&gt;{{citation
 | last1 = Alstrup | first1 = Stephen
 | last2 = Rauhe | first2 = Theis
 | doi = 10.1109/SFCS.2002.1181882
 | journal = [[Symposium on Foundations of Computer Science|Proceedings of the 43rd Annual IEEE Symposium on Foundations of Computer Science]]
 | pages = 53–62
 | title = Small induced-universal graphs and compact implicit graph representations
 | url = http://www.it-c.dk/research/algorithms/Kurser/AD/2002E/Uge7/parent.pdf
 | year = 2002}}.&lt;/ref&gt;
This bound was improved by Gavoille and Labourel who showed that planar graphs and minor-closed graph families have a labeling scheme with {{math|2 log&lt;sub&gt;2&lt;/sub&gt; ''n'' + ''O''(log log ''n'')}}  bits per label, and that graphs of bounded [[treewidth]] have a labeling scheme with {{math|log&lt;sub&gt;2&lt;/sub&gt; ''n'' + ''O''(log log ''n'')}} bits per label.&lt;ref&gt;{{citation
 | last1 = Arnaud  | first1 = Labourel
 | last2 = Gavoille | first2 = Cyril
 | doi = 10.1007/978-3-540-75520-3_52
 | journal = [[European Symposium on Algorithms|Proceedings of the 15th annual European Symposium on Algorithms]]
 | pages = 582–593
 | title = Shorter Implicit Representation for Planar Graphs and Bounded Treewidth Graphs
 | url = http://dept-info.labri.fr/~gavoille/article/GL07.pdf
 | year = 2007}}.&lt;/ref&gt;

==Evasiveness==
The [[Aanderaa–Karp–Rosenberg conjecture]] concerns implicit graphs given as a set of labeled vertices with a black-box rule for determining whether any two vertices are adjacent. This definition differs from an adjacency labeling scheme in that the rule may be specific to a particular graph rather than being a generic rule that applies to all graphs in a family. Because of this difference, every graph has an implicit representation. For instance, the rule could be to look up the pair of vertices in a separate adjacency matrix. However, an algorithm that is given as input an implicit graph of this type must operate on it only through the implicit adjacency test, without reference to how the test is implemented.

A ''graph property'' is the question of whether a graph belongs to a given family of graphs; the answer must remain invariant under any relabeling of the vertices. In this context, the question to be determined is how many pairs of vertices must be tested for adjacency, in the worst case, before the property of interest can be determined to be true or false for a given implicit graph. Rivest and Vuillemin proved that any deterministic algorithm for any nontrivial graph property must test a quadratic number of pairs of vertices.&lt;ref&gt;{{Citation
| doi = 10.1145/800116.803747
| pages = 6&amp;ndash;11
| last1 = Rivest
| first1 = Ronald L.
| authorlink = Ron Rivest
| first2 = Jean | last2 = Vuillemin
| contribution = A generalization and proof of the Aanderaa-Rosenberg conjecture
| title = [[Symposium on Theory of Computing|Proc. 7th ACM Symposium on Theory of Computing]]
| location = Albuquerque, New Mexico, United States
| year = 1975
}}.&lt;/ref&gt; The full Aanderaa–Karp–Rosenberg conjecture is that any deterministic algorithm for a monotonic graph property (one that remains true if more edges are added to a graph with the property) must in some cases test every possible pair of vertices. Several cases of the conjecture have been proven to be true—for instance, it is known to be true for graphs with a prime number of vertices&lt;ref&gt;{{Citation
| publisher = IEEE Computer Society
| doi = 10.1109/SFCS.1983.4
| pages = 31&amp;ndash;33
| last1 = Kahn
| first1 = Jeff
| author2-link = Michael Saks (mathematician) | first2 = Michael | last2 = Saks
| first3 = Dean | last3 = Sturtevant
| contribution = A topological approach to evasiveness
| title = [[Symposium on Foundations of Computer Science]]
| location = Los Alamitos, CA, USA
| year = 1983
}}.&lt;/ref&gt;—but the full conjecture remains open. Variants of the problem for randomized algorithms and quantum algorithms have also been studied.

Bender and Ron have shown that, in the same model used for the evasiveness conjecture, it is possible in only constant time to distinguish [[directed acyclic graph]]s from graphs that are very far from being acyclic. In contrast, such a fast time is not possible in neighborhood-based implicit graph models,&lt;ref&gt;{{citation
 | last1 = Bender | first1 = Michael A.
 | last2 = Ron | first2 = Dana | author2-link = Dana Ron
 | contribution = Testing acyclicity of directed graphs in sublinear time
 | doi = 10.1007/3-540-45022-X_68
 | location = Berlin
 | mr = 1795937
 | pages = 809–820
 | publisher = Springer
 | series = Lecture Notes in Comput. Sci.
 | title = Automata, languages and programming (Geneva, 2000)
 | volume = 1853
 | year = 2000}}.&lt;/ref&gt;

==See also==
*[[Black box group]], an implicit model for [[group theory|group-theoretic]] algorithms
*[[Matroid oracle]], an implicit model for [[matroid]] algorithms

==References==
{{reflist|colwidth=30em}}

[[Category:Graph theory]]
[[Category:Graph data structures]]</text>
      <sha1>klko438tsfrxw89nxg15opaz1uyy3xn</sha1>
    </revision>
  </page>
  <page>
    <title>Interfaces (journal)</title>
    <ns>0</ns>
    <id>18006921</id>
    <revision>
      <id>840609905</id>
      <parentid>828309708</parentid>
      <timestamp>2018-05-10T23:43:36Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* top */remove deprecated |bypass-rcheck from infobox journal ([[Wikipedia:Bots/Requests for approval/JCW-CleanerBot 4|BRFA]]) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1745">{{Infobox journal
| title = Interfaces
| cover = Cover Interfaces.gif
| abbreviation = Interfaces
| discipline = [[Operations research]]
| editor = Srinivas Bollapragada
| publisher = [[Institute for Operations Research and the Management Sciences|INFORMS]]
| country =
| frequency = Bimonthly
| history = 1970-present
| impact = 0.443
| impact-year = 2013
| website = http://pubsonline.informs.org/journal/inte
| link1 = http://pubsonline.informs.org/toc/inte/current
| link1-name = Online access
| link2 = http://pubsonline.informs.org/loi/inte
| link2-name = Online archive
| eISSN = 1526-551X
| ISSN = 0092-2102
| OCLC = 781448734
| LCCN = 74646164
}}
'''''Interfaces''''' is a bimonthly [[peer-reviewed]] [[academic journal]] about [[operations research]] that was established by The Institute of Management Sciences, now part of the [[Institute for Operations Research and the Management Sciences]]. The journal's distinguishing feature is its case-study style: It offers examples of how operations research theory has been applied in businesses and organizations.&lt;ref&gt;[http://portal.acm.org/citation.cfm?id=1245500 ACM Portal: The Guide to Computing Literature]&lt;/ref&gt;

An annual feature is an issue with papers by the previous year's [[Franz Edelman Award]] participants.&lt;ref&gt;[http://www.afmc.af.mil/news/story.asp?id=123019962 Air Force Materiel Command]&lt;/ref&gt;

== References ==
{{reflist}}

== External links ==
* {{Official website|http://interfaces.pubs.informs.org/}}

[[Category:Business and management journals]]
[[Category:Bimonthly journals]]
[[Category:INFORMS academic journals]]
[[Category:English-language journals]]
[[Category:Publications established in 1970]]
[[Category:Operations research]]


{{management-journal-stub}}</text>
      <sha1>fe7jqacmbpptu0wy89r6tmb9na3mcno</sha1>
    </revision>
  </page>
  <page>
    <title>Intertemporal CAPM</title>
    <ns>0</ns>
    <id>7634908</id>
    <revision>
      <id>870564091</id>
      <parentid>868857174</parentid>
      <timestamp>2018-11-25T17:28:38Z</timestamp>
      <contributor>
        <ip>203.110.242.23</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5363">{{multiple issues|
{{Context|date=October 2009}}
{{Refimprove|date=August 2014}}
}}

The '''Intertemporal Capital Asset Pricing Model''', or '''ICAPM''', is an alternative to the [[Capital Asset Pricing Model|CAPM]] provided by [[Robert C. Merton|Robert Merton]].  It is a linear factor model with wealth as state variable that forecast changes in the distribution of future [[Return (finance)|returns]] or [[income]].

In the ICAPM investors are solving lifetime consumption decisions when faced with more than one uncertainty. The main difference between ICAPM and standard CAPM is the additional state variables that acknowledge the fact that [[investors]] hedge against shortfalls in consumption or against changes in the future [[investment]] opportunity set.

==Continuous time version==
[[Robert C. Merton|Merton]]&lt;ref&gt;{{cite journal |first=Robert |last=Merton|title= An Intertemporal Capital Asset Pricing Model |journal= Econometrica|date=1973|pages=867–887|jstor=1913811|volume=41|issue=5 |doi=10.2307/1913811}}&lt;/ref&gt; considers a continuous time market in equilibrium.
The state variable (X) follows a [[Wiener process|brownian motion]]:
:&lt;math&gt; dX = \mu dt + s dZ &lt;/math&gt;
The investor maximizes his  [[Von Neumann–Morgenstern utility theorem|Von Neumann–Morgenstern utility]]:
:&lt;math&gt;E_o \left\{\int_o^T U[C(t),t]dt + B[W(T),T] \right\} &lt;/math&gt;
where T is the time horizon and B[W(T),T] the utility from wealth (W).

The investor has the following constraint on wealth (W). 
Let &lt;math&gt; w_i &lt;/math&gt; be the weight invested in the asset i. Then:
:&lt;math&gt; W(t+dt) = [W(t) -C(t) dt]\sum_{i=0}^n w_i[1+ r_i(t+ dt)] &lt;/math&gt;
where &lt;math&gt; r_i &lt;/math&gt; is the return on asset i.
The change in wealth is:
:&lt;math&gt; dW=-C(t)dt +[W(t)-C(t)dt]\sum w_i(t)r_i(t+dt) &lt;/math&gt;

We can use [[dynamic programming]] to solve the problem. For instance, if we consider a series of discrete time problems:
:&lt;math&gt;\max E_0 \left\{\sum_{t=0}^{T-dt}\int_t^{t+dt} U[C(s),s]ds + B[W(T),T] \right\} &lt;/math&gt;
Then, a [[Taylor series|Taylor expansion]] gives:
:&lt;math&gt; \int_t^{t+dt}U[C(s),s]ds= U[C(t),t]dt + \frac{1}{2} U_t [C(t^*),t^*]dt^2 \approx U[C(t),t]dt &lt;/math&gt;
where &lt;math&gt;t^*&lt;/math&gt; is a value between t and t+dt.

Assuming that returns follow a [[Wiener Process|brownian motion]]:
:&lt;math&gt; r_i(t+dt) = \alpha_i dt + \sigma_i dz_i&lt;/math&gt;
with:
:&lt;math&gt; E(r_i) = \alpha_i dt \quad ;\quad E(r_i^2)=var(r_i)=\sigma_i^2dt \quad ;\quad cov(r_i,r_j) = \sigma_{ij}dt &lt;/math&gt;
Then canceling out terms of second and higher order:
:&lt;math&gt; dW \approx [W(t) \sum w_i \alpha_i - C(t)]dt+W(t) \sum w_i \sigma_i dz_i&lt;/math&gt;

Using [[optimal control|Bellman equation]], we can restate the problem:
:&lt;math&gt; J(W,X,t) = max \; E_t\left\{\int_t^{t+dt} U[C(s),s]ds + J[W(t+dt),X(t+dt),t+dt]\right\}&lt;/math&gt;
subject to the wealth constraint previously stated.

Using [[Ito's lemma]] we can rewrite:
:&lt;math&gt; dJ = J[W(t+dt),X(t+dt),t+dt]-J[W(t),X(t),t+dt]= J_t dt + J_W dW + J_X dX + \frac{1}{2}J_{XX} dX^2 + \frac{1}{2}J_{WW} dW^2 + J_{WX} dX dW&lt;/math&gt;
and the expected value:
:&lt;math&gt; E_t J[W(t+dt),X(t+dt),t+dt]=J[W(t),X(t),t]+J_t dt + J_W E[dW]+ J_X E(dX) + \frac{1}{2} J_{XX} var(dX)+\frac{1}{2} J_{WW} var[dW] + J_{WX} cov(dX,dW)&lt;/math&gt;
After some algebra&lt;ref&gt;:&lt;math&gt; E(dW)=-C(t)dt + W(t) \sum w_i(t) \alpha_i dt &lt;/math&gt;
:&lt;math&gt; var(dW) = [W(t)-C(t)dt]^2 var[ \sum w_i(t)r_i(t+dt)]= W(t)^2 \sum_{i=1} \sum_{i=1} w_i w_j \sigma_{ij} dt &lt;/math&gt;
:&lt;math&gt; \sum_{i=o}^n w_i(t) \alpha_i = \sum_{i=1}^n w_i(t)[\alpha_i - r_f] + r_f &lt;/math&gt;&lt;/ref&gt;
, we have the following objective function:
:&lt;math&gt; max \left\{ U(C,t) + J_t + J_W W [\sum_{i=1}^n w_i(\alpha_i-r_f)+r_f] - J_WC + \frac{W^2}{2} J_{WW}\sum_{i=1}^n\sum_{j=1}^n w_i w_j \sigma_{ij} + J_X \mu + \frac{1}{2}J_{XX} s^2 + J_{WX} W \sum_{i=1}^n w_i \sigma_{iX} \right\} &lt;/math&gt;
where &lt;math&gt;r_f&lt;/math&gt; is the risk-free return.
First order conditions are:
:&lt;math&gt; J_W(\alpha_i-r_f)+J_{WW}W \sum_{j=1}^n w^*_j \sigma_{ij} + J_{WX} \sigma_{iX}=0 \quad i=1,2,\ldots,n&lt;/math&gt;
In matrix form, we have:
:&lt;math&gt; (\alpha - r_f {\mathbf 1}) = \frac{-J_{WW}}{J_W} \Omega w^* W + \frac{-J_{WX}}{J_W} cov_{rX} &lt;/math&gt;
where &lt;math&gt;\alpha&lt;/math&gt; is the vector of expected returns, &lt;math&gt; \Omega &lt;/math&gt; the [[covariance|covariance matrix]] of returns, &lt;math&gt; {\mathbf 1}&lt;/math&gt; a unity vector &lt;math&gt; cov_{rX} &lt;/math&gt; the covariance between returns and the state variable. The optimal weights are:
:&lt;math&gt; {\mathbf w^*} = \frac{-J_W}{J_{WW} W}\Omega^{-1}(\alpha - r_f {\mathbf 1}) - \frac{J_{WX}}{J_{WW}W}\Omega^{-1} cov_{rX}&lt;/math&gt;
Notice that the intertemporal model provides the same weights of the [[Capital asset pricing model|CAPM]]. Expected returns can be expressed as follows:
:&lt;math&gt; \alpha_i = r_f + \beta_{im} (\alpha_m - r_f) + \beta_{ih}(\alpha_h - r_f)&lt;/math&gt;
where m is the market portfolio and h a portfolio to hedge the state variable.

==See also==

*[[Intertemporal portfolio choice]]

==References==
{{Reflist}}
* Merton, R.C., (1973), An Intertemporal Capital Asset Pricing Model. Econometrica 41, Vol. 41, No. 5. (Sep., 1973), pp.&amp;nbsp;867–887
* "Multifactor Portfolio Efficiency and Multifactor Asset Pricing" by Eugene F. Fama, (''The Journal of Financial and Quantitative Analysis''), Vol. 31, No. 4, Dec., 1996

[[Category:Mathematical finance]]
[[Category:Finance theories]]
[[Category:Financial economics]]
[[Category:Financial models]]</text>
      <sha1>8kw4kfgp37wj8q8tn5t3q85oc0pqh4z</sha1>
    </revision>
  </page>
  <page>
    <title>Journal of Mathematical Analysis and Applications</title>
    <ns>0</ns>
    <id>54943204</id>
    <revision>
      <id>796018254</id>
      <timestamp>2017-08-17T23:30:21Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>New article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1132">{{italic title}}
The '''''Journal of Mathematical Analysis and Applications''''' ({{ISSN|1096-0813}}) is an [[academic journal]] in mathematics, specializing in [[mathematical analysis]] and related topics in [[applied mathematics]]. It was founded in 1960, as part of a series of new journals on areas of mathematics published by [[Academic Press]],&lt;ref&gt;{{citation|title=Encyclopedia of Library and Information Science|edition=2nd|volume=3|editor-first=Miriam|editor-last=Drake|publisher=CRC Press|year=2003|isbn=9780824720797|page=1812|url=https://books.google.com/books?id=Sqr-_3FBYiYC&amp;pg=PA1812}}&lt;/ref&gt; and is now published by [[Elsevier]]. For most years since 1997 it has been ranked by [[SCImago Journal Rank]] as among the top 50% of journals in its topic areas.&lt;ref&gt;[http://www.scimagojr.com/journalsearch.php?q=23935&amp;tip=sid SCImagoJR report on the ''Journal of Mathematical Analysis and Applications''], retrieved 2017-08-17&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Elsevier academic journals]]
[[Category:Mathematics journals]]
[[Category:Mathematical analysis]]


{{mathematics-journal-stub}}
{{mathanalysis-stub}}</text>
      <sha1>jtndbf2mkwfrnvucqrb7mqplzdbrnkk</sha1>
    </revision>
  </page>
  <page>
    <title>Kawasaki's Riemann–Roch formula</title>
    <ns>0</ns>
    <id>44340383</id>
    <revision>
      <id>832600356</id>
      <parentid>832600191</parentid>
      <timestamp>2018-03-26T23:13:43Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <comment>/* top */ another link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="722">In [[differential geometry]], '''Kawasaki's Riemann–Roch formula''', introduced by Tetsuro Kawasaki, is the [[Riemann–Roch formula]] for [[orbifold]]s. It can compute the [[Euler characteristic of an orbifold]].

Kawasaki's original proof made a use of the [[equivariant index theorem]]. Today, the formula is known to follow from the [[Riemann–Roch formula for stacks|Riemann–Roch formula]] for [[quotient stack]]s.

== References ==
*Tetsuro Kawasaki. The Riemann-Roch theorem for complex V-manifolds. Osaka J. Math., 16(1):151–159, 1979

{{DEFAULTSORT:Kawasaki's Riemann-Roch formula}}
[[Category:Theorems in differential geometry]]
[[Category:Theorems in algebraic geometry]]


{{differential-geometry-stub}}</text>
      <sha1>ghlc6gfaj42umm240rk9s82zbxkflfg</sha1>
    </revision>
  </page>
  <page>
    <title>König's theorem (set theory)</title>
    <ns>0</ns>
    <id>184082</id>
    <revision>
      <id>842508062</id>
      <parentid>837425920</parentid>
      <timestamp>2018-05-22T22:23:31Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Jean E. Rubin]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7393">{{other uses|König's theorem (disambiguation){{!}}König's theorem}}

In [[set theory]], '''König's theorem'''  states that if the [[axiom of choice]] holds, ''I'' is a [[Set (mathematics)|set]], &lt;math&gt;\kappa_i&lt;/math&gt; and &lt;math&gt;\lambda_i&lt;/math&gt; are [[cardinal number]]s for every ''i'' in ''I'', and &lt;math&gt;\kappa_i &lt; \lambda_i&lt;/math&gt; for every ''i'' in ''I'', then 
:&lt;math&gt;\sum_{i \in I}\kappa_i &lt; \prod_{i \in I}\lambda_i.&lt;/math&gt;

The ''sum'' here is the cardinality of the [[disjoint union]] of the sets ''m&lt;sub&gt;i&lt;/sub&gt;'', and the product is the cardinality of the [[Cartesian product]]. However, without the use of the axiom of choice, the sum and the product cannot be defined as cardinal numbers, and the meaning of the inequality sign would need to be clarified.

König's theorem was introduced by {{harvs|txt|last=König|authorlink=Gyula Kőnig|year=1904}} in the slightly weaker form that the sum of a strictly increasing sequence of nonzero cardinal numbers is less than their product.

== Details ==

The precise statement of the result:  if ''I'' is a [[Set (mathematics)|set]], ''A&lt;sub&gt;i&lt;/sub&gt;'' and ''B&lt;sub&gt;i&lt;/sub&gt;'' are sets for every ''i'' in ''I'', and &lt;math&gt;A_i&lt;B_i&lt;/math&gt; for every ''i'' in ''I'', then 
:&lt;math&gt;\sum_{i \in I}A_i &lt; \prod_{i \in I}B_i,&lt;/math&gt;
where '''&lt;''' means ''strictly less than in [[cardinality]]'', i.e. there is an [[injective]] [[function (mathematics)|function]] from ''A&lt;sub&gt;i&lt;/sub&gt;'' to ''B&lt;sub&gt;i&lt;/sub&gt;'', but not one going the other way. The union involved need not be disjoint (a non-disjoint union can't be any bigger than the disjoint version, also assuming the [[axiom of choice]]).  In this formulation, '''König's theorem''' is equivalent to the [[axiom of choice]].&lt;ref name="Rubin 1985"&gt;{{cite book|last=Rubin|first=H.|author2=Rubin, J. E.|author2-link= Jean E. Rubin |title=Equivalents of the Axiom of Choice, II|publisher=[[North-Holland Publishing Company|North Holland]]|place=New York, NY|year=1985|pages=185|isbn=0-444-87708-8}}&lt;/ref&gt;

(Of course, König's theorem is trivial if the cardinal numbers ''m&lt;sub&gt;i&lt;/sub&gt;'' and ''n&lt;sub&gt;i&lt;/sub&gt;'' are [[finite set|finite]] and the index set ''I'' is finite. If ''I'' is [[empty set|empty]], then the left sum is the empty sum and therefore 0, while the right product is the [[empty product]] and therefore 1).

König's theorem is remarkable because of the strict inequality in the conclusion.  There are many easy rules for the arithmetic of infinite sums and products of cardinals in which one can only conclude a weak inequality ≤, for example:  if &lt;math&gt;m_i &lt; n_i&lt;/math&gt; for all ''i'' in ''I'', then one can only conclude
:&lt;math&gt;\sum_{i \in I} m_i \le \sum_{i \in I} n_i,&lt;/math&gt;
since, for example, setting &lt;math&gt;m_i = 1&lt;/math&gt; and &lt;math&gt;n_i = 2&lt;/math&gt;, where the index set ''I'' is the natural numbers, yields the sum &lt;math&gt;\aleph_0&lt;/math&gt; for both sides, and we have a strict equality.

==Corollaries of König's theorem==
* If &lt;math&gt;\kappa&lt;/math&gt; is a cardinal, then &lt;math&gt;\kappa &lt; 2^\kappa&lt;/math&gt;.
If we take ''m&lt;sub&gt;i&lt;/sub&gt;'' = 1, and ''n&lt;sub&gt;i&lt;/sub&gt;'' = 2 for each ''i'' in κ, then the left side of the above inequality is just κ, while the right side is 2&lt;sup&gt;κ&lt;/sup&gt;, the cardinality of functions from κ to {0, 1}, that is, the cardinality of the power set of κ. Thus, König's theorem gives us an alternate proof of [[Cantor's theorem]]. (Historically of course Cantor's theorem was proved much earlier.)

===Axiom of choice===
One way of stating the axiom of choice is "an arbitrary Cartesian product of non-empty sets is non-empty". Let ''B&lt;sub&gt;i&lt;/sub&gt;'' be a non-empty set for each ''i'' in ''I''. Let ''A&lt;sub&gt;i&lt;/sub&gt;'' = {} for each ''i'' in ''I''. Thus by König's theorem, we have:
* If &lt;math&gt;\forall i \in I(\{\} &lt; B_i)&lt;/math&gt;, then &lt;math&gt;\{\} &lt; \prod_{i \in I}B_i&lt;/math&gt;.
That is, the Cartesian product of the given non-empty sets ''B&lt;sub&gt;i&lt;/sub&gt;'' has a larger cardinality than the sum of empty sets. Thus it is non-empty, which is just what the axiom of choice states. Since the axiom of choice follows from König's theorem, we will use the axiom of choice freely and implicitly when discussing consequences of the theorem.

===König's theorem and cofinality===
König's theorem has also important consequences for [[cofinality]] of cardinal numbers.

* If &lt;math&gt;\kappa \ge \aleph_0&lt;/math&gt;, then &lt;math&gt;\kappa &lt; \kappa^{\operatorname{cf}(\kappa)}&lt;/math&gt;.

Choose a strictly increasing cf(κ)-sequence of ordinals approaching κ. Each of them is less than κ, so their sum, which is κ, is less than the product of cf(κ) copies of κ.

According to [[Easton's theorem]], the next consequence of König's theorem is the only nontrivial constraint on the continuum function for [[regular cardinal]]s.
* If &lt;math&gt;\kappa \geq \aleph_0&lt;/math&gt; and &lt;math&gt;\lambda \geq 2&lt;/math&gt;, then &lt;math&gt;\kappa &lt; \operatorname{cf}(\lambda^\kappa)&lt;/math&gt;.
Let &lt;math&gt;\mu = \lambda^\kappa&lt;/math&gt;. Suppose that, contrary to this corollary, &lt;math&gt;\kappa \ge \operatorname{cf}(\mu)&lt;/math&gt;. Then using the previous corollary, &lt;math&gt;\mu &lt; \mu^{\operatorname{cf}(\mu)} \le \mu^\kappa = (\lambda^\kappa)^\kappa = \lambda^{\kappa \cdot \kappa} = \lambda^\kappa = \mu&lt;/math&gt;, a contradiction. Thus the supposition must be false, and this corollary must be true.

==A proof of König's theorem==
Assuming [[Zermelo–Fraenkel set theory]], including especially the [[axiom of choice]], we can prove the theorem. Remember that we are given &lt;math&gt;\forall i\in I\quad A_i&lt;B_i&lt;/math&gt;, and we want to show :&lt;math&gt;\sum_{i\in I}A_i&lt;\prod_{i\in I}B_i.&lt;/math&gt;

The axiom of choice implies that the condition ''A'' &lt; ''B'' is equivalent to the condition that there is no function from ''A'' onto ''B'' and ''B'' is nonempty.
So we are given that there is no function from ''A''&lt;sub&gt;''i''&lt;/sub&gt; onto ''B''&lt;sub&gt;''i''&lt;/sub&gt;≠{}, and we have to show that any function ''f'' from the disjoint union of the ''A''s to the product of the ''B''s is not surjective and that the product is nonempty. That the product is nonempty follows immediately from the axiom of choice and the fact that the factors are nonempty. For each ''i'' choose a ''b''&lt;sub&gt;''i''&lt;/sub&gt; in ''B''&lt;sub&gt;''i''&lt;/sub&gt; not in the image of ''A''&lt;sub&gt;''i''&lt;/sub&gt; under the composition of ''f'' with the projection to ''B''&lt;sub&gt;''i''&lt;/sub&gt;. Then the product of the elements ''b''&lt;sub&gt;''i''&lt;/sub&gt; is not in the image of ''f'', so ''f'' does not map the disjoint union of the ''A''s onto the product of the ''B''s.

==Notes==
&lt;references/&gt;

==References==
* {{cite book | author=M. Holz, K. Steffens and E. Weitz | title=Introduction to Cardinal Arithmetic | publisher=Birkhäuser | year=1999 | isbn=3-7643-6124-7}}
* {{citation
|year=1904|pages= 144–147
|title=Verhandlungen des dritten Internationalen Mathematiker-Kongresses in Heidelberg vom 8. bis 13. August 1904
|chapter=Zum Kontinuum-Problem
|first=J.|last= König|url=http://ada00.math.uni-bielefeld.de/ICM/ICM1904/
|editor-first=Adolf|editor-last=Krazer}}, reprinted as {{citation|journal=Mathematische Annalen
|year=1905|volume= 60|issue =2|pages= 177–180
|title=Zum Kontinuum-Problem
|first=J.|last= König|doi=10.1007/BF01677263|url=http://archiv.ub.uni-heidelberg.de/volltextserver/12583/}}

{{DEFAULTSORT:Konigs theorem}}
[[Category:Axiom of choice]]
[[Category:Theorems in the foundations of mathematics]]
[[Category:Cardinal numbers]]
[[Category:Articles containing proofs]]</text>
      <sha1>0q92zaut2h317vri5eikgjlhmjkqo08</sha1>
    </revision>
  </page>
  <page>
    <title>Lehmer mean</title>
    <ns>0</ns>
    <id>7422265</id>
    <revision>
      <id>846941602</id>
      <parentid>846941124</parentid>
      <timestamp>2018-06-21T20:57:45Z</timestamp>
      <contributor>
        <ip>178.16.5.186</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4123">In mathematics, the '''Lehmer mean''' of a [[tuple]] &lt;math&gt;x&lt;/math&gt; of positive [[real number]]s, named after [[Derrick Henry Lehmer]],&lt;ref&gt;P. S. Bullen. ''Handbook of means and their inequalities''. Springer, 1987.&lt;/ref&gt; is defined as:
:&lt;math&gt;L_p(\mathbf{x}) = \frac{\sum_{k=1}^n x_k^p}{\sum_{k=1}^n x_k^{p-1}}.&lt;/math&gt;

The '''weighted Lehmer mean''' with respect to a tuple &lt;math&gt;w&lt;/math&gt; of positive weights is defined as:
:&lt;math&gt;L_{p,w}(\mathbf{x}) = \frac{\sum_{k=1}^n w_k\cdot x_k^p}{\sum_{k=1}^n w_k\cdot x_k^{p-1}}.&lt;/math&gt;

The Lehmer mean is an alternative to [[power mean]]s
for [[Interpolation|interpolating]] between [[minimum]] and [[maximum]] via [[arithmetic mean]] and [[harmonic mean]].

== Properties ==

The derivative of &lt;math&gt;p \mapsto L_p(\mathbf{x})&lt;/math&gt; is non-negative
:&lt;math&gt;
  \frac{\partial}{\partial p} L_p(\mathbf{x}) =
  \frac
    {\left(\sum_{j=1}^n \sum_{k=j+1}^n
         \left[x_j - x_k\right] \cdot \left[\ln(x_j) - \ln(x_k)\right] \cdot \left[x_j \cdot x_k\right]^{p-1}\right)}
    {\left(\sum_{k=1}^n x_k^{p-1}\right)^2},
&lt;/math&gt;

thus this function is monotonic and the inequality
:&lt;math&gt;p \le q \Longrightarrow L_p(\mathbf{x}) \le L_q(\mathbf{x})&lt;/math&gt;

holds.

==Special cases==

*&lt;math&gt;\lim_{p \to -\infty} L_p(\mathbf{x})&lt;/math&gt; is the [[minimum]] of the elements of &lt;math&gt;\mathbf{x}&lt;/math&gt;.
*&lt;math&gt;L_0(\mathbf{x})&lt;/math&gt; is the [[harmonic mean]].
*&lt;math&gt;L_\frac{1}{2}\left((x_0, x_1)\right)&lt;/math&gt; is the [[geometric mean]] of the two values &lt;math&gt;x_0&lt;/math&gt; and &lt;math&gt;x_1&lt;/math&gt;.
*&lt;math&gt;L_1(\mathbf{x})&lt;/math&gt; is the [[arithmetic mean]].
*&lt;math&gt;L_2(\mathbf{x})&lt;/math&gt; is the [[contraharmonic mean]].
*&lt;math&gt;\lim_{p \to \infty} L_p(\mathbf{x})&lt;/math&gt; is the [[maximum]] of the elements of &lt;math&gt;\mathbf{x}&lt;/math&gt;.
:Sketch of a proof: [[Without loss of generality]] let &lt;math&gt;x_1,\dots,x_k&lt;/math&gt; be the values which equal the maximum. Then &lt;math&gt;L_p(\mathbf{x}) = x_1\cdot\frac{k + \left(\frac{x_{k+1}}{x_1}\right)^p + \cdots + \left(\frac{x_n}{x_1}\right)^p}{k + \left(\frac{x_{k+1}}{x_1}\right)^{p-1} + \cdots + \left(\frac{x_n}{x_1}\right)^{p-1}}&lt;/math&gt;

== Applications ==

===Signal processing===
Like a [[power mean]],
a Lehmer mean serves a non-linear [[moving average]] which is shifted towards small signal values for small &lt;math&gt;p&lt;/math&gt; and emphasizes big signal values for big &lt;math&gt;p&lt;/math&gt;. Given an efficient implementation of a [[lowpass|moving arithmetic mean]] called &lt;tt&gt;smooth&lt;/tt&gt; you can implement a moving Lehmer mean according to the following [[Haskell (programming language)|Haskell]] code.

&lt;source lang="haskell"&gt;
 lehmerSmooth :: Floating a =&gt; ([a] -&gt; [a]) -&gt; a -&gt; [a] -&gt; [a]
 lehmerSmooth smooth p xs = zipWith (/)
                                     (smooth (map (**p) xs))
                                     (smooth (map (**(p-1)) xs))
&lt;/source&gt;

* For big &lt;math&gt;p&lt;/math&gt; it can serve an [[envelope detector]] on a [[rectifier|rectified]] signal.
* For small &lt;math&gt;p&lt;/math&gt; it can serve an [[Baseline (spectrometry)|baseline detector]] on a [[mass spectrum]].

Gonzalez and Woods call this a "contraharmonic mean [[filter (signal processing)|filter]]" described for varying values of ''p'' (however, as above, the [[contraharmonic mean]] can refer to the specific case &lt;math&gt;p = 2&lt;/math&gt;). Their convention is to substitute ''p'' with the order of the filter ''Q'':

:&lt;math&gt;f(x) = \frac{\sum_{k=1}^n x_k^{Q+1}}{\sum_{k=1}^n x_k^Q}.&lt;/math&gt;

''Q''=0 is the arithmetic mean. Positive ''Q'' can reduce [[salt-and-pepper noise|pepper noise]] and negative ''Q'' can reduce [[salt-and-pepper noise|salt noise]].&lt;ref&gt;{{cite book |title=Digital Image Processing |edition=3 |last1=Gonzalez |first1=Rafael C. |last2=Woods |first2=Richard E. |date=2008 |chapter=Chapter 5 Image Restoration and Reconstruction |isbn=9780131687288 |publisher=Prentice Hall |url=http://www.imageprocessingplace.com/DIP-3E/dip3e_main_page.htm}}&lt;/ref&gt;

==See also==
*[[mean]]
*[[power mean]]

==Notes==
{{reflist}}

==External links==
*[http://mathworld.wolfram.com/LehmerMean.html Lehmer Mean at MathWorld]

[[Category:Means]]
[[Category:Articles with example Haskell code]]</text>
      <sha1>2oawr34v8kkunyonzzow9cjmuojgo78</sha1>
    </revision>
  </page>
  <page>
    <title>Liability-driven investment strategy</title>
    <ns>0</ns>
    <id>8351939</id>
    <revision>
      <id>845896054</id>
      <parentid>845896044</parentid>
      <timestamp>2018-06-14T21:26:48Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/2A00:23C4:8B1A:4400:E0D6:36CD:AE7B:560C|2A00:23C4:8B1A:4400:E0D6:36CD:AE7B:560C]] to version by Shyamsunder. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3408182) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5734">{{dablink|For other uses of LDI see [[LDI (disambiguation)]]}}

'''Liability-driven''' investment policies and [[asset management]] decisions are those largely determined by the sum of current and future liabilities attached to the investor, be it a household or an institution. As it purports to associate constantly both sides of the [[balance sheet]] in the investment process, it has been called a "holistic" investment methodology. 

In essence, the '''liability-driven investment strategy''' ('''LDI''') is an [[investment strategy]] of a company or individual based on the cash flows needed to fund future liabilities. It is sometimes referred to as a "[[Dedicated Portfolio Theory|dedicated portfolio]]" strategy. It differs from a “benchmark-driven” strategy, which is based on achieving better returns than an external [[Stock market index|index]] such as the S&amp;P 500 or a combination of indices that invest in the same types of asset classes. LDI is designed for situations where future liabilities can be predicted with some degree of accuracy. For individuals, the classic example would be the stream of withdrawals from a retirement portfolio that a retiree will make to pay living expenses from the date of retirement to the date of death. For companies, the classic example would be a [[pension fund]] that must make future payouts to pensioners over their expected lifetimes (see below).

== LDI for individuals ==

A retiree following an LDI strategy begins by estimating the income needed each year in the future. Social security payments and any other income is subtracted from the income needed to determine how much will have to be withdrawn each year from the money in the retirement portfolio to meet the income need. These withdrawals become the liabilities that the investment strategy targets. The portfolio must be invested so as to provide the cash flows that match the withdrawals each year, after factoring in adjustments for inflation, irregular spending (such as an ocean cruise every other year), and so on. Individual bonds provide the ability to match the cash flows needed, which is why the term "[[cash flow matching]]" is sometimes used to describe this strategy. Because the bonds are dedicated to providing the cash flows, the term "[[Dedicated Portfolio Theory|dedicated portfolio]]" or “asset dedication” is sometimes used to describe the strategy.

== LDI for pension funds ==

A [[pension fund]] following an LDI strategy focuses on the pension-fund assets in the context of the promises made to employees and pensioners ([[liability (financial accounting)|liabilities]]). This is in contrast to an approach which focuses purely on the asset side of the pension fund [[balance sheet]]. There is no single accepted definition or approach to LDI and different managers apply different approaches.&lt;ref&gt;Lemke and Lins, ''ERISA for Money Managers'' §2:64 (Thomson West, 2013).&lt;/ref&gt; Typical LDI strategies involve [[hedge (finance)|hedging]], in whole or in part, the fund's exposure to changes in [[interest rate]]s and [[inflation]]. These risks can eat into a pension scheme's ability to keep their promises to members. Historically, [[Bond (finance)|bonds]] were used as a partial hedge for these interest rate risks but the recent growth in LDI has focused on using [[Swap (finance)|swaps]] and other [[Derivative (finance)|derivatives]].&lt;ref name="ai"&gt;[http://www.ai-cio.com/channel/REGULATION,_LEGAL/LDI_2_0.html] LDI 2.0, aiCIO Magazine, March 2011&lt;/ref&gt; Various approaches will pursue a "glide path" which over time seeks to reduce interest rate and other risks while achieving a return that matches or exceeds the growth in projected pension plan liabilities.&lt;ref&gt;Lemke and Lins, ''ERISA for Money Managers'' §2:64 (Thomson West, 2013).&lt;/ref&gt;  These various approaches offer significant additional flexibility and capital efficiency compared to bonds, but also raise issues of added complexity, especially when the rebalancing of an LDI portfolio following changes in interest rates is considered. &lt;ref name="3.0"&gt;[http://www.ai-cio.com/channel/ASSET_ALLOCATION/LDI_3_0.html] LDI 3.0, aiCIO Magazine, March 2011&lt;/ref&gt;

LDI investment strategies have come to prominence in the UK as a result of changes in the regulatory and accounting framework. IAS 19 (one of the [[International Financial Reporting Standards]]) requires that UK companies post the funding position of a [[pension fund]] on the corporate sponsor's [[balance sheet]]. In the US the introduction of FAS 158 ([[Financial Accounting Standards Board]]) has created a similar requirement.

==References==
{{reflist}}

==See also==
*[[Benchmark-driven investment strategy]]

==Bibliography==
* Michael Ashton, "[https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1699347 Maximizing Personal Surplus: Liability-Driven Investment for Individuals]", October 28, 2010. [https://www.soa.org/library/monographs/retirement-systems/retirement-security/mono-2011-mrs12-ashton-paper.pdf Published] in "Retirement Security in the New Economy: Paradigm Shifts, New Approaches, and Holistic Strategies", Society of Actuaries, 2011. 
* Vincent Bazi &amp; M. Nicolas J. Firzli, “1st annual [[World Pensions &amp; Investments Forum]]”, Revue Analyse Financière, Q2 2011, pp. 7-8
* George Coats, ‘Dutch regulator blamed for pensions losses’, Financial News, Dec 14 2010
* Roy Hoevenaars, “Strategic Asset Allocation and Asset Liability Management”, University of Maastricht, 18 Jan. 2008
* Thomas P. Lemke and Gerald T. Lins, ''ERISA for Money Managers'' (Thomson West, 2013).

{{Finance}}

[[Category:Actuarial science]]
[[Category:Liability (financial accounting)]]
[[Category:Pensions]]
[[Category:Investment management]]</text>
      <sha1>t689i1tu7nxka8x2qds5sudmc0t9c7g</sha1>
    </revision>
  </page>
  <page>
    <title>List decoding</title>
    <ns>0</ns>
    <id>12044399</id>
    <revision>
      <id>837319951</id>
      <parentid>798650684</parentid>
      <timestamp>2018-04-20T02:30:47Z</timestamp>
      <contributor>
        <username>Onel5969</username>
        <id>10951369</id>
      </contributor>
      <minor/>
      <comment>Disambiguating links to [[Permanent]] (link changed to [[Permanent (mathematics)]]) using [[User:Qwertyytrewqqwerty/DisamAssist|DisamAssist]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20229">{{No footnotes|date=May 2011}}

In [[computer science]], particularly in [[coding theory]], '''list decoding''' is an alternative to unique decoding of [[error-correcting codes]] for large error rates. The notion was proposed by [[Peter Elias|Elias]] in the 1950s. The main idea behind list decoding is that the decoding algorithm instead of outputting a single possible message outputs a list of possibilities one of which is correct. This allows for handling a greater number of errors than that allowed by unique decoding.

The unique decoding model in [[coding theory]], which is constrained to output a single valid codeword from the received word could not tolerate greater fraction of errors.  This resulted in a gap between the error-correction performance for [[stochastic]] noise models (proposed by [[Claude Shannon|Shannon]]) and the adversarial noise model (considered by [[Richard Hamming]]). Since the mid 90s, significant algorithmic progress by the coding theory community has bridged this gap. Much of this progress is based on a relaxed error-correction model called list decoding, wherein the decoder outputs a list of codewords for worst-case pathological error patterns where the actual transmitted codeword is included in the output list. In case of typical error patterns though, the decoder outputs a unique single codeword, given a received word, which is almost always the case (However, this is not known to be true for all codes). The improvement here is significant in that the error-correction performance doubles. This is because now the decoder is not confined by the half-the-minimum distance barrier. This model is very appealing because having a list of codewords is certainly better than just giving up. The notion of list-decoding has many interesting applications in [[Computational complexity theory|complexity theory]].

The way the channel noise is modeled plays a crucial role in that it governs the rate at which reliable communication is possible. There are two main schools of thought in modeling the channel behavior:
*Probabilistic noise model studied by Shannon in which the channel noise is modeled precisely in the sense that the probabilistic behavior of the channel is well known and the probability of occurrence of too many or too few errors is low
*Worst-case or adversarial noise model considered by Hamming in which the channel acts as an adversary that arbitrarily corrupts the codeword subject to a bound on the total number of errors.

The highlight of list-decoding is that even under adversarial noise conditions, it is possible to achieve the information-theoretic optimal trade-off between rate and fraction of errors that can be corrected. Hence, in a sense this is like improving the error-correction performance to that possible in case of a weaker, stochastic noise model.

==Mathematical formulation==

Let &lt;math&gt;\mathcal{C}&lt;/math&gt; be a &lt;math&gt;(n,k,d)_q&lt;/math&gt; error-correcting code; in other words, &lt;math&gt;\mathcal{C}&lt;/math&gt; is a code of length &lt;math&gt;n&lt;/math&gt;, dimension &lt;math&gt;k&lt;/math&gt; and minimum distance &lt;math&gt;d&lt;/math&gt; over an alphabet &lt;math&gt;\Sigma&lt;/math&gt; of size &lt;math&gt;q&lt;/math&gt;. The list-decoding problem can now be formulated as follows:

'''Input:''' Received word &lt;math&gt;x \in \Sigma^{n}&lt;/math&gt;, [[error bound]] &lt;math&gt;e&lt;/math&gt;

'''Output:''' A list of all codewords &lt;math&gt;x_{1},x_{2},\ldots,x_{m} \in \mathcal{C}&lt;/math&gt; whose [[hamming distance]] from &lt;math&gt;x&lt;/math&gt; is at most &lt;math&gt;e&lt;/math&gt;.

==Motivation for list decoding ==

Given a received word &lt;math&gt;y&lt;/math&gt;, which is a noisy version of some transmitted codeword &lt;math&gt;c&lt;/math&gt;, the decoder tries to output the transmitted codeword by placing its bet on a codeword that is “nearest” to the received word. The Hamming distance between two codewords is used as a metric in finding the nearest codeword, given the received word by the decoder. If &lt;math&gt;d&lt;/math&gt; is the minimum Hamming distance of a code &lt;math&gt;\mathcal{C}&lt;/math&gt;, then there exists two codewords &lt;math&gt;c_1&lt;/math&gt; and &lt;math&gt;c_2&lt;/math&gt; that differ in exactly &lt;math&gt;d&lt;/math&gt; positions. Now, in the case where the received word &lt;math&gt;y&lt;/math&gt; is equidistant from the codewords &lt;math&gt;c_1&lt;/math&gt; and &lt;math&gt;c_2&lt;/math&gt;, unambiguous decoding becomes impossible as the decoder cannot decide which one of &lt;math&gt;c_1&lt;/math&gt; and &lt;math&gt;c_2&lt;/math&gt; to output as the original transmitted codeword. As a result, the half-the minimum distance acts as a combinatorial barrier beyond which unambiguous error-correction is impossible, if we only insist on unique decoding. However, received words such as &lt;math&gt;y&lt;/math&gt; considered above occur only in the worst-case and if one looks at the way Hamming balls are packed in high-dimensional space, even for error patterns &lt;math&gt;e&lt;/math&gt; beyond half-the minimum distance, there is only a single codeword &lt;math&gt;c&lt;/math&gt; within Hamming distance &lt;math&gt;e&lt;/math&gt; from the received word. This claim has been shown to hold with high probability for a random code picked from a natural ensemble and more so for the case of [[Reed–Solomon error correction|Reed–Solomon codes]] which is well studied and quite ubiquitous in the real world applications. In fact, Shannon’s proof of the capacity theorem for ''q''-ary symmetric channels can be viewed in light of the above claim for random codes.

Under the mandate of list-decoding, for worst-case errors, the decoder is allowed to output a small list of codewords. With some context specific or side information, it may be possible to prune the list and recover the original transmitted codeword. Hence, in general, this seems to be a stronger error-recovery model than unique decoding.

==List-decoding potential==

For a polynomial-time list-decoding algorithm to exist, we need the combinatorial guarantee that any Hamming ball of radius &lt;math&gt;pn &lt;/math&gt; around a received word &lt;math&gt;r&lt;/math&gt; (where &lt;math&gt;p&lt;/math&gt; is the fraction of errors in terms of the block length &lt;math&gt;n&lt;/math&gt;) has a small number of codewords. This is because the list size itself is clearly a lower bound on the running time of the algorithm. Hence, we require the list size to be a polynomial in the block length &lt;math&gt;n&lt;/math&gt; of the code. A combinatorial consequence of this requirement is that it imposes an upper bound on the rate of a code. List decoding promises to meet this upper bound. It has been shown non-constructively that codes of rate &lt;math&gt;R&lt;/math&gt; exist that can be list decoded up to a fraction of errors approaching &lt;math&gt;1-R&lt;/math&gt;. The quantity &lt;math&gt;1-R&lt;/math&gt; is referred to in the literature as the list-decoding capacity. This is a substantial gain compared to the unique decoding model as we now have the potential to correct twice as many errors. Naturally, we need to have at least a fraction &lt;math&gt;R&lt;/math&gt; of the transmitted symbols to be correct in order to recover the message. This is an information-theoretic lower bound on the number of correct symbols required to perform decoding and with list decoding, we can potentially achieve this information-theoretic limit. However, to realize this potential, we need explicit codes (codes that can be constructed in polynomial time) and efficient algorithms to perform encoding and decoding.

==(''p'', ''L'')-list-decodability==

For any error fraction &lt;math&gt;0 \leqslant p \leqslant 1&lt;/math&gt; and an integer &lt;math&gt;L \geqslant 1&lt;/math&gt;, a code &lt;math&gt;\mathcal{C} \subseteq \Sigma^{n}&lt;/math&gt; is said to be list decodable up to a fraction &lt;math&gt;p&lt;/math&gt; of errors with list size at most &lt;math&gt;L&lt;/math&gt; or &lt;math&gt;(p, L)&lt;/math&gt;-list-decodable if for every &lt;math&gt;y \in \Sigma^{n}&lt;/math&gt;, the number of codewords &lt;math&gt; c \in C &lt;/math&gt; within Hamming distance &lt;math&gt;pn&lt;/math&gt; from &lt;math&gt;y&lt;/math&gt; is at most &lt;math&gt;L.&lt;/math&gt;

==Combinatorics of list decoding==

The relation between list decodability of a code and other  fundamental  parameters such as minimum distance and rate have been fairly well studied. It has been shown that every code can be list decoded using small lists beyond half the minimum distance up to a bound called the Johnson radius. This is quite significant because it proves the existence of &lt;math&gt;(p, L)&lt;/math&gt;-list-decodable codes of good rate with a list-decoding radius much larger than &lt;math&gt;\tfrac{d}{2}.&lt;/math&gt; In other words, the [[Johnson bound]] rules out the possibility of having a large number of codewords in a Hamming ball of radius slightly greater than &lt;math&gt;\tfrac{d}{2}&lt;/math&gt; which means that it is possible to correct far more errors with list decoding.

==List-decoding capacity==

:'''Theorem (List-Decoding Capacity).''' Let &lt;math&gt; q \geqslant 2, 0 \leqslant p \leqslant 1 - \tfrac{1}{q} &lt;/math&gt; and &lt;math&gt; \epsilon \geqslant 0.&lt;/math&gt; The following two statements hold for large enough block length &lt;math&gt;n&lt;/math&gt;.
::i) If &lt;math&gt; R \leqslant 1 - H_q(p) - \epsilon &lt;/math&gt;, then there exists a &lt;math&gt;(p, O(1 / \epsilon))&lt;/math&gt;-list decodable code.
::ii) If &lt;math&gt; R \geqslant 1 - H_q(p) + \epsilon &lt;/math&gt;, then every &lt;math&gt;(p, L)&lt;/math&gt;-list-decodable code has &lt;math&gt; L = q^{\Omega(n)}&lt;/math&gt;.
:Where
::&lt;math&gt; H_q(p) = p\log_q(q - 1) - p\log_qp - (1 - p)\log_q (1 - p)&lt;/math&gt; 
:is the &lt;math&gt;q&lt;/math&gt;-ary entropy function defined for &lt;math&gt;p \in (0,1)&lt;/math&gt; and extended by continuity to &lt;math&gt;[0,1].&lt;/math&gt;

What this means is that for rates approaching the channel capacity, there exists list decodable codes with polynomial sized lists enabling efficient decoding algorithms whereas for rates exceeding the channel capacity, the list size becomes exponential which rules out the existence of efficient decoding algorithms.

The proof for list-decoding capacity is a significant one in that it exactly matches the capacity of a &lt;math&gt;q&lt;/math&gt;-ary symmetric channel &lt;math&gt;qSC_{p}&lt;/math&gt;. In fact, the term "list-decoding capacity" should actually be read as the capacity of an adversarial channel under list decoding. Also, the proof for list-decoding capacity is an important result that pin points the optimal trade-off between rate of a code and the fraction of errors that can be corrected under list decoding.

===Sketch of proof===
The idea behind the proof is similar to that of Shannon's proof for capacity of the [[binary symmetric channel]] &lt;math&gt; BSC_p &lt;/math&gt; where a random code is picked and showing that it is &lt;math&gt;(p, L)&lt;/math&gt;-list-decodable with high probability as long as the rate &lt;math&gt; R \leqslant 1 - H_q(p) - \tfrac{1}{L}.&lt;/math&gt; For rates exceeding the above quantity, it can be shown that the list size &lt;math&gt;L&lt;/math&gt; becomes super-polynomially large.

A "bad" event is defined as one in which, given a received word &lt;math&gt;y \in [q]^n&lt;/math&gt; and &lt;math&gt;L+1&lt;/math&gt; messages &lt;math&gt;m_0, \ldots, m_L \in [q]^k,&lt;/math&gt; it so happens that &lt;math&gt;\mathcal{C}(m_i) \in B(y, pn)&lt;/math&gt;, for every &lt;math&gt; 0 \leqslant i \leqslant L &lt;/math&gt; where &lt;math&gt;p&lt;/math&gt; is the fraction of errors that we wish to correct and &lt;math&gt;B(y, pn)&lt;/math&gt; is the Hamming ball of radius &lt;math&gt; pn &lt;/math&gt; with the received word &lt;math&gt; y &lt;/math&gt; as the center.

Now, the probability that a codeword &lt;math&gt; \mathcal{C}(m_i)&lt;/math&gt; associated with a fixed message &lt;math&gt; m_i \in [q]^k &lt;/math&gt; lies in a Hamming ball &lt;math&gt; B(y, pn) &lt;/math&gt; is given by

: &lt;math&gt; \Pr \left [C(m_i) \in B(y, pn) \right ] = \frac{\mathrm{Vol}_q(y, pn)}{q^n} \leqslant q^{-n(1 - H_q(p))}, &lt;/math&gt;

where the quantity &lt;math&gt; Vol_q(y, pn)&lt;/math&gt; is the volume of a Hamming ball of radius &lt;math&gt; pn &lt;/math&gt; with the received word &lt;math&gt; y &lt;/math&gt; as the center. The inequality in the above relation follows from the upper bound on the volume of a Hamming ball. The quantity &lt;math&gt; q^{H_q(p)}&lt;/math&gt; gives a very good estimate on the volume of a Hamming ball of radius &lt;math&gt;p&lt;/math&gt; centered on any word in &lt;math&gt;[q]^n.&lt;/math&gt; Put another way, the volume of a Hamming ball is translation invariant. To continue with the proof sketch, we conjure the [[union bound]] in probability theory which tells us that the probability of a bad event happening for a given &lt;math&gt; (y, m_0, \dots , m_L) &lt;/math&gt; is upper bounded by the quantity &lt;math&gt; q^{-n(L + 1) (1 - H_q(p))} &lt;/math&gt;.

With the above in mind, the probability of "any" bad event happening can be shown to be less than &lt;math&gt;1&lt;/math&gt;. To show this, we work our way over all possible received words &lt;math&gt; y \in [q]^n &lt;/math&gt; and every possible subset of &lt;math&gt;L&lt;/math&gt; messages in &lt;math&gt;[q]^k.&lt;/math&gt;

Now turning to the proof of part (ii), we need to show that there are super-polynomially many codewords around every &lt;math&gt;y \in [q]^n &lt;/math&gt; when the rate exceeds the list-decoding capacity. We need to show that &lt;math&gt;|\mathcal{C} \cap B(y, pn)| &lt;/math&gt; is super-polynomially large if the rate &lt;math&gt; R \geqslant 1 - H_q(p) + \epsilon &lt;/math&gt;. Fix a codeword &lt;math&gt; c \in \mathcal{C}&lt;/math&gt;. Now, for every &lt;math&gt;y \in [q]^n &lt;/math&gt; picked at random, we have

: &lt;math&gt; \Pr[c \in B(y, pn)] = \Pr[y \in B(c, pn)]&lt;/math&gt;

since Hamming balls are translation invariant. From the definition of the volume of a Hamming ball and the fact that &lt;math&gt; y &lt;/math&gt; is chosen uniformly at random from &lt;math&gt;[q]^n&lt;/math&gt; we also have

: &lt;math&gt; \Pr[c \in B(y, pn)] = \Pr[y \in B(c, pn)] = \frac{\mathrm{Vol}(y, pn)}{q^n} \geqslant  q^{-n(1-H_q(p)) - o(n)}&lt;/math&gt;

Let us now define an indicator variable &lt;math&gt; X_c &lt;/math&gt; such that

: &lt;math&gt;X_c = \begin{cases} 1 &amp; c \in B(y, pn) \\ 0 &amp; \text{otherwise} \end{cases}&lt;/math&gt;

Taking the expectation of the volume of a Hamming ball we have

: &lt;math&gt;\begin{align}
E[|B(y, pn)|] &amp; = \sum_{c \in \mathcal{C}} E[X_c]\\[4pt]
&amp; = \sum_{c \in \mathcal{C}}  \Pr[X_c = 1] \\[4pt]
&amp; \geqslant \sum q^{-n(1 - H_q(p) + o(n))} \\[4pt]
&amp; = \sum q^{n(R - 1 + H_q(p) + o(1))} \\[4pt]
&amp; \geqslant q^{\Omega(n)}
\end{align} &lt;/math&gt;

Therefore, by the probabilistic method, we have shown that if the rate exceeds the list-decoding capacity, then the list size becomes super-polynomially large. This completes the proof sketch for the list-decoding capacity.

==List-decoding algorithms==

In the period from 1995 to 2007, the coding theory community  developed progressively more efficient list-decoding algorithms. Algorithms for [[Reed–Solomon error correction|Reed–Solomon codes]] that can decode up to the Johnson radius which is &lt;math&gt; 1 - \sqrt{1 - \delta} &lt;/math&gt; exist where &lt;math&gt; \delta &lt;/math&gt; is the normalised distance or relative distance. However, for Reed-Solomon codes, &lt;math&gt; \delta = 1 - R &lt;/math&gt; which means a fraction &lt;math&gt; 1 - \sqrt{R}&lt;/math&gt; of errors can be corrected. Some of the most prominent list-decoding algorithms are the following:

* Sudan '95 – The first known non-trivial list-decoding algorithm for Reed–Solomon codes that achieved efficient list decoding up to &lt;math&gt; 1 - \sqrt{2R} &lt;/math&gt; errors developed by [[Madhu Sudan]].
* [[Guruswami–Sudan list decoding algorithm|Guruswami–Sudan '98]] – An improvement on the above algorithm for list decoding Reed–Solomon codes up to &lt;math&gt;1 - \sqrt{R}&lt;/math&gt; errors by Madhu Sudan and his then doctoral student [[Venkatesan Guruswami]].
* Parvaresh–Vardy '05 – In a breakthrough paper, Farzad Parvaresh and [[Alexander Vardy]] presented codes that can be list decoded beyond the &lt;math&gt;1 - \sqrt{R}&lt;/math&gt; radius for low rates &lt;math&gt;R&lt;/math&gt;. Their codes are variants of Reed-Solomon codes which are obtained by evaluating &lt;math&gt;m \geqslant 1&lt;/math&gt; correlated polynomials instead of just &lt;math&gt;1&lt;/math&gt; as in the case of usual Reed-Solomon codes.
* Guruswami–Rudra '06 - In yet another breakthrough, Venkatesan Guruswami and [http://www.cse.buffalo.edu/~atri/ Atri Rudra] give explicit codes that achieve list-decoding capacity, that is, they can be list decoded up to the radius &lt;math&gt;1-R-\epsilon&lt;/math&gt; for any &lt;math&gt;\epsilon&gt;0&lt;/math&gt;. In other words, this is error-correction with optimal redundancy. This answered a question that had been open for about 50 years. This work has been invited to the Research Highlights section of the Communications of the ACM (which is “devoted to the most important research results published in Computer Science in recent years”) and was mentioned in an article titled “Coding and Computing Join Forces” in the Sep 21, 2007 issue of the Science magazine. The codes that they are given are called [[Folded Reed–Solomon code|folded Reed-Solomon codes]] which are nothing but plain Reed-Solomon codes but viewed as a code over a larger alphabet by careful bundling of codeword symbols.

Because of their ubiquity and the nice algebraic properties they possess, list-decoding algorithms for Reed–Solomon codes were a main focus of researchers. The list-decoding problem for Reed–Solomon codes can be formulated as follows:

'''Input''': For an &lt;math&gt; [n, k + 1]_q &lt;/math&gt; Reed-Solomon code, we are given the pair &lt;math&gt; (\alpha_i, y_i) &lt;/math&gt; for &lt;math&gt; 1 \leq i \leq n &lt;/math&gt;, where &lt;math&gt; y_i &lt;/math&gt; is the &lt;math&gt;i&lt;/math&gt;th bit of the received word and the &lt;math&gt;\alpha_i &lt;/math&gt;'s are distinct points in the finite field &lt;math&gt; F_q &lt;/math&gt; and an error parameter &lt;math&gt; e = n - t &lt;/math&gt;.

'''Output''': The goal is to find all the polynomials &lt;math&gt; P(X) \in F_q[X] &lt;/math&gt; of degree at most &lt;math&gt; k &lt;/math&gt; which is the message length such that &lt;math&gt; p(\alpha_i) = y_i&lt;/math&gt; for at least &lt;math&gt; t &lt;/math&gt; values of &lt;math&gt; i &lt;/math&gt;. Here, we would like to have &lt;math&gt; t &lt;/math&gt; as small as possible so that greater number of errors can be tolerated.

With the above formulation, the general structure of list-decoding algorithms for Reed-Solomon codes is as follows:

'''Step 1''': (Interpolation) Find a non-zero bivariate polynomial &lt;math&gt;Q(X,Y)&lt;/math&gt; such that &lt;math&gt; Q(\alpha_i, y_i) = 0 &lt;/math&gt; for &lt;math&gt; 1 \leq i \leq n &lt;/math&gt;.

'''Step 2''': (Root finding/Factorization) Output all degree &lt;math&gt; k &lt;/math&gt; polynomials &lt;math&gt; p(X) &lt;/math&gt; such that &lt;math&gt; Y - p(X) &lt;/math&gt; is a factor of &lt;math&gt;Q(X,Y)&lt;/math&gt; i.e. &lt;math&gt;Q(X,p(X)) = 0&lt;/math&gt;. For each of these polynomials, check if &lt;math&gt; p(\alpha_i) = y_i &lt;/math&gt; for at least &lt;math&gt; t &lt;/math&gt; values of &lt;math&gt; i \in [n] &lt;/math&gt;. If so, include such a polynomial &lt;math&gt; p(X) &lt;/math&gt; in the output list.

Given the fact that bivariate polynomials can be factored efficiently, the above algorithm runs in polynomial time.

==Applications in complexity theory and cryptography==

Algorithms developed for list decoding of several interesting code families have found interesting applications in [[Analysis of algorithms|computational complexity]]  and the field of [[cryptography]]. Following is a sample list of applications outside of coding theory:

* Construction of [[hard-core predicate]]s from [[One-way function|one-way permutations]].
* Predicting witnesses for NP-search problems.
* Amplifying hardness of Boolean functions.
* Average case hardness of [[Permanent (mathematics)|permanent]] of random matrices.
* [[Extractor (mathematics)|Extractors]] and [[Pseudorandom generator]]s.
* Efficient traitor tracing.

==External links==
*[http://theory.lcs.mit.edu/%7Emadhu/papers/noneed/ifip-journ.ps A Survey on list decoding] by [[Madhu Sudan]]
*[http://people.csail.mit.edu/madhu/FT01/ Notes from a course] taught by Madhu Sudan
*[http://www.cs.berkeley.edu/~luca/cs294/ Notes from a course] taught by [[Luca Trevisan]]
*[http://www.cs.washington.edu/education/courses/533/06au/ Notes from a course] taught by [[Venkatesan Guruswami]]
*[http://www.cse.buffalo.edu/~atri/courses/coding-theory/ Notes from a course] taught by Atri Rudra
* P. Elias, "List decoding for noisy channels," Technical Report 335, Research Laboratory of Electronics, MIT, 1957.
* P. Elias, "Error-correcting codes for list decoding," IEEE Transactions on Information Theory, vol. 37, pp.&amp;nbsp;5–12, 1991.
* J. M. Wozencraft, "List decoding," Quarterly Progress Report, Research Laboratory of Electronics, MIT, vol. 48, pp.&amp;nbsp;90–95, 1958.
*[[Venkatesan Guruswami]]'s [https://www.springer.com/computer/foundations/book/978-3-540-24051-8 PhD thesis]
*[http://www.nowpublishers.com/product.aspx?product=TCS&amp;doi=0400000007 Algorithmic Results in List Decoding]
* [[Folded Reed–Solomon code]]

[[Category:Coding theory]]
[[Category:Error detection and correction]]
[[Category:Computational complexity theory]]</text>
      <sha1>lrwd6fusjbsp8j0wjmrr46dhxxssrcm</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after Andrey Markov</title>
    <ns>0</ns>
    <id>56381043</id>
    <revision>
      <id>838089287</id>
      <parentid>831406769</parentid>
      <timestamp>2018-04-24T21:15:59Z</timestamp>
      <contributor>
        <username>Onel5969</username>
        <id>10951369</id>
      </contributor>
      <minor/>
      <comment>Disambiguated: [[Markov tree]] → [[Markov chain]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2143">This article is a list of things named after [[Andrey Markov]], an influential Russian mathematician.

== Markov stochastic processes ==

* [[Markov property]], the essential property of Markov stochastic processes

=== Markov chains ===
* [[Markov chain]]
** [[Additive Markov chain]]
** [[Absorbing Markov chain]]
** [[Nearly completely decomposable Markov chain]]
** [[Quantum Markov chain]]
** [[Telescoping Markov chain]]
* [[Examples of Markov chains]]



* [[Markov model]]
* [[Markov renewal process]]
* [[Markov chain mixing time]]
* [[Markov kernel]]
* [[Piecewise-deterministic Markov process]]
* [[Markovian arrival process]]
* [[Markov strategy]]
* [[Markov information source]]
* [[Hidden Markov model]]
* [[Markov chain Monte Carlo]]
** [[Reversible-jump Markov chain Monte Carlo]]
* [[Markov chain geostatistics]]
* [[Maximum-entropy Markov model]]
* [[Markovian discrimination]]
* [[Markov decision process]]
* [[Markov chain]]
* [[Markov reward model]]
* [[Markov switching multifractal]]
* [[Markov chain approximation method]]
* [[Markov logic network]]
* [[Markov chain approximation method]]
* [[Markov random field]]
* [[Lempel–Ziv–Markov chain algorithm]]
* [[Layered hidden Markov model]]
* [[Markov partition]]
* [[Partially observable Markov decision process]]
* [[Markov odometer]]
* [[Causal Markov condition]]
* [[Markov Reward Model Checker]]
* [[Dynamics of Markovian particles]]


* [[Markov perfect equilibrium]] (game theory)

* [[Markov's inequality]]
* [[Markov brothers' inequality]]
* [[Chebyshev–Markov–Stieltjes inequalities]]
* [[Markov–Krein theorem]]


* [[Gauss–Markov theorem]]
* [[Gauss–Markov process]]


* [[Dynamic Markov compression]]


* [[Markov algorithm]]

* [[Markov spectrum]] in Diophantine equations
* [[Markov number]] (Diophantine equations)


* [[Markov–Kakutani fixed-point theorem]]

* [[Riesz–Markov–Kakutani representation theorem]]



* [[Markov theorem]] on braids

* [[Markov's principle]]

* [[Markov (crater)]]
* [[27514 Markov]], a main-belt asteroid


* [[Semi-Markov model]]




[[Category:Lists of things named after mathematicians|Markov, Andrey]]</text>
      <sha1>clglxo71ktypbxo14z2693e37lgdv2d</sha1>
    </revision>
  </page>
  <page>
    <title>Marcel Grossmann</title>
    <ns>0</ns>
    <id>1247037</id>
    <revision>
      <id>867810549</id>
      <parentid>867801985</parentid>
      <timestamp>2018-11-08T04:08:36Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9357">{{Infobox scientist
| name = Marcel Grossmann
| image = ETH-BIB-Grossmann, Marcel (1878-1936)-Portrait-Portr 01239.tif (cropped).jpg
| birth_date = {{Birth date|1878|4|9|mf=yes}}
| birth_place = [[Budapest]], [[Austria-Hungary]]
| death_date  = {{Death date and age|1936|9|7|1878|4|9|mf=yes}}
| death_place = [[Zurich]], Switzerland
| residence   = 
| citizenship = 
| nationality = 
| fields      = [[Mathematics]]
| workplaces  = 
| alma_mater  = [[Federal Polytechnic School]] 
| doctoral_advisor  = [[Wilhelm Fiedler]]
| academic_advisors = 
| doctoral_students = 
| notable_students  = 
| awards      = honorary member (1935) of the Swiss Mathematical Society&lt;ref&gt;{{cite web|title=Honorary Members of the SMS|url=http://math.ch/members/honorary-members}}&lt;/ref&gt;
}}
'''Marcel Grossmann''' ({{lang-hu|Grossmann Marcell}}, April 9, 1878 &amp;ndash; September 7, 1936) was a [[mathematician]] and a friend and classmate of [[Albert Einstein]]. Grossmann was a member of an old Swiss family from [[Zurich]]. His father managed a textile factory. He became a [[Professor]] of Mathematics at the [[Federal Polytechnic School]] in Zurich, today the ETH Zurich, specializing in [[descriptive geometry]].

==Career==
In 1900 Grossmann graduated from the [[Federal Polytechnic School]] (ETH) and became an assistant to the geometer [[Wilhelm Fiedler]]. He continued to do research on [[non-Euclidean geometry]] and taught in high schools for the next seven years. In 1902, he earned his doctorate from the ETH with the thesis ''On the Metrical Properties of Collinear Structures'' with Fiedler as advisor. In 1907, he was appointed full professor of descriptive geometry at the Federal Polytechnic School.

As a professor of geometry, Grossmann organized summer courses for high school teachers. In 1910, he became one of the founders of the [[Swiss Mathematical Society]]. He was an Invited Speaker of the ICM in 1912 at Cambridge UK&lt;ref&gt;{{cite book|author=Grossmann, Marcel|chapter=Die Zentralprojektion in der absoluten Geometrie|title=''In:'' Proceedings of the Fifth International Congress of Mathematicians (Cambridge, 22–28 August 1912)|pages=66–69|volume=vol. 2|chapter-url=http://www.mathunion.org/ICM/ICM1912.2/Main/icm1912.2.0066.0069.ocr.pdf|deadurl=yes|archiveurl=https://web.archive.org/web/20171203153805/http://www.mathunion.org/ICM/ICM1912.2/Main/icm1912.2.0066.0069.ocr.pdf|archivedate=3 December 2017|df=}}&lt;/ref&gt; and in 1920 at Strasbourg.

===Collaborations with Albert Einstein===
[[Albert Einstein]]'s friendship with Grossmann began with their school days in Zurich. Grossmann's careful and complete lecture notes at the Federal Polytechnic School proved to be a salvation for Einstein, who missed many lectures.&lt;ref&gt;Alice Calaprice, Daniel Kennefick, Robert Schulmann, ''An Einstein Encyclopedia'', Princeton University Press, 2015, p. 70.&lt;/ref&gt; Grossmann's father helped Einstein get his job at the Swiss Patent Office in [[Bern]],&lt;ref&gt;{{Cite journal|last=Janssen|first=Michel|last2=Renn|first2=Jürgen|date=2015-11-19|title=History: Einstein was no lone genius|url=http://www.nature.com/news/history-einstein-was-no-lone-genius-1.18793|journal=Nature|language=en|volume=527|issue=7578|pages=298–300|doi=10.1038/527298a|bibcode=2015Natur.527..298J}}&lt;/ref&gt; and it was Grossmann who helped to conduct the negotiations to bring Einstein back as a professor of physics at the Zurich Polytechnic. Grossmann was an expert in differential geometry and tensor calculus; just the mathematical tools Einstein discovered were needed for his work on gravity. Thus, it was natural that Einstein would enter into a scientific collaboration with Grossmann.&lt;ref&gt;J. Earman and C. Glymour, [http://repository.cmu.edu/cgi/viewcontent.cgi?article=1338&amp;context=philosophy  Lost in the Tensors: Einstein's Struggles with Covariance Principles, 1912-1916], footnote page 255; Carnegie Mellon University Research Showcase (accessed February 12, 2016)&lt;/ref&gt;

It was Grossmann who emphasized the importance of a non-Euclidean geometry called [[Riemannian geometry]] (also [[elliptic geometry]]) to Einstein, which was a necessary step in the development of Einstein's [[general theory of relativity]]. [[Abraham Pais]]'s book&lt;ref&gt;{{cite book | author=Pais, Abraham |title= Subtle is the lord: the science and life of Albert Einstein| year=1982}}&lt;/ref&gt; on Einstein suggests that Grossmann mentored Einstein in [[tensor]] theory as well. Grossmann introduced Einstein to the absolute differential calculus, started by [[Elwin Bruno Christoffel|Christoffel]]&lt;ref&gt;{{citation|title=Ueber die Transformation der homogenen Differentialausdrücke zweiten Grades|last=Christoffel|first=E.B.|author-link=Elwin Bruno Christoffel|journal=Journal für die reine und angewandte Mathematik|volume=B. 70|pages=46–70|year=1869|url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=GDZPPN002153882&amp;IDDOC=266356}}&lt;/ref&gt; and fully developed by [[Gregorio Ricci-Curbastro|Ricci-Curbastro]] and [[Levi-Civita]].&lt;ref&gt;{{citation|title=Méthodes de calcul différentiel absolu et leurs applications|last=Ricci|first=Gregorio|last2=Levi-Civita|first2=Tullio|journal=Mathematische Annalen|publisher=Springer|volume=54|issue=1–2|date=March 1900|pages=125–201|doi=10.1007/BF01454201|url=http://www.springerlink.com/content/u21237446l22rgg7/fulltext.pdf}}&lt;/ref&gt; Grossmann facilitated Einstein's unique synthesis of mathematical and theoretical physics in what is still today considered the most elegant and powerful theory of gravity: the general theory of relativity. The collaboration of Einstein and Grossmann led to a ground-breaking paper: "Outline of a Generalized Theory of Relativity and of a Theory of Gravitation", which was published in 1913 and was one of the two fundamental papers which established Einstein's theory of gravity.&lt;ref&gt;{{cite journal | last1 = Einstein | first1 = A. | authorlink2 = Marcel Grossmann | last2 = Grossmann | first2 = M. |title = Entwurf einer verallgemeinerten Relativitätstheorie und einer Theorie der Gravitation |year = 1913| pages = 225–261 }}&lt;/ref&gt;

==Death==
Grossmann died of [[multiple sclerosis]] in 1936.  The community of relativists celebrates Grossmann's contributions to physics by organizing Marcel Grossmann meetings every three years.

==See also==
* [[Genius (U.S. TV series)|''Genius'']], a television series depicting Einstein's life
* [[History of general relativity]]

==Notes==
{{Reflist|2}}

==References==
*{{cite book | author=Pais, Abraham | title= Subtle is the Lord: the science and life of Albert Einstein| location=Oxford | publisher=[[Oxford University Press]] | year=1982 | isbn=0-19-853907-X}}
* {{cite journal | last1 = Einstein | first1 = A. | authorlink2 = Marcel Grossmann | last2 = Grossmann | first2 = M. | year = 1913 | title = Entwurf einer verallgemeinerten Relativitätstheorie und einer Theorie der Gravitation |trans-title=Outline of a Generalized Theory of Relativity and of a Theory of Gravitation | url = | journal = Zeitschrift für Mathematik und Physik | volume = 62 | issue = | pages = 225–261 }} [http://www.pitt.edu/~jdnorton/teaching/GR&amp;Grav_2007/pdf/Einstein_Entwurf_1913.pdf English translate]
* {{cite journal | last1 = Einstein | first1 = A. | authorlink2 = Marcel Grossmann | last2 = Grossmann | first2 = M. | year = 1914 | title = Kovarianzeigenschaften der Feldgleichungen der auf die verallgemeinerte Relativitätstheorie gegründeten Gravitationstheorie  |trans-title=Covariance Properties of the Field Equations of the Theory of Gravitation Based on the Generalized Theory of Relativity | url = | journal = Zeitschrift für Mathematik und Physik | volume = 63 | issue = | pages = 215–225 |bibcode = 1914ZMP....63..215E }}
* Graf-Grossmann, Claudia, with T. Sauer, ''Marcel Grossmann: Aus Liebe zur Mathematik'', Römerhof-Verlag, Zürich, 2015, {{ISBN|978-3-905894-32-5}}
* T. Sauer, &lt;nowiki&gt;''&lt;/nowiki&gt;Marcel Grossmann's contribution to the general theory of relativity&lt;nowiki&gt;''&lt;/nowiki&gt;, in:  &lt;nowiki&gt;''&lt;/nowiki&gt;Proceedings of the 13th Marcel Grossmann meeting on  Recent Developments in Theoretical and Experimental General Relativity, Astrophysics and Relativistic Field Theories&lt;nowiki&gt;''&lt;/nowiki&gt;, July 2012. Edited by Robert T. Jantzen, Kjell Rosquist, Remo Ruffini. World Scientific, 2015, pp.&amp;nbsp;456–503.(&lt;nowiki&gt;http://arxiv.org/abs/1312.4068&lt;/nowiki&gt;)
* Graf-Grossmann, Claudia, with T. Sauer, English translation by William D. Brewer, ´´Marcel Grossmann: For the Love of Mathematics´´, Springer Biographies, 2018, {{ISBN|3319900765}}, {{ISBN|978-3319900766}}

==External links==
* [http://www.icra.it/MG/ Marcel Grossmann meetings]
* {{MacTutor Biography|id=Grossmann}}
* {{MathGenealogy |id=44413}}

{{Authority control}}

{{DEFAULTSORT:Grossmann, Marcel}}
[[Category:1878 births]]
[[Category:1936 deaths]]
[[Category:19th-century mathematicians]]
[[Category:20th-century Hungarian mathematicians]]
[[Category:ETH Zurich alumni]]
[[Category:ETH Zurich faculty]]
[[Category:Geometers]]
[[Category:Jewish scientists]]
[[Category:Hungarian Jews]]
[[Category:Hungarian people of Swiss descent]]
[[Category:People from Budapest]]
[[Category:Relativity theorists]]
[[Category:Swiss expatriates in Hungary]]
[[Category:Swiss Jews]]
[[Category:Swiss mathematicians]]
[[Category:Swiss people of Hungarian descent]]
[[Category:Deaths from multiple sclerosis]]</text>
      <sha1>gbei9plliqthnhenyjh3bq6cjf7thym</sha1>
    </revision>
  </page>
  <page>
    <title>Mina Aganagic</title>
    <ns>0</ns>
    <id>47538197</id>
    <revision>
      <id>857401151</id>
      <parentid>846681514</parentid>
      <timestamp>2018-08-31T13:10:25Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4361">[[File:Mina Aganagic.jpg|thumb|Mina Aganagic]]
'''Mina Aganagic''' is a Bosnian-born [[mathematical physics|mathematical physicist]] who works as a professor in the Department of Mathematics and the Department of Physics at the [[University of California, Berkeley]].

==Career==
Aganagic was raised in [[Sarajevo]], [[Bosnia and Herzegovina]].&lt;ref name="sloan"/&gt;
She has a bachelor's degree and a doctorate from the [[California Institute of Technology]], in 1995 and 1999 respectively; her PhD advisor was [[John Henry Schwarz]].&lt;ref&gt;{{mathgenealogy|id=162853}}&lt;/ref&gt;  She was a Postdoctoral  Fellow at the [[Harvard University]] physics department
from 1999 to 2003. She then joined the physics faculty at the [[University of Washington]], where she became a [[Sloan Fellowship|Sloan Fellow]] &lt;ref name="sloan"&gt;{{citation|url=http://www.washington.edu/news/2004/03/11/three-profs-win-sloan-research-fellowships/|journal=UW Today|publisher=University of Washington|date=March 11, 2004|title=Three profs win Sloan Research Fellowships}}&lt;/ref&gt; and a [[DOE Outstanding Junior Investigator]].&lt;ref name="DOE"&gt;{{citation|url=https://science.energy.gov/~/media/hep/pdf/files/pdfs/OJI_ALL_Awards.pdf)|title= US Department of Energy Outstanding Junior Investigator Awards}}.&lt;/ref&gt; She moved to UC Berkeley in 2004. In 2016 the [[Simons Foundation]] gave her a Simons Investigator award.&lt;ref&gt;{{citation|url=http://www.ams.org/news?news_id=3115|title=Simons Investigator Awards Announced |work=News, Events and Announcements|publisher=[[American Mathematical Society]]|date=July 13, 2016|accessdate=2017-09-20}}&lt;/ref&gt;

==Research ==
She is known for applying string theory to various problems in mathematics, e.g. [[knot theory]] (refined [[Chern–Simons theory]]),{{ran|3}} [[enumerative geometry]] (topological vertex){{ran|2}}, [[Mirror symmetry (string theory)|mirror symmetry]] {{ran|1}}{{ran|4}} and [[Geometric Langlands Correspondence]] {{ran|5}}.

==Selected publications==
{{rma|1|{{citation
 | first1 = Mina |last1 = Aganagic 
 | first2 = Cumrun | last2 = Vafa | author2-link = Cumrun Vafa
 | arxiv = hep-th/0012041
 | title = Mirror symmetry, D-branes and counting holomorphic discs
 | year = 2000| bibcode = 2000hep.th...12041A}}|tw=2.5em}}
{{rma|2|{{citation
 | last1 = Aganagic | first1 = Mina
 | last2 = Klemm | first2 = Albrecht
 | last3 = Mariño | first3 = Marcos
 | last4 = Vafa | first4 = Cumrun | author4-link = Cumrun Vafa
 | arxiv = hep-th/0305132
 | doi = 10.1007/s00220-004-1162-z
 | issue = 2
 | journal = [[Communications in Mathematical Physics]]
 | mr = 2117633
 | pages = 425–478
 | title = The topological vertex
 | volume = 254
 | year = 2005| bibcode = 2005CMaPh.254..425A}}|tw=2.5em}}
{{rma|3|{{citation
 | last1 = Aganagic | first1 = Mina
 | last2 = Shakirov | first2 = Shamil
 | arxiv = 1105.5117
 | title = Knot homology from refined Chern–Simons theory
 | year = 2011| bibcode = 2011arXiv1105.5117A}}|tw=2.5em}}
{{rma|4|{{citation
 | last1 = Aganagic | first1 = Mina
 | last2 = Vafa | first2 = Cumrun | author2-link = Cumrun Vafa
 | arxiv = 1204.4709
 | title = Large N duality, mirror symmetry, and a Q-deformed A-polynomial for knots
 | year = 2012| bibcode = 2012arXiv1204.4709A}}|tw=2.5em}}
{{rma|5|{{citation
 | last1 = Aganagic | first1 = Mina
 | last2 = Frenkel | first2 = Edward | author2-link = Edward Frenkel
 | last3 = Okounkov | first3 = Andrei | author3-link = Andrei Okounkov
 | arxiv = 1701.03146
 | title = Quantum q-Langlands Correspondence
 | year = 2017| bibcode = 2017arXiv170103146A}}|tw=2.5em}}

==References==
{{reflist}}

== External links ==
*[http://physics.berkeley.edu/people/faculty/mina-aganagic Physics Department home page]
*[https://math.berkeley.edu/people/faculty/mina-aganagic Math Department home page]


{{authority control}}

{{DEFAULTSORT:Aganagic, Mina}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:Bosnia and Herzegovina emigrants to the United States]]
[[Category:California Institute of Technology alumni]]
[[Category:University of Washington faculty]]
[[Category:University of California, Berkeley faculty]]
[[Category:Bosnia and Herzegovina mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Women mathematicians]]
[[Category:Mathematical physicists]]
[[Category:Simons Investigator]]


{{US-physicist-stub}}</text>
      <sha1>64k0ba96mrjui86dm1mbut66x6ft47f</sha1>
    </revision>
  </page>
  <page>
    <title>Monk's formula</title>
    <ns>0</ns>
    <id>22444842</id>
    <revision>
      <id>819195133</id>
      <parentid>627019772</parentid>
      <timestamp>2018-01-08T00:32:50Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: journal=Proceedings of the London Mathematical Society. Third Series → journal=Proceedings of the London Mathematical Society |series=Third Series using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1420">In mathematics, '''Monk's formula''', found by {{harvtxt|Monk|1959}}, is an analogue of [[Pieri's formula]] that describes the product of a linear [[Schubert polynomial]] by a Schubert polynomial.  Equivalently, it describes the product of a special [[Schubert cycle]] by a Schubert cycle in the [[cohomology]] of a [[flag manifold]].

Write ''t''&lt;sub&gt;ij&lt;/sub&gt; for the [[Transposition (mathematics)|transposition]] ''(i j)'', and ''s''&lt;sub&gt;i&lt;/sub&gt; = ''t''&lt;sub&gt;i,i+1&lt;/sub&gt;. Then 𝔖&lt;sub&gt;s&lt;sub&gt;r&lt;/sub&gt;&lt;/sub&gt; = ''x''&lt;sub&gt;1&lt;/sub&gt; + ⋯ + ''x''&lt;sub&gt;r&lt;/sub&gt;, and Monk's formula states that for a permutation ''w'',

&lt;math&gt;
\mathfrak{S}_{s_r} \mathfrak{S}_w = \sum_{{i \leq r &lt; j} \atop {\ell(wt_{ij}) = \ell(w)+1}} \mathfrak{S}_{wt_{ij}},
&lt;/math&gt;

where &lt;math&gt;\ell(w)&lt;/math&gt; is the [[length]] of ''w''. The pairs (''i'', ''j'') appearing in the sum are exactly those such that ''i'' &amp;le; ''r'' &lt; ''j'', ''w''&lt;sub&gt;i&lt;/sub&gt; &lt; ''w''&lt;sub&gt;j&lt;/sub&gt;, and there is no ''i'' &lt; ''k'' &lt; ''j'' with ''w''&lt;sub&gt;i&lt;/sub&gt; &lt; ''w''&lt;sub&gt;k&lt;/sub&gt; &lt; ''w''&lt;sub&gt;j&lt;/sub&gt;; each ''wt''&lt;sub&gt;ij&lt;/sub&gt; is a cover of ''w'' in [[Bruhat order]].

==References==
*{{Citation | last1=Monk | first1=D. | title=The geometry of flag manifolds | doi=10.1112/plms/s3-9.2.253 |mr=0106911 | year=1959 | journal=Proceedings of the London Mathematical Society |series=Third Series | issn=0024-6115 | volume=9 | pages=253–286 | issue=2}}

[[Category:Symmetric functions]]</text>
      <sha1>q0cj36qwunefpb2vaztniup37jzejn7</sha1>
    </revision>
  </page>
  <page>
    <title>Number line</title>
    <ns>0</ns>
    <id>287188</id>
    <revision>
      <id>863058656</id>
      <parentid>863054787</parentid>
      <timestamp>2018-10-08T12:59:22Z</timestamp>
      <contributor>
        <username>Dolphin51</username>
        <id>4754841</id>
      </contributor>
      <minor/>
      <comment>Reverted 2 edits from 68.193.39.186 to last version by Wcherowi. Unexplained deletion and insertion of meaningless text.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9132">
{{About|the mathematical concept|the printer's key|Printer's key}}
{{hatnote|This article covers basic topics. For advanced topics, see [[Real line]].}}

In basic mathematics, a '''number line''' is a picture of a graduated straight [[line (geometry)|line]] that serves as abstraction for [[real number]]s, denoted by &lt;math&gt;\mathbb{R}&lt;/math&gt;. Every point of a number line is assumed to correspond to a [[real number]], and every real number to a point.&lt;ref&gt;{{cite book | last1=Stewart | first1=James B. | last2 = Redlin | first2 = Lothar | last3=Watson | first3=Saleem | authorlink=James Stewart (mathematician) | title=College Algebra | publisher=[[Brooks Cole]]  | year=2008 | edition = 5th | pages=13&amp;ndash;19 | isbn=0-495-56521-0}}&lt;/ref&gt;

The [[integer]]s are often shown as specially-marked points evenly spaced on the line.  Although this image only shows the integers from &amp;minus;9 to 9, the line includes all [[real number]]s, continuing forever in each direction, and also numbers not marked that are between the integers. It is often used as an aid in teaching simple [[addition]] and [[subtraction]], especially involving [[negative number]]s.

[[File:Number-line.svg|center|The number line]]

In advanced mathematics, the expressions ''real number line'', or ''[[real line]]'' are typically used to indicate the above-mentioned concept that every point on a straight line corresponds to a single real number, and [[List of Latin phrases: V#vice versa|vice versa]].

==Drawing the number line==
A number line is usually represented as being [[horizontal plane|horizontal]], but in a [[Cartesian coordinate system|Cartesian coordinate plane]] the vertical axis (y-axis) is also a number line.&lt;ref name=purple&gt;[http://www.purplemath.com/modules/plane.htm Introduction to the x,y-plane] "Purplemath" Retrieved 2015-11-13&lt;/ref&gt; According to one convention, [[positive number]]s always lie on the right side of zero, [[negative number]]s always lie on the left side of zero, and arrowheads on both ends of the line are meant to suggest that the line continues indefinitely in the positive and negative directions. Another convention uses only one arrowhead which indicates the direction in which numbers grow.&lt;ref name=purple/&gt; The line continues indefinitely in the positive and negative directions according to the rules of geometry which define a line without endpoints as an ''infinite line'', a line with one endpoint as a ''ray'', and a line with two endpoints as a ''line segment''.

==Comparing numbers==
If a particular number is farther to the right on the number line than is another number, then the first number is greater than the second (equivalently, the second is less than the first). The distance between them is the magnitude of their difference&amp;mdash;that is, it measures the first number minus the second one, or equivalently the absolute value of the second number minus the first one. Taking this difference is the process of [[subtraction]].

Thus, for example, the length of a [[line segment]] between 0 and some other number represents the magnitude of the latter number.

Two numbers can be [[addition|added]] by "picking up" the length from 0 to one of the numbers, and putting it down again with the end that was 0 placed on top of the other number.

Two numbers can be [[multiplication|multiplied]] as in this example: To multiply 5 × 3, note that this is the same as 5 + 5 + 5, so pick up the length from 0 to 5 and place it to the right of 5, and then pick up that length again and place it to the right of the previous result. This gives a result that is 3 combined lengths of 5 each; since the process ends at 15, we find that 5 × 3 = 15.

[[Division (mathematics)|Division]] can be performed as in the following example: To divide 6 by 2&amp;mdash;that is, to find out how many times 2 goes into 6&amp;mdash;note that the length from 0 to 2 lies at the beginning of the length from 0 to 6; pick up the former length and put it down again to the right of its original position, with the end formerly at 0 now placed at 2, and then move the length to the right of its latest position again. This puts the right end of the length 2 at the right end of the length from 0 to 6. Since three lengths of 2 filled the length 6, 2 goes into 6 three times (that is, 6 ÷ 2 = 3).

&lt;gallery widths=300&gt;
File:Number line with x smaller than y.svg|The ordering on the number line: Greater elements are in direction of the arrow.
File:Number line with addition of -2 and 3.svg|The difference 3-2=3+(-2) on the real number line.
File:Number line with addition of 1 and 2.svg|The addition 1+2 on the real number line
File:Absolute difference.svg|The absolute difference.
File:Number line multiplication 2 with 1,5.svg|The multiplication 2 times 1.5
File:Number line division 3 with 2.svg|The division 3÷2 on the real number line
&lt;/gallery&gt;

==Portions of the number line==
[[File:Intervalo real 04.svg|thumb|The closed interval {{math|[a,b]}}.]]
The section of the number line between two numbers is called an [[interval (mathematics)|interval]]. If the section includes both numbers it is said to be a closed interval, while if it excludes both numbers it is called an open interval. If it includes one of the numbers but not the other one, it is called a half-open interval.

All the points extending forever in one direction from a particular point are together known as a [[ray (mathematics)|ray]]. If the ray includes the particular point, it is a closed ray; otherwise it is an open ray.

==Extensions of the concept==
===Logarithmic scale===
{{main|Logarithmic scale}}
[[Image:LogLog exponentials.svg|thumb|A log-log plot of ''y''&amp;nbsp;=&amp;nbsp;''x''&amp;nbsp;(blue), ''y''&amp;nbsp;=&amp;nbsp;''x''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;(green), and ''y''&amp;nbsp;=&amp;nbsp;''x''&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;(red).&lt;br&gt;Note the logarithmic scale markings on each of the axes, and that the log&amp;nbsp;''x'' and log&amp;nbsp;''y'' axes (where the logarithms are 0) are where ''x'' and ''y'' themselves are 1.]]

On the number line, the distance between two points is the unit length if and only if the difference of the represented numbers equals 1. Other choices are possible. 

One of the most common choices is the ''logarithmic scale'', which is a representation of the ''positive'' numbers on a line, such that the distance of two points is the unit length, if the ratio of the represented numbers has a fixed value, typically 10. In such a logarithmic scale, the origin represents 1; one inch to the right, one has 10, one inch to the right of 10 one has {{nowrap|1=10×10 = 100}}, then {{nowrap|1=10×100 = 1000 = 10&lt;sup&gt;3&lt;/sup&gt;}}, then {{nowrap|1=10×1000 = 10,000 = 10&lt;sup&gt;3&lt;/sup&gt;}}, etc. Similarly, one inch to the left of 1, one has {{nowrap|1=1/10 = 10&lt;sup&gt;–1&lt;/sup&gt;}}, then {{nowrap|1=1/100 = 10&lt;sup&gt;–2&lt;/sup&gt;}}, etc.

This approach is useful, when one wants to represent, on the same figure, values with very different [[order of magnitude]]. For example, one requires a logarithmic scale for representing simultaneously the size of the different bodies that exist in the [[Universe]], typically, a [[photon]], an [[electron]], an [[atom]], a [[molecule]], a [[human]], the [[Earth]], the [[Solar System]], a [[galaxy]], and the visible Universe.

Logarithmic scales are used in [[slide rule]]s for multiplying or dividing numbers by adding or subtracting lengths on logarithmic scales.
[[File:slide rule example3.svg|frame|thumb|center|The two logarithmic scales of a slide rule]]

===Combining number lines===
A line drawn through the origin at right angles to the real number line can be used to represent the [[imaginary number]]s. This line, called [[imaginary line (mathematics)|imaginary line]], extends the number line to a [[complex plane|complex number plane]], with points representing [[complex number]]s.

Alternatively, one real number line can be drawn horizontally to denote possible values of one real number, commonly called ''x'', and another real number line can be drawn vertically to denote possible values of another real number, commonly called ''y''. Together these lines form what is known as a [[Cartesian coordinate system]], and any point in the plane represents the value of a pair of real numbers. Further, the Cartesian coordinate system can itself be extended by visualizing a third number line "coming out of the screen (or page)", measuring a third variable called ''z''. Positive numbers are closer to the viewer's eyes than the screen is, while negative numbers are "behind the screen"; larger numbers are farther from the screen. Then any point in the three-dimensional space that we live in represents the values of a trio of real numbers.

==See also==
*[[Chronology]]
*[[Complex plane]]
*[[Cuisenaire rods]]
*[[Extended real number line]]
*[[Hyperreal number line]]
*[[Number form]] (neurological phenomenon)
*[[Intercept_theorem#The_construction_of_a_decimal_number|The construction of a decimal number]]

==References==
{{reflist}}

{{DEFAULTSORT:Number Line}}
[[Category:Elementary mathematics]]
[[Category:Mathematical manipulatives]]
[[Category:One-dimensional coordinate systems]]

[[ja:直線#座標]]</text>
      <sha1>kt22ek74wuqcf2k9jo908ot4n91131g</sha1>
    </revision>
  </page>
  <page>
    <title>Ordered probit</title>
    <ns>0</ns>
    <id>3810034</id>
    <revision>
      <id>870626746</id>
      <parentid>869774617</parentid>
      <timestamp>2018-11-26T01:22:03Z</timestamp>
      <contributor>
        <username>Benmotz</username>
        <id>14118438</id>
      </contributor>
      <minor/>
      <comment>Adding mention of and reference to Liddell &amp; Kruschke, 2018</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3488">{{Regression bar}}
In [[statistics]], '''ordered probit''' is a whole of the widely used [[Probit model|probit]] analysis to the case of more than two outcomes of an [[ordinal data|ordinal]] [[dependent variable]] (a dependent variable for which the potential values have a natural ordering, as in poor, fair, good, excellent). Similarly, the widely used [[logit]] method also has a counterpart [[ordered logit]]. Ordered probit, like ordered logit, is a particular method of [[ordinal regression]].

For example, in [[clinical research]], the effect a drug may have on a patient may be modeled with ordered probit regression.  Independent variables may include the use or non-use of the drug as well as control variables such as age and details from medical history such as whether the patient suffers from high blood pressure, heart disease, etc. The dependent variable would be ranked from the following list: complete cure, relieve symptoms, no effect, deteriorate condition, death.

Another example application is the [[Likert scale]] commonly employed in survey research, where respondents rate their agreement on an ordered scale (e.g., "Strongly disagree" to "Strongly agree").  The ordered probit model provides an appropriate fit to these data, preserving the ordering of response options while making no assumptions of the interval distances between options. &lt;ref name="Liddell"&gt;{{cite journal|last1=Liddell|first1=T|last2=Kruschke|first2=J|title=Analyzing ordinal data with metric models: What could possibly go wrong?|journal=Journal of Experimental Social Psychology|date=2018|volume=79|pages=328-348|doi=10.1016/j.jesp.2018.08.009}}&lt;/ref&gt;

==Conceptual underpinnings==

Suppose the underlying relationship to be characterized is&lt;ref&gt;{{cite book |last=Greene |first=William H. |authorlink=William Greene (economist) |title=Econometric Analysis |edition=Seventh |location=Boston |publisher=Pearson Education |year=2012 |isbn=978-0-273-75356-8 |pages=827–831 }}&lt;/ref&gt;

:&lt;math&gt;y^* = \mathbf{x}^{\mathsf{T}} \beta + \epsilon&lt;/math&gt;,

where &lt;math&gt;y^*&lt;/math&gt; is the exact but unobserved dependent variable (perhaps the exact level of improvement by the patient); &lt;math&gt;\mathbf{x}&lt;/math&gt; is the vector of independent variables, and &lt;math&gt;\beta&lt;/math&gt; is the vector of regression coefficients which we wish to estimate.  Further suppose that while we cannot observe &lt;math&gt;y^*&lt;/math&gt;, we instead can only observe the categories of response:

:&lt;math&gt; y= \begin{cases}
0~~ \text{if}~~y^* \le 0, \\
1~~ \text{if}~~0&lt;y^* \le \mu_1, \\
2~~ \text{if}~~\mu_1 &lt;y^* \le \mu_2 \\
\vdots \\
N~~ \text{if}~~ \mu_{N-1} &lt; y^*.
\end{cases}&lt;/math&gt;

Then the ordered probit technique will use the observations on &lt;math&gt;y&lt;/math&gt;, which are a form of censored data on &lt;math&gt;y^*&lt;/math&gt;, to fit the parameter vector &lt;math&gt;\beta&lt;/math&gt;.

==Estimation==
{{expand section|date=February 2017}}

The model cannot be consistently estimated using [[ordinary least squares]]; it is usually estimated using [[maximum likelihood]]. For details on how the equation is  estimated, see the article [[Ordinal regression]].

==References==
{{Reflist}}

==Further reading==
* {{cite journal |first=William E. |last=Becker |first2=Peter E. |last2=Kennedy |authorlink2=Peter Kennedy (economist) |title=A Graphical Exposition of the Ordered Probit |journal=Econometric Theory |volume=8 |issue=1 |year=1992 |pages=127–131 |doi=10.1017/S0266466600010781 }}

[[Category:Categorical regression models]]

{{Statistics-stub}}</text>
      <sha1>ae6g85mengqxyl2v2dxvaiifujt2s1p</sha1>
    </revision>
  </page>
  <page>
    <title>Pierre Rosenstiehl</title>
    <ns>0</ns>
    <id>7004401</id>
    <revision>
      <id>860654988</id>
      <parentid>840210465</parentid>
      <timestamp>2018-09-22T05:12:43Z</timestamp>
      <contributor>
        <username>Icem4k</username>
        <id>15680220</id>
      </contributor>
      <minor/>
      <comment>Link to wife in the English Wikipedia</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2458">[[Image:Pierre Rosenstiehl.jpg|300px|thumb|right|Pierre Rosenstiehl]]
'''Pierre Rosenstiehl''' (born 1933) is a [[French people|French]] [[mathematician]] recognized for his work in [[graph theory]], [[planar graph]]s, and [[graph drawing]].

The [[Fraysseix-Rosenstiehl's planarity criterion]] is at the origin of the '''left-right planarity algorithm''' implemented in [http://pigale.sourceforge.net Pigale] software, which is considered as the fastest implemented [[planarity testing]] algorithm.&lt;ref name="PQ"&gt;{{cite conference|author1=J.M. Boyer |author2=P.F. Cortese |author3=M. Patrignani |author4=G. Di Battista.  |last-author-amp=yes | title=Stop minding your P’s and Q’s : implementing fast and simple DFS-based planarity and embedding algorithm | booktitle=[[International Symposium on Graph Drawing|Proc. Int. Symp. Graph Drawing (GD 2003)]] |publisher=Springer-Verlag, Lecture Notes in Computer Science, vol. 2912 | year=2004 | pages=25–36}}&lt;/ref&gt;

Rosenstiehl was directeur d’études at the [[École des Hautes Études en Sciences Sociales]] in [[Paris]], before his retirement.&lt;ref&gt;[http://8fcc.lri.fr/wp-content/documents/retired_researchers.pdf Recently retired researchers], 8th French Combinatorial Conference, 2010, retrieved 2012-07-27.&lt;/ref&gt; He is co-editor in chief of the [[European Journal of Combinatorics]].&lt;ref&gt;{{citation|title=Editorial board|journal=European Journal of Combinatorics|volume=33|issue=8|year=2012|doi=10.1016/S0195-6698(12)00115-1}}.&lt;/ref&gt; Rosenstiehl, Giuseppe Di Battista, [[Peter Eades]] and [[Roberto Tamassia]] organized in 1992 at Marino ([[Italy]]) a meeting devoted to [[graph drawing]] which initiated a long series of international conferences, the [[International Symposium on Graph Drawing|International Symposia on Graph Drawing]].

He has been a member of the French literary group [[Oulipo]] since 1992. He married the French author and illustrator [[Agnès Rosenstiehl]].

==References==
{{reflist}}

{{Authority control}}

{{DEFAULTSORT:Rosenstiehl, Pierre}}
[[Category:1933 births]]
[[Category:Living people]]
[[Category:Oulipo members]]
[[Category:20th-century French mathematicians]]
[[Category:21st-century French mathematicians]]
[[Category:Graph theorists]]
[[Category:Graph drawing people]]
[[Category:Researchers in geometric algorithms]]
[[Category:Academic journal editors]]
[[Category:School for Advanced Studies in the Social Sciences faculty]]


{{France-mathematician-stub}}</text>
      <sha1>suqzpwtqrjyij46qf2s482snw5szrc4</sha1>
    </revision>
  </page>
  <page>
    <title>Proof sketch for Gödel's first incompleteness theorem</title>
    <ns>0</ns>
    <id>9142932</id>
    <revision>
      <id>855520707</id>
      <parentid>824580896</parentid>
      <timestamp>2018-08-18T22:40:30Z</timestamp>
      <contributor>
        <username>Uanfala</username>
        <id>11049176</id>
      </contributor>
      <comment>/* top */ rm irrelevant template message</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24165">This article gives a sketch of a proof of '''[[Gödel's incompleteness theorems#First incompleteness theorem|Gödel's first incompleteness theorem]]'''. This theorem applies to any formal theory that satisfies certain technical hypotheses, which are discussed as needed during the sketch. We will assume for the remainder of the article that a fixed theory satisfying these hypotheses has been selected.

Throughout this article the word "number" refers to a [[natural number]].  The key property these numbers possess is that any natural number can be obtained by starting with the number 0 and adding 1 a finite number of times.

== Hypotheses of the theory ==
Gödel's theorem applies to any formal theory that satisfies certain properties. Each [[Formal system|formal theory]] has a [[signature (logic)|signature]] that specifies the nonlogical symbols in the language of the theory.  For simplicity, we will assume that the language of the theory is composed from the following collection of 15 (and only 15) symbols:

* A constant symbol {{math|'''0'''}} for zero.
* A unary function symbol {{math|'''S'''}} for the [[Successor function|successor operation]] and two binary function symbols '''+''' and '''×''' for addition and multiplication.
* Three symbols for logical conjunction, {{math|'''∧'''}}, disjunction, {{math|'''∨'''}}, and negation, '''¬'''.
* Two symbols for universal, {{math|'''∀'''}}, and existential, {{math|'''∃'''}}, [[Quantifier (logic)|quantifiers]].
* Two symbols for binary relations, '''=''' and '''&lt;''', for equality and order (less than).
* Two symbols for left, {{math|'''('''}} and right, {{math|''')'''}} parentheses for establishing precedence of quantifiers.
* A single variable symbol, {{math|'''x'''}} and a distinguishing symbol {{math|'''*'''}} that can be used to construct additional variables of the form ''x*'', ''x**'', ''x***'', ...

This is the language of [[Peano arithmetic]].  A [[well-formed formula]] is a sequence of these symbols that is formed so as to have a well-defined reading as a mathematical formula. Thus {{math|''x'' {{=}} ''SS''0}}  is well formed while {{math|''x'' {{=}} ∀+}} is not well formed. A theory is a set of well-formed formulas with no [[free variable]]s.

A theory is [[consistency proof|consistent]] if there is no formula {{math|''F''}} such that both {{math|''F''}} and its negation are provable.  [[omega-consistent|&amp;omega;-consistency]] is a stronger property than consistency.  Suppose that {{math|''F''(''x'')}} is a formula with one free variable {{math|''x''}}.  In order to be &amp;omega;-consistent,  the theory cannot prove both {{math|∃''m'' ''F''(''m'')}} while also proving {{math|¬''F''(''n'')}} for each natural number {{math|''n''}}.

The theory is assumed to be effective, which means that the set of axioms must be [[recursively enumerable]].  This means that it is theoretically possible to write a finite-length computer program that, if allowed to run forever, would output the axioms of the theory (necessarily including every well-formed instance of the [[Peano axioms#First-order theory of arithmetic|axiom schema of induction]]) one at a time and not output anything else. This requirement is necessary; there are theories that are [[Completeness (logic)|complete]], consistent, and include elementary arithmetic, but no such theory can be effective.

== Outline of the proof ==

: ''For a simplified outline of the proof, see [[Gödel's incompleteness theorems]]''

The sketch here is broken into three parts.  In the first part, each formula of the theory is assigned a number, known as a Gödel number, in a manner that allows the formula to be effectively recovered from the number. This numbering is extended to cover finite sequences of formulas. In the second part, a specific formula {{math|''PF''(''x'', ''y'')}} is constructed such that for any two numbers {{math|''n''}} and {{math|''m'', ''PF''(''n'',''m'')}} holds if and only if {{math|''n''}} represents a sequence of formulas that constitutes a proof of the formula that {{math|''m''}} represents.  In the third part of the proof, we construct a self-referential formula that, informally, says "I am not provable", and prove that this sentence is neither provable nor disprovable within the theory.

Importantly, all the formulas in the proof can be defined by [[primitive recursive function]]s, which themselves [[Primitive_recursive_function#Use_in_first-order_Peano_arithmetic|can be defined]] in [[first-order logic|first-order]] [[Peano arithmetic]].

== Gödel numbering ==

The first step of the proof is to represent (well-formed) formulas of the theory, and finite lists of these formulas, as natural numbers. These numbers are called the '''[[Gödel number]]s''' of the formulas.

Begin by assigning a natural number to each symbol of the language of arithmetic, similar to the manner in which the [[ASCII]] code assigns a unique binary number to each letter and certain other characters. This article will employ the following assignment, very similar to the one [[Douglas Hofstadter]] used in his ''[[Gödel, Escher, Bach]]'':

{|
|- valign=top
| style="padding-right:60px" |

{| class="wikitable" style="text-align: center;"
|-
! Number !! Symbol !! Meaning
|-
| 666 || 0 || zero
|-
| 123 || {{math|S}} || successor function
|-
| 111 || = || equality relation
|-
| 212 || &lt; || less than relation
|-
| 112 || + || addition operator
|-
| 236 || ✕ || multiplication operator
|-
| 362 || ( || left parenthesis
|-
| 323 || ) || right parenthesis
|}

|

{| class="wikitable" style="text-align: center;"
|-
! Number !! Symbol !! Meaning
|-
| 262 || {{math|''x''}} || a variable name
|-
| 163 || * || star (used to make more variables)
|-
| 333 || ∃ || existential quantifier
|-
| 626 || ∀ || for all
|-
| 161 || ∧ || logical and
|-
| 616 || ∨ || logical or
|-
| 223 || ¬ || logical not
|}

|}

The Gödel number of a formula is obtained by concatenating the Gödel numbers of each symbol making up the formula. The Gödel numbers for each symbol are separated by a zero because by design, no Gödel number of a symbol includes a {{math|0}}. Hence any formula may be correctly recovered from its Gödel number. Let {{math|''G''(''F'')}} denote the Gödel number of the formula {{math|''F''}}.

Given the above Gödel numbering, the sentence asserting that addition [[commutativity|commutes]], {{math|∀''x'' ∀''x''* (''x'' + ''x''* {{=}} ''x''* + ''x'')}} translates as the number:

: {{math|626 0 262 0 626 0 262 0 163 0 362 0 262 0 112 0 262 0 163 0 111 0 262 0 163 0 112 0 262 0 323}}

(Spaces have been inserted on each side of every 0 only for readability; Gödel numbers are strict concatenations of decimal digits.)  Not all natural numbers represent a formula. For example, the number

: {{math|111 0 626 0 112 0 262}}

translates to "{{math|{{=}} ∀ + ''x''}}", which is not well-formed.

Because each natural number can be obtained by applying the [[Successor (graph theory)|successor]] operation {{math|''S''}} to {{math|0}} a finite number of times, every natural number has its own Gödel number. For example, the Gödel number corresponding to {{math|4, ''SSSS''0}}, is:

: {{math|123 0 123 0 123 0 123 0 666}}.

The assignment of Gödel numbers can be extended to finite lists of formulas. To obtain the Gödel number of a list of formulas, write the Gödel numbers of the formulas in order, separating them by two consecutive zeros. Since the Gödel number of a formula never contains two consecutive zeros, each formula in a list of formulas can be effectively recovered from the Gödel number for the list.

It is crucial that the formal arithmetic be capable of proving a minimum set of facts. In particular, it must be able to prove that every number has a Gödel number. A second fact that the theory must prove is that given any Gödel number of a formula {{math|''F''(''x'')}} with one free variable {{math|''x''}} and any number {{math|''m''}}, there is a Gödel number of the formula {{math|''F''(''m'')}} obtained by replacing all occurrences of {{math|''G''(''x'')}} in {{math|''G''(''F''(''x''))}} with {{math|''G''(''m'')}}, and that this second Gödel number can be effectively obtained from the Gödel number of {{math|''F''}} as a function of {{math|''m''}}. To see that this is in fact possible, note that given the Gödel number for {{math|''F''}}, one can recreate the original formula, make the substitution, and then find the Gödel number of the resulting formula. This is a uniform procedure.

== The provability relation ==

Deduction rules can then be represented by binary relations on Gödel numbers of lists of formulas.  In other words, suppose that there is a deduction rule {{math|''D''&lt;sub&gt;1&lt;/sub&gt;}}, by which one can move from the formulas {{math|''S''&lt;sub&gt;1&lt;/sub&gt;,''S''&lt;sub&gt;2&lt;/sub&gt;}} to a new formula {{math|''S''}}.  Then the relation {{math|''R''&lt;sub&gt;1&lt;/sub&gt;}} corresponding to this deduction rule says that {{math|''n''}} is related to {{math|''m''}} (in other words, {{math|''n'' ''R''&lt;sub&gt;1&lt;/sub&gt;''m''}} holds) if {{math|''n''}} is the Gödel number of a list of formulas containing {{math|''S''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''S''&lt;sub&gt;2&lt;/sub&gt;}} and {{math|''m''}} is the Gödel number of the list of formulas consisting of those in the list coded by {{math|''n''}} together with {{math|''S''}}.  Because each deduction rule is concrete, it is possible to effectively determine for any natural numbers {{math|''n''}} and {{math|''m''}} whether they are related by the relation.

The second stage in the proof is to use the Gödel numbering, described above, to show that the notion of provability can be expressed within the formal language of the theory. Suppose the theory has deduction rules: {{math|''D''&lt;sub&gt;1&lt;/sub&gt;, ''D''&lt;sub&gt;2&lt;/sub&gt;, ''D''&lt;sub&gt;3&lt;/sub&gt;, &amp;hellip;}} . Let {{math|''R''&lt;sub&gt;1&lt;/sub&gt;, ''R''&lt;sub&gt;2&lt;/sub&gt;, ''R''&lt;sub&gt;3&lt;/sub&gt;, &amp;hellip;}} be their corresponding relations, as described above.

Every provable statement is either an axiom itself, or it can be deduced from the axioms by a finite number of applications of the deduction rules. We wish to define a set of numbers {{math|''P''}} that represents all these provable statements. We define {{math|''P''}} as the minimal set consisting of all numbers in {{math|''AX''}} (representing axioms) and closed under all the relations {{math|''R''&lt;sub&gt;1&lt;/sub&gt;, ''R''&lt;sub&gt;2&lt;/sub&gt;, &amp;hellip;}} .  This means that whenever {{math|''n''}} is in the set {{math|''P''}} and {{math|''n'' ''R''&lt;sub&gt;i&lt;/sub&gt; ''m''}} for some numbers {{math|''m''}}  and {{math|''i''}}, the number {{math|''m''}} is also in the set {{math|''P''}}.  It is not hard to see that {{math|''P''}} represents the set of provable statements. That is, the members of {{math|''P''}} are the [[Gödel number]]s of the provable statements.
&lt;!-- 
Comment: This is not really necessary - it is clear from the above that any formula has a Godel number, including {{math|''x''}} as many times as is desired

Let {{math|''F''(''x'')}} be a formula with one free variable {{math|''x''}}. An example to such a statement is {{math|∃''y'' (''y'' + ''y'' {{=}} ''x'')}}. We will discuss such statements of the form: "for every {{math|''y'', ''x'' {{=}} ''y''}} implies…" (a statement on {{math|''y''}}). Thus instead of "{{math|''x''}} is even" we will have "for every {{math|''y'', ''x'' {{=}} ''y''}} implies {{math|''y''}} is even". In such a way, {{math|''x''}} appears within {{math|''F''(''x'')}} only in a prefixed location, and one may define the [[Gödel number]] {{math|''G''(''F'')}} of every such {{math|''F''(''x'')}} (and independently of {{math|''x''}}) by the [[Gödel number]] of the statement on {{math|''y''}}. Then, {{math|''G''(''F''(''n''))}} can be constructed from the [[Gödel number]]s of "for every {{math|''y''", ''x'', "{{=}}''y''}} implies" and {{math|''G''(''F'')}}.
 --&gt;

A proof of a formula {{math|''S''}} is itself a string of mathematical statements related by  particular relations (each is either an axiom or related to former statements by deduction rules), where the last statement is {{math|''S''}}. Thus one can define the [[Gödel number]] of a proof. Moreover, one may define a statement form {{math|''PF''(''x'',''y'')}}, which for every two numbers {{math|''x''}} and {{math|''y''}} is provable if and only if {{math|''x''}} is the [[Gödel number]] of a proof of the statement {{math|''S''}} and {{math|''y'' {{=}} ''G''(''S'')}}.

{{math|''PF''(''x'',''y'')}} is in fact an arithmetical relation, just as "{{math|''x'' + ''y'' {{=}} 6}}" is, though a (much) more complicated one. Given such a relation {{math|''R''(''x'',''y'')}}, for any two specific numbers {{math|''n''}} and {{math|''m''}}, either the formula {{math|''R''(''m'',''n'')}}, or its negation {{math|¬''R''(''m'',''n'')}}, but not both, is provable. This is because the relation between these two numbers can be simply "checked". Formally this can be proven by induction, where all these possible relations (which are of infinite number) are constructed one by one.
The detailed construction of the formula {{math|''PF''}} makes essential use of the assumption that the theory is effective; it would not be possible to construct this formula without such an assumption.

== Self-referential formula ==

For every number {{math|''n''}} and every formula {{math|''F''(''y'')}}, where {{math|''y''}} is a free variable,  we define {{math|''q''(''n'', ''G''(''F''))}}, a relation between two numbers {{math|''n''}} and {{math|''G''(''F'')}}, such  that it corresponds to the statement "{{math|''n''}} is not the Gödel number of a proof of {{math|''F''(''G''(''F''))}}". Here, {{math|''F''(''G''(''F''))}} can be understood as {{math|''F''}} with its own Gödel number as its argument.

Note that {{math|''q''}} takes as an argument {{math|''G''(''F'')}}, the Gödel number of {{math|''F''}}. In order to prove either {{math|''q''(''n'', ''G''(''F''))}}, or {{math|¬''q''(''n'', ''G''(''F''))}}, it is necessary to perform number-theoretic operations on {{math|''G''(''F'')}} that mirror the following steps: decode the number {{math|''G''(''F'')}} into the formula {{math|''F''}}, replace all occurrences of {{math|''y''}} in {{math|''F''}} with the number {{math|''G''(''F'')}}, and then compute the Gödel number of the resulting formula {{math|''F''(''G''(''F''))}}.

Note that for every specific number {{math|''n''}} and formula {{math|''F''(''y''), ''q''(''n'', ''G''(''F''))}} is a straightforward (though complicated) arithmetical relation between two numbers {{math|''n''}} and {{math|''G''(''F'')}}, building on the relation {{math|''PF''}} defined earlier. Further, {{math|''q''(''n'', ''G''(''F''))}}  is provable if the finite list of formulas encoded by {{math|''n''}} is not a proof of {{math|''F''(''G''(''F''))}}, and {{math|¬''q''(''n'', ''G''(''F''))}} is provable if the finite list of formulas encoded by {{math|''n''}} is a proof of {{math|''F''(''G''(''F''))}}. Given any numbers {{math|''n''}} and {{math|''G''(''F'')}}, either {{math|''q''(''n'', ''G''(''F''))}} or {{math|¬''q''(''n'',''G''(''F''))}} (but not both) is provable.

Any proof of {{math|''F''(''G''(''F''))}} can be encoded by a Gödel number {{math|''n''}}, such that {{math|''q''(''n'', ''G''(''F''))}} does not hold. If {{math|''q''(''n'', ''G''(''F''))}} holds for all natural numbers {{math|''n''}}, then there is no proof of {{math|''F''(''G''(''F''))}}. In other words,  {{math|∀''y'' ''q''(''y'', ''G''(''F''))}}, a formula about natural numbers, corresponds to "there is no proof of {{math|''F''(''G''(''F''))}}".

We now define the formula {{math|''P''(''x'') {{=}} ∀''y'' ''q''(''y'', ''x'')}}, where {{math|''x''}} is a free variable. The formula {{math|''P''}} itself has a Gödel number {{math|''G''(''P'')}} as does every formula.

This formula has a free variable {{math|''x''}}. Suppose we replace it with {{math|''G''(''F'')}},
the Gödel number of a formula {{math|''F''(''z'')}}, where {{math|''z''}} is a free variable. Then, {{math|''P''(''G''(''F'')) {{=}} ∀''y'' ''q''(''y'', ''G''(''F''))}} corresponds to "there is no proof of {{math|''F''(''G''(''F''))}}", as we have seen.

Consider the formula {{math|''P''(''G''(''P'')) {{=}} ∀''y'', ''q''(''y'', ''G''(''P''))}}. This formula concerning the number {{math|''G''(''P'')}} corresponds to "there is no proof of {{math|''P''(''G''(''P''))}}". We have here the self-referential feature that is crucial to the proof: A formula of the formal theory that somehow relates to its own provability within that formal theory. Very informally, {{math|''P''(''G''(''P''))}} says: "I am not provable".

We will now show that neither the formula {{math|''P''(''G''(''P''))}}, nor its negation {{math|¬''P''(''G''(''P''))}},  is provable.

Suppose {{math|''P''(''G''(''P'')) {{=}} ∀''y'', ''q''(''y'', ''G''(''P''))}} is provable. Let {{math|''n''}} be the Gödel number of a proof of {{math|''P''(''G''(''P''))}}. Then, as seen earlier, the formula {{math|¬''q''(''n'', ''G''(''P''))}}  is provable. Proving both {{math|¬''q''(''n'', ''G''(''P''))}} and {{math|∀''y'' ''q''(''y'', ''G''(''P''))}} violates the [[consistency]] of the formal theory. We therefore conclude that {{math|''P''(''G''(''P''))}} is not provable.

Consider any number {{math|''n''}}. Suppose {{math|¬''q''(''n'', ''G''(''P''))}} is provable.
Then, {{math|''n''}} must be the Gödel number of a proof of {{math|''P''(''G''(''P''))}}. But we have just proved that {{math|''P''(''G''(''P''))}} is not provable. Since either {{math|''q''(''n'', ''G''(''P''))}} or {{math|¬''q''(''n'', ''G''(''P''))}} must be provable, we conclude that, for all natural numbers {{math|''n'', ''q''(''n'', ''G''(''P''))}} is provable.

Suppose the negation of {{math|''P''(''G''(''P''))}}, {{math|¬''P''(''G''(''P'')) {{=}} ∃''x'' ¬ ''q''(''x'', ''G''(''P''))}}, is provable. Proving both {{math|∃''x'' ¬''q''(''x'', ''G''(''P''))}}, and {{math|''q''(''n'', ''G''(''P''))}}, for all natural numbers {{math|''n''}}, violates  [[omega-consistent|&amp;omega;-consistency]] of the formal theory. Thus if the theory is [[omega-consistent|&amp;omega;-consistent]], {{math|¬''P''(''G''(''P''))}} is not provable.

We have sketched a proof showing that:

For any formal, recursively enumerable (i.e. effectively generated) theory of [[Peano Arithmetic]],

: if it is [[consistent]], then there exists an unprovable formula (in the language of that theory).

: if it is [[omega-consistent|&amp;omega;-consistent]], then there exists a formula such that both it and its negation are unprovable.

=== The truth of the Gödel sentence ===

The proof of Gödel's incompleteness theorem just sketched is '''proof-theoretic''' (also called '''syntactic''') in that it shows that if certain proofs exist (a proof of {{math|''P''(''G''(''P''))}} or its negation) then they can be manipulated to produce a proof of a contradiction.  This makes no appeal to whether {{math|''P''(''G''(''P''))}} is "true", only to whether it is provable. Truth is a '''[[Model theory|model-theoretic]]''', or '''semantic''', concept, and is not equivalent to provability except in special cases.

By analyzing the situation of the above proof in more detail, it is possible to obtain a conclusion about the truth of {{math|''P''(''G''(''P''))}} in the standard model ℕ of natural numbers. As just seen, {{math|''q''(''n'', ''G''(''P''))}} is provable for each natural number {{math|''n''}}, and is thus true in the model ℕ. Therefore, within this model,

: &lt;math&gt;P(G(P)) = \forall y\,q(y, G(P))&lt;/math&gt;

holds. This is what the statement "{{math|''P''(''G''(''P''))}} is true" usually refers to&amp;mdash;the sentence is true in the intended model.  It is not true in every model, however: If it were, then by Gödel's [[completeness theorem]] it would be provable, which we have just seen is not the case.

== Boolos's short proof ==

[[George Boolos]] (1989) vastly simplified the proof of the First Theorem, if one agrees that the [[theorem]] is equivalent to:
&lt;blockquote&gt;
"There is no [[algorithm]] {{math|''M''}} whose output contains all true sentences of arithmetic and no false ones."
&lt;/blockquote&gt;
"Arithmetic" refers to [[Peano axioms|Peano]] or [[Robinson arithmetic]], but the proof invokes no specifics of either, tacitly assuming that these systems allow '&lt;' and '&amp;times;' to have their usual meanings. Boolos proves the theorem in about two pages. His proof employs the language of [[first-order logic]], but invokes no facts about the [[logical connective|connectives]] or [[Quantifier (logic)|quantifier]]s. The [[domain of discourse]] is the [[natural number]]s. The [[Gödel sentence]] builds on [[Berry's paradox]].

Let {{math|[''n'']}} abbreviate {{math|''n''}} successive applications of the [[successor function]], starting from {{math|0}}. Boolos then asserts (the details are only sketched) that there exists a defined predicate {{math|''Cxz''}} that comes out true [[iff]] an arithmetic formula containing {{math|''z''}} symbols names the number {{math|''x''}}. This proof sketch contains the only mention of [[Gödel number]]ing; Boolos merely assumes that every formula can be so numbered. Here, a formula {{math|''F'' }}''names'' the number {{math|''n''}} iff the following is provable:

: &lt;math&gt;\forall x (F(x) \leftrightarrow x=n)&lt;/math&gt;

Boolos then defines the related predicates:

* {{math|''Bxy'' &amp;harr; &amp;exist;''z''(''z''&amp;nbsp;&lt;&amp;nbsp;''y'' &amp;and; ''Cxz'')}}. (English: {{math|''Bxy''}} comes out true if {{math|''x''}} can be defined in fewer than {{math|''y''}} symbols):
* {{math|''Axy'' &amp;harr; &amp;not;''Bxy'' &amp;and; &amp;forall;''a''(''a''&amp;nbsp;&lt;&amp;nbsp;''x''&amp;rarr;''Bay'')}}. (English: {{math|''Axy''}} comes out true if {{math|''x''}} is the smallest number not definable in fewer than {{math|''y''}} symbols. More awkwardly, {{math|''Axy''}} holds if {{math|''x''}} cannot be defined in fewer than {{math|''y''}} symbols, and all numbers less than {{math|''x''}} can be defined using fewer than {{math|''y''}} symbols);
* {{math|''Fx'' &amp;harr; &amp;exist;''y''((''y''&amp;nbsp;{{=}}&amp;nbsp;[10] &amp;times; [''k'']) &amp;and; ''Axy'')}}. {{math|''k''&amp;nbsp;{{=}}&amp;nbsp;}}the number of symbols appearing in {{math|''Axy''}}.

{{math|''Fx''}} formalizes Berry's paradox. The balance of the proof, requiring but 12 lines of text, shows that the sentence {{math|&amp;forall;''x''(''Fx''&amp;harr;(''x''&amp;nbsp;{{=}}&amp;nbsp;[''n'']))}} is true for some number {{math|''n''}}, but no algorithm {{math|''M''}} will identify it as true. Hence in arithmetic, truth outruns proof. QED.

The above predicates contain the only [[existential quantifier]]s appearing in the entire proof. The '&lt;' and '&amp;times;' appearing in these predicates are the only defined arithmetical notions the proof requires. The proof nowhere mentions [[recursion#Functional recursion|recursive function]]s or any facts from [[number theory]], and Boolos claims that his proof dispenses with [[diagonal lemma|diagonalization]]. For more on this proof, see [[Berry's paradox]].

== References ==
* 1931, "Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme, I." ''Monatshefte für Mathematik und Physik 38'': 173&amp;ndash;98.
* English translations of the preceding:
** [[Jean van Heijenoort]], 1967. ''From Frege to Gödel: A Source Book on Mathematical Logic''. Harvard University Press: 596&amp;ndash;616.
** Hirzel, Martin (trans.), 2000, [http://www.research.ibm.com/people/h/hirzel/papers/canon00-goedel.pdf "On formally undecidable propositions of Principia Mathematica and related systems I."].
* 1951, "Some basic theorems on the foundations of mathematics and their implications" in [[Solomon Feferman]], ed., 1995. ''Collected works / Kurt Gödel, Vol. III''.  Oxford University Press: 304&amp;ndash;23.
* [[George Boolos]], 1998, "A New Proof of the Gödel Incompleteness Theorem" in Boolos, G., ''Logic, Logic, and Logic''. Harvard Univ. Press.

== External links ==

* [http://www.apronus.com/math/goedel.htm A concise proof of Gödel's Incompleteness Theorem.]

{{DEFAULTSORT:Proof sketch for Godel's first incompleteness theorem}}

[[Category:Mathematical logic]]
[[Category:Mathematical proofs]]</text>
      <sha1>h1f9e9s9gn1exnf4wk8vekpklys20hq</sha1>
    </revision>
  </page>
  <page>
    <title>Prototype-based programming</title>
    <ns>0</ns>
    <id>61003</id>
    <revision>
      <id>865091792</id>
      <parentid>862413461</parentid>
      <timestamp>2018-10-21T17:29:35Z</timestamp>
      <contributor>
        <username>Sarogers86</username>
        <id>34946476</id>
      </contributor>
      <comment>Javascript programming</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18690">{{Distinguish|prototype pattern|Software prototyping}}
{{Programming paradigms}}

'''Prototype-based programming''' is a style of [[object-oriented programming]] in which behaviour reuse (known as [[inheritance (programming)|inheritance]]) is performed via a process of reusing existing [[object (programming)|object]]s &lt;nowiki/&gt;via delegation that serve as [[prototype]]s. This model can also be known as ''prototypal'', ''prototype-oriented,'' ''classless'', or ''instance-based'' programming. [[delegation (object-oriented programming)|Delegation]] is the language feature that supports prototype-based programming.

Prototype object oriented programming uses generalized objects, which can then be cloned and extended. Using fruit as an example, a "fruit" object would represent the properties and functionality of fruit in general. A "banana" object would be cloned from the "fruit" object, and would also be extended to include general properties specific to bananas. Each individual "banana" object would be cloned from the generic "banana" object. Compare to the [[Class-based programming|class-based]] paradigm, where a "fruit" ''class'' would be extended by a "banana" ''class''.

The first prototype-oriented [[programming language]] was [[Self (programming language)|Self]], developed by [[David Ungar]] and [http://research.sun.com/people/randy/ Randall Smith] in the mid-1980s to research topics in object-oriented language design. Since the late 1990s, the classless paradigm has grown increasingly popular.{{Citation needed|date=June 2016}} Some current prototype-oriented languages are [[JavaScript]] (and other [[ECMAScript]] implementations such as [[JScript]] and [[Adobe Flash|Flash]]'s [[ActionScript]] 1.0), [[Lua (programming language)|Lua]], [[Cecil (programming language)|Cecil]], [[NewtonScript]], [[Io (programming language)|Io]], [[Ioke (programming language)|Ioke]], [[MOO (programming language)|MOO]], [[REBOL]], [[Lisaac]] and [[AutoHotkey|AHK]].

==Design and implementation==
Prototypal inheritance in JavaScript is described by [[Douglas Crockford]] as: "you make prototype objects, and then … make new instances. Objects are mutable in JavaScript, so we can augment the new instances, giving them new fields and methods. These can then act as prototypes for even newer objects. We don't need classes to make lots of similar objects… Objects inherit from objects. What could be more object oriented than that?"&lt;ref&gt;{{cite web|last=Crockford|first=Douglas|title=Prototypal Inheritance in JavaScript|url=http://javascript.crockford.com/prototypal.html|accessdate=20 August 2013}}&lt;/ref&gt;

Advocates of prototype-based programming argue that it encourages the programmer to focus on the behavior of some set of examples and only later worry about classifying these objects into archetypal objects that are later used in a fashion similar to [[class (programming)|classes]].&lt;ref name="Taivalsaari"/&gt;  Many prototype-based systems encourage the alteration of prototypes during [[Run time (program lifecycle phase)|run-time]], whereas only very few class-based object-oriented systems (such as the dynamic object-oriented system, [[Common Lisp]], [[Dylan (programming language)|Dylan]], [[Objective-C]], [[Perl]], [[Python (programming language)|Python]], [[Ruby (programming language)|Ruby]], or [[Smalltalk]]) allow classes to be altered during the execution of a program.

Almost all prototype-based systems are based on interpreted and [[dynamically typed]] languages. Systems based on [[statically typed]] languages are technically feasible, however. The Omega language discussed in ''Prototype-Based Programming''&lt;ref&gt;{{cite book | chapter = Section 2.8 | page = 177 | first = Günther | last = Blaschek | title = Omega: Statically Typed Prototypes }}&lt;/ref&gt; is an example of such a system, though according to Omega's website even Omega is not exclusively static, but rather its "compiler may choose to use static binding where this is possible and may improve the efficiency of a program."

==Object construction==
In prototype-based languages there are no explicit classes. Objects inherit directly from other objects through a prototype property. The prototype property is called &lt;tt&gt;prototype&lt;/tt&gt; in [[Self (programming language)|Self]] and [[JavaScript]], or &lt;tt&gt;proto&lt;/tt&gt; in [[Io (programming language)|Io]]. There are two methods of constructing new objects: ''[[ex nihilo]]'' ("from nothing") object creation or through ''cloning'' an existing object. The former is supported through some form of object [[Literal (computer programming)|literal]], declarations where objects can be defined at runtime through special syntax such as &lt;tt&gt;{...}&lt;/tt&gt; and passed directly to a variable. While most systems support a variety of cloning, ''ex nihilo'' object creation is not as prominent.&lt;ref&gt;{{cite book | chapter = Section 1.2 | page = 17 | first1 = Chistophe | last1 = Dony | first2 = Jacques | last2 = Malenfan | first3 = Daniel | last3 = Bardou | chapterurl = http://www.lirmm.fr/~dony/postscript/proto-book.pdf | title = Classifying Prototype-based Programming Languages }}&lt;/ref&gt;

In class-based languages, a new instance is constructed through a class's [[constructor (computer science)|constructor function]], a special function that reserves a block of memory for the object's members (properties and methods) and returns a reference to that block. An optional set of constructor [[parameter (computer science)|arguments]] can be passed to the function and are usually held in properties. The resulting instance will inherit all the methods and properties that were defined in the class, which acts as a kind of template from which similar typed objects can be constructed.

Systems that support ''ex nihilo'' object creation allow new objects to be created from scratch without cloning from an existing prototype. Such systems provide a special syntax for specifying the properties and behaviors of new objects without referencing existing objects. In many prototype languages there exists a root object, often called ''Object'', which is set as the default prototype for all other objects created in run-time and which carries commonly needed methods such as a &lt;tt&gt;toString()&lt;/tt&gt; function to return a description of the object as a string. One useful aspect of ''ex nihilo'' object creation is to ensure that a new object's slot (properties and methods) names do not have [[namespace]] conflicts with the top-level ''Object'' object. (In the [[JavaScript]] language, one can do this by using a null prototype, i.e. &lt;tt&gt;Object.create(null)&lt;/tt&gt;.)

''Cloning'' refers to a process whereby a new object is constructed by copying the behavior of an existing object (its prototype). The new object then carries all the qualities of the original. From this point on, the new object can be modified. In some systems the resulting child object maintains an explicit link (via ''[[delegation (object-oriented programming)|delegation]]'' or ''[[resemblance (programing)|resemblance]]'') to its prototype, and changes in the prototype cause corresponding changes to be apparent in its clone. Other systems, such as the [[Forth (programming language)|Forth]]-like programming language [[Kevo (programming language)|Kevo]], do not propagate change from the prototype in this fashion, and instead follow a more ''concatenative'' model where changes in cloned objects do not automatically propagate across descendants.&lt;ref name="Taivalsaari"&gt;{{cite book | chapter = Section 1.1 | page = 14 | first = Antero | last = Taivalsaari | title = Classes vs. Prototypes: Some Philosophical and Historical Observations | citeseerx = 10.1.1.56.4713 }}&lt;/ref&gt;

&lt;source lang=JavaScript&gt;
// Example of true prototypal inheritance style 
// in JavaScript.

// object creation using the literal 
// object notation {}.
var foo = {name: "foo", one: 1, two: 2};

// Another object.
var bar = {two: "two", three: 3};

// Object.setPrototypeOf() is a method introduced in ECMAScript 2015.
// For the sake of simplicity, let us pretend 
// that the following line works regardless of the 
// engine used:
Object.setPrototypeOf(bar, foo); // foo is now the prototype of bar.

// If we try to access foo's properties from bar 
// from now on, we'll succeed. 
bar.one // Resolves to 1.

// The child object's properties are also accessible.
bar.three // Resolves to 3.

// Own properties shadow prototype properties
bar.two; // Resolves to "two"
bar.name; // unaffected, resolves to "foo"
foo.name; // Resolves to "foo"
&lt;/source&gt;

This example in JS 1.8.5+ (see https://kangax.github.com/es5-compat-table/)
&lt;source lang=JavaScript&gt;
var foo = {one: 1, two: 2};

// bar.[[prototype]] = foo
var bar = Object.create(foo);

bar.three = 3;

bar.one; // 1
bar.two; // 2
bar.three; // 3
&lt;/source&gt;

==Delegation==
In prototype-based languages that use ''delegation'', the language runtime is capable of [[dynamic dispatch|dispatching]] the correct method or finding the right piece of data simply by following a series of delegation pointers (from object to its prototype) until a match is found. All that is required to establish this behavior-sharing between objects is the delegation pointer. Unlike the relationship between class and instance in class-based object-oriented languages, the relationship between the prototype and its offshoots does not require that the child object have a memory or structural similarity to the prototype beyond this link. As such, the child object can continue to be modified and amended over time without rearranging the structure of its associated prototype as in class-based systems. It is also important to note that not only data, but also methods can be added or changed. For this reason, some prototype-based languages refer to both data and methods as "slots" or "members".{{Citation needed|reason=Sentence needs at least 1 citation. I've coded professionally in JS(all variants) &amp; ActionScript for 4 years, and I've NEVER seen "slots" used this way in JS, and rarely in AS. E.g. see inconsistent/nonexistent usage in following: [http://www.google.com/#q=javascript+methods+properties+slots&amp;hl=en&amp;pws=0&amp;biw=1247&amp;bih=673&amp;site=webhp&amp;fp=528dfc887ad8eb4a&amp;bav=on.2,or.r_gc.r_pw.,cf.osb&amp;cad=b] &amp; [http://www.google.com/#q=actionscript+methods+properties+slots&amp;hl=en&amp;pws=0&amp;biw=1247&amp;bih=673&amp;site=webhp&amp;fp=1&amp;bav=on.2,or.r_gc.r_pw.,cf.osb&amp;cad=b] . I'm calling 'Citation-needing', if not 'Dubious'.|date=January 2012}}

==Concatenation==
In ''concatenative'' prototyping - the approach implemented by the Kevo programming language - there are no visible pointers or links to the original prototype from which an object is cloned. The prototype (parent) object is copied rather than linked to and there is no delegation. As a result, changes to the prototype will not be reflected in cloned objects.&lt;ref name=Taivalsaar&gt;{{cite web | url = http://lively.cs.tut.fi/ | title = Simplifying JavaScript with Concatenation-Based Prototype Inheritance | author = Antero Taivalsaar | authorlink = | language = English | publisher = Tampere University of Technology | date = 2009 | archiveurl = http://lively.cs.tut.fi/publications/TR6-JavaScriptConcatenation-Taivalsaari.pdf | archivedate = 2009 | quote = Kevo implemented a pure concatenation-based object model in which new objects were created by copying and the namespaces of all the objects were always fully self-contained. … Furthermore, Kevo had an internal ''clone family'' mechanism that made it possible to track the “genealogy” of changes among groups of objects, so that changes to individual objects could be propagated to other objects when necessary. | accessdate = 2015-03-11}}&lt;/ref&gt;

The main conceptual difference under this arrangement is that changes made to a prototype object are not automatically propagated to clones. This may be seen as an advantage or disadvantage. (However, Kevo does provide additional primitives for publishing changes across sets of objects based on their similarity — so-called ''family resemblances'' or ''clone family'' mechanism&lt;ref name=Taivalsaar /&gt; — rather than through taxonomic origin, as is typical in the delegation model.) It is also sometimes claimed that delegation-based prototyping has an additional disadvantage in that changes to a child object may affect the later operation of the parent. However, this problem is not inherent to the delegation-based model and does not exist in delegation-based languages such as JavaScript, which ensure that changes to a child object are always recorded in the child object itself and never in parents (i.e. the child's value shadows the parent's value rather than changing the parent's value).

In simplistic implementations, concatenative prototyping will have faster member lookup than delegation-based prototyping (because there is no need to follow the chain of parent objects), but will conversely use more memory (because all slots are copied, rather than there being a single slot pointing to the parent object). More sophisticated implementations can avoid these problems, however, although trade-offs between speed and memory are required. For example, systems with concatenative prototyping can use a [[copy-on-write]] implementation to allow for behind-the-scenes data sharing — and such an approach is indeed followed by Kevo.&lt;ref&gt;{{cite journal | first = Antero | last = Taivalsaari | title = Kevo, a prototype-based object-oriented programming language based on concatenation and module operations | journal = Technical Report Report LACIR 92-02 | publisher = University of Victoria | year = 1992 }}&lt;/ref&gt; Conversely, systems with delegation-based prototyping can use [[cache (computing)|caching]] to speed up data lookup.

==Criticism==
Advocates of class-based object models who criticize prototype-based systems often have concerns similar to the concerns that proponents of static type systems for programming languages have of dynamic type systems (see [[datatype]]). Usually, such concerns involve: [[correctness (computer science)|correctness]], [[type safety|safety]], [[predictability]], [[algorithmic efficiency|efficiency]] and programmer unfamiliarity.

On the first three points, classes are often seen as analogous to types (in most statically typed object-oriented languages they serve that role) and are proposed to provide contractual guarantees to their instances, and to users of their instances, that they will behave in some given fashion.

Regarding efficiency, declaring classes simplifies many [[compiler]] optimizations that allow developing efficient method and instance-variable lookup. For the [[Self (programming language)|Self]] language, much development time was spent on developing, compiling, and interpreting techniques to improve the performance of prototype-based systems versus class-based systems.

A common criticism made against prototype-based languages is that the community of [[software developer]]s is unfamiliar with them, despite the popularity and market permeation of [[JavaScript]]. This knowledge level of prototype-based systems seems to be increasing with the proliferation of [[JavaScript framework]]s and the complex use of JavaScript as the [[World Wide Web|Web]] matures.&lt;ref&gt;{{Cite news|url=https://alistapart.com/article/prototypal-object-oriented-programming-using-javascript|title=Prototypal Object-Oriented Programming using JavaScript|date=2016-04-26|work=A List Apart|access-date=2018-10-21|language=en-US}}&lt;/ref&gt;{{citation needed|date=March 2013}} ECMAScript 6 introduced classes as [[syntactic sugar]] over JavaScript's existing prototype-based inheritance, providing an alternative way to create objects and deal with inheritance.&lt;ref&gt;{{cite web|title=Classes|url=https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes|website=JavaScript reference|publisher=Mozilla Developer Network|accessdate=9 February 2016}}&lt;/ref&gt;

==Languages supporting prototype-based programming==
* [[Actor-Based Concurrent Language]] (ABCL): [[ABCL/1]], [[ABCL/R]], [[ABCL/R2]], [[ABCL/c plus|ABCL/c+]]
* [[Agora (programming language)|Agora]]
* [[AutoHotkey]]
* [[Cecil (programming language)|Cecil]] and [[Diesel (programming language)|Diesel]] of [[Craig Chambers]]
* [[ColdC]]
* [[COLA (software architecture)|COLA]]
* [[Common Lisp]]
* [[ECMAScript]]
** [[ActionScript]] 1.0, used by [[Adobe Flash]] and [[Adobe Flex]]
** [[E4X]]
** [[JavaScript]]
** [[JScript]]
* [[Falcon (programming language)|Falcon]]
* [[Io (programming language)|Io]]
* [[Ioke (programming language)|Ioke]]
* [[Lisaac]]
* [[Logtalk]]
* [[LPC (programming language)|LPC]]
* [[Lua (programming language)|Lua]]
* [[M2000 Interpreter (programming language)|M2000]]
* [[Maple (software)|Maple]]
* [[MOO (programming language)|MOO]]
* [[Neko (programming language)|Neko]]
* [[NewtonScript]]
* [[Object Lisp]]
* [[Obliq]]
* [[Omega (programming language)|Omega]]
* [[OpenLaszlo]]
* [[Perl]], with the Class::Prototyped module
* [[Python (programming language)|Python]] with [https://github.com/airportyh/prototype.py prototype.py].
* [[R (programming language)|R]], with the proto package
* [[REBOL]]
* [[Self (programming language)|Self]]
* [[Seph (programming language)|Seph]]
* [[SmartFrog]]
* [[Etoys (programming language)|Etoys]]
* [[TADS]]
* [[Tcl]] with snit extension
* [[Umajin]]&lt;ref&gt;Proprietary scripting language. http://www.davidbrebner.com/?p=4 has some basic examples of use.&lt;/ref&gt;

==See also==
* [[Class-based programming]] (contrast)
* [[Differential inheritance]]
* [[Programming paradigm]]

==References==
{{Reflist}}

==Further reading==
{{Wikibooks|Object oriented programming}}
* {{cite book|first=Martin|last=Abadi|authorlink=Martin Abadi|author2=[[Luca Cardelli]] |title=A Theory of Objects|publisher=Springer-Verlag|year=1996|isbn=978-1-4612-6445-3}}
* [http://www.laputan.org/reflection/warfare.html Class Warfare: Classes vs. Prototypes], by Brian Foote.
* [http://brianodell.net/?page_id=516 Essential Object Oriented JavaScript], by Brian O'Dell.
* {{cite book|editor1-last=Noble|editor1-first=James|editor2-last=Taivalsaari|editor2-first=Antero |editor3-last=Moore|editor3-first=Ivan|year=1999|title=Prototype-Based Programming: Concepts, Languages and Applications|publisher=Springer-Verlag|isbn=981-4021-25-3}}
* [http://web.media.mit.edu/~lieber/Lieberary/OOP/Delegation/Delegation.html Using Prototypical Objects to Implement Shared Behavior in Object Oriented Systems], by Henry Lieberman, 1986.

{{Programming language}}

{{DEFAULTSORT:Prototype-Based Programming}}
[[Category:Prototype-based programming| ]]
[[Category:Object-oriented programming]]
[[Category:Programming paradigms]]
[[Category:Type theory]]</text>
      <sha1>q7664wcz3ully2dycxq6vxuuj1bmlvb</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum dot cellular automaton</title>
    <ns>0</ns>
    <id>8411212</id>
    <revision>
      <id>834379241</id>
      <parentid>818364780</parentid>
      <timestamp>2018-04-05T12:24:20Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23882">{{No footnotes|date=February 2011}}
'''Quantum dot cellular automata''' (sometimes referred to simply as [[quantum cellular automata]], or QCA) are a proposed improvement on conventional computer design ([[CMOS]]), which have been devised in analogy to conventional models of [[cellular automata]] introduced by [[von Neumann]].

==Background==
Any device designed to represent data and perform computation, regardless of the physics principles it exploits and materials used to build it, must have two fundamental properties: distinguishability and conditional change of [[State (computer science)|state]], the latter implying the former. This means that such a device must have barriers that make it possible to distinguish between states, and that it must have the ability to control these barriers to perform [[Indicative conditional|conditional]] change of state. For example, in a digital electronic system, [[transistors]] play the role of such controllable energy barriers, making it extremely practical to perform computing with them.

==Cellular automata==
A [[cellular automata]] (CA) is a [[discrete dynamical system]] consisting of a uniform (finite or infinite) grid of cells. Each cell can be in only one of a finite number of states at a discrete time. As time moves forward, the state of each cell in the grid is determined by a transformation rule that factors in its previous state and the states of the immediately adjacent cells (the cell's "neighborhood"). The most well-known example of a cellular automaton is [[John Horton Conway]]'s "[[Conway's Game of Life|Game of Life]]", which he described in 1970.

==Quantum-dot cells==
===Origin===
Cellular automata are commonly implemented as software programs. However, in 1993, Lent et al. proposed a physical implementation of an automaton using [[Quantum dot|quantum-dot]] cells. The automaton quickly gained popularity and it was first fabricated in 1997. Lent combined the discrete nature of both cellular automata and [[quantum mechanics]], to create [[nano-scale]] devices capable of performing computation at very high switching speeds (order of Terahertz) and consuming extremely small amounts of electrical power.

===Modern cells===
Today, standard [[Solid state (electronics)|solid state]] QCA cell design considers the distance between [[quantum dot]]s to be about 20&amp;nbsp;nm, and a distance between cells of about 60&amp;nbsp;nm. Just like any CA, Quantum (-dot) Cellular Automata are based on the simple interaction rules between cells placed on a [[Grid graph|grid]]. A QCA cell is constructed from four quantum dots arranged in a square pattern. These quantum dots are sites electrons can occupy by [[Quantum tunnelling|tunneling]] to them.

===Cell design===
[[Image:CA02.jpg|frame|left|Figure 2 - A simplified diagram of a four-dot QCA cell.]]
[[Image:CA03.jpg|frame|none|Figure 3 - The two possible states of a four-dot QCA cell.]]

Figure 2 shows a simplified diagram of a quantum-dot cell.&lt;ref&gt;{{Cite journal|last=Roy|first=S. S.|date=September 2016|title=Simplification of master power expression and effective power detection of QCA device (Wave nature tunneling of electron in QCA device)|url=http://ieeexplore.ieee.org/document/7872695/|journal=2016 IEEE Students #8217; Technology Symposium (TechSym)|pages=272–277|doi=10.1109/techsym.2016.7872695}}&lt;/ref&gt; If the cell is charged with two electrons, each free to tunnel to any site in the cell, these electrons will try to occupy the furthest possible site with respect to each other due to mutual [[VSEPR theory|electrostatic repulsion]]. Therefore, two distinguishable cell states exist. Figure 3 shows the two possible minimum [[Energy level|energy states]] of a quantum-dot cell. The state of a cell is called its [[Photon polarization|polarization]], denoted as P. Although arbitrarily chosen, using cell polarization P = -1 to represent [[Boolean algebra (logic)|logic]] “0” and P = +1 to represent logic “1” has become standard practice.

==QCA wire==
[[Image:CA04.jpg|frame|right|Figure 4 - A wire of quantum-dot cells. Note that the relative distances between cells and dots in a cell are not to scale (cells are much farther apart than dots within a cell).]]

Grid arrangements of quantum-dot cells behave in ways that allow for computation. The simplest practical cell arrangement is given by placing quantum-dot cells [[Series and parallel circuits|in series]], to the side of each other. Figure 4 shows such an arrangement of four quantum-dot cells. The bounding boxes in the figure do not represent physical implementation, but are shown as means to identify individual cells.

If the polarization of any of the cells in the arrangement shown in figure 4 were to be changed (by a "driver cell"), the rest of the cells would immediately synchronize to the new polarization due to [[Coulomb barrier|Coulombic interactions]] between them. In this way, a "wire" of quantum-dot cells can be made that transmits polarization state. Configurations of such wires can form a complete set of [[logic gates]] for computation.

There are two types of wires possible in QCA: A simple binary wire as shown in Figure 4 and an inverter chain, which is constituted by placing 45-degree inverted QCA cells side by side.

==Logic gates==
===Majority gate===

Majority gate and inverter (NOT) gate are considered as the two most fundamental building blocks of QCA. Figure 5 shows a majority gate with three inputs and one output. In this structure, the electrical field effect of each input on the output is identical and additive, with the result that whichever input state ("binary 0" or "binary 1") is in the majority becomes the state of the output cell — hence the gate's name. For example, if inputs A and B exist in a “binary 0” state and input C exists in a “binary 1” state, the output will exist in a “binary 0” state since the combined electrical field effect of inputs A and B together is greater than that of input C alone.

[[Image:CA05.jpg|frame|right|Figure 5 - QCA Majority Gate]]

===Other gates===
Other types of gates, namely [[AND gate]]s and [[OR gate]]s, can be constructed using a majority gate with fixed polarization on one of its inputs. A [[NOT gate]], on the other hand, is fundamentally different from the majority gate, as shown in Figure 6. The key to this design is that the input is split and both resulting inputs impinge obliquely on the output. In contrast with an orthogonal placement, the electric field effect of this input structure forces a reversal of polarization in the output.

[[Image:CA06.jpg|frame|none|Figure 6 - Standard Implementation of a NOT gate. Note that the labeling of the input and output values follows a convention exactly opposite to that of the rest of this article.]]

==State transition==
[[Image:CA07.jpg|frame|right|Figure 7 - The QCA clock, its stages and its effects on a cell’s energy barriers.]]

There is a connection between quantum-dot cells and cellular automata. Cells can only be in one of 2 states and the conditional change of state in a cell is dictated by the state of its adjacent neighbors. However, a method to control data flow is necessary to define the direction in which state transition occurs in QCA cells. The [[Clock signal|clocks]] of a QCA system serve two purposes: powering the automaton, and controlling data flow direction.  QCA clocks are areas of conductive material under the automaton’s [[Lattice (group)|lattice]], modulating the electron tunneling barriers in the QCA cells above it.

===Four stages===
A QCA clock induces four stages in the tunneling barriers of the cells above it. In the first stage, the tunneling barriers start to rise. The second stage is reached when the tunneling barriers are high enough to prevent electrons from tunneling. The third stage occurs when the high barrier starts to lower. And finally, in the fourth stage, the tunneling barriers allow electrons to freely tunnel again. In simple words, when the clock signal is high, electrons are free to tunnel. When the clock signal is low, the cell becomes [[Latch (electronics)|latched]].

Figure 7 shows a clock signal with its four stages and the effects on a cell at each clock stage. A typical QCA design requires four clocks, each of which is cyclically 90 degrees out of phase with the prior clock. If a horizontal wire consisted of say, 8 cells and each consecutive pair, starting from the left were to be connected to each consecutive clock, data would naturally flow from left to right. The first pair of cells will stay latched until the second pair of cells gets latched and so forth. In this way, data flow direction is controllable through clock zones

==Wire-crossing==
[[Image:QCA-cross.png|frame|right|Figure 8 - Basic Wire-Crossing Technique. Note that this is schematic and distances are not to scale; cells are much farther apart than dots within cells.]]

Wire-crossing in QCA cells can be done by using two different quantum dot orientations (one at 45 degrees to the other) and allowing a wire composed of one type to pass perpendicularly "through" a wire of the other type, as shown schematically in figure 8. The distances between dots in both types of cells are exactly the same, producing the same Coulombic interactions between the electrons in each cell. Wires composed of these two cell types, however, are different: one type propagates polarization without change; the other reverses polarization from one adjacent cell to the next. The interaction between the different wire types at the point of crossing produces no net polarization change in either wire, thereby allowing the signals on both wires to be preserved.

===Fabrication problems===
Although this technique is rather simple, it represents an enormous fabrication problem. A new kind of cell pattern potentially introduces as much as twice the amount of fabrication cost and infrastructure; the number of possible quantum dot locations on an [[:wikt:interstitial|interstitial]] grid is doubled and an overall increase in geometric design complexity is inevitable. Yet another problem this technique presents is that the additional space between cells of the same orientation decreases the energy barriers between a cell's [[Stationary state|ground state]] and a cell’s first [[excited state]]. This degrades the performance of the device in terms of maximum operating temperature, resistance to [[entropy]], and switching speed.

===Crossbar network===
A different wire-crossing technique, which makes fabrication of QCA devices more practical, was presented by [[Christopher Graunke]], [[David Wheeler (computer scientist)|David Wheeler]], [[Paul Douglas Tougaw|Douglas Tougaw]], and Jeffrey D. Will, in their paper “Implementation of a crossbar network using quantum-dot cellular automata”. The paper not only presents a new method of implementing wire-crossings, but it also gives a new perspective on QCA clocking.

Their wire-crossing technique introduces the concept of implementing QCA devices capable of performing computation as a function of [[Synchronization (computer science)|synchronization]]. This implies the ability to modify the device’s function through the clocking system without making any physical changes to the device. Thus, the fabrication problem stated earlier is fully addressed by: a) using only one type of quantum-dot pattern and, b) by the ability to make a universal QCA building block of adequate complexity, which function is determined only by its timing mechanism (i.e., its clocks).

[[Adiabatic theorem|Quasi-adiabatic]] switching, however, requires that the tunneling barriers of a cell be switched relatively slowly compared to the intrinsic switching speed of a QCA. This prevents [[ringing (signal)|ringing]] and [[Metastability in electronics|metastable]] states observed when cells are switched abruptly. Therefore, the switching speed of a QCA is limited not by the time it takes for a cell to change polarization, but by the appropriate quasi-adiabatic switching time of the clocks being used.

==Parallel to serial==
When designing a device capable of computing, it is often necessary to convert parallel data lines into a [[Serial communications|serial]] [[data stream]]. This conversion allows different pieces of data to be reduced to a time-dependent series of values on a single wire. Figure 9 shows such a parallel-to-serial conversion QCA device. The numbers on the shaded areas represent different clocking zones at consecutive 90-degree phases. Notice how all the inputs are on the same clocking zone. If parallel data were to be driven at the inputs A, B, C and D, and then driven no more for at least the remaining 15 [[serial transmission]] phases, the output X would present the values of D, C, B and A –in that order, at phases three, seven, eleven and fifteen. If a new clocking region were to be added at the output, it could be clocked to latch a value corresponding to any of the inputs by correctly selecting an appropriate state-locking period.

The new latching clock region would be completely independent from the other four clocking zones illustrated in figure 9. For instance, if the value of interest to the new latching region were to be the value that D presents every 16th phase, the clocking mechanism of the new region would have to be configured to latch a value in the 4th phase and every 16th phase from then on, thus, ignoring all inputs but D.

[[Image:CA09.jpg|frame|none|Figure 9 - Parallel to serial conversion.]]

===Additional serial lines===
Adding a second serial line to the device, and adding another latching region would allow for the latching of two input values at the two different outputs. To perform computation, a gate that takes as inputs both serial lines at their respective outputs is added. The gate is placed over a new latching region configured to process data only when both latching regions at the end of the serial lines hold the values of interest at the same instant. Figure 10 shows such an arrangement. If correctly configured, latching regions 5 and 6 will each hold input values of interest to latching region 7. At this instant, latching region 7 will let the values latched on regions 5 and 6 through the AND gate, thus the output could be configured to be the AND result of any two inputs (i.e. R and Q) by merely configuring the latching regions 5, 6 and 7.

This represents the flexibility to implement 16 functions, leaving the physical design untouched. Additional serial lines and parallel inputs would obviously increase the number of realizable functions. However, a significant drawback of such devices is that, as the number of realizable functions increases, an increasing number of clocking regions is required. As a consequence, a device exploiting this method of function implementation may perform significantly slower than its traditional counterpart.

[[File:CA10 (1).jpg|frame|none|Figure 10 – Multifunction QCA Device.]]

==Fabrication==
Generally speaking, there are four different classes of QCA implementations: metal-island, semiconductor, molecular, and magnetic.

===Metal-island===
The metal-island implementation was the first fabrication technology created to demonstrate the concept of QCA. It was not originally intended to compete with current technology in the sense of speed and practicality, as its structural properties are not suitable for scalable designs. The method consists of building quantum dots using aluminum islands. Earlier experiments were implemented with metal islands as big as 1 micrometer in dimension. Because of the relatively large-sized islands, metal-island devices had to be kept at extremely low temperatures for quantum effects (electron switching) to be observable.

===Semiconductor===
[[Semiconductor]] (or [[Solid state (electronics)|solid state]]) QCA implementations could potentially be used to implement QCA devices with the same highly advanced [[semiconductor fabrication]] processes used to implement CMOS devices. Cell polarization is encoded as charge position, and quantum-dot interactions rely on electrostatic coupling. However, current semiconductor processes have not yet reached a point where mass production of devices with such small features (~20 nanometers) is possible. [[Electron beam lithography|Serial lithographic]] methods, however, make QCA solid state implementation achievable, but not necessarily practical. Serial lithography is slow, expensive and unsuitable for mass-production of solid-state QCA devices. Today, most QCA prototyping experiments are done using this implementation technology.

===Molecular===
A proposed but not yet implemented method consists of building QCA devices out of single molecules&lt;ref&gt;{{Cite book|url=https://www.researchgate.net/publication/322049636_Generalized_Quantum_Tunneling_Effect_and_Ultimate_Equations_for_Switching_Time_and_Cell_to_Cell_Power_Dissipation_Approximation_in_QCA_Devices?channel=doi&amp;linkId=5a40a626a6fdcce1970f1f37&amp;showFulltext=true|title=Generalized Quantum Tunneling Effect and Ultimate Equations for Switching Time and Cell to Cell Power Dissipation Approximation in QCA Devices|last=Sinha Roy|first=Soudip|date=2017-12-25|doi=10.13140/rg.2.2.23039.71849}}&lt;/ref&gt;. The expected advantages of such a method include: highly symmetric QCA cell structure, very high switching speeds, extremely high device density, operation at [[room temperature]], and even the possibility of mass-producing devices by means of self-assembly. A number of technical challenges, including choice of molecules, the design of proper interfacing mechanisms, and clocking technology remain to be solved before this method can be implemented.

===Magnetic===
Magnetic QCA, commonly referred to as MQCA (or QCA: M), is based on the interaction between magnetic [[nanoparticles]]. The magnetization vector of these nanoparticles is analogous to the polarization vector in all other implementations. In MQCA, the term “Quantum” refers to the quantum-mechanical nature of magnetic exchange interactions and not to the electron-tunneling effects. Devices constructed this way could operate at room temperature.

==Improvement over CMOS==
[[CMOS|Complementary metal-oxide semiconductor]] (CMOS) technology has been the industry standard for implementing Very Large Scale Integrated (VLSI) devices for the last two decades, mainly due to the consequences of miniaturization of such devices (i.e. increasing switching speeds, increasing complexity and decreasing power consumption). Quantum Cellular Automata (QCA) is only one of the many alternative technologies proposed as a replacement solution to the fundamental limits CMOS technology will impose in the years to come.

Although QCA solves most of the limitations of CMOS technology, it also brings its own. Research suggests that intrinsic switching time of a QCA cell is at best in the order of terahertz. However, the actual speed may be much lower, in the order of megahertz for solid state QCA and gigahertz for molecular QCA, due to the proper quasi-adiabatic clock switching frequency setting.

==References==
&lt;references /&gt;
* Debashis De, Sitanshu Bhattacharaya and K. P. Ghatak, Quantum Dots and Quantum Cellular Automata: Recent Trends and Applications,Nova, 2013
* Srivastava, S.; Asthana, A.; Bhanja, S.; Sarkar, S., "QCAPro - An error-power estimation tool for QCA circuit design," in Circuits and Systems (ISCAS), 2011 IEEE International Symposium on, vol., no., pp.&amp;nbsp;2377-2380, 15–18 May 2011
* M. Rahimi Azghadi, O. Kavehei and K. Navi, “A Novel Design for Quantum-dot Cellular Automata Cells and Full Adders”, Journal of Applied Sciences, Vol. 7, No. 22, pp.&amp;nbsp;3460-3468, 2007. &lt;nowiki&gt;http://scialert.net/qredirect.php?doi=jas.2007.3460.3468&amp;linkid=pdf&lt;/nowiki&gt;
* V.V. Zhirnov, R.K. Cavin, J.A. Hutchby, and G.I. Bourianoff, “Limits to binary logic switch scaling—A gedanken model,” Proc. IEEE, vol. 91, p.&amp;nbsp;1934, Nov. 2003.
* S. Bhanja, and S. Sarkar, “Probabilistic Modeling of QCA Circuits using Bayesian Networks”, IEEE Transactions on Nanotechnology, Vol. 5(6), p.&amp;nbsp;657-670, 2006.
* S. Srivastava, and S. Bhanja, “Hierarchical Probabilistic Macromodeling for QCA Circuits”, IEEE Transactions on Computers,Vol. 56(2), p.&amp;nbsp;174-190, Feb. 2007.
* Beth, T. Proceedings. “Quantum computing: an introduction” The 2000 IEEE International Symposium on Circuits and Systems, 2000. May 2000 p.&amp;nbsp;735-736 vol.1
* Victor V. Zhirnov, James A. Hutchby, George I. Bourianoff and Joe E. Brewer “Emerging Research Logic Devices” IEEE Circuits &amp; Devices Magazine May 2005 p.&amp;nbsp;4
* Wolfram, Stephen “[[A New Kind of Science]]”, Wolfram Media May, 2002 p. ix (Preface)
* C.S. Lent, P. Tougaw, W. Porod, and G. Bernstein, “Quantum cellular automata” Nanotechnology, vol. 4, 1993 p.&amp;nbsp;49-57.
* Victor V. Zhirnov, James A. Hutchby, George I. Bourianoff and Joe E. Brewer “Emerging Research Logic Devices” IEEE Circuits &amp; Devices Magazine May 2005 p.&amp;nbsp;7
* Konrad Walus and G. A. Jullien “Quantum-Dot Cellular Automata Adders” Department of Electrical &amp; Computer Eng. University of Calgary Calgary, AL, Canada p.&amp;nbsp;4 - 6
* S. Henderson, E. Johnson, J. Janulis, and D. Tougaw, “Incorporating standard CMOS design process methodologies into the QCA logic design process” IEEE Trans. Nanotechnology, vol. 3, no. 1, Mar. 2004. p.&amp;nbsp;2 - 9
* Christopher Graunke, David Wheeler, Douglas Tougaw, Jeffreay D. Will. “Implementation of a crossbar network using quantum-dot cellular automata” IEEE Transactions on Nanotechnology, vol. 4, no. 4, Jul. 2005 p.&amp;nbsp;1 - 6
* G. T´oth and C. S. Lent, “Quasiadiabatic switching for metal-island quantum-dot cellular automata”, Journal of Applied Physics, vol. 85, no. 5, 1999 p.&amp;nbsp;2977 - 2984
* G. T´oth, C. S. Lent, “Quantum computing with quantum-dot cellular automata”, Physics Rev. A, vol. 63, 2000 p.&amp;nbsp;1 - 9
* C. S. Lent, B. Isaksen, M. Lieberman, “Molecular Quantum-Dot Cellular Automata”, J. Am. Chem. Soc., vol. 125, 2003 p.&amp;nbsp;1056 - 1063
* K. Walus, G. A. Jullien, V. S. Dimitrov, “Computer Arithmetic Structures for Quantum Cellular Automata” Department of Electrical &amp; Computer Eng. University of Calgary, Calgary, AL, Canada p.&amp;nbsp;1 - 4
* Rui Zhang, Pallav Gupta, and Niraj K. Jha “Synthesis of Majority and Minority Networks and Its Applications to QCA, TPL and SET Based Nanotechnologies” Proceedings of the 18th International Conference on VLSI Design held jointly with 4th International Conference on Embedded Systems Design 2005 p.&amp;nbsp;229- 234
* '' The first published reports introducing the concept of Quantum Automaton:''
* Baianu, I. 1971a. "Categories, Functors and Quantum Automata Theory". The 4th Intl. Congress LMPS, August-Sept.1971;
* Baianu, I.1971b. "Organismic Supercategories and Qualitative Dynamics of Systems." Bull. Math. Biophys., 33 (339-353): http://cogprints.ecs.soton.ac.uk/archive/00003674/01/ORganismic_supercategories_and_qualitative_dynamics_of_systems_final3.pdf.{{dead link|date=July 2016 |bot=InternetArchiveBot |fix-attempted=yes }}
* Niemier, M. 2004. ''Designing Digital Systems In Quantum Cellular Automata'', Ph.D. thesis, University of Notre Dame.
* ''Recent Updates'':
* '' Quantum Reversible Automata'': http://cogprints.org/3697/
* '' Quantum Nano-Automata.'': http://doc.cern.ch/archive/electronic/other/ext/ext-2004-125/Quantumnanoautomata.doc
* ''Categories of Quantum Automata.'': http://fs512.fshn.uiuc.edu/QAuto.pdf.{{dead link|date=July 2016 |bot=InternetArchiveBot |fix-attempted=yes }}

==External links==
*[https://web.archive.org/web/20100813085727/http://www.nd.edu/~qcahome/] – QCA home page at Notre Dame

[[Category:Cellular automata]]
[[Category:Quantum information science]]
[[Category:Quantum dots]]</text>
      <sha1>9x5odm0s7w1f91uajago1wh2bldtu3l</sha1>
    </revision>
  </page>
  <page>
    <title>Rainville polynomials</title>
    <ns>0</ns>
    <id>33015741</id>
    <revision>
      <id>747090833</id>
      <parentid>627077809</parentid>
      <timestamp>2016-10-31T11:15:13Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* References */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="921">In mathematics, the '''Rainville polynomials'''  ''p''&lt;sub&gt;''n''&lt;/sub&gt;(''z'') are  polynomials introduced by {{harvtxt|Rainville|1945}} given by the [[generating function]]

:&lt;math&gt;\displaystyle e^wI_0(zw) = \sum_np_n(z)w^n&lt;/math&gt;

{{harvtxt|Boas|Buck|1958|loc=p.46}}.

==References==

*{{Citation | last1=Boas | first1=Ralph P. | last2=Buck | first2=R. Creighton | title=Polynomial expansions of analytic functions | url=https://books.google.com/books?id=eihMuwkh4DsC | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Ergebnisse der Mathematik und ihrer Grenzgebiete. Neue Folge.  | mr=0094466 | year=1958 | volume=19}}
*{{Citation | last1=Rainville | first1=Earl D. | title=Notes on Legendre polynomials | doi=10.1090/S0002-9904-1945-08330-X  |mr=0011750 | year=1945 | journal=[[Bulletin of the American Mathematical Society]] | issn=0002-9904 | volume=51 | pages=268–271}}
[[Category:Polynomials]]</text>
      <sha1>15tdufok8q68s8p27zvk3pomvi4j3fx</sha1>
    </revision>
  </page>
  <page>
    <title>Ralph P. Boas Jr.</title>
    <ns>0</ns>
    <id>3088231</id>
    <revision>
      <id>832858121</id>
      <parentid>832198146</parentid>
      <timestamp>2018-03-28T11:09:30Z</timestamp>
      <contributor>
        <username>Pirhayati</username>
        <id>16750284</id>
      </contributor>
      <comment>[[A Primer of Real Functions]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10562">{{Infobox scientist
| name              = Ralph P. Boas Jr.
| image             = &lt;!--(filename only)--&gt;
| image_size        = 
| caption           = 
| birth_date        = {{birth date|1912|08|08|mf=y}}
| birth_place       = [[Walla Walla, Washington]]
| death_date        = {{death date and age|1992|07|25|1912|08|08|mf=y}}
| death_place       = [[Seattle, Washington]]
| nationality       = American
| fields            = [[Mathematics]]
| workplaces        = [[Northwestern University]] &lt;br&gt; [[Duke University]]
| alma_mater        = [[Harvard University]]
| doctoral_advisor  = [[David Widder]]
| doctoral_students = [[Creighton Buck]]&lt;br&gt;[[Philip J. Davis]]&lt;br&gt;[[Christopher Imoru]]&lt;br&gt;[[Dale Mugler]]
| known_for         = 
| awards            = [[Lester R. Ford Award]] (1970, 1978)&lt;ref&gt;{{cite journal|author=Boas, Ralph P.|title=Inequalities for the derivatives of polynomials|journal=Mathematics Magazine|volume=42|year=1969|pages=165–174|url=http://www.maa.org/programs/maa-awards/writing-awards/inequalities-for-the-derivatives-of-polynomials|doi=10.2307/2688534}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=Boas, Ralph P.|title=Partial sums of infinite series, and how they grow|journal=Amer. Math. Monthly|volume=84|year=1977|pages=237–258|url=http://www.maa.org/programs/maa-awards/writing-awards/partial-sums-of-infinite-series-and-how-they-grow|doi=10.2307/2318865}}&lt;/ref&gt;
}}
'''Ralph Philip Boas Jr.''' (August 8, 1912 – July 25, 1992) was a mathematician, teacher, and journal editor.  He wrote over 200 papers, mainly in the fields of [[real analysis|real]] and [[complex analysis]].&lt;ref name="gasper"&gt;{{citation|title=In memoriam Ralph P. Boas Jr|first=George|last=Gasper|authorlink=George Gasper|journal=Journal of Mathematical Analysis and Applications|volume=173|year=1993|pages=1–2|url=http://www.math.northwestern.edu/~george/preprints/ggBoasMem/|doi=10.1006/jmaa.1993.1048}}.&lt;/ref&gt;

== Biography ==
He was born in [[Walla Walla, Washington]], the son of an English professor at [[Whitman College]], but moved frequently as a child; his younger sister, [[Marie Boas Hall]], later to become a historian of science, was born in [[Springfield, Massachusetts]], where his father had become a high school teacher.&lt;ref name="mmp"&gt;{{citation|contribution=Ralph P. Boas Jr.|title=More Mathematical People|editor1-first=Donald J.|editor1-last=Albers|editor2-first=Gerald L.|editor2-last=Alexanderson|editor2-link=Gerald L. Alexanderson|editor3-first=Constance|editor3-last=Reid|editor3-link=Constance Reid|publisher=Harcourt Brace Jovanovich|year=1990|pages=22–41}}.&lt;/ref&gt; He was home-schooled until the age of eight, began his formal schooling in the sixth grade, and graduated from high school while still only 15.&lt;ref name="mmp"/&gt; After a gap year auditing classes at [[Mount Holyoke College]] (where his father had become a professor) he entered Harvard, intending to major in chemistry and go into medicine, but ended up studying mathematics instead.&lt;ref name="mmp"/&gt; His first mathematics publication was written as an undergraduate, after he discovered an incorrect proof in another paper.&lt;ref name="mmp"/&gt; He got his [[Bachelor of Arts|A.B. degree]] in 1933, received a Sheldon Fellowship for a year of travel, and returned to Harvard for his doctoral studies in 1934.&lt;ref name="mmp"/&gt; He earned his doctorate there in 1937, under the supervision of [[David Widder]].&lt;ref name="gasper"/&gt;&lt;ref name="mmp"/&gt;&lt;ref&gt;{{MathGenealogy|id=6870}}&lt;/ref&gt;

After postdoctoral studies at [[Princeton University]] with [[Salomon Bochner]], and then the [[University of Cambridge]] in England, he began a two-year instructorship at [[Duke University]], where he met his future wife, [[Mary L. Boas|Mary Layne]], also a mathematics instructor at Duke. They were married in 1941, and when [[World War II]] started later that year, Boas moved to the Navy Pre-flight School in [[Chapel Hill, North Carolina]]. In 1942, he interviewed for a position in the [[Manhattan Project]], at the [[Los Alamos National Laboratory]], but ended up returning to Harvard to teach in a Navy instruction program there, while his wife taught at [[Tufts University]].&lt;ref name="mmp"/&gt;

Beginning when he was an instructor at Duke University, Boas had become a prolific reviewer for ''[[Mathematical Reviews]]'', and at the end of the war he took a position as its full-time editor.&lt;ref name="mmp"/&gt; In the academic year 1950–1951 he was a [[Guggenheim Fellow]].&lt;ref&gt;[https://archive.is/20150201025908/http://www.gf.org/fellows/1449-ralph-p-boas-jr Ralph P. Boas Jr. – John Simon Guggenheim Memorial Foundation]&lt;/ref&gt;
In 1950 he became Professor of Mathematics at [[Northwestern University]], without ever previously having been an assistant or associate professor; his wife became a professor of physics at nearby [[DePaul University]], due to the anti-nepotism rules then in place at Northwestern&lt;ref name="gasper"/&gt;&lt;ref name="mmp"/&gt; He stayed at Northwestern until his retirement in 1980, and was chair there from 1957 to 1972.&lt;ref name="gasper"/&gt;&lt;ref name="mmp"/&gt; He was president of the [[Mathematical Association of America]] from 1973 to 1974, and as president launched the ''Dolciani Mathematical Expositions'' series of books.&lt;ref&gt;{{citation|url=http://www.maa.org/history/presidents/boas.html|title=MAA presidents: Ralph Philip Boas Jr.|publisher=[[Mathematical Association of America]]|accessdate=2013-04-02}}.&lt;/ref&gt; He was also editor of the ''[[American Mathematical Monthly]]'' from 1976 to 1981.&lt;ref name="gasper"/&gt; He continued mathematical work after retiring, for instance as co-editor (with [[George Leitmann]]) of the ''[[Journal of Mathematical Analysis and Applications]]'' from 1985 to 1991.&lt;ref name="gasper"/&gt;

Along with his mathematical education, Boas was educated in many languages: Latin in junior high school, French and German in high school, Greek at Mount Holyoke, Sanskrit as a Harvard undergraduate, and later self-taught Russian while at Duke University.&lt;ref name="mmp"/&gt;

Boas' son [[Harold P. Boas]] is also a noted mathematician.

== The hunting of big game  {{anchor|Big game hunting|Pétard|Petard}} ==
Boas, [[Frank Smithies]], and colleagues were behind the 1938 paper ''A Contribution to the Mathematical Theory of Big Game Hunting'' published in the ''[[American Mathematical Monthly]]'' under the pseudonym '''H.&amp;nbsp;Pétard''' (referring to [[Hamlet]]'s "[[Hoisted by my own petard#.22Hoist with his own petard.22|hoist by his own petard]]").  The paper offers short [[parody|spoofs]] of theorems and proofs from [[mathematics]] and [[physics]], in the form of applications to the [[hunting]] of [[lion]]s in the [[Sahara desert]].  One "proof" [[parody|parodies]] the [[Bolzano–Weierstrass theorem]],

* The Bolzano-Weierstrass Method.  Bisect the desert by a line running N-S.  The lion is either in the E portion or in the W portion; let us suppose him to be in the W portion.  Bisect this portion by a line running E-W.  The lion is either in the N portion or in the S portion; let us suppose him to be in the N portion.  We continue this process indefinitely, constructing a sufficiently strong fence about the chosen portion at each step.  The diameter of the chosen portions approaches zero, so that the lion is ultimately surrounded by a fence of arbitrarily small perimeter.

The paper became a classic of [[mathematical joke|mathematical humor]] and spawned various follow-ons over the years with theories or methods from other scientific areas adapted to hunting lions.

The paper and later work is published in ''Lion Hunting and Other Mathematical Pursuits : A Collection of Mathematics, Verse, and Stories by the Late Ralph P. Boas Jr.'', {{ISBN|0-88385-323-X}}.  Various online collections of the lion hunting methods exist too.

== Pondiczery ==

'''E. S. Pondiczery''' was another pseudonym invented by Boas and Smithies as the fictional person behind the "H. Pétard" pseudonym,&lt;ref name="mmp"/&gt; and later used again by Boas, this time for a serious paper on [[topology]], ''Power problems in abstract spaces'', [[Duke Mathematical Journal]], 11 (1944), 835–837.  This paper and the name became part of the [[Hewitt-Marczewski-Pondiczery theorem]].

The name, revealed in ''Lion Hunting and Other Mathematical Pursuits'' cited above, came from [[Pondicherry (city)|Pondicherry]] (a place in India disputed by the [[Dutch people|Dutch]], [[English people|English]] and [[French people|French]]) and a [[slavic languages|slavic]] twist.  The initials "E.S." were a plan to write a spoof on [[extra-sensory perception]] (ESP).

== Other ==

His best-known books are the lion-hunting book previously mentioned and the monograph ''[[A Primer of Real Functions]]''.&lt;ref&gt;{{cite journal|author=Gál, I. S.|title=Review: ''A Primer of Real Functions'' by Ralph B. Boas Jr., Carus Monograph No. 13. Wiley, New York, 1960|journal=Bulletin of the American Mathematical Society|year=1962|volume=68|issue=1|pages=10–12|doi=10.1090/S0002-9904-1962-10672-7 }}&lt;/ref&gt; The current edition of the primer has been revised and edited by his son, mathematician [[Harold P. Boas]].

The best-known of his 13 doctoral students is [[Philip J. Davis]], who is also his only advisee who did not graduate from Northwestern. Boas advised Davis, who was at [[Harvard University]], while Boas was visiting at [[Brown University]].

== References ==
&lt;references/&gt;

* ''A Contribution to the Mathematical Theory of Big Game Hunting'', [[American Mathematical Monthly]], August–September 1938, page 446.
* ''Pondiczery was Ralph Boas — A Historical Vignette'', [[Melvin Henriksen]]. [http://at.yorku.ca/t/o/p/c/40.htm]

== Further reading ==

* ''Some Modern Mathematical Methods in the Theory of Lion Hunting'', O. Morphy, [[American Mathematical Monthly]], volume 75 (1968), pages 185–187.
* ''[http://specgram.com/LP/21.mathiesen.hunting.html Linguistic Contributions To The Formal Theory Of Big-Game Hunting]'', R. Mathiesen, Lingua Pranca, 1978.

==External links==
*{{wikiquote-inline}}

{{Authority control}}

{{DEFAULTSORT:Boas, Ralph P. Jr.}}
[[Category:1912 births]]
[[Category:1992 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:Complex analysts]]
[[Category:Mathematical analysts]]
[[Category:Mathematical humor]]
[[Category:Harvard University alumni]]
[[Category:Northwestern University faculty]]
[[Category:People from Walla Walla, Washington]]
[[Category:Presidents of the Mathematical Association of America]]
[[Category:Guggenheim Fellows]]
[[Category:Mathematicians from Washington (state)]]</text>
      <sha1>abdjjx9tljkjf7xba9kjnl9ftj247nu</sha1>
    </revision>
  </page>
  <page>
    <title>Regina (program)</title>
    <ns>0</ns>
    <id>4781110</id>
    <revision>
      <id>820002501</id>
      <parentid>818234879</parentid>
      <timestamp>2018-01-12T14:32:50Z</timestamp>
      <contributor>
        <ip>86.123.39.41</ip>
      </contributor>
      <comment>Latest version update</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1915">{{Infobox Software
| name = Regina
| logo = Regina logo.jpg
| screenshot = 
| caption = 
| author = Ben Burton, David Letscher, Richard Rannard, [[Hyam Rubinstein]]
| developer = Ben Burton, Ryan Budney, William Pettersson
| released = December 2000
| latest release version = 5.1
| latest release date = Dec, 2016
| latest preview version = 
| latest preview date = 
| repo = {{URL|https://github.com/regina-normal/regina}}
| operating system = [[Linux]], [[Unix-like]], [[Mac OS|Mac]], [[Microsoft Windows]], [[iOS]]
| platform = 
| language = English
| programming language = [[C++]], [[Python (programming language)|Python]]
| genre=Mathematical Software
| license = [[GPL]]
| website= {{URL|https://regina-normal.github.io}}
}}
'''Regina''' is a suite of mathematical software for [[3-manifold]] [[topology|topologists]]. It focuses upon the study of 3-manifold [[Triangulation (topology)|triangulations]] and includes support for [[normal surface]]s and angle structures.

== Features ==

* Regina implements a variant of [[Hyam Rubinstein|Rubinstein's]] [[3-sphere]] recognition algorithm.  This is an algorithm that determines whether or not a [[Triangulation (topology)|triangulated]] [[3-manifold]] is [[homeomorphism|homeomorphic]] to the [[3-sphere]].
* Regina further implements the [[connected sum|connect-sum]] decomposition.  This will decompose a [[triangulation (topology)|triangulated]] 3-manifold into a [[connected sum|connect-sum]] of [[triangulation (topology)|triangulated]] [[connected sum|prime]] 3-manifolds.
* [[Simplicial homology|Homology]] and [[Poincare duality]] for 3-manifolds, including the [[Poincare duality|torsion linking form]].
* Includes portions of the [[SnapPea|SnapPea kernel]] for some geometric calculations.
* Has both a [[GUI]] and [[Python (programming language)|Python]] interface.

== See also ==

* [[Computational topology]]

[[Category:Mathematical software]]</text>
      <sha1>iynlnmwbyi5yn8exqw562pnkm16zhv9</sha1>
    </revision>
  </page>
  <page>
    <title>Richard Zach</title>
    <ns>0</ns>
    <id>44330423</id>
    <revision>
      <id>848619159</id>
      <parentid>848619081</parentid>
      <timestamp>2018-07-03T04:02:44Z</timestamp>
      <contributor>
        <username>HMSLavender</username>
        <id>21479757</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/2001:56A:7052:FB00:C95D:5D50:4FB3:3FD4|2001:56A:7052:FB00:C95D:5D50:4FB3:3FD4]] ([[User talk:2001:56A:7052:FB00:C95D:5D50:4FB3:3FD4|talk]]): addition of [[WP:BLP|unsourced content]] to a biographical article ([[WP:HG|HG]]) (3.4.3)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5539">{{Infobox scientist
| name        = Richard Zach
| native_name = 
| native_name_lang = 
| image       =         &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size  = 
| alt         = 
| caption     = 
| birth_date  =         &lt;!--{{birth date |YYYY|MM|DD}}--&gt;
| birth_place = 
| death_date  =         &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place = 
| death_cause = 
| resting_place = 
| resting_place_coordinates =  &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names = 
| residence   = {{ublist |[[Canada]] |[[United States]]| [[Austria]]}}
| citizenship = 
| nationality = 
| fields      = {{ublist |[[mathematical logic]] ([[proof theory]]) | [[philosophical logic]]| |[[history of logic]] | [[philosophy of mathematics]] |history of analytic philosophy}}
| workplaces  = [[University of Calgary]]
| patrons     = 
| education   = 
| alma_mater  = [[University of California, Berkeley]]
| thesis_title = Hilbert's Finitism: Historical and Philosophical Perspectives
| thesis_url  =  https://www.ucalgary.ca/rzach/papers/hilbert.html
| thesis_year =  2001       &lt;!--(or  | thesis1_year =   and  | thesis2_year =  )--&gt;
| doctoral_advisors = [[Paolo Mancosu]], [[Jack Silver]]
| academic_advisors = 
| doctoral_students = 
| notable_students = 
| known_for   = 
| influences  = 
| influenced  = 
| awards      = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse      =         &lt;!--(or | spouses = )--&gt;
| partner     =         &lt;!--(or | partners = )--&gt;
| children    = 
| signature   =         &lt;!--(filename only)--&gt;
| signature_alt = 
| website     = {{URL|ucalgary.ca/rzach/}}
| footnotes   = 
}}
'''Richard Zach''' is a Canadian logician, philosopher of mathematics, and historian of logic and analytic philosophy. He is currently Professor of Philosophy at the [[University of Calgary]]. 

==Research==

Zach's research interests include the development of formal logic and historical figures ([[Hilbert]], [[Gödel]], and [[Carnap]]) associated with this development. In the [[philosophy of mathematics]] Zach has worked on [[Hilbert]]'s program and the philosophical relevance of proof theory. In mathematical logic, he has made contributions to [[proof theory]] ([[epsilon calculus]], [[proof complexity]]) and to [[modal logic|modal]] and [[many-valued logic]], especially [[Gödel logic]].&lt;ref&gt;{{cite web|url=https://www.ucalgary.ca/rzach/papers|title=Research and Publications |author=Richard Zach |accessdate=2014-12-10 |publisher=}}&lt;/ref&gt;

==Career==

Zach received his undergraduate education at the [[Vienna University of Technology]] and his Ph.D. at the Group in Logic and the Methodology of Science at the [[University of California, Berkeley]].  He has taught at the [[University of Calgary]] since 2001, and holds the rank of Professor. He has held visiting appointments at the [[University of California, Irvine]]&lt;ref&gt;{{cite web|url=http://www.lps.uci.edu/files/fac-staff/visitors/|author= UC Irvine LPS|title=Logic and Philosophy of Science Visitors|accessdate=2014-12-12}}&lt;/ref&gt; and [[McGill University]].&lt;ref&gt;{{cite web|url=https://www.mcgill.ca/philosophy/people/visitors |author=McGill Philosophy Department|title=Visiting Scholars|accessdate=2014-12-12}}&lt;/ref&gt;Zach is a founding editor of the ''[[Review of Symbolic Logic]]'' and the ''[[Journal for the Study of the History of Analytic Philosophy]]'', and is also associate editor of ''[[Studia Logica]]'', and a subject editor for the ''[[Stanford Encyclopedia of Philosophy]]'' (History of Modern Logic).&lt;ref&gt;{{cite web|url=http://phil.ucalgary.ca/profiles/richard-zach|title=Richard Zach|website=University of Calgary Department of Philosophy|accessdate = 2014-12-11}}&lt;/ref&gt; He serves on the editorial boards of the [[Paul Bernays|Bernays]] edition&lt;ref&gt;{{cite web|url=http://www.phil.cmu.edu/projects/bernays/|title = The Bernays Project|author = Carnegie Mellon University|accessdate=2014-12-11}}&lt;/ref&gt; and the [[Rudolf Carnap|Carnap]] edition.&lt;ref&gt;{{cite web|url=http://www.phil.cmu.edu/projects/carnap/ |title=The Collected Works of Rudolf Carnap|author=Carnegie Mellon University|accessdate=2012-12-11}}&lt;/ref&gt; He was elected to the Council of the [[Association for Symbolic Logic]] in 2008&lt;ref&gt;{{cite web|url=https://www.aslonline.org/files/newsletters/pdfs/jan2008newsletter.pdf | title = ASL Newsletter | author = [[Association for Symbolic Logic]] |date = January 2008}},&lt;/ref&gt; and he has served on the ASL Committee on Logic Education&lt;ref&gt;{{cite web |url=https://www.ucalgary.ca/aslcle/members |author = ASL Committee on Logic Education|title = Members | accessdate=2014-12-12}}&lt;/ref&gt; and the executive committee of the [[Kurt Gödel Society]].&lt;ref&gt;{{cite web|url=http://kgs.logic.at/index.php?id=3|author = Kurt Gödel Society|title = Organization|accessdate=2014-12-12}}&lt;/ref&gt;

==References==
{{Reflist}}

==External links==
* [http://ucalgary.ca/rzach/ Official Website]
* [http://richardzach.org/ LogBlog: A Logic Blog]
* [http://phil.ucalgary.ca/profiles/richard-zach Departmental information page]
* [http://sshap.org/ Society for the Study of the History of Analytical Philosophy]
* [http://openlogicproject.org/ Open Logic Project]

{{Authority control}}

{{DEFAULTSORT:Zach, Richard}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:Canadian philosophers]]
[[Category:University of Calgary faculty]]
[[Category:Mathematical_logicians]]
[[Category:Philosophers_of_mathematics]]
[[Category:Austrian_logicians]]</text>
      <sha1>llh0gz93j5db52dmv8ln8fc7wbq769t</sha1>
    </revision>
  </page>
  <page>
    <title>Riemann–Hilbert correspondence</title>
    <ns>0</ns>
    <id>10478956</id>
    <revision>
      <id>824822658</id>
      <parentid>732174109</parentid>
      <timestamp>2018-02-09T18:25:44Z</timestamp>
      <contributor>
        <ip>2601:445:437F:FE66:0:0:0:3B40</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8403">In mathematics, the '''Riemann–Hilbert correspondence''' is a generalization of [[Hilbert's twenty-first problem]] to higher dimensions. The original setting was for the Riemann sphere, where it was about the existence of [[regular differential equation]]s with prescribed [[monodromy]] groups. 
First the Riemann sphere may be replaced by an arbitrary [[Riemann surface]] and then, in higher dimensions, Riemann surfaces are replaced by [[complex manifold]]s of dimension &gt; 1. 
There is a correspondence between certain systems of [[partial differential equation]]s (linear and having very special properties for their solutions) and possible monodromies of their solutions.

Such a result was proved for algebraic connections with regular singularities by [[Pierre Deligne]] (1970) and more generally for regular holonomic D-modules by [[Masaki Kashiwara]] (1980, 1984) and [[Zoghman Mebkhout]] (1980, 1984) independently.

==Statement==
Suppose that ''X'' is a smooth complex algebraic variety.

'''Riemann–Hilbert correspondence''' (for regular singular connections): 
there is a functor ''Sol'' called the local solutions functor, that is an equivalence from the category of flat connections on algebraic vector bundles on ''X'' with [[regular singularities]] to the category of local systems of finite-dimensional complex vector spaces on ''X''. For ''X'' connected, the category of local systems is also equivalent to the category of complex representations of the [[fundamental group]] of ''X''.

The condition of regular singularities means that locally constant sections of the bundle (with respect to the flat connection) have moderate growth at points of ''Y − X'', where ''Y'' is an algebraic compactification of ''X''. In particular, when ''X'' is compact, the condition of regular singularities is vacuous.

More generally there is the

'''Riemann–Hilbert correspondence''' (for regular holonomic D-modules): there is a functor ''DR'' called the de Rham functor, that is an equivalence from the category of [[D-modules#Holonomic modules|holonomic]] [[D-module]]s on ''X'' with [[regular singularities]] to the category of [[perverse sheaves]] on ''X''.

By considering the irreducible elements of each category, this gives a 1:1 correspondence between isomorphism classes of

*irreducible holonomic D-modules on ''X'' with regular singularities,
and
*[[intersection cohomology]] complexes of irreducible closed subvarieties of ''X'' with coefficients in irreducible [[local system]]s.

A [[D-module]] is something like a system of differential equations on ''X'', and a local system on a subvariety is something like a description of possible monodromies, so this correspondence can be thought of as describing certain systems of differential equations in terms of the monodromies of their solutions.

In the case ''X'' has dimension one (a complex algebraic curve) then there is a more general Riemann–Hilbert correspondence for algebraic connections with no regularity assumption (or for holonomic D-modules with no regularity assumption) described in Malgrange (1991), the '''Riemann–Hilbert–Birkhoff correspondence'''.

==Examples==

An example where the theorem applies is the differential equation

: &lt;math&gt;\frac{df}{dz} = \frac{a}{z}f&lt;/math&gt;

on the punctured affine line ''A''&lt;sup&gt;1&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;{0} (that is, on the nonzero complex numbers '''C''' − {0}). Here ''a'' is a fixed complex number. This equation has [[regular singular point|regular singularities]] at 0 and ∞ in the projective line '''P'''&lt;sup&gt;1&lt;/sup&gt;. The local solutions of the equation are of the form ''cz&lt;sup&gt;a&lt;/sup&gt;'' for constants ''c''. If ''a'' is not an integer, then the function ''z&lt;sup&gt;a&lt;/sup&gt;'' cannot be made well-defined on all of '''C''' − {0}. That means that the equation has nontrivial monodromy. Explicitly, the monodromy of this equation is the 1-dimensional representation of the fundamental group {{pi}}&lt;sub&gt;1&lt;/sub&gt;(''A''&lt;sup&gt;1&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;{0}) =&amp;nbsp;'''Z''' in which the generator (a loop around the origin) acts by multiplication by ''e&lt;sup&gt;2{{pi}}ia&lt;/sup&gt;''.

To see the need for the hypothesis of regular singularities, consider the differential equation

: &lt;math&gt;\frac{df}{dz} = f&lt;/math&gt;

on the affine line ''A''&lt;sup&gt;1&lt;/sup&gt; (that is, on the complex numbers '''C'''). This equation corresponds to a flat connection on the trivial algebraic line bundle over ''A''&lt;sup&gt;1&lt;/sup&gt;. The solutions of the equation are of the form ''ce&lt;sup&gt;z&lt;/sup&gt;'' for constants ''c''. Since these solutions do not have polynomial growth on some sectors around the point ∞ in the projective line '''P'''&lt;sup&gt;1&lt;/sup&gt;, the equation does not have regular singularities at&amp;nbsp;∞. (This can also be seen by rewriting the equation in terms of the variable ''w''&amp;nbsp;:=&amp;nbsp;1/''z'', where it becomes

: &lt;math&gt;\frac{df}{dw} = -\frac{1}{w^2}f.&lt;/math&gt;

The pole of order 2 in the coefficients means that the equation does not have regular singularities at ''w'' = 0, according to [[regular singular point|Fuchs's theorem]].)

Since the functions ''ce&lt;sup&gt;z&lt;/sup&gt;'' are defined on the whole affine line ''A''&lt;sup&gt;1&lt;/sup&gt;, the monodromy of this flat connection is trivial. But this flat connection is not isomorphic to the obvious flat connection on the trivial line bundle over ''A''&lt;sup&gt;1&lt;/sup&gt; (as an algebraic vector bundle with flat connection), because its solutions do not have moderate growth at ∞. This shows the need to restrict to flat connections with regular singularities in the Riemann–Hilbert correspondence. On the other hand, if we work with holomorphic (rather than algebraic) vector bundles with flat connection on a noncompact complex manifold such as ''A''&lt;sup&gt;1&lt;/sup&gt; = '''C''', then the notion of regular singularities is not defined. A much more elementary theorem than the Riemann–Hilbert correspondence states that flat connections on holomorphic vector bundles are determined up to isomorphism by their monodromy.

==See also==

* [[Riemann–Hilbert problem]]

==References==

* {{Citation | last1=Borel | first1=Armand | author1-link=Armand Borel | title=Algebraic D-Modules | publisher=[[Academic Press]] | location=Boston, MA | series=Perspectives in Mathematics | isbn=978-0-12-117740-9 | year=1987 | volume=2 | mr=0882000}}
* {{Citation | last1=Deligne | first1=Pierre | author1-link=Pierre Deligne | title=Équations différentielles à points singuliers réguliers | series=Lecture Notes in Mathematics  | publisher=[[Springer-Verlag]] | oclc=169357 | year=1970 | volume=163 | isbn=3540051902 | mr=0417174}}
* {{Citation | last1=Kashiwara | first1=Masaki | author-link=Masaki Kashiwara | chapter=Faisceaux constructibles et systèmes holonômes d'équations aux dérivées partielles linéaires à points singuliers réguliers | title=Séminaire Goulaouic-Schwartz, 1979–80, Exposé 19 | year=1980 | publisher=École Polytechnique | location=Palaiseau | mr=0600704}}
* {{Citation | last1=Kashiwara | first1=Masaki | author-link=Masaki Kashiwara | title=The Riemann-Hilbert problem for holonomic systems | journal=Publications of the Research Institute for Mathematical Sciences | volume=20 | number=2 | pages=319–365 | year=1984 | url=http://www.ems-ph.org/journals/show_abstract.php?issn=0034-5318&amp;vol=20&amp;iss=2&amp;rank=4 | mr=0743382 | doi=10.2977/prims/1195181610}}
* {{Citation | last1=Malgrange | first1=Bernard | author-link=Bernard Malgrange | title=Équations différentielles à coefficients polynomiaux | publisher=[[Birkhäuser]] | series=Progress in Mathematics | volume=96 | year=1991 | isbn=0-8176-3556-4 | mr=1117227}}
* {{Citation | last1=Mebkhout | first1=Zoghman |author-link=Zoghman Mebkhout | title=Complex analysis, microlocal calculus and relativistic quantum theory (Les Houches, 1979) | chapter=Sur le problėme de Hilbert-Riemann | pages=90–110 | series=Lecture Notes in Physics | volume=126 | publisher=[[Springer-Verlag]] | year=1980 | isbn=3-540-09996-4 | mr=0579742}}
* {{Citation | last1=Mebkhout | first1=Zoghman | author-link=Zoghman Mebkhout | title=Une autre équivalence de catégories | journal=Compositio Mathematica | volume=51 | number=1 | pages=63–88 | year=1984 | url=http://www.numdam.org/numdam-bin/fitem?id=CM_1984__51_1_63_0 | mr=0734785}}

{{DEFAULTSORT:Riemann-Hilbert correspondence}}
[[Category:Differential equations]]
[[Category:Representation theory]]
[[Category:Bernhard Riemann]]</text>
      <sha1>l9c68ufnjd5ylvrm26avej5gajm9zfv</sha1>
    </revision>
  </page>
  <page>
    <title>Robin Thomas (mathematician)</title>
    <ns>0</ns>
    <id>24641679</id>
    <revision>
      <id>845116402</id>
      <parentid>840084601</parentid>
      <timestamp>2018-06-09T14:03:48Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4116">{{ Infobox scientist
| name              = Robin Thomas
| image =
| birth_date        = 
| birth_place       = 
| death_date        = 
| death_place       = 
| nationality       = 
| fields            = [[Mathematics]]
| workplaces        = [[Georgia Institute of Technology]]
| alma_mater        = [[Charles University]]
| doctoral_advisor  = [[Jaroslav Nešetřil]]
| doctoral_students = 
| known_for         = 
| awards            = [[Fulkerson Prize]]&lt;br&gt;Karel Janeček Foundation Neuron Prize
}}

'''Robin Thomas''' is a mathematician working in [[graph theory]] at the [[Georgia Institute of Technology]].

Thomas received his doctorate in 1985 from [[Charles University in Prague|Charles University]] in [[Prague]], [[Czechoslovakia]] (now the [[Czech Republic]]), under the supervision of [[Jaroslav Nešetřil]].&lt;ref&gt;{{mathgenealogy|name=Robin Thomas|id=44107}}.&lt;/ref&gt; He joined the faculty at Georgia Tech in 1989, and is now a Regents' Professor there.&lt;ref&gt;Author biography from {{cite arXiv|title=Voting in agreeable societies|first1=Deborah E.|last1=Berg|first2=Serguei|last2=Norine|first3=Francis Edward|last3=Su|first4=Robin|last4=Thomas|first5=Paul|last5=Wollan|eprint=0811.3245 }}.&lt;/ref&gt;&lt;ref&gt;[http://www.cc.gatech.edu/news/robin-thomas-earns-distinction-named-regents-professor Robin Thomas Earns Distinction, Named Regents' Professor], Georgia Tech College of Computing, June 24, 2010.&lt;/ref&gt;

== Awards ==
Thomas was awarded the [[Fulkerson Prize]] for outstanding papers in [[discrete mathematics]] twice,&lt;ref&gt;[http://www.ams.org/prizes/fulkerson-prize.html Fulkerson Prize: Official site with award details].&lt;/ref&gt; in 1994 as co-author of a paper on the [[Hadwiger conjecture (graph theory)|Hadwiger conjecture]],&lt;ref&gt;{{citation|title=Hadwiger's conjecture for ''K''&lt;sub&gt;6&lt;/sub&gt;-free graphs|author1-link=Neil Robertson (mathematician)|last1=Robertson|first1=Neil|author2-link=Paul Seymour (mathematician)|last2=Seymour|first2= Paul|last3=Thomas|first3=Robin|journal=[[Combinatorica]]|volume=13|issue=3|year=1993|doi=10.1007/BF01202354|pages=279–361}}.&lt;/ref&gt; and in 2009 for the proof of the [[strong perfect graph theorem]].&lt;ref&gt;{{citation
  | first1=Maria|last1=Chudnovsky|author1-link=Maria Chudnovsky|author2-link=Neil Robertson (mathematician)|last2=Robertson|first2=Neil|author3-link=Paul Seymour (mathematician)|last3=Seymour|first3= Paul|last4=Thomas|first4=Robin
  | year = 2006
  | url = http://annals.princeton.edu/annals/2006/164-1/p02.xhtml
  | title = The strong perfect graph theorem
  | journal = [[Annals of Mathematics]]
  | volume = 164 | issue = 1 | doi = 10.4007/annals.2006.164.51
  | pages = 51–229|arxiv=math/0212070}}.&lt;/ref&gt;
In 2011 he was awarded the Karel Janeček Foundation Neuron Prize for Lifetime Achievement in Mathematics.&lt;ref&gt;[http://www.nfkj.cz/cena-neuron-2011 Karel Janeček Foundation 2011 Neuron Prize winners (in Czech)] {{webarchive|url=https://web.archive.org/web/20121223092613/http://www.nfkj.cz/cena-neuron-2011 |date=2012-12-23 }}&lt;/ref&gt; In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-08-27.&lt;/ref&gt;
He was named a [[SIAM Fellow]] in 2018.&lt;ref&gt;{{citation|url=https://sinews.siam.org/Details-Page/siam-announces-class-of-2018-fellows|title=SIAM Announces Class of 2018 Fellows|magazine=SIAM News|date=March 29, 2018}}&lt;/ref&gt;

== References ==
{{reflist}}

== External links ==
* [http://people.math.gatech.edu/~thomas/ Personal homepage of Robin Thomas]

{{Authority control}}

{{DEFAULTSORT:Thomas, Robin}}
[[Category:Charles University in Prague alumni]]
[[Category:Georgia Institute of Technology faculty]]
[[Category:Place of birth missing (living people)]]
[[Category:Year of birth missing (living people)]]
[[Category:20th-century mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:Living people]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Fellows of the Society for Industrial and Applied Mathematics]]
[[Category:Graph theorists]]


{{US-mathematician-stub}}</text>
      <sha1>0pvj02plvi4skutpw0014jbmkgtjlyu</sha1>
    </revision>
  </page>
  <page>
    <title>Shapley–Folkman lemma</title>
    <ns>0</ns>
    <id>29237460</id>
    <revision>
      <id>869765707</id>
      <parentid>869760221</parentid>
      <timestamp>2018-11-20T06:15:06Z</timestamp>
      <contributor>
        <username>Drusus 0</username>
        <id>12091506</id>
      </contributor>
      <comment>/* Statements */ compacter formulation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="87077">{{good article}}
[[File:Shapley–Folkman lemma.svg|thumb|300px|alt=The Shapley–Folkman lemma depicted by a diagram with two panes, one on the left and the other on the right. The left-hand pane displays four sets, which are displayed in a two-by-two array. Each of the sets contains exactly two points, which are displayed in red. In each set, the two points are joined by a pink line-segment, which is the convex hull of the original set. Each set has exactly one point that is indicated with a plus-symbol. In the top row of the two-by-two array, the plus-symbol lies in the interior of the line segment; in the bottom row, the plus-symbol coincides with one of the red-points. This completes the description of the left-hand pane of the diagram. The right-hand pane displays the Minkowski sum of the sets, which is the union of the sums having exactly one point from each summand-set; for the displayed sets, the sixteen sums are distinct points, which are displayed in red: The right-hand red sum-points are the sums of the left-hand red summand-points. The convex hull of the sixteen red-points is shaded in pink. In the pink interior of the right-hand sumset lies exactly one plus-symbol, which is the (unique) sum of the plus-symbols from the right-hand side. Comparing the left array and the right pane, one confirms that the right-hand plus-symbol is indeed the sum of the four plus-symbols from the left-hand sets, precisely two points from the original non-convex summand-sets and two points from the convex hulls of the remaining summand-sets.|The Shapley–Folkman lemma is illustrated by the [[Minkowski addition]] of four sets. The point (+) in the [[convex hull]] of the Minkowski sum of the four [[convex set|non-convex set]]s (''right'') is the sum of four points (+) from the (left-hand) sets—two points in two non-convex sets plus two points in the convex hulls of two sets.  The convex hulls are shaded pink. The original sets each have exactly two points (shown as red dots).&lt;ref name="s69"/&gt;]]
The '''Shapley–Folkman&amp;nbsp;[[lemma (mathematics)|lemma]]''' is a result in [[convex geometry]] with applications in [[mathematical economics]] that describes  the [[Minkowski&amp;nbsp;addition]] of [[set (mathematics)|set]]s in a [[vector space]]. ''Minkowski addition'' is  defined as the addition of the sets' [[element (mathematics)|member]]s: for example, adding the set consisting of the [[integer]]s zero and one to itself yields the set consisting of zero, one, and two:
: {0,&amp;nbsp;1}&amp;nbsp;+&amp;nbsp;{0,&amp;nbsp;1} = {0&amp;nbsp;+&amp;nbsp;0,&amp;nbsp;0&amp;nbsp;+&amp;nbsp;1,&amp;nbsp;1&amp;nbsp;+&amp;nbsp;0,&amp;nbsp;1&amp;nbsp;+&amp;nbsp;1} = {0,&amp;nbsp;1,&amp;nbsp;2}.
The Shapley–Folkman lemma and related results provide an affirmative answer to the question, "Is the sum of many sets close to being [[convex set|convex]]?"&lt;ref name="Howe" &gt;{{harvtxt|Howe|1979|p=1}}: {{citation|title=On the tendency toward convexity of the vector&amp;nbsp;sum of sets|authorlink=Roger Evans Howe|last=Howe|first=Roger |date=3 November 1979 |publisher=[[Cowles Foundation|Cowles Foundation for Research in Economics]], Yale University|series=Cowles Foundation discussion papers|location=Box&amp;nbsp;2125 Yale&amp;nbsp;Station, New&amp;nbsp;Haven, CT&amp;nbsp;06520|volume=538 |url=http://cowles.econ.yale.edu/P/cd/d05a/d0538.pdf|&lt;!-- url-2=http://econpapers.repec.org/RePEc:cwl:cwldpp:538 --&gt;|accessdate=1 January 2011}}
&lt;/ref&gt;  A set is defined to be ''convex'' if every [[line segment]] joining two of its points is a [[subset]] in the set: For example, the solid [[unit disk|disk]]&amp;nbsp;&lt;big&gt;&lt;math&gt;\bullet&lt;/math&gt;&lt;/big&gt; is a convex set but  the [[unit circle|circle]]&amp;nbsp;&lt;big&gt;&lt;math&gt;\circ&lt;/math&gt;&lt;/big&gt; is not, because the line segment joining two distinct points&amp;nbsp;&lt;math&gt;\oslash&lt;/math&gt; is not a subset of the circle. The Shapley–Folkman lemma suggests that if the number of summed sets exceeds the [[dimension (linear algebra)|dimension]] of the vector space, then their Minkowski&amp;nbsp;sum is approximately convex.&lt;ref name="s69"&gt;{{harvtxt|Starr|1969}}&lt;/ref&gt;

The Shapley–Folkman lemma was introduced as a step in the [[mathematical proof|proof]] of the '''Shapley–Folkman [[theorem]]''', which states an [[upper bound]] on the [[Euclidean distance|distance]] between the Minkowski sum and its [[convex hull]]. The ''convex hull'' of a set&amp;nbsp;''Q'' is the smallest convex&amp;nbsp;set that contains&amp;nbsp;''Q''. This distance is zero [[if and only if]] the sum is convex. 
The theorem's bound on the distance depends&amp;nbsp;on the dimension&amp;nbsp;''D'' and on the shapes of the summand-sets, but ''not'' on the number of summand-sets&amp;nbsp;''N'', {{nowrap|when ''N'' &gt; ''D''.}} 
The shapes of a subcollection of only&amp;nbsp;''D'' summand-sets determine the bound on the distance between the Minkowski&amp;nbsp;''[[arithmetic mean|average]]'' of&amp;nbsp;''N''&amp;nbsp;sets
: {{frac|1|''N''}} (''Q''&lt;sub&gt;1&lt;/sub&gt; + ''Q''&lt;sub&gt;2&lt;/sub&gt; + ... + ''Q''&lt;sub&gt;''N''&lt;/sub&gt;)
and its convex hull. As&amp;nbsp;''N'' increases to [[infinity]], the bound [[limit of a sequence|decreases to zero]] (for summand-sets of uniformly bounded size).&lt;ref name="Starr08"/&gt;  The Shapley–Folkman theorem's upper bound was decreased by '''Starr's [[corollary]]''' (alternatively, the '''Shapley–Folkman–Starr theorem''').

The lemma of [[Lloyd Shapley]] and [[Jon Folkman]] was first published by the economist [[Ross Starr|Ross&amp;nbsp;M. Starr]], who was investigating the existence of [[general equilibrium theory#Nonconvexities in large economies|economic equilibria]] while studying with [[Kenneth Arrow]].&lt;ref name="s69"/&gt; In his paper, Starr studied a ''convexified'' economy, in which non-convex sets were replaced by their convex hulls; Starr proved that the convexified economy has equilibria that are closely approximated by "quasi-equilibria" of the original economy; moreover, he proved that every quasi-equilibrium has many of the optimal properties of true equilibria, which are proved to exist for convex economies. Following Starr's&amp;nbsp;1969 paper, the Shapley–Folkman–Starr results have been widely used to show that central results of (convex) economic theory are good approximations to large economies with non-convexities; for example, quasi-equilibria closely approximate equilibria of a convexified economy. "The derivation of these results in general form has been one of the major achievements of postwar economic theory", wrote [[Roger&amp;nbsp;Guesnerie]].&lt;ref name="g89-p138"&gt;{{harvtxt|Guesnerie|1989|p=138}}&lt;/ref&gt; The topic of [[non-convexity (economics)|non-convex sets in economics]] has been studied by many [[Nobel Prize in Economics|Nobel laureates]], besides Lloyd Shapley who won the prize in 2012: Arrow (1972), [[Robert Aumann]] (2005), [[Gérard Debreu]] (1983), [[Tjalling Koopmans]] (1975), [[Paul Krugman]] (2008), and [[Paul Samuelson]] (1970); the complementary topic of [[convexity in economics|convex sets in economics]] has been emphasized by these laureates, along with [[Leonid Hurwicz]], [[Leonid Kantorovich]] (1975), and [[Robert Solow]] (1987).

The Shapley–Folkman lemma has applications also in [[mathematical optimization|optimization]] and [[probability theory]].&lt;ref name="Starr08" &gt;{{harvtxt|Starr|2008}}&lt;/ref&gt; In optimization theory, the Shapley–Folkman lemma has been used to explain the successful solution of minimization problems that are sums of many [[function (mathematics)|function]]s.&lt;ref name="Ekeland76"/&gt;&lt;ref name="Bertsekas82"/&gt; The Shapley–Folkman lemma has also been used in [[mathematical proof|proofs]] of the [[law of large numbers|"law of averages"]] for [[stochastic geometry|random sets]], a theorem that had been proved &lt;!-- to hold --&gt; for only convex sets.&lt;ref name="ArtsteinVitale"/&gt;
{{TOC limit|3}}

==Introductory example==
For example, the subset of the integers&amp;nbsp;{0,&amp;nbsp;1,&amp;nbsp;2} is contained in the [[interval (mathematics)|interval]] of [[real number]]s&amp;nbsp;[0,&amp;nbsp;2], which is convex. The Shapley–Folkman lemma implies that every point in&amp;nbsp;[0,&amp;nbsp;2] is the sum of an integer from&amp;nbsp;{0,&amp;nbsp;1} and a real number from&amp;nbsp;[0,&amp;nbsp;1].&lt;ref name="Carter94" &gt;{{harvtxt|Carter|2001|p=94|}}&lt;/ref&gt;

The distance between the convex interval&amp;nbsp;[0,&amp;nbsp;2] and the non-convex set&amp;nbsp;{0,&amp;nbsp;1,&amp;nbsp;2} equals one-half
: 1/2 = |1 &amp;minus; 1/2| = |0 &amp;minus; 1/2| = |2 &amp;minus; 3/2| = |1 &amp;minus; 3/2|.
However, the distance between the ''[[arithmetic mean|average]]'' Minkowski&amp;nbsp;sum
: 1/2 ( {0,&amp;nbsp;1}&amp;nbsp;+&amp;nbsp;{0,&amp;nbsp;1} ) = {0,&amp;nbsp;1/2,&amp;nbsp;1}
and its convex hull&amp;nbsp;[0,&amp;nbsp;1] is only&amp;nbsp;1/4, which is half the distance&amp;nbsp;(1/2) between its summand&amp;nbsp;{0,&amp;nbsp;1} and&amp;nbsp;[0,&amp;nbsp;1]. As more sets are added together, the average of their sum "fills out" its convex hull: The maximum distance between the average and its convex hull approaches zero as the average includes more [[addition#summand|summand]]s.&lt;ref name="Carter94"/&gt;

==Preliminaries==
The Shapley–Folkman lemma depends upon the following definitions and results from [[convex geometry]].

===Real vector spaces===

A [[real number|real]] [[vector space]] of two&amp;nbsp;[[dimension (vector space)|dimension]]s can be given a [[Cartesian coordinate system]] in which every point is identified by an [[ordered pair]] of real numbers, called "coordinates", which are conventionally denoted by&amp;nbsp;''x'' and&amp;nbsp;''y''. Two points in the Cartesian&amp;nbsp;plane can be ''[[Euclidean vector#Addition and subtraction|added]]'' coordinate-wise
: (''x''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''y''&lt;sub&gt;1&lt;/sub&gt;) + (''x''&lt;sub&gt;2&lt;/sub&gt;,&amp;nbsp;''y''&lt;sub&gt;2&lt;/sub&gt;) = (''x''&lt;sub&gt;1&lt;/sub&gt;+''x''&lt;sub&gt;2&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;+''y''&lt;sub&gt;2&lt;/sub&gt;);
further, a point can be ''[[scalar multiplication|multiplied]]'' by each real&amp;nbsp;number&amp;nbsp;''λ'' coordinate-wise
: ''λ''&amp;nbsp;(''x'',&amp;nbsp;''y'') = (''λx'', ''λy'').

More generally, any real vector space of (finite) dimension&amp;nbsp;''D'' can be viewed as the [[set (mathematics)|set]] of all [[tuple|''D''-tuple]]s of&amp;nbsp;''D'' real&amp;nbsp;numbers {{nowrap|{&amp;nbsp;(''v''&lt;sub&gt;1&lt;/sub&gt;, ''v''&lt;sub&gt;2&lt;/sub&gt;, .&amp;nbsp;.&amp;nbsp;.&amp;nbsp;, ''v''&lt;sub&gt;D&lt;/sub&gt;)}}&amp;nbsp;} on which  two&amp;nbsp;[[operation (mathematics)|operation]]s are defined: [[Euclidean vector#Addition and subtraction|vector&amp;nbsp;addition]] and [[scalar multiplication|multiplication by a real&amp;nbsp;number]]. For finite-dimensional vector spaces, the operations of vector&amp;nbsp;addition and real-number&amp;nbsp;multiplication can each be defined coordinate-wise, following the example of the Cartesian plane.&lt;ref&gt;{{harvtxt|Arrow|Hahn|1980|p=375}}&lt;/ref&gt;

===Convex sets===
{{multiple image
   | width     =155
   | footer    = [[Line segment]]s test whether a subset be [[convex set|convex]].
   | image1    = Convex polygon illustration1.svg
   | alt1      = Illustration of a convex set, which looks somewhat like a disk: A (green) convex set contains the (black) line-segment joining the points x and y. The entire line-segment is a subset of the convex set.
   | caption1  =In a [[convex set]]&amp;nbsp;''Q'', the [[line segment]] connecting any two of its points is a subset of&amp;nbsp;''Q''.
   | image2    = Convex polygon illustration2.svg
   | alt2      = Illustration of a green non-convex set, which looks somewhat like a [[boomerang]] or [[cashew]] nut. The black line-segment joins the points ''x'' and ''y'' of the green non-convex set. Part of the line segment is not contained in the green non-convex set.
   | caption2  =In a [[convex set|non-convex set]]&amp;nbsp;''Q'', a point in some [[line segment|line-segment]] joining two of its points is not a member of&amp;nbsp;''Q''.
}}

In a real vector space, a [[empty set|non-empty]] set&amp;nbsp;''Q'' is defined to be ''[[convex set|convex]]'' if, for each pair of its points, every point on the [[line segment]] that joins them is a [[subset]] of&amp;nbsp;''Q''. For example, a solid [[unit disk|disk]]&amp;nbsp;&lt;big&gt;&lt;math&gt;\bullet&lt;/math&gt;&lt;/big&gt; is convex but a [[unit circle|circle]]&amp;nbsp;&lt;big&gt;&lt;math&gt;\circ&lt;/math&gt;&lt;/big&gt; is not, because it does not contain a line segment joining its points&amp;nbsp;&lt;math&gt;\oslash&lt;/math&gt;; the non-convex set of three integers&amp;nbsp;{0,&amp;nbsp;1,&amp;nbsp;2} is contained in the interval&amp;nbsp;[0,&amp;nbsp;2], which is convex. For example, a solid [[cube (geometry)|cube]] is convex; however, anything that is hollow or dented, for example, a [[crescent]] shape, is non-convex. The [[empty&amp;nbsp;set]] is convex, either by definition&lt;ref name="Rock10" /&gt; or [[vacuous truth|vacuously]], depending on the author.

More formally, a set&amp;nbsp;''Q'' is convex if, for all points&amp;nbsp;''v''&lt;sub&gt;0&lt;/sub&gt; and&amp;nbsp;''v''&lt;sub&gt;1&lt;/sub&gt; in&amp;nbsp;''Q'' and for every real number&amp;nbsp;''λ'' in the [[unit interval]]&amp;nbsp;[0,1], the point
: (1&amp;nbsp;−&amp;nbsp;''λ'')&amp;nbsp;''v''&lt;sub&gt;0&lt;/sub&gt; + ''λv''&lt;sub&gt;1&lt;/sub&gt;
is a [[element (mathematics)|member]] of&amp;nbsp;''Q''.

By [[mathematical induction]], a set&amp;nbsp;''Q'' is convex if and only&amp;nbsp;if every [[convex combination]] of members of&amp;nbsp;''Q'' also belongs to&amp;nbsp;''Q''. By definition, a ''convex combination'' of an indexed&amp;nbsp;subset&amp;nbsp;{''v''&lt;sub&gt;0&lt;/sub&gt;,&amp;nbsp;''v''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;.&amp;nbsp;.&amp;nbsp;.&amp;nbsp;,&amp;nbsp;''v''&lt;sub&gt;D&lt;/sub&gt;} of a vector space is any weighted average&amp;nbsp;{{nowrap|''λ''&lt;sub&gt;0&lt;/sub&gt;''v''&lt;sub&gt;0&lt;/sub&gt; + ''λ''&lt;sub&gt;1&lt;/sub&gt;''v''&lt;sub&gt;1&lt;/sub&gt; + .&amp;nbsp;.&amp;nbsp;. +  ''λ''&lt;sub&gt;D&lt;/sub&gt;''v''&lt;sub&gt;D&lt;/sub&gt;,}} for some indexed&amp;nbsp;set of non-negative real numbers&amp;nbsp;{''λ''&lt;sub&gt;d&lt;/sub&gt;} satisfying the equation&amp;nbsp;{{nowrap|''λ''&lt;sub&gt;0&lt;/sub&gt; + ''λ''&lt;sub&gt;1&lt;/sub&gt; + .&amp;nbsp;.&amp;nbsp;.&amp;nbsp; +  ''λ''&lt;sub&gt;D&lt;/sub&gt;}}&amp;nbsp;=&amp;nbsp;1.&lt;ref&gt;{{harvtxt|Arrow|Hahn|1980|p=376}},  {{harvtxt|Rockafellar|1997|pp=10–11}}, and {{harvtxt|Green|Heller|1981|p=37}}&lt;/ref&gt;

The definition of a convex&amp;nbsp;set implies that the ''[[intersection (set theory)|intersection]]'' of two convex&amp;nbsp;sets is a convex set. More generally, the intersection of a family of convex sets is a convex set. In particular, the intersection of two [[disjoint sets]] is the empty set, which is convex.&lt;ref name="Rock10" &gt;{{harvtxt|Rockafellar|1997|p=10}}&lt;/ref&gt;&lt;!-- In this proposition, the family can be empty, finite, countably infinite, or uncountably infinite.  --&gt;

===Convex hull===
[[File:Extreme points.svg|thumb|right|alt=A picture of a smoothed triangle, like a triangular (Mexican) tortilla-chip or a triangular road-sign. Each of the three rounded corners is drawn with a red curve. The remaining interior points of the triangular shape are shaded with blue.|In the [[convex hull]] of the red&amp;nbsp;set, each blue&amp;nbsp;point is a [[convex combination]] of some red&amp;nbsp;points.]]

For every subset&amp;nbsp;''Q'' of a real vector&amp;nbsp;space, its {{nowrap|''[[convex hull]]''&amp;nbsp;Conv(''Q'')}} is the [[minimal element|minimal]] convex set that contains&amp;nbsp;''Q''. Thus&amp;nbsp;Conv(''Q'') is the intersection of all the convex sets that [[cover (mathematics)|cover]]&amp;nbsp;''Q''. The convex hull of a set can be equivalently defined to be the set of all convex combinations of points in&amp;nbsp;''Q''.&lt;ref&gt;{{harvtxt|Arrow|Hahn|1980|p=385}} and {{harvtxt|Rockafellar|1997|pp=11–12}}&lt;/ref&gt; For example, the convex hull of the set of [[integer]]s&amp;nbsp;{0,1} is the closed [[interval (mathematics)|interval]] of [[real number]]s&amp;nbsp;[0,1], which contains the integer end-points.&lt;ref name="Carter94" /&gt; The convex hull of the [[unit circle]] is the closed [[unit disk]], which contains the unit circle.

===Minkowski addition===
[[File:Minkowski sum graph - vector version.svg|thumb|alt=Three squares are shown in the non-negative quadrant of the Cartesian plane. The square &lt;math&gt;Q_{1}=[0,1]\times [0,1]&lt;/math&gt; is green. The square &lt;math&gt;Q_{2}=[1,2]\times [1,2]&lt;/math&gt; is brown, and it sits inside the turquoise square &lt;math&gt;Q_{1}+Q_{2}=[1,3]\times [1,3]&lt;/math&gt;.|[[Minkowski addition]] of sets. The &lt;!-- [[Minkowski addition|Minkowski]]&amp;nbsp; --&gt;sum of the squares &lt;math&gt;Q_{1}=[0,1]^{2}&lt;/math&gt; and &lt;math&gt;Q_{2}=[1,2]^{2}&lt;/sup&gt; is the square &lt;math&gt;Q_{1}+Q_{2}=[1,3]^{2}2&lt;/math&gt;.]]

In any vector space (or algebraic structure with addition), &lt;math&gt;X&lt;/math&gt;, the [[Minkowski addition|'''Minkowski sum''']] of two non-empty sets &lt;math&gt;A, B\subseteq X&lt;/math&gt; is defined to be the element-wise operation &lt;math&gt;A+B := \{x+y\mid x\in A,~y\in B\}.&lt;/math&gt; (See also &lt;ref&gt;{{harvtxt|Schneider|1993|p=xi}}  and {{harvtxt|Rockafellar|1997|p=16}}&lt;/ref&gt;.)
For example
:&lt;math&gt;\{0,1\}+\{0,1\}=\{0+0,0+1,1+0,1+1\}=\{0,1,2\}&lt;/math&gt;
This operation is clearly commutative and associative on the collection of non-empty sets. All such operations extend in a well-defined manner to recursive forms &lt;math&gt;\sum_{n=1}^{N}Q_{n}=Q_{1}+Q_{2}+\ldots+Q_{N}.&lt;/math&gt; By the principle of induction it is easy to see that&lt;ref&gt;{{harvtxt|Rockafellar|1997|p=17}} and {{harvtxt|Starr|1997|p=78}}&lt;/ref&gt;
:&lt;math&gt;\sum_{n=1}^{N}Q_{n}=\{\sum_{n=1}^{N}q_{n}\mid q_{n}\in Q_{n},~1\leq n\leq N\}.&lt;/math&gt;

===Convex hulls of Minkowski sums===
Minkowski addition behaves well with respect to taking convex hulls. Specifically, for all subsets &lt;math&gt;A,B\subseteq X&lt;/math&gt; of a real vector space, &lt;math&gt;X&lt;/math&gt;, the [[convex hull]] of their Minkowski sum is the Minkowski sum of their convex hulls. That is,
:&lt;math&gt;\mathrm{Conv}(A+B) = \mathrm{Conv}(A)+\mathrm{Conv}(B).&lt;/math&gt;
And by induction it follows that
:&lt;math&gt;\mathrm{Conv}(\sum_{n=1}^{N}Q_{n}) = \sum_{n=1}^{N}\mathrm{Conv}(Q_{n})&lt;/math&gt;
for any &lt;math&gt;N\in\mathbb{N}&lt;/math&gt; and non-empty subsets &lt;math&gt;Q_{n}\subseteq X&lt;/math&gt;, &lt;math&gt;1\leq n\leq N&lt;/math&gt;.&lt;ref name="Schneider"&gt;{{harvtxt|Schneider|1993|pp=2–3}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Arrow|Hahn|1980|p=387}}&lt;/ref&gt;

==Statements==
[[File:Shapley–Folkman lemma.svg|thumb|300px|alt=The Shapley–Folkman lemma depicted by a diagram with two panes, one on the left and the other on the right. The left-hand pane displays four sets, which are displayed in a two-by-two array. Each of the sets contains exactly two points, which are displayed in red. In each set, the two points are joined by a pink line-segment, which is the convex hull of the original set. Each set has exactly one point that is indicated with a plus-symbol. In the top row of the two-by-two array, the plus-symbol lies in the interior of the line segment; in the bottom row, the plus-symbol coincides with one of the red-points. This completes the description of the left-hand pane of the diagram. The right-hand pane displays the Minkowski sum of the sets, which is the union of the sums having exactly one point from each summand-set; for the displayed sets, the sixteen sums are distinct points, which are displayed in red: The right-hand red sum-points are the sums of the left-hand red summand-points. The convex hull of the sixteen red-points is shaded in pink. In the pink interior of the right-hand sumset lies exactly one plus-symbol, which is the (unique) sum of the plus-symbols from the right-hand side. The right-hand plus-symbol is indeed the sum of the four plus-symbols from the left-hand sets, precisely two points from the original non-convex summand-sets and two points from the convex hulls of the remaining summand-sets.|
|Minkowski addition and convex hulls. The sixteen dark-red points (on the right) form  the [[Minkowski addition|Minkowski sum]] of the four non-convex sets (on the left), each of which consists of a pair of red points. Their convex hulls (shaded pink) contain plus-signs (+): The right plus-sign is the sum of the left plus-signs.]]

By the preceding identity, for every point &lt;math&gt;x\in\mathrm{Conv}(\sum_{n=1}^{N}Q_{n})&lt;/math&gt; there exist elements in the convex hulls, &lt;math&gt;q_{n}(x)\in\mathrm{Conv}(Q_{n})&lt;/math&gt; for &lt;math&gt;1\leq n\leq N&lt;/math&gt;, dependent upon &lt;math&gt;x&lt;/math&gt;, and such that &lt;math&gt;\sum_{n=1}^{N}q_{n}(x)=x&lt;/math&gt;.

===Lemma of Shapley and Folkman===
[[File:Shapley, Lloyd (1923).jpeg|thumb|alt=Picture of Lloyd Shapley|A Winner of the 2012 Nobel Award in Economics, [[Lloyd Shapley]] proved the Shapley–Folkman lemma with [[Jon Folkman]].&lt;ref name="s69"/&gt;]]

Working with the above setup, the '''Shapley–Folkman lemma''' states that in the above representation

: &lt;math&gt;x=\sum_{n=1}^{N}q_{n}(x)&lt;/math&gt;

''at most'' &lt;math&gt;D&lt;/math&gt; of the summands &lt;math&gt;q_{n}(x)&lt;/math&gt; need to be taken strictly from the convex hulls. That is, there exists a representation of the above form, such that &lt;math&gt;|\{l\leq n\leq N\mid q_{n}(x)\in\mathrm{Conv}(Q_{n})\setminus Q_{n}\}|\leq D&lt;/math&gt;. Shuffling indexes if necessary, this means that the point has a representation

:&lt;math&gt;x = \sum_{n=1}^{D}q_{n}(x) + \sum_{n=D+1}^{N} q_n(x)&lt;/math&gt;

where &lt;math&gt;q_{n}\in\mathrm{Conv}(Q_{n})&lt;/math&gt; for &lt;math&gt;1\leq n\leq D&lt;/math&gt;
and &lt;math&gt;q_{n}\in Q_{n}&lt;/math&gt; for &lt;math&gt;D+1\leq n\leq N&lt;/math&gt;. Note that the re-indexing depends on the point.&lt;ref&gt;{{harvtxt|Starr|1969|pp=35–36}}&lt;/ref&gt; More succinctly, the Shapley–Folkman lemma states that

:&lt;math&gt;\mathrm{Conv}(\sum_{n=1}^{N}Q_{n})\subseteq\bigcup_{I\subseteq\{1,2,\ldots N\}:~|I|=D}\sum_{n\in I}\mathrm{Conv}(Q_{n})+\sum_{n\notin I}Q_{n}.&lt;/math&gt;

As an example, every point in &lt;math&gt;[0,2]=[0,1]+[0,1]=\mathrm{Conv}(\{0,1\})+\mathrm{Conv}(\{0,1\})&lt;/math&gt; is according to the lemma the sum of an element in &lt;math&gt;\{0,1\}&lt;/math&gt; and an element in &lt;math&gt;[0,1]&lt;/math&gt;.&lt;ref name="Carter94"/&gt;

====Dimension of a real vector space====
Conversely, the Shapley–Folkman lemma characterizes the [[dimension (vector space)|dimension]] of finite-dimensional, real vector spaces. That is, if a vector space obeys the Shapley–Folkman lemma for a [[natural number]]&amp;nbsp;''D'', and for no number less than&amp;nbsp;''D'', then its dimension is exactly&amp;nbsp;''D'';&lt;ref&gt;{{harvtxt|Schneider|1993|p=131}}&lt;/ref&gt;  the Shapley–Folkman lemma holds for only ''finite-dimensional'' vector spaces.&lt;ref&gt;{{harvtxt|Schneider|1993|p=140}} credits this result to {{harvtxt|Borwein|O'Brien|1978}}: {{cite journal|last1=Borwein|first1=J.&amp;nbsp;M.|authorlink=Jonathan Borwein|last2=O'Brien|first2=R.&amp;nbsp;C.|title=Cancellation characterizes convexity|journal=Nanta&amp;nbsp;Mathematica (Nanyang&amp;nbsp;University)|issn=0077-2739|volume=11|year=1978|pages=100–102|mr=510842|ref=harv}}&lt;/ref&gt;

===Shapley–Folkman theorem and Starr's corollary===
[[File:Inner radius.svg|thumb|240px|alt=A blue disk contains red points. A smaller green disk sits in the largest concavity in among these red points.|The circumradius (blue) and inner&amp;nbsp;radius (green) of a point set (dark red, with its convex hull shown as the lighter red dashed lines). The inner&amp;nbsp;radius is smaller than the circumradius except for subsets of a single circle, for which they are equal.]]

Shapley and Folkman used their lemma &lt;!-- , which is purely [[discrete geometry|combinatorial]], --&gt; to prove their &lt;!-- [[metric space|metric]] --&gt; theorem, which bounds the distance between a Minkowski sum and its convex hull, the "''convexified''" sum:
* The ''Shapley–Folkman theorem'' states that the squared [[Euclidean distance]] from any point in the convexified sum&amp;nbsp;{{nowrap|Conv( ∑&amp;nbsp;''Q''&lt;sub&gt;''n''&lt;/sub&gt; )}} to the original (unconvexified) sum&amp;nbsp;{{nowrap|∑&amp;nbsp;''Q''&lt;sub&gt;''n''&lt;/sub&gt;}} is bounded by the sum of the squares of the&amp;nbsp;''D'' largest circumradii of the sets&amp;nbsp;''Q''&lt;sub&gt;''n''&lt;/sub&gt; (the radii of the [[Smallest circle problem|smallest spheres enclosing these sets]]).&lt;ref&gt;{{harvtxt|Schneider|1993|p=129}}&lt;/ref&gt; This bound is independent of the number of summand-sets&amp;nbsp;''N'' (if&amp;nbsp;{{nowrap|''N''&amp;nbsp;&amp;gt;&amp;nbsp;''D'').}}&lt;ref&gt;{{harvtxt|Starr|1969|p=36}}&lt;/ref&gt;
The Shapley–Folkman theorem states a bound on the distance between the Minkowski sum and its convex hull; this distance is zero [[if and only if]] the sum is convex. Their bound on the distance depends&amp;nbsp;on the dimension&amp;nbsp;''D'' and on the shapes of the summand-sets, but ''not'' on the number of summand-sets&amp;nbsp;''N'', {{nowrap|when ''N'' &gt; ''D''.}}&lt;ref name="Starr08"/&gt;

The circumradius often exceeds (and cannot be less than) the ''inner&amp;nbsp;radius'':&lt;ref name="Starr 1969 37"&gt;{{harvtxt|Starr|1969|p=37}}&lt;/ref&gt;

* The ''inner&amp;nbsp;radius'' of a &lt;!-- non–convex --&gt; set&amp;nbsp;''Q''&lt;sub&gt;''n''&lt;/sub&gt; is defined to be the smallest number&amp;nbsp;''r'' such that, for any point&amp;nbsp;''q'' in the convex&amp;nbsp;hull of&amp;nbsp;''Q''&lt;sub&gt;''n''&lt;/sub&gt;, there is a [[sphere]] of radius&amp;nbsp;''r'' that contains a subset of&amp;nbsp;''Q''&lt;sub&gt;''n''&lt;/sub&gt; whose convex&amp;nbsp;hull contains&amp;nbsp;''q''.
Starr used the inner&amp;nbsp;radius to reduce the upper bound stated in the Shapley–Folkman theorem:
* ''Starr's corollary to the Shapley–Folkman theorem'' states that the squared Euclidean distance from any point&amp;nbsp;''x'' in the convexified sum&amp;nbsp;{{nowrap|Conv( ∑&amp;nbsp;''Q''&lt;sub&gt;''n''&lt;/sub&gt; )}} to the original (unconvexified) sum&amp;nbsp;{{nowrap|∑&amp;nbsp;''Q''&lt;sub&gt;''n''&lt;/sub&gt;}}  is bounded by the sum of the squares of the&amp;nbsp;''D'' largest inner-radii of the sets&amp;nbsp;''Q''&lt;sub&gt;''n''&lt;/sub&gt;.&lt;ref name="Starr 1969 37"/&gt;&lt;ref&gt;{{harvtxt|Schneider|1993|pp=129–130}}
&lt;/ref&gt;
Starr's corollary &lt;!-- to the Shapley–Folkman theorem --&gt; states an [[upper and lower bounds|upper&amp;nbsp;bound]] on the Euclidean distance  between the Minkowski&amp;nbsp;sum of&amp;nbsp;''N'' sets and the convex&amp;nbsp;hull of the Minkowski&amp;nbsp;sum; this distance between the sum and its convex hull is a measurement of the non-convexity of the set. For [[abuse of notation|simplicity]], this distance is called the "''non-convexity''" of the set (with respect to Starr's measurement). Thus, Starr's bound on the non-convexity of the sum depends on only the&amp;nbsp;''D'' largest inner&amp;nbsp;radii of the summand-sets; however, Starr's bound does not depend on the number of summand-sets&amp;nbsp;''N'', when&amp;nbsp;{{nowrap|''N''&amp;nbsp;&gt;&amp;nbsp;''D''}}.
For example, the distance between the convex interval&amp;nbsp;[0,&amp;nbsp;2] and the non-convex set&amp;nbsp;{0,&amp;nbsp;1,&amp;nbsp;2} equals one-half
: 1/2 = |1&amp;nbsp;&amp;minus;&amp;nbsp;1/2| = |0&amp;nbsp;&amp;minus;&amp;nbsp;1/2| = |2&amp;nbsp;&amp;minus;&amp;nbsp;3/2| = |1&amp;nbsp;&amp;minus;&amp;nbsp;3/2|.
Thus, Starr's bound on the non-convexity of the ''average''&lt;!-- &amp;nbsp; --&gt;
: {{frac|1|''N''}}&amp;nbsp;∑&amp;nbsp;''Q''&lt;sub&gt;''n''&lt;/sub&gt;
decreases as the number of summands&amp;nbsp;''N'' increases.
For example, the distance between the ''averaged'' set
: 1/2 ( {0,&amp;nbsp;1}&amp;nbsp;+&amp;nbsp;{0,&amp;nbsp;1} ) = {0,&amp;nbsp;1/2,&amp;nbsp;1}
and its convex hull&amp;nbsp;[0,&amp;nbsp;1] is only&amp;nbsp;1/4, which is half the distance&amp;nbsp;(1/2) between its summand&amp;nbsp;{0,&amp;nbsp;1} and&amp;nbsp;[0,&amp;nbsp;1].
The shapes of a subcollection of only&amp;nbsp;''D'' summand-sets determine the bound on the distance between the ''average&amp;nbsp;set'' &lt;!-- : {{frac|1|''N''}}&amp;nbsp;∑&amp;nbsp;''Q''&lt;sub&gt;''n''&lt;/sub&gt; --&gt; and its convex hull; thus, as the number of summands increases to [[infinity]], the bound [[limit of a sequence|decreases to zero]] (for summand-sets of uniformly bounded size).&lt;ref name="Starr08"/&gt; In fact, Starr's bound on the non-convexity of this average&amp;nbsp;set [[limit of a sequence|decreases to zero]] as the number of summands&amp;nbsp;''N'' increases to [[infinity]] (when the inner&amp;nbsp;radii of all the summands are  bounded by the same number).&lt;ref name="Starr08"/&gt;

===Proofs and computations===
The original proof of the Shapley–Folkman lemma established only the [[existence theorem|existence]] of the representation, but did not provide an [[algorithm]] for computing the representation: Similar proofs have been given by [[Kenneth Arrow|Arrow]] and [[Frank Hahn|Hahn]],&lt;ref&gt;{{harvtxt|Arrow|Hahn|1980|pp=392–395}}&lt;/ref&gt; [[J. W. S. Cassels|Cassels]],&lt;ref&gt;{{harvtxt|Cassels|1975|pp=435–436}}&lt;/ref&gt; and Schneider,&lt;ref&gt;{{harvtxt|Schneider|1993|p=128}}&lt;/ref&gt; among others. An abstract and elegant proof by [[Ivar Ekeland|Ekeland]] has been extended by Artstein.&lt;ref&gt;{{harvtxt|Ekeland|1999|pp=357–359}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Artstein|1980|p=180}}&lt;/ref&gt; Different proofs  have appeared in unpublished papers, also.&lt;ref name="Howe"/&gt;&lt;ref&gt;{{citation|title=Economics&amp;nbsp;201B: Nonconvex preferences and approximate equilibria|chapter=1 The Shapley–Folkman theorem|pages=1–5|&lt;!-- date=2005–03–14 --&gt;|date=14 March 2005|first=Robert M.|last=Anderson|authorlink=&lt;!-- NOT WP's Robert M. Anderson --&gt;|location=Berkeley, CA|publisher=Economics Department, University of California, Berkeley|url=http://elsa.berkeley.edu/users/anderson/Econ201B/NonconvexHandout.pdf|accessdate=1 January 2011}}&lt;/ref&gt; In&amp;nbsp;1981, Starr published an [[iterative method]] for computing a representation of a given sum-point; however, his computational proof provides a weaker bound than does the original result.&lt;ref&gt;{{cite journal|mr=640201|last=Starr|first=Ross&amp;nbsp;M.|authorlink=Ross M. Starr|title=Approximation of points of convex hull of a sum of sets by points of the sum: An elementary approach|journal=Journal of Economic Theory|volume=25|year=1981|issue=2|pages=314–317
|doi=10.1016/0022-0531(81)90010-7
|url=http://www.sciencedirect.com/science/article/B6WJ3-4CYGB4B-FB/2/9e65178b1c246365bee61dc19127175d|ref=harv}}&lt;/ref&gt; An elementary proof of the Shapley–Folkman lemma in finite-dimensional space can be found in the book by [[Dimitri Bertsekas|Bertsekas]]&lt;ref&gt;
{{cite book
  | last = Bertsekas
  | first = Dimitri P.
  | authorlink = Dimitri P. Bertsekas
  | title = Convex Optimization Theory
  | publisher = Athena Scientific
  | year = 2009
  | location = Belmont, MA.
  | isbn =  978-1-886529-31-1   |ref=harv
}} 
&lt;/ref&gt;
together with applications in estimating the duality gap in separable optimization problems and zero-sum games.

==Applications==
The Shapley–Folkman lemma enables researchers to extend results for Minkowski sums of convex sets to sums of general sets, which need not be convex. Such sums of sets arise in [[economics]], in [[mathematical optimization]], and in [[probability theory]]; in each of these three mathematical sciences, non-convexity is an important feature of applications.

===Economics===
[[File:Indifference curves showing budget line.svg|thumb|right|alt=The nonnegative quadrant of the Cartesian plane appears. A blue straight-line slopes downward as a secant joining two points, one on each of the axes. This blue line is tangent to a red curve that touches it at a marked point, whose coordinates are labeled ''Qx'' and ''Qy''.|The consumer [[preference (economics)|prefers]] every basket of goods on the [[indifference curve]]&amp;nbsp;''I''&lt;sub&gt;3&lt;/sub&gt; over each basket on &amp;nbsp;''I''&lt;sub&gt;2&lt;/sub&gt;.
The basket&amp;nbsp;(''Q''&lt;sub&gt;x&lt;/sub&gt;,&amp;nbsp;''Q''&lt;sub&gt;y&lt;/sub&gt;), where the budget line (''shown in blue'') [[supporting hyperplane|supports]]&amp;nbsp;''I''&lt;sub&gt;2&lt;/sub&gt;, is optimal and also feasible, unlike any basket lying on &amp;nbsp;''I''&lt;sub&gt;3&lt;/sub&gt;  which is preferred but unfeasible.]]
{{See also|Convexity in economics}}
In [[microeconomics|economics]], a consumer's [[Preference (economics)|preferences]] are defined over all "baskets" of goods. Each basket is represented as a non-negative vector, whose coordinates represent the quantities of the goods. On this set of baskets, an ''[[indifference curve]]'' is defined for each consumer; a consumer's indifference curve contains all the baskets of commodities that the consumer regards as equivalent: That is, for every pair of baskets on the same indifference curve, the consumer does not prefer one basket over another. Through each basket of commodities passes one indifference curve. A consumer's ''preference set'' (relative to an indifference curve) is the [[union (set theory)|union]] of the indifference curve and all the commodity baskets that the consumer prefers over the indifference curve. A consumer's ''preferences'' are ''convex'' if all such preference sets are convex.&lt;ref&gt;{{harvtxt|Mas-Colell|1985|pp=58–61}} and {{harvtxt|Arrow|Hahn|1980|pp=76–79}}&lt;/ref&gt;

An optimal basket of goods occurs where the budget-line [[supporting hyperplane|supports]] a consumer's preference set, as shown in the diagram. This means that an optimal basket is on the highest possible indifference curve given the budget-line, which is defined in terms of a price vector and the consumer's income (endowment vector). Thus, the set of optimal baskets is a &lt;!--  set valued function, or multifunction, or correspondence or relation--&gt;[[function (mathematics)|function]] of the &lt;!-- relative --&gt; prices, and this function is called the consumer's ''[[demand]]''. If the preference set is convex, then at every price the consumer's demand is a convex set, for example, a unique optimal basket or a line-segment of baskets.&lt;ref&gt;{{harvtxt|Arrow|Hahn|1980|pp=79–81}}&lt;/ref&gt;

====Non-convex preferences====
[[File:NonConvex.gif|right|thumb|300px|alt=Image of a non-convex preference set with a concavity un-supported by the budget line|When the consumer's preferences have concavities, the consumer may jump between two separate optimal baskets.]]
{{See also|Non-convexity (economics)}}
However, if a preference set is ''non-convex'', then some prices determine a budget-line that supports two ''separate'' optimal-baskets. For example, we can imagine that, for zoos, a lion costs as much as an eagle, and further that a zoo's budget suffices for one eagle or one lion. We can suppose also that a zoo-keeper views either animal as equally valuable. In this case, the zoo would purchase either one lion or one eagle. Of course, a contemporary zoo-keeper does not want to purchase half of an eagle and half of a lion (or a [[griffin]])! Thus, the zoo-keeper's preferences are non-convex: The zoo-keeper prefers having either animal to having any strictly convex combination of both.&lt;ref&gt;{{harvtxt|Starr|1969|p=26}}: "After all,
one may be indifferent between an automobile and a boat, but in most cases one&amp;nbsp;can neither&amp;nbsp;drive nor&amp;nbsp;sail the combination of half&amp;nbsp;boat, half&amp;nbsp;car."&lt;/ref&gt;

When the consumer's preference set is non-convex, then (for some prices) the consumer's demand is not [[connected space|connected]]; a disconnected demand implies some discontinuous behavior by the consumer, as discussed by [[Harold Hotelling]]:
&lt;blockquote&gt;
If indifference curves for purchases be thought of as possessing a wavy character, convex to the origin in some regions and concave in others, we are forced to the conclusion that it is only the portions convex to the origin that can be regarded as possessing any importance, since the others are essentially unobservable. They can be detected only by the discontinuities that may occur in demand with variation in price-ratios, leading to an abrupt jumping of a point of tangency across a chasm when the straight line is rotated. But, while such discontinuities may reveal the existence of chasms, they can never measure their depth. The concave portions of the indifference curves and their many-dimensional generalizations, if they exist, must forever remain in
unmeasurable obscurity.&lt;ref&gt;
{{harvtxt|Hotelling|1935|p=74}}:
{{cite journal|first=Harold|last=Hotelling|authorlink=Harold Hotelling|ref=harv
|title=Demand functions with limited budgets|journal=Econometrica|volume=3|issue=1|date=January 1935|pages=66–78|jstor=1907346|doi=10.2307/1907346}}
&lt;/ref&gt;
&lt;/blockquote&gt;
&lt;!-- [[File:Convex.gif|right|300px|alt=An image of a convex preference set being supported by a budget line.|With "quasi-equilibrium" prices, the budget-line [[supporting hyperplane|supports]] the convex hull of the [[indifference curve]].]] --&gt;
The difficulties of studying non-convex preferences were emphasized by [[Herman Wold]]&lt;ref&gt;{{harvtxt|Wold|1943b|pp=231 and&amp;nbsp;239–240}}: {{cite journal|last=Wold|first=Herman|authorlink=Herman Wold|year=1943b|title=A synthesis of pure demand analysis&amp;nbsp;'''II'''|journal=Skandinavisk Aktuarietidskrift [Scandinavian Actuarial Journal]|volume=26|pages=220–263&lt;!-- Diewert gives wrong pages, according to Math Rev and my inspection of the article and of Wold's book with Jureen --&gt;|mr=11939|ref=harv}}&lt;p&gt;{{harvtxt|Wold|Juréen|1953|p=146}}: {{cite book|last1=Wold|first1=Herman|authorlink1=Herman Wold|last2=Juréen|first2=Lars (in association with Wold)|chapter=8 Some further applications of preference fields (pp.&amp;nbsp;129–148)|title=Demand analysis: A study in econometrics|location=New York|publisher=John Wiley and Sons,&amp;nbsp;Inc|series=Wiley publications in statistics|year=1953|pages=xvi+358|mr=64385|ref=harv}}&lt;p&gt;&lt;/ref&gt; and again by [[Paul Samuelson]], who wrote that non-convexities are "shrouded in eternal {{nowrap|darkness&amp;nbsp;...",}}&lt;ref&gt;{{harvtxt|Samuelson|1950|pp=359–360}}:&lt;blockquote&gt;It will be noted that any point where the indifference curves are convex rather than concave cannot be observed in a competitive market. Such points are shrouded in eternal darkness—unless we make our consumer a monopsonist and let him choose between goods lying on a very convex "budget curve" (along which he is affecting the price of what he buys). In this monopsony case, we could still deduce the slope of the man's indifference curve from the slope of the observed constraint at the equilibrium point.&lt;/blockquote&gt;{{cite journal|last=Samuelson|first=Paul&amp;nbsp;A.|authorlink=Paul Samuelson|title=The problem of integrability in utility theory|journal=Economica|series=New Series|volume=17|issue=68|date=November 1950|pages=355–385|mr=43436|jstor=2549499|ref=harv|doi=10.2307/2549499}}&lt;p&gt;"Eternal darkness" describes the Hell of [[John Milton]]'s ''[[Paradise Lost]]'', whose concavity is compared to the [[Serbonian Bog]]  in [[wikisource:Paradise Lost (1674)/Book II|Book&amp;nbsp;II, lines&amp;nbsp;592–594]]:&lt;/p&gt;&lt;blockquote&gt;A gulf profound as that Serbonian Bog&lt;br /&gt;Betwixt Damiata and &lt;!-- correcting failed-capitalization in Arrow Hahn "m" (sic) --&gt;Mount Casius old,&lt;br /&gt;Where Armies whole have sunk.&lt;/blockquote&gt;Milton's description of concavity serves as the [[epigraph (literature)|literary epigraph]] prefacing chapter seven of {{harvtxt|Arrow|Hahn|1980|p=169}}, "Markets with non-convex preferences and production", which presents the results of {{harvtxt|Starr|1969}}.&lt;/ref&gt; according to&amp;nbsp;Diewert.&lt;ref name="Diewert" &gt;{{harvtxt|Diewert|1982|pp=552–553}}&lt;/ref&gt;

Nonetheless, non-convex preferences were illuminated from&amp;nbsp;1959 to&amp;nbsp;1961 by a sequence of papers in ''[[The Journal of Political Economy]]''&amp;nbsp;(''JPE''). The main contributors were  &lt;!-- M.&amp;nbsp;J.&amp;nbsp; --&gt;Farrell,&lt;ref&gt;{{cite journal
|title=The Convexity assumption in the theory of competitive markets
|last=Farrell|ref=harv
|first=M.&amp;nbsp;J.
|journal=[[The Journal of Political Economy]]
|volume=67
|issue =4
|date=August 1959
|pages=371–391
|jstor=1825163
|doi=10.1086/258197
}}
{{cite journal
|title=On Convexity, efficiency, and markets: A Reply
|last=Farrell|ref=harv
|first=M.&amp;nbsp;J. &lt;!-- |journal=The Journal of Political Economy --&gt;
|volume=69
|issue=5
|date=October 1961a
|pages=484–489
|jstor=1828538
|doi=10.1086/258541
}}
{{cite journal
|title=The Convexity assumption in the theory of competitive markets: Rejoinder
|last=Farrell
|first=M.&amp;nbsp;J. &lt;!-- |journal=The Journal of Political Economy --&gt;
|volume=69
|issue=5
|date=October 1961b
|pages=493
|jstor=1828541
}}&lt;/ref&gt;&lt;!-- F.&amp;nbsp;M.&amp;nbsp; --&gt; Bator,&lt;ref&gt;{{cite journal|title=On convexity, efficiency, and markets|last=Bator|ref=harv|first=Francis&amp;nbsp;M.|journal=The Journal of Political Economy|volume=69|issue =5|date=October 1961a|pages=480–483|jstor=1828537|doi=10.1086/258540}} {{cite journal|title=On convexity, efficiency, and markets: Rejoinder|last=Bator|first=Francis&amp;nbsp;M.|&lt;!-- journal=The Journal of Political Economy --&gt;|volume=69|issue =5|date=October 1961b|pages=489|jstor=1828539|doi=10.1086/258542}}&lt;/ref&gt; [[Tjalling Koopmans|&lt;!-- T.&amp;nbsp;C.&amp;nbsp; --&gt;Koopmans]],&lt;ref&gt;{{cite journal|title=Convexity assumptions, allocative efficiency, and competitive equilibrium
|last=Koopmans
|first=Tjalling&amp;nbsp;C.
|authorlink=Tjalling Koopmans
|journal=The Journal of Political Economy
|volume=69
|issue=5
|date=October 1961
|pages=478–479
|jstor=1828536
|ref=harv
|doi=10.1086/258539}}&lt;p&gt;{{harvtxt|Koopmans|1961|p=478}} and others—for example, {{harvtxt|Farrell|1959|pp=390–391}} and {{harvtxt|Farrell|1961a|p=484}}, {{harvtxt|Bator|1961a|pp=482–483}}, {{harvtxt|Rothenberg|1960|p=438}}, and {{harvtxt|Starr|1969|p=26}}—commented on {{harvtxt|Koopmans|1957|pp=1–126, especially&amp;nbsp;9–16 [1.3 Summation of opportunity sets],&amp;nbsp;23–35 [1.6 Convex sets and the price implications of optimality], and&amp;nbsp;35–37 [1.7 The role of convexity assumptions in the analysis]}}:&lt;p&gt;{{cite book|first=Tjalling&amp;nbsp;C.|last=Koopmans|authorlink=Tjalling Koopmans|chapter=Allocation of resources and the price system|editor-last=Koopmans|editor-first=Tjalling&amp;nbsp;C|editor-link=Tjalling Koopmans|title=Three essays on the state of economic science|publisher=McGraw–Hill Book Company|location=New&amp;nbsp;York|pages=1–126|year=1957|ref=harv|isbn=0-07-035337-9}}&lt;p&gt;
&lt;/ref&gt;  and &lt;!-- J --&gt;&lt;!-- urban economist Jerome, not structural econometrician T.J. --&gt;&lt;!-- .&amp;nbsp; --&gt;Rothenberg.&lt;ref name="Rothenberg" &gt;{{harvtxt|Rothenberg|1960|p=447}}: {{cite journal
|title=Non-convexity, aggregation, and Pareto optimality
|last=Rothenberg
|first=Jerome|ref=harv
|journal=The Journal of Political Economy
|volume=68
|issue=5
|date=October 1960
|pages=435–468
|jstor=1830308
|doi=10.1086/258363
}} ({{cite journal
|title=Comments on non-convexity
|last=Rothenberg
|first=Jerome
|authorlink=&lt;!-- |journal=The Journal of Political Economy --&gt;
|volume=69
|issue=5
|date=October 1961
|pages=490–492
|jstor=1828540
|doi=10.1086/258543
}})
&lt;/ref&gt; In particular, Rothenberg's paper discussed the approximate convexity of sums of non-convex sets.&lt;ref name="ArrowHahn182" &gt;{{harvtxt|Arrow|Hahn|1980|p=182}}&lt;/ref&gt; These &lt;!-- ''Journal of Political Economy'' --&gt; ''JPE''-papers stimulated a paper by [[Lloyd Shapley]] and [[Martin Shubik]], which considered convexified consumer-preferences and introduced the concept of an "approximate equilibrium".&lt;ref&gt;{{harvtxt|Shapley|Shubik|1966|p=806}}: {{cite journal|authorlink1=Lloyd Shapley|first1=L.&amp;nbsp;S.| last1=Shapley|authorlink2=Martin Shubik|first2=M.|last2=Shubik|title=Quasi-cores in a monetary economy with nonconvex preferences|journal=Econometrica|volume=34|issue=4|date=October 1966|pages=805–827|jstor=1910101|zbl= 0154.45303|ref=harv|doi=10.2307/1910101|url=http://www.dtic.mil/get-tr-doc/pdf?AD=AD0623552}}&lt;/ref&gt; The &lt;!-- ''Journal of Political Economy''  --&gt;''JPE''-papers and the Shapley–Shubik paper influenced another notion of "quasi-equilibria", due to [[Robert Aumann]].&lt;ref name="Aumann" &gt;{{harvtxt|Aumann|1966|pp=1–2}}: {{cite journal|authorlink=Robert Aumann|first=Robert&amp;nbsp;J.|last=Aumann|title=Existence of competitive equilibrium in markets with a continuum of traders|journal=Econometrica|volume=34|issue=1|date=January 1966|pages=1–17|jstor=1909854|mr=191623|ref=harv|doi=10.2307/1909854}} {{harvtxt|Aumann|1966}} uses results from 
{{harvs|txt|last=Aumann|year1=1964|year2=1965}}:
&lt;!-- NOT original research, this comment appears often, e.g. in "What is Bob Aumann trying to accomplish" in the CORE 20th anniversary volume, in which Guesnerie appears --&gt;&lt;p&gt;{{cite journal|authorlink=Robert Aumann|first=Robert&amp;nbsp;J.|last=Aumann|title=Markets with a continuum of traders|journal=Econometrica|volume=32|issue=1–2|date=January–April 1964|pages=39–50|jstor=1913732|mr=172689|ref=harv|doi=10.2307/1913732}}
&lt;p&gt;{{cite journal|authorlink=Robert Aumann|first=Robert&amp;nbsp;J.|last=Aumann|title=Integrals of set-valued functions|journal=Journal of Mathematical Analysis and Applications|volume=12|issue=1|date=August 1965|pages=1–12|url=http://www.sciencedirect.com/science/article/B6WK2-4CRJ2XG-1D4/2/761eda1b7acffb52fde213d766059f3c|doi=10.1016/0022-247X(65)90049-1|MR=185073|ref=harv}}&lt;/ref&gt;&lt;ref&gt;Taking the convex hull of non-convex preferences had been discussed earlier by {{harvtxt|Wold|1943b|p=243}} and by {{harvtxt|Wold|Juréen|1953|p=146}}, according to {{harvtxt|Diewert|1982|p=552}}.&lt;/ref&gt;

==== Starr's 1969 paper and contemporary economics ====
&lt;!-- [[File:Price of market balance.gif|thumb|right|alt=Diagram of an increasing supply curve and a decreasing demand curve, which intersect at the equilibrium.|At an [[economic equilibrium|equilibrium price]]&amp;nbsp;''P''0, the [[Supply and demand|quantity supplied&amp;nbsp;''S''(''P''0) equals the quantity demanded&amp;nbsp;''D''(''P''0)]].]] --&gt;
[[File:Kenneth Arrow, Stanford University.jpg|thumb|alt=Picture of Kenneth Arrow|[[Kenneth Arrow]] (1972 [[Nobel Prize in Economics|Nobel laureate]]) helped [[Ross&amp;nbsp;M. Starr]] to study [[convex set|non-convex]] [[convex preferences|economies]].&lt;ref name="StarrArrow"/&gt;]]

Previous publications on [[non-convexity (economics)|non-convexity and economics]] were collected in an annotated bibliography by [[Kenneth Arrow]]. He gave the bibliography to [[Ross Starr|Starr]], who was then a&lt;!-- [[Stanford University|Stanford]] --&gt;n undergraduate enrolled in Arrow's (graduate) advanced mathematical-economics course.&lt;ref name="StarrArrow" &gt;{{harvtxt|Starr|Stinchcombe|1999|pp=217–218}}: {{cite book|chapter=Exchange in a network of trading posts|last1=Starr|first1=R.&amp;nbsp;M.|authorlink1=Ross Starr|last2=Stinchcombe|first2=M.&amp;nbsp;B.|title=Markets, information and uncertainty: Essays in economic theory in honor of Kenneth&amp;nbsp;J. Arrow|editor-first=Graciela|editor-last=Chichilnisky|editor-link=Graciela Chichilnisky|pages=217–234|publisher=Cambridge University Press|location=Cambridge|year=1999|doi=10.2277/0521553555|isbn=978-0-521-08288-4|ref=harv}}
&lt;/ref&gt; In his term-paper, Starr studied the general equilibria of an artificial economy in which non-convex preferences were replaced by their convex hulls. In the convexified economy, at each price, the &lt;!-- not necessarily closed --&gt;[[aggregate demand]] was the sum of convex hulls of the consumers' demands. Starr's ideas interested the mathematicians [[Lloyd Shapley]] and [[Jon Folkman]], who proved their [[eponym]]ous &lt;!-- Shapley–Folkman --&gt; lemma and &lt;!-- the Shapley–Folkman --&gt; theorem in "private correspondence", &lt;!-- entitled "Starr's problem" (1966), --&gt; which was reported by Starr's published paper of 1969.&lt;ref name="s69"/&gt;

In his 1969 publication, Starr applied the Shapley–Folkman–Starr theorem. Starr proved that the "convexified" economy has general equilibria that can be closely approximated by "''quasi-equilibria''" of the original economy, when the number of agents exceeds the dimension of the goods: Concretely, Starr proved that there exists at least one quasi-equilibrium of prices&amp;nbsp;''p''&lt;sub&gt;opt&lt;/sub&gt; with the following properties:

* For each quasi-equilibrium's prices&amp;nbsp;''p''&lt;sub&gt;opt&lt;/sub&gt;, all consumers can choose optimal baskets (maximally preferred and meeting their budget constraints).
* At quasi-equilibrium prices&amp;nbsp;''p''&lt;sub&gt;opt&lt;/sub&gt; in the convexified economy, every good's market is in equilibrium: Its supply equals its demand.
* For each quasi-equilibrium, the prices "nearly clear" the markets for the original economy: an [[upper bound]] on the [[Hausdorff distance|distance]] between the set of equilibria of the  "convexified" economy and the set of quasi-equilibria of the original economy followed from Starr's corollary to the Shapley–Folkman theorem.&lt;ref&gt;{{harvtxt|Arrow|Hahn|1980|pp=169–182}}. {{harvtxt|Starr|1969|pp=27–33}}
&lt;/ref&gt;

Starr established that
&lt;blockquote&gt;
"in the aggregate, the discrepancy between an allocation in the fictitious economy generated by [taking the convex hulls of all of the consumption&amp;nbsp;and&amp;nbsp;production sets] and some allocation in the real economy is bounded in a way that is independent of the number of economic agents. Therefore, the average&amp;nbsp;agent experiences a deviation from intended actions that vanishes in significance as the number&amp;nbsp;of&amp;nbsp;agents goes to infinity".&lt;ref&gt;{{harvtxt|Green|Heller|1981|p=44}}&lt;/ref&gt;
&lt;/blockquote&gt;
Following Starr's&amp;nbsp;1969 paper, the Shapley–Folkman–Starr results have been widely used in economic theory. [[Roger&amp;nbsp;Guesnerie]] summarized their economic implications: "&lt;!-- [s] --&gt;Some key results obtained under the convexity assumption remain (approximately) relevant in circumstances where convexity fails. For example, in economies with a large consumption&amp;nbsp;side, preference&amp;nbsp;nonconvexities do not destroy the standard results".&lt;ref&gt;{{harvtxt|Guesnerie|1989|pp=99}}&lt;/ref&gt; "The derivation of these results in general form has been one of the major achievements of postwar economic theory", wrote Guesnerie.&lt;ref name="g89-p138"/&gt; The topic of [[non-convexity (economics)|non-convex sets in economics]] has been studied by many [[Nobel Prize in Economics|Nobel laureates]]: Arrow (1972), [[Robert Aumann]] (2005), [[Gérard Debreu]] (1983), [[Tjalling Koopmans]] (1975), [[Paul Krugman]] (2008), and [[Paul Samuelson]] (1970); the complementary topic of [[convexity in economics|convex sets in economics]] has been emphasized by these laureates, along with [[Leonid Hurwicz]], [[Leonid Kantorovich]] (1975), and [[Robert Solow]] (1987).&lt;ref name="MasColell87"&gt;{{harvtxt|Mas-Colell|1987}}&lt;/ref&gt; The Shapley–Folkman–Starr results have been featured in the economics literature: in [[microeconomics]],&lt;ref&gt;{{harvtxt|Varian|1992|pp=393–394}}: {{cite book|authorlink=Hal Varian|last=Varian|ref=harv|first=Hal&amp;nbsp;R.|chapter=21.2&amp;nbsp;Convexity and size|title=Microeconomic Analysis|publisher=W.&amp;nbsp;W.&amp;nbsp;Norton&amp;nbsp;&amp; Company|edition=3rd|year=1992|isbn=978-0-393-95735-8|mr=1036734}}&lt;p&gt;{{harvtxt|Mas-Colell|Whinston|Green|1995|pp=627–630}}: {{cite book|last1=Mas-Colell|first1=Andreu|authorlink=Andreu Mas-Colell|last2=Whinston|first2=Michael&amp;nbsp;D.|first3=Jerry&amp;nbsp;R.|last3=Green|ref=harv|chapter=17.1 Large&amp;nbsp;economies and nonconvexities|title=Microeconomic theory|publisher=Oxford&amp;nbsp;University Press|year=1995|isbn=978-0-19-507340-9}}&lt;/ref&gt; in general-equilibrium theory,&lt;ref&gt;{{harvtxt|Arrow|Hahn|1980|pp=169–182}}&lt;p&gt;{{harvtxt|Mas-Colell|1985|pp=52–55, 145–146, 152–153, and&amp;nbsp;274–275}}: {{cite book|last=Mas-Colell|first=Andreu|authorlink=Andreu Mas-Colell|year=1985|chapter=1.L Averages of sets|title=The Theory of general economic equilibrium: A ''differentiable'' approach|series=Econometric Society monographs|volume=9|publisher=Cambridge University Press|isbn=0-521-26514-2|mr=1113262|ref=harv}}&lt;/p&gt;&lt;p&gt;{{harvtxt|Hildenbrand|1974|pp=37, 115–116, 122, and&amp;nbsp;168}}: {{cite book|last=Hildenbrand|first=Werner|authorlink=Werner Hildenbrand|ref=harv|title=Core and equilibria of a large economy|series=Princeton studies in mathematical economics|volume=5|publisher=Princeton&amp;nbsp;University Press|location=Princeton,&amp;nbsp;N.J.|year=1974|pages=viii+251|isbn=978-0-691-04189-6|mr=389160}}&lt;/p&gt;&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Starr|1997|p=169}}: {{cite book|last=Starr|first=Ross&amp;nbsp;M.|chapter=8 Convex sets, separation theorems, and non-convex sets in&amp;nbsp;'''R'''&lt;sup&gt;''N''&lt;/sup&gt; (new chapters&amp;nbsp;22 and&amp;nbsp;25–26 in (2011) second ed.)|title=General equilibrium theory: An introduction|edition=First|publisher=Cambridge University Press|location=Cambridge|year=1997|pages=xxiii+250|isbn=0-521-56473-5|mr=1462618|ref=harv}}&lt;p&gt;{{harvtxt|Ellickson|1994|pp=xviii, 306–310, 312, 328–329, 347, and&amp;nbsp;352}}: {{cite book|title=Competitive equilibrium: Theory and applications|first=Bryan|last=Ellickson |publisher=Cambridge University Press|isbn=978-0-521-31988-1|doi=10.2277/0521319889|year=1994|pages=|ref=harv}}&lt;/p&gt;&lt;/ref&gt; in [[public economics]]&lt;ref&gt;{{harvtxt|Laffont|1988|pp=63–65}}: {{cite book|last=Laffont|first=Jean-Jacques|authorlink=Jean-Jacques Laffont|year=1988|chapter=3 Nonconvexities &lt;!-- Not "Non–convexities"  --&gt;|title=Fundamentals of public economics|url=https://books.google.com/books?q=editions:ISBN 0-262-12127-1&amp;id=O5MnAQAAIAAJ|publisher=[http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=7534 MIT]
|isbn=0-262-12127-1|ref=harv}}&lt;/ref&gt; (including [[market failure]]s),&lt;ref&gt;{{harvtxt|Salanié|2000|pp=112–113 and&amp;nbsp;107–115}}: {{cite book|last=Salanié|first=Bernard|chapter=7 Nonconvexities &lt;!-- Not "Non–convexities"  --&gt;|title=Microeconomics of market failures|edition=English translation of the (1998) French ''Microéconomie: Les défaillances du&amp;nbsp;marché'' (Economica, Paris)|year=2000|publisher=MIT&amp;nbsp;Press|location=Cambridge,&amp;nbsp;MA|pages=107–125|isbn=0-262-19443-0|ref=harv}}&lt;/ref&gt; as well as in [[game theory]],&lt;ref&gt;{{harvtxt|Ichiishi|1983|pp=24–25}}: {{cite book|last=Ichiishi|first=Tatsuro|title=Game theory for economic analysis|series=Economic theory, econometrics, and mathematical economics|publisher=Academic Press,&amp;nbsp;Inc. [Harcourt Brace Jovanovich, Publishers]|location=New&amp;nbsp;York|year=1983|pages=x+164|isbn=0-12-370180-5|mr=700688|ref=harv}}&lt;/ref&gt; in [[mathematical economics]],&lt;ref&gt;{{harvtxt|Cassels|1981|pp=127 and 33–34}}: {{cite book|last=Cassels|first=J.&amp;nbsp;W.&amp;nbsp;S.|authorlink=J. W. S. Cassels|chapter=Appendix&amp;nbsp;A Convex&amp;nbsp;sets|title=Economics for mathematicians|series=London Mathematical Society lecture note series|volume=62|publisher=Cambridge University Press|location=Cambridge, New&amp;nbsp;York|year=1981|pages=xi+145|isbn=0-521-28614-X|mr=657578|ref=harv}}&lt;/ref&gt; and in [[applied mathematics#Mathematics for economists|applied mathematics]] (for economists).&lt;ref name="Aubin"/&gt;&lt;ref name="Carter" &gt;{{harvtxt|Carter|2001|pp=93–94,&amp;nbsp;143,&amp;nbsp;318–319,&amp;nbsp;375–377, and&amp;nbsp;416}}&lt;/ref&gt;&lt;!-- &lt;ref name="Moore"&gt;{{harvtxt|Moore|1999|p=309}}: {{cite book|last=Moore|first=James&amp;nbsp;C.|title=Mathematical methods for economic theory: Volume&amp;nbsp;'''I'''
|series=Studies in economic theory|volume=9|publisher=Springer-Verlag|location=Berlin|year=1999|pages=xii+414|isbn=3-540-66235-9 |MR=1727000|ref=harv}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Florenzano|Le&amp;nbsp;Van|2001|pp=47–48}}: {{cite book|MR=1878374|last1=Florenzano|first1=Monique|last2=Le&amp;nbsp;Van|first2=Cuong|title=Finite&amp;nbsp;dimensional convexity and optimization|author3=in cooperation with Pascal Gourdel|series=Studies in economic theory|volume=13|publisher=Springer-Verlag|location=Berlin|year=2001|pages=xii+154|isbn=3-540-41516-5|ref=harv}} &lt;/ref&gt; --&gt; The Shapley–Folkman–Starr results have also influenced economics research using [[measure (mathematics)|measure]] and [[integral|integration theory]].&lt;ref&gt;{{harvtxt|Trockel|1984|p=30}}: {{cite book|last=Trockel|first=Walter|ref=harv|title=Market demand: An analysis of large economies with nonconvex preferences|series=Lecture Notes in Economics and Mathematical Systems|volume=223|publisher=Springer-Verlag|location=Berlin|year=1984|pages=viii+205|isbn=3-540-12881-6|mr=737006}}&lt;/ref&gt;

===Mathematical optimization===
[[File:Epigraph convex.svg|right|thumb|300px|alt=A graph of a convex function, which is drawn in black. Its epigraph, the area above its graph, is solid green.|A [[function (mathematics)|function]] is [[convex function|convex]] if the region above its [[graph of a function|graph]] is a [[convex set]].]]
The Shapley–Folkman lemma has been used to explain why large [[nonlinear programming|minimization]] problems with [[convex function|non-convexities]] can be nearly solved (with [[iterative methods]] whose convergence proofs are stated for only [[convex optimization|convex problems]]). The  Shapley–Folkman lemma has encouraged the use of methods of convex minimization on other applications with sums of many functions.&lt;ref name="Bertsekas99"/&gt;

====Preliminaries of optimization theory====
[[Nonlinear programming|Nonlinear optimization]] relies on the following definitions for  [[function (mathematics)|function]]s:

*The [[graph of a function|''graph'']] of a function&amp;nbsp;''f'' is the set of the pairs of [[domain of a function|argument]]s&amp;nbsp;''x'' and function evaluations&amp;nbsp;''f''(''x'')
: Graph(''f'') = &lt;big&gt;&lt;big&gt;{&lt;/big&gt;&lt;/big&gt; &lt;big&gt;(&lt;/big&gt;''x'',&amp;nbsp;''f''(''x'') &lt;big&gt;)&lt;/big&gt; &lt;big&gt;&lt;big&gt;}&lt;/big&gt;&lt;/big&gt;

* The ''[[epigraph (mathematics)|epigraph]]'' of a [[real-valued function]]&amp;nbsp;''f'' is the set of points ''above'' the graph
[[File:Sine.svg|right|thumb|alt=A graph of the sine function, which periodically oscillates up and down between −1 and +1, with the period 2π.|The [[sine|sine&amp;nbsp;function]] is [[convex function|non-convex]]&lt;!--  on the [[interval_(mathematics)#Terminology|interval]]&amp;nbsp;(0,&amp;nbsp;π) --&gt;.]]
: Epi(''f'') = &lt;big&gt;{&lt;/big&gt;&amp;nbsp;(''x'',&amp;nbsp;''u'')&amp;nbsp;:&amp;nbsp;''f''(''x'')&amp;nbsp;≤&amp;nbsp;''u''&amp;nbsp;&lt;big&gt;}&lt;/big&gt;.

*A real-valued function is defined to be a ''[[convex function]]'' if its epigraph is a convex set.&lt;ref name="Rock23" &gt;{{harvtxt|Rockafellar|1997|p=23}}&lt;/ref&gt;

For example, the [[quadratic&amp;nbsp;function]]&amp;nbsp;''f''(''x'')&amp;nbsp;=&amp;nbsp;''x''&lt;sup&gt;2&lt;/sup&gt; is convex, as is the [[absolute&amp;nbsp;value]] function&amp;nbsp;''g''(''x'')&amp;nbsp;=&amp;nbsp;|''x''|. However, the [[sine|sine&amp;nbsp;function]] (pictured) is non-convex on the [[interval (mathematics)#Terminology|interval]]&amp;nbsp;(0,&amp;nbsp;π).

====Additive optimization problems====
In many optimization problems, the [[optimization (mathematics)#objective function|objective function]]&amp;nbsp;f is ''separable'': that is, ''f'' is the sum of ''many'' summand-functions, each of which has its own argument:

: ''f''(''x'') = ''f''&lt;big&gt;(&lt;/big&gt;&amp;nbsp;(''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''N''&lt;/sub&gt;)&lt;big&gt;&amp;nbsp;)&lt;/big&gt; = &lt;big&gt;∑&lt;/big&gt;&amp;nbsp;''f''&lt;sub&gt;''n''&lt;/sub&gt;(''x''&lt;sub&gt;''n''&lt;/sub&gt;).

For example, problems of [[linear programming|linear optimization]] are separable. Given a separable problem with an optimal solution, we fix an optimal solution

: ''x''&lt;sub&gt;min&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;(''x''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''x''&lt;sub&gt;''N''&lt;/sub&gt;)&lt;sub&gt;min&lt;/sub&gt;

with the minimum value&amp;nbsp;{{nowrap|''f''(''x''&lt;sub&gt;min&lt;/sub&gt;).}}  For this separable problem, we also consider an optimal solution  &lt;big&gt;(&lt;/big&gt;''x''&lt;sub&gt;min&lt;/sub&gt;,&amp;nbsp;''f''(''x''&lt;sub&gt;min&lt;/sub&gt;) &lt;big&gt;)&lt;/big&gt;
to the "''convexified problem''", where convex hulls are taken of the graphs of  the summand functions. Such an optimal solution is the [[limit of a sequence]] of points in the convexified problem
: &lt;big&gt;(&lt;/big&gt;''x''&lt;sub&gt;''j''&lt;/sub&gt;,&amp;nbsp;''f''(''x''&lt;sub&gt;j&lt;/sub&gt;) &lt;big&gt;)&lt;/big&gt;&lt;big&gt;&amp;nbsp;∈&amp;nbsp;&lt;/big&gt; &lt;big&gt;∑&lt;/big&gt; Conv &lt;big&gt;(&lt;/big&gt;Graph( ''f''&lt;sub&gt;''n''&lt;/sub&gt; ) &lt;big&gt;)&lt;/big&gt;.&lt;ref name="Ekeland76"/&gt;&lt;ref&gt;
The [[limit of a sequence]] is a member of the [[closure (topology)|closure of the original set]], which is the smallest [[closed set]] that contains the original set. The Minkowski sum of two [[closed set]]s need not be closed, so the following [[subset#inclusion|inclusion]] can be strict
: Clos(P)&amp;nbsp;+&amp;nbsp;Clos(Q) ⊆ Clos(&amp;nbsp;Clos(P)&amp;nbsp;+&amp;nbsp;Clos(Q)&amp;nbsp;);
the inclusion can be strict even for two ''convex'' closed summand-sets, according to {{harvtxt|Rockafellar|1997|pp=49 and&amp;nbsp;75}}. Ensuring that the Minkowski&amp;nbsp;sum of sets be closed requires the closure operation, which appends limits of convergent sequences.&lt;/ref&gt;
Of course, the given optimal-point  is a sum of points in the graphs of the original summands and of a small number of convexified summands, by the Shapley–Folkman lemma.

This analysis was published by [[Ivar Ekeland]] in&amp;nbsp;1974 to explain the apparent convexity of separable problems with many summands, despite the non-convexity of the summand problems. In 1973, the young mathematician [[Claude Lemaréchal]] was surprised by his success with [[convex optimization|convex minimization]] [[iterative method|method]]s on problems that were known to be non-convex; for [[nonlinear programming|minimizing nonlinear]] problems, a solution of the [[dual problem]] problem need not provide useful information for solving the primal problem, unless the primal problem be convex and satisfy a [[constraint qualification]]. Lemaréchal's problem was additively separable, and each summand function was non-convex; nonetheless, a solution to the dual problem provided a close approximation to the primal problem's optimal value.&lt;ref&gt;{{harvtxt|Lemaréchal|1973|p=38}}: {{citation|last=Lemaréchal|first=Claude|authorlink=Claude Lemaréchal|title=Utilisation de la dualité dans les problémes non&amp;nbsp;convexes [Use of duality for non–convex problems]|language=French| date=April 1973 |issue=16|location=Domaine de&amp;nbsp;Voluceau, [[Rocquencourt]],&amp;nbsp;78150 [[Le Chesnay|Le&amp;nbsp;Chesnay]], France|publisher=[[National Institute for Research in Computer Science and Control|IRIA (now&amp;nbsp;INRIA)]], Laboratoire de recherche en informatique et automatique|page=41|ref=harv}}. &lt;!-- Ekeland cites this report in the ''[[Comptes Rendus|CRAS]]'' announcement of the results of his Appendix&amp;nbsp;I --&gt;
Lemaréchal's experiments were discussed in later publications: &lt;p&gt;{{harvtxt|Aardal|1995|pp=2–3}}: {{cite journal|first=Karen|last=Aardal|title=''Optima'' interview &lt;!--sic., neither colon nor m-dash appear --&gt;Claude  Lemaréchal|journal=Optima: Mathematical Programming Society newsletter|pages=2–4|date=March 1995|volume=45|url=http://www.mathprog.org/Old-Optima-Issues/optima45.pdf|accessdate=2 February 2011|ref=harv}}&lt;/p&gt;&lt;p&gt;{{harvtxt|Hiriart-Urruty|Lemaréchal|1993|pp=143–145, 151, 153, and&amp;nbsp;156}}: {{cite book|last1=Hiriart-Urruty|first1=Jean-Baptiste|last2=Lemaréchal|first2=Claude|authorlink2=Claude Lemaréchal|ref=harv|chapter=XII Abstract duality for practitioners|title=Convex analysis and minimization algorithms, Volume&amp;nbsp;'''II''': Advanced theory and bundle methods|series=Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences]|volume=306|publisher=Springer-Verlag|location=Berlin|year=1993|pages=136–193 (and bibliographical comments on pp.&amp;nbsp;334–335)|isbn=3-540-56852-2|mr=1295240}}&lt;/p&gt;
&lt;/ref&gt;&lt;ref name="Ekeland76" &gt;{{harv|Ekeland|1999|pp=357–359}}: Published in the first English edition of 1976, Ekeland's appendix proves the Shapley–Folkman lemma, also acknowledging [[Claude Lemaréchal|Lemaréchal]]'s experiments on page&amp;nbsp;373.&lt;/ref&gt;&lt;ref name="Ekeland74" &gt;{{cite journal|last=Ekeland|first=Ivar|&lt;!-- authorlink=Ivar Ekeland --&gt;|title=Une estimation ''a&amp;nbsp;priori'' en programmation non&amp;nbsp;convexe|journal=Comptes&amp;nbsp;Rendus Hebdomadaires des Séances de l'Académie des Sciences|series=Séries&amp;nbsp;A et&amp;nbsp;B|language=French|issn=0151-0509&lt;!-- Not archived on CRAS site, and CRAS's title has changed multiple times --&gt;|volume=279|year=1974|pages=149–151|MR=395844|ref=harv}}&lt;!-- Ekeland sole author; cites Lemaréchal by title whereas the 1976 appendix acknowledges but does not cite Lemaréchal (1973)--&gt;&lt;/ref&gt; Ekeland's analysis explained the success of methods of convex&amp;nbsp;minimization on ''large'' and ''separable'' problems, despite the non-convexities of the summand functions. Ekeland and later authors argued that additive separability produced an approximately convex aggregate problem, even though the summand functions were non-convex. The crucial step in these publications is the use of the  Shapley–Folkman lemma.&lt;ref name="Ekeland76" /&gt;&lt;ref name="Ekeland74" /&gt;&lt;ref name="AubinEkeland" &gt;{{harvtxt|Aubin|Ekeland|1976|pp=226,&amp;nbsp;233,&amp;nbsp;235,&amp;nbsp;238, and&amp;nbsp;241}}: {{cite journal|last1=Aubin|first1=J.&amp;nbsp;P.|last2=Ekeland|first2=I.|issue=3|journal=Mathematics of Operations Research|pages=225–245|title=Estimates of the duality gap in nonconvex optimization|volume=1| year = 1976
|doi=10.1287/moor.1.3.225|mr=449695|jstor=3689565|ref=harv}}&lt;p&gt;{{harvtxt|Aubin|Ekeland|1976}} and {{harvtxt|Ekeland|1999|pp=362–364}} also considered the ''[[Convex conjugate#Biconjugate convex|convex]]''&amp;nbsp;[[Convex conjugate#Biconjugate|closure]] of a problem of non-convex minimization—that is, the problem defined as the [[Kuratowski closure axioms|closed]]&amp;nbsp;[[convex hull|convex]] [[closure operator|hull]] of the [[epigraph (mathematics)|epigraph]] of the original problem. Their study of duality&amp;nbsp;gaps was extended by Di&amp;nbsp;Guglielmo to the ''[[quasiconvex function|quasiconvex]]'' closure of a non-convex [[multiobjective optimization|minimization]] problem—that is, the problem defined as the [[Kuratowski closure axioms|closed]]&amp;nbsp;[[convex hull|convex]] [[closure operator|hull]] of the [[semicontinuity#lower|lower]] [[level set|level&amp;nbsp;set]]s:&lt;p&gt;&lt;p&gt;{{harvtxt|Di&amp;nbsp;Guglielmo|1977|pp=287–288}}: {{cite journal|last=Di&amp;nbsp;Guglielmo|first=F.|title=Nonconvex duality in multiobjective optimization|doi=10.1287/moor.2.3.285|volume=2|year=1977|ref=harv|issue=3|pages=285–291|journal=Mathematics of Operations Research|mr=484418|jstor=3689518}}&lt;p&gt;
&lt;!-- &lt;p&gt;{{cite book||last=Di&amp;nbsp;Guglielmo|first=F.|chapter=Estimates of the duality&amp;nbsp;gap for discrete&amp;nbsp;and&amp;nbsp;quasiconvex optimization&amp;nbsp;problems|title=Generalized concavity in optimization and economics: Proceedings of the NATO Advanced&amp;nbsp;Study Institute held at the University of British&amp;nbsp;Columbia, Vancouver,&amp;nbsp;B.C., August&amp;nbsp;4–15,&amp;nbsp;1980
|editor1-first=Siegfried|editor1-last=Schaible|editor2-first=William&amp;nbsp;T.|editor2-last=Ziemba|publisher=Academic Press,&amp;nbsp;Inc. [Harcourt Brace Jovanovich, Publishers]|location=New&amp;nbsp;York|year=1981|pages=281–298|isbn=0-12-621120-5|MR=652702|}}&lt;/p&gt; --&gt;
&lt;/ref&gt; The  Shapley–Folkman lemma has encouraged the use of methods of convex minimization on other applications with sums of many functions.&lt;ref name="Ekeland76" /&gt;&lt;ref name="Bertsekas82" &gt;{{harvtxt|Bertsekas|1996|pp=364–381}} acknowledging {{harvtxt|Ekeland|1999}} on page&amp;nbsp;374 and {{harvtxt|Aubin|Ekeland|1976}} on page&amp;nbsp;381:&lt;p&gt;
 {{cite book|last=Bertsekas|first=Dimitri&amp;nbsp;P.|authorlink=Dimitri P. Bertsekas|chapter=5.6 Large&amp;nbsp;scale separable integer programming problems and the exponential method of multipliers|title=Constrained optimization and Lagrange&amp;nbsp;multiplier methods|edition=Reprint of (1982) Academic Press|year=1996|location=Belmont,&amp;nbsp;MA|isbn=1-886529-04-3|pages=xiii+395|publisher=Athena Scientific|mr=690767|ref=harv}}&lt;/p&gt;
&lt;p&gt;{{harvtxt|Bertsekas|1996|pp=364–381}} describes an application of [[dual problem|Lagrangian dual]] methods to the [[scheduling (production processes)|scheduling]] of [[electricity generation|electrical power plant]]s ("[[power system simulation#Unit commitment|unit&amp;nbsp;commitment problem]]s"), where non-convexity appears because of [[integer programming|integer constraints]]:&lt;/p&gt;&lt;p&gt;{{cite journal|journal=IEEE Transactions on Automatic Control|volume=AC-28|date=January 1983|title=Optimal short-term scheduling of large-scale power systems|first1=Dimitri&amp;nbsp;P.|last1=Bertsekas|authorlink1=Dimitri Bertsekas|first2=Gregory&amp;nbsp;S.|last2=Lauer|first3=Nils&amp;nbsp;R.,&amp;nbsp;Jr.|last3=Sandell|first4=Thomas&amp;nbsp;A.|last4=Posbergh|pages=1–11|doi=10.1109/tac.1983.1103136|
issue=Proceedings of&amp;nbsp;1981 IEEE Conference on Decision and Control, San Diego,&amp;nbsp;CA, December&amp;nbsp;1981, pp.&amp;nbsp;432–443|ref=harv|url=http://web.mit.edu/dimitrib/www/Unit_Comm.pdf|accessdate=2 February 2011}}&lt;p&gt;&lt;/ref&gt;&lt;ref name="Aubin" &gt;{{harvtxt|Aubin|2007|pp=458–476}}: {{cite book|last=Aubin|first=Jean-Pierre|chapter=14.2 Duality in the case of non-convex integral criterion and constraints (especially&amp;nbsp;14.2.3 The Shapley–Folkman theorem, pages&amp;nbsp;463–465)|title=Mathematical methods of game and economic theory|edition=Reprint with new preface of&amp;nbsp;1982 North-Holland revised English|publisher=Dover Publications,&amp;nbsp;Inc|location=Mineola,&amp;nbsp;NY|year=2007|pages=xxxii+616|isbn=978-0-486-46265-3|mr=2449499|ref=harv}}&lt;/ref&gt;&lt;ref name="Bertsekas99" &gt;{{harvtxt|Bertsekas|1999|p=496}}: {{cite book|last=Bertsekas|first=Dimitri&amp;nbsp;P.|authorlink=Dimitri P. Bertsekas
|title=Nonlinear Programming|edition=Second|chapter=5.1.6 Separable problems and their geometry|pages=494–498|publisher=Athena Scientific|year=1999|ref=harv|location=Cambridge,&amp;nbsp;MA.|isbn =1-886529-00-0}}&lt;/ref&gt;

===Probability and measure theory===
Convex sets are often studied with [[probability theory]]. Each point in the convex hull of a ([[empty set|non-empty]]) subset&amp;nbsp;''Q'' of a finite-dimensional space is the [[expected value]] of a [[simple function|simple]] [[multivariate random variable|random&amp;nbsp;vector]] that takes its values in&amp;nbsp;''Q'', as a consequence of [[Carathéodory's theorem (convex hull)|Carathéodory's lemma]].&lt;!-- &lt;ref&gt;
This property (representation of points in convex sets via simple random variables) holds for closed and [[bounded set (topological vector space)|bounded set]]s in [[Banach space]]s with the [[Bochner_integral#Radon.E2.80.93Nikodym_property|Radon–Nikodym property]] (by [[Gerald Edgar|Edgar]]'s theorem) and for closed and [[totally bounded space|totally bounded set]]s of a [[locally convex topological vector space]] (by the [[Krein–Milman theorem]]).&lt;/ref&gt; --&gt; Thus, for a non-empty set&amp;nbsp;''Q'', the collection of the expected&amp;nbsp;values of the simple, ''Q''-valued random&amp;nbsp;vectors  equals&amp;nbsp;''Q''{{'s}} convex hull; this equality implies that the Shapley–Folkman–Starr results are useful in probability&amp;nbsp;theory.&lt;ref&gt;{{harvtxt|Schneider|Weil|2008|p=45}}: {{cite book|last1=Schneider|first1=Rolf|last2=Weil|first2=Wolfgang |ref=harv|title=Stochastic and integral geometry |url=http://www.springerlink.com/content/978-3-540-78858-4|series=Probability and its applications|doi=10.1007/978-3-540-78859-1|year=2008|publisher=Springer |isbn=978-3-540-78858-4|mr=2455326}}&lt;/ref&gt; In the other direction, probability&amp;nbsp;theory provides tools to examine convex&amp;nbsp;sets generally and the Shapley–Folkman–Starr results specifically.&lt;ref&gt;{{harvtxt|Cassels|1975|pp=433–434}}: {{cite journal|last=Cassels| first=J.&amp;nbsp;W.&amp;nbsp;S.|authorlink=J. W. S. Cassels|title=Measures of the non-convexity of sets and the Shapley–Folkman–Starr theorem|journal=Mathematical Proceedings of the Cambridge Philosophical Society|volume=78|year=1975|issue=3|pages=433–436|doi=10.1017/S0305004100051884
|url=http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=2075868&amp;fulltextType=RA&amp;fileId=S0305004100051884ER|mr=385711|ref=harv}}&lt;/ref&gt; The Shapley–Folkman–Starr results have been widely used in the [[stochastic geometry|probabilistic&amp;nbsp;theory of random&amp;nbsp;sets]],&lt;ref&gt;{{harvtxt|Molchanov|2005|pp=195–198,&amp;nbsp;218,&amp;nbsp;232,&amp;nbsp;237–238 and&amp;nbsp;407}}: {{cite book|last=Molchanov|first=Ilya|chapter=3 Minkowski addition|title=Theory of random sets|series=Probability and its applications|publisher=Springer-Verlag London Ltd|location=London |year=2005|pages=194–240|isbn=978-1-84996-949-9|doi=10.1007/1-84628-150-4 |url=http://www.springerlink.com/content/978-1-85233-892-3|mr=2132405|ref=harv}}&lt;/ref&gt; for example, to prove a [[law of large numbers|law of large&amp;nbsp;numbers]],&lt;ref name="ArtsteinVitale" &gt;{{harvtxt|Artstein|Vitale|1975|pp=881–882}}: {{citation|last1=Artstein|first1=Zvi|last2=Vitale|first2=Richard&amp;nbsp;A.|year=1975|title=A strong law of large numbers for random compact sets|journal=The Annals of Probability|volume=3|issue=5|pages=879–882 |url=http://projecteuclid.org/euclid.aop/1176996275|doi=10.1214/aop/1176996275|mr=385966|jstor=2959130|zbl=0313.60012|id={{Euclid|euclid.ss/1176996275}}|ref=harv}}&lt;/ref&gt;&lt;ref name="PurRal85" &gt;{{harvtxt|Puri|Ralescu|1985|pp=154–155}}: {{cite journal|last1=Puri|first1=Madan&amp;nbsp;L.|last2=Ralescu|first2=Dan&amp;nbsp;A.|title=Limit theorems for random compact sets in Banach space|url=http://journals.cambridge.org/action/displayAbstract?aid=2087952|journal=Mathematical Proceedings of the Cambridge Philosophical Society|volume=97|year=1985|issue=1|pages=151–158|doi=10.1017/S0305004100062691|mr=764504|ref=harv}}
&lt;/ref&gt; a [[central limit theorem]],&lt;ref name="PurRal85" /&gt;&lt;ref&gt;{{harvtxt|Weil|1982|pp=203, and&amp;nbsp;205–206}}: {{cite journal|last=Weil|first=Wolfgang|title=An application of the central limit theorem for Banach-space–valued random variables to the theory of random sets|journal=Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete [Probability Theory and Related Fields]|volume=60|year=1982 |issue=2|pages=203–208|doi=10.1007/BF00531823|mr=663901|ref=harv}}&lt;/ref&gt; and a [[large deviations theory|large-deviations]]&amp;nbsp;[[rate function|principle]].&lt;ref&gt;{{harvtxt|Cerf|1999|pp=243–244}}: {{cite journal|last=Cerf|first=Raphaël|title=Large deviations for sums of i.i.d. random compact sets |url=http://www.ams.org/journals/proc/1999-127-08/S0002-9939-99-04788-7|journal=Proceedings of the American Mathematical Society|volume=127|year=1999|issue=8|pages=2431–2436|doi=10.1090/S0002-9939-99-04788-7|mr=1487361|ref=harv}} Cerf uses applications of the Shapley–Folkman lemma from {{harvtxt|Puri|Ralescu|1985|pp=154–155}}.&lt;/ref&gt; These proofs of [[convergence of random variables|probabilistic limit&amp;nbsp;theorems]] used the Shapley–Folkman–Starr results to avoid the assumption that all the random&amp;nbsp;sets be convex.

A [[probability measure]] is a finite [[measure (mathematics)|measure]], and the Shapley–Folkman lemma has applications in non-probabilistic measure&amp;nbsp;theory, such as the theories of [[volume]] and of [[vector measure]]s. The Shapley–Folkman lemma enables a refinement of the [[Brunn–Minkowski theorem|Brunn–Minkowski inequality]], which bounds the volume of sums in terms of the volumes of their summand-sets.&lt;ref&gt;{{harvtxt|Ruzsa|1997|p=345}}: {{cite journal|last=Ruzsa|first=Imre&amp;nbsp;Z.|authorlink=Imre Z. Ruzsa|title=The Brunn–Minkowski inequality and nonconvex sets|journal=Geometriae Dedicata|volume=67|doi=10.1023/A:1004958110076 |year=1997|issue=3|pages=337–348|mr=1475877|ref=harv}}&lt;/ref&gt; The volume of a set is defined in terms of the [[Lebesgue&amp;nbsp;&lt;!-- outer --&gt;measure]], which is defined on &lt;!-- measurable ; the, for outer measure --&gt;subsets of [[Euclidean space]].  In advanced measure-theory, the Shapley–Folkman lemma has been used to prove [[Vector measure#Lyapunov's theorem|Lyapunov's theorem]], which states that the [[image (mathematics)|range]]  of a &lt;!-- ([[atom (measure theory)|non-atomic]]) --&gt;[[vector&amp;nbsp;measure]] is convex.&lt;ref name="Tardella" &gt;{{harvtxt|Tardella|1990|pp=478–479}}: {{cite journal|last=Tardella|first=Fabio|title=A new proof of the Lyapunov convexity theorem|journal=SIAM Journal on Control and Optimization|volume=28|year=1990|issue=2|pages=478–481 |doi=10.1137/0328026|mr=1040471|ref=harv}}&lt;/ref&gt; Here, the traditional term "''range''" (alternatively, "image") is the set of values produced by the function. 
A ''vector measure'' is a vector-valued generalization of a measure; 
for example, 
if&amp;nbsp;''p''&lt;sub&gt;1&lt;/sub&gt; and&amp;nbsp;''p''&lt;sub&gt;2&lt;/sub&gt; are [[probability measure]]s defined on the same [[measure (mathematics)#Measurable space|measurable&amp;nbsp;space]], 
then the [[product function]]&amp;nbsp;{{nowrap|''p''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;''p''&lt;sub&gt;2&lt;/sub&gt;}} is a vector&amp;nbsp;measure, 
where&amp;nbsp;{{nowrap|''p''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;''p''&lt;sub&gt;2&lt;/sub&gt;}} 
is defined for every [[event (probability theory)|event]]&amp;nbsp;''ω'' 
by&lt;!-- the assignment --&gt;
:&lt;big&gt;(&lt;/big&gt;''p''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;''p''&lt;sub&gt;2&lt;/sub&gt;&lt;big&gt;)&lt;/big&gt;(''ω'')=&lt;big&gt;(&lt;/big&gt;''p''&lt;sub&gt;1&lt;/sub&gt;(''ω''),&amp;nbsp;''p''&lt;sub&gt;2&lt;/sub&gt;(''ω'')&lt;big&gt;)&lt;/big&gt;.  
Lyapunov's theorem has been used in [[mathematical economics|economics]],&lt;ref name="Aumann"/&gt;&lt;ref&gt;{{harvtxt|Vind|1964|pp=168 and&amp;nbsp;175}}: {{cite journal|last=Vind|first=Karl|date=May 1964|title=Edgeworth-allocations in an exchange economy with many traders|journal=International Economic Review|volume=5|pages=165–77|issue=2|ref=harv|jstor=2525560|doi=10.2307/2525560}} Vind's article was noted by the winner of the 1983 [[Nobel Prize in Economics]], [[Gérard Debreu]]. {{harvtxt|Debreu|1991|p=4}} wrote:
&lt;blockquote&gt;
The concept of a convex set (i.e., a set containing the segment connecting any two of its points) had repeatedly been placed at the center of economic theory before&amp;nbsp;1964. It appeared in a new light with the introduction of integration&amp;nbsp;theory in the study of economic competition: If&lt;!-- original "if" inconsistent with our capitalization  --&gt; one associates with every agent of an economy an arbitrary set in the commodity&amp;nbsp;space and ''if one averages those individual sets'' over a collection of insignificant agents, ''then the resulting set is necessarily convex''. [Debreu appends this footnote: "On this direct consequence of a theorem of A.&amp;nbsp;A.&amp;nbsp;Lyapunov, see {{harvtxt|Vind|1964}}."] But explanations of the &lt;!-- three --&gt; ... functions of prices &lt;!-- taken as examples --&gt; ... can be made to rest&amp;nbsp;on the ''convexity of sets derived by that averaging&amp;nbsp;process''. ''Convexity'' in the commodity&amp;nbsp;space ''obtained by aggregation'' over a collection of insignificant agents is an insight that economic theory owes &lt;!-- in its revealing clarity --&gt; ... to integration theory. [''Italics added'']
&lt;/blockquote&gt;
{{cite journal|title=The Mathematization of economic theory|first=Gérard|last=Debreu|authorlink=Gérard Debreu|issue=Presidential address delivered at the&amp;nbsp;103rd meeting of the American Economic Association,&amp;nbsp;29 December&amp;nbsp;1990, Washington,&amp;nbsp;DC|journal=The American Economic Review|volume=81|date=March 1991|pages=1–7|jstor=2006785|ref=harv}}&lt;/ref&gt; in ([[bang–bang control|"bang-bang"]]) [[control theory]], and in [[statistical theory]].&lt;ref name="Artstein"&gt;{{harvtxt|Artstein|1980|pp=172–183}} {{harvtxt|Artstein|1980}} was republished in a [[festschrift]] for [[Robert Aumann|Robert&amp;nbsp;J. Aumann]], winner of the 2008 [[Nobel Prize in Economics]]: {{cite book|first1=Zvi|last1=Artstein|chapter=22 Discrete and continuous bang–bang and facial spaces or: Look for the extreme points|pages=449–462|title=Game and economic theory: Selected contributions in honor of Robert&amp;nbsp;J. Aumann|url=http://www.press.umich.edu/titleDetailDesc.do?id=14414|editor1-first=Sergiu|editor1-last=Hart|editor2-first=Abraham|editor2-last=Neyman|publisher=University of Michigan Press|location=Ann&amp;nbsp;Arbor,&amp;nbsp;MI|year=1995|isbn=0-472-10673-2|ref=harv|deadurl=yes|archiveurl=https://web.archive.org/web/20110524002010/http://press.umich.edu/titleDetailDesc.do?id=14414|archivedate=24 May 2011|df=dmy-all}}&lt;/ref&gt; Lyapunov's theorem has been called a [[discretization|continuous]] counterpart of the Shapley–Folkman lemma,&lt;ref name="Starr08" /&gt; which has itself been called a [[discrete mathematics#Discrete analogues of continuous mathematics|discrete analogue]] of Lyapunov's theorem.&lt;ref name="MCBlock78" &gt;{{harvtxt|Mas-Colell|1978|p=210}}: {{cite journal|last=Mas-Colell|first=Andreu|authorlink=Andreu Mas-Colell|title=A note on the core&amp;nbsp;equivalence theorem: How many blocking coalitions are there?|journal=Journal of Mathematical Economics|volume=5|year=1978|issue=3|pages=207–215|doi=10.1016/0304-4068(78)90010-1|url=http://www.sciencedirect.com/science/article/B6VBY-4582G5H-2G/2/576b6893a9a730c3557fde0f52d3a9c2|mr=514468|ref=harv}}&lt;/ref&gt;
{{clear}}

==Notes==
{{Reflist|30em}}

==References==

* {{cite book|last1=Arrow|first1=Kenneth&amp;nbsp;J.|authorlink1=Kenneth Arrow|last2=Hahn|first2=Frank&amp;nbsp;H.|authorlink2=Frank Hahn|year=1980&lt;!-- |chapter=Appendix&amp;nbsp;B: Convex and related sets --&gt;|title=General competitive analysis|publisher=North-Holland|&lt;!-- pages=375–401 --&gt;|series=Advanced Textbooks in Economics|volume=12|edition=reprint of San&amp;nbsp;Francisco,&amp;nbsp;CA: Holden-Day,&amp;nbsp;Inc. Mathematical Economics Texts&amp;nbsp;'''6'''|origyear=1971|location=Amsterdam|isbn=0-444-85497-5|mr=439057|ref=harv}}
* {{cite journal|last=Artstein|first=Zvi|title=Discrete&amp;nbsp;and&amp;nbsp;continuous bang-bang and facial&amp;nbsp;spaces, or: Look for the extreme points|journal=SIAM Review|volume=22|year=1980|issue=2|pages=172–185|doi=10.1137/1022026|mr=564562|jstor=2029960|ref=harv}}
* {{cite book|last=Carter|first=Michael|title=Foundations of mathematical economics|url=http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=8630|publisher=MIT&amp;nbsp;Press|location=Cambridge,&amp;nbsp;MA|year=2001|pages=xx+649|isbn=0-262-53192-5|mr=1865841|id=([http://michaelcarteronline.com/FOME/ Author's website] with [http://michaelcarteronline.com/FOME/answers.html answers to exercises])|ref=harv|deadurl=yes|archiveurl=https://web.archive.org/web/20060915230536/http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=8630|archivedate=15 September 2006|df=dmy-all}}
* {{cite book|first=W.&amp;nbsp;E.|last=Diewert|chapter=12 Duality approaches to microeconomic theory
|pages=535–599
|url=http://www.sciencedirect.com/science/article/B7P5Y-4FDF0FN-R/2/dcc0f8c9352eb054c96b3ff481976ce7
|doi=10.1016/S1573-4382(82)02007-4
|title=Handbook of mathematical&amp;nbsp;economics, Volume&amp;nbsp;'''II'''|editor1-link=Kenneth Arrow |editor1-first=Kenneth&amp;nbsp;Joseph|editor1-last=Arrow|editor2-first=Michael&amp;nbsp;D&lt;!-- . --&gt;|editor2-last=Intriligator|series=Handbooks in Economics|volume=1|publisher=North-Holland Publishing&amp;nbsp;Co|location=Amsterdam|year=1982|isbn=978-0-444-86127-6|mr=648778|ref=harv}}
* {{cite book|last=Ekeland|first=Ivar|authorlink=Ivar Ekeland|chapter=Appendix&amp;nbsp;I: An ''a&amp;nbsp;priori'' estimate in convex programming|editor1-last=Ekeland|editor1-first=Ivar|editor2-last=Temam|editor2-first=Roger|editor2-link=Roger Temam|title=Convex analysis and variational problems|edition=Corrected reprinting of the North-Holland|origyear=1976|series=Classics in Applied Mathematics|volume=28 |publisher=Society for Industrial and Applied Mathematics&amp;nbsp;(SIAM)|location=Philadelphia,&amp;nbsp;PA|year=1999|pages=357–373|isbn=0-89871-450-8|mr=1727362|ref=harv}}
* {{cite book|first1=Jerry|last1=Green|first2=Walter&amp;nbsp;P.|last2=Heller|chapter=1 Mathematical&amp;nbsp;analysis and&amp;nbsp;convexity with applications to economics|pages=15–52|url=http://www.sciencedirect.com/science/article/B7P5Y-4FDF0FN-5/2/613440787037f7f62d65a05172503737|doi=10.1016/S1573-4382(81)01005-9|title=Handbook of mathematical&amp;nbsp;economics, Volume&amp;nbsp;'''I'''|editor1-link=Kenneth Arrow |editor1-first=Kenneth&amp;nbsp;Joseph|editor1-last=Arrow|editor2-first=Michael&amp;nbsp;D&lt;!-- . --&gt;|editor2-last=Intriligator|series=Handbooks in Economics|volume=1|publisher=North-Holland Publishing&amp;nbsp;Co|location=Amsterdam|year=1981|isbn=0-444-86126-2|mr=634800|ref=harv}}
* {{cite book|last=Guesnerie|first=Roger|authorlink=Roger Guesnerie|year=1989|chapter=First-best allocation of resources with nonconvexities &lt;!-- original, NOT "non–convexities"  --&gt; in production|pages=99–143|editor-first=Bernard|editor-last=Cornet|editor2-first=Henry|editor2-last=Tulkens|title=Contributions to Operations&amp;nbsp;Research and Economics: The twentieth anniversary of CORE (Papers from the symposium held in Louvain-la-Neuve, January&amp;nbsp;1987)|publisher=MIT Press|location=Cambridge,&amp;nbsp;MA|isbn=0-262-03149-3|mr=1104662|ref=harv}}
* {{cite book|last=Mas-Colell|first=A.|authorlink=Andreu Mas-Colell|chapter=Non-convexity|title=[[The New Palgrave Dictionary of Economics|The new Palgrave: A dictionary of economics]]|editor1-first=John|editor1-last=Eatwell|editor1-link=John Eatwell, Baron Eatwell|editor2-first=Murray|editor2-last=Milgate|editor2-link=Murray Milgate|editor3-first=Peter|editor3-last=Newman|editor3-link=Peter Kenneth Newman|publisher=Palgrave Macmillan|year=1987|edition=first|doi=10.1057/9780230226203.3173&lt;!-- SNAFU at NP? 30 Jan 2011--&gt;|pages=653–661|chapter-url=http://www.dictionaryofeconomics.com/article?id=pde1987_X001573|id=([http://www.econ.upf.edu/~mcolell/research/art_083b.pdf PDF file at Mas-Colell's homepage])|ref=harv}}
* {{cite book|last=Rockafellar|first=R.&amp;nbsp;Tyrrell|authorlink=R. Tyrrell Rockafellar|title=Convex analysis|edition=Reprint of the 1970  ({{MR|274683}}) Princeton Mathematical Series&amp;nbsp;'''28'''|series=Princeton Landmarks in Mathematics|publisher=Princeton University Press|location=Princeton,&amp;nbsp;NJ|year=1997|pages=xviii+451|isbn=0-691-01586-4|mr=1451876|ref=harv}}
* {{cite book|last=Schneider|first=Rolf|title=Convex&amp;nbsp;bodies: The Brunn–Minkowski theory|series=Encyclopedia of Mathematics and its Applications|volume=44|publisher=Cambridge University Press|location=Cambridge|year=1993|pages=xiv+490|ref=harv|isbn=0-521-35220-7|mr=1216521}}
* {{citation|last=Starr|first=Ross&amp;nbsp;M.|authorlink=Ross Starr|issue=1|journal=Econometrica|pages=25–38|title=Quasi-equilibria in markets with non-convex preferences (Appendix&amp;nbsp;2: The Shapley–Folkman theorem, pp.&amp;nbsp;35–37)|volume=37|year=1969|jstor=1909201|ref=harv|doi=10.2307/1909201}}
* {{cite book|last=Starr|first=Ross&amp;nbsp;M.|&lt;!-- |authorlink=Ross Starr --&gt;|chapter=Shapley–Folkman theorem|title=[[The New Palgrave Dictionary of Economics|The new Palgrave dictionary of economics]]|editor-first=Steven&amp;nbsp;N.|editor-last=Durlauf|editor2-first=Lawrence&amp;nbsp;E&lt;!-- . --&gt;|editor2-last=Blume|editor1-link=Steven N. Durlauf|editor2-link=Lawrence E. Blume|publisher=Palgrave Macmillan|year=2008|edition=Second|pages=317–318 (1st&amp;nbsp;ed.)|chapter-url=http://www.dictionaryofeconomics.com/article?id=pde2008_S000107|doi=10.1057/9780230226203.1518|ref=harv}}

==External links==
* {{citation|title=Economics&amp;nbsp;201B: Nonconvex preferences and approximate equilibria|chapter=1 The Shapley–Folkman theorem|pages=1–5|&lt;!-- date=2005–03–14 --&gt;| date=March 2005 |first=Robert M.|last=Anderson|authorlink=&lt;!-- NOT WP's Robert M. Anderson --&gt;|location=Berkeley, CA|publisher=Economics Department, University of California, Berkeley|url=http://elsa.berkeley.edu/users/anderson/Econ201B/NonconvexHandout.pdf|accessdate=15 January 2011}}
* {{citation|title=On the tendency toward convexity of the vector sum of sets|authorlink=Roger Evans Howe|last=Howe|first=Roger| date=November 1979 |publisher=[[Cowles Foundation|Cowles Foundation for Research in Economics]], Yale University|series=Cowles Foundation discussion papers|location=Box&amp;nbsp;2125 Yales Station, New Haven,&amp;nbsp;CT 06520|volume=538 |url=http://cowles.econ.yale.edu/P/cd/d05a/d0538.pdf|&lt;!-- url-2=http://econpapers.repec.org/RePEc:cwl:cwldpp:538 --&gt;|accessdate=15 January 2011}}
* {{citation|last=Starr|first=Ross&amp;nbsp;M.|authorlink=Ross Starr|chapter=8 Convex sets, separation theorems, and non-convex sets in&amp;nbsp;'''R'''&lt;sup&gt;''N''&lt;/sup&gt; (Section&amp;nbsp;8.2.3 Measuring non-convexity, the Shapley–Folkman theorem)|title=General&amp;nbsp;equilibrium theory: An introduction|edition=|publisher=| date=September 2009 |pages=3–6|url=http://www.econ.ucsd.edu/~rstarr/113Winter2010/Webpage/PDFonlyCUPsubmission/Chap8-2009/2009CHAP-08092109.pdf|mr=1462618|id=(Draft of second edition, from Starr's course at the Economics Department of the University of California, San Diego)|accessdate=15 January 2011|doi=10.1017/CBO9781139174749}}
* {{citation|last=Starr|first=Ross&amp;nbsp;M.|authorlink=Ross Starr|title=Shapley–Folkman theorem| date=May 2007 |pages=1–3|url=http://www.econ.ucsd.edu/~rstarr/SFarticle.pdf|accessdate=15 January 2011|id=(Draft of article for the second edition of ''New&amp;nbsp;Palgrave Dictionary of Economics'')}}

{{Geometry-footer|state=collapsed}}
{{Microeconomics|state=collapsed}}
{{Use dmy dates|date=May 2011}}

{{DEFAULTSORT:Shapley-Folkman Lemma}}
[[Category:Convex hulls]]
[[Category:Convex geometry]]
[[Category:Geometric transversal theory]]
[[Category:Additive combinatorics]]
[[Category:Sumsets]]
[[Category:General equilibrium theory]]
[[Category:Convex optimization]]
[[Category:Theorems in geometry]]
[[Category:Lloyd Shapley]]</text>
      <sha1>tenmdwm3epfkghdox62yvgn5dncadb0</sha1>
    </revision>
  </page>
  <page>
    <title>Snark (graph theory)</title>
    <ns>0</ns>
    <id>727811</id>
    <revision>
      <id>846766737</id>
      <parentid>843201140</parentid>
      <timestamp>2018-06-20T19:27:33Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11473">{{About|a term in graph theory||Snark (disambiguation)}}

[[Image:Flower snarkv.svg|thumb|right|The [[flower snark]] J&lt;sub&gt;5&lt;/sub&gt; is one of six snarks on 20 vertices.]]

In the [[mathematics|mathematical]] field of [[graph theory]], a '''snark''' is a [[Graph (discrete mathematics)#Simple graph|simple]], [[Connectivity (graph theory)|connected]], [[Bridge (graph theory)|bridgeless]] [[cubic graph]] with [[chromatic index]] equal to 4. In other words, it is a graph in which every vertex has three neighbors, the connectivity is redundant so that removing no one edge would split the graph, and the edges cannot be colored by only three colors without two edges of the same color meeting at a point. (By [[Vizing's theorem]], the chromatic index of a cubic graph is 3 or 4.) In order to avoid trivial cases, snarks are often restricted to have [[Girth (graph theory)|girth]] at least 5.

Writing in ''[[The Electronic Journal of Combinatorics]]'', [[Miroslav Chladný]] states that
{{cquote|In the study of various important and difficult problems in graph theory (such as the [[Cycle double cover conjecture]] and the [[Nowhere-zero flow#Theory|5-Flow Conjecture]]), one encounters an interesting but somewhat mysterious variety of graphs called snarks.  In spite of their simple definition...and over a century long investigation, their properties and structure are largely unknown.&lt;ref name="chladny2010"&gt;{{Citation| last=Chladný|first=Miroslav|first2=Martin|last2=Škoviera|title=Factorisation of snarks|journal=[[The Electronic Journal of Combinatorics]]| year=2010| volume=17| pages=R32| postscript=.}}&lt;/ref&gt;}}

==History==
[[Peter Guthrie Tait]] initiated the study of snarks in 1880, when he proved that the [[four color theorem]] is equivalent to the statement that no snark is [[Planar graph|planar]].&lt;ref&gt;{{Citation|authorlink=Peter Guthrie Tait|first=Peter Guthrie|last= Tait|title=Remarks on the colourings of maps|journal=Proceedings of the Royal Society of Edinburgh|volume=10|year=1880|pages=729}}&lt;/ref&gt;  The first known snark was the [[Petersen graph]], discovered in 1898. In 1946, [[Croatia]]n [[mathematician]] [[Danilo Blanuša]] discovered two more snarks, both on 18 vertices, now named the [[Blanuša snarks]].&lt;ref&gt;{{Citation|first=Danilo|last=Blanuša|title=Problem četiriju boja|journal=Glasnik Mat. Fiz. Astr. Ser II|volume=1|pages=31&amp;ndash;42|year=1946}}&lt;/ref&gt; The fourth known snark was found two years later by [[W. T. Tutte]] under the pseudonym [[Blanche Descartes]]; it has order 210.&lt;ref&gt;Blanche Descartes, Network-colourings, The Mathematical Gazette (London) 32, 67-69, 1948.&lt;/ref&gt;&lt;ref&gt;Martin Gardner, The Last Recreations: Hydras, Eggs, and Other Mathematical Mystifications, Springer, 2007, {{isbn|0-387-25827-2}}, {{isbn|978-0-387-25827-0}}&lt;/ref&gt; In 1973, [[George Szekeres]] found the fifth known snark — the [[Szekeres snark]].&lt;ref&gt;{{Citation|last=Szekeres|first= George|authorlink=George Szekeres|title=Polyhedral decompositions of cubic graphs|journal=Bulletin of the Australian Mathematical Society|volume=8|pages=367&amp;ndash;387|year=1973|doi=10.1017/S0004972700042660|postscript=.|issue=3}}&lt;/ref&gt; In 1975, [[Rufus Isaacs (game theorist)|Rufus Isaacs]] generalized Blanuša's method to construct two infinite families of snarks: the [[flower snark]] and the BDS or [[Blanuša–Descartes–Szekeres snark]], a family that includes the two Blanuša snarks, the [[Descartes snark]] and the Szekeres snark.&lt;ref&gt;{{Citation | first=R.|last= Isaacs| title=Infinite families of non-trivial trivalent graphs which are not Tait-colorable| journal=[[American Mathematical Monthly]]| volume=82| year=1975| pages=221&amp;ndash;239| doi=10.2307/2319844 | jstor=2319844 | issue=3}}&lt;/ref&gt; Isaacs also discovered a 30-vertices snark that does not belong to the BDS family and that is not a flower snark: the [[double-star snark]].

Snarks were so named by the American mathematician [[Martin Gardner]] in 1976, after the mysterious and elusive object of the poem ''[[The Hunting of the Snark]]'' by [[Lewis Carroll]].&lt;ref&gt;{{Citation|authorlink=Martin Gardner|first=Martin|last=Gardner|title=[[Mathematical Games]]|journal=[[Scientific American]]|issue=234|volume=4|pages=126&amp;ndash;130|year=1976}}&lt;/ref&gt;

==Properties==
All snarks are non-[[Hamiltonian graph|Hamiltonian]], and many known snarks are [[hypohamiltonian graph|hypohamiltonian]]: the removal of any single vertex leaves a Hamiltonian subgraph. A hypohamiltonian snark must be ''bicritical'': the removal of any two vertices leaves a 3-edge-colorable subgraph.&lt;ref&gt;{{citation
 | last = Steffen | first = E.
 | title = Classification and characterizations of snarks
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | volume = 188 | year = 1998 | issue = 1–3 | pages = 183–203
 | mr = 1630478 
 | doi = 10.1016/S0012-365X(97)00255-0}}&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Steffen | first = E.
 | title = On bicritical snarks
 | journal = Math. Slovaca
 | volume = 51 | year = 2001 | issue = 2 | pages = 141–150
 | mr = 1841443 }}&lt;/ref&gt;

It has been shown that the number of snarks for a given even number of vertices is bounded below by an exponential function.&lt;ref&gt;{{cite conference
 | last = Skupień | first = Zdzisław|authorlink=Zdzisław Skupień
 | title = Exponentially many hypohamiltonian snarks
 | conference = 6th Czech-Slovak International Symposium on Combinatorics, Graph Theory, Algorithms and Applications
 | book-title = Electronic Notes in Discrete Mathematics
 | volume = 28 | year = 2007 | pages = 417–424
 | doi = 10.1016/j.endm.2007.01.059}}&lt;/ref&gt;  (Being cubic graphs, all snarks must have an even number of vertices.) [[OEIS]] sequence {{OEIS link|A130315}} contains the number of non-trivial snarks of ''2n'' vertices for small values of ''n''.

The [[cycle double cover conjecture]] posits that in every bridgeless graph one can find a collection of cycles covering each edge twice, or equivalently that the graph can be [[graph embedding|embedded]] onto a surface in such a way that all faces of the embedding are simple cycles. Snarks form the difficult case for this conjecture: if it is true for snarks, it is true for all graphs.&lt;ref&gt;{{citation
 | last = Jaeger | first = François
 | contribution = A survey of the cycle double cover conjecture
 | doi = 10.1016/S0304-0208(08)72993-1
 | pages = 1–12
 | series = North-Holland Mathematics Studies
 | title = Annals of Discrete Mathematics 27 – Cycles in Graphs
 | volume = 27
 | year = 1985
 | isbn = 978-0-444-87803-8}}.&lt;/ref&gt; In this connection, [[Branko Grünbaum]] conjectured that it was not possible to embed any snark onto a surface in such a way that all faces are simple cycles and such that every two faces either are disjoint or share only a single edge; however, a counterexample to Grünbaum's conjecture was found by Martin Kochol.&lt;ref&gt;{{citation
 | last = Kochol | first = Martin
 | contribution = Snarks without small cycles
 | pages = 34–47
 | volume = 67 
 | title = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | year = 1996}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Kochol | first = Martin
 | contribution = 3-Regular non 3-edge-colorable graphs with polyhedral embeddings in orientable surfaces
 | title = Graph Drawing 2008, Editors: I.G. Tollis, M. Patrignani
 | pages = 319–323
 | series = Lecture Notes in Computer Science
 | volume = 5417
 | year = 2009}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Kochol | first = Martin
 | contribution = Polyhedral embeddings of snarks in orientable surfaces
 | pages = 1613–1619
 | volume = 137 
 | title = [[Proceedings of the American Mathematical Society]]
 | year = 2009}}.&lt;/ref&gt;

==Snark theorem==
[[W. T. Tutte]] conjectured that every snark has the Petersen graph as a [[minor (graph theory)|minor]]. That is, he conjectured that the smallest snark, the Petersen graph, may be formed from any other snark by contracting some edges and deleting others. Equivalently (because the Petersen graph has maximum degree three) every snark has a subgraph that can be formed from the Petersen graph by [[homeomorphism (graph theory)|subdividing some of its edges]]. This conjecture is a strengthened form of the four color theorem, because any graph containing the Petersen graph as a minor must be nonplanar. In 1999, [[Neil Robertson (mathematician)|Neil Robertson]], [[Daniel P. Sanders]], [[Paul Seymour (mathematician)|Paul Seymour]], and [[Robin Thomas (mathematician)|Robin Thomas]] announced a proof of this conjecture.&lt;ref&gt;{{cite book
|chapter=Recent Excluded Minor Theorems for Graphs 
|first=Robin
|last=Thomas
|authorlink=Robin Thomas (mathematician)
|pages=201–222
|year=1999
|title=Surveys in Combinatorics, 1999
| publisher=Cambridge University Press
|url=http://people.math.gatech.edu/~thomas/PAP/bcc.pdf}}&lt;/ref&gt; {{asof|2012}}, their proof remains largely unpublished.&lt;ref&gt;{{citation
 | last = belcastro | first = sarah-marie
 | doi = 10.4169/college.math.j.43.1.082
 | issue = 1
 | journal = The College Mathematics Journal
 | mr = 2875562
 | pages = 82–87
 | title = The continuing saga of snarks
 | volume = 43
 | year = 2012}}.&lt;/ref&gt; See the [[Hadwiger conjecture (graph theory)|Hadwiger conjecture]] for other problems and results relating graph coloring to graph minors.

Tutte also conjectured a generalization of the snark theorem to arbitrary graphs: every bridgeless graph with no Petersen minor has a [[Nowhere-zero flows|nowhere zero 4-flow]]. That is, the edges of the graph may be assigned a direction, and a number from the set {1, 2, 3}, such that the sum of the incoming numbers minus the sum of the outgoing numbers at each vertex is divisible by four. As Tutte showed, for cubic graphs such an assignment exists if and only if the edges can be colored by three colors, so the conjecture follows from the snark theorem in this case. However, this conjecture remains open for graphs that need not be cubic.&lt;ref&gt;{{cite web|url=http://garden.irmacs.sfu.ca/?q=op/4_flow_conjecture|title= 4-flow conjecture}}, Open Problem Garden.&lt;/ref&gt;

== List of snarks ==
*[[Petersen graph]] (10 vertices; discovered in 1898)
*[[Tietze's graph]] (12 vertices but with a girth of 3, generally not considered as a snark)
*[[Blanuša snarks]] (two with 18 vertices; discovered in 1946)
*[[Descartes snark]] (210 vertices; discovered by [[Bill Tutte]] in 1948)
*[[Double-star snark]] (30 vertices)
*[[Szekeres snark]] (50 vertices; discovered in 1973)
*[[Watkins snark]] (50 vertices; discovered in 1989)
*[[Flower snark]] (infinite family on 20, 28, 36, 44... vertices; discovered in 1975)

A list of all of the snarks up to 36 vertices, except those with 36 vertices and girth 4, was generated by Gunnar Brinkmann, Jan Goedgebeur, Jonas Hägglund and Klas Markström in 2012.&lt;ref&gt;{{citation | first1 = Gunnar|last1=Brinkmann|first2=Jan|last2=Goedgebeur|first3=Jonas|last3=Hägglund|first4=Klas|last4=Markström | title = Generation and Properties of Snarks | year = 2012 | arxiv = 1206.6690|bibcode=2012arXiv1206.6690B}}&lt;/ref&gt;

==References==
{{reflist|30em}}

== External links ==

* {{MathWorld|title=Snark|urlname=Snark}}
* Alen Orbanić, Tomaž Pisanski, Milan Randić, and Brigite Servatius, "[https://web.archive.org/web/20070311001607/http://www.ijp.si/ftp/pub/preprints/ps/2004/pp914.ps Blanuša Double]", Mathematical Communications 9(2004),91-103.

[[Category:Graph families]]
[[Category:Graph coloring]]
[[Category:Graph minor theory]]
[[Category:Regular graphs]]</text>
      <sha1>p74o32siz23q75whjefvljzcb0bhsoe</sha1>
    </revision>
  </page>
  <page>
    <title>Subalgebra</title>
    <ns>0</ns>
    <id>45239</id>
    <revision>
      <id>861632458</id>
      <parentid>861632420</parentid>
      <timestamp>2018-09-28T20:56:41Z</timestamp>
      <contributor>
        <username>Wbm1058</username>
        <id>14383484</id>
      </contributor>
      <minor/>
      <comment>Disambiguate [[Substructure]] to [[Substructure (mathematics)]] using [[:en:Wikipedia:Tools/Navigation_popups|popups]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3773">In [[mathematics]], a '''subalgebra''' is a subset of an [[algebra]], closed under all its operations, and carrying the induced operations.

"[[Algebra (disambiguation)|Algebra]]", when referring to a structure, often means a [[vector space]] or [[module (mathematics)|module]] equipped with an additional bilinear operation. Algebras in [[universal algebra]] are far more general: they are a common generalisation of ''all'' [[algebraic structures]]. Subalgebra can be a subset of both cases.

== Subalgebras for algebras over a ring or field ==

A '''subalgebra''' of an [[algebra over a field|algebra over a commutative ring or field]] is a [[vector subspace]] which is closed under the multiplication of vectors. The restriction of the algebra multiplication makes it an algebra over the same ring or field. This notion also applies to most specializations, where the multiplication must satisfy additional properties, e.g. to [[associative algebra]]s or to [[Lie algebra]]s. Only for [[unital algebra]]s is there a stronger notion, of '''unital subalgebra''', for which it is also required that the unit of the subalgebra be the unit of the bigger algebra.

=== Example ===

The 2&amp;times;2-matrices over the reals form a unital algebra in the obvious way. The 2&amp;times;2-matrices for which all entries are zero, except for the first one on the diagonal, form a subalgebra. It is also unital, but it is not a unital subalgebra.

== Subalgebras in universal algebra ==
{{main article|Substructure (mathematics)}}
In [[universal algebra]], a '''subalgebra''' of an [[structure (mathematical logic)|algebra]] ''A'' is a [[subset]] ''S'' of ''A'' that also has the structure of an algebra of the same type when the algebraic operations are restricted to ''S''. If the axioms of a kind of [[algebraic structure]] is described by [[variety (universal algebra)|equational laws]], as is typically the case in universal algebra, then the only thing that needs to be checked is that ''S'' is [[closed set|''closed'']] under the operations.

Some authors consider algebras with [[partial functions]]. There are various ways of defining subalgebras for these. Another generalization of algebras is to allow relations. These more general algebras are usually called [[structure (mathematical logic)|structures]], and they are studied in [[model theory]] and in [[theoretical computer science]]. For structures with relations there are notions of weak and of induced [[Substructure (mathematics)|substructure]]s.

=== Example ===
For example, the standard signature for [[group (mathematics)|groups]] in universal algebra is {{nowrap|(&amp;bull;,  &lt;sup&gt;−1&lt;/sup&gt;, 1)}}. (Inversion and unit are needed to get the right notions of homomorphism and so that the group laws can be expressed as equations.) Therefore, a [[subgroup]] of a group ''G'' is a subset ''S'' of ''G'' such that:
* the identity ''e'' of ''G'' belongs to ''S'' (so that ''S'' is closed under the identity constant operation);
* whenever ''x'' belongs to ''S'', so does ''x''&lt;sup&gt;−1&lt;/sup&gt; (so that ''S'' is closed under the inverse operation);
* whenever ''x'' and ''y'' belong to ''S'', so does {{nowrap|''x'' &amp;bull; ''y''}} (so that ''S'' is closed under the group's multiplication operation).

== References ==

* {{Citation | last1=Bourbaki | first1=Nicolas | author1-link=Nicolas Bourbaki | title=Elements of mathematics, Algebra I | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-64243-5 | year=1989}}
* {{Citation | last1=Burris | first1=Stanley N. | last2=Sankappanavar | first2=H. P. | title=A Course in Universal Algebra | url=http://www.thoralf.uwaterloo.ca/htdocs/ualg.html | publisher=[[Springer-Verlag]] | location=Berlin, New York | year=1981}}

[[Category:Universal algebra]]</text>
      <sha1>lzhhbio55dio2g7vxemxrc2vc6hnsdn</sha1>
    </revision>
  </page>
  <page>
    <title>Tommy Bonnesen</title>
    <ns>0</ns>
    <id>50669027</id>
    <revision>
      <id>830376503</id>
      <parentid>783553933</parentid>
      <timestamp>2018-03-14T13:05:26Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <comment>removed [[Category:Danish mathematicians]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2761">[[File:Tommy Bonnesen.jpg|thumb|220px|Tommy Bonnesen]]
'''Tommy Bonnesen''' (27 March 1873 – 14 March 1935) was a Danish mathematician, known for [[Bonnesen's inequality]].

Bonnesen studied at the [[University of Copenhagen]], where in 1902 he received his [[doctorate|Ph.D. (promotion)]] with thesis ''Analytiske studier over ikke-euklidisk geometri'' (Analytic studies of non-Euclidean geometry).&lt;ref&gt;{{MathGenealogy|id=122882}}&lt;/ref&gt; He was the Professor for Descriptive Geometry at the [[Danish Technical University|Polytekniske Læreanstalt]].

He did research on convex geometry and wrote a book on this subject with his student [[Werner Fenchel]]. Bonessen was an Invited Speaker at the [[International Congress of Mathematicians|ICM]] in 1924 in Toronto and in 1928 in Bologna.

With [[Harald Bohr]] he was for many years the co-editor-in-chief of the Matematisk Tidsskrift of the [[Danish Mathematical Society]].

His younger daughter was the theatrical and cinematic star [[Beatrice Bonnesen]] (1906–1979). His elder daughter Merete Bonnesen (1901–1980) was a journalist employed by the newspaper [[Politiken]].

==Selected publications==
* [https://books.google.com/books?id=Ef4UAQAAIAAJ ''Analytiske Studier over ikke-euklidisk Geometri''], Kopenhagen 1902
* with Werner Fenchel: [https://books.google.com/books?id=cvGoBgAAQBAJ ''Theorie der konvexen Körper''], Springer 1934,&lt;ref&gt;{{cite journal|author=Tamarkin, J. D.|authorlink=Jacob Tamarkin|title=Review: ''Theorie den konvexen Körper'' by T. Bonnesen and W. Fenchel|journal=Bull. Amer. Math. Soc.|year=1935|volume=41|issue=9|pages=613–614|url=http://www.ams.org/journals/bull/1935-41-09/S0002-9904-1935-06157-9/S0002-9904-1935-06157-9.pdf|doi=10.1090/s0002-9904-1935-06157-9}}&lt;/ref&gt; English translation: ''Theory of convex bodies'', Moscow (Idaho), BCS Associates 1987
* ''Les Problèmes des Isopérimètres et des Isépiphanes'', Paris, Gauthier-Villars 1929&lt;ref&gt;{{cite journal|author=Gronwall, T. H.|authorlink=Thomas Hakon Grönwall|title=Review: ''Les Problèmes des Isopérimètres et des Isépiphanes'' by T. Bonnesen|journal=Bull. Amer. Math. Soc.|year=1930|volume=36|issue=9|pages=617|url=http://www.ams.org/journals/bull/1930-36-09/S0002-9904-1930-05016-8/S0002-9904-1930-05016-8.pdf|doi=10.1090/s0002-9904-1930-05016-8}}&lt;/ref&gt;
* ''Extréma liés'', Kopenhagen 1931

==Sources==
* Klaus Voss: Integralgeometrie für Stereologie und Bildrekonstruktion, Springer 2007, p.161

==References==
{{reflist}}

{{authority control}}
{{DEFAULTSORT:Bonnesen, Tommy}}
[[Category:1873 births]]
[[Category:1935 deaths]]
[[Category:Geometers]]
[[Category:20th-century Danish mathematicians]]
[[Category:University of Copenhagen alumni]]
[[Category:Technical University of Denmark faculty]]</text>
      <sha1>byb5pvgvbyjw4rxcx3gtx4ta3qpg0ui</sha1>
    </revision>
  </page>
  <page>
    <title>Waring's prime number conjecture</title>
    <ns>0</ns>
    <id>13619909</id>
    <revision>
      <id>858635091</id>
      <parentid>858627676</parentid>
      <timestamp>2018-09-08T16:03:35Z</timestamp>
      <contributor>
        <username>Certes</username>
        <id>5984052</id>
      </contributor>
      <comment>Undid good-faith revision 858627676 by [[Special:Contributions/178.220.28.127|178.220.28.127]] ([[User talk:178.220.28.127|talk]]).  Restore link to article: [[Vinogradov's theorem]] is more than a conjecture, as it has a proof</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1026">In [[number theory]], '''Waring's prime number conjecture''' is a [[conjecture]] related to [[Vinogradov's theorem]], named after the English mathematician [[Edward Waring]]. It states that every [[odd number]] exceeding 3 is either a [[prime number]] or the sum of three prime numbers. It follows from the [[generalized Riemann hypothesis]]&lt;ref&gt;[[Jean-Marc Deshouillers|J.-M. Deshouillers]], G. Effinger, H. te Riele, and D. Zinoviev, ''A complete Vinogradov 3-primes theorem under the Riemann Hypothesis'', Electr. Res. Ann. of AMS 3 (1997), 99--104.&lt;/ref&gt; and (trivially) from [[Goldbach's weak conjecture]].

==See also==

* [[Schnirelmann's constant]]

==References==
&lt;references/&gt;

==External links==
* {{MathWorld|urlname=WaringsPrimeNumberConjecture|title=Waring's prime number conjecture}}

{{Prime number conjectures}}

{{DEFAULTSORT:Waring'S Prime Number Conjecture}}
[[Category:Additive number theory]]
[[Category:Conjectures about prime numbers]]
[[Category:Conjectures that have been proved]]

{{numtheory-stub}}</text>
      <sha1>pakxyizs1kon59z0aninfilqfn83k8h</sha1>
    </revision>
  </page>
  <page>
    <title>Whitney embedding theorem</title>
    <ns>0</ns>
    <id>477578</id>
    <revision>
      <id>846816235</id>
      <parentid>824069702</parentid>
      <timestamp>2018-06-21T02:13:40Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11906">In [[mathematics]], particularly in [[differential topology]], there are two Whitney embedding theorems, named after [[Hassler Whitney]]:

*The '''strong Whitney embedding theorem''' states that any [[differentiable manifold|smooth]] [[real numbers|real]] {{mvar|m}}-[[dimension (mathematics)|dimensional]] [[manifold]] (required also to be [[Hausdorff space|Hausdorff]] and [[second-countable]]) can be [[smooth map|smoothly]] [[embedding|embedded]] in the [[real coordinate space|real {{math|2''m''}}-space]] ({{math|'''R'''&lt;sup&gt;2''m''}}&lt;/sup&gt;), if {{math|''m'' &gt; 0}}. This is the best linear bound on the smallest-dimensional Euclidean space that all {{mvar|m}}-dimensional manifolds embed in, as the [[real projective space]]s of dimension {{mvar|m}} cannot be embedded into real {{math|(2''m'' − 1)}}-space if {{mvar|m}} is a [[power of two]] (as can be seen from a [[characteristic class]] argument, also due to Whitney).
*The '''weak Whitney embedding theorem''' states that any continuous function from an {{mvar|n}}-dimensional manifold to an {{mvar|m}}-dimensional manifold may be approximated by a smooth embedding provided {{math|''m'' &gt; 2''n''}}.  Whitney similarly proved that such a map could be approximated by an [[immersion (mathematics)|immersion]] provided {{math|''m'' &gt; 2''n'' − 1}}. This last result is sometimes called the '''weak Whitney immersion theorem'''.

==A little about the proof==
The general outline of the proof is to start with an immersion {{math|''f'' : ''M'' → '''R'''&lt;sup&gt;2''m''&lt;/sup&gt;}} with [[transversality (mathematics)|transverse]] self-intersections.  These are known to exist from Whitney's earlier work on '''the weak immersion theorem'''. Transversality of the double points follows from a general-position argument.  The idea is to then somehow remove all the self-intersections.  If {{mvar|M}} has boundary, one can remove the self-intersections simply by isotoping {{mvar|M}} into itself (the isotopy being in the domain of {{mvar|f}}), to a submanifold of {{mvar|M}} that does not contain the double-points.  Thus, we are quickly led to the case where {{mvar|M}} has no boundary.  Sometimes it is impossible to remove the double-points via an isotopy—consider for example the figure-8 immersion of the circle in the plane. In this case, one needs to introduce a local double point. [[File:whitneytrickstep1.svg|thumb|350px|right|Introducing double-point.]] Once one has two opposite double points, one constructs a closed loop connecting the two, giving a closed path in {{math|'''R'''&lt;sup&gt;2''m''&lt;/sup&gt;}}.  Since {{math|'''R'''&lt;sup&gt;2''m''&lt;/sup&gt;}} is [[simply connected]], one can assume this path bounds a disc, and provided {{math|2''m'' &gt; 4}} one can further assume (by the '''weak Whitney embedding theorem''') that the disc is embedded in {{math|'''R'''&lt;sup&gt;2''m''&lt;/sup&gt;}} such that it intersects the image of {{mvar|M}} only in its boundary. Whitney then uses the disc to create a [[homotopy|1-parameter family]] of immersions, in effect pushing {{mvar|M}} across the disc, removing the two double points in the process. In the case of the figure-8 immersion with its introduced double-point, the push across move is quite simple (pictured).[[Image:whitneytrickstep2.svg|thumb|450px|right|Cancelling opposite double-points.]] This process of eliminating '''opposite sign''' double-points by pushing the manifold along a disc is called the '''Whitney Trick'''.

To introduce a local double point, Whitney created a family of immersions {{math|α&lt;sub&gt;''m''&lt;/sub&gt; : '''R'''&lt;sup&gt;''m''&lt;/sup&gt; → '''R'''&lt;sup&gt;2''m''&lt;/sup&gt;}} which are approximately linear outside of the unit ball, but containing a single double point.  For {{math|1=''m'' = 1}} such an immersion is given by

:&lt;math&gt;\begin{cases}
\alpha : \mathbf{R}^1 \to \mathbf{R}^2 \\
\alpha(t)=\left(\frac{1}{1+t^2}, t - \frac{2t}{1+t^2}\right)
\end{cases}&lt;/math&gt;

Notice that if {{math|α}} is considered as a map to {{math|'''R'''&lt;sup&gt;3&lt;/sup&gt;}} like so:

:&lt;math&gt;\alpha(t) = \left( \frac{1}{1+t^2},t - \frac{2t}{1+t^2},0\right)&lt;/math&gt;

then the double point can be resolved to an embedding:

:&lt;math&gt;\beta(t,a) = \left(\frac{1}{(1+t^2)(1+a^2)},t - \frac{2t}{(1+t^2)(1+a^2)},\frac{ta}{(1+t^2)(1+a^2)}\right).&lt;/math&gt;

Notice {{math|1=β(''t'', 0) = α(''t'')}} and for {{math|''a'' ≠ 0}} then as a function of {{math|''t''}}, {{math|β(''t'', ''a'')}} is an embedding.

For higher dimensions ''m'', there are {{math|α&lt;sub&gt;''m''&lt;/sub&gt;}} that can be similarly resolved in {{math|'''R'''&lt;sup&gt;2''m''+1&lt;/sup&gt;}}. For an embedding into {{math|'''R'''&lt;sup&gt;5&lt;/sup&gt;}}, for example, define

:&lt;math&gt;\alpha_2(t_1,t_2) = \left(\beta(t_1,t_2),t_2\right) =  \left(\frac{1}{(1+t_1^2)(1+t_2^2)},t_1 - \frac{2t_1}{(1+t_1^2)(1+t_2^2)},\frac{t_1t_2}{(1+t_1^2)(1+t_2^2)}, t_2 \right).&lt;/math&gt;

This process ultimately leads one to the definition:

:&lt;math&gt;\alpha_m(t_1,t_2,\cdots,t_m) = \left(\frac{1}{u},t_1 - \frac{2t_1}{u},  \frac{t_1t_2}{u}, t_2, \frac{t_1t_3}{u}, t_3, \cdots, \frac{t_1t_m}{u}, t_m \right),&lt;/math&gt;

where

:&lt;math&gt;u=(1+t_1^2)(1+t_2^2)\cdots(1+t_m^2).&lt;/math&gt;

The key properties of {{math|α&lt;sub&gt;''m''&lt;/sub&gt;}} is that it is an embedding except for the double-point {{math|1=α&lt;sub&gt;''m''&lt;/sub&gt;(1, 0, ... , 0) = α&lt;sub&gt;''m''&lt;/sub&gt;(−1, 0, ... , 0)}}. Moreover, for {{math|{{!}}(''t''&lt;sub&gt;1&lt;/sub&gt;, ... , ''t&lt;sub&gt;m&lt;/sub&gt;''){{!}}}} large, it is approximately the linear embedding {{math|(0, ''t''&lt;sub&gt;1&lt;/sub&gt;, 0, ''t''&lt;sub&gt;2&lt;/sub&gt;, ... , 0, ''t&lt;sub&gt;m&lt;/sub&gt;'')}}.

===Eventual consequences of the Whitney trick===
The Whitney trick was used by [[Steve Smale]] to prove the [[h-cobordism theorem|''h''-cobordism theorem]]; from which follows the [[Poincaré conjecture]] in dimensions {{math|''m'' ≥ 5}}, and the classification of [[smooth structure]]s on discs (also in dimensions 5 and up). This provides the foundation for [[surgery theory]], which classifies manifolds in dimension 5 and above.

Given two oriented submanifolds of complementary dimensions in a simply connected manifold of dimension ≥ 5, one can apply an isotopy to one of the submanifolds so that all the points of intersection have the same sign.

==History==
{{see also|History of manifolds and varieties}}
The occasion of the proof by [[Hassler Whitney]] of the embedding theorem for smooth manifolds is said (rather surprisingly) to have been the first complete exposition of the ''manifold concept'' precisely because it brought together and unified the differing concepts of manifolds at the time: no longer was there any confusion as to whether abstract manifolds, intrinsically defined via charts, were any more or less general than manifold extrinsically defined as submanifolds of Euclidean space.  See also the [[history of manifolds and varieties]] for context.

==Sharper results==
Although every {{mvar|n}}-manifold embeds in {{math|'''R'''&lt;sup&gt;2''n''&lt;/sup&gt;}}, one can frequently do better.  Let {{math|''e''(''n'')}} denote the smallest integer so that all compact connected {{mvar|n}}-manifolds embed in {{math|'''R'''&lt;sup&gt;''e''(''n'')&lt;/sup&gt;}}. Whitney's strong embedding theorem states that {{math|''e''(''n'') ≤ 2''n''}}.  For {{math|1=''n'' = 1, 2}} we have {{math|1=''e''(''n'') = 2''n''}}, as the [[circle]] and the [[Klein bottle]] show. More generally, for {{math|1=''n'' = 2&lt;sup&gt;''k''&lt;/sup&gt;}} we have {{math|1=''e''(''n'') = 2''n''}}, as the {{math|2&lt;sup&gt;''k''&lt;/sup&gt;}}-dimensional [[real projective space]] show. Whitney's result can be improved to {{math|''e''(''n'') ≤ 2''n'' − 1}} unless {{mvar|n}} is a power of 2. This is a result of [[André Haefliger]] and [[Morris Hirsch]] (for {{math|''n'' &gt; 4}}) and [[C. T. C. Wall]] (for {{math|1=''n'' = 3}}); these authors used important preliminary results and particular cases proved by Hirsch, [[William S. Massey]], [[Sergei Novikov (mathematician)|Sergey Novikov]] and [[Vladimir Rokhlin (Soviet mathematician)|Vladimir Rokhlin]].&lt;ref name=skopenkov2&gt;See section 2 of Skopenkov (2008)&lt;/ref&gt; At present the function {{math|''e''}} is not known in closed-form for all integers (compare to the [[Whitney immersion theorem]], where the analogous number is known).

===Restrictions on manifolds===
One can strengthen the results by putting additional restrictions on the manifold. For example, the [[n-sphere|{{mvar|n}}-sphere]] always embeds in {{math|'''R'''&lt;sup&gt;''n'' + 1&lt;/sup&gt;}}&amp;nbsp;– which is the best possible (closed {{mvar|n}}-manifolds cannot embed in {{math|'''R'''&lt;sup&gt;''n''&lt;/sup&gt;}}). Any compact ''orientable'' surface and any compact surface ''with non-empty boundary'' embeds in {{math|'''R'''&lt;sup&gt;3&lt;/sup&gt;}}, though any ''closed non-orientable'' surface needs {{math|'''R'''&lt;sup&gt;4&lt;/sup&gt;}}.

If {{mvar|N}} is a compact orientable {{mvar|n}}-dimensional  manifold, then {{mvar|N}} embeds in {{math|'''R'''&lt;sup&gt;2''n'' − 1&lt;/sup&gt;}} (for {{mvar|n}} not a power of 2 the orientability condition is superfluous). For {{mvar|n}} a power of 2 this is a result of [[André Haefliger]] and [[Morris Hirsch]] (for {{math|''n'' &gt; 4}}), and Fuquan Fang (for {{math|1=''n'' = 4}}); these authors used important preliminary results proved by Jacques Bo&amp;eacute;chat and Haefliger, [[Simon Donaldson]], Hirsch and [[William S. Massey]].&lt;ref name=skopenkov2/&gt; Haefliger proved that if {{mvar|N}} is a compact {{mvar|n}}-dimensional [[n-connected|{{mvar|k}}-connected]] manifold, then {{mvar|N}} embeds in {{math|'''R'''&lt;sup&gt;2''n'' − ''k''&lt;/sup&gt;}} provided {{math|2''k'' + 3 ≤ ''n''}}.&lt;ref name=skopenkov2/&gt;

==Isotopy versions==
A relatively 'easy' result is to prove that [[Knot theory#Higher dimensions|any two embeddings of a 1-manifold into '''R'''&lt;sup&gt;4&lt;/sup&gt; are isotopic]]. This is proved using general position, which also allows to show that any two embeddings of an {{mvar|n}}-manifold into {{math|'''R'''&lt;sup&gt;2''n'' + 2&lt;/sup&gt;}} are isotopic. This result is an isotopy version of the weak Whitney embedding theorem.

Wu proved that for {{math|''n'' ≥ 2}}, any two embeddings of an {{mvar|n}}-manifold into {{math|'''R'''&lt;sup&gt;2''n'' + 1&lt;/sup&gt;}} are isotopic. This result is an isotopy version of the strong Whitney embedding theorem.

As an isotopy version of his embedding result, [[André Haefliger|Haefliger]] proved that if {{mvar|N}} is a compact {{mvar|n}}-dimensional {{mvar|k}}-connected manifold, then any two embeddings of {{mvar|N}} into {{math|'''R'''&lt;sup&gt;2''n'' − ''k'' + 1&lt;/sup&gt;}} are isotopic provided {{math|2''k'' + 2 ≤ ''n''}}. The dimension restriction {{math|2''k'' + 2 ≤ ''n''}} is sharp: Haefliger went on to give examples of non-trivially embedded 3-spheres in {{math|'''R'''&lt;sup&gt;6&lt;/sup&gt;}} (and, more generally, {{math|(2''d'' − 1)}}-spheres in {{math|'''R'''&lt;sup&gt;3''d''&lt;/sup&gt;}}). See [http://www.map.mpim-bonn.mpg.de/High_codimension_embeddings:_classification further generalizations].

==See also==
* [[Representation theorem]]
* [[Whitney immersion theorem]]
* [[Nash embedding theorem]]

==Notes==
{{reflist}}

==References==
* '''Hassler Whitney; collected papers.''' Hassler Whitney,  James Eells,  Domingo Toledo. Nelson Thornes, 1992
* '''Lectures on the ''h''-cobordism theorem.''' [[John Milnor]].  Princeton University Press. 1965
*[https://books.google.com/books?id=JcMwHWSBSB4C Embeddings and immersions], by Masahisa Adachi, translated by Kiki Hudson
*{{Citation | last1=Skopenkov | first1=A. | title=Embedding and knotting of manifolds in Euclidean spaces | arxiv=math/0604045 | year=2008 | journal=In: Surveys in Contemporary Mathematics, Ed. N. Young and Y. Choi, London Math. Soc. Lect. Notes. | volume=347 | issue=2 | pages=248–342| bibcode=2006math......4045S }}

==External links==
* [http://www.map.mpim-bonn.mpg.de/Embeddings_in_Euclidean_space:_an_introduction_to_their_classification Classification of embeddings]

{{DEFAULTSORT:Whitney Embedding Theorem}}
[[Category:Theorems in differential topology]]</text>
      <sha1>l9t0rz4duhihy7m6zpus91okqb4sgx4</sha1>
    </revision>
  </page>
</mediawiki>
