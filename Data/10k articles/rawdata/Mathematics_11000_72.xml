<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>ATLAS of Finite Groups</title>
    <ns>0</ns>
    <id>22659407</id>
    <revision>
      <id>782550436</id>
      <parentid>742966158</parentid>
      <timestamp>2017-05-27T16:59:02Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1914">{{italic title}}
{{Group theory sidebar}}
The '''''ATLAS of Finite Groups''''', often simply known as the '''''ATLAS''''', is a [[group theory]] book by [[John Horton Conway]], [[Robert T. Curtis|Robert Turner Curtis]], [[Simon P. Norton|Simon Phillips Norton]], [[Richard A. Parker|Richard Alan Parker]] and [[Robert Arnott Wilson]] (with computational assistance from J. G. Thackray), published in December 1985 by [[Oxford University Press]] and reprinted with corrections in 2003 ({{ISBN|978-0-19-853199-9}}).  It lists basic information about 93 finite [[Simple group|simple]] groups, the information being generally: its order, [[Schur multiplier]], [[outer automorphism group]], various constructions (such as [[Presentation of a group|presentations]]), conjugacy classes of [[maximal subgroup]]s (with characters [[group action]] they define), and, most importantly, [[character table]]s (including power maps on the conjugacy classes) of the group itself and bicyclic extensions given by stem extensions and automorphism groups.  In certain cases (such as for the [[Group of Lie type|Chevalley groups]] &lt;math&gt;E_n(2)&lt;/math&gt;), the character table is not listed and only basic information is given.

The ATLAS is a recognizable large format book (sized 420mm by 300mm) with a cherry red cardboard cover and spiral binding.&lt;!---This is worth mentioning because the ATLAS's appearance is very striking and easily memorized as it is often seen apart from other books in math libraries.---&gt; The names of the authors, all six letters long, with initials for the first and second letter, are printed on the cover in the form of an array which evokes the idea of a character table.

The ATLAS is being continued in the form of an electronic database, the [http://brauer.maths.qmul.ac.uk/Atlas/v3/ ATLAS of Finite Group Representations].

[[Category:Finite groups]]
[[Category:Mathematics books]]


{{math-lit-stub}}</text>
      <sha1>7drgditsg37ob3mn59thovv87epaf7d</sha1>
    </revision>
  </page>
  <page>
    <title>Actuarial credentialing and exams</title>
    <ns>0</ns>
    <id>34905254</id>
    <revision>
      <id>868131472</id>
      <parentid>862060096</parentid>
      <timestamp>2018-11-10T05:36:31Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Reformat 2 archive links. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="39210">{{see also|Category:Actuarial associations}}
The '''actuarial credentialing and exam''' process usually requires passing a rigorous series of professional examinations, most often taking several years in total, before one can become recognized as a credentialed [[actuary]]. In some countries, such as Denmark, most study takes place in a university setting. In others, such as the U.S., most study takes place during employment through a series of examinations. In the UK, and countries based on its process, there is a hybrid university-exam structure.

==Policies of various countries==

===Australia===
The education system in Australia is divided into three components: an exam-based curriculum; a professionalism course; and work experience {{harv|IAA-Ed|2013}}. The system is governed by the [[Institute of Actuaries of Australia]].

The exam-based curriculum is in three parts. Part I relies on exemptions from an accredited under-graduate degree from either [[Monash University]], [[Macquarie University]], [[University of New South Wales]], [[University of Melbourne]], [[Australian National University]] or [[Curtin University]] {{harv|IAA-Part I|2013}}. The courses cover subjects including finance, financial mathematics, economics, contingencies, demography, models, probability and statistics. Students may also gain exemptions by passing the exams of the [[Institute of Actuaries]] in London {{harv|IAA-Part I|2013}}. Part II is the [[Actuarial control cycle]] and is also offered by each of the universities above {{harv|IAA-Part II|2013}}. Part III consists of four half-year courses of which two are compulsory and the other two allow specialization {{harv|IAA-Part III|2006}}.

To become an Associate, one needs to complete Part I and Part II of the accreditation process, perform 3 years of recognized work experience, and complete a professionalism course.

To become a Fellow, candidates must complete Part I, II, III, and take a professionalism course. Work experience is not required however, as the Institute deems that those who've successfully completed Part III have shown enough level of professionalism.

===Bangladesh===
The [[Actuarial Society of Bangladesh]] is the unique Professional Body of Actuaries in Bangladesh. [[Actuarial Society of Bangladesh]] follow the curriculum of The [[Institute and Faculty of Actuaries]], [[United Kingdom]]. 
No University in Bangladesh provide the  [[academic degrees]] like [[bachelor's degree]], [[master's degrees]] etc. in [[Actuarial Science]]. [[University of Dhaka]], [[Rajshahi University]], [[Jahangirnagar University]] provide a few course of [[Actuarial Science]] in [[Statistics]], [[Applied Statistics]] department. From 2015 Dhaka university and East west university are providing Master's in Actuarial Science.

===Canada===
The [[Canadian Institute of Actuaries]] (the CIA) recognizes fellows of both the Society of Actuaries and the Casualty Actuary Society, provided that they have specialized study in Canadian actuarial practice. For fellows of the SOA, this is fulfilled by taking the CIA’s Practice Education Course (PEC). For fellows of the Casualty Actuarial Society, this is fulfilled by taking the nation specific Exam 6-Canada, instead of Exam 6-United States {{harv|CAS|2011b}}. Unlike their American counterparts, the CIA only has one class of actuary: Fellow. Further, the CIA requires three years of actuarial practice within the previous decade, and 18 months of Canadian actuarial practice within the last three years, to become a fellow {{harv|CIA|2004}}.
The CIA also offers an associate designation.

===Denmark===
In Denmark it normally takes five years of study at the [[University of Copenhagen]] to become an actuary with no professional experience requirement. There is a focus on [[statistics]] and [[probability theory]], and a requirement for a [[Master's degree|master's]] [[thesis]] {{harv|Norberg|1990}}. By Danish law, responsibility for the practise of any life insurance business must be taken by a formally acknowledged and approved actuary. Approval as a formally responsible actuary requires three to five years of professional experience.{{harv|Haastrup|Nielsen|2007}}

===Germany===
Current rules for the [[German Actuarial Society]] require an actuary to pass more than 13 exams. {{harv|DAV|2011}}

===Greece===
In [[Greece]] the only specialized school of actuaries is the Department of Statistics and Actuary-Finance Mathematics of the [[University of the Aegean]], in [[Samos]]. The duration of studies is four years, with a practice period included, and the certificate given is a bachelor's degree. The Diploma of Actuary is given by the Actuaries Union of Greece, after successful exams within the Union. Other schools that offer actuary directions can be found throughout the rest departments of [[Statistics]] in the various universities of the country, most notably that of the [[Athens University of Economics and Business]] (OPA/ASOEE), which is also the top economic university of [[Greece]].

===India===
The [[Actuarial Society of India]] (now converted into Institute of Actuaries of India) offers both associate-ship and fellowship classes of membership. However, prospective candidates must be admitted to the society as students before they achieve associate-ship or fellowship. The exam sequence is similar to the British model, with Core and Specialty technical and application exams. The exams are conducted twice a year during the months of May–June and October–November {{harv|ASI|2006}}. Starting from January 2012, the institute has started conducting entrance exam. Only those applicants who clear the entrance test can appear for the Core Technical papers.

===Italy===
Italian actuaries also receive their training through university plus a single examination given by the state (''Esame di Stato''). The studies usually take a total of five years to complete, three (''Triennale'') plus two (''Magistrale''), because students need to pass at least 30 exams (the exact number depends on the university and curriculum), many with both written and oral components on actuarial and economic topics. After university, to become qualified to sign statements of actuarial opinion, students must pass the ''Esame di Stato'', which is offered twice a year in [[Rome]] and [[Trieste]]; the ''Esame di Stato'' consists of two written sections, a practical portion, and an oral exam. The association of qualified actuaries is called "Ordine degli Attuari" ("Order of Actuaries").

===Mexico===
Unlike in the United States, in Mexico actuarial training consists of a full four or five-year licenciatura (bachelor) degree course. Only a few universities in the country offer the degree; some of them are the National Autonomous University of Mexico ([[UNAM]]), Autonomous University of Yucatán ([[UADY]]), Universidad de las Americas Puebla ([[UDLAP]]), [[Universidad Anahuac]], Autonomous Technological Institute of Mexico ([[Instituto Tecnológico Autónomo de México|ITAM]]), Autonomous University of Guadalajara ([[Universidad Autónoma de Guadalajara|UAG]]), and Autonomous University of Nuevo León ([[Universidad Autónoma de Nuevo León|UANL]]).

===Norway===
In [[Norway]] the education to become an actuary takes five years. The education usually consists of a bachelor's degree (three years) and a master's degree (two years). The bachelor's degree needs to contain a specific amount of courses in mathematics and statistics. The master's degree usually consists of one year of courses and one year writing a master's degree about a topic related to the actuarial profession. [[University of Bergen|The University of Bergen]] and [[University of Oslo|The University of Oslo]] offers the education to become an actuary in [[Norway]] {{harv|University of Bergen|2011}}.
To become an international qualified actuary, a person with a Norwegian actuarial education must also take two courses in economics (macroeconomics and accounting) and a course in ethics. The ethics course, which lasts a day, is offered by the [[Norwegian Society of Actuaries]] {{harv|Norwegian Society of Actuaries|2011}}.

===Portugal===
In [[Portugal]] the only school that offers a degree in actuarial science is [https://www.iseg.ulisboa.pt/aquila/cursos/ca?ano=2016&amp;locale=en&amp;_request_checksum_=e6a8ecd3c5b8c10590c3589b5ecc21f3d203db2f ISEG] at the [[University of Lisbon]]. It is a two-year master's degree, fully integrated into the Bologna regimen. The programme is, since 2017/18,  accredited by the Institute and Faculty of Actuaries in the UK, leading to exemptions based on the student overall performance during the course, or leading to exemptions from individual exams based on the student's performance in certain modules of the Masters.

===South Africa===
Actuaries in South Africa are served by the [[Actuarial Society of South Africa]] (ASSA). Until recently the requirement to qualify as an actuary in South Africa was to pass the exams hosted by the UK bodies. Starting in 2010, a South African actuarial qualification hosted by ASSA has replaced this arrangement ([http://www.actuarialsociety.org.za/ ASSA's website]). Key changes include exam syllabuses based on South African specific content. The UK actuarial professional bodies however still supports Actuaries qualification through the UK. Students may receive exemption from part of the examinations for qualification from approved universities. The South Africa qualification does have mutual recognition with many of the international actuarial bodies as well as approval of the syllabus from the International Actuarial Association.

One may obtain the Chartered Enterprise Risk Actuary (CERA) designation through the ASSA.

===Sweden===
Actuarial training in [[Sweden]] takes place at [[Stockholm University]]. The five-year [[Master's degree|master's]] program (for those with no previous university-level knowledge in mathematics, or without a bachelor's degree in mathematics) covers the subjects [[mathematics]], [[statistics|mathematical statistics]], [[actuarial science|insurance mathematics]], [[Mathematical finance|financial mathematics]], insurance [[law]] and insurance [[economics]]. The program operates under the Division of Mathematical Statistics {{harv|Stockholm University|2006}}.  For those with a bachelor's degree in mathematics statistics or with a master's degree in mathematics, a two years full-time master's degree [https://archive.is/20130418113757/http://www.math.su.se/utbildning/utbildningsprogram-i-matematik-och-matematisk-statistik/masterprogram-i-forsakringsmatematik-1.70941  Aktuarieprogrammet] has been created since 2002, at Stockholm University, which has a long history of research on  [http://www.math.su.se/english/about-us/history insurance mathematics].

===Turkey ===
Qualification in [[Turkey]] consists of a series of exams administered by an exam board made up of representatives of the [[Actuarial Society of Turkey]], the government and universities. The exams are split into 3 levels: first level (essentials of insurance and economy, mathematics, statistics and probability, financial mathematics); second level (accounting and financial reporting, insurance mathematics (life and non-life), risk analysis, actuarial modeling); and third level (investment and risk management, non-life insurance, life insurance, health insurance, pension systems). After completing the first level exams, a candidate becomes an "actuarial trainee", after the second level an "assistant actuary", and after the third level and 3 years of related work experience the candidate becomes an "actuary".

===UK and Ireland===
Qualification in the [[United Kingdom]] and [[Republic of Ireland|Ireland]] consists of a combination of exams and courses provided by the professional body, the [[Institute and Faculty of Actuaries]]. The exams may only be taken upon having officially joined the body,&lt;ref&gt;[http://www.actuaries.org.uk/students/pages/how-register-student]&lt;/ref&gt; unlike many other countries where exams may be taken earlier. Most trainee actuaries study while working for an actuarial employer using resources provided by ActEd&lt;ref&gt;[http://www.ActEd.co.uk]&lt;/ref&gt; (The Actuarial Education Company, a subsidiary of BPP Actuarial Education Ltd.), which is contracted to provide actuarial tuition for students on behalf of Institute and Faculty Education Ltd (IFE), a subsidiary of the Institute and Faculty of Actuaries.&lt;ref&gt;{{Cite web |url=http://www.actuaries.org.uk/students/pages/exam-preparation |title=Archived copy |access-date=2013-12-31 |archive-url=https://web.archive.org/web/20121106021001/http://www.actuaries.org.uk/students/pages/exam-preparation |archive-date=2012-11-06 |dead-url=yes |df= }}&lt;/ref&gt;

However, a candidate may offer proof of having previously covered topics (at a high enough standard, usually while at university) to be exempt from taking certain subjects.&lt;ref&gt;{{Cite web |url=http://www.actuaries.org.uk/students/pages/frequently-asked-questions-exemptions |title=Archived copy |access-date=2013-12-31 |archive-url=https://web.archive.org/web/20130305040931/http://www.actuaries.org.uk/students/pages/frequently-asked-questions-exemptions |archive-date=2013-03-05 |dead-url=yes |df= }}&lt;/ref&gt;

The exams themselves are split into four sections:&lt;ref&gt;[http://www.actuaries.org.uk/students/pages/our-exams-explained]&lt;/ref&gt; Core Technical (CT), Core Applications (CA), Specialist Technical (ST), and Specialist Applications (SA). For students who joined the Profession after June 2004, a further requirement that the student carry out a "Work-based skills" exercise has been brought into effect. This involves the student submitting a series of essays to the Profession detailing the work that he or she has performed. In addition to exams, essays and courses, it is required that the candidate have at least three years' experience of actuarial work under supervision of a recognized actuary to qualify as a Fellow of the Institute of Actuaries (FIA) or of the Faculty of Actuaries (FFA) {{harv|Institute and Faculty of Actuaries|2011a}}.

Actuaries can also gain partial credit towards Fellowship of the Institute and Faculty of Actuaries by following an [[actuarial science]] degree at an accredited university. At the undergraduate level the only locally accredited programmes are currently at [[University of Manchester]], [[University College Dublin]], [[Queen's University Belfast]], [[Heriot-Watt University]], [[University of Edinburgh]], the [[London School of Economics]], [[University of Southampton]], [[City University, London]], [[University of Leicester]] and the [[University of Kent]]. Full-time accredited masters programmes are provided only by the University of Kent, Heriot-Watt University, University of Leicester and City University; part-time accredited master's degrees are offered by [[Imperial College London]] and the [[University of Leicester]]. Actuarial programmes that offer the possibility of exemption from individual professional exams are also available at City University, London, Heriot-Watt University, the London School of Economics, the [[University of Southampton]], [[Swansea University]], the University of Kent and the [[University of Warwick]]. In Ireland exemptions are offered by [[National University of Ireland, Galway]], [[Dublin City University]], [[University College Cork]]. Some South African universities are also accredited by the Institute and Faculty of Actuaries. These universities include the [[University of Pretoria]], [[University of Cape Town]], [[Stellenbosch University]], [[University of the Free State]] and the [[University of the Witwatersrand]]. [http://www.iseg.utl.pt/ ISEG] in Lisbon, Portugal, offers the possibility of exemption from some professional exams of the Institute and Faculty of Actuaries.

Note that the UK Profession is currently introducing the Certified Actuarial Analyst (CAA) qualification to "provide those working in financial and actuarial roles at a technical level around the world with valuable skills and a well respected qualification".&lt;ref&gt;[http://www.actuaries.org.uk/news/articles/new-qualification-takes-step-forward]&lt;/ref&gt;

===United States===
In the U.S., for life, health, and pension actuaries, exams are given by the [[Society of Actuaries]], while for property-casualty actuaries the exams are administered by the [[Casualty Actuarial Society]]. The Society of Actuaries’ requirements for Associateship include passing five preliminary examinations, demonstrating educational experience in [[economics]], [[corporate finance]] and [[applied statistics]]—called validation by educational experience (VEE), completing an eight-module self-learning series, and taking a course on professionalism {{harv|SOA|2012a}}. For Fellowship, three other modules, three or four exams depending on specialty track, and a special fellowship admission course is added {{harv|SOA|2012c}}. The Casualty Actuarial Society requires the successful completion of seven examinations, two modules, and economics and corporate finance VEE's for Associateship and three additional exams for Fellowship. In addition to these requirements, casualty actuarial candidates must also complete professionalism education and be recommended for membership by existing members {{harv|CAS|2011a}}.  One may become a Chartered (or Certified) Enterprise Risk Analyst (CERA) through either the SOA or the CAS.

To sign certain statements of actuarial opinion, however, American actuaries must be members of the [[American Academy of Actuaries]]. Academy membership requirements include membership in one of the recognized actuarial societies, at least three years of full-time equivalent experience in responsible actuarial work, and either residency in the United States for at least three years or a non-resident or new resident who meets certain requirements {{harv|AAA|2010}}. Continuing education is required after certification for all actuaries who sign statements of actuarial opinion {{harv|AAA|2008}}.

In the pension area, American actuaries must pass three examinations to become an [[Enrolled Actuary]]. Some pension-related filings to the [[Internal Revenue Service]] and the [[Pension Benefit Guaranty Corporation]] require the signature of an Enrolled Actuary. Many Enrolled Actuaries belong to the [[Conference of Consulting Actuaries]] or the [[American Society of Pension Professionals and Actuaries]].

In 2009, the Society of Actuaries began a high-level accreditation system for universities, recognizing the best actuarial schools as [http://www.soa.org/Education/Resources/actuarial-colleges/actuarial-college-listings-details.aspx Centers of Actuarial Excellence.] There are two sets of criteria that must be met: [https://www.soa.org/Education/Resources/Cae/edu-cae-overview.aspx A Criteria and B Criteria.] Additionally, a site visit must be performed by a team of CAE committee members who evaluate the University and conduct interviews with students and faculty. The designation is retained for five years and if a criteria is not met, then the University must provide a plan for how they will address the problem within a reasonable time frame.

====Preliminary Exams====
There are five preliminary exams. Most of the exams are multiple choice and administered on computers at [[Prometric]] testing centers. Candidates are allowed to use a calculator from an approved list.&lt;ref&gt;http://www.beanactuary.com/exams/rules/?fa=identification-and-calculators#calculator&lt;/ref&gt; The exams are timed and last between three and four hours. Some tests provide instant feedback as to whether or not a candidate has passed that particular exam (see table below). All test scores (on a 0-10 scale with 6 or higher passing) are posted six to eight weeks after the test. However, due to the way the test is scaled,  the scores can range from 0-10, but there are also situations where the highest grade for a test is a 9 even if every single question was answered correctly.

Through the end of 2013, four of the preliminary exams (all but MLC) were jointly sponsored by CAS and SOA. In late 2012, SOA announced its intention to end joint sponsorship beginning with tests administered in January 2014. CAS has not announced plans to develop alternative forms of the jointly sponsored exams; however, it accepts SOA exams for CAS credit.

SOA administers exam MLC, which covers life contingencies topics. Starting in May 2014, MLC includes both multiple choice and open-response questions. SOA made this change because, in their view, strict multiple-choice questions are not sufficient or adequate to test whether the candidates are familiar and fluent in the material. The test is four-hours long, allows calculators, and is administered via a paper-and-pencil format. Multiple choice questions account for 40% of the exam, and open-response questions account for 60% of the exam. Candidates may freely move between the two sections. The two sections are graded separately. However, since the multiple-choice questions are easier, only candidates who have answered a certain percentage of the multiple-choice questions correctly have their written answers graded.

CAS develops exam S, as a full alternative to SOA's exam MLC. Exam S covers many topics within statistics, survival models, and stochastic processes. Between the beginning of 2014 and the end of 2015, CAS offered two interim exams: exam LC, covering many life contingencies topics, and exam ST, covering statistical and stochastic methods. Those candidates who passed 3L or MLC before 2014 are exempt from taking LC and ST. Additionally, those candidates passing exam LC, exam ST, and the Statistics VEE by August 2016 are exempt from taking exam S.

{| class="sortable wikitable"
|-
! SOA Exam || CAS Exam || Exam Title || Exam Topics || Format || Tests per Year || Pass/Fail Estimate
|-
| align="center"| P || align="center"| 1 || align="center"| Probability || Law of total probability, Bayes' theorem, basic counting, common discrete and continuous distributions, univariate and multivariate distributions, order statistics, transformation of distributions, conditional expectation, variance and covariance, basic knowledge of insurance and risk management  || align="center"| Computer || align="center"| 6 || align="center"| Yes
|-
| align="center"| FM || align="center"| 2 || align="center"| Financial Mathematics || Basic interest theory, annuities, bonds, loans, cash flows, portfolios, immunization, and financial derivatives, options, hedging, investment strategies, forwards, futures, and swaps || align="center"| Computer || align="center"| 6 || align="center"| Yes
|-
| align="center"| IFM || align="center"| 3F || align="center"| Actuarial Models: Financial Economics || Interest rate models, rational valuation of derivative securities, and risk management techniques || align="center"| Computer || align="center"| 3 || align="center"| No
|-
| align="center"| MLC || align="center"| -- || align="center"| Actuarial Models: Life Contingencies || Survival models, Markov chain models, life insurances and annuities, Traditional and Universal Life Models|| align="center"| Paper and pencil || align="center"| 2 || align="center"| No
|-
| align="center"| C || align="center"| MAS-II || align="center"| Construction and Evaluation of Actuarial Models || Severity models, frequency models, aggregate models, construction of empirical models, construction and selection of parametric models, estimating failure time and loss, determining the acceptability of a fitted model, credibility, simulation || align="center"| Computer || align="center"| 3 || align="center"| Yes
|-
| align="center"| -- || align="center"| MAS-I || align="center"| Statistics and Probabilistic Models || Stochastic processes, survival models (including limited life contingencies concepts), statistics, general linear models (including ordinary least squares) and time series&lt;ref&gt;http://www.casact.org/admissions/syllabus/index.cfm?fa=Ssyllabi&amp;parentID=345&lt;/ref&gt; || align="center"| Paper and pencil || align="center"| 2 || align="center"| No
|}

====Validation by Educational Experience====
Candidates for CAS and SOA membership must pass standardized tests in introductory [[economics]] and [[corporate finance]]. Candidates for SOA membership must pass an additional standardized test in [[applied statistics]]. Economics has two components: macroeconomics and microeconomics. Applied statistics has two components: [[Regression analysis|regression]] and [[time series]]. Instead of passing exams, candidates may earn credit by passing an approved college class with a B- or better grade or by completing an approved correspondence class.

====CAS Advanced Exams====
To earn associate membership (ACAS), a candidate must pass the preliminary exams, VEE, two online modules, exam five, and exam six. For an associate to become a fellow (FCAS), exams seven through nine must be passed. The exams are administered on paper-and-pencil. Exam questions generally require an open answer; however, multiple-choice questions are allowed, too. Exam six comes in two versions: one for candidates in the United States and one for candidates in Canada.

{| class="wikitable"
!CAS Exam
!Subject Matter
!Test Window&lt;ref&gt;http://www.casact.org/admissions/syllabus/schedule.pdf&lt;/ref&gt;
|-
|Exam 5
|Basic Techniques for Ratemaking and Estimating Claim Liabilities
|Late April, Late October
|-
|Exam 6
|Nation-Specific Examination: Regulation and Financial Reporting
|Late April, Late October
|-
|Exam 7
|Estimation of Policy Liabilities, Insurance Company Valuation, and Enterprise Risk Management
|Late April
|-
|Exam 8
|Advanced Ratemaking
|Late October
|-
|Exam 9
|Financial Risk and Rate of Return
|Late April
|}

The two modules that must be completed to become an associate are...

{| class="wikitable"
!Module
!Subject Matter
|-
|Module 1
|Risk Management and Insurance Operations
|-
|Module 2
|Insurance Accounting, Coverage Analysis, Insurance Law, and Insurance Regulation
|}

The exam schedule above started in 2011. Candidates who passed exams offered before 2011 are granted credit according to the following schedule. To earn credit for new exam five, a candidate must pass old exam five and old exam six. Candidates who passed ''one'' of old exam five and old exam six must pass a special exam covering the remaining material on new exam five.

{| class="wikitable"
!Old Exam
!Conversion credit
|-
|Old Exam 5
|Half of New Exam 5 on ''Basic Ratemaking'' plus Module 1 (Risk Management and Insurance Operations)
|-
|Old Exam 6
|Half of New Exam 5 on ''Basic Reserving'' plus New Exam 7
|-
|Old Exam 7
|New Exam 6 plus Module 2 (Insurance Accounting, Coverage Analysis, Insurance Law, and Insurance Regulation)
|-
|Old Exam 8
|New Exam 9
|-
|Old Exam 9
|New Exam 8
|}

====SOA Advanced Exams====
After passing the preliminary exams, SOA candidates complete the Fundamentals of Actuarial Practice e-learning course and the Associateship Professionalism Course. FAP contains eight learning modules and two assessments. APC is a live, in-person seminar held in different places around the country. This completes the requirements for associate membership (ASA).

Associates select one of six areas of competence for further training. Each area has three or four exams and three learning modules. Exam one for "Retirement Benefits" has alternative requirements specific to Canada and the United States. For all tracks other than "Corporate Finance and Enterprise Risk Management," a candidate may pass the "Enterprise Risk Management" exam as a substitute for exam three. After completing the exams and modules, candidates must pass the "Decision Making and Communication Module" and the "Fellowship Admissions Course" before earning promotion to fellow (FSA).

{| class="wikitable"
!Type
!General Insurance
!Corporate Finance and Enterprise Risk Management
!Quantitative Finance and Investment
!Individual Life and Annuities
!Retirement Benefits
!Group and Health
|-
|Exam 1
|Introduction to General Insurance
|Strategic Decision Making
|Quantitative Finance and Investment Core
|Life Pricing
|Funding and Regulation (Canada) '''or''' Enrolled Actuaries Series (US)
|Group and Health Core
|-
|Exam 2
|Introduction to Ratemaking and Reserving
|Corporate Finance Foundations
|Quantitative Finance and Investment Advanced
|Life Finance and Valuation
|Design and Accounting Exam
|Group and Health Advanced
|-
|Exam 3
|Advanced Topics in General Insurance
|Enterprise Risk Management
|Investment Risk Management
|Life Risk Management
|Retirement Plan Investment and Risk Management
|Group and Health Specialty
|-
|Exam 4
|Financial and Regulatory Environment
|
|
|
|
|
|-
|Module 1
|Enterprise Risk Management
|Enterprise Risk Management
|Enterprise Risk Management
|Enterprise Risk Management
|Enterprise Risk Management
|Enterprise Risk Management '''or''' Health Foundations 
|-
|Module 2
|Financial Economics
|Financial Reporting
|Financial Reporting
|Financial Economics
|Financial Economics
|Financial Economics
|-
|Module 3
|Applications of Statistical Techniques
|Advanced Topics in Corporate Finance
|Financial Modeling
|Regulation &amp; Taxation
|Social Insurance
|Pricing, Reserving &amp; Forecasting
|}

====Chartered Enterprise Risk Analyst====
Chartered Enterprise Risk Analyst (CERA) is a global designation awarded by more than ten international actuarial bodies, including the CAS and SOA.  Each body designs its own syllabus and requirements to award the designation, subject to approval by the international CERA body.

CAS candidates must complete all of the requirements to become a FCAS except for exam eight. They must also complete exam ST9, Enterprise Risk Management Specialist Technical, administered by the Institute and Faculty of Actuaries (U.K.) '''and''' the Enterprise Risk Management and Modeling Seminar for CERA Qualification

SOA candidates must complete all of the preliminary exams except for exam MLC. Candidates must also pass VEE Economics, VEE Corporate Finance, Fundamentals of Actuarial Practice, the Enterprise Risk Management exam, the Enterprise Risk Management module, and the Associateship Professionalism Course.

====Enrolled Actuary====
{{Main|Enrolled Actuary}}
In the US the term "Enrolled Actuary" is applied to an individual who has taken certain exams sponsored by the [[Joint Board for the Enrollment of Actuaries]] relating to pension plans. Enrollment in the Joint Board is a requirement for SOA Retirement Fellows working in the US.

The American equivalent of the Canadian Institute of Actuaries is the American Academy of Actuaries (AAA).

===Other countries===
Many other countries pattern their requirements after the larger societies of the US or UK. In general, the websites of these organizations are often the easiest source for finding out about membership requirements and resources.

==References==
&lt;!-- Note: This article uses author-date citation format, not footnotes. If you have any problems, please ask on the talk page and someone will be happy to help you. Also, please place references in alphabetical order by last name or organizational name. The references have been broken into alphabetical sections to make it easier. Thank you. --&gt;
{{refbegin|2}}
&lt;!-- A --&gt;
*{{cite journal
 |year =2008
 |journal =Qualification Standards for Actuaries Issuing Statements of Actuarial Opinion in the United States
 |title =Continuing Education Requirement
 |pages =5–7
 |publisher=[[American Academy of Actuaries]]
 |location=[[Washington, D.C.]]
 |url =http://www.actuary.org/qualstandards/qual.pdf
 |format =PDF
 |accessdate=January 4, 2010
 |ref={{harvid|AAA|2008}}
}}
*{{cite web
 |url          = http://www.actuary.org/beco.asp#3
 |title        = Membership requirements
 |year         = 2010
 |publisher    = [[American Academy of Actuaries]]
 |location     = [[Washington, D.C.]]
 |accessdate   = January 4, 2010
 |ref          = {{harvid|AAA|2010}}
 |archive-url  = https://web.archive.org/web/20090925111655/http://www.actuary.org/beco.asp#3
 |archive-date = 2009-09-25
 |dead-url     = yes
 |df           = 
}}
*{{cite web
 |url=http://www.actuariesindia.org/index.html 
 |title=Actuarial Society of India 
 |accessdate=2007-08-31 
 |ref={{harvid|ASI|2006}} 
 |archiveurl=https://web.archive.org/web/20070823222851/http://www.actuariesindia.org/index.html 
 |archivedate=August 23, 2007 
 |deadurl=no 
 |df= 
}}
&lt;!-- B --&gt;
&lt;!-- C --&gt;
*{{cite web
 |url=http://www.casact.org/admissions/syllabus/summary.pdf
 |title=2011 CAS Basic Education Summary
 |accessdate=2011-01-19
 |year=2011
 |work=Syllabus of Basic Education
 |publisher=[[Casualty Actuarial Society]]
 |format=PDF
 |ref={{harvid|CAS|2011a}}
}}
*{{cite web
 |year=2011
 |url=http://www.casact.org/admissions/syllabus/
 |title=2011 Syllabus of Basic Education
 |publisher=[[Casualty Actuarial Society]]
 |accessdate=August 14, 2011
 |ref={{harvid|CAS|2011b}}
}}
*{{cite web
 |date=October 2004
 |url=http://www.actuaries.ca/membership/enrollment_e.cfm
 |title=Membership &amp; Education: Canadian Enrollment Information
 |publisher=[[Canadian Institute of Actuaries]]
 |accessdate=2006-06-11
 |ref={{harvid|CIA|2004}}
}}
&lt;!-- D --&gt;
*{{cite web
 |url          = http://aktuar.de/dav/ausbildung/inhalte_der_ausbildung/
 |title        = Inhalte der Ausbildung zum/zur Aktuar/in DAV
 |trans-title  = Content of training to/for actuary/in DAV
 |accessdate   = February 27, 2012
 |year         = 2011
 |publisher    = [[German Actuarial Society]]
 |language     = De
 |ref          = {{harvid|DAV|2011}}
 |archive-url  = https://archive.is/20130210054122/http://aktuar.de/dav/ausbildung/inhalte_der_ausbildung/
 |archive-date = 2013-02-10
 |dead-url     = yes
 |df           = 
}}
&lt;!-- E --&gt;
&lt;!-- F --&gt;
&lt;!-- G --&gt;
&lt;!-- H --&gt;
*{{cite journal
 |last1=Haastrup
 |first1=Svend
 |last2=Jens Perch
 |first2=Nielsen
 |year=2007
 |title=The historical perspective of the Danish actuarial profession
 |ref={{harvid|Haastrup|Nielsen|2007}}
}}
&lt;!-- I --&gt;
*{{cite web
 |url=http://www.actuaries.asn.au/Education 
 |title=Education 
 |accessdate=2007-05-01 
 |year=2006 
 |publisher=[[Institute of Actuaries of Australia]] 
 |ref={{harvid|IAA-Ed|2006}} 
 |archiveurl=https://web.archive.org/web/20070208165244/http://www.actuaries.asn.au/Education 
 |archivedate=February 8, 2007 
 |deadurl=no 
 |df= 
}}
*{{cite web
 |url=http://www.actuaries.asn.au/Education/Courses/PartOne 
 |title=Part I 
 |accessdate=2007-05-01 
 |year=2006 
 |work=Courses 
 |publisher=[[Institute of Actuaries of Australia]] 
 |ref={{harvid|IAA-Part I|2006}} 
 |archiveurl=https://web.archive.org/web/20070420194909/http://www.actuaries.asn.au/Education/Courses/PartOne 
 |archivedate=April 20, 2007 
 |deadurl=no 
 |df= 
}}
*{{cite web
 |url=http://www.actuaries.asn.au/Education/Courses/PartTwo 
 |title=Part II (Actuarial Control Cycle) 
 |accessdate=2007-05-01 
 |year=2006 
 |work=Courses 
 |publisher=[[Institute of Actuaries of Australia]] 
 |ref={{harvid|IAA-Part II|2006}} 
 |archiveurl=https://web.archive.org/web/20070315071810/http://www.actuaries.asn.au/Education/Courses/PartTwo 
 |archivedate=March 15, 2007 
 |deadurl=no 
 |df= 
}}
*{{cite web
 |url=http://www.actuaries.asn.au/Education/Courses/PartThree 
 |title=Part III 
 |accessdate=2007-05-01 
 |year=2006 
 |work=Courses 
 |publisher=[[Institute of Actuaries of Australia]] 
 |ref={{harvid|IAA-Part III|2006}} 
 |archiveurl=https://web.archive.org/web/20070403154713/http://www.actuaries.asn.au/Education/Courses/PartThree 
 |archivedate=April 3, 2007 
 |deadurl=no 
 |df= 
}}
*{{cite web
 |year=2011
 |url=http://www.actuaries.org.uk/students/pages/how-register-student
 |title=How to register as a student
 |work=Student
 |publisher=[[Institute and Faculty of Actuaries]]
 |accessdate=February 27, 2012
 |ref={{harvid|Institute and Faculty of Actuaries|2011a}}
}}
&lt;!-- J --&gt;
&lt;!-- K --&gt;
&lt;!-- L --&gt;
&lt;!-- M --&gt;
&lt;!-- N --&gt;
*{{cite conference
 |first=Ragnar
 |last=Norberg
 |year=1990
 |title=Actuarial Statistics&amp;nbsp;— The European Perspective
 |booktitle=International Conference on the Teaching of Statistics 3, Dunedin, New Zealand
 |publisher=International Association for Statistical Education
 |location=Auckland, New Zealand
 |pages=405–410
 |url=http://www.stat.auckland.ac.nz/~iase/publications/18/BOOK2/B7-2.pdf
 |format=PDF
 |accessdate=February 27, 2012
 |ref=harv
}}
*{{cite web
 |url          = http://www.aktfor.no/organisasjon_english.html
 |title        = Norwegian Society of Actuaries
 |accessdate   = 2011-03-04
 |year         = 2011
 |publisher    = [[Norwegian Society of Actuaries]]
 |ref          = {{harvid||Norwegian Society of Actuaries|2011}}
 |archive-url  = https://web.archive.org/web/20110724174123/http://www.aktfor.no/organisasjon_english.html
 |archive-date = 2011-07-24
 |dead-url     = yes
 |df           = 
}}
&lt;!-- O --&gt;
&lt;!-- P --&gt;
&lt;!-- Q --&gt;
&lt;!-- R --&gt;
&lt;!-- S --&gt;
*{{cite web
 |url=http://www.soa.org/education/exam-req/edu-asa-req.aspx
 |title=Associate of the Society of Actuaries (ASA)–Requirements
 |accessdate=February 27, 2012
 |year=2012
 |work=Education
 |publisher=[[Society of Actuaries]]
 |ref={{harvid|SOA|2012a}}
}}
*{{cite web
 |url=http://www.soa.org/education/exam-req/edu-cera-req.aspx
 |title=Chartered Enterprise Risk Analyst (CERA)–Requirements
 |accessdate=February 27, 2012
 |year=2012
 |work=Education
 |publisher=[[Society of Actuaries]]
 |ref={{harvid|SOA|2012b}}
}}
*{{cite web
 |url=http://www.soa.org/education/exam-req/edu-fsa-req.aspx
 |title=Fellow of the Society of Actuaries (FSA)–Requirements
 |accessdate=February 27, 2012
 |year=2012
 |work=Education
 |publisher=[[Society of Actuaries]]
 |ref={{harvid|SOA|2012c}}
}}
*{{cite web
 |url          = http://www.math.su.se/utbildning/vara-utbildningar/utbildningsprogram/program-pa-avancerad-niva/masterprogram-i-forsakringsmatematik-1.70941
 |title        = Aktuarieprogrammet
 |accessdate   = 2006-09-10
 |year         = 2006
 |publisher    = [[Stockholm University]]
 |language     = sv
 |ref          = {{harvid||Stockholm University|2006}}
 |archive-url  = https://web.archive.org/web/20120618125722/http://www.math.su.se/utbildning/vara-utbildningar/utbildningsprogram/program-pa-avancerad-niva/masterprogram-i-forsakringsmatematik-1.70941
 |archive-date = 2012-06-18
 |dead-url     = yes
 |df           = 
}}
&lt;!-- T --&gt;
&lt;!-- U --&gt;
*{{cite web
 |url=http://www.mi.uib.no/adm/grupper/aktuar/aktuar.html
 |title=Aktuarstudiet
 |accessdate=2011-03-04
 |year=2011
 |publisher=[[University of Bergen]]
 |language=Norwegian
 |ref={{harvid||University of Bergen|2011}}
}}
&lt;!-- V --&gt;
&lt;!-- W --&gt;
{{refend}}
{{reflist}}

== External links ==
*[http://www.soa.org/ Society of Actuaries website]
*[http://www.casact.org/ Casualty Actuarial Society website]
*[http://www.actuaries.org.uk/ Faculty and Institute of Actuaries]
*[http://www.beanactuary.org Actuarial Exam information for students]
*[http://www.actuaries.org International Actuarial Association]
*[http://www.acted.co.uk ActEd website]

[[Category:Actuarial science]]
[[Category:Mathematical science occupations]]
[[Category:Professional titles and certifications]]</text>
      <sha1>s0486fhwh8ytzs7dbfl8byx1s9dtggi</sha1>
    </revision>
  </page>
  <page>
    <title>Annual growth rate</title>
    <ns>0</ns>
    <id>35320528</id>
    <revision>
      <id>869819709</id>
      <parentid>869819702</parentid>
      <timestamp>2018-11-20T16:01:30Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/2409:4055:692:6FAD:F336:2A7E:3B54:77FC|2409:4055:692:6FAD:F336:2A7E:3B54:77FC]] to version by Magic links bot. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3543973) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3527">{{refimprove|date=September 2015}}

'''Annual growth rate''' (AGR) is the change in the value of a measurement over the period of a year.

==Economics==

Annual growth rate is a useful tool to identify trends in investments. According to a survey of nearly 200 senior marketing managers conducted by The Marketing Accountability Standards Board, 69% of subjects responded that they consider average annual growth rate to be a useful measurement.&lt;ref name="Marketing_Metrics"&gt;Farris, Paul W.; Neil T. Bendle; Phillip E. Pfeifer; David J. Reibstein (2010). ''Marketing Metrics: The Definitive Guide to Measuring Marketing Performance.'' Upper Saddle River, New Jersey: Pearson Education, Inc. {{ISBN|0137058292}}. The [[Marketing Accountability Standards Board (MASB)]] endorses the definitions, purposes, and constructs of classes of measures that appear in ''Marketing Metrics'' as part of its ongoing [http://www.commonlanguage.wikispaces.net/ Common Language in Marketing Project].&lt;/ref&gt; The formula used to calculate annual growth rate uses the previous year as a base. Over longer periods of time, [[compound annual growth rate|compound annual growth rate (CAGR)]] is generally an acceptable metric for average growth rates.

=== Measure of success ===

Perceptions of the success or failure of many enterprises and businesses are based on assessments of their growth. Measurements of year-on-year growth, however, are complicated by two simple factors:

* ''Changes over time in the base from which growth is measured''. Such changes might include increases in the number of stores, markets, or salespeople. This issue is addressed by using 'same store' measures (or corollary measures for markets, sales personnel and so on).
* ''Compounding growth over multiple periods''. For example, if a company achieves 30% growth in one year, but its results remain unchanged over the two subsequent years, this would not be the same as 10% growth in each of three years. [[CAGR]], the compound annual growth rate, addresses this issue.&lt;ref name=Marketing_Metrics /&gt;

=== Calculations ===
{{main|Relative change and difference}}
"Percentage growth is the central plank of year-on-year analysis. Dividing the results for the current period by the results for the prior period will yield a comparative figure. Subtracting one from the other will highlight the increase or decrease between periods. When evaluating the comparatives, one might say that results in Year 2 were, for example, 110% of those in Year 1. To convert this figure to a growth rate, one need only subtract 100%. The periods considered are often years, but any time-frame can be chosen."&lt;ref name=Marketing_Metrics /&gt;

The first step of this process is to identify the value of the investment at the beginning and end of the year. The next step is to subtract the beginning value from the end value. Dividing the difference by the beginning value, and then multiplying the answer by 100 converts it to a percentage.&lt;ref&gt;{{Cite web|title = Calculating Growth Rates|url = http://pages.uoregon.edu/rgp/PPPM613/class8a.htm|website = pages.uoregon.edu|accessdate = 2015-09-08}}&lt;/ref&gt;

== Notes and references ==
{{reflist}}

'''Works cited'''
* {{dual|source=''Marketing Metrics: The Definitive Guide to Measuring Marketing Performance'' by Farris, Bendle, Pfeifer and Reibstein|sourcepath={{google books |plainurl=y |id=7Ptw4nBoGmkC}}|date=12/20/2011}}

{{DEFAULTSORT:Annual growth}}
[[Category:Economic growth]]
[[Category:Actuarial science]]
[[Category:Investment]]</text>
      <sha1>73zq7apcjnu2arj0fm42mltkxpautxd</sha1>
    </revision>
  </page>
  <page>
    <title>Anticommutativity</title>
    <ns>0</ns>
    <id>294358</id>
    <revision>
      <id>837239474</id>
      <parentid>837121814</parentid>
      <timestamp>2018-04-19T15:48:18Z</timestamp>
      <contributor>
        <username>Purgy Purgatorio</username>
        <id>22035051</id>
      </contributor>
      <comment>Undid revision 837121814 by [[Special:Contributions/Chkno|Chkno]] ([[User talk:Chkno|talk]]) relations are no operations, distinct topics</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5744">In mathematics, '''anticommutativity''' is a specific property of some non-[[commutative]] [[Operation (mathematics)|operations]]. In [[mathematical physics]], where [[symmetry (physics)|symmetry]] is of central importance, these operations are mostly called '''antisymmetric operations''', and are extended in an [[associative]] setting to cover more than two [[Argument of a function|arguments]]. Swapping the position of two arguments of an antisymmetric operation yields a result, which is the ''inverse'' of the result with unswapped arguments. The notion ''[[inverse element|inverse]]'' refers to a [[group (mathematics)|group structure]] on the operation's [[codomain]], possibly with another operation, such as [[addition]].

A prominent example of an anticommutative operation is the  [[Lie algebra|Lie bracket]].

== Definition ==
An &lt;math&gt;n&lt;/math&gt;[[Arity|-ary]] [[Operation_(mathematics)#General_definition|operation]] is antisymmetric if swapping the order of any two arguments [[inverse element|negates]] the result. For example, a [[binary operation]] "∗" is anti-commutative (with respect to addition) if for all ''x'' and ''y'', 

:{{nowrap|1=''x'' ∗ ''y'' = −(''y'' ∗ ''x'')}}.

More formally, a [[Map (mathematics)|map]] &lt;math&gt; *\; :A^n \to A &lt;/math&gt; from the [[Cartesian product#Cartesian_square_and_n-ary_product|set of all ''n''-tuples]] of elements in a [[Set (mathematics)|set]] ''A'' (where ''n'' is a non-negative integer) to a [[Group (mathematics)|group]] &lt;math&gt; \mathfrak{G} = (A,+,0) &lt;/math&gt; is anticommutative with respect to the group operation "+" [[iff|if and only if]]
:&lt;math&gt; *(x_1,x_2, \dots x_n) = \sgn_{\sigma}( * (x_{\sigma(1)},x_{\sigma(2)},\dots x_{\sigma(n)})) \qquad \forall \; (x_1,x_2,\dots,x_n) \in A^n,&lt;/math&gt;

where &lt;math&gt; (\sigma(1), \dots \sigma(n)) &lt;/math&gt; is the result of permuting &lt;math&gt;(1,2, \dots n)&lt;/math&gt; with  the [[permutation]] &lt;math&gt;\sigma,&lt;/math&gt; and &lt;math&gt;\operatorname{sgn}_{\sigma}&lt;/math&gt; is the identity map for even permutations &lt;math&gt;\sigma&lt;/math&gt; and maps each element of ''A'' to its inverse for odd permutations &lt;math&gt;\sigma&lt;/math&gt;. In an associative setting it is convenient to denote this with a binary operation "∗":

:&lt;math&gt; x_1*x_2*\dots*x_n = \sgn_{\sigma} (x_{\sigma(1)}*x_{\sigma(2)}*\dots* x_{\sigma(n)}).&lt;/math&gt;

This [[equality (mathematics)|equality]] expresses the following concept:
* the value of the operation on some fixed [[Tuple#Formal_definitions|ordered n-tuple]] is unchanged when applying any [[Even and odd permutations|even permutation]] to the arguments, and
* the value of the operation is the [[Group_(mathematics)#Definition|additive inverse]] of this value, whenever an [[Even and odd permutations|odd permutation]] is applied to the arguments. The need for the existence of this [[Group_(mathematics)#Definition|additive inverse element]] is the main reason for requiring the [[codomain]] &lt;math&gt;\mathfrak{G} &lt;/math&gt; of the [[operation (mathematics)|operation]] "∗" to be at least a [[Group (mathematics)|group]].

Particularly important is the case {{nowrap|1=''n'' = 2}}. A [[binary operation]] &lt;math&gt; *:A\times A\to \mathfrak{G} &lt;/math&gt; is anticommutative [[iff|if and only if]] 

:&lt;math&gt; x_1 * x_2 = -(x_2 * x_1) \qquad\forall(x_1,x_2)\in A\times A&lt;/math&gt;

This means that {{nowrap|1=''x''&lt;sub&gt;1&lt;/sub&gt; ∗ ''x''&lt;sub&gt;2&lt;/sub&gt;}} is the [[Inverse element|additive inverse]] of the element {{nowrap|1=''x''&lt;sub&gt;2&lt;/sub&gt; ∗ ''x''&lt;sub&gt;1&lt;/sub&gt;}} in &lt;math&gt;\mathfrak{G} &lt;/math&gt;.

In the most frequent cases in physics, where &lt;math&gt;A&lt;/math&gt; carries already a [[field (mathematics)|field structure]], the fact

:&lt;math&gt; x * x = -(x * x) \qquad\forall x\in A&lt;/math&gt;

implies that applying an anticommutative operation to any collection of operands yields zero, if any two operands are equal (provided the [[characteristic (algebra)|characteristic]] of the field is not &lt;math&gt;2&lt;/math&gt;). That is

:&lt;math&gt;x_1* \dots *y* \dots *y* \dots *x_{n-2} = 0.&lt;/math&gt;

== Properties ==
If the group &lt;math&gt; \scriptstyle\mathfrak{G} &lt;/math&gt; is such that

:&lt;math&gt; \mathfrak{-a} = \mathfrak{a} \iff \mathfrak{a} = \mathfrak{0}\qquad \forall \mathfrak{a} \in \mathfrak{G} &lt;/math&gt;

i.e. ''the only element equal to its [[Inverse element|inverse]] is the [[neutral element]]'', then for all the [[Tuple#Formal_definitions|ordered tuple]]s such that &lt;math&gt; x_j = x_i &lt;/math&gt; for at least two different index &lt;math&gt;i,j&lt;/math&gt;

:&lt;math&gt;x_1*x_2*\dots*x_n = \mathfrak{0} &lt;/math&gt;

In the case ''&lt;math&gt; n = 2 &lt;/math&gt;'' this means

:&lt;math&gt; x_1*x_1 = x_2*x_2 = \mathfrak{0} &lt;/math&gt;

== Examples ==

Examples of anticommutative binary operations include:
* [[Subtraction]]
* [[Cross product]]
* Lie bracket of a [[Lie algebra]]
* Lie bracket of a [[Lie ring]]

See also: [[graded-commutative ring]]

==See also== 
* [[Commutativity]]
* [[Commutator]]
* [[Exterior algebra]]
* [[Operation (mathematics)]]
* [[Symmetry in mathematics]]
* [[Particle statistics]] (for anticommutativity in physics).

== References ==
*{{Citation
 | last = Bourbaki
 | first = Nicolas
 | author-link = Nicolas Bourbaki
 | title = Algebra. Chapters 1–3
 | place = [[Berlin]]-[[Heidelberg]]-[[New York City]]
 | publisher = [[Springer-Verlag]]
 | chapter = Chapter III. [[Tensor algebra]]s, [[exterior algebra]]s, [[symmetric algebra]]s
 | series = Elements of Mathematics
 | year = 1989
 | pages = xxiii+709
 | edition = 2nd printing
 | isbn = 3-540-64243-9
 | mr = 0979982
 | zbl = 0904.00001
}}. 

== External links ==
{{Wiktionary}}
*{{springer
| title= Anti-commutative algebra
| id= A/a012580
| last= Gainov
| first= A.T.
| author-link= 
}}
*{{MathWorld 
|title=Anticommutative 
|urlname=Anticommutative}} 

[[Category:Abstract algebra]]
[[Category:Binary operations|*Anticommutativity]]</text>
      <sha1>ort0ean0h2ha7xnfscig6mkdnzh5riv</sha1>
    </revision>
  </page>
  <page>
    <title>Bloch's principle</title>
    <ns>0</ns>
    <id>34529648</id>
    <revision>
      <id>848630898</id>
      <parentid>848621632</parentid>
      <timestamp>2018-07-03T06:34:08Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Cite needed}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2762">'''Bloch's Principle''' is a [[philosophy|philosophical]] principle in [[mathematics]]
stated by [[André Bloch (mathematician)|André Bloch]].&lt;ref&gt;{{cite news|first=A.|last=Bloch|
title=La conception actuelle de la theorie de fonctions entieres et meromorphes|journal=Enseignement math.|year=1926| volume=25|pages=83–103}}&lt;/ref&gt;

Bloch states the principle in Latin as: ''Nihil est in infinito quod non prius fuerit in finito,'' and explains this as follows:  Every proposition in whose statement the [[actual infinity]] occurs can be always considered a consequence, almost immediate, of a proposition where it does not occur, a proposition in ''finite terms''.

Bloch mainly applied this principle to the theory of [[function (mathematics)|functions]] of a [[complex variable]].  Thus, for example, according to this principle, [[Picard's theorem]] corresponds to [[Schottky's theorem]], and [[Bloch's theorem (complex variables)|Valiron's theorem]] corresponds to [[Bloch's theorem (complex variables)|Bloch's theorem]].

Based on his Principle, Bloch was able to predict or conjecture several
important results such as the [[Ahlfors theory|Ahlfors's Five Islands theorem]],
[[Henri cartan|Cartan]]'s theorem on holomorphic curves omitting hyperplanes,&lt;ref&gt;{{cite book|ref="la"|first=S.|last=Lang|
title=Introduction to complex hyperbolic spaces|publisher=[[Springer Verlag]]|year=1987}}&lt;/ref&gt; [[Walter Hayman|Hayman]]'s result that an exceptional set of radii is unavoidable in [[Nevanlinna theory]].

In the more recent times several general theorems were proved which can be regarded as rigorous statements in the spirit of the Bloch Principle.{{cite needed|date=July 2018}}

==Zalcman's lemma==

Let &lt;math&gt;\{f_n\}&lt;/math&gt; be a sequence of meromorphic functions in a region ''D'', which is not a [[normal family]].
Then there exist a sequence of points &lt;math&gt;z_n &lt;/math&gt; in ''D'' and positive numbers &lt;math&gt;\rho_n &lt;/math&gt; with &lt;math&gt;\lim_{n\rightarrow\infty}\rho_{n}=0&lt;/math&gt; such that

: &lt;math&gt;f_n(z_n+\rho_nz)\to f, &lt;/math&gt;

where ''f'' is a non-constant meromorphic function in the complex plane.&lt;ref&gt;{{cite paper|first=L.|last=Zalcman|
title=Heuristic principle in complex function theory|journal=Amer. Math. Monthly|
volume=82|year=1975|pages=813–817}}&lt;/ref&gt;

==Brody's lemma==

Let ''X'' be a [[compact space|compact]] [[complex analytic manifold]], such that every [[holomorphic map]] from the [[complex plane]]
to ''X'' is constant. Then there exists a [[metric (mathematics)|metric]] on ''X'' such that every holomorphic map from the unit disc with the [[Poincaré metric]] to ''X'' does not increase distances.&lt;ref&gt;Lang (1987).&lt;/ref&gt;

==References==

&lt;references /&gt;

[[Category:Mathematical principles]]
[[Category:Philosophy of mathematics]]</text>
      <sha1>s3j1znfkbop95pogveq67dhn1u69ttz</sha1>
    </revision>
  </page>
  <page>
    <title>Chern Prize (ICCM)</title>
    <ns>0</ns>
    <id>39614877</id>
    <revision>
      <id>840587342</id>
      <parentid>793828537</parentid>
      <timestamp>2018-05-10T20:36:54Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>/* top */[[User:PrimeBOT/24|Task 24]] - replace template usage following [[Wikipedia:Templates for discussion/Log/2018 February 19|a TFD]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2729">{{distinguish|text=the [[Chern Medal]] established by the International Mathematical Union in 2010}}
The '''Chern Prize in Mathematics''' was established in 2001 in honor of Professor [[Shiing-Shen Chern]].&lt;ref name="iccm"&gt;{{cite book|title=Fifth International Congress of Chinese Mathematicians|year=2010|publisher=American Mathematical Society and International Press|isbn=9780821875551|page=xiii-xiix|editor1=Lizhen Ji |editor2=Yat Sun Poon |editor3=Lo Yang |editor4=Shing-Tung Yau }}&lt;/ref&gt; The Chern Prize is presented every three years at the [[International Congress of Chinese Mathematicians]] to Chinese mathematicians and those of Chinese descent for "exceptional contributions to mathematical research or to public service activities in support of mathematics".&lt;ref name="iccm" /&gt; Winners are selected by a committee of mathematicians to recognize the achievements of mathematicians of Chinese descent.&lt;ref name=fourth&gt;{{cite web|title=Background|url=http://www.cms.zju.edu.cn/iccm2007/|website=Fourth International Congress of Chinese Mathematicians|accessdate=31 January 2015|deadurl=yes|archiveurl=https://web.archive.org/web/20150310090941/http://www.cms.zju.edu.cn/iccm2007/|archivedate=10 March 2015|df=}}&lt;/ref&gt; In 2010, a special commemorative event was held in Beijing in addition to the normal award presentation to celebrate the centennial of Professor Chern's birth.&lt;ref name=cas&gt;{{cite web|title=The Fifth International Congress of Chinese Mathematicians Held in Beijing|url=http://english.amss.cas.cn/ns/es/201012/t20101224_63558.html|website=Chinese Academy of Sciences|accessdate=31 January 2015|date=24 December 2010}}&lt;/ref&gt;

== Past winners ==
{| class="wikitable sortable" style="margin: 1ex auto 1ex auto"
|-
! Year
! class="unsortable" | Medalists
! class="unsortable" | Institution
|-
| 2001 ||[[Song-Sun Lin]]&lt;br /&gt;[[Jiu-Kang Yu]]||[[National Chiao Tung University|Chiao Tung University]]&lt;br /&gt;[[Purdue University]]
|-
| 2004 ||[[Fanghua Lin]]&lt;br /&gt;[[Lo Yang]]||[[New York University]]&lt;br /&gt;[[Chinese Academy of Sciences]]
|-
| 2007 ||[[Shiu-Yuen Cheng]]&lt;br /&gt;[[Mu-Tao Wang]]||[[Hong Kong University of Science and Technology]]&lt;br /&gt;[[Columbia University]]
|-
| 2010 ||[[Jiaxing Hong]]&lt;br /&gt;[[Conan Nai-Chung Leung]]&lt;br /&gt;[[Winnie Li]]||[[Fudan University]]&lt;br /&gt;[[Chinese University of Hong Kong]]&lt;br /&gt;[[National Center of Theoretical Sciences (Taiwan)]]
|-
| 2013 ||[[Bong Lian]]&lt;br /&gt;[[Lee_Si-Chen|Si-Chen Lee]]||[[Brandeis University]]&lt;br /&gt;[[National Taiwan University]]
|-
| 2016 ||[[Ronnie Chan]]&lt;br /&gt;[[Xiping Zhu]]||Morningside Group &lt;br /&gt;[[Sun Yat-sen University]]
|}

== See also ==
*[[Morningside Medal]]

== References ==
{{reflist}}

[[Category:Mathematics awards]]


{{math-stub}}</text>
      <sha1>mkgm5z0rhrltcc16ih63wsloevpecus</sha1>
    </revision>
  </page>
  <page>
    <title>Coupon collector's problem</title>
    <ns>0</ns>
    <id>14721784</id>
    <revision>
      <id>870195807</id>
      <parentid>868844608</parentid>
      <timestamp>2018-11-23T03:28:07Z</timestamp>
      <contributor>
        <username>AxelBoldt</username>
        <id>2</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9484">[[File:Coupon collector problem.svg|thumb|400px|Graph of number of coupons, ''n'' vs the expected number of tries (i.e., time) needed to collect them all, ''E'' (''T'' )]]
In [[probability theory]], the '''coupon collector's problem''' describes the "collect all coupons and win" contests. It asks the following question: Each box of a brand of cereals contains a coupon, and there are ''n'' different types of coupons, what is the probability that more than ''t'' boxes need to be bought to collect all ''n'' coupons? An alternative statement is: Given ''n'' coupons, how many coupons do you expect you need to draw with replacement before having drawn each coupon at least once? The mathematical analysis of the problem reveals that the [[expected value|expected number]] of trials needed grows as &lt;math&gt;\Theta(n\log(n))&lt;/math&gt;.&lt;ref&gt;Here and throughout this article, "log" refers to the [[natural logarithm]] rather than a logarithm to some other base. The use of Θ here invokes [[big O notation]].&lt;/ref&gt; For example, when ''n''&amp;nbsp;=&amp;nbsp;50 it takes about 225&lt;ref&gt;E(50) = 50(1 + 1/2 + 1/3 + ... + 1/50) = 224.9603, the expected number of trials to collect all 50 coupons. The approximation &lt;math&gt;n\log n+\gamma n+1/2&lt;/math&gt; for this expected number gives in this case &lt;math&gt;50\log 50+50\gamma+1/2 \approx 195.6011+28.8608+0.5\approx 224.9619&lt;/math&gt;.&lt;/ref&gt; trials on average to collect all 50 coupons.

==Solution==

===Calculating the expectation===
Let ''T'' be the time to collect all ''n'' coupons, and let ''t&lt;sub&gt;i&lt;/sub&gt;'' be the time to collect the ''i''-th coupon after ''i''&amp;nbsp;−&amp;nbsp;1 coupons have been collected. Think of ''T'' and ''t&lt;sub&gt;i&lt;/sub&gt;'' as [[random variable]]s. Observe that the probability of collecting a {{em|new}} coupon is ''p&lt;sub&gt;i&lt;/sub&gt;'' = (''n''&amp;nbsp;−&amp;nbsp;(''i''&amp;nbsp;−&amp;nbsp;1))/''n''. Therefore, ''t&lt;sub&gt;i&lt;/sub&gt;'' has [[geometric distribution]] with expectation 1/''p&lt;sub&gt;i&lt;/sub&gt;''. By the [[Expected value#Linearity|linearity of expectations]] we have:

:&lt;math&gt;
\begin{align}
\operatorname{E}(T) &amp;= \operatorname{E}(t_1) + \operatorname{E}(t_2) + \cdots + \operatorname{E}(t_n)
= \frac{1}{p_1} + \frac{1}{p_2} +  \cdots + \frac{1}{p_n} \\
&amp;= \frac{n}{n} + \frac{n}{n-1} +  \cdots + \frac{n}{1} \\
&amp;= n \cdot \left(\frac{1}{1} + \frac{1}{2} + \cdots + \frac{1}{n}\right) \\
&amp;= n \cdot H_n.
\end{align}
&lt;/math&gt;

Here ''H&lt;sub&gt;n&lt;/sub&gt;'' is the ''n''-th [[harmonic number]]. Using the [[asymptotics]] of the harmonic numbers, we obtain:

:&lt;math&gt;
\operatorname{E}(T)  = n \cdot H_n = n \log n + \gamma n + \frac{1}{2} + O(1/n),
&lt;/math&gt;
where &lt;math&gt;\gamma \approx 0.5772156649&lt;/math&gt; is the [[Euler–Mascheroni constant]].

Now one can use the [[Markov inequality]] to bound the desired probability:

:&lt;math&gt;\operatorname{P}(T \geq cn H_n) \le \frac{1}{c}.&lt;/math&gt;

===Calculating the variance===
Using the independence of random variables ''t&lt;sub&gt;i&lt;/sub&gt;'', we obtain:

:&lt;math&gt;
\begin{align}
\operatorname{Var}(T)&amp; = \operatorname{Var}(t_1) + \operatorname{Var}(t_2) + \cdots + \operatorname{Var}(t_n) \\
&amp;= \frac{1-p_1}{p_1^2} + \frac{1-p_2}{p_2^2} +  \cdots + \frac{1-p_n}{p_n^2} \\
&amp;&lt; \left(\frac{n^2}{n^2} + \frac{n^2}{(n-1)^2} +  \cdots + \frac{n^2}{1^2}\right) \\
&amp;= n^2 \cdot \left(\frac{1}{1^2} + \frac{1}{2^2} + \cdots + \frac{1}{n^2} \right) \\
&amp;&lt; \frac{\pi^2}{6} n^2
\end{align}
&lt;/math&gt;

since &lt;math&gt;\frac{\pi^2}6=\frac{1}{1^2}+\frac{1}{2^2}+\cdots+\frac{1}{n^2}+\cdots&lt;/math&gt; (see [[Basel problem]]).

Now one can use the [[Chebyshev inequality]] to bound the desired probability:

:&lt;math&gt;\operatorname{P}\left(|T- n H_n| \geq cn\right) \le \frac{\pi^2}{6c^2}.&lt;/math&gt;

===Tail estimates===

A different upper bound can be derived from the following observation. Let &lt;math&gt;{Z}_i^r&lt;/math&gt; denote the event that the &lt;math&gt;i&lt;/math&gt;-th coupon was not picked in the first &lt;math&gt;r&lt;/math&gt; trials. Then:
:&lt;math&gt;
\begin{align}
P\left [ {Z}_i^r \right ] = \left(1-\frac{1}{n}\right)^r \le e^{-r / n}
\end{align}
&lt;/math&gt;

Thus, for &lt;math&gt;r = \beta n \log n&lt;/math&gt;, we have &lt;math&gt;P\left [ {Z}_i^r \right ] \le e^{(-\beta n \log n ) / n} = n^{-\beta}&lt;/math&gt;.
:&lt;math&gt;
\begin{align}
P\left [ T &gt; \beta n \log n \right ] = P \left [ 	\bigcup_i {Z}_i^{\beta n \log n} \right ] \le n \cdot P [ {Z}_1^{\beta n \log n} ] \le n^{-\beta + 1}
\end{align}
&lt;/math&gt;

==Extensions and generalizations==
* [[Pierre-Simon Laplace]], but also [[Paul Erdős]] and [[Alfréd Rényi]], proved the limit theorem for the distribution of ''T''. This result is a further extension of previous bounds.

::&lt;math&gt;
\operatorname{P}(T &lt; n\log n + cn) \to e^{-e^{-c}}, \ \  \text{as}  \ n \to \infty.
&lt;/math&gt;

* [[Donald J. Newman]] and [[Lawrence Shepp]] found a generalization of the coupon collector's problem when ''m'' copies of each coupon need to be collected. Let ''T&lt;sub&gt;m&lt;/sub&gt;'' be the first time ''m'' copies of each coupon are collected. They showed that the expectation in this case satisfies:

::&lt;math&gt;
\operatorname{E}(T_m) =  n \log n + (m-1) n \log\log n + O(n), \ 
\text{as}  \ n \to \infty.
&lt;/math&gt;
:Here ''m'' is fixed.  When ''m'' = 1 we get the earlier formula for the expectation.

* Common generalization, also due to Erdős and Rényi:

::&lt;math&gt;
\operatorname{P}\bigl(T_m &lt; n\log n + (m-1) n \log\log n + cn\bigr) \to e^{-e^{-c}/(m-1)!}, \ \  \text{as}  \ n \to \infty.
&lt;/math&gt;

* In the general case of a nonuniform probability distribution, according to [[Philippe Flajolet]],&lt;ref name="Flajolet"&gt;{{citation |first=Philippe |last=Flajolet |first2=Danièle |last2=Gardy |first3=Loÿs |last3=Thimonier |url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.217.5965&amp;rep=rep1&amp;type=pdf |title=Birthday paradox, coupon collectors, caching algorithms and self-organizing search |journal=Discrete Applied Mathematics |volume=39 |issue=3 |year=1992 |pages=207–229 |doi=10.1016/0166-218x(92)90177-c}}&lt;/ref&gt;
::&lt;math&gt;
E(T)=\int_0^\infty \big(1-\prod_{i=1}^n(1-e^{-p_it})\big)dt.
&lt;/math&gt;

==See also==

* [[Watterson estimator]]
* [[Birthday problem]]

==Notes==
{{Reflist}}

==References==
*{{citation
 | last1 = Blom | first1 = Gunnar
 | last2 = Holst | first2 = Lars
 | last3 = Sandell | first3 = Dennis
 | contribution = 7.5 Coupon collecting I, 7.6 Coupon collecting II, and 15.4 Coupon collecting III
 | isbn = 0-387-94161-4
 | location = New York
 | mr = 1265713
 | pages = 85–87, 191
 | publisher = Springer-Verlag
 | title = Problems and Snapshots from the World of Probability
 | url = https://books.google.com/books?id=KCsSWFMq2u0C&amp;pg=PA85
 | year = 1994}}.
*{{citation
 | last = Dawkins | first = Brian
 | issue = 1
 | journal = The American Statistician
 | jstor = 2685247
 | pages = 76–82
 | title = Siobhan's problem: the coupon collector revisited
 | volume = 45
 | year = 1991
 | doi=10.2307/2685247}}.
*{{citation
 | last1 = Erdős | first1 = Paul | author1-link = Paul Erdős
 | last2 = Rényi | first2 = Alfréd | author2-link = Alfréd Rényi
 | journal = Magyar Tudományos Akadémia Matematikai Kutató Intézetének Közleményei
 | mr = 0150807
 | pages = 215–220
 | title = On a classical problem of probability theory
 | url = http://www.renyi.hu/~p_erdos/1961-09.pdf
 | volume = 6
 | year = 1961}}.
*{{citation
 | last1 = Laplace | first1 = Pierre-Simon | author1-link = Pierre-Simon Laplace
 | title = Théorie analytique des probabilités 
 | pages = 194-195
 | year = 1812}}.
*{{citation
 | last1 = Newman | first1 = Donald J. | author1-link = Donald J. Newman
 | last2 = Shepp | first2 = Lawrence | author2-link = Lawrence Shepp
 | doi = 10.2307/2308930
 | journal = [[American Mathematical Monthly]]
 | mr = 0120672
 | pages = 58–61
 | title = The double dixie cup problem
 | volume = 67
 | year = 1960}}
*{{citation
 | last1 = Flajolet | first1 = Philippe | author1-link = Philippe Flajolet
 | last2 = Gardy | first2 = Danièle
 | last3 = Thimonier | first3 = Loÿs
 | doi = 10.1016/0166-218X(92)90177-C
 | issue = 3
 | journal = Discrete Applied Mathematics
 | mr = 1189469
 | pages = 207–229
 | title = Birthday paradox, coupon collectors, caching algorithms and self-organizing search
 | url = http://algo.inria.fr/flajolet/Publications/alloc2.ps.gz
 | volume = 39
 | year = 1992}}.
*{{citation
 | last = Isaac | first = Richard
 | contribution = 8.4 The coupon collector's problem solved
 | isbn = 0-387-94415-X
 | location = New York
 | mr = 1329545
 | pages = 80–82
 | publisher = Springer-Verlag
 | series = [[Undergraduate Texts in Mathematics]]
 | title = The Pleasures of Probability
 | url = https://books.google.com/books?id=a_2vsIx4FQMC&amp;pg=PA80
 | year = 1995}}.
*{{citation
 | last1 = Motwani | first1 = Rajeev | author1-link = Rajeev Motwani
 | last2 = Raghavan | first2 = Prabhakar
 | contribution = 3.6. The Coupon Collector's Problem
 | location = Cambridge
 | mr = 1344451
 | pages = 57–63
 | publisher = Cambridge University Press
 | title = Randomized algorithms
 | url = https://books.google.com/books?id=QKVY4mDivBEC&amp;pg=PA57
 | year = 1995}}.

==External links==
* "[http://demonstrations.wolfram.com/CouponCollectorProblem/ Coupon Collector Problem]" by [[Ed Pegg, Jr.]], the [[Wolfram Demonstrations Project]]. Mathematica package.
* ''[http://www.math.rutgers.edu/~zeilberg/mamarim/mamarimhtml/coupon.html How Many Singles, Doubles, Triples, Etc., Should The Coupon Collector Expect?]'', a short note by [[Doron Zeilberger]].

[[Category:Articles containing proofs]]
[[Category:Gambling mathematics]]
[[Category:Probability theorems]]
[[Category:Probability problems]]</text>
      <sha1>j3gu0i7dhl3srz039acdauljzpjjfh4</sha1>
    </revision>
  </page>
  <page>
    <title>Dini's theorem</title>
    <ns>0</ns>
    <id>9177825</id>
    <revision>
      <id>777385710</id>
      <parentid>734144019</parentid>
      <timestamp>2017-04-26T21:31:06Z</timestamp>
      <contributor>
        <ip>128.255.249.134</ip>
      </contributor>
      <comment>/* Proof */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4503">In the [[Mathematics|mathematical]] field of [[Mathematical analysis|analysis]], '''Dini's theorem''' says that if a monotone sequence of continuous functions converges pointwise on a compact space and if the limit function is also continuous, then the convergence is uniform.&lt;ref&gt;{{harvnb|Edwards|1994|page=165}}. {{harvnb|Friedman|2007|page=199}}. {{harvnb|Graves|2009|page=121}}. {{harvnb|Thomson|Bruckner|Bruckner|2008|page=385}}.&lt;/ref&gt;
==Formal statement==
If ''X'' is a [[compact space|compact]] [[topological space]], and { ''f''&lt;sub&gt;''n''&lt;/sub&gt; } is a [[monotonically increasing]] [[sequence]] (meaning {{nowrap|''f''&lt;sub&gt;''n''&lt;/sub&gt;(''x'') ≤ ''f''&lt;sub&gt;''n''+1&lt;/sub&gt;(''x'')}} for all ''n'' and ''x'') of [[continuous function|continuous]] [[real-valued function]]s on ''X'' which converges [[pointwise convergence|pointwise]] to a continuous function ''f'',  then the convergence is [[uniform convergence|uniform]]. The same conclusion holds if { ''f''&lt;sub&gt;''n''&lt;/sub&gt; } is monotonically decreasing instead of increasing. The theorem is named after [[Ulisse Dini]].&lt;ref&gt;According to {{harvnb|Edwards|1994|page=165}}, "[This theorem] is called Dini's theorem because Ulisse Dini (1845–1918) presented the original version of it in his book on the theory of functions of a real variable, published in Pisa in 1878.".&lt;/ref&gt;

This is one of the few situations in mathematics where pointwise convergence implies uniform convergence; the key is the greater control implied by the monotonicity. Note also that the limit function must be continuous, since a uniform limit of continuous functions is necessarily continuous.
==Proof==
Let ε &gt; 0 be given.  For each ''n'', let ''g''&lt;sub&gt;''n''&lt;/sub&gt; = ''f'' &amp;minus; ''f''&lt;sub&gt;''n''&lt;/sub&gt;, and let ''E''&lt;sub&gt;''n''&lt;/sub&gt; be the set of those ''x'' ∈ ''X''  such that ''g''&lt;sub&gt;''n''&lt;/sub&gt;( ''x'' ) &lt; ε.  Each ''g''&lt;sub&gt;''n''&lt;/sub&gt; is continuous, and so each ''E''&lt;sub&gt;''n''&lt;/sub&gt; is open (because each ''E''&lt;sub&gt;''n''&lt;/sub&gt; is the [https://proofwiki.org/wiki/Continuous_Mapping_by_Open_Sets preimage] of an open set under ''g''&lt;sub&gt;''n''&lt;/sub&gt;, a nonnegative continuous function).  Since { ''f''&lt;sub&gt;''n''&lt;/sub&gt; } is monotonically increasing, { ''g''&lt;sub&gt;''n''&lt;/sub&gt; } is monotonically decreasing, it follows that the sequence ''E''&lt;sub&gt;''n''&lt;/sub&gt; is ascending.  Since ''f''&lt;sub&gt;''n''&lt;/sub&gt; converges pointwise to ''f'', it follows that the collection { ''E''&lt;sub&gt;''n''&lt;/sub&gt; } is an [[open cover]] of ''X''.  By compactness, there is a finite subcover, and since ''E''&lt;sub&gt;''n''&lt;/sub&gt; are ascending the largest of these is a cover too. Thus we obtain that there is some positive integer ''N'' such that ''E''&lt;sub&gt;''N''&lt;/sub&gt; = ''X''.  That is, if ''n'' &gt; ''N'' and ''x'' is a point in ''X'', then |''f''( ''x'' ) &amp;minus; ''f''&lt;sub&gt;''n''&lt;/sub&gt;( ''x'' )| &lt;  ε, as desired.

== Notes ==
{{reflist}}

== References ==

* [[Robert G. Bartle|Bartle, Robert G.]] and Sherbert Donald R.(2000) "Introduction to Real Analysis, Third Edition" Wiley. p 238. – Presents a proof using gauges. 
*{{Cite book
 | ref = harv
 | last = Edwards
 | first = Charles Henry
 | title = Advanced Calculus of Several Variables
 | publisher = Dover Publications
 | location = Mineola, New York
 | year = 1994
 | origyear = 1973
 | isbn = 978-0-486-68336-2
}}
*{{Cite book
 | ref = harv
 | last = Graves
 | first = Lawrence Murray
 | title = The theory of functions of real variables
 | publisher = Dover Publications
 | location = Mineola, New York
 | year = 2009
 | origyear = 1946
 | isbn = 978-0-486-47434-2
}}
*{{Cite book
 | ref = harv
 | last = Friedman
 | first = Avner
 | author-link = Avner Friedman
 | title = Advanced calculus
 | publisher = Dover Publications
 | location = Mineola, New York
 | year = 2007
 | origyear = 1971
 | isbn = 978-0-486-45795-6
}}
* [[Jürgen Jost|Jost, Jürgen]] (2005) ''Postmodern Analysis, Third Edition,'' Springer.  See Theorem 12.1 on page 157 for the monotone increasing case.
{{DEFAULTSORT:Dini's Theorem}}
* [[Walter Rudin|Rudin, Walter R.]] (1976) ''Principles of Mathematical Analysis, Third Edition,'' McGraw–Hill.  See Theorem 7.13 on page 150 for the monotone decreasing case.
* {{cite book|ref=harv|last1=Thomson|first1=Brian S.|last2=Bruckner|first2=Judith B.|last3=Bruckner|first3=Andrew M.|author3link=Andrew M. Bruckner|title=Elementary Real Analysis|year=2008|origyear=2001|publisher=ClassicalRealAnalysis.com|isbn=978-1-4348-4367-8}}

[[Category:Theorems in real analysis]]
[[Category:Articles containing proofs]]</text>
      <sha1>8atm4h7wnc6x9knktea724mdzm1r4sv</sha1>
    </revision>
  </page>
  <page>
    <title>Directed information</title>
    <ns>0</ns>
    <id>51619662</id>
    <revision>
      <id>855917319</id>
      <parentid>846302270</parentid>
      <timestamp>2018-08-21T18:02:56Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2914">{{Multiple issues|
{{Underlinked|date=September 2016}}
{{context|date=September 2016}}
}}
'''Directed information''', &lt;math&gt;I(X^n\to Y^n) &lt;/math&gt;, is a measure of [[information theory]] and it measures the amount of information that flows from the process  &lt;math&gt;X^n&lt;/math&gt; to &lt;math&gt;Y^n&lt;/math&gt;, where &lt;math&gt;X^n&lt;/math&gt; denotes the vector &lt;math&gt;X_1,X_2,...,X_n&lt;/math&gt; and &lt;math&gt;Y^n&lt;/math&gt; denotes &lt;math&gt;Y_1,Y_2,...,Y_n&lt;/math&gt;. The term "directed information" was coined by [[James Massey]] and is defined as
:&lt;math&gt;I(X^n\to Y^n) =\sum_{i=1}^n I(X^i;Y_i|Y^{i-1})&lt;/math&gt;,
where &lt;math&gt;I(X^i;Y_i|Y^{i-1})&lt;/math&gt; is the conditional [[mutual information]].

Note that if &lt;math&gt;n=1&lt;/math&gt;, directed information becomes mutual information &lt;math&gt;I(X; Y)&lt;/math&gt;. Directed information has many applications in problems where causality plays an important role such as capacity of channel with feedback,&lt;ref&gt;{{cite journal|last1=Massey|first1=James|title=Causality, Feedback And Directed Information|date=1990|issue=ISITA|url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.5688&amp;rep=rep1&amp;type=pdf}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Permuter|first1=Haim Henry|last2=Weissman|first2=Tsachy|last3=Goldsmith|first3=Andrea J.|title=Finite State Channels With Time-Invariant Deterministic Feedback|journal=IEEE Transactions on Information Theory|date=February 2009|volume=55|issue=2|pages=644–662|doi=10.1109/TIT.2008.2009849|arxiv=cs/0608070}}&lt;/ref&gt; capacity of discrete memoryless networks with feedback,&lt;ref&gt;{{cite journal|last1=Kramer|first1=G.|title=Capacity results for the discrete memoryless network|journal=IEEE Transactions on Information Theory|date=January 2003|volume=49|issue=1|pages=4–21|doi=10.1109/TIT.2002.806135}}&lt;/ref&gt; gambling with causal side information,&lt;ref&gt;{{cite journal|last1=Permuter|first1=Haim H.|last2=Kim|first2=Young-Han|last3=Weissman|first3=Tsachy|title=Interpretations of Directed Information in Portfolio Theory, Data Compression, and Hypothesis Testing|journal=IEEE Transactions on Information Theory|date=June 2011|volume=57|issue=6|pages=3248–3259|doi=10.1109/TIT.2011.2136270|arxiv=0912.4872}}&lt;/ref&gt; compression with causal side information,&lt;ref&gt;{{cite journal|last1=Simeone|first1=Osvaldo|last2=Permuter|first2=Haim Henri|title=Source Coding When the Side Information May Be Delayed|journal=IEEE Transactions on Information Theory|date=June 2013|volume=59|issue=6|pages=3607–3618|doi=10.1109/TIT.2013.2248192|arxiv=1109.1293}}&lt;/ref&gt;
and in real-time control communication settings.&lt;ref&gt;{{cite journal|last1=Charalambous|first1=Charalambos D.|last2=Stavrou|first2=Photios A.|title=Directed Information on Abstract Spaces: Properties and Variational Equalities|journal=IEEE Transactions on Information Theory|date=August 2016|volume=62|issue=11|pages=6019–6052|doi=10.1109/TIT.2016.2604846|arxiv=1302.3971}}&lt;/ref&gt;


==References==
{{Reflist}}

[[Category:Information theory]]</text>
      <sha1>qyeukyv4w6jkqz5cs0tpr0915syeyd4</sha1>
    </revision>
  </page>
  <page>
    <title>Discharging method (discrete mathematics)</title>
    <ns>0</ns>
    <id>8714937</id>
    <revision>
      <id>609940393</id>
      <parentid>513016902</parentid>
      <timestamp>2014-05-24T13:10:06Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <minor/>
      <comment>/* References */Added 2 dois to journal cites using [[Project:AWB|AWB]] (10213)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5805">The '''discharging method''' is a technique used to prove [[Lemma (mathematics)|lemmas]] in structural [[graph theory]].  Discharging is most well known for its central role in the proof of the [[Four Color Theorem]].  The discharging method is used to prove that every graph in a certain class contains some subgraph from a specified list.  The presence of the desired subgraph is then often used to prove a [[graph coloring|coloring result]].

Most commonly, discharging is applied to [[planar graphs]].
Initially, a ''charge'' is assigned to each face and each vertex of the graph.
The charges are assigned so that they sum to a small positive number.  During the ''Discharging Phase'' the charge at each face or vertex may be redistributed to nearby faces and vertices, as required by a set of discharging rules.  However, each discharging rule maintains the sum of the charges.  The rules are designed so that after the discharging phase each face or vertex with positive charge lies in one of the desired subgraphs.  Since the sum of the charges is positive, some face or vertex must have a positive charge.  Many discharging arguments use one of a few standard initial charge functions (these are listed below).  Successful application of the discharging method requires creative design of discharging rules.

==An easy example==

In 1904, Wernicke introduced the discharging method to prove the following theorem, which was part of an attempt to prove the four color theorem.

'''Theorem:'''  If a [[planar graph]] has minimum [[Degree_(graph_theory)|degree]] 5, then it either has an edge
with endpoints both of degree 5 or one with endpoints of degrees 5 and 6.

'''Proof:'''
We use &lt;math&gt;V&lt;/math&gt;, &lt;math&gt;F&lt;/math&gt;, and &lt;math&gt;E&lt;/math&gt; to denote the sets of vertices, faces, and edges, respectively.
We call an edge ''light''  if its endpoints are both of degree 5 or are of degrees 5 and 6.
Embed the graph in the plane.  To prove the theorem, it is sufficient to only consider planar triangulations (for the following reason).  We arbitrarily add edges to the graph until it is a triangulation.  
Since the original graph had minimum degree 5, each endpoint of a new edge has degree at least 6. 
So, none of the new edges are light.
Thus, if the triangulation contains a light edge, then that edge must have been in the original graph.

We give the charge &lt;math&gt;6-d(v)&lt;/math&gt; to each vertex &lt;math&gt;v&lt;/math&gt; and the charge &lt;math&gt;6-2d(f)&lt;/math&gt; to each face &lt;math&gt;f&lt;/math&gt;, where &lt;math&gt;d(x)&lt;/math&gt; denotes the degree of a vertex and the length of a face.  (Since the graph is a triangulation, the charge on each face is 0.)  Recall that the sum of all the degrees in the graph is equal to twice the number of edges; similarly, the sum of all the face lengths equals twice the number of edges.  Using [[Planar_graph#Euler.27s_formula|Euler's Formula]], it's easy to see that the sum of all the charges is 12:

&lt;math&gt;
\begin{align}
\sum_{f\in F} 6-2d(f) + \sum_{v\in V} 6-d(v) =&amp; \\ 

6|F| - 2(2|E|) + 6|V| - 2|E| =&amp; \\

6(|F| - |E| + |V|) = &amp;&amp;12.
\end{align}
&lt;/math&gt;

We use only a single discharging rule:

* Each degree 5 vertex gives a charge of 1/5 to each neighbor.

We consider which vertices could have positive final charge.
The only vertices with positive initial charge are vertices of degree 5.  
Each degree 5 vertex gives a charge of 1/5 to each neighbor.  
So, each vertex is given a total charge of at most &lt;math&gt;d(v)/5&lt;/math&gt;.  
The initial charge of each vertex v is &lt;math&gt;6-d(v)&lt;/math&gt;.  
So, the final charge of each vertex is at most &lt;math&gt;6-4d(v)/5&lt;/math&gt;.  Hence, a vertex can only have positive final charge if it has degree at most 7.  Now we show that each vertex with positive final charge is adjacent to an endpoint of a light edge.

If a vertex &lt;math&gt;v&lt;/math&gt; has degree 5 or 6 and has positive final charge, then v received charge from an adjacent degree 5 vertex &lt;math&gt;u&lt;/math&gt;, so  edge &lt;math&gt;uv&lt;/math&gt; is light.  If a vertex &lt;math&gt;v&lt;/math&gt; has degree 7 and has positive final charge, then &lt;math&gt;v&lt;/math&gt; received charge from at least 6 adjacent degree 5 vertices.  Since the graph is a triangulation, the vertices adjacent to v must form a cycle, and since it has only degree 7, the degree 5 neighbors cannot be all separated by vertices of higher degree; at least two of the degree 5 neighbors of &lt;math&gt;v&lt;/math&gt; must be adjacent to each other on this cycle.  This yields the light edge.

==References==

*{{citation|last1=Appel|first1=Kenneth|author1-link=Kenneth Appel|last2=Haken|first2=Wolfgang|author2-link=Wolfgang Haken|journal=Illinois Journal of Mathematics|volume=21|year=1977|title=Every planar map is four colorable. I. Discharging|pages=429–490}}.
*{{citation|last1=Appel|first1=Kenneth|author1-link=Kenneth Appel|last2=Haken|first2=Wolfgang|author2-link=Wolfgang Haken|journal=Illinois Journal of Mathematics|volume=21|year=1977|title=Every planar map is four colorable. II. Reducibility|pages=491–567}}.
*{{citation|first=Petr|last=Hliněný|url=http://kam.mff.cuni.cz/~kamserie/serie/clanky/2000/s475.ps|title=Discharging technique in practice|year=2000}}.  (Lecture text for Spring School on Combinatorics).
*{{citation|last1=Robertson|first1=Neil|author1-link=Neil Robertson (mathematician)|last2=Sanders|first2=Daniel P.|author2-link=Daniel P. Sanders|last3=Seymour|first3=Paul|author3-link=Paul Seymour (mathematician)|last4=Thomas|first4=Robin|author4-link=Robin Thomas (mathematician)|title=The four-color theorem|journal=Journal of Combinatorial Theory, Series B|volume=70|year=1997|pages=2–44|doi=10.1006/jctb.1997.1750}}.
*{{citation|last=Wernicke|first=P.|title=Über den kartographischen Vierfarbensatz|language=German|journal=Math. Ann.|volume=58|year=1904|issue=3|pages=413–426|doi=10.1007/bf01444968}}.

[[Category:Graph theory]]</text>
      <sha1>4e7hfhnlmvwgmvc600hwgcwa1ytcw9m</sha1>
    </revision>
  </page>
  <page>
    <title>Disorder problem</title>
    <ns>0</ns>
    <id>21029881</id>
    <revision>
      <id>851139339</id>
      <parentid>851138688</parentid>
      <timestamp>2018-07-20T10:13:43Z</timestamp>
      <contributor>
        <username>Kku</username>
        <id>5846</id>
      </contributor>
      <comment>/* References */ cite</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1439">In the study of [[stochastic processes]] in [[mathematics]], a '''disorder problem''' or '''quickest detection problem''' (formulated by [[Kolmogorov]]) is the problem of using ongoing observations of a stochastic process to detect as soon as possible when the probabilistic properties of the process have changed. This is a type of [[change detection]] problem.

An example case is to detect the change in the drift parameter of a [[Wiener process]].&lt;ref&gt;Shiryaev (2007) page 208&lt;/ref&gt;

==Notes==
&lt;references/&gt;
==See also==
*[[compound Poisson process]]

==References==
* {{cite book
|   author = H. Vincent Poor and Olympia Hadjiliadis
|    title = Quickest Detection
|  edition = First
|publisher = Cambridge University Press
| location = Cambridge
|     year = 2008
|     isbn = 978-0-521-62104-5
}}
* {{cite book
|title= Optimal Stopping Rules
|last = [[Shiryaev]]
|first= Albert N.
|isbn = 3-540-74010-4
|year = 2007
|publisher=Springer
}}
* {{cite journal|author=Gapeev, P.V.|year=2005|title=The disorder problem for compound Poisson processes with exponential jumps|journal=Ann. Appl. Probab|volume=15|issue=1A, |pages=487-499|url=http://projecteuclid.org/euclid.aoap/1106922334}}
* Kolmogorov, A. N., Prokhorov, Yu. V. and Shiryaev, A. N. (1990). Methods of detecting spontaneously occurring effects. Proc. Steklov Inst. Math. 1, 1&amp;ndash;21.

[[Category:Stochastic processes]]
[[Category:Optimal decisions]]


{{probability-stub}}</text>
      <sha1>sc12lk4jcknikbkwaspsozdq6opmv0s</sha1>
    </revision>
  </page>
  <page>
    <title>Dwork family</title>
    <ns>0</ns>
    <id>28052186</id>
    <revision>
      <id>832455915</id>
      <parentid>823996534</parentid>
      <timestamp>2018-03-26T03:22:37Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>wikify a ref</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1402">In [[algebraic geometry]], a '''Dwork family''' is a one-parameter family of [[hypersurface]]s depending on an integer ''n'', studied by [[Bernard Dwork]]. Originally considered by Dwork in the context of [[local zeta-function]]s, such families have been shown to have relationships with [[mirror symmetry (string theory)|mirror symmetry]] and extensions of the [[modularity theorem]].&lt;ref&gt;{{cite journal|last=Totaro|first=Burt|authorlink=Burt Totaro| url=http://www.ams.org/journals/bull/2007-44-04/S0273-0979-07-01178-0/S0273-0979-07-01178-0.pdf|title= Euler and algebraic geometry|journal= [[Bulletin of the American Mathematical Society]] |volume =44|year=2007|issue= 4|pages= 541–559|doi=10.1090/S0273-0979-07-01178-0|mr=2338364 |quote=p. 545}}&lt;/ref&gt;

==Definition==
The Dwork family is given by the equations

:&lt;math&gt; x_1^n + x_2^n +\cdots +x_n^n = -n\lambda x_1x_2\cdots x_n \, ,&lt;/math&gt;

for all &lt;math&gt; n\ge 1&lt;/math&gt;.

==References==
*{{Citation | last=Katz | first=Nicholas M. | authorlink=Nick Katz| title=Algebra, arithmetic, and geometry: in honor of Yu. I. Manin. Vol. II | url=http://www.math.princeton.edu/~nmk/dworkfam64.pdf | publisher=Birkhäuser Boston | location=Boston, MA | series=Progress in Mathematics | mr=2641188 | year=2009 | volume=270 | chapter=Another look at the Dwork family | pages=89–126}}
{{reflist}}

[[Category:Algebraic geometry]]


{{algebraic-geometry-stub}}</text>
      <sha1>puccyf26s00a17dq2r8k6s10swmstov</sha1>
    </revision>
  </page>
  <page>
    <title>Embryo drawing</title>
    <ns>0</ns>
    <id>10273</id>
    <revision>
      <id>864619183</id>
      <parentid>864478408</parentid>
      <timestamp>2018-10-18T11:54:15Z</timestamp>
      <contributor>
        <username>Chiswick Chap</username>
        <id>2666701</id>
      </contributor>
      <comment>/* Ernst Haeckel (1834-1919) */ rm adj, seems needlessly pejorative</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30062">{{Use dmy dates|date=July 2013}}
[[Image:Gray41.png|thumb|Drawing of the head of a four-week-old human embryo. From [[Gray's Anatomy]].]]
'''Embryo drawing''' is the [[illustration]] of [[embryo]]s in their [[Embryogenesis|developmental sequence]]. In plants and animals, an embryo develops from a [[zygote]], the single cell that results when an [[Egg (biology)|egg]] and [[sperm]] fuse during [[fertilization]].  In animals, the zygote divides repeatedly to form a ball of cells, which then forms a set of tissue layers that migrate and fold to form an early embryo. Images of embryos provide a means of comparing embryos of different ages, and [[species (biology)|species]]. To this day, embryo drawings are made in [[undergraduate]] [[developmental biology]] lessons.

Comparing different embryonic stages of different animals is a tool that can be used to infer relationships between species, and thus [[biological evolution]]. This has been a source of quite some controversy, both now and in the past. [[Ernst Haeckel]] pioneered in this field. By comparing different embryonic stages of different [[vertebrate]] species, he formulated the [[recapitulation theory]]. This [[theory]] states that an animal's embryonic development follows exactly the same sequence as the sequence of its evolutionary ancestors. Haeckel's work and the ensuing controversy linked the fields of [[developmental biology]] and [[comparative anatomy]] into comparative [[embryology]]. From a more modern perspective, Haeckel's drawings were the beginnings of the field of [[evolutionary developmental biology]] (evo-devo).

The study of comparative embryology aims to prove or disprove that vertebrate embryos of different [[class (biology)|classes]] (e.g. mammals vs. fish) follow a similar developmental path due to their common ancestry. Such developing vertebrates have similar [[gene]]s, which determine the basic body plan. However, further development allows for the distinguishing of distinct characteristics as adults.

==Use of embryo drawings and photography in contemporary biology==
{{Expand section|date=June 2008}}
In current biology, fundamental research in developmental biology and evolutionary developmental biology is no longer driven by [[Morphology (biology)|morphological]] comparisons between embryos, but more by [[molecular biology]]. This is partly because Haeckel's drawings were very inaccurate.

==Controversy==
The exactness of [[Ernst Haeckel]]'s drawings of embryos has caused much controversy among [[Intelligent Design]] proponents recently and Haeckel's intellectual opponents in the past.  Although the early embryos of different species exhibit similarities, Haeckel apparently exaggerated these similarities in support of his [[Recapitulation theory]], sometimes known as the [[Biogenetic Law]] or "[[Ontogeny]] recapitulates [[Phylogenetics|phylogeny]]". Furthermore, Haeckel even proposed theoretical life-forms to accommodate certain stages in embryogenesis. A recent review concluded that the "biogenetic law is supported by several recent studies - if applied to single characters only".&lt;ref&gt;Michael K. Richardson and Gerhard Keuck, "Haeckel's ABC of evolution and development", ''Biol. Rev.'' (2002) '''77''', 495-528&lt;/ref&gt;

Critics in the late 19th and early 20th centuries, [[Karl von Baer]] and [[Wilhelm His, Sr.|Wilhelm His]], did not believe that living embryos reproduce the evolutionary process and produced embryo drawings of their own&lt;ref&gt;{{cite web
|url=http://evolution.berkeley.edu/evolibrary/article/history_10
|title=Developmental Similarities: Karl von Baer
|publisher=''University of California Museum of Paleontology''
|accessdate={{date|2012-03-13}}}}&lt;/ref&gt; which emphasized the differences in early embryological development. Late 20th and early 21st century critic [[Stephen Jay Gould]]&lt;ref&gt;Gould, Stephen Jay. "Abscheulich! (Atrocious!): Haeckel's distortions did not help Darwin". Nat. Hist. 109 (March 2000): 42-49.&lt;/ref&gt; have objected to the continued use of Haeckel's embryo drawings in textbooks.

On the other hand, Michael K. Richardson, Professor of Evolutionary Developmental Zoology, [[Leiden University]], while recognizing that some criticisms of the drawings are legitimate (indeed, it was he and his co-workers who began the modern criticisms in 1998), has supported the drawings as teaching aids,&lt;ref&gt;"Haeckel's much-criticized drawings are important as phylogenetic hypotheses, teaching aids, and evidence for evolution. While some criticisms of the drawings are legitimate, others are more tenditious.", M. K. Richardson and G. Keuck, "Haeckel's ABC of evolution and development", ''Biol. Rev.'' (2002) '''77''', 495-528 (quote from abstract)&lt;/ref&gt; and has said that "on a fundamental level, Haeckel was correct"&lt;ref&gt;Letter to ''Science'', '''280''', (15 May 1998), 983-984.&lt;/ref&gt;

==Famous embryo illustrators==

===Ernst Haeckel (1834-1919)===
[[Image:Haeckel drawings.jpg|thumb|250px|Romanes' 1892 copy of [[Ernst Haeckel]]'s allegedly fraudulent embryo drawings (this version of the figure is often attributed incorrectly to Haeckel).&lt;ref&gt;Richardson and Keuck, "Haeckel’s ABC of evolution and development," p. 516&lt;/ref&gt;]]

Haeckel's illustrations show vertebrate embryos at different stages of development, which exhibit embryonic resemblance as support for evolution, recapitulation as evidence of the Biogenetic Law, and phenotypic divergence as evidence of [[Karl Ernst von Baer#Baer's laws|von Baer's laws]]. The series of twenty-four embryos from the early editions of Haeckel's ''Anthropogenie'' remain the most famous. The different species are arranged in columns, and the different stages in rows. Similarities can be seen along the first two rows; the appearance of specialized characters in each species can be seen in the columns and a diagonal interpretation leads one to Haeckel's idea of recapitulation.

Haeckel's embryo drawings are primarily intended to express his theory of embryonic development, the Biogenetic Law, which in turn assumes (but is not crucial to) the evolutionary concept of [[common descent]]. His postulation of embryonic development coincides with his understanding of evolution as a developmental process.&lt;ref&gt;Nyhart, ''Biology Takes Form'', pp. 132-133&lt;/ref&gt;  In and around 1800, embryology fused with comparative anatomy as the primary foundation of [[Morphology (biology)|morphology]].&lt;ref&gt;Hopwood, "Pictures of Evolution and Charges of Fraud", p. 264&lt;/ref&gt; Ernst Haeckel, along with Karl von Baer and Wilhelm His, are primarily influential in forming the preliminary foundations of ‘phylogenetic embryology’ based on principles of evolution.&lt;ref&gt;Richardson and Keuck, "Haeckel’s ABC of evolution and development," p. 497&lt;/ref&gt;  Haeckel's ‘Biogenetic Law’ portrays the parallel relationship between an embryo's development and phylogenetic history.  The term, ‘recapitulation,’ has come to embody Haeckel's Biogenetic Law, for embryonic development is a recapitulation of evolution.&lt;ref&gt;Nyhart, ''Biology Takes Form'', p. 9&lt;/ref&gt;  Haeckel proposes that all classes of vertebrates pass through an evolutionarily conserved “[[Phylotype|phylotypic]]” stage of development, a period of reduced phenotypic diversity among higher embryos.&lt;ref name="Keuck p. 506"&gt;Richardson and Keuck, "Haeckel’s ABC of evolution and development," p. 506&lt;/ref&gt;  Only in later development do particular differences appear.  Haeckel portrays a concrete demonstration of his Biogenetic Law through his ''[[Gastrea]]'' theory, in which he argues that the early cup-shaped [[gastrula]] stage of development is a universal feature of multi-celled animals.  An ancestral form existed, known as the gastrea, which was a common ancestor to the corresponding gastrula.&lt;ref&gt;Nyhart, ''Biology Takes Form'', p. 159&lt;/ref&gt;

Haeckel argues that certain features in embryonic development are conserved and [[Palingenesis|palingenetic]], while others are [[Caenogenesis|caenogenetic]]. Caenogenesis represents “the blurring of ancestral resemblances in development,” which are said to be the result of certain adaptations to embryonic life due to environmental changes.&lt;ref&gt;Richardson and Keuck, "Haeckel’s ABC of evolution and development," p. 499&lt;/ref&gt;  In his drawings, Haeckel cites the [[notochord]], [[Branchial arch|pharyngeal arches]] and clefts, [[pronephros]] and [[neural tube]] as palingenetic features.  However, the [[yolk sac]], extra-embryonic membranes, egg membranes and [[Endocardium|endocardial]] tube are considered caenogenetic features.&lt;ref&gt;Richardson and Keuck, "Haeckel’s ABC of evolution and development," p. 500&lt;/ref&gt;  The addition of terminal adult stages and the telescoping, or driving back, of such stages to descendant's embryonic stages are likewise representative of Haeckelian embryonic development.  In addressing his embryo drawings to a general audience, Haeckel does not cite any sources, which gives his opponents the freedom to make assumptions regarding the originality of his work.&lt;ref&gt;Hopwood, "Pictures of Evolution and Charges of Fraud", p. 270&lt;/ref&gt;

===Karl Ernst von Baer (1792-1876)===
Haeckel was not the only one to create a series of drawings representing embryonic development.  [[Karl Ernst von Baer|Karl E. von Baer]] and Haeckel both struggled to model one of the most complex problems facing embryologists at the time: the arrangement of general and special characters during development in different species of animals.  In relation to developmental timing, von Baer's scheme of development differs from Haeckel's scheme.  Von Baer's scheme of development need not be tied to developmental stages defined by particular characters, where recapitulation involves [[heterochrony]].  Heterochrony represents a gradual alteration in the original phylogenetic sequence due to embryonic adaptation.&lt;ref&gt;Richardson, Michael K. and Gerhard Keuck, "Haeckel's ABC of Evolution and Development," p. 506&lt;/ref&gt;
As well, von Baer early noted that embryos of different species could not be easily distinguished from one another as in adults.

[[Karl Ernst von Baer#Baer's laws|Von Baer's laws]] governing embryonic development are specific rejections of recapitulation.&lt;ref name="Keuck p. 506"/&gt;   As a response to Haeckel's theory of recapitulation, von Baer enunciates his most notorious laws of development.  Von Baer's laws state that general features of animals appear earlier in the embryo than special features, where less general features stem from the most general, each embryo of a species departs more and more from a predetermined passage through the stages of other animals, and there is never a complete morphological similarity between an embryo and a lower adult.&lt;ref&gt;Gould, ''Ontogeny and Phylogeny'', p. 56&lt;/ref&gt;  Von Baer's embryo drawings&lt;ref&gt;{{cite web|url=http://www.sites.hps.cam.ac.uk/visibleembryos/s3_1.html|title=Histories of development|series=Making Visible Embryos}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|authors=Erki Tammiksaar and Sabine Brauckmann|volume=26|number=3/4|journal=History and Philosophy of the Life Sciences
|title=Karl Ernst von Baer's 'Über Entwickelungsgeschichte der Thiere II' and its Unpublished Drawings|year=2004|pages=291–308, 471–474|jstor=23333718}}&lt;/ref&gt; display that individual development proceeds from general features of the developing embryo in early stages through differentiation into special features specific to the species, establishing that linear evolution could not occur.&lt;ref&gt;Richards, ''The Meaning of Evolution'', p. 57-59&lt;/ref&gt;  Embryological development, in von Baer's mind, is a process of differentiation, "a movement from the more [[wikt:homogeneous|homogeneous]] and universal to the more [[heterogeneous]] and individual."&lt;ref&gt;Richards, ''The Meaning of Evolution'', p. 59-60&lt;/ref&gt;

Von Baer argues that embryos will resemble each other before attaining characteristics differentiating them as part of a specific [[family (biology)|family]], [[genus]] or [[species]], but embryos are not the same as the final forms of lower organisms.

===Wilhelm His (1831-1904)===
Wilhelm His was one of Haeckel's most authoritative and primary opponents advocating physiological embryology.&lt;ref&gt;Gould, ''Ontogeny and Phylogeny'', p. 189&lt;/ref&gt;  His ''Anatomie menschlicher Embryonen'' (Anatomy of human embryos) employs a series of his most important drawings chronicling developing embryos from the end of the second week through the end of the second month of pregnancy.  His, in opposition to Haeckel, seeks to take human embryos out of the hands of Darwinist proponents.{{Citation needed|date=June 2015}}  In 1878, His begins to engage in serious study of the anatomy of human embryos for his drawings.  During the 19th century, embryologists often obtained early human embryos from abortions and miscarriages, postmortems of pregnant women and collections in anatomical museums.&lt;ref&gt;Hopwood, "Producing Development", p. 38&lt;/ref&gt;  In order to construct his series of drawings, His collected specimens which he manipulated into a form that he could operate with.

In His’ ''Normentafel'', he displays specific individual embryos rather than ideal types.&lt;ref&gt;Hopwood, "Producing Development", p. 36&lt;/ref&gt;   His does not produce norms from aborted specimens, but rather visualizes the embryos in order to make them comparable and specifically subjects his embryo specimens to criticism and comparison with other cases.  Ultimately, His’ critical work in embryonic development comes with his production of a series of embryo drawings of increasing length and degree of development.&lt;ref&gt;Hopwood, "Producing Development", p. 50&lt;/ref&gt;  His’ depiction of embryological development strongly differs from Haeckel's depiction, for His argues that the phylogenetic explanation of ontogenetic events is unnecessary.  His argues that all ontogenetic events are the “mechanical” result of differential cell growth.&lt;ref&gt;Di Gregorio, ''From Here to Eternity'', p. 277&lt;/ref&gt;  His’ embryology is not explained in terms of ancestral history.

The debate between Haeckel and His ultimately becomes fueled by the description of an embryo that [[Wilhelm Krause (anatomist)|Wilhelm Krause]] propels directly into the ongoing feud between Haeckel and His.  Haeckel speculates that the [[allantois]] is formed in a similar way in both humans and other mammals.  His, on the other hand, accuses Haeckel of altering and playing with the facts.  Although Haeckel is proven right about the allantois, the utilization of Krause's embryo as justification turns out to be problematic, for the embryo is that of a bird rather than a human.  The underlying debate between Haeckel and His derives from differing viewpoints regarding the similarity or dissimilarity of vertebrate embryos.  In response to Haeckel's evolutionary claim that all vertebrates are essentially identical in the first month of embryonic life as proof of common descent, His responds by insisting that a more skilled observer would recognize even sooner that early embryos can be distinguished.  His also counteracts Haeckel's sequence of drawings in the ''Anthropogenie'' with what he refers to as “exact” drawings, highlighting specific differences.  Ultimately, His goes so far as to accuse Haeckel of “faking” his embryo illustrations to make the vertebrate embryos appear more similar than in reality.  His also accuses Haeckel of creating early human embryos that he conjured in his imagination rather than obtained through [[empirical]] observation.  His completes his denunciation of Haeckel by pronouncing that Haeckel had “‘relinquished the right to count as an equal in the company of serious researchers.’”&lt;ref&gt;Hopwood, "Producing Development", p. 61&lt;/ref&gt;

==Opposition to Haeckel==
Haeckel encountered numerous oppositions to his artistic depictions of embryonic development during the late nineteenth and early twentieth centuries.  Haeckel’s opponents believe that he de-emphasizes the differences between early embryonic stages in order to make the similarities between embryos of different species more pronounced.&lt;ref name="Hopwood p. 282"&gt;Hopwood, "Pictures of Evolution and Charges of Fraud", p. 282&lt;/ref&gt;

===Early opponents: Ludwig Rutimeyer, Theodor Bischoff and Rudolf Virchow===
The first suggestion of fakery against Haeckel was made in late 1868 by Ludwig Rutimeyer in the ''Archiv für Anthropogenie''.&lt;ref name="Hopwood p. 282"/&gt;  Rutimeyer was a professor of zoology and comparative anatomy at the [[University of Basel]], who rejected natural selection as simply mechanistic and proposed an anti-materialist view of nature.  Rutimeyer claimed that Haeckel “had taken to kinds of liberty with established truth.”&lt;ref&gt;Hopwood, "Pictures of Evolution and Charges of Fraud", p. 283&lt;/ref&gt;  Rutimeyer claimed that Haeckel presented the same image three consecutive times as the embryo of the dog, the chicken, and the turtle.&lt;ref&gt;Hopwood, "Pictures of Evolution and Charges of Fraud", p. 275&lt;/ref&gt;

[[Theodor Ludwig Wilhelm Bischoff|Theodor Bischoff]] (1807–1882), was a strong opponent of [[Darwinism]].{{Citation needed|date=March 2008}}  As a pioneer in mammalian embryology, he was one of Haeckel's strongest critics.{{Citation needed|date=March 2008}}  Although Bischoff's 1840 surveys depict how similar the early embryos of man are to other vertebrates, he later demanded that such [[hasty generalization]] was inconsistent with his recent findings regarding the dissimilarity between hamster embryos and those of rabbits and dogs.{{Citation needed|date=March 2008}}  Nevertheless, Bischoff's main argument was in reference to Haeckel's drawings of human embryos, for Haeckel is later accused of miscopying the dog embryo from him.&lt;ref name="Hopwood p. 282"/&gt; Throughout Haeckel's time, criticism of his embryo drawings was often due in part to his critics' belief in his representations of embryological development as “crude schemata.”&lt;ref&gt;Hopwood, "Pictures of Evolution and Charges of Fraud", p. 273&lt;/ref&gt;

===Contemporary criticism of Haeckel: Michael Richardson and Stephen Jay Gould===
Michael Richardson and his colleagues in a July 1997 issue of ''Anatomy and Embryology'',&lt;ref&gt;Richardson, M.K., Hanken, J., Gooneratne, M.L., Pieau, C., Raynaud. A., Selwood, L. and Wright, G.M. (1997): There is no highly conserved embryonic stage in the vertebrates: implications for current theories of evolution and development. Anatomy and Embryology 196(2): 91-106.&lt;/ref&gt; demonstrated that Haeckel falsified his drawings in order to exaggerate the similarity of the phylotypic stage.
In a March 2000 issue of ''[[Natural History (magazine)|Natural History]]'', Stephen Jay Gould argued that Haeckel "exaggerated the similarities by idealizations and omissions." As well, Gould argued that Haeckel's drawings are simply inaccurate and falsified.&lt;ref&gt;
{{cite journal
|title=Abscheulich! - Atrocious! - the precursor to the theory of natural selection
|author=Stephen Jay Gould
|date=March 2000
|journal=[[Natural History (magazine)|Natural History]]
}}&lt;/ref&gt;  On the other hand, one of those who criticized Haeckel's drawings, Michael Richardson, has argued that "Haeckel's much-criticized drawings are important as phylogenetic hypotheses, teaching aids, and evidence for evolution".&lt;ref&gt;Richardson and Keuck, "Haeckel's ABC of evolution and development", ''Biol. Rev.'' (2002) '''77''', 495-528&lt;/ref&gt;
But even Richardson admitted in ''[[Science (journal)|Science]]'' Magazine in 1997 that his team's investigation of Haeckel's drawings were showing them to be "one of the most famous fakes in biology."&lt;ref&gt;{{cite journal|author=Pennisi, Elizabeth|title=Haeckel's Embryos: Fraud Rediscovered|year=1997|journal=Science|doi=10.1126/science.277.5331.1435a}}&lt;/ref&gt;

Some version of Haeckel's drawings can be found in many modern biology textbooks in discussions of the history of embryology, with clarification that these are no longer considered valid .&lt;ref&gt;Futuyma, Douglas, "Evolutionary Biology," p. 652-653&lt;/ref&gt;

==Haeckel's proponents (past and present)==
Although Charles Darwin accepted Haeckel's support for natural selection, he was tentative in using Haeckel's ideas in his writings; with regard to embryology, Darwin relied far more on von Baer's work.  Haeckel's work was published in 1866 and 1874, years after Darwin's "The Origin of Species" (1859).

Despite the numerous oppositions, Haeckel has influenced many disciplines in science in his drive to integrate such disciplines of taxonomy and embryology into the Darwinian framework and to investigate phylogenetic reconstruction through his Biogenetic Law.  As well, Haeckel served as a mentor to many important scientists, including [[Anton Dohrn]], [[Richard Hertwig|Richard]] and [[Oscar Hertwig]], [[Wilhelm Roux]], and [[Hans Driesch]].&lt;ref&gt;Richardson, Michael K. and Gerhard Keuck, "Haeckel's ABC of evolution and development," p. 496&lt;/ref&gt;

One of Haeckel's earliest proponents was [[Carl Gegenbaur]] at the University of Jena (1865–1873), during which both men were absorbing the impact of Darwin's theory.  The two quickly sought to integrate their knowledge into an evolutionary program.  In determining the relationships between "phylogenetic linkages" and "evolutionary laws of form," both Gegenbaur and Haeckel relied on a method of comparison.&lt;ref&gt;Nyhart, Lynn K., ''Biology Takes Form'', p. 150&lt;/ref&gt;  As Gegenbaur argued, the task of comparative anatomy lies in explaining the form and organization of the animal body in order to provide evidence for the continuity and evolution of a series of organs in the body.  Haeckel then provided a means of pursuing this aim with his biogenetic law, in which he proposed to compare an individual's various stages of development with its ancestral line.  Although Haeckel stressed comparative embryology and Gegenbaur promoted the comparison of adult structures, both believed that the two methods could work in conjunction to produce the goal of evolutionary morphology.&lt;ref&gt;Nyhart, Lynn K., ''Biology Takes Form'', p. 153&lt;/ref&gt;

The philologist and anthropologist, [[Max Müller|Friedrich Müller]], used Haeckel's concepts as a source for his ethnological research, involving the systematic comparison of the folklore, beliefs and practices of different societies.  Müller's work relies specifically on theoretical assumptions that are very similar to Haeckel's and reflects the German practice to maintain strong connections between empirical research and the philosophical framework of science.  Language is particularly important, for it establishes a bridge between natural science and philosophy.&lt;ref&gt;Di Gregorio, Mario A., ''From Here to Eternity: Ernst Haeckel and Scientific Faith'', p. 253&lt;/ref&gt;  For Haeckel, language specifically represented the concept that all phenomena of human development relate to the laws of biology.&lt;ref&gt;Di Gregorio, Mario A., ''From Here to Eternity: Ernst Haeckel and Scientific Faith'', p. 252&lt;/ref&gt;  Although Müller did not specifically have an influence in advocating Haeckel's embryo drawings, both shared a common understanding of development from lower to higher forms, for Müller specifically saw humans as the last link in an endless chain of evolutionary development.&lt;ref&gt;Di Gregorio, Mario A., ''From Here to Eternity: Ernst Haeckel and Scientific Faith'', p. 254&lt;/ref&gt;

Modern acceptance of Haeckel's Biogenetic Law, despite current rejection of Haeckelian views, finds support in the certain degree of parallelism between ontogeny and phylogeny.  A. M. Khazen, on the one hand, states that "ontogeny is obliged to repeat the main stages of phylogeny."&lt;ref name="Richardson, Michael K p. 501"&gt;Richardson, Michael K. and Gerhard Keuck, "Haeckel's ABC of Evolution and Development," p. 501&lt;/ref&gt;  A. S. Rautian, on the other hand, argues that the reproduction of ancestral patterns of development is a key aspect of certain biological systems.  Dr. Rolf Siewing acknowledges the similarity of embryos in different species, along with the laws of von Baer, but does not believe that one should compare embryos with adult stages of development.&lt;ref name="Richardson, Michael K p. 501"/&gt;  According to M. S. Fischer, reconsideration of the Biogenetic Law is possible as a result of two fundamental innovations in biology since Haeckel's time: [[cladistics]] and developmental genetics.&lt;ref&gt;Richardson, Michael K. and Gerhard Keuck, "Haeckel's ABC of Evolution and Development," p. 502&lt;/ref&gt;

In defense of Haeckel's embryo drawings, the principal argument is that of "schematisation."&lt;ref name="Richardson, Michael K p. 519"&gt;Richardson, Michael K. and Gerhard Keuck, "Haeckel's ABC of Evolution and Development," p. 519&lt;/ref&gt;  Haeckel's drawings were not intended to be technical and scientific depictions, but rather schematic drawings and reconstructions for a specifically lay audience.&lt;ref name="Richardson, Michael K p. 519"/&gt;  Therefore, as R. Gursch argues, Haeckel's embryo drawings should be regarded as "reconstructions."  Although his drawings are open to criticism, his drawings should not be considered falsifications of any sort.  Although modern defense of Haeckel's embryo drawings still considers the inaccuracy of his drawings, charges of fraud are considered unreasonable.  As [[Erland Nordenskiöld]] argues, charges of fraud against Haeckel are unnecessary.  R. Bender ultimately goes so far as to reject His's claims regarding the fabrication of certain stages of development in Haeckel's drawings, arguing that Haeckel's embryo drawings are faithful representations of real stages of embryonic development in comparison to published embryos.&lt;ref&gt;Richardson, Michael K. and Gerhard Keuck, "Haeckel's ABC of Evolution and Development," p. 520&lt;/ref&gt;

==The survival and reproduction of Haeckel's embryo drawings==
Haeckel's embryo drawings, as comparative plates, were at first only copied into biology textbooks, rather than texts on the study of embryology.{{Citation needed|date=March 2008}}  Even though Haeckel's program in comparative embryology virtually collapsed after the First World War,{{Citation needed|date=February 2007}} his embryo drawings have often been reproduced and redrawn with increased precision and accuracy in works that have kept the study of [[comparative embryology]] alive.{{Citation needed|date=March 2008}}  Nevertheless, neither His-inspired human embryology nor developmental biology are concerned with the comparison of vertebrate embryos.{{Citation needed|date=February 2007}}  Although Stephen Jay Gould's 1977 book ''Ontogeny and Phylogeny'' helps to reassess Haeckelian embryology, it does not address the controversy over Haeckel's embryo drawings.  Nevertheless, new interest in evolution in and around 1977 inspired developmental biologists to look more closely at Haeckel's illustrations.&lt;ref&gt;Hopwood, "Pictures of Evolution and Charges of Fraud," p. 298&lt;/ref&gt;

==See also==
*[[Medical illustration]]
*[[Recapitulation theory]]
*[[Ernst Haeckel]]
*[[Evolutionary developmental biology]]
*[[Embryogenesis]]
*[[History of biology]]
*[[History of zoology, post-Darwin]]
*[[Science education]]

==References==
{{Reflist}}

==Further reading==
*{{cite book|authors=Di Gregorio, Dr. Mario A.|title=From Here to Eternity: Ernst Haeckel and Scientific Faith|location=Göttingen, Germany|publisher=Vandenhoeck &amp; Ruprecht|year=2005}}
*{{cite book|author=Futuyma, Douglas|title=Evolutionary Biology|edition=3rd|publisher=Sinauer|year=1998|pages=652–653}}
*{{cite book|author=Gould, Stephen Jay|title=Ontogeny and Phylogeny|location=Cambridge, Mass|publisher=Belknap Press of [[Harvard University]] Press|year=1977}}
*{{cite web|author=Hopwood, Nick|title=Pictures of Evolution and Charges of Fraud: Ernst Haeckel’s Embryological Illustrations|publisher=Isis|year=2006|pages=260–301|url=http://www.journals.uchicago.edu/ISIS/journal/issues/v97n2/970203/970203.web.pdf|archiveurl=https://web.archive.org/web/20071127234835/http://www.journals.uchicago.edu/ISIS/journal/issues/v97n2/970203/970203.web.pdf|archivedate=27 November 2007|pmid=16892945}}
*{{cite journal|author=Hopwood, Nick|title=Producing Development: The Anatomy of Human Embryos and the Norms of Wilhelm His|journal=The Bulletin of the History of Medicine|year=2000|pages=29–71|doi= 10.1353/bhm.2000.0020}}
*{{cite book|author=Judson, Horace Freeland|title=The Great Betrayal: Fraud in Science|location=Orlando, Florida|publisher=Harcourt, Inc.|year=2004|isbn=978-0151008773}}
*{{cite book|author=Nordenskiold, Erik|title=The History of Biology: A Survey|location=New York, New York|publisher=Tudor Publishing Co.|year=1928|url=https://archive.org/details/historyofbiology00nord}}
*{{cite book|author=Nyhart, Lynn K.|title=Biology Takes Form: Animal Morphology and the German Universities, 1800-1900|location=Chicago, Illinois|publisher=The University of Chicago Press|year=1995|isbn= 978-0226610887}}
*{{cite book|author=Richards, Robert J. |title=The Meaning of Evolution: The Morphological Construction and Ideological Reconstruction of Darwin’s Theory|location=Chicago, Illinois|publisher=The University of Chicago Press|year=1992|isbn=978-0226712024}}
*{{cite journal|authors=Richardson, Michael K. and Keuck, Gerhard|title=Haeckel’s ABC of evolution and development|journal=Biological Reviews|year=2002|pages=495–528|doi=10.1017/S1464793102005948|url=http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=135297}}
*{{cite web|author=Wells, Jonathan|title=Icons of Evolution: Science or Myth? Why much of what we teach about evolution is wrong|location=Washington, DC|publisher=Regnery Publishing, Inc.|year=2000|isbn=978-0895262769}}
*{{cite magazine|author=Wells, Jonathan|title=Survival of the Fakest|publisher=The American Spectator|issue=December 2000/January 2001|url=http://www.discovery.org/scripts/viewDB/filesDB-download.php?command=download&amp;id=12009}}

{{DEFAULTSORT:Embryo Drawing}}
[[Category:Biological techniques and tools]]
[[Category:History of evolutionary biology]]
[[Category:Technical drawing]]</text>
      <sha1>c27i0ke277hk3fp27939lbt1iecrp43</sha1>
    </revision>
  </page>
  <page>
    <title>End extension</title>
    <ns>0</ns>
    <id>21278889</id>
    <revision>
      <id>861654646</id>
      <parentid>790703835</parentid>
      <timestamp>2018-09-29T00:58:28Z</timestamp>
      <contributor>
        <username>Ketiltrout</username>
        <id>202276</id>
      </contributor>
      <minor/>
      <comment>dab</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1148">In [[model theory]] and [[set theory]], which are disciplines within mathematics, a model &lt;math&gt;\mathfrak{B}=\langle B, F\rangle &lt;/math&gt; of some axiom system of [[set theory]] &lt;math&gt; T&lt;/math&gt; in the language of set theory is an '''end extension''' of &lt;math&gt;\mathfrak{A}=\langle A, E\rangle &lt;/math&gt;, in symbols &lt;math&gt;\mathfrak{A}\subseteq_\text{end}\mathfrak{B}&lt;/math&gt;, if 
* &lt;math&gt;\mathfrak{A}&lt;/math&gt; is a [[substructure (mathematics)|substructure]] of &lt;math&gt;\mathfrak{B}&lt;/math&gt;, and 
* &lt;math&gt; b\in A&lt;/math&gt; whenever &lt;math&gt;a\in A&lt;/math&gt; and &lt;math&gt;bFa&lt;/math&gt; hold, i.e., no new elements are added by &lt;math&gt;\mathfrak{B}&lt;/math&gt; to the elements of &lt;math&gt;\mathfrak{A}&lt;/math&gt;.

The following is an equivalent definition of end extension:  &lt;math&gt;\mathfrak{A}&lt;/math&gt; is a substructure of &lt;math&gt;\mathfrak{B}&lt;/math&gt;, and &lt;math&gt;\{b\in A : b E a\}=\{b\in B : b F a\}&lt;/math&gt; for all &lt;math&gt;a\in A&lt;/math&gt;.

For example, &lt;math&gt;\langle B, \in\rangle &lt;/math&gt; is an end extension of &lt;math&gt;\langle A, \in\rangle &lt;/math&gt; if &lt;math&gt; A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; are [[transitive set]]s, and  &lt;math&gt; A\subseteq B&lt;/math&gt;.

[[Category:Mathematical logic]]

{{mathlogic-stub}}</text>
      <sha1>ft4ahlmrjas0ux1n8smxmzrqv5ynjh1</sha1>
    </revision>
  </page>
  <page>
    <title>Equation xʸ=yˣ</title>
    <ns>0</ns>
    <id>50167582</id>
    <revision>
      <id>870554982</id>
      <parentid>865428472</parentid>
      <timestamp>2018-11-25T16:12:43Z</timestamp>
      <contributor>
        <ip>50.101.110.90</ip>
      </contributor>
      <comment>Changed formatting of log</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8291">[[File:Y^x = x^y.svg|thumb|Graph of {{math|1=''x''&lt;sup&gt;''y''&lt;/sup&gt; = ''y''&lt;sup&gt;''x''&lt;/sup&gt;}}.]]

In general, [[exponentiation]] fails to be [[Commutative property|commutative]]. However, the equation &lt;math&gt;x^y=y^x&lt;/math&gt; holds in special cases, such as &lt;math&gt;x=2,\ \ y=4.&lt;/math&gt;&lt;ref name="loczy" /&gt;

== History ==
The equation &lt;math&gt;x^y=y^x&lt;/math&gt; is mentioned in a letter of [[Daniel Bernoulli|Bernoulli]] to [[Christian Goldbach|Goldbach]] (29 June 1728&lt;ref name="Singmaster" /&gt;). The letter contains a statement that when &lt;math&gt;x\ne y,&lt;/math&gt; the only solutions in natural numbers are &lt;math&gt;(2,4)&lt;/math&gt; and &lt;math&gt;(4,2),&lt;/math&gt; although there are infinitely many solutions in rational numbers.&lt;ref name="Sved1990" /&gt;&lt;ref name="Dickson" /&gt;
The reply by Goldbach (31 January 1729&lt;ref name="Singmaster" /&gt;) contains general solution of the equation obtained by substituting &lt;math&gt;y=vx.&lt;/math&gt;&lt;ref name="Sved1990" /&gt; A similar solution was found by [[Leonhard Euler|Euler]].&lt;ref name="Dickson" /&gt;

J. van Hengel pointed out that if &lt;math&gt;r, n&lt;/math&gt; are positive integers with &lt;math&gt;r\geq 3&lt;/math&gt; then &lt;math&gt;r^{r+n} &gt; (r+n)^{r};&lt;/math&gt; therefore it is enough to consider possibilities &lt;math&gt;x = 1&lt;/math&gt; and &lt;math&gt;x = 2&lt;/math&gt; in order to find solutions in natural numbers.&lt;ref name="Dickson" /&gt;&lt;ref name="Hengel1888" /&gt;

The problem was discussed in a number of publications.&lt;ref name="Singmaster" /&gt;&lt;ref name="Sved1990" /&gt;&lt;ref name="Dickson" /&gt; In 1960, the equation was among the questions on the [[William Lowell Putnam Competition]]&lt;ref name="wlp" /&gt;&lt;ref&gt;{{cite web|url=http://www.kalva.demon.co.uk/putnam/putn60.html |title=21st Putnam 1960. Problem B1 |date=20 Oct 1999 |deadurl=bot: unknown |archiveurl=https://web.archive.org/web/20080330183949/http://www.kalva.demon.co.uk/putnam/putn60.html |archivedate=2008-03-30 |df= }}&lt;/ref&gt; which prompted Alvin Hausner to extend results to algebraic number fields.&lt;ref name="Sved1990" /&gt;&lt;ref&gt;{{Cite journal |last=Hausner |first=Alvin |date=November 1961 |title=Algebraic Number Fields and the Diophantine Equation m&lt;sup&gt;n&lt;/sup&gt; = n&lt;sup&gt;m&lt;/sup&gt;  |journal=[[The American Mathematical Monthly]] |volume=68 |issue=9 |pages=856–861 |doi=10.1080/00029890.1961.11989781 |issn=0002-9890}}&lt;/ref&gt;

== Positive real solutions ==
:''Main source:&lt;ref name="loczy" /&gt;
An infinite set of trivial solutions in positive real numbers is given by &lt;math&gt;x=y.&lt;/math&gt;

Nontrivial solutions can be found by assuming &lt;math&gt;x\ne y&lt;/math&gt; and letting &lt;math&gt;y = vx.&lt;/math&gt;
Then
: &lt;math&gt;(vx)^x = x^{vx} = (x^v)^x.&lt;/math&gt;
Raising both sides to the power &lt;math&gt;\tfrac{1}{x}&lt;/math&gt; and dividing by &lt;math&gt;x,&lt;/math&gt;
: &lt;math&gt;v = x^{v-1}.&lt;/math&gt;
Then nontrivial solutions in positive real numbers are expressed as
: &lt;math&gt;x = v^{\frac{1}{v-1}},&lt;/math&gt;
: &lt;math&gt;y = v^{\frac{v}{v-1}}.&lt;/math&gt;

Setting &lt;math&gt;v=2&lt;/math&gt; or &lt;math&gt;v=\tfrac{1}{2}&lt;/math&gt; generates the nontrivial solution in positive integers, &lt;math&gt;4^2=2^4.&lt;/math&gt;

Other pairs consisting of algebraic numbers exist, such as &lt;math&gt;\sqrt3&lt;/math&gt; and &lt;math&gt;3\sqrt3&lt;/math&gt;, as well as &lt;math&gt;\sqrt[3]4&lt;/math&gt; and &lt;math&gt;4\sqrt[3]4&lt;/math&gt;.

The trivial and non-trivial solutions intersect when &lt;math&gt;v = 1&lt;/math&gt;.  The equations above cannot be evaluated directly, but we can take the [[limit of a function|limit]] as &lt;math&gt;v\to 1&lt;/math&gt;.  This is most conveniently done by substituting &lt;math&gt;v = 1 + 1/n&lt;/math&gt; and letting &lt;math&gt;n\to\infty&lt;/math&gt;, so
:&lt;math&gt;x = \lim_{v\to 1}v^{\frac 1{v-1}} = \lim_{n\to\infty}\left(1+\frac 1n\right)^n = e.&lt;/math&gt;
Thus, the line &lt;math&gt;y=x&lt;/math&gt; and the curve for &lt;math&gt;x^y-y^x=0,\,\, y \ne x&lt;/math&gt; intersect at {{math|1=''x'' = ''y'' = [[e (mathematical constant)|''e'']]}}.

== Similar graphs ==
The equation &lt;math&gt;\sqrt[x]y=\sqrt[y]x&lt;/math&gt; produces a graph where the line and curve intersect at &lt;math&gt;1/e&lt;/math&gt;. The curve also terminates at (0,1) and (1,0), instead of continuing on for infinity.

The equation &lt;math&gt;\log_x(y)=\log_y(x)&lt;/math&gt; produces a graph where the curve and line intersect at (1,1). The curve (which is actually the positive section of ''y''=1/''x'') becomes asymptotic to 0, as opposed to 1.

== References ==
{{reflist|refs =

&lt;ref name="Dickson"&gt;{{citation
 |authorlink = Leonard Eugene Dickson|first=Leonard Eugene |last=Dickson
 |title = [[History of the Theory of Numbers]]
 |volume = II
 |location = Washington
 |year = 1920
 |contribution = Rational solutions of x&lt;sup&gt;y&lt;/sup&gt; {{=}} y&lt;sup&gt;x&lt;/sup&gt;
 |contribution-url = https://books.google.com/books?id=dO7C02z4LlcC&amp;pg=PA687
 |pages = 687
}}&lt;/ref&gt;

&lt;ref name="Singmaster"&gt;{{cite web|url=http://www.gotham-corp.com/sources.htm#_Toc69534169 |title=Sources in recreational mathematics: an annotated bibliography. 8th preliminary edition |authorlink=David Singmaster|first=David |last=Singmaster |deadurl=unfit |archiveurl=https://web.archive.org/web/20040416081838/http://www.gotham-corp.com/sources.htm#_Toc69534169 |archivedate=April 16, 2004 }}&lt;/ref&gt;

&lt;ref name="Sved1990"&gt;{{cite journal
 |first = Marta | last = Sved | authorlink = Márta Svéd
 |title = On the Rational Solutions of x&lt;sup&gt;y&lt;/sup&gt; {{=}} y&lt;sup&gt;x&lt;/sup&gt;
 |year = 1990
 |journal = Mathematics Magazine
 |url = http://www.maa.org/sites/default/files/Sved50816668.pdf
 |archiveurl = https://web.archive.org/web/20160304191325/http://www.maa.org/sites/default/files/Sved50816668.pdf
 |archivedate = 2016-03-04
}}&lt;/ref&gt;

&lt;ref name="wlp"&gt;{{citation
 |title = The William Lowell Putnam mathematical competition problems and solutions: 1938-1964
 |authorlink = Andrew M. Gleason|first=A. M. |last=Gleason|first2= R. E. |last2=Greenwood|authorlink3=Leroy Milton Kelly|first3=L. M.|last3= Kelly
 |publisher = [[Mathematical Association of America|MAA]]
 |year = 1980
 |isbn = 0-88385-428-7
 |contribution = The twenty-first William Lowell Putnam mathematical competition (December 3, 1960), afternoon session, problem 1
 |contribution-url = https://books.google.com/books?id=7D0PAQAAMAAJ&amp;q=%22prove+that+you+have+obtained+all+of+them%22
 |pages = 59
}}&lt;!-- — «Find all solutions of ''n''&lt;sup&gt;''m''&lt;/sup&gt; = ''m''&lt;sup&gt;''n''&lt;/sup&gt; in integers ''n'' and ''m'' (''n'' ≠ ''m''). Prove that you have obtained all of them.» --&gt;&lt;/ref&gt;

&lt;ref name="Hengel1888"&gt;{{cite journal
 |title = Beweis des Satzes, dass unter allen reellen positiven ganzen Zahlen nur das Zahlenpaar 4 und 2 für a und b der Gleichung a&lt;sup&gt;b&lt;/sup&gt; {{=}} b&lt;sup&gt;a&lt;/sup&gt; genügt
 |url = http://digital.ub.uni-duesseldorf.de/ulbdsp/periodical/titleinfo/4315444
 |last = van Hengel|first= Johann
 |year = 1888
}}&lt;/ref&gt;

&lt;ref name="loczy"&gt;{{cite journal
 |url = http://www.komal.hu/cikkek/loczy/powers/commpower.e.shtml
 |title = On commutative and associative powers
 |first = Lajos |last=Lóczi
 |journal = KöMaL
 |archiveurl = https://web.archive.org/web/20021015103129/http://www.komal.hu/cikkek/loczy/powers/commpower.e.shtml
 |archivedate = 2002-10-15
}} Translation of: {{cite web
 |url = http://db.komal.hu/KomalHU/cikk.phtml?id=200047
 |title = Mikor kommutatív, illetve asszociatív a hatványozás?
 |language = hu
 |archiveurl = https://web.archive.org/web/20160506183127/http://db.komal.hu/KomalHU/cikk.phtml?id=200047
 |archivedate = 2016-05-06
}}&lt;/ref&gt;

}}

== External links ==
* {{cite web
 |url = http://www.cut-the-knot.org/wiki-math/index.php?n=Algebra.RationalSolutionOfXYYX
 |title = Rational Solutions to x^y {{=}} y^x
 |work = [[Cut-the-Knot|CTK]] Wiki Math
}}
* &lt;!-- About 20 references to published literature and websites. Some dead links there can still be opened through Wayback Machine --&gt;{{cite web
 |url = https://www.math.uni-bielefeld.de/~sillke/PUZZLES/x%5Ey-x%5Ey
 |title = x^y {{=}} y^x - commuting powers
 |publisher = Torsten Sillke
 |work = Arithmetical and Analytical Puzzles
 |archiveurl = https://web.archive.org/web/20151228091303/https://www.math.uni-bielefeld.de/~sillke/PUZZLES/x%5Ey-x%5Ey
 |archivedate = 2015-12-28
}}
* {{cite web
 |url = http://www.geogebra.org/material/show/id/3940
 |title = Parametric Graph of x^y{{=}}y^x
 |publisher = [[GeoGebra]]
 |author = dborkovitz
 |date = 2012-01-29
}}
* {{OEIS el|sequencenumber=A073084|name=Decimal expansion of -x, where x is the negative solution to the equation 2^x {{=}} x^2}}

{{DEFAULTSORT:Equation x}}
[[Category:Diophantine equations]]
[[Category:Recreational mathematics]]</text>
      <sha1>o3m6d0rb8thn7rg9nfv1cv6peuivpjg</sha1>
    </revision>
  </page>
  <page>
    <title>Flajolet–Martin algorithm</title>
    <ns>0</ns>
    <id>44308703</id>
    <revision>
      <id>807641789</id>
      <parentid>787675455</parentid>
      <timestamp>2017-10-29T06:59:00Z</timestamp>
      <contributor>
        <ip>192.143.88.40</ip>
      </contributor>
      <comment>/* The algorithm */Fixed definition of rho(y).</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7382">{{orphan|date=November 2014}}

The '''Flajolet–Martin algorithm''' is an [[algorithm]] for approximating the number of distinct elements in a stream with a single pass and space-consumption logarithmic in the maximal number of possible distinct elements in the stream (the [[count-distinct problem]]). The algorithm was introduced by [[Philippe Flajolet]] and [[G. Nigel Martin]] in their 1984 article "Probabilistic Counting Algorithms for Data Base Applications".&lt;ref&gt;{{Cite journal |doi=10.1016/0022-0000(85)90041-8 |title=Probabilistic counting algorithms for data base applications |journal=Journal of Computer and System Sciences |volume=31 |issue=2 |pages=182&amp;ndash;209 |year=1985 |last1=Flajolet |first1=Philippe |last2=Martin |first2=G. Nigel |url=http://algo.inria.fr/flajolet/Publications/FlMa85.pdf |accessdate=2016-12-11}}&lt;/ref&gt; Later it has been refined in "LogLog counting of large cardinalities" by [[Marianne Durand]] and [[Philippe Flajolet]],&lt;ref&gt;{{Cite book |doi=10.1007/978-3-540-39658-1_55 |chapter=Loglog Counting of Large Cardinalities |chapter-url=http://algo.inria.fr/flajolet/Publications/DuFl03-LNCS.pdf |accessdate=2016-12-11 |title= Algorithms - ESA 2003 |volume=2832 |pages=605 |series=Lecture Notes in Computer Science |year=2003 |last1=Durand |first1=Marianne |last2=Flajolet |first2=Philippe |isbn=978-3-540-20064-2}}&lt;/ref&gt; and "[[HyperLogLog]]: The analysis of a near-optimal cardinality estimation algorithm" by [[Philippe Flajolet]] et al.&lt;ref name="flajolet07"&gt;{{cite journal |citeseerx=10.1.1.76.4286 |first1=Philippe |last1=Flajolet |first2=Éric |last2=Fusy |first3=Olivier |last3=Gandouet |first4=Frédéric |last4=Meunier |title=Hyperloglog: The analysis of a near-optimal cardinality estimation algorithm |url=http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf  |accessdate=2016-12-11 |year=2007 |volume=AH |pages=127–146 |journal=Discrete Mathematics and Theoretical Computer Science proceedings |location=[[Nancy, France]]}}&lt;/ref&gt;

In their 2010 article "An optimal algorithm for the distinct elements problem",&lt;ref&gt;{{Cite book |doi=10.1145/1807085.1807094 |chapter=An optimal algorithm for the distinct elements problem|chapter-url=http://researcher.watson.ibm.com/researcher/files/us-dpwoodru/knw11.pdf |accessdate=2016-12-11 |title=Proceedings of the twenty-ninth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems of data - PODS '10 |page=41 |year=2010 |last1=Kane |first1=Daniel M. |last2=Nelson |first2=Jelani |last3=Woodruff |first3=David P. |isbn=978-1-4503-0033-9}}&lt;/ref&gt; Daniel M. Kane, Jelani Nelson and David P. Woodruff give an improved algorithm, which uses nearly optimal space and has optimal ''O''(1) update and reporting times.

==The algorithm==
Assume that we are given a [[hash function]] &lt;math&gt;\mathrm{hash}(x)&lt;/math&gt; that maps input &lt;math&gt;x&lt;/math&gt; to integers in the range &lt;math&gt;[0; 2^L - 1]&lt;/math&gt;, and where the outputs are sufficiently [[Discrete uniform distribution|uniformly distributed]]. Note that the set of integers from 0 to &lt;math&gt;2^L - 1&lt;/math&gt; corresponds to the set of binary strings of length &lt;math&gt;L&lt;/math&gt;. For any non-negative integer &lt;math&gt;y&lt;/math&gt;, define &lt;math&gt;\mathrm{bit}(y,k)&lt;/math&gt; to be the &lt;math&gt;k&lt;/math&gt;-th bit in the binary representation of &lt;math&gt;y&lt;/math&gt;, such that:

:&lt;math&gt;
y = \sum_{k \geq 0} \mathrm{bit}(y,k) 2^k.
&lt;/math&gt;

We then define a function &lt;math&gt;\rho(y)&lt;/math&gt; that outputs the position of the least-significant set bit in the binary representation of &lt;math&gt;y&lt;/math&gt;:

:&lt;math&gt;\rho(y) = \min \{k \geq 0 \mid \mathrm{bit}(y,k) \neq 0 \}&lt;/math&gt;

where &lt;math&gt;\rho(0) = L&lt;/math&gt;. Note that with the above definition we are using 0-indexing for the positions. For example, &lt;math&gt;\rho(13) = \rho(1101_{2}) = 0&lt;/math&gt;, since the least significant bit is a 1 (0th position), and &lt;math&gt;\rho(8) = \rho(1000_{2}) = 3&lt;/math&gt;, since the least significant bit is at the 3rd position. At this point, note that under the assumption that the output of our hash function is uniformly distributed, then the probability of observing a hash output ending with &lt;math&gt;2^k&lt;/math&gt; (a one, followed by &lt;math&gt;k&lt;/math&gt; zeroes) is &lt;math&gt;2^{-(k+1)}&lt;/math&gt;, since this corresponds to flipping &lt;math&gt;k&lt;/math&gt; heads and then a tail with a fair coin.

Now the Flajolet–Martin algorithm for estimating the cardinality of a [[multiset]] &lt;math&gt;M&lt;/math&gt; is as follows:
# Initialize a bit-vector BITMAP to be of length &lt;math&gt;L&lt;/math&gt; and contain all 0s.
# For each element &lt;math&gt;x&lt;/math&gt; in &lt;math&gt;M&lt;/math&gt;:
## Calculate the index &lt;math&gt;i = \rho(\mathrm{hash}(x))&lt;/math&gt;.
## Set &lt;math&gt;\mathrm{BITMAP}[i] = 1&lt;/math&gt;.
# Let &lt;math&gt;R&lt;/math&gt; denote the smallest index &lt;math&gt;i&lt;/math&gt; such that &lt;math&gt;\mathrm{BITMAP}[i] = 0&lt;/math&gt;.
# Estimate the cardinality of &lt;math&gt;M&lt;/math&gt; as &lt;math&gt;2^R / \phi&lt;/math&gt;, where &lt;math&gt;\phi \approx 0.77351&lt;/math&gt;.

The idea is that if &lt;math&gt;n&lt;/math&gt; is the number of distinct elements in the multiset &lt;math&gt;M&lt;/math&gt;, then &lt;math&gt;\mathrm{BITMAP}[0]&lt;/math&gt; is accessed approximately &lt;math&gt;n/2&lt;/math&gt; times, &lt;math&gt;\mathrm{BITMAP}[1]&lt;/math&gt; is accessed approximately &lt;math&gt;n/4&lt;/math&gt; times and so on. Consequently, if &lt;math&gt;i \gg \log_2 n&lt;/math&gt;, then &lt;math&gt;\mathrm{BITMAP}[i]&lt;/math&gt; is almost certainly 0, and if &lt;math&gt;i \ll \log_2 n&lt;/math&gt;, then &lt;math&gt;\mathrm{BITMAP}[i]&lt;/math&gt; is almost certainly 1. If &lt;math&gt;i \approx \log_2 n&lt;/math&gt;, then &lt;math&gt;\mathrm{BITMAP}[i]&lt;/math&gt; can be expected to be either 1 or 0.

The correction factor &lt;math&gt;\phi \approx 0.77351&lt;/math&gt; is found by calculations, which can be found in the original article.

==Improving accuracy==
A problem with the Flajolet–Martin algorithm in the above form is that the results vary significantly. A common solution has been to run the algorithm multiple times with &lt;math&gt;k&lt;/math&gt; different hash functions and combine the results from the different runs. One idea is to take the mean of the &lt;math&gt;k&lt;/math&gt; results together from each hash function, obtaining a single estimate of the cardinality. The problem with this is that averaging is very susceptible to outliers (which are likely here). A different idea is to use the [[median]], which is less prone to be influences by outliers. The problem with this is that the results can only take form &lt;math&gt;2^R / \phi&lt;/math&gt;, where &lt;math&gt;R&lt;/math&gt; is integer. A common solution is to combine both the mean and the median: Create &lt;math&gt;k \cdot l&lt;/math&gt; hash functions and split them into &lt;math&gt;k&lt;/math&gt; distinct groups (each of size &lt;math&gt;l&lt;/math&gt;). Within each group use the median for aggregating together the &lt;math&gt;l&lt;/math&gt; results, and finally take the mean of the &lt;math&gt;k&lt;/math&gt; group estimates as the final estimate.

The 2007 [[HyperLogLog]] algorithm splits the multiset into subsets and estimates their cardinalities, then it uses the [[harmonic mean]] to combine them into an estimate for the original cardinality.&lt;ref name="flajolet07"/&gt;

== See also ==
* [[Streaming algorithm]]
* [[HyperLogLog]]

==References==
{{reflist}}

== Additional sources==
* {{cite book |last1=Rajaraman |first1=Anand |last2=Ullman |first2=Jeffrey David |title=Mining of Massive Datasets |url=https://books.google.com/books?id=OefRhZyYOb0C&amp;pg=PA119 |accessdate=2014-11-09 |date=2011-10-27 |publisher=[[Cambridge University Press]] |isbn=9781139505345 |page=119 &lt;!-- NEEDS END PAGE --&gt; }}

{{DEFAULTSORT:Flajolet-Martin algorithm}}
[[Category:Algorithms]]</text>
      <sha1>7t2dz4rk9t6dkkmxeidtml3tzoikbe6</sha1>
    </revision>
  </page>
  <page>
    <title>Forensic statistics</title>
    <ns>0</ns>
    <id>40081829</id>
    <revision>
      <id>867816622</id>
      <parentid>867815219</parentid>
      <timestamp>2018-11-08T04:58:42Z</timestamp>
      <contributor>
        <username>Samanthacaitlyn3</username>
        <id>35069457</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11355">{{Forensic science|disciplines|image=Road traffic accidents world map - Death - WHO2012.svg}}
'''Forensic statistics''' is the application of [[Statistical model|probability models]] and [[Statistics|statistical techniques]] to scientific evidence, such as [[DNA profiling|DNA evidence]],&lt;ref name="Gill"&gt;{{cite web|url=http://www.math.leidenuniv.nl/~gill/forensic.statistics.pdf|title=Forensic Statistics: Ready for Consumption?|first=Richard|last=Gill|publisher=Mathematical Institute, Leiden University}}&lt;/ref&gt; and the law. In contrast to "everyday" statistics, to not engender bias or unduly draw conclusions, forensic statisticians report likelihoods as [[Likelihood function|likelihood ratios]] (LR). This ratio of probabilities is then used by [[jury|juries]] or [[judge]]s to draw inferences or conclusions and decide legal matters.&lt;ref name="Gill"/&gt; Jurors and judges rely on the strength of a DNA match, given by statistics, to make conclusions and determine guilt or innocence in legal matters.&lt;ref name="Perlin"&gt;{{cite journal |last1=Perlin |first1=Mark |title=Inclusion probability for DNA mixtures is a subjective one-sided match statistic unrelated to identification information |journal=Journal of Pathology Informatics |date=2015 |volume=6 |issue=59 |url=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4639950/ |accessdate=6 November 2018}}&lt;/ref&gt;

In forensic science, the DNA evidence received for [[DNA profiling]] often contains a mixture of more than one person’s DNA. DNA profiles are generated using a set procedure, however, the interpretation of a DNA profile becomes more complicated when the sample contains a mixture of DNA. Regardless of the number of contributors to the forensic sample, statistics and probabilities must be used to provide weight to the evidence and to describe what the results of the DNA evidence mean. In a single-source DNA profile, the statistic used is termed a random match probability (RMP). RMPs can also be used in certain situations to describe the results of the interpretation of a [[DNA profiling|DNA mixture]]. &lt;ref name="Butler"&gt;{{cite book |last1=Butler |first1=John |title=Forensic DNA Typing |date=2005 |publisher=Elsevier Academic Press |pages=445-529 |edition=2nd}}&lt;/ref&gt; Other statistical tools to describe DNA mixture profiles include likelihood ratios (LR) and combined probability of inclusion (CPI), also known as random man not excluded (RMNE).&lt;ref name="Butler2"&gt;{{cite book |last1=Butler |first1=John |title=Advanced Topics in Forensic DNA Typing: Interpretation |date=2015 |publisher=Elsevier Inc. |location=San Diego, CA |pages=213-333}}&lt;/ref&gt;

Computer programs have been implemented with forensic DNA statistics for assessing the biological relationships between two or more people. Forensic science uses several approaches for DNA statistics with computer programs such as; match probability, exclusion probability, likelihood  ratios, Bayesian approaches, and paternity and kinship testing.&lt;ref&gt;{{Cite journal|url = |title = On Statistical Analysis Of Forensic DNA: Theory, Methods And Computer Programs|last = Fung|first = Wing Kam|date = 2006|journal = Forensic Science International|doi = 10.1016/j.forsciint.2006.06.025|pmid = |access-date =|volume=162|pages=17–23}}&lt;/ref&gt;

Although the precise origin of this term remains unclear, it is apparent that the term was used in the 1980s and 1990s.&lt;ref&gt;{{cite journal | last1 = Valentin | first1 = J | year = 1980 | title = Exclusions and attributions of paternity: practical experiences of forensic genetics and statistics | url = | journal = Am J Hum Genet | volume = 32 | issue = 3| pages = 420–31 }}&lt;/ref&gt; Among the first forensic statistics conferences were two held in 1991 and 1993.&lt;ref&gt;Aitken C. G. G., Taroni F. (2004) [https://books.google.com/books?id=5qvLJXYQ5wEC&amp;pg=PR26&amp;lpg=PR26&amp;source=bl&amp;ots=RmrRyl5DOu&amp;sig=F0kgZ3FoAzbVtqHt3ls6bgxzno4&amp;hl=en&amp;sa=X&amp;ei=_ZDzUfX4H8GMkwWCjIGIDg&amp;ved=0CIMBEOgBMAw4Hg#v=onepage&amp;f=false ''Statistics and the Evaluation of Evidence for Forensic Scientists''], John Wiley and Sons.&lt;/ref&gt;

== Random Match Probability ==

Random match probabilities (RMP) are used to estimate and express the rarity of a DNA profile. RMP can be defined as the probability that someone else in the population, chosen at random, would have the same genotype as the genotype of the contributor of the forensic evidence. RMP is calculated using the [[genotype frequencies]] at all the loci, or how common or rare the alleles of a genotype are. The genotype frequencies are multiplied across all loci, using the [[product rule]], to calculate the RMP. This statistic gives weight to the evidence either for or against a particular suspect being a contributor to the DNA mixture sample.&lt;ref name="Butler2"/&gt;

RMP can only be used as a statistic to describe the DNA profile if it is from a single source or if the analyst is able to differentiate between the peaks on the [[electropherogram]] from the major and minor contributors of a mixture.&lt;ref name="Butler"/&gt; Since the interpretation of DNA mixtures with more than two contributors is very difficult for analysts to do without computer software, RMP becomes difficult to calculate with a mixture of more than two people.&lt;ref name="Butler2"/&gt; If the major and minor contributor peaks can not be differentiated, there are other statistical methods that may be used. 

If the DNA mixture contains a ratio of 4:1 of major to minor contributors, a modified random match probability (mRMP) may be able to be used as a statistical tool. For calculation of mRMP, the analyst must first deduce a major and minor contributor and their genotypes based on the peak heights given in the electropherogram. Computer software is often used in labs conducting DNA analysis in order to more accurately calculate the mRMP, since calculations for each of the most probable genotypes at each locus become tedious and inefficient for the analyst to do by hand.&lt;ref name="Perlin"/&gt;

== Likelihood Ratio ==

Sometimes it can be very difficult to determine the number of contributors in a DNA mixture. If the peaks are easily distinguished and the number of contributors is able to be determined, a likelihood ratio (LR) is used. LRs consider probabilities of events happening and rely on alternative pairs of hypotheses against which the evidence is assessed.&lt;ref name="FSS"&gt;{{cite web |title=What is a likelihood ratio? |url=https://www.isfg.org/files/ISFG2007_Statistics_Gill_LR.pdf |website=International Society of Forensic Genetics |publisher=Forensic Science Service Ltd. 2006 |accessdate=6 November 2018}}&lt;/ref&gt; These alternative pairs of hypotheses in forensic cases are the prosecutor’s hypothesis and the defense hypothesis. In forensic biology cases, the hypotheses often state that the DNA came from a particular person or the DNA came from an unknown person.&lt;ref name="Perlin"/&gt; For example, the prosecution may hypothesize the DNA sample contains DNA from the victim and the suspect, while the defense may hypothesize that the sample contains DNA from the victim and an unknown person. The probabilities of the hypotheses are expressed as a ratio, with the prosecutor’s hypothesis being in the numerator.&lt;ref name="Butler"/&gt; The ratio then expresses the likelihood of both of the events in relation to each other. For the hypotheses where the mixture contains the suspect, the probability is 1, because one can distinguish the peaks and easily tell if the suspect can be excluded as a contributor at each locus based on his/her genotype. The probability of 1 assumes the suspect can not be excluded as a contributor. To determine the probabilities of the unknowns, all genotype possibilities must be determined for that locus.&lt;ref name="Butler"/&gt; 

Once the calculation of the likelihood ratio is made, the number calculated is turned into a statement to provide meaning to the statistic. For the previous example, if the LR calculated is x, then the LR means that the probability of the evidence is x times more likely if the sample contains the victim and the suspect than if it contains the victim and an unknown person.&lt;ref name="FSS"/&gt; Likelihood ratio can also be defined as 1/RMP.&lt;ref name="Butler"/&gt;   

== Combined Probability of Inclusion ==

Combined probability of inclusion (CPI) is a common statistic used when the analyst can not differentiate between the peaks from a major and minor contributor to a sample and the number of contributors can not be determined.&lt;ref name="Butler"/&gt; CPI is also commonly known as random man not excluded (RMNE).&lt;ref name="Butler"/&gt; This statistical calculation is done by adding all the frequencies of observed alleles and then squaring the value, which yields the value for probability of inclusion (PI). These values are then multiplied across all loci, resulting in the value for CPI.&lt;ref name="Perlin"/&gt; The value is squared so that all the possible combinations of genotypes are included in the calculation.&lt;ref name="Butler2"/&gt; 

Once the calculation is done, a statement is made about the meaning of this calculation and what it means. For example, if the CPI calculated is 0.5, this means that the probability of someone chosen at random in the population not being excluded as a contributor to the DNA mixture is 0.5. 

CPI relates to the evidence (the DNA mixture) and it is not dependent on the profile of any suspect. Therefore, CPI is a statistical tool that can be used to provide weight or strength to evidence when no other information about the crime is known.&lt;ref name="Butler"/&gt; This is advantageous in situations where the genotypes in the DNA mixture can not be distinguished from one another. However, this statistic is not very discriminating and is not as powerful of a tool as likelihood ratios and random match probabilities can be when some information about the DNA mixture, such as the number of contributors or the genotypes of each contributor, can be distinguished. Another limitation to CPI is that it is not usable as a tool for the interpretation of a DNA mixture.&lt;ref name="Butler2"/&gt;

== Blood Stains ==
Blood stains are an important part of forensic statistics, as the analysis of blood drop collisions may help to picture the event that had previously gone on. Commonly blood stains are an elliptical shape, because of this blood stains are usually easy to determine the blood droplets angle through the formula “''α = arcsin d/a''”. In this formula 'a' and 'd' are simply estimations of the axis of the ellipse. From these calculations, a visualization of the event causing the stains is able to be drawn, and alongside further information such as the velocity of the entity that caused such stains.''&lt;ref&gt;{{Cite journal|url = |title = Determining The Area Of Convergence In Bloodstain Pattern Analysis: A Probabilistic Approach|last = Camana|first = Francesco|date = 2013|journal = Forensic Science International|doi = 10.1016/j.forsciint.2013.04.019|pmid = |access-date =|volume=231|pages=131–136|arxiv =1210.6106}}&lt;/ref&gt;

==Bibliography==
*Lucy, D. (2005.) ''Introduction to Statistics for Forensic Scientists'', John Wiley and Sons.

==References==
{{Reflist}}

==External links==
{{Empty section|date=January 2014|section=}}

[[Category:Applied statistics]]
[[Category:Forensic disciplines|Statistics]]
[[Category:Forensic statistics|*]]


{{Forensics-stub}}</text>
      <sha1>n999z6jq46ersfnihz16tmcxmpo06my</sha1>
    </revision>
  </page>
  <page>
    <title>Fractional coloring</title>
    <ns>0</ns>
    <id>692369</id>
    <revision>
      <id>836450602</id>
      <parentid>797677863</parentid>
      <timestamp>2018-04-14T22:12:30Z</timestamp>
      <contributor>
        <username>JoshuaZ</username>
        <id>799863</id>
      </contributor>
      <comment>/* Definitions */ Changing Kneser graph (a,b) to new variables (m,n) so as not to confuse with a, b from above</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8108">[[Image:Graph fractional coloring.svg|right|thumb| 5:2-coloring of [[Dodecahedron|Dodecahedral graph]]. A 4:2-coloring of
this graph does not exist.]]

'''Fractional coloring''' is a topic in a young branch of [[graph theory]] known as [[fractional graph theory]]. It is a generalization of ordinary [[graph coloring]]. In a traditional graph coloring, each vertex in a graph is assigned some color, and adjacent vertices — those connected by edges — must be assigned different colors. In a fractional coloring however, a ''set'' of colors is assigned to each vertex of a graph. The requirement about adjacent vertices still holds, so if two vertices are joined by an edge, they must have no colors in common.

Fractional graph coloring can be viewed as the [[linear programming relaxation]] of traditional graph coloring. Indeed, fractional coloring problems are much more amenable to a linear programming approach than traditional coloring problems.

==Definitions==
[[File:Fractional coloring of C5.png|thumb|Above:A 3:1-coloring of the cycle on 5 vertices, and the corresponding 6:2-coloring.&lt;br/&gt;Below: A 5:2 coloring of the same graph.]]
A '''''b''-fold coloring''' of a graph ''G'' is an assignment of sets of size ''b'' to vertices of a graph such that adjacent vertices receive disjoint sets.
An '''''a'':''b''-coloring''' is a ''b''-fold coloring out of ''a'' available colors.
Equivalently, it can be defined as a homomorphism to the [[Kneser graph]] {{math|''KG''&lt;sub&gt;''a'',''b''&lt;/sub&gt;}}.
The '''''b''-fold chromatic number''' &amp;chi;&lt;sub&gt;''b''&lt;/sub&gt;(''G'') is the least ''a'' such that an ''a'':''b''-coloring exists.

The '''fractional chromatic number''' &amp;chi;&lt;sub&gt;f&lt;/sub&gt;(''G'') is defined to be

:&lt;math&gt;\chi_{f}(G) = \lim_{b \to \infty}\frac{\chi_{b}(G)}{b} = \inf_{b}\frac{\chi_{b}(G)}{b}&lt;/math&gt;

Note that the limit exists because &amp;chi;&lt;sub&gt;''b''&lt;/sub&gt;(''G'') is ''[[subadditive function|subadditive]]'', meaning &amp;chi;&lt;sub&gt;''a''+''b''&lt;/sub&gt;(''G'') &amp;le; &amp;chi;&lt;sub&gt;''a''&lt;/sub&gt;(''G'') + &amp;chi;&lt;sub&gt;''b''&lt;/sub&gt;(''G'').

The fractional chromatic number can equivalently be defined in probabilistic terms. &amp;chi;&lt;sub&gt;f&lt;/sub&gt;(''G'') is the smallest ''k'' for which there exists a probability distribution over the [[Independent set (graph theory)|independent sets]] of ''G'' such that for each vertex ''v'', given an independent set ''S'' drawn from the distribution, 
:&lt;math&gt;\Pr(v\in S) \geq \frac{1}{k}&lt;/math&gt;.

Some properties of &amp;chi;&lt;sub&gt;''f''&lt;/sub&gt;(''G''):

:&lt;math&gt;\chi_f(G)\ge n(G)/\alpha(G)&lt;/math&gt;
and
:&lt;math&gt;\omega(G) \le \chi_f(G) \le \chi(G)&lt;/math&gt;.
Furthermore, the fractional chromatic number approximates the chromatic number within a logarithmic factor,&lt;ref&gt;[[László Lovász]]: "[https://dx.doi.org/10.1016/0012-365X(75)90058-8 On the ratio of optimal integral and fractional covers]", Discrete Math. 13:4(1975), p. 383-390.&lt;/ref&gt; in fact:
:&lt;math&gt; \frac{\chi(G)}{1+\ln \alpha(G)} \le \chi_f(G) \le \frac{\chi_b(G)}{b} \le \chi(G).&lt;/math&gt;

Here n(''G'') is the [[glossary of graph theory#Basics|order]] of ''G'', &amp;alpha;(''G'') is the [[independence number]], &amp;omega;(''G'') is the [[clique number]], and &amp;chi;(''G'') is the [[chromatic number]].
Kneser graphs give examples where &amp;chi;(''G'')/&amp;chi;&lt;sub&gt;f&lt;/sub&gt;(''G'') is arbitrarily large, since &amp;chi;({{math|''KG''&lt;sub&gt;''m'',''n''&lt;/sub&gt;}})=''m''-2''n''+2, while &amp;chi;&lt;sub&gt;f&lt;/sub&gt;({{math|''KG''&lt;sub&gt;''m'',''n''&lt;/sub&gt;}})=''m''/''n''.

==Linear Programming (LP) Formulation==
The fractional chromatic number &amp;chi;&lt;sub&gt;f&lt;/sub&gt;(''G'')  of a graph  ''G'' can be obtained as a solution to a [[linear programming|linear program]].  Let &lt;math&gt;\mathcal{I}&lt;/math&gt;(''G'') be the set of all independent sets of ''G'', and let &lt;math&gt;\mathcal{I}&lt;/math&gt;(''G'',''x'') be the set of all those independent sets which include vertex ''x''. For each independent set ''I'', define a nonnegative real variable ''x&lt;sub&gt;I&lt;/sub&gt;''. Then &amp;chi;&lt;sub&gt;f&lt;/sub&gt;(''G'') is the minimum value of
: &lt;math&gt;\sum_{I\in\mathcal{I}(G)} x_I\,&lt;/math&gt;,
: subject to &lt;math&gt;\sum_{I\in\mathcal{I}(G,x)} x_I \ge 1&lt;/math&gt; for each vertex &lt;math&gt;x&lt;/math&gt;.

The [[dual problem|dual]] of this linear program computes the "fractional clique number", a relaxation to the rationals of the integer concept of [[clique number]]. That is, a weighting of the vertices of ''G'' such that the total weight assigned to any independent set is at most ''1''. The [[strong duality]] theorem of linear programming guarantees that the optimal solutions to both linear programs have the same value. Note however that each linear program may have size that is exponential in the number of vertices of ''G'', and that computing the fractional chromatic number of a graph is [[NP-hard]].&lt;ref&gt;[[Carsten Lund]] and [[Mihalis Yannakakis]]: "[https://dx.doi.org/10.1145/185675.306789 On the hardness of approximating minimization problems]", J. ACM 41:5(1994), p. 960-981.&lt;/ref&gt;  This stands in contrast to the problem of fractionally coloring the edges of a graph, which can be solved in polynomial time. This is a straightforward consequence of Edmonds' matching polytope theorem.&lt;ref&gt;Bruce Hajek and Galen Sasaki: "[https://dx.doi.org/10.1109/18.21215 Link scheduling in polynomial time]", IEEE Transactions on Information Theory 34:5(1988), p. 910-917.&lt;/ref&gt;&lt;ref name=schrijver&gt;{{cite book|last=Schrijver|first=Alexander|title=Combinatorial Optimization: Polyhedra and Efficiency|year=2003|publisher=Springer-Verlag|location=Berlin ; Heidelberg ; New York, N.Y.|isbn=3540443894|pages=474}}&lt;/ref&gt;

==Applications==
Applications of fractional graph coloring include ''activity scheduling''. In this case, the graph ''G'' is a ''conflict graph'': an edge in ''G'' between the nodes ''u'' and ''v'' denotes that ''u'' and ''v'' cannot be active simultaneously. Put otherwise, the set of nodes that are active simultaneously must be an independent set in graph ''G''.

An optimal fractional graph coloring in ''G'' then provides a shortest possible schedule, such that each node is active for (at least) 1 time unit in total, and at any point in time the set of active nodes is an independent set. If we have a solution ''x'' to the above linear program, we simply traverse all independent sets ''I'' in an arbitrary order. For each ''I'', we let the nodes in ''I'' be active for &lt;math&gt;x_I&lt;/math&gt; time units; meanwhile, each node not in ''I'' is inactive.

In more concrete terms, each node of ''G'' might represent a ''radio transmission'' in a wireless communication network; the edges of ''G'' represent ''interference'' between radio transmissions. Each radio transmission needs to be active for 1 time unit in total; an optimal fractional graph coloring provides a minimum-length schedule (or, equivalently, a maximum-bandwidth schedule) that is conflict-free.

===Comparison with traditional graph coloring===
If one further required that each node must be active ''continuously'' for 1 time unit (without switching it off and on every now and then), then traditional graph [[vertex coloring]] would provide an optimal schedule: first the nodes of color 1 are active for 1 time unit, then the nodes of color 2 are active for 1 time unit, and so on. Again, at any point in time, the set of active nodes is an independent set.

In general, fractional graph coloring provides a shorter schedule than non-fractional graph coloring; there is an [[integrality gap]]. It may be possible to find a shorter schedule, at the cost of switching devices (such as radio transmitters) on and off more than once.

==Notes==
&lt;references /&gt;

==References==
*{{citation
 | last1 = Scheinerman | first1 = Edward R. | author1-link = Ed Scheinerman
 | last2 = Ullman | first2 = Daniel H.
 | isbn = 0-471-17864-0
 | location = New York
 | publisher = Wiley-Interscience
 | title = Fractional graph theory
 | year = 1997}}.
*{{citation
 | last1 = Godsil | first1 = Chris | author1-link = Chris Godsil
 | last2 = Royle | first2 = Gordon | author2-link = Gordon Royle
 | isbn = 0-387-95241-1
 | location = New York
 | publisher = Springer-Verlag
 | title = Algebraic Graph Theory
 | year = 2001}}.

[[Category:Graph coloring]]</text>
      <sha1>nkg9p9o1gq60t68qiw6p54e89jrylnf</sha1>
    </revision>
  </page>
  <page>
    <title>G2 manifold</title>
    <ns>0</ns>
    <id>648062</id>
    <revision>
      <id>870910178</id>
      <parentid>869313614</parentid>
      <timestamp>2018-11-27T19:09:33Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>[[User:JCW-CleanerBot#Logic|task]], replaced: Comptes rends de l'Académie des Sciences → Comptes Rendus de l'Académie des Sciences</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6081">{{DISPLAYTITLE:G&lt;sub&gt;2&lt;/sub&gt; manifold}}
In [[differential geometry]], a '''''G''&lt;sub&gt;2&lt;/sub&gt; manifold''' is a seven-dimensional [[Riemannian manifold]] with [[holonomy group]] contained in [[G2 (mathematics)|''G''&lt;sub&gt;2&lt;/sub&gt;]]. The [[group (mathematics)|group]] &lt;math&gt;G_2&lt;/math&gt; is one of the five exceptional [[simple Lie group]]s. It can be described as the [[automorphism group]] of the [[octonions]], or equivalently, as a proper subgroup of [[special orthogonal group]] SO(7) that preserves a [[spinor]] in the eight-dimensional [[spinor representation]] or lastly as the subgroup of the [[general linear group]] GL(7) which preserves the non-degenerate 3-form &lt;math&gt;\phi&lt;/math&gt;, the associative form. The [[Hodge dual]], &lt;math&gt;\psi=*\phi&lt;/math&gt; is then a parallel 4-form, the coassociative form. These forms are [[calibrated geometry|calibrations]] in the sense of Reese Harvey and [[H. Blaine Lawson]],&lt;ref&gt;{{citation | first = Reese | last = Harvey | first2 = H. Blaine | last2 = Lawson|authorlink2=H. Blaine Lawson | title = Calibrated geometries | journal = [[Acta Mathematica]] | volume = 148 | year = 1982 | pages = 47&amp;ndash;157 | doi=10.1007/BF02392726 |mr=0666108}}.&lt;/ref&gt; and thus define special classes of 3- and 4-dimensional submanifolds.

== Properties ==
If ''M'' is a &lt;math&gt;G_2&lt;/math&gt;-manifold, then ''M'' is:
* [[Ricci-flat]],
* [[orientable]],
* a [[spin manifold]].

== History ==
The fact that &lt;math&gt;G_2&lt;/math&gt; might  possibly be the holonomy group of certain Riemannian 7-manifolds was first suggested by the 1955 classification theorem of [[Marcel Berger]], and this remained consistent with the simplified proof later given by [[James Harris Simons|Jim Simons]] in 1962. Although not a single example of such a manifold had yet been discovered, [[Edmond Bonan]] then made an interesting contribution by showing that, 
if such a manifold did in fact exist, it would carry both a  parallel 3-form and  a  parallel 4-form,  and that it would necessarily be   Ricci-flat.&lt;ref&gt;{{citation | first =Edmond| last = Bonan| authorlink=Edmond Bonan| title = Sur les variétés riemanniennes à groupe d'holonomie G2 ou Spin(7)| journal = [[Comptes Rendus de l'Académie des Sciences]] | volume =262| year = 1966  | pages = 127&amp;ndash;129}}.&lt;/ref&gt;
The first local examples of 7-manifolds with holonomy &lt;math&gt;G_2&lt;/math&gt; were finally constructed around 1984 by
[[Robert Bryant (mathematician)|Robert Bryant]], and his full proof of their existence  appeared in the Annals in 1987 
.&lt;ref&gt;{Bryant,  Rober L. (1987)  Metrics with exceptional holonomy,  [[Annals of Mathematics]] (2)126, 525&amp;ndash;576.&lt;/ref&gt;
Next,  complete (but still noncompact) 7-manifolds with holonomy &lt;math&gt;G_2&lt;/math&gt; were constructed by Bryant and Simon Salamon in 1989.&lt;ref&gt;{{citation | last1 = Bryant | first1 = Rober L. |authorlink1=Robert Bryant (mathematician)| first2 =  Simon M. | last2 = Salamon | title = On the construction of some complete metrics with exceptional holonomy | journal = [[Duke Mathematical Journal]] | volume = 58 | year = 1989 | pages = 829&amp;ndash;850 | doi = 10.1215/s0012-7094-89-05839-0|mr=1016448 }}.&lt;/ref&gt; The first compact 7-manifolds with holonomy &lt;math&gt;G_2&lt;/math&gt; were constructed by [[Dominic Joyce]] in 1994, and compact &lt;math&gt;G_2&lt;/math&gt; manifolds are sometimes known as "Joyce manifolds", especially in the physics literature.&lt;ref&gt;{{citation | first = Dominic D. | last = Joyce | authorlink=Dominic Joyce| title = Compact Manifolds with Special Holonomy | series = Oxford Mathematical Monographs | publisher = [[Oxford University Press]] |  isbn = 0-19-850601-5 | year = 2000}}.&lt;/ref&gt; In 2013, it was shown by M. Firat Arikan, Hyunjoo Cho, and Sema Salur that any manifold with a [[spin structure]], and, hence, a &lt;math&gt;G_2&lt;/math&gt;-structure, admits a compatible almost contact metric structure, and an explicit compatible almost contact structure was constructed for manifolds with &lt;math&gt;G_2&lt;/math&gt;-structure.&lt;ref&gt;{{citation | first = M. Firat | last = Arikan | first2 =  Hyunjoo | last2 = Cho | first3 =  Sema | last3 = Salur | title = Existence of compatible contact structures on &lt;math&gt;G_2&lt;/math&gt;-manifolds | journal = Asian J. Math | issue = 2 | volume = 17 | year = 2013  | pages = 321&amp;ndash;334 | doi = 10.4310/AJM.2013.v17.n2.a3 | publisher = International Press of Boston| arxiv = 1112.2951 }}.&lt;/ref&gt; In the same paper, it was shown that certain classes of &lt;math&gt;G_2&lt;/math&gt;-manifolds admit a [[Contact geometry#Contact forms and structures|contact structure]].

== Connections to physics ==
These manifolds are important in [[string theory]]. They break the original [[supersymmetry]] to 1/8 of the original amount. For example, [[M-theory]] compactified on a &lt;math&gt;G_2&lt;/math&gt; manifold leads to a realistic four-dimensional (11-7=4) theory with N=1 supersymmetry.  The resulting low energy effective [[supergravity]] contains a single supergravity [[supermultiplet]], a number of [[chiral supermultiplet]]s equal to the third [[Betti number]] of the &lt;math&gt;G_2&lt;/math&gt; manifold and a number of U(1) [[vector supermultiplet]]s equal to the second Betti number.

== See also ==
* [[Spin(7)-manifold]]
* [[Calabi–Yau manifold]]

== References ==
&lt;references /&gt;
* {{citation | last = Bryant | first = R.L. | title = Metrics with exceptional holonomy | journal = Annals of Mathematics | issue = 2 | volume = 126 | year = 1987 | pages = 525&amp;ndash;576 | doi = 10.2307/1971360 | publisher = Annals of Mathematics | jstor = 1971360 |ref = none}}.
* {{citation |last1 =M. Fernandez| last2 =A. Gray | title = Riemannian manifolds with structure group G2| journal = Ann. Mat. Pura Appl.  |  volume = 32| year = 1982| pages = 19&amp;ndash;845 |ref = none}}.
*{{citation | first = Spiro | last = Karigiannis | title = What Is . . . a ''G''&lt;sub&gt;2&lt;/sub&gt;-Manifold? | journal = AMS Notices | volume = 58 | issue = 04 | pages = 580–581 | year = 2011 | url = http://www.ams.org/notices/201104/rtx110400580p.pdf |ref = none}}.
{{String theory topics |state=collapsed}}

[[Category:Differential geometry]]
[[Category:Riemannian geometry]]
[[Category:Structures on manifolds]]</text>
      <sha1>7aymh52catdr94ctz3kezgv5tpoiqdl</sha1>
    </revision>
  </page>
  <page>
    <title>Gordan's lemma</title>
    <ns>0</ns>
    <id>23835696</id>
    <revision>
      <id>765704807</id>
      <parentid>696553499</parentid>
      <timestamp>2017-02-15T23:17:43Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>not a stub; rm see-also redlink</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4322">In [[convex geometry]], '''Gordan's lemma''' states that the [[semigroup]] of integral points in the [[dual cone]] of a rational convex polyhedral cone is finitely generated.&lt;ref&gt;{{harvnb|Cox|loc=Lecture 1. Proposition 1.11.}}&lt;/ref&gt; In [[algebraic geometry]], the [[prime spectrum]] of the [[semigroup algebra]] of such a semigroup is, by definition, an [[affine toric variety]]; thus, the lemma says an affine toric variety is indeed an algebraic variety.  The lemma is named after the German mathematician [[Paul Gordan]] (1837–1912).

== Proof ==
There are topological and algebraic proofs.

=== Topological proof ===
Let &lt;math&gt;\sigma&lt;/math&gt; be the cone as given in the lemma. Let &lt;math&gt;u_1, \dots, u_r&lt;/math&gt; be the integral vectors so that &lt;math&gt;\sigma = \{ x \mid \langle u_i, x \rangle \ge 0, 1 \le i \le r \}.&lt;/math&gt; Then the &lt;math&gt;u_i&lt;/math&gt;'s generate the dual cone &lt;math&gt;\sigma^{\vee}&lt;/math&gt;; indeed, writing ''C'' for the cone generated by &lt;math&gt;u_i&lt;/math&gt;'s, we have: &lt;math&gt;\sigma \subset C^{\vee}&lt;/math&gt;, which must be the equality. Now, if ''x'' is in the semigroup

:&lt;math&gt;S_\sigma = \sigma^\vee \cap \mathbb{Z}^d,&lt;/math&gt;

then it can be written as

:&lt;math&gt;x = \sum_i n_i u_i + \sum_i r_i u_i&lt;/math&gt;

where &lt;math&gt;n_i&lt;/math&gt; are nonnegative integers and &lt;math&gt;0 \le r_i \le 1&lt;/math&gt;. But since ''x'' and the first sum on the right-hand side are integral, the second sum is also integral and thus there can only be finitely many possibilities for the second sum (the topological reason). Hence, &lt;math&gt;S_{\sigma}&lt;/math&gt; is finitely generated.

=== Algebraic proof ===
The proof&lt;ref&gt;{{harvnb|Bruns–Gubeladze|loc=Lemma 4.12.}}&lt;/ref&gt; is based on a fact that a semigroup ''S'' is finitely generated if and only if its semigroup algebra &lt;math&gt;\mathbb{C}[S]&lt;/math&gt; is finitely generated algebra over &lt;math&gt;\mathbb{C}&lt;/math&gt;. To prove Gordan's lemma, by induction (cf. the proof above), it is enough to prove the statement: for any unital subsemigroup ''S'' of &lt;math&gt;\mathbb{Z}^d&lt;/math&gt;,

: If ''S'' is finitely generated, then &lt;math&gt;S^+ = S \cap \{ x \mid \langle x, v \rangle \ge 0 \}&lt;/math&gt;, ''v'' an integral vector, is finitely generated.
Put &lt;math&gt;A = \mathbb{C}[S]&lt;/math&gt;, which has a basis &lt;math&gt;\chi^a, \, a \in S&lt;/math&gt;. It has &lt;math&gt;\mathbb{Z}&lt;/math&gt;-grading given by
:&lt;math&gt;A_n = \operatorname{span} \{ \chi^a \mid a \in S, \langle a, v \rangle = n \}&lt;/math&gt;.
By assumption, ''A'' is finitely generated and thus is Noetherian. It follows from the algebraic lemma below that &lt;math&gt;\mathbb{C}[S^+] = \oplus_0^\infty A_n&lt;/math&gt; is a finitely generated algebra over &lt;math&gt;A_0&lt;/math&gt;. Now, the semigroup &lt;math&gt;S_0 = S \cap \{ x \mid \langle x, v \rangle = 0 \}&lt;/math&gt; is the image of ''S'' under a linear projection, thus finitely generated and so &lt;math&gt;A_0
= \mathbb{C}[S_0]&lt;/math&gt; is finitely generated. Hence, &lt;math&gt;S^+&lt;/math&gt; is finitely generated then.

'''Lemma''': Let ''A'' be a &lt;math&gt;\mathbb{Z}&lt;/math&gt;-graded ring. If ''A'' is a Noetherian ring, then &lt;math&gt;A^+ = \oplus_0^{\infty} A_n&lt;/math&gt; is a finitely generated &lt;math&gt;A_0&lt;/math&gt;-algebra.

Proof: Let ''I'' be the ideal of ''A'' generated by all homogeneous elements of ''A'' of positive degree. Since ''A'' is Noetherian, ''I'' is actually generated by finitely many &lt;math&gt;f_i's&lt;/math&gt;, homogeneous of positive degree. If ''f'' is homogeneous of positive degree, then we can write &lt;math&gt;f = \sum_i g_i f_i&lt;/math&gt; with &lt;math&gt;g_i&lt;/math&gt; homogeneous. If ''f'' has sufficieny large degree, then each &lt;math&gt;g_i&lt;/math&gt; has degree positive and strictly less than that of ''f''. Also, each degree piece &lt;math&gt;A_n&lt;/math&gt; is a finitely generated &lt;math&gt;A_0&lt;/math&gt;-module. (Proof: Let &lt;math&gt;N_i&lt;/math&gt; be an increasing chain of finitely generated submodules of &lt;math&gt;A_n&lt;/math&gt; with union &lt;math&gt;A_n&lt;/math&gt;. Then the chain of the ideals &lt;math&gt;N_i A&lt;/math&gt; stabilizes in finite steps; so does the chain &lt;math&gt;N_i = N_i A \cap A_n.&lt;/math&gt;) Thus, by induction on degree, we see &lt;math&gt;A^+&lt;/math&gt; is a finitely generated &lt;math&gt;A_0&lt;/math&gt;-algebra.

== References ==
{{reflist}}
*D. Cox, [http://www.cs.amherst.edu/~dac/lectures/coxcimpa.pdf Lectures on toric varieties]
*Winfried Bruns and Joseph Gubeladze, ''Polytopes, rings, and K-theory''

== See also ==
*[[Dickson's lemma]]

[[Category:Lemmas]]
[[Category:Convex geometry]]
[[Category:Algebraic geometry]]</text>
      <sha1>0oxyo4nno5q7cslzrwkec3my796719h</sha1>
    </revision>
  </page>
  <page>
    <title>Graham Brightwell</title>
    <ns>0</ns>
    <id>33598275</id>
    <revision>
      <id>806664365</id>
      <parentid>806655572</parentid>
      <timestamp>2017-10-23T12:39:02Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <comment>Rescuing orphaned refs ("ndsu70964" from rev 806460356)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4033">{{Use mdy dates|date=November 2011}}
{{Infobox scientist
|name = Graham Brightwell
|image =Graham R. Brightwell.jpg
|image_size = 
|caption = 
|birth_date = 
|birth_place = 
|death_date = 
|death_place = 
|residence =
|citizenship = 
|nationality = 
|ethnicity = 
|fields = [[Mathematics]]
|workplaces = [[London School of Economics]]
|alma_mater = [[University of Cambridge]]
|doctoral_advisor = [[Béla Bollobás]]
|academic_advisors = 
|doctoral_students= 
|notable_students = 
|known_for = [[Discrete Mathematics]]
|author_abbrev_bot = 
|author_abbrev_zoo = 
|influences = 
|influenced = 
|awards = 
|religion =
|signature = &lt;!--(filename only)--&gt;
|footnotes = 
}}
'''Graham Brightwell''' is a British mathematician working in the field of [[discrete mathematics]].&lt;ref&gt;{{cite web|url=http://dl.acm.org/author_page.cfm?id=81100629874&amp;coll=DL&amp;dl=ACM&amp;trk=0&amp;cfid=53291320&amp;cftoken=75299427|title=recent ACM Publications|publisher=[[Association for Computing Machinery]] |accessdate=November 12, 2011}}&lt;/ref&gt;&lt;ref name="lse"&gt;{{cite web|url=http://www2.lse.ac.uk/researchAndExpertise/Experts/g.r.brightwell@lse.ac.uk|title=University of London&amp;nbsp;– LSE page|publisher=London School of Economics|accessdate=November 12, 2011}}&lt;/ref&gt;

He was a research student at the [[University of Cambridge]] and obtained his [[PhD]] in 1988 writing on "Linear Extensions of Partially Ordered Sets" under the supervision of Béla Bollobás.&lt;ref name="ndsu70964"&gt;{{cite web|url=http://genealogy.math.ndsu.nodak.edu/id.php?id=70964|title=math genealogy|publisher=[[Mathematics Genealogy Project]]|accessdate=November 12, 2011}}&lt;/ref&gt;

He has published nearly 100 papers in [[pure mathematics]], including over a dozen with [[Béla Bollobás]]. His research interests include [[combinatorics|random combinatorial structures]]; partially ordered sets; [[algorithms]]; [[random graphs]]; [[discrete mathematics]] and [[graph theory]].&lt;ref&gt;{{cite web|url=http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brightwell:Graham.html |title=recent Publications |publisher=[[University of Trier]] |accessdate=November 12, 2011 |deadurl=yes |archiveurl=https://web.archive.org/web/20120910061530/http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brightwell%3AGraham.html |archivedate=September 10, 2012 |df=mdy-all }}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.springerlink.com/content/?Author=Graham+Brightwell|title=recent Springer Publications|publisher=[[Springer Science+Business Media]] |accessdate=November 12, 2011}}&lt;/ref&gt;

Professor Brightwell started playing [[Reversi|Othello]] in 1985, after finding himself sharing an apartment with [[Imre Leader]].&lt;ref&gt;{{citation|url=http://www.angelfire.com/il/raanani/inGrBr.html|title=Interview with Graham Brightwell|first=Leonid|last=Shifman|accessdate=2013-10-29|date=c. 2000}}.&lt;/ref&gt; He has finished 3 times as runner-up in the World Othello Championship and is a 5-time British Champion, and has served as chairman of the British Othello Federation and as editor of the British Othello Newsletter.&lt;ref&gt;{{cite web|url=http://www.worldothellofederation.com/historic.asp|title=World Othello Championships|publisher=World Othello Federation|accessdate=November 12, 2011|deadurl=yes|archiveurl=https://web.archive.org/web/20111005065247/http://www.worldothellofederation.com/historic.asp|archivedate=October 5, 2011|df=mdy-all}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.britishothello.org.uk/nationalchampionshipsroh.html|title= British Othello Federation|publisher=British Othello Federation|accessdate=November 12, 2011}}&lt;/ref&gt;

He is currently a Professor at the [[London School of Economics]].

==References==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Brightwell, Graham}}
[[Category:1962 births]]
[[Category:Alumni of the University of Cambridge]]
[[Category:20th-century British mathematicians]]
[[Category:21st-century British mathematicians]]
[[Category:Reversi players]]
[[Category:Combinatorialists]]
[[Category:Academics of the London School of Economics]]
[[Category:Living people]]</text>
      <sha1>43y4txnl6oc6ddyew1cm4qppfoixsmi</sha1>
    </revision>
  </page>
  <page>
    <title>Hermite normal form</title>
    <ns>0</ns>
    <id>9025098</id>
    <revision>
      <id>843493104</id>
      <parentid>835358458</parentid>
      <timestamp>2018-05-29T14:13:07Z</timestamp>
      <contributor>
        <ip>129.88.37.106</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13037">In [[linear algebra]], the '''Hermite normal form''' is an analogue of [[reduced echelon form]] for [[matrix (mathematics)|matrices]] over the [[integer]]s '''Z'''. Just as  [[reduced echelon form]] can be used to solve problems about the solution to the linear system '''Ax=b''' where '''x''' is in '''R&lt;sup&gt;n&lt;/sup&gt;''', the Hermite normal form can solve problems about the solution to the linear system '''Ax=b''' where this time '''x''' is restricted to have integer coordinates only.  Other applications of the Hermite normal form include [[integer programming]],&lt;ref&gt;{{Cite journal|last=Hung|first=Ming S.|last2=Rom|first2=Walter O.|date=1990-10-15|title=An application of the Hermite normal form in integer programming|url=http://www.sciencedirect.com/science/article/pii/0024379590902285|journal=Linear Algebra and its Applications|volume=140|pages=163–179|doi=10.1016/0024-3795(90)90228-5}}&lt;/ref&gt; [[cryptography]],&lt;ref&gt;{{Cite journal|last=Evangelos|first=Tourloupis, Vasilios|date=2013-01-01|title=Hermite normal forms and its cryptographic applications|url=http://ro.uow.edu.au/theses/3788/|publisher=University of Wollongong}}&lt;/ref&gt; and [[abstract algebra]].&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=RFzdBwAAQBAJ|title=Algebra: An Approach via Module Theory|last=Adkins|first=William|last2=Weintraub|first2=Steven|date=2012-12-06|publisher=Springer Science &amp; Business Media|isbn=9781461209232|page=306|language=en}}&lt;/ref&gt;

==Definition==
Various authors may prefer to talk about Hermite normal form in either row-style or column-style.  They are essentially the same up to transposition.

===Row-style Hermite normal form===
An '''m''' by '''n''' matrix '''A''' with integer entries has a (row) Hermite normal form '''H''' if there is a square [[unimodular matrix]] '''U''' where '''H=UA''' and '''H''' has the following restrictions:&lt;ref&gt;{{Cite web|url=http://doc.sagemath.org/html/en/reference/matrices/sage/matrix/matrix_integer_dense.html|title=Dense matrices over the integer ring — Sage Reference Manual v7.2: Matrices and Spaces of Matrices|website=doc.sagemath.org|access-date=2016-06-22}}&lt;/ref&gt;&lt;ref name=":1"&gt;{{Cite book|url=https://books.google.com/books?id=i3RktxvUgB8C|title=Almost Completely Decomposable Groups|last=Mader|first=A.|date=2000-03-09|publisher=CRC Press|isbn=9789056992255|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=-HjrBwAAQBAJ|title=Complexity of Lattice Problems: A Cryptographic Perspective|last=Micciancio|first=Daniele|last2=Goldwasser|first2=Shafi|date=2012-12-06|publisher=Springer Science &amp; Business Media|isbn=9781461508977|language=en}}&lt;/ref&gt;
# '''H''' is upper triangular (that is, '''h&lt;sub&gt;ij&lt;/sub&gt; = 0''' for '''i &gt; j'''), and any rows of zeros are located below any other row.
# The [[Leading coefficient#Linear algebra|leading coefficient]] (the first nonzero entry from the left, also called the [[pivot element|pivot]]) of a nonzero row is always strictly to the right of the leading coefficient of the row above it; moreover, it is positive.
# The elements below pivots are zero and elements above pivots are nonnegative and strictly smaller than the pivot.
The third condition is not standard among authors, for example some sources force non-pivots to be nonpositive&lt;ref&gt;{{Cite web|url=http://mathworld.wolfram.com/HermiteNormalForm.html|title=Hermite Normal Form|last=W.|first=Weisstein, Eric|website=mathworld.wolfram.com|language=en|access-date=2016-06-22}}&lt;/ref&gt;&lt;ref name=":0"&gt;{{Cite book|url=https://books.google.com/books?id=4DwAX3-3ovQC|title=Computer Aided Verification: 21st International Conference, CAV 2009, Grenoble, France, June 26 - July 2, 2009, Proceedings|last=Bouajjani|first=Ahmed|last2=Maler|first2=Oded|date=2009-06-19|publisher=Springer Science &amp; Business Media|isbn=9783642026577|language=en}}&lt;/ref&gt; or place no sign restriction on them.&lt;ref&gt;{{Cite web|url=http://www.mathworks.com/help/symbolic/mupad_ref/linalg-hermiteform.html|title=Hermite normal form of a matrix - MuPAD|website=www.mathworks.com|access-date=2016-06-22}}&lt;/ref&gt; However, these definitions are equivalent by using a different unimodular matrix '''U'''. A unimodular matrix is a square [[Invertible matrix|invertible]] integer matrix whose [[determinant]] is 1 or -1.

===Column-style Hermite normal form===
A m by n matrix '''A''' with integer entries has a (column) Hermite normal form '''H''' if there is a square [[unimodular matrix]] '''U''' where '''H=AU''' and '''H''' has the following restrictions:&lt;ref name=":0" /&gt;&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=c_7xBwAAQBAJ|title=Large Scale Linear and Integer Optimization: A Unified Approach|last=Martin|first=Richard Kipp|date=2012-12-06|publisher=Springer Science &amp; Business Media|isbn=9781461549758|language=en}}&lt;/ref&gt;
# '''H''' is lower triangular, '''h&lt;sub&gt;ij&lt;/sub&gt; = 0''' for '''i &lt; j''', and any columns of zeros are located on the right.
# The [[Leading coefficient#Linear algebra|leading coefficient]] (the first nonzero entry from the top, also called the [[pivot element|pivot]]) of a nonzero column is always strictly below of the leading coefficient of the column before it; moreover, it is positive.
# The elements to the right of pivots are zero and elements to the left of pivots are nonnegative and strictly smaller than the pivot.
Note that the row-style definition has a unimodular matrix '''U''' multiplying '''A''' on the left (meaning '''U''' is acting on the rows of '''A'''), while the column-style definition has the unimodular matrix action on the columns of '''A'''. The two definitions of Hermite normal forms are simply transposes of each other.

==Existence and uniqueness of the Hermite normal form==
Every '''m''' by '''n''' matrix '''A''' with integer entries has a unique '''m by n''' matrix '''H''', such that '''H=UA''' for some square unimodular matrix '''U'''.&lt;ref name=":1" /&gt;&lt;ref name=":3"&gt;{{Cite book|url=https://books.google.com/books?id=zEzW5mhppB8C|title=Theory of Linear and Integer Programming|last=Schrijver|first=Alexander|date=1998-07-07|publisher=John Wiley &amp; Sons|isbn=9780471982326|language=en}}&lt;/ref&gt;&lt;ref name=":2"&gt;{{Cite book|url=https://books.google.com/books?id=5TP6CAAAQBAJ|title=A Course in Computational Algebraic Number Theory|last=Cohen|first=Henri|date=2013-04-17|publisher=Springer Science &amp; Business Media|isbn=9783662029459|language=en}}&lt;/ref&gt;

===Examples===
In the examples below, '''H''' is the Hermite normal form of the matrix '''A''', and '''U''' is a unimodular matrix such that '''UA=H'''.
:&lt;math&gt;
A=\begin{pmatrix}
3 &amp; 3 &amp; 1 &amp; 4 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 19 &amp; 16 \\
0 &amp; 0 &amp; 0 &amp; 3
\end{pmatrix}
\qquad
H=\begin{pmatrix}
3 &amp; 0 &amp; 1 &amp; 1\\
0 &amp; 1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp;19 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 3
\end{pmatrix}
\qquad
U = \left(\begin{array}{rrrr}
1 &amp; -3 &amp; 0 &amp; -1 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; -5 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{array}\right)
&lt;/math&gt;

&lt;math&gt;
A=
\begin{pmatrix}
0&amp;0&amp;5 &amp; 0 &amp; 1 &amp; 4 \\
0&amp;0&amp;0 &amp; -1 &amp; -4 &amp; 99 \\
0&amp;0&amp;0 &amp; 20 &amp; 19 &amp; 16 \\
0&amp;0&amp;0 &amp; 0 &amp; 2 &amp; 1\\
0&amp;0&amp;0 &amp; 0 &amp; 0 &amp; 3\\
0&amp;0&amp;0 &amp; 0 &amp; 0 &amp; 0
\end{pmatrix}
\qquad H=
\begin{pmatrix}
0&amp; 0&amp; 5&amp; 0&amp; 0&amp; 0\\
0&amp; 0&amp; 0&amp; 1&amp; 0&amp; 0\\
0&amp; 0&amp; 0&amp; 0&amp; 1&amp; 0\\
0&amp; 0&amp; 0&amp; 0&amp; 0&amp; 1\\
0&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0\\
0&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0\\
\end{pmatrix}
\qquad U=
\begin{pmatrix}
1 &amp; 100 &amp; 5 &amp; 152 &amp; -3462 &amp; 0 \\
0 &amp; 79 &amp; 4 &amp; 120 &amp; -2735 &amp; 0 \\
0 &amp; 100 &amp; 5 &amp; 153 &amp; -3461 &amp; 0 \\
0 &amp; 40 &amp; 2 &amp; 61 &amp; -1384 &amp; 0
\end{pmatrix}
&lt;/math&gt;

&lt;math&gt;
A = \left(\begin{array}{rrrr}
2 &amp; 3 &amp; 6 &amp; 2 \\
5 &amp; 6 &amp; 1 &amp; 6 \\
8 &amp; 3 &amp; 1 &amp; 1
\end{array}\right)
\qquad
H = \left(\begin{array}{rrrr}
1 &amp; 0 &amp; 50 &amp; -11 \\
0 &amp; 3 &amp; 28 &amp; -2 \\
0 &amp; 0 &amp; 61 &amp; -13
\end{array}\right)
\qquad
U = \left(\begin{array}{rrr}
9 &amp; -5 &amp; 1 \\
5 &amp; -2 &amp; 0 \\
11 &amp; -6 &amp; 1
\end{array}\right)
&lt;/math&gt;

If ''A'' has only one row then either ''H = A'' or ''H = -A'', depending on whether the single row of ''A'' has a positive or negative leading coefficient.

===Algorithms===
There are many algorithms for computing the Hermite normal form dating back to 1851. It was not until 1979 when an algorithm for computing the Hermite normal form that ran in [[strongly polynomial time]] was first developed;&lt;ref&gt;{{Cite journal|last=Kannan|first=R.|last2=Bachem|first2=A.|date=1979-11-01|title=Polynomial Algorithms for Computing the Smith and Hermite Normal Forms of an Integer Matrix|url=http://www.math.tamu.edu/~rojas/kannanbachemhermitesmith79.pdf|journal=SIAM Journal on Computing|volume=8|issue=4|pages=499–507|doi=10.1137/0208040|issn=0097-5397}}&lt;/ref&gt; that is, the number of steps to compute the Hermite normal form is bounded above by a polynomial in the dimensions of the input matrix, and the space used by the algorithm (intermediate numbers) is bounded by a polynomial in the binary encoding size of the numbers in the input matrix. One class of algorithms is based on [[Gaussian elimination]] in that special elementary matrices are repeatedly used.&lt;ref name=":3" /&gt;&lt;ref&gt;{{Cite web|url=http://www.ifor.math.ethz.ch/teaching/lectures/integer_prog_ss10/chapter02|title=Euclidean Algorithm and Hermite Normal Form|last=|first=|date=2 March 2010|website=|publisher=|access-date=25 June 2015}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=c_7xBwAAQBAJ|title=Large Scale Linear and Integer Optimization: A Unified Approach|last=Martin|first=Richard Kipp|date=2012-12-06|publisher=Springer Science &amp; Business Media|isbn=9781461549758|language=en|chapter=Chapter 4.2.4 Hermite Normal Form}}&lt;/ref&gt; The [[Lenstra–Lenstra–Lovász lattice basis reduction algorithm|LLL]] algorithm can also be used to efficiently compute the Hermite normal form.&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=XGjMBQAAQBAJ|title=Lattice Basis Reduction: An Introduction to the LLL Algorithm and Its Applications|last=Bremner|first=Murray R.|date=2011-08-12|publisher=CRC Press|isbn=9781439807040|language=en|chapter=Chapter 14: The Hermite Normal Form}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Havas|first=George|last2=Majewski|first2=Bohdan S.|last3=Matthews|first3=Keith R.|date=1998|title=Extended GCD and Hermite normal form algorithms via lattice basis reduction|url=https://projecteuclid.org/euclid.em/1048515660|journal=Experimental Mathematics|volume=7|issue=2|pages=130-131|issn=1058-6458|via=}}&lt;/ref&gt;

==Applications==

===Lattice calculations===
A typical [[Lattice (group)|lattice]] in '''R&lt;sup&gt;n&lt;/sup&gt;''' has the form &lt;math&gt;
L = \left\{\left. \sum_{i=1}^n \alpha_i a_i \; \right\vert \; \alpha_i \in\Bbb{Z} \right\}
&lt;/math&gt; where the '''a&lt;sub&gt;i&lt;/sub&gt;''' are in '''R&lt;sup&gt;n&lt;/sup&gt;'''. If the ''columns'' of a matrix '''A''' are the '''a&lt;sub&gt;i&lt;/sub&gt;''', the lattice can be associated with the columns of a matrix, and '''A''' is said to be a basis of '''L'''. Because the Hermite normal form is unique, it can be used to answer many questions about two lattice descriptions. For what follows,  &lt;math&gt;
L_A
&lt;/math&gt; denotes the lattice generated by the columns of A. Because the basis is in the columns of the matrix '''A''', the column-style Hermite normal form must be used. Given two bases for a lattice, '''A''' and '''A'&lt;nowiki/&gt;''', the equivalence problem is to decide if &lt;math&gt;L_{A} = L_{A'}.&lt;/math&gt; This can be done by checking if the column-style Hermite normal form of '''A''' and '''A'&lt;nowiki/&gt;''' are the same up to the addition of zero columns. This strategy is also useful for deciding if a lattice is a subset (&lt;math&gt;L_{A} \subseteq L_{A'}&lt;/math&gt; if and only if &lt;math&gt;L_{[A \mid A']} = L_{A'}&lt;/math&gt;), deciding if a vector v is in  a lattice (&lt;math&gt;v \in L_{A}&lt;/math&gt; if and only if &lt;math&gt;L_{[v \mid A]} = L_A&lt;/math&gt;), and for other calculations.&lt;ref&gt;{{Cite web|url=https://cseweb.ucsd.edu/classes/sp14/cse206A-a/lec4.pdf|title=Basic Algorithms|last=Micciancio|first=Daniele|date=|website=|publisher=|access-date=25 June 2016}}&lt;/ref&gt;

===Integer solutions to linear systems===
The linear system '''Ax=b''' has an integer solution '''x''' if and only if the system '''Hy=b''' has an integer solution '''y''' where '''Uy=x''' and '''H''' is the column-style Hermite normal form of '''H'''.&lt;ref name=":3" /&gt;{{Rp|55}} Checking that  '''Hy=b''' has an integer solution is easier than '''Ax=b''' because the matrix '''H''' is triangular.

==Implementations==
Many mathematical software packages can compute the Hermite normal form:
* [[Maple (software)|Maple]] with  [https://www.maplesoft.com/support/help/maple/view.aspx?path=LinearAlgebra%2FHermiteForm HermiteForm]
* [[Wolfram Mathematica|Mathematica]] with [http://reference.wolfram.com/language/ref/HermiteDecomposition.html HermiteDecomposition]
* [[MATLAB]] with  [http://www.mathworks.com/help/symbolic/hermiteform.html hermiteForm]
* [[Number Theory Library|NTL]] with  [http://www.shoup.net/ntl/doc/HNF.cpp.html HNF]
* [[SageMath]] with [http://doc.sagemath.org/html/en/reference/matrices/sage/matrix/matrix_integer_dense.html#sage.matrix.matrix_integer_dense.Matrix_integer_dense.hermite_form hermite_form]

==See also==
*[[Hermite ring]]
*[[Smith normal form]]
*[[Diophantine equation]]

==References==
{{reflist}}

[[Category:Linear algebra]]
[[Category:Matrix normal forms]]</text>
      <sha1>lw4xrhopgfujli2rio0tdre3x78qdod</sha1>
    </revision>
  </page>
  <page>
    <title>History of combinatorics</title>
    <ns>0</ns>
    <id>20885039</id>
    <revision>
      <id>869440925</id>
      <parentid>867304586</parentid>
      <timestamp>2018-11-18T17:00:18Z</timestamp>
      <contributor>
        <ip>178.92.51.5</ip>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16821">The mathematical field of [[combinatorics]] was studied to varying degrees in numerous ancient societies.  Its study in Europe dates to the work of [[Leonardo Fibonacci]] in the 13th century AD, which introduced Arabian and Indian ideas to the continent.  It has continued to be studied in the modern era.

==Earliest records==
[[File:Rhind Mathematical Papyrus.jpg|right|thumb|A portion of the Rhind papyrus.]]

The earliest recorded use of combinatorial techniques comes from problem 79 of the [[Rhind papyrus]], which dates to the 16th century BCE.  The problem concerns a certain geometric series, and has similarities to Fibonacci's problem of counting the number of [[composition (combinatorics)|compositions]] of 1s and 2s that sum to a given total.&lt;ref name="Biggs" /&gt;

In Greece, [[Plutarch]] wrote that [[Xenocrates]] of Chalcedon (396–314 BC) discovered the number of different syllables possible in the Greek language. This would have been the first attempt on record to solve a difficult problem in [[permutations and combinations]].&lt;ref&gt;{{cite book|last1=Heath|first1=Sir Thomas|title=A history of Greek mathematics|date=1981|publisher=Dover|location=New York|isbn=0486240738|edition= Reprod. en fac-sim.}}&lt;/ref&gt;  The claim, however, is implausible: this is one of the few mentions of combinatorics in Greece, and the number they found, 1.002&amp;nbsp;&amp;times;&amp;nbsp;10&lt;sup&gt;&amp;nbsp;12&lt;/sup&gt;, seems too round to be more than a guess.&lt;ref name="Dieudonné" /&gt;&lt;ref name="Gow"&gt;{{cite book
  | last = Gow
  | first = James
  | title = A Short History of Greek Mathematics
  | publisher = AMS Bookstore
  | year = 1968
  | pages = 71
  | url = https://books.google.com/books?id=68sYLQa9FuQC&amp;printsec=frontcover
  | isbn =0-8284-0218-3 }}
&lt;/ref&gt;

The [[Vyākhyāprajñapti|Bhagavati Sutra]] had the first mention of a combinatorics problem; the problem asked how many possible combinations of tastes were possible from selecting tastes in ones, twos, threes, etc. from a selection of six different tastes (sweet, pungent, astringent, sour, salt, and bitter). The Bhagavati is also the first text to mention the [[Binomial coefficient|choose function]].&lt;ref name="India"&gt;{{cite web|title=India|url=http://binomial.csueastbay.edu/India.html|accessdate=2008-03-05}}&lt;/ref&gt; In the second century BC, [[Pingala]] included an enumeration problem in the [[Sanskrit prosody|Chanda Sutra]] (also Chandahsutra) which asked how many ways a six-syllable meter could be made from short and long notes.&lt;ref name="Hall"&gt;{{cite journal|first=Rachel|last=Hall|title=Math for Poets and Drummers-The Mathematics of Meter|date=2005-02-16|url=http://www.sju.edu/~rhall/Rhythms/poets.pdf|accessdate=2008-03-05|format=PDF}}&lt;/ref&gt;&lt;ref name="Kulkarni"&gt;{{cite journal|last=Kulkarni|first=Amba|title=Recursion and Combinatorial Mathematics in Chandashāstra|arxiv=math/0703658|bibcode=2007math......3658K}}&lt;/ref&gt; Pingala found the number of meters that had &lt;math&gt;n&lt;/math&gt; long notes and &lt;math&gt;k&lt;/math&gt; short notes; this is equivalent to finding the [[binomial coefficients]].

The ideas of the Bhagavati were generalized by the Indian mathematician [[Mahavira (mathematician)|Mahavira]] in 850 AD, and Pingala's work on [[Prosody (poetry)|prosody]] was expanded by [[Bhāskara II]]&lt;ref name="India" /&gt;&lt;ref name="Lilavati"&gt;{{cite web
 |last=Bhaskara 
 |authorlink=Bhaskara II 
 |title=The Lilavati of Bhaskara 
 |publisher=Brown University 
 |url=http://www.brown.edu/Departments/History_Mathematics/lilavati.html 
 |accessdate=2008-03-06 
 |archiveurl=https://web.archive.org/web/20080325004552/http://www.brown.edu/Departments/History_Mathematics/lilavati.html 
 |archivedate=2008-03-25 
 |deadurl=yes 
 |df= 
}}&lt;/ref&gt; and [[Hemacandra]] in 1100 AD. Bhaskara was the first known person to find the generalised choice function, although [[Brahmagupta]] may have known earlier.&lt;ref name="Biggs"&gt;{{cite book
 | last = Biggs
 | first = Norman
 |author2=Keith Lloyd |author3=Robin Wilson
  | editor = Ronald Graham |editor2=Martin Grötschel | editor2-link = Martin Grötschel |editor3=László Lovász
 | title = Handbook of Combinatorics
 | year = 1995
 | url = https://books.google.com/books?id=kfiv_-l2KyQC
 | format = Google book
 | accessdate = 2008-03-08
 | publisher = MIT Press
 | isbn = 0-262-57172-2
 | pages = 2163–2188
 | chapter = 44
 }}&lt;/ref&gt; Hemacandra asked how many meters existed of a certain length if a long note was considered to be twice as long as a short note, which is equivalent to finding the [[Fibonacci numbers]].&lt;ref name="Hall" /&gt; 
[[File:Iching-hexagram-37.svg|left|frame|A [[I Ching|hexagram]]]]

The ancient Chinese book of divination [[I Ching]] describes a hexagram as a permutation with repetitions of six lines where each line can be one of two states: solid or dashed. In describing hexagrams in this fashion they determine that there are &lt;math&gt;2^6=64&lt;/math&gt; possible hexagrams. A Chinese monk also may have counted the number of configurations to a game similar to [[Go (board game)|Go]] around 700 AD.&lt;ref name="Dieudonné"&gt;{{cite web
  | last = Dieudonné
  | first = J.
  | title = The Rhind/Ahmes Papyrus - Mathematics and the Liberal Arts
  | work = Historia Math
  | publisher = Truman State University
  | url = https://archive.is/GgX8
  | accessdate = 2008-03-06 }}&lt;/ref&gt; Although China had relatively few advancements in enumerative combinatorics, around 100 AD they solved the [[Lo Shu Square]] which is the [[combinatorial design]] problem of the normal [[magic square]] of order three.&lt;ref name="Biggs" /&gt;&lt;ref name="Swaney"&gt;{{cite web |last=Swaney |first=Mark |title=Mark Swaney on the History of Magic Squares |url=http://www.netmastersinc.com/secrets/magic_squares.htm
|archiveurl=https://web.archive.org/web/20040807015853/http://www.netmastersinc.com/secrets/magic_squares.htm |archivedate=2004-08-07}}&lt;/ref&gt; Magic squares remained an interest of China, and they began to generalize their original &lt;math&gt;3\times3&lt;/math&gt; square between 900 and 1300 AD. China corresponded with the Middle East about this problem in the 13th century.&lt;ref name="Biggs" /&gt; The Middle East also learned about binomial coefficients from Indian work and found the connection to polynomial expansion.&lt;ref name="Middle East"&gt;{{cite web|title=Middle East|url=http://binomial.csueastbay.edu/MidEast.html|accessdate=2008-03-08}}&lt;/ref&gt; The work of Hindus influenced Arabs as seen in the work of [[al-Khalil ibn Ahmad]] who considered the possible arrangements of letters to form syllables. His calculations show an understanding of permutations and combinations. In a passage from the work of Arab mathematician Umar al-Khayyami that dates to around 1100, it is corroborated that the Hindus had knowledge of binomial coefficients, but also that their methods reached the middle east.

In Greece, [[Plutarch]] wrote that Xenocrates discovered the number of different syllables possible in the Greek language. While unlikely, this is one of the few mentions of Combinatorics in Greece. The number they found, 1.002&amp;nbsp;&amp;times;&amp;nbsp;10&lt;sup&gt;&amp;nbsp;12&lt;/sup&gt;, also seems too round to be more than a guess.&lt;ref name="Dieudonné" /&gt;&lt;ref name="Gow"/&gt;

[[Al-Karaji|Abū Bakr ibn Muḥammad ibn al Ḥusayn Al-Karaji]] (c.953-1029) wrote on the binomial theorem and Pascal's triangle. In a now lost work known only from subsequent quotation by [[al-Samaw'al]], [[Al-Karaji]] introduced the idea of argument by mathematical induction.

The [[philosopher]] and [[astronomer]] Rabbi [[Abraham ibn Ezra]] (c. 1140) counted the permutations with repetitions in vocalization of Divine Name.&lt;ref&gt;The short commentary on Exodus 3:13&lt;/ref&gt; He also established the symmetry of [[binomial coefficient]]s, while a closed formula was obtained later by the [[talmudist]] and [[mathematician]] [[Levi ben Gerson]] (better known as Gersonides), in 1321.&lt;ref&gt;[http://ncertbooks.prashanthellina.com/class_11.Mathematics.Mathematics/Ch-07(Permutation%20and%20Combinations%20FINAL%20%2004.01.06).pdf History of Combinatorics], chapter in a textbook.&lt;/ref&gt;
The arithmetical triangle— a graphical diagram showing relationships among the [[binomial coefficient]]s— was presented by mathematicians in treatises dating as far back as the 10th century, and would eventually become known as [[Pascal's triangle]].  Later, in [[Medieval England]], [[campanology]] provided examples of what is now known as [[Hamiltonian cycle]]s in certain [[Cayley graph]]s on permutations.&lt;ref&gt;
Arthur T. White, ”Ringing the Cosets,” ''Amer. Math. Monthly'' '''94''' (1987), no. 8, 721-746; Arthur T. White, ”Fabian Stedman: The First Group Theorist?,” ''Amer. Math. Monthly'' '''103''' (1996), no. 9, 771-778.&lt;/ref&gt;

==Combinatorics in the West==
Combinatorics came to Europe in the 13th century through mathematicians [[Leonardo Fibonacci]] and [[Jordanus de Nemore]]. Fibonacci's [[Liber Abaci]] introduced many of the Arabian and Indian ideas to Europe, including that of the Fibonacci numbers.&lt;ref name="Devlin"&gt;{{cite web
|url=http://www.maa.org/devlin/devlin_10_02.html 
|title= The 800th birthday of the book that brought numbers to the west
|accessdate= 2008-03-08
|last= Devlin
|first= Keith
|date=October 2002

|work=Devlin's Angle 
}}&lt;/ref&gt;&lt;ref name="Fibonacci"&gt;{{cite web
|url= http://science.jrank.org/pages/2705/Fibonacci-Sequence-History.html
|title= Fibonacci Sequence- History
|accessdate= 2008-03-08
|year= 2008
|publisher= Net Industries
}}&lt;/ref&gt; Jordanus was the first person to arrange the binomial coefficients in a triangle, as he did in proposition 70 of ''De Arithmetica''. This was also done in the Middle East in 1265, and China around 1300.&lt;ref name="Biggs" /&gt; Today, this triangle is known as [[Pascal's triangle]].

[[Blaise Pascal|Pascal]]'s contribution to the triangle that bears his name comes from his work on formal proofs about it, and the connections he made between Pascal's triangle and probability.&lt;ref name="Biggs" /&gt; From a letter [[Gottfried Wilhelm Leibniz|Leibniz]] sent to [[Daniel Bernoulli]] we learn that Leibniz was formally studying the mathematical theory of [[Partition (number theory)|partitions]] in the 17th century, although no formal work was published. Together with Leibniz, Pascal published [[De Arte Combinatoria]] in 1666 which was reprinted later.&lt;ref&gt;Leibniz's habilitation thesis ''[[De Arte Combinatoria]]'' was published as a book in 1666 and reprinted later''&lt;/ref&gt; Pascal and Leibniz are considered the founders of modern combinatorics.&lt;ref name="Dickson"&gt;{{cite book
 | last = Dickson
 | first = Leonard
 | title = Diophantine Analysis
 | origyear = 1919
 | series = [[History of the Theory of Numbers]]
 | year = 2005
 | publisher = Dover Publications, Inc.
 | location = Mineola, New York
 | isbn = 0-486-44233-0
 | pages = 101
 | chapter = Chapter III
 }}&lt;/ref&gt;

Both Pascal and Leibniz understood that the [[binomial expansion]] was equivalent to the [[choice function]]. The notion that algebra and combinatorics corresponded was expanded by De Moivre, who found the expansion of a multinomial.&lt;ref name="De Moivre"&gt;{{cite book
 | last = Hodgson
 | first = James |author2=William Derham |author3=Richard Mead
 | title = Miscellanea Curiosa
 | url = https://books.google.com/books?id=sr04AAAAMAAJ&amp;printsec=titlepage
 | format = Google book
 | accessdate = 2008-03-08
 | series = Volume II
 | year = 1708
 | pages = 183–191
 }}&lt;/ref&gt; De Moivre also found the formula for derangements using the principle of [[Inclusion–exclusion principle|principle of inclusion-exclusion]], a method different from Nikolaus Bernoulli, who had found it previously.&lt;ref name="Biggs" /&gt; De Moivre also managed to approximate the [[binomial coefficient]]s and [[Stirling's approximation|factorial]], and found a closed form for the Fibonacci numbers by inventing [[generating functions]].&lt;ref name="O'Connor"&gt;
{{cite web
|url= http://www-history.mcs.st-andrews.ac.uk/Biographies/De_Moivre.html
|title= Abraham de Moivre
|accessdate= 2008-03-09
|last= O'Connor
|first= John
|author2=Edmund Robertson
|date=June 2004
 
|work= The MacTutor History of Mathematics archive
}}&lt;/ref&gt;&lt;ref name="Pang"&gt;{{cite book
 | last = Pang
 | first = Jong-Shi
 |author2=Olvi Mangasarian
 | editor = Jong-Shi Pang
 | title = Computational Optimisation 
 | url = https://books.google.com/books?id=kJa15IMxAoIC&amp;printsec=frontcover#PPA5,M1
 | format = Google book
 | accessdate = 2008-03-09 
 | series = Volume 1
 | year = 1999
 | publisher = Kluwer Academic Publishers 
 | location = Netherlands
 | isbn = 0-7923-8480-6
 | pages = 182–183
 | chapter = 10.6 Generating Function
 }}&lt;/ref&gt;

In the 18th century, [[Euler]] worked on problems of combinatorics, and several problems of probability which are linked to combinatorics. Problems Euler worked on include the [[Knights tour]], [[Graeco-Latin square]], [[Eulerian numbers]], and others. To solve the [[Seven Bridges of Königsberg]] problem he invented graph theory, which also led to the formation of [[topology]]. Finally, he broke ground with [[Partition of a set|partitions]] by the use of [[generating functions]].&lt;ref name="Euler Archive"&gt;{{cite web
  | title = Combinatorics and probability
  | url = http://math.dartmouth.edu/~euler/
  | accessdate = 2008-03-08
 }}&lt;/ref&gt;

==Contemporary combinatorics==
In the 19th century, the subject of [[partially ordered set]]s and [[Lattice (order)|lattice theory]] originated in the work of [[Richard Dedekind|Dedekind]], [[Charles Sanders Peirce|Peirce]], and [[Ernst Schröder|Schröder]]. However, it was [[Garrett Birkhoff]]'s seminal work in his book ''Lattice Theory'' published in 1967,&lt;ref&gt;{{cite book|last1=Birkhoff|first1=Garrett|title=Lattice theory|date=1984|publisher=American Mathematical Society|location=Providence, R.I.|isbn=978-0821810255|edition= 3d ed., reprinted with corrections.}}&lt;/ref&gt; and the work of [[John von Neumann]] that truly established the subjects.&lt;ref name = "Stanley" &gt;{{cite book|last1=Stanley|first1=Richard P.|title=Enumerative combinatorics.|date=2012|publisher=Cambridge University Press|location=Cambridge|isbn=1107602629|pages=391–393|edition= 2nd.}}&lt;/ref&gt; In the 1930s, [[Philip Hall|Hall]] (1936) and [[Louis Weisner|Weisner]] (1935) independently stated the general Möbius inversion formula.&lt;ref&gt;{{cite journal|last1=Bender|first1=Edward A.|last2=Goldman|first2=J.&amp;nbsp;R.|title=On the applications of Möbius inversion in combinatorial analysis|journal=Amer. Math. Monthly|volume=82|year=1975|pages=789–803|url=http://www.maa.org/programs/maa-awards/writing-awards/on-the-applications-of-m-bius-inversion-in-combinatorial-analysis|doi=10.2307/2319793}}&lt;/ref&gt; In 1964, [[Gian-Carlo Rota | Gian-Carlo Rota's]] ''On the Foundations of Combinatorial Theory I. Theory of Miibius Functions '' introduced poset and lattice theory as theories in Combinatorics.&lt;ref name="Stanley"/&gt; [[Richard P. Stanley]] has had a big impact in contemporary combinatorics for his work in matroid theory,&lt;ref name="matroid"&gt;{{cite journal|last1=Stanley|first1=Richard|title=An introduction to hyperplane arrangements|journal=Geometric Combinatorics|date=2007|volume=13|issue=IAS/Park City Mathematics Series|pages=389–496}}&lt;/ref&gt; for introducing Zeta polynomials,&lt;ref&gt;{{cite journal|last1=Stanley|first1=Richard|title=Combinatorial reciprocity theorems|journal=Advances in Mathematics|date=1974|volume=14|pages=194–253}}&lt;/ref&gt; for explicitly defining Eulerian posets,&lt;ref name="eulerianposets"&gt;{{cite journal|last1=Stanley|first1=Richard|title=Some aspects of groups acting on finite posets|journal=Journal of Combinatorial Theory|date=1982|volume=Ser. A 32|pages=132–161}}&lt;/ref&gt; developing the theory of binomial posets along with Rota and Peter Doubilet,&lt;ref&gt;{{cite journal|last1=Stanley|first1=Richard|title=Binomial posets, M¨obius inversion, and permutation enumeration|journal=Journal of Combinatorial Theory|date=1976|volume=Ser. A 20|pages=336–356}}&lt;/ref&gt; and more.

==Notes==
{{reflist|30em}}

== References ==
* N.L. Biggs, The roots of combinatorics, ''Historia Mathematica'' 6 (1979), 109-136.
* Katz, Victor J. (1998). ''A History of Mathematics: An Introduction'', 2nd Edition. Addison-Wesley Education Publishers. {{ISBN|0-321-01618-1}}.
* O'Connor, John J. and Robertson, Edmund F. (1999–2004). ''[[MacTutor History of Mathematics archive]]''. [[St Andrews University]].
* Rashed, R. (1994). ''The development of Arabic mathematics: between arithmetic and algebra''. London.
* [[Robin Wilson (mathematician)|Wilson, R.]] and Watkins, J. (2013). ''Combinatorics: Ancient &amp; Modern''. Oxford.
* Stanley, Richard (2012). ''Enumerative combinatorics (2nd ed. ed.)'', 2nd Edition. Cambridge University Press. {{ISBN| 1107602629}}.
{{History of science}}

{{DEFAULTSORT:History Of Combinatorics}}
[[Category:History of mathematics|Combinatorics]]
[[Category:Combinatorics|+]]</text>
      <sha1>0f6t54u5otkyujpn0jbtcy65qqdse2u</sha1>
    </revision>
  </page>
  <page>
    <title>Hyperfunction</title>
    <ns>0</ns>
    <id>1678626</id>
    <revision>
      <id>868856975</id>
      <parentid>855628175</parentid>
      <timestamp>2018-11-14T22:06:53Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13185">In [[mathematics]], '''hyperfunctions''' are generalizations of functions, as a 'jump' from one [[holomorphic function]] to another at a boundary, and can be thought of informally as  [[Distribution (mathematics)|distribution]]s of infinite order. Hyperfunctions were introduced by [[Mikio Sato]] in [[#CITEREFSato1958|1958]] in Japanese, ([[#CITEREFSato1959|1959]], [[#CITEREFSato1960|1960]] in English), building upon earlier work by [[Laurent Schwartz]], [[Alexander Grothendieck|Grothendieck]] and others.

== Formulation ==
A hyperfunction on the real line can be conceived of as the 'difference' between one holomorphic function defined on the upper half-plane and another on the lower half-plane. That is, a hyperfunction is specified by a pair (''f'',&amp;nbsp;''g''), where ''f'' is a holomorphic function on the upper half-plane and ''g'' is a holomorphic function on the lower half-plane.

Informally, the hyperfunction is what the difference &lt;math&gt;f -g&lt;/math&gt; would be at the real line itself. This difference is not affected by adding the same holomorphic function to both ''f'' and ''g'', so if h is a holomorphic function on the whole [[complex plane]], the hyperfunctions (''f'',&amp;nbsp;''g'') and (''f''&amp;nbsp;+&amp;nbsp;''h'',&amp;nbsp;''g''&amp;nbsp;+&amp;nbsp;''h'') are defined to be equivalent.

===Definition in one dimension===
The motivation can be concretely implemented using ideas from [[sheaf cohomology]].  Let &lt;math&gt;\mathcal{O}&lt;/math&gt; be the [[sheaf (mathematics)|sheaf]] of [[holomorphic function]]s on &lt;math&gt;\Complex.&lt;/math&gt; Define the hyperfunctions on the [[real line]] as the first [[local cohomology]] group:

:&lt;math&gt;\mathcal{B}(\R) = H^1_{\R}(\Complex , \mathcal{O}).&lt;/math&gt;

Concretely, let &lt;math&gt;\Complex^+&lt;/math&gt; and &lt;math&gt;\Complex^-&lt;/math&gt; be the [[upper half-plane]] and [[lower half-plane]] respectively. Then &lt;math&gt;\Complex^+ \cup \Complex^- = \Complex \setminus \R&lt;/math&gt; so

:&lt;math&gt;H^1_{\R  }(\Complex , \mathcal{O}) = \left [ H^0(\Complex ^+, \mathcal{O}) \oplus H^0(\Complex ^-, \mathcal{O}) \right ] /H^0(\Complex , \mathcal{O}).&lt;/math&gt;

Since the zeroth cohomology group of any sheaf is simply the global sections of that sheaf, we see that a hyperfunction is a pair of holomorphic functions one each on the upper and lower complex halfplane modulo entire holomorphic functions.

More generally one can define &lt;math&gt;\mathcal{B}(U)&lt;/math&gt; for any open set &lt;math&gt;U\subseteq\R&lt;/math&gt; as the quotient &lt;math&gt;H^0(\tilde{U}\setminus U,\mathcal{O}) / H^0(\tilde{U},\mathcal{O})&lt;/math&gt; where &lt;math&gt;\tilde{U}\subseteq\Complex&lt;/math&gt; is any open set with &lt;math&gt;\tilde{U}\cap\mathbb{R}=U&lt;/math&gt;. One can show that this definition does not depend on the choice of &lt;math&gt;\tilde{U}&lt;/math&gt; giving another reason to think of hyperfunctions as "boundary values" of holomorphic functions.

== Examples ==

*If ''f'' is any holomorphic function on the whole complex plane, then the restriction of ''f'' to the real axis is a hyperfunction, represented by either (''f'',&amp;nbsp;0) or (0,&amp;nbsp;&amp;minus;''f'').
*The [[Heaviside step function]] can be represented as 
::&lt;math&gt;H(x) = \left(-\tfrac{1}{2\pi i}\log(z),-\tfrac{1}{2\pi i}\log(z)-1\right).&lt;/math&gt;

*The [[Dirac delta function|Dirac delta "function"]] is represented by 
::&lt;math&gt;\left(\tfrac{1}{2\pi iz},\tfrac{1}{2\pi iz}\right).&lt;/math&gt;
:This is really a restatement of [[Cauchy's integral formula]]. To verify it one can calculate the integration of ''f'' just below the real line, and subtract integration of ''g'' just above the real line - both from left to right. Note that the hyperfunction can be non-trivial, even if the components are analytic continuation of the same function. Also this can be easily checked by differentiating the Heaviside function.

*If ''g'' is a [[continuous function]] (or more generally a [[distribution (mathematics)|distribution]]) on the real line with support contained in a bounded interval ''I'', then ''g'' corresponds to the hyperfunction (''f'',&amp;nbsp;&amp;minus;''f''), where ''f'' is a holomorphic function on the complement of ''I'' defined by
::&lt;math&gt; f(z)= \frac 1 {2\pi i} \int_{x\in I} g(x) \frac 1 {z-x} \, dx.&lt;/math&gt;
:This function ''f ''  jumps in value by ''g''(''x'') when crossing the real axis at the point ''x''. The formula for ''f'' follows from the previous example by writing ''g'' as the [[convolution]] of itself with the Dirac delta function.

*Using a partition of unity one can write any continuous function (distribution) as a locally finite sum of functions (distributions) with compact support. This can be exploited to extend the above embedding to an embedding &lt;math&gt;\textstyle\mathcal{D}'(\R)\to\mathcal{B}(\R).&lt;/math&gt;
*If ''f'' is any function that is holomorphic everywhere except for an [[essential singularity]] at 0 (for example, ''e''&lt;sup&gt;1/''z''&lt;/sup&gt;), then &lt;math&gt;(f, -f)&lt;/math&gt; is a hyperfunction with [[Support (mathematics)|support]] 0 that is not a distribution. If ''f'' has a pole of finite order at 0 then &lt;math&gt;(f, -f)&lt;/math&gt; is a distribution, so when ''f'' has an essential singularity then &lt;math&gt;(f, -f)&lt;/math&gt; looks like a "distribution of infinite order" at 0. (Note that distributions always have ''finite'' order at any point.)

==Operations on hyperfunctions==

Let &lt;math&gt;U\subseteq\R&lt;/math&gt; be any open subset.

* By definition &lt;math&gt;  \mathcal{B}(U)&lt;/math&gt; is a vector space such that addition and multiplication with complex numbers are well-defined. Explicitly:
::&lt;math&gt;a(f_+,f_-)+b(g_+,g_-) := (af_++bg_+, af_-+bg_-)&lt;/math&gt;

* The obvious restriction maps turn &lt;math&gt; \mathcal{B}&lt;/math&gt; into a [[sheaf (mathematics)|sheaf]] (which is in fact [[flabby sheaf|flabby]]).
* Multiplication with real analytic functions &lt;math&gt;h\in\mathcal{O}(U)&lt;/math&gt; and differentiation are well-defined:
::&lt;math&gt;\begin{align}
h(f_+,f_-) &amp;:= (hf_+, hf_-) \\ [6pt]
\frac{d}{dz}(f_+,f_-) &amp;:= \left (\frac{df_+}{dz},\frac{df_-}{dz} \right)
\end{align}&lt;/math&gt;
:With these definitions &lt;math&gt;\mathcal{B}(U)&lt;/math&gt; becomes a [[D-module]] and the embedding &lt;math&gt;\mathcal{D}'\hookrightarrow\mathcal{B}&lt;/math&gt; is a morphism of D-modules.

* A point &lt;math&gt;a\in U&lt;/math&gt; is called a ''holomorphic point'' of &lt;math&gt;f\in\mathcal{B}(U)&lt;/math&gt; if &lt;math&gt;f&lt;/math&gt; restricts to a real analytic function in some small neighbourhood of &lt;math&gt;a.&lt;/math&gt; If &lt;math&gt;a\leqslant b&lt;/math&gt; are two holomorphic points, then integration is well-defined:
::&lt;math&gt;\int_a^b f := -\int_{\gamma_+} f_+(z) \, dz + \int_{\gamma_-} f_-(z) \, dz&lt;/math&gt;
:where &lt;math&gt;\gamma_{\pm}:[0,1] \to \Complex^{\pm}&lt;/math&gt; are arbitrary curves with &lt;math&gt;\gamma_{\pm}(0)=a, \gamma_{\pm}(1)=b.&lt;/math&gt; The integrals are independent of the choice of these curves because the upper and lower half plane are [[simply connected]].

*Let &lt;math&gt;\mathcal{B}_c(U)&lt;/math&gt; be the space of hyperfunctions with compact support. Via the bilinear form 
::&lt;math&gt;\begin{cases} \mathcal{B}_c(U)\times\mathcal{O}(U)\to\Complex \\
(f,\varphi)\mapsto\int f \cdot \varphi \end{cases}&lt;/math&gt; 
:one associates to each hyperfunction with compact support a continuous linear function on &lt;math&gt;\mathcal{O}(U).&lt;/math&gt; This induces an identification of the dual space, &lt;math&gt;\mathcal{O}'(U),&lt;/math&gt; with &lt;math&gt;\mathcal{B}_c(U).&lt;/math&gt; A special case worth considering is the case of continuous functions or distributions with compact support: If one considers &lt;math&gt;C_c^0(U)&lt;/math&gt; (or &lt;math&gt;\mathcal{E}'(U)&lt;/math&gt;) as a subset of &lt;math&gt;\mathcal{B}(U)&lt;/math&gt; via the above embedding, then this computes exactly the traditional Lebesgue-integral. Furthermore: If &lt;math&gt;u\in\mathcal{E}'(U)&lt;/math&gt; is a distribution with compact support, &lt;math&gt;\varphi\in\mathcal{O}(U)&lt;/math&gt; is a real analytic function, and &lt;math&gt;\operatorname{supp}(u)\subset(a,b)&lt;/math&gt; then 
::&lt;math&gt;\int_a^b u\cdot\varphi = \langle u,\varphi\rangle.&lt;/math&gt; 
:Thus this notion of integration gives a precise meaning to formal expressions like 
::&lt;math&gt;\int_a^b \delta(x) \, dx&lt;/math&gt; 
:which are undefined in the usual sense. Moreover: Because the real analytic functions are dense in &lt;math&gt;\mathcal{E}(U), \mathcal{E}'(U)&lt;/math&gt; is a subspace of &lt;math&gt;\mathcal{O}'(U)&lt;/math&gt;. This is an alternative description of the same embedding &lt;math&gt;\mathcal{E}'\hookrightarrow\mathcal{B}&lt;/math&gt;.

* If &lt;math&gt;\Phi:U\to V&lt;/math&gt; is a real analytic map between open sets of &lt;math&gt;\R&lt;/math&gt;, then composition with &lt;math&gt;\Phi&lt;/math&gt; is a well-defined operator from &lt;math&gt;\mathcal{B}(V)&lt;/math&gt; to &lt;math&gt;\mathcal{B}(U)&lt;/math&gt;:
::&lt;math&gt;f\circ\Phi:=(f_+\circ\Phi,f_-\circ\Phi)&lt;/math&gt;

==See also==
{{Div col}}
*[[Algebraic analysis]]
*[[Generalized function]]
*[[Distribution (mathematics)]]
*[[Microlocal analysis]]
*[[Pseudo-differential operator]]
*[[Sheaf cohomology]]
{{Div col end}}

== References ==
*{{Citation
 |last=Imai
 |first=Isao
 |authorlink=Isao Imai (physicist)
 |origyear=1992
 |year=2012
 |title=Applied Hyperfunction Theory
 |series=Mathematics and its Applications (Book 8)
 |publisher=Springer
 |isbn=978-94-010-5125-5
 |url=https://www.springer.com/book/9780792315070
}}.
*{{Citation
 |last=Kaneko
 |first=Akira
 |date=1988
 |title=Introduction to the Theory of Hyperfunctions
 |publisher=Springer
 |series=Mathematics and its Applications (Book 3)
 |isbn=978-90-277-2837-1
 |url=https://www.springer.com/book/9789027728371
}}
*{{Citation
 |last1=Kashiwara
 |first1=Masaki
 |author-link=Masaki Kashiwara
 |last2=Kawai
 |first2=Takahiro
 |last3=Kimura
 |first3=Tatsuo
 |translator=Kato, Goro
 |origyear=1986
 |date=2017
 |title=Foundations of Algebraic Analysis
 |publisher=Princeton University Press
 |edition=Reprint
 |series=Princeton Legacy Library (Book 5158)
 |volume=PMS-37
 |isbn=978-0-691-62832-5
 |url=https://press.princeton.edu/titles/798.html
}}
*{{Citation
 |editor-last=Komatsu
 |editor-first=Hikosaburo
 |date=1973
 |title=Hyperfunctions and Pseudo-Differential Equations, Proceedings of a Conference at Katata, 1971
 |series=Lecture Notes in Mathematics 287
 |publisher=Springer
 |isbn=978-3-540-06218-9
 |url=https://www.springer.com/book/9783540062189
}}.
**{{Citation
 |last=Komatsu
 |first=Hikosaburo
 |title=Relative cohomology of sheaves of solutions of differential equations
 |pages=192-261
}}.
**{{Citation
 |last1=Sato
 |first1=Mikio
 |last2=Kawai
 |first2=Takahiro
 |last3=Kashiwara
 |first3=Masaki
 |title=Microfunctions and pseudo-differential eauations
 |pages=265-529
}}. - It is called SKK.
*{{Citation
 |last=Martineau
 |first=André
 |authorlink=André Martineau
 |date=1960-1961
 |title=Les hyperfonctions de M. Sato
 |series=Séminaire Bourbaki, Tome 6 (1960-1961), Exposé no. 214
 |publisher=
 |mr=1611794
 |zbl=0122.34902
 |url=http://www.numdam.org/item/SB_1960-1961__6__127_0
}}.
*{{Citation
 |last=Morimoto
 |first=Mitsuo
 |date=1993
 |title=An Introduction to Sato's Hyperfunctions
 |series=Translations of Mathematical Monographs (Book 129)
 |publisher=American Mathematical Society
 |isbn=978-0-82184571-4
 |url=https://bookstore.ams.org/mmono-129/
}}.
*{{Citation
 |editor-last=Pham
 |editor-first=F. L.
 |date=1975
 |title=Hyperfunctions and Theoretical Physics, Rencontre de Nice, 21-30 Mai 1973
 |series=Lecture Notes in Mathematics 449
 |publisher=Springer
 |isbn=978-3-540-37454-1
 |url=https://www.springer.com/book/9783540071518
}}.
**{{Citation
 |last1=Cerezo
 |first1=A.
 |last2=Piriou
 |first2=A.
 |last3=Chazarain
 |first3=J.
 |title=Introduction aux hyperfonctions
 |pages=1-53
}}.
*{{Citation
 |last=Sato
 |first=Mikio
 |author-link=Mikio Sato
 |year=1958
 |title=Cyōkansū no riron (Theory of Hyperfunctions)
 |publisher=Mathematical Society of Japan
 |journal=Sūgaku
 |volume=10
 |issue=1
 |pages=1-27
 |language=ja
 |issn=0039470X
 |doi=10.11429/sugaku1947.10.1
 |url=https://www.jstage.jst.go.jp/article/sugaku1947/10/1/10_1_1/_article/-char/ja/
}}
* {{citation|last=Sato|first=Mikio|title=Theory of Hyperfunctions, I|hdl=2261/6027|journal=Journal of the Faculty of Science, University of Tokyo. Sect. 1, Mathematics, astronomy, physics, chemistry|volume=8|year=1959|issue=1|pages=139–193|mr=0114124}}.
* {{citation|last=Sato|first=Mikio|title=Theory of Hyperfunctions, II|hdl=2261/6031|journal=Journal of the Faculty of Science, University of Tokyo. Sect. 1, Mathematics, astronomy, physics, chemistry|volume=8|year=1960|issue=2|pages=387–437|mr=0132392}}.
*{{Citation
 |last=Schapira
 |first=Pierre
 |authorlink=Pierre Schapira (mathematician)
 |date=1970
 |title=Theories des Hyperfonctions
 |series=Lecture Notes in Mathematics 126
 |publisher=Springer
 |isbn=978-3-540-04915-9
 |url=https://www.springer.com/book/9783540049159
}}.
*{{Citation
 |last=Schlichtkrull
 |first=Henrik 
 |origyear=1984
 |date=2013
 |title=Hyperfunctions and Harmonic Analysis on Symmetric Spaces
 |publisher=Springer
 |edition=Softcover reprint of the original 1st
 |series=Progress in Mathematics
 |isbn=978-1-4612-9775-8
 |url=https://www.springer.com/book/9781461297758
}}

== External links ==
*{{MathWorld|title=Hyperfunction|urlname=Hyperfunction|author=Jacobs, Bryan}}
*{{SpringerEOM |id=Hyperfunction&amp;oldid=16339 |title=Hyperfunction |author-first=A. |author-last=Kaneko }}
[[Category:Algebraic analysis]]
[[Category:Complex analysis]]
[[Category:Generalized functions]]
[[Category:Sheaf theory]]</text>
      <sha1>liitymax3lzfsr34f110l8uhj064l3b</sha1>
    </revision>
  </page>
  <page>
    <title>John Jebb (reformer)</title>
    <ns>0</ns>
    <id>1592773</id>
    <revision>
      <id>788020769</id>
      <parentid>786920644</parentid>
      <timestamp>2017-06-29T00:52:27Z</timestamp>
      <contributor>
        <username>Suslindisambiguator</username>
        <id>12329968</id>
      </contributor>
      <comment>/* References */ added wstitle for EB1911 article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2689">{{Other people|John Jebb}}
[[File:John Jebb (1736–1786).jpg|thumb|John Jebb]]
'''John Jebb''' (1736–1786) was an [[England|English]] [[Anglicanism#Anglican divines|divine]], medical doctor, and religious and political reformer.

==Life==
He was   the son of John  Jebb, [[Dean of Cashel]], a member of  the Irish branch of a distinguished family  which  came  originally from  [[Mansfield]]  in [[Nottinghamshire]]: among his Irish cousins was [[John Jebb (bishop)|John Jebb]],  [[Bishop of Limerick]].    He was educated at [[Peterhouse, Cambridge]], where he was elected fellow in 1761,&lt;ref&gt;{{cite book|title=History of the University and colleges of C ambridge|last=Dyer|first=George|url=https://books.google.com/books?id=9p3qHytrRrYC&amp;dq=senate%20house%20cambridge&amp;lr=&amp;as_brr=1&amp;pg=PP1#v=onepage&amp;q=senate%20house%20cambridge&amp;f=false}}&lt;/ref&gt; having previously been [[Second Wrangler]] at Cambridge in 1757.&lt;ref&gt;{{acad|id=JB754J|name=Jebb, John}}&lt;/ref&gt; He was a man of independent judgement, and he and his wife [[Ann Jebb|Ann]] warmly supported the movement of 1771 for abolishing university and clerical subscription to the [[Thirty-nine Articles]]. In his lectures on the [[Greek Testament]] he is said to have expressed [[Socinian]] views. In 1775 he resigned his [[Suffolk]] church livings, and two years afterwards graduated M.D. at [[St Andrews]]. He practised medicine in London and was elected a fellow of the [[Royal Society]] in 1779. He and Ann continued to be involved in political reform.

==Views==
Like [[Edmund Law]] and [[Francis Blackburne (archdeacon)|Francis Blackburne]], he was an advocate of [[soul sleep]].&lt;ref&gt;Anthony Page ''John Jebb and the Enlightenment origins of British radicalism'' p68&lt;/ref&gt;

==Notes==
{{reflist}}

==References==
* {{EB1911|wstitle=Jebb, John|volume=15|page=299}}
*Gascoigne, John. “[http://www.oxforddnb.com/view/article/14680 Jebb, John (1736–1786)].” ''Oxford Dictionary of National Biography''. Ed. H. C. G. Matthew and Brian Harrison. Oxford: OUP, 2004. Online ed. Ed. Lawrence Goldman. October 2005. 7 May 2007.
*Page, Anthony. ''John Jebb and the Enlightenment Origins of British Radicalism''. Praeger Publishers, 2003. {{ISBN|0-275-97775-7}}

==External links==
*{{worldcat id|lccn-n85-24976}}
*{{UK National Archives ID}}

{{Authority control}}

{{DEFAULTSORT:Jebb, John}}
[[Category:1736 births]]
[[Category:1786 deaths]]
[[Category:Alumni of Peterhouse, Cambridge]]
[[Category:Alumni of the University of St Andrews]]
[[Category:Fellows of Peterhouse, Cambridge]]
[[Category:18th-century Church of England clergy]]
[[Category:Fellows of the Royal Society]]
[[Category:Second Wranglers]]
[[Category:British reformers]]</text>
      <sha1>rlvy6w6o40vvs2eaiabp6m8em8a0kbr</sha1>
    </revision>
  </page>
  <page>
    <title>Leftover hash lemma</title>
    <ns>0</ns>
    <id>7006101</id>
    <revision>
      <id>829749802</id>
      <parentid>829749778</parentid>
      <timestamp>2018-03-10T16:09:56Z</timestamp>
      <contributor>
        <ip>185.25.95.132</ip>
      </contributor>
      <comment>more formatting</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4233">The '''leftover hash lemma''' is a [[lemma (mathematics)|lemma]] in [[cryptography]] first stated by [[Russell Impagliazzo]], [[Leonid Levin]], and [[Michael Luby]].

Imagine that you have a secret [[key (cryptography)|key]] {{math|''X''}} that has {{math|''n''}} uniform random [[bit]]s, and you would like to use this secret key to encrypt a message. Unfortunately, you were a bit careless with the key, and know that an [[adversary (cryptography)|adversary]] was able to learn about {{math|''t'' &lt; ''n''}} bits of that key, but you do not know which. Can you still use your key, or do you have to throw it away and choose a new key? The leftover hash lemma tells us that we can produce a key of about {{math|''n'' - ''t''}} bits, over which the adversary has [[almost all|almost no]] knowledge. Since the adversary knows all but {{math|''n'' - ''t''}} bits, this is [[almost optimal]].

More precisely, the leftover hash lemma tells us that we can extract a length asymptotic to &lt;math&gt;H_\infty(X)&lt;/math&gt; (the [[min-entropy]] of {{math|''X''}}) bits from a [[random variable]] {{math|''X''}} that are almost uniformly distributed. In other words, an adversary who has some partial knowledge about {{math|''X''}}, will have almost no knowledge about the extracted value. That is why this is also called '''privacy amplification''' (see privacy amplification section in the article [[Quantum key distribution]]).

[[Randomness extractor]]s achieve the same result, but use (normally) less randomness.

Let {{math|''X''}} be a random variable over &lt;math&gt;\mathcal{X}&lt;/math&gt; and let &lt;math&gt;m &gt; 0&lt;/math&gt;. Let &lt;math display="inline"&gt;h\colon \mathcal{S} \times \mathcal{X} \rightarrow \{0,\, 1\}^m&lt;/math&gt; be a [[K-independent hashing|2-universal]] [[hash function]]. If 
:&lt;math display="inline"&gt;m \leq H_\infty(X) - 2 \log\left(\frac{1}{\varepsilon}\right)&lt;/math&gt;
then for {{math|''S''}} uniform over &lt;math&gt;\mathcal{S}&lt;/math&gt; and independent of {{math|''X''}}, we have: 
:&lt;math display="inline"&gt;\delta\left[(h(S, X), S), (U, S)\right] \leq \varepsilon.&lt;/math&gt;

where {{math|''U''}} is uniform over &lt;math&gt;\{0, 1\}^m&lt;/math&gt; and independent of {{math|''S''}}.&lt;ref&gt;{{cite web|url=http://people.csail.mit.edu/ronitt/COURSE/S08/drafts/22.pdf|title=The Leftover Hash Lemma and Explicit Extractions|first1=Ronnit|last1=Rubinfeld|first2=Andy|last2=Drucker|publisher=MIT|date=2008-04-30|accessdate=2015-02-20}}&lt;/ref&gt;

&lt;math display="inline"&gt;H_\infty(X) = -\log \max_x \Pr[X=x]&lt;/math&gt; is the [[min-entropy]] of {{math|''X''}}, which measures the amount of randomness {{math|''X''}} has. The min-entropy is always less than or equal to the [[Shannon entropy]]. Note that &lt;math display="inline"&gt;\max_x \Pr[X=x]&lt;/math&gt; is the probability of correctly guessing {{math|''X''}}. (The best guess is to guess the most probable value.) Therefore, the min-entropy measures how difficult it is to guess {{math|''X''}}.

&lt;math display="inline"&gt;0 \le \delta(X, Y) = \frac{1}{2} \sum_v \left| \Pr[X=v] - \Pr[Y=v] \right| \le 1&lt;/math&gt; is a [[statistical distance]] between {{math|''X''}} and {{math|''Y''}}.

==See also==
* [[Universal hashing]]
* [[Min-entropy]]
* [[Rényi entropy]]
* [[Information theoretic security]]

==References==
{{Reflist}}
*[http://portal.acm.org/citation.cfm?coll=GUIDE&amp;dl=GUIDE&amp;id=45477 C. H. Bennett, G. Brassard, and J. M. Robert. ''Privacy amplification by public discussion''. SIAM Journal on Computing, 17(2):210-229, 1988.]
*[http://portal.acm.org/citation.cfm?coll=GUIDE&amp;dl=GUIDE&amp;id=73009 R. Impagliazzo, L. A. Levin, and M. Luby. ''Pseudo-random generation from one-way functions''. In Proceedings of the 21st Annual ACM Symposium on Theory of Computing (STOC '89), pages 12-24. ACM Press, 1989.]
*[http://ieeexplore.ieee.org/xpls/abs_all.jsp?isnumber=10153&amp;arnumber=476316&amp;type=ref C. Bennett, G. Brassard, C. Crepeau, and U. Maurer. ''Generalized privacy amplification''. IEEE Transactions on Information Theory, 41, 1995.]
*[http://portal.acm.org/citation.cfm?coll=GUIDE&amp;dl=GUIDE&amp;id=312213 J. Håstad, R. Impagliazzo, L. A. Levin and M. Luby. ''A Pseudorandom Generator from any One-way Function''. SIAM Journal on Computing, v28 n4, pp. 1364-1396, 1999.]

[[Category:Theory of cryptography]]
[[Category:Probability theorems]]</text>
      <sha1>2p0evfq75uzmk6x5k39g2me9tomg6zx</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after W. V. D. Hodge</title>
    <ns>0</ns>
    <id>39482883</id>
    <revision>
      <id>582210507</id>
      <parentid>569668950</parentid>
      <timestamp>2013-11-18T14:42:25Z</timestamp>
      <contributor>
        <ip>129.20.37.27</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="428">These are '''things named after [[W. V. D. Hodge]]''', a Scottish mathematician.
{{incomplete-list|date=May 2013}}
* [[Hodge algebra]]
* [[Hodge conjecture]]
* [[Hodge decomposition]]
* [[Hodge duality]]
* [[Hodge filtration]]
* [[Hodge index theorem]]
* [[Hodge structure]]
* [[Hodge–Tate module]]
* [[Hodge theory]]
* [[Hodge diamond]]
* [[p-adic Hodge theory]]

[[Category:Lists of things named after mathematicians|Hodge]]</text>
      <sha1>6yg103xwxfxypxib1yd6rf9xnbmw28q</sha1>
    </revision>
  </page>
  <page>
    <title>Martin Demaine</title>
    <ns>0</ns>
    <id>24075754</id>
    <revision>
      <id>821253164</id>
      <parentid>805291283</parentid>
      <timestamp>2018-01-19T09:14:58Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.2)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6374">'''Martin L.''' ('''Marty''') '''Demaine''' (born 1942&lt;ref&gt;Author information in [[National Library of Australia]] [http://nla.gov.au/anbd.bib-an42254624 catalog entry for ''A lifetime of puzzles : a collection of puzzles in honor of Martin Gardner's 90th birthday''] (A K Peters, 2008, {{ISBN|978-1-56881-245-8}}), edited by Demaine et al.&lt;/ref&gt;) is an artist and mathematician, the Angelika and Barton Weller [[artist in residence]] at the [[Massachusetts Institute of Technology]].&lt;ref&gt;{{citation|url=http://www.eecs.mit.edu/AY04-05/announcements/25.html|title=Martin Demaine appointed EECS Artist-in-Residence|publisher=MIT Department of Electrical Engineering and Computer Science|date=February 25, 2005|postscript=&lt;!--none--&gt;}}.&lt;/ref&gt;

[[File:Erik Demaine et al 2005 cropped.jpg|right|thumb|Erik Demaine (left), Martin Demaine (center), and Bill Spight (right) watch [[John Horton Conway]] demonstrate a card trick (June 2005)]]
Demaine attended [[Medford High School (Massachusetts)|Medford High School]] in [[Medford, Massachusetts]].&lt;ref name="rsfh"/&gt; After studying [[glassblowing]] in England, he began his artistic career by blowing [[art glass]] in [[New Brunswick]] in the early 1970s.&lt;ref name="fluency"&gt;[http://mccainartgallery.com/2007/Fluency.htm "Fluency", past exhibitions] {{webarchive|url=https://web.archive.org/web/20110714055813/http://mccainartgallery.com/2007/Fluency.htm |date=2011-07-14 }}, Andrew and Laura McCain Art Gallery, Florenceville, New Brunswick, Canada, retrieved 2009-08-22.&lt;/ref&gt; The Demaine Studio, located in [[Miramichi Bay]] and later at Opus Village in [[Mactaquac, New Brunswick|Mactaquac]], was the first one-man glass studio in Canada,&lt;ref&gt;{{citation|title=In Touch with the Tides : Canadian Glassblower Jon Sawyer|journal=The World and I|volume=18|first=Stephen|last=Henkin|date=October 2003|url=http://goliath.ecnext.com/coms2/gi_0199-1222755/In-Touch-With-the-Tides.html|postscript=&lt;!--none--&gt;}}. Jon Sawyer was an apprentice of Demaine at Mactaquac beginning in 1977.&lt;/ref&gt; part of the [[Glass art#The international studio glass movement|international studio glass movement]]. Demaine's pieces from this period are represented in the permanent collections of half a dozen major museums&lt;ref name="cv"&gt;[http://martindemaine.org/cv.pdf Curriculum vitae] from Demaine's web site.&lt;/ref&gt; including the [[Canadian Museum of Civilization]]&lt;ref&gt;[http://www.civilization.ca/cmc/exhibitions/hist/verre/vedec01e.shtml Glass and glass-making in Canada - Inspirational glass]. [[Canadian Museum of Civilization]]. Retrieved 2009-08-22.&lt;/ref&gt; and the [[National Gallery of Canada]]. Since joining MIT, Demaine has begun blowing glass again, as an instructor at the MIT Glass Lab;&lt;ref&gt;[http://web.mit.edu/glasslab/peeps_marty.html The MIT Glass Lab: Martin Demaine].&lt;/ref&gt; his newer work features innovative glassblowing techniques intended as a puzzle to his fellow glassblowers.&lt;ref name="fluency"/&gt;&lt;ref name="pwstw"&gt;{{citation|title=‘Puzzles Will Save The World.’ Martin Demaine is kidding, mostly, when he says this, but his puzzles have made cars safer, candies easier to unwrap, and maybe one day will help cure diseases|journal=[[Boston Globe]]|url=http://www.boston.com/news/education/higher/articles/2007/06/24/puzzles_will_save_the_world/|first=Amy|last=Karafin|date=June 24, 2007|postscript=&lt;!--none--&gt;}}.&lt;/ref&gt;

Martin Demaine is the father of MIT Computer Science professor and [[MacArthur Fellowship|MacArthur Fellow]] [[Erik Demaine]]; in 1987 (when Erik was six) they together founded the Erik and Dad Puzzle Company which distributed puzzles throughout Canada.&lt;ref&gt;{{citation|contribution=Algorithms Meet Art, Puzzles and Magic|last=Demaine|first=Erik|title=Proc. Algorithms and Data Structures Symposium (WADS 2009), Banff, Canada|series=Lecture Notes in Computer Science|volume=5664|year=2009|publisher=Springer-Verlag|postscript=&lt;!--none--&gt;}}.&lt;/ref&gt; Erik was [[homeschooling|home-schooled]] by Martin, and although Martin never received any higher degree than his high school diploma, his home-schooling caused Erik to be awarded a B.S. at age 14 and a Ph.D. and MIT professorship at age 20,&lt;ref name="rsfh"&gt;{{citation|title=Road Scholar Finds Home at MIT|last=Barry|first=Ellen|journal=[[Boston Globe]]|date=February 17, 2002|postscript=&lt;!--none--&gt;}}.&lt;/ref&gt;&lt;ref&gt;{{citation|title=Erik Demaine|publisher=Homeschooling Teen Magazine|date=March 20, 2009|url=http://www.homeschoolingteen.com/2009/03/erik-demaine-math-wizard/|postscript=&lt;!--none--&gt;}}.&lt;/ref&gt; making him the youngest professor ever hired by MIT.&lt;ref name="nyt"&gt;{{cite news|url=https://www.nytimes.com/2005/02/15/science/15origami.html?pagewanted=1&amp;ei=5090&amp;en=7c6938eb4b440672&amp;ex=1266210000&amp;partner=rssuserland|title=Origami as the Shape of Things to Come|last=Wertheim|first=Margaret|publisher=[[New York Times]]|date=February 15, 2005}}&lt;/ref&gt;
The two Demaines continue to work closely together and have many joint works of both mathematics and art,&lt;ref&gt;[http://web.mit.edu/newsoffice/2003/demaine-father-1008.html Father and son share love of art, computer science], MIT Tech Talk, October 8, 2003.&lt;/ref&gt; including three pieces of [[mathematical origami]] in the permanent collection of the [[Museum of Modern Art]], [[New York City|New York]];&lt;ref&gt;[http://erikdemaine.org/curved/ Curved Origami Sculpture], from the web site of Erik Demaine. Retrieved 2009-08-22.&lt;/ref&gt; their joint mathematical works focus primarily on the [[Mathematics of paper folding|mathematics of folding and unfolding objects]] out of flat materials such as paper and on [[game complexity|the computational complexity of games and puzzles]].&lt;ref name="pwstw"/&gt;&lt;ref name="nyt"/&gt; Martin and Erik are also featured in the movie ''Between the Folds'', a documentary on modern origami.

Demaine is a citizen of both [[Canada]] and the [[United States]].&lt;ref name="cv"/&gt;

==References==
{{reflist|30em}}

==External links==
*[http://martindemaine.org/ Demaine's web site]

{{Authority control}}
{{DEFAULTSORT:Demaine, Martin L.}}
{{Mathematical art}}

[[Category:1942 births]]
[[Category:Living people]]
[[Category:Glass artists]]
[[Category:Origami artists]]
[[Category:Researchers in geometric algorithms]]
[[Category:Artists from Massachusetts]]
[[Category:Artists from New Brunswick]]
[[Category:Massachusetts Institute of Technology people]]
[[Category:Mathematical artists]]</text>
      <sha1>i6bfk2uymizg7zso6fcvjrj6h6xludc</sha1>
    </revision>
  </page>
  <page>
    <title>Multidimensional transform</title>
    <ns>0</ns>
    <id>41309901</id>
    <revision>
      <id>812721893</id>
      <parentid>812721825</parentid>
      <timestamp>2017-11-29T13:55:07Z</timestamp>
      <contributor>
        <ip>130.190.34.130</ip>
      </contributor>
      <comment>/* MD DFT */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="25074">In [[mathematical analysis]] and applications, '''multidimensional transforms''' are used to analyze the frequency content of signals in a domain of two or more dimensions.

== Multidimensional Fourier transform ==

One of the more popular multidimensional  transforms is the [[Fourier transform]], which converts a signal from a time/space domain representation to a frequency domain representation.&lt;ref name="Smith"&gt;Smith,W. Handbook of Real-Time Fast Fourier Transforms:Algorithms to Product Testing, Wiley_IEEE Press, edition 1, pages 73–80, 1995&lt;/ref&gt; The discrete-domain multidimensional  Fourier transform (FT) can be computed as follows:

:&lt;math&gt; F(w_1,w_2,\dots,w_m) = \sum_{n_1=-\infty}^\infty \sum_{n_2=-\infty}^\infty \cdots \sum_{n_m=-\infty}^\infty f(n_1,n_2,\dots,n_m) e^{-i w_1 n_1 -i w_2 n_2 \cdots -i w_m n_m}&lt;/math&gt;
                        
where ''F'' stands for the multidimensional Fourier transform, ''m'' stands for multidimensional dimension. Define ''f'' as a multidimensional  discrete-domain signal. The inverse multidimensional Fourier transform is given by

:&lt;math&gt; f(n_1,n_2,\dots,n_m) = \left(\frac{1}{2 \pi}\right)^m \int_{- \pi}^{\pi} \cdots \int_{-\pi}^{\pi} F(w_1,w_2,\ldots,w_m) e^{i w_1 n_1 +i w_2 n_2 + \cdots+i w_m n_m} \, dw_1 \cdots \,dw_m &lt;/math&gt;

The multidimensional Fourier transform for continuous-domain signals is defined as follows:&lt;ref name="Smith"/&gt;
:&lt;math&gt;F(\Omega_1,\Omega_2,\ldots,\Omega_m) = \int_{-\infty}^{\infty} \cdots \int_{-\infty}^{\infty} 
f(t_1,t_2,\ldots,t_m) e^{-i \Omega_1 t_1-i \Omega_2 t_2 \cdots -i \Omega_m t_m} \, dt_1 \cdots \,dt_m  &lt;/math&gt;

=== Properties of Fourier transform ===

Similar properties of the 1-D FT transform apply, but instead of the input parameter being just a single entry, it's a Multi-dimensional (MD) array or vector. Hence, it's x(n1,…,nM) instead of x(n).

====Linearity====

if &lt;math&gt;x_1(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X_1(\omega_1,\ldots,\omega_M)&lt;/math&gt; , and &lt;math&gt;x_2(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X_2(\omega_1,\ldots,\omega_M)&lt;/math&gt; then,

: &lt;math&gt;a x_1(n_1,\ldots,n_M) + b x_2(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} a X_1(\omega_1,\ldots,\omega_M) + b X_2 (\omega_1, \ldots, \omega_M) &lt;/math&gt;

====Shift====

if &lt;math&gt;x(n_1,...,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X(\omega_1,...,\omega_M)&lt;/math&gt;, then&lt;br /&gt;
&lt;math&gt;x(n_1 - a_1,...,n_M - a_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} e^{-j(\omega_1 a_1 +,...,+ \omega_M a_M)} X(\omega_1,...,\omega_M)&lt;/math&gt;

====[[Multidimensional modulation|Modulation]]====

if &lt;math&gt;x(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X(\omega_1,\ldots,\omega_M)&lt;/math&gt;, then

: &lt;math&gt;e^{j(\theta_1 n_1 +\cdots+ \theta_M n_M)} x(n_1 - a_1,\ldots,n_M - a_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X(\omega_1 - \theta_1,\ldots,\omega_M - \theta_M)&lt;/math&gt;

====Multiplication====

if &lt;math&gt;x_1(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X_1(\omega_1,\ldots,\omega_M)&lt;/math&gt;, and &lt;math&gt;x_2(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X_2 (\omega_1,\ldots,\omega_M)&lt;/math&gt;

then,

: {{NumBlk|:|&lt;math&gt; x_1(n_1,\ldots,n_M)  x_2(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} \frac{1}{(2\pi)^M} \int \limits_{-\pi}^\pi \cdots \int\limits_{-\pi}^\pi X_1(\omega_1 - \theta_1,\ldots,\omega_M - \theta_M) X_2 (\theta_1, \ldots, \theta_M) \, d\theta_1 \cdots d\theta_M&lt;/math&gt;|{{EquationRef|MD Convolution in Frequency Domain}}}}

or,
: {{NumBlk|:|&lt;math&gt; x_1(n_1,\ldots,n_M) x_2(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} \frac{1}{(2\pi)^M} \int\limits_{-\pi}^\pi \cdots \int\limits_{-\pi}^\pi X_1(\theta_1,\ldots,\theta_M) X_2(\omega_1 - \theta_1,\ldots,\omega_M - \theta_M)  \, d\theta_1\cdots d\theta_M&lt;/math&gt;|{{EquationRef|MD Convolution in Frequency Domain}}}}

====Differentiation====

If &lt;math&gt;x(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X(\omega_1,\ldots,\omega_M)&lt;/math&gt;, then

: &lt;math&gt;-jn_1x(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} \frac{\partial}{(\partial\omega_1)} X(\omega_1,\ldots,\omega_M), &lt;/math&gt;
: &lt;math&gt;-jn_2x(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} \frac{\partial}{(\partial\omega_2)} X(\omega_1,\ldots,\omega_M), &lt;/math&gt;
: &lt;math&gt;(-j)^M(n_1n_2\cdots n_M)x(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} \frac{(\partial)^M}{(\partial\omega_1\partial\omega_2\cdots\partial\omega_M)} X(\omega_1,\ldots,\omega_M),&lt;/math&gt;

====Transposition====

If &lt;math&gt;x(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X(\omega_1,\ldots,\omega_M)&lt;/math&gt;, then

: &lt;math&gt;x(n_M,\ldots,n_1) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X (\omega_M,\ldots,\omega_1)&lt;/math&gt;

====Reflection====

If &lt;math&gt;x(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X (\omega_1,\ldots,\omega_M)&lt;/math&gt;, then

: &lt;math&gt;x(\pm n_1,\ldots,\pm n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X(\pm \omega_1,\ldots,\pm \omega_M)&lt;/math&gt;

====Complex conjugation====

If &lt;math&gt;x(n_1,\ldots,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X(\omega_1,\ldots,\omega_M)&lt;/math&gt;, then

: &lt;math&gt;x^{*}(\pm n_1,\ldots,\pm n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X^{*}(-\omega_1,\ldots,-\omega_M)&lt;/math&gt;

====Parseval's theorem (MD)====

if &lt;math&gt;x_1(n_1,...,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X_1(\omega_1,...,\omega_M)&lt;/math&gt; , and &lt;math&gt;x_2(n_1,...,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X_2(\omega_1,...,\omega_M)&lt;/math&gt; then,

&lt;math&gt;\sum_{n_1=-\infty}^\infty ... \sum_{n_M =-\infty}^\infty x_1 (n_1,...,n_M) x_2^{*}(n_1,...,n_M) {=} \frac{1}{(2\pi)^M} \int\limits_{-\pi}^{\pi} ... \int\limits_{-\pi}^{\pi}X_1(\omega_1,...,\omega_M) X_2^{*}(\omega_1,...,\omega_M)d\omega_1...d\omega_M&lt;/math&gt;

if &lt;math&gt;x_1(n_1,...,n_M) {=} x_2(n_1,...,n_M)&lt;/math&gt;,  then

&lt;math&gt;\sum_{n_1=-\infty}^\infty ... \sum_{n_M =-\infty}^\infty |x_1 (n_1,...,n_M)|^2 {=} \frac{1}{(2\pi)^M} \int\limits_{-\pi}^{\pi} ... \int\limits_{-\pi}^{\pi}|X_1(\omega_1,...,\omega_M)|^2 d\omega_1...d\omega_M&lt;/math&gt;

A special case of the Parseval's theorem is when the two multi-dimensional signals are the same. In this case, the theorem portrays the energy conservation of the signal and the term in the summation or integral is the energy-density of the signal.

====Separability====

One property is the separability property. A signal or system is said to be separable if it can be expressed as a product of 1-D functions with different independent variables. This phenomenon allows computing the FT transform as a product of 1-D FTs instead of multi-dimensional FT.

if &lt;math&gt;x(n_1,...,n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} X(\omega_1,...,\omega_M)&lt;/math&gt;, &lt;math&gt;a(n_1) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} A(\omega_1)&lt;/math&gt;,
&lt;math&gt;b(n_2) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} B(\omega_2)&lt;/math&gt; ... &lt;math&gt;y(n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} Y(\omega_M)&lt;/math&gt;, and if 
&lt;math&gt;x(n_1,...,n_M) {=} a(n_1)b(n_2)...y(n_M)&lt;/math&gt;, then

&lt;math&gt;X(\omega_1,...,\omega_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} x(n_1,...,n_M) {=} a(n_1)b(n_2)...y(n_M) \overset{\underset{\mathrm{FT}}{}}{\longleftrightarrow} A(\omega_1) B(\omega_2)...Y(\omega_M)&lt;/math&gt;, so

&lt;math&gt;X(\omega_1,...,\omega_M) {=} A(\omega_1) B(\omega_2)...Y(\omega_M)&lt;/math&gt;

=== MD FFT ===
A [[fast Fourier transform]] (FFT) is an algorithm to compute the discrete Fourier transform (DFT) and its inverse. An FFT computes the DFT and produces exactly the same result as evaluating the DFT definition directly; the only difference is that an FFT is much faster. (In the presence of round-off error, many FFT algorithms are also much more accurate than evaluating the DFT definition directly).There are many different FFT algorithms involving a wide range of mathematics, from simple complex-number arithmetic to group theory and number theory. See more in [[FFT]].

=== MD DFT ===

The multidimensional [[discrete Fourier transform]] (DFT) is a sampled version of the discrete-domain FT by evaluating it at sample frequencies that are uniformly spaced.&lt;ref&gt;Dudgeon and Mersereau, Multidimensional Digital Signal Processing,2nd edition,1995&lt;/ref&gt; The {{nowrap|''N''&lt;sub&gt;1&lt;/sub&gt; × ''N''&lt;sub&gt;2&lt;/sub&gt; × ... ''N''&lt;sub&gt;''m''&lt;/sub&gt;}} DFT is given by:

:&lt;math&gt;  Fx(K_1,K_2,\ldots,K_m)= \sum_{n_1=0}^{N_1-1} \cdots \sum_{n_m=0}^{N_m-1} fx(n_1,n_2,\ldots,n_m) e^{-i \frac{2 \pi}{N_1} n_1 K_1  -i \frac{2 \pi}{N_2} n_2 K_2 \cdots -i \frac{2 \pi}{N_m} n_m K_m}   &lt;/math&gt;
                                                    
for {{nowrap|0 ≤ ''K&lt;sub&gt;i&lt;/sub&gt;'' ≤ ''N&lt;sub&gt;i&lt;/sub&gt;'' &amp;minus; 1}}, {{nowrap|''i'' {{=}} 1, 2, ..., ''m''}}.

The inverse multidimensional DFT equation is

:&lt;math&gt; fx(n_1,n_2,\ldots,n_m)= \frac{1}{N_1 \cdots N_m} \sum_{K_1=0}^{N_1-1} \cdots \sum_{K_m=0}^{N_m-1} Fx(K_1,K_2, \ldots ,K_m) e^{i \frac{2 \pi}{N_1} n_1 K_1 +i \frac{2 \pi}{N_2}  n_2 K_2\cdots+i \frac{2 \pi}{N_m} n_m K_m}    &lt;/math&gt;
                                      
for {{nowrap|0 ≤ ''n''&lt;sub&gt;1&lt;/sub&gt;, ''n''&lt;sub&gt;2&lt;/sub&gt;, ... , ''n''&lt;sub&gt;''m''&lt;/sub&gt; ≤ ''N''&lt;sub&gt;(1, 2, ... , ''m'')&lt;/sub&gt; – 1}}.

== Multidimensional discrete cosine transform ==

The discrete cosine transform (DCT) is used in a wide range of applications such as data [[Data compression|compression]], [[feature extraction]], [[Image reconstruction]], multi-frame [[detection]] and so on. The multidimensional  DCT is given by:

:&lt;math&gt; Fx(K_1,K_2,\ldots,K_r ) = \sum_{n_1=0}^{N_1-1} \sum_{n_2=0}^{N_2-1} \cdots \sum_{n_r=0}^{N_r-1} fx(n_1,n_2,\ldots,n_r) \cos { \frac{ \pi (2n_1+1) K_1}{2N_1}} \cdots \cos { \frac{ \pi (2n_r+1) K_r}{2N_r}}&lt;/math&gt;
                          
for {{nowrap|''k&lt;sub&gt;i&lt;/sub&gt;'' {{=}} 0, 1, ..., ''N&lt;sub&gt;i&lt;/sub&gt;'' &amp;minus; 1}}, ''i'' = 1, 2, ..., ''r''.

== Multidimensional Laplace transform ==
The multidimensional Laplace transform is useful for the solution of boundary value problems. Boundary value problems in two or more variables characterized by partial differential equations can be solved by a direct use of the Laplace transform.&lt;ref name=":0"&gt;{{Cite journal|title = Theorems on multidimensional laplace transform for solution of boundary value problems|url = http://www.sciencedirect.com/science/article/pii/089812218990031X|journal = Computers &amp; Mathematics with Applications|date = 1989-01-01|pages = 1033–1056|volume = 18|issue = 12|doi = 10.1016/0898-1221(89)90031-X|first = Joyati|last = Debnath|first2 = R. S.|last2 = Dahiya}}&lt;/ref&gt; The Laplace transform for an M-dimensional case is defined&lt;ref name=":0"/&gt; as

&lt;math&gt; F(s_1,s_2,\ldots,s_n) = \int_{0}^{\infty} \cdots \int_{0}^{\infty} 
f(t_1,t_2,\ldots,t_n) e^{-s_nt_n -s_{n-1}t_{n-1} \cdots \cdots s_1t_1} \, dt_1 \cdots \,dt_n &lt;/math&gt;

where F stands for the s-domain representation of the signal f(t).

A special case (along 2 dimensions) of the multi-dimensional Laplace transform of function f(x,y) is defined&lt;ref&gt;{{Cite book|title = Operational Calculus in two Variables and its Application (1st English edition) - translated by D.M.G. Wishart (Calcul opérationnel)|last = |first = |publisher = |year = |isbn = |location = |pages = }}&lt;/ref&gt; as

&lt;math display="block"&gt;F(s_1,s_2)=\textstyle \int\limits_{0}^{\infty}\int\limits_{0}^{\infty}\ f(x,y) e^{-s_1x-s_2y}\, dxdy&lt;/math&gt;

&lt;math&gt; F(s_1,s_2) &lt;/math&gt; is called the image of &lt;math&gt; f(x,y) &lt;/math&gt; and &lt;math&gt; f(x,y) &lt;/math&gt; is known as the original of &lt;math&gt; F(s_1,s_2) &lt;/math&gt;.&lt;ref name=":1"&gt;{{Cite journal|url = |title = Multi-Dimensional Laplace Transforms and Systems of Partial Differential Equations |last = Aghili and Moghaddam|first =  |journal = International Mathematical Forum |volume=1 |year=2006 |issue=21 |pages=1043–1050|doi = |pmid = |access-date = }}&lt;/ref&gt; This special case can be used to solve the [[Telegrapher's equations]].&lt;ref name=":1" /&gt;

== Multidimensional Z transform&lt;ref&gt;{{Cite web|url = http://dsp-book.narod.ru/HFTSP/8579ch08.pdf|title = Narod Book|date = |accessdate = |website = |publisher = |last = |first = }}&lt;/ref&gt; ==
The multidimensional Z transform is used to map the discrete time domain multidimensional signal to the Z domain. This can be used to check the stability of filters. The equation of the multidimensional Z transform is given by
[[File:Figure 1.1a depicting region of support.png|thumb|209x209px|Figure 1.1a]]
&lt;math&gt; F(z_1,z_2,\ldots,z_m)= \sum_{n_1=-\infty}^{\infty} \cdots \sum_{n_m=-\infty}^{\infty} f(n_1,n_2,\ldots,n_m) z_1^{-n_1}  z_2^{-n_2} \ldots z_m^{-n_m} &lt;/math&gt;

where F stands for the z-domain representation of the signal f(n).

A special case of the multidimensional Z transform is the 2D Z transform which is given as

&lt;math&gt; F(z_1,z_2)= \sum_{n_1=-\infty}^{\infty} \sum_{n_2=-\infty}^{\infty} f(n_1,n_2) z_1^{-n_1}  z_2^{-n_2} &lt;/math&gt;

The Fourier transform is a special case of the Z transform evaluated along the unit circle (in 1D) and unit bi-circle (in 2D). i.e. at

&lt;math display="inline"&gt; z=e^{jw} &lt;/math&gt; where z and w are vectors.

=== Region of convergence ===
[[File:Region of Convergence for figure 1.1a.png|thumb|201x201px|Figure 1.1b]]
Points (''z''&lt;sub&gt;1&lt;/sub&gt;,''z''&lt;sub&gt;2&lt;/sub&gt;) for which &lt;math&gt;F(z_1,z_2)=\sum_{n_1=-\infty}^\infty \sum_{n_2=-\infty}^\infty |f(n_1,n_2)| |z_1|^{-n_1} |z_2|^{-n_2}&lt;/math&gt; &lt;math&gt;&lt;\infty&lt;/math&gt; are located in the ROC.

An example:

If a sequence has a support as shown in Figure 1.1a, then its ROC is shown in Figure 1.1b. This follows that |''F''(''z''&lt;sub&gt;1&lt;/sub&gt;,''z''&lt;sub&gt;2&lt;/sub&gt;)| &lt; '''∞''' .

&lt;math&gt;(z_{01},z_{02})&lt;/math&gt; lies in the ROC, then all points&lt;math&gt;(z_1,z_2)&lt;/math&gt;that satisfy |z1|≥|z01| and |z2|≥|z02 lie in the ROC.

Therefore, for figure 1.1a and 1.1b, the ROC would be

: &lt;math&gt; \ln|z_1| \ge \ln|z_{01}| \text{ and } \ln|z_2| \ge L \ln|z_1| + \{ \ln|z_{02}| - L\ln|z_{01}| \} &lt;/math&gt;

where ''L'' is the slope.

The [[2D Z-transform]], similar to the Z-transform, is used in multidimensional signal processing to relate a two-dimensional discrete-time signal to the complex frequency domain in which the 2D surface in 4D space that the Fourier transform lies on is known as the unit surface or unit bicircle.

== Applications ==

The DCT and DFT are often used in signal processing&lt;ref&gt;Tan Xiao, Shao-hai Hu, Yang Xiao. 2-D DFT-DWT Application to Multidimensional Signal Processing. ICSP2006 Proceedings, 2006 IEEE&lt;/ref&gt; and image processing, and they are also used to efficiently solve partial differential equations by spectral methods. The DFT can also be used to perform other operations such as convolutions or multiplying large integers. The DFT and DCT have seen wide usage across a large number of fields, we only sketch a few examples below.

=== Image processing ===

[[File:Dctjpeg.png|thumb|250px|Two-dimensional DCT frequencies from the [[JPEG#Discrete cosine transform|JPEG DCT]]]]

The DCT is used in [[JPEG]] image compression, [[MJPEG]], [[MPEG]], [[DV]], [[Daala]], and [[Theora]] [[video compression]]. There, the two-dimensional DCT-II of ''N''x''N'' blocks are computed and the results are [[Quantization (signal processing)|quantized]] and [[Entropy encoding|entropy coded]]. In this case, ''N'' is typically 8 and the DCT-II formula is applied to each row and column of the block. The result is an 8x8 transform coefficient array in which the: (0,0) element (top-left) is the DC (zero-frequency) component and entries with increasing vertical and horizontal index values represent higher vertical and horizontal spatial frequencies, as shown in the picture on the right.

In image processing, one can also analyze and describe unconventional cryptographic methods based on 2D DCTs, for inserting non-visible binary watermarks into the 2D image plane,&lt;ref&gt;Peter KULLAI, Pavol SABAKAI, JozefHUSKAI. Simple Possibilities of 2D DCT Application in Digital
Monochrome Image Cryptography. Radioelektronika, 17th International Conference, IEEE, 2007, pp. 1–6&lt;/ref&gt; and According to different orientations, the 2-D directional DCT-DWT hybrid transform can be applied in denoising ultrasound images.&lt;ref&gt;Xin-ling Wen, Yang Xiao. The 2-D Directional DCT-DWT Hybrid Transform and Its Application in Denoising Ultrasound Image. Signal Processing. ICSP 2008. 9th International Conference, Page(s): 946–949&lt;/ref&gt; 3-D DCT can also be used to transform video data or 3-D image data in watermark embedding schemes in transform domain.&lt;ref&gt;Jinwei Wang, Shiguo Lian, Zhongxuan Liu, Zhen Ren, Yuewei Dai, Haila Wang. Image Watermarking Scheme Based on 3-D DCT.Industrial Electronics and Applications, 2006 1ST IEEE Conference, pp. 1–6&lt;/ref&gt;&lt;ref&gt;Jin Li, Moncef Gabbouj, Jarmo Takala, Hexin Chen. Direct 3-D DCT-to-DCT Resizing Algorithm for Video Coding. Image and Signal Processing and Analysis, 2009. ISPA 2009. Proceedings of 6th International Symposium
pp. 105–110&lt;/ref&gt;

=== Spectral analysis ===

When the DFT is used for [[Frequency spectrum#Spectrum analysis|spectral analysis]], the {''x&lt;sub&gt;n&lt;/sub&gt;''} sequence usually represents a finite set of uniformly spaced time-samples of some signal ''x''(''t'') where ''t'' represents time.  The conversion from continuous time to samples (discrete-time) changes the underlying [[continuous Fourier transform|Fourier transform]] of ''x''(''t'') into a [[discrete-time Fourier transform]] (DTFT), which generally entails a type of distortion called [[aliasing]].  Choice of an appropriate sample-rate (see ''[[Nyquist rate]]'') is the key to minimizing that distortion.  Similarly, the conversion from a very long (or infinite) sequence to a manageable size entails a type of distortion called ''[[Spectral leakage|leakage]]'', which is manifested as a loss of detail (aka resolution) in the DTFT.  Choice of an appropriate sub-sequence length is the primary key to minimizing that effect.  When the available data (and time to process it) is more than the amount needed to attain the desired frequency resolution, a standard technique is to perform multiple DFTs, for example to create a [[spectrogram]].  If the desired result is a power spectrum and noise or randomness is present in the data, averaging the magnitude components of the multiple DFTs is a useful procedure to reduce the [[variance]] of the spectrum (also called a [[periodogram]] in this context); two examples of such techniques are the [[Welch method]] and the [[Bartlett method]]; the general subject of estimating the power spectrum of a noisy signal is called [[spectral estimation]].

A final source of distortion (or perhaps ''illusion'') is the DFT itself, because it is just a discrete sampling of the DTFT, which is a function of a continuous frequency domain.  That can be mitigated by increasing the resolution of the DFT.  That procedure is illustrated at [[Discrete-time Fourier transform#Sampling the DTFT|Sampling the DTFT]].
*The procedure is sometimes referred to as ''zero-padding'', which is a particular implementation used in conjunction with the [[fast Fourier transform]] (FFT) algorithm.  The inefficiency of performing multiplications and additions with zero-valued "samples" is more than offset by the inherent efficiency of the FFT.
*As already noted, leakage imposes a limit on the inherent resolution of the DTFT.  So there is a practical limit to the benefit that can be obtained from a fine-grained DFT.

===Partial differential equations===

Discrete Fourier transforms are often used to solve [[partial differential equations]], where again the DFT is used as an approximation for the [[Fourier series]] (which is recovered in the limit of infinite ''N''). The advantage of this approach is that it expands the signal in complex exponentials ''e''&lt;sup&gt;''inx''&lt;/sup&gt;, which are eigenfunctions of differentiation: ''d''/''dx'' ''e''&lt;sup&gt;''inx''&lt;/sup&gt; = ''in'' ''e''&lt;sup&gt;''inx''&lt;/sup&gt;. Thus, in the Fourier representation, differentiation is simple—we just multiply by ''i n''.  (Note, however, that the choice of ''n'' is not unique due to aliasing; for the method to be convergent, a choice similar to that in the [[Discrete Fourier transform#Trigonometric interpolation polynomial|trigonometric interpolation]] section above should be used.) A [[linear differential equation]] with constant coefficients is transformed into an easily solvable algebraic equation. One then uses the inverse DFT to transform the result back into the ordinary spatial representation. Such an approach is called a [[spectral method]].

DCTs are also widely employed in solving partial differential equations by spectral methods, where the different variants of the DCT correspond to slightly different even/odd boundary conditions at the two ends of the array.

Laplace transforms are used to solve partial differential equations. The general theory for obtaining solutions in this technique is developed by theorems on Laplace transform in n dimensions.&lt;ref name=":0" /&gt;

The multidimensional Z transform can also be used to solve partial differential equations.&lt;ref&gt;{{Cite journal|url = http://dml.cz/bitstream/handle/10338.dmlcz/124265/Kybernetika_24-1988-7_1.pdf|title = Kybernetika|last = Gregor|first = Jiří |date= 1998 |journal= Kybernetika |volume=24 |access-date = }}&lt;/ref&gt;

=== Image processing for arts surface analysis by FFT ===

One very important factor is that we must apply a non-destructive method to obtain those rare valuables information (from the HVS viewing point, is focused in whole colorimetric and spatial information) about works of art and zero-damage on them.
We can understand the arts by looking at a color change or by measuring the surface uniformity change. Since the whole image will be very huge, so we use a double raised cosine window to truncate the image:&lt;ref name="Angelini et al"&gt;Angelini, E., Grassin, S. ; Piantanida, M. ; Corbellini, S. ; Ferraris, F. ; Neri, A. ; Parvis, M. FFT-based imaging processing for cultural heritage monitoring  Instrumentation and Measurement Technology Conference (I2MTC), 2010 IEEE&lt;/ref&gt;

:&lt;math&gt; w(x,y)=\frac{1}{4} \left(1 + \cos {\frac {x \pi} N }\right)\left(1 + \cos {\frac{y \pi} N }\right) &lt;/math&gt;

where ''N'' is the image dimension and ''x'', ''y'' are the coordinates from the center of image spans from 0 to ''N''/2.
The author wanted to compute an equal value for spatial frequency such as:&lt;ref name="Angelini et al"/&gt;

: &lt;math&gt;
\begin{align}
A_m(f)^2= \left[ \sum_{i=-f}^f \right. &amp; \operatorname{FFT}(-f,i)^2+ \sum_{i=-f}^f \operatorname{FFT}(f,i)^2 \\[5pt]
&amp; \left. {} + \sum_{i=-f+1}^{f-1} \operatorname{FFT}(i,-f)^2+ \sum_{i=-f+1}^{f-1} \operatorname{FFT}(i,f)^2 \right]
\end{align}
&lt;/math&gt;
        
where "FFT" denotes the fast Fourier transform, and ''f'' is the spatial frequency spans from 0 to {{nowrap|''N''/2 – 1}}. The proposed FFT-based imaging approach is diagnostic technology to ensure a long life and stable to culture arts. This is a simple, cheap which can be used in 
museums without affecting their daily use. But this method doesn’t allow a quantitative measure of the corrosion rate.

=== Application to weakly nonlinear circuit simulation&lt;ref&gt;{{Cite journal|url = http://ieeexplore.ieee.org/search/searchresult.jsp?newsearch=true&amp;queryText=Weakly%20Nonlinear%20Circuit%20Analysis%20Based%20on%20Fast%20Multidimensional%20Inverse%20Laplace%20Transform|title = Weakly Nonlinear Circuit Analysis Based on Fast Multidimensional Inverse Laplace Transform|last = Wang|first = Tingting|date = 2012|journal = IEEE Conference Publications|doi = 10.1109/ASPDAC.2012.6165013|pmid = |access-date = }}&lt;/ref&gt; ===
[[File:A weakly circuit.PNG|thumb|330x330px|An example of a weakly nonlinear circuit]]
The inverse multidimensional Laplace transform can be applied to simulate nonlinear circuits. This is done so by formulating a circuit as a state-space and expanding the Inverse Laplace Transform based on [[Laguerre function]] expansion.

The Lagurre method can be used to simulate a weakly nonlinear circuit and the Laguerre method can invert a multidimensional Laplace transform efficiently with a high accuracy.

It is observed that a high accuracy and significant speedup can be achieved for simulating large nonlinear circuits using multidimensional Laplace transforms.

== See also ==
* [[Discrete cosine transform]]
* [[List of Fourier-related transforms]]
* [[List of Fourier analysis topics]]
* [[Multidimensional discrete convolution]]
* [[2D Z-transform]]
* [[Multidimensional empirical mode decomposition]]
* [[Multidimensional signal reconstruction]]

== References ==
&lt;!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;

{{Reflist}}

[[Category:Fourier analysis]]
[[Category:Integral transforms]]
[[Category:Multidimensional signal processing]]</text>
      <sha1>r2n3i09skp6hk7wkkb4kjzedfeblyf7</sha1>
    </revision>
  </page>
  <page>
    <title>Non-smooth mechanics</title>
    <ns>0</ns>
    <id>15947157</id>
    <revision>
      <id>824234225</id>
      <parentid>720135997</parentid>
      <timestamp>2018-02-06T03:11:28Z</timestamp>
      <contributor>
        <ip>52.119.120.143</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2810">'''Non-smooth mechanics''' is a modeling approach in [[mechanics]] which does not require the time evolutions of the positions and of the velocities to be [[smooth function]]s anymore. Due to possible impacts, the velocities of the mechanical system are even allowed to undergo jumps at certain time instants in order to fulfill the kinematical restrictions. Consider for example a rigid model of a ball which falls on the ground. Just before the impact between ball and ground, the ball has non-vanishing pre-impact velocity. At the impact time instant, the velocity must jump to a post-impact velocity which is at least zero, or else penetration would occur. Non-smooth mechanical models are often used in [[contact dynamics]].

== See also==
*[[Contact dynamics]]
*[[Unilateral contact]]
*[[Jean Jacques Moreau]]

==References==
*Acary V., Brogliato, B. Numerical Methods for Nonsmooth Dynamical Systems. Applications in Mechanics and Electronics. ''Springer Verlag, LNACM 35, Heidelberg, 2008.''
*Brogliato B. Nonsmooth Mechanics. Models, Dynamics and Control. ''Communications and Control Engineering Series, Springer-Verlag, London, 2016 (3rd Ed.)''
*Glocker, Ch. ''Dynamik von Starrkoerpersystemen mit Reibung und Stoessen'', volume 18/182 of ''VDI Fortschrittsberichte Mechanik/Bruchmechanik.'' VDI Verlag, Düsseldorf, 1995
*Glocker Ch. and Studer C. Formulation and preparation for Numerical Evaluation of Linear Complementarity Systems. ''Multibody System Dynamics'' 13(4):447-463, 2005
*Jean M. The non-smooth contact dynamics method. ''Computer Methods in Applied mechanics and Engineering'' 177(3-4):235-257, 1999
*Moreau J.J. '' Unilateral Contact and Dry Friction in Finite Freedom Dynamics,'' volume 302 of '' Non-smooth Mechanics and Applications, CISM Courses and Lectures''. Springer, Wien, 1988
*Pfeiffer F., Foerg M. and Ulbrich H. Numerical aspects of non-smooth multibody dynamics. ''Comput. Methods Appl. Mech. Engrg'' 195(50-51):6891-6908, 2006
*Potra F.A., Anitescu M., Gavrea B. and Trinkle J. A linearly implicit trapezoidal method for integrating stiff multibody dynamics with contacts, joints and friction. ''Int. J. Numer. Meth. Engng'' 66(7):1079-1124, 2006
*Stewart D.E. and Trinkle J.C. An Implicit Time-Stepping Scheme for Rigid Body Dynamics with Inelastic Collisions and Coulomb Friction. ''Int. J. Numer. Methods Engineering'' 39(15):2673-2691, 1996
*Studer C. ''Augmented time-stepping integration of non-smooth dynamical systems'', PhD Thesis ETH Zurich, ETH E-Collection, to appear 2008
*Studer C. ''Numerics of Unilateral Contacts and Friction -- Modeling and Numerical Time Integration in Non-Smooth Dynamics'', Lecture Notes in Applied and Computational Mechanics, Volume 47, Springer, Berlin, Heidelberg, 2009

[[Category:Mechanics]]
[[Category:Dynamical systems]]</text>
      <sha1>kxycelkujsfj5tp9by974h2ta1epdcu</sha1>
    </revision>
  </page>
  <page>
    <title>Northeast (disambiguation)</title>
    <ns>0</ns>
    <id>663680</id>
    <revision>
      <id>857911645</id>
      <parentid>824910571</parentid>
      <timestamp>2018-09-03T21:00:59Z</timestamp>
      <contributor>
        <username>Dogru144</username>
        <id>1731964</id>
      </contributor>
      <comment>/* Trains</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4559">{{Wiktionary|northeast|northeastern}}
'''[[Northeast]]''' is a compass point.

'''Northeast''', '''north-east''', '''north east''', '''northeastern''' or '''north-eastern''' or '''north eastern''' may also refer to:
* [[Northeast (direction)]], an intercardinal direction
{{TOC right}}

== Places ==

=== Africa ===
* [[North Eastern Province (Kenya)]]
* [[North-East District (Botswana)]]
* [[North Eastern District, Eritrea]]

=== Asia and Oceania ===
* [[Northeast India]] or the Seven Sister States
* [[North East Delhi]], a district of Delhi
* [[North Eastern Province, Sri Lanka]]
* [[Northeast China]], or Manchuria
* [[North East District, Singapore]]
* [[North Eastern (General Electors Communal Constituency, Fiji)]], an electoral division of Fiji
* [[North-East Region, Singapore]]
* [[Northeast Province (IMCRA region)]], an Australian marine biogeographic province
* [[Northeast (Vietnam)]]
* [[Tōhoku region]] or "Northeast Region", Japan

=== Europe ===
* [[North East (London Assembly constituency)]], a constituency of the London Assembly
* [[North East (London sub region)]], a sub-region of the London Plan
* [[North East England]], one of the official government regions of England
* [[North East Scotland]], an electoral region, but in wider use to refer to the area made up of Aberdeen, Aberdeenshire and Moray

=== North and South America ===
* [[North East, Maryland]]
* [[North East, New York]]
* [[North East, Pennsylvania]]
* [[Northeast, Minneapolis]] (sometimes referred to as Nordeast)
* [[Northeast Region, Brazil]], an official grouping of states for economic and statistical purposes
* [[Atlantic Northeast]], a region of North America
* [[Northeast, Washington, D.C.]], the northeast quadrant of Washington, D.C.
* [[Northeastern United States]]
* [[Northeast Community]], a neighborhood in Tampa, Florida
* [[Northeast (Billings)]], a section of Billings, Montana

==People==
* [[Sam Northeast]] (born 1989), English cricketer

== Airlines ==
* [[Northeast Airlines]], a now defunct US airline which began operations in 1931 and merged with Delta Air Lines 1972
* [[Northeast Airlines (UK)]], a now defunct British airline which began operations in 1951 as BKS and was merged into British Airways in 1976
* [[Northeast Airlines (China)]], a planned start-up airline to be based in Shenyang, People's Republic of China
* [[Northeast Express Regional Airlines]], a now defunct Maine-based regional airline which operated as an affiliate of Northwest Airlines

== Sports ==
* [[NorthEast United FC]], football team based in Guwahati, Assam, India which competes in Indian Super League 
* [[Northeastern Warriors]], badminton team based in Guwahati, Assam, India which competes in Premier Badminton League 
* [[NEROCA FC|North East Re-Organising Cultural Association FC]], football club based in Imphal, Manipur, India which competes in I-League 
* [[North East Tigers]], boxing team which competes in Super Boxing League (India)
* [[Northeastern Huskies]], are athletic teams representing Northeastern University in Boston, Massachusetts, United States

==Trains==
* ''Northeastern Limited,'' named passenger train of the [[Illinois Central]], from [[Shreveport, Louisiana]] to [[Meridian, Mississippi]].

== Other uses ==
* [[Northeast (film)|''Northeast'' (film)]], a 2005 Argentine film
* [[North East Island (disambiguation)]]
* [[Northeastern University]], a university in Boston, Massachusetts, USA
* [[Northeastern University (disambiguation)]]
* [[Northeastern Conference]], a high school athletic conference in Massachusetts

== See also ==
* [[Nord-Est (disambiguation)]], French for northeast
* [[Nor'easter]], a storm
* [[Nord-Ost]], a Russian musical theatre production
* {{intitle|northeast OR "north-east" OR "north east" OR northeastern OR "north-eastern" OR "north eastern"|All articles with "Northeast" (or a variant) in the title}}
* {{intitle|(northeast OR "north-east" OR "north east" OR  northeastern OR  "north-eastern" OR "north eastern") (university OR college OR school)|All articles with "Northeast" (or a variant) and "University/College/School" in the title}}
* {{intitle|(northeast OR "north-east" OR "north east" OR  northeastern OR  "north-eastern" OR "north eastern") (region OR district OR province)|All articles with "Northeast" (or a variant) and "Region/District/Province" in the title}}

{{Disambiguation|geo}}
[[Category:Orientation (geometry)]]

[[fr:Nord-Est]]
[[pam:Pangulu-aslagan]]
[[pt:Nordeste (desambiguação)]]
[[fi:Koillinen]]
[[vo:North East]]
[[war:Dumagsaan]]
[[zh:东北]]</text>
      <sha1>ls1ahzbr3x0pchom4kinsc940vz6iqc</sha1>
    </revision>
  </page>
  <page>
    <title>Ore's theorem</title>
    <ns>0</ns>
    <id>3100586</id>
    <revision>
      <id>858191044</id>
      <parentid>835447130</parentid>
      <timestamp>2018-09-05T17:30:57Z</timestamp>
      <contributor>
        <username>Tidycanary</username>
        <id>34582083</id>
      </contributor>
      <comment>The previous first paragraph was the proof of a completely different statement (Let G be a graph on n vertices and suppose that for every two non-adjacent vertices v and u, deg(v) + deg(u) ≥ n + 1 . Then G is Hamiltonian-connected.)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8444">{{for|Ore's theorem in ring theory|Ore condition}}
'''Ore's theorem''' is a result in [[graph theory]] proved in 1960 by [[Norway|Norwegian]] mathematician [[Øystein Ore]]. It gives a sufficient condition for a graph to be [[Hamiltonian graph|Hamiltonian]], essentially stating that a graph with sufficiently many edges must contain a [[Hamilton cycle]]. Specifically, the theorem considers the sum of the [[Degree (graph theory)|degrees]] of pairs of [[non-adjacent]] [[Vertex (graph theory)|vertices]]: if every such pair has a sum that at least equals the total number of vertices in the graph, then the graph is Hamiltonian.

==Formal statement==
Let {{math|''G''}} be a (finite and simple) [[Graph (discrete mathematics)|graph]] with {{math|''n'' ≥ 3}} vertices. We denote by {{math|deg ''v''}} the degree of a vertex {{math|''v''}} in {{math|''G''}}, i.e. the number of [[incidence (graph theory)|incident]] [[Edge (graph theory)|edges]] in {{math|''G''}} to {{math|''v''}}. Then, Ore's theorem states that if

:{{math|deg ''v'' + deg ''w'' ≥ ''n''}} for every pair of distinct [[non-adjacent]] vertices {{math|''v''}} and {{math|''w''}} of {{math|''G''}} (*)

then {{math|''G''}} is [[Hamiltonian path|Hamiltonian]].

==Proof==
It is equivalent to show that every non-Hamiltonian graph {{mvar|G}} does not obey condition (*). Accordingly, let {{mvar|G}} be a graph on {{math|''n'' ≥ 3}} vertices that is not Hamiltonian, and let {{mvar|H}} be formed from {{mvar|G}} by adding edges one at a time that do not create a Hamiltonian cycle, until no more edges can be added. Let {{math|''x''}} and {{math|''y''}} be any two non-adjacent vertices in {{mvar|H}}. Then adding edge {{math|''xy''}} to {{mvar|H}} would create at least one new Hamiltonian cycle, and the edges other than {{math|''xy''}} in such a cycle must form a [[Hamiltonian path]] {{math|''v''&lt;sub&gt;1&lt;/sub&gt;''v''&lt;sub&gt;2&lt;/sub&gt;...''v''&lt;sub&gt;''n''&lt;/sub&gt;}} in {{mvar|H}} with {{math|1=''x'' = ''v''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|1=''y'' = ''v&lt;sub&gt;n&lt;/sub&gt;''}}. For each index {{math|''i''}} in the range {{math|2 ≤ ''i'' ≤ ''n''}}, consider the two possible edges in {{mvar|H}} from {{math|''v''&lt;sub&gt;1&lt;/sub&gt;}} to {{math|''v''&lt;sub&gt;''i''&lt;/sub&gt;}} and from {{math|''v''&lt;sub&gt;''i'' &amp;minus; 1&lt;/sub&gt;}} to {{math|''v''&lt;sub&gt;''n''&lt;/sub&gt;}}. At most one of these two edges can be present in {{mvar|H}}, for otherwise the cycle {{math|''v''&lt;sub&gt;1&lt;/sub&gt;''v''&lt;sub&gt;2&lt;/sub&gt;...''v''&lt;sub&gt;''i'' &amp;minus; 1&lt;/sub&gt;''v''&lt;sub&gt;''n''&lt;/sub&gt;''v''&lt;sub&gt;''n'' &amp;minus; 1&lt;/sub&gt;...''v''&lt;sub&gt;''i''&lt;/sub&gt;}} would be a Hamiltonian cycle. Thus, the total number of edges incident to either {{math|''v''&lt;sub&gt;1&lt;/sub&gt;}} or {{math|''v''&lt;sub&gt;''n''&lt;/sub&gt;}} is at most equal to the number of choices of {{math|''i''}}, which is {{math|''n'' &amp;minus; 1}}. Therefore, {{mvar|H}} does not obey property (*), which requires that this total number of edges ({{math|deg ''v''&lt;sub&gt;1&lt;/sub&gt; + deg ''v''&lt;sub&gt;''n''&lt;/sub&gt;}}) be greater than or equal to {{math|''n''}}. Since the vertex degrees in {{mvar|G}} are at most equal to the degrees in {{mvar|H}}, it follows that {{mvar|G}} also does not obey property&amp;nbsp;(*).

==Algorithm==
{{harvtxt|Palmer|1997}} describes the following simple algorithm for constructing a Hamiltonian cycle in a graph meeting Ore's condition.

#Arrange the vertices arbitrarily into a cycle, ignoring adjacencies in the graph.
#While the cycle contains two consecutive vertices ''v''&lt;sub&gt;''i''&lt;/sub&gt; and ''v''&lt;sub&gt;''i''&amp;nbsp;+&amp;nbsp;1&lt;/sub&gt; that are not adjacent in the graph, perform the following two steps:
#*Search for an index ''j'' such that the four vertices ''v''&lt;sub&gt;''i''&lt;/sub&gt;, ''v''&lt;sub&gt;''i''&amp;nbsp;+&amp;nbsp;1&lt;/sub&gt;, ''v''&lt;sub&gt;''j''&lt;/sub&gt;, and ''v''&lt;sub&gt;''j''&amp;nbsp;+&amp;nbsp;1&lt;/sub&gt; are all distinct and such that the graph contains edges from ''v''&lt;sub&gt;''i''&lt;/sub&gt; to ''v''&lt;sub&gt;''j''&lt;/sub&gt; and from ''v''&lt;sub&gt;''j''&amp;nbsp;+&amp;nbsp;1&lt;/sub&gt; to ''v''&lt;sub&gt;''i''&amp;nbsp;+&amp;nbsp;1&lt;/sub&gt;
#*Reverse the part of the cycle between ''v''&lt;sub&gt;''i''&amp;nbsp;+&amp;nbsp;1&lt;/sub&gt; and ''v''&lt;sub&gt;''j''&lt;/sub&gt; (inclusive).

Each step increases the number of consecutive pairs in the cycle that are adjacent in the graph, by one or two pairs (depending on whether ''v''&lt;sub&gt;''j''&lt;/sub&gt; and ''v''&lt;sub&gt;''j''&amp;nbsp;+&amp;nbsp;1&lt;/sub&gt; are already adjacent), so the outer loop can only happen at most ''n'' times before the algorithm terminates, where ''n'' is the number of vertices in the given graph. By an argument similar to the one in the proof of the theorem, the desired index ''j'' must exist, or else the nonadjacent vertices ''v''&lt;sub&gt;''i''&lt;/sub&gt; and ''v''&lt;sub&gt;''i''&amp;nbsp;+&amp;nbsp;1&lt;/sub&gt; would have too small a total degree. Finding ''i'' and ''j'', and reversing part of the cycle, can all be accomplished in time O(''n''). Therefore, the total time for the algorithm is O(''n''&lt;sup&gt;2&lt;/sup&gt;), matching the number of edges in the input graph.

==Related results==
Ore's theorem is a generalization of [[Dirac's theorem on Hamiltonian cycles|Dirac's theorem]] that, when each vertex has degree at least {{math|''n''/2}}, the graph is Hamiltonian. For, if a graph meets Dirac's condition, then clearly each pair of vertices has degrees adding to at least {{math|''n''}}.

In turn Ore's theorem is generalized by the [[Bondy–Chvátal theorem]]. One may define a closure operation on a graph in which, whenever two nonadjacent vertices have degrees adding to at least {{math|''n''}}, one adds an edge connecting them; if a graph meets the conditions of Ore's theorem, its closure is a [[complete graph]]. The Bondy–Chvátal theorem states that a graph is Hamiltonian if and only if its closure is Hamiltonian; since the complete graph is Hamiltonian, Ore's theorem is an immediate consequence.

{{harvtxt|Woodall|1972}} found a version of Ore's theorem that applies to [[directed graph]]s. Suppose a digraph ''G'' has the property that, for every two vertices ''u'' and ''v'', either there is an edge from ''u'' to ''v'' or the outdegree of ''u'' plus the indegree of ''v'' equals or exceeds the number of vertices in ''G''. Then, according to Woodall's theorem, ''G'' contains a directed Hamiltonian cycle. Ore's theorem may be obtained from Woodall by replacing every edge in a given undirected graph by a pair of directed edges. A closely related theorem by {{harvtxt|Meyniel|1973}} states that an ''n''-vertex [[Strongly connected component|strongly connected]] digraph with the property that, for every two nonadjacent vertices ''u'' and ''v'', the total number of edges incident to ''u'' or ''v'' is at least 2''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 must be Hamiltonian.

Ore's theorem may also be strengthened to give a stronger conclusion than Hamiltonicity as a consequence of the degree condition in the theorem. Specifically, every graph satisfying the conditions of Ore's theorem is either a [[regular graph|regular]] [[complete bipartite graph]] or is [[pancyclic graph|pancyclic]] {{harv|Bondy|1971}}.

==References==
*{{citation
 | last = Bondy | first = J. A. | authorlink = John Adrian Bondy
 | doi = 10.1016/0095-8956(71)90016-5
 | issue = 1
 | journal = [[Journal of Combinatorial Theory, Series B]]
 | pages = 80–84
 | title = Pancyclic graphs I
 | volume = 11
 | year = 1971}}.
*{{Citation
 | last=Meyniel
 | first=M.
 | title=Une condition suffisante d'existence d'un circuit hamiltonien dans un graphe orienté
 | journal=[[Journal of Combinatorial Theory, Series B]] 
 | language = French
 | volume=14
 | year=1973
 | pages=137–147
 | doi=10.1016/0095-8956(73)90057-9
 | issue=2}}.
*{{citation|first=Ø.|last=Ore|authorlink=Øystein Ore|title=Note on Hamilton circuits|journal=[[American Mathematical Monthly]]|volume=67|year=1960|page=55|issue=1|jstor=2308928|doi=10.2307/2308928}}.
*{{citation
 | last = Palmer | first = E. M.
 | doi = 10.1016/S0898-1221(97)00225-3
 | issue = 11
 | journal = Computers &amp; Mathematics with Applications
 | mr = 1486890
 | pages = 113–119
 | title = The hidden algorithm of Ore's theorem on Hamiltonian cycles
 | volume = 34
 | year = 1997}}.
*{{citation
 | last = Woodall | first = D. R.
 | journal = Proceedings of the London Mathematical Society | series = Third Series
 | mr = 0318000
 | pages = 739–755
 | title = Sufficient conditions for circuits in graphs
 | volume = 24
 | year = 1972
 | doi = 10.1112/plms/s3-24.4.739 }}.

[[Category:Extremal graph theory]]
[[Category:Theorems in graph theory]]
[[Category:Articles containing proofs]]
[[Category:Hamiltonian paths and cycles]]</text>
      <sha1>h7r14qwx86mo7h52w3197itmdvdpzai</sha1>
    </revision>
  </page>
  <page>
    <title>Organon</title>
    <ns>0</ns>
    <id>499019</id>
    <revision>
      <id>871119087</id>
      <parentid>871118892</parentid>
      <timestamp>2018-11-29T01:40:59Z</timestamp>
      <contributor>
        <username>Botteville</username>
        <id>347079</id>
      </contributor>
      <minor/>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12542">{{italic title}}
{{about|Aristotle's works on logic|a discussion of Aristotelian logic as a system|Term logic|other uses}}
The '''''Organon''''' (Greek: Ὄργανον, meaning "instrument, tool, organ") is the standard collection of [[Aristotle]]'s six works on [[logic]]. The name ''Organon'' was given by Aristotle's followers, the [[Peripatetic school|Peripatetic]]s. They are as follows:
{{Corpus Aristotelicum table |logic |key=omit}}

== Constitution of the texts ==

The order of the works is not chronological (which is now hard to determine) but was deliberately chosen by [[Theophrastus]] to constitute a well-structured system. Indeed, parts of them seem to be a scheme of a lecture on logic.  The arrangement of the works was made by [[Andronicus of Rhodes]] around 40 BC.{{r|Oxford}}

Aristotle's ''Metaphysics'' has some points of overlap with the works making up the ''Organon'' but is not traditionally considered part of it; additionally there are works on logic attributed, with varying degrees of plausibility, to Aristotle that were not known to the Peripatetics.

:1. The ''[[Categories (Aristotle)|Categories]]'' (Latin: ''Categoriae'') introduces Aristotle's 10-fold classification of that which exists: substance, quantity, quality, relation, place, time, situation, condition, action, and passion.
:2. ''[[De Interpretatione|On Interpretation]]'' (Latin: ''De Interpretatione'', Greek ''Peri hermeneias'') introduces Aristotle's conception of [[proposition]] and [[judgment]], and the various relations between affirmative, negative, universal, and particular propositions. Aristotle discusses the [[square of opposition]] or square of [[Apuleius]] in Chapter 7 and its appendix Chapter 8. Chapter 9 deals with the [[problem of future contingents]]. 
:3. The ''[[Prior Analytics]]'' (Latin: ''Analytica Priora'') introduces his [[syllogism|syllogistic]] method (see [[term logic]]), argues for its correctness, and discusses inductive inference.
:4. The ''[[Posterior Analytics]]'' (Latin: ''Analytica Posteriora'') deals with [[Demonstration (teaching)|demonstration]], [[definition]], and [[scientific knowledge]].
:5. The ''[[Topics (Aristotle)|Topics]]'' (Latin: ''Topica'') treats issues in constructing valid arguments, and inference that is probable, rather than certain.  It is in this treatise that Aristotle mentions the [[Predicables]], later discussed by [[Porphyry (philosopher)|Porphyry]] and the scholastic logicians.
:6. The [[On Sophistical Refutations|''Sophistical Refutations'']] (Latin: ''De Sophisticis Elenchis'') gives a treatment of logical fallacies, and provides a key link to Aristotle's work on rhetoric.

Whereas the modern ''Organon'' comprises only the above six works, the medieval ''Organon'', including the Arabic tradition, appends to the list Aristotle's ''Rhetoric'' and his ''Poetics''.&lt;ref&gt;See Black, Deborah L., ''Logic and Aristotle’s Rhetoric and Poetics in medieval Arabic philosophy'', p. 1. Also [https://plato.stanford.edu/entries/aristotle-logic/#AriLogWorOrg the “Organon” entry] at the [[Stanford Encyclopedia of Philosophy|SEP]].&lt;/ref&gt;

== Influence ==

The ''Organon'' was used in the school founded by Aristotle at the [[Lyceum]], and some parts of the works seem to be a scheme of a lecture on logic. So much so that after Aristotle's death, his publishers ([[Andronicus of Rhodes]] in 50 BC, for example) collected these works.

Following the collapse of the [[Western Roman Empire]] in the fifth century, much of Aristotle's work was lost in the Latin West. The ''Categories'' and ''On Interpretation'' are the only significant logical works that were available in the early Middle Ages.  These had been translated into [[Latin]] by [[Boethius]].  The other logical works were not available in Western Christendom until translated into Latin in the 12th century. However, the original Greek texts had been preserved in the [[Greek language|Greek]]-speaking lands of the [[Eastern Roman Empire]] (aka [[Byzantium]]). In the mid-twelfth century, [[James of Venice]] translated into Latin the ''Posterior Analytics'' from Greek manuscripts found in Constantinople.

The books of Aristotle were available in the early Arab Empire, and after 750 AD Muslims had most of them, including the ''Organon'', translated into Arabic, sometimes via earlier Syriac translations.  They were studied by [[Islamic]] and [[Jewish]] scholars, including Rabbi [[Moses Maimonides]] (1135–1204) and the Muslim Judge [[Ibn Rushd]], known in the West as Averroes (1126–1198); both were originally from [[Cordoba, Spain]], although the former left Iberia and by 1168 lived in Egypt.

All the major scholastic philosophers wrote commentaries on the ''Organon''. [[Aquinas]], [[William of Ockham|Ockham]] and [[Duns Scotus|Scotus]] wrote commentaries on ''On Interpretation''. Ockham and Scotus wrote commentaries on the ''Categories'' and ''Sophistical Refutations''. [[Grosseteste]] wrote an influential commentary on the ''Posterior Analytics''.

In the [[Age of Enlightenment|Enlightenment]] there was a revival of interest in logic as the basis of rational enquiry, and a number of texts, most successfully the [[Port-Royal Logic]], polished Aristotelian term logic for pedagogy.  During this period, while the logic certainly was based on that of Aristotle, Aristotle's writings themselves were less often the basis of study.  There was a tendency in this period to regard the [[logical system]]s of the day to be complete, which in turn no doubt stifled innovation in this area. However [[Francis Bacon]] published his ''[[Novum Organum]]'' ("The New ''Organon''") as a scathing attack in [[1620 in literature|1620]].{{r|teaching}}  [[Immanuel Kant]] thought that there was nothing else to invent after the work of Aristotle, and the famous logic historian [[Karl von Prantl]] claimed that any logician who said anything new about logic was "confused, stupid or perverse." These examples illustrate the force of influence which Aristotle's works on logic had. Indeed, he had already become known by the Scholastics (medieval Christian scholars) as "The Philosopher", due to the influence he had upon medieval theology and philosophy. His influence continued into the Early Modern period and Organon was the basis of school philosophy even in the beginning of 18th century.&lt;ref&gt;{{Cite book | publisher = Cambridge University Press| isbn = 9780521822428| last = Rutherford| first = Donald| title = The Cambridge Companion to Early Modern Philosophy| year = 2006| page = 170ff}}&lt;/ref&gt;
Since the logical innovations of the 19th century, particularly the formulation of modern [[predicate logic]], Aristotelian logic had for a time fallen out of favor among many [[analytic philosophy|analytic philosophers]].

However the logic historian [[John Corcoran (logician)|John Corcoran]] and others have shown that the works of [[George Boole]] and [[Gottlob Frege]]—which laid the groundwork for modern mathematical logic—each represent a continuation and extension to Aristote's logic and in no way contradict or displace it. 
&lt;ref&gt;[[George Boole]]. 1854/2003. The Laws of Thought, facsimile of 1854 edition, with an introduction by J. Corcoran. Buffalo: Prometheus Books (2003). Reviewed by James van Evra in Philosophy in Review.24 (2004) 167–169.&lt;/ref&gt; 
&lt;ref&gt;[[John Corcoran (logician)|John Corcoran]], Aristotle's Prior Analytics and Boole's Laws of Thought, History and Philosophy of Logic, vol.  24 (2003), pp. 261–288.&lt;/ref&gt;  
Boole fully accepted and endorsed Aristotle’s logic, and Frege included Aristotle's [[square of opposition]] at the end of his groundbreaking [[Begriffsschrift]] to show the harmony of his theory with the Aristotelian tradition.&lt;ref&gt;[[Jean-Yves Béziau]] “Is modern logic non-Aristotelian?”, to appear in D.Zaitsev (ed), Nikolai Vasiliev's Logical Legacy and Modern Logic, Springer, Heidelberg, 2015.&lt;/ref&gt;

== See also ==
* ''[[Ignoratio elenchi]]''

== Notes ==
{{reflist|refs=
&lt;ref name=Oxford&gt;Hammond, p.&amp;nbsp;64,  "Andronicus Rhodus"&lt;/ref&gt;
&lt;ref name=teaching&gt;The Teaching Company&amp;nbsp;— Birth of the Modern Mind&lt;/ref&gt;
}}

== References ==

; Primary sources
{{refbegin}}
* {{Citation
 | surname1    = Edghill
 | given1      = E. M. (translator)
 | authorlink  = Ella Mary Edghill
 | year        =  2007
 | title       = Categories
 | publisher   = eBooks @ Adelaide
 | place = The [[University of Adelaide]]
 | url = http://ebooks.adelaide.edu.au/a/aristotle/categories/
}}.

* {{Citation
 | surname1    = Edghill
 | given1      = E. M. (translator)
 | authorlink  = Ella Mary Edghill
 | year        =  2007
 | title       = On Interpretation
 | publisher   = eBooks @ Adelaide
 | place = The [[University of Adelaide]]
 | url = http://ebooks.adelaide.edu.au/a/aristotle/interpretation/
}}.

* {{Citation
 | surname1    = Jenkinson
 | given1      = A. J. (translator)
 | year        =  2007
 | title       = Prior Analytics
 | publisher   = eBooks @ Adelaide
 | place = The [[University of Adelaide]]
 | url = http://ebooks.adelaide.edu.au/a/aristotle/a8pra/
}}.

* {{Citation
 | surname1    = Mure
 | given1      = G. R. G. (translator)
 | authorlink = Geoffrey Reginald Gilchrist Mure
 | year        =  2007
 | title       = Posterior Analytics
 | publisher   = eBooks @ Adelaide
 | place = The [[University of Adelaide]]
 | url = http://ebooks.adelaide.edu.au/a/aristotle/a8poa/
}}.

* {{Citation
 | surname1    = Pickard-Cambridge
 | given1      = W. A. (translator)
 | year        =  2007
 | title       = Topics
 | publisher   = eBooks @ Adelaide
 | place = The [[University of Adelaide]]
 | url = http://ebooks.adelaide.edu.au/a/aristotle/a8t/
}}.

* {{Citation
 | surname1    = Pickard-Cambridge
 | given1      = W. A. (translator)
 | year        =  2007
 | title       = On Sophistical Refutations
 | publisher   = eBooks @ Adelaide
 | place = The [[University of Adelaide]]
 | url = http://ebooks.adelaide.edu.au/a/aristotle/sophistical/
}}.

; Studies

* Bocheński, I. M., 1951. ''Ancient Formal Logic''. Amsterdam: North-Holland.
*[[Jan Łukasiewicz]], 1951.  ''Aristotle's Syllogistic, from the Standpoint of Modern Formal Logic''. Oxford: Clarendon Press.
* Lea, Jonathan 1980. ''Aristotle and Logical Theory'', Cambridge: Cambridge University Press.
* Monteil, Jean-François ''La transmission d’Aristote par les Arabes à la chrétienté occidentale: une trouvaille relative au De Interpretatione'', Revista Española de Filosofia Medieval 11: 181-195
* Monteil, Jean-François ''Isidor Pollak et les deux traductions arabes différentes du De interpretatione d’Aristote'', Revue d’Études Anciennes 107: 29-46 (2005).
* Monteil, Jean-François ''Une exception allemande: la traduction du De Interpretatione par le Professeur Gohlke: la note 10 sur les indéterminées d’Aristote'', Revues de Études Anciennes 103: 409-427 (2001).
* Parry and Hacker, 1991. ''Aristotelian Logic''. Albany: State University of New York Press.
* Rose, Lynn E., 1968. ''Aristotle's Syllogistic''. Springfield, Ill.: Clarence C. Thomas.
* Whitaker, C.W.A. 1996. ''Aristotle's De interpretatione. Contradiction and Dialectic'', Oxford: Clarendon Press.
* Veatch, Henry B., 1969. ''Two Logics: The Conflict between Classical and Neo-Analytic Philosophy.'' Evanston: Northwestern University Press.
{{refend}}

== External links ==
{{commonscat|Organon (Aristotle)}}

{{Wikisource}}

{{EB1911 poster|Organon}}
* {{cite SEP |url-id=aristotle-logic |title=Aristotle's Logic |last=Smith |first=Robin}}.
* {{cite SEP |url-id=square |title=Traditional Square of Opposition |last=Parsons |first=Terence}}.
* [http://www.iep.utm.edu/a/aris-log.htm Aristotle: Logic] entry by [[Louis Groarke]] in the [[Internet Encyclopedia of Philosophy]].
* Turner, W., 1903.  '[https://web.archive.org/web/20050908014723/http://www.nd.edu/Departments/Maritain/etext/hop.htm History of Philosophy]'.  Ginn and Co, Boston.  All references in this article are to [https://web.archive.org/web/20050829000817/http://www.nd.edu/Departments/Maritain/etext/hop11.htm Chapter nine on 'Aristotle'].
* [https://archive.org/details/AristotleOrganon ''Aristotle Organon And Other Works'' e-book] at archive.org.
* [http://thefirstscience.org/syllogistic-machine/  Interactive Syllogistic Machine for Aristotle's Logic], a web-based syllogistic machine for exploring fallacies, figures, terms, and modes of syllogisms.

{{Aristotelianism}}

[[Category:Works by Aristotle| ]]
[[Category:History of logic]]
[[Category:Logic literature]]
[[Category:Term logic]]</text>
      <sha1>9zzz2tgj5gtu9mna2bmh0ax5ca7qump</sha1>
    </revision>
  </page>
  <page>
    <title>Outline of geometry</title>
    <ns>0</ns>
    <id>6473626</id>
    <revision>
      <id>828155125</id>
      <parentid>827522018</parentid>
      <timestamp>2018-02-28T21:52:00Z</timestamp>
      <contributor>
        <username>CBM</username>
        <id>1108292</id>
      </contributor>
      <minor/>
      <comment>Remove self-reference, restore header</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4279">{{general geometry}}

'''[[Geometry]]''' is a branch of [[mathematics]] concerned with questions of shape, size, relative position of figures, and the properties of space. Geometry is one of the oldest mathematical sciences.

{{TOC limit|limit=2}}

== Classical branches ==

* [[Algebraic geometry]] —
* [[Analytic geometry]] —
* [[Differential geometry]] —
* [[Euclidean geometry]] —
* [[Non-Euclidean geometry]] —
* [[Projective geometry]] —
* [[Riemannian geometry]] —

== Contemporary branches ==
* [[Absolute geometry]]
* [[Affine geometry]]
* [[Archimedes' use of infinitesimals]]
* [[Birational geometry]]
* [[Complex geometry]]
* [[Combinatorial geometry]]
* [[Computational geometry]]
* [[Conformal geometry]]
* [[Constructive solid geometry]]
* [[Contact geometry]]
* [[Convex geometry]]
* [[Descriptive geometry]]
* [[Digital geometry]]
* [[Discrete geometry]]
* [[Distance geometry]]
* [[Elliptic geometry]]
* [[Enumerative geometry]]
* [[Epipolar geometry]]
* [[Finite geometry]]
* [[Geometry of numbers]]
* [[Hyperbolic geometry]]
* [[Information geometry]]
* [[Integral geometry]]
* [[Inversive geometry]]
* [[Klein geometry]]
* [[Lie sphere geometry]]
* [[Computational geometry#Numerical computational geometry|Numerical geometry]]
* [[Ordered geometry]]
* [[Parabolic geometry (differential geometry)|Parabolic geometry]]
* [[Euclidean plane geometry|Plane geometry]]
* [[Quantum geometry]]
* [[Ruppeiner geometry]]
* [[Spherical geometry]]
* [[Symplectic geometry]]
* [[Synthetic geometry]]
* [[Systolic geometry]]
* [[Taxicab geometry]]
* [[Toric geometry]]
* [[Transformation geometry]]
* [[Tropical geometry]]

==History of geometry==

[[History of geometry]]
* [[Timeline of geometry]]
* [[Babylonian geometry]]
* [[Egyptian geometry]]
* Ancient Greek geometry
** [[Euclidean geometry]]
*** [[Pythagorean theorem]]
*** [[Euclid's Elements|Euclid's ''Elements'']]
*** ''[[Measurement of a Circle]]''
* [[Indian mathematics]]
** [[Bakhshali manuscript]]
* Modern geometry
** [[History of analytic geometry]]
*** [[History of the Cartesian coordinate system]]
** [[History of non-Euclidean geometry]]
** [[History of topology]]
** [[History of algebraic geometry]]

==General geometry concepts==
===General concepts===

* [[Geometric progression]] — [[Geometric shape]] — [[Geometry]] — [[Pi]] — [[angular velocity]] — [[velocity|linear velocity]] — [[De Moivre's formula|De Moivre's theorem]] — [[parallelogram rule]] — [[Pythagorean theorem]] — [[similar triangles]] — [[trigonometric identity]] — [[unit circle]] — [[Trapezoid]] — [[Triangle]] — [[Theorem]] — [[point (geometry)|point]] — [[line (mathematics)#Ray|ray]] — [[plane (mathematics)|plane]] — [[line (mathematics)|line]] — [[line segment]]

===Measurements===

* [[bearing (navigation)|Bearing]]
* [[Angle]]
* [[degree (angle)|Degree]]
* [[minute of arc|Minute]]
* [[Radian]]
* [[Circumference]]
* [[Diameter]]

===Trigonometric functions===

* [[Trigonometric function]]
** [[Asymptotes]]
** [[Circular functions]]
** [[Periodic functions]]
** [[Law of cosines]]
** [[Law of sines]]

===Vectors===

{{Main|Vector (geometric)}}

* [[Amplitude]]
* [[Dot product]]
* [[Norm (mathematics)]] (also known as magnitude)
* [[Position vector]]
* [[Scalar multiplication]]
* [[Vector addition]]
* [[Zero vector]]

===Vector spaces and complex dimensions===

* [[Complex plane]]
* [[Imaginary axis]]
* [[Linear interpolation]]
* [[bijection|One-to-one]]
* [[Orthogonal]]
* [[Polar coordinate system]]
* [[Pole (complex analysis)|Pole]]
* [[Real axis]]
* [[Secant line]]
* [[CIrcular sector]] or "sector"
* [[Semiperimeter]]

==Lists==

* [[List of mathematical shapes]]
* [[List of geometers]]
* [[List of curves]]
* [[List of curves topics]]

==See also==
{{Portal|Geometry}}

* [[List of basic mathematics topics]]
* [[List of mathematics articles]]
* [[Table of mathematical symbols]]

==Further reading==
*{{cite book | last = Rich | first = Barnett | title = Schaum's Outline of Geometry |edition= 4th | publisher = McGraw-Hill | location = New York | year = 2009 | isbn = 978-0-07-154412-2 }}

==External links==

{{Outline footer}}

[[Category:Wikipedia outlines|Geometry|]]
[[Category:Geometry| ]]
[[Category:Mathematics-related lists|Geometry]]</text>
      <sha1>76gjtrmxmc030nhml3i6y2to27ubxg5</sha1>
    </revision>
  </page>
  <page>
    <title>Percentage</title>
    <ns>0</ns>
    <id>64493</id>
    <revision>
      <id>870155982</id>
      <parentid>870095419</parentid>
      <timestamp>2018-11-22T20:01:06Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/42.109.209.21|42.109.209.21]] ([[User talk:42.109.209.21|talk]]) to last revision by KH-1. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15877">{{For|the 2014 film|Percentage (film)}}
[[File:Web-browser usage on Wikimedia.svg|thumb|A [[pie chart]] showing the '''percentage''' by web browser visiting [[Wikimedia Foundation|Wikimedia]] sites (April 2009 to 2012)]]
In [[mathematics]], a '''percentage''' is a number or [[ratio]] expressed as a [[fraction (mathematics)|fraction]] of 100. It is often [[Denotation|denoted]] using the [[percent sign]], "%", or the abbreviations "pct.", "pct"; sometimes the abbreviation "pc" is also used.&lt;ref&gt;https://www.telegraph.co.uk/finance/economics/11329769/Eurozone-officially-falls-into-deflation-piling-pressure-on-ECB.html&lt;/ref&gt; A percentage is a [[Dimensionless quantity|dimensionless number]] (pure number).

== Examples  ==
For example, 45% (read as "forty-five percent") is equal to [[fraction (mathematics)|{{sfrac|45|100}}]], [[Ratio|45:100]], or [[decimal|0.45]]. 
Percentages are often used to express a proportionate part of a total.

(Similarly, one can express a number as a fraction of 1,000 using the term "[[per mille]]" or the symbol "&lt;big&gt;‰&lt;/big&gt;".)

===Example 1===
If 50% of the total number of students in the class are male, that means that 50 out of every 100 students are male. If there are 500 students, then 250 of them are male.

===Example 2===
An increase of $0.15 on a price of $2.50 is an increase by a fraction of {{sfrac|0.15|2.50}} = 0.06. Expressed as a percentage, this is a 6% increase.

While many percentage values are between 0 and 100, there is no mathematical restriction and percentages may take on other values.&lt;ref&gt;{{citation|first1=Jeffrey|last1=Bennett|first2=William|last2=Briggs|title=Using and Understanding Mathematics / A Quantitative Reasoning Approach|edition=3rd|year=2005|publisher=Pearson Addison Wesley|isbn=0-321-22773-5|page=134}}&lt;/ref&gt; For example, it is common to refer to 111% or −35%, especially for [[percent change]]s and comparisons.

== History ==
In [[Ancient Rome]], long before the existence of the decimal system, computations were often made in fractions which were multiples of {{sfrac|100}}. For example, [[Augustus]] levied a tax of {{sfrac|100}} on goods sold at auction known as ''[[centesima rerum venalium]]''. Computation with these fractions was equivalent to computing percentages. As denominations of money grew in the [[Middle Ages]], computations with a denominator of 100 became more standard and from the late 15th century to the early 16th century it became common for arithmetic texts to include such computations. Many of these texts applied these methods to profit and loss, interest rates, and the [[Rule of three (mathematics)|Rule of Three]]. By the 17th century it was standard to quote interest rates in hundredths.&lt;ref&gt;{{cite book|last=Smith|first=D.E.|title=History of Mathematics|isbn=0-486-20430-8
|publisher=Courier Dover Publications|origyear=1951|year=1958|volume=2|pages=247–249}}&lt;/ref&gt;

==Percent sign==
{{main|percent sign}}
[[Image:Percent 18e.svg|thumb|A percent sign]]
The term "per cent" is derived from the Latin ''per centum'', meaning "by the hundred".&lt;ref&gt;American Heritage Dictionary of the English Language, 3rd ed. (1992) Houghton Mifflin&lt;/ref&gt; 
The [[percentage sign|sign for "per cent"]] evolved by gradual contraction of the [[Italian language|Italian]] term ''per cento'', meaning "for a hundred". The "per" was often abbreviated as "p." and eventually disappeared entirely. The "cento" was contracted to two circles separated by a horizontal line, from which the modern "%" symbol is derived.&lt;ref&gt;Smith p. 250&lt;/ref&gt;

== Calculations ==
The percent value is computed by multiplying the numeric value of the ratio by 100. For example, to find 50 apples as a percentage of 1250 apples, first compute the ratio {{sfrac|50|1250}} = 0.04, and then multiply by 100 to obtain 4%. The percent value can also be found by multiplying first, so in this example the 50 would be multiplied by 100 to give 5,000, and this result would be divided by 1250 to give 4%.

To calculate a percentage of a percentage, convert both percentages to fractions of 100, or to decimals, and multiply them. For example, 50% of 40% is:
:{{nowrap|1= {{sfrac|50|100}} × {{sfrac|40|100}} = 0.50 × 0.40 = 0.20 = {{sfrac|20|100}} = 20%.}}
It is not correct to divide by 100 and use the percent sign at the same time. (E.g. {{nowrap|1= 25% = {{sfrac|25|100}} = 0.25}}, not {{sfrac|25%|100}}, which actually is {{nowrap|1= {{sfrac|{{frac|25|100}}|100}} = 0.0025}}. A term such as {{nowrap|{{sfrac|100|100}}%}} would also be incorrect, this would be read as 1 percent even if the intent was to say 100%.)

Whenever we talk about a percentage, it is important to specify what it is relative to, i.e. what is the total that corresponds to 100%. The following problem illustrates this point.

:''In a certain college 60% of all students are female, and 10% of all students are computer science majors. If 5% of female students are computer science majors, what percentage of computer science majors are female?''

We are asked to compute the [[ratio]] of female computer science majors to all computer science majors. We know that 60% of all students are female, and among these 5% are computer science majors, so we conclude that {{sfrac|60|100}} × {{sfrac|5|100}} = {{sfrac|3|100}} or 3% of all students are female computer science majors. Dividing this by the 10% of all students that are computer science majors, we arrive at the answer: {{sfrac|3%|10%}} = {{sfrac|30|100}} or 30% of all computer science majors are female.

This example is closely related to the concept of [[conditional probability]].

== Percentage increase and decrease ==
Due to inconsistent usage, it is not always clear from the context what a percentage is relative to. When speaking of a "10% rise" or a "10% fall" in a quantity, the usual interpretation is that this is relative to the ''initial value'' of that quantity. For example, if an item is initially priced at $200 and the price rises 10% (an increase of $20), the new price will be $220. Note that this final price is 110% of the initial price (100% + 10% = 110%).

Some other examples of [[Percent difference#Percentage change|percent changes]]:
* An increase of 100% in a quantity means that the final amount is 200% of the initial amount (100% of initial + 100% of increase = 200% of initial); in other words, the quantity has doubled.
* An increase of 800% means the final amount is 9 times the original (100% + 800% = 900% = 9 times as large).
* A decrease of 60% means the final amount is 40% of the original (100% – 60% = 40%).
* A decrease of 100% means the final amount is ''zero'' (100% – 100% = 0%).

In general, a change of {{math|''x''}} percent in a quantity results in a final amount that is 100&amp;nbsp;+&amp;nbsp;{{math|''x''}} percent of the original amount (equivalently, 1&amp;nbsp;+&amp;nbsp;0.01{{math|''x''}} times the original amount).

==Compounding percentages==

Percent changes applied sequentially ''do not add up'' in the usual way. For example, if the 10% increase in price considered earlier (on the $200 item, raising its price to $220) is followed by a 10% decrease in the price (a decrease of $22), the final price will be $198, ''not'' the original price of $200.  The reason for the apparent discrepancy is that the two percent changes (+10% and −10%) are measured relative to ''different'' quantities ($200 and $220, respectively), and thus do not "cancel out".

In general, if an increase of {{math|''x''}} percent is followed by a decrease of {{math|''x''}} percent, and the initial amount was {{math|''p''}}, the final amount is {{nowrap|1= {{math|''p''}}(1 + 0.01{{math|''x''}})(1 − 0.01{{math|''x''}}) = {{math|''p''}}(1 − (0.01{{math|''x''}}){{sup|2}})}}; thus the net change is an overall decrease by {{math|''x''}} percent ''of'' {{math|''x''}} percent (the square of the original percent change when expressed as a decimal number).  Thus, in the above example, after an increase and decrease of {{nowrap|1= {{math|''x''}} = 10 percent}}, the final amount, $198, was 10% of 10%, or 1%, less than the initial amount of $200. The net change is the same for a decrease of {{math|''x''}} percent followed by an increase of {{math|''x''}} percent; the final amount is {{nowrap|1= {{math|''p''}}(1 - 0.01{{math|''x''}})(1 + 0.01{{math|''x''}}) = {{math|''p''}}(1 − (0.01{{math|''x''}}){{sup|2}})}}.

This can be expanded for a case where you do not have the same percent change.  If the initial percent change is {{math|''x''}} and the second percent change is {{math|''y''}}, and the initial amount was {{math|''p''}}, then the final amount is {{nowrap|1= {{math|''p''}}(1 + 0.01{{math|''x''}})(1 + 0.01{{math|''y''}})}}.  To change the above example, after an increase of {{nowrap|1= {{math|''x''}} = 10 percent}} and decrease of {{nowrap|1= {{math|''y''}} = −5 percent}}, the final amount, $209, is 4.5% more than the initial amount of $200.

As shown above, percent changes can be applied in any order and have the same effect.

In the case of [[interest rate]]s, a very common but ambiguous way to say that an interest rate rose from 10% per annum to 15% per annum, for example, is to say that the interest rate increased by 5%, which could ''theoretically'' mean that it increased from 10% per annum to 10.05%  per annum. It is clearer to say that the interest rate increased by 5 [[percentage point]]s (pp). The same confusion between the different concepts of percent(age) and percentage points can potentially cause a major misunderstanding when journalists report about election results, for example, expressing both new results and differences with earlier results as percentages. For example, if a party obtains 41% of the vote and this is said to be a 2.5% increase, does that mean the earlier result was 40% (since 41 = &lt;span style="padding-right:0.1em;"&gt;{{nowrap|40 × (1 + {{sfrac|2.5|100}})}}&lt;/span&gt;) or 38.5% (since 41 = {{nowrap|38.5 + 2.5}})?

In financial markets, it is common to refer to an increase of one percentage point (e.g. from 3% per annum to 4% per annum) as an increase of "100 basis points".

== Word and symbol ==
{{main|Percent sign}}

In [[British English]], ''percent'' is usually written as two words (''per cent''), although ''percentage'' and ''[[percentile]]'' are written as one word.&lt;ref&gt;{{cite web|url=http://www.wsu.edu/~brians/errors/percent1.html|first=Paul|last=Brians|title=Percent/per cent|work=Common Errors in English Usage|publisher=Washington State University|accessdate=22 November 2010}}&lt;/ref&gt; In [[American English]], ''percent'' is the most common variant&lt;ref&gt;{{cite web|url=http://oxforddictionaries.com/view/entry/m_en_us1276846?rskey=eX1NKq&amp;result=1#m_en_us1276846|title=Percent (per cent)|publisher=Oxford Dictionaries |accessdate=22 November 2010}}&lt;/ref&gt; (but ''[[per mille]]'' is written as two words).

In the early 20th century, there was a dotted abbreviation form "''per cent.''", as opposed to "''per cent''". The form "''per cent.''" is still in use in the highly formal language found in certain documents like commercial loan agreements (particularly those subject to, or inspired by, common law), as well as in the [[Hansard]] transcripts of British Parliamentary proceedings. The term has been attributed to [[Latin]] ''per centum''.&lt;ref&gt;{{OED|Percent}}&lt;/ref&gt; The concept of considering values as parts of a hundred is originally [[Ancient Greece|Greek]]. The [[percent sign|symbol for percent]] (%) evolved from a symbol abbreviating the Italian ''per cento''. In some other languages, the form ''procent'' or ''prosent'' is used instead. Some languages use both a word derived from ''percent'' and an expression in that language meaning the same thing, e.g. Romanian ''procent'' and ''la sută'' (thus, ''10%'' can be read or sometimes written ''ten for [each] hundred'', similarly with the English ''one out of ten''). Other abbreviations are rarer, but sometimes seen.

Grammar and style guides often differ as to how percentages are to be written. For instance, it is commonly suggested that the word percent (or per cent) be spelled out in all texts, as in "1&amp;nbsp;percent" and not "1%". Other guides prefer the word to be written out in humanistic texts, but the symbol to be used in scientific texts. Most guides agree that they always be written with a numeral, as in "5&amp;nbsp;percent" and not "five percent", the only exception being at the beginning of a sentence: "Ten percent of all writers love style guides." Decimals are also to be used instead of fractions, as in "3.5&amp;nbsp;percent of the gain" and not "{{frac|3|1|2}} percent of the gain". However the titles of bonds issued by governments and other issuers use the fractional form, e.g. "{{frac|3|1|2}}% Unsecured Loan Stock 2032 Series 2". (When interest rates are very low, the number 0 is included if the interest rate is less than 1%, e.g. "{{frac|0|3|4}}% Treasury Stock", not "{{frac|3|4}}% Treasury Stock".) It is also widely accepted to use the percent symbol (%) in tabular and graphic material.

In line with common English practice, style guides—such as ''[[The Chicago Manual of Style]]''—generally state that the number and percent sign are written without any space in between.&lt;ref&gt;
{{cite web
 | title = The Chicago Manual of Style
 | publisher = [[University of Chicago Press]]
 | year = 2003
 | url = http://www.chicagomanualofstyle.org/
 | accessdate = 2007-01-05}}
&lt;/ref&gt;
However, the [[International System of Units]] and the [[ISO 31-0]] standard require a space.&lt;ref&gt;
{{cite web
 | title = The International System of Units
 | publisher = [[International Bureau of Weights and Measures]]
 | year = 2006
 | url = http://www.bipm.org/utils/common/pdf/si_brochure_8.pdf
 | accessdate = 2007-08-06}}
&lt;/ref&gt;&lt;ref&gt;
{{cite web
 | title = ISO 31-0 — Quantities and units – Part 0: General principles
 | publisher = [[International Organization for Standardization]]
 | date = 1999-12-22
 | url = http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=3621
 | accessdate = 2007-01-05}}
&lt;/ref&gt;

== Other uses ==

The word "percentage" is often a [[misnomer]] in the context of sports statistics, when the referenced number is expressed as a decimal proportion, not a percentage: "The [[Phoenix Suns]]' [[Shaquille O'Neal]] led the [[NBA]] with a .609 [[field goal percentage]] (FG%) during the 2008–09 season."  (O'Neal made 60.9% of his shots, not 0.609%.) Likewise, the [[winning percentage]] of a team, the fraction of matches that the club has won, is also usually expressed as a decimal proportion; a team that has a .500 winning percentage has won 50% of their matches. The practice is probably related to the similar way that [[batting average]]s are quoted.

As "percent" it is used to describe the steepness of the [[Grade (slope)|slope]] of a [[road]] or [[Rail tracks|railway]], formula for which is 100&amp;nbsp;×&amp;nbsp;{{sfrac|rise|run}} which could also be expressed as the [[Tangent (trigonometry)|tangent]] of the angle of inclination times 100. This is the ratio of distances a vehicle would advance vertically and horizontally, respectively, when going up- or downhill, expressed in percent.

Percentage is also used to express composition of a mixture by [[mass percent]] and [[mole percent]].

== Related units ==
{{visualisation_parts_per.svg}}
* [[Percentage point]]
* [[permille|Per mille]] (‰) 1 part in 1,000
* [[Basis point]] (‱) 1 part in 10,000
* [[Per cent mille]] (pcm) 1 part in 100,000
* [[Parts-per notation]]
* [[Grade (slope)]]
* [[Per-unit system]]

== Practical applications ==
* [[Baker percentage]]
* [[Volume percent]]

==See also==
*[[Percent difference]]
*[[Percentage change]]

==References==
{{Reflist}}

{{Wiktionary|percentage}}

{{Fractions and ratios}}
{{Use dmy dates|date=May 2011}}

[[Category:100 (number)]]
[[Category:Elementary arithmetic]]
[[Category:Fractions (mathematics)]]</text>
      <sha1>c6apivhqma6v5zsztvmacts69ijypzp</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum digital signature</title>
    <ns>0</ns>
    <id>15794879</id>
    <revision>
      <id>868861129</id>
      <parentid>822418838</parentid>
      <timestamp>2018-11-14T22:39:40Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14512">A '''Quantum Digital Signature (QDS)''' refers to the quantum mechanical equivalent of either a classical [[digital signature]] or, more generally, a handwritten signature on a paper document. Like a handwritten signature, a digital signature is used to protect a document, such as a digital contract, against forgery by another party or by one of the participating parties.

As e-commerce has become more important in society, the need to certify the origin of exchanged information has arisen. Modern digital signatures enhance security based on the difficulty of solving a mathematical problem, such as finding the factors of large numbers (as used in the [[RSA (algorithm)|RSA algorithm]]). Unfortunately, the task of solving these problems becomes feasible when a quantum computer is available (see [[Shor's algorithm]]). To face this new problem, new quantum digital signature schemes are in development to provide protection against tampering, even from parties in possession of quantum computers and using powerful quantum cheating strategies.

== Classical public-key method ==
The [[Public-key cryptography|public-key method]] of cryptography allows a sender to sign a message (often only the [[Cryptographic hash function|cryptographic hash]] of the message) with a sign key in such a way that any recipient can, using the corresponding public key, check the authenticity of the message.  To allow this, the public key is made broadly available to all potential recipients.  To make sure only the legal author of the message can validly sign the message, the public key is created from a random, private sign key, using a [[one-way function]].  This is a function that is designed such that computing the result given the input is very easy, but computing the input given the result is very difficult.  A classic example is the multiplication of two very large primes:  The multiplication is easy, but factoring the product without knowing the primes is normally considered infeasible.

:&lt;math&gt; x \mapsto f(x) &lt;/math&gt; ''easy''

:&lt;math&gt; f(x) \mapsto x &lt;/math&gt; ''very difficult''

== Quantum Digital Signature ==
Like classical digital signatures, quantum digital signatures make use of asymmetric keys.  Thus, a person who wants to sign a message creates one or more pairs of sign and corresponding public keys.  In general we can divide quantum digital signature schemes into two groups:
# A scheme that creates a public quantum-bit key out of a private '''classical''' bit string:  &lt;math&gt; k \mapsto |f_k \rangle &lt;/math&gt;
# A scheme that creates a public quantum-bit key out of a private '''quantum''' bit string:  &lt;math&gt; |k \rangle \mapsto |f_k \rangle &lt;/math&gt;

In both cases f is a one-way quantum function that has the same properties as a classical one-way function.
That is, the result is easy to compute, but, in contrast to the classical scheme, the function is ''impossible'' to invert, even if one uses powerful quantum cheating strategies.

The most famous scheme for the first method above is provided by Gottesman and Chuang &lt;ref name="Chuang"&gt;Daniel Gottesman, Isaac L. Chuang. ''Quantum Digital Signatures'', 
[https://arxiv.org/abs/quant-ph/0105032v2 ''arXiv:quant-ph/0105032'' '''v2'''], (November 15, 2001)&lt;/ref&gt;

=== Requirements for a good and usable signature scheme ===
Most of the requirements for a classical digital signature scheme also apply to the quantum digital signature scheme.

In detail
# The scheme has to provide security against tampering by
## The sender after the message was signed (see [[Commitment scheme|bit commitment]])
## The receiver
## A third party
# Creating a signed message has to be easy
# Every recipient has to get the same answer, when testing the message for validity (Valid, Non-Valid)
&lt;ref name="Chuang" /&gt;&lt;ref name="Feng"&gt;Xin Lü, Deng-Guo Feng. ''Quantum Digital Signature Based on Quantum One-way Functions'', [https://arxiv.org/abs/quant-ph/0403046 ''arxiv:quant-ph/04030462'' '''v2'''], (June 24, 2004)&lt;/ref&gt;

=== Differences between classical and quantum one-way functions ===

==== Nature of the one-way function ====
A classical one-way function as said above is based on a classical infeasible mathematical task, whereas a quantum one-way function exploits the uncertainty principle which makes it impossible even for a quantum computer to compute the inverse.
This is done by providing a quantum output state, with whom one cannot learn enough about the input string to reproduce it.
In case of the first group of schemes this is shown by Holevo's theorem, which says, that from a given n-qubit quantum state one cannot extract more than n classical bits of information.&lt;ref name="Holevo"&gt;Michael A. Nielsen, Isaac L. Chuang. ''Quantum Computation and Quantum Information 1st Ed.'', Cambridge University Press, '''p.531-536'''&lt;/ref&gt;
One possibility to ensure that the scheme uses less qubits for a bit string of a certain length is by using nearly orthogonal states
: &lt;math&gt; | \langle f_k|f_k' \rangle | &lt; \delta \qquad \text{ for } k \neq k' \land 0 \le \delta \le 1 &lt;/math&gt;
That gives us the possibility to induce a basis with more than two states.&lt;ref name="Chuang" /&gt;
So to describe an information of &lt;math&gt; 2^n &lt;/math&gt; bits, we can use less than n qubits.
An example with a 3 qubit basis
:* &lt;math&gt; |0 \rangle &lt;/math&gt;
:* &lt;math&gt; |1 \rangle &lt;/math&gt;
:* &lt;math&gt; \frac{1}{\sqrt{2}} (|0 \rangle + |1 \rangle ) &lt;/math&gt;
Only m qubits are needed to describe n classical bits when &lt;math&gt; 3^m = 2^n &lt;/math&gt; holds.

Because of Holevo's theorem and the fact, that m can be much smaller than n, we can only get m bits out of the n bits message. More general, if one gets T copies of the public key he can extract at most Tm bits of the private key.
If &lt;math&gt; \delta &lt;/math&gt; is big &lt;math&gt; n-Tm &lt;/math&gt; becomes very large, which makes it impossible for a dishonest person to guess the sign key.

''Note: You cannot distinguish between non-orthogonal states, if you only have a small amount of identical states. That's how the quantum one-way functions works. ''&lt;br&gt;
''Nevertheless &lt;math&gt; |f_k \rangle &lt;/math&gt; leaks information about the private key, in contrast to the classical public key, which forces one to get nothing or all about the private key. ''

==== Copying the public key ====
In the classical case we create a classical public key out of a classical sign key, thus it is easy to provide every potential recipient with a copy of the public key. The public key can be freely distributed.
This becomes more difficult in the quantum case, because copying a quantum state is forbidden by the no cloning theorem, as long as the state itself is unknown.&lt;ref name="Cloning"&gt;Michael A. Nielsen, Isaac L. Chuang. ''Quantum Computation and Quantum Information 1st Ed.'', Cambridge University Press,  '''p.532'''&lt;/ref&gt;
So public keys can only be created and distributed by a person who knows the exact quantum state he wants to create, thus who knows the sign key (This can be the sender or in more general a trustful institution).
Nevertheless, in contrast to the classical public key there is an upper bound for the number of public quantum keys '''T''' which can be created, without enabling one to guess the sign key and thus endangering the security of the scheme (&lt;math&gt; n-Tm  &lt;/math&gt; has to be big)

==== Public Key should be the same for every recipient (Swap Test)====
To make sure that every recipient gets identical results when testing the authenticity of a message, public keys distributed have to be the same.
This is straightforward in the classical case, because one can easily compare two classical bit strings and see if those match.
Nevertheless, in the quantum state it is more complicated.
To test, if two public quantum states are the same one has to compare the following
:&lt;math&gt; |f_k' \rangle = |f_k \rangle &lt;/math&gt;

[[Image:QDS Swap test.jpg|frame|Swap test for qubits]]
This is done with the following quantum circuit which uses one [[Fredkin gate]] ''F'', one [[Hadamard transform|Hadamard gate]] ''H''  and an ancilla qubit ''a''.
First of all the ancilla qubit is set to a symmetric state &lt;math&gt; |a \rangle = \frac{1}{\sqrt{2}} (|0 \rangle + |1 \rangle) &lt;/math&gt;.

Right after the ancilla qubit is used as a control on the targets &lt;math&gt; |f_k \rangle \ &lt;/math&gt; and &lt;math&gt; \ |f_k' \rangle &lt;/math&gt; in a Fredkin Gate.

Furthermore, a Hadamard gate is applied on the ancilla qubit and finally the first qubit gets measured.
If both states are the same, the result &lt;math&gt; |0 \rangle &lt;/math&gt; is measured.
If both states are nearly orthogonal, the result can be either &lt;math&gt; |0 \rangle \ &lt;/math&gt; or &lt;math&gt; \ |1 \rangle &lt;/math&gt;.&lt;ref name="Chuang" /&gt;

The calculation of the swap test in more detail:

The overall state
: &lt;math&gt; | \psi_0 \rangle = |a \rangle |f_k \rangle |f_k' \rangle &lt;/math&gt;

: &lt;math&gt; | \psi_0 \rangle = \frac{1}{\sqrt{2}} \bigg(|0 \rangle + |1 \rangle \bigg) |f_k \rangle |f_k' \rangle &lt;/math&gt;

: &lt;math&gt; | \psi_0 \rangle = \frac{1}{\sqrt{2}} \bigg(|0 \rangle |f_k \rangle |f_k' \rangle + |1 \rangle |f_k \rangle |f_k' \rangle \bigg)&lt;/math&gt;

After the '''Fredkin''' gate is applied

&lt;math&gt; \Rightarrow \frac{1}{\sqrt{2}} \bigg(|0 \rangle |f_k \rangle |f_k' \rangle + |1 \rangle \mathbf {|f_k' \rangle |f_k \rangle} \bigg)&lt;/math&gt;

After the '''Hadamard''' gate is applied on the first qubit

&lt;math&gt; \Rightarrow \frac{1}{2}\bigg[\bigg(|0 \rangle + |1 \rangle \bigg) |f_k \rangle |f_k' \rangle + \bigg(|0 \rangle - |1 \rangle \bigg)|f_k' \rangle |f_k \rangle \bigg]&lt;/math&gt;

After '''sorting''' for &lt;math&gt; |0 \rangle \text{ and } |1 \rangle &lt;/math&gt;

&lt;math&gt; \Rightarrow |\psi \rangle = \frac{1}{2}\bigg[|0 \rangle \bigg(|f_k \rangle |f_k' \rangle + |f_k' \rangle |f_k \rangle \bigg) + |1 \rangle \bigg(|f_k \rangle |f_k' \rangle - |f_k' \rangle |f_k \rangle \bigg)\bigg]&lt;/math&gt;

Now it is easy to see, if the states &lt;math&gt; |f_k \rangle = |f_k' \rangle \ &lt;/math&gt; then &lt;math&gt; \ | \psi \rangle = |0 \rangle |f_k \rangle |f_k \rangle &lt;/math&gt;, which gives us a 0 whenever it is measured.

== An example of a signing-validation process using a simplified Gottesman-Chuang scheme ==

=== Signing Process ===
[[Image:QDS Singing.jpg|thumb|right|A signing process example for a message-bit b = 0 using Gottesman-Chuang scheme]]
Let Person A (Alice) want to send a message to Person B (Bob).
Hash algorithms won't be considered, so Alice has to sign every single bit of her message. Message-Bit '''b''' &lt;math&gt; \in \{ 0,1 \} &lt;/math&gt;.

Alice chooses '''M''' pairs of private keys &lt;math&gt; \{ k_0^i,k_1^i \} \quad 1 \le i \le M &lt;/math&gt;
* All the &lt;math&gt; k_0 &lt;/math&gt; keys will be used to sign the message-bit if b = 0.
* All the &lt;math&gt; k_1 &lt;/math&gt; keys will be used to sign the message-bit if b = 1.
The function which maps &lt;math&gt; k \mapsto |f_k \rangle &lt;/math&gt; is known to all parties.
Alice now computes the corresponding public keys &lt;math&gt; \{ |f_{k_0}^i \rangle, |f_{k_1}^i \rangle \} &lt;/math&gt; and gives all of them to the recipients. She can make as many copies as she needs, but has to take care, not to endanger the security &lt;math&gt; \left( n \gg Tm  \text{ has to hold } \right) &lt;/math&gt;.

''Her level of security limits the number of identical public keys she can create''

If
* message-bit '''b = 0''', she sends all her private keys '''&lt;math&gt; k_0 &lt;/math&gt;''' along with the message-bit '''b''' to Bob
* message-bit '''b = 1''', she sends all her private keys '''&lt;math&gt; k_1 &lt;/math&gt;''' along with the message-bit '''b''' to Bob

''Remember: In this example Alice picks only one bit '''b''' and signs it. She has to do that for every single bit in her message ''

=== Validation Process ===
[[Image:QDS Validation.jpg|thumb|right|A validation example using Gottesman-Chuang scheme. Only one threshold is considered]]
Bob now possesses
* The message-bit '''b'''
* The corresponding private keys &lt;math&gt; k_0 \text{ or } k_1 &lt;/math&gt;
* All public keys &lt;math&gt; \{ |f_{k_0} \rangle, |f_{k_1} \rangle \} &lt;/math&gt;

Now Bob calculates &lt;math&gt; |f_{k_b} \rangle &lt;/math&gt; for all received private keys (either &lt;math&gt; k_0 \text{ or } k_1 &lt;/math&gt;).

After he has done so he makes use of the swap test to compare the calculated states with the received public keys.
Since the swap test has some probability to give the wrong answer he has to do it for all the '''M''' keys and counts how many incorrect keys he gets '''r'''. It is obvious, that '''M''' is some kind of a security parameter. It is more unlikely to validate a bit wrong for bigger '''M'''.
* If he only gets a few incorrect keys, then the bit is most probably valid, because his calculated keys and the public keys seem to be the same.
* If he gets many incorrect keys, then somebody faked the message with high probability.

== Avoid a message to be validated differently ==
One problem which arises especially for small '''M''' is, that the number of incorrect keys different recipients measure differ with probability. So to define only one threshold is not enough, because it would cause a message to be validated differently, when the number of incorrect keys '''r''' is very close to the defined threshold.

This can be prevented by defining more than one threshold.
Because the number of errors increase proportional with M, the thresholds are defined like
: '''Acceptance''' &lt;math&gt; T_{a} = c_1 M &lt;/math&gt;

: '''Rejection''' &lt;math&gt; T_{r} = c_2 M &lt;/math&gt;

* If the number of incorrect keys '''r''' is below &lt;math&gt; T_{a} &lt;/math&gt;, then the bit is valid with high probability
* If the number of incorrect keys '''r''' is above &lt;math&gt; T_{r} &lt;/math&gt;, then the bit is faked with high probability
* If the number of incorrect keys '''r''' is in-between both thresholds, then the recipient cannot be sure, if another recipient gets the same outcome, when validating the bit. Furthermore, he can't be even sure, if he validated the message right.
&lt;ref name="Chuang" /&gt;

''If we assume perfect channels without noise, so the bit can't be changed due to the transfer, then the threshold &lt;math&gt; T_a &lt;/math&gt; can be set to zero, because the swap test passes always, when the compared states are the same''

== See also ==

* [[Lamport signature]] - A practical digital signature method invented in the 1970s and believed to be secure even against quantum computing attacks.
* [[Quantum cryptography]]
* [[Quantum fingerprinting]]

== References ==
{{reflist}}

{{Cryptography navbox | public-key}}

{{DEFAULTSORT:Quantum Digital Signature}}
[[Category:Digital signature schemes]]
[[Category:Key management]]
[[Category:Quantum information science]]
[[Category:Theoretical computer science]]</text>
      <sha1>9uj7s3sdtcihvez99jfgv84tym1gwtj</sha1>
    </revision>
  </page>
  <page>
    <title>Random geometric graph</title>
    <ns>0</ns>
    <id>12106740</id>
    <revision>
      <id>861623925</id>
      <parentid>846741477</parentid>
      <timestamp>2018-09-28T19:43:15Z</timestamp>
      <contributor>
        <username>Htruett</username>
        <id>33842979</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9723">{{Network Science}}

[[File:Random geometric graph.svg|250px|right|thumb|Example of Random Geometric Graph on a flat 2-d closed square &lt;nowiki&gt;[&lt;/nowiki&gt;0,&amp;nbsp;1&lt;nowiki&gt;]&lt;/nowiki&gt; with ''N=256'' vertices and connectivity threshold ''r=0.1''.]]

In [[graph theory]], a '''random geometric graph''' ('''RGG''') is the mathematically simplest [[spatial network]], namely an [[undirected graph]] constructed by randomly placing ''N'' [[Node (graph theory)|nodes]] in some [[metric space]] (according to a specified probability distribution) and connecting two nodes by a [[link (geometry)|link]] if and only if their distance is in a given range, e.g. smaller than a certain neighborhood radius, ''r''.

Random geometric graphs resemble real human social networks in a number of ways. For instance, they spontaneously demonstrate [[community structure]] - clusters of nodes with high [[Modularity (networks)|modularity]]. Other random graph generation algorithms, such as those generated using the [[Erdős–Rényi model]] or  [[Barabási–Albert model|Barabási–Albert (BA) model]] do not create this type of structure. Additionally, random geometric graphs display degree [[assortativity]]: "popular" nodes (those with many links) are particularly likely to be linked to other popular nodes.

A real-world application of RGGs is the modeling of [[Mobile ad hoc network|ad hoc networks]].&lt;ref&gt;{{cite journal|last1=Nekovee|first1=Maziar|title=Worm epidemics in wireless ad hoc networks|journal=New Journal of Physics|date=28 June 2007|volume=9|issue=6|pages=189–189|doi=10.1088/1367-2630/9/6/189|arxiv=0707.2293|bibcode=2007NJPh....9..189N}}&lt;/ref&gt;

== Connectivity in Random Geometric Graphs==
The connectivity properties in RGGs have been well studied since their introduction by [[Edgar Gilbert]] in 1961 &lt;ref&gt;{{cite journal|last1=Gilbert|first1=Edgar|title=Random Plane Networks|journal=Journal of the Society for Industrial and Applied Mathematics|date=1961|volume=9.4|pages=533–543|doi=10.1137/0109045}}&lt;/ref&gt;, which stated wireless communication networks as a suggested application; nodes (vertices) represent wireless devices distributed in the plane according to some point process and connect if their euclidean distance is less than some critical transmission range r{{sub|0}}. 
Since then the connectivity properties of RGGs have been widely studied both on the plane &lt;ref&gt;{{cite journal|last1=Penrose|first1=Mathew D|title=The longest edge of the random minimal spanning tree|journal=The annals of applied probability|date=1997|pages=340361}}&lt;/ref&gt; &lt;ref&gt;{{cite journal|last1=Penrose|first1=Mathew D|title=On k‐connectivity for a geometric random graph|journal=Random Structures &amp; Algorithms|date=1999|volume=15.2|pages=145–164|doi=10.1002/(sici)1098-2418(199909)15:2&lt;145::aid-rsa2&gt;3.0.co;2-g}}&lt;/ref&gt; and in other spaces such as hyperbolic space &lt;ref&gt;{{cite journal|last1=Krioukov|first1=D|last2=Papadopoulos|first2=F|last3=Kitsak|first3=M|last4=Vahdat|first4=A|last5=Boguna|first5=M|title=Hyperbolic geometry of complex networks|journal=Physical Review E|date=2010|volume=82|issue=3|doi=10.1103/physreve.82.036106|arxiv=1006.5169|bibcode=2010PhRvE..82c6106K}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Kleinberg|first1=R|title=Geographic routing using hyperbolic space|journal=26th IEEE International Conference on Computer Communications.|date=2007|pages=1902–1909}}&lt;/ref&gt;. 

Gilbert’s initial paper provided a lower bound (by creating an associated branching process) and upper bound (by using results from bond percolation) for the critical transmission range needed for a giant component in the plane. 
Penrose &lt;ref&gt;{{cite journal|last1=Penrose|first1=Mathew D|title=The longest edge of the random minimal spanning tree|journal=The annals of applied probability|date=1997|pages=340361}}&lt;/ref&gt;  showed for a uniform [[Poisson point process]] that the main obstacle to full connectivity is isolated nodes as the number of nodes N →∞; a result which has since been used as an approximation for full connectivity.
Furthermore, assuming a homogeneous [[Poisson point process]], the probability a node is isolated is a ”local” event and thus the distribution of isolated nodes can be modelled by a limiting Poisson process &lt;ref&gt;{{cite book|last1=Penrose|first1=M|title=Random geometric graphs|date=2003|publisher=Oxford University Press}}&lt;/ref&gt;. 
For the 1-dimensional case the main obstacle for full connectivity is no loner isolated nodes since the network is likely to split into two clusters of arbitrary sizes. 

=== Generalised Random Geometric Graphs===
In 1988 Waxman &lt;ref&gt;{{cite journal|last1=Waxman|first1=B.M|title=Routing of multipoint connections,|journal=IEEE journal on selected areas in communications|date=1988|volume=6|issue=9|pages=1617–1622,|doi=10.1109/49.12889}}&lt;/ref&gt; generalised the standard RGG by introducing a probabilistic connection function as opposed to the deterministic one suggested by Gilbert. 
The example introduced by Waxman was a stretched exponential where two nodes i and j connect with probability given by H{{sub|ij}} = βexp(-{{frac|r{{sub|ij}}|r{{sub|0}}}}), where {{sub|ij}} is the euclidean separation and β, r{{sub|0}} are parameters determined by the system. 
This type of RGG with probabilistic connection function is often referred to a soft Random Geometric Graph, which now has two sources of randomness; the location of nodes (vertices) and the formation of links(edges). 
This connection function has been generalised further in the literature H{{sub|ij}} = βexp(-({{frac|r{{sub|ij}}|r{{sub|0}}}}){{sup|η}}) which is often used to study wireless networks without interference. 
The parameter η represents how the signal decays with distance, when η = 2 is free space, η &gt; 2 models a more cluttered environment like a town ( = 6 models cities like New York) whilst η &lt; 2 models highly reflective environments. 
We notice that for η =1 is the Waxman model, whilst as η→∞ and β = 1 we have the standard RGG. 
Intuitively these type of connection functions model how the probability of a link being made decays with distance. 

===Overview of some results for Soft RGG===
In the high density limit for a network with exponential connection function the number of isolated nodes is Poisson distributed, and the resulting network contains a unique giant component and isolated nodes only &lt;ref&gt;{{cite journal|last1=Mao|first1=G|last2=Anderson|first2=B.D|title=Connectivity of large wireless networks under a general connection model|journal=IEEE Transactions on Information|date=2013|volume=59|issue=3|pages=1761–1772|doi=10.1109/tit.2012.2228894}}&lt;/ref&gt;. Therefore by ensuring there are no isolated nodes, in the dense regime, the network is a.a.s fully connected; similar to the results shown in &lt;ref&gt;{{cite journal|last1=Penrose|first1=Mathew D|title=The longest edge of the random minimal spanning tree|journal=The annals of applied probability|date=1997|pages=340361}}&lt;/ref&gt; for the disk model. 
Often the properties of these networks such as betweenness centrality &lt;ref&gt;{{cite journal|last1=Giles|first1=A.P|last2=Georgiou|first2=O|last3=Dettmann|first3=C.P|title=Betweenness centrality in dense random geometric networks|journal=IEEE International Conference on Communications|date=2015}}&lt;/ref&gt; and connectivity &lt;ref&gt;{{cite journal|last1=Mao|first1=G|last2=Anderson|first2=B.D|title=Connectivity of large wireless networks under a general connection model|journal=IEEE Transactions on Information|date=2013|volume=59|issue=3|pages=1761–1772|doi=10.1109/tit.2012.2228894}}&lt;/ref&gt; are studied in the limit as the density → ∞ which often means border effects become negligible.
However, in real life where networks are finite, although can still be extremely dense, border effects will impact on full connectivity; in fact &lt;ref&gt;{{cite journal|last1=Coon|first1=J|last2=Dettmann|first2=C P|last3=Georgiou|first3=O|title=Full connectivity: corners, edges and faces|journal=Journal of Statistical Physics|date=2012|volume=147|issue=4|pages=758–778|doi=10.1007/s10955-012-0493-y|arxiv=1201.3123|bibcode=2012JSP...147..758C}}&lt;/ref&gt; showed that for full connectivity, with an exponential connection function, is greatly impacted by boundary effects as nodes near the corner/face of a domain are less likely to connect compared with those in the bulk. As a result full connectivity can be expressed as a sum of the contributions from the bulk and the geometries boundaries.
A more general analysis of the connection functions in wireless networks has shown that the probability of full connectivity can be well approximated expressed by a few moments of the
connection function and the regions geometry &lt;ref&gt;{{cite journal|last1=Dettmann|first1=C.P|last2=Georgiou|first2=O|title=Random geometric graphs with general connection functions|journal=Physical Review E,|date=2016|volume=93|issue=3|doi=10.1103/physreve.93.032313|arxiv=1411.3617|bibcode=2016PhRvE..93c2313D}}&lt;/ref&gt;.

== Examples ==
* In 1 dimension, one can study RGGs on a line of unit length (open boundary condition) or on a circle of unit circumference. 
* In 2 dimensions, an RGG can be constructed by choosing a flat unit square &lt;nowiki&gt;[&lt;/nowiki&gt;0,&amp;nbsp;1&lt;nowiki&gt;]&lt;/nowiki&gt; (see figure) or a [[torus]] of unit circumferences &lt;nowiki&gt;[&lt;/nowiki&gt;0,&amp;nbsp;1&lt;nowiki&gt;)&lt;/nowiki&gt;&lt;sup&gt;2&lt;/sup&gt; as the embedding space. 
The simplest choice for the node distribution is to sprinkle them  [[continuous uniform distribution|uniformly]] and [[statistical independence|independently]] in the embedding space.

==References==
{{reflist}}
* Penrose, Mathew: ''Random Geometric Graphs'' (Oxford Studies in Probability, 5), 2003.

[[Category:Geometric graphs]]
[[Category:Random graphs]]</text>
      <sha1>h3vai2tls1xxb89ysjd1us3fspexi7t</sha1>
    </revision>
  </page>
  <page>
    <title>Roger Schank</title>
    <ns>0</ns>
    <id>1076541</id>
    <revision>
      <id>839499482</id>
      <parentid>839023286</parentid>
      <timestamp>2018-05-03T20:55:53Z</timestamp>
      <contributor>
        <ip>2620:5:8000:20C4:98DF:7E4B:2A1:7C1E</ip>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14292">{{Infobox scientist
| name              = Roger Schank
| birth_date        = {{birth year and age|1946}}
| workplaces        = {{ublist |[[Stanford University]] | [[Yale University]] | [[Carnegie Mellon University]]}} 
| alma_mater        = {{ublist |[[Carnegie Mellon University]] | [[University of Texas]]}}  
| thesis_title      = A Conceptual Dependency Representation for a Computer-Oriented Semantics
| thesis_url        = http://search.proquest.com/docview/302479013/
| thesis_year       = 1969
| doctoral_advisor  = [[Jacob L. Mey]]
| doctoral_students = [[Jaime Carbonell]]{{fact|date=April 2018}}&lt;br&gt;[[Lawrence Hunter]]&lt;ref name="hunterphd"&gt;{{cite thesis |degree=PhD |first=Lawrence E.|last=Hunter |title=Knowledge acquisition planning: Gaining expertise through experience |publisher=Yale University |date=1989 |url=http://search.proquest.com/docview/303852846|authorlink= Lawrence Hunter|hdl= 10079/bibid/9838922|website=proquest.com|oclc=24116492}}&lt;/ref&gt;  
| website           = {{URL|rogerschank.com/}}
}}
'''Roger Carl Schank''' (born 1946) is an American [[artificial intelligence]] theorist, [[cognitive psychology|cognitive psychologist]], [[learning sciences|learning scientist]], educational reformer, and [[entrepreneur]].

Beginning in the late 1960s, he pioneered [[conceptual dependency theory]] (within the context of [[natural language understanding]]) and [[case-based reasoning]], both of which challenged [[cognitivism (psychology)|cognitivist]] views of memory and reasoning.

In 1989, Schank was granted $30 million in a 10-year commitment to his research and development by [[Andersen Consulting]], through which he founded the Institute for the Learning Sciences (ILS) at [[Northwestern University]] in Chicago.

==Academic career==
For his undergraduate degree, Schank studied mathematics at [[Carnegie Mellon University]]&lt;ref name="shank_tank"&gt;{{cite web|last1=Freedman|first1=David|title=The Schank Tank|url=https://www.wired.com/1994/08/schank/|website=Wired|publisher=Wired|accessdate=7 April 2018}}&lt;/ref&gt; in [[Pittsburgh|Pittsburgh PA]], and later was awarded a PhD in [[linguistics]] at the [[University of Texas]] in Austin and went on to work in faculty positions at [[Stanford University]] and then at [[Yale University]].&lt;ref name=freedman&gt;{{Cite news| volume = 2| issue = 8| last = Freedman| first = David H.| title = The Schank Tank| work = Wired| accessdate = 2011-10-04| date = August 1994| url = https://www.wired.com/wired/archive/2.08/schank_pr.html}}&lt;/ref&gt; In 1974, he became professor of [[computer science]] and [[psychology]] at Yale University. In 1981, Schank became Chairman of Computer Science at Yale and director of the Yale Artificial Intelligence Project.&lt;ref name=bio1&gt;{{cite web|title=Biography: Part 1 of 2|work=RogerSchank.com|url=http://www.rogerschank.com/biography.html|year=2009|accessdate=October 9, 2011|deadurl=yes|archiveurl=https://web.archive.org/web/20111006130700/http://www.rogerschank.com/biography.html|archivedate=October 6, 2011|df=}}&lt;/ref&gt;

In 1989, Schank was granted $30 million in a 10-year commitment to his research and development by [[Accenture|Andersen Consulting]], allowing him to leave Yale and set up the Institute for the Learning Sciences (ILS) at [[Northwestern University]] in Chicago, bringing along 25 of his Yale colleagues.&lt;ref&gt;{{cite news|first=Glenn|last=Rifkin|title= Andersen Consulting's Culture of 'Clones'|work=New York Times |url=https://www.nytimes.com/1992/09/06/business/andersen-consulting-s-culture-of-clones.html?pagewanted=all&amp;src=pm|date=September 6, 1992|accessdate= September 28, 2011}}&lt;/ref&gt; ILS attracted other corporate sponsors such as [[IBM]] and [[Ameritech]], as well as government sponsors such as the [[United States Army|U.S. Army]], [[United States Environmental Protection Agency|EPA]] and the [[National Guard of the United States|National Guard]],&lt;ref name=bio2 /&gt; leading to a focus on the development of educational software,&lt;ref name=freedman /&gt; especially in employee training.&lt;ref name=bio2&gt;{{cite web|title=Biography: Part 2 of 2|work=RogerSchank.com|url=http://www.rogerschank.com/biography-part2.html|year=2009|accessdate=October 9, 2011|deadurl=yes|archiveurl=https://web.archive.org/web/20111006151508/http://www.rogerschank.com/biography-part2.html|archivedate=October 6, 2011|df=}}&lt;/ref&gt; ILS was later absorbed by the School of Education as a separate department.

When Carnegie Mellon University's [[Carnegie Mellon Silicon Valley|Silicon Valley campus]] was established in 2002, Schank came to serve as Chief Educational Officer at the institution.&lt;ref name=socratic /&gt;

==Entrepreneurship==
While at Yale in 1979, Schank was among the first to "capitalize on the expected boom"&lt;ref&gt;{{cite news|first=Andrew|last=Pollack|work= New York Times|title=Selling artificial intelligence |url=https://www.nytimes.com/1982/09/13/business/selling-artificial-intelligence.html|date=September 13, 1982|accessdate=6 October 2011}}&lt;/ref&gt; in AI when he founded Cognitive Systems, a company that went public in 1986. Schank resigned as chairman and chief executive in 1988 for personal reasons, but stayed as a board member and advisor.&lt;ref&gt;{{cite news|title=Top officer resigns at Cognitive Systems|work=New York Times|url=https://www.nytimes.com/1988/06/24/business/business-people-top-officer-resigns-at-cognitive-systems.html|date=June 24, 1988|accessdate=September 27, 2011}}&lt;/ref&gt;

In 1994, Schank founded Cognitive Arts Corporation&lt;ref name=socratic&gt;{{cite web|title=Roger Schank|work=Socratic Arts |url=http://www.socraticarts.com/about.cfm?lead=Roger-Schank|accessdate=October 9, 2011}}&lt;/ref&gt; (originally named Learning Sciences Corporation) to market the software developed at ILS, and led the company until it was sold in 2003.

From 2005 to 2007, Schank was the chief learning officer of Trump University.&lt;ref&gt;https://www.linkedin.com/pulse/trump-university-i-state-accreditation-issue-roger-schank&lt;/ref&gt;

In 2001 he founded Socratic Arts, a company that sells e-learning software to both businesses and schools.&lt;ref name=bio2 /&gt;

In 2008, Schank built a story-centered curriculum (SCC) at the Business Engineering School of La Salle International Graduate School of [[Ramon Llull University]], Barcelona to teach MBA students to launch their own businesses or to go to work.&lt;ref name=bio2 /&gt;

In 2012, Schank founded XTOL (Experiential Training Online) which "designs learn-by-doing experiential short courses for use by universities, corporations and professional organizations, as well as Master's programs in partnership with degree-granting universities around the world."&lt;ref name=xtol&gt;{{cite web|title=XTOL (Experiential Training Online)|url=http://www.xtolcorp.com/|accessdate=January 21, 2014| website=XTOL Corp}}&lt;/ref&gt;

==Educational reform==
Schank believes that the educational system is fundamentally broken and that software will need to replace conventional teaching methods.&lt;ref name=green&gt;{{cite news|first=Joshua|last=Green|title=No Lectures or Teachers, Just Software|url=https://www.nytimes.com/learning/teachers/featured_articles/20000811friday.html| date=August 11, 2000|accessdate=October 10, 2011|work=New York Times}}&lt;/ref&gt; To serve this purpose, he founded Engines for Education in 2001, a not-for-profit organization which designs and implements curricula for primary and secondary schools&lt;ref name=bio2 /&gt; and hosts the Virtual International Science and Technology Academy (VISTA).

==Influence==
Schank was a leading pioneer of [[artificial intelligence]] and [[cognitive psychology]] in the 1970s and 1980s. His innovations in these fields were [[conceptual dependency theory]] and [[case-based reasoning]], both of which challenged [[Cognitivism (psychology)|cognitivist]] views of memory and reasoning.

In 1969 Schank introduced the [[conceptual dependency theory]] for [[natural language understanding]].&lt;ref&gt;{{Cite conference| pages = 1–3| last = Schank| first = Roger| title = A conceptual dependency parser for natural language| booktitle =  Proceedings of the 1969 conference on Computational linguistics| location = Sång-Säby, Sweden| year = 1969}}&lt;/ref&gt; This model, partly based on the work of [[Sydney Lamb]], was extensively used by Schank's students at [[Yale University]], such as [[Robert Wilensky]], Wendy Lehnert, and [[Janet Kolodner]].

Case-based reasoning (CBR) is based on Schank's model of dynamic memory&lt;ref name="ref_schank"&gt;Roger Schank, Dynamic Memory: ''A Theory of Learning in Computers and People'' (New York: Cambridge University Press, 1982)&lt;/ref&gt; and was the basis for the earliest CBR systems: [[Janet Kolodner|Janet Kolodner's]] CYRUS&lt;ref name="ref_kolodner"&gt;Janet Kolodner, "Reconstructive Memory: A Computer Model," ''Cognitive Science'' 7 (1983): 4.&lt;/ref&gt; and Michael Lebowitz's IPP.&lt;ref name="ref_lebowitz"&gt;Michael Lebowitz, "Memory-Based Parsing," ''Artificial Intelligence'' 21 (1983), 363-404.&lt;/ref&gt;

Other schools of CBR and closely allied fields emerged in the 1980s, investigating such topics as CBR in legal reasoning, memory-based reasoning (a way of reasoning from examples on massively parallel machines), and combinations of CBR with other reasoning methods.  In the 1990s, interest in CBR grew, as evidenced by the establishment of an International Conference on Case-Based Reasoning in 1995, as well as European, German, British, Italian, and other CBR workshops.

CBR technology has produced a number of successful deployed systems, the earliest being Lockheed's CLAVIER,&lt;ref name="ref_mark"&gt;Bill Mark, "Case-Based Reasoning for Autoclave Management," ''Proceedings of the Case-Based Reasoning Workshop'' (1989).&lt;/ref&gt; a system for laying out composite parts to be baked in an industrial convection oven. CBR has been used extensively in [[help desk]] applications such as the Compaq SMART system&lt;ref name="ref_nguyen"&gt;Trung Nguyen, Mary Czerwinski, and Dan Lee, "COMPAQ QuickSource: Providing the Consumer with the Power of Artificial Intelligence," in ''Proceedings of the Fifth Annual Conference on Innovative Applications of Artificial Intelligence'' (Washington, DC: AAAI Press, 1993), 142-151.&lt;/ref&gt; and has found a major application area in the health sciences.&lt;ref&gt;{{Cite journal| doi = 10.1109/TSMCC.2010.2071862| issn = 1094-6977| volume = 41| issue = 4| pages = 421–434| last = Begum| first = S.|author2=M. U Ahmed |author3=P. Funk |author4=Ning Xiong |author5=M. Folke | title = Case-Based Reasoning Systems in the Health Sciences: A Survey of Recent Trends and Developments| journal = IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews| date = July 2011}}&lt;/ref&gt;

==Works==
*Schank, Roger. ''Teaching Minds: How Cognitive Science Can Save Our Schools''. New York: Teachers College Press, 2011, {{ISBN|978-0-8077-5266-1}} (paper) and {{ISBN|978-0-8077-5267-8}} (hardcover).
*Schank, Roger, Dimitris Lyras and Elliot Soloway. ''The Future of Decision Making: How Revolutionary Software Can Improve the Ability to Decide''. New York: Palgrave Macmillan, 2010. {{ISBN|978-0-230-10365-8}}
*Schank, Roger. ''Lessons in Learning, e-Learning, and Training: Perspectives and Guidance for the Enlightened Trainer''. Pfeiffer, 2005. {{ISBN|0-7879-7666-0}}.
*Schank, Roger. ''Scrooge Meets Dick and Jane''. Mahwah: Lawrence Erlbaum, 2001, {{ISBN|0-8058-3877-5}}.
*Schank, Roger. ''Dynamic Memory Revisited'', 2nd Edition. New York: Cambridge University Press, 1999, {{ISBN|0-521-63398-2}}.
*Schank, Roger, ''Virtual Learning: A Revolutionary Approach to Building a Highly Skilled Workforce.'' New York: McGraw Hill 1997. {{ISBN|0-7863-1148-7}}
*Schank, Roger and [[Gary Saul Morson]]. ''Tell Me A Story: Narrative and Intelligence''. Northwestern Press, 1995. {{ISBN|0-8101-1313-9}}.
*Schank, Roger and Chip Cleary, ''Engines for Education''. Hillsdale, NJ: Lawrence Erlbaum, 1995. 
*Schank, Roger. ''The Connoisseur's Guide to the Mind: How we think, How we learn, and what it means to be intelligent''. Summit Books, 1991.
*Schank, Roger. ''Tell Me A Story: A new look at real and artificial memory''. Scribner's, 1990.
*Schank, Roger and Peter Childers. ''The Creative Attitude: Learning to Ask and Answer the Right Questions''. MacMillan Publishing Company, 1988, {{ISBN|0-02-607170-3}}.
*Schank, Roger. ''The Cognitive Computer: On Language, Learning and Artificial Intelligence''. Reading: Addison Wesley, 1984.
*Schank, Roger. ''Dynamic Memory: A Theory of Learning in Computers and People''. New York: Cambridge University Press, 1982.
*{{cite book | first=Roger | last=Schank | first2=Robert P. | last2=Abelson | authorlink=Roger Schank | author2-link=Robert Abelson | title=Scripts, plans, goals and understanding: An inquiry into human knowledge structures | location=New Jersey | publisher=Erlbaum | year=1977 | isbn=0-470-99033-3 }}
*Schank, Roger. Conceptualizations underlying natural language. In ''Computer Models of Thought and Language'', R. Schank &amp; K. Colby, eds. San Francisco: W.H. Freeman, 1973.

== See also ==
*[[Robert P. Abelson]]

==References==
{{Reflist|30em}}

==External links==
{{Commons category|Roger Schank}}
*[http://www.rogerschank.com/ Roger Schank's Homepage]
*{{Twitter}}
*[http://www.socraticarts.com/ Socratic Arts]
*[http://www.socraticarts.com/beslasalle/index.html Institute for the Learning Sciences]
*[http://www.engines4ed.org/ Engines for Education]
*[http://engines4ed.org/about/vista.cfm VISTA (Virtual International Science and Technology Academy)]
*[http://www.grandparentgames.com/ Grandparent Games]
*[http://www.imissthatkid.com/ I Miss That Kid]
*[http://www.milosplace.com/ Milo's Place]
*[http://www.cognitivearts.com/ Cognitive Arts]
*[http://www.edge.org/3rd_culture/schank/schank_index.html EDGE Magazine interview with Roger Schank]
*[https://web.archive.org/web/20041215042910/http://west.cmu.edu/masters/ls/ CMU Center for the Learning Sciences]
*[http://www.xtolcorp.com XTOL Corp]

{{Authority control}}

{{DEFAULTSORT:Schank, Roger}}
[[Category:1946 births]]
[[Category:Living people]]
[[Category:Artificial intelligence researchers]]
[[Category:History of artificial intelligence]]
[[Category:Theoretical computer science]]
[[Category:Carnegie Mellon University faculty]]
[[Category:Carnegie Mellon University alumni]]
[[Category:American scientists]]</text>
      <sha1>ju8ucydq6ultaq8fmndxr5yytx3d7dg</sha1>
    </revision>
  </page>
  <page>
    <title>Roland Fraïssé</title>
    <ns>0</ns>
    <id>4234672</id>
    <revision>
      <id>868757135</id>
      <parentid>857358126</parentid>
      <timestamp>2018-11-14T06:59:17Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */recategorize</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3432">{{Use dmy dates|date=May 2013}}
{{Infobox scientist
| name              = Roland Fraïssé
| image             = &lt;!--(filename only)--&gt;
| image_size        = 
| caption           = 
| birth_date        = {{Birth date|1920|3|12|df=y}}
| birth_place       = [[Bressuire]], France
| death_date        = {{Death date and age|2008|3|30|1920|3|12|df=y}}
| death_place       = [[Marseille]], France
| nationality       = French
| fields            = Mathematics
| workplaces        = [[University of Provence]]
| alma_mater        = [[University of Paris]]
| doctoral_advisor  = [[René de Possel]]
| doctoral_students = 
| known_for         = 
| awards            = 
}}
'''Roland Fraïssé''' ({{IPA-fr|ʁɔlɑ̃  fʁajse|lang}}; 12 March 1920 – 30 March 2008&lt;ref&gt;[http://www.site.uottawa.ca/~lrakotom/rogics2008/RolandFraisse.html Rogics08 – Décès de Roland Fraïssé –  Message de Maurice Pouzet et Gérard Lopez], accessed 22 May 2008.&lt;/ref&gt;) was a French [[mathematical logic]]ian.

Fraïssé received his doctoral degree from the [[University of Paris]] in 1953. In his thesis,&lt;ref&gt;''Sur une nouvelle classification des systèmes de relations'', Roland Fraïssé, ''Comptes Rendus'' '''230''' (1950), 1022–1024.&lt;/ref&gt;&lt;ref&gt;''Sur quelques classifications des systèmes de relations'', Roland Fraïssé, thesis, Paris, 1953;
published in ''Publications Scientifiques de l'Université d'Alger'', series
 A '''1''' (1954), 35–182.&lt;/ref&gt; Fraïssé used the [[back-and-forth method]] to determine whether two [[model theory|model-theoretic]] [[structure (mathematical logic)|structures]] were [[elementarily equivalent]]. This method of determining elementary equivalence was later formulated as the [[Ehrenfeucht–Fraïssé game]]. Fraïssé worked primarily in [[theory of relations|relation theory]]. Another of his important works was the [[Age (model theory)|Fraïssé construction]] of a Fraïssé limit of finite structures. He also introduced the notion of compensor in the [[Partially ordered set|theory of posets]].&lt;ref&gt;Petits posets : dénombrement, représentabilité par cercles et compenseurs, Roland Fraïssé and Nik Lygeros Comptes Rendus de l'Académie des Sciences, Série I 313 (1991), no. 7, 417—420&lt;/ref&gt;

Most of his career was spent as Professor at the [[University of Provence]] in [[Marseille]], France.

== Selected publications ==
* ''Sur quelques classifications des systèmes de relations'', thesis, University of Paris, 1953; published in ''Publications Scientifiques de l'Université d'Alger'', series A '''1''' (1954), 35–182.
* ''Cours de logique mathématique'', Paris: Gauthier-Villars Éditeur, 1967; second edition, 3 vols., 1971–1975; tr. into English and ed. by David Louvish as ''Course of Mathematical Logic'', 2 vols., Dordrecht: Reidel, 1973–1974.
* ''Theory of relations'', tr. into English by P. Clote, Amsterdam: North-Holland, 1986; rev. ed. 2000.

== References ==
{{reflist}}

==External links==
*{{MathGenealogy |id=111973}}

{{Authority control}}

{{DEFAULTSORT:Fraisse, Roland}}
[[Category:French logicians]]
[[Category:Model theorists]]
[[Category:University of Provence faculty]]
[[Category:20th-century French mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:1920 births]]
[[Category:2008 deaths]]
[[Category:Mathematical logicians]]
[[Category:French philosophers]]
[[Category:French male non-fiction writers]]


{{France-mathematician-stub}}</text>
      <sha1>iyvlownx2u836f9t16hnis41dra8wbb</sha1>
    </revision>
  </page>
  <page>
    <title>School Mathematics Project</title>
    <ns>0</ns>
    <id>3196691</id>
    <revision>
      <id>791299818</id>
      <parentid>791298285</parentid>
      <timestamp>2017-07-19T10:32:44Z</timestamp>
      <contributor>
        <username>Jdgilbey</username>
        <id>5059751</id>
      </contributor>
      <comment>Remove now-dead URLs from page</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2007">The '''School Mathematics Project''' is a developer of mathematics textbooks for [[secondary school]]s, formerly based in [[Southampton]] in the [[United Kingdom|UK]]. 

Now generally known as SMP, it began as a research project inspired by a 1961 conference chaired by [[Bryan Thwaites]] at the [[University of Southampton]], which itself was precipitated by calls to reform mathematics teaching in the wake of the [[Sputnik]] launch by the [[Soviet Union]], the same circumstances which prompted the wider [[New Math]] movement.  It maintained close ties with the former Collaborative Group for Research in Mathematics Education at the university.

Instead of dwelling on 'traditional' areas such as arithmetic and geometry, SMP dwelt on subjects such as set theory, graph theory and logic, non-cartesian co-ordinate systems, matrix mathematics, affine transforms, vectors and non-decimal number systems.

The SMP is now a registered charity, and continues to publish textbooks in association with [[Cambridge University Press]] for [[General Certificate of Secondary Education|GCSE]] and both [[Assessment and Qualifications Alliance|AQA]] and [[Edexcel]] [[Advanced Level (UK)|A-level]] exams. It also published an educational comic called "Mathematical Mike and his Dog Dingle."  

The computer paper tape motif on early educational material reads "THE SCHOOL MATHEMATICS PROJECT DIRECTED BY BRYAN THWAITES".

    O O   O        O    O  O OO    O   O  O    O  OO   O O  O O O
    O  O    OOOO O  O O  O     OO     O        O   O O  O  O    O
    O O O O   OO O O OO O      O O O O  O OOO        O O O  OO  O
 ···································································
    O     OO OO           OO  OOO O    O O    O  OO  O   O    O O
    O   O OO OO  OO  OOO OOO   O OO   O OO O   O   OO    OOO OO O
      THE SCHOOL MATHEMATICS PROJECT DIRECTED BY BRYAN THWAITES
==References==
{{reflist}}

[[Category:Mathematics education]]</text>
      <sha1>oqu2wzndod9tjp1vrasmaj1mio1j7t9</sha1>
    </revision>
  </page>
  <page>
    <title>SequenceL</title>
    <ns>0</ns>
    <id>37895661</id>
    <revision>
      <id>842487296</id>
      <parentid>827931505</parentid>
      <timestamp>2018-05-22T19:45:59Z</timestamp>
      <contributor>
        <username>Acyclic</username>
        <id>29997616</id>
      </contributor>
      <comment>Added {{Dead link|date=May 2018}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20946">{{Infobox programming language
| name = SequenceL
| logo = &lt;!-- (filename) --&gt;
| logo caption = 
| screenshot = &lt;!-- (filename) --&gt;
| screenshot caption = 
| paradigms = [[Parallel computing]], [[Functional programming|Functional]], [[Purely functional programming|Purely functional]], [[Declarative programming]]
| family =  
| designers = Dr. Daniel Cooke,&lt;br/&gt;Dr. Nelson Rushton,&lt;br/&gt;Dr. Brad Nemanich
| developers = Texas Tech University,&lt;br/&gt;Texas Multicore Technologies
| released = {{Start date and age|1989}}
| latest release version = 
| latest release date = &lt;!-- {{Start date and age|2016|MM|DD|df=yes/no}} --&gt;
| latest preview version = 
| latest preview date = &lt;!-- {{Start date and age|2016|MM|DD|df=yes/no}} --&gt;
| typing = [[Type system#Static type checking|Static]], [[type inference]]
| scope = 
| programming language = 
| platform = [[x86]], [[IBM POWER microprocessors|POWER]], [[ARM architecture|ARM]]
| operating system = [[Microsoft Windows|Windows]], [[macOS]], [[Linux]]
| file ext = 
| file format = &lt;!-- or: | file formats = --&gt;
| website = {{URL|texasmulticore.com}}{{Dead link|date=May 2018}}
| implementations = 
| dialects = 
| influenced by = 
| influenced = 
| license = [[Proprietary software|Proprietary]]&lt;ref name=Licensing&gt;{{cite web |url=https://texasmulticore.com/products/sequencel-licenses/ |title=SequenceL Licensing}}&lt;/ref&gt;
}}
'''SequenceL''' is a general purpose [[functional programming]] language and auto-parallelizing ([[Parallel computing]]) compiler and tool set, whose primary design objectives are performance on [[multi-core processor]] hardware, ease of programming, platform portability/optimization, and code clarity and readability.  Its main advantage is that it can be used to write straightforward code that automatically takes full advantage of all the processing power available, without [[programmer]]s needing to be concerned with identifying [[Parallel computing|parallelisms]], specifying [[Automatic vectorization|vectorization]], avoiding [[race condition]]s, and other challenges of manual [[Directive pragma|directive-based programming]] approaches such as [[OpenMP]].

Programs written in SequenceL can be compiled to [[Thread (computing)|multithreaded]] code that runs in parallel, with no explicit indications from a programmer of how or what to parallelize. {{As of|2015}}, versions of the SequenceL [[compiler]] generate parallel code in [[C++]] and [[OpenCL]], which allows it to work with most popular programming languages, including [[C (programming language)|C]], C++, [[C Sharp (programming language)|C#]], [[Fortran]], [[Java (programming language)|Java]], and [[Python (programming language)|Python]].  A platform-specific runtime manages the threads safely, automatically providing parallel performance according to the number of cores available, currently supporting [[x86]], [[Power Architecture|OpenPOWER/POWER8]], and [[ARM architecture|ARM]] platforms.

==History==
SequenceL was initially developed over a 20-year period starting in 1989, mostly at [[Texas Tech University]].  Primary funding was from [[NASA]], which originally wanted to develop a specification language which was "self-verifying"; that is, once written, the requirements could be ''executed'', and the results verified against the desired outcome.

The principal researcher on the project was initially Dr. Daniel Cooke,&lt;ref&gt;[http://www.texasmulticoretechnologies.com/about/inventors/ Dr. Daniel Cooke at Texas Multicore Technologies]&lt;/ref&gt; who was soon joined by Dr. Nelson Rushton (another Texas Tech professor) and later Dr. Brad Nemanich (then a PhD student under Cooke). The goal of creating a language that was simple enough to be readable, but unambiguous enough to be executable, drove the inventors to settle on a [[Functional programming|functional]], [[Declarative programming|declarative]] language approach, where a programmer describes desired results, rather than the means to achieve them.  The language is then free to solve the problem in the most efficient manner that it can find.

As the language evolved, the researchers developed new computational approaches, including ''consume-simplify-produce'' (CSP).&lt;ref&gt;[https://texasmulticore.com/wp-content/uploads/2016/05/2004-ttudamp.pdf Consume-simplify-produce (CSP)]&lt;/ref&gt;  In 1998, research began to apply SequenceL to [[parallel computing]].  This culminated in 2004 when it took its more complete form with the addition of the ''normalize-transpose'' (NT) semantic,&lt;ref&gt;{{Citation |last1=Nemanich |first1=Brad |last2=Cooke |first2=Daniel |last3=Rushton |first3=Nelson |title=SequenceL: Transparency And Multi-Core Parallelisms |series=DAMP '10 Proceedings of the 5th ACM SIGPLAN workshop on Declarative Aspects of Multicore Programming |publisher=ACM |year=2010 |pages=45–52 |location=New York, NY, US |url=https://texasmulticore.com/wp-content/uploads/2016/05/2004-ttudamp.pdf}}&lt;/ref&gt;&lt;ref&gt;{{Citation |last1=Cooke |first1=Daniel |last2=Rushton |first2=Nelson |last3=Nemanich |first3=Brad |last4=Watson |first4=Robert G. |last5=Andersen |first5=Per |title=Normalize, Transpose, and Distribute: An Automatic Approach for Handling Nonscalars |journal=ACM Transactions on Programming Languages and Systems |publisher=ACM |volume=30 |issue=2 |date=March 2008 |doi=10.1145/1330017.1330020 |location=New York, NY, US |url=http://dl.acm.org/citation.cfm?id=1330020&amp;dl=ACM&amp;coll=DL&amp;CFID=893264698&amp;CFTOKEN=93567450}}&lt;/ref&gt; which coincided with the major vendors of [[central processing unit]]s (CPUs) making a major shift to [[multi-core processor]]s rather than continuing to increase clock speeds. NT is the semantic work-horse, being used to simplify and decompose structures, based on a [[dataflow]]-like execution strategy similar to GAMMA&lt;ref&gt;{{Citation |last1=Banater |first1=J-P |last2=Le Metayer |first2=D. |title=Programming by Multiset Transformation |journal=Communications of the ACM |publisher=ACM |date=January 1993 |volume=36 |issue=1 |pages=98–111 |doi= 10.1145/151233.151242}}&lt;/ref&gt; and NESL.&lt;ref&gt;{{Citation |last1=Blelloch |first1=Guy |title=Programming Parallel Algorithms |journal=Communications of the ACM |publisher=ACM |date=March 1996 |volume=39 |issue= 3 |pages=85–97 |doi=10.1145/227234.227246}}&lt;/ref&gt; The NT semantic achieves a goal similar to that of the Lämmel and Peyton-Jones’ boilerplate elimination.&lt;ref&gt;{{Citation |last1=Lämmel |first1=Ralf |last2=Peyton-Jones |first2=Simon |title=Scrap your boilerplate: a practical design pattern for generic programming |journal=Proceedings of TLDI 2003 |publisher=ACM Press |year=2003}}&lt;/ref&gt;&lt;ref&gt;{{Citation |last1=Lämmel |first1=Ralf |last2=Peyton-Jones |first2=Simon |title=Scrap more boilerplate: reflection, zips, and generalised casts |journal=Proceedings of ICFP 2004 |publisher=ACM Press |year=2004}}&lt;/ref&gt; 
All other features of the language are definable from these two laws - including [[Recursion (computer science)|recursion]], subscripting structures, function references, and evaluation of function bodies.&lt;ref&gt;{{Citation |last1=Cooke |first1=Daniel |last2=Rushton |first2=Nelson |title=Iterative and Parallel Algorithm Design from High Level Language Traces |journal=ICCS'05 Proceedings of the 5th international conference on Computational Science |date=January 1993 |volume=Part III |pages=891–894 |doi=10.1007/11428862_132 |isbn =978-3-540-26044-8 |url=https://texasmulticore.com/wp-content/uploads/2016/05/2005-Iterative-and-Parallel-Algorithm-Design-from-High.pdf}}&lt;/ref&gt;&lt;ref&gt;{{Citation |last1=Cooke |first1=Daniel |last2=Rushton |first2=Nelson |title=SequenceL – An Overview of a Simple Language |journal=Proceedings of the 2005 International Conference on Programming Languages and Compilers, PLC 2005 |date=June 27–30, 2005 |location=Las Vegas, Nevada, US}}&lt;/ref&gt;

Though it was not the original intent, these new approaches allowed the language to parallelize a large fraction of the operations it performed, transparently to the programmer. In 2006, a prototype auto-parallelizing compiler was developed at Texas Tech University. In 2009, Texas Tech licensed the intellectual property to Texas Multicore Technologies (TMT),&lt;ref&gt;[http://www.texasmulticoretechnologies.com Texas Multicore Technologies, Inc.]&lt;/ref&gt; for follow-on commercial development. In January 2017 TMT released v3, which includes a free Community Edition for download in addition to the commercial Professional Edition.

==Design==
SequenceL is designed to be as simple as possible to learn and use, focusing on algorithmic code where it adds value, e.g., the inventors chose not to reinvent I/O since C handled that well. As a result, the full [https://texasmulticore.com/documentation/3.0/0710language_ref.html language reference for SequenceL] is only 40 pages, with copious examples, and its formal grammar has around 15 production rules.&lt;ref&gt;{{Citation |last1=Nemanich |first1=Brad |last2=Cooke |first2=Daniel |last3=Rushton |first3=Nelson |title=SequenceL: Transparency And Multi-Core Parallelisms |series=DAMP '10 Proceedings of the 5th ACM SIGPLAN workshop on Declarative Aspects of Multicore Programming |publisher=ACM |year=2010 |pages=45–52 |location=New York, NY, US |url=https://texasmulticore.com/wp-content/uploads/2016/05/2004-ttudamp.pdf}}&lt;/ref&gt;

SequenceL is strictly evaluated (like [[Lisp (programming language)|Lisp]]), statically typed with [[type inference]] (like [[Haskell (programming language)|Haskell]]), and uses a combination of infix and prefix operators that resemble standard, informal mathematical notation (like [[C (programming language)|C]], [[Pascal (programming language)|Pascal]], [[Python (programming language)|Python]], etc.).  It is a purely declarative language, meaning that a programmer defines functions, in the mathematical sense, without giving instructions for their implementation. For example, the mathematical definition of matrix multiplication is as follows:

:The product of the ''m''×''p'' matrix ''A'' with the ''p''×''n'' matrix ''B'' is the ''m''×''n'' matrix whose (''i'',''j'')'th entry is
::&lt;math&gt;\sum_{k=1}^p A(i,k)B(k,j)&lt;/math&gt;

The SequenceL definition mirrors that definition more or less exactly:
    matmul(A(2), B(2)) [i,j] := 
        let k := 1...size(B); 
        in  sum( A[i,k] * B[k,j] );

The subscripts following each parameter ''A'' and ''B'' on the left hand side of the definition indicate that ''A'' and ''B'' are depth-2 structures (i.e., lists of lists of scalars), which are here thought of as matrices. From this formal definition, SequenceL infers the dimensions of the defined product from the formula for its (''i'', ''j'')'th entry (as the set of pairs (''i'', ''j'') for which the right hand side is defined) and computes each entry by the same formula as in the informal definition above. Notice there are no explicit instructions for iteration in this definition, or for the order in which operations are to be carried out. Because of this, the SequenceL compiler can perform operations in any order (including parallel order) which satisfies the defining equation.  In this example, computation of coordinates in the product will be parallelized in a way that, for large matrices, scales linearly with the number of processors.

As noted above, SequenceL has no built-in constructs for [[input/output]] (I/O) since it was designed to work in an additive manner with other programming languages. The decision to compile to multithreaded C++ and support the 20+ Simplified Wrapper and Interface Generator ([[SWIG]]) languages (C, C++, C#, Java, Python, etc.) means it easily fits into extant design flows, training, and tools. It can be used to enhance extant applications, create multicore libraries, and even create standalone applications by linking the resulting code with other code which performs I/O tasks. SequenceL functions can also be queried from an [[Interpreter (computing)|interpreter]] with given inputs, like Python and other interpreted languages.

==Normalize–transpose==
The main non-scalar construct of SequenceL is the sequence, which is essentially a list. Sequences may be nested to any level. To avoid the routine use of recursion common in many purely functional languages, SequenceL uses a technique termed ''normalize–transpose'' (NT), in which scalar operations are automatically distributed over elements of a sequence.&lt;ref&gt;{{Citation |last1=Cooke |first1=Daniel |last2=Rushton |first2=Nelson |title=SequenceL – An Overview of a Simple Language |journal=Proceedings of the 2005 International Conference on Programming Languages and Compilers, PLC 2005 |date=June 27–30, 2005 |location=Las Vegas, Nevada, US}}&lt;/ref&gt; For example, in SequenceL we have
:&lt;math&gt;[1,2,3] + 10 == [11,12,13]&lt;/math&gt;
This results not from overloading the '+' operator, but from the effect of NT that extends to all operations, both built-in and user-defined.
As another example, if f() is a 3-argument function whose arguments are scalars, then for any appropriate x and z we will have
:&lt;math&gt;f(x,[1,2,3],z) == [f(x,1,z), f(x,2,z), f(x,3,z)]&lt;/math&gt;
The NT construct can be used for multiple arguments at once, as in, for example
:&lt;math&gt;[1,2,3] + [10,20,30] == [11,22,33]&lt;/math&gt;
It also works when the expected argument is a non-scalar of any type T, and the actual argument is a list of objects of type T (or, in greater generality, any data structure whose coordinates are of type T). For example, if '''''A''''' is a matrix and '''''X&lt;sub&gt;s&lt;/sub&gt;''''' is a list of matrices [X&lt;sub&gt;1&lt;/sub&gt;, ..., X&lt;sub&gt;n&lt;/sub&gt;], and given the above definition of matrix multiply, in SequenceL we would have

    matmul(A,X&lt;sub&gt;s&lt;/sub&gt;) = [matmul(A,X&lt;sub&gt;1&lt;/sub&gt;),...,matmul(A,X&lt;sub&gt;n&lt;/sub&gt;)]

As a rule, NTs eliminate the need for iteration, recursion, or high level functional operators to 
#do the same things to every member of a data structure, or to
#process corresponding parts of similarly shaped structures together.
This tends to account for most uses of iteration and recursion.

==Example: prime numbers==
A good example that demonstrates the above concepts would be in finding prime numbers.  A [[prime number]] is defined as

:''An integer greater than 1, with no positive divisors other than itself and 1.''

So a positive integer ''z'' is prime if no numbers from 2 through ''z''-1, inclusive, divide evenly.  SequenceL allows this problem to be programmed by literally transcribing the above definition into the language.

In SequenceL, a sequence of the numbers from 2 through ''z''-1, inclusive, is just (2...(''z''-1)), so a program to find all of the primes between 100 and 200 can be written:

    prime(z) := z when none(z mod (2...(z-1)) = 0);

Which, in English just says,

:''...return the argument if none of the numbers between 2, and 1 less than the argument itself, divide evenly into it.''

If that condition isn’t met, the function returns nothing.  As a result, running this program yields

    cmd:&gt;prime(17)
    17
    cmd:&gt;prime(18)
    empty

The string "between 100 and 200" doesn’t appear in the program.  Rather, a programmer will typically pass that part in as the argument.  Since the program expects a scalar as an argument, passing it a sequence of numbers instead will cause SequenceL to perform the operation on each member of the sequence automatically.  Since the function returns empty for failing values, the result will be the input sequence, but filtered to return only those numbers that satisfy the criteria for primes:

    cmd:&gt;prime(100...200)
    [101,103,107,109,113,127,131,137,139,149,151,157,163,167,173,179,181,191,193,197,199]

In addition to solving this problem with a very short and readable program, SequenceL’s evaluation of the nested sequences would all be performed in parallel.

==Components==
The following software components are available and supported by TMT for use in writing SequenceL code.  All components are available on [[x86]] platforms running [[Microsoft Windows|Windows]], [[macOS]], and most varieties of [[Linux]] (including [[CentOS]], [[RedHat]], [[OpenSUSE]], and [[Ubuntu (operating system)|Ubuntu]]), and on [[ARM architecture|ARM]] and [[IBM POWER microprocessors|IBM POWER]] platforms running most varieties of [[Linux]].

===Interpreter===
A [[Command-line interface|command-line]] [[Interpreter (computing)|interpreter]] allows writing code directly into a command shell, or loading code from prewritten text files.  This code can be executed, and the results evaluated, to assist in checking code correctness, or finding a quick answer. It is also available via the popular [[Eclipse (software)|Eclipse]] [[integrated development environment]] (IDE). Code executed in the interpreter does not run in parallel; it executes in one thread.

===Compiler===
A command-line [[compiler]] reads SequenceL code and generates highly parallelized, [[Automatic vectorization|vectorized]], C++, and optionally OpenCL, which must be linked with the SequenceL runtime library to execute.

===Runtime===
The runtime environment is a pre-compiled set of libraries which works with the compiled parallelized C++ code to execute optimally on the target platform.  It builds on Intel Threaded Building Blocks (TBB)&lt;ref&gt;[https://www.threadingbuildingblocks.org/ Intel Threaded Building Blocks (TBB)]&lt;/ref&gt; and handles things such as cache optimization, memory management, work queues-stealing, and performance monitoring.

===Eclipse IDE plug-in with debugger===
An [[Eclipse (software)|Eclipse]] [[integrated development environment]] [[Plug-in (computing)|plug-in]] provides standard editing abilities (function rollup, chromacoding, etc.), and a SequenceL debugging environment.  This plug-in runs against the SequenceL Interpreter, so cannot be used to debug the multithreaded code; however, by providing automatic parallelization, debugging of parallel SequenceL code is really verifying correctness of sequential SequenceL code.  That is, if it runs correctly sequentially, it should run correctly in parallel – so debugging in the interpreter is sufficient.

===Libraries===
Various math and other standard function libraries are included as SequenceL source code to streamline the programming process and serve as best practice examples.  These may be imported, in much the same way that C or C++ libraries are #included.

==See also==
* [[Parallel computing]]
* [[Automatic parallelization tool]]
* [[Multi-core processor]]
* [[Multiprocessing]]
* [[Functional programming]]
* [[Purely functional programming]]
* [[Declarative programming]]
* [[Comparison of programming paradigms]]
* [[Automatic vectorization]]
* [[Simon Peyton Jones]]
* [[Rosetta Code]]

==References==
{{Reflist}}

==External links==
* {{Official website|texasmulticore.com}}{{Dead link|date=May 2018}} Texas Multicore Technologies
* [https://texasmulticore.com/technology/multicore-performance/ Why SequenceL Works]
* [https://texasmulticore.com/technology/openmp-comparison/ OpenMP compared to SequenceL]
* [https://texasmulticore.com/products/features/ SequenceL Features]
* [https://texasmulticore.com/technology/patented-auto-parallel/ Overview: Patented Automatic Parallelization in SequenceL]
* [https://www.youtube.com/channel/UCb6JyUsAuS_vmBAE3gXVKzQ YouTube: Texas Multicore Technologies]
* [https://texasmulticore.com/resources/downloads/ Free Downloads]
* [https://texasmulticore.com/documentation/ Programmer Resources and Education]
* [https://texasmulticore.com/wp-content/uploads/2016/05/2008-ACM-paper_NTD-Auto-Approach-for-Handling-Nonscalars-1.pdf Normalize, Transpose and Distribute: An Automatic Approach for Handling Nonscalars]
* [http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=8839212.PN.&amp;OS=PN/8839212&amp;RS=PN/8839212/ US Patent 8,839,212, Method, apparatus and computer program product for automatically generating a computer program using consume, simplify and produce semantics with normalize, transpose and distribute operations]
* [https://rosettacode.org/wiki/Category:SequenceL SequenceL examples on Rosetta Code wiki]

[[Category:High-level programming languages]]
[[Category:Parallel computing]]
[[Category:Array programming languages]]
[[Category:Cross-platform software]]
[[Category:Declarative programming languages]]
[[Category:Functional programming]]
[[Category:Functional languages]]
[[Category:Statically typed programming languages]]
[[Category:Heterogeneous computing]]
[[Category:Concurrent programming languages]]
[[Category:Mathematical software]]
[[Category:Numerical analysis software for Windows]]
[[Category:Numerical analysis software for MacOS]]
[[Category:Numerical analysis software for Linux]]
[[Category:Numerical linear algebra]]
[[Category:Numerical programming languages]]
[[Category:Numerical software]]
[[Category:Science software for Windows]]
[[Category:Science software for MacOS]]
[[Category:Science software for Linux]]
[[Category:GPGPU]]</text>
      <sha1>8fo888t02smzdiprvvzl1z071ollq7u</sha1>
    </revision>
  </page>
  <page>
    <title>Sum of two squares theorem</title>
    <ns>0</ns>
    <id>46248976</id>
    <revision>
      <id>863794099</id>
      <parentid>761026130</parentid>
      <timestamp>2018-10-13T02:30:59Z</timestamp>
      <contributor>
        <username>Seahawk01</username>
        <id>34873291</id>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1839">In [[number theory]], the '''sum of two squares theorem''' says when an integer {{nowrap|{{mvar|n}} &gt; 1}} can be written as a sum of two squares, that is, when {{nowrap|1={{mvar|n}} = {{mvar|a}}&lt;sup&gt;2&lt;/sup&gt; + {{mvar|b}}&lt;sup&gt;2&lt;/sup&gt;}} for some integers {{mvar|a}}, {{mvar|b}}.

:''An integer greater than one can be written as a sum of two squares [[if and only if]] its [[prime decomposition]] contains no prime congruent to 3&amp;nbsp;(mod&amp;nbsp;4) raised to an odd power.''&lt;ref&gt;{{cite book|title=Elementary Number Theory|author=[[Underwood Dudley]]|publisher=W.H. Freeman and Company|edition=2|year=1978}}&lt;/ref&gt;

This theorem supplements [[Fermat's two-square theorem]] which says when a [[prime number]] can be written as a sum of two squares, in that it also covers the case for [[composite number]]s.

==Examples==

The prime decomposition of the number 2450 is given by 2450 = 2{{cdot}}5&lt;sup&gt;2&lt;/sup&gt;{{cdot}}7&lt;sup&gt;2&lt;/sup&gt;. Of the primes occurring in this decomposition, 2, 5, and 7, only 7 is congruent to 3 modulo 4. Its exponent in the decomposition, 2, is even. Therefore, the theorem states, it is expressible as the sum of two squares. Indeed, {{nowrap|1=2450 = 7&lt;sup&gt;2&lt;/sup&gt; + 49&lt;sup&gt;2&lt;/sup&gt;}}.

The prime decomposition of the number 3430 is 2{{cdot}}5{{cdot}}7&lt;sup&gt;3&lt;/sup&gt;. This time, the exponent of 7 in the decomposition is 3, an odd number. So 3430 cannot be written as the sum of two squares.

== See also ==

* [[Brahmagupta–Fibonacci identity]].  This identity entails that the set of all sums of two squares is [[Closure (mathematics)|closed]] under multiplication.
* [[Landau–Ramanujan constant]], used in a formula for the density of the numbers that are sums of two squares

==References==
&lt;references/&gt;

[[Category:Additive number theory]]
[[Category:Squares in number theory]]
[[Category:Theorems in number theory]]</text>
      <sha1>re6437xi4wyn0pimu1znrhkgwl03n2g</sha1>
    </revision>
  </page>
  <page>
    <title>Tardos function</title>
    <ns>0</ns>
    <id>54960916</id>
    <revision>
      <id>798846925</id>
      <parentid>796964537</parentid>
      <timestamp>2017-09-04T04:54:34Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>[[Martin Grötschel]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4115">In [[graph theory]] and [[circuit complexity]], the '''Tardos function''' is a [[graph invariant]] introduced by [[Éva Tardos]] in 1988 that has the following properties:&lt;ref name=e&gt;{{citation
 | last = Tardos | first = É. | authorlink = Éva Tardos
 | url = http://www.cs.cornell.edu/~eva/Gap.Between.Monotone.NonMonotone.Circuit.Complexity.is.Exponential.pdf
 | doi = 10.1007/BF02122563
 | issue = 1
 | journal = [[Combinatorica]]
 | mr = 952004
 | pages = 141–142
 | title = The gap between monotone and nonmonotone circuit complexity is exponential
 | volume = 8
 | year = 1988}}&lt;/ref&gt;&lt;ref&gt;{{citation|title=Boolean Function Complexity: Advances and Frontiers|volume=27|series=Algorithms and Combinatorics|first=Stasys|last=Jukna|publisher=Springer|year=2012|page=272|url=https://books.google.com/books?id=rHn7hXxyPAkC&amp;pg=PA272|isbn=9783642245084}}&lt;/ref&gt;
*Like the [[Lovász number]] of the [[Complement graph|complement of a graph]], the Tardos function is sandwiched between the [[clique number]] and the [[chromatic number]] of the graph. These two numbers are both [[NP-hard]] to compute.
*The Tardos function is monotone, in the sense that adding edges to a graph can only cause its Tardos function to increase or stay the same, but never decrease.
*The Tardos function can be computed in [[polynomial time]].
*Any [[monotone circuit]] for computing the Tardos function requires exponential size.

To define her function, Tardos uses a [[polynomial-time approximation scheme]] for the Lovász number, based on the [[ellipsoid method]] and provided by {{harvtxt|Grötschel|Lovász|Schrijver|1981}}.&lt;ref&gt;{{citation
 | last1 = Grötschel | first1 = M. | author1-link = Martin Grötschel
 | last2 = Lovász | first2 = L. | author2-link = László Lovász
 | last3 = Schrijver | first3 = A. | author3-link = Alexander Schrijver
 | doi = 10.1007/BF02579273
 | issue = 2
 | journal = [[Combinatorica]]
 | mr = 625550
 | pages = 169–197
 | title = The ellipsoid method and its consequences in combinatorial optimization
 | volume = 1
 | year = 1981}}.&lt;/ref&gt; Approximating the Lovász number of the complement and then rounding the approximation to an integer would not necessarily produce a monotone function, however. To make the result monotone, Tardos approximates the Lovász number of the complement to within an additive error of &lt;math&gt;1/n^2&lt;/math&gt;, adds &lt;math&gt;m/n^2&lt;/math&gt; to the approximation, and then rounds the result to the nearest integer. Here &lt;math&gt;m&lt;/math&gt; denotes the number of edges in the given graph, and &lt;math&gt;n&lt;/math&gt; denotes the number of vertices.&lt;ref name=e/&gt;

Tardos used her function to prove an exponential separation between the capabilities of monotone Boolean logic circuits and arbitrary circuits.
A result of [[Alexander Razborov]], previously used to show that the clique number required exponentially large monotone circuits,&lt;ref&gt;{{citation
 | last = Razborov | first = A. A. | authorlink = Alexander Razborov
 | issue = 4
 | journal = Doklady Akademii Nauk SSSR
 | mr = 785629
 | pages = 798–801
 | title = Lower bounds on the monotone complexity of some Boolean functions
 | volume = 281
 | year = 1985}}&lt;/ref&gt;&lt;ref&gt;{{citation
 | last1 = Alon | first1 = N. | author1-link = Noga Alon
 | last2 = Boppana | first2 = R. B.
 | doi = 10.1007/BF02579196
 | issue = 1
 | journal = [[Combinatorica]]
 | mr = 905147
 | pages = 1–22
 | title = The monotone circuit complexity of Boolean functions
 | volume = 7
 | year = 1987}}&lt;/ref&gt; also shows that the Tardos function requires exponentially large monotone circuits despite being computable by a non-monotone circuit of polynomial size.
Later, the same function was used to provide a [[counterexample]] to a purported proof of [[P ≠ NP]] by Norbert Blum.&lt;ref&gt;{{citation|url=https://lucatrevisan.wordpress.com/2017/08/15/on-norbert-blums-claimed-proof-that-p-does-not-equal-np/|title=On Norbert Blum’s claimed proof that P does not equal NP|first=Luca|last=Trevisan|authorlink=Luca Trevisan|work=in theory|date=August 15, 2017}}&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Graph invariants]]
[[Category:Circuit complexity]]</text>
      <sha1>gopnj74lc646bzswa0hbrw8jynwgzwq</sha1>
    </revision>
  </page>
  <page>
    <title>The Method of Mechanical Theorems</title>
    <ns>0</ns>
    <id>261272</id>
    <revision>
      <id>838021522</id>
      <parentid>817536552</parentid>
      <timestamp>2018-04-24T13:10:25Z</timestamp>
      <contributor>
        <username>Smeagol 17</username>
        <id>7183365</id>
      </contributor>
      <comment>/* Other propositions in the palimpsest */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15760">{{italic title}}
'''''The Method of Mechanical Theorems''''' ({{lang-el|Περὶ μηχανικῶν θεωρημάτων πρὸς Ἐρατοσθένη ἔφοδος}}), also referred to as '''''The Method''''', is considered one of the major surviving works of the [[ancient Greece|ancient Greek]] [[polymath]] [[Archimedes]]. ''The Method'' takes the form of a letter from Archimedes to [[Eratosthenes]],&lt;ref&gt;{{harvnb|Archimedes|1912}}&lt;/ref&gt; the chief librarian at the [[Library of Alexandria]], and contains the first attested explicit use of ''[[method of indivisibles|indivisibles]]'' (sometimes referred to as [[infinitesimal]]s).&lt;ref&gt;{{harvnb|Archimedes|1912}}&lt;/ref&gt;&lt;ref&gt;Netz, Reviel; Saito, Ken; Tchernetska, Natalie: A new reading of Method Proposition 14: preliminary evidence from the Archimedes palimpsest. I. SCIAMVS 2 (2001), 9–29.&lt;/ref&gt; The work was originally thought to be lost, but in 1906 was rediscovered in the celebrated [[Archimedes Palimpsest]].  The palimpsest includes Archimedes' account of the "mechanical method", so-called because it relies on the [[Lever#Law of the lever|law of the lever]], which was first  demonstrated by Archimedes, and of the [[center of mass]] (or [[centroid]]), which he had found for many special shapes.

Archimedes did not admit the method of indivisibles as part of rigorous mathematics, and therefore did not publish his method in the formal treatises that contain the results. In these treatises, he proves the same theorems by [[method of exhaustion|exhaustion]], finding rigorous upper and lower bounds which both converge to the answer required. Nevertheless, the mechanical method was what he used to discover the relations for which he later gave rigorous proofs.

== Area of a parabola ==

To explain Archimedes' method today, it is convenient to make use of a little bit of Cartesian geometry, although this of course was unavailable at the time. His idea is to use the law of the lever to determine the areas of figures from the known center of mass of other figures. The simplest example in modern language is the area of the parabola. Archimedes uses a more elegant method, but in Cartesian language, his method is calculating the integral

: &lt;math&gt; \int_0^1 x^2 \, dx  = \frac{1}{3},&lt;/math&gt;

which can easily be checked nowadays using elementary [[integral calculus]].

The idea is to mechanically balance the parabola (the curved region being integrated above) with a certain triangle that is made of the same material. The parabola is the region in the ''x''-''y'' plane between the ''x''-axis and ''y''&amp;nbsp;=&amp;nbsp;''x''&lt;sup&gt;2&lt;/sup&gt; as ''x'' varies from 0 to&amp;nbsp;1.  The triangle is the region in the ''x''-''y'' plane between the ''x''-axis and the line ''y''&amp;nbsp;=&amp;nbsp;''x'', also as ''x'' varies from 0 to&amp;nbsp;1.

Slice the parabola and triangle into vertical slices, one for each value of&amp;nbsp;''x''. Imagine that the ''x''-axis is a lever, with a fulcrum at&amp;nbsp;''x''&amp;nbsp;=&amp;nbsp;0. The [[Lever#Law of the lever|law of the lever]] states that two objects on opposite sides of the fulcrum will balance if each has the same [[torque]], where an object's torque equals its weight times its distance to the fulcrum. For each value of&amp;nbsp;''x'', the slice of the triangle at position x has a mass equal to its height&amp;nbsp;''x'', and is at a distance&amp;nbsp;''x'' from the fulcrum; so it would balance the corresponding slice of the parabola, of height ''x''&lt;sup&gt;2&lt;/sup&gt;, if the latter were moved to ''x''&amp;nbsp;=&amp;nbsp;&amp;minus;1, at a distance of 1 on the other side of the fulcrum.

Since each pair of slices balances, moving the whole parabola to ''x''&amp;nbsp;=&amp;nbsp;&amp;minus;1 would balance the whole triangle. This means that if the original uncut parabola is hung by a hook from the point ''x''&amp;nbsp;=&amp;nbsp;&amp;minus;1 (so that the whole mass of the parabola is attached to that point), it will balance the triangle sitting between ''x''&amp;nbsp;=&amp;nbsp;0 and&amp;nbsp;''x''&amp;nbsp;=&amp;nbsp;1.

The center of mass of a triangle can be easily found by the following method, also due to Archimedes. If a [[Median (geometry)|median line]] is drawn from any one of the vertices of a triangle to the opposite edge ''E'', the triangle will balance on the median, considered as a fulcrum. The reason is that if the triangle is divided into infinitesimal line segments parallel to ''E'', each segment has equal length on opposite sides of the median, so balance follows by symmetry. This argument can be easily made rigorous by [[method of exhaustion|exhaustion]] by using little rectangles instead of infinitesimal lines, and this is what Archimedes does in [[On the Equilibrium of Planes]].

So the center of mass of a triangle must be at the intersection point of the medians. For the triangle in question, one median is the line ''y''&amp;nbsp;=&amp;nbsp;''x''/2, while a second median is the line ''y''&amp;nbsp;=&amp;nbsp;1&amp;nbsp;&amp;minus;&amp;nbsp;''x''. Solving these equations, we see that the intersection of these two medians is above the point ''x''&amp;nbsp;=&amp;nbsp;2/3, so that the total effect of the triangle on the lever is as if the total mass of the triangle were pushing down on (or hanging from) this point.  The total torque exerted by the triangle is its area, 1/2, times the distance 2/3 of its center of mass from the fulcrum at ''x''&amp;nbsp;=&amp;nbsp;0.  This torque of 1/3 balances the parabola, which is at a distance -1 from the fulcrum.  Hence, the area of the parabola must be&amp;nbsp;1/3 to give it the opposite torque.

This type of method can be used to find the area of an arbitrary section of a parabola, and similar arguments can be used to find the integral of any power of ''x'', although higher powers become complicated without algebra. Archimedes only went as far as the integral of ''x''&lt;sup&gt;3&lt;/sup&gt;, which he used to find the center of mass of a hemisphere, and in other work, the center of mass of a parabola.

==First proposition in the palimpsest==

Consider the [[parabola]] in the figure to the right. Pick two points on the parabola and call them ''A'' and ''B''.

[[Image:Archie1small.png|right]]

Suppose the line segment ''AC'' is parallel to the axis of symmetry of the parabola. Further suppose that the line segment ''BC'' lies on a line that is [[tangent]] to the parabola at ''B''.
The first proposition states:

:The area of the triangle ''ABC'' is exactly three times the area bounded by the parabola and the [[secant line]] ''AB''.

:''Proof'': 
Let ''D'' be the midpoint of ''AC''. Construct a line segment ''JB'' through ''D'', where the distance from ''J'' to ''D'' is equal to the distance from ''B'' to ''D''.  We will think of the segment ''JB'' as a "lever" with ''D'' as its fulcrum. As Archimedes had previously shown, the center of mass of the triangle is at the point ''I'' on the "lever" where ''DI'' :''DB''&amp;nbsp;=&amp;nbsp;1:3. Therefore, it suffices to show that if the whole weight of the interior of the triangle rests at ''I'', and the whole weight of the section of the parabola at ''J'', the lever is in equilibrium.

Consider an infinitely small cross-section of the triangle given by the segment ''HE'', where the point ''H'' lies on ''BC'', the point ''E'' lies on ''AB'', and ''HE'' is parallel to the axis of symmetry of the parabola. Call the intersection of ''HE'' and the parabola ''F'' and the intersection of ''HE'' and the lever ''G''. If the whole weight of the triangle rests at ''I'', it exerts the same torque on the lever ''JB'' as it does on ''HE''. Thus, we wish to show that if the weight of the cross-section ''HE'' rests at ''G'' and the weight of the cross-section ''EF'' of the section of the parabola rests at ''J'', then the lever is in equilibrium.  In other words, it suffices to show that ''EF'' :''GD''&amp;nbsp;=&amp;nbsp;''EH'' :''JD''.  But that is a routine consequence of the equation of the parabola.&amp;nbsp;[[Q.E.D.]]

== Volume of a sphere ==
Again, to illuminate the mechanical method, it is convenient to use a little bit of coordinate geometry. If a sphere of radius 1 is placed with its center at ''x''&amp;nbsp;=&amp;nbsp;1, the vertical cross sectional radius &lt;math&gt;\rho_S&lt;/math&gt; at any ''x'' between 0 and 2 is given by the following formula:
::&lt;math&gt;\rho_S(x) = \sqrt{x(2-x)}.&lt;/math&gt;

The mass of this cross section, for purposes of balancing on a lever, is proportional to the area:

::&lt;math&gt; \pi \rho_S(x)^2 = 2\pi x - \pi x^2.&lt;/math&gt;

Archimedes then considered rotating the triangular region between ''y''&amp;nbsp;=&amp;nbsp;0 and ''y''&amp;nbsp;=&amp;nbsp;''x'' and ''x'' =&amp;nbsp;''2'' on the ''x''-''y'' plane around the ''x''-axis, to form a cone. The cross section of this cone is a circle of radius &lt;math&gt;\rho_C&lt;/math&gt;

::&lt;math&gt;\rho_C(x) = x &lt;/math&gt;

and the area of this cross section is

::&lt;math&gt;\pi \rho_C^2 = \pi x^2. &lt;/math&gt;

So if slices of the cone and the sphere ''both'' are to be weighed together, the combined cross-sectional area is:

::&lt;math&gt; M(x) = 2\pi x. &lt;/math&gt;

If the two slices are placed together at distance 1 from the fulcrum, their total weight would be exactly balanced by a circle of area &lt;math&gt;2\pi&lt;/math&gt; at a distance ''x'' from the fulcrum on the other side. This means that the cone and the sphere together, if all their material were moved to ''x = 1'', would balance a cylinder of base radius 1 and length 2 on the other side.

As ''x'' ranges from 0 to 2, the cylinder will have  a center of gravity a distance 1 from the fulcrum, so all the weight of the cylinder can be considered to be at position 1. The condition of balance ensures that the volume of the cone plus the volume of the sphere is equal to the volume of the cylinder.

The volume of the cylinder is the cross section area, &lt;math&gt;2\pi&lt;/math&gt; times the height, which is 2, or &lt;math&gt;4\pi&lt;/math&gt;. Archimedes could also find the volume of the cone using the mechanical method, since, in modern terms, the integral involved is exactly the same as the one for area of the parabola. The volume of the cone is 1/3 its base area times the height. The base of the cone is a circle of radius 2, with area &lt;math&gt;4\pi&lt;/math&gt;, while the height is 2, so the area is &lt;math&gt;8\pi/3&lt;/math&gt;. Subtracting the volume of the cone from the volume of the cylinder gives the volume of the sphere:

::&lt;math&gt; V_S = 4\pi - {8\over 3}\pi = {4\over 3}\pi.&lt;/math&gt;

The dependence of the volume of the sphere on the radius is obvious from scaling, although that also was not trivial to make rigorous back then. The method then gives the familiar formula for the [[volume of a sphere]]. By scaling the dimensions linearly Archimedes easily extended the volume result to [[spheroids]].

Archimedes argument is nearly identical to the argument above, but his cylinder had a bigger radius, so that the cone and the cylinder hung at a greater distance from the fulcrum. He considered this argument to be his greatest achievement, requesting that the accompanying figure of the balanced sphere, cone, and cylinder be engraved upon his tombstone.

== Surface area of a sphere ==

To find the surface area of the sphere, Archimedes argued that just as the area of the circle could be thought of as infinitely many infinitesimal right triangles going around the circumference (see [[Measurement of the Circle]]), the volume of the sphere could be thought of as divided into many cones with height equal to the radius and base on the surface. The cones all have the same height, so their volume is 1/3 the base area times the height.

Archimedes states that the total volume of the sphere is equal to the volume of a cone whose base has the same surface area as the sphere and whose height is the radius. There are no details given for the argument, but the obvious reason is that the cone can be divided into infinitesimal cones by splitting the base area up, and the each cone makes a contribution according to its base area, just the same as in the sphere.

Let the surface of the sphere be&amp;nbsp;''S''. The volume of the cone with base area ''S'' and height ''r'' is &lt;math&gt;\scriptstyle Sr/3&lt;/math&gt;, which must equal the volume of the sphere: &lt;math&gt;\scriptstyle 4\pi r^3/3&lt;/math&gt;. Therefore, the surface area of the sphere must be &lt;math&gt; 4\pi r^2&lt;/math&gt;, or "four times its largest circle". Archimedes proves this rigorously in [[On the Sphere and Cylinder]].

== Curvilinear shapes with rational volumes ==
One of the remarkable things about the ''Method'' is that Archimedes finds two shapes defined by sections of cylinders, whose volume does not involve&amp;nbsp;''&amp;pi;'', despite the shapes having curvilinear boundaries. This is a central point of the investigation&amp;mdash;certain curvilinear shapes could be rectified by ruler and compass, so that there are nontrivial rational relations between the volumes defined by the intersections of geometrical solids.

Archimedes emphasizes this in the beginning of the treatise, and invites the reader to try to reproduce the results by some other method. Unlike the other examples, the volume of these shapes is not rigorously computed in any of his other works. From fragments in the palimpsest, it appears that Archimedes did inscribe and circumscribe shapes to prove rigorous bounds for the volume, although the details have not been preserved.

The two shapes he considers are the intersection of two cylinders at right angles, which is the region of (''x'',&amp;nbsp;''y'',&amp;nbsp;''z'') obeying:

::('''2Cyl''') &lt;math&gt; x^2 + y^2 &lt;1 \;\;\; y^2 + z^2 &lt;1 &lt;/math&gt;

and the circular prism, which is the region obeying:

::('''CirP''') &lt;math&gt; x^2 + y^2&lt;1 \;\;\;\;\; 0&lt;z&lt;y. &lt;/math&gt;

Both problems have a slicing which produces an easy integral for the mechanical method. For the circular prism, cut up the ''x''-axis into slices. The region in the ''y''-''z'' plane at any x is the interior of a right triangle of side length &lt;math&gt;\scriptstyle \sqrt{1-x^2}&lt;/math&gt; whose area is &lt;math&gt;\scriptstyle 1/2(1-x^2)&lt;/math&gt;, so that the total volume is:

::('''CirP''')  &lt;math&gt;\displaystyle\int_{-1}^1 {1\over 2} (1-x^2) \, dx &lt;/math&gt;

which can be easily rectified using the mechanical method. Adding to each triangular section a section of a triangular pyramid with area &lt;math&gt;\scriptstyle x^2/2&lt;/math&gt; balances a prism whose cross section is constant.

For the intersection of two cylinders, the slicing is lost in the manuscript, but it can be reconstructed in an obvious way in parallel to the rest of the document: if the x-z plane is the slice direction, the equations for the cylinder give that &lt;math&gt;\scriptstyle x^2 \,&lt;\, 1-y^2&lt;/math&gt; while &lt;math&gt;\scriptstyle z^2\,&lt;\, 1-y^2&lt;/math&gt;, which defines a region which is a square in the ''x''-''z'' plane of side length &lt;math&gt;\scriptstyle 2\sqrt{1-y^2}&lt;/math&gt;, so that the total volume is:

::('''2Cyl''')  &lt;math&gt;\displaystyle\int_{-1}^1 4(1-y^2) \, dy. &lt;/math&gt;

And this is the same integral as for the previous example.

==Other propositions in the palimpsest==

A series of propositions of geometry are proved in the palimpsest by similar arguments. One theorem is that the location of a center of mass of a [[wikt:hemisphere|hemisphere]] is located 5/8 of the way from the pole to the center of the sphere. This problem is notable, because it is evaluating a cubic integral.

== See also ==
* [[Archimedes Palimpsest]]
* [[Method of indivisibles]]
* [[Method of exhaustion]]

==Notes==
&lt;references/&gt;

== References ==
* {{Citation|last=Archimedes |authorlink=Archimedes| title=The method of Archimedes recently discovered by Heiberg; a supplement to the Works of Archimedes| publisher=[[Cambridge University Press]] |year=1912 | url=https://archive.org/details/cu31924005730563}} (translated by [[Thomas Little Heath]]).

{{Archimedes}}
{{Infinitesimals}}

{{DEFAULTSORT:Method of Mechanical Theorems}}
[[Category:History of calculus]]
[[Category:Archimedes]]
[[Category:Works by Archimedes]]</text>
      <sha1>5u05y0nh2ivshr0mjij0915r2hf30gs</sha1>
    </revision>
  </page>
  <page>
    <title>The Road to Reality</title>
    <ns>0</ns>
    <id>1076615</id>
    <revision>
      <id>809777389</id>
      <parentid>809777360</parentid>
      <timestamp>2017-11-11T09:40:47Z</timestamp>
      <contributor>
        <username>FreeKnowledgeCreator</username>
        <id>8971613</id>
      </contributor>
      <comment>add category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4841">{{Use dmy dates|date=May 2012}}
{{Infobox book | &lt;!-- See Wikipedia:WikiProject_Novels or Wikipedia:WikiProject_Books --&gt;
| name          = The Road to Reality:&lt;br&gt;A Complete Guide to the Laws of the Universe.
| image         = The Road to Reality.jpg
| caption       = Cover of the hardcover edition
| author        = [[Roger Penrose]]
| country       = United States
| language      = English
| subject       = [[Modern physics]]
| publisher     = [[Alfred A. Knopf]]
| release_date  = 2004&lt;br&gt;Later revised editions: 2005, 2006, 2007
| media_type    = Print, e-book
| pages         = 1136 pp.
| isbn          = 978-0679454434
| italic title  = force
| preceded_by   = [[Shadows of the Mind]]
| followed_by   = [[Cycles of Time]]
}}

'''''The Road to Reality: A Complete Guide to the Laws of the Universe''''' is a book on modern [[physics]] by the British mathematical physicist [[Roger Penrose]], published in 2004.&lt;ref&gt;{{cite web |url=https://www.nytimes.com/2005/02/27/books/review/the-road-to-reality-a-really-long-history-of-time.html?_r=0 |title='The Road to Reality': A Really Long History of Time |first1=George |last1=Johnson |date=27 February 2005 |publisher=''The New York Times, USA'' |accessdate=3 April 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=The Road to Reality: A Complete Guide to the Laws of the Universe by Roger Penrose|url=http://www.goodreads.com/book/show/10638.The_Road_to_Reality?from_search=true&amp;search_version=service|website=[[Goodreads]]|publisher=goodreads.com|accessdate=18 November 2015}}&lt;/ref&gt; It covers the basics of the [[Standard Model]] of particle physics, discussing [[general relativity]] and [[quantum mechanics]], and discusses the possible unification of these two theories.

==Overview==
The book discusses the physical world. Many fields that 19th century scientists believed were separate, such as [[electricity and magnetism]], are aspects of more fundamental properties. Some texts, both popular and university level, introduce these topics as separate concepts, and then reveal their combination much later. ''The Road to Reality'' reverses this process, first expounding the underlying mathematics of [[space–time]], then showing how electromagnetism and other phenomena fall out fully formed.

The book is just over 1100 pages, of which the first 383 are dedicated to mathematics—Penrose's goal is to acquaint inquisitive readers with the mathematical tools needed to understand the remainder of the book in depth. Physics enters the discussion on page 383 with the topic of space–time. From there it moves on to [[field (physics)|fields]] in spacetime, deriving the [[electromagnetism|classical electrical and magnetic forces]] from [[first principles]]; that is, if one lives in spacetime of a particular sort, these fields develop naturally as a consequence. Energy and [[Conservation law (physics)|conservation law]]s appear in the discussion of [[Lagrangian mechanics|Lagrangians]] and [[Hamiltonian mechanics|Hamiltonian]]s, before moving on to a full discussion of quantum physics, [[particle physics|particle theory]] and [[quantum field theory]]. A discussion of the [[measurement problem]] in quantum mechanics is given a full chapter; [[superstring]]s are given a chapter near the end of the book, as are [[loop gravity]] and [[twistor theory]].  The book ends with an exploration of other theories and possible ways forward.

The final chapters reflect Penrose's personal perspective, which differs in some respects from what he regards as the current fashion among theoretical physicists. He is skeptical about [[string theory]], to which he prefers [[loop quantum gravity]]. He is optimistic about his own approach, [[twistor theory]]. He also holds some controversial views about the role of consciousness in physics, as laid out in his earlier books (see ''[[Shadows of the Mind]]'').

==Editions==
*Alfred A. Knopf (publisher), February 2005, hardcover, {{ISBN|0-679-45443-8}}
*Vintage Books, 2005, softcover, {{ISBN|0-09-944068-7}}
*Vintage Books, 2006, softcover, {{ISBN|0-09-944068-7}} 
*Vintage Books, 2007, softcover, {{ISBN|0-679-77631-1}}

==References==
{{Reflist}}

==External links==
* [https://web.archive.org/web/20130912160048/http://www.roadsolutions.ox.ac.uk/ Site] with errata and solutions to some exercises from the first few chapters. Not sponsored by Penrose.
* [http://www.roadtoreality.info/ Archive] of the Road to Reality internet forum, now defunct.
* [https://sites.google.com/site/vascoprat/rtr-solutions Solutions] for many Road to Reality exercises.
{{Roger Penrose}}

{{DEFAULTSORT:Road to Reality}}
[[Category:2004 books]]
[[Category:Alfred A. Knopf books]]
[[Category:Cosmology books]]
[[Category:Mathematics books]]
[[Category:Physics books]]
[[Category:Quantum mind]]
[[Category:String theory books]]
[[Category:Works by Roger Penrose]]</text>
      <sha1>6nydaxpwxwr5kryyt8u53rpdu63j4ay</sha1>
    </revision>
  </page>
  <page>
    <title>Theorem on friends and strangers</title>
    <ns>0</ns>
    <id>2431128</id>
    <revision>
      <id>825508727</id>
      <parentid>790777891</parentid>
      <timestamp>2018-02-13T20:17:17Z</timestamp>
      <contributor>
        <ip>140.180.249.29</ip>
      </contributor>
      <comment>Removing incomplete sentence</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4502">{{for|the friendship theorem of [[Paul Erdős]], [[Alfréd Rényi]], and [[Vera T. Sós]] characterizing graphs in which each two vertices have exactly one neighbor|friendship graph}}
[[Image:Friends strangers graph.gif|right|frame|
All the 78 possible friends-strangers graphs with 6 nodes. For each graph the red/blue nodes
shows a sample triplet of mutual friends/strangers.]]

The '''theorem on friends and strangers''' is a [[mathematical theorem]] in an area of mathematics called [[Ramsey theory]].

==Statement==
Suppose a party has six people. Consider any two of them. They might be meeting for the first time—in  which case we will call them mutual strangers; or they might have met before—in which case we will call them mutual acquaintances. The theorem says:

:In any party of six people either at least three of them are (pairwise) mutual strangers or at least three of them are (pairwise) mutual acquaintances.

==Conversion to a graph-theoretic setting==
A [[mathematical proof|proof]] of the theorem requires nothing but a three-step logic.  It is convenient to phrase the problem in graph-theoretic language. 

Suppose a [[Graph (discrete mathematics)|graph]] has 6 vertices and every pair of (distinct) vertices is joined by an edge. Such a graph is called a [[complete graph]] (because there cannot be any more edges). A complete graph on &lt;math&gt;n&lt;/math&gt; vertices is denoted by the symbol &lt;math&gt;K_n&lt;/math&gt;.

Now take a &lt;math&gt;K_6&lt;/math&gt;. It has 15 edges in all. Let the 6 vertices stand for the 6 people in our party. Let the edges be coloured red or blue depending on whether the two people represented by the vertices connected by the edge are mutual strangers or mutual acquaintances, respectively. The theorem now asserts:

:No matter how you colour the 15 edges of a &lt;math&gt;K_6&lt;/math&gt; with red and blue, you cannot avoid having either a red triangle—that is, a triangle all of whose three sides are red, representing three pairs of mutual strangers—or a blue triangle, representing three pairs of mutual acquaintances.  In other words, whatever colours you use, there will always be at least one monochromatic triangle ( that is, a triangle all of whose edges have the same color ).

==Proof==
Choose any one vertex; call it ''P''. There are five edges leaving ''P''. They are each coloured red or blue. The [[pigeonhole principle]] says that at least three of them must be of the same colour; for if there are less than three of one colour, say red, then there are at least three that are blue.

Let ''A'', ''B'', ''C'' be the other ends of these three edges, all of the same colour, say blue. If any one of ''AB'', ''BC'', ''CA'' is blue, then that edge together with the two edges from P to the edge's endpoints forms a blue triangle.  If none of ''AB'', ''BC'', ''CA'' is blue, then all three edges are red and we have a red triangle, namely, ''ABC''.

==Ramsey's paper==
The utter simplicity of this argument, which so powerfully produces a very interesting conclusion, is what makes the theorem appealing. In 1930, in a paper entitled 'On a Problem in Formal Logic,' [[Frank P. Ramsey]] proved a very general theorem (now known as [[Ramsey's theorem]]) of which this theorem is a simple case. This theorem of Ramsey forms the foundation of the area known as [[Ramsey theory]] in [[combinatorics]].

==Boundaries to the theorem==
[[Image:RamseyTheory K5 no mono K3.svg|frame|A 2-colouring of ''K''&lt;sub&gt;5&lt;/sub&gt; with no monochromatic ''K''&lt;sub&gt;3&lt;/sub&gt;]]

The conclusion to the theorem does not hold if we replace the party of six people by a party of less than six. To show this, we give a coloring of ''K''&lt;sub&gt;5&lt;/sub&gt; with red and blue that does not contain a triangle with all edges the same color.  We draw ''K''&lt;sub&gt;5&lt;/sub&gt; as a [[pentagon]] surrounding a star (a [[pentagram]]).  We color the edges of the pentagon red and the edges of the star blue.
Thus, 6 is the smallest number for which we can claim the conclusion of the theorem. In Ramsey theory, we write this fact as:

: &lt;math&gt;R(3,3: 2) = 6.&lt;/math&gt;

==References==
*V. Krishnamurthy. Culture, Excitement and Relevance of Mathematics, Wiley Eastern, 1990. {{isbn|81-224-0272-0}}.

==External links==
* [http://www.cut-the-knot.org/Curriculum/Combinatorics/ThreeOrThree.shtml Party Acquaintances] at [[cut-the-knot]] (requires Java)

&lt;!-- This article needs help on input of one graphic. --&gt;

[[Category:Ramsey theory]]
[[Category:Theorems in discrete mathematics]]
[[Category:Articles containing proofs]]</text>
      <sha1>swsp8dhdrfolfoje4mly0pfa02lcv1d</sha1>
    </revision>
  </page>
  <page>
    <title>Uncomfortable science</title>
    <ns>0</ns>
    <id>416598</id>
    <revision>
      <id>805743775</id>
      <parentid>805741231</parentid>
      <timestamp>2017-10-17T10:37:07Z</timestamp>
      <contributor>
        <username>Trappist the monk</username>
        <id>10289486</id>
      </contributor>
      <minor/>
      <comment>/* Bibliography */ cite repair;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2665">'''Uncomfortable science''', as identified by [[statistician]] [[John Tukey]],&lt;ref&gt;{{Cite journal | doi = 10.1038/msb.2011.70| title = The self-assessment trap: Can we all be better than average?| journal = Molecular Systems Biology| volume = 7| year = 2011| last1 = Norel | first1 = R. | last2 = Rice | first2 = J. J. | last3 = Stolovitzky | first3 = G. | pages=537 | pmid=21988833 | pmc=3261704}}&lt;/ref&gt;&lt;ref&gt;{{cite book |editor=Hoaglin, D.C |title=Exploring Data Tables Trends and Shapes |publisher=Wiley |isbn=0-471-09776-4 |quote=Much of science also falls under John Tukey's label "uncomfortable science," because real repetition is not feasible or practical. |display-editors=etal}}&lt;/ref&gt; comprises situations in which there is a need to draw an [[statistical inference|inference]] from a limited [[sample (statistics)|sample]] of [[data]], where further samples influenced by the same [[cause system]] will not be available. More specifically, it involves the analysis of a finite natural phenomenon for which it is difficult to overcome the problem of using a common sample of [[data]] for both [[exploratory data analysis]] and [[confirmatory data analysis]]. This leads to the danger of [[systematic bias]] through [[testing hypotheses suggested by the data]].

A typical example is [[Titius-Bode law|Bode's law]], which provides a simple numerical rule for the distances of the [[planet]]s in the [[solar system]] from the [[Sun]]. Once the rule has been derived, through the [[trial and error]] matching of various rules with the observed [[data]] (exploratory data analysis), there are not enough planets remaining for a rigorous and independent test of the [[hypothesis]] (confirmatory data analysis). We have exhausted the natural [[phenomenon|phenomena]]. The agreement between data and the numerical rule should be no surprise, as we have deliberately chosen the rule to match the data.  If we are concerned about what Bode's law tells us about the cause system of planetary distribution then we demand confirmation that will not be available until better information about other planetary systems becomes available.

==See also==
*[[Cosmic variance]] for an extreme example of this phenomenon
*[[Data mining]]

==Bibliography==
*{{cite book |last=Diaconis |first=P. |author-link=P. Diaconis |editor-last=Hoaglin |editor-first=D.C |chapter=Theories of data analysis: from magical thinking through classical statistics |title=Exploring Data Tables Trends and Shapes | publisher=Wiley | isbn=0-471-09776-4 |date=1985 |display-editors=etal}}

==References==
{{Reflist}}

[[Category:Philosophy of statistics]]
[[Category:Statistical hypothesis testing]]</text>
      <sha1>liitkwjjrjl9c75gdsr1vsct8fsq9da</sha1>
    </revision>
  </page>
  <page>
    <title>Unordered pair</title>
    <ns>0</ns>
    <id>1112432</id>
    <revision>
      <id>842508489</id>
      <parentid>757162360</parentid>
      <timestamp>2018-05-22T22:27:20Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Jean E. Rubin]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2901">In [[mathematics]], an '''unordered pair''' or '''pair set''' is a [[Set (mathematics)|set]] of the form {''a'',&amp;nbsp;''b''}, i.e. a set having two elements ''a'' and&amp;nbsp;''b'' with no particular relation between them. In contrast, an [[ordered pair]] (''a'',&amp;nbsp;''b'') has ''a'' as its first element and ''b'' as its second element. 

While the two elements of an ordered pair (''a'',&amp;nbsp;''b'') need not be distinct, modern authors only call {''a'',&amp;nbsp;''b''} an unordered pair if ''a''&amp;nbsp;≠&amp;nbsp;''b''.&lt;ref&gt;
{{Citation | last1=Düntsch | first1=Ivo | last2=Gediga | first2=Günther | title=Sets, Relations, Functions | publisher=Methodos | series=Primers Series | isbn=978-1-903280-00-3 | year=2000}}.&lt;/ref&gt;&lt;ref&gt;{{Citation | last1=Fraenkel | first1=Adolf | title=Einleitung in die Mengenlehre | publisher=[[Springer-Verlag]] | location=Berlin, New York | year=1928}}&lt;/ref&gt;&lt;ref&gt;{{Citation | last1=Roitman | first1=Judith | title=Introduction to modern set theory | publisher=[[John Wiley &amp; Sons]] | location=New York | isbn=978-0-471-63519-2 | year=1990}}.&lt;/ref&gt;&lt;ref&gt;{{Citation | last1=Schimmerling | first1=Ernest | title=Undergraduate set theory | year=2008 }}
&lt;/ref&gt;
But for a few authors a [[Singleton (mathematics)|singleton]] is also considered an unordered pair, although today, most would say that {a,a} is a [[multiset]]. It is typical to use the term unordered pair even in the situation where the elements a and b could be equal, as long as this equality has not yet been established.

A set with precisely two elements is also called a [[finite set|2-set]] or (rarely) a '''binary set'''.

An unordered pair is a [[finite set]]; its [[cardinality]] (number of elements) is 2 or (if the two elements are not distinct)&amp;nbsp;1.

In [[axiomatic set theory]], the existence of unordered pairs is required by an axiom, the [[axiom of pairing]].

More generally, an '''unordered '''''n'''''-tuple''' is a set of the form {''a''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''a''&lt;sub&gt;2&lt;/sub&gt;,...&amp;nbsp;''a&lt;sub&gt;n&lt;/sub&gt;''}.&lt;ref&gt;
{{Citation | last1=Hrbacek | first1=Karel | last2=Jech | first2=Thomas | author2-link=Thomas Jech | title=Introduction to set theory | publisher=Dekker | location=New York | edition=3rd | isbn=978-0-8247-7915-3 | year=1999}}.&lt;/ref&gt;&lt;ref&gt;{{Citation | last1=Rubin | first1=Jean E. |author1-link=Jean E. Rubin | title=Set theory for the mathematician | publisher=Holden-Day | year=1967}}&lt;/ref&gt;&lt;ref&gt;{{Citation | last1=Takeuti | first1=Gaisi | last2=Zaring | first2=Wilson M. | title=Introduction to axiomatic set theory | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Graduate Texts in Mathematics | year=1971}}&lt;/ref&gt;

==Notes==
{{reflist}}

==References==
* {{Citation | last1=Enderton | first1=Herbert | title=Elements of set theory | publisher=[[Academic Press]] | location=Boston, MA | isbn=978-0-12-238440-0 | year=1977}}.

[[Category:Basic concepts in set theory]]</text>
      <sha1>ntvllogm6xhrby35iy75sv9ajh24hfc</sha1>
    </revision>
  </page>
  <page>
    <title>Waldegrave problem</title>
    <ns>0</ns>
    <id>48545958</id>
    <revision>
      <id>755076180</id>
      <parentid>717845053</parentid>
      <timestamp>2016-12-16T02:32:09Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Moving category Named probability problems to [[:Category:Probability problems]] per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2016 November 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1716">In [[probability]] and [[game theory]], the '''Waldegrave problem''' refers to a problem first described in the second edition of [[Pierre Raymond de Montmort|Montmort]]`s ''[[Essay d'analyse sur les jeux de hazard]]''. This problem is remarkable in that it is the first appearance to a mixed strategy solution in game theory. Montmort originally called Waldegrave’s Problem the ''Problème de la Poulle'' or the Problem of the Pool. He provides a [[minimax]] [[mixed strategy]] solution to a two-person version of the card game [[le Her]]. It was Isaac Todhunter who called it Waldegrave’s Problem. The general description of the problem is as follows: Suppose there are n+1 players with each player putting one unit into the pot or pool. The first two players play each other and the winner plays the third player. The loser of each game puts one unit into the pot. Play continues in like fashion through all the players until one of the players has beaten all the others in succession. The original problem, stated in a letter dated 10 April, 1711, from Montmort to [[Nicolaus I Bernoulli|Nicholas Bernoulli]] is for n = 2 and is attributed to ''M. de Waldegrave''. The problem, according to Montmort, is to find the expectation of each player and the probability that the pool will be won within a specified number of games.{{sfn|Bellhouse|2007|p=}}

==References==
{{reflist|20em}}

==Sources==
*{{citation|last=Bellhouse|first=David |title=The Problem of Waldegrave |journal=Electronic Journal for History of Probability and Statistics| volume=3| issue=2| year=2007| url=http://www.jehps.net/Decembre2007/Bellhouse.pdf}}

[[Category:Game theory]]
[[Category:Probability problems]]

{{mathematics-lit-stub}}</text>
      <sha1>nf5w1luvsbktfoxm4uvalhwhlkqdjuh</sha1>
    </revision>
  </page>
  <page>
    <title>Π-calculus</title>
    <ns>0</ns>
    <id>420373</id>
    <revision>
      <id>871673416</id>
      <parentid>870246409</parentid>
      <timestamp>2018-12-02T18:27:24Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <comment>converting {{tau}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30555">{{DISPLAYTITLE:{{pi}}-calculus}}
In [[theoretical computer science]], the '''{{pi}}-calculus''' (or '''pi-calculus''') is a [[process calculus]]. The {{pi}}-calculus allows channel names to be communicated along the channels themselves, and in this way it is able to describe [[concurrent computation]]s whose network configuration may change during the computation.

The {{pi}}-calculus is simple, it has very few terms and so is a very small language {{crossreference|selfref=no|(see [[#Syntax]])}}, yet is very expressive. Functional programs can be encoded into the {{pi}}-calculus, and the encoding emphasises the dialogue nature of computation, drawing connections with [[game semantics]]. Extensions of the {{pi}}-calculus, such as the spi calculus and applied {{pi}}, have been successful in reasoning about [[cryptographic protocol]]s. Beside the original use in describing concurrent systems, the {{pi}}-calculus has also been used to reason about [[business process]]es&lt;ref name="omg"&gt;OMG Specification (2011). [http://www.omg.org/spec/BPMN/2.0 "Business Process Model and Notation (BPMN) Version 2.0"], [https://en.wikipedia.org/wiki/Object_Management_Group ''Object Management Group'']. p.21&lt;/ref&gt; and [[molecular biology]].&lt;ref name="reeve" /&gt;

== Informal definition ==
The {{pi}}-calculus belongs to the family of [[process calculi]], mathematical formalisms for describing and analyzing properties of concurrent computation. In fact, the {{pi}}-calculus, like the [[lambda calculus|λ-calculus]], is so minimal that it does not contain primitives such as numbers, booleans, data structures, variables, functions, or even the usual control flow statements (such as &lt;code&gt;if-then-else&lt;/code&gt;, &lt;code&gt;while&lt;/code&gt;).

=== Process constructs ===

Central to the {{pi}}-calculus is the notion of ''name''. The simplicity of the calculus lies in the dual role that names play as ''communication channels'' and ''variables''.

The process constructs available in the calculus are the following&lt;ref&gt;{{Cite web|url=http://www.cs.tufts.edu/~nr/cs257/archive/jeannette-wing/pi.pdf|title=FAQ on π-Calculus|last=Wing|first=Jeannette M.|date=27 December 2002|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; (a precise definition is given in the following section):

* ''concurrency'', written &lt;math&gt;P \mid Q&lt;/math&gt;, where &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;Q&lt;/math&gt; are two processes or threads executed concurrently.
* ''communication'', where
** ''input prefixing'' &lt;math&gt;c\left(x\right).P&lt;/math&gt; is a process waiting for a message that was sent on a communication channel named &lt;math&gt;c&lt;/math&gt; before proceeding as {{nowrap|&lt;math&gt;P&lt;/math&gt;,}} binding the name received to the name {{nowrap|{{mvar|x}}.}} Typically, this models either a process expecting a communication from the network or a label &lt;code&gt;c&lt;/code&gt; usable only once by a &lt;code&gt;goto c&lt;/code&gt; operation.
** ''output prefixing''  &lt;math&gt;\overline{c} \langle y \rangle.P&lt;/math&gt; describes that the name &lt;math&gt;y&lt;/math&gt; is emitted on channel &lt;math&gt;c&lt;/math&gt; before proceeding as {{nowrap|&lt;math&gt;P&lt;/math&gt;.}} Typically, this models either sending a message on the network or a &lt;code&gt;goto c&lt;/code&gt; operation.
* ''replication'', written &lt;math&gt;!\,P&lt;/math&gt;, which may be seen as a process which can always create a new copy of {{nowrap|&lt;math&gt;P&lt;/math&gt;.}} Typically, this models either a network service or a label &lt;code&gt;c&lt;/code&gt; waiting for any number of &lt;code&gt;goto c&lt;/code&gt; operations.
* ''creation of a new name'', written &lt;math&gt;\left(\nu x\right)P&lt;/math&gt;, which may be seen as a process allocating a new constant {{mvar|x}} within {{nowrap|&lt;math&gt;P&lt;/math&gt;.}} The constants of {{nowrap|{{pi}}-calculus}} are defined by their names only and are always communication channels. Creation of a new name in a process is also called ''restriction''.
* the nil process, written &lt;math&gt;0&lt;/math&gt;, is a process whose execution is complete and has stopped.

Although the minimalism of the {{pi}}-calculus prevents us from writing programs in the normal sense, it is easy to extend the calculus. In particular, it is easy to define both control structures such as recursion, loops and sequential composition and datatypes such as first-order functions, [[truth value]]s, lists and integers. Moreover, extensions of the {{nowrap|{{pi}}-calculus}} have been proposed which take into account distribution or public-key cryptography. The ''applied {{nowrap|{{pi}}-calculus}}'' due to Abadi and Fournet [http://www.cse.ucsc.edu/~abadi/Papers/isss02.pdf] put these various extensions on a formal footing by extending the {{nowrap|{{pi}}-calculus}} with arbitrary datatypes.

=== A small example ===

Below is a tiny example of a process which consists of three parallel components. The channel name {{mvar|x}} is only known by the first two components.

:&lt;math&gt;
\begin{align}

    &amp;  \begin{align}
                (\nu x) \; &amp; ( \; \overline{x} \langle z \rangle . \; 0 \\
                           &amp; | \; x(y). \; \overline{y}\langle x \rangle . \; x(y). \; 0 \; )
        \end{align} \\
| \; &amp; z(v) . \; \overline{v}\langle v \rangle . 0

\end{align}
&lt;/math&gt;

The first two components are able to communicate on the channel {{mvar|x}}, and the name &lt;math&gt;y&lt;/math&gt; becomes bound to &lt;math&gt;z&lt;/math&gt;. The next step in the process is therefore

:&lt;math&gt;
\begin{align}

  &amp; \begin{align}
      ( \nu x) \; ( \; &amp; 0 \\
                  | \; &amp; \overline{z} \langle x \rangle . \; x(y). \; 0 \; )
    \end{align}

  \\

| \; &amp; z(v). \; \overline{v}\langle v \rangle . \; 0

\end{align}
&lt;/math&gt;

Note that the remaining &lt;math&gt;y&lt;/math&gt; is not affected because it is defined in an inner scope.
The second and third parallel components can now communicate on the channel name &lt;math&gt;z&lt;/math&gt;, and the name &lt;math&gt;v&lt;/math&gt; becomes bound to {{mvar|x}}. The next step in the process is now

:&lt;math&gt;
\begin{align}

 (\nu x)        ( \; &amp; 0 \\
                | \; &amp; x(y). \; 0  \\
                | \; &amp; \overline{x}\langle x \rangle . \; 0 \; )

\end{align}
&lt;/math&gt;

Note that since the local name {{mvar|x}} has been output, the scope of {{mvar|x}} is extended to cover the third component as well. Finally, the channel {{mvar|x}} can be used for sending the name {{mvar|x}}. After that all concurrently executing processes have stopped

:&lt;math&gt;
\begin{align}

 (\nu x)        ( \; &amp; 0 \\
                | \; 0  \\
                | \; 0 \; )

\end{align}
&lt;/math&gt;

== Formal definition ==

=== Syntax ===

Let Χ be a set of objects called ''names''. The [[abstract syntax]] for the {{pi}}-calculus is built from the following [[BNF grammar]] (where ''x'' and ''y'' are any names from Χ):&lt;ref&gt;[http://www.lfcs.inf.ed.ac.uk/reports/89/ECS-LFCS-89-85/ A Calculus of Mobile Processes part 1] page 10, by R. Milner, J. Parrow and D. Walker published in Information and Computation 100(1) pp.1-40, Sept 1992&lt;/ref&gt;

:&lt;math&gt;
\begin{align}
P, Q, R ::= \, &amp; x(y).P \,\,\, \, \, &amp; \text{Receive on channel }x\text{, bind the result to }y\text{, then run }P \\
|\,\,\, &amp; \overline{x} \langle y \rangle.P \,\,\, \, \, &amp;\text{Send the value }y\text{ over channel }x\text{, then run }P \\
|\,\,\, &amp; P|Q \,\,\, \, \, \, \, \, \, &amp;\text{Run }P\text{ and }Q\text{ simultaneously} \\
|\,\,\, &amp; (\nu x)P  \,\,\, &amp;\text{Create a new channel }x\text{ and run }P \\
|\,\,\, &amp; !P \,\,\, &amp;\text{Repeatedly spawn copies of }P \\
|\,\,\, &amp; 0 &amp; \text{Terminate the process}
\end{align}
&lt;/math&gt;

In the concrete syntax below, the prefixes bind more tightly than the parallel composition (|), and parentheses are used to disambiguate.

Names are bound by the restriction and input prefix constructs. Formally, the set of free names of a process in {{pi}}–calculus are defined inductively by the table below. The set of bound names of a process are defined as the names of a process that are not in the set of free names.
{| class="wikitable" style="width: 100%;"
! Construct
! Free names
|-
| &lt;math&gt;0&lt;/math&gt;
| None
|-
| &lt;math&gt;\overline{a} \langle x \rangle.P&lt;/math&gt;
| ''a''; ''x''; all free names of ''P''
|-
| &lt;math&gt;a(x).P&lt;/math&gt;
| ''a''; free names of ''P'' except for ''x''
|-
| &lt;math&gt;P|Q&lt;/math&gt;
| All free names of ''P'' and ''Q''
|-
| &lt;math&gt;(\nu x).P&lt;/math&gt;
| Free names of ''P'' except for ''x''
|-
| &lt;math&gt;!P&lt;/math&gt;
| All free names of ''P''
|}

=== Structural congruence ===

Central to both the reduction semantics and the labelled transition semantics is the notion of '''structural congruence'''. Two processes are structurally congruent, if they are identical up to structure. In particular, parallel composition is commutative and associative.

More precisely, structural congruence is defined as the least equivalence relation preserved by the process constructs and satisfying:

''Alpha-conversion'':

:* &lt;math&gt;P \equiv Q&lt;/math&gt; if &lt;math&gt;Q&lt;/math&gt; can be obtained from &lt;math&gt;P&lt;/math&gt; by renaming one or more bound names in &lt;math&gt;P&lt;/math&gt;.

''Axioms for parallel composition'':

:* &lt;math&gt;P|Q \equiv Q|P&lt;/math&gt;
:* &lt;math&gt;(P|Q)|R \equiv P|(Q|R)&lt;/math&gt;
:*&lt;math&gt;P | 0 \equiv P&lt;/math&gt;

''Axioms for restriction'':

:* &lt;math&gt;(\nu x)(\nu y)P \equiv (\nu y)(\nu x)P&lt;/math&gt;
:* &lt;math&gt;(\nu x)0 \equiv 0&lt;/math&gt;

''Axiom for replication'':

:* &lt;math&gt;!P \equiv P|!P&lt;/math&gt;

''Axiom relating restriction and parallel'':

:* &lt;math&gt;(\nu x)(P | Q) \equiv (\nu x)P | Q &lt;/math&gt; if {{mvar|x}} is not a free name of &lt;math&gt;Q&lt;/math&gt;.

This last axiom is known as the "scope extension" axiom. This axiom is central, since it describes how a bound name {{mvar|x}} may be extruded by an output action, causing the scope of {{mvar|x}} to be extended. In cases where {{mvar|x}} is a free name of &lt;math&gt;Q&lt;/math&gt;, alpha-conversion may be used to allow extension to proceed.

=== Reduction semantics ===

We write &lt;math&gt;P \rightarrow P'&lt;/math&gt; if &lt;math&gt;P&lt;/math&gt; can perform a computation step, following which it is now &lt;math&gt;P'&lt;/math&gt;.
This ''reduction relation'' &lt;math&gt;\rightarrow&lt;/math&gt; is defined as the least relation closed under a set of reduction rules.

The main reduction rule which captures the ability of processes to communicate through channels is the following:
* &lt;math&gt;\overline{x}\langle z \rangle.P | x(y).Q \rightarrow P | Q[z/y] &lt;/math&gt;
: where &lt;math&gt;Q[z/y]&lt;/math&gt; denotes the process &lt;math&gt;Q&lt;/math&gt; in which the free name &lt;math&gt;z&lt;/math&gt; has been ''substituted'' for the free occurrences of &lt;math&gt;y&lt;/math&gt;. If a free occurrence of &lt;math&gt;y&lt;/math&gt; occurs in a location where &lt;math&gt;z&lt;/math&gt; would not be free, alpha-conversion may be required.

There are three additional rules:
* If &lt;math&gt;P \rightarrow Q&lt;/math&gt; then also &lt;math&gt;P|R \rightarrow Q|R&lt;/math&gt;.
: This rule says that parallel composition does not inhibit computation.
* If &lt;math&gt;P \rightarrow Q&lt;/math&gt;, then also &lt;math&gt;(\nu x)P \rightarrow (\nu x)Q&lt;/math&gt;.
: This rule ensures that computation can proceed underneath a restriction.
* If &lt;math&gt;P \equiv P'&lt;/math&gt; and &lt;math&gt;P' \rightarrow Q'&lt;/math&gt; and &lt;math&gt;Q' \equiv Q&lt;/math&gt;, then also &lt;math&gt;P \rightarrow Q&lt;/math&gt;.

The latter rule states that processes that are structurally congruent have the same reductions.

=== The example revisited ===

Consider again the process

:&lt;math&gt; (\nu x)(\overline{x} \langle z \rangle.0  |  x(y).   \overline{y}\langle x \rangle . x(y).0 ) | z(v) . \overline{v}\langle v \rangle. 0 &lt;/math&gt;

Applying the definition of the reduction semantics, we get the reduction

:&lt;math&gt; (\nu x)(\overline{x} \langle z \rangle.0  |  x(y).   \overline{y}\langle x \rangle . x(y).0 ) | z(v) . \overline{v}\langle v \rangle. 0  \rightarrow (\nu x)(0|  \overline{z}\langle x \rangle . x(y). 0 ) | z(v). \overline{v}\langle v \rangle .0 &lt;/math&gt;

Note how, applying the reduction substitution axiom, free occurrences of &lt;math&gt;y&lt;/math&gt; are now labeled as &lt;math&gt;z&lt;/math&gt;.

Next, we get the reduction

:&lt;math&gt; (\nu x)(0|  \overline{z}\langle x \rangle . x(y). 0 ) | z(v). \overline{v}\langle v \rangle .0 \rightarrow (\nu x)(0|  x(y). 0  | \overline{x}\langle x \rangle .0)  &lt;/math&gt;

Note that since the local name {{mvar|x}} has been output, the scope of {{mvar|x}} is extended to cover the third component as well.  This was captured using the scope extension axiom.

Next, using the reduction substitution axiom, we get

:&lt;math&gt; (\nu x)(0 | 0 | 0) &lt;/math&gt;

Finally, using the axioms for parallel composition and restriction, we get

:&lt;math&gt; 0 &lt;/math&gt;

=== Labelled semantics ===

Alternatively, one may give the pi-calculus a labelled transition semantics (as has been done with the [[Calculus of Communicating Systems]]). Transitions in this semantics are of the form:
{{NumBlk|:|&lt;math&gt;
P\,\xrightarrow{\overset{}\alpha} P'
&lt;/math&gt;|{{EquationRef|1}}}}
This [[State transition system|notation]] signifies that &lt;math&gt;P&lt;/math&gt; after the action &lt;math&gt;\alpha&lt;/math&gt; becomes &lt;math&gt;P'&lt;/math&gt;. &lt;math&gt;\alpha&lt;/math&gt; can be an ''input action'' &lt;math&gt;a(x)&lt;/math&gt;, an ''output action'' ''&lt;math&gt;\overline{a}\langle x \rangle&lt;/math&gt;'', or a tau-action {{mvar|&amp;tau;}} corresponding to an internal communication.

A standard result about the labelled semantics is that it agrees with the reduction semantics in the sense that 
&lt;math&gt;P \rightarrow P'&lt;/math&gt; if and only if 
&lt;math&gt;P\,\xrightarrow{\overset{}\tau} P'&lt;/math&gt; for some action &amp;tau;.

== Extensions and variants ==

The syntax given above is a minimal one. However, the syntax may be modified in various ways.

A ''nondeterministic choice operator'' &lt;math&gt;P + Q&lt;/math&gt; can be added to the syntax.

A test for ''name equality'' &lt;math&gt;[x=y]P&lt;/math&gt; can be added to the syntax. This ''match operator'' can proceed as &lt;math&gt;P&lt;/math&gt; if and only if {{mvar|x}} and &lt;math&gt;y&lt;/math&gt; are the same name.
Similarly, one may add a ''mismatch operator'' for '''name inequality'''. Practical programs which can pass names (URLs or pointers) often use such functionality: for directly modelling such functionality inside the calculus, this and related extensions are often useful.

The ''asynchronous {{pi}}-calculus''&lt;ref&gt;{{cite book|last1=Boudol|first1=G.|title=Asynchrony and the {{pi}}-calculus. Techical Report 1702, INRIA, Sophia-Antipolis| date=1992}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Honda |first1=K. | last2=Tokoro | first2=M. |title=An Object Calculus for Asynchronous Communication. ECOOP 91|publisher=Springer Verlag| date=1991}}&lt;/ref&gt;
allows only outputs with no suffix, i.e. output atoms of the form &lt;math&gt;\overline{x}\langle y \rangle&lt;/math&gt;, yielding a smaller calculus. However, any process in the original calculus can be represented by the smaller asynchronous {{pi}}-calculus using an extra channel to simulate explicit acknowledgement from the receiving process. Since a continuation-free output can model a message-in-transit, this fragment shows that the original {{pi}}-calculus, which is intuitively based on synchronous communication, has an expressive asynchronous communication model inside its syntax. However, the nondeterministic choice operator defined above cannot be expressed in this way, as an [[guard (computer science)|unguarded]] choice would be converted into a guarded one; this fact has been used to demonstrate that the asynchronous calculus is strictly less expressive than the synchronous one (with the choice operator).&lt;ref&gt;{{cite journal|last=Palamidessi|first=Catuscia|title=Comparing the expressive power of the Synchronous and the Asynchronous pi-calculus|journal=Proceedings of the 24th ACM Symposium on Principles of Programming Languages|year=1997|pages=256–265|arxiv=cs/9809008|accessdate=|bibcode=1998cs........9008P}}&lt;/ref&gt;

The ''polyadic {{pi}}-calculus'' allows communicating more than one name in a single action: &lt;math&gt;\overline{x}\langle z_1,...,z_n\rangle.P&lt;/math&gt; ''(polyadic output)'' and &lt;math&gt;x(z_1,...,z_n).P&lt;/math&gt; ''(polyadic input)''. This polyadic extension, which is useful especially when studying types for name passing processes,  can be encoded in the monadic calculus by passing the name of a private channel through which the multiple arguments are then passed in sequence. The encoding is defined recursively by the clauses

&lt;math&gt;\overline{x}\langle y_1,\cdots,y_n\rangle.P&lt;/math&gt; is encoded as &lt;math&gt;(\nu w) \overline{x}\langle w \rangle.\overline{w}\langle y_1\rangle.\cdots.\overline{w}\langle y_n\rangle.[P]&lt;/math&gt;

&lt;math&gt;x(y_1,\cdots,y_n).P&lt;/math&gt; is encoded as &lt;math&gt;x(w).w(y_1).\cdots.w(y_n).[P]&lt;/math&gt;

All other process constructs are left unchanged by the encoding.

In the above, &lt;math&gt;[P]&lt;/math&gt; denotes the encoding of all prefixes in the continuation &lt;math&gt;P&lt;/math&gt; in the same way.

The full power of replication &lt;math&gt;!P&lt;/math&gt; is not needed. Often, one only considers ''replicated input'' &lt;math&gt;! x(y).P&lt;/math&gt;, whose structural congruence axiom is &lt;math&gt;! x(y).P \equiv x(y).P | !x(y).P&lt;/math&gt;.

Replicated input process such as &lt;math&gt; !x(y).P&lt;/math&gt; can be understood as servers, waiting on channel
{{mvar|x}} to be invoked by clients. Invocation of a server spawns a new copy of
the process &lt;math&gt;P[a/y]&lt;/math&gt;, where a is the name passed by the client to the
server, during the latter's invocation.

A ''higher order {{pi}}-calculus'' can be defined where not only names but processes are sent through channels.
The key reduction rule for the higher order case is

&lt;math&gt;\overline{x}\langle R \rangle.P | x(Y).Q \rightarrow P | Q[R/Y] &lt;/math&gt;

Here, &lt;math&gt;Y&lt;/math&gt; denotes a ''process variable'' which can be instantiated by a process term. Sangiorgi
established that the ability to pass processes does not
increase the expressivity of the {{pi}}-calculus: passing a process ''P'' can be
simulated by just passing a name that points to ''P'' instead.

== Properties ==

=== Turing completeness ===

The {{pi}}-calculus is a [[Turing complete|universal model of computation]]. This was first observed by Milner in his paper "Functions as Processes",&lt;ref&gt;{{cite journal|last=Milner|first=Robin|title=Functions as Processes|journal=Mathematical Structures in Computer Science|pages=119–141|year=1992|volume=2|doi=10.1017/s0960129500001407|url=http://hal.archives-ouvertes.fr/docs/00/07/54/05/PDF/RR-1154.pdf}}&lt;/ref&gt; in which he presents two encodings of the [[lambda-calculus]] in the {{pi}}-calculus. One encoding simulates the eager (call-by-value) [[evaluation strategy]], the other encoding simulates the normal-order (call-by-name) strategy. In both of these, the crucial insight is the modeling of environment bindings – for instance, "{{mvar|x}} is bound to term &lt;math&gt;M&lt;/math&gt;" – as replicating agents that respond to requests for their bindings by sending back a connection to the term &lt;math&gt;M&lt;/math&gt;.

The features of the {{pi}}-calculus that make these encodings possible are name-passing and replication (or, equivalently, recursively defined agents). In the absence of replication/recursion, the {{pi}}-calculus ceases to be [[Turing]]-powerful. This can be seen by the fact that [[bisimulation]] equivalence becomes decidable for the recursion-free calculus and even for the finite-control {{pi}}-calculus where the number of parallel components in any process is bounded by a constant.&lt;ref&gt;{{cite journal|last=Dam|first=Mads|title=On the Decidability of Process Equivalences for the pi-Calculus|journal=Theoretical Computer Science|issue=183|pages=215–228|year=1997|volume=183|doi=10.1016/S0304-3975(96)00325-8}}&lt;/ref&gt;

== Bisimulations in the {{pi}}-calculus ==

{{See also|Bisimulation}}

As for process calculi, the {{pi}}-calculus allows for a definition of bisimulation equivalence. In the {{pi}}-calculus, the definition of bisimulation equivalence (also known as bisimilarity) may be based on either the reduction semantics or on the labelled transition semantics.

There are (at least) three different ways of defining ''labelled bisimulation equivalence'' in the {{pi}}-calculus: Early, late and open bisimilarity. This stems from the fact that the {{pi}}-calculus is a value-passing process calculus.

In the remainder of this section, we let &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; denote processes and &lt;math&gt;R&lt;/math&gt; denote binary relations over processes.

=== Early and late bisimilarity ===

Early and late bisimilarity were both formulated by Milner, Parrow and Walker in their original paper on the {{pi}}-calculus.&lt;ref&gt;{{cite journal|last=Milner|first=R.|author2=J. Parrow |author3= D. Walker|title=A calculus of mobile processes|journal=Information and Computation|issue=1|pages=1–40|year=1992|doi=10.1016/0890-5401(92)90008-4|volume=100}}&lt;/ref&gt;

A binary relation &lt;math&gt;R&lt;/math&gt; over processes is an ''early bisimulation'' if for every pair of processes &lt;math&gt;(p, q) \in R&lt;/math&gt;,
* whenever &lt;math&gt;
p \,\xrightarrow{a(x)}\,p'
&lt;/math&gt; then for every name &lt;math&gt;y&lt;/math&gt; there exists some &lt;math&gt;q'&lt;/math&gt; such that &lt;math&gt;
q \,\xrightarrow{a(x)}\,q'
&lt;/math&gt; and &lt;math&gt;(p'[y/x],q'[y/x]) \in R&lt;/math&gt;;
* for any non-input action &lt;math&gt;\alpha&lt;/math&gt;, if &lt;math&gt;{
p \xrightarrow{\overset{}{\alpha}}  p'
}  &lt;/math&gt; then there exists some &lt;math&gt;q'&lt;/math&gt; such that &lt;math&gt;
q \xrightarrow{\overset{}{\alpha}} q'
  &lt;/math&gt; and &lt;math&gt;(p',q') \in R&lt;/math&gt;;
* and symmetric requirements with &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; interchanged.

Processes &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; are said to be early bisimilar, written &lt;math&gt;p \sim_e q&lt;/math&gt; if the pair &lt;math&gt;(p,q) \in R&lt;/math&gt; for some early bisimulation &lt;math&gt;R&lt;/math&gt;.

In late bisimilarity, the transition match must be independent of the name being transmitted.
A binary relation &lt;math&gt;R&lt;/math&gt; over processes is a ''late bisimulation'' if for every pair of processes &lt;math&gt;(p, q) \in R&lt;/math&gt;,
* whenever &lt;math&gt;
p \xrightarrow{a(x)}  p'
&lt;/math&gt; then for some &lt;math&gt;q'&lt;/math&gt; it holds that &lt;math&gt;
q \xrightarrow{a(x)} q'
&lt;/math&gt; and &lt;math&gt;(p'[y/x],q'[y/x]) \in R&lt;/math&gt; ''for every name y'';
*for any non-input action &lt;math&gt;\alpha&lt;/math&gt;, if &lt;math&gt;
p \xrightarrow{\overset{}{\alpha}} p'
  &lt;/math&gt; implies that there exists some &lt;math&gt;q'&lt;/math&gt; such that &lt;math&gt;
q \xrightarrow{\overset{}{\alpha}} q'
  &lt;/math&gt;and &lt;math&gt;(p',q') \in R&lt;/math&gt;;
* and symmetric requirements with &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; interchanged.
Processes &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; are said to be late bisimilar, written &lt;math&gt;p \sim_l q&lt;/math&gt; if the pair &lt;math&gt;(p,q) \in R&lt;/math&gt; for some late bisimulation &lt;math&gt;R&lt;/math&gt;.

Both &lt;math&gt;\sim_e&lt;/math&gt; and &lt;math&gt;\sim_l&lt;/math&gt; suffer from the problem that they are not ''congruence relations'' in the sense that they are not preserved by all process constructs. More precisely, there exist processes &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; such that &lt;math&gt;p \sim_e q&lt;/math&gt; but &lt;math&gt;a(x).p \not \sim_e a(x).q&lt;/math&gt;. One may remedy this problem by considering the maximal congruence relations included in &lt;math&gt;\sim_e&lt;/math&gt; and &lt;math&gt;\sim_l&lt;/math&gt;, known as ''early congruence'' and ''late congruence'', respectively.

=== Open bisimilarity ===

Fortunately, a third definition is possible, which avoids this problem, namely that of ''open bisimilarity'', due to Sangiorgi.&lt;ref&gt;{{cite journal|last=Sangiorgi|first=D.|title=A theory of bisimulation for the π-calculus|journal=Acta Informatica|volume=33|pages=69–97|year=1996|doi=10.1007/s002360050036}}&lt;/ref&gt;

A binary relation &lt;math&gt;R&lt;/math&gt; over processes is an ''open bisimulation'' if for every pair of elements &lt;math&gt;(p, q) \in R&lt;/math&gt; and for every name substitution &lt;math&gt;\sigma&lt;/math&gt; and every action &lt;math&gt;\alpha&lt;/math&gt;, whenever &lt;math&gt;
p\sigma \xrightarrow{\overset{}{\alpha}}  p'&lt;/math&gt; then there exists some &lt;math&gt;q'&lt;/math&gt; such that &lt;math&gt;
q\sigma  \xrightarrow{\overset{}{\alpha}} q'
  &lt;/math&gt; and &lt;math&gt;(p',q') \in R&lt;/math&gt;.

Processes &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; are said to be open bisimilar, written &lt;math&gt;p \sim_o q&lt;/math&gt; if the pair &lt;math&gt;(p,q) \in R&lt;/math&gt; for some open bisimulation &lt;math&gt;R&lt;/math&gt;.

==== Early, late and open bisimilarity are distinct ====

Early, late and open bisimilarity are distinct. The containments are proper, so &lt;math&gt;\sim_o \subsetneq \sim_l \subsetneq \sim_e&lt;/math&gt;.

In certain subcalculi such as the asynchronous pi-calculus, late, early and open bisimilarity are known to coincide. However, in this setting a more appropriate notion is that of ''asynchronous bisimilarity''.

The reader should note that, in the literature, the term ''open bisimulation'' usually refers to a more sophisticated notion, where processes and relations are indexed by distinction relations; details are in Sangiorgi's paper cited above.

=== Barbed equivalence ===

Alternatively, one may define bisimulation equivalence directly from the reduction semantics. We write &lt;math&gt;p \Downarrow a&lt;/math&gt; if process &lt;math&gt;p&lt;/math&gt; immediately allows an input or an output on name &lt;math&gt;a&lt;/math&gt;.

A binary relation &lt;math&gt;R&lt;/math&gt; over processes is a ''barbed bisimulation'' if it is a symmetric relation which satisfies that for every pair of elements &lt;math&gt;(p, q) \in R&lt;/math&gt; we have that

:(1) &lt;math&gt;p \Downarrow a&lt;/math&gt; if and only if &lt;math&gt;q \Downarrow a&lt;/math&gt; for every name &lt;math&gt;a&lt;/math&gt;

and

:(2) for every reduction &lt;math&gt; p \rightarrow p'&lt;/math&gt; there exists a reduction &lt;math&gt; q \rightarrow  q' &lt;/math&gt;

such that &lt;math&gt;(p',q') \in R&lt;/math&gt;.

We say that &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; are ''barbed bisimilar'' if there exists a barbed bisimulation &lt;math&gt;R&lt;/math&gt; where &lt;math&gt;(p,q) \in R&lt;/math&gt;.

Defining a context as a {{pi}} term with a hole [] we say that two processes P and Q are ''barbed congruent'', written &lt;math&gt;P \sim_b Q\,\!&lt;/math&gt;, if for every context &lt;math&gt;C[] &lt;/math&gt; we have that &lt;math&gt;C[P]&lt;/math&gt; and &lt;math&gt;C[Q]&lt;/math&gt; are barbed bisimilar. It turns out that barbed congruence coincides with the congruence induced by early bisimilarity.

== Applications ==&lt;!-- This section is linked from [[SPI]] --&gt;

The {{pi}}-calculus has been used to describe many different kinds of concurrent systems. In fact, some of the most recent applications lie outside the realm of traditional computer science.

In 1997, [[Martin Abadi]] and Andrew Gordon proposed an extension of the {{pi}}-calculus, the [[Spi-calculus]], as a formal notation for describing and reasoning about cryptographic protocols. The spi-calculus extends the {{pi}}-calculus with primitives for encryption and decryption. In 2001, [[Martin Abadi]] and Cedric Fournet generalised the handling of cryptographic protocols to produce the applied {{pi}} calculus. There is now a large body of work devoted to variants of the applied {{pi}} calculus, including a number of experimental verification tools. One example is the tool [[ProVerif]] [http://www.proverif.ens.fr/] due to [[Bruno Blanchet]], based on a translation of the applied {{pi}}-calculus into Blanchet's logic programming framework. Another example is Cryptyc [http://www.cryptyc.org], due to Andrew Gordon and Alan Jeffrey, which uses Woo and Lam's method of correspondence assertions as the basis for type systems that can check for authentication properties of cryptographic protocols.

Around 2002, Howard Smith and [[Peter Fingar]] became interested that {{pi}}-calculus would become a description tool for modelling business processes. By July 2006, there is discussion in the community about how useful this would be. Most recently, the {{pi}}-calculus has formed the theoretical basis of [[Business Process Modeling Language]] (BPML), and of Microsoft's XLANG.&lt;ref&gt;[http://www.bpmi.org/downloads/BPML-BPEL4WS.pdf "BPML | BPEL4WS: A Convergence Path toward a Standard BPM Stack."] BPMI.org Position Paper. August 15, 2002.&lt;/ref&gt;

The {{pi}}-calculus has also attracted interest in molecular biology. In 1999, [[Aviv Regev]] and [[Ehud Shapiro]] showed that one can describe a cellular signaling pathway (the so-called [[Receptor tyrosine kinase|RTK]]/[[MAPK]] cascade)  and in particular the molecular "lego" which implements these tasks of communication in an extension of the {{pi}}-calculus.&lt;ref name="reeve"&gt;{{cite journal|first=Aviv|last=Regev|authorlink=Aviv Regev|author2=William Silverman |author3= Ehud Y. Shapiro|year=2001|title=Representation and Simulation of Biochemical Processes Using the pi-Calculus Process Algebra|journal=[[Pacific Symposium on Biocomputing]]|pages=459–470}}&lt;/ref&gt; Following this seminal paper, other authors described the whole metabolic network of a minimal cell.&lt;ref&gt;{{cite journal|first=Davide|last=Chiarugi|author2=Pierpaolo Degano |author3= Roberto Marangoni|year=2007|title=A computational approach to the functional screening of genomes|journal=[[PLOS Computational Biology]]|pages=1801–1806|url=http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.0030174}}&lt;/ref&gt;

== History ==
The {{pi}}-calculus was originally developed by [[Robin Milner]], Joachim Parrow and [[David Walker (computer scientist)|David Walker]] in 1992, based on ideas by Uffe Engberg and Mogens Nielsen. It can be seen as a continuation of Milner's work on the process calculus CCS ([[Calculus of Communicating Systems]]).  In his Turing lecture, Milner describes the development of the {{pi}}-calculus as an attempt to capture the uniformity of values and processes in actors.&lt;ref&gt;Robin Milner. 1993. Elements of interaction: Turing award lecture. Commun. ACM 36, 1 (January 1993), 78-89. DOI=10.1145/151233.151240 http://doi.acm.org/10.1145/151233.151240&lt;/ref&gt;

== Implementations ==

The following programming languages are implementations either of the {{pi}}-calculus or of its variants:

* [[Business Process Modeling Language]] (BPML)
* [[occam-π]]
* [[Pict programming language|Pict]]
* [[JoCaml]] (based on the [[Join-calculus]])

== Notes ==
{{Reflist}}

== References ==
* {{cite book|last=Milner|first=Robin|authorlink=Robin Milner|title=Communicating and Mobile Systems: The π-calculus|year=1999|publisher=Cambridge University Press|location=Cambridge, UK|isbn=0-521-65869-1}}
* {{cite book|last=Milner|first=Robin|authorlink=Robin Milner|editor=F. L. Hamer |editor2=W. Brauer |editor3=H. Schwichtenberg|title=Logic and Algebra of Specification|url=http://www.lfcs.inf.ed.ac.uk/reports/91/ECS-LFCS-91-180/ECS-LFCS-91-180.ps|year=1993|publisher=Springer-Verlag|chapter=The Polyadic π-Calculus: A Tutorial}}
* {{cite book|last1=Sangiorgi|first1=Davide|authorlink1=Davide Sangiorgi|last2=Walker|first2=David|authorlink2=David Walker (computer scientist)|title=The π-calculus: A Theory of Mobile Processes|year=2001|publisher=Cambridge University Press|location=Cambridge, UK|isbn=0-521-78177-9}}

== External links ==
* [http://c2.com/cgi/wiki?PiCalculus PiCalculus] on the C2 wiki
* [http://www.cs.tufts.edu/~nr/cs257/archive/jeannette-wing/pi.pdf FAQ on π-Calculus] by [[Jeannette M. Wing]]

{{DEFAULTSORT:Pi Calculus}}
[[Category:Process calculi]]
[[Category:Theoretical computer science]]</text>
      <sha1>hxz1xdbdf1j58ttviwdxynjw9ijvls4</sha1>
    </revision>
  </page>
</mediawiki>
