<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>179 (number)</title>
    <ns>0</ns>
    <id>2290298</id>
    <revision>
      <id>849557162</id>
      <parentid>849557131</parentid>
      <timestamp>2018-07-09T20:23:19Z</timestamp>
      <contributor>
        <username>Anaxial</username>
        <id>2273576</id>
      </contributor>
      <minor/>
      <comment>Reverted 2 edits by [[Special:Contributions/182.1.196.164|182.1.196.164]] ([[User talk:182.1.196.164|talk]]) to last revision by Dhrm77. using [[WP:TW|TW]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2013">{{Infobox number
| factorization = [[prime number|prime]]
| prime = 41st
| divisor = 1, 179
}}
'''179''' ('''one hundred [and] seventy-nine''') is the [[natural number]] following [[178 (number)|178]] and preceding [[180 (number)|180]].

==In mathematics==
179 is an [[odd number]].

179 is a [[prime number]]; that is, it is not divisible by integer (except for 1 and itself). It is an [[Eisenstein prime]], as it is indivisible even by complex [[Gaussian integer]]s. It is a [[Chen prime]], being [[twin prime|two less than]] another prime, [[181 (number)|181]]. It is a [[full reptend prime]], meaning 1/179 has a decimal expansion of a repeated sequence of 178 digits.

179 is a [[safe prime]], as it is one more than two times the prime [[89 (number)|89]]. It is also a [[Sophie Germain prime]], as the prime [[359 (number)|359]] is one more than two times 179. It is only the fifth number with both of these properties (after [[5 (number)|5]], [[11 (number)|11]], [[23 (number)|23]], and [[83 (number)|83]]).&lt;ref&gt;{{Cite web|url=https://oeis.org/A059455|title=Sloane's A059455 : Safe primes which are also Sophie Germain primes|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-28}}&lt;/ref&gt;

179 is a [[strictly non-palindromic number]]. It is not a [[palindromic number]] in any [[Number base|base]].

179 (of [[365 (number)|365]]) days of the year are [[Parity (mathematics)|even numbered]].

==See also==
* [[179|AD 179]] and [[179 BC]]
* [[List of highways numbered 179]]

==External links==
{{Commons category|179 (number)}}
* [http://athensohio.net/reference/number/179 Number Facts and Trivia: 179]
* [http://www.numdic.com/179 The Number 179]
* [http://www.positiveintegers.org/179 The Positive Integer 179]
* [http://primes.utm.edu/curios/page.php/179.html Prime curiosities: 179]
* [http://www.numbergossip.com/179 Number Gossip: 179]

== References ==
{{Reflist}}
{{Integers|1}}

{{DEFAULTSORT:179 (Number)}}
[[Category:Integers]]</text>
      <sha1>8hahl9rahsigcoyfljufm6g69cabvwb</sha1>
    </revision>
  </page>
  <page>
    <title>Antifundamental representation</title>
    <ns>0</ns>
    <id>695082</id>
    <revision>
      <id>745452018</id>
      <parentid>657524855</parentid>
      <timestamp>2016-10-21T06:24:40Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="717">{{context|date=August 2012}}
In [[mathematics]], an '''antifundamental representation''' of a [[Lie group]] is the complex conjugate of the [[fundamental representation]],&lt;ref&gt;{{citation|title=The Standard Model: A Primer|first1=Cliff|last1=Burgess|first2=Guy|last2=Moore|publisher=Cambridge University Press|isbn=9781139460460|page=492|url=https://books.google.com/books?id=PLYECqs2geEC&amp;pg=PA492}}.&lt;/ref&gt; although the distinction between the fundamental and the antifundamental representation is a matter of convention. However, these two are often non-equivalent, because each of them is a [[complex representation]].

==References==
{{reflist}}

[[Category:Representation theory of Lie groups]]


{{geometry-stub}}</text>
      <sha1>hn64vv1khnk17woszf2yx3mprcpypal</sha1>
    </revision>
  </page>
  <page>
    <title>Bell's theorem</title>
    <ns>0</ns>
    <id>56369</id>
    <revision>
      <id>869448567</id>
      <parentid>869443731</parentid>
      <timestamp>2018-11-18T18:00:22Z</timestamp>
      <contributor>
        <username>Dkapetansky</username>
        <id>19971731</id>
      </contributor>
      <minor/>
      <comment>/* Importance */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="75168">{{cleanup|reason= The article seems to have had too many local edits: it's a bit rambling, has unstable notation, and repeats itself many times.|date=May 2017}}
{{quantum|cTopic=Fundamentals}}
'''Bell's theorem''' is a "[[no-go theorem]]" that draws an important distinction between [[quantum mechanics]] and the world as described by [[classical mechanics]], particularly concerning ''[[quantum entanglement]]'' where two or more particles in a ''[[quantum state]]'' continue to be mutually dependent, even at large physical separations. This theorem is named after [[John Stewart Bell]].

A series of experiments has verified the theorem and showed that quantum entanglement occurs over large distances. 
Quantum entanglement has profound implications for the outcomes of measurements of quantum systems; for example, in ''[[quantum computing]]''.

In its simplest form, Bell's theorem states:&lt;ref name="C.B. Parker 1994 542"&gt;{{cite book | author = C.B. Parker | title = McGraw-Hill Encyclopaedia of Physics | edition = 2nd | page = 542 | year=  1994 | publisher = McGraw-Hill  | isbn = 978-0-07-051400-3 }}  Bell himself wrote: "If [a hidden variable theory] is local it will not agree with quantum mechanics, and if it agrees with quantum mechanics it will not be local.  This is what the theorem says."  John Bell, ''Speakable and Unspeakable in Quantum Mechanics'', Cambridge University Press, 1987, p. 65.&lt;/ref&gt;

{{quotation|No physical theory of [[Local hidden variable theory|local hidden variables]] can ever reproduce all of the predictions of quantum mechanics.}}

[[Cornell University|Cornell]] solid-state physicist [[David Mermin]] has described the appraisals of the importance of Bell's theorem in the physics community as ranging from "indifference" to "wild extravagance".&lt;ref&gt;{{cite journal|authorlink=David Mermin| first=David| last=Mermin| title=Is the moon there when nobody looks? Reality and the quantum theory|journal=Physics Today|date=April 1985|pages=38–47| doi = 10.1063/1.880968 | url=http://cp3.irmp.ucl.ac.be/~maltoni/PHY1222/mermin_moon.pdf|bibcode = 1985PhT....38d..38M| volume=38| issue=4}}&lt;/ref&gt; [[Lawrence Berkeley National Laboratory|Lawrence Berkeley]] particle physicist [[Henry Stapp]] declared: "Bell's theorem is the most profound discovery of science."&lt;ref&gt;{{cite journal|authorlink=Henry P. Stapp|first=Henry P.|last=Stapp|title=Bell's Theorem and World Process|journal=[[Nuovo Cimento]]|volume=29B|issue=2|pages=270–276|year=1975|doi=10.1007/BF02728310|ref=harv|bibcode = 1975NCimB..29..270S |url=http://www.escholarship.org/uc/item/7m59f6nz}} (Quote on p. 271)&lt;/ref&gt;

Bell's theorem rules out [[local hidden variable]]s as a viable explanation of quantum mechanics (though it still leaves the door open for non-local hidden variables, such as [[De Broglie–Bohm theory]], etc). Bell concluded:

{{quotation|In a theory in which parameters are added to quantum mechanics to determine the results of individual measurements, without changing the statistical predictions, there must be a mechanism whereby the setting of one measuring device can influence the reading of another instrument, however remote. Moreover, the signal involved must propagate instantaneously, so that such a theory could not be [[Lorentz invariance|Lorentz invariant]].&lt;ref name=Bell1964/&gt;}}

Bell summarized one of the least popular ways to address the theorem, [[superdeterminism]], in a 1985 BBC Radio interview:

{{quotation|There is a way to escape the inference of [[superluminal]] speeds and spooky action at a distance. But it involves absolute [[determinism]] in the universe, the complete absence of [[free will]]. Suppose the world is super-deterministic, with not just inanimate nature running on behind-the-scenes clockwork, but with our behavior, including our belief that we are free to choose to do one experiment rather than another, absolutely predetermined, including the 'decision' by the experimenter to carry out one set of measurements rather than another, the difficulty disappears. There is no need for a faster-than-light signal to tell particle ''A'' what measurement has been carried out on particle&amp;nbsp;''B'', because the universe, including particle&amp;nbsp;''A'', already 'knows' what that measurement, and its outcome, will be.&lt;ref&gt;The quotation is an adaptation from the edited transcript of the radio interview with John Bell of 1985. See [https://books.google.com/books?id=KHezRs7nsAgC&amp;redir_esc=y ''The Ghost in the Atom: A Discussion of the Mysteries of Quantum Physics''], by Paul C. W. Davies and Julian R. Brown, 1986/1993, [https://books.google.com/books?id=KHezRs7nsAgC&amp;q=%22Your+famous+result+that+we+all+know%22&amp;redir_esc=y#v=snippet&amp;q=%22Your%20famous%20result%20that%20we%20all%20know%22&amp;f=false pp. 45-46]&lt;/ref&gt;}}

[[File:Bell_theorem.png|thumb|300px|thumbtime=0|right|Example of simple Bell type inequality and its violation in quantum mechanics. Top: assuming any probability distribution among 8 possibilities for values of 3 binary variables ABC, we always get the above inequality. Bottom: example of its violation using quantum [[Born rule]]: probability is normalized square of amplitude.]]

== Historical background ==
In the early 1930s, the philosophical implications of the current interpretations of quantum theory troubled many prominent physicists of the day, including [[Albert Einstein]].  In a well-known 1935 paper, [[Boris Podolsky]] and co-authors Einstein and [[Nathan Rosen]] (collectively "EPR") sought to demonstrate by the [[EPR paradox]] that quantum mechanics was incomplete.  This provided hope that a more complete (and less troubling) theory might one day be discovered.  But that conclusion rested on the seemingly reasonable assumptions of ''locality'' and ''realism'' (together called "local realism" or "[[local hidden variables]]", often interchangeably). In the vernacular of Einstein: [[Principle of locality|locality]] meant no instantaneous [[quantum entanglement|("spooky") action at a distance]]; realism meant the moon is there even when not being observed. These assumptions were hotly debated in the physics community, notably [[Bohr–Einstein debates|between Einstein and Niels Bohr]].

In his groundbreaking 1964 paper, "On the Einstein Podolsky Rosen paradox",&lt;ref name=Bell1964/&gt;&lt;ref&gt;Reprinted in {{cite book |title=Speakable and Unspeakable in Quantum Mechanics: Collected Papers on Quantum Philosophy  |author=JS Bell |chapter=Chapter 2:On the Einstein-Podolsky-Rosen paradox |chapter-url=https://books.google.com/books?id=mwAhAwAAQBAJ&amp;pg=PT8 |isbn=978-0521523387  |year=2004 |publisher=Cambridge University Press |edition=Alain Aspect introduction to 1987 |pages=14–21}}&lt;/ref&gt; physicist [[John Stewart Bell]] presented an analogy (based on spin measurements on pairs of entangled electrons) to EPR's hypothetical paradox.  Using their reasoning, he said, a choice of measurement setting here should not affect the outcome of a measurement there (and vice versa).  After providing a mathematical formulation of locality and realism based on this, he showed specific cases where this would be inconsistent with the predictions of quantum mechanics theory.

In experimental tests following Bell's example, now using [[quantum entanglement]] of photons instead of electrons, [[John Clauser]] and [[Stuart Freedman]] (1972) and [[Alain Aspect]] ''et al''. (1981) demonstrated that the predictions of quantum mechanics are correct in this regard, although relying on additional unverifiable assumptions that open [[Loopholes in Bell test experiments|loopholes]] for local realism.

In October 2015, Hensen and co-workers&lt;ref name="ReferenceA"&gt;{{cite journal |doi = 10.1038/nature15759 | volume=526 | issue=7575 | title=Loophole-free Bell inequality violation using electron spins separated by 1.3 kilometres | journal=Nature | pages=682–686|bibcode = 2015Natur.526..682H |arxiv=1508.05949 | pmid=26503041 | last1 = Hensen | first1 = B | last2 = Bernien | first2 = H | last3 = Dréau | first3 = AE | last4 = Reiserer | first4 = A | last5 = Kalb | first5 = N | last6 = Blok | first6 = MS | last7 = Ruitenberg | first7 = J | last8 = Vermeulen | first8 = RF | last9 = Schouten | first9 = RN | last10 = Abellán | first10 = C | last11 = Amaya | first11 = W | last12 = Pruneri | first12 = V | last13 = Mitchell | first13 = MW | last14 = Markham | first14 = M | last15 = Twitchen | first15 = DJ | last16 = Elkouss | first16 = D | last17 = Wehner | first17 = S | last18 = Taminiau | first18 = TH | last19 = Hanson | first19 = R| year=2015 }}&lt;/ref&gt; reported that they performed a loophole-free Bell test which might force one to reject at least one of the principles of locality, realism, or [[Loopholes in Bell test experiments#Free choice of detector orientations|freedom-of-choice]] (the last "could" lead to alternative [[Superdeterminism|superdeterministic]] theories).&lt;ref&gt;{{Cite journal|url= http://www.nature.com/news/quantum-spookiness-passes-toughest-test-yet-1.18255 |author=Zeeya Merali |title=Quantum 'spookiness' passes toughest test yet |journal=Nature |volume= 525 |issue=7567 |pages=14–15 |date=2015-08-27|accessdate=2017-06-03|doi=10.1038/nature.2015.18255 |pmid=26333448 }}&lt;/ref&gt; Two of these logical possibilities, non-locality and non-realism, correspond to well-developed interpretations of quantum mechanics, and have many supporters; this is not the case for the third logical possibility, non-freedom. Conclusive experimental evidence of the violation of Bell's inequality would drastically reduce the class of acceptable deterministic theories but would not falsify absolute determinism, which was described by Bell himself as "not just inanimate nature running on behind-the-scenes clockwork, but with our behaviour, including our belief that we are free to choose to do one experiment rather than another, absolutely predetermined". However, Bell himself considered absolute determinism an implausible solution.

== Overview ==
Bell's theorem states that any physical theory that incorporates [[Principle of locality#Local realism|local realism]] cannot reproduce all the predictions of quantum mechanical theory.  Because numerous experiments agree with the predictions of quantum mechanical theory, and show differences between correlations that could not be explained by local hidden variables, the experimental results have been taken by many as refuting the concept of local realism as an explanation of the physical phenomena under test. For a hidden variable theory, if Bell's conditions are correct, the results that agree with quantum mechanical theory appear to indicate [[superluminal]] (faster-than-light) effects, in contradiction to the principle of locality.

These three key concepts – locality, realism, freedom&amp;nbsp;– are highly technical and much debated. In particular, the concept of ''realism'' is now somewhat different from what it was in discussions in the 1930s. It is more precisely called ''[[counterfactual definiteness]]''; it means that we may think of outcomes of measurements that were not actually performed as being just as much part of reality as those that were made. ''Locality'' is short for ''local relativistic causality''. (Currently accepted [[quantum field theory|quantum field theories]] ''are'' local in the terminology of the [[Lagrangian (field theory)|Lagrangian formalism]] and [[Local quantum field theory|axiomatic approach]].) ''Freedom'' refers to the physical possibility of determining settings on measurement devices independently of the internal state of the physical system being measured.

[[Image:Bell test for entangled qubits.svg|thumb|450px|right|Illustration of Bell test for spin-half particles such as electrons. A source produces a [[singlet state|singlet]] pair, one particle is sent to one location, and the other is sent to another location. A [[measurement in quantum mechanics|measurement]] of the entangled property is performed at various angles at each location. The scheme for measurements on [[photons]] looks very similar: the quantum state is different but has very similar properties.]]

The theorem is usually proved by consideration of a quantum system of two [[quantum entanglement|entangled]] [[qubit]]s. The most common examples concern systems of particles that are entangled in [[spin (physics)|spin]] or [[polarization (waves)|polarization]]. Quantum mechanics allows predictions of correlations that would be observed if these two particles have their spin or polarization measured in different directions. Bell showed that if a local hidden variable theory holds, then these correlations would have to satisfy certain constraints, called Bell inequalities. However, for the quantum correlations arising in the specific example considered, those constraints are not satisfied, hence the phenomenon being studied cannot be explained by a local hidden variables theory.

Following the argument in the [[EPR paradox|Einstein–Podolsky–Rosen (EPR) paradox]] paper (but using the example of spin, as in [[David Bohm]]'s version of the EPR argument&lt;ref name="Bell1964"&gt;{{cite journal |last=Bell |first=John |year=1964 |title=On the Einstein Podolsky Rosen Paradox |url=http://www.drchinese.com/David/Bell_Compact.pdf |journal=[[Physics (American Physical Society journal)|Physics]] |volume=1 |issue=3 |pages=195–200}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Bohm|first=David|title=Quantum Theory|authorlink=David Bohm|publisher=Prentice−Hall|year=1951}}&lt;/ref&gt;), Bell considered an experiment in which there are "a pair of spin one-half particles formed somehow in the [[Singlet state|singlet spin state]] and moving freely in opposite directions."&lt;ref name=Bell1964/&gt; The two particles travel away from each other to two distant locations, at which measurements of spin are performed, along axes that are independently chosen. Each measurement yields a result of either spin-up&amp;nbsp;(+) or spin-down&amp;nbsp;(−); it means, spin in the positive or negative direction of the chosen axis.

The probability of the same result being obtained at the two locations depends on the relative angles at which the two spin measurements are made, and is strictly between zero and one for all relative angles other than perfectly parallel or antiparallel alignments (0° or 180°). Since total angular momentum is conserved, and since the total spin is zero in the singlet state, the probability of the same result with parallel (antiparallel) alignment is 0 (1). This last prediction is true classically as well as quantum mechanically.

Bell's theorem is concerned with correlations defined in terms of averages taken over very many trials of the experiment. The [[Quantum correlation|correlation]] of two binary variables is usually defined in quantum physics as the average of the products of the pairs of measurements. Note that this is different from the usual definition of [[correlation]] in statistics. The quantum physicist's "correlation" is the statistician's "raw (uncentered, unnormalized) product [[Moment (mathematics)|moment]]". They are similar in that, with either definition, if the pairs of outcomes are always the same, the correlation is +1; if the pairs of outcomes are always opposite, the correlation is -1; and if the pairs of outcomes agree 50% of the time, then the correlation is 0. The correlation is related in a simple way to the probability of equal outcomes, namely it is equal to twice the probability of equal outcomes, minus one.

[[Pauli operator|Measuring the spin]] of these entangled particles along anti-parallel directions—i.e., along the same axis but in opposite directions, the set of all results is perfectly correlated. On the other hand, if measurements are performed along parallel directions they always yield opposite results, and the set of measurements shows perfect anti-correlation. This is in accord with the above stated probabilities of measuring the same result in these two cases. Finally, measurement at perpendicular directions has a 50% chance of matching, and the total set of measurements is uncorrelated. These basic cases are illustrated in the table below. Columns should be read as ''examples'' of pairs of values that could be recorded by Alice and Bob with time increasing going to the right.

{| style="float:center; text-align:center;"
|- style="vertical-align:bottom;"
! rowspan=2 style="text-align:left;" | Anti-parallel
! colspan=6 | Pair
! rowspan=2 |
|-
! 1    !! 2  !! 3  !! 4  !! … !! {{math|''n''}}
|-
| style="text-align:left;" | [[Alice and Bob|Alice]], 0°
| +    || −  || +  || +  || … || −              ||
|-
| style="text-align:left;" | [[Alice and Bob|Bob]], 180°
| +    || −  || +  || +  || … || −              ||
|- style="text-align:left;"
| Correlation
| ( +1 || +1 || +1 || +1 || … || +1 )           || / {{math|''n''}} = +1
|-
| colspan=7 |
| style="text-align:left;" | &lt;small&gt;(100% identical)&lt;/small&gt;
|-
! style="text-align:left;" | Parallel
! 1    !! 2  !! 3  !! 4  !! … !! {{math|''n''}}
!
|-
| style="text-align:left;" | [[Alice and Bob|Alice]], 0°
| +    || −  || −  || +  || … || +              ||
|-
| style="text-align:left;" | [[Alice and Bob|Bob]], 0° or 360°
| −    || +  || +  || −  || … || −              ||
|- style="text-align:left;"
| Correlation
| ( −1 || −1 || −1 || −1 || … || −1 )           || / {{math|''n''}} = −1
|-
| colspan=7 |
| style="text-align:left;" | &lt;small&gt;(100% opposite)&lt;/small&gt;
|-
! style="text-align:left;" | Orthogonal
! 1    !! 2  !! 3  !! 4  !! … !! {{math|''n''}}
!
|-
| style="text-align:left;" | Alice, 0°
| +    || −  || +  || −  || … || −              ||
|-
| style="text-align:left;" | Bob, 90° or 270°
| −    || −  || +  || +  || … || −              ||
|- style="text-align:left;"
| Correlation
| ( −1 || +1 || +1 || −1 || … || +1 )           || / {{math|''n''}} = 0
|-
| colspan=7 |
| style="text-align:left;" | &lt;small&gt;(50% identical, 50% opposite)&lt;/small&gt;
|}

[[Image:Bell.svg|400px|thumb|The best possible local realist imitation (red) for the quantum correlation of two spins in the singlet state (blue), insisting on perfect anti-correlation at 0°, perfect correlation at 180°. Many other possibilities exist for the classical correlation subject to these side conditions, but all are characterized by sharp peaks (and valleys) at 0°, 180°, and 360°, and none has more extreme values (±0.5) at 45°, 135°, 225°, and 315°. These values are marked by stars in the graph, and are the values measured in a standard Bell-CHSH type experiment: QM allows {{nowrap|±1/{{sqrt|2}} {{=}} ±0.7071…}}, local realism predicts ±0.5 or less.]]

With the measurements oriented at intermediate angles between these basic cases, the existence of local hidden variables could agree with/would be consistent with a linear dependence of the [[quantum correlation|correlation]] in the angle but, according to Bell's inequality (see below), could not agree with the dependence predicted by quantum mechanical theory, namely, that the correlation is the negative [[cosine]] of the angle.  Experimental results match the curve predicted by quantum mechanics.&lt;ref name="C.B. Parker 1994 542"/&gt;

Over the years, Bell's theorem has undergone a wide variety of experimental tests.  However, various [[Bell test loopholes|common deficiencies in the testing of the theorem]] have been identified, including the ''detection loophole''&lt;ref name="Stanford"&gt;[http://plato.stanford.edu/entries/bell-theorem Article on ''Bell's Theorem''] by Abner Shimony in the [[Stanford Encyclopedia of Philosophy]], (2004).&lt;/ref&gt; and the ''communication loophole''.&lt;ref name="Stanford"/&gt; Over the years experiments have been gradually improved to better address these loopholes. In 2015, the first experiment to simultaneously address all of the loopholes was performed.&lt;ref name="ReferenceA"/&gt;

To date, Bell's theorem is generally regarded as supported by a substantial body of evidence and there are few supporters of local hidden variables, though the theorem is continually the subject of study, criticism, and refinement.&lt;ref&gt;{{cite book |last=Griffiths |first=David J. |year=1998 |title=Introduction to Quantum Mechanics |edition=2nd |publisher=[[Pearson Education|Pearson]]/[[Prentice Hall]] |pages=423}}&lt;/ref&gt;&lt;ref&gt;{{cite book
 |last=Merzbacher |first=Eugene  |year=2005 |title=Quantum Mechanics |edition=3rd |publisher=[[John Wiley &amp; Sons]] |pages=18, 362}}&lt;/ref&gt;

==Importance==
Bell's theorem, derived in his seminal 1964 paper titled ''On the Einstein Podolsky Rosen paradox'',&lt;ref name=Bell1964/&gt; has been called, on the assumption that the theory is correct, "the most profound in science".&lt;ref&gt;{{harvnb|Stapp|1975}}&lt;/ref&gt;  Perhaps of equal importance is Bell's deliberate effort to encourage and bring legitimacy to work on the completeness issues, which had fallen into disrepute.&lt;ref name="Bell 1982"&gt;{{cite journal|last=Bell|first=JS|title=On the impossible pilot wave|url=http://prac.us.edu.pl/~ztpce/QM/Bell_pilot_wave.pdf|journal=Foundations of Physics|year=1982|volume=12|issue=10|pages=989–99|doi=10.1007/bf01889272|bibcode = 1982FoPh...12..989B }} Reprinted in ''Speakable and unspeakable in quantum mechanics: collected papers on quantum philosophy''. CUP, 2004, p. 160.&lt;/ref&gt;  Later in his life, Bell expressed his hope that such work would "continue to inspire those who suspect that what is proved by the impossibility proofs is lack of imagination."&lt;ref name="Bell 1982"/&gt;

The title of Bell's seminal article refers to the 1935 paper by [[EPR paradox|Einstein, Podolsky and Rosen]]&lt;ref&gt;{{cite journal |doi=10.1103/PhysRev.47.777 |title=Can Quantum-Mechanical Description of Physical Reality Be Considered Complete? |year=1935 |last1=Einstein |first1=A. |last2=Podolsky |first2=B. |last3=Rosen |first3=N. |journal=Physical Review |volume=47 |issue=10 |pages=777–780|bibcode = 1935PhRv...47..777E|url=http://www.drchinese.com/David/EPR.pdf}}&lt;/ref&gt; that challenged the completeness of quantum mechanics.  In his paper, Bell started from the same two assumptions as did EPR, namely (i) ''reality'' (that microscopic objects have real properties determining the outcomes of quantum mechanical measurements), and (ii) ''locality'' (that reality in one location is not influenced by measurements performed simultaneously at a distant location). Bell was able to derive from those two assumptions an important result, namely Bell's inequality. The theoretical (and later experimental) violation of this inequality implies that at least one of the two assumptions must be false.

In two respects Bell's 1964 paper was a step forward compared to the EPR paper: firstly, it considered more [[Hidden variable theory|hidden variables]] than merely the [[EPR paradox|element of physical reality]] in the EPR paper; and Bell's inequality was, in part, experimentally testable, thus raising the possibility of testing the local realism hypothesis. Limitations on such tests to date are noted below.  Whereas Bell's paper deals only with deterministic hidden variable theories, Bell's theorem was later generalized to [[stochastic]] theories&lt;ref name="Clauser–Horne"&gt;{{cite journal|doi=10.1103/PhysRevD.10.526|title=Experimental consequences of objective local theories|year=1974|last1=Clauser|first1=John F.|journal=Physical Review D|volume=10|issue=2|pages=526–535|bibcode=1974PhRvD..10..526C|url=http://www.philoscience.unibe.ch/documents/physics/Clauser1974/Clauser1974.pdf|deadurl=yes|archiveurl=https://web.archive.org/web/20131225072037/http://www.philoscience.unibe.ch/documents/physics/Clauser1974/Clauser1974.pdf|archivedate=2013-12-25|df=}}&lt;/ref&gt; as well, and it was also realised&lt;ref&gt;{{cite journal |last= Eberhard |first=P. H. |year=1977 |title=Bell's theorem without hidden variables |journal=[[Nuovo Cimento B]] |volume=38 |issue=1 |pages=75–80 |doi= 10.1007/BF02726212 |url= http://www.iaea.org/inis/collection/NCLCollectionStore/_Public/08/282/8282046.pdf|bibcode = 1977NCimB..38...75E |arxiv=quant-ph/0010047 |citeseerx=10.1.1.252.6568 }}&lt;/ref&gt; that the theorem is not so much about hidden variables, as about the outcomes of measurements that could have been taken instead of the one actually taken. Existence of these variables is called the assumption of realism, or the assumption of [[counterfactual definiteness]].

After the EPR paper, quantum mechanics was in an unsatisfactory position: either it was incomplete, in the sense that it failed to account for some elements of physical reality, or it violated the principle of a finite propagation speed of physical effects. In a modified version of the EPR thought experiment, two hypothetical [[Observer (quantum physics)|observers]], now commonly referred to as [[Alice and Bob|''Alice'' and ''Bob'']], perform independent measurements of spin on a pair of electrons, prepared at a source in a special state called a ''[[spin singlet]] state''. It is the conclusion of EPR that once Alice measures spin in one direction (e.g. on the ''x'' axis), Bob's measurement in that direction is determined with certainty, as being the opposite outcome to that of Alice, whereas immediately before Alice's measurement Bob's outcome was only statistically determined (i.e., was only a probability, not a certainty); thus, either the spin in each direction is an ''element of physical reality'', or the effects travel from Alice to Bob instantly.

In QM, predictions are formulated in terms of [[probability|probabilities]] — for example, the probability that an [[electron]] will be detected in a particular place, or the probability that its spin is up or down. The idea persisted, however, that the electron in fact has a ''definite'' position and spin, and that QM's weakness is its inability to predict those values precisely. The possibility existed that some unknown theory, such as a ''hidden variables theory'', might be able to predict those quantities exactly, while at the same time also being in complete agreement with the probabilities predicted by QM. If such a hidden variables theory exists, then because the hidden variables are not described by QM the latter would be an incomplete theory.

==Local realism==
The concept of local realism is formalized to state, and prove, Bell's theorem and generalizations.  A common approach is the following:
# There is a [[probability space]] {{math|Λ}} and the observed outcomes by both Alice and Bob result by random sampling of the (unknown, "hidden") parameter {{math|''λ'' ∈ Λ}}.
# The values observed by Alice or Bob are functions of the local detector settings and the hidden parameter only. Thus, there are functions {{math|''A'',''B'' : ''S''&lt;sup&gt;2&lt;/sup&gt; × Λ → {-1, +1} }}, where a detector setting is modeled as a location on the unit sphere {{math|''S''&lt;sup&gt;2&lt;/sup&gt;}}, such that
#*The value observed by Alice with detector setting {{mvar|a}} is {{math|''A''(''a'', ''λ'')}}
#*The value observed by Bob with detector setting {{mvar|b}} is {{math|''B''(''b'', ''λ'')}}

Perfect anti-correlation would require {{math|''B''(''c'', ''λ'') {{=}} −''A''(''c'', ''λ''), ''c'' ∈ ''S''&lt;sup&gt;2&lt;/sup&gt;}}. Implicit in assumption 1) above, the hidden parameter space {{math|Λ}} has a [[probability measure]] {{mvar|μ}} and the [[expectation value (quantum mechanics)|expectation]] of a random variable {{mvar|X}} on {{math|Λ}} with respect to {{mvar|μ}} is written

:&lt;math&gt; \operatorname{E}(X) = \int_\Lambda X(\lambda) p(\lambda) d \lambda, &lt;/math&gt;

where for accessibility of notation we assume that the probability measure has a [[probability density]] {{mvar|p}} that therefore is nonnegative and integrates to {{math|1}}. The hidden parameter is often thought of as being associated with the source but it can just as well also contain components associated with the two measurement devices.

== Bell inequalities ==
Bell inequalities concern measurements made by observers on pairs of particles that have interacted and then separated. Assuming local realism, certain constraints must hold on the relationships between the correlations between subsequent measurements of the particles under various possible measurement settings. Let {{mvar|A}} and {{mvar|B}} be as above. Define for the present purposes three correlation functions:
*Let {{math|''C''&lt;sub&gt;''e''&lt;/sub&gt;(''a'', ''b'')}} denote the experimentally measured correlation defined by
*:&lt;math&gt;C_e(a, b) = \frac{N_{++} + N_{--} - N_{+-} - N_{-+}}{N_{++} + N_{--} + N_{+-} + N_{-+}},&lt;/math&gt;
:where {{math|''N''&lt;sub&gt;++&lt;/sub&gt;}} is the number of measurements yielding "spin up" in the direction of {{math|'''a'''}} measured by Alice (first subscript {{math|+}}) ''and'' "spin up" in the direction of {{math|'''b'''}} measured by Bob. The other occurrences of {{mvar|N}} are analogously defined.
*Let {{math|''C''&lt;sub&gt;''q''&lt;/sub&gt;(''a'', ''b'')}} denote the correlation as predicted by quantum mechanics. This is given by the expression
*:&lt;math&gt;C_q(a, b) = \left\langle A \left|(\boldsymbol\sigma \cdot \mathbf b)^{(2)}(\boldsymbol\sigma \cdot \mathbf a)^{(1)}\right| A \right\rangle,&lt;/math&gt;
:where {{mvar|A}} is the antisymmetric spin wave function. This value is calculated to be
::&lt;math&gt;C_q(a, b) = -\mathbf a \cdot \mathbf b.&lt;/math&gt;
*Let {{math|''C''&lt;sub&gt;''h''&lt;/sub&gt;(''a'', ''b'')}} denote the correlation as predicted by any hidden variable theory. In the formalization of above, this is
*:&lt;math&gt;C_h(a, b) = E(A(\mathbf{a}, \lambda) B(\mathbf{b}, \lambda)) = \int_\Lambda A(\mathbf{a}, \lambda)B(\mathbf{b}, \lambda) p(\lambda) d\lambda.&lt;/math&gt;

{{Hidden begin
 | title style=color:green; background:lightgrey;
 | title=Details on calculation of {{math|''C''&lt;sub&gt;''q''&lt;/sub&gt;('''a''', '''b''')}}
}}
The two-particle spin space is the [[tensor product]] of the two-dimensional spin Hilbert spaces of the individual particles. Each individual space is an [[Irreducible representation|irreducible representation space]] of the [[rotation group SO(3)]]. The product space decomposes as a direct sum of irreducible representations with definite total spins {{math|0}} and {{math|1}} of dimensions {{math|1}} and {{math|3}} respectively. Full details may be found in [[Clebsch–Gordan coefficients|Clebsch—Gordan decomposition]]. The total spin zero subspace is spanned by the [[singlet state]] in the product space, a vector explicitly given by
:&lt;math&gt;
  |A\rangle =
  \frac{1}{\sqrt{2}}\left(\alpha^{(1)}\beta^{(2)} - \beta^{(1)}\alpha^{(2)}\right) =
  \frac{1}{\sqrt{2}}\left(
    \begin{bmatrix}1 \\ 0\end{bmatrix} \otimes \begin{bmatrix}0 \\ 1\end{bmatrix} -
    \begin{bmatrix}0 \\ 1\end{bmatrix} \otimes \begin{bmatrix}1 \\ 0\end{bmatrix}
  \right),
&lt;/math&gt;

with adjoint in this representation
:&lt;math&gt;\langle A| = \frac{1}{\sqrt{2}}\left(\begin{bmatrix}1 &amp; 0\end{bmatrix}\otimes\begin{bmatrix}0 &amp; 1\end{bmatrix} - \begin{bmatrix}0 &amp; 1\end{bmatrix}\otimes\begin{bmatrix}1 &amp; 0\end{bmatrix}\right).&lt;/math&gt;

The way single particle operators act on the product space is exemplified below by the example at hand; one defines the tensor product of operators, where the factors are single particle operators, thus if {{math|Π, Ω}} are single particle operators,
:&lt;math&gt;(\Pi \otimes \Omega ) (|x\rangle \otimes |y\rangle) = \Pi|x\rangle \otimes \Omega|y\rangle,&lt;/math&gt;

and
:&lt;math&gt;\Pi^{(1)} (|x\rangle \otimes |y\rangle) \equiv \Pi|x\rangle \otimes \operatorname{Id}|y\rangle,&lt;/math&gt;

etc., where the superscript in parentheses indicates on which Hilbert space in the tensor product space the action is intended and the action is defined by the right hand side. The singlet state has total spin {{math|0}} as may be verified by application of the operator of total spin {{math|'''J''' · '''J''' {{=}} ('''J'''&lt;sub&gt;1&lt;/sub&gt; + '''J'''&lt;sub&gt;2&lt;/sub&gt;) ⋅ ('''J'''&lt;sub&gt;1&lt;/sub&gt; + '''J'''&lt;sub&gt;2&lt;/sub&gt;)}} by a calculation similar to that presented below.

The expectation value of the operator
:&lt;math&gt;
  \left(\boldsymbol{\sigma} \cdot \mathbf{b}\right)^{(2)}\left(\boldsymbol{\sigma} \cdot \mathbf{a}\right)^{(1)} =
  \left(\operatorname{Id} \otimes \boldsymbol{\sigma} \cdot \mathbf{b}\right)\left(\boldsymbol{\sigma} \cdot \mathbf{a} \otimes \operatorname{Id}\right),
&lt;/math&gt;

in the singlet state can be calculated straightforwardly. One has, by definition of the [[Pauli matrices]],

:&lt;math&gt;\boldsymbol{\sigma} \cdot \mathbf{a} \otimes \operatorname{Id} = \begin{bmatrix} a_z &amp; a_x - ia_y \\ a_x + ia_y &amp; -a_z \end{bmatrix} \otimes \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix}.&lt;/math&gt;

Upon left application of this on {{ket|''A''}} one obtains

:&lt;math&gt;\boldsymbol{\sigma} \cdot \mathbf{a} \otimes \mathrm{Id} |A\rangle =
  \frac{1}{\sqrt{2}}\left(
    \begin{bmatrix}a_z \\ a_x + ia_y\end{bmatrix} \otimes \begin{bmatrix}0 \\ 1\end{bmatrix} -
    \begin{bmatrix}a_x - ia_y \\ -a_z\end{bmatrix} \otimes \begin{bmatrix}1 \\ 0\end{bmatrix}
  \right).
&lt;/math&gt;

Likewise, application (to the left) of the operator corresponding to {{math|'''b'''}} on {{bra|''A''}} yields

:&lt;math&gt;
  \langle A|\operatorname{Id} \otimes \boldsymbol{\sigma} \cdot \mathbf{b} =
  \frac{1}{\sqrt{2}} \left(
    \begin{bmatrix}1 &amp; 0\end{bmatrix} \otimes \begin{bmatrix}b_x + ib_y &amp; -b_z\end{bmatrix} -
    \begin{bmatrix}0 &amp; 1\end{bmatrix} \otimes \begin{bmatrix}b_z &amp; b_x - ib_y\end{bmatrix}
  \right).
&lt;/math&gt;

The inner products on the tensor product space is defined by

:&lt;math&gt;\langle x \otimes y|u \otimes v\rangle = \langle x|u\rangle\langle y|v\rangle.&lt;/math&gt;

Given this, the expectation value reduces to
:&lt;math&gt;\langle A|(\boldsymbol\sigma \cdot \mathbf b)^{(2)}(\boldsymbol\sigma \cdot \mathbf a)^{(1)}|A\rangle = -\mathbf a \cdot \mathbf b.&lt;/math&gt;
----
{{Hidden end}}
With this notation, a concise summary of what follows can be made.
*Theoretically, there exists {{math|'''a''', '''b'''}} such that
::&lt;math&gt;C_q \ne C_h,&lt;/math&gt;
:whatever are the particular characteristics of the hidden variable theory as long as it abides to the rules of local realism as defined above. That is to say, no local hidden variable theory can make the same predictions as quantum mechanics.
*Experimentally, instances of
::&lt;math&gt;C_e \ne C_h&lt;/math&gt;
:have been found (whatever the hidden variable theory), but 
::&lt;math&gt;C_e \ne C_q\quad \text{(not found)}&lt;/math&gt;
:has never been found. That is to say, predictions of quantum mechanics have never been falsified by experiment. These experiments include such that can rule out local hidden variable theories. But see below on possible loopholes.

=== Original Bell's inequality ===
The inequality that Bell derived can then be written as:&lt;ref name=Bell1964/&gt;

:&lt;math&gt;C_h(a, c) - C_h(b, a) - C_h(b, c) \le 1,&lt;/math&gt;

where {{mvar|a, b}} and {{mvar|c}} refer to three arbitrary settings of the two analysers. This inequality is however restricted in its application to the rather special case in which the outcomes on both sides of the experiment are always exactly anticorrelated whenever the analysers are parallel. The advantage of restricting attention to this special case is the resulting simplicity of the derivation. In experimental work, the inequality is not very useful because it is hard, if not impossible, to create ''perfect'' anti-correlation.

This simple form has an intuitive explanation, however. It is equivalent to the following elementary result from probability theory. Consider three (highly correlated, and possibly biased) coin-flips {{mvar|X, Y}}, and ''Z'', with the property that:
#''X'' and ''Y'' give the same outcome (both heads or both tails) 99% of the time
#''Y'' and ''Z'' also give the same outcome 99% of the time,

then ''X'' and ''Z'' must also yield the same outcome at least 98% of the time. The number of mismatches between ''X'' and ''Y'' (1/100) plus the number of mismatches between ''Y'' and ''Z'' (1/100) are together the ''maximum possible'' number of mismatches between ''X'' and ''Z'' (a simple [[Fréchet inequalities|Boole–Fréchet inequality]]).

Imagine a pair of particles that can be measured at distant locations. Suppose that the measurement devices have settings, which are angles—e.g., the devices measure something called spin in some direction. The experimenter chooses the directions, one for each particle, separately. Suppose the measurement outcome is binary (e.g., spin up, spin down). Suppose the two particles are perfectly anti-correlated—in the sense that whenever both measured in the same direction, one gets identically opposite outcomes, when both measured in opposite directions they always give the same outcome. The only way to imagine how this works is that both particles leave their common source with, somehow, the outcomes they will deliver when measured in any possible direction. (How else could particle 1 know how to deliver the same answer as particle 2 when measured in the same direction? They don't know in advance how they are going to be measured...). The measurement on particle 2 (after switching its sign) can be thought of as telling us what the same measurement on particle 1 would have given.

Start with one setting exactly opposite to the other. All the pairs of particles give the same outcome (each pair is either both spin up or both spin down). Now shift Alice's setting by one degree relative to Bob's. They are now one degree off being exactly opposite to one another. A small fraction of the pairs, say ''f'', now give different outcomes. If instead we had left Alice's setting unchanged but shifted Bob's by one degree (in the opposite direction), then again a fraction ''f'' of the pairs of particles turns out to give different outcomes. Finally consider what happens when both shifts are implemented at the same time: the two settings are now exactly two degrees away from being opposite to one another. By the mismatch argument, the chance of a mismatch at two degrees can't be more than twice the chance of a mismatch at one degree: it cannot be more than 2''f''.

Compare this with the predictions from quantum mechanics for the singlet state. For a small angle {{mvar|θ}}, measured in radians, the chance of a different outcome is approximately &lt;math&gt;f_1=\theta^2/4&lt;/math&gt; as explained by [[small-angle approximation]]. At two times this small angle, the chance of a mismatch is therefore about 4 times larger, since &lt;math&gt;f_2=(2\theta)^2/4=2^2 \theta^2/4 \approx 4f_1&lt;/math&gt;. But we just argued that it cannot be more than 2 times as large.

This intuitive formulation is due to [[David Mermin]]. The small-angle limit is discussed in Bell's original article, and therefore goes right back to the origin of the Bell inequalities.

===CHSH inequality===
{{Main article|CHSH inequality}}
Generalizing Bell's original inequality,&lt;ref name=Bell1964/&gt; [[John Clauser]], Michael Horne, [[Abner Shimony]] and R. A. Holt introduced the [[CHSH inequality]],&lt;ref name="Clauser 1969"&gt;{{cite journal |doi=10.1103/PhysRevLett.23.880 |title=Proposed Experiment to Test Local Hidden-Variable Theories |year=1969 |last1=Clauser |first1=John |last2=Horne |first2=Michael |last3=Shimony |first3=Abner |last4=Holt |first4=Richard |journal=Physical Review Letters |volume=23 |issue=15 |pages=880–884|bibcode = 1969PhRvL..23..880C}}&lt;/ref&gt; which puts classical limits on the set of four correlations in Alice and Bob's experiment, without any assumption of perfect correlations (or anti-correlations) at equal settings

:&lt;math&gt;(1) \quad C_h(a,b) + C_h(a,b') + C_h(a',b) - C_h(a',b') \leq 2.&lt;/math&gt;

Making the special choice &lt;math&gt;a'=b+\pi&lt;/math&gt;, denoting &lt;math&gt;b'=c&lt;/math&gt;, and assuming perfect anti-correlation at equal settings, perfect correlation at opposite settings, therefore &lt;math&gt;\rho(a,a+\pi)=1&lt;/math&gt; and &lt;math&gt;\rho(b,a+\pi)=-\rho(b,a)&lt;/math&gt;, the CHSH inequality reduces to the original Bell inequality. Nowadays, (1) is also often simply called "the Bell inequality", but sometimes more completely "the Bell-CHSH inequality".

==== Derivation ====
With abbreviated notation

:&lt;math&gt;A = A(a, \lambda), A' = A(a', \lambda), B = B(b, \lambda), B' = B(b', \lambda),&lt;/math&gt;

the CHSH inequality can be derived as follows. Each of the four quantities is {{math|±1}} and each depends on {{mvar|λ}}. It follows that for any {{math|''λ'' ∈ Λ}}, one of {{math|''B'' + ''B''&amp;prime;}} and {{math|''B'' − ''B''&amp;prime;}} is zero, and the other is {{math|±2}}. From this it follows that

:&lt;math&gt;AB + AB' + A'B - A'B'= A\left(B + B'\right) + A'\left(B - B'\right) \leq 2,&lt;/math&gt;

and therefore

:&lt;math&gt;\begin{align}
  C_h(a, b) + C_h\left(a, b'\right) + C_h\left(a', b\right) - C_h\left(a', b'\right) 
    &amp;= \int_\Lambda ABp d\lambda + \int_\Lambda AB'p d\lambda + \int_\Lambda A'Bp d\lambda - \int_\Lambda A'B'p d\lambda \\
    &amp;= \int_\Lambda \left(AB + AB' + A'B - A'B'\right)p d\lambda \\
    &amp;= \int_\Lambda \left(A\left(B + B'\right) + A'\left(B - B'\right)\right) p d\lambda \leq 2.
\end{align}&lt;/math&gt;

At the heart of this derivation is a simple algebraic inequality concerning four variables, {{math|''A'', ''A''&amp;prime;, ''B'', ''B''&amp;prime;}}, which take the values {{math|±1}} only:

:&lt;math&gt;AB + AB' + A'B - A'B' = A\left(B + B'\right) + A'\left(B - B'\right) \le 2.&lt;/math&gt;

The CHSH inequality is seen to depend only on the following three key features of a local hidden variables theory: (1) realism: alongside of the outcomes of actually performed measurements, the outcomes of potentially performed measurements also exist at the same time; (2) locality, the outcomes of measurements on Alice's particle don't depend on which measurement Bob chooses to perform on the other particle; (3) freedom: Alice and Bob can indeed choose freely which measurements to perform.

The ''realism'' assumption is actually somewhat idealistic, and Bell's theorem only proves non-locality with respect to variables that only ''exist'' for metaphysical reasons{{Citation needed|date=July 2018}}. However, before the discovery of quantum mechanics, both realism and locality were completely uncontroversial features of physical theories.

==Bell inequalities are violated by quantum mechanical predictions==
The measurements performed by Alice and Bob are spin measurements on electrons. Alice can choose between two detector settings labeled ''a'' and ''a''′; these settings correspond to measurement of spin along the ''z'' or the ''x'' axis. Bob can choose between two detector settings labeled ''b'' and ''b''′; these correspond to measurement of spin along the ''z''′ or ''x''′ axis, where the {{math|''x''′ − ''z''′}} coordinate system is rotated 135° relative to the {{math|''x'' − ''z''}} coordinate system.  The spin observables are represented by the 2 × 2 self-adjoint matrices:

:&lt;math&gt; S_x = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp;  0 \end{bmatrix}, \quad S_z = \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}&lt;/math&gt;

These are the [[Pauli spin matrix|Pauli spin matrices]] normalized so that the corresponding eigenvalues are {{math|±1}}. As is customary, we use the [[bra–ket notation]] to denote the eigenvectors of {{mvar|S&lt;sub&gt;x&lt;/sub&gt;}} by

:&lt;math&gt; \left|+x\right\rang, \quad \left|-x\right\rang. &lt;/math&gt;

Let &lt;math&gt;\phi&lt;/math&gt; be the spin singlet state for a pair of electrons discussed in the EPR paradox.  This is a specially constructed state described by the following vector in the tensor product

:&lt;math&gt;|\phi\rang = \frac{1}{\sqrt{2}} \left( \, \left|+x\right\rang \otimes \left|-x\right\rang -\left|-x\right\rang \otimes \left|+x\right\rang \, \right)&lt;/math&gt;

Now let us apply the CHSH formalism to the measurements that can be performed by Alice and Bob.

:&lt;math&gt;\begin{align}
  A(a)  &amp;= S_z \otimes I\\
  A(a') &amp;= S_x \otimes I\\
  B(b)  &amp;= -\frac{1}{\sqrt{2}} \ I \otimes (S_z + S_x)\\
  B(b') &amp;=  \frac{1}{\sqrt{2}} \ I \otimes (S_z - S_x)
\end{align}&lt;/math&gt;

The operators &lt;math&gt;\scriptstyle B(b'), B(b)&lt;/math&gt; correspond to Bob's spin measurements along ''x''′ and ''z''′. Note that the {{mvar|A}} operators commute with the {{mvar|B}} operators, so we can apply our calculation for the correlation. In this case, we can show that the CHSH inequality fails. In fact, a straightforward calculation shows that {{Citation needed|date=August 2014}}

:&lt;math&gt;\begin{align}
  \left\langle A(a) B(b) \right\rangle = \left\langle A\left(a'\right) B(b) \right\rangle =
    \left\langle A\left(a'\right) B\left(b'\right) \right\rangle &amp;=  \frac{1}{\sqrt{2}} \\
                \left\langle A(a) B\left(b'\right) \right\rangle &amp;= -\frac{1}{\sqrt{2}}
\end{align}&lt;/math&gt;

so that

:&lt;math&gt;
  \left\langle A(a) B(b) \right\rangle + \left\langle A\left(a'\right) B\left(b'\right) \right\rangle +
  \left\langle A\left(a'\right) B(b) \right\rangle - \left\langle A(a) B\left(b'\right) \right\rangle =
    \frac{4}{\sqrt{2}} = 2\sqrt{2} &gt; 2
&lt;/math&gt;

Bell's Theorem: If the quantum mechanical formalism is correct, then the system consisting of a pair of entangled electrons cannot satisfy the principle of local realism.  Note that {{math|2{{sqrt|2}}}} is indeed the upper bound for quantum mechanics called [[Tsirelson's bound]]. The operators giving this maximal value are always [[isomorphic]] to the Pauli matrices.

== Testing by practical experiments ==
[[Image:Bell-test-photon-analyer.png|450px|thumb|right|'''Scheme of a "two-channel" Bell test'''&lt;br /&gt;The source S produces pairs of "photons", sent in opposite directions. Each photon encounters a two-channel polariser whose orientation (a or b) can be set by the experimenter. Emerging signals from each channel are detected and coincidences of four types (++, −−, +− and −+) counted by the coincidence monitor.]]
{{Main article|Bell test experiments}}

Experimental tests can determine whether the Bell inequalities required by local realism hold up to the empirical evidence.

Actually, most experiments have been performed using polarization of photons rather than spin of electrons (or other spin-half particles). The quantum state of the pair of entangled photons is not the singlet state, and the correspondence between angles and outcomes is different from that in the spin-half set-up. The polarization of a photon is measured in a pair of perpendicular directions. Relative to a given orientation, polarization is either vertical (denoted by V or by +) or horizontal (denoted by H or by -). The photon pairs are generated in the quantum state

:&lt;math&gt;\frac{1}{\sqrt{2}} \left (|V\rangle\otimes |V\rangle+|H\rangle\otimes|H\rangle \right)&lt;/math&gt;

where &lt;math&gt;|V\rangle&lt;/math&gt; and &lt;math&gt;|H\rangle&lt;/math&gt; denotes the state of a single vertically or horizontally polarized photon, respectively (relative to a fixed and common reference direction for both particles).

When the polarization of both photons is measured in the same direction, both give the same outcome: perfect correlation. When measured at directions making an angle 45° with one another, the outcomes are completely random (uncorrelated). Measuring at directions at 90° to one another, the two are perfectly anti-correlated. In general, when the polarizers are at an angle {{mvar|θ}} to one another, the correlation is {{math|cos(2''θ'')}}. So relative to the correlation function for the singlet state of spin half particles, we have a positive rather than a negative cosine function, and angles are halved: the correlation is periodic with period {{mvar|π}} instead of {{math|2''π''}}.

Bell's inequalities are tested by "coincidence counts" from a Bell test experiment such as the optical one shown in the diagram.  Pairs of particles are emitted as a result of a quantum process, analysed with respect to some key property such as polarisation direction, then detected.  The setting (orientations) of the analysers are selected by the experimenter.

Bell test experiments to date overwhelmingly violate Bell's inequality.

===Two classes of Bell inequalities===
The ''fair sampling'' problem was faced openly in the 1970s. In early designs of their 1973 experiment, Freedman and Clauser&lt;ref name="Clauser–Freedman"&gt;{{cite journal |doi=10.1103/PhysRevLett.28.938 |title=Experimental Test of Local Hidden-Variable Theories |year=1972 |last1=Freedman |first1=Stuart J. |last2=Clauser |first2=John F. |journal=Physical Review Letters |volume=28 |issue=14 |pages=938–941|bibcode = 1972PhRvL..28..938F |url= http://dieumsnh.qfb.umich.mx/archivoshistoricosMQ/ModernaHist/Freedman.pdf }}&lt;/ref&gt; used ''fair sampling'' in the form of the Clauser–Horne–Shimony–Holt (CHSH&lt;ref name="Clauser 1969"/&gt;) hypothesis. However, shortly afterwards Clauser and Horne&lt;ref name="Clauser–Horne"/&gt;  made the important distinction between inhomogeneous (IBI) and homogeneous (HBI) Bell inequalities. Testing an IBI requires that we compare certain coincidence rates in two separated detectors with the singles rates of the two detectors. Nobody needed to perform the experiment, because singles rates with all detectors in the 1970s were at least ten times all the coincidence rates. So, taking into account this low detector efficiency, the QM prediction actually satisfied the IBI. To arrive at an experimental design in which the QM prediction violates IBI we require detectors whose efficiency exceeds 82.8% for singlet states,&lt;ref name="Garg &amp; Mermin, 1987"&gt;{{citation |author1=Anupam Garg |author2=N.D. Mermin |year=1987 |title=Detector inefficiencies in the Einstein-Podolsky-Rosen experiment |journal=Phys. Rev. D |volume=25 |issue=12 |pages=3831–5 |doi=10.1103/PhysRevD.35.3831|bibcode = 1987PhRvD..35.3831G }}&lt;/ref&gt; but have very low dark rate and short dead and resolving times. This is now within reach.

===Practical challenges===
{{Main article|Loopholes in Bell test experiments}}

Because, at that time, even the best detectors didn't detect a large fraction of all photons, Clauser and Horne&lt;ref name="Clauser–Horne"/&gt; recognized that testing Bell's inequality required some extra assumptions. They introduced the ''No Enhancement Hypothesis'' (NEH):

{{quote|A light signal, originating in an [[atomic cascade]] for example, has a certain probability of activating a detector.  Then, if a polarizer is interposed between the cascade and the detector, the detection probability cannot increase.}}

Given this assumption, there is a Bell inequality between the coincidence rates with polarizers and coincidence rates without polarizers.

The experiment was performed by Freedman and Clauser,&lt;ref name="Clauser–Freedman"/&gt; who found that the Bell's inequality was violated. So the no-enhancement hypothesis cannot be true in a local hidden variables model.

While early experiments used atomic cascades,  later experiments have used parametric down-conversion, following a suggestion by Reid and Walls,&lt;ref&gt;{{cite journal|author1-link=Margaret D. Reid |first1=M. D. |last1=Reid |first2=D. F. |last2=Walls |title= Violations of classical inequalities in quantum optics|journal=[[Physical Review A]]|volume=34|issue=2 |pages=1260–1276|year=1986|doi=10.1103/PhysRevA.34.1260|bibcode = 1986PhRvA..34.1260R }}&lt;/ref&gt; giving improved generation and detection properties. As a result, the most recent experiments with photons no longer suffer from the detection loophole (see [[Bell test experiments]]). This makes the photon the first experimental system for which all main experimental loopholes have been surmounted, albeit presently only in separate experiments (Giustina et al. (2013), ''Bell violation using entangled photons without the fair-sampling assumption'', Nature 497, 227–230; B.G. Christensen et al. (2013), ''Detection-Loophole-Free Test of Quantum Nonlocality, and Applications'', arXiv:1306.5772).

== Metaphysical aspects ==
Most advocates of the hidden-variables idea believe that experiments have ruled out local hidden variables.  They are ready to give up locality, explaining the violation of Bell's inequality by means of a non-local [[hidden variable theory]], in which the particles exchange information about their states. This is the basis of the [[Bohm interpretation]] of quantum mechanics, which requires that all particles in the universe be able to instantaneously exchange information with all others. A 2007 experiment ruled out a large class of non-Bohmian non-local hidden variable theories.&lt;ref&gt;{{cite journal |doi=10.1038/nature05677 |title=An experimental test of non-local realism |year=2007 |last1=Gröblacher |first1=Simon |last2=Paterek |first2=Tomasz |last3=Kaltenbaek |first3=Rainer |last4=Brukner |first4=Časlav |last5=Żukowski |first5=Marek |last6=Aspelmeyer |first6=Markus |last7=Zeilinger |first7=Anton |journal=Nature |volume=446 |issue=7138 |pages=871–5 |pmid=17443179|bibcode = 2007Natur.446..871G | arxiv= 0704.2529 }}&lt;/ref&gt;

If the hidden variables can communicate with each other faster than light, Bell's inequality can easily be violated. Once one particle is measured, it can communicate the necessary correlations to the other particle. Since in relativity the notion of simultaneity is not absolute, this is unattractive. One idea is to replace instantaneous communication with a process that travels backwards in time along the past [[light cone]]. This is the idea behind a [[transactional interpretation]] of quantum mechanics, which interprets the statistical emergence of a quantum history as a gradual coming to agreement between histories that go both forward and backward in time.&lt;ref&gt;{{cite journal|doi=10.1103/RevModPhys.58.647|title=The transactional interpretation of quantum mechanics|year=1986|last1=Cramer|first1=John|journal=Reviews of Modern Physics| volume=58| issue=3| pages=647–687| bibcode = 1986RvMP...58..647C }}&lt;/ref&gt;

A few advocates of deterministic models have not given up on local hidden variables. For example, [[Gerard 't Hooft]] has argued that the [[superdeterminism]] loophole cannot be dismissed.&lt;ref&gt;{{cite arXiv |eprint=0908.3408 |author1=Gerard 't Hooft |title=Entangled quantum states in a local deterministic theory |class=quant-ph |year=2009}}&lt;/ref&gt;&lt;ref&gt;{{cite arXiv|eprint=quant-ph/0701097|author1=Gerard 't Hooft|title=The Free-Will Postulate in Quantum Mechanics |year=2007}}&lt;/ref&gt;

A possible (but not universally accepted) solution is offered by the [[many-worlds interpretation|many worlds theory]] of quantum mechanics. According to this, not only is collapse of the wave function illusory, but the apparent random branching of possible futures when quantum systems interact with the macroscopic world is also an illusion. Measurement does not lead to a random choice of possible outcome; rather, the only ingredient of quantum mechanics is the unitary evolution of the wave function. All possibilities co-exist forever and the only reality is the quantum mechanical wave function. According to this view, two distant observers both split into superpositions when measuring a spin. The Bell inequality violations are no longer counterintuitive, because it is not clear which copy of the observer B will be seen by observer A when they compare notes. If reality includes all the different outcomes, locality in physical space (not outcome space) places no restrictions on how the split observers can meet up.

This point underlines the fact that the argument that realism is incompatible with quantum mechanics and locality depends on a particular formalization of the concept of realism. In its weakest form, the assumption underpinning that particular formalization is called [[counterfactual definiteness]]. This is the assumption that outcomes of measurements that are not performed are just as real as those of measurements that were performed.  Counterfactual definiteness is an uncontroversial property of all classical physical theories prior to quantum theory, due to their determinism. Many worlds interpretations are not only counterfactually indefinite, but are also factually indefinite. The results of all experiments, even ones that have been performed, are not uniquely determined.

If one chooses to reject counterfactual definiteness, reality has been made smaller, and there is no non-locality problem. On the other hand, one is thereby introducing irreducible or intrinsic randomness into our picture of the world: randomness that cannot be "explained" as merely the reflection of our ignorance of underlying, variable, physical quantities. Non-determinism becomes a fundamental property of nature.

Assuming counterfactual definiteness, reality has been enlarged, and there is a non-locality problem. On the other hand, in the many-worlds interpretation of quantum mechanics, reality consists only of a deterministically evolving wave function and non-locality is a non-issue.

There have also been repeated claims that Bell's arguments are irrelevant because they depend on hidden assumptions that, in fact, are questionable.  For example, [[E. T. Jaynes]]&lt;ref&gt;{{Cite book |title=Clearing up Mysteries—The Original Goal |year=1989 |last1=Jaynes |first1=E. T. |journal=Maximum Entropy and Bayesian Methods |pages=1–27 | url=http://bayes.wustl.edu/etj/articles/cmystery.pdf |doi=10.1007/978-94-015-7860-8_1|isbn=978-90-481-4044-2 |citeseerx=10.1.1.46.1264 }}&lt;/ref&gt; claimed in 1989 that there are two hidden assumptions in Bell's theorem that could limit its generality. According to him:
# Bell interpreted conditional probability P(X|Y) as a causal inference, i.e. Y exerted a causal inference on X in reality.  However, P(X|Y) actually only means logical inference (induction).  Causes cannot travel faster than light or backward in time, but deduction can.
# Bell's inequality does not apply to some possible hidden variable theories. It only applies to a certain class of local hidden variable theories.  In fact, it might have just missed the kind of hidden variable theories that Einstein is most interested in.

However, [[Richard D. Gill]] has argued that Jaynes misunderstood Bell's analysis. Gill points out that in the same conference volume in which Jaynes argues against Bell, Jaynes confesses to being extremely impressed by a short proof by [[Steve Gull]] presented at the same conference, that the singlet correlations could not be reproduced by a computer simulation of a local hidden variables theory.&lt;ref&gt;{{cite journal |title=Time, Finite Statistics, and Bell's Fifth Position |year=2003 |last1=Gill |first1=Richard D. |journal=Proc. Of "Foundations of Probability and Physics - 2", Ser. Math. Modelling in Phys., Engin., and Cogn. Sc. |volume=5/2002| pages=179–206 |arxiv= quant-ph/0301059|bibcode = 2003quant.ph..1059G }}&lt;/ref&gt; According to Jaynes (writing nearly 30 years after Bell's landmark contributions), it would probably take us another 30 years to fully appreciate Gull's stunning result.

In 2006 a flurry of activity about implications for determinism arose with the paper: [[Free will theorem|''The Free Will Theorem'']]&lt;ref&gt;{{cite journal | last = Conway | first = John |author2=Simon Kochen | year = 2006 | title = The Free Will Theorem | journal = Foundations of Physics | volume = 36 | issue = 10 | pages = 1441–1473 | doi = 10.1007/s10701-006-9068-6 |arxiv = quant-ph/0604079 |bibcode = 2006FoPh...36.1441C }}&lt;/ref&gt; which stated "the response of a spin 1 particle to a triple experiment is free—that is to say, is not a function of properties of that part of the universe that is earlier than this response with respect to any given inertial frame."&lt;ref&gt;{{cite journal |author1=Conway, John H. |author2=Simon Kochen  |lastauthoramp=yes |title=The strong free will theorem |journal= Notices of the AMS |volume=56 |issue=2 |year=2009 |pages=226–232 |url=http://www.ams.org/notices/200902/rtx090200226p.pdf?q=will&amp;sa=U&amp;ei=k71jU8X7DoypyASw9YGoCA&amp;ved=0CCAQFjAB&amp;usg=AFQjCNE7L-k87yWE32ru0rDjkLOdg12LRQ}}&lt;/ref&gt; This theorem raised awareness of a tension between determinism fully governing an experiment (on the one hand) and Alice and Bob being free to choose any settings they like for their observations (on the other).&lt;ref&gt;{{cite journal |author1=Cator, Eric |author2=Klaas Landsman  |lastauthoramp=yes |title=Constraints on determinism: Bell versus Conway–Kochen |journal=Foundations of Physics |volume=44 |issue=7 |year=2014 |pages=781–791 |doi=10.1007/s10701-014-9815-z|arxiv = 1402.1972 |bibcode = 2014FoPh...44..781C }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author=Esfeld, Michael |title=Bell's Theorem and the Issue of Determinism and Indeterminism |journal= Foundations of Physics |year=2015 |pages= 471–482|arxiv = 1503.00660 | doi = 10.1007/s10701-015-9883-8 |volume=45|issue=5 |bibcode = 2015FoPh...45..471E }}&lt;/ref&gt; The philosopher David Hodgson supports this theorem as showing that determinism is ''unscientific'', and that quantum mechanics allows observers (at least in some instances) the freedom to make observations of their choosing, thereby leaving the door open for free will.&lt;ref&gt;{{cite book |author=David Hodgson |title=Rationality + Consciousness = Free Will |chapter=Chapter 7: Science and determinism |isbn=9780199845309 |year=2012 |publisher=Oxford University Press |chapter-url=https://books.google.com/books?id=4SGsmowYARsC&amp;pg=PA121&amp;dq=%22Conway+and+Kochen+call+the+free+will+theorem%22&amp;hl=en&amp;sa=X&amp;ei=UiMYVeTBII3woATFkoKAAQ&amp;ved=0CB4Q6AEwAA#v=onepage&amp;q=%22Conway%20and%20Kochen%20call%20the%20free%20will%20theorem%22&amp;f=false}}&lt;/ref&gt;

==General remarks==
The violations of Bell's inequalities, due to quantum entanglement, provide near definitive demonstrations of something that was already strongly suspected: that quantum physics cannot be represented by any version of the classical picture of physics.&lt;ref&gt;{{cite book |first=Roger |last=Penrose |title=The Road to Reality |edition= |page=583 |year=2007 |publisher=Vintage Books |isbn=978-0-679-77631-4}}&lt;/ref&gt; Some earlier elements that had seemed incompatible with classical pictures included [[Complementarity (physics)|complementarity]] and [[wavefunction collapse]]. The Bell violations show that no resolution of such issues can avoid the ultimate strangeness of quantum behavior.&lt;ref&gt;{{cite book |first=E. |last=Abers |title=Quantum Mechanics |edition= |pages=193–195 |year=2004 |publisher=Addison Wesley |isbn=9780131461000}}&lt;/ref&gt;

The EPR paper "pinpointed" the unusual properties of the ''entangled states'', e.g. the above-mentioned singlet state, which is the foundation for present-day applications of quantum physics, such as [[quantum cryptography]]; one application involves the measurement of quantum entanglement as a physical source of bits for [[Michael O. Rabin|Rabin's]] [[oblivious transfer]] protocol. This non-locality was originally supposed to be illusory, because the standard interpretation could easily do away with action-at-a-distance by simply assigning to each particle definite spin-states for all possible spin directions. The EPR argument was: therefore these definite states exist, therefore quantum theory is incomplete, since they do not appear in the theory. Bell's theorem showed that the "entangledness" prediction of quantum mechanics has a degree of non-locality that cannot be explained away by any local theory.

What is powerful about Bell's theorem is that it doesn't refer to any particular physical theory. It shows that nature violates the most general assumptions behind classical pictures, not just details of some particular models. No combination of local deterministic and local random variables can reproduce the phenomena predicted by quantum mechanics and repeatedly observed in experiments.&lt;ref&gt;{{cite book|author1=R.G. Lerner |author2=G.L. Trigg | title = Encyclopaedia of Physics | edition = 2nd | page = 495 | year=  1991 | publisher = VHC publishers | isbn =978-0-89573-752-6}}&lt;/ref&gt;

==See also==
{{portal|physics}}
{{Div col|colwidth=27em}}
* [[Bell test experiments]]
* [[Bohr–Einstein debates|Bohr–Einstein debates on quantum mechanics]]
* [[CHSH Bell test]]
* [[Counterfactual definiteness]]
* [[Correlation does not imply causation]]
* [[Einstein's thought experiments]]
* ''[[Epistemological Letters]]''
* [[Free will theorem]]
* [[Fundamental Fysiks Group]]
* [[GHZ experiment]]
* [[Hidden variable theory]]
* [[Local hidden variable theory]]
* [[Loopholes in Bell test experiments]]
* [[Leggett inequality]]
* [[Leggett–Garg inequality]]
* [[Measurement in quantum mechanics]]
* [[Mott problem]]
* [[Normally distributed and uncorrelated does not imply independent]]
* [[PBR theorem]]
* [[Quantum contextuality]]
* [[Quantum entanglement]]
* [[Quantum nonlocality]]
* [[Renninger negative-result experiment]]
* [[Sakurai's Bell inequality]]
{{Div col end}}

==Notes==
{{Reflist}}

==References==
{{Refbegin|colwidth=60em}}
* {{cite journal | last1 = Aspect | first1 = A. | title = Experimental Tests of Realistic Local Theories via Bell's Theorem | url = | journal = Phys. Rev. Lett. | volume = 47 | pages = 460–463 | issue = 7| year = 1981 |display-authors=etal | doi=10.1103/physrevlett.47.460|bibcode = 1981PhRvL..47..460A }}
* {{cite journal | last1 = Aspect | first1 = A. | title = Experimental Realization of Einstein–Podolsky–Rosen–Bohm Gedankenexperiment: A New Violation of Bell's Inequalities | url = | journal = Phys. Rev. Lett. | volume = 49 | issue = 2 | pages = 91–94 | year = 1982 |display-authors=etal | doi=10.1103/physrevlett.49.91|bibcode = 1982PhRvL..49...91A }}
* {{cite journal | last1 = Aspect | first1 = A. | title = Experimental Test of Bell's Inequalities Using Time-Varying Analyzers | url = | journal = Phys. Rev. Lett. | volume = 49 | issue = 25 | pages = 1804–1807 | year = 1982 |display-authors=etal | doi=10.1103/physrevlett.49.1804|bibcode = 1982PhRvL..49.1804A }}
* {{cite journal | last1 = Aspect | first1 = A. | last2 = Grangier | first2 = P. | title = About resonant scattering and other hypothetical effects in the Orsay atomic-cascade experiment tests of Bell inequalities: a discussion and some new experimental data | url = | journal = Lettere al Nuovo Cimento | volume = 43 | issue = 8 | pages = 345–348 | year = 1985 | doi=10.1007/bf02746964}}
* {{cite journal | last1 = D'Espagnat | first1 = B. | year = 1979 | title = The Quantum Theory and Reality | url = http://www.sciam.com/media/pdf/197911_0158.pdf | format = PDF | journal = Scientific American | volume = 241 | issue = 5| pages = 158–181 | doi=10.1038/scientificamerican1179-158|bibcode = 1979SciAm.241e.158D }}
* {{cite journal | last1 = Bell | first1 = J. S. | title = On the problem of hidden variables in quantum mechanics | url = | journal = Rev. Mod. Phys. | volume = 38 | issue = 3 | pages = 447–452 | year = 1966 | doi = 10.1103/revmodphys.38.447 |bibcode = 1966RvMP...38..447B }}
* {{cite journal | last1 = Bell | first1 = J. S. | year = 1964 | title = On the Einstein Podolsky Rosen Paradox | url = https://cds.cern.ch/record/111654/files/vol1p195-200_001.pdf | journal = Physics | volume = 1 | issue = 3| pages = 195–200 }}
* J. S. Bell, ''Introduction to the hidden variable question'', Proceedings of the International School of Physics 'Enrico Fermi', Course IL, Foundations of Quantum Mechanics (1971) 171–81
* J. S. Bell, ''Bertlmann's socks and the nature of reality'', Journal de Physique, Colloque C2, suppl. au numero 3, Tome '''42''' (1981) pp C2 41–61
* J. S. Bell, ''Speakable and Unspeakable in Quantum Mechanics'' (Cambridge University Press 1987) [A collection of Bell's papers, including all of the above.]
* {{cite journal | last1 = Clauser | first1 = J. F. | last2 = Shimony | first2 = A. | title = Bell's theorem: experimental tests and implications | url = http://www.physics.oregonstate.edu/~ostroveo/COURSES/ph651/Supplements_Phys651/RPP1978_Bell.pdf| journal = Reports on Progress in Physics | volume = 41 | issue = 12 | pages = 1881–1927 | year = 1978 | doi = 10.1088/0034-4885/41/12/002 |bibcode = 1978RPPh...41.1881C | citeseerx = 10.1.1.482.4728 }}
* {{cite journal | last1 = Clauser | first1 = J. F. | last2 = Horne | first2 = M. A. | year = 1974 | title =  Experimental consequences of objective local theories| url = | journal = Phys. Rev. D | volume = 10 | issue = 2| pages = 526–535 | doi =  10.1103/physrevd.10.526 |bibcode = 1974PhRvD..10..526C }}
* {{cite journal | last1 = Fry | first1 = E. S. | last2 = Walther | first2 = T. | last3 = Li | first3 = S. | title = Proposal for a loophole-free test of the Bell inequalities | url = http://oaktrust.library.tamu.edu/bitstream/1969.1/126533/1/PhysRevA.52.4381.pdf| journal = Phys. Rev. A | volume = 52 | issue = 6 | pages = 4381–4395 | year = 1995 | doi=10.1103/physreva.52.4381| pmid = 9912775 |bibcode = 1995PhRvA..52.4381F | hdl = 1969.1/126533 }}
* E. S. Fry, and T. Walther, ''Atom based tests of the Bell Inequalities — the legacy of John Bell continues'', pp 103–117 of ''Quantum [Un]speakables'', R.A. Bertlmann and A. Zeilinger (eds.) (Springer, Berlin-Heidelberg-New York, 2002)
* R. B. Griffiths, ''Consistent Quantum Theory''', Cambridge University Press (2002).
* {{cite journal | last1 = Hardy | first1 = L. | year = 1993 | title = Nonlocality for 2 particles without inequalities for almost all entangled states | url = | journal = Physical Review Letters | volume = 71 | issue = 11| pages = 1665–1668 | doi=10.1103/physrevlett.71.1665|bibcode = 1993PhRvL..71.1665H | pmid=10054467}}
* M. A. Nielsen and I. L. Chuang, ''Quantum Computation and Quantum Information'', Cambridge University Press (2000)
* {{cite journal | last1 = Pearle | first1 = P. | year = 1970 | title = Hidden-Variable Example Based upon Data Rejection | url = | journal = Physical Review D | volume = 2 | issue = 8| pages = 1418–25 | doi=10.1103/physrevd.2.1418|bibcode = 1970PhRvD...2.1418P }}
* A. Peres, ''Quantum Theory: Concepts and Methods'', Kluwer, Dordrecht, 1993.
* P. Pluch, ''Theory of Quantum Probability'', PhD Thesis, University of Klagenfurt, 2006.
* B. C. van Frassen, ''Quantum Mechanics'', Clarendon Press, 1991.
* {{cite journal | last1 = Rowe | first1 = M.A. | last2 = Kielpinski | first2 = D. | last3 = Meyer | first3 = V. | last4 = Sackett | first4 = C.A. | last5 = Itano | first5 = W.M. | last6 = Monroe | first6 = C. | last7 = Wineland | first7 = D.J. | year = 2001 | title = Experimental violation of Bell's inequalities with efficient detection | url = | journal = Nature | volume = 409 | issue = 6822| pages = 791–794 | doi=10.1038/35057215|bibcode = 2001Natur.409..791K | pmid=11236986}}
* {{cite journal | last1 = Sulcs | first1 = S. | year = 2003 | title = The Nature of Light and Twentieth Century Experimental Physics | doi = 10.1023/A:1026323203487 | journal = Foundations of Science | volume = 8 | issue = 4| pages = 365–391 }}
* {{cite journal | last1 = Gröblacher | first1 = S. | display-authors = etal   | year = 2007 | title = An experimental test of non-local realism | url = | journal = Nature | volume = 446 | issue = 7138| pages = 871–875 | doi=10.1038/nature05677 | pmid=17443179|arxiv = 0704.2529 |bibcode = 2007Natur.446..871G }}
* {{cite journal | last1 = Matsukevich | first1 = D. N. | last2 = Maunz | first2 = P. | last3 = Moehring | first3 = D. L. | last4 = Olmschenk | first4 = S. | last5 = Monroe | first5 = C. | year = 2008 | title = Bell Inequality Violation with Two Remote Atomic Qubits | url = | journal = Phys. Rev. Lett. | volume = 100 | issue = 15| page = 150404 | doi=10.1103/physrevlett.100.150404|arxiv = 0801.2184 |bibcode = 2008PhRvL.100o0404M | pmid=18518088}}
* The comic ''[[Dilbert]]'', by [[Scott Adams]], refers to Bell's Theorem in the [http://www.dilbert.com/strips/comic/1992-09-21/ 1992-09-21] and [http://www.dilbert.com/strips/comic/1992-09-22/ 1992-09-22] strips.
* {{Cite SEP|bell-theorem|title=Bell's Theorem|first = Abner | last = Shimony|author-link=Abner Shimony}}
{{Refend}}

== Further reading ==
The following are intended for general audiences.

* Amir D. Aczel, ''Entanglement: The greatest mystery in physics'' (Four Walls Eight Windows, New York, 2001).
* A. Afriat and F. Selleri, ''The Einstein, Podolsky and Rosen Paradox'' (Plenum Press, New York and London, 1999)
* J. Baggott, ''The Meaning of Quantum Theory'' (Oxford University Press, 1992)
* N. David Mermin, "Is the moon there when nobody looks? Reality and the quantum theory", in ''Physics Today'', April 1985, pp.&amp;nbsp;38–47.
* Louisa Gilder, ''The Age of Entanglement: When Quantum Physics Was Reborn'' (New York: Alfred A. Knopf, 2008)
* Brian Greene, ''The Fabric of the Cosmos'' (Vintage, 2004, {{ISBN|0-375-72720-5}})
* Nick Herbert, ''Quantum Reality: Beyond the New Physics'' (Anchor, 1987, {{ISBN|0-385-23569-0}})
* D. Wick, ''The infamous boundary: seven decades of controversy in quantum physics'' (Birkhauser, Boston 1995)
* R. Anton Wilson, ''Prometheus Rising'' (New Falcon Publications, 1997, {{ISBN|1-56184-056-4}})
* [[Gary Zukav]] "[[The Dancing Wu Li Masters]]" (Perennial Classics, 2001, {{ISBN|0-06-095968-1}})
* {{cite journal | last1 = Goldstein | first1 = Sheldon | display-authors = etal   | year = 2011| title = Bell's theorem | url = | journal = [[Scholarpedia]] | volume = 6 | issue = 10| page = 8378 | doi = 10.4249/scholarpedia.8378 |bibcode = 2011SchpJ...6.8378G }}

==External links==
{{wikibooks |Quantum_Mechanics }}
{{wikiversity |Bell's_theorem }}
{{Commons category|Optics}}
* "[https://web.archive.org/web/20131126021928/http://philoscience.unibe.ch/documents/TexteHS10/bell1964epr.pdf On the Einstein Podolsky Rosen Paradox]", Bell's original paper.
* [http://www.drchinese.com/David/Bell_Compact.pdf Another version of Bell's paper].
* [http://www.ncsu.edu/felder-public/kenny/papers/bell.html An explanation of Bell's Theorem], based on N. D. Mermin's article, {{cite journal |doi=10.1119/1.12594 |title=Bringing home the atomic world: Quantum mysteries for anybody |year=1981 |last1=Mermin |first1=N. D. |journal=American Journal of Physics |volume=49 |issue=10 |pages=940–943|bibcode = 1981AmJPh..49..940M }}
* [https://www.youtube.com/watch?v=ta09WXiUqcQ Mermin: Spooky Actions At A Distance? Oppenheimer Lecture ]
* [http://www.faculty.umb.edu/gary_zabel/Courses/Parallel%20Universes/Texts/Quantum%20Entanglement.htm Quantum Entanglement, by Dr Andrew H. Thomas].
* [http://drchinese.com/David/Bell_Theorem_Easy_Math.htm Bell's Theorem with Easy Math, by David R. Schneider]. Another simple explanation of Bell's Inequality.
* [http://xstructure.inr.ac.ru/x-bin/theme3.py?level=2&amp;index1=369244 Bell's theorem on arXiv.org]
* [http://www.didaktik.physik.uni-erlangen.de/quantumlab/english/index.html Interactive experiments with single photons: entanglement and Bell´s theorem]
* [http://plato.stanford.edu/entries/bell-theorem/ Article on Bell's theorem at Stanford encyclopedia of philosophy by Abner Shimony]
* [http://stats.stackexchange.com/questions/94143/rigorous-bell-chsh/ Discussion using a recent framework introduced by Gill]
* {{cite IEP |url-id=epr |title=Bell&amp;#39;s theorem}}
* {{springer|title=Bell inequalities|id=p/b110230}}
* [http://www.felderbooks.com/papers/bell.html Spooky Action at a Distance: an Explanation of Bell's Theorem]
{{authority control}}

{{DEFAULTSORT:Bell's Theorem}}
[[Category:Concepts in physics]]
[[Category:Quantum information science]]
[[Category:Quantum measurement]]
[[Category:Theorems in quantum physics]]
[[Category:Quantum mechanics]]
[[Category:Hidden variable theory]]
[[Category:Inequalities]]
[[Category:1964 introductions]]</text>
      <sha1>tm3pxdjqd2v9zohgyx8bsqa5sv3cy9y</sha1>
    </revision>
  </page>
  <page>
    <title>Categorical logic</title>
    <ns>0</ns>
    <id>1063799</id>
    <revision>
      <id>798861232</id>
      <parentid>783712290</parentid>
      <timestamp>2017-09-04T06:59:15Z</timestamp>
      <contributor>
        <username>Cic</username>
        <id>1968383</id>
      </contributor>
      <comment>/* External links */ Wiki link instead of external link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7676">{{About|mathematical logic in the context of category theory|Aristotle's system of logic|term logic}}
__NOTOC__
'''Categorical logic''' is the branch of [[mathematics]] in which tools and concepts from [[category theory]] are applied to the study of [[mathematical logic]]. It is also notable for its connections to [[theoretical computer science]]. In broad terms, categorical logic represents both syntax and semantics by a [[category (mathematics)|category]], and an [[Interpretation (logic)|interpretation]] by a [[functor]].  The categorical framework provides a rich conceptual background for logical and [[type theory|type-theoretic]] constructions. The subject has been recognisable in these terms since around 1970.

== Overview ==

There are three important&lt;!--to computer science --&gt; themes in the categorical approach to logic:
;Categorical semantics: Categorical logic introduces the notion of ''structure valued in a category'' C with the classical [[model theory|model theoretic]] notion of a structure appearing in the particular case where C is the [[Category of sets|category of sets and functions]]. This notion has proven useful when the set-theoretic notion of a model lacks generality and/or is inconvenient. [[R.A.G. Seely]]'s modeling of various [[impredicative]] theories, such as [[system F]] is an example of the usefulness of categorical semantics.

:It was found that the connectives of pre-categorical logic were more clearly understood using the concept of adjoint functor, and that the quantifiers were also best understood using adjoint functors.&lt;ref&gt;Lawvere, Quantifiers and Sheaves&lt;/ref&gt;

;Internal languages: This can be seen as a formalization and generalization of proof by [[diagram chasing]]. One defines a suitable internal language naming relevant constituents of a category, and then applies categorical semantics to turn assertions in a logic over the internal language into corresponding categorical statements. This has been most successful in the theory of [[topos]]es, where the internal language of a topos together with the semantics of intuitionistic higher-order logic in a topos enables one to reason about the objects and morphisms of a topos "as if they were sets and functions".{{Citation needed|reason=if this is an actual quote, who said it?|date=July 2015}} This has been successful in dealing with toposes that have "sets" with properties incompatible with classical logic. A prime example is [[Dana Scott]]'s model of [[untyped lambda calculus]] in terms of objects that retract onto their own function space. Another is the Moggi–Hyland model of [[system F]] by an internal [[full subcategory]] of the [[effective topos]] of [[Martin Hyland]].
;Term-model constructions: In many cases, the categorical semantics of a logic provide a basis for establishing a correspondence between [[Theory (mathematical logic)|theories]] in the logic and instances of an appropriate kind of category. A classic example is the correspondence between theories of [[beta reduction|βη]]-[[equational logic]] over [[simply typed lambda calculus]] and [[Cartesian closed category|Cartesian closed categories]]. Categories arising from theories via term-model constructions can usually be characterized up to [[Equivalence of categories|equivalence]] by a suitable [[universal property]]. This has enabled proofs of [[Metalogic|meta-theoretical]] properties of some logics by means of an appropriate [[:Category:monoidal categories|categorical algebra]]&lt;!--no good article--&gt;. For instance, [[Peter J. Freyd|Freyd]] gave a proof of the existence and disjunction properties of [[intuitionistic logic]] this way.

==See also==
* [[History of topos theory]]
{{Portal|Logic}}

==References==
;Books
*{{cite book 
|last1=Abramsky
|first1=Samson
|last2=Gabbay
|first2=Dov
|title=Handbook of Logic in Computer Science: Logic and algebraic methods
|publisher=Oxford University Press
|location=Oxford
|year=2001
|isbn=0-19-853781-6
|ref=harv}}

*{{cite book
|last=Gabbay
|first=Dov
|title=Handbook of the History of Logic: Sets and extensions in the twentieth century
|publisher=Elsevier
|location=Oxford
|year=2012
|isbn=978-0-444-51621-3
|ref=harv}}

*{{cite book
|last1=Kent
|first1=Allen
|last2=Williams
|first2=James G.
|title=Encyclopedia of Computer Science and Technology
|publisher=Marcel Dekker Inc.
|location=New York
|year=1990
|isbn=0-8247-2272-8
|ref=harv}}

* [[Michael Barr (mathematician)|Barr, M.]] and [[Charles Wells (mathematician)|Wells, C.]] (1990), ''Category Theory for Computing Science''. [[Hemel Hempstead]], UK.
* [[Joachim Lambek|Lambek, J.]] and [[P.J. Scott|Scott, P.J.]] (1986), ''Introduction to Higher Order Categorical Logic''. Cambridge University Press, Cambridge, UK.
* [[Francis William Lawvere|Lawvere, F.W.]], and [[Robert Rosebrugh|Rosebrugh, R.]] (2003), ''Sets for Mathematics''. Cambridge University Press, Cambridge, UK.
* [[Francis William Lawvere|Lawvere, F.W.]] (2000), and [[Stephen H. Schanuel|Schanuel, S.H.]], ''Conceptual Mathematics: A First Introduction to Categories''. Cambridge University Press, Cambridge, UK, 1997. Reprinted with corrections, 2000.

'''Seminal papers'''
*  [[Francis William Lawvere|Lawvere, F.W.]], ''Functorial Semantics of Algebraic Theories''. In ''Proceedings of the National Academy of Sciences'' 50, No. 5 (November 1963), 869-872.
*  [[Francis William Lawvere|Lawvere, F.W.]], ''Elementary Theory of the Category of Sets''. ''In Proceedings of the National Academy of Sciences 52'', No. 6 (December 1964), 1506-1511.
*  [[Francis William Lawvere|Lawvere, F.W.]], ''Quantifiers and Sheaves''. In ''Proceedings of the International Congress on Mathematics (Nice 1970)'', Gauthier-Villars (1971) 329-334.

== Notes ==
{{reflist}}

== Further reading ==
* [[Michael Makkai]] and Gonzalo E. Reyes, 1977, ''First order categorical logic'', Springer-Verlag.
* [[Joachim Lambek|Lambek, J.]] and Scott, P. J., 1986. ''Introduction to [[higher-order logic|Higher Order]] Categorical Logic''. Fairly accessible introduction, but somewhat dated. The categorical approach to higher-order logics over polymorphic and dependent types was developed largely after this book was published.
*{{cite book
  | first = Bart
  | last = Jacobs
  | title = Categorical Logic and Type Theory
  | year = 1999
  | publisher = North Holland, Elsevier
  | isbn =  0-444-50170-3
  | series = Studies in Logic and the Foundations of Mathematics 141
  | url = http://www.cs.ru.nl/B.Jacobs/CLT/bookinfo.html }} A comprehensive monograph written by a computer scientist; it covers both first-order and higher-order logics, and also polymorphic and dependent types. The focus is on [[fibred category]] as universal tool in categorical logic, which is necessary in dealing with polymorphic and dependent types.

* [[John Lane Bell]] (2005) ''The Development of Categorical Logic''. Handbook of Philosophical Logic, Volume 12. Springer. Version available [http://publish.uwo.ca/~jbell/catlogprime.pdf online] at [http://publish.uwo.ca/~jbell/ John Bell's homepage.]
* Jean-Pierre Marquis and Gonzalo E. Reyes (2012). ''The History of Categorical Logic 1963–1977''. Handbook of the History of Logic: Sets and Extensions in the Twentieth Century, Volume 6, D. M. Gabbay, A. Kanamori &amp; J. Woods, eds., North-Holland, pp.&amp;nbsp;689–800. A preliminary version is available at [http://www.webdepot.umontreal.ca/Usagers/marquisj/MonDepotPublic/HistofCatLog.pdf].

==External links==
* [http://www.andrew.cmu.edu/user/awodey/catlog/ Categorical Logic] lecture notes by [[Steve Awodey]]

[[Category:Systems of formal logic]]
[[Category:Theoretical computer science]]
[[Category:Categorical logic| ]]</text>
      <sha1>ad4vtzlavil99bf2c3f41lcbvgtfear</sha1>
    </revision>
  </page>
  <page>
    <title>Complex geodesic</title>
    <ns>0</ns>
    <id>11568881</id>
    <revision>
      <id>729252113</id>
      <parentid>532051437</parentid>
      <timestamp>2016-07-10T23:37:07Z</timestamp>
      <contributor>
        <username>Dcirovic</username>
        <id>11795905</id>
      </contributor>
      <minor/>
      <comment>/* References */refs using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2375">In [[mathematics]], a '''complex geodesic''' is a generalization of the notion of [[geodesic]] to [[complex number|complex]] spaces.

==Definition==
Let (''X'',&amp;nbsp;||&amp;nbsp;||) be a complex [[Banach space]] and let ''B'' be the [[open set|open]] [[unit ball]] in ''X''. Let Δ denote the open unit disc in the [[Complex plane#Other meanings of "complex plane"|complex plane]] '''C''', thought of as the [[Poincaré disc model]] for 2-dimensional real/1-dimensional complex [[hyperbolic geometry]]. Let the Poincaré metric ''ρ'' on Δ be given by

:&lt;math&gt;\rho (a, b) = \tanh^{-1} \frac{| a - b |}{|1 - \bar{a} b |}&lt;/math&gt;

and denote the corresponding [[Carathéodory metric]] on ''B'' by ''d''. Then a [[holomorphic function]] ''f''&amp;nbsp;:&amp;nbsp;Δ&amp;nbsp;→&amp;nbsp;''B'' is said to be a '''complex geodesic''' if

:&lt;math&gt;d(f(w), f(z)) = \rho (w, z) \,&lt;/math&gt;

for all points ''w'' and ''z'' in Δ.

==Properties and examples of complex geodesics==
* Given ''u''&amp;nbsp;∈&amp;nbsp;''X'' with ||''u''||&amp;nbsp;=&amp;nbsp;1, the map ''f''&amp;nbsp;:&amp;nbsp;Δ&amp;nbsp;→&amp;nbsp;''B'' given by ''f''(''z'')&amp;nbsp;=&amp;nbsp;''zu'' is a complex geodesic.
* Geodesics can be reparametrized: if ''f'' is a complex geodesic and ''g''&amp;nbsp;∈&amp;nbsp;Aut(Δ) is a bi-holomorphic [[automorphism]] of the disc Δ, then ''f''&amp;nbsp;&lt;small&gt;o&lt;/small&gt;&amp;nbsp;''g'' is also a complex geodesic. In fact, any complex geodesic ''f''&lt;sub&gt;1&lt;/sub&gt; with the same image as ''f'' (i.e., ''f''&lt;sub&gt;1&lt;/sub&gt;(Δ)&amp;nbsp;=&amp;nbsp;''f''(Δ)) arises as such a reparametrization of ''f''.
* If
::&lt;math&gt;d(f(0), f(z)) = \rho (0, z)&lt;/math&gt;
:for some ''z''&amp;nbsp;&amp;ne;&amp;nbsp;0, then ''f'' is a complex geodesic.
*If
::&lt;math&gt;\alpha (f(0), f'(0)) = 1,&lt;/math&gt;
:where ''&amp;alpha;'' denotes the Caratheodory length of a tangent vector, then ''f'' is a complex geodesic.

==References==
* {{cite book
|   author = Earle, Clifford J. and Harris, Lawrence A. and Hubbard, John H. and Mitra, Sudeb
|  chapter = Schwarz's lemma and the Kobayashi and Carathéodory pseudometrics on complex Banach manifolds
|    title = Kleinian groups and hyperbolic 3-manifolds (Warwick, 2001)
|editor1=Komori, Y. |editor2=Markovic, V. |editor3=Series, C. |   series = London Math. Soc. Lecture Note Ser. 299
|    pages = 363&amp;ndash;384
|publisher = Cambridge Univ. Press
| location = Cambridge
|     year = 2003
}}

[[Category:Hyperbolic geometry]]
[[Category:Metric geometry]]</text>
      <sha1>06kuhwa8kl4iotbmf85xr3llcijczkr</sha1>
    </revision>
  </page>
  <page>
    <title>Computational photography</title>
    <ns>0</ns>
    <id>1059791</id>
    <revision>
      <id>860756541</id>
      <parentid>860123525</parentid>
      <timestamp>2018-09-22T20:56:30Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <comment>added [[Category:Computer vision]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13067">{{broader|Computational imaging}}

[[Image:Process nocomparam.png|299px|thumb|Computational ("undigital") photography provides many new capabilities. This example combines HDR (High Dynamic Range) Imaging with panoramics ([[image-stitching]]), by optimally combining information from multiple differently exposed pictures of overlapping subject matter&lt;ref&gt;[[Steve Mann]]. "Compositing Multiple Pictures of the Same Scene", Proceedings of the 46th Annual Imaging Science &amp; Technology Conference, May 9–14, Cambridge, Massachusetts, 1993&lt;/ref&gt;&lt;ref&gt;S. Mann, C. Manders, and J. Fung, "The Lightspace Change Constraint Equation (LCCE) with practical application to estimation of the projectivity+gain transformation between multiple pictures of the same subject matter" IEEE International Conference on Acoustics, Speech, and Signal Processing, 6–10 April 2003, pp III - 481-4 vol.3.&lt;/ref&gt;&lt;ref&gt;joint parameter estimation in both domain and range of functions in same orbit of the projective-Wyckoff group" ", IEEE International Conference on Image Processing,Vol.3, 16-19,pp.193-196 September 1996&lt;/ref&gt;&lt;ref&gt;Frank M. Candocia: Jointly registering images in domain and range by piecewise linear comparametric analysis. IEEE Transactions on Image Processing 12(4): 409-419 (2003)&lt;/ref&gt;&lt;ref&gt;Frank M. Candocia: Simultaneous homographic and comparametric alignment of multiple exposure-adjusted pictures of the same scene. IEEE Transactions on Image Processing 12(12): 1485-1494 (2003)&lt;/ref&gt;]]

'''Computational photography''' refers to digital image capture and processing techniques that use digital computation instead of optical processes. Computational photography can improve the capabilities of a camera, or introduce features that were not possible at all with film based photography, or reduce the cost or size of camera elements. Examples of computational photography include in-camera computation of digital [[panoramas]],&lt;ref&gt;Steve Mann and R. W. Picard. "Virtual bellows: constructing high-quality images from video.", In Proceedings of the IEEE First International Conference on Image ProcessingAustin, Texas, November 13–16, 1994&lt;/ref&gt; [[high-dynamic-range imaging|high-dynamic-range images]], and [[light field camera]]s. Light field cameras use novel optical elements to capture three dimensional scene information which can then be used to produce 3D images, enhanced [[depth of field|depth-of-field]], and selective de-focusing (or "post focus"). Enhanced depth-of-field reduces the need for mechanical [[focus (optics)|focusing]] systems. All of these features use computational imaging techniques.

The definition of computational photography has evolved to cover a number of
subject areas in [[computer graphics]], [[computer vision]], and applied
[[optics]].  These areas are given below, organized according to a taxonomy
proposed by [[Shree K. Nayar]]{{cn|date=November 2017}}.  Within each area is a list of techniques, and for
each technique one or two representative papers or books are cited.
Deliberately omitted from the
taxonomy are [[image processing]] (see also [[digital image processing]])
techniques applied to traditionally captured
images in order to produce better images.  Examples of such techniques are
[[image scaling]], dynamic range compression (i.e. [[tone mapping]]),
[[color management]], image completion (a.k.a. inpainting or hole filling),
[[image compression]],  [[digital watermarking]], and artistic image effects.
Also omitted are techniques that produce [[3D scanner|range data]],
[[voxel|volume data]], [[3D model]]s, [[light field|4D light fields]],
4D, 6D, or 8D [[Bidirectional reflectance distribution function|BRDF]]s, or other high-dimensional image-based representations. [[Epsilon Photography]] is a sub-field of computational photography.

==Computational illumination==

This is controlling photographic illumination in a structured fashion, then processing the captured images,
to create new images. The applications include image-based relighting, image enhancement, [[image deblurring]], geometry/material recovery and so forth.

High-dynamic-range imaging uses differently exposed pictures of the same scene to extend dynamic range.&lt;ref&gt;[http://wearcam.org/is_t95_myversion.pdf ON BEING `UNDIGITAL' WITH DIGITAL CAMERAS: EXTENDING DYNAMIC RANGE BY COMBINING DIFFERENTLY EXPOSED PICTURES, IS&amp;T's (Society for Imaging Science and Technology's) 48th annual conference, Cambridge, Massachusetts, May 1995, pages 422-428]&lt;/ref&gt;  Other examples include processing and merging differently illuminated images of the same subject matter ("lightspace").

==Computational optics==

This is capture of optically coded images, followed by computational decoding to produce new images.
[[Coded aperture]] imaging was mainly applied in astronomy or X-ray imaging to boost the image quality. Instead of a single pin-hole, a pinhole pattern is applied in imaging, and [[deconvolution]] is performed to recover the image.&lt;ref&gt;{{cite web|last1=Martinello|first1=Manuel|title=Coded Aperture Imaging|url=http://www.manemarty.com/Publications_files/Martinello_PhDThesis_small.pdf}}&lt;/ref&gt; In [[coded exposure imaging]], the on/off state of the shutter is coded to modify the kernel of [[motion blur]].&lt;ref&gt;{{cite web |url=http://web.media.mit.edu/~raskar/deblur/ |title=Coded Exposure Photography: Motion Deblurring using Fluttered Shutter |first1=Ramesh |last1=Raskar |first2=Amit |last2=Agrawal |first3=Jack |last3=Tumblin |year=2006 |accessdate=November 29, 2010}}&lt;/ref&gt; In this way motion deblurring becomes a [[well-conditioned problem]]. Similarly, in a lens based coded aperture, the aperture can be modified by inserting a [[broadband mask]].&lt;ref&gt;{{cite web |url=http://web.media.mit.edu/~raskar/Mask/ |title=Dappled Photography: Mask Enhanced Cameras for Heterodyned Light Fields and Coded Aperture Refocusing |first1=Ashok |last1=Veeraraghavan |first2=Ramesh |last2=Raskar |first3=Amit |last3=Agrawal |first4=Ankit |last4=Mohan |first5=Jack |last5=Tumblin |year=2007 |accessdate=November 29, 2010}}&lt;/ref&gt; Thus, out of focus deblurring becomes a [[well-conditioned problem]]. The coded aperture can also improve the quality in light field acquisition using Hadamard transform optics.

Coded aperture patterns can also be designed using color filters, in order to apply different codes at different wavelengths.&lt;ref&gt;{{Cite journal|last=Martinello|first=Manuel|last2=Wajs|first2=Andrew|last3=Quan|first3=Shuxue|last4=Lee|first4=Hank|last5=Lim|first5=Chien|last6=Woo|first6=Taekun|last7=Lee|first7=Wonho|last8=Kim|first8=Sang-Sik|last9=Lee|first9=David|year=2015|title=Dual Aperture Photography: Image and Depth from a Mobile Camera|url=http://www.manemarty.com/Publications_files/Martinello_ICCP2015_small.pdf|journal=International Conference on Computational Photography|volume=|pages=|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Chakrabarti|first=A.|last2=Zickler|first2=T.|year=2012|title=Depth and deblurring from a spectrally-varying depth-of-field.|url=|journal=IEEE European Conference on Computer Vision|volume=7576|pages=648–666|via=}}&lt;/ref&gt; This allows to increase the amount of light that reaches the camera sensor, compared to binary masks.

==Computational imaging==

Computational imaging is a set of imaging techniques that combine data acquisition and data processing to create the image of an object through indirect means to yield '''enhanced resolution''', additional information such as '''optical phase''' or 3D reconstruction. The information is often recorded without using a [[Optical Microscope|conventional optical microscope configuration]] or with limited datasets.

Computational imaging allows to go beyond physical limitations of optical systems, such as [[numerical aperture]]
&lt;ref&gt;Ou et al., [https://doi.org/10.1364/OE.23.003472 "High numerical aperture Fourier ptychography: principle, implementation and characterization"]''Optics Express 23, 3 (2015)&lt;/ref&gt;, or even obliterates the need for [[Lens_(optics)|optical elements]]
&lt;ref&gt;Boominathan et al., [https://www.ece.rice.edu/~vb10/documents/2016/Lensless_Imaging_Computaitonal_Renaissance.pdf "Lensless Imaging: A Computational Renaissance"] (2016)&lt;/ref&gt;.

For parts of the [[optical spectrum]] where imaging elements such as objectives are difficult to manufacture or [[image sensors]]  cannot be miniaturized, computational imaging provides useful alternatives, in fields such as [[X-Ray]]&lt;ref&gt;Miyakawa et al., [https://dx.doi.org/10.1364/OE.22.019803 "Coded aperture detector : an image sensor with sub 20-nm pixel resolution"], ''Optics Express'' 22, 16 (2014)&lt;/ref&gt; and [[Terahertz radiation|THz radiations]].

===Common techniques ===
Among common computational imaging techniques are [[Coded aperture|lensless imaging]], computational speckle imaging&lt;ref&gt;Katz et al., [https://dx.doi.org/10.1038/nphoton.2014.189 "Non-invasive single-shot imaging through scattering layers and around corners via speckle correlations"], ''Nature Photonics 8, 784–790 (2014)&lt;/ref&gt;, [[ptychography]] and [[Fourier ptychography]].

Computational imaging technique often draws on [[compressive sensing]] or [[phase retrieval]] techniques, where the angular spectrum of the object is being reconstructed. Other techniques are related to the field of computational imaging, such as [[digital holography]], [[computer vision]] and inverse problems such as [[tomography]].

==Computational processing==

This is processing of non-optically-coded images to produce new images.

==Computational sensors==

These are detectors that combine sensing and processing, typically in hardware, like the [[oversampled binary image sensor]]. &lt;!-- More detail would be welcome! --&gt;

==Early work in computer vision==

Although computational photography is a currently popular buzzword in computer graphics, many of its
techniques first appeared in the computer vision literature,
either under other names or within papers aimed at 3D shape analysis.

==Art history==
[[Image:Lightspace-wearcomp-lightcomb.jpg|100px|left|thumb|A 1981 wearable computational photography apparatus.]]
[[Image:Computational-photography-lightvectoring-as-art-form.jpg|200px|thumb|Wearable Computational Photography originated in the 1970s and early 1980s, and has evolved into a more recent art form. This picture was used on the cover of the John Wiley and Sons textbook on the subject.]]

Computational photography, as an art form, has been practiced by capture of differently exposed pictures of the same subject matter, and combining them together.  This was the insipiration for the development of the wearable computer in the 1970s and early 1980s. Computational photography was inspired by the work of [[Charles Wyckoff]], and thus computational photography datasets (e.g. differently exposed pictures of the same subject matter that are taken in order to make a single composite image) are sometimes referred to as Wyckoff Sets, in his honor.

Early work in this area (joint estimation of image projection and exposure value) was undertaken by Mann and Candoccia.

Charles Wyckoff devoted much of his life to creating special kinds of 3-layer photographic films that captured different exposures of the same subject matter. A picture of a nuclear explosion, taken on Wyckoff's film, appeared on the cover of [[Life Magazine]] and showed the dynamic range from dark outer areas to inner core.

==See also==
* [[Adaptive Optics]]
* [[Multispectral imaging]]
* [[Simultaneous localization and mapping]]
* [[Super-resolution microscopy]]
* [[Time-of-flight camera]]

==References==
{{Reflist}}

==External links==
* Nayar, Shree K. (2007). [http://www.cvl.iis.u-tokyo.ac.jp/mva/proceedings/2007CD/papers/04-01.pdf "Computational Cameras"], ''Conference on Machine Vision Applications''.
* [https://www.amazon.com/dp/1568813139/ ''Computational Photography'' (Raskar, R., Tumblin, J.,)], A.K. Peters.  In press.
* [http://graphics.stanford.edu/papers/lfphoto/comp-photo-articles/start-e.pdf Special issue on Computational Photography], IEEE Computer, August 2006.
* [http://www.computer.org/portal/web/computingnow/cgacfp1 Camera Culture and Computational Journalism: Capturing and Sharing Visual Experiences], IEEE CG&amp;A Special Issue, Feb 2011.
* Rick Szeliski (2010), ''[http://szeliski.org/Book/ Computer Vision: Algorithms and Applications]'', Springer.
* Computational Photography: Methods and Applications (Ed. Rastislav Lukac), CRC Press, 2010.
*[http://wearcam.org/textbook.htm Intelligent Image Processing] (John Wiley and Sons book information).
*[http://wearcam.org/comparam.htm Comparametric Equations].
*[http://www.dcs.shef.ac.uk/~guy/mscprojects/ GJB-1: Increasing the dynamic range of a digital camera by using the Wyckoff principle]
*[http://wearcam.org/dusting Examples of wearable computational photography as an art form]
*[https://web.archive.org/web/20060827204747/http://www.merl.com/people/raskar/photo/ Siggraph Course in Computational Photography]

[[Category:Digital photography]]
[[Category:Computational fields of study]]
[[Category:Computer vision]]</text>
      <sha1>5uwm0f79pubwa362ofgkuutle8rr7vl</sha1>
    </revision>
  </page>
  <page>
    <title>Conformal field theory</title>
    <ns>0</ns>
    <id>364774</id>
    <revision>
      <id>844300384</id>
      <parentid>843192203</parentid>
      <timestamp>2018-06-04T01:18:09Z</timestamp>
      <contributor>
        <ip>209.2.227.212</ip>
      </contributor>
      <comment>Completely incomprehensible article.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9504">{{Technical|date=June 2018}}

A '''conformal field theory''' ('''CFT''') is a [[quantum field theory]] that is [[Invariant (physics)|invariant]] under [[conformal map|conformal transformations]]. In [[two-dimensional geometry|two]] [[dimension]]s, there is an infinite-dimensional algebra of local conformal transformations, and conformal field theories can sometimes be exactly solved or classified.

Conformal field theory has important applications&lt;ref&gt;[[Paul Ginsparg]] (1989), ''Applied Conformal Field Theory''. {{arxiv|hep-th/9108028}}. Published in ''Ecole d'Eté de Physique Théorique: Champs, cordes et phénomènes critiques/Fields, strings and critical phenomena'' (Les Houches), ed. by [[E. Brézin]] and [[J. Zinn-Justin]],  Elsevier Science Publishers B.V.&lt;/ref&gt; to [[condensed matter physics]], [[statistical mechanics]], [[quantum statistical mechanics]], and  [[string theory]]. Statistical and condensed matter systems are indeed often conformally invariant at their [[critical point (thermodynamics)|thermodynamic]] or [[quantum critical point]]s.

==Scale invariance vs. conformal invariance==
While it is possible for a [[quantum field theory]] to be [[scale invariance|scale invariant]]  but not conformally-invariant, examples are rare.&lt;ref&gt;One physical example is the theory of elasticity in two and three dimensions (also known as the theory of a vector field without gauge invariance). See 
{{cite journal|author=Riva V, Cardy J|title=Scale and conformal invariance in field theory: a physical counterexample|journal=	Phys. Lett. B|volume=622|pages=339–342|year=2005|doi=10.1016/j.physletb.2005.07.010|arxiv=hep-th/0504197|bibcode = 2005PhLB..622..339R }}&lt;/ref&gt; For this reason, the terms are often used interchangeably in the context of quantum field theory, even though the scale symmetry group is smaller.

In some particular cases it is possible to prove that scale invariance implies conformal invariance in a quantum field theory, for example in [[unitarity (physics)|unitary]] [[compact space|compact]] conformal field theories in two dimensions.

== Dimensional considerations ==

=== Two dimensions ===
{{main|Two-dimensional conformal field theory}}
There are two versions of 2D CFT: 1) Euclidean, and 2) Lorentzian. The former applies to [[statistical mechanics]], and the latter to [[quantum field theory]]. The two versions are related by a [[Wick rotation]].

Two-dimensional CFTs are (in some way) invariant under an ''infinite-dimensional symmetry group''. For example, consider a CFT on the [[Riemann sphere]]. It has the [[Möbius transformation]]s as the conformal group, which is isomorphic to (the finite-dimensional) [[Möbius transformation|PSL(2,'''C''')]].

However, the infinitesimal conformal transformations&lt;ref&gt;Since the [[conformal Killing equation]]s in two dimensions, &lt;math&gt;\partial_\mu \xi_\nu + \partial_\nu \xi_\mu = \partial \cdot\xi \eta_{\mu \nu},~&lt;/math&gt; reduce to just the Cauchy-Riemann equations, &lt;math&gt;\partial_{\bar{z}} \xi(z) = 0 = \partial_z \xi (\bar{z}) &lt;/math&gt;, the infinity of modes of arbitrary analytic coordinate transformations &lt;math&gt;\xi(z)&lt;/math&gt; yield the infinity of [[Killing vector field]]s &lt;math&gt;z^n\partial_z&lt;/math&gt;.&lt;/ref&gt; form an '''infinite-dimensional algebra''', called the [[Witt algebra]], but this infinity of conformal transformations do not have global inverses on ℂ. Only the primary fields (or chiral fields) are invariant with respect to this full infinitesimal conformal group. Its generators are indexed by integers {{mvar|n}},
:&lt;math&gt;L_n=\oint_{z=0} \frac{dz}{2\pi i } z^{n+1} T_{zz}~,&lt;/math&gt;
where {{math|''T&lt;sub&gt;zz&lt;/sub&gt;''}} is the [[holomorphic functions|holomorphic]] part of the non-trace piece of the [[stress-energy tensor|energy momentum tensor]] of the theory.
E.g., for a free scalar field,  
:&lt;math&gt; T_{zz}= \tfrac{1}{2} (\partial_z \phi)^2 ~. &lt;/math&gt;

In most conformal field theories, a conformal anomaly, also known as a [[Weyl anomaly]], arises in the quantum theory. This results in the appearance of a nontrivial central charge, and the [[Witt algebra]] is [[Lie algebra extension#Virasoro algebra|extended]] to the [[Virasoro algebra]].

In Euclidean CFT, one has both a holomorphic and an antiholomorphic copy of the Virasoro algebra. In Lorentzian CFT, one has a left-moving and a right moving copy of the Virasoro algebra (spacetime is a cylinder, with space being a circle, and time a line).

This symmetry makes it possible to classify two-dimensional CFTs much more precisely than in higher dimensions. In particular, it is possible to relate the spectrum of primary operators in a theory to the value of the [[central charge]], {{mvar|c}}.

The [[Hilbert space]] of physical states is a unitary [[Module (mathematics)|module]] of the Virasoro algebra corresponding to a fixed value of ''c''. Stability requires that the energy spectrum of the [[Hamiltonian (quantum mechanics)|Hamiltonian]] be nonnegative. The modules of interest are the highest weight modules of the Virasoro algebra.

A chiral field is a holomorphic field ''W''(''z'') which transforms as
:&lt;math&gt;L_n W(z)=-z^{n+1} \frac{\partial}{\partial z} W(z) - (n+1)\Delta z^n W(z)&lt;/math&gt;
and
:&lt;math&gt;\bar L_n W(z)=0~.&lt;/math&gt;
Analogously, mutatis mutandis, for an antichiral field. {{mvar|Δ}} is called the ''conformal weight'' of the chiral field {{mvar|W}}.

Furthermore, it was shown by [[Alexander Zamolodchikov]] that there exists a function, C, which decreases monotonically under the [[renormalization group]] flow of a two-dimensional quantum field theory, and is equal to the central charge for a two-dimensional conformal field theory. This is known as the Zamolodchikov [[C-theorem]], and tells us that [[renormalization group flow]] in two dimensions is irreversible.

Frequently, we are not just interested in the operators, but we are also interested in the vacuum state, or in statistical mechanics, the thermal state. Unless ''c=0'', there can't possibly be any state which leaves the entire infinite dimensional conformal symmetry unbroken. The best we can come up with is a state which is invariant under L&lt;sub&gt;−1&lt;/sub&gt;, L&lt;sub&gt;0&lt;/sub&gt;, L&lt;sub&gt;1&lt;/sub&gt;, L&lt;sub&gt;i&lt;/sub&gt;, &lt;math&gt;i &gt; 1&lt;/math&gt;. This contains the Möbius subgroup. The rest of the conformal group is spontaneously broken.

Two-dimensional conformal field theories play an important role in statistical mechanics, where they describe critical points of many lattice models.

=== More than two dimensions ===

In ''d''&amp;#8239;&gt;&amp;#8239;2 dimensions, the conformal group is locally isomorphic to {{math|SO(''d''&amp;#8239;+&amp;#8239;1, 1 )}} in Euclidean signature, or {{math|SO(''d'', 2 )}} in Minkowski space.

Higher-dimensional conformal field theories are prominent in the [[AdS/CFT correspondence]], in which a gravitational theory in [[anti-de Sitter space]] (AdS) is equivalent to a conformal field theory on the AdS boundary. Notable examples are ''d''&amp;#8239;=&amp;#8239;4, [[N = 4 supersymmetric Yang–Mills theory]], which is dual to [[Type IIB string theory]] on AdS&lt;sub&gt;5&lt;/sub&gt;&amp;#8239;×&amp;#8239;S&lt;sup&gt;5&lt;/sup&gt;, and ''d''&amp;#8239;=&amp;#8239;3, ''N''&amp;#8239;=&amp;#8239;6 super-[[Chern–Simons theory]], which is dual to [[M-theory]] on AdS&lt;sub&gt;4&lt;/sub&gt;&amp;#8239;×&amp;#8239;S&lt;sup&gt;7&lt;/sup&gt;. (The prefix "super" denotes [[supersymmetry]], ''N'' denotes the degree of [[extended supersymmetry]] possessed by the theory, and d the number of space-time dimensions on the boundary.)

==Conformal symmetry==
[[Conformal symmetry]] is a symmetry under [[scale invariance]] and under the special [[conformal transformation]]s having the following relations.

: &lt;math&gt;[P_\mu,P_\nu]=0,&lt;/math&gt;
: &lt;math&gt;[D,K_\mu]=-K_\mu, &lt;/math&gt;
: &lt;math&gt;[D,P_\mu]=P_\mu,&lt;/math&gt;
: &lt;math&gt;[K_\mu,K_\nu]=0,&lt;/math&gt;
: &lt;math&gt;[K_\mu,P_\nu]=\eta_{\mu\nu}D-iM_{\mu\nu},&lt;/math&gt;

where &lt;math&gt;P&lt;/math&gt; generates [[translation (physics)|translation]]s, &lt;math&gt;D&lt;/math&gt; generates scaling transformations as a scalar and &lt;math&gt;K_\mu&lt;/math&gt; generates the special conformal transformations as a [[covariant vector]] under Lorentz transformation.

{{main|Conformal symmetry|Conformal Killing equation}}

== See also ==
* [[Logarithmic conformal field theory]]
* [[AdS/CFT correspondence]]
* [[Operator product expansion]]
* [[Vertex operator algebra]]
* [[WZW model]]
* [[Critical point (physics)|Critical point]]
* [[Boundary conformal field theory]]
* [[Primary field]]
* [[Superconformal algebra]]
* [[Conformal algebra]]
* [[Conformal bootstrap]]
* [[History of conformal field theory]]

== References ==
{{reflist}}

==Further reading==
* Martin Schottenloher, ''A Mathematical Introduction to Conformal Field Theory'', Springer-Verlag, Berlin, Heidelberg, 1997. {{ISBN|3-540-61753-1}}, 2nd edition 2008, {{ISBN|978-3-540-68625-5}}.
* P. Di Francesco, P. Mathieu, and D. Sénéchal, ''Conformal Field Theory'', Springer-Verlag, New York, 1997. {{ISBN|0-387-94785-X}}.
*[http://www.stringwiki.org/wiki/Conformal_Field_Theory Conformal Field Theory] page in [http://www.stringwiki.org/wiki/String_Theory_Wiki String Theory Wiki] lists books and reviews.
*{{cite journal |last= Rychkov|first=Slava |date=2016 |title= EPFL Lectures on Conformal Field Theory in D ≥ 3 Dimensions| journal=SpringerBriefs in Physics |doi=10.1007/978-3-319-43626-5|arxiv=1601.05000}}

==External links==
*{{Commonscat-inline}}

{{Statistical mechanics topics}}
{{Quantum field theories}}

{{DEFAULTSORT:Conformal Field Theory}}
[[Category:Conformal field theory| ]]
[[Category:Symmetry]]
[[Category:Scaling symmetries]]</text>
      <sha1>nv9qc1q3d3s85z5nwaj3hy4y4bqt38a</sha1>
    </revision>
  </page>
  <page>
    <title>Decrease and conquer</title>
    <ns>0</ns>
    <id>20831056</id>
    <redirect title="Divide and conquer algorithm" />
    <revision>
      <id>756898173</id>
      <parentid>598013144</parentid>
      <timestamp>2016-12-27T14:15:36Z</timestamp>
      <contributor>
        <username>AvicBot</username>
        <id>11952314</id>
      </contributor>
      <minor/>
      <comment>Bot: Fixing double redirect to [[Divide and conquer algorithm]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="104">#REDIRECT [[Divide and conquer algorithm#Decrease and conquer]] {{R to section}}
[[Category:Algorithms]]</text>
      <sha1>65gv587lxh4rhuvqxlle6x7jl1hr1p6</sha1>
    </revision>
  </page>
  <page>
    <title>Dixon's elliptic functions</title>
    <ns>0</ns>
    <id>51402829</id>
    <revision>
      <id>846567020</id>
      <parentid>837642023</parentid>
      <timestamp>2018-06-19T15:16:40Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2960">In mathematics, '''Dixon's elliptic functions''', are two [[doubly periodic function|doubly periodic]] [[meromorphic function|meromorphic functions]] on the [[complex plane]] that have [[regular hexagon]]s as repeating units: the plane can be [[tessellation|tiled]] by regular hexagons in such a way that the restriction of the function to such a hexagon is simply a [[shift operator|shift]] of its restriction to any of the other hexagons. This in no way contradicts the fact that a doubly periodic meromorphic function has a fundamental region that is a [[parallelogram]]: the vertices of such a parallelogram (indeed, in this case a rectangle) may be taken to be the centers of four suitably located hexgaons.

These functions are named after [[Alfred Cardew Dixon]],&lt;ref&gt;{{cite journal
 | last1 = van Fossen Conrad | first1 = Eric
 | last2 = Flajolet | first2 = Philippe | author2-link = Philippe Flajolet
 | arxiv = math/0507268
 | date = July 2005
 | journal = [[Séminaire Lotharingien de Combinatoire]]
 | mr = 2223029
 | page = Art. B54g, 44
 | title = The Fermat cubic, elliptic functions, continued fractions, and a combinatorial excursion
 | volume = 54| bibcode = 2005math......7268V}}&lt;/ref&gt; who introduced them in 1890.&lt;ref&gt;{{cite journal
 | first = A. C.
 | last = Dixon
 | authorlink = Alfred Cardew Dixon
 | title = On the doubly periodic functions arising out of the curve {{math|1=''x''&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''y''&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;1}}
 | journal = Quarterly Journal of Pure and Applied Mathematics
 | year = 1890
 | volume = XXIV
 | pages = 167–233
 | url = https://gdz.sub.uni-goettingen.de/id/PPN600494829_0024?tify={%22pages%22:%5b179%5d} }}&lt;/ref&gt;

Dixon's elliptic functions are denoted sm and cm, and they satisfy the following identities:

: &lt;math&gt; \operatorname{cm}^3(x) + \operatorname{sm}^3(x) = 1 &lt;/math&gt;
: &lt;math&gt; \operatorname{sm}\left( \frac{\pi_3} 3 - z \right) = \operatorname{cm}(z),&lt;/math&gt; where &lt;math&gt;\pi_3 = B\left( \frac 1 3, \frac 1 3\right)&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; is the [[Beta function]]
: &lt;math&gt; \operatorname{sm}\left( z \exp\left( \frac{2i\pi} 3\right) \right) = \exp\left( \frac{2i\pi} 3 \right) \operatorname{sm}(z) &lt;/math&gt;
: &lt;math&gt; \operatorname{cm} \left( z \exp\left( \frac{2i\pi} 3 \right) \right) = \operatorname{cm}(z) &lt;/math&gt;
: &lt;math&gt; \operatorname{sm}'(z) = \operatorname{cm}^2(z) &lt;/math&gt;
: &lt;math&gt; \operatorname{cm}'(z) = -\operatorname{sm}^2(z) &lt;/math&gt;
: &lt;math&gt; \operatorname{sm}(z) = \frac{6\wp\left( z; 0, \frac 1 {27} \right)}{1 - 3\wp'\left(z;0,\frac 1 {27} \right)} &lt;/math&gt;
: &lt;math&gt; \operatorname{cm}(z) = \frac{3\wp'\left( z;0,\frac 1 {27}\right) + 1}{3\wp'\left(z;0,\frac 1 {27}\right) - 1} &lt;/math&gt; where &lt;math&gt; \wp &lt;/math&gt; is [[Weierstrass's elliptic functions|Weierstrass's elliptic function]]

== See also ==

* [[Abel elliptic functions]]
* [[Jacobi elliptic functions]]
* [[Weierstrass elliptic functions]]

== Notes and references ==

{{reflist}}

[[Category:Complex analysis]]</text>
      <sha1>dcjojkbz8flks6zglobe2teqsxeraw5</sha1>
    </revision>
  </page>
  <page>
    <title>Eduard Heine</title>
    <ns>0</ns>
    <id>608289</id>
    <revision>
      <id>857345787</id>
      <parentid>857345746</parentid>
      <timestamp>2018-08-31T03:36:28Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5462">{{Infobox scientist
| name = Eduard Heine
| image = Heinrich Eduard Heine 1.jpg
| image_size = 250px
| caption = Heinrich Eduard Heine
| birth_date  = {{birth date|1821|3|16|df=y}} 
| birth_place = [[Berlin]], [[Prussia]]
| death_date  ={{death date and age|1881|10|21|1821|3|15|df=y}}
| death_place = [[Halle (Saale)|Halle]], [[Prussia]] 
| residence = [[Prussia]]
| nationality = [[Germany|German]]
| field = [[Mathematician]]
| work_institution = [[University of Bonn]]&lt;br/&gt;[[University of Halle]]
| alma_mater = [[University of Berlin]]
| doctoral_advisor = [[Enno Dirksen]]&lt;br/&gt;[[Martin Ohm]] 
| influences = [[Peter Gustav Lejeune Dirichlet]]
| doctoral_students = 
| notable_students = 
| known_for  = [[Uniform continuity]]
| prizes = Gauss Medal
| footnotes =
}}

'''Heinrich Eduard Heine''' (16 March 1821 &amp;ndash; October 1881) was a [[Germany|German]] [[mathematics|mathematician]].

Heine became known for results on [[special function]]s and in [[real analysis]]. In particular, he authored an important treatise on [[spherical harmonics]] and [[Legendre functions]] (''Handbuch der Kugelfunctionen''). He also investigated [[basic hypergeometric series]]. He introduced the [[Mehler–Heine formula]].

==Biography==
Heinrich Eduard Heine was born on 16 March 1821 in Berlin, as the eighth child of banker Karl Heine and his wife Henriette Märtens. Eduard was initially [[home schooled]], then studied at the Friedrichswerdersche [[Gymnasium (Germany)|Gymnasium]] and Köllnische Gymnasium in Berlin.&lt;ref name=Narins&gt;{{cite book| last = Narins| first = Brigham | title=World of mathematics | year=2001| publisher=Gale Group| location  = | isbn= 978-0-7876-5064-3| pages= 289}}&lt;/ref&gt; In 1838, after graduating from gymnasium, he enrolled at the [[University of Berlin]], but transferred to the [[University of Göttingen]] to attend the mathematics lectures of [[Carl Friedrich Gauss]] and [[Moritz Stern]]. In 1840 Heine returned to Berlin, where he studied mathematics under [[Peter Gustav Lejeune Dirichlet]], while also attending classes of [[Jakob Steiner]] and [[Johann Franz Encke]]. In 1842 he was awarded a [[Ph.D.]] by the University of Berlin for a thesis on [[differential equations]] submitted with [[Enno Dirksen]] and [[Martin Ohm]] as advisors. Heine dedicated the doctoral thesis to his professor Gustav Dirichlet. Next he went to the [[University of Königsberg]] to participate in the mathematical seminar of [[Carl Gustav Jacob Jacobi|Carl Gustav Jacobi]], while also following [[mathematical physics]] classes of [[Franz Ernst Neumann]]. In [[Königsberg]] Heine got in contact with fellow students [[Gustav Kirchhoff]] and [[Philipp Ludwig von Seidel]].&lt;ref name=Halle&gt;{{cite web   | last = Goebel | first = M. | authorlink = |author2=Ka Richter |author3=H. Schlosser   | title = Heinrich Eduard Heine (1821–1881) | work = | publisher = [[University of Halle]]  | url = http://www.mathematik.uni-halle.de/history/heine/index.html | doi = | accessdate = 2011-12-07}}&lt;/ref&gt;

In 1844 Heine went for a teaching position at the [[University of Bonn]], passing his [[habilitation]] and starting as a [[privatdozent]]. He continued his research in mathematics in Bonn and, in 1848, was promoted to [[extraordinary professor]]. In 1850 he married Sophie Wolff, the daughter of a Berlin merchant; the couple had five children, four daughters and one son. In 1856 Heine moved as a full professor to the [[University of Halle]], where he remained for the rest of his life. From 1864 to 1865, he served as a rector of the university. In 1875, the University of Göttingen offered Heine a mathematics chair but he decided to reject the offer and remain in Halle. In 1877, at the centenary of Gauss' birth, he was awarded the Gauss Medal for his research.&lt;ref name=Halle/&gt; Eduard Heine died on 21 October 1881 in Halle.&lt;ref name=Halle/&gt;

==Selected works==
* [http://www-gdz.sub.uni-goettingen.de/cgi-bin/digbib.cgi?PPN31520639X De aequationibus nonnullis differentialibus] (Berlin, 1842)
* [https://books.google.com/books?id=YE8DAAAAQAAJ&amp;pg=PA3&amp;dq=Eduard+Heine&amp;hl=en#PPR1,M1 Handbuch der Kugelfunctionen] (G. Reimer, Berlin, 1861)
* [http://historical.library.cornell.edu/cgi-bin/cul.math/docviewer?did=01990001&amp;view=50&amp;frames=0&amp;seq=4 Handbuch der Kugelfunctionen, Theorie und Anwendungen (Volume 1)] (2nd ed., G. Reimer, Berlin, 1878)
* [http://historical.library.cornell.edu/cgi-bin/cul.math/docviewer?did=01410002&amp;seq=4 Handbuch der Kugelfunctionen, Theorie und Anwendungen (Volume 2)] (2nd ed., G. Reimer, Berlin, 1881)

==See also==
*[[Heine–Borel theorem]]
*[[Heine–Cantor theorem]]
*[[Continuous function#Heine definition of continuity|Heine definition of continuity]]
*[[Heine's Reciprocal Square Root Identity]]
*[[List of things named after Eduard Heine]]

== References ==
{{reflist}}

==External links==
* {{MacTutor Biography|id=Heine}}
* {{MathGenealogy |id=45117}}

{{Authority control}}

{{DEFAULTSORT:Heine, Eduard}}
[[Category:1821 births]]
[[Category:1881 deaths]]
[[Category:German mathematicians]]
[[Category:19th-century German mathematicians]]
[[Category:Mathematical analysts]]
[[Category:People from Berlin]]
[[Category:People from the Province of Brandenburg]]
[[Category:University of Göttingen alumni]]
[[Category:Humboldt University of Berlin alumni]]
[[Category:University of Königsberg alumni]]
[[Category:University of Bonn faculty]]
[[Category:Martin Luther University of Halle-Wittenberg faculty]]</text>
      <sha1>1k5tyit9gygbn9wmtkmvwl1yyzovalg</sha1>
    </revision>
  </page>
  <page>
    <title>Empty type</title>
    <ns>0</ns>
    <id>24027503</id>
    <redirect title="Bottom type" />
    <revision>
      <id>309715884</id>
      <parentid>308631977</parentid>
      <timestamp>2009-08-24T03:09:18Z</timestamp>
      <contributor>
        <username>Pcap</username>
        <id>7417813</id>
      </contributor>
      <comment>[[Category:type theory]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="51">#REDIRECT [[Bottom type]]

[[Category:type theory]]</text>
      <sha1>rst1p2tweuq4ver60bfyhd8qyj48taa</sha1>
    </revision>
  </page>
  <page>
    <title>Epipolar geometry</title>
    <ns>0</ns>
    <id>7889445</id>
    <revision>
      <id>871265078</id>
      <parentid>871246682</parentid>
      <timestamp>2018-11-29T22:53:32Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Clarify}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9382">{{broader|Computer stereo vision}}
[[File:Aufnahme mit zwei Kameras.svg|thumb|right|250px|Typical use case for epipolar geometry&lt;br /&gt;&lt;small&gt;Two cameras take a picture of the same scene from different points of view. The epipolar geometry then describes the relation between the two resulting views.&lt;/small&gt;]]
'''Epipolar geometry''' is the geometry of [[stereo vision#Computer stereo vision|stereo vision]].  When two cameras view a 3D scene from two distinct positions, there are a number of geometric relations between the 3D points and their projections onto the 2D images that lead to constraints between the image points.  These relations are derived based on the assumption that the cameras can be approximated by the [[pinhole camera model]].

==Epipolar geometry==
The [[Epipolar geometry#Epipolar constraint and triangulation|figure below]] depicts two pinhole cameras looking at point '''X'''. In real cameras, the image plane is actually behind the focal center, and produces an image that is the symmetry about the focal center of the lens.  Here, however, the problem is simplified by placing a ''virtual image plane'' in front of the focal center i.e. [[optical center]] of each camera lens to produce an image not transformed by the symmetry.  '''O'''&lt;sub&gt;L&lt;/sub&gt; and '''O'''&lt;sub&gt;R&lt;/sub&gt; represent the centers of symmetry of the two cameras lenses. '''X''' represents the point of interest in both cameras.  Points '''x'''&lt;sub&gt;L&lt;/sub&gt; and '''x'''&lt;sub&gt;R&lt;/sub&gt; are the projections of point '''X''' onto the image planes.

Each camera captures a 2D image of the 3D world. This conversion from 3D to 2D is referred to as a [[perspective projection]] and is described by the pinhole camera model. It is common to model this projection operation by rays that emanate from the camera, passing through its focal center.  Note that each emanating ray corresponds to a single point in the image.

=== Epipole or epipolar point ===
Since the optical centers  of the cameras lenses are distinct, each center projects onto a distinct point into the other camera's image plane.  These two image points, denoted by '''e'''&lt;sub&gt;L&lt;/sub&gt; and '''e'''&lt;sub&gt;R&lt;/sub&gt;, are called ''epipoles'' or ''epipolar points''.  Both epipoles '''e'''&lt;sub&gt;L&lt;/sub&gt; and '''e'''&lt;sub&gt;R&lt;/sub&gt; in their respective image planes and both optical centers '''O'''&lt;sub&gt;L&lt;/sub&gt; and '''O'''&lt;sub&gt;R&lt;/sub&gt; lie on a single 3D line.

=== Epipolar line ===
The line '''O'''&lt;sub&gt;L&lt;/sub&gt;–'''X''' is seen by the left camera as a point because it is directly in line with that camera's lens optical center. However, the right camera sees this line as a line in its image plane.  That line ('''e'''&lt;sub&gt;R&lt;/sub&gt;–'''x'''&lt;sub&gt;R&lt;/sub&gt;) in the right camera is called an ''epipolar line''.  Symmetrically, the line '''O'''&lt;sub&gt;R&lt;/sub&gt;–'''X''' seen by the right camera as a point is seen as epipolar line '''e'''&lt;sub&gt;L&lt;/sub&gt;–'''x'''&lt;sub&gt;L&lt;/sub&gt;by the left camera.

An epipolar line is a function of the position of point '''X''' in the 3D space, i.e. as '''X''' varies  a set of epipolar lines is generated in both images.  Since the 3D line
'''O'''&lt;sub&gt;L&lt;/sub&gt;–'''X''' passes through the optical center of the lens '''O'''&lt;sub&gt;L&lt;/sub&gt;, the corresponding epipolar line in the right image must pass through the epipole '''e'''&lt;sub&gt;R&lt;/sub&gt; (and correspondingly for epipolar lines in the left image).  All epipolar lines in one image contain the epipolar point of that image.  In fact, any line which contains the epipolar point is an epipolar line since it can be derived from some 3D point '''X'''.

=== Epipolar plane ===
As an alternative visualization, consider the points '''X''', '''O'''&lt;sub&gt;L&lt;/sub&gt; &amp; '''O'''&lt;sub&gt;R&lt;/sub&gt; that form a plane called the ''epipolar plane''. The epipolar plane intersects each camera's image plane where it forms lines—the epipolar lines.  All epipolar planes and epipolar lines intersect the epipole regardless of where '''X''' is located.

=== Epipolar constraint and triangulation ===
[[File:Epipolar geometry.svg|thumb|right|250px|Epipolar geometry]]
If the relative position of the two cameras is known, this leads to two important observations:

* Assume the projection point '''x'''&lt;sub&gt;L&lt;/sub&gt; is known, and the epipolar line '''e'''&lt;sub&gt;R&lt;/sub&gt;–'''x'''&lt;sub&gt;R&lt;/sub&gt; is known and the point '''X''' projects into the right image, on a point '''x'''&lt;sub&gt;R&lt;/sub&gt; which must lie on this particular epipolar line.  This means that for each point observed in one image the same point must be observed in the other image on a known epipolar line.  This provides an ''epipolar constraint'': the projection of X on the right camera plane '''x'''&lt;sub&gt;R&lt;/sub&gt; must be contained in the '''e'''&lt;sub&gt;R&lt;/sub&gt;–'''x'''&lt;sub&gt;R&lt;/sub&gt; epipolar line. Note also that all points X e.g. '''X'''&lt;sub&gt;1&lt;/sub&gt;, '''X'''&lt;sub&gt;2&lt;/sub&gt;, '''X'''&lt;sub&gt;3&lt;/sub&gt; on the '''O'''&lt;sub&gt;L&lt;/sub&gt;–'''X'''&lt;sub&gt;L&lt;/sub&gt; line will verify that constraint. It means that it is possible to test if two points correspond to the same 3D point.  Epipolar constraints can also be described by the [[essential matrix]] or the [[fundamental matrix (computer vision)|fundamental matrix]] between the two cameras.
* If the points '''x'''&lt;sub&gt;L&lt;/sub&gt; and '''x'''&lt;sub&gt;R&lt;/sub&gt; are known, their projection lines are also known.  If the two image points correspond to the same 3D point '''X''' the projection lines must intersect precisely at '''X'''.  This means that '''X''' can be calculated from the coordinates of the two image points, a process called ''[[Triangulation (computer vision)|triangulation]]''.

=== Simplified cases ===
[[File:Epipolar Geometry1.svg|thumb|right|300px|'''Example of epipolar geometry.''' This paragraph needs clarification as the content is not clear: if the two camera plane coincide{{clarify|reason=The planes in this figure do not coincide, i.e., their normal vectors are not parallel. Is this caption attempting to describe the figure?|date=November 2018}} then the two epipoles are undetermined as intersection of one optical center of one camera with the other camera plane is not a point but a line. 
Two cameras, with their respective centers of projection points '''O'''&lt;sub&gt;L&lt;/sub&gt; and '''O'''&lt;sub&gt;R&lt;/sub&gt;, observe a point '''P'''.  The projection of '''P''' onto each of the image planes is denoted '''p'''&lt;sub&gt;L&lt;/sub&gt; and '''p'''&lt;sub&gt;R&lt;/sub&gt;.  Points '''E'''&lt;sub&gt;L&lt;/sub&gt; and '''E'''&lt;sub&gt;R&lt;/sub&gt; are the epipoles.]]
The epipolar geometry is simplified if the two camera image planes coincide. In this case, the epipolar lines also coincide ('''E'''&lt;sub&gt;L&lt;/sub&gt;–'''P'''&lt;sub&gt;L&lt;/sub&gt; = '''E'''&lt;sub&gt;R&lt;/sub&gt;–'''P'''&lt;sub&gt;R&lt;/sub&gt;).  Furthermore, the epipolar lines are parallel to the line '''O'''&lt;sub&gt;L&lt;/sub&gt;–'''O'''&lt;sub&gt;R&lt;/sub&gt; between the centers of projection, and can in practice be aligned with the horizontal axes of the two images.  This means that for each point in one image, its corresponding point in the other image can be found by looking only along a horizontal line.  If the cameras cannot be positioned in this way, the image coordinates from the cameras may be transformed to emulate having a common image plane.  This process is called [[image rectification]].

=== Epipolar geometry of pushbroom sensor ===
In contrast to the conventional frame camera which uses a two-dimensional CCD, [[Push broom scanner|pushbroom camera]] adopts an array of one-dimensional CCDs to produce long continuous image strip which is called "image carpet". Epipolar geometry of this sensor is quite different from that of pinhole projection cameras. First, the epipolar line of pushbroom sensor is not straight, but hyperbola-like curve. Second, epipolar 'curve' pair does not exist.&lt;ref&gt;Jaehong Oh. [http://etd.ohiolink.edu/view.cgi?acc_num=osu1306250594 "Novel Approach to Epipolar Resampling of HRSI and Satellite Stereo Imagery-based Georeferencing of Aerial Images"], 2011, accessed 2011-08-05.&lt;/ref&gt;

== See also ==

* [[3D reconstruction]]
* [[3D reconstruction from multiple images]]
* [[3D scanner]]
* [[Binocular disparity]]
* [[Photogrammetry]]

==References==
{{reflist}}

==Further reading==
{{More footnotes|date=July 2009}}
*{{cite book |
author=Richard Hartley and Andrew Zisserman |
title=Multiple View Geometry in computer vision |
publisher=Cambridge University Press|
year=2003 |
isbn=0-521-54051-8}}

*{{cite web|
author=Quang-Tuan Luong|
title=Learning Epipolar Geometry|
url=http://www.ai.sri.com/~luong/research/Meta3DViewer/EpipolarGeo.html|
work=[[Artificial Intelligence Center]]|
publisher=[[SRI International]]|
accessdate=2007-03-04}}

*{{cite web|
author=Robyn Owens|
title=Epipolar geometry|
url=http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/OWENS/LECT10/node3.html|
accessdate=2007-03-04}}

*{{cite book |
author=[[Linda Shapiro|Linda G. Shapiro]] and George C. Stockman |
title=Computer Vision |
publisher=Prentice Hall|
year=2001 |
isbn=0-13-030796-3|
pages=395–403}}

*{{cite book |
author=Vishvjit S. Nalwa |
title=A Guided Tour of Computer Vision |
publisher=Addison Wesley|
year=1993 |
isbn=0-201-54853-4|
pages=216–240}}

*{{cite book |
author=Roberto Cipolla and Peter Giblin  |
title=Visual motion of curves and surfaces | 
publisher=Cambridge University Press, Cambridge | 
year=2000 |
isbn=0-521-63251-X}}

{{Authority control}}

{{DEFAULTSORT:Epipolar Geometry}}
[[Category:Geometry in computer vision]]
[[Category:Stereophotogrammetry]]</text>
      <sha1>dpvybxxum6wuvjs7vo97804a59io0oy</sha1>
    </revision>
  </page>
  <page>
    <title>Erdős Prize</title>
    <ns>0</ns>
    <id>23831652</id>
    <revision>
      <id>827612567</id>
      <parentid>788914286</parentid>
      <timestamp>2018-02-25T19:05:19Z</timestamp>
      <contributor>
        <ip>109.67.222.236</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2274">{{Primary sources|date=August 2009}}
: ''Not to be confused with '''[[Paul Erdős Prize]]''' of the [[Hungarian Academy of Sciences]]'' or ''[[Paul Erdős Award]]'' of the ''[[World Federation of National Mathematics Competitions]]''

{{Infobox award
| name        = Anna and Lajos Erdős Prize in Mathematics
| image       = 
| description = mathematics and computer science
| presenter   = Israel Mathematical Union 
| country     = [[Israel]]
| year        = 1977 
| website     = {{url|http://imu.org.il/Prizes/ErdosPrize/}}
}}
The '''Anna and Lajos Erdős Prize in Mathematics''' is a prize given by the [[Israel Mathematical Union]] to an [[Israel]]i [[mathematician]] (in any field of [[mathematics]] and [[computer science]]), "with preference to candidates up to the age of 40."  The prize was established by [[Paul Erdős]] in 1977 in honor of his parents, and is awarded annually or biannually.  The name was changed from "Erdős Prize" in 1996, after Erdős's death, to reflect his original wishes.

== Erdős Prize recipients ==
Source: [https://imudotorgdotil.wordpress.com/Prizes/ Israel Mathematical Union]
{{Columns-list|colwidth=20em|
* [[Saharon Shelah]] (1977)
* [[Eliyahu Rips|Ilya Rips]] (1979)
* [[Ofer Gabber]] (1981)
* [[Adi Shamir]] (1983)
* [[Shmuel Kiro]] (1985)
* [[Yosef Yomdin]] (1987)
* [[Noga Alon]] (1989)
* [[Alexander Lubotzky]] (1990)
* [[Gil Kalai]] (1992)
* [[Ehud Hrushovski]] (1994)
* [[Oded Schramm]] (1996)
* [[Leonid Polterovich]] (1998)
* [[Shahar Mozes]] (2000)
* [[Zeev Rudnick]] (2001)
* [[Ran Raz]] (2002)
* [[Zlil Sela]] (2003)
* [[Semyon Alesker]] (2004)
* [[Paul Biran]] (2006)
* [[Yehuda Shalom]] (2007)
* [[Gady Kozma]] (2008)
* [[Elon Lindenstrauss]] (2009)
* [[Boaz Klartag]] (2010)
* [[Tamar Ziegler]] (2011)
* [[Irit Dinur]] (2012)
* [[Omri Sarig]] (2013)
* [[Eran Nevo]] (2014)
* [[Mike Hochman]] (2015)
* [[Shiri Artstein-Avidan]] (2015)
* [[Emanuel Milman]] (2016)
* [[Nir Lev]] (2017)
* [[Ronen Eldan]] (2018)
}}

== See also ==
* [[List of things named after Paul Erdős]]

{{DEFAULTSORT:Erdos Prize}}
[[Category:Mathematics awards]]
[[Category:Awards established in 1977]]
[[Category:Israeli awards]]
[[Category:Lists of Israeli award winners]]
[[Category:Israeli science and technology awards]]

{{math-stub}}</text>
      <sha1>jx4d7wtdxbnl53k02dicsdylyo3hete</sha1>
    </revision>
  </page>
  <page>
    <title>Esakia duality</title>
    <ns>0</ns>
    <id>26600432</id>
    <revision>
      <id>862314830</id>
      <parentid>830065419</parentid>
      <timestamp>2018-10-03T15:44:28Z</timestamp>
      <contributor>
        <ip>134.59.11.233</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2522">In [[mathematics]], '''Esakia duality''' is the [[equivalence of categories|dual equivalence]] between the [[category (mathematics)|category]] of [[Heyting algebra]]s and the category of [[Esakia space]]s. Esakia duality provides an order-topological representation of Heyting algebras via Esakia spaces.

Let '''Esa''' denote the category of Esakia spaces and [[Esakia space#Esakia morphisms|Esakia morphisms]].

Let {{math|''H''}} be a Heyting algebra, {{math|''X''}} denote the set of [[prime ideal|prime filters]] of {{math|''H''}}, and {{math|&amp;le;}} denote set-theoretic inclusion on the prime filters of {{math|''H''}}. Also, for each {{math|''a''&lt;small&gt;&amp;isin;&lt;/small&gt; ''H''}}, let {{math|''&amp;phi;''(''a'')&amp;nbsp;{{=}}&amp;nbsp;{''x''&lt;small&gt;&amp;isin;&lt;/small&gt;&amp;nbsp;''X''&amp;nbsp;:&amp;nbsp;''a''&lt;small&gt;&amp;isin;&lt;/small&gt;&amp;nbsp;''x''}}}, and let {{math|''&amp;tau;''}} denote the topology on {{math|''X''}} generated by {{math| {''&amp;phi;''(''a''),&amp;nbsp;''X''&amp;nbsp;&amp;minus;&amp;nbsp;''&amp;phi;''(''a'')&amp;nbsp;:&amp;nbsp;''a''&lt;small&gt;&amp;isin;&lt;/small&gt;&amp;nbsp;''H''}}}.

Theorem:&lt;ref name=":0"&gt;{{cite journal|last=Esakia|first=Leo|date=1974|title=Topological kripke models|journal=Soviet Math|volume=15|issue=1|pages=147-151}}&lt;/ref&gt; {{math|(''X'', ''&amp;tau;'', &amp;le;)}} is an Esakia space, called the ''Esakia dual'' of {{math|''H''}}. Moreover, {{math|''&amp;phi;''}} is a Heyting algebra [[isomorphism]] from {{math|''H''}} onto the Heyting algebra of all [[clopen set|clopen]] [[up-set]]s of {{math|(''X'',''&amp;tau;'',&amp;le;)}}. Furthermore, each Esakia space is isomorphic in '''Esa''' to the Esakia dual of some Heyting algebra.

This representation of Heyting algebras by means of Esakia spaces is [[functorial]] and yields a dual equivalence between the category '''HA''' of Heyting algebras and Heyting algebra [[homomorphisms]] and the category '''Esa''' of Esakia spaces and Esakia morphisms.

Theorem:&lt;ref name=":0" /&gt;&lt;ref&gt;{{cite journal|last=Esakia|first=L|date=1985|title=Heyting Algebras I. Duality Theory|journal=Metsniereba, Tbilisi}}&lt;/ref&gt;&lt;ref&gt;{{cite book|url=https://pure.uva.nl/ws/files/3836071/40465_Bezhanishvili.pdf|title=Lattices of intermediate and cylindric modal logics|last=Bezhanishvili|first=N.|date=2006|publisher=Amsterdam Institute for Logic, Language and Computation (ILLC)|year=|isbn=978-90-5776-147-8|location=|pages=}}&lt;/ref&gt; '''HA''' is dually equivalent to '''Esa'''.

==References==
{{reflist}}


==See also==

* [[Duality theory for distributive lattices]]

{{DEFAULTSORT:Esakia Duality}}
[[Category:Topology]]
[[Category:Lattice theory]]</text>
      <sha1>m3xdwnhgg1wtexvhfbi611kcq2mbyxs</sha1>
    </revision>
  </page>
  <page>
    <title>Fetch-and-add</title>
    <ns>0</ns>
    <id>2050276</id>
    <revision>
      <id>845460242</id>
      <parentid>845459192</parentid>
      <timestamp>2018-06-11T23:15:49Z</timestamp>
      <contributor>
        <username>AllanGottlieb</username>
        <id>1277193</id>
      </contributor>
      <comment>/* History */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7240">In [[computer science]], the '''fetch-and-add''' [[Central processing unit|CPU]] instruction (FAA) [[atomic (computer science)|atomically]] increments the contents of a memory location by a specified value. 

That is, fetch-and-add performs the operation
:increment the value at address {{mvar|x}} by {{mvar|a}}, where {{mvar|x}} is a memory location and {{mvar|a}} is some value, and return the original value at {{mvar|x}}
in such a way that if this operation is executed by one process in a [[concurrent computing|concurrent]] system, no other process will ever see an intermediate result. 

Fetch-and-add can be used to implement [[concurrency control]] structures such as [[mutual exclusion|mutex locks]] and [[Semaphore (programming)|semaphores]].

==Overview==
The motivation for having an atomic fetch-and-add is that operations that appear in programming languages as

:{{mono|x {{=}} x + a}}

are not safe in a concurrent system, where multiple [[Process (computing)|processes]] or [[Thread (computing)|threads]] are running concurrently (either in a [[multi-processor]] system, or [[Preemption (computing)|preemptively]] scheduled onto some single-core systems). The reason is that such an operation is actually implemented as multiple machine instructions:

# Fetch the value at the location {{mvar|x}}, say {{math|''x''&lt;sub&gt;old&lt;/sub&gt;}}, into a register;
# add {{mvar|a}} to {{math|''x''&lt;sub&gt;old&lt;/sub&gt;}} in the register;
# store the new value of the register back into {{mvar|x}}.

When one process is doing {{mono|x {{=}} x + a}} and another is doing {{mono|x {{=}} x + b}} concurrently, there is a [[race condition]]. They might both fetch {{math|''x''&lt;sub&gt;old&lt;/sub&gt;}} and operate on that, then both store their results with the effect that one overwrites the other and the stored value becomes either {{math|''x''&lt;sub&gt;old&lt;/sub&gt; + ''a''}} or {{math|''x''&lt;sub&gt;old&lt;/sub&gt; + ''b''}}, not {{math|''x''&lt;sub&gt;old&lt;/sub&gt; + ''a'' + ''b''}} as might be expected.

In [[uniprocessor]] systems with no [[kernel preemption]] supported, it is sufficient to disable [[interrupt]]s before accessing a [[critical section]].
However, in multiprocessor systems (even with interrupts disabled) two or more processors could be attempting to access the same memory at the same time. The fetch-and-add instruction allows any processor to atomically increment a value in memory, preventing such multiple processor collisions.

[[Maurice Herlihy]] (1991) proved that fetch-and-add has a finite [[Consensus (computer science)|consensus]] number, in contrast to the [[compare-and-swap]] operation. The fetch-and-add operation can solve the wait-free consensus problem for no more than two concurrent processes.&lt;ref&gt;{{cite journal |last=Herlihy |first=Maurice |title=Wait-free synchronization |journal=ACM Trans. Program. Lang. Syst. |volume=13 |issue=1 |date=January 1991 |pages=124–149 |url=http://www.cs.brown.edu/~mph/Herlihy91/p124-herlihy.pdf |accessdate=2007-05-20 |doi=10.1145/114005.102808 }}&lt;/ref&gt;

==Implementation==
The fetch-and-add instruction behaves like the following function. Crucially, the entire function is executed [[atomic (computer science)|atomically]]: no process can interrupt the function mid-execution and hence see a state that only exists during the execution of the function. This code only serves to help explain the behaviour of fetch-and-add; atomicity requires explicit hardware support and hence can not be implemented as a simple high level function.

 &lt;&lt; atomic &gt;&gt;
 '''function''' FetchAndAdd(''address'' location, ''int'' inc) {
     ''int'' value := *location
     *location := value + inc
     '''return''' value
 }

To implement a mutual exclusion lock, we define the operation FetchAndIncrement, which is equivalent to FetchAndAdd with inc=1.
With this operation, a mutual exclusion lock can be implemented using the [[ticket lock]] algorithm as:

  '''record''' locktype {
     ''int'' ticketnumber
     ''int'' turn
  }
  '''procedure''' LockInit( ''locktype''* lock ) {
     lock.ticketnumber := 0
     lock.turn := 0
  }
  '''procedure''' Lock( ''locktype''* lock ) {
     ''int'' myturn := FetchAndIncrement( &amp;lock.ticketnumber ) //must be atomic, since many threads might ask for a lock at the same time
     '''while''' lock.turn ≠ myturn 
         '''skip''' // ''spin until lock is acquired''
  }
  '''procedure''' UnLock( ''locktype''* lock ) {
     FetchAndIncrement( &amp;lock.turn ) //this need not be atomic, since only the possessor of the lock will execute this
  }

These routines provide a mutual-exclusion lock when following conditions are met:
*Locktype data structure is initialized with function LockInit before use
*Number of tasks waiting for the lock does not exceed INT_MAX at any time
*Integer datatype used in lock values can 'wrap around' when continuously incremented

==Hardware and software support==
An atomic {{mono|fetch_add}} function appears in the [[C++11]] standard.&lt;ref&gt;{{cite web |title=std::atomic::fetch_add |website=cppreference.com |url=http://en.cppreference.com/w/cpp/atomic/atomic/fetch_add |accessdate=1 June 2015}}&lt;/ref&gt; It is available as a proprietary extension to [[C (programming language)|C]] in the [[Itanium]] [[Application binary interface|ABI]] specification,&lt;ref&gt;{{cite web |title=Intel Itanium Processor-specific Application Binary Interface (ABI) |publisher=[[Intel Corporation]] |year=2001 |url=http://download.intel.com/design/itanium/downloads/245370.pdf}}&lt;/ref&gt; and (with the same syntax) in [[GNU Compiler Collection|GCC]].&lt;ref&gt;{{cite web |title=Atomic Builtins |website=Using the GNU Compiler Collection (GCC) |publisher=Free Software Foundation |year=2005 |url=https://gcc.gnu.org/onlinedocs/gcc-4.1.2/gcc/Atomic-Builtins.html}}&lt;/ref&gt;

===x86 implementation===
In the x86 architecture, the instruction ADD with the destination operand specifying a memory location is a fetch-and-add instruction that has been there since the [[8086]] (it just wasn't called that then), and with the LOCK prefix, is atomic across multiple processors. However, it could not return the original value of the memory location (though it returned some flags) until the [[80486|486]] introduced the XADD instruction.

The following is a [[C (programming language)|C]] implementation for the [[GNU Compiler Collection|GCC]] compiler, for both 32 and 64 bit x86 Intel platforms, based on extended asm syntax:
&lt;source lang="c"&gt;
  static inline int fetch_and_add(int* variable, int value)
  {
      __asm__ volatile("lock; xaddl %0, %1"
        : "+r" (value), "+m" (*variable) // input+output
        : // No input-only
        : "memory"
      );
      return value;
  }
&lt;/source&gt;

===History===
fetch-and-add was introduced by the [[Ultracomputer]] project, which also produced a multiprocessor supporting fetch-and-add and containing custom vlsi switches that were able to combine concurrent memory references (including fetch-and-adds) to prevent them from serializing at the memory module containing the destination operand.

==See also==
*[[Test-and-set]]
*[[Test and Test-and-set]]
*[[Compare-and-swap]]
*[[Load-Link/Store-Conditional]]

==References==
&lt;references/&gt;

[[Category:Concurrency control]]
[[Category:Computer arithmetic]]


{{operating-system-stub}}</text>
      <sha1>cyjoro92had8iknpm48c9h0xbcxj4nq</sha1>
    </revision>
  </page>
  <page>
    <title>Gauss map</title>
    <ns>0</ns>
    <id>378881</id>
    <revision>
      <id>798974392</id>
      <parentid>756225384</parentid>
      <timestamp>2017-09-04T22:22:00Z</timestamp>
      <contributor>
        <username>Convex math</username>
        <id>31724689</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5185">{{About|differential geometry||}}
{{no footnotes|date=July 2011}}
[[Image:Gauss map.svg|thumb|400px|The Gauss map provides a mapping from every point on a curve or a surface to a corresponding point on a unit sphere]]
In [[differential geometry]], the '''Gauss map''' (named after [[Carl Friedrich Gauss|Carl F. Gauss]]) maps a [[Surface (topology)|surface]] in [[Euclidean space]] '''R'''&lt;sup&gt;3&lt;/sup&gt; to the unit [[sphere]] ''S''&lt;sup&gt;2&lt;/sup&gt;. Namely, given a surface ''X'' lying in '''R'''&lt;sup&gt;3&lt;/sup&gt;, the Gauss map is a continuous map ''N'': ''X'' → ''S''&lt;sup&gt;2&lt;/sup&gt; such that  ''N''(''p'') is a unit vector orthogonal to ''X'' at ''p'', namely the normal vector to ''X'' at ''p''.

The Gauss map can be defined (globally) if and only if the surface is [[orientable]], in which case its [[Degree of a continuous mapping|degree]] is half the [[Euler characteristic]]. The Gauss map can always be defined locally (i.e. on a small piece of the surface). The [[Jacobian matrix and determinant|Jacobian]] determinant of the Gauss map is equal to [[Gaussian curvature]], and the [[differential (calculus)|differential]] of the Gauss map is called the [[shape operator]].

Gauss first wrote a draft on the topic in 1825 and published in 1827.

There is also a Gauss map for a [[Link (knot theory)|link]], which computes [[linking number]].

==Generalizations==
The Gauss map can be defined for [[hypersurface]]s in '''R'''&lt;sup&gt;''n''&lt;/sup&gt; as a map from a hypersurface to the unit sphere ''S''&lt;sup&gt;''n'' &amp;minus; 1&lt;/sup&gt; &amp;nbsp;⊆&amp;nbsp; '''R'''&lt;sup&gt;''n''&lt;/sup&gt;.

For a general oriented ''k''-[[submanifold]] of '''R'''&lt;sup&gt;''n''&lt;/sup&gt; the Gauss map can also be defined, and its target space is the ''oriented'' [[Grassmannian]] 
&lt;math&gt;\tilde{G}_{k,n}&lt;/math&gt;, i.e. the set of all oriented ''k''-planes in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;. In this case a point on the submanifold is mapped to its oriented tangent subspace. One can also map to its oriented ''normal'' subspace; these are equivalent as &lt;math&gt;\tilde{G}_{k,n} \cong \tilde{G}_{n-k,n}&lt;/math&gt; via orthogonal complement.
In [[Euclidean space|Euclidean 3-space]], this says that an oriented 2-plane is characterized by an oriented 1-line, equivalently a unit normal vector (as &lt;math&gt;\tilde{G}_{1,n} \cong S^{n-1}&lt;/math&gt;), hence this is consistent with the definition above.

Finally, the notion of Gauss map can be generalized to an oriented submanifold ''X'' of dimension ''k'' in an oriented ambient [[Riemannian manifold]] ''M'' of dimension ''n''. In that case, the Gauss map then goes from ''X'' to the set of tangent ''k''-planes in the [[tangent bundle]] ''TM''. The target space for the Gauss map ''N'' is a [[Grassmann bundle]] built on the tangent bundle ''TM''. In the case where &lt;math&gt;M=\mathbf{R}^n&lt;/math&gt;, the tangent bundle is trivialized (so the Grassmann bundle becomes a map to the Grassmannian), and we recover the previous definition.

==Total curvature==
The area of the image of the Gauss map is called the '''total curvature''' and is equivalent to the [[surface integral]] of the [[Gaussian curvature]].  This is the original interpretation given by Gauss. The [[Gauss–Bonnet theorem]] links total curvature of a surface to its [[topology|topological]] properties.
:&lt;math&gt; \iint_R |N_u \times N_v| \ du\, dv = \iint_R K|X_u \times X_v| \ du\, dv = \iint_R K \ dA&lt;/math&gt;

==Cusps of the Gauss map==
The Gauss map reflects many properties of the surface: when the surface has zero Gaussian curvature, (that is along a [[parabolic line]]) the Gauss map will have a [[Catastrophe theory#Fold catastrophe|fold catastrophe]]. This fold may contain [[cusp (singularity)|cusps]] and these cusps were studied in depth by [[Thomas Banchoff]], [[Terence Gaffney]] and [[Clint McCrory]]. Both parabolic lines and cusp are stable phenomena and will remain under slight deformations of the surface. Cusps occur when:
#The surface has a bi-tangent plane
#A [[ridge (differential geometry)|ridge]] crosses a parabolic line
#at the closure of the set of inflection points of the [[asymptotic curve]]s of the surface.
There are two types of cusp: ''elliptic cusp'' and ''hyperbolic cusps''.

==References==
*Gauss, K. F., ''Disquisitiones generales circa superficies curvas'' (1827)
*Gauss, K. F., ''General investigations of curved surfaces'', English translation. Hewlett, New York: Raven Press (1965).
*Banchoff, T., Gaffney T., McCrory C., ''Cusps of the Gauss Map'', (1982) Research Notes in Mathematics 55, Pitman, London. [http://www.math.brown.edu/~dan/cgm/index.html online version]
*Koenderink, J. J., ''Solid Shape'', MIT Press (1990)

== External links ==
* {{MathWorld | urlname=GaussMap | title=Gauss Map}}
* {{cite book|author1=Thomas Banchoff|author2=Terence Gaffney|author3=Clint McCrory|author4=Daniel Dreibelbis|title=Cusps of Gauss Mappings|series=Research Notes in Mathematics|volume=55|date=1982|publisher=Pitman Publisher Ltd.|location=London|isbn=0-273-08536-0|url=http://www.emis.de/monographs/CGM/index.html|accessdate=4 March 2016}}

[[Category:Differential geometry]]
[[Category:Differential geometry of surfaces]]
[[Category:Riemannian geometry]]
[[Category:Surfaces]]
[[Category:Carl Friedrich Gauss]]</text>
      <sha1>htw83cgonq7cerd1vz1pw5yg8utlc7p</sha1>
    </revision>
  </page>
  <page>
    <title>Genetic method</title>
    <ns>0</ns>
    <id>51246780</id>
    <revision>
      <id>808300055</id>
      <parentid>797732353</parentid>
      <timestamp>2017-11-02T01:13:24Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <comment>ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9454">The '''genetic method''' is a method of [[teaching]] [[mathematics]] coined by [[Otto Toeplitz]] in 1927. As an alternative to the [[axiomatic system]], the method suggests using [[history of mathematics]] to deliver excitement and motivation and engage the class.

== History ==
[[File:Otto_Toeplitz_at_the_University_of_Bonn.jpg|thumb|right|Otto Toeplitz at the University of Bonn]]
Otto Toeplitz, a research mathematician in the area of [[functional analysis]], introduced the method in his manuscript "The problem of calculus courses at universities and their demarcation against calculus courses at high schools"{{sfn|Toeplitz|1927|p=92}} in 1927. A part of this manuscript was published in a book in 1949, after Toeplitz's death.

Toeplitz's method was not completely new at the time. In his 1895 talk{{sfn|Fricke|Vermell|1922|pp=246-254}} given at the public meeting of the royal society of sciences in Goettingen, "On the arithmetization of mathematics", the famous German mathematician [[Felix Klein]] suggested the idea "that on a small scale, a learner naturally and always has to repeat the same developments that the sciences went through on a large scale".{{sfn|Fricke|Vermell|1922|pp=246-254}}

In addition, the genetic method was occasionally applied in [[Gerhard Kowalewski]]'s book from 1909, "The classical problems of the analysis of the infinite".{{sfn|Kowalewski|1909}}

In 1962 the mathematics education in the US met a situation similar to that of Toeplitz in 1926 in Germany, in connection with the introduction of [[New_Math|"New Mathematics"]]. Shortly after the [[Sputnik crisis]], a "New Mathematics" reform was introduced to improve the level of mathematics education in the US, so that the threat of Soviet engineers, assumed to be well educated in mathematics, could be met. To prepare students for advanced mathematics, the curriculum shifted to focus on abstraction and rigor. One of the more reasonable responses to "New Mathematics" was a collective statement by [[Lipman Bers]], [[Morris Kline]], [[George Pólya]], and [[Max Schiffer]], cosigned by 61 others, that was published in "The Mathematics Teacher" and ''[[American_Mathematical_Monthly|The American Mathematical Monthly]]'' in 1962.{{sfn|Memorandum|1962}} In this letter, the undersigned called for the use of the genetic method:

{{quote|This may suggest a general principle: The best way to guide the mental development of the individual is to let him retrace  the mental development of its great lines, of course, and not the thousand errors of detail.{{sfn|Memorandum|1962|p=190}}}}

Also, in the 1980s, departments of mathematics in the US were facing criticism from other departments, especially departments in engineering, that they were failing too many of their students, and that those students that were certified as knowing calculus in fact had no idea how to apply its concepts in other classes. This led to the [[Reform_mathematics|"Calculus Reform"]] in the US.

== Motivation ==
[[File:Toeplitz_Classification_of_Mathematics_Students_in_1927.pdf|thumb|right|Otto Toeplitz' classification of German mathematics students in 1927]]
Otto Toeplitz had alleged that only 5% of the class can be reached by the traditional axiomatic approaches. To engage 45% of the students, he suggested to expose the students to the history of mathematics. The history of mathematics would give students an idea of the challenges and the elements of mathematics research process and applications. Furthermore, Toeplitz claimed that 50% of the students in universities were not 'reachable' and were 'unfit' for university education. The classification is illustrated in the picture.

== Variants ==
There are two recognised variants of the genetic method.

A '''direct''' genetic method displays the history of the development of mathematical concepts as a narrative. The history is taught step by step, exposing the class to each step that lead to the development of a mathematical concept. It is suggested to include confusions as a part of this method to demonstrate that mistakes and unsuccessful hypotheses are a part of the mathematics research process during the entire duration of mathematics history.

The '''indirect''' genetic method includes the same information as the direct one, but the confusions and problems throughout the development of each mathematical concept are analysed and the motivations for the correct resolution are discussed. More focus is given to the diagnosis of problems to allow students to diagnose problems in the current state of art in mathematics to form a part of their critical analysis skills in the field.

== References ==
=== Notes ===
{{Reflist}}

=== Sources ===
* {{cite book|last=Toeplitz|first=O|date=1927 |title=Das Problem der Universitaetsvorlesungen ueber Infinitesimalrechnung und ihrer Abgrenzung gegenueber der Infinitesimalrechnung an den hoeheren Schulen|url=https://www.digizeitschriften.de/dms/img/?PID=GDZPPN002127989|language=German|location=Leipzig|publisher=Teubner|pages=88–99|ref=harv}}
* {{cite book |last1=Fricke |first1= R|last2=Vermell|first2=H|date=1922 |title=Felix Klein Gesammelte Mathematische Abhandlungen: Zweiter Band|url=https://archive.org/download/gesammeltema02kleirich/gesammeltema02kleirich.pdf|language=German|location=Berlin |publisher=Springer|pages=232--240|ref=harv}}
* {{cite book |last=Kowalewski |first= G|date=1909 |title=Die klassischen Probleme der Analysis des Unendlichen|url=https://archive.org/details/dieklassischenpr00kowauoft|language=German|location=Leipzig |publisher=Wilhelm Engelmann Verlag|ref=harv}}

== Further reading ==
* {{cite book |last1=Bekken |first1= O B | last2=Mosvold |first2=R|date= 2003|title= Study The Masters-The Abel-Fauvel Conference Gimlekollen Mediacentre-Kristiansand June 12-15, 2002 |location=Goeteborg|publisher=Nationellt Centrum für Matematikutbildning|page= |isbn=978-9185143009|ref=harv}}
* {{cite book |last=Beyer |first= H R |date= 2010 |title= Calculus and Analysis: A Combined Approach  |url= http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470617950.html|location=New York |publisher= Wiley|page= |isbn=978-0-470-61795-3|ref=harv}}
* {{cite book |last1=Beyer |first1= H R |last2=Ruiz| first2=P H| last3=Beyer| first3=H M| date= 2014 |title= Matemáticas Para Todos: La Historia |language=Spanish|location=Morelia |publisher= Secretaría de Cultura de Michoacán|page= |isbn=978-607-8201-79-2|ref=harv}}
* {{cite journal |last=Fauvel |first=J |date=1991 |title= Using History in Mathematics Education|jstor=40248010|journal=For the Learning of Mathematics |publisher=FLM Publishing Association|volume=11|issue=2 |pages=3–6|ref=harv}}
* {{cite book |last1=Fauvel  |first1= J |last2= van Maanen| first2= J E (eds)|date= 2000 |title= History in Mathematics Education: The ICMI Study |url= https://www.springer.com/gp/book/9780792363996|location=New York |publisher= Springer|page= |isbn=978-0-7923-6399-6|ref=harv}}
* {{cite journal |last=Furinghetti |first=F |date=2000 |title= The History of Mathematics as a Coupling Link Between Secondary and University Teaching|jstor=40248010|journal=International Journal of Mathematical Education in Science and Technology |publisher=Taylor and Francis Ltd|volume=31|issue=1 |pages=43–51| doi=10.1080/002073900287372||ref=harv}}
* {{cite book |last=Katz |first= V J (ed.)|date= 2010 |title=Using history to teach mathematics: An international perspective |url=http://www.maa.org/press/books/using-history-to-teach-mathematics-an-international-perspective|location=New York |publisher=The Mathematical Association of America|page= |isbn=978-0883851630|ref=harv}}
* {{cite journal |last=Memorandum|date=1962 |title=On the Mathematics Curriculum of the High School |jstor=2311046|journal=The American Mathematical Monthly |publisher=Mathematical Association of America|volume=69|issue=3 |pages=189–193 | doi=10.2307/2311046|ref=harv}}
* {{cite journal |last=Moreno-Armella|first=L|date=2014 |title=An Essential Tension in Mathematics Education|url=https://link.springer.com/article/10.1007/s11858-014-0580-4|journal=Zentralblatt für Didaktik der Mathematik |publisher=Springer|volume=46|issue=4 |pages=621–633 | doi=10.1007/s11858-014-0580-4||ref=harv}}
* {{cite journal |last=Siu|first=M-K|date=1997 |title=The ABCD of using history of mathematics in the (undergraduate) classroom|url=http://hkumath.hku.hk/~mks/ABCD.pdf|journal=Bulletin of the Hong Kong Mathematical Society |publisher=Hong Kong Mathematical Society|volume=1|issue=1 |pages=143–154|ref=harv}}
* {{cite book|last=Toeplitz|first=O|date=1949 |title=Die Entwicklung der Infinitesimalrechnung:Eine Einleitung in die Infinitesimalrechnung Nach der Genetischen Methode. Erster Band |url=https://www.springer.com/de/book/9783642494963|language=German|location=Berlin|publisher=Springer|isbn=978-3-642-49496-3|ref=harv}}
* {{cite book|last=Toeplitz|first=O|date=1963 |title=The calculus: A genetic approach|url=http://press.uchicago.edu/ucp/books/book/chicago/C/bo5485725.html|location=Chicago|publisher=University of Chicago Press|isbn=9780226806686|ref=harv}}

== External links ==
* [http://horstbeyer.eu.pn/ Beyer, H R (October 2016), Teaching]
* [https://dspace01.hit.no/bitstream/handle/2282/1357/Rapp-2002-09.pdf?sequence=1, Mosvold R (2002), Genesis Principles in Mathematics Education]

&lt;!--- Categories ---&gt;

[[Category:Articles created via the Article Wizard]]
[[Category:Mathematics education]]</text>
      <sha1>s6hp949dndt2rcpljtza7emwf9t9gtr</sha1>
    </revision>
  </page>
  <page>
    <title>Geometric calculus</title>
    <ns>0</ns>
    <id>19363014</id>
    <revision>
      <id>869897847</id>
      <parentid>858384430</parentid>
      <timestamp>2018-11-21T02:41:36Z</timestamp>
      <contributor>
        <username>Volunteer1234</username>
        <id>30845620</id>
      </contributor>
      <comment>/* Relation to differential forms */ [[wp:noted]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14477">{{distinguish|matrix calculus|vector calculus|multiplicative calculus}}
{{Calculus |Multivariable}}

In [[mathematics]], '''geometric calculus''' extends the [[geometric algebra]] to include [[Derivative|differentiation]] and [[Integral|integration]].  The formalism is powerful and can be shown to encompass other mathematical theories including [[differential geometry]] and [[differential form]]s.&lt;ref&gt;[[David Hestenes]], Garrett Sobczyk: Clifford Algebra to Geometric Calculus, a Unified Language for mathematics and Physics (Dordrecht/Boston:G.Reidel Publ.Co., 1984, {{ISBN|90-277-2561-6}}&lt;/ref&gt;

==Differentiation==

With a geometric algebra given, let ''a'' and ''b'' be [[vector (mathematics and physics)|vectors]] and let ''F(a)'' be a [[multivector]]-valued function.  The [[directional derivative]] of ''F(a)'' along ''b'' is defined as

:&lt;math&gt;\nabla_b F(a) = \lim_{\epsilon \rightarrow 0}{\frac{F(a + \epsilon b) - F(a)}{\epsilon}},&lt;/math&gt;

provided that the limit exists, where the limit is taken for scalar ''ε''.  This is similar to the usual definition of a directional derivative but extends it to functions that are not necessarily scalar-valued.

Next, choose a set of [[basis vector]]s &lt;math&gt;\{e_i\}&lt;/math&gt; and consider the operators, noted &lt;math&gt;(\partial_i)&lt;/math&gt;, that perform directional derivatives in the directions of &lt;math&gt;(e_i)&lt;/math&gt;:
:&lt;math&gt;\partial_i : F \mapsto (x\mapsto \nabla_{e_i} F(x)).&lt;/math&gt;

Then, using the [[Einstein summation notation]], consider the operator:
:&lt;math&gt;e^i\partial_i,&lt;/math&gt;
which means
:&lt;math&gt;F \mapsto e^i\partial_i F,&lt;/math&gt;
or, more verbosely:
:&lt;math&gt;F \mapsto (x\mapsto e^i\nabla_{e_i} F(x)).&lt;/math&gt;

It can be shown that this operator is independent of the choice of frame, and can thus be used to define the ''geometric derivative'':
:&lt;math&gt;\nabla = e^i\partial_i.&lt;/math&gt;

This is similar to the usual definition of the [[gradient]], but it, too, extends to functions that are not necessarily scalar-valued.

It can be shown that the directional derivative is linear regarding its direction, that is:
:&lt;math&gt;\nabla_{\alpha a + \beta b} = \alpha\nabla_a + \beta\nabla_b.&lt;/math&gt;
From this follows that the directional derivative is the inner product of its direction by the geometric derivative.  All needs to be observed is that the direction &lt;math&gt;a&lt;/math&gt; can be written &lt;math&gt;a = (a\cdot e^i) e_i&lt;/math&gt;, so that:
:&lt;math&gt;\nabla_a = \nabla_{(a\cdot e^i)e_i} = (a\cdot e^i)\nabla_{e_i} = a\cdot(e^i\nabla_{e^i}) = a\cdot \nabla.&lt;/math&gt;
For this reason, &lt;math&gt;\nabla_a F(x)&lt;/math&gt; is often noted &lt;math&gt;a\cdot \nabla F(x)&lt;/math&gt;.

The standard [[order of operations]] for the geometric derivative is that it acts only on the function closest to its immediate right.  Given two functions ''F'' and ''G'', then for example we have

:&lt;math&gt;\nabla FG = (\nabla F)G.&lt;/math&gt;

===Product rule===

Although the partial derivative exhibits a [[product rule]], the geometric derivative only partially inherits this property.  Consider two functions ''F'' and ''G'':

:&lt;math&gt;\begin{align}\nabla(FG) &amp;= e^i\partial_i(FG) \\
&amp;= e^i((\partial_iF)G+F(\partial_iG)) \\
&amp;= e^i(\partial_iF)G+e^iF(\partial_iG). \end{align}&lt;/math&gt;

Since the geometric product is not [[commutative]] with &lt;math&gt;e^iF \ne Fe^i&lt;/math&gt; in general, we cannot proceed further without new notation.  A solution is to adopt the ''[[overdot]] notation'', in which the scope of a geometric derivative with an overdot is the multivector-valued function sharing the same overdot.  In this case, if we define

:&lt;math&gt;\dot{\nabla}F\dot{G}=e^iF(\partial_iG),&lt;/math&gt;

then the product rule for the geometric derivative is

:&lt;math&gt;\nabla(FG) = \nabla FG+\dot{\nabla}F\dot{G}.&lt;/math&gt;

===Interior and exterior derivative===

Let ''F'' be an ''r''-grade multivector.  Then we can define an additional pair of operators, the interior and exterior derivatives,

:&lt;math&gt;\nabla \cdot F = \langle \nabla F \rangle_{r-1} = e^i \cdot \partial_i F,&lt;/math&gt;
:&lt;math&gt;\nabla \wedge F = \langle \nabla F \rangle_{r+1} = e^i \wedge \partial_i F.&lt;/math&gt;

In particular, if ''F'' is grade 1 (vector-valued function), then we can write

:&lt;math&gt;\nabla F = \nabla \cdot F + \nabla \wedge F&lt;/math&gt;

and identify the [[divergence]] and [[curl (mathematics)|curl]] as

:&lt;math&gt;\nabla \cdot F = \operatorname{div} F,&lt;/math&gt;
:&lt;math&gt;\nabla \wedge F = I \, \operatorname{curl} F.&lt;/math&gt;

Note, however, that these two operators are considerably weaker than the geometric derivative counterpart for several reasons.  Neither the interior derivative operator nor the exterior derivative operator is [[invertible]].

==Integration==

Let &lt;math&gt;\{e_1, \ldots, e_n\}&lt;/math&gt; be a set of basis vectors that span an ''n''-dimensional vector space.  From geometric algebra, we interpret the [[pseudoscalar]] &lt;math&gt;e_1 \wedge e_2 \wedge\cdots\wedge e_n&lt;/math&gt; to be the [[signed volume]] of the ''n''-[[Parallelepiped#Parallelotope|parallelotope]] subtended by these basis vectors.  If the basis vectors are [[orthonormal]], then this is the unit pseudoscalar.

More generally, we may restrict ourselves to a subset of ''k'' of the basis vectors, where &lt;math&gt;1 \le k \le n&lt;/math&gt;, to treat the length, area, or other general ''k''-volume of a subspace in the overall ''n''-dimensional vector space.  We denote these selected basis vectors by &lt;math&gt;\{e_{i_1}, \ldots, e_{i_k} \}&lt;/math&gt;.  A general ''k''-volume of the ''k''-parallelotope subtended by these basis vectors is the grade ''k'' multivector &lt;math&gt;e_{i_1} \wedge e_{i_2} \wedge\cdots\wedge e_{i_k}&lt;/math&gt;.

Even more generally, we may consider a new set of vectors &lt;math&gt;\{x^{i_1}e_{i_1}, \ldots, x^{i_k}e_{i_k} \}&lt;/math&gt; proportional to the ''k'' basis vectors, where each of the &lt;math&gt;\{x^{i_j}\}&lt;/math&gt; is a component that scales one of the basis vectors.  We are free to choose components as infinitesimally small as we wish as long as they remain nonzero.  Since the outer product of these terms can be interpreted as a ''k''-volume, a natural way to define a [[measure (mathematics)|measure]] is

:&lt;math&gt;\begin{align}d^kX &amp;= \left(dx^{i_1} e_{i_1}\right) \wedge \left(dx^{i_2}e_{i_2}\right) \wedge\cdots\wedge \left(dx^{i_k}e_{i_k}\right) \\
&amp;= \left( e_{i_1}\wedge e_{i_2}\wedge\cdots\wedge e_{i_k} \right) dx^{i_1} dx^{i_2} \cdots dx^{i_k}.\end{align}&lt;/math&gt;

The measure is therefore always proportional to the unit pseudoscalar of a ''k''-dimensional subspace of the vector space.  Compare the [[Riemannian volume form]] in the theory of differential forms.  The integral is taken with respect to this measure:

:&lt;math&gt;\int_V F(x)\,d^kX = \int_V F(x) \left( e_{i_1}\wedge e_{i_2}\wedge\cdots\wedge e_{i_k} \right) dx^{i_1} dx^{i_2} \cdots dx^{i_k}.&lt;/math&gt;

More formally, consider some directed volume ''V'' of the subspace.  We may divide this volume into a sum of [[simplices]].  Let &lt;math&gt;\{x_i\}&lt;/math&gt; be the coordinates of the vertices.  At each vertex we assign a measure &lt;math&gt;\Delta U_i(x)&lt;/math&gt; as the average measure of the simplices sharing the vertex.  Then the integral of ''F(x)'' with respect to ''U(x)'' over this volume is obtained in the limit of finer partitioning of the volume into smaller simplices:

:&lt;math&gt;\int_V F\,dU = \lim_{n \rightarrow \infty} \sum_{i=1}^n F(x_i)\,\Delta U_i(x).&lt;/math&gt;

===Fundamental theorem of geometric calculus===

The reason for defining the geometric derivative and integral as above is that they allow a strong generalization of [[Stokes' theorem]].  Let &lt;math&gt;\mathsf{L}(A;x)&lt;/math&gt; be a multivector-valued function of ''r''-grade input ''A'' and general position ''x'', linear in its first argument.  Then the fundamental theorem of geometric calculus relates the integral of a derivative over the volume ''V'' to the integral over its boundary:

{{Equation box 1
|equation =
&lt;math&gt;\int_V \dot{\mathsf{L}} \left(\dot{\nabla} dX;x \right) = \oint_{\partial V} \mathsf{L} (dS;x).&lt;/math&gt;
}}

As an example, let &lt;math&gt;\mathsf{L}(A;x)=\langle F(x) A I^{-1} \rangle&lt;/math&gt; for a vector-valued function ''F(x)'' and a (''n''&amp;minus;1)-grade multivector ''A''.  We find that

:&lt;math&gt;\begin{align}\int_V \dot{\mathsf{L}} \left(\dot{\nabla} dX;x \right) &amp;= \int_V \langle\dot{F}(x)\dot{\nabla}\,dX\,I^{-1} \rangle \\
&amp;= \int_V \langle\dot{F}(x)\dot{\nabla}\,|dX| \rangle \\
&amp;= \int_V \nabla \cdot F(x)\,|dX|. \end{align}&lt;/math&gt;

Likewise,

:&lt;math&gt;\begin{align}\oint_{\partial V} \mathsf{L} (dS;x) &amp;= \oint_{\partial V} \langle F(x)\,dS\,I^{-1} \rangle \\
&amp;= \oint_{\partial V} \langle F(x) \hat{n}\,|dS| \rangle \\
&amp;= \oint_{\partial V} F(x) \cdot \hat{n}\,|dS|. \end{align}&lt;/math&gt;

Thus we recover the [[divergence theorem]],

:&lt;math&gt;\int_V \nabla \cdot F(x)\,|dX| = \oint_{\partial V} F(x) \cdot \hat{n}\,|dS|.&lt;/math&gt;

==Covariant derivative==

A sufficiently smooth ''k''-surface in an ''n''-dimensional space is deemed a [[manifold]].  To each point on the manifold, we may attach a ''k''-blade ''B'' that is tangent to the manifold.  Locally,  ''B'' acts as a pseudoscalar of the ''k''-dimensional space.  This blade defines a [[geometric algebra#Projection and rejection|projection]] of vectors onto the manifold:

:&lt;math&gt;\mathcal{P}_B (A) = (A \cdot B^{-1}) B.&lt;/math&gt;

Just as the geometric derivative &lt;math&gt;\nabla&lt;/math&gt; is defined over the entire ''n''-dimensional space, we may wish to define an ''intrinsic derivative'' &lt;math&gt;\partial&lt;/math&gt;, locally defined on the manifold:

:&lt;math&gt;\partial F = \mathcal{P}_B (\nabla )F.&lt;/math&gt;

(Note: The right hand side of the above may not lie in the tangent space to the manifold. Therefore, it is not the same as &lt;math&gt;\mathcal{P}_B (\nabla F)&lt;/math&gt;, which necessarily does lie in the tangent space.)

If ''a'' is a vector tangent to the manifold, then indeed both the geometric derivative and intrinsic derivative give the same directional derivative:

:&lt;math&gt;a \cdot \partial F = a \cdot \nabla F.&lt;/math&gt;

Although this operation is perfectly valid, it is not always useful because &lt;math&gt;\partial F&lt;/math&gt; itself is not necessarily on the manifold.  Therefore, we define the ''covariant derivative'' to be the forced projection of the intrinsic derivative back onto the manifold:

:&lt;math&gt;a \cdot DF = \mathcal{P}_B (a \cdot \partial F) = \mathcal{P}_B (a \cdot \mathcal{P}_B (\nabla F)).&lt;/math&gt;

Since any general multivector can be expressed as a sum of a projection and a rejection, in this case

:&lt;math&gt;a \cdot \partial F = \mathcal{P}_B (a \cdot \partial F) + \mathcal{P}_B^{\perp} (a \cdot \partial F),&lt;/math&gt;

we introduce a new function, the [[shape tensor]] &lt;math&gt;\mathsf{S}(a)&lt;/math&gt;, which satisfies

:&lt;math&gt;F \times \mathsf{S}(a) = \mathcal{P}_B^{\perp} (a \cdot \partial F),&lt;/math&gt;

where &lt;math&gt;\times&lt;/math&gt; is the commutator product.  In a local coordinate basis &lt;math&gt;\{e_i\}&lt;/math&gt; spanning the tangent surface, the shape tensor is given by

:&lt;math&gt;\mathsf{S}(a) = e^i \wedge \mathcal{P}_B^{\perp} (a \cdot \partial e_i).&lt;/math&gt;

Importantly, on a general manifold, the covariant derivative does not commute.  In particular, the [[commutator]] is related to the shape tensor by

:&lt;math&gt;[a \cdot D, \, b \cdot D]F=-(\mathsf{S}(a) \times \mathsf{S}(b)) \times F.&lt;/math&gt;

Clearly the term &lt;math&gt;\mathsf{S}(a) \times \mathsf{S}(b)&lt;/math&gt; is of interest.  However it, like the intrinsic derivative, is not necessarily on the manifold.  Therefore, we can define the [[Riemann tensor]] to be the projection back onto the manifold:

:&lt;math&gt;\mathsf{R}(a \wedge b)=-\mathcal{P}_B (\mathsf{S}(a) \times \mathsf{S}(b)).&lt;/math&gt;

Lastly, if ''F'' is of grade ''r'', then we can define interior and exterior covariant derivatives as

:&lt;math&gt;D \cdot F = \langle DF \rangle_{r-1},&lt;/math&gt;
:&lt;math&gt;D \wedge F = \langle D F \rangle_{r+1},&lt;/math&gt;

and likewise for the intrinsic derivative.

==Relation to differential geometry==

On a manifold, locally we may assign a tangent surface spanned by a set of basis vectors &lt;math&gt;\{e_i\}&lt;/math&gt;.  We can associate the components of a [[metric tensor]], the [[Christoffel symbols]], and the Riemann tensor as follows:

:&lt;math&gt;g_{ij}=e_i \cdot e_j,&lt;/math&gt;
:&lt;math&gt;\Gamma^k_{ij}=(e_i \cdot De_j) \cdot e^k,&lt;/math&gt;
:&lt;math&gt;R_{ijkl}=(\mathsf{R}(e_i \wedge e_j) \cdot e_k) \cdot e_l.&lt;/math&gt;

These relations embed the theory of differential geometry within geometric calculus.

==Relation to differential forms==

In a [[local coordinate system]] (''x''&lt;sup&gt;1&lt;/sup&gt;, ..., ''x''&lt;sup&gt;''n''&lt;/sup&gt;), the coordinate differentials ''dx''&lt;sup&gt;1&lt;/sup&gt;, ..., ''dx''&lt;sup&gt;''n''&lt;/sup&gt; form a basic set of one-forms within the [[coordinate chart]]. Given a [[multi-index]] {{nowrap|''i''&lt;sub&gt;1&lt;/sub&gt;, ..., ''i''&lt;sub&gt;''k''&lt;/sub&gt;}} with {{nowrap|1 &amp;le; ''i&lt;sub&gt;p&lt;/sub&gt;'' &amp;le; ''n''}} for {{nowrap|1 &amp;le; ''p'' &amp;le; ''k''}}, we can define a ''k''-form 
:&lt;math&gt;\omega = f_I\,dx^I=f_{i_1,i_2\cdots i_k}\,dx^{i_1}\wedge dx^{i_2}\wedge\cdots\wedge dx^{i_k}.&lt;/math&gt;

We can alternatively introduce a ''k''-grade multivector ''A'' as

:&lt;math&gt;A = f_{i_1,i_2\cdots i_k}e^{i_1}\wedge e^{i_2}\wedge\cdots\wedge e^{i_k}&lt;/math&gt;

and a measure

:&lt;math&gt;\begin{align}d^kX &amp;= \left(dx^{i_1} e_{i_1}\right) \wedge \left(dx^{i_2}e_{i_2}\right) \wedge\cdots\wedge \left(dx^{i_k}e_{i_k}\right) \\
&amp;= \left( e_{i_1}\wedge e_{i_2}\wedge\cdots\wedge e_{i_k} \right) dx^{i_1} dx^{i_2} \cdots dx^{i_k}.\end{align}&lt;/math&gt;

Apart from a subtle difference in meaning for the exterior product with respect to differential forms versus the exterior product with respect to vectors (in the former the ''increments'' are covectors, whereas in the latter they represent scalars), we see the correspondences of the differential form

:&lt;math&gt;\omega \cong A^{\dagger} \cdot d^kX = A \cdot \left(d^kX \right)^{\dagger},&lt;/math&gt;

its derivative

:&lt;math&gt;d\omega \cong (D \wedge A)^{\dagger} \cdot d^{k+1}X = (D \wedge A) \cdot \left(d^{k+1}X \right)^{\dagger},&lt;/math&gt;

and its [[Hodge dual]]

:&lt;math&gt;\star\omega \cong (I^{-1} A)^{\dagger} \cdot d^kX,&lt;/math&gt;

embed the theory of differential forms within geometric calculus.

== History ==

Following is a diagram summarizing the history of geometric calculus.

[[File:Geometric Calculus Family Tree.png|center|300px|thumb |Figure 1 (from [32])|History of geometric calculus.]]

{{-}}

== References and further reading ==
{{reflist}}
*{{cite book|first=Alan |last=Macdonald |title=Vector and Geometric Calculus |location=Charleston |publisher=CreateSpace |year=2012 |url=http://faculty.luther.edu/~macdonal/vagc/ | oclc=829395829 |isbn=9781480132450}}

[[Category:Calculus]]
[[Category:Geometric algebra]]</text>
      <sha1>g0rsupujwkm09etm3bi64561dk9hubt</sha1>
    </revision>
  </page>
  <page>
    <title>Graph dynamical system</title>
    <ns>0</ns>
    <id>20335837</id>
    <revision>
      <id>846610830</id>
      <parentid>841542002</parentid>
      <timestamp>2018-06-19T20:43:53Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 2 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10039">In [[mathematics]], the concept of '''graph dynamical systems''' can be used to capture a wide range of processes taking place on graphs or networks. A major theme in the mathematical and computational analysis of GDSs is to relate their structural properties (e.g. the network connectivity) and the global dynamics that result.

The work on GDSs considers finite graphs and finite state spaces. As such, the research typically involves techniques from, e.g., [[graph theory]], [[combinatorics]], [[algebra]], and [[dynamical systems]] rather than differential geometry. In principle, one could define and study GDSs over an infinite graph (e.g. [[cellular automata]] or [[Stochastic cellular automata|probabilistic cellular automata]] over &lt;math&gt;\mathbb{Z}^k&lt;/math&gt; or [[interacting particle systems]] when some randomness is included), as well as GDSs with infinite state space (e.g. &lt;math&gt;\mathbb{R}&lt;/math&gt; as in coupled map lattices); see, for example, Wu.&lt;ref name=wu-05&gt;{{cite journal |doi=10.1088/0951-7715/18/3/007 |last=Wu |first=Chai Wah |year=2005 |title=Synchronization in networks of nonlinear dynamical systems coupled via a directed graph |journal=Nonlinearity |volume= 18 |issue= 3|pages=1057–1064 |ref=Wu:05|bibcode=2005Nonli..18.1057W }}&lt;/ref&gt; In the following, everything is implicitly assumed to be finite unless stated otherwise.

==Formal definition==

A graph dynamical system is constructed from the following components:

&lt;blockquote&gt;
* A finite ''graph'' ''Y'' with vertex set v[''Y''] = {1,2, ... , n}. Depending on the context the graph can be directed or undirected.
* A state ''x&lt;sub&gt;v&lt;/sub&gt;'' for each vertex ''v'' of ''Y'' taken from a finite set ''K''. The ''system state'' is the ''n''-tuple ''x'' = (''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ... , ''x&lt;sub&gt;n&lt;/sub&gt;''), and ''x''[''v''] is the tuple consisting of the states associated to the vertices in the 1-neighborhood of ''v'' in ''Y'' (in some fixed order).
* A ''vertex function'' ''f&lt;sub&gt;v&lt;/sub&gt;'' for each vertex ''v''. The vertex function maps the state of vertex ''v'' at time ''t'' to the vertex state at time ''t''&amp;nbsp;+&amp;nbsp;1 based on the states associated to the 1-neighborhood of ''v'' in ''Y''.
* An ''update scheme'' specifying the mechanism by which the mapping of individual vertex states is carried out so as to induce a discrete dynamical system with map ''F'': ''K&lt;sup&gt;n&lt;/sup&gt; → K&lt;sup&gt;n&lt;/sup&gt;''.
&lt;/blockquote&gt;

The ''phase space'' associated to a dynamical system with map ''F'': ''K&lt;sup&gt;n&lt;/sup&gt; → K&lt;sup&gt;n&lt;/sup&gt;'' is the finite directed graph with vertex set ''K&lt;sup&gt;n&lt;/sup&gt;'' and directed edges (''x'', ''F''(''x'')). The structure of the phase space is governed by the properties of the graph ''Y'', the vertex functions (''f&lt;sub&gt;i&lt;/sub&gt;'')''&lt;sub&gt;i&lt;/sub&gt;'', and the update scheme. The research in this area seeks to infer phase space properties based on the structure of the system constituents. The analysis has a local-to-global character.

== Generalized cellular automata (GCA) ==

If, for example, the update scheme consists of applying the vertex functions synchronously one obtains the class of ''generalized cellular automata'' (CA). In this case, the global map ''F'': ''K&lt;sup&gt;n&lt;/sup&gt; → K&lt;sup&gt;n&lt;/sup&gt;'' is given by

&lt;math&gt;F(x)_v = f_v(x[v]) \;.&lt;/math&gt;

This class is referred to as generalized cellular automata since the classical or standard [[Cellular automaton|cellular automata]] are typically defined and studied over regular graphs or grids, and the vertex functions are typically assumed to be identical.

'''Example:''' Let ''Y'' be the circle graph on vertices {1,2,3,4} with edges {1,2}, {2,3}, {3,4} and {1,4}, denoted Circ&lt;sub&gt;4&lt;/sub&gt;. Let ''K'' = {0,1} be the state space for each vertex and use the function nor&lt;sub&gt;3&lt;/sub&gt; : ''K&lt;sup&gt;3&lt;/sup&gt;'' → ''K'' defined by nor&lt;sub&gt;3&lt;/sub&gt;(''x,y,z'')&amp;nbsp;=&amp;nbsp;(1&amp;nbsp;+&amp;nbsp;''x'')(1&amp;nbsp;+&amp;nbsp;''y'')(1&amp;nbsp;+&amp;nbsp;''z'') with arithmetic modulo 2 for all vertex functions. Then for example the system state (0,1,0,0) is mapped to (0,&amp;nbsp;0,&amp;nbsp;0,&amp;nbsp;1) using a synchronous update. All the transitions are shown in the phase space below.

[[File:circ-4-nor.jpg|frame|center | 326]]

== Sequential dynamical systems (SDS) ==

If the vertex functions are applied asynchronously in the sequence specified by a word ''w'' = (''w''&lt;sub&gt;1&lt;/sub&gt;, ''w''&lt;sub&gt;2&lt;/sub&gt;, ... , ''w&lt;sub&gt;m&lt;/sub&gt;'') or permutation &lt;math&gt;\pi&lt;/math&gt; = ( &lt;math&gt;\pi_1&lt;/math&gt;, &lt;math&gt;\pi_2,\dots,\pi_n&lt;/math&gt;) of ''v''[''Y''] one obtains the class of ''[[Sequential dynamical system]]s'' (SDS).&lt;ref name=Mortveit-08&gt;{{cite book |last=Mortveit |first=Henning S. |author2=Reidys, Christian M. | year=2008 |title=An introduction to sequential dynamical systems |publisher=[[Springer Verlag]] |location=New York |isbn=978-0-387-30654-4 | series=Universitext| ref=Mortveit:08}}&lt;/ref&gt; In this case it is convenient to introduce the ''Y''-local maps ''F&lt;sub&gt;i&lt;/sub&gt;'' constructed from the vertex functions by

: &lt;math&gt;F_i (x) = (x_1, x_2,\ldots, x_{i-1}, f_i(x[i]), x_{i+1}, \ldots , x_n) \;. &lt;/math&gt;

The SDS map ''F'' = [''F&lt;sub&gt;Y&lt;/sub&gt;'' , ''w''] : ''K&lt;sup&gt;n&lt;/sup&gt;'' → ''K&lt;sup&gt;n&lt;/sup&gt;'' is the function composition

: &lt;math&gt;[F_Y ,w] = F_{w(m)} \circ F_{w(m-1)} \circ \cdots \circ F_{w(2)} \circ F_{w(1)} \;. &lt;/math&gt;

If the update sequence is a permutation one frequently speaks of a ''permutation SDS'' to emphasize this point.

'''Example:''' Let ''Y'' be the circle graph on vertices {1,2,3,4} with edges {1,2}, {2,3}, {3,4} and {1,4}, denoted Circ&lt;sub&gt;4&lt;/sub&gt;. Let ''K''={0,1} be the state space for each vertex and use the function nor&lt;sub&gt;3&lt;/sub&gt; : ''K''&lt;sup&gt;3&lt;/sup&gt; → ''K'' defined by nor&lt;sub&gt;3&lt;/sub&gt;(''x,&amp;nbsp;y,&amp;nbsp;z'') = (1&amp;nbsp;+&amp;nbsp;''x'')(1&amp;nbsp;+&amp;nbsp;''y'')(1&amp;nbsp;+&amp;nbsp;''z'') with arithmetic modulo 2 for all vertex functions. Using the update sequence (1,2,3,4) then the system state (0,&amp;nbsp;1,&amp;nbsp;0,&amp;nbsp;0) is mapped to (0,&amp;nbsp;0,&amp;nbsp;1,&amp;nbsp;0). All the system state transitions for this sequential dynamical system are shown in the phase space below.

[[File:circ-4-nor-1234.jpg|frame|center | 326]]

== Stochastic graph dynamical systems ==

From, e.g., the point of view of applications it is interesting to consider the case where one or more of the components of a GDS contains stochastic elements. Motivating applications could include processes that are not fully understood (e.g. dynamics within a cell) and where certain aspects for all practical purposes seem to behave according to some probability distribution. There are also applications governed by deterministic principles whose description is so complex or unwieldy that it makes sense to consider probabilistic approximations.

Every element of a graph dynamical system can be made stochastic in several ways. For example, in a sequential dynamical system the update sequence can be made stochastic. At each iteration step one may choose the update sequence ''w'' at random from a given distribution of update sequences with corresponding probabilities. The matching probability space of update sequences induces a probability space of SDS maps. A natural object to study in this regard is the [[Markov chain]] on state space induced by this collection of SDS maps. This case is referred to as ''update sequence stochastic GDS'' and is motivated by, e.g., processes where "events" occur at random according to certain rates (e.g. chemical reactions), synchronization in parallel computation/discrete event simulations, and in computational paradigms described later&lt;!-- Make sure this cross ref stays/works. --&gt;.

This specific example with stochastic update sequence illustrates two general facts for such systems: when passing to a stochastic graph dynamical system one is generally led to (1) a study of Markov chains (with specific structure governed by the constituents of the GDS), and (2) the resulting Markov chains tend to be large having an exponential number of states. A central goal in the study of stochastic GDS is to be able to derive reduced models.

One may also consider the case where the vertex functions are stochastic, i.e., ''function stochastic GDS''. For example, Random [[Boolean network]]s are examples of function stochastic GDS using a synchronous update scheme and where the state space is ''K'' = {0,&amp;nbsp;1}. Finite [[probabilistic cellular automata]] (PCA) is another example of function stochastic GDS. In principle the class of Interacting particle systems (IPS) covers finite and infinite [[probabilistic cellular automata|PCA]], but in practice the work on IPS is largely concerned with the infinite case since this allows one to introduce more interesting topologies on state space.

==Applications==

Graph dynamical systems constitute a natural framework for capturing distributed systems such as biological networks and epidemics over social networks, many of which are frequently referred to as complex systems.

==See also==

*[[Chemical reaction network theory]]
*[[Dynamic network analysis]] (a [[social science]] topic)
*[[Finite state machine]]s
*[[Hopfield net]]works
*[[Kauffman network]]s
*[[Petri net]]s

==References==

{{reflist}}

==Further reading==
* {{cite journal |doi=10.1088/0951-7715/22/2/010 |last=Macauley |first=Matthew |author2=Mortveit, Henning S. |year=2009 |title=Cycle equivalence of graph dynamical systems |journal=Nonlinearity |volume=22 |issue=2 |pages=421&amp;ndash;436 |ref=Macauley:09a|arxiv=0802.4412 |bibcode=2009Nonli..22..421M }}
*{{cite book |last=Golubitsky |first=Martin |authorlink=Marty Golubitsky|author2=Stewart, Ian |year=2003 |title =The Symmetry Perspective |publisher=Birkhauser |location=Basel | ref=Golubitsky:03 |isbn=0-8176-2171-7}}

==External links==
*[http://www.samsi.info/sites/default/files/samsi-05-dec-08.pdf Graph Dynamical Systems – A Mathematical Framework for Interaction-Based Systems, Their Analysis and Simulations by Henning Mortveit]


{{DEFAULTSORT:Graph Dynamical System}}
[[Category:Dynamical systems]]
[[Category:Algebra]]
[[Category:Graph theory]]
[[Category:Combinatorics]]</text>
      <sha1>dkd4huikbhlto1wx60885rjd3hadb1v</sha1>
    </revision>
  </page>
  <page>
    <title>Gray's conjecture</title>
    <ns>0</ns>
    <id>35543850</id>
    <revision>
      <id>763484210</id>
      <parentid>657195910</parentid>
      <timestamp>2017-02-03T14:45:39Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Moving category Conjectures which were proven to [[:Category:Conjectures that have been proved]] per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2016 December 21]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1280">{{Orphan|date=April 2012}}

In [[mathematics]], '''Gray's conjecture''' is a conjecture made by Brayton Gray in 1984 about maps between [[loop space]]s of spheres.&lt;ref&gt;{{cite journal | last1=Gray | first1=Brayton | title=Unstable families related to the image of J | doi=10.1017/S0305004100061971 |mr=743705 | year=1984 | journal=Mathematical Proceedings of the Cambridge Philosophical Society | issn=0305-0041 | volume=96 | issue=1 | pages=95–113}}&lt;/ref&gt; It was later proved by John Harper&lt;ref&gt;{{cite book | last1=Harper | first1=John R. | title=Algebraic topology (Evanston, IL, 1988) | publisher=[[American Mathematical Society]] | location=Providence, Rhode Island | series=Contempemporary Mathematics |mr=1022681 | year=1989 | volume=96 | chapter=A proof of Gray's conjecture | pages=189–195}}&lt;/ref&gt; and Stephen Theriault.&lt;ref&gt;{{cite journal | last1=Theriault | first1=Stephen D. | title=Proofs of two conjectures of Gray involving the double suspension| doi=10.1090/S0002-9939-03-06847-3 |mr=1974354 | year=2003 | journal=[[Proceedings of the American Mathematical Society]] | issn=0002-9939 | volume=131 | issue=9 | pages=2953–2962}}&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Algebraic topology]]
[[Category:Conjectures that have been proved]]


{{topology-stub}}</text>
      <sha1>9z9mhhuko2ommm9qttbqr9p2ajewt5v</sha1>
    </revision>
  </page>
  <page>
    <title>Haboush's theorem</title>
    <ns>0</ns>
    <id>632762</id>
    <revision>
      <id>841566128</id>
      <parentid>841566093</parentid>
      <timestamp>2018-05-16T16:37:05Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <minor/>
      <comment>/* References */Journal cites, Added 2 dois to journal cites</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8021">In [[mathematics]] '''Haboush's theorem''', often still referred to as the '''Mumford conjecture''', states that for any [[Semisimple algebraic group|semisimple]] [[algebraic group]] ''G'' over a [[field (mathematics)|field]] ''K'', and for any linear representation ρ of ''G'' on a ''K''-[[vector space]] ''V'', given ''v''&amp;nbsp;≠&amp;nbsp;0 in ''V'' that is fixed by the action of ''G'', there is a [[G-invariant|''G''-invariant]] [[polynomial]] ''F'' on ''V'', without constant term,  such that

:''F''(''v'') &amp;ne; 0.

The polynomial can be taken to be [[homogeneous polynomial|homogeneous]], in other words an element of a symmetric power of the dual of ''V'', and if the characteristic is ''p''&gt;0 the degree of the polynomial can be taken to be a power of ''p''.  
When ''K'' has characteristic 0 this was well known; in fact Weyl's theorem on the complete reducibility of the representations of ''G'' implies that ''F'' can even be taken to be linear. Mumford's conjecture about the extension to prime characteristic ''p'' was proved  by W. J. {{harvtxt|Haboush|1975}}, about a decade after the problem had been posed by [[David Mumford]], in the introduction to the first edition of his book ''Geometric Invariant Theory''.

==Applications==
Haboush's theorem can be used to generalize  results of [[geometric invariant theory]] from characteristic 0, where they were already known, to characteristic ''p''&gt;0. In particular Nagata's earlier results together with Haboush's theorem show that if a reductive group (over an algebraically closed field) acts on a finitely generated algebra then the fixed subalgebra is also finitely generated.

Haboush's theorem implies that if ''G'' is a reductive algebraic group acting regularly on an affine algebraic variety, then disjoint closed invariant sets ''X'' and ''Y'' can be separated by an invariant function ''f'' (this means that ''f'' is 0 on ''X'' and 1 on ''Y'').

C.S. Seshadri (1977) extended Haboush's theorem to reductive groups over schemes.

It follows from the work of {{harvtxt|Nagata|1963}}, Haboush, and Popov that the following conditions are equivalent for an affine algebraic group ''G'' over a field ''K'':
*''G'' is reductive (its unipotent radical is trivial).
*For any non-zero invariant vector in a rational representation of ''G'', there is an invariant homogeneous polynomial that does not vanish on it.
*For any finitely generated ''K'' algebra on which ''G'' act rationally, the algebra of fixed elements is finitely generated.

==Proof==
The theorem is proved in several steps as follows:
*We can assume that the group is defined over an [[algebraically closed]] field ''K'' of characteristic ''p''&gt;0.
*Finite groups are easy to deal with as one can just take a product over all elements, so one can reduce to the case of '''connected''' reductive groups (as the connected component has finite index). By taking a central extension which is harmless one can also assume the group ''G'' is '''simply connected'''.
*Let ''A''(''G'') be the coordinate ring of ''G''. This is a representation of ''G'' with ''G'' acting by left translations. Pick an element ''v&amp;prime;'' of the dual of ''V'' that has value 1 on the invariant vector ''v''. The map ''V'' to ''A''(''G'') by sending ''w''∈''V'' to the element ''a''∈''A''(''G'') with ''a''(''g'') = ''v''&amp;prime;(''g''(''w'')). This sends ''v'' to 1∈''A''(''G''), so we can assume that ''V''⊂''A''(''G'') and ''v''=1.
*The structure of the representation ''A''(''G'') is given as follows. Pick a maximal torus ''T'' of ''G'', and let it act on  ''A''(''G'') by right translations (so that it commutes with the action of ''G''). Then ''A''(''G'') splits as a sum over characters λ of ''T'' of the subrepresentations ''A''(''G'')&lt;sup&gt;λ&lt;/sup&gt; of elements transforming according to λ. So we can assume that ''V'' is contained in the ''T''-invariant subspace ''A''(''G'')&lt;sup&gt;λ&lt;/sup&gt; of ''A''(''G'').
*The representation ''A''(''G'')&lt;sup&gt;λ&lt;/sup&gt; is an increasing union of subrepresentations of the form ''E''&lt;sub&gt;λ+''n''ρ&lt;/sub&gt;⊗''E''&lt;sub&gt;''n''ρ&lt;/sub&gt;, where ρ is the Weyl vector for a choice of simple roots of ''T'', ''n'' is a positive integer, and ''E''&lt;sub&gt;μ&lt;/sub&gt; is the space of sections of the [[line bundle]] over ''G''/''B'' corresponding to a character μ of ''T'', where ''B'' is a [[Borel subgroup]] containing ''T''.
*If ''n'' is sufficiently large then ''E''&lt;sub&gt;''n''ρ&lt;/sub&gt; has dimension (''n''+1)&lt;sup&gt;''N''&lt;/sup&gt; where ''N'' is the number of positive roots. This is because in characteristic 0 the corresponding module has this dimension by the [[Weyl character formula]], and for ''n'' large enough that the line bundle over ''G''/''B'' is [[very ample]], ''E''&lt;sub&gt;''n''ρ&lt;/sub&gt; has the same dimension as in characteristic 0.
*If ''q''=''p''&lt;sup&gt;''r''&lt;/sup&gt;  for a positive integer ''r'', and ''n''=''q''&amp;minus;1, then ''E''&lt;sub&gt;''n''ρ&lt;/sub&gt; contains the [[Steinberg representation]] of ''G''('''F'''&lt;sub&gt;''q''&lt;/sub&gt;) of dimension ''q''&lt;sup&gt;''N''&lt;/sup&gt;. (Here '''F'''&lt;sub&gt;''q''&lt;/sub&gt; ⊂ ''K'' is the finite field of order ''q''.) The Steinberg representation is an irreducible representation of ''G''('''F'''&lt;sub&gt;''q''&lt;/sub&gt;) and therefore of ''G''(''K''), and for ''r'' large enough it has the same dimension as ''E''&lt;sub&gt;''n''ρ&lt;/sub&gt;, so there are infinitely many values of ''n'' such that ''E''&lt;sub&gt;''n''ρ&lt;/sub&gt; is irreducible.
*If ''E''&lt;sub&gt;''n''ρ&lt;/sub&gt; is irreducible it is isomorphic to its dual, so ''E''&lt;sub&gt;''n''ρ&lt;/sub&gt;⊗''E''&lt;sub&gt;''n''ρ&lt;/sub&gt; is isomorphic to End(''E''&lt;sub&gt;''n''ρ&lt;/sub&gt;). Therefore, the ''T''-invariant subspace ''A''(''G'')&lt;sup&gt;λ&lt;/sup&gt; of ''A''(''G'') is an increasing union of subrepresentations of the form End(''E'') for  representations ''E'' (of the form ''E''&lt;sub&gt;(''q''&amp;minus;1)ρ&lt;/sub&gt;)). However, for  representations of the form End(''E'')  an invariant polynomial that separates 0 and 1 is given by the determinant. This completes the sketch of the proof of Haboush's theorem.

==References==
*{{citation|mr=0444786
|last=Demazure|first= Michel|authorlink=Michel Demazure
|chapter=Démonstration de la conjecture de Mumford (d'après W. Haboush)|title= Séminaire Bourbaki (1974/1975: Exposés Nos. 453--470)|pages= 138–144|series= Lecture Notes in Math.|volume= 514|publisher= Springer|place= Berlin|year= 1976|doi=10.1007/BFb0080063|isbn=978-3-540-07686-5}} 
*{{citation|authorlink=William Haboush|first=W. J. |last=Haboush|title=Reductive groups are geometrically reductive|journal=Ann. of Math. |volume=102|year=1975|pages=67–83|doi=10.2307/1970974|issue=1|publisher=The Annals of Mathematics, Vol. 102, No. 1|jstor=1970974}}
*Mumford, D.; Fogarty, J.; Kirwan, F. ''Geometric invariant theory''. Third edition. [[Ergebnisse der Mathematik und ihrer Grenzgebiete]] (2) (Results in Mathematics and Related Areas (2)), 34. Springer-Verlag, Berlin, 1994. xiv+292 pp. {{MathSciNet|id=1304906}} {{ISBN|3-540-56963-4}}
*{{Citation | last1=Nagata | first1=Masayoshi | author1-link=Masayoshi Nagata | title=Invariants of a group in an affine ring | url=http://projecteuclid.org/euclid.kjm/1250524787 | year=1963  | journal=Journal of Mathematics of Kyoto University | issn=0023-608X | volume=3 | pages=369–377 | mr=0179268 | doi=10.1215/kjm/1250524787}}
*{{cite journal | last1 = Nagata | first1 = M. | last2 = Miyata | first2 = T. | year = 1964 | title = Note on semi-reductive groups | url = | journal = J. Math. Kyoto Univ. | volume = 3 | issue = | pages = 379–382 | doi=10.1215/kjm/1250524788}}
*{{springer|id=M/m065570|first=V.L. |last=Popov|authorlink=Vladimir L. Popov|title=Mumford hypothesis}}
*{{cite journal | last1 = Seshadri | first1 = C.S. | year = 1977 | title = Geometric reductivity over arbitrary base | url = | journal = Adv. Math. | volume = 26 | issue = | pages = 225–274 | doi=10.1016/0001-8708(77)90041-x}}

[[Category:Representation theory of algebraic groups]]
[[Category:Invariant theory]]
[[Category:Theorems in representation theory]]
[[Category:Conjectures that have been proved]]</text>
      <sha1>pg6xazihtwayqdq3ubzv30tqh36kmcx</sha1>
    </revision>
  </page>
  <page>
    <title>Henk Barendregt</title>
    <ns>0</ns>
    <id>1651213</id>
    <revision>
      <id>782649400</id>
      <parentid>736578579</parentid>
      <timestamp>2017-05-28T08:24:47Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4329">[[File:Henk Barendregt at the Old Jewish Cemetery in Prague.jpg|thumb|Henk Barendregt during his visit in Prague in April 2012]]
'''Hendrik Pieter (Henk) Barendregt''' (born 18 December 1947, [[Amsterdam]])&lt;ref&gt;{{cite book |editor1=Erik Barendsen |editor2=Herman Geuvers |editor3=Venanzio Capretta |editor4=Milad Niqui | title=Reflections on Type Theory, Lambda Calculus, and the Mind &amp;mdash; Essays Dedicated to Henk Barendregt on the Occasion of his 60th Birthday | location= | publisher=University Nijmegen | url=http://www.cs.ru.nl/barendregt60/essays | isbn=978-90-9022446-6 | year=2007 }} Here: [http://www.cs.ru.nl/barendregt60/essays/preliminary/prelims.pdf Preface], p.5&lt;/ref&gt; is a Dutch [[Mathematical logic|logician]], known for his work in [[lambda calculus]] and [[type theory]].

== Life and work ==
Barendregt studied [[mathematical logic]] at [[Utrecht University]], obtaining his master's degree in 1968 and his PhD in 1971, both ''[[cum laude]]'', under [[Dirk van Dalen]] and [[Georg Kreisel]]. After a postdoctoral position at [[Stanford University]], he taught at [[Utrecht University]].

Since 1986, Barendregt has taught at [[Radboud University Nijmegen]], where he now holds the Chair of Foundations of Mathematics and Computer Science. His research group works on Constructive Interactive Mathematics. He is also Adjunct Professor at [[Carnegie Mellon University]], Pittsburgh, USA. He has been a visiting scholar at Darmstadt, [[ETH Zürich]], Siena, and Kyoto.

In 1997 Barendregt was elected member of the [[Royal Netherlands Academy of Arts and Sciences]].&lt;ref&gt;{{cite web|url=https://www.knaw.nl/nl/leden/leden/3833 |title=Henk Barendregt |publisher=Royal Netherlands Academy of Arts and Sciences |date= |accessdate=26 July 2015}}&lt;/ref&gt; On 6 February 2003 Barendregt was awarded the [[Spinozapremie]] for 2002, the highest scientific award in the Netherlands.&lt;ref&gt;{{cite web|url=http://www.nwo.nl/en/research-and-results/programmes/spinoza+prize/spinoza+laureates/overview+by+year/2002 |title=NWO Spinoza Prize 2002 |publisher=Netherlands Organisation for Scientific Research |date=5 September 2014 |accessdate=30 January 2016}}&lt;/ref&gt; In 2002 he was knighted in the [[Order of the Netherlands Lion|Orde van de Nederlandse Leeuw]].

Barendregt received an honorary doctorate from [[Heriot-Watt University]] in 2015.&lt;ref&gt;{{Cite web|url = http://www.hw.ac.uk/news/edinburgh-campus-graduations.htm|title = Edinburgh Campus graduations - News {{!}} Heriot-Watt University Edinburgh|website = www.hw.ac.uk|access-date = 2016-03-24}}&lt;/ref&gt;

== Selected publications ==
* {{cite book | author=H.P. Barendregt | title=The Lambda Calculus &amp;mdash; Its Syntax and Semantics | location=Amsterdam | publisher=North-Holland | series=Studies in Logic and the Foundations of Mathematics | volume=103 | year=1985 | isbn=0-444-87508-5}} &amp;mdash;  See [ftp://ftp.cs.kun.nl/pub/CompMath.Found/errata.lambda-calculus.pdf Errata]
* {{cite book | authors=Toyama, Y. and [[Jan Willem Klop|Klop, J.W.]] and Barendregt, H.P. | contribution=Termination for the Direct Sum of left-Linear Term Rewriting Systems (Preliminary Draft) | pages=477–491 |year=1989 | editor=[[Nachum Dershowitz]] | title=[[Rewriting Techniques and Applications]], 3rd Int. Conf., RTA-89 | series=[[LNCS]] | volume=355 | publisher=Springer}}
* {{cite book | author=Barendregt, H. | contribution=Computing and Proving (invited lecture)  | year=2001 | editor=Middeldorp, A. | title=Rewriting Techniques and Applications, 12th Int. Conf., RTA-01 | series=LNCS | volume=2051 | publisher=Springer}}  
*2013. ''Lambda Calculus with Types'', part of ''Perspectives in Logic''. Cambridge University Press. {{ISBN|9780521766142}}

==References==
{{reflist}}

==External links==
*[http://www.cs.ru.nl/~henk Barendregt's homepage]
* [https://zbmath.org/authors/?q=ai:barendregt.henk Author profile] in the database [[Zentralblatt MATH|zbMATH]]

{{Authority control}}

{{DEFAULTSORT:Barendregt, Henk}}
[[Category:1947 births]]
[[Category:Living people]]
[[Category:Dutch computer scientists]]
[[Category:Mathematical logicians]]
[[Category:Members of the Royal Netherlands Academy of Arts and Sciences]]
[[Category:Radboud University Nijmegen faculty]]
[[Category:Spinoza Prize winners]]
[[Category:Utrecht University alumni]]
[[Category:Scientists from Amsterdam]]</text>
      <sha1>mwnzk327aupxsb39d02ogng1bhsgsee</sha1>
    </revision>
  </page>
  <page>
    <title>Increased limit factor</title>
    <ns>0</ns>
    <id>51478216</id>
    <revision>
      <id>833090224</id>
      <parentid>790418088</parentid>
      <timestamp>2018-03-29T16:25:25Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed parent category of [[Category:Actuarial science]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5525">{{technical|date=June 2017}}
'''Increased limit factors''' or '''ILFs''' are multiplicative factors that are applied to premiums for "basic" limits of coverage to determine premiums for higher limits of coverage. They are commonly used in [[casualty insurance]] pricing.&lt;ref name=irmi&gt;{{cite|url=https://www.irmi.com/online/insurance-glossary/terms/i/increased-limit-factors.aspx|title=Glossary of Insurance &amp; Risk Management Terms: Increased limit factors}}&lt;/ref&gt;&lt;ref name=palm&gt;{{cite|url=https://www.casact.org/library/studynotes/palmer.pdf|title=Increased limits ratemaking for liability insurance|date=July 2006|first=Joseph|last=Palmer}}&lt;/ref&gt;

==Overview==

Often, limited data is available to determine appropriate charges for high limits of insurance. In order to price policies with high limits of insurance adequately, [[actuaries]] may first determine a "basic limit" premium and then apply increased limits factors. The basic limit is a lower limit of liability under which there is a more credible amount of data.&lt;ref name=palm&gt;&lt;/ref&gt;

For example, basic limit loss costs or rates may be calculated for many territories and classes of business. At a relatively low limit of liability, such as $100,000, there may be a high volume of data that can be used to derive those rates. For higher limits, there may be a credible volume of data at the countrywide level but not much data available for individual territories or classes. Increased limit factors can be derived at the countrywide level (or some other broad grouping) and then applied to the basic limit rates to arrive at rates for higher limits of liability.&lt;ref name=palm&gt;&lt;/ref&gt;

==Formula==
An increased limit factor (ILF) at limit L relative to basic limit B can be defined as

&lt;math&gt;ILF(L) = \dfrac{Expected\ indemnity\ cost(L) + ALAE(L) + ULAE(L) + RL(L)}{Expected\ indemnity\ cost(B) + ALAE(B) + ULAE(B) + RL(B)}&lt;/math&gt;

where ALAE is the allocated loss adjustment expense provision, ULAE is the unallocated loss adjustment expense provision, and RL is the risk load provision.&lt;ref name=palm&gt;&lt;/ref&gt;

An indemnity-only ILF can be expressed as

&lt;math&gt;ILF(L) = \dfrac{Expected\ indemnity\ cost(L)}{Expected\ indemnity\ cost(B)} = \dfrac{Expected\ frequency(L) * Expected\ severity(L)}{Expected\ frequency(B) * Expected\ severity(B)}&lt;/math&gt;&lt;ref name=palm&gt;&lt;/ref&gt;

Often, frequency is assumed to be independent of the policy limit, in which case the formula can be simplified to

&lt;math&gt;ILF(L) = \dfrac{Expected\ severity(L)}{Expected\ severity(B)}&lt;/math&gt;&lt;ref name=palm&gt;&lt;/ref&gt;
&lt;ref name=clark&gt;{{cite|url=http://www.casact.org/library/studynotes/Clark_2014.pdf|first=David|last=Clark|title=Basics of Reinsurance Pricing|page=27}}&lt;/ref&gt;&lt;ref name=wang&gt;{{cite|url=http://www.stat.sfu.ca/~cltsai/ACMA490/Wang_Ratemaking_1995.pdf|first=Shaun|last=Wang|title=Insurance pricing and increased limits ratemaking by proportional hazards transforms|page=43,52-53}}&lt;/ref&gt;

The expected severity at each limit is often referred to as "limited average severity," or LAS.&lt;ref name=palm&gt;&lt;/ref&gt;

==Examples==

In the United States, many insurers use ILFs published by the Insurance Services Office, a division of [[Verisk Analytics|Verisk]].&lt;ref name=wang&gt;&lt;/ref&gt;

== References ==
{{reflist}}

==Further reading==
*{{cite|url=http://www.insurancegateway.co.za/download/5409|title=The Determination of Revised Increased Limit Factors and Deductible Credits for S.A. Professional Indemnity and Fidelity Guarantee Insurance Business|first=Catherine|last=Berry|date=October 2009}}
*{{cite|url=https://www.willis.com/Documents/publications/Industries/Healthcare/Demystifying_Actuarial_Reports_V3.pdf|title=Demystifying Actuarial Reports|first=Brad|last=Norrick}}
*{{cite|url=https://www.casact.org/pubs/proceed/proceed91/91163.pdf|title=The competitive market equilibrium risk load formula for increased limits ratemaking|first=Glenn|last=Meyers}}

==External links==
*{{cite |url=https://www.casact.org/education/rpm/2011/handouts/WS1-Zhu.pdf|title=2011 RPM Basic Ratemaking Workshop. Section 3: Introduction to Increased Limits Factors|first=Li|last=Zhu}}
*{{cite |url=https://www.casact.org/library/studynotes/Werner_Modlin_Ratemaking.pdf|first1=Geoff|last1=Werner|first2=Claudine|last2=Modlin|title=Basic Ratemaking|chapter=Chapter 11|date=October 2010}}
*{{cite |url=https://www.thelibrarybook.net/pdf-increased-limits-ratemaking-for-liability-insurance.html |title=Increased limits ratemaking for liability insurance |first=Joseph|last=Palmer}}
*{{cite |url=https://www.casact.org/pubs/proceed/proceed77/77027.pdf|last=Miccolis|first=Robert|title=On the Theory of Increased Limits and Excess of Loss Pricing}}&lt;/ref&gt;
*{{cite |url=https://cas.confex.com/cas/rpms12/webprogram/Presentation/Session4766/CAS2012RPMSeminar_BasicRatemakingWorkshop_IncreasedLimitFactors_Handouts.pdf|first=Jared|last=Smollik |title=Basic Ratemaking Workshop: Intro to Increased Limits Factors}}
*{{cite |url=https://www.actuaries.org.uk/documents/extreme-value-techniques-part-iii-increased-limits-factors-ilf-pricing|first1=Hans-Fredo|last1=List|first2=Nora|last2=Lohner|title=Extreme Value Techniques, Part III: Increased Limits Factors (ILF) Pricing}}
*{{cite |url=https://books.google.com/books?id=nr_5YrljLaUC&amp;lpg=PA331&amp;ots=Nog6siZwHX&amp;dq=%22increased%20limits%20factors%22&amp;pg=PA331#v=onepage&amp;q=%22increased%20limits%20factors%22&amp;f=false|first=Andreas|last=Schwepcke |title=Reinsurance: Principles and State of the Art - A Guidebook for Home Learners|page=331}}

[[Category:Actuarial science]]</text>
      <sha1>nzzrd66uppmfblks03org40anw5wq3o</sha1>
    </revision>
  </page>
  <page>
    <title>Induced character</title>
    <ns>0</ns>
    <id>31429542</id>
    <revision>
      <id>547334400</id>
      <parentid>479602155</parentid>
      <timestamp>2013-03-27T21:33:39Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>clean up the (single) reference, add a wikilink, and clarify description of Brauer</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1485">In [[mathematics]], an '''induced character''' is the [[character (mathematics)|character]] of the [[group representation|representation]] ''V'' of a [[finite group]] ''G'' [[induced representation|induced]] from a representation ''W'' of a [[subgroup]] ''H'' ≤ ''G''.&lt;!-- Someone should generalize this article. Taku --&gt;  More generally, there is also a notion of [[induction of a class function|induction]] &lt;math&gt;\operatorname{Ind}(f)&lt;/math&gt; of a [[class function]] ''f'' on ''H'' given by the formula

:&lt;math&gt;\operatorname{Ind}(f)(s) = \frac{1}{|H|} \sum_{t \in G,\  t^{-1} st \in H} f(t^{-1} st).&lt;/math&gt;

If ''f'' is a character of the representation ''W'' of ''H'', then this formula for &lt;math&gt;\operatorname{Ind}(f)&lt;/math&gt; calculates the character of the induced representation ''V'' of ''G''.&lt;ref&gt;{{citation
 | last = Serre | first = Jean-Pierre | author-link = Jean-Pierre Serre
 | isbn = 0-387-90190-6
 | location = New York
 | mr = 0450380
 | at = 7.2, Proposition 20
 | publisher = Springer-Verlag
 | title = Linear Representations of Finite Groups
 | year = 1977}}. Translated from the second French edition by Leonard L. Scott.&lt;/ref&gt;

The basic result on induced characters is [[Brauer's theorem on induced characters]]. It states that every irreducible character on ''G'' is a [[linear combination]] with integer coefficients of characters induced from [[elementary group|elementary subgroup]]s.

== References ==
{{reflist}}

[[Category:Group theory]]

{{algebra-stub}}</text>
      <sha1>pnvzh7nlevlnnhwiemua7lk92scfdds</sha1>
    </revision>
  </page>
  <page>
    <title>Infimum and supremum</title>
    <ns>0</ns>
    <id>39382</id>
    <revision>
      <id>865413968</id>
      <parentid>853232820</parentid>
      <timestamp>2018-10-23T20:00:59Z</timestamp>
      <contributor>
        <ip>147.232.182.183</ip>
      </contributor>
      <comment>Changed larger than to larger then or equal to.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14516">
[[Image:Infimum illustration.svg|thumb|right|250px|A set ''T'' of real numbers (red and green balls), a subset ''S'' of ''T'' (green balls), and the infimum of ''S''. Note that for finite, totally ordered  sets the infimum and the [[minimum]] are equal.]]
[[Image:Supremum illustration.png|thumb|right|250px|A set ''A'' of real numbers (blue balls), a set of upper bounds of ''A'' (red diamond and balls), and the smallest such upper bound, that is, the supremum of ''A'' (red diamond).]]

In [[mathematics]], the '''infimum''' (abbreviated '''inf'''; plural '''infima''') of a [[subset]] ''S'' of a [[partially ordered set]] ''T'' is the [[greatest element]] in ''T'' that is less than or equal to all elements of ''S'', if such an element exists.&lt;ref name=BabyRudin&gt;{{cite book |first=Walter |last=Rudin |authorlink=Walter Rudin |title=Principles of Mathematical Analysis |location= |publisher=McGraw-Hill |edition=3rd |year=1976 |isbn=0-07-054235-X |chapter="Chapter 1 The Real and Complex Number Systems" |format="print" |page=4 |url=https://books.google.com/books?id=kwqzPAAACAAJ }}&lt;/ref&gt;  Consequently, the term ''greatest lower bound'' (abbreviated as ''GLB'') is also commonly used.&lt;ref name=BabyRudin /&gt;

The '''supremum''' (abbreviated '''sup'''; plural '''suprema''') of a subset ''S'' of a partially ordered set ''T'' is the [[greatest element|least element]] in ''T'' that is greater than or equal to all elements of ''S'', if such an element exists.&lt;ref name=BabyRudin /&gt; Consequently, the supremum is also referred to as the ''least upper bound'' (or ''LUB'').&lt;ref name=BabyRudin /&gt;

The infimum is in a precise sense [[Duality (order theory)|dual]] to the concept of a supremum.  Infima and suprema of [[real number]]s are common special cases that are important in [[mathematical analysis|analysis]], and especially in [[Lebesgue integration]].  However, the general definitions remain valid in the more abstract setting of [[order theory]] where arbitrary partially ordered sets are considered.

The concepts of infimum and supremum are similar to [[minimum]] and [[maximum]], but are more useful in analysis because they better characterize special sets which may have ''no minimum or maximum''.  For instance, the [[positive real numbers]] ℝ&lt;sup&gt;+&lt;/sup&gt; (not including 0) does not have a minimum, because any given element of ℝ&lt;sup&gt;+&lt;/sup&gt; could simply be divided in half resulting in a smaller number that is still in ℝ&lt;sup&gt;+&lt;/sup&gt;.  There is, however, exactly one infimum of the positive real numbers: 0, which is smaller than all the positive real numbers and greater than any other real number which could be used as a lower bound.

== Formal definition ==
[[File:Illustration of supremum.svg|thumb|supremum = least upper bound]]
A ''lower bound'' of a subset ''S'' of a partially ordered set (''P'',≤) is an element ''a'' of ''P'' such that
* ''a'' ≤ ''x'' for all ''x'' in ''S''.
A lower bound ''a'' of ''S'' is called an ''infimum'' (or ''greatest lower bound'', or ''meet'') of ''S'' if
* for all lower bounds ''y'' of ''S'' in ''P'', ''y'' ≤ ''a'' (''a'' is larger than or equal to any other lower bound).

Similarly, an ''upper bound'' of a subset ''S'' of a partially ordered set (''P'',≤) is an element ''b'' of ''P'' such that
* ''b'' ≥ ''x'' for all ''x'' in ''S''.
An upper bound ''b'' of ''S'' is called a ''supremum'' (or ''least upper bound'', or ''join'') of ''S'' if
* for all upper bounds ''z'' of ''S'' in ''P'', ''z'' ≥ ''b'' (''b'' is less than any other upper bound).

== Existence and uniqueness ==

Infima and suprema do not necessarily exist. Existence of an infimum of a subset ''S'' of ''P'' can fail if ''S'' has no lower bound at all, or if the set of lower bounds does not contain a maximal element. However, if an infimum or supremum does exist, it is unique.

Consequently, partially ordered sets for which certain infima are known to exist become especially interesting. For instance, a [[lattice (order)|lattice]] is a partially ordered set in which all {{em|nonempty finite}} subsets have both a supremum and an infimum, and a [[complete lattice]] is a partially ordered set in which {{em|all}} subsets have both a supremum and an infimum. More information on the various classes of partially ordered sets that arise from such considerations are found in the article on [[completeness (order theory)|completeness properties]].

If the supremum of a subset ''S'' exists, it is unique.  If ''S'' contains a greatest element, then that element is the supremum; otherwise, the supremum does not belong to ''S'' (or does not exist).  Likewise, if the infimum exists, it is unique.  If ''S'' contains a least element, then that element is the infimum; otherwise, the infimum does not belong to ''S'' (or does not exist).

== Relation to maximum and minimum elements ==

The infimum of a subset ''S'' of a partially ordered set ''P'', assuming it exists, does not necessarily belong to ''S''. If it does, it is a [[maximal element|minimum or least element]] of ''S''. Similarly, if the supremum of ''S'' belongs to ''S'', it is a [[maximal element|maximum or greatest element]] of ''S''.

For example, consider the set of negative real numbers (excluding zero).  This set has no greatest element, since for every element of the set, there is another, larger, element.  For instance, for any negative real number ''x'', there is another negative real number &lt;math&gt;\tfrac{x}{2}&lt;/math&gt;, which is greater. On the other hand, every real number greater than or equal to zero is certainly an upper bound on this set.  Hence, 0 is the least upper bound of the negative reals, so the supremum is 0. This set has a supremum but no greatest element.

However, the definition of [[maximal element|maximal and minimal elements]] is more general. In particular, a set can have many maximal and minimal elements, whereas infima and suprema are unique.

=== Minimal upper bounds ===
Finally, a partially ordered set may have many minimal upper bounds without having a least upper bound. Minimal upper bounds are those upper bounds for which there is no strictly smaller element that also is an upper bound. This does not say that each minimal upper bound is smaller than all other upper bounds, it merely is not greater. The distinction between "minimal" and "least" is only possible when the given order is not a [[totally ordered set|total]] one. In a totally ordered set, like the real numbers, the concepts are the same.

As an example, let ''S'' be the set of all finite subsets of natural numbers and consider the partially ordered set obtained by taking all sets from ''S'' together with the set of [[integer]]s ℤ and the set of positive real numbers ℝ&lt;sup&gt;+&lt;/sup&gt;, ordered by subset inclusion as above. Then clearly both ℤ and ℝ&lt;sup&gt;+&lt;/sup&gt; are greater than all finite sets of natural numbers. Yet, neither is ℝ&lt;sup&gt;+&lt;/sup&gt; smaller than ℤ nor is the converse true: both sets are minimal upper bounds but none is a supremum.

=== Least-upper-bound property ===
{{main|Least-upper-bound property}}

The ''least-upper-bound property'' is an example of the aforementioned [[completeness (order theory)|completeness properties]] which is typical for the set of real numbers. This property is sometimes called ''Dedekind completeness''.

If an ordered set ''S'' has the property that every nonempty subset of ''S'' having an upper bound also has a least upper bound, then ''S'' is said to have the least-upper-bound property.  As noted above, the set ℝ of all real numbers has the least-upper-bound property.  Similarly, the set ℤ of integers has the least-upper-bound property; if ''S'' is a nonempty subset of ℤ and there is some number ''n'' such that every element ''s'' of ''S'' is less than or equal to ''n'', then there is a least upper bound ''u'' for ''S'', an integer that is an upper bound for ''S'' and is less than or equal to every other upper bound for ''S''. A [[well-order]]ed set also has the least-upper-bound property, and the empty subset has also a least upper bound: the minimum of the whole set.

An example of a set that ''lacks'' the least-upper-bound property is ℚ, the set of rational numbers.  Let ''S'' be the set of all rational numbers ''q''  such that ''q''&lt;sup&gt;2&lt;/sup&gt; &lt; 2. Then ''S'' has an upper bound (1000, for example, or 6) but no least upper bound in ℚ: If we suppose ''p'' ∈ ℚ is the least upper bound, a contradiction is immediately deduced because between any two reals ''x'' and ''y'' (including [[square root of 2|{{sqrt|2}}]] and ''p'') there exists some rational ''p''′, which itself would have to be the least upper bound (if ''p'' &gt; {{sqrt|2}}) or a member of ''S'' greater than ''p'' (if ''p'' &lt; {{sqrt|2}}). Another example is the [[hyperreals]]; there is no least upper bound of the set of positive infinitesimals.

There is a corresponding 'greatest-lower-bound property'; an ordered set possesses the greatest-lower-bound property if and only if it also possesses the least-upper-bound property; the least-upper-bound of the set of lower bounds of a set is the greatest-lower-bound, and the greatest-lower-bound of the set of upper bounds of a set is the least-upper-bound of the set.

If in a partially ordered set ''P'' every bounded subset has a supremum, this applies also, for any set ''X'', in the function space containing all functions from ''X'' to ''P'', where ''f'' ≤ ''g'' if and only if ''f''(''x'') ≤ ''g''(''x'') for all ''x'' in ''X''. For example, it applies for real functions, and, since these can be considered special cases of functions, for real ''n''-tuples and sequences of real numbers.

The [[least-upper-bound property]] is an indicator of the suprema.

== Infima and suprema of real numbers ==

In [[mathematical analysis|analysis]], infima and suprema of subsets ''S'' of the [[real numbers]] are particularly important. For instance, the negative [[real number]]s do not have a greatest element, and their supremum is 0 (which is not a negative real number).&lt;ref name=BabyRudin /&gt;
The [[completeness of the real numbers]] implies (and is equivalent to) that any bounded nonempty subset ''S'' of the real numbers has an infimum and a supremum. If ''S'' is not bounded below, one often formally writes inf(''S'') = −∞. If ''S'' is [[empty set|empty]], one writes inf(''S'') = +∞.

=== Properties ===
Let ''A'', ''B'' ⊆ ℝ and suppose the infima and suprema of these sets exist.  Define ''λA'' = { ''λx'' : ''x'' ∈ ''A'' }, ''A'' + ''B'' = { ''x'' + ''y'' : ''x'' ∈ ''A'', ''y'' ∈ ''B'' }, and ''AB'' = { ''xy'' : ''x'' ∈ ''A'', ''y'' ∈ B }.
* ''p'' = inf ''A'' if and only if for every ''ε'' &gt; 0 there is an ''x'' ∈ ''A'' with ''x'' &lt; ''p'' + ''ε'', and ''x'' ≥ ''p'' for every ''x'' ∈ ''A''.
* ''p'' = sup ''A'' if and only if for every ''ε'' &gt; 0 there is an ''x'' ∈ ''A'' with ''x'' &gt; ''p'' − ''ε'', and ''x'' ≤ ''p'' for every ''x'' ∈ ''A''.
* If ''A'' ⊆ ''B'' then inf ''A'' ≥ inf ''B'' and sup ''A'' ≤ sup ''B''.
* If ''λ'' ≥ 0, then inf ''λA'' = ''λ'' inf ''A'' and sup ''λA'' = ''λ'' sup ''A''.
* If ''λ'' &lt; 0, then inf ''λA'' = ''λ'' sup ''A'' and sup ''λA'' = ''λ'' inf ''A''.
* inf ''A'' + ''B'' = inf ''A'' + inf ''B''; similarly for suprema.
* If ''A'', ''B'' are sets of ''positive'' real numbers then inf ''AB'' = inf ''A'' · inf ''B''; similarly for suprema.&lt;ref = "zakon"&gt;{{cite book |title=Mathematical Analysis I |first=Elias |last=Zakon |pages=39–42 |publisher=Trillia Group |date=2004  |url=http://www.trillia.com/zakon-analysisI.html}}&lt;/ref&gt;

== Duality ==

If one denotes by ''P''&lt;sup&gt;op&lt;/sup&gt; the partially-ordered set ''P'' with the opposite order relation, i.e.
* ''x'' ≤ ''y'' in ''P''&lt;sup&gt;op&lt;/sup&gt; if and only if ''x'' ≥ ''y'' in ''P'',
then infimum of a subset ''S'' in ''P'' equals the supremum of ''S'' in ''P''&lt;sup&gt;op&lt;/sup&gt; and vice versa.

For subsets of the real numbers, another kind of duality holds: inf ''S'' = −sup(−''S''), where −''S'' = { −''s'' | ''s'' ∈ ''S'' }.

== Examples ==

=== Infima ===

*The infimum of the set of numbers {{nowrap|{2,3,4}}} is 2. The number 1 is a lower bound, but not the greatest lower bound, and hence not the infimum.
*More generally, if a set has a smallest element, then the smallest element is the infimum for the set.  In this case, it is also called the [[minimum]] of the set.
*&lt;math&gt;\inf \{ 1,2,3,\ldots \} = 1&lt;/math&gt;
*&lt;math&gt;\inf \{ x \in \mathbb{R} \mid 0 &lt; x &lt; 1 \} = 0&lt;/math&gt;
*&lt;math&gt;\inf \{ x \in \mathbb{Q} \mid x^3 &gt; 2 \} = \sqrt[3]{2}&lt;/math&gt;
*&lt;math&gt;\inf \left\{ (-1)^n + \tfrac{1}{n} \mid n = 1,2,3,\ldots \right\} = -1&lt;/math&gt;
*If ''x&lt;sub&gt;n&lt;/sub&gt;'' is a decreasing sequence with limit ''x'', then {{nowrap|inf ''x&lt;sub&gt;n&lt;/sub&gt;'' {{=}} ''x''}}.

=== Suprema ===
*The supremum of the set of numbers {1,2,3} is 3. The number 4 is an upper bound, but it is not the least upper bound, and hence is not the supremum.
*&lt;math&gt;\sup \{ x \in \mathbb{R} \mid 0 &lt; x &lt; 1\} = \sup \{ x \in \mathbb{R} \mid 0 \leq x \leq 1\} = 1&lt;/math&gt;
*&lt;math&gt;\sup \left\{ (-1)^n - \tfrac{1}{n} \mid n = 1,2,3,\ldots \right\} = 1&lt;/math&gt;
*&lt;math&gt;\sup \{ a + b \mid a \in A, b \in B \} = \sup A + \sup B&lt;/math&gt;
*&lt;math&gt;\sup \{ x \in \mathbb{Q} \mid x^2 &lt; 2 \} = \sqrt{2}&lt;/math&gt;
In the last example, the supremum of a set of [[rational number|rationals]] is [[irrational number|irrational]], which means that the rationals are [[complete space|incomplete]].

One basic property of the supremum is

:&lt;math&gt;\sup \{ f(t) + g(t) \mid t \in A \} \leq \sup \{ f(t) \mid t \in A \} + \sup \{ g(t) \mid t \in A \}&lt;/math&gt;

for any [[functional (mathematics)|functionals]] ''f'' and ''g''.

The supremum of a subset ''S'' of (ℕ,|) where | denotes "[[Divisor|divides]]", is the [[lowest common multiple]] of the elements of ''S''.

The supremum of a subset ''S'' of (''P'',⊆), where ''P'' is the [[power set]] of some set, is the supremum with respect to ⊆ (subset) of a subset ''S'' of ''P'' is the [[union (set theory)|union]] of the elements of ''S''.

== See also ==
{{Commons category}}
* [[Essential supremum and essential infimum]]
* [[Limit superior and limit inferior]] (infimum limit)
* [[Maximal element]]
* [[Partially ordered set]]
* [[Total order]]
* [[Lattice (order)|Lattice]]
* [[Complete lattice]]

== References ==
{{reflist}}

== External links ==
* {{springer|title=Upper and lower bounds|id=p/u095810}}
* {{mathworld|Supremum|author=Breitenbach, Jerome R. and Weisstein, Eric W.}}

[[Category:Order theory]]</text>
      <sha1>lrp8yt1b52g6v52yfu8z14dgu2vmoqe</sha1>
    </revision>
  </page>
  <page>
    <title>Iterative closest point</title>
    <ns>0</ns>
    <id>1830232</id>
    <revision>
      <id>868197040</id>
      <parentid>858549259</parentid>
      <timestamp>2018-11-10T17:09:16Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>clean up, replaced: IEEE Trans. on Pattern Analysis and Machine Intelligence → IEEE Transactions on Pattern Analysis and Machine Intelligence</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7004">{{More footnotes|date=February 2017}}
'''Iterative closest point''' ('''ICP''')&lt;ref name="autogenerated239"&gt;{{cite journal|last=Besl|first=Paul J.|author2=N.D. McKay|title=A Method for Registration of 3-D Shapes|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|year=1992|volume=14|pages=239–256|doi=10.1109/34.121791|publisher=IEEE Computer Society|location=Los Alamitos, CA, USA|issue=2}}&lt;/ref&gt;&lt;ref name="autogenerated145"&gt;{{cite journal|last=Chen|first=Yang|author2=Gerard Medioni|title=Object modelling by registration of multiple range images|journal=Image Vision Comput.|year=1991|pages=145–155|doi=10.1016/0262-8856(92)90066-C|publisher=Butterworth-Heinemann|location=Newton, MA, USA}}&lt;/ref&gt;&lt;ref name="zhang IJCV 1994"/&gt; is an [[algorithm]] employed to [[point set registration|minimize the difference between two clouds of points]]. ICP is often used to reconstruct 2D or 3D surfaces from different scans, to localize robots and achieve optimal path planning (especially when wheel odometry is unreliable due to slippery terrain), to co-register [[bone]] models, etc.

==Overview==
In the Iterative Closest Point or, in some sources, the Iterative Corresponding Point, one point cloud (vertex cloud), the ''reference'', or ''target'', is kept fixed, while the other one, the ''source'', is transformed to best match the reference. The algorithm iteratively revises the transformation (combination of translation and rotation) needed to minimize an error metric, usually a distance from the source to the reference point cloud, such as the sum of squared differences between the coordinates of the matched pairs. ICP is one of the widely used algorithms in aligning three dimensional models given an initial guess of the rigid body transformation required.&lt;ref name="rusinkiewicz145"&gt;{{cite conference|last=Rusinkiewicz|first=Szymon|author2=Marc Levoy|title=Efficient Variants of the ICP Algorithm|conference=Proceedings Third International Conference on 3-D Digital Imaging and Modeling|year=2001|pages=145–152|doi=10.1109/IM.2001.924423|location=Quebec City, Quebec, Canada}}&lt;/ref&gt;
The ICP algorithm was first introduced by Chen and Medioni,&lt;ref name="autogenerated145"/&gt; and Besl and McKay.&lt;ref name="autogenerated239"/&gt;

The Iterative Closest Point algorithm contrasts with the [[Kabsch algorithm]] and other solutions to the [[orthogonal Procrustes problem]] in that the Kabsch algorithm requires correspondence between point sets as an input where-as Iterative Closest Point treats correspondence as a variable to be estimated.

Inputs: reference and source point clouds, initial estimation of the transformation to align the source to the reference (optional), criteria for stopping the iterations.

Output: refined transformation.

Essentially, the algorithm steps are:&lt;ref name="rusinkiewicz145"/&gt;

# For each point (from the whole set of vertices usually referred to as dense or a selection of pairs of vertices from each model) in the source point cloud, Match the closest point in the reference point cloud (or a selected set).
# Estimate the combination of rotation and translation using a root mean square point to point distance metric minimization technique which will best align each source point to its match found in the previous step. This step may also involve weighting points and rejecting outliers prior to alignment.
# Transform the source points using the obtained transformation.
# [[Iterative method|Iterate]] (re-associate the points, and so on).

Zhang &lt;ref name="zhang IJCV 1994"&gt;{{cite journal|last=Zhang|first=Zhengyou|title=Iterative point matching for registration of free-form curves and surfaces|journal=International Journal of Computer Vision|year=1994|volume=13|issue=12|pages=119–152|doi=10.1007/BF01427149|publisher=Springer}}&lt;/ref&gt; proposes a modified [[K-d tree|K-D tree]] algorithm for efficient closest point computation. In this work a statistical method based on the distance distribution is used to deal with outliers, occlusion, appearance, and disappearance, which enables subset-subset matching.

There exist many ICP variants,&lt;ref name=reviewPointCloud&gt;{{cite journal|last1=Pomerleau|first1=François|last2=Colas|first2=Francis|last3=Siegwart|first3=Roland|title=A Review of Point Cloud Registration Algorithms for Mobile Robotics|journal=Foundations and Trends in Robotics|date=2015|volume=4|issue=1|pages=1–104|doi=10.1561/2300000035|url=https://www.researchgate.net/publication/277558596_A_Review_of_Point_Cloud_Registration_Algorithms_for_Mobile_Robotics}}&lt;/ref&gt; from which point-to-point and point-to-plane are the most popular. The latter usually performs better in structured environments.&lt;ref&gt;{{cite web|url=http://www.comp.nus.edu.sg/~lowkl/publications/lowk_point-to-plane_icp_techrep.pdf |format=PDF |publisher=Technical Report TR04-004, Department of Computer Science, University of North Carolina at Chapel Hill |date=February 2004 |title=Linear Least-Squares Optimization for Point-to-Plane ICP Surface Registration |author=Kok-Lim Low |website=Comp.nys.edu.sg |accessdate=2017-02-27}}&lt;/ref&gt;&lt;ref&gt;François Pomerleau, Francis Colas, Roland Siegwart, and Stéphane Magnenat. [http://stephane.magnenat.net/publications/Comparing%20ICP%20Variants%20on%20Real-World%20Data%20Sets%20-%20Pomerleau%20et%20al.%20-%20Autonomous%20Robots%20-%202013.pdf Comparing ICP Variants on Real-World Data Sets.] In Autonomous Robots, 34(3), pages 133–148, DOI: 10.1007/s10514-013-9327-2, April 2013.&lt;/ref&gt;

==Implementations==
* [[MeshLab]] an open source mesh processing tool that includes a GNU General Public License implementation of the ICP algorithm.
* [[CloudCompare]] an open source point and model processing tool that includes an implementation of the ICP algorithm. Released under the GNU General Public License.
* [[PCL (Point Cloud Library)]] is an open-source framework for n-dimensional point clouds and 3D geometry processing. It includes several variants of the ICP algorithm.&lt;ref name=PCL-Tutorial&gt;{{cite journal|last1=Holz|first1=Dirk|last2=Ichim |first2= Alexandru E.|last3=Tombari|first3=Federico| last4=Rusu|first4= Radu B.| last5= Behnke |first5=Sven|title= Registration with the Point Cloud Library: A Modular Framework for Aligning in 3-D | journal=IEEE Robotics Automation Magazine|date=2015|volume=22|issue=4|pages=110–124|doi= 10.1109/MRA.2015.2432331|url= https://www.researchgate.net/publication/283198426_Registration_with_the_Point_Cloud_Library_-_A_Modular_Framework_for_Aligning_in_3-D }}&lt;/ref&gt;
* Open source C++ implementations of the ICP algorithm are available in [[VTK]], [[Insight Segmentation and Registration Toolkit|ITK]] and [http://www.open3d.org Open3D] libraries.
* [https://github.com/ethz-asl/libpointmatcher libpointmatcher] is an implementation of point-to-point and point-to-plane ICP released under a BSD license.

== See also ==
* [[Point set registration]]

==References==
{{reflist|30em}}

[[Category:Geometry in computer vision]]
[[Category:Robot navigation]]</text>
      <sha1>m6i372jv1wu8afgmydqzxetxnlkvhpa</sha1>
    </revision>
  </page>
  <page>
    <title>K-connectivity certificate</title>
    <ns>0</ns>
    <id>48785760</id>
    <revision>
      <id>775314024</id>
      <parentid>775313858</parentid>
      <timestamp>2017-04-14T02:20:08Z</timestamp>
      <contributor>
        <username>Karlpoppery</username>
        <id>30732546</id>
      </contributor>
      <comment>Added {{[[Template:copypaste|copypaste]]}} tag to article ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8317">{{copypaste|date=April 2017}}
{{DISPLAYTITLE:''k''-connectivity certificate}}
{{multiple issues|
{{refimprove|date=February 2016}}
{{Orphan|date=December 2015}}
}}

[[File:Kv3.PNG|thumb|419x419px|Graph on the right is a ''k''-connectivity certificate for the graph ''G'' on the left for k=1,2.]]
In [[graph theory]], for a [[K-connected graph|k-connected]] [[Graph (discrete mathematics)|graph]] G = (V, E), a subset of edges &lt;math&gt;E' \subseteq E&lt;/math&gt; is considered a certificate for the [[K-connected graph|k-connectivity]] of the graph G if and only if the subgraph G' = (V, E') is [[K-connected graph|k-connected]].&lt;ref&gt;{{Cite journal|title = An Algorithm for Determining Whether the Connectivity of a Graph is at Least k|url = http://epubs.siam.org/doi/abs/10.1137/0204034|journal = SIAM Journal on Computing|date = 1975-09-01|issn = 0097-5397|pages = 393–396|volume = 4|issue = 3|doi = 10.1137/0204034|first = S.|last = Even}}&lt;/ref&gt;

== Sparse certificates ==

For a k-connected graph with ''n'' [[Vertex (graph theory)|vertices]], there always exists a [[K-vertex-connected graph|''k''-connectivity]] certificate with at most k(n-1) edges. K-connectivity certificates are considered sparse if they contain ''O''(''kn'') edges.&lt;ref name=":0" /&gt; In this figure, the graph on the right is also a sparse certificate for the graph ''G'' on the left.

== Scan-first search ==
Scan-First is an algorithm for the parallel construction of [[K-vertex-connected graph|k-connectivity]] certificates for graphs. It was introduced in the paper Scan-First Search and Sparse Certificates: An Improved Parallel Algorithm for [[K-vertex-connected graph|K-Vertex Connectivity]] by Joseph Cheriyan, Ming-Yang Kao, and Ramakrishna Thurimella.&lt;ref name=":0"&gt;{{Cite journal|title = Scan-First Search and Sparse Certificates: An Improved Parallel Algorithm for k-Vertex Connectivity|url = http://epubs.siam.org/doi/abs/10.1137/0222013|journal = SIAM Journal on Computing|date = 1993-02-01|issn = 0097-5397|pages = 157–174|volume = 22|issue = 1|doi = 10.1137/0222013|first = J.|last = Cheriyan|first2 = M.|last2 = Kao|first3 = R.|last3 = Thurimella}}&lt;/ref&gt; The Scan-First Search algorithm improves the running time of building a sparse certificate for [[K-vertex-connected graph|k-connectivity]] using the parallel computation model.

We can find a sparse certificate for k-connectivity by iteratively running scan-first search k times on sub-graphs of our input graph. Our input is a graph G = (V, E) and a root vertex r. For each iteration of scan-first search, we first compute a spanning tree T of our input graph G, and assign a pre-order numbering to all the vertices, which we will use as our scanning order. From our root r, we first scan r, which involves marking all its neighboring vertices.

Given a connected undirected graph and a specified vertex, a scan-first search in the graph starting from the specified vertex is a systematic way of marking the vertices. The main marking step is called ''scan'': to scan a marked vertex means to mark all previously unmarked neighbors of that vertex. At the beginning of the search, only the specified starting vertex is marked. Then the search iteratively scans a marked and unscanned vertex until all vertices are scanned.

A scan-first search in a connected undirected graph produces a spanning tree defined as follows. At the beginning of the search, the tree is empty. Then, for each vertex x in the graph, when x is scanned, all the edges between x and its previously unmarked neighbors are added to the tree; the edges between x and its previously marked neighbors are not added to the tree.
[[File:Sfs.PNG|thumb|543x543px|An example showing two iterations of scan-first search on the graph G. For a k-Connected graph, we do k iterations of Scan-first Search. First and second iterations of Scan-first Search are shown above.]]
All previously unmarked vertices constitute the end-point of an edge from the currently scanned vertex, so if we start from some vertex v, and it has neighbors w and x, then if both w and x are unmarked, we create the edges (v, w) and (v, x) and add them to our output tree T'. If either w or x was previously marked, we do not add the edge that includes that vertex to T'. With these new edges in T', we move to the next vertex with the lowest preorder number to scan, which involves continuously marking previously unmarked vertices and adding the edges from the current vertex to these vertices to our output tree.

We use scan-first search to generate certificates for k-connectivity by running it for k iterations. An important note moving forward is that for each edge added to some output tree T' in each iteration, we remove the edges from the original graph G so they may not be included in some spanning forest for the next iteration. However, we can view the markings on the vertices as reset, so no vertices are marked on the next iteration.

Once we have exhausted all vertices, we have an edge set for the first iteration, E&lt;sub&gt;1&lt;/sub&gt;. We then remove E&lt;sub&gt;1&lt;/sub&gt; from G = G&lt;sub&gt;0&lt;/sub&gt;, and make that G&lt;sub&gt;1&lt;/sub&gt;, and move onto the second iteration using the graph G&lt;sub&gt;1&lt;/sub&gt;. At the end of each iteration we have:
** E&lt;sub&gt;i&lt;/sub&gt; : The set of edges we encountered during our scan-first search
** F&lt;sub&gt;i&lt;/sub&gt; : Scan-first search forest, the grouping of edges into what may be separate trees at each step.
** G&lt;sub&gt;i&lt;/sub&gt; : The resulting graph from removing E&lt;sub&gt;i&lt;/sub&gt; from the graph G&lt;sub&gt;i-1&lt;/sub&gt; that we used to begin this iteration.
** H&lt;sub&gt;i&lt;/sub&gt; : The union the edges from every iteration to now, E&lt;sub&gt;1&lt;/sub&gt; ∪ E&lt;sub&gt;2&lt;/sub&gt; ∪ ... ∪ E&lt;sub&gt;i&lt;/sub&gt;. 
We say that ''H&lt;sub&gt;k&lt;/sub&gt;'' is the sparse certificate for the graph G.

=== The Main Certificate Theorem ===
Given an undirected [[Graph (discrete mathematics)|graph]] ''G'' = (''V'', ''E'') with ''n'' vertices, let ''k'' be some positive integer. For all ''i'' = 1, 2, . . . , ''k'', let ''E''&lt;sub&gt;''i''&lt;/sub&gt; be the set of edges generated by the ''i''-th iteration of scan-first search, corresponding to a graph ''G''&lt;sub&gt;''i''−1&lt;/sub&gt; = (''V'', ''E'' − (''E''&lt;sub&gt;1&lt;/sub&gt; ∪ . . . ∪ ''E''&lt;sub&gt;''i''−1&lt;/sub&gt;)). So for each iteration of scan-first search, as stated above, we will remove edges from the graph ''G'' to create some new graph ''G''&lt;sub&gt;''i''&lt;/sub&gt; that results at the end of the ''i''th iteration. For every iteration ''i'', our scan-first search forest is built from the graph ''G''&lt;sub&gt;''i''−1&lt;/sub&gt;, where ''G'' = ''G''&lt;sub&gt;0&lt;/sub&gt;. The claim of the Main Certificate Theorem is that the union ''E''&lt;sub&gt;1&lt;/sub&gt; ∪ . . . ∪ ''E''&lt;sub&gt;''k''&lt;/sub&gt; is a certificate for the ''k''-vertex connectivity of ''G'' and that it has at most {{nowrap|''k''(''n'' − 1)}} edges.&lt;ref name=":0" /&gt;

=== Computational complexity ===
The most important running-time is that of the algorithm running in parallel, using the CRCW PRAM model in this case. Our first spanning tree ''T'' can be found in {{nowrap|''O''(log ''n'')}} time using ''C''(''n'',''m'') processors. Our preorder numbers and neighbours can also be calculated in O(log n) time because parallel techniques&lt;ref&gt;{{Cite book|title = Handbook of Theoretical Computer Science (Vol. A)|url = http://dl.acm.org/citation.cfm?id=114872.114889|publisher = MIT Press|date = 1990-01-01|location = Cambridge, MA, USA|isbn = 0-444-88071-2|pages = 869–941|first = Richard M.|last = Karp|first2 = Vijaya|last2 = Ramachandran|editor-first = Jan|editor-last = van Leeuwen}}&lt;/ref&gt; with {{nowrap|''O''((''n'' + ''m'')/log ''n'')}} processors, our ''C''(''n'',''m'') value. For this reason, we can generate a single ''T&amp;prime'' corresponding to one iteration in ''O''(log ''n'') time.

Using a distributed breadth-first search approach, we can find our spanning forest in {{nowrap|''O''(''d'' log&lt;sup&gt;3&lt;/sup&gt; ''n'')}} time on a graph with diameter ''d'' using {{nowrap|''O''(''m'' + ''n'' log&lt;sup&gt;3&lt;/sup&gt; ''n'')}} messages. The sequential approach is quite simply the running time for breadth-first search, {{nowrap|''O''(''m'' + ''n'')}}.

== See also ==
* [[K-vertex-connected graph|k-vertex connectivity]]
* [[K-edge-connected graph|k-edge connectivity]]
* [[Menger's theorem]]
* [[Connectivity (graph theory)]]

== References ==
&lt;references /&gt;



[[Category:Graph connectivity]]</text>
      <sha1>b7bp8h53xfmovojnufujoaha8w1vzvp</sha1>
    </revision>
  </page>
  <page>
    <title>Karl Menninger (mathematics)</title>
    <ns>0</ns>
    <id>5496919</id>
    <revision>
      <id>707905068</id>
      <parentid>668396068</parentid>
      <timestamp>2016-03-02T13:47:48Z</timestamp>
      <contributor>
        <username>KasparBot</username>
        <id>24420788</id>
      </contributor>
      <comment>migrating [[Wikipedia:Persondata|Persondata]] to Wikidata, [[toollabs:kasparbot/persondata/|please help]], see [[toollabs:kasparbot/persondata/challenge.php/article/Karl Menninger (mathematics)|challenges for this article]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1065">{{About|the mathematician|the psychiatrist|Karl Menninger}}
{{other people|Menninger}}

'''Karl Menninger''' (October 6, 1898 &amp;ndash; October 2, 1963) was a [[German people|German]] teacher of and writer about mathematics.  His major work was ''Zahlwort und Ziffer'' (1934,; English trans., ''Number Words and Number Symbols''), about non-academic mathematics in much of the world.  (The omission of [[Africa]] was rectified by [[Claudia Zaslavsky]] in her book ''Africa Counts''.)

==References==

*Dauben, Joseph Warren, and Christoph Scriba, eds. (2002), ''Writing the History of Mathematics'', Birkhäuser, Basel, page 483.
*Menninger, Karl (1934), ''Zahlwort und Ziffer''.  Revised edition (1958).  Göttingen: Vandenhoeck and Ruprecht.
*Menninger, Karl (1969), ''Number Words and Number Symbols''.  Cambridge, Mass.: The M.I.T. Press.

{{Authority control}}
{{DEFAULTSORT:Menninger, Karl}}
[[Category:Historians of mathematics]]
[[Category:20th-century German mathematicians]]
[[Category:1898 births]]
[[Category:1963 deaths]]


{{germany-mathematician-stub}}</text>
      <sha1>c6w4qtq6knmeuv4h94gzvjdg8o2shhh</sha1>
    </revision>
  </page>
  <page>
    <title>Local cohomology</title>
    <ns>0</ns>
    <id>3212091</id>
    <revision>
      <id>856155805</id>
      <parentid>854968048</parentid>
      <timestamp>2018-08-23T07:45:10Z</timestamp>
      <contributor>
        <username>Latex-yow</username>
        <id>27692366</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9670">In [[algebraic geometry]], '''local cohomology''' is an analog of [[relative cohomology]]. [[Alexander Grothendieck]] introduced it in seminars in Harvard in 1961 written up by {{harvtxt|Hartshorne|1967}}, and in 1961-2 at IHES written up as [[SGA2]]  - {{harvtxt|Grothendieck|1968}}, republished as {{harvtxt|Grothendieck|2005}}.

==Definition==
In the geometric form of the theory, sections Γ&lt;sub&gt;''Y''&lt;/sub&gt; are considered of a [[sheaf (mathematics)|sheaf]] ''F'' of [[abelian group]]s, on a [[topological space]] ''X'', with [[support (mathematics)|support]] in a [[closed subset]] ''Y''. The [[derived functor]]s of Γ&lt;sub&gt;''Y''&lt;/sub&gt; form '''local cohomology groups'''

:&lt;math&gt;H_Y^i(X,F)&lt;/math&gt;

For applications in [[commutative algebra]], the space ''X'' is the [[spectrum of a ring|spectrum]] Spec(''R'') of a commutative ring ''R'' (supposed to be [[Noetherian ring|Noetherian]] throughout this article) and the sheaf ''F'' is the [[quasicoherent sheaf]] associated to an ''R''-[[module (mathematics)|module]] ''M'', denoted by &lt;math&gt;\tilde M&lt;/math&gt;. The [[closed subscheme]] ''Y'' is defined by an [[ideal (ring theory)|ideal]] ''I''. In this situation, the functor Γ&lt;sub&gt;''Y''&lt;/sub&gt;(''F'') corresponds to the [[annihilator (ring theory)|annihilator]]

:&lt;math&gt;\Gamma_I(M) := \bigcup_{n \ge 0} (0 :_M I^n),&lt;/math&gt;

i.e., the elements of ''M'' which are annihilated by some power of ''I''. Equivalently,

:&lt;math&gt;\Gamma_I(M) := \varinjlim_{n \in N} \operatorname {Hom}_R(R/I^n, M),&lt;/math&gt;

which also shows that local cohomology of quasi-coherent sheaves agrees with

:&lt;math&gt;H_I^i(M) := \varinjlim_{n \in N} \operatorname {Ext}_R^i(R/I^n, M).&lt;/math&gt;

==Basic properties==
There is a [[long exact sequence]] of [[sheaf cohomology]] linking the ordinary sheaf cohomology of ''X'' and of the [[open set]]  ''U'' = ''X'' \''Y'', with the local cohomology groups.

If ''Y'' is defined by an ideal ''I''=(''f''&lt;sub&gt;1&lt;/sub&gt;, ..., ''f''&lt;sub&gt;''n''&lt;/sub&gt;), then local cohomology can be computed by means of [[Koszul complex]]es:

:&lt;math&gt;H_I^i(M) = \varinjlim_m H^i \left (\operatorname{Hom}_R \left (K \left (f_1^m, \dots, f_n^m \right ), M \right ) \right ),&lt;/math&gt;

where ''K'' denotes the Koszul complex, obtained as the tensor product of the Koszul complex for the individual &lt;math&gt;f_i^m&lt;/math&gt;, defined as 

:&lt;math&gt;R \stackrel {f_i^m} \longrightarrow R.&lt;/math&gt;

In particular, this leads to an exact sequence

:&lt;math&gt;0 \to H_I^0(M) \to M \stackrel {\text{res}} \to H^0(U, \tilde M) \to H^1_I(M) \to 0,&lt;/math&gt;

where ''U'' is the open complement of ''Y'' and the middle map is the restriction of sections. The target of this restriction map is also referred to as the [[ideal transform]]. For ''n'' &amp;ge; 1, there are isomorphisms

:&lt;math&gt;H^{n}(U, \tilde M) \stackrel \cong \to H^{n+1}_I(M).&lt;/math&gt;

An important special case is the one when ''R'' is [[graded ring|graded]], ''I'' consists of the elements of degree &amp;ge; 1, and ''M'' is a graded module.&lt;ref&gt;{{harvtxt|Eisenbud|1995|loc=§A.4}}&lt;/ref&gt; In this case, the cohomology of ''U'' above can be identified with the cohomology groups

:&lt;math&gt;\bigoplus_{k \in \mathbf Z} H^n(\text{Proj}(R), \tilde M(k))&lt;/math&gt;

of the [[Proj construction|projective scheme]] associated to ''R'' and (''k'') denotes the [[Serre twist]]. This relates local cohomology with global cohomology on projective schemes. For example, [[Castelnuovo–Mumford regularity]] can be formulated using local cohomology.&lt;ref&gt;{{harvtxt|Brodman|Sharp|1998|loc=§16}}&lt;/ref&gt;

==Relation to invariants of modules==
The dimension dim&lt;sub&gt;''R''&lt;/sub&gt;(M) of a module (defined as the [[Krull dimension]] of its support) provides an upper bound for local cohomology groups:&lt;ref&gt;{{harvtxt|Brodman|Sharp|1998|loc=Theorem 6.1.2}}&lt;/ref&gt;

:&lt;math&gt;H_I^n(M) = 0 \text{ for all }n&gt;\dim_R(M).&lt;/math&gt;

If ''R'' is [[local ring|local]] and ''M'' [[finitely generated module|finitely generated]], then this bound is sharp, i.e., &lt;math&gt;H^n_\mathfrak{m}(M) \ne 0&lt;/math&gt;.

The [[depth of a module|depth]] (defined as the maximal length of a [[regular sequence|regular ''M''-sequence]]; also referred to as the grade of ''M'') provides a sharp lower bound, i.e., it is the smallest integer ''n'' such that&lt;ref&gt;{{harvtxt|Hartshorne|1967|loc=Theorem 3.8}}, {{harvtxt|Brodman|Sharp|1998|loc=Theorem 6.2.7}}, ''M'' is finitely generated, ''IM'' &amp;ne; ''M''&lt;/ref&gt;

:&lt;math&gt;H^n_I(M) \ne 0.&lt;/math&gt;

These two bounds together yield a characterisation of [[Cohen–Macaulay module]]s over local rings: they are precisely those modules where &lt;math&gt;H^n_\mathfrak{m}(M)&lt;/math&gt; vanishes for all but one ''n''.

==Local duality==
The [[local duality theorem]] is a local analogue of [[Serre duality]]. For a [[Gorenstein ring]] ''R'', it states that the natural pairing

:&lt;math&gt;H^n_\mathfrak m(M) \times \operatorname{Ext}_R^{d-n}(M, \omega) \to H^n_\mathfrak m(R)&lt;/math&gt;

is a [[perfect pairing]], where &amp;omega; denotes a [[dualising module]].&lt;ref&gt;{{harvtxt|Hartshorne|1967|loc=Theorem 6.3}}, see also {{harvtxt|Hartshorne|1967|loc=Theorem 6.7}} for a converse statement.&lt;/ref&gt;

==Applications==
The initial applications were to analogues of the [[Lefschetz hyperplane theorem]]s. In general such theorems state that homology or cohomology is supported on a [[hyperplane section]] of an [[algebraic variety]], except for some 'loss' that can be controlled. These results applied to the [[algebraic fundamental group]] and to the [[Picard group]].

Another type of application are connectedness theorems such as [[Grothendieck's connectedness theorem]] (a local analogue of the [[Bertini theorem]]) or the [[Fulton–Hansen connectedness theorem]] due to {{harvtxt|Fulton|Hansen|1979}} and {{harvtxt|Faltings|1979}}. The latter asserts that for two [[projective variety|projective varieties]] ''V'' and ''W'' in '''P'''&lt;sup&gt;''r''&lt;/sup&gt; over an [[algebraically closed field]], the [[connectedness dimension]] of ''Z'' = ''V'' ∩ ''W'' (i.e., the minimal dimension of a closed subset ''T'' of ''Z'' that has to be removed from ''Z'' so that the [[complement (set theory)|complement]] ''Z'' \ ''T'' is [[disconnected space|disconnected]]) is bound by
:c(''Z'') &amp;ge; dim ''V'' + dim ''W'' &amp;minus; ''r'' &amp;minus; 1.
For example, ''Z'' is connected if dim ''V'' + dim ''W'' &gt; ''r''.&lt;ref&gt;{{harvtxt|Brodman|Sharp|1998|loc=§19.6}}&lt;/ref&gt;

==Notes==
&lt;references /&gt;

== Introductory Reference ==
* Huneke, Craig; Taylor, Amelia, [http://homepages.math.uic.edu/~bshipley/huneke.pdf Lectures on Local Cohomology]

==References==

*{{citation|author1=Brodman|first1=M. P. |author2=Sharp|first2=R. Y. |year=1998|title=Local Cohomology: An Algebraic Introduction with Geometric Applications|publisher=Cambridge University Press|edition=2nd}} [http://www.ams.org/bull/1999-36-03/S0273-0979-99-00785-5/S0273-0979-99-00785-5.pdf Book review by Hartshorne]
*{{cite book | author=Eisenbud, David | title=Commutative algebra with a view toward algebraic geometry | location=New York | publisher=[[Springer-Verlag]] | series=[[Graduate Texts in Mathematics]] | volume=150 | year=1995 | mr=1322960 | isbn=0-387-94268-8 | nopp=true | page=xvi+785}}
*{{Citation|author=Faltings|first=Gerd|title=Algebraisation of some formal vector bundles|journal=Ann. of Math. |series= 2| volume=110|year=1979|issue=3|pages=501–514|mr=554381|doi=10.2307/1971235}}
*{{citation|first=W.|last= Fulton|first2= J. |last2=Hansen|title=A connectedness theorem for projective varieties with applications to intersections and singularities of mappings|journal= Annals of Mathematics |volume=110 |year=1979|pages= 159–166| doi=10.2307/1971249| jstor=1971249 |issue=1| publisher= Annals of Mathematics}}
*{{Citation | last1=Grothendieck | first1=Alexander | author1-link=Alexander Grothendieck | title=Séminaire de Géométrie Algébrique du Bois Marie - 1962 - Cohomologie locale des faisceaux cohérents et théorèmes de Lefschetz locaux et globaux - (SGA 2) | origyear= 1968 | arxiv=math/0511279 | publisher=[[Société Mathématique de France]] | location=Paris | series=Documents Mathématiques (Paris)  | isbn=978-2-85629-169-6 | mr=2171939 | year=2005 | volume=4| bibcode=2005math.....11279G }}
*{{cite book | last = Grothendieck| first = Alexandre | authorlink = Alexandre Grothendieck | title = Séminaire de Géométrie Algébrique du Bois Marie - 1962 - Cohomologie locale des faisceaux cohérents et théorèmes de Lefschetz locaux et globaux - (SGA 2) (Advanced Studies in Pure Mathematics '''2''')
 | year = 1968 | origyear = 1962 | publisher = North-Holland Publishing Company | location = Amsterdam | language = French | pages = vii+287 | nopp = true}}
*{{Citation | last1=Hartshorne | first1=Robin | author1-link=Robin Hartshorne | title=Local cohomology. A seminar given by A. Grothendieck, Harvard University, Fall, 1961 | origyear=1961 | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture notes in mathematics | doi=10.1007/BFb0073971 |mr=0224620 | year=1967 | volume=41}}
*{{Citation | last1=Iyengar | first1=Srikanth B. | last2=Leuschke | first2=Graham J. | last3=Leykin | first3=Anton | last4=Miller | first4=Claudia | last5=Miller | first5=Ezra | last6=Singh | first6=Anurag K. | last7=Walther | first7=Uli | title=Twenty-four hours of local cohomology | url=https://books.google.com/books?id=5HgmUQsbe5sC | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=[[Graduate Studies in Mathematics]] | isbn=978-0-8218-4126-6 |mr=2355715 | year=2007 | volume=87 | doi=10.1090/gsm/087}}

[[Category:Sheaf theory]]
[[Category:Topological methods of algebraic geometry]]
[[Category:Cohomology theories]]
[[Category:Commutative algebra]]
[[Category:Duality theories]]</text>
      <sha1>90e0fztqi12fs9dab42f971winh4qqy</sha1>
    </revision>
  </page>
  <page>
    <title>Matrix-exponential distribution</title>
    <ns>0</ns>
    <id>41981077</id>
    <revision>
      <id>810366191</id>
      <parentid>787016853</parentid>
      <timestamp>2017-11-14T20:43:49Z</timestamp>
      <contributor>
        <username>BetterMath</username>
        <id>27435083</id>
      </contributor>
      <comment>/* Moments */  use non-bbold "E" for [[expected value]] operator</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3460">{{Probability distribution
  | name       = Matrix-exponential
  | type       = continuous
  | parameters = '''α''', '''T''', '''s'''
  | support    = {{nowrap|''x'' ∈ [0, ∞)}}
  | pdf        = {{nowrap|'''α''' ''e''&lt;sup&gt;''x'' '''T'''&lt;/sup&gt;'''s'''}}
  | cdf        = {{nowrap|1 + '''α'''e&lt;sup&gt;x'''T'''&lt;/sup&gt;'''T'''&lt;sup&gt;−1&lt;/sup&gt;'''s'''}}
  | mean       =
  | median     = 
  | mode       = 
  | variance   = 
  | skewness   =
  | kurtosis   = 
  | entropy    = 
  | mgf        = 
  | char       = 
  | rate       = 
  }}
In [[probability theory]], the '''matrix-exponential distribution''' is an [[absolutely continuous]] distribution with rational [[Laplace–Stieltjes transform]].&lt;ref name="asmussen2006"&gt;{{Cite book | doi = 10.1002/0471667196.ess1092.pub2| chapter = Matrix-Exponential Distributions| title = Encyclopedia of Statistical Sciences| year = 2006| last1 = Asmussen | first1 = S. R. | last2 = o’Cinneide | first2 = C. A. | isbn = 0471667196}}&lt;/ref&gt; They were first introduced by [[David Cox (statistician)|David Cox]] in 1955 as '''distributions with rational Laplace–Stieltjes transforms'''.&lt;ref name="bean2008"&gt;{{Cite journal | doi = 10.1080/15326340802232186| title = Characterization of Matrix-Exponential Distributions| journal = [[Stochastic Models]]| volume = 24| issue = 3| pages = 339| year = 2008| last1 = Bean | first1 = N. G. | last2 = Fackrell | first2 = M. | last3 = Taylor | first3 = P. }}&lt;/ref&gt;

The [[probability density function]] is

: &lt;math&gt; f(x) = \mathbf{\alpha} e^{x\,T} \mathbf{s} \text{ for }x\ge 0 &lt;/math&gt;

(and 0 when ''x''&amp;nbsp;&lt;&amp;nbsp;0) where

: &lt;math&gt;
\begin{align}
\alpha &amp; \in \mathbb R^{1\times n}, \\
T &amp; \in \mathbb R^{n\times n}, \\
s &amp; \in \mathbb R^{n\times 1}.
\end{align}
&lt;/math&gt;

There are no restrictions on the parameters '''α''', '''T''', '''s''' other than that they correspond to a probability distribution.&lt;ref&gt;{{Cite journal | doi = 10.1239/aap/1175266478| title = On matrix exponential distributions| journal = Advances in Applied Probability| volume = 39| pages = 271–292| year = 2007| last1 = He | first1 = Q. M. | last2 = Zhang | first2 = H. | publisher = [[Applied Probability Trust]]}}&lt;/ref&gt; There is no straightforward way to ascertain if a particular set of parameters form such a distribution.&lt;ref name="bean2008" /&gt; The dimension of the matrix '''T''' is the order of the matrix-exponential representation.&lt;ref name="asmussen2006" /&gt;

The distribution is a generalisation of the [[phase type distribution]].

==Moments==

If ''X'' has a matrix-exponential distribution then the ''k''th [[moment (mathematics)|moment]] is given by&lt;ref name="bean2008" /&gt;

:&lt;math&gt;\operatorname E(X^k) = (-1)^{k+1}k! \mathbf{\alpha} T^{-(k+1)}\mathbf{s}.&lt;/math&gt;

==Fitting==

Matrix exponential distributions can be fitted using [[maximum likelihood estimation]].&lt;ref&gt;{{Cite journal | doi = 10.1081/STM-200056227| title = Fitting with Matrix-Exponential Distributions| journal = [[Stochastic Models (journal)|Stochastic Models]]| volume = 21| issue = 2–3| pages = 377| year = 2005| last1 = Fackrell | first1 = M. }}&lt;/ref&gt;

==Software==

*''[http://webspn.hit.bme.hu/~telek/tools/butools/butools.html BuTools]'' a [[MATLAB]] and [[Mathematica]] script for fitting matrix-exponential distributions to three specified moments.

==See also==

* [[Rational arrival process]]

==References==

{{reflist}}

{{Probability distributions}}

[[Category:Continuous distributions]]

{{probability-stub}}</text>
      <sha1>gj4r5f5djpcjywlkuka5qhzupf8byov</sha1>
    </revision>
  </page>
  <page>
    <title>Metric (mathematics)</title>
    <ns>0</ns>
    <id>1561467</id>
    <revision>
      <id>854946220</id>
      <parentid>848458864</parentid>
      <timestamp>2018-08-14T21:22:49Z</timestamp>
      <contributor>
        <username>Undsoweiter</username>
        <id>8967780</id>
      </contributor>
      <comment>/* Premetrics */  Removed the potentially confusing and unnecessary use of "open" in scare quotes as an adjective describing r-balls centered at a point.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24209">{{distinguish|Measure (mathematics)}}
[[File:Manhattan distance.svg|thumb|200px|An illustration comparing the [[Taxicab geometry|taxicab metric]] to the Euclidean metric on the plane: According to the taxicab metric all three pictured paths (red, yellow, and blue) have the same [[Arc length|length]] (12). According to the Euclidean metric, the green path has length &lt;math&gt;6 \sqrt{2} \approx 8.49&lt;/math&gt;, and is the unique shortest path.]]

In [[mathematics]], a '''metric''' or '''distance function''' is a [[function (mathematics)|function]] that defines a [[distance]]  between each pair of elements of a [[Set (mathematics)|set]]. A set with a metric is called a [[metric space]]. A metric induces a [[topology]] on a set, but not all topologies can be generated by a metric. A [[topological space]] whose topology can be described by a metric is called [[metrizable]].

An important source of metrics in [[differential geometry]] are [[metric tensor]]s, [[bilinear form]]s that may be defined from the [[tangent vector]]s of a [[differentiable manifold]] onto a scalar. A metric tensor allows distances along curves to be determined through integration, and thus determines a metric. However, not every metric comes from a metric tensor in this way.

==Definition==

A '''metric''' on a set {{mvar|X}} is a [[function (mathematics)|function]] (called the ''distance function'' or simply '''distance''')
:&lt;math&gt;d : X \times X \to [0,\infty)&lt;/math&gt;,
where &lt;math&gt;[0,\infty)&lt;/math&gt; is the set of non-negative [[real number]]s and for all &lt;math&gt;x,y,z \in X&lt;/math&gt;, the following conditions are satisfied:

:{|
|-
|style="width:20px"| 1.
|style="width:250px"|&lt;math&gt;d(x,y) \ge 0 &lt;/math&gt; 
|| [[Non-negative|non-negativity]] or separation axiom
|-
| 2. || &lt;math&gt;d(x,y) = 0 \Leftrightarrow x = y&lt;/math&gt; || [[identity of indiscernibles]]
|-
| 3. || &lt;math&gt;d(x,y)  = d(y,x) &lt;/math&gt; || [[Symmetric function|symmetry]]
|-
| 4. || &lt;math&gt;d(x,z) \le d(x,y) + d(y, z)&lt;/math&gt;  || [[subadditivity]] or [[triangle inequality]]
|}

Conditions 1 and 2 together define a ''[[positive-definite function]]''. 
The first condition is implied by the others.

A metric is called an [[ultrametric space|ultrametric]] if it satisfies the following stronger version of the ''triangle inequality'' where points can never fall 'between' other points:
: &lt;math&gt;d(x, z) \leq \max(d(x, y), d(y, z))&lt;/math&gt;
for all &lt;math&gt;x,y,z \in X&lt;/math&gt;

A metric {{mvar|d}} on {{mvar|X}} is called [[intrinsic metric|intrinsic]] if any two points {{mvar|x}} and {{mvar|y}} in {{mvar|X}} can be joined by a [[curve]] with [[Curve#Lengths of curves|length]] arbitrarily close to {{math|''d''(''x'', ''y'')}}.

For sets on which an addition + : {{math|''X'' &amp;times; ''X'' → ''X''}} is defined,
{{mvar|d}} is called a '''[[Translational invariance|translation invariant metric]]''' if
: &lt;math&gt;d(x, y) = d(x + a, y + a)&lt;/math&gt;
for all {{mvar|x}}, {{mvar|y}}, and {{mvar|a}} in {{mvar|X}}.

== Notes ==

These conditions express intuitive notions about the concept of [[distance]]. For example, that the distance between distinct points is positive and the distance from ''x'' to ''y'' is the same as the distance from ''y'' to ''x''. The triangle inequality means that the distance from ''x'' to ''z'' via ''y'' is at least as great as from ''x'' to ''z'' directly. [[Euclid]] in his [[Euclidean geometry|work]] stated that the shortest distance between two points is a line; that was the triangle inequality for his geometry.

If a modification of the triangle inequality
:4*.  ''d''(''x'', ''z'') ≤ ''d''(''z'', ''y'') + ''d''(''y'', ''x'')
is used in the definition then property 1 follows straight from property 4*. Properties 2 and 4* give property 3 which in turn gives property 4.

== Examples ==

{{Main|Metric space#Examples of metric spaces}}
* The [[discrete space|discrete metric]]: if ''x'' = ''y'' then ''d''(''x'',''y'') = 0.  Otherwise, ''d''(''x'',''y'') = 1.
* The [[Euclidean metric]] is translation and rotation invariant.
* The [[Taxicab geometry|taxicab metric]] is translation invariant.
* More generally, any metric induced by a [[norm (mathematics)|norm]] is translation invariant.
* If &lt;math&gt;(p_n)_{n\in N}&lt;/math&gt; is a [[sequence]] of [[seminorm]]s defining a ([[locally convex]]) [[topological vector space]] ''E'', then
:&lt;math&gt;d(x,y)=\sum_{n=1}^\infty \frac{1}{2^n} \frac{p_n(x-y)}{1+p_n(x-y)}&lt;/math&gt;
:is a metric defining the same [[topology]].  (One can replace &lt;math&gt; \frac{1}{2^n}&lt;/math&gt; by any [[absolute convergence|summable sequence]] &lt;math&gt;(a_n)&lt;/math&gt; of strictly [[positive number]]s.)
* [[Graph metric]], a metric defined in terms of distances in a certain graph.
* The [[Hamming distance]] in coding theory.
* [[Riemannian metric]], a type of metric function that is appropriate to impose on any [[differentiable manifold]]. For any such [[manifold]], one chooses at each point p a symmetric, positive definite, bilinear form L: T&lt;sub&gt;p&lt;/sub&gt; × T&lt;sub&gt;p&lt;/sub&gt; → ℝ on the [[tangent space]] T&lt;sub&gt;p&lt;/sub&gt; at p, doing so in a smooth manner. This form determines the length of any tangent vector '''v''' on the manifold, via the definition ||v||  =  {{radic|L('''v''', '''v''')}}. Then for any differentiable path on the manifold, its length is defined as the integral of the length of the tangent vector to the path at any point, where the integration is done with respect to the path parameter.  Finally, to get a metric defined on any pair {x, y} of points of the manifold, one takes the infimum, over all paths from x to y, of the set of path lengths. A smooth manifold equipped with a Riemannian metric is called a [[Riemannian manifold]].
* The [[Fubini–Study metric]] on [[complex projective space]]. This is an example of a Riemannian metric.
* [[String metric]]s, such as [[Levenshtein distance]] and other [[Edit distance|string edit distances]], define a metric over [[String (computer science)|strings]].
* [[Graph edit distance]] defines a distance function between [[Graph (discrete mathematics)|graphs]].
* The [[Wasserstein metric]] is a distance function defined between two [[probability distribution]]s.

== Equivalence of metrics ==

For a given set ''X'', two metrics ''d''&lt;sub&gt;1&lt;/sub&gt; and ''d''&lt;sub&gt;2&lt;/sub&gt; are called '''topologically equivalent''' ('''uniformly equivalent''') if the identity mapping
:id: (''X'',''d''&lt;sub&gt;1&lt;/sub&gt;) → (''X'',''d''&lt;sub&gt;2&lt;/sub&gt;)
is a [[homeomorphism]] ([[uniform isomorphism]]).

For example, if &lt;math&gt;d&lt;/math&gt; is a metric, then &lt;math&gt;\min (d, 1)&lt;/math&gt; and &lt;math&gt;{d \over 1+d}&lt;/math&gt; are metrics equivalent to &lt;math&gt;d.&lt;/math&gt;

See also [[Metric space#Notions of metric space equivalence|notions of metric space equivalence]].

== Metrics on vector spaces ==
&lt;!-- linked from [[Relation of norms and metrics]] --&gt;
Norms on vector spaces are equivalent to certain metrics, namely homogeneous, translation-invariant ones. In other words, every norm determines a metric, and some metrics determine a norm.

Given a [[normed vector space]] &lt;math&gt;(X, \|\cdot\|)&lt;/math&gt; we can define a metric on ''X'' by
:&lt;math&gt;d(x,y) := \| x-y\|&lt;/math&gt;.
The metric ''d'' is said to be '''induced by''' the norm &lt;math&gt;\|\cdot\|&lt;/math&gt;.

Conversely if a metric ''d'' on a [[vector space]] ''X'' satisfies the properties
*&lt;math&gt;d(x,y) = d(x+a,y+a)&lt;/math&gt; (''translation invariance'')
*&lt;math&gt;d(\alpha x, \alpha y) = |\alpha| d(x,y)&lt;/math&gt; (''homogeneity'')
then we can define a [[norm (mathematics)|norm]] on ''X'' by
:&lt;math&gt;\|x\| := d(x,0)&lt;/math&gt;

Similarly, a [[seminorm]] induces a pseudometric (see below), and a homogeneous, translation invariant pseudometric induces a seminorm.

==Metrics on multisets==
We can generalize the notion of a metric from a distance between two elements to a distance between two nonempty finite multisets of elements. A [[multiset]] is a generalization of the notion of a [[set (mathematics)|set]] such that an element can occur more than once.  Define &lt;math&gt;Z=XY&lt;/math&gt; if
&lt;math&gt;Z&lt;/math&gt; is the multiset consisting of the elements of the multisets &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt;, that is, if &lt;math&gt;x&lt;/math&gt; occurs once in &lt;math&gt;X&lt;/math&gt; and once in &lt;math&gt;Y&lt;/math&gt; then it occurs twice in &lt;math&gt;Z&lt;/math&gt;. 
A distance function
&lt;math&gt;d&lt;/math&gt; on the set of nonempty finite multisets is a metric&lt;ref name="Vi11"&gt;{{cite journal|doi=10.1109/TIT.2011.2110130|title=Information Distance in Multiples|journal=IEEE Transactions on Information Theory|volume=57|issue=4|pages=2451|year=2011|last1=Vitanyi|first1=Paul M. B.|arxiv=0905.3347}}&lt;/ref&gt; if
#  &lt;math&gt;d(X)=0&lt;/math&gt; if all elements of &lt;math&gt;X&lt;/math&gt; are equal and &lt;math&gt;d(X) &gt; 0&lt;/math&gt; otherwise ([[positive definiteness]]), that is, ([[Non-negative|non-negativity]] plus [[identity of indiscernibles]])
# &lt;math&gt;d(X)&lt;/math&gt; is invariant under all permutations of &lt;math&gt;X&lt;/math&gt; ([[symmetry]])
# &lt;math&gt;d(XY) \leq d(XZ)+d(ZY)&lt;/math&gt; ([[triangle inequality]])
Note that the familiar metric between two elements results if the multiset &lt;math&gt;X&lt;/math&gt; has two elements in 1 and 2 and the multisets &lt;math&gt;X,Y,Z&lt;/math&gt; have one element each in 3. For instance if &lt;math&gt;X&lt;/math&gt; consists of two occurrences of &lt;math&gt;x&lt;/math&gt;, then &lt;math&gt;d(X)=0&lt;/math&gt; according to 1.

A simple example is the set of all nonempty finite multisets &lt;math&gt;X&lt;/math&gt;  of integers with &lt;math&gt;d(X)=\max\{x: x \in X\}- \min\{x:x \in X\}&lt;/math&gt;. More complex examples are [[information distance]] in multisets;&lt;ref name="Vi11"/&gt; and [[normalized compression distance]] (NCD) in multisets.&lt;ref&gt;{{Cite journal|arxiv=1212.5711|last1= Cohen|first1= Andrew R.|title= Normalized Compression Distance of Multisets with Applications|journal= IEEE Transactions on Pattern Analysis and Machine Intelligence|volume= 37|issue= 8|pages= 1602–1614|last2=  Vitanyi|first2= Paul M. B.|year= 2012|doi= 10.1109/TPAMI.2014.2375175}}
&lt;/ref&gt;

== Generalized metrics ==
There are numerous ways of relaxing the axioms of metrics, giving rise to various notions of generalized metric spaces. These generalizations can also be combined. The terminology used to describe them is not completely standardized. Most notably, in [[functional analysis]] pseudometrics often come from [[seminorm]]s on vector spaces, and so it is natural to call them "semimetrics". This conflicts with the use of the term in [[topology]].

=== Extended metrics ===
Some authors allow the distance function ''d'' to attain the value ∞, i.e. distances are non-negative numbers on the [[extended real number line]]. 
Such a function is called an ''extended metric'' or "∞-metric". 
Every extended metric can be transformed to a finite metric such that the metric spaces are equivalent as far as notions of [[topology]] (such as [[continuous function (topology)|continuity]] or [[limit (mathematics)|convergence]]) are concerned. This can be done using a [[Subadditive function|subadditive]] monotonically increasing bounded function which is zero at zero, e.g. ''d''&amp;prime;(''x'', ''y'') = ''d''(''x'', ''y'') / (1 + ''d''(''x'', ''y'')) or ''d''&amp;prime;&amp;prime;(''x'', ''y'') = min(1, ''d''(''x'', ''y'')).

The requirement that the metric take values in &lt;nowiki&gt;[0,∞)&lt;/nowiki&gt; can even be relaxed to consider metrics with values in other [[directed set]]s.  The reformulation of the axioms in this case leads to the construction of [[uniform space]]s: topological spaces with an abstract structure enabling one to compare the local topologies of different points.

===Pseudometrics===
{{Main|Pseudometric space}}
A '''pseudometric''' on ''X'' is a function ''d'' : ''X'' × ''X'' → '''R''' which satisfies the axioms for a metric, except that instead of the second (identity of indiscernibles) only ''d''(''x'',''x'')=0 for all ''x'' is required. In other words, the axioms for a pseudometric are:

# ''d''(''x'', ''y'') ≥ 0
&lt;!--# ''d''(''x'', ''y'') = 0 &amp;nbsp; if and only if &amp;nbsp; ''x'' = ''y''--&gt;
# '''''d''(''x'', ''x'') = 0''' (but possibly ''d''(''x'', ''y'') = 0 for some distinct values ''x'' ≠ ''y''.)
# ''d''(''x'', ''y'') = ''d''(''y'', ''x'')
# ''d''(''x'', ''z'') ≤ ''d''(''x'', ''y'') + ''d''(''y'', ''z'').

In some contexts, pseudometrics are referred to as ''semimetrics'' because of their relation to [[seminorm]]s.

===Quasimetrics===
Occasionally, a '''quasimetric''' is defined as a function that satisfies all axioms for a metric with the possible exception of symmetry:&lt;ref&gt;E.g. Steen &amp;amp; Seebach (1995).&lt;/ref&gt;&lt;ref&gt;{{cite conference | title=Quasi uniformities: reconciling domains with metric spaces | last=Smyth | first=M. | year=1987 | pages=236–253 | conference=3rd Conference on Mathematical Foundations of Programming Language Semantics | editor=M.Main |editor2=A.Melton |editor3=M.Mislove |editor4=D.Schmidt | publisher=Springer-Verlag, Lecture Notes in Computer Science 298}}&lt;/ref&gt;. The name of this generalisation is not entirely standardized.&lt;ref&gt;{{Citation | title=Functional Analysis and Control Theory: Linear Systems | last=Rolewicz | first=Stefan | year=1987 | isbn=90-277-2186-6 | publisher=[[Springer Science+Business Media|Springer]] | oclc=13064804 }} This book calls them "semimetrics". That same term is also frequently used for two other generalizations of metrics.&lt;/ref&gt;

# ''d''(''x'', ''y'') ≥ 0 ('''positivity''')
# ''d''(''x'', ''y'') = 0 &amp;nbsp; if and only if &amp;nbsp; ''x'' = ''y'' ('''positive definiteness''')
# &lt;del&gt;''d''(''x'', ''y'') = ''d''(''y'', ''x'')&lt;/del&gt; ('''symmetry''', dropped)
# ''d''(''x'', ''z'') ≤ ''d''(''x'', ''y'') + ''d''(''y'', ''z'') ('''triangle inequality''')

Quasimetrics are common in real life. For example, given a set ''X'' of mountain villages, the typical walking times between elements of ''X'' form a quasimetric because travel up hill takes longer than travel down hill. Another example is a [[taxicab geometry]] topology having one-way streets, where a path from point ''A'' to point ''B'' comprises a different set of streets than a path from ''B'' to ''A''. 

A quasimetric on the reals can be defined by setting
:''d''(''x'', ''y'') = ''x'' − ''y'' if ''x'' ≥ ''y'', and
:''d''(''x'', ''y'') = 1 otherwise. The 1 may be replaced by infinity or by &lt;math&gt;1+10^{(y-x)}&lt;/math&gt;.
The topological space underlying this quasimetric space is the [[Sorgenfrey line]]. This space describes the process of [[Filing (metalworking)|filing down]] a metal stick: it is easy to reduce its size, but it is difficult or impossible to grow it.

If ''d'' is a quasimetric on ''X'', a metric ''d&lt;nowiki&gt;'&lt;/nowiki&gt;'' on ''X'' can be formed by taking
:''d&lt;nowiki&gt;'&lt;/nowiki&gt;''(''x'', ''y'') = {{frac|2}}(''d''(''x'', ''y'') + ''d''(''y'', ''x'')).

===Metametrics===

In a ''metametric'', all the axioms of a metric are satisfied except that the distance between identical points is not necessarily zero. In other words, the axioms for a metametric are:

# ''d''(''x'', ''y'') ≥ 0
# ''d''(''x'', ''y'') = 0 implies ''x'' = ''y'' (but not vice versa.)
# ''d''(''x'', ''y'') = ''d''(''y'', ''x'')
# ''d''(''x'', ''z'') ≤ ''d''(''x'', ''y'') + ''d''(''y'', ''z'').

Metametrics appear in the study of [[Δ-hyperbolic space|Gromov hyperbolic metric spaces]] and their boundaries. The ''visual metametric'' on such a space satisfies ''d''(''x'', ''x'') = 0 for points ''x'' on the boundary, but otherwise ''d''(''x'', ''x'') is approximately the distance from ''x'' to the boundary. Metametrics were first defined by Jussi Väisälä.&lt;ref&gt;{{citation
 | last = Väisälä | first = Jussi
 | doi = 10.1016/j.exmath.2005.01.010
 | issue = 3
 | journal = Expositiones Mathematicae
 | mr = 2164775
 | pages = 187–231
 | title = Gromov hyperbolic spaces
 | url = http://www.helsinki.fi/~jvaisala/grobok.pdf
 | volume = 23
 | year = 2005}}&lt;/ref&gt;

===Semimetrics===
A '''semimetric''' on ''X'' is a function ''d'' : ''X'' × ''X'' → '''R''' that satisfies the first three axioms, but not necessarily the triangle inequality:

# ''d''(''x'', ''y'') ≥ 0
# ''d''(''x'', ''y'') = 0 &amp;nbsp; if and only if &amp;nbsp; ''x'' = ''y''
# ''d''(''x'', ''y'') = ''d''(''y'', ''x'')

Some authors work with a weaker form of the triangle inequality, such as:
: ''d''(''x'', ''z'') ≤ ρ (''d''(''x'', ''y'') + ''d''(''y'', ''z'')) &amp;nbsp;&amp;nbsp;&amp;nbsp; (ρ-relaxed triangle inequality)
: ''d''(''x'', ''z'') ≤ ρ max(''d''(''x'', ''y''), ''d''(''y'', ''z'')) &amp;nbsp;&amp;nbsp;&amp;nbsp; (ρ-inframetric inequality).
The ρ-inframetric inequality implies the ρ-relaxed triangle inequality (assuming the first axiom), and the ρ-relaxed triangle inequality implies the 2ρ-inframetric inequality. Semimetrics satisfying these equivalent conditions have sometimes been referred to as "quasimetrics",&lt;ref&gt;{{Citation
 | title = The Geodesic Problem in Quasimetric Spaces
 | year = 2009
 | author = Xia, Q.
 | journal = Journal of Geometric Analysis
 | pages = 452–479
 | volume = 19
 | doi = 10.1007/s12220-008-9065-4
 | issue = 2 }}&lt;/ref&gt; "nearmetrics"&lt;ref&gt;{{Citation | author1=Qinglan Xia | title=The geodesic problem in nearmetric spaces | year=2008 | pages=452–479 | volume=19 | issue=2 | journal=Journal of Geometric Analysis | arxiv=0807.3377 | postscript=.| bibcode=2008arXiv0807.3377X }}&lt;/ref&gt; or '''inframetrics'''.&lt;ref name=inframetrics&gt;* {{cite book
 | title = 2008 IEEE INFOCOM - The 27th Conference on Computer Communications
 | citeseerx=10.1.1.113.6748
 | year = 2008
 | journal = IEEE INFOCOM 2008. the 27th Conference on Computer Communications
 | pages = 1085–1093
 | last1 = Fraigniaud	 | first1 =  P.
 | last2 =  Lebhar	 | first2 =  E.
 | last3 =  Viennot	 | first3 =  L.
 | doi = 10.1109/INFOCOM.2008.163
 | chapter = The Inframetric Model for the Internet
 | isbn = 978-1-4244-2026-1 }}.&lt;/ref&gt;

The ρ-inframetric inequalities were introduced to model [[round-trip delay time]]s in the [[internet]].&lt;ref name=inframetrics /&gt; The triangle inequality implies the 2-inframetric inequality, and the [[ultrametric inequality]] is exactly the 1-inframetric inequality.

===Premetrics===
Relaxing the last three axioms leads to the notion of a '''premetric''', i.e. a function satisfying the following conditions:

# ''d''(''x'', ''y'') ≥ 0
# ''d''(''x'', ''x'') = ''0''

This is not a standard term. Sometimes it is used to refer to other generalizations of metrics such as pseudosemimetrics&lt;ref&gt;{{Citation
 | title =  Metric characterization of random variables and random processes
 | year = 2000
 | last1 = Buldygin	 | first1 =  V.V.
 | last2 =  Kozachenko	 | first2 =  I.U.V.
}}.&lt;/ref&gt; or pseudometrics;&lt;ref&gt;{{citation
 | title =  Lectures and exercises on functional analysis
 | year = 2006
 | author = Khelemskiĭ
}}.&lt;/ref&gt; in translations of Russian books it sometimes appears as "prametric".&lt;ref&gt;Arkhangel'skii &amp;amp; Pontryagin (1990). {{citation
 | title =  An introduction to geometrical physics
 | year = 1995
 | last1 = Aldrovandi	 | first1 =  R.
 | last2 =  Pereira	 | first2 =  J.G.
}}.&lt;/ref&gt;

Any premetric gives rise to a topology as follows. For a positive real ''r'', the ''r''-ball centered at a point ''p'' is defined as
:''B&lt;sub&gt;r&lt;/sub&gt;''(''p'') = { ''x'' | ''d''(''x'', ''p'') &lt; r }.
A set is called ''open'' if for any point ''p'' in the set there is an ''r''-ball centered at ''p'' which is contained in the set. Every premetric space is a topological space, and in fact a [[sequential space]].&lt;!--I copied this claim from [[premetric space]] without checking--&gt;
In general, the ''r''-balls themselves need not be open sets with respect to this topology. 
As for metrics, the distance between two sets ''A'' and ''B'', is defined as
:''d''(''A'', ''B'') = inf&lt;sub&gt;''x''∊''A'', ''y''∊''B''&lt;/sub&gt; ''d''(''x'', ''y'').
This defines a premetric on the [[power set]] of a premetric space. If we start with a (pseudosemi-)metric space, we get a pseudosemimetric, i.e. a symmetric premetric.
Any premetric gives rise to a [[preclosure operator]] ''cl'' as follows:
:''cl''(''A'') = { ''x'' | ''d''(''x'', ''A'') = 0 }.

===Pseudoquasimetrics===
The prefixes ''pseudo-'', ''quasi-'' and ''semi-'' can also be combined, e.g., a '''pseudoquasimetric''' (sometimes called '''hemimetric''') relaxes both the indiscernibility axiom and the symmetry axiom and is simply a premetric satisfying the triangle inequality. For pseudoquasimetric spaces the open ''r''-balls form a basis of open sets. A very basic example of a pseudoquasimetric space is the set {0,1} with the premetric given by ''d''(0,1) = 1 and ''d''(1,0) = 0. The associated topological space is the [[Sierpiński space]].

Sets equipped with an extended pseudoquasimetric were studied by [[William Lawvere]] as "generalized metric spaces".&lt;ref&gt;{{citation | last=Lawvere | first=F.W. | title=Metric spaces, generalised logic, and closed categories | series=Reprints in Theory and Applications of Categories | volume=1 | year=2002 | origyear=1973 | pages=1–37 }}.&lt;/ref&gt;&lt;ref&gt;{{citation | last=Vickers | first=Steven | title=Localic completion of generalized metric spaces I | journal=Theory and Applications of Categories | volume=14 | year=2005 | pages=328–356 | url=http://www.tac.mta.ca/tac/volumes/14/15/14-15abs.html }}
&lt;/ref&gt; From a [[Category theory|categorical]] point of view, the extended pseudometric spaces and the extended pseudoquasimetric spaces, along with their corresponding nonexpansive maps, are the best behaved of the metric space categories. One can take arbitrary products and coproducts and form quotient objects within the given category. If one drops "extended", one can only take finite products and coproducts. If one drops "pseudo", one cannot take quotients. [[Approach space]]s are a generalization of metric spaces that maintains these good categorical properties.

=== Important cases of generalized metrics ===
In [[differential geometry]], one considers a [[metric tensor]], which can be thought of as an "infinitesimal" quadratic metric function. This is defined as a [[nondegenerate]] symmetric [[bilinear form]] on the [[tangent space]] of a [[manifold]] with an appropriate [[differentiability]] requirement.  While these are not metric functions as defined in this article, they induce what is called a pseudo-semimetric function by [[Antiderivative|integration]] of its square root along a path through the manifold. If one imposes the positive-definiteness requirement of an [[inner product]] on the metric tensor, this restricts to the case of a [[Riemannian manifold]], and the path integration yields a metric.

In [[general relativity]] the related concept is a [[metric tensor (general relativity)]] which expresses the structure of a [[pseudo-Riemannian manifold]]. Though the term "metric" is used in cosmology, the fundamental idea is different because there are non-zero [[null vector]]s in the tangent space of these manifolds. This generalized view of "metrics", in which zero distance does ''not'' imply identity, has crept into some mathematical writing too:&lt;ref&gt;S. Parrott (1987) ''Relativistic Electrodynamics and Differential Geometry'', page 4, Springer-Verlag {{isbn|0-387-96435-5}} : "This bilinear form is variously called the ''Lorentz metric'', or ''Minkowski metric'' or ''metric tensor''."&lt;/ref&gt;&lt;ref&gt;Thomas E. Cecil (1992) ''Lie Sphere Geometry'', page 9, Springer-Verlag {{isbn|0-387-97747-3}} : "We call this scalar product the ''Lorentz metric''"&lt;/ref&gt;

== See also ==
*[[Acoustic metric]]
*[[Complete metric]]
*[[Similarity measure]]
*[[Signed distance function]]

== Notes ==
&lt;references /&gt;

== References ==
* {{Citation | title=General Topology I: Basic Concepts and Constructions Dimension Theory | last1=Arkhangel'skii | first1=A. V. | last2=Pontryagin |first2=L. S. | year=1990 | isbn=3-540-18178-4 | publisher=[[Springer Science+Business Media|Springer]] | series=Encyclopaedia of Mathematical Sciences}}
*{{citation | last1=Steen | first1=Lynn Arthur | authorlink1=Lynn Arthur Steen | last2=Seebach | first2=J. Arthur Jr. | authorlink2=J. Arthur Seebach Jr. | title=[[Counterexamples in Topology]] | origyear=1978 | publisher=[[Dover Publications|Dover]] | isbn=978-0-486-68735-3 |mr=507446 | year=1995 | oclc=32311847 }}

==External links==
* {{planetmath reference|id=6274|title=Quasimetric space}}
* {{planetmath reference|id=5904|title=Semimetric}}

{{DEFAULTSORT:Metric (Mathematics)}}
[[Category:Metric geometry]]
[[Category:Topology]]</text>
      <sha1>1yoa5ccyt9q35nna1j65zmmsl77qqdm</sha1>
    </revision>
  </page>
  <page>
    <title>Minkowski space</title>
    <ns>0</ns>
    <id>230488</id>
    <revision>
      <id>862709912</id>
      <parentid>861779361</parentid>
      <timestamp>2018-10-06T05:24:40Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="73721">[[File:De Raum zeit Minkowski Bild.jpg|250px|right|thumb|[[Hermann Minkowski]] (1864–1909)  found that the theory of special relativity, introduced by his former student [[Albert Einstein]], could be best understood as a four-dimensional space, since known as the Minkowski spacetime.]]
In [[mathematical physics]], '''Minkowski space''' (or '''Minkowski spacetime''') is a combining of [[Three-dimensional space|three-dimensional]] [[Euclidean space]] and [[time]] into a four-dimensional [[manifold]] where the [[spacetime interval]] between any two [[Event (relativity)|events]] is independent of the [[inertial frame of reference]] in which they are recorded. Although initially developed by mathematician [[Hermann Minkowski]] for [[Maxwell's equations]] of electromagnetism, the mathematical structure of Minkowski spacetime was shown to be an immediate consequence of the [[postulates of special relativity]].&lt;ref&gt;{{harvnb|Landau|Lifshitz|2002|p=5}}&lt;/ref&gt;

Minkowski space is closely associated with [[Albert Einstein|Einstein's]] theory of [[special relativity]], and is the most common mathematical structure on which special relativity is formulated. While the individual components in Euclidean space and time may differ due to [[length contraction]] and [[time dilation]], in Minkowski spacetime, all frames of reference will agree on the total distance in spacetime between events.&lt;ref group=nb&gt;This makes spacetime distance an [[Invariant (physics)|invariant]].&lt;/ref&gt; Because it treats time differently than it treats the 3 spatial dimensions, Minkowski space differs from [[Four-dimensional space|four-dimensional Euclidean space]].

In 3-dimensional Euclidean space (e.g. simply ''space'' in [[Galilean relativity]]), the [[isometry group]] (the maps preserving the regular [[Euclidean distance]]) is the [[Euclidean group]]. It is generated by [[Rotation matrix|rotations]], [[Reflection (mathematics)|reflections]] and [[Translation (geometry)|translations]]. When time is amended as a fourth dimension, the further transformations of translations in time and [[Galilean boost]]s are added, and the group of all these transformations is called the [[Galilean group]]. All Galilean transformations preserve the ''3-dimensional'' Euclidean distance. This distance is purely spatial. Time differences are ''separately'' preserved as well. This changes in the spacetime of special relativity, where space and time are interwoven.

Spacetime is equipped with an indefinite [[Degenerate bilinear form|non-degenerate]] [[bilinear form]], variously called the ''Minkowski metric'',&lt;ref&gt;{{harvnb|Lee|1997|p=31}}&lt;/ref&gt; the ''Minkowski norm squared'' or ''Minkowski inner product'' depending on the context.&lt;ref group=nb&gt;Consistent use of the terms "Minkowski inner product", "Minkowski norm" or "Minkowski metric" is intended for the bilinear form here, since it is in widespread use. It is by no means "standard" in the literature, but no standard terminology seems to exist.&lt;/ref&gt; The Minkowski inner product is defined as to yield the [[spacetime interval]] between two events when given their coordinate difference vector as argument.&lt;ref&gt;{{cite book |title=Independent Axioms for Minkowski Space-Time |edition=illustrated |first1=John W. |last1=Schutz |publisher=CRC Press |year=1977 |isbn=978-0-582-31760-4 |pages=184–185 |url=https://books.google.com/books?id=eOO1SWD17GIC}} [https://books.google.com/books?id=eOO1SWD17GIC&amp;pg=PA184 Extract of page 184]&lt;/ref&gt; Equipped with this inner product, the mathematical model of spacetime is called Minkowski space. The analogue of the Galilean group for Minkowski space, preserving the spacetime interval (as opposed to the spatial Euclidean distance) is the [[Poincaré group]].

In summary, Galilean spacetime and Minkowski spacetime are, when viewed as manifolds, actually ''the same''. They differ in what further structures are defined ''on'' them.  The former has the Euclidean distance function and time (separately) together with inertial frames whose coordinates are related by Galilean transformations, while the latter has the Minkowski metric together with inertial frames whose coordinates are related by Poincaré transformations.

==History==
{{Spacetime|cTopic=Types}}

===Four-dimensional Euclidean spacetime===
{{See also|Four-dimensional space}}
In 1905&amp;ndash;06 [[Henri Poincaré]] showed&lt;ref&gt;{{harvnb|Poincaré|1905–1906|pp=129&amp;ndash;176}} Wikisource translation: [[s:Translation:On the Dynamics of the Electron (July)|On the Dynamics of the Electron]]&lt;/ref&gt; that by taking time to be an imaginary fourth [[spacetime]] coordinate {{math|''ict''}}, where {{mvar|c}} is the [[speed of light]] and {{mvar|i}} is the [[imaginary unit]], a [[Lorentz transformation]] can formally be regarded as a rotation of coordinates in a four-dimensional space with three real coordinates representing space, and one [[imaginary time|imaginary coordinate]] representing time, as the fourth dimension. In physical spacetime special relativity stipulates that the quantity

:&lt;math&gt;- t^2 + x^2 + y^2 + z^2&lt;/math&gt;

is invariant under coordinate changes from one inertial frame to another, i. e. under Lorentz transformations. Here the speed of light {{mvar|c}} is, following Poincaré, set to unity. In the space suggested by him (Poincaré mentions this only in passing) where physical spacetime is ''coordinatized'' by {{math|(''t'', ''x'', ''y'', ''z'') ↦ (''x'', ''y'', ''z'', ''it'')}}, call it ''coordinate space'', Lorentz transformations appear as ordinary rotations preserving the quadratic form

:&lt;math&gt;x^2 + y^2 + z^2 + t^2&lt;/math&gt;

on coordinate space. The naming and ordering of coordinates, with the same labels for space coordinates, but with the imaginary time coordinate as the ''fourth coordinate'', is conventional. The above expression, while making the former expression more familiar,&lt;ref group=nb&gt;The surface {{math|''x''&lt;sup&gt;2&lt;/sup&gt; + ''y''&lt;sup&gt;2&lt;/sup&gt; + ''z''&lt;sup&gt;2&lt;/sup&gt; + ''t''&lt;sup&gt;2&lt;/sup&gt; {{=}} ''R''&lt;sup&gt;2&lt;/sup&gt; &gt; 0}} is a [[3-sphere]] in {{math|ℝ&lt;sup&gt;4&lt;/sup&gt;}} and linear transformations preserving {{math|''R''&lt;sup&gt;2&lt;/sup&gt;}} are either [[Rotation group|rotations]] or reflections.&lt;/ref&gt; may potentially be confusing because it is ''not'' the same {{mvar|t}} that appears in the latter (''time coordinate'') as in the former (''time itself'' in some inertial system as measured by clocks stationary in that system).

Rotations in planes spanned by two space unit vectors appear in coordinate space as well as in physical spacetime appear as Euclidean rotations and are interpreted in the ordinary sense. The "rotation" in a plane spanned by a space unit vector and a time unit vector, while formally still a rotation in coordinate space, is a [[Lorentz boost]] in physical spacetime with ''real'' inertial coordinates (see also [[Lorentz transformation#Hyperbolic rotation of coordinates|hyperbolic rotation]]). The analogy with Euclidean rotations is thus only partial.

This idea was elaborated by [[Hermann Minkowski]],&lt;ref&gt;{{harvnb|Minkowski|1907–1908|pp=53&amp;ndash;111}} *Wikisource translation: [[s:Translation:The Fundamental Equations for Electromagnetic Processes in Moving Bodies|The Fundamental Equations for Electromagnetic Processes in Moving Bodies]].&lt;/ref&gt; who used it to restate the [[Maxwell equations]] in four dimensions, showing directly their invariance under the Lorentz transformation. He further reformulated in four dimensions the then-recent theory of special relativity of [[Albert Einstein|Einstein]]. From this he concluded that time and space should be treated equally, and so arose his concept of events taking place in a unified four-dimensional [[spacetime continuum]].

===Minkowski space===
In a further development in his 1908 "Space and Time" lecture,&lt;ref name=raumzeit&gt;{{harvnb|Minkowski|1907–1909|pp=75&amp;ndash;88}} Various English translations on Wikisource: "[[s:Translation:Space and Time|Space and Time]]."&lt;/ref&gt; Minkowski gave an alternative formulation of this idea that used a real time coordinate instead of an imaginary one, representing the four variables {{math|(''x'', ''y'', ''z'', ''t'')}} of space and time in coordinate form in a four dimensional real [[vector space]]. Points in this space correspond to events in spacetime. In this space, there is a defined [[light-cone]] associated with each point, and events not on the light-cone are classified by their relation to the apex as ''spacelike'' or ''timelike''. It is principally this view of spacetime that is current nowadays, although the older view involving imaginary time has also influenced special relativity. 

In the English translation of Minkowski's paper, the Minkowski metric as defined below is referred to as the ''line element''. The Minkowski inner product of below appears unnamed when referring to orthogonality (which he calls ''normality'') of certain vectors, and the Minkowski norm squared is referred to (somewhat cryptically, perhaps this is translation dependent) as "sum".

Minkowski's principal tool is the [[Minkowski diagram]], and he uses it to define concepts and demonstrate properties of Lorentz transformations (e.g. [[proper time]] and [[length contraction]]) and to provide geometrical interpretation to the generalization of Newtonian mechanics to [[relativistic mechanics]]. For these special topics, see the referenced articles, as the presentation below will be principally confined to the mathematical structure (Minkowski metric and from it derived quantities and the Poincaré group as symmetry group of spacetime) ''following'' from the invariance of the spacetime interval on the spacetime manifold as consequences of the postulates of special relativity, not to specific application or ''derivation'' of the invariance of the spacetime interval. This structure provides the background setting of all present relativistic theories, barring general relativity for which flat Minkowski spacetime still provides a springboard as curved spacetime is locally Lorentzian.

Minkowski, aware of the fundamental restatement of the theory which he had made, said
{{quote|The views of space and time which I wish to lay before you have sprung from the soil of experimental physics, and therein lies their strength. They are radical. Henceforth space by itself, and time by itself, are doomed to fade away into mere shadows, and only a kind of union of the two will preserve an independent reality.| Hermann Minkowski, 1908, 1909&lt;ref name=raumzeit/&gt;}}

Though Minkowski took an important step for physics, [[Einstein]] saw its limitation:
:At a time when Minkowski was giving the geometrical interpretation of special relativity by extending the Euclidean three-space to a [[pseudo-Euclidean space|quasi-Euclidean]] four-space that included time, Einstein was already aware that this is not valid, because it excludes the phenomenon of [[gravitation]]. He was still far from the study of curvilinear coordinates and [[Riemannian geometry]], and the heavy mathematical apparatus entailed.&lt;ref&gt;[[Cornelius Lanczos]] (1972) "Einstein's Path from Special to General Relativity", pages 5—19 of ''General Relativity: Papers in Honour of J.L. Synge'', L. O’Raifeartaigh editor, [[Clarendon Press]], see page 11&lt;/ref&gt;

For further historical information see references {{harvtxt|Galison|1979}}, {{harvtxt|Corry|1997}} and {{harvtxt|Walter|1999}}.

== Mathematical structure ==
[[Image:Image Tangent-plane.svg|thumb|A pictorial representation of the tangent space at a point, {{mvar|x}}, on a [[sphere]]. This vector space can be thought of as a subspace of {{math|ℝ&lt;sup&gt;3&lt;/sup&gt;}} itself. Then vectors in it would be called ''geometrical tangent vectors''. By the same principle, the tangent space at a point in flat spacetime can be thought of as a subspace of spacetime which happens to be ''all'' of spacetime.]]
It is assumed below that spacetime is endowed with a coordinate system corresponding to an [[inertial frame]]. This provides an ''origin'', which is necessary in order to be able to refer to spacetime as being modeled as a vector space. This is not really ''physically'' motivated in that a canonical origin ("central" event in spacetime) should exist. One can get away with less structure, that of an [[affine space]], but this would needlessly complicate the discussion and would not reflect how flat spacetime is normally treated mathematically in modern introductory literature.

For an overview, Minkowski space is a {{math|4}}-dimensional [[real number|real]] [[vector space]] equipped with  a nondegenerate, [[symmetric bilinear form]] on the [[tangent space]] at each point in spacetime, here simply called the ''Minkowski inner product'', with [[metric signature]] either {{math|(+ − − −)}} or {{math|(− + + +)}}. The tangent space at each event is a vector space of the same dimension as spacetime, {{math|4}}.

=== Tangent vectors ===
In practice, one need not be concerned with the tangent spaces. The vector space nature of Minkowski space allows for the canonical identification of vectors in tangent spaces at points (events) with vectors (points, events) in Minkowski space itself. See e.g. {{harvtxt|Lee|2003|loc=Proposition 3.8.}} These identifications are routinely done in mathematics. They can be expressed formally in Cartesian coordinates as&lt;ref&gt;{{harvnb|Lee|1997|p=15}}&lt;/ref&gt;

:&lt;math&gt;(x^0, x^1, x^2, x^3) \leftrightarrow x^0\mathbf e_0|_p + x^1\mathbf e_1|_p + x^2\mathbf e_2|_p + x^3\mathbf e_3|_p \leftrightarrow x^0\mathbf e_0|_q + x^1\mathbf e_1|_q + x^2\mathbf e_2|_q + x^3\mathbf e_3|_q,&lt;/math&gt;

with basis vectors in the tangent spaces defined by

:&lt;math&gt;\mathbf e_\mu|_p = \left .\frac{\partial}{\partial x^\mu}\right|_p \text{ or } \mathbf e_0|_p = \left(\begin{matrix} 1\\0\\0\\0\end{matrix}\right) \text{, etc}.&lt;/math&gt;

Here {{math|''p''}} and {{math|''q''}} are any two events and the last identification is referred to as [[parallel transport]]. The first identification is the canonical identification of vectors in the tangent space at any point with vectors in the space itself. The appearance of basis vectors in tangent spaces as first order differential operators is due to this identification. It is motivated by the observation that a geometrical tangent vector can be associated in a one-to-one manner with a [[directional derivative]] operator on the set of smooth functions. This is promoted to a ''definition'' of tangent vectors in manifolds ''not'' necessarily being embedded in {{math|ℝ&lt;sup&gt;''n''&lt;/sup&gt;}}. This definition of tangent vectors is not the only possible one as ordinary n-tuples can be used as well.
{{Hidden begin| titlestyle = color:green;background:lightgrey;|title=Definitions of tangent vectors as ordinary vectors}}
A tangent vector at a point {{mvar|p}} may be defined, here specialized to Cartesian coordinates in Lorentz frames, as {{math|4 × 1}} column vectors {{mvar|v}} associated to ''each'' Lorentz frame related by Lorentz transformation {{math|Λ}} such that the vector {{mvar|v}} in a frame related to some frame by {{math|Λ}} transforms according to {{math|''v'' → Λ''v''}}. This is the ''same'' way in which the coordinates {{math|''x''&lt;sup&gt;''μ''&lt;/sup&gt;}} transform. Explicitly,
:&lt;math&gt;\begin{align}x'^\mu &amp;= {\Lambda^\mu}_\nu x^\nu,\\ v'^\mu &amp;= {\Lambda^\mu}_\nu v^\nu.\end{align}&lt;/math&gt;
This definition is equivalent to the definition given above under a canonical isomorphism.
{{Hidden end}}

For some purposes it is desirable to identify tangent vectors at a point {{math|''p''}} with ''displacement vectors'' at {{math|''p''}}, which is, of course, admissible by essentially the same canonical identification.&lt;ref&gt;{{harvnb|Lee|2003|loc=See Lee's discussion on geometric tangent vectors early in chapter 3.}}&lt;/ref&gt; The identifications of vectors referred to above in the mathematical setting can correspondingly be found in a more physical and explicitly geometrical setting in {{harvtxt|Misner|Thorne|Wheeler|1970}}. They offer various degree of sophistication (and rigor) depending on which part of the material one chooses to read.

=== Metric signature ===
The metric signature refers to which sign the Minkowski inner product yields when given space (''spacelike'' to be specific, defined further down) and time basis vectors (''timelike'') as arguments. Further discussion about this theoretically inconsequential, but practically necessary choice for purposes of internal consistency and convenience is deferred to the hide box below.
{{Hidden begin| titlestyle = color:green;background:lightgrey;|title=The choice of metric signature}}
In general, but with several exceptions, mathematicians and general relativists prefer spacelike vectors to yield a positive sign, {{math|(− + + +)}}, while particle physicists tend to prefer timelike vectors to yield a positive sign, {{math|(+ − − −)}}. Authors covering several areas of physics, e.g. [[Steven Weinberg]] and [[Course of Theoretical Physics|Landau and Lifshitz]] ({{math|(− + + +)}} and {{math|(+ − − −)}} respectively) stick to one choice regardless of topic. Arguments for the former convention include "continuity" from the Euclidean case corresponding to the non-relativistic limit {{math|''c'' → ∞}}. Arguments for the latter include that minus signs, otherwise ubiquitous in particle physics, go away. Yet other authors, especially of introductory texts, e.g. {{harvtxt|Kleppner|Kolenkow|1978}}, do ''not'' choose a signature at all, but instead opt to coordinatize spacetime such that the time ''coordinate'' (but not time itself!) is imaginary. This removes the need of the ''explicit'' introduction of a [[metric tensor]] (which may seem as an extra burden in an introductory course), and one needs ''not'' be concerned with [[covariant vector]]s and [[contravariant vector]]s (or raising and lowering indices) to be described below. The inner product is instead effected by a straightforward extension of the [[dot product]] in {{math|ℝ&lt;sup&gt;3&lt;/sup&gt;}} to {{math|ℝ&lt;sup&gt;3&lt;/sup&gt; × ℂ}}. This works in the flat spacetime of special relativity, but not in the curved spacetime of general relativity, see {{harvtxt|Misner|Thorne|Wheeler|1970|loc=Box 2.1, Farewell to ''ict''}} (who, by the way use {{math|(− + + +)}}). MTW also argues that it hides the true ''indefinite'' nature of the metric and the true nature of Lorentz boosts, which aren't rotations. It also needlessly complicates the use of tools of [[differential geometry]] that are otherwise immediately available and useful for geometrical description and calculation &amp;ndash; even in the flat spacetime of special relativity, e.g. of the electromagnetic field.
{{Hidden end}}

=== Terminology ===
Mathematically associated to the bilinear form is a [[tensor]] of type {{math|(0,2)}} at each point in spacetime, called the ''Minkowski metric''.&lt;ref group=nb&gt;For comparison and motivation of terminology, take a [[Riemannian metric]], which provides a positive definite symmetric bilinear form, i. e. an [[inner product]] proper at each point on a manifold.&lt;/ref&gt; The Minkowski metric, the bilinear form, and the Minkowski inner product are actually all the very same object; it is a bilinear function that accepts two (contravariant) vectors and returns a real number. In coordinates, this is the {{math|4×4}} matrix representing the bilinear form.

For comparison, in [[general relativity]], a [[Lorentzian manifold]] {{math|''L''}} is likewise equipped with a [[Metric tensor (general relativity)|metric tensor]] {{math|''g''}}, which is a nondegenerate symmetric bilinear form on the tangent space {{math|''T''&lt;sub&gt;''p''&lt;/sub&gt;''L''}} at each point {{mvar|p}} of {{math|''L''}}. In coordinates, it may be represented by a {{math|4×4}} matrix ''depending on spacetime position''. Minkowski space is thus a comparatively simple special case of a Lorentzian manifold. Its metric tensor is in coordinates the same symmetric matrix at every point of {{math|''M''}}, and its arguments can, per above, be taken as vectors in spacetime itself.

Introducing more terminology (but not more structure), Minkowski space is thus a [[pseudo-Euclidean space]] with total dimension {{math|''n'' {{=}} 4}} and signature {{math|(3, 1)}} or {{math|(1, 3)}}. Elements of Minkowski space are called [[Event (relativity)|events]]. Minkowski space is often denoted {{math|'''R'''&lt;sup&gt;3,1&lt;/sup&gt;}} or {{math|'''R'''&lt;sup&gt;1,3&lt;/sup&gt;}} to emphasize the chosen signature, or just {{math|''M''}}. It is perhaps the simplest example of a [[pseudo-Riemannian manifold]].

An interesting example of non-inertial coordinates for (part of) Minkowski spacetime are the [[Born coordinates]]. Another useful set of coordinates are the [[Light-cone coordinates|lightcone coordinates]].

=== Pseudo-Euclidean metrics ===
{{main article|Pseudo-Euclidean space|Lorentzian manifolds}}

The Minkowski metric&lt;ref group=nb&gt;The Minkowski inner product is not an [[inner product]], since it is not [[Definite bilinear form|positive-definite]], i.e. the [[quadratic form]] {{math|''η''(''v'', ''v'')}} need not be positive for nonzero {{mvar|v}}. The positive-definite condition has been replaced by the weaker condition of non-degeneracy. The bilinear form is said to be ''indefinite''.&lt;/ref&gt; {{mvar|η}} is the metric tensor of Minkowski space. It is a pseudo-Euclidean metric, or more generally a ''constant'' pseudo-Riemannian metric in Cartesian coordinates. As such it is a nondegenerate symmetric bilinear form, a type {{math|(0,2)}} tensor. It accepts two arguments {{math|''u''&lt;sub&gt;''p''&lt;/sub&gt;, ''v''&lt;sub&gt;''p''&lt;/sub&gt;}}, vectors in {{math|''T''&lt;sub&gt;''p''&lt;/sub&gt;''M'', ''p'' ∈ ''M''}}, the tangent space at {{math|''p''}} in {{math|''M''}}. Due to the above-mentioned canonical identification of {{math|''T''&lt;sub&gt;''p''&lt;/sub&gt;''M''}} with {{math|''M''}} itself, it accepts arguments {{math|''u'', ''v''}} with both {{math|''u''}} and {{math|''v'' }} in {{math|''M''}}.

As a notational convention, vectors {{mvar|v}} in {{mvar|M}}, called [[4-vector]]s, are denoted in sans-serif italics, and not, as is common in the Euclidean setting, with boldface {{math|'''v'''}}. The latter is generally reserved for the {{math|3}}-vector part (to be introduced below) of a {{math|4}}-vector.

The definition

:&lt;math&gt;u \cdot v =\eta(u, v)&lt;/math&gt;

yields an inner product-like structure on {{math|''M''}}, previously and also henceforth, called the ''Minkowski inner product'', similar to the Euclidean [[inner product]], but it describes a different geometry. It is also called the ''relativistic dot product''. If the two arguments are the same,

:&lt;math&gt;u \cdot u =\eta(u, u) \equiv ||u||^2 \equiv u^2,&lt;/math&gt;

the resulting quantity will be called the ''Minkowski norm squared''. The Minkowski inner product satisfies the following properties.

*&lt;math&gt;\eta(au + v, w) = a\eta(u, w) + \eta(v,  w), \quad \forall  u, v \in M, \forall a \in \mathbb R \qquad \text{(linearity in first slot)}&lt;/math&gt;
*&lt;math&gt;\eta( u,  v) = \eta( v,  u) \qquad \text{(symmetry)}&lt;/math&gt;
*&lt;math&gt;\eta( u,  v) = 0 \quad \forall v \in M \Rightarrow u = 0 \qquad \text{(non-degeneracy)}&lt;/math&gt;

The first two conditions imply bilinearity. The defining ''difference'' between a pseudo-inner product and an [[inner product]] proper is that the former is ''not'' required to be positive definite, that is, {{math|''η''(''u'', ''u'') &lt; 0}} is allowed.

The most important feature of the inner product and norm squared is that ''these are quantities unaffected by Lorentz transformations''. In fact, it can be taken as the defining property of a Lorentz transformation that it preserves the inner product (i.e. the value of the corresponding bilinear form on two vectors). This approach is taken more generally for ''all'' classical groups definable this way in [[classical group]]. There, the matrix {{math|Φ}} is identical in the case {{math|O(3, 1)}} (the Lorentz group) to the matrix {{math|''η''}} to be displayed below.

Two vectors {{math|''v''}} and {{math|''w''}} are said to be [[orthogonal]] if {{math|''η''(''v'', ''w'') {{=}} 0}}. For a geometric interpretation of orthogonality in the special case when {{math|''η''(''v'', ''v'') ≤ 0}} and {{math|''η''(''w'', ''w'') ≥ 0}} (or vice versa), see [[hyperbolic orthogonality]].

A vector {{math|''e''}} is called a [[unit vector]] if {{math|''η''(''e'', ''e'') {{=}} ±1}}. A [[Basis (linear algebra)|basis]] for {{math|''M''}} consisting of mutually orthogonal unit vectors is called an [[orthonormal basis]].{{cn|reason=M not inner product space|date=October 2017}}

For a given [[inertial frame]], an orthonormal basis in space, combined by the unit time vector, forms an orthonormal basis in Minkowski space. The number of positive and negative unit vectors in any such basis is a fixed pair of numbers, equal to the signature of the bilinear form associated with the inner product. This is [[Sylvester's law of inertia]].

More terminology (but not more structure): The Minkowski metric is a [[pseudo-Riemannian metric]], more specifically, a [[Lorentzian metric]], even more specifically, ''the'' Lorentz metric, reserved for {{math|4}}-dimensional flat spacetime with the remaining ambiguity only being the signature convention.

=== Minkowski metric ===
From the [[Postulates of special relativity|second postulate of special relativity]], together with homogeneity of spacetime and isotropy of space, it follows that the [[spacetime interval]] between two arbitrary events called {{math|1}} and {{Math|2}} is:

:&lt;math&gt;\pm\left[c^2(t_1 - t_2)^2 - (x_1 - x_2)^2 - (y_1 - y_2)^2 - (z_1 - z_2)^2\right].&lt;/math&gt;

The interval is independent of the inertial frame chosen, as is shown [[Derivations of the Lorentz transformations#Invariance of interval|here]]. The factor {{math|±1}} determines the choice of the [[metric signature]] as an arbitrary [[sign convention]].&lt;ref&gt;{{cite book  |title=Flat and Curved Space-times |edition=illustrated |first1=G. F. |last1=Rayner Ellis |first2=Ruth M. |last2=Williams |publisher=Oxford University Press |year=2000 |isbn=978-0-19-850656-0 |page=209 |url=https://books.google.com/books?id=Hos31wty5WIC}} [https://books.google.com/books?id=Hos31wty5WIC&amp;pg=PA209 Extract of page 209]&lt;/ref&gt; The numerical values of {{mvar|η}}, viewed as a matrix representing the Minkowski inner product, follow from the theory of [[bilinear form]]s.

Just as the signature of the metric is differently defined in the literature, this quantity is not consistently named. The interval (as defined here) is sometimes referred to as the interval squared.&lt;ref&gt;{{harvnb|Sard|1970|p=71}}&lt;/ref&gt; Even the square root of the present interval occurs.&lt;ref&gt;{{harvnb|Landau|Lifshitz|2002|p=4}}&lt;/ref&gt; When signature and interval are fixed, ambiguity still remains as which coordinate is the time coordinate. It may be the fourth, or it may be the zeroth. This is not an exhaustive list of notational inconsistencies. It is a fact of life that one has to check out the definitions first thing when one consults the relativity literature.

The invariance of the interval under coordinate transformations between inertial frames follows from the invariance of

:&lt;math&gt;\pm\left[c^2t^2 - x^2 - y^2 - z^2\right]&lt;/math&gt;

(with either sign {{math|±}} preserved), provided the transformations are linear. This [[quadratic form]] can be used to define a bilinear form

:&lt;math&gt; u \cdot  v = \pm\left[c^2t_1t_2 - x_1x_2 - y_1y_2 - z_1z_2\right].&lt;/math&gt;

via the [[polarization identity]]. This bilinear form can in turn be written as

:&lt;math&gt; u \cdot  v =  u^{\mathrm T}[\eta] v,&lt;/math&gt;

where {{math|[''η'']}} is a {{math|4×4}} matrix associated with {{mvar|η}}. Possibly confusingly, denote {{math|[''η'']}} with just {{mvar|η}} as is common practice. The matrix is read off from the explicit bilinear form as

:&lt;math&gt;\eta = \pm \begin{pmatrix}-1&amp;0&amp;0&amp;0\\0&amp;1&amp;0&amp;0\\0&amp;0&amp;1&amp;0\\0&amp;0&amp;0&amp;1\end{pmatrix},&lt;/math&gt;

and the bilinear form

:&lt;math&gt;u \cdot v =\eta(u, v),&lt;/math&gt;

with which this section started by assuming its existence, is now identified.

For definiteness and shorter presentation, the signature {{math|(− + + +)}} is adopted below. This choice (or the other possible choice) has no (known) physical implications. The symmetry group preserving the bilinear form with one choice of signature is isomorphic (under the map given [[Classical group#O(p, q) and O(n) – the orthogonal groups|here]]) with the symmetry group preserving the other choice of signature. This means that both choices are in accord with the two postulates of relativity. Switching between the two conventions is straightforward. If the metric tensor {{math|''η''}} has been used in a derivation, go back to the earliest point where it was used, substitute {{math|''η''}} for {{math|''–η''}}, and retrace forward to the desired formula with the desired metric signature.

=== Standard basis ===
A standard basis for Minkowski space is a set of four mutually orthogonal vectors {{math|{ ''e''&lt;sub&gt;0&lt;/sub&gt;, ''e''&lt;sub&gt;1&lt;/sub&gt;, ''e''&lt;sub&gt;2&lt;/sub&gt;, ''e''&lt;sub&gt;3&lt;/sub&gt; } }} such that
:&lt;math&gt;-\eta(e_0, e_0) = \eta(e_1, e_1) = \eta(e_2, e_2) = \eta(e_3, e_3) = 1 .&lt;/math&gt;
These conditions can be written compactly in the form
:&lt;math&gt;\eta(e_\mu, e_\nu) = \eta_{\mu \nu}.&lt;/math&gt;

Relative to a standard basis, the components of a vector {{math|''v''}} are written {{math|(''v''&lt;sup&gt;0&lt;/sup&gt;, ''v''&lt;sup&gt;1&lt;/sup&gt;, ''v''&lt;sup&gt;2&lt;/sup&gt;, ''v''&lt;sup&gt;3&lt;/sup&gt;)}} where the [[Einstein notation]] is used to write {{math|''v'' {{=}} ''v''&lt;sup&gt;''μ''&lt;/sup&gt;''e''&lt;sub&gt;''μ''&lt;/sub&gt;}}. The component {{math|''v''&lt;sup&gt;0&lt;/sup&gt;}} is called the '''timelike component''' of {{math|''v''}} while the other three components are called the '''spatial components'''. The spatial components of a {{math|4}}-vector {{math|''v''}} may be identified with a {{math|3}}-vector {{math|'''v''' {{=}} (''v''&lt;sub&gt;1&lt;/sub&gt;, ''v''&lt;sub&gt;2&lt;/sub&gt;, ''v''&lt;sub&gt;3&lt;/sub&gt;)}}.

In terms of components, the Minkowski inner product between two vectors {{math|''v''}} and {{math|''w''}} is given by

:&lt;math&gt;\eta(v, w) = \eta_{\mu \nu} v^\mu w^\nu =  v^0 w_0 + v^1 w_1 + v^2 w_2 + v^3 w_3 = v^\mu w_\mu = v_\mu w^\mu,&lt;/math&gt;

and

:&lt;math&gt;\eta(v, v) = \eta_{\mu \nu} v^\mu v^\nu =  v^0v_0 + v^1 v_1 + v^2 v_2 + v^3 v_3 = v^\mu v_\mu.&lt;/math&gt;

Here '''lowering of an index''' with the metric was used.

====Raising and lowering of indices====
{{main|Raising and lowering indices|tensor contraction}}

[[File:1-form linear functional.svg|thumb|400px|Linear functionals (1-forms) '''α''', '''β''' and their sum '''σ''' and vectors '''u''', '''v''', '''w''', in [[three-dimensional space|3d]] [[Euclidean space]]. The number of (1-form) [[hyperplane]]s intersected by a vector equals the [[inner product]].&lt;ref&gt;{{harvnb|Misner|Thorne|Wheeler|1973}}&lt;/ref&gt;]]
Technically, a non-degenerate bilinear form provides a map between a vector space and its dual, in this context, the map is between the tangent spaces of {{math|''M''}} and the [[cotangent space]]s of {{math|''M''}}. At a point in {{math|''M''}}, the tangent and cotangent spaces are [[dual vector space]]s (so the dimension of the cotangent space at an event is also {{math|4}}). Just as an authentic inner product on a vector space with one argument fixed, by [[Riesz representation theorem]], may be expressed as the action of a [[linear functional]] on the vector space, the same holds for the Minkowski inner product of Minkowski space.&lt;ref&gt;{{harvnb|Lee|2003}}. One point in Lee's proof of existence of this map needs modification (Lee deals with [[Riemannian metric]]s.). Where Lee refers to positive definiteness to show injectivity of the map, one needs instead appeal to non-degeneracy.&lt;/ref&gt;

Thus if {{math|''v''&lt;sup&gt;''μ''&lt;/sup&gt;}} are the components of a vector in a tangent space, then {{math|''η''&lt;sub&gt;''μν''&lt;/sub&gt;''v''&lt;sup&gt;''μ''&lt;/sup&gt; {{=}} ''v''&lt;sub&gt;''ν''&lt;/sub&gt;}} are the components of a vector in the cotangent space (a linear functional). Due to the identification of vectors in tangent spaces with vectors in {{math|''M''}} itself, this is mostly ignored, and vectors with lower indices are referred to as '''covariant vectors'''. In this latter interpretation, the covariant vectors are (almost always implicitly) identified with vectors (linear functionals) in the dual of Minkowski space. The ones with upper indices are '''contravariant vectors'''. In the same fashion, the inverse of the map from tangent to cotangent spaces, explicitly given by the inverse of {{math|''η''}} in matrix representation, can be used to define '''raising of an index'''. The components of this inverse are denoted {{math|''η''&lt;sup&gt;''μν''&lt;/sup&gt;}}. It happens that {{math|''η''&lt;sup&gt;''μν''&lt;/sup&gt; {{=}} ''η''&lt;sub&gt;''μν''&lt;/sub&gt;}}. These maps between a vector space and its dual can be denoted {{math|''η''&lt;sup&gt;&amp;#x266D;&lt;/sup&gt;}} (eta-flat) and {{math|''η''&lt;sup&gt;&amp;#x266F;&lt;/sup&gt;}} (eta-sharp) by the musical analogy.&lt;ref&gt;{{harvnb|Lee|2003|loc=The tangent-cotangent isomorphism p. 282.}}&lt;/ref&gt;

Contravariant and covariant vectors are geometrically very different objects. The first can and should be thought of as arrows. A linear functional can be characterized by two objects: its [[kernel (linear algebra)|kernel]], which is a [[hyperplane]] passing through the origin, and its norm. Geometrically thus, covariant vectors should be viewed as a set of hyperplanes, with spacing depending on the norm (bigger = smaller spacing), with one of them (the kernel) passing through the origin. The mathematical term for a covariant vector is 1-covector or [[1-form]] (though the latter is usually reserved for covector ''fields'').

{{harvtxt|Misner|Thorne|Wheeler|1970}} uses a vivid analogy with wave fronts of a [[de Broglie wave]] (scaled by a factor of Planck's reduced constant) quantum mechanically associated to a [[momentum four-vector]] to illustrate how one could imagine a covariant version of a contravariant vector. The inner product of two contravariant vectors could equally well be thought of as the action of the covariant version of one of them on the contravariant version of the other. The inner product is then how many time the arrow pierces the planes. The mathematical reference, {{harvtxt|Lee|2003}}, offers the same geometrical view of these objects (but mentions no piercing).

The [[electromagnetic field tensor]] is a [[2-form|differential 2-form]], which geometrical description can as well be found in MTW.

One may, of course, ignore geometrical views all together (as is the style in e.g. {{harvtxt|Weinberg|2002}} and {{harvnb|Landau|Lifshitz|2002}}) and proceed algebraically in a purely formal fashion. The time-proven robustness of the formalism itself, sometimes referred to as [[index gymnastics]], ensures that moving vectors around and changing from contravariant to covariant vectors and vice versa (as well as higher order tensors) is mathematically sound. Incorrect expressions tend to reveal themselves quickly.

====The formalism of the Minkowski metric====
The present purpose is to show semi-rigorously how ''formally'' one may apply the Minkowski metric to two vectors and obtain a real number, i.e. to display the role of the differentials, and how they disappear in a calculation. The setting is that of smooth manifold theory, and concepts such as convector fields and exterior derivatives are introduced.
{{Hidden begin| titlestyle = color:green;background:lightgrey;|title=A formal approach to the Minkowski metric}}
A full-blown version of the Minkowski metric in coordinates as a tensor field on spacetime has the appearance

:&lt;math&gt;\eta_{\mu\nu} dx^\mu \otimes dx^\nu = \eta_{\mu\nu} dx^\mu \odot dx^\nu = \eta_{\mu\nu} dx^\mu  dx^\nu.&lt;/math&gt;

Explanation: The coordinate differentials are 1-form fields. They are defined as the [[exterior derivative]] of the coordinate functions {{math|''x''&lt;sup&gt;''μ''&lt;/sup&gt;}}. These quantities evaluated at a point {{mvar|p}} provide a basis for the cotangent space at {{mvar|p}}. The [[tensor product]] (denoted by the symbol {{math|⊗}}) yields a tensor field of type {{math|(0, 2)}}, i.e. the type that expects two contravariant vectors as arguments. On the right hand side, the [[Symmetric tensor#Symmetric part of a tensor|symmetric product]] (denoted by the symbol {{math|⊙}} or by juxtaposition) has been taken. The equality holds since, by definition, the Minkowski metric is symmetric.&lt;ref&gt;{{harvnb|Lee|2003}}&lt;/ref&gt; The notation on the far right is also sometimes used for the related, but different, [[line element]]. It is ''not'' a tensor. For elaboration on the differences and similarities, see {{harvtxt|Misner|Thorne|Wheeler|1973|loc=Box 3.2 and section 13.2.}}

''Tangent'' vectors are, in this formalism, given in terms of a basis of differential operators of the first order,

:&lt;math&gt;\left .\frac{\partial}{\partial x^\mu} \right|_p,&lt;/math&gt;

where {{mvar|p}} is an event. This operator applied to a function {{mvar|f}} gives the [[directional derivative]] of {{mvar|f}} at {{mvar|p}} in the direction of increasing {{math|''x''&lt;sup&gt;''μ''&lt;/sup&gt;}} with {{math|''x''&lt;sup&gt;''ν''&lt;/sup&gt;, ''ν'' ≠ ''μ''}} fixed. They provide a basis for the tangent space at {{mvar|p}}.

The exterior derivative {{math|''df''}} of a function {{mvar|f}} is a '''covector field''', i.e. an assignment of a cotangent vector to each point {{math|p}}, by definition such that

:&lt;math&gt;df(X) = Xf,&lt;/math&gt;

for each [[vector field]] {{mvar|X}}. A vector field is an assignment of a tangent vector to each point {{math|p}}. In coordinates {{mvar|X}} can be expanded at each point {{mvar|p}} in the basis given by the {{math|∂/∂''x''&lt;sup&gt;''ν''&lt;/sup&gt;{{!}}&lt;sub&gt;''p''&lt;/sub&gt;}}. Applying this with {{math|''f'' {{=}} ''x''&lt;sup&gt;''μ''&lt;/sup&gt;}}, the coordinate function itself, and {{math|''X'' {{=}} ∂/∂''x''&lt;sup&gt;''ν''&lt;/sup&gt;}}, called a ''coordinate vector field'', one obtains

:&lt;math&gt;dx^\mu\left(\frac{\partial}{\partial x^\nu}\right) = \frac{\partial x^\mu}{\partial x^\nu} = \delta_\nu^\mu.&lt;/math&gt;

Since this relation holds at each point {{mvar|p}}, the {{math|''dx''&lt;sup&gt;''μ''&lt;/sup&gt;{{!}}&lt;sub&gt;''p''&lt;/sub&gt;}} provide a basis for the cotangent space at each {{mvar|p}} and the bases {{math|''dx''&lt;sup&gt;''μ''&lt;/sup&gt;{{!}}&lt;sub&gt;''p''&lt;/sub&gt;}} and {{math|∂/∂''x''&lt;sup&gt;''ν''&lt;/sup&gt;{{!}}&lt;sub&gt;''p''&lt;/sub&gt;}} are [[dual basis|dual]] to each other,

:&lt;math&gt;\left .dx^\mu\right|_p\left(\left .\frac{\partial}{\partial x^\nu}\right|_p\right) = \delta^\mu_\nu.&lt;/math&gt;

at each {{mvar|p}}. Furthermore, one has

:&lt;math&gt;\alpha \otimes \beta (a, b) = \alpha(a)\beta(b)&lt;/math&gt;

for general one-forms on a tangent space {{math|''α'', ''β''}} and general tangent vectors {{math|''a'', ''b''}}. (This can be taken as a definition, but may also be proved in a more general setting.)

Thus when the metric tensor is fed two vectors fields {{math|''a'', ''b''}}, both expanded in terms of the basis coordinate vector fields, the result is

:&lt;math&gt;\eta_{\mu\nu} dx^\mu \otimes dx^\nu(a, b) = \eta_{\mu\nu} a^\mu b^\nu,&lt;/math&gt;

where {{math|''a''&lt;sup&gt;''μ''&lt;/sup&gt;}}, {{math|''b''&lt;sup&gt;''ν''&lt;/sup&gt;}} are the ''component functions'' of the vector fields. The above equation holds at each point {{mvar|p}}, and the relation may as well be interpreted as the Minkowski metric at {{mvar|p}} applied to two tangent vectors at {{mvar|p}}.

As mentioned, in a vector space, such as that modelling the spacetime of special relativity, tangent vectors can be canonically identified with vectors in the space itself, and vice versa. This means that the tangent spaces at each point are canonically identified with each other and with the vector space itself. This explains how the right hand side of the above equation can be employed directly, without regard to spacetime point the metric is to be evaluated and from where (which tangent space) the vectors come from.

This situation changes in [[general relativity]]. There one has

:&lt;math&gt;g(p)_{\mu\nu} dx^\mu|_p dx^\nu|_p(a, b) = g(p)_{\mu\nu} a^\mu b^\nu,&lt;/math&gt;

where now {{math|''η'' → ''g''(''p'')}}, i.e. {{mvar|g}} is still a metric tensor but now depending on spacetime and is a solution of [[Einstein's field equation]]s. Moreover, {{math|''a'', ''b''}} ''must'' be tangent vectors at spacetime point {{mvar|p}} and can no longer be moved around freely.
{{Hidden end}}

== Lorentz transformations and symmetry ==

[[Image:Standard conf.png|right|thumb|250px|Standard configuration of coordinate systems for Lorentz transformations.]]

The [[Poincaré group]] is the group of all transformations preserving the interval. The interval is quite easily seen to be preserved by the [[translation group]] in {{math|4}} dimensions. The other transformations are those that preserve the interval and leave the origin fixed. Given the bilinear form associated with the Minkowski metric, the appropriate group follows directly from the theory (in particular the definition) of [[classical group#O(p, q) and O(n) – the orthogonal groups|classical group]]s. In the linked article, one should identify {{math|''η''}} (in its a matrix representation) with the matrix {{math|Φ}}.

The appropriate group is {{math|O(3,1)}}, in this context called the [[Lorentz group]]. Its elements are called (homogeneous) [[Lorentz transformation]]s. For other methods of derivation, with a more physical twist, see [[derivations of the Lorentz transformations]].

Among the simplest Lorentz transformations is a [[Lorentz boost]]. For reference, a boost in the {{math|''x''}}-direction is given by
:&lt;math&gt;
\begin{bmatrix}
U'_0 \\ U'_1 \\ U'_2 \\ U'_3
\end{bmatrix}
=
\begin{bmatrix}
\gamma&amp;-\beta \gamma&amp;0&amp;0\\
-\beta \gamma&amp;\gamma&amp;0&amp;0\\
0&amp;0&amp;1&amp;0\\
0&amp;0&amp;0&amp;1\\
\end{bmatrix}
\begin{bmatrix}
U_0 \\ U_1 \\ U_2 \\ U_3
\end{bmatrix}, 
&lt;/math&gt;

where

:&lt;math&gt;\gamma = { 1 \over \sqrt{1 - {v^2 \over c^2}} }&lt;/math&gt;

is the [[Lorentz factor]], and

:&lt;math&gt;\beta = { v \over c} \,.&lt;/math&gt;

Other Lorentz transformations are pure rotations, and hence elements of the {{math|[[Rotation group SO(3)|SO(3)]]}} subgroup of {{math|O(3,1)}}. A general homogeneous Lorentz transformation is a product of a pure boost and a pure rotation. An ''inhomogeneous'' Lorentz transformation is a homogeneous transformation followed by a translation in space and time. Special transformations are those that invert the space coordinates [[Parity (physics)#|({{math|P}})]] and time coordinate [[time reversal symmetry|({{math|T}})]] respectively, or both {{math|(PT)}}.

All [[four-vector]]s in Minkowski space transform, by definition, according to the same formula under Lorentz transformations. [[Minkowski diagram]]s illustrate Lorentz transformations.

==Causal structure==
[[File:World line.svg|250px|thumb|right|Subdivision of Minkowski spacetime with respect to an event in four disjoint sets. The [[light cone]], the '''absolute future''', the '''absolute past''', and '''elsewhere'''. The terminology is from {{harvtxt|Sard|1970}}.]]

[[File:Lorentz transform of world line.gif|right|framed|The momentarily co-moving inertial frames along the trajectory ("[[world line]]") of a rapidly accelerating observer (center). The vertical direction indicates time, while the horizontal indicates distance, the dashed line is the [[spacetime]] of the observer. The small dots are specific events in spacetime. Note how the momentarily co-moving inertial frame changes when the observer accelerates.]]

{{Main article|Causal structure}}
Where v is velocity, and x, y, and z are [[Cartesian coordinate system|Cartesian]] coordinates in 3-dimensional space, and c is the constant representing the universal speed limit, and t is time, the four-dimensional vector {{math|''v'' {{=}} (''ct'', ''x'', ''y'', ''z'') {{=}} (''ct'', '''r''')}} is classified according to the sign of {{math|''c''&lt;sup&gt;2&lt;/sup&gt;''t''&lt;sup&gt;2&lt;/sup&gt; − ''r''&lt;sup&gt;2&lt;/sup&gt;}}. A vector is '''timelike''' if {{math|''c''&lt;sup&gt;2&lt;/sup&gt;''t''&lt;sup&gt;2&lt;/sup&gt; &gt; ''r''&lt;sup&gt;2&lt;/sup&gt;}}, '''spacelike''' if {{math|''c''&lt;sup&gt;2&lt;/sup&gt;''t''&lt;sup&gt;2&lt;/sup&gt; &lt; ''r''&lt;sup&gt;2&lt;/sup&gt;}}, and '''null''' or '''lightlike''' if {{math|''c''&lt;sup&gt;2&lt;/sup&gt;''t''&lt;sup&gt;2&lt;/sup&gt; {{=}} ''r''&lt;sup&gt;2&lt;/sup&gt;}}. This can be expressed in terms of the sign of {{math|''η''(''v'',''v'')}} as well, but depends on the signature. The classification of any vector will be the same in all frames of reference that are related by a Lorentz transformation (but not by a general Poincaré transformation because the origin may then be displaced) because of the invariance of the interval.

The set of all null vectors at an event&lt;ref group=nb&gt;Translate the coordinate system so that the event is the new origin.&lt;/ref&gt; of Minkowski space constitutes the [[light cone]] of that event. Given a timelike vector {{math|''v''}}, there is a [[worldline]] of constant velocity associated with it, represented by a straight line in a Minkowski diagram.

Once a direction of time is chosen,&lt;ref group=nb&gt;This corresponds to the time coordinate either increasing or decreasing when proper time for any particle increases. An application of {{mvar|T}} flips this direction.&lt;/ref&gt; timelike and null vectors can be further decomposed into various classes. For timelike vectors one has
# future-directed timelike vectors whose first component is positive, (tip of vector located in absolute future in figure) and
# past-directed timelike vectors whose first component is negative (absolute past).
Null vectors fall into three classes:
# the zero vector, whose components in any basis are {{math|(0, 0, 0, 0)}} (origin),
# future-directed null vectors whose first component is positive (upper light cone), and
# past-directed null vectors whose first component is negative (lower light cone).
Spacelike vectors are in elsewhere. The terminology stems from the fact that spacelike separated events are connected by vectors requiring [[faster-than-light]] travel, and so cannot possibly influence each other. Together with spacelike and lightlike vectors there are 7 classes in all.

An [[orthonormal]] basis for Minkowski space necessarily consists of one timelike and three spacelike unit vectors. If one wishes to work with non-orthonormal bases it is possible to have other combinations of vectors. For example, one can easily construct a (non-orthonormal) basis consisting entirely of null vectors, called a '''null basis'''.

[[Vector field]]s are called timelike, spacelike or null if the associated vectors are timelike, spacelike or null at each point where the field is defined.

===Chronological and causality relations===

Let {{math|''x'', ''y'' ∈ ''M''}}. We say that

#{{math|''x''}} '''''chronologically precedes''''' {{math|''y''}} if {{math|''y'' − ''x''}} is future-directed timelike. This relation has the [[transitive property]] and so can be written {{math|''x'' &lt; ''y''}}. 
#{{math|''x''}} '''''causally precedes''''' {{math|''y''}} if {{math|''y'' − ''x''}} is future-directed null or future-directed timelike. It gives a [[partial ordering]] of space-time and so can be written {{math|''x'' ≤ ''y''}}.

Suppose ''x'' ∈ ''M'' is timelike. Then the '''simultaneous hyperplane''' for x is &lt;math&gt;\{y : \eta(x, y ) = 0\}.&lt;/math&gt; Since this [[hyperplane]] varies as ''x'' varies, there is a [[relativity of simultaneity]] in Minkowski space.

===Reversed triangle inequality===

If {{math|''v''}} and {{math|''w''}} are both future-directed timelike four-vectors, then in the {{math|(+ − − −)}} sign convention for norm, 
:&lt;math&gt; \left\| v+w \right\| \ge \left\| v \right\| + \left\| w \right\| .&lt;/math&gt;

== Generalizations ==
{{main article|Lorentzian manifold|Super Minkowski space}}
A Lorentzian manifold is a generalization of Minkowski space in two ways. The total number of spacetime dimensions is not restricted to be  {{math|4}} ({{math|2}} or more) and a Lorentzian manifold need not be flat, i.e. it allows for curvature.

=== Generalized Minkowski space ===
Minkowski space refers to a mathematical formulation in four dimensions. However, the mathematics can easily be extended or simplified to create an analogous generalized Minkowski space in any number of dimensions. If {{math|''n'' ≥ 2}}, {{math|''n''}}-dimensional Minkowski space is a vector space of real dimension {{math|''n''}} on which there is a constant Minkowski metric of signature {{math|(''n'' − 1, 1)}} or {{math|(1, ''n'' − 1)}}. These generalizations are used in theories where spacetime is assumed to have more or less than {{math|4}} dimensions. [[String theory]] and [[M-theory]] are two examples where {{math|''n'' &gt; 4}}. In string theory, there appears [[conformal field theory|conformal field theories]] with {{math|1 + 1}} spacetime dimensions.

[[de Sitter space]] can be formulated as a submanifold of generalized Minkowski space as can the model spaces of [[hyperbolic geometry]] (see below).

=== Curvature ===
As a ''flat spacetime'', the three spatial components of Minkowski spacetime always obey the [[Pythagorean Theorem]]. Minkowski space is a suitable basis for [[special relativity]], a good description of physical systems over finite distances in systems without significant [[gravitation]]. However, in order to take gravity into account, physicists use the theory of [[general relativity]], which is formulated in the mathematics of a [[non-Euclidean geometry]]. When this geometry is used as a model of physical space, it is known as [[curved space]].

Even in curved space, Minkowski space is still a good description in an [[Local reference frame|infinitesimal region]] surrounding any point (barring gravitational singularities).&lt;ref group=nb&gt;This similarity between flat and curved space at infinitesimally small distance scales is foundational to the definition of a [[manifold]] in general.&lt;/ref&gt; More abstractly, we say that in the presence of gravity spacetime is described by a curved 4-dimensional [[manifold]] for which the [[tangent space]] to any point is a 4-dimensional Minkowski space. Thus, the structure of Minkowski space is still essential in the description of general relativity.

== Geometry ==
{{main article|Hyperboloid model}}

The meaning of the term ''geometry'' in the context of Minkowski space depends heavily on what is meant by the term. Minkowski space is not endowed with a Euclidean geometry, and not with any of the generalized Riemannian geometries with intrinsic curvature, those exposed by the ''model spaces'' in [[hyperbolic geometry]] (negative curvature) and the geometry modeled by the [[sphere]] (positive curvature). The reason is the indefiniteness of the Minkowski metric. Minkowski space is, in particular, not a [[metric space]] and not a Riemannian manifold with a Riemannian metric. However, Minkowski space contains [[submanifold]]s endowed with a Riemannian metric yielding hyperbolic geometry.

Model spaces of hyperbolic geometry of low dimension, say {{math|2}} or {{math|3}}, ''cannot'' be isometrically embedded in Euclidean space with one more dimension, i.e. {{math|ℝ&lt;sup&gt;3&lt;/sup&gt;}} or {{math|ℝ&lt;sup&gt;4&lt;/sup&gt;}} respectively, with the Euclidean metric {{math|{{overline|''g''}}}}, disallowing easy visualization.&lt;ref group=nb&gt;There ''is'' an isometric embedding into {{math|ℝ&lt;sup&gt;''n''&lt;/sup&gt;}} according to the [[Nash embedding theorem]] ({{harvtxt|Nash|1956}}), but the embedding dimension is much higher, {{math|''n'' {{=}} (''m''/2)(''m'' + 1)(3''m'' + 11)}} for a Riemannian manifold of dimension {{mvar|m}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Lee|1997|p=66}}&lt;/ref&gt; By comparison, model spaces with positive curvature are just spheres in Euclidean space of one higher dimension.&lt;ref&gt;{{harvnb|Lee|1997|p=33}}&lt;/ref&gt; It turns out however that these hyperbolic spaces ''can'' be isometrically embedded in spaces of one more dimension when the embedding space is endowed with the Minkowski metric {{math|''η''}}.

Define {{math|'''H'''{{su|p=1(''n'')|b=''R''}} ⊂ '''M'''&lt;sup&gt;''n''+1&lt;/sup&gt;}} to be the upper sheet ({{math|''ct'' &gt; 0}}) of the [[hyperboloid]]

:&lt;math&gt;\mathbf H_R^{1(n)} = \left\{\left(ct, x^1, \ldots, x^n\right) \in \mathbf M^n: c^2 t^2 - \left(x^1\right)^2 \cdots \left(x^n\right)^2 = R^2, ct &gt; 0\right\}&lt;/math&gt;

in generalized Minkowski space {{math|'''M'''&lt;sup&gt;''n''+1&lt;/sup&gt;}} of spacetime dimension {{math|''n'' + 1}}. This is one of the [[Lorentz group#Restricted Lorentz group|surfaces of transitivity]] of the generalized Lorentz group. The [[induced metric]] on this submanifold,

:&lt;math&gt;h_R^{1(n)} = \iota^* \eta,&lt;/math&gt;

the [[Pullback (differential geometry)|pullback]] of the Minkowski metric {{math|''η''}} under inclusion, is a [[Riemannian metric]]. With this metric {{math|'''H'''{{su|p=1(''n'')|b=''R''}}}} is a [[Riemannian manifold]]. It is one of the model spaces of Riemannian geometry, the [[hyperboloid model]] of [[hyperbolic space]]. It is a space of constant negative curvature {{math|−1/''R''&lt;sup&gt;2&lt;/sup&gt;}}.&lt;ref&gt;{{harvnb|Lee|1997}}&lt;/ref&gt; The {{math|1}} in the upper index refers to an enumeration of the different model spaces of hyperbolic geometry, and the {{math|''n''}} for its dimension. A {{math|2(2)}} corresponds to the [[Poincaré disk model]], while {{math|3(''n'')}} corresponds to the [[Poincaré half-plane model|Poincaré half-space model]] of dimension {{math|''n''}}.

=== Preliminaries ===
In the definition above {{math|''ι'':'''H'''{{su|p=1(''n'')|b=''R''}} → '''M'''&lt;sup&gt;''n''+1&lt;/sup&gt;}} is the [[inclusion map]] and the superscript star denotes the [[Pullback (differential geometry)|pullback]]. The present purpose is to describe this and similar operations as a preparation for the actual demonstration that {{math|'''H'''{{su|p=1(''n'')|b=''R''}}}} actually is a hyperbolic space. 
{| class="wikitable collapsible collapsed"
! Behavior of tensors under inclusion, pullback of covariant tensors under general maps and pushforward of vectors under general maps
|-
|
&lt;u&gt;'''Behavior of tensors under inclusion:'''&lt;/u&gt;&lt;br/&gt;
For inclusion maps from a submanifold {{mvar|S}} into {{mvar|M}} and a covariant tensor {{mvar|α}} of order {{mvar|k}} on {{mvar|M}} it holds that

:&lt;math&gt;\iota^*\alpha\left(X_1, X_2, \ldots, X_k\right) = \alpha\left(\iota_*X_1, \iota_*X_2, \ldots, \iota_*X_k\right) = \alpha\left(X_1, X_2, \ldots, X_k\right),&lt;/math&gt;

where {{math|''X''&lt;sub&gt;1&lt;/sub&gt;, ''X''&lt;sub&gt;1&lt;/sub&gt;, ..., ''X''&lt;sub&gt;k&lt;/sub&gt;}} are vector fields on {{mvar|S}}. The subscript star denotes the pushforward (to be introduced later), and it is in this special case simply the identity map (as is the inclusion map). The latter equality holds because a tangent space to a submanifold at a point is in a canonical way a subspace of the tangent space of the manifold itself at the point in question. One may simply write

:&lt;math&gt;\iota^*\alpha = \alpha|_S,&lt;/math&gt;

meaning (with slight [[abuse of notation]]) the restriction of {{mvar|α}} to accept as input vectors tangent to some {{math|''s'' ∈ ''S''}} only.

&lt;u&gt;'''Pullback of tensors under general maps:'''&lt;/u&gt;&lt;br/&gt;
The pullback of a covariant {{mvar|k}}-tensor {{mvar|α}} (one taking only contravariant vectors as arguments) under a map {{math|''F'':''M'' → ''N''}} is a linear map

:&lt;math&gt;F^*:T_{F(p)}^k N \rightarrow T_p^k M,&lt;/math&gt;

where for any vector space {{mvar|V}},

:&lt;math&gt;T^k V = \underbrace{V^* \otimes V^* \cdots \otimes V^*}_{k\text{ times}}.&lt;/math&gt;

It is defined by

:&lt;math&gt;F^*(\alpha)\left(X_1, X_2, \ldots, X_k\right) = \alpha\left(F_* X_1, F_*X_2, \ldots, F_* X_k\right),&lt;/math&gt;

where the subscript star denotes the [[pushforward (differential)|pushforward]] of the map {{mvar|F}}, and {{math|''X''&lt;sup&gt;1&lt;/sup&gt;, ''X''&lt;sup&gt;2&lt;/sup&gt;, ..., X&lt;sup&gt;''k''&lt;/sup&gt;}} are vectors in {{math|''T''&lt;sub&gt;''p''&lt;/sub&gt;''M''}}. (This is in accord with what was detailed about the pullback of the inclusion map. In the general case here, one cannot proceed as simply because {{math|''F''&lt;sub&gt;∗&lt;/sub&gt;''X''&lt;sub&gt;1&lt;/sub&gt; ≠ ''X''&lt;sub&gt;1&lt;/sub&gt;}} in general.)

&lt;u&gt;'''The pushforward of vectors under general maps:'''&lt;/u&gt;&lt;br/&gt;
Heuristically, pulling back a tensor to {{math|''p'' ∈ ''M''}} from {{math|''F''(''p'') ∈ ''N''}} feeding it vectors residing at {{math|''p'' ∈ ''M''}} is by definition the same as pushing forward the vectors from {{math|''p'' ∈ ''M''}} to {{math|''F''(''p'') ∈ ''N''}} feeding them to the tensor residing at {{math|''F(''p'') ∈ ''N''}}.

Further unwinding the definitions, the pushforward {{math|F&lt;sub&gt;∗&lt;/sub&gt;:''TM''&lt;sub&gt;''p''&lt;/sub&gt; → ''TN''&lt;sub&gt;''F''(''p'')&lt;/sub&gt;}} of a vector field under a map {{math|''F'':''M'' → ''N''}} between manifolds is defined by

:&lt;math&gt;F_*(X)f = X(f \circ F),&lt;/math&gt;

where {{mvar|f}} is a function on {{mvar|N}}. When {{math|''M'' {{=}} ℝ&lt;sup&gt;''m''&lt;/sup&gt;, ''N''{{=}} ℝ&lt;sup&gt;''n''&lt;/sup&gt;}} the pushforward of {{mvar|F}} reduces to {{math|''DF'':ℝ&lt;sup&gt;''m''&lt;/sup&gt; →  ℝ&lt;sup&gt;''n''&lt;/sup&gt;}}, the ordinary [[Total derivative#The total derivative as a linear map|differential]], which is given by the [[Jacobian matrix]] of partial derivatives of the component functions. The differential is the best linear approximation of a function {{mvar|F}} from {{math|ℝ&lt;sup&gt;''m''&lt;/sup&gt;}} to {{math|ℝ&lt;sup&gt;''n''&lt;/sup&gt;}}. The pushforward is the smooth manifold version of this. It acts between tangent spaces, and is in coordinates represented by the Jacobian matrix of the ''coordinate representation'' of the function.

The corresponding pullback is the [[Transpose of a linear map|dual map]] from the dual of the range tangent space to the dual of the domain tangent space, i.e. it is a linear map,

:&lt;math&gt;F^*:T^*_{F(p)}N \rightarrow T^*_p M.&lt;/math&gt;
|}

=== Hyperbolic stereographic projection ===
[[File:HyperboloidProjection.png|thumb|right|Red circular arc is geodesic in [[Poincaré disk model]]; it projects to the brown geodesic on the green hyperboloid.]]
In order to exhibit the metric it is necessary to pull it back via a suitable ''parametrization''. A parametrization of a submanifold {{mvar|''S''}} of {{math|''M''}} is a map {{math|''U'' ⊂ ℝ&lt;sup&gt;''m''&lt;/sup&gt; → ''M''}} whose range is an open subset of {{math|''S''}}. If {{mvar|S}} has the same dimension as {{math|''M''}}, a parametrization is just the inverse of a coordinate map {{math|''φ'':''M'' → ''U'' ⊂ ℝ&lt;sup&gt;''m''&lt;/sup&gt;}}. The parametrization to be used is the inverse of ''hyperbolic stereographic projection''. This is illustrated in the figure to the left for {{math|''n'' {{=}} 2}}. It is instructive to compare to [[stereographic projection]] for spheres.

Stereographic projection {{math|''σ'':'''H'''{{su|p=''n''|b=''R''}} → ℝ&lt;sup&gt;''n''&lt;/sup&gt;}} and its inverse {{math|''σ''&lt;sup&gt;−1&lt;/sup&gt;:ℝ&lt;sup&gt;''n''&lt;/sup&gt; → '''H'''{{su|p=''n''|b=''R''}}}} are given by

{{Equation box 1
|indent =:
|equation = 
:&lt;math&gt;\begin{align}
                     \sigma(\tau, \mathbf x) &amp;= \mathbf u = \frac{R\mathbf x}{R + \tau},\\
  \sigma^{-1}(\mathbf u) = (\tau, \mathbf x) &amp;= \left(R\frac{R^2 + |u|^2}{R^2 - |u|^2}, \frac{2R^2\mathbf u}{R^2 - |u|^2}\right),
\end{align}&lt;/math&gt;
|cellpadding= 6
|border
|border colour = #0073CF
|bgcolor=#F9FFF7}}

where, for simplicity, {{math|''τ'' ≡ ''ct''}}. The {{math|(''τ'', '''x''')}} are coordinates on {{math|'''M'''&lt;sup&gt;''n''+1&lt;/sup&gt;}} and the {{math|'''u'''}} are coordinates on {{math|ℝ&lt;sup&gt;n&lt;/sup&gt;}}.
{{-}}
{| class="wikitable collapsible collapsed"
!Detailed derivation
|-
|
Let

:&lt;math&gt;\mathbf H_R^n = \left\{\left(\tau, x^1, \ldots, x^n\right) \subset \mathbf M: -\tau^2 + \left(x^1\right)^2 + \cdots + \left(x^n\right)^2 = -R^2, \tau &gt; 0\right\}&lt;/math&gt;

and let

:&lt;math&gt;S = (-1, 0, \ldots, 0)&lt;/math&gt;

If

:&lt;math&gt;P = \left(\tau, x^1, \ldots, x^n\right) \in \mathbf H_R^n,&lt;/math&gt;

then it is geometrically clear that the vector

:&lt;math&gt;\overrightarrow{PS}&lt;/math&gt;

intersects the hyperplane

:&lt;math&gt;\left\{\left(\tau, x^1, \ldots x^n\right) \in M: \tau = 0\right\}&lt;/math&gt;

once in point denoted

:&lt;math&gt;U = \left(0, u^1(P), \ldots, u^n(P)\right) \equiv (0, \mathbf u).&lt;/math&gt;

One has

:&lt;math&gt;\begin{align}
  S + \overrightarrow{SU} &amp;= U \Rightarrow \overrightarrow{SU} = U - S,\\
  S + \overrightarrow{SP} &amp;= P \Rightarrow \overrightarrow{SP} = U - P
\end{align}.&lt;/math&gt;

or

:&lt;math&gt;\begin{align}
  \overrightarrow{SU} &amp;= (0, \mathbf u) - (-R, 0) = (R, \mathbf u),\\
  \overrightarrow{SP} &amp;= (\tau, \mathbf x) - (-R, 0) = (\tau + R, \mathbf x).
\end{align}&lt;/math&gt;

By construction of stereographic projection one has

:&lt;math&gt;\overrightarrow{SU} = \lambda(\tau)\overrightarrow{SP}.&lt;/math&gt;

This leads to the system of equations

:&lt;math&gt;\begin{align}
          R &amp;= \lambda(\tau + R),\\
  \mathbf u &amp;= \lambda \mathbf x.
\end{align}&lt;/math&gt;

The first of these is solved for &lt;math&gt;\lambda&lt;/math&gt; and one obtains for stereographic projection

:&lt;math&gt;\sigma(\tau, \mathbf x) = \mathbf u = \frac{R\mathbf x}{R + \tau}.&lt;/math&gt;

Next, the inverse &lt;math&gt;\sigma^{-1}(u) = (\tau, \mathbf x)&lt;/math&gt; must be calculated. Use the same considerations as before, but now with
:&lt;math&gt;\begin{align}
  U &amp;= (0, \mathbf u)\\
  P &amp;= (\tau(\mathbf u), \xi(\mathbf u)).
\end{align}&lt;/math&gt;

One gets

:&lt;math&gt;\begin{align}
       \tau &amp;= \frac{R(1 - \lambda)}{\lambda},\\
  \mathbf x &amp;= \frac{\mathbf u}{\lambda},
\end{align}&lt;/math&gt;

but now with &lt;math&gt;\lambda&lt;/math&gt; depending on &lt;math&gt;\mathbf u.&lt;/math&gt; The condition for {{mvar|P}} lying in the hyperboloid is

:&lt;math&gt;-\tau^2 + \mathbf u \cdot \mathbf u = -\tau^2 + |u|^2 = -R^2,&lt;/math&gt;

or

:&lt;math&gt;-\frac{R^2(1 - \lambda)^2}{\lambda^2} = \frac{|u|^2}{\lambda^2},&lt;/math&gt;

leading to

:&lt;math&gt;\lambda = \frac{R^2 - |u|^2}{2R^2}.&lt;/math&gt;

With this &lt;math&gt;\lambda&lt;/math&gt;, one obtains

:&lt;math&gt;\sigma^{-1}(\mathbf u) = (\tau, \mathbf x) = \left(R\frac{R^2 + |u|^2}{R^2 - |u|^2}, \frac{2R^2\mathbf u}{R^2 - |u|^2}.\right)&lt;/math&gt;
|}

=== Pulling back the metric ===
One has

:&lt;math&gt;h_R^{1(n)} = \eta|_{\mathbf H_R^{1(n)}} = \left(dx^1\right)^2 + \cdots + \left(dx^n\right)^2 - d\tau^2&lt;/math&gt;

and the map

:&lt;math&gt;\sigma^{-1}:\mathbb R^n \rightarrow \mathbf H_R^{1 (n)}; \sigma^{-1}(\mathbf u) = (\tau (\mathbf u), \mathbf x (\mathbf u)) = \left(R\frac{R^2 + |u|^2}{R^2 - |u|^2}, \frac{2R^2\mathbf u}{R^2 - |u|^2}\right).&lt;/math&gt;

The pulled back metric can be obtained by straightforward methods of calculus;

:&lt;math&gt;\left.\left(\sigma^{-1}\right)^* \eta\right|_{\mathbf H_R^{1 (n)}} = \left(dx^1(\mathbf u)\right)^2 + \cdots + \left(dx^n(\mathbf u)\right)^2 - \left(d\tau(\mathbf u)\right)^2.&lt;/math&gt;

One computes according to the standard rules for computing differentials (though one is really computing the rigorously defined exterior derivatives),

:&lt;math&gt;\begin{align}
  dx^1(\mathbf u) &amp;= d\left(\frac{2R^2 u^1}{R^2 - |u|^2}\right)
                   = \frac{\partial}{\partial u^1}\frac{2R^2 u^1}{R^2 - |u|^2}du^1 + \cdots +
                       \frac{\partial}{\partial u^n}\frac{2R^2 u^1}{R^2 - |u|^2}du^n +
                       \frac{\partial}{\partial \tau}\frac{2R^2 u^1}{R^2 - |u|^2}d\tau,\\
                   &amp;{}\vdots\\
   dx^n(\mathbf u) &amp;= d\left(\frac{2R^2 u^n}{R^2 - |u|^2}\right) = \cdots,\\
  d\tau(\mathbf u) &amp;= d\left(R\frac{R^2 + |u|^2}{R^2 - |u|^2}\right) = \cdots,\end{align}
&lt;/math&gt;

and substitutes the results into the right hand side. This yields

{{Equation box 1
|indent =:
|equation = 
:&lt;math&gt;\left(\sigma^{-1}\right)^* h_R^{1(n)} = \frac{4R^2 \left[\left(du^1\right)^2 + \cdots + \left(du^n\right)^2\right]}{\left(R^2 - |u|^2\right)^2} \equiv h_R^{2(n)}. &lt;/math&gt;
|cellpadding= 6
|border
|border colour = #0073CF
|bgcolor=#F9FFF7
}}

{| class="wikitable collapsible collapsed"
! Detailed outline of computation
|-
|

One has

:&lt;math&gt;\begin{align}
  \frac{\partial}{\partial u^1}\frac{2R^2 u^1}{R^2 - |u|^2}du^1 &amp;= \frac{2\left(R^2 -|u|^2\right) + 4R^2 \left(u^1\right)^2}{\left(R^2 - |u|^2\right)^2}du^1, \\
  \frac{\partial}{\partial u^2}\frac{2R^2 u^1}{R^2 - |u|^2}du^2 &amp;= \frac{4R^2 u^1 u^2 du^2}{\left(R^2 - |u|^2\right)^2}du^2,
\end{align}&lt;/math&gt;

and

:&lt;math&gt;\frac{\partial}{\partial \tau}\frac{2R^2 u^1}{R^2 - |u|^2}d\tau^2 = 0.&lt;/math&gt;

With this one may write

:&lt;math&gt;dx^1(\mathbf u) = \frac{2R^2 \left(R^2 - |u|^2\right)du^1 + 4R^2 u^1(\mathbf u \cdot d\mathbf u)}{\left(R^2 - |u|^2\right)^2},&lt;/math&gt;

from which

:&lt;math&gt;\left(dx^1(\mathbf u)\right)^2 = \frac{4R^2 \left(r^2 - |u|^2\right)^2 \left(du^1\right)^2 + 16R^4 \left(R^2 - |u|^2\right)\left(\mathbf u \cdot d\mathbf u\right)u^1 du^1 + 14R^r \left(u^1\right)^2 \left(\mathbf u \cdot d\mathbf u\right)^2}{\left(R^2 - |u|^2\right)^4}.&lt;/math&gt;

Summing this formula one obtains

:&lt;math&gt;\begin{align}
      &amp;\left(dx^1(\mathbf u)\right)^2 + \cdots + \left(dx^n(\mathbf u)\right)^2 \\
  ={} &amp;\frac{4R^2 \left(R^2 - |u|^2\right)^2 \left[\left(du^1\right)^2 + \cdots + \left(du^n\right)^2\right] +
             16R^4 \left(R^2 - |u|^2\right)(\mathbf u \cdot d\mathbf u)(\mathbf u \cdot d\mathbf u) +
             16R^4 |u|^2 (\mathbf u \cdot d\mathbf u)^2}
            {\left(R^2 - |u|^2\right)^4} \\
  ={} &amp;\frac{4R^2 \left(R^2 - |u|^2\right)^2 \left[\left(du^1\right)^2 + \cdots + \left(du^n\right)^2\right]}{\left(R^2 - |u|^2\right)^4} +
      R^2 \frac{16R^4 (\mathbf u \cdot d\mathbf u)}{\left(R^2 - |u|^2\right)^4}.
\end{align}&lt;/math&gt;

Similarly, for {{mvar|τ}} one gets

:&lt;math&gt;
  d\tau = \sum_{i=1}^n \frac{\partial}{\partial u^i} R\frac{R^2 + |u|^2}{R^2 + |u|^2}du^i + \frac{\partial}{\partial\tau}R\frac{R^2 + |u|^2}{R^2 + |u|^2}d\tau
        = \sum_{i=1}^n R^4\frac{4R^2u^idu^i}{\left(R^2 - |u|^2\right)},
&lt;/math&gt;

yielding

:&lt;math&gt;-dt^2 = -\left(R\frac{4R^4\left(\mathbf u \cdot d\mathbf u\right)}{\left(R^2 - |u|^2\right)^2}\right)^2 = -R^2\frac{14R^4(\mathbf u \cdot d\mathbf u)^2}{\left(R^2 - |u|^2\right)^4}.&lt;/math&gt;

Now add this contribution to finally get

:&lt;math&gt;\left(\sigma^{-1}\right)^* h_R^{1(n)} = \frac{4R^2\left[\left(du^1\right)^2 + \cdots + \left(du^n\right)^2\right]}{\left(R^2 - |u|^2\right)^2} \equiv h_R^{2(n)}. &lt;/math&gt;
|}
This last equation shows that the metric on the ball is identical to the Riemannian metric {{math|''h''{{su|p=2(''n'')|b=''R''}}}} in the [[Poincaré ball model]], another standard model of hyperbolic geometry.
{| class="wikitable collapsible collapsed"
! Alternative calculation using the pushforward
|-
|

The pullback can be computed in a different fashion. By definition,

:&lt;math&gt;\left(\sigma^{-1}\right)^* h_R^{1(n)}(V, V) = h_R^{1(n)}\left(\left(\sigma^{-1}\right)_* V, \left(\sigma^{-1}\right)_* V\right) = \eta|_{\mathbf H_R^{1(n)}} \left(\left(\sigma^{-1}\right)_* V, \left(\sigma^{-1}\right)_* V\right).&lt;/math&gt;

In coordinates,
:&lt;math&gt;(\sigma^{-1})_*V = (\sigma^{-1})_*V^i\frac{\partial}{\partial u^i} = V^i\frac{\partial x^j}{\partial u^i}\frac{\partial}{\partial x^j} + V^i\frac{\partial \tau}{\partial u^i}\frac{\partial}{\partial \tau} = V^i\frac{\partial }x^j{\partial u^i}\frac{\partial}{\partial x^j} + V^i\frac{\partial }\tau{\partial u^i}\frac{\partial}{\partial \tau} = Vx^j\frac{\partial}{\partial x^j} + V\tau \frac{\partial}{\partial \tau}.&lt;/math&gt;

One has from the formula for {{math|''σ''&lt;sup&gt;–1&lt;/sup&gt;}}

:&lt;math&gt;\begin{align}Vx^j &amp;= V^i\frac{\partial}{\partial u^i}\left(\frac{2R^2u^j}{R^2 - |u|^2}\right) = \frac{2R^2V^j}{R^2 - |u|^2} - \frac{4R^2u^j\langle \mathbf V, \mathbf u\rangle}{\left(R^2 - |u|^2\right)^2}, \qquad \left(\text{here } V|u|^2 = 2\Sigma_{k=1}^nV^ku^k \equiv 2\langle \mathbf V, \mathbf u\rangle\right)\\
V\tau &amp;= V\left (R\frac{R^2 + |u|^2}{R^2 - |u|^2}\right) = \frac{4R^3\langle \mathbf V, \mathbf u\rangle}{\left(R^2 - |u|^2\right)^2}.\end{align}&lt;/math&gt;

Lastly,

:&lt;math&gt;\eta(\sigma_*^{-1}V, \sigma_*^{-1})V) = \Sigma_{j=1}^n\left(Vx^j\right)^2 - (V\tau)^2 = \frac{4R^4 |V|^2}{\left(R^2 - |u|^2\right)^2} = h_R^{2(n)}(V, V),&lt;/math&gt;

and the same conclusion is reached.
|}

==See also==
{{div col|colwidth=25em}}
* [[Introduction to the mathematics of general relativity]]
* [[Minkowski plane]]
{{div col end}}

== Remarks ==
{{Reflist|group=nb|2}}

== Notes ==
{{Reflist|2}}

== References==
*{{cite journal|ref=harv|last=Corry|first=L.|title=Hermann Minkowski and the postulate of relativity|journal=Arch. Hist. Exact Sci.|volume=51|issue=4|year=1997|doi=10.1007/BF00518231|pages=273&amp;ndash;314|publisher=[[Springer-Verlag]]|issn=0003-9519|url=https://link.springer.com/article/10.1007%2FBF00518231|subscription=yes}}
*{{cite book|ref=harv|last1=Catoni|first1=F.|year=2008|title=Mathematics of Minkowski Space|series=Frontiers in Mathematics|publisher=[[Birkhäuser Verlag]]|issn=1660-8046|location=Basel|isbn=978-3-7643-8613-9|doi=10.1007/978-3-7643-8614-6|display-authors=etal}}
*{{cite book|ref=harv|last=Galison|first=P. L.|title=Minkowski's Space-Time: from visual thinking to the absolute world|series=Historical Studies in the Physical Sciences|volume=10|doi=10.2307/27757388|editor=R McCormach|publisher=[[Johns Hopkins University Press]]|year=1979|pages=85&amp;ndash;121|jstor=27757388|subscription=yes|display-editors=etal}}
*{{cite book|ref=harv|first1=D.|last1=Kleppner|authorlink1=Daniel Kleppner|first2=R. J.|last2=Kolenkow|authorlink2=Robert J. Kolenkow|title=An Introduction to Mechanics|year=1978|orig-year=1973|isbn=0-07-035048-5|publisher=[[McGraw-Hill]]|location=London}}
*{{cite book|ref=harv|last1=Landau|first1=L.D.|authorlink1=Lev Landau|last2=Lifshitz|first2=E.M.|authorlink2=Evgeny Lifshitz|title=The Classical Theory of Fields|series=Course of Theoretical Physics|volume=2|edition=4th|publisher=[[Butterworth&amp;ndash;Heinemann]]|isbn=0 7506 2768 9|year=2002|orig-year=1939}}
*{{cite book|ref=harv|last=Lee|first= J. M.|title=Introduction to Smooth manifolds|year=2003|publisher=|series=Springer Graduate Texts in Mathematics|isbn=0-387-95448-1|volume=218}}
*{{cite book|ref=harv|last=Lee|first= J. M.|title=Riemannian Manifolds &amp;ndash; An Introduction to Curvature|year=1997|publisher=Springer Verlag|location=New York · Berlin · Heidelberg|series=Springer Graduate Texts in Mathematics|volume=176|isbn=978-0-387-98322-6}}
*{{Citation|last=Minkowski|first=Hermann|authorlink=Hermann Minkowski|year=1907–1908|title=[[s:de:Die Grundgleichungen für die elektromagnetischen Vorgänge in bewegten Körpern|Die Grundgleichungen für die elektromagnetischen Vorgänge in bewegten Körpern]]|trans-title=The Fundamental Equations for Electromagnetic Processes in Moving Bodies|journal=Nachrichten von der Gesellschaft der Wissenschaften zu Göttingen, Mathematisch-Physikalische Klasse|pages=53–111}} *Wikisource translation: [[s:Translation:The Fundamental Equations for Electromagnetic Processes in Moving Bodies|The Fundamental Equations for Electromagnetic Processes in Moving Bodies]]
*{{Citation|last=Minkowski|first=Hermann|year=1908–1909|title=[[s:de:Raum und Zeit (Minkowski)|Raum und Zeit]]|trans-title=Space and Time|journal=Physikalische Zeitschrift|volume=10|pages=75–88}} Various English translations on Wikisource: [[s:Translation:Space and Time|Space and Time]]
* {{Citation|first=Charles W.|last=Misner|authorlink=Charles W. Misner|first2=Kip. S.|last2=Thorne|author2-link=Kip Thorne|first3=John A.|last3=Wheeler|author3-link=John A. Wheeler|title=[[Gravitation (book)|Gravitation]]|publisher= W. H. Freeman|date=1973|isbn=0-7167-0344-0}}
*{{Cite book|ref=harv|last=Naber|first=G. L.|title=The Geometry of Minkowski Spacetime|year=1992|publisher=[[Springer-Verlag]]|location=New York|isbn=0-387-97848-8}}
*{{cite journal|ref=harv|first=J.|last=Nash|authorlink=John Forbes Nash|title=The Imbedding Problem for Riemannian Manifolds|journal=[[Annals of Mathematics]]|year=1956|volume=63|issue=1|pages=20&amp;ndash;63|doi=10.2307/1969989|mr=0075639|jstor=1969989}}
*{{cite book|ref=harv|last=Penrose|first=Roger|authorlink=Roger Penrose|year=2005|title=Road to Reality : A Complete Guide to the Laws of the Universe|chapter=18 Minkowskian geometry|publisher=[[Alfred A. Knopf]]|isbn=9780679454434}}
*{{Citation|last=Poincaré|first=Henri|authorlink=Henri Poincaré|year=1905–1906|title=[[s:fr:Sur la dynamique de l’électron (juillet)|Sur la dynamique de l’électron]]|trans-title=On the Dynamics of the Electron|journal=Rendiconti del Circolo matematico di Palermo|volume=21|pages=129–176|doi=10.1007/BF03013466}} Wikisource translation: [[s:Translation:On the Dynamics of the Electron (July)|On the Dynamics of the Electron]]
*{{cite book|ref=harv|last=Sard|first=R. D.|title=Relativistic Mechanics - Special Relativity and Classical Particle Dynamics|year=1970|publisher=W. A. Benjamin|location=New York|isbn=978-0805384918}}
*{{cite book|ref=harv|last=Shaw|first=R.|year=1982|title=Linear Algebra and Group Representations|chapter=§ 6.6 Minkowski space, § 6.7,8 Canonical forms pp 221&amp;ndash;242|publisher=[[Academic Press]]|isbn=0-12-639201-3}}
* {{Cite book|last=Walter|first=Scott A.|title=The Expanding Worlds of General Relativity |chapter=Minkowski, Mathematicians, and the Mathematical Theory of Relativity |authorlink= |editor=Goenner, Hubert (ed.) |year=1999 |publisher=Birkhäuser |location=Boston |isbn=0-8176-4060-6 |pages=45&amp;ndash;86 |chapterurl=http://scottwalter.free.fr/papers/1999-mmm-walter.html |display-editors=etal}}
*{{citation|last=Weinberg|first=S.|year=2002|title=The Quantum Theory of Fields|volume=1|isbn=0-521-55001-7|authorlink=Steven Weinberg|publisher=[[Cambridge University Press]]}}

==External links==
{{Commons category-inline|bullet=none|Minkowski diagrams}}
*{{YouTube|C2VMO7pcWhg|Animation clip}} visualizing Minkowski space in the context of special relativity.
*[https://web.archive.org/web/20150402140655/http://www.relativityscience.com/Minkowski_special_relativity_geometry.shtml The Geometry of Special Relativity: The Minkowski Space - Time Light Cone]

{{Relativity}}

{{Authority control}}

{{DEFAULTSORT:Minkowski Space}}
[[Category:Concepts in physics]]
[[Category:Geometry]]
[[Category:Minkowski spacetime| ]]
[[Category:Lorentzian manifolds]]
[[Category:Special relativity]]
[[Category:Exact solutions in general relativity]]
[[Category:Hermann Minkowski]]</text>
      <sha1>ecgk399d5kdnpdjudyt1vfiidvcxvno</sha1>
    </revision>
  </page>
  <page>
    <title>Mostowski model</title>
    <ns>0</ns>
    <id>43774420</id>
    <revision>
      <id>624886501</id>
      <parentid>624743370</parentid>
      <timestamp>2014-09-10T02:11:12Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>more wikilinks</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="925">In mathematical [[set theory]], the '''Mostowski model''' is a [[Model theory|model]] of set theory with [[Atom (set theory)|atoms]] where the full [[axiom of choice]] fails, but every set can be [[Linear extension#Order-extension principle |linearly ordered]]. It was introduced by {{harvs|txt|last=Mostowski|year=1939|authorlink=Andrzej Mostowski}}. The Mostowski model can be constructed as the [[permutation model]] corresponding to the [[automorphism group|group of all automorphisms]] of the ordered set of [[rational numbers]] and the ideal of finite subsets of the rational numbers.

==References==
*{{citation|journal=Fundamenta Mathematicae
|year=1939 |volume= 32 |issue= 1 | pages=201-252
|title=Über die Unabhängigkeit des Wohlordnungssatzes vom Ordnungsprinzip
|first=Andrzej|last= Mostowski |url=http://pldml.icm.edu.pl/pldml/element/bwmeta1.element.bwnjournal-article-fmv32i1p18bwm}}

[[Category:Set theory]]</text>
      <sha1>9ms7my12c8s1gp856cqrknit4i4za22</sha1>
    </revision>
  </page>
  <page>
    <title>Nodoid</title>
    <ns>0</ns>
    <id>11396581</id>
    <revision>
      <id>705030198</id>
      <parentid>705027367</parentid>
      <timestamp>2016-02-15T02:26:06Z</timestamp>
      <contributor>
        <username>Nicoguaro</username>
        <id>6284746</id>
      </contributor>
      <comment>Vector image</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="890">[[File:Nodoid.svg|thumb|Half of a nodoid surface.]]

In [[differential geometry]], a '''nodoid''' is a [[surface of revolution]] with [[Constant mean curvature surface|constant nonzero mean curvature]] obtained by rolling a [[hyperbola]] along a fixed line, tracing the [[Focus (geometry)|focus]], and revolving the resulting [[nodary]] curve around the line.&lt;ref name="oprea"&gt;{{citation
 | last = Oprea | first = John
 | edition = 2nd
 | isbn = 978-0-88385-748-9
 | location = Washington, DC
 | mr = 2327126
 | pages = 147–148
 | publisher = Mathematical Association of America
 | series = Classroom Resource Materials Series
 | title = Differential Geometry and its Applications
 | year = 2007}}.&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*[http://demonstrations.wolfram.com/DelaunayNodoids/ Wolfram Demonstrations: Delaunay Nodoids]

{{geometry-stub}}
[[Category:Surfaces]]</text>
      <sha1>natl87xqk5facbnx7a9neuvpf56r6v3</sha1>
    </revision>
  </page>
  <page>
    <title>Noncototient</title>
    <ns>0</ns>
    <id>758718</id>
    <revision>
      <id>849140227</id>
      <parentid>849137927</parentid>
      <timestamp>2018-07-06T20:31:34Z</timestamp>
      <contributor>
        <ip>101.15.51.215</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8283">In mathematics, a '''noncototient''' is a positive integer ''n'' that cannot be expressed as the difference between a positive integer ''m'' and the number of [[coprime]] integers below it. That is, ''m''&amp;nbsp;&amp;minus;&amp;nbsp;φ(''m'')&amp;nbsp;=&amp;nbsp;''n'', where φ stands for [[Euler's totient function]], has no solution for&amp;nbsp;''m''.  The ''[[cototient]]'' of ''n'' is defined as ''n''&amp;nbsp;&amp;minus;&amp;nbsp;φ(''n''), so a '''noncototient''' is a number that is never a cototient.

It is conjectured that all noncototients are even. This follows from a modified form of the slightly stronger version of the [[Goldbach conjecture]]: if the even number ''n'' can be represented as a sum of two distinct primes ''p'' and ''q,'' then

:&lt;math&gt;pq - \varphi(pq) = pq - (p-1)(q-1) = p+q-1 = n-1. \,&lt;/math&gt;

It is expected that every even number larger than 6 is a sum of two distinct primes, so probably no odd number larger than 5 is a noncototient. The remaining odd numbers are covered by the observations &lt;math&gt;1=2-\phi(2), 3 = 9 - \phi(9)&lt;/math&gt; and &lt;math&gt;5 = 25 - \phi(25)&lt;/math&gt;.

For even numbers, it can be shown
:&lt;math&gt;2pq - \varphi(2pq) = 2pq - (p-1)(q-1) = pq+p+q-1 = (p+1)(q+1)-2&lt;/math&gt;

Thus, all even numbers ''n'' such that ''n''+2 can be written as (p+1)*(q+1) with ''p'', ''q'' primes are cototients.

The first few noncototients are

:[[10 (number)|10]], [[26 (number)|26]], [[34 (number)|34]], [[50 (number)|50]], [[52 (number)|52]], [[58 (number)|58]], [[86 (number)|86]], [[100 (number)|100]], [[116 (number)|116]], [[122 (number)|122]], [[130 (number)|130]], [[134 (number)|134]], [[146 (number)|146]], [[154 (number)|154]], [[170 (number)|170]], [[172 (number)|172]], 186, 202, 206, 218, [[222 (number)|222]], 232, 244, 260, 266, 268, 274, 290, 292, 298, 310, 326, 340, 344, 346, 362, 366, 372, 386, 394, 404, 412, 436, 466, 470, 474, 482, 490, ... {{OEIS|id=A005278}}

The cototient of ''n'' are
:0, 1, 1, 2, 1, 4, 1, 4, 3, 6, 1, 8, 1, 8, 7, 8, 1, 12, 1, 12, 9, 12, 1, 16, 5, 14, 9, 16, 1, 22, 1, 16, 13, 18, 11, 24, 1, 20, 15, 24, 1, 30, 1, 24, 21, 24, 1, 32, 7, 30, 19, 28, 1, 36, 15, 32, 21, 30, 1, 44, 1, 32, 27, 32, 17, 46, 1, 36, 25, 46, 1, 48, ... {{OEIS|id=A051953}}

Least ''k'' such that the cototient of ''k'' is ''n'' are (start with ''n'' = 0, 0 if no such ''k'' exists)
:1, 2, 4, 9, 6, 25, 10, 15, 12, 21, 0, 35, 18, 33, 26, 39, 24, 65, 34, 51, 38, 45, 30, 95, 36, 69, 0, 63, 52, 161, 42, 87, 48, 93, 0, 75, 54, 217, 74, 99, 76, 185, 82, 123, 60, 117, 66, 215, 72, 141, 0,  ... {{OEIS|id=A063507}}

Greatest ''k'' such that the cototient of ''k'' is ''n'' are (start with ''n'' = 0, 0 if no such ''k'' exists)
:1, ∞, 4, 9, 8, 25, 10, 49, 16, 27, 0, 121, 22, 169, 26, 55, 32, 289, 34, 361, 38, 85, 30, 529, 46, 133, 0, 187, 52, 841, 58, 961, 64, 253, 0, 323, 68, 1369, 74, 391, 76, 1681, 82, 1849, 86, 493, 70, 2209, 94, 589, 0, ... {{OEIS|id=A063748}}

Number of ''k''s such that ''k''-φ(''k'') is ''n'' are (start with ''n'' = 0)
:1, ∞, 1, 1, 2, 1, 1, 2, 3, 2, 0, 2, 3, 2, 1, 2, 3, 3, 1, 3, 1, 3, 1, 4, 4, 3, 0, 4, 1, 4, 3, 3, 4, 3, 0, 5, 2, 2, 1, 4, 1, 5, 1, 4, 2, 4, 2, 6, 5, 5, 0, 3, 0, 6, 2, 4, 2, 5, 0, 7, 4, 3, 1, 8, 4, 6, 1, 3, 1, 5, 2, 7, 3, ... {{OEIS|id=A063740}}

[[Paul Erdős|Erdős]] (1913-1996) and [[Wacław Sierpiński|Sierpinski]] (1882-1969) asked whether there exist infinitely many noncototients. This was finally answered in the affirmative by Browkin and Schinzel (1995), who showed every member of the infinite family &lt;math&gt; 2^k \cdot 509203&lt;/math&gt; is an example (See [[Riesel number]]). Since then other infinite families, of roughly the same form, have been given by Flammenkamp and Luca (2000).

{|class="wikitable"
|''n''||numbers ''k'' such that ''k''-φ(''k'') = ''n''||''n''||numbers ''k'' such that ''k''-φ(''k'') = ''n''||''n''||numbers ''k'' such that ''k''-φ(''k'') = ''n''||''n''||numbers ''k'' such that ''k''-φ(''k'') = ''n''
|-
|1||all primes||37||217, 1369||73||213, 469, 793, 1333, 5329||109||321, 721, 1261, 2449, 2701, 2881, 11881
|-
|2||4||38||74||74||146||110||150, 182, 218
|-
|3||9||39||99, 111, 319, 391||75||207, 219, 275, 355, 1003, 1219, 1363||111||231, 327, 535, 1111, 2047, 2407, 2911, 3127
|-
|4||6, 8||40||76||76||148||112||196, 208
|-
|5||25||41||185, 341, 377, 437, 1681||77||245, 365, 497, 737, 1037, 1121, 1457, 1517||113||545, 749, 1133, 1313, 1649, 2573, 2993, 3053, 3149, 3233, 12769
|-
|6||10||42||82||78||114||114||226
|-
|7||15, 49||43||123, 259, 403, 1849||79||511, 871, 1159, 1591, 6241||115||339, 475, 763, 1339, 1843, 2923, 3139
|-
|8||12, 14, 16||44||60, 86||80||152, 158||116||
|-
|9||21, 27||45||117, 129, 205, 493||81||189, 237, 243, 781, 1357, 1537||117||297, 333, 565, 1177, 1717, 2581, 3337
|-
|10||||46||66, 70||82||130||118||174, 190
|-
|11||35, 121||47||215, 287, 407, 527, 551, 2209||83||395, 803, 923, 1139, 1403, 1643, 1739, 1763, 6889||119||539, 791, 1199, 1391, 1751, 1919, 2231, 2759, 3071, 3239, 3431, 3551, 3599
|-
|12||18, 20, 22||48||72, 80, 88, 92, 94||84||164, 166||120||168, 200, 232, 236
|-
|13||33, 169||49||141, 301, 343, 481, 589||85||165, 249, 325, 553, 949, 1273||121||1331, 1417, 1957, 3397
|-
|14||26||50||||86||||122||
|-
|15||39, 55||51||235, 451, 667||87||415, 1207, 1711, 1927||123||1243, 1819, 2323, 3403, 3763
|-
|16||24, 28, 32||52||||88||120, 172||124||244
|-
|17||65, 77, 289||53||329, 473, 533, 629, 713, 2809||89||581, 869, 1241, 1349, 1541, 1769, 1829, 1961, 2021, 7921||125||625, 1469, 1853, 2033, 2369, 2813, 3293, 3569, 3713, 3869, 3953
|-
|18||34||54||78, 106||90||126, 178||126||186
|-
|19||51, 91, 361||55||159, 175, 559, 703||91||267, 1027, 1387, 1891||127||255, 2071, 3007, 4087, 16129
|-
|20||38||56||98, 104||92||132, 140||128||192, 224, 248, 254, 256
|-
|21||45, 57, 85||57||105, 153, 265, 517, 697||93||261, 445, 913, 1633, 2173||129||273, 369, 381, 1921, 2461, 2929, 3649, 3901, 4189
|-
|22||30||58||||94||138, 154||130||
|-
|23||95, 119, 143, 529||59||371, 611, 731, 779, 851, 899, 3481||95||623, 1079, 1343, 1679, 1943, 2183, 2279||131||635, 2147, 2507, 2987, 3131, 3827, 4187, 4307, 4331, 17161
|-
|24||36, 40, 44, 46||60||84, 100, 116, 118||96||144, 160, 176, 184, 188||132||180, 242, 262
|-
|25||69, 125, 133||61||177, 817, 3721||97||1501, 2077, 2257, 9409||133||393, 637, 889, 3193, 3589, 4453
|-
|26||||62||122||98||194||134||
|-
|27||63, 81, 115, 187||63||135, 147, 171, 183, 295, 583, 799, 943||99||195, 279, 291, 979, 1411, 2059, 2419, 2491||135||351, 387, 575, 655, 2599, 3103, 4183, 4399
|-
|28||52||64||96, 112, 124, 128||100||||136||268
|-
|29||161, 209, 221, 841||65||305, 413, 689, 893, 989, 1073||101||485, 1157, 1577, 1817, 2117, 2201, 2501, 2537, 10201||137||917, 1397, 3161, 3317, 3737, 3977, 4661, 4757, 18769
|-
|30||42, 50, 58||66||90||102||202||138||198, 274
|-
|31||87, 247, 961||67||427, 1147, 4489||103||303, 679, 2263, 2479, 2623, 10609||139||411, 1651, 3379, 3811, 4171, 4819, 4891, 19321
|-
|32||48, 56, 62, 64||68||134||104||206||140||204, 220, 278
|-
|33||93, 145, 253||69||201, 649, 901, 1081, 1189||105||225, 309, 425, 505, 1513, 1909, 2773||141||285, 417, 685, 1441, 3277, 4141, 4717, 4897
|-
|34||||70||102, 110||106||170||142||230, 238
|-
|35||75, 155, 203, 299, 323||71||335, 671, 767, 1007, 1247, 1271, 5041||107||515, 707, 1067, 1691, 2291, 2627, 2747, 2867, 11449||143||363, 695, 959, 1703, 2159, 3503, 3959, 4223, 4343, 4559, 5063, 5183
|-
|36||54, 68||72||108, 136, 142||108||156, 162, 212, 214||144||216, 272, 284
|}

==References==
* {{cite journal | zbl=0820.11003 | last1=Browkin | first1=J. | last2=Schinzel | first2=A. | title=On integers not of the form n-φ(n) | journal=Colloq. Math. | volume=68 | number=1 | pages=55–58 | year=1995 }}
* {{cite journal | zbl=0965.11003 | last1=Flammenkamp | first1=A. | last2=Luca | first2=F. | title=Infinite families of noncototients | journal=Colloq. Math. | volume=86 | number=1 | pages=37–41 | year=2000 }}
* {{cite book |last=Guy | first=Richard K. | authorlink=Richard K. Guy | title=Unsolved problems in number theory | publisher=[[Springer-Verlag]] |edition=3rd | year=2004 |isbn=978-0-387-20860-2 | zbl=1058.11001 | pages=138–142}}

== External links ==
* [http://mathworld.wolfram.com/Noncototient.html Noncototient definition from MathWorld]

{{Totient}}
{{Classes of natural numbers}}

[[Category:Integer sequences]]</text>
      <sha1>ct94n62eawwm0ie153apn1j1esnhp4o</sha1>
    </revision>
  </page>
  <page>
    <title>Numerical differentiation</title>
    <ns>0</ns>
    <id>1254566</id>
    <revision>
      <id>868498262</id>
      <parentid>867923759</parentid>
      <timestamp>2018-11-12T15:59:20Z</timestamp>
      <contributor>
        <ip>62.167.48.104</ip>
      </contributor>
      <comment>/* Higher Derivatives */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12161">In [[numerical analysis]], '''numerical differentiation''' describes [[algorithm]]s for estimating the [[derivative]] of a [[mathematical function]] or function [[subroutine]] using values of the function and perhaps other knowledge about the function.

[[Image:Derivative.svg|230px|right]]

==Finite difference formulas==
The simplest method is to use finite difference approximations.

A simple two-point estimation is to compute the slope of a nearby [[secant line]] through the points (''x'',''f(x)'') and (''x+h'',''f(x+h)'').&lt;ref&gt;Richard L. Burden, J. Douglas Faires (2000), ''Numerical Analysis'', (7th Ed),  Brooks/Cole. {{isbn|0-534-38216-9}}&lt;/ref&gt; Choosing a small number ''h'',  ''h'' represents a small change in ''x'', and it can be either positive or negative.  The slope of this line is
:&lt;math&gt;{f(x+h)-f(x)\over h}.&lt;/math&gt;
This expression is [[Isaac Newton|Newton]]'s [[difference quotient]] (also known as a first-order [[divided difference]].)

The slope of this secant line differs from the slope of the tangent line by an amount that is approximately proportional to ''h''. As ''h'' approaches zero, the slope of the secant line approaches the slope of the tangent line. Therefore, the true '''derivative of''' '''''f''''' '''at''' '''''x''''' is the limit of the value of the difference quotient as the secant lines get closer and closer to being a tangent line:
:&lt;math&gt;f'(x)=\lim_{h\to 0}{f(x+h)-f(x)\over h}.&lt;/math&gt;

Since immediately [[substitution (logic)|substituting]] 0 for ''h'' results in [[division by zero]], calculating the derivative directly can be unintuitive.

Equivalently, the slope could be estimated by employing positions (x - h) and x.

Another two-point formula is to compute the slope of a nearby secant line through the points (''x-h'',''f(x-h)'') and (''x+h'',''f(x+h)''). The slope of this line is
:&lt;math&gt;{f(x+h)-f(x-h)\over 2h}.&lt;/math&gt;

This formula is known as the [[symmetric difference quotient]]. In this case the first-order errors cancel, so the slope of these secant lines differ from the slope of the tangent line by an amount that is approximately proportional to &lt;math&gt;h^2&lt;/math&gt;. Hence for small values of ''h'' this is a more accurate approximation to the tangent line than the one-sided estimation. Note however that although the slope is being computed at x, the value of the function at x is not involved.

The estimation error is given by:

:&lt;math&gt;R = {{-f^{(3)}(c)}\over {6}}h^2&lt;/math&gt;,

where &lt;math&gt;c&lt;/math&gt; is some point between &lt;math&gt;x-h&lt;/math&gt; and &lt;math&gt;x+h&lt;/math&gt;.
This error does not include the [[rounding error]] due to numbers being represented and calculations being performed in limited precision.

The symmetric difference quotient is employed as the method of approximating the derivative in a number of calculators, including [[TI-82]], [[TI-83]], [[TI-84]], [[TI-85]] all of which use this method with ''h''=0.001.&lt;ref name="Merseth2003"&gt;{{cite book|author=Katherine Klippert Merseth|title=Windows on Teaching Math: Cases of Middle and Secondary Classrooms|year=2003|publisher=Teachers College Press|isbn=978-0-8077-4279-2|page=34}}&lt;/ref&gt;&lt;ref name="RubySellers2014"&gt;{{cite book|author1=Tamara Lefcourt Ruby|author2=James Sellers|author3=Lisa Korf |author4=Jeremy Van Horn |author5=Mike Munn|title=Kaplan AP Calculus AB &amp; BC 2015|year=2014|publisher=Kaplan Publishing|isbn=978-1-61865-686-5|page=299}}&lt;/ref&gt;

===Practical considerations using floating point arithmetic===
[[Image:AbsoluteErrorNumericalDifferentiationExample.png|thumb|300px|Example showing the difficulty of choosing &lt;math&gt;h&lt;/math&gt; due to both rounding error and formula error]]

An important consideration in practice when the function is calculated using [[floating point]] arithmetic is how small a value of ''h'' to choose. If chosen too small, the subtraction will yield a large [[rounding error]]. In fact all the finite difference formulae are [[ill-conditioned]]&lt;ref name=Fornberg1&gt;Numerical Differentiation of Analytic Functions, B Fornberg - ACM Transactions on Mathematical Software (TOMS), 1981&lt;/ref&gt; and due to cancellation will produce a value of zero if ''h'' is small enough.&lt;ref name=SquireTrapp1&gt;Using Complex Variables to Estimate Derivatives of Real Functions, W Squire, G Trapp - SIAM REVIEW, 1998&lt;/ref&gt; If too large, the calculation of the slope of the secant line will be more accurately calculated, but the estimate of the slope of the tangent by using the secant could be worse.

A choice for ''h'' which is small without producing a large rounding error is &lt;math&gt;\sqrt{\varepsilon}x&lt;/math&gt; (though not when ''x'' = 0) where the [[machine epsilon]] ''&amp;epsilon;'' is typically of the order of 2.2&amp;times;10&lt;sup&gt;−16&lt;/sup&gt;.
&lt;ref&gt;Following ''[[Numerical Recipes]] in C'', [http://www.nrbook.com/a/bookcpdf/c5-7.pdf Chapter 5.7]&lt;/ref&gt; A formula for ''h'' that balances the rounding error against the secant error for optimum accuracy is

&lt;math&gt;h = 2\sqrt{\varepsilon\left|{f(x)\over f''(x)}\right|}&lt;/math&gt;
&lt;ref&gt;[http://www.uio.no/studier/emner/matnat/math/MAT-INF1100/h10/kompendiet/kap11.pdf p. 263]&lt;/ref&gt;
(though not when f"(x) = 0) and to employ it will require knowledge of the function.

This epsilon is for double precision (64-bit) variables: such calculations in single precision are rarely useful. The resulting value is unlikely to be a "round" number in binary, so it is important to realise that although ''x'' is a machine-[[Floating point#Representable numbers, conversion and rounding|representable]] number, ''x'' + ''h'' almost certainly will not be. This means that ''x'' + ''h'' will be changed (via rounding or truncation) to a nearby machine-representable number, with the consequence that (''x'' + ''h'') - ''x'' will ''not'' equal ''h''; the two function evaluations will not be exactly ''h'' apart. In this regard, since most decimal fractions are recurring sequences in binary (just as 1/3 is in decimal) a seemingly round step such as ''h'' = 0.1 will not be a round number in binary; it is 0.000110011001100... A possible approach is as follows:
  h:=sqrt(eps)*x;
  xph:=x + h;
  dx:=xph - x;
  slope:=(F(xph) - F(x))/dx;
However, with computers, [[compiler optimization]] facilities may fail to attend to the details of actual computer arithmetic, and instead apply the axioms of mathematics to deduce that ''dx'' and ''h'' are the same. With C and similar languages, a directive that ''xph'' is a [[volatile variable]] will prevent this.

===Higher-order methods===
{{further|Finite difference coefficients}}
Higher-order methods for approximating the derivative, as well as methods for higher derivatives exist.

Given below is the five point method for the first derivative ([[five-point stencil]] in one dimension).&lt;ref&gt;Abramowitz &amp; Stegun, Table 25.2&lt;/ref&gt;
:&lt;math&gt;f'(x) = \frac{-f(x+2 h)+8 f(x+h)-8 f(x-h)+f(x-2h)}{12 h}+\frac{h^4}{30}f^{(5)}(c)&lt;/math&gt;
where &lt;math&gt;c\in[x-2h,x+2h]&lt;/math&gt;.

For other stencil configurations and derivative orders, the [http://web.media.mit.edu/~crtaylor/calculator.html Finite Difference Coefficients Calculator] is a tool which can be used to generate derivative approximation methods for any stencil with any derivative order (provided a solution exists).

=== Higher Derivatives ===
Using Newton's difference quotient,

&lt;math&gt;f'(x)=\lim_{h\to 0}{f(x+h)-f(x)\over h}&lt;/math&gt;

the following can be shown (for positive n):

&lt;math&gt;f^n(x)=\lim_{h\to 0}{1\over h^n}\sum_{k=0}^{n} (-1)^{k+1}\binom{n}{k}f(x+kh)&lt;/math&gt;

==Differential quadrature==
[[Differential quadrature]] is the approximation of derivatives by using weighted sums of function values.&lt;ref&gt;Differential Quadrature and Its Application in Engineering: Engineering Applications, Chang Shu, Springer, 2000, {{isbn|978-1-85233-209-9}}&lt;/ref&gt;&lt;ref&gt;Advanced Differential Quadrature Methods, Yingyan Zhang, CRC Press, 2009, {{isbn|978-1-4200-8248-7}}&lt;/ref&gt; The name is in analogy with ''quadrature'' meaning [[Numerical integration]] where weighted sums are used in methods such as [[Simpson's method]] or the [[Trapezium rule]]. There are various methods for determining the weight coefficients. Differential quadrature is used to solve [[partial differential equations]].

==Complex variable methods==

The classical finite difference approximations for numerical differentiation are ill-conditioned. However, if &lt;math&gt;f&lt;/math&gt; is a [[holomorphic function]], real-valued on the real line, which can be evaluated at points in the complex plane near &lt;math&gt;x&lt;/math&gt; then there are [[Numerical stability|stable]] methods. For example,&lt;ref name=SquireTrapp1/&gt; the first derivative can be calculated by the complex-step derivative formula:&lt;ref&gt;{{cite journal | last1 = Martins | first1 = JRRA | first2 = P | last2 = Sturdza | first3 = JJ | last3 = Alonso | year = 2003 | citeseerx=10.1.1.141.8002 | title = The Complex-Step Derivative Approximation | journal = ACM Transactions on Mathematical Software | volume = 29 | issue = 3 | pages = 245–262 | doi=10.1145/838250.838251}}&lt;/ref&gt;

:&lt;math&gt;f'(x)\approx \Im(f(x + ih))/h&lt;/math&gt;.

The above formula is only valid for calculating a first-order derivative. A generalization of the above for calculating derivatives of any order derivatives employ [[multicomplex numbers]], resulting in multicomplex derivatives.&lt;ref&gt;http://russell.ae.utexas.edu/FinalPublications/ConferencePapers/2010Feb_SanDiego_AAS-10-218_mulicomplex.pdf&lt;/ref&gt;

In general, derivatives of any order can be calculated using [[Cauchy's integral formula]]:
:&lt;math&gt;f^{(n)}(a) = {n! \over 2\pi i} \oint_\gamma {f(z) \over (z-a)^{n+1}}\, \mathrm{d}z&lt;/math&gt;,
where the integration is done [[Numerical integration|numerically]].

Using complex variables for numerical differentiation was started by Lyness and Moler in 1967.&lt;ref name=LynessMoler1&gt;{{cite journal | first1 = J. N. | last1 = Lyness | first2 = C. B. | last2 = Moler | title = Numerical differentiation of analytic functions | journal = SIAM J.Numer. Anal. | volume = 4 | year = 1967 | pages = 202–210 | doi=10.1137/0704019}}&lt;/ref&gt; A method based on numerical inversion of a complex [[Laplace transform]] was developed by Abate and Dubner.&lt;ref&gt;{{cite journal | title = A New Method for Generating Power Series Expansions of Functions | first1 = J | last1 = Abate | first2 = H | last2 = Dubner | journal = SIAM J. Numer. Anal. | volume =5 | issue = 1 | pages = 102–112 |date=March 1968 | doi=10.1137/0705008}}&lt;/ref&gt; An algorithm which can be used without requiring knowledge about the method or the character of the function was developed by Fornberg.&lt;ref name=Fornberg1/&gt;

==See also==
*[[Automatic differentiation]]
*[[Finite difference]]
*[[Five-point stencil]]
*[[Numerical integration]]
*[[Numerical ordinary differential equations]]
*[[Numerical smoothing and differentiation]]
*[[List of numerical analysis software]]

==References==
{{reflist}}

== External links ==
{{wikibooks|Numerical Methods}}
* http://mathworld.wolfram.com/NumericalDifferentiation.html
*[http://numericalmethods.eng.usf.edu/topics/continuous_02dif.html Numerical Differentiation Resources: Textbook notes, PPT, Worksheets, Audiovisual YouTube Lectures] at [http://numericalmethods.eng.usf.edu/ Numerical Methods for STEM Undergraduate]
*ftp://math.nist.gov/pub/repository/diff/src/DIFF Fortran code for the numerical differentiation of a function using Neville's process to extrapolate from a sequence of simple polynomial approximations.
* [http://www.nag.co.uk/numeric/fl/nagdoc_fl24/html/D04/d04conts.html NAG Library numerical differentiation routines]
* http://graphulator.com [http://graphulator.com Online numerical graphing calculator with calculus function.]
* [http://www.boost.org/doc/libs/release/libs/math/doc/html/math_toolkit/diff.html Boost. Math numerical differentiation, including finite differencing and the complex step derivative]
*[https://blogs.mathworks.com/cleve/2013/10/14/complex-step-differentiation/ Complex Step Differentiation]
*[https://sinews.siam.org/Details-Page/differentiation-without-a-difference Differentiation With(out) a Difference] by [[Nicholas Higham]], [[SIAM]] News.
{{DEFAULTSORT:Numerical Differentiation}}
[[Category:Numerical analysis]]
[[Category:Differential calculus]]</text>
      <sha1>ag2au6lynw6lniu178fvsat3ulxtr0m</sha1>
    </revision>
  </page>
  <page>
    <title>Ostrogradsky instability</title>
    <ns>0</ns>
    <id>44481226</id>
    <revision>
      <id>869476490</id>
      <parentid>853055890</parentid>
      <timestamp>2018-11-18T21:29:15Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <comment>/* Outline of proof {{Cite book |title=The Invisible Universe: Dark Matter and Dark Energy |volume=720 |pages=403–433 |arxiv=astro-ph/0601672|doi=10.1007/978-3-540-71013-4_14 |chapter=Avoiding Dark Energy with 1/R Modifications of Gravity |series=Lecture Notes in Physics |isbn=978-3-540-71012-7 |year=2007 |url=http://cds.cern.ch/record/925754/files/0601672.pdf|last1=Papantonopoulos |first1=Eleftherios }} */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3661">In applied mathematics, the '''Ostrogradsky instability''' is a consequence of a theorem of [[Mikhail Ostrogradsky]] in [[classical mechanics]] according to which a non-degenerate [[Lagrangian mechanics|Lagrangian]] dependent on time derivatives higher than the first corresponds to a linearly unstable [[Hamiltonian mechanics#Mathematical formalism|Hamiltonian]] associated with the Lagrangian via a [[Legendre transformation#Hamilton-Lagrange mechanics|Legendre transform]]. The Ostrogradsky instability has been proposed as an explanation as to why no differential equations of higher order than two appear to describe physical phenomena.&lt;ref&gt;{{Cite journal |title= Third-order equations of motion and the Ostrogradsky instability |journal=Physical Review D|volume=91|issue=8|arxiv=1411.3721|doi=10.1103/PhysRevD.91.085009|year=2015|last1=Motohashi|first1=Hayato|last2=Suyama|first2=Teruaki}}&lt;/ref&gt;

==Outline of proof &lt;ref&gt;{{Cite book |title=The Invisible Universe: Dark Matter and Dark Energy |volume=720 |pages=403–433 |arxiv=astro-ph/0601672|doi=10.1007/978-3-540-71013-4_14 |chapter=Avoiding Dark Energy with 1/R Modifications of Gravity |series=Lecture Notes in Physics |isbn=978-3-540-71012-7 |year=2007 |url=http://cds.cern.ch/record/925754/files/0601672.pdf|last1=Papantonopoulos |first1=Eleftherios }}&lt;/ref&gt;==

The main points of the proof can be made clearer by considering a one-dimensional system with a Lagrangian &lt;math&gt;L(q,{\dot q}, {\ddot q})&lt;/math&gt;. The [[Euler–Lagrange equation]] is

:&lt;math&gt; \frac{dL}{dq} - \frac{d}{dt} \frac{dL}{d{\dot q}}+ \frac{d^2}{dt^2}\frac{dL}{d{\ddot q}} = 0.&lt;/math&gt;

Non-degeneracy of &lt;math&gt;L&lt;/math&gt; means that the [[canonical coordinates]] can be expressed in terms of the derivatives of &lt;math&gt;{q}&lt;/math&gt; and vice versa. Thus, &lt;math&gt;dL/d{\ddot q}&lt;/math&gt; is a function of &lt;math&gt;{\ddot q}&lt;/math&gt; (if it was not, the [[Jacobian matrix and determinant|Jacobian]] &lt;math&gt;\det[d^2 L/(d{\ddot q_i}\, d{\ddot q}_j)]&lt;/math&gt; would vanish, which would mean that &lt;math&gt;L&lt;/math&gt; is degenerate), meaning that we can write &lt;math&gt;q^{(4)} = F(q,{\dot q}, {\ddot q}, q^{(3)})&lt;/math&gt; or, inverting, &lt;math&gt;q = G(t, q_0, {\dot q}_0, {\ddot q}_0, q^{(3)}_0)&lt;/math&gt;. Since the evolution of &lt;math&gt;q&lt;/math&gt; depends upon four initial parameters, this means that there are four canonical coordinates. We can write those as

:&lt;math&gt;Q_1 : = q&lt;/math&gt;
:&lt;math&gt;Q_2 : = {\dot q}&lt;/math&gt;

and by using the definition of the conjugate momentum,

:&lt;math&gt;P_1 : = \frac{dL}{d{\dot q}} - \frac{d}{dt} \frac{dL}{d{\ddot q}}&lt;/math&gt;
:&lt;math&gt;P_2 : =  \frac{dL}{d{\ddot q}} &lt;/math&gt;

Due to non-degeneracy, we can write &lt;math&gt; {\ddot q}&lt;/math&gt; as &lt;math&gt;{\ddot q} = a(Q_1, Q_2, P_2)&lt;/math&gt;. Note that only ''three'' arguments are needed since the Lagrangian itself only has three free parameters. By Legendre transforming, we find the Hamiltonian to be

:&lt;math&gt;H = P_1 Q_2 - P_2  a(Q_1, Q_2, P_2) - L &lt;/math&gt;

We now notice that the Hamiltonian is linear in &lt;math&gt;P_1&lt;/math&gt;. This is Ostrogradsky's instability, and it stems from the fact that the Lagrangian depends on fewer coordinates than there are canonical coordinates (which correspond to the initial parameters needed to specify the problem). The extension to higher dimensional systems is analogous, and the extension to higher derivatives simply means that the phase space is of even higher dimension than the configuration space, which exacerbates the instability (since the Hamiltonian is linear in even more canonical coordinates).

==Notes==
{{Reflist}}

[[Category:Lagrangian mechanics]]
[[Category:Hamiltonian mechanics]]
[[Category:Calculus of variations]]
[[Category:Mathematical physics]]</text>
      <sha1>878wm0vss5wccsssopjxanikzpkde10</sha1>
    </revision>
  </page>
  <page>
    <title>Pentagram map</title>
    <ns>0</ns>
    <id>26179254</id>
    <revision>
      <id>855924645</id>
      <parentid>855917839</parentid>
      <timestamp>2018-08-21T18:55:49Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="40768">In [[mathematics]], the '''pentagram map''' is a discrete [[dynamical system]] on the [[moduli space]] of [[polygons]] in the [[projective plane]]. The [[pentagram]] map takes a given polygon, finds the intersections of the shortest [[diagonal]]s of the polygon, and constructs a new polygon from these intersections. [[Richard Schwartz (mathematician)|Richard Schwartz]] introduced the pentagram map for a general polygon in a 1992 paper &lt;ref name=SCH1&gt;{{cite journal|title =The Pentagram Map|url =http://projecteuclid.org/euclid.em/1048709118|author =Schwartz, Richard Evan |journal=[[Experimental Mathematics (journal)|Experimental Math]] |year=1992 |volume=1|pages=90–95}}&lt;/ref&gt; though it seems that the special case, in which the map is defined for [[pentagons]] only, goes back to an 1871 paper of [[Alfred Clebsch]]&lt;ref name = CLE&gt;{{cite journal|title=Ueber das ebene Funfeck|journal = Mathematische Annalen|volume=4|year = 1871|pages= 476–489|author=A. Clebsch|doi=10.1007/bf01455078}}&lt;/ref&gt; and a 1945 paper of [[Theodore Motzkin]].&lt;ref name=MOT&gt;{{cite journal|doi=10.1090/S0002-9904-1945-08488-2|title=The pentagon in the projective plane, with a comment on Napier's rule|journal=[[Bulletin of the American Mathematical Society]]|volume=51|issue=12|year=1945|pages=985–989|author=Th. Motzkin|authorlink=Theodore Motzkin}}&lt;/ref&gt; The pentagram map is similar in spirit to the constructions underlying [[Desargues' theorem]] and [[Poncelet's porism]]. It echoes the rationale and construction underlying a conjecture of [[Branko Grünbaum]] concerning the diagonals of a polygon. &lt;ref name=ZAK&gt;{{cite journal|title = On the products of cross-ratios on diagonals of polygons|author= Zaks, Joseph|url=http://www.springerlink.com/content/p592345k82444x61/|journal=[[Geometriae Dedicata]] |volume=60 |number=2 |pages=145–151 |doi=10.1007/BF00160619 |accessdate= 2010-02-12}}&lt;/ref&gt;

==Definition of the map==

===Basic construction===
Suppose that the [[vertex (geometry)|vertices]] of the [[polygon]] P are given by &lt;math&gt; P_1,P_3,P_5,\ldots &lt;/math&gt; The image of ''P'' under the pentagram map is the polygon ''Q'' with vertices &lt;math&gt; Q_2,Q_4,Q_6,\ldots&lt;/math&gt; as shown in the figure. Here &lt;math&gt; Q_4 &lt;/math&gt; is the intersection of the diagonals &lt;math&gt; (P_1P_5)&lt;/math&gt; and &lt;math&gt;(P_3P_7) &lt;/math&gt;, and so on.
[[File:penga3.svg|border|right|300px|test]]

On a basic level, one can think of the pentagram map as an operation defined on [[convex set|convex]] polygons in the [[Plane (geometry)|plane]]. From a more sophisticated point of view, the pentagram map is defined for a polygon contained in the [[projective plane]] over a [[Field (mathematics)|field]] provided that the [[vertex (geometry)|vertices]] are in sufficiently [[general position]]. The pentagram map [[Commutative property|commutes]] with [[projective transformations]] and thereby induces a [[Map (mathematics)|mapping]] on the [[moduli space]] of projective [[equivalence classes]] of polygons.

===Labeling conventions===

The map &lt;math&gt; P \to Q &lt;/math&gt; is slightly problematic, in the sense that the indices of the ''P''-vertices are naturally odd integers whereas the indices of ''Q''-vertices are naturally even integers. A more conventional approach to the labeling would be to label the vertices of P and Q by integers of the same parity. One can arrange this either by adding or subtracting 1 from each of the indices of the ''Q''-vertices. Either choice is equally canonical. An even more conventional choice would be to label the vertices of ''P'' and ''Q'' by consecutive integers, but again there are two natural choices for how to align these labellings: Either &lt;math&gt; Q_k &lt;/math&gt; is just clockwise from &lt;math&gt; P_k &lt;/math&gt; or just counterclockwise. In most papers on the subject, some choice is made once and for all at the beginning of the paper and then the formulas are tuned to that choice.

There is a perfectly natural way to label the vertices of the second iterate of the pentagram map by consecutive integers. For this reason, the second iterate of the pentagram map is more naturally considered as an iteration defined on labeled polygons. See the figure.
[[File:Penta8.svg|border|right|300px]]

===Twisted polygons===

The pentagram map is also defined on the larger space of twisted polygons.&lt;ref name=SCH2/&gt;

A twisted ''N''-gon is a bi-infinite sequence of points in the projective plane that is ''N''-periodic modulo a [[projective transformation]] That is, some projective transformation ''M'' carries &lt;math&gt; P_k &lt;/math&gt; to &lt;math&gt; P_{N+k} &lt;/math&gt; for all ''k''. The map ''M'' is called the [[monodromy]] of the twisted ''N''-gon. When ''M'' is the identity, a twisted ''N''-gon can be interpreted as an ordinary ''N''-gon whose vertices have been listed out repeatedly. Thus, a twisted ''N''-gon is a generalization of an ordinary ''N''-gon.

Two twisted ''N''-gons are equivalent if a projective transformation carries one to the other. The moduli space of twisted ''N''-gons is the set of equivalence classes of twisted ''N''-gons. The space of twisted ''N''-gons contains the space of ordinary ''N''-gons as a sub-variety of co-dimension 8.&lt;ref name=SCH2/&gt;&lt;ref name=OST1/&gt;

==Elementary properties==

===Action on pentagons and hexagons===
The pentagram map is the identity on the moduli space of [[pentagon]]s.&lt;ref name=SCH1/&gt;&lt;ref name = CLE/&gt;&lt;ref name=MOT/&gt; This is to say that there is always a [[projective transformation]] carrying a pentagon to its image under the pentagram map.

The map &lt;math&gt;T^2&lt;/math&gt; is the identity on the space of labeled [[hexagon]]s.&lt;ref name=SCH1/&gt; Here ''T'' is the second iterate of the pentagram map, which acts naturally on labeled hexagons, as described above. This is to say that the hexagons &lt;math&gt; H &lt;/math&gt; and &lt;math&gt; T^2(H) &lt;/math&gt; are equivalent by a label-preserving [[projective transformation]]. More precisely, the hexagons &lt;math&gt; H' &lt;/math&gt; and &lt;math&gt; T(H) &lt;/math&gt; are projectively equivalent, where &lt;math&gt; H' &lt;/math&gt; is the labeled hexagon obtained from &lt;math&gt; H &lt;/math&gt; by shifting the labels by 3. &lt;ref name=SCH1/&gt; See the figure. It seems entirely possible that this fact was also known in the 19th century.
[[File:penta hexagon.svg|border|right|300px]]

The action of the pentagram map on pentagons and hexagons is similar in spirit to classical configuration theorems in projective geometry such as [[Pascal's theorem]], [[Desargues's theorem]] and others. &lt;ref&gt;{{cite arXiv|title = Elementary Surprises in Projective Geometry|first1= Richard Evan |last1=Schwartz |first2=Serge |last2=Tabachnikov|authorlink2=Sergei Tabachnikov |date=October 2009|eprint=0910.1952}}&lt;/ref&gt;

===Exponential shrinking===

The iterates of the pentagram map shrink any [[convex polygon]] exponentially fast to a point. &lt;ref name=SCH1/&gt; This is to say that the diameter of the nth iterate of a convex polygon is less than &lt;math&gt; K a^n &lt;/math&gt; for constants &lt;math&gt; K&gt;0 &lt;/math&gt; and &lt;math&gt; 0&lt;a&lt;1 &lt;/math&gt; which depend on the initial polygon. Here we are taking about the geometric action on the polygons themselves, not on the moduli space of projective equivalence classes of polygons.

==Motivating discussion==
This section is meant to give a non-technical overview for much of the remainder of the article. The context for the pentagram map is [[projective geometry]]. Projective geometry is the geometry of our vision. When one looks at the top of a glass, which is a [[circle]], one typically sees an [[ellipse]]. When one looks at a [[rectangular]] door, one sees a typically non-rectangular [[quadrilateral]]. [[Projective transformations]] convert between the various shapes one can see when looking at same object from different points of view. This is why it plays such an important role in old topics like [[perspective drawing]] and new ones like [[computer vision]]. Projective geometry is built around the fact that a straight [[line (geometry)|line]] looks like a straight line from any perspective. The straight lines are the building blocks for the subject. The pentagram map is defined entirely in terms of points and straight lines. This makes it adapted to projective geometry. If you look at the pentagram map from another point of view (''i.e.'', you tilt the paper on which it is drawn) then you are still looking at the pentagram map. This explains the statement that the pentagram map commutes with projective transformations.

The pentagram map is fruitfully considered as a [[Map (mathematics)|mapping]] on the moduli space of [[polygons]]. A [[moduli space]] is an auxiliary space whose points index other objects. For example, in [[Euclidean geometry]], the sum of the angles of a [[triangle]] is always 180 degrees. You can specify a [[triangle]] (up to scale) by giving 3 positive numbers, &lt;math&gt; x,y,z &lt;/math&gt; such that &lt;math&gt; x+y+z =180. &lt;/math&gt; So, each point &lt;math&gt; (x,y,z) &lt;/math&gt;, satisfying the constraints just mentioned, indexes a triangle (up to scale). One might say that &lt;math&gt; (x,y,z) &lt;/math&gt; are coordinates for the moduli space of scale equivalence classes of triangles. If you want to index all possible quadrilaterals, either up to scale or not, you would need some additional [[parameters]]. This would lead to a [[higher-dimensional]] moduli space. The moduli space relevant to the pentagram map is the moduli space of projective equivalence classes of polygons. Each point in this space corresponds to a polygon, except that two polygons which are different views of each other are considered the same. Since the pentagram map is adapted to projective geometry, as mentioned above, it induces a [[Map (mathematics)|mapping]] on this particular moduli space. That is, given any point in the moduli space, you can apply the pentagram map to the corresponding polygon and see what new point you get.

The reason for considering what the pentagram map does to the moduli space is that it gives more salient features of the map. If you just watch, geometrically, what happens to an individual polygon, say a [[convex polygon]], then repeated application shrinks the polygon to a point.&lt;ref name=SCH1/&gt; To see things more clearly, you might dilate the shrinking family of polygons so that they all have, say, the same [[area]]. If you do this, then typically you will see that the family of polygons gets long and thin.&lt;ref name=SCH1/&gt; Now you can change the [[aspect ratio]] so as to try to get yet a better view of these polygons. If you do this process as systematically as possible, you find that you are simply looking at what happens to points in the moduli space. The attempts to zoom in to the picture in the most perceptive possible way lead to the introduction of the moduli space.

To explain how the pentagram map acts on the moduli space, one must say a few words about the [[torus]]. One way to roughly define the torus is to say that it is the surface of an idealized [[donut]]. Another way is that it is the playing field for the [[Asteroids (video game)|Asteroids]] video game. Yet another way to describe the torus is to say that it is a computer screen with wrap, both left-to-right and up-to-down. The [[torus]] is a classical example of what is known in mathematics as a [[manifold]]. This is a space that looks somewhat like ordinary [[Euclidean space]] at each point, but somehow is hooked together differently. A [[sphere]] is another example of a manifold. This is why it took people so long to figure out that the [[Earth]] was not flat; on small scales one cannot easily distinguish a sphere from a [[Plane (geometry)|plane]]. So, too, with manifolds like the torus. There are higher-dimensional tori as well. You could imagine playing Asteroids in your room, where you can freely go through the walls and ceiling/floor, popping out on the opposite side.

One can do experiments with the pentagram map, where one looks at how this mapping acts on the moduli space of polygons. One starts with a point and just traces what happens to it as the map is applied over and over again. One sees a surprising thing: These points seem to line up along multi-dimensional tori.&lt;ref name=SCH1/&gt; These invisible tori fill up the moduli space somewhat like the way the layers of an onion fill up the onion itself, or how the individual cards in a deck fill up the deck. The technical statement is that the tori make a [[foliation]] of the moduli space. The tori have half the dimension of the moduli space. For instance, the moduli space of &lt;math&gt; 7 &lt;/math&gt;-gons is &lt;math&gt; 6 &lt;/math&gt; dimensional and the tori in this case are &lt;math&gt; 3 &lt;/math&gt; dimensional.

The tori are invisible [[subset]]s of the moduli space. They are only revealed when one does the pentagram map and watches a point move round and round, filling up one of the tori. Roughly speaking, when [[dynamical systems]] have these invariant tori, they are called [[integrable system]]s. Most of the results in this article have to do with establishing that the pentagram map is an integrable system, that these tori really exist. The monodromy invariants, discussed below, turn out to be the equations for the tori. The Poisson bracket, discussed below, is a more sophisticated math gadget that sort of encodes the local geometry of the tori. What is nice is that the various objects fit together exactly, and together add up to a proof that this torus motion really exists.

==Coordinates for the moduli space==

===Cross-ratio===
When the field underlying all the constructions is ''F'', the [[affine line]] is just a copy of ''F''. The affine line is a subset of the [[projective line]]. Any finite list of points in the projective line can be moved into the affine line by a suitable [[projective transformation]].

Given the four points &lt;math&gt; t_1,t_2,t_3,t_4 &lt;/math&gt; in the affine line one defines the (inverse) [[cross ratio]]

: &lt;math&gt; X=\frac{(t_1 - t_2)(t_3 - t_4)}{(t_1 - t_3)(t_2 - t_4)}. &lt;/math&gt;

Most authors consider 1/''X'' to be the [[cross-ratio]], and that is why ''X'' is called the inverse cross ratio. The inverse cross ratio is invariant under projective transformations and thus makes sense for points in the projective line. However, the formula above only makes sense for points in the affine line.

In the slightly more general set-up below, the cross ratio makes sense for any four collinear points in [[projective space]] One just identifies the line containing the points with the projective line by a suitable [[projective transformation]] and then uses the formula above. The result is independent of any choices made in the identification. The inverse cross ratio is used in order to define a coordinate system on the moduli space of polygons, both ordinary and twisted.

===The corner coordinates===

The corner invariants are basic coordinates on the space of twisted polygons.&lt;ref name=SCH2/&gt;&lt;ref name=OST1/&gt;&lt;ref name = ST1/&gt; Suppose that P is a [[polygon]]. A [[Flag (geometry)|flag]] of ''P'' is a pair (''p'',''L''), where ''p'' is a vertex of ''P'' and ''L'' is an adjacent line of ''P''. Each vertex of ''P'' is involved in two flags, and likewise each edge of ''P'' is involved in two flags. The flags of ''P'' are ordered according to the orientation of ''P'', as shown in the figure. In this figure, a flag is represented by a thick arrow. Thus, there are 2''N'' flags associated to an N-gon.

[[File:Penta flag2.svg|border|right|300px]]
[[File:Penta corner7.svg|border|right|300px]]

Let ''P'' be an ''N''-gon, with flags &lt;math&gt; F_1,\ldots,F_{2N} &lt;/math&gt; To each flag F, we associate the inverse cross ratio of the points &lt;math&gt; t_1,t_2,t_3,t_4&lt;/math&gt; shown in the figure at left. In this way, one associates numbers &lt;math&gt; x_1,\ldots,x_{2n} &lt;/math&gt; to an n-gon. If two n-gons are related by a projective transformation, they get the same coordinates. Sometimes the variables &lt;math&gt; x_1,y_1,x_2,y_2,\ldots &lt;/math&gt; are used in place of &lt;math&gt; x_1,x_2,x_3,x_4,\ldots\,. &lt;/math&gt;

The corner invariants make sense on the moduli space of twisted polygons. When one defines the corner invariants of a twisted polygon, one obtains a 2''N''-periodic bi-infinite sequence of numbers. Taking one period of this sequence identifies a twisted ''N''-gon with a point in &lt;math&gt; F^{2N} &lt;/math&gt; where ''F'' is the underlying field. Conversely, given almost any (in the sense of [[measure theory]]) point in &lt;math&gt; F^{2N} &lt;/math&gt; one can construct a twisted ''N''-gon having this list of corner invariants. Such a list will not always give rise to an ordinary polygon; there are an additional 8 equations which the list must satisfy for it to give rise to an ordinary ''N''-gon.

===(ab) coordinates===

There is a second set of coordinates for the moduli space of twisted polygons, developed by [[Sergei Tabachnikov]] and Valentin Ovsienko. &lt;ref name=OST1&gt;{{cite journal|title = The Pentagram Map, A Discrete Integrable System|first1=Valentin |last1=Ovsienko |first2=Richard Evan |last2=Schwartz |first3=Serge |last3=Tabachnikov |url=http://math.univ-lyon1.fr/~ovsienko/Publis/Penta.pdf |format=pdf |journal=Comm. Math. Phys. |volume=299 |year=2010 |issue=2 |pages=409–446 |accessdate=June 26, 2011|bibcode=2010CMaPh.299..409O |doi=10.1007/s00220-010-1075-y |arxiv=0810.5605 }}&lt;/ref&gt; One describes a polygon in the [[projective plane]] by a sequence of vectors &lt;math&gt; \ldots V_1,V_2,V_3,\ldots &lt;/math&gt; in &lt;math&gt; R^3 &lt;/math&gt; so that each consecutive triple of vectors spans a [[parallelopiped]] having unit volume. This leads to the relation

: &lt;math&gt; V_{i+3} = a_i V_{i+2} + b_i V_{i+1} + V_i &lt;/math&gt;

The coordinates &lt;math&gt; a_1,b_1,a_2,b_2,\ldots &lt;/math&gt; serve as coordinates for the moduli space of twisted ''N''-gons as long as ''N'' is not divisible by&amp;nbsp;3.

The (ab) coordinates bring out the close analogy between twisted polygons and solutions of 3rd order linear [[ordinary differential equations]], normalized to have unit [[Wronskian]].

==Formula for the pentagram map==

===As a birational mapping ===
Here is a formula for the pentagram map, expressed in corner coordinates.&lt;ref name=SCH2/&gt; The equations work more gracefully when one considers the second iterate of the pentagram map, thanks to the canonical labelling scheme discussed above. The second iterate of the pentagram map is the [[function composition|composition]] &lt;math&gt; B \circ A&lt;/math&gt;. The maps &lt;math&gt; A &lt;/math&gt; and &lt;math&gt; B &lt;/math&gt; are [[birational mapping]]s of order 2, and have the following action.
:&lt;math&gt; A(x_1,\ldots,x_{2N})=(a_1,\ldots,a_{2N}) &lt;/math&gt;
:&lt;math&gt; B(x_1,\ldots,x_{2N})=(b_1,\ldots,b_{2N}) &lt;/math&gt;
where
:&lt;math&gt;
\begin{align}
a_{2k-1} &amp; = \frac{(1-x_{2k+1}x_{2k+2})}{(1-x_{2k-3}x_{2k-2})} x_{2k+0} \\[4pt]
a_{2k+0} &amp; = \frac{(1-x_{2k-3}x_{2k-2})}{(1-x_{2k+1}x_{2k+2})} x_{2k-1} \\[4pt]
b_{2k+1} &amp; =\frac{(1-x_{2k-2}x_{2k-1})}{(1-x_{2k+2}x_{2k+3})} x_{2k+0} \\[4pt]
b_{2k+0} &amp; = \frac{(1-x_{2k+2}x_{2k+3})}{(1-x_{2k-2}x_{2k-1})} x_{2k-1}
\end{align}
&lt;/math&gt;

(Note: the index 2''k''&amp;nbsp;+&amp;nbsp;0 is just&amp;nbsp;2''k''. The 0 is added to align the formulas.) In these coordinates, the pentagram map is a birational mapping of &lt;math&gt; F^{2N} &lt;/math&gt;

===As grid compatibility relations===

[[File:penta relations2.svg|border|300px|right]]
The formula for the pentagram map has a convenient interpretation as a certain compatibility rule for labelings on the [[edge (geometry)|edges]] of triangular grid, as shown in the figure.&lt;ref name=SCH2/&gt; In this interpretation, the corner invariants of a polygon P label the non-horizontal edges of a single row, and then the non-horizontal edges of subsequent rows are labeled by the corner invariants of &lt;math&gt; A(P) &lt;/math&gt;, &lt;math&gt;B(A(P))&lt;/math&gt;, &lt;math&gt; A(B(A(P))) &lt;/math&gt;, and so forth. the compatibility rules are
:&lt;math&gt; c=1-ab&lt;/math&gt;
:&lt;math&gt; wx=yz&lt;/math&gt;
These rules are meant to hold for all configurations which are [[isometry|congruent]] to the ones shown in the figure. In other words, the figures involved in the relations can be in all possible positions and orientations. The labels on the horizontal edges are simply auxiliary variables introduced to make the formulas simpler. Once a single row of non-horizontal edges is provided, the remaining rows are uniquely determined by the compatibility rules. 
==Invariant structures==

===Corner coordinate products===

It follows directly from the formula for the pentagram map, in terms of corner coordinates, that the two quantities
:&lt;math&gt; O_N= x_1x_3\cdots x_{2N-1} &lt;/math&gt;
:&lt;math&gt; E_N = x_2x_4\cdots x_{2N} &lt;/math&gt;
are invariant under the pentagram map. This observation is closely related to the 1991 paper of Joseph Zaks &lt;ref name=ZAK/&gt; concerning the diagonals of a polygon.

When ''N''&amp;nbsp;=&amp;nbsp;2''k'' is even, the functions
:&lt;math&gt; O_k = x_1x_5x_9 \cdots x_{2N-3}+ x_3x_7x_{11} \cdots x_{2N-1}&lt;/math&gt;
:&lt;math&gt; E_k = x_2x_6x_{10} \cdots x_{2N-2}+ x_4x_8x_{12} \cdots x_{2N}&lt;/math&gt;
are likewise seen, directly from the formula, to be invariant functions. All these products turn out to be [[Casimir invariant]]s with respect to the invariant Poisson bracket discussed below. At the same time, the functions &lt;math&gt; O_k &lt;/math&gt; and &lt;math&gt; E_k &lt;/math&gt; are the simplest examples of the monodromy invariants defined below.

The [[level set]]s of the function &lt;math&gt; f=O_NE_N &lt;/math&gt; are [[Compact space|compact]], when f is restricted to the moduli space of real [[convex polygon]]s. &lt;ref name=SCH1/&gt; Hence, each orbit of the pentagram map acting on this space has a [[Compact space|compact]] [[Closure (mathematics)|closure]].

===Volume form===

The pentagram map, when acting on the moduli space ''X'' of convex polygons, has an invariant [[volume form]]. &lt;ref name=SCH3&gt;{{cite journal|title =Recurrence of the Pentagram Map|url =http://www.expmath.org/expmath/volumes/10/10.4/Schwartz.pdf|author =Schwartz, Richard Evan |journal=Experimental Math |format=pdf |year=2001 |volume=10 | issue = 4 |pages=519–528 |accessdate=June 30, 2011 |doi=10.1080/10586458.2001.10504671}}&lt;/ref&gt; At the same time, as was already mentioned, the function &lt;math&gt;f=O_NE_N &lt;/math&gt; has [[Compact space|compact]] [[level sets]] on ''X''. These two properties combine with the [[Poincaré recurrence theorem]] to imply that the action of the pentagram map on ''X'' is recurrent: The orbit of almost any equivalence class of convex polygon ''P'' returns infinitely often to every neighborhood of ''P''.&lt;ref name=SCH3/&gt; This is to say that, modulo projective transformations, one typically sees nearly the same shape, over and over again, as one iterates the pentagram map. (It is important to remember that one is considering the projective equivalence classes of convex polygons. The fact that the pentagram map visibly shrinks a convex polygon is irrelevant.)

It is worth mentioning that the recurrence result is subsumed by the complete integrability results discussed below.&lt;ref name=OST1/&gt;&lt;ref name=SOL/&gt;

===Monodromy invariants===

The so-called monodromy invariants are a collection of [[Function (mathematics)|functions]] on the [[moduli space]] that are invariant under the pentagram map. &lt;ref name=SCH2&gt;{{cite journal|title = Discrete monodromy, pentagrams, and the method of condensation|author= Schwartz, Richard Evan|journal= journal of Fixed Point Theory and Applications (2008)|url= http://www.springerlink.com/content/627311749037p274/|accessdate= 2010-02-12|doi=10.1007/s11784-008-0079-0|volume=3|pages=379–409|arxiv=0709.1264}}&lt;/ref&gt;

With a view towards defining the monodromy invariants, say that a block is either a single integer or a triple of consecutive integers, for instance 1 and 567. Say that a block is odd if it starts with an odd integer. Say that two blocks are well-separated if they have at least 3 integers between them. For instance 123 and 567 are not well separated but 123 and 789 are well separated. Say that an odd admissible sequence is a finite sequence of integers that decomposes into well separated odd blocks. When we take these sequences from the set 1,&amp;nbsp;...,&amp;nbsp;2''N'', the notion of well separation is meant in the cyclic sense. Thus, 1 and 2''N''&amp;nbsp;−&amp;nbsp;1 are not well separated.

Each odd admissible sequence gives rise to a [[monomial]] in the corner invariants. This is best illustrated by example
*1567 gives rise to &lt;math&gt; - x_1x_5x_6x_7 &lt;/math&gt;
*123789 gives rise to &lt;math&gt; + x_1x_2x_3x_7x_8x_9 &lt;/math&gt;
The sign is determined by the [[Parity (mathematics)|parity]] of the number of single-digit blocks in the sequence. The monodromy invariant &lt;math&gt; O_k &lt;/math&gt; is defined as the sum of all monomials coming from odd admissible sequences composed of k blocks. The monodromy invariant &lt;math&gt; E_k &lt;/math&gt; is defined the same way, with even replacing odd in the definition.

When ''N'' is odd, the allowable values of ''k'' are 1,&amp;nbsp;2,&amp;nbsp;...,&amp;nbsp;(''n''&amp;nbsp;&amp;minus;&amp;nbsp;1)/2. When ''N'' is even, the allowable values of k are 1,&amp;nbsp;2,&amp;nbsp;...,&amp;nbsp;''n''/2. When ''k''&amp;nbsp;=&amp;nbsp;''n''/2, one recovers the product invariants discussed above. In both cases, the invariants &lt;math&gt; O_N &lt;/math&gt; and &lt;math&gt; E_N &lt;/math&gt; are counted as monodromy invariants, even though they are not produced by the above construction.

The monodromy invariants are defined on the space of twisted polygons, and restrict to give invariants on the space of closed polygons. They have the following geometric interpretation. The monodromy M of a twisted polygon is a certain [[rational function]] in the corner coordinates. The monodromy invariants are essentially the homogeneous parts of the [[Trace (linear algebra)|trace]] of&amp;nbsp;''M''. There is also a description of the monodromy invariants in terms of the (ab) coordinates. In these coordinates, the invariants arise as certain [[determinants]] of 4-diagonal [[matrix (mathematics)|matrices]]. &lt;ref name=OST1/&gt;&lt;ref name=ST1/&gt;

Whenever ''P'' has all its vertices on a [[conic section]] (such as a circle) one has &lt;math&gt;O_k(P)=E_k(P)&lt;/math&gt; for all&amp;nbsp;''k''. &lt;ref name=ST1&gt;{{cite journal|title= The pentagram integrals for inscribed polygons|arxiv= 1004.4311|first1= Richard Evan |last1=Schwartz |first2=Sergei |last2=Tabachnikov|journal=[[Electronic Journal of Combinatorics]] |date=October 2009 |bibcode=2010arXiv1004.4311S}} &lt;/ref&gt;

===Poisson bracket===

A [[Poisson bracket]] is an anti-symmetric [[linear]] operator &lt;math&gt; \{\cdot,\cdot\} &lt;/math&gt; on the space of functions which satisfies the [[Derivation (abstract algebra)|Leibniz Identity]] and the [[Jacobi identity]]. In a 2010 paper,&lt;ref name=OST1/&gt; Valentin Ovsienko, Richard Schwartz and Sergei Tabachnikov produced a [[Poisson bracket]] on the space of twisted polygons which is invariant under the pentagram map. They also showed that monodromy invariants commute with respect to this bracket. This is to say that

:&lt;math&gt; \{O_i,O_j\}=\{O_i,E_j\}=\{E_i,E_j\}=0 &lt;/math&gt;

for all indices.

Here is a description of the invariant Poisson bracket in terms of the variables.
: &lt;math&gt; x_1,y_1,x_2,y_2,\ldots\,. &lt;/math&gt;
: &lt;math&gt;\{x_i,x_{i+1}\} = -x_i\, x_{i+1}&lt;/math&gt;
: &lt;math&gt;\{x_i, x_{i-1}\} = x_i\, x_{i-1}&lt;/math&gt;
: &lt;math&gt;\{y_i,y_{i+1}\} = y_i\, y_{i+1}&lt;/math&gt;
: &lt;math&gt;\{y_i,y_{i-1}\} = -y_i\, y_{i-1}&lt;/math&gt;
: &lt;math&gt;\{x_i,x_j\} = \{y_i,y_j\} = \{x_i,y_j\} = 0 &lt;/math&gt; for all other &lt;math&gt; i,j.&lt;/math&gt;
There is also a description in terms of the (ab) coordinates, but it is more complicated.&lt;ref name=OST1/&gt;

Here is an alternate description of the invariant bracket. Given any function &lt;math&gt; f &lt;/math&gt; on the moduli space, we have the so-called [[Hamiltonian vector field]]

: &lt;math&gt; H(f) = \left( x_{i+1} \frac{\partial f}{\partial x_{i+1}} - x_{i-1} \frac{\partial f}{\partial x_{i-1}} \right) x_i \frac{\partial}{\partial x_i} + \left( y_{i-1} \frac{\partial f}{\partial y_{i-1}} - y_{i+1} \frac{\partial f}{\partial y_{i+1}} \right) y_i \frac{\partial}{\partial y_i} &lt;/math&gt;

where a summation over the repeated indices is understood. Then

:&lt;math&gt; H(f) g = \{f,g\} &lt;/math&gt;

The first expression is the [[directional derivative]] of &lt;math&gt; g &lt;/math&gt; in the direction of the vector field &lt;math&gt; H(f) &lt;/math&gt;. In practical terms, the fact that the monodromy invariants Poisson-commute means that the corresponding Hamiltonian [[vector field]]s define commuting flows.

==Complete integrability==

===Arnold–Liouville integrability===

The monodromy invariants and the invariant bracket combine to establish Arnold–Liouville integrability of the pentagram map on the space of twisted ''N''-gons. &lt;ref name=OST1/&gt; The situation is easier to describe for N odd. In this case, the two products
: &lt;math&gt; O_n =x_1\cdots x_n &lt;/math&gt;
: &lt;math&gt; E_n = y_1\cdots y_n &lt;/math&gt;
are [[Casimir invariant]]s for the bracket, meaning (in this context) that
: &lt;math&gt; \{O_n,f\}=\{E_n,f\} =0 &lt;/math&gt;
for all functions f. A Casimir [[level set]] is the set of all points in the space having a specified value for both &lt;math&gt; O_n &lt;/math&gt; and &lt;math&gt; E_n &lt;/math&gt;.

Each Casimir level set has an iso-monodromy [[foliation]], namely, a decomposition into the common level sets of the remaining monodromy functions. The Hamiltonian vector fields associated to the remaining monodromy invariants generically span the tangent distribution to the iso-monodromy foliation. The fact that the monodromy invariants Poisson-commute means that these vector fields define commuting flows. These flows in turn define local [[coordinate charts]] on each iso-monodromy level such that the transition maps are Euclidean translations. That is, the Hamiltonian vector fields impart a flat Euclidean structure on the iso-monodromy levels, forcing them to be flat tori when they are [[Smooth manifold|smooth]] and [[compact space|compact]] [[manifolds]]. This happens for almost every level set. Since everything in sight is pentagram-invariant, the pentagram map, restricted to an iso-monodromy leaf, must be a translation. This kind of motion is known as [[quasi-periodic motion]]. This explains the Arnold-Liouville integrability.

From the point of view of [[symplectic geometry]], the Poisson bracket gives rise to a [[symplectic form]] on each Casimir level set.

===Algebro-geometric integrability===

In a 2011 preprint, &lt;ref name=SOL&gt;{{cite arXiv|title = Integrability of the Pentagram Map|eprint = 1106.3950|author=Soloviev, Fedor |year=2011}}&lt;/ref&gt; Fedor Soloviev showed that the pentagram map has a [[Lax representation]] with a spectral parameter, and proved its algebraic-geometric integrability. This means that the space of polygons (either twisted or ordinary) is parametrized in terms of a spectral curve with marked points and a [[Divisor (algebraic geometry)|divisor]]. The spectral curve is determined by the monodromy invariants, and the divisor corresponds to a point on a torus—the Jacobi variety of the spectral curve. The algebraic-geometric methods guarantee that the pentagram map exhibits [[quasi-periodic motion]] on a torus (both in the twisted and the ordinary case), and they allow one to construct explicit solutions formulas using Riemann [[theta functions]] (i.e., the variables that determine the polygon as explicit functions of time). Soloviev also obtains the invariant Poisson bracket from the Krichever–Phong universal formula.

==Connections to other topics==

===The Octahedral recurrence ===

The octahedral recurrence is a dynamical system defined on the vertices of the octahedral tiling of space. Each octahedron has 6 vertices, and these vertices are labelled in such a way that
:&lt;math&gt; a_1b_1 + a_2b_2 = a_3b_3 &lt;/math&gt;
Here &lt;math&gt; a_i &lt;/math&gt; and &lt;math&gt; b_i &lt;/math&gt; are the labels of antipodal vertices. A common convention is that &lt;math&gt; a_2,b_2,a_3,b_3 &lt;/math&gt; always lie in a central horizontal plane and a_1,b_1 are the top and bottom vertices. The octahedral recurrence is closely related to [[Lewis Carroll|C. L. Dodgson's]] method of condensation for computing [[determinants]].&lt;ref name=SCH2/&gt; Typically one labels two horizontal layers of the tiling and then uses the basic rule to let the labels propagate dynamically.

Max Glick used the [[cluster algebra]] formalism to find formulas for the iterates of the pentagram map in terms of [[alternating sign matrix|alternating sign matrices]].&lt;ref name=GLI/&gt; These formulas are similar in spirit to the formulas found by [[David P. Robbins]] and Harold Rumsey for the iterates of the octahedral recurrence.

[[File:penta oct9.svg|border|450px|right]]
Alternatively, the following construction relates the octahedral recurrence directly to the pentagram map. &lt;ref name=SCH2/&gt; Let &lt;math&gt; T &lt;/math&gt; be the octahedral tiling. Let &lt;math&gt; \pi: T \to R^2 &lt;/math&gt; be the [[linear projection]] which maps each octahedron in &lt;math&gt; T &lt;/math&gt; to the configuration of 6 points shown in the first figure. Say that an adapted labeling of &lt;math&gt; T &lt;/math&gt; is a labeling so that all points in the (infinite) [[inverse image]] of any point in &lt;math&gt; G=\pi(T) &lt;/math&gt; get the same numerical label. The octahedral recurrence applied to an adapted labeling is the same as a recurrence on &lt;math&gt; G &lt;/math&gt; in which the same rule as for the octahedral recurrence is applied to every configuration of points [[isometry|congruent]] to the configuration in the first figure. Call this the planar octahedral recurrence.

[[File:penta oct10.svg|border|450px|right]]
Given a labeling of &lt;math&gt; G &lt;/math&gt; which obeys the planar octahedral recurrence, one can create a labeling of the edges of &lt;math&gt; G &lt;/math&gt; by applying the rule

: &lt;math&gt; v=AD/BC &lt;/math&gt;

to every edge. This rule refers to the figure at right and is meant to apply to every configuration that is [[isometry|congruent]] to the two shown. 
When this labeling is done, the edge-labeling of G satisfies the relations for the pentagram map.

===The Boussinesq equation===

The continuous limit of a convex polygon is a parametrized convex curve in the plane. When the time parameter is suitably chosen, the continuous limit of the pentagram map is the classical [[Boussinesq approximation (water waves)|Boussinesq equation]].&lt;ref name=SCH2/&gt;&lt;ref name=OST1/&gt; This equation is a classical example of an [[integrable]] [[partial differential equation]].

Here is a description of the geometric action of the Boussinesq equation. Given a [[locally convex]] curve &lt;math&gt; C:R-&gt;R^2 &lt;/math&gt;, and real numbers x and t, we consider the [[chord (geometry)|chord]] connecting &lt;math&gt; C(x-t) &lt;/math&gt; to &lt;math&gt; C(x+t) &lt;/math&gt;. The envelop of all these chords is a new curve &lt;math&gt; C_t(x) &lt;/math&gt;. When t is extremely small, the curve &lt;math&gt; C_t(x) &lt;/math&gt; is a good model for the time t evolution of the original curve &lt;math&gt; C_0(x) &lt;/math&gt; under the Boussinesq equation. This geometric description makes it fairly obvious that the B-equation is the continuous limit of the pentagram map. At the same time, the pentagram invariant bracket is a discretization of a well known invariant Poisson bracket associated to the Boussinesq equation. &lt;ref name=OST1/&gt;

Recently, there has been some work on higher-dimensional generalizations of the pentagram map and its connections to Boussinesq-type partial differential equations &lt;ref name=GMB&gt;{{cite journal|url=http://www.math.wisc.edu/~maribeff/pentagrammap1.pdf |title=On Generalizations of the Pentagram Map: Discretizal of AGD Flows |format=pdf|first1=Gloria Marỉ|last1= Beffa |place=Madison, Wisconsin |publisher=University of Wisconsin}}&lt;/ref&gt;

===Projectively natural evolution===

The pentagram map and the Boussinesq equation are examples of projectively natural geometric evolution equations. Such equations arise in diverse fields of mathematics, such as [[projective geometry]] and [[computer vision]]. &lt;ref&gt;{{cite journal|title=On Projective Invariant Smoothing and Evolutions of Planar Curves and Polygons|first1=Alfred M. |last1=Bruckstein |first2=Doron |last2=Shaked |url= http://www.springerlink.com/content/u364060228p51548/fulltext.pdf |format=pdf |journal=Journal of Mathematical Imaging and Vision |volume=7 |number=3 |pages=225–240 |doi=10.1023/A:1008226427785 |accessdate= 2010-02-12}}&lt;/ref&gt; &lt;ref&gt;{{cite journal|title = Differential Invariant Signatures and Flows in Computer Vision: A Symmetry Group Approach|author= [[Peter J. Olver]]; Guillermo Sapiro; [[Allen Tannenbaum]]; MINNESOTA UNIV MINNEAPOLIS DEPT OF MATHEMATICS|url= http://www.stormingmedia.us/71/7169/A716954.html|accessdate= 2010-02-12}}&lt;/ref&gt;

===Cluster algebras===

In a 2010 paper &lt;ref name=GLI&gt;*{{cite arXiv|title= The Pentagram Map and Y-Patterns|author=Glick, Max |&lt;!--journal=Advances in Mathematics--&gt; |date=2010 |eprint=1005.0598v2 }}&lt;/ref&gt; Max Glick identified the pentagram map as a special case of a [[cluster algebra]].

==See also==
* [[Combinatorics]]
* [[Periodic table of shapes]]

==Notes==
{{reflist}}

==References==
*{{cite journal|url=http://www.math.wisc.edu/~maribeff/pentagrammap1.pdf |title=On Generalizations of the Pentagram Map: Discretizal of AGD Flows |format=pdf|first1=Gloria Marỉ| last1= Beffa|place=Madison, Wisconsin |publisher=University of Wisconsin}}
*{{cite journal|title=On Projective Invariant Smoothing and Evolutions of Planar Curves and Polygons|first1=Alfred M. |last1=Bruckstein |first2=Doron |last2=Shaked |url= http://www.springerlink.com/content/u364060228p51548/fulltext.pdf |format=pdf |journal=Journal of Mathematical Imaging and Vision
|volume=7 |number=3 |pages=225–240 |doi=10.1023/A:1008226427785 |accessdate= 2010-02-12}}
*{{cite arXiv|title= The Pentagram Map and Y-Patterns|author=Glick, Max |&lt;!--journal=Advances in Mathematics--&gt; |date=2010 |eprint=1005.0598v2 }}
*{{cite journal|doi=10.1090/S0002-9904-1945-08488-2|title=The pentagon in the projective plane, with a comment on Napier's rule|journal=Bull. Amer. Math. Soc.|volume=51|issue=12|year=1945|pages=985–989|author=Motzkin, Theodore|authorlink=Theodore Motzkin}}
*{{cite journal|title = Differential Invariant Signatures and Flows in Computer Vision: A Symmetry Group Approach|first1= Peter J. |last1=Olver |first2=Guillermo |last2=Sapiro |first3=Allen |last3=Tannenbaum|author3-link=Allen Tannenbaum |publisher=Minnesota University Minneapolis Department of Mathematics|url= http://www.stormingmedia.us/71/7169/A716954.html|year=1993|accessdate= 2010-02-12}}
*{{cite journal|title = Discrete integrable systems in projective geometry|first1=Valentin |last1=Ovsienko |first2=Serge |last2=Tabachnikov |url= http://www.birs.ca/workshops/2008/08rit125/report08rit125.pdf|accessdate= 2010-02-12}}
*{{cite journal|title = The Pentagram Map, A Discrete Integrable System|first1=Valentin |last1=Ovsienko |first2=Richard Evan |last2=Schwartz |first3=Serge |last3=Tabachnikov |url=http://math.univ-lyon1.fr/~ovsienko/Publis/Penta.pdf |format=pdf |journal=Comm. Math. Phys. |volume=299 |year=2010 |issue=2 |pages=409–446 |accessdate=June 26, 2011|bibcode=2010CMaPh.299..409O |doi=10.1007/s00220-010-1075-y |arxiv=0810.5605 }}
*{{cite journal|title =Quasiperiodic Motion for the Pentagram Map |url =http://aimsciences.org/journals/pdfs.jsp?paperID=4031&amp;mode=full|format=pdf |first1=Valentin |last1=Ovsienko |first2=Richard Evan |last2=Schwartz |first3=Serge |last3=Tabachnikov|journal=Electron. Res. Announc. Math. Sci. |volume=16 |year=2009 |pages=1–8 |doi=10.3934/era.2009.16.1|arxiv=0901.1585 }}
*{{cite journal|title =The Pentagram Map|url =https://eudml.org/doc/228847|author =Schwartz, Richard Evan |journal=Experimental Math |year=1992 |volume=1|pages=90–95}}
*{{cite journal|title =Recurrence of the Pentagram Map|url =http://www.expmath.org/expmath/volumes/10/10.4/Schwartz.pdf|author =Schwartz, Richard Evan |journal=Experimental Math |format=pdf |year=2001 |volume=10 | issue = 4 |pages=519–528 |accessdate=June 30, 2011 |doi=10.1080/10586458.2001.10504671}}
*{{cite journal|title = Discrete monodromy, pentagrams, and the method of condensation|author=Schwartz, Richard Evan |journal=
Journal of Fixed Point Theory and Applications |year=2008|url=http://www.springerlink.com/content/627311749037p274/|accessdate= 2010-02-12|doi=10.1007/s11784-008-0079-0|volume=3|pages=379–409|arxiv=0709.1264}}
*{{cite journal|title= The pentagram integrals for inscribed polygons|arxiv= 1004.4311|first1=Richard Evan |last1=Schwartz |first2=Serge |last2=Tabachnikov|journal=Electronic Journal of Combinatorics |bibcode=2010arXiv1004.4311S}}
*{{cite arXiv|title = Elementary Surprises in Projective Geometry|first1=Richard Evan |last1=Schwartz |first2=Serge |last2=Tabachnikov |eprint=0910.1952 |date=2009}}
*{{cite arXiv|title = Integrability of the Pentagram Map|eprint = 1106.3950|author=Soloviev, Fedor |year=2011}}
*{{cite journal|title = On the products of cross-ratios on diagonals of polygons|author= Zaks, Joseph|url=http://www.springerlink.com/content/p592345k82444x61/|journal=[[Geometriae Dedicata]] |volume=60 |number=2 |pages=145–151 |doi=10.1007/BF00160619 |accessdate= 2010-02-12}}

[[Category:Projective geometry]]
[[Category:Dynamical systems]]</text>
      <sha1>qi7lclx7ofib26spp8or14mc6q3ma9z</sha1>
    </revision>
  </page>
  <page>
    <title>Process-data diagram</title>
    <ns>0</ns>
    <id>16869761</id>
    <revision>
      <id>777984486</id>
      <parentid>777633230</parentid>
      <timestamp>2017-04-30T13:58:45Z</timestamp>
      <contributor>
        <ip>126.162.5.22</ip>
      </contributor>
      <comment>There was a sentence that had no meaning: "It is not important any more but it is useful right simeplfuly." The promoun 'it' had no clear meaning, nor did the last word in the sentence - nor the sentence itself.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10897">[[File:Process-Data Diagram 01.jpg|thumb|360px|right|The process data diagram]]
A '''process-data diagram (PDD)''', also known as '''process-deliverable diagram''' is a [[diagram]] that describes [[process (computing)|process]]es and [[data]] that act as output of these processes. On the left side the [[meta-process model]] can be viewed and on the right side the [[metadata modeling|meta-data model]] can be viewed.&lt;ref name="WSVB"&gt;I. Van de Weerd, J. Souer, J. Versendaal and [[Sjaak Brinkkemper]] (2005). ''Situational Requirements Engineering of Web Content Management Implementations''. SREP2005.&lt;/ref&gt;

A process-data diagram can be seen as combination of a [[business process model]] and [[data model]].

== Overview ==
[[Image:SAP Implementation process-data diagram.png|240px|right|thumbnail|SAP Implementation process-data diagram]] 
The process-data diagram that is depicted at the right, gives an overview of all of these activities/processes and deliverables. The four gray boxes depict the four main [[implementation]] phases, which each contain several processes that are in this case all sequential. The boxes at the right show all the deliverables/[[concept]]s that result from the processes. Boxes without a shadow have no further sub-concepts. Boxes with a black shadow depict complex closed concepts, so concepts that have sub-concepts, which however will not be described in any more detail. Boxes with a white shadow (a box behind it) depict open closed concepts, where the sub-concepts are expanded in greater detail. The lines with diamonds show a has-a relationship between concepts.

The [[SAP Implementation]] process is made up out of four main phases, i.e. the project preparation where a vision of the future-state of the SAP solution is being created, a sizing and blueprinting phase where a [[solution stack|software stack]] is acquired and [[training]] is being performuued, a functional development phase and finally a final preparation phase, when the last [[Software testing|tests]] are being performed before the actual go live. For each phase, the vital activities are addressed and the [[deliverable]]s/[[Product (business)|product]]s are explained.

== Process-data diagram building blocks ==

=== Sequential activities ===
{{main article|Activity diagram}}
Sequential activities are activities that need to be carried out in a pre-defined order. The activities are connected with an arrow, implying that they have to be followed in that sequence. Both activities and sub-activities can be modeled in a sequential way. In Figure 1 an activity diagram is illustrated with one activity and two sequential sub-activities. A special kind of sequential activities are the start and stop states, which are also illustrated in Figure 1.

In Figure 2 an example from practice is illustrated. The example is taken from the requirements capturing workflow in UML-based Web Engineering. The main activity, user &amp; domain modeling, consists of three activities that need to be carried out in a predefined order.

&lt;gallery&gt;
Image:Process-Data Diagram 21.gif|1: Sequential activities
Image:Process-Data Diagram 22.gif|2: Example 
Image:Process-Data Diagram 23.gif|3: Unordered activities
Image:Process-Data Diagram 24.gif|4: Example  
&lt;/gallery&gt;

=== Unordered activities ===
Unordered activities are used when sub-activities of an activity do not have a pre-defined sequence in which they need to be carried out. Only sub-activities can be unordered. Unordered activities are represented as sub-activities without transitions within an activity, as is represented in Figure 3.

Sometimes an activity consists of both sequential and unordered sub-activities. The solution to this modeling issue is to divide the main activity in different parts. In Figure 4 an example is illustrated, which clarifies the necessity to be able to model unordered activities. The example is taken from the requirements analysis workflow of the Unified Process. The main activity, “describe candidate requirements”, is divided into two parts. The first part is a sequential activity. The second part consists of four activities that do not need any sequence in order to be carried out correctly.

=== Concurrent activities ===
Activities can occur concurrently. This is handled with forking and joining. By drawing the activities parallel in the diagram, connected with a synchronization bar, one can fork several activities. Later on these concurrent activities can join again by using the same synchronization bar. Both activities and sub-activities can occur concurrently. In the example of Figure 5, Activity 2 and Activity 3 are concurrent activities.

In Figure 6, a fragment of a requirements capturing process is depicted. Two activities, defining the actors and defining the use cases, are carried out concurrently. The reason for carrying out these activities concurrently is that defining the actors influences the use cases greatly, and vice versa.

&lt;gallery&gt;
Image:Process-Data Diagram 25.gif|5: Concurrent activities
Image:Process-Data Diagram 26.gif|6: Example 
Image:Process-Data Diagram 27.gif|7: Conditional activities
Image:Process-Data Diagram 28.gif|8: Example 
&lt;/gallery&gt;

=== Conditional activities ===
Conditional activities are activities that are only carried out if a pre-defined condition is met. This is graphically represented by using a branch. Branches are illustrated with a diamond and can have incoming and outgoing transitions. Every outgoing transition has a guard expression, the condition. This guard expression is actually a Boolean expression, used to make a choice which direction to go. Both activities and sub-activities can be modeled as conditional activities. In Figure 7 two conditional activities are illustrated.

In Figure 8 an example from practice is illustrated. A requirements analysis starts with studying the material. Based on this study, the decision is taken whether to do an extensive requirements elicitation session or not. The condition for not carrying out this requirements session is represented at the left of the branch, namely [requirements clear]. If this condition is not met, [else], the other arrow is followed.

The integration of both types of diagrams is quite straightforward. Each action or activity results in a concept. They are connected with a dotted arrow to the produced artifacts, as is demonstrated in Figure 9.  The concepts and activities are abstract in this picture.

::[[Image:Mm41.gif|frame|left|Figure 9: Process-Data Diagram]]{{clear|left}}

In Table 1 a generic table is presented with the description of activities, sub-activities and their relations to the concepts. In section 5 examples are given of both process-data diagram and activity table.

::{| class="wikitable"
|- bgcolor="#ccccff"
|'''Activity'''
|'''Sub-Activity'''
|'''Description'''
|-
|'''Activity 2'''
|Sub-activity 4
|Sub-activity 4 results in a STANDARD CONCEPT
|-
|}
::'''Table 1: Activity table'''

== Example of a process-data diagram ==
In Figure 10 an example of a process-data diagram is illustrated. It concerns an example from the orientation phase of complex project in a WebEngineering method.&lt;ref name="WSVB"/&gt;

Notable is the use of open and closed concepts. Since project management is actually not within the scope of this research, the concept CONTROL MANAGEMENT has not been expanded. However, in a complex project is RISK MANAGEMENT of great importance. Therefore, the choice is made to expand the RISK MANAGEMENT concept.

::[[File:Process-Data Diagram 41.gif|frame|left|Figure 10: Example Process-Data Diagram - Orientation phase in a complex project]]{{clear|left}}

In Table 2 the activities and sub-activities, and relation to the concepts are described.

::{| class="wikitable"
|- bgcolor="#ccccff"
|'''Activity'''
|'''Sub-Activity'''
|'''Description'''
|-valign="top"
|'''Describe Project'''
|
|Describing the project is done in terms of participants, targets, products, scope and assumptions. This information is derived from the proposal, but with more emphasis on the project management issues. The activity end in a project DESCRIPTION.
|-valign="top"
|'''Construct planning'''
|Describe project phases
|The PLANNING is divided into five PROJECT PHASES, which should be shortly described.
|-valign="top"
|'''Construct planning'''
|Describe activities
|The project ACTIVITIES are described and grouped into PROJECT PHASES.
|-valign="top"
|'''Construct planning'''
|Describe deliverables
|The DELIVERABLES that result from the project ACTIVITIES are described.
|-valign="top"
|'''Construct planning'''
|Set up schedule
|For every DELIVERABLE a DATE is set and for each ACTIVITY a TIME SLOT is estimated.
|-valign="top"
|'''Control project'''
|
|Controlling the project results in a CONTROL MANAGEMENT artifact. This artifact is not further explained here, since it concerns regular project management issues, like communication management, progress management, change management and problem management that lie outside the scope of this research.
|-valign="top"
|'''Control risk'''
|Identify risks
|Identifying risks can be done by using standard checklists or organizing risk workshops. The RISKS are included in the PROJECT PLAN.
|-valign="top"
|'''Control risk'''
|Evaluate risks
|Every RISK is provided with an EVALUATION; a description and estimation about the complexity or uncertainty of a project is given.
|-valign="top"
|'''Control risk'''
|Analyze impact
|Analyzing the impact of a risk handles about the IMPACT, a risk has on the success of a project. The evaluation and risk values are indicated by selecting a value: low, moderate or high.
|-valign="top"
|'''Control risk'''
|Prioritize risks
|Prioritizing the risks is done by combining IMPACT and EVALUATION in a table. High priority is then given to RISKS with the highest scores.
|-valign="top"
|'''Define actions for risk strategy'''
|
|Risk strategy actions can be obtained from experience or from relevant literature. The project manager adapts the actions to the project in the ACTION LIST FOR RISK STRATEGY. RISKS with the highest priority are on top of the list and need to be handled first.
|-
|}
::'''Table 2: Activities and sub-activities in a complex orientation phase'''

== See also ==
{{Commons category|Process-data diagram}}
* [[Acquisition Initiation (ISPL)]]
* [[Change management (engineering)]]
* [[Dynamic Systems Development Method]]
* [[ITIL Security Management]]
* [[Implementation Maturity Model Assessment]]
* [[Managing stage boundaries]]
* [[Metadata modeling]]
* [[Object Process Methodology]]
* [[PREview]]
* [[Product Family Engineering]]
* [[Product Structure Modeling]]
* [[Synchronization model]]

== References ==
{{reflist}}
{{Refimprove|date=November 2008}}

{{DEFAULTSORT:Process-Data Diagram}}
[[Category:Diagrams]]
[[Category:Systems engineering]]
[[Category:Unified Modeling Language]]</text>
      <sha1>1542yg1ly1103f0hzdussgnz2koezkl</sha1>
    </revision>
  </page>
  <page>
    <title>Put–call parity</title>
    <ns>0</ns>
    <id>207387</id>
    <revision>
      <id>862039207</id>
      <parentid>858123220</parentid>
      <timestamp>2018-10-01T19:34:28Z</timestamp>
      <contributor>
        <username>Sandstein</username>
        <id>359256</id>
      </contributor>
      <minor/>
      <comment>Removing link(s): [[Wikipedia:Articles for deletion/Espen Gaarder Haug (2nd nomination)]] closed as delete ([[WP:XFDC|XFDcloser]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13750">In [[financial mathematics]], '''put–call parity''' defines a relationship between the price of a [[European call option]] and [[European put option]], both with the identical [[strike price]] and expiry, namely that a portfolio of a long call option and a short put option is equivalent to (and hence has the same value as) a single [[forward contract]] at this strike price and expiry. This is because if the price at expiry is above the strike price, the call will be exercised, while if it is below, the put will be exercised, and thus in either case one unit of the asset will be purchased for the strike price, exactly as in a forward contract.

The validity of this relationship requires that certain assumptions be satisfied; these are specified and the relationship is derived below. In practice transaction costs and financing costs (leverage) mean this relationship will not exactly hold, but in [[Market liquidity|liquid markets]] the relationship is close to exact.

==Assumptions==
Put–call parity is a [[static replication]], and thus requires minimal assumptions, namely the existence of a [[forward contract]]. In the absence of traded forward contracts, the forward contract can be replaced (indeed, itself replicated) by the ability to buy the underlying asset and finance this by borrowing for fixed term (e.g., borrowing bonds), or conversely to borrow and sell (short) the underlying asset and loan the received money for term, in both cases yielding a [[self-financing portfolio]].

These assumptions do not require any transactions between the initial date and expiry, and are thus significantly weaker than those of the [[Black–Scholes model]], which requires [[dynamic replication (finance)|dynamic replication]] and continual transaction in the underlying.

Replication assumes one can enter into derivative transactions, which requires leverage (and capital costs to back this), and buying and selling entails [[transaction cost]]s, notably the [[bid–ask spread]]. The relationship thus only holds exactly in an ideal [[frictionless market]] with unlimited liquidity. However, real world markets may be sufficiently liquid that the relationship is close to exact, most significantly FX markets in major currencies or major stock indices, in the absence of market turbulence.

==Statement==
'''Put–call parity''' can be stated in a number of equivalent ways, most tersely as:
:&lt;center&gt;&lt;math&gt;C - P = D(F - K)&lt;/math&gt;&lt;/center&gt;
where ''C'' is the (current) value of a call, ''P'' is the (current) value of a put, ''D'' is the [[discount factor]], ''F'' is the [[forward price]] of the asset, and ''K'' is the strike price. Note that the spot price is given by &lt;math&gt;D\cdot F = S&lt;/math&gt; (spot price is present value, forward price is future value, discount factor relates these). The left side corresponds to a portfolio of long a call and short a put, while the right side corresponds to a forward contract. The assets ''C'' and ''P'' on the left side are given in current values, while the assets ''F'' and ''K'' are given in future values (forward price of asset, and strike price paid at expiry), which the discount factor ''D'' converts to present values.

Using spot price ''S'' instead of forward price ''F'' yields: 
:&lt;center&gt;&lt;math&gt;C - P = S - D\cdot K&lt;/math&gt;&lt;/center&gt;

Rearranging the terms yields a different interpretation:
:&lt;center&gt;&lt;math&gt;C + D \cdot K = P + S&lt;/math&gt;&lt;/center&gt;
In this case the left-hand side is a [[fiduciary call]], which is long a call and enough cash (or bonds) to pay the strike price if the call is exercised, while the right-hand side is a [[protective put]], which is long a put and the asset, so the asset can be sold for the strike price if the spot is below strike at expiry. Both sides have payoff ''max''(''S''(''T''), ''K'') at expiry (i.e., at least the strike price, or the value of the asset if more), which gives another way of proving or interpreting put–call parity.

In more detail, this original equation can be stated as:
:&lt;center&gt;&lt;math&gt; C(t) - P(t) = S(t)- K \cdot B(t,T)&lt;/math&gt;&lt;/center&gt;
where
:&lt;math&gt;C(t)&lt;/math&gt; is the value of the call at time &lt;math&gt;t&lt;/math&gt;,
:&lt;math&gt;P(t)&lt;/math&gt; is the value of the put of the same expiration date,
:&lt;math&gt;S(t)&lt;/math&gt; is the [[spot price]] of the underlying asset,
:&lt;math&gt;K&lt;/math&gt; is the strike price, and
:&lt;math&gt;B(t,T)&lt;/math&gt; is the present value of a [[zero-coupon bond]] that matures to $1 at time &lt;math&gt;T.&lt;/math&gt; This is the present value factor for K.

Note that the right-hand side of the equation is also the price of buying a [[forward contract]] on the stock with delivery price ''K''.  Thus one way to read the equation is that a portfolio that is long a call and short a put is the same as being long a forward.  In particular, if the underlying is not tradeable but there exists forwards on it, we can replace the right-hand-side expression by the price of a forward.

If the bond [[interest rate]], &lt;math&gt;r&lt;/math&gt;, is assumed to be constant then
:&lt;center&gt;&lt;math&gt; B(t,T) = e^{-r(T-t)}&lt;/math&gt;&lt;/center&gt;

Note: &lt;math&gt;r&lt;/math&gt; refers to the [[force of interest]], which is approximately equal to the effective annual rate for small interest rates. However, one should take care with the approximation, especially with larger rates and larger time periods. To find &lt;math&gt;r&lt;/math&gt; exactly, use &lt;math&gt;r = ln (1+i) &lt;/math&gt;, where &lt;math&gt;i&lt;/math&gt; is the effective annual interest rate.

When valuing European options written on stocks with known dividends that will be paid out during the life of the option, the formula becomes:

:&lt;center&gt;&lt;math&gt; C(t) - P(t) + D(t) = S(t) - K \cdot B(t,T)&lt;/math&gt;&lt;/center&gt;

where D(t) represents the total value of the dividends from one stock share to be paid out over the remaining life of the options, discounted to [[present value]].  
We can rewrite the equation as:

:&lt;center&gt;&lt;math&gt; C(t) - P(t) = S(t) - K \cdot B(t,T)\ - D(t)&lt;/math&gt;&lt;/center&gt;

and note that the right-hand side is the price of a forward contract on the stock with delivery price ''K'', as before.

==Derivation==
We will suppose that the put and call options are on traded stocks, but the [[underlying]] can be any other tradeable asset.  The ability to buy and sell the underlying is crucial to the "no arbitrage" argument below.

First, note that under the assumption that there are no [[arbitrage]] opportunities (the prices are [[arbitrage-free]]), two portfolios that always have the same payoff at time T must have the same value at any prior time.  To prove this suppose that, at some time ''t'' before ''T'', one portfolio were cheaper than the other. Then one could purchase (go long) the cheaper portfolio and sell (go short) the more expensive.  At time ''T'', our overall portfolio would, for any value of the share price, have zero value (all the assets and liabilities have canceled out).  The profit we made at time ''t'' is thus a riskless profit, but this violates our assumption of no arbitrage.

We will derive the put-call parity relation by creating two portfolios with the same payoffs ([[static replication]]) and invoking the above principle ([[rational pricing]]).

Consider a call option and a put option with the same strike ''K'' for expiry at the same date ''T'' on some stock ''S'', which pays no dividend.  We assume the existence of a [[Bond (finance)|bond]] that pays 1 dollar at maturity time ''T''.  The bond price may be random (like the stock) but must equal 1 at maturity.

Let the price of ''S'' be S(t) at time t.  Now assemble a portfolio by buying a call option ''C'' and selling a put option ''P'' of the same maturity ''T'' and strike ''K''.   The payoff for this portfolio is ''S(T) - K''.  Now assemble a second portfolio by buying one share and borrowing ''K'' bonds.  Note the payoff of the latter portfolio is also ''S(T) - K'' at time ''T'', since our share bought for ''S(t)'' will be worth ''S(T)'' and the borrowed bonds will be worth ''K''.

By our preliminary observation that identical payoffs imply that both portfolios must have the same price at a general time &lt;math&gt;t&lt;/math&gt;, the following relationship exists between the value of the various instruments:

:&lt;center&gt;&lt;math&gt; C(t) - P(t) = S(t)- K \cdot B(t,T) \, &lt;/math&gt;&lt;/center&gt;

Thus given no arbitrage opportunities, the above relationship, which is known as '''put-call parity''', holds, and for any three prices of the call, put, bond and stock one can compute the implied price of the fourth.

In the case of dividends, the modified formula can be derived in similar manner to above, but with the modification that one portfolio consists of going long a call, going short a put, and ''D(T)'' bonds that each pay 1 dollar at maturity ''T'' (the bonds will be worth ''D(t)'' at time ''t''); the other portfolio is the same as before - long one share of stock, short ''K'' bonds that each pay 1 dollar at ''T''.  The difference is that at time ''T'', the stock is not only worth ''S(T)'' but has paid out ''D(T)'' in dividends.

==History==
Forms of put-call parity appeared in practice as early as medieval ages, and was formally described by a number of authors in the early 20th century.

Michael Knoll, in ''The Ancient Roots of Modern Financial Innovation: The Early History of Regulatory Arbitrage'', describes the important role that put-call parity played in developing the [[equity of redemption]], the defining characteristic of a modern mortgage, in Medieval England.

In the 19th century, financier [[Russell Sage]] used put-call parity to create synthetic loans, which had higher interest rates than the usury laws of the time would have normally allowed.{{Citation needed|date=June 2011}}

Nelson, an option arbitrage trader in New York, published a book: "The A.B.C. of Options and Arbitrage" in 1904 that describes the put-call parity in detail. His book was re-discovered by Espen Gaarder Haug in the early 2000s and many references from Nelson's book are given in Haug's book "Derivatives Models on Models".

Henry Deutsch describes the put-call parity  in 1910 in his book "Arbitrage in Bullion, Coins, Bills, Stocks, Shares and Options, 2nd Edition". London: Engham Wilson but in less detail than Nelson (1904).

Mathematics professor [[Vinzenz Bronzin]] also derives the put-call parity in 1908 and uses it as part of his arbitrage argument to develop a series of mathematical option models under a series of different distributions. The work of professor  Bronzin was just recently rediscovered by professor Wolfgang Hafner and professor Heinz Zimmermann. The original work of Bronzin is a book written in German and is now translated and published in English in an edited work by Hafner and Zimmermann ("Vinzenz Bronzin's option pricing models", [[Springer Verlag]]).

Its first description in the modern academic literature appears to be by [[Hans Stoll|Hans R. Stoll]] in the ''[[Journal of Finance]]''. &lt;ref&gt;{{cite journal|title=The Relationship Between Put and Call Option Prices|last=Stoll|first=Hans R.|journal=Journal of Finance|volume=24|date=December 1969|jstor=2325677|doi=10.2307/2325677}}&lt;/ref&gt;&lt;ref&gt;Cited for instance in {{cite journal|last1=Derman|first1= Emanuel|first2=Nassim Nicholas |last2=Taleb|title=The illusions of dynamic replication|journal=Quantitative Finance |volume=5:4 |year=2005|pages=323-326|doi=10.1080/14697680500305105}}&lt;/ref&gt;

==Implications==
Put–call parity implies:

* ''Equivalence of calls and puts'': Parity implies that a call and a put can be used interchangeably in any [[delta neutral|delta-neutral]] portfolio. If &lt;math&gt;d&lt;/math&gt; is the call's delta, then buying a call, and selling &lt;math&gt;d&lt;/math&gt; shares of stock, is the same as selling a put and selling &lt;math&gt;1 - d&lt;/math&gt; shares of stock. Equivalence of calls and puts is very important when trading options.{{cn|date=July 2017}}
* ''Parity of implied volatility'': In the absence of dividends or other costs of carry (such as when a stock is difficult to borrow or sell short), the [[implied volatility]] of calls and puts must be identical.&lt;ref name="JHull"&gt;{{cite book | last = Hull
| first = John C. | edition = 5th | title = Options, Futures and Other Derivatives | year = 2002 | publisher = [[Prentice Hall]] | pages=330–331 | isbn = 0-13-009056-5 }}&lt;/ref&gt;

==See also==
* [[Spot-future parity]]
* [[Vinzenz Bronzin]]

==References==
{{Reflist}}


==External links==
*Put-Call parity
**[https://www.khanacademy.org/economics-finance-domain/core-finance/derivative-securities/put-call-options/v/put-call-parity Put-call parity], tutorial by [[Salman Khan (educator)]]
**[http://www.putcallparity.net Put-Call Parity of European Options], putcallparity.net
**[http://www.investopedia.com/articles/optioninvestor/05/011905.asp Put-Call Parity and Arbitrage Opportunity], investopedia.com
**[http://lsr.nellco.org/upenn/wps/papers/49/ The Ancient Roots of Modern Financial Innovation: The Early History of Regulatory Arbitrage], Michael Knoll's history of Put-Call Parity
*Other arbitrage relationships
**[http://www.sjsu.edu/faculty/watkins/arb.htm Arbitrage Relationships for Options], Prof. Thayer Watkins
**[http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN99-05.pdf Rational Rules and Boundary Conditions for Option Pricing] ([[portable document format|PDFDi]]), Prof. Don M. Chance
**[https://web.archive.org/web/20101121224056/http://faculty.chicagobooth.edu/robert.novy-marx/teaching/35100/Lectures/lec03.pdf No-Arbitrage Bounds on Options], Prof. Robert Novy-Marx
*Tools
**[http://www.duke.edu/~charvey/Classes/ba350/optval/arbitrage/arbitrage.htm Option Arbitrage Relations], Prof. Campbell R. Harvey

{{Derivatives market}}

{{DEFAULTSORT:Put-call parity}}
[[Category:Finance theories]]
[[Category:Mathematical finance]]
[[Category:Options (finance)]]</text>
      <sha1>du4c9zj3i6styx9hmrehfq7p3qamvj9</sha1>
    </revision>
  </page>
  <page>
    <title>Quasiperiodic function</title>
    <ns>0</ns>
    <id>2657905</id>
    <revision>
      <id>815515761</id>
      <parentid>801721279</parentid>
      <timestamp>2017-12-15T08:58:29Z</timestamp>
      <contributor>
        <ip>112.215.238.13</ip>
      </contributor>
      <comment>/* Quasiperiodic signals */Fixed typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2704">In [[mathematics]], a '''quasiperiodic function''' is a [[function (mathematics)|function]] that has a certain similarity to a periodic function. A function &lt;math&gt;f&lt;/math&gt; is quasiperiodic with quasiperiod &lt;math&gt;\omega&lt;/math&gt; if &lt;math&gt;f(z + \omega) = g(z,f(z))&lt;/math&gt;, where &lt;math&gt;g&lt;/math&gt; is a "''simpler''" function than &lt;math&gt;f&lt;/math&gt;. What it means to be  "''simpler''" is vague.

A simple case (sometimes called arithmetic quasiperiodic) is if the function obeys the equation:

:&lt;math&gt; f(z + \omega) = f(z) + C &lt;/math&gt;

Another case (sometimes called geometric quasiperiodic) is if the function obeys the equation:

:&lt;math&gt; f(z + \omega) = C f(z) &lt;/math&gt;

An example of this is the [[theta function|Jacobi theta function]], where

:&lt;math&gt;\vartheta(z+\tau;\tau) = e^{-2\pi iz - \pi i\tau}\vartheta(z;\tau),&lt;/math&gt;

shows that for fixed ''&amp;tau;'' it has quasiperiod ''&amp;tau;''; it also is periodic with period one. Another example is provided by the [[Weierstrass sigma function]], which is quasiperiodic in two independent quasiperiods, the periods of the corresponding [[Weierstrass elliptic functions|Weierstrass ''&amp;weierp;'' function]].

Functions with an additive functional equation

:&lt;math&gt; f(z + \omega) = f(z)+az+b \ &lt;/math&gt;
are also called quasiperiodic. An example of this is the [[Weierstrass zeta function]], where

:&lt;math&gt; \zeta(z + \omega, \Lambda) = \zeta(z , \Lambda) + \eta (\omega , \Lambda) \ &lt;/math&gt;

for a ''z''-independent &amp;eta; when &amp;omega; is a period of the corresponding Weierstrass &amp;weierp; function.

In the special case where &lt;math&gt; f(z + \omega)=f(z) \ &lt;/math&gt; we say ''f'' is [[periodic function|periodic]] with period &amp;omega; in the period lattice &lt;math&gt;\Lambda&lt;/math&gt;.

==Quasiperiodic signals==

Quasiperiodic signals in the sense of audio processing are not quasiperiodic functions in the sense defined here; instead they have the nature of [[almost periodic function]]s and that article should be consulted. The more vague and general notion of [[quasiperiodicity]] has even less to do with quasiperiodic functions in the mathematical sense.

A useful example is the function:

:&lt;math&gt; f(z) = \sin(Az) + \sin(Bz) &lt;/math&gt;

If the ratio ''A''/''B'' is rational, this will have a true period, but if ''A''/''B'' is irrational there is no true period, but a succession of increasingly accurate "almost" periods.

== See also ==
* [[Quasiperiodicity]]
* [[Quasiperiodic motion]]
* [[Almost periodic function]]

==External links==
*[https://web.archive.org/web/20070713223414/http://planetmath.org/encyclopedia/QuasiperiodicFunction.html Quasiperiodic function] at [[PlanetMath]]{{dead link|date=March 2015}}

[[Category:Complex analysis]]
[[Category:Types of functions]]</text>
      <sha1>1w8b4hzhdvctb7xclohz1xpob1groqe</sha1>
    </revision>
  </page>
  <page>
    <title>Riemannian metric and Lie bracket in computational anatomy</title>
    <ns>0</ns>
    <id>49400436</id>
    <revision>
      <id>858241138</id>
      <parentid>819528242</parentid>
      <timestamp>2018-09-05T22:01:53Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: journal. Add: citeseerx. Removed parameters. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[User:AquaDTRS|AquaDTRS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21643">{{COI|date=December 2017}}{{Further information|LDDMM}}
{{Main|Computational anatomy}}

[[Computational anatomy|Computational anatomy (CA)]] is the study of shape and form in [[medical imaging]]. The study of deformable shapes in [[computational anatomy]] rely on high-dimensional diffeomorphism groups &lt;math&gt; \varphi \in \operatorname{Diff}_V &lt;/math&gt; which generate orbits of the form &lt;math&gt; \mathcal{M} \doteq
\{ \varphi \cdot m \mid \varphi \in \operatorname{Diff}_V \} &lt;/math&gt;. In CA, this orbit is in general considered a smooth [[Riemannian manifold]]
since at every point of the manifold &lt;math&gt; m \in \mathcal{M} &lt;/math&gt; there is an  [[Inner product space|inner product]] inducing the norm &lt;math&gt; \| \cdot \|_m &lt;/math&gt; on the [[tangent space]]
that varies smoothly from point to point in the manifold of shapes &lt;math&gt; m \in \mathcal{M} &lt;/math&gt;. This is generated by viewing the
group of diffeomorphisms &lt;math&gt; \varphi \in \operatorname{Diff}_V &lt;/math&gt; as a Riemannian manifold with &lt;math&gt; \| \cdot \|_\varphi  &lt;/math&gt;,  associated to the tangent space at  &lt;math&gt; \varphi \in\operatorname{Diff}_V &lt;/math&gt; . This induces the norm and metric on the orbit &lt;math&gt; m \in \mathcal{M} &lt;/math&gt; under the action from the group of diffeomorphisms.

==The diffeomorphisms group generated as Lagrangian and Eulerian flows==
The diffeomorphisms in [[computational anatomy]] are generated to satisfy the [[Computational anatomy#Lagrangian and Eulerian flows for generating diffeomorphisms|Lagrangian and Eulerian specification of the flow fields]], &lt;math&gt; \varphi_t,  t \in [0,1] &lt;/math&gt;, generated via the ordinary differential equation

{{NumBlk|:|&lt;math&gt;
\frac{d}{dt} \varphi_t = v_t \circ \varphi_t , \ \varphi_0 = \operatorname{id}; &lt;/math&gt;|{{EquationRef|Lagrangian flow}}}}
with the Eulerian vector fields &lt;math&gt; v \doteq (v_1,v_2,v_3) &lt;/math&gt; in &lt;math&gt;  {\mathbb R}^3   &lt;/math&gt;  for &lt;math&gt;v_t = \dot \varphi_t \circ \varphi_t^{-1}, t \in [0,1]&lt;/math&gt;, with the inverse for the flow given by

{{NumBlk|:|&lt;math&gt;
 \frac{d}{dt} \varphi_t^{-1} = -(D \varphi_t^{-1}) v_t, \ \varphi_0^{-1} = \operatorname{id}, &lt;/math&gt;|{{EquationRef|Eulerianflow}}}}
and the &lt;math&gt;3 \times 3&lt;/math&gt; Jacobian matrix for flows in &lt;math&gt;\mathbb{R}^3&lt;/math&gt;  given as &lt;math&gt; \ D\varphi \doteq \left(\frac{\partial \varphi_i}{\partial x_j}\right). &lt;/math&gt;

To ensure smooth flows of diffeomorphisms with inverse,  the vector fields &lt;math&gt;  {\mathbb R}^3   &lt;/math&gt; must be at least 1-time continuously differentiable in space&lt;ref name=":22"&gt;P. Dupuis, U. Grenander, M.I. Miller, Existence of Solutions on Flows of Diffeomorphisms, Quarterly of Applied Math, 1997.&lt;/ref&gt;&lt;ref name=":4"&gt;A. Trouvé. Action de groupe de dimension infinie et reconnaissance de formes. C R Acad Sci Paris Sér I Math, 321(8):1031– 1034, 1995.&lt;/ref&gt; which are modelled as elements of the Hilbert space  &lt;math&gt;(V, \| \cdot \|_V )&lt;/math&gt; using the [[Sobolev space|Sobolev]] embedding theorems so that each element &lt;math&gt;v_i \in H_0^3, i=1,2,3,&lt;/math&gt; has 3-square-integrable derivatives thusly implies &lt;math&gt;(V, \| \cdot \|_V )&lt;/math&gt; embeds smoothly in 1-time continuously differentiable functions.&lt;ref name=":22" /&gt;&lt;ref name=":4" /&gt;  The diffeomorphism group are flows with vector fields absolutely integrable in Sobolev norm:{{NumBlk|:|&lt;math&gt;
\operatorname{Diff}_V \doteq \{\varphi=\varphi_1: \dot \varphi_t = v_t \circ \varphi_t , \varphi_0 = \operatorname{id}, \int_0^1 \|v_t \|_V \,dt &lt; \infty \} \ .
&lt;/math&gt;|{{EquationRef|Diffeomorphism Group}}}}

==The Riemannian orbit model==
Shapes in [[Computational anatomy|Computational Anatomy (CA)]] &lt;nowiki/&gt;are studied via the use of diffeomorphic mapping for establishing correspondences between anatomical coordinate systems. In this setting, 3-dimensional medical images are modelled as diffemorphic transformations of some exemplar, termed the template &lt;math&gt; I_{temp} &lt;/math&gt;, resulting in the observed images to be elements of the random [[Computational anatomy#The deformable template orbit model of CA|orbit model of CA]]. For images these are defined as &lt;math&gt; I \in \mathcal {I}
\doteq \{ I = I_{temp} \circ \varphi, \varphi \in \operatorname{Diff}_V \} &lt;/math&gt;, with for charts representing sub-manifolds denoted as &lt;math&gt;\mathcal{M} \doteq \{ \varphi \cdot m_{temp} : \varphi \in \operatorname{Diff}_V \}&lt;/math&gt;.

==The Riemannian metric==
The orbit of shapes and forms in Computational Anatomy  are generated by the group action&lt;math&gt;\mathcal{M} \doteq \{ \varphi \cdot m : \varphi \in \operatorname{Diff}_V \}&lt;/math&gt;.   This is made into a Riemannian orbit by introducing a metric associated to each point and associated tangent space. For this a metric is defined on the group which induces the metric on the orbit. Take as the metric for  [[Computational anatomy]] at each element of the tangent space &lt;math&gt;\varphi \in \operatorname{Diff}_V&lt;/math&gt; in the group of diffeomorphisms 
:&lt;math&gt; \| \dot \varphi \|_\varphi \doteq \| \dot \varphi \circ \varphi^{-1} \|_V=\| v \|_V &lt;/math&gt;, 
with the vector fields modelled to be in a Hilbert space with the norm in the Hilbert space &lt;math&gt;(V, \| \cdot \|_V )&lt;/math&gt;. We model &lt;math&gt;V&lt;/math&gt; as a reproducing kernel Hilbert space (RKHS) defined by a 1-1, differential operator&lt;math&gt; A: V \rightarrow V^*  &lt;/math&gt;. For &lt;math&gt; \sigma(v) \doteq Av \in V^*
&lt;/math&gt; a distribution or generalized function, the linear form &lt;math&gt; (\sigma\mid w) \doteq \int_{\mathbb R^3}  \sum_i w_i(x) \sigma_i (dx)
&lt;/math&gt; determines the norm:and inner product for &lt;math&gt;v \in V&lt;/math&gt; according to 
:&lt;math&gt; \langle v , w \rangle_V \doteq \int_X A v \cdot w \, dx, \ \| v\|_V^2 \doteq \int_X A v \cdot v \, dx, \ v,w \in V \ .
&lt;/math&gt;
where the integral is calculated by integration by parts for &lt;math&gt; Av &lt;/math&gt; a generalized function &lt;math&gt; Av \in V^*&lt;/math&gt; the dual-space.
The differential operator is selected so that the Green's kernel associated to the inverse is sufficiently smooth so that the [[Computational anatomy#The Smoothness Condition on Vector fields as Modelled in a Reproducing kernel Hilbert space|vector fields support 1-continuous derivative]].

===The right-invariant metric on diffeomorphisms===
The metric on the group of diffeomorphisms is defined by the distance as defined on pairs of elements in the group of diffeomorphisms according to

{{NumBlk||&lt;math&gt; d_{\operatorname{Diff}_V} (\psi, \varphi) = \inf_{v_t} \left(\frac 1 2 \int_0^1 \int_X Av_t \cdot v_t \,dx \  dt : \varphi_0 = \psi, \varphi_1 = \varphi, \dot \varphi_t = v_t \circ \varphi_t \right)^{1/2} \ .
&lt;/math&gt;|{{EquationRef|metric-diffeomorphisms}}}}

This distance provides a right-invariant metric of diffeomorphometry,&lt;ref&gt;{{Cite journal|last=Miller|first=M. I.|last2=Younes|first2=L.|date=2001-01-01|title=Group Actions, Homeomorphisms, And Matching: A General Framework|journal=International Journal of Computer Vision|volume=41|pages=61–84|doi=10.1023/A:1011161132514|citeseerx=10.1.1.37.4816}}&lt;/ref&gt;&lt;ref name="pmid24904924" /&gt;&lt;ref&gt;{{Cite journal|last=Miller|first=Michael I.|last2=Trouvé|first2=Alain|last3=Younes|first3=Laurent|date=2015-01-01|title=Hamiltonian Systems and Optimal Control in Computational Anatomy: 100 Years Since D'Arcy Thompson|journal=Annual Review of Biomedical Engineering|volume=17|issue=1|pages=447–509|doi=10.1146/annurev-bioeng-071114-040601|pmid=26643025}}&lt;/ref&gt; invariant to reparameterization of space since for all &lt;math&gt; \varphi \in \operatorname{Diff}_V &lt;/math&gt;,

:&lt;math&gt; d_{\operatorname{Diff}_V}(\psi, \varphi) = d_{\operatorname{Diff}_V}(\psi \circ \varphi, \varphi \circ \varphi).&lt;/math&gt;

==The Lie bracket in the group of diffeomorphisms==
The [[Lie bracket]] gives the adjustment of the velocity term resulting from a perturbation of the motion in the setting of curved spaces. Using [[Hamilton's principle]] of least-action derives the optimizing flows as a critical point for the action integral of the integral of the kinetic energy. The Lie bracket for vector fields in Computational Anatomy was first introduced in Miller, Trouve and Younes.&lt;ref&gt;{{Cite journal|last=MILLER|first=MICHAEL I.|last2=TROUVÉ|first2=ALAIN|last3=YOUNES|first3=LAURENT|date=2006-01-31|title=Geodesic Shooting for Computational Anatomy|journal=Journal of Mathematical Imaging and Vision|volume=24|issue=2|pages=209–228|doi=10.1007/s10851-005-3624-0|issn=0924-9907|pmc=2897162|pmid=20613972}}&lt;/ref&gt; The derivation calculates the perturbation &lt;math&gt; \delta v &lt;/math&gt; on the vector fields
&lt;math&gt; v^\varepsilon = v + \varepsilon \delta v &lt;/math&gt;   in terms of the derivative in time of the group perturbation  adjusted by the correction of the [[Lie bracket of vector fields]] in this function setting involving the Jacobian matrix, unlike the matrix group case:
{{NumBlk|:|&lt;math&gt; ad_v:V \mapsto V &lt;/math&gt; given by &lt;math&gt; ad_v(w)\doteq (Dv)w - (Dw)v ,   v,w \in V .&lt;/math&gt;
|{{EquationRef|adjoint-Lie-bracket}}}}

'''Proof:'''
Proving [[Lie bracket of vector fields]] take a first order perturbation of the flow at point &lt;math&gt; \varphi \in \operatorname{Diff}_V &lt;/math&gt;.
{{hidden |
Lie bracket of vector fields
|
Taking the first order perturbation gives &lt;math&gt; \varphi_t^\varepsilon \doteq 
(\operatorname{id} + \varepsilon w) \circ \varphi = \varphi+\varepsilon w \circ \varphi &lt;/math&gt;, with fixed boundary &lt;math&gt; w_0= w_1=0 &lt;/math&gt;, with  &lt;math&gt; \frac{d}{dt} \varphi_t^\varepsilon = v_t^\varepsilon \circ \varphi_t^\varepsilon, \varphi_0^\varepsilon = \operatorname{id} , \varphi_1^\varepsilon = \varphi_1&lt;/math&gt;, giving the following two Eqns:  
:* &lt;math&gt;
\frac{d}{dt} \varphi_t^\varepsilon = \frac{d}{dt} \varphi_t + \varepsilon \frac{d}{dt}(w_t \circ \varphi_t ) =v_t \circ \varphi_t + (D w_t)\circ \varphi_t v_t \circ \varphi_t +o(\varepsilon)\ .
&lt;/math&gt;
:* &lt;math&gt; \dot \varphi_t^\varepsilon = (v_t + \varepsilon \delta v_t) \circ (\varphi_t + \varepsilon w_t \circ \varphi_t) \simeq v_t \circ \varphi_t +\varepsilon (Dv_t)\circ \varphi_t w_t \circ \varphi_t + \delta v_t \circ \varphi_t +o(\varepsilon) \ .
&lt;/math&gt;
Equating the above two equations gives the perturbation of the vector field in terms of the Lie bracket adjustment.
}}
The Lie bracket gives the first order variation of the vector field with respect to first order variation of the flow.
:&lt;math&gt; \delta v_t = \frac{d}{d t} w_t - ad_{v_t}(w_t) =\frac{d}{d t} w_t- ((Dv_t) w_t - (Dw_t)v_t) \ . &lt;/math&gt;

==The generalized Euler–Lagrange equation for the metric on diffeomorphic flows ==
{{Main|Computational anatomy|Computational anatomy#The Euler–Lagrange equation on shape momentum for geodesics on the group of diffeomorphisms}}
The Euler–Lagrange equation can be used to calculate geodesic flows through the group which form the basis for the metric. The [[Computational anatomy#The Action Integral for Hamilton's Principle on the Lagrangian Kinetic Energy|action integral for the Lagrangian of the kinetic energy]] for Hamilton's principle becomes 
{{NumBlk|:|&lt;math&gt;
J(\varphi) \doteq \frac{1}{2}\int_0^1 \| \dot \varphi_t \|_{\varphi_t}^2 \,dt = \frac{1}{2}\int_0^1  \| \dot \varphi_t \circ \varphi_t^{-1} \|_V^2 \,dt =\frac{1}{2}\int_0^1  \int_X A (\dot \varphi_t \circ \varphi_t^{-1})\cdot (\dot \varphi_t \circ \varphi_t^{-1}) \, dx \,dt \ .
&lt;/math&gt; |{{EquationRef|Hamilton's Action Integral}}}}
The action integral in terms of the vector field corresponds to integrating the kinetic energy
:&lt;math&gt;
 J(v) \doteq \frac{1}{2} \int_0^1 \| v_t \|_V^2 dt = \frac{1}{2} \int_0^1 \int_X Av_t \cdot v_t \,dx \ dt
\ .
&lt;/math&gt;
The shortest paths geodesic connections in the orbit are defined via [[Hamilton's principal of least action|Hamilton's Principle of least action]] requires first order variations of the solutions in the orbits of Computational Anatomy which are based on computing critical points on the metric length or energy of the path.
The original derivation of the Euler equation&lt;ref&gt;{{Cite journal|title = Geodesic Shooting for Computational Anatomy|journal = Journal of Mathematical Imaging and Vision|date = 2006-01-31|issn = 0924-9907|pmc = 2897162|pmid = 20613972|pages = 209–228|volume = 24|issue = 2|doi = 10.1007/s10851-005-3624-0|first = MICHAEL I.|last = MILLER|first2 = ALAIN|last2 = TROUVÉ|first3 = LAURENT|last3 = YOUNES}}&lt;/ref&gt; associated to the [[Computational anatomy#The Euler Equation for Geodesic Flows of Diffeomorphisms in Computational Anatomy|geodesic flow of diffeomorphisms]] exploits the was a generalized function equation when&lt;math&gt;Av \in V^*&lt;/math&gt; is a distribution, or generalized function, take the first order variation of the action integral using the adjoint operator for the Lie bracket ({{EquationNote|adjoint-Lie-bracket}}) gives for all smooth &lt;math&gt; w \in V
&lt;/math&gt;, 
:&lt;math&gt; \frac{d}{d \varepsilon} J(\varphi^\varepsilon)|_{\varepsilon=0} = \int_0^1 \int_X Av_t \cdot \delta v_t\,dx \, dt =
\int_0^1 \int_X Av_t \cdot \left( \frac{d}{d t} w_t -( (Dv_t)w-(Dw)v_t) \right)\,dx \,dt.
&lt;/math&gt;
Using the bracket &lt;math&gt; ad_v: w \in V \mapsto V &lt;/math&gt; and &lt;math&gt; ad_v^*: V^* \rightarrow V^* &lt;/math&gt; gives{{NumBlk|:|&lt;math&gt; \frac{d}{dt} Av_t + ad_{v_t}^* (Av_t)=0  \ , \ t \in [0,1] \  ,
&lt;/math&gt; |{{EquationRef|EL-General}}}}
meaning for all smooth &lt;math&gt; w \in V ,&lt;/math&gt;
:&lt;math&gt; \int_X \left( \frac{d}{dt} Av_t + ad_{v_t}^* (Av_t) \right) \cdot w\, dx = \int_X \frac{d}{dt} Av_t \cdot w \,dx + \int_X Av_t \cdot \left( (Dv_t)w-(Dw)v_t \right) \,dx =0 . &lt;/math&gt;
Equation ({{EquationNote|Euler-general}}) is the Euler-equation when diffeomorphic shape momentum is a generalized function.
&lt;ref name=":0"&gt;M.I. Miller, A. Trouve, L. Younes, Geodesic Shooting in Computational Anatomy, IJCV, 2006.&lt;/ref&gt;
This equation has been called EPDiff, Euler–Poincare equation for diffeomorphisms and  has been studied in the context of fluid mechanics for incompressible fluids with &lt;math&gt;L^2&lt;/math&gt; metric.
&lt;ref name=":2"&gt;66. Camassa R, Holm DD. 1993. An integrable shallow water equation with peaked solitons. Phys. Rev. Lett.
71:1661–64
&lt;/ref&gt;
&lt;ref name=":3"&gt;Holm DD, Marsden JE, Ratiu TS. 1998. The Euler–Poincar´e equations and semidirect products with
applications to continuum theories. Adv. Math. 137:1–81
&lt;/ref&gt;

==Riemannian exponential for positioning==
In the [[Computational anatomy|random orbit model of Computational anatomy]], the entire flow is reduced to the initial condition which forms the coordinates encoding the diffeomorphism, as well as providing the means of positioning information in the orbit. This was first terms a geodesic positioning system in Miller, Trouve, and Younes.&lt;ref name="pmid24904924"&gt;{{Cite journal|last=Miller|first=Michael I.|last2=Younes|first2=Laurent|last3=Trouvé|first3=Alain|date=2014-03-01|title=Diffeomorphometry and geodesic positioning systems for human anatomy|journal=Technology|volume=2|issue=1|pages=36–43|doi=10.1142/S2339547814500010|issn=2339-5478|pmc=4041578|pmid=24904924}}&lt;/ref&gt; From the initial condition &lt;math&gt; v_0 &lt;/math&gt; then geodesic positioning  with respect to the [[Computational anatomy#Diffeomorphometry and the metric space of shapes and forms|Riemannian metric]] of Computational anatomy solves for the flow of the Euler–Lagrange equation. Solving the geodesic from the initial condition &lt;math&gt; v_0 &lt;/math&gt; is termed the '''Riemannian-exponential,''' a mapping &lt;math&gt; \operatorname{Exp}_{\operatorname{id}}(\cdot): V \to \operatorname{Diff}_V
&lt;/math&gt; at identity to the group.

The Riemannian exponential satisfies &lt;math&gt;
\operatorname{Exp}_\operatorname{id} (v_0)= \varphi_1 &lt;/math&gt; for initial condition &lt;math&gt;\dot \varphi_0 = v_0&lt;/math&gt;, vector field dynamics &lt;math&gt;\dot \varphi_t = v_t \circ \varphi_t, t \in [0,1]  
&lt;/math&gt;,  
* for classical equation on the diffeomorphic shape momentum as a smooth vector &lt;math&gt; Av_t = \mu_t \,dx &lt;/math&gt; with &lt;math&gt;\int_X \mu_t \cdot w \,dx \ ,w \in V&lt;/math&gt; the Euler equation exists in the classical sense as first derived for the density:&lt;ref&gt;M.I. Miller, A. Trouve, L Younes, On the Metrics and Euler–Lagrange equations of Computational Anatomy,
Annu. Rev. Biomed. Eng. 2002. 4:375–405
doi: 10.1146/annurev.bioeng.4.092101.125733
Copyright °c 2002 by Annual Reviews.
&lt;/ref&gt;
:&lt;math&gt;
 \frac{d}{dt} \mu_t +  (Dv_t)^T \mu_t +(D\mu_t)v_t + ( \nabla \cdot v) \mu_t =0  \ , \ Av_t= \mu_t \, dx  ;
&lt;/math&gt;

* for generalized equation, &lt;math&gt;
Av \in V^* 
&lt;/math&gt;, then  
:&lt;math&gt; \frac{d}{dt} Av_t + ad_{v_t}^* (Av_t)=0  \ , \ t \in [0,1] \  .
&lt;/math&gt;

It is
extended to the entire group,
&lt;math&gt;
\varphi= \operatorname{Exp}_\varphi(v_0\circ \varphi) \doteq \operatorname{Exp}_\operatorname{id} (v_0) \circ \varphi
&lt;/math&gt;.

==The variation problem for matching or registering coordinate system information in computational anatomy==
{{Further information | Large deformation diffeomorphic metric mapping}}
Matching information across coordinate systems is central to [[computational anatomy]]. Adding a matching term &lt;math&gt;E: \varphi \in \operatorname{Diff}_V \rightarrow R^+&lt;/math&gt; to the action integral of Equation ({{EquationNote|Hamilton's action integral}})
which represents the target endpoint 
:&lt;math&gt;C(\varphi) \doteq \int_0^1 \int_X Av_t \cdot v_t \,dx \, dt + E(\varphi_1) \ .&lt;/math&gt;
The endpoint term adds a boundary condition for the Euler–Lagrange equation ({{EquationNote|EL-General}})
which gives the Euler equation with boundary term. Taking the variation gives
*Necessary geodesic condition:
:: &lt;math&gt;
\begin{cases} &amp;
\dfrac{d}{dt} Av_t +  (Dv_t)^T Av_t +(DAv_t)v_t + ( \nabla \cdot v) Av_t =0  \  ;
\\[4pt]
&amp; Av_1 + \frac{\partial E(\varphi)}{\partial \varphi_1} = 0 
\end{cases}
&lt;/math&gt;

'''Proof:'''&lt;ref&gt;M.I. Miller, A. Trouve, L Younes,
On the Metrics and Euler–Lagrange equations of Computational Anatomy,
Annu. Rev. Biomed. Eng. 2002. 4:375–405
doi: 10.1146/annurev.bioeng.4.092101.125733
Copyright °c 2002 by Annual Reviews.
&lt;/ref&gt; The Proof via variation calculus uses the perturbations from above and classic calculus of variation arguments.

{{hidden 
| Proof via calculus of variations with endpoint  energy 
|
: &lt;math&gt;
\begin{align}
&amp; \int_0^1 \int_X Av_t \cdot \left(\frac{d}{d t} \delta \varphi_t  - (Dv_t \delta \varphi_t-D\delta \varphi_t v_t) \right)\,dx \, dt + \int_X \left( \frac{\partial E(\varphi)}{\partial \varphi_1}\cdot \delta \varphi_1 \,dx\right) \\[6pt]
= {} &amp; -\int_0^1 \int_X \left(\frac{d Av_t}{d t}+ad_{v_t}^*(Av_t)\right) \cdot \delta \varphi_t \,dx \,dt + \int_X \left(Av_1 + \frac{\partial E(\varphi)}{\partial \varphi_1} \right) \cdot \delta \varphi_1 \,dx .
\end{align}
&lt;/math&gt;
}}
===Euler–Lagrange geodesic endpoint conditions for image matching===
The earliest [[large deformation diffeomorphic metric mapping]] ([[LDDMM]]) algorithms solved matching problems associated to images and registered landmarks.   are in a vector spaces. The image matching geodesic equation satisfies the classical dynamical equation with endpoint condition. The necessary conditions for the geodesic for image matching takes the form of the classic Equation ({{EquationNote|EL-Classic}}) of Euler–Lagrange with boundary condition:

:&lt;math&gt; \min_{\varphi: \dot \varphi = v_t \circ \varphi_t } C(\varphi) \doteq \frac 1 2 \int_0^1 \int_X Av_t \cdot v_t \,dx\,dt  +\frac 1 2 \int_X |I \circ \varphi_1^{-1}(x) - J(x) |^2 \, dx &lt;/math&gt;
*Necessary geodesic condition:
:: &lt;math&gt;
\begin{cases} &amp;
\dfrac{d}{dt} Av_t +  (Dv_t)^T Av_t +(DAv_t)v_t + ( \nabla \cdot v) Av_t =0  \  ;
\\[4pt]
&amp; Av_1 =(I \circ \varphi_1^{-1} -J) \nabla (I\circ \varphi_1^{-1}) 
\end{cases}
&lt;/math&gt;

===Euler–Lagrange geodesic endpoint conditions for landmark matching===
The registered landmark matching problem satisfies the dynamical equation for generalized functions with endpoint condition:
:&lt;math&gt; \min_{\varphi: \dot \varphi = v_t \circ \varphi_t } C(\varphi) \doteq \frac{1}{2} \int_0^1
   \int_X Av_t \cdot v_t\, dx\,dt  +\frac{1}{2} \sum_i  ( \varphi_1(x_i)-y_i )\cdot ( \varphi_1(x_i)-y_i ) . &lt;/math&gt;
* Necessary geodesic conditions:
:: &lt;math&gt; \begin{cases}
&amp;
\dfrac{d}{dt} Av_t + ad_{v_t}^* (Av_t)=0  \ , \ t \in [0,1] \  ,
\\[4pt]
&amp;
Av_1 = \sum_{i=1}^n \delta_{\varphi_1 (x_i)} (y_i-\varphi_1(x_i))
\end{cases} &lt;/math&gt;
'''Proof:'''&lt;ref name=":6"&gt;M.I. Miller, A. Trouve, L Younes,
On the Metrics and Euler–Lagrange equations of Computational Anatomy,
Annu. Rev. Biomed. Eng. 2002. 4:375–405
doi: 10.1146/annurev.bioeng.4.092101.125733
Copyright °c 2002 by Annual Reviews.
&lt;/ref&gt;

The variation &lt;math&gt; \frac{\partial}{\partial \varphi} E(\varphi) &lt;/math&gt; requires variation of the inverse &lt;math&gt;\varphi^{-1}&lt;/math&gt; generalizes the [[Matrix (mathematics)|matrix]] [[Invertible matrix#Derivative of the matrix inverse|perturbation of the inverse]]  via &lt;math&gt;(\varphi + \varepsilon \delta \varphi \circ \varphi)\circ (\varphi^{-1} + \varepsilon \delta \varphi^{-1} \circ \varphi^{-1}) = \operatorname{id} + o(\varepsilon)&lt;/math&gt; giving  
&lt;math&gt;\delta \varphi^{-1} \circ \varphi^{-1} =-(D \varphi_1^{-1}) \delta \varphi  &lt;/math&gt;
giving

:&lt;math&gt;
\begin{align}
&amp; \frac{d}{d \varepsilon} \frac{1}{2} \left. \int_X | I \circ ( \varphi^{-1} + \varepsilon \delta \varphi^{-1} \circ \varphi^{-1})-J|^2 \, dx\right|_{\varepsilon =0} \\[6pt]
= {} &amp; \int_X (I \circ \varphi^{-1} -J ) \nabla I|_{\varphi^{-1}} (-D \varphi_1^{-1}) \delta \varphi \, dx \\[6pt]
= {} &amp;-\int_X(I \circ \varphi_1^{-1} -J) \nabla (I\circ \varphi_1^{-1}) \delta \varphi \, dx.
\end{align}
&lt;/math&gt;

==References==
{{Reflist}}

==External links==
* [https://web.archive.org/web/20060329103039/http://www.irancaravan.com/Ardabil.htm www.example.com]

&lt;!--- Categories ---&gt;
[[Category:Computational anatomy]]
[[Category:Physics]]
[[Category:Geometry]]
[[Category:Fluid mechanics]]
[[Category:Neural engineering]]
[[Category:Biomedical engineering]]</text>
      <sha1>nwejkxpzeuhvkpmbqrinad4q230fdbv</sha1>
    </revision>
  </page>
  <page>
    <title>Sign-value notation</title>
    <ns>0</ns>
    <id>5984280</id>
    <revision>
      <id>853385559</id>
      <parentid>841761357</parentid>
      <timestamp>2018-08-04T11:44:28Z</timestamp>
      <contributor>
        <ip>111.94.157.142</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2280">{{about|a class of numeral signs|the sociological/economic concept of sign value|Sign value|a representation of signed numbers in computers|Sign-magnitude}}

A '''sign-value notation''' represents numbers by a series of numeric signs that added together equal the number represented.  In [[Roman numerals]] for example, X means ten and L means fifty.  Hence LXXX means eighty (50&amp;nbsp;+&amp;nbsp;10&amp;nbsp;+&amp;nbsp;10&amp;nbsp;+&amp;nbsp;10).  There is no need for zero in sign-value notation.  Sign-value notation was the pre-historic way of writing numbers and only gradually evolved into place-value notation, also known as [[positional notation]].  

When pre-historic people wanted to write "two sheep" in clay, they could inscribe in clay a picture of two sheep.  But this would be impractical when they wanted to write "twenty sheep".  In [[Mesopotamia]] they used small clay tokens to represent a number of a specific commodity, and strung the tokens like beads on a string, which were used for accounting.  There was a token for one sheep and a token for ten sheep, and a different token for ten goats, etc.  To ensure that nobody could alter the number and type of tokens, they invented a clay envelope shaped like a hollow ball into which the tokens on a string were placed and then baked.  If anybody contested the number, they could break open the clay envelope and do a recount.  To avoid unnecessary damage to the record, they pressed archaic number signs on the outside of the envelope before it was baked, each sign similar in shape to the tokens they represented.  Since there was seldom any need to break open the envelope, the signs on the outside became the first written language for writing numbers in clay, using sign-value notation.

==See also==
*[[History of writing ancient numbers]]
*[[Positional_notation|Positional Notation]]

==References==
*Denise Schmandt-Besserat, How Writing Came About, University of Texas Press, 1992, {{ISBN|0-292-77704-3}} (pbk).

==External links==
*[http://www.naughtykitty.org/ Worksheets Kindergarten]
*[https://web.archive.org/web/20070104051643/http://netzreport.googlepages.com/online_converter_for_dec_roman.html  Online Converter] for Decimal/Roman Numerals ([[JavaScript]], [[GPL]])

[[Category:Numeral systems]]

{{number-stub}}</text>
      <sha1>3hzwglkbi0ep8oewoqb59q4sq1q3i5m</sha1>
    </revision>
  </page>
  <page>
    <title>Slope number</title>
    <ns>0</ns>
    <id>36545943</id>
    <revision>
      <id>860954522</id>
      <parentid>845114469</parentid>
      <timestamp>2018-09-24T05:25:44Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Bettina Speckmann]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13108">[[File:Petersen graph with slope number 3.svg|thumb|A drawing of the [[Petersen graph]] with slope number 3]]
In [[graph drawing]] and [[geometric graph theory]], the '''slope number''' of a graph is the minimum possible number of distinct [[slope]]s of edges in a drawing of the graph in which vertices are represented as points in the [[Euclidean plane]] and edges are represented as [[line segment]]s that do not pass through any non-incident vertex.

==Complete graphs==
Although closely related problems in [[discrete geometry]] had been studied earlier, e.g. by {{harvtxt|Scott|1970}} and {{harvtxt|Jamison|1984}},
the problem of determining the slope number of a graph was introduced by {{harvtxt|Wade|Chu|1994}}, who showed that the slope number of an {{mvar|n}}-vertex [[complete graph]] {{math|''K''&lt;sub&gt;''n''&lt;/sub&gt;}} is exactly&amp;nbsp;{{mvar|n}}. A drawing with this slope number may be formed by placing the vertices of the graph on a [[regular polygon]].

==Relation to degree==
The slope number of a graph of maximum degree {{mvar|d}} is clearly at least &lt;math&gt;\lceil d/2\rceil&lt;/math&gt;, because at most two of the incident edges at a degree-{{mvar|d}} vertex can share a slope. More precisely, the slope number is at least equal to the [[linear arboricity]] of the graph, since the edges of a single slope must form a [[linear forest]], and the linear arboricity in turn is at least &lt;math&gt;\lceil d/2\rceil&lt;/math&gt;.

{{unsolved|mathematics|Do the graphs of maximum degree four have bounded slope number?}}
There exist graphs with maximum [[degree (graph theory)|degree]] five that have arbitrarily large slope number.&lt;ref&gt;Proved independently by {{harvtxt|Barát|Matoušek|Wood|2006}} and {{harvtxt|Pach|Pálvölgyi|2006}}, solving a problem posed by {{harvtxt|Dujmović|Suderman|Wood|2005}}. See theorems 5.1 and 5.2 of {{harvtxt|Pach|Sharir|2009}}.&lt;/ref&gt; However, every graph of maximum degree three has slope number at most four;&lt;ref&gt;{{harvtxt|Mukkamala|Szegedy|2009}}, improving an earlier result of {{harvtxt|Keszegh|Pach|Pálvölgyi|Tóth|2008}}; theorem 5.3 of {{harvtxt|Pach|Sharir|2009}}.&lt;/ref&gt; the result of {{harvtxt|Wade|Chu|1994}} for the complete graph {{math|''K''&lt;sub&gt;4&lt;/sub&gt;}} shows that this is tight. Not every set of four slopes is suitable for drawing all degree-3 graphs: a set of slopes is suitable for this purpose if and only it forms the slopes of the sides and diagonals of a [[parallelogram]]. In particular, any degree 3 graph can be drawn so that its edges are either axis-parallel or parallel to the main diagonals of the [[integer lattice]].&lt;ref&gt;{{harvtxt|Mukkamala|Pálvölgyi|2012}}.&lt;/ref&gt; It is not known whether graphs of maximum degree four have bounded or unbounded slope number.&lt;ref&gt;{{harvtxt|Pach|Sharir|2009}}.&lt;/ref&gt;

[[File:KesPacPal-GD-10.svg|thumb|The method of {{harvtxt|Keszegh|Pach|Pálvölgyi|2011}} for combining circle packings and quadtrees to achieve bounded slope number for planar graphs with bounded degree]]

==Planar graphs==
As {{harvtxt|Keszegh|Pach|Pálvölgyi|2011}} showed, every [[planar graph]] has a [[Fáry's theorem|planar straight-line drawing]] in which the number of distinct slopes is a function of the degree of the graph. Their proof follows a construction of {{harvtxt|Malitz|Papakostas|1994}} for bounding the [[Angular resolution (graph drawing)|angular resolution]] of planar graphs as a function of degree, by completing the graph to a [[maximal planar graph]] without increasing its degree by more than a constant factor, and applying the [[circle packing theorem]] to represent this augmented graph as a collection of tangent circles. If the degree of the initial graph is bounded, the ratio between the radii of adjacent circles in the packing will also be bounded,&lt;ref&gt;{{harvtxt|Hansen|1988}}.&lt;/ref&gt; which in turn implies that using a [[quadtree]] to place each graph vertex on a point within its circle will produce slopes that are ratios of small integers. The number of distinct slopes produced by this construction is exponential in the degree of the graph.

==Complexity==
It is [[NP-complete]] to determine whether a graph has slope number two.&lt;ref&gt;{{harvtxt|Formann|Hagerup|Haralambides|Kaufmann|1993}}; {{harvtxt|Eades|Hong|Poon|2010}}; {{harvtxt|Maňuch|Patterson|Poon|Thachuk|2011}}.&lt;/ref&gt; From this, it follows that it is NP-hard to determine the slope number of an arbitrary graph, or to approximate it with an [[approximation ratio]] better than 3/2.

It is also NP-complete to determine whether a planar graph has a planar drawing with slope number two,&lt;ref&gt;{{harvtxt|Garg|Tamassia|2001}}.&lt;/ref&gt;
and hard for the [[existential theory of the reals]] to determine the minimum slope number of a planar drawing.&lt;ref&gt;{{harvtxt|Hoffmann|2016}}.&lt;/ref&gt;

==Notes==
{{reflist|colwidth=30em}}

==References==
{{refbegin|colwidth=30em}}
*{{citation
 | last1 = Barát | first1 = János
 | last2 = Matoušek | first2 = Jiří | author2-link = Jiří Matoušek (mathematician)
 | last3 = Wood | first3 = David R.
 | issue = 1
 | journal = [[Electronic Journal of Combinatorics]]
 | mr = 2200531
 | page = R3
 | title = Bounded-degree graphs have arbitrarily large geometric thickness
 | url = http://www.combinatorics.org/Volume_13/Abstracts/v13i1r3.html
 | volume = 13
 | year = 2006}}.
*{{citation
 | last1 = Dujmović | first1 = Vida
 | last2 = Suderman | first2 = Matthew
 | last3 = Wood | first3 = David R.
 | editor-last = Pach | editor-first = János | editor-link = János Pach
 | contribution = Really straight graph drawings
 | doi = 10.1007/978-3-540-31843-9_14
 | location = Berlin
 | pages = 122–132
 | publisher = Springer-Verlag
 | series = [[Lecture Notes in Computer Science]]
 | title = [[International Symposium on Graph Drawing|Graph Drawing: 12th International Symposium, GD 2004, New York, NY, USA, September 29-October 2, 2004, Revised Selected Papers]]
 | volume = 3383
 | year = 2005| arxiv = cs/0405112}}.
*{{citation
 | last1 = Eades | first1 = Peter | author1-link = Peter Eades
 | last2 = Hong | first2 = Seok-Hee
 | last3 = Poon | first3 = Sheung-Hung
 | editor1-last = Eppstein | editor1-first = David | editor1-link = David Eppstein
 | editor2-last = Gansner | editor2-first = Emden R.
 | contribution = On rectilinear drawing of graphs
 | doi = 10.1007/978-3-642-11805-0_23
 | location = Berlin
 | mr = 2680455
 | pages = 232–243
 | publisher = Springer
 | series = Lecture Notes in Computer Science
 | title = [[International Symposium on Graph Drawing|Graph Drawing: 17th International Symposium, GD 2009, Chicago, IL, USA, September 22-25, 2009, Revised Papers]]
 | volume = 5849
 | year = 2010}}.
*{{citation
 | last1 = Formann | first1 = M.
 | last2 = Hagerup | first2 = T.
 | last3 = Haralambides | first3 = J.
 | last4 = Kaufmann | first4 = M.
 | last5 = Leighton | first5 = F. T. | author5-link = F. Thomson Leighton
 | last6 = Symvonis | first6 = A.
 | last7 = Welzl | first7 = E. | author7-link = Emo Welzl
 | last8 = Woeginger | first8 = G. | author8-link = Gerhard J. Woeginger
 | doi = 10.1137/0222063
 | issue = 5
 | journal = [[SIAM Journal on Computing]]
 | mr = 1237161
 | pages = 1035–1052
 | title = Drawing graphs in the plane with high resolution
 | volume = 22
 | year = 1993}}.
*{{citation
 | last1 = Garg | first1 = Ashim
 | last2 = Tamassia | first2 = Roberto | author2-link = Roberto Tamassia
 | doi = 10.1137/S0097539794277123
 | issue = 2
 | journal = [[SIAM Journal on Computing]]
 | mr = 1861292
 | pages = 601–625
 | title = On the computational complexity of upward and rectilinear planarity testing
 | volume = 31
 | year = 2001}}.
*{{citation
 | last = Hansen | first = Lowell J.
 | issue = 1
 | journal = Complex Variables, Theory and Application
 | mr = 946096
 | pages = 23–30
 | title = On the Rodin and Sullivan ring lemma
 | volume = 10
 | year = 1988
 | doi=10.1080/17476938808814284}}.
*{{citation
 | last = Hoffmann | first = Udo
 | contribution = The planar slope number
 | title = Proceedings of the 28th Canadian Conference on Computational Geometry (CCCG 2016)
 | year = 2016}}.
*{{citation
 | last = Jamison | first = Robert E.
 | doi = 10.1007/BF00147419
 | issue = 1
 | journal = [[Geometriae Dedicata]]
 | mr = 757792
 | pages = 17–34
 | title = Planar configurations which determine few slopes
 | volume = 16
 | year = 1984}}.
*{{citation
 | last1 = Keszegh | first1 = Balázs
 | last2 = Pach | first2 = János | author2-link = János Pach
 | last3 = Pálvölgyi | first3 = Dömötör
 | editor1-last = Brandes | editor1-first = Ulrik
 | editor2-last = Cornelsen | editor2-first = Sabine
 | contribution = Drawing planar graphs of bounded degree with few slopes
 | doi = 10.1007/978-3-642-18469-7_27
 | location = Heidelberg
 | mr = 2781274
 | pages = 293–304
 | publisher = Springer
 | series = Lecture Notes in Computer Science
 | title = [[International Symposium on Graph Drawing|Graph Drawing: 18th International Symposium, GD 2010, Konstanz, Germany, September 21-24, 2010, Revised Selected Papers]]
 | volume = 6502
 | year = 2011| arxiv = 1009.1315}}.
*{{citation
 | last1 = Keszegh | first1 = Balázs
 | last2 = Pach | first2 = János | author2-link = János Pach
 | last3 = Pálvölgyi | first3 = Dömötör
 | last4 = Tóth | first4 = Géza
 | doi = 10.1016/j.comgeo.2007.05.003
 | issue = 2
 | journal = [[Computational Geometry (journal)|Computational Geometry: Theory and Applications]]
 | mr = 2400539
 | pages = 138–147
 | title = Drawing cubic graphs with at most five slopes
 | volume = 40
 | year = 2008}}.
*{{citation
 | last1 = Malitz | first1 = Seth
 | last2 = Papakostas | first2 = Achilleas
 | doi = 10.1137/S0895480193242931
 | issue = 2
 | journal = [[SIAM Journal on Discrete Mathematics]]
 | mr = 1271989
 | pages = 172–183
 | title = On the angular resolution of planar graphs
 | volume = 7
 | year = 1994}}.
*{{citation
 | last1 = Maňuch | first1 = Ján
 | last2 = Patterson | first2 = Murray
 | last3 = Poon | first3 = Sheung-Hung
 | last4 = Thachuk | first4 = Chris
 | editor1-last = Brandes | editor1-first = Ulrik
 | editor2-last = Cornelsen | editor2-first = Sabine
 | contribution = Complexity of finding non-planar rectilinear drawings of graphs
 | doi = 10.1007/978-3-642-18469-7_28
 | location = Heidelberg
 | mr = 2781275
 | pages = 305–316
 | publisher = Springer
 | series = Lecture Notes in Computer Science
 | title = [[International Symposium on Graph Drawing|Graph Drawing: 18th International Symposium, GD 2010, Konstanz, Germany, September 21-24, 2010, Revised Selected Papers]]
 | volume = 6502
 | year = 2011}}.
*{{citation
 | last1 = Mukkamala | first1 = Padmini
 | last2 = Szegedy | first2 = Mario | author2-link = Mario Szegedy
 | doi = 10.1016/j.comgeo.2009.01.005
 | issue = 9
 | journal = [[Computational Geometry (journal)|Computational Geometry: Theory and Applications]]
 | mr = 2543806
 | pages = 842–851
 | title = Geometric representation of cubic graphs with four directions
 | volume = 42
 | year = 2009}}.
*{{citation
 | last1 = Mukkamala | first1 = Padmini
 | last2 = Pálvölgyi | first2 = Dömötör
 | editor1-last = van Kreveld | editor1-first = Marc
 | editor2-last = Speckmann | editor2-first = Bettina | editor2-link = Bettina Speckmann
 | contribution = Drawing cubic graphs with the four basic slopes
 | doi = 10.1007/978-3-642-25878-7_25
 | pages = 254–265
 | publisher = Springer
 | series = Lecture Notes in Computer Science
 | title = [[International Symposium on Graph Drawing|Graph Drawing: 19th International Symposium, GD 2011, Eindhoven, The Netherlands, September 21-23, 2011, Revised Selected Papers]]
 | volume = 7034
 | year = 2012| arxiv = 1106.1973}}.
*{{citation
 | last1 = Pach | first1 = János | author1-link = János Pach
 | last2 = Pálvölgyi | first2 = Dömötör
 | issue = 1
 | journal = [[Electronic Journal of Combinatorics]]
 | mr = 2200545
 | page = N1
 | title = Bounded-degree graphs can have arbitrarily large slope numbers
 | url = http://www.combinatorics.org/Volume_13/Abstracts/v13i1n1.html
 | volume = 13
 | year = 2006}}.
*{{citation
 | last1 = Pach | first1 = János | author1-link = János Pach
 | last2 = Sharir | first2 = Micha | author2-link = Micha Sharir
 | contribution = 5.5 Angular resolution and slopes
 | pages = 126–127
 | publisher = [[American Mathematical Society]]
 | series = Mathematical Surveys and Monographs
 | title = Combinatorial Geometry and Its Algorithmic Applications: The Alcalá Lectures
 | volume = 152
 | year = 2009}}.
*{{citation
 | last = Scott | first = P. R.
 | journal = [[American Mathematical Monthly]]
 | mr = 0262933
 | pages = 502–505
 | title = On the sets of directions determined by {{mvar|n}} points
 | volume = 77
 | year = 1970
 | doi=10.2307/2317384}}.
*{{citation
 | last1 = Wade | first1 = G. A.
 | last2 = Chu | first2 = J.-H.
 | doi = 10.1093/comjnl/37.2.139
 | issue = 2
 | journal = [[The Computer Journal]]
 | pages = 139–142
 | title = Drawability of complete graphs using a minimal slope set
 | volume = 37
 | year = 1994}}.
{{refend}}

[[Category:Graph invariants]]
[[Category:Graph drawing]]
[[Category:Geometric graph theory]]</text>
      <sha1>ccrhylpswdmtnpj0it9j3ne9haasxzk</sha1>
    </revision>
  </page>
  <page>
    <title>Smoothness (probability theory)</title>
    <ns>0</ns>
    <id>24140640</id>
    <revision>
      <id>449735073</id>
      <parentid>350752721</parentid>
      <timestamp>2011-09-11T07:23:42Z</timestamp>
      <contributor>
        <username>CitationCleanerBot</username>
        <id>15270283</id>
      </contributor>
      <minor/>
      <comment>Various citation &amp; identifier cleanup, plus AWB genfixes. Report errors and suggestions at [[User talk:CitationCleanerBot]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1985">In [[probability theory]] and [[statistics]], '''smoothness''' of a [[density function]] is a measure which determines how many times the density function can be differentiated, or equivalently the limiting behavior of distribution’s [[Characteristic function (probability theory)|characteristic function]].

Formally, we call the distribution of a [[random variable]] ''X'' '''ordinary smooth''' of order ''β'' &lt;ref name="fan91"&gt;{{cite journal|last=Fan|first=Jianqing|year=1991|title=On the optimal rates of convergence for nonparametric deconvolution problems|journal=The Annals of Statistics|volume=19|issue=3|pages=1257–1272|jstor=2241949|doi=10.1214/aos/1176348248}}&lt;/ref&gt; if its [[Characteristic function (probability theory)|characteristic function]] satisfies
: &lt;math&gt;d_0 |t|^{-\beta} \leq \varphi_X(t) \leq d_1 |t|^{-\beta} \quad \text{as } t\to\infty&lt;/math&gt;
for some positive constants ''d''&lt;sub&gt;0&lt;/sub&gt;, ''d''&lt;sub&gt;1&lt;/sub&gt;, ''β''. The examples of such distributions are [[Gamma distribution|gamma]], [[Exponential distribution|exponential]], [[Uniform distribution (continuous)|uniform]], etc.

The distribution is called '''supersmooth''' of order ''β'' &lt;ref name="fan91"/&gt;  if its characteristic function satisfies
: &lt;math&gt;d_0 |t|^{\beta_0}\exp\big(-|t|^\beta/\gamma\big) \leq \varphi_X(t) \leq d_1 |t|^{\beta_1}\exp\big(-|t|^\beta/\gamma\big) \quad \text{as } t\to\infty&lt;/math&gt;
for some positive constants ''d''&lt;sub&gt;0&lt;/sub&gt;, ''d''&lt;sub&gt;1&lt;/sub&gt;, ''β'', ''γ'' and constants ''β''&lt;sub&gt;0&lt;/sub&gt;, ''β''&lt;sub&gt;1&lt;/sub&gt;. Such supersmooth distributions have derivatives of all orders. Examples: [[normal distribution|normal]], [[Cauchy distribution|Cauchy]], mixture normal.

== References ==
{{reflist}}

* {{cite book
  | last = Lighthill
  | first = M. J.
  | year = 1962
  | title = Introduction to Fourier analysis and generalized functions
  | publisher = London: Cambridge University Press
  }}

[[Category:Theory of probability distributions]]


{{probability-stub}}</text>
      <sha1>hepkcwoye8wul0okmsvqi691j76jlcl</sha1>
    </revision>
  </page>
  <page>
    <title>Spin squeezing</title>
    <ns>0</ns>
    <id>56072400</id>
    <revision>
      <id>865254516</id>
      <parentid>857924906</parentid>
      <timestamp>2018-10-22T19:05:07Z</timestamp>
      <contributor>
        <username>John of Reading</username>
        <id>11308236</id>
      </contributor>
      <minor/>
      <comment>Typo fixing, replaced: numer → number, aparatuses → apparatuses</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16414">{{Orphan|date=December 2017}}

'''Spin squeezing''' is a quantum process that decreases the variance of one of the angular momentum components in an ensemble of particles with a spin. The quantum states obtained  are called spin squeezed states.&lt;ref&gt;{{Cite journal|date=2011-12-01|title=Quantum spin squeezing|url=https://www.sciencedirect.com/science/article/pii/S0370157311002201|journal=Physics Reports|volume=509|issue=2-3|pages=89–165|doi=10.1016/j.physrep.2011.08.003|issn=0370-1573|arxiv=1011.2978|bibcode=2011PhR...509...89M}}&lt;/ref&gt; Such states can be used for [[quantum metrology]], as they can provide a better precision for estimating a rotation angle than classical interferometers.&lt;ref&gt;{{Cite journal|last=Gross|first=Christian|accessdate=2018-03-16|title=Spin squeezing, entanglement and quantum metrology with Bose–Einstein condensates|url=http://stacks.iop.org/0953-4075/45/i=10/a=103001|journal=Journal of Physics B: Atomic, Molecular and Optical Physics|language=en|volume=45|issue=10|pages=103001|date=2012-05-14|doi=10.1088/0953-4075/45/10/103001|issn=0953-4075|arxiv=1203.5359|bibcode=2012JPhB...45j3001G}}&lt;/ref&gt;

== Mathematical definition ==
Spin squeezed states for an ensemble of spins have been defined analogously to [[squeezed state]]s of a bosonic mode.&lt;ref&gt;{{Cite journal|last=Kitagawa|first=Masahiro|last2=Ueda|first2=Masahito|date=1993-06-01|title=Squeezed spin states|url=https://link.aps.org/doi/10.1103/PhysRevA.47.5138|journal=Physical Review A|volume=47|issue=6|pages=5138–5143|doi=10.1103/PhysRevA.47.5138|bibcode=1993PhRvA..47.5138K}}&lt;/ref&gt; A quantum state always obeys the [[Heisenberg uncertainty]] relation

&lt;math&gt;(\Delta J_x)^2(\Delta J_y)^2 \geqslant \frac 1 4  |\langle J_z \rangle |^2,&lt;/math&gt;

where &lt;math&gt;J_l&lt;/math&gt; are the collective angular momentum components defined as &lt;math&gt;J_l=\sum_n j_l^{(n)}, &lt;/math&gt;  and &lt;math&gt;j_l^{(n)}&lt;/math&gt; are the single particle angular momentum components. The state is spin-squeezed in the &lt;math&gt;x&lt;/math&gt;-direction, if the variance of the &lt;math&gt;x&lt;/math&gt;-component is smaller than the square root of the right-hand side of the inequality above

&lt;math&gt;(\Delta J_x)^2 &lt; \frac 1 2 |\langle J_z \rangle |.&lt;/math&gt;

It is important that &lt;math&gt;z&lt;/math&gt; is the direction of the mean spin. A different definition was based on using states with a reduced spin-variance for metrology.&lt;ref&gt;{{Cite journal|last=Wineland|first=D. J.|last2=Bollinger|first2=J. J.|last3=Itano|first3=W. M.|last4=Moore|first4=F. L.|last5=Heinzen|first5=D. J.|date=1992-12-01|title=Spin squeezing and reduced quantum noise in spectroscopy|url=https://link.aps.org/doi/10.1103/PhysRevA.46.R6797|journal=Physical Review A|volume=46|issue=11|pages=R6797–R6800|doi=10.1103/PhysRevA.46.R6797|bibcode=1992PhRvA..46.6797W}}&lt;/ref&gt;

== Applications in quantum metrology ==
Spin squeezed states can be used to estimate a rotation angle with a precision better than the classical or shot-noise limit. In particular, if the almost maximal mean spin points to the &lt;math&gt;z&lt;/math&gt;-direction, and the state is spin-squeezed in the &lt;math&gt;x&lt;/math&gt;-direction, then it can be used to estimate the rotation angle around the &lt;math&gt;y&lt;/math&gt;-axis. For instance, this can be used for magnetometry.

== Relations to quantum entanglement ==
Spin squeezed states can be proven to be [[Quantum entanglement|entangled]] based on measuring the spin length and the variance of the spin in an orthogonal direction.&lt;ref&gt;{{Cite journal|last=Sørensen|first=A.|last2=Duan|first2=L.-M.|last3=Cirac|first3=J. I.|last4=Zoller|first4=P.|accessdate=2018-03-16|date=2001-01-04 |title=Many-particle entanglement with Bose–Einstein condensates|url=https://www.nature.com/articles/35051038|journal=Nature|language=En|volume=409|issue=6816|pages=63–66|doi=10.1038/35051038|issn=1476-4687|via=|arxiv=quant-ph/0006111}}&lt;/ref&gt; Let us define the spin squeezing parameter

&lt;math&gt;\xi_{\rm s}^2=N\frac{(\Delta J_x)^2} {|\langle J_z \rangle |^2}&lt;/math&gt;,

where &lt;math&gt;N&lt;/math&gt; is the number of the spin-&lt;math&gt;1/2&lt;/math&gt; particles in the ensemble. Then, if &lt;math&gt;\xi_{\rm s}^2&lt;/math&gt; is smaller than &lt;math&gt;1&lt;/math&gt; then the state is entangled. It has also been shown that a higher and higher level of multipartite entanglement is needed to achieve a larger and larger degree of spin squeezing.&lt;ref name=":0"&gt;{{Cite journal|last=Sørensen|first=Anders S.|last2=Mølmer|first2=Klaus|date=2001-05-14|title=Entanglement and Extreme Spin Squeezing|url=https://link.aps.org/doi/10.1103/PhysRevLett.86.4431|journal=Physical Review Letters|volume=86|issue=20|pages=4431–4434|doi=10.1103/PhysRevLett.86.4431|arxiv=quant-ph/0011035|bibcode=2001PhRvL..86.4431S}}&lt;/ref&gt;

== Experiments ==

Experiments have been carried out with cold or even room temperature atomic ensembles.&lt;ref&gt;{{Cite journal|last=Hald|first=J.|last2=Sørensen|first2=J. L.|last3=Schori|first3=C.|last4=Polzik|first4=E. S.|date=1999-08-16|title=Spin Squeezed Atoms: A Macroscopic Entangled Ensemble Created by Light|url=https://link.aps.org/doi/10.1103/PhysRevLett.83.1319|journal=Physical Review Letters|volume=83|issue=7|pages=1319–1322|doi=10.1103/PhysRevLett.83.1319|bibcode=1999PhRvL..83.1319H}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Sewell|first=R. J.|last2=Koschorreck|first2=M.|last3=Napolitano|first3=M.|last4=Dubost|first4=B.|last5=Behbood|first5=N.|last6=Mitchell|first6=M. W.|date=2012-12-19|title=Magnetic Sensitivity Beyond the Projection Noise Limit by Spin Squeezing|url=https://link.aps.org/doi/10.1103/PhysRevLett.109.253605|journal=Physical Review Letters|volume=109|issue=25|pages=253605|doi=10.1103/PhysRevLett.109.253605|arxiv=1111.6969|bibcode=2012PhRvL.109y3605S}}&lt;/ref&gt; In this case, the atoms do not interact with each other. Hence, in order to entangle them, they make them interact with light which is then measured. A 20&amp;nbsp;dB (100 times) spin squeezing has been obtained in such a system.&lt;ref&gt;{{Cite journal|last=Hosten|first=Onur|last2=Engelsen|first2=Nils J.|last3=Krishnakumar|first3=Rajiv|last4=Kasevich|first4=Mark A.|accessdate=2018-03-16|date=2016-01-28|title=Measurement noise 100 times lower than the quantum-projection limit using entangled atoms|url=http://www.nature.com/articles/nature16176|journal=Nature|language=En|volume=529|issue=7587|pages=505–508|doi=10.1038/nature16176|issn=1476-4687|bibcode=2016Natur.529..505H}}&lt;/ref&gt; Simultaneous spin squeezing of two ensembles, which interact with the same light field, has been used to entangle the two ensembles.&lt;ref&gt;{{Cite journal|last=Julsgaard|first=Brian|last2=Kozhekin|first2=Alexander|last3=Polzik|first3=Eugene S.|date=2001-01-27|accessdate=2018-03-16|title=Experimental long-lived entanglement of two macroscopic objects|url=https://www.nature.com/articles/35096524|journal=Nature|language=En|volume=413|issue=6854|pages=400–403|doi=10.1038/35096524|issn=1476-4687}}&lt;/ref&gt; Spin squeezing can be enhanced by using cavities.&lt;ref&gt;{{Cite journal|last=Leroux|first=Ian D.|last2=Schleier-Smith|first2=Monika H.|last3=Vuletić|first3=Vladan|date=2010-02-17|title=Implementation of Cavity Squeezing of a Collective Atomic Spin|url=https://link.aps.org/doi/10.1103/PhysRevLett.104.073602|journal=Physical Review Letters|volume=104|issue=7|pages=073602|doi=10.1103/PhysRevLett.104.073602|arxiv=0911.4065|bibcode=2010PhRvL.104g3602L}}&lt;/ref&gt;

Cold gas experiments have also been carried out with Bose-Einstein Condensates (BEC).&lt;ref&gt;{{Cite journal|last=Estève|first=J.|last2=Gross|first2=C.|last3=Weller|first3=A.|last4=Giovanazzi|first4=S.|last5=Oberthaler|first5=M. K.|accessdate=2018-03-16|date=2008-10-30|title=Squeezing and entanglement in a Bose–Einstein condensate|url=https://www.nature.com/articles/nature07332|journal=Nature|language=En|volume=455|issue=7217|pages=1216–1219|doi=10.1038/nature07332|issn=1476-4687|arxiv=0810.0600|bibcode=2008Natur.455.1216E}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Muessel|first=W.|last2=Strobel|first2=H.|last3=Linnemann|first3=D.|last4=Hume|first4=D. B.|last5=Oberthaler|first5=M. K.|date=2014-09-05|title=Scalable Spin Squeezing for Quantum-Enhanced Magnetometry with Bose-Einstein Condensates|url=https://link.aps.org/doi/10.1103/PhysRevLett.113.103004|journal=Physical Review Letters|volume=113|issue=10|pages=103004|doi=10.1103/PhysRevLett.113.103004|arxiv=1405.6022|bibcode=2014PhRvL.113j3004M}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Riedel|first=Max F.|last2=Böhi|first2=Pascal|last3=Li|first3=Yun|last4=Hänsch|first4=Theodor W.|last5=Sinatra|first5=Alice|last6=Treutlein|first6=Philipp|accessdate=2018-03-16|date=2010-04-22|title=Atom-chip-based generation of entanglement for quantum metrology|url=https://www.nature.com/articles/nature08988|journal=Nature|language=En|volume=464|issue=7292|pages=1170–1173|doi=10.1038/nature08988|issn=1476-4687|arxiv=1003.1651|bibcode=2010Natur.464.1170R}}&lt;/ref&gt; In this case, the spin squeezing is due to the interaction between the atoms.

Most experiments have been carried out using only two internal states of the particles, hence, effectively with spin-&lt;math&gt;1/2&lt;/math&gt; particles. There are also experiments aiming at spin squeezing with particles of a higher spin.&lt;ref&gt;{{Cite journal|last=Hamley|first=C. D.|last2=Gerving|first2=C. S.|last3=Hoang|first3=T. M.|last4=Bookjans|first4=E. M.|last5=Chapman|first5=M. S.|accessdate=2018-03-16|date=2012-02-26|title=Spin-nematic squeezed vacuum in a quantum gas|url=https://www.nature.com/articles/nphys2245|journal=Nature Physics|language=En|volume=8|issue=4|pages=305–308|doi=10.1038/nphys2245|issn=1745-2481|arxiv=1111.1694|bibcode=2012NatPh...8..305H}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Behbood|first=N.|last2=Martin Ciurana|first2=F.|last3=Colangelo|first3=G.|last4=Napolitano|first4=M.|last5=Tóth|first5=Géza|last6=Sewell|first6=R. J.|last7=Mitchell|first7=M. W.|date=2014-08-25|title=Generation of Macroscopic Singlet States in a Cold Atomic Ensemble|url=https://link.aps.org/doi/10.1103/PhysRevLett.113.093601|journal=Physical Review Letters|volume=113|issue=9|pages=093601|doi=10.1103/PhysRevLett.113.093601|arxiv=1403.1964|bibcode=2014PhRvL.113i3601B}}&lt;/ref&gt; Nuclear-electron spin squeezing within the atoms, rather than interatomic spin squeezing, has also been created in room temperature gases.&lt;ref&gt;{{Cite journal|last=Fernholz|first=T.|last2=Krauter|first2=H.|last3=Jensen|first3=K.|last4=Sherson|first4=J. F.|last5=Sørensen|first5=A. S.|last6=Polzik|first6=E. S.|date=2008-08-12|title=Spin Squeezing of Atomic Ensembles via Nuclear-Electronic Spin Entanglement|url=https://link.aps.org/doi/10.1103/PhysRevLett.101.073601|journal=Physical Review Letters|volume=101|issue=7|pages=073601|doi=10.1103/PhysRevLett.101.073601|arxiv=0802.2876|bibcode=2008PhRvL.101g3601F}}&lt;/ref&gt;

Experiments with atomic ensembles usually are usually implemented in free-space with Gaussian laser beams. To enhance the spin squeezing effect towards generating non-Gaussian states,&lt;ref&gt;{{Cite journal|last=Adesso|first=Gerardo|last2=Ragy|first2=Sammy|last3=Lee|first3=Antony R.|date=2014-03-12|title=Continuous Variable Quantum Information: Gaussian States and Beyond|url=http://www.worldscientific.com/doi/abs/10.1142/S1230161214400010|journal=[[Open Systems &amp; Information Dynamics]]|volume=21|issue=1n02|pages=1440001|arxiv=1401.4679|doi=10.1142/S1230161214400010|issn=1230-1612}}&lt;/ref&gt; which are metrologically useful, the free-space apparatuses are not enough. Cavities and nanophotonic waveguides have been used to enhance the squeezing effect with less atoms.&lt;ref name="Chen2014"&gt;{{cite journal |title=Cavity-aided nondemolition measurements for atom counting and spin squeezing |doi=10.1103/PhysRevA.89.043837 |journal=Physical Review A |year=2014 |first1=Zilong |last1=Chen |first2=J. G. |last2=Bohnet |first3=J. M. |last3=Weiner |first4=K. C. |last4=Cox |first5=J. K. |last5=Thompson |volume=89 |issue=4 |page=043837 |accessdate=|arxiv=1211.0723 |bibcode=2014PhRvA..89d3837C }}&lt;/ref&gt;   
For the waveguide systems, the atom-light coupling and the squeezing effect can be enhanced using the evanescent field near to the waveguides, and the type of atom-light interaction can be controlled by choosing a proper polarization state of the guided input light, the internal state subspace of the atoms and the geometry of the trapping shape. Spin squeezing protocols using nanophotonic waveguides based on the birefringence effect&lt;ref name="Qi2016"&gt;{{cite journal |title=Dispersive response of atoms trapped near the surface of an optical nanofiber with applications to quantum nondemolition measurement and spin squeezing |doi=10.1103/PhysRevA.93.023817 |journal=Physical Review A |year=2016 |first1=Xiaodong |last1=Qi |first2=Ben Q. |last2=Baragiola |first3=Poul S. |last3=Jessen |first4=Ivan H. |last4=Deutsch |volume=93 |issue=2 |page=023817 |accessdate=|arxiv=1509.02625 |bibcode=2016PhRvA..93b3817Q }}&lt;/ref&gt; and the Faraday effect&lt;ref name="Qi2018"&gt;{{cite journal |title=Enhanced cooperativity for quantum-nondemolition-measurement–induced spin squeezing of atoms coupled to a nanophotonic waveguide |doi=10.1103/PhysRevA.93.033829 |journal=Physical Review A |first1=Xiaodong |last1=Qi |first2=Yuan-Yu |last2=Jau |first3=Ivan H. |last3=Deutsch |volume=97 |issue=3 |page=033829 |accessdate=|date=2018-03-16|arxiv=1712.02916 |bibcode=2016PhRvA..93c3829K }}&lt;/ref&gt; have been proposed. By optimizing the [[optical depth]] or [[cooperativity]] through controlling the geometric factors mentioned above, the Faraday protocol demonstrates that, to enhance the squeezing effect, one needs to find a geometry that generates weaker local electric field at the atom positions.&lt;ref name="Qi2018"/&gt; This is counterintuitive, because usually to enhance atom-light coupling, a strong local field is required. But it opens the door to perform very precise measurement with little disruptions to the quantum system, which cannot be simultaneously satisfied with a strong field.

== Generalized spin squeezing ==

In entanglement theory, generalized spin squeezing also refers to any criterion that is given with the first and second moments of angular momentum coordinates, and detects entanglement in a quantum state. For a large ensemble of spin-1/2 particles a complete set of such relations have been found,&lt;ref&gt;{{Cite journal|last=Tóth|first=Géza|last2=Knapp|first2=Christian|last3=Gühne|first3=Otfried|last4=Briegel|first4=Hans J.|date=2007-12-19|title=Optimal Spin Squeezing Inequalities Detect Bound Entanglement in Spin Models|url=https://link.aps.org/doi/10.1103/PhysRevLett.99.250405|journal=Physical Review Letters|volume=99|issue=25|pages=250405|doi=10.1103/PhysRevLett.99.250405|arxiv=quant-ph/0702219|bibcode=2007PhRvL..99y0405T}}&lt;/ref&gt; which have been generalized to particles with an arbitrary spin.&lt;ref&gt;{{Cite journal|last=Vitagliano|first=Giuseppe|last2=Hyllus|first2=Philipp|last3=Egusquiza|first3=Iñigo L.|last4=Tóth|first4=Géza|date=2011-12-09|title=Spin Squeezing Inequalities for Arbitrary Spin|url=https://link.aps.org/doi/10.1103/PhysRevLett.107.240502|journal=Physical Review Letters|volume=107|issue=24|pages=240502|doi=10.1103/PhysRevLett.107.240502|arxiv=1104.3147|bibcode=2011PhRvL.107x0502V}}&lt;/ref&gt; Apart from detecting entanglement in general, there are relations that detect multipartite entanglement.&lt;ref name=":0" /&gt;&lt;ref&gt;{{Cite journal|last=Lücke|first=Bernd|last2=Peise|first2=Jan|last3=Vitagliano|first3=Giuseppe|last4=Arlt|first4=Jan|last5=Santos|first5=Luis|last6=Tóth|first6=Géza|last7=Klempt|first7=Carsten|date=2014-04-17|title=Detecting Multiparticle Entanglement of Dicke States|url=https://link.aps.org/doi/10.1103/PhysRevLett.112.155304|journal=Physical Review Letters|volume=112|issue=15|pages=155304|doi=10.1103/PhysRevLett.112.155304|arxiv=1403.4542|bibcode=2014PhRvL.112o5304L}}&lt;/ref&gt; Some of the generalized spin-squeezing entanglement criteria have also a relation to quantum metrological tasks. For instance, planar squeezed states can be used to measure an unknown rotation angle optimally.&lt;ref&gt;{{Cite journal|last=He|first=Q. Y.|last2=Peng|first2=Shi-Guo|last3=Drummond|first3=P. D.|last4=Reid|first4=M. D.|date=2011-08-11|title=Planar quantum squeezing and atom interferometry|url=https://link.aps.org/doi/10.1103/PhysRevA.84.022107|journal=Physical Review A|volume=84|issue=2|pages=022107|doi=10.1103/PhysRevA.84.022107|arxiv=1101.0448|bibcode=2011PhRvA..84b2107H}}&lt;/ref&gt;

== References ==

&lt;references /&gt;

[[Category:Quantum information science]]
[[Category:Quantum optics]]</text>
      <sha1>ohps3vsnff9d14bvl7bvpj3or5x6stq</sha1>
    </revision>
  </page>
  <page>
    <title>Tachytrope</title>
    <ns>0</ns>
    <id>6899692</id>
    <revision>
      <id>575797133</id>
      <parentid>574888113</parentid>
      <timestamp>2013-10-04T23:38:48Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>{{applied-math-stub}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="628">A '''tachytrope''' is a [[curve]] in which the law of the [[velocity]] is given.  It was first used by [[United States|American]] [[mathematician]] [[Benjamin Peirce]] in ''A System of Analytic Mechanics'', first published in 1855.{{Sfn|Peirce|1855|pp=364–370}}

==References==
{{primary sources|date=August 2012}}
{{Reflist}}

;Sources
*{{Cite book |ref=harv |last=Peirce |first=Benjamin |title=A System of Analytic Mechanics |location=Boston |publisher=Little, Brown and Company |year=1855 |pages=364–370 |url=http://www.math.harvard.edu/history/peirce_mechanics/0392.html }}

[[Category:Velocity]]


{{applied-math-stub}}</text>
      <sha1>dfhjxibfh4xjx2owmu2jy5tqpd9uwhx</sha1>
    </revision>
  </page>
  <page>
    <title>Transcomputational problem</title>
    <ns>0</ns>
    <id>31646448</id>
    <revision>
      <id>856992346</id>
      <parentid>818591786</parentid>
      <timestamp>2018-08-28T21:10:49Z</timestamp>
      <contributor>
        <username>InedibleHulk</username>
        <id>877242</id>
      </contributor>
      <minor/>
      <comment>/* Examples of transcomputational problems */ Clearly not examples of how to not lift a sofa.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5866">In [[computational complexity theory]], a '''transcomputational problem''' is a problem that requires processing of more than 10&lt;sup&gt;93&lt;/sup&gt; bits of information.&lt;ref name=Klir&gt;{{cite book|last=Klir|first=George J.|title=Facets of systems science|year=1991|publisher=Springer|isbn=978-0-306-43959-9|pages=121–128}}&lt;/ref&gt; Any number greater than 10&lt;sup&gt;93&lt;/sup&gt; is called a '''transcomputational number'''. The number 10&lt;sup&gt;93&lt;/sup&gt;, called [[Bremermann's limit]], is, according to [[Hans-Joachim Bremermann]], the total number of bits processed by a hypothetical computer the size of the [[Earth]] within a time period equal to the estimated age of the Earth.&lt;ref name="Klir"/&gt;&lt;ref name="Bre"&gt;Bremermann, H.J. (1962) [http://holtz.org/Library/Natural%20Science/Physics/Optimization%20Through%20Evolution%20and%20Recombination%20-%20Bremermann%201962.htm ''Optimization through evolution and recombination''] In: Self-Organizing systems 1962, edited M.C. Yovitts et al., Spartan Books, Washington, D.C. pp. 93–106.&lt;/ref&gt; The term ''transcomputational'' was coined by Bremermann.&lt;ref&gt;{{cite web|last=Heinz Muhlenbein|title=Algorithms, data and hypotheses : Learning in open worlds|url=http://muehlenbein.org/algo95.pdf|publisher=German National Research Center for Computer Science|accessdate=3 May 2011}}&lt;/ref&gt;

==Examples==

===Testing integrated circuits===
Exhaustively testing all combinations of an [[integrated circuit]] with 309 [[Input (computer science)|input]]s and 1 [[Output (computing)|output]] requires testing of a total of 2&lt;sup&gt;309&lt;/sup&gt; combinations of inputs. Since the number 2&lt;sup&gt;309&lt;/sup&gt; is a transcomputational number (that is, a number greater than 10&lt;sup&gt;93&lt;/sup&gt;), the problem of testing such a system of [[integrated circuit]]s is a transcomputational problem. This means that there is no way one can verify the correctness of the circuit for all combinations of inputs through [[Brute-force search|brute force]] alone.&lt;ref name="Klir"/&gt;&lt;ref&gt;{{cite web|last=Miles|first=William|title=Bremermann's Limit|url=http://www.wmiles.com/2010/01/bremermanns-limit|accessdate=1 May 2011}} While the source uses 308 as the number of inputs, this number is based on an error: 2&lt;sup&gt;308&lt;/sup&gt; &lt; 10&lt;sup&gt;93&lt;/sup&gt;.&lt;/ref&gt;

===Pattern recognition===
Consider a ''q''&amp;times;''q'' array of the [[chessboard]] type, each square of which can have one of ''k'' [[color]]s. Altogether there are ''k''&lt;sup&gt;''n''&lt;/sup&gt; [[color]] [[pattern]]s, where ''n'' = ''q''&lt;sup&gt;2&lt;/sup&gt;. The problem of determining the best classification of the patterns, according to some chosen criterion, may be solved by a search through all possible color patterns. For two colors, such a search becomes transcomputational when the array is 18&amp;times;18 or larger. For a 10&amp;times;10 array, the problem becomes transcomputational when there are 9 or more colors.&lt;ref name="Klir"/&gt;

This has some relevance in the physiological studies of the [[retina]]. The retina contains about a million [[Light sensitivity|light-sensitive]] [[Cell (biology)|cell]]s. Even if there were only two possible states for each cell (say, an active state and an inactive state) the processing of the [[retina]] as a whole requires processing of more than 10&lt;sup&gt;300,000&lt;/sup&gt; bits of information. This is far beyond [[Bremermann's limit]].&lt;ref name="Klir"/&gt;

===General systems problems===
A [[system]] of ''n'' variables, each of which can take ''k'' different states, can have 
''k''&lt;sup&gt;''n''&lt;/sup&gt; possible system states. To analyze such a system, a minimum of ''k''&lt;sup&gt;''n''&lt;/sup&gt; bits of information are to be processed. The problem becomes transcomputational when ''k''&lt;sup&gt;''n''&lt;/sup&gt; &gt; 10&lt;sup&gt;93&lt;/sup&gt;. This happens for the following values of ''k'' and ''n'':&lt;ref name="Klir"/&gt;
{| class="wikitable"
|-
| ''k'' || 2 || 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10
|-
| ''n'' || 308 || 194 || 154 || 133 || 119 || 110 || 102 || 97 || 93
|}

==Implications==
The existence of real-world transcomputational problems implies the limitations of computers as data processing tools. This point is best summarized in Bremermann's own words:&lt;ref name="Bre"/&gt;

:"The experiences of various groups who work on problem solving, theorem proving and [[pattern recognition]] all seem to point in the same direction: These problems are tough. There does not seem to be a royal road or a simple method which at one stroke will solve all our problems. My discussion of ultimate limitations on the speed and amount of data processing may be summarized like this: Problems involving vast numbers of possibilities will not be solved by sheer data processing quantity. We must look for quality, for refinements, for tricks, for every ingenuity that we can think of. Computers faster than those of today will be a great help. We will need them. However, when we are concerned with problems in principle, present day computers are about as fast as they ever will be.

:We may expect that the technology of data processing will proceed step by step – just as ordinary technology has done. There is an unlimited challenge for ingenuity applied to specific problems. There is also an unending need for general notions and theories to organize the myriad details."

== In fiction ==
In Douglas Adams's  ''[[Hitchhiker's Guide to the Galaxy|The Hitchhiker's Guide to the Galaxy]]'', Earth is a supercomputer, designed to calculate the question known as the "Ultimate Question of Life, The Universe and Everything" (the answer to which is known to be 42).&lt;ref&gt;See [[Places in The Hitchhiker's Guide to the Galaxy#Earth]]&lt;/ref&gt;

== See also ==
* [[Hypertask]]
* [[Matrioshka brain]], a theoretical computing megastructure 
* [[Strict finitism]]

==References==
{{reflist}}

{{DEFAULTSORT:Transcomputational Problem}}
[[Category:Theory of computation]]
[[Category:Computational complexity theory]]
[[Category:Limits of computation]]</text>
      <sha1>kwiowtomn8uy7dngt59j1c565csmjn3</sha1>
    </revision>
  </page>
  <page>
    <title>William Henry Maule</title>
    <ns>0</ns>
    <id>12809718</id>
    <revision>
      <id>840793872</id>
      <parentid>834074024</parentid>
      <timestamp>2018-05-12T06:01:25Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Speedily moving category Members of the Parliament of the United Kingdom for County Carlow constituencies to [[:Category:Members of the Parliament of the United Kingdom for County Carlow constituencies (1801–1922)‎]] per [[WP:CFDS|CFDS]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4204">{{Use dmy dates|date=November 2014}}
{{Use British English|date=November 2014}}
'''Sir William Henry Maule''' [[Privy Councillor|PC]] (25 April 1788 – 1858) was an [[England|English]] [[lawyer]], [[member of parliament]] and [[judge]].

== Life ==
Maule was born in [[Edmonton]], [[Middlesex]]. His father, Henry, was a [[physician]] and his mother, Hannah ''née'' Rawson, a [[Quaker]]. He was educated at a private school then at [[Trinity College, Cambridge]], where he was [[senior wrangler]] and [[Smith's prize]] winner in 1810 and where he became a [[Fellow#Oxford, Cambridge and Dublin|fellow]] in 1811.&lt;ref&gt;{{acad|id=ML805WH|name=Maule, William Henry}}&lt;/ref&gt;

He initially remained in [[Cambridge]], where he was a close friend of [[Charles Babbage]], and worked as a [[mathematics]] tutor, including [[Edward Ryan (barrister)|Edward Ryan]]&lt;ref name="ODNB"&gt;FitzGerald (2004)&lt;/ref&gt; and [[Cresswell Cresswell]]&lt;ref&gt;Getzler, J. S. (2004) "[http://www.oxforddnb.com/view/article/6673 Cresswell, Sir Cresswell (1793–1863)]", ''[[Oxford Dictionary of National Biography]]'', Oxford University Press, accessed 12 August 2007 {{ODNBsub}}&lt;/ref&gt; among his students. He was offered the post of professor of mathematics at the [[East India College]] but, in 1810, Maule had already entered [[Lincoln's Inn]] with the intention of practising [[law]]. He was [[called to the bar]] in 1814 and began practice in [[commercial law]], especially [[marine insurance]], at [[3 Essex Court]]. Maule was appointed [[King's Council]] in 1833 and in 1835 became counsel to the [[Bank of England]], succeeding [[James Scarlett (judge)|Sir James Scarlett]].&lt;ref name="ODNB"/&gt;

His retention by the bank did not prevent him from acting for [[Nicholas Aylward Vigors]] who faced an [[election petition]] over his [[County Carlow (UK Parliament constituency)|County Carlow]] [[by-election]] victory in February 1837. Maule's success established his reputation in the region and he himself was elected for [[Carlow Borough (UK Parliament constituency)|Carlow Borough]] in the [[United Kingdom general election, 1837]] of August.&lt;ref name="ODNB"/&gt;

Maule was [[knight]]ed and appointed a [[Baron of the Court of the Exchequer]] in 1839, transferring to the [[Court of Common Pleas (England)|Court of Common Pleas]] later that year. He was a practical and knowledgeable judge with a fine judicial sense of humour (witness his pointed opinion in a case of [[Wife selling (English custom)#Separation|wife selling]]). Maule was the only judge to dissent (in part) on the ruling in ''M'Naghten's Case'' (insanity).&lt;ref&gt;http://www.bailii.org/uk/cases/UKHL/1843/J16.html&lt;/ref&gt;
Maule retired from the bench because of poor health in 1855 but became a [[Her Majesty's Most Honourable Privy Council|Privy Councillor]].&lt;ref name="ODNB"/&gt;  Maule never married, sharing a house with his widowed sister, Emma Maria Leathley, and unmarried niece, Emma Leathley. He died at home in [[London]].&lt;ref name="ODNB"/&gt;

== References ==
{{reflist}}

== Bibliography ==
*Obituaries:
**''Law Magazine'', new ser., 5 (1858), 1–34
**''Solicitors' Journal'', 2 (1857–8), 236
**''Law Times'' (23 Jan 1858), 247–8
---- 
* FitzGerald, J. D. (2004) "[http://www.oxforddnb.com/view/article/18369 Maule, Sir William Henry (1788–1858)]", rev. Hugh Mooney, ''[[Oxford Dictionary of National Biography]]'', Oxford University Press, accessed 17 August 2007 {{ODNBsub}}
* {{ cite book | author=Foss, E. | title=A Biographical Dictionary of the Judges of England: From the Conquest to the Present Time 1066-1870 | origyear=1848–64 | year=2006 | isbn=1428629599 | authorlink=Edward Foss }}

==External links==
{{wikiquote}}

{{Authority control}}

{{DEFAULTSORT:Maule, William Henry}}
[[Category:1788 births]]
[[Category:1858 deaths]]
[[Category:English lawyers]]
[[Category:English judges]]
[[Category:Fellows of Trinity College, Cambridge]]
[[Category:UK MPs 1837–41]]
[[Category:Members of the Parliament of the United Kingdom for County Carlow constituencies (1801–1922)]]
[[Category:Senior Wranglers]]
[[Category:Justices of the Common Pleas]]
[[Category:Barons of the Exchequer]]
[[Category:Members of the Privy Council of the United Kingdom]]</text>
      <sha1>1234mrpt42utqb050bgut1i19x0pu61</sha1>
    </revision>
  </page>
  <page>
    <title>−1</title>
    <ns>0</ns>
    <id>449568</id>
    <revision>
      <id>865121865</id>
      <parentid>860272033</parentid>
      <timestamp>2018-10-21T21:47:50Z</timestamp>
      <contributor>
        <username>IntegralPython</username>
        <id>33883676</id>
      </contributor>
      <comment>/* Square roots of −1 */ rewording for clarity.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6474">{{about|the number|the 1963 short story|Minus One|the song|The Negative One}}
{{Infobox number
| number = -1
| cardinal = −1, minus one, {{nowrap|negative one}}
| ordinal = −1st (negative first)
| lang1 = [[Hindu–Arabic numeral system|Arabic]]
| lang1 symbol = −{{resize|150%|١}}
| lang2 = [[Chinese numerals#Negative numbers|Chinese numeral]]
| lang2 symbol = 负一，负弌，负壹
| lang3 = [[Bengali language|Bengali]]
| lang3 symbol = −{{resize|150%|১}}
| lang4 = [[Binary numeral system|Binary]] ([[byte]])
| lang4 symbol = {{aligned table|leftright=y
| [[Signed magnitude|S&amp;M]]: | 100000001&lt;sub&gt;2&lt;/sub&gt;
| [[Two's complement|2sC]]: | 11111111&lt;sub&gt;2&lt;/sub&gt;
}}
| lang5 = [[Hexadecimal|Hex]] ([[byte]])
| lang5 symbol = {{aligned table|leftright=y
| [[Signed magnitude|S&amp;M]]: | 0x101&lt;sub&gt;16&lt;/sub&gt;
| [[Two's complement|2sC]]: | 0xFF&lt;sub&gt;16&lt;/sub&gt;
}}
}}
In [[mathematics]], '''−1''' is the [[additive inverse]] of [[1 (number)|1]], that is, the number that when [[addition|added]] to 1 gives the additive identity element, 0. It is the [[negative number|negative]] [[integer]] greater than negative two (−2) and less than&amp;nbsp;[[0 (number)|0]].

Negative one bears relation to [[Euler's identity]] since ''e''{{sup|''i''{{pi}}}} = −1.

In [[software development]], '''−1''' is a common initial value for integers and is also used to show that [[Sentinel value|a variable contains no useful information]].

In [[programming languages]], '''−1''' can be used to [[array slicing|index]] the last (or 2nd last) item of an [[array data structure|array]], depending on whether 0 or 1 represents the first item.

'''Negative one''' has some similar but slightly different properties to positive one.&lt;ref&gt;[https://books.google.com/books?id=Xrh89dLWZqEC Mathematical analysis and applications]
 By Jayant V. Deshpande, {{ISBN|1-84265-189-7}}&lt;/ref&gt;

== Algebraic properties ==
Multiplying a number by −1 is equivalent to changing the sign on the number. This can be proved using the [[distributive law]] and the axiom that 1 is the multiplicative identity: for ''x'' [[real number|real]], we have

:&lt;math&gt;x+(-1)\cdot x=1\cdot x+(-1)\cdot x=(1+(-1))\cdot x=0 \cdot x=0&lt;/math&gt;

where we used the fact that any real ''x'' times 0 equals 0, implied by [[cancellation property|cancellation]] from the equation

:&lt;math&gt;0\cdot x=(0+0)\cdot x=0\cdot x+0\cdot x \, &lt;/math&gt;

[[File:ImaginaryUnit5.svg|thumb|right|0, 1, −1, '''''[[imaginary unit|i]]''''', and −'''''i''''' in the [[complex plane|complex]] or [[cartesian plane]]]]

In other words,

:&lt;math&gt;x+(-1)\cdot x=0 \, &lt;/math&gt;

so (−1)&amp;nbsp;·&amp;nbsp;''x'', or&amp;nbsp;−''x'', is the arithmetic inverse of ''x''.

=== Square of −1 ===
The [[square (algebra)|square]] of −1, i.e. −1 multiplied by −1, equals 1. As a consequence, a product of two negative real numbers is positive.

For an algebraic proof of this result, start with the equation

:&lt;math&gt;0 =-1\cdot 0 =-1\cdot [1+(-1)]&lt;/math&gt;

The first equality follows from the above result. The second follows from the definition of −1 as additive inverse of 1: it is precisely that number that when added to 1 gives 0. Now, using the distributive law, we see that

:&lt;math&gt;0 =-1\cdot [1+(-1)]=-1\cdot1+(-1)\cdot(-1)=-1+(-1)\cdot(-1)&lt;/math&gt;

The second equality follows from the fact that 1 is a multiplicative identity. But now adding 1 to both sides of this last equation implies

:&lt;math&gt;(-1) \cdot (-1) = 1&lt;/math&gt;

The above arguments hold in any [[ring (mathematics)|ring]], a concept of [[abstract algebra]] generalizing integers and real numbers.

=== Square roots of −1 ===
Although there are no [[Real number| real]] square roots of -1, the [[complex number]] ''[[Imaginary unit|i]]'' satisfies ''i''&lt;sup&gt;2&lt;/sup&gt; = −1, and as such can be considered as a [[square root]] of −1. The only other complex number who's square is 1 is −''i''.&lt;ref&gt;{{cite web|url=http://mathforum.org/library/drmath/view/58251.html |title=Ask Dr. Math |publisher=Math Forum |date= |accessdate=2012-10-14}}&lt;/ref&gt; In the algebra of [[quaternion]]s, which contain the complex plane, [[Quaternion#Square roots of −1|the equation ''x''&lt;sup&gt;2&lt;/sup&gt; = −1 has infinite solutions]].

== Exponentiation to negative integers ==
[[Exponentiation]] of a non-zero real number can be extended to [[Exponentiation#Negative integer exponents|negative integers]]. We make the definition that ''x''&lt;sup&gt;−1&lt;/sup&gt; = {{sfrac|1|''x''}}, meaning that we define raising a number to the power −1 to have the same effect as taking its [[reciprocal (mathematics)|reciprocal]]. This definition is then extended to negative integers preserves the exponential law ''x''&lt;sup&gt;''a''&lt;/sup&gt;''x''&lt;sup&gt;''b''&lt;/sup&gt; = ''x''&lt;sup&gt;(''a'' + ''b'')&lt;/sup&gt; for real numbers ''a'' and ''b''.

Exponentiation to negative integers can be extended to invertible elements of a ring, by defining  ''x''&lt;sup&gt;−1&lt;/sup&gt; as the multiplicative inverse of ''x''.

−1 that appears next to functions or matrices does not mean raising them to the power −1 but their [[inverse functions]] or [[inverse matrices]]. For example, ''f''&lt;sup&gt;−1&lt;/sup&gt;(''x'') is the inverse of ''f''(''x''), or sin&lt;sup&gt;−1&lt;/sup&gt;(''x'') is a notation of [[arcsine]] function.

== Computer representation ==
{{Main|Signed number representations}}
Most computer systems represent negative integers using [[two's complement]]. In such systems, −1 is represented using a bit pattern of all ones. For example, an 8-bit signed integer using two's complement would represent −1 as the bitstring "11111111", or "FF" in [[hexadecimal]] (base 16). If interpreted as an unsigned integer, the same bitstring of ''n'' ones represents 2&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1, the largest possible value that ''n'' bits can hold. For example, the 8-bit string "11111111" above represents 2&lt;sup&gt;8&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1&amp;nbsp;=&amp;nbsp;255.

== Programming languages ==
In some programming languages, when used to [[array slicing|index some data types]] (such as an [[array data structure|array]]), then -1 can be used to identify the very last (or 2nd last) item, depending on whether 0 or 1 represents the first item.
If the first item is indexed by 0, then -1 identifies the last item.
If the first item is indexed by 1, then -1 identifies the second-to-last item.

== See also ==
* [[Menelaus's theorem]]
== References ==
{{Portal|Mathematics}}
{{Reflist}}

[[Category:Integers|-8]]
[[Category:1 (number)|Negative one]]
[[Category:Negative concepts]]</text>
      <sha1>iktl1od8u20fse3g0hrqhau0ajjtonb</sha1>
    </revision>
  </page>
</mediawiki>
