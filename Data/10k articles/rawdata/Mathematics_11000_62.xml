<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>41 (number)</title>
    <ns>0</ns>
    <id>21156145</id>
    <revision>
      <id>871025473</id>
      <parentid>871025236</parentid>
      <timestamp>2018-11-28T13:07:14Z</timestamp>
      <contributor>
        <username>Girth Summit</username>
        <id>6225634</id>
      </contributor>
      <minor/>
      <comment>Reverted 2 edits by [[Special:Contributions/106.192.8.153|106.192.8.153]] ([[User talk:106.192.8.153|talk]]) to last revision by Certes. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9296">{{pp-move-indef}}
{{Example farm|date=March 2010}}
{{Infobox number
| number = 41
| factorization = [[prime number|prime]]
| prime = 13th
| divisor = 1, 41
}}
'''41''' ('''forty-one''') is the [[natural number]] following [[40 (number)|40]] and preceding [[42 (number)|42]].

{{wiktionary|forty-one}}

==In mathematics==
* the 13th smallest [[prime number]]. The next is [[43 (number)|43]], making both [[twin prime]]s.
* the sum of the first six prime numbers (2&amp;nbsp;+&amp;nbsp;3&amp;nbsp;+&amp;nbsp;5&amp;nbsp;+&amp;nbsp;7&amp;nbsp;+&amp;nbsp;11&amp;nbsp;+&amp;nbsp;13).
* the sum of three primes (11&amp;nbsp;+&amp;nbsp;13&amp;nbsp;+&amp;nbsp;17).
* the 12th [[Supersingular prime (moonshine theory)|supersingular prime]]&lt;ref&gt;{{Cite web|url=https://oeis.org/A002267|title=Sloane's A002267 : The 15 supersingular primes|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt;
* a [[Newman–Shanks–Williams prime]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A088165|title=Sloane's A088165 : NSW primes|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt; 
* the smallest [[Sophie Germain prime]] to start a [[Cunningham chain]] of the first kind of three terms, {41, 83, 167}.
* an [[Eisenstein prime]], with no imaginary part and real part of the form&amp;nbsp;3''n''&amp;nbsp;&amp;minus;&amp;nbsp;1.
* a [[Proth prime]] as it is&amp;nbsp; 5&amp;nbsp;&amp;times;&amp;nbsp;2&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;1.&lt;ref&gt;{{Cite web|url=https://oeis.org/A080076|title=Sloane's A080076 : Proth primes|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt;
* the largest [[Lucky numbers of Euler|lucky number of Euler]]: the polynomial {{nowrap|f(''k'') {{=}} ''k''{{sup|2}} − ''k'' + 41}} yields primes for all the integers ''k'' with {{nowrap|1 ≤ ''k'' &lt; 41}}.
* the sum of two squares, 4&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;5&lt;sup&gt;2&lt;/sup&gt;.
* the sum of the sum of the divisors of the first 7 [[positive integers]].
* the smallest integer whose reciprocal has a 5-digit [[repetend]].  That is a consequence of the fact that 41 is a factor of&amp;nbsp;99999.
* a [[centered square number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A001844|title=Sloane's A001844 : Centered square numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt;

==In science==
* The [[atomic number]] of [[niobium]].

===In astronomy===
* [[Messier object]] [[Messier 41|M41]], a [[visual magnitude|magnitude]] 5.0 [[open cluster]] in the [[constellation]] [[Canis Major]].
* The [[New General Catalogue]] object NGC 41, a [[spiral galaxy]] in the [[constellation]] [[Pegasus (constellation)|Pegasus]].

==In music==
* [[Symphony No. 41 (Mozart)|Symphony No. 41]], the longest and last symphony of [[Wolfgang Amadeus Mozart]].
* "[[41 (song)|#41]]", a song by [[Dave Matthews Band]].
* The band [[Sum 41]].
* [[American Skin (41 Shots)]] is a song by [[Bruce Springsteen]] about an immigrant [[Amadou Bailo Diallo|murder victim]] who was shot at 41 times by the [[NYPD]].

== In film ==
* The name of an independent documentary about [[Nicholas O'Neill (writer)|Nicholas O'Neill]], the youngest victim of the [[Station nightclub fire]].
* 2012 Documentary on the life of the 41st President of the United States [[George H. W. Bush]]&lt;ref name="navy"&gt;{{cite web|url=https://www.imdb.com/title/tt2148554/?ref_=sr_2|title=41 (II)|date=|accessdate=June 16, 2013|publisher=[[IMDB]]}}&lt;/ref&gt; 
* [[The Forty-First (1956 film)]]
* [[Charlton Heston]]'s designation as a Roman warship slave in the film ''[[Ben-Hur (1959 film)|Ben-Hur]]''.
* The code number given to [[Tetsuo Shima]] by scientists in the [[manga]] and 1988 [[film]] ''[[Akira (1988 film)|Akira]]''.
* [[Jonathan Pryce]]'s destination level for his apartment in [[Terry Gilliam]]'s ''[[Brazil (1985 film)|Brazil]]''.
* Billy Cole's jersey number in the [[Tony Scott]] film ''[[The Last Boy Scout]]''.
* In the feature film ''[[The Matrix]]'', Morpheus is aggressively questioned in the 41st floor of the government building, in reference to the murder of [[Amadou Diallo]].&lt;ref&gt;Boyd, M. J. "The African American Presence and the Resolution of Race in The Matrix Trilogy." ''Black Renaissance''. 3 (2004): 134&lt;/ref&gt;
* The victim number that appears on Dr. Lucy Lynskey's forehead in the [[Peter Jackson]] film ''[[The Frighteners]]''.
* The precinct number that appears on the NYC police car in the film ''[[Ghostbusters]]'' during the earthquake moment of the film's climax.
* The district number where the "zombie virus" reappears in the film ''[[Doomsday (2008 film)|Doomsday]]''.
* The distance in kilometers when Ripcord and Duke from the 2009 film ''[[G.I. Joe: The Rise of Cobra]]'' realize that their escort mission is in jeopardy.
* The restricted penthouse level of Lady Tanaka's Yakuza hideout in ''[[The Punisher (1989 film)]]''.
* In the 1959 [[Alfred Hitchcock]] film ''[[North by Northwest]]'', [[Cary Grant]] is attacked by a crop-dusting airplane at Prairie Corners on Highway 41.
*The truck driver number, in the ''[[Knight Rider (1982 TV series)]]'' pilot, who agrees to a $25,000 cash reward for 'smashing head on' into Michael Knight and ''[[KITT]]'' during the finale.
*In ''[[The Expendables (2010 film)]]'', the number of soldiers actor [[Eric Roberts]] laments to his subordinates about having been killed by star [[Sylvester Stallone]] in his escape from their island.
*The reported number of survivors aboard the USS Neptune, in the 1978 disaster film ''[[Gray Lady Down]]'', upon its initial depth position of 1,450 feet

==In sports==
* The race number worn by Sir Roger Bannister when he broke the mythical 4-minute mile barrier in 1954.&lt;ref&gt;[https://www.telegraph.co.uk/news/5050286/Roger-Bannister-makes-history---but-whos-the-guy-on-the-mobile-phone.html Telegraph.co.uk]&lt;/ref&gt;

==In other fields==
* The model number of the [[HP-41]]C/CV/CX.
* The [[List of country calling codes|international direct dialing]] (IDD) code for Switzerland.&lt;ref&gt;{{cite web|url=http://www.bakom.admin.ch/themen/telekom/00479/00604/index.html?lang%3Den |title=Archived copy |accessdate=2009-05-05 |deadurl=yes |archiveurl=https://web.archive.org/web/20100715142107/http://www.bakom.admin.ch/themen/telekom/00479/00604/index.html?lang=en |archivedate=2010-07-15 |df= }}&lt;/ref&gt;
* [[C-41 process]] is the [[film developing]] process for 35mm color negative film.
* Bush 41, [[George H. W. Bush]], the 41st [[President of the United States]].&lt;ref&gt;{{ cite book | last=Kellogg | first=William O. | title= Barron's AP United States History | page=364 | year= 2010 | edition=9th | publisher=Barron's Educational Series | isbn= 9780764141843 | url= https://books.google.com/books?id=K-M7tOXlC40C&amp;pg=PA364&amp;dq=George+H+W+Bush+%22Bush+41%22+%22Bush+43%22&amp;hl=en&amp;sa=X&amp;ei=3eXQT6fBEIek8gTkyI2_AQ&amp;ved=0CF8Q6AEwBjgK#v=onepage&amp;q=George%20H%20W%20Bush%20%22Bush%2041%22%20%22Bush%2043%22&amp;f=false | quote=''George H. W. Bush'' (Republican) [Bush 41—i.e., the first president Bush, George H. W. Bush was the forty-first President of the United States, and so some have referred to him in this way since the election of his son, George W. Bush or Bush 43—the forty-third president of the United States.]}}&lt;/ref&gt;
* In the 1994 [[arcade game]] ''[[Daytona USA (arcade game)|Daytona USA]]'', the player racing team, Team Hornet, has a race number of 41. It is also continued in the 1998 arcade game ''[[Daytona USA 2]]'', where it is applied to three more player cars. The number 41 does not appear on the player cars on linked cabinets for both games. The Hornet, driven by AGES in ''[[Sonic &amp; All-Stars Racing Transformed]]'', also used the number 41.
* In Mexico "cuarenta y uno" (41) is slang referring to a [[homosexual]]. This is due to the 1901 arrest of 41 homosexuals at a hotel in [[Mexico City]] during the government of Porfirio Díaz (1876–1911). See: [[Dance of the Forty-One]]&lt;ref&gt;{{Cite web |url=http://www.chavodel8.com/mexicanismos/numero-41.php |title=Reference 1 |access-date=2008-06-13 |archive-url=https://web.archive.org/web/20080531085502/http://www.chavodel8.com/mexicanismos/numero-41.php |archive-date=2008-05-31 |dead-url=yes |df= }}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://www.islaternura.com/APLAYA/HOMOenHISTORIA/HomoHistoria2005/Los%2041%20en%20mexico/En%20el%20centenario%20de%20los%2041%20Diciembre2005.htm |title=Reference 2 |access-date=2008-06-13 |archive-url=https://web.archive.org/web/20071130032556/http://www.islaternura.com/APLAYA/HOMOenHISTORIA/HomoHistoria2005/Los%2041%20en%20mexico/En%20el%20centenario%20de%20los%2041%20Diciembre2005.htm |archive-date=2007-11-30 |dead-url=yes |df= }}&lt;/ref&gt;
* The number of the French department [[Loir-et-Cher]].
* The number of members in the [[U.S. Senate]] needed to defeat a [[cloture]] vote and sustain a [[filibuster]] indefinitely.
* Number of ballistic missile submarines of the [[George Washington class submarine|George Washington class]] and its successors, collectively known as the "[[41 for Freedom]]".
* Some [[10 mm caliber]] firearm cartridges are denoted as ".41," the decimal inch equivalent.

==References==
&lt;references/&gt;

{{Integers|zero}}

{{DEFAULTSORT:41 (Number)}}
[[Category:Integers]]</text>
      <sha1>fx3i3kzml0tw1pod7mkqnflaxi3awtg</sha1>
    </revision>
  </page>
  <page>
    <title>Alethic modality</title>
    <ns>0</ns>
    <id>2304796</id>
    <revision>
      <id>747979378</id>
      <parentid>654830168</parentid>
      <timestamp>2016-11-05T16:12:59Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */clean up; http&amp;rarr;https for [[Google Books]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2784">{{for|the concept in modal logic|Subjunctive possibility}}

'''Alethic modality''' (from Greek [[Aletheia|ἀλήθεια]] = truth) is a [[linguistic modality]] that indicates modalities of truth, in particular the modalities of logical necessity, possibility or impossibility.&lt;ref name="SIL"&gt;{{cite web|url=http://www.sil.org/linguistics/GlossaryOflinguisticTerms/WhatIsAlethicModality.htm|title=What is alethic modality?|publisher=SIL International|work=Glossary of linguistic terms|last=Loos|first=Eugene E.|author2=Susan Anderson|author3= Dwight H. Day, Jr.|author4= Paul C. Jordan|author5= J. Douglas Wingate|accessdate=2010-01-03}}&lt;/ref&gt;

Alethic modality is often associated with [[epistemic modality]] in research, and it has been questioned whether this modality should be considered distinct from epistemic modality which denotes the speaker's evaluation or judgment of the truth. The criticism states that there is no real difference between "the truth in the world" (alethic) and "the truth in an individual's mind" (epistemic).&lt;ref&gt;{{cite book|last=Eschenroeder|first=Erin|author2=Sarah Mills|author3= Thao Nguyen|title=The Expression of Modality|editor=William Frawley|publisher=Mouton de Gruyter|date=2006-09-30|series=The Expression of Cognitive Categories|pages=8–9|url=https://books.google.com/books?id=72URszHq2SEC&amp;pg=PT18|isbn=3-11-018436-2|accessdate=2010-01-03}}&lt;/ref&gt; An investigation has not found a single language in which alethic and epistemic modalities would be formally distinguished, for example by the means of a [[grammatical mood]].&lt;ref&gt;{{cite book|last=Nuyts|first=Jan|title=Epistemic Modality, Language, and Conceptualization: A Cognitive-pragmatic Perspective|publisher=John Benjamins Publishing Co|date=November 2000|series=Human Cognitive Processing|page=28|isbn=90-272-2357-2}}&lt;/ref&gt;  In such a language, "A circle can't be square", "can't be" would be expressed by an alethic mood, whereas for "He can't be that wealthy", "can't be" would be expressed by an epistemic mood. As we can see, this is not a distinction drawn in English grammar.

"You can't give these plants too much water." is a well-known play on the distinction between perhaps alethic and hortatory or injunctive modalities. The dilemma is fairly easily resolved when listening through paralinguistic cues and particularly suprasegmental cues (intonation).  So while there may not be a morphologically based alethic mood, this does not seem to preclude the usefulness of distinguishing between these two types of modes.  Alethic modality might then concern what are considered to be [[apodicticity|apodictic]] statements.

==References==
{{reflist}}

{{Grammatical moods}}

{{DEFAULTSORT:Alethic Mood}}
[[Category:Grammatical moods]]
[[Category:Modal logic]]

{{ling-stub}}</text>
      <sha1>8gyeyo0zwt4d33gf86of4uuzovstdi8</sha1>
    </revision>
  </page>
  <page>
    <title>Archibald Smith</title>
    <ns>0</ns>
    <id>14091966</id>
    <revision>
      <id>850299553</id>
      <parentid>850299156</parentid>
      <timestamp>2018-07-15T00:54:51Z</timestamp>
      <contributor>
        <username>Stephencdickson</username>
        <id>11716108</id>
      </contributor>
      <comment>/* Early life and education */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5136">{{Use dmy dates|date=March 2018}}
{{Use British English|date=March 2018}}
{{other people}}
[[File:Archibald Smith.jpg|thumb|right|200px|[[Carte de visite]] depicting Archibald Smith, 1860s.]]
'''Archibald Smith of Jordanhill''' {{post-nominals|country=GBR|FRS|FRSE}} (10 August 1813, in [[Greenhead (Wishaw)|Greenhead]], [[North Lanarkshire]] &amp;ndash; 26 December 1872, in London) was a [[Scottish people|Scots-born]] barrister and amateur mathematician.

==Early life and education==
He was the only son of [[James Smith of Jordanhill|James Smith]] [[FRSE]] (1782-1867), a wealthy merchant and antiquary and owner of the [[Jordanhill College|Jordanhill estate]] in [[Glasgow]],&lt;ref name=Curiosities&gt;George Stewart, [http://gdl.cdlr.strath.ac.uk/stecit/stecit14090.htm 'Archibald Smith'], in ''Curiosities of Glasgow Citizenship'', 1881, p. 238&lt;/ref&gt; and his wife Mary Wilson, granddaughter of [[Alexander Wilson (mathematician)|Alexander Wilson]], professor of astronomy in [[Glasgow University]] (and brother of [[Patrick Wilson (astronomer)|Patrick Wilson]]). He was educated at the [[Redland, Bristol|Redland School]] near Bristol from 1826 to 1828.

Archibald studied Law at Glasgow University from 1828, and then at [[Trinity College, Cambridge]], where he was [[Senior Wrangler]], said to be the first Scot to achieve this position,&lt;ref name=Curiosities/&gt; and first [[Smith's prize]]man in 1836, elected a fellow of Trinity College.&lt;ref&gt;{{acad|id=SMT832A|name=Smith, Archibald}}&lt;/ref&gt;  He was one of the founders of the ''[[Cambridge Mathematical Journal]]''. He graduated BA in 1836 and MA in 1839.

==Career as lawyer==
He entered [[Lincoln's Inn]], and was called to the bar as a barrister in 1841. He then practised as an equity draughtsman and property lawyer in [[London]].

==Career as scientist==
His scientific work was mainly in the field of applications of [[magnetism]] and the [[Earth's magnetic field]]. He obtained practical formulae for the correction of magnetic compass observations made on board ship, which General Sir [[Edward Sabine]] published in the ''[[Philosophical Transactions of the Royal Society|Transactions]]'' of the Royal Society: Smith later made convenient tables.  In 1859 he edited [[William Scoresby]]'s ''Journal of a Voyage to Australia for Magnetical Research'' and gave an exact formula for the effect of the iron of a ship on the compass. In 1862, in conjunction with the hydrographer [[Frederick John Owen Evans|Sir Frederick John Owen Evans]] FRS (1815-1885), then superintendent of the compass department of the navy, he published an ''Admiralty Manual for ascertaining and applying the Deviations of the Compass caused by the Iron in a Ship''.&lt;ref&gt;[[James Clerk Maxwell|J. C. Mawell]], [[s:A Treatise on Electricity and Magnetism|''A Treatise on Electricity and Magnetism'']], Volume 2, section 441.&lt;/ref&gt;

He was elected a Fellow of the [[Royal Society of Edinburgh]] in 1837 his proposer being [[James David Forbes]].&lt;ref&gt;http://www-groups.dcs.st-and.ac.uk/~history/Societies/FRSE.html&lt;/ref&gt; Elected a [[Fellow of the Royal Society]] in June 1856, he was awarded its [[Royal Medal]] in 1865 "for his papers in the Philosophical Transactions and elsewhere, on the magnetism of ships".&lt;ref&gt;http://www.royalsoc.ac.uk/page.asp?id=1753&lt;/ref&gt;  In 1866 Emperor [[Alexander II of Russia]] presented him with a gold compass, set in diamonds, and emblazoned with the Imperial Arms.

He died in London on 26 December 1872.

==Personal life==
In 1853, Smith married Susan Emma Parker, daughter of [[James Parker (judge)|Sir James Parker]] of [[Rothley Temple]], Leicestershire, and Mary [[Babington family|Babington]]. They had six sons and two daughters:

*[[James Parker Smith]] [[FRSE]] (1854–1929) M.P. for [[Partick (UK Parliament constituency)|Partick]], [[Lanarkshire]]
*Rev. Walter Edward Smith (1855–1940), vicar at Andover
*Lt. Com. Charles Stewart Smith (1859–1934), Royal Navy officer, Consul-General to Barcelona
*[[Arthur Smith (curator)|Arthur Hamilton Smith]] (1860–1941), museum curator and archaeologist
*Sir [[Henry Babington Smith]] (1863–1923), prominent civil servant and banker
*Mary Susan Smith (1865–1915)
*Margaret Smith  (1867–1904)
*Brig. Gen. George Edward Smith (1868–1944)

==Notes==
{{reflist}}

==References==
*{{DNB Cite|wstitle=Smith, Archibald}}
* Obituary notice by "W.T." ([[Lord Kelvin]]), Proceedings of the Royal Society '''22''' (1873-1874) pp.&amp;nbsp;1-xxiv {{jstor|112889}} (the first known occurrence of the phrase ''[[harmonic analysis]]'' is on p.vi [http://members.aol.com/jeff570/h.html])

{{Authority control}}

{{DEFAULTSORT:Smith, Archibald}}
[[Category:1813 births]]
[[Category:1872 deaths]]
[[Category:Alumni of the University of Glasgow]]
[[Category:Alumni of Trinity College, Cambridge]]
[[Category:Fellows of Trinity College, Cambridge]]
[[Category:19th-century British mathematicians]]
[[Category:Scottish mathematicians]]
[[Category:Members of Lincoln's Inn]]
[[Category:Fellows of the Royal Society of Edinburgh]]
[[Category:Fellows of the Royal Society]]
[[Category:Royal Medal winners]]
[[Category:Senior Wranglers]]</text>
      <sha1>hkvh97eb790k6f50tof7pjjmgecremh</sha1>
    </revision>
  </page>
  <page>
    <title>Bruce Harding</title>
    <ns>0</ns>
    <id>13100627</id>
    <revision>
      <id>859722849</id>
      <parentid>748935202</parentid>
      <timestamp>2018-09-15T21:54:03Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* Further reading */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2896">'''Bruce Harding''' is a [[gemstone]] cutter and mechanical design [[engineer]] and [[mathematician]].  He received the Lapidary Award of the Eastern Federation of the Mineralogical and Lapidary Society in 1975. That same year, in an article on "Faceting Limits" in ''Gems and Gemology'', the magazine of the [[Gemological Institute of America]], he identified the effect of an observer's head blocking rays of illumination for the main facets of a number of gem materials, including [[diamonds]].&lt;ref&gt;[http://www.gemology.ru/cut/english/faceting Faceting Limits]&lt;/ref&gt; In 1986 Harding developed one of the earliest software programs to perform ray path analysis. Harding was a speaker at the [[International Diamond Cut Conference (IDCC)]] in Moscow in 2004.&lt;ref&gt;[http://www.cutstudy.com/conference/program.htm 1st International Diamond Cut Conference&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

A translator of "Angewandte Getribelehre" to "Applied Kinematics", McGraw-Hill 1967.

Translator of Russian to "Optimizing Faceting for Beauty", British 'Journal of Gemmology', Jan.2004.

U.S. valve patents 4,326,754 &amp; 4,632,140A.

==References==
{{Reflist}}

===Further reading===
;Gemology articles:
*[http://www.gemology.ru/cut/english/tolkow2/_1.htm Gemology.ru: Diamond Design Revisited]
*[http://journal.pricescope.com/Articles/46/1/Fractioning-of-Color-by-a-Gem.aspx Pricescope.com: Fractioning of Color by a Gem]
*[http://journal.pricescope.com/Articles/36/1/Cutting-Ovals.aspx Pricescope.com: Cutting Ovals]
*[http://journal.pricescope.com/Articles/33/1/Scallops.aspx Pricescope.com: Scallops]
*[http://journal.pricescope.com/Articles/29/1/Grading-the-Princess-Cut.aspx Pricescope.com: Grading the Princess Cut]
*"Orientation of Optical Effects in Cabochons",  'Vestnik Gemmologii', No.10, 2003 {{ru icon}}
* Articles in circa 1973-1980 issues of: "[[Lapidary Journal Jewelry Artist|Lapidary Journal]]" &amp; "Rock &amp; Gem Magazine".

;Mechanical engineering−mathematics articles:
*"A Derivation of Grashov's Law", Mechanical Engineering News, circa 1960 — ''uses an interesting manipulation of absolutes and inequalities''.
*"Hesitation", ASME Kinematics Conference 1964 — ''shows approximate dwells in mechanisms and theory of consecutive zero derivatives; discusses analysis of 'chain derivatives' in composite mechanisms and motions''.
*"Inverse Derivatives", Mechanical Engineering News, circa 1965 — ''uses dimensional notation and showed usefulness on inverse functions''.
*"Proposed System for Notation and Classification of the Four-bar Linkage", ASME Paper 57F28 (1957).


{{authority control}}

{{DEFAULTSORT:Harding, Bruce}}
[[Category:American mathematicians]]
[[Category:American mechanical engineers]]
[[Category:Gemologists]]
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:Place of birth missing (living people)]]


{{mathematician-stub}}</text>
      <sha1>4nh5hbglqcyl64u57wztuamvbzmddew</sha1>
    </revision>
  </page>
  <page>
    <title>CRESTA</title>
    <ns>0</ns>
    <id>8050713</id>
    <revision>
      <id>754112683</id>
      <parentid>739117532</parentid>
      <timestamp>2016-12-10T22:45:43Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed parent category of [[Category:Actuarial science]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5244">[[File:cresta map gulf of mexico.png|thumb|Map sample of the CRESTA system. It shows individual zones in the Gulf of Mexico region; within a zone the risk is for insurance considered to be equal.]]
'''CRESTA (Catastrophe Risk Evaluation and Standardizing Target Accumulations)''' was founded as a joint project of [[Swiss Re|Swiss Reinsurance Company]], Gerling-Konzern Globale Reinsurance Company, and [[Munich Re|Munich Reinsurance Company]]. CRESTA has set itself the aim of establishing a globally uniform system for the accumulation risk control of natural hazards - particularly [[earthquakes]], [[storms]] and [[floods]]. Those risk zones are essentially based on the observed and expected seismic activity, as well as on other natural disasters, such as droughts, floods and storms. CRESTA zones regard the distribution of insured values within a region or country for easier assessment of risks. CRESTA Zones are the essential basis for reinsurance negotiation and portfolio analysis. Nowadays, CRESTA sets widely accepted standards which apply throughout the international [[insurance industry]]. CRESTA zone information is used by most insurers for assessing the insurance catastrophe premiums they will charge.

==Origin of the name==

While the acronym CRESTA stands for '''Catastrophe Risk Evaluation and Standardizing Target Accumulations''', the name was derived from the name of the hotel (Cresta Hotel) where the founding meeting occurred, and the subsequent creation of a suitable acronym to correspond to the name.

==About CRESTA==
[[File:cresta map worldwide.png|thumb|Overview of the worldwide CRESTA (Catastrophe Risk Evaluating and Standardizing Target Accumulations)coverage.]]
CRESTA has set itself the aim of establishing a globally uniform system for the accumulation risk control of natural hazards - particularly earthquakes, storms and floods. Nowadays, widely accepted standards apply throughout the international insurance industry.  CRESTA's main tasks are:

* Determining country-specific zones for the uniform and detailed reporting of accumulation risk data relating to natural hazards and creating corresponding zonal maps for each country.
* Drawing up standardised accumulation risk-recording forms for each country.
* Working out a uniform format for the processing and electronic transfer of accumulation risk data between insurance and reinsurance companies.

In addition, CRESTA also undertakes the following activities:
* Collating relevant scientific and insurance-related data dealing with insurance and natural phenomena in a written record.
* Collecting summaries of information dealing with natural phenomena for each country, in particular relating to earthquakes.
* Collecting information on natural hazards for each country which is of relevance to the insurance and reinsurance industry.

As of 18.8.2008 http://www.cresta.org/)

==Hazard and Disaster Risk Assessment==

There is basically no [[risk]] that cannot be insured against, however it is difficult to assess how risky it is to give out insurance contracts to customers and to assess for insurance providers how high their rates should be. One main indicator for every insurer is the premiums that are paid for their [[reinsurance]]. When applying for reinsurance the forms will often be based on the [[Catastrophe modeling|models]] provided by CRESTA. CRESTA (Catastrophe Risk Evaluating and Standardising Target Accumulations) is an independent group led by Munich Re and Swiss Re which promotes the accurate and efficient mapping and evaluation of catastrophe perils. CRESTA furthermore and most importantly established a worldwide zone classification used within the insurance industry, the CRESTA Zones. The CRESTA Zones are defined for much of the world down to [[postcode]] level. CRESTA Zones can form the basis of reinsurance negotiation and [[Portfolio (finance)|portfolio]] analysis.

In order for an insurer to calculate the risk distribution in their portfolio for each natural disaster type, accumulations of insured property in individual CRESTA Zones will be taken into account.

In [[seismic risk]] analysis, for example, a successful loss estimation of insured and reinsured values depends on the seismic hazard analysis, on the vulnerability of facilities and on the ability to calculate the earthquake risk premium, also known as average annual loss (AAL).  CRESTA is simply one of the biggest, if not the most comprehensive and most actual information resource for natural risks and hazards.

On the downside, CRESTA specific [[information]] is not available freely. CRESTA zone information can either be bought directly from CRESTA or bundled with [[map]] systems.

==Sources==

Information about CRESTA:

CRESTA Organisation, http://www.cresta.org

What are CRESTA Zones? https://www.europa.uk.com/what-are-cresta-zones/

New 2013 CRESTA zones improve natural hazard risk management, https://www.europa.uk.com/article-2013-cresta-zones/

GfK GeoMarketing, http://www.gfk-geomarketing.com/cresta_zones

Europa Technologies, https://www.europa.uk.com/global-map-data/global-cresta-plus/

{{DEFAULTSORT:Cresta, Catastrophe Risk Evaluating And Standardizing Target Accumulations}}
[[Category:Actuarial science]]</text>
      <sha1>9bg83jwqk0w97bn838xfycy8lgn4h7u</sha1>
    </revision>
  </page>
  <page>
    <title>Cantor's theorem</title>
    <ns>0</ns>
    <id>341442</id>
    <revision>
      <id>871630165</id>
      <parentid>868623741</parentid>
      <timestamp>2018-12-02T11:59:49Z</timestamp>
      <contributor>
        <ip>2600:1700:B850:561F:0:0:0:D31</ip>
      </contributor>
      <comment>"recursively" is incorrect here---you want a synonym for "repeatedly" or "iteratively"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19844">{{For|other theorems bearing Cantor's name}}
[[File:Hasse diagram of powerset of 3.svg|thumb|The cardinality of the set {''x'', ''y'', ''z''}, is three, while there are eight elements in its power set (3 &lt; 2&lt;sup title="Order theory"&gt;3&lt;/sup&gt; = 8), here [[order theory|ordered]] in respect to [[Inclusion (set theory)|inclusion]].]]

In elementary [[set theory]], '''Cantor's theorem''' is a fundamental result that states that, for any [[Set (mathematics)|set]] &lt;math&gt;A&lt;/math&gt;, the set of all [[subset]]s of &lt;math&gt;A&lt;/math&gt; (the [[power set]] of &lt;math&gt;A&lt;/math&gt;, denoted by &lt;math&gt;\mathcal{P}(A)&lt;/math&gt;) has a strictly greater [[cardinality]] than &lt;math&gt;A&lt;/math&gt; itself. For [[finite set]]s, Cantor's theorem can be seen to be true by simple [[enumeration]] of the number of subsets. Counting the empty subset, a set with &lt;math&gt;n&lt;/math&gt; members has &lt;math&gt;2^n&lt;/math&gt; subsets, so that if &lt;math&gt;{\rm card}(A) = n,&lt;/math&gt; then &lt;math&gt;{\rm card}(\mathcal{P}(A)) = 2^n&lt;/math&gt;, and the theorem holds because &lt;math&gt;2^n &gt; n&lt;/math&gt; is true for all [[non-negative integers]].

Much more significant is Cantor's discovery of an argument that is applicable to any set, which showed that the theorem holds for [[infinite set|infinite]] sets, countable or uncountable, as well as finite ones.  As a particularly important consequence, the power set of the set of [[natural number]]s, a [[countably infinite]] set with cardinality ℵ&lt;sub&gt;0&lt;/sub&gt; = card(ℕ), is [[uncountable set|uncountably infinite]] and has the same size as the set of real numbers, a cardinality often referred to as the [[cardinality of the continuum]]: 𝔠 = card(ℝ) = card(𝒫(ℕ)).  The relationship between these cardinal numbers is often expressed symbolically by the equality &lt;math&gt;\mathfrak{c}=2^{\aleph_0}&lt;/math&gt;.

The theorem is named for [[Germany|German]] [[mathematician]] [[Georg Cantor]], who first stated and proved it at the end of the 19th century.  Cantor's theorem had immediate and important consequences for the philosophy of mathematics.  For instance, by iteratively taking the power set of an infinite set and applying Cantor's theorem, we obtain an endless hierarchy of infinite cardinals, each strictly larger than the one before it.  Consequently, the theorem implies that there is no largest cardinal number (colloquially, "there's no largest infinity").

==Proof==
Cantor's argument is elegant and remarkably simple.  The complete proof is presented below, with detailed explanations to follow.

{{quotebox|quote='''Theorem (Cantor).''' Let &lt;math&gt;f&lt;/math&gt; be a map from set &lt;math&gt;A&lt;/math&gt; to its power set &lt;math&gt;\mathcal{P}(A)&lt;/math&gt;.  Then &lt;math&gt;f:A\to\mathcal{P}(A)&lt;/math&gt; is not surjective.  As a consequence, &lt;math&gt;\mathrm{card}(A)&lt;\mathrm{card}(\mathcal{P}(A))&lt;/math&gt; holds for any set &lt;math&gt;A&lt;/math&gt;.
&lt;br/&gt;
'''Proof:''' Consider the set &lt;math&gt; B=\{x \in A \, | \, x \notin f(x)\}&lt;/math&gt;.  Suppose to the contrary that &lt;math&gt;f&lt;/math&gt; is [[surjective]].  Then there exists &lt;math&gt;\xi\in A&lt;/math&gt; such that &lt;math&gt;f(\xi)=B&lt;/math&gt;.  But by construction, &lt;math&gt;\xi\in B \iff \xi\notin f(\xi)= B &lt;/math&gt;. This is a contradiction.  Thus, &lt;math&gt;f&lt;/math&gt; cannot be surjective.  On the other hand, &lt;math&gt;g:A\to\mathcal{P}(A)&lt;/math&gt; defined by &lt;math&gt;x\mapsto\{x\}&lt;/math&gt; is an injective map.  Consequently, we must have &lt;math&gt;\mathrm{card}(A)&lt;\mathrm{card}(\mathcal{P}(A))&lt;/math&gt;.&lt;math&gt;\ \blacksquare&lt;/math&gt;|qalign=left}}

By definition of cardinality, we have card(''X'') &lt; card(''Y'') for any two sets ''X'' and ''Y'' if and only if there is an [[injective function]] but no [[Bijective Function|bijective function]] from ''X'' to ''Y''.  It suffices to show that there is no surjection from ''X'' to ''Y''.  This is the heart of Cantor's theorem: there is no surjective function from any set ''A'' to its power set.  To establish this, it is enough to show that no function ''f'' that maps elements in ''A'' to subsets of ''A'' can reach every possible subset, i.e., we just need to demonstrate the existence of a subset of ''A'' that is not equal to ''f''(''x'') for any ''x'' ∈ ''A''. (Recall that each ''f''(''x'') is a subset of ''A''.)  Such a subset is given by the following construction, sometimes called the ''Cantor diagonal set'' of ''f'':&lt;ref name="Dasgupta2013"&gt;{{cite book|author=Abhijit Dasgupta|title=Set Theory: With an Introduction to Real Point Sets|year=2013|publisher=[[Springer Science &amp; Business Media]]|isbn=978-1-4614-8854-5|pages=362–363}}&lt;/ref&gt;&lt;ref name="Paulson1992"&gt;{{cite book|author=Lawrence Paulson|title=Set Theory as a Computational Logic |url=https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-271.pdf|year=1992|publisher=University of Cambridge Computer Laboratory|page=14}}&lt;/ref&gt;

:&lt;math&gt;B=\left\{\,x\in A\,|\,x\not\in f(x)\,\right\}&lt;/math&gt;.

This means, by definition, that for all ''x'' in ''A'', ''x''&amp;nbsp;∈&amp;nbsp;''B'' if and only if ''x''&amp;nbsp;∉&amp;nbsp;''f''(''x''). For all ''x'' the sets ''B'' and ''f''(''x'') cannot be the same because ''B'' was constructed from elements of ''A'' whose images (under ''f'') did not include themselves. More specifically, consider any ''x''&amp;nbsp;∈&amp;nbsp;''A'', then either ''x''&amp;nbsp;∈&amp;nbsp;''f''(''x'') or ''x''&amp;nbsp;∉&amp;nbsp;''f''(''x''). In the former case, ''f''(''x'') cannot equal ''B'' because ''x''&amp;nbsp;∈&amp;nbsp;''f''(''x'') by assumption and ''x''&amp;nbsp;∉&amp;nbsp;''B'' by the construction of ''B''. In the latter case, ''f''(''x'') cannot equal ''B'' because ''x''&amp;nbsp;∉&amp;nbsp;''f''(''x'') by assumption and ''x''&amp;nbsp;∈&amp;nbsp;''B'' by the construction of ''B''.

Equivalently, and slightly more formally, we just proved that the existence of ξ ∈ ''A'' such that ''f''(ξ) = ''B'' implies the following [[contradiction]]:

:&lt;math&gt;\xi \in f(\xi) \iff \xi \in B\quad\quad(\mathrm{by} \ \mathrm{assumption}\ \mathrm{that}\ f(\xi)=B)&lt;/math&gt;;
:&lt;math&gt;\xi\in B \iff \xi\notin f(\xi)\quad\quad(\mathrm{by}\ \mathrm{definition}\ \mathrm{of}\ B)&lt;/math&gt;.

Therefore, by [[reductio ad absurdum]], the assumption must be false.&lt;ref name="Priest2002"/&gt; Thus there is no ξ ∈ ''A'' such that ''f''(ξ) = ''B''; in other words, ''B'' is not in the image of ''f'' and ''f'' does not map to every element of the power set of ''A'', i.e., ''f'' is not surjective (onto).

Finally, to complete the proof, we need to exhibit an injective function from ''A'' to its power set.  Finding such a function is trivial: just map ''x'' to the singleton set {''x''}.  The argument is now complete, and we have established the strict inequality for any set ''A'' that card(''A'') &lt; card(𝒫(''A'')).

Another way to think of the proof is that ''B'', empty or non-empty, is always in the power set of ''A''. For ''f'' to be [[Surjective function|onto]], some element of ''A'' must map to ''B''. But that leads to a contradiction: no element of ''B'' can map to ''B'' because that would contradict the criterion of membership in ''B'', thus the element mapping to ''B'' must not be an element of ''B'' meaning that it satisfies the criterion for membership in ''B'', another contradiction. So the assumption that an element of ''A'' maps to ''B'' must be false; and ''f'' cannot be onto.

Because of the double occurrence of ''x'' in the expression "''x'' ∉ ''f''(''x'')", this is a [[Cantor's diagonal argument|diagonal argument]]. For a countable (or finite) set, the argument of the proof given above can be illustrated by constructing a table in which each row is labelled by a unique ''x'' from ''A'' = {''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, …}, in this order. ''A'' is assumed to admit a [[Total order|linear order]] so that such table can be constructed. Each column of the table is labelled by a unique ''y'' from the [[power set]] of ''A''; the columns are ordered by the argument to ''f'', i.e. the column labels are ''f''(''x''&lt;sub&gt;1&lt;/sub&gt;), ''f''(''x''&lt;sub&gt;2&lt;/sub&gt;), …, in this order. The intersection of each row ''x'' and column ''y'' records a true/false bit whether ''x'' ∈ ''y''. Given the order chosen for the row and column labels, the main diagonal ''D'' of this table thus records whether  ''x'' ∈ ''f''(''x'') for all ''x'' in ''A''. The set ''B'' constructed in the previous paragraphs coincides with the row labels for the subset of entries on this main diagonal ''D'' where the table records that ''x'' ∈ ''f''(''x'') is false.&lt;ref name="Priest2002"&gt;{{cite book|author=Graham Priest|title=Beyond the Limits of Thought|year=2002|publisher=Oxford University Press|isbn=978-0-19-925405-7|pages=118–119}}&lt;!--note that the page numbers differ between the OUP and CUP editions of Priest's book!--&gt;&lt;/ref&gt; Each column records the values of the [[indicator function]] of the set corresponding to the column. The indicator function of ''B'' coincides with the [[logical negation|logically negated]] (true ↔ false) entries of the main diagonal. Thus the indicator function of ''B'' does not agree with any column in at least one entry. Consequently, no column represents ''B''.

For a finite set, the proof can also be illustrated using a more prosaic presentation known as the [[barber paradox]].&lt;ref name="Howson1990"&gt;{{cite book|author=Albert Geoffrey Howson|title=The Popularization of Mathematics|year=1990|publisher=Cambridge University Press|isbn=978-0-521-40319-1|page=197}}&lt;/ref&gt;

Despite the simplicity of the above proof, it is rather difficult for an [[automated theorem prover]] to produce it. The main difficulty lies in an automated discovery of the Cantor diagonal set. [[Lawrence Paulson]] noted in 1992 that [[Otter (theorem prover)|Otter]] could not do it, whereas [[Isabelle (proof assistant)|Isabelle]] could, albeit with a certain amount of direction in terms of tactics that might perhaps be considered cheating.&lt;ref name="Paulson1992"/&gt;

==A detailed explanation of the proof when ''X'' is countably infinite==
To understand the proof, let's examine it for the specific case when ''X'' is [[countably infinite]]. [[Without loss of generality]], we may take ''X'' = '''ℕ''' = {1, 2, 3,...}, the set of [[natural number]]s.

Suppose that ℕ is [[equinumerous]] with its [[power set]] 𝒫('''ℕ'''). Let us see a sample of what 𝒫('''ℕ''') looks like:

:&lt;math&gt;\mathcal{P}(\mathbb{N})=\{\varnothing,\{1, 2\}, \{1, 2, 3\}, \{4\}, \{1, 5\}, \{3, 4, 6\}, \{2, 4, 6,\dots\},\dots\}.&lt;/math&gt;

𝒫('''ℕ''') contains infinite subsets of '''ℕ''', e.g. the set of all even numbers {2, 4, 6,...}, as well as the [[empty set]].

Now that we have an idea of what the elements of 𝒫('''ℕ''') look like, let us attempt to pair off each [[element (math)|element]] of '''ℕ''' with each element of 𝒫('''ℕ''') to show that these infinite sets are equinumerous. In other words, we will attempt to pair off each element of '''ℕ''' with an element from the infinite set 𝒫('''ℕ'''), so that no element from either infinite set remains unpaired. Such an attempt to pair elements would look like this:

:&lt;math&gt;\mathbb{N}\begin{Bmatrix} 1 &amp; \longleftrightarrow &amp; \{4, 5\}\\ 2 &amp; \longleftrightarrow &amp; \{1, 2, 3\} \\ 3 &amp; \longleftrightarrow &amp; \{4, 5, 6\} \\ 4 &amp; \longleftrightarrow &amp; \{1, 3, 5\} \\ \vdots &amp; \vdots &amp; \vdots \end{Bmatrix}\mathcal{P}(\mathbb{N}).&lt;/math&gt;

Given such a pairing, some natural numbers are paired with [[subset]]s that contain the very same number. For instance, in our example the number 2 is paired with the subset {1, 2, 3}, which contains 2 as a member. Let us call such numbers ''selfish''. Other natural numbers are paired with [[subset]]s that do not contain them. For instance, in our example the number 1 is paired with the subset {4, 5}, which does not contain the number 1. Call these numbers ''non-selfish''. Likewise, 3 and 4 are non-selfish.

Using this idea, let us build a special set of natural numbers. This set will provide the [[proof by contradiction|contradiction]] we seek. Let ''D'' be the set of ''all'' non-selfish natural numbers. By definition, the [[power set]] 𝒫('''ℕ''') contains all sets of natural numbers, and so it contains this set ''D'' as an element. If the mapping is bijective, ''D'' must be paired off with some natural number, say ''d''. However, this causes a problem. If ''d'' is in ''D'', then ''d'' is selfish because it is in the corresponding set, contradicting the definition of "D". If ''d'' is not in ''D'', then it is non-selfish and should instead be a member of ''D''. Therefore, no such element ''d'' which maps to ''D'' can exist.

Since there is no natural number which can be paired with ''D'', we have contradicted our original supposition, that there is a [[bijection]] between '''ℕ''' and 𝒫('''ℕ''').

Note that the set ''D'' may be empty. This would mean that every natural number ''x'' maps to a set of natural numbers that contains ''x''. Then, every number maps to a nonempty set and no number maps to the empty set. But the empty set is a member of 𝒫('''ℕ'''), so the mapping still does not cover 𝒫('''ℕ''').

Through this [[proof by contradiction]] we have proven that the [[cardinality]] of '''ℕ''' and 𝒫('''ℕ''') cannot be equal. We also know that the [[cardinality]] of 𝒫('''ℕ''') cannot be less than the [[cardinality]] of '''ℕ''' because 𝒫('''ℕ''') contains all [[singleton (mathematics)|singleton]]s, by definition, and these singletons form a "copy" of '''ℕ''' inside of 𝒫('''ℕ'''). Therefore, only one possibility remains, and that is that the [[cardinality]] of 𝒫('''ℕ''') is strictly greater than the [[cardinality]] of '''ℕ''', proving Cantor's theorem.

==Related paradoxes==
Cantor's theorem and its proof are closely related to two [[paradoxes of set theory]].

[[Cantor's paradox]] is the name given to a contradiction following from Cantor's theorem together with the assumption that there is a set containing all sets, the [[universal set]] '''V'''. In order to distinguish this paradox from the next one discussed below, it is important to note what this contradiction is. By Cantor's theorem |𝒫(''X'')| &gt; |''X''| for any set ''X''. On the other hand, all elements of 𝒫('''V''') are sets, and thus contained in '''V''', therefore |𝒫('''V''')| ≤ |'''V'''|.&lt;ref name="Dasgupta2013"/&gt;

Another paradox can be derived from the proof of Cantor's theorem by instantiating the function ''f'' with the [[identity function]]; this turns Cantor's diagonal set into what is sometimes called the ''Russell set'' of a given set ''A'':&lt;ref name="Dasgupta2013"/&gt;

:&lt;math&gt;R_A=\left\{\,x\in A : x\not\in x\,\right\}.&lt;/math&gt;

The proof of Cantor's theorem is straightforwardly adapted to show that assuming a set of all sets ''U'' exists, then considering its Russell set ''R''&lt;sub&gt;''U''&lt;/sub&gt; leads to the contradiction:

:&lt;math&gt;R_U \in R_U \iff R_U \notin R_U.&lt;/math&gt;
 
This argument is known as [[Russell's paradox]].&lt;ref name="Dasgupta2013"/&gt; As a point of subtlety, the version of Russell's paradox we have presented here is actually a theorem of [[Zermelo]];&lt;ref name="Ebbinghaus2007"/&gt; we can conclude from the contradiction obtained that we must reject the hypothesis that ''R''&lt;sub&gt;''U''&lt;/sub&gt;∈''U'', thus disproving the existence of a set containing all sets. This was possible because we have used [[Axiom schema of specification|restricted comprehension]] (as featured in [[ZFC]]) in the definition of ''R''&lt;sub&gt;''A''&lt;/sub&gt; above, which in turn entailed that

:&lt;math&gt;R_U \in R_U \iff (R_U \in U \wedge R_U \notin R_U). &lt;/math&gt;

Had we used [[unrestricted comprehension]] (as in [[Frege]]'s system for instance) by defining the Russell set simply as &lt;math&gt;R=\left\{\,x : x\not\in x\,\right\}&lt;/math&gt;, then the axiom system itself would have entailed the contradiction, with no further hypotheses needed.&lt;ref name="Ebbinghaus2007"&gt;{{cite book|author=Heinz-Dieter Ebbinghaus|title=Ernst Zermelo: An Approach to His Life and Work|year=2007|publisher=Springer Science &amp; Business Media|isbn=978-3-540-49553-6|pages=86–87}}&lt;/ref&gt;

Despite the syntactical similarities between the Russell set (in either variant) and the Cantor diagonal set, [[Alonzo Church]] emphasized that Russell's paradox is independent of considerations of cardinality and its underlying notions like one-to-one correspondence.&lt;ref&gt;Church, A. [1974] "Set theory with a universal set." in ''Proceedings of the Tarski Symposium. Proceedings of Symposia in Pure Mathematics XXV,'' ed. L. Henkin, Providence RI, Second printing with additions 1979, pp. 297−308. {{ISBN|978-0-8218-7360-1}}. Also published in ''International Logic Review'' 15 pp. 11−23.&lt;/ref&gt;

==History==
Cantor gave essentially this proof in a paper published in 1891 ''Über eine elementare Frage der Mannigfaltigkeitslehre'', where the [[Cantor's diagonal argument|diagonal argument]] for the uncountability of the [[real number|reals]] also first appears (he had [[Cantor's first uncountability proof|earlier proved the uncountability of the reals by other methods]]). The version of this argument he gave in that paper was phrased in terms of indicator functions on a set rather than subsets of a set. He showed that if ''f'' is a function defined on ''X'' whose values are 2-valued functions on ''X'', then the 2-valued function ''G''(''x'') = 1 &amp;minus; ''f''(''x'')(''x'') is not in the range of ''f''.

[[Bertrand Russell]] has a very similar proof in ''[[Principles of Mathematics]]'' (1903, section 348), where he shows that there are more [[propositional function]]s than objects.  "For suppose a correlation of all objects and some propositional functions to have been affected, and let phi-''x'' be the correlate of ''x''. Then "not-phi-''x''(''x'')," i.e. "phi-''x'' does not hold of ''x''" is a propositional function not contained in this correlation; for it is true or false of ''x'' according as phi-''x'' is false or true of ''x'', and therefore it differs from phi-''x'' for every value of ''x''."  He attributes the idea behind the proof to Cantor.

[[Ernst Zermelo]] has a theorem (which he calls "Cantor's Theorem") that is identical to the form above in the paper that became the foundation of modern set theory ("Untersuchungen über die Grundlagen der Mengenlehre I"), published in 1908. See [[Zermelo set theory]].

==Generalizations==
{{expand section|date=April 2015}}
Cantor's theorem has been generalized to any [[Category (mathematics)|category]] with [[Product (category theory)|products]].&lt;ref name="LawvereSchanuel2009"&gt;{{cite book|author1=F. William Lawvere|author2=Stephen H. Schanuel|title=Conceptual Mathematics: A First Introduction to Categories|year=2009|publisher=Cambridge University Press|isbn=978-0-521-89485-2|at=Session 29}}&lt;/ref&gt;

==Other applications==

Patrick Grim has applied Cantor's theorem to argue that the set of all truths does not exist.&lt;ref&gt;Patrick Grim (1983) There Is No Set of All Truths. ''Analysis'', Vol. 44, No. 4 (Oct., 1984), pp. 206-208.&lt;/ref&gt;

==See also==
*[[Schröder–Bernstein theorem]]
*[[Cantor's first uncountability proof]]
*[[Controversy over Cantor's theory]]

==References==
{{reflist}}
*[[Paul Halmos|Halmos, Paul]], ''[[Naive Set Theory (book)|Naive Set Theory]]''. Princeton, NJ: D. Van Nostrand Company, 1960. Reprinted by [[Springer-Verlag]], New York, 1974. {{ISBN|0-387-90092-6}} (Springer-Verlag edition). Reprinted by Martino Fine Books, 2011. {{ISBN|978-1-61427-131-4}} (Paperback edition).
*{{Citation|last=Jech|first=Thomas|authorlink=Thomas Jech|year=2002|title=Set Theory|edition=3rd millennium|series=Springer Monographs in Mathematics|publisher=Springer|isbn=3-540-44085-2}}

==External links==
* {{springer|title=Cantor theorem|id=p/c020260}}
* {{MathWorld |title=Cantor's Theorem |id=CantorsTheorem }}

{{Metalogic}}
{{Set theory}}

[[Category:1891 introductions]]
[[Category:1891 in science]]
[[Category:Set theory]]
[[Category:Theorems in the foundations of mathematics]]
[[Category:Cardinal numbers]]
[[Category:Georg Cantor]]</text>
      <sha1>12re5xbh8sbbz7bk0sd0gnmhi1wdywt</sha1>
    </revision>
  </page>
  <page>
    <title>Category of representations</title>
    <ns>0</ns>
    <id>55872661</id>
    <revision>
      <id>843191786</id>
      <parentid>812826985</parentid>
      <timestamp>2018-05-27T14:28:20Z</timestamp>
      <contributor>
        <username>CitationCleanerBot</username>
        <id>15270283</id>
      </contributor>
      <minor/>
      <comment>arxivify URL / redundant url</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6614">In [[representation theory]], the '''[[Category (mathematics)|category]] of representations''' of some algebraic structure {{var|A}} has the representations of {{var|A}} as objects and [[Representation theory#Equivariant maps and isomorphisms|equivariant maps]] as [[morphism]]s between them. One of the basic thrusts of representation theory is to understand the conditions under which this category is [[semisimple category|semisimple]]; i.e., whether an object decomposes into [[simple object]]s (see [[Maschke's theorem]] for the case of finite groups).

The [[Tannakian formalism]] gives conditions under which a group ''G'' may be recovered from the category of representations of it together with the forgetful functor to the [[category of vector spaces]].&lt;ref&gt;{{cite arxiv|last=Jacob|first=Lurie,|date=2004-12-14|title=Tannaka Duality for Geometric Stacks|arxiv=math/0412266|language=en}}&lt;/ref&gt;

The [[Grothendieck ring]] of the category of finite-dimensional representations of a group ''G'' is called the [[representation ring]] of ''G''.

== Definitions ==
Depending on the types of the representations one wants to consider, it is typical to use slightly different definitions.

For a finite group {{var|G}} and a [[Field (mathematics)|field]] {{var|F}}, the '''category of representations of {{var|G}} over {{var|F}}''' has 
* objects: [[Tuple|pairs]] ({{var|V}},{{var|f}}) of [[vector space]]s {{var|V}} over {{var|F}} and representations {{var|f}} of {{var|G}} on that vector space
* morphisms: equivariant maps
* composition: the [[Function composition|composition]] of equivariant maps
* identities: the [[identity function]] (which is indeed an equivariant map).

The category is denoted by &lt;math&gt;\operatorname{Rep}_F(G)&lt;/math&gt; or &lt;math&gt;\operatorname{Rep}(G)&lt;/math&gt;.

For a Lie group, one typically requires the representations to be [[smooth representation|smooth]] or [[admissible representation|admissible]]. For the case of a Lie algebra, see [[Lie algebra representation]]. See also: [[category O]].

=== The category of modules over the group ring ===
{{See also|Representation theory of finite groups#Representations, modules and the convolution algebra|Isomorphism of categories#Examples}}

There is an [[isomorphism of categories]] between the category of representations of a group {{var|G}} over a field {{var|F}} (described above) and the [[category of modules]] over the [[group ring]] {{var|F}}[{{var|G}}], denoted '''{{var|F}}[{{var|G}}]-Mod'''.

=== Category-theoretic definition ===
{{See also|Equivariant map#Generalization}}

Every group {{var|G}} can be viewed as a category with a single object, where [[morphism]]s in this category are the elements of {{var|G}} and composition is given by the group operation. Given an arbitrary category '''{{var|C}}''', a ''representation'' of {{var|G}} in '''{{var|C}}''' is a [[functor]] from {{var|G}} to '''{{var|C}}'''. Such a functor selects an object of '''{{var|C}}''' and a [[subgroup]] of the [[automorphism group]] of that object. For example, a [[Group action|{{var|G}}-set]] is equivalent to a functor from {{var|G}} to '''Set''', the [[category of sets]], and a linear representation is equivalent to a functor to  '''Vect'''&lt;sub&gt;{{var|F}}&lt;/sub&gt;, the [[category of vector spaces]] over a field.&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/851741862|title=Categories for the Working Mathematician|last=Mac Lane|first=Saunders|date=1978|publisher=Springer New York|year=|isbn=1441931236|edition=Second|location=New York, NY|pages=41|oclc=851741862}}&lt;/ref&gt;

In this setting, the '''category of linear representations of {{var|G}} over {{var|F}}''' is the functor category {{var|G}} → '''Vect'''&lt;sub&gt;{{var|F}}&lt;/sub&gt;, which has [[natural transformation]]s as its morphisms.

== Properties ==
{{Expand section|date=November 2017}}
The category of linear representations of a group has a [[Monoidal category|monoidal structure]] given by the [[tensor product of representations]], which is an important ingredient in Tannaka-Krein duality (see below).

[[Maschke's theorem]] states that when the [[Characteristic (algebra)|characteristic]] of {{var|F}} doesn't divide the [[Order (group theory)|order]] of {{var|G}}, the category of representations of {{var|G}} over {{var|F}} is [[Semisimple category|semisimple]].

== Restriction and induction ==
Given a group {{var|G}} with a [[subgroup]] {{var|H}}, there are two fundamental functors between the categories of representations of {{var|G}} and {{var|H}} (over a fixed field): one is a [[forgetful functor]] called the [[Restricted representation|restriction functor]]
:&lt;math displaystyle="block"&gt;
\begin{align}
  \operatorname{Res}_H^G : \operatorname{Rep}(G) &amp;\longrightarrow \operatorname{Rep}(H) \\
  \pi &amp;\longmapsto \pi|_H
\end{align}
&lt;/math&gt;
and the other, the [[induction functor]]
:&lt;math displaystyle="block"&gt;\operatorname{Ind}_H^G : \operatorname{Rep}(H) \to \operatorname{Rep}(G)&lt;/math&gt;.

When {{var|G}} and {{var|H}} are finite groups, they are [[adjoint functor|adjoint]] to each other
:&lt;math displaystyle="block"&gt;\operatorname{Hom}_G(\operatorname{Ind}_H^G W, U) \cong \operatorname{Hom}_H(W, \operatorname{Res}_H^G U)&lt;/math&gt;,
a theorem called [[Frobenius reciprocity]].

The basic question is whether the decomposition into irreducible representations (simple objects of the category) behaves under restriction or induction. The question may be attacked for instance by the [[Mackey theory]].

== Tannaka-Krein duality ==
{{Main|Tannaka–Krein duality}}

'''Tannaka–Krein duality''' concerns the interaction of a [[compact group|compact]] [[topological group]] and its category of [[linear representation]]s. Tannaka's theorem describes the converse passage from the category of finite dimensional representations of a group {{var|G}} back to the group {{var|G}}, allowing one to recover the group from its category of representations. Krein's theorem in effect completely characterizes all categories that can arise from a group in this fashion. These concepts can be applied to representations of several different structures, see the main article for details.

== Notes ==
{{Refbegin}}
{{Reflist}}
{{Refend}}

== References ==
*{{Citation | last1=André | first1=Yves | title=Une introduction aux motifs (motifs purs, motifs mixtes, périodes) | publisher=Société Mathématique de France | location=Paris | series=Panoramas et Synthèses | isbn=978-2-85629-164-1 |mr=2115000 | year=2004 | volume=17}}

== External links ==
* https://ncatlab.org/nlab/show/category+of+representations

[[Category:Representation theory]]
[[Category:Category theory]]</text>
      <sha1>emf24uk491bcrpi7g8wx55ctpwncbcf</sha1>
    </revision>
  </page>
  <page>
    <title>Cauchy product</title>
    <ns>0</ns>
    <id>863791</id>
    <revision>
      <id>840556326</id>
      <parentid>831700258</parentid>
      <timestamp>2018-05-10T17:08:50Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>/* Convergence and Mertens' theorem */[[User:PrimeBOT/24|Task 24]] - replace template usage following [[Wikipedia:Templates for discussion/Log/2018 February 19|a TFD]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16534">In [[mathematics]], more specifically in [[mathematical analysis]], the '''Cauchy product''' is the discrete [[convolution]] of two [[Series (mathematics)|infinite series]]. It is named after the French mathematician [[Augustin Louis Cauchy]].

==Definitions==
The Cauchy product may apply to infinite series&lt;ref&gt;{{harvnb|Canuto|Tabacco|2015|p=20}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Bloch|2011|p=463}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Friedman|Kandel|2011|p=204}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Ghorpade|Limaye|2006|p=416}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Hijab|2011|p=43}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Montesinos|Zizler|Zizler|2015|p=98}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Oberguggenberger|Ostermann|2011|p=322}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Pedersen|2015|p=210}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Ponnusamy|2012|p=200}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Pugh|2015|p=210}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Sohrab|2014|p=73}}.&lt;/ref&gt; or power series.&lt;ref&gt;{{harvnb|Canuto|Tabacco|2015|p=53}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Mathonline|loc=Cauchy Product of Power Series}}.&lt;/ref&gt; When people apply it to finite sequences&lt;ref&gt;{{harvnb|Weisstein|loc=Cauchy Product}}.&lt;/ref&gt; or finite series, it is by abuse of language: they actually refer to [[Convolution#Discrete convolution|discrete convolution]].

[[Convergence (mathematics)|Convergence]] issues are discussed in the [[#Convergence and Mertens' theorem|next section]].

===Cauchy product of two infinite series===

Let &lt;math&gt;\textstyle \sum_{i=0}^\infty a_i&lt;/math&gt; and &lt;math&gt;\textstyle \sum_{j=0}^\infty b_j&lt;/math&gt; be two [[infinite series]] with complex terms. The Cauchy product of these two infinite series is defined by a discrete convolution as follows:

:&lt;math&gt;\left(\sum_{i=0}^\infty a_i\right) \cdot \left(\sum_{j=0}^\infty b_j\right) = \sum_{k=0}^\infty c_k&lt;/math&gt; &amp;nbsp; &amp;nbsp; where &amp;nbsp; &amp;nbsp; &lt;math&gt;c_k=\sum_{l=0}^k a_l b_{k-l}&lt;/math&gt;.

===Cauchy product of two power series===

Consider the following two [[power series]]

:&lt;math&gt;\sum_{i=0}^\infty a_i x^i&lt;/math&gt; &amp;nbsp; &amp;nbsp; and &amp;nbsp; &amp;nbsp; &lt;math&gt;\sum_{j=0}^\infty b_j x^j&lt;/math&gt;

with complex coefficients &lt;math&gt;\{a_i\}&lt;/math&gt; and &lt;math&gt;\{b_j\}&lt;/math&gt;. The Cauchy product of these two power series is defined by a discrete convolution as follows:

:&lt;math&gt;\left(\sum_{i=0}^\infty a_i x^i\right) \cdot \left(\sum_{j=0}^\infty b_j x^j\right) = \sum_{k=0}^\infty c_k x^k&lt;/math&gt; &amp;nbsp; &amp;nbsp; where &amp;nbsp; &amp;nbsp; &lt;math&gt;c_k=\sum_{l=0}^k a_l b_{k-l}&lt;/math&gt;.

==Convergence and Mertens' theorem==
{{distinguish|text=[[Mertens' theorems]] concerning distribution of prime numbers}}

Let {{math|(''a&lt;sub&gt;n&lt;/sub&gt;'')&lt;sub&gt;''n''≥0&lt;/sub&gt;}} and {{math|(''b&lt;sub&gt;n&lt;/sub&gt;'')&lt;sub&gt;''n''≥0&lt;/sub&gt;}} be real or complex sequences. It was proved by [[Franz Mertens]]{{cn|date=December 2017}} that, if the series &lt;math&gt;\textstyle \sum_{n=0}^\infty a_n&lt;/math&gt; [[Convergent series|converges]] to {{math|''A''}} and &lt;math&gt;\textstyle \sum_{n=0}^\infty b_n&lt;/math&gt; converges to {{math|''B''}}, and at least one of them [[Absolute convergence|converges absolutely]], then their Cauchy product converges to {{math|''AB''}}.

It is not sufficient for both series to be convergent; if both sequences are [[conditional convergence|conditionally convergent]], the Cauchy product does not have to converge towards the product of the two series, as the following example shows:

===Example===
Consider the two [[alternating series]] with

:&lt;math&gt;a_n = b_n = \frac{(-1)^n}{\sqrt{n+1}}\,,&lt;/math&gt;

which are only conditionally convergent (the divergence of the series of the absolute values follows from the [[direct comparison test]] and the divergence of the [[harmonic series (mathematics)|harmonic series]]). The terms of their Cauchy product are given by

:&lt;math&gt;c_n = \sum_{k=0}^n \frac{(-1)^k}{\sqrt{k+1}} \cdot \frac{ (-1)^{n-k} }{ \sqrt{n-k+1} } = (-1)^n \sum_{k=0}^n \frac{1}{ \sqrt{(k+1)(n-k+1)} }&lt;/math&gt;

for every integer {{math|''n'' ≥ 0}}. Since for every {{math|''k'' ∈ {{mset|0, 1, ..., ''n''}}}} we have the inequalities {{math|''k'' + 1 ≤ ''n'' + 1}} and {{math|''n'' – ''k'' + 1 ≤ ''n'' + 1}}, it follows for the square root in the denominator that {{math|{{sqrt|(''k'' + 1)(''n'' − ''k'' + 1)}} ≤ ''n'' +1}}, hence, because there are {{math|''n'' + 1}} summands,

:&lt;math&gt;|c_n| \ge \sum_{k=0}^n \frac{1}{n+1} = 1&lt;/math&gt;

for every integer {{math|''n'' ≥ 0}}. Therefore, {{math|''c&lt;sub&gt;n&lt;/sub&gt;''}} does not converge to zero as {{math|''n'' → ∞}}, hence the series of the {{math|(''c&lt;sub&gt;n&lt;/sub&gt;'')&lt;sub&gt;''n''≥0&lt;/sub&gt;}} diverges by the [[term test]].

===Proof of Mertens' theorem===
Assume [[without loss of generality]] that the series &lt;math&gt;\textstyle \sum_{n=0}^\infty a_n&lt;/math&gt; converges absolutely.
Define the [[partial sums]]

:&lt;math&gt;A_n = \sum_{i=0}^n a_i,\quad B_n = \sum_{i=0}^n b_i\quad\text{and}\quad C_n = \sum_{i=0}^n c_i&lt;/math&gt;

with

:&lt;math&gt;c_i=\sum_{k=0}^ia_kb_{i-k}\,.&lt;/math&gt;

Then

:&lt;math&gt;C_n = \sum_{i=0}^n  a_{n-i}B_i&lt;/math&gt;

by rearrangement, hence

{{NumBlk|:|&lt;math&gt;C_n = \sum_{i=0}^na_{n-i}(B_i-B)+A_nB\,.&lt;/math&gt;|{{EquationRef|1}}}}

Fix {{math|''ε'' &gt; 0}}. Since &lt;math&gt;\textstyle \sum_{k\in{\mathbb N}} |a_k|&lt;\infty&lt;/math&gt; by absolute convergence, and since {{math|''B&lt;sub&gt;n&lt;/sub&gt;''}} converges to {{math|''B''}} as {{math|''n'' → ∞}}, there exists an integer {{math|''N''}} such that, for all integers {{math|''n'' ≥ ''N''}},

{{NumBlk|:|&lt;math&gt;|B_n-B|\le\frac{\varepsilon/3}{\sum_{ k\in{\mathbb N} } |a_k|+1}&lt;/math&gt;|{{EquationRef|2}}}}

(this is the only place where the absolute convergence is used). Since the series of the {{math|(''a&lt;sub&gt;n&lt;/sub&gt;'')&lt;sub&gt;''n''≥0&lt;/sub&gt;}} converges, the individual {{math|''a&lt;sub&gt;n&lt;/sub&gt;''}} must converge to 0 by the [[term test]]. Hence there exists an integer {{math|''M''}} such that, for all integers {{math|''n'' ≥ ''M''}},

{{NumBlk|:|&lt;math&gt;|a_n|\le\frac{\varepsilon}{3N(\sup_{ i\in\{0,\dots,N-1\} } |B_i-B|+1)}\,. &lt;/math&gt;|{{EquationRef|3}}}}

Also, since {{math|''A&lt;sub&gt;n&lt;/sub&gt;''}} converges to {{math|''A''}} as {{math|''n'' → ∞}}, there exists an integer {{math|''L''}} such that, for all integers {{math|''n'' ≥ ''L''}},

{{NumBlk|:|&lt;math&gt;|A_n-A|\le\frac{\varepsilon/3}{|B|+1}\,.&lt;/math&gt;|{{EquationRef|4}}}}

Then, for all integers {{math|''n'' ≥ max{{mset|''L'', ''M'' + ''N''}}}}, use the representation ({{EquationNote|1}}) for {{math|''C&lt;sub&gt;n&lt;/sub&gt;''}}, split the sum in two parts, use the [[triangle inequality]] for the [[absolute value]], and finally use the three estimates ({{EquationNote|2}}), ({{EquationNote|3}}) and ({{EquationNote|4}}) to show that

:&lt;math&gt;\begin{align}
|C_n - AB| &amp;= \biggl|\sum_{i=0}^n a_{n-i}(B_i-B)+(A_n-A)B\biggr| \\
 &amp;\le \sum_{i=0}^{N-1}\underbrace{|a_{\underbrace{\scriptstyle n-i}_{\scriptscriptstyle \ge M}}|\,|B_i-B|}_{\le\,\varepsilon/(3N)\text{ by (3)}}+{}\underbrace{\sum_{i=N}^n |a_{n-i}|\,|B_i-B|}_{\le\,\varepsilon/3\text{ by (2)}}+{}\underbrace{|A_n-A|\,|B|}_{\le\,\varepsilon/3\text{ by (4)}}\le\varepsilon\,. 
\end{align}&lt;/math&gt;

By the [[Convergent series|definition of convergence of a series]], {{math|''C&lt;sub&gt;n&lt;/sub&gt;'' → ''AB''}} as required.

==Cesàro's theorem==
{{unreferenced section|date=December 2017}}
&lt;!-- [[Cesàro's theorem]] redirects here --&gt;

In cases where the two sequences are convergent but not absolutely convergent, the Cauchy product is still [[Cesàro summation|Cesàro summable]].  Specifically:

If &lt;math&gt;\textstyle (a_n)_{n\geq0}&lt;/math&gt;, &lt;math&gt;\textstyle (b_n)_{n\geq0}&lt;/math&gt; are real sequences with &lt;math&gt;\textstyle \sum a_n\to A&lt;/math&gt; and &lt;math&gt;\textstyle \sum b_n\to B&lt;/math&gt; then

: &lt;math&gt;\frac{1}{N}\left(\sum_{n=1}^N\sum_{i=1}^n\sum_{k=0}^i a_k b_{i-k}\right)\to AB.&lt;/math&gt;

This can be generalised to the case where the two sequences are not convergent but just Cesàro summable:

===Theorem===
For &lt;math&gt;\textstyle r&gt;-1&lt;/math&gt; and &lt;math&gt;\textstyle s&gt;-1&lt;/math&gt;, suppose the sequence &lt;math&gt;\textstyle (a_n)_{n\geq0}&lt;/math&gt; is &lt;math&gt;\textstyle (C,\; r)&lt;/math&gt; summable with sum ''A'' and &lt;math&gt;\textstyle (b_n)_{n\geq0}&lt;/math&gt; is &lt;math&gt;\textstyle (C,\; s)&lt;/math&gt; summable with sum ''B''. Then their Cauchy product is &lt;math&gt;\textstyle (C,\; r+s+1)&lt;/math&gt; summable with sum ''AB''.

==Examples==

* For some &lt;math&gt;\textstyle x,y\in\mathbb{R}&lt;/math&gt;, let &lt;math&gt;\textstyle a_n = x^n/n!&lt;/math&gt; and  &lt;math&gt;\textstyle b_n = y^n/n!&lt;/math&gt;.  Then

:&lt;math&gt; c_n = \sum_{i=0}^n\frac{x^i}{i!}\frac{y^{n-i}}{(n-i)!} = \frac{1}{n!}\sum_{i=0}^n\binom{n}{i}x^i y^{n-i} =
\frac{(x+y)^n}{n!}&lt;/math&gt;

by definition and the [[binomial formula]].  Since, [[formal series|formally]], &lt;math&gt;\textstyle \exp(x) = \sum a_n&lt;/math&gt; and &lt;math&gt;\textstyle \exp(y) = \sum b_n&lt;/math&gt;, we have shown that &lt;math&gt;\textstyle \exp(x+y) = \sum c_n&lt;/math&gt;.  Since the limit of the Cauchy product of two [[absolute convergence|absolutely convergent]] series is equal to the product of the limits of those series, we have proven the formula &lt;math&gt;\textstyle \exp(x+y) = \exp(x)\exp(y)&lt;/math&gt; for all &lt;math&gt;\textstyle x,y\in\mathbb{R}&lt;/math&gt;.

* As a second example, let &lt;math&gt;\textstyle  a_n=b_n = 1&lt;/math&gt; for all &lt;math&gt;\textstyle n\in\mathbb{N}&lt;/math&gt;.  Then &lt;math&gt;\textstyle c_n = n+1&lt;/math&gt; for all &lt;math&gt;n\in\mathbb{N}&lt;/math&gt; so the Cauchy product &lt;math&gt;\textstyle \sum c_n = (1,1+2,1+2+3,1+2+3+4,\dots)&lt;/math&gt; does not converge.

==Generalizations==

All of the foregoing applies to sequences in &lt;math&gt;\textstyle \mathbb{C}&lt;/math&gt; ([[complex number]]s).  The '''Cauchy product''' can be defined for series in the &lt;math&gt;\textstyle \mathbb{R}^n&lt;/math&gt; spaces ([[Euclidean spaces]]) where multiplication is the [[inner product]].  In this case, we have the result that if two series converge absolutely then their Cauchy product converges absolutely to the inner product of the limits.

=== Products of finitely many infinite series ===
Let &lt;math&gt;n \in \mathbb N&lt;/math&gt; such that &lt;math&gt;n \ge 2&lt;/math&gt; (actually the following is also true for &lt;math&gt;n=1&lt;/math&gt; but the statement becomes trivial in that case) and let &lt;math&gt;\sum_{k_1 = 0}^\infty a_{1, k_1}, \ldots, \sum_{k_n = 0}^\infty a_{n, k_n}&lt;/math&gt; be infinite series with complex coefficients, from which all except the &lt;math&gt;n&lt;/math&gt;th one converge absolutely, and the &lt;math&gt;n&lt;/math&gt;th one converges. Then the series
:&lt;math&gt;\sum_{k_1 = 0}^\infty \sum_{k_2 = 0}^{k_1} \cdots \sum_{k_n = 0}^{k_{n-1}} a_{1, k_n} a_{2, k_{n-1} - k_n} \cdots a_{n, k_1 - k_2}&lt;/math&gt;
converges and we have:
:&lt;math&gt;\sum_{k_1 = 0}^\infty \sum_{k_2 = 0}^{k_1} \cdots \sum_{k_n = 0}^{k_{n-1}} a_{1, k_n} a_{2, k_{n-1} - k_n} \cdots a_{n, k_1 - k_2} = \prod_{j=1}^n \left( \sum_{k_j = 0}^\infty a_{j, k_j} \right)&lt;/math&gt;

This statement can be proven by induction over &lt;math&gt;n&lt;/math&gt;: The case for &lt;math&gt;n = 2&lt;/math&gt; is identical to the claim about the Cauchy product. This is our induction base.

The induction step goes as follows: Let the claim be true for an &lt;math&gt;n \in \mathbb N&lt;/math&gt; such that &lt;math&gt;n \ge 2&lt;/math&gt;, and let &lt;math&gt;\sum_{k_1 = 0}^\infty a_{1, k_1}, \ldots, \sum_{k_{n+1} = 0}^\infty a_{n+1, k_{n+1}}&lt;/math&gt; be infinite series with complex coefficients, from which all except the &lt;math&gt;n+1&lt;/math&gt;th one converge absolutely, and the &lt;math&gt;n+1&lt;/math&gt;th one converges. We first apply the induction hypothesis to the series &lt;math&gt;\sum_{k_1 = 0}^\infty |a_{1, k_1}|, \ldots, \sum_{k_n = 0}^\infty |a_{n, k_n}|&lt;/math&gt;. We obtain that the series
:&lt;math&gt;\sum_{k_1 = 0}^\infty \sum_{k_2 = 0}^{k_1} \cdots \sum_{k_n = 0}^{k_{n-1}} |a_{1, k_n} a_{2, k_{n-1} - k_n} \cdots a_{n, k_1 - k_2}|&lt;/math&gt;
converges, and hence, by the triangle inequality and the sandwich criterion, the series
:&lt;math&gt;\sum_{k_1 = 0}^\infty \left| \sum_{k_2 = 0}^{k_1} \cdots \sum_{k_n = 0}^{k_{n-1}} a_{1, k_n} a_{2, k_{n-1} - k_n} \cdots a_{n, k_1 - k_2} \right|&lt;/math&gt;
converges, and hence the series
:&lt;math&gt;\sum_{k_1 = 0}^\infty \sum_{k_2 = 0}^{k_1} \cdots \sum_{k_n = 0}^{k_{n-1}} a_{1, k_n} a_{2, k_{n-1} - k_n} \cdots a_{n, k_1 - k_2}&lt;/math&gt;
converges absolutely. Therefore, by the induction hypothesis, by what Mertens proved, and by renaming of variables, we have:
:&lt;math&gt;\begin{align}
\prod_{j=1}^{n+1} \left( \sum_{k_j = 0}^\infty a_{j, k_j} \right) &amp; = \left( \sum_{k_{n+1} = 0}^\infty \overbrace{a_{n+1, k_{n+1}}}^{=:a_{k_{n+1}}} \right) \left( \sum_{k_1 = 0}^\infty \overbrace{\sum_{k_2 = 0}^{k_1} \cdots \sum_{k_n = 0}^{k_{n-1}} a_{1, k_n} a_{2, k_{n-1} - k_n} \cdots a_{n, k_1 - k_2}}^{=:b_{k_1}} \right) \\
&amp; = \sum_{k_1 = 0}^\infty \sum_{k_2 = 0}^{k_1} a_{n+1, k_1 - k_2} \sum_{k_3 = 0}^{k_2} \cdots \sum_{k_{n+1} = 0}^{k_n} a_{1, k_{n+1}} a_{2, k_n - k_{n+1}} \cdots a_{n, k_2 - k_3}
\end{align}&lt;/math&gt;
Therefore, the formula also holds for &lt;math&gt;n+1&lt;/math&gt;.

== Relation to convolution of functions ==
A finite sequence can be viewed as an infinite sequence with only finitely many nonzero terms. A finite sequence can be viewed as a function &lt;math&gt;f: \mathbb{N} \to \mathbb{C}&lt;/math&gt; with finite support. For any complex-valued functions ''f'', ''g'' on &lt;math&gt;\mathbb{N}&lt;/math&gt; with finite support, one can take their [[convolution (mathematics)|convolution]]:
:&lt;math&gt;(f * g)(n) = \sum_{i + j = n} f(i) g(j)&lt;/math&gt;.
Then &lt;math&gt;\sum (f *g)(n)&lt;/math&gt; is the same thing as the Cauchy product of &lt;math&gt;\sum f(n)&lt;/math&gt; and &lt;math&gt;\sum g(n)&lt;/math&gt;.

More generally, given a unital semigroup ''S'', one can form the [[semigroup algebra]] &lt;math&gt;\mathbb{C}[S]&lt;/math&gt; of ''S'', with, as usual, the multiplication given by convolution. If one takes, for example, &lt;math&gt;S = \mathbb{N}^d&lt;/math&gt;, then the multiplication on &lt;math&gt;\mathbb{C}[S]&lt;/math&gt; is a sort of a generalization of the Cauchy product to higher dimension.

==Notes==
{{reflist}}

==References==
*{{Citation
 | first = Tom M.
 | last = Apostol
 | authorlink = Tom M. Apostol
 | title = Mathematical Analysis
 | edition = 2nd
 | year = 1974
 | publisher = Addison Wesley
 | isbn = 978-0-201-00288-1
 | page=204
}}.

*{{Citation
 | first = Ethan D.
 | last = Bloch
 | title = The Real Numbers and Real Analysis
 | publisher = [[Springer Science+Business Media|Springer]]
 | year = 2011
}}.

*{{Citation
 | first1 = Claudio
 | last1 = Canuto
 | first2 = Anita
 | last2 = Tabacco
 | title = Mathematical Analysis II
 | edition = 2nd
 | publisher = [[Springer Science+Business Media|Springer]]
 | year = 2015
}}.

*{{Citation
 | first1 = Menahem
 | last1 = Friedman
 | first2 = Abraham
 | last2 = Kandel
 | title = Calculus Light
 | publisher = [[Springer Science+Business Media|Springer]]
 | year = 2011
}}.

*{{Citation
 | first1 = Sudhir R.
 | last1 = Ghorpade
 | first2 = Balmohan V.
 | last2 = Limaye
 | title = A Course in Calculus and Real Analysis
 | publisher = [[Springer Science+Business Media|Springer]]
 | year = 2006
}}.

*{{Citation
 | first = G. H.
 | last = Hardy
 | authorlink = G. H. Hardy
 | title = Divergent Series
 | year = 1949
 | publisher = [[Oxford University Press]]
 | page = 227–229
}}.

*{{Citation
 | first = Omar
 | last = Hijab
 | title = Introduction to Calculus and Classical Analysis
 | edition = 3rd
 | publisher = [[Springer Science+Business Media|Springer]]
 | year = 2011
}}.

*{{Citation
 | last = Mathonline
 | title = Cauchy Product of Power Series
 | url = http://mathonline.wikidot.com/cauchy-product-of-power-series
}}.

*{{Citation
 | first1 = Vicente
 | last1 = Montesinos
 | first2 = Peter
 | last2 = Zizler
 | first3 = Václav
 | last3 = Zizler
 | title = An Introduction to Modern Analysis
 | publisher = [[Springer Science+Business Media|Springer]]
 | year = 2015
}}.

*{{Citation
 | first1 = Michael
 | last1 = Oberguggenberger
 | first2 = Alexander
 | last2 = Ostermann
 | title = Analysis for Computer Scientists
 | publisher = [[Springer Science+Business Media|Springer]]
 | year = 2011
}}.

*{{Citation
 | first = Steen
 | last = Pedersen
 | title = From Calculus to Analysis
 | publisher = [[Springer Science+Business Media|Springer]]
 | year = 2015
}}.

*{{Citation
 | first = S.
 | last = Ponnusamy
 | title = Foundations of Mathematical Analysis
 | publisher = [[Birkhäuser]]
 | year = 2012
}}.

*{{Citation
 | first = Charles C.
 | last = Pugh
 | title = Real Mathematical Analysis
 | edition = 2nd
 | publisher = [[Springer Science+Business Media|Springer]]
 | year = 2015
}}.

*{{Citation
 | first = Houshang H.
 | last = Sohrab
 | title = Basic Real Analysis
 | edition = 2nd
 | publisher = [[Birkhäuser]]
 | year = 2014
}}.

*{{Citation
 | first = Eric W.
 | last = Weisstein
 | contribution = Cauchy Product
 | title = From MathWorld – A Wolfram Web Resource
 | url = http://mathworld.wolfram.com/CauchyProduct.html
}}.

[[Category:Real analysis]]
[[Category:Complex analysis]]
[[Category:Sequences and series]]
[[Category:Articles containing proofs]]</text>
      <sha1>fsq3t00k4lb4ayl7s03pkygorzua5r9</sha1>
    </revision>
  </page>
  <page>
    <title>Classical Wiener space</title>
    <ns>0</ns>
    <id>6810363</id>
    <revision>
      <id>862708570</id>
      <parentid>856250576</parentid>
      <timestamp>2018-10-06T05:14:02Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5383">[[Image:Norbert wiener.jpg|thumb|upright|Norbert Wiener]]

In [[mathematics]], '''classical Wiener space''' is the collection of all [[continuous function]]s on a given [[domain of a function|domain]] (usually a sub-[[interval (mathematics)|interval]] of the [[real line]]), taking values in a [[metric space]] (usually ''n''-dimensional [[Euclidean space]]). Classical Wiener space is useful in the study of [[stochastic processes]] whose sample paths are continuous functions. It is named after the [[United States|American]] [[mathematician]] [[Norbert Wiener]].

==Definition==
Consider ''E'' ⊆ '''R'''&lt;sup&gt;''n''&lt;/sup&gt; and a metric space (''M'', ''d''). The '''classical Wiener space''' ''C''(''E''; ''M'') is the space of all continuous functions ''f'' : ''E'' → ''M''. I.e. for every fixed ''t'' in ''E'',

:&lt;math&gt;d(f(s), f(t)) \to 0&lt;/math&gt; as &lt;math&gt;| s - t | \to 0.&lt;/math&gt;

In almost all applications, one takes ''E'' = [0, ''T''] or [0, +∞) and ''M'' = '''R'''&lt;sup&gt;''n''&lt;/sup&gt; for some ''n'' in '''N'''. For brevity, write ''C'' for ''C''([0, ''T'']; '''R'''&lt;sup&gt;''n''&lt;/sup&gt;); this is a [[vector space]]. Write ''C''&lt;sub&gt;0&lt;/sub&gt; for the [[linear subspace]] consisting only of those functions that take the value zero at the infimum of the set ''E''. Many authors refer to ''C''&lt;sub&gt;0&lt;/sub&gt; as "classical Wiener space".

==Properties of classical Wiener space==
===Uniform topology===
The vector space ''C'' can be equipped with the [[uniform norm]]

:&lt;math&gt;\| f \| := \sup_{t \in [0, T]} | f(t) |&lt;/math&gt;

turning it into a [[normed vector space]] (in fact a [[Banach space]]). This norm induces a [[metric (mathematics)|metric]] on ''C'' in the usual way: &lt;math&gt;d (f, g) := \| f-g \|&lt;/math&gt;. The [[topology]] generated by the [[open set]]s in this metric is the topology of [[uniform convergence]] on [0, ''T''], or the [[uniform topology (disambiguation)|uniform topology]].

Thinking of the domain [0, ''T''] as "time" and the range '''R'''&lt;sup&gt;''n''&lt;/sup&gt; as "space", an intuitive view of the uniform topology is that two functions are "close" if we can "wiggle space a bit" and get the graph of ''f'' to lie on top of the graph of ''g'', while leaving time fixed. Contrast this with the [[Càdlàg#Skorokhod space|Skorokhod topology]], which allows us to "wiggle" both space and time.

===Separability and completeness===
With respect to the uniform metric, ''C'' is both a [[separable space|separable]] and a [[complete space]]:
* separability is a consequence of the [[Stone-Weierstrass theorem]];
* completeness is a consequence of the fact that the uniform limit of a sequence of continuous functions is itself continuous.

Since it is both separable and complete, ''C'' is a [[Polish space]].

===Tightness in classical Wiener space===
Recall that the [[modulus of continuity]] for a function ''f'' : [0, ''T''] → '''R'''&lt;sup&gt;''n''&lt;/sup&gt; is defined by

:&lt;math&gt;\omega_{f} (\delta) := \sup \left\{ | f(s) - f(t) | \left| s, t \in [0, T], | s - t | \leq \delta \right. \right\}.&lt;/math&gt;

This definition makes sense even if ''f'' is not continuous, and it can be shown that ''f'' is continuous [[if and only if]] its modulus of continuity tends to zero as δ → 0:

:&lt;math&gt;f \in C \iff \omega_{f} (\delta) \to 0&lt;/math&gt; as δ → 0.

By an application of the [[Arzelà-Ascoli theorem]], one can show that a sequence &lt;math&gt;(\mu_{n})_{n = 1}^{\infty}&lt;/math&gt; of [[probability measure]]s on classical Wiener space ''C'' is [[tightness of measures|tight]] if and only if both the following conditions are met:

:&lt;math&gt;\lim_{a \to \infty} \limsup_{n \to \infty} \mu_{n} \{ f \in C | | f(0) | \geq a \} = 0,&lt;/math&gt; and
:&lt;math&gt;\lim_{\delta \to 0} \limsup_{n \to \infty} \mu_{n} \{ f \in C | \omega_{f} (\delta) \geq \varepsilon \} = 0&lt;/math&gt; for all ε &gt; 0.

===Classical Wiener measure===
There is a "standard" measure on ''C''&lt;sub&gt;0&lt;/sub&gt;, known as '''classical Wiener measure''' (or simply '''Wiener measure'''). Wiener measure has (at least) two equivalent characterizations:

If one defines [[Brownian motion]] to be a [[Markov property|Markov]] [[stochastic process]] ''B'' : [0, ''T''] × Ω → '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, starting at the origin, with [[almost surely]] continuous paths and [[independent increments]]

:&lt;math&gt;B_{t} - B_{s} \sim \mathrm{Normal} \left( 0, | t - s | \right),&lt;/math&gt;

then classical Wiener measure γ is the [[law (stochastic processes)|law]] of the process ''B''.

Alternatively, one may use the [[abstract Wiener space]] construction, in which classical Wiener measure γ is the [[Radonifying function|radonification]] of the [[Cylinder set measure#Cylinder set measures on Hilbert spaces|canonical Gaussian cylinder set measure]] on the Cameron-Martin [[Hilbert space]] corresponding to ''C''&lt;sub&gt;0&lt;/sub&gt;.

Classical Wiener measure is a [[Gaussian measure]]: in particular, it is a [[strictly positive measure|strictly positive]] probability measure.

Given classical Wiener measure γ on ''C''&lt;sub&gt;0&lt;/sub&gt;, the [[product measure]] γ&lt;sup&gt;''n''&lt;/sup&gt; × γ is a probability measure on ''C'', where γ&lt;sup&gt;''n''&lt;/sup&gt; denotes the standard [[Gaussian measure]] on '''R'''&lt;sup&gt;''n''&lt;/sup&gt;.

==See also==
* [[Càdlàg|Skorokhod space]], a generalization of classical Wiener space, which allows functions to be discontinuous
* [[Abstract Wiener space]]
* [[Wiener process]]

[[Category:Stochastic processes]]
[[Category:Metric geometry]]</text>
      <sha1>m0ru3kz3zejjvcwumtmof6eycq8egft</sha1>
    </revision>
  </page>
  <page>
    <title>Commutator</title>
    <ns>0</ns>
    <id>7193</id>
    <revision>
      <id>865761364</id>
      <parentid>865761104</parentid>
      <timestamp>2018-10-26T00:03:58Z</timestamp>
      <contributor>
        <ip>96.241.163.169</ip>
      </contributor>
      <comment>/* Lie-algebra identities */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12468">{{about|the mathematical concept|the electrical component|Commutator (electric)|the relation between [[conjugate variables|canonical conjugate entities]]|Canonical commutation relation|other uses|Commutation (disambiguation){{!}}Commutation}}
In [[mathematics]], the '''commutator''' gives an indication of the extent to which a certain [[binary operation]] fails to be [[commutative]]. There are different definitions used in [[group theory]] and [[ring theory]].

== Group theory ==
The '''commutator''' of two elements, {{mvar|g}} and {{mvar|h}}, of a [[group (mathematics)|group]] {{mvar|G}}, is the element
: {{math|[''g'', ''h''] {{=}} ''g''&lt;sup&gt;−1&lt;/sup&gt;''h''&lt;sup&gt;−1&lt;/sup&gt;''gh''}}.

It is equal to the group's identity if and only if {{mvar|g}} and {{mvar|h}} commute (i.e., if and only if {{math|''gh'' {{=}} ''hg''}}). The [[subgroup]] of ''G'' [[Generating set of a group|generated]] by all commutators is called the ''derived group'' or the ''[[commutator subgroup]]'' of ''G''. Note that one must consider the subgroup generated by the set of commutators because in general the set of commutators is not closed under the group operation. Commutators are used to define [[nilpotent group|nilpotent]] and [[solvable group|solvable]] groups.

The above definition of the commutator is used by some group theorists, as well as throughout this article. However, many other group theorists define the commutator as
:{{math|[''g'', ''h''] {{=}} ''ghg''&lt;sup&gt;−1&lt;/sup&gt;''h''&lt;sup&gt;−1&lt;/sup&gt;}}.&lt;ref&gt;{{harvtxt|Fraleigh|1976|p=108}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Herstein|1975|p=65}}&lt;/ref&gt;

=== Identities (group theory) ===
Commutator identities are an important tool in [[group theory]].&lt;ref&gt;{{harvtxt|McKay|2000|p=4}}&lt;/ref&gt; The expression {{math|''a&lt;sup&gt;x&lt;/sup&gt;''}} denotes the [[conjugate (group theory)#Definition|conjugate]] of {{mvar|a}} by {{mvar|x}}, defined as {{math|''x''&lt;sup&gt;−1&lt;/sup&gt;''ax''}}.

# &lt;math&gt;x^y = x[x, y].&lt;/math&gt;
# &lt;math&gt;[y, x] = [x,y]^{-1}.&lt;/math&gt;
# &lt;math&gt;[x, zy] = [x, y]\cdot [x, z]^y&lt;/math&gt; and &lt;math&gt;[x z, y] = [x, y]^z \cdot [z, y].&lt;/math&gt;
# &lt;math&gt;\left[x, y^{-1}\right] = [y, x]^{y^{-1}}&lt;/math&gt; and &lt;math&gt;\left[x^{-1}, y\right] = [y, x]^{x^{-1}}.&lt;/math&gt;
# &lt;math&gt;\left[\left[x, y^{-1}\right], z\right]^y \cdot \left[\left[y, z^{-1}\right], x\right]^z \cdot \left[\left[z, x^{-1}\right], y\right]^x = 1&lt;/math&gt; and &lt;math&gt;\left[\left[x, y\right], z^x\right] \cdot  \left[[z ,x], y^z\right] \cdot \left[[y, z], x^y\right] = 1.&lt;/math&gt;

Identity (5) is also known as the ''Hall–Witt identity'', after [[Philip Hall]] and [[Ernst Witt]].  It is a group-theoretic analogue of the [[Jacobi identity]] for the ring-theoretic commutator (see next section).

N.B., the above definition of the conjugate of {{mvar|a}} by {{mvar|x}} is used by some group theorists.&lt;ref&gt;{{harvtxt|Herstein|1975|p=83}}&lt;/ref&gt;  Many other group theorists define the conjugate of {{mvar|a}} by {{mvar|x}} as {{math|''xax&lt;sup&gt;−1&lt;/sup&gt;''}}.&lt;ref&gt;{{harvtxt|Fraleigh|1976|p=128}}&lt;/ref&gt;  This is often written &lt;math&gt;{}^x a&lt;/math&gt;.  Similar identities hold for these conventions.

Many identities are used that are true modulo certain subgroups.  These can be particularly useful in the study of [[solvable group]]s and [[nilpotent group]]s.  For instance, in any group, second powers behave well:
:&lt;math&gt;(xy)^2 = x^2 y^2 [y, x][[y, x], y].&lt;/math&gt;

If the [[derived subgroup]] is central, then
:&lt;math&gt;(xy)^n = x^n y^n [y, x]^\binom{n}{2}.&lt;/math&gt;

== Ring theory ==&lt;!-- This section is linked from [[Lie algebra]] --&gt;
The '''commutator''' of two elements ''a'' and ''b'' of a [[ring (algebra)|ring]] or an [[associative algebra]] is defined by
: &lt;math&gt;[a, b] = ab - ba.&lt;/math&gt;

It is zero if and only if ''a'' and ''b'' commute. In [[linear algebra]], if two [[endomorphism]]s of a space are represented by commuting matrices in terms of one basis, then they are so represented in terms of every basis. By using the commutator as a [[Lie algebra|Lie bracket]], every associative algebra can be turned into a [[Lie algebra]].

The '''anticommutator''' of two elements {{mvar|a}} and {{mvar|b}} of a ring or an associative algebra is defined by
: &lt;math&gt;\{a, b\} = ab + ba.&lt;/math&gt;

Sometimes the brackets [ ]&lt;sub&gt;+&lt;/sub&gt; are also used to denote anticommutators, while [ ]&lt;sub&gt;−&lt;/sub&gt; is then used for commutators.&lt;ref&gt;{{harvtxt|McMahon|2008}}&lt;/ref&gt; The anticommutator is used less often than the commutator, but can be used, for example, to define [[Clifford algebra]]s, [[Jordan algebra]]s and is utilized to derive the [[Dirac equation]] in particle physics.

The commutator of two operators acting on a [[Hilbert space]] is a central concept in [[quantum mechanics]], since it quantifies how well the two [[observable]]s described by these operators can be measured simultaneously. The [[uncertainty principle]] is ultimately a theorem about such commutators, by virtue of the [[Uncertainty relation|Robertson–Schrödinger relation]].&lt;ref&gt;{{harvtxt|Liboff|2003|pp=140–142}}&lt;/ref&gt; In [[phase space]], equivalent commutators of function [[Moyal product|star-products]] are called [[Moyal bracket]]s, and are completely isomorphic to the Hilbert-space commutator structures mentioned.

=== Identities (ring theory) ===
The commutator has the following properties:

====Lie-algebra identities====
# &lt;math&gt;[A + B, C] = [A, C] + [B, C]&lt;/math&gt;
# &lt;math&gt;[A, A] = 0&lt;/math&gt;
# &lt;math&gt;[A, B] = -[B, A]&lt;/math&gt;
# &lt;math&gt;[A, [B, C]] + [B, [C, A]] + [C, [A, B]] = 0&lt;/math&gt;

The third relation is called [[anticommutativity]], while the fourth is the [[Jacobi identity]].

====Additional identities====
# &lt;math&gt;[A, BC] = [A, B]C + B[A, C]&lt;/math&gt;
# &lt;math&gt;[A, BCD] = [A, B]CD + B[A, C]D + BC[A, D]&lt;/math&gt;
# &lt;math&gt;[A, BCDE] = [A, B]CDE + B[A, C]DE + BC[A, D]E + BCD[A, E]&lt;/math&gt;
# &lt;math&gt;[AB, C] = A[B, C] + [A, C]B&lt;/math&gt;
# &lt;math&gt;[ABC, D] = AB[C, D] + A[B, D]C + [A, D]BC&lt;/math&gt;
# &lt;math&gt;[ABCD, E] = ABC[D, E] + AB[C, E]D + A[B, E]CD + [A, E]BCD&lt;/math&gt;
# &lt;math&gt;[AB, CD] = A[B, CD] +[A, CD]B &lt;/math&gt;
# &lt;math&gt;[A, B + C] = [A, B] + [A, C]&lt;/math&gt;
# &lt;math&gt;[A + B, C + D] = [A, C] + [A, D] + [B, C] + [B, D]&lt;/math&gt;

An additional identity may be found for this last expression, in the form:
# &lt;math&gt;[AB, CD] = A[B, C]D + [A, C]BD + CA[B, D] + C[A, D]B&lt;/math&gt;
# &lt;math&gt;[[A, C], [B, D]] = [[[A, B], C], D] + [[[B, C], D], A] + [[[C, D], A], B] + [[[D, A], B], C]&lt;/math&gt;

If {{mvar|A}} is a fixed element of a ring ''R'', the first additional identity can be interpreted as a [[product rule|Leibniz rule]] for the map &lt;math&gt;\operatorname{ad}_A: R \rightarrow R&lt;/math&gt; given by  &lt;math&gt;\operatorname{ad}_A(B) = [A, B]&lt;/math&gt;.  In other words, the map ad&lt;sub&gt;''A''&lt;/sub&gt; defines a [[derivation (abstract algebra)|derivation]] on the ring ''R''.  The second and third identities represent Leibniz rules for more than two factors that are valid for any derivation.  Identities 4–6 can also be interpreted as Leibniz rules for a certain derivation.

[[Hadamard's lemma]], applied on nested commutators holds, and underlies the [[Baker–Campbell–Hausdorff formula#An important lemma|Baker–Campbell–Hausdorff expansion]] of log(exp(''A'') exp(''B'')):
* &lt;math&gt;e^A Be^{-A}
  \equiv B + [A, B] + \frac{1}{2!}[A, [A, B]] + \frac{1}{3!}[A, [A, [A, B]]] + \cdots
  \equiv e^{\operatorname{ad}(A)} B.
&lt;/math&gt;

This formula is valid in any ring or algebra in which the [[exponential function]] can be meaningfully defined, for example, in a [[Banach algebra]] or in a ring of [[formal power series]].

Use of the same expansion expresses the above Lie group commutator in terms of a series of nested Lie bracket (algebra) commutators,
* &lt;math&gt;
  \ln \left(e^A e^B e^{-A} e^{-B}\right) =
  [A, B] + \frac{1}{2!}[(A + B), [A, B]] + \frac{1}{3!} \left(\frac{1}{2} [A, [B, [B, A]]] + [(A + B), [(A + B), [A, B]]]\right) + \cdots.
&lt;/math&gt;

These identities can be written more generally using the subscript convention to include the anticommutator defined above.&lt;ref&gt;
{{cite web
 | url= https://arxiv.org/pdf/1304.5050.pdf
 | title= Jacobi -type identities in algebras and superalgebras
 | last= Lavrov
 | first= P.M.
 | date=
 | website=
 | publisher=
 | access-date=
 | quote=
}}&lt;/ref&gt;
For example, 
# &lt;math&gt;[AB, C]_- = A[B, C]_\mp \pm [A, C]_\mp B&lt;/math&gt;
# &lt;math&gt;[AB, CD]_- = A[B, C]_\mp D \pm AC[B, D]_\mp + [A, C]_\mp DB \pm C[A, D]_\mp B&lt;/math&gt;
# &lt;math&gt;\left[A, [B, C]_\pm\right] + \left[B, [C, A]_\pm\right] + \left[C, [A, B]_\pm\right] = 0&lt;/math&gt;

== Graded rings and algebras ==
When dealing with [[graded algebra]]s, the commutator is usually replaced by the '''graded commutator''', defined in homogeneous components as 
:&lt;math&gt;[\omega, \eta]_{gr} := \omega\eta - (-1)^{\deg \omega \deg \eta} \eta\omega.&lt;/math&gt;

== Derivations ==
Especially if one deals with multiple commutators, another notation turns out to be useful, the [[adjoint representation of a Lie algebra|adjoint representation]]:
: &lt;math&gt;\operatorname{ad} (x)(y) = [x, y] .&lt;/math&gt;

Then {{math|ad(''x'')}} is a linear [[derivation (abstract algebra)|derivation]]:   
: &lt;math&gt;\operatorname{ad}(x + y) = \operatorname{ad}(x) + \operatorname{ad}(y)&lt;/math&gt; and &lt;math&gt;\operatorname{ad}(\lambda x) = \lambda \operatorname{ad}(x)&lt;/math&gt;

and, crucially, it is a [[Lie algebra]] homomorphism:
: &lt;math&gt;\operatorname{ad}([x, y]) = [\operatorname{ad}(x), \operatorname{ad}(y)]~.&lt;/math&gt;

By contrast, it is '''not''' always an algebra homomorphism; '''it does not hold in general''':
: &lt;math&gt;\operatorname{ad}(xy) \,\stackrel{?}{=}\, \operatorname{ad}(x)\operatorname{ad}(y) &lt;/math&gt;

; Examples: &lt;math&gt;\begin{align}
      \operatorname{ad}(x)\operatorname{ad}(x)(y) &amp;= [x, [x, y]\,] \\
  \operatorname{ad}(x)\operatorname{ad}(a + b)(y) &amp;= [x, [a + b, y]\,]
\end{align}&lt;/math&gt;

=== General Leibniz rule ===
The [[general Leibniz rule]], expanding repeated derivatives of a product, can be written abstractly using the adjoint representation:
: &lt;math&gt;x^n y = \sum_{k = 0}^n \binom{n}{k} \left(\operatorname{ad}(x)\right)^k(y)\, x^{n - k}&lt;/math&gt;

Replacing ''x'' by the differentiation operator &lt;math&gt;\partial&lt;/math&gt;, and ''y'' by the multiplication operator &lt;math&gt;m_f:g\mapsto fg&lt;/math&gt;, we get &lt;math&gt;\operatorname{ad}(\partial)(m_f) = m_{\partial(f)}&lt;/math&gt;, and applying both sides to a function ''g'', the identity becomes the general Leibniz rule for &lt;math&gt;\partial^n(fg)&lt;/math&gt;.

== See also ==
* [[Anticommutativity]]
* [[Associator]]
* [[Baker–Campbell–Hausdorff formula]]
* [[Canonical commutation relation]]
* [[Centralizer]] a.k.a. [[commutant]]
* [[Derivation (abstract algebra)]]
* [[Moyal bracket]]
* [[Pincherle derivative]]
* [[Poisson bracket]]
* [[Ternary commutator]]
* [[Three subgroups lemma]]

== Notes ==
{{Reflist}}

== References ==
* {{citation | first1 = John B. | last1 = Fraleigh | year = 1976 | isbn = 0-201-01984-1 | title = A First Course In Abstract Algebra | edition = 2nd | publisher = [[Addison-Wesley]] | location = Reading }}
*{{citation | last1 = Griffiths | first1 = David J. | author1-link = David J. Griffiths | title=Introduction to Quantum Mechanics | edition = 2nd | publisher = [[Prentice Hall]] |year=2004 |isbn=0-13-805326-X}}
*{{citation | first = I. N. | last = Herstein | authorlink= Israel Nathan Herstein | year = 1975 | title = Topics In Algebra | edition= 2nd | publisher = [[John Wiley &amp; Sons]] }}
*{{citation | last1=Liboff | first1=Richard L. | author1-link = Richard L. Liboff | title=Introductory Quantum Mechanics | edition = 4th | publisher = [[Addison-Wesley]] | year=2003 | isbn=0-8053-8714-5}}
*{{Citation | last1=McKay | first1=Susan | title=Finite p-groups | publisher = [[University of London]] | series=Queen Mary Maths Notes | isbn=978-0-902480-17-9 | mr=1802994 | year=2000 | volume=18}}
* {{citation | first1 = D. | last1 = McMahon | year = 2008 | isbn = 978-0-07-154382-8 | title = Quantum Field Theory | publisher = [[McGraw Hill]] | location = USA }}

==Further reading==
*{{citation | author1-first= R.| author1-last= McKenzie | author2-first= J. | author2-last= Snow | author1-link= Ralph McKenzie | contribution= Congruence modular varieties: commutator theory | title= Structural Theory of Automata, Semigroups, and Universal Algebra | editor1-first= V. B. | editor1-last= Kudryavtsev | editor2-first= I. G. | editor2-last= Rosenberg| pages= 273–329 | year= 2005 | publisher= Springer}}

==External links==
* {{springer|title=Commutator|id=p/c023430}}

[[Category:Abstract algebra]]
[[Category:Group theory]]
[[Category:Binary operations]]
[[Category:Mathematical identities]]</text>
      <sha1>1z23wp25t8ghfu1mfrt3zuvhs6sdwsm</sha1>
    </revision>
  </page>
  <page>
    <title>Confluence (abstract rewriting)</title>
    <ns>0</ns>
    <id>3755377</id>
    <revision>
      <id>860341974</id>
      <parentid>860341163</parentid>
      <timestamp>2018-09-20T00:38:46Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <minor/>
      <comment>linking</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12456">[[Image:Koblenz im Buga-Jahr 2011 - Deutsches Eck 01.jpg|thumb|'''Pic.1:''' The name ''confluence'' is inspired from [[Confluence|geography]], meaning there the meeting of two bodies of water.]]
In computer science, '''confluence''' is a property of [[rewriting]] systems, describing which terms in such a system can be rewritten in more than one way, to yield the same result. This article describes the properties in the most abstract setting of an [[abstract rewriting system]].

== Motivating examples ==

[[File:Confluence example expression.svg|right]]
The usual rules of elementary arithmetic form an abstract rewriting system.
For example, the expression (11 + 9) × (2 + 4) can be evaluated starting either at the left or at the right parentheses;
however, in both cases the same result is obtained eventually.
This suggests that the arithmetic rewriting system is a confluent one.

A second, more abstract example is obtained from the following proof of each [[Group_(mathematics)|group]] element equalling the [[Group_(mathematics)#Definition|inverse]] of its inverse:
&lt;ref&gt;{{cite book| title=Deduktionsssysteme| year=1992| pages=291| publisher=Oldenbourg| editor=K. H. Bläsius and H.-J. Bürckert}}; here: p.134; axiom and proposition names follow the original text&lt;/ref&gt;

{| style="border: 1px solid grey; float: left; margin: 1em 1em;"
|+ Group axioms
|- 
| '''A1''' || 1 ⋅ ''a'' || = ''a''
|-
| '''A2''' || ''a''&lt;sup&gt;−1&lt;/sup&gt; ⋅ ''a'' || = 1
|-
| '''A3''' &amp;nbsp; &amp;nbsp; || (''a'' ⋅ ''b'') ⋅ ''c'' || = ''a'' ⋅ (''b'' ⋅ ''c'')
|}
{| style="border: 1px solid grey; float: left; margin: 1em 1em;"
|+ Proof of '''R4''': ''a''&lt;sup&gt;−1&lt;/sup&gt;⋅(''a''⋅''b'') = ''b''
|-
|   || ''a''&lt;sup&gt;−1&lt;/sup&gt; ⋅ (''a'' ⋅ ''b'') ||
|-
| = || (''a''&lt;sup&gt;−1&lt;/sup&gt; ⋅ ''a'') ⋅ ''b'' || by A3(r) &amp;nbsp;  &amp;nbsp; 
|-
| = || 1 ⋅ ''b'' || by A2
|-
| = || ''b'' || by A1
|} 
{| style="border: 1px solid grey; float: left; margin: 1em 1em;"
|+ Proof of '''R6''': (''a''&lt;sup&gt;−1&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt; ⋅ 1 = ''a''
|-
|   || (''a''&lt;sup&gt;−1&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt; ⋅ 1 ||
|-
| = || (''a''&lt;sup&gt;−1&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt; ⋅ (''a''&lt;sup&gt;−1&lt;/sup&gt; ⋅ ''a'') || by A2(r)
|-
| = || ''a'' || by R4
|}
{| style="border: 1px solid grey; float: left; margin: 1em 1em;"
|+ Proof of '''R10''': (''a''&lt;sup&gt;−1&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt; ⋅ ''b'' = ''a'' ⋅ ''b''
|-
|   || (''a''&lt;sup&gt;−1&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt; ⋅ ''b'' ||
|-
| = || (''a''&lt;sup&gt;−1&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt; ⋅ (''a''&lt;sup&gt;−1&lt;/sup&gt; ⋅ (''a'' ⋅ ''b'')) || by R4(r)
|-
| = || ''a'' ⋅ ''b'' || by R4
|} 
{| style="border: 1px solid grey; float: left; margin: 1em 1em;"
|+ Proof of '''R11''': ''a'' ⋅ 1 = ''a''
|-
|   || ''a'' ⋅ 1 ||
|-
| = || (''a''&lt;sup&gt;−1&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt; ⋅ 1 || by R10(r)
|-
| = || ''a'' || by R6
|} 
{| style="border: 1px solid grey; float: left; margin: 1em 1em;"
|+ Proof of '''R12''': (''a''&lt;sup&gt;−1&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt; = ''a''
|-
|   || (''a''&lt;sup&gt;−1&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt; ||
|-
| = || (''a''&lt;sup&gt;−1&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt; ⋅ 1 || by R11(r) &amp;nbsp;  &amp;nbsp; 
|-
| = || ''a'' || by R6
|}
{{clear}}
This proof starts from the given group axioms A1-A3, and establishes five propositions R4, R6, R10, R11, and R12, each of them using some earlier ones, and R12 being the main theorem. Some of the proofs require non-obvious, if not creative, steps, like applying axiom A2 in reverse, thereby rewriting "1" to "''a''&lt;sup&gt;−1&lt;/sup&gt; ⋅ a" in the first step of R6's proof. One of the historical motivations to develop the ''theory of term rewriting'' was to avoid the need for such steps, which are difficult to find by an unexperienced human, let alone by a computer program. 

If a [[Term_rewriting#Term_rewriting_systems|term rewriting system]] is '''confluent''' and ''[[Rewriting#Termination|terminating]]'', a straightforward method exists to prove equality between two expressions (a.k.a. ''[[term (logic)|terms]]'') ''s'' and ''t'':
Starting with ''s'', apply equalities&lt;ref group=note&gt;then called ''rewrite rules'' to emphasize their left-to-right orientation&lt;/ref&gt; from left to right as long as possible, eventually obtaining a term ''s’''.
Obtain from ''t'' a term ''t’'' in a similar way.
If both terms ''s’'' and ''t’'' literally agree, then ''s'' and ''t'' are (not surprisingly) proven equal.
More important, if they disagree, ''s'' and ''t'' cannot be equal.
That is, any two terms ''s'' and ''t'' that can be proven equal at all, can be so by that method.

The success of that method doesn't depend on a certain sophisticated order in which to apply rewrite rules, as '''confluence''' ensures that any sequence of rule applications will eventually lead to the same result (while the ''termination'' property ensures that any sequence will eventually reach an end at all). Therefore, if a confluent and terminating term rewriting system can be provided for some equational theory,&lt;ref group=note&gt;The [[Knuth–Bendix completion algorithm]] can be used to compute such a system from a given set of equations. Such a system e.g. for groups is shown [[Word problem (mathematics)#Example: A term rewriting system to decide the word problem in the free group|here]], with its propositions consistently numbered. Using it, a proof of e.g. R6 consists in applying R11 and R12 in any order to (''a''&lt;sup&gt;−1&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt;⋅1 to obtain ''a''.; no other rules are applicable.&lt;/ref&gt; 
not a tinge of creativity is required to perform proofs of term equality; that task hence becomes amenable to computer programs. Modern approaches handle more general ''abstract rewriting systems'' rather than ''term'' rewriting systems; the latter are a special case of the former.

== General case and theory ==
[[Image:Confluence.svg|right|200px|thumb|'''Pic.2:''' In this diagram, {{mvar|a}} reduces to both {{mvar|b}} or {{mvar|c}} in zero or more rewrite steps (denoted by the asterisk). In order for the rewrite relation to be confluent, both reducts must in turn reduce to some common {{mvar|d}}.]]

A rewriting system can be expressed as a [[directed graph]] in which nodes represent expressions and edges represent rewrites. So, for example, if the expression ''a'' can be rewritten into ''b'', then we say that ''b'' is a ''reduct'' of ''a'' (alternatively, ''a'' ''reduces to'' ''b'', or ''a'' is an ''expansion'' of ''b''). This is represented using arrow notation; ''a'' → ''b'' indicates that ''a'' reduces to ''b''. Intuitively, this means that the corresponding graph has a directed edge from ''a'' to ''b''.

If there is a path between two graph nodes ''c'' and ''d'', then it forms a ''reduction sequence''. So, for instance, if ''c'' → ''c''’ → ''c''’’ → ... → ''d''’ → ''d'', then we can write ''c'' {{overset|&amp;lowast;|→}} ''d'', indicating the existence of a reduction sequence from ''c'' to ''d''. Formally, {{overset|&amp;lowast;|→}} is the [[Closure (mathematics)#P closures of binary relations|reflexive-transitive closure]] of →. Using the example from the previous paragraph, we have (11+9)×(2+4) → 20×(2+4) and 20×(2+4) → 20×6, so (11+9)×(2+4) {{overset|&amp;lowast;|→}} 20×6.

With this established, confluence can be defined as follows. ''a'' ∈ ''S'' is deemed confluent if for all pairs ''b'', ''c'' ∈ ''S'' such that ''a'' {{overset|&amp;lowast;|→}} ''b'' and ''a'' {{overset|&amp;lowast;|→}} ''c'', there exists a ''d'' ∈ ''S'' with ''b'' {{overset|&amp;lowast;|→}} ''d'' and ''c'' {{overset|&amp;lowast;|→}} ''d''. If every ''a'' ∈ ''S'' is confluent, we say that → is confluent, or has the ''Church-Rosser property''. This property is also sometimes called the ''diamond property'', after the shape of the diagram shown on the right. Some authors reserve the term ''diamond property'' for a variant of the diagram with single reductions everywhere; that is, whenever ''a'' → ''b'' and ''a'' → ''c'', there must exist a ''d'' such that ''b'' → ''d'' and ''c'' → ''d''. The single-reduction variant is strictly stronger than the multi-reduction one. 

=== Local confluence ===

[[File:Cyclic_locally,_but_not_globally_confluent_rewrite_system.png|thumb|'''Pic.3:''' Cyclic, locally-confluent, but not globally confluent rewrite system]]
[[File:Non-cyclic locally, but not globally confluent rewrite system.gif|thumb|'''Pic.4:''' Non-cyclic, locally-confluent, but not globally confluent rewrite system]]

An element ''a'' ∈ ''S'' is said to be locally (or weakly) confluent if for all ''b'', ''c'' ∈ ''S'' with ''a'' → ''b'' and ''a'' → ''c'' there exists ''d'' ∈ ''S'' with ''b'' {{overset|&amp;lowast;|→}} ''d'' and ''c'' {{overset|&amp;lowast;|→}} ''d''. If every ''a'' ∈ ''S'' is locally confluent, then → is called locally (or weakly) confluent, or having the ''weak Church-Rosser property''. This is different from confluence in that ''b'' and ''c'' must be reduced from ''a'' in one step. In analogy with this, confluence is sometimes referred to as ''global confluence''. 

The relation {{overset|&amp;lowast;|→}}, introduced as a notation for reduction sequences, may be viewed as a rewriting system in its own right, whose relation is the [[Closure_(mathematics)#P_closures_of_binary_relations|reflexive-transitive closure]] of ''→''. Since a sequence of reduction sequences is again a reduction sequence (or, equivalently, since forming the reflexive-transitive closure is [[idempotence#Unary operation|idempotent]]), {{overset|&amp;lowast;|{{overset|&amp;lowast;|→}}}} = {{overset|&amp;lowast;|→}}. It follows that → is confluent if and only if {{overset|&amp;lowast;|→}} is locally confluent.

A rewriting system may be locally confluent without being (globally) confluent. Examples are shown in picture 3 and 4. However, [[Newman's lemma]] states that if a locally confluent rewriting system has no infinite reduction sequences (in which case it is said to be ''terminating'' or ''strongly normalizing''), then it is globally confluent.

=== Semi-confluence ===

The definition of local confluence differs from that of global confluence in that only elements reached from a given element in a single rewriting step are considered. By considering one element reached in a single step and another element reached by an arbitrary sequence, we arrive at the intermediate concept of semi-confluence: ''a'' ∈ ''S'' is said to be semi-confluent if for all ''b'', ''c'' ∈ ''S'' with ''a'' → ''b'' and ''a'' {{overset|&amp;lowast;|→}} ''c'' there exists ''d'' ∈ ''S'' with ''b'' {{overset|&amp;lowast;|→}} ''d'' and ''c'' {{overset|&amp;lowast;|→}} ''d''; if every ''a'' ∈ ''S'' is semi-confluent, we say that → is semi-confluent. 

A semi-confluent element need not be confluent, but a semi-confluent rewriting system is necessarily confluent, and a confluent system is trivially semi-confluent.

=== Strong confluence ===

Strong confluence is another variation on local confluence that allows us to conclude that a rewriting system is globally confluent. An element ''a'' ∈ ''S'' is said to be strongly confluent if for all ''b'', ''c'' ∈ ''S'' with ''a'' → ''b'' and ''a'' → ''c'' there exists ''d'' ∈ ''S'' with ''b'' {{overset|&amp;lowast;|→}} ''d'' and either ''c'' → ''d'' or ''c'' = ''d''; if every ''a'' ∈ ''S'' is strongly confluent, we say that → is strongly confluent. 

A confluent element need not be strongly confluent, but a strongly confluent rewriting system is necessarily confluent.

== Examples of confluent systems ==
* Reduction of polynomials modulo an ideal is a confluent rewrite system provided one works with a [[Gröbner basis]].
* [[Matsumoto's theorem (group theory)|Matsumoto's theorem]] follows from confluence of the braid relations.
* β-reduction of λ-terms is confluent by the [[Church-Rosser theorem]].

== See also ==
* [[Church–Rosser theorem]]
* [[Convergence (logic)]]
* [[Critical pair (logic)]]
* [[Normal form (abstract rewriting)]]

== Notes ==
{{reflist|group=note}}

== References ==
* ''Term Rewriting Systems'', Terese, Cambridge Tracts in Theoretical Computer Science, 2003. 
* ''[https://books.google.com/books?id=N7BvXVUCQk8C&amp;printsec=frontcover#v=onepage&amp;q=confluence%20OR%20confluent&amp;f=false Term Rewriting and All That]'', [[Franz Baader]] and [[Tobias Nipkow]], Cambridge University Press, 1998
{{reflist}}

==External links==
* {{MathWorld | urlname=Confluent | title=Confluent}}

{{Authority control}}
{{DEFAULTSORT:Confluence (Abstract Rewriting)}}
[[Category:Rewriting systems]]</text>
      <sha1>it5e7zjs4xu9pcmxefd6qzncv059obo</sha1>
    </revision>
  </page>
  <page>
    <title>Convex volume approximation</title>
    <ns>0</ns>
    <id>22721042</id>
    <revision>
      <id>870284706</id>
      <parentid>794465835</parentid>
      <timestamp>2018-11-23T19:12:42Z</timestamp>
      <contributor>
        <ip>130.225.188.33</ip>
      </contributor>
      <comment>added "of"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6581">In the [[analysis of algorithms]], several authors have studied the computation of the [[volume]] of high-dimensional [[convex body|convex bodies]], a problem that can also be used to model many other problems in [[combinatorial enumeration]].
Often these works use a black box model of computation in which the input is given by a subroutine for testing whether a point is inside or outside of the convex body, rather than by an explicit listing of the vertices or faces of a [[convex polytope]].
It is known that, in this model, no [[deterministic algorithm]] can achieve an accurate approximation,{{R|E|BF}} and even for an explicit listing of faces or vertices the problem is [[Sharp-P-complete|#P-hard]].{{r|DF}}
However, a joint work by [[Martin Dyer]], [[Alan M. Frieze]] and [[Ravindran Kannan]] provided a randomized [[polynomial time approximation scheme]] for the problem,
providing a sharp contrast between the capabilities of randomized and deterministic algorithms.{{r|DFK}}

The main result of the paper is a randomized algorithm for finding an &lt;math&gt;\varepsilon&lt;/math&gt; approximation to the volume of a convex body &lt;math&gt;K&lt;/math&gt; in &lt;math&gt;n&lt;/math&gt;-dimensional Euclidean space by assuming the existence of a membership oracle. The algorithm takes time bounded by a polynomial in &lt;math&gt;n&lt;/math&gt;, the dimension of &lt;math&gt;K&lt;/math&gt; and &lt;math&gt;1/\varepsilon&lt;/math&gt;.
The algorithm combines two ideas:
*By using a [[Markov chain Monte Carlo]] (MCMC) method, it is possible to generate points that are nearly uniformly randomly distributed within a given convex body. The basic scheme of the algorithm is a nearly uniform sampling from within &lt;math&gt;K&lt;/math&gt; by placing a grid consisting of &lt;math&gt;n&lt;/math&gt;-dimensional cubes and doing a [[random walk]] over these cubes. By using the theory of [[Markov chain mixing time|rapidly mixing Markov chains]], they show that it takes a polynomial time for the random walk to settle down to being a nearly uniform distribution.{{r|DFK}}
*By using [[rejection sampling]], it is possible to compare the volumes of two convex bodies, one nested within another, when their volumes are within a small factor of each other. The basic idea is to generate random points within the outer of the two bodies, and to count how often those points are also within the inner body.
The given convex body can be approximated by a sequence of nested bodies, eventually reaching one of known volume (a hypersphere), with this approach used to estimate the factor by which the volume changes at each step of this sequence. Multiplying these factors gives the approximate volume of the original body.

This work earned its authors the 1991 [[Fulkerson Prize]].&lt;ref&gt;[http://www.ams.org/profession/prizes-awards/pabrowse?purl=fulkerson-prize Fulkerson Prize winners], [[American Mathematical Society]], retrieved 2017-08-03.&lt;/ref&gt;
Although the time for this algorithm is polynomial, it has a high exponent.
Subsequent authors improved the running time of this method by providing more quickly mixing Markov chains for the same problem.{{r|AK|KLS|LS|LV}}

==References==
{{reflist|refs=

&lt;ref name=AK&gt;{{citation
 | last1 = Applegate | first1 = David | author1-link = David Applegate
 | last2 = Kannan | first2 = Ravi | author2-link = Ravindran Kannan
 | contribution = Sampling and Integration of Near Log-concave Functions
 | doi = 10.1145/103418.103439
 | isbn = 0-89791-397-3
 | location = New York, NY, USA
 | pages = 156–163
 | publisher = ACM
 | title = Proceedings of the Twenty-third Annual ACM Symposium on Theory of Computing (STOC '91)
 | year = 1991}}&lt;/ref&gt;

&lt;ref name=BF&gt;{{citation
 | last1 = Bárány | first1 = Imre | author1-link = Imre Bárány
 | last2 = Füredi | first2 = Zoltán | author2-link = Zoltán Füredi
 | doi = 10.1007/BF02187886
 | issue = 4
 | journal = [[Discrete and Computational Geometry]]
 | mr = 911186
 | pages = 319–326
 | title = Computing the volume is difficult
 | volume = 2
 | year = 1987}}&lt;/ref&gt;

&lt;ref name=DF&gt;{{citation
 | last1 = Dyer | first1 = Martin | author1-link = Martin Dyer
 | last2 = Frieze | first2 = Alan | author2-link = Alan M. Frieze
 | doi = 10.1137/0217060
 | issue = 5
 | journal = [[SIAM Journal on Computing]]
 | mr = 961051
 | pages = 967–974
 | title = On the complexity of computing the volume of a polyhedron
 | volume = 17
 | year = 1988}}&lt;/ref&gt;

&lt;ref name=DFK&gt;{{citation
 | last1 = Dyer | first1 = Martin | author1-link = Martin Dyer
 | last2 = Frieze | first2 = Alan | author2-link = Alan M. Frieze
 | last3 = Kannan | first3 = Ravi | author3-link = Ravindran Kannan
 | doi = 10.1145/102782.102783
 | issue = 1
 | journal = [[Journal of the ACM]]
 | mr = 1095916
 | pages = 1–17
 | title = A random polynomial-time algorithm for approximating the volume of convex bodies
 | volume = 38
 | year = 1991}}&lt;/ref&gt;

&lt;ref name=E&gt;{{citation
 | last = Elekes | first = G. | authorlink = György Elekes
 | doi = 10.1007/BF02187701
 | issue = 4
 | journal = [[Discrete and Computational Geometry]]
 | mr = 866364
 | pages = 289–292
 | title = A geometric inequality and the complexity of computing volume
 | volume = 1
 | year = 1986}}&lt;/ref&gt;

&lt;ref name=KLS&gt;{{citation
 | last1 = Kannan | first1 = Ravi | author1-link = Ravindran Kannan
 | last2 = Lovász | first2 = László | author2-link = László Lovász
 | last3 = Simonovits | first3 = Miklós | author3-link = Miklós Simonovits
 | doi = 10.1002/(SICI)1098-2418(199708)11:1&lt;1::AID-RSA1&gt;3.0.CO;2-X
 | issue = 1
 | journal = Random Structures &amp; Algorithms
 | mr = 1608200
 | pages = 1–50
 | title = Random walks and an &lt;math&gt;O^*(n^5)&lt;/math&gt; volume algorithm for convex bodies
 | volume = 11
 | year = 1997}}&lt;/ref&gt;

&lt;ref name=LS&gt;{{citation
 | last1 = Lovász | first1 = L. | author1-link = László Lovász
 | last2 = Simonovits | first2 = M. | author2-link = Miklós Simonovits
 | doi = 10.1002/rsa.3240040402
 | issue = 4
 | journal = Random Structures &amp; Algorithms
 | mr = 1238906
 | pages = 359–412
 | title = Random walks in a convex body and an improved volume algorithm
 | volume = 4
 | year = 1993}}&lt;/ref&gt;

&lt;ref name=LV&gt;{{citation
 | last1 = Lovász | first1 = L. | author1-link = László Lovász
 | last2 = Vempala | first2 = Santosh | author2-link = Santosh Vempala
 | doi = 10.1016/j.jcss.2005.08.004
 | issue = 2
 | journal = [[Journal of Computer and System Sciences]]
 | mr = 2205290
 | pages = 392–417
 | title = Simulated annealing in convex bodies and an &lt;math&gt;O^*(n^4)&lt;/math&gt; volume algorithm
 | volume = 72
 | year = 2006}}&lt;/ref&gt;
}}

[[Category:Computational geometry]]
[[Category:Approximation algorithms]]</text>
      <sha1>oc9400ybff0cbmwiwtst0kzykcy83yd</sha1>
    </revision>
  </page>
  <page>
    <title>Dan Segal</title>
    <ns>0</ns>
    <id>9276503</id>
    <revision>
      <id>806516025</id>
      <parentid>722857591</parentid>
      <timestamp>2017-10-22T14:58:32Z</timestamp>
      <contributor>
        <username>Melcous</username>
        <id>20472590</id>
      </contributor>
      <comment>per template, only for those notable enough for their own wiki article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3735">{{Infobox scientist
|name              = Dan Segal
|image             = Dan Segal.jpeg
|caption           = Dan Segal in 2008&lt;br /&gt;(photo from MFO)
|workplaces        = [[All Souls College, Oxford]]
|alma_mater        = [[Peterhouse, Cambridge]]&lt;br /&gt;[[University of London]]
|doctoral_advisor  = [[Bertram Wehrfritz]]
|doctoral_students = [[Geoff Smith (mathematician)|Geoff Smith]]&lt;br /&gt;[[Marcus du Sautoy]]
|prizes            = [[Adams Prize]] {{small|(1982)}}&lt;br&gt;[[Whitehead Prize]] {{small|(1985)}}&lt;br&gt;[[Pólya Prize (LMS)]] &lt;small&gt;(2012)&lt;/small&gt;
}}

'''Daniel Segal''' (born 1947)&lt;ref&gt;[http://www.science.unitn.it/~caranti/Conferences/PAGT2007/ 2007 website for a mathematical conference held on the 60th birthday of Dan Segal]&lt;/ref&gt; is a [[United Kingdom|British]] [[mathematician]] and a Professor of Mathematics at the [[University of Oxford]]. He specialises in [[algebra]] and [[group theory]].

He studied at [[Peterhouse, Cambridge]], before taking a [[PhD]] at [[Queen Mary, University of London|Queen Mary College]], [[University of London]], in 1972, supervised by [[Bertram Wehrfritz]], with a dissertation on [[group theory]] entitled ''Groups of [[Automorphism]]s of Infinite [[Soluble Group]]s''.&lt;ref&gt;{{MathGenealogy|id=52887}}&lt;/ref&gt; He is a Fellow of [[All Souls College]] at Oxford, where he is sub-warden.&lt;ref&gt;[http://www.all-souls.ox.ac.uk/people.php?personid=62 Professor Daniel Segal, sub-warden]&lt;/ref&gt;&lt;ref&gt;[http://www.maths.ox.ac.uk/people/profiles/dan.segal Homepage in Oxford]&lt;/ref&gt;

His postgraduate students have included [[Marcus du Sautoy]] and [[Geoff Smith (mathematician)|Geoff Smith]]. He is the son of psychoanalyst [[Hanna Segal]] and brother of philosopher [[Gabriel Segal]]. 

==Publications==
*''Polycyclic Groups'', Cambridge University Press 1983
*with J. Dixon, M. Du Sautoy, A. Mann ''Analytic pro-p-groups'', Cambridge University Press 1999,&lt;ref name=LubotzskyReview&gt;{{cite journal|author=[[Alexander Lubotzky|Lubotzky]], Alexander|title=Review of ''Analytic pro-p-groups'', ''New horizons in pro-p-groups'', and two other books|journal=Bull. Amer. Math. Soc. (N.S.)|year=2001|volume=38|issue=4|pages=475–479|url=http://www.ams.org/journals/bull/2001-38-04/S0273-0979-01-00914-4/ | doi = 10.1090/S0273-0979-01-00914-4}}&lt;/ref&gt; Paperback edn. 2003
*ed. with M. Du Sautoy, [[Aner Shalev|A. Shalev]] ''New horizons in pro-p-groups'', Birkhäuser 2000&lt;ref name="LubotzskyReview"/&gt;
*with [[Alexander Lubotzky]] ''Subgroup growth'', Birkhäuser 2003&lt;ref&gt;{{cite journal|author=Grigorchuk, Rostislav I.|authorlink=Rostislav Grigorchuk|title=Review: ''Subgroup growth'', by Alexander Lubotzky and Dan Segal|journal=Bull. Amer. Math. Soc. (N.S.)|year=2004|volume=41|issue=2|pages=253–256|url=http://www.ams.org/journals/bull/2004-41-02/S0273-0979-03-01003-6/|doi=10.1090/s0273-0979-03-01003-6}}&lt;/ref&gt;
*''Words: notes on verbal width in groups'', London Mathematical Society Lecture Notes, vol. 361, Cambridge University Press 2009&lt;ref&gt;{{cite journal|author=Nekrashevych, V.|title=Review: ''Words: notes on verbal width in groups'', by Dan Segal|journal=Bull. Amer. Math. Soc. (N.S.)|year=2011|volume=48|issue=3|pages=491–494|url=http://www.ams.org/journals/bull/2011-48-03/S0273-0979-2011-01333-7/|doi=10.1090/s0273-0979-2011-01333-7}}&lt;/ref&gt;

==References==
{{reflist}}

{{Authority control}}
{{DEFAULTSORT:Segal, Dan}}
[[Category:Living people]]
[[Category:20th-century British mathematicians]]
[[Category:21st-century British mathematicians]]
[[Category:Alumni of Peterhouse, Cambridge]]
[[Category:Alumni of the University of London]]
[[Category:Fellows of All Souls College, Oxford]]
[[Category:Group theorists]]
[[Category:Algebraists]]
[[Category:1947 births]]

{{UK-mathematician-stub}}</text>
      <sha1>euhqk4ot9lf30uwpmx8vqr21xlaxyh7</sha1>
    </revision>
  </page>
  <page>
    <title>Davies attack</title>
    <ns>0</ns>
    <id>9635691</id>
    <revision>
      <id>861578574</id>
      <parentid>861578257</parentid>
      <timestamp>2018-09-28T13:29:49Z</timestamp>
      <contributor>
        <username>Ntsimp</username>
        <id>1219859</id>
      </contributor>
      <comment>/* References */ update accessdate</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2641">In [[cryptography]], the '''Davies attack''' is a dedicated statistical [[cryptanalysis]] method for attacking the [[Data Encryption Standard]] (DES). The attack was originally created in 1987 by [[Donald Davies]]. In 1994, [[Eli Biham]] and [[Alex Biryukov]] made significant improvements to the technique. It is a [[known-plaintext attack]] based on the non-uniform [[probability distribution|distribution]] of the outputs of pairs of adjacent [[substitution box|S-boxes]]. It works by collecting many known plaintext/ciphertext pairs and calculating the [[empirical distribution function|empirical distribution]] of certain characteristics. Bits of the [[key (cryptography)|key]] can be deduced given sufficiently many known plaintexts, leaving the remaining bits to be found through [[brute force attack|brute force]]. There are tradeoffs between the number of required plaintexts, the number of key bits found, and the probability of success; the attack can find 24 bits of the key with 2&lt;sup&gt;52&lt;/sup&gt; known plaintexts and 53% success rate.

The Davies attack can be adapted to other [[Feistel cipher]]s besides DES. In 1998, Pornin developed techniques for analyzing and maximizing a cipher's resistance to this kind of cryptanalysis.

==References==
* {{cite journal
    | author = Donald Davies, [[Sean Murphy (cryptographer)|Sean Murphy]]
    | title = Pairs And Triplets Of DES S-Boxes
    | journal = [[Journal of Cryptology]]
    | volume = 8
    | issue = 1
    | issn = 0933-2790
    | pages = 1–25
    | date = 20 September 1993
    | url = https://www.bolet.org/~pornin/1998-asiacrypt-pornin.pdf
    | format = [[PDF]]
    | accessdate = 28 September 2018 }}
* {{cite conference
    | author = Eli Biham, Alex Biryukov
    | title = An Improvement of Davies' Attack on DES
    | conference = Advances in Cryptology — [[Eurocrypt]] '94
    | pages = 461–467
    | publisher = [[Springer-Verlag]]
    | date = May 1994
    | location = [[Perugia]]
    | url = http://citeseer.ist.psu.edu/467934.html
    | format = [[gzip]]ped PostScript
    | accessdate = 24 January 2007 }}
* {{cite conference
    | author = Thomas Pornin
    | title = Optimal Resistance Against the Davies and Murphy Attack
    | conference = Advances in Cryptology — [[ASIACRYPT]] '98
    | pages = 148–159
    | publisher = Springer-Verlag
    | date = October 1998
    | location = [[Beijing]]
    | url = https://www.bolet.org/~pornin/1998-asiacrypt-pornin.pdf
    | format = PDF
    | accessdate = 28 September 2018 }}

{{cryptography navbox|block}}

[[Category:Cryptographic attacks]]
[[Category:Data Encryption Standard]]


{{crypto-stub}}</text>
      <sha1>0dbz14lwwm77puqana1bmqyoy5dn613</sha1>
    </revision>
  </page>
  <page>
    <title>Deformation theory</title>
    <ns>0</ns>
    <id>679351</id>
    <revision>
      <id>866696683</id>
      <parentid>830315666</parentid>
      <timestamp>2018-10-31T23:24:53Z</timestamp>
      <contributor>
        <username>Jakob.scholbach</username>
        <id>1935000</id>
      </contributor>
      <comment>/* Applications of deformation theory */ Serre-Tate</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15844">In [[mathematics]], '''deformation theory''' is the study of ''infinitesimal conditions'' associated with varying a solution ''P'' of a problem to slightly different solutions ''P''&lt;sub&gt;ε&lt;/sub&gt;, where ε is a small number, or vector of small quantities. The infinitesimal conditions are therefore the result of applying the approach of [[differential calculus]] to solving a problem with [[Constraint (mathematics)|constraint]]s. One might  think, in analogy, of a structure that is not completely rigid, and that deforms slightly to accommodate forces applied from the outside; this explains the name.

Some characteristic phenomena are: the derivation of first-order equations by treating the ε quantities as having negligible squares; the possibility of ''isolated solutions'', in that varying a solution may not be possible, ''or'' does not bring anything new; and the question of whether the infinitesimal constraints actually 'integrate', so that their solution does provide small variations. In some form these considerations have a history of centuries in mathematics, but also in [[physics]] and [[engineering]]. For example, in the [[geometry of numbers]] a class of results called ''isolation theorems'' was recognised, with the topological interpretation of an ''open orbit'' (of a [[group action]]) around a given solution. [[Perturbation theory]] also looks at deformations, in general of [[Operator (mathematics)|operator]]s.

==Deformations of complex manifolds==
The most salient deformation theory in mathematics has been that of [[complex manifold]]s and [[algebraic varieties]]. This was put on a firm basis by foundational work of [[Kunihiko Kodaira]] and [[Donald C. Spencer]], after deformation techniques had received a great deal of more tentative application in the [[Italian school of algebraic geometry]]. One expects, intuitively, that deformation theory of the first order should equate the [[Zariski tangent space]] with a [[moduli space]]. The phenomena turn out to be rather subtle, though, in the general case.

In the case of [[Riemann surface]]s, one can explain that the complex structure on the [[Riemann sphere]] is isolated (no moduli). For genus 1, an [[elliptic curve]] has a one-parameter family of complex structures, as shown in [[elliptic function]] theory. The general Kodaira–Spencer theory identifies as the key to the deformation theory the [[sheaf cohomology]] group

: &lt;math&gt; H_1(\Theta) \, &lt;/math&gt;

where Θ is (the sheaf of germs of sections of) the holomorphic [[tangent bundle]]. There is an obstruction in the ''H''&lt;sup&gt;2&lt;/sup&gt; of the same sheaf; which is always zero in case of a curve, for general reasons of dimension. In the case of genus 0 the ''H''&lt;sup&gt;1&lt;/sup&gt; vanishes, also. For genus 1 the dimension is the [[Hodge number]] ''h''&lt;sup&gt;1,0&lt;/sup&gt; which is therefore 1.  It is known that all curves of genus one have equations of form ''y''&lt;sup&gt;2&lt;/sup&gt; = ''x''&lt;sup&gt;3&lt;/sup&gt; + ''ax'' + ''b''.  These obviously depend on two parameters, a and b, whereas the isomorphism classes of such curves have only one parameter.  Hence there must be an equation relating those a and b which describe isomorphic elliptic curves.  It turns out that curves for which ''b''&lt;sup&gt;2&lt;/sup&gt;''a''&lt;sup&gt;−3&lt;/sup&gt; has the same value, describe isomorphic curves.  I.e. varying a and b is one way to deform the structure of the curve ''y''&lt;sup&gt;2&lt;/sup&gt; = ''x''&lt;sup&gt;3&lt;/sup&gt; + ''ax'' + ''b'', but not all variations of ''a,b'' actually change the isomorphism class of the curve.

One can go further with the case of genus ''g'' &gt; 1, using [[Serre duality]] to relate the  ''H''&lt;sup&gt;1&lt;/sup&gt; to

: &lt;math&gt; H^0(\Omega^{[2]}) &lt;/math&gt;

where Ω is the holomorphic [[cotangent bundle]] and the notation Ω&lt;sup&gt;[2]&lt;/sup&gt; means the ''tensor square'' (''not'' the second [[exterior power]]). In other words, deformations are regulated by holomorphic [[quadratic differential]]s on a Riemann surface, again something known classically. The dimension of the moduli space, called [[Teichmüller space]] in this case, is computed as 3''g'' &amp;minus; 3, by the [[Riemann–Roch theorem]].

These examples are the beginning of a theory applying to holomorphic families of complex manifolds, of any dimension. Further developments included: the extension by Spencer of the techniques to other structures of [[differential geometry]]; the assimilation of the Kodaira–Spencer theory into the abstract algebraic geometry of [[Grothendieck]], with a consequent substantive clarification of earlier work; and deformation theory of other structures, such as algebras.

==Functorial description==
Another method for formalizing deformation theory is using functors on the category of local Artin algebras over a field. A '''pre-deformation functor''' is defined as a functor
:&lt;math&gt;F: \text{Art}_k \to \text{Sets}&lt;/math&gt;
such that &lt;math&gt;F(k)&lt;/math&gt; is a point. The intuition is that we want to study the infinitesimal structure of some moduli space around a point where lying above that point is the space of interest. It is typically the case that it is easier to described the functor for a moduli problem instead of finding an actual space. For example, if we want to consider the moduli-space of hypersurfaces of degree &lt;math&gt;d&lt;/math&gt; in &lt;math&gt;\mathbb{P}^n&lt;/math&gt;, then we could consider the functor
:&lt;math&gt;F: \text{Sch} \to \text{Sets}&lt;/math&gt;
where
:&lt;math&gt;
F(S) = \left\{
\begin{matrix}
X \\
\downarrow \\
S
\end{matrix}
: \text{ each fiber is a degree } d \text{ hypersurface in }\mathbb{P}^n\right\}
&lt;/math&gt;

Although in general, it is more convenient/required to work with functor of groupoids instead of sets. This is true for moduli of curves.

===Technical remarks about infinitesimals===
Infinitesimals have long been in use by mathematicians for non-rigorous arguments in calculus. The idea is that if we consider polynomials &lt;math&gt;F(x,\varepsilon)&lt;/math&gt; with an infinitesimal &lt;math&gt;\varepsilon&lt;/math&gt;, then only the first order terms really matter; that is, we can consider
:&lt;math&gt; F(x,\varepsilon) \equiv f(x) + \varepsilon g(x) + O(\varepsilon^2)&lt;/math&gt;
A simple application of this is that we can find the derivatives of monomials using infinitesimals:
:&lt;math&gt; (x+\varepsilon)^3 = x^3 + 3x^2\varepsilon + O(\varepsilon^2)&lt;/math&gt;
the &lt;math&gt;\varepsilon&lt;/math&gt; term contains the derivative of the monomial, demonstrating its use in calculus. We could also interpret this equation as the first two terms of the Taylor expansion of the monomial. Infinitesimals can be made rigorous using nilpotent elements in local artin algebras. In the ring &lt;math&gt;k[y]/(y^2)&lt;/math&gt; we see that arguments with infinitesimals can work. This motivates the notation &lt;math&gt;k[\varepsilon] = k[y]/(y^2)&lt;/math&gt;. 

Moreover, if we want to consider higher-order terms of a taylor approximation then we could consider the artin algebras &lt;math&gt;k[y]/(y^k)&lt;/math&gt;. For our monomial, suppose we want to write out the second order expansion, then
:&lt;math&gt;(x+\varepsilon)^3 = x^3 + 3x^2\varepsilon + 3x\varepsilon^2 + \varepsilon^3&lt;/math&gt;
Recall that a Taylor expansion (at zero) can be written out as
:&lt;math&gt;f(x) = f(0) + \frac{f^{(1)}(x)}{1!} + \frac{f^{(2)}(x)}{2!} + \frac{f^{(3)}(x)}{3!} + \cdots &lt;/math&gt;
hence the previous two equations show that the second derivative of &lt;math&gt;x^3&lt;/math&gt; is &lt;math&gt;6x&lt;/math&gt;.

In general, since we want to consider arbitrary order Taylor expansions in any number of variables, we will consider the category of all local artin algebras over a field.

===Motivation===
To motivative the definition of a pre-deformation functor, consider the projective hypersurface over a field
:&lt;math&gt;
\begin{matrix}
\operatorname{Proj}\left( \dfrac{\mathbb{C}[x_0,x_1,x_2,x_3]}{(x_0^4 + x_1^4 + x_2^4 + x_3^4)} \right) \\
\downarrow \\
\operatorname{Spec}(k)
\end{matrix}
&lt;/math&gt;
If we want to consider an infinitesimal deformation of this space, then we could write down a Cartesian square
:&lt;math&gt;
\begin{matrix}
\operatorname{Proj}\left( \dfrac{\mathbb{C}[x_0,x_1,x_2,x_3]}{(x_0^4 + x_1^4 + x_2^4 + x_3^4)} \right) &amp; \to &amp; \operatorname{Proj}\left( \dfrac{ \mathbb{C}[x_0,x_1,x_2,x_3][\varepsilon]}{(x_0^4 + x_1^4 + x_2^4 + x_3^4 + \varepsilon  x_0^{a_0} x_1^{a_1} x_2^{a_2} x_3^{a_3}) } \right) \\
\downarrow &amp; &amp; \downarrow\\
\operatorname{Spec}(k) &amp; \to &amp; \operatorname{Spec}(k[\varepsilon])
\end{matrix}
&lt;/math&gt;
where &lt;math&gt;a_0 + a_1 + a_2 + a_3 = 4&lt;/math&gt;. Then, the space on the right hand corner is one example of an infinitesimal deformation: the extra scheme theoretic structure of the nilpotent elements in &lt;math&gt;\operatorname{Spec}(k[\varepsilon])&lt;/math&gt; (which is topologically a point) allows us to organize this infinitesimal data. Since we want to consider all possible expansions, we will let our predeformation functor be defined on objects as
:&lt;math&gt;
F(A) = \left\{
\begin{matrix}
\operatorname{Proj}\left( \dfrac{\mathbb{C}[x_0,x_1,x_2,x_3]}{(x_0^4 + x_1^4 + x_2^4 + x_3^4)} \right) &amp; \to &amp; \mathfrak{X} \\
\downarrow &amp; &amp; \downarrow \\
\operatorname{Spec}(k) &amp; \to &amp; \operatorname{Spec}(A)
\end{matrix}
\right\}
&lt;/math&gt;
where &lt;math&gt;A&lt;/math&gt; is a local Artin &lt;math&gt;k&lt;/math&gt;-algebra.

===Smooth pre-deformation functors===
A pre-deformation functor is called '''smooth''' if for any surjection &lt;math&gt;A' \to A&lt;/math&gt; such that the square of any element in the kernel is zero, there is a surjection
:&lt;math&gt;F(A') \to F(A)&lt;/math&gt;
This is motivated by the following question: given a deformation
:&lt;math&gt;
\begin{matrix}
X &amp; \to &amp; \mathfrak{X} \\
\downarrow &amp; &amp; \downarrow \\
\operatorname{Spec}(k) &amp; \to &amp; \operatorname{Spec}(A)
\end{matrix}
&lt;/math&gt;
does there exist an extension of this cartesian diagram to the cartesian diagrams
:&lt;math&gt;
\begin{matrix}
X &amp; \to &amp; \mathfrak{X} &amp; \to &amp; \mathfrak{X}' \\
\downarrow &amp; &amp; \downarrow &amp; &amp; \downarrow \\
\operatorname{Spec}(k) &amp; \to &amp; \operatorname{Spec}(A) &amp; \to &amp; \operatorname{Spec}(A')
\end{matrix}
&lt;/math&gt;
the name smooth comes from the lifting criterion of a smooth morphism of schemes.

===Tangent space===
Recall that the tangent space of a scheme &lt;math&gt;X&lt;/math&gt; can be described as the &lt;math&gt;\operatorname{Hom}&lt;/math&gt;-set
:&lt;math&gt;TX := \operatorname{Hom}_{\text{Sch}/k}(\operatorname{Spec}(k[x]),X)&lt;/math&gt;
Since we are considering the tangent space of a point of some moduli space, we can define the tangent space of our (pre)-deformation functor as
:&lt;math&gt;T_F := F(k[\varepsilon])&lt;/math&gt;

== Applications of deformation theory ==
=== Bend-and-break ===
Deformation theory was famously applied in [[birational geometry]] by [[Shigefumi Mori]] to study the existence of [[rational curve]]s on [[algebraic variety|varieties]].&lt;ref&gt;{{cite book| first=Olivier|last = Debarre | author-link = Olivier Debarre|  title = Higher-Dimensional Algebraic Geometry|year = 2001 | publisher= Springer| chapter = 3. Bend-and-Break Lemmas | series = Universitext}}&lt;/ref&gt; For a [[Fano variety]] of positive dimension Mori showed that there is a rational curve passing through every point. The method of the proof later became known as '''Mori's bend-and-break'''. The rough idea is to start with some curve ''C'' through a chosen point and keep deforming it until it breaks into several [[irreducible component|components]]. Replacing ''C'' by one of the components has the effect of decreasing either the   [[genus of a curve|genus]] or the [[degree of an algebraic variety|degree]] of ''C''. So after several repetitions of the procedure, eventually we'll obtain a curve of genus 0, i.e. a rational curve. The existence and the properties of deformations of ''C'' require arguments from deformation theory and a reduction to [[positive characteristic]].

===Arithmetic deformations===
One of the major applications of deformation theory is in arithmetic. It can be used to answer the following question: if we have a variety &lt;math&gt;X/\mathbb{F}_p&lt;/math&gt;, what are the possible extensions &lt;math&gt;\mathfrak{X}/\mathbb{Z}_p&lt;/math&gt;? If our variety is a curve, then the vanishing &lt;math&gt;H^2&lt;/math&gt; implies that every deformation induces a variety over &lt;math&gt;\mathbb{Z}_p&lt;/math&gt;; that is, if we have a smooth curve
:&lt;math&gt;
\begin{matrix}
X \\
\downarrow \\
\operatorname{Spec}(\mathbb{F}_p)
\end{matrix}
&lt;/math&gt;
and a deformation
:&lt;math&gt;
\begin{matrix}
X &amp; \to &amp; \mathfrak{X}_2 \\
\downarrow &amp; &amp; \downarrow \\
\operatorname{Spec}(\mathbb{F}_p) &amp; \to &amp; \operatorname{Spec}(\mathbb{Z}/(p^2))
\end{matrix}
&lt;/math&gt;
then we can always extend it to a diagram of the form
:&lt;math&gt;
\begin{matrix}
X &amp; \to &amp; \mathfrak{X}_2 &amp; \to &amp; \mathfrak{X}_3 &amp; \to \cdots \\
\downarrow &amp; &amp; \downarrow &amp; &amp; \downarrow &amp;  \\
\operatorname{Spec}(\mathbb{F}_p) &amp; \to &amp; \operatorname{Spec}(\mathbb{Z}/(p^2)) &amp; \to &amp; \operatorname{Spec}(\mathbb{Z}/(p^3)) &amp; \to \cdots
\end{matrix}
&lt;/math&gt;
This implies that we can construct a formal scheme &lt;math&gt;\mathfrak{X} = \operatorname{Spet}(\mathfrak{X}_\bullet)&lt;/math&gt; giving a curve over &lt;math&gt;\mathbb{Z}_p&lt;/math&gt;.
=== Deformations of abelian schemes ===

The [[Serre–Tate theorem]] asserts, roughly speaking, that the deformations of [[abelian variety|abelian scheme]] ''A'' is controlled by deformations of the [[p-divisible group|''p''-divisible group]] &lt;math&gt;A[p^\infty]&lt;/math&gt; consisting of its ''p''-power torsion points.

=== Galois deformations ===
Another application of deformation theory is with Galois deformations. It allows us to answer the question: If we have a Galois representation
:&lt;math&gt;G \to \operatorname{GL}_n(\mathbb{F}_p)&lt;/math&gt;
how can we extend it to a representation
:&lt;math&gt;G \to \operatorname{GL}_n(\mathbb{Z}_p) \text{?}&lt;/math&gt;

==Relationship to string theory==
The so-called [[Deligne conjecture]] arising in the context of algebras (and [[Hochschild cohomology]]) stimulated much interest in deformation theory in relation to [[string theory]] (roughly speaking, to formalise the idea that a string theory can be regarded as a deformation of a point-particle theory). This is now accepted as proved, after some hitches with early announcements. [[Maxim Kontsevich]] is among those who have offered a generally accepted proof of this.

==See also==
* [[Exalcomm]]
* [[Cotangent complex]]
* [[Gromov–Witten invariant]]
* [[Moduli of algebraic curves]]

==References==
===Pedagogical===
*[https://math.stackexchange.com/a/1124227/251222 Studying Deformation Theory of Schemes]
*{{Citation | first=Eduardo | last=Sernesi | title=Deformations of Algebraic Schemes}}
*{{Citation | first=Robin | last=Hartshorne | title=Deformation Theory}}
*[https://math.berkeley.edu/~robin/math274root.pdf Notes from Hartshorne's Course on Deformation Theory]
*[http://www.msri.org/summer_schools/419 MSRI – Deformation Theory and Moduli in Algebraic Geometry]

===Survey Articles===
*{{Citation | last=Mazur | first=Barry | authorlink=Barry Mazur|title= Perturbations, Deformations, and Variations (and "Near-Misses" in Geometry, Physics, and Number Theory | journal=[[Bulletin of the American Mathematical Society]]|year=2004|volume=41|issue=3|pages=307–336|doi=10.1090/S0273-0979-04-01024-9|mr=2058289|url=http://www.ams.org/journals/bull/2004-41-03/S0273-0979-04-01024-9/S0273-0979-04-01024-9.pdf }}
*{{Citation | last=Anel | first=M. | title=Why deformations are cohomological | url=http://mathieu.anel.free.fr/mat/doc/Anel%20-%20WhyDeformationAreCohomological.pdf}}

===References===
*{{springer|id=d/d030700|title=deformation}}
*[[Murray Gerstenhaber|Gerstenhaber, Murray]] and [[Jim Stasheff|Stasheff,  James]], eds. (1992). ''Deformation Theory and Quantum Groups with Applications to Mathematical Physics'', [[American Mathematical Society]] (Google eBook) {{ISBN|0821851411}}

===Notes===
&lt;references /&gt;

==External links==
*{{cite web|url= http://www.math.ucdavis.edu/~osserman/classes/256A/notes/deform.pdf |title=A glimpse of deformation theory }}, lecture notes by Brian Osserman

[[Category:Algebraic geometry]]
[[Category:Differential algebra]]</text>
      <sha1>qb7k8o1uelzqteyu440ooaaaieiuzvz</sha1>
    </revision>
  </page>
  <page>
    <title>Description number</title>
    <ns>0</ns>
    <id>7805214</id>
    <revision>
      <id>689566707</id>
      <parentid>674656803</parentid>
      <timestamp>2015-11-08T00:53:15Z</timestamp>
      <contributor>
        <username>Wiae</username>
        <id>3495083</id>
      </contributor>
      <minor/>
      <comment>Disambiguating links to [[Unary]] (link changed to [[Unary numeral system]]) using [[User:Qwertyytrewqqwerty/DisamAssist|DisamAssist]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5726">'''Description numbers''' are numbers that arise in the theory of [[Turing machine]]s.  They are very similar to [[Gödel number]]s, and are also occasionally called "Gödel numbers" in the literature.  Given some [[universal Turing machine]], every Turing machine can, given its encoding on that machine, be assigned a number.  This is the machine's description number.  These numbers play a key role in [[Alan Turing]]'s proof of the undecidability of the [[halting problem]], and are very useful in reasoning about Turing machines as well.

==An example of a description number==
Say we had a Turing machine ''M'' with states q&lt;sub&gt;1&lt;/sub&gt;, ... q&lt;sub&gt;R&lt;/sub&gt;, with a tape alphabet with symbols s&lt;sub&gt;1&lt;/sub&gt;, ... s&lt;sub&gt;m&lt;/sub&gt;, with the blank denoted by s&lt;sub&gt;0&lt;/sub&gt;, and transitions giving the current state, current symbol, and actions performed (which might be to overwrite the current tape symbol and move the tape head left or right, or maybe not move it at all), and the next state.  Under the original universal machine described by Alan Turing, this machine would be encoded as input to it as follows:

# The state q&lt;sub&gt;i&lt;/sub&gt; is encoded by the letter 'D' followed by the letter 'A' repeated i times (a [[Unary numeral system|unary]] encoding)
# The tape symbol s&lt;sub&gt;j&lt;/sub&gt; is encoded by the letter 'D' followed by the letter 'C' repeated j times
# The transitions are encoded by giving the state, input symbol, symbol to write on the tape, direction to move (expressed by the letters 'L', 'R', or 'N', for left, right, or no movement), and the next state to enter, with states and symbols encoded as above.

The UTM's input thus consists of the transitions separated by semicolons, so its input alphabet consists of the seven symbols, 'D', 'A', 'C', 'L', 'R', 'N', and ';'.  For example, for a very simple Turing machine that alternates printing 0 and 1 on its tape forever:

# State: q&lt;sub&gt;1&lt;/sub&gt;, input symbol: blank, action: print 1, move right, next state: q&lt;sub&gt;2&lt;/sub&gt;
# State: q&lt;sub&gt;2&lt;/sub&gt;, input symbol: blank, action: print 0, move right, next state: q&lt;sub&gt;1&lt;/sub&gt;

Letting the blank be s&lt;sub&gt;0&lt;/sub&gt;, '0' be s&lt;sub&gt;1&lt;/sub&gt; and '1' be s&lt;sub&gt;2&lt;/sub&gt;, the machine would be encoded by the UTM as:

DADDCCRDAA;DAADDCRDA;

But then, if we replaced each of the seven symbols 'A' by 1, 'C' by 2, 'D' by 3, 'L' by 4, 'R' by 5, 'N' by 6, and ';' by 7, we would have an encoding of the Turing machine as a natural number: this is the description number of that Turing machine under Turing's universal machine.  The simple Turing machine described above would thus have the description number 313322531173113325317.  There is an analogous process for every other type of universal Turing machine.  It is usually not necessary to actually compute a description number in this way: the point is that every [[natural number]] may be interpreted as the code for at most one Turing machine, though many natural numbers may not be the code for any Turing machine (or to put it another way, they represent Turing machines that have no states).  The fact that such a number always exists for any Turing machine is generally the important thing.

==Application to undecidability proofs==
Description numbers play a key role in many undecidability proofs, such as the proof that the [[halting problem]] is [[Undecidable problem|undecidable]].  In the first place, the existence of this direct correspondence between natural numbers and Turing machines shows that the set of all Turing machines is [[denumerable]], and since the set of all [[partial function]]s is [[uncountably infinite]], there must certainly be many functions that cannot be computed by Turing machines.

By making use of a technique similar to [[Cantor's diagonal argument]], it is possible exhibit such an uncomputable function, for example, that the halting problem in particular is undecidable.  First, let us denote by U(e, x) the action of the universal Turing machine given a description number e and input x, returning 0 if e is not the description number of a valid Turing machine.  Now, supposing that there were some [[algorithm]] capable of settling the halting problem, i.e. a Turing machine TEST(e) which given the description number of some Turing machine would return 1 if the Turing machine halts on every input, or 0 if there are some inputs that would cause it to run forever.  By combining the outputs of these machines, it should be possible to construct another machine δ(k) that returns U(k, k) + 1 if TEST(k) is 1 and 0 if TEST(k) is 0.  From this definition δ is defined for every input and must naturally be [[total recursive]].  Since δ is built up from what we have assumed are Turing machines as well then it too must have a description number, call it e.  So, we can feed the description number e to the UTM again, and by definition, δ(k) = U(e, k), so δ(e) = U(e, e).  But since TEST(e) is 1, by our other definition, δ(e) = U(e, e) + 1, leading to a contradiction.  Thus, TEST(e) cannot exist, and in this way we have settled the halting problem as undecidable.

==See also==
* [[Gödel number]]
* [[Universal Turing machine]]
* [[Church numeral]]
* [[Halting problem]]

==References==
* {{cite book|author = [[John Hopcroft]] and [[Jeffrey D. Ullman]] | year = 1979 | title = [[Introduction to Automata Theory, Languages, and Computation]] | publisher = Addison-Wesley | edition = 1st | isbn = 0-201-44124-1}} (the Cinderella book)
* Turing, A. M. "On computable numbers, with an application to the [[Entscheidungsproblem]]", Proc. Roy. Soc. London, 2(42), 1936, pp.&amp;nbsp;230–265.

[[Category:Theory of computation]]
[[Category:Alan Turing]]
[[Category:Computability theory]]
[[Category:Models of computation]]</text>
      <sha1>iwm3abv33mqg1we649e2esffy76pbsd</sha1>
    </revision>
  </page>
  <page>
    <title>Direct sum of modules</title>
    <ns>0</ns>
    <id>58899</id>
    <revision>
      <id>857708445</id>
      <parentid>835636392</parentid>
      <timestamp>2018-09-02T14:06:42Z</timestamp>
      <contributor>
        <username>Vatai</username>
        <id>345366</id>
      </contributor>
      <minor/>
      <comment>/* Direct sum of modules with bilinear forms */ missing parenthesis</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23440">{{for|the broader use of the term in mathematics|Direct sum}}
 
In [[abstract algebra]], the '''direct sum''' is a construction which combines several [[module (mathematics)|modules]] into a new, larger module. The direct sum of modules is the smallest module which contains the given modules as submodules with no "unnecessary" constraints, making it an example of a [[coproduct]]. Contrast with the [[direct product]], which is the [[duality (category theory)|dual]] notion.

The most familiar examples of this construction occur when considering [[vector space]]s (modules over a [[field (mathematics)|field]]) and [[abelian group]]s (modules over the ring '''Z''' of [[integer]]s). The construction may also be extended to cover [[Banach space]]s and [[Hilbert space]]s.

== Construction for vector spaces and abelian groups ==

We give the construction first in these two cases, under the assumption that we have only two objects. Then we generalise to an arbitrary family of arbitrary modules. The key elements of the general construction are more clearly identified by considering these two cases in depth.

=== Construction for two vector spaces ===

Suppose ''V'' and ''W'' are [[vector space]]s over the [[field (mathematics)|field]] ''K''. The [[cartesian product]] ''V'' × ''W'' can be given the structure of a vector space over ''K'' {{harv|Halmos|1974|loc=§18}} by defining the operations componentwise:

* (''v''&lt;sub&gt;1&lt;/sub&gt;, ''w''&lt;sub&gt;1&lt;/sub&gt;) + (''v''&lt;sub&gt;2&lt;/sub&gt;, ''w''&lt;sub&gt;2&lt;/sub&gt;) = (''v''&lt;sub&gt;1&lt;/sub&gt; + ''v''&lt;sub&gt;2&lt;/sub&gt;, ''w''&lt;sub&gt;1&lt;/sub&gt; + ''w''&lt;sub&gt;2&lt;/sub&gt;)
* α (''v'', ''w'') = (α ''v'', α ''w'')

for ''v'', ''v''&lt;sub&gt;1&lt;/sub&gt;, ''v''&lt;sub&gt;2&lt;/sub&gt; ∈ ''V'', ''w'', ''w''&lt;sub&gt;1&lt;/sub&gt;, ''w''&lt;sub&gt;2&lt;/sub&gt; ∈ ''W'', and α ∈ ''K''.

The resulting vector space is called the ''direct sum'' of ''V'' and ''W'' and is usually denoted by a plus symbol inside a circle:

:&lt;math&gt;V \oplus W&lt;/math&gt;

It is customary to write the elements of an ordered sum not as ordered pairs (''v'', ''w''), but as a sum ''v'' + ''w''.

The subspace ''V'' × {0} of ''V'' ⊕ ''W'' is isomorphic to ''V'' and is often identified with ''V''; similarly for {0} × ''W'' and ''W''. (See ''internal direct sum'' below.) With this identification, every element of ''V'' ⊕ ''W'' can be written in one and only one way as the sum of an element of ''V'' and an element of ''W''. The [[dimension of a vector space|dimension]] of ''V'' ⊕ ''W'' is equal to the sum of the dimensions of ''V'' and ''W''.  One elementary use is the reconstruction
of a finite vector space from any subspace ''W'' and its orthogonal complement:  

:&lt;math&gt;\mathbb{R}^n = W \oplus W^{\perp}&lt;/math&gt;

This construction readily generalises to any [[finite set|finite]] number of vector spaces.

=== Construction for two abelian groups ===

For [[abelian group]]s ''G'' and ''H'' which are written additively, the [[direct product]] of ''G'' and ''H'' is also called a direct sum {{harv|Mac Lane|Birkhoff|1999|loc=§V.6}}. Thus the [[cartesian product]] ''G'' × ''H'' is equipped with the structure of an abelian group by defining the operations componentwise:

* (''g''&lt;sub&gt;1&lt;/sub&gt;, ''h''&lt;sub&gt;1&lt;/sub&gt;) + (''g''&lt;sub&gt;2&lt;/sub&gt;, ''h''&lt;sub&gt;2&lt;/sub&gt;) = (''g''&lt;sub&gt;1&lt;/sub&gt; + ''g''&lt;sub&gt;2&lt;/sub&gt;, ''h''&lt;sub&gt;1&lt;/sub&gt; + ''h''&lt;sub&gt;2&lt;/sub&gt;)

for ''g''&lt;sub&gt;1&lt;/sub&gt;, ''g''&lt;sub&gt;2&lt;/sub&gt; in ''G'', and ''h''&lt;sub&gt;1&lt;/sub&gt;, ''h''&lt;sub&gt;2&lt;/sub&gt; in ''H''.

Integral multiples are similarly defined componentwise by

* ''n''(''g'', ''h'') = (''ng'', ''nh'')

for ''g'' in ''G'', ''h'' in ''H'', and ''n'' an [[integer]]. This parallels the extension of the scalar product of vector spaces to the direct sum above.

The resulting abelian group is called the ''direct sum'' of ''G'' and ''H'' and is usually denoted by a plus symbol inside a circle:

:&lt;math&gt;G \oplus H&lt;/math&gt;

It is customary to write the elements of an ordered sum not as ordered pairs (''g'', ''h''), but as a sum ''g'' + ''h''.

The subgroup ''G'' × {0} of ''G'' ⊕ ''H'' is isomorphic to ''G'' and is often identified with ''G''; similarly for {0} × ''H'' and ''H''. (See [[Direct_sum_of_modules#Internal_direct_sum|''internal direct sum'']] below.) With this identification, it is true that every element of ''G'' ⊕ ''H'' can be written in one and only one way as the sum of an element of ''G'' and an element of ''H''. The [[rank of an abelian group|rank]] of ''G'' ⊕ ''H'' is equal to the sum of the ranks of ''G'' and ''H''.

This construction readily generalises to any [[finite set|finite]] number of abelian groups.

== Construction for an arbitrary family of modules ==

One should notice a clear similarity between the definitions of the direct sum of two vector spaces and of two abelian groups. In fact, each is a special case of the construction of the direct sum of two [[module (mathematics)|modules]]. Additionally, by modifying the definition one can accommodate the direct sum of an infinite family of modules. The precise definition is as follows {{harv|Bourbaki|1989|loc=§II.1.6}}.

Let ''R'' be a ring, and {''M''&lt;sub&gt;''i''&lt;/sub&gt;&amp;nbsp;:&amp;nbsp;''i''&amp;nbsp;∈&amp;nbsp;''I''} a [[indexed family|family]] of left ''R''-modules indexed by the [[Set (mathematics)|set]] ''I''. The ''direct sum'' of {''M''&lt;sub&gt;''i''&lt;/sub&gt;} is then defined to be the set of all sequences &lt;math&gt;(\alpha_i)&lt;/math&gt; where &lt;math&gt;\alpha_i \in M_i&lt;/math&gt; and &lt;math&gt;\alpha_i = 0&lt;/math&gt; for [[cofinitely many]] indices ''i''. (The [[direct product]] is analogous but the indices do not need to cofinitely vanish.)

It can also be defined as [[function (mathematics)|functions]] α from ''I'' to the [[disjoint union]] of the modules ''M''&lt;sub&gt;''i''&lt;/sub&gt; such that α(''i'')&amp;nbsp;∈&amp;nbsp;''M''&lt;sub&gt;''i''&lt;/sub&gt; for all ''i'' ∈ ''I'' and α(''i'') = 0 for [[cofinitely many]] indices ''i''.  These functions can equivalently be regarded as [[compact support|finitely supported]] sections of the [[fiber bundle]] over the index set ''I'', with the fiber over &lt;math&gt;i \in I&lt;/math&gt; being &lt;math&gt;M_i&lt;/math&gt;.

This set inherits the module structure via component-wise addition and scalar multiplication. Explicitly, two such sequences (or functions) α and β can be added by writing &lt;math&gt;(\alpha + \beta)_i = \alpha_i + \beta_i&lt;/math&gt; for all ''i'' (note that this is again zero for all but finitely many indices), and such a function can be multiplied with an element ''r'' from ''R'' by defining &lt;math&gt;r(\alpha)_i = (r\alpha)_i&lt;/math&gt; for all ''i''. In this way, the direct sum becomes a left ''R''-module, and it is denoted

:&lt;math&gt; \bigoplus_{i \in I} M_i. &lt;/math&gt;

It is customary to write the sequence &lt;math&gt;(\alpha_i)&lt;/math&gt; as a sum &lt;math&gt; \Sigma \alpha_i&lt;/math&gt;. Sometimes a primed summation &lt;math&gt; \Sigma ' \alpha_i&lt;/math&gt; is used to indicate that [[cofinitely many]] of the terms are zero.

== Properties ==

* The direct sum is a [[submodule]] of the [[direct product]] of the modules ''M''&lt;sub&gt;''i''&lt;/sub&gt; {{harv|Bourbaki|1989|loc=§II.1.7}}.  The direct product is the set of all functions ''α'' from ''I'' to the disjoint union of the modules ''M''&lt;sub&gt;''i''&lt;/sub&gt; with ''α''(''i'')∈''M''&lt;sub&gt;''i''&lt;/sub&gt;, but not necessarily vanishing for all but finitely many ''i''. If the index set ''I'' is finite, then the direct sum and the direct product are equal.
* Each of the modules ''M''&lt;sub&gt;''i''&lt;/sub&gt; may be identified with the submodule of the direct sum consisting of those functions which vanish on all indices different from ''i''. With these identifications, every element ''x'' of the direct sum can be written in one and only one way as a sum of finitely many elements from the modules ''M''&lt;sub&gt;''i''&lt;/sub&gt;.
* If the ''M''&lt;sub&gt;''i''&lt;/sub&gt; are actually vector spaces, then the dimension of the direct sum is equal to the sum of the dimensions of the ''M''&lt;sub&gt;''i''&lt;/sub&gt;. The same is true for the [[rank of an abelian group|rank of abelian groups]] and the [[length of a module|length of modules]].
* Every vector space over the field ''K'' is isomorphic to a direct sum of sufficiently many copies of ''K'', so in a sense only these direct sums have to be considered. This is not true for modules over arbitrary rings.
* The [[tensor product]] distributes over direct sums in the following sense: if ''N'' is some right ''R''-module, then the direct sum of the tensor products of ''N'' with ''M''&lt;sub&gt;''i''&lt;/sub&gt; (which are abelian groups) is naturally isomorphic to the tensor product of ''N'' with the direct sum of the ''M''&lt;sub&gt;''i''&lt;/sub&gt;.
* Direct sums are also commutative and associative (up to isomorphism), meaning that it doesn't matter in which order one forms the direct sum.
* The group of ''R''-linear homomorphisms from the direct sum to some left ''R''-module ''L'' is naturally isomorphic to the [[direct product]] of the sets of ''R''-linear homomorphisms from ''M''&lt;sub&gt;''i''&lt;/sub&gt; to ''L'':
*::&lt;math&gt;\operatorname{Hom}_R\biggl( \bigoplus_{i \in I} M_i,L\biggr) \cong \prod_{i \in I}\operatorname{Hom}_R\left(M_i,L\right).&lt;/math&gt;
*:Indeed, there is clearly a homomorphism ''τ'' from the left hand side to the right hand side, where ''τ''(''θ'')(i) is the ''R''-linear homomorphism sending ''x''∈''M''&lt;sub&gt;''i''&lt;/sub&gt; to ''θ''(''x'') (using the natural inclusion of ''M''&lt;sub&gt;''i''&lt;/sub&gt; into the direct sum). The inverse of the homomorphism ''τ'' is defined by
*:&lt;math&gt; \tau^{-1}(\beta)(\alpha) = \sum_{i\in I} \beta(i)(\alpha(i))&lt;/math&gt;
*:for any ''α'' in the direct sum of the modules ''M''&lt;sub&gt;''i''&lt;/sub&gt;. The key point is that the definition of ''τ''&lt;sup&gt;−1&lt;/sup&gt; makes sense because ''α''(''i'') is zero for all but finitely many ''i'', and so the sum is finite.
*:In particular, the [[dual space|dual vector space]] of a direct sum of vector spaces is isomorphic to the [[direct product]] of the duals of those spaces.
*The ''finite'' direct sum of modules is a [[biproduct]]: If
*::&lt;math&gt;p_k: A_1 \oplus \cdots \oplus A_n \to A_k&lt;/math&gt;
*:are the canonical projection mappings and
*::&lt;math&gt;i_k: A_k \mapsto A_1 \oplus \cdots \oplus A_n &lt;/math&gt;
*:are the inclusion mappings, then
*::&lt;math&gt;i_1 \circ p_1 + \cdots + i_n \circ p_n&lt;/math&gt;
*:equals the identity morphism of ''A''&lt;sub&gt;1&lt;/sub&gt; ⊕ ··· ⊕ ''A''&lt;sub&gt;''n''&lt;/sub&gt;, and
*::&lt;math&gt;p_k \circ i_l&lt;/math&gt;
*:is the identity morphism of ''A''&lt;sub&gt;''k''&lt;/sub&gt; in the case ''l=k'', and is the zero map otherwise.

== Internal direct sum ==
&lt;!-- linked from redirects [[Complementary subspace]] and [[Complementary subspaces]] --&gt;
{{see also|Internal direct product}}
Suppose ''M'' is some ''R''-module, and ''M''&lt;sub&gt;''i''&lt;/sub&gt; is a [[submodule]] of ''M'' for every ''i'' in ''I''. If every ''x'' in ''M'' can be written in one and only one way as a sum of finitely many elements of the ''M''&lt;sub&gt;''i''&lt;/sub&gt;, then we say that ''M'' is the '''internal direct sum''' of the submodules ''M''&lt;sub&gt;''i''&lt;/sub&gt; {{harv|Halmos|1974|loc=§18}}. In this case, ''M'' is naturally isomorphic to the (external) direct sum of the ''M''&lt;sub&gt;''i''&lt;/sub&gt; as defined above {{harv|Adamson|1972|loc=p.61}}.

A submodule ''N'' of ''M'' is a '''direct summand''' of ''M'' if there exists some other submodule ''N′'' of ''M'' such that ''M'' is the ''internal'' direct sum of ''N'' and ''N′''. In this case, ''N'' and ''N′'' are '''complementary submodules'''.

== Universal property ==
In the language of [[category theory]], the direct sum is a [[coproduct]] and hence a [[limit (category theory)|colimit]] in the category of left ''R''-modules, which means that it is characterized by the following [[universal property]]. For every ''i'' in ''I'', consider the ''natural embedding''

:&lt;math&gt;j_i : M_i \rightarrow \bigoplus_{k \in I} M_k&lt;/math&gt;

which sends the elements of ''M''&lt;sub&gt;''i''&lt;/sub&gt; to those functions which are zero for all arguments but ''i''. If ''f''&lt;sub&gt;''i''&lt;/sub&gt; : ''M''&lt;sub&gt;''i''&lt;/sub&gt; → ''M'' are arbitrary ''R''-linear maps for every ''i'', then there exists precisely one ''R''-linear map

:&lt;math&gt;f : \bigoplus_{i \in I} M_i \rightarrow M&lt;/math&gt;

such that ''f'' o ''j&lt;sub&gt;i&lt;/sub&gt;'' = ''f''&lt;sub&gt;''i''&lt;/sub&gt; for all ''i''.

Dually, the [[direct product]] is the [[Product (category theory)|product]].

== Grothendieck group ==
The direct sum gives a collection of objects the structure of a commutative [[monoid]], in that the addition of objects is defined, but not subtraction. In fact, subtraction can be defined, and every commutative monoid can be extended to an [[abelian group]]. This extension is known as the [[Grothendieck group]]. The extension is done by defining equivalence classes of pairs of objects, which allows certain pairs to be treated as inverses. The construction, detailed in the article on the Grothendieck group, is "universal", in that it has the [[universal property]] of being unique, and homomorphic to any other embedding of an abelian monoid in an abelian group.

== Direct sum of modules with additional structure ==

If the modules we are considering carry some additional structure (e.g. a [[norm (mathematics)|norm]] or an [[inner product]]), then the direct sum of the modules can often be made to carry this additional structure, as well. In this case, we obtain the [[coproduct]] in the appropriate [[category (category theory)|category]] of all objects carrying the additional structure. Two prominent examples occur for [[Banach space]]s and [[Hilbert space]]s.

In some classical texts, the notion of direct sum of [[algebra over a field|algebras over a field]] is also introduced. This construction, however, does not provide a coproduct in the category of algebras, but a direct product (''see note below'' and the remark on [[Direct sum#Direct sum of rings|direct sums of rings]]).

===Direct sum of algebras===
A direct sum of [[algebra over a field|algebras]]  ''X'' and ''Y'' is the direct sum as vector spaces, with product 
:&lt;math&gt;(x_1 + y_1) (x_2 + y_2) = (x_1 x_2 + y_1 y_2) .&lt;/math&gt;
Consider these classical examples:
:&lt;math&gt;\mathbf{R} \oplus \mathbf{R}&lt;/math&gt; is [[ring isomorphism|ring isomorphic]] to [[split-complex number]]s, also used in [[interval analysis]].
:&lt;math&gt;\mathbf{C} \oplus \mathbf{C}&lt;/math&gt; is the algebra of [[tessarine]]s introduced by [[James Cockle (lawyer)|James Cockle]] in 1848.
:&lt;math&gt;\mathbf{H} \oplus \mathbf{H}&lt;/math&gt;, called the [[split-biquaternion]]s, was introduced by [[William Kingdon Clifford]] in 1873.
[[Joseph Wedderburn]] exploited the concept of a direct sum of algebras in his classification of [[hypercomplex number]]s. See his ''Lectures on Matrices'' (1934), page 151.
Wedderburn makes clear the distinction between a direct sum and a direct product of algebras: For the direct sum the field of scalars acts jointly on both parts: &lt;math&gt;\lambda (x \oplus y) = \lambda x \oplus \lambda y&lt;/math&gt; while for the direct product a scalar factor may be collected alternately with the parts, but not both:&lt;math&gt;\lambda (x,y) = (\lambda x, y) = (x, \lambda y) \!&lt;/math&gt;.
[[Ian R. Porteous]] uses the three direct sums above, denoting them &lt;math&gt;^2 R,\ ^2 C,\ ^2 H \!&lt;/math&gt;, as rings of scalars in his analysis of ''Clifford Algebras and the Classical Groups'' (1995).

The construction described above, as well as Wedderburn's use of the terms ''direct sum'' and ''direct product'' follow a different convention from the one in [[category theory]]. In categorical terms, Wedderburn's ''direct sum'' is a [[Product (category theory)|categorical product]], whilst Wedderburn's ''direct product'' is a [[Coproduct|coproduct (or categorical sum)]], which (for commutative algebras) actually corresponds to the [[tensor product of algebras]].

===Composition algebras===
{{main|Composition algebra}}
A composition algebra (''A'', *, n) is an [[algebra over a field]] ''A'', an [[involution (mathematics)|involution]] * and a "norm" n(''x'') = ''x x''*. Any field ''K'' gives rise to a series of composition algebras beginning with ''K'', and the trivial involution, so that n(''x'') = ''x''&lt;sup&gt;2&lt;/sup&gt;. The inductive step in the series involves forming the direct sum A ⊕ A and using the new involution &lt;math&gt;(x,y)^*  = x^* - y.&lt;/math&gt;

[[Leonard Dickson]] developed this construction doubling [[quaternion]]s for [[Cayley number]]s, and the doubling method involving the direct sum A ⊕ A is called the [[Cayley–Dickson construction]]. In the instance beginning with ''K'' = ℝ, the series generates [[complex number]]s, quaternions, octonions, and [[sedenion]]s. Beginning with ''K'' = ℂ and the norm n(''z'') = ''z''&lt;sup&gt;2&lt;/sup&gt;, the series continues with [[bicomplex number]]s, [[biquaternion]]s, and [[bioctonion]]s.

[[Max Zorn]] realized that the classical Cayley–Dickson construction missed constructing some composition algebras that arise as real subalgebras in the (ℂ, ''z''&lt;sup&gt;2&lt;/sup&gt;) series, in particular the [[split-octonion]]s. A [[Cayley–Dickson_construction#Modified_Cayley.E2.80.93Dickson_construction|modified Cayley–Dickson construction]], still based on use of the direct sum A ⊕ A of a base algebra A, has since been used to exhibit the series ℝ, [[split-complex number]]s, [[split-quaternion]]s, and split-octonions.

=== Direct sum of Banach spaces ===
&lt;span id="Banachspaces"&gt;&lt;/span&gt;

The direct sum of two [[Banach space]]s ''X'' and ''Y'' is the direct sum of ''X'' and ''Y'' considered as vector spaces, with the norm ||(''x'',''y'')|| = ||''x''||&lt;sub&gt;X&lt;/sub&gt; + ||''y''||&lt;sub&gt;Y&lt;/sub&gt; for all ''x'' in ''X'' and ''y'' in ''Y''.

Generally, if ''X''&lt;sub&gt;''i''&lt;/sub&gt; is a collection of Banach spaces, where ''i'' traverses the [[index set]] ''I'', then the direct sum ⨁&lt;sub&gt;''i''∈''I''&lt;/sub&gt;&amp;nbsp;''X''&lt;sub&gt;''i''&lt;/sub&gt; is a module consisting of all functions ''x'' [[Domain of a function|defined over]] ''I'' such that ''x''(''i'') ∈ ''X''&lt;sub&gt;''i''&lt;/sub&gt; for all ''i'' ∈ ''I'' and

:&lt;math&gt; \sum_{i \in I} \| x(i) \|_{X_i} &lt; \infty. &lt;/math&gt;

The norm is given by the sum above. The direct sum with this norm is again a Banach space.

For example, if we take the index set ''I'' = '''N''' and ''X''&lt;sub&gt;''i''&lt;/sub&gt; = '''R''', then the direct sum ⨁&lt;sub&gt;''i''∈'''N'''&lt;/sub&gt;''X''&lt;sub&gt;''i''&lt;/sub&gt; is the space ''l''&lt;sub&gt;1&lt;/sub&gt;, which consists of all the sequences (''a''&lt;sub&gt;''i''&lt;/sub&gt;) of reals with finite norm ||''a''|| = ∑&lt;sub&gt;''i''&lt;/sub&gt;&amp;nbsp;|''a''&lt;sub&gt;''i''&lt;/sub&gt;|.

A closed subspace ''A'' of a Banach space ''X'' is '''complemented''' if there is another closed subspace ''B'' of ''X'' such that ''X'' is equal to the internal direct sum &lt;math&gt;A\oplus B&lt;/math&gt;. Note that not every closed subspace is complemented, e.g. [[c0 space|''c''&lt;sub&gt;0&lt;/sub&gt;]] is not complemented in &lt;math&gt;\ell^\infty&lt;/math&gt;.

===Direct sum of modules with bilinear forms===
Let {(''M''&lt;sub&gt;''i''&lt;/sub&gt;,''b''&lt;sub&gt;''i''&lt;/sub&gt;) &amp;nbsp;:&amp;nbsp;''i''&amp;nbsp;∈&amp;nbsp;''I''} be a [[indexed family|family]] indexed by ''I'' of modules equipped with [[bilinear form]]s. The '''orthogonal direct sum''' is the module direct sum with bilinear form ''B'' defined by&lt;ref&gt;{{cite book | first1=J. | last1=Milnor | author1-link=John Milnor| first2=D. | last2=Husemoller | title=Symmetric Bilinear Forms | series=[[Ergebnisse der Mathematik und ihrer Grenzgebiete]] | volume=73 | publisher=[[Springer-Verlag]] | year=1973 | isbn=3-540-06009-X | zbl=0292.10016 | pages=4–5}}&lt;/ref&gt;

:&lt;math&gt; B\left({\left({x_i}\right),\left({y_i}\right)}\right) = \sum_{i\in I} b_i\left({x_i,y_i}\right) &lt;/math&gt;

in which the summation makes sense even for infinite index sets ''I'' because only finitely many of the terms are non-zero.

===&lt;span id="Hilbertspaces"&gt;&lt;/span&gt; Direct sum of Hilbert spaces===
{{further|Positive-definite kernel#Connection with reproducing kernel Hilbert spaces and feature maps}}

If finitely many [[Hilbert space]]s ''H''&lt;sub&gt;1&lt;/sub&gt;,...,''H''&lt;sub&gt;''n''&lt;/sub&gt; are given, one can construct their orthogonal direct sum as above (since they are vector spaces), defining the inner product as:

:&lt;math&gt;\langle (x_1,...,x_n),(y_1,...,y_n) \rangle = \langle x_1,y_1 \rangle +...+ \langle x_n,y_n \rangle. &lt;/math&gt;

The resulting direct sum is a Hilbert space which contains the given Hilbert spaces as mutually [[orthogonal]] subspaces.

If infinitely many Hilbert spaces ''H''&lt;sub&gt;''i''&lt;/sub&gt; for ''i'' in ''I'' are given, we can carry out the same construction; notice that when defining the inner product, only finitely many summands will be non-zero. However, the result will only be an [[inner product space]] and it will not necessarily be [[completeness (topology)|complete]]. We then define the direct sum of the Hilbert spaces ''H''&lt;sub&gt;''i''&lt;/sub&gt; to be the completion of this inner product space. 

Alternatively and equivalently, one can define the direct sum of the Hilbert spaces ''H''&lt;sub&gt;''i''&lt;/sub&gt; as the space of all functions α with domain ''I'', such that α(''i'')  is an element of ''H''&lt;sub&gt;''i''&lt;/sub&gt; for every ''i'' in ''I'' and:

:&lt;math&gt;\sum_i \left\| \alpha_{(i)} \right\|^2 &lt; \infty.&lt;/math&gt;

The inner product of two such function α and β is then defined as:

:&lt;math&gt;\langle\alpha,\beta\rangle=\sum_i \langle \alpha_i,\beta_i \rangle.&lt;/math&gt;

This space is complete and we get a Hilbert space.

For example, if we take the index set ''I'' = '''N''' and ''X''&lt;sub&gt;''i''&lt;/sub&gt; = '''R''', then the direct sum ⨁&lt;sub&gt;''i''∈'''N'''&lt;/sub&gt; ''X''&lt;sub&gt;''i''&lt;/sub&gt; is the space ''l''&lt;sub&gt;2&lt;/sub&gt;, which consists of all the sequences (''a''&lt;sub&gt;''i''&lt;/sub&gt;) of reals with finite norm &lt;math&gt;\left\| a \right\| = \sqrt{\sum_i \left\| a_i \right\|^2}&lt;/math&gt;. Comparing this with the example for Banach spaces, we see that the Banach space direct sum and the Hilbert space direct sum are not necessarily the same. But if there are only finitely many summands, then the Banach space direct sum is isomorphic to the Hilbert space direct sum, although the norm will be different.

Every Hilbert space is isomorphic to a direct sum of sufficiently many copies of the base field (either '''R''' or '''C''').  This is equivalent to the assertion that every Hilbert space has an orthonormal basis.  More generally, every closed subspace of a Hilbert space is complemented: it admits an [[orthogonal complement]].  Conversely, the [[Lindenstrauss–Tzafriri theorem]] asserts that if every closed subspace of a Banach space is complemented, then the Banach space is isomorphic (topologically) to a Hilbert space.

== See also ==
* [[Biproduct]]
* [[Indecomposable module]]
* [[Jordan–Hölder theorem]]
* [[Krull–Schmidt theorem]]
* [[Split exact sequence]]

== References ==
{{reflist}}
* {{Citation | author= Iain T. Adamson | title=Elementary rings and modules | series=University Mathematical Texts | publisher=Oliver and Boyd | year=1972 | isbn=0-05-002192-3 }}
* {{citation|first = Nicolas|last=Bourbaki|authorlink=Nicolas Bourbaki | title = Elements of mathematics, Algebra I| publisher = Springer-Verlag | year = 1989|isbn=3-540-64243-9}}.
* {{citation|first1=David S.|last1=Dummit|first2=Richard M.|last2=Foote|title=Abstract algebra|publisher=Prentice Hall, Inc.|publication-place=Englewood Cliffs, NJ|year=1991|isbn=0-13-004771-6}}.
* {{citation|authorlink=Paul Halmos|first=Paul|last=Halmos|title=Finite dimensional vector spaces|year=1974|publisher=Springer|isbn=0-387-90093-4}}
* {{citation|first1=S.|last1=Mac Lane|authorlink1=Saunders Mac Lane|authorlink2=Garrett Birkhoff|last2=Birkhoff|first2=G.|title=Algebra|publisher=AMS Chelsea|year=1999|isbn=0-8218-1646-2}}.

{{DEFAULTSORT:Direct Sum Of Modules}}
[[Category:Linear algebra]]
[[Category:Module theory]]</text>
      <sha1>ss3onxxh8wpidgfkwh0f7q4lhdoy5hc</sha1>
    </revision>
  </page>
  <page>
    <title>Eta invariant</title>
    <ns>0</ns>
    <id>35063240</id>
    <revision>
      <id>814474143</id>
      <parentid>679061815</parentid>
      <timestamp>2017-12-09T01:14:23Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>[[User:JCW-CleanerBot#Logic|task]], replaced: journal=[[Annals of Mathematics|Annals of Mathematics. Second Series]] → journal=[[Annals of Mathematics]] |series=Second Series (2) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2978">In [[mathematics]], the '''eta invariant''' of a self-adjoint [[elliptic differential operator|elliptic]] [[differential operator]] on a [[compact manifold]] is formally the number of positive [[eigenvalue]]s minus the number of negative eigenvalues. In practice both numbers are often infinite so are defined using [[zeta function regularization]]. It was introduced by {{harvs|txt|last1=Atiyah|author1-link=Michael Atiyah|last2=Patodi|author2-link=Vijay Kumar Patodi|last3=Singer|author3-link=Isadore Singer|year1=1973|year2=1975}} who used it to extend the [[Hirzebruch signature theorem]] to manifolds with boundary. The name comes from the fact that it is a generalization of the [[Dirichlet eta function]].

They also later used the eta invariant of a self-adjoint operator to define the eta invariant of a compact odd-dimensional smooth manifold.

{{harvs|txt | last1=Atiyah | first1=Michael Francis | author1-link=Michael Atiyah | last2=Donnelly | first2=H. | last3=Singer | first3=I. M. | title=Eta invariants, signature defects of cusps, and values of L-functions | doi=10.2307/2006957 | mr=707164  | year=1983 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=118 | issue=1 | pages=131–177}}
defined the [[signature defect]] of the boundary of a manifold as the eta invariant, and used this to show that Hirzebruch's signature defect of a cusp of a [[Hilbert modular surface]] can be expressed in terms of the value at ''s''=0 or 1 of a [[Shimizu L-function]].

==Definition==

The eta invariant of self-adjoint operator ''A'' is given by ''η''&lt;sub&gt;''A''&lt;/sub&gt;(0), where ''η'' is the analytic continuation of

:&lt;math&gt;\eta(s)=\sum_{\lambda\ne 0} \frac{\operatorname{sign}(\lambda)}{|\lambda|^s}&lt;/math&gt;

and the sum is over the nonzero eigenvalues λ of&amp;nbsp;''A''.

==References==

*{{Citation | last1=Atiyah | first1=Michael Francis | author1-link=Michael Atiyah | last2=Patodi | first2=V. K. | last3=Singer | first3=I. M. | title=Spectral asymmetry and Riemannian geometry | doi=10.1112/blms/5.2.229  | mr=0331443  | year=1973 | journal=The Bulletin of the London Mathematical Society | issn=0024-6093 | volume=5 | pages=229–234}}
*{{Citation | last1=Atiyah | first1=Michael Francis | author1-link=Michael Atiyah | last2=Patodi | first2=V. K. | last3=Singer | first3=I. M. | title=Spectral asymmetry and Riemannian geometry. I | doi=10.1017/S0305004100049410 | mr=0397797  | year=1975 | journal=Mathematical Proceedings of the Cambridge Philosophical Society | issn=0305-0041 | volume=77 | pages=43–69}}
*{{Citation | last1=Atiyah | first1=Michael Francis | author1-link=Michael Atiyah | last2=Donnelly | first2=H. | last3=Singer | first3=I. M. | title=Eta invariants, signature defects of cusps, and values of L-functions | doi=10.2307/2006957 | mr=707164  | year=1983 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=118 | issue=1 | pages=131–177}}

[[Category:Differential operators]]</text>
      <sha1>gap4yk1qwtdj9tko70snannfb7kfvqg</sha1>
    </revision>
  </page>
  <page>
    <title>Goldbach–Euler theorem</title>
    <ns>0</ns>
    <id>14498167</id>
    <revision>
      <id>855758072</id>
      <parentid>793622264</parentid>
      <timestamp>2018-08-20T16:48:16Z</timestamp>
      <contributor>
        <username>Ira Leviton</username>
        <id>25046916</id>
      </contributor>
      <minor/>
      <comment>Deleted the phrasing 'it is also interesting to note that' - see [[Wikipedia:Manual_of_Style/Words_to_watch#editorializing]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4299">{{about|a certain mathematical series|The Goldbach's theorem concerning Fermat numbers|Fermat number#Basic properties}}

In [[mathematics]], the '''Goldbach–Euler theorem''' (also known as '''Goldbach's theorem'''), states that the sum of 1/(''p''&amp;nbsp;&amp;minus;&amp;nbsp;1) over the set of [[perfect powers]] ''p'', excluding 1 and omitting repetitions, [[Convergent series|converges]] to 1:

:&lt;math&gt;\sum_{p}^{\infty }\frac{1}{p-1}= {\frac{1}{3} +  \frac{1}{7} + \frac{1}{8}+ \frac{1}{15} + \frac{1}{24} + \frac{1}{26}+ \frac{1}{31}}+ \cdots = 1.&lt;/math&gt;

This result was first published in [[Leonhard Euler|Euler]]'s 1737 paper "''Variæ observationes circa series infinitas''". Euler attributed the result to a letter (now lost) from [[Christian Goldbach|Goldbach]].

==Proof==

Goldbach's original proof to Euler involved assigning a constant to the [[harmonic series (mathematics)|harmonic series]]:
&lt;math&gt;  \textstyle x = \sum_{n=1}^\infty \frac{1}{n}&lt;/math&gt;, which is [[divergent series|divergent]]. Such a proof is not considered rigorous by modern standards. There is a strong resemblance between the method of sieving out powers employed in his proof and the [[Proof of the Euler product formula for the Riemann zeta function|method of factorization used to derive Euler's product formula for the Riemann zeta function]].

Let x be given by

:&lt;math&gt;x = 1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \frac{1}{5} + \frac{1}{6} + \frac{1}{7} + \frac{1}{8} \cdots&lt;/math&gt;

Since the sum of the reciprocal of every power of two is &lt;math&gt; \textstyle 1 = \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \frac{1}{16} + \cdots&lt;/math&gt;, subtracting the terms with powers of two from x gives

:&lt;math&gt;x - 1 = 1 + \frac{1}{3} + \frac{1}{5} + \frac{1}{6} + \frac{1}{7} + \frac{1}{9} + \frac{1}{10} + \frac{1}{11} + \cdots&lt;/math&gt;

Repeat the process with the terms with the powers of three: &lt;math&gt;\textstyle \frac{1}{2} = \frac{1}{3} + \frac{1}{9} + \frac{1}{27} + \frac{1}{81} + \cdots&lt;/math&gt;

:&lt;math&gt;x - 1 - \frac{1}{2} = 1 + \frac{1}{5} + \frac{1}{6} + \frac{1}{7} + \frac{1}{10} + \frac{1}{11} + \frac{1}{12} + \cdots&lt;/math&gt;

Absent from the above sum are now all terms with powers of two and three. Continue by removing terms with powers of 5, 6 and so on until the right side is exhausted to the value of 1. Eventually, we obtain the equation

:&lt;math&gt;x - 1 - \frac{1}{2} - \frac{1}{4} - \frac{1}{5} - \frac{1}{6} - \frac{1}{9} - \cdots = 1&lt;/math&gt;

which we rearrange into

:&lt;math&gt;x - 1 = 1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{5} + \frac{1}{6} + \frac{1}{9} + \cdots&lt;/math&gt;

where the denominators consist of all positive integers that are the non-powers minus one. By subtracting the previous equation from the definition of x given above, we obtain

:&lt;math&gt;1 = \frac{1}{3} +  \frac{1}{7} + \frac{1}{8}+ \frac{1}{15} + \frac{1}{24} + \frac{1}{26}+ \frac{1}{31} + \cdots&lt;/math&gt;

where the denominators now consist only of perfect powers minus one.

While lacking mathematical rigor, Goldbach's proof provides a reasonably intuitive visualization of the problem. Rigorous proofs require proper and more careful treatment of the divergent terms of the harmonic series. Other proofs make use of the fact that the sum of 1/''p'' over the set of perfect powers ''p'', excluding 1 but including repetitions, converges to 1 by demonstrating the equivalence:

:&lt;math&gt;\sum_{p}^{\infty }\frac{1}{p - 1} = \sum_{m=2}^\infty \sum_{n=2}^\infty \frac{1}{m^n} = 1.&lt;/math&gt;

==See also==
* [[Goldbach's conjecture]]
* [[List of sums of reciprocals]]

==References==
* {{Cite journal|last1=Viader|first1=Pelegrí|last2=Bibiloni|first2= Lluís|last3=Paradís|first3= Jaume|date=|year=2006|title=On a series of Goldbach and Euler|url=https://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/bibiloni206.pdf|journal=[[American Mathematical Monthly]]|volume= 113|issue=3|pages= 206–220|doi=10.2307/27641889|jstor=27641889|postscript=&lt;!--None--&gt;|via=}}.
* {{cite book |title=Concrete Mathematics |last=Graham |first=Ronald |authorlink=Ronald Graham |author2=[[Donald Knuth]] |author3=[[Oren Patashnik]] |year=1988 |publisher=Addison-Wesley |location= |isbn=0-201-14236-8 }}

{{DEFAULTSORT:Goldbach-Euler theorem}}
[[Category:Theorems in analysis]]
[[Category:Mathematical series]]
[[Category:Articles containing proofs]]</text>
      <sha1>b132vozo50u0n3k7hw7d0ocvx4tv0g7</sha1>
    </revision>
  </page>
  <page>
    <title>Guess value</title>
    <ns>0</ns>
    <id>2712653</id>
    <revision>
      <id>791879757</id>
      <parentid>764956259</parentid>
      <timestamp>2017-07-23T01:31:17Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>unstub</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2184">{{unreferenced|date=June 2012}}

In mathematical modeling, a '''guess value''' is more commonly called a '''starting value''' or '''initial value'''. These are necessary for most [[Optimization (mathematics)|optimization]] problems which use [[search algorithms]], because those algorithms are mainly [[Deterministic algorithm|deterministic]] and [[iterative]], and they need to start somewhere. One common type of application is  [[nonlinear regression]].

==Use==
The quality of the initial values can have a considerable impact on the success or lack of such of the search algorithm. This is because the [[fitness function]] or [[objective function]] (in many cases a sum of squared errors ([[Sum of squared errors of prediction|SSE]])) can have difficult shapes. In some parts of the search region, the function may increase exponentially, in others quadratically, and there may be regions where the function [[asymptotes]] to a [[Plateau (mathematics)|plateau]]. Starting values that fall in an exponential region can lead to algorithm failure because of [[arithmetic overflow]]. Starting values that fall in the asymptotic plateau region can lead to algorithm failure because of "[[dithering]]". Deterministic search algorithms may use a slope function to go to a minimum. If the slope is very small, then underflow errors can cause the algorithm to wander, seemingly aimlessly; this is dithering.

==Finding value==
Guess values can be determined a number of ways. Guessing is one of them. If one is familiar with the type of problem, then this is an educated guess or [[guesstimate]]. Other techniques include [[linearization]], solving [[simultaneous equations]], reducing [[dimensions]], treating the problem as a [[time series]], converting the problem to a (hopefully) [[linear]] [[differential equation]], and using [[mean]] values. Further methods for determining starting values and optimal values in their own right come from [[stochastic]] methods, the most commonly known of these being [[evolutionary algorithms]] and particularly [[genetic algorithms]].

[[Category:Mathematical optimization]]
[[Category:Regression analysis]]
[[Category:Computational statistics]]</text>
      <sha1>fosiw8p60pih9i74ghrvfusf63jzic9</sha1>
    </revision>
  </page>
  <page>
    <title>History of programming languages</title>
    <ns>0</ns>
    <id>896120</id>
    <revision>
      <id>871453682</id>
      <parentid>871453444</parentid>
      <timestamp>2018-12-01T04:58:02Z</timestamp>
      <contributor>
        <username>Jboutland</username>
        <id>11778802</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30279">{{expand lead|date=February 2018}}
{{For|a detailed timeline of events|Timeline of programming languages}}
{{Hide in print|{{History of computing}}}}
The first high-level programming language was [[Plankalkül]], created by [[Konrad Zuse]] between 1942 and 1945&lt;ref&gt;{{cite journal |last=Knuth|first=Donald E.|last2=Pardo|first2=Luis Trabb|title=Early development of programming languages|journal=Encyclopedia of Computer Science and Technology|volume=7|pages=419–493|publisher=Marcel Dekker |postscript=&lt;!--None--&gt;}}&lt;/ref&gt;. The first high-level language to have an associated [[compiler]], was created by [[Corrado Böhm]] in 1951, for [http://e-collection.library.ethz.ch/eserv/eth:32719/eth-32719-02.pdf his PhD thesis]. The first commercially available language was [[FORTRAN]] (FORmula TRANslation); developed in 1956 (first manual appeared in 1956, but first developed in 1954) by a team led by [[John Backus]] at [[IBM]].

When FORTRAN was first introduced it was treated with suspicion because of the belief that programs compiled from high-level language would be less efficient than those written directly in machine code. FORTRAN became popular because it provided a means of porting existing code to new computers, in a hardware market that was rapidly evolving; the language eventually became known for its efficiency.

== Early history ==
During 1842–1843 [[Ada Lovelace]] translated the memoir of Italian mathematician [[Francis Maneclang]] about [[Charles Babbage]]'s newest proposed machine, the [[analytical engine]]; she supplemented the memoir with notes that specified in detail a method for calculating [[Bernoulli number]]s with the engine, recognized by some historians as the world's first computer program.&lt;ref&gt;{{citation|author = J. Fuegi and J. Francis| title = Lovelace &amp; Babbage and the creation of the 1843 'notes'|journal = Annals of the History of Computing| volume = 25| issue = 4|date=October–December 2003| doi = 10.1109/MAHC.2003.1253887| pages = 16, 19, 25}}&lt;/ref&gt;

The first computer codes were specialized for their applications: e.g., [[Alonzo Church]] was able to express the [[lambda calculus]] in a formulaic way and the [[Turing machine]] was an abstraction of the operation of a tape-marking machine.

To some people, some degree of expressive power and human-readability is required before the status of "programming language" is granted.  [[Jacquard Loom]]s and Charles Babbage's [[Difference engine|Difference Engine]] both had simple, extremely limited languages for describing the actions that these machines should perform.

== First programming languages ==
In the 1940s, the first recognizably modern electrically powered computers were created. The limited speed and memory capacity forced programmers to write hand tuned [[assembly language]] programs. It was eventually realized that programming in assembly language required a great deal of intellectual effort.

The first programming languages designed to communicate instructions to a computer were written in the 1950s.  An early [[high-level programming language]] to be designed for a computer was [[Plankalkül]], developed by the Germans for [[Z1 (computer)|Z1]] by [[Konrad Zuse]] between 1943 and 1945. However, it was not implemented until 1998 and 2000.&lt;ref&gt;[[Raúl Rojas|Rojas, Raúl]], et al. (2000). "Plankalkül: The First High-Level Programming Language and its Implementation". Institut frame Informatik, Freie Universität Berlin, Technical Report B-3/2000. [ftp://ftp.mi.fu-berlin.de/pub/reports/TR-B-00-03.pdf (full text)]&lt;/ref&gt;

[[John Mauchly]]'s [[Short Code (computer language)|Short Code]], proposed in 1949, was one of the first high-level languages ever developed for an [[electronic computer]].&lt;ref name=Sebesta&gt;{{cite book |last=Sebesta |first=W.S. |date=2006 |title=Concepts of Programming Languages |url= |location= |publisher= |page=44 |isbn=0-321-33025-0 |access-date= }}&lt;/ref&gt; Unlike [[machine code]], Short Code statements represented mathematical expressions in understandable form. However, the program had to be translated into [[machine code]] every time it ran, making the process much slower than running the equivalent machine code.

&lt;!-- [[WP:NFCC]] violation: [[File:Manchester Mark2.jpg|thumb|300px|The [[Manchester Mark 1]] ran programs written in [[Autocode]] from 1952.]] --&gt;
At the [[University of Manchester]], [[Alick Glennie]] developed [[Autocode]] in the early 1950s, with the second iteration developed for the Mark 1 by [[Tony Brooker|R. A. Brooker]] in 1954, known as the "Mark 1 Autocode". Brooker also developed an autocode for the [[Ferranti Mercury]] in the 1950s in conjunction with the University of Manchester. The version for the [[EDSAC]] 2 was devised by [[D. F. Hartley]] of [[University of Cambridge Mathematical Laboratory]] in 1961. Known as EDSAC 2 Autocode, it was a straight development from Mercury Autocode adapted for local circumstances, and was noted for its object code optimisation and source-language diagnostics which were advanced for the time. A contemporary but separate thread of development, [[Atlas Autocode]] was developed for the University of Manchester [[Atlas Computer (Manchester)|Atlas 1]] machine.

In 1954, language [[FORTRAN]] was invented at IBM by a team led by [[John Backus]]; it was the first widely used [[high-level language|high level general purpose programming language]] to have a functional implementation, as opposed to just a design on paper.&lt;ref&gt;{{cite web|author=|url=http://www.msnbc.msn.com/id/17704662/ |title=Fortran creator John Backus dies - Tech and gadgets- msnbc.com |publisher=MSNBC |date=2007-03-20 |accessdate=2010-04-25}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.math.grin.edu/~rebelsky/Courses/CS302/99S/Outlines/outline.02.html |title=CSC-302 99S : Class 02: A Brief History of Programming Languages |publisher=Math.grin.edu |accessdate=2010-04-25}}&lt;/ref&gt; It is still a popular language for [[high-performance computing]]&lt;ref name=hpc&gt;{{cite journal|url=http://queue.acm.org/detail.cfm?id=1820518|author=Eugene Loh|title=The Ideal HPC Programming Language|journal=Queue|date=18 June 2010 |publisher = Association of Computing Machines|volume=8|issue=6}}&lt;/ref&gt; and is used for programs that benchmark and rank the world's [[TOP500|fastest supercomputers]].&lt;ref&gt;{{cite web|title = HPL - A Portable Implementation of the High-Performance Linpack Benchmark for Distributed-Memory Computers | accessdate = 2015-02-21 | url = http://www.netlib.org/benchmark/hpl}}&lt;/ref&gt;

Another early programming language was devised by [[Grace Hopper]] in the US, called [[FLOW-MATIC]]. It was developed for the [[UNIVAC I]] at [[Remington Rand]] during the period from 1955 until 1959. Hopper found that business data processing customers were uncomfortable with mathematical notation, and in early 1955, she and her team wrote a specification for an [[English language|English]] programming language and implemented a prototype.&lt;ref&gt;Hopper (1978) p.&amp;nbsp;16.&lt;/ref&gt; The FLOW-MATIC compiler became publicly available in early 1958 and was substantially complete in 1959.&lt;ref&gt;Sammet (1969) p.&amp;nbsp;316&lt;/ref&gt; Flow-Matic was a major influence in the design of [[COBOL]], since only it and its direct descendent [[AIMACO]] were in actual use at the time.&lt;ref&gt;Sammet (1978) p.&amp;nbsp;204.&lt;/ref&gt;

Other languages still in use today include [[Lisp (programming language)|LISP]] (1958), invented by [[John McCarthy (computer scientist)|John McCarthy]] and [[COBOL]] (1959), created by the Short Range Committee. Another milestone in the late 1950s was the publication, by a committee of American and European computer scientists, of "a new language for algorithms";  the ''[[ALGOL]] 60 Report'' (the "'''ALGO'''rithmic '''L'''anguage"). This report consolidated many ideas circulating at the time and featured three key language innovations:

* nested block structure: code sequences and associated declarations could be grouped into [[block (programming)|blocks]] without having to be turned into separate, explicitly named procedures;
* [[Scope (programming)|lexical scoping]]: a block could have its own private variables, procedures and functions, invisible to code outside that block, that is, [[information hiding]].
Another innovation, related to this, was in how the language was described:
* a mathematically exact notation, [[Backus–Naur form]] (BNF), was used to describe the language's syntax. Nearly all subsequent programming languages have used a variant of BNF to describe the [[context-free grammar|context-free]] portion of their syntax.

Algol 60 was particularly influential in the design of later languages, some of which soon became more popular. The [[Burroughs large systems]] were designed to be programmed in an extended subset of Algol.

Algol's key ideas were continued, producing [[ALGOL 68]]:

* syntax and semantics became even more orthogonal, with anonymous routines, a recursive typing system with higher-order functions, etc.;
* not only the context-free part, but the full language syntax and semantics were defined formally, in terms of [[Van Wijngaarden grammar]], a formalism designed specifically for this purpose.
Algol 68's many little-used language features (for example, concurrent and parallel blocks) and its complex system of syntactic shortcuts and automatic type coercions made it unpopular with implementers and gained it a reputation of being ''difficult''. [[Niklaus Wirth]] actually walked out of the design committee to create the simpler [[Pascal (programming language)|Pascal]] language.

[[File:Fortran acs cover.jpeg|thumb|150px|Fortran]]

Some notable languages that were developed in this period include:

{|
| valign=top |
* 1951 – [[Assembly language|Regional Assembly Language]]
* 1952 – [[Autocode]]
* 1954 – [[Information Processing Language|IPL]] (forerunner to LISP)
* 1955 – [[FLOW-MATIC]] (led to COBOL)
* 1957 – [[Fortran|FORTRAN]] (First compiler)
* 1957 – [[COMTRAN]] (precursor to COBOL)
* 1958 – [[Lisp (programming language)|LISP]]
* 1958 – [[ALGOL 58]]
* 1959 – [[FACT computer language|FACT]] (forerunner to COBOL)
* 1959 – [[COBOL]] {{ns|20}} {{ns|30}}
| valign=top |
* 1959 – [[IBM RPG|RPG]]
* 1962 – [[APL (programming language)|APL]]
* 1962 – [[Simula]]
* 1962 – [[SNOBOL]]
* 1963 – [[Combined Programming Language|CPL]] (forerunner to C)
* 1964 – [[Speakeasy (computational environment)]]
* 1964 – [[BASIC]]
* 1964 – [[PL/I]]
* 1966 – [[JOSS]]
* 1967 – [[BCPL]] (forerunner to C)
|}

== Establishing fundamental paradigms ==

[[File:Lambda lc.svg|thumb|100px|Scheme]]
The period from the late 1960s to the late 1970s brought a major flowering of programming languages.  Most of the major language paradigms now in use were invented in this period:{{Original research inline|date=May 2018}}

* '''[[Speakeasy (computational environment)]]''', developed in 1964 at [[Argonne National Laboratory]] (ANL) by [[Stanley Cohen (physicist)|Stanley Cohen]], is an OOPS ([[object-oriented programming]], much like the later [[MATLAB]], [[IDL (programming language)]] and [[Mathematica]]) numerical package. Speakeasy has a clear [[Fortran]] foundation syntax. It first addressed efficient physics computation internally at ANL, was modified for research use (as "Modeleasy") for the [[Federal Reserve Board]] in the early 1970s and then was made available commercially; Speakeasy and Modeleasy are still in use currently.
* '''[[Simula]]''', invented in the late 1960s by [[Kristen Nygaard|Nygaard]] and [[Ole-Johan Dahl|Dahl]] as a superset of Algol 60, was the first language designed to support [[object-oriented programming]].
* '''[[C (programming language)|C]]''', an early [[system programming|systems programming]] language, was developed by [[Dennis Ritchie]] and [[Ken Thompson]] at [[Bell Labs]] between 1969 and 1973.
* '''[[Smalltalk]]''' (mid-1970s) provided a complete ground-up design of an object-oriented language.
* '''[[Prolog]]''', designed in 1972 by [[Alain Colmerauer|Colmerauer]], [[Phillipe Roussel|Roussel]], and [[Robert Kowalski|Kowalski]], was the first [[logic programming]] language.
* '''[[ML (programming language)|ML]]''' built a polymorphic type system (invented by [[Robin Milner]] in 1973) on top of Lisp,&lt;ref name="Gordon1996"&gt;{{cite web | last = Gordon | first = Michael J. C. | authorlink = Michael J. C. Gordon | year=1996 | title = From LCF to HOL: a short history | url = http://www.cl.cam.ac.uk/~mjcg/papers/HolHistory.pdf | page = 3 | quote = Edinburgh LCF, including the ML interpreter, was implemented in Lisp.| accessdate = 2015-05-04}}&lt;/ref&gt; pioneering [[Type system|statically typed]] [[functional programming]] languages.
Each of these languages spawned an entire family of descendants, and most modern languages count at least one of them in their ancestry.

The 1960s and 1970s also saw considerable debate over the merits of "[[structured programming]]", which essentially meant programming without the use of "[[goto]]".  A significant fraction of programmers believed that, even in languages that provide "goto", it is bad [[programming style]] to use it except in rare circumstances.  This debate was closely related to language design: some languages did not include a "goto" at all, which forced structured programming on the programmer.

To provide even faster compile times, some languages were structured for "[[one-pass compiler]]s" which expect subordinate routines to be defined first, as with [[Pascal (programming language)|Pascal]], where the main routine, or driver function, is the final section of the program listing.

Some notable languages that were developed in this period include:

{|
| valign=top |
* 1967 – [[BCPL]] (forerunner to B)
* 1968 – [[Logo (programming language)|Logo]]
* 1969 – [[B (programming language)|B]] (forerunner to C)
* 1970 – [[Pascal (programming language)|Pascal]]
* 1970 – [[Forth (programming language)|Forth]]
* 1972 – [[C (programming language)|C]]{{how|date=May 2018}}{{full citation needed|date=September 2018}}{{ns|20}} {{ns|30}}
| valign=top |
* 1972 – [[Smalltalk]]
* 1972 – [[Prolog]]
* 1973 – [[ML (programming language)|ML]]
* 1975 – [[Scheme (programming language)|Scheme]]
* 1978 – [[SQL]] (a query language, later extended)
|}

== 1980s: consolidation, modules, performance ==
[[File:Matlab Logo.png|thumb|100px|MATLAB]]
[[File:Erlang logo.png|thumb|100px|Erlang]]
[[File:Tcl.svg|thumb|50px|Tcl]]
The 1980s were years of relative consolidation in [[imperative language]]s. Rather than inventing new paradigms, all of these movements elaborated upon the ideas invented in the previous decade. [[C++]] combined object-oriented and systems programming.  The United States government standardized [[Ada (programming language)|Ada]], a systems programming language intended for use by defense contractors.  In Japan and elsewhere, vast sums were spent investigating so-called [[fifth-generation programming language]]s that incorporated logic programming constructs.  The functional languages community moved to standardize ML and Lisp. Research in [[Miranda (programming language)|Miranda]], a functional language with [[lazy evaluation]], began to take hold in this decade.

One important new trend in language design was an increased focus on programming for large-scale systems through the use of ''modules'', or large-scale organizational units of code. [[Modula]], Ada, and ML all developed notable module systems in the 1980s.  Module systems were often wedded to [[generic programming]] constructs---generics being, in essence, parametrized modules{{fact|date=August 2017}} (see also [[polymorphism in object-oriented programming]]).

Although major new paradigms for imperative programming languages did not appear, many researchers expanded on the ideas of prior languages and adapted them to new contexts.  For example, the languages of the [[Argus (computer system)|Argus]] and [[Emerald (computer system)|Emerald]] systems adapted object-oriented programming to [[distributed computing|distributed systems]].

The 1980s also brought advances in programming language implementation.  The [[Reduced instruction set computer|RISC]] movement in [[computer architecture]] postulated that hardware should be designed for [[compiler]]s rather than for human assembly programmers.  Aided by [[Central processing unit|processor]] speed improvements that enabled increasingly aggressive compilation techniques, the RISC movement sparked greater interest in compilation technology for high-level languages.

Language technology continued along these lines well into the 1990s. &lt;!-- However, the adoption of languages has always been driven by the adoption of new computer systems, and in the mid-1990s one of the most important new systems in computer history suddenly exploded in popularity. --&gt;

Some notable languages that were developed in this period include:

{|
| valign=top |
* 1980 – [[C++]] (as [[C with classes]], renamed in&amp;nbsp;1983)
* 1983 – [[Ada (programming language)|Ada]]
* 1984 – [[Common Lisp]]
* 1984 – [[MATLAB]]
* 1984 – dBase III, dBase III Plus  (Clipper and [[FoxPro]] as [[FoxBASE]], later developing into [[Visual FoxPro]]
* 1985 – [[Eiffel (programming language)|Eiffel]]
* 1986 – [[Objective-C]] {{ns|20}} {{ns|30}}
| valign=top |
* 1986 – [[LabVIEW]] (Visual Programming Language)
* 1986 – [[Erlang (programming language)|Erlang]]
* 1987 – [[Perl]]
* 1988 – [[Tcl]]
* 1988 – [[Wolfram Language]] (as part of [[Mathematica]], only got a separate name in June 2013)
* {{nowrap|1989 – [[FL (programming language)|FL]] (Backus)}}{{ns}}
|}

== 1990s: the Internet age ==
[[File:Haskell-Logo.svg|thumb|100px|Haskell]]
[[File:Lua-logo-nolabel.svg|thumb|100px|Lua]]
[[File:PHP Logo.png|thumb|100px|PHP]]
[[File:Rebol logo.png|thumb|100px|Rebol]]
The rapid growth of the Internet in the mid-1990s was the next major historic event in programming languages. By opening up a radically new platform for computer systems, the Internet created an opportunity for new languages to be adopted. In particular, the JavaScript programming language rose to popularity because of its early integration with the Netscape Navigator web browser. Various other scripting languages achieved widespread use in developing customized applications for web servers such as PHP. The 1990s saw no fundamental novelty in [[imperative language]]s, but much recombination and maturation of old ideas. This era began the spread of [[functional language]]s.  A big driving philosophy was programmer productivity.  Many "rapid application development" (RAD) languages emerged, which usually came with an [[Integrated development environment|IDE]], [[garbage collection (computer science)|garbage collection]], and were descendants of older languages.  All such languages were [[object-oriented programming|object-oriented]].  These included [[Object Pascal]], [[Visual Basic]], and [[Java (programming language)|Java]].  Java in particular received much attention.

More radical and innovative than the RAD languages were the new [[scripting language]]s.  These did not directly descend from other languages and featured new syntaxes and more liberal incorporation of features.  Many consider these scripting languages to be more productive than even the RAD languages, but often because of choices that make small programs simpler but large programs more difficult to write and maintain.{{Citation needed|date=June 2009}}  Nevertheless, scripting languages came to be the most prominent ones used in connection with the Web.

Some notable languages that were developed in this period include:

{|
| valign=top |
* 1990 – [[Haskell (programming language)|Haskell]]
* 1991 – [[Python (programming language)|Python]]
* 1991 – [[Visual Basic]]
* 1993 – [[Lua (programming language)|Lua]]
* 1993 – [[R (programming language)|R]]
* 1994 – [[CLOS]] (part of ANSI [[Common Lisp]])
| valign=top |
* 1995 – [[Ruby (programming language)|Ruby]]
* 1995 – [[Ada 95]] {{ns|20}} {{ns|30}}
* 1995 – [[Java (programming language)|Java]]
* {{nowrap|1995 – [[Embarcadero Delphi|Delphi (Object Pascal)]]}}
* 1995 – [[JavaScript]]
* 1995 – [[PHP]]
* 1997 – [[REBOL|Rebol]]
|}

== Current trends ==

Programming language evolution continues, in both industry and research.  Some of the recent trends have included:

[[File:D Programming Language logo.svg|thumb|100px|D Programming Language]]
[[File:Groovy-logo.svg|thumb|100px|Groovy]]
[[File:Rust programming language black logo.svg|thumb|100px|Rust]]
[[File:Scratchlogo.svg|thumb|100px|Scratch]]
[[File:Swift logo with text.svg|thumb|100px|Swift]]

* Increasing support for [[functional programming]] in mainstream languages used commercially, including [[Purely functional programming|pure functional programming]] for making code easier to reason about and easier to parallelise (at both micro- and macro- levels)
* Constructs to support [[Concurrent computing|concurrent]] and [[Distributed computing|distributed]] programming.
* Mechanisms for adding security and reliability verification to the language: extended static checking, [[dependent typing]], information flow control, static [[thread safety]].
* Alternative mechanisms for composability and modularity: [[mixin]]s, [[Trait (computer programming)|traits]], [[typeclass]]es, [[Delegation (programming)|delegates]], [[aspect-oriented programming|aspects]].
* Component-oriented software development.
* [[Metaprogramming]], [[Reflection (computer science)|reflection]] or access to the [[abstract syntax tree]]
** AOP or [[Aspect Oriented Programming]] allowing developers to insert code in another module or class at "join points"
** [[Domain specific language]]s and [[Automatic programming|code generation]]
*** XML for graphical interface ([[XUL]], [[Extensible Application Markup Language|XAML]])
* Increased interest in distribution and mobility.
* Integration with databases, including [[XML]] and [[relational database]]s.
* [[Open-source software|Open source]] as a developmental philosophy for languages, including the GNU Compiler Collection and languages such as [[Python (programming language)|Python]], [[Ruby (programming language)|Ruby]], and [[Scala (programming language)|Scala]].
* Massively parallel languages for coding 2000 processor GPU graphics processing units and supercomputer arrays including [[OpenCL]]
* Early research into (as-yet-unimplementable) [[quantum computing]] programming languages
* More interest in [[Visual_programming_language|visual programming languages]] like [[Scratch (programming language)|Scratch]] 

Some notable languages developed during this period include:

{|
| valign=top |
* 2000 – [[ActionScript]]
* 2001 – [[C Sharp (programming language)|C#]]
* 2001 – [[D (programming language)|D]]
* 2002 – [[Scratch (programming language)|Scratch]]
* 2003 – [[Groovy (programming language)|Groovy]] {{ns|15}} {{ns|30}}
* 2003 – [[Scala (programming language)|Scala]]
* 2005 – [[F Sharp (programming language)|F#]]
* 2006 – [[Windows PowerShell|PowerShell]]
* 2007 – [[Clojure]]
| valign=top |
* 2009 – [[Go (programming language)|Go]]
* 2010 – [[Rust (programming language)|Rust]]
* 2011 – [[Dart (programming language)|Dart]]
* 2011 – [[Kotlin (programming language)|Kotlin]]
* 2011 – [[Red (programming language)|Red]]
* 2011 – [[Elixir (programming language)|Elixir]] 
* 2012 – [[Julia (programming language)|Julia]]
* 2014 – [[Swift (programming language)|Swift]]
* 2016 – [[Ring (programming language)|Ring]] &lt;ref name="evolution"&gt;{{cite web |url=https://www.codeproject.com/Articles/1223114/The-evolution-of-the-Ring-programming-language |title=The evolution of the Ring programming language, Ring in Top 50 programming languages according to TIOBE Index |author=Rubin Liu |date=28 February 2018 |work=codeproject.com |publisher=[[Code_Project]]}}&lt;/ref&gt;&lt;ref name="TIOBE Index"&gt;{{cite web |url=https://www.tiobe.com/tiobe-index/ |title=TIOBE Index, Ring in Top 50 programming languages according to TIOBE Index |author=TIOBE |date=2 March 2018 |work=www.tiobe.com |publisher=[[TIOBE_index]]}}&lt;/ref&gt;
|}

== Prominent people ==
[[File:Anders Hejlsberg.jpg|thumb|100px|Anders Hejlsberg]]
[[File:Yukihiro Matsumoto EuRuKo 2011.jpg|thumb|100px|Yukihiro Matsumoto]]
[[File:Grace Hopper.jpg|thumb|100px|Grace M. Hopper]]
[[File:BjarneStroustrup.jpg|thumb|100px|Bjarne Stroustrup]]
[[File:Niklaus Wirth, UrGU.jpg|thumb|100px|Niklaus Wirth]]

Some key people who helped develop programming languages:

* [[Alan Cooper]], developer of [[Visual Basic]].
* [[Alan Kay]], pioneering work on object-oriented programming, and originator of [[Smalltalk]].
* [[Anders Hejlsberg]], developer of [[Turbo Pascal]], [[Embarcadero Delphi|Delphi]], [[C Sharp (programming language)|C#]], and [[TypeScript]].
* [[Bertrand Meyer]], inventor of [[Eiffel (programming language)|Eiffel]].
* [[Bjarne Stroustrup]], developer of [[C++]].
* [[Brian Kernighan]], co-author of the first book on the [[C (programming language)|C]] programming language with [[Dennis Ritchie]], coauthor of the [[AWK]] and [[AMPL (programming language)|AMPL]] programming languages.
* [[Chris Lattner]], creator of [[Swift (programming language)|Swift]] and [[LLVM]].
* [[Dennis Ritchie]], inventor of [[C (programming language)|C]]. Unix Operating System, Plan 9 Operating System.
* [[Grace Hopper]], first to use the term [[compiler]] and developer of [[Flow-Matic]], influenced development of [[COBOL]].  Popularized machine-independent programming languages and the term "[[debugging]]".
* [[Guido van Rossum]], creator of [[Python (programming language)|Python]].
* [[James Gosling]], lead developer of [[Java (programming language)|Java]] and its precursor, [[Oak (programming language)|Oak]].
* [[Jean Ichbiah]], chief designer of [[Ada (programming language)|Ada]], [[Ada 83]].
* [[Jean-Yves Girard]], co-inventor of the [[polymorphic lambda calculus]] (System F).
* [[Jeff Bezanson]], main designer, and one of the core developers of [[Julia (programming language)|Julia]].
* [[Joe Armstrong (programming)|Joe Armstrong]], creator of [[Erlang (programming language)|Erlang]].
* [[John Backus]], inventor of [[Fortran]] and cooperated in the design of [[ALGOL 58]] and [[ALGOL 60]].
* [[John C. Reynolds]], co-inventor of the polymorphic lambda calculus (System F).
* [[John McCarthy (computer scientist)|John McCarthy]], inventor of [[Lisp (programming language)|LISP]].
* [[John von Neumann]], originator of the [[operating system]] concept.
* [[Rust (programming language)|Graydon Hoare]], inventor of [[Rust (programming language)|Rust]].
* [[Ken Thompson]], inventor of [[B (programming language)|B]], [[Go (programming language)|Go Programming Language]], Inferno Programming Language, and [[Unix]] Operating System co-author.
* [[Kenneth E. Iverson]], developer of [[APL (programming language)|APL]], and co-developer of [[J (programming language)|J]] along with [[Roger Hui]].
* [[Konrad Zuse]], designed the first [[high-level programming language]], [[Plankalkül]] (which influenced [[ALGOL 58]]&lt;ref&gt;{{cite book |last=Rojas|first=Raúl|first2=Ulf|last2=Hashagen| year=2002 |title=The First Computers: History and Architectures|page=292 |url=https://books.google.com/books?id=nDWPW9uwZPAC&amp;pg=PA292&amp;dq=algol-68+konrad+zuse |location= |publisher=MIT Press |isbn=978-0262681377 |accessdate=October 25, 2013 }}&lt;/ref&gt;).
* [[Kristen Nygaard]], pioneered object-oriented programming, co-invented [[Simula]].
* [[Larry Wall]], creator of the Perl programming language (see [[Perl]] and [[Perl 6]]).
* [[Martin Odersky]], creator of [[Scala (programming language)|Scala]], and previously a contributor to the design of [[Java (programming language)|Java]].
* [[Martin Richards (computer scientist)|Martin Richards]] developed the [[BCPL]] programming language, forerunner of the [[B (programming language)|B]] and [[C (programming language)|C]] languages.
* [[Nathaniel Rochester (computer scientist)|Nathaniel Rochester]], inventor of first [[Assembler (computing)|assembler]] (IBM 701).
* [[Niklaus Wirth]], inventor of [[Pascal (programming language)|Pascal]], [[Modula]] and [[Oberon (programming language)|Oberon]].
* [[Ole-Johan Dahl]], pioneered object-oriented programming, co-invented [[Simula]].
* [[Rasmus Lerdorf]], creator of [[PHP]]
* [[Rich Hickey]], creator of [[Clojure]].
* [[Robin Milner]], inventor of [[ML (programming language)|ML]], and sharing credit for [[Hindley–Milner]] [[parametric polymorphism|polymorphic]] [[type inference]].
* [[Stephen Wolfram]], creator of [[Mathematica]].
* [[Tom Love]] and [[Brad Cox]], creator of [[Objective-C]].
* [[Walter Bright]], creator of [[D (programming language)|D]].
* [[Yukihiro Matsumoto]], creator of [[Ruby (programming language)|Ruby]].

== See also ==
{|
| valign=top |
* [[Association for Computing Machinery|ACM]]
* [[SIGPLAN]]
* [[History of Programming Languages Conference]]
* [[History of compiler writing]]
* [[History of computing hardware]]  {{ns|10}} {{ns|23}}
| valign=top |
* [[Programming language]]
* [[Timeline of computing]]
* [[Timeline of programming languages]]
* [[List of programming languages]]
* [[List of programmers]]
|}

== References ==
&lt;references /&gt;

== Further reading ==
* [[Saul Rosen|Rosen, Saul]], (editor), ''Programming Systems and Languages'', McGraw-Hill, 1967.
* [[Jean E. Sammet|Sammet, Jean E.]], ''Programming Languages: History and Fundamentals'', Prentice-Hall, 1969.
* {{cite journal|author=Sammet, Jean E.|title=Programming Languages: History and Future|journal=Communications of the ACM|volume=15|issue=7|date=July 1972|pages=601–610|doi=10.1145/361454.361485}}
* [[Richard L. Wexelblat]] (ed.): ''History of Programming Languages'', [[Academic Press]] 1981.
* Thomas J. Bergin and Richard G. Gibson (eds.): ''History of Programming Languages'', Addison Wesley, 1996.

== External links ==
* [http://www.scriptol.com/programming/history.php History and evolution of programming languages]
* [http://www.levenez.com/lang/history.html Graph of programming language history]

{{Programming languages}}

{{DEFAULTSORT:Programming languages}}
[[Category:History of computing]]
[[Category:History of computer science]]</text>
      <sha1>buet5qnhtwu7p4duz75w3g0rjarxa7p</sha1>
    </revision>
  </page>
  <page>
    <title>Homography (computer vision)</title>
    <ns>0</ns>
    <id>40393020</id>
    <revision>
      <id>862160311</id>
      <parentid>862160075</parentid>
      <timestamp>2018-10-02T15:15:05Z</timestamp>
      <contributor>
        <ip>2A02:8106:15:BD00:8DE3:FBF0:CE94:98C1</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7163">{{for|other uses of this term|homography (disambiguation)}}
[[File:Hauck_Neue_Constructionen_der_Perspective_fig1a.png|right|thumb|250px|Geometrical setup for homography: [[stereo cameras]] O&lt;sub&gt;1&lt;/sub&gt; and O&lt;sub&gt;2&lt;/sub&gt; both pointed at ''X'' in [[epipolar geometry]]. Drawing from ''Neue Konstruktionen der Perspektive und Photogrammetrie'' by Hermann Guido Hauck (1845 — 1905)]]
In the field of [[computer vision]], any two images of the same planar surface in space are related by a '''homography''' (assuming a [[pinhole camera model]]).  This has many practical applications, such as [[image rectification]], [[image registration]], or computation of camera motion—rotation and translation—between two images.   Once camera rotation and translation have been extracted from an estimated homography matrix, this information may be used for navigation, or to insert models of 3D objects into an image or video, so that they are rendered with the correct perspective and appear to have been part of the original scene (see [[Augmented reality]]).

== 3D plane to plane equation ==

We have two cameras ''a'' and ''b'', looking at points &lt;math&gt;P_i&lt;/math&gt; in a plane.
Passing from the projection &lt;math&gt;{}^bp_i=\left({}^bu_i;{}^bv_i;1\right)&lt;/math&gt; of &lt;math&gt;P_i&lt;/math&gt; in ''b'' to the projection &lt;math&gt;{}^ap_i=\left({}^au_i;{}^av_i;1\right)&lt;/math&gt; of &lt;math&gt;P_i&lt;/math&gt; in ''a'':

: &lt;math&gt;{}^ap_i = \frac{{}^bz_i}{{}^az_i}K_a \cdot H_{ab} \cdot K_b^{-1} \cdot {}^bp_i&lt;/math&gt;

where &lt;math&gt;{}^az_i&lt;/math&gt; and &lt;math&gt;{}^bz_i&lt;/math&gt; are the z coordinates of P in each camera frame and where the homography matrix &lt;math&gt;H_{ab}&lt;/math&gt; is given by

: &lt;math&gt;H_{ab} = R - \frac{t n^T}{d}&lt;/math&gt;.

&lt;math&gt;R&lt;/math&gt; is the [[rotation matrix]] by which ''b'' is rotated in relation to ''a''; ''t'' is the translation [[Vector (geometry)|vector]] from ''a'' to ''b''; ''n'' and ''d'' are the normal vector of the plane and the distance to the plane respectively.
''K''&lt;sub&gt;''a''&lt;/sub&gt; and ''K''&lt;sub&gt;''b''&lt;/sub&gt; are the cameras' [[Camera_resectioning#Intrinsic_parameters|intrinsic parameter]] matrices. 

[[Image:Homography-transl-bold.svg]]

The figure shows camera ''b'' looking at the plane at distance ''d''.
Note: From above figure, assuming &lt;math&gt;n^T P_i + d = 0&lt;/math&gt; as plane model, &lt;math&gt;n^T P_i&lt;/math&gt; is the projection of vector &lt;math&gt;P_i&lt;/math&gt; along &lt;math&gt;n&lt;/math&gt;, and equal to &lt;math&gt;-d&lt;/math&gt;. So &lt;math&gt;t = t \cdot 1 = t \left(-\frac{n^TP_i}{d}\right)&lt;/math&gt;. And we have &lt;math&gt;H_{ab} P_i = R P_i + t&lt;/math&gt; where &lt;math&gt;H_{ab} = R - \frac{t n^T}{d}&lt;/math&gt;.

This formula is only valid if camera ''b'' has no rotation and no translation. In the general case where &lt;math&gt;R_a,R_b&lt;/math&gt; and &lt;math&gt;t_a,t_b&lt;/math&gt; are the respective rotations and translations of camera ''a'' and ''b'', &lt;math&gt;R=R_a R_b^T&lt;/math&gt; and the homography matrix &lt;math&gt;H_{ab}&lt;/math&gt; becomes

: &lt;math&gt;H_{ab} = R_a R_b^T - R_a \frac{(t_b-t_a) n^T}{d}R_b^T = R_a \left(I - \frac{(t_b-t_a) n^T}{d}\right)R_b^T . &lt;/math&gt;

where ''d'' is the distance of the camera ''b'' to the plane.

The homography matrix can only be computed between images taken from the same camera shot at different angles. It doesn't matter what is present in the images. The matrix contains a warped form of the images.

== Affine homography ==   
When the image region in which the homography is computed is small or the image has been acquired with a large focal length, an ''affine homography'' is a more appropriate model of image displacements. An affine homography is a special type of a general homography whose last row is fixed to  

: &lt;math&gt;h_{31}=h_{32}=0, \; h_{33}=1.&lt;/math&gt;

==See also==
* [[Direct linear transformation]]
* [[Epipolar geometry]]
* [[Feature (computer vision)]]
* [[Fundamental matrix (computer vision)]]
* [[Pose (computer vision)]]

==References==
{{Reflist}}

*{{cite journal |
author=O. Chum and T. Pajdla and P. Sturm |
title=The Geometric Error for Homographies |
journal=Computer Vision and Image Understanding |
volume=97 |
pages=86–102 |
year=2005 |
doi=10.1016/j.cviu.2004.03.004
| issue=1}}

==External links==
* Serge Belongie &amp; David Kriegman (2007) [http://cseweb.ucsd.edu/classes/wi07/cse252a/homography_estimation/homography_estimation.pdf Explanation of Homography Estimation] from Department of Computer Science and Engineering, [[University of California, San Diego]].
* A. Criminisi, I. Reid &amp; A. Zisserman (1997) [http://www.robots.ox.ac.uk/~vgg/presentations/bmvc97/criminispaper/ "A Plane Measuring Device"], §3 Computing the Plane to Plane Homography, from Visual Geometry Group, Department of Engineering Science, [[University of Oxford]].
* Elan Dubrofsky (2009) [https://www.cs.ubc.ca/grads/resources/thesis/May09/Dubrofsky_Elan.pdf Homography Estimation], [[Master's thesis]], from Department of Computer Science, [[University of British Columbia]]. 
* Richard Hartley &amp; Andrew Zisserman (2004) [http://www.robots.ox.ac.uk/%7Evgg/hzbook/ Multiple View Geometry] from Visual Geometry Group, Oxford. Includes [[Matlab]] [http://www.robots.ox.ac.uk/%7Evgg/hzbook/code/ Functions] for calculating a homography and the [[fundamental matrix (computer vision)]]. 
* Manolis Lourakis (2007) [http://www.ics.forth.gr/%7elourakis/homest/ homest], a [[GPL]] [[C (programming language)|C]]/[[C++]] library for [[robust statistics|robust]], non-linear (based on the [[Levenberg–Marquardt algorithm]]) homography estimation from matched point pairs, from Institute of Computer Science, [[Foundation for Research %26 Technology – Hellas]], [[Heraklion, Crete]]. 
*[[OpenCV]] is a complete (''open and free'') computer vision software library that has many routines related to homography estimation ([http://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#findhomography cvFindHomography]) and re-projection ([http://docs.opencv.org/modules/core/doc/operations_on_arrays.html#perspectivetransform cvPerspectiveTransform]).
*[https://www.youtube.com/watch?v=vjSoI3b-I_w GIMP Tutorial – using the Perspective Tool] by Billy Kerr on [[YouTube]]. Shows how to do a '''perspective transform''' using [[GIMP]].
* Allan Jepson (2010) [http://www.cs.toronto.edu/~jepson/csc2503/tutorials/homography.pdf Planar Homographies] from Department of Computer Science, [[University of Toronto]]. Includes 2D homography from four pairs of corresponding points, mosaics in image processing, removing perspective distortion in computer vision, rendering textures in computer graphics, and computing planar shadows.
* [http://www.cs.washington.edu/education/courses/cse576/10sp/notes/ransac.pdf Plane transfer homography] Course notes from CSE576 at [[University of Washington]] in [[Seattle]].
* Etienne Vincent &amp; Robert Laganiere (2000) [http://www.site.uottawa.ca/research/viva/papers/homographie.pdf Detecting Planar Homographies in an Image Pair] from School of Information Technology and Engineering,  [[University of Ottawa]]. Describes an algorithm for detecting planes in images, uses random sample consensus ([[RANSAC]]) method, describes heuristics and iteration.



[[Category:Geometry in computer vision]]
[[Category:Functions and mappings]]</text>
      <sha1>05zwpm2y7b301w4y2cqzrird25dews0</sha1>
    </revision>
  </page>
  <page>
    <title>Incentive compatibility</title>
    <ns>0</ns>
    <id>5365395</id>
    <revision>
      <id>865334773</id>
      <parentid>861640941</parentid>
      <timestamp>2018-10-23T08:20:34Z</timestamp>
      <contributor>
        <ip>138.231.80.123</ip>
      </contributor>
      <comment>simplify syntax</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3217">A [[mechanism design|mechanism]] is called '''incentive-compatible (IC)''' if every participant can achieve the best outcome to himself just by acting according to his true preferences. &lt;ref name=agt07&gt;{{Cite Algorithmic Game Theory 2007}}&lt;/ref&gt;{{rp|225}}

There are several different degrees of incentive-compatibility: 
* The stronger degree is '''[[Strategyproofness|dominant-strategy incentive-compatibility]]''' (DSIC).&lt;ref name=agt07/&gt;{{rp|415}} It means that truth-telling is a weakly-[[dominant strategy]], i.e you fare best or at least not worse by being truthful, regardless of what the others do. In a DSIC mechanism, strategic considerations cannot help any agent achieve better outcomes than the truth; hence, such mechanisms are also called '''strategyproof'''&lt;ref name=agt07/&gt;{{rp|244,752}} or '''truthful'''.&lt;ref name=agt07/&gt;{{rp|415}}
* A weaker degree is '''Bayesian-Nash incentive-compatibility''' (BNIC).&lt;ref name=agt07/&gt;{{rp|416}} It means that there is a [[Bayesian Nash equilibrium]] in which all participants reveal their true preferences. I.e, ''if'' all the others act truthfully, ''then'' it is also best or at least not worse for you to be truthful.&lt;ref name=agt07/&gt;{{rp|234}} 

Every DSIC mechanism is also BNIC, but a BNIC mechanism may exist even if no DSIC mechanism exists.

Typical examples of DSIC mechanisms are [[majority voting]] between two alternatives, and [[second-price auction]].

Typical examples of a mechanisms that are not DSIC are [[plurality voting]] between three or more alternatives and [[first-price auction]].

== Incentive-compatibility in randomized mechanisms ==
A randomized mechanism is a probability-distribution on deterministic mechanisms. There are two ways to define incentive-compatibility of randomized mechanisms:&lt;ref name=agt07/&gt;{{rp|231–232}}
* The stronger definition is: a randomized mechanism is '''universally-incentive-compatible''' if every mechanism selected with positive probability is incentive-compatible (e.g. if truth-telling gives the agent an optimal value regardless of the coin-tosses of the mechanism).
* The weaker definition is: a randomized mechanism is '''incentive-compatible-in-expectation''' if the game induced by expectation is incentive-compatible (e.g. if truth-telling gives the agent an optimal [[expected value]]).

== Revelation principles ==
{{Main|Revelation principle}}
The famous Revelation principle comes in two variants corresponding to the two flavors of incentive-compatibility:
* The dominant-strategy revelation-principle says that every social-choice function that can be implemented in dominant-strategies can be implemented by a DSIC mechanism.
* The Bayesian–Nash revelation-principle says that every social-choice function that can be implemented in Bayesian–Nash equilibrium ([[Bayesian game]], i.e. game of incomplete information) can be implemented by a BNIC mechanism.

==See also==
* [[Lindahl tax]]
* [[Preference revelation]]
* [[Strategyproofness]]
* [[Monotonicity (mechanism design)]]
* [[Implementability (disambiguation)|Implementability]]
==References==
{{reflist}}

{{Game theory}}

{{DEFAULTSORT:Incentive Compatibility}}

[[Category:Mechanism design]]
[[Category:Game theory]]</text>
      <sha1>k8okj0qqciohumtmc0113pdzvrw3ecp</sha1>
    </revision>
  </page>
  <page>
    <title>Integral cryptanalysis</title>
    <ns>0</ns>
    <id>7210758</id>
    <revision>
      <id>723098251</id>
      <parentid>675448898</parentid>
      <timestamp>2016-06-01T00:22:41Z</timestamp>
      <contributor>
        <username>Dcirovic</username>
        <id>11795905</id>
      </contributor>
      <minor/>
      <comment>/* References */clean up using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7196">In [[cryptography]], '''integral cryptanalysis''' is a [[cryptanalysis|cryptanalytic attack]] that is particularly applicable to [[block cipher]]s based on [[substitution-permutation network]]s. It was originally designed by [[Lars Knudsen]] as a dedicated attack against [[Square (cipher)|Square]],  so it is commonly known as the '''Square attack'''. It was also extended to a few other ciphers related to Square: [[CRYPTON]], [[Rijndael]], and [[SHARK]]. [[Stefan Lucks]] generalized the attack to what he called a ''saturation attack'' and used it to attack [[Twofish]], which is not at all similar to Square, having a radically different [[Feistel network]] structure. Forms of integral cryptanalysis have since been applied to a variety of ciphers, including [[Hierocrypt]], [[International Data Encryption Algorithm|IDEA]], [[Camellia (cipher)|Camellia]], [[Skipjack (cipher)|Skipjack]], [[MISTY1]], [[MISTY2]], [[SAFER++]], [[KHAZAD]], and ''FOX'' (now called [[IDEA NXT]]).

Unlike [[differential cryptanalysis]], which uses pairs of [[chosen plaintext attack|chosen plaintexts]] with a fixed [[XOR]] difference, integral cryptanalysis uses [[set (mathematics)|set]]s or even [[multiset]]s of chosen plaintexts of which part is held constant and another part varies through all possibilities. For example, an attack might use 256 chosen plaintexts that have all but 8 of their bits the same, but all differ in those 8 bits. Such a set necessarily has an XOR sum of 0, and the XOR sums of the corresponding sets of ciphertexts provide information about the cipher's operation. This contrast between the differences of pairs of texts and the sums of larger sets of texts inspired the name "integral cryptanalysis", borrowing the terminology of [[calculus]].

==References==
* {{ cite conference
     | author = [[Joan Daemen]], [[Lars Knudsen]], [[Vincent Rijmen]]
     | title = The Block Cipher Square
     | conference = 4th International Workshop on [[Fast Software Encryption]] (FSE '97), Volume 1267 of [[Lecture Notes in Computer Science]]
     | pages = 149–165
     | publisher = [[Springer-Verlag]]
     | date = January 1997
     | location = [[Haifa]]
     | url = http://www.cosic.esat.kuleuven.be/publications/article-309.pdf
     | format = [[PDF]]
     | accessdate = 2007-02-15 }}
* {{ cite conference
     | author = Carl D'Halluin, Gert Bijnens, Vincent Rijmen, [[Bart Preneel]]
     | title = Attack on Six Rounds of Crypton
     | conference = 6th International Workshop on Fast Software Encryption (FSE '99)
     | pages = 46–59
     | publisher = Springer-Verlag
     | date = March 1999
     | location = [[Rome]]
     | url = http://citeseer.ist.psu.edu/479905.html
     | format = PDF/[[PostScript]]
     | accessdate = 2007-03-03 }}
* {{ cite conference
     | author = [[Niels Ferguson|N. Ferguson]], [[John Kelsey (cryptanalyst)|J. Kelsey]], [[Stefan Lucks|S. Lucks]], [[Bruce Schneier|B. Schneier]], M. Stay, [[David A. Wagner|D. Wagner]], D. Whiting
     | title = Improved Cryptanalysis of Rijndael
     | conference = 7th International Workshop on Fast Software Encryption (FSE 2000)
     | pages = 213–230
     | publisher = Springer-Verlag
     | date = April 2000
     | location = [[New York City]]
     | url = http://www.schneier.com/paper-rijndael.html
     | format = PDF/PostScript
     | accessdate = 2007-03-06 }}
* {{ cite conference
     | author = Stefan Lucks
     | title = The Saturation Attack - a Bait for Twofish
     | conference = 8th International Workshop on Fast Software Encryption (FSE '01)
     | pages = 1–15
     | publisher = Springer-Verlag
     | date = September 14, 2000
     | location = [[Yokohama]]
     | url = http://eprint.iacr.org/2000/046
     | format = PDF/[[PostScript]]
     | accessdate = 2006-11-30 }}
* {{ cite conference
     | author = [[Paulo S. L. M. Barreto]], Vincent Rijmen, [[Jorge Nakahara, Jr.]], Bart Preneel, [[Joos Vandewalle]], Hae Yong Kim
     | title = Improved SQUARE Attacks against Reduced-Round HIEROCRYPT
     | conference = 8th International Workshop on Fast Software Encryption (FSE '01)
     | pages = 165–173
     | publisher = Springer-Verlag
     | date = April 2001
     | location = Yokohama
     | url = http://www.cosic.esat.kuleuven.be/publications/article-83.pdf
     | format = PDF
     | accessdate = 2007-03-03 }}
* {{ cite journal
     |author1=Jorge Nakahara, Jr. |author2=Paulo S.L.M. Barreto |author3=Bart Preneel |author4=Joos Vandewalle |author5=Hae Y. Kim | title = SQUARE Attacks on Reduced-Round PES and IDEA Block Ciphers
     | year = 2001
     | url = http://citeseer.ist.psu.edu/548521.html
     | format = PDF/PostScript
     | accessdate = 2007-03-03 }}
* {{ cite conference
     |author1=Yongjin Yeom |author2=Sangwoo Park |author3=Iljun Kim | title = On the Security of CAMELLIA against the Square Attack
     | conference = 9th International Workshop on Fast Software Encryption (FSE '02)
     | pages = 89–99
     | publisher = Springer-Verlag
     | date = February 2002
     | location = [[Leuven]]
     | url = http://maths.utime.cn:81/Crypt1998-2003/bibs/2365/23650089.htm
     | format = PDF
     | accessdate = 2007-03-03 }}
* {{ cite conference
     |author1=Kyungdeok Hwang |author2=Wonil Lee |author3=Sungjae Lee |author4=Sangjin Lee |author5=Jongin Lim | title = Saturation Attacks on Reduced Round Skipjack
     | conference = 9th International Workshop on Fast Software Encryption (FSE '02)
     | pages = 100–111
     | publisher = Springer-Verlag
     | date = February 2002
     | location = Leuven
     | url = http://maths.utime.cn:81/Crypt1998-2003/bibs/2365/23650100.htm
     | format = PDF
     | accessdate = 2007-03-03 }}
* {{ cite conference
     |author1=Lars Knudsen |author2=David Wagner | title = Integral cryptanalysis
     | conference = 9th International Workshop on Fast Software Encryption (FSE '02)
     | pages = 112–127
     | publisher = Springer-Verlag
     | date = December 11, 2001
     | location = Leuven
     | url = http://citeseer.ist.psu.edu/506311.html
     | format = PDF/PostScript
     | accessdate = 2006-11-30 }}
* {{ cite journal
     | author = [[Gilles Piret]], [[Jean-Jacques Quisquater]]
     | title = Integral Cryptanalysis on reduced-round Safer++
     | date = February 16, 2003
     | url = http://citeseer.ist.psu.edu/559604.html
     | format = PDF/PostScript
     | accessdate = 2007-03-03 }}
* {{ cite conference
     | author = Frédéric Muller
     | title = A New Attack against Khazad
     | conference = Advances in Cryptology - [[ASIACRYPT]] 2003
     | pages = 347–358
     | publisher = Springer-Verlag
     | date = December 2003
     | location = [[Taipei]]
     | url = http://www.mathmagic.cn/Crypt1998-2003/bibs/2894/28940347.htm
     | format = PDF
     | accessdate = 2007-03-03 }}
* {{ cite journal
     |author1=Wu Wenling |author2=Zhang Wentao |author3=Feng Dengguo | title = Improved Integral Cryptanalysis of FOX Block Cipher
     | date = August 25, 2005
     | url = http://eprint.iacr.org/2005/292.pdf
     | format = PDF
     | accessdate = 2007-03-03 }}

{{Cryptography navbox | block}}

[[Category:Cryptographic attacks]]


{{crypto-stub}}</text>
      <sha1>tox20avwkzoevc6695xernev4hxqi1m</sha1>
    </revision>
  </page>
  <page>
    <title>José Ádem</title>
    <ns>0</ns>
    <id>6018290</id>
    <revision>
      <id>868196712</id>
      <parentid>860212185</parentid>
      <timestamp>2018-11-10T17:06:59Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <minor/>
      <comment>a link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4701">{{infobox scientist
  | name        = José Ádem
  | image       = Jose Adem math.jpg
  | birth_place = [[Tuxpan, Veracruz]], [[Mexico]]
  | nationality       = {{MEX}}
  | fields            = [[Algebraic Topology]]
  | workplaces        = 
    | alma_mater  = [[National University of Mexico]] &lt;small&gt; (B.S., 1949)&lt;/small&gt;&lt;br&gt; [[Princeton University]]&lt;small&gt; (Ph.D., 1952)&lt;/small&gt;
  |known_for = [[Steenrod algebra#Ádem relations|Ádem relations]]
 | doctoral_advisor  = [[Norman Steenrod]]
    }}

'''José Ádem''' (born in [[Tuxpan]], [[Veracruz]], October 27, 1921; died February 14, 1991)  was a [[Mexican people|Mexican]] mathematician who worked in [[algebraic topology]], and proved the [[Steenrod algebra#Ádem relations|Ádem relations]] between [[Steenrod square]]s.

==Life and education==
Ádem showed an interest in mathematics from an early age, and moved to [[Mexico City]] in 1941 to pursue a degree in engineering and mathematics. He obtained his [[B.S.]] in mathematics from the [[National Autonomous University of Mexico]] (UNAM) in 1949.&lt;ref name="bio"&gt;{{web cite| url=https://web.archive.org/web/20070105165733/http://www.colegionacional.org.mx/AdemJo0.htm| title=Biography of José Ádem}}&lt;/ref&gt; During this time met [[Solomon Lefschetz]], a famous algebraic topologist who was spending prolonged periods of time in Mexico. Lefschetz recognized Ádem's mathematical talent, and sent him as a doctoral student to [[Princeton University]] where he graduated in 1952.&lt;ref name=matmor&gt;{{web cite|url=http://www.matmor.unam.mx/~muciray/smm/60/adem.html|title=Biography of José Ádem|author=[[Alejandro Adem|Alejandro Ádem Díaz de León]]|language=Spanish| access-date=2018-04-01}}&lt;/ref&gt; His dissertation, ''Iterations of the squaring operations in algebraic topology'', was written under the supervision of [[Norman Steenrod]] and introduced what are now called the Ádem relations.&lt;ref&gt;{{MathGenealogy|id=8585}}&lt;/ref&gt;

His brother [[Julián Adem]] was also a distinguished Mexican mathematician, who obtained a Ph.D. in applied mathematics from [[Brown University]] in 1953.&lt;ref&gt;{{Mathgenealogy|name=Julián Adem|id=14309}}&lt;/ref&gt; Julián's son is topologist [[Alejandro Adem]].&lt;ref&gt;{{cite web|url=https://anthonybonato.com/2017/02/15/interview-with-a-mathematician-alejandro-adem/|title=Interview with a Mathematician: Alejandro Adem|accessdate=10 July 2018}}&lt;/ref&gt;

==Career==
Ádem became a researcher at the Mathematics Institute of UNAM (1954–1961), and then head of the Mathematics Department at the  [[Instituto Politécnico Nacional]] (1961–1973).&lt;ref&gt;{{cite web|url=https://www.encyclopedia.com/humanities/encyclopedias-almanacs-transcripts-and-maps/adem-chahin-jose-1921-1991|title=Adem Chahín, José (1921-1991)|accessdate=10 July 2018}}&lt;/ref&gt;
He was elected to [[Colegio Nacional (Mexico)|El Colegio Nacional]] on 4 April 1960.&lt;ref name="bio" /&gt;

In 1951 he was awarded a [[Guggenheim Fellowship]].&lt;ref&gt;{{cite web|url=https://www.gf.org/fellows/all-fellows/jose-adem/|title=Guggenheim Fellowship for José Ádem|access-date=2018-04-01}}&lt;/ref&gt;  He started in 1956 the second series of the Boletín de la Sociedad Matemática Mexicana.&lt;ref name=matmor /&gt;

==Publications==
* {{cite journal|last=Ádem|first=José|title=The iteration of the Steenrod squares in algebraic topology|journal=[[Proceedings of the National Academy of Sciences of the United States of America]]|volume= 38|year=1952|pages=720–726|mr=0050278|doi=10.1073/pnas.38.8.720|pmc=1063640}}
* {{cite journal|last=Ádem|first=José|title=Relations on iterated reduced powers|journal=[[Proceedings of the National Academy of Sciences of the United States of America]]|volume= 39|year=1953|pages=636–638|mr=0056293}}

==References==
{{reflist}}

==External links==
* {{cite book|title=Symposium on Algebraic Topology in honor of José Adem. Papers from the Symposium held in Oaxtepec, August 10–17, 1981|editor-first= Samuel|editor-last= Gitler|editor-link=Samuel Gitler Hammer|series= Contemporary Mathematics|volume= 12| publisher=[[American Mathematical Society]]|location= Providence, R.I.|year= 1982|isbn=0-8218-5010-5|mr=0676309}}

{{Authority control}}

{{DEFAULTSORT:Adem, Jose}}
[[Category:1921 births]]
[[Category:1991 deaths]]
[[Category:Place of death missing]]
[[Category:People from Veracruz]]
[[Category:20th-century Mexican mathematicians]]
[[Category:Topologists]]
[[Category:National Autonomous University of Mexico alumni]]
[[Category:Princeton University alumni]]
[[Category:National Autonomous University of Mexico faculty]]
[[Category:Instituto Politécnico Nacional faculty]]
[[Category:Members of El Colegio Nacional]]


{{Mexico-scientist-stub}}
{{mathematician-stub}}</text>
      <sha1>slpsokw6p4vahvtix2x7g0oo4hya3od</sha1>
    </revision>
  </page>
  <page>
    <title>Journal of Logic and Computation</title>
    <ns>0</ns>
    <id>27311945</id>
    <revision>
      <id>726780275</id>
      <parentid>605235146</parentid>
      <timestamp>2016-06-24T09:51:00Z</timestamp>
      <contributor>
        <ip>82.145.37.203</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1195">{{Infobox journal
| title = Journal of Logic and Computation
| cover = 
| editor = [[Dov Gabbay]]
| discipline = [[Computer science]]
| abbreviation = 
| publisher = [[Oxford University Press]]
| country =
| frequency = Bimonthly
| history = 1990–present
| openaccess = 
| license =
| impact = 
| impact-year =
| website = http://logcom.oxfordjournals.org/
| link1 = 
| link1-name =
| link2 = 
| link2-name =
| JSTOR = 
| OCLC =
| LCCN = 
| CODEN =
| ISSN = 0955-792X
| eISSN = 1465-363X
}}
The '''''Journal of Logic and Computation''''' is a [[Peer review|peer-reviewed]] [[academic journal]] focused on [[logic]] and [[computing]]. It was established in 1990 and is published by [[Oxford University Press]] under licence from Professor [[Dov Gabbay]] as owner of the journal.

== External links ==
* {{Official|http://logcom.oxfordjournals.org/}}

[[Category:Publications established in 1990]]
[[Category:Computer science journals]]
[[Category:Logic journals]]
[[Category:Logic in computer science]]
[[Category:Formal methods publications]]
[[Category:Oxford University Press academic journals]]
[[Category:Bimonthly journals]]
[[Category:English-language journals]]


{{compu-journal-stub}}</text>
      <sha1>t455m4ugln9wryldayyeh5doz7ixpi0</sha1>
    </revision>
  </page>
  <page>
    <title>Kostant partition function</title>
    <ns>0</ns>
    <id>23994987</id>
    <revision>
      <id>842551147</id>
      <parentid>840757771</parentid>
      <timestamp>2018-05-23T05:11:32Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add pmc identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6763">In [[representation theory]], a branch of mathematics, the '''Kostant partition function''', introduced by {{harvs|txt|authorlink=Bertram Kostant|first=Bertram |last=Kostant|year1=1958|year2=1959}}, of a [[root system]] &lt;math&gt;\Delta&lt;/math&gt; is the number of ways one can represent a vector ([[Weight (representation theory)|weight]]) as a non-negative integer linear combination of the [[positive root]]s &lt;math&gt;\Delta^+\subset\Delta&lt;/math&gt;.  Kostant used it to rewrite the [[Weyl character formula]] as a formula (the '''Kostant multiplicity formula''') for the [[multiplicity (mathematics)|multiplicity]] of a weight of an [[irreducible representation]] of a [[semisimple Lie algebra]]. An alternative formula, that is more computationally efficient in some cases, is [[Weyl_character_formula#Freudenthal.27s_formula|Freudenthal's forumula]].

The Kostant partition function can also be defined for [[Kac–Moody algebra]]s and has similar properties.

==An example==
[[File:Kostant_partition_function_for_A2.png|thumb|right|The Kostant partition function for the A2 root system]]
Consider the A2 root systems, with positive roots &lt;math&gt;\alpha_1&lt;/math&gt;, &lt;math&gt;\alpha_2&lt;/math&gt;, and &lt;math&gt;\alpha_3:=\alpha_1+\alpha_2&lt;/math&gt;. If an element &lt;math&gt;\mu&lt;/math&gt; can be expressed as a non-negative integer linear combination of &lt;math&gt;\alpha_1&lt;/math&gt;, &lt;math&gt;\alpha_2&lt;/math&gt;, and &lt;math&gt;\alpha_3&lt;/math&gt;, then since &lt;math&gt;\alpha_3=\alpha_1+\alpha_2&lt;/math&gt;, it can also be expressed as a non-negative integer linear combination of &lt;math&gt;\alpha_1&lt;/math&gt; and &lt;math&gt;\alpha_2&lt;/math&gt;:
:&lt;math&gt;\mu=n_1\alpha_1+n_2\alpha_2&lt;/math&gt; 
with &lt;math&gt;n_1&lt;/math&gt; and &lt;math&gt;n_2&lt;/math&gt; being non-negative integers. This expression gives ''one'' way to write &lt;math&gt;\mu&lt;/math&gt; as a non-negative integer combination of positive roots; other expressions can be obtained by replacing &lt;math&gt;\alpha_1+\alpha_2&lt;/math&gt; with &lt;math&gt;\alpha_3&lt;/math&gt; some number of times. We can do the replacement &lt;math&gt;k&lt;/math&gt; times, where &lt;math&gt;0\leq k\leq\mathrm{min}(n_1,n_2)&lt;/math&gt;. Thus, if the Kostant partition function is denoted by &lt;math&gt;p&lt;/math&gt;, we obtain the formula
:&lt;math&gt;p(n_1\alpha_1+n_2\alpha_2)=1+\mathrm{min}(n_1,n_2)&lt;/math&gt;.
This result is shown graphically in the image at right. If an element &lt;math&gt;\mu&lt;/math&gt; is not of the form &lt;math&gt;\mu=n_1\alpha_1+n_2\alpha_2&lt;/math&gt;, then &lt;math&gt;p(\mu)=0&lt;/math&gt;.

==Relation to the Weyl character formula==
===Inverting the Weyl denominator===
For each root &lt;math&gt;\alpha&lt;/math&gt; and each &lt;math&gt;H\in\mathfrak{h}&lt;/math&gt;, we can ''formally'' apply the formula for the sum of a geometric series to obtain
:&lt;math&gt;\frac{1}{1-e^{-\alpha(H)}}=1+e^{-\alpha(H)}+e^{-2\alpha(H)}+\cdots&lt;/math&gt;
where we do not worry about convergence—that is, the equality is understood at the level of formal power series. Using [[Weyl_character_formula#Weyl_denominator_formula|Weyl's denominator formula]]

:&lt;math&gt;{\sum_{w\in W} (-1)^{\ell(w)}e^{w\cdot\rho(H)} = e^{\rho(H)}\prod_{\alpha&gt;0}(1-e^{-\alpha(H)})},&lt;/math&gt;
we obtain a formal expression for the reciprocal of the Weyl denominator:&lt;ref&gt;{{harvnb|Hall|2015}} Proposition 10.27&lt;/ref&gt;

:&lt;math&gt;\begin{align}
\frac{1}{\sum_{w\in W} (-1)^{\ell(w)}e^{w\cdot\rho(H)}}&amp;{}=e^{-\rho(H)}\prod_{\alpha&gt;0}(1+e^{-\alpha(H)}+e^{-2\alpha(H)}+e^{-3\alpha(H)}+\cdots) \\
&amp;{}=e^{-\rho(H)}\sum_{\mu}p(\mu)e^{-\mu(H)}
\end{align}
&lt;/math&gt;
Here, the first equality is by taking a product over the positive roots of the geometric series formula and the second equality is by counting all the ways a given exponential &lt;math&gt;e^{\mu(H)}&lt;/math&gt; can occur in the product.

===Rewriting the character formula===
This argument shows that we can convert the [[Weyl character formula]] for the irreducible representation with highest weight &lt;math&gt;\lambda&lt;/math&gt;:

:&lt;math&gt;\operatorname{ch}(V)={\sum_{w\in W} (-1)^{\ell(w)}e^{w\cdot(\lambda+\rho)(H)} \over \sum_{w\in W} (-1)^{\ell(w)}e^{w\cdot\rho(H)}}&lt;/math&gt;

from a quotient to a product:

:&lt;math&gt;\operatorname{ch}(V)=\left(\sum_{w\in W} (-1)^{\ell(w)}e^{w\cdot(\lambda+\rho)(H)}\right) \left(e^{-\rho(H)}\sum_{\mu}p(\mu)e^{-\mu(H)}\right)  .&lt;/math&gt;

===The multiplicity formula===
Using the preceding rewriting of the character formula, it is relatively easy to write the character as a sum of exponentials. The coefficients of these exponentials are the multiplicities of the corresponding weights. We thus obtain a formula for the multiplicity of a given weight &lt;math&gt;\mu&lt;/math&gt; in the irreducible representation with highest weight &lt;math&gt;\lambda&lt;/math&gt;:&lt;ref&gt;{{harvnb|Hall|2015}} Theorem 10.29&lt;/ref&gt;
:&lt;math&gt;\mathrm{mult}(\mu)=\sum_{w\in W}(-1)^{\ell(w)}p(w\cdot(\lambda+\rho)-(\mu+\rho))&lt;/math&gt;.
This result is the '''Kostant multiplicity formula'''. 

The dominant term in this formula is the term &lt;math&gt;w=1&lt;/math&gt;; the contribution of this term is &lt;math&gt;p(\lambda-\mu)&lt;/math&gt;, which is just the multiplicity of &lt;math&gt;\mu&lt;/math&gt; in the [[Verma module]] with highest weight &lt;math&gt;\lambda&lt;/math&gt;. If &lt;math&gt;\lambda&lt;/math&gt; is sufficiently far inside the fundamental Weyl chamber and &lt;math&gt;\mu&lt;/math&gt; is sufficiently close to &lt;math&gt;\lambda&lt;/math&gt;, it may happen that all other terms in the formula are zero. Specifically, unless &lt;math&gt;w\cdot(\lambda+\rho)&lt;/math&gt; is higher than &lt;math&gt;\mu+\rho&lt;/math&gt;, the value of the Kostant partition function on &lt;math&gt;w\cdot(\lambda+\rho)-(\mu+\rho)&lt;/math&gt; will be zero. Thus, although the sum is nominally over the whole Weyl group, in most cases, the number of nonzero terms is smaller than the order of the Weyl group.

==References==
{{Reflist}}
==Sources==
{{refbegin}}
* {{Citation| last=Hall|first=Brian C.|title=Lie Groups, Lie Algebras, and Representations: An Elementary Introduction|edition=2nd|series=Graduate Texts in Mathematics|volume=222|publisher=Springer|year=2015|isbn= 978-3319134666}}
* Humphreys, J.E. Introduction to Lie algebras and representation theory, Springer, 1972.
*{{Citation | doi=10.1073/pnas.44.6.588 | last1=Kostant | first1=Bertram | title=A formula for the multiplicity of a weight | jstor=89667 | mr=0099387  | year=1958 | journal=[[Proceedings of the National Academy of Sciences|Proceedings of the National Academy of Sciences of the United States of America]] | issn=0027-8424 | volume=44 | pages=588–589 | issue=6 | publisher=National Academy of Sciences| pmc=528626 }}
*{{Citation | last1=Kostant | first1=Bertram | title=A formula for the multiplicity of a weight | jstor=1993422 | mr=0109192  | year=1959 | journal=[[Transactions of the American Mathematical Society]] | issn=0002-9947 | volume=93 | pages=53–73 | issue=1 | publisher=American Mathematical Society | doi=10.2307/1993422| pmc=528626 }}
{{refend}}

[[Category:Representation theory]]
[[Category:Representation theory of Lie algebras]]
[[Category:Types of functions]]</text>
      <sha1>gsxsklxir81mlvo88k14kbwa1cha1n0</sha1>
    </revision>
  </page>
  <page>
    <title>Link encryption</title>
    <ns>0</ns>
    <id>1065304</id>
    <revision>
      <id>843680942</id>
      <parentid>835129183</parentid>
      <timestamp>2018-05-30T18:51:53Z</timestamp>
      <contributor>
        <ip>161.69.112.11</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1388">{{unref|date=January 2016}}
'''Link encryption''' is an approach to [[communications security]] that [[encryption|encrypts]] and decrypts all traffic at each network routing point (e.g. network switch, or node through which it passes) until arrival at its final destination. This repeated decryption and encryption is necessary to allow the routing information contained in each transmission to be read and employed further to direct the transmission toward its destination, before which it is re-encrypted. This contrasts with '''[[end-to-end encryption]]''' where internal information, but not the header/routing information, are encrypted by the sender at the point of origin and only decrypted by the intended receiver.

Link encryption offers a couple of advantages:
* encryption is automatic so there is less opportunity for human error.
* if the communications link operates continuously and carries an unvarying level of traffic, link encryption defeats [[traffic analysis]].

On the other hand, end-to-end encryption ensures only the recipient sees the [[plaintext]].

Link encryption can be used with end-to-end systems by [[superencryption|superencrypting]] the messages.

'''Bulk encryption''' refers to encrypting a large number of circuits at once, after they have been [[multiplexing|multiplexed]].

==References==
&lt;references /&gt;

[[Category:Cryptography]]

{{crypto-stub}}</text>
      <sha1>rbaen329yj12iqcdt422th48oatmodp</sha1>
    </revision>
  </page>
  <page>
    <title>Matiyasevich's theorem</title>
    <ns>0</ns>
    <id>101853</id>
    <redirect title="Diophantine set" />
    <revision>
      <id>783891903</id>
      <parentid>457013328</parentid>
      <timestamp>2017-06-05T08:39:24Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{Redirect category shell}} using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="167">#REDIRECT [[Diophantine set#Matiyasevich's theorem]]

{{Redirect category shell|1=
{{R to section}}
{{R with possibilities}}
}}

[[Category:Theorems in number theory]]</text>
      <sha1>m5mu2wam3f5a656tgva6tm8b887hmgc</sha1>
    </revision>
  </page>
  <page>
    <title>Movable singularity</title>
    <ns>0</ns>
    <id>7664719</id>
    <revision>
      <id>786596586</id>
      <parentid>717962227</parentid>
      <timestamp>2017-06-20T12:17:50Z</timestamp>
      <contributor>
        <username>CBM</username>
        <id>1108292</id>
      </contributor>
      <minor/>
      <comment>Manually reviewed edit to replace magic words per [[Special:PermanentLink/772743896#Future_of_magic_links|local rfc]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2582">{{no footnotes|date=January 2011}}
[[File:MovingSingularity.png|right|thumb|390px|Solutions to the differential equation &lt;math&gt;\frac{dy}{dx} = \frac{1}{2y}&lt;/math&gt; subject to the initial conditions y(0)=0, 1 and 2 (red, green and blue curves respectively). The positions of the moving singularity at x= 0, -1 and -4 is indicated by the vertical lines.]]

In the theory of [[ordinary differential equation]]s, a '''movable singularity''' is a point where the solution of the equation [[Singularity (mathematics)|behaves badly]] and which is "movable" in the sense that its location depends on the [[initial conditions]] of the differential equation.&lt;ref name=BenderOrszag7&gt;

{{Cite book  | last = Bender  | first = Carl M.  | authorlink =   |author2=Orszag, Steven A.  | title = Advanced Mathematical Methods for Scientists and Engineers: Asymptotic Methods and Perturbation Series  | publisher = Springer  | date = 1999  | location =   | pages = 7 }}&lt;/ref&gt;
Suppose we have an [[ordinary differential equation]] in the complex domain.  Any given solution ''y''(''x'') of this equation may well have singularities at various points (i.e. points at which it is not a regular [[holomorphic function]], such as [[branch points]], [[Essential singularity|essential singularities]] or [[Pole (complex analysis)|poles]]).  A singular point is said to be '''movable''' if its location depends on the particular solution we have chosen, rather than being fixed by the equation itself.

For example the equation

:&lt;math&gt; \frac{dy}{dx} = \frac{1}{2y}&lt;/math&gt;

has solution &lt;math&gt;y=\sqrt{x-c}&lt;/math&gt; for any constant ''c''. This solution has a branchpoint at &lt;math&gt;x=c&lt;/math&gt;, and so the equation has a movable branchpoint (since it depends on the choice of the solution, i.e. the choice of the constant ''c'').

It is a basic feature of linear ordinary differential equations that singularities of solutions occur only at singularities of the equation, and so linear equations do not have movable singularities.

When attempting to look for 'good' nonlinear differential equations it is this property of linear equations that one would like to see: asking for no movable singularities is often too stringent, instead one often asks for the so-called [[Painlevé transcendents|Painlevé property]]: 'any movable singularity should be a pole', first used by [[Sofia Kovalevskaya]].

== References ==
{{reflist}}
* Einar Hille (1997), ''Ordinary Differential Equations in the Complex Domain'', Dover. {{isbn|0-486-69620-0}}

[[Category:Complex analysis]]
[[Category:Ordinary differential equations]]</text>
      <sha1>aiay2wi5peqj0kd68fgc6h2j33oo0c7</sha1>
    </revision>
  </page>
  <page>
    <title>Newton polygon</title>
    <ns>0</ns>
    <id>742477</id>
    <revision>
      <id>862710006</id>
      <parentid>852416188</parentid>
      <timestamp>2018-10-06T05:25:23Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6783">{{refimprove|date=March 2008}}
[[Image:Newton-polygon.gif|thumb|right|Construction of the Newton polygon of the polynomial P(X) = 1 + 5 X + 1/5 X^2 + 35 X^3 + 25 X^5 + 625 X^6 with respect to the 5-adic valuation.]]
In [[mathematics]], the '''Newton polygon''' is a tool for understanding the behaviour of [[polynomial]]s over [[local field]]s.

In the original case, the local field of interest was the field of [[formal Laurent series]] in the indeterminate ''X'', i.e. the [[field of fractions]] of the [[formal power series]] ring

:''K''&lt;nowiki&gt;[[X]]&lt;/nowiki&gt;,

over ''K'', where ''K'' was the [[real number]] or [[complex number]] field. This is still of considerable utility with respect to [[Puiseux expansion]]s. The Newton polygon is an effective device for understanding the leading terms

:''aX''&lt;sup&gt;''r''&lt;/sup&gt;

of the power series expansion solutions to equations

:''P''(''F''(''X'')) = 0

where ''P'' is a polynomial with coefficients in ''K''[''X''], the [[polynomial ring]]; that is, [[implicit function|implicitly defined]] [[algebraic function]]s. The exponents ''r'' here are certain [[rational number]]s, depending on the [[branch of a function|branch]] chosen; and the solutions themselves are power series in

:''K''&lt;nowiki&gt;[[Y]]&lt;/nowiki&gt;

with ''Y'' = ''X''&lt;sup&gt;1/''d''&lt;/sup&gt; for a denominator ''d'' corresponding to the branch. The Newton polygon gives an effective, algorithmic approach to calculating ''d''.

After the introduction of the [[p-adic number]]s, it was shown that the Newton polygon is just as useful in questions of [[Ramification (mathematics)|ramification]] for local fields, and hence in [[algebraic number theory]].  Newton polygons have also been useful in the study of [[elliptic curve]]s.

==Definition==
A priori, given a polynomial over a field, the behaviour of the roots (assuming it has roots) will be unknown. Newton polygons provide one technique for the study of the behaviour of the roots.

Let &lt;math&gt;K&lt;/math&gt; be a [[local field]] with [[discrete valuation]] &lt;math&gt;v_K&lt;/math&gt; and let

:&lt;math&gt;f(x) = a_nx^n + \cdots + a_1x + a_0 \in K[x]&lt;/math&gt;

with &lt;math&gt;a_0 a_n \ne 0&lt;/math&gt;.  Then the Newton polygon of &lt;math&gt;f&lt;/math&gt; is defined to be the lower [[convex hull]] of the set of points

:&lt;math&gt;P_i=\left(i,v_K(a_i)\right),&lt;/math&gt;

ignoring the points with &lt;math&gt;a_i = 0&lt;/math&gt;.
Restated geometrically, plot all of these points ''P''&lt;sub&gt;''i''&lt;/sub&gt; on the ''xy''-plane. Let's assume that the points indices increase from left to right (''P''&lt;sub&gt;''0''&lt;/sub&gt; is the leftmost point, ''P''&lt;sub&gt;''n''&lt;/sub&gt; is the rightmost point). Then, starting at ''P''&lt;sub&gt;0&lt;/sub&gt;, draw a [[ray (geometry)|ray]] straight down parallel with the ''y''-axis, and rotate this ray counter-clockwise until it hits the point ''P''&lt;sub&gt;k&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt; (not necessarily ''P''&lt;sub&gt;1&lt;/sub&gt;). Break the ray here. Now draw a second ray from ''P''&lt;sub&gt;k&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt; straight down parallel with the ''y''-axis, and rotate this ray counter-clockwise until it hits the point ''P''&lt;sub&gt;k&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt;. Continue until the process reaches the point ''P''&lt;sub&gt;''n''&lt;/sub&gt;;  the resulting polygon (containing the points ''P''&lt;sub&gt;0&lt;/sub&gt;, ''P''&lt;sub&gt;k&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt;, ''P''&lt;sub&gt;k&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt;, ..., ''P''&lt;sub&gt;k&lt;sub&gt;m&lt;/sub&gt;&lt;/sub&gt;, ''P''&lt;sub&gt;''n''&lt;/sub&gt;) is the Newton polygon.

Another, perhaps more intuitive way to view this process is this : consider a rubber band surrounding all the points ''P''&lt;sub&gt;0&lt;/sub&gt;, ..., ''P''&lt;sub&gt;n&lt;/sub&gt;. Stretch the band upwards, such that the band is stuck on its lower side by some of the points (the points act like nails, partially hammered into the xy plane). The vertices of the Newton polygon are exactly those points.

For a neat diagram of this see Ch6 §3 of "Local Fields" by JWS Cassels, LMS Student Texts 3, CUP 1986. It is on p99 of the 1986 paperback edition.

== History==
Newton polygons are named after [[Isaac Newton]], who first described them and some of their uses in correspondence from the year 1676 addressed to [[Henry Oldenburg]].&lt;ref&gt;[[Egbert Brieskorn]], [[Horst Knörrer]] (1986). ''Plane Algebraic Curves'', pp. 370–383.&lt;/ref&gt;

== Applications ==
A Newton Polygon is sometimes a special case of a {{Interlanguage link multi|Newton Polytope|ru|3=Многогранник Ньютона}}, and can be used to construct asymptotic solutions of two-variable polynomial equations like 
&lt;math&gt;  3 x^2 y^3 - x y^2 + 2 x^2 y^2 - x^3 y = 0 &lt;/math&gt;

 [[File:Diagram_of_a_Newton_Polygon_Convex_hull.svg|thumb|right| This diagram shows the Newton polygon for  P(x,y) = 3 x^2 y^3 - x y^2 + 2 x^2 y^2 - x^3 y, with positive monomials in red and negative monomials in cyan. Faces are labelled with the limiting terms they correspond to.
]]

Another application of the Newton polygon comes from the following result:

Let

:&lt;math&gt;\mu_1, \mu_2, \ldots, \mu_r&lt;/math&gt;

be the slopes of the line segments of the Newton polygon of &lt;math&gt;f(x)&lt;/math&gt; (as defined above) arranged in increasing order, and let

:&lt;math&gt;\lambda_1, \lambda_2, \ldots, \lambda_r&lt;/math&gt;

be the corresponding lengths of the [[line segment]]s projected onto the x-axis (i.e. if we have a line segment stretching between the points &lt;math&gt;P_i&lt;/math&gt; and &lt;math&gt;P_j&lt;/math&gt; then the length is &lt;math&gt;j-i&lt;/math&gt;). Then for each [[integer]] &lt;math&gt;1\leq\kappa\leq r&lt;/math&gt;, &lt;math&gt;f(x)&lt;/math&gt; has exactly &lt;math&gt;\lambda_{\kappa}&lt;/math&gt; roots with valuation &lt;math&gt;-\mu_{\kappa}&lt;/math&gt;.

==Symmetric function explanation==
In the context of a valuation, we are given certain information in the form of the valuations of [[elementary symmetric function]]s of the roots of a polynomial, and require information on the valuations of the actual roots, in an [[algebraic closure]]. This has aspects both of [[ramification theory]] and [[singularity theory]]. The valid inferences possible are to the valuations of [[Power sum symmetric polynomial|power sums]], by means of [[Newton's identities]].

==See also==

*[[F-crystal]]
*[[Eisenstein's criterion]]
*[[Newton–Okounkov body]]

==References==
{{reflist}}
* {{Citation | last=Goss | first=David | title=Basic structures of function field arithmetic | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Ergebnisse der Mathematik und ihrer Grenzgebiete (3) [Results in Mathematics and Related Areas (3)] | isbn=978-3-540-61087-8 |mr=1423131 | year=1996 | volume=35 | doi=10.1007/978-3-642-61480-4}}
* [[Fernando Q. Gouvêa|Gouvêa, Fernando]]: p-adic numbers: An introduction. Springer Verlag 1993. p.&amp;nbsp;199.

== External links ==
{{Commons category|Newton polygon}}
* [http://www.math.sc.edu/~filaseta/newton/newton.html Applet drawing a Newton Polygon]

{{Isaac Newton}}

[[Category:Algebraic number theory]]
[[Category:Symmetric functions]]
[[Category:Isaac Newton]]</text>
      <sha1>hb44yyzf3h0t3t1h7f9viacm76i7qsp</sha1>
    </revision>
  </page>
  <page>
    <title>Non-Archimedean geometry</title>
    <ns>0</ns>
    <id>35093912</id>
    <revision>
      <id>698298263</id>
      <parentid>674543111</parentid>
      <timestamp>2016-01-05T06:21:08Z</timestamp>
      <contributor>
        <username>EmausBot</username>
        <id>11292982</id>
      </contributor>
      <minor/>
      <comment>Bot: Migrating 1 interwiki links, now provided by [[Wikipedia:Wikidata|Wikidata]] on [[d:Q4315479]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2423">In [[mathematics]], '''non-Archimedean geometry'''&lt;ref&gt;[[Robin Hartshorne]], ''Geometry: Euclid and beyond'' (2000), p. 158.&lt;/ref&gt; is any of a number of forms of [[geometry]] in which the [[axiom of Archimedes]] is negated. An example of such a geometry is the [[Dehn plane]]. Non-Archimedean geometries may, as the example indicates, have properties significantly different from [[Euclidean geometry]].

There are two senses in which the term may be used, referring to geometries over [[field (algebra)|field]]s which violate one of the two senses of the [[Archimedean property]] (i.e. with respect to order or magnitude).

== Geometry over a non-Archimedean ordered field ==

The first sense of the term is the geometry over a [[non-Archimedean ordered field]], or a subset thereof. The aforementioned Dehn plane takes the self-product of the finite portion of a certain non-Archimedean ordered field based on the field of [[rational function]]s. In this geometry, there are significant differences from Euclidean geometry; in particular, there are infinitely many parallels to a straight line through a point—so the [[parallel postulate]] fails—but the sum of the angles of a triangle is still a straight angle.&lt;ref&gt;{{Citation | last1=Hilbert | first1=David | author1-link=David Hilbert | title=The foundations of geometry | year=1902 | publisher=The Open Court Publishing Co., La Salle, Ill. | mr=0116216 |url=http://www.gutenberg.org/files/17384/17384-pdf.pdf}}&lt;/ref&gt;

Intuitively, in such a space, the points on a line cannot be described by the real numbers or a subset thereof, and there exist segments of "infinite" or "infinitesimal" length.

== Geometry over a non-Archimedean valued field ==

The second sense of the term is the metric geometry over a non-Archimedean [[absolute value (algebra)|valued field]],&lt;ref&gt;Conrad, B. "Several approaches to non-archimedean geometry. In p-adic Geometry (Lectures from the 2007 Arizona Winter School). AMS University Lecture Series." ''Amer. Math. Soc., Providence, RI'' 41 (2008): 78.&lt;/ref&gt; or [[ultrametric space]]. In such a space, even more contradictions to Euclidean geometry result. For example, all triangles are isosceles, and overlapping [[ball (mathematics)|balls]] nest. An example of such a space is the [[p-adic numbers]].

Intuitively, in such a space, distances fail to "add up" or "accumulate".

== References ==
&lt;references /&gt;

[[Category:Geometry]]</text>
      <sha1>mgmrknxuf15kkrisb2l768dy9kkyt8w</sha1>
    </revision>
  </page>
  <page>
    <title>Nonmetricity tensor</title>
    <ns>0</ns>
    <id>1519351</id>
    <revision>
      <id>746112992</id>
      <parentid>607121513</parentid>
      <timestamp>2016-10-25T09:35:04Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="708">In [[mathematics]], the '''nonmetricity tensor''' in [[differential geometry]] is the [[covariant derivative]] of the [[metric tensor]].&lt;ref&gt;{{citation
 | last1 = Kopeikin | first1 = Sergei
 | last2 = Efroimsky | first2 = Michael
 | last3 = Kaplan | first3 = George
 | isbn = 9783527408566
 | page = 242
 | publisher = John Wiley &amp; Sons
 | title = Relativistic Celestial Mechanics of the Solar System
 | url = https://books.google.com/books?id=RfR2GawB-xcC&amp;pg=PA242
 | year = 2011}}.&lt;/ref&gt; It is therefore a [[tensor field]] of [[Tensor order|order]] three. It vanishes for the case of [[Riemannian geometry]].

==References==
{{reflist}}


{{Tensors}}

[[Category:Differential geometry]]


{{Geometry-stub}}</text>
      <sha1>gchpv0bmxl8hznzxmh8xjijmc85ddbh</sha1>
    </revision>
  </page>
  <page>
    <title>Octagonal number</title>
    <ns>0</ns>
    <id>538132</id>
    <revision>
      <id>747072035</id>
      <parentid>683488347</parentid>
      <timestamp>2016-10-31T08:04:41Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1846">{{refimprove|date=October 2013}}
An '''octagonal number''' is a [[figurate number]] that represents an [[octagon]]. The octagonal number for ''n'' is given by the formula 3''n''&lt;sup&gt;2&lt;/sup&gt; - 2''n'', with ''n'' &gt; 0. The first few octagonal numbers are:

[[1 (number)|1]], [[8 (number)|8]], [[21 (number)|21]], [[40 (number)|40]], [[65 (number)|65]], [[96 (number)|96]], [[133 (number)|133]], [[176 (number)|176]], 225, [[280 (number)|280]], 341, 408, 481, 560, 645, 736, 833, 936 {{OEIS|id=A000567}}

Octagonal numbers can be formed by placing triangular numbers on the four sides of a square. To put it algebraically, the ''n''-th octagonal number is

:&lt;math&gt;x_n=n^2 + 4\sum_{k = 1}^{n - 1} k = 3n^2-2n.&lt;/math&gt;

The octagonal number for ''n'' can also be calculated by adding the square of ''n'' to twice the (''n - 1'')th [[pronic number]].

Octagonal numbers consistently alternate [[parity (mathematics)|parity]].

Octagonal numbers are occasionally referred to as "[[star number]]s," though that term is more commonly used to refer to centered dodecagonal numbers.&lt;ref&gt;{{citation|title=Figurate Numbers|first1=Elena|last1=Deza|first2=Michel|last2=Deza|author2-link=Michel Deza|publisher=World Scientific|year=2012|isbn=9789814355483|page=57|url=https://books.google.com/books?id=cDxYdstLPz4C&amp;pg=PA57}}.&lt;/ref&gt;

==Test for octagonal numbers==

Solving the formula for the ''n''-th octagonal number, &lt;math&gt;x_n,&lt;/math&gt; for ''n'' gives
:&lt;math&gt;n= \frac{\sqrt{3x_n+1}+1}{3}.&lt;/math&gt;
An arbitrary number ''x'' can be checked for octagonality by putting it in this equation. If ''n'' is an integer, then ''x'' is the ''n''-th octagonal number. If ''n'' is not an integer, then ''x'' is not octagonal.

==See also==
* [[Centered octagonal number]]

==References==
{{reflist}}

{{Classes of natural numbers}}
[[Category:Figurate numbers]]


{{num-stub}}</text>
      <sha1>fhfgtpbsxkuvazpmq7t7h07duvn0ts0</sha1>
    </revision>
  </page>
  <page>
    <title>Octic equation</title>
    <ns>0</ns>
    <id>35870410</id>
    <revision>
      <id>852356099</id>
      <parentid>824193417</parentid>
      <timestamp>2018-07-28T11:43:09Z</timestamp>
      <contributor>
        <ip>59.13.59.57</ip>
      </contributor>
      <comment>/* Solvable octics */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3634">{{Confuse|Optic equation}}

[[Image:Polynomial degree 8.png|thumb|right|Graph of a polynomial of degree 8, with 8 [[real number|real]] [[root of a polynomial|roots]] (crossings of the {{math|''x''}} axis) and with 7 [[critical point (mathematics)|critical points]]. In general, depending on the number and vertical location of the local [[minimum|maxima and minima]], the number of real roots could be 8, 6, 4, 2, or 0. The number of [[complex number|complex]] roots equals 8 minus the number of real roots.]]

In [[algebra]], an '''octic equation'''&lt;ref&gt;[[James Cockle]] proposed the names "sexic", "septic", "octic", "nonic", and "decic" in 1851. ([https://books.google.com/books?id=cxIFAAAAQAAJ&amp;pg=PP1#v=onepage&amp;q=sexic%20septic%20octic%20nonic%20decic&amp;f=false ''Mechanics Magazine'', Vol. LV, p. 171])&lt;/ref&gt; is an [[equation]] of the form

:&lt;math&gt;ax^8+bx^7+cx^6+dx^5+ex^4+fx^3+gx^2+hx+k=0,\,&lt;/math&gt;

where {{math|''a'' ≠ 0}}.

An '''octic function''' is a [[Function (mathematics)|function]] of the form

:&lt;math&gt;f(x)=ax^8+bx^7+cx^6+dx^5+ex^4+fx^3+gx^2+hx+k,&lt;/math&gt;

where {{math|''a'' ≠ 0}}. In other words, it is a [[polynomial]] of [[Degree of a polynomial|degree]] eight. If {{math|1=''a'' = 0}}, then ''f'' is a [[septic function]] ({{math|''b'' ≠ 0}}), [[sextic function]] ({{math|1=''b'' = 0, ''c ''≠ 0}}), etc.

The equation may be obtained from the function by setting {{math|1=''f''(''x'') = 0}}.

The ''coefficients'' {{math|''a'', ''b'', ''c'', ''d'', ''e'', ''f'', ''g'', ''h'', ''k''}} may be either [[integers]], [[rational number]]s, [[real number]]s, [[complex number]]s or, more generally, members of any [[field (mathematics)|field]].

Since an octic function is defined by a polynomial with an even degree, it has the same infinite limit when the argument goes to positive or negative [[infinity]]. If the [[leading coefficient]] {{math|''a''}} is positive, then the function increases to positive infinity at both sides; and thus the function has a global minimum. Likewise, if {{math|''a''}} is negative, the octic function decreases to negative infinity and has a global maximum. The [[derivative]] of an octic function is a [[septic function]].

== Solvable octics ==

By the [[Abel–Ruffini theorem]], there is no general [[algebraic formula]] for a solution of an octic equation in terms of its parameters. However, some sub-classes of octics do have such formulas.

Trivially, octics of the form

:&lt;math&gt;x^8=a&lt;/math&gt;

with positive ''a'' have the solutions 

:&lt;math&gt;x_k=a^{1/8}\omega_k\, , \quad k=1, \dots , 8,&lt;/math&gt;

where &lt;math&gt;\omega_k&lt;/math&gt; is the ''k''-th [[roots of unity|eighth root of 1]] in the [[complex plane]].

Octics of the form 
:&lt;math&gt;ax^8+ex^4+k=0&lt;/math&gt;
can be solved through factorisation or application of the [[quadratic formula]] in the variable {{math|''x''&lt;sup&gt;4&lt;/sup&gt;}}. 

Octics of the form
:&lt;math&gt;ax^8 +cx^6+ex^4+gx^2+k=0&lt;/math&gt;

can be solved using the [[quartic equation|quartic formula]] in the variable {{math|''x''&lt;sup&gt;2&lt;/sup&gt;}}.

==Application==

In some cases some of the quadrisections (partitions into four regions of equal area) of a [[triangle]] by [[perpendicular lines]] are solutions of an octic equation.&lt;ref&gt;http://forumgeom.fau.edu/FG2018volume18/FG201802.pdf Carl Eberhart, “Revisiting the quadrisection problem of Jacob Bernoulli”, ''Forum Geometricorum'' 18, 2018, pp. 7–16 (particularly pp. 14–15).&lt;/ref&gt;

==See also==
*[[Cubic function]]
*[[Quartic function]]
*[[Quintic function]]

==References==
&lt;references/&gt;

{{Polynomials}}

{{DEFAULTSORT:Octic Equation}}
[[Category:Equations]]
[[Category:Galois theory]]
[[Category:Polynomials]]</text>
      <sha1>1fxotd6e0ko4rpa9v3mlzp3ttld3782</sha1>
    </revision>
  </page>
  <page>
    <title>Paul Balmer</title>
    <ns>0</ns>
    <id>47548749</id>
    <revision>
      <id>854132382</id>
      <parentid>852884183</parentid>
      <timestamp>2018-08-09T05:16:18Z</timestamp>
      <contributor>
        <username>Soleswort</username>
        <id>34273364</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3270">{{Infobox scientist
| honorific_prefix =
| name        = Paul Balmer
| honorific_suffix =
| native_name = 
| native_name_lang = 
| image       = 
| image_size  = 
| alt         = 
| caption     = 
| birth_date  = {{Birth year and age|1970}}
| birth_place = 
| death_date  =         &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place = 
| death_cause = 
| resting_place = 
| resting_place_coordinates =  &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names = 
| residence   = 
| citizenship = 
| nationality = Swiss
| fields      = [[Algebra]]
| workplaces  = [[UCLA]]
| patrons     = 
| education   = 
| alma_mater  = [[University of Lausanne]]
| thesis_title = Groupes de Witt d&amp;eacute;riv&amp;eacute;s des sch&amp;eacute;mas
| thesis_url  =         &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year = 1998
| doctoral_advisor = [[Manuel Ojanguren]]
| academic_advisors = 
| doctoral_students = 
| notable_students = 
| known_for   = 
| influences  = 
| influenced  = 
| awards      = [[Humboldt Prize]]
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse      =         &lt;!--(or | spouses = )--&gt;
| partner     =         &lt;!--(or | partners = )--&gt;
| children    = 
| signature   =         &lt;!--(filename only)--&gt;
| signature_alt = 
| website     = {{URL|www.math.ucla.edu/~balmer}}
| footnotes   = 
}}
'''Paul Balmer''' (born 1970) is a Swiss mathematician, working in algebra. He is a professor of mathematics at [[UCLA]].&lt;ref&gt;http://www.math.ucla.edu/~balmer/&lt;/ref&gt;

Balmer received his Ph.D. from the [[University of Lausanne]] in 1998, under the supervision of [[Manuel Ojanguren]], with a thesis entitled ''Groupes de Witt d&amp;eacute;riv&amp;eacute;s des Sch&amp;eacute;mas'' (in French).&lt;ref&gt;{{MathGenealogy|id=44976|title=Paul Balmer}}&lt;/ref&gt;

His research centers around [[triangulated categories]]. More specifically, he is a proponent of tensor-triangular geometry, an umbrella topic which covers geometric aspects of [[algebraic geometry]], [[modular representation theory]], [[stable homotopy theory]], and other areas, by means of relevant tensor-triangulated categories.

Balmer was an Invited Speaker at the [[International Congress of Mathematicians]] in Hyderabad in 2010, with a talk on ''Tensor Triangular Geometry''.&lt;ref&gt;{{cite book|author=Balmer, P.|chapter=Tensor triangular geometry|title=Proceedings of International Congress of Mathematicians, Vol. II.|year=2010|pages=85–112|url=http://www.mathunion.org/ICM/ICM2010.2/Main/icm2010.2.0085.0112.pdf}}&lt;/ref&gt;
In 2012, he became a fellow of the [[American Mathematical Society]]&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society]&lt;/ref&gt;.
He was awarded a [[Humboldt Prize]] in 2015.&lt;ref&gt;https://www.humboldt-foundation.de/web/humboldt-award.html&lt;/ref&gt;

==References==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Balmer, Paul}}
[[Category:Living people]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Swiss mathematicians]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:University of Lausanne alumni]]
[[Category:University of California, Los Angeles faculty]]
[[Category:1970 births]]</text>
      <sha1>cy7dd010mf9yljrocy48wvjhebri00k</sha1>
    </revision>
  </page>
  <page>
    <title>Periodic matrix set</title>
    <ns>0</ns>
    <id>24497161</id>
    <revision>
      <id>653781950</id>
      <parentid>634155125</parentid>
      <timestamp>2015-03-27T18:05:38Z</timestamp>
      <contributor>
        <username>Myasuda</username>
        <id>1187538</id>
      </contributor>
      <minor/>
      <comment>/* Applied sets */ sp</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8784">{{notability|date=November 2014}}
{{Cleanup|date=October 2009}}

In [[mathematics]], a '''periodic matrix set''' is a set of [[Square matrix#Square matrices|square matrices]] in which each square [[matrix (mathematics)|matrix]] is of a different size, and such that each cell within each matrix within a set contains data associated with some type of periodic distribution.&lt;ref&gt;[[Periodic table#Periodicity of chemical properties]]&lt;/ref&gt; {{Citation needed|date=October 2009}}

==Construction of a set==
A [[Set (mathematics)|set]] may be specified to contain a fixed number of matrices and is identified by a set number (''S''&lt;sub&gt;''M''&lt;/sub&gt;), where ''S'' is the set identification number and ''M'' is the number of matrices included in the set. There is no limit to the number of matrices which may be members of a periodic set.

Each matrix within a set has an identification number (a) and must contain a "root cell". A root cell must be located at any corner of a matrix. All root cells must be located at the same corner of each matrix within a single set. A diagonal line drawn from a root cell to the opposite corner of the same matrix is a "root diagonal".

The periodicity is defined by "partial square rings" (rings) of cells adjoining a root cell on two sides. All cells within the same ring, (even if they are located in a different matrix) have a similar "period". If a matrix contains (n+1)&lt;sup&gt;2&lt;/sup&gt; cells then the outermost ring contains "2n+1" cells which are all included in the same period. A ring identification number (n) identifies each period. The root cell is also the smallest ring and is identified as; n = 0. Each subsequent ring (1, 2, 3, etc.) has 2n+1 cells (3, 5, 7, etc.).

Individual cells contained within a ring are identified by their [[Deviation (statistics)|deviation]] from the root diagonal. Each cell within a ring is assigned a deviation number (D). All cells intersected by the root diagonal have; D = 0. All cell locations in a column deviation have positive values of D. All cell locations in a row deviation have negative values of D.

Any cell within a set will require three numbers for the identification of its location;&lt;br /&gt;a is the matrix number&lt;br /&gt;n is the ring number&lt;br /&gt;D is the deviation number

The cell could also have its location identified as;&lt;br /&gt;a is the matrix number&lt;br /&gt;x is the column number (root cell = 0)&lt;br /&gt;y is the row number (root cell = 0)

The two locational systems are analogous to Radial (anD) and Cartesian (axy) systems. Generally this article will use the "anD" locational method.

The contents of any cell must contain data that is periodic in some manner.

==Combined Sets==
Combinations of sets are possible; however each set must be [[conformable]] for combination. A resultant set (R&lt;sub&gt;N M&lt;/sub&gt;) is the combination of N sets each having M matrices.

Two sets (of compatible construction) may combine so that the root cells on similar sized matrices are adjacent. This is a "set pair" and is identified by a "pair number" (P). The resultant matrices are not square but are 2n x n rectangular.

Four sets may also combine so that all root cells on similar sized matrices are adjacent. This gives a resultant set of square matrices having an even number of cells on each side. All root cells will form a central 2x2 "core" within each resultant matrix. The resultant set is actually two pairs. Each pair forms half of the resultant set. The identifiers (P,S) will tag each quadrant of the resultant set, which is all of the original sets. &lt;br /&gt;P = +½ represents the upper pair&lt;br /&gt;P = -½ represents the lower pair&lt;br /&gt;S = +½ represents the right set of each pair.&lt;br /&gt;S = -½ represents the left set of each pair.

Five identifiers are required to locate any cell in R&lt;sub&gt;4 M&lt;/sub&gt;;&lt;br /&gt;P is the pair number&lt;br /&gt;S is the set number&lt;br /&gt;a is the matrix number&lt;br /&gt;n is the ring number&lt;br /&gt;D is the deviation number

==Applied sets==
Periodic matrix sets have an application to chemistry (for example, in the [[periodic table]]) and particle physics (for example, with [[sub atomic particle]]s). The resultant set R&lt;sub&gt;4 4&lt;/sub&gt; is of special interest.

The periodic rings may be associated with quantum harmonic oscillation. A [[Quantum_harmonic_oscillator#Hamiltonian_and_energy_eigenstates|quantum harmonic oscillator]] has energy (E&lt;sub&gt;n&lt;/sub&gt;) defined as; E&lt;sub&gt;n&lt;/sub&gt; = (n + ½)ћω. Where; ћ = h/2π and h is Planck's constant, and ω is frequency. The number of cells in each period may be written as; 2E&lt;sub&gt;n&lt;/sub&gt;/ћω.

The rings may also be associated with [[atomic orbitals]]. If the ring number (n) is equal to the [[quantum number]] for orbital angular momentum (the azimuthal number '''''l''''' ), then the rings (0, 1, 2, 3) correspond to the orbitals (s, p, d, f). The ring number is NOT equal to the principal quantum number ('''''n''''' ). The number of cells per ring is half the number of electrons per orbital due to spin duality of the electrons.

The quantum numbers are; &lt;br /&gt;'''''n''''' is the principal quantum number&lt;br /&gt;'''''l''''' is the quantum number for orbital angular momentum (the azimuthal number)&lt;br /&gt;'''''ml''''' is the orbital magnetic moment&lt;br /&gt;'''''ms''''' is the spin magnetic moment

The spin quantum number ('''''s''''') is not normally used in chemistry applications as all electrons are; '''''s''''' = ½.
&lt;br /&gt;The atomic number ('''''Z''''') may be expressed as a function of energies which in turn are functions of the quantum numbers.

If a resultant set is R&lt;sub&gt;4 4&lt;/sub&gt; then the locational numbers correspond to the quantum numbers as follows.
&lt;br /&gt;S = '''''ms'''''
&lt;br /&gt;n = '''''l'''''
&lt;br /&gt;D = '''''ml'''''

The Madelung rule gives the "P" and "a" relationships. This rule may be generalized as follows; &lt;br /&gt;2a - P = '''''n''''' + '''''l''''' + '''''s'''''
&lt;br /&gt;(2'''''n''''' + 2'''''l''''' + 2'''''s''''' - 4a)&lt;sup&gt;2&lt;/sup&gt; = 1

This generalization may also be obtained from '''''J''''' coupling.

If; P = -½
&lt;br /&gt;Then; a = ½('''''n''''' + '''''l''''')

If; P = +½
&lt;br /&gt;Then; a = ½('''''n''''' + '''''l''''') + ½

The sub-atomic particles may be grouped as an R&lt;sub&gt;4 3&lt;/sub&gt; combination.

==Data compliance==
A set is considered to be "locationally compliant" if the data contained in each cell is also a function of the location of the cell. Let an R&lt;sub&gt;4 4&lt;/sub&gt; resultant set be populated with atomic numbers. Each cell contains one atomic number ('''''Z'''''). The number in each cell should be a function of the locators of the cell. If a term is associated with each locator then the atomic number will be the sum of all terms and a constant.

'''''Z''''' = '''''Z'''''&lt;sub&gt;P&lt;/sub&gt; + '''''Z'''''&lt;sub&gt;S&lt;/sub&gt; + '''''Z'''''&lt;sub&gt;a&lt;/sub&gt; + '''''Z'''''&lt;sub&gt;n&lt;/sub&gt; + '''''Z'''''&lt;sub&gt;D&lt;/sub&gt; - ½

The five locator terms are as follows.

'''''Z'''''&lt;sub&gt;P&lt;/sub&gt; = -2a&lt;sup&gt;2&lt;/sup&gt;(P+½)

'''''Z'''''&lt;sub&gt;S&lt;/sub&gt; = -2(n+½)(S+½)

'''''Z'''''&lt;sub&gt;a&lt;/sub&gt; = 4a(a+1)(a+½)/3

'''''Z'''''&lt;sub&gt;n&lt;/sub&gt; = -2n(n+½)

'''''Z'''''&lt;sub&gt;D&lt;/sub&gt; = (D+½)

This distribution of atomic numbers in R&lt;sub&gt;4 4&lt;/sub&gt; is a locationally compliant matrix set of the Periodic Table. The following tables show the resultant matrices populated with the atomic numbers.

'''R&lt;sub&gt;4 4&lt;/sub&gt; showing combined matrices 1 to 4 populated with atomic number (Z)'''

&lt;br /&gt;'''a = 1'''
{| class="wikitable"
|-
| 2
| 1
|-
| 4
| 3
|}

&lt;br /&gt;'''a = 2'''
{| class="wikitable"
|-
| 9
| 8
| 5
| 6
|-
| 10
| 12
| 11
| 7
|-
| 18
| 20
| 19
| 15
|-
| 17
| 16
| 13
| 14
|}
&lt;br /&gt;'''a = 3'''
{| class="wikitable"
|-
| 28
| 27
| 26
| 21
| 22
| 23
|-
| 29
| 35
| 34
| 31
| 32
| 24
|-
| 30
| 36
| 38
| 37
| 33
| 25
|-
| 48
| 54
| 56
| 55
| 51
| 43
|-
| 47
| 53
| 52
| 49
| 50
| 42
|-
| 46
| 45
| 44
| 39
| 40
| 41
|}
&lt;br /&gt;'''a = 4'''
{| class="wikitable"
|-
| 67
| 66
| 65
| 64
| 57
| 58
| 59
| 60
|-
| 68
| 78
| 77
| 76
| 71
| 72
| 73
| 61
|-
| 69
| 79
| 85
| 84
| 81
| 82
| 74
| 62
|-
| 70
| 80
| 86
| 88
| 87
| 83
| 75
| 63
|-
| 102
| 112
| 118
| 120
| 119
| 115
| 107
| 95
|-
| 101
| 111
| 117
| 116
| 113
| 114
| 106
| 94
|-
| 100
| 110
| 109
| 108
| 103
| 104
| 105
| 93
|-
| 99
| 98
| 97
| 96
| 89
| 90
| 91
| 92
|}

==See also==
* [[Square pyramidal number]]

==References==
{{Reflist}}
* E.R. Scerri. ''The Periodic Table, Its Story and Its Significance.'' Oxford University Press, New York, 2007.

==External links==
{{Wikibooks|Linear Algebra|Matrices}}
{{Wikiversity|at=Linear algebra#Matrices|Matrices}}
* [http://www.meta-synthesis.com/webbook/35_pt/pt.html#j Janet Periodic Table]
* [http://www.meta-synthesis.com/webbook/35_pt/pt_database.php?PT_id=156 Periodic Stack]
* [http://www.perfectperiodictable.com Improved Janet Periodic Table (ADOMAH PT)]

{{DEFAULTSORT:Periodic Matrix Set}}
[[Category:Mathematical structures]]</text>
      <sha1>th52jw1dsxg1q2lyfjo34ua96sgwtju</sha1>
    </revision>
  </page>
  <page>
    <title>Pipelined CORDIC</title>
    <ns>0</ns>
    <id>49022822</id>
    <redirect title="CORDIC" />
    <revision>
      <id>699006738</id>
      <parentid>698520901</parentid>
      <timestamp>2016-01-09T17:35:00Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+cat</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="196">#redirect [[CORDIC#Pipelined CORDIC]] {{R to related topic}}

[[Category:Numerical analysis]]
[[Category:Trigonometry]]
[[Category:Digit-by-digit algorithms]]
[[Category:Shift-and-add algorithms]]</text>
      <sha1>l458uxvkfqc5m9nxyee44120ewa6ptq</sha1>
    </revision>
  </page>
  <page>
    <title>Plaintext</title>
    <ns>0</ns>
    <id>157935</id>
    <revision>
      <id>860344378</id>
      <parentid>860344166</parentid>
      <timestamp>2018-09-20T01:03:57Z</timestamp>
      <contributor>
        <ip>213.149.51.97</ip>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6498">{{About|cryptography|the computing term meaning the storage of textual material that is (largely) unformatted|plain text}}
{{refimprove|date=June 2011}}

In [[cryptography]], '''plaintext''' or '''cleartext''' is unencrypted information, as opposed to information encrypted for storage or transmission. ''Plaintext'' usually means unencrypted information pending input into cryptographic algorithms, usually [[encryption]] algorithms. ''Cleartext'' usually refers to data that is transmitted or stored unencrypted ('in the clear').

==Overview==
With the advent of [[computing]], the term ''plaintext'' expanded beyond human-readable documents to mean any data, including binary files, in a form that can be viewed or used without requiring a key or other decryption device.  Information—a message, document, file, etc.—if to be communicated or stored in encrypted form is referred to as plaintext.

Plaintext is used as input to an [[encryption algorithm]]; the output is usually termed [[ciphertext]], particularly when the algorithm is a [[cipher]]. [[Codetext]] is less often used, and almost always only when the algorithm involved is actually a [[code]]. Some systems use multiple layers of [[encryption]], with the output of one encryption algorithm becoming "plaintext" input for the next.

==Secure handling==
Insecure handling of plaintext can introduce weaknesses into a [[cryptosystem]] by letting an attacker bypass the cryptography altogether. Plaintext is vulnerable in use and in storage, whether in electronic or paper format. ''[[Physical security]]'' means the securing of information and its storage media from physical, attack—for instance by someone entering a building to access papers, storage media, or computers. Discarded material, if not disposed of securely, may be a security risk. Even [[paper shredder|shredded]] documents and erased magnetic media might be reconstructed with sufficient effort.

If plaintext is stored in a [[computer file]], the storage media, the computer and its components, and all backups must be secure. Sensitive data is sometimes processed on computers whose mass storage is removable, in which case physical security of the removed disk is vital. In the case of securing a computer, useful (as opposed to [[handwaving]]) security must be physical (e.g., against [[burglary]], brazen removal under cover of supposed repair, installation of covert monitoring devices, etc.), as well as virtual (e.g., [[operating system]] modification, illicit network access, [[Trojan horse (computing)|Trojan]] programs). Wide availability of [[keydrives]], which can plug into most modern computers and store large quantities of data, poses another severe security headache. A spy (perhaps posing as a cleaning person) could easily conceal one, and even swallow it if necessary.

[[Discarded computers]], disk drives and media are also a potential source of plaintexts. Most operating systems do not actually erase anything&amp;mdash;they simply mark the disk space occupied by a deleted file as 'available for use', and remove its entry from the file system [[directory (file systems)|directory]]. The information in a file deleted in this way remains fully present until overwritten at some later time when the operating system reuses the disk space. With even low-end computers commonly sold with many gigabytes of disk space and rising monthly, this 'later time' may be months later, or never. Even overwriting the portion of a disk surface occupied by a deleted file is insufficient in many cases. [[Peter Gutmann (computer scientist)|Peter Gutmann]] of the [[University of Auckland]] wrote a celebrated 1996 paper on the recovery of overwritten information from magnetic disks; areal storage densities have gotten much higher since then, so this sort of recovery is likely to be more difficult than it was when Gutmann wrote. 

Modern hard drives automatically remap failing sectors, moving data to good sectors. This process makes information on those failing, excluded sectors invisible to the file system and normal applications. Special software, however, can still extract information from them. 

Some government agencies (e.g., US [[NSA]]) require that personnel physically pulverize discarded disk drives and, in some cases, treat them with chemical corrosives. This practice is not widespread outside government, however. Garfinkel and Shelat (2003) analyzed 158 second-hand hard drives they acquired at garage sales and the like, and found that less than 10% had been sufficiently sanitized. The others contained a wide variety of readable personal and confidential information. See [[data remanence]]. 

Physical loss is a serious problem. The [[US State Department]], [[US Department of Defense|Department of Defense]], and the [[British Secret Service]] have all had laptops with secret information, including in plaintext, lost or stolen. Appropriate [[disk encryption]] techniques can safeguard data on misappropriated computers or media.

On occasion, even when data on host systems is encrypted, media that personnel use to transfer data between systems is plaintext because of poorly designed data policy. For example, in October 2007, the [[Loss of United Kingdom child benefit data (2007)|HM Revenue and Customs lost CDs]] that contained the unencryped records of 25 million child benefit recipients in the United Kingdom.

Modern cryptographic systems resist [[known plaintext]] or even [[chosen plaintext]] attacks, and so may not be entirely compromised when plaintext is lost or stolen. Older systems resisted the effects of plaintext data loss on security with less effective techniques—such as [[Padding (cryptography)|padding]] and [[Russian copulation]] to obscure information in plaintext that could be easily guessed.

==See also==
*[[Ciphertext]]
*[[Red/black concept]]

==References==
* S. Garfinkel and A Shelat, "Remembrance of Data Passed: A Study of Disk Sanitization Practices", IEEE Security and Privacy, January/February 2003 [http://www.computer.org/security/garfinkel.pdf (PDF)].
* UK HM Revenue and Customs loses 25m records of child benefit recipients [http://news.bbc.co.uk/2/hi/uk_news/politics/7104368.stm BBC]
*Kissel, Richard (editor). (February, 2011). [http://csrc.nist.gov/publications/nistir/ir7298-rev1/nistir-7298-revision1.pdf NIST IR 7298 Revision 1, Glossary of Key Information Security Terms (PDF)]. National Institute of Standards and Technology.

{{Reflist}}

[[Category:Cryptography]]</text>
      <sha1>poz7wwhnh6plessgxj30mswv61n29xg</sha1>
    </revision>
  </page>
  <page>
    <title>Schwarzian derivative</title>
    <ns>0</ns>
    <id>555745</id>
    <revision>
      <id>859521229</id>
      <parentid>846757763</parentid>
      <timestamp>2018-09-14T15:25:03Z</timestamp>
      <contributor>
        <username>Beland</username>
        <id>57939</id>
      </contributor>
      <minor/>
      <comment>subst template</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="34983">In [[mathematics]], the '''Schwarzian derivative''', named after the German mathematician [[Hermann Schwarz]], is a certain operator that is invariant under all [[linear fractional transformation]]s.  Thus, it occurs in the theory of the [[complex projective line]], and in particular, in the theory of [[modular forms]] and [[hypergeometric functions]]. It plays an important role in the theory of [[univalent function]]s, [[conformal mapping]] and [[Teichmüller space]]s.

==Definition==
The Schwarzian derivative of a [[holomorphic function]] {{mvar|f}} of one [[complex variable]] {{mvar|z}} is defined by

:&lt;math&gt;
(Sf)(z)  = \left( \frac{f''(z)}{f'(z)}\right)'  - \frac{1}{2}\left({f''(z)\over f'(z)}\right)^2 
 = \frac{f'''(z)}{f'(z)}-\frac{3}{2}\left({f''(z)\over f'(z)}\right)^2.
&lt;/math&gt;

The same formula also defines the Schwarzian derivative of a [[Smoothness|''C&lt;sup&gt;3&lt;/sup&gt;'' function]] of one [[Function of a real variable|real variable]].
The alternative notation

:&lt;math&gt;\{f,z\} = (Sf)(z)&lt;/math&gt;

is frequently used.

==Properties==
The Schwarzian derivative of any [[fractional linear transformation]]

: &lt;math&gt;g(z) = \frac{az + b}{cz + d}&lt;/math&gt;

is zero. Conversely, the fractional linear transformations are the only functions with this property. Thus, the Schwarzian derivative precisely measures the degree to which  a function fails to be a fractional linear transformation.

If ''g'' is a fractional linear transformation, then the composition ''g''&amp;nbsp;&lt;small&gt;o&lt;/small&gt;&amp;nbsp;''f'' has the same Schwarzian derivative as ''f''; and on the other hand, the Schwarzian derivative of ''f'' &lt;small&gt;o&lt;/small&gt; ''g'' is given by the [[chain rule]]

: &lt;math&gt;(S(f \circ g))(z) = (Sf)(g(z)) \cdot g'(z)^2.&lt;/math&gt;
&lt;!--:{{bigmath|(S(&lt;VAR &gt;f&lt;/VAR &gt; &amp;#8728; &lt;VAR &gt;g&lt;/VAR &gt;))(&lt;VAR &gt;z&lt;/VAR &gt;) {{=}} (S&lt;VAR &gt;f&lt;/VAR &gt;)(&lt;VAR &gt;g&lt;/VAR &gt;(z)) &amp;sdot; &lt;VAR &gt;g&lt;/VAR &gt;&amp;prime;(&lt;VAR &gt;z&lt;/VAR &gt;)&amp;sup2;}}--&gt;

More generally, for any sufficiently differentiable functions ''f'' and ''g''

: &lt;math&gt;S(f \circ g) = \left( S(f)\circ g\right ) \cdot(g')^2+S(g).&lt;/math&gt;
&lt;!--:{{bigmath|(S(&lt;VAR &gt;f&lt;/VAR &gt; &amp;#8728; &lt;VAR &gt;g&lt;/VAR &gt;))(&lt;VAR &gt;z&lt;/VAR &gt;) {{=}} (S&lt;VAR &gt;f&lt;/VAR &gt;)(&lt;VAR &gt;g&lt;/VAR &gt;(z)) &amp;sdot; &lt;VAR &gt;g&lt;/VAR &gt;&amp;prime;(&lt;VAR &gt;z&lt;/VAR &gt;)&amp;sup2; + S(&lt;VAR &gt;g&lt;/VAR &gt;)}}--&gt;

This makes the Schwarzian derivative an important tool in one-dimensional [[Dynamical system|dynamics]] &lt;ref&gt;[http://mathworld.wolfram.com/SchwarzianDerivative.html  Weisstein, Eric W. "Schwarzian Derivative." From MathWorld--A Wolfram Web Resource.]&lt;/ref&gt; since it implies that all iterates of a function with negative Schwarzian will also have negative Schwarzian.

Introducing the function of two complex variables&lt;ref&gt;{{harvnb|Schiffer|1966}}&lt;/ref&gt;

:&lt;math&gt;F(z,w)= \log \left ( \frac{f(z)-f(w)}{z-w} \right ),&lt;/math&gt;

its second mixed partial derivative is given by

:&lt;math&gt; \frac{\partial^2 F(z,w)}{\partial z \, \partial w} = {f^\prime(z)f^\prime(w)\over(f(z)-f(w))^2}-{1\over(z-w)^2},&lt;/math&gt;

and the Schwarzian derivative is given by the formula:

:&lt;math&gt; (Sf)(w)= \left. 6 \cdot {\partial^2 F(z,w)\over \partial z \partial w}\right\vert_{z=w}.&lt;/math&gt;

The Schwarzian derivative has a simple inversion formula, exchanging the dependent and the independent variables. One has

:&lt;math&gt;(Sw)(v) = -\left(\frac{dw}{dv}\right)^2 (Sv)(w)&lt;/math&gt;

which follows from the [[inverse function theorem]], namely that &lt;math&gt;v'(w)=1/w'.&lt;/math&gt;

==Differential equation==
The Schwarzian derivative has a fundamental relation with a second-order linear [[Complex differential equation|ordinary differential equation in the complex plane]].&lt;ref&gt;{{harvnb|Hille|1976|pages=374–401}}&lt;/ref&gt; Let &lt;math&gt;f_1(z)&lt;/math&gt; and &lt;math&gt;f_2(z)&lt;/math&gt; be two [[Wronskian|linearly independent]] [[Holomorphic function|holomorphic]] solutions of

:&lt;math&gt;\frac{d^2f}{dz^2}+ Q(z) f(z)=0.&lt;/math&gt;

Then the ratio &lt;math&gt;g(z)=f_1(z)/f_2(z)&lt;/math&gt; satisfies

:&lt;math&gt;(Sg)(z) = 2Q(z)&lt;/math&gt;

over the domain on which &lt;math&gt;f_1(z)&lt;/math&gt; and &lt;math&gt;f_2(z)&lt;/math&gt;  are defined, and &lt;math&gt;f_2(z) \ne 0.&lt;/math&gt; The converse is also true: if such a ''g'' exists, and it is holomorphic on a [[simply connected]] domain, then two solutions &lt;math&gt;f_1&lt;/math&gt; and &lt;math&gt;f_2&lt;/math&gt; can be found, and furthermore, these are unique [[up to]] a common scale factor.

When a linear second-order ordinary differential equation can be brought into the above form, the resulting ''Q'' is sometimes called the '''Q-value''' of the equation.

Note that the Gaussian [[hypergeometric differential equation]] can be brought into the above form, and thus pairs of solutions to the hypergeometric equation are related in this way.

==Conditions for univalence==
If ''f'' is a [[holomorphic function]] on the unit disc, '''D''', then W. Kraus (1932) and [[Zeev Nehari|Nehari]] (1949) proved that a ''necessary condition'' for ''f'' to be [[univalent function|univalent]] is&lt;ref&gt;{{harvnb|Lehto|1987|p=60}}&lt;/ref&gt;

:&lt;math&gt;|S(f)| \le 6(1-|z|^2)^{-2}.&lt;/math&gt;

Conversely if ''f''(''z'') is a holomorphic function on '''D''' satisfying

:&lt;math&gt; |S(f)(z)| \le 2(1-|z|^2)^{-2},&lt;/math&gt;

then Nehari proved that ''f'' is univalent.&lt;ref&gt;{{harvnb|Duren|1983}}&lt;/ref&gt;

In particular a ''sufficient condition'' for univalence is&lt;ref&gt;{{harvnb|Lehto|1987|p=90}}&lt;/ref&gt;

:&lt;math&gt; |S(f)|\le 2.&lt;/math&gt;

==Conformal mapping of circular arc polygons==
{{see also|Schwarz triangle function}}
The Schwarzian derivative and associated second order ordinary differential equation can be used to determine the [[Riemann mapping]] between the upper half-plane or unit circle and any bounded polygon in the complex plane, the edges of which are circular arcs or straight lines.  For polygons with straight edges, this reduces to the [[Schwarz–Christoffel mapping]], which can be derived directly without using the Schwarzian derivative. The ''accessory parameters'' that arise as constants of integration are related to the [[Spectral theory of ordinary differential equations|eigenvalues]] of the second order differential equation. Already in 1890 [[Felix Klein]] had studied the case of quadrilaterals in terms of the [[Lamé function|Lamé differential equation]].&lt;ref&gt;{{harvnb|Nehari|1953}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|von Koppenfels|Stallmann|1959}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Klein|1922}}&lt;/ref&gt;

Let Δ be a circular arc polygon with angles {{pi}}α&lt;sub&gt;1&lt;/sub&gt;, ..., {{pi}}α&lt;sub&gt;''n''&lt;/sub&gt; in clockwise order. Let ''f'' : '''H''' → Δ be a holomorphic map extending continuously to a map between the boundaries. Let the vertices correspond to points ''a''&lt;sub&gt;1&lt;/sub&gt;, ..., ''a&lt;sub&gt;n&lt;/sub&gt;'' on the real axis. Then ''p''(''x'') = ''S''(''f'')(''x'') is real-valued for ''x'' real and not one of the points. By the [[Schwarz reflection principle]] ''p''(''x'') extends to a rational function on the complex plane with a double pole at ''a&lt;sub&gt;i&lt;/sub&gt;'':

:&lt;math&gt; p(z)=\sum_{i=1}^n \frac{(1-\alpha_i^2)}{2(z-a_i)^2} + \frac{\beta_i}{z-a_i}.&lt;/math&gt;

The real numbers β&lt;sub&gt;''i''&lt;/sub&gt; are called ''accessory parameters''. They are subject to ''3'' linear constraints:

:&lt;math&gt;\sum \beta_i=0&lt;/math&gt;
:&lt;math&gt; \sum 2a_i \beta_i + \left ( 1-\alpha_i^2 \right ) =0&lt;/math&gt;
:&lt;math&gt; \sum a_i^2 \beta_i + a_i \left ( 1-\alpha_i^2 \right ) =0&lt;/math&gt;

which correspond to the vanishing of the coefficients of &lt;math&gt; z^{-1}, z^{-2}&lt;/math&gt; and  &lt;math&gt;z^{-3}&lt;/math&gt; in the expansion of ''p''(''z'') around ''z'' = ∞. The mapping ''f''(''z'') can then be written as

:&lt;math&gt; f(z) = {u_1(z)\over u_2(z)},&lt;/math&gt;

where &lt;math&gt;u_1(z)&lt;/math&gt; and &lt;math&gt;u_2(z)&lt;/math&gt; are linearly independent holomorphic solutions of the linear second order ordinary differential equation

:&lt;math&gt; u^{\prime\prime}(z) + \tfrac{1}{2} p(z)u(z)=0.&lt;/math&gt;

There are ''n''−3 linearly independent accessory parameters, which can be difficult to determine in practise.

For a triangle, when ''n'' = 3, there are no accessory parameters. The ordinary differential equation is equivalent to the [[hypergeometric differential equation]] and ''f''(''z'') can be written in terms of [[hypergeometric function]]s.

For a quadrilateral the accessory parameters depend on one independent variable λ. Writing ''U''(''z'') = ''q''(''z'')''u''(''z'') for a suitable choice of ''q''(''z''), the ordinary differential equation takes the form

:&lt;math&gt; a(z) U^{\prime\prime}(z) + b(z) U^\prime(z) +(c(z)+\lambda)U(z)=0.&lt;/math&gt;

Thus &lt;math&gt;q(z) u_i(z)&lt;/math&gt; are eigenfunctions of a [[Sturm-Liouville equation]] on the interval &lt;math&gt;[a_i,a_{i+1}]&lt;/math&gt;. By the [[Sturm separation theorem]], the non-vanishing of &lt;math&gt;u_2(z)&lt;/math&gt; forces λ to be the lowest eigenvalue.

==Complex structure on Teichmüller space==
[[Universal Teichmüller space]] is defined to be the space of [[real analytic]] [[quasiconformal mapping]]s of the unit disc '''D''', or equivalently the [[upper half-plane]] '''H''', onto itself, with two mappings considered to be equivalent if on the boundary one is obtained from the other by composition with a [[Möbius transformation]]. Identifying '''D''' with the lower hemisphere of the [[Riemann sphere]], any quasiconformal self-map ''f'' of the lower hemisphere corresponds naturally to a conformal mapping of the upper hemisphere &lt;math&gt;\tilde{f}&lt;/math&gt; onto itself. In fact &lt;math&gt;\tilde{f}&lt;/math&gt; is determined as the restriction to the upper hemisphere of the solution of the [[Beltrami differential equation]]

:&lt;math&gt; \frac{\partial F}{\partial \overline{z}} = \mu(z) \frac{\partial F}{\partial z},&lt;/math&gt;

where μ is the bounded measurable function defined by

:&lt;math&gt;\mu(z) = {{\partial f\over \partial \overline{z}}\over{\partial f\over \partial z}}&lt;/math&gt;

on the lower hemisphere, extended to 0 on the upper hemisphere.

Identifying the upper hemisphere with '''D''', [[Lipman Bers]] used the Schwarzian derivative to define a [[Bers embedding|mapping]]

:&lt;math&gt; g= S(\tilde{f}),&lt;/math&gt;
 
which embeds universal Teichmüller space into an open subset ''U'' of the space of bounded holomorphic functions ''g'' on '''D''' with the [[uniform norm]].  [[Frederick Gehring]] showed in 1977 that ''U'' is the interior of the closed subset of Schwarzian derivatives of univalent functions.&lt;ref&gt;{{harvnb|Ahlfors|1966}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Lehto|1987}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Imayoshi|Taniguchi|1992}}&lt;/ref&gt;

For a [[compact Riemann surface]] ''S'' of genus greater than 1, its [[universal covering space]] is the unit disc '''D''' on which its fundamental group Γ acts by Möbius transformations. The [[Teichmüller space]] of ''S'' can be identified with the subspace of the universal Teichmüller space invariant under Γ. The holomorphic functions ''g'' have the property that

:&lt;math&gt;g(z) dz^{2}&lt;/math&gt;

is invariant under Γ, so determine [[quadratic differential]]s on ''S''. In this way, the Teichmüller space of ''S'' is realized as an open subspace of the finite-dimensional complex vector space of quadratic differentials on ''S''.

==Diffeomorphism group of the circle==
===Crossed homomorphisms===
The transformation property

: &lt;math&gt;S(f \circ g) = \left( S(f)\circ g\right ) \cdot(g')^2+S(g).&lt;/math&gt;

allows the Schwarzian derivative to be interpreted as a continuous 1-cocycle or [[crossed homomorphism]] of the diffeomorphism group of the circle with coefficients in the module of densities of degree 2 on the circle.&lt;ref&gt;{{harvnb|Ovsienko|Tabachnikov|2005|pages=21–22}}&lt;/ref&gt;
Let ''F''&lt;sub&gt;λ&lt;/sub&gt;('''S'''&lt;sup&gt;1&lt;/sup&gt;) be the space of [[tensor density|tensor densities]] of degree λ on '''S'''&lt;sup&gt;1&lt;/sup&gt;. The group of orientation-preserving diffeomorphisms of '''S'''&lt;sup&gt;1&lt;/sup&gt;, Diff('''S'''&lt;sup&gt;1&lt;/sup&gt;), acts on ''F''&lt;sub&gt;λ&lt;/sub&gt;('''S'''&lt;sup&gt;1&lt;/sup&gt;) via [[pushforward (differential)|pushforwards]]. If ''f'' is an element of Diff('''S'''&lt;sup&gt;1&lt;/sup&gt;) then consider the mapping

:&lt;math&gt;f \to S(f^{-1}).&lt;/math&gt;

In the language of [[group cohomology]] the chain-like rule above says that this mapping is a 1-cocycle on Diff('''S'''&lt;sup&gt;1&lt;/sup&gt;) with coefficients in ''F''&lt;sub&gt;2&lt;/sub&gt;('''S'''&lt;sup&gt;1&lt;/sup&gt;). In fact

:&lt;math&gt;H^1(\text{Diff}(\mathbf{S}^1);F_2 (\mathbf{S}^1)) = \mathbf{R}&lt;/math&gt;

and the 1-cocycle generating the cohomology is ''f'' → ''S''(''f''&lt;sup&gt;−1&lt;/sup&gt;). The computation of 1-cohomology is a particular case of the more general result

:&lt;math&gt;H^1(\text{Diff}(\mathbf{S}^1);F_\lambda (\mathbf{S}^1)) = \mathbf{R}\,\, \mathrm{for} \,\, \lambda=0,1,2\,\, \mathrm{and} \,\,(0) \,\,\mathrm{otherwise.}&lt;/math&gt;

Note that if ''G'' is a group and ''M'' a ''G''-module, then the identity defining a crossed homomorphism ''c''  of ''G'' into ''M'' can be expressed in terms of standard homomorphisms of groups: it is encoded in a homomorphism {{phi}} of ''G'' into the semidirect product 
&lt;math&gt;M\rtimes G&lt;/math&gt; such that the composition of {{phi}} with the projection &lt;math&gt;M\rtimes G&lt;/math&gt; onto ''G'' is the identity map; the correspondence is by the map ''C''(''g'') = (''c''(''g''), ''g''). The crossed homomorphisms form a vector space and containing as a subspace the coboundary crossed homomorphisms ''b''(''g'') = ''g'' ⋅ ''m'' − ''m'' for ''m'' in ''M''.  A simple averaging argument shows that, if ''K'' is a compact group and ''V'' a topological vector space on which ''K'' acts continuously, then the higher cohomology groups vanish ''H''&lt;sup&gt;''m''&lt;/sup&gt;(''K'', ''V'') = (0) for ''m'' &gt; 0. n particular for 1-cocycles χ with

:&lt;math&gt;\chi(xy) = \chi(x) + x\cdot \chi(y),&lt;/math&gt;

averaging over ''y'', using left invariant of the [[Haar measure]] on ''K'' gives

:&lt;math&gt;\chi(x) = m - x\cdot m,&lt;/math&gt;
 
with

:&lt;math&gt;m=\int_K \chi(y)\,dy.&lt;/math&gt;

Thus by averaging it may be assumed that ''c'' satisfies the normalisation condition ''c''(''x'') = 0 for ''x'' in Rot('''S'''&lt;sup&gt;1&lt;/sup&gt;). Note that if any element ''x'' in ''G'' satisifes ''c''(''x'') = 0 then ''C''(''x'') = (0,''x''). But then, since ''C'' is a homomorphism,
''C''(''xgx''&lt;sup&gt;–1&lt;/sup&gt;) = ''C''(''x'')''C''(''g'')''C''(''x'')&lt;sup&gt;–1&lt;/sup&gt;, so that ''c'' satisfies the equivariance condition ''c''(''xgx''&lt;sup&gt;–1&lt;/sup&gt;)=''x'' ⋅ ''c''(''g''). Thus it may be assumed that the cocycle satisifies these normalisation conditions for Rot('''S'''&lt;sup&gt;1&lt;/sup&gt;). The Schwarzian derivative in fact vanishes whenever ''x'' is a Möbius transformation corresponding to SU(1,1). The other two 1-cycles discussed below vanish only on Rot('''S'''&lt;sup&gt;1&lt;/sup&gt;) (λ = 0, 1). 

There is an infinitesimal version of this result giving a 1-cocycle for Vect('''S'''&lt;sup&gt;1&lt;/sup&gt;), the Lie algebra of smooth [[vector field]]s, and hence for the [[Witt algebra]], the subalgebra of trigonometric polynomial vector fields. Indeed, when ''G'' is  a Lie group and the action of ''G'' on ''M'' is smooth, there is a Lie algebraic version of crossed homomorphism obtained by taking the corresponding homomorphisms of the Lie algebras (the derivatives of the homomotphisms at the identity). This also makes sense for
Diff('''S'''&lt;sup&gt;1&lt;/sup&gt;) and leads to the 1-cocycle 

:&lt;math&gt; s(f\, {d\over d\theta})={d^3f\over\, d\theta^3}\,(d\theta)^2&lt;/math&gt;

which satisfies the identity

:&lt;math&gt;s([X,Y])=X\cdot s(Y) -Y\cdot s(X).&lt;/math&gt;

In the Lie algebra case, the coboundary maps have the form ''b''(''X'') = ''X'' ⋅ ''m'' for ''m'' in ''M''. In both cases the 1-cohomology is defined as the space of crossed homomorphisms modulo coboundaries. The natural correspondence between group homomorphisms and Lie algebra homomorphisms leads to the "van Est inclusion map"

:&lt;math&gt;H^1(\text{Diff}(\mathbf{S}^1);F_\lambda (\mathbf{S}^1)) \hookrightarrow H^1(\text{Vect}(\mathbf{S}^1);F_\lambda (\mathbf{S}^1)),&lt;/math&gt;

In this way the calculation can be reduced to that of [[Lie algebra cohomology]]. By continuity this reduces to the computation of crossed homomorphisms {{phi}} of the Witt algebra into ''F''&lt;sub&gt;λ&lt;/sub&gt;('''S'''&lt;sup&gt;1&lt;/sup&gt;). The normalisations conditions on the group crossed homomorphism imply the following additional conditions for {{phi}}:

:&lt;math&gt;\varphi(\text{Ad}(x) X) = x\cdot \varphi(X),\,\, \varphi(d/d\theta) = 0&lt;/math&gt;

for ''x'' in Rot('''S'''&lt;sup&gt;1&lt;/sup&gt;). 

Following the conventions of {{harvtxt|Kac|Raina|1987}}, a basis of the Witt algebra is given by

:&lt;math&gt;d_n = i e^{in\theta} \,{d\over d\theta}&lt;/math&gt;

so that [''d''&lt;sub&gt;''m''&lt;/sub&gt;,''d''&lt;sub&gt;''n''&lt;/sub&gt;] = (''m'' – ''n'') ''d''&lt;sub&gt;''m'' + ''n''&lt;/sub&gt;. A basis for  the complexification of ''F''&lt;sub&gt;λ&lt;/sub&gt;('''S'''&lt;sup&gt;1&lt;/sup&gt;) is given by 

:&lt;math&gt;v_n=e^{in\theta} \, (d\theta)^\lambda,&lt;/math&gt;

so that

:&lt;math&gt; d_m \cdot v_n = -(n+\lambda m)v_{n+m},\,\, g_\zeta \cdot v_n = \zeta^{n} v_n,&lt;/math&gt;

for ''g''&lt;sub&gt;ζ&lt;/sub&gt; in Rot('''S'''&lt;sup&gt;1&lt;/sup&gt;) = '''T'''. This forces {{math|1={{phi}}(''d''&lt;sub&gt;''n''&lt;/sub&gt;) = ''a''&lt;sub&gt;''n''&lt;/sub&gt; ⋅ ''v''&lt;sub&gt;''n'' &lt;/sub&gt;}} for suitable coefficients {{math|''a''&lt;sub&gt;''n''&lt;/sub&gt;}}. The crossed homomorphism condition
{{math|1={{phi}}([''X'',''Y'']) = ''X''{{phi}}(''Y'') – ''Y''{{phi}}(''X'')}} gives a recurrence relation for the {{math|''a''&lt;sub&gt;''n''&lt;/sub&gt;}}:

:&lt;math&gt; (m-n) a_{m+n} = (m+\lambda n) a_m-(n+\lambda m)a_n.&lt;/math&gt;

The condition {{phi}}(''d''/''d''&amp;theta;) = 0, implies that ''a''&lt;sub&gt;0&lt;/sub&gt; = 0. From this condition and the recurrence relation, it follows that up to scalar multiples, this has a unique non-zero solution when λ equals 0, 1 or 2 and only the zero solution otherwise. The solution for {{math|1=λ = 1}} corresponds to the group 1-cocycle &lt;math&gt;\varphi_1(f) =f^{\prime\prime}/f^\prime\, d\theta&lt;/math&gt;. The solution for {{math|1=λ = 0}} corresponds to the group 1-cocycle {{phi}}&lt;sub&gt;0&lt;/sub&gt;(''f'') = log ''f' ''. The corresponding Lie algebra 1-cocycles for λ = 0, 1, 2 are given up to a scalar multiple by 

:&lt;math&gt;\varphi_\lambda\left(F {d\over d\theta}\right) = {d^{\lambda+1} F\over d\theta^{\lambda +1}} \, (d\theta)^\lambda.&lt;/math&gt;

===Central extensions===
The crossed homomorphisms in turn give rise to the central extension of Diff('''S'''&lt;sup&gt;1&lt;/sup&gt;) and of its Lie algebra Vect('''S'''&lt;sup&gt;1&lt;/sup&gt;), the so-called [[Virasoro algebra]].

===Coadjoint action===
The group Diff('''S'''&lt;sup&gt;1&lt;/sup&gt;) and its central extension also appear naturally in the context of Teichmüller theory and [[string theory]].&lt;ref&gt;{{harvnb|Pekonen|1995}}&lt;/ref&gt; In fact the homeomorphisms of '''S'''&lt;sup&gt;1&lt;/sup&gt; induced by quasiconformal self-maps of '''D''' are precisely the [[quasisymmetric map|quasisymmetric homeomorphisms]] of '''S'''&lt;sup&gt;1&lt;/sup&gt;; these are exactly homeomorphisms which do not send four points with [[cross ratio]] 1/2 to points with cross ratio near 1 or 0. Taking boundary values, universal Teichmüller can be identified with the quotient of the group of quasisymmetric homeomorphisms QS('''S'''&lt;sup&gt;1&lt;/sup&gt;) by the subgroup of Möbius transformations Moeb('''S'''&lt;sup&gt;1&lt;/sup&gt;). (It can also be realized naturally as the space of [[quasicircle]]s in '''C'''.) Since

:&lt;math&gt;\text{Moeb}(\mathbf{S}^1)\subset \text{Diff}(\mathbf{S}^1) \subset \text{QS}(\mathbf{S}^1)&lt;/math&gt;

the [[homogeneous space]] Diff('''S'''&lt;sup&gt;1&lt;/sup&gt;)/Moeb('''S'''&lt;sup&gt;1&lt;/sup&gt;) is naturally a subspace of universal Teichmüller space. It is also naturally a complex manifold and this and other natural geometric structures are compatible with those on Teichmüller space. The dual of the Lie algebra of Diff('''S'''&lt;sup&gt;1&lt;/sup&gt;) can be identified with the space of [[Hill differential equation|Hill's operators]] on '''S'''&lt;sup&gt;1&lt;/sup&gt;

:&lt;math&gt;{d^2\over d\theta^2} + q(\theta),&lt;/math&gt;

and the [[coadjoint action]] of Diff('''S'''&lt;sup&gt;1&lt;/sup&gt;) invokes the Schwarzian derivative. The inverse of the diffeomorphism ''f'' sends the Hill's operator to

:&lt;math&gt;{d^2\over d\theta^2} + f^\prime(\theta)^2 \,q\circ f(\theta) + \tfrac{1}{2} S(f)(\theta).&lt;/math&gt;

==Pseudogroups and connections==
The Schwarzian derivative and the other 1-cocycle defined on Diff('''S'''&lt;sup&gt;1&lt;/sup&gt;) can be extended to biholomorphic between open sets in the complex plane. In this case the local description leads to the theory of analytic [[pseudogroup]]s, formalizing the theory of infinite-dimensional groups and Lie algebras first studied by [[Élie Cartan]] in the 1910s. This is related to affine and projective structures on Riemann surfaces as well as the theory of Schwarzian or projective connections, discussed by Gunning, Schiffer and Hawley.

A holomorphic [[pseudogroup]] Γ on '''C''' consists of a collection of [[biholomorphism]]s {{math|''f''}} between open sets ''U'' and ''V'' in '''C''' which contains the identity maps for each open ''U'', which is closed under restricting to opens, which is closed under composition (when possible), which is closed under taking inverses and such that if a biholomorphisms is locally in Γ, then it too is in Γ. The pseudogroup is said to be ''transitive'' if, given {{math|''z''}} and {{math|''w''}} in '''C''', there is a biholomorphism {{math|''f''}} in Γ such that {{math|1=''f''(''z'') = ''w''}}. A particular case of transitive pseudogroups are those which are ''flat'', i.e. contain all complex translations {{math|1=''T''&lt;sub&gt;''b''&lt;/sub&gt;(''z'') = ''z'' + ''b''}}.  Let ''G'' be the group, under composition, of [[formal power series]] transformations {{math|1=''F''(z) = ''a''&lt;sub&gt;1&lt;/sub&gt;''z'' + ''a''&lt;sub&gt;2&lt;/sub&gt;''z''&lt;sup&gt;2&lt;/sup&gt; + ....}}  with {{math|''a''&lt;sub&gt;1&lt;/sub&gt; ≠ 0}}. A holomorphic pseudogroup Γ defines a subgroup ''A'' of ''G'', namely the subgroup defined by the Taylor series expansion about 0  (or [[jet (mathematics)|"jet"]]) of elements {{math|''f''}} of Γ with {{math|1=''f''(0) = 0}}. Conversely if Γ is flat it is uniquely determined by ''A'': a biholomorphism {{math|''f''}} on ''U'' is contained in Γ in if and only if the power series  of {{math|''T''&lt;sub&gt;–''f''(''a'')&lt;/sub&gt; ∘ ''f'' ∘ ''T''&lt;sub&gt;''a''&lt;/sub&gt;}} lies in ''A'' for every {{math|''a''}} in ''U'': in other words the formal power series for {{math|''f''}} at {{math|''a''}} is given by an element of ''A'' with {{math|''z''}} replaced by {{math|''z'' − ''a''}}; or more briefly all the jets of ''f'' lie in ''A''. &lt;ref&gt; {{harvnb|Sternberg|1983|page=421–424}}&lt;/ref&gt;

The group ''G'' has a natural homomorphisms onto the  group ''G''&lt;sub&gt;''k''&lt;/sub&gt; of ''k''-jets obtained by taking the truncated power series taken up to the term ''z''&lt;sup&gt;''k''&lt;/sup&gt;. This group acts faithfully on the space of polynomials of degree ''k'' (truncating terms of order higher than ''k''). Truncations similarly define homomorphisms of ''G''&lt;sub&gt;''k''&lt;/sub&gt; onto ''G''&lt;sub&gt;''k'' − 1&lt;/sub&gt;; the kernel consists of maps ''f'' with ''f''(''z'') = ''z'' + ''bz''&lt;sup&gt;''k''&lt;/sup&gt;, so is Abelian. Thus the group ''G''&lt;sub&gt;''k''&lt;/sub&gt; is solvable, a fact also clear from the fact that it is in triangular form for the basis of monomials. 

A flat pseudogroup  Γ  is said to be '''''"defined by differential equations"''''' if there is a finite integer ''k'' such that homomorphism of ''A'' into ''G''&lt;sub&gt;''k''&lt;/sub&gt; is faithful and the image is a closed subgroup. The smallest such ''k'' is said to be the ''order'' of Γ.
There is a complete classification of all subgroups ''A'' that arise in this way which satisfy the additional assumptions that the image of ''A'' in ''G''&lt;sub&gt;''k''&lt;/sub&gt; is a complex subgroup and that ''G''&lt;sub&gt;1&lt;/sub&gt; equals '''C'''*: this implies that the pseudogroup also contains the scaling transformations ''S''&lt;sub&gt;''a''&lt;/sub&gt;(''z'') = ''az'' for ''a'' ≠ 0, i.e. contains ''A'' contains every polynomial ''az'' with ''a'' ≠ 0.

The only possibilities in this case are that ''k'' = 1 and ''A'' = {''az'':  ''a'' ≠ 0}; or that ''k'' = 2 and ''A'' = {''az''/(1−''bz'') : ''a'' ≠ 0}. The former is the pseudogroup defined by affine subgroup of the complex Möbius group (the ''az'' + ''b'' transformations fixing ∞); the latter is the pseudogroup defined by the whole complex Möbius group.

This classification can easily be reduced to a Lie algebraic problem since the formal Lie algebra &lt;math&gt;\mathfrak{g}&lt;/math&gt; of ''G'' consists of formal vector fields ''F''(''z'') ''d''/''dz'' with ''F'' a formal power series. It contains the polynomial vectors fields with basis ''d''&lt;sub&gt;''n''&lt;/sub&gt; = ''z''&lt;sup&gt;''n''+1&lt;/sup&gt; ''d''/''dz'' (''n'' ≥ 0), which is a subalgebra of the Witt algebra. The Lie brackets are given by [''d''&lt;sub&gt;''m''&lt;/sub&gt;,''d''&lt;sub&gt;''n''&lt;/sub&gt;] = (''n'' − ''m'')''d''&lt;sub&gt;''m''+''n''&lt;/sub&gt;. Again these act on the space of polynomials of degree ≤ ''k'' by differentiation—it can be identified with '''C'''&lt;nowiki&gt;[[&lt;/nowiki&gt;''z''&lt;nowiki&gt;]]&lt;/nowiki&gt;/(''z''&lt;sup&gt;''k''+1&lt;/sup&gt;)—and the images of ''d''&lt;sub&gt;0&lt;/sub&gt;, ..., ''d''&lt;sub&gt;''k'' – 1&lt;/sub&gt; give a basis of the Lie algebra of ''G''&lt;sub&gt;''k''&lt;/sub&gt;. Note that {{math|1=Ad(''S''&lt;sub&gt;''a''&lt;/sub&gt;) ''d''&lt;sub&gt;''n''&lt;/sub&gt;= ''a''&lt;sup&gt;–''n''&lt;/sup&gt; ''d''&lt;sub&gt;''n''&lt;/sub&gt;}}. Let &lt;math&gt;\mathfrak{a}&lt;/math&gt; denote the Lie algebra of ''A'': it is isomorphic to a subalgebra of the Lie algebra of ''G''&lt;sub&gt;''k''&lt;/sub&gt;. It contains ''d''&lt;sub&gt;0&lt;/sub&gt; and is invariant under Ad(''S''&lt;sub&gt;''a''&lt;/sub&gt;). Since &lt;math&gt;\mathfrak{a}&lt;/math&gt; is a Lie subalgebra of the Witt algebra, the only possibility is that it has basis ''d''&lt;sub&gt;0&lt;/sub&gt; or basis ''d''&lt;sub&gt;0&lt;/sub&gt;, ''d''&lt;sub&gt;''n''&lt;/sub&gt; for some ''n'' ≥ 1. There are corresponding group elements of the form ''f''(''z'')= ''z'' + ''bz''&lt;sup&gt;''n''+1&lt;/sup&gt; + .... Composing this with translations yields ''T''&lt;sub&gt;–''f''(ε)&lt;/sub&gt; ∘ ''f'' ∘ ''T''&lt;sub&gt; ε&lt;/sub&gt;(''z'') = ''cz'' + ''dz''&lt;sup&gt;2&lt;/sup&gt; + ... with ''c'', ''d'' ≠ 0. Unless ''n'' = 2, this contradicts the form of subgroup ''A''; so ''n'' = 2.&lt;ref&gt;{{harvnb|Gunning|1978}}&lt;/ref&gt;

The Schwarzian derivative is related to the pseudogroup for the complex Möbius group. In fact if ''f'' is a biholomorphism defined on ''V'' then {{phi}}&lt;sub&gt;2&lt;/sub&gt;(''f'') = ''S''(''f'') is a quadratic differential on ''V''. If ''g'' is a bihomolorphism defined on ''U'' and ''g''(''V'') ⊆ ''U'', ''S''(''f'' ∘ ''g'') and ''S''(''g'') are quadratic differentials on ''U''; moreover ''S''(''f'') is a quadratic differential on ''V'', so that ''g''&lt;sub&gt;∗&lt;/sub&gt;''S''(f) is also a quadratic differential on ''U''. The identity

:&lt;math&gt; S(f\circ g) = g_*S(f) + S(g)&lt;/math&gt;

is thus the analogue of a 1-cocycle for the pseudogroup of biholomorphisms with coefficients in holomorphic quadratic differentials. Similarly &lt;math&gt; \varphi_0(f) = \log f^\prime &lt;/math&gt; and &lt;math&gt;\varphi_1(f) = f^{\prime\prime}/f^\prime&lt;/math&gt; are 1-cocycles for the same pseudogroup with values in holomorphic functions and holomorphic differentials. In general 1-cocycle can be defined for holomorphic differentials of any order so that

:&lt;math&gt;\varphi(f\circ g) = g_*\varphi(f) + \varphi(g).&lt;/math&gt;

Applying the above identity to inclusion maps ''j'', it follows that {{phi}}(''j'') = 0 ;and hence that if ''f''&lt;sub&gt;1&lt;/sub&gt; is the restriction of ''f''&lt;sub&gt;2&lt;/sub&gt;, so that ''f''&lt;sub&gt;2&lt;/sub&gt; ∘ ''j'' = ''f''&lt;sub&gt;1&lt;/sub&gt;, then {{phi}}(''f''&lt;sub&gt;1&lt;/sub&gt;) = {{phi}} (''f''&lt;sub&gt;2&lt;/sub&gt;). On the other hand taking the local holomororphic flow defined by holomorphic vector fields,—the exponential of the vector fields—the holomorphic pseudogroup of local biholomorphisms is generated by holomorphic vector fields.  If the 1-cocycle {{phi}} satisfies suitable continuity or analyticity conditions, it induces a 1-cocycle of holomorphic vector fields, also compatible with restriction. Accordingly it defines a 1-cocycle on holomorphic vector fields on '''C''':&lt;ref&gt;{{harvnb|Libermann|year=1959}}&lt;/ref&gt;

:&lt;math&gt;\varphi([X,Y]) = X \varphi(Y) - Y \varphi(X).&lt;/math&gt;

Restricting to the Lie algebra of polynomial vector fields with basis ''d''&lt;sub&gt;''n''&lt;/sub&gt; = ''z''&lt;sup&gt;''n''+1&lt;/sup&gt; ''d''/''dz'' (''n'' ≥ -1), these can be determined using the same methods of Lie algebra cohomology (as in the previous section on crossed homomorphisms). There the calculation was for the whole Witt algebra acting on densities of order ''k'', whereas here it is just for a subalgebra acting on holomorphic (or polynomial) differentials of order ''k''. Again, assuming that {{phi}} vanishes on rotations of '''C''', there are non-zero 1-cocycles, unique up to scalar multiples. only for differentials of degree 0, 1 and 2 given by the same derivative formula

:&lt;math&gt;\varphi_k\left(p(z) {d\over dz}\right) = p^{(k+1)}(z) \, (dz)^k,&lt;/math&gt;

where ''p''(''z'') is a polynomial.

The 1-cocycles define the three pseudogroups by {{phi}}&lt;sub&gt;''k''&lt;/sub&gt;(''f'') = 0: this gives the scaling group (''k'' = 0); the affine group (''k'' = 1); and the whole complex Möbius group (''k'' = 2). So these 1-cocycles are the special [[ordinary differential equation]]s defining the pseudogroup. More significantly they can be used to define corresponding affine or projective structures and connections on Riemann surfaces. If Γ is a pseudogroup of smooth mappings on '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, a topological space ''M'' is said to have a Γ-structure if it has a collection of charts ''f'' that are homeomorphisms from open sets ''V''&lt;sub&gt;''i''&lt;/sub&gt; in ''M'' to open sets ''U''&lt;sub&gt;''i''&lt;/sub&gt; in '''R'''&lt;sup&gt;''n''&lt;/sup&gt; such that, for every non-empty intersection, the natural map from {{math|''f''&lt;sub&gt;''i''&lt;/sub&gt; (''U''&lt;sub&gt;''i''&lt;/sub&gt; ∩ ''U''&lt;sub&gt;''j''&lt;/sub&gt;)}} to {{math|''f''&lt;sub&gt;''j''&lt;/sub&gt; (''U''&lt;sub&gt;''i''&lt;/sub&gt; ∩ ''U''&lt;sub&gt;''j''&lt;/sub&gt;)}} lies in  Γ. This defines the structure of a smooth ''n''-manifold if Γ consists of local diffeomorphims and a Riemann surface if ''n'' = 2—so that '''R'''&lt;sup&gt;2&lt;/sup&gt; ≡ '''C'''—and  Γ consists of biholomorphisms. If Γ is the affine pseudogroup, ''M'' is said to have an affine structure; and if Γ is the Möbius pseudogroup, ''M'' is said to have a projective structure. Thus a genus one surface given as '''C'''/Λ for some lattice  Λ ⊂ '''C''' has an affine structure; and a genus ''p'' &gt; 1 surface given as the quotient of the upper half plane or unit disk by a Fuchsian group has a projective structure.&lt;ref&gt; {{harvnb|Gunning|1966}}&lt;/ref&gt;

{{harvtxt|Gunning|1966}} describes how this process can be reversed: for genus ''p'' &gt; 1, the existence of a projective connection, defined using the Schwarzian derivative {{phi}}&lt;sub&gt;2&lt;/sub&gt; and proved using standard results on cohomology, can be used to identify the universal covering surface with the upper half plane or unit disk (a similar result holds for genus 1, using affine connections and {{phi}}&lt;sub&gt;1&lt;/sub&gt;).

==Notes==
{{reflist|2}}

==References==
*{{citation|first=Lars|last=Ahlfors|authorlink=Lars Ahlfors|title=Lectures on quasiconformal mappings|publisher=Van Nostrand|year=1966|pages=117–146}}, Chapter 6, "Teichmüller Spaces"
*{{citation|last=Duren|first=Peter L.|title=Univalent functions|publisher=Springer-Verlag|series=Grundlehren der Mathematischen Wissenschaften |volume=259|year= 1983|isbn= 0-387-90795-5|pages=258–265}}]
*{{citation|last=Guieu|first=Laurent|last2= Roger|first2= Claude|title=
L'algèbre et le groupe de Virasoro|publisher=CRM|location= Montreal|year=2007|isbn= 2-921120-44-5}}
*{{citation|last=Gunning|first= R. C.|title=Lectures on Riemann surfaces|series=Princeton Mathematical Notes |publisher= [[Princeton University Press]]|year= 1966}}
*{{citation|last=Gunning|first= R. C.|title=On uniformization of complex manifolds: the role of connections|series=Mathematical Notes|volume=22|publisher=[[Princeton University Press]]|year=1978|isbn= 0-691-08176-X}}
*{{citation|first=Einar|last=Hille|authorlink=Einar Hille|title=Ordinary differential equations in the complex domain|publisher=Dover|year=1976|isbn=0-486-69620-0|pages=374–401}}, Chapter 10,  "The Schwarzian".
*{{citation|first=Y.|last=Imayoshi|first2=M.|last2=Taniguchi|title=An introduction to Teichmüller spaces|publisher=Springer-Verlag|year=1992|isbn=4-431-70088-9}}
*{{citation|last=Kac|first=V. G.|last2=Raina|first2= A. K.|title=Bombay lectures on highest weight representations of infinite-dimensional Lie algebras|publisher= World Scientific|year=1987|isbn=9971-50-395-6}}
*{{citation|first=W.|last=von Koppenfels|first2=F.|last2=Stallmann|title=Praxis der konformen Abbildung|year=1959|publisher=Springer-Verlag|series=Die Grundlehren der mathematischen Wissenschaften|volume=100|pages=114–141}}, Section 12, "Mapping of polygons with circular arcs".
*{{citation|first=Felix|last=Klein|authorlink=Felix Klein|title=Collected works|volume=2|pages=540–549|url=http://gdz.sub.uni-goettingen.de/en/dms/load/img/?PPN=PPN237843552|publisher=Springer-Verlag
|year=1922}}, "On the theory of generalized Lamé functions".
*{{citation|first=Otto|last=Lehto|title=Univalent functions and  Teichmüller spaces|publisher=Springer-Verlag|year=1987|isbn=0-387-96310-3|pages=50–59, 111–118, 196–205}}
*{{citation|last=Libermann|first=Paulette|authorlink=Paulette Libermann|title=Pseudogroupes infinitésimaux attachés aux pseudogroupes de Lie|journal=Bull. Soc. Math. France|volume= 87|year= 1959|pages=409–425}}
*{{citation | last1=Nehari | first1=Zeev |authorlink=Zeev Nehari| title=The Schwarzian derivative and schlicht functions | doi=10.1090/S0002-9904-1949-09241-8  |mr=0029999 | year=1949 | journal=[[Bulletin of the American Mathematical Society]] | issn=0002-9904 | volume=55 | pages=545–551}}
*{{citation|first=Zeev|last=Nehari|authorlink=Zeev Nehari|title=Conformal mapping|publisher=Dover|year=1952|isbn=0-486-61137-X|pages=189–226}}
*{{citation|first=V. |last=Ovsienko|first2=S.|last2= Tabachnikov |title=Projective Differential Geometry Old and New|publisher= Cambridge University Press|year=2005|isbn=0-521-83186-5}}
* {{citation | first1 = Valentin | last1 = Ovsienko | first2 = Sergei | last2 = Tabachnikov | title = What Is . . . the Schwarzian Derivative? | journal = AMS Notices | volume = 56 | issue = 01 | pages = 34–36 | year = 2009
    | url = http://www.ams.org/notices/200901/tx090100034p.pdf }}
*{{citation|last=Pekonen|first=Osmo|title=Universal Teichmüller space in geometry and physics|journal=J. Geom. Phys.|volume=15|year= 1995|pages= 227–251|
url=http://www.sciencedirect.com/science/article/pii/039304409400007Q|doi=10.1016/0393-0440(94)00007-Q|arxiv=hep-th/9310045|bibcode=1995JGP....15..227P}}
* {{citation|title=Half-Order Differentials on Riemann Surfaces|first=
Menahem|last= Schiffer|journal=SIAM Journal on Applied Mathematics|volume=14|pages=922–934|year=1966|jstor=2946143|doi=10.1137/0114073}}
*{{citation|last=Segal|first= Graeme|title=Unitary representations of some infinite-dimensional groups|journal=Comm. Math. Phys. |volume=80 |year=1981|pages=301–342|doi=10.1007/bf01208274|bibcode=1981CMaPh..80..301S}}
*{{citation|last=Sternberg|first= Shlomo|title=Lectures on differential geometry|edition=Second |publisher= Chelsea Publishing|year= 1983|isbn= 0-8284-0316-3}}
*{{citation|last=Takhtajan|first= Leon A.|last2=Teo|first2=Lee-Peng|title=Weil-Petersson metric on the universal Teichmüller space|series=
Mem. Amer. Math. Soc.|volume= 183 |year=2006|number=861}}
[[Category:Projective geometry]]
[[Category:Modular forms]]
[[Category:Ordinary differential equations]]
[[Category:Complex analysis]]
[[Category:Conformal mapping]]</text>
      <sha1>813hly6e0medtla7va7tyshaob49sh4</sha1>
    </revision>
  </page>
  <page>
    <title>Semilinear set</title>
    <ns>0</ns>
    <id>2628576</id>
    <redirect title="Generalized arithmetic progression" />
    <revision>
      <id>323214900</id>
      <parentid>81384395</parentid>
      <timestamp>2009-11-01T03:02:33Z</timestamp>
      <contributor>
        <username>Nbarth</username>
        <id>570614</id>
      </contributor>
      <comment>r to anchor</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="106">#REDIRECT [[Generalized arithmetic progression#semilinear set]]
{{R to anchor}}
[[Category:Combinatorics]]</text>
      <sha1>gd47bcrlsyo4eap52c2xqwz16gux00u</sha1>
    </revision>
  </page>
  <page>
    <title>Seymour Ginsburg</title>
    <ns>0</ns>
    <id>5621883</id>
    <revision>
      <id>835262857</id>
      <parentid>810244455</parentid>
      <timestamp>2018-04-07T16:11:49Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* Professional Contributions */[[User:JCW-CleanerBot#Logic|task]], replaced: J. UCS → Journal of Universal Computer Science using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12136">{{Infobox scientist 
|name = Seymour Ginsburg
|birth_date = {{birth date|1927|12|12}}
|residence = [[United States|U.S.]]
|nationality = U.S.
|death_date = {{death date and age|2004|12|5|1927|12|12}}
|field = [[Computer Science]]
|work_institution = [[University of Southern California]],&lt;br&gt;[[University of Miami]] 
|alma_mater = [[CCNY|City College of New York]],&lt;br&gt;[[University of Michigan]]
|doctoral_advisor = [[Dushnik-Miller dimension|Ben Dushnik]]|
|known_for  = [[formal language theory|Formal Language Theory]],&lt;br&gt;[[Abstract Families of Languages]],&lt;br&gt;[[Database]] theory,&lt;br&gt;[[Object Histories]]
|religion = [[Jewish]]
}}

'''Seymour Ginsburg''' (December 12, 1927 – December 5, 2004) was an American pioneer of  [[automata]] theory,  [[formal language]] theory, and
[[database]] theory, in particular; and [[computer science]], in general. His work was influential in distinguishing theoretical Computer Science from the disciplines of Mathematics and Electrical Engineering.

During his career, Ginsburg published over 100 papers and three books on various topics in theoretical Computer Science.

== Biography ==

Seymour Ginsburg received his B.S. from [[CCNY|City College of New York]] in 1948, where along with fellow student [[Martin Davis]] he attended an honors mathematics class taught by [[Emil Post]].&lt;ref&gt;{{Citation |last=Urquhart|first=Alasdair|editor1-last=Gabbay|editor1-first=Dov M. |editor2-last=Woods|editor2-first=John|chapter=Emil Post|series=Handbook of the History of Logic|title=Logic from Russell to Church|volume=5|publisher=North Holland|publication-date=2009|isbn= 978-0-444-51620-6}}&lt;/ref&gt; He earned a Ph.D. in [[Mathematics]] from the [[University of Michigan]] in 1952, studying under [[Dushnik-Miller dimension|Ben Dushnik]].

Ginsburg's professional career began in 1951 when he accepted a position as Assistant Professor of Mathematics at the [[University of Miami]] in Florida.  He turned his attention wholly towards [[Computer Science]] in 1955, when he moved to California to work for the [[Northrop Corporation]]. He followed this with positions at the [[National Cash Register Corporation]], [[Hughes Aircraft]], and [[System Development Corporation]].

At SDC, Ginsburg first concentrated on the theory of abstract machines.&lt;ref&gt;{{Citation|first=Seymour|last=Ginsburg|journal=Commun. ACM|volume=4|issue=4|year=1961|pages=195|doi=10.1145/355578.366521|title=Theory of abstract machines}}&lt;/ref&gt; He subsequently formed and led a research project dedicated to formal language theory and the foundations of Computer Science. Members of the research group included: [[Sheila Greibach]], [[Michael A. Harrison]], Gene Rose, [[Ed Spanier]], and [[Joe Ullian]]. The work that came out of this group distinguished Computer Science theory from other fields, putting Ginsburg at the center of what became the theoretical Computer Science community.&lt;ref name=memory&gt;{{Citation|last1=Abiteboul|first1=S.|author1-link=Serge Abiteboul|last2=Hull|first2=R.|last3=Vianu|first3=V.|author3-link=Victor Vianu|title=In memory of Seymour Ginsburg, 1928-2004|journal=ACM SIGMOD Record|volume=34|issue=1|date=March 2005|doi=10.1145/1058150.1058152|pages=5}}&lt;/ref&gt;

It was during the SDC years that a young [[Jeff Ullman]] spent one summer working for Ginsburg, learning both formal language theory and a broad approach to research in Computer Science theory. [[Al Aho]] credited Ullman's summer with Ginsburg as being highly influential on Aho's career in Computer Science. In an interview, Aho recalled that there was little Computer Science at Princeton while he was studying for his PhD. However, after Ullman returned from his summer with Ginsburg, he stated that Ullman "essentially taught [[John Hopcroft|Hopcroft]], and me, formal language theory".&lt;ref&gt;[http://www.princeton.edu/~hos/mike/transcripts/aho.htm An interview of Al Aho by Professor M.S. Mahoney]&lt;/ref&gt;

Ginsburg joined the faculty of [[University of Southern California]] in 1966 where he helped to establish the [[Computer Science]] department in 1968. He was awarded a [[Guggenheim Fellowship]] in 1974 and spent the year touring the world, lecturing on the areas of theoretical Computer Science which he had helped to create.  Ginsburg was named the first Fletcher Jones Professor of Computer Science at USC in 1978, a chair he held until his retirement in 1999. He continued his work on formal language theory and automata through the 1970s.

At USC in the 1980s, Ginsburg created a research group dedicated to [[Database]] theory. He organized the first PODS ([[Symposium on Principles of Database Systems]]) in [[Marina del Rey]] in 1982 and was a moving force at the conference into the 1990s. He was honored with a surprise session at the 1992 PODS on the occasion of his 64th birthday. A festschrift edited by [[Jeff Ullman]] was created in his honor for the occasion.&lt;ref&gt;{{Citation|title=To Seymour Ginsburg on the occasion of his &lt;math&gt;2^6&lt;/math&gt; birthday|series=Theoretical Studies in Computer Science|publisher=Academic Press|year=1992|isbn=0-12-708240-9|editor=Jeff Ullman}}&lt;/ref&gt;

Ginsburg's career ended suddenly in 1999 when he was diagnosed with the onset of [[Alzheimer's disease]]. He retired from active teaching and became Professor Emeritus of Computer Science at USC. He spent his last years in declining health until dying on December 5, 2004.

Ginsburg was remembered fondly in a memorial published in the [[Association for Computing Machinery|ACM]] [[SIGMOD]] Record&lt;ref name=memory/&gt; in 2005. Beyond his contributions to Computer Science theory, he was remembered for the clarity of focus he brought to research and the seriousness with which he took his role as an advisor to PhD students. He was also remembered for his generous support of younger researchers. Those who benefitted from Ginsburg's mentorship,  who were not also his PhD students, included: [[Jonathan Goldstine]], [[Sheila Greibach]], [[Michael A. Harrison]], [[Richard Hull (computer scientist)|Richard Hull]], and [[Jeff Ullman]].

== Professional Contributions ==

Ginsburg's early work concentrated on [[automata theory]]. In 1958, he proved that "[[don't-care term|don't-care]]" circuit minimization does not necessarily yield a minimal result.&lt;ref&gt;{{Citation|doi=10.1145/320964.320983|last=Ginsburg|first=Seymour|title=On the Reduction of Superfluous States in a Sequential Machine|journal=J. ACM|year=1959|volume=6|issue=2|pages=259–282}}&lt;/ref&gt; His work in automata theory led the switching theory community into a more theoretical direction. This work culminated in the publication of a book on the mathematics of machines in 1962.&lt;ref&gt;{{Citation|first=Seymour|last=Ginsburg|title=Introduction to Mathematical Machine Theory|publisher=Addison Wesley|year=1962}}&lt;/ref&gt;

Ginsburg turned his attention to [[formal language theory]] in the 1960s. He studied [[context-free grammar]]s and published a well-known comprehensive overview of context-free languages in 1966.&lt;ref&gt;{{Citation|last=Ginsburg|first=Seymour|title=The Mathematical Theory of Context-free Languages|year=1966|publisher=McGraw-Hill|publication-place=New  York, San Francisco, St. Louis, Toronto, London, Sydney}}&lt;/ref&gt; Ginsburg was the first to observe the connection between [[context-free language]]s and "[[ALGOL]]-like" languages.&lt;ref&gt;{{Citation|doi=10.1145/321127.321132|last=Ginsburg|first=Seymour|last2=Rice|first2=H. Gordon|title=Two Families of Languages Related to ALGOL|journal=J. ACM|volume=9|issue=3|year=1962|pages=350–371}}&lt;/ref&gt;  This brought the field of [[formal language theory]] to bear on [[programming language]] research. Ginsburg's results on context-free grammars and push-down acceptors are considered to be some of the deepest and most beautiful in the area. They remain standard tools for many computer scientists working in the areas of formal languages and automata.&lt;ref name=memory/&gt; Many of his papers at this time were co-authored with other prominent formal language researchers, including [[Sheila Greibach]], and [[Michael A. Harrison]].

The unification of different views of formal systems was a constant theme in Ginsburg's work.&lt;ref name=memory/&gt; In formal language theory his papers examined the relationships between grammar-based systems, acceptor-based systems, and algebraic characterizations of families of languages. The culmination of this work was the creation of one of the deepest branches of [[Computer Science]], [[Abstract Families of Languages]], in collaboration with [[Sheila Greibach]] in 1967.&lt;ref&gt;{{Citation|first1=Seymour|last1=Ginsburg|first2=Sheila A.|last2=Greibach|title=Abstract Families of Languages|journal=FOCS|year=1967|pages=128–139}}&lt;/ref&gt;&lt;ref&gt;{{Citation|first=Seymour|last=Ginsburg|title='Algebraic and automata theoretic properties of formal languages|publisher=North-Holland|year=1975|isbn=0-7204-2506-9}}&lt;/ref&gt;

In 1974, Ginsburg, along with [[Armin B. Cremers]], developed the theory of Grammar Forms.&lt;ref&gt;{{Citation|doi=10.1145/321812.321817|first1=Armen|last1=Gabrielian|first2=Seymour|last2=Ginsburg|title=Grammar Schemata|journal=J. ACM|volume=21|issue=2|year=1974|pages=213–226}}&lt;/ref&gt;&lt;ref&gt;{{Citation|first1=Armin B.|last1=Cremers|last2=Ginsburg|first2=Seymour|title=Context-Free Grammar Forms|journal=Automata, Languages and Programming, 2nd Colloquium, University of Saarbrücken, July 29 - August 2, 1974, Proceedings|editor=Jacques Loeckx|publisher=Springer|series=Lecture Notes in Computer Science|volume=14|year=1974|isbn=3-540-06841-4}}&lt;/ref&gt;&lt;ref&gt;{{Citation|last=Ginsburg|first=Seymour|title=A survey of grammar forms - 1977|journal=Acta Cybernetica|volume=3|year=1977|pages=269–280}}&lt;/ref&gt;

In the 1980s, Ginsburg became an early pioneer in the field of [[Database]] Theory.  He continued to work in this field until his retirement. His professional contributions spanned subjects as diverse as [[Functional dependency]],&lt;ref&gt;{{Citation|first1=Seymour|last1=Ginsburg|first2=Richard|last2=Hull|title=Characterization for Functional Dependency and Boyce-Codd Normal Form Databases|journal=XP2 Workshop on Relational Database Theory|year=1981}}&lt;/ref&gt;&lt;ref&gt;{{Citation|doi=10.1145/322326.322331|last1=Ginsburg|first1=Seymour|first2=Sami Mohammed|last2=Zaiddan|title= Properties of functional-dependency families|journal=J. ACM|volume=29|issue=3|year=1982|pages=678–698}}&lt;/ref&gt; object histories,&lt;ref&gt;{{Citation|doi=10.1145/5922.5924|first1=Seymour|last1=Ginsburg|first2=Katsumi|last2=Tanaka|title=Computation-Tuple Sequences and Object Histories|journal=ACM Trans. Database Syst.|volume=11|issue=2|year=1986|pages=186–212}}&lt;/ref&gt; spreadsheet histories,&lt;ref&gt;{{Citation|first1=Seymour|last1=Ginsburg|first2=Stephen|last2=Kurtzman|title=Object-History and Spreadsheet P-Simulation|journal=ICDT'88, 2nd International Conference on Database Theory, Bruges, Belgium, August 31 - September 2, 1988, Proceedings|editor1=Marc Gyssens|editor2=Jan Paredaens|editor3=Dirk Van Gucht|series=Lecture Notes in Computer Science|volume=326|year=1988|pages=383–395|isbn=3-540-50171-1|publisher=Springer}}&lt;/ref&gt; [[Datalog]],&lt;ref&gt;{{Citation|doi=10.1016/0304-3975(90)90015-A|first1=Guozhu|last1=Dong|first2=Seymour|last2=Ginsburg|title=On the Decomposition of Datalog Program Mappings|journal=Theor. Comput. Sci.|volume=76|issue=1|year=1990|pages=143–177}}&lt;/ref&gt; and data restructuring.&lt;ref&gt;{{Citation|last1=Ginsburg|first1=Seymour|first2=Nan C.|last2=Shu|first3=Dan A.|last3=Simovici|title=Automatic Data Restructuring|journal=Journal of Universal Computer Science|volume=5|issue=4|year=1999|pages=243–299}}&lt;/ref&gt;

==See also==
* [[List of pioneers in computer science]]

== References ==
{{reflist}}

==External links==
*{{DBLP|name=Seymour Ginsburg}}
*{{MathGenealogy}}

{{Authority control}}

{{DEFAULTSORT:Ginsburg, Seymour}}
[[Category:1927 births]]
[[Category:2004 deaths]]
[[Category:American computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:City College of New York alumni]]
[[Category:University of Miami faculty]]
[[Category:University of Michigan alumni]]
[[Category:University of Southern California faculty]]
[[Category:Guggenheim Fellows]]</text>
      <sha1>c3ce9luyl0352y2zwxi7ruy99ck3rd4</sha1>
    </revision>
  </page>
  <page>
    <title>Simultaneous algebraic reconstruction technique</title>
    <ns>0</ns>
    <id>45254486</id>
    <revision>
      <id>800270216</id>
      <parentid>800270185</parentid>
      <timestamp>2017-09-12T13:37:03Z</timestamp>
      <contributor>
        <username>Tony1</username>
        <id>332841</id>
      </contributor>
      <minor/>
      <comment>Tony1 moved page [[Simultaneous Algebraic Reconstruction Technique]] to [[Simultaneous algebraic reconstruction technique]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2779">The '''SART''' algorithm&lt;ref&gt;{{cite journal | last1 = Andersen | first1 = A. | last2 = Kak | first2 = A. | year = 1984 | title = Simultaneous Algebraic Reconstruction Technique (SART): A Superior Implementation of ART | url = http://www.sciencedirect.com/science/article/pii/0161734684900087 | journal = Ultrasonic Imaging| volume =  6| issue = | pages =  81–94| doi=10.1016/0161-7346(84)90008-7}}&lt;/ref&gt; ('''simultaneous algebraic reconstruction technique'''), proposed by Anders Andersen and [[Avinash Kak]] in 1984, has had a major impact in [[computerized tomography]] (CT) imaging applications where the projection data is limited.  It generates a good reconstruction in just one iteration and  it is superior to standard algebraic reconstruction technique (ART).

As a measure of its popularity, researchers have proposed various extensions to 
SART: OS-SART, FA-SART, VW-OS-SART,&lt;ref&gt;http://www.hindawi.com/journals/ijbi/2006/010398/abs/&lt;/ref&gt; SARTF, etc. Researchers have also studied how SART can best be implemented on different [[Parallel computing|parallel processing]] architectures. SART and its proposed extensions are used in emission CT in [[nuclear medicine]], dynamic CT, and holographic [[tomography]], and other reconstruction applications.&lt;ref&gt;Byrne, C. A unified treatment of some iterative algorithms in signal processing and image reconstruction. Inverse Problems 20 103 (2004)&lt;/ref&gt;  Convergence
of the SART algorithm was theoretically established in 2004 by Jiang and Wang.&lt;ref&gt;{{cite journal | last1 = Jiang | first1 = M. | last2 = Wang | first2 = G. | year = 2003 | title = Convergence of the simultaneous algebraic reconstruction technique (SART) | url = | journal = IEEE Transactions on Image Processing | volume = 12 | issue = | pages = 957–961 | doi=10.1109/tip.2003.815295}}&lt;/ref&gt; Further convergence analysis was done by Yan.&lt;ref&gt;ftp://ftp.math.ucla.edu/pub/camreport/cam10-27.pdf&lt;/ref&gt;

An application of SART to ionosphere was presented by Hobiger et al.&lt;ref&gt;http://www.terrapub.co.jp/journals/EPS/abstract/6007/60070727.html&lt;/ref&gt; Their  method does not use matrix algebra and therefore it can be implemented in a low-level programming language. Its convergence speed is significantly higher than that of classical SART. A discrete version of SART called DART was developed by Batenburg and Sijbers.&lt;ref&gt;{{cite journal | last1 = Batenburg | first1 = K.J. | last2 = Sijbers | first2 = J. | year = 2011 | title = DART: a practical reconstruction algorithm for discrete tomography | url = | journal = IEEE Transactions on Image Processing | volume = 20 | issue = 9| pages = 2542–2553 | doi=10.1109/tip.2011.2131661}}&lt;/ref&gt;

== References ==

&lt;references /&gt;

[[Category:Radiology]]
[[Category:Medical imaging]]
[[Category:Inverse problems]]</text>
      <sha1>glt3aq9lg59ida9s1kgqo24a8wk6t2l</sha1>
    </revision>
  </page>
  <page>
    <title>Sylver coinage</title>
    <ns>0</ns>
    <id>896746</id>
    <revision>
      <id>761996664</id>
      <parentid>761995656</parentid>
      <timestamp>2017-01-26T01:39:17Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* top */ must eventually end</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6966">'''Sylver coinage''' is a [[mathematical game]] for two players, invented by [[John H. Conway]].  It is discussed in chapter 18 of
''[[Winning Ways for Your Mathematical Plays]]''.  This article summarizes that chapter.  

The two players take turns naming positive [[integers]] that are not the sum of nonnegative multiples of previously named integers.  
After 1 is named, all positive integers can be expressed in this way:
1&amp;nbsp;=&amp;nbsp;1, 2&amp;nbsp;=&amp;nbsp;1&amp;nbsp;+&amp;nbsp;1, 3&amp;nbsp;=&amp;nbsp;1&amp;nbsp;+&amp;nbsp;1&amp;nbsp;+&amp;nbsp;1, etc., ending the game.  The player who named 1 loses.

Sylver coinage is named after
[[James Joseph Sylvester]], who proved that if ''a'' and ''b''
are [[relatively prime]] positive integers, then (''a''&amp;nbsp;−&amp;nbsp;1)(''b''&amp;nbsp; −&amp;nbsp;1)&amp;nbsp;−&amp;nbsp;1 is the largest number that is not a sum of nonnegative multiples of ''a'' and ''b''.  Thus, if ''a'' and ''b'' are the first two moves in a game of sylver coinage, this formula gives the largest number that can still be played. More generally, if
the [[greatest common divisor]] of the moves played so far is ''g'', then only finitely many multiples of ''g'' can remain to be played, and after they are all played then ''g'' must decrease on the next move. Therefore, every game of sylver coinage must eventually end. 
When a sylver coinage game has only a finite number of remaining moves, the largest number that can still be played is called the [[Frobenius number]], and finding this number is called the [[coin problem]].

== Example ==
A sample game between A and B:
* A opens with 5. Now neither player can name 5, 10, 15, ....
* B names 4. Now neither player can name 4, 5, 8, 9, 10, or any number greater than 11.
* A names 11. Now the only remaining numbers are 1, 2, 3, 6, and 7.
* B names 6. Now the only remaining numbers are 1, 2, 3, and 7.
* A names 7. Now the only remaining numbers are 1, 2, and 3.
* B names 2. Now the only remaining numbers are 1 and 3.
* A names 3, leaving only 1.
* B is forced to name 1 and loses.

Each of A's moves was to a winning position.

==Analysis==
Unlike many similar mathematical games, sylver coinage has not been completely solved, mainly because many positions have infinitely many possible moves.  Furthermore, the main theorem that identifies a class of winning positions, due to R. L. Hutchings, guarantees that such a position has a winning strategy but does not identify the strategy.  Hutchings's Theorem states that any of the [[prime number]]s 5, 7, 11, 13, …, wins as a first move, but very little is known about the subsequent winning moves: these are the only winning openings known.

When the [[greatest common divisor]] of the moves that have been made so far is 1, the remaining set of numbers that can be played will be a [[finite set]], and can be described mathematically as the set of gaps of a [[numerical semigroup]]. Some of these finite positions, including all of the positions after the second player has responded to one of Hutchings' winning moves, allow a special move that Sicherman calls an "ender".
An ender is a number that may only be played immediately: playing any other number would rule it out. If an ender exists, it is always the largest number that can still be played. For instance, after the moves (4,5), the largest number that can still be played is 11. Playing 11 cannot rule out any smaller numbers, but playing any of the smaller available numbers (1, 2, 3, 6, or 7) would rule out playing 11, so 11 is an ender. When an ender exists, the next player can win by following a [[strategy-stealing argument]]. If one of the non-ender moves can win, the next player takes that winning move. And if none of the non-ender moves wins, then the next player can win by playing the ender and forcing the other player to make one of the other non-winning moves. However, although this argument proves that the next player can win, it does not identify a winning strategy for the player. After playing a prime number that is 5 or larger as a first move, the first player in a game of sylver coinage can always win by following this (non-constructive) ender strategy on their next turn.

{{unsolved|mathematics|Are there any non-prime winning opening moves in sylver coinage?}}
If there are any other winning openings, they must be 3-[[smooth number]]s (numbers of the form {{math|2&lt;sup&gt;''i''&lt;/sup&gt;3&lt;sup&gt;''j''&lt;/sup&gt;}} for non-negative integers {{mvar|i}} and {{mvar|j}}).
For, if any number {{mvar|n}} that is not of this form and is not prime is played, then the second player can win by choosing a large prime factor of {{mvar|n}}.
The first few 3-smooth numbers, 1, 2, 3, 4, 6, 8, 9, and 12, are all losing openings, for which complete strategies are known by which the second player can win.
By [[Dickson's lemma]] (applied to the pairs of exponents {{math|(''i'', ''j'')}} of these numbers), only finitely many 3-smooth numbers can be winning openings, but it is not known whether any of them are.

==References==
* {{cite book | title = [[Winning Ways for your Mathematical Plays]], Vol. II: Games in Particular | publisher = Academic Press| year = 1982 | first1 =  Elwyn R. |last1 = Berlekamp | author1-link = Elwyn Berlekamp | first2 = John H. | last2 = Conway | 
author2-link = John Horton Conway| first3 = Richard K. |last3 = Guy | author3-link =  Richard K. Guy | chapter = 18.  The Emperor and His Money | pages = 575–606 | chapter-url = http://www.link.cs.cmu.edu/15859-s11/notes/sylver-coinage.pdf}}
* {{cite journal | last = Guy | first = Richard K. | authorlink=Richard K. Guy | doi = 10.2307/2319892 | issue = 8 | journal = [[American Mathematical Monthly]] | mr = 1538138 | pages = 634–637 | department = Research Problems | title = Twenty questions concerning Conway's Sylver Coinage | volume = 83 | year = 1976}}
* {{cite book |last=Guy | first=Richard K. | authorlink=Richard K. Guy | title=Unsolved problems in number theory | publisher=[[Springer-Verlag]] |edition=3rd | year=2004 |isbn=978-0-387-20860-2 | at=C7 | zbl=1058.11001 }}
*{{cite book | title = How to Guard an Art Gallery and Other Discrete Mathematical Adventures | first = T. S. | last = Michael | publisher = JHU Press | year = 2009 | isbn = 9780801897047 | chapter = 6. From Stamps to Sylver Coins | pages = 169–206 | url = https://books.google.com/books?id=zW0EFRjsfdUC&amp;pg=PA169}}
* {{cite journal | first = George | last = Sicherman  | title = Theory and Practice of Sylver Coinage | journal = Integers | year = 2002 | volume = 2 | at = G2 | url = http://www.integers-ejcnt.org/cg2/cg2.pdf}}
* {{cite journal | first=James J. | last=Sylvester | authorlink=James Joseph Sylvester | department=Mathematical Questions |journal= Educational Times | volume=41 | year=1884 | page=21 | title= Question 7382 }}

==External links==
* [http://www.monmouth.com/~colonel/sylver/ The Sylver Coinage Page]

[[Category:Mathematical games]]
[[Category:Combinatorial game theory]]
[[Category:Recreational mathematics]]</text>
      <sha1>so6493srrom04vrasyxg3kjo6yytnbn</sha1>
    </revision>
  </page>
  <page>
    <title>Tree stack automaton</title>
    <ns>0</ns>
    <id>50818263</id>
    <revision>
      <id>818605482</id>
      <parentid>801020903</parentid>
      <timestamp>2018-01-04T14:48:37Z</timestamp>
      <contributor>
        <username>Tdenk</username>
        <id>28571479</id>
      </contributor>
      <comment>/* Tree stack automata */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8313">A tree stack automaton{{efn|not to be confused with a device with the same name introduced in 1990 by Wolfgang Golubski and Wolfram-M. Lippe &lt;ref name="GolLip90"&gt;Golubski, Wolfgang and Lippe, Wolfram-M. (1990). ''Tree-stack automata''. Proceedings of the 15th Symposium on Mathematical Foundations of Computer Science (MFCS 1990). Lecture Notes in Computer Science, Vol. 452, pages 313–321, [http://www.dx.doi.org/10.1007/BFb0029624 doi:10.1007/BFb0029624].&lt;/ref&gt;}} (plural: tree stack automata) is a [[formalism (philosophy of mathematics)|formalism]] considered in [[automata theory]]. It is a [[finite state automaton]] with the additional ability to manipulate a [[Tree (set theory)#Tree (automata theory)|tree]]-shaped [[Stack (abstract data type)|stack]]. It is an automaton with storage&lt;ref name="Sco67"&gt;Scott, Dana (1967). ''Some Definitional Suggestions for Automata Theory''. Journal of Computer and System Sciences, Vol. 1(2), pages 187–212, [http://www.dx.doi.org/10.1016/s0022-0000(67)80014-x doi:10.1016/s0022-0000(67)80014-x].&lt;/ref&gt; whose storage roughly resembles the configurations of a [[thread automaton]]. A restricted class of tree stack automata recognises exactly the [[formal language|languages]] generated by multiple [[context-free grammar]]s&lt;ref name="Den16"&gt;Denkinger, Tobias (2016). ''An automata characterisation for multiple context-free languages''. Proceedings of the 20th International Conference on Developments in Language Theory (DLT 2016). Lecture Notes in Computer Science, Vol. 9840, pages 138–150, [https://link.springer.com/chapter/10.1007/978-3-662-53132-7_12 doi:10.1007/978-3-662-53132-7_12].&lt;/ref&gt; (or [[Generalized context-free grammar#Linear Context-free Rewriting Systems (LCFRSs)|linear context-free rewriting systems]]).

==Definition==
===Tree stack===
[[File:Tree stack.svg|thumb|A tree stack with stack pointer 1.2 and domain {''ε'', 1, 42, 1.2, 1.5, 1.5.3}]]

For a finite and non-empty set {{math|''Γ''}}, a ''tree stack over {{math|{{var|Γ}}}}'' is a tuple {{math|(''t'', ''p'')}} where
* {{math|''t''}} is a [[partial function]] from strings of positive integers to the set {{math|''Γ'' ∪ {@}}} with [[Substring#Prefix|prefix]]-closed{{efn|A set of strings is ''prefix-closed'' if for every element {{math|''w''}} in the set, all prefixes of {{math|''w''}} are also in the set.}} [[domain of a function|domain]] (called ''tree''),
* {{math|@}} (called ''bottom symbol'') is not in {{math|''Γ''}} and appears exactly at the root of {{math|''t''}}, and
* {{math|''p''}} is an element of the domain of {{math|''t''}} (called ''stack pointer'').
The set of all tree stacks over {{math|''Γ''}} is denoted by {{math|TS(''Γ'')}}.

The set of ''predicates'' on {{math|TS(''Γ'')}}, denoted by {{math|Pred(''Γ'')}}, contains the following [[unary operation|unary]] [[predicate (mathematical logic)|predicates]]:
* {{math|true}} which is true for any tree stack over {{math|''Γ''}},
* {{math|bottom}} which is true for tree stacks whose stack pointer points to the bottom symbol, and
* {{math|equals(''γ'')}} which is true for some tree stack {{math|(''t'', ''p'')}} if {{math|''t''(''p'') {{=}} ''γ''}},
for every {{math|''γ'' ∈ ''Γ''}}.

The set of ''instructions'' on {{math|TS(''Γ'')}}, denoted by {{math|Instr(''Γ'')}}, contains the following partial functions:
* {{math|id: TS(''Γ'') → TS(''Γ'')}} which is the identity function on {{math|TS(''Γ'')}},
* {{math|push&lt;sub&gt;''n'',''γ''&lt;/sub&gt;: TS(''Γ'') → TS(''Γ'')}} which adds for a given tree stack {{math|(''t'',''p'')}} a pair {{math|(''pn'' ↦ ''γ'')}} to the tree {{math|''t''}} and sets the stack pointer to {{math|''pn''}} (i.e. it pushes {{math|''γ''}} to the {{math|''n''}}-th child position) if {{math|''pn''}} is not yet in the domain of {{math|''t''}},
* {{math|up&lt;sub&gt;''n''&lt;/sub&gt;: TS(''Γ'') → TS(''Γ'')}} which replaces the current stack pointer {{math|''p''}} by {{math|''pn''}} (i.e. it moves the stack pointer to the {{math|''n''}}-th child position) if {{math|''pn''}} is in the domain of {{math|''t''}},
* {{math|down: TS(''Γ'') → TS(''Γ'')}} which removes the last symbol from the stack pointer (i.e. it moves the stack pointer to the parent position), and 
* {{math|set&lt;sub&gt;''γ''&lt;/sub&gt;: TS(''Γ'') → TS(''Γ'')}} which replaces the symbol currently under the stack pointer by {{math|''γ''}}, 
for every positive integer {{math|''n''}} and every {{math|''γ'' ∈ ''Γ''}}.

{|style="margin: 0 auto;"
| [[File:Id on a tree stack.svg|thumb|Illustration of the instruction id on a tree stack]]
| [[File:Push on a tree stack.svg|thumb|Illustration of the instruction push on a tree stack]]
| [[File:Up and down on a tree stack.svg|thumb|Illustration of the instructions up and down on a tree stack]]
| [[File:Set on a tree stack.svg|thumb|Illustration of the instruction set on a tree stack]]
|}

===Tree stack automata===
A ''tree stack automaton'' is a 6-tuple {{math|''A'' {{=}} (''Q'', ''Γ'', ''Σ'', ''q''&lt;sub&gt;i&lt;/sub&gt;, ''δ'', ''Q''&lt;sub&gt;f&lt;/sub&gt;)}} where
* {{math|''Q''}}, {{math|''Γ''}}, and {{math|''Σ''}} are finite sets (whose elements are called ''states'', ''stack symbols'', and ''input symbols'', respectively),
* {{math|''q''&lt;sub&gt;i&lt;/sub&gt; &amp;isin; ''Q''}} (the ''initial state''),
* {{math|''δ'' &amp;sube;&lt;sub&gt;fin.&lt;/sub&gt; ''Q'' × (''Σ'' ∪ {''ε''}) × Pred(''Γ'') × Instr(''Γ'') × ''Q''}} (whose elements are called ''transitions''), and
* {{math|''Q''&lt;sub&gt;f&lt;/sub&gt; &amp;sube; TS(''Γ'')}} (whose elements are called ''final states'').

A ''configuration of {{math|{{var|A}}}}'' is a tuple {{math|(''q'', ''c'', ''w'')}} where
* {{math|''q''}} is a state (the ''current state''),
* {{math|''c''}} is a tree stack (the ''current tree stack''), and
* {{math|''w''}} is a word over {{math|''Σ''}} (the ''remaining word'' to be read).

A transition {{math|''τ'' {{=}} (''q''&lt;sub&gt;1&lt;/sub&gt;, ''u'', ''p'', ''f'', ''q''&lt;sub&gt;2&lt;/sub&gt;)}} is ''applicable'' to a configuration {{math|(''q'', ''c'', ''w'')}} if
* {{math|''q''&lt;sub&gt;1&lt;/sub&gt; {{=}} ''q''}},
* {{math|''p''}} is true on {{math|''c''}},
* {{math|''f''}} is defined for {{math|''c''}}, and
* {{math|''u''}} is a prefix of {{math|''w''}}.
The ''transition relation of {{math|{{var|A}}}}'' is the [[binary relation]] {{math|⊢}} on configurations of {{math|{{var|A}}}} that is the union of all the relations {{math|⊢&lt;sub&gt;''τ''&lt;/sub&gt;}} for a transition {{math|''τ'' {{=}} (''q''&lt;sub&gt;1&lt;/sub&gt;, ''u'', ''p'', ''f'', ''q''&lt;sub&gt;2&lt;/sub&gt;)}} where, whenever {{math|''τ''}} is applicable to {{math|(''q'', ''c'', ''w'')}}, we have {{math|(''q'', ''c'', ''w'') ⊢&lt;sub&gt;''τ''&lt;/sub&gt; (''q''&lt;sub&gt;2&lt;/sub&gt;, ''f''(''c''), ''v'')}} and {{math|''v''}} is obtained from {{math|''w''}} by removing the prefix {{math|''u''}}.

The ''language of {{math|{{var|A}}}}'' is the set of all words {{math|''w''}} for which there is some state {{math|''q'' ∈ ''Q''&lt;sub&gt;f&lt;/sub&gt;}} and some tree stack {{math|''c''}} such that {{math|(''q''&lt;sub&gt;i&lt;/sub&gt;, ''c''&lt;sub&gt;i&lt;/sub&gt;, w) ⊢&lt;sup&gt;*&lt;/sup&gt; (''q'', ''c'', ''ε'')}} where
* {{math|⊢&lt;sup&gt;*&lt;/sup&gt;}} is the [[Binary relation#Operations on binary relations|reflexive transitive closure]] of {{math|⊢}} and
* {{math|''c''&lt;sub&gt;i&lt;/sub&gt; {{=}} (''t''&lt;sub&gt;i&lt;/sub&gt;, ''ε'')}} such that {{math|''t''&lt;sub&gt;i&lt;/sub&gt;}} assigns for {{math|''ε''}} the symbol {{math|@}} and is undefined otherwise.

==Related formalisms==
Tree stack automata are equivalent to [[Turing machine|Turing machines]].

A tree stack automaton is called ''{{math|{{var|k}}}}-restricted'' for some positive natural number {{math|{{var|k}}}} if, during any run of the automaton, any position of the tree stack is accessed at most {{math|''k''}} times from below.

1-restricted tree stack automata are equivalent to [[pushdown automaton|pushdown automata]] and therefore also to [[context-free grammar|context-free grammars]].
{{math|''k''}}-restricted tree stack automata are equivalent to [[Generalized context-free grammar#Linear Context-free Rewriting Systems (LCFRSs)|linear context-free rewriting systems]] and multiple context-free grammars of fan-out at most {{math|''k''}} (for every positive integer {{math|''k''}}).&lt;ref name="Den16" /&gt;

==Notes==
{{notelist}}

==References==
{{reflist}}

{{Formal languages and grammars}}
[[Category:Models of computation]]
[[Category:Automata (computation)]]</text>
      <sha1>10zrh5r8f6ksg04i8y8jd8jwo0lztus</sha1>
    </revision>
  </page>
  <page>
    <title>Tutte embedding</title>
    <ns>0</ns>
    <id>39503349</id>
    <revision>
      <id>866382835</id>
      <parentid>866382722</parentid>
      <timestamp>2018-10-30T00:39:02Z</timestamp>
      <contributor>
        <username>Bsvineethiitg</username>
        <id>35012683</id>
      </contributor>
      <comment>aesthetic fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13547">In [[graph drawing]] and [[geometric graph theory]], a '''Tutte embedding''' or '''barycentric embedding''' of a [[simple graph|simple]] [[k-vertex-connected graph|3-vertex-connected]] [[planar graph]] is a [[Fáry's theorem|crossing-free straight-line embedding]] with the properties that the outer face is a [[convex polygon]] and that each interior vertex is at the [[Centroid|average]] (or barycenter) of its neighbors' positions. If the outer polygon is fixed, this condition on the interior vertices determines their position uniquely as the solution to a [[system of linear equations]]. Solving the equations geometrically produces a '''[[planar graph|planar embedding]]'''. '''Tutte's spring theorem''', proven by {{harvs|authorlink=W. T. Tutte|first=W. T.|last=Tutte|year=1963|txt}}, states that this unique solution is always crossing-free, and more strongly that every face of the resulting planar embedding is convex.&lt;ref&gt;{{Citation
 | last = Tutte | first = W. T. | authorlink = W. T. Tutte
 | title = How to draw a graph
 | journal = Proceedings of the London Mathematical Society
 | volume = 13
 | year = 1963
 | pages = 743–767
 | mr = 0158387
 | doi = 10.1112/plms/s3-13.1.743}}.&lt;/ref&gt; It is called the spring theorem because such an embedding can be found as the equilibrium position for a system of [[Spring (device)|springs]] representing the edges of the graph.

==Example==
[[File:Tutte cube.svg|thumb|Tutte embedding of the graph of a cube. The outer four vertices are fixed at the corners of a [[:en:Unit square|unit square]] and each remaining vertex is at the average of its neighbors' positions.]]
Let ''G'' be the graph of a cube, and (selecting one of its quadrilateral faces as the outer face) fix the four vertices of the outer face at the four corners of a [[unit square]], the points whose ''x'' and ''y'' coordinates are all four combinations of zero and one.
Then, if the remaining four vertices are placed at the four points whose ''x'' and ''y'' coordinates are combinations of 1/3 and 2/3, as in the figure, the result will be a Tutte embedding. For, at each interior vertex ''v'' of the embedding, and for each of the two coordinates, the three neighbors of ''v'' have coordinate values that are equal to ''v'', smaller by 1/3, and larger by 1/3; the average of these values is the same as the coordinate value of ''v'' itself.

==System of linear equations==
The condition that a vertex ''v'' be at the average of its neighbors' positions may be expressed as two [[linear equation]]s, one for the ''x''&amp;nbsp;coordinate of&amp;nbsp;''v'' and another for the ''y''&amp;nbsp;coordinate of&amp;nbsp;''v''. For a graph with ''n'' vertices, ''h'' of which are fixed in position on the outer face, there are two equations for each interior vertex and also two unknowns (the coordinates) for each interior vertex. Therefore, this gives a [[system of linear equations]] with 2(''n''&amp;nbsp;&amp;minus;&amp;nbsp;''h'') equations in 2(''n''&amp;nbsp;&amp;minus;&amp;nbsp;''h'') unknowns, the solution to which is a Tutte embedding. As {{harvtxt|Tutte|1963}} showed, for 3-vertex-connected planar graphs, this system is non-degenerate. Therefore, it has a unique solution, and (with the outer face fixed) the graph has a unique Tutte embedding. This embedding can be found in [[polynomial time]] by solving the system of equations, for instance by using [[Gaussian elimination]].&lt;ref name="rote"/&gt;

==Polyhedral representation==
By [[Steinitz's theorem]], the 3-connected planar graphs to which Tutte's spring theorem applies coincide with the [[polyhedral graph]]s, the graphs formed by the vertices and edges of a [[convex polyhedron]]. According to the [[Maxwell–Cremona correspondence]], a two-dimensional embedding of a planar graph forms the vertical projection of a three-dimensional convex polyhedron if and only if the embedding has an ''equilibrium stress'', an assignment of forces to each edge (affecting both endpoints in equal and opposite directions parallel to the edge) such that the forces cancel at every vertex. For a Tutte embedding, assigning to each edge an attractive force proportional to its length (like a spring) makes the forces cancel at all interior vertices, but this is not necessarily an equilibrium stress at the vertices of the outer polygon. However, when the outer polygon is a triangle, it is possible to assign repulsive forces to its three edges to make the forces cancel there, too. In this way, Tutte embeddings can be used to find [[Schlegel diagram]]s of every [[convex polyhedron]]. For every 3-connected planar graph ''G'', either ''G'' itself or the [[dual graph]] of ''G'' has a triangle, so either this gives a polyhedral representation of ''G'' or of its dual; in the case that the dual graph is the one with the triangle, [[Dual polyhedron#Polar reciprocation|polarization]] gives a polyhedral representation of ''G'' itself.&lt;ref name="rote"&gt;{{citation|contribution=Realizing planar graphs as convex polytopes|first=Günter|last=Rote|title=Graph Drawing: 19th International Symposium, GD 2011, Eindhoven, The Netherlands, September 21–23, 2011, Revised Selected Papers|year=2012|publisher=Springer|series=Lecture Notes in Computer Science|pages=238–241|doi=10.1007/978-3-642-25878-7_23|volume=7034}}.&lt;/ref&gt;

==Applications in Geometry Processing==
In geometry processing, Tutte's embedding is used for 2D ''uv''-parametrization &lt;math&gt;\mathcal{S}^*&lt;/math&gt;of 3D surfaces &lt;math&gt;\mathcal{S}&lt;/math&gt; most commonly for the cases where the topology of the surface remains the same across &lt;math&gt;\mathcal{S}&lt;/math&gt; and &lt;math&gt;\mathcal{S}^*&lt;/math&gt;(disk topology). Tutte's method minimizes the total distortion energy of the parametrized space by considering each transformed vertex as a point mass, and edges across the corresponding vertices as springs. The tightness of each spring is determined by the length of the edges in the original 3D surface to preserve the shape. Since it is reasonable to have smaller parametrized edge lengths for the smaller edges of &lt;math&gt;\mathcal{S}&lt;/math&gt;, and larger parametrized edge lengths for the larger edges of &lt;math&gt;\mathcal{S}&lt;/math&gt;, the spring constants &lt;math&gt;w_{ij}&lt;/math&gt;are usually taken as the inverse of the absolute distance between the vertices &lt;math&gt;i,~j&lt;/math&gt; in the 3D space.

&lt;math&gt;\text{Distortion Energy,}~E=\Sigma _{(i,j)\in E(\mathcal{S})} ~w_{ij}~\|\textbf{u}_\text{i} - \textbf{u}_\text{j}\| ^ 2 \text{, where } w_{ij} = \frac{1}{\|\textbf{v}_\text{i} - \textbf{v}_\text{j}\|}\text{, } \{\textbf{u}_\text{i}\}\in\mathcal{S}^*\text{, }\{\textbf{v}_\text{i}\}\in\mathcal{S}&lt;/math&gt;

where &lt;math&gt;E(\mathcal{S})&lt;/math&gt; represents the set of edges in the original 3D surface. When the weights &lt;math&gt;w_{ij}&lt;/math&gt; are positive (as is the case above), it is guaranteed that the mapping is bijective without any inversions. But when no further constraints are applied, the solution that minimizes the distortion energy trivially collapses to a single point in the parametrized space. 

Therefore, one must provide boundary conditions where a set of known vertices of the 3D surface are mapped to known points in the 2D parametrized space. One common way of choosing such boundary conditions is to consider the vertices on the largest boundary loop of the original 3D surface which can be then constrained to be mapped to the outer ring of a unit disk in the 2D parametrized space. Note that if the 3D surface is a manifold, the boundary edges can be detected by verifying that they belong to only one face of the mesh.

Applications of parametrization in graphics and animation include texture mapping, among many others.

==Generalizations==

{{harvtxt|Colin de Verdiére|1991}} generalized Tutte's spring theorem to graphs on higher-[[genus (mathematics)|genus]] [[surface (topology)|surfaces]] with [[non-positive curvature]],&lt;ref&gt;{{citation
 | last1 = Colin de Verdiére | first1 = Yves.
 | doi = 10.5169/seals-58738
 | mr = 1151746 
 | issue = 3–4 
 | journal = L’Enseignement Mathématique
 | pages = 201–212
 | title = Comment rendre géodésique une triangulation d’une surface ?
 | volume = 37
 | year = 1991}}.&lt;/ref&gt; and {{harvtxt|Gortler|Gotsman|Thurston|2006}} proved analogous results for [[Toroidal graph|graphs embedded on a torus]].&lt;ref&gt;{{citation
 | last1 = Gortler | first1 = Steven J.
 | last2 = Gotsman | first2 = Craig
 | last3 = Thurston | first3 = Dylan
 | doi = 10.1016/j.cagd.2005.05.002
 | mr = 2189438
 | issue = 2
 | journal = Computer Aided Geometric Design
 | pages = 83–112
 | title = Discrete one-forms on meshes and applications to 3D mesh parameterization
 | volume = 23
 | year = 2006}}.&lt;/ref&gt;

{{harvtxt|Chilakamarri|Dean|Littman|1995}} investigate three-dimensional graph embeddings of the graphs of four-dimensional [[polytope]]s, formed by the same method as Tutte's embedding: choose one facet of the polytope as being the outer face of a three-dimensional embedding, and fix its vertices into place as the vertices of a three-dimensional polyhedron in space.
Let each remaining vertex of the polytope be free to move in space, and replace each edge of the polytope by a spring. Then, find the minimum-energy configuration of the system of springs. As they show, the system of equations obtained in this way is again non-degenerate, but it is unclear under what conditions this method will find an embedding that realizes all facets of the polytope as convex polyhedra.&lt;ref&gt;{{citation
 | last1 = Chilakamarri | first1 = Kiran
 | last2 = Dean | first2 = Nathaniel
 | last3 = Littman | first3 = Michael
 | department = Proceedings of the Twenty-sixth Southeastern International Conference on Combinatorics, Graph Theory and Computing (Boca Raton, FL, 1995)
 | journal = Congressus Numerantium
 | mr = 1369261
 | pages = 129–140
 | title = Three-dimensional Tutte embedding
 | volume = 107
 | year = 1995}}.&lt;/ref&gt;

==Related results==
The result that every [[simple graph|simple]] planar graph can be drawn with straight line edges is called [[Fáry's theorem]].&lt;ref&gt;For the relation between Tutte's and Fáry's theorem, and the history of rediscovery of Fáry's theorem, see {{citation|title=Geometric Graphs and Arrangements: Some Chapters from Combinatorial Geometry|series=Advanced Lectures in Mathematics|first=Stefan|last=Felsner|publisher=Springer|year=2012|isbn=9783322803030|page=37|url=https://books.google.com/books?id=szoDCAAAQBAJ&amp;pg=PA37}}.&lt;/ref&gt; The Tutte spring theorem proves this for 3-connected planar graphs, but the result is true more generally for planar graphs regardless of connectivity. Using the Tutte spring system for a graph that is not 3-connected may result in degeneracies, in which subgraphs of the given graph collapse onto a point or a line segment; however, an arbitrary planar graph may be drawn using the Tutte embedding by adding extra edges to make it 3-connected, drawing the resulting 3-connected graph, and then removing the extra edges.

A graph is [[k-vertex-connected graph|''k''-vertex-connected]], but not necessarily planar, if and only if it has an embedding into (''k''&amp;nbsp;&amp;minus;1)-dimensional space in which an arbitrary ''k''-tuple of vertices are placed at the vertices of a [[simplex]] and, for each remaining vertex ''v'', the [[convex hull]] of the neighbors of&amp;nbsp;''v'' is full-dimensional with ''v'' in its interior. If such an embedding exists, one can be found by fixing the locations of the chosen ''k'' vertices and solving a system of equations that places each vertex at the average of its neighbors, just as in Tutte's planar embedding.&lt;ref&gt;{{citation
 | last1 = Linial | first1 = N. | author1-link = Nati Linial
 | last2 = Lovász | first2 = L. | author2-link = László Lovász
 | last3 = Wigderson | first3 = A. | author3-link = Avi Wigderson
 | doi = 10.1007/BF02122557
 | issue = 1
 | journal = [[Combinatorica]]
 | mr = 951998
 | pages = 91–102
 | title = Rubber bands, convex embeddings and graph connectivity
 | volume = 8
 | year = 1988}}.&lt;/ref&gt;

In [[finite element method|finite element]] [[mesh generation]], [[Laplacian smoothing]] is a common method for postprocessing a generated mesh to improve the quality of its elements;&lt;ref&gt;{{citation
 | last = Herrmann | first = Leonard R.
 | issue = 5
 | journal = Journal of the Engineering Mechanics Division
 | pages = 749–907
 | title = Laplacian-isoparametric grid generation scheme
 | volume = 102
 | year = 1976}}.&lt;/ref&gt; it is particularly popular for [[quadrilateral mesh]]es, for which other methods such as [[Lloyd's algorithm]] for triangular mesh smoothing are less applicable. In this method, each vertex is moved to or towards the average of its neighbors' positions, but this motion is only performed for a small number of iterations, to avoid large distortions of element sizes or (in the case of non-convex mesh domains) tangled non-planar meshes.

[[Force-directed graph drawing]] systems continue to be a popular method for visualizing graphs, but these systems typically use more complicated systems of forces that combine attractive forces on graph edges (as in Tutte's embedding) with repulsive forces between arbitrary pairs of vertices. These additional forces may cause the system to have many locally stable configurations rather than, as in Tutte's embedding, a single global solution.&lt;ref&gt;{{citation|first=Stephen G.|last=Kobourov|title=Spring Embedders and Force-Directed Graph Drawing Algorithms|year=2012|arxiv=1201.3011|bibcode=2012arXiv1201.3011K}}.&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Planar graphs]]
[[Category:Graph drawing]]</text>
      <sha1>6j9k6pibdv3ttlb30uperton6jwfcso</sha1>
    </revision>
  </page>
  <page>
    <title>Verdier duality</title>
    <ns>0</ns>
    <id>7190735</id>
    <revision>
      <id>841692400</id>
      <parentid>839802230</parentid>
      <timestamp>2018-05-17T12:37:18Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <minor/>
      <comment>/* References */Journal cites, added 1 DOI</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7724">{{for|duality over number fields|Artin–Verdier duality}}
In [[mathematics]], '''Verdier duality''' is a duality in [[sheaf theory]] that generalizes [[Poincaré duality]] for [[manifold]]s. Verdier duality was introduced by {{harvs|txt|authorlink=Jean-Louis Verdier|last=Verdier|year1=1967|year2=1995}} as an analog for locally compact spaces of the  [[coherent duality]] for schemes due to [[Grothendieck]]. It is commonly encountered when studying constructible or [[perverse sheaves]].

==Verdier duality==
Verdier duality states that certain [[image functors for sheaves]] are actually [[adjoint functors]]. There are two versions.

'''Global Verdier duality''' states that for a continuous map &lt;math&gt; f: X \to Y &lt;/math&gt;,  the derived functor of the direct image with proper supports ''Rf''&lt;sub&gt;!&lt;/sub&gt; has a right adjoint ''f''&lt;sup&gt;!&lt;/sup&gt; in the derived category of sheaves, in other words, for a sheaf &lt;math&gt;\mathcal F&lt;/math&gt; on X and &lt;math&gt;\mathcal G&lt;/math&gt; on Y we have 
:&lt;math&gt;[Rf_!\mathcal{F},\mathcal{G}] \cong [\mathcal{F},f^!\mathcal{G}] . &lt;/math&gt;
The exclamation mark is often pronounced "shriek" (slang for exclamation mark), and the maps called "''f'' shriek" or "''f'' lower shriek" and "''f'' upper shriek" – see also [[shriek map]].

'''Local Verdier duality''' states that
:&lt;math&gt;R\,\mathcal{H}om(Rf_!\mathcal{F},\mathcal{G}) \cong Rf_{\ast}R\,\mathcal{H}om(\mathcal{F},f^!\mathcal{G})&lt;/math&gt;
in the [[derived category]] of sheaves of ''k'' modules over ''Y''. 
It is important to note that the distinction between the global and local versions is that the former relates maps between sheaves, whereas the latter relates (complexes of) sheaves directly and so can be evaluated locally. Taking global sections of both sides in the local statement gives global Verdier duality.

The '''dualizing complex''' ''D&lt;sub&gt;X&lt;/sub&gt;'' on ''X'' is defined to be
:&lt;math&gt;\omega_X = p^!(k) , &lt;/math&gt;
where ''p'' is the map from ''X'' to a point. Part of what makes Verdier duality interesting in the singular setting is that when ''X'' is not a manifold (a graph or singular algebraic variety for example) then the dualizing complex is not quasi-isomorphic to a sheaf concentrated in a single degree. From this perspective the derived category is necessary in the study of singular spaces.

If ''X'' is a finite-dimensional locally compact space, and ''D''&lt;sup&gt;''b''&lt;/sup&gt;(''X'') the bounded [[derived category]] of sheaves of abelian groups over ''X'', then the '''Verdier dual''' is a [[contravariant functor]]

:&lt;math&gt;D \colon D^b(X)\to D^b(X) &lt;/math&gt;

defined by

:&lt;math&gt;D(\mathcal{F}) = R\,\mathcal{H}om(\mathcal{F}, \omega_X) . &lt;/math&gt;

It has the following properties:

{{unordered list
|1= &lt;math&gt; D^2(\mathcal{F})\cong \mathcal{F}&lt;/math&gt; for sheaves with constructible cohomology.
|2= (Intertwining of functors ''f''&lt;sub&gt;*&lt;/sub&gt; and ''f''&lt;sub&gt;!&lt;/sub&gt;) If ''f'' is a continuous map from ''X'' to ''Y'' then there is an isomorphism
:&lt;math&gt;D(Rf_{!}(\mathcal{F})) \cong Rf_\ast D(\mathcal{F})&lt;/math&gt;.
}}

==Poincaré duality==
[[Poincaré duality]] can be derived as a special case of Verdier duality. Here one explicitly calculates cohomology of a space using the machinery of [[sheaf cohomology]].

Suppose ''X'' is a compact orientable ''n''-dimensional manifold, ''k'' is a field and ''k''&lt;sub&gt;X&lt;/sub&gt; is the constant sheaf on ''X'' with coefficients in ''k''. Let ''f=p'' be the constant map. Global Verdier duality then states
:&lt;math&gt;[Rp_!k_X,k] \cong [k_X,p^!k] . &lt;/math&gt;
To understand how Poincaré duality is obtained from this statement, it is perhaps easiest to understand both sides piece by piece. Let 
:&lt;math&gt;k_X\to (I^{\bullet}_X = I^0_X \to I^1_X \to \cdots) &lt;/math&gt; 
be an injective resolution of the constant sheaf. Then by standard facts on right derived functors 
:&lt;math&gt;Rp_!k_X=p_!I^{\bullet}_X=\Gamma_c(X;I^{\bullet}_X)&lt;/math&gt;
is a complex whose cohomology is the compactly supported cohomology of ''X''. Since morphisms between complexes of sheaves (or vector spaces) themselves form a complex we find that
:&lt;math&gt;\mathrm{Hom}^{\bullet}(\Gamma_c(X;I^{\bullet}_X),k)= \cdots \to \Gamma_c(X;I^2_X)^{\vee}\to \Gamma_c(X;I^1_X)^{\vee}\to \Gamma_c(X;I^0_X)^{\vee}\to 0&lt;/math&gt;
where the last non-zero term is in degree 0 and the ones to the left are in negative degree. Morphisms in the derived category are obtained from the [[homotopy category of chain complexes]] of sheaves by taking the zeroth cohomology of the complex, i.e.
:&lt;math&gt;[Rp_!k_X,k]\cong H^0(\mathrm{Hom}^{\bullet}(\Gamma_c(X;I^{\bullet}_X),k))=H^0_c(X;k_X)^{\vee}.&lt;/math&gt;

For the other side of the Verdier duality statement above, we have to take for granted the fact that when ''X'' is a compact orientable ''n''-dimensional manifold 
:&lt;math&gt;p^!k=k_X[n],&lt;/math&gt;
which is the dualizing complex for a manifold. Now we can re-express the right hand side as
:&lt;math&gt;[k_X,k_X[n]]\cong H^n(\mathrm{Hom}^{\bullet}(k_X,k_X))=H^n(X;k_X).&lt;/math&gt;
We finally have obtained the statement that
:&lt;math&gt;H^0_c(X;k_X)^{\vee}\cong H^n(X;k_X).&lt;/math&gt;
By repeating this argument with the sheaf ''k''&lt;sub&gt;X&lt;/sub&gt; replaced with the same sheaf placed in degree ''i'' we get the classical Poincaré duality
:&lt;math&gt;H^i_c(X;k_X)^{\vee}\cong H^{n-i}(X;k_X).&lt;/math&gt;

==See also==
*[[Six operators]]
*[[Coherent duality]]

==References==
&lt;references /&gt;
* {{Citation | last1=Borel | first1=Armand | author1-link=Armand Borel | title=Intersection cohomology | publisher=Birkhäuser | location=Basel, Boston, Berlin | series=Progress in Mathematics | isbn=978-0-8176-3274-8 | year=1984}}
* {{Citation | last1=Gelfand | first1=Sergei I. | last2=Manin | first2=Yuri Ivanovich | author2-link=Yuri Ivanovich Manin | title=Homological algebra | isbn=978-3-540-65378-3 | year=1999 | publisher=Springer | location=Berlin}}
* {{Citation | last1=Grothendieck | first1=Alexandre | author1-link=Alexandre Grothendieck | title=Séminaire de Géométrie Algébrique du Bois Marie - 1965-66 - Cohomologie l-adique et Fonctions L - (SGA 5) | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture notes in mathematics | isbn=978-3-540-08248-4 | year=1977 | volume=589 | pages=xii+484}}, Exposés I and II contain the corresponding theory in the étale situation
* {{Citation | last1=Iversen | first1=Birger | title=Cohomology of sheaves | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Universitext | isbn=978-3-540-16389-3 |mr=842190 | year=1986 | doi=10.1007/978-3-642-82783-9}}
* {{Citation | last1=Kashiwara | first1=Masaki | last2=Schapira | first2=Pierre | author1-link=Masaki Kashiwara | title=Sheaves on Manifolds | isbn=3540518614 | year=2002 | publisher=Springer | location=Berlin}}
*{{Citation | last1=Verdier | first1=Jean-Louis | author1-link=Jean-Louis Verdier | editor-last=Springer | editor1-first=Tonny Albert | title=Proceedings of a Conference on Local Fields: NUFFIC Summer School held at Driebergen (The Netherlands) in 1966 | url=https://books.google.com/books?id=SW-mAAAAIAAJ | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-03953-2 |mr=0230732 | year=1967 | chapter=A duality theorem in the etale cohomology of schemes | pages=184–198}}
*{{Citation | last1=Verdier | first1=Jean-Louis | author1-link=Jean-Louis Verdier | title=Séminaire Bourbaki, Vol. 9 | url=http://www.numdam.org/item?id=SB_1964-1966__9__337_0 | publisher=[[Société Mathématique de France]] | location=Paris | isbn=978-2-85629-042-2  |mr=1610971 | year=1995 | chapter=Dualité dans la cohomologie des espaces localement compacts | pages=Exp. No. 300, 337–349}}

{{DEFAULTSORT:Verdier Duality}}
[[Category:Topology]]
[[Category:Homological algebra]]
[[Category:Sheaf theory]]
[[Category:Duality theories]]</text>
      <sha1>grkl6tg0n5l5o1fgogii9om2xp5bot1</sha1>
    </revision>
  </page>
  <page>
    <title>Voronoi diagram</title>
    <ns>0</ns>
    <id>177668</id>
    <revision>
      <id>870857450</id>
      <parentid>864731884</parentid>
      <timestamp>2018-11-27T12:38:33Z</timestamp>
      <contributor>
        <username>Ladislav Mecir</username>
        <id>596030</id>
      </contributor>
      <comment>/* History and research */ remove red link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="34867">[[Image:Euclidean Voronoi diagram.svg|thumb|20 points and their Voronoi cells (larger version [[#Illustration|below]])]]
In [[mathematics]], a '''Voronoi diagram''' is a [[Partition of a set|partitioning]] of a [[plane (geometry)|plane]] into regions based on distance to points in a specific subset of the plane. That set of points (called seeds, sites, or generators) is specified beforehand, and for each seed there is a corresponding region consisting of all points closer to that seed than to any other. These regions are called Voronoi cells. The Voronoi diagram of a set of points is [[Duality (mathematics)|dual]] to its [[Delaunay triangulation]].

It is named after [[Georgy Voronoi]], and is also called a '''Voronoi tessellation''', a '''Voronoi decomposition''', a '''Voronoi partition''', or a '''Dirichlet tessellation''' (after [[Peter Gustav Lejeune Dirichlet]]). Voronoi diagrams have practical and theoretical applications in a large number of fields, mainly in [[science]] and [[technology]], but also in [[visual art]].&lt;ref&gt;{{cite journal |first=Franz |last=Aurenhammer |authorlink=Franz Aurenhammer |date=1991 |title=Voronoi Diagrams – A Survey of a Fundamental Geometric Data Structure |journal=ACM Computing Surveys |volume=23 |issue=3 |pages=345–405 |doi=10.1145/116873.116880}}&lt;/ref&gt;&lt;ref&gt;{{cite book |first1=Atsuyuki |last1=Okabe |first2=Barry |last2=Boots |first3=Kokichi |last3=Sugihara |first4=Sung Nok |last4=Chiu |date=2000 |title=Spatial Tessellations – Concepts and Applications of Voronoi Diagrams |edition=2nd |publisher=John Wiley |isbn=0-471-98635-6}}&lt;/ref&gt;
They are also known as '''Thiessen polygons'''.&lt;ref&gt;Principles of Geographical Information Systems, By Peter A. Burrough, Rachael McDonnell, Rachael A. McDonnell, Christopher D. Lloyd [https://books.google.com.br/books?id=kvoJCAAAQBAJ&amp;lpg=PA161&amp;dq=Thiessen%20polygon&amp;pg=PA160#v=onepage&amp;q=Thiessen%20voronoi&amp;f=false]&lt;/ref&gt;&lt;ref&gt;[https://books.google.com.br/books?id=-FbVI-2tSuYC&amp;lpg=PA333&amp;dq=Thiessen%20polygon&amp;pg=PA333#v=onepage&amp;q=Thiessen%20voronoi&amp;f=false Geographic Information Systems and Science, By Paul Longley]&lt;/ref&gt;&lt;ref&gt;[https://books.google.com.br/books?id=6N0yDQAAQBAJ&amp;lpg=PA57&amp;dq=Thiessen%20voronoi&amp;pg=PA57#v=onepage&amp;q=Thiessen%201912&amp;f=false Spatial Modeling Principles in Earth Sciences, Zekai Sen]&lt;/ref&gt;

==The simplest case==
In the simplest case, shown in the first picture, we are given a finite set of points {''p''&lt;sub&gt;1&lt;/sub&gt;, …, ''p''&lt;sub&gt;''n''&lt;/sub&gt;} in the [[Euclidean plane]]. In this case each site ''p''&lt;sub&gt;''k''&lt;/sub&gt; is simply a point, and its corresponding Voronoi cell ''R''&lt;sub&gt;''k''&lt;/sub&gt; consists of every point in the Euclidean plane whose distance to ''p''&lt;sub&gt;''k''&lt;/sub&gt; is less than or equal to its distance to any other ''p''&lt;sub&gt;''k''&lt;/sub&gt;. Each such cell is obtained from the intersection of [[Half-space (geometry)|half-spaces]], and hence it is a [[convex polygon]]. The [[line segment]]s of the Voronoi diagram are all the points in the plane that are equidistant to the two nearest sites.  The Voronoi vertices ([[Node (graph theory)|node]]s) are the points equidistant to three (or more) sites.

==Formal definition==
Let &lt;math&gt; \scriptstyle X &lt;/math&gt; be a [[metric space]] with distance function &lt;math&gt;\scriptstyle d&lt;/math&gt;. Let &lt;math&gt;\scriptstyle K&lt;/math&gt; be a set of indices and let &lt;math&gt;\scriptstyle (P_k)_{k \in K}&lt;/math&gt; be a [[tuple]] (ordered collection) of nonempty [[subsets]] (the sites) in the space &lt;math&gt;\scriptstyle X&lt;/math&gt;. The Voronoi cell, or Voronoi region,  &lt;math&gt;\scriptstyle R_k&lt;/math&gt;, associated with the site &lt;math&gt;\scriptstyle P_k&lt;/math&gt; is the set of all points in &lt;math&gt;\scriptstyle X&lt;/math&gt; whose distance to &lt;math&gt;\scriptstyle P_k&lt;/math&gt; is not greater than their distance to the other sites &lt;math&gt;\scriptstyle P_j&lt;/math&gt;, where &lt;math&gt;\scriptstyle j&lt;/math&gt; is any index different from &lt;math&gt;\scriptstyle k&lt;/math&gt;. In other words, if &lt;math&gt;\scriptstyle d(x,\, A) \;=\; \inf\{d(x,\, a) \mid a \,\in\, A\}&lt;/math&gt; denotes the distance between the point &lt;math&gt;\scriptstyle x&lt;/math&gt; and the subset &lt;math&gt;\scriptstyle A&lt;/math&gt;, then

:&lt;math&gt; R_k = \{x \in X \mid d(x, P_k) \leq d(x, P_j)\; \text{for all}\; j \neq k\}&lt;/math&gt;

The Voronoi diagram is simply the [[tuple]] of cells &lt;math&gt;\scriptstyle (R_k)_{k \in K} &lt;/math&gt;. In principle, some of the sites can intersect and even coincide (an application is described below for sites representing shops), but usually they are assumed to be disjoint. In addition, infinitely many sites are allowed in the definition (this setting has  applications in [[geometry of numbers]] and [[crystallography]]), but again, in many cases only finitely many sites are considered.

In the particular case where the space is a [[finite-dimensional]] [[Euclidean space]], each site is a point, there are finitely many points and all of them are different, then the Voronoi cells are [[convex polytope]]s and they can be represented in a combinatorial way using their vertices, sides, 2-dimensional faces, etc. Sometimes the induced combinatorial structure is referred to as the Voronoi diagram. However, in general the Voronoi cells may not be convex or even connected.

In the usual Euclidean space,  we can rewrite the formal definition in usual terms. Each Voronoi polygon &lt;math&gt;\scriptstyle R_k&lt;/math&gt; is associated with a generator point  &lt;math&gt;\scriptstyle P_k&lt;/math&gt;.
Let &lt;math&gt;\scriptstyle X&lt;/math&gt; be the set of all points in the Euclidean space. Let &lt;math&gt;\scriptstyle P_1&lt;/math&gt; be a point that generates its Voronoi region  &lt;math&gt;\scriptstyle R_1&lt;/math&gt;, &lt;math&gt;\scriptstyle P_2&lt;/math&gt; that generates  &lt;math&gt;\scriptstyle R_2&lt;/math&gt;, and &lt;math&gt;\scriptstyle P_3&lt;/math&gt; that generates  &lt;math&gt;\scriptstyle R_3&lt;/math&gt;, and so on. &lt;!--Then,

:&lt;math&gt; R_1 = \{x \in X \mid d(x, P_1) \leq d(x, P_2) \;\and\; d(x, P_1) \leq d(x, P_3) \;\and\; \ldots\}&lt;/math&gt;
:&lt;math&gt; R_2 = \{x \in X \mid d(x, P_2) \leq d(x, P_1) \;\and\; d(x, P_2) \leq d(x, P_3) \;\and\; \ldots\}&lt;/math&gt;
:...
--&gt; Then, as expressed by Tran ''et al''&lt;ref name="Tran09"&gt;{{cite book |first1=Q. T. |last1=Tran |first2=D. |last2=Tainar |first3=M. |last3=Safar |date=2009 |title=Transactions on Large-Scale Data- and Knowledge-Centered Systems |page=357 |isbn=9783642037214}}&lt;/ref&gt; "all locations in the Voronoi polygon are closer to the generator point of that polygon than any other generator point in the Voronoi diagram in Euclidean plane".

==Illustration==
As a simple illustration, consider a group of shops in a city. Suppose we want to estimate the number of customers of a given shop. With all else being equal (price, products, quality of service, etc.), it is reasonable to assume that customers choose their preferred shop simply by distance considerations: they will go to the shop located nearest to them. In this case the Voronoi cell &lt;math&gt;\scriptstyle R_k&lt;/math&gt; of a given shop &lt;math&gt;\scriptstyle P_k&lt;/math&gt; can be used for giving a rough estimate on the number of potential customers going to this shop (which is modeled by a point in our city).

For most cities, the distance between points can be measured using the familiar
[[Euclidean distance]]: &lt;math&gt;\ell_2 = d\left[\left(a_1, a_2\right), \left(b_1, b_2\right)\right] = \sqrt{\left(a_1 - b_1\right)^2 + \left(a_2 - b_2\right)^2}&lt;/math&gt; or the [[Manhattan distance]]:&lt;math&gt;d\left[\left(a_1, a_2\right), \left(b_1, b_2\right)\right] = \left|a_1 - b_1\right| + \left|a_2 - b_2\right|&lt;/math&gt;. The corresponding Voronoi diagrams look different for different distance metrics.

{{multiple image
 | align     = center
 | direction = horizontal
 | width     = 382
 | header    = Voronoi diagrams of 20 points under two different metrics
 | header_align = center
 | image1    = Euclidean Voronoi diagram.svg
 | alt1      = Voronoi diagram under Euclidean distance
 | caption1  = [[Euclidean distance]]
 | image2    = Manhattan Voronoi Diagram.svg
 | alt2      = Voronoi diagram under Manhattan distance
 | caption2  = [[Manhattan distance]]
}}

==Properties==
* The [[dual graph]] for a Voronoi diagram (in the case of a [[Euclidean space]] with point sites) corresponds to the [[Delaunay triangulation]] for the same set of points.
* The [[closest pair of points]] corresponds to two adjacent cells in the Voronoi diagram.
* Assume the setting is the [[Euclidean plane]] and a group of different points are given. Then two points are adjacent on the [[convex hull]] if and only if their Voronoi cells share an infinitely long side.
* If the space is a [[normed space]] and the distance to each site is attained (e.g., when a site is a [[compact set]] or a closed ball), then each Voronoi cell can be represented as a union of line segments emanating from the sites.&lt;ref name=Reem_alg&gt;{{cite journal |first=Daniel |last=Reem |title=An algorithm for computing Voronoi diagrams of general generators in general normed spaces |doi=10.1109/ISVD.2009.23 |journal=Proceedings of the sixth International Symposium on Voronoi Diagrams in science and engineering (ISVD 2009) |date=2009 |pages=144–152}}&lt;/ref&gt; As shown there, this property does not necessarily hold when the distance is not attained.
* Under relatively general conditions (the space is a possibly infinite-dimensional [[uniformly convex space]], there can be infinitely many sites of a general form, etc.) Voronoi cells enjoy a certain stability property: a small change in the shapes of the sites, e.g., a change caused by some translation or distortion, yields a small change in the shape of the Voronoi cells. This is the geometric stability of Voronoi diagrams.&lt;ref name=Reem_geo_stable&gt;{{cite journal |first=Daniel |last=Reem |title=The geometric stability of  Voronoi diagrams with respect to small changes of the sites |arxiv=1103.4125 |date=2011 |doi=10.1145/1998196.1998234 |journal=Proceedings of the 27th Annual ACM Symposium on Computational Geometry (SoCG) |pages=254–263}}&lt;/ref&gt; As shown there, this property does not hold in general, even if the space is two-dimensional (but non-uniformly convex, and, in particular, non-Euclidean) and the sites are points.

==History and research==
Informal use of Voronoi diagrams can be traced back to [[Descartes]] in 1644. [[Peter Gustav Lejeune Dirichlet]] used 2-dimensional and 3-dimensional Voronoi diagrams in his study of quadratic forms in 1850.
British physician [[John Snow (physician)|John Snow]] used a Voronoi diagram in 1854 to illustrate how the majority of people who died in the [[1854 Broad Street cholera outbreak|Broad Street cholera outbreak]] lived closer to the infected [[Soho#Broad Street pump|Broad Street pump]] than to any other water pump.

Voronoi diagrams are named after Russian mathematician [[Georgy Voronoy|Georgy Fedosievych Voronoy]] who defined and studied the general ''n''-dimensional case in 1908. Voronoi diagrams that are used in [[geophysics]] and [[meteorology]] to analyse spatially distributed data (such as rainfall measurements) are called Thiessen polygons after American meteorologist [[Alfred H. Thiessen]]. In [[condensed matter physics]], such tessellations are also known as [[Wigner–Seitz unit cell]]s. Voronoi tessellations of the [[reciprocal lattice]] of [[momentum|momenta]] are called [[Brillouin zone]]s. For general lattices in [[Lie group]]s,  the cells are simply called [[fundamental domain]]s. In the case of general [[metric space]]s, the cells are often called metric [[fundamental polygon]]s.
Other equivalent names for this concept (or particular important cases of it): Voronoi polyhedra, Voronoi polygons, domain(s) of influence, Voronoi decomposition, Voronoi tessellation(s), Dirichlet tessellation(s).

==Examples==
[[Image:Coloured Voronoi 3D slice.svg|right|thumb|This is a slice of the Voronoi diagram of a random set of points in a 3D box. In general a cross section of a 3D Voronoi tessellation is not a 2D Voronoi tessellation itself. (The cells are all [[Convex set|convex]] [[polyhedron|polyhedra]].)]]

Voronoi tessellations of regular [[Lattice (group)|lattice]]s of points in two or three dimensions give rise to many familiar tessellations.
* A 2D lattice gives an irregular honeycomb tessellation, with equal hexagons with point symmetry; in the case of a regular triangular lattice it is regular; in the case of a rectangular lattice the hexagons reduce to rectangles in rows and columns; a [[Square (geometry)|square]] lattice gives the regular tessellation of squares; note that the rectangles and the squares can also be generated by other lattices (for example the lattice defined by the vectors (1,0) and (1/2,1/2) gives squares). See [https://mbostock.github.com/d3/ex/voronoi.html here] for a dynamic visual example.
* A [[simple cubic lattice]] gives the [[cubic honeycomb]].
* A [[hexagonal close-packed]] lattice gives a tessellation of space with [[trapezo-rhombic dodecahedron|trapezo-rhombic dodecahedra]].
* A [[face-centred cubic]] lattice gives a tessellation of space with [[rhombic dodecahedron|rhombic dodecahedra]].
* A [[body-centred cubic]] lattice gives a tessellation of space with [[truncated octahedron|truncated octahedra]].
* Parallel planes with regular triangular lattices aligned with each other's centers give the [[hexagonal prismatic honeycomb]].
* Certain body centered tetragonal lattices give a tessellation of space with [[rhombo-hexagonal dodecahedron|rhombo-hexagonal dodecahedra]].

For the set of points (''x'',&amp;nbsp;''y'') with ''x'' in a discrete set ''X'' and ''y'' in a discrete set ''Y'', we get rectangular tiles with the points not necessarily at their centers.

==Higher-order Voronoi diagrams==
Although a normal Voronoi cell is defined as the set of points closest to a single point in ''S'', an ''n''th-order Voronoi cell is defined as the set of points having a particular set of ''n'' points in ''S'' as its ''n'' nearest neighbors.  Higher-order Voronoi diagrams also subdivide space.

Higher-order Voronoi diagrams can be generated recursively.  To generate the ''n''&lt;sup&gt;th&lt;/sup&gt;-order Voronoi diagram from set&amp;nbsp;''S'', start with the (''n''&amp;nbsp;−&amp;nbsp;1)&lt;sup&gt;th&lt;/sup&gt;-order diagram and replace each cell generated by ''X''&amp;nbsp;=&amp;nbsp;{''x''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''x''&lt;sub&gt;2&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''x''&lt;sub&gt;''n''−1&lt;/sub&gt;} with a Voronoi diagram generated on the set&amp;nbsp;''S''&amp;nbsp;−&amp;nbsp;''X''.

===Farthest-point Voronoi diagram===
For a set of ''n'' points the (''n''&amp;nbsp;−&amp;nbsp;1)&lt;sup&gt;th&lt;/sup&gt;-order Voronoi diagram is called a farthest-point Voronoi diagram.

For a given set of points ''S''&amp;nbsp;=&amp;nbsp;{''p''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''p''&lt;sub&gt;2&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''p''&lt;sub&gt;''n''&lt;/sub&gt;} the farthest-point Voronoi diagram divides the plane into cells in which the same point of ''P'' is the farthest point. A point of ''P'' has a cell in the farthest-point Voronoi diagram if and only if it is a vertex of the [[convex hull]] of ''P''. Let ''H''&amp;nbsp;=&amp;nbsp;{''h''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''h''&lt;sub&gt;2&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''h''&lt;sub&gt;''k''&lt;/sub&gt;} be the convex hull of ''P''; then the farthest-point Voronoi diagram is a subdivision of the plane into ''k'' cells, one for each point in ''H'', with the property that a point ''q'' lies in the cell corresponding to a site ''h''&lt;sub&gt;''i''&lt;/sub&gt; if and only if d(''q'', ''h''&lt;sub&gt;''i''&lt;/sub&gt;) &gt; d(''q'', ''p''&lt;sub&gt;''j''&lt;/sub&gt;) for each ''p''&lt;sub&gt;''j''&lt;/sub&gt;&amp;nbsp;∈&amp;nbsp;''S'' with ''h''&lt;sub&gt;''i''&lt;/sub&gt; ≠ ''p''&lt;sub&gt;''j''&lt;/sub&gt;, where d(''p'', ''q'') is the [[Euclidean distance]] between two points ''p'' and&amp;nbsp;''q''.&lt;ref name="berg2008"&gt;{{cite book|year=2008|title=Computational Geometry |isbn=978-3-540-77974-2 |publisher=[[Springer-Verlag]]|edition=Third |first1=Mark |last1=de Berg |first2=Marc |last2=van Kreveld |first3=Mark |last3=Overmars |first4=Otfried |last4=Schwarzkopf |authorlink1=Mark de Berg |authorlink2=Marc van Kreveld |authorlink3=Mark Overmars |authorlink4=Otfried Schwarzkopf }} 7.4 Farthest-Point Voronoi Diagrams. Includes a description of the algorithm.&lt;/ref&gt;&lt;ref&gt;{{cite journal |first=Sven |last=Skyum |title=A simple algorithm for computing the smallest enclosing circle |journal=Information Processing Letters |volume=37 |issue=3 |date=18 February 1991 |pages=121–125 |doi=10.1016/0020-0190(91)90030-L}}, contains a simple algorithm to compute the farthest-point Voronoi diagram.&lt;/ref&gt;

The boundaries of the cells in the farthest-point Voronoi diagram have the structure of a [[Real tree|topological tree]], with infinite [[Ray (mathematics)|rays]] as its leaves. Every finite tree is isomorphic to the tree formed in this way from a farthest-point Voronoi diagram.&lt;ref&gt;{{cite conference
 | last1 = Biedl | first1 = Therese | authorlink = Therese Biedl
 | last2 = Grimm | first2 = Carsten
 | last3 = Palios | first3 = Leonidas
 | last4 = Shewchuk | first4 = Jonathan | author4-link = Jonathan Shewchuk
 | last5 = Verdonschot | first5 = Sander
 | contribution = Realizing farthest-point Voronoi diagrams
 | title = Proceedings of the 28th Canadian Conference on Computational Geometry (CCCG 2016)
 | year = 2016}}&lt;/ref&gt;

==Generalizations and variations==
As implied by the definition, Voronoi cells can be defined for metrics other than Euclidean, such as the [[Mahalanobis distance]] or [[Manhattan distance]]. However, in these cases the boundaries of the Voronoi cells may be more complicated than in the Euclidean case, since the equidistant locus for two points may fail to be subspace of codimension 1, even in the 2-dimensional case.

[[Image:Approximate Voronoi Diagram.svg|thumb|Approximate Voronoi diagram of a set of points. Notice the blended colors in the fuzzy boundary of the Voronoi cells.]]
A [[weighted Voronoi diagram]] is the one in which the function of a pair of points to define a Voronoi cell is a distance function modified by multiplicative or additive weights assigned to generator points. In contrast to the case of Voronoi cells defined using a distance which is a [[metric (mathematics)|metric]], in this case some of the Voronoi cells  may be empty. A [[power diagram]] is a type of Voronoi diagram defined from a set of circles using the [[Power of a point|power distance]]; it can also be thought of as a weighted Voronoi diagram in which a weight defined from the radius of each circle is added to the [[quadrance|squared distance]] from the circle's center.&lt;ref&gt;{{citation|last=Edelsbrunner|first=Herbert|author-link=Herbert Edelsbrunner|contribution=13.6 Power Diagrams|pages=327–328|publisher=Springer-Verlag|series=EATCS Monographs on Theoretical Computer Science|title=Algorithms in Combinatorial Geometry|volume=10|year=1987}}.&lt;/ref&gt;

The Voronoi diagram of ''n'' points in ''d''-dimensional space requires &lt;math&gt;\scriptstyle O\left(n^{\left\lceil \frac{1}{2}d \right\rceil}\right)&lt;/math&gt; storage space.{{clarify | reason = 'Storage space' for what, exactly?|date=November 2016}} Therefore, Voronoi diagrams are often not feasible for ''d''&amp;nbsp;&gt;&amp;nbsp;2.{{clarify | reason = It seems implausible that a modern computer could not easily work with, say, a 3D diagram for reasonable ''n''|date=November 2016}} An alternative is to use [[approximate Voronoi diagram]]s, where the Voronoi cells have a fuzzy boundary, which can be approximated.&lt;ref&gt;S. Arya, T. Malamatos, and [[David Mount|D. M. Mount]],
[http://www.cs.ust.hk/faculty/arya/pub/stoc02.pdf Space-Efficient Approximate Voronoi Diagrams], Proc. 34th ACM Symp. on Theory of Computing (STOC 2002), pp. 721–730.&lt;/ref&gt;

Voronoi diagrams are also related to other geometric structures such as the [[medial axis]] (which has found applications in image segmentation, [[optical character recognition]], and other computational applications), [[straight skeleton]], and [[zone diagram]]s. Besides points, such diagrams use lines and polygons as seeds. By augmenting the diagram with line segments that connect to nearest points on the seeds, a planar subdivision of the environment is obtained.&lt;ref&gt;{{citation|last=Geraerts|first=Roland|pages=1997–2004|publisher=IEEE|series=International Conference on Robotics and Automation|title=Planning Short Paths with Clearance using Explicit Corridors|year=2010|url=http://www.staff.science.uu.nl/~gerae101/pdf/ecm.pdf}}.&lt;/ref&gt; This structure can be used as a [[navigation mesh]] for path-finding through large spaces. The navigation mesh has been generalized to support 3D multi-layered environments, such as an airport or a multi-storey building.&lt;ref&gt;{{citation|last1=van Toll|first1=Wouter G.|last2=Cook IV|first2=Atlas F.|last3=Geraerts|first3=Roland|pages=3526–3532|publisher=IEEE/RSJ|series=International Conference on Intelligent Robots and Systems|title=Navigation Meshes for Realistic Multi-Layered Environments|year=2011|url=http://www.staff.science.uu.nl/~gerae101/pdf/navmesh.pdf}}.&lt;/ref&gt;

==Applications==

=== Natural sciences ===
[[File:Voronoi growth euclidean.gif|thumb|A Voronoi tessellation emerges by radial growth from seeds outward.]]
*In [[biology]], Voronoi diagrams are used to model a number of different biological structures, including [[Cell (biology)|cells]]&lt;ref&gt;{{cite journal|last1=Bock |first1=Martin |last2=Tyagi |first2=Amit Kumar |last3=Kreft |first3=Jan-Ulrich |last4=Alt |first4=Wolfgang |title=Generalized Voronoi Tessellation as a Model of Two-dimensional Cell Tissue Dynamics|journal=Bulletin of Mathematical Biology|volume=72|issue=7|pages=1696–1731|doi= 10.1007/s11538-009-9498-3|year=2009|arxiv=0901.4469v1}}&lt;/ref&gt; and [[Cancellous bone|bone microarchitecture.]]&lt;ref&gt;{{cite journal|author=Hui Li|title=Spatial Modeling of Bone Microarchitecture|year=2012}}&lt;/ref&gt; Indeed, Voronoi tessellations work as a geometrical tool to understand the physical constraints that drive the organization of biological tissues.&lt;ref name="Sanchez-Gutierrez 77–88"&gt;{{Cite journal|last=Sanchez-Gutierrez|first=D.|last2=Tozluoglu|first2=M.|last3=Barry|first3=J. D.|last4=Pascual|first4=A.|last5=Mao|first5=Y.|last6=Escudero|first6=L. M.|date=2016-01-04|title=Fundamental physical cellular constraints drive self-organization of tissues|url=http://emboj.embopress.org/content/35/1/77.long|journal=The EMBO Journal|language=en|volume=35|issue=1|pages=77–88|doi=10.15252/embj.201592374|pmc=4718000|pmid=26598531}}&lt;/ref&gt;
*In [[hydrology]], Voronoi diagrams are used to calculate the rainfall of an area, based on a series of point measurements. In this usage, they are generally referred to as Thiessen polygons.
*In [[ecology]], Voronoi diagrams are used to study the growth patterns of forests and forest canopies, and may also be helpful in developing predictive models for forest fires.
*In [[computational chemistry]], Voronoi cells defined by the positions of the nuclei in a molecule are used to compute [[partial charge|atomic charge]]s. This is done using the [[Voronoi deformation density]] method.
*In [[astrophysics]], Voronoi diagrams are used to generate adaptative smoothing zones on images, adding signal fluxes on each one. The main objective for these procedures is to maintain a relatively constant [[signal-to-noise ratio]] on all the image.
*In [[computational fluid dynamics]], the Voronoi tessellation of a set of points can be used to define the computational domains used in [[finite volume]] methods, e.g. as in the moving-mesh cosmology code AREPO.&lt;ref&gt;{{cite journal|title=E pur si muove: Galilean-invariant cosmological hydrodynamical simulations on a moving mesh|last=Springel|first=Volker|year=2010|journal=MNRAS|volume=401|issue=2|pages=791–851|doi=10.1111/j.1365-2966.2009.15715.x|bibcode=2010MNRAS.401..791S|arxiv=0901.4107}}&lt;/ref&gt;
*In [[computational physics]], Voronoi diagrams are used to calculate profiles of an object with [[Shadowgraph]] and proton radiography in [[High energy density physics]].&lt;ref&gt;{{Cite journal|last=Kasim|first=Muhammad Firmansyah|date=2017-01-01|title=Quantitative shadowgraphy and proton radiography for large intensity modulations|url=https://link.aps.org/doi/10.1103/PhysRevE.95.023306|journal=Physical Review E|volume=95|issue=2|doi=10.1103/PhysRevE.95.023306|arxiv=1607.04179|bibcode=2017PhRvE..95b3306K}}&lt;/ref&gt;

=== Health ===
*In [[medical diagnosis]], models of muscle tissue, based on Voronoi diagrams, can be used to detect neuromuscular diseases.&lt;ref name="Sanchez-Gutierrez 77–88"/&gt; [[File:Snow-cholera-map-1.jpg|thumb|John Snow's original diagram]]
*In [[epidemiology]], Voronoi diagrams can be used to correlate sources of infections in epidemics. One of the early applications of Voronoi diagrams was implemented by [[John Snow (physician)|John Snow]] to study the [[1854 Broad Street cholera outbreak]] in Soho, England. He showed the correlation between residential areas on the map of Central London whose residents had been using a specific water pump, and the areas with most deaths due to the outbreak.&lt;ref name="Johnson2006"&gt;{{cite book|author=Steven Johnson|title=The Ghost Map: The Story of London's Most Terrifying Epidemic — and How It Changed Science, Cities, and the Modern World|url=https://books.google.com/books?id=8R3NrzE8veEC&amp;pg=PT187|date=19 October 2006|accessdate=16 October 2017|publisher=Penguin Publishing Group|isbn=978-1-101-15853-1|page=187}}&lt;/ref&gt;

=== Engineering ===
*In [[polymer physics]], Voronoi diagrams can be used to represent free volumes of polymers.
*In [[materials science]], polycrystalline microstructures in metallic alloys are commonly represented using Voronoi tessellations. In solid state physics, the [[Wigner-Seitz cell]] is the Voronoi tessellation of a solid, and the [[Brillouin zone]] is the Voronoi tessellation of reciprocal (wave number) space of crystals which have the symmetry of a space group.
*In [[aviation]], Voronoi diagrams are superimposed on oceanic plotting charts to identify the nearest airfield for in-flight diversion (see [[ETOPS]]), as an aircraft progresses through its flight plan.
*In [[architecture]], Voronoi patterns were the basis for the winning entry for redevelopment of [[The Arts Centre Gold Coast]].&lt;ref&gt;{{cite web|title=GOLD COAST CULTURAL PRECINCT|url=http://www.a-r-m.com.au/projects_GoldCoastCP.html|publisher=ARM Architecture}}&lt;/ref&gt;
*In [[mining]], Voronoi polygons are used to estimate the reserves of valuable materials, minerals, or other resources. Exploratory drillholes are used as the set of points in the Voronoi polygons.

=== Geometry ===
*A [[point location]] data structure can be built on top of the Voronoi diagram in order to answer [[nearest neighbor search|nearest neighbor]] queries, where one wants to find the object that is closest to a given query point. Nearest neighbor queries have numerous applications. For example, one might want to find the nearest hospital, or the most similar object in a [[database]]. A large application is [[vector quantization]], commonly used in [[data compression]]. 
*In [[geometry]], Voronoi diagrams can be used to find the [[Largest empty sphere|largest empty circle]] amid a set of points, and in an enclosing polygon; e.g. to build a new supermarket as far as possible from all the existing ones, lying in a certain city.
*Voronoi diagrams together with farthest-point Voronoi diagrams are used for efficient algorithms to compute the [[Roundness (object)|roundness]] of a set of points.&lt;ref name="berg2008" /&gt; The Voronoi approach is also put to good use in the evaluation of circularity/[[roundness (object)|roundness]] while assessing the dataset from a [[coordinate-measuring machine]].
*Modern [[computational geometry]] has provided efficient algorithms for constructing Voronoi diagrams, and has allowed them to be used in [[mesh generation]], [[point location]], [[cluster analysis]], machining plans and many other computational tasks.&lt;ref&gt;{{cite book|last=Wolfram|first=Stephen|title=A New Kind of Science|publisher=Wolfram Media, Inc.|year=2002|page=987|isbn=1-57955-008-8}}&lt;/ref&gt;

=== Informatics ===
*In [[Computer network|networking]], Voronoi diagrams can be used in derivations of the capacity of a [[wireless network]].
*In [[computer graphics]], Voronoi diagrams are used to calculate 3D shattering / fracturing geometry patterns.  It is also used to procedurally generate organic or lava-looking textures.
* In autonomous [[robot navigation]], Voronoi diagrams are used to find clear routes. If the points are obstacles, then the edges of the graph will be the routes furthest from obstacles (and theoretically any collisions).
*In [[machine learning]], Voronoi diagrams are used to do [[k-nearest neighbor algorithm|1-NN]] classifications.&lt;ref&gt;{{cite book |title=Machine Learning |first=Tom M. |last=Mitchell |year=1997 |publisher=McGraw-Hill |edition=International |isbn=0-07-042807-7|page=233}}&lt;/ref&gt;
*In [[user interface]] development, Voronoi patterns can be used to compute the best hover state for a given point.&lt;ref&gt;{{cite web|title=User Interface Algorithms|url=https://www.youtube.com/watch?v=90NsjKvz9Ns}}&lt;/ref&gt;

=== Civics and planning ===
* In Victoria, Australia, government schools typically admit eligible students to the nearest primary school or high school to where they live.&lt;ref&gt;{{Cite web|url=http://www.education.vic.gov.au/school/parents/primary/Pages/boundary.aspx|title=Restrictions and boundaries|website=www.education.vic.gov.au|language=en|access-date=2017-11-19}}&lt;/ref&gt;  Students and parents can see which school "catchment zone" they live in by using [http://melbourneschoolzones.com/ this Voronoi representation].

==Algorithms==
Direct algorithms:
*[[Fortune's algorithm]], an [[big O notation|O]](''n'' log(''n'')) algorithm for generating a Voronoi diagram from a set of points in a plane.
*[[Lloyd's algorithm]] and its generalization via the [[Linde–Buzo–Gray algorithm]] (aka [[k-means clustering]]), produces a Voronoi tessellation in a space of arbitrary dimensions.

Starting with a [[Delaunay triangulation]] (obtain the dual):
*[[Bowyer–Watson algorithm]], an [[big O notation|O]](''n'' log(''n'')) to [[big O notation|O]](''n''&lt;sup&gt;2&lt;/sup&gt;) algorithm for generating a Delaunay triangulation in any number of dimensions, from which the Voronoi diagram can be obtained.

==See also==
*[[Centroidal Voronoi tessellation]]
*[[Computational geometry]]
*[[Delaunay triangulation]]
*[[Mathematical diagram]]
*[[Natural neighbor interpolation]]
*[[Nearest neighbor search]]
*[[Nearest-neighbor interpolation]]
*[[Voronoi pole]]
*[[Power diagram]]
*[[Map segmentation]]

==Notes==
{{Reflist|30em}}

==References==
{{refbegin}}
* {{cite journal
|author-link=Peter Gustav Lejeune Dirichlet |first=G. Lejeune |last=Dirichlet
|year=1850
|title=Über die Reduktion der positiven quadratischen Formen mit drei unbestimmten ganzen Zahlen
|journal=Journal für die Reine und Angewandte Mathematik
|volume=40
|pages=209–227
}}
* {{cite journal
|first1=Georgy
|last1= Voronoi
|year=1908
|title=Nouvelles applications des paramètres continus à la théorie des formes quadratiques
|journal=Journal für die Reine und Angewandte Mathematik
|volume=1908
|issue= 133
|doi=10.1515/crll.1908.133.97
|pages=97–178
}}
* Atsuyuki Okabe, Barry Boots, [[Kokichi Sugihara]] &amp; Sung Nok Chiu (2000). ''Spatial Tessellations&amp;nbsp;– Concepts and Applications of Voronoi Diagrams''. 2nd edition. John Wiley, 2000, 671 pages, {{isbn|0-471-98635-6}}
* [[Franz Aurenhammer]], Rolf Klein &amp; [[Der-Tsai Lee]] (2013) "Voronoi Diagrams and Delaunay Triangulations". World Scientific, 2013, 337 pages, {{isbn|978-9814447638}}
* {{Cite journal | last1 = Bowyer | first1 = Adrian |author1-link=Adrian Bowyer| title = Computing Dirichlet tessellations | doi = 10.1093/comjnl/24.2.162 | journal = [[The Computer Journal|Comput. J.]] | volume = 24 | issue = 2 | pages = 162–166 | year = 1981 | pmid =  | pmc = }}
* {{Cite news
|first1=Daniel
|last1=Reem
|year=2009
|title=An algorithm for computing Voronoi diagrams of general generators in general normed spaces
|doi=10.1109/ISVD.2009.23
|journal=Proceedings of the  sixth International Symposium on Voronoi Diagrams in science and engineering (ISVD 2009)
|pages=144–152
}}

* Daniel Reem (2011). ''The geometric stability of  Voronoi diagrams with respect to small changes of the sites''. Full version: [https://arxiv.org/abs/1103.4125 arXiv 1103.4125 (2011)], Extended abstract: [https://dx.doi.org/10.1145/1998196.1998234 in Proceedings of the 27th Annual ACM Symposium on Computational Geometry (SoCG 2011), pp. 254–263].
* {{Cite journal | last1 = Watson | first1 = David F. | authorlink1 = | title = Computing the ''n''-dimensional Delaunay tessellation with application to Voronoi polytopes | doi = 10.1093/comjnl/24.2.167 | journal = [[The Computer Journal|Comput. J.]] | volume = 24 | issue = 2 | pages = 167–172 | year = 1981 | pmid =  | pmc = }}
* {{cite book |year=2000 |title=Computational Geometry |publisher=[[Springer-Verlag]] |edition=2nd revised |isbn=3-540-65620-0 |first1=Mark |last1=de Berg |first2=Marc |last2=van Kreveld |first3=Mark |last3=Overmars |first4=Otfried |last4=Schwarzkopf |authorlink3=Mark Overmars}} Chapter 7: Voronoi Diagrams: pp.&amp;nbsp;147–163. Includes a description of Fortune's algorithm.
* {{cite book |first=Rolf |last=Klein |year=1989 |title=Abstract voronoi diagrams and their applications |series=[[Lecture Notes in Computer Science]] |volume=333 |pages=148–157 |doi= 10.1007/3-540-50335-8_31 |publisher=[[Springer-Verlag]] |edition= |isbn=3-540-52055-4}}
{{refend}}

==External links==
{{Commons category|Voronoi diagrams}}
* [http://www.cs.cornell.edu/Info/People/chew/Delaunay.html Real time interactive Voronoi and Delaunay diagrams with source code]
* [http://www.nirarebakun.com/eng.html Demo for various metrics]
* [http://mathworld.wolfram.com/VoronoiDiagram.html Mathworld on Voronoi diagrams]
* [http://www.ics.uci.edu/~eppstein/gina/scot.drysdale.html Voronoi Diagrams: Applications from Archaeology to Zoology]
* [http://www.cgal.org/Part/VoronoiDiagrams  Voronoi Diagrams] in [[CGAL]], the Computational Geometry Algorithms Library
* [http://www.math.psu.edu/qdu/Res/Pic/gallery3.html More discussions and picture gallery on centroidal Voronoi tessellations]
* [http://demonstrations.wolfram.com/VoronoiDiagrams/ Voronoi Diagrams] by [[Ed Pegg, Jr.]],  Jeff Bryant, and [[Theodore Gray]], [[Wolfram Demonstrations Project]].
* [http://www.preschern.org/detri/DeTri_en.html A Voronoi diagram on a sphere, in 3d, and others]
* [http://datavoreconsulting.com/programming-tips/voronoi-diagrams-in-mathematica/ Plot a Voronoi diagram with Mathematica]
* [https://bl.ocks.org/mbostock/4060366 Voronoi Tessellation] – Interactive Voronoi tessellation with [[D3.js]]
* [http://alexbeutel.com/webgl/voronoi.html Interactive Voronoi diagram and natural neighbor interpolation visualization (WebGL)]

{{Tessellation}}
{{authority control}}

{{DEFAULTSORT:Voronoi Diagram}}
[[Category:Discrete geometry]]
[[Category:Computational geometry]]
[[Category:Diagrams]]
[[Category:Ukrainian inventions]]
[[Category:Russian inventions]]</text>
      <sha1>5hj1mfuvrbe83sw6ovegt4dq7c8iwd1</sha1>
    </revision>
  </page>
  <page>
    <title>Weyl module</title>
    <ns>0</ns>
    <id>32084687</id>
    <revision>
      <id>811967465</id>
      <parentid>670498423</parentid>
      <timestamp>2017-11-25T03:05:08Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <comment>/* top */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1591">In algebra, a '''Weyl module''' is a [[group representation|representation]] of a [[reductive group|reductive]] [[algebraic group]], introduced by {{harvs|txt|last=Carter||last2=Lusztig|year1=1974|year2=1974b}} and named after [[Hermann Weyl]]. In [[characteristic (algebra)|characteristic]]&amp;nbsp;0 these representations are [[irreducible representation|irreducible]], but in positive characteristic they can be reducible, and their decomposition into irreducible components can be hard to determine.

== See also ==
*[[Borel–Weil–Bott theorem]]

==Further reading==

*{{Citation | last1=Carter | first1=Roger W. | author1-link=Roger Carter (mathematician) | last2=Lusztig | first2=George | author2-link=George Lusztig| title=On the modular representations of the general linear and symmetric groups | doi=10.1007/BF01214125 | mr=0354887 | year=1974 | journal=[[Mathematische Zeitschrift]] | issn=0025-5874 | volume=136 | pages=193–242}}
*{{Citation | last1=Carter | first1=Roger W. | author1-link=Roger Carter (mathematician) | last2=Lusztig | first2=G. | author2-link=George Lusztig | title=Proceedings of the Second International Conference on the Theory of Groups (Australian Nat. Univ., Canberra, 1973) | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Mathematics | doi=10.1007/BFb0065172 | mr=0369503 | year=1974b | volume=372 | chapter=On the modular representations of the general linear and symmetric groups | pages=218–220}}
*{{eom|id=Weyl_module|first=R.|last= Dipper}}

[[Category:Representation theory]]
[[Category:Algebraic groups]]</text>
      <sha1>7czn87efkis0vyx9p0gokdak85hxlud</sha1>
    </revision>
  </page>
  <page>
    <title>Widest path problem</title>
    <ns>0</ns>
    <id>31567349</id>
    <revision>
      <id>830382901</id>
      <parentid>827527211</parentid>
      <timestamp>2018-03-14T14:03:25Z</timestamp>
      <contributor>
        <username>Jeff Erickson</username>
        <id>17228316</id>
      </contributor>
      <minor/>
      <comment>/* Undirected graphs */ Fix link to Kaibel+ Peinhardt</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23233">{{good article}}
[[File:CPT-Graphs-undirected-weighted.svg|thumb|240px|In this graph, the widest path from Maldon to Feering has bandwidth 29, and passes through Clacton, Tiptree, Harwich, and Blaxhall.]]
In [[graph algorithm]]s, the '''widest path problem''' is the problem of finding a [[path (graph theory)|path]] between two designated [[vertex (graph theory)|vertices]] in a [[weighted graph]], maximizing the weight of the minimum-weight edge in the path. The widest path problem is also known as the '''bottleneck shortest path problem''' or the '''maximum capacity path problem'''. It is possible to adapt most [[shortest path]] algorithms to compute widest paths, by modifying them to use the bottleneck distance instead of path length.&lt;ref&gt;{{citation|title=The maximum capacity through a network|first=Maurice|last=Pollack|journal=[[Operations Research (journal)|Operations Research]]|volume=8|issue=5|year=1960|pages=733–736|jstor= 167387|doi=10.1287/opre.8.5.733}}&lt;/ref&gt; However, in many cases even faster algorithms are possible.

For instance, in a graph that represents connections between [[Router (computing)|router]]s in the [[Internet]], where the weight of an edge represents the [[bandwidth (computing)|bandwidth]] of a connection between two routers, the widest path problem is the problem of finding an end-to-end path between two Internet nodes that has the maximum possible bandwidth.&lt;ref&gt;{{citation|contribution=Multicast routing of hierarchical data|last=Shacham|first=N.|title=IEEE International Conference on Communications (ICC '92)|year=1992|pages=1217–1221|volume=3|doi=10.1109/ICC.1992.268047}}; {{citation|contribution=Bandwidth-delay based routing algorithms|first1=Zheng|last1=Wang|last2=Crowcroft|first2=J.|title=IEEE Global Telecommunications Conference (GLOBECOM '95)|year=1995|pages=2129–2133|volume=3|doi=10.1109/GLOCOM.1995.502780}}&lt;/ref&gt;  The smallest edge weight on this path is known as the capacity or bandwidth of the path. As well as its applications in network routing, the widest path problem is also an important component of the [[Schulze method]] for deciding the winner of a multiway election,&lt;ref name="Schulze"&gt;{{citation
 | last = Schulze | first = Markus
 | doi = 10.1007/s00355-010-0475-4
 | issue = 2
 | journal = [[Social Choice and Welfare]]
 | pages = 267–303
 | title = A new monotonic, clone-independent, reversal symmetric, and Condorcet-consistent single-winner election method
 | volume = 36
 | year = 2011}}&lt;/ref&gt; and has been applied to [[digital compositing]],&lt;ref name="fga"/&gt; [[Metabolic network modelling#Metabolic network simulation|metabolic pathway analysis]],&lt;ref name="ulh09"&gt;{{citation
 | last1 = Ullah | first1 = E.
 | last2 = Lee | first2 = Kyongbum
 | last3 = Hassoun | first3 = S.
 | contribution = An algorithm for identifying dominant-edge metabolic pathways
 | pages = 144–150
 | title = IEEE/ACM International Conference on Computer-Aided Design (ICCAD 2009)
 | url = http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5361299
 | year = 2009}}&lt;/ref&gt; and the computation of [[maximum flow]]s.&lt;ref name="amo"/&gt;

A closely related problem, the '''minimax path problem''', asks for the path that minimizes the maximum weight of any of its edges. It has applications that include [[transportation planning]].&lt;ref name="bh87"&gt;{{citation
 | last1 = Berman | first1 = Oded
 | last2 = Handler | first2 = Gabriel Y.
 | doi = 10.1287/trsc.21.2.115
 | issue = 2
 | journal = [[Transportation Science]]
 | pages = 115–122
 | title = Optimal Minimax Path of a Single Service Unit on a Network to Nonservice Destinations
 | volume = 21
 | year = 1987}}&lt;/ref&gt; Any algorithm for the widest path problem can be transformed into an algorithm for the minimax path problem, or vice versa, by reversing the sense of all the weight comparisons performed by the algorithm, or equivalently by replacing every edge weight by its negation.

==Undirected graphs==
In an [[undirected graph]], a widest path may be found as the path between the two vertices in the [[minimum spanning tree|maximum spanning tree]] of the graph, and a minimax path may be found as the path between the two vertices in the minimum spanning tree.&lt;ref&gt;{{citation|title=The maximum capacity route problem|first=T. C.|last=Hu|journal=[[Operations Research (journal)|Operations Research]]|volume=9|issue=6|year=1961|pages=898–900|jstor=167055|doi=10.1287/opre.9.6.898}}&lt;/ref&gt;&lt;ref name="punnen"/&gt;&lt;ref&gt;{{citation
 | last1 = Malpani | first1 = Navneet
 | last2 = Chen | first2 = Jianer
 | doi = 10.1016/S0020-0190(01)00323-4
 | mr = 1904226
 | issue = 3
 | journal = [[Information Processing Letters]]
 | pages = 175–180
 | title = A note on practical construction of maximum bandwidth paths
 | volume = 83
 | year = 2002}}&lt;/ref&gt;

In any graph, directed or undirected, there is a straightforward algorithm for finding a widest path once the weight of its minimum-weight edge is known: simply delete all smaller edges and search for any path among the remaining edges using [[breadth first search]] or [[depth first search]]. Based on this test, there also exists a [[linear time]] [[algorithm]] for finding a widest {{math|''s''-''t''}} path in an undirected graph, that does not use the maximum spanning tree. The main idea of the algorithm is to apply the linear-time path-finding algorithm to the [[median]] edge weight in the graph, and then either to delete all smaller edges or contract all larger edges according to whether a path does or does not exist, and recurse in the resulting smaller graph.&lt;ref name="punnen"&gt;{{citation|title=A linear time algorithm for the maximum capacity path problem|first=Abraham P.|last=Punnen|journal=[[European Journal of Operational Research]]|volume=53|issue=3|year=1991|pages=402–404|doi=10.1016/0377-2217(91)90073-5}}&lt;/ref&gt;&lt;ref&gt;{{citation|first=P. M.|last=Camerini|year=1978|title=The min-max spanning tree problem and some extensions|journal=[[Information Processing Letters]]|volume=7|issue=1|pages=10–14|doi=10.1016/0020-0190(78)90030-3}}&lt;/ref&gt;&lt;ref name="kp"&gt;{{citation|title=On the bottleneck shortest path problem|first1=Volker|last1=Kaibel|first2=Matthias A. F.|last2=Peinhardt|series=ZIB-Report 06-22|year=2006|publisher=Konrad-Zuse-Zentrum für Informationstechnik Berlin|url= https://opus4.kobv.de/opus4-zib/files/916/ZR-06-22.pdf}}&lt;/ref&gt;

{{harvtxt|Fernandez|Garfinkel|Arbiol|1998}} use undirected bottleneck shortest paths in order to form [[Digital compositing|composite]] [[Aerial photography|aerial photographs]] that combine multiple images of overlapping areas. In the subproblem to which the widest path problem applies, two images have already been [[Image registration|transformed into a common coordinate system]]; the remaining task is to select a ''seam'', a curve that passes through the region of overlap and divides one of the two images from the other. Pixels on one side of the seam will be copied from one of the images, and pixels on the other side of the seam will be copied from the other image. Unlike other compositing methods that average pixels from both images, this produces a valid photographic image of every part of the region being photographed. They weight the edges of a [[grid graph]] by a numeric estimate of how visually apparent a seam across that edge would be, and find a bottleneck shortest path for these weights. Using this path as the seam, rather than a more conventional shortest path, causes their system to find a seam that is difficult to discern at all of its points, rather than allowing it to trade off greater visibility in one part of the image for lesser visibility elsewhere.&lt;ref name="fga"&gt;{{citation
 | last1 = Fernandez | first1 = Elena
 | last2 = Garfinkel | first2 = Robert
 | last3 = Arbiol | first3 = Roman
 | issue = 3
 | journal = [[Operations Research (journal)|Operations Research]]
 | pages = 293–304
 | title = Mosaicking of aerial photographic maps via seams defined by bottleneck shortest paths
 | jstor = 222823
 | volume = 46
 | year = 1998 | doi=10.1287/opre.46.3.293}}&lt;/ref&gt;

A solution to the minimax path problem between the two opposite corners of a [[grid graph]] can be used to find the [[Fréchet distance|weak Fréchet distance]] between two [[polygonal chain]]s. Here, each grid graph vertex represents a pair of line segments, one from each chain, and the weight of an edge represents the Fréchet distance needed to pass from one pair of segments to another.&lt;ref&gt;{{citation
 | last1 = Alt | first1 = Helmut
 | last2 = Godau | first2 = Michael
 | doi = 10.1142/S0218195995000064
 | issue = 1–2
 | journal = International Journal of Computational Geometry and Applications
 | pages = 75–91
 | title = Computing the Fréchet distance between two polygonal curves
 | url = http://www.cs.uu.nl/people/marc/asci/ag-cfdbt-95.pdf
 | volume = 5
 | year = 1995}}.&lt;/ref&gt;

If all edge weights of an undirected graph are [[positive number|positive]], then the minimax distances between pairs of points (the maximum edge weights of minimax paths) form an [[ultrametric]]; conversely every finite ultrametric space comes from minimax distances in this way.&lt;ref&gt;{{citation
 | last = Leclerc | first = Bruno
 | mr = 623034
 | issue = 73
 | journal = Centre de Mathématique Sociale. École Pratique des Hautes Études. Mathématiques et Sciences Humaines
 | language = French
 | pages = 5–37, 127
 | title = Description combinatoire des ultramétriques
 | year = 1981}}&lt;/ref&gt; A [[data structure]] constructed from the minimum spanning tree allows the minimax distance between any pair of vertices to be queried in constant time per query, using [[lowest common ancestor]] queries in a [[Cartesian tree]]. The root of the Cartesian tree represents the heaviest minimum spanning tree edge, and the children of the root are Cartesian trees [[recursion|recursively]] constructed from the subtrees of the minimum spanning tree formed by removing the heaviest edge. The leaves of the Cartesian tree represent the vertices of the input graph, and the minimax distance between two vertices equals the weight of the Cartesian tree node that is their lowest common ancestor. Once the minimum spanning tree edges have been sorted, this Cartesian tree can be constructed in linear time.&lt;ref&gt;{{citation|contribution=On Cartesian trees and range minimum queries|first1=Erik D.|last1=Demaine|author1-link=Erik Demaine|first2=Gad M.|last2=Landau|author2-link = Gad Landau|first3=Oren|last3=Weimann|series=Lecture Notes in Computer Science|volume=5555|year=2009|pages=341–353|doi=10.1007/978-3-642-02927-1_29|title=Automata, Languages and Programming, 36th International Colloquium, ICALP 2009, Rhodes, Greece, July 5-12, 2009}}&lt;/ref&gt;

==Directed graphs==
In [[directed graph]]s, the maximum spanning tree solution cannot be used. Instead, several different algorithms are known; the choice of which algorithm to use depends on whether a start or destination vertex for the path is fixed, or whether paths for many start or destination vertices must be found simultaneously.

===All pairs===
The all-pairs widest path problem has applications in the [[Schulze method]] for choosing a winner in multiway [[election]]s in which voters rank the candidates in [[Ranked voting systems|preference order]]. The Schulze method constructs a [[tournament (graph theory)|complete directed graph]] in which the vertices represent the candidates and every two vertices are connected by an edge. Each edge is directed from the winner to the loser of a pairwise contest between the two candidates it connects, and is labeled with the margin of victory of that contest. Then the method computes widest paths between all pairs of vertices, and the winner is the candidate whose vertex has wider paths to each opponent than vice versa.&lt;ref name="Schulze"/&gt; The results of an election using this method are consistent with the [[Condorcet method]] – a candidate who wins all pairwise contests automatically wins the whole election – but it generally allows a winner to be selected, even in situations where the Concorcet method itself fails.&lt;ref&gt;More specifically, the only kind of tie that the Schulze method fails to break is between two candidates who have equally wide paths to each other.&lt;/ref&gt; The Schulze method has been used by several organizations including the [[Wikimedia Foundation]].&lt;ref name=Wikimedia&gt;See Jesse Plamondon-Willard, [[mailarchive:foundation-l/2008-May/043134.html|Board election to use preference voting]], May 2008; Mark Ryan, [[mailarchive:foundation-l/2008-June/044361.html|2008 Wikimedia Board Election results]], June 2008; [[m:Board elections/2008/Results/en|2008 Board Elections]], June 2008; and [[m:Board elections/2009/Results/en|2009 Board Elections]], August 2009.&lt;/ref&gt;

To compute the widest path widths for all pairs of nodes in a [[Dense graph|dense]] directed graph, such as the ones that arise in the voting application, the [[Asymptotic computational complexity|asymptotically]] fastest known approach takes time {{math|''O''(''n''&lt;sup&gt;(3+ω)/2&lt;/sup&gt;)}} where ω is the exponent for [[fast matrix multiplication]]. Using the best known algorithms for matrix multiplication, this time bound becomes  {{math|''O''(''n''&lt;sup&gt;2.688&lt;/sup&gt;)}}.&lt;ref&gt;{{citation
 | last1 = Duan | first1 = Ran
 | last2 = Pettie | first2 = Seth
 | contribution = Fast algorithms for (max, min)-matrix multiplication and bottleneck shortest paths
 | pages = 384–391
 | title = Proceedings of the 20th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA '09)
 | url = http://portal.acm.org/citation.cfm?id=1496813
 | year = 2009}}. For an earlier algorithm that also used fast matrix multiplication to speed up all pairs widest paths, see {{citation
 | last1 = Vassilevska | first1 = Virginia | author1-link = Virginia Vassilevska Williams
 | last2 = Williams | first2 = Ryan | author2-link = Ryan Williams (computer scientist)
 | last3 = Yuster | first3 = Raphael
 | contribution = All-pairs bottleneck paths for general graphs in truly sub-cubic time
 | doi = 10.1145/1250790.1250876
 | mr = 2402484
 | location = New York
 | pages = 585–589
 | publisher = ACM
 | title = [[Symposium on Theory of Computing|Proceedings of the 39th Annual ACM Symposium on Theory of Computing (STOC '07)]]
 | year = 2007}} and Chapter 5 of {{citation|title=Efficient Algorithms for Path Problems in Weighted Graphs|first=Virginia|last=Vassilevska|series=Ph.D. thesis, Report CMU-CS-08-147|year=2008|url=http://www.cs.cmu.edu/afs/cs/Web/People/virgi/thesis.pdf|publisher=Carnegie Mellon University School of Computer Science}}&lt;/ref&gt; Instead, the reference implementation for the Schulze method uses a modified version of the simpler [[Floyd–Warshall algorithm]], which takes {{math|''O''(''n''&lt;sup&gt;3&lt;/sup&gt;)}} time.&lt;ref name="Schulze"/&gt; For [[sparse graph]]s, it may be more efficient to repeatedly apply a single-source widest path algorithm.

===Single source===
If the edges are sorted by their weights, then a modified version of [[Dijkstra's algorithm]] can compute the bottlenecks between a designated start vertex and every other vertex in the graph, in linear time. The key idea behind the speedup over a conventional version of Dijkstra's algorithm is that the sequence of bottleneck distances to each vertex, in the order that the vertices are considered by this algorithm, is a [[monotonic]] subsequence of the sorted sequence of edge weights; therefore, the [[priority queue]] of Dijkstra's algorithm can be implemented as a [[bucket queue]]: an array indexed by the numbers from 1 to {{mvar|m}} (the number of edges in the graph), where array cell {{mvar|i}} contains the vertices whose bottleneck distance is the weight of the edge with position {{mvar|i}} in the sorted order. This method allows the widest path problem to be solved as quickly as [[sorting algorithm|sorting]]; for instance, if the edge weights are represented as integers, then the time bounds for [[integer sorting]] a list of {{mvar|m}} integers would apply also to this problem.&lt;ref name="kp"/&gt;

===Single source and single destination===
{{harvtxt|Berman|Handler|1987}} suggest that service vehicles and emergency vehicles should use minimax paths when returning from a service call to their base. In this application, the time to return is less important than the response time if another service call occurs while the vehicle is in the process of returning. By using a minimax path, where the weight of an edge is the maximum travel time from a point on the edge to the farthest possible service call, one can plan a route that minimizes the maximum possible delay between receipt of a service call and arrival of a responding vehicle.&lt;ref name="bh87"/&gt; {{harvtxt|Ullah|Lee|Hassoun|2009}} use maximin paths to model the dominant reaction chains in [[metabolic network]]s; in their model, the weight of an edge is the free energy of the metabolic reaction represented by the edge.&lt;ref name="ulh09"/&gt;

Another application of widest paths arises in the [[Ford–Fulkerson algorithm]] for the [[maximum flow problem]]. Repeatedly augmenting a flow along a maximum capacity path in the residual network of the flow leads to a small bound, {{math|''O''(''m'' log ''U'')}}, on the number of augmentations needed to find a maximum flow; here, the edge capacities are assumed to be integers that are at most {{mvar|U}}. However, this analysis does not depend on finding a path that has the exact maximum of capacity; any path whose capacity is within a constant factor of the maximum suffices. Combining this approximation idea with the shortest path augmentation method of the [[Edmonds–Karp algorithm]] leads to a maximum flow algorithm with running time {{math|''O''(''mn'' log ''U'')}}.&lt;ref name="amo"&gt;{{citation | first1=Ravindra K. | last1=Ahuja | author1-link = Ravindra K. Ahuja | first2 = Thomas L. | last2 = Magnanti | author2-link = Thomas L. Magnanti | first3 = James B. | last3 = Orlin | author3-link = James B. Orlin | title= Network Flows: Theory, Algorithms and Applications | publisher=Prentice Hall | year=1993 | isbn=0-13-617549-X|contribution=7.3 Capacity Scaling Algorithm|pages=210–212}}&lt;/ref&gt;

It is possible to find maximum-capacity paths and minimax paths with a single source and single destination very efficiently even in models of computation that allow only comparisons of the input graph's edge weights and not arithmetic on them.&lt;ref name="kp"/&gt;&lt;ref name="gt"&gt;{{citation
 | last1 = Gabow | first1 = Harold N.
 | last2 = Tarjan | first2 = Robert E. | author2-link = Robert Tarjan
 | doi = 10.1016/0196-6774(88)90031-4
 | mr = 955149
 | issue = 3
 | journal = Journal of Algorithms
 | pages = 411–417
 | title = Algorithms for two bottleneck optimization problems
 | volume = 9
 | year = 1988}}&lt;/ref&gt; The algorithm maintains a set {{mvar|S}} of edges that are known to contain the bottleneck edge of the optimal path; initially, {{mvar|S}} is just the set of all {{mvar|m}} edges of the graph. At each iteration of the algorithm, it splits {{mvar|S}} into an ordered sequence of subsets {{math|''S''&lt;sub&gt;1&lt;/sub&gt;, ''S''&lt;sub&gt;2&lt;/sub&gt;, ...}} of approximately equal size; the number of subsets in this partition is chosen in such a way that all of the split points between subsets can be found by repeated median-finding in time {{math|''O''(''m'')}}. The algorithm then reweights each edge of the graph by the index of the subset containing the edge, and uses the modified Dijkstra algorithm on the reweighted graph; based on the results of this computation, it can determine in linear time which of the subsets contains the bottleneck edge weight. It then replaces {{mvar|S}} by the subset {{math|''S''&lt;sub&gt;''i''&lt;/sub&gt;}} that it has determined to contain the bottleneck weight, and starts the next iteration with this new set&amp;nbsp;{{mvar|S}}. The number of subsets into which {{mvar|S}} can be split increases exponentially with each step, so the number of iterations is proportional to the [[iterated logarithm]] function, {{math|''O''({{log-star}}''n'')}}, and the total time is {{math|''O''(''m'' {{log-star}}''n'')}}.&lt;ref name="gt"/&gt; In a model of computation where each edge weight is a machine integer, the use of repeated bisection in this algorithm can be replaced by a list-splitting technique of {{harvtxt|Han|Thorup|2002}}, allowing {{mvar|S}} to be split into {{math|''O''({{sqrt|''m''}})}} smaller sets {{math|''S''&lt;sub&gt;''i''&lt;/sub&gt;}} in a single step and leading to a linear overall time bound.&lt;ref&gt;{{citation
 | last1 = Han | first1 = Yijie
 | last2 = Thorup | first2 = M. | author2-link = Mikkel Thorup
 | contribution = Integer sorting in {{math|O(''n''{{sqrt|log log ''n''}})}} expected time and linear space
 | doi = 10.1109/SFCS.2002.1181890
 | pages = 135–144
 | title = [[Symposium on Foundations of Computer Science|Proc. 43rd Annual Symposium on Foundations of Computer Science (FOCS 2002)]]
 | year = 2002}}.&lt;/ref&gt;

==Euclidean point sets==
[[File:Gaussian moat 15x15.svg|thumb|The dark blue band separates pairs of [[Gaussian integer|Gaussian prime numbers]] whose minimax path length is 2 or more.]]
A variant of the minimax path problem has also been considered for sets of points in the [[Euclidean plane]]. As in the undirected graph problem, this Euclidean minimax path problem can be solved efficiently by finding a [[Euclidean minimum spanning tree]]: every path in the tree is a minimax path. However, the problem becomes more complicated when a path is desired that not only minimizes the hop length but also, among paths with the same hop length, minimizes or approximately minimizes the total length of the path. The solution can be approximated using [[geometric spanner]]s.&lt;ref&gt;{{citation
 | last1 = Bose | first1 = Prosenjit | author1-link = Jit Bose
 | last2 = Maheshwari | first2 = Anil
 | last3 = Narasimhan | first3 = Giri
 | last4 = Smid | first4 = Michiel
 | last5 = Zeh | first5 = Norbert
 | doi = 10.1016/j.comgeo.2004.04.003
 | mr = 2095376
 | issue = 3
 | journal = [[Computational Geometry (journal)|Computational Geometry. Theory and Applications]]
 | pages = 233–249
 | title = Approximating geometric bottleneck shortest paths
 | volume = 29
 | year = 2004}}&lt;/ref&gt;

In [[number theory]], the unsolved [[Gaussian moat]] problem asks whether or not minimax paths in the [[Gaussian integer|Gaussian prime numbers]] have bounded or unbounded minimax length. That is, does there exist a constant {{mvar|B}} such that, for every pair of points {{mvar|p}} and {{mvar|q}} in the infinite Euclidean point set defined by the Gaussian primes, the minimax path in the Gaussian primes between {{mvar|p}} and {{mvar|q}} has minimax edge length at most&amp;nbsp;{{mvar|B}}?&lt;ref&gt;{{citation
 | last1 = Gethner | first1 = Ellen
 | last2 = Wagon | first2 = Stan | author2-link = Stan Wagon
 | last3 = Wick | first3 = Brian
 | doi = 10.2307/2589708
 | mr = 1614871
 | issue = 4
 | journal = [[American Mathematical Monthly]]
 | pages = 327–337
 | title = A stroll through the Gaussian primes
 | volume = 105
 | year = 1998}}.&lt;/ref&gt;
{{clear}}

==References==
{{reflist|30em}}

[[Category:Network theory]]
[[Category:Polynomial-time problems]]
[[Category:Graph algorithms]]
[[Category:Computational problems in graph theory]]</text>
      <sha1>czz9a35o7vg6h8ydg6rqlc9wg5sb4dm</sha1>
    </revision>
  </page>
</mediawiki>
