<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Abstract nonsense</title>
    <ns>0</ns>
    <id>630022</id>
    <revision>
      <id>860100611</id>
      <parentid>860100576</parentid>
      <timestamp>2018-09-18T10:20:28Z</timestamp>
      <contributor>
        <ip>68.170.77.93</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6626">In [[mathematics]], '''abstract nonsense''', '''general abstract nonsense''', '''generalized abstract nonsense''', and '''general nonsense''' are terms used by [[mathematician]]s to describe abstract methods related to [[category theory]] and [[homological algebra]]. More generally, “abstract nonsense” may refer to a proof that relies on category-theoretic methods, or even to the study of category theory itself.

==Background==

Roughly speaking, category theory is the study of the general form, that is, categories of mathematical theories, without regard to their content.  As a result, [[mathematical proof]]s that rely on category-theoretic ideas often seem out of context, somewhat akin to a [[non sequitur (literary device)|non sequitur]].  Authors sometimes dub these proofs “abstract nonsense” as a light-hearted way of alerting readers to their abstract nature.  Labeling an argument "abstract nonsense" is usually ''not'' intended to be derogatory,&lt;ref name="monastyrsky"&gt;Michael Monastyrsky, ''Some Trends in Modern Mathematics and the Fields Medal.'' Can. Math. Soc. Notes, March and April 2001, Volume 33, nos. 2 and 3.  Online version available at http://www.fields.utoronto.ca/aboutus/FieldsMedal_Monastyrsky.pdf.
:"''In algebra, the term “abstract nonsense” has a definite meaning without any pejorative connotation.''"&lt;/ref&gt;&lt;ref name="mathworld" /&gt; and is instead used jokingly,&lt;ref name="maclane"/&gt; in a [[self-deprecating]] way,&lt;ref name="rotman"/&gt; affectionately,&lt;ref name="lang"/&gt; or even as a compliment to the generality of the argument.

Certain ideas and constructions in mathematics share a uniformity throughout many domains, unified by category theory. Typical methods include the use of [[classifying space]]s and [[universal property|universal properties]], use of the [[Yoneda lemma]], [[natural transformation]]s between [[functor]]s, and [[diagram chasing]].

When an audience can be assumed to be familiar with the general form of such arguments, mathematicians will use the expression ''Such and such is true by abstract nonsense'' rather than provide an elaborate explanation of particulars.&lt;ref name="mathworld"&gt;{{MathWorld| urlname=AbstractNonsense | title=Abstract Nonsense|author=Macura, Wiktor K.}}&lt;/ref&gt; For example, one might say ''By abstract nonsense, [[product (category theory)|products]] are unique up to isomorphism when they exist'', instead of arguing about how these isomorphisms can be derived from the [[universal property]] that defines the product. This allows one to skip proof details that can be considered trivial or not providing much insight, focusing instead on genuinely innovative parts of a larger proof.

==History==

The term predates the foundation of category theory as a subject itself. Referring to a joint paper with [[Samuel Eilenberg]] that introduced the notion of a "[[category (mathematics)|category]]" in 1942, [[Saunders Mac Lane]] wrote the subject was 'then called "general abstract nonsense"'.&lt;ref name="maclane"&gt;Saunders Mac Lane. "[http://www.pnas.org/content/94/12/5983.full The PNAS way back then]". ''Proc. Natl. Acad. Sci. USA'' Vol. 94, pp.&amp;nbsp;5983–5985, June 1997.
:"''The first of these papers is a more striking case; it introduced the very abstract idea of a "category"—a subject then called "general abstract nonsense"!''"&lt;/ref&gt; The term is often used to describe the application of category theory and its techniques to less abstract domains.&lt;ref&gt;[https://web.archive.org/web/20040726025100/http://www.csupomona.edu/~jis/1999/lord.pdf An Application of Abstract Nonsense to Surface Area], Harriet Lord&lt;/ref&gt;&lt;ref&gt;[http://www.edsko.net/tcd/talks/cattheory.pdf Abstract Nonsense for Functional Programmers], Edsko de Vries&lt;/ref&gt;

The term is believed to have been coined by the mathematician [[Norman Steenrod]],&lt;ref&gt;Colin McLarty, ''The Uses and Abuses of the History of Topos Theory'', Br. J. Philos. Sci., 41 (1990) p 355.
: "''Steenrod jokingly tagged category theory 'abstract nonsense' and made it central to his axiomatics for homology''"&lt;/ref&gt;&lt;ref name="rotman"&gt;Joseph Rotman, "''An Introduction to Homological Algebra'', by Charles A. Weibel" (book review), Bull. Am. Math. Soc., 33:4 (Oct. 1996) 473–476.
:"''The self-deprecating phrase ''general abstract nonsense'' (due to Steenrod) was promulgated by Eilenberg and Mac Lane, two of the major innovators of homological algebra, to highlight this aspect of the subject.''"&lt;/ref&gt;&lt;ref name="lang"&gt;[[Serge Lang]], "Algebra" Second Edition, Addison Wesley, 1984, p 175&lt;/ref&gt; himself one of the developers of the categorical point of view.

==Examples==

Consider the example of showing that a [[3-manifold]] ''M'' admits a [[map (mathematics)|map]] to the [[2-sphere]] that is non-trivial (i.e. non-homotopic to a constant map), when the 2nd [[Betti number]] of ''M'' is positive. This means the 2nd [[cohomology group]] has positive [[Rank of an abelian group|rank]] (by the  [[universal coefficient theorem for cohomology]]), so it has a non-zero element. The [[Cohomology#Eilenberg–MacLane spaces|properties of Eilenberg–MacLane space]]s then give a corresponding non-trivial map ''f'' from ''M'' to the infinite-dimensional [[complex projective space]] '''CP'''&lt;sup&gt;∞&lt;/sup&gt;, since it is a [[K(Z,2)|''K''('''Z''',2)]] [[Eilenberg–MacLane space]]. The space '''CP'''&lt;sup&gt;∞&lt;/sup&gt; can be realized as a [[CW complex]] with exactly one cell in each even dimension and no cells in odd dimension, while ''M'' can be realized with no cells in dimensions above 3, so by the [[cellular approximation theorem]] there is a map homotopic to ''f'' that maps ''M'' into the 3-skeleton of '''CP'''&lt;sup&gt;∞&lt;/sup&gt;, which is the 2-sphere.

Though this proof establishes the truth of the statement in question, the proof technique has little to do with the [[topology]] or [[geometry]] of the 2-sphere, let alone 3-manifolds, as it relies on more general categorical principles.  Because of the reliance on these abstract principles, the result is independent of subtler geometric details, so offers little geometric insight into the nature of such a map.  On the other hand, the proof is surprisingly short and clean, and a “hands-on” approach involving the explicit construction of such a map would be potentially laborious.

==Notes and references==
{{Reflist|30em}}

==External links==
{{wiktionary|abstract nonsense}}
* [http://www.math.harvard.edu/~elkies/M55a.05/nonsense.html Usage in mathematical exposition] from [http://www.math.harvard.edu/~elkies/ Noam Elkies' class notes]

[[Category:Mathematical terminology]]
[[Category:Category theory]]</text>
      <sha1>5lf4kfryh35bi5u1qbomzd1a8zvrmeu</sha1>
    </revision>
  </page>
  <page>
    <title>Adjacent-vertex-distinguishing-total coloring</title>
    <ns>0</ns>
    <id>39479572</id>
    <revision>
      <id>796032605</id>
      <parentid>787688399</parentid>
      <timestamp>2017-08-18T01:42:58Z</timestamp>
      <contributor>
        <username>Quinton Feldberg</username>
        <id>29380370</id>
      </contributor>
      <minor/>
      <comment>fix citations</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6788">[[File:Avd-total-coloring-of-complete-graph-K4.svg|thumb|A proper AVD-total-coloring of the [[complete graph]] K&lt;sub&gt;4&lt;/sub&gt; with 5 colors, the minimum number possible.]]

In [[graph theory]], a [[total coloring]] is a coloring on the vertices and edges of a graph such that:

(1). no adjacent vertices have the same color;

(2). no adjacent edges have the same color; and

(3). no edge and its endvertices are assigned the same color.

In 2005, Zhang et al.&lt;ref&gt;Zhang 2005.&lt;/ref&gt; added a restriction to the definition of total coloring and proposed a new type of coloring defined as follows.

Let ''G'' = (''V'',''E'') be a simple graph endowed with a total coloring φ, and let ''u'' be a vertex of ''G''. The set of colors that '''occurs''' in the vertex ''u'' is defined as ''C''(''u'') = {''&amp;phi;''(''u'')} ∪ {''&amp;phi;''(''uv'') | ''uv'' ∈ ''E''(''G'')}. Two vertices ''u'',''v'' ∈ ''V''(''G'') are '''distinguishable''' if their color-sets are distinct, i.e., ''C''(''u'') ≠ ''C''(''v'').

In [[graph theory]], a total coloring is an '''adjacent-vertex-distinguishing-total-coloring''' (AVD-total-coloring) if it has the following additional property:

(4). for every two adjacent vertices ''u'',''v'' of a graph ''G'', their colors-sets are distinct from each other, i.e., ''C''(''u'') ≠ ''C''(''v'').

The '''adjacent-vertex-distinguishing-total-chromatic number''' ''χ''&lt;sub&gt;at&lt;/sub&gt;(''G'') of a graph ''G'' is the least number of colors needed in an AVD-total-coloring of ''G''.

The following lower bound for the AVD-total chromatic number can be obtained from the definition of AVD-total-coloring: If a simple graph ''G'' has two adjacent vertices of maximum degree, then ''&amp;chi;''&lt;sub&gt;''at''&lt;/sub&gt;(''G'') ≥ Δ(''G'') + 2.&lt;ref&gt;Zhang 2005, p. 290.&lt;/ref&gt; Otherwise, if a simple graph ''G'' does not have two adjacent vertices of maximum degree, then ''&amp;chi;''&lt;sub&gt;''at''&lt;/sub&gt;(''G'') ≥ Δ(''G'') + 1.

In 2005, Zhang et al. determined the AVD-total-chromatic number for some classes of graphs, and based in their results they conjectured the following.

'''AVD-Total-Coloring Conjecture.''' (Zhang et al.&lt;ref&gt;Zhang 2005, p. 299.&lt;/ref&gt;)
:''&amp;chi;''&lt;sub&gt;''at''&lt;/sub&gt;(''G'') &amp;le; &amp;Delta;(''G'') + 3.

The AVD-Total-Coloring Conjecture is known to hold for some classes of graphs, such as [[complete graph]]s,&lt;ref&gt;Hulgan 2009, p. 2.&lt;/ref&gt; graphs with Δ=3,&lt;ref&gt;Hulgan 2009, p. 2.&lt;/ref&gt;&lt;ref&gt;Chen 2008.&lt;/ref&gt; and all [[bipartite graph]]s.&lt;ref&gt;Zhang 2005.&lt;/ref&gt;

In 2012, Huang et al.&lt;ref&gt;Huang2012&lt;/ref&gt; showed that ''&amp;chi;''&lt;sub&gt;''at''&lt;/sub&gt;(''G'') &amp;le; 2&amp;Delta;(''G'')
for any simple graph ''G'' with maximum degree &amp;Delta;(''G'') &gt; 2.
In 2014, Papaioannou and Raftopoulou&lt;ref&gt;Papaioannou2014&lt;/ref&gt; described an algorithmic procedure that gives a 
7-AVD-total-colouring for any 4-regular graph.

== Notes ==
{{Reflist}}

== References ==

* {{cite journal | last1 = Zhang | first1 = Zhong-fu | last2 = Chen | first2 = Xiang-en | last3 = Li | first3 = Jingwen | last4 = Yao | first4 = Bing | last5 = Lu | first5 = Xinzhong | last6 = Wang | first6 = Jianfang | year = 2005 | title = On adjacent-vertex-distinguishing total coloring of graphs | url = | journal = Science China Mathematics | volume = 48 | issue = 3 | pages = 289–299 | doi = 10.1360/03ys0207}}
* {{cite journal | last1 = Hulgan | first1 = Jonathan | year = 2009 | title = Concise proofs for adjacent vertex-distinguishing total colorings | url = | journal = Discrete Mathematics | volume = 309 | issue = 8 | pages = 2548–2550 | doi = 10.1016/j.disc.2008.06.002 }}
* {{cite journal | last1 = Chen | first1 = Xiang'en | year = 2008 | title = On the adjacent vertex distinguishing total coloring numbers of graphs with Delta=3 | url = | journal = Discrete Mathematics | volume = 308 | issue = 17| pages = 4003–4007 | doi = 10.1016/j.disc.2007.07.091 }}
* {{cite journal | last1 = Huang | first1 = D. | last2 = Wang | first2 = W. | last3 = Yan | first3 = C. | year = 2012 | title = A note on the adjacent vertex distinguishing total chromatic number of graphs | url = | journal = Discrete Mathematics | volume = 312 | issue = 24 | pages = 3544–3546 | doi = 10.1016/j.disc.2012.08.006 }}
* {{cite journal | last1 = Chen | first1 = Meirun | last2 = Guo | first2 = Xiaofeng | year = 2009 | title = Adjacent vertex-distinguishing edge and total chromatic numbers of hypercubes | url = | journal = Information Processing Letters | volume = 109 | issue = 12 | pages = 599–602 | doi = 10.1016/j.ipl.2009.02.006 }}
* {{cite journal | last1 = Wang | first1 = Yiqiao | last2 = Wang | first2 = Weifan | year = 2010 | title = Adjacent vertex distinguishing total colorings of outerplanar graphs | url = | journal = Journal of Combinatorial Optimization | volume = 19 | issue = 2 | pages = 123–133 | doi = 10.1007/s10878-008-9165-x }}
* {{cite journal|last1=P. de Mello |first1=Célia |last2=Pedrotti |first2=Vagner |year=2010 |title=Adjacent-vertex-distinguishing total coloring of indifference graphs |url=http://mc.sbm.org.br/edicoes/39/12_39_mc_rev_vagner_ctfgi.pdf |journal=Matematica Contemporanea |volume=39 |issue= |pages=101–110 |doi= }}{{dead link|date=June 2017 |bot=InternetArchiveBot |fix-attempted=yes }}
* {{cite journal | last1 = Wang | first1 = Weifan | last2 = Huang | first2 = Danjun | year = 2012 | title = The adjacent vertex distinguishing total coloring of planar graphs | url = | journal = Journal of Combinatorial Optimization | volume = 27| issue = 2| pages = 379| doi = 10.1007/s10878-012-9527-2}}
* {{cite journal | last1 = Chen | first1 = Xiang-en | last2 = Zhang | first2 = Zhong-fu | year = 2008 | title = AVDTC numbers of generalized Halin graphs with maximum degree at least 6 | url = | journal = Acta Mathematicae Applicatae Sinica | volume = 24 | issue = 1 | pages = 55–58 | doi = 10.1007/s10878-012-9527-2}}
* {{cite journal | last1 = Huang | first1 = Danjun | last2 = Wang | first2 = Weifan | last3 = Yan | first3 = Chengchao | year = 2012 | title = A note on the adjacent vertex distinguishing total chromatic number of graphs | url = | journal = Discrete Mathematics | volume = 312 | issue = 24 | pages = 3544–3546 | doi = 10.1016/j.disc.2012.08.006}}
* {{cite journal | last1 = Papaioannou | first1 = A. | last2 = Raftopoulou | first2 = C. | year = 2014 | title = On the AVDTC of 4-regular graphs | url = | journal = Discrete Mathematics | volume = 330 | issue = | pages = 20–40 | doi = 10.1016/j.disc.2014.03.019}}
* {{cite journal | last1 = Luiz | first1 = Atílio G. | last2 = Campos | first2 = C.N. | last3 = de Mello | first3 = C.P. | year = 2015 | title = AVD-total-colouring of complete equipartite graphs | url = | journal = Discrete Applied Mathematics | volume = 184| issue = | pages = 189| doi = 10.1016/j.dam.2014.11.006}}

[[Category:Graph coloring]]</text>
      <sha1>h538ybt8vnq242ztx2rmbl9wjfg9pm7</sha1>
    </revision>
  </page>
  <page>
    <title>Arithmetic derivative</title>
    <ns>0</ns>
    <id>16838651</id>
    <revision>
      <id>870385365</id>
      <parentid>860900273</parentid>
      <timestamp>2018-11-24T12:45:19Z</timestamp>
      <contributor>
        <username>Crisófilax</username>
        <id>93624</id>
      </contributor>
      <minor/>
      <comment>/* Elementary properties */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5953">In [[number theory]], the '''Lagarias arithmetic derivative''', or '''number derivative''', is a function defined for [[integer]]s, based on [[prime factorization]], by analogy with the [[product rule]] for the [[derivative|derivative of a function]] that is used in [[mathematical analysis]].

There are many versions of "arithmetic derivatives", including the one discussed in this article (the Lagarias arithmetic derivative), such as Ihara's arithmetic derivative and Buium's arithmetic derivatives.

==Definition==
For [[natural numbers]] the arithmetic derivative is defined as follows:

* &lt;math&gt;p' \;=\; 1 &lt;/math&gt; for any prime &lt;math&gt;p &lt;/math&gt;.
* &lt;math&gt;(pq)'\;=\;p'q\,+\,p q' &lt;/math&gt; for any &lt;math&gt;p \textrm{,}\, q \;\in\; \mathbb{N}&lt;/math&gt; ([[product rule|Leibniz rule]]).

[[E. J. Barbeau]] was most likely the first person to formalize this definition. He also extended it to all integers by proving that &lt;math&gt;(-x)' \;=\; -(x')&lt;/math&gt; uniquely defines the derivative over the integers. Barbeau also further extended it to rational numbers, showing that the familiar [[quotient rule]] gives a well-defined derivative on '''Q''':

:&lt;math&gt;\left(\frac{p}{q}\right)' = \frac{p'q-p q'}{q^2} \ .&lt;/math&gt;

[[Victor Ufnarovski]] and [[Bo Åhlander]] expanded it to certain irrationals. In these extensions, the formula above still applies, but the exponents &lt;math&gt;e_i&lt;/math&gt; are allowed to be arbitrary rational numbers.

==Elementary properties==
The Leibniz rule implies that &lt;math&gt;0'=0&lt;/math&gt; (take &lt;math&gt;p = q = 0&lt;/math&gt;) and &lt;math&gt;1'=0&lt;/math&gt; (take &lt;math&gt;p = q = 1&lt;/math&gt;).

The ''power rule'' is also valid for the arithmetic derivative. For any integers {{mvar|p}} and {{math|''n'' &amp;ge; 0}}:

:&lt;math&gt;(p^n)' = np^{n-1} p'.&lt;/math&gt;

This allows one to compute the derivative from the prime factorisation of an integer, &lt;math&gt;x = p_1^{n_1}\cdots p_k^{n_k}&lt;/math&gt;:

:&lt;math&gt;x' = \sum_{i=1}^k n_i p_1^{n_1} \cdots p_{i-1}^{n_{i-1}} p_i^{n_i-1} p_{i+1}^{n_{i+1}}\cdots p_k^{n_k} = \sum_{i=1}^k \frac {n_i} {p_i}x.&lt;/math&gt;

For example: 

:&lt;math&gt;60' = (2^2 \cdot 3 \cdot 5)' = \left(\frac{2}{2} + \frac{1}{3} + \frac{1}{5}\right) \cdot 60 = 92,&lt;/math&gt;

or

:&lt;math&gt;81' = (3^4)' = 4\cdot 3^3\cdot 3' = 4\cdot 27\cdot 1 = 108.&lt;/math&gt;

The sequence of number derivatives for {{math|1=''k'' = 0, 1, 2, ...}} begins {{OEIS|id=A003415}}:

:&lt;math&gt;0, 0, 1, 1, 4, 1, 5, 1, 12, 6, 7, 1, 16, 1, 9, \ldots &lt;/math&gt;

== Related function==
The ''logarithmic derivative'' &lt;math&gt;\operatorname{ld}(x)=\frac{x'}{x}&lt;/math&gt; is a [[totally additive function]]: &lt;math&gt;\operatorname{ld}(x \cdot y) = \operatorname{ld}(x)+\operatorname{ld}(y).&lt;/math&gt;

==Inequalities and bounds==
E. J. Barbeau examined bounds of the arithmetic derivative. He found that the arithmetic derivative of natural numbers is bounded by
: &lt;math&gt;
n' \leq \frac{n \log_p n}{k}
&lt;/math&gt;
where '''''p''''' is the least prime in ''n'' and 

: &lt;math&gt;
n' \geq sn^{\frac{s-1}{s}}
&lt;/math&gt;
where '''''s''''' is the number of prime factors in ''n''.
In both bounds above, equality always occurs when ''n'' is a perfect power of 2, that is &lt;math&gt;n=2^m&lt;/math&gt; for some ''m''.

[[Alexander Loiko]], [[Jonas Ernst Olsson|Jonas Olsson]] and [[Niklas Dahl]] found that it is impossible to find similar bounds for the arithmetic derivative extended to rational numbers by proving that between any two rational numbers there are other rationals with arbitrary large or small derivatives.

==Order of the average==
We have 

:&lt;math&gt; \sum_{n \le x} \frac{n'}{n} = T_0 x + O(\log x \log\log x) &lt;/math&gt;

and

:&lt;math&gt; \sum_{n \le x} n' = (1/2)T_0 x^2 + O(x^{1+\delta}) &lt;/math&gt;

for any δ&gt;0, where 

:&lt;math&gt;T_0 = \sum_p \frac{1}{p(p-1)}. &lt;/math&gt;

==Relevance to number theory==

[[Victor Ufnarovski]] and [[Bo Åhlander]] have detailed the function's connection to famous number-theoretic conjectures like the [[twin prime conjecture]], the prime triples conjecture, and [[Goldbach's conjecture]]. For example, Goldbach's conjecture would imply, for each ''k''&amp;nbsp;&gt;&amp;nbsp;1 the existence of an ''n'' so that ''n''&lt;nowiki&gt;'&lt;/nowiki&gt; = 2''k''. The twin prime conjecture would imply that there are infinitely many ''k'' for which ''k''&lt;nowiki&gt;''&lt;/nowiki&gt; = 1.

==References==
{{reflist}}
* {{cite journal | first=E. J. | last=Barbeau | title=Remarks on an arithmetic derivative | journal=[[Canadian Mathematical Bulletin]] | volume=4 | year=1961 | pages=117–122 | doi=10.4153/CMB-1961-013-0 | zbl=0101.03702 }}
* {{cite journal | first1=Victor | last1=Ufnarovski | first2=Bo | last2=Åhlander | url=http://www.cs.uwaterloo.ca/journals/JIS/VOL6/Ufnarovski/ufnarovski.html | title=How to Differentiate a Number | journal=[[Journal of Integer Sequences]] | volume=6 | year=2003 | at=Article 03.3.4 | zbl=1142.11305 | issn=1530-7638 }}
* [https://web.archive.org/web/20071018000709/http://planetmath.org/encyclopedia/ArithmeticDerivative.html Arithmetic Derivative]'', [[Planet Math]]'', accessed 04:15, 9 April 2008 (UTC)
* L. Westrick (2003). ''[https://web.archive.org/web/20050426071741/http://web.mit.edu/lwest/www/intmain.pdf Investigations of the Number Derivative]''.
* Peterson, I. ''[http://www.maa.org/mathland/mathtrek_03_22_04.html Math Trek: Deriving the Structure of Numbers]''.
* {{cite journal | first=Michael | last=Stay | journal=[[Journal of Integer Sequences]] | volume=8 | year=2005 | at=Article 05.1.4 | title=Generalized Number Derivatives | url=https://cs.uwaterloo.ca/journals/JIS/VOL8/Stay/stay44.html | zbl=1065.05019 | issn=1530-7638 }}
* Dahl N., Olsson J., Loiko A., ''[https://arxiv.org/abs/1108.4762 Investigation of the properties of the arithmetic derivative]''.
*{{cite book | last1 = Balzarotti| first1 = Giorgio| last2 = Lava| first2 = Paolo Pietro| title = La derivata aritmetica. Alla scoperta di un nuovo approccio alla teoria dei numeri | publisher= Hoepli| location = Milan | date = 2013| isbn = 978-88-203-5864-8 }}

[[Category:Number theory]]
[[Category:Generalizations of the derivative]]</text>
      <sha1>0mjupqu4o5k4gca3gbxo59fpd8ww4e4</sha1>
    </revision>
  </page>
  <page>
    <title>Arithmetic shift</title>
    <ns>0</ns>
    <id>40725</id>
    <revision>
      <id>861598366</id>
      <parentid>856640156</parentid>
      <timestamp>2018-09-28T16:10:42Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Rescued 1 archive link; reformat 1 link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13901">&lt;!--This article is in Commonwealth English--&gt;
[[Image:Rotate left logically.svg|thumb|300px|A left arithmetic shift of a binary number by 1. The empty position in the [[least significant bit]] is filled with a zero.]]
[[Image:Rotate right arithmetically.svg|thumb|300px|A right arithmetic shift of a binary number by 1. The empty position in the most significant bit is filled with a copy of the original MSB.]]

&lt;!-- Table arranged in rough alphabetic order of shifts. --&gt;
{| class="wikitable" style="float:right; clear:right;"
|+ Arithmetic shift operators in various programming languages and processors
! Language or processor !! Left !! Right
|-
| [[ActionScript]] 3, [[Java (programming language)|Java]], [[JavaScript]], [[Python (programming language)|Python]], [[PHP]], [[Ruby (programming language)|Ruby]];&lt;br /&gt;[[C (programming language)|C]], [[C++]], [[C_Sharp_(programming_language)|C#]], [[Go (programming language)|Go]], [[Julia (programming language)|Julia]], [[Swift (programming language)|Swift]] (signed types only)&lt;ref group="note"&gt;The &lt;code&gt; &gt;&gt; &lt;/code&gt; operator in C and C++ is not necessarily an arithmetic shift.  Usually it is only an arithmetic shift if used with a signed integer type on its left-hand side.  If it is used on an unsigned integer type instead, it will be a ''logical'' shift.&lt;/ref&gt; || &lt;code&gt; &lt;&lt; &lt;/code&gt; || &lt;code&gt; &gt;&gt; &lt;/code&gt;
|-
| [[Standard ML]] || &lt;code&gt; &lt;&lt; &lt;/code&gt; || &lt;code&gt; ~&gt;&gt; &lt;/code&gt;
|-
| [[Verilog]] || &lt;code&gt; &lt;&lt;&lt; &lt;/code&gt; || &lt;code&gt; &gt;&gt;&gt; &lt;/code&gt;&lt;ref group="note"&gt;The Verilog arithmetic right shift operator only actually performs an arithmetic shift if the first operand is signed.  If the first operand is unsigned, the operator actually performs a ''logical'' right shift.&lt;/ref&gt;
|-
| [[OpenVMS]] macro language
| colspan="2" align="center" | @{{#tag:ref|In the [[OpenVMS]] macro language, whether an arithmetic shift is left or right is determined by whether the second operand is positive or negative. This is unusual. In most programming languages the two directions have distinct operators, with the operator specifying the direction, and the second operand is implicitly positive. (Some languages, such as Verilog, require that negative values be converted to unsigned positive values. Some languages, such as C and C++, have no defined behaviour if negative values are used.){{sfn|HP|2001}}{{Page needed|date=March 2012}}|group="note"}}
|-
| [[Scheme (programming language)|Scheme]]
| colspan="2" align="center" | &lt;code&gt;arithmetic-shift&lt;/code&gt;&lt;ref group="note" name="scheme"&gt;In Scheme &lt;code&gt;arithmetic-shift&lt;/code&gt; can be both left and right shift, depending on the second operand, very similar to the OpenVMS macro language, although R6RS Scheme adds both &lt;code&gt;-right&lt;/code&gt; and &lt;code&gt;-left&lt;/code&gt; variants.&lt;/ref&gt;
|-
| [[Common Lisp]]
| colspan="2" align="center" | &lt;code&gt;ash&lt;/code&gt;
|-
| [[OCaml]] || &lt;code&gt;lsl&lt;/code&gt; || &lt;code&gt;asr&lt;/code&gt;
|-
| [[Haskell (programming language)|Haskell]] || &lt;code&gt;shiftL&lt;/code&gt; || &lt;code&gt;shiftR&lt;/code&gt;
|-
| Assembly, [[Motorola 68000 series|68k]] || &lt;code&gt;ASL&lt;/code&gt; || &lt;code&gt;ASR&lt;/code&gt;
|-
| [[x86 assembly language|Assembly, x86]] || &lt;code&gt;SAL&lt;/code&gt; || &lt;code&gt;SAR&lt;/code&gt;
|-
| [[VHDL]] || &lt;code&gt;sla&lt;/code&gt;&lt;ref group="note"&gt;The VHDL arithmetic left shift operator is unusual.  Instead of filling the LSB of the result with zero, it copies the original LSB into the new LSB.  While this is an exact mirror image of the arithmetic right shift, it is not the conventional definition of the operator, and is not equivalent to multiplication by a power of 2.  In the VHDL 2008 standard this strange behavior was left unchanged (for backward compatibility) for argument types that do not have forced numeric interpretation (e.g., BIT_VECTOR) but 'SLA' for ''unsigned'' and ''signed'' argument types behaves in the expected way (i.e., rightmost positions are filled with zeros).  VHDL's shift left logical (SLL) function does implement the aforementioned 'standard' arithmetic shift.&lt;/ref&gt; || &lt;code&gt;sra&lt;/code&gt;
|}
In [[computer programming]], an '''arithmetic shift''' is a [[shift operator]], sometimes termed a '''signed shift''' (though it is not restricted to signed operands).  The two basic types are the '''arithmetic left shift''' and the '''arithmetic right shift'''. For [[binary numeral system|binary number]]s it is a [[bitwise operation]] that shifts all of the bits of its operand; every bit in the operand is simply moved a given number of bit positions, and the vacant bit-positions are filled in.  Instead of being filled with all 0s, as in [[logical shift]], when shifting to the right, the leftmost bit (usually the [[sign bit]] in signed integer representations) is replicated to fill in all the vacant positions (this is a kind of [[sign extension]]).

Some authors prefer the terms ''sticky right-shift'' and ''zero-fill right-shift'' for arithmetic and logical shifts respectively.&lt;ref&gt;
Thomas R. Cain and Alan T. Sherman.
[https://web.archive.org/web/20140109191811/http://www.cisa.umbc.edu/papers/ShermanCryptologia97.pdf "How to break Gifford's cipher"].
Section 8.1: "Sticky versus Non-Sticky Bit-shifting".
Cryptologia.
1997.
&lt;/ref&gt;

Arithmetic shifts can be useful as efficient ways to perform multiplication or division of signed integers by powers of two. Shifting left by ''n'' bits on a signed or unsigned binary number has the effect of multiplying it by 2&lt;sup&gt;''n''&lt;/sup&gt;. Shifting right by ''n'' bits on a [[two's complement]] ''signed'' binary number has the effect of dividing it by 2&lt;sup&gt;''n''&lt;/sup&gt;, but it always rounds down (towards negative infinity). This is different from the way rounding is usually done in signed integer division (which rounds towards 0). This discrepancy has led to bugs in more than one compiler.&lt;ref&gt;{{cite web|last=Steele Jr|first=Guy|title=Arithmetic Shifting Considered Harmful|url=http://dspace.mit.edu/bitstream/handle/1721.1/6090/AIM-378.pdf|publisher=MIT AI Lab|accessdate=20 May 2013}}&lt;/ref&gt;

For example, in the [[x86 instruction listings|x86 instruction set]], the SAR instruction (arithmetic right shift) divides a signed number by a power of two, rounding towards negative infinity.{{sfn|Hyde|1996|loc=&amp;sect; 6.6.2.2 SAR}} However, the IDIV instruction (signed divide) divides a signed number, rounding towards zero. So a SAR instruction cannot be substituted for an IDIV by power of two instruction nor vice versa.

== Formal definition ==
The formal definition of an arithmetic shift, from [[Federal Standard 1037C]] is that it is:
:A shift, applied to the representation of a number in a fixed [[radix]] numeration system and in a [[fixed-point arithmetic|fixed-point]] representation system, and in which only the characters representing the fixed-point part of the number are moved. An arithmetic shift is usually equivalent to multiplying the number by a positive or a negative integral power of the radix, except for the effect of any rounding; compare the [[logical shift]] with the arithmetic shift, especially in the case of [[floating-point]] representation.

An important word in the FS 1073C definition is "usually".

=== Equivalence of arithmetic left shift and multiplication ===
Arithmetic ''left'' shifts are equivalent to multiplication by a (positive, integral) power of the radix (e.g., a multiplication by a power of 2 for binary numbers).  Arithmetic left shifts are, with two exceptions, identical in effect to logical left shifts.  Exception one is the minor trap that arithmetic shifts may trigger [[arithmetic overflow]] whereas logical shifts do not. Obviously, that exception occurs in real world use cases only if a trigger signal for such an overflow is needed by the design it is used for. Exception two is the MSB is preserved.  Processors usually do not offer logical and arithmetic left shift operations with a significant difference, if any.

=== Non-equivalence of arithmetic right shift and division ===
However, arithmetic ''right'' shifts are major traps for the unwary, specifically in treating rounding of negative integers. For example, in the usual [[two's complement]] representation of negative integers, −1 is represented as all 1's. For an 8-bit signed integer this is 1111&amp;nbsp;1111. An arithmetic right-shift by 1 (or 2, 3, …, 7) yields 1111&amp;nbsp;1111 again, which is still −1. This corresponds to rounding down (towards negative infinity), but is not the usual convention for division.

It is frequently stated that arithmetic right shifts are equivalent to [[division (mathematics)|division]] by a (positive, integral) power of the radix (e.g., a division by a power of 2 for binary numbers), and hence that division by a power of the radix can be optimized by implementing it as an arithmetic right shift.  (A shifter is much simpler than a divider.  On most processors, shift instructions will execute faster than division instructions.) Large number of 1960s and 1970s programming handbooks, manuals, and other specifications from companies and institutions such as [[Digital Equipment Corporation|DEC]], [[IBM]], [[Data General]], and [[American National Standards Institute|ANSI]] make such incorrect statements {{sfn|Steele|1977|p=}}{{Page needed|date=March 2012}}.

Logical right shifts are equivalent to division by a power of the radix (usually 2) only for positive or unsigned numbers. Arithmetic right shifts are equivalent to logical right shifts for positive signed numbers. Arithmetic right shifts for negative numbers in N&amp;minus;1's complement (usually [[two's complement]]) is roughly equivalent to division by a power of the radix (usually 2), where for odd numbers rounding downwards is applied (not towards 0 as usually expected).

Arithmetic right shifts for negative numbers are equivalent to division using rounding towards 0 in [[one's complement]] representation of signed numbers as was used by some historic computers, but this is no longer in general use.

==== Handling the issue in programming languages ====

The (1999) ISO standard for the programming language [[C (programming language)|C]] defines the right shift operator in terms of divisions by powers of 2.{{sfn|ISOIEC9899|1999|loc=&amp;sect; 6.5.7 Bitwise shift operators}} Because of the above-stated non-equivalence, the standard explicitly excludes from that definition the right shifts of signed numbers that have negative values.  It does not specify the behaviour of the right shift operator in such circumstances, but instead requires each individual C compiler to define the behaviour of shifting negative values right.{{#tag:ref|The C standard was intended to not restrict the C language to either ones' complement or two's complement architectures.  In cases where the behaviours of ones' complement and two's complement representations differ, such as this, the standard requires individual C compilers to document the behaviour of their target architectures.  The documentation for [[GNU Compiler Collection]] (GCC), for example, documents its behaviour as employing sign-extension.{{sfn|FSF|2008|loc=&amp;sect; 4.5 Integers implementation}}|group="note"}}

== Applications ==
In applications where consistent rounding down is desired, arithmetic right shifts for signed values are useful. An example is in [[downscaling]] raster coordinates by a power of two, which maintains even spacing. For example, right shift by 1 sends 0, 1, 2, 3, 4, 5, … to 0, 0, 1, 1, 2, 2, …, and −1, −2, −3, −4, … to −1, −1, −2, −2, …, maintaining even spacing as −2, −2, −1, −1, 0, 0, 1, 1, 2, 2, … In contrast, integer division with rounding towards zero sends −1, 0, and 1 all to 0 (3 points instead of 2), yielding −2, −1, −1, 0, 0, 0, 1, 1, 2, 2, … instead, which is irregular at 0.

== Notes ==
&lt;references group="note"/&gt;

== References ==

=== Cross-reference ===
{{Reflist|30em}}

=== Sources used ===
{{FS1037C}}
{{Refbegin}}
* {{cite book|ref=harv|first=Donald|last=Knuth|title=[[The Art of Computer Programming]], Volume 2 &amp;mdash; Seminumerical algorithms|pages=169&amp;ndash;170|location=Reading, Mass.|publisher=Addison-Wesley|year=1969|authorlink=Donald Knuth}}
* {{cite journal|ref=harv|title=Arithmetic shifting considered harmful|journal=ACM SIGPLAN Notices archive|volume=12|issue=11|date=November 1977|pages=61&amp;ndash;69|first=Guy L.|last=Steele|publisher=ACM Press|location=New York|doi=10.1145/956641.956647|url=http://www.dtic.mil/get-tr-doc/pdf?AD=ADA031883}}
* {{cite book |ref=CITEREFHP2001|chapter-url=http://h71000.www7.hp.com/doc/73FINAL/4515/4515pro_002.html#8_arithmeticshiftoperator |work=HP OpenVMS Systems Documentation|title=VAX MACRO and Instruction Set Reference Manual |chapter=3.7.1 Arithmetic Shift Operator|publisher=Hewlett-Packard Development Company|date=April 2001 |archive-url=https://web.archive.org/web/20110808085326/http://h71000.www7.hp.com/doc/73final/4515/4515pro_002.html#8_arithmeticshiftoperator |archive-date=2011-08-08}}
* {{Cite journal|ref=CITEREFISOIEC98991999|title=Programming languages &amp;mdash; C|publisher=[[International Organization for Standardization]]|year=1999|version=ISO/IEC 9899:1999}}
* {{cite book|ref=harv|chapter=CHAPTER SIX: THE 80x86 INSTRUCTION SET (Part 3)|date=1996-09-26|title=The Art of ASSEMBLY LANGUAGE PROGRAMMING|first=Randall|last=Hyde|url=http://www.arl.wustl.edu/~lockwood/class/cs306/books/artofasm/Chapter_6/CH06-3.html#HEADING3-120|access-date=2007-11-28|archive-url=https://web.archive.org/web/20071123223102/http://www.arl.wustl.edu/~lockwood/class/cs306/books/artofasm/Chapter_6/CH06-3.html#HEADING3-120|archive-date=2007-11-23|dead-url=yes|df=}}
* {{cite web|ref=CITEREFFSF2008|year=2008|publisher=[[Free Software Foundation]]|url=https://gcc.gnu.org/onlinedocs/gcc-4.3.3/gcc/Integers-implementation.html#Integers-implementation|work=GCC manual|title=C Implementation}}
{{refend}}

{{DEFAULTSORT:Arithmetic Shift}}
[[Category:Binary arithmetic]]
[[Category:Operators (programming)]]</text>
      <sha1>rmg0im35mpgit9j4j8zd60jdjpr50ot</sha1>
    </revision>
  </page>
  <page>
    <title>Association for Symbolic Logic</title>
    <ns>0</ns>
    <id>3770438</id>
    <revision>
      <id>866575533</id>
      <parentid>866575507</parentid>
      <timestamp>2018-10-31T05:30:29Z</timestamp>
      <contributor>
        <username>Thsb97</username>
        <id>25484303</id>
      </contributor>
      <minor/>
      <comment>/* Sacks Prize */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6311">{{Infobox organization
| name          = Association for Symbolic Logic
| bgcolor       = 
| fgcolor       = 
| image         = 
| image_border  = 
| size          = 
| alt           = 
| caption       = 
| abbreviation  =  ASL
| motto         = 
| predecessor   = 
| successor     = 
| formation     = 1936
| extinction    = 
| type          = [[Learned society|Scholarly society]]
| status        = 
| purpose       = [[Research]], [[Inquiry]]
| headquarters  = [[Poughkeepsie, New York]]
| location      = 
| coords        = 
| region_served = 
| membership    =  
| language      = 
| general       = 
| leader_title  = President
| leader_name   = [[Ulrich Kohlenbach]]
| leader_title2 = Vice President 
| leader_name2  = [[Julia F. Knight]]
| leader_title3 = Secretary
| leader_name3  = Charles I. Steinhorn
| leader_title4 = 
| leader_name4  = 
| key_people    = 
| main_organ    = 
| parent_organization = 
| affiliations  =
| budget        = 
| num_staff     = 
| num_volunteers = 
| website       = {{url|http://www.aslonline.org}}
| remarks       = 
| former name   = 
}}

The '''Association for Symbolic Logic''' ('''ASL''') is an [[international organization]] of specialists in [[mathematical logic]] and [[philosophical logic]].  The ASL was founded in 1936, and its first president was [[Alonzo Church]]. The current president of the ASL is [[Ulrich Kohlenbach]].&lt;ref&gt; {{cite web|url =https://www.aslonline.org/info-council.html|title= Council - Association for Symbolic Logic (ASL)|publisher= Association for Symbolic Logic|accessdate = 25 January 2018}} &lt;/ref&gt;

== Publications ==

The ASL publishes [[book]]s and [[academic journal]]s.  Its three official journals are:
* ''[[Journal of Symbolic Logic]]'' [https://web.archive.org/web/20110112081351/http://www.aslonline.org/journals-journal.html (website)] &amp;ndash; publishes research in all areas of mathematical logic.  Founded in 1936, {{issn|0022-4812}}.
* ''Bulletin of Symbolic Logic'' [http://www.aslonline.org/journals-bulletin.html (website)] &amp;ndash; publishes primarily expository articles and reviews. Founded in 1995, {{issn|1079-8986}}. 
* ''Review of Symbolic Logic'' [http://www.aslonline.org/journals-review.html (website)] &amp;ndash; publishes research relating to logic, philosophy, science, and their interactions. Founded in 2008, {{issn|1755-0203}}.

In addition, the ASL has a sponsored journal:  
* ''Journal of Logic and Analysis'' [http://www.logicandanalysis.org (website)] &amp;ndash; Publishes research on the interactions between mathematical logic and pure and applied analysis.  Founded in 2009 as an [[open-access journal|open-access]] successor to the Springer journal ''Logic and Analysis''. {{issn|1759-9008}}. 

The organization played a part in publishing the collected writings of [[Kurt Gödel]].

== Meetings ==

The ASL holds two main meetings every year, one in North America and one in Europe (the latter known as the ''Logic Colloquium''). In addition, the ASL regularly holds joint meetings with both the [[American Mathematical Society]] ("AMS") and the [[American Philosophical Association]] ("APA"), and sponsors meetings in many different countries every year.

==Awards==
The association periodically presents a number of prizes and awards.&lt;ref&gt; {{cite web|url = http://www.aslonline.org/info-prizes.html|title= Prizes and Awards|publisher= Association of Symbolic Logic|accessdate = 27 August 2015}} &lt;/ref&gt;

===Karp Prize===
The Karp Prize is awarded by the association every five years for an outstanding paper or book in the field of symbolic logic. It consists of a cash award and was established in 1973 in memory of Professor [[Carol Karp]]. 

Recipients comprise:&lt;br&gt;
Source: [https://web.archive.org/web/20080513151024/http://www.aslonline.org/Karp_recipients.html ASL]
*2013 [[Moti Gitik]], Tel Aviv University; [[Ya'acov Peterzil]], University of Haifa; [[Jonathan Pila]], University of Oxford; [[Sergei Starchenko]], University of Notre Dame;  [[Alex Wilkie]], University of Manchester
*2008 [[Zlil Sela]], Hebrew University
*2003 [[Gregory Hjorth]], UCLA and [[Alexander Kechris]], Caltech
*1998 [[Ehud Hrushovski]], Hebrew University
*1993 [[Ehud Hrushovski]], MIT and [[Alex Wilkie]], Oxford
*1988 [[Donald A. Martin]], UCLA; [[John R. Steel]], UCLA; [[W. Hugh Woodin]], University of California, Berkeley
*1983 [[Saharon Shelah]], Hebrew University
*1978 [[Robert Vaught]], University of California, Berkeley

===Sacks Prize===
The Sacks Prize is awarded for the most outstanding doctoral dissertation in mathematical logic. It consists of a cash award and was established in 1999 to honor Professor [[Gerald Sacks]] of MIT and Harvard.


The recipients comprise:

{| class="wikitable"
|-
! Year !! Recipient(s)
|-
| 2016 || William Johnson and Ludovic Patey
|-
| 2015  || [[Omer Ben-Neria]] and [[Martino Lupini]]
|-
| 2014 || no prize awarded
|-
| 2013 || [[Artem Chernikov]]  and [[Nathanaël Mariaule]]
|-
| 2012 || [[Pierre Simon]]
|-
| 2011 || [[Mingzhong Cai]] and Adam Day
|-
| 2010 || [[Uri Andrews]] 
|-
| 2009 || [[Isaac Goldbring]] and [[Grigor Sargsyan]]
|-
| 2008 || [[Inessa Epstein]] and [[Dilip Raghavan]]
|-
| 2007 || [[Adrien Deloro]] and [[Wojciech Moczydlowski]]
|-
| 2006 || [[Matteo Viale]]
|-
| 2005 || [[Antonio Montalbán]]
|-
| 2004 || [[Joseph Mileti]] and [[Nathan Segerlind]]
|-
| 2003 || [[Itay Ben Yaacov]]
|-
| 2002 || no prize awarded
|-
| 2001 || [[Matthias Aschenbrenner]]
|-
| 2000 || [[Eric Jaligot]]
|-
| 1999 || [[Denis Hirschfeldt]] and  [[Rene Schipperus]]
|-
| 1998 ||  no prize awarded
|-
| 1997 || [[Ilijas Farah]] and Thomas Scanlon
|-
| 1996 || [[Byunghan Kim]]
|-
| 1995 || [[Slawomir Solecki]]
|-
| 1994 || [[Gregory Hjorth]]
|}
 
 
  
  
 
 
 
 

 
  

 

 
 
 &lt;ref&gt;https://www.aslonline.org/Sacks_recipients.html&lt;/ref&gt;

===Shoenfield Prize===
The Shoenfield Prize is awarded for outstanding expository writing in the field of logic and honors the name of [[Joseph R. Shoenfield]].

==References==
{{reflist}}

==External links==
* [http://www.aslonline.org/index.htm ASL website]

{{Authority control}}
[[Category:Learned societies of the United States]]
[[Category:Mathematical logic organizations]]
[[Category:Philosophical logic]]
[[Category:Philosophy organizations]]
[[Category:Organizations established in 1936]]

{{logic-stub}}</text>
      <sha1>i7fqojv836wzxnp8a912v3w9tux8stc</sha1>
    </revision>
  </page>
  <page>
    <title>BUN-to-creatinine ratio</title>
    <ns>0</ns>
    <id>5653826</id>
    <revision>
      <id>833694097</id>
      <parentid>817548146</parentid>
      <timestamp>2018-04-02T00:09:41Z</timestamp>
      <contributor>
        <username>Me, Myself, and I are Here</username>
        <id>17619453</id>
      </contributor>
      <minor/>
      <comment>/* Definition */ move ref</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14048">{{Infobox diagnostic
| Name            = BUN-to-creatinine ratio
| Image           =
| Alt             =
| Caption         =
| DiseasesDB      =
| ICD10           =
| ICD9            =
| ICDO            =
| MedlinePlus     =
| eMedicine       =
| MeshID          =
| LOINC           = {{LOINC|44734-2}}, {{LOINC|3097-3}}
| HCPCSlevel2     =
| Reference_range =
}}
In [[medicine]], the '''BUN-to-creatinine ratio''' is the [[ratio]] of two serum laboratory values, the [[blood urea nitrogen]] (BUN) (mg/dL) and [[serum creatinine]] (Cr) (mg/dL). Outside the [[United States]], particularly in [[Canada]] and [[Europe]], the truncated term [[urea]] is used (though it is still the same blood chemical) and the units are different (mmol/L). The units of creatinine are also different (μmol/L), and this value is termed the '''urea-to-creatinine ratio'''. The ratio may be used to determine the cause of [[acute kidney injury]] or [[dehydration]].

The principle behind this ratio is the fact that both urea (BUN) and creatinine are freely filtered by the [[glomerulus]]; however, urea reabsorbed by the tubules can be regulated (increased or decreased) whereas creatinine reabsorption remains the same (minimal reabsorption).

==Definition==

Urea and creatinine are nitrogenous end products of metabolism.&lt;ref name="auto"&gt;{{cite book|url=https://www.ncbi.nlm.nih.gov/books/NBK305/|title=Clinical Methods: The History, Physical, and Laboratory Examinations|first=Adrian O.|last=Hosten|editor-first1=H. Kenneth|editor-last1=Walker|editor-first2=W. Dallas|editor-last2=Hall|editor-first3=J. Willis|editor-last3=Hurst|date=11 November 1990|publisher=Butterworths|via=PubMed|pmid=21250147}}&lt;/ref&gt; Urea is the primary metabolite derived from dietary protein and tissue protein turnover. Creatinine is the product of muscle creatine catabolism. Both are relatively small molecules (60 and 113 daltons, respectively) that distribute throughout total body water. In Europe, the whole urea molecule is assayed, whereas in the United States only the nitrogen component of urea (the blood or serum urea nitrogen, i.e., BUN or SUN) is measured. The BUN, then, is roughly one-half (7/15 or 0.466) of the blood urea.

The normal range of urea nitrogen in blood or serum is 5 to 20&amp;nbsp;mg/dl, or 1.8 to 7.1&amp;nbsp;mmol urea per liter. The range is wide because of normal variations due to protein intake, endogenous protein catabolism, state of hydration, hepatic urea synthesis, and renal urea excretion. A BUN of 15&amp;nbsp;mg/dl would represent significantly impaired function for a woman in the thirtieth week of gestation. Her higher glomerular filtration rate (GFR), expanded extracellular fluid volume, and anabolism in the developing fetus contribute to her relatively low BUN of 5 to 7&amp;nbsp;mg/dl. In contrast, the rugged rancher who eats in excess of 125 g protein each day may have a normal BUN of 20&amp;nbsp;mg/dl.

The normal serum creatinine (sCr) varies with the subject's body muscle mass and with the technique used to measure it. For the adult male, the normal range is 0.6 to 1.2&amp;nbsp;mg/dl, or 53 to 106 μmol/L by the kinetic or enzymatic method, and 0.8 to 1.5&amp;nbsp;mg/dl, or 70 to 133 μmol/L by the older manual Jaffé reaction. For the adult female, with her generally lower muscle mass, the normal range is 0.5 to 1.1&amp;nbsp;mg/dl, or 44 to 97 μmol/L by the enzymatic method.

==Technique==

Multiple methods for analysis of BUN and creatinine have evolved over the years. Most of those in current use are automated and give clinically reliable and reproducible results.

There are two general methods for the measurement of urea nitrogen. The diacetyl, or Fearon, reaction develops a yellow chromogen with urea, and this is quantified by photometry. It has been modified for use in autoanalyzers and generally gives relatively accurate results. It still has limited specificity, however, as illustrated by spurious elevations with sulfonylurea compounds, and by colorimetric interference from hemoglobin when whole blood is used.

In the more specific enzymatic methods, the enzyme urease converts urea to ammonia and carbonic acid. These products, which are proportional to the concentration of urea in the sample, are assayed in a variety of systems, some of which are automated. One system checks the decrease in absorbance at 340&amp;nbsp;mm when the ammonia reacts with alpha-ketoglutaric acid. The Astra system measures the rate of increase in conductivity of the solution in which urea is hydrolyzed.

Even though the test is now performed mostly on serum, the term BUN is still retained by convention. The specimen should not be collected in tubes containing sodium fluoride because the fluoride inhibits urease. Also chloral hydrate and guanethidine have been observed to increase BUN values.

The 1886 Jaffé reaction, in which creatinine is treated with an alkaline picrate solution to yield a red complex, is still the basis of most commonly used methods for measuring creatinine. This reaction is nonspecific and subject to interference from many noncreatinine chromogens, including acetone, acetoacetate, pyruvate, ascorbic acid, glucose, cephalosporins, barbiturates, and protein. It is also sensitive to pH and temperature changes. One or another of the many modifications designed to nullify these sources of error is used in most clinical laboratories today. For example, the recent kinetic-rate modification, which isolates the brief time interval during which only true creatinine contributes to total color formation, is the basis of the Astra modular system.

More specific, non-Jaffé assays have also been developed. One of these, an automated dry-slide enzymatic method, measures ammonia generated when creatinine is hydrolyzed by creatinine iminohydrolase. Its simplicity, precision, and speed highly recommend it for routine use in the clinical laboratory. Only 5-fluorocytosine interferes significantly with the test.

Creatinine must be determined in plasma or serum and not whole blood because erythrocytes contain considerable amounts of noncreatinine chromogens. To minimize the conversion of creatine to creatinine, specimens must be as fresh as possible and maintained at pH 7 during storage.

The amount of urea produced varies with substrate delivery to the liver and the adequacy of liver function. It is increased by a high-protein diet, by gastrointestinal bleeding (based on plasma protein level of 7.5 g/dl and a hemoglobin of 15 g/dl, 500 ml of whole blood is equivalent to 100 g protein), by catabolic processes such as fever or infection, and by antianabolic drugs such as tetracyclines (except doxycycline) or glucocorticoids. It is decreased by low-protein diet, malnutrition or starvation, and by impaired metabolic activity in the liver due to parenchymal liver disease or, rarely, to congenital deficiency of urea cycle enzymes. The normal subject on a 70 g protein diet produces about 12 g of urea each day.

This newly synthesized urea distributes throughout total body water. Some of it is recycled through the enterohepatic circulation. Usually, a small amount (less than 0.5&amp;nbsp;g/day) is lost through the gastrointestinal tract, lungs, and skin; during exercise, a substantial fraction may be excreted in sweat. The bulk of the urea, about 10&amp;nbsp;g each day, is excreted by the kidney in a process that begins with glomerular filtration. At high urine flow rates (greater than 2&amp;nbsp;ml/min), 40% of the filtered load is reabsorbed, and at flow rates lower than 2&amp;nbsp;ml/min, reabsorption may increase to 60%. Low flow, as in urinary tract obstruction, allows more time for reabsorption and is often associated with increases in antidiuretic hormone (ADH), which increases the permeability of the terminal collecting tubule to urea. During ADH-induced antidiuresis, urea secretion contributes to the intratubular concentration of urea. The subsequent buildup of urea in the inner medulla is critical to the process of urinary concentration. Reabsorption is also increased by volume contraction, reduced renal plasma flow as in congestive heart failure, and decreased glomerular filtration.

Creatinine formation begins with the transamidination from arginine to glycine to form glycocyamine or guanidoacetic acid (GAA). This reaction occurs primarily in the kidneys, but also in the mucosa of the small intestine and the pancreas. The GAA is transported to the liver where it is methylated by S-adenosyl methionine (SAM) to form creatine. Creatine enters the circulation, and 90% of it is taken up and stored by muscle tissue.&lt;ref name="auto"/&gt;

==Interpretation==
{{Blood test  sample values|align=right}}
Normal serum values
{| class="wikitable"
|-
! Test
! SI units
! US units
|-
| BUN (Urea)
|
| 7–20&amp;nbsp;mg/dL
|-
| Urea
| 2.5–10.7&amp;nbsp;mmol/L
| 20–40&amp;nbsp;mg/dL
|-
| Creatinine
| 62–106 μmol/L
| 0.7–1.2&amp;nbsp;mg/dL
|}

Serum Ratios
{| class="wikitable"
|-
! BUN:Cr
! Urea:Cr
! Location
! Mechanism
|-
| &gt;20:1
| &gt;100:1
| [[Acute kidney injury#Prerenal|Prerenal]] (before the [[kidney]])
| BUN reabsorption is increased. BUN is disproportionately elevated relative to creatinine in serum. Dehydration or hypoperfusion is suspected.
|-
| 10–20:1
| 40–100:1
| Normal or [[Acute kidney injury#Postrenal|Postrenal]] (after the kidney)
| Normal range.  Can also be postrenal disease. BUN reabsorption is within normal limits.
|-
| &lt;10:1
| &lt;40:1
| [[Acute kidney injury#Intrarenal|Intrarenal]] (within kidney)
| Renal damage causes reduced reabsorption of BUN, therefore lowering the BUN:Cr ratio.
|}

An elevated  BUN:Cr due to a low or low-normal creatinine and a BUN within the  reference range is unlikely to be of clinical significance.

==Specific causes of elevation==

===Acute kidney injury (previously termed acute renal failure)===
The ratio is predictive of prerenal injury when BUN:Cr exceeds 20&lt;ref&gt;{{cite journal |vauthors=Morgan DB, Carver ME, Payne RB |title=Plasma creatinine and urea: creatinine ratio in patients with raised plasma urea |journal=Br Med J |volume=2 |issue=6092 |pages=929–32 |date=October 1977 |pmid=912370 |pmc=1631607 |doi=10.1136/bmj.2.6092.929}}&lt;/ref&gt; or when urea:Cr exceeds 100.&lt;ref&gt;{{cite web|title=Acute renal failure: urea:creatinine ratio was not very helpful in diagnosing prerenal failure |work=Evidence-Based On-Call database |url=http://www.eboncall.org/CATs/1844.htm |deadurl=yes |archiveurl=https://web.archive.org/web/20060926050204/http://www.eboncall.org/CATs/1844.htm |archivedate=2006-09-26 |df= }}&lt;/ref&gt;  In prerenal injury, urea increases disproportionately to creatinine due to enhanced proximal tubular reabsorption that follows the enhanced transport of sodium and water.

===Gastrointestinal bleeding===
The ratio is useful for the diagnosis of [[upper gastrointestinal bleeding|bleeding]] from the [[gastrointestinal tract|gastrointestinal (GI) tract]] in patients who do not present with overt vomiting of blood.&lt;ref&gt;{{cite journal |vauthors=Witting MD, Magder L, Heins AE, Mattu A, Granja CA, Baumgarten M |title=ED predictors of upper gastrointestinal tract bleeding in patients without hematemesis |journal=Am J Emerg Med |volume=24 |issue=3 |pages=280–5 |date=May 2006 |pmid=16635697 |doi=10.1016/j.ajem.2005.11.005 |url=http://linkinghub.elsevier.com/retrieve/pii/S0735-6757(05)00427-4}}&lt;/ref&gt; In children, a BUN:Cr ratio of 30 or greater has a sensitivity of 68.8% and a specificity of 98% for upper gastrointestinal bleeding.&lt;ref&gt;{{cite journal |vauthors=Urashima M, Toyoda S, Nakano T |title=BUN/Cr ratio as an index of gastrointestinal bleeding mass in children |journal=J. Pediatr. Gastroenterol. Nutr. |volume=15 |issue=1 |pages=89–92 |date=July 1992 |pmid=1403455 |doi=10.1097/00005176-199207000-00014|display-authors=etal}}&lt;/ref&gt;

A common assumption is that the ratio is elevated because of amino acid digestion, since blood (excluding water) consists largely of the [[protein]] [[hemoglobin]] and is broken down by [[digestive enzyme]]s of the upper GI tract into amino acids, which are then reabsorbed in the GI tract and [[amino acid catabolism|broken down]] into urea.  However, elevated BUN:Cr ratios are not observed when other high protein loads (e.g., steak) are consumed.{{Citation needed|date=September 2011}} Renal hypoperfusion secondary to the blood lost from the GI  bleed has been postulated to explain the elevated BUN:Cr ratio. However, other research has found that renal hypoperfusion cannot fully explain the elevation.&lt;ref&gt;{{cite journal |vauthors=Mortensen PB, Nøhr M, Møller-Petersen JF, Balslev I |title=The diagnostic value of serum urea/creatinine ratio in distinguishing between upper and lower gastrointestinal bleeding. A prospective study. |journal=Danish Medical Bulletin |date=April 1994}}&lt;/ref&gt;

===Advanced age===
Because of decreased [[muscle]] mass, elderly patients may have an elevated BUN:Cr at baseline.&lt;ref&gt;{{cite journal |vauthors=Feinfeld DA, Bargouthi H, Niaz Q, Carvounis CP |title=Massive and disproportionate elevation of blood urea nitrogen in acute azotemia |journal=Int Urol Nephrol |volume=34 |issue=|pages=143–5 |year=2002 |pmid=12549657 |url=http://www.kluweronline.com/art.pdf?issn=0301-1623&amp;volume=34&amp;page=143}}&lt;/ref&gt;

===Other causes===
Hypercatabolic states, high-dose glucocorticoids, and resorption of large hematomas have all been cited as causes of a disproportionate rise in BUN relative to the creatinine.&lt;ref&gt;{{cite book|author=Irwin, RS. |author2=Rippe, JM.|title=Irwin and Rippe's Intensive Care Medicine|year=2008|publisher=Lippincott Williams &amp; Wilkins|location=Philadelphia|isbn=0781791537}}&lt;/ref&gt;

==References==
{{reflist|30em}}

==External links==
*{{cite journal |vauthors=Agrawal M, Swartz R |title=Acute renal failure |journal=Am Fam Physician |volume=61 |issue=7 |pages=2077–88 |date=April 2000 |pmid=10779250 |url=http://www.aafp.org/afp/20000401/2077.html}}

{{Blood tests}}
{{Renal physiology}}

{{DEFAULTSORT:Bun-to-creatinine ratio}}
[[Category:Nephrology]]
[[Category:Gastroenterology]]
[[Category:Ratios]]</text>
      <sha1>cj6venf40rjurqp93i8eqegduzt11j8</sha1>
    </revision>
  </page>
  <page>
    <title>Basis theorem (computability)</title>
    <ns>0</ns>
    <id>53605449</id>
    <revision>
      <id>775776907</id>
      <parentid>775606752</parentid>
      <timestamp>2017-04-17T01:33:00Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <minor/>
      <comment>clean up using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3297">In [[computability theory]], there are a number of '''basis theorems'''. These theorems show that particular kinds of sets always must have some members that are, in terms of [[Turing degree]], not too complicated. One family of basis theorems concern nonempty effectively closed sets (that is, nonempty &lt;math&gt;\Pi^0_1&lt;/math&gt; sets in the [[arithmetical hierarchy]]); these theorems are studied as part of classical computability theory. Another family of basis theorems concern nonempty lightface [[analytic set]]s (that is, &lt;math&gt;\Sigma^1_1&lt;/math&gt; in the [[analytical hierarchy]]); these theorems are studied as part of [[hyperarithmetical theory]].

== Effectively closed sets ==

Effectively closed sets are a topic of study in classical computability theory. An effectively closed set is the set of all paths through some computable subtree of the binary tree &lt;math&gt;2^{&lt;\omega}&lt;/math&gt;. These sets are closed, [[closed set|in the topological sense]], as subsets of the [[Cantor space]] &lt;math&gt;2^\omega&lt;/math&gt;, and the complement of an effective closed set is an effective open set in the sense of [[effective Polish space]]s.   [[Stephen Cole Kleene]] proved in 1952 that there is a nonempty, effectively closed set with no computable point (Cooper 1999, p.&amp;nbsp;134). There are basis theorems that show there must be points that are not "too far" from being computable, in an informal sense.

A class &lt;math&gt;X \subseteq 2^\omega&lt;/math&gt; is a '''basis''' for effectively closed sets if every nonempty effectively closed set includes a member of&amp;nbsp;''X'' (Cooper&amp;nbsp;2003, p.&amp;nbsp;329). Basis theorems show that particular classes are bases in this sense.  These theorems include (Cooper 1999, p.&amp;nbsp;134): 
* The '''[[low basis theorem]]''': each nonempty &lt;math&gt;\Pi^0_1&lt;/math&gt; set has a member that is of r.e. degree. 
* The '''hyperimmune-free basis theorem''': each nonempty &lt;math&gt;\Pi^0_1&lt;/math&gt; set has a member that is of [[hyperimmune-free]] degree. 
* The '''r.e. basis theorem''': each nonempty &lt;math&gt;\Pi^0_1&lt;/math&gt; set has a member that is of r.e. degree.

In the second bullet, a set ''X'' has hyperimmune-free degree if every total function from the natural numbers to the natural numbers is dominated by a total computable function.

== Lightface analytic sets ==

There are also basis theorems for lightface &lt;math&gt;\Sigma^1_1&lt;/math&gt; sets. These basis theorems are studied as part of [[hyperarithmetical theory]]. One theorem is the Gandy basis theorem, which is analogous to the low basis theorem. The '''Gandy basis theorem''' shows that each nonempty &lt;math&gt;\Sigma^1_1&lt;/math&gt;. set has an element that is hyperarithmetically low, that is, which has the same hyperdegree as [[Kleene's O|Kleene's set &lt;math&gt;\mathcal{O}&lt;/math&gt;]].

== References == 
* Cooper, S. B. (1999). "Local degree theory", in ''Handbook of Computability Theory'', E.R. Griffor (ed.), Elsevier, pp.&amp;nbsp;121&amp;ndash;153. {{ISBN|978-0-444-89882-1}}
* &amp;mdash; (2003), ''Computability Theory'', Chapman-Hall. {{ISBN|1-584-88237-9}}

== External links ==
* Simpson, S. "[http://sendailogic.math.tohoku.ac.jp/CTFM/slides/Simpson.pdf A survey of basis theorems]", slides from ''Computability Theory and Foundations of Mathematics'', Tokyo Institute of Technology, February 18–20, 2013.

[[Category:Computability theory]]</text>
      <sha1>ls1ffkbupj6kg3waw0zzs7sgclh99qt</sha1>
    </revision>
  </page>
  <page>
    <title>Bracket (mathematics)</title>
    <ns>0</ns>
    <id>11219603</id>
    <revision>
      <id>868445195</id>
      <parentid>868356605</parentid>
      <timestamp>2018-11-12T07:08:03Z</timestamp>
      <contributor>
        <username>Tea2min</username>
        <id>36029</id>
      </contributor>
      <comment>Undid revision 868356605 by [[Special:Contributions/129.59.122.14|129.59.122.14]] ([[User talk:129.59.122.14|talk]]): It was right before.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9183">In [[mathematics]], various typographical forms of [[bracket]]s are frequently used in [[mathematical notation]] such as [[parentheses]] (&amp;nbsp;), [[square brackets]] [&amp;nbsp;], braces {&amp;nbsp;}, and [[angle brackets]] ⟨&amp;nbsp;⟩.  Generally such bracketing denotes some form of grouping: in evaluating an expression containing a bracketed sub-expression, the operators in the sub-expression take precedence over those surrounding it. Additionally, there are several  uses and meanings for the various brackets.

Historically, other notations, such as the [[vinculum (symbol)|vinculum]], were similarly used for grouping; in present-day use, these notations all have specific meanings. The earliest use of brackets to indicate aggregation (i.e. grouping) was suggested in 1608 by [[Christopher Clavius]] and in 1629 by [[Albert Girard]].&lt;ref&gt;[[Cajori]], Florian 1980. ''A history of mathematics''. New York: Chelsea Publishing, p. 158&lt;/ref&gt;

==Symbols for representing angle brackets==
A variety of different symbols are used to represent angle brackets. In e-mail and other [[ASCII]] text it is common to use the less-than (&lt;code&gt;&amp;lt;&lt;/code&gt;) and greater-than (&lt;code&gt;&amp;gt;&lt;/code&gt;) signs to represent angle brackets, because ASCII does not include angle brackets.&lt;ref&gt;{{citation|title=The New Hacker's Dictionary|first=Eric S.|last=Raymond|authorlink=Eric S. Raymond|publisher=MIT Press|year=1996|isbn=9780262680929|page=41|url=https://books.google.com/books?id=g80P_4v4QbIC&amp;pg=PA41}}.&lt;/ref&gt; [[Unicode]] has three pairs of dedicated characters:
* {{unichar|27E8|MATHEMATICAL LEFT ANGLE BRACKET}} and {{unichar|27E9|MATHEMATICAL RIGHT ANGLE BRACKET}}
* {{unichar|3008|LEFT ANGLE BRACKET}} and {{unichar|3009|RIGHT ANGLE BRACKET}}, used in Chinese punctuation
* {{unichar|2329|LEFT-POINTING ANGLE BRACKET}} and {{unichar|232A|RIGHT-POINTING ANGLE BRACKET}}, which are deprecated&lt;ref&gt;{{cite web|url=https://www.unicode.org/charts/PDF/U2300.pdf||title=Miscellaneous Technical|publisher=unicode.org}}&lt;/ref&gt;

In [[LaTeX]] the markup is &lt;code&gt;\langle&lt;/code&gt; and &lt;code&gt;\rangle&lt;/code&gt;: &lt;math&gt;\langle\ \rangle&lt;/math&gt;.

==Algebra==
{{See|1=Associative property|2=Bracketing (linguistics)|3=Dyck language}}

In [[elementary algebra]] parentheses, ( ), are used to specify the [[order of operations]]. Terms inside the bracket are evaluated first; hence 2×(3&amp;nbsp;+&amp;nbsp;4) is 14 and 10 ÷ 5(1&amp;nbsp;+&amp;nbsp;0) is 2 and 8 ÷ 4(2&amp;nbsp;+&amp;nbsp;0) is 1 and (2×3)&amp;nbsp;+&amp;nbsp;4 is 10. This notation is extended to cover more general [[algebra]] involving variables: for example &lt;math&gt;(x+y)\times(x-y)&lt;/math&gt;. Square brackets are also often used in place of a second set of parentheses when they are nested, to provide a visual distinction.

Also in [[mathematical expression]]s in general, parentheses are used to indicate grouping (that is, which parts belong together) when necessary to avoid ambiguities, or for the sake of clarity. For example, in the formula (εη)&lt;sub&gt;''X''&lt;/sub&gt; = ε&lt;sub&gt;''Cod η&lt;sub&gt;X&lt;/sub&gt;''&lt;/sub&gt;η&lt;sub&gt;''X''&lt;/sub&gt;, used in the definition of composition of two [[natural transformation]]s, the parentheses around εη serve to indicate that the indexing by ''X'' is applied to the composition εη, and not just its last component η.

==Functions==
The arguments to a [[function (mathematics)|function]] are frequently surrounded by brackets: &lt;math&gt;f(x) &lt;/math&gt;. It is common to omit the parentheses around the argument when there is little chance of ambiguity, thus: &lt;math&gt;\sin x&lt;/math&gt;.

==Coordinates and vectors==

In the [[cartesian coordinate system]] brackets are used to specify the coordinates of a point: (2,3) denotes the point with ''x''-coordinate 2 and ''y''-coordinate 3. 

The [[inner product]] of two vectors is commonly written as &lt;math&gt; \langle a, b\rangle&lt;/math&gt;, but the notation (''a'', ''b'') is also used.

==Intervals==
{{main|Interval (mathematics)}}
Both parentheses, ( ), and square brackets, [ ], can also be used to denote an [[interval (mathematics)|interval]].  The notation &lt;math&gt;[a, c)&lt;/math&gt; is used to indicate an interval from a to c that is inclusive of &lt;math&gt;a&lt;/math&gt; but exclusive of &lt;math&gt;c&lt;/math&gt;. That is, &lt;math&gt;[5, 12)&lt;/math&gt; would be the set of all real numbers between 5 and 12, including 5 but not 12. The numbers may come as close as they like to 12, including 11.999 and so forth (with any [[finite set|finite]] number of 9s), but 12.0 is not included. In some European countries, the notation &lt;math&gt;[5,12[&lt;/math&gt; is also used for this.

The endpoint adjoining the square bracket is known as ''closed'', while the endpoint adjoining the parenthesis is known as ''open''. If both types of brackets are the same, the entire interval may be referred to as ''closed'' or ''open'' as appropriate. Whenever [[infinity]] or negative infinity is used as an endpoint in the case of intervals on the real number line, it is always considered ''open'' and adjoined to a parenthesis. The endpoint can be closed when considering intervals on the [[extended real number line]].

==Sets and groups==
Braces { } are used to identify the elements of a [[Set (mathematics)|set]]: {''a'',''b'',''c''} denotes a set of three elements. 

Angle brackets are used in [[group theory]] to write [[group presentation]]s, and to denote the [[group generators|subgroup generated]] by a collection of elements.

==Matrices==
An explicitly given [[matrix (mathematics)|matrix]] is commonly written between large round or square brackets:

:&lt;math&gt;\begin{pmatrix}
1 &amp; -1 \\
2 &amp; 3 \end{pmatrix}
\quad\quad\begin{bmatrix}
c &amp; d \end{bmatrix}
&lt;/math&gt;

==Derivatives==
The notation
:&lt;math&gt;f^{(n)}(x)&lt;/math&gt;
stands for the ''n''-th derivative of function ''f'', applied to argument ''x''. So, for example, if &lt;math&gt;f(x) = \exp(\lambda x)&lt;/math&gt;, then &lt;math&gt;f^{(n)}(x) = \lambda^n\exp(\lambda x)&lt;/math&gt;. This is to be contrasted with &lt;math&gt;f^n(x) = f(f(\ldots(f(x))\ldots))&lt;/math&gt;, the ''n''-fold application of ''f'' to argument ''x''.

==Falling and rising factorial==

The notation (''x'')&lt;sub&gt;''n''&lt;/sub&gt; is used to denote the ''[[falling factorial]]'', an ''n''-th degree [[polynomial]] defined by
:&lt;math&gt;(x)_n=x(x-1)(x-2)\cdots(x-n+1)=\frac{x!}{(x-n)!}.&lt;/math&gt;

Confusingly, the same notation may be encountered as representing the ''rising factorial'', also called "[[Pochhammer symbol]]". Another notation for the same is ''x''&lt;sup&gt;(''n'')&lt;/sup&gt;. It can be defined by
:&lt;math&gt;x^{(n)}=x(x+1)(x+2)\cdots(x+n-1)=\frac{(x+n-1)!}{(x-1)!}.&lt;/math&gt;

==Quantum mechanics==
In [[quantum mechanics]], angle brackets are also used as part of [[Paul Dirac|Dirac]]'s formalism, [[bra–ket notation]], to note vectors from the [[dual space]]s of the bra&amp;nbsp;&lt;math&gt;\left\langle A\right|&lt;/math&gt; and the ket&amp;nbsp;&lt;math&gt;\left|B\right\rangle&lt;/math&gt;. 

In statistical mechanics, angle brackets denote ensemble or time average.

==Polynomial rings==
Square brackets are used to denote the variable in [[polynomial ring]]s. For example, &lt;math&gt;\mathbb{R}[x]&lt;/math&gt; is the polynomial ring with the &lt;math&gt;x&lt;/math&gt; variable and [[real number]] coefficients.&lt;ref&gt;{{cite book|last=Stewart|first=Ian|title=Concepts of Modern Mathematics|year=1995|publisher=Dover Publications|page=90|url=https://books.google.ca/books?id=PcqiXD_BxA4C&amp;pg=PA90&amp;lpg=PA90#v=onepage&amp;q&amp;f=false}}&lt;/ref&gt;

==Lie bracket and commutator==
In [[group theory]] and [[ring theory]], square brackets are used to denote the [[commutator]].  In group theory, the commutator &lt;nowiki&gt;[&lt;/nowiki&gt;''g'',''h''&lt;nowiki&gt;]&lt;/nowiki&gt; is commonly defined as ''g''&lt;sup&gt;&amp;minus;1&lt;/sup&gt;''h''&lt;sup&gt;&amp;minus;1&lt;/sup&gt;''gh''.  In ring theory, the commutator &lt;nowiki&gt;[&lt;/nowiki&gt;''a'',''b''&lt;nowiki&gt;]&lt;/nowiki&gt; is defined as ''ab'' &amp;minus; ''ba''.  Furthermore, in  theory, braces are used to denote the [[commutator|anticommutator]] where {''a'',''b''} is defined as ''ab'' + ''ba''.  

The '''Lie bracket''' of a [[Lie algebra]] is a [[binary operation]]  denoted by &lt;math&gt;[\cdot,\cdot]:\mathfrak{g}\times\mathfrak{g}\to\mathfrak{g}&lt;/math&gt;. By using the commutator as a Lie bracket, every associative algebra can be turned into a Lie algebra. There are many different forms of '''Lie bracket''', in particular the [[Lie derivative]] and the [[Jacobi–Lie bracket]].

==Floor/ceiling functions and fractional part==

Square brackets, as in {{math|1=&amp;#91;[[Pi|π]]&amp;#93; = 3}}, are sometimes used to denote the [[floor function]], which [[rounding|rounds]] a real number down to the next integer. However the floor and ceiling functions are usually typeset with left and right square brackets where only the lower (for floor function) or upper (for ceiling function) horizontal bars are displayed, as in {{math|1=⌊π⌋ = 3}} or {{math|1=⌈π⌉ = 4}}.

Braces, as in {{math|1={π} &lt; &lt;sup&gt;1&lt;/sup&gt;/&lt;sub&gt;7&lt;/sub&gt;}}, may denote the [[fractional part]] of a real number.

==See also==
*[[Iverson bracket]]
*[[Binomial coefficient]]
*[[Poisson bracket]]
*[[Bracket polynomial]]
*[[Pochhammer symbol]]
*[[Frölicher–Nijenhuis bracket]]
*[[Nijenhuis–Richardson bracket]], also known as ''algebraic bracket''.
*[[Schouten–Nijenhuis bracket]]
*[[Dyck language]]

== Notes ==
&lt;references/&gt;

[[Category:Arithmetic]]
[[Category:Mathematical notation]]</text>
      <sha1>ep7sl0ci63yolucjs8wyp37azf43obp</sha1>
    </revision>
  </page>
  <page>
    <title>Cantor algebra</title>
    <ns>0</ns>
    <id>43215632</id>
    <revision>
      <id>747432762</id>
      <parentid>615945837</parentid>
      <timestamp>2016-11-02T10:37:58Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* References */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1973">{{for|the algebras encoding a bijection from an infinite set ''X'' onto the product ''X''×''X'', sometimes called Cantor algebras |Jónsson–Tarski algebra}}
In mathematics, a '''Cantor algebra''', named after [[Georg Cantor]], is one of two closely related Boolean algebras, one countable and one complete.

The countable Cantor algebra is the  Boolean algebra of all clopen subsets of the [[Cantor set]]. This is the free Boolean algebra on a countable number of generators. Up to isomorphism, this is the only nontrivial Boolean algebra that is both countable and atomless.

The complete Cantor algebra is the complete Boolean algebra of [[Borel subset]]s of the reals modulo [[meager set]]s {{harv|Balcar|Jech|2006}}. It is isomorphic to the completion of the countable Cantor algebra. (The complete Cantor algebra is sometimes called the Cohen algebra, though "[[Cohen algebra]]" usually refers to a different type of Boolean algebra.) The complete Cantor algebra was studied by von Neumann in 1935 (later published as {{harv|von Neumann|1998}}), who showed that it is not isomorphic to the [[random algebra]] of Borel subsets modulo measure zero sets.

==References==
*{{citation
 | last1 = Balcar | first1 = Bohuslav | author1-link = Bohuslav Balcar
 | last2 = Jech | first2 = Thomas | author2-link = Thomas Jech
 | issue = 2
 | journal = [[Bulletin of Symbolic Logic]]
 | mr = 2223923
 | pages = 241–266
 | title = Weak distributivity, a problem of von Neumann and the mystery of measurability
 | url = http://www.math.ucla.edu/~asl/bsl/1202-toc.htm
 | volume = 12
 | year = 2006}}
*{{Citation | last1=von Neumann | first1=John | author1-link=John von Neumann | title=Continuous geometry | origyear=1960 | url=https://books.google.com/books?id=onE5HncE-HgC | publisher=[[Princeton University Press]] | series=Princeton Landmarks in Mathematics | isbn=978-0-691-05893-1 | mr=0120174 | year=1998}}
 
[[Category:Forcing (mathematics)]]
[[Category:Boolean algebra]]</text>
      <sha1>1t8uifi971y6lnz2eu2on3r0huz38n3</sha1>
    </revision>
  </page>
  <page>
    <title>Category of metric spaces</title>
    <ns>0</ns>
    <id>535617</id>
    <revision>
      <id>778182982</id>
      <parentid>745471872</parentid>
      <timestamp>2017-05-01T16:36:34Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Moving category Category-theoretic categories to [[:Category:Categories in category theory]] per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2017 March 24]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4426">In [[category theory|category-theoretic mathematics]], '''Met''' is a category that has [[metric space]]s as its [[object (category theory)|objects]] and [[metric map]]s (continuous functions between metric spaces that do not increase any pairwise distance) as its [[morphism]]s. This is a category because the [[function composition|composition]] of two metric maps is again a metric map. It was  first considered by {{harvtxt|Isbell|1964}}.

==Arrows==
The [[monomorphism]]s in '''Met''' are the [[injective]] metric maps, maps that do not map two points into a single point. The [[epimorphism]]s are the metric maps in which the domain of the map has a dense image in the range. The [[isomorphism]]s are the [[isometry|isometries]], metric maps that are one-to-one, onto, and distance-preserving.

As an example, the inclusion of the [[rational number]]s into the [[real number]]s is a monomorphism and an epimorphism, but it is clearly not an isomorphism; this example shows that '''Met''' is not a [[balanced category]].

==Objects==
The empty metric space is the [[initial object]] of '''Met'''; any [[singleton (mathematics)|singleton]] metric space is a [[terminal object]]. Because the initial object and the terminal objects differ, there are no [[zero object]]s in '''Met'''.

The [[injective object]]s in '''Met''' are called [[injective metric space]]s. Injective metric spaces were introduced and studied first by {{harvtxt|Aronszajn|Panitchpakdi|1956}}, prior to the study of '''Met''' as a category; they may also be defined intrinsically in terms of a [[Helly family|Helly property]] of their metric balls, and because of this alternative definition Aronszajn and Panitchpakdi named these spaces ''hyperconvex spaces''. Any metric space has a smallest injective metric space into which it can be isometrically embedded, called its metric envelope or [[tight span]].

==Products and functors==
The [[product (category theory)|product]] of a finite set of metric spaces in '''Met''' is a metric space that has the [[cartesian product]] of the spaces as its points; the distance in the product space is given by the supremum of the distances in the base spaces. That is, it is the [[product metric]] with the sup norm. However, the product of an infinite set of metric spaces may not exist, because the distances in the base spaces may not have a supremum. That is, '''Met''' is not a [[complete category]], but it is finitely complete. There is no [[coproduct (category theory)|coproduct]] in '''Met'''.

The "forgetful" [[functor]] '''Met''' → '''[[category of sets|Set]]''' assigns to each metric space the underlying [[Set (mathematics)|set]] of its points, and assigns to each metric map the underlying [[function (mathematics)|set-theoretic function]]. This functor is [[faithful functor|faithful]], and therefore '''Met''' is a [[concrete category]].

==Related categories==
'''Met''' is not the only category whose objects are metric spaces; others include the category of [[uniform continuity|uniformly continuous functions]], the category of [[Lipschitz continuity|Lipschitz functions]] and the category of [[quasi-Lipschitz mapping]]s. The metric maps are both uniformly continuous and Lipschitz, with Lipschitz constant at most one.

== References ==
*{{citation
 | author1-link = Nachman Aronszajn | last1 = Aronszajn | first1 = N. | last2 = Panitchpakdi | first2 = P.
 | title = Extensions of uniformly continuous transformations and hyperconvex metric spaces
 | journal = Pacific Journal of Mathematics
 | volume = 6
 | year = 1956
 | pages = 405–439
 | url = http://projecteuclid.org/Dienst/UI/1.0/Summarize/euclid.pjm/1103043960 | doi=10.2140/pjm.1956.6.405}}.
*{{citation
 | last1 = Deza | first1 = Michel Marie | author1-link = Michel Deza
 | last2 = Deza | first2 = Elena
 | contribution = Category of metric spaces
 | page = 38
 | publisher = Springer-Verlag
 | title = Encyclopedia of Distances
 | url = https://books.google.com/books?id=LXEezzccwcoC&amp;pg=PA38
 | year = 2009}}.
*{{citation
 | last = Isbell | first = J. R. | authorlink = John R. Isbell
 | title = Six theorems about injective metric spaces
 | journal = Comment. Math. Helv.
 | volume = 39
 | issue = 1
 | year = 1964
 | pages = 65–76
 | url = http://www.digizeitschriften.de/resolveppn/GDZPPN002058340 | doi = 10.1007/BF02566944}}.

[[Category:Categories in category theory|Metric spaces]]
[[Category:Metric geometry]]</text>
      <sha1>bne6zh4zo38a7bf5j30kc27h7zzl5wf</sha1>
    </revision>
  </page>
  <page>
    <title>Center for Data-Driven Discovery</title>
    <ns>0</ns>
    <id>44638802</id>
    <revision>
      <id>713423594</id>
      <parentid>651107916</parentid>
      <timestamp>2016-04-03T23:46:48Z</timestamp>
      <contributor>
        <username>Bender235</username>
        <id>88026</id>
      </contributor>
      <minor/>
      <comment>clean up; http-&gt;https (see [[WP:VPR/Archive 127#RfC: Should we convert existing Google and Internet Archive links to HTTPS?|this RfC]]) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1493">The '''Center for Data-Driven Discovery''' &lt;ref&gt;[http://cd3.caltech.edu/about/ The Center for Data-Driven Discovery]&lt;/ref&gt; is a multi-division research group at the [[California Institute of Technology]], focusing on the methodologies for handling and analysis of large and complex data sets, facilitating the data-to-discovery process. It supports all applications of data-driven computing in various scientific domains, such as biology, physics, astronomy, geophysics, etc.  It also functions as a catalyst for new collaborations and projects between different scientific disciplines, and between the campus and JPL, with especial interest in the sharing and transfer of methodologies, where the solutions from one field can be reapplied in another one.

The Center for Data-Driven Discovery is a part of a joint initiative with the Center for Data Science and Technology at [[JPL]].&lt;ref&gt;[http://datascience.jpl.nasa.gov Center for Data Science and Technology]&lt;/ref&gt; It became operational Fall 2014.&lt;ref&gt;[https://www.caltech.edu/news/new-center-supports-data-driven-research-44589 Caltech Announces New Center Supports Data-Driven Research]&lt;/ref&gt; Also known as ''CD(cube)''.

==Directors of the Center for Data-Driven Discovery==
* [[Stanislav George Djorgovski]] (2014–Present)

==Notes==
{{reflist}}

[[Category:Computational science]]
[[Category:Jet Propulsion Laboratory]]
[[Category:California Institute of Technology]]
[[Category:2014 establishments in California]]


{{US-edu-stub}}</text>
      <sha1>5tgmgzg0jaho9on8m1r1lnqpzik827o</sha1>
    </revision>
  </page>
  <page>
    <title>Clock Constraints Specification Language</title>
    <ns>0</ns>
    <id>41766625</id>
    <revision>
      <id>791493184</id>
      <parentid>596460963</parentid>
      <timestamp>2017-07-20T16:50:41Z</timestamp>
      <contributor>
        <username>Fmallet</username>
        <id>31553509</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="747">The '''Clock Constraint Specification Language''' or '''CCSL''', is a software language for modeling relations among so-called clocks. It is part of the time model defined in the UML Profile for [[Modeling and Analysis of Real Time and Embedded systems|MARTE]].&lt;ref&gt;http://www.omgmarte.org/&lt;/ref&gt;

CCSL provides a concrete syntax to handle [[logical clock]]s. The term '''logical clock''' refers to [[Leslie Lamport]]'s logical clocks and its usage in CCSL is directly inspired from [[Synchronous programming language]]s (like [[Esterel]] or Signal).

A [[solver]] of CCSL constraints is implemented in the TimeSquare tool.&lt;ref&gt;http://timesquare.inria.fr/&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Time]]
[[Category:Unified Modeling Language]]</text>
      <sha1>8vxfv11ufbxmsj599wjx0p52swhc5ib</sha1>
    </revision>
  </page>
  <page>
    <title>Codomain</title>
    <ns>0</ns>
    <id>50264</id>
    <revision>
      <id>847147713</id>
      <parentid>847147430</parentid>
      <timestamp>2018-06-23T07:32:25Z</timestamp>
      <contributor>
        <ip>202.142.80.62</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8884">[[File:Codomain2.SVG|right|thumb|250px|A function {{math|'''f'''}} from {{math|'''X'''}} to {{math|'''Y'''}}. The large blue oval is {{math|'''Y'''}} which is the codomain of {{math|'''f'''}}{{nbsp}}. The smaller (yellow) oval inside {{math|'''Y'''}} is the [[image (mathematics)|image]] of {{math|'''f'''}}{{nbsp}}.]]

In [[mathematics]], the '''codomain''' or '''target set''' of a [[Function (mathematics)|function]] is the [[Set (mathematics)|set]] {{mvar|Y}} into which all of the [[output (mathematics)|output]] of the function is constrained to fall. It is the set {{mvar|Y}} in the notation {{math|''f'': ''X'' → ''Y''}}. The codomain is also sometimes referred to as the [[range (mathematics)|range]] but that term is ambiguous as it may also refer to the [[image (mathematics)|image]].

The codomain is part of a function {{mvar|f}} if it is defined as described in 1954 by [[Nicolas Bourbaki]],&lt;ref&gt;{{cite book |title=Elements de Mathematique,Theorie des Ensembles |author=N.Bourbaki |authorlink=Nicolas Bourbaki |publisher=Hermann &amp; cie |page=76 |year=1954}}&lt;/ref&gt; namely a triple {{math|(''X'', ''Y'', ''F'')}}, with {{mvar|F}} a functional subset&lt;ref&gt;A set of pairs is ''functional'' iff no two distinct pairs have the same first component [Bourbaki, ''op. cit.'', p. 76]&lt;/ref&gt; of the [[Cartesian product]] {{math|''X'' × ''Y''}} and {{math|''X''}} is the set of first components of the pairs in {{mvar|F}} (the ''domain''). The set {{mvar|F}} is called the ''graph'' of the function. The set of all elements of the form {{math|''f''(''x'')}}, where {{mvar|x}} ranges over the elements of the [[domain of a function|domain]] {{mvar|X}}, is called the [[image (mathematics)|image]] of {{mvar|f}}. In general, the image of a function is a subset of its codomain. Thus, it may not coincide with its codomain. Namely, a function that is not [[Surjective function|surjective]] has elements {{mvar|y}} in its codomain for which the equation {{math|1=''f''(''x'') = ''y''}} does not have a solution.

An alternative definition of ''function'' by Bourbaki [Bourbaki, ''op. cit.'', p.&amp;nbsp;77], namely as just a functional graph, does not include a codomain and is also widely used.&lt;ref&gt;{{Harvnb|Forster|2003}}, [{{Google books|plainurl=y|id=mVeTuaRwWssC|page=10|text=Some mathematical cultures make this explicit, saying that a function}} pp. 10&amp;ndash;11]&lt;/ref&gt; For example in [[set theory]] it is desirable to permit the domain of a function to be a [[Class (set theory)|proper class]] {{mvar|X}}, in which case there is formally no such thing as a triple {{math|(''X'', ''Y'', ''F'')}}. With such a definition functions do not have a codomain, although some authors still use it informally after introducing a function in the form {{math|''f'': ''X'' → ''Y''}}.&lt;ref&gt;{{Harvnb|Eccles|1997}}, p. 91 ([{{Google books|plainurl=y|id=ImCSX_gm40oC|page=91|text=The reader may wonder at this variety of ways of thinking about a function}} quote 1], [{{Google books|plainurl=y|id=ImCSX_gm40oC|page=91|text=When defining a function using a formula it is important to be clear about which sets are the domain and the codomain of the function}} quote 2]); {{Harvnb|Mac Lane|1998}}, [{{Google books|plainurl=y|id=MXboNPdTv7QC|page=8|text=Here "function" means a function with specified domain and specified codomain}} p. 8]; Mac Lane, in {{Harvnb|Scott|Jech|1967}}, [{{Google books|plainurl=y|id=5mf4Vckj0gEC|page=232|text=Note explicitly that the notion of function is not that customary in axiomatic set theory}} p. 232]; {{Harvnb|Sharma|2004}}, [{{Google books|plainurl=y|id=IGvDpe6hYiQC|page=91|text=Functions as sets of ordered pairs}} p. 91]; {{Harvnb|Stewart|Tall|1977}}, [{{Google books|plainurl=y|id=TLelvnIU2sEC|page=89|text=Strictly speaking we cannot talk of 'the' codomain of a function}} p. 89]&lt;/ref&gt;

==Examples==
For a function

:&lt;math&gt;f\colon \mathbb{R}\rightarrow\mathbb{R}&lt;/math&gt;

defined by

:&lt;math&gt;f\colon\,x\mapsto x^2, \text{ or equivalently }f(x)\ =\ x^2,&lt;/math&gt;

the codomain of {{mvar|f}} is &lt;math&gt;\textstyle \mathbb R&lt;/math&gt;, but {{mvar|f}} does not map to any negative number. 
Thus the image of {{mvar|f}} is the set &lt;math&gt;\textstyle \mathbb{R}^+_0&lt;/math&gt;; i.e., the [[interval (mathematics)|interval]] {{closed-open|0, ∞}}.

An alternative function {{mvar|g}} is defined thus: 

: &lt;math&gt;g\colon\mathbb{R}\rightarrow\mathbb{R}^+_0&lt;/math&gt;
: &lt;math&gt;g\colon\,x\mapsto x^2.&lt;/math&gt;

While {{mvar|f}} and {{mvar|g}} map a given {{mvar|x}} to the same number, they are not, in this view, the same function because they have different codomains. A third function {{mvar|h}} can be defined to demonstrate why:

: &lt;math&gt;h\colon\,x\mapsto \sqrt x.&lt;/math&gt;

The domain of {{mvar|h}} must be defined to be &lt;math&gt;\textstyle \mathbb{R}^+_0&lt;/math&gt;:

: &lt;math&gt;h\colon\mathbb{R}^+_0\rightarrow\mathbb{R}.&lt;/math&gt;

The [[function composition|compositions]] are denoted

:&lt;math&gt;h \circ f,&lt;/math&gt;
:&lt;math&gt;h \circ g.&lt;/math&gt;

On inspection, {{math|''h'' ∘ ''f''}} is not useful. It is true, unless defined otherwise, that the image of {{mvar|f}} is not known; it is only known that it is a subset of &lt;math&gt;\textstyle \mathbb R&lt;/math&gt;. For this reason, it is possible that {{mvar|h}}, when composed with {{mvar|f}}, might receive an argument for which no output is defined – negative numbers are not elements of the domain of {{mvar|h}}, which is the [[square root function]].

Function composition therefore is a useful notion only when the ''codomain''  of the function on the right side of a composition (not its ''image'', which is a consequence of the function and could be unknown at the level of the composition) is the same as the domain of the function on the left side.

The codomain affects whether a function is a [[surjection]], in that the function is surjective if and only if its codomain equals its image.  In the example, {{mvar|g}} is a surjection while {{mvar|f}} is not.  The codomain does not affect whether a function is an [[injective function|injection]].

A second example of the difference between codomain and image is demonstrated by the [[linear transformation]]s between two [[vector space]]s – in particular, all the linear transformations from &lt;math&gt;\textstyle \mathbb{R}^2&lt;/math&gt; to itself, which can be represented by the {{math|2×2}} [[Matrix (mathematics)|matrices]] with real coefficients.  Each matrix represents a map with the domain &lt;math&gt;\textstyle \mathbb{R}^2&lt;/math&gt; and codomain &lt;math&gt;\textstyle \mathbb{R}^2&lt;/math&gt;.  However, the image is uncertain.  Some transformations may have image equal to the whole codomain (in this case the matrices with [[Rank (linear algebra)|rank]] {{math|2}}) but many do not, instead mapping into some smaller [[Linear subspace|subspace]] (the matrices with rank {{math|1}} or {{math|0}}).  Take for example the matrix {{mvar|T}} given by
:&lt;math&gt;T = \begin{pmatrix}
1 &amp; 0 \\
1 &amp; 0 \end{pmatrix}&lt;/math&gt;
which represents a linear transformation that maps the point {{math|(''x'', ''y'')}} to {{math|(''x'', ''x'')}}.  The point {{math|(2, 3)}} is not in the image of {{mvar|T}}, but is still in the codomain since linear transformations from &lt;math&gt;\textstyle \mathbb{R}^2&lt;/math&gt; to &lt;math&gt;\textstyle \mathbb{R}^2&lt;/math&gt; are of explicit relevance.  Just like all {{math|2×2}} matrices, {{mvar|T}} represents a member of that set.  Examining the differences between the image and codomain can often be useful for discovering properties of the function in question.  For example, it can be concluded that {{mvar|T}} does not have full rank since its image is smaller than the whole codomain.

==See also==
* [[Range (mathematics)]]
* [[Domain of a function]]
* [[Surjective function]]
* [[Injective function]]
* [[Bijection]]

==Notes==
{{reflist}}

==References==
* {{citation|authorlink1=Peter Eccles (mathematician)|title=An Introduction to Mathematical Reasoning: Numbers, Sets, and Functions|first=Peter J.|last= Eccles|publisher=Cambridge University Press|year= 1997|isbn=978-0-521-59718-0}}
*{{citation
|title=Logic, Induction and Sets
|author=Forster, Thomas
|publisher=Cambridge University Press
|year=2003
|isbn=978-0-521-53361-4}}
* {{citation|title=Categories for the working mathematician|first=Saunders|last=Mac Lane|edition=2nd|publisher= Springer|year= 1998|isbn=978-0-387-98403-2}}
* {{citation|title=Axiomatic set theory|series=Symposium in Pure Mathematics|first1= Dana S.|last1=Scott|first2= Thomas J.|last2=Jech|publisher=American Mathematical Society|year=1967|isbn=978-0-8218-0245-8}}
* {{citation|title=Introduction To Set Theory|first=A.K.|last= Sharma|publisher=Discovery Publishing House|year= 2004|isbn=978-81-7141-877-0}}
* {{citation|title=The foundations of mathematics|first1=Ian|last1=Stewart|first2=David Orme|last2= Tall|publisher=Oxford University Press|year= 1977|isbn=978-0-19-853165-4}}

[[Category:Functions and mappings]]
[[Category:Basic concepts in set theory]]</text>
      <sha1>0kcquqk6b0bb4to9yj53h17g1926ay8</sha1>
    </revision>
  </page>
  <page>
    <title>Complex line</title>
    <ns>0</ns>
    <id>7975294</id>
    <revision>
      <id>808566005</id>
      <parentid>757469729</parentid>
      <timestamp>2017-11-03T17:14:23Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>/* top */Follow-up, WL 1 first-publisher; [[WP:GenFixes]] on; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1722">In [[mathematics]], a '''complex line''' is a one-[[dimension]]al [[affine space|affine subspace]] of a [[vector space]] over the [[complex numbers]].&lt;ref&gt;{{citation
 | last1 = Brass | first1 = Peter
 | last2 = Moser | first2 = William
 | last3 = Pach | first3 = János
 | isbn = 9780387299297
 | mr = 2163782
 | page = 305
 | publisher = Springer, New York
 | title = Research Problems in Discrete Geometry
 | url = https://books.google.com/books?id=cT7TB20y3A8C&amp;pg=PA305
 | year = 2005}}.&lt;/ref&gt;&lt;ref&gt;{{citation|title=Introduction to Complex Analysis: Functions of Several Variables|volume=110|series=Translations of mathematical monographs|first=Boris Vladimirovich|last=Shabat|publisher=[[American Mathematical Society]]|year=1992|isbn=9780821819753|page=3|url=https://books.google.com/books?id=h5H4AwAAQBAJ&amp;pg=PA3}}&lt;/ref&gt; A common point of confusion is that while a complex line has [[complex dimension|dimension]] one over '''C''' (hence the term "line"), it has dimension two over the [[real numbers]] '''R''', and is topologically equivalent to a real plane, not a real line.&lt;ref&gt;{{citation
 | last1 = Miller | first1 = Ezra
 | last2 = Reiner | first2 = Victor
 | last3 = Sturmfels | first3 = Bernd
 | isbn = 978-0-8218-3736-8
 | location = Providence, RI
 | mr = 2383123
 | page = 9
 | publisher = American Mathematical Society
 | series = IAS/Park City Mathematics Series
 | title = Geometric Combinatorics: Lectures from the Graduate Summer School held in Park City, UT, 2004
 | url = https://books.google.com/books?id=W_SPdwfPTw8C&amp;pg=PA9
 | volume = 13
 | year = 2007}}.&lt;/ref&gt;

==See also==
* [[Riemann sphere]]

==References==
{{reflist}}

[[Category:Geometry]]
[[Category:Complex analysis]]


{{geometry-stub}}</text>
      <sha1>1ty08psa4z5jnouhwaqcbo8xy9hdapb</sha1>
    </revision>
  </page>
  <page>
    <title>Dadda multiplier</title>
    <ns>0</ns>
    <id>4181062</id>
    <revision>
      <id>864358313</id>
      <parentid>861670743</parentid>
      <timestamp>2018-10-16T17:56:28Z</timestamp>
      <contributor>
        <username>Swpb</username>
        <id>1921264</id>
      </contributor>
      <comment>/* Algorithm example */clean up - [[WP:ACCIM]] rule #6</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8843">[[File:Hindu lattice 2.svg|thumb |
[[Lattice multiplication]], a similar concept from decimal math.
]]The '''Dadda multiplier''' is a hardware multiplier design invented by computer scientist [[Luigi Dadda]] in 1965.&lt;ref name="Dadda_1965"/&gt; It is similar to the [[Wallace multiplier]], but it is slightly faster (for all operand sizes) and requires fewer gates (for all but the smallest operand sizes).&lt;ref name="Townsend_2003"/&gt;

In fact, Dadda and Wallace multipliers have the same three steps for two bit strings &lt;math&gt;w_1&lt;/math&gt; and &lt;math&gt;w_2&lt;/math&gt; of lengths &lt;math&gt;\ell_1&lt;/math&gt; and &lt;math&gt;\ell_2&lt;/math&gt; respectively:

# Multiply ([[Logical conjunction|logical AND]]) each bit of &lt;math&gt;w_1&lt;/math&gt;, by each bit of &lt;math&gt;w_2&lt;/math&gt;, yielding &lt;math&gt;\ell_1\cdot\ell_2&lt;/math&gt; results, grouped by weight in columns 
# Reduce the number of partial products by stages of [[Adder (electronics)|full and half adders]] until we are left with at most two bits of each weight.
# Add the final result with a conventional adder.

As with the Wallace multiplier, the multiplication products of the first step carry different weights reflecting the magnitude of the original bit values in the multiplication. For example, the product of bits &lt;math&gt;a_n b_m&lt;/math&gt; has weight &lt;math&gt;n+m&lt;/math&gt;.

Unlike Wallace multipliers that reduce as much as possible on each layer, Dadda multipliers attempt to minimize the number of gates used, as well as input/output delay. Because of this, Dadda multipliers have a less expensive reduction phase, but the final numbers may be a few bits longer, thus requiring slightly bigger adders.

== Description ==
[[File:Full-adder.svg|thumb | An example of a full-adder circuit.]]To achieve a more optimal final product, the structure of the reduction process is governed by slightly more complex rules than in Wallace multipliers. 

The progression of the reduction is controlled by a maximum-height sequence &lt;math&gt;d_j&lt;/math&gt;, defined by:

: &lt;math&gt;d_1 = 2 \text{ and } d_{j+1} = \operatorname{floor}(1.5 d_j).&lt;/math&gt;

This yields a sequence like so:

: &lt;math&gt;d_1=2, d_2=3, d_3=4, d_4=6, d_5=9, d_6=13, \ldots &lt;/math&gt;

The initial value of &lt;math&gt;j&lt;/math&gt; is chosen as the largest value such that &lt;math&gt;d_j &lt; min(n_1, n_2)&lt;/math&gt;, where &lt;math&gt;n_1&lt;/math&gt; and &lt;math&gt;n_2&lt;/math&gt; are the number of bits in the input multiplicand and multiplier. The lesser of the two bit lengths will be the maximum height of each column of weights after the first stage of multiplication. For each stage &lt;math&gt;j&lt;/math&gt; of the reduction, the goal of the algorithm is the reduce the height of each column so that it is less than or equal to the value of &lt;math&gt;d_j&lt;/math&gt;. 

For each stage from &lt;math&gt;,\ldots,1&lt;/math&gt;, reduce each column starting at the lowest-weight column, &lt;math&gt;c_0&lt;/math&gt; according to these rules:
# If &lt;math&gt;\operatorname{height}(c_i) \leqslant d_j&lt;/math&gt; the column does not require reduction, move to column &lt;math&gt;c_{i+1}&lt;/math&gt;
# If &lt;math&gt;\operatorname{height}(c_i) = d_j + 1&lt;/math&gt; add the top two elements in a half-adder, placing the result at the bottom of the column and the carry at the top of column &lt;math&gt;c_{i+1}&lt;/math&gt;, then move to column &lt;math&gt;c_{i+1}&lt;/math&gt;
# Else, add the top three elements in a full-adder, placing the result at the bottom of the column and the carry at the top of column &lt;math&gt;c_{i+1}&lt;/math&gt;, restart &lt;math&gt;c_i&lt;/math&gt;at step 1

== Algorithm example ==
[[File:dadda tree 8x8.svg|thumb | Example of Dadda reduction on 8&amp;nbsp;×&amp;nbsp;8 multiplier. Bits with lower weight are rightmost.]]
The example in the adjacent image illustrates the reduction of an 8&amp;nbsp;×&amp;nbsp;8 multiplier, explained here.

The initial state &lt;math&gt;j = 4&lt;/math&gt; is chosen as &lt;math&gt;d_4 = 6&lt;/math&gt;, the largest value less than 8.

'''Stage &lt;math&gt;j=4&lt;/math&gt;, &lt;math&gt;d_4 = 6&lt;/math&gt;'''
* &lt;math&gt;\operatorname{height}(c_0\cdots c_5)&lt;/math&gt; are all less than or equal to six bits in height, so no changes are made
* &lt;math&gt;\operatorname{height}(c_6) = d_4 + 1 = 7&lt;/math&gt;, so a half-adder is applied, reducing it to six bits and adding its carry bit to &lt;math&gt;c_7&lt;/math&gt;
* &lt;math&gt;\operatorname{height}(c_7) = 9&lt;/math&gt; including the carry bit from &lt;math&gt;c_6&lt;/math&gt;, so we apply a full-adder and a half-adder to reduce it to six bits
* &lt;math&gt;\operatorname{height}(c_8) = 9&lt;/math&gt; including two carry bits from &lt;math&gt;c_7&lt;/math&gt;, so we again apply a full-adder and a half-adder to reduce it to six bits
* &lt;math&gt;\operatorname{height}(c_9) = 8&lt;/math&gt; including two carry bits from &lt;math&gt;c_8&lt;/math&gt;, so we apply a single full-adder and reduce it to six bits
* &lt;math&gt;\operatorname{height}(c_{10}\cdots c_{14})&lt;/math&gt; are all less than or equal to six bits in height including carry bits, so no changes are made
'''Stage &lt;math&gt;j=3&lt;/math&gt;, &lt;math&gt;d_3 = 4&lt;/math&gt;'''
* &lt;math&gt;\operatorname{height}(c_0\cdots c_3)&lt;/math&gt; are all less than or equal to four bits in height, so no changes are made
* &lt;math&gt;\operatorname{height}(c_4) = d_3 + 1 = 5&lt;/math&gt;, so a half-adder is applied, reducing it to four bits and adding its carry bit to &lt;math&gt;c_5&lt;/math&gt;
* &lt;math&gt;\operatorname{height}(c_5) = 7&lt;/math&gt; including the carry bit from &lt;math&gt;c_4&lt;/math&gt;, so we apply a full-adder and a half-adder to reduce it to four bits
* &lt;math&gt;\operatorname{height}(c_6\cdots c_{10}) = 8&lt;/math&gt; including previous carry bits, so we apply two full-adders to reduce them to four bits
* &lt;math&gt;\operatorname{height}(c_{11}) = 6&lt;/math&gt; including previous carry bits, so we apply a full-adder to reduce it to four bits
* &lt;math&gt;\operatorname{height}(c_{12}\cdots c_{14})&lt;/math&gt; are all less than or equal to four bits in height including carry bits, so no changes are made
'''Stage &lt;math&gt;j=2&lt;/math&gt;, &lt;math&gt;d_2 = 3&lt;/math&gt;'''
* &lt;math&gt;\operatorname{height}(c_0\cdots c_2)&lt;/math&gt; are all less than or equal to three bits in height, so no changes are made
* &lt;math&gt;\operatorname{height}(c_3) = d_2 + 1 = 4&lt;/math&gt;, so a half-adder is applied, reducing it to three bits and adding its carry bit to &lt;math&gt;c_4&lt;/math&gt;
* &lt;math&gt;\operatorname{height}(c_4\cdots c_{12}) = 5&lt;/math&gt; including previous carry bits, so we apply one full-adder to reduce them to three bits
* &lt;math&gt;\operatorname{height}(c_{13}\cdots c_{14})&lt;/math&gt; are all less than or equal to three bits in height including carry bits, so no changes are made
'''Stage &lt;math&gt;j=1&lt;/math&gt;, &lt;math&gt;d_1 = 2&lt;/math&gt;'''
* &lt;math&gt;\operatorname{height}(c_0\cdots c_1)&lt;/math&gt; are all less than or equal to two bits in height, so no changes are made
* &lt;math&gt;\operatorname{height}(c_2) = d_1 + 1 = 3&lt;/math&gt;, so a half-adder is applied, reducing it to two bits and adding its carry bit to &lt;math&gt;c_3&lt;/math&gt;
* &lt;math&gt;\operatorname{height}(c_3\cdots c_{13}) = 4&lt;/math&gt; including previous carry bits, so we apply one full-adder to reduce them to two bits
* &lt;math&gt;\operatorname{height}(c_{14}) = 2&lt;/math&gt; including the carry bit from &lt;math&gt;c_{13}&lt;/math&gt;, so no changes are made
'''Addition'''

The output of the last stage leaves 14 columns of height two or less which can be passed into a standard adder.

==See also==
* [[Booth's multiplication algorithm]]
* [[Fused multiply–add]]
* [[Wallace tree]]
* [[BKM algorithm]] for complex logarithms and exponentials
* [[Kochanski multiplication]] for [[modular arithmetic|modular]] multiplication

==References==
{{Reflist|refs=
&lt;ref name="Dadda_1965"&gt;{{cite journal |author-last=Dadda |author-first=Luigi |author-link=Luigi Dadda |title=Some schemes for parallel multipliers |journal=Alta Frequenza |volume=34 |number=5 |pages=349–356 |date=May 1965}}&lt;/ref&gt;
&lt;ref name="Townsend_2003"&gt;{{cite conference |author-last1=Townsend |author-first1=Whitney J. |author-last2=Swartzlander, Jr. |author-first2=Earl E. |author-last3=Abraham |author-first3=Jacob A. |author-link3=Jacob A. Abraham |title=A Comparison of Dadda and Wallace Multiplier Delays |booktitle=SPIE Advanced Signal Processing Algorithms, Architectures, and Implementations XIII |orig-year=2003-08-06 |date=December 2003 |doi=10.1117/12.507012 |publisher=[[The International Society]] |url=http://ieeemilestones.ethw.org/images/d/db/A_comparison_of_Dadda_and_Wallace_multiplier_delays.pdf |access-date=2018-07-16 |dead-url=no |archive-url=https://web.archive.org/web/20180716212641/http://ieeemilestones.ethw.org/images/d/db/A_comparison_of_Dadda_and_Wallace_multiplier_delays.pdf |archive-date=2018-07-16}}&lt;/ref&gt;
}}

==Further reading==
* {{cite web |title=Advanced Arithmetic Techniques |author-first=John J. G. |author-last=Savard |date=2018 |orig-year=2006 |work=quadibloc |url=http://www.quadibloc.com/comp/cp0202.htm |access-date=2018-07-16 |dead-url=no |archive-url=https://web.archive.org/web/20180703001722/http://www.quadibloc.com/comp/cp0202.htm |archive-date=2018-07-03}}

[[Category:Digital circuits]]

[[Category:Computer arithmetic]]
[[Category:Multiplication]]
[[Category:1965 introductions]]
[[Category:1965 in computer science]]</text>
      <sha1>o6hj9qcdoxds72hxeftvuz7dusxxjoa</sha1>
    </revision>
  </page>
  <page>
    <title>Dan Archdeacon</title>
    <ns>0</ns>
    <id>54748286</id>
    <revision>
      <id>857348846</id>
      <parentid>833171716</parentid>
      <timestamp>2018-08-31T04:03:27Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2946">'''Dan Steven Archdeacon''' (1954–2015) was an American [[graph theory|graph theorist]] specializing in [[topological graph theory]],{{r|ajc|amc}} who served for many years as a professor of mathematics and statistics at the [[University of Vermont]].{{r|uvm}}

Archdeacon was born on May 11, 1954 in [[Dayton, Ohio]], and grew up in [[Centerville, Ohio]].
He did his undergraduate studies at [[Earlham College]], graduating in 1975.{{r|ajc}}
He completed his Ph.D. in 1980 from [[Ohio State University]], under the supervision of Henry Hatfield Glover, with a dissertation proving an analogue of [[Kuratowski's theorem]] for the [[projective plane]].{{r|mgp}} He took a position at the University of Vermont in 1982, joining fellow graph theorist and Ohio State graduate [[Jeff Dinitz]], after previously working as an instructor at the [[University of Kansas]].{{r|ajc|uvm}}
He died of cancer on February 18, 2015, in [[Burlington, Vermont]].{{r|ajc}}

In 2003–2004, the University of Vermont named him as University Scholar.{{r|amc|uvm}}
A special issue of the ''[[Australasian Journal of Combinatorics]]'' was published in his honor in 2017.{{r|ajc}}

==References==
{{reflist|refs=

&lt;ref name=ajc&gt;{{citation
 | last1 = Bonnington | first1 = C. Paul
 | last2 = Dinitz | first2 = Jeff | author2-link = Jeff Dinitz
 | last3 = Širáň | first3 = Jozef
 | journal = [[Australasian Journal of Combinatorics]]
 | mr = 3607813
 | pages = 65–76
 | title = Special issue in honour of Dan S. Archdeacon: guest editorial
 | url = https://ajc.maths.uq.edu.au/pdf/67/ajc_v67_p065.pdf
 | volume = 67
 | year = 2017}}&lt;/ref&gt;

&lt;ref name=amc&gt;{{citation
 | last1 = Bokal | first1 = Drago
 | last2 = Mohar | first2 = Bojan | author2-link = Bojan Mohar
 | last3 = Širáň | first3 = Jozef
 | issue = 1
 | department = News and Photos
 | journal = Ars Mathematica Contemporanea
 | mr = 3647300
 | title = Dan Archdeacon (11 May 1954 to 18 February 2015)
 | url = http://amc-journal.eu/index.php/amc/article/view/1106/965
 | volume = 12
 | year = 2017}}&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=9972}}&lt;/ref&gt;

&lt;ref name=uvm&gt;{{citation|url=http://www.uvm.edu/~uvmpr/?Page=news&amp;&amp;storyID=20290|title=Mathematics Professor Dan Archdeacon Dies After 33-Year Career at UVM|date=February 20, 2015|work=University Communications|publisher=University of Vermont|accessdate=2017-08-03}}&lt;/ref&gt;

}}

==External links==
*{{Google Scholar id|va5zau0AAAAJ}}

{{authority control}}

{{DEFAULTSORT:Archdeacon, Dan}}
[[Category:1954 births]]
[[Category:2015 deaths]]
[[Category:People from Dayton, Ohio]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Graph theorists]]
[[Category:Earlham College alumni]]
[[Category:Ohio State University alumni]]
[[Category:University of Kansas faculty]]
[[Category:University of Vermont faculty]]
[[Category:Mathematicians from Ohio]]
[[Category:Deaths from cancer in Vermont]]</text>
      <sha1>cpdttlf3bu8s8nnfwjocvlpzht6sl4w</sha1>
    </revision>
  </page>
  <page>
    <title>Dataflow</title>
    <ns>0</ns>
    <id>864364</id>
    <revision>
      <id>862162077</id>
      <parentid>858067893</parentid>
      <timestamp>2018-10-02T15:28:54Z</timestamp>
      <contributor>
        <username>Kvng</username>
        <id>910180</id>
      </contributor>
      <comment>add to nebulous lead, more work needed before {{lead too short}} can be removed</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6278">{{about|software engineering|the flow of data within a computer network|Traffic flow (computer networking)|the graphical representation of flow of data within an information system|data flow diagram|the hardware architecture|dataflow architecture}}
{{Multiple issues|
{{lead too short|date=November 2013}}
{{More citations needed |date= September 2016 }}
}}

'''''Dataflow''''' is a term used in [[computing]] which has various meanings depending on application and the context in which the term is used. In the context of [[software architecture]], data flow relates to [[stream processing]] or [[reactive programming]].

==Software architecture==
Dataflow is a software paradigm based on the idea of disconnecting computational actors into stages (pipelines) that can execute concurrently. Dataflow can also be called [[stream processing]] or [[reactive programming]].&lt;ref&gt;[http://www.jonathanbeard.io/blog/2015/09/19/streaming-and-dataflow.html A Short Intro to Stream Processing]&lt;/ref&gt;

There have been multiple data-flow/stream processing languages of various forms (see [[Stream processing]]). Data-flow hardware (see [[Dataflow architecture]]) is an alternative to the classic [[Von Neumann architecture]]. The most obvious example of data-flow programming is the subset known as [[reactive programming]] with spreadsheets. As a user enters new values, they are instantly transmitted to the next logical "actor" or formula for calculation.

[[Distributed data flow]]s have also been proposed as a programming abstraction that captures the dynamics of distributed multi-protocols. The data-centric perspective characteristic of data flow programming promotes high-level functional specifications and simplifies formal reasoning about system components.

==Hardware architecture==
{{main|Dataflow architecture}}
Hardware architectures for dataflow was a major topic in [[Computer architecture]] research in the 1970s and early 1980s. [[Jack Dennis]] of [[MIT]] pioneered the field of static dataflow architectures. Designs that use conventional memory addresses as data dependency tags are called static dataflow machines. These machines did not allow multiple instances of the same routines to be executed simultaneously because the simple tags could not differentiate between them. Designs that use [[Content-addressable memory]] are called dynamic dataflow machines by [[Arvind (computer scientist)|Arvind]]. They use tags in memory to facilitate parallelism.
Data flows around the computer through the components of the computer. It gets entered from the input devices and can leave through output devices (printer etc.).

==Concurrency==
A dataflow network is a network of concurrently executing processes or automata that can communicate by sending data over ''channels'' (see [[message passing]].)

In [[Kahn process networks]], named after [[Gilles Kahn]], the processes are ''determinate''. This implies that each determinate process computes a [[continuous function]] from input streams to output streams, and that a network of determinate processes is itself determinate, thus computing a continuous function. This implies that the behavior of such networks can be described by a set of recursive equations, which can be solved using [[fixed point theory]]. The movement and transformation of the data is represented by a series of shapes and lines.

==See also==
* [[BMDFM]]
* [[Communicating Sequential Processes]]
* [[Complex event processing]]
* [[Data flow diagram]]
* [[Data-flow analysis]], a type of program analysis
* [[Data stream]]
* [[Dataflow programming]] (a programming language paradigm)
* [[Flow-based programming]] (FBP)
* [[Functional reactive programming]]
* [[Lazy evaluation]]
* [[Lucid (programming language)]]
* [[Oz (programming language)]]
* [[Packet flow]]
* [[Pipeline (computing)]]
* [[Pure Data]]
* [[TensorFlow]]
* [[Theano]]

== References ==
{{Reflist}}

== External links ==
{{Wiktionary|dataflow}}
{{External links|date=May 2017}}
* [http://dataflowanalytics.com DataFlow Analytics]: Composable Analytics - Flexible Business Intelligence.
* [http://bmdfm.com BMDFM]: Binary Modular Dataflow Machine, [[BMDFM]].
* [http://greta.cs.ioc.ee/~khoros2/k2tools/cantata/cantata.html Cantata]: Dataflow Visual Language for [[image processing]].
* [http://common-lisp.net/project/cells/ Cells]: Dataflow extension to [[Common Lisp]] [[Common Lisp Object System|Object System]], CLOS.
* [http://code.google.com/p/dc-lib/ DC]: Library that allows the embedding of one-way dataflow constraints in a C/C++ program.
* [http://www.iseesystems.com/softwares/Education/StellaSoftware.aspx Stella]: Dataflow Visual Language for dynamic dataflow [[Mathematical model|modeling]] and [[Computer simulation|simulation]].
* [http://www-sop.inria.fr/members/Jean-Vivien.Millo/kpassa/index.php KPASSA] : a tool for static-scheduling, performance analysis and optimizations for DataFlow models.
* [http://www.pointillistic.com/open-REBOL/moa/steel/liquid/index.html Liquid Rebol]
* [http://www.es.ele.tue.nl/sdf3 SDF3] : Performance analysis tool for DataFlow Model
* [https://github.com/larrytheliquid/dataflow/tree/master Ruby Dataflow] : Ruby gem adding Dataflow variable support
* Acar ''et al.'', [http://citeseer.ist.psu.edu/old/752721.html Adaptive Functional Programming], POPL 2002
* [https://web.archive.org/web/20130119045517/http://doc.akka.io/docs/akka/snapshot/scala/dataflow.html Scala Dataflow] : The Akka toolkit provides (among other things) dataflow concurrency in Scala
* [http://www.tensorflow.org/ TensorFlow] : Google's open source ([[Apache License|Apache 2.0]]) second-generation [[Python (programming language)|Python]] and [[C++]] machine learning library using dataflow graphs
* [http://flink.apache.org/ Apache Flink] : An open-source stream processing framework based on the dataflow programming model&lt;ref&gt;Carbone, P., Katsifodimos, A., Ewen, S., Markl, V., Haridi, S. et al. (2015) Apache flink: Stream and batch processing in a single engine. Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 36(4)&lt;/ref&gt;

&lt;!-- [[Category:Computer data]] Dataflow has nothing to do with this category! --&gt;
[[Category:Computer architecture]]
[[Category:Models of computation]]

[[it:Dataflow (microprocessori)]]</text>
      <sha1>804kwz5talew1kqg5pgb0oqwk8s20st</sha1>
    </revision>
  </page>
  <page>
    <title>Differential CORDIC</title>
    <ns>0</ns>
    <id>48708868</id>
    <redirect title="CORDIC" />
    <revision>
      <id>699006190</id>
      <parentid>693420553</parentid>
      <timestamp>2016-01-09T17:30:38Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+cat</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="199">#redirect [[CORDIC#Differential CORDIC]] {{R to related topic}}

[[Category:Numerical analysis]]
[[Category:Trigonometry]]
[[Category:Digit-by-digit algorithms]]
[[Category:Shift-and-add algorithms]]</text>
      <sha1>dzwws57o3w8kegn3fuy2fsoh184utb1</sha1>
    </revision>
  </page>
  <page>
    <title>Disintegration theorem</title>
    <ns>0</ns>
    <id>6845737</id>
    <revision>
      <id>752890474</id>
      <parentid>752890389</parentid>
      <timestamp>2016-12-04T00:17:52Z</timestamp>
      <contributor>
        <ip>77.126.98.68</ip>
      </contributor>
      <comment>Undid revision 752873980 by [[Special:Contributions/77.126.98.68|77.126.98.68]] ([[User talk:77.126.98.68|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6964">
In [[mathematics]], the '''disintegration theorem''' is a result in [[measure theory]] and [[probability theory]]. It rigorously defines the idea of a non-trivial "restriction" of a [[measure (mathematics)|measure]] to a [[measure zero]] subset of the [[measure space]] in question. It is related to the existence of [[conditioning (probability)|conditional probability measures]]. In a sense, "disintegration" is the opposite process to the construction of a [[product measure]].

==Motivation==
Consider the unit square in the [[Euclidean plane]] '''R'''&lt;sup&gt;2&lt;/sup&gt;, ''S'' = [0, 1] × [0, 1]. Consider the [[probability measure]] μ defined on ''S'' by the restriction of two-dimensional [[Lebesgue measure]] λ&lt;sup&gt;2&lt;/sup&gt; to ''S''. That is, the probability of an event ''E'' ⊆ ''S'' is simply the area of ''E''. We assume ''E'' is a measurable subset of ''S''.

Consider a one-dimensional subset of ''S'' such as the line segment ''L''&lt;sub&gt;''x''&lt;/sub&gt; = {''x''} × [0, 1]. ''L''&lt;sub&gt;''x''&lt;/sub&gt; has μ-measure zero; every subset of ''L''&lt;sub&gt;''x''&lt;/sub&gt; is a μ-[[null set]]; since the Lebesgue measure space is a [[complete measure|complete measure space]],

:&lt;math&gt;E \subseteq L_{x} \implies \mu (E) = 0.&lt;/math&gt;

While true, this is somewhat unsatisfying. It would be nice to say that μ "restricted to" ''L''&lt;sub&gt;''x''&lt;/sub&gt; is the one-dimensional Lebesgue measure λ&lt;sup&gt;1&lt;/sup&gt;, rather than the [[trivial measure|zero measure]]. The probability of a "two-dimensional" event ''E'' could then be obtained as an [[Lebesgue integration|integral]] of the one-dimensional probabilities of the vertical "slices" ''E'' ∩ ''L''&lt;sub&gt;''x''&lt;/sub&gt;: more formally, if μ&lt;sub&gt;''x''&lt;/sub&gt; denotes one-dimensional Lebesgue measure on ''L''&lt;sub&gt;''x''&lt;/sub&gt;, then

:&lt;math&gt;\mu (E) = \int_{[0, 1]} \mu_{x} (E \cap L_{x}) \, \mathrm{d} x&lt;/math&gt;

for any "nice" ''E'' ⊆ ''S''. The disintegration theorem makes this argument rigorous in the context of measures on [[metric space]]s.

==Statement of the theorem==
(Hereafter, '''''P'''''(''X'') will denote the collection of [[Borel measure|Borel]] probability measures on a [[metric space]] (''X'', ''d'').)

Let ''Y'' and ''X'' be two [[Radon space]]s (i.e. [[separable space|separable]] metric spaces on which every probability measure is a [[Radon measure]]). Let μ ∈ '''''P'''''(''Y''), let π : ''Y'' → ''X'' be a Borel-[[measurable function]], and let &lt;math&gt;\nu&lt;/math&gt; ∈ '''''P'''''(''X'') be the [[pushforward measure]] &lt;math&gt;\nu&lt;/math&gt;&amp;nbsp;=&amp;nbsp;π&lt;sub&gt;∗&lt;/sub&gt;(μ)&amp;nbsp;=&amp;nbsp;μ&amp;nbsp;∘&amp;nbsp;π&lt;sup&gt;−1&lt;/sup&gt;. Then there exists a &lt;math&gt;\nu&lt;/math&gt;-[[almost everywhere]] uniquely determined family of probability measures {μ&lt;sub&gt;''x''&lt;/sub&gt;}&lt;sub&gt;''x''∈''X''&lt;/sub&gt; ⊆ '''''P'''''(''Y'') such that
* the function &lt;math&gt;x \mapsto \mu_{x}&lt;/math&gt; is Borel measurable, in the sense that &lt;math&gt;x \mapsto \mu_{x} (B)&lt;/math&gt; is a Borel-measurable function for each Borel-measurable set ''B'' ⊆ ''Y'';
* μ&lt;sub&gt;''x''&lt;/sub&gt; "lives on" the [[fiber (mathematics)|fiber]] π&lt;sup&gt;−1&lt;/sup&gt;(''x''): for &lt;math&gt;\nu&lt;/math&gt;-[[almost all]] ''x'' ∈ ''X'',

::&lt;math&gt;\mu_{x} \left( Y \setminus \pi^{-1} (x) \right) = 0,&lt;/math&gt;

:and so μ&lt;sub&gt;''x''&lt;/sub&gt;(''E'') = μ&lt;sub&gt;''x''&lt;/sub&gt;(''E'' &amp;cap; π&lt;sup&gt;−1&lt;/sup&gt;(''x''));

* for every Borel-measurable function ''f'' : ''Y'' → [0, ∞],

::&lt;math&gt;\int_{Y} f(y) \, \mathrm{d} \mu (y) = \int_{X} \int_{\pi^{-1} (x)} f(y) \, \mathrm{d} \mu_{x} (y) \mathrm{d} \nu (x).&lt;/math&gt;

:In particular, for any event ''E'' &amp;sube; ''Y'', taking ''f'' to be the [[indicator function]] of ''E'',&lt;ref name=Dellacherie_Meyer&gt;{{cite book |author1=Dellacherie, C.  |author2=Meyer, P.-A. | title=Probabilities and potential| publisher=North-Holland Mathematics Studies, North-Holland Publishing Co., Amsterdam | year=1978}}&lt;/ref&gt;

::&lt;math&gt;\mu (E) = \int_{X} \mu_{x} \left( E \right) \, \mathrm{d} \nu (x).&lt;/math&gt;

==Applications==

===Product spaces===
The original example was a special case of the problem of product spaces, to which the disintegration theorem applies.

When ''Y'' is written as a [[Cartesian product]] ''Y'' = ''X''&lt;sub&gt;1&lt;/sub&gt; × ''X''&lt;sub&gt;2&lt;/sub&gt; and π&lt;sub&gt;''i''&lt;/sub&gt; : ''Y'' → ''X''&lt;sub&gt;''i''&lt;/sub&gt; is the natural [[projection (mathematics)|projection]], then each fibre ''π''&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;−1&lt;/sup&gt;(''x''&lt;sub&gt;1&lt;/sub&gt;) can be [[canonical form|canonically]] identified  with ''X''&lt;sub&gt;2&lt;/sub&gt; and there exists a Borel family of probability measures &lt;math&gt;\{ \mu_{x_{1}} \}_{x_{1} \in X_{1}}&lt;/math&gt; in '''''P'''''(''X''&lt;sub&gt;2&lt;/sub&gt;) (which is (π&lt;sub&gt;1&lt;/sub&gt;)&lt;sub&gt;∗&lt;/sub&gt;(μ)-almost everywhere uniquely determined) such that

:&lt;math&gt;\mu = \int_{X_{1}} \mu_{x_{1}} \, \mu \left(\pi_1^{-1}(\mathrm d x_1) \right)= \int_{X_{1}} \mu_{x_{1}} \, \mathrm{d} (\pi_{1})_{*} (\mu) (x_{1}),&lt;/math&gt;
which is in particular
:&lt;math&gt;\int_{X_1\times X_2} f(x_1,x_2)\, \mu(\mathrm d x_1,\mathrm d x_2) = \int_{X_1}\left( \int_{X_2} f(x_1,x_2) \mu(\mathrm d x_2|x_1) \right) \mu\left( \pi_1^{-1}(\mathrm{d} x_{1})\right)&lt;/math&gt;
and
:&lt;math&gt;\mu(A \times B) = \int_A \mu\left(B|x_1\right) \, \mu\left( \pi_1^{-1}(\mathrm{d} x_{1})\right).&lt;/math&gt;

The relation to [[conditional expectation]] is given by the identities
:&lt;math&gt;\operatorname E(f|\pi_1)(x_1)= \int_{X_2} f(x_1,x_2) \mu(\mathrm d x_2|x_1),&lt;/math&gt;
:&lt;math&gt;\mu(A\times B|\pi_1)(x_1)= 1_A(x_1) \cdot \mu(B| x_1).&lt;/math&gt;

===Vector calculus===
The disintegration theorem can also be seen as justifying the use of a "restricted" measure in [[vector calculus]]. For instance, in [[Stokes' theorem]] as applied to a [[vector field]] flowing through a [[compact space|compact]] [[surface (mathematics)|surface]] Σ ⊂ '''R'''&lt;sup&gt;3&lt;/sup&gt;, it is implicit that the "correct" measure on Σ is the disintegration of three-dimensional Lebesgue measure λ&lt;sup&gt;3&lt;/sup&gt; on Σ, and that the disintegration of this measure on ∂Σ is the same as the disintegration of λ&lt;sup&gt;3&lt;/sup&gt; on ∂Σ.&lt;ref name=Ambrosio_Gigli_Savare&gt;{{cite book | author=Ambrosio, L., Gigli, N. &amp; Savaré, G. | title=Gradient Flows in Metric Spaces and in the Space of Probability Measures | publisher=ETH Zürich, Birkhäuser Verlag, Basel | year=2005 | isbn=3-7643-2428-7 }}&lt;/ref&gt;

===Conditional distributions===
The disintegration theorem can be applied to give a rigorous treatment of conditional probability distributions in statistics, while avoiding purely abstract formulations of conditional probability.&lt;ref name=Chang_Pollard&gt;{{cite journal|last=Chang|first=J.T.|author2=Pollard, D.|title=Conditioning as disintegration|journal=Statistica Neerlandica| year=1997 | volume=51|issue=3|url=http://www.stat.yale.edu/~jtc5/papers/ConditioningAsDisintegration.pdf|doi=10.1111/1467-9574.00056|pages=287}}&lt;/ref&gt;

==See also==
*[[Joint probability distribution]]
*[[Copula (statistics)]]
*[[Conditional expectation]]

==References==
{{Reflist}}
{{Use dmy dates|date=December 2010}}

[[Category:Theorems in measure theory]]
[[Category:Probability theorems]]</text>
      <sha1>h6yolj468douz0rn5yvba655rk2qmit</sha1>
    </revision>
  </page>
  <page>
    <title>Fick's laws of diffusion</title>
    <ns>0</ns>
    <id>11671</id>
    <revision>
      <id>871461635</id>
      <parentid>871174012</parentid>
      <timestamp>2018-12-01T06:32:18Z</timestamp>
      <contributor>
        <ip>74.195.229.135</ip>
      </contributor>
      <comment>/* Fick's second law */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24006">{{for|the technique of measuring [[cardiac output]]|Fick principle}}
{{Use dmy dates|date=September 2011}}
[[File:DiffusionMicroMacro.gif|thumb|right|250px|[[Molecular diffusion]] from a microscopic and macroscopic point of view. Initially, there are [[Solution|solute]] molecules on the left side of a barrier (purple line) and none on the right. The barrier is removed, and the solute diffuses to fill the whole container. '''Top''': A single molecule moves around randomly. '''Middle''': With more molecules, there is a clear trend where the solute fills the container more and more uniformly. '''Bottom''': With an enormous number of solute molecules, randomness becomes undetectable: The solute appears to move smoothly and systematically from high-concentration areas to low-concentration areas. This smooth flow is described by Fick's laws.]]
'''Fick's laws of diffusion''' describe [[diffusion]] and were derived by [[Adolf Fick]] in 1855. They can be used to solve for the [[Mass diffusivity|diffusion coefficient]], {{mvar|D}}. Fick's first law can be used to derive his second law which in turn is identical to the [[diffusion equation]].

== Fick's first law ==
'''Fick's first law''' relates the diffusive [[flux]] to the concentration under the assumption of [[steady state]]. It postulates that the flux goes from regions of high concentration to regions of low concentration, with a magnitude that is proportional to the concentration gradient (spatial derivative), or in simplistic terms the concept that a solute will move from a region of high concentration to a region of low concentration across a concentration gradient. In one (spatial) dimension, the law is:

:&lt;math&gt;J = -D \frac{d \varphi}{d x} &lt;/math&gt;
where
* {{mvar|J}} is the '''diffusion flux''', of which the [[dimensional analysis|dimension]] is [[amount of substance]] per unit area per unit time, so it is expressed in such units as mol&amp;nbsp;m&lt;sup&gt;−2&lt;/sup&gt;&amp;nbsp;s&lt;sup&gt;−1&lt;/sup&gt;. {{mvar|J}} measures the amount of substance that will flow through a unit area during a unit time interval.
* {{mvar|D}} is the '''diffusion coefficient''' or '''[[mass diffusivity|diffusivity]]'''. Its dimension is area per unit time, so typical units for expressing it would be m&lt;sup&gt;2&lt;/sup&gt;/s.
* {{mvar|φ}} (for ideal mixtures) is the concentration, of which the dimension is amount of substance per unit volume. It might be expressed in units of mol/m&lt;sup&gt;3&lt;/sup&gt;.
* {{mvar|x}} is position, the dimension of which is length. It might thus be expressed in the unit m.

{{mvar|D}} is proportional to the squared velocity of the diffusing particles, which depends on the temperature, [[viscosity]] of the fluid and the size of the particles according to the [[Einstein relation (kinetic theory)#Stokes-Einstein equation|Stokes–Einstein relation]]. In dilute aqueous solutions the diffusion coefficients of most ions are similar and have values that at room temperature are in the range of {{val|0.6|-|2|e=-9|u=m&lt;sup&gt;2&lt;/sup&gt;/s}}. For biological molecules the diffusion coefficients normally range from 10&lt;sup&gt;−11&lt;/sup&gt; to 10&lt;sup&gt;−10&lt;/sup&gt;&amp;nbsp;m&lt;sup&gt;2&lt;/sup&gt;/s.

In two or more dimensions we must use {{math|∇}}, the [[del]] or [[gradient]] operator, which generalises the first derivative, obtaining

:&lt;math&gt; \mathbf{J}=- D\nabla \varphi&lt;/math&gt;

where {{math|'''J'''}} denotes the diffusion flux vector.

The driving force for the one-dimensional diffusion is the quantity {{math|−{{sfrac|∂''φ''|∂''x''}}}}, which for ideal mixtures is the concentration gradient. In chemical systems other than ideal solutions or mixtures, the driving force for diffusion of each species is the gradient of [[chemical potential]] of this species. Then Fick's first law (one-dimensional case) can be written as:

:&lt;math&gt;J_i = - \frac{D c_i}{RT} \frac{\partial \mu_i}{\partial x}&lt;/math&gt;

where the index {{mvar|i}} denotes the {{mvar|i}}th species, {{mvar|c}} is the concentration (mol/m&lt;sup&gt;3&lt;/sup&gt;), {{mvar|R}} is the [[universal gas constant]] (J/K/mol), {{mvar|T}} is the absolute temperature (K), and {{mvar|μ}} is the chemical potential (J/mol).

If the primary variable is mass fraction ({{mvar|y&lt;sub&gt;i&lt;/sub&gt;}}, given, for example, in kg/kg), then the equation changes to:

:&lt;math&gt;J_i=- \rho D\nabla y_i &lt;/math&gt;

where {{mvar|ρ}} is the fluid [[density]] (for example, in kg/m&lt;sup&gt;3&lt;/sup&gt;). Note that the density is outside the [[gradient]] operator.

== Fick's second law ==
'''Fick's second law''' predicts how diffusion causes the concentration to change with time. It is a [[partial differential equation]] which in one dimension reads:

:&lt;math&gt;\frac{\partial \varphi}{\partial t} = D\,\frac{\partial^2 \varphi}{\partial x^2}&lt;/math&gt;

where
* {{mvar| &lt;math&gt;\varphi&lt;/math&gt;}} is the concentration in dimensions of [(amount of substance) length&lt;sup&gt;−3&lt;/sup&gt;], example mol/m&lt;sup&gt;3&lt;/sup&gt;; {{math|&lt;math&gt;\varphi&lt;/math&gt; {{=}} &lt;math&gt;\varphi&lt;/math&gt;(''x'',''t'')}} is a function that depends on location {{mvar|x}} and time {{mvar|t}}
* {{mvar|t}} is time, example s
* {{mvar|D}} is the diffusion coefficient in dimensions of [length&lt;sup&gt;2&lt;/sup&gt; time&lt;sup&gt;−1&lt;/sup&gt;], example m&lt;sup&gt;2&lt;/sup&gt;/s
* {{mvar|x}} is the position [length], example m

In two or more dimensions we must use the [[Laplacian]] {{math|Δ {{=}} ∇&lt;sup&gt;2&lt;/sup&gt;}}, which generalises the second derivative, obtaining the equation

:&lt;math&gt;\frac{\partial \varphi}{\partial t} = D\Delta \varphi&lt;/math&gt;

==Derivation of Fick's laws==

===Fick's first law===
In one dimension, the following derivation is based on a similar argument made in Berg 1977 (see [[#References|references]]).

Consider a collection of particles performing a random walk in one dimension with length scale {{math|Δ''x''}} and time scale {{math|Δ''t''}}. Let {{math|''N''(''x'',''t'')}} be the number of particles at position {{mvar|x}} at time {{mvar|t}}.

At a given time step, half of the particles would move left and half would move right. Since half of the particles at point {{mvar|x}} move right and half of the particles at point {{math|''x'' + Δ''x''}} move left, the net movement to the right is:

:&lt;math&gt;-\tfrac{1}{2}\bigl[N(x + \Delta x, t) - N(x, t)\bigr]&lt;/math&gt;

The flux, {{mvar|J}}, is this net movement of particles across some area element of area {{mvar|a}}, normal to the random walk during a time interval {{math|Δ''t''}}. Hence we may write:

:&lt;math&gt;J = - \frac{1}{2} \left[\frac{ N(x + \Delta x, t)}{a \Delta t} - \frac{ N(x, t)}{a \Delta t}\right]&lt;/math&gt;

Multiplying the top and bottom of the right hand side by {{math|(Δ''x'')&lt;sup&gt;2&lt;/sup&gt;}} and rewriting, one obtains:

:&lt;math&gt; J = -\frac{\left(\Delta x\right)^2}{2 \Delta t}\left[\frac{N(x + \Delta x, t)}{a \left(\Delta x\right)^2} - \frac{N(x, t)}{a \left(\Delta x\right)^2}\right]&lt;/math&gt;

Concentration is defined as particles per unit volume, and hence
:&lt;math&gt;\varphi (x, t) = \frac{N(x, t)}{a \Delta x}.&lt;/math&gt;

In addition, {{math|{{sfrac|(Δ''x'')&lt;sup&gt;2&lt;/sup&gt;|2Δ''t''}}}} is the definition of the one-dimensional diffusion constant, {{mvar|D}}. Thus our expression simplifies to:

:&lt;math&gt; J = -D \left[\frac{\varphi (x + \Delta x, t)}{\Delta x} - \frac{\varphi (x , t)}{\Delta x}\right]&lt;/math&gt;

In the limit where {{math|Δ''x''}} is infinitesimal, the right-hand side becomes a space derivative:

:&lt;math&gt; J = - D \frac{\partial \varphi}{\partial x}  &lt;/math&gt;

===Fick's second law===
Fick's second law can be derived from Fick's first law and the [[mass conservation]] in absence of any chemical reactions:

:&lt;math&gt;\frac{\partial \varphi}{\partial t} + \frac{\partial}{\partial x}J = 0\Rightarrow\frac{\partial \varphi}{\partial t} -\frac{\partial}{\partial x}\left(D\frac{\partial}{\partial x}\varphi\right)\,=0&lt;/math&gt;

Assuming the diffusion coefficient {{mvar|D}} to be a constant, one can exchange the orders of the differentiation and multiply by the constant:

:&lt;math&gt;\frac{\partial}{\partial x}\left(D\frac{\partial}{\partial x} \varphi\right) = D\frac{\partial}{\partial x} \frac{\partial}{\partial x} \varphi = D\frac{\partial^2\varphi}{\partial x^2}&lt;/math&gt;

and, thus, receive the form of the Fick's equations as was stated above.

For the case of diffusion in two or more dimensions Fick's second law becomes

:&lt;math&gt;\frac{\partial \varphi}{\partial t} = D\nabla^2\varphi,&lt;/math&gt;

which is analogous to the [[heat equation]].

If the diffusion coefficient is not a constant, but depends upon the coordinate or concentration, Fick's second law yields

:&lt;math&gt;\frac{\partial \varphi}{\partial t} =  \nabla \cdot (D\nabla\varphi).&lt;/math&gt;

An important example is the case where {{math|'''φ'''}} is at a steady state, i.e. the concentration does not change by time, so that the left part of the above equation is identically zero. In one dimension with constant {{mvar|D}}, the solution for the concentration will be a linear change of concentrations along {{mvar|x}}. In two or more dimensions we obtain

:&lt;math&gt; \nabla^2\varphi =0&lt;/math&gt;

which is [[Laplace's equation]], the solutions to which are referred to by mathematicians as [[harmonic functions]].

==Derivation==
Fick's second law is a special case of the [[convection–diffusion equation]] in which there is no [[advection|advective flux]] and no net volumetric source. It can be derived from the [[Continuity equation#Differential form|continuity equation]]:

:&lt;math&gt; \frac{\partial \varphi}{\partial t} + \nabla\cdot\mathbf{j} = R, &lt;/math&gt;
where {{math|'''j'''}} is the total [[flux]] and {{mvar|R}} is a net volumetric source for {{math|'''φ'''}}. The only source of flux in this situation is assumed to be '''diffusive flux''':
:&lt;math&gt;\mathbf{j}_{\text{diffusion}} = -D \nabla \varphi&lt;/math&gt;

Plugging the definition of diffusive flux to the continuity equation and assuming there is no source ({{math|''R'' {{=}} 0}}), we arrive at Fick's second law:

:&lt;math&gt;\frac{\partial \varphi}{\partial t} = D\frac{\partial^2 \varphi}{\partial x^2}&lt;/math&gt;

If flux were the result of both '''diffusive flux''' and [[advection|advective flux]], the [[convection–diffusion equation]] is the result.

===Example solution in one dimension: diffusion length===

A simple case of diffusion with time {{mvar|t}} in one dimension (taken as the {{mvar|x}}-axis) from a boundary located at position {{math|''x'' {{=}} 0}}, where the concentration is maintained at a value {{math|''n''&lt;sub&gt;0&lt;/sub&gt;}} is

:&lt;math&gt;n \left(x,t \right)=n_0 \mathrm{erfc} \left( \frac{x}{2\sqrt{Dt}}\right)&lt;/math&gt;.

where {{math|erfc}} is the complementary [[error function]]. This is the case when corrosive gases diffuse through the oxidative layer towards the metal surface (if we assume that concentration of gases in the environment is constant and the diffusion space – that is, the corrosion product layer – is ''semi-infinite'', starting at 0 at the surface and spreading infinitely deep in the material). If, in its turn, the diffusion space is ''infinite'' (lasting both through the layer with {{math|''n''(''x'',0) {{=}} 0}}, {{math|''x'' &gt; 0}} and that with {{math|''n''(''x'',0) {{=}} ''n''&lt;sub&gt;0&lt;/sub&gt;}}, {{math|''x'' ≤ 0}}), then the solution is amended only with coefficient {{sfrac|2}} in front of {{math|''n''&lt;sub&gt;0&lt;/sub&gt;}} (as the diffusion now occurs in both directions). This case is valid when some solution with concentration {{math|''n''&lt;sub&gt;0&lt;/sub&gt;}} is put in contact with a layer of pure solvent. (Bokstein, 2005) The length {{math|2{{sqrt|''Dt''}}}} is called the ''diffusion length'' and provides a measure of how far the concentration has propagated in the {{mvar|x}}-direction by diffusion in time {{mvar|t}} (Bird, 1976).

As a quick approximation of the error function, the first 2 terms of the Taylor series can be used:
:&lt;math&gt;n \left(x,t \right)=n_0 \left[ 1 - 2 \left(\frac{x}{2\sqrt{Dt\pi}}\right) \right] &lt;/math&gt;

If {{mvar|D}} is time-dependent, the diffusion length becomes
:&lt;math&gt; 2\sqrt{\int_0^{t}D\tau \,d\tau}. &lt;/math&gt;.
This idea is useful for estimating a diffusion length over a heating and cooling cycle, where {{mvar|D}} varies with temperature.

===Generalizations===

* In ''non-homogeneous media'', the diffusion coefficient varies in space, {{math|''D'' {{=}} ''D''(''x'')}}. This dependence does not affect Fick's first law but the second law changes:
::&lt;math&gt;\frac{\partial \varphi(x,t)}{\partial t}=\nabla\cdot \bigl(D(x) \nabla \varphi(x,t)\bigr)=D(x) \Delta \varphi(x,t)+\sum_{i=1}^3 \frac{\partial D(x)}{\partial x_i} \frac{\partial \varphi(x,t)}{\partial x_i}&lt;/math&gt;

* In ''[[anisotropic]] media'', the diffusion coefficient depends on the direction. It is a symmetric [[tensor]] {{math|''D'' {{=}} ''D&lt;sub&gt;ij&lt;/sub&gt;''}}. Fick's first law changes to
::&lt;math&gt;J=-D \nabla \varphi &lt;/math&gt;,
:it is the product of a tensor and a vector:
::&lt;math&gt; J_i=-\sum_{j=1}^3 D_{ij} \frac{\partial \varphi}{\partial x_j}.&lt;/math&gt;
:For the diffusion equation this formula gives
::&lt;math&gt;\frac{\partial \varphi(x,t)}{\partial t}=\nabla\cdot \bigl(D \nabla \varphi(x,t)\bigr)=\sum_{i=1}^3\sum_{j=1}^3D_{ij} \frac{\partial^2 \varphi(x,t)}{\partial x_i \partial x_j}. &lt;/math&gt;
:The symmetric matrix of diffusion coefficients {{math|''D&lt;sub&gt;ij&lt;/sub&gt;''}} should be [[Positive-definite matrix|positive definite]]. It is needed to make the right hand side operator [[Elliptic operator|elliptic]].

* For ''inhomogeneous anisotropic media'' these two forms of the diffusion equation should be combined in
::&lt;math&gt;\frac{\partial \varphi(x,t)}{\partial t}=\nabla\cdot \bigl(D(x) \nabla \varphi(x,t)\bigr)=\sum_{i,j=1}^3\left(D_{ij}(x) \frac{\partial^2 \varphi(x,t)}{\partial x_i \partial x_j}+ \frac{\partial D_{ij}(x)}{\partial x_i }  \frac{\partial \varphi(x,t)}{\partial x_j}\right). &lt;/math&gt;

* The approach based on [[Diffusion#Einstein's mobility and Teorell formula|Einstein's mobility and Teorell formula]] gives the following generalization of Fick's equation for the ''multicomponent diffusion'' of the perfect components:
::&lt;math&gt;\frac{\partial \varphi_i}{\partial t}  =\sum_j \nabla\cdot\left(D_{ij} \frac{\varphi_i}{\varphi_j} \nabla \, \varphi_j\right) .&lt;/math&gt;
:where {{mvar|φ&lt;sub&gt;i&lt;/sub&gt;}} are concentrations of the components and {{mvar|D&lt;sub&gt;ij&lt;/sub&gt;}} is the matrix of coefficients. Here, indices {{mvar|i}} and {{mvar|j}} are related to the various components and not to the space coordinates.

The [[Diffusion#The theory of diffusion in gases based on Boltzmann's equation|Chapman–Enskog formulae for diffusion in gases]] include exactly the same terms. These physical models of diffusion are different from the test models {{math|∂&lt;sub&gt;''t''&lt;/sub&gt;''φ&lt;sub&gt;i&lt;/sub&gt;'' {{=}} ∑&lt;sub&gt;''j''&lt;/sub&gt; ''D&lt;sub&gt;ij&lt;/sub&gt;'' Δ''φ&lt;sub&gt;j&lt;/sub&gt;''}} which are valid for very small deviations from the uniform equilibrium. Earlier, such terms were introduced in the [[Maxwell–Stefan diffusion]] equation.

For anisotropic multicomponent diffusion coefficients one needs a rank-four tensor, for example {{math|''D''&lt;sub&gt;''ij'',''αβ''&lt;/sub&gt;}}, where {{math|''i'', ''j''}} refer to the components and {{math|''α'', ''β'' {{=}} 1, 2, 3}} correspond to the space coordinates.

== Applications ==
Equations based on Fick's law have been commonly used to model [[Passive transport|transport processes]] in foods, [[neuron]]s, [[biopolymer]]s, [[Pharmacology|pharmaceuticals]], [[porous]] [[soil]]s, [[population dynamics]], nuclear materials, [[plasma physics]], and [[Doping (semiconductor)|semiconductor doping]] processes. Theory of all [[Voltammetry|voltammetric]] methods is based on solutions of Fick's equation. Much experimental research in [[polymer]] science and food science has shown that a more general approach is required to describe transport of components in materials undergoing [[glass transition]].  In the vicinity of glass transition the flow behavior becomes "non-Fickian". It can be shown that the Fick's law can be obtained from the [[Maxwell–Stefan]] equations&lt;ref&gt;{{cite journal
|last= Taylor
|first=Ross
|first2=R. |last2=Krishna
|title = Multicomponent mass transfer
|publisher = Wiley
|year=1993
}}&lt;/ref&gt;
of [[multi-component]] [[mass transfer]]. The Fick's law is limiting case of the Maxwell–Stefan equations, when the mixture is extremely dilute and every chemical species is interacting only with the bulk mixture and not with other species. To account for the presence of multiple species in a non-dilute mixture, several variations of the Maxwell–Stefan equations are used. See also non-diagonal coupled transport processes ([[Onsager reciprocal relations|Onsager]] relationship). &lt;!-- Onsager = important point to be still developed --&gt;

=== Biological perspective ===
The first law gives rise to the following formula:&lt;ref&gt;{{GeorgiaPhysiology|3/3ch9/s3ch9_2}}&lt;/ref&gt;

:&lt;math&gt;\text{flux} = {-P \left(c_2 - c_1\right)}&lt;/math&gt;

in which,
* {{mvar|P}} is the permeability, an experimentally determined membrane "[[Electrical conductance|conductance]]" for a given gas at a given temperature.
* {{math|''c''&lt;sub&gt;2&lt;/sub&gt; − ''c''&lt;sub&gt;1&lt;/sub&gt;}} is the difference in [[concentration]] of the gas across the [[Artificial membrane|membrane]] for the direction of flow (from {{math|''c''&lt;sub&gt;1&lt;/sub&gt;}} to {{math|''c''&lt;sub&gt;2&lt;/sub&gt;}}).

Fick's first law is also important in radiation transfer equations.  However, in this context it becomes inaccurate when the diffusion constant is low and the radiation becomes limited by the speed of light rather than by the resistance of the material the radiation is flowing through.  In this situation, one can use a [[flux limiter]].

The exchange rate of a gas across a fluid membrane can be determined by using this law together with [[Graham's law]].

=== Fick's flow in liquids ===
When two [[miscibility|miscible]] liquids are brought into contact, and diffusion takes place, the macroscopic (or average) concentration evolves following Fick's law. On a mesoscopic scale, that is, between the macroscopic scale described by Fick's law and molecular scale, where molecular [[random walk]]s take place, fluctuations cannot be neglected. Such situations can be successfully modeled with Landau-Lifshitz fluctuating hydrodynamics. In this theoretical framework, diffusion is due to fluctuations whose dimensions range from the molecular scale to the macroscopic scale.&lt;ref&gt;{{cite journal|first1=D. |last1=Brogioli |first2=A. |last2=Vailati |title=Diffusive mass transfer by nonequilibrium fluctuations: Fick's law revisited |journal=Phys. Rev. E |volume=63 |page=012105 |issue=1–4 |date=2001 |arxiv = cond-mat/0006163 |bibcode = 2001PhRvE..63a2105B |doi = 10.1103/PhysRevE.63.012105 }}&lt;/ref&gt;

In particular, fluctuating hydrodynamic equations include a Fick's flow term, with a given diffusion coefficient, along with hydrodynamics equations and stochastic terms describing fluctuations. When calculating the fluctuations with a perturbative approach, the zero order approximation is Fick's law. The first order gives the fluctuations, and it comes out that fluctuations contribute to diffusion. This represents somehow a [[tautology (logic)|tautology]], since the phenomena described by a lower order approximation is the result of a higher approximation: this problem is solved only by [[renormalization|renormalizing]] the fluctuating hydrodynamics equations.

=== Semiconductor fabrication applications ===
[[Integrated circuit]] fabrication technologies, model processes like CVD, thermal oxidation, wet oxidation, doping, etc. use diffusion equations obtained from Fick's law.

In certain cases, the solutions are obtained for boundary conditions such as constant source concentration diffusion, limited source concentration, or moving boundary diffusion (where junction depth keeps moving into the substrate).

== History ==
In 1855, physiologist Adolf Fick first reported&lt;ref&gt;
*{{cite journal|first=A. |last=Fick |journal=Annalen der Physik |date=1855 |volume=94 |pages=59–86 |DOI=10.1002/andp.18551700105|language=German |title=Ueber Diffusion}}
*{{cite journal|first=A. |last=Fick |journal=Phil. Mag. |date=1855 |volume=10 |page=30 |language=English}}&lt;/ref&gt; his now well-known laws governing the transport of mass through diffusive means.  Fick's work was inspired by the earlier experiments of [[Thomas Graham (chemist)|Thomas Graham]], which fell short of proposing the fundamental laws for which Fick would become famous.  The Fick's law is analogous to the  relationships discovered at the same epoch by other eminent scientists: [[Darcy's law]] (hydraulic flow), [[Ohm's law]] (charge transport), and [[Fourier's Law]] (heat transport).

Fick's experiments (modeled on Graham's) dealt with measuring the concentrations and fluxes of salt, diffusing between two reservoirs through tubes of water. It is notable that Fick's work primarily concerned diffusion in fluids, because at the time, diffusion in solids was not considered generally possible.&lt;ref&gt;{{cite journal |url=http://www.uni-leipzig.de/diffusion/journal/pdf/volume2/diff_fund_2(2005)1.pdf |first=Jean |last=Philibert |title=One and a Half Centuries of Diffusion: Fick, Einstein, before and beyond |journal=Diffusion Fundamentals |volume=2 |date=2005 |page=1.1–1.10 |deadurl=yes |archiveurl=https://web.archive.org/web/20090205030323/http://www.uni-leipzig.de/diffusion/journal/pdf/volume2/diff_fund_2(2005)1.pdf |archivedate=5 February 2009 |df=dmy }}&lt;/ref&gt;  Today, Fick's Laws form the core of our understanding of diffusion in solids, liquids, and gases (in the absence of bulk fluid motion in the latter two cases).  When a diffusion process does ''not'' follow Fick's laws (which happens in cases of diffusion through porous media and diffusion of swelling penetrants, among others),&lt;ref&gt;{{cite book|first=J. L. |last=Vázquez |date=2006 |chapter=The Porous Medium Equation |title=Mathematical Theory |publisher=Oxford Univ. Press.}}&lt;/ref&gt;&lt;ref name=GorbanMMNP2011&gt;{{cite journal|author1-link=Alexander Nikolaevich Gorban|first1=A. N. |last1=Gorban, |first2=H. P. |last2=Sargsyan |first3=H. A. |last3=Wahab |date=2011 |arxiv=1012.2908|title=Quasichemical Models of Multicomponent Nonlinear Diffusion |journal= Mathematical Modelling of Natural Phenomena|volume=6 |issue=05 |pages= 184–262 |doi=10.1051/mmnp/20116509}}&lt;/ref&gt; it is referred to as ''non-Fickian''.

== See also ==
* [[Diffusion]]
* [[Osmosis]]
* [[Mass flux]]
* [[Maxwell–Stefan diffusion]]
* [[Churchill–Bernstein equation]]
* [[Nernst–Planck equation]]
* [[Gas exchange]]
* [[False diffusion]]
* [[Advection]]

==Notes==
{{reflist}}

== References ==
* {{cite book|first=W. F. |last=Smith |title=Foundations of Materials Science and Engineering |edition=3rd |publisher=McGraw-Hill |date=2004}}
* {{cite book|first=H. C. |last=Berg |title=Random Walks in Biology |publisher=Princeton |date=1977}}
* {{cite book|first1=R. B. |last1=Bird |first2=W. E. |last2=Stewart |first3=E. N. |last3=Lightfoot |title=Transport Phenomena |publisher=John Wiley &amp; Sons |date=1976}}
* {{cite book|first=J. |last=Crank |title=The Mathematics of Diffusion |publisher=Oxford University Press |date=1980}}
* {{cite book|title=Thermodynamics and Kinetics in Materials Science: A Short Course |editor1-last=Bokshtein |editor1-first=B. S. |editor2-last=Mendelev |editor2-first=M. I. |editor3-last=Srolovitz |editor3-first=D. J. |publisher=Oxford University Press |location=Oxford |date=2005 |pages=167–171}}
* {{cite journal|first=A. |last=Fick |title=On liquid diffusion |journal=Poggendorffs Annalen. |volume=94 |page=59 |date=1855}} – reprinted in {{cite journal|journal=Journal of Membrane Science |volume=100 |pages=33–38 |date=1995 |doi=10.1016/0376-7388(94)00230-v |title=On liquid diffusion}}

==External links==
* [http://dragon.unideb.hu/~zerdelyi/Diffusion-on-the-nanoscale/node2.html Fick's equations, Boltzmann's transformation, etc.] (with figures and animations)
* [http://cnx.org/content/m1036/2.11/ Fick's Second Law] on [[OpenStax]]

[[Category:Diffusion]]
[[Category:Statistical mechanics]]
[[Category:Physical chemistry]]
[[Category:Mathematics in medicine]]

[[de:Diffusion#Erstes Fick’sches Gesetz]]</text>
      <sha1>b7fh97tdqqi3wbwtrf444q7v14tu8fz</sha1>
    </revision>
  </page>
  <page>
    <title>Frenet–Serret formulas</title>
    <ns>0</ns>
    <id>666987</id>
    <revision>
      <id>862709085</id>
      <parentid>852441332</parentid>
      <timestamp>2018-10-06T05:18:16Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32154">{{redirect|Binormal|the category-theoretic meaning of this word|normal morphism}}

[[Image:frenet.png|thumb|300px|right|A space curve; the vectors '''T''', '''N''' and '''B'''; and the [[osculating plane]] spanned by '''T''' and '''N''']]
In [[differential geometry]], the '''Frenet–Serret formulas''' describe the [[kinematic]] properties of a particle moving along a continuous, differentiable [[curve]] in three-dimensional [[Euclidean space]] ℝ&lt;sup&gt;3&lt;/sup&gt;, or the geometric properties of the curve itself irrespective of any motion.  More specifically, the formulas describe the [[derivative]]s of the so-called '''tangent, normal, and binormal''' [[unit vector]]s in terms of each other.  The formulas are named after the two French mathematicians who  independently discovered them: [[Jean Frédéric Frenet]], in his thesis of 1847, and [[Joseph Alfred Serret]] in 1851.  Vector notation and linear algebra currently used to write these formulas were not yet in use at the time of their discovery.

The tangent, normal, and binormal unit vectors, often called '''T''', '''N''', and '''B''', or collectively the '''Frenet–Serret frame''' or '''TNB frame''', together form an [[orthonormal basis]] [[Linear span|spanning]] ℝ&lt;sup&gt;3&lt;/sup&gt; and are defined as follows:
* '''T''' is the unit vector [[tangent vector|tangent]] to the curve, pointing in the direction of motion.
* '''N''' is the [[normal vector|normal]] unit vector, the derivative of '''T''' with respect to the [[Rectifiable path|arclength parameter]] of the curve, divided by its length.
* '''B''' is the binormal unit vector, the [[cross product]] of '''T''' and '''N'''.
The Frenet–Serret formulas are:
:&lt;math&gt; 
\begin{align}
\dfrac{d\mathbf{T}}{ds} &amp;=&amp; \kappa \mathbf{N}, \\
\dfrac{d\mathbf{N}}{ds} &amp;=&amp; - \kappa \mathbf{T} + \tau \mathbf{B},\\
\dfrac{d\mathbf{B}}{ds} &amp;=&amp; -\tau \mathbf{N},
\end{align}
&lt;/math&gt;
where ''d''/''ds'' is the derivative with respect to arclength, ''κ'' is the [[curvature]], and ''τ'' is the [[torsion of curves|torsion]] of the curve. The two [[Scalar (mathematics)|scalars]] ''κ'' and ''τ'' effectively define the curvature and torsion of a space curve.  The associated collection, '''T''', '''N''', '''B''', ''κ'', and ''τ'', is called the '''Frenet–Serret apparatus'''.  Intuitively, curvature measures the failure of a curve to be a straight line, while torsion measures the failure of a curve to be planar.

==Definitions==
[[Image:FrenetTN.svg|thumb|right|350px|The '''T''' and '''N''' vectors at two points on a plane curve, a translated version of the second frame (dotted), and the change in '''T''': δ'''T''''. δs is the distance between the points. In the limit &lt;math&gt;\tfrac{d\mathbf{T}}{ds}&lt;/math&gt; will be in the direction '''N''' and the curvature describes the speed of rotation of the frame.]]

Let '''r'''(t) be a [[curve]] in [[Euclidean space]], representing the [[position vector]] of the particle as a function of time.  The Frenet–Serret formulas apply to curves which are ''non-degenerate'', which roughly means that they have nonzero [[curvature]].  More formally, in this situation the [[velocity]] vector '''r'''&amp;prime;(t) and the [[acceleration]] vector '''r'''&amp;prime;&amp;prime;(t) are required not to be proportional.

Let ''s(t)'' represent the [[arc length]] which the particle has moved along the [[curve]] in time t.  The quantity ''s'' is used to give the curve traced out by the trajectory of the particle a [[Rectifiable path|natural parametrization]] by arc length, since many different particle paths may trace out the same geometrical curve by traversing it at different rates.  In detail, ''s'' is given by
:&lt;math&gt;s(t)=\int_0^t \|\mathbf{r}'(\sigma)\|d\sigma.&lt;/math&gt;
Moreover, since we have assumed that '''r'''&amp;prime; ≠ 0, it follows that ''s''(''t'') is a strictly monotonically increasing function.  Therefore, it is possible to solve for ''t'' as a function of ''s'', and thus to write '''r'''(''s'') = '''r'''(''t''(''s'')).  The curve is thus parametrized in a preferred manner by its arc length.

With a non-degenerate curve '''r'''(''s''), parameterized by its arc length, it is now possible to define the '''Frenet–Serret frame''' (or '''TNB frame'''):
* The tangent unit vector '''T''' is defined as
::&lt;math&gt; \mathbf{T} = {\frac{d\mathbf{r}}{ds} \over \left\| \frac{d\mathbf{r}}{ds} \right\|}. \qquad \qquad (1) &lt;/math&gt;
* The normal unit vector '''N''' is defined as
::&lt;math&gt; \mathbf{N} = {\frac{d\mathbf{T}}{ds} \over \left\| \frac{d\mathbf{T}}{ds} \right\|}. \qquad \qquad (2) &lt;/math&gt;
* The binormal unit vector '''B''' is defined as the [[cross product]] of '''T''' and '''N''':
::&lt;math&gt; \mathbf{B} = \mathbf{T} \times \mathbf{N}. \qquad \qquad (3) &lt;/math&gt;

[[Image:frenetframehelix.gif|thumb|right|400px|The Frenet-Serret frame moving along a [[helix]]. The '''T''' is represented by the blue arrow, '''N''' is represented by the red vector while '''B''' is represented by the black vector.]]

From equation (2) it follows, since '''T''' always has unit [[magnitude (mathematics)|magnitude]], that '''N''' (the change of '''T''') is always perpendicular to '''T''', since there is no change in direction of '''T'''.   From equation (3) it follows that '''B''' is always perpendicular to both '''T''' and '''N'''.  Thus, the three unit vectors '''T''', '''N''', and '''B''' are all perpendicular to each other.

The '''Frenet–Serret formulas''' are:

:&lt;math&gt; 
\begin{matrix}
\frac{d\mathbf{T}}{ds} &amp;=&amp; &amp; \kappa \mathbf{N} &amp; \\
&amp;&amp;&amp;&amp;\\
\frac{d\mathbf{N}}{ds} &amp;=&amp; - \kappa \mathbf{T} &amp; &amp;+\, \tau \mathbf{B}\\
&amp;&amp;&amp;&amp;\\
\frac{d\mathbf{B}}{ds} &amp;=&amp; &amp; -\tau \mathbf{N} &amp;
\end{matrix}
&lt;/math&gt;

where &lt;math&gt;\kappa&lt;/math&gt; is the [[curvature]] and &lt;math&gt;\tau&lt;/math&gt; is the [[Torsion of curves|torsion]].

The Frenet–Serret formulas are also known as ''Frenet–Serret theorem'', and can be stated more concisely using matrix notation:&lt;ref&gt;{{harvnb|Kühnel|2002|loc=§1.9}}&lt;/ref&gt;
:&lt;math&gt; \begin{bmatrix} \mathbf{T'} \\ \mathbf{N'} \\ \mathbf{B'} \end{bmatrix} = \begin{bmatrix} 0 &amp; \kappa &amp; 0 \\ -\kappa &amp; 0 &amp; \tau \\ 0 &amp; -\tau &amp; 0 \end{bmatrix} \begin{bmatrix} \mathbf{T} \\ \mathbf{N} \\ \mathbf{B} \end{bmatrix}.&lt;/math&gt;

This matrix is [[Skew-symmetric matrix|skew-symmetric]].

== Formulas in ''n'' dimensions ==

The Frenet–Serret formulas were generalized to higher-dimensional Euclidean spaces by [[Camille Jordan]] in 1874.

Suppose that '''r'''(''s'') is a smooth curve in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, parametrized by arc length, and that the first ''n'' derivatives of '''r''' are linearly independent.&lt;ref&gt;Only the first ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 actually need to be linearly independent, as the final remaining frame vector '''e'''&lt;sub&gt;n&lt;/sub&gt; can be chosen as the unit vector orthogonal to the span of the others, such that the resulting frame is positively oriented.&lt;/ref&gt;  The vectors in the Frenet–Serret frame are an [[orthonormal basis]] constructed by applying the [[Gram-Schmidt process]] to the vectors ('''r'''&amp;prime;(''s''), '''r'''&amp;prime;&amp;prime;(''s''), ..., '''r'''&lt;sup&gt;(''n'')&lt;/sup&gt;(''s'')).

In detail, the unit tangent vector is the first Frenet vector ''e''&lt;sub&gt;1&lt;/sub&gt;(''s'') and is defined as

:&lt;math&gt;\mathbf{e}_1(s) = \mathbf{r}'(s)&lt;/math&gt;

The '''normal vector''', sometimes called the '''curvature vector''', indicates the deviance of the curve from being a straight line. It is defined as
:&lt;math&gt;\overline{\mathbf{e}_2}(s) = \mathbf{r}''(s) - \langle \mathbf{r}''(s), \mathbf{e}_1(s) \rangle \, \mathbf{e}_1(s)&lt;/math&gt;

Its normalized form, the '''unit normal vector''', is the second Frenet vector '''e'''&lt;sub&gt;2&lt;/sub&gt;(''s'') and defined as

:&lt;math&gt;\mathbf{e}_2(s) = \frac{\overline{\mathbf{e}_2}(s)} {\| \overline{\mathbf{e}_2}(s) \|}
&lt;/math&gt;

The tangent and the normal vector at point ''s'' define the '''[[osculating plane]]''' at point '''r'''(''s'').

The remaining vectors in the frame (the binormal, trinormal, etc.) are defined similarly by

:&lt;math&gt;\begin{align}
\mathbf{e}_{j}(s) = \frac{\overline{\mathbf{e}_{j}}(s)}{\|\overline{\mathbf{e}_{j}}(s) \|} 
\mbox{, } 
\end{align} &lt;/math&gt;
:&lt;math&gt;\begin{align}
\overline{\mathbf{e}_{j}}(s) = \mathbf{r}^{(j)}(s) - \sum_{i=1}^{j-1} \langle \mathbf{r}^{(j)}(s), \mathbf{e}_i(s) \rangle \, \mathbf{e}_i(s).
\end{align} &lt;/math&gt;

The real valued functions χ&lt;sub&gt;''i''&lt;/sub&gt;(''s'') are called '''generalized curvature''' and are defined as

:&lt;math&gt;\chi_i(s) = \frac{\langle \mathbf{e}_i'(s), \mathbf{e}_{i+1}(s) \rangle}{\| \mathbf{r}'(s) \|} &lt;/math&gt;

The '''Frenet–Serret formulas''', stated in matrix language, are

:&lt;math&gt;\begin{align}
\begin{bmatrix}
  \mathbf{e}_1'(s)\\
           \vdots \\
 \mathbf{e}_n'(s) \\
\end{bmatrix}

= \\
\end{align} &lt;/math&gt;&lt;math&gt;\begin{align}
\begin{bmatrix}
          0 &amp; \chi_1(s) &amp;                &amp;             0 \\
 -\chi_1(s) &amp;    \ddots &amp;         \ddots &amp;               \\
            &amp;    \ddots &amp;              0 &amp; \chi_{n-1}(s) \\
          0 &amp;           &amp; -\chi_{n-1}(s) &amp;             0 \\
\end{bmatrix}

\begin{bmatrix}
 \mathbf{e}_1(s) \\
          \vdots \\
 \mathbf{e}_n(s) \\
\end{bmatrix} 
\end{align} &lt;/math&gt;

==Proof==
Consider the matrix

:&lt;math&gt; 
Q = \left[\begin{matrix}
 \mathbf{T}\\
 \mathbf{N}\\
 \mathbf{B}
\end{matrix}\right]
&lt;/math&gt;

The rows of this matrix are mutually perpendicular unit vectors: an [[orthonormal basis]] of ℝ&lt;sup&gt;3&lt;/sup&gt;.  As a result, the [[transpose of a matrix|transpose]] of ''Q'' is equal to the [[inverse of a matrix|inverse]] of ''Q'': ''Q'' is an [[orthogonal matrix]].  It suffices to show that

:&lt;math&gt;
\left(\frac{dQ}{ds}\right)Q^T =
\left[\begin{matrix}
  0 &amp; \kappa &amp; 0\\
  -\kappa &amp; 0 &amp; \tau\\
  0 &amp; -\tau &amp; 0
\end{matrix}\right]
&lt;/math&gt;

Note the first row of this equation already holds, by definition of the normal '''N''' and curvature κ.  So it suffices to show that (d''Q''/d''s'')''Q''&lt;sup&gt;T&lt;/sup&gt; is a [[skew-symmetric matrix]].  Since ''I'' = ''QQ''&lt;sup&gt;T&lt;/sup&gt;, taking a derivative and applying the product rule yields

:&lt;math&gt;\begin{align}
0 = \frac{dI}{ds} = \left(\frac{dQ}{ds}\right)Q^T + Q\left(\frac{dQ}{ds}\right)^T
    \implies \\
    \left(\frac{dQ}{ds}\right)Q^T = 
    -\left(\left(\frac{dQ}{ds}\right)Q^T\right)^T \\
\end{align} 
&lt;/math&gt;

which establishes the required skew-symmetry.&lt;ref&gt;This proof is likely due to [[Élie Cartan]].  See Griffiths (1974) where he gives the same proof, but using the [[Maurer-Cartan form]].  Our explicit description of the Maurer-Cartan form using matrices is standard.  See, for instance, Spivak, Volume II, p. 37.  A generalization of this proof to ''n'' dimensions is not difficult, but was omitted for the sake of exposition.  Again, see Griffiths (1974) for details.&lt;/ref&gt;

==Applications and interpretation==

=== Kinematics of the frame ===
[[Image:Frenet-Serret moving frame1.png|right|thumb|The Frenet-Serret frame moving along a [[helix]] in space]]

The Frenet–Serret frame consisting of the tangent '''T''', normal '''N''', and binormal '''B''' collectively forms an [[orthonormal basis]] of 3-space.  At each point of the curve, this ''attaches'' a [[frame of reference]] or [[rectilinear grid|rectilinear]] [[coordinate system]] (see image).

The Frenet–Serret formulas admit a [[kinematics|kinematic]] interpretation.  Imagine that an observer moves along the curve in time, using the attached frame at each point as her coordinate system.  The Frenet–Serret formulas mean that this coordinate system is constantly rotating as an observer moves along the curve.  Hence, this coordinate system is always [[Non-inertial reference frame|non-inertial]].  The [[angular momentum]] of the observer's coordinate system is proportional to the [[Darboux vector]] of the frame.

[[Image:TNB frame momenta.svg|left|thumb|A top whose axis is situated along the binormal is observed to rotate with angular speed &amp;kappa;. If the axis is along the tangent, it is observed to rotate with angular speed &amp;tau;.]]
Concretely, suppose that the observer carries an (inertial) [[top]] (or [[gyroscope]]) with her along the curve.  If the axis of the top points along the tangent to the curve, then it will be observed to rotate about its axis with angular velocity -τ relative to the observer's non-inertial coordinate system.  If, on the other hand, the axis of the top points in the binormal direction, then it is observed to rotate with angular velocity -κ.  This is easily visualized in the case when the curvature is a positive constant and the torsion vanishes.  The observer is then in [[uniform circular motion]].  If the top points in the direction of the binormal, then by [[conservation of angular momentum]] it must rotate in the ''opposite'' direction of the circular motion.  In the limiting case when the curvature vanishes, the observer's normal [[precess]]es about the tangent vector, and similarly the top will rotate in the opposite direction of this precession.

The general case is illustrated [[#Illustrations|below]]. There are further [[commons:Category:Illustrations for curvature and torsion of curves|illustrations]] on Wikimedia.

'''Applications.'''  The kinematics of the frame have many applications in the sciences.
*  In the [[life sciences]], particularly in models of microbial motion, considerations of the Frenet-Serret frame have been used to explain the mechanism by which a moving organism in a viscous medium changes its direction.&lt;ref&gt;Crenshaw (1993).&lt;/ref&gt;
* In physics, the Frenet-Serret frame is useful when it is impossible or inconvenient to assign a natural coordinate system for a trajectory.  Such is often the case, for instance, in [[relativity theory]].  Within this setting, Frenet-Serret frames have been used to model the precession of a gyroscope in a gravitational well.&lt;ref&gt;Iyer and Vishveshwara (1993).&lt;/ref&gt;&lt;!--More elementary applications?  Classic papers on coriolis effects maybe?--&gt;
{{clear}}

====Graphical Illustrations====

# Example of a moving Frenet basis ('''T''' in blue, '''N''' in green, '''B''' in purple) along [[Viviani's curve]].

[[File:Frenet-Serret-frame along Vivani-curve.gif]]

#&lt;li value=2&gt; On the example of a [[torus knot]], the tangent vector '''T''', the normal vector '''N''', and the binormal vector '''B''', along with the curvature κ(s), and the torsion τ(s) are displayed. &lt;br&gt; At the peaks of the torsion function the rotation of the Frenet-Serret frame ('''T''','''N''','''B''') around the tangent vector is clearly visible.

[[File:Torus-Knot nebeneinander animated.gif]]

#&lt;li value=3&gt; The kinematic significance of the curvature is best illustrated with plane curves (having constant torsion equal to zero). See the page on [[Curvature#Curvature of plane curves|curvature of plane curves]].
&lt;/li&gt;

=== Frenet–Serret formulas in calculus ===
The Frenet–Serret formulas are frequently introduced in courses on [[multivariable calculus]] as a companion to the study of space curves such as the [[helix]].  A helix can be characterized by the height 2π''h'' and radius ''r'' of a single turn.  The curvature and torsion of a helix (with constant radius) are given by the formulas
: &lt;math&gt; \kappa = \frac{r}{r^2+h^2} &lt;/math&gt;
: &lt;math&gt; \tau = \pm\frac{h}{r^2+h^2}. &lt;/math&gt;
[[Image:Frenet-Serret helices.png|right|thumb|Two helices (slinkies) in space. (a) A more compact helix with higher curvature and lower torsion. (b) A stretched out helix with slightly higher torsion but lower curvature.]]
The sign of the torsion is determined by the right-handed or left-handed [[right-hand rule|sense]] in which the helix twists around its central axis. Explicitly, the parametrization of a single turn of a right-handed helix with height 2π''h'' and radius ''r'' is
: ''x'' = ''r'' cos ''t''
: ''y'' = ''r'' sin ''t''
: ''z'' = ''h'' ''t''
: (0 &amp;le; t &amp;le; 2 &amp;pi;)
and, for a left-handed helix,
: ''x'' = ''r'' cos ''t''
: ''y'' = &amp;minus;''r'' sin ''t''
: ''z'' = ''h'' ''t''
: (0 &amp;le; t &amp;le; 2 &amp;pi;).
Note that these are not the arc length parametrizations (in which case, each of ''x'', ''y'', and ''z'' would need to be divided by &lt;math&gt;\sqrt{h^2+r^2}&lt;/math&gt;.)

In his expository writings on the geometry of curves, [[Rudy Rucker]]&lt;ref&gt;Rucker (1999).&lt;/ref&gt; employs the model of a [[slinky]] to explain the meaning of the torsion and curvature.  The slinky, he says, is characterized by the property that the quantity
:&lt;math&gt; A^2 = h^2+r^2&lt;/math&gt;
remains constant if the slinky is vertically stretched out along its central axis.  (Here 2π''h'' is the height of a single twist of the slinky, and ''r'' the radius.)  In particular, curvature and torsion are complementary in the sense that the torsion can be increased at the expense of curvature by stretching out the slinky.

=== Taylor expansion ===
Repeatedly differentiating the curve and applying the Frenet–Serret formulas gives the following [[Taylor's theorem|Taylor approximation]] to the curve near ''s''&amp;nbsp;=&amp;nbsp;0:&lt;ref&gt;{{harvnb|Kühnel|2002|p=19}}&lt;/ref&gt;
:&lt;math&gt;\mathbf r(s) = \mathbf r(0) + \left(s-\frac{s^3\kappa^2(0)}{6}\right)\mathbf T(0) + \left(\frac{s^2\kappa(0)}{2}+\frac{s^3\kappa'(0)}{6}\right)\mathbf N(0) + \left(\frac{s^3\kappa(0)\tau(0)}{6}\right)\mathbf B(0) + o(s^3).&lt;/math&gt;

For a generic curve with nonvanishing torsion, the projection of the curve onto various coordinate planes in the '''T''', '''N''', '''B''' coordinate system at {{nowrap|1=''s'' = 0}} have the following interpretations:

*The '''[[osculating plane]]''' is the plane [[linear span|containing]] '''T''' and '''N'''.  The projection of the curve onto this plane has the form:&lt;br/&gt;&amp;nbsp;&amp;nbsp;&lt;math&gt;\mathbf r(0) + s\mathbf T(0) + \frac{s^2\kappa(0)}{2}\mathbf N(0)+ o(s^2).&lt;/math&gt;&lt;br/&gt;This is a [[parabola]] up to terms of order ''o''(''s''&lt;sup&gt;2&lt;/sup&gt;), whose curvature at 0 is equal to κ(0).
*The '''normal plane''' is the plane containing '''N''' and '''B'''.  The projection of the curve onto this plane has the form:&lt;br/&gt;&amp;nbsp;&amp;nbsp;&lt;math&gt;\mathbf r(0) + \left(\frac{s^2\kappa(0)}{2}+\frac{s^3\kappa'(0)}{6}\right)\mathbf N(0) + \left(\frac{s^3\kappa(0)\tau(0)}{6}\right)\mathbf B(0)+ o(s^3)&lt;/math&gt;&lt;br/&gt;which is a [[cuspidal cubic]] to order ''o''(''s''&lt;sup&gt;3&lt;/sup&gt;).
*The '''rectifying plane''' is the plane containing '''T''' and '''B'''.  The projection of the curve onto this plane is:&lt;br/&gt;&amp;nbsp;&amp;nbsp;&lt;math&gt;\mathbf r(0) + \left(s-\frac{s^3\kappa^2(0)}{6}\right)\mathbf T(0) + \left(\frac{s^3\kappa(0)\tau(0)}{6}\right)\mathbf B(0)+ o(s^3)&lt;/math&gt;&lt;br/&gt;which traces out the graph of a [[cubic polynomial]] to order ''o''(''s''&lt;sup&gt;3&lt;/sup&gt;).

=== Ribbons and tubes ===
[[File:Ribbon-Frenet.png|thumb|350px|A  ribbon defined by a curve of constant torsion and a highly oscillating curvature. The arc length parameterization of the curve was defined via integration of the Frenet-Serret equations.]]
The Frenet–Serret apparatus allows one to define certain optimal ''ribbons'' and ''tubes'' centered around a curve.  These have diverse applications in [[materials science]] and [[elasticity theory]],&lt;ref&gt;Goriely ''et al.'' (2006).&lt;/ref&gt; as well as to [[computer graphics]].&lt;ref&gt;Hanson.&lt;/ref&gt;

A '''Frenet ribbon'''&lt;ref&gt;For terminology, see Sternberg (1964).&lt;/ref&gt; along a curve ''C'' is the surface traced out by sweeping the line segment [&amp;minus;'''N''','''N'''] generated by the unit normal along the curve.  Geometrically, a ribbon is a piece of the [[envelope (mathematics)|envelope]] of the osculating planes of the curve. Symbolically, the ribbon ''R'' has the following parametrization:
:&lt;math&gt; R(s,t) = C(s)+t\mathbf{N},\quad -1\le t\le 1.&lt;/math&gt;
In particular, the binormal '''B''' is a unit vector normal to the ribbon.  Moreover, the ribbon is a [[ruled surface]] whose reguli are the line segments spanned by '''N'''.  Thus each of the frame vectors '''T''', '''N''', and '''B''' can be visualized entirely in terms of the Frenet ribbon.&lt;ref&gt;For such an interpretation, see Rucker (1999).&lt;/ref&gt;

The [[Gauss curvature]] of a Frenet ribbon vanishes, and so it is a [[developable surface]].  Geometrically, it is possible to "roll" a plane along the ribbon without slipping or twisting so that the regulus always remains within the plane.&lt;ref&gt;See Guggenheimer (1977).&lt;/ref&gt;  The ribbon then traces out a ribbon in the plane (possibly with multiple sheets).  The curve ''C'' also traces out a curve ''C''&lt;sub&gt;P&lt;/sub&gt; in the plane, whose curvature is given in terms of the curvature and torsion of ''C'' by
:&lt;math&gt;\kappa_P(s) = \pm\sqrt{\kappa(s)^2+\tau(s)^2}.&lt;/math&gt;
This fact gives a general procedure for constructing any Frenet ribbon.&lt;ref&gt;Exploited by Rucker's construction of so-called ''kappatau curves''.&lt;/ref&gt;  Intuitively, one can cut out a curved ribbon from a flat piece of paper.  Then by bending the ribbon out into space without tearing it, one produces a Frenet ribbon.&lt;ref&gt;Somewhat more accurately, the plane ribbon should be thought of as a "railroad track": one may move it up into space, but without shearing or bending its cross-ties.&lt;/ref&gt;  In the simple case of the slinky, the ribbon is several turns of an [[Annulus (mathematics)|annulus]] in the plane, and bending it up into space corresponds to stretching out the slinky.

=== Congruence of curves ===
In classical [[Euclidean geometry]], one is interested in studying the properties of figures in the plane which are ''invariant'' under congruence, so that if two figures are congruent then they must have the same properties.  The Frenet-Serret apparatus presents the curvature and torsion as numerical invariants of a space curve.

Roughly speaking, two curves ''C'' and ''C''&amp;prime; in space are ''congruent'' if one can be rigidly moved to the other.  A rigid motion consists of a combination of a translation and a rotation.  A translation moves one point of ''C'' to a point of ''C''&amp;prime;.  The rotation then adjusts the orientation of the curve ''C'' to line up with that of ''C''&amp;prime;.  Such a combination of translation and rotation is called a [[Euclidean transformation|Euclidean motion]].  In terms of the parametrization '''r'''(t) defining the first curve ''C'', a general Euclidean motion of ''C'' is a composite of the following operations:
* (''Translation''.)  '''r'''(t) →  '''r'''(t) + '''v''', where '''v''' is a constant vector.
* (''Rotation''.)  '''r'''(t) + '''v''' → M('''r'''(t) + '''v'''), where ''M'' is the matrix of a rotation.

The Frenet–Serret frame is particularly well-behaved with regard to Euclidean motions.  First, since '''T''', '''N''', and '''B''' can all be given as successive derivatives of the parametrization of the curve, each of them is insensitive to the addition of a constant vector to '''r'''(t).  Intuitively, the '''TNB''' frame attached to '''r'''(t) is the same as the '''TNB''' frame attached to the new curve '''r'''(t) + '''v'''.

This leaves only the rotations to consider.  Intuitively, if we apply a rotation ''M'' to the curve, then the '''TNB''' frame also rotates.  More precisely, the matrix ''Q'' whose rows are the '''TNB''' vectors of the Frenet-Serret frame changes by the matrix of a rotation

:&lt;math&gt; Q \rightarrow QM.&lt;/math&gt;

''A fortiori'', the matrix (d''Q''/d''s'')''Q''&lt;sup&gt;T&lt;/sup&gt; is unaffected by a rotation:

:&lt;math&gt;
\left(\frac{d(QM)}{ds}\right)(QM)^T 
= \left(\frac{dQ}{ds}\right)MM^TQ^T
= \left(\frac{dQ}{ds}\right)Q^T
&lt;/math&gt;

since ''MM''&lt;sup&gt;T&lt;/sup&gt; = ''I'' for the matrix of a rotation.

Hence the entries κ and τ of (d''Q''/d''s'')''Q''&lt;sup&gt;T&lt;/sup&gt; are ''invariants'' of the curve under Euclidean motions: if a Euclidean motion is applied to a curve, then the resulting curve has ''the same'' curvature and torsion.

Moreover, using the Frenet–Serret frame, one can also prove the converse: any two curves having the same curvature and torsion functions must be congruent by a Euclidean motion.  Roughly speaking, the Frenet–Serret formulas express the [[Darboux derivative]] of the '''TNB''' frame.  If the Darboux derivatives of two frames are equal, then a version of the [[fundamental theorem of calculus]] asserts that the curves are congruent.  In particular, the curvature and torsion are a ''complete'' set of invariants for a curve in three-dimensions.

==Other expressions of the frame==
The formulas given above for '''T''', '''N''', and '''B''' depend on the curve being given in terms of the arclength parameter.  This is a natural assumption in Euclidean geometry, because the arclength is a Euclidean invariant of the curve.  In the terminology of physics, the arclength parametrization is a natural choice of [[gauge theory|gauge]]. However, it may be awkward to work with in practice.  A number of other equivalent expressions are available.

Suppose that the curve is given by '''r'''(''t''), where the parameter ''t'' need no longer be arclength.  Then the unit tangent vector '''T''' may be written as

:&lt;math&gt;\mathbf{T}(t) = \frac{\mathbf{r}'(t)}{\|\mathbf{r}'(t)\|}.&lt;/math&gt;

The normal vector '''N''' takes the form

:&lt;math&gt;\mathbf{N}(t) = \frac{\mathbf{T}'(t)}{\|\mathbf{T}'(t)\|} = \frac{\mathbf{r}'(t) \times \left(\mathbf{r}''(t) \times \mathbf{r}'(t) \right)}{\left\|\mathbf{r}'(t)\right\| \, \left\|\mathbf{r}''(t) \times \mathbf{r}'(t)\right\|}.&lt;/math&gt;

The binormal '''B''' is then

:&lt;math&gt;\mathbf{B}(t) = \mathbf{T}(t)\times\mathbf{N}(t) = \frac{\mathbf{r}'(t)\times\mathbf{r}''(t)}{\|\mathbf{r}'(t)\times\mathbf{r}''(t)\|}.&lt;/math&gt;

An alternative way to arrive at the same expressions is to take the first three derivatives of the curve '''r'''&amp;prime;(''t''), '''r'''&amp;prime;&amp;prime;(''t''), '''r'''&amp;prime;&amp;prime;&amp;prime;(''t''), and to apply the [[Gram-Schmidt process]].  The resulting ordered [[orthonormal basis]] is precisely the '''TNB''' frame.  This procedure also generalizes to produce Frenet frames in higher dimensions.

In terms of the parameter ''t'', the Frenet–Serret formulas pick up an additional factor of ||'''r'''&amp;prime;(''t'')|| because of the [[chain rule]]:

:&lt;math&gt;\frac{d}{dt} \begin{bmatrix}
\mathbf{T}\\
\mathbf{N}\\
\mathbf{B}
\end{bmatrix}
= \|\mathbf{r}'(t)\|
\begin{bmatrix}
0&amp;\kappa&amp;0\\
-\kappa&amp;0&amp;\tau\\
0&amp;-\tau&amp;0
\end{bmatrix}
\begin{bmatrix}
\mathbf{T}\\
\mathbf{N}\\
\mathbf{B}
\end{bmatrix}.
&lt;/math&gt;

Explicit expressions for the curvature and torsion may be computed. For example,

:&lt;math&gt;\kappa = \frac{\|\mathbf{r}'(t)\times\mathbf{r}''(t)\|}{\|\mathbf{r}'(t)\|^3}.&lt;/math&gt;

The torsion may be expressed using a [[scalar triple product]] as follows,

:&lt;math&gt;\tau = \frac{[\mathbf{r}'(t),\mathbf{r}''(t),\mathbf{r}'''(t)]}{\|\mathbf{r}'(t)\times\mathbf{r}''(t)\|^2}.&lt;/math&gt;

==Special cases==
If the curvature is always zero then the curve will be a straight line. Here the vectors '''N''', '''B''' and the torsion are not well defined.

If the torsion is always zero then the curve will lie in a plane.

A curve may have nonzero curvature and zero torsion.  For example, the [[circle]] of radius ''R'' given by '''r'''(''t'')=(''R'' cos ''t'', ''R'' sin ''t'', 0) in the ''z''=0 plane has zero torsion and curvature equal to 1/''R''.  The converse, however, is false.  That is, a regular curve with nonzero torsion must have nonzero curvature.  (This is just the contrapositive of the fact that zero curvature implies zero torsion.)

A [[helix]] has constant curvature and constant torsion.

===[[Plane curves]]===

Given a curve contained on the ''x''-''y'' plane, its tangent vector '''T''' is also contained on that plane. Its binormal vector '''B''' can be naturally postulated to coincide with the normal ''to the plane'' (along the ''z'' axis). Finally, the curve normal can be found completing the right-handed system, '''N''' = '''B''' × '''T'''.&lt;ref&gt;[http://mathworld.wolfram.com/NormalVector.html]&lt;/ref&gt; This form is well-defined even when the curvature is zero; for example, the normal to a straight line on a plane will be perpendicular to the tangent, all co-planar.

==See also==
*[[Affine geometry of curves]]
*[[Differential geometry of curves]]
*[[Darboux frame]]
*[[Kinematics]]
*[[Moving frame]]

==Notes==
{{reflist}}

==References==
* {{citation|last1 = Crenshaw|first1=H.C.|last2=Edelstein-Keshet|first2=L.|title = Orientation by Helical Motion II.  Changing the direction of the axis of motion|journal=Bulletin of Mathematical Biology|volume=55|issue=1|year=1993|pages=213–230|doi=10.1016/s0092-8240(05)80070-9}}
* {{citation|title=Salas and Hille's Calculus &amp;mdash; One and Several Variables|edition=7th|first1=Garret|last1=Etgen|first3=Saturnino|last3=Salas|first2=Einar|last2=Hille|publisher=John Wiley &amp; Sons|year=1995|page=896}}
* {{citation|last=Frenet|first=F.|url=http://sites.mathdoc.fr/JMPA/PDF/JMPA_1852_1_17_A22_0.pdf | title=Sur les courbes à double courbure|publication-place=Thèse, Toulouse|year=1847}}. Abstract in ''Journal de Mathématiques Pures et Appliqueés'' '''17''', 1852.
* {{citation|last1=Goriely|first1=A.|last2=Robertson-Tessi|first2=M.|last3=Tabor|first3=M.|last4=Vandiver|first4=R.|year=2006|url=http://math.arizona.edu/~goriely/Papers/2006-biomat.pdf|contribution=Elastic growth models|title=BIOMAT-2006|publisher=Springer-Verlag|deadurl=yes|archiveurl=https://web.archive.org/web/20061229011619/http://math.arizona.edu/~goriely/Papers/2006-biomat.pdf|archivedate=2006-12-29|df=}}.
*{{citation | first = Phillip|last = Griffiths|authorlink=Phillip Griffiths|title = On Cartan's method of Lie groups and moving frames as applied to uniqueness and existence questions in differential geometry|journal =  [[Duke Mathematical Journal]] |volume = 41|issue = 4 | year = 1974 | pages = 775–814 | doi = 10.1215/S0012-7094-74-04180-5}}.
* {{citation|first=Heinrich|last=Guggenheimer|title=Differential Geometry|year=1977|publisher=Dover|isbn=0-486-63433-7}}
* {{citation|last=Hanson|first=A.J.|url=http://www.cs.indiana.edu/pub/techreports/TR407.pdf|title=Quaternion Frenet Frames: Making Optimal Tubes and Ribbons from Curves|year=2007|journal=Indiana University Technical Report}}
* {{citation|last1 = Iyer|first1=B.R.|last2=Vishveshwara|first2=C.V.|title = Frenet-Serret description of gyroscopic precession | journal = Phys. Rev.|series = D |volume = 48|pages = 5706–5720 | year = 1993|issue = 12 |doi=10.1103/physrevd.48.5706|arxiv = gr-qc/9310019 |bibcode = 1993PhRvD..48.5706I }}
* {{citation|first = Camille|last = Jordan|title = Sur la théorie des courbes dans l'espace à n dimensions|journal = C. R. Acad. Sci. Paris|volume=79|year=1874|pages=795–797}}
* {{Citation | last1=Kühnel | first1=Wolfgang | title=Differential geometry | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=Student Mathematical Library | isbn=978-0-8218-2656-0 | mr=1882174  | year=2002 | volume=16}}
* {{citation|last=Serret|first=J. A.|url=http://sites.mathdoc.fr/JMPA/PDF/JMPA_1851_1_16_A12_0.pdf|title=Sur quelques formules relatives à la théorie des courbes à double courbure|journal=Journal de Mathématiques Pures et Appliqueés|volume=16|year=1851}}.
* {{citation|first=Michael|last=Spivak|authorlink=Michael Spivak|title=A Comprehensive Introduction to Differential Geometry (Volume Two)|publisher=Publish or Perish, Inc.|year=1999}}.
* {{citation|first=Shlomo|last=Sternberg|title=Lectures on Differential Geometry|year=1964|publisher=Prentice-Hall}}
* {{citation|last=Struik|first=Dirk J.|title=Lectures on Classical Differential Geometry|publisher=Addison-Wesley|publication-place=Reading, Mass|year=1961}}.

==External links==
{{Commons category|Illustrations for curvature and torsion of curves|Graphical illustrations for curvature and torsion of curves}}
*[http://www.math.uni-muenster.de/u/urs.hartl/gifs/CurvatureAndTorsionOfCurves.mw Create your own animated illustrations of moving Frenet-Serret frames, curvature and torsion functions] ([[Maple (software)|Maple]]-Worksheet)
*[https://web.archive.org/web/20041015020304/http://www.mathcs.sjsu.edu/faculty/rucker/kaptaudoc/ktpaper.htm Rudy Rucker's KappaTau Paper].
*[http://www.math.byu.edu/~math302/content/learningmod/trihedron/trihedron.html Very nice visual representation for the trihedron]

{{curvature}}

{{DEFAULTSORT:Frenet-Serret formulas}}
[[Category:Differential geometry]]
[[Category:Multivariable calculus]]
[[Category:Curves]]
[[Category:Curvature (mathematics)]]</text>
      <sha1>1zzgnxyyxa79m42mdcvchtprvrn6g1s</sha1>
    </revision>
  </page>
  <page>
    <title>Graph state</title>
    <ns>0</ns>
    <id>4660507</id>
    <revision>
      <id>852308266</id>
      <parentid>852293398</parentid>
      <timestamp>2018-07-28T01:39:42Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5240">{{no footnotes|date=October 2015}}
In [[quantum computing]], a '''graph state''' is a special type of multi-[[qubit]] state that can be represented by a [[Graph (discrete mathematics)|graph]]. Each qubit is represented by a [[Vertex (graph theory)|vertex]] of the graph, and there is an edge between every interacting pair of qubits. In particular, they are a convenient way of representing certain types of [[Entanglement (graph measure)|entangled]] states.

Graph states are useful in [[quantum error-correcting code]]s, entanglement measurement and purification and for characterization of computational resources in measurement based quantum computing models.

== Formal definition ==

Given a graph ''G''&amp;nbsp;=&amp;nbsp;(''V'',&amp;nbsp;''E''), with the set of [[vertex (graph theory)|vertices]] ''V'' and the set of [[Glossary of graph theory#Basics|edges]] ''E'', the corresponding graph state is defined as

:&lt;math&gt;{\left| G \right\rangle} =\prod _{(a,b)\in E}U^{\{ a,b\} } {\left| + \right\rangle} ^{\otimes V}&lt;/math&gt;

where &lt;math&gt;{\left| + \right\rangle} = ({\left| 0 \right\rangle} +{\left| 1 \right\rangle} )/\sqrt{2}&lt;/math&gt; and the operator &lt;math&gt;U^{\{ a,b\} }&lt;/math&gt; is the [[Quantum gate#Controlled gates|controlled-''Z'']] interaction between the two vertices (qubits) ''a'', ''b''

:&lt;math&gt;  U^{\{ a,b\} } =\left[\begin{array}{cccc} {1} &amp; {0} &amp; {0} &amp; {0} \\ {0} &amp; {1} &amp; {0} &amp; {0} \\ {0} &amp; {0} &amp; {1} &amp; {0} \\ {0} &amp; {0} &amp; {0} &amp; {-1} \end{array}\right]&lt;/math&gt;

=== Alternative definition ===

An alternative and equivalent definition is the following.

Define an operator &lt;math&gt;S_v&lt;/math&gt; for each vertex ''v'' of ''G'':

:&lt;math&gt;S_v =\sigma _{x}^{(v)} \prod _{u \in N(v)} \sigma _{z}^{(u)}    &lt;/math&gt;

where &lt;math&gt;\sigma _{x,y,z}&lt;/math&gt; are the [[Pauli matrices]] and ''N''(''v'') is the set of vertices adjacent to ''v''.  The &lt;math&gt;S_v&lt;/math&gt; operators commute.  The graph state &lt;math&gt;{\left| G \right\rangle}&lt;/math&gt; is defined as the simultaneous &lt;math&gt;+1&lt;/math&gt;-eigenvalue eigenstate of the &lt;math&gt;\left|V\right|&lt;/math&gt; operators &lt;math&gt;\left\{S_v \right\}_{v \in V} &lt;/math&gt;: 

:&lt;math&gt;S_v {\left| G \right\rangle} = {\left| G \right\rangle}&lt;/math&gt;

== Examples ==

* If &lt;math&gt;G = P_3&lt;/math&gt; is a three-vertex [[Path_graph|path]], then the &lt;math&gt;S_v&lt;/math&gt; stabilizers are 

:&lt;math&gt;
\begin{align}
\sigma_x \otimes \sigma_z \otimes I, \\
\sigma_z \otimes \sigma_x \otimes \sigma_z, \\
I \otimes \sigma_z \otimes \sigma_x
\end{align}
&lt;/math&gt;

The corresponding quantum state is 

: &lt;math&gt;{\left| P_3 \right\rangle} = \frac{1}{\sqrt{8}}( 
{\left| 000 \right\rangle} 
+ {\left| 100 \right\rangle} 
+ {\left| 010 \right\rangle} 
- {\left| 110 \right\rangle} 
+ {\left| 001 \right\rangle} 
+ {\left| 101 \right\rangle} 
- {\left| 011 \right\rangle} 
+ {\left| 111 \right\rangle}
)&lt;/math&gt;

* If &lt;math&gt;G = K_3&lt;/math&gt; is a [[Triangle_graph|triangle]] on three vertices, then the &lt;math&gt;S_v&lt;/math&gt; stabilizers are 

:&lt;math&gt;
\begin{align}
\sigma_x \otimes \sigma_z \otimes \sigma_z, \\
\sigma_z \otimes \sigma_x \otimes \sigma_z, \\
\sigma_z \otimes \sigma_z \otimes \sigma_x
\end{align}
&lt;/math&gt;

The corresponding quantum state is 

: &lt;math&gt;{\left| K_3 \right\rangle} = \frac{1}{\sqrt{8}}( 
{\left| 000 \right\rangle} 
+ {\left| 100 \right\rangle} 
+ {\left| 010 \right\rangle} 
- {\left| 110 \right\rangle} 
+ {\left| 001 \right\rangle} 
- {\left| 101 \right\rangle} 
- {\left| 011 \right\rangle} 
- {\left| 111 \right\rangle} 
)&lt;/math&gt;

Observe that &lt;math&gt;{\left| P_3 \right\rangle}&lt;/math&gt; and &lt;math&gt;{\left| K_3 \right\rangle}&lt;/math&gt; are locally equivalent to each other, i.e., can be mapped to each other by applying one-qubit unitaries.  Indeed, switching &lt;math&gt;\sigma_x&lt;/math&gt; and &lt;math&gt;\sigma_y&lt;/math&gt; on the first and last qubits, while switching &lt;math&gt;\sigma_y&lt;/math&gt; and &lt;math&gt;\sigma_z&lt;/math&gt; on the middle
qubit, maps the stabilizer group of one into that of the other.  

More generally, two graph states are locally equivalent if and only if the corresponding graphs are related by a sequence of so-called ``local complementation" steps, as shown by Van den Nest et al. (2005).  

== See also ==
* [[Entanglement (graph measure)|Entanglement]]
* [[Cluster state]]

==References==
* {{cite journal |author1=M. Hein |author2=J. Eisert |author3=H. J. Briegel | title=Multiparty entanglement in graph states| journal=[[Physical Review A]] | year=2004| volume=69 | pages=062311 | doi=10.1103/PhysRevA.69.062311|arxiv=quant-ph/0307130|bibcode=2004PhRvA..69f2311H}}
* {{cite journal |author1=S. Anders |author2=H. J. Briegel | title=Fast simulation of stabilizer circuits using a graph-state representation| journal=[[Physical Review A]] | year=2006| volume=73 | pages=022334 | doi=10.1103/PhysRevA.73.022334  | arxiv=quant-ph/0504117| bibcode=2006PhRvA..73b2334A}}
* {{cite journal |author1=M. Van den Nest|author2=J. Dehaene|author3=B. De Moor | title=Local unitary versus local Clifford equivalence of stabilizer states| journal=[[Physical Review A]] | year=2005| volume=71 | pages=062323 | doi=10.1103/PhysRevA.71.062323  | arxiv=quant-ph/0411115| bibcode=2005PhRvA..71f2323V}}
*[http://xstructure.inr.ac.ru/x-bin/theme3.py?level=1&amp;index1=423009  Graph states on arxiv.org]

[[Category:Quantum information science]]


{{Comp-sci-stub}}</text>
      <sha1>h6d04fojs6370w0oioldlvptrvcrbp8</sha1>
    </revision>
  </page>
  <page>
    <title>HOMFLY polynomial</title>
    <ns>0</ns>
    <id>1039260</id>
    <revision>
      <id>822485987</id>
      <parentid>785753711</parentid>
      <timestamp>2018-01-26T17:14:12Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3903">In the [[mathematics|mathematical]] field of [[knot theory]], the '''HOMFLY polynomial''', sometimes called the '''HOMFLY-PT''' polynomial or the generalized [[Jones polynomial]], is a 2-variable [[knot polynomial]], i.e. a [[knot invariant]] in the form of a [[polynomial]] of variables ''m'' and ''l''.   

A central question in the [[knot theory|mathematical theory of knots]] is whether two [[knot diagram]]s represent the same knot. One tool used to answer such questions is a knot polynomial, which is computed from a diagram of the knot and can be shown to be an [[knot invariant|invariant of the knot]], i.e. diagrams representing the same knot have the same [[polynomial]]. The converse may not be true. The HOMFLY polynomial is one such invariant and it generalizes two polynomials previously discovered, the [[Alexander polynomial]] and the [[Jones polynomial]], both of which can be obtained by appropriate substitutions from HOMFLY. The HOMFLY polynomial is also a [[quantum invariant]].

The name  ''HOMFLY'' combines the initials of its co-discoverers: [[Jim Hoste]], [[Adrian Ocneanu]], [[Kenneth Millett]], [[Peter J. Freyd]], [[W. B. R. Lickorish]], and David N. Yetter.&lt;ref&gt;{{cite journal|authors= Freyd, P., Yetter, D., Hoste, J., Lickorish, W.B.R., Millett, K., and Ocneanu, A.|title = A New Polynomial Invariant of Knots and Links|journal = Bulletin of the American Mathematical Society|volume = 12|issue = 2|year = 1985|pages = 239–246|doi = 10.1090/S0273-0979-1985-15361-3}}&lt;/ref&gt; The addition of ''PT'' recognizes independent work  carried out by [[Józef H. Przytycki]] and Paweł Traczyk.

==Definition==
The polynomial is defined using [[skein relation]]s:

: &lt;math&gt;P( \mathrm{unknot} ) = 1,\,&lt;/math&gt;

: &lt;math&gt;\ell P(L_+) + \ell^{-1}P(L_-) + mP(L_0)=0,\,&lt;/math&gt;

where &lt;math&gt;L_+, L_-, L_0&lt;/math&gt; are links formed by crossing and smoothing changes on a local region of a link diagram, as indicated in the figure.  [[Image:Skein (HOMFLY).svg|200px|center]]

The HOMFLY polynomial of a link ''L'' that is a split union of two links &lt;math&gt;L_1&lt;/math&gt; and &lt;math&gt;L_2&lt;/math&gt; is given by

: &lt;math&gt;P(L) = \frac{-(\ell+\ell^{-1})}{m} P(L_1)P(L_2).&lt;/math&gt;

See the page on [[skein relation]] for an example of a computation using such relations.

==Other HOMFLY skein relations==
This polynomial can be obtained also using other skein relations:
: &lt;math&gt;\alpha P(L_+) - \alpha^{-1}P(L_-) = zP(L_0),\,&lt;/math&gt;
: &lt;math&gt;xP(L_+) + yP(L_-) + zP(L_0)=0,\,&lt;/math&gt;

==Main properties==
: &lt;math&gt;P(L_1 \# L_2)=P(L_1)P(L_2),\,&lt;/math&gt;, where # denotes the [[knot sum]]; thus the HOMFLY polynomial of a [[composite knot]] is the product of the HOMFLY polynomials of its components.

: &lt;math&gt;P_K(\ell,m)=P_{\text{Mirror Image}(K)}(\ell^{-1},m),\,&lt;/math&gt;, so the HOMFLY polynomial can often be used to distinguish between two knots of different [[chirality]]. However there exist chiral pairs of knots that have the same HOMFLY polynomial, e.g. knots 9&lt;sub&gt;42&lt;/sub&gt; and 10&lt;sub&gt;71&lt;/sub&gt;&lt;ref&gt;https://arxiv.org/pdf/hep-th/9401095.pdf&lt;/ref&gt;

The Jones polynomial, ''V''(''t''), and the Alexander polynomial, &lt;math&gt;\Delta(t)\,&lt;/math&gt; can be computed in terms of the HOMFLY polynomial (the version in &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;z&lt;/math&gt; variables) as follows:
: &lt;math&gt;V(t)=P(\alpha=t^{-1},z=t^{1/2}-t^{-1/2}),\,&lt;/math&gt;

: &lt;math&gt;\Delta(t)=P(\alpha=1,z=t^{1/2}-t^{-1/2}),\,&lt;/math&gt;

==References==
{{reflist}}

==Further reading==
* [[Louis Kauffman|Kauffman, L.H.]], "Formal knot theory", Princeton University Press, 1983.
* [[W. B. R. Lickorish|Lickorish, W.B.R.]] "An Introduction to Knot Theory". Springer. {{ISBN|0-387-98254-X}}.

==External links==
* {{springer|title=Jones-Conway polynomial|id=p/j130040}}
* {{MathWorld|HOMFLYPolynomial|HOMFLY Polynomial}}
* {{Knot Atlas|The HOMFLY-PT Polynomial}}

{{Knot theory}}

{{DEFAULTSORT:Homfly Polynomial}}
[[Category:Knot theory]]
[[Category:Polynomials]]</text>
      <sha1>4xwmu9cv8b2bu3l8mj40631745rx0ai</sha1>
    </revision>
  </page>
  <page>
    <title>Hadwiger number</title>
    <ns>0</ns>
    <id>1665366</id>
    <revision>
      <id>871634298</id>
      <parentid>705667774</parentid>
      <timestamp>2018-12-02T12:49:49Z</timestamp>
      <contributor>
        <username>Syp</username>
        <id>91052</id>
      </contributor>
      <minor/>
      <comment>/* Related concepts */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10963">[[File:Hadwiger conjecture.svg|thumb|upright=1.2|A graph with four connected subgraphs that, when contracted, form a complete graph. It has no five-vertex complete minor by [[Wagner's theorem]], so its Hadwiger number is exactly four.]]
In [[graph theory]], the '''Hadwiger number''' of an [[undirected graph]] ''G'' is the size of the largest [[complete graph]] that can be obtained by [[edge contraction|contracting edges]] of ''G''.
Equivalently, the Hadwiger number ''h''(''G'') is the largest number ''k'' for which the complete graph  ''K&lt;sub&gt;k&lt;/sub&gt;'' is a [[graph minor|minor]] of ''G'', a smaller graph obtained from ''G'' by edge contractions and vertex and edge deletions. The Hadwiger number is also known as the '''contraction clique number''' of ''G''{{sfnp|Bollobás|Catlin|Erdős|1980}} or the '''homomorphism degree''' of ''G''.{{sfnp|Halin|1976}} It is named after [[Hugo Hadwiger]], who introduced it in 1943 in conjunction with the [[Hadwiger conjecture (graph theory)|Hadwiger conjecture]], which states that the Hadwiger number is always at least as large as the [[chromatic number]] of&amp;nbsp;''G''.

The graphs that have Hadwiger number at most four have been characterized by {{harvtxt|Wagner|1937}}. The graphs with any finite bound on the Hadwiger number are sparse, and have small chromatic number. Determining the Hadwiger number of a graph is [[NP-hard]] but [[parameterized complexity|fixed-parameter tractable]].

==Graphs with small Hadwiger number==
A graph ''G'' has Hadwiger number at most two if and only if it is a [[tree (graph theory)|forest]], for a three-vertex complete minor can only be formed by contracting a [[cycle (graph theory)|cycle]] in&amp;nbsp;''G''.

A graph has Hadwiger number at most three if and only if its [[treewidth]] is at most two, which is true if and only if each of its [[biconnected component]]s is a [[series-parallel graph]].

[[File:Clique-sum.svg|thumb|upright=1.2|A clique-sum of two planar graphs and the Wagner graph, forming a larger graph with Hadwiger number four.]]
[[Wagner's theorem]], which characterizes the [[planar graph]]s by their [[Forbidden graph characterization|forbidden minors]], implies that the planar graphs have Hadwiger number at most four. In the same paper that proved this theorem, {{harvtxt|Wagner|1937}} also characterized the graphs with Hadwiger number at most four more precisely: they are graphs that can be formed by [[clique-sum]] operations that combine planar graphs with the eight-vertex [[Wagner graph]].

The graphs with Hadwiger number at most five include the [[apex graph]]s and the [[linkless embedding|linklessly embeddable graphs]], both of which have the complete graph ''K''&lt;sub&gt;6&lt;/sub&gt; among their forbidden minors.{{sfnp|Robertson|Seymour|Thomas|1993b}}

==Sparsity==
Every graph with ''n'' vertices and Hadwiger number ''k'' has 
O(''nk''&amp;nbsp;{{radic|log ''k''}}) edges. This bound is tight: for every ''k'', there exist graphs with Hadwiger number ''k'' that have Ω(''nk''&amp;nbsp;{{radic|log ''k''}}) edges.&lt;ref&gt;{{harvtxt|Kostochka|1984}}; {{harvtxt|Thomason|2001}}. The letters O and &amp;Omega; in these expressions invoke [[big O notation]].&lt;/ref&gt; If a graph ''G'' has Hadwiger number ''k'', then all of its subgraphs also have Hadwiger number at most ''k'', and it follows that ''G'' must have [[degeneracy (graph theory)|degeneracy]] O(''k''&amp;nbsp;{{radic|log ''k''}}). Therefore, the graphs with bounded Hadwiger number are [[sparse graph]]s.

==Coloring==
The [[Hadwiger conjecture (graph theory)|Hadwiger conjecture]] states that the Hadwiger number is always at least as large as the [[chromatic number]] of&amp;nbsp;''G''. That is, every graph with Hadwiger number ''k'' should have a [[graph coloring]] with at most ''k'' colors. The case ''k''&amp;nbsp;=&amp;nbsp;4 is equivalent (by Wagner's characterization of the graphs with this Hadwiger number) to the [[four color theorem]] on colorings of [[planar graph]]s, and the conjecture has also been proven for ''k''&amp;nbsp;≤&amp;nbsp;5, but remains unproven for larger values of&amp;nbsp;''k''.{{sfnp|Robertson|Seymour|Thomas|1993a}}

Because of their low degeneracy, the graphs with Hadwiger number at most ''k'' can be colored by a [[greedy coloring]] algorithm using O(''k''&amp;nbsp;{{radic|log ''k''}}) colors.

==Computational complexity==
Testing whether the Hadwiger number of a given graph is at least a given value ''k'' is [[NP-complete]],{{sfnp|Eppstein|2009}} from which it follows that determining the Hadwiger number is [[NP-hard]]. However, the problem is [[Parameterized complexity|fixed-parameter tractable]]: there is an algorithm for finding the largest clique minor in an amount of time that depends only polynomially on the size of the graph, but exponentially in ''h''(''G'').&lt;ref name="alw"&gt;{{harvtxt|Alon|Lingas|Wahlen|2007}}&lt;/ref&gt; Additionally, polynomial time algorithms can approximate the Hadwiger number significantly more accurately than the best polynomial-time approximation (assuming P&amp;nbsp;≠&amp;nbsp;NP) to the size of the largest [[clique (graph theory)|complete subgraph]].&lt;ref name="alw"/&gt;

==Related concepts==
The [[Complete coloring|achromatic number]] of a graph ''G'' is the size of the largest clique that can be formed by contracting a family of [[Independent set (graph theory)|independent set]]s in ''G''.

[[Uncountable]] clique minors in infinite graphs may be characterized in terms of [[Haven (graph theory)|havens]], which formalize the evasion strategies for certain [[pursuit-evasion]] games: if the Hadwiger number is uncountable, then it equals the largest order of a haven in the graph.{{sfnp|Robertson|Seymour|Thomas|1991}}

Every graph with Hadwiger number ''k'' has at most ''n''2&lt;sup&gt;O(''k''&amp;nbsp;log&amp;nbsp;log&amp;nbsp;''k'')&lt;/sup&gt; [[clique (graph theory)|cliques]] (complete subgraphs).{{sfnp|Fomin|Oum|Thilikos|2010}}

{{harvtxt|Halin|1976}} defines a class of graph parameters that he calls ''S''-functions, which include the Hadwiger number. These functions from graphs to integers are required to be zero on [[empty graph|graphs with no edges]], to be [[graph minor|minor-monotone]]&lt;ref&gt;If a function ''f'' is minor-monotone then if ''H'' is a minor of ''G'' then ''f(H) ≤ f(G)''.&lt;/ref&gt;, to increase by one when a new vertex is added that is adjacent to all previous vertices, and to take the larger value from the two subgraphs on either side of a [[clique (graph theory)|clique]] [[Vertex separator|separator]]. The set of all such functions forms a [[complete lattice]] under the operations of elementwise minimization and maximization. The bottom element in this lattice is the Hadwiger number, and the top element is the [[treewidth]].

==Notes==
{{reflist|colwidth=30em}}

==References==
{{refbegin|colwidth=30em}}
*{{citation | last1 = Alon | first1 = Noga | authorlink1 = Noga Alon | last2 = Lingas | first2 = Andrzej | last3 = Wahlen | first3 = Martin | title = Approximating the maximum clique minor and some subgraph homeomorphism problems | journal = Theoretical Computer Science | volume = 374 | issue = 1–3 | year = 2007 | pages = 149–158 | doi = 10.1016/j.tcs.2006.12.021 | url = http://www.math.tau.ac.il/~nogaa/PDFS/lingas7.pdf}}.
*{{citation | last1 = Bollobás | first1 = B. | authorlink1 = Béla Bollobás | last2 = Catlin | first2 = P. A. | last3 = Erdős | first3 = Paul | authorlink3 = Paul Erdős | title = Hadwiger's conjecture is true for almost every graph | journal = [[European Journal of Combinatorics]] | volume = 1 | year = 1980 | pages = 195–199 | url = http://www.renyi.hu/~p_erdos/1980-10.pdf | doi=10.1016/s0195-6698(80)80001-1}}.
*{{citation
 | last = Eppstein | first = David | authorlink = David Eppstein
 | arxiv = 0807.0007 | issue = 2
 | journal = [[Journal of Graph Algorithms and Applications]]
 | pages = 197–204
 | title = Finding large clique minors is hard
 | doi = 10.7155/jgaa.00183
 | volume = 13
 | year = 2009}}.
*{{citation
 | last1 = Fomin | first1 = Fedor V.
 | last2 = Oum | first2 = Sang-il
 | last3 = Thilikos | first3 = Dimitrios M.
 | arxiv = 0910.0079
 | doi = 10.1016/j.ejc.2010.05.003
 | issue = 7
 | journal = European Journal of Combinatorics
 | pages = 1617–1628
 | title = Rank-width and tree-width of ''H''-minor-free graphs
 | volume = 31
 | year = 2010}}.
*{{citation | last1=Hadwiger | first1=Hugo | author1-link=Hugo Hadwiger | title=Über eine Klassifikation der Streckenkomplexe | year=1943 | journal=Vierteljschr. Naturforsch. Ges. Zürich | volume=88 | pages=133–143}}.
*{{citation
 | last = Halin | first = Rudolf | author-link = Rudolf Halin
 | doi = 10.1007/BF01917434
 | issue = 1-2
 | journal = J. Geometry
 | mr = 0444522
 | pages = 171–186
 | title = ''S''-functions for graphs
 | volume = 8
 | year = 1976}}.
*{{citation | last = Kostochka | first = A. V. | title = Lower bound of the Hadwiger number of graphs by their average degree | journal = Combinatorica | volume = 4 | issue = 4 | pages = 307–316 | year = 1984 | doi = 10.1007/BF02579141}}.
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = Paul | author2-link = Paul Seymour (mathematician)
 | last3 = Thomas | first3 = Robin | author3-link = Robin Thomas (mathematician)
 | doi = 10.1016/0012-365X(91)90343-Z
 | issue = 1-3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | mr = 1141945
 | pages = 303–319
 | title = Excluding infinite minors
 | volume = 95
 | year = 1991}}.
*{{citation | last1=Robertson | first1=Neil | author1-link=Neil Robertson (mathematician) | last2=Seymour | first2=Paul | author2-link=Paul Seymour (mathematician) | last3=Thomas | first3=Robin | author3-link=Robin Thomas (mathematician) | title=Hadwiger's conjecture for K&lt;sub&gt;6&lt;/sub&gt;-free graphs | url=http://www.math.gatech.edu/~thomas/PAP/hadwiger.pdf | year=1993a | journal=[[Combinatorica]] | volume=13 | pages=279–361 | doi=10.1007/BF01202354 | issue=3}}.
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = P. D. | author2-link = Paul Seymour (mathematician)
 | last3 = Thomas | first3 = Robin | author3-link = Robin Thomas (mathematician)
 | doi = 10.1090/S0273-0979-1993-00335-5
 | arxiv = math/9301216 |mr=1164063
 | issue = 1
 | journal = Bulletin of the American Mathematical Society
 | pages = 84–89
 | title = Linkless embeddings of graphs in 3-space
 | volume = 28
 | year = 1993b}}.
*{{citation
 | last = Thomason | first = Andrew
 | doi = 10.1006/jctb.2000.2013
 | issue = 2
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | pages = 318–338
 | title = The extremal function for complete minors
 | volume = 81
 | year = 2001}}.
*{{citation|first=K.|last=Wagner|authorlink=Klaus Wagner|year=1937|title=Über eine Eigenschaft der ebenen Komplexe|journal=Math. Ann.|volume=114|pages=570–590|doi=10.1007/BF01594196}}.
{{refend}}

[[Category:Graph invariants]]
[[Category:Graph minor theory]]</text>
      <sha1>p0ulog96wcje66st1q05wpbr6p06x51</sha1>
    </revision>
  </page>
  <page>
    <title>Hausdorff completion</title>
    <ns>0</ns>
    <id>35953535</id>
    <revision>
      <id>626464943</id>
      <parentid>532071372</parentid>
      <timestamp>2014-09-21T11:24:51Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1015">
In algebra, the '''Hausdorff completion''' &lt;math&gt;\widehat{G}&lt;/math&gt; of a [[group (mathematics)|group]] ''G'' with [[filtration (mathematics)|filtration]] &lt;math&gt;G_n&lt;/math&gt; is the [[inverse limit]] &lt;math&gt;\varprojlim G/G_n&lt;/math&gt; of the [[discrete group]] &lt;math&gt;G/G_n&lt;/math&gt;.  A basic example is a [[profinite group|profinite completion]].  The image of the canonical map &lt;math&gt;G \to \widehat{G}&lt;/math&gt; is a [[Hausdorff space|Hausdorff]] [[topological group]] and its [[kernel (algebra)|kernel]] is the intersection of all &lt;math&gt;G_n&lt;/math&gt;: i.e., the [[closure (topology)|closure]] of the identity element.  The canonical [[homomorphism]] &lt;math&gt;\operatorname{gr}(G) \to \operatorname{gr}(\widehat{G})&lt;/math&gt; is an [[isomorphism]], where &lt;math&gt;\operatorname{gr}(G)&lt;/math&gt; is a [[associated graded module|graded module associated]] to the filtration.

The concept is named after [[Felix Hausdorff]].

== References ==
*[[Nicolas Bourbaki]], ''Commutative algebra''



[[Category:Commutative algebra]]


{{algebra-stub}}</text>
      <sha1>6ffpobvbq8lacw9m9o3hhyuyz2ddbxt</sha1>
    </revision>
  </page>
  <page>
    <title>József Solymosi</title>
    <ns>0</ns>
    <id>58278355</id>
    <revision>
      <id>861379494</id>
      <parentid>859284281</parentid>
      <timestamp>2018-09-27T00:34:12Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8817">[[File:SolymosiJozsef2017 MFO21679.jpg|thumb|József Solymosi at a Discrete Geometry Workshop, April 2017 in [[Mathematical Research Institute of Oberwolfach|Oberwolfach]].]]
'''József Solymosi''' is a Hungarian-Canadian mathematician and a professor of mathematics at the [[University of British Columbia]]. His main research interests are [[arithmetic combinatorics]], [[discrete geometry]], [[graph theory]], and [[combinatorial number theory]].{{r|cv}}

==Education and career==
Solymosi earned his master’s degree in 1999 under the supervision of László Székely from the [[Eötvös Loránd University]]{{r|szekstud}} and his Ph.D. in 2001 at [[ETH Zurich|ETH Zürich]] under the supervision of [[Emo Welzl]]. His doctoral dissertation was ''Ramsey-Type Results on Planar Geometric Objects''.{{r|mgp}}

From 2001 to 2003 he was S. E. Warschawski Assistant Professor of Mathematics at the [[University of California, San Diego]]. He joined the faculty of the University of British Columbia in 2002.{{r|cv}}

He was [[editor in chief]] of the ''[[Electronic Journal of Combinatorics]]''{{r|ejc}} from 2013 to 2015.

==Contributions==
Solymosi was the first online contributor to the first [[Polymath Project]], set by [[Timothy Gowers]] to find improvements to the [[Hales–Jewett theorem]].{{r|nielsen}}

One of his theorems states that if a finite set of points in the [[Euclidean plane]] has every pair of points at an integer distance from each other, then
the set must have a [[diameter]] (largest distance) that is linear in the number of points. This result is connected to the [[Erdős–Anning theorem]], according to which an infinite set of points with integer distances must lie on one line.{{r|gis}}{{ran|ID}} In connection with the related [[Erdős–Ulam problem]], on the existence of dense subsets of the plane for which all distances are rational numbers, Solymosi and de Zeeuw proved that every infinite rational-distance set must either be dense in the [[Zariski topology]] or it must have all but finitely many of its points on a single line or circle.{{r|erdosulam}}{{ran|EU}}

With [[Terence Tao]], Solymosi proved a bound of &lt;math&gt;(mn)^{2/3+\varepsilon}&lt;/math&gt; on the number of incidences between &lt;math&gt;n&lt;/math&gt; points and &lt;math&gt;m&lt;/math&gt; affine subspaces of any finite-dimensional Euclidean space, whenever each pair of subspaces has at most one point of intersection. This generalizes the [[Szemerédi–Trotter theorem]] on points and lines in the Euclidean plane, and because of this the exponent of &lt;math&gt;2/3&lt;/math&gt; cannot be improved. Their theorem solves (up to the &lt;math&gt;\varepsilon&lt;/math&gt; in the exponent) a conjecture of Toth, and was inspired by an analogue of the Szemerédi–Trotter theorem for lines in the [[complex plane]].{{r|guth|ithd}}{{ran|HD}}

He has also contributed improved bounds for the [[Erdős–Szemerédi theorem]], showing that every set of real numbers has either a large set of pairwise sums or a large set of pairwise products,{{r|sumprod}}{{ran|ME}} and for the [[Erdős distinct distances problem]], showing that every set of points in the plane has many different pairwise distances.{{r|distdist}}{{ran|DD}}

==Recognition==
In 2006, Solymosi received a [[Sloan Research Fellowship]]{{r|sloan}} and in 2008 he was awarded the [[Aisenstadt Prize|André Aisenstadt Mathematics Prize]].{{r|aisenstadt}} In 2012 he was named a doctor of the [[Hungarian Academy of Science]].{{r|mtadoc}}

==Selected publications==
{{rma|DD|tw=2em|{{citation
 | last1 = Solymosi | first1 = J.
 | last2 = Tóth | first2 = Cs. D.
 | doi = 10.1007/s00454-001-0009-z
 | issue = 4
 | journal = Discrete &amp; Computational Geometry
 | mr = 1838423
 | pages = 629–634
 | title = Distinct distances in the plane
 | volume = 25
 | year = 2001}}}}

{{rma|ID|tw=2em|{{citation
 | last = Solymosi | first = József
 | doi = 10.1007/s00454-003-0014-7
 | issue = 2
 | journal = [[Discrete &amp; Computational Geometry]]
 | mr = 2007970
 | pages = 337–342
 | title = Note on integral distances
 | volume = 30
 | year = 2003}}}}

{{rma|ME|tw=2em|{{citation
 | last = Solymosi | first = József
 | doi = 10.1016/j.aim.2009.04.006
 | issue = 2
 | journal = [[Advances in Mathematics]]
 | mr = 2538014
 | pages = 402–408
 | title = Bounding multiplicative energy by the sumset
 | volume = 222
 | year = 2009}}}}

{{rma|EU|tw=2em|{{citation
 | last1 = Solymosi | first1 = Jozsef
 | last2 = de Zeeuw | first2 = Frank
 | doi = 10.1007/s00454-009-9179-x
 | issue = 2
 | journal = [[Discrete &amp; Computational Geometry]]
 | mr = 2579704
 | pages = 393–401
 | title = On a question of Erdős and Ulam
 | volume = 43
 | year = 2010}}}}

{{rma|HD|tw=2em|{{citation
 | last1 = Solymosi | first1 = József
 | last2 = Tao | first2 = Terence | author2-link = Terence Tao
 | doi = 10.1007/s00454-012-9420-x
 | issue = 2
 | journal = [[Discrete &amp; Computational Geometry]]
 | mr = 2946447
 | pages = 255–280
 | title = An incidence theorem in higher dimensions
 | volume = 48
 | year = 2012}}}}

==References==
{{reflist|refs=

&lt;ref name=aisenstadt&gt;{{citation|url=http://www.ams.org/notices/200802/tx080200264p.pdf|journal=[[Notices of the American Mathematical Society]]|department=Mathematics People|title=Solymosi and Taylor Awarded Aisenstadt Prize|page=266|volume=55|issue=2|date=February 2008}}&lt;/ref&gt;

&lt;ref name=cv&gt;{{citation|url=http://www.math.ubc.ca/~solymosi/CVshort.html|title=Short curriculum vitae|accessdate=2018-09-08}}&lt;/ref&gt;

&lt;ref name=distdist&gt;{{harvtxt|Guth|2016|page=83}}&lt;/ref&gt;

&lt;ref name=ejc&gt;{{citation|url=http://www.combinatorics.org/ojs/index.php/eljc/about/editorialTeam|title=Editorial team|journal=[[Electronic Journal of Combinatorics]]|accessdate=2018-09-08}}&lt;/ref&gt;

&lt;ref name=erdosulam&gt;{{citation|url=https://terrytao.wordpress.com/2014/12/20/the-erdos-ulam-problem-varieties-of-general-type-and-the-bombieri-lang-conjecture/|first=Terence|last=Tao|authorlink=Terence Tao|date=December 20, 2014|work=What's New|title=The Erdős–Ulam problem, varieties of general type, and the Bombieri–Lang conjecture}}&lt;/ref&gt;

&lt;ref name=gis&gt;{{citation
 | last1 = Garibaldi | first1 = Julia
 | last2 = Iosevich | first2 = Alex
 | last3 = Senger | first3 = Steven
 | isbn = 978-0-8218-5281-1
 | mr = 2721878
 | page = 16
 | publisher = American Mathematical Society, Providence, RI
 | series = Student Mathematical Library
 | title = The Erdős Distance Problem
 | url = https://books.google.com/books?id=SzCIAwAAQBAJ&amp;pg=PA16
 | volume = 56
 | year = 2011}}&lt;/ref&gt;

&lt;ref name=guth&gt;{{citation
 | last = Guth | first = Larry
 | isbn = 978-1-4704-2890-7
 | mr = 3495952
 | pages = 89–90
 | publisher = American Mathematical Society, Providence, RI
 | series = University Lecture Series
 | title = Polynomial Methods in Combinatorics
 | url = https://books.google.com/books?id=t9ZTDAAAQBAJ&amp;pg=PA89
 | volume = 64
 | year = 2016}}&lt;/ref&gt;

&lt;ref name=ithd&gt;{{citation|url=https://terrytao.wordpress.com/2011/03/17/an-incidence-theorem-in-higher-dimensions/|first=Terence|last=Tao|authorlink=Terence Tao|date=March 17, 2011|work=What's New|title=An incidence theorem in higher dimensions}}&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=54429}}&lt;/ref&gt;

&lt;ref name=mtadoc&gt;{{citation|url=http://mta.hu/koztestuleti_tagok?PersonId=22844|title=Solymosi József|work=Az MTA köztestületének tagjai [Members of the public body of MTA]|language=Hungarian|accessdate=2018-09-08}}&lt;/ref&gt;

&lt;ref name=nielsen&gt;{{citation|title=Reinventing Discovery: The New Era of Networked Science|first=Michael|last=Nielsen|publisher=Princeton University Press|year=2012|isbn=9780691148908|page=1|url=https://books.google.com/books?id=afqfFW8WV9cC&amp;pg=PA1}}&lt;/ref&gt;

&lt;ref name=sloan&gt;{{citation|url=https://sloan.org/storage/app/media/files/annual_reports/2006_annual_report.pdf|year=2006|title=Annual Report|publisher=Alfred P. Sloan Foundation|accessdate=2018-09-08}}&lt;/ref&gt;

&lt;ref name=sumprod&gt;{{citation|url=https://terrytao.wordpress.com/2008/06/17/the-sum-product-phenomenon-in-arbitrary-rings/|first=Terence|last=Tao|authorlink=Terence Tao|date=June 17, 2008|work=What's New|title=The sum-product phenomenon in arbitrary rings}}&lt;/ref&gt;

&lt;ref name=szekstud&gt;{{citation|url=http://people.math.sc.edu/laszlo/students.html|title=László Székely's Students|publisher=University of South Carolina|accessdate=2018-09-08}}&lt;/ref&gt;

}}

==External links==
*[http://www.math.ubc.ca/~solymosi/ Home page]
*{{Google Scholar id|-t18JkQAAAAJ}}

{{authority control}}

{{DEFAULTSORT:Solymosi, Jozsef}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:Canadian mathematicians]]
[[Category:Hungarian mathematicians]]
[[Category:Eötvös Loránd University alumni]]
[[Category:ETH Zurich alumni]]
[[Category:University of British Columbia faculty]]
[[Category:Combinatorialists]]
[[Category:Graph theorists]]</text>
      <sha1>8a7ox6pqqlfm0504vzbsxywf3sc7o1l</sha1>
    </revision>
  </page>
  <page>
    <title>Key ceremony</title>
    <ns>0</ns>
    <id>15314230</id>
    <revision>
      <id>791522154</id>
      <parentid>752274949</parentid>
      <timestamp>2017-07-20T20:29:19Z</timestamp>
      <contributor>
        <username>Nitpicking polish</username>
        <id>17980321</id>
      </contributor>
      <minor/>
      <comment>General [[WP:MOS|formatting]] by [[User:Ohconfucius/script|script]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4276">{{Multiple issues|
{{Unreferenced|date=January 2008}}
{{cite check|Reference to SAS70|date=March 2014}}
}}
{{expert needed|Cryptography|date=July 2016}}

In [[public-key cryptography]] and [[computer security]], a '''root key ceremony''' is a procedure where a unique pair of public and private root keys is generated.  Depending on the certificate policy, the generation of the root keys may require notarization, legal representation, witnesses and "key holders" to be present, as the information on the system is a responsibility of the parties.  A commonly recognized best practice is to follow the [[Statement on Auditing Standards No. 70: Service Organizations|SAS 70]] standard for root key ceremonies.

At the heart of every [[certificate authority]] (CA) is at least one root key or root certificate and usually at least one intermediate root certificate. A root key is a term for a unique passcode that must be generated for secure server interaction with a protective network, usually called the root zone. Prompts for information from this zone can be done through a server. The keys and certificates mentioned are the credentials and safe guards for the system.  These digital certificates are made from a public and a [[private key]].

==Examples==

'''Example A: These passcodes are used for Strong identification and non-repudiation for email and web access'''

Unless the information being accessed or transmitted is valued in terms of millions of dollars, it is probably sufficient that the root key ceremony be conducted within the security of the vendor's laboratory.  The customer may opt to have the root key stored in a [[hardware security module]], but in most cases, the safe storage of the root Key on a CD or hard disk is sufficient.  The root key is never stored on the CA server.

'''Example B: [[Machine Readable Travel Document]] [MRTD] ID Card or e Passport'''

This type of environment requires much higher security.  When conducting the root key ceremony, the government or organization will require rigorous security checks to be conducted on all personnel in attendance.  Those that are normally required to attend the key ceremony will include a minimum of two administrators from the organization, two signatories from the organization, one lawyer, a notary, and two video camera operators, in addition to the CA software vendor's own technical team.

Example A and B are at opposite ends of the security spectrum and no two environments are the same. Depending on the level of protection required, different levels of security will be used.

==Overview==

The actual root key-pair generation is normally conducted in a secure vault that has no communication or contact with the outside world other than a single telephone line or intercom. Once the vault is secured, all personnel present must prove their identity using at least two legally recognized forms of identification. Every person present, every transaction and every event is logged by the lawyer in a root key ceremony log book and each page is notarized by the notary. From the moment the vault door is closed until it is re-opened, everything is also video recorded. The lawyer and the organization's two signatories must sign the recording and it too is then notarized.

Finally, as part of the above process, the root key is broken into as many as twenty-one parts and each individual part is secured in its own safe for which there is a key and a numerical lock. The keys are distributed to as many as twenty-one people and the numerical code is distributed to another twenty-one people.

==Providers==

The CA vendors and organisations that would implement projects of this nature where conducting a root key ceremony would be a central component of their service would be organisations like, for example; [[RSA (security firm)|RSA]], [[VeriSign]] and Digi-Sign.

==See also==
* [[Statement on Auditing Standards No. 70: Service Organizations|SAS 70]]
* [[Certificate authority]]
* [[Public-key cryptography]]

==External links==
* [https://www.iana.org/dnssec/ceremonies/22 Summary of events at DNSSEC KSK Ceremony 22], which took place 13 August 2015 at the [[ICANN]] Key Management Facility, El Segundo, CA, USA

[[Category:Cryptography]]
[[Category:Key management]]</text>
      <sha1>m7bdubbmkx06rm1je1bl8vr27kocqsd</sha1>
    </revision>
  </page>
  <page>
    <title>Kharitonov region</title>
    <ns>0</ns>
    <id>8788855</id>
    <revision>
      <id>601728148</id>
      <parentid>536843229</parentid>
      <timestamp>2014-03-28T23:15:01Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>[[WP:CHECKWIKI]] error fixes + other fixes using [[Project:AWB|AWB]] (10065)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="988">{{multiple issues|
{{Orphan|date=February 2013}}
{{Expert-subject|Mathematics|date=February 2009}}
}}

A '''Kharitonov region''' is a concept in [[mathematics]].  It arises in the study of the [[Stable polynomial|stability of polynomials]].

Let &lt;math&gt;D&lt;/math&gt; be a [[simply-connected set]] in the [[complex plane]] and let &lt;math&gt;P&lt;/math&gt; be the polynomial family.

&lt;math&gt;D&lt;/math&gt; is said to be a '''Kharitonov region''' if

:&lt;math&gt;V_T^n(V_S^n)&lt;/math&gt;

is a subset of &lt;math&gt;P.&lt;/math&gt; Here, &lt;math&gt;V_T^n&lt;/math&gt;  denotes the set of all [[vertex polynomial]]s of complex interval polynomials &lt;math&gt;(T^n)&lt;/math&gt; and &lt;math&gt;V_S^n&lt;/math&gt; denotes the set of all vertex polynomials of real interval polynomials &lt;math&gt;(S^n).&lt;/math&gt;

==See also==
*[[Kharitonov's theorem]]

==References==
{{reflist}}
* Y C Soh and Y K Foo (1991), “Kharitonov Regions: It Suffices to Check a Subset of Vertex Polynomials”, IEEE Trans. on Aut. Cont., 36, 1102 – 1105.

[[Category:Polynomials]]


{{algebra-stub}}</text>
      <sha1>9cdrulsdnrcrdygcu9wcpe4fap6pqnv</sha1>
    </revision>
  </page>
  <page>
    <title>List of algorithm general topics</title>
    <ns>0</ns>
    <id>632487</id>
    <revision>
      <id>838275194</id>
      <parentid>794788725</parentid>
      <timestamp>2018-04-26T00:57:10Z</timestamp>
      <contributor>
        <username>Allforrous</username>
        <id>12120664</id>
      </contributor>
      <comment>new key for [[Category:Algorithms]]: "*" using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1458">This is a '''list of [[algorithm]] general topics'''. 

* [[Analysis of algorithms]]
* [[Ant colony algorithm]]
* [[Approximation algorithm]]
* [[Best and worst cases]]
* [[Big O notation]]
* [[Combinatorial search]]
* [[Competitive analysis (online algorithm)|Competitive analysis]]
* [[Computability theory]]
* [[Computational complexity theory]]
* [[Embarrassingly parallel|Embarrassingly parallel problem]]
* [[Emergent algorithm]]
* [[Evolutionary algorithm]]
* [[Fast Fourier transform]]
* [[Genetic algorithm]]
* [[Graph exploration algorithm]]
* [[Heuristic]]
* [[Hill climbing]]
* [[Implementation]]
* [[Las Vegas algorithm]]
* [[Lock-free and wait-free algorithms]]
* [[Monte Carlo algorithm]]
* [[Numerical analysis]]
* [[Online algorithm]]
* [[Polynomial time approximation scheme]]
* [[Problem size]]
* [[Pseudorandom number generator]]
* [[Quantum algorithm]]
* [[Random-restart hill climbing]]
* [[Randomized algorithm]]
* [[Running time]]
* [[Sorting algorithm]]
* [[Search algorithm]]
* [[Stable algorithm (disambiguation)]]
* [[Super-recursive algorithm]]
* [[Tree search algorithm]]

==See also==
* [[List of algorithms]] for specific algorithms
* [[List of computability and complexity topics]] for more abstract theory
* [[List of complexity classes]], [[complexity class]]
* [[List of data structures]].

{{DEFAULTSORT:List Of Algorithm General Topics}}
[[Category:Mathematics-related lists|Algorithm general]]
[[Category:Algorithms|*]]</text>
      <sha1>raj23eew6qim806umuue0o8feff0no9</sha1>
    </revision>
  </page>
  <page>
    <title>Logic alphabet</title>
    <ns>0</ns>
    <id>11641180</id>
    <revision>
      <id>787895463</id>
      <parentid>760895531</parentid>
      <timestamp>2017-06-28T06:25:25Z</timestamp>
      <contributor>
        <ip>185.33.138.198</ip>
      </contributor>
      <comment>/* Content */ -Dr</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10278">The '''logic alphabet''', also called the X-stem Logic Alphabet (XLA), constitutes an iconic set of [[Symbol (formal)|symbol]]s that systematically represents the sixteen possible binary [[truth function]]s of [[logic]]. The logic alphabet was developed by [[Shea Zellweger]]. The major emphasis of his iconic "logic alphabet" is to provide a more cognitively ergonomic notation for logic. Zellweger's visually iconic system more readily reveals, to the novice and expert alike, the underlying [[symmetry]] relationships and [[geometric]] properties of the sixteen binary connectives within [[Boolean algebra (logic)|Boolean algebra]].

==Truth functions==
[[Truth function]]s are functions from [[sequence]]s of [[truth value]]s to truth values. A [[unary function|unary]] truth function, for example, takes a single truth value and maps it onto another truth value. Similarly, a [[binary function|binary]] truth function maps [[ordered pair]]s of truth values onto truth values, while a [[arity|ternary]] truth function maps ordered triples of truth values onto truth values, and so on.

In the unary case, there are two possible inputs, viz. '''T''' and '''F''', and thus four possible unary truth functions: one mapping '''T''' to '''T''' and '''F''' to '''F''', one mapping '''T''' to '''F''' and '''F''' to '''F''', one mapping '''T''' to '''T''' and '''F''' to '''T''', and finally one mapping '''T''' to '''F''' and '''F''' to '''T''', this last one corresponding to the familiar operation of [[logical negation]]. In the form of a table, the four unary truth functions may be represented as follows.

{| border="1" class="wikitable" style="text-align:center;"
|+ Unary truth functions
! style="width:40px;background:#aaaaaa;" | p
! style="width:40px" | p
! style="width:40px" | F
! style="width:40px" | T
! style="width:40px" | ~p
|-
| T || T || F || T || F
|-
| F || F || F || T || T
|}

In the binary case, there are four possible inputs, viz. ('''T''','''T'''), ('''T''','''F'''), ('''F''','''T'''), and ('''F''','''F'''), thus yielding sixteen possible binary truth functions. Quite generally, for any number ''n'', there are &lt;math&gt;2^{2^n}&lt;/math&gt; possible ''n''-[[arity|ary]] truth functions. The sixteen possible binary truth functions are listed in the table below.

{| border="1" class="wikitable" style="text-align:center;"
|+ Binary truth functions
! style="width:35px;background:#aaaaaa;" | p
! style="width:35px;background:#aaaaaa;" | q
! style="width:35px" | T
! style="width:35px" | NAND
! style="width:35px" | →
! style="width:35px" | NOT p
! style="width:35px" | ←
! style="width:35px" | NOT q
! style="width:35px" | ↔
! style="width:35px" | NOR
! style="width:35px" | OR
! style="width:35px" | XOR
! style="width:35px" | q
! style="width:35px" | NOT ←
! style="width:35px" | p
! style="width:35px" | NOT →
! style="width:35px" | AND
! style="width:35px" | F
|-
| T || T || T || F || T || F || T || F || T || F || T || F || T || F || T || F || T || F
|-
| T || F || T || T || F || F || T || T || F || F || T || T || F || F || T || T || F || F
|-
| F || T || T || T || T || T || F || F || F || F || T || T || T || T || F || F || F || F
|-
| F || F || T || T || T || T || T || T || T || T || F || F || F || F || F || F || F || F
|}

==Content==
[[Shea Zellweger|Zellweger's]] logic alphabet offers a visually systematic way of representing each of the sixteen binary truth functions. The idea behind the logic alphabet is to first represent the sixteen binary truth functions in the form of a [[square matrix]] rather than the more familiar tabular format seen in the table above, and then to assign a [[letter (alphabet)|letter]] shape to each of these matrices. Letter shapes are derived from the distribution of '''T'''s in the matrix. When drawing a logic symbol, one passes through each square with assigned '''F''' values while stopping in a square with assigned '''T''' values. In the extreme examples, the symbol for [[tautology (logic)|tautology]] is a X (stops in all four squares), while the symbol for [[contradiction]] is an O (passing through all squares without stopping). The square matrix corresponding to each binary truth function, as well as its corresponding letter shape, are displayed in the table below.

&lt;!-- Deleted image removed: [[Image:Zellweger-LogicGarnet.jpg|thumb|200px]] --&gt;
{| border="1" class="wikitable" style="text-align:center;"
|+ Symbols
! Conventional symbol
! Matrix
! Logic alphabet shape
|-
| T                           || [[Image:LAlphabet T table.jpg|70px]]      || [[Image:LAlphabet T.jpg|45px]]
|-
| [[Sheffer stroke|NAND]]     || [[Image:LAlphabet NAND table.jpg|70px]]   || [[Image:LAlphabet NAND.jpg|45px]]
|-
| [[Material conditional|→]]  || [[Image:LAlphabet IFTHEN table.jpg|70px]] || [[Image:LAlphabet IFTHEN.jpg|45px]]
|-
| NOT p                       || [[Image:LAlphabet NOTP table.jpg|70px]]   || [[Image:LAlphabet NOTP.jpg|45px]]
|-
| ←                           || [[Image:LAlphabet FI table.jpg|70px]]     || [[Image:LAlphabet FI.jpg|45px]]
|-
| NOT q                       || [[Image:LAlphabet NOTQ table.jpg|70px]]   || [[Image:LAlphabet NOTQ.jpg|45px]]
|-
| [[Biconditional|↔]]         || [[Image:LAlphabet IFF table.jpg|70px]]    || [[Image:LAlphabet IFF.jpg|45px]]
|-
| [[Logical NOR|NOR]]         || [[Image:LAlphabet NOR table.jpg|70px]]    || [[Image:LAlphabet NOR.jpg|45px]]
|-
| [[logical disjunction|OR]]  || [[Image:LAlphabet OR table.jpg|70px]]     || [[Image:LAlphabet OR.jpg|45px]]
|-
| [[XOR]]                     || [[Image:LAlphabet XOR table.jpg|70px]]    || [[Image:LAlphabet XOR.jpg|45px]]
|-
| q                           || [[Image:LAlphabet Q table.jpg|70px]]      || [[Image:LAlphabet Q.jpg|45px]]
|-
| NOT ←                       || [[Image:LAlphabet NFI table.jpg|70px]]    || [[Image:LAlphabet NFI.jpg|45px]]
|-
| p                           || [[Image:LAlphabet P table.jpg|70px]]      || [[Image:LAlphabet P.jpg|45px]]
|-
| NOT →                       || [[Image:LAlphabet NIF table.jpg|70px]]    || [[Image:LAlphabet NIF.jpg|45px]]
|-
| [[Logical conjunction|AND]] || [[Image:LAlphabet AND table.jpg|70px]]    || [[Image:LAlphabet AND.jpg|45px]]
|-
| F                           || [[Image:LAlphabet F table.jpg|70px]]      || [[Image:LAlphabet F.jpg|45px]]
|}

==Significance==
The interest of the logic alphabet lies in its [[aesthetic]], symmetric, and geometric qualities. These qualities combine to allow an individual to more easily, rapidly and visually manipulate the relationships between entire truth tables. A logic operation performed on a two dimensional logic alphabet connective, with its geometric qualities, produces a symmetry transformation.  When a symmetry transformation occurs, each input symbol, without any further thought, immediately changes into the correct output symbol. For example, by reflecting the symbol for [[Sheffer stroke|NAND]] (viz. 'h') across the vertical axis we produce the symbol for ←, whereas by reflecting it across the horizontal axis we produce the symbol for [[Material conditional|→]], and by reflecting it across both the horizontal and vertical axes we produce the symbol for [[logical disjunction|∨]]. Similar symmetry transformations can be obtained by operating upon the other symbols.

In effect, the X-stem Logic Alphabet is derived from three disciplines that have been stacked and combined: (1) mathematics, (2) logic, and (3) semiotics. This happens because, in keeping with the mathelogical semiotics, the connectives have been custom designed in the form of geometric letter shapes that serve as iconic replicas of their corresponding square-framed truth tables. Logic cannot do it alone.  Logic is sandwiched between mathematics and semiotics. Indeed, [[Shea Zellweger|Zellweger]] has constructed intriguing structures involving the symbols of the logic alphabet on the basis of these symmetries ([http://www.logic-alphabet.net/images/logicbug_2345_2.jpg] [http://www.logic-alphabet.net/images/clockcompass_2353_2.jpg]). The considerable aesthetic appeal of the logic alphabet has led to exhibitions of [[Shea Zellweger|Zellweger's]] work at the [[Museum of Jurassic Technology]] in [[Los Angeles]], among other places.

The value of the logic alphabet lies in its use as a visually simpler pedagogical tool than the traditional system for logic notation. The logic alphabet eases the introduction to the fundamentals of logic, especially for children, at much earlier stages of cognitive development. Because the logic notation system, in current use today, is so deeply embedded in our computer culture, the "logic alphabets" adoption and value by the field of [[logic]] itself, at this juncture, is questionable. Additionally, systems of [[natural deduction]], for example, generally require introduction and elimination rules for each connective, meaning that the use of all sixteen binary connectives would result in a highly complex [[Mathematical proof|proof]] system. Various subsets of the sixteen binary connectives (e.g., {∨,&amp;,→,~}, {∨,~}, {&amp;, ~}, {→,~}) are themselves [[functional completeness|functionally complete]] in that they suffice to define the remaining connectives. In fact, both [[Sheffer stroke|NAND]] and [[Logical NOR|NOR]] are [[sole sufficient operator]]s, meaning that the remaining connectives can all be defined solely in terms of either of them. Nonetheless, the logic alphabet’s 2-dimensional geometric letter shapes along with its group symmetry properties can help ease the learning curve for children and adult students alike, as they become familiar with the interrelations and operations on all 16 binary connectives.  Giving children and students this advantage is a decided gain.

==See also==
* [[Polish notation]]
* [[Propositional logic]]
* [[Boolean function]]
* [[Boolean algebra (logic)]]
* [[Logic gate]]

==External links==
* [http://www.logic-alphabet.net/ Page dedicated to Zellweger's logic alphabet]
* Exhibition in a [[Museum of Jurassic Technology|small museum]]: [https://www.flickr.com/photos/43992178@N00/387339135/ Flickr photopage], including a discussion between Tilman Piesk and probably [[Shea Zellweger]]

{{DEFAULTSORT:Logic Alphabet}}
[[Category:Binary operations]]
[[Category:Boolean algebra]]</text>
      <sha1>8h85z09vya9i3chipzm96ysddbo34q9</sha1>
    </revision>
  </page>
  <page>
    <title>Mass-to-charge ratio</title>
    <ns>0</ns>
    <id>3957360</id>
    <revision>
      <id>869566840</id>
      <parentid>869566773</parentid>
      <timestamp>2018-11-19T12:20:06Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <comment>/* top */ e is positive charge</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15191">[[File:Cyclotron motion.jpg|width=300px|thumb|right|Beam of electrons moving in a circle in a [[Teltron tube]], due to the presence of a [[magnetic field]]. Purple light is emitted along the electron path, due to the electrons colliding with gas molecules in the bulb. The mass-to-charge ratio of the electron can be measured in this apparatus by comparing the radius of the purple circle, the strength of the magnetic field, and the voltage on the electron gun. The mass and charge ''cannot'' be ''separately'' measured this way—only their ratio.]]
{{Infobox physical quantity
| name = Mass-to-charge ratio
| symbols = {{mvar|m}}/{{mvar|Q}}
| baseunits = [[Kilogram|kg]]⋅[[Ampere|A]]{{sup|-1}}⋅[[Second|s]]{{sup|-1}}
| unit = kg/[[coulomb|C]]
| dimension =&lt;math&gt;MI^{-1}T^{-1}&lt;/math&gt;
}}

The '''mass-to-charge ratio''' (''m''/''Q'') is a [[physical quantity]] that is most widely used in the [[electrodynamics]] of charged particles, e.g. in electron optics and [[ion optics]].  It appears in the scientific fields of [[electron microscopy]], [[cathode ray tube]]s, [[accelerator physics]], [[nuclear physics]], [[Auger electron spectroscopy]], [[physical cosmology|cosmology]] and [[mass spectrometry]].&lt;ref name="M03752"&gt;{{GoldBookRef|title=mass-to-charge ratio, m/z in mass spectrometry|file=M03752}}&lt;/ref&gt;  The importance of the mass-to-charge ratio, according to classical electrodynamics, is that two particles with the same mass-to-charge ratio move in the same path in a vacuum , when subjected to the same electric and magnetic fields. Its SI units are [[kilogram|kg]]/[[Coulomb|C]]. In rare occasions the [[Thomson (unit)|thomson]] has been used as its unit in the field of mass spectrometry.

Some fields use the '''charge-to-mass''' ratio (''Q''/''m'') instead, which is the [[multiplicative inverse]] of the mass-to-charge ratio.  The 2014 CODATA recommended value for an [[electron]] is {{frac|''Q''|''m''}} = {{val|-1.758820024|(11)|e=11|u=C/kg}}.&lt;ref name=autogenerated1&gt;[http://physics.nist.gov/cgi-bin/cuu/Value?esme electron charge to mass quotient]. NIST Database&lt;/ref&gt;

==Origin==

When charged particles move in electric and magnetic fields the following two laws apply:

:{|
|-
|&lt;math&gt;\mathbf{F} = Q (\mathbf{E} + \mathbf{v} \times \mathbf{B}),&lt;/math&gt;
| &amp;nbsp;
|([[Lorentz force]] law)
|-
|&lt;math&gt;\mathbf{F}=m\mathbf{a} = m \frac{\mathrm{d}\mathbf{v}}{\mathrm{d}t}&lt;/math&gt;
| &amp;nbsp;
|([[Newton's second law]] of motion)
|}

where '''F''' is the [[force]] applied to the ion, ''m'' is the [[mass]] of the particle, '''a''' is the [[acceleration]], ''Q'' is the [[electric charge]], '''E''' is the [[electric field]], and '''v''' &amp;times; '''B''' is the [[cross product]] of the ion's [[velocity]] and the [[magnetic flux density]].

This differential equation is the classic equation of motion for charged particles. Together with the particle's initial conditions, it completely determines the particle's motion in space and time in terms of ''m''/''Q''. Thus [[Mass spectrometry|mass spectrometers]] could be thought of as "mass-to-charge spectrometers". When presenting data in a [[mass spectrum]], it is common to use the dimensionless ''m''/''z'', which denotes the dimensionless quantity formed by dividing the mass number of the ion by its charge number.&lt;ref name="M03752" /&gt;

Combining the two previous equations yields:

: &lt;math&gt;\left(\frac{m}{Q}\right)\mathbf{a} = \mathbf{E}+ \mathbf{v} \times \mathbf{B}&lt;/math&gt;.

This differential equation is the classic equation of motion of a charged particle in vacuum. Together with the particle's initial conditions it determines the particle's motion in space and time.  It immediately reveals that two particles with the same ''m''/''Q'' ratio behave in the same way. This is why the mass-to-charge ratio is an important physical quantity in those scientific fields where charged particles interact with magnetic or electric fields.

=== Exceptions ===

There are non-classical effects that derive from [[quantum mechanics]], such as the [[Stern–Gerlach experiment|Stern–Gerlach effect]] that can diverge the path of ions of identical ''m''/''Q''.

== Symbols and units ==
The IUPAC recommended symbol for mass and charge are ''m'' and ''Q'', respectively,&lt;ref&gt;{{GreenBookRef2nd|page=4}}&lt;/ref&gt;&lt;ref&gt;{{GreenBookRef2nd|page=14}}&lt;/ref&gt; however using a lowercase ''q'' for charge is also very common. Charge is a scalar property, meaning that it can be either [[positive number|positive]] (+) or [[negative number|negative]] (&amp;minus;). The [[Coulomb]] (C) is the SI unit of charge; however, other units can be used, such as expressing charge in terms of the [[elementary charge]] (e). The [[SI unit]] of the physical quantity ''m''/''Q'' is kilogram per coulomb.

===Mass spectrometry and ''m''/''z''===
{{main|Mass spectrum}}
The units and notation above are used when dealing with the physics of mass spectrometry; however, the ''m''/''z'' notation is used for the independent variable in a [[mass spectrum]].&lt;ref name="IUPAC"&gt;{{cite book | title=IUPAC. Compendium of Chemical Terminology, 2nd ed. (the –"––Gold Book") | publisher=[[Blackwell Scientific Publications]] | author=Compiled by A. D. McNaught and A. Wilkinson | year=1997 | location=Oxford | isbn=0-9678550-9-8 | url=http://goldbook.iupac.org/M03752.html | doi=10.1351/goldbook.M03752}}&lt;/ref&gt; This notation eases{{Clarify|reason=How it eases? An example might help.|date=July 2018}} data interpretation since it is numerically more related to the [[unified atomic mass unit]].&lt;ref name="M03752" /&gt; The ''m'' refers to the molecular or atomic mass number and ''z'' to the [[charge number]] of the [[ion]]; however, the quantity of ''m''/''z'' is dimensionless by definition.&lt;ref name="IUPAC" /&gt; An ion of 100 atomic mass units (''m'' = 100) carrying two charges (''z'' = 2) will be observed at ''m''/''z'' = 50.

== History ==
In the 19th century, the mass-to-charge ratios of some ions were measured by electrochemical methods. In 1897, the mass-to-charge ratio of the [[electron]] was first measured by [[J. J. Thomson]].&lt;ref&gt;[http://web.lemoyne.edu/~giunta/thomson1897.html J. J. Thomson (1856–1940)] Philosophical Magazine, 44, 293 (1897).&lt;/ref&gt; By doing this, he showed that the electron was in fact a particle with a mass and a charge, and that its mass-to-charge ratio was much smaller than that of the hydrogen ion H&lt;sup&gt;+&lt;/sup&gt;. In 1898, [[Wilhelm Wien]] separated ions ([[canal ray]]s) according to their mass-to-charge ratio with an ion optical device with superimposed electric and magnetic fields ([[Wien filter]]). In 1901 [[Walter Kaufmann (physicist)|Walter Kaufman]] measured the increase of [[electromagnetic mass]] of fast electrons ([[Kaufmann–Bucherer–Neumann experiments]]), or [[Mass in special relativity|relativistic mass]] increase in modern terms. In 1913, Thomson measured the mass-to-charge ratio of [[ion]]s with an instrument he called a parabola spectrograph.&lt;ref&gt;[http://web.lemoyne.edu/~giunta/canal.html Joseph John Thomson (1856–1940)] Proceedings of the Royal Society A 89, 1–20 (1913) [as excerpted in Henry A. Boorse &amp; Lloyd Motz, The World of the Atom, Vol. 1 (New York: Basic Books, 1966)]&lt;/ref&gt; Today, an instrument that measures the mass-to-charge ratio of charged particles is called a [[mass spectrometer]].

==Charge-to-mass ratio==

[[File:Mass spectrometer large print.svg|thumb|160px|'''B''' is uniform throughout; '''E''' exists only where shown.]]
The '''charge-to-mass ratio''' (''Q''/''m'') of an object is, as its name implies, the [[electric charge|charge]] of an object divided by the mass of the same object.  This quantity is generally useful only for objects that may be treated as particles.  For extended objects, total charge, charge density, total mass, and mass density are often more useful.

Derivation:

&lt;math&gt;qvB=mv\frac{v}{r}&lt;/math&gt; or &lt;math&gt;\frac{q}{m}=\frac{v}{Br}&lt;/math&gt; (1)

Since &lt;math&gt;F_{electric}=F_{magnetic}&lt;/math&gt;,

&lt;math&gt;Eq=Bqv&lt;/math&gt; or &lt;math&gt;v=\frac{E}{B}&lt;/math&gt; (2)

Equations (1) and (2) yield

&lt;math&gt;\frac{q}{m}=\frac{E}{B^2r}&lt;/math&gt;

=== Significance ===
In some experiments, the charge-to-mass ratio is the only quantity that can be measured directly.  Often, the charge can be inferred from theoretical considerations, so that the charge-to-mass ratio provides a way to calculate the mass of a particle.

Often, the charge-to-mass ratio can be determined from observing the deflection of a charged particle in an external [[magnetic]] field.  The [[cyclotron]] equation, combined with other information such as the [[kinetic energy]] of the particle, will give the charge-to-mass ratio. One application of this principle is the mass spectrometer.  The same principle can be used to extract information in experiments involving the [[cloud chamber]].

The ratio of electrostatic to gravitational forces between two particles will be proportional to the product of their charge-to-mass ratios.  It turns out that gravitational forces are negligible on the subatomic level, due to the extremely small masses of subatomic particles.

=== The electron ===

The elementary charge-to-electron mass quotient, &lt;math&gt;e/m_{e}&lt;/math&gt;, is a quantity in experimental physics.  It bears significance because the electron mass ''m''&lt;sub&gt;e&lt;/sub&gt; is difficult to measure directly, and is instead derived from measurements of the elementary charge e and &lt;math&gt;e/m_{e}&lt;/math&gt;.  It also has historical significance; the ''Q''/''m'' ratio of the electron was successfully calculated by [[J. J. Thomson]] in 1897—and more successfully by Dunnington, which involves the [[angular momentum]] and deflection due to a perpendicular [[magnetic field]]. Thomson's measurement convinced him that [[cathode ray]]s were particles, which were later identified as [[electron]]s, and he is generally credited with their discovery.

The 2014 [[Committee on Data for Science and Technology|CODATA]] recommended value is &lt;math&gt;e/m_{e}&lt;/math&gt; = {{val|fmt=commas|-1.758820024|(11)|e=11|u=[[Coulomb|C]]/[[kilogram|kg]]}}.&lt;ref name=autogenerated1 /&gt; CODATA refers to this as the '''electron charge-to-mass quotient''', but '''ratio''' is still commonly used.

There are two other common ways of measuring the charge-to-mass ratio of an electron, apart from Thomson and Dunnington's methods.

#The magnetron method: Using a GRD7 Valve ([[Ferranti valve]]),{{dubious|date=November 2010}} electrons are expelled from a hot tungsten-wire filament towards an anode. The electron is then deflected using a solenoid. From the current in the solenoid and the current in the Ferranti Valve, e/m can be calculated.{{citation needed|date=November 2010}}
#Fine beam tube method: A heater heats a cathode, which emits electrons.  The electrons are accelerated through a known potential, so the velocity of the electrons is known.  The beam path can be seen when the electrons are accelerated through a helium (He) gas.  The collisions between the electrons and the helium gas produce a visible trail.  A pair of [[Helmholtz coil]]s produces a uniform and measurable magnetic field at right angles to the electron beam.  This magnetic field deflects the electron beam in a circular path.  By measuring the accelerating potential (volts), the current (amps) to the Helmholtz coils, and the radius of the electron beam, e/m can be calculated.&lt;ref&gt;PASCO scientific, Instruction Manual and Experimental guide for the PASCO scientific Model SE-9638, pg. 1.&lt;/ref&gt;

===Zeeman Effect===
The charge-to-mass ratio of an electron may also be measured with the [[Zeeman effect]], which gives rise to energy splittings in the presence of a [[magnetic field]] ''B'':
:&lt;math&gt; \Delta E = \frac{e\hbar B}{2m}(m_{j,f}g_{J,f}-m_{j,i}g_{J,i})&lt;/math&gt;

Here ''m''&lt;sub&gt;''j''&lt;/sub&gt; are quantum integer values ranging from -''j'' to ''j'', with ''j'' as the [[eigenvalue]] of the [[total angular momentum]] [[operator (physics)|operator]] '''J''', with&lt;ref name=autogenerated1 /&gt;
:&lt;math&gt;\mathbf{J} = \mathbf{L} + \mathbf{S}&lt;/math&gt;
where '''S''' is the [[Spin (physics)|spin operator]] with eigenvalue ''s'' and '''L''' is  the [[angular momentum operator]] with eigenvalue ''l''. ''g''&lt;sub&gt;''J''&lt;/sub&gt; is the [[Landé g-factor]], calculated as

:&lt;math&gt;g_J = 1 + \frac{j(j+1) + s(s+1) - l(l+1)}{2j(j+1)}&lt;/math&gt;

The shift in energy is also given in terms of [[frequency]] ''&amp;nu;'' and [[wavelength]] ''&amp;lambda;'' as

:&lt;math&gt; \Delta E = h\Delta\nu = h c \Delta \left( \frac{1}{\lambda} \right ) = hc \frac{\Delta\lambda}{\lambda^2}&lt;/math&gt;

Measurements of the Zeeman effect commonly involve the use of a [[Fabry–Pérot interferometer]], with light from a source (placed in a magnetic field) being passed between two mirrors of the interferometer. If ''&amp;delta;D'' is the change in mirror separation required to bring the ''m''&lt;sup&gt;th&lt;/sup&gt;-order ring of wavelength ''λ'' + ''Δλ'' into coincidence with that of wavelength ''λ'', and ''ΔD'' brings the (''m'' + 1)&lt;sup&gt;th&lt;/sup&gt; ring of wavelength ''λ'' into coincidence with the ''m''&lt;sup&gt;th&lt;/sup&gt;-order ring, then

:&lt;math&gt;\Delta\lambda = \lambda^2\frac{\delta D}{2D\Delta D}&lt;/math&gt;.

It follows then that

:&lt;math&gt;hc\frac{\Delta\lambda}{\lambda^2} = hc\frac{\delta D}{2D\Delta D} = \frac{e\hbar B}{2m}(m_{j,f}g_{J,f}-m_{j,i}g_{J,i}) \ .&lt;/math&gt;

Rearranging, it is possible to solve for the charge-to-mass ratio of an electron as

:&lt;math&gt;\frac{e}{m} = \frac{4 \pi c}{B(m_{j,f}g_{J,f}-m_{j,i}g_{J,i})}\frac{\delta D}{D\Delta D} \ .&lt;/math&gt;

==See also==
*[[Gyromagnetic ratio]]
*[[Thomson (unit)]]

== References==
{{Reflist}}

== Bibliography ==
*{{cite book |author=Szilágyi, Miklós |title=Electron and ion optics |publisher=Plenum Press |location=New York |year=1988 |pages= |isbn=0-306-42717-6 |oclc= |doi= |accessdate=}}
*{{cite book |author=Septier, Albert L. |title=Applied charged particle optics |publisher=[[Academic Press]] |location=Boston |year=1980 |pages= |isbn=0-12-014574-X |oclc= |doi= |accessdate=}}
* {{cite book |author= |title=International vocabulary of basic and general terms in metrology =: Vocabulaire international des termes fondamentaux et généraux de métrologie |publisher=[[International Organization for Standardization]] |location= |year=1993 |pages= |isbn=92-67-01075-1 |oclc= |doi= |accessdate=}}CC.
* IUPAP Red Book SUNAMCO 87-1 "Symbols, Units, Nomenclature and Fundamental Constants in Physics" (does not have an online version).
* Symbols Units and Nomenclature in Physics   IUPAP-25  IUPAP-25, E.R. Cohen &amp; P. Giacomo, Physics 146A (1987) 1–68.

==External links==
*[https://web.archive.org/web/20140502000422/http://www.bipm.org/utils/en/pdf/si-brochure.pdf BIPM SI brochure]
* [https://web.archive.org/web/20140611124954/http://www.aip.org/pubservs/style/4thed/AIP_Style_4thed.pdf AIP style manual]
* NIST on [http://physics.nist.gov/cuu/Units/index.html units] and [http://physics.nist.gov/cuu/Units/checklist.html manuscript check list]
* Physics Today's [https://web.archive.org/web/20060215103724/http://www.physicstoday.org/guide/metric.pdf instructions on quantities and units]

{{DEFAULTSORT:Mass-To-Charge Ratio}}
[[Category:Concepts in physics]]
[[Category:Mass spectrometry]]
[[Category:Metrology]]
[[Category:Ratios]]</text>
      <sha1>1stmampuf8kwt2wa71040ft59151puh</sha1>
    </revision>
  </page>
  <page>
    <title>Mean-periodic function</title>
    <ns>0</ns>
    <id>37496709</id>
    <revision>
      <id>848995505</id>
      <parentid>848995358</parentid>
      <timestamp>2018-07-05T19:29:06Z</timestamp>
      <contributor>
        <username>Galoisfka</username>
        <id>33688401</id>
      </contributor>
      <minor/>
      <comment>added malgrange link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3779">In [[mathematical analysis]], the concept of a '''mean-periodic function''' is a generalization of the concept of a [[periodic function]] introduced in 1935 by [[Jean Delsarte]].&lt;ref&gt;{{cite journal | author-first = Jean | author-last = Delsarte | title = Les fonctions moyenne-périodiques | journal = Journal de Math., Pures et Appl. | volume = 17 | year=1935 |pages = 403-453}}&lt;/ref&gt;&lt;ref name=Kahane59&gt;{{cite book | author-first = J.-P. | author-last = Kahane |author-link = Jean-Pierre Kahane | title = Lectures on Mean Periodic Functions |year = 1959 | publisher = Tata Institute of Fundamental Research, Bombay |url=http://www.math.tifr.res.in/~publ/ln/tifr15.pdf}}&lt;/ref&gt; Further results were made by [[Laurent Schwartz]]. &lt;ref&gt;{{cite article|author-first = Bernard | author-last = Malgrange | author-link=Bernard Malgrange|year=1954 | title = Fonctions moyenne-périodiques (d'après J.-P. Kahane)|journal=Séminaire Bourbaki|number=97|pages=425-437|url=http://www.numdam.org/article/SB_1951-1954__2__425_0.pdf}}&lt;/ref&gt;&lt;ref name=Schwartz47&gt;{{Cite journal | author-first = Laurent| author-last = Schwartz | author-link = Laurent Schwartz | title=Théorie générale des fonctions moyenne-périodiques | journal= Ann. of Math. | year = 1947 | pages=857-929 |volume = 48 | issue = 2| url=http://sites.mathdoc.fr/OCLS/pdf/OCLS_1947__8__857_0.pdf}}&lt;/ref&gt;

==Definition==
Consider a [[complex number|complex]]-valued function {{math|''f''}} of a [[real number|real]] variable.  The function {{math|''f''}} is periodic with period {{math|''a''}} precisely if for all real {{math|''x''}}, we have {{math|''f''(''x'') − ''f''(''x'' − ''a'') {{=}} 0}}. This can be written as

: &lt;math&gt; \int f(x-y) \, d\mu(y) = 0\qquad\qquad(1) &lt;/math&gt;

where &lt;math&gt;\mu&lt;/math&gt; is the difference between the [[Dirac delta function|Dirac measures]] at&amp;nbsp;0&amp;nbsp;and&amp;nbsp;''a''.  The function {{math|''f''}} is mean-periodic if it satisfies the same equation (1), but where &lt;math&gt;\mu&lt;/math&gt; is some arbitrary nonzero measure with compact (hence bounded) support.

Equation (1) can be interpreted as a [[convolution]], so that a mean-periodic function is a function {{math|''f''}} for which there exists a compactly supported (signed) Borel measure &lt;math&gt;\mu&lt;/math&gt; for which &lt;math&gt;f*\mu = 0&lt;/math&gt;.&lt;ref name=Schwartz47 /&gt;

There are several well-known equivalent definitions.&lt;ref name=Kahane59 /&gt;

==Relation to almost periodic functions==
Mean-periodic functions are a separate generalization of periodic functions from the [[almost periodic function]]s. For instance, exponential functions are mean-periodic since {{math|exp(''x''+1) − ''e''.exp(''x'') {{=}} 0}}, but they are not almost periodic as they are unbounded. Still, there is a theorem which states that any [[uniformly continuous]] bounded mean-periodic function is almost periodic (in the sense of Bohr). In the other direction, there exist almost periodic functions which are not mean-periodic.&lt;ref name=Kahane59 /&gt;

==Applications==
In work related to the [[Langlands correspondence]], the mean-periodicity of certain (functions related to) zeta functions associated to an [[arithmetic scheme]] have been suggested to correspond to automorphicity of the related L-function.&lt;ref&gt;{{cite article|author3-first = M.|author3-last = Suzuki|author2-first=G.|author2-last=Ricotta|author1-first=I.|author1-last=Fesenko|author1-link=Ivan Fesenko|title=Mean-periodicity and zeta functions|journal=Annales de l'institut Fourier|year=2012|volume=62|pages=1819-1887|number=5|url=http://www.numdam.org/item/AIF_2012__62_5_1819_0|arxiv=0803.2821}}&lt;/ref&gt; There is a certain class of mean-periodic functions arising from number theory. 

==See also==
*　[[almost periodic function]]s

==References==
{{reflist}}

[[Category:Mathematical analysis]]</text>
      <sha1>06qy2txct8tiiyavty3da4zzceaznc3</sha1>
    </revision>
  </page>
  <page>
    <title>Method of matched asymptotic expansions</title>
    <ns>0</ns>
    <id>4265892</id>
    <revision>
      <id>840896920</id>
      <parentid>833415727</parentid>
      <timestamp>2018-05-12T20:44:59Z</timestamp>
      <contributor>
        <ip>137.110.65.176</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12678">In [[mathematics]], the '''method of matched asymptotic expansions''' is a common approach to finding an accurate approximation to the solution to an [[equation]], or [[simultaneous equations|system of equations]]. It is particularly used when solving [[singular perturbation|singularly perturbed]] [[differential equation]]s. It involves finding several different approximate solutions, each of which is valid (i.e. accurate) for part of the range of the independent variable, and then combining these different solutions together to give a single approximate solution that is valid for the whole range of values of the independent variable.

==Method overview==
In a large class of singularly perturbed problems, the [[Domain of a function|domain]] may be divided into two or more subdomains. In one of these, often the largest, the solution is accurately approximated by an [[asymptotic series]]&lt;ref&gt;R.B. Dingle (1973), ''Asymptotic Expansions: Their Derivation and Interpretation'', [[Academic Press]].&lt;/ref&gt; found by treating the problem as a regular [[perturbation theory|perturbation]] (i.e. by setting a relatively small parameter to zero). The other subdomains consist of one or more small areas in which that approximation is inaccurate, generally because the perturbation terms in the problem are not negligible there. These areas are referred to as transition layers, and as boundary or interior layers depending on whether they occur at the domain boundary (as is the usual case in applications) or inside the domain.

An approximation in the form of an asymptotic series is obtained in the transition layer(s) by treating that part of the domain as a separate perturbation problem. This approximation is called the "inner solution," and the other is the "outer solution," named for their relationship to the transition layer(s). The outer and inner solutions are then combined through a process called "matching" in such a way that an approximate solution for the whole domain is obtained.&lt;ref name=verhulst&gt;{{cite book | author=Verhulst, F. | title=Methods and Applications of Singular Perturbations: Boundary Layers and Multiple Timescale Dynamics | publisher=Springer | year=2005 | isbn=0-387-22966-3 }}&lt;/ref&gt;&lt;ref&gt;{{Cite book | author=Nayfeh, A. H. | title=Perturbation Methods | series=Wiley Classics Library | year=2000 | publisher=Wiley-Interscience | isbn=978-0-471-39917-9 }}&lt;/ref&gt;&lt;ref&gt;{{Cite book |author1=Kevorkian, J. |author2=Cole, J. D. | title=Multiple Scale and Singular Perturbation Methods | year=1996 | publisher=Springer | isbn=0-387-94202-5 }}&lt;/ref&gt;

==A simple example==
Consider the [[boundary value problem]]

:&lt;math&gt; \varepsilon y'' + (1+\varepsilon) y' + y = 0,&lt;/math&gt;

where &lt;math&gt;y&lt;/math&gt; is a function of independent time variable &lt;math&gt;t&lt;/math&gt;, which ranges from 0 to 1, the boundary conditions are &lt;math&gt;y(0)=0&lt;/math&gt; and &lt;math&gt;y(1)=1&lt;/math&gt;, and &lt;math&gt;\varepsilon&lt;/math&gt; is a small parameter, such that &lt;math&gt;0&lt;\varepsilon\ll 1&lt;/math&gt;.

===Outer solution, valid for ''t''&amp;nbsp;=&amp;nbsp;''O''(1)===

Since &lt;math&gt;\varepsilon&lt;/math&gt; is very small, our first approach is to treat the equation as a regular perturbation problem, i.e. make the approximation &lt;math&gt;\varepsilon=0&lt;/math&gt;, and hence find the solution to the problem

:&lt;math&gt;y'+y=0.\,&lt;/math&gt;

Alternatively, consider that when &lt;math&gt;y&lt;/math&gt; and &lt;math&gt;t&lt;/math&gt; are both of size ''O''(1), the four [[Term (mathematics)|terms]] on the left hand side of the original equation are respectively of sizes ''O''(&lt;math&gt;\varepsilon&lt;/math&gt;), ''O''(1), ''O''(&lt;math&gt;\varepsilon&lt;/math&gt;) and ''O''(1). The [[leading-order]] balance on this timescale, valid in the [[distinguished limit]] &lt;math&gt;\varepsilon \to 0&lt;/math&gt;, is therefore given by the second and fourth terms, i.e. &lt;math&gt;y'+y=0.\,&lt;/math&gt;

This has solution

:&lt;math&gt;y=Ae^{-t}\,&lt;/math&gt;

for some constant &lt;math&gt;A&lt;/math&gt;. Applying the boundary condition &lt;math&gt;y(0) = 0&lt;/math&gt;, we would have &lt;math&gt;A=0&lt;/math&gt;; applying the boundary condition &lt;math&gt;y(1) = 1&lt;/math&gt;, we would have &lt;math&gt;A=e&lt;/math&gt;. It is therefore impossible to satisfy both boundary conditions, so &lt;math&gt;\varepsilon=0&lt;/math&gt; is not a valid approximation to make across the whole of the domain (i.e. this is a [[singular perturbation]] problem). From this we infer that there must be a boundary layer at one of the endpoints of the domain where &lt;math&gt;\varepsilon&lt;/math&gt; needs to be included. This region will be where &lt;math&gt;\varepsilon&lt;/math&gt; is no longer negligible compared to the independent variable &lt;math&gt;t&lt;/math&gt;, i.e. &lt;math&gt;t&lt;/math&gt; and &lt;math&gt;\varepsilon&lt;/math&gt; are of comparable size, i.e. the boundary layer is adjacent to &lt;math&gt;t=0&lt;/math&gt;. Therefore, the other boundary condition &lt;math&gt;y(1) = 1&lt;/math&gt; applies in this outer region, so &lt;math&gt;A=e&lt;/math&gt;, i.e. &lt;math&gt;y_O=e^{1-t}\,&lt;/math&gt; is an accurate approximate solution to the original boundary value problem in this outer region. It is the leading-order solution.

===Inner solution, valid for ''t''&amp;nbsp;=&amp;nbsp;''O''(''&amp;epsilon;'')===

In the inner region, &lt;math&gt;t&lt;/math&gt; and &lt;math&gt;\varepsilon&lt;/math&gt; are both tiny, but of comparable size, so define the new ''O''(1) time variable &lt;math&gt;\tau = t/\varepsilon&lt;/math&gt;. Rescale the original boundary value problem by replacing &lt;math&gt;t&lt;/math&gt; with &lt;math&gt;\tau\varepsilon&lt;/math&gt;, and the problem becomes

:&lt;math&gt; \frac{1}{\varepsilon} y''(\tau ) + \left( {1 + \varepsilon } \right)\frac{1}{\varepsilon }y'(\tau ) +  y(\tau ) = 0,\,&lt;/math&gt;

which, after multiplying by &lt;math&gt;\varepsilon&lt;/math&gt; and taking &lt;math&gt;\varepsilon = 0&lt;/math&gt;, is

:&lt;math&gt;y'' + y' = 0. \, &lt;/math&gt;

Alternatively, consider that when &lt;math&gt;t&lt;/math&gt; has reduced to size ''O''(&lt;math&gt;\varepsilon&lt;/math&gt;), then &lt;math&gt;y&lt;/math&gt; is still of size ''O''(1) (using the expression for &lt;math&gt;y_O&lt;/math&gt;), and so the four terms on the left hand side of the original equation are respectively of sizes ''O''(&lt;math&gt;\varepsilon&lt;/math&gt;&lt;sup&gt;−1&lt;/sup&gt;), ''O''(&lt;math&gt;\varepsilon&lt;/math&gt;&lt;sup&gt;−1&lt;/sup&gt;), ''O''(1) and ''O''(1). The [[leading-order]] balance on this timescale, valid in the distinguished limit &lt;math&gt;\varepsilon \to 0&lt;/math&gt;, is therefore given by the first and second terms, i.e. &lt;math&gt;y'' + y'=0.\,&lt;/math&gt;

This has solution

:&lt;math&gt;y=B-Ce^{-\tau}\,&lt;/math&gt;

for some constants &lt;math&gt;B&lt;/math&gt; and &lt;math&gt;C&lt;/math&gt;. Since &lt;math&gt;y(0)=0&lt;/math&gt; applies in this inner region, this gives &lt;math&gt;B=C&lt;/math&gt;, so an accurate approximate solution to the original boundary value problem in this inner region (it is the leading-order solution) is

:&lt;math&gt;y_I  = B\left( {1 - e^{ - \tau } } \right)= B\left( {1 - e^{ - t/\varepsilon } } \right).\,&lt;/math&gt;

===Matching===

We use matching to find the value of the constant &lt;math&gt;B&lt;/math&gt;. The idea of matching is that the inner and outer solutions should agree for values of &lt;math&gt;t&lt;/math&gt; in an intermediate (or overlap) region, i.e. where &lt;math&gt;\varepsilon \ll  t \ll 1&lt;/math&gt;.  We need the outer limit of the inner solution to match the inner limit of the outer solution, i.e.
&lt;math&gt;\lim_{\tau \rightarrow \infty} y_I  = \lim_{t \to 0} y_O ,\,&lt;/math&gt;
which gives &lt;math&gt;B=e&lt;/math&gt;.

===Composite solution===

To obtain our final, matched, composite solution, valid on the whole domain, one popular method is the uniform method. In this method, we add the inner and outer approximations and subtract their overlapping value, &lt;math&gt;\,y_\mathrm{overlap}&lt;/math&gt;, which would otherwise be counted twice. The overlapping value is the outer limit of the inner boundary layer solution, and the inner limit of the outer solution; these limits were above found to equal &lt;math&gt;e&lt;/math&gt;. Therefore, the final approximate solution to this boundary value problem is,

:&lt;math&gt;y(t) = y_I  + y_O  - y_\mathrm{overlap} = e\left( {1 - e^{ - t/\varepsilon } } \right) + e^{1 - t}  - e = e\left( {e^{ - t}  - e^{ - t/\varepsilon } } \right).\,&lt;/math&gt;

Note that this expression correctly reduces to the expressions for &lt;math&gt;y_I&lt;/math&gt; and &lt;math&gt;y_O&lt;/math&gt; when &lt;math&gt;t&lt;/math&gt; is ''O''(&lt;math&gt;\varepsilon&lt;/math&gt;) and ''O''(1), respectively.

===Accuracy===
[[Image:Singular perturbation convergence.svg|thumb|right|400px|Convergence of approximations. Approximations and exact solutions, which are indistinguishable at this scale, are shown for various &lt;math&gt;\varepsilon&lt;/math&gt;. The outer solution is also shown. Note that since the boundary layer becomes narrower with decreasing &lt;math&gt;\varepsilon&lt;/math&gt;, the approximations [[Limit of a sequence|converge]] to the outer solution [[Pointwise convergence|pointwise]], but not [[Uniform convergence|uniformly]], almost everywhere.]]

This final solution satisfies the problem's original differential equation (shown by substituting it and its derivatives into the original equation). Also, the boundary conditions produced by this final solution match the values given in the problem, up to a constant multiple. This implies, due to the uniqueness of the solution, that the matched asymptotic solution is identical to the exact solution up to a constant multiple. This is not necessarily always the case, any remaining terms should go to zero uniformly as &lt;math&gt; \varepsilon \rightarrow 0 &lt;/math&gt;.

Not only does our solution successfully approximately solve the problem at hand, it closely approximates the problem's exact solution. It happens that this particular problem is easily found to have exact solution

:&lt;math&gt;y(t) = \frac{{e^{ - t}  - e^{ - t/\varepsilon } }}{{e^{ - 1}  - e^{ - 1/\varepsilon } }},\,&lt;/math&gt;

which has the same form as the approximate solution, by the multiplying constant. Note also that the approximate solution is the first term in a binomial expansion of the exact solution in powers of &lt;math&gt; e^{1 - 1/\varepsilon }&lt;/math&gt;.

===Location of boundary layer===
Conveniently, we can see that the boundary layer, where &lt;math&gt;y'&lt;/math&gt; and &lt;math&gt;y''&lt;/math&gt; are large, is near &lt;math&gt;t=0&lt;/math&gt;, as we supposed earlier. If we had supposed it to be at the other endpoint and proceeded by making the rescaling &lt;math&gt;\tau  = (1 - t)/\varepsilon&lt;/math&gt;, we would have found it impossible to satisfy the resulting matching condition. For many problems, this kind of trial and error is the only way to determine the true location of the boundary layer.&lt;ref name=verhulst/&gt;

==Harder problems==

The problem above is a simple example because it is a single equation with only one dependent variable, and there is one boundary layer in the solution. Harder problems may contain several co-dependent variables in a system of several equations, and/or with several boundary and/or interior layers in the solution.

It is often desirable to find more terms in the asymptotic expansions of both the outer and the inner solutions. The appropriate form of these expansions is not always clear: while a power-series expansion in &lt;math&gt;\varepsilon&lt;/math&gt; may work, sometimes the appropriate form involves fractional powers of &lt;math&gt;\varepsilon&lt;/math&gt;, functions such as &lt;math&gt;\varepsilon \log \varepsilon&lt;/math&gt;, et cetera. As in the above example, we will obtain outer and inner expansions with some coefficients which must be determined by matching.&lt;ref&gt;{{cite book|last1=Hinch|first1=John|title=Perturbation Methods | year=1991 |publisher=[[Cambridge University Press]]}}&lt;/ref&gt;

==Second-order differential equations==
A method of matched asymptotic expansions - with matching of solutions in the common domain of validity - has been developed and used extensively by Dingle and Müller-Kirsten for the derivation of asymptotic expansions of the solutions and characteristic numbers (band boundaries) of Schrödinger-like second-order differential equations with periodic potentials - in particular for the Mathieu equation&lt;ref&gt;R.B. Dingle and H.J.W. Müller, ''[[J. reine angew. Math.]]'' 211 (1962) 11-32 and 216 (1964) 123-133; H.J.W. Müller, ''J. reine angew. Math.'' 211 (1962) 179-190.&lt;/ref&gt; (best example), Lamé and ellipsoidal wave equations,&lt;ref&gt;H.J.W. Müller, ''[[Mathematische Nachrichten]]'' 31 (1966) 89-101, 32 (1966) 49-62, 32 (1966) 157-172.&lt;/ref&gt; oblate&lt;ref&gt;H.J.W. Müller, ''[[J. reine angew. Math.]]'' 211 (1962) 33-47.&lt;/ref&gt; and prolate&lt;ref&gt;H.J.W. Müller, ''[[J. reine angew. Math.]]'' 212 (1963) 26-48.&lt;/ref&gt; spheroidal wave equations, and equations with anharmonic potentials.&lt;ref&gt;H.J.W. Müller-Kirsten (2012), ''Introduction to Quantum Mechanics: Schrödinger Equation and Path Integral'', 2nd ed., [[World Scientific]], {{isbn|978-9814397742}}. Chapter 18 on Anharmonic potentials.&lt;/ref&gt;

==See also==
* [[Asymptotic analysis]]
* [[Multiple-scale analysis]]
* [[Activation energy asymptotics]]

==References==
{{reflist|2}}

[[Category:Differential equations]]
[[Category:Asymptotic analysis]]</text>
      <sha1>dqyhifaselvmxuxj10iqsy9onyn89jw</sha1>
    </revision>
  </page>
  <page>
    <title>Morley rank</title>
    <ns>0</ns>
    <id>1401941</id>
    <revision>
      <id>630285180</id>
      <parentid>630263145</parentid>
      <timestamp>2014-10-19T20:50:27Z</timestamp>
      <contributor>
        <ip>67.169.126.67</ip>
      </contributor>
      <comment>/* Examples */ I've removed another of the "examples", about the intersection of an empty set and a nonempty set. It's possible that this example could be meaningful, but it made no sense as written.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4084">In [[mathematical logic]], '''Morley rank''', introduced by {{harvs|txt=yes|authorlink=Michael D. Morley|first=Michael D. |last=Morley|year=1965}}, is a means of measuring the size of a subset of a  [[model theory|model]] of a theory, generalizing the notion of dimension in [[algebraic geometry]].

==Definition==
Fix a theory ''T'' with a model ''M''. The Morley rank of a  formula φ defining a definable subset ''S'' of ''M'' 
is an ordinal or &amp;minus;1 or ∞, defined by first recursively defining what it means for a formula to have Morley rank at least α for some ordinal α. 
*The Morley rank is at least 0 if ''S'' is non-empty.
*For α a successor ordinal, the Morley rank is at least α if in some [[elementary extension]] ''N'' of ''M'', ''S'' has countably many disjoint definable subsets ''S&lt;sub&gt;i&lt;/sub&gt;'', each of rank at least ''α''&amp;nbsp;&amp;minus;&amp;nbsp;1.
*For α a non-zero limit ordinal, the Morley rank is at least α if it is at least β for all β less than α.
The Morley rank is then defined to be α if it is at least α but not at least ''α''&amp;nbsp;+&amp;nbsp;1, and is defined to be ∞ if it is at least α for all ordinals α, and is defined to be &amp;minus;1 if ''S'' is empty.

For a subset of a model ''M'' defined by a formula φ the Morley rank is defined to be the Morley rank of φ in any ℵ&lt;sub&gt;0&lt;/sub&gt;-saturated elementary extension of ''M''. In particular for ℵ&lt;sub&gt;0&lt;/sub&gt;-saturated models the Morley rank of a subset is the Morley rank of any formula defining the subset.

If φ defining ''S'' has rank α, and ''S'' breaks up into no more than ''n''&amp;nbsp;&lt;&amp;nbsp;ω subsets of rank α, then φ is said to have '''Morley degree'''&amp;nbsp;''n''.  A formula defining a finite set has Morley rank 0.  A formula with Morley rank 1 and Morley degree 1 is called [[strongly minimal theory|strongly minimal]].  A '''strongly minimal''' structure is one where the trivial formula ''x''&amp;nbsp;=&amp;nbsp;''x'' is strongly minimal.  Morley rank and strongly minimal structures are key tools in the proof of [[Morley's categoricity theorem]] and in the larger area of [[stability theory (model theory)]].

==Examples==
*The empty set has Morley rank &amp;minus;1, and conversely anything of Morley rank &amp;minus;1 is empty.
*A subset has Morley rank 0 if and only if it is finite and non-empty.
*If ''V'' is an [[algebraic set]] in ''K''&lt;sup&gt;''n''&lt;/sup&gt;, for an [[algebraically closed field]] ''K'', then the Morley rank of ''V'' is the same as its usual [[Krull dimension]]. The Morley degree of ''V'' is the number of [[irreducible component]]s of maximal dimension; this is not the same as its [[degree (algebraic geometry)|degree in algebraic geometry]], except when its components of maximal dimension are linear spaces.
*The rational numbers, considered as an ordered set, has Morley rank ∞, as it contains a countable disjoint union of definable subsets isomorphic to itself.

==See also==
*[[Cherlin–Zilber conjecture]]
*[[Group of finite Morley rank]]
*[[U-rank]]

==References==
*[[Alexandre Borovik]],   A. Nesin,   "Groups of finite Morley rank", Oxford Univ. Press  (1994)
*B. Hart [http://www.msri.org/publications/books/Book39/files/hart.pdf Stability theory and its variants] (2000) pp.&amp;nbsp;131–148 in ''Model theory, algebra and geometry'', edited by D. Haskell et al., Math. Sci. Res. Inst. Publ. 39, Cambridge Univ. Press, New York, 2000. Contains a formal definition of Morley rank.
*David Marker [http://www.msri.org/publications/books/Book39/files/dcf.pdf Model Theory of Differential Fields] (2000) pp.&amp;nbsp;53–63 in ''Model theory, algebra and geometry'', edited by D. Haskell et al., Math. Sci. Res. Inst. Publ. 39, Cambridge Univ. Press, New York, 2000.
*{{citation|first=M.D. |last=Morley|title=Categoricity in power|journal=  Trans. Amer. Math. Soc. |volume= 114  |year=1965|pages= 514–538|doi=10.2307/1994188|issue=2|jstor=1994188|publisher=American Mathematical Society  }}
*{{springer|id=g/g110270|title=Group of finite Morley rank|first=A. |last=Pillay}}
*{{springer|id=M/m110200|first=A. |last=Pillay}}

[[Category:Model theory]]</text>
      <sha1>6t6z64324w9h7abosispc7fscike78b</sha1>
    </revision>
  </page>
  <page>
    <title>Network Description Language</title>
    <ns>0</ns>
    <id>23868797</id>
    <revision>
      <id>822925679</id>
      <parentid>822910136</parentid>
      <timestamp>2018-01-29T08:46:46Z</timestamp>
      <contributor>
        <username>Djm-leighpark</username>
        <id>30218082</id>
      </contributor>
      <minor/>
      <comment>Wikilink lightpath</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1167">'''Network Description Language''' (NDL) is a tool to reduce the complexity as networks evolve into the future.  NDL enables both humans and machines to have a better grasp on today’s highly evolved networks to ease time consuming and tedious tasks being performed by humans. Through the use of [[Resource Description Framework]] (RDF), researchers have been able to create an ontology for [[complex network]]s, thus creating a clear view of any network.

NDL has proven itself useful in solving many issues as it pertains to the operation of hybrid networks, allowing the creation of network maps and facilitating path finding algorithms. SURFnet6, a Dutch [[National Research and Education Network|national research and education network]] was one such network that has utilized NDL for [[Lightpath (optical network)|lightpath]] and IP service planning.

==External links==
*[http://www.science.uva.nl/research/sne/ndl SNE NDL]
*[http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4258536&amp;tag=1 IEEE Xplore - Using the Network Description Language in Optical Networks]
{{Compu-lang-stub}}

[[Category:Network theory]]
[[Category:Hardware description languages]]</text>
      <sha1>f9ex9ntqaomj6a1gopvjxsqab2i4xis</sha1>
    </revision>
  </page>
  <page>
    <title>Object aggregation</title>
    <ns>0</ns>
    <id>50026365</id>
    <redirect title="Object composition" />
    <revision>
      <id>713267993</id>
      <timestamp>2016-04-03T00:37:51Z</timestamp>
      <contributor>
        <username>Nbarth</username>
        <id>570614</id>
      </contributor>
      <comment>init, r to section</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="140">#REDIRECT [[Object composition#Aggregation]] {{R to section}}

[[Category:Object (computer science)]]
[[Category:Unified Modeling Language]]</text>
      <sha1>lm332agqm524cmsp8hfp8dukbba56up</sha1>
    </revision>
  </page>
  <page>
    <title>Paul R. Halmos – Lester R. Ford Award</title>
    <ns>0</ns>
    <id>8105253</id>
    <revision>
      <id>860307969</id>
      <parentid>860307229</parentid>
      <timestamp>2018-09-19T19:33:10Z</timestamp>
      <contributor>
        <username>Wkrif</username>
        <id>32139174</id>
      </contributor>
      <minor/>
      <comment>Added wikilinks</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2301">The '''Paul R. Halmos – Lester R. Ford Award''' (formerly known as the '''Lester R. Ford Award''') is a $1,000 prize given annually by the [[Mathematical Association of America]] for authors of articles of expository excellence published in ''[[The American Mathematical Monthly]]'' or ''[[Mathematics Magazine]]''.&lt;ref name=MAA&gt;[https://www.maa.org/programs/maa-awards/writing-awards/paul-halmos-lester-ford-awards Paul R. Halmos - Lester R. Ford Awards] on the website of the Mathematical Association of America.
&lt;/ref&gt; It is awarded to at most four authors each year.&lt;ref name=MAA/&gt; 
The prize was established in 1964 as the Lester R. Ford Award to honor the contributions of mathematician and former MAA president [[Lester R. Ford]].&lt;ref name=MAA/&gt;  In 2012 the award was renamed the Paul R. Halmos – Lester R. Ford Award to honor the contributions of former ''The American Mathematical Monthly'' editor [[Paul R. Halmos]] and the support of the Halmos family for the awards.&lt;ref name=MAA/&gt; Halmos himself received the award in 1971 and 1977.

== Recipients ==
The recipients of the '''Paul R. Halmos – Lester R. Ford Award''' are&lt;ref name="MAA" /&gt;:

* 2013:  Robert T. Jantzen and Klaus Volpert
* 2013:  Dimitris Koukoulopoulos and Johann Thiel
* 2013:  Lionel Levine and Katherine E. Stange
* 2013:  Dan Kalman and Mark McKinzie
* 2014:  Will Traves
* 2014:  [[Tadashi Tokieda]]
* 2014:  Jacques Lévy Véhel and Franklin Mendivil
* 2014:  Susan H. Marshall and Alexander R. Perlis
* 2015:  Mario Ponce and Patricio Santibanez
* 2015:  Daniel Velleman
* 2015:  Allison Henrich and [[Louis Kauffman|Louis H Kauffman]]
* 2015:  Erwan Brugallé and Kristin Shaw
* 2016:  Alex Chin, Gary Gordon, Kellie MacPhee, and Charles Vincent
* 2016:  Kenneth S. Williams
* 2016:  Manya Raman-Sundström
* 2016:  Zhiqin Lu and Julie Rowlett
* 2017:  [[Harold P. Boas]]
* 2017:  Adrien Kassel and David B. Wilson
* 2017:  Deborah Kent and David Muraki
* 2017:  [[Lawrence Zalcman]]

==References==
{{reflist}}

==External links==
* [https://www.maa.org/programs/maa-awards/writing-awards/paul-halmos-lester-ford-awards Paul R. Halmos - Lester R. Ford Awards] on the website of the Mathematical Association of America. Includes a list of past recipients.


{{award-stub}}



[[Category:Mathematics awards]]</text>
      <sha1>9g5gcwl1k3xdunxuxvnprlfkul2xonu</sha1>
    </revision>
  </page>
  <page>
    <title>Rectangular mask short-time Fourier transform</title>
    <ns>0</ns>
    <id>45164071</id>
    <revision>
      <id>858573356</id>
      <parentid>698705157</parentid>
      <timestamp>2018-09-08T04:23:51Z</timestamp>
      <contributor>
        <username>Enterprisey</username>
        <id>16663390</id>
      </contributor>
      <comment>Added {{[[:Template:merge to|merge to]]}} tag to article ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3628">{{merge to|Short-time Fourier transform|discuss=Talk:Short-time Fourier transform#Proposed merge with Rectangular mask short-time Fourier transform|date=September 2018}}
{{multiple issues|
{{lead missing|date=January 2015}}
{{orphan|date=January 2015}}
{{context|date=January 2016}}
{{technical|date=January 2016}}
}}
In mathematics, a '''rectangular mask short-time Fourier transform''' has the simple form of [[short-time Fourier transform]]. Other types of the STFT may require more computation time than the rec-STFT.
Define its mask function

: &lt;math&gt; w(t) =\begin{cases}
\ 1; &amp; |t|\leq B \\
\ 0; &amp; |t|&gt;B
\end{cases}&lt;/math&gt;
[[File:SquareWave.jpg|thumb|''B'' = 50, ''x''-axis (sec)]]

We can change ''B'' for different signal.

Rec-STFT

: &lt;math&gt;X(t,f)=\int_{t-B}^{t+B} x(\tau) e^{-j2\pi f\tau} \, d\tau&lt;/math&gt;

Inverse form

: &lt;math&gt;x(t)=\int_{-\infty}^\infty X(t_1,f)e^{j2\pi ft} \, df\text{ where } t-B&lt;t_1&lt;t+B&lt;/math&gt;

==Property==
Rec-STFT has similar properties with Fourier transform
* Integration
(a)
: &lt;math&gt;\int_{-\infty}^\infty X(t, f)\, df = \int_{t-B}^{t+B} x(\tau)\int_{-\infty}^\infty e^{-j 2 \pi f \tau}\, df \, d\tau = \int_{t-B}^{t+B} x(\tau)\delta(\tau) \, d\tau=\begin{cases}
\ x(0); &amp; |t|&lt; B \\
\ 0; &amp; \text{otherwise}
\end{cases}&lt;/math&gt;

(b)
: &lt;math&gt;\int_{-\infty}^\infty X(t, f)e^{-j 2 \pi f v} \,df =\begin{cases}
\ x(v); &amp; v-B&lt;t&lt; v+B \\
\ 0; &amp; \text{otherwise}
\end{cases}&lt;/math&gt;
*Shifting property(shift along x-axis)

:: &lt;math&gt;\int_{t-B}^{t+B} x(\tau+\tau_0) e^{-j 2 \pi f \tau}\, d\tau = X(t+\tau_0,f)e^{j 2 \pi f \tau_0}&lt;/math&gt;

*Modulation property (shift along ''y''-axis)

:&lt;math&gt;\int_{t-B}^{t+B} [x(\tau) e^{j 2 \pi f_0 \tau}] d\tau = X(t,f-f_0)&lt;/math&gt;

*special input
#When &lt;math&gt;x(t)=\delta(t), X(t,f)=\begin{cases}
\ 1; &amp; |t|&lt; B \\
\ 0; &amp; \text{otherwise}
\end{cases}&lt;/math&gt;
#When &lt;math&gt;x(t)=1,X(t,f)=2B\operatorname{sinc}(2Bf)e^{j 2 \pi f t}&lt;/math&gt;

*Linearity property
If &lt;math&gt;h(t)=\alpha x(t)+\beta y(t) \,&lt;/math&gt;,&lt;math&gt; H(t,f), X(t,f),&lt;/math&gt;and &lt;math&gt;Y(t,f) \,&lt;/math&gt;are their rec-STFTs, then

: &lt;math&gt;H(t,f)=\alpha X(t,f)+\beta Y(t,f) .&lt;/math&gt;

* Power integration property

:: &lt;math&gt;\int_{-\infty}^\infty |X(t, f)|^2\, df = \int_{t-B}^{t+B} |x(\tau)|^2\,d\tau&lt;/math&gt;
:: &lt;math&gt;\int_{-\infty}^\infty \int_{-\infty}^\infty |X(t, f)|^2\,df\,dt = 2B \int_{-\infty}^\infty |x(\tau)|^2\,d\tau&lt;/math&gt;

* Energy sum property([[Parseval's theorem]])

:: &lt;math&gt;\int_{-\infty}^\infty X(t,f)Y^*(t,f)\,df =  \int_{t-B}^{t+B} x(\tau)y^*(\tau)\,d\tau&lt;/math&gt;
:: &lt;math&gt;\int_{-\infty}^\infty \int_{-\infty}^{\infty}X(t,f)Y^*(t,f)\,df\,dt =2B \int_{-\infty}^\infty x(\tau)y^*(\tau)\,d\tau&lt;/math&gt;

==Rectangular mask ''B''&lt;nowiki&gt;'&lt;/nowiki&gt;s effect==
[[File:DifferentB.JPG|thumb|right|400px|comparison of different B]]
From the image, when ''B'' is smaller, the time resolution is better. Otherwise, when ''B'' is larger, the frequency resolution is better.

We can choose specified ''B'' to decide time resolution and frequency resolution.

==Advantage and disadvantage==
*Compare with the Fourier transform

'''Advantage'''
The instantaneous frequency can be observed.

'''Disadvantage'''
Higher complexity of computation.

*Compared with other types of time-frequency analysis: 
The rec-STFT has an advantage of the least computation time for digital implementation,
but its performance is worse than other types of time-frequency analysis.

==See also==

* [[Uncertainty principle]]

==References==

# [http://djj.ee.ntu.edu.tw/TFW.htm Jian-Jiun Ding (2014) Time-frequency analysis and wavelet transform]

[[Category:Fourier analysis]]
[[Category:Time–frequency analysis]]
[[Category:Transforms]]</text>
      <sha1>laapbjbq9pxax1lx8rmxl7nhcl8h9t1</sha1>
    </revision>
  </page>
  <page>
    <title>Rota–Baxter algebra</title>
    <ns>0</ns>
    <id>21091721</id>
    <revision>
      <id>867305044</id>
      <parentid>863626729</parentid>
      <timestamp>2018-11-04T22:54:50Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* top */[[User:JCW-CleanerBot#Logic|task]], replaced: Advances in Math. → Advances in Mathematics</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6813">In [[mathematics]], a '''Rota&amp;ndash;Baxter algebra''' is an [[associative algebra]], together with a particular [[linear map]] ''R'' which satisfies the '''Rota&amp;ndash;Baxter identity'''. It appeared first in the work of the American mathematician [[Glen E. Baxter]]&lt;ref&gt;{{Cite journal |first=G. |last=Baxter |title=An analytic problem whose solution follows from a simple algebraic identity |journal=Pacific J. Math. |volume=10 |issue= 3|pages=731–742 |year=1960 |mr=0119224 |doi=10.2140/pjm.1960.10.731}}&lt;/ref&gt;  in the realm of [[probability theory]]. Baxter's work was further explored from different angles by [[Gian-Carlo Rota]],&lt;ref&gt;{{Cite journal |first=G.-C. |last=Rota |title=Baxter algebras and combinatorial identities, I, II |journal=Bull. Amer. Math. Soc. |volume=75 |pages=325–329 |year=1969 |doi=10.1090/S0002-9904-1969-12156-7 |issue=2 }}; ibid. 75, 330&amp;ndash;334, (1969). Reprinted in: ''Gian-Carlo Rota on Combinatorics: Introductory papers and commentaries'', J.P.S. Kung Ed., Contemp. Mathematicians, Birkhäuser Boston, Boston, MA, 1995.&lt;/ref&gt;&lt;ref&gt;G.-C. Rota, ''Baxter operators, an introduction'', In: ''Gian-Carlo Rota on Combinatorics, Introductory papers and commentaries'', J.P.S. Kung Ed., Contemp. Mathematicians, Birkhäuser Boston, Boston, MA, 1995.&lt;/ref&gt;&lt;ref&gt;G.-C. Rota and D. Smith, ''Fluctuation theory and Baxter algebras'', Instituto Nazionale di Alta Matematica, IX, 179&amp;ndash;201, (1972). Reprinted in: ''Gian-Carlo Rota on Combinatorics: Introductory papers and commentaries'', J.P.S. Kung Ed., Contemp. Mathematicians, Birkhäuser Boston, Boston, MA, 1995.&lt;/ref&gt; [[Pierre Cartier (mathematician)|Pierre Cartier]],&lt;ref&gt;{{Cite journal |first=P. |last=Cartier |title=On the structure of free Baxter algebras |journal=Advances in Mathematics |volume=9 |issue= 2|pages=253–265 |year=1972 |doi=10.1016/0001-8708(72)90018-7 }}&lt;/ref&gt; and [[Frederic V. Atkinson]],&lt;ref&gt;{{Cite journal |first=F. V. |last=Atkinson |title=Some aspects of Baxter's functional equation |journal=J. Math. Anal. Appl. |volume=7 |issue= |pages=1–30 |year=1963 |doi=10.1016/0022-247X(63)90075-1 }}&lt;/ref&gt; among others. Baxter’s derivation of this identity that later bore his name emanated from some of the fundamental results of the famous probabilist [[Frank Spitzer]] in [[random walk]] theory.&lt;ref&gt;{{Cite journal |first=F. |last=Spitzer |title=A combinatorial lemma and its application to probability theory |journal=Trans. Amer. Math. Soc. |volume=82 |issue= 2|pages=323–339 |year=1956 |doi=10.1090/S0002-9947-1956-0079851-X }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |first=F. |last=Spitzer |title=Principles of random walks |edition=Second |series=Graduate Texts in Mathematics |volume=34 |publisher=Springer-Verlag |location=New York, Heidelberg |year=1976 }}&lt;/ref&gt;

In the 1980s, the Rota-Baxter operator of weight 0 in the context of Lie algebras was rediscovered as the operator form of the classical [[Yang-Baxter equation]],&lt;ref&gt;{{Cite journal |first=M.A. |last=Semenov-Tian-Shansky |title=What is a classical ''r''-matrix? |journal=Func. Anal. Appl. |volume=17 |issue= 4|pages=259–272 |year=1983 }}&lt;/ref&gt; named after the well-known physicists [[Chen-Ning Yang]] and [[Rodney Baxter]].

The study of Rota–Baxter algebras experienced a renaissance this century, beginning with several developments, in the algebraic approach to renormalization of perturbative quantum field theory,&lt;ref&gt;{{cite journal|last1=Connes|first1=A.|last2=Kreimer|first2=D.|title=Renormalization in quantum field theory and the Riemann-Hilbert problem. I. The Hopf algebra structure of graphs and the main theorem|journal=Comm. Math. Phys.|date=2000|volume=210|issue=1|pages=249–273|doi=10.1007/s002200050779|arxiv=hep-th/9912092}}&lt;/ref&gt; [[dendriform algebra]]s, associative analogue of the classical Yang-Baxter equation&lt;ref&gt;{{Cite journal |first=M. |last=Aguiar |title=Infinitesimal Hopf algebras |journal=Contemp. Math. |volume=267 |issue= |pages=1–29 |year=2000 }}&lt;/ref&gt; and mixable shuffle product constructions.&lt;ref&gt;{{cite journal|last1=Guo|first1=L.|last2=Keigher|first2=W.|title=Baxter algebras and shuffle products|journal=Adv. Math.|date=2000|volume=150|pages=117–149|doi=10.1006/aima.1999.1858|doi-access=free|arxiv=math/0407155}}&lt;/ref&gt;

==Definition and first properties==
Let ''k'' be a commutative ring and let &lt;math&gt;\lambda&lt;/math&gt; be given. A linear operator ''R'' on a ''k''-algebra ''A'' is called a '''Rota-Baxter operator of weight &lt;math&gt;\lambda&lt;/math&gt;''' if it satisfies the '''Rota-Baxter relation of weight &lt;math&gt;\lambda&lt;/math&gt;''':

:&lt;math&gt; R(x)R(y)=R(R(x)y) + R(xR(y)) + \lambda R(xy)&lt;/math&gt;

for all &lt;math&gt;x, y \in A&lt;/math&gt;. Then the pair &lt;math&gt;(A,R)&lt;/math&gt; or simply ''A'' is called a '''Rota–Baxter algebra of weight &lt;math&gt;\lambda&lt;/math&gt;'''. In some literature, &lt;math&gt;\theta=-\lambda&lt;/math&gt; is used in which case the above equation becomes

:&lt;math&gt; R(x)R(y)+\theta R(xy) = R(R(x)y) + R(xR(y)),&lt;/math&gt;

called the '''Rota-Baxter equation of weight &lt;math&gt;\theta&lt;/math&gt;'''. The terms Baxter operator algebra and Baxter algebra are also used.

Let &lt;math&gt;R&lt;/math&gt; be a Rota-Baxter of weight &lt;math&gt;\lambda&lt;/math&gt;. Then &lt;math&gt;-\lambda Id - R&lt;/math&gt; is also a Rota-Baxter operator of weight &lt;math&gt;\lambda&lt;/math&gt;. Further, for  &lt;math&gt;\mu&lt;/math&gt; in ''k'', &lt;math&gt;\mu R&lt;/math&gt; is a Rota-Baxter operator of weight &lt;math&gt;\mu\lambda&lt;/math&gt;.

==Examples==
'''Integration by Parts'''

[[Integration by parts]] is an example of a Rota–Baxter algebra of weight 0.  Let &lt;math&gt;C(R)&lt;/math&gt; be the algebra of [[continuous functions]] from the real line to the real line. Let :&lt;math&gt;f(x) \in C(R)&lt;/math&gt; be a continuous function. Define [[integral|integration]] as the Rota&amp;ndash;Baxter operator

:&lt;math&gt;I(f)(x) = \int_0^x f(t) dt \;.&lt;/math&gt;

Let ''G(x)'' = ''I(g)(x)'' and ''F(x)'' = ''I(f)(x)''. Then the formula for integration for parts can be written in terms of these variables as

:&lt;math&gt; F(x)G(x) = \int_0^x f(t) G(t) dt + \int_0^x F(t)g(t) dt \;.&lt;/math&gt;

In other words

:&lt;math&gt; I(f)(x)I(g)(x) = I(fI(g)(t))(x) + I(I(f)(t)g)(x) \; , &lt;/math&gt;

which shows that ''I'' is a Rota&amp;ndash;Baxter algebra of weight 0.

==Spitzer identity==
The Spitzer identity appeared is named after the American mathematician [[Frank Spitzer]]. It is regarded as a remarkable 
stepping stone in the theory of sums of independent random variables in fluctuation theory of probability. It can naturally be understood in terms of Rota&amp;ndash;Baxter operators.

===Bohnenblust&amp;ndash;Spitzer identity===
{{Empty section|date=August 2010}}

==Notes==
{{Reflist|colwidth=30em}}

==External links==
* Li Guo. [http://www.ams.org/notices/200911/rtx091101436p.pdf WHAT IS...a Rota-Baxter Algebra?] Notices of the AMS, December 2009, Volume 56 Issue 11

{{DEFAULTSORT:Rota-Baxter Algebra}}
[[Category:Algebras]]
[[Category:Combinatorics]]</text>
      <sha1>mlb79hoec4nftg98buwsre1qhoxa9jq</sha1>
    </revision>
  </page>
  <page>
    <title>Salo Finkelstein</title>
    <ns>0</ns>
    <id>4134907</id>
    <revision>
      <id>814261344</id>
      <parentid>787816621</parentid>
      <timestamp>2017-12-07T19:19:42Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 2 sources and tagging 0 as dead. #IABot (v1.6.1) ([[User:Balon Greyjoy|Balon Greyjoy]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3210">'''Salo Finkelstein''' (born 1896 or 1897, date of death unknown) was a [[mental calculator]], ranked eighth in the "100 Greatest Mental Calculators".&lt;ref&gt;{{cite web |url=http://www.mentalcalculation.com/greatest/calculator.html |title=Archived copy |accessdate=2006-02-20 |deadurl=yes |archiveurl=https://web.archive.org/web/20060622234514/http://www.mentalcalculation.com/greatest/calculator.html |archivedate=2006-06-22 |df= }}&lt;/ref&gt; He was born in [[Łódź]] (then within the [[Russian Empire]], now [[Poland]]) to a [[Jew]]ish family. 

While at school he was above average in mathematics, and discovered his calculating abilities as well as his faculty in memorizing numbers. At the age of 23, he began demonstrating this in public but lost interest for some time. He found employment with the Polish government in State Statistical office. 

In 1928 he performed before Professor [[Hans Henning]] in the [[Free City of Danzig]]. Henning previously tested other calculators, [[Dr. Ferrol]] and [[Gottfried Ruckle]], and found Finkelstein to be superior. In 1931 Finkelstein went on an international tour demonstrating his abilities and submitting himself for tests.

In 1932 he arrived in the [[United States]] and tried without success to find employment in a bank as a checker of calculations. In 1937 an article was published that described and analyzed his abilities, with the general conclusion that although he could perform calculations much more rapidly than most people, his thinking processes seem to obey the same laws and are not indicative of any unnatural powers. In particular, during multiplication, the time for performing operations was proportional not to the numbers of digits in  multiplied numbers, but to the number of separate "acts of attention" necessary to perform multiplication by ordinary rules. Also, the correctness of the results was not always 100 percent, decreased rapidly with the growth of the number of "acts of attention", and apparently depended on concentration.

After failing to secure himself a job that matched his abilities and unwilling to become a stage calculator, he attempted a career playing [[chess]] between 1941–1949. After that his further fate is unknown.

==Notes==

{{reflist}}

==References==
*Weinlad, J.D., Schlauch W.S. ''An examination of the computing ability of Mr. Salo Finkelstein'', [[Journal of Experimental Psychology]], 21 (1937) 382–402 [http://users.lk.net/~stepanov/mnemo/vein37e.html]
*Smith, Steven Bradley, ''Great Mental Calculators'', [[Columbia University Press]], 1983, {{ISBN|0-231-05640-0}}

==External links==
*[http://users.lk.net/~stepanov/mnemo/smith33e.html Salo Finkelstein] at The Great Mental Calculators
*[https://web.archive.org/web/20060622234514/http://www.mentalcalculation.com/greatest/calculator.html The 100 Greatest Mental Calculators]
*[http://www.chessgames.com/perl/chessplayer?pid=18802 Chessgames]

{{DEFAULTSORT:Finkelstein, Salo}}
[[Category:Polish Jews]]
[[Category:Mental calculators]]
[[Category:Polish chess players]]
[[Category:Jewish chess players]]
[[Category:Jewish Polish history]]
[[Category:1890s births]]
[[Category:Year of death missing]]
[[Category:Sportspeople from Łódź]]</text>
      <sha1>d1dfzsnkf7nlo083k8zca65lhg5ld8d</sha1>
    </revision>
  </page>
  <page>
    <title>Space of directions</title>
    <ns>0</ns>
    <id>57702051</id>
    <revision>
      <id>846774212</id>
      <parentid>846774066</parentid>
      <timestamp>2018-06-20T20:18:31Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>Often the editorial "we" is better avoided, but this instance actually seems like a good occasion for it.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2798">{{expert needed|Mathematics|reason=to review the article}}

In [[metric geometry]], the '''space of directions''' at a point describes the directions of curves that start at the point. It generalizes the [[tangent space]] in a [[differentiable manifold]].

==Definitions==
Let (''M'', ''d'') be a [[metric space]]. First we define the '''upper angle''' for two curves starting at the same point in ''M''. So let  
&lt;math&gt;\alpha, \beta:[0,\varepsilon)\to M&lt;/math&gt; be two curves with &lt;math&gt;\alpha(0)=\beta(0)=p&lt;/math&gt;. The upper angle between them at ''p'' is
:&lt;math&gt;\angle_U(\alpha,\beta) := \varlimsup_{s,t\to 0} \arccos \frac {d(\alpha(s),p)^2 + d(\beta(t),p)^2 - d(\alpha(s), \beta(t))^2} {2 d(\alpha(s),p) d(\beta(t),p)}.&lt;/math&gt;

The upper angle satisfies the [[triangle inequality]]: For three curves &lt;math&gt;\alpha_1, \alpha_2, \alpha_3&lt;/math&gt; starting at ''p'',
:&lt;math&gt;\angle_U(\alpha_1,\alpha_3) \le \angle_U(\alpha_1,\alpha_2) + \angle_U(\alpha_2,\alpha_3).&lt;/math&gt;

A curve is said to have a '''direction''' if the upper angle of two copies of itself at the starting point is zero. For curves which have directions at a point, we define an [[equivalence relation]] on them by saying that two curves are equivalent if the upper angle between them at the point is zero. Two equivalent curves are said to have the same direction at the point.

The set of equivalence classes of curves with directions at the point ''p'' equipped with the upper angle is a metric space, called the '''space of directions''' at the point, denoted as &lt;math&gt;\Omega_p(M)&lt;/math&gt;. The [[complete metric space|metric completion]] of the space of directions is called the '''completed space of directions''', denoted as &lt;math&gt;\overline{\Omega_p(M)}&lt;/math&gt;.

For an [[Alexandrov space]] with curvature bounded either above or below, there is also a similar definition in which shortest paths, which always have directions, are used. The space of directions at a point is then defined as the metric completion of the set of equivalence classes of shortest paths starting at the point.
 
==References==
*{{cite journal|title = The tangent cone of an Aleksandrov space of curvature ≤ K |author = Igor Nikolaev|journal= manuscripta mathematica |number = 86| pages=137–147|year= 1995}}
*{{cite book|title = A Course in Metric Geometry | author1 = Dmitri Burago| author2 = [[Yuri Burago]]| author3 = Sergei Ivanov| publisher = American Mathematical Society| year = 2001| isbn = 0-8218-2129-6 }}
*{{cite book|chapter =  Multidimensional generalized Riemannian spaces | author1 = V. Berestovskii| author2 = I. Nikolaev| title= Geometry IV. Non-regular Riemannian geometry| pages= 165–244 | year =1993| publisher= Springer-Verlag| location=Berlin| series = Encyclopaedia of Mathematical Sciences}}
[[Category:Metric geometry]]</text>
      <sha1>ie8smm5igeq68jovhhikisglfu2xwot</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical study of energy data</title>
    <ns>0</ns>
    <id>10854000</id>
    <revision>
      <id>843801348</id>
      <parentid>776419676</parentid>
      <timestamp>2018-05-31T15:23:06Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 2 sources and tagging 0 as dead. #IABot (v2.0beta)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3245">'''Energy statistics''' refers to collecting, compiling, analyzing and disseminating data on commodities such as [[coal]], [[crude oil]], [[natural gas]], [[electricity]], or renewable energy sources ([[biomass]], [[geothermal power|geothermal]], [[wind power|wind]] or [[solar power|solar energy]]), when they are used for the energy they contain. [[Energy]] is the capability of some substances, resulting from their physico-chemical properties, to do [[Work (thermodynamics)|work]] or produce [[heat]]. Some energy commodities, called [[fuels]], release their [[energy content]] as heat when they [[combustion|burn]]. This heat could be used to run an [[Internal combustion engine|internal]] or [[external combustion engine]].

The need to have [[statistics]] on energy commodities became obvious during the [[1973 oil crisis]] that brought tenfold increase in [[petroleum prices]]. Before the crisis, to have accurate data on global energy supply and demand was not deemed critical. Another concern of energy statistics today is a huge gap in energy use between [[developed country|developed]] and [[developing country|developing]] countries. As the gap narrows (''see picture''), the pressure on energy supply increases tremendously.[[Image:Global energy consumption.jpg|thumb|right|525px|Global energy consumption per capita, 1950-2004]] 

The data on energy and electricity come from three principal sources:
* [[Energy industry]]
* Other industries ("self-producers")
* Consumers
The flows of and trade in energy commodities are measured both in physical units (e.g., [[metric ton]]s), and, when [[Energy accounting|energy balances]] are calculated, in energy units (e.g., [[terajoule]]s or [[Ton of oil equivalent|tons of oil equivalent]]). What makes energy statistics specific and different from other fields of [[economic statistics]] is the fact that energy commodities undergo greater number of transformations (flows) than other commodities. In these transformations energy is conserved, as defined by and within the limitations of the [[First law of thermodynamics|first]] and [[second law of thermodynamics|second]] laws of thermodynamics. 

== See also ==

{{Portal|Energy}} 

* [[Energy system]]
* [[World energy resources and consumption]]

==External links==
* [http://yearbook.enerdata.net/ Statistical Energy Database Review: Enerdata Yearbook 2012]
* [http://www.iea.org/Textbase/stats/index.asp International Energy Agency: Statistics]
* [http://unstats.un.org/unsd/energy/default.htm United Nations: Energy Statistics]
* [https://web.archive.org/web/20070428093556/http://www.ssb.no/english/conference/ocg/ The Oslo Group on Energy Statistics]
* [http://www.eia.doe.gov/ DOE Energy Information Administration]
* [https://web.archive.org/web/20090724153202/http://energy.sigmaxi.org/ Year of Energy 2009]
* [http://www.energy.eu/ European Energy Statistics &amp; Key Indicators]

==Publications==
* [http://unstats.un.org/unsd/energy/yearbook/EYB_pdf.htm Energy Statistics Yearbook 2004, United Nations, 2006]
* [http://unstats.un.org/unsd/energy/balance/EBEP_pdf.htm Energy Balances and Electricity Profiles 2004, United Nations, 2006]

[[Category:Statistical data sets]]
[[Category:Energy]]
[[Category:Applied statistics]]</text>
      <sha1>tdypkygria4jef1il97k1sfwkion12z</sha1>
    </revision>
  </page>
  <page>
    <title>Stone duality</title>
    <ns>0</ns>
    <id>379619</id>
    <revision>
      <id>855503964</id>
      <parentid>832035750</parentid>
      <timestamp>2018-08-18T20:00:14Z</timestamp>
      <contributor>
        <username>Beland</username>
        <id>57939</id>
      </contributor>
      <minor/>
      <comment>convert HTML entities</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15494">{{No footnotes|date=March 2018}}

In [[mathematics]], there is an ample supply of [[duality of categories|categorical dualities]] between certain [[category theory|categories]] of [[topological space]]s and categories of [[partially ordered set]]s. Today, these dualities are usually collected under the label '''Stone duality''', since they form a natural generalization of [[Stone's representation theorem for Boolean algebras]]. These concepts are named in honor of [[Marshall Stone]]. Stone-type dualities also provide the foundation for [[pointless topology]] and are exploited in [[theoretical computer science]] for the study of [[Semantics of programming languages|formal semantics]].

This article gives pointers to special cases of Stone duality and explains a very general instance thereof in detail.

==Overview of Stone-type dualities==
Probably the most general duality that is classically referred to as "Stone duality" is the duality between the category '''Sob''' of [[sober space]]s with [[continuous function]]s and the category '''SFrm''' of spatial [[complete Heyting algebra|frames]] with appropriate frame homomorphisms. The [[dual (category theory)|dual category]] of '''SFrm''' is the category of [[complete Heyting algebra|locales]] denoted by '''SLoc'''. The [[equivalence of categories|categorical equivalence]] of '''Sob''' and '''SLoc''' is the basis for the mathematical area of [[pointless topology]], that is devoted to the study of '''Loc''' – the category of all locales of which '''SLoc''' is a full subcategory. The involved constructions are characteristic for this kind of duality, and are detailed below.

Now one can easily obtain a number of other dualities by restricting to certain special classes of sober spaces:

* The category '''CohSp''' of [[Spectral space|coherent]] sober spaces (and coherent maps) is equivalent to the category '''CohLoc''' of [[coherent locale|coherent (or spectral) locales]] (and coherent maps), on the assumption of the [[Boolean prime ideal theorem]] (in fact, this statement is equivalent to that assumption). The significance of this result stems from the fact that '''CohLoc''' in turn is dual to the category '''DLat''' of [[distributivity (order theory)|distributive]] [[lattice (order)|lattices]]. Hence, '''DLat''' is dual to '''CohSp''' – one obtains [[Stone's representation theorem for distributive lattices]].
* When restricting further to coherent sober spaces that are [[Hausdorff space|Hausdorff]], one obtains the category '''Stone''' of so-called [[Stone space]]s. On the side of '''DLat''', the restriction yields the subcategory '''Bool''' of [[Boolean algebra (structure)|Boolean algebras]]. Thus one obtains [[Stone's representation theorem for Boolean algebras]].
* Stone's representation for distributive lattices can be extended via an equivalence of coherent spaces and [[Priestley space]]s (ordered topological spaces, that are [[compact space|compact]] and totally order-disconnected). One obtains a representation of distributive lattices via ordered topologies: [[Priestley's representation theorem for distributive lattice]]s.

Many other Stone-type dualities could be added to these basic dualities.

== Duality of sober spaces and spatial locales ==

=== The lattice of open sets ===
The starting point for the theory is the fact that every topological space is characterized by a set of points ''X'' and a system Ω(''X'') of [[open set]]s of elements from ''X'', i.e. a subset of the [[powerset]] of ''X''. It is known that Ω(''X'') has certain special properties: it is a [[complete lattice]] within which [[supremum|suprema]] and finite [[infimum|infima]] are given by set unions and finite set intersections, respectively. Furthermore, it contains both ''X'' and the [[empty set]]. Since the [[order embedding|embedding]] of Ω(''X'') into the powerset lattice of ''X'' [[limit preserving (order theory)|preserves]] finite infima and arbitrary suprema, Ω(''X'') inherits the following distributivity law:

:&lt;math&gt;x \wedge \bigvee S = \bigvee \{\, x \wedge s : s \in S \,\}, &lt;/math&gt;

for every element (open set) ''x'' and every subset ''S'' of Ω(''X''). Hence Ω(''X'') is not an arbitrary complete lattice but a ''complete Heyting algebra'' (also called ''frame'' or ''locale'' – the various names are primarily used to distinguish several categories that have the same class of objects but different morphisms: frame morphisms, locale morphisms and homomorphisms of complete Heyting algebras). Now an obvious question is: To what extent is a topological space characterized by its locale of open sets?

As already hinted at above, one can go even further. The category '''Top''' of topological spaces has as morphisms the continuous functions, where a function ''f'' is continuous if the [[inverse image]] ''f''&lt;sup&gt; &amp;minus;1&lt;/sup&gt;(''O'') of any open set in the [[codomain]] of ''f'' is open in the [[domain of a function|domain]] of ''f''. Thus any continuous function ''f'' from a space ''X'' to a space ''Y'' defines an inverse mapping ''f''&lt;sup&gt; &amp;minus;1&lt;/sup&gt; from Ω(''Y'') to Ω(''X''). Furthermore, it is easy to check that ''f''&lt;sup&gt; &amp;minus;1&lt;/sup&gt; (like any inverse image map) preserves finite intersections and arbitrary unions and therefore is a ''morphism of frames''. If we define Ω(''f'') = ''f''&lt;sup&gt; &amp;minus;1&lt;/sup&gt; then Ω becomes a [[contravariant functor]] from the category '''Top''' to the category '''Frm''' of frames and frame morphisms. Using the tools of category theory, the task of finding a characterization of topological spaces in terms of their open set lattices is equivalent to finding a functor from '''Frm''' to '''Top''' which is [[adjoint functors|adjoint]] to Ω.

=== Points of a locale ===
The goal of this section is to define a functor pt from '''Frm''' to '''Top''' that in a certain sense "inverts" the operation of Ω by assigning to each locale ''L'' a set of points pt(''L'') (hence the notation pt) with a suitable topology. But how can we recover the set of points just from the locale, though it is not given as a lattice of sets? It is certain that one cannot expect in general that pt can reproduce all of the original elements of a topological space just from its lattice of open sets – for example all sets with the [[indiscrete topology]] yield (up to isomorphism) the same locale, such that the information on the specific set is no longer present. However, there is still a reasonable technique for obtaining "points" from a locale, which indeed gives an example of a central construction for Stone-type duality theorems.

Let us first look at the points of a topological space ''X''. One is usually tempted to consider a point of ''X'' as an element ''x'' of the set ''X'', but there is in fact a more useful description for our current investigation. Any point ''x'' gives rise to a continuous function ''p''&lt;sub&gt;''x''&lt;/sub&gt; from the one element topological space 1 (all subsets of which are open) to the space ''X'' by defining ''p''&lt;sub&gt;''x''&lt;/sub&gt;(1) = ''x''. Conversely, any function from 1 to ''X'' clearly determines one point: the element that it "points" to. Therefore, the set of points of a topological space is equivalently characterized as the set of functions from 1 to ''X''.

When using the functor Ω to pass from '''Top''' to '''Frm''', all set-theoretic elements of a space are lost, but – using a fundamental idea of category theory – one can as well work on the [[function space]]s. Indeed, any "point" ''p''&lt;sub&gt;''x''&lt;/sub&gt;: 1 → ''X'' in '''Top''' is mapped to a morphism Ω(''p''&lt;sub&gt;''x''&lt;/sub&gt;): Ω(''X'') → Ω(1). The open set lattice of the one-element topological space Ω(1) is just (isomorphic to) the two-element locale 2 = { 0, 1 } with 0 &lt; 1. After these observations it appears reasonable to define the set of points of a locale ''L'' to be the set of frame morphisms from ''L'' to 2. Yet, there is no guarantee that every point of the locale Ω(''X'') is in one-to-one correspondence to a point of the topological space ''X'' (consider again the indiscrete topology, for which the open set lattice has only one "point").

Before defining the required topology on pt(''X''), it is worthwhile to clarify the concept of a point of a locale further. The perspective motivated above suggests to consider a point of a locale ''L'' as a frame morphism ''p'' from ''L'' to 2. But these morphisms are characterized equivalently by the inverse images of the two elements of 2. From the properties of frame morphisms, one can derive that ''p''&lt;sup&gt; &amp;minus;1&lt;/sup&gt;(0) is a lower set (since ''p'' is [[Monotonic function|monotone]]), which contains a greatest element ''a''&lt;sub&gt;''p''&lt;/sub&gt; = V ''p''&lt;sup&gt; &amp;minus;1&lt;/sup&gt;(0) (since ''p'' preserves arbitrary suprema). In addition, the [[ideal (order theory)|principal ideal]] ''p''&lt;sup&gt; &amp;minus;1&lt;/sup&gt;(0) is a [[ideal (order theory)|prime ideal]] since ''p'' preserves finite infima and thus the principal ''a''&lt;sub&gt;''p''&lt;/sub&gt; is a [[prime (order theroy)|meet-prime element]]. Now the set-inverse of ''p''&lt;sup&gt; &amp;minus;1&lt;/sup&gt;(0) given by ''p''&lt;sup&gt; &amp;minus;1&lt;/sup&gt;(1) is a [[filter (mathematics)|completely prime filter]] because ''p''&lt;sup&gt; &amp;minus;1&lt;/sup&gt;(0) is a principal prime ideal. It turns out that all of these descriptions uniquely determine the initial frame morphism. We sum up:

A point of a locale ''L'' is equivalently described as:
* a frame morphism from ''L'' to 2
* a principal prime ideal of ''L''
* a meet-prime element of ''L''
* a completely prime filter of ''L''.

All of these descriptions have their place within the theory and it is convenient to switch between them as needed.

=== The functor pt ===
Now that a set of points is available for any locale, it remains to equip this set with an appropriate topology in order to define the object part of the functor pt. This is done by defining the open sets of pt(''L'') as

:φ(''a'') = { ''p'' ∈ pt(''L'') | ''p''(''a'') = 1 },

for every element ''a'' of ''L''. Here we viewed the points of ''L'' as morphisms, but one can of course state a similar definition for all of the other equivalent characterizations. It can be shown that setting Ω(pt(''L'')) = {φ(''a'') | ''a'' ∈ ''L''} does really yield a topological space (pt(''L''), Ω(pt(''L''))). It is common to abbreviate this space as pt(''L'').

Finally pt can be defined on morphisms of '''Frm''' rather canonically by defining, for a frame morphism ''g'' from ''L'' to ''M'', pt(''g''): pt(''M'') → pt(''L'') as pt(''g'')(''p'') = ''p'' o ''g''. In words, we obtain a morphism from ''L'' to 2 (a point of ''L'') by applying the morphism ''g'' to get from ''L'' to ''M'' before applying the morphism ''p'' that maps from ''M'' to 2. Again, this can be formalized using the other descriptions of points of a locale as well – for example just calculate (''p'' o ''g'')&lt;sup&gt; &amp;minus;1&lt;/sup&gt;(0).

=== The adjunction of Top and Loc===
As noted several times before, pt and Ω usually are not inverses. In general neither is ''X'' [[homeomorphism|homeomorphic]] to pt(Ω(''X'')) nor is ''L'' [[order isomorphism|order-isomorphic]] to Ω(pt(''L'')). However, when introducing the topology of pt(''L'') above, a mapping φ from ''L'' to Ω(pt(''L'')) was applied. This mapping is indeed a frame morphism. Conversely, we can define a continuous function ψ from ''X'' to pt(Ω(''X'')) by setting ψ(''x'') = Ω(''p''&lt;sub&gt;''x''&lt;/sub&gt;), where ''p''&lt;sub&gt;''x''&lt;/sub&gt; is just the characteristic function for the point ''x'' from 1 to ''X'' as described above. Another convenient description is given by viewing points of a locale as meet-prime elements. In this case we have ψ(''x'') = ''X'' \ Cl{''x''}, where Cl{''x''} denotes the topological closure of the set {''x''} and \ is just set-difference.

At this point we already have more than enough data to obtain the desired result: the functors Ω and pt define an adjunction between the categories '''Top''' and '''Loc''' = '''Frm'''&lt;sup&gt;op&lt;/sup&gt;, where pt is right adjoint to Ω and the [[natural transformation]]s ψ and φ&lt;sup&gt;op&lt;/sup&gt; provide the required unit and counit, respectively.

=== The duality theorem ===
The above adjunction is not an equivalence of the categories '''Top''' and '''Loc''' (or, equivalently, a duality of '''Top''' and '''Frm'''). For this it is necessary that both ψ and φ are isomorphisms in their respective categories.

For a space ''X'', ψ: ''X'' → pt(Ω(''X'')) is a homeomorphism [[if and only if]] it is [[bijective]]. Using the characterization via meet-prime elements of the open set lattice, one sees that this is the case if and only if every meet-prime open set is of the form ''X'' \ Cl{''x''} for a unique ''x''. Alternatively, every join-prime closed set is the closure of a unique point, where "join-prime" can be replaced by [[irreducible (order theory)|(join-) irreducible]] since we are in a distributive lattice. Spaces with this property are called '''sober'''.

Conversely, for a locale ''L'', φ: ''L'' → Ω(pt(''L'')) is always surjective. It is additionally injective if and only if any two elements ''a'' and ''b'' of ''L'' for which ''a'' is not less-or-equal to ''b'' can be separated by points of the locale, formally:

: if not ''a'' ≤ ''b'', then there is a point ''p'' in pt(''L'') such that p(''a'') = 1 and p(''b'') = 0.

If this condition is satisfied for all elements of the locale, then the locale is '''spatial''', or said to have enough points. (See also [[well-pointed category]] for a similar condition in more general categories.)

Finally, one can verify that for every space ''X'', Ω(''X'') is spatial and for every locale ''L'', pt(''L'') is sober. Hence, it follows that the above adjunction of '''Top''' and '''Loc''' restricts to an equivalence of the full subcategories '''Sob''' of sober spaces and '''SLoc''' of spatial locales. This main result is completed by the observation that for the functor pt o Ω, sending each space to the points of its open set lattice is left adjoint to the [[inclusion functor]] from '''Sob''' to '''Top'''. For a space ''X'', pt(Ω(''X'')) is called its '''soberification'''. The case of the functor Ω o pt is symmetric but a special name for this operation is not commonly used.

==References==
* Burris, Stanley N., and H.P. Sankappanavar, H. P., 1981. ''[http://www.thoralf.uwaterloo.ca/htdocs/ualg.html A Course in Universal Algebra.]''  [[Springer-Verlag]]. {{isbn|3-540-90578-2}}. (available free online at the website mentioned)
* P. T. Johnstone, ''Stone Spaces'', Cambridge Studies in Advanced Mathematics 3, [[Cambridge University Press]], Cambridge, 1982. {{isbn|0-521-23893-5}}.
* {{cite book | editor1-last=Pedicchio | editor1-first=Maria Cristina | editor2-last=Tholen | editor2-first=Walter | title=Categorical foundations. Special topics in order, topology, algebra, and sheaf theory | series=Encyclopedia of Mathematics and Its Applications | volume=97 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2004 | isbn=0-521-83414-7 | zbl=1034.18001 }}
* {{cite book | last=Vickers | first=Steven | authorlink=Steve Vickers (computer scientist) | title=Topology via logic | series=Cambridge Tracts in Theoretical Computer Science | volume=5 | location=Cambridge | publisher=[[Cambridge University Press]] | year=1989 | isbn=0-521-36062-5 | zbl=0668.54001 }}
* [http://paultaylor.eu/ASD/ Abstract Stone Duality]

[[Category:Topology]]
[[Category:Order theory]]
[[Category:Duality theories]]</text>
      <sha1>mhbc1dpnn37cp5v64xier7oavgddcpd</sha1>
    </revision>
  </page>
  <page>
    <title>Theory of sonics</title>
    <ns>0</ns>
    <id>26556669</id>
    <revision>
      <id>863196514</id>
      <parentid>857044979</parentid>
      <timestamp>2018-10-09T09:05:01Z</timestamp>
      <contributor>
        <username>WereSpielChequers</username>
        <id>4071608</id>
      </contributor>
      <comment>[[WP:AWB/T|Typo fixing]], replaced: ,i → , i, ,th → , th, [[WP:AWB/T|typo(s) fixed]]: Therefore → Therefore,</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16576">{{Use dmy dates|date=July 2018}}
{{more footnotes|date=March 2010}}
'''The theory of sonics''' is a branch of [[continuum mechanics]] which describes the transmission of mechanical [[energy]] through [[oscillation|vibration]]s. The birth of the theory of sonics&lt;ref&gt;https://archive.org/stream/theoryofwavetran00consrich#page/n3/mode/2up&lt;/ref&gt;  can be considered the publication of the book ''A treatise on transmission of power by vibrations'' in 1918 by the [[Romanians|Romanian]] scientist [[Gogu Constantinescu]].
&lt;blockquote&gt;ONE of the fundamental problems of mechanical engineering is that of transmitting energy found in nature, after suitable transformation, to some point at which can be made available for performing useful work. The methods of transmitting power known and practised by engineers are broadly included in two classes: mechanical including hydraulic, pneumatic and wire rope methods; and electrical methods....According to the new system, energy is transmitted from one point to another, which may be at a considerable distance, by means of impressed variations of pressure or tension producing longitudinal vibrations in solid, liquid or gaseous columns. The energy is transmitted by periodic changes of pressure and volume in the longitudinal direction and may be described as wave transmission of power, or '''mechanical wave transmission'''. &amp;ndash; Gogu Constantinescu&lt;ref&gt;Constantinesco, G. Theory of Sonics: A Treatise on Transmission of Power  by Vibrations. The Admiralty, London, 1918&lt;/ref&gt;&lt;ref&gt;https://archive.org/stream/theoryofwavetran00consrich#page/n3/mode/2up&lt;/ref&gt;&lt;/blockquote&gt;

Later on the theory was expanded in electro-sonic, hydro-sonic, sonostereo-sonic and thermo-sonic.
The theory was the first chapter of [[compressible flow]] applications and has stated for the first time the mathematical theory of compressible fluid, and was considered a branch of [[continuum mechanics]].The laws discovered by Constantinescu, used in sonicity are  the same with the laws used in electricity.

==Book chapters==
The book ''A treatise on transmission of power by vibrations'' has the following chapters:

# Introductory
# Elementary physical principles
# Definitions
# Effects of [[Capacitor|capacity]], [[inertia]], [[friction]], and leakage on alternating currents
# Waves in long pipes
# Alternating in long pipes allowing for Friction
# [[Infinitesimal strain theory|Theory of displacements]] &amp;ndash; motors
# Theory of [[resonator]]s
# [[Alternating current#Effects at high frequencies|High-frequency currents]]
# Charged lines
# [[Transformer]]s

George Constantinescu defined his work as follow.

== Theory of sonics: applications ==
[[File:Airco DH-4.jpg|thumb|right|240px|No. 55 squadron of DH4s, the first aircraft to go into active service fitted with the C.C. Gear, arrived in France on 6 March 1917.]]
* [[Synchronization gear#The Constantinesco synchronization gear|The Constantinesco synchronization gear]], used on military aircraft in order to allow them to target opponents without damaging their own propellers.
* Automatic gear
* [[Drilling rig#Sonic .28vibratory.29 drilling|Sonic Drilling]], was one of the first applications developed by Constantinescu. A sonic drill head works by sending high frequency resonant vibrations  down the drill string to the drill bit, while the operator controls  these frequencies to suit the specific conditions of the soil/rock  geology.
* [[Torque converter|Torque Converter]].&lt;ref&gt;http://www.imsar.ro/SISOM_Papers_2007/D_18.pdf&lt;/ref&gt; A mechanical application of sonic theory on the transmission of power by vibrations. Power is transmitted from the engine to the output shaft through a system of oscillating levers and inertias.
* Sonic Engine

==Elementary physical principles==

If '''''v''''' is the velocity of which waves travel along the pipe, and '''''n''''' the number of the revolutions of the crank '''''a'''''&lt;br&gt;
The wavelength '''λ''' is ='''''v''/''n'''''&lt;br&gt;
Assuming that the pipe is finite and closed at the point '''''r''''' situated at a distance which is multiple of '''λ''', and considering that the piston is smaller than wavelength, at r the wave compression is stopped and reflected, the reflected wave traveling back along the pipe.

{| class="wikitable" border="1"
|+ Physics
! Elementary physical  principles !! Description
|-
| [[File:GoguConstantinescuFigureI Sonicitysvg.png|thumb|left|500px|'''Figure I''']]
Suppose the crank a to be rotating uniformly, causing the piston b to  reciprocate in the pipe c, which is full of liquid. At each in stroke of  the piston a zone of high pressure is formed, and these zones, shown by  shading, travel along the pipe away from the piston; between every pair  of high pressures zones is a zone of light pressure shown in the  picture. The pressure at any point in the pipe will go through a series  of values from a maximum to a minimum.
|-
| [[File:GoguConstantinescuRezonanta.svg|thumb|left|500px|'''Figure II''']]
Assuming that the pipe is finite and  closed at the point '''''r'''''  situated at a distance which is multiple of '''λ''',  and considering that the piston is smaller than the wavelength, at r  the  wave compression is stopped and reflected, the reflected wave  traveling  back along the pipe.If the crank continues rotation at  uniform speed, a zone of maximum pressure will start from the piston at  the same time the reflected wave came to the piston, as a result the  maximum pressure will double. At next rotation the amplitude is  increased, and so on, till the pipe burst.
|-
|[[File:GoguConstantinescuWaveTransmission.svg|thumb|left|500px|'''Figure III''']]
If instead of a closing pipe we  have a piston at r; the wave will be similar at piston b and piston m, the piston m therefore will have the same energy as the piston b; if the  distance between the b and m is not a multiple of '''λ''' the movement of m will differ in phase compared with the piston b. 
|-
| [[File:GoguConstantinescuLimitator.svg|thumb|left|500px|'''Figure IV''']]
If more energy is produced by piston b then is taken by piston m the energy will be reflected by piston m in  pipe, and the energy will accumulate till the pipe burst. If we have a  large volume vessel d, compared with the stroke volume of piston b, the  capacity d will act as a spring taking out the energy of direct or  reflected waves at high pressure, and giving back energy when pressure  falls. The mean pressure in d and in the pipe will be the same. The result of reflected waves will be a stationary wave in pipe with no increase of energy, and the pressure in the pipe will never exceed the  pressure limit.
|-
|[[File:GoguConstantinescuRezonantaFigure5.svg|thumb|left|500px|'''Figure V''']]
Waves are transmitted by a reciprocating piston along the pipe eeee. The pipe is closed at p, a distance of one complete wavelength. There are branches at one-half,  three-quarters and one full wavelength distances. If p is open and d is open, the motor l will rotate synchronous with motor a. If all valves are closed, there will be a stationary wave with extreme values at '''λ''' and '''λ/2''', (points b and d,) where the flow will be zero, and where the pressure will alternate between maximum and minimum values determined by the capacity of reservoir f. The maximum and minimum points do not move along the pipe, and no energy flows from generator a. If valve b is open, the motor m is able to take the energy from the line, the stationary half-wave between a and b being replaced by a traveling wave; between b and p a stationary wave will persist. If only valve c is open, since at this point the variation of pressure is always zero, no energy can be  taken out by the motor n, and the stationary wave will persist. If the  motor is connected in an intermediary point, part of the energy will be taken out by the motor while the stationary wave will persist at reduced amplitude. If the motor l is not capable of consuming all the energy of the generator a, then there will be a traveling wave a and a stationary wave. Therefore, there will be no point in the pipe where the pressure variation will be zero, and consequently, a motor connected at any point of the pipe will be able to use a portion of generated energy.
|}

==Definitions==

=== Alternating fluid currents ===

Considering any flow or pipes, if:

:: ω = the area section of the '''pipe''' measured in square centimeters;
:: ''v'' =the velocity of the fluid at any moment in centimeters per second;

and

:: ''i'' =the flow of liquid in square cubic centimeters per seconds,

then we have:

:: ''i'' =''v''ω

Assuming that the fluid current is produced by a piston having a simple harmonic movement, in a '''piston cylinder''' having a section &lt;big&gt;Ω&lt;/big&gt;.
If we have:

:: ''r'' =the equivalent of driving crank in centimeters
:: ''a'' =the angular velocity of the crank or the pulsations in radians degree per second.
:: ''n'' =the number of crank rotations per second.

Then:

:: The flow from the cylinder to the pipe is: '''''i''''' = '''''I''''' '''sin'''(''at''+''φ'')

Where:

:: '''''I''''' = '''''ra'''''Ω (the maximum alternating flow in square centimeters per second; Amplitude of the flow.
:: ''t'' = time in seconds
:: φ = the angle of the phase

If T= period of a complete alternation (one revolution of the crank) then:

:: ''a'' = 2π''n''; where ''n'' = 1/T

The effective current can be defined by the equation:
::&lt;math&gt;I_{eff}^2= \frac{1}{T}\int\limits_{0}^{T}i^2\,dt&lt;/math&gt; and the effective velocity is : &lt;math&gt;v_{eff}=  \frac{I_{eff}}{\omega}&lt;/math&gt;
The stoke volume &lt;big&gt;δ&lt;/big&gt; will be given by the relation:
::&lt;math&gt;\delta = 2r\Omega = 2\frac{I}{a}&lt;/math&gt;

==Alternating pressures==
The alternating pressures are very similar with alternating currents in electricity.
In a pipe were the currents are flowing, we will have:
::&lt;math&gt;p = H \sin{(at+\Phi)}+p_m&lt;/math&gt; ;where H is the maximum alternating pressure measured in kilograms per square centimeter. &lt;math&gt;\Phi =&lt;/math&gt; the angle of phase; &lt;math&gt;p_m&lt;/math&gt; representing the mean pressure in the pipe.
Considering the above formulas:
:: the minimum pressure is &lt;math&gt;P_{min} =P_m -H&lt;/math&gt; and maximum pressure is &lt;math&gt;P_{max}  =P_m +H&lt;/math&gt;
If p&lt;sub&gt;1&lt;/sub&gt; is the pressure at an arbitrary point and p&lt;sub&gt;2&lt;/sub&gt; pressure in another arbitrary point:
::The difference&lt;math&gt; h =p_1-p_2 = H\sin{(at+\Phi)}&lt;/math&gt; is defined as '''instantaneous ''[[hydromotive]]''''' force between point p&lt;sub&gt;1&lt;/sub&gt; and p&lt;sub&gt;2&lt;/sub&gt;, H representing the amplitude.
The effective hydromotive force will be: &lt;math&gt;H_{eff}  = \frac{H}{\sqrt{2}}&lt;/math&gt;

== Friction ==

In alternating current flowing a pipe the friction appear at the surface of the pipe and also in liquid itself. Therefore, the relation between the hydromotive and current can be written:

:: &lt;math&gt; H =Ri&lt;/math&gt;; where R= coefficient of friction in &lt;math&gt; \frac{kg.sec.}{cm.^5}&lt;/math&gt;

Using experiments R may be calculated from formula:

:: &lt;math&gt;R = \epsilon \frac{\gamma l v_{eff}}{2g \omega d} &lt;/math&gt;;

Where:

* &lt;math&gt;\gamma&lt;/math&gt; is the density of the liquid in kg per cm.&lt;sup&gt;3&lt;/sup&gt;
* l is length of the pipe in cm.
* g gravitational acceleration in cm. per sec.&lt;sup&gt;2&lt;/sup&gt;
* &lt;math&gt;\omega&lt;/math&gt; section of the pipe in square centimeters.
* v&lt;sub&gt;eff&lt;/sub&gt; the effective velocity
* d internal diameter of the pipe in centimeters.
* for water &lt;math&gt;\epsilon =0.02 + \frac{0.18}{\sqrt{v_{eff}d}}&lt;/math&gt; this is an approximation made by experiments.
* h is instantaneous hydromotive force
If we introduce &lt;math&gt;\epsilon&lt;/math&gt; in the formula, we get:

:: &lt;math&gt;R = \frac{\gamma l}{g \omega} \big( 0.01 \frac{v}{d}+ \frac{0.09}{d} \sqrt{ \frac{v_{eff}}{d}} \big)&lt;/math&gt; this is equivalent with:
:: &lt;math&gt;100k = \frac{v_{eff}}{d} + \frac{9}{d} \sqrt{\frac{v_{eff}}{d}} =\frac{v_{eff}}{d}\big( 1+\frac{9}{v_{eff}} \sqrt{\frac{v_{eff}}{d}} \big)&lt;/math&gt;; introducing k in formula, result thar &lt;math&gt;R =   k\frac{\gamma l}{g  \omega} &lt;/math&gt;
For pipes with greater diameter greater velocity can be achieve for same value of k.
The loss of power due to friction is calculated with:
::&lt;math&gt;W = \frac{1}{T} \int_0^T hi\,dt&lt;/math&gt;,  putting h=Ri result:
::&lt;math&gt;W =  \frac{1}{T} \int_0^T Ri^2\,dt=\frac{R}{T} \int_0^T i^2\,dt=\frac{RI^2}{2}&lt;/math&gt;
::Therefore:   &lt;math&gt;W =\frac{RI^2}{2}=\frac{HI}{2}=H_{eff}\times I_{eff}&lt;/math&gt;

==Capacity and condensers==
Definition: Hydraulic condensers are appliances for making alterations in value of fluid currents, pressures or phases of alternating fluid currents. The apparatus usually consists of a mobile solid body, which is dividing the liquid column, and fixed elastically in a middle position, in such way that it follows the movements of the liquid column.

The principal function of hydraulic condensers is to counteract inertia effects due to moving masses.

{| class="wikitable" border="1"
|-
! Hydraulic Condenser Drawing
! Theory
|-
| [[File:HidraulicCondeserConstantinescuFig6.gif|thumb|400px|left|Hydraulic Condenser Example]]
[[File:Muelle.gif|thumb|400px|left|[[Hooke's law]] for spring &lt;math&gt;F = m \frac{\mathrm{d}^2x}{\mathrm{d}t^2} = -k x &lt;/math&gt;; in this case x=f=piston movement.]]
[[File:Simple harmonic motion animation.gif|thumb|left|Simple Harmonic]]
The principal function of hydraulic condensers is to counteract inertia effects due to moving masses.

The capacity ''C'' of a condenser consisting of a piston of section ω on which the liquid pressure is acting, held in mean position by means of springs, is given by the equation:
&lt;br /&gt;
::ΔV=ωΔ''f''=''C''Δ''p''
where:
&lt;br /&gt;
::ΔV=the variation of volume of the space for liquid;
::Δ''f''=the variation of the longitudinal position of the piston,
and
&lt;br /&gt;
::Δ''p''=the variation of the pressure in the liquid.
&lt;br /&gt;
If the piston is held by a spring at any given moment:
&lt;br /&gt;
::''f''=''AF'' where
::A= a constant depending on the spring
&lt;br /&gt;
and
&lt;br /&gt;
::F=the force acting on the spring.
&lt;br /&gt;
In the condenser we will have:
&lt;br /&gt;
::Δ''F''=ωΔ''p''
&lt;br /&gt;
and
&lt;br /&gt;
::Δ''f''=AωΔ''p''
&lt;br /&gt;
Considering the above equations:
&lt;br /&gt;
::C=Aω&lt;sup&gt;2&lt;/sup&gt;
&lt;br /&gt;
and
::&lt;math&gt;F =\frac{f}{A}=\frac{f\omega}{C}&lt;/math&gt;
For a spring wire of circular section:
::&lt;math&gt;B= Ff&lt;/math&gt;
Where 
::B is the volume of [[Spring (mathematics)|spring]] in cubic centimeters
and 
::σ the allowable [[Yield (engineering)|stress]] of metal in kilograms per square centimeter.
::G the coefficient of transverse elasticity of the metal.
Therefore:
::B=mFf
m being a constant depending on σ and G.
If d is the diameter of the spring wire and the D the mean diameter of the spring. Then:
::&lt;math&gt;F=0.4\frac{d^3}{D}\sigma&lt;/math&gt;
so that:
::&lt;math&gt;d=\sqrt[3]{\frac{FD}{0.4\sigma} } &lt;/math&gt;
if we consider ::&lt;math&gt;n=\sqrt[3]{\frac{1}{0.4\sigma} } &lt;/math&gt; then:

::&lt;math&gt;d=n\sqrt[3]{FD}&lt;/math&gt;
The above equations are used in order to calculate the springs required for a condenser of a given capacity required to work at a given maximum stress.
|}

==Notes==
&lt;references/&gt;

==References==
*https://archive.org/stream/theoryofwavetran00consrich#page/n3/mode/2up
*http://www.rexresearch.com/constran/1constran.htm
*Constantinesco, G. Theory of Sonics: A Treatise on Transmission of Power by Vibrations. The Admiralty, London,  1918.
*Constantinesco, G., Sonics. Trans. Soc. of  Engineers, London, June 1959
*Clark, R.Edison, The Man Who Made the Future.  Macdonald and Jane's, London, 1977.
*McNeil, I., George Constantinesco, 1881–1965  and the Development of Sonic Power Transmission. Excerpt from volume  54, Trans. of the Newcomen Society, London, 1982&amp;ndash;83.
*Constantinesco, G., A Hundred Years of  Development in Mechanical Engineering. Trans. Soc. of Engineers, London,  Sept. 1954.
*http://www.gs-harper.com/Mining_Research/Power/Sonics005.asp
*Constantinesco, G. Transmission of Power the Present, the Future. Paper read before the North East Coast Institution of Engineers and Shipbuilders in Newcastle upon Tyne, on 4 December 1925. Reprinted by order of the Council. North East Coast  Institution of Engineers and Shipbuilders, Newcastle upon Tyne, 1926.
*https://web.archive.org/web/20090603102058/http://www.rri.ro/arh-art.shtml?lang=1&amp;sec=9&amp;art=3596
*http://www.utcluj.ro/download/doctorat/Rezumat_Carmen_Bal.pdf
*http://www.rexresearch.com/constran/1constran.htm
*http://imtuoradea.ro/auo.fmte/files-2008/MECANICA_files/MARCU%20FLORIN%201.pdf
*http://dynamicsflorio.webs.com/arotmm.htm

[[Category:George Constantinescu]]
[[Category:Mathematical physics]]
[[Category:Romanian inventions]]</text>
      <sha1>ilgsaog74yjeg551ty4ocx243ldd0qp</sha1>
    </revision>
  </page>
  <page>
    <title>Three spheres inequality</title>
    <ns>0</ns>
    <id>52378516</id>
    <revision>
      <id>861022315</id>
      <parentid>751510315</parentid>
      <timestamp>2018-09-24T17:09:53Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>/* Statement of the three spheres inequality */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1334">{{orphan|date=November 2016}}
{{unreferenced|date=November 2016}}
In [[mathematics]], the '''three spheres inequality''' bounds the &lt;math&gt;L^2&lt;/math&gt; norm of an [[harmonic function]] on a given [[sphere]] in terms of the &lt;math&gt;L^2&lt;/math&gt; norm of this function on two spheres, one with bigger radius and one with smaller radius.

== Statement of the three spheres inequality ==

Let &lt;math&gt;u&lt;/math&gt; be an harmonic function on &lt;math&gt;\mathbb R^n&lt;/math&gt;. Then for all &lt;math&gt;0 &lt; r_1 &lt; r &lt;r_2&lt;/math&gt; one has
:&lt;math&gt;\| u \|_{L^2(S_r)} \leq \| u \|^\alpha_{L^2(S_{r_1})} \| u \|^{1-\alpha}_{L^2(S_{r_2})} &lt;/math&gt;
where &lt;math&gt;S_\rho := \{ x \in \mathbb R^n \colon \vert x \vert = \rho\}&lt;/math&gt; for &lt;math&gt;\rho&gt;0&lt;/math&gt; is the sphere of radius &lt;math&gt;\rho&lt;/math&gt; centred at the origin and where
:&lt;math&gt;\alpha:=\frac{\log(r_2/r)}{\log(r_2/r_1)}.&lt;/math&gt;
Here we use the following normalisation for the &lt;math&gt;L^2&lt;/math&gt; norm:
:&lt;math&gt; \| u \|^2_{L^2(S_\rho)} := \rho^{1-n} \int_{\mathbb S^{n-1}} \vert u(\rho \hat x) \vert^2\, d\sigma(\hat x).&lt;/math&gt;

==References==

*{{citation|mr=1302068
|last=Korevaar|first= J.|last2=Meyers|first2= J. L. H.
|title=Logarithmic convexity for supremum norms of harmonic functions
|journal=Bull. London Math. Soc.|volume= 26 |year=1994|issue= 4|pages= 353–362|doi=10.1112/blms/26.4.353}}
 
[[Category:Inequalities]]</text>
      <sha1>6cyzuz1m7of7s69rerrfpnlk8p4iijp</sha1>
    </revision>
  </page>
  <page>
    <title>Totally bounded space</title>
    <ns>0</ns>
    <id>1528346</id>
    <revision>
      <id>863196277</id>
      <parentid>820686828</parentid>
      <timestamp>2018-10-09T09:01:08Z</timestamp>
      <contributor>
        <ip>78.132.80.153</ip>
      </contributor>
      <comment>fix awkward notation for emphasis</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11406">In [[topology]] and related branches of [[mathematics]], a '''totally bounded space''' is a space that can be [[cover (topology)|cover]]ed by [[finite set|finite]]ly many [[subset]]s of every fixed "size" (where the meaning of "size" depends on the given context). The smaller the size fixed, the more subsets may be needed, but any specific size should require only finitely many subsets. A related notion is a '''totally bounded set''', in which only a subset of the space needs to be covered. Every subset of a totally bounded space is a totally bounded set; but even if a space is not totally bounded, some of its subsets still will be.

The term '''precompact''' (or '''pre-compact''') is sometimes used with the same meaning, but ''pre-compact''  is also used to mean [[relatively compact]]. For subsets of a [[complete metric space]] 
these meanings coincide but in general they do not. See also [[#Use of the axiom of choice|use of the axiom of choice]] below.

== Definition for a metric space ==

A [[metric space]] &lt;math&gt; (M,d) &lt;/math&gt; is '''totally bounded''' 
if and only if for every real number &lt;math&gt; \varepsilon &gt;0&lt;/math&gt;, there exists
a finite collection of [[open ball]]s in ''M'' of radius &lt;math&gt; \varepsilon &lt;/math&gt; whose union contains&amp;nbsp;''M''. Equivalently, the metric space ''M'' is totally bounded if and only if for every &lt;math&gt; \varepsilon &gt;0&lt;/math&gt;, there exists a [[finite cover]] such that the radius of each element of the cover is at most &lt;math&gt;\varepsilon&lt;/math&gt;. This is equivalent to the existence of a finite [[ε-net (metric spaces)|ε-net]].{{sfn|Sutherland|1975|p=139}}

Each totally bounded space is [[Bounded set|bounded]] (as the union of finitely many bounded sets is bounded), but the converse is not true in general.
For example, an infinite set equipped with the [[discrete metric]] is bounded but not totally bounded.

If ''M'' is [[Euclidean space]] and d is the [[Euclidean distance]], then 
a subset (with the [[subspace topology]]) is totally bounded if and only if it is bounded.

A metric space is said to be '''cauchy-precompact''' if every sequence admits a Cauchy subsequence.  Note that cauchy-precompact is not the same as precompact (relative compact), because cauchy-precompact is an intrinsic property of the space, while precompact depends on the ambient space. Thus for metric spaces we have: compactness = cauchy-precompactness + completeness. It turns out that the space is cauchy-precompact if and only if it is totally bounded. Therefore, both names (cauchy-precompact and totally bounded) can be used interchangeably.

== Definitions in other contexts==

The general [[logic (symbolic)|logic]]al form of the [[definition]] is: a subset ''S'' of a space ''X'' is a totally bounded set if and only if, [[given any]] size ''E'', [[there exist]] a [[natural number]] ''n'' and a [[family of sets|family]] ''A''&lt;sub&gt;1&lt;/sub&gt;, ''A''&lt;sub&gt;2&lt;/sub&gt;, ..., ''A''&lt;sub&gt;''n''&lt;/sub&gt; of subsets of ''X'', such that ''S'' is contained in the [[union (set theory)|union]] of the family (in other words, the family is a ''finite cover'' of ''S''), and such that each set ''A''&lt;sub&gt;''i''&lt;/sub&gt; in the family is of size ''E'' (or less). In [[mathematical symbols]]:

: &lt;math&gt; \forall E\; \exists n \in \mathbb{N}\; A_1, A_2, \ldots, A_n \subseteq X \left ( S \subseteq \bigcup_{i=1}^n A_i \text{ and for } i = 1, \ldots, n \operatorname{size}(A_i) \leq E \right ). \! &lt;/math&gt;

The space ''X'' is a totally bounded space if and only if it is a totally bounded set when considered as a subset of itself.
(One can also define totally bounded spaces directly, and then define a set to be totally bounded if and only if it is totally bounded when considered as a [[subspace (topology)|subspace]].)

The terms "space" and "size" here are vague, and they may be made precise in various ways:

A subset ''S'' of a [[metric space]] ''X'' is totally bounded if and only if, given any [[positive number|positive]] [[real number]] ''E'', there exists a finite cover of ''S'' by subsets of ''X'' whose [[diameter]]s are all less than ''E''. (In other words, a "size" here is a positive real number, and a subset is of size ''E'' if its diameter is less than ''E''.) Equivalently, ''S'' is totally bounded if and only if, given any ''E'' as before, there exist elements ''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;, ..., ''a''&lt;sub&gt;''n''&lt;/sub&gt; of ''X'' such that ''S'' is contained in the union of the ''n'' [[open ball]]s of radius ''E'' around the points ''a''&lt;sub&gt;''i''&lt;/sub&gt;.

A subset ''S'' of a [[topological vector space]], or more generally [[topological abelian group]], ''X'' is totally bounded if and only if, given any [[neighbourhood (topology)|neighbourhood]] ''E'' of the [[identity element|identity (zero) element]] of ''X'', there exists a finite cover of ''S'' by subsets of ''X'' each of which is a [[translate (geometry)|translate]] of a subset of ''E''. (In other words, a "size" here is a neighbourhood of the identity element, and a subset is of size ''E'' if it is translate of a subset of ''E''.) Equivalently, ''S'' is totally bounded if and only if, given any ''E'' as before, there exist elements ''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;, ..., ''a''&lt;sub&gt;''n''&lt;/sub&gt; of ''X'' such that ''S'' is contained in the union of the ''n'' translates of ''E'' by the points ''a''&lt;sub&gt;''i''&lt;/sub&gt;.

A [[topological group]] ''X'' is ''left''-totally bounded if and only if it satisfies the definition for topological abelian groups above, using ''left'' translates. That is, use ''a''&lt;sub&gt;''i''&lt;/sub&gt;''E'' in place of ''E'' + ''a''&lt;sub&gt;''i''&lt;/sub&gt;. Alternatively, ''X'' is ''right''-totally bounded if and only if it satisfies the definition for topological abelian groups above, using ''right'' translates. That is, use ''Ea''&lt;sub&gt;''i''&lt;/sub&gt; in place of ''E'' + ''a''&lt;sub&gt;''i''&lt;/sub&gt;. (In other words, a "size" here is unambiguously a neighbourhood of the identity element, but there are two notions of ''whether'' a set is of a given size: a left notion based on left translation and a right notion based on right translation.)

Generalising the above definitions, a subset ''S'' of a [[uniform space]] ''X'' is totally bounded if and only if, given any [[entourage (topology)|entourage]] ''E'' in ''X'', there exists a finite cover of ''S'' by subsets of ''X'' each of whose [[Cartesian square]]s is a subset of ''E''. (In other words, a "size" here is an entourage, and a subset is of size ''E'' if its Cartesian square is a subset of ''E''.) Equivalently, ''S'' is totally bounded if and only if, given any ''E'' as before, there exist subsets ''A''&lt;sub&gt;1&lt;/sub&gt;, ''A''&lt;sub&gt;2&lt;/sub&gt;, ..., ''A''&lt;sub&gt;''n''&lt;/sub&gt; of ''X'' such that ''S'' is contained in the union of the ''A''&lt;sub&gt;''i''&lt;/sub&gt; and, whenever the elements ''x'' and ''y'' of ''X'' both belong to the same set ''A''&lt;sub&gt;''i''&lt;/sub&gt;, then (''x'',''y'') belongs to ''E'' (so that ''x'' and ''y'' are close as measured by ''E'').

The definition can be extended still further, to any category of spaces with a notion of [[compactness (topology)|compactness]] and [[Cauchy completion]]: a space is totally bounded if and only if its completion is compact.

== Examples and nonexamples ==
* A subset of the [[real line]], or more generally of (finite-dimensional) [[Euclidean space]], is totally bounded if and only if it is [[bounded set|bounded]]. Archimedean property is used.
* The [[unit ball]] in a [[Hilbert space]], or more generally in a [[Banach space]], is totally bounded if and only if the space has finite [[dimension (linear algebra)|dimension]].
* Every [[compact set]] is totally bounded, whenever the concept is defined.
* Every totally bounded metric space is bounded. However, not every bounded metric space is totally bounded.{{sfn|Willard|2004|p=182}}
* A subset of a [[complete metric space]] is totally bounded if and only if it is [[relatively compact set|relatively compact]] (meaning that its [[closure (topology)|closure]] is compact).
* In a [[locally convex space]] endowed with the [[weak topology (polar topology)|weak topology]] the precompact sets are exactly the [[bounded set (topological vector space)|bounded set]]s.
* A metric space is [[separable space|separable]] if and only if it is [[homeomorphism|homeomorphic]] to a totally bounded metric space.{{sfn|Willard|2004|p=182}}
* An infinite metric space with the [[discrete metric]] (the distance between any two [[Distinct (mathematics)|distinct]] points is 1) is ''not'' totally bounded, even though it is bounded.

== Relationships with compactness and completeness ==

There is a nice relationship between total boundedness and [[compactness (topology)|compactness]]:

Every compact metric space is totally bounded.

Every metric space that is complete (i.e. every Cauchy sequence of points in the space converges to a point within the space) and totally bounded is compact.

A [[uniform space]] is compact [[if and only if]] it is both totally bounded and [[Cauchy complete]]. This can be seen as a generalisation of the [[Heine–Borel theorem]] from [[Euclidean space]]s to arbitrary spaces: we must replace [[bounded set|boundedness]] with total boundedness (and also replace [[closed set|closedness]] with completeness).

There is a complementary relationship between total boundedness and the process of [[Cauchy completion]]: A uniform space is totally bounded if and only if its Cauchy completion is totally bounded. (This corresponds to the fact that, in Euclidean spaces, a set is bounded if and only if its closure is bounded.)

Combining these theorems, a uniform space is totally bounded if and only if its completion is compact. This may be taken as an alternative definition of total boundedness. Alternatively, this may be taken as a definition of ''precompactness'', while still using a separate definition of total boundedness. Then it becomes a theorem that a space is totally bounded if and only if it is precompact. (Separating the definitions in this way is useful in the absence of the [[axiom of choice]]; see the next section.)

== Use of the axiom of choice ==

The properties of total boundedness mentioned above rely in part on the [[axiom of choice]]. In the absence of the axiom of choice, total boundedness and precompactness must be distinguished. That is, we define total boundedness in elementary terms but define precompactness in terms of compactness and Cauchy completion. It remains true (that is, the proof does not require choice) that every precompact space is totally bounded; in other words, if the completion of a space is compact, then that space is totally bounded. But it is no longer true (that is, the proof requires choice) that every totally bounded space is precompact; in other words, the completion of a totally bounded space might not be compact in the absence of choice.

==See also==

* [[Measure of non-compactness]]
* [[Locally compact space]]

==Notes==
{{reflist}}

== References ==

{{refbegin}}
*{{cite book | author=Willard, Stephen | title=General Topology | publisher=Dover Publications | year=2004 | isbn=0-486-43479-6}}
*{{cite book | author=Sutherland, W.A. | title=Introduction to metric and topological spaces| publisher=Oxford University Press | year=1975 | isbn=0-19-853161-3 | zbl=0304.54002 }}
{{refend}}

{{DEFAULTSORT:Totally Bounded Space}}
[[Category:Uniform spaces]]
[[Category:Metric geometry]]
[[Category:Compactness (mathematics)]]</text>
      <sha1>nguzct1rc1ogxcbi7j8gh99pc3ke783</sha1>
    </revision>
  </page>
  <page>
    <title>Tunnell's theorem</title>
    <ns>0</ns>
    <id>6144888</id>
    <revision>
      <id>853372435</id>
      <parentid>851441490</parentid>
      <timestamp>2018-08-04T08:53:37Z</timestamp>
      <contributor>
        <username>Fruits Monster</username>
        <id>2432305</id>
      </contributor>
      <minor/>
      <comment>/* References */ added link.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2713">In [[number theory]], '''Tunnell's theorem''' gives a partial resolution to the [[congruent number problem]], and under the [[Birch and Swinnerton-Dyer conjecture]], a full resolution.

==Congruent number problem==
{{main|Congruent number problem}}
The congruent number problem asks which [[positive integers]] can be the area of a right triangle with all three sides rational.  Tunnell's theorem relates this to the number of integral solutions of a few fairly simple [[Diophantine equation]]s.

==Theorem==
For a given square-free integer ''n'', define

:&lt;math&gt;\begin{align}
A_n &amp; =  \#\{ (x,y,z) \in \mathbb{Z}^3 \mid n = 2x^2 + y^2 + 32z^2 \}, \\
B_n &amp; =  \#\{ (x,y,z) \in \mathbb{Z}^3 \mid n = 2x^2 + y^2 + 8z^2 \}, \\
C_n &amp; =  \#\{ (x,y,z) \in \mathbb{Z}^3 \mid n = 8x^2 + 2y^2 + 64z^2 \}, \\
D_n &amp; =  \#\{ (x,y,z) \in \mathbb{Z}^3 \mid n = 8x^2 + 2y^2 + 16z^2 \}.
\end{align}&lt;/math&gt;

Tunnell's theorem states that supposing ''n'' is a congruent number, if ''n'' is odd then 2''A''&lt;sub&gt;''n''&lt;/sub&gt; = ''B''&lt;sub&gt;n&lt;/sub&gt; and if ''n'' is even then 2''C''&lt;sub&gt;''n''&lt;/sub&gt; = ''D''&lt;sub&gt;''n''&lt;/sub&gt;.  Conversely, if the [[Birch and Swinnerton-Dyer conjecture]] holds true for [[elliptic curve]]s of the form &lt;math&gt;y^2 = x^3 - n^2x&lt;/math&gt;, these equalities are sufficient to conclude that ''n'' is a congruent number.

==History==
The theorem is named for [[Jerrold B. Tunnell]], a number theorist at [[Rutgers University]], who proved it in {{Harvtxt|Tunnell|1983}}.

==Importance==
The importance of Tunnell's theorem is that the criterion it gives is testable by a finite calculation.  For instance, for a given ''n'', the numbers ''A''&lt;sub&gt;''n''&lt;/sub&gt;,''B''&lt;sub&gt;''n''&lt;/sub&gt;,''C''&lt;sub&gt;''n''&lt;/sub&gt;,''D''&lt;sub&gt;''n''&lt;/sub&gt; can be calculated by exhaustively searching through ''x'',''y'',''z'' in the range &lt;math&gt;-\sqrt{n},\ldots,\sqrt{n}&lt;/math&gt;.

==See also==
{{Div col}}
*[[Birch and Swinnerton-Dyer conjecture]]
*[[Congruent number]]
{{Div col end}}

==References==
* {{citation
  | last = Koblitz
  | first = Neal
  | authorlink = Neal Koblitz
  | title = Introduction to Elliptic Curves and Modular Forms
  | edition = 2nd
  | series = [[Graduate Texts in Mathematics]] (Book 97)
  | publisher = Springer-Verlag
  | year = 2012
  | isbn = 978-1-4612-6942-7}}
* {{citation
  | last = Tunnell
  | first = Jerrold B.
  | authorlink = Jerrold B. Tunnell
  | title = A classical Diophantine problem and modular forms of weight 3/2
  | journal = [[Inventiones Mathematicae]]
  | volume = 72
  | issue = 2
  | pages = 323–334
  | year = 1983
  | doi = 10.1007/BF01389327
  | url = http://www.digizeitschriften.de/dms/img/?PID=GDZPPN002099403}}

[[Category:Theorems in number theory]]
[[Category:Diophantine equations]]</text>
      <sha1>n8kw6fyx12qa7i0nlhw02xwz5pjn49s</sha1>
    </revision>
  </page>
  <page>
    <title>Vibrational circular dichroism</title>
    <ns>0</ns>
    <id>9233359</id>
    <revision>
      <id>855069302</id>
      <parentid>845188485</parentid>
      <timestamp>2018-08-15T18:34:39Z</timestamp>
      <contributor>
        <username>Annafarrell 2</username>
        <id>34173608</id>
      </contributor>
      <comment>added a section about modeling VCD</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22410">'''Vibrational circular dichroism''' ('''VCD''') is a [[spectroscopy|spectroscopic]] technique which detects differences in attenuation of left and right [[circular polarization|circularly polarized light]] passing through a sample. It is the extension of [[circular dichroism]] spectroscopy into the [[infrared]] and near infrared ranges.&lt;ref&gt;[http://planetphysics.org/?op=getobj;from=objects;id=410 Principles of IR and NIR Spectroscopy]&lt;/ref&gt;

Because VCD is sensitive to the mutual orientation of distinct groups in a molecule, it provides three-dimensional structural information. Thus, it is a powerful technique as VCD spectra of enantiomers can be simulated using ''ab initio'' calculations, thereby allowing the identification of absolute configurations of small molecules in solution from VCD spectra. Among such quantum computations of VCD spectra resulting from the chiral properties of small organic molecules are those based on [[density functional theory]] (DFT) and [[gauge-invariant]] [[atomic orbitals]] (GIAO). As a simple example of the experimental results that were obtained by VCD are the spectral data obtained within the carbon-hydrogen (C-H) stretching region of 21 [[amino acid]]s in [[heavy water]] solutions. Measurements of vibrational optical activity (VOA) have thus numerous applications, not only for small molecules, but also for large and complex biopolymers such as muscle proteins ([[myosin]], for example) and [[DNA]].

==Vibrational modes==
&lt;gallery&gt;
File:Symmetrical stretching.gif
File:Asymmetrical stretching.gif
File:Scissoring.gif
File:Twisting.gif
File:Wagging.gif
File:Agitation moléculaire en milieu aqueux.PNG
&lt;/gallery&gt;

==Theory==
While the fundamental quantity associated with the infrared absorption is the dipole strength, the differential absorption is also proportional to the rotational strength, a quantity which depends on both the electric and magnetic dipole transition moments. Sensitivity of the handedness of a molecule toward circularly polarized light results from the form of the rotational strength. A rigorous theoretical development of VCD was developed concurrently by the late Professor P.J. Stephens, FRS, at the [[University of Southern California]],&lt;ref&gt;{{cite journal | doi = 10.1021/j100251a006 | volume=89 | title=Theory of vibrational circular dichroism | year=1985 | journal=The Journal of Physical Chemistry | pages=748–752 | author=Stephens Philip J}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | doi = 10.1021/j100291a009 | volume=91 | title=Gauge dependence of vibrational magnetic dipole transition moments and rotational strengths | year=1987 | journal=The Journal of Physical Chemistry | pages=1712–1715 | author=Stephens P. J.}}&lt;/ref&gt; and the group of Professor A.D. Buckingham, FRS, at [[Cambridge University]] in the UK,&lt;ref&gt;{{cite journal | doi = 10.1016/0301-0104(87)85017-6 | volume=112 | title=Velocity-dependent property surfaces and the theory of vibrational circular dichroism | year=1987 | journal=Chemical Physics | pages=1–14 | author=Buckingham A.D., Fowler P.W., Galwas P.A.| bibcode=1987CP....112....1B }}&lt;/ref&gt; and first implemented analytically in the Cambridge Analytical Derivative Package (CADPAC) by R.D. Amos.&lt;ref&gt;{{cite journal | doi = 10.1016/0009-2614(87)80046-5 | volume=133 | title=Efficient calculation of vibrational magnetic dipole transition moments and rotational strengths | year=1987 | journal=Chemical Physics Letters | pages=21–26 | author=Amos R.D., Handy N.C., Jalkanen K.J., Stephens P.J.| bibcode=1987CPL...133...21A }}&lt;/ref&gt; Previous developments by D.P. Craig and T. Thirmachandiman at the [[Australian National University]]&lt;ref&gt;{{cite journal | doi = 10.1080/00268977800100611 | volume=35 | title=A theory of vibrational circular dichroism in terms of vibronic interactions | year=1978 | journal=Molecular Physics | pages=825–840 | author=Craig D.P., Thirunamachandran T.}}&lt;/ref&gt; and Larry A. Nafie and Teresa B. Freedman at [[Syracuse University]]&lt;ref&gt;{{cite journal | doi = 10.1063/1.444741 | volume=78 | title=Vibronic coupling theory of infrared vibrational transitions | year=1983 | journal=The Journal of Chemical Physics | pages=7108–7116 | author=Nafie Laurence A., Freedman Teresa B.| bibcode=1983JChPh..78.7108N }}&lt;/ref&gt; though theoretically correct, were not able to be straightfowardly implemented, which prevented their use. Only with the development of the Stephens formalism as implemented in CADPAC did a fast efficient and theoretically rigorous theoretical calculation of the VCD spectra of chiral molecules become feasible. This also stimulated the commercialization of VCD instruments by Biotools, Bruker, Jasco and Thermo-Nicolet (now Thermo-Fisher).

==Peptides and proteins==
Extensive VCD studies have been reported for both polypeptides and several proteins in solution;&lt;ref&gt;{{cite journal|title=Vibrational Circular Dichroism of Polypeptides XII. Re-evaluation of the Fourier Transform Vibrational Circular Dichroism of Poly-gamma-Benzyl-L-Glutamate|author=P. Malon|author2=R. Kobrinskaya|author3=T. A. Keiderling|journal =Biopolymers |volume=27|pages= 733–746 |date=1988|pmid=2454680|issue=5|doi=10.1002/bip.360270503}}&lt;/ref&gt;&lt;ref&gt;{{cite book|chapter=Vibrational Circular Dichroism of Biopolymers|display-authors=6|author=T. A. Keiderling|author2=S. C. Yasui|author3=U. Narayanan|author4=A. Annamalai|author5=P. Malon|author6=R. Kobrinskaya|author7=L. Yang |title=Spectroscopy of Biological Molecules New Advances|editor= E. D. Schmid|editor2= F. W. Schneider|editor3= F. Siebert|pages= 73–76 |date=1988|isbn=0-471-91934-9|publisher=Wiley}}
&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Vibrational Circular Dichroism of Polypeptides and Proteins|author=S. C. Yasui|author2=T. A. Keiderling|journal=Mikrochimica Acta|doi=10.1007/BF01349780|volume= II|pages= 325–327 |date=1988}}&lt;/ref&gt; several recent reviews were also compiled.&lt;ref&gt;{{cite journal|chapter=Chapter 8. Vibrational Circular Dichroism of Proteins Polysaccharides and Nucleic Acids|author= T. A. Keiderling |title=Physical Chemistry of Food Processes|volume= 2 Advanced Techniques, Structures and Applications|editor=I.C. Baianu|editor2=H. Pessen|editor3=T. Kumosinski|publisher= Van Norstrand-Reinhold|place=New York |date=1993|pages= 307–337}}&lt;/ref&gt;&lt;ref&gt;{{cite book|chapter=Spectroscopic characterization of Unfolded peptides and proteins studied with infrared absorption and vibrational circular dichroism spectra|author= T. A. Keiderling|author2= Qi Xu|last-author-amp= yes|title= Advances in Protein Chemistry |volume =62|editor= George Rose|publisher= Academic Press|place=New York|date=2002|pages= 111–161}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Protein and Peptide Secondary Structure and Conformational Determination with Vibrational Circular Dichroism|doi=10.1016/S1367-5931(02)00369-1|date=2002|last1=Keiderling|first1=Timothy A|journal=Current Opinion in Chemical Biology|volume=6|issue=5|pages=682–8|pmid=12413554}}&lt;/ref&gt;&lt;ref&gt;{{cite book|chapter=Review: Conformational Studies of Peptides with Infrared Techniques|author= Timothy A. Keiderling|author2= R. A. G. D. Silva|last-author-amp= yes|title= Synthesis of Peptides and Peptidomimetics|editor=M. Goodman|editor2=G. Herrman|editor3=Houben-Weyl|volume= 22Eb|publisher= Georg Thiem Verlag|place=New York|date=2002|pages= 715–738 (written in 2000}}&lt;/ref&gt; An extensive but not comprehensive VCD publications list is also provided in the "References" section. The published reports over the last 22 years have established VCD as a powerful technique with improved results over those previously obtained by visible/UV circular dichroism (CD) or [[optical rotatory dispersion]] (ORD) for proteins and nucleic acids.

The effects due to solvent on stabilizing the structures (conformers and zwitterionic species) of amino acids and peptides and the corresponding effects seen in the vibrational circular dichroism (VCD) and Raman optical activity spectra (ROA) have been recently documented by a combined theoretical and experimental work on L-alanine and N-acetyl L-alanine N'-methylamide,.&lt;ref&gt;{{cite journal | doi = 10.1007/s00214-007-0361-z | volume=119 | title=Role of hydration in determining the structure and vibrational spectra of L-alanine and N-acetyl L-alanine N′-methylamide in aqueous solution: a combined theoretical and experimental approach | year=2007 | journal=Theoretical Chemistry Accounts | pages=191–210 | author=Jalkanen K. J., Degtyarenko I. M., Nieminen R. M., Cao X., Nafie L. A., Zhu F., Barron L. D.}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|doi=10.1021/jp972299m | volume=102 | title=Theoretical Study of AqueousN-Acetyl-l-alanineN‘-Methylamide: Structures and Raman, VCD, and ROA Spectra | year=1998 | journal=The Journal of Physical Chemistry B | pages=2587–2602 | author=Han Wen-Ge, Jalkanen K. J., Elstner Marcus, Suhai Sándor}}&lt;/ref&gt; Similar effects have also been seen in the nuclear magnetic resonance (NMR) spectra by the Weise and Weisshaar NMR groups at the [[University of Wisconsin-Madison]].&lt;ref&gt;{{cite journal | doi = 10.1021/ja993953+ | volume=122 | title=Do Bridging Water Molecules Dictate the Structure of a Model Dipeptide in Aqueous Solution? | year=2000 | journal=Journal of the American Chemical Society | pages=5642–5643 | author=Poon Chi-Duen, Samulski Edward T., Weise Christoph F., Weisshaar James C.}}&lt;/ref&gt;

==Nucleic acids==
VCD spectra of nucleotides, synthetic polynucleotides and several nucleic acids, including DNA, have been reported and assigned in terms of the type and number of helices present in A-, B-, and Z-DNA.

==Instrumentation==
VCD can be regarded as a relatively recent technique. Although Vibrational Optical Activity and in particular Vibrational Circular Dichroism, has been known for a long time, the first VCD instrument was developed in 1973&lt;ref&gt;L. A. Nafie, T. A. Keiderling, P. J. Stephens, JACS 1973, 98, 2715&lt;/ref&gt; and commercial instruments were available only since 1997.&lt;ref&gt;[http://btools.com/docs/BioTools_Catalog.pdf BioTools Catalog, page 4] {{webarchive |url=https://web.archive.org/web/20141224025457/http://btools.com/docs/BioTools_Catalog.pdf |date=December 24, 2014 }}&lt;/ref&gt;

For biopolymers such as proteins and nucleic acids, the difference in absorbance between the levo- and dextro- configurations is five orders of magnitude smaller than the
corresponding (unpolarized) absorbance. Therefore, VCD of biopolymers requires the use of very sensitive, specially built instrumentation as well as time-averaging over relatively long intervals of time even with such sensitive VCD spectrometers.
Most CD instruments produce left- and right- circularly polarized light which is then either sine-wave or square-wave modulated, with subsequent phase-sensitive detection and lock-in amplification of the detected signal. In the case of FT-VCD,
a photo-elastic modulator (PEM) is employed in conjunction with an FTIR interferometer set-up. An example is that of a Bomem model MB-100 FTIR interferometer equipped with additional polarizing optics/ accessories needed for recording VCD spectra.
A parallel beam emerges through a side port of the interferometer which passes first through a wire grid linear polarizer and then through an octagonal-shaped ZnSe crystal PEM which modulates the polarized beam at a fixed, lower frequency such as 37.5&amp;nbsp;kHz. A mechanically stressed crystal such as ZnSe exhibits [[birefringence]] when stressed by an adjacent piezoelectric transducer. The linear polarizer is positioned close to, and at 45 degrees, with respect to the ZnSe crystal axis. The polarized radiation focused onto the detector is doubly modulated, both by the PEM and by the interferometer setup. A very low noise detector, such as MCT (HgCdTe), is also selected for the VCD signal phase-sensitive detection. The first dedicated VCD spectrometer brought to market was the ChiralIR from Bomem/BioTools, Inc. in 1997. Today, Thermo-Electron, Bruker, Jasco and BioTools offer either VCD accessories or stand-alone instrumentation.&lt;ref&gt;{{cite journal|title=Vibrational Circular Dichroism: A New Tool for the Solution-State Determination of the Structure and Absolute Configuration of Chiral Natural Product Molecules|author= Laurence A. Nafie|journal= Natural Product Communications|volume= 3|issue=3|pages= 451–466|date=2008}}&lt;/ref&gt; To prevent detector saturation an appropriate, long wave pass filter is placed before the very low noise MCT detector, which allows only radiation below 1750&amp;nbsp;cm&lt;sup&gt;−1&lt;/sup&gt; to reach the MCT detector; the latter however measures radiation only down to 750&amp;nbsp;cm&lt;sup&gt;−1&lt;/sup&gt;. FT-VCD spectra accumulation of the selected sample solution is then carried out, digitized and stored by an in-line computer. Published reviews that compare various VCD methods are also available.&lt;ref&gt;{{cite journal|title=Polarization Modulation Fourier Transform Infrared Spectroscopy with Digital Signal Processing: Comparison of Vibrational Circular Dichroism Methods|author=Jovencio Hilario|author2=David Drapcho|author3=Raul Curbelo|author4=Timothy A. Keiderling|journal= Applied Spectroscopy |volume=55|pages= 1435–1447|date=2001|doi=10.1366/0003702011953810|issue=11|bibcode = 2001ApSpe..55.1435H }}&lt;/ref&gt;&lt;ref&gt;{{cite book|chapter=Vibrational circular dichroism of biopolymers. Summary of methods and applications|author= Timothy A. Keiderling|author2= Jan Kubelka|author3= Jovencio Hilario|title=Vibrational spectroscopy of polymers and biological systems|editor= Mark Braiman|editor2= Vasilis Gregoriou |publisher=CRC Press|place= Boca Raton, FL|date=2006|pages= 253–324}} (written in 2000, updated in 2003)&lt;/ref&gt;

== Modeling VCD Spectra ==
In 1994, researchers at the University of Southern California (USC)[[United States Army Research Laboratory|, U.S. Army Research Laboratory]] (USARL), and Lorentzian Inc., reported an accuracy ranking of [[Quantum mechanics|quantum mechanical]] analytical techniques to theoretically determine vibrational frequencies, [[dipole]] strengths, and rotational strengths of an organic molecule. This ranking claimed [[Density functional theory#Applications|density functional theory]] (DFT) at the B3LYP/6-31G* level of theory was the most accurate and effective computation used to model and vibrational [[circular dichroism]] (VCD)  spectra. &lt;ref&gt;{{Cite journal|last=Stephens|first=P. J.|last2=Devlin|first2=F. J.|last3=Chabalowski|first3=C. F.|last4=Frisch|first4=M.J.|date=1994|title=Ab Initio Calculation of Vibrational Absorption and Circular Dichroism Spectra Using Density Functional Force Fields|url=https://pubs.acs.org/doi/10.1021/j100096a001|journal=Journal of Physical Chemistry|volume=98|pages=11623-11627|via=}}&lt;/ref&gt; Electronic structure computations, by solving either the [[Schrödinger equation]] or the [[Kohn–Sham equations|Kohn-Sham equation]], can be used to obtain information about ground state energy, bond vibrational frequency, and electron density (Ψ&lt;sup&gt;2&lt;/sup&gt;), and other characteristics.&lt;ref name=":0"&gt;{{Cite book|title=Beyond the Molecular Frontier: Challenges for Chemistry and Chemical Engineering|last=|first=|publisher=Committee on Challenges for the Chemical Sciences in the 21st Century, National Research Council|year=2003|isbn=0-309-50512-7|location=|pages=}}&lt;/ref&gt; 

Theoretical calculations of vibrational energy often involve the [[Schrödinger equation|Schrödinger’s]] equation with the [[Hamiltonian (quantum mechanics)|Hamiltonian operator]]. The computers that process this massive calculation can incorporate the molecule’s kinetic energy as well as the vast number of repulsions and columbic attractions between subatomic particles. The calculations are said to be very costly, as they are difficult and take a long time to accomplish. This is partially because integrating the electron-electron interactions into the equation involves determining electron [[Exchange interaction|exchange interactions]].&lt;ref&gt;{{Cite web|url=https://web.ornl.gov/~kentpr/thesis/pkthnode8.html|title=1.2 Electronic structure calculations|website=web.ornl.gov|access-date=2018-08-15}}&lt;/ref&gt; Methods like DFT and the [[Hartree–Fock method|Hartree Fock]] look at a group of atomic orbitals referred to as a [[Basis set (chemistry)|basis set]] to estimate wave function. The wave function can be used to determine frequency, wavelength, energy etc.&lt;ref&gt;{{Cite book|url=http://physics.mq.edu.au/~jcresser/Phys301/Chapters/Chapter3.pdf|title=Quantum Physics Notes|last=Cresser|first=J.D.|publisher=|year=2009|isbn=|location=|pages=14-26}}&lt;/ref&gt; Hartree Fock operates with a feedback loop called a self-consistent field that continuously refines the wave function estimates until the value falls within a satisfactory change in energy threshold that they converge the calculation and determine an approximated wavefunction.&lt;ref&gt;{{Cite book|url=http://vergil.chemistry.gatech.edu/notes/hf-intro/hf-intro.pdf|title=An Introduction to Hartree-Fock Molecular Orbital|last=Sherril|first=David C.|publisher=|year=2000|isbn=|location=|pages=1-8}}&lt;/ref&gt; &lt;ref&gt;{{Cite web|url=https://www.cup.uni-muenchen.de/oc/zipse/teaching/computational-chemistry-1/topics/convergence-in-hartree-fock-calculations/|title=- Convergence in Hartree-Fock Calculations|website=www.cup.uni-muenchen.de|access-date=2018-08-15}}&lt;/ref&gt;

The study conducted by USC, USARL, and Lorentzian Inc. analyzed the infrared ([[Fourier-transform infrared spectroscopy|FTIR]]) and VCD spectra of the chiral molecule 4-methyl-2-oxetanone. Lorentzian bands were fit to FTIR and VCD spectra to obtain their peak intensity, line width, and frequency, which may be used to infer properties such as dipole strengths and rotational strengths.&lt;ref name=":0" /&gt; These experimental values were then compared to theoretical results. The scientists reported that DFT computations evaluated with the B3LYP functional best modelled FTIR and VCD spectra. To achieve a better cost to benefit ratio the researchers recommended pairing this method with the 6-31* [[Basis set (chemistry)|basis set]]. The second best method reported was the second order [[Møller–Plesset perturbation theory]] (MP2). The third and fourth best calculation methods were DFT with the BLYP and LSDA functionals respectively. The researchers stated that ''Ab initio'' [[Hartree–Fock method| Hartree Fock]] Self Consistent Field (HF-SCF) computations modelled FTIR and VCD spectra with the lowest accuracy compared to other methodologies investigated.&lt;ref name=":0" /&gt;

The significance in claimed improvement in accuracy of DFT computations over ''ab'' ''initio'' techniques was that DFT computations were reported to quicken computational speed. By evaluating an effective potential using electron density, which can by specified across three degrees of freedom, DFT sidesteps the evaluation of coulombic potentials between every single electron, which is specified over 3N degrees of freedom (where N is the number of electrons). The B3LYP basis set is a hybrid between direct Hartree-Fock exchange terms as well as local and gradient corrections for [[Exchange interaction|exchange]] and [[Electronic correlation|correlation]] interactions. Therefore, the B3LYP functional is claimed to efficiently model FTIR and VCD of some molecules ''via'' DFT at a fraction of the cost. &lt;ref name=":0" /&gt;

==Magnetic VCD==
VCD spectra have also been reported in the presence of an applied external magnetic field.&lt;ref&gt;{{cite journal|title=Observation of Magnetic Vibrational Circular Dichroism|author=T. A. Keiderling|journal= Journal of Chemical Physics|volume= 75|pages= 3639–41 |date=1981|doi=10.1063/1.442437|issue=7|bibcode = 1981JChPh..75.3639K }}&lt;/ref&gt; This method can enhance the VCD spectral resolution for small molecules.&lt;ref&gt;{{cite journal|title=Vibrational Spectral Assignment and Enhanced Resolution Using Magnetic Vibrational Circular Dichroism|author=T. R. Devine|author2=T. A. Keiderling|last-author-amp=yes|journal=Spectrochimica Acta|volume= 43A|pages= 627–629 |date=1987}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Magnetic Vibrational Circular Dichroism with an FTIR|bibcode=1989SPIE.1145..152C|author=P. V. Croatto|author2=R. K. Yoo|author3=T. A. Keiderling|journal= Proceedings of SPIE |volume=1145|pages=152–153 |date=1989|doi=10.1117/12.969401}}
&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Direct Measurement of the Rotational g-Value in the Ground State of Acetylene by Magnetic Vibrational Circular Dichroism|author= C. N. Tam|author2= T. A. Keiderling|last-author-amp= yes|journal= Chemical Physics Letters|volume= 243|pages= 55–58 |doi=10.1016/0009-2614(95)00843-S|date=1995|bibcode = 1995CPL...243...55J }}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Ab initio calculation of the vibrational magnetic dipole moment|author= P. Bour|author2= C. N. Tam|author3= T. A. Keiderling|journal= Journal of Physical Chemistry |volume=99|pages= 17810–17813 |date=1995|doi=10.1021/j100051a002}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Rotationally Resolved Magnetic Vibrational Circular Dichroism. Experimental Spectra and Theoretical Simulation for Diamagnetic Molecules|doi=10.1080/00268979600100201|author=P. Bour|author2=C. N. Tam|author3=B. Wang|author4=T. A. Keiderling|journal=Molecular Physics|volume= 87|pages= 299–318 |date=1996|bibcode = 1996MolPh..87..299B }}&lt;/ref&gt;

==Raman optical activity (ROA)==
[[Raman optical activity|ROA]] is a technique complementary to VCD especially useful in the 50–1600&amp;nbsp;cm&lt;sup&gt;−1&lt;/sup&gt; spectral region; it is considered as the technique of choice for determining optical activity for photon energies less than 600&amp;nbsp;cm&lt;sup&gt;−1&lt;/sup&gt;.

==See also==
{{colbegin}}
* [[Amino acid]]
* [[Birefringence]]
* [[Circular dichroism]]
* [[Density functional theory]]
* [[DNA]]
* [[DNA structure]]
* [[IR spectroscopy]]
* [[Magnetic circular dichroism]]
* [[Molecular models of DNA]]
* [[Nucleic acid]]
* [[Optical rotatory dispersion]]
* [[Photoelastic modulator]]
* [[Polarization (waves)|Polarization]]
* [[Protein]]
* [[Protein structure]]
* [[Quantum chemistry]]
* [[Raman optical activity]] (ROA)
{{colend}}

==References==
{{reflist|35em}}

[[Category:Polarization (waves)]]
[[Category:Physical chemistry]]
[[Category:Proteins]]
[[Category:Peptides]]
[[Category:Nucleic acids]]
[[Category:Infrared spectroscopy]]
[[Category:Spectroscopy]]
[[Category:Biochemistry]]
[[Category:Biophysics]]
[[Category:DNA]]
[[Category:Molecular biology]]
[[Category:Molecular geometry]]
[[Category:Quantum chemistry]]</text>
      <sha1>fbf5avnnsxgjnvcjwl3qeolavrfxo9y</sha1>
    </revision>
  </page>
  <page>
    <title>Warren Goldfarb</title>
    <ns>0</ns>
    <id>15629024</id>
    <revision>
      <id>773692464</id>
      <parentid>735828245</parentid>
      <timestamp>2017-04-03T20:27:46Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>+cats</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2283">'''Warren David Goldfarb''' (born 1949) is a philosopher and mathematician with a specialization in the history of [[analytic philosophy]] and in logic, most notably his work on the classical [[Decidability (logic)|decision problem]] (see his book on the subject, ''The decision problem: Solvable classes of quantificational formulas'', with [[Burton Dreben]]).

He received his Ph.D. from [[Harvard University]], where he is now Walter Beverly Pearson Professor of Modern Mathematics and Mathematical Logic in the Department of Philosophy. He has been on the Harvard faculty since 1975, and was [[tenure]]d in 1982, the only philosopher to be promoted to tenure at Harvard between 1962 and 1999.&lt;ref&gt;[http://chronicle.com/weekly/v45/i35/35a05601.htm Harvard Tenures First Philosopher in 17 Years], [[The Chronicle of Higher Education]], May 7, 1999.&lt;/ref&gt;

Prof. Goldfarb is also one of the founders of the [[Harvard Gay &amp; Lesbian Caucus]] and was one of the first openly gay Harvard faculty members.&lt;ref&gt;[http://hglc.org/about/whoswho.html Who's Who: About Us], Harvard Gay and Lesbian Caucus.&lt;/ref&gt;&lt;ref&gt;[http://www.thecrimson.com/article.aspx?ref=174942 Gay Faculty Become Activists], Melissa Lee and Anna D. Wilde, [[Harvard Crimson]], April 23, 1993.&lt;/ref&gt;

Goldfarb was an editor of volumes III–V of [[Kurt Gödel]]'s ''Collected Works''.  He has also published articles on important analytic philosophers, including [[Frege]], [[Bertrand Russell|Russell]], [[Wittgenstein|Wittgenstein's]] early and later work, [[Carnap]] and [[Willard Van Orman Quine|Quine]].&lt;ref&gt;"The Goldfarb Panel," Warren Goldfarb on Quine: https://www.youtube.com/watch?v=-_tSuKAOGSY&lt;/ref&gt;

==References==
{{Reflist}}

== External links ==
* [http://philosophy.fas.harvard.edu/people/warren-goldfarb Goldfarb's web page at Harvard University]
* Works by Warren Goldfarb at [http://philpapers.org/s/Warren%20Goldfarb PhilPapers]

{{Authority control}}

{{DEFAULTSORT:Goldfarb, Warren D.}}
[[Category:Living people]]
[[Category:American logicians]]
[[Category:Mathematical logicians]]
[[Category:Historians of mathematics]]
[[Category:Harvard University alumni]]
[[Category:Harvard University faculty]]
[[Category:LGBT people from the United States]]
[[Category:1949 births]]


{{US-mathematician-stub}}</text>
      <sha1>6z6jldtimass4x82mjwbyugtmk4lvf8</sha1>
    </revision>
  </page>
  <page>
    <title>Weil's conjecture on Tamagawa numbers</title>
    <ns>0</ns>
    <id>3036289</id>
    <revision>
      <id>867888882</id>
      <parentid>866552061</parentid>
      <timestamp>2018-11-08T16:44:17Z</timestamp>
      <contributor>
        <ip>141.20.53.115</ip>
      </contributor>
      <comment>added missing space</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5360">In [[mathematics]], the '''Weil conjecture on Tamagawa numbers''' is the statement that the [[Tamagawa number]] &lt;math&gt;\tau(G)&lt;/math&gt; of a [[simply connected]] simple [[algebraic group]] defined over a number field is 1. In this case, ''simply connected'' means "not having a proper ''algebraic'' covering" in the algebraic [[group theory]] sense, which is not always the [[simply connected space|topologists' meaning]].

==History==
{{harvs|txt|authorlink=André Weil|last=Weil|year=1959}} calculated the Tamagawa number in many cases of [[classical group]]s and observed that it is an integer in all considered cases and that it was equal to 1 in the cases when the group is simply connected. The first observation does not hold for all groups: {{harvtxt|Ono|1963}} found examples  where the Tamagawa numbers are not integers. The second observation, that the Tamagawa numbers of simply connected semisimple groups seem to be 1, became known as the Weil conjecture.

[[Robert Langlands]] (1966) introduced [[harmonic analysis]] methods to show it for [[Chevalley group]]s. K. F. Lai (1980) extended the class of known cases to [[quasisplit reductive group]]s. {{harvtxt|Kottwitz|1988}} proved it for all groups satisfying the [[Hasse principle]], which at the time was known for all groups without  [[E8 (group)|''E''&lt;sub&gt;8&lt;/sub&gt;]] factors. V. I. Chernousov (1989) removed this restriction, by proving the Hasse principle for the resistant ''E''&lt;sub&gt;8&lt;/sub&gt; case (see [[strong approximation in algebraic groups]]), thus completing the proof of Weil's conjecture. In 2011, [[Jacob Lurie]] and [[Dennis Gaitsgory]] announced a proof of the conjecture for algebraic groups over function fields over finite fields.{{sfn|Lurie|2014}}

==Applications==
{{harvtxt|Ono|1965}} used the Weil conjecture to calculate the Tamagawa numbers of all semisimple algebraic groups.

For [[spin group]]s, the conjecture implies the known [[Smith–Minkowski–Siegel mass formula]].{{sfn|Lurie|2014}

==See also==
*[[Tamagawa number]]

==References==
*{{Springer|id=T/t092060|title=Tamagawa number}}
*{{citation|last= Chernousov|first= V. I. |title=The Hasse principle for groups of type E8 |journal=  Soviet Math. Dokl. |volume= 39  |year=1989|pages= 592–596|mr= 1014762}}
*{{citation|last= Kottwitz|first= Robert E. |title=Tamagawa numbers |journal=  Ann. of Math. |series=   2 |volume= 127  |year=1988|issue=  3|pages=629–646|doi=10.2307/2007007|jstor=2007007|publisher=Annals of Mathematics|mr= 0942522}}.
*{{citation|last=Lai|first= K. F. |title=Tamagawa number of reductive algebraic groups|journal= Compositio Mathematica|volume= 41 |issue= 2 |year=1980|pages= 153–188 |url= http://www.numdam.org/item?id=CM_1980__41_2_153_0|mr=581580}}
*{{citation |last=Langlands|first= R. P. |chapter=The volume of the fundamental domain for some arithmetical subgroups of Chevalley groups|year=  1966 |title= Algebraic Groups and Discontinuous Subgroups |series=Proc. Sympos. Pure Math.|pages=  143–148 |publisher=Amer. Math. Soc.|publication-place= Providence, R.I. |mr=0213362}}
*{{Citation | last1=Ono | first1=Takashi | authorlink=Takashi Ono (mathematician) | title=On the Tamagawa number of algebraic tori | jstor=1970502 |mr=0156851 | year=1963 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=78 | pages=47–73 | doi=10.2307/1970502}}
*{{Citation | last1=Ono | first1=Takashi | title=On the relative theory of Tamagawa numbers | jstor=1970563 |mr=0177991 | year=1965 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=82 | pages=88–111 | doi=10.2307/1970563}}
*{{Citation | last1=Tamagawa | first1=Tsuneo | title=Algebraic Groups and Discontinuous Subgroups | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=Proc. Sympos. Pure Math. |mr=0212025 | year=1966 | volume=IX | chapter=Adèles | pages=113–121}}
*{{citation|first=V. E.|last= Voskresenskii|title=Algebraic Groups and their Birational Invariants|series= AMS translation|year= 1991}}
*{{Citation | last1=Weil | first1=André | author1-link=André Weil | title=Exp. No. 186, Adèles et groupes algébriques | url=http://www.numdam.org/item?id=SB_1958-1960__5__249_0 | series=Séminaire Bourbaki | year=1959 | volume=5 | pages=249–257}}
*{{Citation | last1=Weil | first1=André | author1-link=André Weil | title=Adeles and algebraic groups | origyear=1961 | url=https://books.google.com/books/about/Adeles_and_algebraic_groups.html?id=vQvvAAAAMAAJ | publisher=Birkhäuser Boston | location=Boston, MA | series=Progress in Mathematics | isbn=978-3-7643-3092-7 |mr=670072 | year=1982 | volume=23}}
*{{Citation | last=Lurie | first=Jacob  | author-link=Jacob Lurie | title=Tamagawa Numbers via Nonabelian Poincaré Duality | year=2014 | url=http://www.math.harvard.edu/~lurie/282y.html }}

== Further reading ==
*Aravind Asok, Brent Doran and Frances Kirwan, [https://arxiv.org/pdf/0801.4733v1.pdf "Yang-Mills theory and Tamagawa Numbers: the fascination of unexpected links in mathematics"], February 22, 2013
*J. Lurie, [http://www.cornell.edu/video/jacob-lurie-the-siegel-mass-formula The Siegel Mass Formula, Tamagawa Numbers, and Nonabelian Poincaré Duality] posted June 8, 2012.

[[Category:Conjectures]]
[[Category:Theorems in algebra]]
[[Category:Algebraic groups]]
[[Category:Diophantine geometry]]</text>
      <sha1>gzn6npomp93sqtxytgxptq1000uhdpm</sha1>
    </revision>
  </page>
</mediawiki>
