<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>1 + 1 + 1 + 1 + ⋯</title>
    <ns>0</ns>
    <id>9929142</id>
    <revision>
      <id>846980458</id>
      <parentid>845111162</parentid>
      <timestamp>2018-06-22T02:57:13Z</timestamp>
      <contributor>
        <username>CitationCleanerBot</username>
        <id>15270283</id>
      </contributor>
      <minor/>
      <comment>/* top */cleanup</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4343">{{Multiple image
|image1=Sum1111Plain.svg |alt1=A graph depicting the series with layered boxes |caption1=The series 1 + 1 + 1 + 1 + ⋯
|image2=Sum1111Smoothed.svg |alt2=A graph depicting the smoothed series with layered curving stripes |caption2=After smoothing
}}
[[File:Sum1111Asymptote.svg|thumb|Asymptotic behavior of the smoothing. The ''y''-intercept of the line is −{{sfrac|1|2}}.&lt;ref&gt;{{Citation |first=Terence |last=Tao |authorlink=Terence Tao |date=April 10, 2010 |title=The Euler-Maclaurin formula, Bernoulli numbers, the zeta function, and real-variable analytic continuation |url=http://terrytao.wordpress.com/2010/04/10/the-euler-maclaurin-formula-bernoulli-numbers-the-zeta-function-and-real-variable-analytic-continuation/ |accessdate=January 30, 2014}}&lt;/ref&gt; |alt=A graph showing a line that dips just below the ''y''-axis]]

In [[mathematics]], {{nowrap|'''1 + 1 + 1 + 1 + ⋯'''}}, also written &lt;math&gt;\sum_{n=1}^{\infin} n^0&lt;/math&gt;, &lt;math&gt;\sum_{n=1}^{\infin} 1^n&lt;/math&gt;, or simply &lt;math&gt;\sum_{n=1}^{\infin} 1&lt;/math&gt;, is a [[divergent series]], meaning that its sequence of [[partial sum]]s does not converge to a [[limit of a sequence|limit]] in the [[real number]]s. The sequence 1&lt;sup&gt;{{mvar|n}}&lt;/sup&gt; can be thought of as a [[geometric series]] with the [[Geometric series#Common ratio|common ratio]] 1. Unlike other geometric series with [[rational number|rational]] ratio (except −1), it converges in neither the real numbers nor in the [[p-adic number|{{mvar|p}}-adic numbers]] for some&amp;nbsp;{{mvar|p}}. In the context of the [[extended real number line]]
: &lt;math&gt;\sum_{n=1}^{\infin} 1 = +\infty \, ,&lt;/math&gt;
since its sequence of partial sums increases [[monotonic function|monotonically]] without bound.

Where the sum of {{math|''n''&lt;sup&gt;0&lt;/sup&gt;}} occurs in [[theoretical physics|physical]] applications, it may sometimes be interpreted by [[zeta function regularization]], as the value at {{math|1=''s'' = 0}} of the [[Riemann zeta function]]
:&lt;math&gt;\zeta(s)=\sum_{n=1}^\infty\frac{1}{n^s}=\frac{1}{1-2^{1-s}}\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n^s}\,,&lt;/math&gt;

The two formulas given above are not valid at zero however, so one might try the [[analytic continuation]] of the Riemann zeta function,

:&lt;math&gt;
\zeta(s) = 2^s\pi^{s-1}\ \sin\left(\frac{\pi s}{2}\right)\ \Gamma(1-s)\ \zeta(1-s)
\!,&lt;/math&gt;

Using this one gets (given that {{math|Γ(1) {{=}} 1}}),
:&lt;math&gt;\zeta(0) = \frac{1}{\pi} \lim_{s \rightarrow 0} \ \sin\left(\frac{\pi s}{2}\right)\ \zeta(1-s) = \frac{1}{\pi} \lim_{s \rightarrow 0} \ \left( \frac{\pi s}{2} - \frac{\pi^3 s^3}{48} + ... \right)\ \left( -\frac{1}{s} + ... \right) = -\frac{1}{2}&lt;/math&gt;

where the power series expansion for {{math|''ζ''(''s'')}} about {{math|1=''s'' = 1}} follows because {{math|''ζ''(''s'')}} has a simple pole of [[residue (complex analysis)|residue]] one there. In this sense {{math|1=1 + 1 + 1 + 1 + ⋯ = ''ζ''(0) = −{{sfrac|1|2}}}}.

[[Emilio Elizalde]] presents an anecdote on attitudes toward the series:
{{blockquote|1=In a short period of less than a year, two distinguished physicists, [[Andrei Slavnov|A. Slavnov]] and [[Francisco José Ynduráin|F. Yndurain]], gave seminars in Barcelona, about different subjects. It was remarkable that, in both presentations, at some point the speaker addressed the audience with these words: 'As everybody knows, {{nowrap|1=1 + 1 + 1 + ⋯ = −{{sfrac|1|2}}}}.' Implying maybe: ''If you do not know this, it is no use to continue listening.''&lt;ref&gt;{{cite encyclopedia |first=Emilio |last=Elizalde |chapter=Cosmology: Techniques and Applications |title=Proceedings of the II International Conference on Fundamental Interactions |year=2004 |arxiv=gr-qc/0409076|bibcode=2004gr.qc.....9076E }}&lt;/ref&gt;}}

==See also==
* [[Grandi's series]]
* [[1 − 2 + 3 − 4 + · · ·]]
* [[1 + 2 + 3 + 4 + · · ·]]
* [[1 + 2 + 4 + 8 + · · ·]]
* [[1 − 2 + 4 − 8 + ⋯]]
* [[1 − 1 + 2 − 6 + 24 − 120 + · · ·]]
* [[Harmonic series (mathematics)|Harmonic series]]

==Notes==
{{reflist}}

==External links==
*{{OEIS el|1=A000012|2=The simplest sequence of positive numbers: the all 1's sequence}}

{{Series (mathematics)}}

{{DEFAULTSORT:1 + 1 + 1 + 1 + ...}}
[[Category:Arithmetic series]]
[[Category:Divergent series]]
[[Category:Geometric series]]
[[Category:1 (number)]]
[[Category:Mathematics paradoxes]]</text>
      <sha1>iw0pdd6xdchhf4wbmp8atcjz8c4k6nw</sha1>
    </revision>
  </page>
  <page>
    <title>Abel's binomial theorem</title>
    <ns>0</ns>
    <id>12216711</id>
    <revision>
      <id>752872672</id>
      <parentid>633965450</parentid>
      <timestamp>2016-12-03T21:52:28Z</timestamp>
      <contributor>
        <ip>66.205.145.185</ip>
      </contributor>
      <comment>added stub tag</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="759">{{Math-stub}}
'''Abel's binomial theorem''', named after [[Niels Henrik Abel]], is a [[Identity (mathematics)|mathematical identity]] involving [[Summation|sums]] of [[binomial coefficient]]s. It states the following:

: &lt;math&gt;\sum_{k=0}^m \binom{m}{k} (w+m-k)^{m-k-1}(z+k)^k=w^{-1}(z+w+m)^m.&lt;/math&gt;

==Example==
===''m'' = 2===
: &lt;math&gt;
\begin{align}
&amp; {} \quad \binom{2}{0}(w+2)^1(z+0)^0+\binom{2}{1}(w+1)^0(z+1)^1+\binom{2}{2}(w+0)^{-1}(z+2)^2 \\
&amp; = (w+2)+2(z+1)+\frac{(z+2)^2}{w} \\
&amp; = \frac{(z+w+2)^2}{w}.
\end{align}
&lt;/math&gt;

==See also==

* [[Binomial theorem]]
* [[Binomial type]]

==References==

* {{mathworld|title=Abel's binomial theorem|urlname=AbelsBinomialTheorem}}

[[Category:Factorial and binomial topics]]
[[Category:Theorems in algebra]]</text>
      <sha1>3yf0g2eqncg187qnbj63parexgnfwa1</sha1>
    </revision>
  </page>
  <page>
    <title>Abstract structure</title>
    <ns>0</ns>
    <id>359377</id>
    <revision>
      <id>808053740</id>
      <parentid>804497909</parentid>
      <timestamp>2017-10-31T16:15:05Z</timestamp>
      <contributor>
        <username>Textdoc</username>
        <id>31741182</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2666">{{unreferenced|date=June 2009|bot=yes}}
An '''abstract structure''' is a [[formal object]] that is defined by a set of laws, properties and relationships in a way that is logically if not always historically independent of the structure of contingent experiences, for example, those involving physical objects.  Abstract structures are studied not only in [[logic]] and [[mathematics]] but in the fields that apply them, as [[computer science]], and in the studies that reflect on them, such as [[philosophy]] (especially the [[philosophy of mathematics]]).  Indeed, modern mathematics has been defined in a very general sense as the study of abstract structures (by the [[Nicolas Bourbaki|Bourbaki]] group: see discussion there, at [[algebraic structure]] and also [[structure (category theory)|structure]]).

An abstract structure may be represented (perhaps with some degree of approximation) by one or more physical objects{{snd}} this is called an implementation or [[Instantiation principle|instantiation]] of the abstract structure. But the abstract structure itself is defined in a way that is not dependent on the properties of any particular implementation.

An abstract structure has a richer structure than a [[concept]] or an [[idea]]. An abstract structure must include precise rules of behaviour which can be used to determine whether a candidate implementation actually matches the abstract structure in question. Thus we may debate how well a particular government fits the concept of [[democracy]], but there is no room for debate over whether a given sequence of moves is or is not a valid game of chess.   

==Examples==   
* A [[sorting algorithm]] is an abstract structure, but a [[recipe]] is not, because it depends on the properties and quantities of its ingredients.
* A simple [[melody]] is an abstract structure, but an [[orchestration]] is not, because it depends on the properties of particular instruments.
* [[Euclidean geometry]] is an abstract structure, but the theory of [[continental drift]] is not, because it depends on the geology of the [[Earth]].
* A [[formal language]] is an abstract structure, but a [[natural language]] is not, because its rules of grammar and syntax are open to debate and interpretation.

==See also==
* [[Abstraction (computer science)|Abstraction in computer science]]
* [[Abstraction|Abstraction in general]]
* [[Abstraction (mathematics)|Abstraction in mathematics]]
* [[Abstract object]]
* [[Deductive apparatus]]
* [[Formal science]]s
* [[Mathematical structure]]

{{mathlogic-stub}}
[[Category:Abstraction]]
[[Category:Mathematical terminology]]
[[Category:Structure]]

[[da:Abstrakt (begreb)]]</text>
      <sha1>mrneel5z9ulo33elmg8iva660fuw98d</sha1>
    </revision>
  </page>
  <page>
    <title>Alternated order-4 hexagonal tiling</title>
    <ns>0</ns>
    <id>38731422</id>
    <revision>
      <id>782229254</id>
      <parentid>777261705</parentid>
      <timestamp>2017-05-25T17:26:46Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2543">{{Uniform hyperbolic tiles db|Uniform hyperbolic tiling stat table|U443_0}}
In [[geometry]], the '''alternated order-4 hexagonal tiling''' or '''ditetragonal tritetratrigonal tiling''' is a [[Uniform tilings in hyperbolic plane|uniform]] tiling of the [[Hyperbolic geometry|hyperbolic plane]]. It has [[Schläfli symbol]] of (3,4,4), h{6,4}, and hr{6,6}.

== Uniform constructions ==
There are four uniform constructions, with some of lower ones which can be seen with two colors of triangles:
{| class=wikitable
! [[443 symmetry|*443]]
! [[3333 symmetry|3333]]
! [[3232 symmetry|*3232]]
! [[3222 symmetry|3*22]]
|- align=center
| {{CDD|node_h1|6|node|4|node}} = {{CDD|branch_10ru|split2-44|node}}
| {{CDD|node_h|6|node_g|4sg|node_g}} = {{CDD|branch_hh|3a3b-cross|branch_hh}}
| {{CDD|node_h1|6|node|4|node_h0}} = {{CDD|node_h1|split1-66|nodes}}  = {{CDD|nodes_11|3a3b-cross|nodes}}
| {{CDD|node_h|6|node_h0|4|node}} = {{CDD|branch_hh|2a2b-cross|nodes}}
|- align=center
|colspan=2|[[File:H2 tiling 344-1.png|120px]]
|colspan=2|[[File:Uniform tiling verf 34343434.png|120px]]
|-
!colspan=2|(4,4,3) = h{6,4}
!colspan=2|hr{6,6} = h{6,4}{{frac|1|2}}
|}

== Related polyhedra and tiling ==
{{Order 6-4 tiling table}}
{{Order 6-6 tiling table}}
{{Order 4-4-3 tiling table}}
{{Order 3-2-3-2 tiling table}}

==References==
* [[John Horton Conway|John H. Conway]], Heidi Burgiel, Chaim Goodman-Strass, ''The Symmetries of Things'' 2008, {{ISBN|978-1-56881-220-5}} (Chapter 19, The Hyperbolic Archimedean Tessellations)
* {{Cite book|title=The Beauty of Geometry: Twelve Essays|year=1999|publisher=Dover Publications|lccn=99035678|isbn=0-486-40919-8|chapter=Chapter 10: Regular honeycombs in hyperbolic space}}

==See also==
{{Commonscat|Uniform tiling 3-4-3-4-3-4-3-4}}
*[[Square tiling]]
*[[Uniform tilings in hyperbolic plane]]
*[[List of regular polytopes]]

== External links ==
*{{MathWorld | urlname= HyperbolicTiling | title = Hyperbolic tiling}}
*{{MathWorld | urlname=PoincareHyperbolicDisk | title = Poincaré hyperbolic disk }}
* [http://bork.hampshire.edu/~bernie/hyper/ Hyperbolic and Spherical Tiling Gallery]
* [http://geometrygames.org/KaleidoTile/index.html KaleidoTile 3: Educational software to create spherical, planar and hyperbolic tilings]
* [http://www.plunk.org/~hatch/HyperbolicTesselations Hyperbolic Planar Tessellations, Don Hatch]

{{Tessellation}}

[[Category:Hexagonal tilings]]
[[Category:Hyperbolic tilings]]
[[Category:Isogonal tilings]]
[[Category:Order-4 tilings]]
[[Category:Semiregular tilings]]

{{geometry-stub}}</text>
      <sha1>5qetmw9w8awphymah1qmwkem7vd85em</sha1>
    </revision>
  </page>
  <page>
    <title>Atiyah–Bott formula</title>
    <ns>0</ns>
    <id>44849824</id>
    <revision>
      <id>810182270</id>
      <parentid>810182114</parentid>
      <timestamp>2017-11-13T20:10:52Z</timestamp>
      <contributor>
        <username>Popolon</username>
        <id>73260</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1070">{{otheruse|Atiyah–Bott fixed-point theorem}}
In [[algebraic geometry]], the '''Atiyah–Bott formula''' says&lt;ref&gt;{{harvnb|Gaitsgory–Lurie|loc=§ 6.2.}}&lt;/ref&gt; the [[cohomology ring]]
:&lt;math&gt;\operatorname{H}^*(\operatorname{Bun}_G(X), \mathbb{Q}_l)&lt;/math&gt;
of the [[moduli stack of principal bundles]] is a [[free algebra|free]] [[supercommutative algebra|graded-commutative algebra]] on certain homogeneous generators. [[Michael Atiyah]] and [[Raoul Bott]]'s original work concerned integral cohomology ring of Bun&lt;sub&gt;''G''&lt;/sub&gt;(''X'').

== See also ==
*[[Borel's theorem]], which says the cohomology ring of a classifying stack is a polynomial ring.

== Notes ==
{{reflist}}

== References ==
* Atiyah, M. F. and R. Bott.; "The Yang-Mills equations over Riemann surfaces." Philos. Trans. Roy. Soc. London Ser. A 308 (1983), no. 1505.
* Gaitsgory, D; Lurie, J.; "Weil's Conjecture for Function Fields." 2014, [http://www.math.harvard.edu/~lurie/papers/tamagawa.pdf]

{{DEFAULTSORT:Atiyah-Bott formula}}
[[Category:Theorems in algebraic geometry]]


{{topology-stub}}</text>
      <sha1>nj4th13cdx10wmrc6g2i3l1oy4j4d7w</sha1>
    </revision>
  </page>
  <page>
    <title>Beam and Warming scheme</title>
    <ns>0</ns>
    <id>44260845</id>
    <revision>
      <id>869592915</id>
      <parentid>869592864</parentid>
      <timestamp>2018-11-19T16:17:07Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>/* Tri-diagonal system */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6636">In numerical mathematics, '''Beam and Warming scheme ''' or '''Beam–Warming implicit scheme''' introduced in 1978 by Richard M. Beam and R. F. Warming,&lt;ref name="An Implicit Finite-Difference Algorithm for Hyperbolic Systems in Conservation-Law Form"&gt;{{cite journal | title=An Implicit Finite-Difference Algorithm for Hyperbolic Systems in Conservation-Law Form | author=Richard M Beam, R.F Warming | journal=Journal of Computational Physics |date=September 1976  | volume=22 | issue=1 | pages=87–110 | doi=10.1016/0021-9991(76)90110-8}}&lt;/ref&gt;&lt;ref name="An Implicit Factored Scheme for the Compressible Navier–Stokes Equations"&gt;{{cite journal | title=An Implicit Factored Scheme for the Compressible Navier–Stokes Equations | author=Richard M. Beam; R. F. Warming | journal=AIAA Journal |date=April 1978  | volume=16 | issue=4 | doi=10.2514/3.60901}}&lt;/ref&gt; is a second order accurate [[Explicit and implicit methods|implicit scheme]], mainly used for solving non-linear hyperbolic equation.  It is not used much nowadays.

==Introduction==
This scheme is a spatially factored, non iterative, [[Alternating direction implicit method|ADI]] scheme and uses [[Backward Euler method|implicit Euler]] to perform the time Integration. The algorithm is in '''delta-form''',  linearized through implementation of a [[Taylor series|Taylor-series]]. Hence observed as increments of the conserved variables. In this an efficient factored algorithm is obtained by evaluating the spatial cross derivatives explicitly. This allows for direct derivation of scheme and efficient solution using this computational algorithm. The efficiency is because although it is three-time-level scheme, but requires only two time levels of data storage.  This results in unconditional stability. It is centered and needs the artificial dissipation operator to guarantee numerical stability.&lt;ref name="An Implicit Finite-Difference Algorithm for Hyperbolic Systems in Conservation-Law Form" /&gt;

The delta form of the equation produced has the advantageous property of stability (if existing) independent of the size of the time step.&lt;ref name="Computational Fluid Mechanics and Heat Transfer, Third Edition"&gt;{{cite book | title=Computational Fluid Mechanics and Heat Transfer, Third Edition | publisher=CRC Press | author=Richard H. Pletcher | year=2012 | isbn=978-1591690375}}&lt;/ref&gt;

==The method==
[[File:Steps in beam and warming.png|thumb|right|300px]]
Consider the inviscid [[Burgers' equation]] in one dimension
: &lt;math&gt; \frac{\partial u}{\partial t} = -u \frac{\partial u}{\partial x} \quad \text{with } x\in R &lt;/math&gt;

Burgers' equation in conservation form,
:&lt;math&gt; \frac{\partial u}{\partial t} = - \frac{\partial E}{\partial x} &lt;/math&gt;

where :&lt;math&gt;  E = \frac{u^2}{2} &lt;/math&gt;
&lt;!--===Initial conditions ===
:&lt;math&gt; u(x,0) = \left\{ \begin{array}{cc}
1 &amp; 0 \leq x &lt; 2  \\
0 &amp; 2 \leq x \leq 4 \\ \end{array} \right. &lt;/math&gt;--&gt;

===Taylor series expansion===
[[File:Basis of Beam-warming.png|thumb|right|300px]]
The expansion of :&lt;math&gt;u^{n+1}_i&lt;/math&gt;
:&lt;math&gt;
u^{n+1}_i = u^n_i + \frac{1}{2} \left[\left. \frac{\partial u}{\partial t} \right|^{n}_i + \left. \frac{\partial u}{\partial t} \right|^{n+1}_i \right] \, \Delta t + O(\Delta t^3)
&lt;/math&gt;

This is also known as the [[Trapezoidal rule|trapezoidal formula]].

:&lt;math&gt;
\therefore \frac{u^{n+1}_i - u^n_i}{\Delta t} = -\frac{1}{2} \left( \left.\frac{\partial E}{\partial x}\right|^{n+1}_i + \left.\frac{\partial E}{\partial x}\right|^n_i + \frac{\partial}{\partial x} \left[ A(u^{n+1}_i - u^n_i)\right] \right)
&lt;/math&gt;
:&lt;math &gt;\because \frac{\partial u}{\partial t} = -\frac{ \partial E}{\partial x} &lt;/math&gt;

=== Tri-diagonal system ===
Resulting tri-diagonal system:
:&lt;math&gt;
\begin{align}
&amp; - \frac{\Delta t}{4 \, \Delta x} \left( A^n_{i-1} u^{n+1}_{i-1}\right) + u^{n+1}_i + \frac{\Delta t}{4 \, \Delta x} \left( A^n_{i+1} u^{n+1}_{i+1} \right) \\[6pt]
= {} &amp; u^n_i - \frac{1}{2} \frac{\Delta t}{\Delta x} \left( E^n_{i+1} - E^n_{i-1} \right) + \frac{\Delta t}{4 \, \Delta x} \left( A^n_{i+1} u^n_{i+1} - A^n_{i-1} u^n_{i-1} \right)
\end{align}
&lt;/math&gt;
This resulted system of linear equations can be solved using the modified [[tridiagonal matrix algorithm]], also known as the Thomas algorithm.&lt;ref name="Computational Fluid Dynamics"&gt;{{cite book | title=Computational Fluid Dynamics, 2nd Edition | publisher=Cambridge University Press | author=Chung, T.J. | year=2010 | isbn=978-0521769693}}&lt;/ref&gt;

== Dissipation term ==
Under the condition of shock wave, dissipation term is required for [[Hyperbolic partial differential equation|nonlinear hyperbolic equations]] such as this. This is done to keep the solution under control and maintain convergence of the solution.
:&lt;math&gt; D = -\varepsilon_e (u^n_{i+2} - 4u^n_{i+1} + 6u^n_i - 4u^n_{i-1} + u^n_{i-2}) &lt;/math&gt;

This term is added explicitly at level &lt;math&gt;n&lt;/math&gt; to the right hand side. This is always used for successful computation where high-frequent oscillations are observed and must be suppressed.

== Smoothing term ==
If only the stable solution is required, then in the equation to the right hand side a second-order [[Relaxation (iterative method)|smoothing term]] is added on the implicit layer.
The other term in the same equation can be second-order because it has no influence on the stable solution if
:&lt;math&gt; \nabla^n(U) = 0 &lt;/math&gt;

The addition of smoothing term increases the number of steps required by three.

==Properties==
This scheme is produced by combining the trapezoidal formula, linearization, factoring, Padt spatial differencing, the homogeneous property of the flux vectors (where applicable), and hybrid spatial differencing and is most suitable for nonlinear systems in conservation-law form. ADI algorithm retains the order of accuracy and the steady-state property while reducing the bandwidth of the system of equations.&lt;ref name="Simplification of Beam and Warming's implicit scheme for two-dimensional compressible flows"&gt;{{cite journal | title=Simplification of Beam and Warming's implicit scheme for two-dimensional compressible flows | author=Lee, Jon | journal=AIAA Journal |date=January 1992  | volume=30 | pages=266–268 | doi=10.2514/3.10908}}&lt;/ref&gt;
Stability of the equation is
:&lt;math&gt; L^2&lt;/math&gt;-stable under CFL : &lt;math&gt;|a| \, \Delta t \le 2 \, \Delta x &lt;/math&gt;
The order of Truncation error is
:&lt;math&gt; O ((\Delta t)^2 + (\Delta x) ^2)&lt;/math&gt;
The result is smooth with considerable overshoot (that does not grow much with time).

==References==
{{reflist|30em}}

[[Category:Finite differences]]
[[Category:Numerical differential equations]]
[[Category:Computational fluid dynamics]]</text>
      <sha1>t9j7y7olt5qcsmofvbg1krg3vdscry4</sha1>
    </revision>
  </page>
  <page>
    <title>Birkhoff orthogonality</title>
    <ns>0</ns>
    <id>49468975</id>
    <revision>
      <id>715720672</id>
      <parentid>713280771</parentid>
      <timestamp>2016-04-17T16:06:26Z</timestamp>
      <contributor>
        <username>Postcard Cathy</username>
        <id>1744116</id>
      </contributor>
      <comment>added [[Category:Linear algebra]]; removed {{uncategorized}} using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="343">{{Multiple issues|{{unreferenced|date=February 2016}}{{technical|date=February 2016}}
{{Orphan|date=April 2016}}
}}

Two vectors  ''x'' and ''y'' in a [[normed linear space]] are said to be '''Birkhoff orthogonal''' if and only if || ''x'' + λ''y'' || ≥ || ''x'' || for all scalar λ.



{{linear-algebra-stub}}

[[Category:Linear algebra]]</text>
      <sha1>pzq9scfy73dzq2fdr8kh54pmxxhwxgk</sha1>
    </revision>
  </page>
  <page>
    <title>Bit-string physics</title>
    <ns>0</ns>
    <id>17553460</id>
    <revision>
      <id>815413606</id>
      <parentid>782906468</parentid>
      <timestamp>2017-12-14T18:08:38Z</timestamp>
      <contributor>
        <ip>168.150.123.35</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2108">'''Bit-string physics''' is a body of theory which supposes that [[reality]] can be represented by a process of operations on finite strings of dichotomous symbols, or [[bit]]s (1's and 0's). Bit-string physics has developed from [[Frederick Parker-Rhodes]]' 1964 discovery of the [[combinatorial hierarchy]]: four numbers produced from a purely mathematical recursive [[algorithm]] that correspond to the relative strengths of the four [[forces]]. These strengths are characterized by the strong, weak, electromagnetic ([[fine-structure constant]]), and gravitational [[coupling constant]]s.&lt;ref name= bastin&gt;Ted Bastin and C.W. Kilmister, Combinatorial Physics, World Scientific 1995, {{ISBN|981-02-2212-2}}&lt;/ref&gt; Other leading contributors in the field include [[H. Pierre Noyes]], [[Ted Bastin]], [[Clive W. Kilmister]], John Amson, Mike Manthey, and [[David McGoveran]].&lt;ref name= bastin/&gt;&lt;ref name="bits"&gt;{{cite book |author= H. Pierre Noyes |editor= J. C. van den Berg |title= Bit-String Physics: A Finite and Discrete Approach to Natural Philosophy |publisher= World Scientific |year= 2001|isbn= 978-981-02-4611-2 |url= https://books.google.com/books?id=DI5qEz4RpLQC }}&lt;/ref&gt;

In a 2001 paper by Noyes, evidence was presented for predictions made by the theory that were later confirmed.&lt;ref&gt;{{cite web |title= Observational Evidence for Two Cosmological Predictions Made by Bit-String Physics |work= Publication 8779 |date= March 23, 2001 |author= H. Pierre Noyes |publisher= Stanford Linear Accelerator Center |url= http://www.slac.stanford.edu/cgi-wrap/getdoc/slac-pub-8779.pdf  |accessdate= June 22, 2011}}&lt;/ref&gt;

==See also==
*[[Carl Friedrich von Weizsäcker]]
*[[Combinatorics]]
*[[Combinatorics and physics]]
*[[Distinction (philosophy)]]
*[[Digital physics]]

==References==
{{reflist}}

==External links==
* {{cite web |title= Journal of the Western Regional Chapter of the Alternative Natural Philosophy Association |publisher= Stanford University |url= http://www.stanford.edu/~pnoyes }}

{{DEFAULTSORT:Bit-String Physics}}
[[Category:Mathematical physics]]
[[Category:Quantum mechanics]]</text>
      <sha1>lg1b715xmxxa4guf0h40bmb8xbcb53q</sha1>
    </revision>
  </page>
  <page>
    <title>C. P. Ramanujam</title>
    <ns>0</ns>
    <id>14709171</id>
    <revision>
      <id>856876186</id>
      <parentid>847453761</parentid>
      <timestamp>2018-08-28T03:04:56Z</timestamp>
      <contributor>
        <ip>103.70.60.99</ip>
      </contributor>
      <comment>/* Early life and education */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9793">{{EngvarB|date=September 2014}}
{{Use dmy dates|date=September 2014}}
{{Infobox scientist
| name                    = C. P. Ramanujam
| image                   =
| birth_date              = 9 January 1938
| birth_place             = [[Chennai|Madras]], [[Madras Presidency]], British India
| death_date              = 27 October 1974 (age {{age|1938|1|9|1974|10|27}})
| death_place             = [[Bangalore]], [[India]]
| nationality             = Indian
| ethnicity               = [[Tamil people|Tamil]]
| field                   = Mathematics
| work_institution        = [[Tata Institute of Fundamental Research]]
| alma_mater              = [[Tata Institute of Fundamental Research]]
| doctoral_advisor        = [[K. G. Ramanathan]]
| prizes                  = Fellow, [[Indian Academy of Sciences]]
}}
'''Chakravarthi Padmanabhan Ramanujam''' (9 January 1938 – 27 October 1974) was an [[India]]n [[mathematician]] who worked in the fields of [[number theory]] and [[algebraic geometry]]. He was elected a fellow of the [[Indian Academy of Sciences]] in 1973.

Like his namesake [[Srinivasa Ramanujam|Srinivasa Ramanujan]], Ramanujam also had a very short life.&lt;ref&gt;[http://www.indiaonline.in/about/Personalities/Scientists/CP-Ramanujam.html C. P. Ramanujam (1938-1974), Famous Indian Mathematician, indiaonline.in]&lt;/ref&gt;

As [[David Mumford]] put it, Ramanujam felt that the spirit of mathematics demanded of him not merely routine developments but the right theorem on any given topic. "He wanted mathematics to be beautiful and to be clear and simple. He was sometimes tormented by the difficulty of these high standards, but in retrospect, it is clear to us how often he succeeded in adding to our knowledge, results both new, beautiful and with a genuinely original stamp".&lt;ref&gt;[http://www.dam.brown.edu/people/mumford/beyond/papers/1978b--WorkRamanujam-NC.pdf "The work of C. P. Ramanujam in Algebraic Geometry" by D. Mumford, 1978]&lt;/ref&gt;

== Early life and education ==
Ramanujam was born to a [[Tamil people|Tamil]] family on 9 January 1938 in [[Madras]] (now Chennai), India, as the eldest of seven, to Chakravarthi Srinivasa Padmanabhan. He finished his schooling in Town Hr.Sec. School , Kumbakonam . and joined [[Loyola College, Chennai|Loyola College]] in [[Madras]] in 1952. He wanted to specialise in mathematics and he set out to master it with vigour and passion. He also enjoyed music and his favourite musician was Dr. [[M. D. Ramanathan]], a maverick concert musician. His teacher and friend at this time was Father Racine, a missionary who had obtained his doctorate under the supervision of [[Élie Cartan]]. With Father Racine's encouragement and recommendation, Ramanujam applied and was admitted to the graduate school at the [[Tata Institute of Fundamental Research]] in Bombay. His father had wanted him to join the [[Indian Statistical Institute]] in [[Calcutta]] as he had passed the entrance exam meritoriously.

== Career ==
Ramanujam set out for [[Mumbai]] at the age of eighteen to pursue his interest in mathematics. He and his friend and schoolmate [[Raghavan Narasimhan]], and [[S. Ramanan]] joined [[TIFR]] together in 1957. At the Tata Institute there was a stream of first-rate visiting mathematicians from all over the world. It was a tradition for some graduate student to write up the notes of each course of lectures. Accordingly, Ramanujam wrote up in his first year, the notes of [[Max Deuring]]'s lectures on ''Algebraic functions of one variable''. It was a nontrivial effort and the notes were written clearly and were well received. The analytical mind was much in evidence in this effort as he could simplify and extend the notes within a short time period. "He could reduce difficult solutions to be simple and elegant due to his deep knowledge of the subject matter" states Ramanan. "Max Deuring's lectures gave him a taste for [[algebraic number theory]]. He studied not only [[algebraic geometry]] and [[analytic number theory]] of which he displayed a deep knowledge but he became an expert in several other allied subjects as well".

On the suggestion of his [[doctoral advisor]], [[K. G. Ramanathan]], he began working on a problem relating to the work of the German number theorist [[Carl Ludwig Siegel]]. In the course of proving the main result to the effect that every cubic form in 54 variables over any algebraic number field ''K'' had a non-trivial zero over that field, he had also simplified the earlier method of Siegel. He took up [[Waring's problem]] in [[algebraic number field]]s and got interesting results. In recognition of his work and his contribution to [[Number Theory]], the Institute promoted him to associate professor. He protested against this promotion as 'undeserved', and had to be persuaded to accept the position. He proceeded to write his thesis in 1966 and took his doctoral examination in 1967. Dr. Siegel, who was one of the examiners, was highly impressed with the young man's depth of knowledge and his great mathematical abilities.

Ramanujam was a scribe for [[Igor Shafarevich]]'s course of lectures in 1965 on minimal models and birational transformation of two-dimensional schemes. Professor Shafarevich subsequently wrote to say that Ramanujam not only corrected his mistakes but complemented the proofs of many results. The same was the case with [[David Mumford|Mumford]]'s lectures on abelian varieties, which were delivered at [[TIFR]] around 1967. Mumford wrote in the preface to his book that the notes improved upon his work and that his current work on [[Abelian variety|abelian varieties]] was a joint effort between him and Ramanujam. A little-known fact is that during this time he started teaching himself German, Italian, Russian and French so that he could study mathematical works in their original form. His personal library contained quite a few non-English mathematical works.

== Illness and death ==
Between 1964 and 1968, he was making great strides in number theory and his contacts with [[Igor Shafarevich|Shafarevich]] and Mumford led him on to [[algebraic geometry]]. According to Ramanathan and other colleagues, his progress and deep understanding of algebraic geometry was phenomenal. In 1964, based on his participation in the International Colloquium on Differential Analysis, he earned the respect of [[Alexander Grothendieck]] and of [[David Mumford]], who invited him to Paris and [[Harvard]]. He accepted the invitation and was in Paris, but for a brief period. He was diagnosed in 1964 with schizophrenia with severe depression and left Paris for [[Chennai]]. He later decided to quit his position at [[TIFR]].

He quit his post at [[Mumbai]] in 1965 after a bout of illness and secured a tenured position as a professor in [[Chandigarh]], Punjab. There he met the young student [[Chitikila Musili]], who later went on to prove interesting results in the geometry connected with the theory of [[Lie group]]s and wrote good expository books. Ramanujam stayed in Chandigarh only eight months and he had to return to Chennai again for treatment. TIFR was his real home and he was back there again in June 1965. Around this time he accepted an invitation from [[Institut des Hautes Études Scientifiques]], near Paris. He was barely there before he was flown back to Chennai. Unfortunately schizophrenia, a highly treatable condition today, was not properly diagnosed and treated at that time. Thus he continued until the end of his life to be highly creative for short periods before the recurrent illness overtook him. Again, in 1970, he sent his resignation letter to [[TIFR]] but the institute would not take it seriously. Around this time, Mumford invited him to Warwick as a visiting professor during the algebraic geometry year. Mumford writes that he spent many delightful evenings with Ramanujam and that his presence contributed importantly to the success of the algebraic geometry year. A famous paper written during this time, by [[Michael Artin]] and [[David Mumford]] acknowledges Ramanujam's suggestions and help. He also had a short tenure at Turin where he was widely appreciated and accepted. Just after his death a commemorative hall was named after him in the former Istituto di Matematica (Institute of Mathematics) of the [[university of Genoa]].

Back in [[India]] after his year at the [[University of Warwick]], Ramanujam requested for a professorship at the Tata Institute but to be made tenable in their [[Bangalore]] campus. The Tata Institute had an applied mathematics wing in Bangalore. Although Ramanjuam had nothing to do with this area, the Institute, wishing him to continue his research, made a special arrangement by which he could stay and work there. By this time, he was deeply affected and depressed by his illness. He was put in charge of a new branch dealing with applied mathematics. He settled down in Bangalore, but again in the depths of depression caused by his illness, he tried to leave the Institute and obtain a university teaching post. During one of the attacks, he tried to take his life, but was rescued in time. However, late one evening on 27 October 1974, after a lively discussion with a visiting foreign professor he took his life with an overdose of barbiturates. He was barely thirty-seven.

==See also==
* [[Ramanujam–Samuel theorem]]
* [[Ramanujam vanishing theorem]]

==Notes==
{{Reflist}}

==External links==
* {{MacTutor Biography|id=Ramanujam}}

{{Indian mathematics}}
{{Authority control}}

{{DEFAULTSORT:Ramanujam, C. P.}}
[[Category:1974 deaths]]
[[Category:1938 births]]
[[Category:20th-century Indian mathematicians]]
[[Category:University of Madras alumni]]
[[Category:Mathematicians who committed suicide]]
[[Category:Scientists from Chennai]]
[[Category:Tamil mathematicians]]</text>
      <sha1>1r9ou305b8u0e0z1nl7im2r740uks7u</sha1>
    </revision>
  </page>
  <page>
    <title>Categorial grammar</title>
    <ns>0</ns>
    <id>882427</id>
    <revision>
      <id>808712981</id>
      <parentid>783197559</parentid>
      <timestamp>2017-11-04T17:28:05Z</timestamp>
      <contributor>
        <username>Gladius-veritatis</username>
        <id>31058642</id>
      </contributor>
      <comment>/* References */ Added link to Pauline Jacobson's page</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22517">'''Categorial grammar''' is a term used for a family of formalisms in [[natural language]] [[syntax]] motivated by the principle of [[compositionality]] and organized according to the view that syntactic constituents should generally combine as [[Function (mathematics)|function]]s or according to a function-argument relationship. Most versions of categorial grammar analyze sentence structure in terms of constituencies (as opposed to dependencies) and are therefore [[phrase structure grammar]]s (as opposed to [[dependency grammar]]s).

==Basics==
A categorial grammar consists of two parts: a lexicon, which assigns a set of types (also called categories) to each basic symbol, and some [[type inference]] rules, which determine how the type of a string of symbols follows from the types of the constituent symbols.  It has the advantage that the type inference rules can be fixed once and for all, so that the specification of a particular language grammar is entirely determined by the lexicon.

A categorial grammar shares some features with the [[simply typed lambda calculus]].
Whereas the [[lambda calculus]] has only one function type &lt;math&gt;A \rightarrow B&lt;/math&gt;,
a categorial grammar typically has two function types, one type which is applied on the left,
and one on the right. For example, a simple categorial grammar might have two function types &lt;math&gt;B/A\,\!&lt;/math&gt; and &lt;math&gt;A\backslash B&lt;/math&gt;.
The first, &lt;math&gt;B/A\,\!&lt;/math&gt;, is the type of a phrase that results in a phrase of type
&lt;math&gt;B\,\!&lt;/math&gt; when followed (on the right) by a phrase of type &lt;math&gt;A\,\!&lt;/math&gt;.
The second, &lt;math&gt;A\backslash B\,\!&lt;/math&gt;, is the type of a phrase that results
in a phrase of type &lt;math&gt;B\,\!&lt;/math&gt; when preceded (on the left) by a phrase of type 
&lt;math&gt;A\,\!&lt;/math&gt;.  

The notation is based upon algebra. A fraction when multiplied by (i.e. concatenated with) its denominator yields its numerator. As concatenation is not [[commutative]], it makes a difference whether the denominator occurs to the left or right. The concatenation must be on the same side as the denominator for it to cancel out.

The first and simplest kind of categorial grammar is called a basic categorial grammar, or sometimes an AB-grammar (after Ajdukiewicz and Bar-Hillel).
Given a set of primitive types &lt;math&gt;\text{Prim}\,\!&lt;/math&gt;, let 
&lt;math&gt;\text{Tp}(\text{Prim})\,\!&lt;/math&gt; be the set of types constructed from primitive types.  In the basic case, this is the least set such that &lt;math&gt;\text{Prim}\subseteq \text{Tp}(\text{Prim})&lt;/math&gt;
and if &lt;math&gt;X, Y\in \text{Tp}(\text{Prim})&lt;/math&gt;
then &lt;math&gt;(X/Y), (Y\backslash X) \in \text{Tp}(\text{Prim})&lt;/math&gt;.
Think of these as purely formal expressions freely generated from the primitive types; any semantics will be added later.  Some authors assume a fixed infinite set of primitive types used by all grammars, but by making the primitive types part of the grammar, the whole construction is kept finite.

A basic categorial grammar is a tuple &lt;math&gt;(\Sigma, \text{Prim}, S, \triangleleft)&lt;/math&gt;
where &lt;math&gt;\Sigma\,\!&lt;/math&gt; is a finite set of symbols,
&lt;math&gt;\text{Prim}\,\!&lt;/math&gt; is a finite set of primitive types, and &lt;math&gt;S \in \text{Tp}(\text{Prim})&lt;/math&gt;.

The relation &lt;math&gt;\triangleleft&lt;/math&gt; is the lexicon, which relates types to symbols &lt;math&gt;(\triangleleft) \subseteq \text{Tp}(\text{Prim}) \times \Sigma&lt;/math&gt;.
Since the lexicon is finite, it can be specified by listing a set of pairs like &lt;math&gt;TYPE\triangleleft\text{symbol}&lt;/math&gt;.

Such a grammar for English might have three basic types &lt;math&gt;(N,NP, \text{ and } S)\,\!&lt;/math&gt;, assigning [[count noun]]s the type &lt;math&gt;N\,\!&lt;/math&gt;, complete noun phrases the type
&lt;math&gt;NP\,\!&lt;/math&gt;, and sentences the type &lt;math&gt;S\,\!&lt;/math&gt;.
Then an [[adjective]] could have the type &lt;math&gt;N/N\,\!&lt;/math&gt;, because if it is followed by a noun then the whole phrase is a noun. 
Similarly, a [[determiner (linguistics)|determiner]] has the type &lt;math&gt;NP/N\,\!&lt;/math&gt;,
because it forms a complete noun phrase when followed by a noun.
Intransitive [[verb]]s have the type &lt;math&gt;NP\backslash S&lt;/math&gt;, and transitive verbs the type &lt;math&gt;(NP\backslash S)/NP&lt;/math&gt;.
Then a string of words is a sentence if it has overall type &lt;math&gt;S\,\!&lt;/math&gt;.

For example, take the string "the bad boy made that mess".  Now "the" and "that" are determiners, "boy" and "mess" are nouns, "bad" is an adjective, and "made" is a transitive verb, so the lexicon is
{&lt;math&gt;NP/N\triangleleft\text{the}&lt;/math&gt;,
&lt;math&gt;NP/N\triangleleft\text{that}&lt;/math&gt;,
&lt;math&gt;N\triangleleft\text{boy}&lt;/math&gt;,
&lt;math&gt;N\triangleleft\text{mess}&lt;/math&gt;,
&lt;math&gt;N/N\triangleleft\text{bad}&lt;/math&gt;,
&lt;math&gt;(NP\backslash S)/NP\triangleleft\text{made}&lt;/math&gt;}.

and the sequence of types in the string is

&lt;math&gt;
{\text{the}\atop {NP/N,}}
{\text{bad}\atop {N/N,}}
{\text{boy}\atop {N,}}
{\text{made}\atop {(NP\backslash S)/NP,}}
{\text{that}\atop {NP/N,}}
{\text{mess}\atop {N}}
&lt;/math&gt;

now find functions and appropriate arguments and reduce them according to the two [[inference rule]]s
&lt;math&gt; X\leftarrow X/Y,\; Y&lt;/math&gt; and
&lt;math&gt; X\leftarrow Y,\; Y\backslash X&lt;/math&gt;:

&lt;math&gt;.\qquad NP/N,\; N/N,\; N,\; (NP\backslash S)/NP,\; \underbrace{NP/N,\; N}&lt;/math&gt;&lt;br&gt;
&lt;math&gt;.\qquad NP/N,\; N/N,\; N,\; \underbrace{(NP\backslash S)/NP, \quad NP}&lt;/math&gt;&lt;br&gt;
&lt;math&gt;.\qquad NP/N,\; \underbrace{N/N,\; N}, \qquad (NP\backslash S)&lt;/math&gt;&lt;br&gt;
&lt;math&gt;.\qquad \underbrace{NP/N,\; \quad N},\; \qquad (NP\backslash S)&lt;/math&gt;&lt;br&gt;
&lt;math&gt;.\qquad \qquad\underbrace{NP,\; \qquad (NP\backslash S)}&lt;/math&gt;&lt;br&gt;
&lt;math&gt;.\qquad \qquad\qquad\quad\;\;\; S&lt;/math&gt;

The fact that the result is &lt;math&gt;S\,\!&lt;/math&gt; means that the string is a sentence, while the sequence of reductions shows that it must be parsed as ((the (bad boy)) (made (that mess))).

Categorial grammars of this form (having only function application rules) are equivalent in generative capacity to [[context-free grammar]]s and are thus often considered inadequate for theories of natural language syntax. Unlike CFGs, categorial grammars are [[lexicalized]], meaning that only a small number of (mostly language-independent) rules are employed, and all other syntactic phenomena derive from the lexical entries of specific words.

Another appealing aspect of categorial grammars is that it is often easy to assign them a compositional semantics, by first assigning [[interpretation type]]s to all the basic categories, and then associating all the [[derived category|derived categories]] with appropriate [[Function (mathematics)|function]] types. The interpretation of any constituent is then simply the value of a function at an argument. With some modifications to handle [[intensionality]] and [[Quantification (linguistics)|quantification]], this approach can be used to cover a wide variety of semantic phenomena.

==Lambek calculus==

A Lambek grammar is an elaboration of this idea that has a
concatenation operator for types, and several other inference rules.
Pentus has shown that these still have the generative capacity of
context-free grammars.

For the Lambek calculus, there is a type concatenation
operator &lt;math&gt;\star\,\!&lt;/math&gt;, so
that &lt;math&gt;\text{Prim}\subseteq \text{Tp}(\text{Prim})&lt;/math&gt;
and if &lt;math&gt;X, Y\in \text{Tp}(\text{Prim})&lt;/math&gt;
then &lt;math&gt;(X/Y), (X\backslash Y), (X\star Y)\in \text{Tp}(\text{Prim})&lt;/math&gt;.

The Lambek calculus consists of several deduction rules, which specify
how type inclusion assertions can be derived.  In the following
rules, upper case roman letters stand for types, upper case Greek
letters stand for sequences of types.  A sequent of the form
&lt;math&gt; X \leftarrow \Gamma &lt;/math&gt;
can be read: a string is of type &lt;math&gt;X\,\!&lt;/math&gt; if it consists of the concatenation
of strings of each of the types in &lt;math&gt;\Gamma\,\!&lt;/math&gt;.  If a type is
interpreted as a set of strings, then the
&lt;math&gt;\leftarrow&lt;/math&gt; may be interpreted as &lt;math&gt;\supseteq\,\!&lt;/math&gt;,
that is, "includes as a subset". 
A horizontal line means that the inclusion above the line
implies the one below the line.

The process is begun by the Axiom rule, which has no antecedents and
just says that any type includes itself.

&lt;math&gt;
(Axiom)\quad
{{}\over X \leftarrow X}
&lt;/math&gt;

The Cut rule says that inclusions can be composed.

&lt;math&gt;
(Cut) \quad
{Z \leftarrow \Delta X \Delta' \qquad X \leftarrow \Gamma
   \over
 Z \leftarrow \Delta \Gamma \Delta'}
&lt;/math&gt;

The other rules come in pairs, one pair for each type construction
operator, each pair consisting of one rule for the operator in the
target, one in the source, of the arrow.
The name of a rule consists of the operator and an arrow, with the
operator on the side of the arrow on which it occurs in the conclusion.

{| class="wikitable" border="1" cellpadding="5"
|-
!Target
!Source
|-
|&lt;math&gt;
(\backslash \leftarrow) \quad
{Y\leftarrow X \Gamma
   \over
 X\backslash Y\leftarrow\Gamma}
&lt;/math&gt;
|&lt;math&gt;
(\leftarrow \backslash) \quad
{Z \leftarrow \Delta Y \Delta' \qquad X\leftarrow\Gamma
   \over
 Z \leftarrow \Delta \Gamma(X\backslash Y) \Delta'}
&lt;/math&gt;
|-
|&lt;math&gt;
(/\leftarrow) \quad
{Y\leftarrow \Gamma X
  \over
Y/X\leftarrow\Gamma}
&lt;/math&gt;
|&lt;math&gt;
(\leftarrow/) \quad
{Z\leftarrow \Delta Y \Delta' \qquad X\leftarrow\Gamma 
  \over
 Z\leftarrow \Delta (Y/X)\Gamma \Delta'}
&lt;/math&gt;
|-
|&lt;math&gt;
(\star\leftarrow) \quad {X\leftarrow \Gamma \qquad Y \leftarrow \Gamma'
  \over
X \star Y \leftarrow \Gamma\Gamma'}
&lt;/math&gt;
|&lt;math&gt;
(\leftarrow\star) \quad {Z\leftarrow \Delta X Y \Delta'
   \over
Z\leftarrow \Delta (X \star Y) \Delta'}
&lt;/math&gt;
|}

For an example, here is a derivation of "type raising", which says that
&lt;math&gt;(B/A)\backslash B \leftarrow A&lt;/math&gt;.  The names of rules and the substitutions used are to the right.

&lt;math&gt; 
\dfrac {\dfrac{}{B \leftarrow B} \qquad \dfrac{}{A \leftarrow A} }
       {\dfrac {B \leftarrow (B/A), \;\; A} 
               {(B/A)\backslash B \leftarrow A} }
\qquad
\begin{matrix}
  \mbox{(Axioms)}\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad{ }\\
  {(\leftarrow/)\,\,[Z=Y=B,X=A,\Gamma=(A),\Delta=\Delta'=()]}\\
  {(\backslash\leftarrow)\,\,[Y=B,X=(B/A),\Gamma=(A)]}\qquad\qquad\qquad{ }\\
\end{matrix}
&lt;/math&gt;

===Relation to context-free grammars===

Recall that a [[context-free grammar]] is a 4-tuple:

&lt;math&gt;G = (V,\, \Sigma,\, ::=,\, S)&lt;/math&gt;
where

1. &lt;math&gt;V\, &lt;/math&gt; is a finite set of ''non-terminals'' or ''variables''.

2. &lt;math&gt;\Sigma\,&lt;/math&gt; is a finite set of ''terminal symbols''.

3. &lt;math&gt;::=\,&lt;/math&gt; is a finite set of production rules, that is, a finite relation
&lt;math&gt;(::=)\subseteq V \times (V \cup \Sigma)^*&lt;/math&gt;.

4. &lt;math&gt;S\,&lt;/math&gt; is the start variable.

From the point of view of categorial grammars, a context-free grammar
can be seen as a calculus with a set of special purpose axioms for
each language, but with no type construction operators and no
inference rules except Cut.

Specifically, given a context-free grammar as above, define a categorial
grammar 
&lt;math&gt;(\text{Prim},\, \Sigma,\, \triangleleft,\, S)&lt;/math&gt;
where  &lt;math&gt;\text{Prim}=V\cup\Sigma&lt;/math&gt;,
and   &lt;math&gt;\text{Tp}(\text{Prim})=\text{Prim}\,\!&lt;/math&gt;. 
Let there be an axiom
&lt;math&gt;{x \leftarrow x}&lt;/math&gt; for every symbol 
&lt;math&gt;x \in V\cup\Sigma&lt;/math&gt;,
an axiom &lt;math&gt;{X \leftarrow \Gamma}&lt;/math&gt; 
for every production rule &lt;math&gt;X ::= \Gamma\,\!&lt;/math&gt;,
a lexicon entry &lt;math&gt;{s \triangleleft s}&lt;/math&gt; for every terminal symbol 
&lt;math&gt;s \in \Sigma&lt;/math&gt;,
and Cut for the only rule.
This categorial grammar generates the same language as the given CFG.

Of course, this is not a basic categorial grammar, since it has
special axioms that depend upon the language; i.e. it is not lexicalized.
Also, it makes no use at all of non-primitive types.

To show that any context-free language can be generated by
a basic categorial grammar, recall that 
any context-free language can be generated by a context-free grammar
in [[Greibach normal form]].

The grammar is in Greibach normal form if every production rule is
of the form
&lt;math&gt; A ::= s A_0 \ldots A_{N-1}&lt;/math&gt;,
where capital letters are variables, &lt;math&gt;s \in \Sigma&lt;/math&gt;,
and &lt;math&gt;N\ge 0&lt;/math&gt;,
that is, the right side of the production is a single terminal symbol
followed by zero or more (non-terminal) variables.

Now given a CFG in Greibach normal form,
define a basic categorial grammar with a primitive type
for each non-terminal variable
&lt;math&gt;\text{Prim}=V\,\!&lt;/math&gt;,
and with an entry in the lexicon 
&lt;math&gt; A/A_{N-1}/ \ldots /A_0 \triangleleft s &lt;/math&gt;,
for each production rule
&lt;math&gt; A ::= s A_0 \ldots A_{N-1}&lt;/math&gt;.
It is fairly easy to see that this basic categorial grammar
generates the same language as the original CFG.
Note that the lexicon of this grammar will generally
assign multiple types to each symbol.

The same construction works for Lambek grammars, since
they are an extension of basic categorial grammars.
It is necessary to verify that the extra inference rules
do not change the generated language.  This can be done
and shows that every context-free language is generated
by some Lambek grammar.

To show the converse, that every language generated by a
Lambek grammar is context-free, is much more difficult.
It was an open problem for nearly thirty years, from
the early 1960s until about 1991 when it was proven
by Pentus.

The basic idea is, given a Lambek grammar,
&lt;math&gt;(\text{Prim},\, \Sigma,\, \triangleleft,\, S)&lt;/math&gt;
construct a context-free grammar
&lt;math&gt;(V,\, \Sigma,\, ::=,\, S)&lt;/math&gt;
with the same set of terminal symbols, the
same start symbol, with variables some (not all) types
&lt;math&gt;V\subset \text{Tp}(\text{Prim})\,\!&lt;/math&gt;,
and with a production rule
&lt;math&gt;T::=\text{s}\,\!&lt;/math&gt;
for each entry
&lt;math&gt;T\triangleleft\text{s}&lt;/math&gt;
in the lexicon,
and production rules &lt;math&gt;T::=\Gamma\,\!&lt;/math&gt;
for certain sequents &lt;math&gt;T\leftarrow\Gamma&lt;/math&gt;
that are derivable in the Lambek calculus.

Of course, there are infinitely many types
and infinitely many derivable sequents, so in
order to make a finite grammar it is necessary
put a bound on the size of the types and sequents
that are needed.  The heart of Pentus's proof
is to show that there is such a finite bound.

===Notation===
The notation in this field is not standardized.  The notations used in
formal language theory, logic, category theory, and linguistics, conflict
with each other.  In logic, arrows point to the more general from the more particular,
that is, to the conclusion from the hypotheses.  In this article,
this convention is followed, i.e. the target of the arrow is the more general (inclusive) type.

In logic, arrows usually point left to right.  In this article this convention is
reversed for consistency with the notation of context-free grammars, where the
single non-terminal symbol is always on the left.  We use the symbol &lt;math&gt;::=&lt;/math&gt;
in a production rule as in [[Backus-Naur form]].  Some authors use an arrow, which
unfortunately may point in either direction, depending on whether the grammar is
thought of as generating or recognizing the language.

Some authors on categorial grammars write &lt;math&gt;B\backslash A&lt;/math&gt; instead of
&lt;math&gt;A\backslash B&lt;/math&gt;.  The convention used here follows Lambek and algebra.

==Historical notes==
The basic ideas of categorial grammar date from work by [[Kazimierz Ajdukiewicz]] (in 1935) and [[Yehoshua Bar-Hillel]] (in 1953). In 1958, [[Joachim Lambek]] introduced a [[Lambek Calculus|syntactic calculus]] that formalized the function [[type constructors]] along with various rules for the combination of functions. This calculus is a forerunner of
[[linear logic]] in that it is a [[substructural logic]]. [[Montague grammar]] uses an ad hoc syntactic system for English that is based on the principles of categorial grammar. Although [[Richard Montague|Montague's]] work is sometimes regarded as syntactically uninteresting, it helped to bolster interest in categorial grammar by associating it with a highly successful formal treatment of natural language [[semantics]]. More recent work in categorial grammar has focused on the improvement of syntactic coverage. One formalism which has received considerable attention in recent years is [[Mark Steedman|Steedman]] and [[Anna Szabolcsi|Szabolcsi]]'s [[combinatory categorial grammar]] which builds on [[combinatory logic]] invented by [[Moses Schönfinkel]] and [[Haskell Curry]].

There are a number of related formalisms of this kind in linguistics, such as [[type logical grammar]] and [[abstract categorial grammar]].

==Some definitions==
;Derivation: A derivation is a binary tree that encodes a proof.
;Parse tree: A parse tree displays a derivation, showing the syntactic structure of a sentence.
;Functor and Argument: In a right (left) function application, the node of the type A\B (B/A) is called the functor, and the node of the type A is called an argument.
;Functor-argument structure{{what| where's the definition?|date=July 2015}}

==Refinements of categorial grammar==
A variety of changes to categorial grammar have been proposed to improve syntactic coverage. Some of the most common ones are listed below.

===Features and subcategories===
Most systems of categorial grammar subdivide categories. The most common way to do this is by tagging them with [[grammatical feature|features]], such as [[Grammatical person|person]], [[Grammatical gender|gender]], [[Grammatical number|number]], and [[Grammatical tense|tense]]. Sometimes only atomic categories are tagged in this way. In Montague grammar, it is traditional to subdivide function categories using a multiple slash convention, so ''A/B'' and ''A//B'' would be two distinct categories of left-applying functions, that took the same arguments but could be distinguished between by other functions taking them as arguments.

===Function composition===
Rules of function composition are included in many categorial grammars. An example of such a rule would be one that allowed the concatenation of a constituent of type ''A/B'' with one of type ''B/C'' to produce a new constituent of type ''A/C''. The semantics of such a rule would simply involve the composition of the functions involved. Function composition is important in categorial accounts of [[logical conjunction|conjunction]] and extraction, especially as they relate to phenomena like [[right node raising]]. The introduction of function composition into a categorial grammar leads to many kinds of derivational ambiguity that are vacuous in the sense that they do not correspond to semantic ambiguities.

===Conjunction===
Many categorial grammars include a typical conjunction rule, of the general form ''X CONJ X → X'', where ''X'' is a category. Conjunction can generally be applied to nonstandard constituents resulting from type raising or function composition..

===Discontinuity===
The grammar is extended to handle linguistic phenomena such as discontinuous idioms, gapping and extraction.

==See also==
*[[Combinatory categorial grammar]]
*[[Noncommutative logic]]
*[[Pregroup Grammar]]
*[[Link grammar]]

==References==
*{{citation |last1=Curry|first1=Haskell B.|author1-link=Haskell Curry |first2=Richard |last2= Feys|year=1958 | title= Combinatory Logic |volume= 1 |publisher=North-Holland}}
*{{citation |last1=Jacobson|first1= Pauline|author1-link=Pauline Jacobson |title=Towards a variable-free semantics. |journal=Linguistics and Philosophy|volume=22|year=1999 |pages=117–184}}
*{{citation |last1=Lambek |first1=Joachim|author1-link=Joachim Lambek|year=1958 |title=The mathematics of sentence structure |journal=[[American Mathematical Monthly|Amer. Math. Monthly]]|volume= 65 |pages=154–170}}
*{{citation |last1=Pentus |first1= Mati |year=1997 |title=Lambek Calculus and Formal Grammars| publisher= Amer. Math. Soc. Transl.}}
*{{citation |last1=Steedman|first1=Mark |author1-link=Mark Steedman|year=1987 |title=Combinatory grammars and parasitic gaps |journal=Natural Language and Linguistic Theory |volume=5|pages=403–439|doi=10.1007/bf00134555}}
*{{citation |last1=Steedman|first1= Mark |author1-link=Mark Steedman|year=1996 |title=Surface Structure and Interpretation|publisher=[[The MIT Press]]}}
*{{citation |last1=Steedman|first1=Mark |author1-link=Mark Steedman |year=2000 | title=The Syntactic Process |publisher=[[The MIT Press]]}}
*{{cite book |last1=Szabolcsi|first1=Anna|year=1989|chapter=Bound variables in syntax (are there any?)|title=Semantics and Contextual Expression| editor1-last=Bartsch|editor2-last=van Benthem|editor3= van Emde Boas|publisher= Foris |pages=294–318}}
*{{cite book |last1=Szabolcsi |first1=Anna |year=1992 |chapter=Combinatory grammar and projection from the lexicon|title=Lexical Matters|journal=CSLI Lecture Notes|volume=24|editor1=Sag|editor2= Szabolcsi |publication-place=Stanford |publisher=CSLI Publications |pages= 241–269}}
*{{citation |last1=Szabolcsi |first1=Anna |year=2003 |chapter=Binding on the fly: Cross-sentential anaphora in variable-free semantics|title=Resource Sensitivity in Binding and Anaphora|editor1= Kruijff |editor2=Oehrle |publisher=Kluwer |pages=215–229|doi=10.1007/978-94-010-0037-6_8}}
*{{citation |last1=Morril |first1=Glyn |year=1995 |title=Discontinuity in categorial grammar |journal=Linguistics and Philosophy |publisher=Springer |pages=175-219|doi=10.1007/bf00985216}}

==Further reading==
* Michael Moortgat, ''Categorial Type Logics'', Chapter 2 in J. van Benthem and A. ter Meulen (eds.) ''Handbook of Logic and Language''. Elsevier, 1997, {{ISBN|0-262-22053-9}}
* Wojciech Buszkowski, ''Mathematical linguistics and proof theory'', Chapter 12 in J. van Benthem and A. ter Meulen (eds.) ''Handbook of Logic and Language''. Elsevier, 1997, {{ISBN|0-262-22053-9}}
* {{cite book|author=Gerhard Jäger|title=Anaphora and Type Logical Grammar|year=2005|publisher=Springer|isbn=978-1-4020-3904-1}}
* {{cite book|author=Glyn Morrill|title=Categorial Grammar: Logical Syntax, Semantics, and Processing|year=2010|publisher=Oxford University Press|isbn=978-0-19-958986-9}}
* {{cite book|author1=Richard Moot|author2=Christian Retore|title=The Logic of Categorial Grammars: A Deductive Account of Natural Language Syntax and Semantics|year=2012|publisher=Springer Verlag|isbn=978-3-642-31554-1}}

==External links==
* [http://eom.springer.de/g/g044770.htm Grammar, categorial] at Springer [[Encyclopaedia of Mathematics]]
* http://plato.stanford.edu/entries/typelogical-grammar/

[[Category:Grammar frameworks]]
[[Category:Formal languages]]
[[Category:Computational linguistics]]
[[Category:Type theory]]</text>
      <sha1>8q3m6v3afakxfouau0prdl3sxwm0jm0</sha1>
    </revision>
  </page>
  <page>
    <title>Clockwise</title>
    <ns>0</ns>
    <id>26569682</id>
    <revision>
      <id>864791421</id>
      <parentid>864782512</parentid>
      <timestamp>2018-10-19T13:51:49Z</timestamp>
      <contributor>
        <username>Purgy Purgatorio</username>
        <id>22035051</id>
      </contributor>
      <comment>Undid revision 864782512 by [[Special:Contributions/201.76.183.242|201.76.183.242]] ([[User talk:201.76.183.242|talk]])unexplained</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8399">{{about|the direction}}
[[Image:Clockwise arrow.svg|thumb|right|The clockwise direction]]
Two-dimensional [[rotation]] can occur in two possible directions. A '''clockwise''' (typically abbreviated as '''CW''') motion is one that proceeds in the same direction as a [[clock]]'s hands: from the top to the right, then down and then to the left, and back up to the top. The opposite sense of [[rotation]] or [[Turn_(geometry)|revolution]] is (in [[North American English]]) '''counterclockwise''' ('''CCW''') or (in [[Commonwealth English]]) '''anticlockwise''' ('''ACW''').

==Terminology==
Before clocks were commonplace, the terms "[[sunwise]]" and "deasil", "deiseil" and even "deocil" from the [[Scottish Gaelic]] language and from the same root as the Latin "dexter" ("right") were used for clockwise. "[[Widdershins]]" or "withershins" (from [[Middle Low German]] "weddersinnes", "opposite course") was used for counterclockwise.{{Citation needed|date=March 2012}}
[[Image:Counterclockwise arrow.svg|thumb|right|The counterclockwise or anticlockwise direction]]

The terms clockwise and counterclockwise can only be applied to a rotational motion once a side of the rotational plane is specified, from which the rotation is observed. For example, the daily rotation of the [[Earth]] is clockwise  when viewed from above the [[South Pole]], and counterclockwise when viewed from above the [[North Pole]] (considering "above a point" to be defined as "farther away from the center of earth and on the same ray").

Clocks traditionally follow this sense of rotation because of the clock's predecessor: the [[sundial]]. Clocks with hands were first built in the Northern Hemisphere (see ''[[Clock]]''), and they were made to work like horizontal sundials. In order for such a sundial to work north of the equator during spring and summer, and north of the [[Tropic of Cancer]] the whole year, the noon-mark of the dial must be placed northward of the pole casting the shadow. Then, when the [[Sun]] moves in the sky (from east to south to west), the shadow, which is cast on the sundial in the opposite direction, moves with the same sense of rotation (from west to north to east). This is why hours must be drawn in horizontal sundials in that manner, and why modern clocks have their numbers set in the same way, and their hands moving accordingly. For a vertical sundial (such as those placed on the walls of buildings, the dial being ''below'' the post), the movement of the sun is from right to top to left, and, accordingly, the shadow moves from left to down to right, i.e., counterclockwise. This effect is caused by the plane of the dial having been rotated through the plane of the motion of the sun and thus the shadow is observed from the other side of the dial's plane and is observed as moving in the opposite direction. Some clocks were constructed to mimic this. The best-known surviving example is the astronomical clock in the [[Münster Cathedral]], whose hands move counterclockwise.

Occasionally, clocks whose hands revolve counterclockwise are nowadays sold as a novelty. Historically, some [[Judaism|Jewish]] clocks were built that way, for example in some synagogue towers in Europe such as the [[Jewish Town Hall (Prague)|Jewish Town Hall in Prague]], to accord with right-to-left reading in the [[Hebrew language]]. In 2014 under [[Bolivia]]n president [[Evo Morales]], the clock outside the Legislative Assembly in [[Plaza Murillo]], [[La Paz, Bolivia|La Paz]], was shifted to counterclockwise motion to promote indigenous values.&lt;ref&gt;{{cite web |url= https://www.theguardian.com/world/2014/jun/25/bolivia-clocks-time-run-different|title= Bolivia turns back the clock in bid to rediscover identity and 'southernness'|author= Sam Jones and Sara Shahriari|date= June 25, 2014|publisher= The Guardian|accessdate=June 26, 2014}}&lt;/ref&gt;

==Usage==
===Shop-work===
Typical [[Nut (hardware)|nuts]], [[screw]]s, [[Screw#Bolt|bolt]]s, [[bottle cap]]s, and jar lids are tightened (moved away from the observer) clockwise and loosened (moved towards the observer) counterclockwise in accordance with the [[right-hand rule]].

To apply the right-hand rule, place one's loosely clenched right hand above the object with the thumb pointing in the direction one wants the screw, nut, bolt, or cap ultimately to move, and the curl of the fingers, from the palm to the tips, will indicate in which way one needs to turn the screw, nut, bolt or cap to achieve the desired result. Almost all threaded objects obey this rule except for a few left-handed exceptions described below.

The reason for the clockwise standard for most screws and bolts is that [[supination]] of the arm, which is used by a right-handed person to tighten a screw clockwise, is generally stronger than [[pronation]] used to loosen. 

Sometimes the opposite (left-handed, counterclockwise, reverse) sense of threading is used for a special reason. A thread might need to be left-handed to prevent operational stresses from loosening it. For example, some older [[car]]s and trucks had right-handed [[lug nut]]s on the right wheels and left-handed lug nuts on the left wheels, so that, as the vehicle moved forward, the lug nuts tended to tighten rather than loosen.  For [[bicycle pedal]]s, the one on the left must be reverse-threaded to prevent it unscrewing during use. Similarly, the [[Spinning wheel#Treadle wheel|flyer whorl]] of a [[spinning wheel]] uses a left-hand thread to keep it from loosening. A [[turnbuckle]] has right-handed threads on one end and left-handed threads on the other.  Some gas fittings are left-handed to prevent disastrous misconnections: oxygen fittings are right-handed, but [[acetylene]], [[propane]], and other flammable gases are unmistakably distinguished by left-handed fittings.

===Mathematics===
In [[trigonometry]] and [[mathematics]] in general, plane [[angle]]s are conventionally measured counterclockwise, starting with 0° or 0 [[radian]]s pointing directly to the right (or east), and 90° pointing straight up (or north).  However, in [[navigation]], [[compass]] headings increase clockwise around the compass face, starting with 0° at the top of the compass (the northerly direction), with 90° to the right (east).

A circle defined parametrically in a [[Cartesian coordinate system#Orientation and "handedness"|positive Cartesian plane]] by the equations {{nowrap|1=''x'' = cos ''t''}} and {{nowrap|1=''y'' = sin ''t''}} is traced counterclockwise as the angle ''t'' increases in value, from the right-most point at {{nowrap|1=''t'' = 0}}. An alternative formulation with sin and cos swapped gives a clockwise trace from the upper-most point.

===Games and activities===
In general, most card games, board games, parlor games and multiple team sports play in a clock-wise turn rotation in Western Countries and Latin America with a notable resistance to playing in the opposite direction (counter-clockwise). Traditionally (and still continued for the most part) turns pass counter-clockwise in many Asian countries. In Western countries when speaking and discussion activities take part in a circle, turns tend to naturally pass in a clockwise motion even though there is no obligation to do so. Curiously, unlike with games, there is usually no objection when the activity uncharacteristically begins in a counter-clockwise motion.

Notably, the game of baseball is played counter-clockwise.

==In humans==
Most left-handed people prefer to draw circles and circulate in buildings clockwise, while most right-handed people prefer to draw circles and circulate in buildings counterclockwise. This is believed to result from dominant brain hemispheres,&lt;ref&gt;Theodore H. Blau, ''The torque test: A measurement of cerebral dominance.'' 1974, American Psychological Association.&lt;/ref&gt; though some attribute it to muscle mechanics.&lt;ref&gt;
Ack Demarest &amp; Lorrie Demarest, 'DOES THE TORQUE TEST' MEASURE CEREBRAL DOMINANCE IN ADULTS?', 1980, Perceptual and Motor Skills: Volume 50, Issue , pp. 155-158  http://www.amsciepub.com/doi/abs/10.2466/pms.1980.50.1.155?journalCode=pms&lt;/ref&gt;

==See also==
* [[Handedness]]
* [[Chirality (physics)]], [[Chirality (chemistry)]]
* [[Inner/outer orientation]]
* [[Optical isomerism]]
* [[Retrograde motion]]
* [[Relative direction]]

==References==
{{reflist|2}}

[[Category:Concepts in physics]]
[[Category:Orientation (geometry)]]</text>
      <sha1>pfhtdrx4ovve1zy01fegvl31rs2tkf4</sha1>
    </revision>
  </page>
  <page>
    <title>Comprehensive School Mathematics Program</title>
    <ns>0</ns>
    <id>1765838</id>
    <revision>
      <id>832796647</id>
      <parentid>832796481</parentid>
      <timestamp>2018-03-28T01:45:33Z</timestamp>
      <contributor>
        <username>Oshwah</username>
        <id>3174456</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/162.156.33.119|162.156.33.119]] ([[User talk:162.156.33.119|talk]]): addition of [[WP:CITE|unsourced content]] ([[WP:HG|HG]]) (3.3.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7553">'''Comprehensive School Mathematics Program''' (CSMP) stands for both the name of a curriculum and the name of the project that was responsible for developing curriculum materials. 

Two major curricula were developed under CSMP project, Comprehensive School Mathematics Program(CSMP), a K-6 mathematics program for regular classroom instruction, and the Elements of Mathematics (EM) program, a grades 7-12 mathematics program for gifted students. EM treats traditional topics rigorously and in depth and was the only curriculum that strictly adhere to the Goals for School Mathematics: The Report of the Cambridge Conference on School Mathematics (1963). As a result, it includes much of the content generally required for an undergraduate mathematics major. These two curricula are unrelated to one another but certain members of the CSMP staff contributed to the development of both projects.  (There was also some interaction with the [[Secondary School Mathematics Curriculum Improvement Study]] program being developed around the same time.)  The Elements of Mathematics is widely used at the IMACS institute listed below.  What follows is a description of the K-6 program that was designed for a general heterogeneous audience.

The CSMP Project was established in 1966, under the direction of Burt Kaufman, who remained director until 1979 when Clare Heidema became director until 2003. It was originally affiliated with Southern Illinois University in Carbondale, Illinois. After a year of planning, CSMP was incorporated into the Central Midwest Regional Educational Laboratory (later CEMREL, Inc.), one of the national educational laboratories funded at that time by the U.S. Office of Education. (see Final Evaluation Report by Martin Herbert referenced below for more detail) . In 1984, the project moved to Mid-continental Research for Learning (McREL) Institute's Comprehensive School Reform program, who supported the program until 2003. Clare Heidema remained director to its conclusion.  In 1984, it was implemented in 150 school districts in 42 states and about 55,000 students.

== Overview ==

The most influential figure on this project was Frederque’ Papy.  This project employs four non-verbal languages for the purpose of posing problems and representing mathematical concepts.  They are: the Papy Minicomputer(mental computation), Arrows(relations), Strings(classification) and Calculators(patterns). It was designed to teach mathematics as a problem solving activity rather than just teaching arithmetic skills. The program was highly structured using the spiral scheme of program development. It introduced many basic concepts such as fractions earlier than normal but was criticized for lack of emphasis given to calculation. New content in probability and geometry was introduced. There was a range of supporting material including story books with mathematical problems. Lessons were often posed in a story.  One character in these books was Eli the Elephant, a [[Elephant|pachyderm]] with a bag of magic peanuts &amp;mdash; some representing positive integers, some negative.

== Mini-computer ==

[[Image:CSMP mini computer.svg|thumb|right|300px|The number 9067 represented on a mini-computer.]]
One device used throughout the program was a ''mini-computer''. This was a 2 by 2 grid of squares, the squares represented the numbers 1, 2, 4, and 8. Checkers could be placed on the grid to represent different numbers in a similar fashion to the way the [[binary numeral system]] is used to represent numbers in a [[computer]].

The mini-computer is laid out as follows: a white square in the lower right corner with a value of 1, a red square in the lower left with a value of 2, a purple square in the upper right with a value of 4, and a brown square in the upper left with a value of 8. Each mini-computer is designed to represent a single decimal digit, and multiple mini-computers can be used together to represent multiple-digit numbers. Each successive board's values are increased by a power of ten. For example, a second mini-computer's squares will represent 10, 20, 40, and 80; a third, 100, 200, 400, and 800, and so on.

Students are instructed to represent values on the mini-computers by adding checkers to the proper squares. To do this only requires a memorization of representations for the digits zero through nine, although non-standard representations are possible since squares can hold more than one checker. Each checker is worth the value of the square it is in, and the sum of the checkers on the board(s) determine the overall value represented. Most checkers used by students are a solid color- any color is fine. The only exception is checkers marked with a [[caret]] (^), which are negative.

An example of representing a number: 9067 requires four boards. The leftmost board has two checkers in the 8 and 1 squares (8000 + 1000). The second board has none, as the value has zero hundreds. The third board has checkers in the 4 and 2 squares (40 + 20), and the rightmost board has checkers in the 4, 2, and 1 squares (4 + 2 + 1). Together, these 7 values (8000 + 1000 + 40 + 20 + 4 + 2 + 1) total up to 9067.

This would be considered a standard way to represent the number as it involves the fewest checkers possible without involving negatives. It would be simpler to replace the last board with a positive checker in the 8 and a negative checker in the 1, but this is not taught as the standard.

Arithmetic can be performed on the mini-computer by combining two numbers' representations into a single board and performing simplification techniques. One such technique is to replace checkers from the 8 and 2 squares of one board with a checker on the 1 square of the adjacent board to the left. Another technique is to replace a pair of checkers in the same square with one checker in the next higher square, such as two 4's with an 8.

==Study results==

The program received extensive evaluation, with over 50 studies. These studies showed broadly similar results for non CSMP students in computation, concepts and applications. However there was a marked improvement when assessed according to The Mathematics Applied to Novel Situations (MANS) tests which were introduced to measure students ability for problem solving in novel situations.

==Copyright==

==Current curriculum use==
Burt Kaufman, a mathematics curriculum specialist, headed the team at SIU writing CSMP.  He eventually started the Institute for Mathematics &amp; Computer Science (IMACS).  IMACS appears to use elements of the program in their "Mathematics Enrichment" program. For instance, mini-computers and "Eli the Elephant" are present in the IMACS material. IMACS is a private education business focusing on the instruction of students from first grade through high school.{{cn|date=April 2016}}https://www.imacs.org/about/news/burt-kaufman.html
==References==
*[http://stern.buffalostate.edu/Evaluation/1984CSMPFinalReport.pdf CSMP final evaluation report]
*[http://stern.buffalostate.edu/Evaluation/ReporttotheProgramEffectivenessPanel.pdf Report to the Program Effectiveness Panel]
*[http://www.mathcurriculumcenter.org/PDFS/CCM/summaries/cambridge_summary.pdf Goals for School Mathematics: The Report of the Cambridge Conference on School Mathematics (1963).]
== External links ==
*[http://stern.buffalostate.edu A comprehensive archive of CSMP materials from Buffalo State]
*[http://www.imacs.org Institute for Mathematics and Computer Science]
*[http://www.mcrel.org MCREL]

[[Category:Mathematics education]]</text>
      <sha1>1383eo3d7mdkry28fnt0hojdonc1uxm</sha1>
    </revision>
  </page>
  <page>
    <title>Conway polyhedron notation</title>
    <ns>0</ns>
    <id>5021705</id>
    <revision>
      <id>868373944</id>
      <parentid>867961831</parentid>
      <timestamp>2018-11-11T20:09:46Z</timestamp>
      <contributor>
        <username>Kevin Lamoreau</username>
        <id>105726</id>
      </contributor>
      <minor/>
      <comment>/* Operators */ t(C) doesn't equal aC, but a(C) does.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="44453">[[File:Conway relational chart.png|400px|thumb|This example chart shows how 11 new forms can be derived from the cube using 3 operations. The new polyhedra are shown as maps on the surface of the cube so the topological changes are more apparent. Vertices are marked in all forms with circles.]]
In geometry, '''Conway polyhedron notation''', invented by [[John Horton Conway]] and promoted by [[George W. Hart]], is used to describe [[polyhedron|polyhedra]] based on a seed polyhedron modified by various prefix [[operation (mathematics)|operation]]s.&lt;ref name="SoT"&gt;{{cite book|author1=John Horton Conway|author2=Heidi Burgiel|author3=Chaim Goodman-Strass| title=The Symmetries of Things|year=2008|isbn=978-1-56881-220-5|chapter= Chapter 21: Naming the Archimedean and Catalan polyhedra and Tilings}}&lt;/ref&gt;&lt;ref&gt;{{mathworld|id=ConwayPolyhedronNotation|title=Conway Polyhedron Notation}}&lt;/ref&gt;

Conway and Hart extended the idea of using operators, like [[Truncation (geometry)|truncation]] as defined by [[Kepler]], to build related polyhedra of the same symmetry. For example, ''tC'' represents a [[truncated cube]], and ''taC'', parsed as {{tmath|t(aC)}}, is a [[truncated cuboctahedron]]. The simplest operator [[Dual polyhedron|dual]] swaps vertex and face elements; e.g., a dual cube is an octahedron: ''dC''=''O''. Applied in a series, these operators allow many higher order polyhedra to be generated. Conway defined the operators ''abdegjkmost'', while Hart added ''r'' and ''p''.&lt;ref name="Hart"&gt;{{cite web|url=http://www.georgehart.com/virtual-polyhedra/conway_notation.html|author=George W. Hart|title=Conway Notation for Polyhedra|website=Virtual Polyhedra|date=1998}}&lt;/ref&gt; Conway's basic operations are sufficient to generate the [[Archimedean solid|Archimedean]] and [[Catalan solid]]s from the Platonic solids. Some basic operations can be made as composites of others. Later implementations named further operators, sometimes referred to as "extended" operators.&lt;ref name="Antiprism"&gt;{{cite web|url=http://www.antiprism.com/programs/conway.html|author=Adrian Rossiter|title=conway - Conway Notation transformations|website=Antiprism Polyhedron Modelling Software}}&lt;/ref&gt;&lt;ref name="Levskaya"&gt;{{cite web|url=https://levskaya.github.io/polyhedronisme/|author=Anselm Levskaya|title=polyHédronisme}}&lt;/ref&gt;

In general, it is difficult to predict the resulting appearance of the composite of two or more operations from a given seed polyhedron. For instance, ambo applied twice is the expand operation: ''aa'' = ''e'', while a truncation after ambo produces [[bevel]]: ''ta'' = ''b''. Many basic questions about Conway operators remain open, for instance, how many operators of a given "size" exist.&lt;ref name=Brinkmann&gt;{{Cite journal|year=2017|title=Goldberg, Fuller, Caspar, Klug and Coxeter and a general approach to local symmetry-preserving operations|journal=Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences|volume=473|issue=2206|pages=20170267|arxiv=1705.02848|last1=Brinkmann|first1=G.|last2=Goetschalckx|first2=P.|last3=Schein|first3=S.|doi=10.1098/rspa.2017.0267|bibcode=2017RSPSA.47370267B}}&lt;/ref&gt;

== Operators ==
In Conway's notation, operations on polyhedra are applied like functions, from right to left. For example, a [[cuboctahedron]] is an ''ambo&lt;ref&gt;{{cite web|url=http://www.georgehart.com/virtual-polyhedra/conway_notation.html |title=Conway Notation for Polyhedra| website=Virtual Polyhedra| date=1998| first=George| last=Hart}} (See fourth row in table, "a = ambo".)&lt;/ref&gt; cube'', i.e. {{tmath|1=a(C) = aC}}, and a [[truncated cuboctahedron]] is {{tmath|1=t(a(C)) = t(aC) = taC}}. Repeated application of an operator can be denoted with an exponent: ''j&lt;sup&gt;2&lt;/sup&gt;'' = ''o''. In general, Conway operators are not [[commutative]]. The resulting polyhedron has a fixed topology (vertices, edges, faces), while exact geometry is not specified: it can be thought of as one of many [[graph embedding|embeddings]] of a [[polyhedral graph]] on the sphere. Often the polyhedron is put into [[Canonical polyhedron|canonical form]].

Individual operators can be visualized in terms of "chambers", as below. Each white chamber is a rotated version of the others. For [[achiral]] operators, the red chambers are a reflection of the white chambers. Achiral and [[chiral]] operators are also called local symmetry-preserving operations (LSP) and local operations that preserve orientation-preserving symmetries (LOPSP), respectively, although the exact definition is a little more restrictive.&lt;ref name="Brinkmann" /&gt;
&lt;gallery mode="packed"&gt;
File:Triangle chambers.svg
File:Quadrilateral chambers.svg
File:Pentagon chambers.svg
File:Hexagon chambers.svg
&lt;/gallery&gt;

{| class="wikitable floatright"
|-
! x 
| &lt;math&gt;\begin{bmatrix}
  a &amp; b &amp; c \\
  0 &amp; d &amp; 0 \\
  a' &amp; b' &amp; c'
  \end{bmatrix}=\mathbf{M}_x&lt;/math&gt; 
|-
! xd
| &lt;math&gt;\begin{bmatrix}
  c &amp; b &amp; a \\
  0 &amp; d &amp; 0 \\
  c' &amp; b' &amp; a'
  \end{bmatrix}=\mathbf{M}_x\mathbf{M}_d&lt;/math&gt; 
|-
!dx
| &lt;math&gt;\begin{bmatrix}
  a' &amp; b' &amp; c' \\
  0 &amp; d &amp; 0 \\
  a &amp; b &amp; c
  \end{bmatrix}=\mathbf{M}_d\mathbf{M}_x&lt;/math&gt; 
|-
!dxd
| &lt;math&gt;\begin{bmatrix}
  c' &amp; b' &amp; a' \\
  0 &amp; d &amp; 0 \\
  c &amp; b &amp; a
  \end{bmatrix} = \mathbf{M}_d\mathbf{M}_x\mathbf{M}_d&lt;/math&gt; 
|}
The relationship between the number of vertices, edges, and faces of the seed and the polyhedron created by the operations listed in this article can be expressed as a matrix &lt;math&gt;\mathbf{M}_x&lt;/math&gt;. When ''x'' is the operator, &lt;math&gt;v,e,f&lt;/math&gt; are the vertices, edges, and faces of the seed (respectively), and &lt;math&gt;v',e',f'&lt;/math&gt; are the vertices, edges, and faces of the result, then 

:&lt;math&gt;\mathbf{M}_x \begin{bmatrix} v \\ e \\ f \end{bmatrix} = \begin{bmatrix} v' \\ e' \\ f' \end{bmatrix}&lt;/math&gt;.

The matrix for the composition of two operators is just the product of the matrixes for the two operators. Distinct operators may have the same matrix, for example, ''p'' and ''l''. The edge count of the result is an integer multiple ''d'' of that of the seed: this is called the inflation rate, or the edge factor.&lt;ref name="Brinkmann" /&gt;

The simplest operators, the [[identity operator]] ''S'' and the [[Dual polyhedron|dual operator]] ''d'', have simple matrix forms:
: &lt;math&gt;\mathbf{M}_S = \begin{bmatrix}
  1 &amp; 0 &amp; 0 \\
  0 &amp; 1 &amp; 0 \\
  0 &amp; 0 &amp; 1
  \end{bmatrix} = \mathbf{I}_3&lt;/math&gt;, &lt;math&gt;\mathbf{M}_d = \begin{bmatrix}
  0 &amp; 0 &amp; 1 \\
  0 &amp; 1 &amp; 0 \\
  1 &amp; 0 &amp; 0
  \end{bmatrix}&lt;/math&gt;
Two dual operators cancel out; ''dd'' = ''S'', and the square of &lt;math&gt;\mathbf{M}_d&lt;/math&gt; is the [[identity matrix]]. When applied to other operators, the dual operator corresponds to horizontal and vertical reflections of the matrix. Operators can be grouped into groups of four (or fewer if some forms are the same) by identifying the operators ''x'', ''xd'' (operator of dual), ''dx'' (dual of operator), and ''dxd'' (conjugate of operator). In this article, only the matrix for ''x'' is given, since the others are simple reflections.

Hart introduced the reflection operator ''r'', that gives the mirror image of the polyhedron.{{cn|date=October 2018 &lt;!--Hart 1998?--&gt;}} This is not strictly a LOPSP, since it does not preserve orientation (it reverses it). ''r'' has no effect on achiral seeds, and ''rr'' returns the original seed. An overline can be used to indicate the other chiral form of an operator, like {{overline|''s''}} = ''rsr''. ''r'' does not affect the matrix.

An operation is irreducible if it cannot be expressed as a composition of operators aside from ''d'' and ''r''. The majority of Conway's original operators are irreducible: the exceptions are ''e'', ''b'', ''o'', and ''m''.

Some open questions about Conway operators include:&lt;ref name="Brinkmann" /&gt;
* Are there two non-equivalent series of operations, not related by ''d'' or ''r'', that create the same polyhedron from the same seed?
* How many Conway operators exist for a given inflation rate?
* Can an algorithm be developed to generate all the Conway operators for a given inflation rate?
* Can an algorithm be developed to decompose a given polyhedron into a series of operations on a smaller seed?

== Original operations ==
Strictly, seed (''S''), needle (''n''), and zip (''z'') were not included by Conway, but they are related to original Conway operations by duality so are included here.

From here on, operations are visualized on cube seeds, drawn on the surface of that cube. Blue faces cross edges of the seed, and pink faces lie over vertices of the seed. There is some flexibility in the exact placement of vertices, especially with chiral operators. 

{| class="wikitable sortable" style="text-align: center"
|+Original Conway operators
|-
! Edge factor !! Matrix &lt;math&gt;\mathbf{M}_x&lt;/math&gt;!!x !! xd !!dx !!  dxd !! Notes
|-
| 1 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 0 &amp; 0 \\
  0 &amp; 1 &amp; 0 \\
  0 &amp; 0 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Conway_C.png|100px]]&lt;br&gt;'''Seed''': ''S''
|colspan="2"| [[File:Conway_dC.png|100px]]&lt;br&gt;'''Dual''': ''d'' 
| [[File:Conway_C.png|100px]]&lt;br&gt;'''Seed''': ''dd'' = ''S''
| Dual replaces each face with a vertex, and each vertex with a face.
|-
| 2 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 0 &amp; 1 \\
  0 &amp; 2 &amp; 0 \\
  0 &amp; 1 &amp; 0
  \end{bmatrix}&lt;/math&gt;
|colspan="2"| [[File:Conway_jC.png|100px]]&lt;br&gt;'''Join''': ''j''
|colspan="2"| [[File:Conway_aC.png|100px]]&lt;br&gt;'''Ambo''': ''a'' 
| Join creates quadrilateral faces. Ambo creates degree-4 vertices, and is also called [[rectification (geometry)|rectification]], or the [[medial graph]] in graph theory.&lt;ref&gt;{{mathworld|id=Rectification|title=Rectification}}&lt;/ref&gt; 
|-
| 3 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 0 &amp; 1 \\
  0 &amp; 3 &amp; 0 \\
  0 &amp; 2 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Conway_kC.png|100px]]&lt;br&gt;'''Kis''': ''k'' 
| [[File:Conway_kdC.png|100px]]&lt;br&gt;'''Needle''': ''n'' 
| [[File:Conway_dkC.png|100px]]&lt;br&gt;'''Zip''': ''z''
| [[File:Conway_tC.png|100px]]&lt;br&gt;'''Truncate''': ''t'' 
| Kis raises a pyramid on each face, and is also called akisation, [[Kleetope]], cumulation,&lt;ref&gt;{{mathworld|id=Cumulation|title=Cumulation}}&lt;/ref&gt; accretion, or pyramid-[[augmentation (geometry)|augmentation]]. [[Truncation (geometry)|Truncate]] cuts off the polyhedron at its vertices but leaves a portion of the original edges.&lt;ref&gt;{{mathworld|id=Truncation|title=Truncation}}&lt;/ref&gt; Zip is also called [[bitruncation]].
|-
| 4 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 1 &amp; 1 \\
  0 &amp; 4 &amp; 0 \\
  0 &amp; 2 &amp; 0
  \end{bmatrix}&lt;/math&gt;
|colspan=2| [[File:Conway_oC.png|100px]]&lt;br&gt; '''Ortho''': ''o'' = ''jj''
|colspan=2| [[File:Conway_eC.png|100px]]&lt;br&gt; '''Expand''': ''e'' = ''aa''
|
|-
| 5
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 1 \\
  0 &amp; 5 &amp; 0 \\
  0 &amp; 2 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Conway_gC.png|100px]]&lt;br&gt;'''Gyro''': ''g''
| ''gd'' = ''rgr''
| ''sd'' = ''rsr''
| [[File:Conway_sC.png|100px]]&lt;br&gt;'''Snub''': ''s''
| Chiral operators. See [[Snub (geometry)]]. Contrary to Hart,&lt;ref name="Hart" /&gt; ''gd'' is not the same as ''g'': it is its chiral pair.&lt;ref&gt;{{cite web|title=Antiprism - Chirality issue in conway|url=https://groups.google.com/forum/#!topic/antiprism/6NcYnKP4mTc}}&lt;/ref&gt;
|-
| 6
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 1 &amp; 1 \\
  0 &amp; 6 &amp; 0 \\
  0 &amp; 4 &amp; 0
  \end{bmatrix}&lt;/math&gt;
|colspan="2"| [[File:Conway_mC.png|100px]]&lt;br&gt; '''Meta''': ''m'' = ''kj''
|colspan="2"| [[File:Conway_bC.png|100px]]&lt;br&gt; '''Bevel''': ''b'' = ''ta''
|
|}

== Seeds ==
Any polyhedron can serve as a seed, as long as the operations can be executed on it. Common seeds have been assigned a letter.
The [[Platonic solid]]s are represented by the first letter of their name ([[Tetrahedron|'''T'''etrahedron]], [[Octahedron|'''O'''ctahedron]], [[Cube|'''C'''ube]], [[Icosahedron|'''I'''cosahedron]], [[Dodecahedron|'''D'''odecahedron]]); the [[prism (geometry)|'''p'''rism]]s ('''P'''&lt;sub&gt;''n''&lt;/sub&gt;) for ''n''-gonal forms; [[antiprism|'''a'''ntiprisms]] ('''A'''&lt;sub&gt;''n''&lt;/sub&gt;); [[Cupola (geometry)|c'''u'''polae]] ('''U'''&lt;sub&gt;''n''&lt;/sub&gt;); [[anticupola]]e ('''V'''&lt;sub&gt;''n''&lt;/sub&gt;); and [[pyramid (geometry)|p'''y'''ramid]]s ('''Y'''&lt;sub&gt;''n''&lt;/sub&gt;). Any [[Johnson solid|'''J'''ohnson solid]] can be referenced as '''J'''&lt;sub&gt;''n''&lt;/sub&gt;, for ''n''=1..92.

All of the five regular polyhedra can be generated from prismatic generators with zero to two operators:&lt;ref&gt;{{cite journal|url=http://www.mi.sanu.ac.rs/vismath/zefiro2008/__generation_of_icosahedron_by_5tetrahedra.htm|title=Generation of an icosahedron by the intersection of five tetrahedra: geometrical and crystallographic features of the intermediate polyhedra|author=Livio Zefiro|journal=Vismath|year=2008}}&lt;/ref&gt;
{{div col}}
* '''[[Triangular pyramid]]''': ''Y''&lt;sub&gt;3&lt;/sub&gt; (A tetrahedron is a special pyramid)
** ''[[Tetrahedron|T]]'' = ''Y''&lt;sub&gt;3&lt;/sub&gt;   
** ''[[Octahedron|O]]'' = ''aT''  (ambo tetrahedron)
** ''[[Cube|C]]'' = ''jT'' (join tetrahedron)
** ''[[Regular icosahedron|I]]'' = ''sT''  (snub tetrahedron)
** ''[[Regular dodecahedron|D]]'' = ''gT'' (gyro tetrahedron)
* '''[[Antiprism|Triangular antiprism]]''': ''A''&lt;sub&gt;3&lt;/sub&gt; (An octahedron is a special antiprism)
** ''O'' = ''A''&lt;sub&gt;3&lt;/sub&gt;
** ''C'' = ''dA''&lt;sub&gt;3&lt;/sub&gt;
* '''[[Prism (geometry)|Square prism]]''': ''P''&lt;sub&gt;4&lt;/sub&gt; (A cube is a special prism)
** ''C'' = ''P''&lt;sub&gt;4&lt;/sub&gt;
* '''[[Pentagonal antiprism]]''': ''A''&lt;sub&gt;5&lt;/sub&gt;
** ''I'' = ''k''&lt;sub&gt;5&lt;/sub&gt;''A''&lt;sub&gt;5&lt;/sub&gt;  (A special [[gyroelongated dipyramid]])
** ''D'' = ''t''&lt;sub&gt;5&lt;/sub&gt;''dA''&lt;sub&gt;5&lt;/sub&gt; (A special [[truncated trapezohedron]])
{{div col end}}

The regular Euclidean tilings can also be used as seeds:
* Q = Quadrille = [[Square tiling]]
* H = Hextille  = [[Hexagonal tiling]] = dΔ
* Δ = Deltille = [[Triangular tiling]] = dH

== Extended operations ==
These are operations created after Conway's original set. Note that many more operations exist than have been named; just because an operation is not here does not mean it does not exist (or is not an LSP or LOPSP). To simplify, only irreducible operators are 
included in this list: others can be created by composing operators together.

{| class="wikitable sortable" style="text-align: center"
|+Irreducible extended operators
|-
! Edge factor !! Matrix &lt;math&gt;\mathbf{M}_x&lt;/math&gt; !!x !! xd !!dx !!  dxd !! Notes
|-
| 4
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 0 \\
  0 &amp; 4 &amp; 0 \\
  0 &amp; 1 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Conway_cC.png|100px]]&lt;br&gt;'''Chamfer''': ''c'' 
| [[File:Conway duC.png|100px]]&lt;br&gt;''cd'' = ''du''
| [[File:Conway_dcC.png|100px]]&lt;br&gt; ''dc'' = ''ud''
| [[File:Conway uC.png|100px]]&lt;br&gt;'''Subdivide''': ''u''
| Chamfer is the join-form of ''l''. See [[Chamfer (geometry)]].
|-
| 5
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 0 \\
  0 &amp; 5 &amp; 0 \\
  0 &amp; 2 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Conway_pC.png|100px]]&lt;br&gt;'''Propeller''': ''p''
|colspan="2"| [[File:Conway_dpC.png|100px]]&lt;br&gt;''dp'' = ''pd'' 
| [[File:Conway_pC.png|100px]]&lt;br&gt;''dpd'' = ''p'' 
| Chiral operators. The propeller operator was developed by George Hart.&lt;ref name="Hart2000"&gt;{{cite conference|url=http://www.georgehart.com/propello/propello.html|author=George W. Hart|title=Sculpture based on Propellorized Polyhedra|conference=Proceedings of MOSAIC 2000|location=Seattle, WA|date=August 2000| pp=61–70 }}&lt;/ref&gt;
|-
| 5
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 0 \\
  0 &amp; 5 &amp; 0 \\
  0 &amp; 2 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Conway_lC.png|100px]]&lt;br&gt;'''Loft''': ''l'' 
| [[File:Conway_ldC.png|100px]]&lt;br&gt;''ld''
| [[File:Conway_dlC.png|100px]]&lt;br&gt; ''dl''
| [[File:Conway_dldC.png|100px]]&lt;br&gt;''dld''
| 
|-
|6
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 3 &amp; 0 \\
  0 &amp; 6 &amp; 0 \\
  0 &amp; 2 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Conway qC.png|100px]]&lt;br&gt;'''Quinto''': ''q'' 
| [[File:Conway_qdC.png|100px]]&lt;br&gt;''qd''
| [[File:Conway_dqC.png|100px]]&lt;br&gt; ''dq''
| [[File:Conway_dqdC.png|100px]]&lt;br&gt;''dqd''
| 
|-
|6
|&lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 0 \\
  0 &amp; 6 &amp; 0 \\
  0 &amp; 3 &amp; 1
  \end{bmatrix}&lt;/math&gt;
|[[File:Conway L0C.png|100px]]&lt;br&gt;'''Join-lace''': ''L''&lt;sub&gt;0&lt;/sub&gt;
|&lt;br&gt;''L&lt;sub&gt;0&lt;/sub&gt;d''
|[[File:Conway dL0C.png|100px]]&lt;br&gt;''dL''&lt;sub&gt;0&lt;/sub&gt;
|[[File:Conway dL0d.png|100px]]&lt;br&gt;''dL''&lt;sub&gt;0&lt;/sub&gt;''d''
| See below for explanation of join notation.
|-
|7
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 0 \\
  0 &amp; 7 &amp; 0 \\
  0 &amp; 4 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Conway_LC.png|100px]]&lt;br&gt;'''Lace''': ''L'' 
| [[File:Conway L0dC.png|100px]]&lt;br&gt;''Ld''
| [[File:Conway_dLC.png|100px]]&lt;br&gt; ''dL''
| [[File:Conway_dLdC.png|100px]]&lt;br&gt;''dLd''
| 
|-
|7
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 1 \\
  0 &amp; 7 &amp; 0 \\
  0 &amp; 4 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Conway_KC.png|100px]]&lt;br&gt;'''Stake''': ''K'' 
| [[File:Conway_KdC.png|100px]]&lt;br&gt;''Kd''
| [[File:Conway_dKC.png|100px]]&lt;br&gt; ''dK''
| [[File:Conway_dKdC.png|100px]]&lt;br&gt;''dKd''
| 
|-
| 7
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 4 &amp; 0 \\
  0 &amp; 7 &amp; 0 \\
  0 &amp; 2 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Conway_wC.png|100px]]&lt;br&gt;'''Whirl''': ''w''
| ''wd'' = ''dv''
| [[File:Conway_dwC.png|100px]]&lt;br&gt;''vd'' = ''dw''
| '''Volute''': ''v''
| Chiral operators. 
|-
|8
|&lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 1 \\
  0 &amp; 8 &amp; 0 \\
  0 &amp; 5 &amp; 0
  \end{bmatrix}&lt;/math&gt;
|[[File:Conway (kk)0C.png|100px]]&lt;br&gt;'''Join-kis-kis''': {{tmath|1=(kk)_0}}
|[[File:Conway (kk)0dC.png|100px]]&lt;br&gt;  {{tmath|1=(kk)_0d}}
|[[File:Conway d(kk)0C.png|100px]]&lt;br&gt;  {{tmath|1=d(kk)_0}}
|[[File:Conway d(kk)0dC.png|100px]]&lt;br&gt; {{tmath|1=d(kk)_0d}}
|Sometimes named ''J''.&lt;ref name="Antiprism" /&gt; See below for explanation of join notation. The non-join-form, ''kk'', is not irreducible.
|-
|10
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 3 &amp; 1 \\
  0 &amp; 10 &amp; 0 \\
  0 &amp; 6 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Conway XC.png|100px]]&lt;br&gt;'''Cross''': ''X'' 
| [[File:Conway_XdC.png|100px]]&lt;br&gt;''Xd''
| [[File:Conway dXC.png|100px]]&lt;br&gt; ''dX''
| [[File:Conway_dXdC.png|100px]]&lt;br&gt;''dXd''
| 
|}

==Indexed extended operations==
A number of operators can be grouped together by some criteria, or have their behavior modified by an index.&lt;ref name="Antiprism" /&gt; These are written as an operator with a subscript: ''x&lt;sub&gt;n&lt;/sub&gt;''.

===Augmentation===
[[Augmentation (geometry)|Augmentation]] operations retain original edges. They may be applied to any independent subset of faces, or may be converted into a ''join''-form by removing the original edges. Conway notation supports an optional index to these operators: 0 for the join-form, or 3 or higher for how many sides affected faces have. For example, ''k''&lt;sub&gt;4&lt;/sub&gt;''Y''&lt;sub&gt;4&lt;/sub&gt;=O: taking a square-based pyramid and gluing another pyramid to the square base gives an octahedron.
{| class=wikitable style="text-align: center"
!Operator||k||l||L||K||(kk)
|-
!x
|[[File:Conway_kC.png|80px]]
|[[File:Conway_lC.png|80px]]
|[[File:Conway_LC.png|80px]]
|[[File:Conway_KC.png|80px]]
|[[File:Conway kkC.png|80px]]
|-
!x&lt;sub&gt;0&lt;/sub&gt;
|[[File:Conway_jC.png|80px]]&lt;br&gt;''k''&lt;sub&gt;0&lt;/sub&gt; = ''j''
|[[File:Conway_cC.png|80px]]&lt;br&gt;''l''&lt;sub&gt;0&lt;/sub&gt; = ''c''
|[[File:Conway L0C.png|80px]]&lt;br&gt;''L''&lt;sub&gt;0&lt;/sub&gt;
|[[File:Conway_K0C.png|80px]]&lt;br&gt;''K''&lt;sub&gt;0&lt;/sub&gt; = ''jk''
|[[File:Conway (kk)0C.png|80px]]&lt;br&gt;{{tmath|1=(kk)_0}}
|- align=center
!Augmentation
||[[Pyramid (geometry)|Pyramid]]||[[Prism (geometry)|Prism]]||[[Antiprism]]||||
|}

The truncate operator ''t'' also has an index form ''t&lt;sub&gt;n&lt;/sub&gt;'', indicating that only vertices of a certain degree are truncated. It is equivalent to ''dk&lt;sub&gt;n&lt;/sub&gt;d''.

Some of the extended operators can be created in special cases with ''k&lt;sub&gt;n&lt;/sub&gt;'' and ''t&lt;sub&gt;n&lt;/sub&gt;'' operators. For example, a [[chamfered cube]], ''cC'', can be constructed as ''t''&lt;sub&gt;4&lt;/sub&gt;''daC'', as a [[rhombic dodecahedron]], ''daC'' or ''jC'', with its degree-4 vertices truncated. A lofted cube, ''lC'' is the same as ''t''&lt;sub&gt;4&lt;/sub&gt;''kC''. A quinto-dodecahedron, ''qD'' can be constructed as ''t''&lt;sub&gt;5&lt;/sub&gt;''daaD'' or ''t''&lt;sub&gt;5&lt;/sub&gt;''deD'' or ''t''&lt;sub&gt;5&lt;/sub&gt;''oD'', a [[deltoidal hexecontahedron]], ''deD'' or ''oD'', with its degree-5 vertices truncated.

===Meta/Bevel===
Meta adds vertices at the center and along the edges, while bevel adds faces at the center, seed vertices, and along the edges. The index is how many vertices or faces are added along the edges. Meta (in its non-indexed form) is also called [[cantitruncation]] or [[omnitruncation]]. Note that 0 here does not mean the same as for augmentation operations: it means zero vertices (or faces) are added along the edges.&lt;ref name="Antiprism" /&gt;
{| class="wikitable sortable" style="text-align: center"
|+Meta/Bevel operators
|-
!  n !! Edge factor !! Matrix &lt;math&gt;\mathbf{M}_x&lt;/math&gt; !! x !! xd !! dx !! dxd
|-
| 0
| 3
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 0 &amp; 1 \\
  0 &amp; 3 &amp; 0 \\
  0 &amp; 2 &amp; 0
  \end{bmatrix}&lt;/math&gt;
|[[File:Conway_kC.png|100px]]&lt;br&gt;''k'' = ''m''&lt;sub&gt;0&lt;/sub&gt;
| [[File:Conway_kdC.png|100px]]&lt;br&gt;''n'' 
|[[File:Conway_dkC.png|100px]]&lt;br&gt;''z'' = ''b''&lt;sub&gt;0&lt;/sub&gt;
| [[File:Conway_tC.png|100px]]&lt;br&gt;''t'' 
|-
| 1
| 6
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 1 &amp; 1 \\
  0 &amp; 6 &amp; 0 \\
  0 &amp; 4 &amp; 0
  \end{bmatrix}&lt;/math&gt;
|colspan="2"| [[File:Conway_mC.png|100px]]&lt;br&gt; ''m'' = ''m''&lt;sub&gt;1&lt;/sub&gt; = ''kj''
|colspan="2"| [[File:Conway_bC.png|100px]]&lt;br&gt; ''b'' = ''b''&lt;sub&gt;1&lt;/sub&gt; = ''ta''
|-
| 2 
|9
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 1 \\
  0 &amp; 9 &amp; 0 \\
  0 &amp; 6 &amp; 0
  \end{bmatrix}&lt;/math&gt;
|[[File:Conway_m3C.png|100px]]&lt;br&gt;''m''&lt;sub&gt;2&lt;/sub&gt;
|[[File:Conway_m3dC.png|100px]]&lt;br&gt;''m''&lt;sub&gt;2&lt;/sub&gt;''d''
|[[File:Conway_b3C.png|100px]]&lt;br&gt;''b''&lt;sub&gt;2&lt;/sub&gt;
|[[File:Conway_dm3dC.png|100px]]&lt;br&gt;''b''&lt;sub&gt;2&lt;/sub&gt;''d''
|-
| 3
|12
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 3 &amp; 1 \\
  0 &amp; 12 &amp; 0 \\
  0 &amp; 8 &amp; 0
  \end{bmatrix}&lt;/math&gt;
|[[File:Conway_m4C.png|100px]]&lt;br&gt;''m''&lt;sub&gt;3&lt;/sub&gt;
|''m''&lt;sub&gt;3&lt;/sub&gt;''d''
|''b''&lt;sub&gt;3&lt;/sub&gt;
|''b''&lt;sub&gt;3&lt;/sub&gt;''d''
|-
| ''n''
| 3''n''+3
| &lt;math&gt;\begin{bmatrix}
  1 &amp; n &amp; 1 \\
  0 &amp; 3n+3 &amp; 0 \\
  0 &amp; 2n+2 &amp; 0
  \end{bmatrix}&lt;/math&gt;
|''m&lt;sub&gt;n&lt;/sub&gt;''
|''m&lt;sub&gt;n&lt;/sub&gt;d''
|''b&lt;sub&gt;n&lt;/sub&gt;''
|''b&lt;sub&gt;n&lt;/sub&gt;d''
|}

===Medial===
Medial is like meta, except it does not add edges from the center to each seed vertex. The index 1 form is identical to Conway's ortho and expand operators: expand is also called [[Cantellation (geometry)|cantellation]] and [[Expansion (geometry)|expansion]]. Note that ''o'' and ''e'' have their own indexed forms, described below. Also note that some implementations start indexing at 0 instead of 1.&lt;ref name="Antiprism" /&gt;
{| class="wikitable sortable" style="text-align: center"
|+Medial operators
|-
!  n !! Edge&lt;br&gt;factor !! Matrix &lt;math&gt;\mathbf{M}_x&lt;/math&gt; !! x !! xd !! dx !! dxd
|-
| 1
| 4 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 1 &amp; 1 \\
  0 &amp; 4 &amp; 0 \\
  0 &amp; 2 &amp; 0
  \end{bmatrix}&lt;/math&gt;
|colspan=2| [[File:Conway_oC.png|100px]]&lt;br&gt; ''M''&lt;sub&gt;1&lt;/sub&gt; = ''o'' = ''jj''
|colspan=2| [[File:Conway_eC.png|100px]]&lt;br&gt; ''e'' = ''aa''
|-
| 2
|7
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 1 \\
  0 &amp; 7 &amp; 0 \\
  0 &amp; 4 &amp; 0
  \end{bmatrix}&lt;/math&gt;
|[[File:Conway MC.png|100px]]&lt;br&gt;'''Medial''': ''M'' = ''M''&lt;sub&gt;2&lt;/sub&gt;
|[[File:Conway MdC.png|100px]]&lt;br&gt;''Md''
|[[File:Conway dMC.png|100px]]&lt;br&gt;''dM''
|[[File:Conway dMdC.png|100px]]&lt;br&gt;''dMd''
|-
| ''n''
|3''n''+1
| &lt;math&gt;\begin{bmatrix}
  1 &amp; n &amp; 1 \\
  0 &amp; 3n+1 &amp; 0 \\
  0 &amp; 2n &amp; 0
  \end{bmatrix}&lt;/math&gt;
|''M&lt;sub&gt;n&lt;/sub&gt;''
|''M&lt;sub&gt;n&lt;/sub&gt;d''
|''dM&lt;sub&gt;n&lt;/sub&gt;''
|''dM&lt;sub&gt;n&lt;/sub&gt;d''
|}

===Goldberg-Coxeter===
The Goldberg-Coxeter (GC) Conway operators are two infinite families of operators that are an extension of the [[Goldberg-Coxeter construction]].&lt;ref name="Deza2004"&gt;{{cite journal |author1=[[Michel Deza|Deza, M.]]|author2=Dutour, M|title=Goldberg–Coxeter constructions for 3-and 4-valent plane graphs|journal=The Electronic Journal of Combinatorics |volume=11|year=2004|pp=#R20|url=http://www.combinatorics.org/ojs/index.php/eljc/article/view/v11i1r20}}&lt;/ref&gt;&lt;ref name=Deza2015&gt;{{cite book|author1=Deza, M.-M.|author2=Sikirić, M. D.|author3=Shtogrin, M. I. | year=2015 |title=Geometric Structure of Chemistry-Relevant Graphs: Zigzags and Central Circuits|publisher=Springer|pp=131–148 |chapter=Goldberg–Coxeter Construction and Parameterization|url=https://books.google.com/?id=HLi4CQAAQBAJ&amp;lpg=PA130&amp;dq=goldberg-coxeter&amp;pg=PA130#v=onepage&amp;q=goldberg-coxeter&amp;f=false   |isbn=9788132224495}}&lt;/ref&gt; The GC construction can be thought of as taking a triangular section of a triangular lattice, or a square section of a square lattice, and laying that over each face of the polyhedron. This construction can be extended to any face by identifying the chambers of the triangle or square (the "master polygon").&lt;ref name="Brinkmann" /&gt; Operators in the triangular family can be used to produce the [[Goldberg polyhedra]] and [[geodesic polyhedra]]: see [[List of geodesic polyhedra and Goldberg polyhedra]] for formulas.

The two families are the triangular GC family, ''c&lt;sub&gt;a,b&lt;/sub&gt;'' and ''u&lt;sub&gt;a,b&lt;/sub&gt;'', and the quadrilateral GC family, ''e&lt;sub&gt;a,b&lt;/sub&gt;'' and ''o&lt;sub&gt;a,b&lt;/sub&gt;''. Both the GC families are indexed by two integers &lt;math&gt;a \ge 1&lt;/math&gt; and &lt;math&gt;b \ge 0&lt;/math&gt;. They possess many nice qualities:
* The indexes of the families have a relationship with certain [[Euclidean domain]]s over the complex numbers: the [[Eisenstein integers]] for the triangular GC family, and the [[Gaussian integers]] for the quadrilateral GC family.
* Operators in the ''x'' and ''dxd'' columns within the same family commute with each other.

The operators are divided into three classes (examples are written in terms of ''c'' but apply to all 4 operators):
* Class I: {{tmath|1=b=0}}. Achiral, preserves original edges. Can be written with the zero index suppressed, e.g. ''c''&lt;sub&gt;''a'',0&lt;/sub&gt; = ''c&lt;sub&gt;a&lt;/sub&gt;''.
* Class II: {{tmath|1=a=b}}. Also achiral. Can be decomposed as ''c&lt;sub&gt;a,a&lt;/sub&gt;'' = ''c&lt;sub&gt;a&lt;/sub&gt;c''&lt;sub&gt;1,1&lt;/sub&gt;
* Class III: All other operators. These are chiral, and ''c&lt;sub&gt;a,b&lt;/sub&gt;'' and ''c&lt;sub&gt;b,a&lt;/sub&gt;'' are the chiral pairs of each other.

Of the original Conway operations, the only ones that do not fall into the GC family are ''g'' and ''s'' (gyro and snub). Meta and bevel (''m'' and ''b'') can be expressed in terms of one operator from the triangular family and one from the quadrilateral family.

==== Triangular ====
{| class="wikitable sortable" style="text-align: center"
|+Triangular Goldberg-Coxeter operators
|-
!  a !! b !! Class !! Edge factor &lt;br&gt;T = a&lt;sup&gt;2&lt;/sup&gt; + ab + b&lt;sup&gt;2&lt;/sup&gt; !! Matrix &lt;math&gt;\mathbf{M}_x&lt;/math&gt; !! Master triangle !! x !! xd !!dx !!  dxd
|-
| 1 
| 0 
| I
| 1 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 0 &amp; 0 \\
  0 &amp; 1 &amp; 0 \\
  0 &amp; 0 &amp; 1
  \end{bmatrix}&lt;/math&gt;
|[[File:Subdivided_triangle_01_00.svg|100px]]
|[[File:Conway_C.png|100px]]&lt;br&gt;''u''&lt;sub&gt;1&lt;/sub&gt; = ''S''
|colspan=2|[[File:Conway_dC.png|100px]]&lt;br&gt;''d''
|[[File:Conway_C.png|100px]]&lt;br&gt;''c''&lt;sub&gt;1&lt;/sub&gt; = ''S''
|-
| 2 
| 0 
| I
| 4 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 1 &amp; 0 \\
  0 &amp; 4 &amp; 0 \\
  0 &amp; 2 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_02_00.svg|100px]]
| [[File:Conway uC.png|100px]]&lt;br&gt;''u''&lt;sub&gt;2&lt;/sub&gt; = ''u'' 
| [[File:Conway_dcC.png|100px]]&lt;br&gt;''dc''
| [[File:Conway duC.png|100px]]&lt;br&gt;''du''
| [[File:Conway_cC.png|100px]]&lt;br&gt;''c''&lt;sub&gt;2&lt;/sub&gt; = ''c''
|-
| 3 
| 0 
| I
| 9 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 1 \\
  0 &amp; 9 &amp; 0 \\
  0 &amp; 6 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_03_00.svg|100px]]
| [[File:Conway_ktC.png|100px]]&lt;br&gt;''u''&lt;sub&gt;3&lt;/sub&gt; = ''nn'' 
| [[File:Conway_dtkC.png|100px]]&lt;br&gt;''nk'' 
| [[File:Conway_dktC.png|100px]]&lt;br&gt;''zt'' 
| [[File:Conway_tkC.png|100px]]&lt;br&gt;''c''&lt;sub&gt;3&lt;/sub&gt; = ''zz''
|-
| 4 
| 0 
| I
| 16 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 5 &amp; 0 \\
  0 &amp; 16 &amp; 0 \\
  0 &amp; 10 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_04_00.svg|100px]]
|[[File:Conway_u4C.png|100px]]&lt;br&gt;''u''&lt;sub&gt;4&lt;/sub&gt; = ''uu''  
| ''uud'' = ''dcc''
| ''duu'' = ''ccd''
|''c''&lt;sub&gt;4&lt;/sub&gt; = ''cc''
|-
| 5 
| 0 
| I
| 25 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 8 &amp; 0 \\
  0 &amp; 25 &amp; 0 \\
  0 &amp; 16 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_05_00.svg|100px]]
|[[File:Conway_u5C.png|100px]]&lt;br&gt;''u''&lt;sub&gt;5&lt;/sub&gt;
|''u''&lt;sub&gt;5&lt;/sub&gt;''d'' = ''dc''&lt;sub&gt;5&lt;/sub&gt;
|''du''&lt;sub&gt;5&lt;/sub&gt; = ''c''&lt;sub&gt;5&lt;/sub&gt;''d''
| ''c''&lt;sub&gt;5&lt;/sub&gt;
|-
| 6 
| 0 
| I
| 36 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 11 &amp; 1 \\
  0 &amp; 36 &amp; 0 \\
  0 &amp; 24 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_06_00.svg|100px]]
|[[File:Conway_u6C.png|100px]]&lt;br&gt;''u''&lt;sub&gt;6&lt;/sub&gt; = ''unn''
| ''unk''
| ''czt''
|''u''&lt;sub&gt;6&lt;/sub&gt; = ''czz''
|-
| 7 
| 0 
| I
| 49 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 16 &amp; 0 \\
  0 &amp; 49 &amp; 0 \\
  0 &amp; 32 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_07_00.svg|100px]]
|[[File:Conway_u7.png|100px]]&lt;br&gt;''u''&lt;sub&gt;7&lt;/sub&gt; = ''u''&lt;sub&gt;2,1&lt;/sub&gt;''u''&lt;sub&gt;1,2&lt;/sub&gt; = ''vrv''
| ''vrvd'' = ''dwrw''
| ''dvrv'' = ''wrwd''
| ''c''&lt;sub&gt;7&lt;/sub&gt; = ''c''&lt;sub&gt;2,1&lt;/sub&gt;''c''&lt;sub&gt;1,2&lt;/sub&gt; = ''wrw''
|-
| 8 
| 0 
| I
| 64 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 21 &amp; 0 \\
  0 &amp; 64 &amp; 0 \\
  0 &amp; 42 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_08_00.svg|100px]]
|[[File:Conway_u8C.png|100px]]&lt;br&gt;''u''&lt;sub&gt;8&lt;/sub&gt; = ''u''&lt;sup&gt;3&lt;/sup&gt;
| ''u''&lt;sup&gt;3&lt;/sup&gt;''d'' = ''dc''&lt;sup&gt;3&lt;/sup&gt;
| ''du''&lt;sup&gt;3&lt;/sup&gt; = ''c''&lt;sup&gt;3&lt;/sup&gt;''d'' 
| ''c''&lt;sub&gt;8&lt;/sub&gt; = ''c''&lt;sup&gt;3&lt;/sup&gt;
|-
| 9 
| 0 
| I
| 81 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 26 &amp; 1 \\
  0 &amp; 81 &amp; 0 \\
  0 &amp; 54 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_09_00.svg|100px]]
|[[File:Conway_u9C.png|100px]]&lt;br&gt;''u''&lt;sub&gt;9&lt;/sub&gt; = ''n''&lt;sup&gt;4&lt;/sup&gt;  
| ''n''&lt;sup&gt;3&lt;/sup&gt;''k'' = ''kz''&lt;sup&gt;3&lt;/sup&gt; 
| ''tn''&lt;sup&gt;3&lt;/sup&gt; = ''z''&lt;sup&gt;3&lt;/sup&gt;''t'' 
| ''c''&lt;sub&gt;9&lt;/sub&gt; = ''z''&lt;sup&gt;4&lt;/sup&gt;
|-
| 1 
| 1 
| II
| 3
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 0 &amp; 1 \\
  0 &amp; 3 &amp; 0 \\
  0 &amp; 2 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_01_01.svg|100px]]
|[[File:Conway_kdC.png|100px]]&lt;br&gt;''u''&lt;sub&gt;1,1&lt;/sub&gt; = ''n'' 
| [[File:Conway_kC.png|100px]]&lt;br&gt;''k''
| [[File:Conway_tC.png|100px]]&lt;br&gt;''t''
| [[File:Conway_dkC.png|100px]]&lt;br&gt;''c''&lt;sub&gt;1,1&lt;/sub&gt; = ''z''
|-
| 2 
| 1 
| III
| 7 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 0 \\
  0 &amp; 7 &amp; 0 \\
  0 &amp; 4 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_02_01.svg|100px]]
| ''v'' = ''u''&lt;sub&gt;2,1&lt;/sub&gt;
| [[File:Conway_dwC.png|100px]]&lt;br&gt;''vd'' = ''dw''
| ''dv'' = ''wd''
| [[File:Conway_wC.png|100px]]&lt;br&gt;''w'' = ''c''&lt;sub&gt;2,1&lt;/sub&gt;
|-
| 3
| 1 
| III
| 13
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 4 &amp; 0 \\
  0 &amp; 13 &amp; 0 \\
  0 &amp; 8 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_03_01.svg|100px]]
|''u''&lt;sub&gt;3,1&lt;/sub&gt;
|''u''&lt;sub&gt;3,1&lt;/sub&gt;''d'' = ''dc''&lt;sub&gt;3,1&lt;/sub&gt;  
|''du''&lt;sub&gt;3,1&lt;/sub&gt; = ''c''&lt;sub&gt;3,1&lt;/sub&gt;''d''
| [[File:Conway_w3C.png|100px]]&lt;br&gt;''c''&lt;sub&gt;3,1&lt;/sub&gt;
|-
| 3
| 2
| III
| 19
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 6 &amp; 0 \\
  0 &amp; 19 &amp; 0 \\
  0 &amp; 12 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_03_02.svg|100px]]
| ''u''&lt;sub&gt;3,2&lt;/sub&gt;  
| ''u''&lt;sub&gt;3,2&lt;/sub&gt;''d'' = ''dc''&lt;sub&gt;3,2&lt;/sub&gt;
| ''du''&lt;sub&gt;3,2&lt;/sub&gt; = ''c''&lt;sub&gt;3,2&lt;/sub&gt;''d''  
| [[File:Conway_w3-2.png|100px]]&lt;br&gt;''c''&lt;sub&gt;3,2&lt;/sub&gt;
|-
| 4
| 3
| III
| 37
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 12 &amp; 0 \\
  0 &amp; 37 &amp; 0 \\
  0 &amp; 24 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_04_03.svg|100px]]
| ''u''&lt;sub&gt;4,3&lt;/sub&gt;
| ''u''&lt;sub&gt;4,3&lt;/sub&gt;''d'' = ''dc''&lt;sub&gt;4,3&lt;/sub&gt;
| ''du''&lt;sub&gt;4,3&lt;/sub&gt; = ''c''&lt;sub&gt;4,3&lt;/sub&gt;''d''  
|[[File:Conway_w4-3C.png|100px]]&lt;br&gt;''c''&lt;sub&gt;4,3&lt;/sub&gt;
|-
| 5
| 4
| III
| 61
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 20 &amp; 0 \\
  0 &amp; 61 &amp; 0 \\
  0 &amp; 40 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_05_04.svg|100px]]
|''u''&lt;sub&gt;5,4&lt;/sub&gt;
|''u''&lt;sub&gt;5,4&lt;/sub&gt;''d'' = ''dc''&lt;sub&gt;5,4&lt;/sub&gt;
|''du''&lt;sub&gt;5,4&lt;/sub&gt; = ''c''&lt;sub&gt;5,4&lt;/sub&gt;''d''
|[[File:Conway_w5-4C.png|100px]]&lt;br&gt;''c''&lt;sub&gt;5,4&lt;/sub&gt;
|-
| 6
| 5
| III
| 91
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 30 &amp; 0 \\
  0 &amp; 91 &amp; 0 \\
  0 &amp; 60 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_06_05.svg|100px]]
|''u''&lt;sub&gt;6,5&lt;/sub&gt; = ''u''&lt;sub&gt;1,2&lt;/sub&gt;''u''&lt;sub&gt;1,3&lt;/sub&gt; 
|''u''&lt;sub&gt;6,5&lt;/sub&gt;''d'' = ''dc''&lt;sub&gt;6,5&lt;/sub&gt;  
|''du''&lt;sub&gt;6,5&lt;/sub&gt; = ''c''&lt;sub&gt;6,5&lt;/sub&gt;''d''  
|[[File:Conway_w6-5C.png|100px]]&lt;br&gt;''c''&lt;sub&gt;6,5&lt;/sub&gt;=''c''&lt;sub&gt;1,2&lt;/sub&gt;''c''&lt;sub&gt;1,3&lt;/sub&gt;
|-
| 7
| 6
| III
| 127
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 42 &amp; 0 \\
  0 &amp; 127 &amp; 0 \\
  0 &amp; 84 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_07_06.svg|100px]]
|''u''&lt;sub&gt;7,6&lt;/sub&gt;
|''u''&lt;sub&gt;7,6&lt;/sub&gt;''d'' = ''dc''&lt;sub&gt;7,6&lt;/sub&gt;
|''du''&lt;sub&gt;7,6&lt;/sub&gt; = ''c''&lt;sub&gt;7,6&lt;/sub&gt;''d''  
|[[File:Conway_w7C.png|100px]]&lt;br&gt;''c''&lt;sub&gt;7,6&lt;/sub&gt;
|-
| 8
| 7
| III
| 169
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 56 &amp; 0 \\
  0 &amp; 169 &amp; 0 \\
  0 &amp; 112 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_08_07.svg|100px]]
|''u''&lt;sub&gt;8,7&lt;/sub&gt; = ''u''&lt;sub&gt;3,1&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;
|''u''&lt;sub&gt;8,7&lt;/sub&gt;''d'' = ''dc''&lt;sub&gt;8,7&lt;/sub&gt;
|''du''&lt;sub&gt;8,7&lt;/sub&gt; = ''c''&lt;sub&gt;8,7&lt;/sub&gt;''d''  
|[[File:Conway_w8C.png|100px]]&lt;br&gt;''c''&lt;sub&gt;8,7&lt;/sub&gt; = ''c''&lt;sub&gt;3,1&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;
|-
| 9
| 8
| III
| 217
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 72 &amp; 0 \\
  0 &amp; 217 &amp; 0 \\
  0 &amp; 144 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_triangle_09_08.svg|100px]]
|''u''&lt;sub&gt;9,8&lt;/sub&gt; = ''u''&lt;sub&gt;2,1&lt;/sub&gt;''u''&lt;sub&gt;5,1&lt;/sub&gt;
|''u''&lt;sub&gt;9,8&lt;/sub&gt;''d'' = ''dc''&lt;sub&gt;9,8&lt;/sub&gt;
|''du''&lt;sub&gt;9,8&lt;/sub&gt; = ''c''&lt;sub&gt;9,8&lt;/sub&gt;''d''  
|[[File:Conway_w9C.png|100px]]&lt;br&gt;''c''&lt;sub&gt;9,8&lt;/sub&gt; = ''c''&lt;sub&gt;2,1&lt;/sub&gt;''c''&lt;sub&gt;5,1&lt;/sub&gt;
|-
|colspan=2| &lt;math&gt;a \equiv b&lt;/math&gt;&lt;math&gt;\ (\mathrm{mod}\ 3)&lt;/math&gt;
| I, II, or III
| &lt;math&gt;T \equiv 0\ &lt;/math&gt;&lt;math&gt;(\mathrm{mod}\ 3)&lt;/math&gt;
| &lt;math&gt;\begin{bmatrix}
  1 &amp; \frac{T}{3}-1 &amp; 1 \\
  0 &amp; T &amp; 0 \\
  0 &amp; \frac{2}{3}T &amp; 0
  \end{bmatrix}&lt;/math&gt;
|...
|''u&lt;sub&gt;a,b&lt;/sub&gt;''
|''u&lt;sub&gt;a,b&lt;/sub&gt;d'' = ''dc&lt;sub&gt;a,b&lt;/sub&gt;''
|''du&lt;sub&gt;a,b&lt;/sub&gt;'' = ''c&lt;sub&gt;a,b&lt;/sub&gt;d''
|''c&lt;sub&gt;a,b&lt;/sub&gt;''
|-
|colspan=2| &lt;math&gt;a \not \equiv b&lt;/math&gt;&lt;math&gt;\ (\mathrm{mod}\ 3)&lt;/math&gt;
| I or III
| &lt;math&gt;T \equiv 1&lt;/math&gt;&lt;math&gt;\ (\mathrm{mod}\ 3)&lt;/math&gt;
| &lt;math&gt;\begin{bmatrix}
  1 &amp; \frac{T-1}{3} &amp; 0 \\
  0 &amp; T &amp; 0 \\
  0 &amp; 2\frac{T-1}{3} &amp; 1
  \end{bmatrix}&lt;/math&gt;
|...
|''u&lt;sub&gt;a,b&lt;/sub&gt;''
|''u&lt;sub&gt;a,b&lt;/sub&gt;d'' = ''dc&lt;sub&gt;a,b&lt;/sub&gt;''
|''du&lt;sub&gt;a,b&lt;/sub&gt;'' = ''c&lt;sub&gt;a,b&lt;/sub&gt;d''
|''c&lt;sub&gt;a,b&lt;/sub&gt;''
|}
By basic number theory, for any values of ''a'' and ''b'', &lt;math&gt;T \not\equiv 2\ (\mathrm{mod}\ 3)&lt;/math&gt;.

==== Quadrilateral ====
{| class="wikitable sortable" style="text-align: center"
|+Quadrilateral Goldberg-Coxeter operators
|-
! a !! b !! Class !! Edge factor &lt;br&gt;T = a&lt;sup&gt;2&lt;/sup&gt; + b&lt;sup&gt;2&lt;/sup&gt; !! Matrix &lt;math&gt;\mathbf{M}_x&lt;/math&gt; !! Master square !! x !! xd !!dx !!  dxd
|-
| 1 
| 0 
| I
| 1 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 0 &amp; 0 \\
  0 &amp; 1 &amp; 0 \\
  0 &amp; 0 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_01_00.svg|100px]]
|[[File:Conway_C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;1&lt;/sub&gt; = ''S''
|colspan=2|[[File:Conway_dC.png|100px]]&lt;br&gt;''e''&lt;sub&gt;1&lt;/sub&gt; = ''d''
|[[File:Conway_C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;1&lt;/sub&gt; = ''dd'' = ''S''
|-
| 2 
| 0 
| I
| 4 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 1 &amp; 1 \\
  0 &amp; 4 &amp; 0 \\
  0 &amp; 2 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_02_00.svg|100px]]
|colspan=2| [[File:Conway_oC.png|100px]]&lt;br&gt;''o''&lt;sub&gt;2&lt;/sub&gt; = ''o'' = ''j''&lt;sup&gt;2&lt;/sup&gt;
|colspan=2| [[File:Conway_eC.png|100px]]&lt;br&gt;''e''&lt;sub&gt;2&lt;/sub&gt; = ''e'' = ''a''&lt;sup&gt;2&lt;/sup&gt;

|-
| 3 
| 0 
| I
| 9 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 4 &amp; 0 \\
  0 &amp; 9 &amp; 0 \\
  0 &amp; 4 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_03_00.svg|100px]]
| [[File:Conway_o3C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;3&lt;/sub&gt;
|colspan=2| [[File:Conway_e3C.png|100px]]&lt;br&gt;''e''&lt;sub&gt;3&lt;/sub&gt;
| [[File:Conway_o3C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;3&lt;/sub&gt;
|-
| 4 
| 0 
| I
| 16 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 7 &amp; 1 \\
  0 &amp; 16 &amp; 0 \\
  0 &amp; 8 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_04_00.svg|100px]]
|colspan=2|[[File:Conway_deeC.png|100px]]&lt;br&gt;''o''&lt;sub&gt;4&lt;/sub&gt; = ''oo'' = ''j''&lt;sup&gt;4&lt;/sup&gt;
|colspan=2| [[File:Conway_eeC.png|100px]]&lt;br&gt;''e''&lt;sub&gt;4&lt;/sub&gt; = ''ee'' = ''a''&lt;sup&gt;4&lt;/sup&gt;
|-
| 5 
| 0 
| I
| 25 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 12 &amp; 0 \\
  0 &amp; 25 &amp; 0 \\
  0 &amp; 12 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_05_00.svg|100px]]
|[[File:Conway o5C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;5&lt;/sub&gt; = ''o''&lt;sub&gt;2,1&lt;/sub&gt;''o''&lt;sub&gt;1,2&lt;/sub&gt; = ''prp''
|colspan=2|''e''&lt;sub&gt;5&lt;/sub&gt; = ''e''&lt;sub&gt;2,1&lt;/sub&gt;''e''&lt;sub&gt;1,2&lt;/sub&gt;
|[[File:Conway o5C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;5&lt;/sub&gt;= ''dprpd''
|-
| 6 
| 0 
| I
| 36 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 17 &amp; 1 \\
  0 &amp; 36 &amp; 0 \\
  0 &amp; 18 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_06_00.svg|100px]]
|colspan=2|[[File:Conway_o6C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;6&lt;/sub&gt; = ''o''&lt;sub&gt;2&lt;/sub&gt;''o''&lt;sub&gt;3&lt;/sub&gt;
|colspan=2|''e''&lt;sub&gt;6&lt;/sub&gt; = ''e''&lt;sub&gt;2&lt;/sub&gt;''e''&lt;sub&gt;3&lt;/sub&gt;
|-
| 7 
| 0 
| I
| 49 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 24 &amp; 0 \\
  0 &amp; 49 &amp; 0 \\
  0 &amp; 24 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_07_00.svg|100px]]
|[[File:Conway_o7C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;7&lt;/sub&gt;
|colspan=2|''e''&lt;sub&gt;7&lt;/sub&gt;
|[[File:Conway_o7C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;7&lt;/sub&gt;
|-
| 8 
| 0 
| I
| 64 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 31 &amp; 1 \\
  0 &amp; 64 &amp; 0 \\
  0 &amp; 32 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_08_00.svg|100px]]
|colspan=2|[[File:Conway_o8C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;8&lt;/sub&gt; = ''o''&lt;sup&gt;3&lt;/sup&gt; = ''j''&lt;sup&gt;6&lt;/sup&gt;
|colspan=2| ''e''&lt;sub&gt;8&lt;/sub&gt; = ''e''&lt;sup&gt;3&lt;/sup&gt; = ''a''&lt;sup&gt;6&lt;/sup&gt;
|-
| 9 
| 0 
| I
| 81 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 40 &amp; 0 \\
  0 &amp; 81 &amp; 0 \\
  0 &amp; 40 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_09_00.svg|100px]]
|[[File:Conway_o9C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;9&lt;/sub&gt; = ''o''&lt;sub&gt;3&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;
|colspan=2| &lt;br&gt;''e''&lt;sub&gt;9&lt;/sub&gt; = ''e''&lt;sub&gt;3&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;
|[[File:Conway_o9C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;9&lt;/sub&gt;
|-
| 10 
| 0 
| I
| 100 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 49 &amp; 1 \\
  0 &amp; 100 &amp; 0 \\
  0 &amp; 50 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_10_00.svg|100px]]
|colspan=2|[[File:Conway_o10C.png|100px]]&lt;br&gt;''o''&lt;sub&gt;10&lt;/sub&gt; = ''oo''&lt;sub&gt;2,1&lt;/sub&gt;''o''&lt;sub&gt;1,2&lt;/sub&gt;
|colspan=2|''e''&lt;sub&gt;10&lt;/sub&gt; = ''ee''&lt;sub&gt;2,1&lt;/sub&gt;e&lt;sub&gt;1,2&lt;/sub&gt;
|-
| 1 
| 1 
| II
| 2 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 0 &amp; 1 \\
  0 &amp; 2 &amp; 0 \\
  0 &amp; 1 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_01_01.svg|100px]]
|colspan=2| [[File:Conway_jC.png|100px]]&lt;br&gt;''o''&lt;sub&gt;1,1&lt;/sub&gt; = ''j'' 
|colspan=2| [[File:Conway_aC.png|100px]]&lt;br&gt;''e''&lt;sub&gt;1,1&lt;/sub&gt; = ''a''
|-
| 2 
| 2 
| II
| 8 
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 3 &amp; 1 \\
  0 &amp; 8 &amp; 0 \\
  0 &amp; 4 &amp; 0
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_02_02.svg|100px]]
|colspan=2| [[File:Conway_daaaC.png|100px]]&lt;br&gt;''o''&lt;sub&gt;2,2&lt;/sub&gt; = ''j''&lt;sup&gt;3&lt;/sup&gt;
|colspan=2|  [[File:Conway_aaaC.png|100px]]&lt;br&gt;''e''&lt;sub&gt;2,2&lt;/sub&gt; = ''a''&lt;sup&gt;3&lt;/sup&gt;
|-
| 1
| 2
| III
| 5
| &lt;math&gt;\begin{bmatrix}
  1 &amp; 2 &amp; 0 \\
  0 &amp; 5 &amp; 0 \\
  0 &amp; 2 &amp; 1
  \end{bmatrix}&lt;/math&gt;
| [[File:Subdivided_square_01_02.svg|100px]]
| [[File:Conway_pC.png|100px]]&lt;br&gt;''o''&lt;sub&gt;1,2&lt;/sub&gt; = ''p''
|colspan=2| [[File:Conway_dpC.png|100px]]&lt;br&gt;''e''&lt;sub&gt;1,2&lt;/sub&gt; = ''dp'' = ''pd''
| [[File:Conway_pC.png|100px]]&lt;br&gt;''p''
|-
|colspan=2| &lt;math&gt;a \equiv b&lt;/math&gt;&lt;math&gt;\ (\mathrm{mod}\ 2)&lt;/math&gt;
| I, II, or III
| ''T'' even
| &lt;math&gt;\begin{bmatrix}
  1 &amp; \frac{T}{2}-1 &amp; 1 \\
  0 &amp; T &amp; 0 \\
  0 &amp; \frac{T}{2} &amp; 0
  \end{bmatrix}&lt;/math&gt;
|...
|colspan=2|''o&lt;sub&gt;a,b&lt;/sub&gt;''
|colspan=2|''e&lt;sub&gt;a,b&lt;/sub&gt;''
|-
|colspan=2| &lt;math&gt;a \not\equiv b&lt;/math&gt;&lt;math&gt;\ (\mathrm{mod}\ 2)&lt;/math&gt;
| I or III
| ''T'' odd
| &lt;math&gt;\begin{bmatrix}
  1 &amp; \frac{T-1}{2} &amp; 0 \\
  0 &amp; T &amp; 0 \\
  0 &amp; \frac{T-1}{2} &amp; 1
  \end{bmatrix}&lt;/math&gt;
|...
|''o&lt;sub&gt;a,b&lt;/sub&gt;''
|colspan=2|''e&lt;sub&gt;a,b&lt;/sub&gt;''
|''o&lt;sub&gt;a,b&lt;/sub&gt;''
|}

==Examples==
See also [[List of geodesic polyhedra and Goldberg polyhedra]].

===Archimedean and Catalan solids===
Conway's original set of operators can create all of the [[Archimedean solids]] and [[Catalan solids]], using the [[Platonic solids]] as seeds. (Note that the ''r'' operator is not necessary to create both chiral forms.)
&lt;gallery caption=Archimedean&gt;
Image:truncated tetrahedron.png| [[Truncated tetrahedron]]&lt;br&gt;tT
Image:cuboctahedron.png| [[Cuboctahedron]]&lt;br&gt;aC = aaT
Image:truncated hexahedron.png| [[Truncated cube]]&lt;br&gt;tC
Image:truncated octahedron.png| [[Truncated octahedron]]&lt;br&gt;tO = bT
Image:small rhombicuboctahedron.png| [[Rhombicuboctahedron]]&lt;br&gt;eC = a&lt;sup&gt;3&lt;/sup&gt;T
Image:Great rhombicuboctahedron.png| [[truncated cuboctahedron]]&lt;br&gt; bC
Image:snub hexahedron.png| [[snub cube]]&lt;br&gt;sC
Image:icosidodecahedron.png| [[icosidodecahedron]]&lt;br&gt;aD
Image:truncated dodecahedron.png| [[truncated dodecahedron]]&lt;br&gt;tD
Image:truncated icosahedron.png| [[truncated icosahedron]]&lt;br&gt;tI
Image:small rhombicosidodecahedron.png| [[rhombicosidodecahedron|rhombicosidodeca&amp;shy;hedron]]&lt;br&gt;eD
Image:Great rhombicosidodecahedron.png| [[truncated icosidodecahedron]]&lt;br&gt;bD
Image:snub dodecahedron ccw.png| [[snub dodecahedron]]&lt;br&gt;sD &amp; sI
&lt;/gallery&gt;
&lt;gallery caption=Catalan&gt;
Image:triakistetrahedron.jpg| [[Triakis tetrahedron]]&lt;br&gt;kT
Image:rhombicdodecahedron.jpg| [[Rhombic dodecahedron]]&lt;br&gt;jC
Image:triakisoctahedron.jpg| [[Triakis octahedron]]&lt;br&gt;kO
Image:tetrakishexahedron.jpg| [[Tetrakis hexahedron]]&lt;br&gt;kC
Image:deltoidalicositetrahedron.jpg| [[Deltoidal icositetrahedron]]&lt;br&gt;oC
Image:disdyakisdodecahedron.jpg| [[Disdyakis dodecahedron]]&lt;br&gt;mC
Image:pentagonalicositetrahedronccw.jpg| [[Pentagonal icositetrahedron]]&lt;br&gt;gC
Image:rhombictriacontahedron.jpg| [[Rhombic triacontahedron]]&lt;br&gt;jD
Image:triakisicosahedron.jpg| [[Triakis icosahedron]]&lt;br&gt;kI
Image:Pentakisdodecahedron.jpg| [[Pentakis dodecahedron]]&lt;br&gt;kD
Image:Deltoidalhexecontahedron.jpg| [[Deltoidal hexecontahedron]]&lt;br&gt;oD
Image:Disdyakistriacontahedron.jpg| [[Disdyakis triacontahedron]]&lt;br&gt;mD
Image:Pentagonalhexecontahedronccw.jpg| [[Pentagonal hexecontahedron]]&lt;br&gt;gD &amp; gI
&lt;/gallery&gt;

===Composite operators===
The [[truncated icosahedron]], ''tI = zD'', can be used as a seed to create some more visually-pleasing polyhedra, although these are neither [[Vertex transitive|vertex]] nor [[face-transitive]].
&lt;gallery&gt;
File:Uniform polyhedron-53-t12.png|tI=zD
File:Rectified truncated icosahedron.png|atI
File:truncated truncated icosahedron.png|ttI
File:Conway polyhedron Dk6k5tI.png|ztI
File:Expanded truncated icosahedron.png|etI
File:Truncated rectified truncated icosahedron.png|btI
File:Snub rectified truncated icosahedron.png|stI
&lt;/gallery&gt;
&lt;gallery caption=Duals&gt;
File:Pentakisdodecahedron.jpg|nI=kD
File:Joined truncated icosahedron.png|jtI
File:kissed kissed dodecahedron.png|ntI
File:Conway polyhedron K6k5tI.png|ktI
File:ortho truncated icosahedron.png|otI
File:Meta_truncated_icosahedron.png|mtI
File:Gyro_truncated_icosahedron.png|gtI
&lt;/gallery&gt;

===Other surfaces===

;On the plane:
Each of the [[List of convex uniform tilings|convex uniform tilings]] can be created by applying Conway operators to the [[regular tilings]] Q, H, and Δ.
&lt;gallery&gt;
File:1-uniform_n5.svg|[[Square tiling]]&lt;br&gt;Q=dQ
File:1-uniform_n2.svg|[[Truncated square tiling]]&lt;br&gt;tQ
File:1-uniform_2_dual.svg|[[Tetrakis square tiling]]&lt;br&gt;kQ
File:1-uniform_n9.svg|[[Snub square tiling]]&lt;br&gt;sQ
File:1-uniform_9_dual.svg|[[Cairo pentagonal tiling]]&lt;br&gt;gQ
&lt;/gallery&gt;
&lt;gallery&gt;
File:1-uniform_n1.svg|[[Hexagonal tiling]]&lt;br&gt;H = dΔ
File:1-uniform_n7.svg|[[Trihexagonal tiling]]&lt;br&gt;aH = aΔ
File:1-uniform_n4.svg|[[Truncated hexagonal tiling]]&lt;br&gt;tH
File:1-uniform_n6.svg|[[Rhombitrihexagonal tiling]]&lt;br&gt;eH = eΔ
File:1-uniform_n3.svg|[[Truncated trihexagonal tiling]]&lt;br&gt;bH = bΔ
File:1-uniform_n10.svg|[[Snub trihexagonal tiling]]&lt;br&gt;sH = sΔ

&lt;/gallery&gt;
&lt;gallery&gt;
File:1-uniform_1_dual.svg|[[Triangle tiling]]&lt;br&gt;Δ = dH
File:1-uniform_7_dual.svg|[[Rhombille tiling]]&lt;br&gt;jΔ = jH
File:1-uniform_4_dual.svg|[[Triakis triangular tiling]]&lt;br&gt;kΔ
File:1-uniform_6_dual.svg|[[Deltoidal trihexagonal tiling]]&lt;br&gt;oΔ = oH
File:1-uniform_3_dual.svg|[[Kisrhombille tiling]]&lt;br&gt;mΔ = mH
File:1-uniform_10_dual.svg|[[Floret pentagonal tiling]]&lt;br&gt;gΔ = gH
&lt;/gallery&gt;

;On the torus:
Conway operators can also be applied to [[toroidal polyhedra]] and polyhedra with multiple holes.
&lt;gallery&gt;
File:Toroidal monohedron.png|A 1x1 regular square torus, {4,4}&lt;sub&gt;1,0&lt;/sub&gt;
File:Torus map 4x4.png|A regular 4x4 square torus, {4,4}&lt;sub&gt;4,0&lt;/sub&gt;
File:First truncated square tiling on torus24x12.png|tQ24×12 projected to torus
File:Truncated square tiling on torus24x12.png|taQ24×12 projected to torus
File:Conway_torus_ActQ24x8.png|actQ24×8 projected to torus
File:Truncated hexagonal tiling torus24x12.png|tH24×12 projected to torus
File:Truncated trihexagonal tiling on torus24x8.png|taH24×8 projected to torus
Conway torus kH24-12.png|kH24×12 projected to torus
&lt;/gallery&gt;

== See also ==
{{Commons|Conway polyhedra}}
* [[Symmetrohedron]]
* [[Zonohedron]]

== References ==
{{Reflist}}

== External links==
* [https://levskaya.github.com/polyhedronisme/ polyHédronisme]: generates polyhedra in HTML5 canvas, taking Conway notation as input

{{Polyhedron navigator}}

[[Category:Elementary geometry]]
[[Category:Polyhedra]]
[[Category:Mathematical notation]]</text>
      <sha1>oktz1yccc1ir2m6mr521p0zzp65rwdp</sha1>
    </revision>
  </page>
  <page>
    <title>Cumulative accuracy profile</title>
    <ns>0</ns>
    <id>54727095</id>
    <revision>
      <id>800121983</id>
      <parentid>799926805</parentid>
      <timestamp>2017-09-11T16:49:29Z</timestamp>
      <contributor>
        <username>Victoriaweller</username>
        <id>31455205</id>
      </contributor>
      <minor/>
      <comment>added title of refrence</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4181">The '''cumulative accuracy profile (CAP)''' is used in data science to visualize the discriminative power of a model. The CAP of a model represents the cumulative number of positive outcomes along the ''y''-axis versus the corresponding cumulative number of a classifying parameter along the ''x''-axis. The CAP is distinct from the [[receiver operating characteristic]] (ROC), which plots the [[true-positive rate]] against the [[false-positive rate]].

==Example==

An example is a model that predicts whether a product is bought ('''positive outcome''') by each individual from a group of people ('''classifying parameter''') based on factors such as their gender, age, income etc. If group members would be contacted at random, the cumulative number of products sold would rise linearly toward a maximum value corresponding to the total number of buyers within the group. This distribution is called the '''"random" CAP'''. A perfect prediction, on the other hand, determines exactly which group members will buy the product, such that the maximum number of products sold will be reached with a minimum number of calls. This produces a steep line on the CAP curve that stays flat once the maximum is reached (contacting all other group members will not lead to more products sold), which is the '''"perfect" CAP'''.

[[File:CAP profiles.jpg|thumb|The CAP profiles for the perfect, good and random model predicting the buying customers from a pool of 100 individuals.]]

A successful model predicts the likelihood of individuals purchasing the product and ranks these probabilities to produce a list of potential customers to be contacted first. The resulting cumulative number of sold products will increase rapidly and eventually flatten out to the given maximum as more group members are contacted. This results in a distribution that lies between the random and the perfect CAP curves.

==Analyzing a CAP==

The CAP can be used to evaluate a model by comparing the curve to the '''perfect CAP''' in which the maximum number of positive outcomes is achieved directly and to the '''random CAP''' in which the positive outcomes are distributed equally. A good model will have a CAP between the perfect CAP and the random CAP with a better model tending to the perfect CAP.

The '''accuracy ratio (AR)''' is defined as the ratio of the area between the model CAP and the random CAP and the area between the perfect CAP and the random CAP.&lt;ref&gt;{{Citation
 | first = Raffaella
 | last = Calabrese
 | title = The validation of Credit Rating and Scoring Models
 | series = Swiss Statistics Meeting
 | year = 2009
 | place = Geneva, Switzerland
 | url = http://www.statoo.ch/jss09/presentations/Calabrese.pdf }}&lt;/ref&gt; For a successful model the '''AR''' has values between zero and one, with a higher value for a stronger model.

Another indication of the model strength is given by the cumulative number of positive outcomes at 50% of the classifying parameter. For a successful model this value should lie between 50% and 100% of the maximum, with a higher percentage for stronger models.

==Applications==

The CAP and the ROC are both commonly used by banks and regulators to analyze the discriminatory ability of rating systems that evaluate the credit risks &lt;ref&gt;{{Citation
 | last =Engelmann
 | first =Bernd
 | last2 =Hayden
 | first2 =Evelyn
 | last3 =Tasche
 | first3 =Dirk
 | title =Measuring the Discriminative Power of Rating Systems
 | journal =Discussion Paper
 | volume =Series 2: Banking and Financial Supervision
 | issue = No 01
 | date =2003
 | url = https://www.bundesbank.de/Redaktion/EN/Downloads/Publications/Discussion_Paper_2/2003/2003_10_01_dkp_01.pdf?__blob=publication }}&lt;/ref&gt;
&lt;ref&gt;{{Citation
 | last =Sobehart
 | first =Jorge
 | last2 =Keenan
 | first2 =Sean
 | last3 =Stein
 | first3 =Roger
 | title =Validation methodologies for default risk models
 | journal =Moody's Risk Management Services
 | date =2000-05-15
 | url = http://www.rogermstein.com/wp-content/uploads/SobehartKeenanStein2000.pdf }}&lt;/ref&gt;

== References ==
{{Reflist|30em}}

&lt;!--- Categories ---&gt;
[[Category:Articles created via the Article Wizard]]
[[Category:Mathematical modeling]]</text>
      <sha1>irdkm6zgahz6h75l3xdkslgrbg7ux7o</sha1>
    </revision>
  </page>
  <page>
    <title>Curve448</title>
    <ns>0</ns>
    <id>56665655</id>
    <revision>
      <id>849280226</id>
      <parentid>848875856</parentid>
      <timestamp>2018-07-07T21:45:26Z</timestamp>
      <contributor>
        <username>Katharineamy</username>
        <id>2590656</id>
      </contributor>
      <comment>added [[Category:Elliptic curves]]; removed {{uncategorized}} using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2259">In [[cryptography]], '''Curve448''' or '''Curve448-Goldilocks'''  is an [[elliptic curve cryptography|elliptic curve]] potentially offering 224 bits of security and designed for use with the [[elliptic curve Diffie–Hellman]] (ECDH) key agreement scheme. Developed by [[Mike Hamburg]] of [[Rambus]] Cryptography Research, Curve448 allows fast performance compared with other proposed curves with comparable security.&lt;ref name=hamburg448&gt;[https://eprint.iacr.org/2015/625.pdf Ed448-Goldilocks, a new elliptic curve], Mike Hamburg, 2015&lt;/ref&gt; The [[reference implementation]] is available under an [[MIT license]].&lt;ref&gt;https://sourceforge.net/p/ed448goldilocks/code/ci/master/tree/&lt;/ref&gt; The curve is favored by the Internet Research Task Force Crypto Forum Research Group (IRTF CFRG) for inclusion in future TLS standards along with [[Curve25519]]. In 2017, NIST announced that Curve25519 and Curve448 would be added to Special Publication 800-186, which specifies approved elliptic curves for use by the US Federal Government.&lt;ref&gt;{{cite web|url=https://csrc.nist.gov/News/2017/Transition-Plans-for-Key-Establishment-Schemes|title=Transition Plans for Key Establishment Schemes}}&lt;/ref&gt; Both are described in [https://tools.ietf.org/html/rfc7748 RFC 7748].

== Mathematical properties ==
Hamburg chose the [[Solinas prime|Solinas trinomial prime]] base ''p'' = 2&lt;sup&gt;448&lt;/sup&gt; − 2&lt;sup&gt;224&lt;/sup&gt; − 1, calling it a “Goldilocks” prime “because its form defines the golden ratio φ ≡ 2&lt;sup&gt;224&lt;/sup&gt;.” The main advantage of a golden-ratio prime is fast [[Karatsuba multiplication]].

The curve Hamburg used is an untwisted [[Edwards curve]]
E&lt;sub&gt;d&lt;/sub&gt;: {{math|&lt;var&gt;y&lt;/var&gt;&lt;sup&gt;2&lt;/sup&gt; + &lt;var&gt;x&lt;/var&gt;&lt;sup&gt;2&lt;/sup&gt; {{=}} 1 − 39081&lt;var&gt;x&lt;/var&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;var&gt;y&lt;/var&gt;&lt;sup&gt;2&lt;/sup&gt;}}. The constant ''d'' = −39081 was chosen as the smallest absolute value that had the required mathematical properties, thus a [[nothing up my sleeve number]].

Curve448 is constructed such that it avoids many potential implementation pitfalls.&lt;ref&gt;{{Cite web|title = SafeCurves: Introduction|url = https://safecurves.cr.yp.to|website = safecurves.cr.yp.to|accessdate = 2018-02-23}}&lt;/ref&gt;

==References==
{{reflist}}


{{crypto-stub}}



[[Category:Elliptic curves]]</text>
      <sha1>9u5ds8tjanndwl9sxn9gt1cgtws4oq4</sha1>
    </revision>
  </page>
  <page>
    <title>DFT matrix</title>
    <ns>0</ns>
    <id>1090930</id>
    <revision>
      <id>848520147</id>
      <parentid>847792046</parentid>
      <timestamp>2018-07-02T13:07:12Z</timestamp>
      <contributor>
        <ip>93.180.190.128</ip>
      </contributor>
      <comment>/* Four-point */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8976">In applied mathematics, a '''DFT matrix''' is an expression of a '''[[discrete Fourier transform]] (DFT)''' as a [[transformation matrix]], which can be applied to a signal through [[matrix multiplication]].

==Definition==
An ''N''-point DFT is expressed as the multiplication &lt;math&gt;X = W x&lt;/math&gt;, where &lt;math&gt;x&lt;/math&gt; is the original input signal, &lt;math&gt;W&lt;/math&gt; is the ''N''-by-''N'' [[square matrix|square]] DFT matrix, and &lt;math&gt;X&lt;/math&gt; is the DFT of the signal.

The transformation matrix &lt;math&gt;W&lt;/math&gt; can be defined as &lt;math&gt;W = \left(\frac{\omega^{jk}}{{\sqrt{N}}}\right)_{j,k=0,\ldots,N-1} &lt;/math&gt;, or equivalently:

:&lt;math&gt;
W = \frac{1}{\sqrt{N}} \begin{bmatrix}
1&amp;1&amp;1&amp;1&amp;\cdots &amp;1 \\
1&amp;\omega&amp;\omega^2&amp;\omega^3&amp;\cdots&amp;\omega^{N-1} \\
1&amp;\omega^2&amp;\omega^4&amp;\omega^6&amp;\cdots&amp;\omega^{2(N-1)}\\ 1&amp;\omega^3&amp;\omega^6&amp;\omega^9&amp;\cdots&amp;\omega^{3(N-1)}\\
\vdots&amp;\vdots&amp;\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
1&amp;\omega^{N-1}&amp;\omega^{2(N-1)}&amp;\omega^{3(N-1)}&amp;\cdots&amp;\omega^{(N-1)(N-1)}
\end{bmatrix},
&lt;/math&gt;

where &lt;math&gt;\omega = e^{-2\pi i/N}&lt;/math&gt; is a [[Root of unity|primitive ''N''th root of unity]] in which &lt;math&gt;i^2=-1&lt;/math&gt;.
This is the [[Vandermonde matrix]] for the roots of unity, up to the normalization factor.  Note that the normalization factor in front of the sum( &lt;math&gt;1/\sqrt{N}&lt;/math&gt; ) and the sign of the exponent in &amp;omega; are merely conventions, and differ in some treatments. All of the following discussion applies regardless of the convention, with at most minor adjustments. The only important thing is that the forward and inverse transforms have opposite-sign exponents, and that the product of their normalization factors be 1/''N''.  However, the &lt;math&gt;1/\sqrt{N}&lt;/math&gt; choice here makes the resulting DFT matrix [[unitary matrix|unitary]], which is convenient in many circumstances.

[[Fast Fourier transform]] algorithms utilize the symmetries of the matrix to reduce the time of multiplying a vector by this matrix, from the usual &lt;math&gt;O(N^2)&lt;/math&gt;. Similar techniques can be applied for multiplications by matrices such as [[Hadamard matrix]] and the [[Walsh matrix]].

==Examples==

===Two-point===
The two-point DFT is a simple case, in which the first entry is the [[DC bias|DC]] (sum) and the second entry is the [[AC coefficients|AC]] (difference).

:&lt;math&gt;

\begin{bmatrix}
1 &amp; 1 \\
1 &amp; -1 \end{bmatrix}
&lt;/math&gt;

The first row performs the sum, and the second row performs the difference.

The factor of &lt;math&gt;1/\sqrt{2}&lt;/math&gt; is to make the transform unitary (see below).

===Four-point===
The four-point DFT matrix is as follows:

:&lt;math&gt;
W = 
\begin{bmatrix}
 \omega^0  &amp; \omega^0  &amp;\omega^0  &amp;\omega^0 \\
 \omega^0  &amp; \omega^1  &amp;\omega^2  &amp;\omega^3  \\
 \omega^0  &amp; \omega^2  &amp;\omega^4  &amp;\omega^6  \\
 \omega^0  &amp; \omega^3  &amp;\omega^6  &amp;\omega^9  \\
\end{bmatrix} = 
\begin{bmatrix}
1 &amp;  1 &amp;  1 &amp;  1\\
1 &amp;  -i &amp; -1 &amp; i\\
1 &amp; -1 &amp;  1 &amp; -1\\
1 &amp; i &amp; -1 &amp; -i\end{bmatrix}
&lt;/math&gt;
where &lt;math&gt;\omega = e^{-\frac{2 \pi i}{4}} = -i&lt;/math&gt;.

===Eight-point===
The first non-trivial integer power of two case is for eight points:

:&lt;math&gt;W=

\begin{bmatrix}
 \omega^0  &amp; \omega^0  &amp;\omega^0  &amp;\omega^0  &amp;\omega^0  &amp;\omega^0  &amp;\omega^0  &amp; \omega^0 \\
 \omega^0  &amp; \omega^1  &amp;\omega^2  &amp;\omega^3  &amp;\omega^4  &amp;\omega^5  &amp;\omega^6  &amp; \omega^7 \\
 \omega^0  &amp; \omega^2  &amp;\omega^4  &amp;\omega^6  &amp;\omega^8  &amp;\omega^{10}  &amp;\omega^{12}  &amp; \omega^{14} \\
 \omega^0  &amp; \omega^3  &amp;\omega^6  &amp;\omega^9  &amp;\omega^{12}  &amp;\omega^{15}  &amp;\omega^{18}  &amp; \omega^{21} \\
 \omega^0  &amp; \omega^4  &amp;\omega^8  &amp;\omega^{12}  &amp;\omega^{16}  &amp;\omega^{20}  &amp;\omega^{24}  &amp; \omega^{28} \\
 \omega^0  &amp; \omega^5  &amp;\omega^{10}  &amp;\omega^{15}  &amp;\omega^{20}  &amp;\omega^{25}  &amp;\omega^{30}  &amp; \omega^{35} \\
 \omega^0  &amp; \omega^6  &amp;\omega^{12}  &amp;\omega^{18}  &amp;\omega^{24}  &amp;\omega^{30}  &amp;\omega^{36}  &amp; \omega^{42} \\
 \omega^0  &amp; \omega^7  &amp;\omega^{14}  &amp;\omega^{21}  &amp;\omega^{28}  &amp;\omega^{35}  &amp;\omega^{42}  &amp; \omega^{49} \\
\end{bmatrix} = 
\begin{bmatrix}
 1  &amp;1         &amp;1   &amp;1         &amp;1   &amp;1         &amp;1   &amp;1         \\
 1  &amp;\omega    &amp;-i  &amp;-i\omega  &amp;-1  &amp;-\omega   &amp;i   &amp;i\omega   \\
 1  &amp;-i        &amp;-1  &amp;i         &amp;1   &amp;-i        &amp;-1  &amp;i         \\
 1  &amp;-i\omega  &amp;i   &amp;\omega    &amp;-1  &amp;i\omega   &amp;-i  &amp;-\omega   \\
 1  &amp;-1        &amp;1   &amp;-1        &amp;1   &amp;-1        &amp;1   &amp;-1        \\
 1  &amp;-\omega   &amp;-i  &amp;i\omega   &amp;-1  &amp;\omega    &amp;i   &amp;-i\omega  \\
 1  &amp;i         &amp;-1  &amp;-i        &amp;1   &amp;i         &amp;-1  &amp;-i        \\
 1  &amp;i\omega   &amp;i   &amp;-\omega   &amp;-1  &amp;-i\omega  &amp;-i  &amp;\omega    \\
\end{bmatrix}
&lt;/math&gt;

where

:&lt;math&gt;\omega = e^{-\frac{2 \pi i}{8}} = \frac{1}{\sqrt{2}} - \frac{i}{\sqrt{2}}&lt;/math&gt;

(Note that &lt;math&gt;\omega^{8 + n} = \omega^{n}&lt;/math&gt;.)

The following image depicts the DFT as a matrix multiplication, with elements of the matrix depicted by samples of complex exponentials:

[[Image:Fourierop rows only.svg]]

The real part (cosine wave) is denoted by a solid line, and the imaginary part (sine wave) by a dashed line.

The top row is all ones (scaled by &lt;math&gt;1/\sqrt{8}&lt;/math&gt; for unitarity), so it "measures" the [[DC bias|DC component]] in the input signal.  The next row is eight samples of negative one cycle of a complex exponential, i.e., a signal with a [[fractional frequency]] of −1/8, so it "measures" how much "strength" there is at fractional frequency +1/8 in the signal.  Recall that a [[matched filter]] compares the signal with a time reversed version of whatever we're looking for, so when we're looking for fracfreq. 1/8 we compare with fracfreq. −1/8 so that is why this row is a [[negative frequency]].  The next row is negative two cycles of a complex exponential, sampled in eight places, so it has a fractional frequency of −1/4, and thus "measures" the extent to which the signal has a fractional frequency of +1/4.

The following summarizes how the 8-point DFT works, row by row, in terms of fractional frequency:

* 0      measures how much DC is in the signal
* −1/8   measures how much of the signal has a fractional frequency of +1/8
* −1/4   measures how much of the signal has a fractional frequency of +1/4
* −3/8   measures how much of the signal has a fractional frequency of +3/8
* −1/2   measures how much of the signal has a fractional frequency of +1/2
* −5/8   measures how much of the signal has a fractional frequency of +5/8
* −3/4   measures how much of the signal has a fractional frequency of +3/4
* −7/8   measures how much of the signal has a fractional frequency of +7/8

Equivalently the last row can be said to have a fractional frequency of +1/8 and thus measure how much of the signal has a fractional frequency of −1/8.  In this way, it could be said that the top rows of the matrix "measure" positive frequency content in the signal and the bottom rows measure negative frequency component in the signal.

==Unitary transform==
The DFT is (or can be, through appropriate selection of scaling) a unitary transform, i.e., one that preserves energy.  The appropriate choice of scaling to achieve unitarity is &lt;math&gt;1/\sqrt{N}&lt;/math&gt;, so that the energy in the physical domain will be the same as the energy in the Fourier domain, i.e., to satisfy [[Parseval's theorem]].  (Other, non-unitary, scalings, are also commonly used for computational convenience; e.g., the [[convolution theorem]] takes on a slightly simpler form with the scaling shown in the [[discrete Fourier transform]] article.)

==Other properties==
For other properties of the DFT matrix, including its eigenvalues, connection to convolutions, applications, and so on, see the [[discrete Fourier transform]] article.

==In the limit: The Fourier operator==
{{main article|Fourier operator}}
{{multiple image
| footer    = The [[Fourier operator]]
| width     = 150
| image1    = Fourieropr.png
| caption1  = Real part (cosine)
| image2    = Fourieropi.png
| caption2  = Imaginary part (sine)
}}
If we make a very large matrix with complex exponentials in the rows (i.e., cosine real parts and sine imaginary parts), and increase the resolution without bound, we approach the kernel of the Fredholm integral equation of the 2nd kind, namely the [[Fourier operator]] that defines the continuous Fourier transform.  A rectangular portion of this continuous Fourier operator can be displayed as an image, analogous to the DFT matrix, as shown at right, where greyscale pixel value denotes numerical quantity.

==See also==
* [[Multidimensional transform]]
* [[Generalizations of Pauli matrices#Construction: The clock and shift matrices|Clock and shift matrices]]

==References==
* [https://www.amazon.com/gp/reader/0849336929 The Transform and Data Compression Handbook by P. C. Yip, K. Ramamohan Rao] – See chapter 2 for a treatment of the DFT based largely on the DFT matrix

==External links==
{{commonscat}}

* [http://wearcam.org/ece431/course_material/fourierop_and_dit.htm Fourier Operator and Decimation In Time (DIT)]

[[Category:Fourier analysis]]
[[Category:Digital signal processing]]
[[Category:Matrices]]</text>
      <sha1>58alnsc26k91du5z0p4kvt3kl0g3jqi</sha1>
    </revision>
  </page>
  <page>
    <title>Derivative algebra (abstract algebra)</title>
    <ns>0</ns>
    <id>1022286</id>
    <revision>
      <id>841515312</id>
      <parentid>628688481</parentid>
      <timestamp>2018-05-16T09:31:29Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1313">In [[abstract algebra]], a '''derivative algebra''' is an [[algebraic structure]] of the signature   
    
:&lt;''A'', ·, +, ', 0, 1, &lt;sup&gt;D&lt;/sup&gt;&gt;   
    
where    

:&lt;''A'', ·, +, ', 0, 1&gt;   

is a [[Boolean algebra (structure)|Boolean algebra]] and &lt;sup&gt;D&lt;/sup&gt; is a [[unary operator]], the '''derivative operator''', satisfying the identities:    
    
# 0&lt;sup&gt;D&lt;/sup&gt; = 0    
# ''x''&lt;sup&gt;DD&lt;/sup&gt; ≤ ''x'' + ''x''&lt;sup&gt;D&lt;/sup&gt;    
# (''x'' + ''y'')&lt;sup&gt;D&lt;/sup&gt; = ''x''&lt;sup&gt;D&lt;/sup&gt; + ''y''&lt;sup&gt;D&lt;/sup&gt;.  

x&lt;sup&gt;D&lt;/sup&gt; is called the '''[[derivative]]''' of x. Derivative algebras provide an algebraic abstraction of the '''[[derived set (mathematics)|derived set]]''' operator in [[topological space|topology]]. They also [[Lindenbaum–Tarski algebra|play the same role]] for the [[modal logic]] ''wK4'' = ''K''&amp;nbsp;+ ''p''∧?''p''&amp;nbsp;→&amp;nbsp;??''p'' that [[Boolean algebra (structure)|Boolean algebra]]s play for ordinary [[propositional logic]].   

==References==   
* Esakia, L., ''Intuitionistic logic and modality via topology'', Annals of Pure and Applied Logic, 127 (2004) 155-170
* McKinsey, J.C.C. and [[Alfred Tarski|Tarski, A.]], ''The Algebra of Topology'', Annals of Mathematics, 45 (1944) 141-191

[[Category:Algebras]]
[[Category:Boolean algebra]]
[[Category:Topology]]

{{algebra-stub}}</text>
      <sha1>33gwrlaakx1bqbf4ugdwkt3seye7ud4</sha1>
    </revision>
  </page>
  <page>
    <title>Diamond-square algorithm</title>
    <ns>0</ns>
    <id>3371483</id>
    <revision>
      <id>871185235</id>
      <parentid>868023012</parentid>
      <timestamp>2018-11-29T14:25:08Z</timestamp>
      <contributor>
        <ip>129.215.63.70</ip>
      </contributor>
      <comment>added links to xmountains</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5931">[[Image:Plasmafractal.gif|200px|right|thumb|Plasma fractal]]
[[File:-PLASMA-ColorCycling.Gif|200px|thumb|right|Animated plasma fractal]]

The '''diamond-square algorithm''' is a method for generating [[heightmap]]s for [[computer graphics]]. It is a slightly better algorithm than the three-dimensional implementation of the midpoint displacement algorithm which produces two-dimensional landscapes.  It is also known as the '''random midpoint displacement fractal''', the '''cloud fractal''' or the '''plasma fractal''', because of the [[plasma effect]] produced when applied.

The idea was first introduced by [[Alain Fournier|Fournier]], [[Don Fussell|Fussell]] and [[Loren Carpenter|Carpenter]] at [[SIGGRAPH]] 1982.&lt;ref name=fournier&gt;{{cite journal|last=Fournier|first=Alain|last2=Fussell|first2=Don|last3=Carpenter|first3=Loren|title=Computer rendering of stochastic models|journal=Communications of the ACM|date=June 1982|volume=25|issue=6|pages=371–384|doi=10.1145/358523.358553}}&lt;!--|accessdate=3 November 2011--&gt;&lt;/ref&gt;

The diamond-square algorithm starts with a 2D grid then [[terrain generation|randomly generates terrain height]] from four seed values arranged in a grid of points so that the entire plane is covered in squares.

==Description==
The diamond-square algorithm begins with a 2D square array of width and height 2&lt;sup&gt;n&lt;/sup&gt; + 1.  The four corner points of the array must first be set to initial values.
The diamond and square steps are then performed alternately until all array values have been set.

'''The diamond step:''' For each square in the array, set the midpoint of that square to be the average of the four corner points plus a random value.

'''The square step:''' For each diamond in the array, set the midpoint of that diamond to be the average of the four corner points plus a random value.

At each iteration, the magnitude of the random value should be reduced.

During the square steps, points located on the edges of the array will have only three adjacent values set rather than four.  There are a number of ways to handle this complication - the simplest being to take the average of just the three adjacent values.  Another option is to 'wrap around', taking the fourth value from the other side of the array.  When used with consistent initial corner values this method also allows generated fractals to be stitched together without discontinuities.

==Visualization==
The image below shows the steps involved in running the diamond-square algorithm on a 5 × 5 array.

[[File:Diamond Square.svg|800px|Visualization of the Diamond Square Algorithm]]

==Applications==

This [[algorithm]] can be used to generate realistic-looking [[Fractal landscape|landscapes]], and different implementations are used in computer graphics software such as [[Terragen]]. It is also applicable as a common component in [[procedural textures]].

==Artifacts and extensions==

The diamond-square algorithm was analyzed by [[Gavin S. P. Miller]] in SIGGRAPH 1986&lt;ref name=miller&gt;{{cite journal|last=Miller|first=Gavin S. P.|title=The definition and rendering of terrain maps|journal=ACM SIGGRAPH Computer Graphics|date=August 1986|volume=20|issue=4|pages=39–48|doi=10.1145/15886.15890}}&lt;!--|accessdate=3 November 2011--&gt;&lt;/ref&gt; who described it as flawed because the algorithm produces noticeable vertical and horizontal "creases" due to the most significant perturbation taking place in a rectangular grid. The grid artifacts were addressed in a generalized algorithm introduced by J.P. Lewis.&lt;ref&gt;{{cite journal|last1=Lewis|first1=J. P.|title=Generalized stochastic subdivision|journal=ACM Transactions on Graphics|date=1 July 1987|volume=6|issue=3|pages=167–190|doi=10.1145/35068.35069}}&lt;/ref&gt; In this variant the weights on the neighboring points are obtained by solving
a small linear system motivated by estimation theory, rather than being fixed. The Lewis algorithm also allows the synthesis of non-fractal heightmaps such as rolling hills or ocean waves.
Similar results can be efficiently obtained with Fourier synthesis,&lt;ref name=PeitgenSaupe&gt;{{cite book|last1=Peitgen|first1=Heinz-Otto, Dietmar Saupe|title=The Science of fractal images|date=1988|publisher=Springer-Verlag|location=New York|isbn=0-387-96608-0}}&lt;/ref&gt; although the possibility of adaptive refinement is lost. The diamond-square algorithm and its refinements are reviewed in the book.&lt;ref name=PeitgenSaupe /&gt;

==References==
&lt;references /&gt;

==External links==
* [https://github.com/mlepage/heightmap Simple open source heightmap module for Lua] using diamond-square algorithm
* [http://www.gameprogrammer.com/fractal.html#diamond Generating Random Fractal Terrain: The Diamond-Square Algorithm] from [http://www.gameprogrammer.com/ GameProgrammer.com]
* [http://www.ic.sunysb.edu/Stu/jseyster/plasma/ Plasma Fractal] from Justin Seyster's web page
* [http://www2.vo.lu/homepages/phahn/fractals/plasma.htm Plasma fractals] from Patrick Hahn's home page
* [http://www.lighthouse3d.com/opengl/terrain/index.php?mpd2 Terrain Tutorial] from Lighthouse3d.com
* [http://www.somethinghitme.com/2009/12/06/terrain-generation-with-canvas-and-javascript/ Random Midpoint Displacement with Canvas]
* [http://www.cescg.org/CESCG97/marak/node3.html Random midpoint displacement method]
* [https://github.com/A1essandro/Diamond-And-Square Diamond And Square] algorithm on [https://github.com/ Github] (PHP)
* [http://blog.cleancoder.com/uncle-bob/2017/01/09/DiamondSquare.html An example] of [[Test-driven_development|test-driving]] an implementation of the algorithm on [[Robert Cecil Martin|Uncle Bob]]'s [http://blog.cleancoder.com/ Clean Coder blog]
* [https://spbooth.github.io/xmountains/ Xmountains] classic sideways scrolling X11 implementation. [https://spbooth.github.io/xmountains/about_xmountains.html Algorithm details].
[[Category:Fractals]]
[[Category:Computer graphics algorithms]]
[[Category:Procedural generation]]</text>
      <sha1>7vetgcc04a9tzqh3krbe0mwzcshlf1t</sha1>
    </revision>
  </page>
  <page>
    <title>E-function</title>
    <ns>0</ns>
    <id>7735427</id>
    <revision>
      <id>841872008</id>
      <parentid>685375424</parentid>
      <timestamp>2018-05-18T16:29:51Z</timestamp>
      <contributor>
        <username>Pauli133</username>
        <id>146032</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4142">{{for|the generalization of hypergeometric series |MacRobert E function}}
In [[mathematics]], '''E-functions''' are a type of [[power series]] that satisfy particular arithmetic conditions on the coefficients. They are of interest in [[transcendental number theory]], and are more special than [[G-function (power series)|G-function]]s.

==Definition==

A function ''f''(''x'') is called of '''type ''E''''', or an '''''E''-function''',&lt;ref&gt;Carl Ludwig Siegel, ''Transcendental Numbers'', p.33, Princeton University Press, 1949.&lt;/ref&gt; if the power series

:&lt;math&gt;f(x)=\sum_{n=0}^{\infty} c_{n}\frac{x^{n}}{n!}&lt;/math&gt;

satisfies the following three conditions:

* All the coefficients ''c&lt;sub&gt;n&lt;/sub&gt;'' belong to the same [[algebraic number field]], ''K'', which has [[Degree of a field extension|finite degree]] over the rational numbers;
* For all ε&amp;nbsp;&amp;gt;&amp;nbsp;0,
:&lt;math&gt;\overline{\left|c_{n}\right|}=O\left(n^{n\varepsilon}\right)&lt;/math&gt;,
where the left hand side represents the maximum of the absolute values of all the [[Conjugate element (field theory)|algebraic conjugates]] of ''c&lt;sub&gt;n&lt;/sub&gt;'';
* For all ε&amp;nbsp;&amp;gt;&amp;nbsp;0 there is a sequence of natural numbers ''q''&lt;sub&gt;0&lt;/sub&gt;, ''q''&lt;sub&gt;1&lt;/sub&gt;, ''q''&lt;sub&gt;2&lt;/sub&gt;,... such that ''q&lt;sub&gt;n&lt;/sub&gt;c&lt;sub&gt;k&lt;/sub&gt;'' is an [[algebraic integer]] in ''K'' for ''k''=0, 1, 2,..., ''n'', and ''n'' = 0, 1, 2,... and for which
:&lt;math&gt;q_{n}=O\left(n^{n\varepsilon}\right)&lt;/math&gt;.

The second condition implies that ''f'' is an [[entire function]] of ''x''.

==Uses==

''E''-functions were first studied by [[Carl Ludwig Siegel|Siegel]] in 1929.&lt;ref&gt;C.L. Siegel, ''Über einige Anwendungen diophantischer Approximationen'', Abh. Preuss. Akad. Wiss. '''1''', 1929.&lt;/ref&gt;  He found a method to show that the values taken by certain ''E''-functions were [[algebraically independent]].This was a result which established the algebraic independence of classes of numbers rather than just linear independence.&lt;ref&gt;Alan Baker, ''Transcendental Number Theory'', pp.109-112, Cambridge University Press, 1975.&lt;/ref&gt; Since then these functions have proved somewhat useful in [[number theory]] and in particular they have application in [[Transcendental numbers|transcendence]] proofs and [[differential equations]].&lt;ref&gt;[[Serge Lang]], ''Introduction to Transcendental Numbers'', pp.76-77, Addison-Wesley Publishing Company, 1966.&lt;/ref&gt;

==The Siegel–Shidlovsky theorem==

Perhaps the main result connected to ''E''-functions is the Siegel–Shidlovsky theorem (also known as the Shidlovsky and Shidlovskii theorem), named after [[Carl Ludwig Siegel]] and Andrei Borisovich Shidlovskii.

Suppose that we are given ''n'' ''E''-functions, ''E''&lt;sub&gt;1&lt;/sub&gt;(''x''),...,''E''&lt;sub&gt;''n''&lt;/sub&gt;(''x''), that satisfy a system of homogeneous linear differential equations
:&lt;math&gt;y^\prime_i=\sum_{j=1}^n f_{ij}(x)y_j\quad(1\leq i\leq n)&lt;/math&gt;
where the ''f&lt;sub&gt;ij&lt;/sub&gt;'' are rational functions of ''x'', and the coefficients of each ''E'' and ''f'' are elements of an algebraic number field ''K''.  Then the theorem states that if ''E''&lt;sub&gt;1&lt;/sub&gt;(''x''),...,''E''&lt;sub&gt;''n''&lt;/sub&gt;(''x'') are algebraically independent over ''K''(''x''), then for any non-zero algebraic number α that is not a pole of any of the ''f&lt;sub&gt;ij&lt;/sub&gt;'' the numbers ''E''&lt;sub&gt;1&lt;/sub&gt;(α),...,''E''&lt;sub&gt;''n''&lt;/sub&gt;(α) are algebraically independent.

==Examples==

# Any polynomial with algebraic coefficients is a simple example of an ''E''-function.
# The [[exponential function]] is an ''E''-function, in its case ''c&lt;sub&gt;n&lt;/sub&gt;''=1 for all of the ''n''.
# If λ is an algebraic number then the [[Bessel function]] ''J''&lt;sub&gt;λ&lt;/sub&gt; is an ''E''-function.
# The sum or product of two ''E''-functions is an ''E''-function.  In particular ''E''-functions form a [[Ring (mathematics)|ring]].
# If ''a'' is an algebraic number and ''f''(''x'') is an ''E''-function then ''f''(''ax'') will be an ''E''-function.
# If ''f''(''x'') is an ''E''-function then the derivative and integral of ''f'' are also ''E''-functions.

==References==

&lt;references/&gt;
* {{mathworld|title=E-Function|urlname=E-Function}}

[[Category:Number theory]]</text>
      <sha1>btijrv0ehf55tnqtqemh5s2udwijj7t</sha1>
    </revision>
  </page>
  <page>
    <title>Echo removal</title>
    <ns>0</ns>
    <id>47824717</id>
    <revision>
      <id>692086194</id>
      <parentid>681294018</parentid>
      <timestamp>2015-11-23T18:53:53Z</timestamp>
      <contributor>
        <username>Klbrain</username>
        <id>11677590</id>
      </contributor>
      <comment>Disambiguated: [[regularization]] → [[regularization (physics)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="964">'''Echo removal''' is the process of removing [[echo]] and [[reverberation]] artifacts from audio signals. The reverberation is typically modeled as the [[convolution]] of a (sometimes time-varying) [[impulse response]] with a hypothetical clean input signal, where both the clean input signal (which is to be recovered) and the impulse response are unknown. This is an example of an [[inverse problem]]. In almost all cases, there is insufficient information in the input signal to uniquely determine a plausible original image, making it an [[ill-posed problem]]. This is generally solved by the use of a [[regularization (physics)|regularization]] term to attempt to eliminate implausible solutions.

This problem is analogous to [[deblurring]] in the image processing domain.

== See also ==
* [[Echo suppression and cancellation]]
* [[Digital room correction]]
* [[Noise reduction]]
* [[Linear prediction coder]]

{{math-stub}}

[[Category:Signal processing]]</text>
      <sha1>nypzoel8wx1sk4krjw0l8z0va213l4s</sha1>
    </revision>
  </page>
  <page>
    <title>Edward Hall Alderson</title>
    <ns>0</ns>
    <id>12379776</id>
    <revision>
      <id>871731227</id>
      <parentid>807929535</parentid>
      <timestamp>2018-12-03T02:29:16Z</timestamp>
      <contributor>
        <username>Atchom</username>
        <id>85952</id>
      </contributor>
      <comment>removed [[Category:British judges]]; added [[Category:English judges]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9820">{{EngvarB|date=September 2014}}
{{Use dmy dates|date=September 2014}}
[[File:Baron Alderson.jpg|thumbnail|Baron Alderson]]

'''Sir Edward Hall Alderson''' ([[baptism|baptised]] 11 September 1787 – 27 January 1857) was an English lawyer and judge whose many judgments on [[commercial law]] helped to shape the emerging British capitalism of the [[Victorian era]].&lt;ref name="hedley"&gt;Hedley (2004)&lt;/ref&gt;

He was a [[Baron of the Exchequer]] and so held the honorary title '''Baron Alderson''', in print '''Alderson, B'''.

==Early life==
Born in [[Great Yarmouth]], Alderson was the eldest son of Robert (died 1833), a [[barrister]] and [[recorder (judge)|recorder]], and Elizabeth ''née'' Hurry who died in 1791. Alderson suffered an unstable childhood, variously living with relatives, unhappily attending [[Charterhouse School]] but, more positively, being tutored by [[Edward Maltby]].&lt;ref name="hedley"/&gt; He was an able student of mathematics and [[classics]] at [[Gonville and Caius College, Cambridge]], about to take exams he heard of the sad death of his sister Isabella.  A year later in 1809 he graduated as [[senior wrangler]], First [[Smith's prize]], was First Medallist, and [[Chancellor's Gold Medal]]list.  During free time he became an ardent debater and avid reader; winning Middle Bachelors, and the Latin Prize for ''Comparison of Ancient Dialogues with Modern''.  In his finals year he also won the [[Members Prize]], and [[Senior Bachelors Prize]].  He was consequently elected [[Fellow#Oxford, Cambridge and Dublin|fellow]].&lt;ref&gt;{{acad|id=ALDR804EH|name=Alderson, Edward Hall}}&lt;/ref&gt;

A pupil of [[Joseph Chitty (the elder)|Joseph Chitty]], Alderson was [[called to the bar]] in 1811 at the [[Inner Temple]] and began work on the northern circuit where he established a substantial practice. He joined with [[Richard Barnewall]] as a [[law report]]er from 1817 to 1822. On 26 October 1823 he married Georgina Drewe (died 1871) and the couple had many children.&lt;ref name="hedley"/&gt;

An early indication of his abilities came in 1825 when he was instructed by opponents of the proposed [[Liverpool and Manchester Railway]], principally the directors of the [[Bridgewater Canal|Bridgewater]] and [[Leeds and Liverpool Canal]]s, as their counsel in the [[Act of Parliament#United Kingdom Parliament|committee stage]] of the [[private bill]] needed to establish the railway. Alderson was to [[cross-examination|cross-examine]] [[George Stephenson]] on his designs for the railway and the surveys on which they were based. Alderson proved an able advocate and Stephenson a poor witness. Stephenson later confessed, "I was not long in the witness box before I began to wish for a hole to creep out at." Largely owing to Alderson's devastating closing speech, the bill was lost, the railway was delayed for several years and Stephenson's early reputation badly damaged.&lt;ref&gt;{{ cite book | author=Rolt, L.T.C. | year=1960 | title=George and Robert Stephenson: The Railway Revolution | publisher=Penguin | location=London | isbn=0-14-007646-8 | pages=109–112 }}&lt;/ref&gt;

==Judicial career==
Alderson was appointed to the [[Common Law Commission]] in 1828 and a judge of the [[Court of Common Pleas (England)|Court of Common Pleas]] in 1830, with the attendant [[knighthood]]. He became a [[Baron of the Exchequer]] in the [[Exchequer of Pleas]] in 1834, and transferred to the [[Court of Chancery]] in 1841. He was an advocate of the plasticity of the [[common law]] in adapting to the changing times. According to Hedley, he was popular and jocular, a "clever, analytical, and forthright judge, with little patience for those of lesser abilities". He never sought to be a [[Queen's Counsel]] or Member of Parliament.&lt;ref name="hedley"/&gt;

==Personality and family==
Though, as a [[criminal law|criminal]] judge at the [[assizes]], he was instrumental in suppressing the [[Luddites]] and [[Chartists]], he believed that [[rehabilitation (penology)|rehabilitation]] was the principal goal of [[sentence (law)|sentencing]]. He was dubious of the effects of [[deterrence (legal)|deterrence]] and argued for the limitation of capital punishment, himself seeking to disapply it, by whatever technical means he could creatively devise.&lt;ref name="hedley"/&gt;

An active member of the [[Church of England]] and a close friend of [[Bishop of London]] [[Charles James Blomfield]], Alderson supported the [[Gorham judgment]] which held that the Church was subject to secular law. He was a noted advocate of [[affirmation in law|affirmation]] as an alternative to the [[oath]] for witnesses but opposed the growing contemporary campaign for secular education. Hedley describes Alderson as a "Conservative... suspicious of the 'tyranny' he saw in democracy".&lt;ref name="hedley"/&gt;

Alderson established homes in London and [[Lowestoft]] where he wrote poetry, in English and [[Latin (language)|Latin]], and corresponded with his cousin, novelist [[Amelia Opie]].&lt;ref name="hedley"/&gt; He was also an enthusiastic and knowledgeable follower of [[horse racing]].&lt;ref&gt;Foulkes (2010) ''p''213&lt;/ref&gt;

While sitting at [[Liverpool]] assizes in December 1856, he heard of a serious injury to one of his sons and collapsed. He died the following January at his London home from a [[Brain#Brain pathology|brain disease]]. He was buried at St Mary Magdalen's Church, [[Risby, Suffolk|Risby]], near [[Bury St Edmunds]].&lt;ref name="hedley"/&gt;

Alderson's daughter [[Georgina Gascoyne-Cecil, Marchioness of Salisbury|Georgina Charlotte]] married British [[politician|statesman]], [[Robert Gascoyne-Cecil, 3rd Marquess of Salisbury]] in 1857. Salisbury's father, [[James Gascoyne-Cecil, 2nd Marquess of Salisbury]], opposed the marriage owing to Georgina's lack of wealth and social standing.&lt;ref&gt;Grenville, J. A. S. (2001) "Salisbury, Robert Arthur Talbot...." ''[[Encyclopædia Britannica]]'' Deluxe Edition CD-ROM&lt;/ref&gt;

==Cases==
* ''Miller v. Salomons '' - oath of abjuration
*''R v Pritchard'' (1836) 7 C. &amp; P. 303 continues to be used in modern criminal cases in England and Wales as having laid down the criteria for assessing a defendant's [[fitness to plead]].&lt;ref&gt;Archbold Criminal Pleading, Evidence and Practice 2014, 4–235 at page 431&lt;/ref&gt;
*''[[Winterbottom v. Wright]]'' (1842) – Reasserted the traditional doctrine of [[privity of contract]] to dismiss a [[negligence]] claim for [[damages]] by a pedestrian who was injured by a defective vehicle.&lt;ref&gt;{{ cite book | pages=''pp''91–91 | title=Tort Law:Text and Materials |author1=Lunney, M.  |author2=Oliphant, K. | edition=2nd | publisher=Oxford University Press | location =Oxford | year=2003 | isbn=0-19-926055-9 }}&lt;/ref&gt;
*''[[Wood v Peel]]'' (1844) – in a trial to determine the winner of the [[Epsom Derby|Derby]], Alderson ordered that the purported winner ''Running Rein'' be produced in court. The horse could not be found and the result of the race was overturned.&lt;ref&gt;{{ cite book | url=https://books.google.com/books?id=jc0kh800jGIC&amp;printsec=titlepage#PRA3-PA350,M1 | title=The Annual Register, or a View of the History and Politics of the Year 1844 | year=1845 | author= [[Edmund Burke|Burke, E.]] | location=London | publisher=Rivington | pages=''pp''350–352 }} ([[Google Books]])&lt;/ref&gt;&lt;ref&gt;Foulkes (2010)&lt;/ref&gt;
* ''R v. Serva and others''
*''[[Priest-penitent privilege in the UK#R v. Griffin|R v. Griffin]]'' (1853) – Alderson suggested, contrary to precedent but ''[[obiter dicta]]'', that the principle of [[Priest-penitent privilege in the UK|priest-penitent privilege]] applied in England.&lt;ref&gt;{{ cite book | title=Law of Privilege | author=McNicol, S. B. | year=1992 | publisher=Law Book Co. Ltd | location=Sydney | isbn=0-455-21149-3 | pages=324–325 }}&lt;/ref&gt;
*''[[Neilson v Harford]]'' (1841) – Distinguished patenting a principle (impermissible) from patenting a physical implementation of a principle (permissible)
*''[[White v Bluett]]''
* ''Knight (Clerk) v. The Marquess of Waterford''
*''[[Hadley v Baxendale]]'' (1854) – Defined the scope of contractual [[damages]] in English law.
*''[[Blyth v Company Proprietors of the Birmingham Water Works]]'' (1856) – Introduced the concept of the [[reasonable person]] in setting judicial standards for the appropriate level of care owed to another.

==References==
{{reflist}}

==Bibliography==
*[Anon.] (1857) ''Law Times'' 31 Jan, ''p.''255; 7 Feb, ''p.''266
*{{ cite book | author=Alderson, C. H. | year=1858 | title=Selections From the Charges and Other Detached Papers of Baron Alderson. With an Introductory Notice of His Life | location=London | publisher=John W. Parker &amp; Son }}
*{{ cite book | author=Foulkes, N. | publisher=Weidenfeld &amp; Nicolson | location=London | title=Gentlemen and Blackguards: Gambling Mania and Plot to Steal the Derby of 1844 | year=2010 | page=Ch.17–19 }}
*Hedley, S. (2004) "[http://www.oxforddnb.com/view/article/303 Alderson, Sir Edward Hall (bap. 1787, d. 1857)]", ''[[Oxford Dictionary of National Biography]]'', Oxford University Press, accessed 22 July 2007 {{ODNBsub}}

==External links==
{{DNB Poster|Alderson, Edward Hall|Edward Hall Alderson}}
{{wikiquote}}
*[http://www.chartists.net/Lancaster-Trial-1843.htm The trial of Feargus O'Connor and 58 other Chartists – 1843] – a trial at which Alderson was judge

{{Authority control}}

{{DEFAULTSORT:Alderson, Edward Hall}}
[[Category:1787 births]]
[[Category:1857 deaths]]
[[Category:English judges]]
[[Category:English Anglicans]]
[[Category:Alumni of Gonville and Caius College, Cambridge]]
[[Category:Fellows of Gonville and Caius College, Cambridge]]
[[Category:People educated at Charterhouse School]]
[[Category:Senior Wranglers]]
[[Category:Justices of the Common Pleas]]
[[Category:Barons of the Exchequer]]
[[Category:Knights Bachelor]]
[[Category:People from Great Yarmouth]]</text>
      <sha1>gg0nfn742qijt7qll1arv4gj7oqijxl</sha1>
    </revision>
  </page>
  <page>
    <title>Fisher information</title>
    <ns>0</ns>
    <id>598971</id>
    <revision>
      <id>870430953</id>
      <parentid>864801225</parentid>
      <timestamp>2018-11-24T19:27:28Z</timestamp>
      <contributor>
        <ip>37.26.146.245</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="34328">In [[mathematical statistics]], the '''Fisher information''' (sometimes simply called '''information'''&lt;ref&gt;Lehmann &amp; Casella, p. 115&lt;/ref&gt;) is a way of measuring the amount of information that an observable random variable ''X'' carries about an unknown parameter ''θ'' of a distribution that models ''X''. 
Formally, it is the [[variance]] of the [[score (statistics)|score]], or the [[expected value]] of the [[observed information]]. In [[Bayesian statistics]], the [[Asymptotic distribution]] of the [[posterior distribution|posterior]] [[mode (statistics)|mode]] depends on the Fisher information and not on the [[prior distribution|prior]] (according to the [[Bernstein–von Mises theorem]], which was anticipated by [[Laplace]] for [[exponential families]]).&lt;ref&gt;[[Lucien Le Cam]] (1986) ''Asymptotic Methods in Statistical Decision Theory'': Pages 336 and 618–621 (von Mises and Bernstein).
&lt;/ref&gt; The role of the Fisher information in the asymptotic theory of [[maximum-likelihood estimation]] was emphasized by the statistician [[Ronald Fisher]] (following some initial results by [[Francis Ysidro Edgeworth]]). The Fisher information is also used in the calculation of the [[Jeffreys prior]], which is used in Bayesian statistics.

The Fisher-information matrix is used to calculate the [[covariance matrices]] associated with [[Maximum likelihood|maximum-likelihood]] [[Estimator|estimates]]. It can also be used in the formulation of test statistics, such as the [[Wald test]].

Statistical systems of a scientific nature (physical, biological, etc.) whose likelihood functions obey shift invariance have been shown to obey maximum Fisher information.&lt;ref&gt;Frieden &amp; Gatenby (2013)&lt;/ref&gt; The level of the maximum depends upon the nature of the system constraints.

==Definition==
The Fisher information is a way of measuring the amount of information that an observable [[random variable]] ''X'' carries about an unknown [[parameter]] ''θ'' upon which the probability of ''X'' depends. Let ''f''(''X''; ''θ'') be the [[probability density function]] (or [[probability mass function]]) for ''X'' conditional on the value of ''θ''. This is also the [[likelihood function]] for ''θ''. It describes the probability that we observe a given sample ''X'', ''given'' a known value of ''θ''. If ''f'' is sharply peaked with respect to changes in ''θ'', it is easy to indicate the “correct” value of ''θ'' from the data, or equivalently, that the data ''X'' provides a lot of information about the parameter ''θ''. If the likelihood ''f'' is flat and spread-out, then it would take many samples like of ''X'' to estimate the actual “true” value of ''θ'' that ''would'' be obtained using the entire population being sampled. This suggests studying some kind of variance with respect to ''θ''.

Formally, the [[partial derivative]] with respect to ''θ'' of the [[natural logarithm]] of the likelihood function is called the “''[[score (statistics)|score]]''”. Under certain regularity conditions, if ''θ'' is the true parameter (i.e. ''X'' is actually distributed as ''f''(''X''; ''θ'')), it can be shown that the [[expected value]] (the first [[moment (mathematics)|moment]]) of the score is 0:&lt;ref name=SubaRao&gt;{{cite web|last=Suba Rao|title=Lectures on statistical inference|url=http://www.stat.tamu.edu/~suhasini/teaching613/inference.pdf}}&lt;/ref&gt;
:&lt;math&gt;\begin{align}
\operatorname{E} \left[\left. \frac{\partial}{\partial\theta} \log f(X;\theta)\right|\theta \right]
&amp;= \int \frac{\frac{\partial}{\partial\theta} f(x;\theta)}{f(x; \theta)} f(x;\theta)\,dx \\
&amp;= \frac{\partial}{\partial\theta} \int f(x; \theta)\,dx \\
&amp;= \frac{\partial}{\partial\theta} 1 = 0.
\end{align}&lt;/math&gt;
The [[variance]] (which equals the [[Central moment|second central moment]]) is defined to be the '''Fisher information''':
:&lt;math&gt; \mathcal{I}(\theta)=\operatorname{E} \left[\left. \left(\frac{\partial}{\partial\theta} \log f(X;\theta)\right)^2\right|\theta \right] = \int \left(\frac{\partial}{\partial\theta} \log f(x;\theta)\right)^2 f(x; \theta)\,dx,&lt;/math&gt;
Note that &lt;math&gt;0 \leq \mathcal{I}(\theta) &lt; \infty&lt;/math&gt;. A random variable carrying high Fisher information implies that the absolute value of the score is often high. The Fisher information is not a function of a particular observation, as the random variable ''X'' has been averaged out.

If {{nowrap|log ''f''(''x''; ''θ'')}} is twice differentiable with respect to ''θ'', and under certain regularity conditions,&lt;ref name="SubaRao" /&gt; then the Fisher information may also be written as&lt;ref&gt;Lehmann &amp; Casella, eq. (2.5.16), Lemma 5.3, p.116.&lt;/ref&gt;
:&lt;math&gt; \mathcal{I}(\theta) = - \operatorname{E} \left[\left. \frac{\partial^2}{\partial\theta^2} \log f(X;\theta)\right|\theta \right],&lt;/math&gt;
since
:&lt;math&gt;\frac{\partial^2}{\partial\theta^2} \log f(X;\theta) = \frac{\frac{\partial^2}{\partial\theta^2} f(X;\theta)}{f(X; \theta)} - \left( \frac{\frac{\partial}{\partial\theta} f(X;\theta)}{f(X; \theta)} \right)^2
= \frac{\frac{\partial^2}{\partial\theta^2} f(X;\theta)}{f(X; \theta)} - \left( \frac{\partial}{\partial\theta} \log f(X;\theta)\right)^2 &lt;/math&gt;
and
:&lt;math&gt; \operatorname{E} \left[\left. \frac{\frac{\partial^2}{\partial\theta^2} f(X;\theta)}{f(X; \theta)}\right|\theta \right] = \frac{\partial^2}{\partial\theta^2} \int f(x;\theta)\,dx = 0. &lt;/math&gt;
Thus, the Fisher information may be seen as the curvature of the [[support curve]] (the graph of the log-likelihood). Near the [[maximum likelihood]] estimate, low Fisher information therefore indicates that the maximum appears "blunt", that is, the maximum is shallow and there are many nearby values with a similar log-likelihood. Conversely, high Fisher information indicates that the maximum is sharp.

===Informal derivation of the Cramér–Rao bound===
The [[Cramér–Rao bound]] states that the inverse of the Fisher information is a lower bound on the variance of any [[unbiased estimator]] of ''θ''. H.L. Van Trees (1968) and [[B. Roy Frieden]] (2004) provide the following method of deriving the [[Cramér–Rao bound]], a result which describes use of the Fisher information.

Informally, we begin by considering an [[unbiased estimator]] &lt;math&gt;\hat\theta(X)&lt;/math&gt;. Mathematically, "unbiased" means that

:&lt;math&gt;
\operatorname{E}\left[ \left. \hat\theta(X) - \theta \right| \theta \right]
= \int \left(\hat\theta(x) - \theta\right) \, f(x ;\theta) \, dx = 0.
&lt;/math&gt;

This expression is zero independent of ''θ'', so its partial derivative with respect to ''θ'' must also be zero. By the [[product rule]], this partial derivative is also equal to

:&lt;math&gt;
0 = \frac{\partial}{\partial\theta} \int \left(\hat\theta(x) - \theta \right) \, f(x ;\theta) \,dx
= \int \left(\hat\theta(x)-\theta\right) \frac{\partial f}{\partial\theta} \, dx - \int f \,dx.
&lt;/math&gt;

For each ''θ'', the likelihood function is a probability density function, and therefore &lt;math&gt;\int f\,dx = 1&lt;/math&gt;. A basic computation implies that

:&lt;math&gt;\frac{\partial f}{\partial\theta} = f \, \frac{\partial \log f}{\partial\theta}.&lt;/math&gt;

Using these two facts in the above, we get

:&lt;math&gt;
\int \left(\hat\theta-\theta\right) f \, \frac{\partial \log f}{\partial\theta} \, dx = 1.
&lt;/math&gt;

Factoring the integrand gives
:&lt;math&gt;
\int \left(\left(\hat\theta-\theta\right) \sqrt{f} \right) \left( \sqrt{f} \, \frac{\partial \log f}{\partial\theta} \right) \, dx = 1.
&lt;/math&gt;

Squaring the expression in the integral, the [[Cauchy–Schwarz inequality]] yields

:&lt;math&gt;
1 =
\biggl( \int \left[\left(\hat\theta-\theta\right) \sqrt{f} \right] \cdot \left[ \sqrt{f} \, \frac{\partial \log f}{\partial\theta} \right] \, dx \biggr)^2
\le
\left[ \int \left(\hat\theta - \theta\right)^2 f \, dx \right] \cdot \left[ \int \left( \frac{\partial \log f}{\partial\theta} \right)^2 f \, dx \right].
&lt;/math&gt;

The second bracketed factor is defined to be the Fisher Information, while the first bracketed factor is the expected mean-squared error of the estimator &lt;math&gt;\hat\theta&lt;/math&gt;. By rearranging, the inequality tells us that

:&lt;math&gt;
\operatorname{Var}\left(\hat\theta\right) \geq \frac{1}{\mathcal{I}\left(\theta\right)}.
&lt;/math&gt;

In other words, the precision to which we can estimate ''θ'' is fundamentally limited by the Fisher information of the likelihood function.

===Single-parameter Bernoulli experiment===
A [[Bernoulli trial]] is a random variable with two possible outcomes, "success" and "failure", with success having a probability of ''θ''. The outcome can be thought of as determined by a coin toss, with the probability of heads being ''θ'' and the probability of tails being {{nowrap|1 − ''θ''}}.

Let ''X'' be a Bernoulli trial. The Fisher information contained in ''X'' may be calculated to be
:&lt;math&gt;\begin{align}
\mathcal{I}(\theta)
&amp;= -\operatorname{E}\left[\left. \frac{\partial^2}{\partial\theta^2} \log\left(\theta^X (1 - \theta)^{1 - X}\right)\right|\theta\right] \\[5pt]
&amp;= -\operatorname{E}\left[\left. \frac{\partial^2}{\partial\theta^2} \big(X\log\theta + (1 - X)\log(1-\theta)\big)\right|\theta\right] \\[5pt]
&amp;= \operatorname{E}\left[\left. \frac{X}{\theta^2} + \frac{1 - X}{(1 - \theta)^2}\right|\theta\right] \\[5pt]
&amp;= \frac{\theta}{\theta^2} + \frac{1 - \theta}{(1 - \theta)^2} \\[5pt]
&amp;= \frac{1}{\theta(1 - \theta)}.
\end{align}&lt;/math&gt;

Because Fisher information is additive, the Fisher information contained in ''n'' independent [[Bernoulli trial]]s is therefore
:&lt;math&gt;\mathcal{I}(\theta) = \frac{n}{\theta(1 - \theta)}.&lt;/math&gt;
This is the reciprocal of the [[variance]] of the mean number of successes in ''n'' [[Bernoulli trial]]s, so in this case, the Cramér–Rao bound is an equality.

==Matrix form==
When there are ''N'' parameters, so that ''θ'' is a {{nowrap|''N'' × 1}} [[column vector|vector]] &lt;math&gt;\theta = \begin{bmatrix}
 \theta_1, \theta_2, \dots , \theta_N \end{bmatrix}^{\mathrm T},&lt;/math&gt; then the Fisher information takes the form of an {{nowrap|''N'' × ''N''}} [[matrix (mathematics)|matrix]].  This matrix is called the '''Fisher information matrix''' (FIM) and has typical element

:&lt;math&gt;
{\bigl[\mathcal{I}(\theta) \bigr]}_{i, j}
=
\operatorname{E}
\left[\left.
 \left(\frac{\partial}{\partial\theta_i} \log f(X;\theta)\right)
 \left(\frac{\partial}{\partial\theta_j} \log f(X;\theta)\right)
\right|\theta\right].
&lt;/math&gt;

The FIM is a {{nowrap|''N'' × ''N''}} [[positive semidefinite matrix|positive semidefinite]] matrix.  If it is positive definite, then it defines a [[Riemannian metric]] on the ''N''-[[dimension]]al [[parameter space]].  The topic [[information geometry]] uses this to connect Fisher information to [[differential geometry]], and in that context, this metric is known as the [[Fisher information metric]].

Under certain regularity conditions, the Fisher information matrix may also be written as

:&lt;math&gt;
\bigl[\mathcal{I}(\theta) \bigr]_{i, j}
= - \operatorname{E}
\left[\left.
 \frac{\partial^2}{\partial\theta_i \, \partial\theta_j} \log f(X;\theta)
\right|\theta\right]\,.
&lt;/math&gt;

The result is interesting in several ways:
*It can be derived as the [[Hessian matrix|Hessian]] of the [[relative entropy]].
*It can be understood as a metric induced from the [[Euclidean metric]], after appropriate change of variable.
*In its complex-valued form, it is the [[Fubini–Study metric]].
*It is the key part of the proof of [[Wilks' theorem|Wilks’ theorem]], which allows confidence region estimates for [[maximum likelihood estimation]] (for those conditions for which it applies) without needing the [[Likelihood Principle]].

===Orthogonal parameters===
We say that two parameters ''θ&lt;sub&gt;i&lt;/sub&gt;'' and ''θ&lt;sub&gt;j&lt;/sub&gt;'' are orthogonal if the element of the ''i''th row and ''j''th column of the Fisher information matrix is zero. Orthogonal parameters are easy to deal with in the sense that their [[maximum likelihood| maximum likelihood estimates]] are independent and can be calculated separately. When dealing with research problems, it is very common for the researcher to invest some time searching for an orthogonal parametrization of the densities involved in the problem.{{Citation needed|date=August 2010}}

===Singular statistical model===
{{see also|Regular parametric model}}
&lt;!--The section title should not be changed, because it is targeted by a REDIRECT from [[Singular statistical model]].--&gt;
If the Fisher information matrix is positive definite for all {{mvar|&amp;theta;}}, then the corresponding [[statistical model]] is said to be ''regular''; otherwise, the statistical model is said to be ''singular''.&lt;ref&gt;{{Citation|first=S. | last= Watanabe | title= Algebraic geometrical method in singular statistical estimation | work= Quantum Bio-Informatics | editor1-first= L. | editor2-first= W. | editor3-first= M. | editor1-last= Accardi | editor2-last= Freudenberg | editor3-last=Ohya | pages= 325–336 | year= 2008 | publisher= [[World Scientific]]}}.&lt;/ref&gt; Examples of singular statistical models include the following: normal mixtures, binomial mixtures, multinomial mixtures, Bayesian networks, neural networks, radial basis functions, hidden Markov models, stochastic context-free grammars, reduced rank regressions, Boltzmann machines.

In [[machine learning]], if a statistical model is devised so that it extracts hidden structure from a random phenomenon, then it naturally becomes singular.&lt;ref&gt;{{cite journal | last1 = Watanabe | first1 = S | year = 2013 | title = A Widely Applicable Bayesian Information Criterion | url = | journal = [[Journal of Machine Learning Research]] | volume = 14 | issue = | pages = 867–897 }}&lt;/ref&gt;

===Multivariate normal distribution===
The FIM for a ''N''-variate [[multivariate normal distribution]], &lt;math&gt;\,X \sim N\left(\mu(\theta), \Sigma(\theta)\right)&lt;/math&gt; has a special form. Let the ''K''-dimensional vector of parameters be &lt;math&gt;\theta = \begin{bmatrix} \theta_1, \dots , \theta_K \end{bmatrix}^\mathrm{T}&lt;/math&gt; and the vector of random normal variables be &lt;math&gt;X = \begin{bmatrix} X_1, \dots , X_N \end{bmatrix}^\mathrm{T}&lt;/math&gt;.  Assume that the mean values of these random variables are &lt;math&gt;\,\mu(\theta) = \begin{bmatrix} \mu_1(\theta), \dots , \mu_N(\theta) \end{bmatrix}^\mathrm{T}&lt;/math&gt;, and let &lt;math&gt;\,\Sigma(\theta)&lt;/math&gt; be the [[covariance matrix]]. Then, for &lt;math&gt;1 \le m, n \le K&lt;/math&gt;, the (''m'', ''n'') entry of the FIM is:&lt;ref&gt;{{cite journal |title=Information geometry of the Gaussian distribution in view of stochastic optimization |first=Luigi |last=Malagò |first2=Giovanni |last2=Pistone |journal=[[Proceedings of the 2015 ACM Conference on Foundations of Genetic Algorithms XIII]] |year=2015 |pages=150–162 |doi=10.1145/2725494.2725510 }}&lt;/ref&gt;
:&lt;math&gt;
\mathcal{I}_{m,n}
=
\frac{\partial \mu^\mathrm{T}}{\partial \theta_m}
\Sigma^{-1}
\frac{\partial \mu}{\partial \theta_n}
+
\frac{1}{2}
\operatorname{tr}
\left(
 \Sigma^{-1}
 \frac{\partial \Sigma}{\partial \theta_m}
 \Sigma^{-1}
 \frac{\partial \Sigma}{\partial \theta_n}
\right),
&lt;/math&gt;

where &lt;math&gt;(\cdot)^\mathrm{T}&lt;/math&gt; denotes the [[transpose]] of a vector, {{math|tr(&amp;middot;)}} denotes the [[trace (matrix)|trace]] of a [[square matrix]], and:

*&lt;math&gt;
\frac{\partial \mu}{\partial \theta_m}
=
\begin{bmatrix}
 \frac{\partial \mu_1}{\partial \theta_m} &amp;
 \frac{\partial \mu_2}{\partial \theta_m} &amp;
 \cdots &amp;
 \frac{\partial \mu_N}{\partial \theta_m}
\end{bmatrix}^\mathrm{T};
&lt;/math&gt;

*&lt;math&gt;
\frac{\partial \Sigma}{\partial \theta_m}
=
\begin{bmatrix}
 \frac{\partial \Sigma_{1,1}}{\partial \theta_m} &amp;
 \frac{\partial \Sigma_{1,2}}{\partial \theta_m} &amp;
 \cdots &amp;
 \frac{\partial \Sigma_{1,N}}{\partial \theta_m} \\[5pt]
 \frac{\partial \Sigma_{2,1}}{\partial \theta_m} &amp;
 \frac{\partial \Sigma_{2,2}}{\partial \theta_m} &amp;
 \cdots &amp;
 \frac{\partial \Sigma_{2,N}}{\partial \theta_m} \\
 \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
 \frac{\partial \Sigma_{N,1}}{\partial \theta_m} &amp;
 \frac{\partial \Sigma_{N,2}}{\partial \theta_m} &amp;
 \cdots &amp;
 \frac{\partial \Sigma_{N,N}}{\partial \theta_m}
\end{bmatrix}.
&lt;/math&gt;

Note that a special, but very common, case is the one where
&lt;math&gt;\Sigma(\theta) = \Sigma&lt;/math&gt;, a constant. Then

:&lt;math&gt;
\mathcal{I}_{m,n}
=
\frac{\partial \mu^\mathrm{T}}{\partial \theta_m}
\Sigma^{-1}
\frac{\partial \mu}{\partial \theta_n}.\ 
&lt;/math&gt;

In this case the Fisher information matrix may be identified with the coefficient matrix of the normal equations of [[least squares]] estimation theory.

Another special case occurs when the mean and covariance depend on two different vector parameters, say, ''β'' and ''θ''. This is especially popular in the analysis of spatial data, which often uses a linear model with correlated residuals. In this case,&lt;ref&gt;{{cite journal |title=Maximum likelihood estimation of models for residual covariance in spatial regression |first=K. V. |last=Mardia |first2=R. J. |last2=Marshall |journal=[[Biometrika]] |year=1984 |volume=71 |issue=1 |pages=135–46 |doi=10.1093/biomet/71.1.135 }}&lt;/ref&gt;

: &lt;math&gt;\mathcal{I}(\beta,\theta)=\operatorname{diag}\left( \mathcal{I}(\beta), \mathcal{I}(\theta) \right)&lt;/math&gt;
where
: &lt;math&gt;
\begin{align}
\mathcal{I}{(\beta)_{m,n}} &amp; =\frac{\partial\mu^{\text{T}}}{\partial\beta_m} \Sigma^{-1} \frac{\partial \mu }{\partial\beta_n}, \\[5pt]
\mathcal{I}{(\theta)_{m,n}} &amp; =\frac{1}{2}\operatorname{tr}\left(\Sigma^{-1} \frac{\partial \Sigma}{\partial\theta_m}{\Sigma^{-1}}\frac{\partial\Sigma}{\partial\theta_n} \right)
\end{align}
&lt;/math&gt;

==Properties==

===Chain rule===
Similar to the [[Entropy (information theory)#Further properties|entropy]] or [[Mutual information#Conditional mutual information|mutual information]], the Fisher information also possesses a '''chain rule''' decomposition. In particular, if ''X'' and ''Y'' are jointly distributed random variables, it follows that:&lt;ref&gt;{{cite journal |title=A proof of the Fisher information inequality via a data processing argument |first=R. |last=Zamir |journal=[[IEEE Transactions on Information Theory]] |year=1998 |volume=44 |issue=3 |pages=1246–1250 |doi=10.1109/18.669301 }}&lt;/ref&gt; 
:&lt;math&gt; \mathcal{I}_{X,Y}(\theta) = \mathcal{I}_X(\theta) + \mathcal{I}_{Y\mid X}(\theta), &lt;/math&gt;
where &lt;math&gt;\mathcal{I}_{Y\mid X}(\theta)&lt;/math&gt; is the Fisher information of ''Y'' relative to &lt;math&gt;\theta&lt;/math&gt; calculated with respect to the conditional density of ''Y'' given a specific value&amp;nbsp;''X''&amp;nbsp;=&amp;nbsp;''x''.

As a special case, if the two random variables are [[statistical independence|independent]], the information yielded by the two random variables is the sum of the information from each random variable separately:
:&lt;math&gt; \mathcal{I}_{X,Y}(\theta) = \mathcal{I}_X(\theta) + \mathcal{I}_Y(\theta). &lt;/math&gt;
Consequently, the information in a random sample of ''n'' [[Independent and identically distributed random variables|independent and identically distributed]] observations is ''n'' times the information in a sample of size&amp;nbsp;1.

===Sufficient statistic===
The information provided by a [[sufficiency (statistics)|sufficient statistic]] is the same as that of the sample ''X''. This may be seen by using [[Sufficient statistic#Fisher–Neyman factorization theorem|Neyman's factorization criterion]] for a sufficient statistic. If ''T''(''X'') is sufficient for ''θ'', then
:&lt;math&gt;f(X;\theta) = g(T(X), \theta) h(X)&lt;/math&gt;
for some functions ''g'' and ''h''.  The independence of ''h''(''X'') from ''θ'' implies
:&lt;math&gt;\frac{\partial}{\partial\theta} \log \left[f(X   ;\theta)\right] = \frac{\partial}{\partial\theta} \log \left[g(T(X);\theta)\right],&lt;/math&gt;
and the equality of information then follows from the definition of Fisher information. More generally, if {{nowrap|''T {{=}} t''(''X'')}} is a [[statistic]], then

:&lt;math&gt; \mathcal{I}_T(\theta) \leq \mathcal{I}_X(\theta) &lt;/math&gt;

with equality [[if and only if]] ''T'' is a [[sufficient statistic]].

===Reparametrization===
The Fisher information depends on the parametrization of the problem. If ''θ'' and ''η'' are two scalar parametrizations of an estimation problem, and ''θ'' is a [[continuously differentiable]] function of ''η'', then
:&lt;math&gt;{\mathcal I}_\eta(\eta) = {\mathcal I}_\theta(\theta(\eta)) \left( \frac{d\theta}{d\eta} \right)^2&lt;/math&gt;
where &lt;math&gt;{\mathcal I}_\eta&lt;/math&gt; and &lt;math&gt;{\mathcal I}_\theta&lt;/math&gt; are the Fisher information measures of ''η'' and ''θ'', respectively.&lt;ref&gt;Lehmann &amp; Casella, eq. (2.5.11).&lt;/ref&gt;

In the vector case, suppose &lt;math&gt;{\boldsymbol \theta}&lt;/math&gt; and &lt;math&gt;{\boldsymbol \eta}&lt;/math&gt; are ''k''-vectors which parametrize an estimation problem, and suppose that &lt;math&gt;{\boldsymbol \theta}&lt;/math&gt; is a continuously differentiable function of &lt;math&gt;{\boldsymbol \eta}&lt;/math&gt;, then,&lt;ref&gt;Lehmann &amp; Casella, eq. (2.6.16)&lt;/ref&gt;
:&lt;math&gt;{\mathcal I}_{\boldsymbol \eta}({\boldsymbol \eta}) = {\boldsymbol J}^{\mathrm T} {\mathcal I}_{\boldsymbol \theta} ({\boldsymbol \theta}({\boldsymbol \eta})) {\boldsymbol J}
&lt;/math&gt;
where the (''i'', ''j'')th element of the ''k''&amp;nbsp;×&amp;nbsp;''k'' [[Jacobian matrix]] &lt;math&gt;\boldsymbol J&lt;/math&gt; is defined by
:&lt;math&gt;J_{ij} = \frac{\partial \theta_i}{\partial \eta_j},&lt;/math&gt;
and where &lt;math&gt;{\boldsymbol J}^{\mathrm T}&lt;/math&gt; is the matrix transpose of &lt;math&gt;{\boldsymbol J}.&lt;/math&gt;

In [[information geometry]], this is seen as a change of coordinates on a [[Riemannian manifold]], and the intrinsic properties of curvature are unchanged under different parametrization.  In general, the Fisher information matrix provides a Riemannian metric (more precisely, the Fisher–Rao metric) for the manifold of thermodynamic states, and can be used as an information-geometric complexity measure for a classification of [[phase transitions]], e.g., the scalar curvature of the thermodynamic metric tensor diverges at (and only at) a phase transition point.&lt;ref&gt;{{cite journal |first=W. |last=Janke |first2=D. A. |last2=Johnston |first3=R. |last3=Kenna |title=Information Geometry and Phase Transitions |journal=Physica A |volume=336 |issue=1–2 |pages=181 |year=2004 |doi=10.1016/j.physa.2004.01.023 |arxiv=cond-mat/0401092 |bibcode=2004PhyA..336..181J }}&lt;/ref&gt;

In the thermodynamic context, the Fisher information matrix is directly related to the rate of change in the corresponding [[Order parameter#Order parameters|order parameters]].&lt;ref&gt;{{cite journal |first=M. |last=Prokopenko |first3=J. T. |last3=Lizier |first4=O. |last4=Obst |first5=X. R. |last5=Wang |title=Relating Fisher information to order parameters |journal=Physical Review E |volume=84 |issue= 4|pages=041116 |year=2011 |doi=10.1103/PhysRevE.84.041116 |last2=Lizier |first2=Joseph T. |bibcode=2011PhRvE..84d1116P }}&lt;/ref&gt; In particular, such relations identify second-order phase transitions via divergences of individual elements of the Fisher information matrix.

==Applications==

===Optimal design of experiments===
Fisher information is widely used in [[Optimal design|optimal experimental design]]. Because of the reciprocity of estimator-variance and Fisher information, ''minimizing'' the ''variance'' corresponds to ''maximizing'' the ''information''.

When the [[Linear model|linear]] (or [[nonlinear regression|linearized]]) [[statistical model]] has several [[parameter]]s, the [[Expected value|mean]] of the parameter estimator is a [[column vector|vector]] and its [[covariance matrix|variance]] is a [[Matrix (mathematics)|matrix]]. The inverse of the variance matrix is called the "information matrix". Because the variance of the estimator of a parameter vector is a matrix, the problem of "minimizing the variance" is complicated. Using [[statistical theory]], statisticians compress the  information-matrix using real-valued [[summary statistics]]; being real-valued functions, these "information criteria" can be maximized.

Traditionally, statisticians have evaluated estimators and designs by considering some [[summary statistics|summary statistic]] of the covariance matrix (of an unbiased estimator), usually with positive real values (like the [[determinant]] or [[matrix trace]]). Working with positive real numbers brings several advantages: If the estimator of a single parameter has a positive variance, then the variance and the Fisher information are both positive real numbers; hence they are members of the convex cone of nonnegative real numbers (whose nonzero members have reciprocals in this same cone).
For several parameters, the covariance matrices and information matrices are elements of the convex cone of nonnegative-definite symmetric matrices in a [[partial order|partially]] [[ordered vector space]], under the [[Charles Loewner|Loewner]] (Löwner) order. This cone is closed under matrix addition and inversion, as well as under the multiplication of positive real numbers and matrices. An exposition of matrix theory and Loewner order appears in Pukelsheim.&lt;ref&gt;{{cite book |first=Friedrick |last=Pukelsheim |title=Optimal Design of Experiments |location=New York |publisher=Wiley |year=1993 |isbn=0-471-61971-X }}&lt;/ref&gt;

The traditional optimality criteria are the [[information]] matrix's invariants, in the sense of [[invariant theory]]; algebraically, the traditional optimality criteria are [[Functional (mathematics)|functionals]] of the [[eigenvalue]]s of the (Fisher) information matrix (see [[optimal design]]).

===Jeffreys prior in Bayesian statistics===
In [[Bayesian statistics]], the Fisher information is used to calculate the [[Jeffreys prior]], which is a standard, non-informative prior for continuous distribution parameters.&lt;ref&gt;{{cite book |title=Bayesian Theory |first=Jose M. |last=Bernardo |first2=Adrian F. M. |last2=Smith |location=New York |publisher=John Wiley &amp; Sons |year=1994 |isbn=0-471-92416-4 }}&lt;/ref&gt;

===Computational neuroscience===
The Fisher information has been used to find bounds on the accuracy of neural codes. In that case, ''X'' is typically the joint responses of many neurons representing a low dimensional variable ''θ'' (such as a stimulus parameter). In particular the role of correlations in the noise of the neural responses has been studied.&lt;ref&gt;Abbott, Larry F., and Peter Dayan. "The effect of correlated variability on the accuracy of a population code." Neural computation 11.1 (1999): 91-101.&lt;/ref&gt;

===Derivation of physical laws===
Fisher information plays a central role in a controversial principle put forward by [[B. Roy Frieden|Frieden]] as the basis of physical laws, a claim that has been disputed.&lt;ref&gt;{{cite book|first=R. F.|last=Streater|title=Lost Causes in and beyond Physics|publisher=Springer|year=2007|isbn=3-540-36581-8|page=69}}&lt;/ref&gt;

=== Machine learning===
The Fisher information is used in machine learning techniques such as [[elastic weight consolidation]],&lt;ref&gt;{{Cite journal|last=Kirkpatrick|first=James|last2=Pascanu|first2=Razvan|last3=Rabinowitz|first3=Neil|last4=Veness|first4=Joel|last5=Desjardins|first5=Guillaume|last6=Rusu|first6=Andrei A.|last7=Milan|first7=Kieran|last8=Quan|first8=John|last9=Ramalho|first9=Tiago|date=2017-03-28|title=Overcoming catastrophic forgetting in neural networks|url=http://www.pnas.org/content/114/13/3521|journal=Proceedings of the National Academy of Sciences|language=en|volume=114|issue=13|pages=3521–3526|doi=10.1073/pnas.1611835114|issn=0027-8424|pmid=28292907|pmc=5380101}}&lt;/ref&gt; which reduces [[catastrophic interference|catastrophic forgetting]] in [[artificial neural networks]].

==Relation to relative entropy==
{{See also|Fisher information metric}}
Fisher information is related to [[relative entropy]].&lt;ref&gt;[https://books.google.com/books?id=gqI-pAP2JZ8C&amp;pg=PA87 Gourieroux &amp; Montfort (1995), page 87]&lt;/ref&gt; Consider a family of probability distributions &lt;math&gt;f(x; \theta)&lt;/math&gt; where &lt;math&gt;\theta&lt;/math&gt; is a parameter which lies in a range of values. Then the relative entropy, or [[Kullback–Leibler divergence]], between two distributions in the family can be written as
:&lt;math&gt;
D(\theta\|\theta') = \int f(x; \theta)\log\frac{f(x;\theta)}{f(x; \theta')} dx = \int f(x; \theta)\left(\log f(x;\theta) - \log f(x; \theta')\right) dx,
&lt;/math&gt;
while the Fisher information matrix is:
:&lt;math&gt;
[\mathcal{I}(\theta)]_{ij} = \left(\frac{\partial^2}{\partial\theta'_i \partial\theta'_j}D(\theta\|\theta')\right)_{\theta'=\theta} = -\int f(x; \theta) \frac{\partial^2 \log f(x;\theta)}{\partial\theta_i \partial\theta_j}dx.
&lt;/math&gt;

If &lt;math&gt;\theta&lt;/math&gt; is fixed, then the relative entropy between two distributions of the same family is minimized at &lt;math&gt;\theta'=\theta&lt;/math&gt;. For &lt;math&gt;\theta'&lt;/math&gt; close to &lt;math&gt;\theta&lt;/math&gt;, one may expand the previous expression in a series up to second order:

:&lt;math&gt;
D(\theta\|\theta') = \frac{1}{2}(\theta'-\theta)^\top\underbrace{\left(\frac{\partial^2}{\partial\theta'_i \,  \partial \theta'_j} D(\theta\|\theta')\right)_{\theta'=\theta}}_{\text{Fisher info.}}(\theta'-\theta)+\cdots
&lt;/math&gt;

Thus the Fisher information represents the [[curvature]] of the relative entropy.

Schervish (1995: &amp;sect;2.3) says the following.
{{quote| One advantage Kullback-Leibler information has over Fisher information is that it is not affected by changes in parameterization. Another advantage is that Kullback-Leibler information can be used even if the distributions under consideration are not all members of a parametric family.
...&lt;br&gt;
Another advantage to Kullback-Leibler information is that no smoothness
conditions on the densities &amp;hellip; are needed.
}}

==History==
The Fisher information was discussed by several early statisticians, notably [[Francis Ysidro Edgeworth|F. Y. Edgeworth]].&lt;ref&gt;Savage (1976)&lt;/ref&gt; For example, Savage&lt;ref&gt;Savage(1976), page 156&lt;/ref&gt; says: "In it [Fisher information], he [Fisher] was to some extent anticipated (Edgeworth 1908–9 esp. 502, 507–8, 662, 677–8, 82–5 and references he [Edgeworth] cites including Pearson and Filon 1898 [. . .])."
There are a number of early historical sources&lt;ref&gt;Edgeworth (September 1908, December 1908)&lt;/ref&gt;
and a number of reviews of this early work.&lt;ref&gt;Pratt (1976)&lt;/ref&gt;&lt;ref&gt;Stigler (1978, 1986, 1999)&lt;/ref&gt;&lt;ref&gt;Hald (1998, 1999)&lt;/ref&gt;

==See also==
*[[Observed information]]
*[[Fisher information metric]]
*[[Formation matrix]]
*[[Information geometry]]
*[[Jeffreys prior]]
*[[Cramér–Rao bound]]

Other measures employed in [[information theory]]:
*[[Entropy (information theory)]]
*[[Kullback–Leibler divergence]]
*[[Self-information]]

==Notes==
{{Reflist|30em}}

==References==

* {{cite journal|doi=10.2307/2339461 | authorlink=Francis Ysidro Edgeworth|first1=F. Y.|last1= Edgeworth | title=On the Probable Errors of Frequency-Constants|jstor=2339461| journal=[[Journal of the Royal Statistical Society]]| volume=71| issue=2 |date=Jun 1908|pages=381–397}}
* {{cite journal|doi=10.2307/2339293| authorlink=Francis Ysidro Edgeworth|first1=F. Y.|last1= Edgeworth | title=On the Probable Errors of Frequency-Constants (Contd.) |jstor=2339293| journal=[[Journal of the Royal Statistical Society]]| volume=71| issue=3 |date=Sep 1908|pages=499–512}}
* {{cite journal|doi=10.2307/2339378| authorlink=Francis Ysidro Edgeworth|first1=F. Y.|last1= Edgeworth | title=On the Probable Errors of Frequency-Constants (Contd.) |jstor=2339378| journal=[[Journal of the Royal Statistical Society]]| volume=71| issue=4 |date=Dec 1908|pages=651–678}}
* [[B. Roy Frieden|Frieden, B. R.]] (2004) ''Science from Fisher Information: A Unification''. Cambridge Univ. Press. {{ISBN|0-521-00911-1}}.
* {{cite journal|doi=10.1103/PhysRevE.88.042144|title=Principle of maximum Fisher information from Hardy's axioms applied to statistical systems|journal=Physical Review E|volume=88|issue=4|year=2013|last1=Frieden|first1=B. Roy|last2=Gatenby|first2=Robert A.|arxiv=1405.0007|bibcode=2013PhRvE..88d2144F}}
* {{cite journal | title=On the History of Maximum Likelihood in Relation to Inverse Probability and Least Squares| author= Hald, A. |journal=[[Statistical Science]] |volume= 14| issue=2 |date=May 1999 | pages =214–222 |jstor=2676741 | doi=10.1214/ss/1009212248}}
* {{Cite book| author=Hald, A. |year=1998| title=A History of Mathematical Statistics from 1750 to 1930| publisher=Wiley| location=New York| isbn=0-471-17912-4}}
* {{Cite book
  | last = Lehmann
  | first = E. L.
  | authorlink= Erich Leo Lehmann
  |author2=Casella, G.
  | title = Theory of Point Estimation
  | year = 1998
  | publisher = Springer
  | isbn = 0-387-98502-6
  | edition= 2nd
}}
* {{Cite book
|first=Lucien
|last=Le Cam
|authorlink=Lucien Le Cam
|title = Asymptotic Methods in Statistical Decision Theory
|year = 1986
|publisher = Springer-Verlag
|isbn=0-387-96307-3
}}
* {{cite journal |doi=10.1214/aos/1176343457 |title=F. Y. Edgeworth and R. A. Fisher on the Efficiency of Maximum Likelihood Estimation | author=Pratt, John W.| journal=[[Annals of Statistics]]| volume=4| issue=3 |date=May 1976|pages=501–514 |jstor=2958222}}
* {{cite journal|doi=10.1214/aos/1176343456| author= Savage, L. J. |authorlink=Leonard J. Savage |title=On Rereading R. A. Fisher | journal=[[Annals of Statistics]] | volume=4  | issue=3 |date=May 1976 |pages=441–500 |jstor=2958221}}
*{{Cite book
| last = Schervish
| first = Mark J.
| title = Theory of Statistics
| publisher = Springer
| year = 1995
| location = New York
| isbn = 0-387-94546-6
}}
* {{Cite book|author= Stigler, S. M. |authorlink=Stephen Stigler|title=The History of Statistics: The Measurement of Uncertainty before 1900|year=1986| isbn=0-674-40340-1|publisher=Harvard University Press}}{{page needed|date=February 2012}}
* {{cite journal |doi=10.2307/2344804 |title=[[Francis Ysidro Edgeworth]], Statistician| author= Stigler, S. M. |authorlink=Stephen Stigler |jstor=2344804|journal= Journal of the Royal Statistical Society, Series A| volume=141 |issue= 3 |year= 1978 | pages =287–322 }}
* {{Cite book|author= Stigler, S. M.|authorlink= Stephen Stigler|title=Statistics on the Table: The History of Statistical Concepts and Methods|year=1999| isbn=0-674-83601-4|publisher=Harvard University Press}} {{page needed|date=February 2012}}
*{{Cite book
| last = Van Trees
| first = H. L.
| title = Detection, Estimation, and Modulation Theory, Part I
| publisher = Wiley
| year = 1968
| location = New York
| isbn = 0-471-09517-6
}}

{{DEFAULTSORT:Fisher Information}}
[[Category:Estimation theory]]
[[Category:Information theory]]
[[Category:Design of experiments]]</text>
      <sha1>iprco3ow5xrvrlxadiooe5w7eypqqk1</sha1>
    </revision>
  </page>
  <page>
    <title>Fisher–Tippett–Gnedenko theorem</title>
    <ns>0</ns>
    <id>20962073</id>
    <revision>
      <id>758211034</id>
      <parentid>716444332</parentid>
      <timestamp>2017-01-04T03:05:46Z</timestamp>
      <contributor>
        <ip>66.39.164.242</ip>
      </contributor>
      <comment>fixed indirect link; changed wording</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3478">{{About|the extreme value theorem in statistics|the result in calculus|extreme value theorem}}
[[File:Youngronaldfisher2.JPG|thumb|right|200px|Ronald Fisher]]
In [[statistics]], the '''Fisher–Tippett–Gnedenko theorem''' (also the '''Fisher–Tippett theorem''' or the '''extreme value theorem''') is a general result in [[extreme value theory]] regarding asymptotic distribution of extreme [[order statistic]]s. The maximum of a sample of [[iid]] [[random variable]]s after proper renormalization can only [[converges in distribution | converge in distribution]] to one of 3 possible distributions, the [[Gumbel distribution]], the [[Fréchet distribution]], or the [[Weibull distribution]]. Credit for the extreme value theorem (or convergence to types theorem) is given to [[Gnedenko]] (1948), previous versions were stated by [[Ronald Fisher]] and [[Leonard Henry Caleb Tippett]] in 1928 and [[Fréchet]] in 1927.

The role of the extremal types theorem for maxima is similar to that of [[central limit theorem]] for averages, except that the central limit theorem applies to the average of a sample from any distribution with finite variance, while the Fisher-Tippet-Gnedenko theorem only states that ''if'' the distribution of a normalized maximum converges, ''then'' the limit has to be one of a particular class of distributions. It does not state that the distribution of the normalized maximum does converge.

==Statement==
Let &lt;math&gt;X_1,X_2\ldots, X_n\ldots&lt;/math&gt; be a sequence of [[independent and identically-distributed random variables]], and &lt;math&gt;M_n=\max\{X_1,\ldots,X_n\}&lt;/math&gt;. If a sequence of pairs of real numbers &lt;math&gt;(a_n, b_n)&lt;/math&gt; exists such that each &lt;math&gt;a_n&gt;0&lt;/math&gt; and
&lt;math&gt; \lim_{n \to \infty}P\left(\frac{M_n-b_n}{a_n}\leq x\right) = F(x)&lt;/math&gt;,
where &lt;math&gt;F&lt;/math&gt; is a non degenerate distribution function, then the limit distribution &lt;math&gt;F&lt;/math&gt; belongs to either the [[Gumbel distribution|Gumbel]], the [[Fréchet distribution|Fréchet]] or the [[Weibull distribution|Weibull]] [[location-scale family|family]]. These can be grouped into the [[generalized extreme value distribution]].

==Conditions of convergence==
If ''G'' is the distribution function of ''X'', then ''M&lt;sub&gt;n&lt;/sub&gt;'' can be rescaled to [[Convergence of random variables#Convergence in distribution|converge in distribution]] to
*a Fréchet if and only if ''G'' (''x'') &lt; 1 for all real ''x'' and &lt;math&gt;\frac{1-G(tx)}{1-G(t)}\xrightarrow[t\to +\infty]{} x^{-\theta}, \quad x&gt;0&lt;/math&gt;. In this case, possible sequences are
::''b&lt;sub&gt;n&lt;/sub&gt;'' = 0 and &lt;math&gt;a_n=G^{-1}\left(1-\frac{1}{n}\right).&lt;/math&gt;
*a Weibull if and only if &lt;math&gt;\omega = \sup\{G&lt;1\} &lt;+\infty&lt;/math&gt; and &lt;math&gt;\frac{1-G(\omega+tx)}{1-G(\omega-t)}\xrightarrow[t\to 0^+]{} (-x)^\theta, \quad x&lt;0&lt;/math&gt;. In this case possible sequences are
::''b&lt;sub&gt;n&lt;/sub&gt;'' = ω and &lt;math&gt;a_n=\omega - G^{-1}\left(1-\frac{1}{n}\right).&lt;/math&gt;

Convergence conditions for the Gumbel distribution are more involved.

==See also==
* [[Extreme value theory]]
* [[Gumbel distribution]]
* [[Generalized extreme value distribution]]
* [[Pickands–Balkema–de Haan theorem]]

==References==

*R. A. Fisher, The Genetical Theory of Natural Selection, Oxford University Press, Oxford, 1930.
{{Unreferenced|date=March 2011}}

{{DEFAULTSORT:Fisher-Tippett-Gnedenko theorem}}
[[Category:Statistical theorems]]
[[Category:Extreme value data]]
[[Category:Tails of probability distributions]]


{{statistics-stub}}</text>
      <sha1>ofk1bs1rv2ltom6d6yjs3rx5zwowt66</sha1>
    </revision>
  </page>
  <page>
    <title>Fractional part</title>
    <ns>0</ns>
    <id>501532</id>
    <revision>
      <id>870962129</id>
      <parentid>870962118</parentid>
      <timestamp>2018-11-28T02:06:56Z</timestamp>
      <contributor>
        <username>GorillaWarfare</username>
        <id>4968133</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/2600:100C:B010:B1F:1D3B:56ED:D0C7:1ED2|2600:100C:B010:B1F:1D3B:56ED:D0C7:1ED2]] ([[User talk:2600:100C:B010:B1F:1D3B:56ED:D0C7:1ED2|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3959">The '''fractional part''' or '''decimal part'''&lt;ref&gt;{{cite web|url=https://en.oxforddictionaries.com/definition/decimal_part|title=Decimal part|publisher=[[OxfordDictionaries.com]]|accessdate=2018-02-15}}&lt;/ref&gt; of a non‐negative real number &lt;math&gt;x&lt;/math&gt; is the excess beyond that number's [[integer part]]. If the latter is defined as the largest integer not greater than ''x'', called [[floor (mathematics)|floor]] of ''x'' or &lt;math&gt;\lfloor x\rfloor&lt;/math&gt;, its fractional part can be written as: 

:&lt;math&gt;\operatorname{frac} (x)=x - \lfloor x \rfloor,\; x &gt; 0&lt;/math&gt;.

For a [[positive number|positive]] number written in a conventional [[positional numeral system]] (such as [[binary numeral system|binary]] or [[decimal]]), its fractional part hence corresponds to the digits appearing after the [[radix point]].

==For negative numbers==
However, in case of negative numbers, there are various conflicting ways to extend the fractional part function to them: It is either defined in the same way as for positive numbers, i.e. by &lt;math&gt;\operatorname{frac} (x)=x-\lfloor x \rfloor&lt;/math&gt; {{harv|Graham|Knuth|Patashnik|1992}},&lt;ref&gt;{{citation | title=Concrete mathematics: a foundation for computer science | first1=Ronald L. | last1=Graham | authorlink1=Ronald Graham | first2=Donald E. | last2=Knuth | authorlink2=Donald Knuth | first3=Oren | last3=Patashnik | authorlink3=Oren Patashnik | publisher=Addison-Wesley | isbn=0-201-14236-8 | year=1992 | page=70 }}&lt;/ref&gt; or as the part of the number to the right of the radix point, &lt;math&gt;\operatorname{frac} (x)=|x|-\lfloor |x| \rfloor&lt;/math&gt; {{harv|Daintith|2004}},&lt;ref&gt;{{cite book|title=A Dictionary of Computing|author=John Daintith|date=2004|publisher=Oxford University Press}}&lt;/ref&gt; finally, by the [[odd function]] &lt;ref&gt;[http://mathworld.wolfram.com/FractionalPart.html Weisstein, Eric W. "Fractional Part." From MathWorld--A Wolfram Web Resource]&lt;/ref&gt; 

:&lt;math&gt;\operatorname{frac} (x)=\begin{cases}
x - \lfloor x \rfloor &amp; x \ge 0 \\
x - \lceil x \rceil &amp; x &lt; 0
\end{cases}&lt;/math&gt; 

with &lt;math&gt; \lceil x \rceil&lt;/math&gt; as the smallest integer not less than ''x'', also called the [[ceiling function|ceiling]] of ''x''. By consequence, we may get, for example, three different values for the fractional part of just one x: let it be −1.3, its fractional part will be 0.7 according to the first definition, 0.3 according to the second definition, and −0.3 according to the third definition, whose result can also be obtained in a straightforward way by
:&lt;math&gt;\operatorname{frac} (x)= x - \lfloor |x| \rfloor \cdot \sgn(x)&lt;/math&gt;.

==Unique decomposition into integer and fractional parts==
Under the first definition all [[real number]]s can be written in the form &lt;math&gt;n+r&lt;/math&gt;, where &lt;math&gt;n&lt;/math&gt; is the number to the left of the [[radix point]], and the remaining fractional part &lt;math&gt;r&lt;/math&gt; is a nonnegative real number less than one. If &lt;math&gt;x&lt;/math&gt; is a positive [[rational number]], then the fractional part of &lt;math&gt;x&lt;/math&gt; can be expressed in the form &lt;math&gt;p/q&lt;/math&gt;, where &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; are integers and &lt;math&gt;0 \le p &lt; q&lt;/math&gt;. For example, if ''x''&amp;#8239;=&amp;#8239;1.05, then the fractional part of ''x'' is 0.05 and can be expressed as 5&amp;#8239;/&amp;#8239;100&amp;#8239;=&amp;#8239;1&amp;#8239;/&amp;#8239;20.

==Relation to continued fractions==
Every real number can be essentially uniquely represented as a [[continued fraction]], namely as the sum of its integer part and the [[reciprocal (mathematics)|reciprocal]] of its fractional part which is written as the sum of ''its'' integer part and the reciprocal of ''its'' fractional part, and so on.

==See also==
* [[Floor and ceiling functions]], the main article on fractional parts
* [[Equidistributed sequence]]
* [[One-parameter group]]
* [[Pisot–Vijayaraghavan number]]
* [[Significand]]
* [[Quotient space (linear algebra)]]

==References==
{{Reflist}}

[[Category:Arithmetic]]
[[Category:Unary operations]]</text>
      <sha1>43ki06my5qivnh1jzbop9fy3w9b4s41</sha1>
    </revision>
  </page>
  <page>
    <title>Further Mathematics</title>
    <ns>0</ns>
    <id>1362593</id>
    <revision>
      <id>852985814</id>
      <parentid>852985763</parentid>
      <timestamp>2018-08-01T17:31:46Z</timestamp>
      <contributor>
        <ip>146.199.207.217</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6598">'''Further Mathematics''' is the title given to a number of advanced [[secondary education|secondary]] [[mathematics]] courses. Higher and Further Mathematics may also refer to any of several advanced mathematics courses at many institutions. It thought to be a course of high-calibre as compared to the standard [[Advanced Level (UK)|AS-Level]] mathematics course.

In the United Kingdom, Further Mathematics describes a course studied in addition to the standard mathematics [[Advanced Level (UK)|AS-Level]] and [[Advanced Level (UK)|A-Level]] courses. In [[Victoria (Australia)|Victoria]], Australia it describes a course delivered as part of the [[Victorian Certificate of Education]]. See the section on Victoria for a more detailed explanation. Globally, it describes a course studied in addition to GCE AS-Level and A-Level Mathematics, or one delivered as part of the [[International Baccalaureate Diploma]].

==United Kingdom==
===Background===
A qualification in Further Mathematics involves studying both [[pure mathematics|pure]] and [[applied mathematics|applied]] modules.  Whilst the pure modules - formerly known as Pure 4-6 (or Core 4-6), now known as Further Pure 1-3 (4 exists for the [[Assessment and Qualifications Alliance|AQA]] board) - build on knowledge from the core mathematics modules, the applied modules may start from first principles. 

To achieve an A level in Further Maths, candidates must study six modules which have not already been used for their Maths A level. These six modules must consist of FP1, at least one of FP2 or FP3, and 4 other modules.
With regard to Mathematics degrees, most universities do not require Further Mathematics, and may incorporate foundation math modules or offer "catch-up" classes covering any additional content. Exceptions are the [[University of Warwick]],&lt;ref&gt;http://www2.warwick.ac.uk/fac/sci/maths/admissions/ug/offer/&lt;/ref&gt; the [[University of Cambridge]] which requires Further Mathematics to at least AS level; University College London requires or recommends an A2 in Further Maths for its maths courses; Imperial College requires an A in A level Further Maths while other universities may recommend it or may promise lower offers in return. Some schools and colleges may not offer Further mathematics but online resources are available &lt;ref&gt;[http://www.economist.com/world/britain/displaystory.cfm?story_id=7950110]&lt;/ref&gt;
Although the subject has about 60% of its cohort obtaining "A" grades,&lt;ref&gt;http://news.bbc.co.uk/1/shared/bsp/hi/education/09/exam_results/a_levels/html/mathematics_further.stm&lt;/ref&gt; students choosing the subject are assumed to be more able in mathematics. 

Some medicine courses do not count maths and further maths as separate subjects for the purposes of making offers&lt;ref&gt;{{cite web|title=Medical school a-level requirements|url=http://www.thestudentroom.co.uk/wiki/Medical_School_A_Level_Requirements|website=The Student Room}}&lt;/ref&gt; due to the perceived overlap in content and the potentially narrow education a candidate with maths, further maths and just one other subject may have.

==Australia (Victoria)==
In contrast with other Further Mathematics courses, Further Maths as part of the [[Victorian Certificate of Education|VCE]] is the easiest level of mathematics. Any student wishing to undertake tertiary studies in areas such as Science, Engineering, Commerce, Economics, and some Information Technology courses, must undertake one or both of the other two VCE maths subjects- Mathematical Methods or Specialist Mathematics. The Further Mathematics syllabus in VCE consists of three core modules, which all students undertake, plus two modules chosen by the student (or usually by the school or teacher) from a list of four. The core modules are Univariate Data, Bivariate Data, Time Series, Number Patterns and Business-Related Mathematics. The optional modules are  Geometry and Trigonometry, Graphs and Relations, Networks and Decision Mathematics, or Matrices.
See also: [[Mickey Mouse degrees|Mickey Mouse]]

==Singapore==
Further Mathematics is available as a second and higher mathematics course at A Level (now H2), in addition to the Mathematics course at A Level. Students can offer this subject if they have A2 and better in 'O' Level Mathematics and Additional Mathematics, depending on the school. &lt;ref&gt;[http://www.moe.gov.sg/media/speeches/2015/07/24/speech-by-mr-heng-swee-keat-at-the-closing-ceremony-of-the-national-engineers-day-2015.php]&lt;/ref&gt;

==International Baccalaureate Diploma==
Further Mathematics, as studied within the International Baccalaureate Diploma Programme, is a Higher Level (HL) course that can be taken in conjunction with [[IB Group 5 subjects|Mathematics HL]] or on its own. It consists of studying all four of the options in Mathematics HL, plus two additional topics.

Topics studied in Further Mathematics include:&lt;ref&gt;{{cite book|title=IB DP Further mathematics HL guide (first examinations 2014)|date=June 2012|publisher=International Baccalaureate Organization|location=Cardiff, Wales, United Kingdom|accessdate=20 April 2014|format=Electronic (PDF)}}&lt;/ref&gt;
*'''Topic 1''' - [[Linear algebra]] - studies on [[Matrix (mathematics)|matrices]], [[vector space]]s, linear and geometric [[Transformation (function)|transformations]]
*'''Topic 2''' - [[Geometry]] - closer look on [[triangle]]s, [[circle]]s and [[conic section]]s
*'''Topic 3''' - [[Statistics]] and [[probability]] - the [[Geometric distribution|geometric]] and [[Negative binomial distribution|negative binomial]] distributions, [[Bias of an estimator|unbiased estimators]], [[statistical hypothesis testing]] and an introduction to [[Joint probability distribution|bivariate distributions]]
*'''Topic 4''' - [[Set (mathematics)|Sets]], [[Binary relation|relations]] and [[Group (mathematics)|groups]] - [[algebra of sets]], [[ordered pair]]s, [[binary operation]]s and [[group homomorphism]]
*'''Topic 5''' - [[Calculus]] - infinite [[sequence]]s and [[Series (mathematics)|series]], [[Limit (mathematics)|limit]]s, [[improper integral]]s and various first-order ordinary [[differential equation]]s
*'''Topic 6''' - [[Discrete mathematics]] - complete [[mathematical induction]], linear [[Diophantine equation]]s, [[Fermat's little theorem]], [[route inspection problem]] and [[recurrence relation]]s

== See also ==
* [[Additional Mathematics]]

== References ==
{{reflist|2}}

==External links==
*[http://www.furthermaths.org.uk/ The Further Mathematics Support Programme]
*[http://www.mechanics-online.com Mechanics M1 Material]

[[Category:Mathematics education]]</text>
      <sha1>0zh3naxqyerxtilsguwbiei2orevlb1</sha1>
    </revision>
  </page>
  <page>
    <title>Ideal tasks</title>
    <ns>0</ns>
    <id>13028195</id>
    <revision>
      <id>826038750</id>
      <parentid>826038705</parentid>
      <timestamp>2018-02-16T21:14:05Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Psychology]]; added [[Category:Cognitive psychology]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1660">'''Ideal tasks''' arise during [[task analysis]].  Ideal tasks are different from real tasks.  They are ideals in the [[Plato]]nic sense of a [[circle]] being an ideal whereas a drawn circle is flawed and real.  The study of theoretically best or “mathematically ideal” tasks (Green &amp; Swets, 1966), has been the basis of the branch of [[stimulus control]] in psychology called [[Psychophysics]] as well as being part of [[Artificial Intelligence]] (e. g. Goel &amp; Chandrasekaran, 1992).  Such studies include the instantiation of such ideal tasks in the real world.  The notion of the ideal task has also played an important role in [[information theory]].  Tasks are defined as sequences of contingencies, each presenting stimuli and requiring an action or a sequence of actions to occur in some non-arbitrary fashion.  These contingencies may not only provide stimuli that require the discrimination of relations among actions and events but among task actions themselves.  Again, Task actions, E, are actions that are required to complete tasks.  Properties of tasks (usually the stimuli, or the relationship among stimuli and actions) are varied, and responses to them can be measured and analyzed.

==References==

*  Goel, A., &amp; Chandrasekaran, B.  (1992).  Case-Based Design: A Task Analysis.  In C. Tong and D. Sriram (editors), ''Artificial intelligence approaches to engineering design, Volume II: Innovative design'' (pp.&amp;nbsp;165–184).  San Diego: Academic Press.
*  Green, D. M. &amp; Swets, J. A.  (1966).  ''Signal Detection Theory and Psychophysics''.  Huntington, NY: Krieger.

[[Category:Cognitive psychology]]
[[Category:Information theory]]</text>
      <sha1>1u2a0vvb40xi3h2z34jjto4kf6nfdr4</sha1>
    </revision>
  </page>
  <page>
    <title>Integer triangle</title>
    <ns>0</ns>
    <id>27430123</id>
    <revision>
      <id>863794531</id>
      <parentid>863113626</parentid>
      <timestamp>2018-10-13T02:36:35Z</timestamp>
      <contributor>
        <username>Seahawk01</username>
        <id>34873291</id>
      </contributor>
      <minor/>
      <comment>added category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="37608">[[Image:Triangle-heronian.svg|thumb|right|A Heronian triangle with sidelengths ''c'', ''e'' and ''b''&amp;nbsp;+&amp;nbsp;''d'', and height ''a'', all integers.]]

An '''integer triangle''' or '''integral triangle''' is a [[triangle]] all of whose sides have lengths that are integers.  A '''rational triangle''' can be defined as one having all sides with rational length; any such rational triangle can be integrally rescaled (can have all sides multiplied by the same integer, namely a common multiple of their denominators) to obtain an integer triangle, so there is no substantive difference between integer triangles and rational triangles in this sense. Note however, that other definitions of the term "rational triangle" also exist: In 1914 Carmichael&lt;ref&gt;{{cite book |last=Carmichael |first=R. D. |origyear=1914 |chapter=Diophantine Analysis'' |pages=11–13 |editor=R. D. Carmichael |year=1959 |title=The Theory of Numbers and Diophantine Analysis |publisher=Dover}}&lt;/ref&gt; used the term in the sense that we today use the term [[Heronian triangle]]; Somos&lt;ref name=Somos&gt;Somos, M., "Rational triangles", http://somos.crg4.com/rattri.html&lt;/ref&gt; uses it to refer to triangles whose ratios of sides are rational;  Conway and Guy &lt;ref name=CG&gt;Conway, J. H., and Guy, R. K., "The only rational triangle", in ''The Book of Numbers'', 1996, Springer-Verlag, pp. 201 and 228–239.&lt;/ref&gt; define a rational triangle as one with rational sides and rational angles measured in degrees—in which case the only rational triangle is the rational-sided equilateral triangle.

There are various general properties for an integer triangle, given in the first section below. All other sections refer to classes of integer triangles with specific properties.

==General properties for an integer triangle==

===Integer triangles with given perimeter===
Any triple of positive integers can serve as the side lengths of an integer triangle as long as it satisfies the triangle inequality: the longest side is shorter than the sum of the other two sides. Each such triple defines an integer triangle that is unique up to congruence. So the number of integer triangles (up to congruence) with perimeter ''p'' is the number of [[Partition (number theory)|partitions]] of ''p'' into three positive parts that satisfy the triangle inequality. This is the integer closest to {{frac|''p''&lt;sup&gt;2&lt;/sup&gt;|48|}} when ''p'' is even and to {{frac|(''p'' + 3)&lt;sup&gt;2&lt;/sup&gt;|48|}} when ''p'' is odd.&lt;ref name=Jenkyns&gt;Tom Jenkyns and Eric Muller, Triangular Triples from Ceilings to Floors, American Mathematical Monthly 107:7 (August 2000) 634–639&lt;/ref&gt;&lt;ref&gt;Ross Honsberger, ''Mathematical Gems III'', pp. 39–37&lt;/ref&gt; It also means that the number of integer triangles with even numbered perimeters ''p''&amp;nbsp;=&amp;nbsp;2''n'' is the same as the number of integer triangles with odd numbered perimeters ''p''&amp;nbsp;=&amp;nbsp;2''n''&amp;nbsp;−&amp;nbsp;3.  Thus there is no integer triangle with perimeter 1, 2 or 4, one with perimeter 3, 5, 6 or 8, and two with perimeter 7 or 10. The sequence of the number of integer triangles with perimeter ''p'', starting at ''p'' = 1, is:

:0, 0, 1, 0, 1, 1, 2, 1, 3, 2, 4, 3, 5, 4, 7, 5, 8, 7, 10, 8 ... {{OEIS|A005044}}

===Integer triangles with given largest side===
The number of integer triangles (up to congruence) with given largest side ''c'' and integer triple (''a'',&amp;nbsp;''b'',&amp;nbsp;''c'') is the number of integer triples such that ''a''&amp;nbsp;+&amp;nbsp;''b''&amp;nbsp;&gt;&amp;nbsp;''c'' and ''a''&amp;nbsp;&amp;le;&amp;nbsp;''b''&amp;nbsp;&amp;le;&amp;nbsp;''c''. This is the integer value Ceiling[{{frac|(''c''&amp;nbsp;+&amp;nbsp;1)|2}}]&amp;nbsp;*&amp;nbsp;Floor[{{frac|(''c''&amp;nbsp;+&amp;nbsp;1)|2}}].&lt;ref name=Jenkyns/&gt;&amp;nbsp;Alternatively, for ''c'' even it is the double [[triangular number]] {{frac|''c''|2}}({{frac|''c''|2}}&amp;nbsp;+&amp;nbsp;1) and for ''c'' odd it is the [[square number|square]] {{frac|(''c''&amp;nbsp;+&amp;nbsp;1)&lt;sup&gt;2&lt;/sup&gt;|4}}.&amp;nbsp;It also means that the number of integer triangles with greatest side ''c'' exceeds the number of integer triangles with greatest side ''c''&amp;minus;2 by ''c''. The sequence of the number of non-congruent integer triangles with largest side ''c'', starting at ''c''&amp;nbsp;=&amp;nbsp;1, is:
:1, 2, 4, 6, 9, 12, 16, 20, 25, 30, 36, 42, 49, 56, 64, 72, 81, 90 ... {{OEIS|A002620}}

The number of integer triangles (up to congruence) with given largest side ''c'' and integer triple (''a'',&amp;nbsp;''b'',&amp;nbsp;''c'') that lie on or within a semicircle of diameter ''c'' is the number of integer triples such that ''a''&amp;nbsp;+&amp;nbsp;''b''&amp;nbsp;&gt;&amp;nbsp;''c''&amp;nbsp;,&amp;nbsp;''a&lt;sup&gt;2&lt;/sup&gt;''&amp;nbsp;+&amp;nbsp;''b''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;&amp;le;&amp;nbsp;''c''&lt;sup&gt;2&lt;/sup&gt; and ''a''&amp;nbsp;&amp;le;&amp;nbsp;''b''&amp;nbsp;&amp;le;&amp;nbsp;''c''. This is also the number of integer sided obtuse or right (non-acute) triangles with largest side ''c''. The sequence starting at ''c''&amp;nbsp;=&amp;nbsp;1, is:
:0, 0, 1, 1, 3, 4, 5, 7, 10, 13, 15, 17, 22, 25, 30, 33, 38, 42, 48 ... {{OEIS|A236384}}

Consequently, the difference between the two above sequences gives the number of acute integer sided triangles (up to congruence) with given largest side ''c''. The sequence starting at ''c''&amp;nbsp;=&amp;nbsp;1, is:
:1, 2, 3, 5, 6, 8, 11, 13, 15, 17, 21, 25, 27, 31, 34, 39, 43, 48, 52 ... {{OEIS|A247588}}

===Area of an integer triangle===
By [[Heron's formula]], if ''T'' is the area of a triangle whose sides have lengths ''a'', ''b'', and ''c'' then

:&lt;math&gt;4T = \sqrt{(a+b+c)(a+b-c)(a-b+c)(-a+b+c)}.&lt;/math&gt;

Since all the terms under the [[square root|radical]] on the right side of the formula are integers it follows that all integer triangles must have an integer value of ''16T&lt;sup&gt;2&lt;/sup&gt;'' and ''T&lt;sup&gt;2&lt;/sup&gt;'' will be rational.

===Angles of an integer triangle===

By the [[law of cosines]], every [[angle]] of an integer triangle has a [[rational number|rational]] [[cosine]].

If the angles of any triangle form an arithmetic progression then one of its angles must be 60°.&lt;ref name=Zelator/&gt; For integer triangles the remaining angles must also have rational cosines and a method of generating such triangles is given below. However, apart from the trivial case of an equilateral triangle there are no integer triangles whose angles form either a geometric or harmonic progression. This is because such angles have to be rational angles of the form {{frac|πp|q|}} with rational &amp;nbsp;0 &lt; {{frac|p|q|}} &lt; 1. But all the angles of integer triangles must have rational cosines and this will occur only when&amp;nbsp;{{frac|p|q|}}&amp;nbsp;=&amp;nbsp;{{frac|3|}}&amp;nbsp;&lt;ref&gt;{{cite journal |first=Jörg |last=Jahnel |title=When is the (Co)Sine of a Rational Angle equal to a rational number? |arxiv=1006.2938 |year=2010|bibcode=2010arXiv1006.2938J }}&lt;/ref&gt;{{rp|p.2}} i.e. the integer triangle is equilateral.

The square of each internal [[angle bisector]] of an integer triangle is rational, because the general triangle formula for the internal angle bisector of angle ''A'' is &lt;math&gt;\tfrac{2\sqrt{bcs(s-a)}}{b+c}&lt;/math&gt; where ''s'' is the [[semiperimeter]] (and likewise for the other angles' bisectors).

===Side split by an altitude===

Any [[Altitude (triangle)|altitude]] dropped from a vertex onto an opposite side or its extension will split that side or its extension into rational lengths.

===Medians===

The square of twice any [[median (geometry)|median]] of an integer triangle is an integer, because the general formula for the squared median ''m''&lt;sub&gt;a&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; to side ''a'' is &lt;math&gt;\tfrac{(2b^2+2c^2-a^2)}{4}&lt;/math&gt;, giving (2''m''&lt;sub&gt;a&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;2''b''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;2''c''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;''a''&lt;sup&gt;2&lt;/sup&gt; (and likewise for the medians to the other sides).

===Circumradius and inradius===

Because the square of the area of an integer triangle is rational, the square of its [[circumradius]] is also rational, as is the square of the [[inradius]].

The ratio of the inradius to the circumradius of an integer triangle is rational, equaling &lt;math&gt;\tfrac{4T^2}{sabc}&lt;/math&gt; for semiperimeter ''s'' and area ''T''.

The product of the inradius and the circumradius of an integer triangle is rational, equaling &lt;math&gt;\tfrac{abc}{2(a+b+c)}.&lt;/math&gt;

Thus the squared distance between the [[incenter]] and the [[circumcenter]] of an integer triangle, given by [[Euler's theorem in geometry|Euler's theorem]] as ''R&lt;sup&gt;2&lt;/sup&gt;&amp;minus;2Rr'', is rational.

==Heronian triangles==
{{Main article|Heronian triangle}}

All Heronian triangles can be placed on a lattice with each vertex at a lattice point.&lt;ref&gt; Yiu, P., “Heronian triangles are lattice triangles”, ''American Mathematical Monthly'' 108 (2001), 261–263.&lt;/ref&gt;

===General formula===

A Heronian triangle, also known as a '''Heron triangle''' or a '''Hero triangle''', is a triangle with integer sides and integer area.  Every Heronian triangle has sides proportional to&lt;ref&gt;Carmichael, R. D. ''The Theory of Numbers and Diophantine Analysis''. New York: Dover, 1952.&lt;/ref&gt;
:&lt;math&gt;a=n(m^{2}+k^{2}) \, &lt;/math&gt;
:&lt;math&gt;b=m(n^{2}+k^{2}) \, &lt;/math&gt;
:&lt;math&gt;c=(m+n)(mn-k^{2}) \, &lt;/math&gt;
:&lt;math&gt;\text{Semiperimeter}=mn(m+n) \, &lt;/math&gt;
:&lt;math&gt;\text{Area}=mnk(m+n)(mn-k^{2}) \, &lt;/math&gt;

for integers ''m'', ''n'' and ''k'' subject to the constraints:

:&lt;math&gt;\gcd{(m,n,k)}=1 \, &lt;/math&gt;
:&lt;math&gt;mn &gt; k^2 \ge m^2n/(2m+n) \, &lt;/math&gt;
:&lt;math&gt; m \ge n \ge 1 \,&lt;/math&gt;.

The proportionality factor is generally a rational &amp;nbsp;&lt;math&gt;\frac{p}{q}&lt;/math&gt;&amp;nbsp; where &amp;nbsp;&lt;math&gt;q=\gcd{(a,b,c)}&lt;/math&gt;&amp;nbsp; reduces the generated Heronian triangle to its primitive and &amp;nbsp;&lt;math&gt;p&lt;/math&gt;&amp;nbsp; scales up this primitive to the required size.

===Pythagorean triangles===

{{Main article|Pythagorean triple}}

A Pythagorean triangle is right angled and Heronian. Its three integer sides are known as a [[Pythagorean triple]] or '''Pythagorean triplet''' or '''Pythagorean triad'''.&lt;ref name="Sierpinski"&gt;Sierpiński, Wacław. ''Pythagorean Triangles'', Dover Publ., 2003 (orig. 1962).&lt;/ref&gt;  All Pythagorean triples &lt;math&gt;(a, b, c)&lt;/math&gt; with hypotenuse &lt;math&gt;c&lt;/math&gt; which are '''primitive''' (the sides having no common factor) can be generated by

:&lt;math&gt; a = m^2 - n^2, \, &lt;/math&gt;
:&lt;math&gt; b = 2mn, \, &lt;/math&gt;
:&lt;math&gt; c = m^2 + n^2, \, &lt;/math&gt;
:&lt;math&gt;\text{Semiperimeter}=m(m+n) \, &lt;/math&gt;
:&lt;math&gt;\text{Area}=mn(m^2-n^2) \, &lt;/math&gt;

where ''m'' and ''n'' are [[coprime]] integers and one of them is even with ''m''&amp;nbsp;&gt;&amp;nbsp;''n''.

Every even number greater than 2 can be the leg of a Pythagorean triangle (not necessarily primitive) because if the leg is given by &lt;math&gt;a=2m&lt;/math&gt; and we choose &lt;math&gt;b=(a/2)^2-1=m^2-1&lt;/math&gt; as the other leg then the hypotenuse is &lt;math&gt;c=m^2+1&lt;/math&gt;.&lt;ref name="pyth_tr_area"&gt;{{Cite OEIS|1=A009111|2=List of ordered areas of Pythagorean triangles|accessdate=2017-03-03}}&lt;/ref&gt; This is essentially the generation formula above with &lt;math&gt;n&lt;/math&gt; set to 1 and allowing &lt;math&gt;m&lt;/math&gt; to range from 2 to infinity.

====Pythagorean triangles with integer altitude from the hypotenuse====

There are no primitive Pythagorean triangles with integer altitude from the hypotenuse. This is because twice the area equals any base times the corresponding height: 2 times the area thus equals both ''ab'' and ''cd'' where ''d'' is the height from the hypotenuse ''c''. The three side lengths of a primitive triangle are coprime, so ''d''&amp;nbsp;=&amp;nbsp;{{Frac|ab|c|}} is in fully reduced form; since ''c'' cannot equal 1 for any primitive Pythagorean triangle, ''d'' cannot be an integer.

However, any Pythagorean triangle with legs ''x'',&amp;nbsp;''y'' and hypotenuse ''z'' can generate a Pythagorean triangle with an integer altitude, by scaling up the sides by the length of the hypotenuse ''z''. If ''d'' is the altitude, then the generated Pythagorean triangle with integer altitude is given by&lt;ref name="Richinik"&gt;Richinick, Jennifer, "The upside-down Pythagorean Theorem", ''Mathematical Gazette'' 92, July 2008, 313–317.&lt;/ref&gt;

:&lt;math&gt;(a,b,c,d)=(xz, yz, z^2, xy). \, &lt;/math&gt;

Consequently, all Pythagorean triangles with legs ''a'' and ''b'', hypotenuse ''c'', and integer altitude ''d'' from the hypotenuse, with gcd&amp;nbsp;(''a, b, c, d'')&amp;nbsp;=&amp;nbsp;1, which necessarily have both ''a''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''b''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;c&lt;sup&gt;2&lt;/sup&gt; and &lt;math&gt;\tfrac{1}{a^{2}}+\tfrac{1}{b^{2}}=\tfrac{1}{d^{2}}&lt;/math&gt;, are generated by&lt;ref&gt;Voles, Roger, "Integer solutions of ''a''&lt;sup&gt;−2&lt;/sup&gt;+''b''&lt;sup&gt;−2&lt;/sup&gt;=d&lt;sup&gt;−2&lt;/sup&gt;", ''Mathematical Gazette'' 83, July 1999, 269–271.&lt;/ref&gt;&lt;ref name="Richinik"/&gt;

:&lt;math&gt;a=(m^2-n^2)(m^2+n^2), \,&lt;/math&gt;

:&lt;math&gt;b=2mn(m^2+n^2), \,&lt;/math&gt;
 
:&lt;math&gt;c=(m^2+n^2)^2, \,&lt;/math&gt;
 
:&lt;math&gt;d=2mn(m^2-n^2), \,&lt;/math&gt;
 
:&lt;math&gt;\text{Semiperimeter}=m(m+n)(m^2+n^2) \, &lt;/math&gt;
 
:&lt;math&gt;\text{Area}=mn(m^2-n^2)(m^2+n^2)^2 \, &lt;/math&gt;
 
for coprime integers ''m'', ''n'' with ''m''&amp;nbsp;&gt;&amp;nbsp;''n''.

===Heronian triangles with sides in arithmetic progression===

A triangle with integer sides and integer area has sides in arithmetic progression if and only if&lt;ref name=Buchholz&gt;{{Cite journal |title=Heron Quadrilaterals with sides in Arithmetic or Geometric progression |last=Buchholz |first=R. H. |last2=MacDougall |first2=J. A. |journal=Bulletin of the Australian Mathematical Society |pages=263–269 |volume=59 |year=1999 |url=http://journals.cambridge.org/article_S0004972700032883}}&lt;/ref&gt; the sides are (''b'' – ''d'', ''b'', ''b'' + ''d''), where

:&lt;math&gt;b=2(m^2+3n^2)/g, \,&lt;/math&gt;

:&lt;math&gt;d=(m^2-3n^2)/g, \, &lt;/math&gt;

and where  ''g'' is the greatest common divisor of &lt;math&gt;m^2-3n^2,&lt;/math&gt; &lt;math&gt;2mn&lt;/math&gt;, and &lt;math&gt;m^2+3n^2.&lt;/math&gt;

===Heronian triangles with one angle equal to twice another===

All Heronian triangles with B=2A are generated by&lt;ref&gt;Mitchell, Douglas W., "Heron triangles with ∠B=2∠A", ''Mathematical Gazette'' 91, July 2007, 326–328.&lt;/ref&gt; either

:&lt;math&gt;a=\tfrac{k^2(s^2+r^2)^2}{4}, \, &lt;/math&gt;
:&lt;math&gt;b=\tfrac{k^2(s^4-r^4)}{2}, \, &lt;/math&gt;
:&lt;math&gt;c=\tfrac{k^2(3s^4-10s^2 r^2+3r^4)}{4} \, &lt;/math&gt;
:&lt;math&gt;\text{Area}=\tfrac{k^2 csr(s^2-r^2)}{2} \, &lt;/math&gt;

with integers ''k'', ''s'', ''r'' such that ''s''&lt;sup&gt;2&lt;/sup&gt; &gt; 3''r''&lt;sup&gt;2&lt;/sup&gt;, or

:&lt;math&gt;a=\tfrac{q^{2}(u^{2}+v^{2})^{2}}{4} \,&lt;/math&gt;,
:&lt;math&gt;b=q^{2}uv(u^{2}+v^{2}) \,&lt;/math&gt;,
:&lt;math&gt;c=\tfrac{q^{2}(14u^{2}v^{2}-u^{4}-v^{4})}{4} \, &lt;/math&gt;,
:&lt;math&gt;\text{Area}=\tfrac{q^{2}cuv(v^{2}-u^{2})}{2} \,&lt;/math&gt;,

with integers ''q'', ''u'', ''v'' such that ''v'' &gt; ''u''  and ''v''&lt;sup&gt;2&lt;/sup&gt; &lt; (7+4{{radic|3}})''u''&lt;sup&gt;2&lt;/sup&gt;.

No Heronian triangles with ''B''&amp;nbsp;=&amp;nbsp;2''A'' are isosceles or right triangles because all resulting angle combinations generate angles with non-rational sines, giving a non-rational area or side.

===Isosceles Heronian triangles===

All [[isosceles]] Heronian triangles are decomposable. They are formed by joining two congruent Pythagorean triangles along either of their common legs such that the equal sides of the isosceles triangle are the hypotenuses of the Pythagorean triangles, and the base of the isosceles triangle is twice the other Pythagorean leg. Consequently, every Pythagorean triangle is the building block for two isosceles Heronian triangles since the join can be along either leg.
All pairs of isosceles Heronian triangles are given by rational multiples of&lt;ref name=Sastry&gt;Sastry, K. R. S., [http://forumgeom.fau.edu/FG2005volume5/FG200515.pdf "Construction of Brahmagupta n-gons"], ''Forum Geometricorum'' 5 (2005): 119–126.&lt;/ref&gt;

:&lt;math&gt;a=2(u^2-v^2),&lt;/math&gt;
:&lt;math&gt;b=u^2+v^2,&lt;/math&gt;
:&lt;math&gt;c=u^2+v^2,&lt;/math&gt;

and

:&lt;math&gt;a=4uv,&lt;/math&gt;
:&lt;math&gt;b=u^2+v^2,&lt;/math&gt;
:&lt;math&gt;c=u^2+v^2,&lt;/math&gt;


for coprime integers ''u'' and ''v'' with ''u'' &gt; ''v'' and ''u'' + ''v'' odd.

===Heronian triangles whose perimeter is four times a prime===
It has been shown that a Heronian triangle whose perimeter is four times a prime is uniquely associated with the prime and that the prime is of the form &lt;math&gt;1\text{ or }3\text{ mod }8&lt;/math&gt;. &lt;ref&gt;Yiu, P., [https://cms.math.ca/crux/v24/n3/page175-177.pdf "CRUX, Problem 2331, Proposed by Paul Yiu"], ''Memorial University of Newfoundland'' (1998): 175-177&lt;/ref&gt;&lt;ref&gt;Yui, P. and Taylor, J. S., [http://dongthapvietnam.informe.com/blog/uploads/2012/10/cruxv25_1999.pdf "CRUX, Problem 2331, Solution"] ''Memorial University of Newfoundland'' (1999): 185-186&lt;/ref&gt; It is well known that such a prime &lt;math&gt;p&lt;/math&gt; can be uniquely partitioned into integers &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;n&lt;/math&gt; such that &lt;math&gt;p=m^2+2n^2&lt;/math&gt; (see [[Idoneal number|Euler's idoneal numbers]]). Furthermore, it has been shown that such Heronian triangles are primitive since the smallest side of the triangle has to be equal to the prime that is one quarter of its perimeter.

Consequently, all primitive Heronian triangles whose perimeter is four times a prime can be generated by
:&lt;math&gt;a=m^2+2n^2&lt;/math&gt;
:&lt;math&gt;b=m^2+4n^2&lt;/math&gt;
:&lt;math&gt;c=2(m^2+n^2)&lt;/math&gt;
:&lt;math&gt;\text{Semiperimeter}=2a=2(m^2+2n^2)&lt;/math&gt;
:&lt;math&gt;\text{Area}=2mn(m^2+2n^2)&lt;/math&gt;

for integers &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;n&lt;/math&gt; such that &lt;math&gt;m^2+2n^2&lt;/math&gt; is a prime.

Furthermore, the factorization of the area is &lt;math&gt;2mnp&lt;/math&gt; where &lt;math&gt;p=m^2+2n^2&lt;/math&gt; is prime. However the area of a Heronian triangle is always divisible by &lt;math&gt;6&lt;/math&gt;. This gives the result that apart from when &lt;math&gt;m=1&lt;/math&gt; and &lt;math&gt;n=1,&lt;/math&gt; which gives &lt;math&gt;p=3,&lt;/math&gt; all other parings of &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;n&lt;/math&gt; must have &lt;math&gt;m&lt;/math&gt; odd with only one of them divisible by &lt;math&gt;3&lt;/math&gt;.

===Heronian triangles with integer inradius and exradii===

There are infinitely many decomposable, and infinitely many indecomposable, primitive Heronian (non-Pythagorean) triangles with integer radii for the [[incircle]] and each [[excircle]].&lt;ref name=Zhou&gt;Li Zhou, “Primitive Heronian Triangles With Integer Inradius and Exradii”, ''Forum Geometricorum'' 18, 2018, pp. 71–77.&lt;/ref&gt;{{rp|Thms. 3 and 4}} A family of decomposible ones is given by
:&lt;math&gt;a= 4n^2, \quad \quad b=(2n+1)(2n^2 -2n+1),\quad \quad c=(2n-1)(2n^2 +2n+1),&lt;/math&gt;
::&lt;math&gt;r=2n-1, \quad \quad r_a=2n+1, \quad \quad r_b=2n^2, \quad \quad r_c=\text{Area}=2n^2(2n-1)(2n+1);&lt;/math&gt;
and a family of indecomposable ones is given by

:&lt;math&gt;a=5(5n^2 +n-1), \quad \quad b= (5n+3)(5n^2-4n+1), \quad \quad c= (5n-2)(5n^2 +6n+2), &lt;/math&gt;
::&lt;math&gt;r=5n-2, \quad \quad r_a=5n+3,\quad \quad r_b=5n^2+n-1, \quad\quad r_c=\text{Area}=(5n-2)(5n+3)(5n^2 +n-1).&lt;/math&gt;

===Heronian triangles as faces of a tetrahedron===

There exist [[tetrahedra]] having integer-valued [[volume]] and Heron triangles as [[face (geometry)|faces]]. One example has one edge of 896, the opposite edge of 190, and the other four edges of 1073; two faces have areas of 436800 and the other two have areas of 47120, while the volume is 62092800.&lt;ref&gt;[[Wacław Sierpiński]], ''Pythagorean Triangles'', Dover Publications, 2003 (orig. ed. 1962).&lt;/ref&gt;{{rp|p.107}}

===Heronian triangles in a 2D lattice===

A 2D [[Lattice graph|lattice]] is a regular array of isolated points where if any one point is chosen as the [[Cartesian coordinate system|Cartesian origin]] (0, 0), then all the other points are at (''x, y'') where ''x'' and ''y'' range over all positive and negative integers. A lattice triangle is any triangle drawn within a 2D lattice such that all vertices lie on lattice points. By [[Pick's theorem]] a lattice triangle has a rational area that either is an integer or has a denominator of 2. If the lattice triangle has integer sides then it is Heronian with integer area.&lt;ref name=Buchholz1&gt;{{cite journal |last=Buchholz  |first=R. H. |last2=MacDougall |first2=J. A. |title=Cyclic Polygons with Rational Sides and Area |citeseerx = 10.1.1.169.6336 |year=2001 |page=3 |publisher=CiteSeerX Penn State University }}&lt;/ref&gt;

Furthermore, it has been proved that all Heronian triangles can be drawn as lattice triangles.&lt;ref&gt;P. Yiu, "Heronian triangles are lattice triangles", ''American Mathematical Monthly'' 108 (2001), 261–263.&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Marshall |first=Susan H. |last2=Perlis |first2=Alexander R. |title=Heronian tetrahedra are lattice tetrahedra |url=http://math.arizona.edu/~aprl/publications/latticetetrahedra/marshallperlis_latticetetrahedra_26Mar2012.pdf |year=2012 |page=2 |publisher=University of Arizona}}&lt;/ref&gt; Consequently, an integer triangle is Heronian if and only if it can be drawn as a lattice triangle.

There are infinitely many primitive Heronian (non-Pythagorean) triangles which can be placed on an integer lattice with all vertices, the [[incenter]], and all three [[excenter]]s at lattice points. Two families of such triangles are the ones with parametrizations given above at [[#Heronian triangles with integer inradius and exradii]].&lt;ref name=Zhou/&gt;{{rp|Thm. 5}}

==Integer automedian triangles==

{{Main article|Automedian triangle}}

An automedian triangle is one whose medians are in the same proportions (in the opposite order) as the sides. If ''x'', ''y'', and ''z'' are the three sides of a right triangle, sorted in increasing order by size, and if 2''x''&amp;nbsp;&lt;&amp;nbsp;''z'', then ''z'', ''x''&amp;nbsp;+&amp;nbsp;''y'', and ''y''&amp;nbsp;&amp;minus;&amp;nbsp;''x'' are the three sides of an automedian triangle. For instance, the right triangle with side lengths 5, 12, and 13 can be used in this way to form the smallest non-trivial (i.e., [[equilateral triangle|non-equilateral]]) integer automedian triangle, with side lengths 13, 17, and 7.&lt;ref name="parry"&gt;{{cite journal
 | last = Parry | first = C. F.
 | issue = 472
 | journal = The Mathematical Gazette
 | jstor = 3620241
 | pages = 151–154
 | title = Steiner–Lehmus and the automedian triangle
 | volume = 75
 | year = 1991}}.&lt;/ref&gt;

Consequently, using [[Pythagorean_triple#Proof_of_Euclid.27s_formula|Euclid's formula]], which generates primitive Pythagorean triangles, it is possible to generate primitive integer automedian triangles as
:&lt;math&gt;a=|m^2-2mn-n^2|&lt;/math&gt;
:&lt;math&gt;b=m^2+2mn-n^2&lt;/math&gt;
:&lt;math&gt;c=m^2+n^2&lt;/math&gt;
with &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;n&lt;/math&gt; coprime and &lt;math&gt;m+n&lt;/math&gt; odd, and &lt;math&gt;n&lt;m&lt;n\sqrt{3}&lt;/math&gt;&amp;nbsp; (if the quantity inside the absolute value signs is negative) or &amp;nbsp;&lt;math&gt;m&gt;(2+\sqrt{3})n&lt;/math&gt; (if that quantity is positive) to satisfy the [[triangle inequality]].

An important characteristic of the automedian triangle is that the squares of its sides form an [[arithmetic progression]]. Specifically, &lt;math&gt;c^2-a^2=b^2-c^2&lt;/math&gt; so &lt;math&gt;2c^2=a^2+b^2&lt;/math&gt;.

==Integer triangles with specific angle properties==

===Integer triangles with a rational angle bisector===

A triangle family with integer sides &lt;math&gt;a,b,c&lt;/math&gt; and with rational bisector &lt;math&gt;d&lt;/math&gt; of angle A is given by&lt;ref&gt;Zelator, Konstantine, ''Mathematical Spectrum'' 39(3), 2006/2007, 59−62.&lt;/ref&gt;

:&lt;math&gt;a=2(k^2-m^2), \, &lt;/math&gt;
:&lt;math&gt;b=(k-m)^2, \,&lt;/math&gt;
:&lt;math&gt;c=(k+m)^2, \, &lt;/math&gt;
:&lt;math&gt;d=\tfrac{2km(k^2-m^2)}{k^2+m^2}, \, &lt;/math&gt;

with integers &lt;math&gt;k&gt;m&gt;0&lt;/math&gt;.

===Integer triangles with integer ''n''-sectors of all angles===

There exist infinitely many non-similar triangles in which the three sides and the bisectors of each of the three angles are integers.&lt;ref name=DeBruyn/&gt;

There exist infinitely many non-similar triangles in which the three sides and the two trisectors of each of the three angles are integers.&lt;ref name=DeBruyn/&gt;

However, for ''n'' &gt; 3 there exist no triangles in which the three sides and the (''n''–1) ''n''-sectors of each of the three angles are integers.&lt;ref name=DeBruyn&gt;[http://forumgeom.fau.edu/FG2005volume5/FG200507.pdf De Bruyn,Bart, "On a Problem Regarding the n-Sectors of a Triangle", ''Forum Geometricorum'' 5, 2005: pp. 47–52.]&lt;/ref&gt;

===Integer triangles with one angle with a given rational cosine===

Some integer triangles with one angle at vertex ''A'' having given rational cosine ''h/k'' (''h''&lt;0 or &gt;0; ''k''&gt;0) are given by&lt;ref&gt;Sastry, K. R. S., "Integer-sided triangles containing a given rational cosine", ''Mathematical Gazette'' 68, December 1984, 289−290.&lt;/ref&gt;

:&lt;math&gt;a=p^2-2pqh+q^2k^2,&lt;/math&gt;
:&lt;math&gt;b=p^2-q^2k^2,&lt;/math&gt;
:&lt;math&gt;c=2qk(p-qh),&lt;/math&gt;

where ''p'' and ''q'' are any coprime positive integers such that ''p&gt;qk''.

====Integer triangles with a 60° angle (angles in arithmetic progression)====

All integer triangles with a 60° angle have their angles in an arithmetic progression. All such triangles are proportional to:&lt;ref name=Zelator&gt;[https://arxiv.org/ftp/arxiv/papers/0803/0803.3778.pdf Zelator, K., "Triangle Angles and Sides in Progression and the diophantine equation x&lt;sup&gt;2&lt;/sup&gt;+3y&lt;sup&gt;2&lt;/sup&gt;=z&lt;sup&gt;2&lt;/sup&gt;", ''Cornell Univ. archive'', 2008]&lt;/ref&gt;

:&lt;math&gt;a=4mn \, &lt;/math&gt;
:&lt;math&gt;b=3m^2+n^2\, &lt;/math&gt;
:&lt;math&gt;c=2mn+|3m^2-n^2| \, &lt;/math&gt;

with coprime integers ''m'', ''n'' and 1&amp;nbsp;&amp;le;&amp;nbsp;''n''&amp;nbsp;&amp;le;&amp;nbsp;''m'' or 3''m''&amp;nbsp;&amp;le;&amp;nbsp;''n''. From here, all primitive solutions can be obtained by dividing ''a'', ''b'', and ''c'' by their greatest common divisor.

Integer triangles with a 60° angle can also be generated by&lt;ref&gt;Gilder, J., Integer-sided triangles with an angle of 60°", ''Mathematical Gazette'' 66, December 1982, 261&amp;nbsp;266&lt;/ref&gt;

:&lt;math&gt;a=m^2-mn+n^2 \, &lt;/math&gt;
:&lt;math&gt;b=2mn - n^2\, &lt;/math&gt;
:&lt;math&gt;c=m^2-n^2 \, &lt;/math&gt;

with coprime integers ''m'', ''n'' with 0&amp;nbsp;&lt;&amp;nbsp;''n''&amp;nbsp;&lt;&amp;nbsp;''m'' (the angle of 60° is opposite to the side of length ''a''). From here, all primitive solutions can be obtained by dividing ''a'', ''b'', and ''c'' by their greatest common divisor (e.g. an equilateral triangle solution is obtained by taking ''m'' = 2 and ''n'' = 1, but this produces ''a'' = ''b'' = ''c'' = 3, which is not a primitive solution). See also &lt;ref name="Burn"&gt;Burn, Bob, "Triangles with a 60° angle and sides of integer length", ''Mathematical Gazette'' 87, March 2003, 148–153.&lt;/ref&gt;&lt;ref name=Read&gt;Read, Emrys, "On integer-sided triangles containing angles of 120° or 60°", ''Mathematical Gazette'' 90, July 2006, 299−305.&lt;/ref&gt;

More precisely, If &lt;math&gt;m = -n \ (mod \ 3)&lt;/math&gt;, then &lt;math&gt;gcd(a,b,c)=3&lt;/math&gt;, otherwise &lt;math&gt;gcd(a,b,c)=1&lt;/math&gt;. Two different pairs &lt;math&gt;(m, n)&lt;/math&gt; and &lt;math&gt;(m, m-n)&lt;/math&gt; generate the same triple. Unfortunately the two pairs can both be of gcd=3, so we can't avoid duplicates by simply skipping that case. Instead, duplicates can be avoided by &lt;math&gt;n&lt;/math&gt; going only till &lt;math&gt;m/2&lt;/math&gt;. Note that we still need to divide by 3 if gcd=3. The only solution for &lt;math&gt;n=m/2&lt;/math&gt; under the above constraints is &lt;math&gt;(3,3,3) \equiv  (1,1,1)&lt;/math&gt; for &lt;math&gt;m=2,n=1&lt;/math&gt;. With this additional &lt;math&gt;n \leq m/2&lt;/math&gt; constraint all triples can be generated uniquely.

An [[Eisenstein triple]] is a set of integers which are the lengths of the sides of a triangle where one of the angles is 60 degrees.

====Integer triangles with a 120° angle====

Integer triangles with a 120° angle can be generated by&lt;ref&gt;Selkirk, K., "Integer-sided triangles with an angle of 120°", ''Mathematical Gazette'' 67, December 1983, 251–255.&lt;/ref&gt;

:&lt;math&gt;a = m^2 + mn + n^2, \, &lt;/math&gt;
:&lt;math&gt;b = 2mn+n^2, \, &lt;/math&gt;
:&lt;math&gt;c = m^2 - n^2 \, &lt;/math&gt;

with coprime integers ''m'',&amp;nbsp;''n'' with 0&amp;nbsp;&lt;&amp;nbsp;''n''&amp;nbsp;&lt;&amp;nbsp;''m'' (the angle of 120° is opposite to the side of length ''a''). From here, all primitive solutions can be obtained by dividing ''a'', ''b'', and ''c'' by their greatest common divisor (e.g. by taking ''m'' = 4 and ''n'' = 1, one obtains ''a'' = 21, ''b'' = 9 and ''c'' = 15, which is not a primitive solution, but leads to the primitive solution ''a'' = 7, ''b'' = 3, and ''c'' = 5 which, up to order, can be obtained with the values ''m'' = 2 and ''n'' = 1). See also.&lt;ref name="Burn"/&gt;&lt;ref name=Read/&gt;

More precisely, If &lt;math&gt;m = n \ (mod \ 3)&lt;/math&gt;, then &lt;math&gt;gcd(a,b,c)=3&lt;/math&gt;, otherwise &lt;math&gt;gcd(a,b,c)=1&lt;/math&gt;. Since the biggest side ''a'' can only be generated with a single &lt;math&gt;(m, n)&lt;/math&gt; pair,  each primitive triple can be generated in precisely two ways: once directly with gcd=1, and once indirectly with gcd=3. Therefore, in order to generate all primitive triples uniquely, one can just add additional &lt;math&gt;m \ne n \ (mod \ 3)&lt;/math&gt; condition.

===Integer triangles with one angle equal to an arbitrary rational number times another angle===

For positive relatively prime integers ''h'' and ''k'', the triangle with the following sides has angles &lt;math&gt;h \alpha&lt;/math&gt;, &lt;math&gt;k \alpha&lt;/math&gt;, and &lt;math&gt; \pi - (h+k) \alpha&lt;/math&gt; and hence two angles in the ratio ''h : k'', and its sides are integers:&lt;ref&gt;Hirschhorn, Michael D., "Commensurable triangles", ''Mathematical Gazette'' 95, March 2011, pp. 61−63.&lt;/ref&gt;

:&lt;math&gt;a = q^{h+k-1} \frac{\sin h \alpha}{\sin \alpha} = q^k \cdot\sum_{0 \leq i \leq \frac{h-1}{2}}(-1)^{i}\binom{h}{2i+1}p^{h-2i-1}(q^2-p^2)^i,&lt;/math&gt;

:&lt;math&gt;b = q^{h+k-1} \frac{\sin k \alpha}{\sin \alpha} = q^h \cdot\sum_{0 \leq i \leq \frac{k-1}{2}}(-1)^{i}\binom{k}{2i+1}p^{k-2i-1}(q^2-p^2)^i,&lt;/math&gt;

:&lt;math&gt;c = q^{h+k-1} \frac{\sin (h+k) \alpha}{\sin \alpha} = \sum_{0 \leq i \leq \frac{h+k-1}{2}}(-1)^{i}\binom{h+k}{2i+1}p^{h+k-2i-1}(q^2-p^2)^i,&lt;/math&gt;

where &lt;math&gt;\alpha = \cos^{-1} \frac{p}{q}&lt;/math&gt; and ''p'' and ''q'' are any relatively prime integers such that &lt;math&gt;\cos \frac{\pi}{h+k} &lt; \frac{p}{q} &lt; 1&lt;/math&gt;.

====Integer triangles with one angle equal to twice another====

With angle A opposite side &lt;math&gt;a&lt;/math&gt; and angle B opposite side &lt;math&gt;b&lt;/math&gt;, some triangles with B=2A are generated by&lt;ref name="Deshpande"&gt;Deshpande,M. N., "Some new triples of integers and associated triangles", ''Mathematical Gazette'' 86, November 2002, 464–466.&lt;/ref&gt;

:&lt;math&gt;a=n^2, \, &lt;/math&gt;
:&lt;math&gt;b = mn \, &lt;/math&gt;
:&lt;math&gt;c=m^2 - n^2, \, &lt;/math&gt;

with integers ''m'', ''n'' such that 0&amp;nbsp;&lt;&amp;nbsp;''n''&amp;nbsp;&lt;&amp;nbsp;''m''&amp;nbsp;&lt;&amp;nbsp;2''n''.

Note that all triangles with ''B''&amp;nbsp;=&amp;nbsp;2''A'' (whether integer or not) have&lt;ref&gt;Willson, William Wynne, "A generalisation of the property of the 4,&amp;nbsp;5,&amp;nbsp;6&amp;nbsp;triangle", ''[[Mathematical Gazette]]'' 60, June 1976, 130–131.&lt;/ref&gt; &lt;math&gt;a(a+c)=b^2&lt;/math&gt;.

====Integer triangles with one angle equal to 3/2 times another====

The equivalence class of similar triangles with &lt;math&gt;\ B=\tfrac{3}{2}A&lt;/math&gt; are generated by&lt;ref name="Deshpande" /&gt;

:&lt;math&gt;a=mn^3, \, &lt;/math&gt;
:&lt;math&gt;b=n^2(m^2-n^2), \, &lt;/math&gt;
:&lt;math&gt;c=(m^2 - n^2)^2 - m^2 n^2, \, &lt;/math&gt;

with integers &lt;math&gt;\ m, n&lt;/math&gt; such that &lt;math&gt;\ 0&lt;\varphi n&lt;m&lt;2n&lt;/math&gt;, where &lt;math&gt;\ \varphi&lt;/math&gt; is the [[golden ratio]] &lt;math&gt;\varphi = \frac{1+\sqrt{5}}{2}\approx 1.61803&lt;/math&gt;.

Note that all triangles with &lt;math&gt;\ B=\tfrac{3}{2}A&lt;/math&gt; (whether with integer sides or not) satisfy &lt;math&gt;\ (b^{2}-a^{2})(b^{2}-a^{2}+bc) = a^{2}c^{2}&lt;/math&gt;.

====Integer triangles with one angle three times another====

We can generate the full equivalence class of similar triangles that satisfy B=3A  by using the formulas &lt;ref&gt;{{cite journal |last=Parris |first=Richard |journal=College Mathematics Journal |title=Commensurable Triangles |doi=10.1080/07468342.2007.11922259 |volume=38 |issue=5 |date=November 2007 |pages=345–355}}&lt;/ref&gt;

:&lt;math&gt;a=n^{3}, \,&lt;/math&gt;
:&lt;math&gt;b=n(m^{2}-n^{2}), \, &lt;/math&gt;
:&lt;math&gt;c=m(m^{2}-2n^{2}), \, &lt;/math&gt;

where &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;n&lt;/math&gt; are integers such that &lt;math&gt;\sqrt{2}n &lt; m &lt; 2n&lt;/math&gt;.

Note that all triangles with B = 3A (whether with integer sides or not) satisfy &lt;math&gt;ac^2 = (b-a)^{2}(b+a)&lt;/math&gt;.

===Integer triangles with three rational angles===

The only integer triangle with three rational angles (rational numbers of degrees, or equivalently rational fractions of a full turn) is the [[equilateral triangle]].&lt;ref name=CG/&gt; This is because integer sides imply three rational [[cosine]]s by the [[law of cosines]], and by [[Niven's theorem]] a rational cosine coincides with a rational angle if and only if the cosine equals 0, ±1/2, or ±1. The only ones of these giving an angle strictly between 0° and 180° are the cosine value 1/2 with the angle 60°, the cosine value –1/2 with the angle 120°, and the cosine value 0 with the angle 90°. The only combination of three of these, allowing multiple use of any of them and summing to 180°, is three 60° angles.

==Integer triangles with integer ratio of circumradius to inradius==

Conditions are known in terms of [[elliptic curve]]s for an integer triangle to have an integer ratio ''N'' of the [[circumradius]] to the [[inradius]].&lt;ref&gt;[http://forumgeom.fau.edu/FG2010volume10/FG201017.pdf MacLeod, Allan J., "Integer triangles with R/r = N", ''Forum Geometricorum'' 10, 2010: pp. 149−155.]&lt;/ref&gt;&lt;ref&gt;[http://forumgeom.fau.edu/FG2012volume12/FG201203.pdf Goehl, John F. Jr., "More integer triangles with R/r = N", ''Forum Geometricorum'' 12, 2012: pp. 27−28]&lt;/ref&gt; The smallest case, that of the [[equilateral triangle]], has ''N''=2. In every known case, ''N'' ≡ 2 (mod 8)—that is, ''N''–2 is divisible by 8.

==5-Con triangle pairs==

{{Main article|5-Con triangles}}

A 5-Con triangle pair is a pair of triangles that are [[similarity (geometry)|similar]] but not [[congruence (geometry)|congruent]] and that share three angles and two sidelengths. Primitive integer 5-Con triangles, in which the four distinct integer sides (two sides each appearing in both triangles, and one other side in each triangle) share no prime factor, have triples of sides 

:&lt;math&gt;(x^3, x^2y, xy^2)&lt;/math&gt; and &lt;math&gt;(x^2y, xy^2, y^3)&lt;/math&gt; 

for positive coprime integers ''x'' and ''y''. The smallest example is the pair (8, 12, 18), (12, 18, 27), generated by ''x'' = 2, ''y'' = 3.

==Particular integer triangles==

*The only triangle with consecutive integers for sides and area has sides (3, 4, 5) and area 6.
*The only triangle with consecutive integers for an altitude and the sides  has sides (13, 14, 15) and altitude from side 14 equal to 12.
*The (2, 3, 4) triangle and its multiples are the only triangles with integer sides in arithmetic progression and having the complementary exterior angle property.&lt;ref&gt;Barnard, T., and Silvester, J., "Circle theorems and a property of the (2,3,4) triangle", ''Mathematical Gazette'' 85, July 2001, 312−316.&lt;/ref&gt;&lt;ref&gt;Lord, N., "A striking property of the (2,3,4) triangle", ''Mathematical Gazette'' 82, March 1998, 93−94.&lt;/ref&gt;&lt;ref name="Mitchell 2:3:4"&gt;Mitchell, Douglas W., "The 2:3:4, 3:4:5, 4:5:6, and 3:5:7 triangles", ''Mathematical Gazette'' 92, July 2008.&lt;/ref&gt;  This property states that if angle C is obtuse and if a segment is dropped from B meeting perpendicularly AC [[extended side|extended]] at P, then ∠CAB=2∠CBP.
*The (3, 4, 5) triangle and its multiples are the only integer right triangles having sides in arithmetic progression&lt;ref name="Mitchell 2:3:4" /&gt;
*The (4, 5, 6) triangle and its multiples are the only triangles with one angle being twice another and having integer sides in arithmetic progression.&lt;ref name="Mitchell 2:3:4" /&gt;
*The (3, 5, 7) triangle and its multiples are the only triangles with a 120° angle and having integer sides in arithmetic progression.&lt;ref name="Mitchell 2:3:4" /&gt;
*The only integer triangle with area=semiperimeter&lt;ref name="MacHale, D. 1989"&gt;MacHale, D., "That 3,4,5 triangle again", ''Mathematical Gazette'' 73, March 1989, 14−16.&lt;/ref&gt; has sides (3, 4, 5).
*The only integer triangles with area = perimeter have sides&lt;ref name="MacHale, D. 1989"/&gt;&lt;ref&gt;[[L. E. Dickson]], ''[[History of the Theory of Numbers]], vol.2'', 181.&lt;/ref&gt; (5, 12, 13), (6, 8, 10), (6, 25, 29), (7, 15, 20), and (9, 10, 17).  Of these the first two, but not the last three, are right triangles.
*There exist integer triangles with three rational [[Median (geometry)|medians]].&lt;ref name="Sierpinski"/&gt;{{rp|p. 64}}  The smallest has sides (68, 85, 87).  Others include (127, 131, 158), (113, 243, 290), (145, 207, 328) and (327, 386, 409).
*There are no isosceles Pythagorean triangles.&lt;ref name=Sastry/&gt;
*The only primitive Pythagorean triangles for which the square of the perimeter equals an integer multiple of the area are (3, 4, 5) with perimeter 12 and area 6 and with the ratio of perimeter squared to area being 24; (5, 12, 13) with perimeter 30 and area 30 and with the ratio of perimeter squared to area being 30; and (9, 40, 41) with perimeter 90 and area 180 and with the ratio of perimeter squared to area being 45.&lt;ref&gt;[http://forumgeom.fau.edu/FG2009volume9/FG200927.pdf Goehl, John F. Jr., "Pythagorean triangles with square of perimeter equal to an integer multiple of area", ''Forum Geometricorum'' 9 (2009): 281–282.]&lt;/ref&gt;
*There exists a unique (up to similitude) pair of a rational right triangle and a rational isosceles triangle which have the same perimeter and the same area. The unique pair consists of the (377, 135, 352) triangle and the (366, 366, 132) triangle.&lt;ref name=":0"&gt;{{Cite journal|last=Hirakawa|first=Yoshinosuke|last2=Matsumura|first2=Hideki|date=2018|title=A unique pair of triangles|url=https://linkinghub.elsevier.com/retrieve/pii/S0022314X18302269|journal=Journal of Number Theory|volume=|pages=|doi=10.1016/j.jnt.2018.07.007|issn=0022-314X|via=}}&lt;/ref&gt;  There is no pair of such triangles if the triangles are also required to be primitive integral triangles.&lt;ref name=":0" /&gt;

==See also==

*[[Robbins pentagon]], a cyclic pentagon with integer sides and integer area
*[[Euler brick]], a cuboid with integer edges and integer face diagonals
*[[Tetrahedron#Integer tetrahedra]]

==References==

{{reflist|30em}}

{{DEFAULTSORT:Integer Triangle}}
[[Category:Arithmetic problems of plane geometry]]
[[Category:Discrete geometry]]
[[Category:Squares in number theory]]
[[Category:Triangles]]</text>
      <sha1>j1jafi1737q0e2reqay4zh2biaae1uh</sha1>
    </revision>
  </page>
  <page>
    <title>Internal validity</title>
    <ns>0</ns>
    <id>1562189</id>
    <revision>
      <id>863479569</id>
      <parentid>862827798</parentid>
      <timestamp>2018-10-11T01:33:50Z</timestamp>
      <contributor>
        <ip>130.102.10.84</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12739">'''Internal validity''' is the extent to which a piece of evidence supports a claim about [[causality|cause and effect]], within the context of a particular study. It is one of the most important properties of scientific studies, and is an important concept in reasoning about [[evidence]] more generally. Internal validity is determined by how well a study can rule out alternative explanations for its findings (usually, sources of [[systematic error]] or 'bias'). It contrasts with [[external validity]], the extent to which results can justify conclusions about other contexts (that is, the extent to which results can be [[generalization|generalized]]).

== Details ==
Inferences are said to possess internal validity if a causal relationship between two [[Variable and attribute (research)|variables]] is properly demonstrated.&lt;ref&gt;Brewer, M. (2000). Research Design and Issues of Validity. In Reis, H. and Judd, C. (eds.) Handbook of Research Methods in Social and Personality Psychology. Cambridge:Cambridge University Press.&lt;/ref&gt;&lt;ref name=Shadish&gt;Shadish, W., Cook, T., and Campbell, D. (2002). Experimental and Quasi-Experimental Designs for Generilized Causal Inference Boston:Houghton Mifflin.&lt;/ref&gt; 
A valid causal inference may be made when three criteria are satisfied: 
# the "cause" precedes the "effect" in time (temporal precedence),
# the "cause" and the "effect" tend to occur together (covariation), and
# there are no plausible alternative explanations for the observed covariation (nonspuriousness).&lt;ref name=Shadish/&gt;

In scientific experimental settings, researchers often change the state of one variable (the [[independent variable]]) to see what effect it has on a second variable (the [[dependent variable]]).&lt;ref&gt;Levine, G. and Parkinson, S. (1994). Experimental Methods in Psychology. Hillsdale, NJ:Lawrence Erlbaum.&lt;/ref&gt; For example, a researcher might manipulate the dosage of a particular drug between different groups of people to see what effect it has on health. In this example, the researcher wants to make a causal inference, namely, that different doses of the drug may be ''held responsible'' for observed changes or differences. When the researcher may confidently attribute the observed changes or differences in the dependent variable to the independent variable (that is, when the researcher observes an association between these variables and can rule out other explanations or ''rival hypotheses''), then the causal inference is said to be internally valid.&lt;ref&gt;Liebert, R. M. &amp; Liebert, L. L. (1995). Science and behavior: An introduction to methods of psychological research. Englewood Cliffs, NJ: Prentice Hall.&lt;/ref&gt;

In many cases, however, the [[Effect size|size of effects]] found in the dependent variable may not just depend on 
* variations in the independent variable,
* the [[Statistical power|power]] of the instruments and statistical procedures used to measure and detect the effects, and
* the choice of statistical methods (see: [[Statistical conclusion validity]]).

Rather, a number of variables or circumstances uncontrolled for (or uncontrollable) may lead to additional or alternative explanations (a) for the effects found and/or (b) for the magnitude of the effects found. Internal validity, therefore, is more a matter of degree than of either-or, and that is exactly why research designs other than true experiments may also yield results with a high degree of internal validity.

In order to allow for inferences with a high degree of internal validity, precautions may be taken during the design of the study. As a rule of thumb, conclusions based on direct manipulation of the independent variable allow for greater internal validity than conclusions based on an association observed without manipulation. 

When considering only Internal Validity, highly controlled true experimental designs (i.e. with random selection, random assignment to either the control or experimental groups, reliable instruments, reliable manipulation processes, and safeguards against confounding factors) may be the  "gold standard" of scientific research. However, the very methods used to increase internal validity may also limit the generalizability or [[external validity]] of the findings. For example, studying the behavior of animals in a zoo may make it easier to draw valid causal inferences within that context, but these inferences may not generalize to the behavior of animals in the wild. In general, a typical experiment in a laboratory, studying a particular process, may leave out many variables that normally strongly affect that process in nature.

==Example Threats==

===Ambiguous temporal precedence===
When it is not known which variable changed first, it can be difficult to determine which variable is the cause and which is the effect.

===Confounding===
A major threat to the validity of causal inferences is [[Confounding variable|confounding]]: Changes in the dependent variable may rather be attributed to variations in a third variable which is related to the manipulated variable. Where [[spurious relationship]]s cannot be ruled out, rival hypotheses to the original causal inference may be developed.

===Selection bias===
Selection bias refers to the problem that, at pre-test, differences between groups exist that may interact with the independent variable and thus be 'responsible' for the observed outcome. Researchers and participants bring to the experiment a myriad of characteristics, some learned and others inherent. For example, sex, weight, hair, eye, and skin color, personality, mental capabilities, and physical abilities, but also attitudes like motivation or willingness to participate.

During the selection step of the research study, if an unequal number of test subjects have similar subject-related variables there is a threat to the internal validity. For example, a researcher created two test groups, the experimental and the control groups.  The subjects in both groups are not alike with regard to the independent variable but similar in one or more of the subject-related variables.

Self-selection also has a negative effect on the interpretive power of the dependent variable.  This occurs often in online surveys where individuals of specific demographics opt into the test at higher rates than other demographics.

===History===
Events outside of the study/experiment or between repeated measures of the dependent variable may affect participants' responses to experimental procedures. Often, these are large-scale events (natural disaster, political change, etc.) that affect participants' attitudes and behaviors such that it becomes impossible to determine whether any change on the dependent measures is due to the independent variable, or the historical event.

===Maturation===
Subjects change during the course of the experiment or even between measurements. For example, young children might mature and their ability to concentrate may change as they grow up. Both permanent changes, such as physical growth and temporary ones like fatigue, provide "natural" alternative explanations; thus, they may change the way a subject would react to the independent variable. So upon completion of the study, the researcher may not be able to determine if the cause of the discrepancy is due to time or the independent variable.

===Repeated testing (also referred to as testing effects)===
Repeatedly measuring the participants may lead to bias. Participants may remember the correct answers or may be conditioned to know that they are being tested. Repeatedly taking (the same or similar) intelligence tests usually leads to score gains, but instead of concluding that the underlying skills have changed for good, this threat to Internal Validity provides a good rival hypotheses.

===Instrument change (instrumentality)===
The instrument used during the testing process can change the experiment. This also refers to observers being more concentrated or primed, or having unconsciously changed the criteria they use to make judgments. This can also be an issue with self-report measures given at different times. In this case the impact may be mitigated through the use of retrospective pretesting. If any instrumentation changes occur, the internal validity of the main conclusion is affected, as alternative explanations are readily available.

===Regression toward the mean===
{{main|Regression toward the mean}}
This type of error occurs when subjects are selected on the basis of extreme scores (one far away from the mean) during a test. For example, when children with the worst reading scores are selected to participate in a reading course, improvements at the end of the course might be due to regression toward the mean and not the course's effectiveness. If the children had been tested again before the course started, they would likely have obtained better scores anyway.
Likewise, extreme outliers on individual scores are more likely to be captured in one instance of testing but will likely evolve into a more normal distribution with repeated testing.

===Mortality/differential attrition===
{{main|Survivorship bias}}
This error occurs if inferences are made on the basis of only those participants that have participated from the start to the end. However, participants may have dropped out of the study before completion, and maybe even due to the study or programme or experiment itself. For example, the percentage of group members having quit smoking at post-test was found much higher in a group having received a quit-smoking training program than in the control group. However, in the experimental group only 60% have completed the program. 
If this attrition is systematically related to any feature of the study, the administration of the independent variable, the instrumentation, or if dropping out leads to relevant bias between groups, a whole class of alternative explanations is possible that account for the observed differences.

===Selection-maturation interaction===
This occurs when the subject-related variables, color of hair, skin color, etc., and the time-related variables, age, physical size, etc., interact. If a discrepancy between the two groups occurs between the testing, the discrepancy may be due to the age differences in the age categories.

===Diffusion===
If treatment effects spread from treatment groups to control groups, a lack of differences between experimental and control groups may be observed. This does not mean, however, that the independent variable has no effect or that there is no relationship between dependent and independent variable.

===Compensatory rivalry/resentful demoralization===
Behavior in the control groups may alter as a result of the study. For example, control group members may work extra hard to see that expected superiority of the experimental group is not demonstrated. Again, this does not mean that the independent variable produced no effect or that there is no relationship between dependent and independent variable. Vice versa, changes in the dependent variable may only be affected due to a demoralized control group, working less hard or motivated, not due to the independent variable.

===Experimenter bias===
Experimenter bias occurs when the individuals who are conducting an experiment inadvertently affect the outcome by non-consciously behaving in different ways to members of control and experimental groups. It is possible to eliminate the possibility of experimenter bias through the use of [[double blind]] study designs, in which the experimenter is not aware of the condition to which a participant belongs.

For eight of these threats there exists the [[Mnemonic#First letter mnemonics|first letter mnemonic]] ''THIS MESS'', which refers to the first letters of ''T''esting (repeated testing), ''H''istory, ''I''nstrument change, ''S''tatistical Regression toward the mean, ''M''aturation, ''E''xperimental mortality, ''S''election and ''S''election Interaction.&lt;ref&gt;{{cite journal |last1=Wortman |first1=P. M. |last2= |first2= |year=1983 |title=Evaluation research – A methodological perspective |journal=Annual Review of Psychology |volume= 34|issue= |pages=223–260 |publisher= |doi=10.1146/annurev.ps.34.020183.001255 |url= |accessdate= }}&lt;/ref&gt;

==See also==
*[[External validity]]
*[[Construct validity]]
*[[Content validity]]
*[[Statistical conclusion validity]]
*[[Validity (statistics)|Validity in statistics]]
*[[Ecological validity]]

==References==
{{reflist}}

==External links==
* [http://www.socialresearchmethods.net/kb/intval.php Internal validity] (Social research methods)

{{DEFAULTSORT:Internal Validity}}
[[Category:Causal inference]]
[[Category:Validity (statistics)]]</text>
      <sha1>bnz5q3dpxr9faisze3y2cm1lnz2u0zu</sha1>
    </revision>
  </page>
  <page>
    <title>Israel Gelfand</title>
    <ns>0</ns>
    <id>364643</id>
    <revision>
      <id>866134233</id>
      <parentid>864829121</parentid>
      <timestamp>2018-10-28T13:54:45Z</timestamp>
      <contributor>
        <username>Feanor0</username>
        <id>11413340</id>
      </contributor>
      <comment>/* Family */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19593">{{Distinguish|Alexander Gelfond}}
{{Eastern Slavic name|Moiseevich|Gelfand}}

{{Infobox scientist
|name              = Israïl Moiseevich Gelfand
|image             = IM_Gelfand.jpg
|birth_date        = {{birth date|1913|09|02}}
|birth_place       = [[Okny]], [[Kherson Governorate]], [[Russian Empire]]
|nationality       = [[Soviet Union]]&lt;br&gt;[[Russia]]n
|death_date        = {{death date and age|2009|10|05|1913|09|02}}
|death_place       = [[New Brunswick, New Jersey|New Brunswick]], [[New Jersey]], United States
|field             = [[Mathematician]]
|work_institution  = [[Moscow State University]]&lt;br&gt;[[Rutgers University]]
|alma_mater        = [[Moscow State University]]
|doctoral_advisor  = [[Andrey Kolmogorov]]
|doctoral_students = [[Georgy Adelson-Velsky]]&lt;br&gt;[[Felix Berezin]]&lt;br&gt;[[Joseph Bernstein]]&lt;br&gt;[[Victor Ginzburg]] &lt;br&gt;[[Alexander Goncharov]]&lt;br&gt;[[Alexandre Kirillov]]&lt;br/&gt;[[Georgiy Shilov]]&lt;br&gt;[[Endre Szemerédi]]&lt;br&gt;[[Andrei Zelevinsky]]&lt;br&gt;[[Vitalii Ditkin]]
|known_for         = [[Group Theory]], [[Representation Theory]], [[mathematical analysis]]&lt;br&gt;[[Gelfand–Levitan–Marchenko integral equation]]&lt;br&gt;[[Liouville–Bratu–Gelfand equation]]
|prizes            = [[Order of Lenin]] (three times)&lt;br&gt;[[Wolf Prize]] &lt;small&gt;(1978)&lt;/small&gt;&lt;br&gt;[[Wigner Medal]] &lt;small&gt;(1980)&lt;/small&gt;&lt;br&gt;[[Kyoto Prize]] in Mathematical sciences &lt;small&gt;(1989)&lt;/small&gt;&lt;br&gt;[[American Mathematical Society|AMS]] [[Steele Prize]] &lt;small&gt;(2005)&lt;/small&gt;
}}
'''Israel Moiseevich Gelfand''', also written '''Israïl Moyseyovich Gel'fand''', or '''Izrail M. Gelfand''' ({{lang-yi|ישראל געלפֿאַנד}}, {{lang-ru|Изра́иль Моисе́евич Гельфа́нд}}; {{OldStyleDate|2 September|1913|20 August}} – 5 October 2009) was a prominent [[USSR|Soviet]] [[mathematician]]. He made significant contributions to many branches of mathematics, including [[group theory]], [[representation theory]] and [[functional analysis]].  The recipient of many awards, including the [[Order of Lenin]] and the [[Wolf Prize]], he was a [[Fellow of the Royal Society]] and professor at [[Moscow State University]] and, after immigrating to the United States shortly before his 76th birthday, at [[Rutgers University]].

His legacy continues through his students, who include [[Endre Szemerédi]], [[Alexandre Kirillov]], [[Edward Frenkel]],&lt;ref&gt;{{cite book |last=[[Edward Frenkel]] |first= |date=2013 |title=Love and Math: The Heart of Hidden Reality |url=http://www.loveandmathbook.com/ |location= |publisher=Basic Books |chapter=preface |quote=One of my teachers, the great Israel Gelfand |isbn=978-0465050741 |access-date= }}&lt;/ref&gt; [[Joseph Bernstein]], as well as his own son, Sergei Gelfand.

==Early years==
A native of [[Kherson Governorate]] of the [[Russian Empire]], Gelfand was born into a [[History of the Jews in Ukraine|Jewish]] family in the small southern  [[Ukraine|Ukrainian]] town of [[Okny]].  According to his own account, Gelfand was expelled from high school because his father had been a mill owner. Bypassing both high school and college, he proceeded to postgraduate study at the age of 19 at [[Moscow State University]], where his advisor was the preeminent mathematician [[Andrei Kolmogorov]]. &lt;ref name="Telegraph"&gt;{{cite news|url=https://www.telegraph.co.uk/news/obituaries/science-obituaries/6440484/Israel-Gelfand.html|title=Science Obituaries: Israel Gelfand|date=26 Oct 2009|work=The Telegraph|accessdate=31 May 2013|location=London}}&lt;/ref&gt;

==Work==

Gelfand is known for many developments including:
* the book ''Calculus of Variations'' (1963), which he co-authored with [[Sergei Fomin]]
* the [[Gelfand representation]] in [[Banach algebra]] theory;
* the [[Gelfand–Mazur theorem]] in [[Banach algebra]] theory;
* the [[Gelfand–Naimark theorem]];
* the [[Gelfand–Naimark–Segal construction]];
* [[Gelfand–Shilov space]]s
* the [[Pettis integral|Gelfand–Pettis integral]];
* the [[representation theory]] of the complex classical [[Lie group]]s;
* contributions to the theory of [[Verma module]]s in the [[representation theory]] of [[semisimple Lie algebra]]s (with I. N. Bernstein and S. I. Gelfand);
* contributions to [[distribution (mathematics)|distribution]] theory and measures on infinite-dimensional spaces;&lt;ref&gt;{{Citation|title=[[Generalized function|Generalized Functions]]|first=I.M.|last=Gel'fand |author2=N.Ya.Vilenkin |isbn=0-12-279504-0|publisher=Academic Press|pages=375|year=1964}}&lt;/ref&gt;
* the first observation of the connection of [[automorphic form]]s with representations (with [[Sergei Fomin]]);
* conjectures about the [[Atiyah–Singer index theorem]];
* [[Ordinary differential equation]]s (Gelfand–[[Boris Levitan|Levitan]] theory);
* work on [[calculus of variations]] and [[soliton]] theory (Gelfand–Dikii equations);
* contributions to the ''[[philosophy of cusp forms]]'';
* Gelfand–Fuks cohomology of [[foliation]]s;
* [[Gelfand–Kirillov dimension]];
* [[integral geometry]];
* combinatorial definition of the [[Pontryagin class]];
* [[Coxeter functor]]s;
* [[general hypergeometric function]]s;
* Gelfand–Tsetlin patterns;
* and many other results, particularly in the representation theory for the classical groups.

==Influence outside mathematics==
The [[Restricted representation#Gelfand–Tsetlin basis|Gelfand–Tsetlin (also spelled Zetlin) basis]] is a widely used tool in [[theoretical physics]] and the result of Gelfand's work on the representation theory of the unitary group and Lie groups in general.

Gelfand also published works on biology and medicine.&lt;ref&gt;[[:ru:Гельфанд, Израиль Моисеевич]]&lt;/ref&gt; For a long time he took an interest in [[cell biology]] and organized a research seminar on the subject.&lt;ref&gt;V.I. Agol, [http://www.springerlink.com/content/p7138232265768r3/ Notes about I.M. Gelfand’s Seminar], ''Russian Journal Developmental Biology, Volume 39, Number 6, 367-368.&lt;/ref&gt;&lt;ref&gt;L.V. Beloussov, [http://www.springerlink.com/content/a684321218166641/ Short notes about Gelfand’s Seminar], ''Russian Journal Developmental Biology, Volume 39, Number 6, 369-370.&lt;/ref&gt;

He worked extensively in mathematics education, particularly with correspondence education. In 1994, he was awarded a [[MacArthur Fellowship]] for this work.

==Family==
Gelfand was married to [[Zorya Shapiro]], and their two sons, Sergei and Vladimir both live in the United States.  A third son, Aleksandr, died of [[leukemia]].  Following the divorce from his first wife, Gelfand married his second wife, Tatiana; together they had a daughter, Tatiana. The family also includes four grandchildren and three great-grandchildren.&lt;ref&gt;[https://www.nytimes.com/2009/10/08/science/08gelfand.html?_r=1&amp;scp=1&amp;sq=Israel%20Gelfand&amp;st=cse Chang, Kenneth. "Israel Gelfand, Math Giant, Dies at 96", ''The New York Times'' (October 7, 2009)]&lt;/ref&gt;&lt;ref&gt;{{cite news| url=https://www.theguardian.com/science/2009/nov/08/israel-gelfand-obituary | location=London | work=The Guardian | first=Ian | last=Stewart | title=Israel Gelfand obituary | date=November 8, 2009}}&lt;/ref&gt;
The memories about I.Gelfand are collected at the special site&lt;ref&gt;http://israelmgelfand.com/ site dedicated to Israel M. Gelfand&lt;/ref&gt; handled by his family.

==Honors and awards==
Gelfand held several honorary degrees and was awarded the [[Order of Lenin]] three times for his research.  In 1977 he was elected a [[Foreign Member of the Royal Society]]. He won the [[Wolf Prize]] in 1978, [[Kyoto Prize]] in 1989 and MacArthur Foundation Fellowship in 1994. He held the presidency of the [[Moscow Mathematical Society]] between 1968 and 1970, and was elected a foreign member of the [[United States National Academy of Sciences|U.S. National Academy of Science]], the [[American Academy of Arts and Sciences]], the [[Royal Irish Academy]], the [[American Mathematical Society]] and the [[London Mathematical Society]].

In an October 2003 article in ''[[The New York Times]]'', written on the occasion of his 90th birthday, Gelfand is described as a scholar who is considered "among the greatest mathematicians of the 20th century",&lt;ref&gt;[https://www.nytimes.com/2003/10/05/nyregion/in-person-an-equation-for-success.html Kochman, Marilyn. "In Person: An Equation for Success", ''The New York Times'' (October 5, 2003)]&lt;/ref&gt; having exerted a tremendous influence on the field both through his own works and those of his students.

==Death==
Israel Gelfand died at the [[Robert Wood Johnson University Hospital]] near his home in [[Highland Park, New Jersey]].  He was less than five weeks past his 96th birthday.  His death was first reported on the blog of his former collaborator Andrei Zelevinsky&lt;ref&gt;{{ru icon}} [http://avzel.blogspot.com/2009/10/blog-post_05.html "Скончался И.М. Гельфанд"] ("I.M. Gelfand has died"), accessed 2009-10-06&lt;/ref&gt; and confirmed a few hours later by an obituary in the Russian online newspaper ''Polit.ru''.&lt;ref&gt;[http://www.polit.ru/science/2009/10/06/imgelfand.html "5 октября ушел из жизни выдающийся математик Израиль Моисеевич Гельфанд. "Эпоха Гельфанда ушла, но она продолжится в существующих поколениях" {"Renowned Mathematician Israil Moiseyevich Gelfand Departed on October 5. Gelfand's era has gone, but it shall continue in succeeding generations"}]&lt;/ref&gt;

==Publications==
*{{Citation | last1=Gelfand | first1=I. M.| title=Lectures on linear algebra | url=https://books.google.com/books?id=1ebLTz_MtUcC | publisher=Courier Dover Publications | isbn=978-0-486-66082-0 | year=1998}}
*{{Citation | last1=Gelfand | first1=I. M. | last2=Fomin | first2=Sergei V. | editor1-last=Silverman | editor1-first=Richard A. | title=Calculus of variations | url=https://books.google.com/books?id=YkFLGQeGRw4C | publisher=Prentice-Hall Inc. | location=Englewood Cliffs, N.J. | isbn=978-0-486-41448-5 | year=1963 | mr=0160139}}
*{{Citation | last1=Gelfand | first1=I. | last2=Raikov | first2=D. | last3=Shilov | first3=G. | title=Commutative normed rings | origyear=1960 | url=https://books.google.com/books?id=K_CIW-oau88C | publisher=Chelsea Publishing Co. | location=New York | series=Translated from the Russian, with a supplementary chapter | year=1964 | mr=0205105 | isbn=978-0-8218-2022-3}}
*{{Citation | last1=Gel'fand | first1=I. M. | last2=Shilov | first2=G. E. | title=Generalized functions. Vol. I: Properties and operations | origyear=1958 | url=https://books.google.com/books?id=QoWBSgAACAAJ | publisher=[[Academic Press]] | location=Boston, MA | series=Translated by Eugene Saletan | isbn=978-0-12-279501-5 | year=1964 | mr=0166596}}&lt;ref name="GuilleminReview"&gt;{{cite journal|author=Guillemin, Victor|authorlink=Victor Guillemin|title=Review: ''Generalized functions'', by I. M. Gel'fand and G. E. Shilov|journal=Bull. Amer. Math. Soc. (N.S.)|year=1980|volume=3|issue=1, Part 1|pages=758–762|url=http://www.ams.org/journals/bull/1980-03-01/S0273-0979-1980-14813-2/|doi=10.1090/s0273-0979-1980-14813-2}}&lt;/ref&gt;
*{{Citation | last1=Gelfand | first1=I. M. | last2=Shilov | first2=G. E. | title=Generalized functions. Vol. 2. Spaces of fundamental and generalized functions | origyear=1958 | url=https://books.google.com/books?id=9mEPAQAAMAAJ | publisher=[[Academic Press]] | location=Boston, MA | series=Translated from the Russian by Morris D. Friedman, Amiel Feinstein and Christian P. Peltzer | isbn=978-0-12-279502-2 | year=1968 | mr=0230128}}&lt;ref name=GuilleminReview/&gt;
*{{Citation | last1=Gelfand | first1=I. M. | last2=Shilov | first2=G. E. | title=Generalized functions. Vol. 3: Theory of differential equations | origyear=1958 | publisher=[[Academic Press]] | location=Boston, MA | series=Translated from the Russian by Meinhard E. Mayer | year=1967 | mr=0217416}}&lt;ref name=GuilleminReview/&gt;
*{{Citation | last1=Gelfand | first1=I. M. | last2=Vilenkin | first2=N. Ya. | title=Generalized functions. Vol. 4: Applications of harmonic analysis | origyear=1961 | url=https://books.google.com/books?id=dd35YQEACAAJ | publisher=[[Academic Press]] | location=Boston, MA | series=Translated by Amiel Feinstein | isbn=978-0-12-279504-6 | year=1964 | mr=0173945}}&lt;ref name=GuilleminReview/&gt;
*{{Citation | last1=Gelfand | first1=I. M. | last2=Graev | first2=M. I. | last3=Vilenkin | first3=N. Ya. | title=Generalized functions. Vol. 5: Integral geometry and representation theory | origyear=1962 | publisher=[[Academic Press]] | location=Boston, MA | series=Translated from the Russian by Eugene Saletan | isbn=978-0-12-279505-3 | year=1966 | mr=0207913}}&lt;ref name=GuilleminReview/&gt;
*{{Citation | last1=Gelfand | first1=I. M. | last2=Graev | first2=M. I. | last3=Pyatetskii-Shapiro | first3=I. I. | title=Representation theory and automorphic functions | url=https://books.google.com/books?id=_p5qAAAAMAAJ | publisher=W. B. Saunders Co. | location=Philadelphia, Pa. | series=Translated from the Russian by K. A. Hirsch | isbn=978-0-12-279506-0 | year=1969 | mr=0233772}}
*{{Citation | last1=Gelfand | first1=Izrail M. | editor1-last=Gindikin | editor1-first=S. G. | editor2-last=Guillemin | editor2-first=V. W. | editor3-last=Kirillov | editor3-first=A. A. | editor4-last=Kostant | editor4-first=Bertram | editor5-last=Sternberg | editor5-first=Shlomo | editor5-link=Shlomo Sternberg | title=Collected papers. Vol. I | url=https://books.google.com/books?id=yJofAQAAIAAJ | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-13619-4 | year=1987 | mr=929821}}
*{{Citation | last1=Gelfand | first1=Izrail M. | editor1-last=Gindikin | editor1-first=S. G. | editor2-last=Guillemin | editor2-first=V. W. | editor3-last=Kirillov | editor3-first=A. A. | editor4-last=Kostant | editor4-first=Bertram | editor5-last=Sternberg | editor5-first=Shlomo | editor5-link=Shlomo Sternberg | title=Collected papers. Vol. II | url=https://books.google.com/books?id=Y5wfAQAAIAAJ | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-19035-6 | year=1988 | mr=929821}}
*{{Citation | last1=Gelfand | first1=Izrail M. | editor1-last=Gindikin | editor1-first=S. G. | editor2-last=Guillemin | editor2-first=V. W. | editor3-last=Kirillov | editor3-first=A. A. | editor4-last=Kostant | editor4-first=Bertram | editor5-last=Sternberg | editor5-first=Shlomo | editor5-link=Shlomo Sternberg | title=Collected papers. Vol. III | url=https://books.google.com/books?id=OunuAAAAMAAJ | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-19399-9 | year=1989 | mr=0997939}}
*{{Citation | last1=Gelfand | first1=I. M. | last2=Kapranov | first2=M.M. | last3=Zelevinsky | first3=A.V. | title=Discriminants, resultants, and multidimensional determinants | publisher=Boston: Birkhäuser | isbn=978-0-8176-3660-9 | year=1994}}&lt;ref&gt;{{cite journal|author=Catanese, Fabrizio|title=Review: ''Discriminants, resultants, and multidimensional determinants'', by I. M. Gelfand, M. M. Kapranov, and A. V. Zelevinsky|journal=Bull. Amer. Math. Soc. (N.S.)|year=2000|volume=37|issue=2|pages=183–198|url=http://www.ams.org/journals/bull/2000-37-02/S0273-0979-99-00858-7/|doi=10.1090/s0273-0979-99-00858-7}}&lt;/ref&gt;
*{{Citation | last1=Gelfand | first1=I. M. | last2=Gindikin | first2=S. G. | last3=Graev | first3=M. I. | title=Selected topics in integral geometry | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=Translations of Mathematical Monographs | isbn=978-0-8218-2932-5 | year=2003 | volume=220 | mr=2000133}}
*{{Citation | last1=Borovik | first1=Alexandre V. | last2=Gelfand | first2=I. M. | last3=White | first3=Neil | title=Coxeter matroids | url=https://books.google.com/books?id=-4jcuw8en5wC | publisher=Birkhäuser Boston | location=Boston, MA | series=Progress in Mathematics | isbn=978-0-8176-3764-4 | year=2003 | volume=216 | mr=1989953}}
*[http://bookstore.ams.org/chelgelfset/ ''Generalized Functions Volumes, 1-6''], American Math Society, (2015)

==See also==

*[[Gelfand duality]]
*[[Gelfand pair]]
*[[Gelfand ring]]
*[[Gelfand triple]]

== References ==
=== Citations ===
{{Reflist}}

=== Sources ===
{{refbegin}}
*[https://www.nytimes.com/2009/10/08/science/08gelfand.html?_r=1&amp;scp=1&amp;sq=Israel%20Gelfand&amp;st=cse Chang, Kenneth. "Israel Gelfand, Math Giant, Dies at 96", ''The New York Times'' (October 7, 2009)]
*[https://www.usatoday.com/news/nation/2009-10-09-top-mathematician-dies_N.htm "Leading mathematician Israel Gelfand dies in N.J." ''USA Today'' (October 9, 2009)]
*[http://www.philly.com/philly/obituaries/20091010_Israel_Gelfand___Top_mathematician__96.html "Israel Gelfand | Top mathematician, 96". ''The Philadelphia Inquirer'' (October 10, 2009)]
*[https://www.telegraph.co.uk/news/obituaries/science-obituaries/6440484/Israel-Gelfand.html "Israel Gelfand" ''The Daily Telegraph'' (October 27, 2009)]
{{refend}}

==External links==
*[http://israelmgelfand.com/index.html Israel Moiseevich Gelfand], dedicated site, maintained by Tatiana V. Gelfand and Tatiana I. Gelfand
*[https://www.telegraph.co.uk/news/obituaries/science-obituaries/6440484/Israel-Gelfand.html Israel Gelfand] - Daily Telegraph obituary
*[https://www.theguardian.com/science/2009/nov/08/israel-gelfand-obituary Israel Gelfand] - Guardian obituary
*{{MathGenealogy |id=17512}}
*{{MacTutor Biography|id=Gelfand}}
*[http://www.math.rutgers.edu/home/gelfand/ Web page at Rutgers]
*[http://www.math.rutgers.edu/~sontag/gelfand-publics.pdf List of publications].
*[http://www.ams.org/notices/200504/comm-steele.pdf Steele Prize citation].
*[https://web.archive.org/web/20130729134201/http://www.scribd.com/doc/45316780/The-Unity-of-Mathematics-In-Honor-of-the-Ninetieth-Birthday-of-I-M-Gelfand The unity of mathematics – In honor of the ninetieth burthday of I. M. Gelfand]
*Interview: "A talk with professor I. M. Gelfand.", recorded by V. Retakh and A. Sosinsky, Kvant (1989), no. 1, 3–12 (in Russian). English translation in: Quantum (1991), no. 1, 20–26. ([http://israelmgelfand.com/talks/quantum_interview.pdf Link])

{{Wolf Prize in Mathematics}}

{{Authority control}}

{{DEFAULTSORT:Gelfand, Israel}}
[[Category:1913 births]]
[[Category:2009 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:American people of Russian-Jewish descent]]
[[Category:American people of Ukrainian-Jewish descent]]
[[Category:Foreign Members of the Royal Society]]
[[Category:Full Members of the Russian Academy of Sciences]]
[[Category:Full Members of the USSR Academy of Sciences]]
[[Category:Functional analysts]]
[[Category:Kyoto laureates in Basic Sciences]]
[[Category:MacArthur Fellows]]
[[Category:Mathematical analysts]]
[[Category:Members of the French Academy of Sciences]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Moscow State University alumni]]
[[Category:Operator theorists]]
[[Category:Soviet biologists]]
[[Category:20th-century biologists]]
[[Category:Soviet emigrants to the United States]]
[[Category:Soviet Jews]]
[[Category:Soviet mathematicians]]
[[Category:People from Highland Park, New Jersey]]
[[Category:People from Krasni Okny Raion]]
[[Category:People from Kherson Governorate]]
[[Category:Recipients of the Order of Lenin]]
[[Category:Recipients of the Order of Friendship of Peoples]]
[[Category:Stalin Prize winners]]
[[Category:Lenin Prize winners]]
[[Category:Ukrainian emigrants to the United States]]
[[Category:Ukrainian Jews]]
[[Category:Wolf Prize in Mathematics laureates]]
[[Category:Textbook writers]]
[[Category:Fluid dynamicists]]</text>
      <sha1>ct8eaur9a17gc5452jb77l2k9wsqwqi</sha1>
    </revision>
  </page>
  <page>
    <title>Jack Copeland</title>
    <ns>0</ns>
    <id>5717942</id>
    <revision>
      <id>869384523</id>
      <parentid>850420844</parentid>
      <timestamp>2018-11-18T07:26:02Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */recategorize</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13023">{{for|the American transplant surgeon|Jack Copeland (surgeon)}}
{{Use British English|date=May 2012}}
{{Use dmy dates|date=May 2012}}
{{Infobox scientist
| image             = Jack Copeland IMG 2109.jpg
| image_size        = 
| caption           = 
| birth_name        = Brian Jack Copeland
| birth_date        = {{Birth year and age|1950|}}
| birth_place       = United Kingdom
| death_date        = 
| death_place       = 
| nationality       = British
| fields            = Philosophy, [[logic]]
| workplaces        = [[University of Plymouth]]&lt;br /&gt;[[University of Canterbury]]
| alma_mater        = [[Corpus Christi College, Oxford]]
| residence         = [[Christchurch]], New Zealand
| doctoral_advisor  = [[Dana Scott]]&lt;ref&gt;{{MathGenealogy|93763}}&lt;/ref&gt;
| doctoral_students = 
| known_for         = Study of [[Alan Turing]]
| awards            = 
}}

'''Brian Jack Copeland''' (born 1950) is Professor of Philosophy at the [[University of Canterbury]], [[Christchurch]], [[New Zealand]], and author of books on the computing pioneer [[Alan Turing]].

==Overview==
Jack Copeland's education includes a [[BPhil]] and a [[DPhil]] from the [[University of Oxford]] in philosophy, where he undertook research on [[modal logic|modal]] and [[non-classical logic]] under the supervision of [[Dana Scott]].&lt;ref&gt;{{cite web | url=http://genealogy.math.ndsu.nodak.edu/id.php?id=93763  | title=John Copeland | publisher=[[North Dakota State University]] |work=[[Mathematics Genealogy Project]] | accessdate=26 December 2011}}&lt;/ref&gt;

Jack Copeland is the Director of the Turing Archive for the History of Computing,&lt;ref&gt;{{cite web| url=http://www.alanturing.net/ | title=Turing Archive for the History of Computing }}&lt;/ref&gt; an extensive online archive on the computing pioneer [[Alan Turing]]. He has also written and edited books on Turing.  He is one of the people responsible for identifying the concept of [[hypercomputation]] and machines more capable than [[Turing machine]]s.

Copeland has held visiting professorships at the [[University of Sydney]], Australia (1997, 2002), the [[University of Aarhus]], Denmark (1999), the [[University of Melbourne]], Australia (2002, 2003), and the [[University of Portsmouth]], United Kingdom (1997–2005). In 2000, he was a Senior Fellow in the [[Dibner Institute for the History of Science and Technology]]&lt;ref&gt;{{cite web| url=http://dibinst.mit.edu/ | title=Dibner Institute for the History of Science and Technology | publisher=[[Massachusetts Institute of Technology]] | location=USA }}&lt;/ref&gt; at the [[Massachusetts Institute of Technology]], United States.

Copeland is also President of the US Society for Machines and Mentality&lt;ref&gt;[http://www.cs.hamilton.edu/~sfmm/ Society for Machines and Mentality] {{webarchive|url=https://web.archive.org/web/20070608134140/http://www.cs.hamilton.edu/~sfmm/ |date=8 June 2007 }}, USA.&lt;/ref&gt; and a member of the UK [[Bletchley Park]] Trust Heritage Advisory Panel. He is the founding editor of ''[[The Rutherford Journal]]'', established in 2005.

Copeland was awarded Lecturer of the Year 2010 by the University of Canterbury's student union.&lt;ref&gt;{{cite web|publisher=UCSA |title=CANTA survey |location=New Zealand |url=http://canta.co.nz/media/uploads/2011_03/Canta_22.pdf |date=March 2011 |deadurl=yes |archiveurl=https://web.archive.org/web/20130206073645/http://canta.co.nz/media/uploads/2011_03/Canta_22.pdf |archivedate=6 February 2013 |df=dmy }}&lt;/ref&gt;

==''The Rutherford Journal''==
{{Infobox journal
| title = The Rutherford Journal 
| cover =
| abbreviation=Rutherford J.
| editor = Jack Copeland&lt;ref&gt;{{cite web| url=http://www.canterbury.ac.nz/spark/researcher.aspx?researcherid=86390 | title=Distinguished Professor Jack Copeland | publisher=[[University of Canterbury]] | location=New Zealand | accessdate=7 December 2016 }}&lt;/ref&gt;
| discipline = [[History of science|History]] and [[philosophy of science]]
&lt;!-- | abbreviation = Rutherford J. --&gt;
| publisher = [[University of Canterbury]]
| country = [[New Zealand]]
| frequency = 
| history = 2005 onwards
| website = http://www.rutherfordjournal.org
| ISSN = 1177-1380
| OCLC = 145735058
| italic title=no
}}
Jack Copeland is [[editor-in-chief]] of '''''The Rutherford Journal''''', a [[Peer review|peer-reviewed]] online [[academic journal]] published in [[New Zealand]]&lt;ref&gt;{{cite web| url=http://www.indexnz.com/Top/Education/Academic-Journals/2 | title=New Zealand &gt; Education &gt; Academic Journals | work=indexNS | accessdate=7 December 2016 }}&lt;/ref&gt; that covers the [[History of science|history]] and [[philosophy of science]] and [[philosophy of technology|technology]].&lt;ref name="about"&gt;[http://www.rutherfordjournal.org/about.html About the Journal], ''The Rutherford Journal''.&lt;/ref&gt;&lt;ref&gt;{{cite article| last=Jenkin | first=John | title=Review of Copeland, Jack, ed., The Rutherford Journal: the New Zealand Journal for the History and Philosophy of Science and Technology (2005) | journal=[[Historical Records of Australian Science]] | volume=17 | number=2 | date=2006 | pages=298–299 }}&lt;/ref&gt; The journal is published as needed and was established in December 2005 by Copeland.&lt;ref&gt;{{cite web | url=http://hapi.uq.edu.au/professor-jack-copeland | title=Professor Jack Copeland | work=[[Archive.org]] | publisher=[[The University of Queensland]] | location=Australia | accessdate=4 January 2014 | deadurl=bot: unknown | archiveurl=https://web.archive.org/web/20150326030020/http://hapi.uq.edu.au/professor-jack-copeland | archivedate=26 March 2015 | df=dmy-all }}&lt;/ref&gt; The full text of articles is freely available online in [[HTML]] format.

''The Rutherford Journal'' is named after the [[chemistry|chemist]] and [[physics|physicist]] [[Ernest Rutherford]] (1871–1937),&lt;ref&gt;{{cite web| url=http://atomictheoryfinal.weebly.com/ernest-rutherford.html | title=Rutherford's Experiment | work=Atomic Theory | accessdate=7 December 2016 }}&lt;/ref&gt; a New Zealander, who studied for a BA at the [[University of Canterbury|Canterbury College]] ([[Christchurch]]) in 1890.&lt;ref&gt;{{cite article| first=Simon | last=Clarke | url=http://www.rutherfordjournal.com/article010112.html | title=Rutherford at Canterbury University College | journal=The Rutherford Journal | volume=1 | date=December 2005 }}&lt;/ref&gt;

The journal is indexed as an [[open access]] scholarly resource and journal&lt;ref name="road"&gt;{{cite web| url=http://road.issn.org/issn/1177-1380-the-rutherford-journal#.WEgbZvmLREY | title=The Rutherford Journal | work=Directory of Open Access Scholarly Resources | publisher=ROAD | accessdate=7 December 2016 }}&lt;/ref&gt;&lt;ref name="journalindex"&gt;{{cite web| url=http://www.journalindex.net/visit.php?j=7606 | title=The Rutherford Journal | work=JournalIndex.net | accessdate=7 December 2016 }}&lt;/ref&gt; and in various index lists.&lt;ref name="intute"&gt;{{cite web| url=http://www.intute.ac.uk/cgi-bin/fullrecord.pl?handle=20070427-161734 | title=Rutherford Journal: the New Zealand journal for the history and philosophy of science and technology | publisher=[[Intute]] | location=UK | accessdate=7 December 2016 }}&lt;/ref&gt;&lt;ref name="alanturing"&gt;{{cite web| url=http://www.alanturing.net/turing_archive/pages/links.html | title=History and Theory of Computation Sites | work=AlanTuring.net | accessdate=4 January 2014 }}&lt;/ref&gt; It was listed in an article on [[electronic journal]]s in the Journal for the Association of History and Computing&lt;ref&gt;{{cite article| url=http://hdl.handle.net/2027/spo.3310410.0010.307 | title=E-Journals – Inside and Out | work=Journal of the Association of History and Computing | location=Ann Arbor, MI | publisher=MPublishing | first=Lynn C. | last=Westney | volume=10 | number=3 | date=December 2007 }}&lt;/ref&gt; and included in the ''Isis Current Bibliography of the History of Science and Its Cultural Influences''.&lt;ref&gt;{{cite article| title=Current Bibliography of the History of Science and Its Cultural Influences | journal=[[Isis (journal)|Isis]] | volume=101 | number=S1 | date=December 2010 | pages=1–305 | publisher=[[University of Chicago Press]] / [[History of Science Society]] | doi=10.1086/660768 }}&lt;/ref&gt; The journal features technology as diverse as [[totalisator]]s&lt;ref&gt;{{cite web| url=http://hackaday.com/2015/11/04/tote-boards-the-impressive-engineering-of-horse-gambling/ | title=Tote Boards: The Impressive Engineering of Horse Gambling | work=Hackaday | first=Kristina | last=Panos | date=4 November 2015 | accessdate=7 December 2016 }}&lt;/ref&gt; and the [[CSIRAC]] computer.&lt;ref&gt;{{cite web| url=http://www.godzillaseamonkey.com/was-george-julius-the-inspiration-for-csirac-australias-first-electronic-digital-computer/ | title=Was George Julius the inspiration for CSIRAC, Australia’s first electronic digital computer? | first=Don | last=McKenzie | work=Godzilla Sea Monkey | date=12 March 2011 | accessdate=7 December 2016 }}&lt;/ref&gt;

==Books==
* ''[[Artificial Intelligence]]: A Philosophical Introduction'' ([[Blackwell Publishing|Blackwell]], 1993, 2nd edition due) {{ISBN|0-631-18385-X}}
* ''Logic and Reality Essays on the Legacy of [[Arthur Prior]]'' ([[Oxford University Press]], 1996) {{ISBN|0-19-824060-0}}
* ''The Essential Turing'' (Oxford University Press, 2004) {{ISBN|0-19-825080-0}}&lt;ref&gt;{{cite article| title=The essential Turing, Copeland Jack (ed). Pp. 613. £50 (hbk). £14.99 (pbk). 2004. {{ISBN|0 19 825079 7}} (hbk); {{ISBN|0 19 825080 0}} (pbk) (Oxford University Press) | first=S. C. | last=Coutinho | date=March 2006 | doi=10.1017/S0025557200179513 |volume=90 | number=517 | pages=185–186 | journal=[[The Mathematical Gazette]] | publisher=[[Cambridge University Press]] }}&lt;/ref&gt;
* ''Alan Turing’s [[Automatic Computing Engine]]: The Master Codebreaker's Struggle to Build the Modern Computer'' (Oxford University Press, 2005) {{ISBN|0-19-856593-3}}
* ''[[Colossus computer|Colossus]]: The Secrets of Bletchley Park's Codebreaking Computers'' (Oxford University Press, 2006) {{ISBN|0-19-284055-X}}&lt;ref&gt;{{cite news| title=The Colossus of codes: Georgina Ferry on four new books that tackle the story of Bletchley Park's other decryption machine | first=Georgina | last=Ferry | date=29 July 2006 | newspaper=[[The Guardian]] | location=UK }}&lt;/ref&gt;
* ''Alan Turing’s Electronic Brain: The Struggle to Build the ACE, the World’s Fastest Computer'' (Oxford University Press, 2012) {{ISBN|978-0199609154}}&lt;ref name="ams"&gt;{{cite article| title=His Just Deserts: A Review of Four Books | first=Alvy Ray | last=Smith | date=September 2014 | pages=891–895 | journal=[[Notices of the AMS]] | publisher=[[American Mathematical Society]] | url=http://www.ams.org/notices/201408/rnoti-p891.pdf }}&lt;/ref&gt;
* ''Computability: Turing, [[Kurt Gödel|Gödel]], [[Alonzo Church|Church]], and Beyond'' ([[MIT Press]], 2013). {{ISBN|978-0262527484}} (with [[Carl Posy]] and [[Oron Shagrir]])
* ''Turing: Pioneer of the Information Age'' (Oxford University Press, 2014: Paperback edition) {{ISBN|978-0198719182}}&lt;ref name="ams" /&gt;&lt;ref&gt;{{cite news| title=Turing: Pioneer of the Information Age, by Jack Copeland | first=Tom | last=Moriarty | date=18 January 2015 | newspaper=[[The Irish Times]] }}&lt;/ref&gt;&lt;ref&gt;{{cite article| title=Review Essay: B. Jack Copeland, Turing: Pioneer of the Information Age (Oxford University Press, 2012) | first=Colin | last=Hughes | date=Summer 2016 | volume=15 | number=2–3 | journal=[[Logos: A Journal of Modern Society and Culture]] }}&lt;/ref&gt;&lt;ref&gt;{{cite article| title=Turing: Pioneer of the Information Age, by B. Jack Copeland | first=Juan A. | last=Añel | date=9 September 2013 | doi=10.1080/00107514.2013.836246Colin |volume=54 | number=5 | journal=[[Contemporary Physics]] }}&lt;/ref&gt;
* ''[[The Turing Guide]]'' (Oxford University Press, 2017) {{ISBN|978-0198747826}} (hardcover), {{ISBN|978-0198747833}} (paperback)&lt;ref&gt;{{cite article| authorlink=W. Andrew Robinson | last=Robinson | first=Andrew | url=https://www.newscientist.com/article/mg23331072-700-the-turing-guide-last-words-on-an-enigmatic-codebreaker/ | title=The Turing Guide: Last words on an enigmatic codebreaker? | journal=[[New Scientist]] | date=4 January 2017 }}&lt;/ref&gt; (with [[Jonathan Bowen]], [[Robin Wilson (mathematician)|Robin Wilson]], Mark Sprevak, et al.)

==References==
{{reflist|2}}

==External links==
* [http://www.arts.canterbury.ac.nz/philosophy/people/copeland.shtml Home page]
* [http://www.alanturing.net/turing_archive AlanTuring.net]
* [http://www.rutherfordjournal.org/article040101.html Alan Turing: Father of the Modern Computer]
* {{AcademicSearch|325889}} 
* {{DBLP|name=B. Jack Copeland}}

{{Authority control}}

{{DEFAULTSORT:Copeland, Jack}}
[[Category:1950 births]]
[[Category:Living people]]
[[Category:Alumni of Corpus Christi College, Oxford]]
[[Category:English philosophers]]
[[Category:New Zealand philosophers]]
[[Category:Historians of science]]
[[Category:Historians of mathematics]]
[[Category:Academics of the University of Portsmouth]]
[[Category:University of Canterbury faculty]]
[[Category:Academic journal editors]]
[[Category:English male non-fiction writers]]</text>
      <sha1>s2qydjj9ukxfvbnbh1amwzqw2rkcbxt</sha1>
    </revision>
  </page>
  <page>
    <title>Jack Edmonds</title>
    <ns>0</ns>
    <id>3625459</id>
    <revision>
      <id>850895213</id>
      <parentid>847832108</parentid>
      <timestamp>2018-07-18T17:47:38Z</timestamp>
      <contributor>
        <username>S142857</username>
        <id>27441559</id>
      </contributor>
      <comment>/* Career */ Replaced broken link with a archive.org snapshot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8892">'''Jack R. Edmonds''' (born April 5, 1934) is an American [[computer scientist]], regarded as one of the most important contributors to the field of [[combinatorial optimization]].

==Research==
A breakthrough contribution of Edmonds is the [[Cobham–Edmonds thesis]], defining the concept of polynomial time characterising the difference between a practical and an impractical algorithm (in modern terms, a [[tractable problem]] or intractable problem). Today, problems solvable in polynomial time are called the [[complexity class]] '''[[PTIME]]''', or simply '''[[P (complexity)|P]]'''. Another of Edmonds' earliest and most notable contributions is the [[blossom algorithm]] for constructing [[maximum matching]]s on graphs, discovered in 1961&lt;ref name = "glimpse"&gt;{{Citation
 | last = Edmonds
 | first = Jack 
 | contribution = A glimpse of heaven
 | year = 1991
 | title = History of Mathematical Programming --- A Collection of Personal Reminiscences
 | editor = J.K. Lenstra |editor2=A.H.G. Rinnooy Kan |editor3=A. Schrijver, ed.
 | pages = 32–54
 | publisher = CWI, Amsterdam and North-Holland, Amsterdam }}&lt;/ref&gt; and published in 1965.&lt;ref name = "algorithm"&gt;
{{cite journal
  | doi = 10.4153/CJM-1965-045-4
  | author = Edmonds, Jack
  | title = Paths, trees, and flowers
  | journal = Can. J. Math.
  | volume = 17
  | year = 1965
  | pages = 449&amp;ndash;467
}}&lt;/ref&gt; This was the first polynomial-time algorithm for maximum matching in graphs. Its generalization to weighted graphs&lt;ref name = "weighted"&gt;
{{cite journal
  | author = Edmonds, Jack
  | title = Maximum matching and a polyhedron with 0,1-vertices
  | journal = Journal of Research of the National Bureau of Standards Section B
  | volume = 69
  | year = 1965
  | pages = 125&amp;ndash;130
}}&lt;/ref&gt; was a conceptual breakthrough in the use of [[linear programming]] ideas in [[combinatorial optimization]]. It sealed in the importance of there being proofs, or "witnesses", that the answer for an instance is yes and there being proofs, or "witnesses", that the answer for an instance is no. In this blossom algorithm paper, Edmonds also characterizes feasible problems as those solvable in polynomial time; this is one of the origins of the [[Cobham–Edmonds thesis]].&lt;ref&gt;{{cite book |title=Algorithms and Complexity |first=Gerard |last=Meurant |year=2014 |isbn=978-0-08093391-7 |page=[https://books.google.com/books?id=6WriBQAAQBAJ&amp;pg=PA4&amp;dq=Edmonds p. 4] |quote=A problem is said to be ''feasible'' if it can be solved in polynomial time (as stated for the first time in Edmonds [26] [1965, Paths, trees, and flowers])).}}&lt;/ref&gt;

Additional landmark work of Edmonds is in the area of [[matroids]]. He found a polyhedral description for all [[spanning tree]]s of a graph, and more generally for all independent sets of a matroid.&lt;ref name = "matroid"&gt;
{{cite journal
  | author = Edmonds, Jack
  | title = Matroids and the greedy algorithm
  | journal = Math. Programming (Princeton Symposium Math. Prog. 1967)
  | volume = 1
  | year = 1971
  | pages = 127&amp;ndash;136
}}&lt;/ref&gt; Building on this, as a novel application of linear programming to discrete mathematics, he proved the [[matroid intersection]] theorem, a very general combinatorial min-max theorem&lt;ref name="intersection"&gt;{{citation
 | last = Edmonds
 | first = Jack
 | contribution = Submodular functions, matroids, and certain polyhedra
 | editor = R. Guy |editor2=H. Hanam |editor3=N. Sauer |editor4=J. Schonheim
 | title = Combinatorial structures and their applications (Proc. 1969 Calgary Conference)
 | pages = 69&amp;ndash;87
 | publisher = Gordon and Breach, New York
 | year = 1970
}}.&lt;/ref&gt;&lt;ref name="eureka" /&gt; which, in modern terms, showed that the matroid intersection problem lay in both [[NP (complexity)|NP]] and [[co-NP]].

Edmonds is well known for his theorems on [[Chu–Liu/Edmonds algorithm|max-weight branching algorithms]]&lt;ref name = "wbranchings"&gt;
{{cite journal
  | author = Edmonds, Jack
  | title = Optimum Branchings
  | journal = J. Res. Nat. Bur. Standards
  | year = 1967
  | volume = 71B
  | pages = 233&amp;ndash;240
}}&lt;/ref&gt; and packing edge-disjoint branchings&lt;ref name = "branchings"&gt;
{{citation 
  | author = Edmonds, Jack
  | title = Edge-disjoint branchings
  | journal = Combinatorial Algorithms (Courant Computer Science Symposium 9, Monterey, California, 1972; R. Rustin, ed.)
  | publisher = Algorithmics Press, New York
  | year = 1973
  | pages = 91&amp;ndash;96
}}&lt;/ref&gt; and his work with [[Richard Karp]] on [[Edmonds–Karp algorithm|faster flow algorithms]]. The Edmonds–[[Tibor Gallai|Gallai]] decomposition theorem describes finite graphs from the point of view of matchings. He introduced [[polymatroid]]s,&lt;ref name="intersection" /&gt; [[submodular]] flows with Richard Giles,&lt;ref name = "subflows"&gt;
{{citation 
  |author1=Edmonds, Jack  |author2=Giles, Richard
  | title = A min-max relation for submodular functions on graphs
  | journal = Studies in Integer Programming (Proceedings Workshop on Integer Programming, Bonn, 1975; P.L. Hammer, E.L. Johnson, B.H. Korte, G.L. Nemhauser, eds.)
  | volume = 1
  | series = Annals of Discrete Mathematics
  | publisher = North-Holland, Amsterdam
  | year = 1977
  | pages = 185&amp;ndash;204
}}&lt;/ref&gt; and the terms [[clutter (mathematics)|clutter]] and blocker in the study of [[hypergraph]]s.&lt;ref name = "glimpse" /&gt; A recurring theme in his work&lt;ref name="Witzgall"&gt;
{{citation 
  | author = Christoph Witzgall
  | contribution = Paths, Trees, and Flowers
  | title = A Century of Excellence in Measurements, Standards, and Technology
  | publisher = National Institute of Standards and Technology 
  | year = 2001
  | pages = 140&amp;ndash;144
  | url = http://nvl.nist.gov/pub/nistpubs/sp958-lide/140-144.pdf
}}&lt;/ref&gt; is to seek algorithms whose time complexity is polynomially bounded by their input size and bit-complexity.&lt;ref name = "glimpse" /&gt;

==Career==
Edmonds graduated with a baccalaureate degree from [[George Washington University]] in 1958, and obtained a master's degree from the [[University of Maryland, College Park|University of Maryland]] in 1959, with a thesis on the problem of embedding graphs
into surfaces.

From 1959 to 1969 he worked at the [[National Institute of Standards and Technology]] (then the National Bureau of Standards), and was a founding member of [[Alan J. Goldman|Alan Goldman]]’s newly created Operations Research Section in 1961.

From 1969 on, with the exception of 1991-1993, he held a faculty position at the Department of Combinatorics and Optimization at the [[University of Waterloo]]'s [[University of Waterloo Faculty of Mathematics|Faculty of Mathematics]]. He supervised the doctoral work of a dozen students in this time.

From 1991 to 1993, he was involved in a dispute ("the Edmonds affair") with the University of Waterloo,&lt;ref&gt;[https://web.archive.org/web/20120605150100/http://www.communications.uwaterloo.ca/Gazette/1992/Gazette,%20October%207,%201992/CAUT%20called%20in%20on%20Jack%20Edmonds%20case UW Gazette, October 7, 1992: CAUT called in on Jack Edmonds case]&lt;/ref&gt;&lt;ref&gt;[http://arts.uwaterloo.ca/~kwesthue/workplmobintro Editor's introduction], in: Kenneth Westhues, ed., Workplace Mobbing in Academe: Reports from Twenty Universities, Lewiston: NY: The Edwin Mellen Press, 2004&lt;/ref&gt; wherein the university claimed that a letter submitted constituted a letter of resignation, which Edmonds denied.&lt;ref&gt;[http://www.bulletin.uwaterloo.ca/2001/mar/05mo.html University of Waterloo Daily Bulletin, March 5 2001: Conference honours Jack Edmonds]&lt;/ref&gt; The conflict was resolved in 1993, and he returned to the university.

Edmonds retired in 1999. The fifth [[Aussois]] Workshop on Combinatorial Optimization in 2001 was dedicated to him.&lt;ref name = "eureka"&gt;
{{citation |editor1=Jünger, Michael |editor2=Reinelt, Gerhard |editor3=Rinaldi, Giovanni | title = Combinatorial Optimization -- Eureka, You Shrink! | journal = Lecture Notes in Computer Science |volume=2570 | publisher = Springer | year = 2003}}&lt;/ref&gt;

==Personal life==
Jack's son Jeff Edmonds is a professor of computer science at [[York University]], and his wife Kathie Cameron is a professor of mathematics at [[Laurier University]].

== See also ==
* [[Edmonds matrix]]

==References==
&lt;references/&gt;

==External links==
* {{MathGenealogy |id=44142}}
* [https://www.informs.org/content/view/full/271949 Biography of Jack Edmonds] from the Institute for Operations Research and the Management Sciences

{{John von Neumann Theory Prize recipients}}
{{Authority control}}

{{DEFAULTSORT:Edmonds, Jack}}
[[Category:Combinatorialists]]
[[Category:John von Neumann Theory Prize winners]]
[[Category:Canadian mathematicians]]
[[Category:20th-century mathematicians]]
[[Category:University of Waterloo faculty]]
[[Category:1934 births]]
[[Category:Living people]]
[[Category:Combinatorial optimization]]
[[Category:Canadian computer scientists]]</text>
      <sha1>6i45cl97osjy1a8cztr02a9i8i9d0td</sha1>
    </revision>
  </page>
  <page>
    <title>List of calculus topics</title>
    <ns>0</ns>
    <id>337876</id>
    <revision>
      <id>869216327</id>
      <parentid>868126128</parentid>
      <timestamp>2018-11-17T04:22:05Z</timestamp>
      <contributor>
        <ip>124.109.58.36</ip>
      </contributor>
      <comment>/* Integral calculus */Fixed typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4263">{{Calculus}}
This is a '''list of [[calculus]] topics'''.

==Limits==
* [[Limit (mathematics)]]
* [[Limit of a function]]
** [[One-sided limit]]
* [[Limit of a sequence]]
* [[Indeterminate form]]
&lt;!-- *[[Wikisource:Table of common limits|Table of common limits]] There is something wrong with this link. Right. It doesn't exist as of 2006-02-09. --&gt;
* [[Orders of approximation]]
* [[(ε, δ)-definition of limit]]
Deriviablity &amp; continuty

==[[Differential calculus]]==
* [[Derivative]]
* [[Notation for differentiation|Notation]]
** [[Newton's notation for differentiation]]
** [[Leibniz's notation for differentiation]]
* Simplest rules
** [[Derivative of a constant]]
** [[Sum rule in differentiation]]
** [[Constant factor rule in differentiation]]
** [[Linearity of differentiation]]
** [[Power rule]]
* [[Chain rule]]
* [[local linearization]]
* [[Product rule]]
* [[Quotient rule]]
* [[Inverse functions and differentiation]]
* [[Implicit differentiation]]
* [[Stationary point]]
** [[Maxima and minima]]
** [[First derivative test]]
** [[Second derivative test]]
** [[Extreme value theorem]]
* [[Differential equation]]
* [[Differential operator]]
* [[Newton's method]]
* [[Taylor's theorem]]
* [[L'Hôpital's rule]]
* [[General Leibniz rule]]
* [[Mean value theorem]]
* [[Logarithmic derivative]]
* [[Differential (calculus)]]
* [[Related rates]]
* [[Regiomontanus' angle maximization problem]]

* [[Rolle's theorem]]

==Integral calculus==
* [[Antiderivative|Antiderivative/Indefinite integral]]
* Simplest rules
** [[Sum rule in integration]]
** [[Constant factor rule in integration]]
** [[Linearity of integration]]
* [[Arbitrary constant of integration]]
* [[Fundamental theorem of calculus]]
* [[Integration by parts]]
* [[Inverse chain rule method]]
* [[Integration by substitution]]
** [[Tan of integration
* [[Differentiation under the integral sign]]
* [[Trigonometric substitution]]
* [[Partial fractions in integration]]
** [[Quadratic integral]]
* [[Proof that 22/7 exceeds π]]
* [[Trapezium rule]]
* [[Integral of the secant function]]
* [[Integral of secant cubed]]
* [[Arclength]]
* [[Shell integration]]

==Special functions and numbers==
* [[Natural logarithm]]
* [[e (mathematical constant)]]
* [[Exponential function]]
* [[Hyperbolic angle]]
* [[Hyperbolic function]]
* [[Stirling's approximation]]
* [[Bernoulli number]]s

==[[Numerical integration]]==
''See also [[list of numerical analysis topics]]''
* [[Rectangle method]]
* [[Trapezium rule]]
* [[Simpson's rule]]
* [[Newton–Cotes formulas]]
* [[Gaussian quadrature]]

==Lists and tables==
* [[Table of limits|Table of common limits]]
* [[Table of derivatives]]
* [[Table of integrals]]
* [[Table of mathematical symbols]]
* [[List of integrals]]
* [[List of integrals of rational functions]]
* [[List of integrals of irrational functions]]
* [[List of integrals of trigonometric functions]]
* [[List of integrals of inverse trigonometric functions]]
* [[List of integrals of hyperbolic functions]]
* [[List of integrals of exponential functions]]
* [[List of integrals of logarithmic functions]]
* [[List of integrals of area functions]]

==Multivariable==
* [[Partial derivative]]
* [[Disk integration]]
* [[Gabriel's horn]]
* [[Jacobian matrix]]
* [[Hessian matrix]]
* [[Curvature]]
* [[Green's theorem]]
* [[Divergence theorem]]
* [[Stokes' theorem]]

==Series==
* [[Infinite series]]
* [[Maclaurin series]], [[Taylor series]]
* [[Fourier series]]
* [[Euler–Maclaurin formula]]

==History==
* [[Adequality]]
* [[Infinitesimal]]
** [[Archimedes' use of infinitesimals]]
* [[Gottfried Leibniz]]
* [[Isaac Newton]]
* ''[[Method of Fluxions]]''
* [[Infinitesimal calculus]]
* [[Brook Taylor]]
* [[Colin Maclaurin]]
* [[Leonhard Euler]]
* [[Gauss]]
* [[Joseph Fourier]]
* [[Law of continuity]]
* [[History of calculus]]
* [[Generality of algebra]]

==Nonstandard calculus==
* ''[[Elementary Calculus: An Infinitesimal Approach]]''
* [[Nonstandard calculus]]
* [[Infinitesimal]]
* [[Archimedes' use of infinitesimals]]

For further developments: see [[list of real analysis topics]], [[list of complex analysis topics]], [[list of multivariable calculus topics]].

[[Category:Mathematics-related lists|Calculus]]
[[Category:Calculus| ]]
[[Category:Lists of topics|Calculus]]</text>
      <sha1>15gvwkziotfsiivutlcjthv9hxd4p6n</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after Évariste Galois</title>
    <ns>0</ns>
    <id>39664285</id>
    <revision>
      <id>869814713</id>
      <parentid>699872742</parentid>
      <timestamp>2018-11-20T15:18:20Z</timestamp>
      <contributor>
        <username>Cocorrector</username>
        <id>35063181</id>
      </contributor>
      <comment>[[Galois axis]] is added</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="749">These are things named after [[Évariste Galois]] (1811–1832), a French mathematician.
*[[Absolute Galois group]]
*[[Differential Galois theory]]
*[[Galois axis]]
*[[Galois closure]]
*[[Galois cohomology]]
*[[Galois connection]]
*[[Galois/Counter Mode]]
*[[Galois covering]]
*[[Galois (crater)]]
*[[Galois deformation]]
*[[Galois descent]]
*[[Galois extension]]
*[[Galois field]]
*[[Galois geometry]]
*[[Galois group]]
*[[Linear feedback shift register#Galois LFSRs|Galois LFSRs]]
*[[Galois module]]
*[[Galois representation]]
*[[Galois sequence]]
**[[Inverse Galois sequence]]
*[[Galois theory]]
*[[Inverse Galois problem]]

{{DEFAULTSORT:List of things named after Evariste Galois}}
[[Category:Lists of things named after mathematicians|Galois]]</text>
      <sha1>bdllky4q3lb2qs0kuy6j9applfg27gu</sha1>
    </revision>
  </page>
  <page>
    <title>Logical machine</title>
    <ns>0</ns>
    <id>5989279</id>
    <revision>
      <id>744946537</id>
      <parentid>741094047</parentid>
      <timestamp>2016-10-18T11:36:45Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* Bibliography */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3802">A '''logical machine''' is a [[tool]] containing a set of parts that uses energy to perform [[formal logic]] operations.  Early logical machines were mechanical devices that performed basic operations in [[Boolean logic]].  Contemporary logical machines are computer-based electronic programs that perform proof assistance with theorems in mathematical logic.  In the 21st century, these proof assistant programs have given birth to a new field of study called [[mathematical knowledge management]].

==Origins==
The earliest logical machines were mechanical constructs built in the late 19th century.  [[William Stanley Jevons]] invented the first logical machine in 1869, the logic piano.{{sfn|Bennett|2005|pp=162-3}}  In 1883, Allan Marquand invented a new logical machine that performed the same operations as Jevons' logic piano but with improvements in design simplification, portability, and input-output controls.{{sfn|Bennett|2005|p=163}}

==See also==
{{Portal|Mathematics}}
*[[Allan Marquand]]
*[[William Stanley Jevons]]
*[[Logics for computability]]

==References==
{{Reflist}}

== Bibliography ==
*{{cite book|last1=Bennett|first1=Deborah|title=Logic Made Easy: How to Know When Language Deceives You|date=2005|publisher=W. W. Norton &amp; Company|isbn=0393326926|url=https://books.google.com/books?id=wB10fzJgQ68C&amp;pg=PA163&amp;dq=Allan+Marquand+logic+machine&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwitoK_ImafPAhVM9YMKHQL6D68Q6AEILDAB#v=onepage&amp;q&amp;f=false|accessdate=24 September 2016}}   
* Marquand, Allan
** (1883), "A Machine for Producing Syllogistic Variation" in C.&amp;nbsp;S. Peirce, ed., ''[[Charles Sanders Peirce bibliography#SIL|Studies in Logic]]'', pp.&amp;nbsp;12–15, along with "Note on an Eight-Term Logical Machine", p.&amp;nbsp;16. Google Books [https://books.google.com/books?id=V7oIAAAAQAAJ&amp;jtp=12 Eprint]. Book reprinted 1983 with introduction by Max Fisch.
** (1886), "A New Logical Machine", ''Proceedings of the American Academy of Arts and Sciences'' '''21''': 303–07. Google Books [https://books.google.com/books?id=pwj3K__QWKkC&amp;pg=PA303 Eprint].
* Peirce, C. S. 
** (1886 letter), Letter, Peirce to A. Marquand, 1886 December 30, published 1993 in Kloesel, C. et al., eds., ''Writings of Charles S. Peirce: A Chronological Edition'', Vol. 5. Indiana Univ. Press, pp.&amp;nbsp;421–3. Google Books [https://books.google.com/books?id=DnvLHp919_wC&amp;q=Marquand Preview].
** (1887), "Logical Machines", ''The American Journal of Psychology'' v. 1, n. 1, Baltimore: N. Murray, pp.&amp;nbsp;165–70.  Google Books [https://books.google.com/books?id=RdQLAAAAIAAJ&amp;pg=PA165 Eprint]. Reprinted in (1976) ''The New Elements of Mathematics'' v. III, pt. 1, pp.&amp;nbsp;625–32; (1997) ''Modern Logic'' 7:71–77, Project Euclid [http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&amp;id=pdf_1&amp;handle=euclid.rml/1204900343 Eprint]; and (2000) ''Writings of Charles S. Peirce'' v. 6, pp.&amp;nbsp;65–73.
* Baldwin, Mark James (1902), "Logical Machine", ''Dictionary of Philosophy and Psychology'', pp.&amp;nbsp;28–30 Google Books [https://books.google.com/books?id=Dc8YAAAAIAAJ&amp;pg=PA28 Eprint]. ''Classics in the History of Psychology'' [http://psychclassics.yorku.ca/Baldwin/Dictionary/defs/L4defs.htm#Logical%20Machine Eprint].
* Ketner, Kenneth Laine (1984), "The early history of computer design: Charles Sanders Peirce and Marquand's logical machines", with the assistance of Arthur Franklin Stewart, ''Princeton University Library Chronicle'', v. 45, n. 3, pp.&amp;nbsp;186–211. PULC [http://libweb5.princeton.edu/visual_materials/pulc/pulc_v_45_n_3.pdf 15MB PDF Eprint].
* Dalakov, Georgi (undated), "Charles Peirce and Allan Marquand", ''History of Computers and Computing''. [http://history-computer.com/ModernComputer/thinkers/Peirce.html Eprint].

[[Category:Mathematical logic]]


{{mathlogic-stub}}</text>
      <sha1>oee8s57g9jzlzhsz6cuapv7i59y5htx</sha1>
    </revision>
  </page>
  <page>
    <title>Master stability function</title>
    <ns>0</ns>
    <id>42628154</id>
    <revision>
      <id>846674884</id>
      <parentid>841542257</parentid>
      <timestamp>2018-06-20T06:50:02Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 2 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2438">{{orphan|date=May 2014}}
In mathematics, the '''master stability function''' is a tool used to analyse the [[stability theory|stability]] of the synchronous state in a [[dynamical system]] consisting of many identical [[oscillator]]s which are coupled together, such as the [[Kuramoto model]]. 

The setting is as follows. Consider a system with &lt;math&gt; N &lt;/math&gt; identical oscillators. Without the coupling, they evolve according to the same [[ordinary differential equation|differential equation]], say &lt;math&gt; \dot{x}_i = f(x_i) &lt;/math&gt; where &lt;math&gt; x_i &lt;/math&gt; denotes the state of oscillator &lt;math&gt; i &lt;/math&gt;. A synchronous state of the system of oscillators is where all the oscillators are in the same state.

The coupling is defined by a coupling strength &lt;math&gt; \sigma &lt;/math&gt;, a matrix &lt;math&gt; A_{ij} &lt;/math&gt; which describes how the oscillators are coupled together, and a function &lt;math&gt; g &lt;/math&gt; of the state of a single oscillator. Including the coupling leads to the following equation:
:&lt;math&gt; \dot{x}_i = f(x_i) + \sigma \sum_{j=1}^N A_{ij} g(x_j). &lt;/math&gt;
It is assumed that the row sums &lt;math&gt; \sum_j A_{ij} &lt;/math&gt; vanish so that the manifold of synchronous states is neutrally stable.

The master stability function is now defined as the function which maps the complex number &lt;math&gt; \gamma &lt;/math&gt; to the greatest [[Lyapunov exponent]] of the equation
:&lt;math&gt; \dot{y} = (Df + \gamma Dg) y. &lt;/math&gt;
The synchronous state of the system of coupled oscillators is stable if the master stability function is negative at &lt;math&gt; \sigma \lambda_k &lt;/math&gt; where &lt;math&gt; \lambda_k &lt;/math&gt; ranges over the eigenvalues of the coupling matrix &lt;math&gt; A &lt;/math&gt;.

==References==
* {{citation | last1 = Arenas | first1 = Alex | last2 = Díaz-Guilera | first2 = Albert | last3 = Kurths | first3 = Jurgen | last4 = Moreno | first4 = Yamir | last5 = Zhou | first5 = Changsong | title = Synchronization in complex networks | journal = Physics Reports | year = 2008 | volume = 469 | pages = 93–153 | doi = 10.1016/j.physrep.2008.09.002 | arxiv = 0805.2976 | bibcode = 2008PhR...469...93A }}.
* {{citation | last1 = Pecora | first1 = Luis M. | last2 = Carroll | first2 = Thomas L. | title = Master stability functions for synchronized coupled systems | journal = Physical Review Letters | year = 1998 | volume = 80 | pages = 2109–2112 | doi = 10.1103/PhysRevLett.80.2109 | bibcode = 1998PhRvL..80.2109P }}.

[[Category:Dynamical systems]]</text>
      <sha1>rhttsqaifm1mq3lor98v7jbf7ilefcu</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematical Society of Japan</title>
    <ns>0</ns>
    <id>18376786</id>
    <revision>
      <id>801471772</id>
      <parentid>801471734</parentid>
      <timestamp>2017-09-19T21:35:59Z</timestamp>
      <contributor>
        <ip>107.179.240.50</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1422">The '''Mathematical Society of Japan''' ('''MSJ''', {{lang-ja|日本数学会}}) was the first academic society in [[Japan]].

In 1877, the organization was established as the ''Tokyo Sugaku Kaisha.'' It was re-organized and re-established in its present form in 1946.

Today, the MSJ has more than 5,000 members.  They have the opportunity to participate in programs at MSJ meetings which take place in spring and autumn each year. They also have the opportunity to announce their own research at these meetings.

==Takebe Prizes==

In the context of its 50th anniversary celebrations, the Mathematical Society of Japan established the Takebe Prizes for the encouragement of those who show promise as mathematicians.  The award is named after [[Edo period]] mathematician {{nihongo|[[Takebe Kenkō|Takebe Katahiro]]|建部賢弘|1664-1739}} who is also known as [[Takebe Kenkō]].&lt;ref&gt;[http://mathsoc.jp  Mathematical Society of Japan], [http://mathsoc.jp/en/pamph/current/takebe_pr.html  Takebe Prize]&lt;/ref&gt;

==See also==
* [[List of mathematical societies]]
* [[Geometry prize]]

==Notes==
{{reflist|2}}

==References==
* [http://www-groups.dcs.st-and.ac.uk/~history/Societies/Japanese.html Mathematical Society of Japan]

==External links==
* [http://mathsoc.jp/en/ Official website]

[[Category:1877 establishments in Japan]]
[[Category:Mathematical societies]]
[[Category:Learned societies of Japan]]


{{math-stub}}</text>
      <sha1>p3g2yu2jvd429lklfiiwa2pohxbfk0r</sha1>
    </revision>
  </page>
  <page>
    <title>Maximum satisfiability problem</title>
    <ns>0</ns>
    <id>3351916</id>
    <revision>
      <id>869202054</id>
      <parentid>821849845</parentid>
      <timestamp>2018-11-17T01:46:21Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* Related problems */[[User:JCW-CleanerBot#Logic|task]], replaced: IEEE Transaction → IEEE Transactions</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11659">In [[computational complexity theory]], the '''maximum satisfiability problem''' ('''MAX-SAT''') is the problem of determining the maximum number of clauses, of a given [[Propositional formula|Boolean]] formula in [[conjunctive normal form]], that can be made true by an assignment of truth values to the variables of the formula. It is a generalization of the [[Boolean satisfiability problem]], which asks whether there exists a truth assignment that makes all clauses true.

==Example==
The conjunctive normal form formula
:&lt;math&gt; (x_0\lor x_1)\land(x_0\lor\lnot x_1)\land(\lnot x_0\lor x_1)\land(\lnot x_0\lor\lnot x_1)&lt;/math&gt;
is not satisfiable: no matter which truth values are assigned to its two variables, at least one of its four clauses will be false.
However, it is possible to assign truth values in such a way as to make three out of four clauses true; indeed, every truth assignment will do this.
Therefore, if this formula is given as an instance of the MAX-SAT problem, the solution to the problem is the number three.

==Hardness==
The MAX-SAT problem is [[NP-hard]], since its solution easily leads to the solution of the [[boolean satisfiability problem]], which is [[NP-complete]].

It is also difficult to find an [[approximation algorithm|approximate]] solution of the problem, that satisfies a number of clauses within a guaranteed [[approximation ratio]] of the optimal solution. More precisely, the problem is [[APX]]-complete, and thus does not admit a [[polynomial-time approximation scheme]] unless P = NP.&lt;ref&gt;Mark Krentel. The Complexity of Optimization Problems. Proc. of STOC '86. 1986.&lt;/ref&gt;&lt;ref&gt;Christos Papadimitriou. Computational Complexity. Addison-Wesley, 1994.&lt;/ref&gt;&lt;ref&gt;Cohen, Cooper, Jeavons. A complete characterization of complexity for boolean constraint optimization problems. CP 2004.&lt;/ref&gt;

== Weighted MAX-SAT ==
More generally, one can define a weighted version of MAX-SAT as follows: given a conjunctive normal form formula with non-negative weights assigned to each clause, find truth values for its variables that maximize the combined weight of the satisfied clauses. The MAX-SAT problem is an instance of weighted MAX-SAT where all weights are 1.{{sfn|Vazirani|2001|p=131}}&lt;ref&gt;{{Cite journal|last=Borchers|first=Brian|last2=Furman|first2=Judith|date=1998-12-01|title=A Two-Phase Exact Algorithm for MAX-SAT and Weighted MAX-SAT Problems|url=https://link.springer.com/article/10.1023/A:1009725216438|journal=Journal of Combinatorial Optimization|language=en|volume=2|issue=4|doi=10.1023/A:1009725216438|issn=1382-6905}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=https://books.google.com/books?hl=en&amp;lr=&amp;id=_GOVQRL50kcC&amp;oi=fnd&amp;pg=PA393&amp;dq=weighted+max+sat&amp;ots=ZN7-u5RwU0&amp;sig=fHMgnooTMuQm7CHkAxl51gmBIiE#v=onepage&amp;q=weighted%20max%20sat&amp;f=false|title=Satisfiability Problem: Theory and Applications : DIMACS Workshop, March 11-13, 1996|last=Du|first=Dingzhu|last2=Gu|first2=Jun|last3=Pardalos|first3=Panos M.|date=1997-01-01|publisher=American Mathematical Soc.|isbn=9780821870808|language=en|pp=393}}&lt;/ref&gt;

=== Approximation algorithms ===
&lt;!-- Given a conjunctive normal form formula {{var|F}} with variables {{var|x}}&lt;sub&gt;1&lt;/sub&gt;, {{var|x}}&lt;sub&gt;2&lt;/sub&gt;, ..., {{var|x}}&lt;sub&gt;n&lt;/sub&gt;, --&gt;

==== 1/2-approximation ====

Randomly assigning each variable to be true with probability 1/2 gives an [[Expected value|expected]] [[Approximation algorithm#Performance guarantees|2-approximation]]. More precisely, if each clause has at least {{var|k}} variables, then this yields a (1 − 2&lt;sup&gt;−{{var|k}}&lt;/sup&gt;)-approximation.{{sfn|Vazirani|2001|loc=Lemma 16.2}} This algorithm can be [[Randomized algorithm#Derandomization|derandomized]] using the [[method of conditional probabilities]].{{sfn|Vazirani|2001|loc=Section 16.2}}

==== (1-1/{{var|e}})-approximation ====

MAX-SAT can also be expressed using an [[integer linear program]] (ILP). Fix a conjunctive normal form formula {{var|F}} with variables {{var|x}}&lt;sub&gt;1&lt;/sub&gt;, {{var|x}}&lt;sub&gt;2&lt;/sub&gt;, ..., {{var|x}}&lt;sub&gt;n&lt;/sub&gt;, and let {{var|C}} denote the clauses of {{var|F}}. For each clause {{var|c}} in {{var|C}}, let {{var|S}}&lt;sup&gt;+&lt;/sup&gt;&lt;sub&gt;{{var|c}}&lt;/sub&gt; and {{var|S}}&lt;sup&gt;−&lt;/sup&gt;&lt;sub&gt;{{var|c}}&lt;/sub&gt; denote the sets of variables which are not negated in {{var|c}}, and those that are negated in {{var|c}}, respectively. The variables {{var|y}}&lt;sub&gt;{{var|x}}&lt;/sub&gt; of the ILP will correspond to the variables of the formula {{var|F}}, whereas the variables {{var|z}}&lt;sub&gt;{{var|c}}&lt;/sub&gt; will correspond to the clauses. The ILP is as follows: 
{|
| maximize
| &lt;math&gt;\sum_{c \in C} w_c\cdot z_c&lt;/math&gt;
|
| (maximize the weight of the satisfied clauses)
|-
| subject to
| &lt;math&gt;z_c\leq\sum_{x\in S_c^+} y_x+\sum_{x\in S_c^-} (1-y_x)&lt;/math&gt;
| for all &lt;math&gt;c\in C&lt;/math&gt;
| (clause is true [[If and only if|iff]] it has a true, non-negated variable or a false, negated one)
|-
|
| &lt;math&gt;z_c \in \{0,1\}&lt;/math&gt;
| for all &lt;math&gt;c\in C&lt;/math&gt;.
| (every clause is either satisfied or not)
|-
|
| &lt;math&gt;y_x \in \{0,1\}&lt;/math&gt;
| for all &lt;math&gt;x\in F&lt;/math&gt;.
| (every variable is either true or false)
|}

The above program can be [[Linear programming relaxation|relaxed]] to the following linear program {{var|L}}:

{|
| maximize
| &lt;math&gt;\sum_{c \in C} w_c\cdot z_c&lt;/math&gt;
|
| (maximize the weight of the satisfied clauses)
|-
| subject to
| &lt;math&gt;z_c\leq\sum_{x\in S_c^+} y_x+\sum_{x\in S_c^-} (1-y_x)&lt;/math&gt;
| for all &lt;math&gt;c\in C&lt;/math&gt;
| (clause is true [[If and only if|iff]] it has a true, non-negated variable or a false, negated one)
|-
|
| &lt;math&gt;0\leq z_c \leq 1&lt;/math&gt;
| for all &lt;math&gt;c\in C&lt;/math&gt;.
|-
|
| &lt;math&gt;0\leq y_x\leq 1&lt;/math&gt;
| for all &lt;math&gt;x\in F&lt;/math&gt;.
|}

The following algorithm using that relaxation is an expected (1-1/[[E (mathematical constant)|e]])-approximation:{{sfn|Vazirani|p=136}}
# Solve the linear program {{var|L}} and obtain a solution {{var|O}}
# Set variable {{var|x}} to be true with probability {{var|y}}&lt;sub&gt;{{var|x}}&lt;/sub&gt; where {{var|y}}&lt;sub&gt;{{var|x}}&lt;/sub&gt; is the value given in {{var|O}}.

This algorithm can also be derandomized using the method of conditional probabilities.

==== 3/4-approximation ====

The 1/2-approximation algorithm does better when clauses are large whereas the (1-1/{{var|e}})-approximation  does better when clauses are small. They can be combined as follows:
# Run the (derandomized) 1/2-approximation algorithm to get a truth assignment {{var|X}}.
# Run the (derandomized) (1-1/e)-approximation to get a truth assignment {{var|Y}}.
# Output whichever of {{var|X}} or {{var|Y}} maximizes the weight of the satisfied clauses.

This is a deterministic factor (3/4)-approximation.{{sfn|Vazirani|2001|loc=Theorem 16.9}}

==== Example ====

On the formula
:&lt;math display="block"&gt;F=\underbrace{(x\lor y)}_{\text{weight }1}\land \underbrace{(x\lor\lnot y)}_{\text{weight }1}\land\underbrace{(\lnot x\lor z)}_{\text{weight }2+\epsilon}&lt;/math&gt;

where &lt;math&gt;\epsilon &gt;0&lt;/math&gt;, the (1-1/{{var|e}})-approximation will set each variable to True with probability 1/2, and so will behave identically to the 1/2-approximation. Assuming that the assignment of {{var|x}} is chosen first during derandomization, the derandomized algorithms will pick a solution with total weight &lt;math&gt;3+\epsilon&lt;/math&gt;, whereas the optimal solution has weight &lt;math&gt;4+\epsilon&lt;/math&gt;.{{sfn|Vazirani|2001|loc=Example 16.11}}

==Solvers==
Many exact solvers for MAX-SAT have been developed during recent years, and many of them were presented in the well-known conference on the boolean satisfiability problem and related problems, the SAT Conference. In 2006 the SAT Conference hosted the first '''MAX-SAT evaluation''' comparing performance of practical solvers for MAX-SAT, as it has done in the past for the [[0-1 integer programming|pseudo-boolean satisfiability]] problem and the [[quantified boolean formula]] problem.
Because of its NP-hardness, large-size MAX-SAT instances cannot in general be solved exactly, and one must often resort to [[approximation algorithm]]s
and [[Metaheuristic|heuristics]] &lt;ref&gt;
R. Battiti and M. Protasi.
Approximate Algorithms and Heuristics for MAX-SAT
Handbook of Combinatorial Optimization, Vol 1, 1998, 77-148, Kluwer Academic Publishers.&lt;/ref&gt;

There are several solvers submitted to the last Max-SAT Evaluations:
* [[Branch and Bound]] based: Clone, MaxSatz (based on [[Satz (SAT solver)|Satz]]), IncMaxSatz, IUT_MaxSatz, WBO, GIDSHSat.
* Satisfiability based: SAT4J, QMaxSat.
* Unsatisfiability based: msuncore, WPM1, PM2.

==Special cases==
MAX-SAT is one of the optimization extensions of the [[boolean satisfiability problem]], which is the problem of determining whether the variables of a given [[Propositional formula|Boolean]] formula can be assigned in such a way as to make the formula evaluate to TRUE. If the clauses are restricted to have at most 2 literals, as in [[2-satisfiability]], we get the [[MAX-2SAT]] problem. If they are restricted to at most 3 literals per clause, as in [[3-satisfiability]], we get the [[MAX-3SAT]] problem.

==Related problems==
There are many problems related to the satisfiability of conjunctive normal form Boolean formulas.

* [[Decision problem]]s:
** [[2-satisfiability|2SAT]]
** [[Boolean satisfiability problem|3SAT]]
* Optimization problems, where the goal is to maximize the number of clauses satisfied:
** MAX-SAT, and the corresponded weighted version [[#Weighted MAX-SAT|Weighted MAX-SAT]]
** MAX-{{var|k}}SAT, where each clause has exactly {{var|k}} variables:
*** [[2-satisfiability#Maximum-2-satisfiability|MAX-2SAT]]
*** [[MAX-3SAT]]
*** [[MAXEkSAT]]
** The partial maximum satisfiability problem (PMAX-SAT) asks for the maximum number of clauses which can be satisfied by any assignment of a given subset of clauses. The rest of the clauses must be satisfied.
** The soft satisfiability problem (soft-SAT), given a set of SAT problems, asks for the maximum number of sets which can be satisfied by any assignment.&lt;ref&gt;Josep Argelich and Felip Manyà. [http://www.springerlink.com/content/870v1535q0h51717/ Exact Max-SAT solvers for over-constrained problems]. In Journal of Heuristics 12(4) pp. 375-392. Springer, 2006.&lt;/ref&gt;
** The minimum satisfiability problem.
* The MAX-SAT problem can be extended to the case where the variables of the [[constraint satisfaction problem]] belong the set of reals. The problem amounts to finding the smallest ''q'' such that the ''q''-[[relaxed intersection]] of the constraints is not empty.&lt;ref&gt;{{cite journal|last1=Jaulin|first1=L.|last2=Walter|first2=E.| title=Guaranteed robust nonlinear minimax estimation| journal=IEEE Transactions on Automatic Control|year=2002|volume=47| url=http://www.ensta-bretagne.fr/jaulin/paper_qminimax.pdf}}&lt;/ref&gt;

== See also ==
* [[Boolean satisfiability problem|Boolean Satisfiability Problem]]
* [[Constraint satisfaction]]
* [[Satisfiability modulo theories]]

== External links ==
* http://www.satisfiability.org/
* https://web.archive.org/web/20060324162911/http://www.iiia.csic.es/~maxsat06/
* http://www.maxsat.udl.cat
* [http://www.nlsde.buaa.edu.cn/~kexu/benchmarks/max-sat-benchmarks.htm Weighted Max-2-SAT Benchmarks with Hidden Optimum Solutions]
* [http://www.cs.tau.ac.il/~azar/Methods-Class6.pdf Lecture Notes on MAX-SAT Approximation]

== References ==
&lt;references /&gt;
* {{Citation| last = Vazirani | first = Vijay V.
 | authorlink = Vijay Vazirani
 | title = Approximation Algorithms
 | year = 2001
 | publisher = Springer-Verlag
 | isbn = 3-540-65367-8
 | url = http://www.cc.gatech.edu/fac/Vijay.Vazirani/book.pdf
}}

[[Category:Logic in computer science]]
[[Category:Combinatorial optimization]]
[[Category:Satisfiability problems]]</text>
      <sha1>cy99gj4t3b78rmfsfy94o7yphxnnsn9</sha1>
    </revision>
  </page>
  <page>
    <title>Near polygon</title>
    <ns>0</ns>
    <id>41024203</id>
    <revision>
      <id>833613941</id>
      <parentid>802645007</parentid>
      <timestamp>2018-04-01T16:20:21Z</timestamp>
      <contributor>
        <username>Joel B. Lewis</username>
        <id>13974845</id>
      </contributor>
      <minor/>
      <comment>Various formatting</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8769">{{DISPLAYTITLE:Near polygon}}
[[File:GQ(2,2), the Doily.svg|thumb|240px|A dense near polygon with diameter ''d''&amp;nbsp;=&amp;nbsp;2]]
In [[mathematics]], a '''near polygon''' is an [[incidence geometry]] introduced by Ernest E. Shult and Arthur Yanushka in 1980.&lt;ref&gt;Shult, Ernest; Yanushka, Arthur. "Near n-gons and line systems".&lt;/ref&gt; Shult and Yanushka showed the connection between the so-called tetrahedrally closed line-systems in Euclidean spaces and a class of [[incidence geometry|point-line geometries]] which they called near polygons. These structures generalise the notion of [[generalized polygon]] as every generalized 2''n''-gon is a near 2''n''-gon of a particular kind. Near polygons were extensively studied and connection between them and dual [[Polar space|polar spaces]] &lt;ref&gt;Cameron, Peter J. "Dual polar spaces".&lt;/ref&gt; was shown in 1980s and early 1990s. Some [[sporadic group|sporadic simple groups]], for example the [[Hall-Janko group]] and the [[Mathieu group]]s, act as automorphism groups of near polygons.

== Definition ==

A near 2''d''-gon is an [[incidence structure]] (&lt;math&gt;P,L,I&lt;/math&gt;), where &lt;math&gt;P&lt;/math&gt; is the set of points, &lt;math&gt;L&lt;/math&gt; is the set of lines and &lt;math&gt;I\subseteq P\times L&lt;/math&gt; is the [[incidence relation]], such that:
* The maximum distance between two points (the so-called diameter) is ''d''. 
* For every point &lt;math&gt;x&lt;/math&gt; and every line &lt;math&gt;L&lt;/math&gt; there exists a unique point on &lt;math&gt;L&lt;/math&gt; which is nearest to &lt;math&gt;x&lt;/math&gt;.

Note that the distance are measure in the collinearity [[Graph (discrete mathematics)|graph]] of points, i.e., the graph formed by taking points as vertices and joining a pair of vertices if they are incident with a common line. 
We can also give an alternate [[graph (discrete mathematics)|graph theoretic]] definition, a near 2''d''-gon is a connected graph of finite diameter ''d'' with the property that for every vertex ''x'' and every maximal clique ''M'' there exists a unique vertex ''x''' in ''M'' nearest to ''x''. 
The maximal cliques of such a graph correspond to the lines in the incidence structure definition. 
A near 0-gon (''d'' = 0) is a single point while a near 2-gon (''d'' = 1) is just a single line, i.e., a complete graph.  A near quadrangle (''d'' = 2) is same as a (possibly degenerate) [[generalized quadrangle]]. In fact, it can be shown that every [[generalized polygon|generalized 2''d''-gon]] is a near 2''d''-gon that satisfies the following two additional conditions: 
* Every point is incident with at least two lines. 
*  For every two points ''x'',&amp;nbsp;''y'' at distance ''i''&amp;nbsp;&lt;&amp;nbsp;''d'', there exists a unique neighbour of ''y'' at distance ''i''&amp;nbsp;−&amp;nbsp;1 from&amp;nbsp;''x''.

A near polygon is called dense if every line is incident with at least three points and if every two points at distance two have at least two common neighbours. It is said to have order (''s'',&amp;nbsp;''t'') if every line is incident with precisely ''s''&amp;nbsp;+&amp;nbsp;1 points and every point is incident with precisely ''t''&amp;nbsp;+&amp;nbsp;1 lines. Dense near polygons have a rich theory and several classes of them (like the slim dense near polygons) have been completely classified.&lt;ref&gt;De Bruyn, Bart. ''Near Polygons''&lt;/ref&gt;

== Examples ==

* All connected [[bipartite graph]]s are near polygons. In fact, any near polygon that has precisely two points per line must be a connected bipartite graph. 
* All finite [[generalized polygon]]s except the projective planes. 
* All [[polar space|dual polar spaces]].
* The Hall–Janko near octagon, also known as the Cohen-[[Jacques Tits|Tits]] near octagon&lt;ref&gt;http://www.win.tue.nl/~aeb/graphs/HJ315.html&lt;/ref&gt; associated with the [[Hall–Janko group]]. It can be constructed by choosing the [[conjugacy class]] of 315 central involutions of the Hall-Janko group as points and lines as three element subsets {x, y, xy} whenever x and y commute. 
* The M&lt;sub&gt;24&lt;/sub&gt; near hexagon related to the [[Mathieu group M24]] and the [[Binary Golay code|extended binary Golay code]]. It is constructed by taking the 759 octads (blocks) in the Witt design ''S''(5, 8, 24) corresponding to the Golay code as points and a triple of three pairwise disjoint octads as lines.&lt;ref&gt;https://www.win.tue.nl/~aeb/2WF02/Witt.pdf&lt;/ref&gt; 
* Take the [[Partition of a set|partitions]] of {1, 2, ..., 2''n'' + 2} into ''n'' + 1 2-subsets as points and the partitions into ''n'' − 1 2-subsets and one 4-subset as lines. A point is incident to a line if as a partition it is a refinement of the line. This gives us a near 2''n''-gon with three points on each line, usually denoted '''H'''&lt;sub&gt;''n''&lt;/sub&gt;. Its full automorphism group is the [[symmetric group]] ''S''&lt;sub&gt;2''n''+2&lt;/sub&gt;.&lt;ref&gt;{{citation|last1 = Brouwer|first1 = A.E.|last2=Wilbrink|first2=H.A.|title=Two infinite sequences of near polygons|url=http://www.win.tue.nl/~aeb/preprints/zw194.pdf}}&lt;/ref&gt;&lt;ref&gt;{{citation|first=Bart|last=De Bruyn|title=Isometric embeddings between the near polygon '''H'''&lt;sub&gt;n&lt;/sub&gt; and '''G'''&lt;sub&gt;n&lt;/sub&gt;|url=https://biblio.ugent.be/publication/5842831/file/5842840.pdf}}&lt;/ref&gt;

== Regular near polygons ==

A finite near &lt;math&gt;2d&lt;/math&gt;-gon S is called regular if it has an order &lt;math&gt;(s,t)&lt;/math&gt; and if there exist constants &lt;math&gt;t_i, i \in \{1,\ldots,d\}&lt;/math&gt;, such that for every two points &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; at distance &lt;math&gt;i&lt;/math&gt;, there are precisely &lt;math&gt;t_i + 1&lt;/math&gt; lines through &lt;math&gt;y&lt;/math&gt; containing a (necessarily unique) point at distance &lt;math&gt;i - 1&lt;/math&gt; from &lt;math&gt;x&lt;/math&gt;. It turns out that regular near &lt;math&gt;2d&lt;/math&gt;-gons are precisely those near &lt;math&gt;2d&lt;/math&gt;-gons whose point graph (also known as a [[Collinearity#Collinearity graph|collinearity graph]]) is a [[distance-regular graph]]. A generalized &lt;math&gt;2d&lt;/math&gt;-gon of order &lt;math&gt;(s, t)&lt;/math&gt; is a regular near &lt;math&gt;2d&lt;/math&gt;-gon with parameters &lt;math&gt;t_1 = 0, t_2 = 0, \ldots, t_d = t&lt;/math&gt;

== See also ==

* [[Finite geometry]]
* [[Polar space]]
* [[Partial linear space]]
* [[Association scheme]]
* [[Hall–Janko graph]]

== Notes ==

{{Reflist}}

== References ==

&lt;!--- See [[Wikipedia:Footnotes]] on how to create references using&lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;

*{{Citation
 | last1 = Brouwer | first1 = A.E.
 | last2 = Cohen | first2 = A. M. 
 | last3 = Wilbrink | first3 = H. A. 
 | last4 = Hall | first4 = J. J.
 | journal = Geom. Dedicata
 | pages = 349–368
 | title = Near polygons and Fischer spaces
 | volume = 49
 | issue = 3
 | year = 1994
 | doi= 10.1007/BF01264034}}.

*{{citation
 | last1 = Brouwer | first1 = A.E. | authorlink=Andries Brouwer
 | last2 = Cohen | first2 = A.M. 
 | last3 = Neumaier | first3 = A.
 | publisher = Berlin, New York: Springer-Verlag.
 | mr = 1002568
 | title = Distance Regular Graphs
 | isbn = 3-540-50619-5
 | year = 1989}}.

*{{citation
 | last1 = Brouwer | first1 = A.E. | authorlink=Andries Brouwer
 | last2 = Wilbrink | first2 = H. A.
 | publisher = Mathematisch Centrum
 | title = Two infinite sequences of near polygons
 | url = http://www.win.tue.nl/~aeb/preprints/zw194.pdf
 | year = 1983
 | series = Report ZW194/83}}.

*{{citation
 | last1 = Cameron | first1 = Peter J. 
 | authorlink=Peter Cameron (mathematician)
 | journal = Geom. Dedicata
 | mr = 645040
 | pages = 75–85
 | title = Dual polar spaces
 | volume = 12
 | year = 1982
 | doi=10.1007/bf00147332}}.

*{{Citation | last1=Cameron | first1=Peter J. | authorlink=Peter Cameron (mathematician) | title=Projective and polar spaces | url=http://www.maths.qmul.ac.uk/~pjc/pps/ | publisher=Queen Mary and Westfield College School of Mathematical Sciences | location=London | series=QMW Maths Notes | mr=1153019 | year=1991 | volume=13}}.

*{{citation
 | last = De Bruyn | first1 = Bart 
 | doi = 10.1007/978-3-7643-7553-9
 | publisher = Birkhäuser Verlag
 | mr = 2227553
 | title = Near Polygons
 | isbn = 3-7643-7552-3
 | year = 2006
 | series = Frontiers in Mathematics}}.

* {{citation|last1=De Clerck|first1=F.|last2=Van Maldeghem|first2=H.|contribution=Some classes of rank 2 geometries|title=Handbook of Incidence Geometry|publisher=North-Holland|place=Amsterdam|publication-date=1995|pages=433–475}}.
* {{citation
 | last = Shult | first1 = Ernest E.
 | doi = 10.1007/978-3-642-15627-4
 | publisher = Springer
 | title = Points and Lines
 | isbn = 978-3-642-15626-7
 | year = 2011
 | series =Universitext}}.

*{{Citation
 | last1 = Shult | first1 = Ernest 
 | last2 = Yanushka | first2 = Arthur 
 | doi = 10.1007/BF00156473
 | journal = Geom. Dedicata
 | mr = 566437
 | pages = 1–72
 | title = Near n-gons and line systems
 | volume = 9
 | year = 1980}}.

[[Category:Incidence geometry]]
[[Category:Finite geometry]]
[[Category:Set families]]</text>
      <sha1>svrh1va83y808ql12rqsdzuz4s2n5i1</sha1>
    </revision>
  </page>
  <page>
    <title>Optimality criterion</title>
    <ns>0</ns>
    <id>15015787</id>
    <revision>
      <id>751031480</id>
      <parentid>723610359</parentid>
      <timestamp>2016-11-22T23:12:36Z</timestamp>
      <contributor>
        <username>ArmbrustBot</username>
        <id>18663209</id>
      </contributor>
      <minor/>
      <comment>/* top */re-categorisation per [[WP:CFDS|CFDS]], replaced: Category:Hypothesis testing → Category:Statistical hypothesis testing using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1318">{{unref|date=January 2008}}
In [[statistics]], an '''optimality criterion''' provides a measure of the fit of the data to a given [[hypothesis]], to aid in [[model selection]]. A [[statistical model|model]] is designated as the "best" of the candidate models if it gives the best value of an [[objective  function]] measuring the degree of satisfaction of the criterion used to evaluate the alternative hypotheses.

The term has been used to identify the different criteria that are used to evaluate a [[phylogenetic tree]]. For example, in order to determine the best topology between two phylogenetic trees using the maximum likelihood optimality criterion, one would calculate the maximum likelihood score of each tree and choose the one that had the better score. However, different optimality criteria can select different hypotheses. In such circumstances caution should be exercised when making strong conclusions.

Many other disciplines use similar criteria or have specific measures geared toward the objectives of the field. Optimality criteria include [[maximum likelihood]], [[Bayesian probability|Bayesian]], [[maximum parsimony]], [[sum of squared residuals]], [[least absolute deviations]], and many others.

{{statistics-stub}}

[[Category:Statistical hypothesis testing]]
[[Category:Model selection]]</text>
      <sha1>q50zbabwzm77gbh6pjg1mc9w82llkjv</sha1>
    </revision>
  </page>
  <page>
    <title>P-recursive equation</title>
    <ns>0</ns>
    <id>58006825</id>
    <revision>
      <id>855217202</id>
      <parentid>854450765</parentid>
      <timestamp>2018-08-16T18:51:30Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <minor/>
      <comment>Michael Hardy moved page [[P-recursive equations]] to [[P-recursive equation]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14690">{{expert needed|Mathematics|reason=to review the article}}

In mathematics a '''P-recursive equation''' is a linear equation of [[Sequence|sequences]] where the coefficient sequences can be represented as [[Polynomial ring|polynomials]]. P-recursive equations are '''linear recurrence equations''' (or '''linear recurrence relations''' or '''linear difference equations''') '''with polynomial coefficients'''. These equations play an important role in different areas of mathematics, specifically in [[combinatorics]]. The sequences which are solutions of these equations are called [[Holonomic function|holonomic]], P-recursive or D-finite.

From the late 1980s on the first algorithms were developed to find solutions for these equations. Sergei A. Abramov, [[Marko Petkovšek]] and Mark van Hoeij described algorithms to find polynomial, rational, hypergeometric and d'Alembertian solutions.

== Definition ==
Let &lt;math display="inline"&gt;\mathbb{K}&lt;/math&gt; be a [[field of characteristic zero]] (for example &lt;math display="inline"&gt;\mathbb{K} = \mathbb{Q}&lt;/math&gt;), &lt;math display="inline"&gt;p_k(n) \in \mathbb{K} [n]&lt;/math&gt; polynomials for &lt;math display="inline"&gt;k = 0,\dots,r&lt;/math&gt;,&lt;math display="inline"&gt;f \in \mathbb{K}^{\N}&lt;/math&gt; a sequence and &lt;math display="inline"&gt;y \in \mathbb{K}^{\N}&lt;/math&gt; an unknown sequence. The equation&lt;math display="block"&gt;\sum_{k=0}^r p_k(n) \, y (n+k) = f(n)&lt;/math&gt;is called a linear recurrence equation with polynomial coefficients (all recurrence equations in this article are of this form). If &lt;math display="inline"&gt;p_0&lt;/math&gt; and &lt;math display="inline"&gt;p_r&lt;/math&gt; are both nonzero, then &lt;math display="inline"&gt;r&lt;/math&gt; is called the order of the equation. If &lt;math display="inline"&gt;f&lt;/math&gt; is zero the equation is called homogeneous, otherwise it is called inhomogeneous.

This can also be written as &lt;math display="inline"&gt;L y = f&lt;/math&gt; where &lt;math display="inline"&gt;L=\sum_{k=0}^r p_k N^k&lt;/math&gt; is a linear recurrence operator with polynomial coefficients and &lt;math display="inline"&gt;N&lt;/math&gt; is the shift operator, i.e. &lt;math display="inline"&gt;N \, y (n) = y (n+1)&lt;/math&gt;.

== Closed form solutions ==
Let &lt;math display="inline"&gt;\sum_{k=0}^r p_k(n) \, y (n+k) = f(n)&lt;/math&gt; or equivalently &lt;math display="inline"&gt;Ly=f&lt;/math&gt; be a recurrence equation with polynomial coefficients. There exist several algorithms which compute solutions of this equation. These algorithms can compute polynomial, rational, hypergeometric and d'Alembertian solutions. The solution of a homogeneous equation is given by the [[Kernel (linear algebra)|kernel]] of the linear recurrence operator: &lt;math display="inline"&gt;\ker L = \{ y \in \mathbb{K}^\N \, : \, L y = 0\}&lt;/math&gt;. As a subspace of the space of sequences this kernel has a [[Basis (linear algebra)|basis]].&lt;ref&gt;If sequences are considered equal if they are equal in almost all terms, then this basis is finite. More on this can be found in the book A=B by Petkovšek, Wilf and Zeilberger.&lt;/ref&gt; Let &lt;math display="inline"&gt;\{ y^{(1)}, y^{(2)}, \dots, y^{(m)} \}&lt;/math&gt; be a basis of &lt;math display="inline"&gt;\ker L&lt;/math&gt;, then the formal sum &lt;math display="inline"&gt;c_1 y^{(1)} + \dots + c_m y^{(m)}&lt;/math&gt; for arbitrary constants &lt;math display="inline"&gt;c_1,\dots,c_m \in \mathbb{K} &lt;/math&gt; is called the general solution of the homogeneous problem &lt;math display="inline"&gt;Ly=0&lt;/math&gt;. If &lt;math display="inline"&gt;\tilde{y}&lt;/math&gt; is a particular solution of &lt;math display="inline"&gt;Ly=f&lt;/math&gt;, i.e. &lt;math display="inline"&gt;L \tilde{y}=f&lt;/math&gt;, then &lt;math display="inline"&gt;c_1 y^{(1)} + \dots + c_m y^{(m)} + \tilde{y}&lt;/math&gt; is also a solution of the inhomogeneous problem and it is called the general solution of the inhomogeneous problem.

=== Polynomial solutions ===
{{Main|Polynomial solutions of P-recursive equations}}In the late 1980s Sergei A. Abramov described an algorithm which finds the general polynomial solution of a recurrence equation, i.e. &lt;math display="inline"&gt;y (n) \in \mathbb{K} [n]&lt;/math&gt;, with a polynomial right-hand side&lt;math display="inline"&gt;f(n) \in \mathbb{K} [n]&lt;/math&gt;. He (and a few years later [[Marko Petkovšek]]) gave a degree bound for polynomial solutions. This way the problem can simply be solved by considering a [[system of linear equations]].&lt;ref&gt;{{Cite journal|last=Abramov|first=Sergei A.|date=1989|title=Problems in computer algebra that are connected with a search for polynomial solutions of linear differential and difference equations|url=|journal=Moscow University Computational Mathematics and Cybernetics|volume=3|pages=|via=}}&lt;/ref&gt;&lt;ref name=":0"&gt;{{Cite journal|last=Petkovšek|first=Marko|date=1992|title=Hypergeometric solutions of linear recurrences with polynomial coefficients|url=http://linkinghub.elsevier.com/retrieve/pii/0747717192900386|journal=Journal of Symbolic Computation|volume=14|issue=2-3|pages=243–264|doi=10.1016/0747-7171(92)90038-6|issn=0747-7171|via=}}&lt;/ref&gt;&lt;ref name=":1"&gt;{{Cite book|url=https://www.math.upenn.edu/~wilf/Downld.html|title=A=B|last=Petkovšek|first=Marko|last2=Wilf|first2=Herbert S.|last3=Zeilberger|first3=Doron|date=1996|publisher=A K Peters|others=|year=|isbn=1568810636|location=|pages=|oclc=33898705}}&lt;/ref&gt; In 1995 Abramov, Bronstein and Petkovšek showed that the polynomial case can be solved more efficiently by considering [[Formal power series|power series]] solution of the recurrence equation in a specific power basis (i.e. not the ordinary basis &lt;math display="inline"&gt;(x^n)_{n \in \N}&lt;/math&gt;).&lt;ref&gt;{{Cite journal|last=Abramov|first=Sergei A.|last2=Bronstein|first2=Manuel|last3=Petkovšek|first3=Marko|date=1995|title=On polynomial solutions of linear operator equations|url=http://dl.acm.org/citation.cfm?id=220346.220384|journal=ISSAC '95 Proceedings of the 1995 international symposium on Symbolic and algebraic computation|publisher=ACM|volume=|pages=290–296|doi=10.1145/220346.220384|isbn=0897916999|via=}}&lt;/ref&gt;

The other algorithms for finding more general solutions (e.g. rational or hypergeometric solutions) also rely on algorithms which compute polynomial solutions.

=== Rational solutions ===
{{Main|Abramov's algorithm}}In 1989 Sergei A. Abramov showed that a general [[Rational function|rational]] solution, i.e. &lt;math display="inline"&gt;y(n) \in \mathbb{K} (n)&lt;/math&gt;, with polynomial right-hand side &lt;math display="inline"&gt;f(n) \in \mathbb{K}[n]&lt;/math&gt;, can be found by using the notion of a universal denominator. A universal denominator is a polynomial &lt;math display="inline"&gt;u&lt;/math&gt; such that the denominator of every rational solution divides &lt;math display="inline"&gt;u&lt;/math&gt;. Abramov showed how this universal denominator can be computed by only using the first and the last coefficient polynomial &lt;math display="inline"&gt;p_0&lt;/math&gt; and &lt;math display="inline"&gt;p_r&lt;/math&gt;. Substituting this universal denominator for the unknown denominator of &lt;math&gt;y&lt;/math&gt; all rational solutions can be found by computing all polynomial solutions of a transformed equation.&lt;ref&gt;{{Cite journal|last=Abramov|first=Sergei A.|date=1989|title=Rational solutions of linear differential and difference equations with polynomial coefficients|url=https://doi.org/10.1016/S0041-5553(89)80002-3|journal=USSR Computational Mathematics and Mathematical Physics|volume=29|issue=6|pages=7–12|doi=10.1016/s0041-5553(89)80002-3|issn=0041-5553|via=}}&lt;/ref&gt;

=== Hypergeometric solution ===
{{Main|Petkovšek's algorithm}}A sequence &lt;math display="inline"&gt;y(n)&lt;/math&gt; is called [[Hypergeometric identity|hypergeometric]] if the ratio of two consecutive terms is a rational function in &lt;math&gt;n&lt;/math&gt;, i.e. &lt;math display="inline"&gt;y (n+1) / y(n) \in \mathbb{K} (n)&lt;/math&gt;. This is the case if and only if the sequence is the solution of a first-order recurrence equation with polynomial coefficients. The set of hypergeometric sequences is not a subspace of the space of sequences as it is not closed under addition.

In 1992 [[Marko Petkovšek]] gave an [[Petkovšek's algorithm|algorithm]] to get the general hypergeometric solution of a recurrence equation where the right-hand side &lt;math&gt;f&lt;/math&gt; is the sum of hypergeometric sequences. The algorithm makes use of the Gosper-Petkovšek normal-form of a rational function. With this specific representation it is again sufficient to consider polynomial solutions of a transformed equation.&lt;ref name=":0" /&gt;

A different and more efficient approach is due to Mark van Hoeij. Considering the roots of the first and the last coefficient polynomial &lt;math display="inline"&gt;p_0&lt;/math&gt; and &lt;math display="inline"&gt;p_r&lt;/math&gt; – called singularities – one can build a solution step by step making use of the fact that every hypergeometric sequence &lt;math display="inline"&gt;y (n)&lt;/math&gt; has a representation of the form&lt;math display="block"&gt;y (n) = c \, r(n)\, z^n \, \Gamma(n-\xi_1)^{e_1} \Gamma(n-\xi_2)^{e_2} \cdots \Gamma(n-\xi_s)^{e_s}&lt;/math&gt;for some &lt;math display="inline"&gt;c \in \mathbb{K}, z \in \overline{\mathbb{K}}, s \in \N, r(n) \in \overline\mathbb{K}(n), \xi_1, \dots, \xi_s \in \overline{\mathbb{K}}&lt;/math&gt; with &lt;math display="inline"&gt;\xi_i-\xi_j \notin \Z&lt;/math&gt; for &lt;math display="inline"&gt;i \neq j&lt;/math&gt; and &lt;math display="inline"&gt;e_1, \dots, e_s \in \Z&lt;/math&gt;. Here &lt;math display="inline"&gt;\Gamma (n)&lt;/math&gt; denotes the [[Gamma function]] and &lt;math display="inline"&gt;\overline{\mathbb{K}}&lt;/math&gt; the [[algebraic closure]] of the field &lt;math display="inline"&gt;\mathbb{K}&lt;/math&gt;. Then the &lt;math display="inline"&gt;\xi_1, \dots, \xi_s &lt;/math&gt; have to be singularities of the equation (i.e. roots of &lt;math display="inline"&gt;p_0&lt;/math&gt; or &lt;math display="inline"&gt;p_r&lt;/math&gt;). Furthermore one can compute bounds for the exponents &lt;math display="inline"&gt;e_i&lt;/math&gt;. For fixed values &lt;math display="inline"&gt;\xi_1, \dots, \xi_s, e_1, \dots, e_s &lt;/math&gt; it is possible to make an ansatz which gives candidates for &lt;math display="inline"&gt;z&lt;/math&gt;. For a specific &lt;math display="inline"&gt;z&lt;/math&gt; one can again make an ansatz to get the rational function &lt;math display="inline"&gt;r(n)&lt;/math&gt; by Abramov's algorithm. Considering all possibilities one gets the general solution of the recurrence equation.&lt;ref&gt;{{Cite journal|last=van Hoeij|first=Mark|date=1999|title=Finite singularities and hypergeometric solutions of linear recurrence equations|url=https://doi.org/10.1016/S0022-4049(99)00008-0|journal=Journal of Pure and Applied Algebra|volume=139|issue=1-3|pages=109–131|doi=10.1016/s0022-4049(99)00008-0|issn=0022-4049|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Cluzeau|first=Thomas|last2=van Hoeij|first2=Mark|date=2006|title=Computing Hypergeometric Solutions of Linear Recurrence Equations|url=https://doi.org/10.1007/s00200-005-0192-x|journal=Applicable Algebra in Engineering, Communication and Computing|language=en|volume=17|issue=2|pages=83–115|doi=10.1007/s00200-005-0192-x|issn=0938-1279|via=}}&lt;/ref&gt;

=== D'Alembertian solutions ===
A sequence &lt;math&gt;y&lt;/math&gt; is called d'Alembertian if &lt;math display="inline"&gt;y = h_1 \sum h_2 \sum \cdots \sum h_k&lt;/math&gt; for some hypergeometric sequences &lt;math display="inline"&gt;h_1,\dots,h_k&lt;/math&gt; and &lt;math display="inline"&gt;y=\sum x&lt;/math&gt; means that &lt;math display="inline"&gt;\Delta y = x&lt;/math&gt; where &lt;math display="inline"&gt;\Delta &lt;/math&gt; denotes the difference operator, i.e. &lt;math display="inline"&gt;\Delta y = N y - y = y (n+1) - y(n)&lt;/math&gt;. This is the case if and only if there are first-order linear recurrence operators &lt;math display="inline"&gt;L_1, \dots, L_k&lt;/math&gt; with rational coefficients such that &lt;math display="inline"&gt;L_k \cdots L_1 y = 0&lt;/math&gt;.&lt;ref name=":1" /&gt;

1994 Abramov and Petkovšek described an algorithm which computes the general d'Alembertian solution of a recurrence equation. This algorithm computes hypergeometric solutions and reduces the order of the recurrence equation recursively.&lt;ref&gt;{{Cite journal|last=Abramov|first=Sergei A.|last2=Petkovšek|first2=Marko|date=1994|title=D'Alembertian solutions of linear differential and difference equations|url=http://dl.acm.org/citation.cfm?id=190347.190412|journal=ISSAC '94 Proceedings of the international symposium on Symbolic and algebraic computation|publisher=ACM|volume=|pages=169–174|doi=10.1145/190347.190412|isbn=0897916387|via=}}&lt;/ref&gt;

== Examples ==

=== Signed permutation matrices ===
The number of [[Generalized permutation matrix|signed permutation matrices]] of size &lt;math&gt;n \times n&lt;/math&gt; can be described by the [[Sequence space|sequence]] &lt;math display="inline"&gt;y(n) \in \Q^{\N}&lt;/math&gt;. A signed permutation matrix is a square matrix which has exactly one nonzero entry in every row and in every column. The nonzero entries can be &lt;math display="inline"&gt;\pm 1&lt;/math&gt;. The sequence is determined by the linear recurrence equation with polynomial coefficients&lt;math display="block"&gt;y (n) = 4(n-1)^2 \, y (n-2) + 2 \, y (n-1)&lt;/math&gt;and the initial values &lt;math display="inline"&gt;y(0) = 1, y(1) = 2&lt;/math&gt;. Applying an algorithm to find hypergeometric solutions one can find the general hypergeometric solution&lt;math display="block"&gt;y (n) = c \, 2^n n!&lt;/math&gt;for some constant &lt;math display="inline"&gt;c&lt;/math&gt;. Also considering the initial values, the sequence &lt;math display="inline"&gt;y (n) = 2^n n!&lt;/math&gt; describes the number of signed permutation matrices.&lt;ref&gt;{{Cite web|url=https://oeis.org/A000165|title=A000165 - OEIS|website=oeis.org|access-date=2018-07-02}}&lt;/ref&gt;

=== Involutions ===
The number of [[Involution (mathematics)|involutions]] &lt;math display="inline"&gt;y(n)&lt;/math&gt; of a set with &lt;math display="inline"&gt;n&lt;/math&gt; elements is given by the recurrence equation&lt;math display="block"&gt;y (n) = (n-1) \, y (n-2) + y (n-1).&lt;/math&gt;Applying for example [[Petkovšek's algorithm]] it is possible to see that there is no polynomial, rational or hypergeometric solution for this recurrence equation.&lt;ref name=":1" /&gt;

== Applications ==
A function &lt;math display="inline"&gt;F(n,k)&lt;/math&gt; is called hypergeometric if &lt;math display="inline"&gt;F(n,k+1)/F(n,k), F(n+1,k)/F(n,k) \in \mathbb{K}(n,k)&lt;/math&gt; where &lt;math display="inline"&gt;\mathbb{K}(n,k)&lt;/math&gt; denotes the rational functions in &lt;math display="inline"&gt;n&lt;/math&gt; and &lt;math display="inline"&gt;k&lt;/math&gt;. A hypergeometric sum is a finite sum of the form &lt;math display="inline"&gt;f(n)=\sum_k F(n,k)&lt;/math&gt; where &lt;math display="inline"&gt;F(n,k)&lt;/math&gt; is hypergeometric. [[Doron Zeilberger|Zeilberger]]'s creative telescoping algorithm can transform such a hypergeometric sum into a recurrence equation with polynomial coefficients. This equation can then be solved to get for example a linear combination of hypergeometric solutions which is called a closed form solution of &lt;math display="inline"&gt;f&lt;/math&gt;.&lt;ref name=":1" /&gt;

== References ==
&lt;references /&gt;



[[Category:Polynomials]]</text>
      <sha1>pwx74s4l34yht7bgnk1hc93gi90s5mu</sha1>
    </revision>
  </page>
  <page>
    <title>Remainder</title>
    <ns>0</ns>
    <id>502897</id>
    <revision>
      <id>855195576</id>
      <parentid>855180926</parentid>
      <timestamp>2018-08-16T15:49:22Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Citation needed}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9758">{{Other uses}}
{{Calculation results}}

In mathematics, the '''remainder''' is the amount "left over" after performing some computation. In [[arithmetic]], the remainder is the integer "left over" after [[division (mathematics)|dividing]] one [[integer]] by another to produce an integer [[quotient]] (integer division). In [[algebra]], the remainder is the polynomial "left over" after dividing one polynomial by another. The ''[[modulo operation]]'' is the operation that produces such a remainder when given a dividend and divisor.

Formally it is also true that a remainder is what is left after [[subtraction|subtracting]] one number from another, although this is more precisely called the ''difference''. This usage can be found in some elementary textbooks; colloquially it is replaced by the expression "the rest" as in "Give me two dollars back and keep the rest."&lt;ref&gt;{{harvnb|Smith|1958|loc=p. 97}}&lt;/ref&gt; However, the term "remainder" is still used in this sense when a [[function (mathematics)|function]] is approximated by a [[series expansion]] and the error expression ("the rest") is referred to as the [[remainder term]].

==Integer division==

If ''a'' and ''d'' are [[integer]]s, with ''d'' non-zero, it can be proven that there exist unique integers ''q'' and ''r'', such that ''a'' = ''qd''&amp;nbsp;+&amp;nbsp;''r'' and 0&amp;nbsp;≤&amp;nbsp;''r''&amp;nbsp;&lt;&amp;nbsp;''|d|''. The number ''q'' is called the ''[[quotient]]'', while ''r'' is called the ''remainder''.

See [[Euclidean division]] for a proof of this result and [[division algorithm]] for algorithms describing how to calculate the remainder.

The remainder, as defined above, is called the ''least positive remainder'' or simply the ''remainder''.&lt;ref&gt;{{harvnb|Ore|1988|loc=p. 30}}. But if the remainder is 0, it is not positive, even though it is called a "positive remainder".&lt;/ref&gt; The integer ''a'' is either a multiple of ''d'' or lies in the interval between consecutive multiples of ''d'', namely, ''q⋅d'' and (''q'' + 1)''d'' (for positive ''q'').

At times it is convenient to carry out the division so that ''a'' is as close as possible to an integral multiple of ''d'', that is, we can write 
:''a'' = ''k⋅d'' + ''s'', with |''s''| ≤ |''d''/2| for some integer ''k''.
In this case, ''s'' is called the ''least absolute remainder''.&lt;ref&gt;{{harvnb|Ore|1988|loc=p. 32}}&lt;/ref&gt; As with the quotient and remainder, ''k'' and ''s'' are uniquely determined except in the case where ''d'' = 2''n'' and ''s'' = ± ''n''. For this exception we have,
: ''a'' = ''k⋅d'' + ''n'' = (''k'' + 1)''d'' − ''n''.
A unique remainder can be obtained in this case by some convention such as always taking the positive value of ''s''.

==Examples==
In the division of 43 by 5 we have:
: 43 = 8 × 5 + 3,
so 3 is the least positive remainder. We also have,
: 43 = 9 × 5 − 2,
and −2 is the least absolute remainder.

These definitions are also valid if ''d'' is negative, for example, in the division of 43 by −5,

:43 = (−8) × (−5) + 3,

and 3 is the least positive remainder, while,

:43 = (−9) × (−5) + (−2)

and &amp;minus;2 is the least absolute remainder.

In the division of 42 by 5 we have:
:42 = 8 × 5 + 2,
and since 2 &lt; 5/2, 2 is both the least positive remainder and the least absolute remainder.

In these examples, the (negative) least absolute remainder is obtained from the least positive remainder by subtracting 5, which is ''d''. This holds in general. When dividing by ''d'', either both remainders are positive and therefore equal, or they have opposite signs. If the positive remainder is ''r''&lt;sub&gt;1&lt;/sub&gt;, and the negative one is ''r''&lt;sub&gt;2&lt;/sub&gt;, then

:r&lt;sub&gt;1&lt;/sub&gt; = ''r''&lt;sub&gt;2&lt;/sub&gt; + ''d''.

== For floating-point numbers==

When ''a'' and ''d'' are [[floating-point number]]s, with ''d'' non-zero, ''a'' can be divided by ''d'' without remainder, with the quotient being another floating-point number. If the quotient is constrained to being an integer, however, the concept of remainder is still necessary. It can be proved that there exists a unique integer quotient ''q'' and a unique floating-point remainder ''r'' such that ''a''&amp;nbsp;=&amp;nbsp;''qd''&amp;nbsp;+&amp;nbsp;''r'' with 0&amp;nbsp;≤&amp;nbsp;''r''&amp;nbsp;&lt;&amp;nbsp;|''d''|.

Extending the definition of remainder for floating-point numbers as described above is not of theoretical importance in mathematics; however, many [[programming language]]s implement this definition, see [[modulo operation]].

== In programming languages ==
{{Main|Modulo operation}}

While there are no difficulties inherent in the definitions, there are implementation issues that arise when negative numbers are involved in calculating remainders. Different programming languages have adopted different conventions:

* [[Pascal (programming language)|Pascal]] chooses the result of the ''mod'' operation positive, but does not allow ''d'' to be negative or zero (so, {{nowrap|1=''a'' = (''a div d'' ) × ''d'' + ''a mod d''}} is not always valid).&lt;ref name="iso/iec 7185:1990 6.7.2.2"&gt;[http://pascal-central.com/iso7185.html Pascal ISO 7185:1990] 6.7.2.2&lt;/ref&gt;

* [[C99]] chooses the remainder with the same sign as the dividend ''a''.&lt;ref&gt;{{cite web |title=C99 specification (ISO/IEC 9899:TC2) |url=http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1124.pdf |accessdate=16 August 2018 |location=6.5.5 Multiplicative operators |date=2005-05-06}}&lt;/ref&gt; (Before C99, the C language allowed other choices.)

* [[Perl]], [[Python (programming language)|Python]] (only modern versions), and [[Common Lisp]] choose the remainder with the same sign as the divisor ''d''.&lt;ref&gt;{{Citation needed|date=August 2018}}&lt;/ref&gt;

* [[Haskell (programming language)|Haskell]] and [[Scheme (programming language)|Scheme]] offer two functions, ''remainder'' and ''modulo'' – [[PL/I]] has ''mod'' and ''rem'', while [[Fortran]] has ''mod'' and ''modulo''; in each case, the former agrees in sign with the dividend, and the latter with the divisor.

==Polynomial division==
{{main|Euclidean division of polynomials}}

Euclidean division of polynomials is very similar to [[Euclidean division]] of integers and leads to polynomial remainders. Its existence is based on the following theorem: Given two univariate polynomials ''a''(''x'') and ''b''(''x'') (with ''b''(''x'') not the zero polynomial) defined over a field (in particular, the [[Real number|reals]] or [[complex number]]s), there exist two polynomials ''q''(''x'') (the ''quotient'') and ''r''(''x'') (the ''remainder'')  which satisfy:&lt;ref&gt;{{harvnb|Larson|Hostetler|2007|loc=p. 154}}&lt;/ref&gt;
:&lt;math&gt;a(x) = b(x)q(x) + r(x)&lt;/math&gt;
where
:&lt;math&gt;\deg(r(x)) &lt; \deg(b(x)),&lt;/math&gt;
where "deg(...)" denotes the degree of the polynomial (the degree of the constant polynomial whose value is always 0 is defined to be negative, so that this degree condition will always be valid when this is the remainder.) Moreover, ''q''(''x'') and ''r''(''x'') are uniquely determined by these relations.

This differs from the Euclidean division of integers in that, for the integers, the degree condition is replaced by the bounds on the remainder ''r'' (non-negative and less than the divisor, which insures that ''r'' is unique.) The similarity of Euclidean division for integers and also for polynomials leads one to ask for the most general algebraic setting in which Euclidean division is valid. The rings for which such a theorem exists are called [[Euclidean domain]]s, but in this generality uniqueness of the quotient and remainder are not guaranteed.&lt;ref&gt;{{harvnb|Rotman|2006|loc=p. 267}}&lt;/ref&gt;

Polynomial division leads to a result known as the [[Polynomial remainder theorem|Remainder theorem]]: If a polynomial ''f''(''x'') is divided by ''x'' − ''k'', the remainder is the constant ''r'' = ''f''(''k'').&lt;ref&gt;{{harvnb|Larson|Hostetler|2007|loc=p. 157}}&lt;/ref&gt;

== See also ==
{{div col}}
* [[Chinese remainder theorem]]
* [[Divisibility rule]]
* [[Egyptian multiplication and division]]
* [[Euclidean algorithm]]
* [[Long division]]
* [[Modular arithmetic]]
* [[Polynomial long division]]
* [[Taylor's theorem]]
{{div col end}}

==Notes==
&lt;References /&gt;

==References==
* {{citation|first1=Ron|last1=Larson|first2=Robert|last2=Hostetler|title=Precalculus:A Concise Course|year=2007|publisher=Houghton Mifflin|isbn=978-0-618-62719-6}}
* {{citation|first=Oystein|last=Ore|year=1988|origyear=1948|title=Number Theory and Its History|publisher=Dover|isbn=978-0-486-65620-5}}
* {{citation|first=Joseph J.|last=Rotman|year=2006|title=A First Course in Abstract Algebra with Applications|edition=3rd|publisher=Prentice-Hall|isbn=978-0-13-186267-8}}
* {{citation|last=Smith|first=David Eugene|title=History of Mathematics, Volume 2|year=1958|origyear=1925|publisher=Dover|location=New York|isbn=0486204308}}

==Further reading==
* {{cite book |author=Davenport, Harold |title=The higher arithmetic: an introduction to the theory of numbers |publisher=Cambridge University Press |location=Cambridge, UK |year=1999 |page=25 |isbn=0-521-63446-6}}
* {{cite book|editor-last=Katz|editor-first=Victor|title=The mathematics of Egypt, Mesopotamia, China, India, and Islam : a sourcebook|year=2007|publisher=Princeton University Press|location=Princeton|isbn=9780691114859}}
* {{cite encyclopedia|last=Schwartzman|first=Steven|title=remainder (noun) |encyclopedia=The words of mathematics : an etymological dictionary of mathematical terms used in english|year=1994|publisher=Mathematical Association of America|location=Washington|isbn=9780883855119}}
* {{cite book |author=Zuckerman, Martin M |title=Arithmetic: A Straightforward Approach |publisher=Rowman &amp; Littlefield Publishers, Inc |location=Lanham, Md |year= |pages= |isbn=0-912675-07-1}}

[[Category:Division (mathematics)]]
[[Category:Number theory]]</text>
      <sha1>kgup6hlquwn0skz4nao10fk2h19pupr</sha1>
    </revision>
  </page>
  <page>
    <title>Risk-adjusted return on capital</title>
    <ns>0</ns>
    <id>1631010</id>
    <revision>
      <id>824245081</id>
      <parentid>823736745</parentid>
      <timestamp>2018-02-06T04:56:15Z</timestamp>
      <contributor>
        <username>EconExpert1</username>
        <id>33000631</id>
      </contributor>
      <comment>added section describing decision metrics based on regulatory and economic capital</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6202">{{refimprove|date=July 2006}}

'''Risk-adjusted return on capital''' ('''RAROC''') is a [[risk]]-based profitability measurement framework for analysing risk-adjusted financial performance and providing a consistent view of [[Profit (accounting)|profitability]] across businesses. The concept was developed by [[Bankers Trust]] and principal designer Dan Borge in the late 1970s.&lt;ref name="isbn0-691-12883-9"&gt;{{cite book |author1=Herring, Richard |author2=Diebold, Francis X. |author3=Doherty, Neil A. |title=The Known, the Unknown, and the Unknowable in Financial Risk Management: Measurement and Theory Advancing Practice |publisher=Princeton University Press |location=Princeton, N.J |year=2010 |page=347}}&lt;/ref&gt; Note, however, that increasingly '''return on risk adjusted capital''' (RORAC) is used as a measure, whereby the risk adjustment of Capital is based on the [[capital adequacy guidelines]] as outlined by the [[Basel Committee on Banking Supervision|Basel Committee]], currently [[Basel III]].{{citation needed|date=August 2012}}

==Basic formulae==
&lt;br /&gt;
:&lt;math&gt;\mbox{RAROC} = {\mbox{Expected return} \over \mbox{Economic capital}}&lt;/math&gt; &lt;ref name="pstat.ucsb.edu"&gt;[http://www.pstat.ucsb.edu/research/papers/report10_2004%5B1%5D.pdf Quantifying Risk in the Electricity Business: A RAROC-based Approach]&lt;/ref&gt;   or   &lt;math&gt;\mbox{RAROC} = {\mbox{Expected return} \over \mbox{Value at risk}}&lt;/math&gt;&lt;ref name="pstat.ucsb.edu"/&gt; 
&lt;br /&gt;
Broadly speaking, in business enterprises, risk is traded off against benefit. RAROC is defined as the ratio of risk adjusted return to [[economic capital]]. The economic capital is the amount of money which is needed to secure the survival in a worst-case scenario, it is a buffer against unexpected shocks in market values. Economic capital is a function of [[market risk]], [[credit risk]], and [[operational risk]], and is often calculated by [[Value at risk|VaR]]. This use of capital based on risk improves the capital allocation across different functional areas of banks, insurance companies, or any business in which capital is placed at risk for an expected return above the [[risk-free rate]].

RAROC system allocates capital for two basic reasons:
#Risk management
#Performance evaluation

For risk management purposes, the main goal of allocating capital to individual business units is to determine the bank's optimal [[capital structure]]—that is economic capital allocation is closely correlated with individual business risk. As a performance evaluation tool, it allows banks to assign capital to business units based on the [[economic value added]] of each unit.

== Decision measures based on regulatory and economic capital ==
With the [[Financial crisis of 2007–2008|financial crisis of 2007]], and the introduction of [[Dodd–Frank Wall Street Reform and Consumer Protection Act|Dodd–Frank Act]], and [[Basel III]], minimum required regulatory capital requirements have become onerous. An implication of stringent regulatory capital requirements spurred debates on the validity of required economic capital in managing an organization’s portfolio composition, highlighting that constraining requirements should have organizations focus entirely on the return on regulatory capital in measuring profitability and in guiding portfolio composition.&lt;ref&gt;{{Cite journal|last=Beat|first=Baer|last2=Mehta|first2=Amit|last3=Samandari|first3=Hamid|date=2011|title=The Use of Economic Capital in Performance Management for Banks: A Perspective|url=https://www.mckinsey.com/~/media/mckinsey/dotcom/client_service/risk/working%20papers/24_the_use_of_economic_capital.ashx|journal=McKinsey Working Paper on Risk|volume=24|pages=1-20|via=McKinsey}}&lt;/ref&gt;  The counterargument highlights that concentration and diversification effects should play a prominent role in portfolio selection – dynamics recognized in economic capital, but not regulatory capital. 

It did not take long for the industry to recognize the relevance and importance of both regulatory and economic measures, and eschewed focusing exclusively on one or the other. Relatively simple rules were devised to have both regulatory and economic capital enter into the process. In 2012, researchers at Moody’s Analytics designed a formal extension to the RORAC model that accounts for regulatory capital requirements as well as economic risks.&lt;ref&gt;{{Cite journal|last=Levy|first=Amnon|date=2012|title=A Unified Decision Measure Incorporating Both Regulatory Capital and Economic Capital|url=https://www.moodysanalytics.com/-/media/article/2017/capital-allocation-measure-integrating-regulatory-economic-capital-impact-of-ifrs9-cecl.pdf|journal=Moody's Analytics Whitepaper|volume=|pages=|via=}}&lt;/ref&gt; In the framework, capital allocation can be represented as a composite capital measure (CCM) that is a weighted combination of economic and regulatory capital – with the weight on regulatory capital determined by the degree to which an organization is capital constrained.&lt;ref&gt;{{Cite journal|last=Levy|first=Amnon|last2=Xu|first2=Pierre|date=2017|title=A Composite Capital Allocation Measure Integrating Regulatory and Economic Capital, and the Impact of IFRS 9 and CECL|url=https://www.moodysanalytics.com/-/media/article/2017/capital-allocation-measure-integrating-regulatory-economic-capital-impact-of-ifrs9-cecl.pdf|journal=Moody's Analytics Whitepaper|volume=|pages=|via=}}&lt;/ref&gt;

==See also==
*[[Enterprise risk management]]
*[[Financial risk management]]
*[[Omega ratio]]
*[[Risk-return spectrum]]
*[[Sharpe ratio]]
*[[Sortino ratio]]
* [[Risk return ratio|Risk Return Ratio]]

==Notes==
{{reflist}}

==References==
* {{cite book|last1=Glantz|first1=Morton|title=Managing Bank Risk: An Introduction to Broad-Base Credit Engineering|date=2003|publisher=Academic Press|location=Amsterdam|isbn=0-12-285785-2}}

==External links==
*[http://www.teradata.com/tdmo/v07n01/pdf/AR5210.pdf RAROC &amp; Economic Capital]
*[http://www.erisk.com/ResourceCenter/Features/raroc.pdf Between RAROC and a hard place]

{{Financial risk}}
{{Financial ratios}}

[[Category:Actuarial science]]
[[Category:Financial ratios]]
[[Category:Financial risk]]
[[Category:Capital requirement]]</text>
      <sha1>5pdxb825hc79ceqi6edmbw18r2bj12i</sha1>
    </revision>
  </page>
  <page>
    <title>Scientific community metaphor</title>
    <ns>0</ns>
    <id>2058995</id>
    <revision>
      <id>840193070</id>
      <parentid>822424172</parentid>
      <timestamp>2018-05-08T09:18:24Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 0 sources and tagging 1 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12816">{{Multiple issues|
{{context|date=October 2009}}
{{confusing|date=September 2009}}
{{COI|date=January 2015}}
}}

{{Copied to Wikibooks}}

In [[computer science]], the '''scientific community metaphor''' is a [[metaphor]] used to aid understanding [[scientific community|scientific communities]].  The first publications on the scientific community metaphor in 1981 and 1982&lt;ref&gt;[[Bill Kornfeld]] and [[Carl Hewitt]] 1981, Kornfeld 1981, Kornfeld 1982&lt;/ref&gt; involved the development of a [[programming language]] named [[Ether (programming language)|Ether]] that invoked procedural plans to process goals and assertions concurrently by dynamically creating new rules during program execution.  Ether also addressed issues of conflict and contradiction with multiple sources of knowledge and multiple viewpoints.

==Development==
The scientific community metaphor builds on the [[philosophy of science|philosophy]], [[history of science|history]] and [[sociology of science]].  It was originally developed building on work in the philosophy of science by [[Karl Popper]] and [[Imre Lakatos]].  In particular, it initially made use of Lakatos' work on [[Imre Lakatos#Proofs and refutations|proofs and refutations]]. Subsequently, development has been influenced by the work of Geof Bowker, [[Michel Callon]], [[Paul Feyerabend]], Elihu M. Gerson, [[Bruno Latour]], [[John Law (sociologist)|John Law]], [[Karl Popper]], [[Susan Leigh Star]], [[Anselm Strauss]], and [[Lucy Suchman]].

In particular Latour's ''[[Science in Action (book)|Science in Action]]'' had great influence.  In the book, [[Janus (mythology)|Janus]] figures make paradoxical statements about scientific development.  An important challenge for the scientific community metaphor is to reconcile these paradoxical statements.

==Qualities of scientific research==
Scientific research depends critically on monotonicity, concurrency, commutativity, and pluralism to propose, modify, support, and oppose scientific methods, practices, and theories. 
Quoting from Carl Hewitt,{{Ref|hewitt-2006}} scientific community metaphor systems have characteristics of ''monotonicity'', ''concurrency'', ''commutativity'', ''pluralism'', ''skepticism'' and ''provenance''.

:'''monotonicity''': Once something is published it cannot be undone.  Scientists publish their results so they are available to all.  Published work is collected and indexed in libraries.  Scientists who change their mind can publish later articles contradicting earlier ones.

:'''concurrency''': Scientists can work concurrently, overlapping in time and interacting with each other.

:'''commutativity''': Publications can be read regardless of whether they initiate new research or become relevant to ongoing research.  Scientists who become interested in a scientific question typically make an effort to find out if the answer has already been published.  In addition they attempt to keep abreast of further developments as they continue their work.

:'''pluralism''': Publications include heterogeneous, overlapping and possibly conflicting information.  There is no central arbiter of truth in scientific communities.

:'''skepticism''': Great effort is expended to test and validate current information and replace it with better information.

:'''provenance''': The provenance of information is carefully tracked and recorded.

The above characteristics are limited in real scientific communities.  Publications are sometimes lost or difficult to retrieve.  Concurrency is limited by resources including personnel and funding.  Sometimes it is easier to rederive a result than to look it up.  Scientists only have so much time and energy to read and try to understand the literature.  Scientific fads sometimes sweep up almost everyone in a field.  The order in which information is received can influence how it is processed.  Sponsors can try to control scientific activities.  In Ether the semantics of the kinds of activity described in this paragraph are governed by the [[actor model]].

Scientific research includes generating theories and processes for modifying, supporting, and opposing these theories.  [[Karl Popper]] called the process "conjectures and refutations", which although expressing a core insight, has been shown to be too restrictive a characterization by the work of [[Michel Callon]], [[Paul Feyerabend]], Elihu M. Gerson, [[Mark Johnson (professor)|Mark Johnson]], [[Thomas Samuel Kuhn|Thomas Kuhn]], [[George Lakoff]], [[Imre Lakatos]], [[Bruno Latour]], [[John Law (sociologist)|John Law]], [[Susan Leigh Star]], [[Anselm Strauss]], [[Lucy Suchman]], [[Ludwig Wittgenstein]], ''etc.''.  Three basic kinds of participation in Ether are proposing, supporting, and opposing.  Scientific communities are structured to support competition as well as cooperation.

These activities affect the adherence to approaches, theories, methods, ''etc.'' in scientific communities.  Current adherence does not imply adherence for all future time.  Later developments will modify and extend current understandings.  Adherence is a local rather than a global phenomenon.  No one speaks for the scientific community as a whole.

Opposing ideas may coexist in communities for centuries.  On rare occasions a community reaches a ''breakthrough''  that clearly decides an issue previously muddled.

==Ether==
Ether used ''viewpoints'' to relativist information in publications.  However a great deal of information is shared across viewpoints.  So Ether made use of ''inheritance'' so that information in a viewpoint could be readily used in other viewpoints.  Sometimes this inheritance is not exact as when the laws of physics in [[Newtonian mechanics]] are derived from those of [[Special Relativity]].  In such cases Ether used ''translation'' instead of inheritance.  [[Bruno Latour]] has analyzed translation in scientific communities in the context of [[actor network theory]].  [[Imre Lakatos]] studied very sophisticated kinds of translations of mathematical (''e.g.'', the [[Euler]] formula for [[polyhedra]]) and scientific theories.

Viewpoints were used to implement natural deduction (Fitch [1952]) in Ether.  In order to prove a goal of the form &lt;tt&gt;(P ''implies'' Q)&lt;/tt&gt; in a viewpoint &lt;tt&gt;V&lt;/tt&gt;, it is sufficient to create a new viewpoint &lt;tt&gt;V'&lt;/tt&gt; that inherits from &lt;tt&gt;V&lt;/tt&gt;, assert &lt;tt&gt;P&lt;/tt&gt; in &lt;tt&gt;V'&lt;/tt&gt;, and then prove &lt;tt&gt;Q&lt;/tt&gt; in &lt;tt&gt;V'&lt;/tt&gt;.  An idea like this was originally introduced into programming language proving by Rulifson, Derksen, and Waldinger [1973] except since Ether is concurrent rather than being sequential it does not rely on being in a single viewpoint that can be sequentially pushed and popped to move to other viewpoints.

Ultimately resolving issues among these viewpoints are matters for [[negotiation]] (as studied in the sociology and philosophy of science by Geof Bowker, [[Michel Callon]], [[Paul Feyerabend]], Elihu M. Gerson, [[Bruno Latour]], [[John Law (sociologist)|John Law]], [[Karl Popper]], Susan Leigh Star, Anselm Strauss, Lucy Suchman, etc.).

==Emphasis on communities rather than individuals==
[[Alan Turing]] was one of the first to attempt to more precisely characterize ''individual'' intelligence through the notion of his famous [[Turing Test]].  This paradigm was developed and deepened in the field of [[Artificial Intelligence]].  [[Allen Newell]] and [[Herbert A. Simon]] did pioneer work in analyzing the protocols of individual human problem solving behavior on puzzles.  More recently [[Marvin Minsky]] has developed the idea that the mind of an individual human is composed of a society of agents in [[Society of Mind]] (see the analysis by Push Singh).

The above research on individual human problem solving is ''complementary'' to the scientific community metaphor.

== Current applications==
Some developments in hardware and software technology for the [[Internet]] are being applied in light of the scientific community metaphor.{{Ref|RepeatedDemise|Hewitt 2006|-}}

Legal concerns (''e.g.'', [[Health Insurance Portability and Accountability Act|HIPAA]], [[Sarbanes-Oxley]], "The Books and Records Rules"  in SEC Rule 17a-3/4 and  "Design Criteria Standard for Electronic Records Management Software Applications"  in  DOD 5015.2 in the [[United States|U.S.]]) are leading organizations to store information monotonically forever.  It has just now become less costly in many cases to store information on [[disk storage|magnetic disk]] than on tape.  With increasing storage capacity, sites can monotonically record what they read from the Internet as well as monotonically recording their own operations.

[[Search engines]] currently provide rudimentary access to all this information.  Future systems will provide [[question answering|interactive question answering broadly conceived]] that will make all this information much more useful.

Massive [[concurrent computing|concurrency]] (''i.e.,'' [[Web service]]s and [[multi-core (computing)|multi-core]] computer architectures) lies in the future posing enormous challenges and opportunities for the scientific community metaphor. In particular, the scientific community metaphor is being used in client [[cloud computing]].&lt;ref&gt;[https://arxiv.org/abs/0901.4934 A historical perspective on developing foundations for privacy-friendly client cloud computing: the paradigm shift from “inconsistency denial” to “semantic integration”] ArXiv January 30, 2009.&lt;/ref&gt;

==See also==
* [[Paraconsistent logics]]
* [[Planner programming language|Planner]]
* [[Science studies]]
* ''[[The Structure of Scientific Revolutions]]''

==References==
{{reflist}}

==Further reading==
*Julian Davies. "Popler 1.5 Reference Manual" University of Edinburgh, TPU  Report No. 1, May 1973.
*Frederic Fitch. ''Symbolic Logic: an Introduction''. Ronald Press, New York, 1952.
*Ramanathan Guha. ''Contexts: A Formalization and Some Applications'' PhD thesis, Stanford University, 1991.
*Pat Hayes. "Computation and Deduction" Mathematical Foundations of Computer Science: Proceedings of Symposium and Summer School, Štrbské Pleso, High Tatras, Czechoslovakia, September 3–8, 1973.
*Carl Hewitt. "PLANNER: A Language for Proving Theorems in Robots" IJCAI 1969
*Carl Hewitt. "Procedural Embedding of Knowledge In Planner" IJCAI 1971.
*Carl Hewitt, Peter Bishop and Richard Steiger. "A Universal Modular Actor Formalism for Artificial Intelligence"  IJCAI 1973.
*Carl Hewitt. [http://hewitt-seminars.blogspot.com/2008/03/large-scale-organizational-computing.html Large-scale Organizational Computing requires Unstratified Reflection and Strong Paraconsistency] in "Coordination, Organizations, Institutions, and Norms in Agent Systems III" edited by Jaime Sichman, Pablo Noriega, Julian Padget and Sascha Ossowski.  Springer. 2008.
*Carl Hewitt. [http://hewitt-seminars.blogspot.com/2008/05/development-of-logic-programming-what.html '''Development of Logic Programming: What went wrong, What was done about it, and What it might mean for the future''']{{dead link|date=May 2018 |bot=InternetArchiveBot |fix-attempted=yes }} What Went Wrong and Why: Lessons from AI Research and Applications; papers from the 2008 AAAI Workshop. Technical Report WS-08-14. AAAI Press. July 2008.
*William Kornfeld and Carl Hewitt. [https://dspace.mit.edu/handle/1721.1/5693  "The Scientific Community Metaphor"] IEEE Transactions on Systems, Man and Cybernetics, SMC-11. 1981
*Bill Kornfeld. "The Use of Parallelism to Implement a Heuristic Search" IJCAI 1981.
*Bill Kornfeld.  ''Parallelism in Problem Solving'' MIT EECS Doctoral Dissertation. August 1981.
*Bill Kornfeld. "Combinatorially Implosive Algorithms" CACM.  1982.
*Robert Kowalski "Predicate Logic as Programming Language" Memo 70, Department of Artificial Intelligence, Edinburgh University.  1973
*Imre Lakatos. "Proofs and Refutations" Cambridge: Cambridge University Press. 1976.
*Bruno Latour. ''[[Science in Action (book)|Science In Action: How to Follow Scientists and Engineers Through Society]]'', Harvard University Press, Cambridge Mass., USA, 1987.
*John McCarthy.  "Generality in Artificial Intelligence" CACM.  December 1987.
*Jeff Rulifson, Jan Derksen, and [[Richard Waldinger]]. "QA4, A Procedural Calculus for Intuitive Reasoning" SRI AI Center Technical Note 73, November 1973.
*Earl Sacerdoti, et al., "QLISP A Language for the Interactive Development of Complex Systems"  AFIPS. 1976
*[http://web.media.mit.edu/~push/ExaminingSOM.html Push Singh "Examining the Society of Mind"] To appear in Computing and Informatics

{{DEFAULTSORT:Scientific Community Metaphor}}
[[Category:Actor model (computer science)]]
[[Category:Logic programming]]
[[Category:Science studies]]
[[Category:Philosophy of science|Philosophy of science]]
[[Category:Theoretical computer science]]</text>
      <sha1>9my9t7njxpyiov6dyohl1mmix7ha0wv</sha1>
    </revision>
  </page>
  <page>
    <title>Shelling (topology)</title>
    <ns>0</ns>
    <id>32457161</id>
    <revision>
      <id>790126790</id>
      <parentid>731585233</parentid>
      <timestamp>2017-07-11T19:42:50Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>see MOS:SECTIONORDER</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2619">In [[mathematics]], a '''shelling''' of a [[simplicial complex]] is a way of gluing it together from its maximal simplices (simplices that are not a face of another simplex) in a well-behaved way. A complex admitting a shelling is called '''shellable'''.

==Definition==
A ''d''-dimensional simplicial complex is called '''pure''' if its maximal simplices all have dimension ''d''. Let &lt;math&gt;\Delta&lt;/math&gt; be a finite or countably infinite simplicial complex. An ordering &lt;math&gt;C_1,C_2,\ldots&lt;/math&gt; of the maximal simplices of &lt;math&gt;\Delta&lt;/math&gt; is a '''shelling''' if the complex &lt;math&gt;B_k:=\left(\bigcup_{i=1}^{k-1}C_i\right)\cap C_k&lt;/math&gt; is pure and &lt;math&gt;(\dim C_k-1)&lt;/math&gt;-dimensional for all &lt;math&gt;k=2,3,\ldots&lt;/math&gt;. That is, the "new" simplex &lt;math&gt;C_k&lt;/math&gt; meets the previous simplices along some union &lt;math&gt;B_k&lt;/math&gt; of top-dimensional simplices of the boundary of &lt;math&gt;C_k&lt;/math&gt;. If &lt;math&gt;B_k&lt;/math&gt; is the entire boundary of &lt;math&gt;C_k&lt;/math&gt; then &lt;math&gt;C_k&lt;/math&gt; is called '''spanning'''.

For &lt;math&gt;\Delta&lt;/math&gt; not necessarily countable, one can define a shelling as a well-ordering of the maximal simplices of &lt;math&gt;\Delta&lt;/math&gt; having analogous properties.

==Properties==
* A shellable complex is [[homotopy|homotopy equivalent]] to a [[wedge sum]] of [[n-sphere|spheres]], one for each spanning simplex and of corresponding dimension.
* A shellable complex may admit many different shellings, but the number of spanning simplices, and their dimensions, do not depend on the choice of shelling. This follows from the previous property.

==Examples==
* Every [[Coxeter complex]], and more generally every [[building (mathematics)|building]], is shellable.&lt;ref&gt;{{Cite journal
| issn = 0001-8708
| volume = 52
| issue = 3
| pages = 173–212
| last = Björner
| first = Anders
| title = Some combinatorial and algebraic properties of Coxeter complexes and Tits buildings
| journal = Advances in Mathematics
| date = June 1984
| doi = 10.1016/0001-8708(84)90021-5
}}&lt;/ref&gt;

* There is an unshellable [[Triangulation (geometry)|triangulation]] of the [[tetrahedron]].&lt;ref&gt;{{Cite journal
| issn = 1088-9485
| volume = 64
| issue = 3
| pages = 90–91
| last = Rudin
| first = M.E.
| title = An unshellable triangulation of a tetrahedron
| journal = Bull. Am. Math. Soc.
| date = 1958-02-14
| doi=10.1090/s0002-9904-1958-10168-8
}}&lt;/ref&gt;

==Notes==
{{reflist}}

==References==
* {{cite book |author=Dmitry Kozlov |title=Combinatorial Algebraic Topology |publisher=Springer |location=Berlin |year=2008 |isbn=978-3-540-71961-8 |oclc= |doi=}}

[[Category:Topology]]
[[Category:Algebraic topology]]</text>
      <sha1>rm544dr4v9wr9rmwydg5if0rlyaz5s2</sha1>
    </revision>
  </page>
  <page>
    <title>Singly and doubly even</title>
    <ns>0</ns>
    <id>2481457</id>
    <revision>
      <id>832699420</id>
      <parentid>832585587</parentid>
      <timestamp>2018-03-27T14:26:57Z</timestamp>
      <contributor>
        <username>DePiep</username>
        <id>199625</id>
      </contributor>
      <minor/>
      <comment>OEIS in section external links: use dedicated {{OEIS el}} (via [[WP:JWB]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11583">In [[mathematics]] an [[parity (mathematics)|even]] [[integer]], that is, a number that is [[divisibility|divisible]] by 2, is called '''evenly even''' or '''doubly even''' if it is a multiple of 4, and '''oddly even''' or '''singly even''' if it is not.  (The former names are traditional ones, derived from the ancient Greek; the latter have become common in recent decades.)

These names reflect a basic concept in [[number theory]], the '''2-order''' of an integer: how many times the integer can be divided by 2. This is equivalent to the [[multiplicity (mathematics)|multiplicity]] of 2 in the [[prime factorization]].
A singly even number can be divided by 2 only once; it is even but its quotient by 2 is odd.
A doubly even number is an integer that is divisible more than once by 2; it is even and its quotient by 2 is also even.

The separate consideration of oddly and evenly even numbers is useful in many parts of mathematics, especially in number theory, [[combinatorics]], [[coding theory]] (see [[even code]]s), among others.

==Definitions==
The ancient Greek terms "even-times-even" and "even-times-odd" were given various inequivalent definitions by [[Euclid]] and later writers such as [[Nicomachus]].&lt;ref&gt;{{cite book |title=The Thirteen Books of Euclid's Elements |author=Euclid; Johan Ludvig Heiberg |year=1908 |publisher=The University Press |pages=281–284 |url=https://books.google.com/books?id=lxkPAAAAIAAJ}}&lt;/ref&gt; Today, there is a standard development of the concepts. The 2-order or 2-adic order is simply a special case of the [[p-adic order|''p''-adic order]] at a general [[prime number]] ''p''; see [[p-adic number|''p''-adic number]] for more on this broad area of mathematics. Many of the following definitions generalize directly to other primes.

For an integer ''n'', the 2-order of ''n'' (also called ''valuation'') is the largest natural number ν such that 2&lt;sup&gt;ν&lt;/sup&gt; [[divides]] ''n''. This definition applies to positive and negative numbers ''n'', although some authors restrict it to positive ''n''; and one may define the 2-order of 0 to be infinity (see also [[parity of zero]]).&lt;ref&gt;{{cite journal |first=Tamas |last=Lengyel |title=Characterizing the 2-adic order of the logarithm |journal=The Fibonacci Quarterly |volume=32 |year=1994 |pages=397–401 |url=http://employees.oxy.edu/lengyel/papers/FQ/pdf/log2.pdf}}&lt;/ref&gt; The 2-order of ''n'' is written ν&lt;sub&gt;2&lt;/sub&gt;(''n'') or ord&lt;sub&gt;2&lt;/sub&gt;(''n''). It is not to be confused with the multiplicative [[order (group theory)|order]] [[multiplicative group of integers modulo n|modulo 2]].

The 2-order provides a unified description of various classes of integers defined by evenness:
*Odd numbers are those with ν&lt;sub&gt;2&lt;/sub&gt;(''n'') = 0, i.e., integers of the form {{nowrap|2''m'' + 1}}.
*Even numbers are those with ν&lt;sub&gt;2&lt;/sub&gt;(''n'') &gt; 0, i.e., integers of the form {{nowrap|2''m''}}. In particular:
**Singly even numbers are those with ν&lt;sub&gt;2&lt;/sub&gt;(''n'') = 1, i.e., integers of the form {{nowrap|4''m'' + 2}}.
**Doubly even numbers are those with ν&lt;sub&gt;2&lt;/sub&gt;(''n'') &gt; 1, i.e., integers of the form {{nowrap|4''m''}}.
***In this terminology, a doubly even number may or may not be divisible by 8, so there is no particular terminology for "triply even" numbers.

One can also extend the 2-order to the [[rational numbers]] by defining ν&lt;sub&gt;2&lt;/sub&gt;(''q'') to be the unique integer ν where
:&lt;math&gt;q = 2^\nu\frac{a}{b}&lt;/math&gt;
and ''a'' and ''b'' are both odd. For example, [[half-integer]]s have a negative 2-order, namely &amp;minus;1. Finally, by defining the 2-adic norm,
:&lt;math&gt;|n|_2 = 2^{-\nu_2(n)},&lt;/math&gt;
one is well on the way to constructing the [[p-adic number|2-adic numbers]].

==Applications==

===Safer outs in darts===
The object of the game of [[darts]] is to reach a score of 0, so the player with the smaller score is in a better position to win. At the beginning of a leg, "smaller" has the usual meaning of [[absolute value]], and the basic strategy is to aim at high-value areas on the dartboard and score as many points as possible. At the end of a leg, since one needs to double out to win, the 2-adic norm becomes the relevant measure. With any odd score no matter how small in absolute value, it takes at least two darts to win. Any even score between 2 and 40 can be satisfied with a single dart, and 40 is a much more desirable score than 2, due to the effects of missing.

A common miss when aiming at the double ring is to hit a single instead and accidentally halve one's score. Given a score of 22 — a singly even number — one has a game shot for double 11. If one hits single 11, the new score is 11, which is odd, and it will take at least two further darts to recover. By contrast, when shooting for double 12, one may make the same mistake but still have 3 game shots in a row: D12, D6, and D3. Generally, with a score of {{nowrap|''n'' &lt; 42}}, one has {{nowrap|ν&lt;sub&gt;2&lt;/sub&gt;(''n'')}} such game shots. This is why {{nowrap|1=32 = 2&lt;sup&gt;5&lt;/sup&gt;}} is such a desirable score: it splits 5 times.&lt;ref&gt;{{cite book |title=Children Doing Mathematics |author=[[Terezinha Nunes|Nunes, Terezinha]] and Peter Bryant |year=1996 |publisher=Blackwell |isbn=0-631-18472-4 |pages=98–99}}&lt;/ref&gt;&lt;ref&gt;{{cite book |title=A Bar Player's Guide to Winning Darts |first=Fred |last=Everson |year=2006 |publisher=Trafford |isbn=1-55369-321-3 |page=39}}&lt;/ref&gt;

===Irrationality of {{radic|2}}===
The classic proof that the [[square root of 2]] is [[irrational number|irrational]] operates by [[infinite descent]]. Usually, the descent part of the proof is abstracted away by assuming (or proving) the existence of [[irreducible fraction|irreducible]] representations of [[rational number]]s. An alternate approach is to exploit the existence of the ν&lt;sub&gt;2&lt;/sub&gt; operator.

[[Assume by contradiction]] that

:&lt;math&gt;\sqrt2 = a / b,&lt;/math&gt;

where ''a'' and ''b'' are non-zero natural numbers. Square both sides of the equality and apply
the 2-order valuation operator ν&lt;sub&gt;2&lt;/sub&gt; to {{nowrap|1=2''b''&lt;sup&gt;2&lt;/sup&gt; = ''a''&lt;sup&gt;2&lt;/sup&gt;}}:

:&lt;math&gt;\nu_2(2b^2) = \nu_2(a^2)&lt;/math&gt;
:&lt;math&gt;\nu_2(b^2) + 1 = \nu_2(a^2)&lt;/math&gt;
:&lt;math&gt;2\nu_2(b) + 1 = 2\nu_2(a)&lt;/math&gt;
:&lt;math&gt;\nu_2(a) - \nu_2(b) = \frac12&lt;/math&gt;

Since 2-order valuations are integers, the difference cannot be equal to the rational &lt;math&gt;\frac12&lt;/math&gt;. By contradiction, therefore, {{radic|2}} is not a rational. 

More concretely, since the valuation of 2''b''&lt;sup&gt;2&lt;/sup&gt; is odd, while valuation of ''a''&lt;sup&gt;2&lt;/sup&gt; is even, they must be distinct integers, so that &lt;math&gt;|2 b^2 - a^2| \geq 1&lt;/math&gt;.  An easy calculation then yields a lower bound of &lt;math&gt;\frac{1}{3b^2}&lt;/math&gt; for the difference &lt;math&gt;|\sqrt2 - a / b|&lt;/math&gt;, yielding a direct proof of irrationality not relying on the law of excluded middle.&lt;ref&gt;{{cite book |title=The Moment of Proof: Mathematical Epiphanies |first=Donald C. |last=Benson |year=2000 |publisher=Oxford UP |isbn=0-19-513919-4 |pages=46–47}}&lt;/ref&gt;

===Geometric topology===
In [[geometric topology]], many properties of manifolds depend only on their dimension mod 4 or mod 8; thus one often studies manifolds of singly even and doubly even dimension (4''k''+2 and 4''k'') as classes. For example, doubly even-dimensional manifolds have a ''symmetric'' [[nondegenerate bilinear form]] on their middle-dimension [[cohomology group]], which thus has an integer-valued [[signature (topology)|signature]]. Conversely, singly even-dimensional manifolds have a [[Skew-symmetric graph|''skew''-symmetric]] nondegenerate bilinear form on their middle dimension; if one defines a [[quadratic refinement]] of this to a [[quadratic form]] (as on a [[framed manifold]]), one obtains the [[Arf invariant]] as a mod 2 invariant. Odd-dimensional manifolds, by contrast, do not have these invariants, though in [[algebraic surgery theory]] one may define more complicated invariants. This 4-fold and 8-fold periodicity in the structure of manifolds is related to the 4-fold periodicity of [[L-theory]] and the 8-fold periodicity of real [[topological K-theory]], which is known as [[Bott periodicity]] – note further that real K-theory is 4-fold periodic [[away from 2]].

If a [[compact space|compact]] [[oriented manifold|oriented]] [[smooth manifold|smooth]] [[spin manifold]] has dimension {{nowrap|''n'' ≡ 4 mod 8}}, or {{nowrap|1=ν&lt;sub&gt;2&lt;/sub&gt;(''n'') = 2}} exactly, then its [[signature (topology)|signature]] is an integer multiple of 16.&lt;ref&gt;Ochanine, Serge, "Signature modulo 16, invariants de Kervaire généralisés et nombres caractéristiques dans la K-théorie réelle", Mém. Soc. Math. France 1980/81, no. 5, 142 pp.  {{MathSciNet|id=1809832}}&lt;/ref&gt;

===Other appearances===

A singly even number cannot be a [[powerful number]]. It cannot be represented as a [[difference of two squares]]. However, a singly even number can be represented as the difference of two [[pronic number]]s or of two powerful numbers.&lt;ref group=&gt;* {{cite journal  | author = McDaniel, Wayne L.  | title = Representations of every integer as the difference of powerful numbers  | journal = [[Fibonacci Quarterly]]  | volume = 20  | year = 1982  | pages = 85–87}}&lt;/ref&gt;

In [[group theory]], it is relatively simple&lt;ref&gt;See, for example: {{cite book |title=Elements of mathematics: Algebra I: Chapters 1-3 |author=Bourbaki |publisher=Springer |year=1989 |edition=Softcover reprint of 1974 English translation |isbn=3-540-64243-9 |pages=154–155}}&lt;/ref&gt; to show that the order of a [[nonabelian group|nonabelian]] [[finite simple group]] cannot be a singly even number. In fact, by the [[Feit–Thompson theorem]], it cannot be odd either, so every such group has doubly even order.

[[Lambert's continued fraction]] for the [[tangent function]] gives the following [[continued fraction]] involving the positive singly even numbers:&lt;ref&gt;{{cite book |author=Hairer, Ernst and Gerhard Wanner |title=Analysis by Its History |year=1996 |publisher=Springer |isbn=0-387-94551-2 |pages=69–78}}&lt;/ref&gt;

:&lt;math&gt;\tanh \frac{1}{2} = \frac{e - 1}{e + 1} = 0 + \cfrac{1}{2 + \cfrac{1}{6 + \cfrac{1}{10 + \cfrac{1}{14 + \cfrac{1}{\ddots}}}}}&lt;/math&gt;

This expression leads to similar [[List of representations of e|representations of {{math|''e''}}]].&lt;ref&gt;{{cite book |title=Introduction to Diophantine Approximations |first=Serge |last=Lang |year=1995 |publisher=Springer |isbn=0-387-94456-7 |pages=69–73}}&lt;/ref&gt;

In [[organic chemistry]], [[Hückel's rule]], also known as the 4n + 2 rule, predicts that a [[cyclic compound|cyclic]] [[pi bond|π-bond]] system containing a singly even number of [[electron configuration|p electron]]s will be [[aromatic]].&lt;ref&gt;{{cite book |title=Organic Chemistry |author=Ouellette, Robert J. and J. David Rawn |publisher=Prentice Hall |isbn=0-02-390171-3 |page=473 |year=1996}}&lt;/ref&gt;

==Related classifications==
Although the 2-order can detect when an integer is congruent to 0 (mod 4) or 2 (mod 4), it cannot tell the difference between 1 (mod 4) or 3 (mod 4). This distinction has some interesting consequences, such as [[Fermat's theorem on sums of two squares]].

==See also==

* [[p-adic order]]

==References==
{{reflist}}

==External links==
*[http://planetmath.org/encyclopedia/SinglyEvenNumber.html singly even number] at [[PlanetMath]]
*{{OEIS el|sequencenumber=A016825|name=Numbers congruent to 2 mod 4|formalname=Positive integers congruent to 2 mod 4: a(n) = 4n+2, for n &gt;= 0}}
*{{OEIS el|sequencenumber=A008586|name=Multiples of 4}}

[[Category:Integer sequences]]
[[Category:Parity (mathematics)]]
[[Category:Elementary number theory]]</text>
      <sha1>kqdaejrkexfyqqwreigylckteoevmdo</sha1>
    </revision>
  </page>
  <page>
    <title>Symbol of a differential operator</title>
    <ns>0</ns>
    <id>10639143</id>
    <revision>
      <id>861024052</id>
      <parentid>861023947</parentid>
      <timestamp>2018-09-24T17:22:00Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5642">{{Expert-subject|Mathematics|date=February 2009}}

In [[mathematics]], the '''symbol of a linear differential operator''' is obtained from a [[differential operator]] of a [[polynomial]] by, roughly speaking, replacing each [[partial derivative]] by a new variable. The symbol of a differential operator has broad applications to [[Fourier analysis]]. In particular, in this connection it leads to the notion of a [[pseudo-differential operator]].  The highest-order terms of the symbol, known as the principal symbol, almost completely controls the qualitative behavior of solutions of a [[partial differential equation]].  Linear [[elliptic partial differential equation]]s can be characterized as those whose principal symbol is nowhere zero.  In the study of [[hyperbolic partial differential equation|hyperbolic]] and [[parabolic partial differential equation]]s, zeros of the principal symbol correspond to the [[method of characteristics|characteristics]] of the partial differential equation.  Consequently, the symbol is often fundamental for the solution of such equations, and is one of the main computational devices used to study their singularities.

==Definition==
===Operators on Euclidean space===
Let ''P'' be a linear differential operator of order ''k'' on the [[Euclidean space]] '''R'''&lt;sup&gt;''d''&lt;/sup&gt;.  Then ''P'' is a polynomial in the derivative ''D'', which in [[multi-index]] notation can be written
:&lt;math&gt;P = p(x,D) = \sum_{|\alpha|\le k} a_\alpha(x) D^\alpha.&lt;/math&gt;
The '''total symbol''' of ''P'' is the polynomial ''p'':

:&lt;math&gt; p(x,\xi) = \sum_{|\alpha|\le k} a_\alpha(x)\xi^\alpha.&lt;/math&gt;

The '''leading symbol''', also known as the '''principal symbol''', is the highest-degree component of ''p'' :

:&lt;math&gt;\sigma_P (\xi) = \sum_{|\alpha|= k} a_\alpha\xi^\alpha&lt;/math&gt;

and is of importance later because it is the only part of the symbol that transforms as a [[tensor]] under changes to the coordinate system.

The symbol of ''P'' appears naturally in connection with the [[Fourier transform]] as follows.  Let ƒ be a [[Schwartz function]].  Then by the inverse Fourier transform,

:&lt;math&gt;Pf(x) = \frac{1}{(2\pi)^d} \int_{\mathbf{R}^d} e^{ ix\cdot\xi} p(x,i\xi)\hat{f}(\xi)\, d\xi.&lt;/math&gt;

This exhibits ''P'' as a [[Fourier multiplier]].  A more general class of functions ''p''(''x'',ξ) which satisfy at most polynomial growth conditions in ξ under which this integral is well-behaved comprises the [[pseudo-differential operator]]s.

===Vector bundles===

Let ''E'' and ''F'' be [[vector bundle]]s over a [[closed manifold]] ''X'', and suppose

:&lt;math&gt; P: C^\infty(E) \to C^\infty(F) &lt;/math&gt;

is a differential operator of order &lt;math&gt; k &lt;/math&gt;. In [[local coordinates]] on ''X'', we have 

:&lt;math&gt; Pu(x)  = \sum_{|\alpha| = k} P^\alpha(x) \frac {\partial^\alpha u} {\partial x^{\alpha}} + \text{lower-order terms}&lt;/math&gt;

where, for each [[multi-index]] α, &lt;math&gt; P^\alpha(x):E \to F&lt;/math&gt; is a [[bundle map]], symmetric on the indices α.

The ''k''&lt;sup&gt;th&lt;/sup&gt; order coefficients of ''P'' transform as a [[symmetric tensor]]

:&lt;math&gt; \sigma_P: S^k (T^*X) \otimes E \to F &lt;/math&gt;

from the [[tensor product]] of the ''k''&lt;sup&gt;th&lt;/sup&gt; [[symmetric power]] of the [[cotangent bundle]] of ''X'' with ''E'' to ''F''.  This symmetric tensor is known as the '''principal symbol''' (or just the '''symbol''') of ''P''.

The coordinate system ''x''&lt;sup&gt;''i''&lt;/sup&gt; permits a local trivialization of the cotangent bundle by the coordinate differentials d''x''&lt;sup&gt;''i''&lt;/sup&gt;, which determine fiber coordinates ξ&lt;sub&gt;''i''&lt;/sub&gt;. In terms of a basis of frames ''e''&lt;sub&gt;μ&lt;/sub&gt;, ''f''&lt;sub&gt;ν&lt;/sub&gt; of ''E'' and ''F'', respectively, the differential operator ''P'' decomposes into components

:&lt;math&gt;(Pu)_\nu = \sum_\mu P_{\nu\mu}u_\mu&lt;/math&gt;

on each section ''u'' of ''E''.  Here ''P''&lt;sub&gt;νμ&lt;/sub&gt; is the scalar differential operator defined by

:&lt;math&gt;P_{\nu\mu} = \sum_{\alpha} P_{\nu\mu}^\alpha\frac{\partial}{\partial x^\alpha}.&lt;/math&gt;

With this trivialization, the principal symbol can now be written

:&lt;math&gt;(\sigma_P(\xi)u)_\nu = \sum_{|\alpha|=k} \sum_{\mu}P_{\nu\mu}^\alpha(x)\xi_\alpha u^\mu.&lt;/math&gt;

In the cotangent space over a fixed point ''x'' of ''X'', the symbol &lt;math&gt; \sigma_P &lt;/math&gt; defines a [[homogeneous polynomial]] of degree ''k'' in &lt;math&gt; T^*_x X &lt;/math&gt; with values in &lt;math&gt; \operatorname{Hom}(E_x, F_x) &lt;/math&gt;.  

The differential operator &lt;math&gt; P &lt;/math&gt; is [[elliptic differential operator|elliptic]] if its symbol is invertible; that is for each nonzero &lt;math&gt; \theta \in T^*X &lt;/math&gt; the bundle map &lt;math&gt; \sigma_P (\theta, \dots, \theta)&lt;/math&gt; is invertible. On a [[compact manifold]], it follows from the elliptic theory that ''P'' is a [[Fredholm operator]]: it has finite-dimensional [[kernel (algebra)|kernel]] and cokernel.

==See also==
* [[Multiplier (Fourier analysis)]]
* [[Atiyah–Singer index theorem#Symbol of a differential operator|Atiyah–Singer index theorem (section on symbol of operator)]]

==References==
{{reflist}}
* {{citation|first=Daniel S.|last=Freed|title=Geometry of Dirac operators|p=8}} &lt;!--Year? Publisher?--&gt;
*{{citation|mr=0717035|first=L.|last= Hörmander|authorlink=Lars Hörmander|title=The analysis of linear partial differential operators I|series= Grundl. Math. Wissenschaft. |volume= 256 |publisher=Springer |year=1983|isbn=3-540-12104-8 |doi=10.1007/978-3-642-96750-4}}.
* {{citation|last=Wells|first=R.O.|authorlink=Raymond O. Wells, Jr.|title=Differential analysis on complex manifolds|year=1973|publisher=Springer-Verlag|isbn=0-387-90419-0}}.

[[Category:Differential operators]]
[[Category:Vector bundles]]</text>
      <sha1>0y3cjybti6mo13goi6p7jqvk55r27gw</sha1>
    </revision>
  </page>
  <page>
    <title>Total variation</title>
    <ns>0</ns>
    <id>683561</id>
    <revision>
      <id>853137708</id>
      <parentid>849103360</parentid>
      <timestamp>2018-08-02T17:36:25Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Removed 1 archive link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24538">{{distinguish|Total variation distance of probability measures}}
{{primary sources|date=February 2012}}
[[Image:Total variation.gif|right|frame|As the green ball travels on the graph of the given function, the length of the path travelled by that ball's projection on the ''y''-axis, shown as a red ball, is the total variation of the function.]]

In [[mathematics]], the '''total variation''' identifies several slightly different concepts, related to the ([[local property|local]] or global) structure of the [[codomain]] of a [[Function (mathematics)|function]] or a [[measure (mathematics)|measure]]. For a [[real number|real-valued]] [[continuous function]] ''f'', defined on an [[interval (mathematics)|interval]] [''a'', ''b''] ⊂ ℝ, its total variation on the interval of definition is a measure of the one-dimensional [[arclength]] of the curve with parametric equation ''x'' ↦ ''f''(''x''), for ''x'' ∈ [''a'', ''b''].

==Historical note==
The concept of total variation for functions of one real variable was first introduced by [[Camille Jordan]] in the paper {{Harv|Jordan|1881}}.&lt;ref&gt;According to {{Harvtxt|Golubov|Vitushkin|2001}}.&lt;/ref&gt; He used the new concept in order to prove a convergence theorem for [[Fourier series]] of [[discontinuous function|discontinuous]] [[periodic function]]s whose variation is [[Bounded variation|bounded]]. The extension of the concept to functions of more than one variable however is not simple for various reasons.

==Definitions==

===Total variation for functions of one real variable===
{{EquationRef|1|Definition 1.1.}} The '''total variation''' of a [[real number|real]]-valued (or more generally [[complex number|complex]]-valued) [[function (mathematics)|function]] ''&lt;math&gt;f&lt;/math&gt;'', defined on an [[interval (mathematics)|interval]] &lt;math&gt; [a , b] \subset \mathbb{R}&lt;/math&gt; is the quantity

:&lt;math&gt; V^a_b(f)=\sup_{\mathcal{P}} \sum_{i=0}^{n_P-1} | f(x_{i+1})-f(x_i) |, &lt;/math&gt;

where the [[supremum]] runs over the [[Set (mathematics)|set]] of all [[partition of an interval|partitions]] &lt;math&gt; \scriptstyle \mathcal{P} =\left\{P=\{ x_0, \dots , x_{n_P}\}|P\text{ is a partition of } [a,b] \right\} &lt;/math&gt; of the given [[interval (mathematics)|interval]].

===Total variation for functions of ''n'' &gt; 1 real variables===
{{EquationRef|2|Definition 1.2.}} Let '''Ω''' be an [[open subset]] of ℝ&lt;sup&gt;''n''&lt;/sup&gt;. Given a function ''f'' belonging to ''L''&lt;sup&gt;1&lt;/sup&gt;('''Ω'''), the '''total variation''' of ''f'' in '''Ω''' is defined as

:&lt;math&gt; V(f,\Omega):=\sup\left\{\int_\Omega f(x) \operatorname{div} \phi(x) \, \mathrm{d}x \colon \phi\in  C_c^1(\Omega,\mathbb{R}^n),\ \Vert \phi\Vert_{L^\infty(\Omega)}\le 1\right\}, &lt;/math&gt;

where  &lt;math&gt; \scriptstyle C_c^1(\Omega,\mathbb{R}^n)&lt;/math&gt; is the [[Set (mathematics)|set]] of [[Smooth function|continuously differentiable]] [[vector-valued function|vector functions]] of [[support (mathematics)#Compact support|compact support]] contained  in &lt;math&gt;\Omega&lt;/math&gt;, and &lt;math&gt; \scriptstyle \Vert\;\Vert_{L^\infty(\Omega)}&lt;/math&gt; is the [[essential supremum]] [[Norm (mathematics)|norm]]. Note that this definition ''does not require'' that the [[Domain of a function|domain]] &lt;math&gt;\Omega \subseteq \mathbb{R}^n&lt;/math&gt; of the given function be a [[bounded set]].

===Total variation in measure theory===

====Classical total variation definition====
Following {{Harvtxt|Saks|1937|p=10}}, consider a [[signed measure]] ''&lt;math&gt;\mu&lt;/math&gt;'' on a [[sigma-algebra|measurable space]] &lt;math&gt;(X,\Sigma)&lt;/math&gt;: then it is possible to define two [[set function]]s &lt;math&gt;\scriptstyle\overline{\mathrm{W}}(\mu,\cdot)&lt;/math&gt; and &lt;math&gt;\scriptstyle\underline{\mathrm{W}}(\mu,\cdot)&lt;/math&gt;, respectively called '''upper variation''' and '''lower variation''', as follows

:&lt;math&gt;\overline{\mathrm{W}}(\mu,E)=\sup\left\{\mu(A)\mid A\in\Sigma\text{ and }A\subset E \right\}\qquad\forall E\in\Sigma&lt;/math&gt;
:&lt;math&gt;\underline{\mathrm{W}}(\mu,E)=\inf\left\{\mu(A)\mid A\in\Sigma\text{ and }A\subset E \right\}\qquad\forall E\in\Sigma&lt;/math&gt;

clearly

:&lt;math&gt;\overline{\mathrm{W}}(\mu,E)\geq 0 \geq \underline{\mathrm{W}}(\mu,E)\qquad\forall E\in\Sigma&lt;/math&gt;

{{EquationRef|3|Definition 1.3.}} The '''variation''' (also called '''absolute variation''') of the signed measure ''&lt;math&gt;\mu&lt;/math&gt;'' is the set function

:&lt;math&gt;|\mu|(E)=\overline{\mathrm{W}}(\mu,E)+\left|\underline{\mathrm{W}}(\mu,E)\right|\qquad\forall E\in\Sigma&lt;/math&gt;

and its '''total variation''' is defined as the value of this measure on the whole space of definition, i.e.

:&lt;math&gt;\|\mu\|=|\mu|(X)&lt;/math&gt;

====Modern definition of total variation norm====
{{Harvtxt|Saks|1937|p=11}} uses upper and lower variations to prove the [[Hahn decomposition theorem|Hahn&amp;ndash;Jordan decomposition]]: according to his version of this theorem, the upper and lower variation are respectively a [[non-negative]] and a [[non-positive]] [[Measure (mathematics)|measure]]. Using a more modern notation, define

:&lt;math&gt;\mu^+(\cdot)=\overline{\mathrm{W}}(\mu,\cdot)\,,&lt;/math&gt;
:&lt;math&gt;\mu^-(\cdot)=-\underline{\mathrm{W}}(\mu,\cdot)\,,&lt;/math&gt;

Then ''&lt;math&gt;\mu^+&lt;/math&gt;'' and ''&lt;math&gt;\mu^-&lt;/math&gt;'' are two non-negative [[measure (mathematics)|measure]]s such that

:&lt;math&gt;\mu=\mu^+-\mu^-&lt;/math&gt;
:&lt;math&gt;|\mu|=\mu^++\mu^-&lt;/math&gt;

The last measure is sometimes called, by [[abuse of notation]], '''total variation measure'''.

====Total variation norm of complex measures====
If the measure ''&lt;math&gt;\mu&lt;/math&gt;'' is [[Complex number|complex-valued]] i.e. is a [[complex measure]], its upper and lower variation cannot be defined and the Hahn&amp;ndash;Jordan decomposition theorem can only be applied to its real and imaginary parts. However, it is possible to follow {{Harvtxt|Rudin|1966|pp=137&amp;ndash;139}} and define the total variation of the complex-valued measure ''&lt;math&gt;\mu&lt;/math&gt;'' as follows

{{EquationRef|4|Definition 1.4.}} The '''variation''' of the complex-valued measure ''&lt;math&gt;\mu&lt;/math&gt;'' is the [[set function]]

:&lt;math&gt;|\mu|(E)=\sup_\pi \sum_{A\isin\pi} |\mu(A)|\qquad\forall E\in\Sigma&lt;/math&gt;

where the [[supremum]] is taken over all partitions ''&lt;math&gt;\pi&lt;/math&gt;'' of a [[measurable set]] ''&lt;math&gt;E&lt;/math&gt;'' into a countable number of disjoint measurable subsets.

This definition coincides with the above definition ''&lt;math&gt;|\mu|=\mu^++\mu^-&lt;/math&gt;'' for the case of real-valued signed measures.

====Total variation norm of vector-valued measures====

The variation so defined is a [[positive measure]] (see {{Harvtxt|Rudin|1966|p=139}}) and coincides with the one defined by {{EquationNote|3|1.3}} when ''&lt;math&gt;\mu&lt;/math&gt;'' is a [[signed measure]]: its total variation is defined as above. This definition works also if ''&lt;math&gt;\mu&lt;/math&gt;'' is a [[vector measure]]: the variation is then defined by the following formula

:&lt;math&gt;|\mu|(E) = \sup_\pi \sum_{A\isin\pi} \|\mu(A)\|\qquad\forall E\in\Sigma&lt;/math&gt;

where the supremum is as above. Note also that this definition is slightly more general than the one given by {{Harvtxt|Rudin|1966|p=138}} since it requires only to consider ''finite partitions'' of the space ''&lt;math&gt;X&lt;/math&gt;'': this implies that it can be used also to define the total variation on [[Sigma additivity|finite-additive measures]].

====Total variation of probability measures====
{{unreferenced section|date=May 2012}}
{{main|Total variation distance of probability measures}}
The total variation of any [[probability measure]] is exactly one, therefore it is not interesting as a means of investigating the properties of such measures. However, when μ and ν are [[probability measure]]s, the '''[[total variation distance of probability measures]]''' can be defined as ''&lt;math&gt;\| \mu - \nu \|&lt;/math&gt;'' where the norm is the total variation norm of signed measures.  Using the property that ''&lt;math&gt;(\mu-\nu)(X)=0&lt;/math&gt;'', we eventually arrive at the equivalent definition

:&lt;math&gt;\|\mu-\nu\| = |\mu-\nu|(X)=2 \sup\left\{\,\left|\mu(A)-\nu(A)\right| : A\in \Sigma\,\right\}&lt;/math&gt;

and its values are non-trivial. The factor &lt;math&gt;2&lt;/math&gt; above is usually dropped (as is the convention in the article [[total variation distance of probability measures]]). Informally, this is the largest possible difference between the probabilities that the two [[probability distribution]]s can assign to the same event. For a [[categorical distribution]] it is possible to write the total variation distance as follows

:&lt;math&gt;\delta(\mu,\nu) = \sum_x \left| \mu(x) - \nu(x) \right|\;.&lt;/math&gt;

It may also be normalized to values in  &lt;math&gt;[0, 1]&lt;/math&gt; by halving the previous definition as follows

:&lt;math&gt;\delta(\mu,\nu) = \frac{1}{2}\sum_x \left| \mu(x) - \nu(x) \right|&lt;/math&gt;&lt;ref&gt;{{cite web|last1=Gibbs|first1=Alison|author2=Francis Edward Su|title=On Choosing and Bounding Probability Metrics|url=https://www.math.hmc.edu/~su/papers.dir/metrics.pdf|accessdate=8 April 2017|pages=7|date=2002}}&lt;/ref&gt;

==Basic properties==

===Total variation of differentiable functions===
The total variation of a &lt;math&gt;C^1(\overline{\Omega})&lt;/math&gt;  function &lt;math&gt;f&lt;/math&gt; can be expressed as an [[integral]] involving the given function instead of as the [[supremum]] of the [[functional (mathematics)|functional]]s of definitions {{EquationNote|1|1.1}} and {{EquationNote|2|1.2}}.

====The form of the total variation of a differentiable function of one variable====
{{EquationRef|5|Theorem 1.}} The '''total variation''' of a [[differentiable function]] ''&lt;math&gt;f&lt;/math&gt;'', defined on an [[interval (mathematics)|interval]] &lt;math&gt; [a , b] \subset \mathbb{R}&lt;/math&gt;, has the following expression if ''&lt;math&gt;f'&lt;/math&gt;'' is Riemann integrable

:&lt;math&gt; V^a_b(f) = \int _a^b |f'(x)|\mathrm{d}x&lt;/math&gt;

====The form of the total variation of a differentiable function of several variables====
{{EquationRef|6|Theorem 2.}} Given a &lt;math&gt;C^1(\overline{\Omega})&lt;/math&gt; function '''&lt;math&gt;f&lt;/math&gt;''' defined on a [[bounded set|bounded]] [[open set]] &lt;math&gt;\Omega \subseteq \mathbb{R}^n&lt;/math&gt;, with &lt;math&gt;\partial \Omega &lt;/math&gt; of class &lt;math&gt;C^1&lt;/math&gt;,  the '''total variation of &lt;math&gt;f&lt;/math&gt;''' has the following expression

:&lt;math&gt;V(f,\Omega) = \int\limits_\Omega\left|\nabla f(x)\right|\mathrm{d}x&lt;/math&gt;

Here &lt;math&gt;|.|&lt;/math&gt; denotes the &lt;math&gt;l_2&lt;/math&gt;-norm.

=====Proof=====
The first step in the proof is to first prove an equality which follows from the [[Gauss–Ostrogradsky theorem]].

=====Lemma=====
Under the conditions of the theorem, the following equality holds:
: &lt;math&gt; \int\limits_\Omega f\operatorname{div}\varphi = -\int_\Omega\nabla f\cdot\varphi &lt;/math&gt;

======Proof of the lemma======
From the [[Gauss–Ostrogradsky theorem]]:
: &lt;math&gt; \int\limits_\Omega \operatorname{div}\mathbf R = \int\limits_{\partial\Omega}\mathbf R\cdot \mathbf n &lt;/math&gt;
by substituting &lt;math&gt;\mathbf R:= f\mathbf\varphi&lt;/math&gt;, we have:

:&lt;math&gt; \int\limits_\Omega\operatorname{div}\left(f\mathbf\varphi\right) =
\int\limits_{\partial\Omega}\left(f\mathbf\varphi\right)\cdot\mathbf n &lt;/math&gt;
where &lt;math&gt;\mathbf\varphi &lt;/math&gt; is zero on the border of &lt;math&gt;\Omega&lt;/math&gt; by definition:
:&lt;math&gt; \int\limits_\Omega\operatorname{div}\left(f\mathbf\varphi\right)=0&lt;/math&gt;
:&lt;math&gt; \int\limits_\Omega \partial_{x_i} \left(f\mathbf\varphi_i\right)=0&lt;/math&gt;
:&lt;math&gt; \int\limits_\Omega \mathbf\varphi_i\partial_{x_i} f + f\partial_{x_i}\mathbf\varphi_i=0&lt;/math&gt;
:&lt;math&gt; \int\limits_\Omega f\partial_{x_i}\mathbf\varphi_i = - \int\limits_\Omega \mathbf\varphi_i\partial_{x_i} f &lt;/math&gt;
:&lt;math&gt; \int\limits_\Omega f\operatorname{div} \mathbf\varphi = - \int\limits_\Omega \mathbf\varphi\cdot\nabla f &lt;/math&gt;

=====Proof of the equality=====
Under the conditions of the theorem, from the lemma we have:
:&lt;math&gt; \int\limits_\Omega f\operatorname{div} \mathbf\varphi = - \int\limits_\Omega \mathbf\varphi\cdot\nabla f \leq \left| \int\limits_\Omega \mathbf\varphi\cdot\nabla f \right|\leq \int\limits_\Omega \left|\mathbf\varphi\right|\cdot\left|\nabla f\right|\leq \int\limits_\Omega \left|\nabla f\right| &lt;/math&gt;
in the last part &lt;math&gt;\mathbf\varphi&lt;/math&gt; could be omitted, because by definition its essential supremum is at most one.

On the other hand we consider &lt;math&gt;\theta_N:=-\mathbb I_{\left[-N,N\right]}\mathbb I_{\{\nabla f\ne 0\}}\frac{\nabla f}{\left|\nabla f\right|}&lt;/math&gt; and &lt;math&gt;\theta^*_N&lt;/math&gt; which is the up to &lt;math&gt;\varepsilon&lt;/math&gt; approximation of &lt;math&gt;\theta&lt;/math&gt; in &lt;math&gt; C^1_c&lt;/math&gt; with the same integral. We can do this since &lt;math&gt; C^1_c&lt;/math&gt; is dense in &lt;math&gt; L^1 &lt;/math&gt;. Now again substituting into the lemma:

:&lt;math&gt;\lim\limits_{N\rightarrow\infty}\int\limits_\Omega f\operatorname{div}\theta^*_N =
\lim\limits_{N\rightarrow\infty}\int\limits_{\{\nabla f\ne 0\}}\mathbb I_{\left[-N,N\right]}\nabla f\cdot\frac{\nabla f}{\left|\nabla f\right|}=
\lim\limits_{N\rightarrow\infty}\int\limits_{\mathbb I_{\left[-N,N\right]}\cap{\{\nabla f\ne 0\}}} \nabla f\cdot\frac{\nabla f}{\left|\nabla f\right|} = \int\limits_\Omega\left|\nabla f\right|
&lt;/math&gt;
This means we have a convergent sequence of &lt;math&gt;\int\limits_\Omega f \operatorname{div} \mathbf\varphi&lt;/math&gt; that tends to &lt;math&gt;\int\limits_\Omega\left|\nabla f\right|&lt;/math&gt; as well as we know that &lt;math&gt;\int\limits_\Omega f\operatorname{div}\mathbf\varphi \leq \int\limits_\Omega\left|\nabla f\right| &lt;/math&gt;. q.e.d.

It can be seen from the proof that the supremum is attained when
: &lt;math&gt;\varphi\to \frac{-\nabla f}{\left|\nabla f\right|}.&lt;/math&gt;

The [[Function (mathematics)|function]] ''&lt;math&gt;f&lt;/math&gt;'' is said to be of [[bounded variation]] precisely if its total variation is finite.

===Total variation of a measure===
The total variation is a [[norm (mathematics)|norm]] defined on the space of measures of bounded variation.  The space of measures on a σ-algebra of sets is a [[Banach space]], called the [[ca space]], relative to this norm.  It is contained in the larger Banach space, called the [[ba space]], consisting of ''[[Finitely additive measure|finitely additive]]'' (as opposed to countably additive) measures, also with the same norm. The [[distance function]] associated to the norm gives rise to the total variation distance between two measures ''μ'' and ''ν''.

For finite measures on ℝ, the link between the total variation of a measure ''μ'' and the total variation of a function, as described above, goes as follows. Given ''μ'', define a function &lt;math&gt;\scriptstyle\varphi\colon \mathbb{R}\to \mathbb{R}&lt;/math&gt; by
:&lt;math&gt;\varphi(t) = \mu((-\infty,t])~.&lt;/math&gt;
Then, the total variation of the signed measure ''μ'' is equal to the total variation, in the above sense, of the function ''φ''. In general, the total variation of a signed measure can be defined using [[Hahn decomposition theorem|Jordan's decomposition theorem]] by
:&lt;math&gt;\|\mu\|_{TV} = \mu_+(X) + \mu_-(X)~,&lt;/math&gt;
for any signed measure ''μ'' on a measurable space &lt;math&gt;(X,\Sigma)&lt;/math&gt;.

== Applications ==
Total variation can be seen as a [[non-negative]] [[real number|real]]-valued [[functional (mathematics)|functional]] defined on the space of [[real number|real-valued]] [[function (mathematics)|function]]s (for the case of functions of one variable) or on the space of [[integrable function]]s (for the case of functions of several variables). As a functional, total variation finds applications in several branches of mathematics and engineering, like [[optimal control]], [[numerical analysis]], and [[calculus of variations]], where the solution to a certain problem has to [[Maxima and minima|minimize]] its value. As an example, use of the total variation functional is common in the following two kind of problems

* '''Numerical analysis of differential equations''': it is the science of finding approximate solutions to [[differential equation]]s. Applications of total variation to these problems are detailed in the article "''[[total variation diminishing]]''"
* '''Image denoising''': in [[image processing]], denoising is a collection of methods used to reduce the [[Electronic noise|noise]] in an [[image]] reconstructed from data obtained by electronic means, for example [[data transmission]] or [[Sensor|sensing]]. "''[[Total variation denoising]]''" is the name for the application of total variation to image noise reduction; further details can be found in the papers of {{Harv|Rudin|Osher|Fatemi|1992}} and {{Harv|Caselles|Chambolle|Novaga|2007}}. A sensible extension of this model to colour images, called Colour TV, can be found in {{Harv|Blomgren|Chan|1998}}.

== See also ==
* [[Bounded variation]]
* [[p-variation]]
* [[Total variation diminishing]]
* [[Total variation denoising]]
* [[Quadratic variation]]
* [[Total variation distance of probability measures]]
* [[Kolmogorov–Smirnov test]]

==Notes==
{{more footnotes|date=February 2012}}
{{Reflist|2}}

==Historical references==
*{{Citation
| last = Arzelà
| first = Cesare
| author-link = Cesare Arzelà
| title = Sulle funzioni di due variabili a variazione limitata (On functions of two variables of bounded variation)
| journal = Rendiconto delle sessioni della [[Reale Accademia delle scienze dell'Istituto di Bologna]]
| series = Nuova serie
| volume = IX
| issue = 4
| pages = 100–107
| language = Italian
| date = 7 May 1905
| url = https://archive.org/details/rendicontodelle04bologoog
| archiveurl = https://archive.org/stream/rendicontodelle04bologoog#page/n121/mode/2up
| archivedate = 2007-08-07
| doi =
| jfm = 36.0491.02
}}.
*{{springer
| title= Arzelà variation
| id= a/a013470
| last= Golubov
| first= Boris I.
}}.
*{{springer
| title= Fréchet variation
| id= f/f041400
| last= Golubov
| first= Boris I.
}}.
*{{springer
| title= Hardy variation
| id= h/h046400
| last= Golubov
| first= Boris I.
}}.
*{{springer
| title= Pierpont variation
| id= p/p072720
| last= Golubov
| first= Boris I.
}}.
*{{springer
| title= Vitali variation
| id= h/h046400
| last= Golubov
| first= Boris I.
}}.
*{{springer
| title= Tonelli plane variation
| id= t/t092990
| last= Golubov
| first= Boris I.
}}.
*{{springer
| title= Variation of a function
| id= V/v096110
| last= Golubov
| first= Boris I.
| last2= Vitushkin
| first2= Anatoli G.
| author2-link= Anatoli Georgievich Vitushkin
}}
*{{Citation
| last = Jordan
| first = Camille
| author-link = Camille Jordan
| title = Sur la série de Fourier
| journal = Comptes rendus hebdomadaires des séances de l'Académie des sciences
| language = French
| volume = 92
| pages = 228–230
| year = 1881
| url = http://gallica.bnf.fr/ark:/12148/bpt6k7351t/f227
| jfm = 13.0184.01
}} (available at [[Gallica]]). This is, according to Boris Golubov, the first paper on functions of bounded variation.
*{{Citation
| last = Hahn
| first = Hans
| author-link = Hans Hahn (mathematician)
| title = Theorie der reellen Funktionen
| place = Berlin
| publisher = Springer Verlag
| year = 1921
| language = German
| pages = VII+600
| url = https://archive.org/details/theoriederreelle01hahnuoft
| doi =
| jfm = 48.0261.09
| isbn = 
}}.
* {{Citation
| last = Vitali
| first = Giuseppe
| author-link= Giuseppe Vitali
| title = Sui gruppi di punti e sulle funzioni di variabili reali (On groups of points and functions of real variables)
| journal = [[Atti dell'Accademia delle Scienze di Torino]]
| origyear = 17 dicembre 1907
| year = 1908
| volume = 43
| language = Italian
| pages = 75–92
| url = https://archive.org/details/attidellarealeac43real
| archiveurl = https://archive.org/stream/attidellarealeac43real#page/228/mode/2up
| archivedate = 2009-03-31
| jfm= 39.0101.05
}}. The paper containing the first proof of [[Vitali covering theorem]].

==References==
*{{Citation
| last = Adams
| first = C. Raymond
| last2 = Clarkson
| first2 = James A.
| title = On definitions of bounded variation for functions of two variables
| journal = [[Transactions of the American Mathematical Society]]
| volume = 35
| pages = 824–854
| year = 1933
| url = http://www.ams.org/journals/tran/1933-035-04/S0002-9947-1933-1501718-2/home.html
| doi = 10.1090/S0002-9947-1933-1501718-2
| jfm = 59.0285.01
| mr = 1501718 
| zbl = 0008.00602
}}.
*{{Citation
| last = Cesari
| first = Lamberto
| author-link = Lamberto Cesari
| title = Sulle funzioni a variazione limitata (On the functions of bounded variation)
| journal = [[Annali della Scuola Normale Superiore]]
| series = II
| volume = 5
| issue = 3-4
| language = Italian
| pages = 299&amp;ndash;313
| date =
| year = 1936
| url = http://www.numdam.org/item?id=ASNSP_1936_2_5_3-4_299_0
| doi =
| jfm = 62.0247.03 
| mr = 1556778
| zbl = 0014.29605
}}. Available at [http://www.numdam.org Numdam].

*{{Citation
 | last =Leoni
 | first =Giovanni
 | author-link =
 | title = A First Course in Sobolev Spaces: Second Edition
 | place =
 | publisher =American Mathematical Society
 | series = Graduate Studies in Mathematics
 | year =2017
 | pages =xxii+734
 | isbn = 978-1-4704-2921-8
 | mr =
 | zbl =
}}.
*{{Citation
| last = Saks
| first = Stanisław
| author-link = Stanisław Saks
| title = Theory of the Integral
| place = Warszawa–Lwów
| publisher = G.E. Stechert &amp; Co.
| year = 1937
| series = [http://matwbn.icm.edu.pl/ksspis.php?wyd=10&amp;jez=pl Monografie Matematyczne]
| volume = 7
| edition = 2nd
| pages = VI+347
| url = http://matwbn.icm.edu.pl/kstresc.php?tom=7&amp;wyd=10&amp;jez=pl
| jfm = 63.0183.05 
| mr = 1556778
| zbl = 0017.30004
}}. (available at the [http://matwbn.icm.edu.pl/ Polish Virtual Library of Science]). English translation from the original French by [[Laurence Chisholm Young]], with two additional notes by [[Stefan Banach]].
*{{Citation
| last = Rudin
| first = Walter
| author-link = Walter Rudin
| title = Real and Complex Analysis
| place = New York
| publisher = McGraw-Hill
| series = McGraw-Hill Series in Higher Mathematics
| year = 1966
| edition = 1st
| pages = xi+412
| mr = 210528
| zbl = 0142.01701
| isbn = 
}}.

== External links ==
&lt;!-- Most of these are not External links in the sense of [[WP:EL]] --&gt;

'''One variable'''
* "[http://planetmath.org/encyclopedia/TotalVariation.html Total variation]" on [[PlanetMath]].

'''One and more variables'''
*[http://www.encyclopediaofmath.org/index.php/Function_of_bounded_variation Function of bounded variation] at [http://www.encyclopediaofmath.org/ Encyclopedia of Mathematics]

'''Measure theory'''
*{{MathWorld
|author=Rowland, Todd
|title=Total Variation
|urlname=TotalVariation
}}.
*{{PlanetMath|urlname=JordanDecomposition|title=Jordan decomposition}}.
*[http://www.encyclopediaofmath.org/index.php/Jordan_decomposition_%28of_a_signed_measure%29 Jordan decomposition] at [http://www.encyclopediaofmath.org/ Encyclopedia of Mathematics]

=== Applications ===
*{{Citation
 |last        = Caselles
 |first       = Vicent
 |last2       = Chambolle
 |first2      = Antonin
 |last3       = Novaga
 |first3      = Matteo
 |title       = The discontinuity set of solutions of the TV denoising problem and some extensions
 |url         = http://cvgmt.sns.it/papers/caschanov07/
 |publisher   = [[Society for Industrial and Applied Mathematics|SIAM]], Multiscale Modeling and Simulation, vol. 6 n. 3,
 |year        = 2007
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20110927172158/http://cvgmt.sns.it/papers/caschanov07/
 |archivedate = 2011-09-27
 |df          = 
}} (a work dealing with total variation application in denoising problems for [[image processing]]).

*{{Citation
 | last = Rudin | first = Leonid I. | last2 = Osher | first2 = Stanley
 | last3 = Fatemi | first3 = Emad 
 | title = Nonlinear total variation based noise removal algorithms
 | url = http://www.sciencedirect.com/science/article/pii/016727899290242F
 | publisher = Physica D: Nonlinear Phenomena 60.1: 259-268
 | year = 1992}}.

*{{Citation
 | last = Blomgren | first = Peter | last2 = Chan | first2 = Tony F. 
 | title = Color TV: total variation methods for restoration of vector-valued images
 | url = http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=661180&amp;tag=1
 | publisher = Image Processing, IEEE Transactions on, vol. 7, no. 3: 304-309
 | year = 1998}}.

*[[Tony F. Chan]] and Jackie (Jianhong) Shen (2005), [https://web.archive.org/web/20080117220948/http://jackieneoshen.googlepages.com/ImagingNewEra.html ''Image Processing and Analysis - Variational, PDE, Wavelet, and Stochastic Methods''], [[Society for Industrial and Applied Mathematics|SIAM]], {{isbn|0-89871-589-X}} (with in-depth coverage and extensive applications of Total Variations in modern image processing, as started by Rudin, Osher, and Fatemi).

{{DEFAULTSORT:Total Variation}}
[[Category:Mathematical analysis]]</text>
      <sha1>4ummq96vw6i3toxb3vqacufgzuw6o7h</sha1>
    </revision>
  </page>
  <page>
    <title>Wiener index</title>
    <ns>0</ns>
    <id>14223173</id>
    <revision>
      <id>868963324</id>
      <parentid>814766308</parentid>
      <timestamp>2018-11-15T14:59:31Z</timestamp>
      <contributor>
        <username>Parcly Taxel</username>
        <id>13854216</id>
      </contributor>
      <comment>/* Inverse problem */ the values</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14972">In [[chemical graph theory]], the '''Wiener index''' (also '''Wiener number''') introduced by [[Harry Wiener]], is a [[topological index]] of a [[molecule]], defined as the sum of the lengths of the [[shortest path]]s between all pairs of vertices in the [[chemical graph]] representing the non-[[hydrogen]] atoms in the molecule.&lt;ref name="r02"&gt;{{citation
 | last = Rouvray | first = Dennis H.
 | editor1-last = Rouvray | editor1-first = Dennis H.
 | editor2-last = King | editor2-first = Robert Bruce
 | contribution = The rich legacy of half a century of the Wiener index
 | pages = 16–37
 | publisher = Horwood Publishing
 | title = Topology in Chemistry: Discrete Mathematics of Molecules
 | url = https://books.google.com/books?id=a-ZkUeVLdO8C&amp;pg=PA16
 | year = 2002}}.&lt;/ref&gt;

==History==
The Wiener index is named after [[Harry Wiener]], who introduced it in 1947; at the time, Wiener called it the "path number".&lt;ref name="w47"&gt;{{citation
 | last = Wiener | first = H.
 | doi = 10.1021/ja01193a005
 | issue = 69
 | journal = Journal of the American Chemical Society
 | pages = 17–20
 | title = Structural determination of paraffin boiling points
 | volume = 1
 | year = 1947}}.&lt;/ref&gt; It is the oldest topological index related to molecular branching.&lt;ref&gt;{{citation
 | last1 = Todeschini | first1 = Roberto
 | last2 = Consonni | first2 = Viviana
 | isbn = 3-527-29913-0
 | publisher = Wiley
 | title = Handbook of Molecular Descriptors
 | year = 2000}}.&lt;/ref&gt; Based on its success, many other topological indexes of chemical graphs, based on information in the distance matrix of the graph, have been developed subsequently to Wiener's work.&lt;ref&gt;{{harvtxt|Rouvray|2002}}. See in particular Table 2 on p.&amp;nbsp;32.&lt;/ref&gt;
 
The same quantity has also been studied in pure mathematics, under various names including the gross status,&lt;ref&gt;{{citation
 | last = Harary | first = Frank | authorlink = Frank Harary
 | journal = Sociometry
 | mr = 0134798
 | pages = 23–43
 | title = Status and contrastatus
 | volume = 22
 | year = 1959
 | doi=10.2307/2785610}}&lt;/ref&gt; the distance of a graph,&lt;ref name="ejs76"&gt;{{citation
 | last1 = Entringer | first1 = R. C.
 | last2 = Jackson | first2 = D. E.
 | last3 = Snyder | first3 = D. A.
 | journal = Czechoslovak Mathematical Journal
 | mr = 0543771
 | pages = 283–296
 | title = Distance in graphs
 | volume = 26 | issue = 101
 | year = 1976}}.&lt;/ref&gt; and the transmission.&lt;ref&gt;{{citation
 | last = Šoltés | first = Ľubomír
 | issue = 1
 | journal = Mathematica Slovaca
 | mr = 1094978
 | pages = 11–16
 | title = Transmission in graphs: a bound and vertex removing
 | volume = 41
 | year = 1991}}.&lt;/ref&gt; The Wiener index is also closely related to the [[centrality|closeness centrality]] of a vertex in a graph, a quantity inversely proportional to the sum of all distances between the given vertex and all other vertices that has been frequently used in [[sociometry]] and the theory of [[social network]]s.&lt;ref name="ejs76"/&gt;

==Example==
[[Butane]] (C&lt;sub&gt;4&lt;/sub&gt;H&lt;sub&gt;10&lt;/sub&gt;) has two different [[structural isomers]]: ''n''-butane, with a linear structure of four carbon atoms, and [[isobutane]], with a branched structure. The chemical graph for ''n''-butane is a four-vertex [[path graph]], and the chemical graph for isobutane is a tree with one central vertex connected to three leaves.
&lt;gallery caption="The two isomers of butane" perrow=2&gt;
Image:Butane simple.svg|n-Butane
Image:Isobutane4.png|Isobutane
&lt;/gallery&gt;
The ''n''-butane molecule has three pairs of vertices at distance one from each other, two pairs at distance two, and one pair at distance three, so its Wiener index is
:&lt;math&gt;3\times 1 + 2\times 2 + 1\times 3 = 10.&lt;/math&gt;
The isobutane molecule has three pairs of vertices at distances one from each other (the three leaf-center pairs), and three pairs at distance two (the leaf-leaf pairs). Therefore, its Wiener index is
:&lt;math&gt;3\times 1 + 3\times 2 = 9.&lt;/math&gt;
These numbers are instances of formulas for special cases of the Wiener index: it is &lt;math&gt;(n^3-n)/6&lt;/math&gt; for any &lt;math&gt;n&lt;/math&gt;-vertex path graph such as the graph of ''n''-butane,&lt;ref&gt;As {{harvtxt|Rouvray|2002}} describes, this formula was already given by {{harvtxt|Wiener|1947}}.&lt;/ref&gt; and &lt;math&gt;(n-1)^2&lt;/math&gt; for any &lt;math&gt;n&lt;/math&gt;-vertex [[Star (graph theory)|star]] such as the graph of isobutane.&lt;ref&gt;{{citation
 | last1 = Bonchev | first1 = D.
 | last2 = Trinajstić | first2 = N.
 | doi = 10.1063/1.434593
 | issue = 10
 | journal = Journal of Chemical Physics
 | pages = 4517–4533
 | title = Information theory, distance matrix, and molecular branching
 | volume = 67
 | year = 1977| bibcode = 1977JChPh..67.4517B}}.&lt;/ref&gt;

Thus, even though these two molecules have the same chemical formula, and the same numbers of carbon-carbon and carbon-hydrogen bonds, their different structures give rise to different Wiener indices.

==Relation to chemical properties==
Wiener showed that the Wiener index number is closely correlated with the [[boiling point]]s of [[alkane]] molecules.&lt;ref name="w47"/&gt; Later work on [[quantitative structure–activity relationship]]s showed that it is also correlated with other quantities including the parameters of its [[Critical point (thermodynamics)|critical point]],&lt;ref&gt;{{citation
 | last1 = Stiel | first1 = Leonard I.
 | last2 = Thodos | first2 = George
 | doi = 10.1002/aic.690080421
 | issue = 4
 | journal = AIChE Journal
 | pages = 527–529
 | title = The normal boiling points and critical constants of saturated aliphatic hydrocarbons
 | volume = 8
 | year = 1962}}.&lt;/ref&gt; the [[density]], [[surface tension]], and [[viscosity]] of its liquid phase,&lt;ref&gt;{{citation
 | last1 = Rouvray | first1 = D. H.
 | last2 = Crafford | first2 = B. C.
 | journal = South African Journal of Science
 | page = 47
 | title = The dependence of physical-chemical properties on topological factors
 | volume = 72
 | year = 1976}}.&lt;/ref&gt; and the [[van der Waals surface area]] of the molecule.&lt;ref&gt;{{citation
 | last1 = Gutman | first1 = Ivan
 | last2 = Körtvélyesi | first2 = T.
 | journal = Zeitschrift für Naturforschung
 | pages = 669–671
 | title = Wiener indices and molecular surfaces
 | volume = 50a
 | year = 1995}}.&lt;/ref&gt;

==Calculation in arbitrary graphs==
The Wiener index may be calculated directly using an algorithm for computing all pairwise distances in the graph. When the graph is unweighted (so the length of a path is just its number of edges), these distances may be calculated by repeating a [[breadth-first search]] algorithm, once for each starting vertex.&lt;ref name="mp88"/&gt; The total time for this approach is O(''nm''), where ''n'' is the number of vertices in the graph and ''m'' is its number of edges.

For weighted graphs, one may instead use the [[Floyd–Warshall algorithm]]&lt;ref name="mp88"/&gt;&lt;ref&gt;{{citation
 | last = Floyd | first = Robert W. | author-link = Robert W. Floyd
 | date = June 1962
 | doi = 10.1145/367766.368168
 | issue = 6
 | journal = [[Communications of the ACM]]
 | page = 345
 | title = Algorithm 97: Shortest Path
 | volume = 5}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Warshall | first = Stephen
 | date = January 1962
 | doi = 10.1145/321105.321107
 | issue = 1
 | journal = [[Journal of the ACM]]
 | pages = 11–12
 | title = A theorem on Boolean matrices
 | volume = 9}}.&lt;/ref&gt; or [[Johnson's algorithm]],&lt;ref&gt;{{citation
 | last = Johnson | first = Donald B. | author-link = Donald B. Johnson
 | doi = 10.1145/321992.321993
 | issue = 1
 | journal = [[Journal of the ACM]]
 | pages = 1–13
 | title = Efficient algorithms for shortest paths in sparse networks
 | volume = 24
 | year = 1977}}.&lt;/ref&gt; with running time O(''n''&lt;sup&gt;3&lt;/sup&gt;) or O(''nm''&amp;nbsp;+&amp;nbsp;''n''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;log&amp;nbsp;''n'') respectively. Alternative but less efficient algorithms based on repeated [[matrix multiplication]] have also been developed within the chemical informatics literature.&lt;ref&gt;{{citation
 | last = Bersohn | first = Malcom
 | doi = 10.1002/jcc.540040115
 | issue = 1
 | journal = Journal of Computational Chemistry
 | pages = 110–113
 | title = A fast algorithm for calculation of the distance matrix of a molecule
 | volume = 4
 | year = 1983}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last1 = Müller | first1 = W. R.
 | last2 = Szymanski | first2 = K.
 | last3 = Knop | first3 = J. V.
 | last4 = Trinajstić | first4 = N.
 | doi = 10.1002/jcc.540080209
 | issue = 2
 | journal = Journal of Computational Chemistry
 | pages = 170–173
 | title = An algorithm for construction of the molecular distance matrix
 | volume = 8
 | year = 1987}}.&lt;/ref&gt;

==Calculation in special types of graph==
When the underlying graph is a [[tree (graph theory)|tree]] (as is true for instance for the alkanes originally studied by Wiener), the Wiener index may be calculated more efficiently. If the graph is partitioned into two subtrees by removing a single edge ''e'', then its Wiener index is the sum of the Wiener indices of the two subtrees, together with a third term representing the paths that pass through ''e''. This third term may be calculated in linear time by computing the sum of distances of all vertices from ''e'' within each subtree and multiplying the two sums.&lt;ref&gt;{{citation
 | last1 = Canfield | first1 = E. R.
 | last2 = Robinson | first2 = R. W.
 | last3 = Rouvray | first3 = D. H.
 | doi = 10.1002/jcc.540060613
 | issue = 6
 | journal = Journal of Computational Chemistry
 | mr = 824918
 | pages = 598–609
 | title = Determination of the Wiener molecular branching index for the general tree
 | volume = 6
 | year = 1985}}.&lt;/ref&gt; This [[divide and conquer algorithm]] can be generalized from trees to graphs of bounded [[treewidth]], and leads to near-linear-time algorithms for such graphs.&lt;ref&gt;{{citation
 | last1 = Cabello | first1 = Sergio
 | last2 = Knauer | first2 = Christian
 | doi = 10.1016/j.comgeo.2009.02.001
 | issue = 9
 | journal = Computational Geometry
 | mr = 2543804
 | pages = 815–824
 | title = Algorithms for graphs of bounded treewidth via orthogonal range searching
 | volume = 42
 | year = 2009}}.&lt;/ref&gt;
 
An alternative method for calculating the Wiener index of a tree, by [[Bojan Mohar]] and [[Tomaž Pisanski]], works by generalizing the problem to graphs with weighted vertices, where the weight of a path is the product of its length with the weights of its two endpoints. If ''v'' is a leaf vertex of the tree then the Wiener index of the tree may be calculated by merging ''v'' with its parent (adding their weights together), computing the index of the resulting smaller tree, and adding a simple correction term for the paths that pass through the edge from ''v'' to its parent. By repeatedly removing leaves in this way, the Wiener index may be calculated in linear time.&lt;ref name="mp88"&gt;{{citation
 | last1 = Mohar | first1 = Bojan | author1-link = Bojan Mohar
 | last2 = Pisanski | first2 = Tomaž | author2-link = Tomaž Pisanski
 | doi = 10.1007/BF01167206
 | issue = 3
 | journal = Journal of Mathematical Chemistry
 | mr = 966088
 | pages = 267–277
 | title = How to compute the Wiener index of a graph
 | volume = 2
 | year = 1988}}.&lt;/ref&gt;

For graphs that are constructed as [[Graph product|products]] of simpler graphs, the Wiener index of the product graph can often be computed by a simple formula that combines the indices of its factors.&lt;ref&gt;{{citation
 | last1 = Yeh | first1 = Yeong Nan
 | last2 = Gutman | first2 = Ivan
 | doi = 10.1016/0012-365X(93)E0092-I
 | issue = 1-3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | mr = 1310892
 | pages = 359–365
 | title = On the sum of all distances in composite graphs
 | volume = 135
 | year = 1994}}.&lt;/ref&gt; [[Benzenoid]]s (graphs formed by gluing regular hexagons edge-to-edge) can be embedded [[Isometry|isometrically]] into the [[Cartesian product of graphs|Cartesian product]] of three trees, allowing their Wiener indices to be computed in linear time by using the product formula together with the linear time tree algorithm.&lt;ref&gt;{{citation
 | last1 = Chepoi | first1 = Victor
 | last2 = Klavžar | first2 = Sandi
 | issue = 4
 | journal = Journal of Chemical Information and Computer Sciences
 | pages = 752–755
 | title = The Wiener index and the Szeged index of benzenoid systems in linear time
 | volume = 37
 | year = 1997
 | doi=10.1021/ci9700079}}. For earlier algorithms for benzenoids based on their [[partial cube]] structure, see {{citation
 | last1 = Klavžar | first1 = Sandi
 | last2 = Gutman | first2 = Ivan
 | last3 = Mohar | first3 = Bojan | author3-link = Bojan Mohar
 | issue = 3
 | journal = Journal of Chemical Information and Computer Sciences
 | pages = 590–593
 | title = Labeling of benzenoid systems which reflects the vertex-distance relations
 | url = http://www.fmf.uni-lj.si/~klavzar/preprints/labeling-benzi.pdf
 | volume = 35
 | year = 1995 | doi=10.1021/ci00025a030}}.&lt;/ref&gt;

==Inverse problem==
{{harvtxt|Gutman|Yeh|1995}} considered the problem of determining which numbers can be represented as the Wiener index of a graph.&lt;ref&gt;{{citation
 | last1 = Gutman | first1 = Ivan
 | last2 = Yeh | first2 = Yeong-Nan
 | issue = 4
 | journal = Mathematica Slovaca
 | mr = 1387048
 | pages = 327–334
 | title = The sum of all distances in bipartite graphs
 | volume = 45
 | year = 1995}}.&lt;/ref&gt; They showed that all but two positive integers have such a representation; the two exceptions are the numbers 2 and 5, which are not the Wiener index of any graph. For graphs that must be bipartite, they found that again almost all integers can be represented, with a larger set of exceptions: none of the numbers in the set
:{2, 3, 5, 6, 7, 11, 12, 13, 15, 17, 19, 33, 37, 39}
can be represented as the Wiener index of a bipartite graph.

Gutman and Yeh conjectured, but were unable to prove, a similar description of the numbers that can be represented as Wiener indices of trees, with a set of 49 exceptional values:
:2, 3, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 19, 21, 22, 23, 24, 26, 27, 30, 33, 34, 37, 38, 39, 41, 43, 45, 47, 51, 53, 55, 60, 61, 69, 73, 77, 78, 83, 85, 87, 89, 91, 99, 101, 106, 113, 147, 159 {{OEIS|A122686}}
The conjecture was later proven by Wagner, Wang, and Yu.&lt;ref&gt;{{citation
 | last = Wagner | first = Stephan G.
 | doi = 10.1007/s10440-006-9026-5
 | issue = 2
 | journal = Acta Applicandae Mathematicae
 | mr = 2249544
 | pages = 119–132
 | title = A class of trees and its Wiener index
 | volume = 91
 | year = 2006}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last1 = Wang | first1 = Hua
 | last2 = Yu | first2 = Guang
 | doi = 10.1007/s10440-006-9037-2
 | issue = 1
 | journal = Acta Applicandae Mathematicae
 | mr = 2263469
 | pages = 15–20
 | title = All but 49 numbers are Wiener indices of trees
 | volume = 92
 | year = 2006}}.&lt;/ref&gt;

==References==
{{reflist|colwidth=30em}}

==External links==
* {{MathWorld|id=WienerIndex|title=Wiener Index}}

[[Category:Mathematical chemistry]]
[[Category:Cheminformatics]]
[[Category:Graph invariants]]</text>
      <sha1>pn3lw46mie1el72dejphvbhuijc17mt</sha1>
    </revision>
  </page>
  <page>
    <title>XS-3 code</title>
    <ns>0</ns>
    <id>49311074</id>
    <redirect title="Excess-3" />
    <revision>
      <id>703093990</id>
      <parentid>703090178</parentid>
      <timestamp>2016-02-03T13:13:11Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+cats</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="107">#redirect [[Excess-3]] {{R from abbreviation}}

[[Category:Binary arithmetic]]
[[Category:Numeral systems]]</text>
      <sha1>blen9b0t532wg3ut20uew4rca1k10dz</sha1>
    </revision>
  </page>
  <page>
    <title>Zonal polynomial</title>
    <ns>0</ns>
    <id>8910528</id>
    <revision>
      <id>721907533</id>
      <parentid>721907495</parentid>
      <timestamp>2016-05-24T19:50:55Z</timestamp>
      <contributor>
        <ip>65.29.219.180</ip>
      </contributor>
      <comment>Undid revision 695765481 by [[Special:Contributions/193.52.94.40|193.52.94.40]] ([[User talk:193.52.94.40|talk]]) rvv</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1004">In [[mathematics]], a '''zonal polynomial''' is a multivariate [[symmetric polynomial|symmetric]] [[homogeneous polynomial]]. The zonal polynomials form a [[basis (algebra)|basis]] of the space of symmetric polynomials.

They appear as [[zonal spherical function]]s of the [[Gelfand pair]]s
&lt;math&gt;(S_{2n},H_n)&lt;/math&gt; (here, &lt;math&gt;H_n&lt;/math&gt; is the hyperoctahedral group) and &lt;math&gt;(Gl_n(\mathbb{R}),
O_n)&lt;/math&gt;, which means that they describe canonical basis of the double class
algebras &lt;math&gt;\mathbb{C}[H_n \backslash S_{2n} / H_n]&lt;/math&gt; and  &lt;math&gt;\mathbb{C}[O_d(\mathbb{R})\backslash
M_d(\mathbb{R})/O_d(\mathbb{R})]&lt;/math&gt;.

They are applied in [[multivariate statistics]].

The zonal polynomials are the &lt;math&gt;\alpha=2&lt;/math&gt; case of the '''C''' normalization of the [[Jack function]].

==References==

* Robb Muirhead, ''Aspects of Multivariate Statistical Theory'', John Wiley &amp; Sons, Inc., New York, 1984.

{{algebra-stub}}
[[Category:Homogeneous polynomials]]
[[Category:Symmetric functions]]</text>
      <sha1>lbqm25xc5rkbal50nv4jwapc796w02g</sha1>
    </revision>
  </page>
</mediawiki>
