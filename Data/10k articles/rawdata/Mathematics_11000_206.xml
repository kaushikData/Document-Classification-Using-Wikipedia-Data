<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>224 (number)</title>
    <ns>0</ns>
    <id>4189047</id>
    <revision>
      <id>864511880</id>
      <parentid>864473013</parentid>
      <timestamp>2018-10-17T18:20:03Z</timestamp>
      <contributor>
        <username>Arthur Rubin</username>
        <id>374195</id>
      </contributor>
      <comment>Reverted [[WP:AGF|good faith]] edits by [[Special:Contributions/109.93.191.114|109.93.191.114]] ([[User talk:109.93.191.114|talk]]): Trivia. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="814">'''224''' ('''two hundred [and] twenty-four''') is the natural number following [[223 (number)|223]] and preceding [[225 (number)|225]].
{{Infobox number
| number = 224
| prime = No
}}

224 is a [[practical number]],&lt;ref&gt;{{Cite OEIS|A005153|name=Practical numbers}}&lt;/ref&gt;
and a sum of two positive cubes {{nowrap|2&lt;sup&gt;3&lt;/sup&gt; + 6&lt;sup&gt;3&lt;/sup&gt;}}.&lt;ref&gt;{{Cite OEIS|A003325|Numbers that are the sum of 2 positive cubes}}&lt;/ref&gt;

224 is the smallest ''k'' with λ(''k'') = 24, where λ(''k'') is the [[Carmichael function]].&lt;ref&gt;{{Cite OEIS|A141162|name=Smallest k such that lambda(k) = n}}&lt;/ref&gt;

==In other fields==
*The years [[224]] and [[224 BC]]
*[[Area codes 847 and 224|Area code 224]]
*[[.224 Weatherby Magnum]], firearm cartridge

==References==
{{Reflist}}

{{Integers|2}}

[[Category:Integers]]

{{Num-stub}}</text>
      <sha1>tftzpef36p2pmuc0luaic722kv709q2</sha1>
    </revision>
  </page>
  <page>
    <title>Acta Applicandae Mathematicae</title>
    <ns>0</ns>
    <id>30625447</id>
    <revision>
      <id>797622042</id>
      <parentid>643113856</parentid>
      <timestamp>2017-08-28T08:28:10Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[Wikipedia:Bots/Requests for approval/KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1474">{{Infobox journal
 | title        = Acta Applicandae Mathematicae
 | cover        = 
 | abbreviation = Acta Appl. Math.
 | discipline   = [[Applied mathematics]]
 | editor       = {{nowrap|1=[[Laurent Desvillettes]],}} {{nowrap|1=[[Emmanuel Trélat]]}}
 | publisher    = [[Springer Science+Business Media|Springer]]
 | frequency    = 3/year
 | history      = 1983–present
 | impact       = 0.899
 | impact-year  = 2011
 | link1-name   = Online access
 | link1        = http://www.springerlink.com/content/1572-9036/
 | url          = https://www.springer.com/mathematics/journal/10440
 | ISSN         = 0167-8019
 | eISSN        = 1572-9036 
 | CODEN        = AAMADV 
 | LCCN         = 83646887 
 | OCLC         = 09710183 
}}

''''' Acta Applicandae Mathematicae''''' is a [[peer review|peer-reviewed]] [[mathematics journal]] published by [[Springer Science+Business Media|Springer]].
Founded in 1983, the journal publishes articles on [[applied mathematics]].
The journal is indexed by ''[[Mathematical Reviews]]'' and [[Zentralblatt MATH]].
Its 2009 [[Mathematical Citation Quotient|MCQ]] was 0.34, and its 2009 [[impact factor]] was 0.523.

==External links==
*{{Official website|http://www.springerlink.com/content/1572-9036/}}

[[Category:Mathematics journals]]
[[Category:Publications established in 1983]]
[[Category:English-language journals]]
[[Category:Springer Science+Business Media academic journals]]
[[Category:Triannual journals]]


{{math-journal-stub}}</text>
      <sha1>1kwwqxegtw0xmmy8w2zjb7cv3padzik</sha1>
    </revision>
  </page>
  <page>
    <title>Alessio Figalli</title>
    <ns>0</ns>
    <id>38609892</id>
    <revision>
      <id>864897842</id>
      <parentid>863977278</parentid>
      <timestamp>2018-10-20T07:37:50Z</timestamp>
      <contributor>
        <username>Orenburg1</username>
        <id>10248457</id>
      </contributor>
      <minor/>
      <comment>sp</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8904">{{Use dmy dates|date=August 2018}}
{{Infobox scientist
| name = Alessio Figalli
| image = Alessio Figalli (cropped).jpg
| birth_date = {{Birth date and age|1984|4|2|df=y}}
| birth_place = [[Rome, Italy]]
| death_date = &lt;!-- {{Death date and age|df=yes|YYYY|MM|DD|YYYY|MM|DD}} (death date then birth date) --&gt;
| nationality = [[Italy|Italian]]
| fields = [[Mathematics]]
| workplaces = [[ETH Zurich]]&lt;br&gt;[[University of Texas at Austin]]
| alma_mater = [[Scuola Normale Superiore di Pisa]]&lt;br&gt;[[École Normale Supérieure de Lyon|École normale supérieure de Lyon]]
| doctoral_advisor = [[Luigi Ambrosio]]&lt;br&gt;[[Cédric Villani]]
| doctoral_students = 
| awards = Prix and [[Cours Peccot]] (2012)&lt;br&gt; [[EMS Prize]] (2012) &lt;br&gt; [[Stampacchia Medal]] (2015)  &lt;br&gt; [[Feltrinelli Prize]] (2017) &lt;br&gt; [[Fields Medal]] (2018)
| spouse = Mikaela Iacobelli
}}

'''Alessio Figalli''' ({{IPA-it|aˈlesːjo fiˈɡalːi|lang}}; born 2 April 1984) is an [[Italy|Italian]] [[mathematician]] working primarily on [[calculus of variations]] and [[partial differential equation]]s.

He was awarded the Prix and {{Ill|Cours Peccot|fr}} in 2012, the [[EMS Prize]] in 2012,&lt;ref&gt;{{cite web|title=6th European Congress of Mathematics|url=http://www.6ecm.pl/docs/6ecm-prizes.pdf|publisher=European mathematical Society|accessdate=13 March 2013}}&lt;/ref&gt; the [[Stampacchia Medal]] in 2015,&lt;ref&gt;{{cite web|url=http://umi.dm.unibo.it/wp-content/uploads/2015/03/motivazioni_figalli.pdf|title=2015 Stampacchia Medal winner citation|publisher=}}&lt;/ref&gt; the [[Feltrinelli Prize]] in 2017 and the [[Fields Medal]] in 2018. He was an [[list of International Congresses of Mathematicians Plenary and Invited Speakers|invited speaker at the International Congress of Mathematicians]] 2014.&lt;ref&gt;{{cite web|title=ICM 2014 |url=http://www.icm2014.org/en/program/scientific/topics |deadurl=yes |archiveurl=https://web.archive.org/web/20141106014030/http://www.icm2014.org/en/program/scientific/topics |archivedate=6 November 2014 }}&lt;/ref&gt;
In 2016 he was awarded a [[European Research Council]] (ERC) grant.

==Biography==
Figalli received his master's degree from the [[Scuola Normale Superiore di Pisa]] in 2006, and earned his doctorate in 2007 under the supervision of [[Luigi Ambrosio]] at the [[Scuola Normale Superiore di Pisa]] and [[Cédric Villani]] at the [[École Normale Supérieure de Lyon]]. In 2007 he was appointed Chargé de recherche at the [[French National Centre for Scientific Research]], in 2008 he went to the [[École polytechnique]] as Professeur Hadamard.

In 2009 he moved to the [[University of Texas at Austin]] as Associate Professor. Then he became Full Professor in 2011, and [[Robert Lee Moore|R. L. Moore]] Chair holder in 2013. Since 2016, he is a chaired professor at [[ETH Zurich|ETH Zürich]].

Amongst his several recognitions, Figalli has won an [[EMS Prize]] in 2012, he has been awarded the Peccot-Vimont Prize 2011 and Cours Peccot 2012 of the [[Collège de France]] and has been appointed Nachdiplom Lecturer in 2014 at [[ETH Zurich|ETH Zürich]].&lt;ref&gt;{{cite web|title=ETH Lectures in Mathematics|url=https://people.math.ethz.ch/~struwe/ND/nachdiplom.html}}&lt;/ref&gt; He has won the 2015 edition of the [[Stampacchia Medal]], and the 2017 edition of the [[Feltrinelli Prize]] for mathematics.

In 2018 he won the [[Fields Medal]] "for his contributions to the theory of optimal transport, and its application to partial differential equations, metric geometry, and probability".&lt;ref&gt;[https://www.quantamagazine.org/alessio-figalli-a-mathematician-on-the-move-wins-fields-medal-20180801 A Traveler Who Finds Stability in the Natural World, August 1, 2018]&lt;/ref&gt;

==Work==
Figalli has worked in the theory of [[Transportation theory (mathematics)|optimal transport]], with particular emphasis on the regularity theory of optimal transport maps and its connections to [[Monge–Ampère equation]]s. Amongst the results he obtained in this direction, there stand out an important higher integrability property of the second derivatives of solutions to the Monge–Ampère equation&lt;ref&gt;{{cite journal|title=&lt;math&gt;W^{2,1}&lt;/math&gt; regularity for solutions of the Monge–Ampère equation |authors= Guido De Philippis, Alessio Figalli  |doi=10.1007/s00222-012-0405-4 |journal=Inventiones Mathematicae|arxiv=1111.7207|bibcode=2013InMat.192...55D}}&lt;/ref&gt; and a partial regularity result for Monge–Ampère type equations,&lt;ref&gt;{{cite journal |title=Partial regularity for optimal transport maps |authors= Guido De Philippis, Alessio Figalli |doi=10.1007/s10240-014-0064-7 |journal=Publications mathématiques de l'IHÉS |arxiv=1209.5640 }}&lt;/ref&gt; both proved together with [[Guido de Philippis]]. He used optimal transport techniques to get improved versions of the anisotropic [[isoperimetric inequality]], and obtained several other important results on the stability of functional and geometric inequalities. In particular, together with Francesco Maggi and Aldo Pratelli, he proved a sharp quantitative version of the anisotropic [[isoperimetric inequality]].&lt;ref&gt;{{cite journal|title=A mass transportation approach to quantitative isoperimetric inequalities |authors=Figalli, A.; Maggi, F.; Pratelli, A. |doi=10.1007/s00222-010-0261-z |journal=Inventiones Mathematicae |bibcode=2010InMat.182..167F }}&lt;/ref&gt; 

Then, in a joint work with Eric Carlen, he addressed the stability analysis of some [[Gagliardo–Nirenberg interpolation inequality|Gagliardo–Nirenberg]] and logarithmic [[Sobolev inequality|Hardy–Littlewood–Sobolev inequalities]] to obtain a quantitative rate of convergence for the critical mass Keller–Segel equation.&lt;ref&gt;{{cite journal |title=Stability for a GNS inequality and the Log-HLS inequality, with application to the critical mass Keller–Segel equation |authors= Eric A. Carlen, Alessio Figalli |doi=10.1215/00127094-2019931 |journal=Duke Mathematical Journal |arxiv=1107.5976 }}&lt;/ref&gt; He also worked on [[Hamilton–Jacobi equation]]s and their connections to weak [[Kolmogorov–Arnold–Moser theorem|Kolmogorov–Arnold–Moser theory]]. In a paper with Gonzalo Contreras and Ludovic Rifford, he proved generic hyperbolicity of Aubry sets on compact surfaces.&lt;ref&gt;{{cite journal |title=Generic hyperbolicity of Aubry sets on surfaces |authors= Contreras, G.; Figalli, A.; Rifford, L.|doi=10.1007/s00222-014-0533-0 |journal=Inventiones Mathematicae|bibcode=2015InMat.200..201C}}&lt;/ref&gt; 

In addition, he has given several contributions to the Di Perna–Lions' theory, applying it both to the understanding of [[Semiclassical physics|semiclassical]] limits of the [[Schrödinger equation]] with very rough potentials,&lt;ref&gt;{{cite journal |title=Semiclassical limit of quantum dynamics with rough potentials and well-posedness of transport equations with measure initial data |authors= Luigi Ambrosio, Alessio Figalli, Gero Friesecke et al. |doi=10.1002/cpa.20371 |journal=Communications on Pure and Applied Mathematics |volume=64 |issue=9 |year=2011 |pages=1199–1242 |arxiv=1006.5388 }}&lt;/ref&gt; and to study the Lagrangian structure of weak solutions to the [[Vlasov equation|Vlasov–Poisson equation]].&lt;ref&gt;{{cite journal |title=On the Lagrangian structure of transport equations: The Vlasov–Poisson system |authors= Luigi Ambrosio, Maria Colombo, and Alessio Figalli |doi=10.1215/00127094-2017-0032|journal=Duke Mathematical Journal |volume=166 |issue=18 |year=2017 |pages=3505–3568 }}&lt;/ref&gt; More recently, in collaboration with [[Alice Guionnet]], he introduced and developed new transportation techniques in the topic of [[random matrices]] to prove universality results in several-matrix models.&lt;ref&gt;{{cite journal |title=Universality in several-matrix models via approximate transport maps |authors= Alessio Figalli and Alice Guionnet |doi=10.1007/s11511-016-0142-4 |journal=Acta Mathematica |volume=217 |issue=1 |year=2016 |pages=81–176 }}&lt;/ref&gt; Also, together with Joaquim Serra, he has proved the [[Ennio de Giorgi|De Giorgi]]'s conjecture for boundary reaction terms in dimension ≤ 5, and he has improved the classical results by [[Luis Caffarelli]] on the structure of singular points in the [[obstacle problem]].

==References==
{{Reflist}}

==External links==
*[https://people.math.ethz.ch/~afigalli/ Website at ETH Zurich]
*{{MathGenealogy |id=126306 }}
*{{Google scholar id}}
*{{Scopus id}}

{{Fields medalists}}

{{Authority control}}

{{DEFAULTSORT:Figalli, Alessio}}
[[Category:1984 births]]
[[Category:Fields Medalists]]
[[Category:Living people]]
[[Category:Italian mathematicians]]
[[Category:21st-century Italian mathematicians]]
[[Category:Mathematical analysts]]
[[Category:ETH Zurich faculty]]
[[Category:Variational analysts]]
[[Category:European Research Council grantees]]
[[Category:People from Rome]]
[[Category:University of Pisa alumni]]
[[Category:Scuola Normale Superiore di Pisa alumni]]
[[Category:École Normale Supérieure alumni]]</text>
      <sha1>q1cyfg3oag2nis4pt2w28v4vraeb0na</sha1>
    </revision>
  </page>
  <page>
    <title>Arrangement of lines</title>
    <ns>0</ns>
    <id>864149</id>
    <revision>
      <id>868255385</id>
      <parentid>868244657</parentid>
      <timestamp>2018-11-11T01:25:05Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>/* References */ more links</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="42508">[[File:Complete-quads.svg|thumb|upright=1.35|A simplicial line arrangement (left) and a simple line arrangement (right).]]
In [[geometry]] an '''arrangement of lines''' is the [[Partition of a set|partition]] of the [[Plane (geometry)|plane]] formed by a collection of [[Line (geometry)|lines]]. Bounds on the complexity of arrangements have been studied in [[discrete geometry]], and [[computational geometry|computational geometers]] have found algorithms for the efficient construction of arrangements.

==Definition==
For any set ''A'' of lines in the [[Euclidean plane]], one can define an [[equivalence relation]] on the points of the plane according to which two points ''p'' and ''q'' are equivalent if, for every line ''l'' of ''A'', either ''p'' and ''q'' are both on ''l'' or both belong to the same open [[half-plane]] bounded by ''l''. When ''A'' is finite or locally finite&lt;ref&gt;For an arrangement to be locally finite, every bounded subset of the plane may be crossed by only finitely many lines.&lt;/ref&gt; the [[equivalence class]]es of this relation are of three types:
#the interiors of bounded or unbounded convex polygons (the ''cells'' of the arrangement), the [[Connected component (topology)|connected components]] of the subset of the plane not contained in any of the lines of ''A'',
#open line segments and open infinite rays (the ''edges'' of the arrangement), the connected components of the points of a single line that do not belong to any other lines of ''A'', and
#single points (the ''[[vertex (geometry)|vertices]]'' of the arrangement), the intersections of two or more lines of ''A''.
These three types of objects link together to form a [[cell complex]] covering the plane. Two arrangements are said to be ''isomorphic'' or ''combinatorially equivalent'' if there is a one-to-one adjacency-preserving correspondence between the objects in their associated cell complexes.&lt;ref&gt;{{harvtxt|Grünbaum|1972}}, page 4.&lt;/ref&gt;

==Complexity of arrangements==
The study of arrangements was begun by [[Jakob Steiner]], who proved the first bounds on the maximum number of features of different types that an arrangement may have.&lt;ref&gt;{{harvtxt|Steiner|1826}}; {{harvtxt|Agarwal|Sharir|2000}}.&lt;/ref&gt;
An arrangement with ''n'' lines has at most [[triangular number|''n''(''n''&amp;nbsp;&amp;minus;&amp;nbsp;1)/2]] vertices, one per pair of crossing lines. This maximum is achieved for ''simple arrangements'', those in which each two lines has a distinct pair of crossing points. In any arrangement there will be ''n'' infinite-downward rays, one per line; these rays separate ''n''&amp;nbsp;+&amp;nbsp;1 cells of the arrangement that are unbounded in the downward direction. The remaining cells all have a unique bottommost vertex,&lt;ref&gt;For cells in which there is a horizontal bottom edge, choose the bottommost vertex to be the right endpoint of the bottom edge.&lt;/ref&gt; and each vertex is bottommost for a unique cell, so the number of cells in an arrangement is the number of vertices plus ''n''&amp;nbsp;+&amp;nbsp;1, or at most ''n''(''n''&amp;nbsp;+&amp;nbsp;1)/2&amp;nbsp;+&amp;nbsp;1; see [[lazy caterer's sequence]]. The number of edges of the arrangement is at most ''n''&lt;sup&gt;2&lt;/sup&gt;, as may be seen either by using the [[Euler characteristic]] to calculate it from the numbers of vertices and cells, or by observing that each line is partitioned into at most ''n'' edges by the other ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 lines; again, this worst-case bound is achieved for simple arrangements.

{{anchor|Zone theorem}}
The ''zone'' of a line ''l'' in a line arrangement is the collection of cells having edges belonging to ''l''. The [[zone theorem]] states that the total number of edges in the cells of a single zone is linear. More precisely, the total number of edges of the cells belonging to a single side of line ''l'' is at most 5''n''&amp;nbsp;&amp;minus;&amp;nbsp;1,&lt;ref name="zone"&gt;{{harvtxt|Chazelle|Guibas|Lee|1985}}, {{harvtxt|Edelsbrunner|1987}}, {{harvtxt|Edelsbrunner|O'Rourke|Seidel|1986}}.&lt;/ref&gt; and the total number of edges of the cells belonging to both sides of ''l'' is at most &lt;math&gt;\lfloor 9.5n\rfloor-1&lt;/math&gt;.&lt;ref name="bepy"&gt;{{harvtxt|Bern|Eppstein|Plassman|Yao|1991}}.&lt;/ref&gt; More generally, the total complexity of the cells of a line arrangement that are intersected by any convex curve is O(''n''&amp;nbsp;α(''n'')), where α denotes the [[Ackermann function|inverse Ackermann function]], as may be shown using [[Davenport–Schinzel sequence]]s.&lt;ref name="bepy"/&gt; Summing the complexities of all zones, one finds that the sum of squares of cell complexities in an arrangement is O(''n''&lt;sup&gt;2&lt;/sup&gt;).&lt;ref&gt;{{harvtxt|Aronov|Matoušek|Sharir|1994}}.&lt;/ref&gt;

The [[K-set (geometry)|''k-level'']] of an arrangement is the polygonal chain formed by the edges that have exactly ''k'' other lines directly below them, and the ''≤k-level'' is the portion of the arrangement below the ''k''-level. Finding matching upper and lower bounds for the complexity of a ''k''-level remains a major open problem in discrete geometry; the best upper bound is O(''nk''&lt;sup&gt;1/3&lt;/sup&gt;), while the best lower bound  is Ω(''n'' exp(''c'' (log''k'')&lt;sup&gt;1/2&lt;/sup&gt;)).&lt;ref&gt;{{harvtxt|Dey|1998}}; {{harvtxt|Tóth|2001}}. The problem of bounding the complexity of ''k''-levels was first studied by {{harvtxt|Lovász|1971}} and {{harvtxt|Erdős|Lovász|Simmons|Straus|1973}}.&lt;/ref&gt; In contrast, the maximum complexity of the ≤''k''-level is known to be Θ(''nk'').&lt;ref&gt;{{harvtxt|Alon|Győri|1986}}.&lt;/ref&gt; A ''k''-level is a special case of a monotone path in an arrangement; that is, a sequence of edges that intersects any vertical line in a single point. However, monotone paths may be much more complicated than ''k''-levels: there exist arrangements and monotone paths in these arrangements where the number of points at which the path changes direction is Ω(''n''&lt;sup&gt;2&amp;nbsp;&amp;minus;&amp;nbsp;o(1)&lt;/sup&gt;).&lt;ref&gt;{{harvtxt|Balogh|Regev|Smyth|Steiger|2004}}; see also {{harvtxt|Matoušek|1991}}.&lt;/ref&gt;

Although a single cell in an arrangement may be bounded by all ''n'' lines, it is not possible in general for ''m'' different cells to all be bounded by ''n'' lines. Rather, the total complexity of ''m'' cells is at most Θ(''m''&lt;sup&gt;2/3&lt;/sup&gt;''n''&lt;sup&gt;2/3&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''n''),&lt;ref&gt;{{harvtxt|Canham|1969}}; {{harvtxt|Clarkson|Edelsbrunner|Guibas|Sharir|1990}}.&lt;/ref&gt; almost the same bound as occurs in the [[Szemerédi–Trotter theorem]] on point-line incidences in the plane. A simple proof of this follows from the [[Crossing number (graph theory)|crossing number inequality]]:&lt;ref&gt;{{harvtxt|Ajtai|Chvátal|Newborn|Szemerédi|1982}}; {{harvtxt|Leighton|1983}}.&lt;/ref&gt; if ''m'' cells have a total of ''x''&amp;nbsp;+&amp;nbsp;''n'' edges, one can form a graph with ''m'' nodes (one per cell) and ''x'' edges (one per pair of consecutive cells on the same line). The edges of this graph can be drawn as curves that do not cross within the cells corresponding to their endpoints, and then follow the lines of the arrangement; therefore, there are O(''n''&lt;sup&gt;2&lt;/sup&gt;) crossings in this drawing. However, by the crossing number inequality, there are Ω(''x''&lt;sup&gt;3&lt;/sup&gt;/''m''&lt;sup&gt;2&lt;/sup&gt;) crossings; in order to satisfy both bounds, ''x'' must be O(''m''&lt;sup&gt;2/3&lt;/sup&gt;''n''&lt;sup&gt;2/3&lt;/sup&gt;).&lt;ref&gt;{{harvtxt|Székely|1997}}.&lt;/ref&gt;

==Projective arrangements and projective duality==
It is often convenient to study line arrangements not in the Euclidean plane but in the [[projective plane]], due to the fact that in projective geometry every pair of lines has a crossing point. In the projective plane, we may no longer define arrangements using sides of lines (a line in the projective plane does not separate the plane into two distinct sides), but we may still define the cells of an arrangement to be the connected components of the points not belonging to any line, the edges to be the connected components of sets of points belonging to a single line, and the vertices to be points where two or more lines cross. A line arrangement in the projective plane differs from its Euclidean counterpart in that the two Euclidean rays at either end of a line are replaced by a single edge in the projective plane that connects the leftmost and rightmost vertices on that line, and in that pairs of unbounded Euclidean cells are replaced in the projective plane by single cells that are crossed by the projective line at infinity.

Due to [[projective duality]], many statements about the combinatorial properties of points in the plane may be more easily understood in an equivalent dual form about arrangements of lines. For instance, the [[Sylvester–Gallai theorem]], stating that any non-collinear set of points in the plane has an ''ordinary line'' containing exactly two points, transforms under projective duality to the statement that any arrangement of lines with more than one vertex has an ''ordinary point'', a vertex where only two lines cross. The earliest known proof of the Sylvester–Gallai theorem, by {{harvtxt|Melchior|1940}}, uses the [[Euler characteristic]] to show that such a vertex must always exist.

==Triangles in arrangements==
[[File:17KobonDreiecke.svg|thumb|upright=1.35|[[Kobon triangle problem|Kobon triangles]] in an arrangement of 17 lines]]
An arrangement of lines in the projective plane is said to be ''simplicial'' if every cell of the arrangement is bounded by exactly three edges; simplicial arrangements were first studied by Melchior.&lt;ref&gt;{{harvtxt|Melchior|1940}}; {{harvtxt|Grünbaum|2005}}.&lt;/ref&gt; Three infinite families of simplicial line arrangements are known:
#A ''near-pencil'' consisting of ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 lines through a single point, together with a single additional line that does not go through the same point,
#The family of lines formed by the sides of a [[regular polygon]] together with its [[axis of symmetry|axes of symmetry]], and
#The sides and axes of symmetry of an even regular polygon, together with the line at infinity.
Additionally there are many other examples of ''sporadic simplicial arrangements'' that do not fit into any known infinite family.&lt;ref&gt;{{harvtxt|Grünbaum|1972}}; {{harvtxt|Grünbaum|2005}}.&lt;/ref&gt;
As Grünbaum&lt;ref&gt;{{harvtxt|Grünbaum|2005}}&lt;/ref&gt; writes, simplicial arrangements “appear as examples or counterexamples in many contexts of combinatorial geometry and its applications.” For instance, {{harvtxt|Artés|Grünbaum|Llibre|1998}} use simplicial arrangements to construct counterexamples to a conjecture on the relation between the degree of a set of [[differential equation]]s and the number of invariant lines the equations may have. The two known counterexamples to the Dirac-Motzkin conjecture (which states that any ''n''-line arrangement has at least ''n''/2 ordinary points) are both simplicial.&lt;ref&gt;{{harvtxt|Crowe|McKee|1968}}; {{harvtxt|Dirac|1951}}; {{harvtxt|Kelly|Moser|1958}}; {{harvtxt|Grünbaum|1972}}, page 18.&lt;/ref&gt;

The [[dual graph]] of a line arrangement, in which there is one node per cell and one edge linking any pair of cells that share an edge of the arrangement, is a [[partial cube]], a graph in which the nodes can be labeled by [[bitvector]]s in such a way that the graph distance equals the [[Hamming distance]] between labels; in the case of a line arrangement, each coordinate of the labeling assigns 0 to nodes on one side of one of the lines and 1 to nodes on the other side.&lt;ref&gt;{{harvtxt|Eppstein|Falmagne|Ovchinnikov|2007}}.&lt;/ref&gt; Dual graphs of simplicial arrangements have been used to construct infinite families of [[cubic graph|3-regular]] partial cubes, isomorphic to the graphs of [[zonohedron|simple zonohedra]].&lt;ref&gt;{{harvtxt|Eppstein|2006}}.&lt;/ref&gt;

It is also of interest to study the extremal numbers of triangular cells in arrangements that may not necessarily be simplicial. In any arrangement, there must be at least ''n'' triangles; every arrangement that has only ''n'' triangles must be simple.&lt;ref&gt;{{harvtxt|Grünbaum|1972}}; {{harvtxt|Levi|1926}}; {{harvtxt|Roudneff|1988}}.&lt;/ref&gt; The maximum possible number of triangles in a simple arrangement is known to be upper bounded by ''n''(''n''&amp;nbsp;&amp;minus;&amp;nbsp;1)/3 and lower bounded by ''n''(''n''&amp;nbsp;&amp;minus;&amp;nbsp;3)/3; the lower bound is achieved by certain subsets of the diagonals of a regular 2''n''-gon.&lt;ref&gt;{{harvtxt|Füredi|Palásti|1984}}; {{harvtxt|Grünbaum|1972}}.&lt;/ref&gt; For non-simple arrangements the maximum number of triangles is similar but more tightly bounded.&lt;ref&gt;{{harvtxt|Purdy|1979}}; {{harvtxt|Purdy|1980}}; {{harvtxt|Strommer|1977}}.&lt;/ref&gt; The closely related [[Kobon triangle problem]] asks for the maximum number of non-overlapping finite triangles (not necessarily faces) in an arrangement in the Euclidean plane; for some but not all values of ''n'', ''n''(''n''&amp;nbsp;&amp;minus;&amp;nbsp;2)/3 triangles are possible.

==Multigrids and Penrose tilings==
[[File:Tiling Dual Semiregular V4-6-12 Bisected Hexagonal.svg|thumb|The [[bisected hexagonal tiling]].]]
The dual graph of a simple line arrangement may be represented geometrically as a collection of [[rhombus|rhombi]], one per vertex of the arrangement, with sides perpendicular to the lines that meet at that vertex. These rhombi may be joined together to form a tiling of a [[convex polygon]] in the case of an arrangement of finitely many lines, or of the entire plane in the case of a locally finite arrangement with infinitely many lines. {{harvtxt|de Bruijn|1981}} investigated special cases of this construction in which the line arrangement consists of ''k'' sets of equally spaced parallel lines. For two perpendicular families of parallel lines this construction just gives the familiar [[square tiling]] of the plane, and for three families of lines at 120-degree angles from each other (themselves forming a [[trihexagonal tiling]]) this produces the [[rhombille tiling]]. However, for more families of lines this construction produces [[aperiodic tiling]]s. In particular, for five families of lines at equal angles to each other (or, as de Bruijn calls this arrangement, a ''pentagrid'') it produces a family of tilings that include the rhombic version of the [[Penrose tiling]]s.

The [[tetrakis square tiling]] is an infinite arrangement of lines forming a periodic tiling that resembles a multigrid with four parallel families, but in which two of the families are more widely spaced than the other two, and in which the arrangement is simplicial rather than simple. Its dual is the [[truncated square tiling]]. Similarly, the [[triangular tiling]] is an infinite simplicial line arrangement with three parallel families, which has as its dual the [[hexagonal tiling]], and the [[bisected hexagonal tiling]] is an infinite simplicial line arrangement with six parallel families and two line spacings, dual to the [[great rhombitrihexagonal tiling]].

==Algorithms==
''Constructing'' an arrangement means, given as input a list of the lines in the arrangement, computing a representation of the vertices, edges, and cells of the arrangement together with the adjacencies between these objects, for instance as a [[doubly connected edge list]]. Due to the zone theorem, arrangements can be constructed efficiently by an incremental algorithm that adds one line at a time to the arrangement of the previously added lines: each new line can be added in time proportional to its zone, resulting in a total construction time of O(''n''&lt;sup&gt;2&lt;/sup&gt;).&lt;ref name="zone"/&gt; However, the memory requirements of this algorithm are high, so it may be more convenient to report all features of an arrangement by an algorithm that does not keep the entire arrangement in memory at once. This may again be done efficiently, in time O(''n''&lt;sup&gt;2&lt;/sup&gt;) and space O(''n''), by an algorithmic technique known as ''topological sweeping''.&lt;ref&gt;{{harvtxt|Edelsbrunner|Guibas|1989}}.&lt;/ref&gt; Computing a line arrangement exactly requires a numerical precision several times greater than that of the input coordinates: if a line is specified by two points on it, the coordinates of the arrangement vertices may need four times as much precision as these input points. Therefore, computational geometers have also studied algorithms for constructing arrangements efficiently with limited numerical precision.&lt;ref&gt;{{harvtxt|Fortune|Milenkovic|1991}}; {{harvtxt|Greene|Yao|1986}}; {{harvtxt|Milenkovic|1989}}.&lt;/ref&gt;

As well, researchers have studied efficient algorithms for constructing smaller portions of an arrangement, such as zones,&lt;ref&gt;{{harvtxt|Aharoni|Halperin|Hanniel|Har-Peled|1999}}.&lt;/ref&gt; ''k''-levels,&lt;ref&gt;{{harvtxt|Agarwal|de Berg|Matoušek|Schwarzkopf|1998}}; {{harvtxt|Chan|1999}}; {{harvtxt|Cole|Sharir|Yap|1987}}; {{harvtxt|Edelsbrunner|Welzl|1986}}.&lt;/ref&gt; or the set of cells containing a given set of points.&lt;ref&gt;{{harvtxt|Agarwal|1990}}; {{harvtxt|Agarwal|Matoušek|Sharir|1998}}; {{harvtxt|Edelsbrunner|Guibas|Sharir|1990}}.&lt;/ref&gt; The problem of finding the arrangement vertex with the median ''x''-coordinate arises (in a dual form) in [[robust statistics]] as the problem of computing the [[Theil–Sen estimator]] of a set of points.&lt;ref&gt;{{harvtxt|Cole|Salowe|Steiger|Szemerédi|1989}}.&lt;/ref&gt;

Marc van Kreveld suggested the algorithmic problem of computing [[shortest path]]s between vertices in a line arrangement, where the paths are restricted to follow the edges of the arrangement, more quickly than the quadratic time that it would take to apply a shortest path algorithm to the whole arrangement graph.&lt;ref&gt;{{harvtxt|Erickson|1997}}.&lt;/ref&gt; An [[approximation algorithm]] is known,&lt;ref&gt;{{harvtxt|Bose|Evans|Kirkpatrick|McAllister|1996}}.&lt;/ref&gt; and the problem may be solved efficiently for lines that fall into a small number of parallel families (as is typical for urban street grids),&lt;ref&gt;{{harvtxt|Eppstein|Hart|1999}}.&lt;/ref&gt; but the general problem remains open.

==Non-Euclidean line arrangements==
{{multiple images
&lt;!-- Essential parameters --&gt;
| align     = center
| direction = horizontal
| image1    = Pappos_pseudo.svg
| width1    = 383
| caption1  = A non-stretchable pseudoline arrangement of nine pseudolines. (All arrangements of fewer than nine pseudolines are stretchable.) Per [[Pappus's hexagon theorem]], this arrangement cannot be realized in a [[projective plane]] over any field.

| image2    = Ageev 5X circle graph.svg
| width2    = 300
| caption2  = A hyperbolic line arrangement combinatorially equivalent to a chord diagram used by {{harvtxt|Ageev|1996}} to show that [[triangle-free graph|triangle-free]] [[circle graph]]s may sometimes need [[graph coloring|5 colors]].
}}

A '''pseudoline arrangement''' is a family of [[curve]]s that share similar [[topology|topological]] properties with a line arrangement.&lt;ref&gt;{{harvtxt|Grünbaum|1972}}; {{harvtxt|Agarwal|Sharir|2002}}.&lt;/ref&gt; These can be defined most simply in the [[projective plane]] as [[simple closed curve]]s any two of which meet in a single crossing point.&lt;ref&gt;This definition is from {{harvtxt|Grünbaum|1972}}. For a comparison of alternative definitions of pseudolines, see {{harvtxt|Eppstein|Falmagne|Ovchinnikov|2007}}.&lt;/ref&gt; A pseudoline arrangement is said to be ''stretchable'' if it is combinatorially equivalent to a line arrangement; it is [[Complete (complexity)|complete]] for the [[existential theory of the reals]] to distinguish stretchable arrangements from non-stretchable ones.&lt;ref&gt;{{harvtxt|Shor|1991}}; {{harvtxt|Schaefer|2010}}.&lt;/ref&gt; Every arrangement of finitely many pseudolines can be extended so that they become lines in a "spread", a type of non-Euclidean [[incidence geometry]] in which every two points of a topological plane are connected by a unique line (as in the Euclidean plane) but in which other axioms of Euclidean geometry may not apply.

Another type of non-Euclidean geometry is the [[Hyperbolic space|hyperbolic plane]], and
'''arrangements of hyperbolic lines''' in this geometry have also been studied. Any finite set of lines in the Euclidean plane has a combinatorially equivalent arrangement in the hyperbolic plane (e.g. by enclosing the vertices of the arrangement by a large circle and interpreting the interior of the circle as a [[Klein model]] of the hyperbolic plane). However, in hyperbolic line arrangements lines may avoid crossing each other without being parallel; the [[intersection graph]] of the lines in a hyperbolic arrangement is a [[circle graph]]. The corresponding concept to hyperbolic line arrangements for pseudolines is a ''weak pseudoline arrangement'',&lt;ref&gt;{{harvtxt|de Fraysseix|Ossona de Mendez|2003}}.&lt;/ref&gt; a family of curves having the same topological properties as lines&lt;ref&gt;Here an alternative definition from {{harvtxt|Shor|1991}}, that a pseudoline is the image of a line under a [[homeomorphism]] of the plane, is appropriate.&lt;/ref&gt; such that any two curves in the family either meet in a single crossing point or have no intersection.

==See also==
*[[Configuration (geometry)]], an arrangement of lines and a set of points with all lines containing the same number of points and all points belonging to the same number of lines.
*[[Arrangement (space partition)]], a partition of the plane given by overlaid curves or of a higher dimensional space by overlaid surfaces, without requiring the curves or surfaces to be flat

==Notes==
{{reflist|30em}}

==References==
{{refbegin|30em}}
*{{citation
 | last = Agarwal | first = P. K. | authorlink = Pankaj K. Agarwal
 | doi = 10.1007/BF02187809
 | issue = 1
 | journal = [[Discrete &amp; Computational Geometry]]
 | pages = 533–573
 | title =  Partitioning arrangements of lines II: Applications
 | volume = 5
 | year = 1990}}.
*{{citation
 | last1 = Agarwal | first1 = P. K. | author1-link = Pankaj K. Agarwal
 | last2 = de Berg | first2 = M.
 | last3 = Matoušek | first3 = J. | author3-link = Jiří Matoušek (mathematician)
 | last4 = Schwarzkopf | first4 = O.
 | doi = 10.1137/S0097539795281840
 | issue = 3
 | journal = [[SIAM Journal on Computing]]
 | pages = 654–667
 | title = Constructing levels in arrangements and higher order Voronoi diagrams
 | volume = 27
 | year = 1998}}.
*{{citation
 | last1 = Agarwal | first1 = P. K. | author1-link = Pankaj K. Agarwal
 | last2 = Matoušek | first2 = J. | author2-link = Jiří Matoušek (mathematician)
 | last3 = Sharir | first3 = M. | author3-link = Micha Sharir
 | doi = 10.1137/S009753979426616X
 | issue = 2
 | journal = [[SIAM Journal on Computing]]
 | pages = 491–505
 | title = Computing many faces in arrangements of lines and segments
 | volume = 27
 | year = 1998}}.
*{{citation
 |last1=Agarwal |first1=P. K. | author1-link = Pankaj K. Agarwal 
 |last2=Sharir |first2=M. |author2-link=Micha Sharir 
 |contribution=Arrangements and their applications 
 |editor1-last=Sack 
 |editor1-first=J.-R. 
 |editor1-link=Jörg-Rüdiger Sack 
 |editor2-last=Urrutia 
 |editor2-first=J. 
 |editor2-link=Jorge Urrutia Galicia 
 |pages=49–119 
 |publisher=Elsevier 
 |title=Handbook of Computational Geometry 
 |contribution-url=https://users.cs.duke.edu/~pankaj/publications/surveys/arrangement-survey.pdf
 |year=2000 
}}.
*{{citation
 | last1 = Agarwal | first1 = P. K. | author1-link = Pankaj K. Agarwal 
 | last2 = Sharir | first2 = M. | author2-link = Micha Sharir
 | contribution = Pseudo-line arrangements: duality, algorithms, and applications
 | location = San Francisco
 | pages = 800–809
 | publisher = Society for Industrial and Applied Mathematics
 | title = Proc. 13th ACM-SIAM [[Symposium on Discrete Algorithms]] (SODA '02)
 | contribution-url = http://portal.acm.org/citation.cfm?id=545486
 | year = 2002}}.
*{{citation
 | doi = 10.1016/0012-365X(95)00349-2
 | last = Ageev | first = A. A.
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 295–298
 | title = A triangle-free circle graph with chromatic number 5
 | volume = 152
 | year = 1996}}.
*{{citation
 | last1 = Aharoni | first1 = Y.
 | last2 = Halperin | first2 = D.
 | last3 = Hanniel | first3 = I.
 | last4 = Har-Peled | first4 = S. | author4-link = Sariel Har-Peled
 | last5 = Linhart | first5 = C.
 | contribution = On-line zone construction in arrangements of lines in the plane
 | doi = 10.1007/3-540-48318-7_13
 | pages = 139–153
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = Algorithm Engineering: 3rd International Workshop, WAE’99, London, UK, July 19–21, 1999, Proceedings
 | editor1-first = Jeffrey S. | editor1-last = Vitter | editor1-link = Jeffrey Vitter
 | editor2-first = Christos D. | editor2-last = Zaroliagis
 | volume = 1668
 | year = 1999}}.
*{{citation
 | last1 = Ajtai | first1 = M. | author1-link = Miklós Ajtai
 | last2 = Chvátal | first2 = V. | author2-link = Václav Chvátal
 | last3 = Newborn | first3 = M. | author3-link = Monty Newborn
 | last4 = Szemerédi | first4 = E. | author4-link = Endre Szemerédi
 | contribution = Crossing-free subgraphs
 | pages = 9–12
 | series = North-Holland Mathematics Studies
 | volume = 60
 | publisher = North-Holland
 | title = Theory and Practice of Combinatorics
 | year = 1982
 | mr = 806962}}.
*{{citation
 | last1 = Alon | first1 = N. | author1-link = Noga Alon
 | last2 = Győri | first2 = E.
 | doi = 10.1016/0097-3165(86)90122-6
 | journal = [[Journal of Combinatorial Theory]], Series A
 | pages = 154–157
 | title = The number of small semi-spaces of a finite set of points in the plane
 | volume = 41
 | year = 1986}}.
*{{citation
 | last1 = Aronov | first1 = B. | author1-link = Boris Aronov
 | last2 = Matoušek | first2 = J. | author2-link = Jiří Matoušek (mathematician)
 | last3 = Sharir | first3 = M. | author3-link = Micha Sharir
 | doi = 10.1016/0097-3165(94)90027-2
 | issue = 2
 | journal = [[Journal of Combinatorial Theory]], Series A
 | pages = 311–321
 | title = On the sum of squares of cell complexities in hyperplane arrangements
 | volume = 65
 | year = 1994}}
*{{citation
 | doi = 10.2140/pjm.1998.184.207
 | last1 = Artés | first1 = J. C.
 | last2 = Grünbaum | first2 = B. | author2-link = Branko Grünbaum
 | last3 = Llibre | first3 = J.
 | issue = 2
 | journal = [[Pacific Journal of Mathematics]]
 | pages = 207–230
 | title = On the number of invariant straight lines for polynomial differential systems
 | url = http://pjm.math.berkeley.edu/pjm/1998/184-2/pjm-v184-n2-p02-p.pdf
 | volume = 184
 | year = 1998}}.
*{{citation
 | last1 = Balogh | first1 = J.
 | last2 = Regev | first2 = O.
 | last3 = Smyth | first3 = C.
 | last4 = Steiger | first4 = W.
 | last5 = Szegedy | first5 = M. | author5-link = Mario Szegedy
 | doi = 10.1007/s00454-004-1119-1
 | issue = 2
 | journal = [[Discrete &amp; Computational Geometry]]
 | pages = 167–176
 | title = Long monotone paths in line arrangements
 | volume = 32
 | year = 2004}}.
*{{citation
 | last1 = Bern | first1 = M. W.
 | last2 = Eppstein | first2 = D. | author2-link = David Eppstein
 | last3 = Plassman | first3 = P. E.
 | last4 = Yao | first4 = F. F. | author4-link = Frances Yao
 | contribution = Horizon theorems for lines and polygons
 | edition = 6
 | editor1-last = Goodman | editor1-first = J. E. | editor1-link = Jacob E. Goodman
 | editor2-last = Pollack | editor2-first = R. | editor3-link = Richard M. Pollack
 | editor3-last = Steiger | editor3-first = W.
 | pages = 45–66
 | publisher = Amer. Math. Soc.
 | series = DIMACS Ser. Discrete Math. and Theoretical Computer Science
 | title = Discrete and Computational Geometry: Papers from the DIMACS Special Year
 | year = 1991
 | mr =1143288 }}.
*{{citation
 | last1 = Bose | first1 = P. | author1-link = Jit Bose
 | last2 = Evans | first2 = W.
 | last3 = Kirkpatrick | first3 = D. G. | author3-link = David G. Kirkpatrick
 | last4 = McAllister | first4 = M.
 | last5 = Snoeyink | first5 = J.
 | contribution = Approximating shortest paths in arrangements of lines
 | pages = 143–148
 | title = Proc. 8th Canadian Conf. Computational Geometry
 | year = 1996}}.
*{{citation
 | last = de Bruijn | first = N. G. | author-link = Nicolaas Govert de Bruijn
 | journal = [[Indagationes Mathematicae]]
 | pages = 38–66
 | title = Algebraic theory of Penrose's non-periodic tilings of the plane
 | url = http://alexandria.tue.nl/repository/freearticles/597566.pdf
 | volume = 43
 | year = 1981}}.
*{{citation
 | doi = 10.1007/BF02788872
 | last = Canham | first = R.
 | journal = Israel J. Math.
 | pages = 393–397
 | title = A theorem on arrangements of lines in the plane
 | volume = 7
 | year = 1969
 | issue = 4}}.
*{{citation
 |last=Chan 
 |first=T. 
 |author-link=Timothy M. Chan 
 |title=Remarks on ''k''-level algorithms in the plane 
 |url=http://www.cs.uwaterloo.ca/~tmchan/lev2d_7_7_99.ps.gz 
 |year=1999 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20101104182509/http://www.cs.uwaterloo.ca/~tmchan/lev2d_7_7_99.ps.gz 
 |archivedate=2010-11-04 
}}.
*{{citation
 | last1 = Chazelle | first1 = B. | author1-link = Bernard Chazelle
 | last2 = Guibas | first2 = L. J. | author2-link = Leonidas J. Guibas
 | last3 = Lee | first3 = D. T. | author3-link = Der-Tsai Lee
 | doi = 10.1007/BF01934990
 | issue = 1
 | journal = [[BIT Numerical Mathematics]]
 | pages = 76–90
 | title = The power of geometric duality
 | volume = 25
 | year = 1985}}.
*{{citation
 | last1 = Clarkson | first1 = K. | author1-link = Kenneth L. Clarkson
 | last2 = Edelsbrunner | first2 = H. | author2-link = Herbert Edelsbrunner
 | last3 = Guibas | first3 = L. J. | author3-link = Leonidas J. Guibas
 | last4 = Sharir | first4 = M. | author4-link = Micha Sharir
 | last5 = Welzl | first5 = E. | author5-link = Emo Welzl
 | doi = 10.1007/BF02187783
 | issue = 1
 | journal = [[Discrete &amp; Computational Geometry]]
 | pages = 99–160
 | title = Combinatorial complexity bounds for arrangements of curves and spheres
 | volume = 5
 | year = 1990}}.
*{{citation
 | last1 = Cole | first1 = Richard
 | last2 = Salowe | first2 = Jeffrey S.
 | last3 = Steiger | first3 = W. L.
 | last4 = Szemerédi | first4 = Endre | author4-link = Endre Szemerédi
 | doi = 10.1137/0218055
 | issue = 4
 | journal = [[SIAM Journal on Computing]]
 | mr = 1004799
 | pages = 792–810
 | title = An optimal-time algorithm for slope selection
 | volume = 18
 | year = 1989}}.
*{{citation
 | last1 = Cole | first1 = R.
 | last2 = Sharir | first2 = M. | author2-link = Micha Sharir
 | last3 = Yap | first3 = C.-K.
 | doi = 10.1137/0216005
 | issue = 1
 | journal = [[SIAM Journal on Computing]]
 | pages = 61–77
 | title = On ''k''-hulls and related problems
 | volume = 16
 | year = 1987}}.
*{{citation
 | doi = 10.2307/2687957
 | last1 = Crowe | first1 = D. W.
 | last2 = McKee | first2 = T. A.
 | issue = 1
 | journal = [[Mathematics Magazine]]
 | pages = 30–34
 | title = Sylvester's problem on collinear points
 | volume = 41
 | year = 1968
 | publisher = Mathematical Association of America
 | jstor = 2687957}}.
*{{citation
 | last = Dey | first = T. L.
 | doi = 10.1007/PL00009354
 | issue = 3
 | journal = [[Discrete &amp; Computational Geometry]]
 | pages = 373–382
 | title = Improved bounds for planar ''k''-sets and related problems
 | volume = 19
 | year = 1998
 | mr = 1608878}}.
*{{citation
 | last = Dirac | first = G. | author-link = Gabriel Andrew Dirac
 | doi = 10.1093/qmath/2.1.221
 | journal = [[Quarterly Journal of Mathematics]]
 | pages = 221–227
 | title = Collinearity properties of sets of points
 | volume = 2
 | year = 1951| bibcode = 1951QJMat...2..221D}}.
*{{citation
 | last = Edelsbrunner | first = H. | author-link = Herbert Edelsbrunner
 | isbn = 978-3-540-13722-1
 | publisher = Springer-Verlag
 | series = EATCS Monographs in Theoretical Computer Science
 | title = Algorithms in Combinatorial Geometry
 | year = 1987}}.
*{{citation
 | last1 = Edelsbrunner | first1 = H. | author1-link = Herbert Edelsbrunner
 | last2 = Guibas | first2 = L. J. | author2-link = Leonidas J. Guibas
 | doi = 10.1016/0022-0000(89)90038-X
 | issue = 1
 | journal = [[Journal of Computer and System Sciences]]
 | pages = 165–194
 | title = Topologically sweeping an arrangement
 | volume = 38
 | year = 1989}}.
*{{citation
 | last1 = Edelsbrunner | first1 = H. | author1-link = Herbert Edelsbrunner
 | last2 = Guibas | first2 = L. J. | author2-link = Leonidas J. Guibas
 | last3 = Sharir | first3 = M. | author3-link = Micha Sharir
 | doi = 10.1007/BF02187784
 | issue = 1
 | journal = [[Discrete &amp; Computational Geometry]]
 | pages = 161–196
 | title = The complexity and construction of many faces in arrangements of lines and of segments
 | volume = 5
 | year = 1990}}.
*{{citation
 | last1 = Edelsbrunner | first1 = H. | author1-link = Herbert Edelsbrunner
 | last2 = O'Rourke | first2 = J. | author2-link = Joseph O'Rourke (professor)
 | last3 = Seidel | first3 = R. | author3-link = Raimund Seidel
 | doi = 10.1137/0215024
 | issue = 2
 | journal = [[SIAM Journal on Computing]]
 | pages = 341–363
 | title = Constructing arrangements of lines and hyperplanes with applications
 | volume = 15
 | year = 1986}}.
*{{citation
 | last1 = Edelsbrunner | first1 = H. | author1-link = Herbert Edelsbrunner
 | last2 = Welzl | first2 = E. | author2-link = Emo Welzl
 | doi = 10.1137/0215019
 | issue = 1
 | journal = [[SIAM Journal on Computing]]
 | pages = 271–284
 | title = Constructing belts in two-dimensional arrangements with applications
 | volume = 15
 | year = 1986}}.
*{{citation
 | last = Eppstein | first = D. | author-link = David Eppstein
 | year = 2006
 | issue = 1, R79
 | journal =  [[Electronic Journal of Combinatorics]]
 | pages = 1–14
 | title = Cubic partial cubes from simplicial arrangements
 | url = http://www.combinatorics.org/Volume_13/Abstracts/v13i1r79.html
 | volume = 13
 | arxiv = math.CO/0510263
 | mr = 2255421}}.
*{{citation
 | last1 = Eppstein | first1 = D. | author1-link = David Eppstein
 | last2 = Falmagne | first2 = J.-Cl. | author2-link = Jean-Claude Falmagne
 | last3 = Ovchinnikov | first3 = S.
 | publisher = Springer-Verlag
 | title = Media Theory
 | year = 2007}}.
*{{citation
 | last1 = Eppstein | first1 = D. | author1-link = David Eppstein
 | last2 = Hart | first2 = D.
 | contribution = Shortest paths in an arrangement with ''k'' line orientations
 | year = 1999
 | pages = 310–316
 | title = Proceedings of the 10th ACM–SIAM [[Symposium on Discrete Algorithms]] (SODA '99)
 | contribution-url = http://portal.acm.org/citation.cfm?id=314580}}.
*{{citation
 | last1 = Erdős | first1 = P. | author1-link = Paul Erdős
 | last2 = Lovász | first2 = L. | author2-link = László Lovász
 | last3 = Simmons | first3 = A.
 | last4 = Straus | first4 = E. G. | author4-link = Ernst G. Straus
 | contribution = Dissection graphs of planar point sets
 | location = Amsterdam
 | pages = 139–149
 | publisher = North-Holland
 | title = A Survey of Combinatorial Theory (Proc. Internat. Sympos., Colorado State Univ., Fort Collins, Colo., 1971)
 | year = 1973
 | mr = 363986}}.
*{{citation
 | last = Erickson | first = J.
 | title = Shortest paths in line arrangements
 | url = http://compgeom.cs.uiuc.edu/~jeffe/open/algo.html#shortpath
 | year = 1997}}.
*{{citation
 | last1 = Fortune | first1 = S.
 | last2 = Milenkovic | first2 = V.
 | contribution = Numerical stability of algorithms for line arrangements
 | doi = 10.1145/109648.109685
 | pages = 334–341
 | title = Proc. 7th ACM [[Symposium on Computational Geometry]] (SoCG '91)
 | year = 1991}}.
*{{citation
 | last1 = de Fraysseix | first1 = H.
 | last2 = Ossona de Mendez | first2 = P. | author2-link = Patrice Ossona de Mendez
 | contribution = Stretching of Jordan arc contact systems
 | edition = 2912
 | pages = 71–85
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = Proceedings of the 11th [[International Symposium on Graph Drawing]] (GD 2003)
 | year = 2003}}.
*{{citation
 | last1 = Füredi | first1 = Z. | author1-link = Zoltán Füredi
 | last2 = Palásti | first2 = I. | author2-link = Ilona Palásti
 | issue = 4
 | journal = [[Proceedings of the American Mathematical Society]]
 | pages = 561–566
 | title = Arrangements of lines with a large number of triangles
 | url = http://www.math.uiuc.edu/~z-furedi/PUBS/furedi_palasti_lines.pdf
 | volume = 92
 | year = 1984 | doi=10.2307/2045427}}
*{{citation
 | last1 = Greene | first1 = D.
 | last2 = Yao | first2 = F. F. | author2-link = Frances Yao
 | contribution = Finite-resolution computational geometry
 | doi = 10.1109/SFCS.1986.19
 | pages = 143–152
 | title = Proceedings of the 27th IEEE [[Symposium on Foundations of Computer Science]] (FOCS '86)
 | year = 1986}}.
*{{citation
 | last = Grünbaum | first = B. | author-link = Branko Grünbaum
 | location = Providence, R.I.
 | publisher = American Mathematical Society
 | series = Regional Conference Series in Mathematics
 | title = Arrangements and Spreads
 | volume = 10
 | year = 1972}}.
*{{citation
 | last = Grünbaum | first = B. | author-link = Branko Grünbaum
 | title = A catalogue of simplicial arrangements in the real projective plane
 | url = http://digital.lib.washington.edu/dspace/handle/1773/2269
 | year = 2005}}.
*{{citation
 | doi = 10.4153/CJM-1958-024-6
 | last1 = Kelly | first1 = L. M. | author1-link = Leroy Milton Kelly
 | last2 = Moser | first2 = W. O. J.
 | journal = [[Canadian Journal of Mathematics]]
 | pages = 210–219
 | title = On the number of ordinary lines determined by ''n'' points
 | volume = 10
 | year = 1958}}.
*{{citation
 | last = Leighton | first = F. T. | author-link = F. Thomson Leighton
 | location = Cambridge, MA
 | publisher = MIT Press
 | series = Foundations of Computing Series
 | title = Complexity Issues in VLSI
 | year = 1983}}.
*{{citation
 | last = Levi | first = F. | authorlink = Friedrich Wilhelm Levi
 | journal = Ber. Math.-Phys. Kl. Sächs. Akad. Wiss. Leipzig
 | pages = 256–267
 | title = Die Teilung der projektiven Ebene durch Gerade oder Pseudogerade
 | volume = 78
 | year = 1926}}.
*{{citation
 | last = Lovász | first = L. | author-link = László Lovász
 | journal = Annales Universitatis Scientiarum Budapestinensis de Rolando Eőtvős Nominatae Sectio Mathematica
 | pages = 107–108
 | title = On the number of halving lines
 | volume = 14
 | year = 1971}}.
*{{citation
 | last = Matoušek | first = J. | authorlink = Jiří Matoušek (mathematician)
 | doi = 10.1007/BF02574679
 | issue = 1
 | journal = [[Discrete &amp; Computational Geometry]]
 | pages = 129–134
 | title = Lower bounds on the length of monotone paths in arrangements
 | volume = 6
 | year = 1991}}.
*{{citation
 | last = Melchior | first = E. | authorlink = Eberhard Melchior
 | journal = [[Deutsche Mathematik]]
 | pages = 461–475
 | title = Über Vielseite der projektiven Ebene
 | volume = 5
 | year = 1940}}.
*{{citation
 | last = Milenkovic | first = V.
 | contribution = Double precision geometry: a general technique for calculating line and segment intersections using rounded arithmetic
 | doi = 10.1109/SFCS.1989.63525
 | pages = 500–505
 | title = Proceedings of the 30th IEEE [[Symposium on Foundations of Computer Science]] (FOCS '89)
 | year = 1989}}.
*{{citation
 | last = Motzkin
 | first = Th.
 | authorlink = Theodore Motzkin
 | journal = [[Transactions of the American Mathematical Society]]
 | jstor = 1990609
 | volume = 70
 | issue = 3
 | pages = 451–464
 | title = The lines and planes connecting the points of a finite set
 | year = 1951
 | doi=10.2307/1990609
}}.
*{{citation
 | doi = 10.1016/0012-365X(79)90018-9
 | last = Purdy | first = G. B. | authorlink = George B. Purdy
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 157–163
 | title = Triangles in arrangements of lines
 | volume = 25
 | year = 1979
 | issue = 2}}.
*{{citation
 | last = Purdy | first = G. B. | authorlink = George B. Purdy
 | journal = [[Proceedings of the American Mathematical Society]]
 | pages = 77–81
 | title = Triangles in arrangements of lines, II
 | volume = 79
 | year = 1980
 | doi = 10.1090/S0002-9939-1980-0560588-4}}.
*{{citation
 | last = Roudneff | first = J.-P.
 | doi = 10.1007/BF02187900
 | issue = 1
 | journal = [[Discrete &amp; Computational Geometry]]
 | pages = 97–102
 | title = Arrangements of lines with a minimum number of triangles are simple
 | volume = 3
 | year = 1988}}.
*{{citation|first=Marcus|last=Schaefer|contribution=Complexity of some geometric and topological problems|contribution-url=http://ovid.cs.depaul.edu/documents/convex.pdf|title=[[International Symposium on Graph Drawing|Graph Drawing, 17th International Symposium, GS 2009, Chicago, IL, USA, September 2009, Revised Papers]]|series=Lecture Notes in Computer Science|publisher=Springer-Verlag|volume=5849|pages=334–344|doi=10.1007/978-3-642-11805-0_32|year=2010}}.
*{{citation
 | last = Shor | first = P. W. | authorlink = Peter Shor
 | contribution = Stretchability of pseudolines is NP-hard
 | editor1-last = Gritzmann | editor1-first = P.
 | editor2-last = Sturmfels | editor2-first = B. | editor2-link = Bernd Sturmfels
 | location = Providence, R.I.
 | pages = 531–554
 | publisher = American Mathematical Society
 | series = DIMACS Series in Discrete Mathematics and Theoretical Computer Science
 | title = Applied Geometry and Discrete Mathematics: The [[Victor Klee]] Festschrift
 | volume = 4
 | year = 1991}}.
*{{citation
 | last = Steiner | first = J. | author-link = Jakob Steiner
 | journal = [[Crelle's Journal|J. Reine Angew. Math.]]
 | pages = 349–364
 | title = Einige Gesetze über die Theilung der Ebene und des Raumes
 | volume = 1
 | year = 1826}}.
*{{citation
 | doi = 10.1016/0097-3165(77)90022-X
 | last = Strommer | first = T. O.
 | journal = [[Journal of Combinatorial Theory]], Series A
 | pages = 314–320
 | title = Triangles in arrangements of lines
 | volume = 23
 | year = 1977
 | issue = 3}}.
*{{citation
 | last = Székely | first = L. A.
 | doi = 10.1017/S0963548397002976
 | issue = 3
 | journal = [[Combinatorics, Probability and Computing]]
 | pages = 353–358
 | title = Crossing numbers and hard Erdős problems in discrete geometry
 | volume = 6
 | year = 1997}}.
*{{citation
 | last = Tóth | first = G.
 | doi = 10.1007/s004540010022
 | issue = 2
 | journal = [[Discrete &amp; Computational Geometry]]
 | pages = 187–194
 | title = Point sets with many ''k''-sets
 | volume = 26
 | year = 2001}}.
{{refend}}

== External links ==
* [http://geometry.inf.ethz.ch/christt/linearr/ Database of Combinatorially Different Line Arrangements]

{{DEFAULTSORT:Arrangement Of Lines}}
[[Category:Discrete geometry]]
[[Category:Euclidean plane geometry]]</text>
      <sha1>38v7vrhezwm49y7h74twsobxmb5cits</sha1>
    </revision>
  </page>
  <page>
    <title>Astrostatistics</title>
    <ns>0</ns>
    <id>37815827</id>
    <revision>
      <id>804775474</id>
      <parentid>804708126</parentid>
      <timestamp>2017-10-11T02:09:25Z</timestamp>
      <contributor>
        <username>Tayste</username>
        <id>6531599</id>
      </contributor>
      <minor/>
      <comment>Undid revision 804708126 by [[Special:Contributions/103.239.85.43|103.239.85.43]] ([[User talk:103.239.85.43|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1343">'''Astrostatistics''' is a discipline which spans [[astrophysics]], [[statistical analysis]] and [[data mining]].&lt;ref&gt;[https://asaip.psu.edu  Astrostatistics and Astroinformatics Portal]&lt;/ref&gt; It is used to process the vast amount of data produced by [[automated scanning]] of the cosmos, to characterize complex datasets, and to link [[astronomical data]] to [[astrophysical theory]].  Many branches of statistics are involved in astronomical analysis including [[nonparametrics]], [[multivariate regression]] and [[multivariate classification]], [[time series analysis]], and especially [[Bayesian inference]].

==Professional association==
Practitioners are represented by the [[International Astrostatistics Association]] affiliated with the [[International Statistical Institute]], the [[International Astronomical Union]] Working Group in Astrostatistics and Astroinformatics, the [[American Astronomical Society]] Working Group in Astroinformatics and Astrostatistics, and the [[American Statistical Association]] Interest Group in Astrostatistics.  All of these organizations participate in the [http://asaip.psu.edu Astrostatistics and Astroinformatics Portal] Web site.

==References==
{{reflist}}

[[Category:Astrophysics]]
[[Category:Applied statistics]]
[[Category:Data mining and machine learning software]]


{{Statistics-stub}}</text>
      <sha1>pae3903moejwm1zj40omwe5g48dbfdr</sha1>
    </revision>
  </page>
  <page>
    <title>Cochleoid</title>
    <ns>0</ns>
    <id>2737856</id>
    <revision>
      <id>815093965</id>
      <parentid>802021229</parentid>
      <timestamp>2017-12-12T18:56:10Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v478)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1516">[[File:Cochleoid with a=1.svg|thumb|&lt;math&gt;r=\frac{\sin \theta}{\theta}, -20&lt;\theta&lt;20&lt;/math&gt;]]
A '''cochleoid''' is a [[snail]]-shaped curve similar to a [[strophoid]] which can be represented by the [[polar equation]]
:&lt;math&gt;r=\frac{a \sin \theta}{\theta},&lt;/math&gt;
the [[Cartesian equation]]
:&lt;math&gt;(x^2+y^2)\arctan\frac{y}{x}=ay,&lt;/math&gt;
or the [[parametric equation]]s
:&lt;math&gt;x=\frac{a\sin t\cos t}{t}, \quad y=\frac{a\sin^2 t}{t}.&lt;/math&gt;

==References==
* {{cite book | author=J. Dennis Lawrence | title=A catalog of special plane curves | publisher=Dover Publications | year=1972 | isbn=0-486-60288-5 | page=192 }}
*[https://www.encyclopediaofmath.org/index.php/Cochleoid ''Cochleoid''] in the [[Encyclopedia of Mathematics]]
*Liliana Luca, Iulian Popescu: [http://www.utgjiu.ro/rev_mec/mecanica/pdf/2011-01/3_luca.pdf ''A Special Spiral: The Cochleoid'']. Fiabilitate si Durabilitate - Fiability &amp; Durability no 1(7)/ 2011, Editura “Academica Brâncuşi” , Târgu Jiu, {{issn|1844}}–640X
*Roscoe Woods: ''The Cochlioid''. The American Mathematical Monthly, Vol. 31, No. 5 (May, 1924), pp.&amp;nbsp;222–227 ([https://www.jstor.org/stable/2299243 JSTOR])
* [[Howard Eves]]: ''A Graphometer''. The Mathematics Teacher, Vol. 41, No. 7 (November 1948), pp. 311-313 ([https://www.jstor.org/stable/27953353 JSTOR])

== External links ==
{{commonscat}}
*[http://www.2dcurves.com/spiral/spiralc.html cochleoid] at 2dcurves.com
* {{MathWorld|title=Cochleoid|urlname=Cochleoid}}

[[Category:Curves]]


{{geometry-stub}}</text>
      <sha1>1g7t5yzmz5ln2przfp6nkof9ar5lgmz</sha1>
    </revision>
  </page>
  <page>
    <title>Complex analysis</title>
    <ns>0</ns>
    <id>5759</id>
    <revision>
      <id>861956179</id>
      <parentid>861918543</parentid>
      <timestamp>2018-10-01T06:43:33Z</timestamp>
      <contributor>
        <username>Purgy Purgatorio</username>
        <id>22035051</id>
      </contributor>
      <comment>Undid revision 861918543 by [[Special:Contributions/2601:58C:201:A884:225:FF:FE4B:69ED|2601:58C:201:A884:225:FF:FE4B:69ED]] ([[User talk:2601:58C:201:A884:225:FF:FE4B:69ED|talk]])seems to be a one-trick-IP</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14051">{{redirect|Complex analytic|the class of functions often called "complex analytic"|Holomorphic function}}
{{distinguish|Complexity theory (disambiguation){{!}}Complexity theory}}

[[Image:Color complex plot.jpg|right|thumb|262px|[[Domain coloring|Color wheel graph]] of the function
{{math|''f''(''z'') {{=}} (''z''&lt;sup&gt;2&lt;/sup&gt; − 1)(''z'' + 2 − ''i'')&lt;sup&gt;2&lt;/sup&gt;}}
{{math|/ (''z''&lt;sup&gt;2&lt;/sup&gt; + 2 - 2''i'')}}.&lt;br&gt;
[[Hue]] represents the [[Argument (complex analysis)|argument]], [[brightness]] the [[Absolute_value#Complex_numbers|magnitude.]]]]

{{Complex analysis sidebar}}

'''Complex analysis''', traditionally known as the '''theory of functions of a complex variable''', is the branch of [[mathematical analysis]] that investigates [[Function (mathematics)|functions]] of [[complex numbers]]. It is useful in many branches of mathematics, including [[algebraic geometry]], [[number theory]], [[analytic combinatorics]], [[applied mathematics]]; as well as in [[physics]], including the branches of [[hydrodynamics]], [[thermodynamics]], and particularly [[quantum mechanics]]. By extension, use of complex analysis also has applications in engineering fields such as [[nuclear engineering|nuclear]], [[aerospace engineering|aerospace]], [[mechanical engineering|mechanical]] and [[electrical engineering]].{{Citation needed|date=June 2018}}

As a [[derivative|differentiable function]] of a complex variable is equal to the sum of its [[Taylor series]] (that is, it is [[analytic function|analytic]]), complex analysis is particularly concerned with analytic functions of a complex variable (that is, [[holomorphic function]]s).

== History ==
[[Image:Mandel zoom 00 mandelbrot set.jpg|right|262px|thumb|The [[Mandelbrot set]], a [[fractal]]]]
Complex analysis is one of the classical branches in mathematics, with roots in the 18th century and just prior. Important mathematicians associated with complex numbers include [[Euler]], [[Carl Friedrich Gauss|Gauss]], [[Bernhard Riemann|Riemann]], [[Cauchy]], [[Weierstrass]], and many more in the 20th century. Complex analysis, in particular the theory of [[conformal mapping]]s, has many physical applications and is also used throughout [[analytic number theory]]. In modern times, it has become very popular through a new boost from [[complex dynamics]] and the pictures of [[fractal]]s produced by iterating [[holomorphic functions]].  Another important application of complex analysis is in [[string theory]] which studies conformal invariants in [[quantum field theory]].

== Complex functions ==&lt;!-- This section is linked from [[Complex plane]] --&gt;
A complex function is a function whose [[domain (mathematics)#Domain of a function|domain]] and [[range (mathematics)|range]] are [[subset]]s of the [[complex plane]]. This is also expressed by saying that the [[independent variable]] and the [[dependent variable]] both are complex numbers.

For any complex function, the values &lt;math&gt;z&lt;/math&gt; from the domain and their images &lt;math&gt;f(z)&lt;/math&gt; in the range may be separated into [[Real number|real]] and [[Imaginary number|imaginary]] parts:

: &lt;math&gt;z=x+iy \quad&lt;/math&gt; and &lt;math&gt; \quad f(z) = f(x+iy)=u(x,y)+iv(x,y)&lt;/math&gt;,

where &lt;math&gt;x,y,u(x,y),v(x,y)&lt;/math&gt; are all real-valued.  

In other words, a complex function &lt;math&gt;f:\mathbb{C}\to\mathbb{C}&lt;/math&gt; may be decomposed into 

: &lt;math&gt;u:\mathbb{R}^2\to\mathbb{R} \quad&lt;/math&gt; and &lt;math&gt;\quad v:\mathbb{R}^2\to\mathbb{R},&lt;/math&gt;

i.e., into two real-valued functions (&lt;math&gt;u&lt;/math&gt;, &lt;math&gt;v&lt;/math&gt;) of two real variables (&lt;math&gt;x&lt;/math&gt;, &lt;math&gt;y&lt;/math&gt;).

The basic concepts of complex analysis are often introduced by extending the elementary [[real function]]s (e.g., [[exponential function]]s, [[logarithmic function]]s, and [[trigonometric function]]s) into a complex domain and the corresponding complex range.

== Holomorphic functions ==
{{main|Holomorphic function}}
Complex functions that are [[differentiable function|differentiable]] at every point of an [[open set|open subset]] &lt;math&gt;\Omega&lt;/math&gt; of the complex plane are said to be ''holomorphic'' ''on'' &lt;math&gt;\Omega&lt;/math&gt;.  In the context of complex analysis, the derivative of &lt;math&gt;f&lt;/math&gt; at &lt;math&gt;z_0&lt;/math&gt; is defined to be  &lt;blockquote&gt;&lt;math&gt;f'(z_0)=\lim_{z\to z_0} \frac{f(z)-f(z_0)}{z-z_0},z\in
\mathbb{C}&lt;/math&gt;.&lt;/blockquote&gt;Superficially, this definition is formally analogous to that of the derivative of a real function.  However, complex derivatives and differentiable functions behave in significantly different ways compared to their real counterparts.  In particular, for this limit to exist, the value of the difference quotient must approach the same complex number, regardless of the manner in which we approach &lt;math&gt;z_0&lt;/math&gt; in the complex plane.  Consequently, complex differentiability has much stronger implications than real differentiability. For instance, holomorphic functions are [[infinitely differentiable]], whereas the existence of the ''n''th derivative need not imply the existence of the (''n'' + 1)th derivative for real functions.  Furthermore, all holomorphic functions satisfy the stronger condition of [[analytic function|analyticity]], meaning that the function is, at every point in its domain, locally given by a convergent power series. In essence, this means that functions holomorphic on &lt;math&gt;\Omega&lt;/math&gt; can be approximated arbitrarily well by polynomials in some neighborhood of every point in &lt;math&gt;\Omega&lt;/math&gt;. This stands in sharp contrast to differentiable real functions; even [[non-analytic smooth function#A smooth function which is nowhere real analytic|infinitely differentiable real functions can be ''nowhere'' analytic]].

Most elementary functions, including the [[exponential function]], the [[trigonometric function]]s, and all [[polynomial|polynomial functions]], extended appropriately to complex arguments as functions &lt;math&gt;\mathbb{C}\to\mathbb{C}&lt;/math&gt;, are holomorphic over the entire complex plane, making them ''entire'' ''functions'', while rational functions &lt;math&gt;p/q&lt;/math&gt;, where ''p'' and ''q'' are polynomials, are holomorphic on domains that exclude points where ''q'' is zero.  Such functions that are holomorphic everywhere except a set of isolated points are known as ''meromorphic functions''.  On the other hand, the functions &lt;math&gt;z\mapsto \Re(z)&lt;/math&gt;, &lt;math&gt;z\mapsto |z|&lt;/math&gt;, and &lt;math&gt;z\mapsto \bar{z}&lt;/math&gt; are not holomorphic anywhere on the complex plane, as can be shown by their failure to satisfy the Cauchy-Riemann conditions (see below).

An important property that characterizes holomorphic functions is the relationship between the partial derivatives of their real and imaginary components, known as the [[Cauchy-Riemann conditions]].  If &lt;math&gt;f:\mathbb{C}\to\mathbb{C}&lt;/math&gt;, defined by &lt;math&gt;f(z)=f(x+iy)=u(x,y)+iv(x,y)&lt;/math&gt;, where &lt;math&gt;x,y, u(x,y),v(x,y)\in\mathbb{R}&lt;/math&gt;, is holomorphic on a [[Region (mathematics)|region]] &lt;math&gt;\Omega&lt;/math&gt;, then ''&lt;math&gt;(\partial f/\partial \bar{z})(z_0)= 0&lt;/math&gt;'' must hold for all &lt;math&gt;z_0\in \Omega&lt;/math&gt;.  Here, the differential operator &lt;math&gt;\partial/\partial\bar{z} &lt;/math&gt; is defined as &lt;math&gt;(1/2)(\partial/\partial x+i\partial/\partial y) &lt;/math&gt;''.''  In terms of the real and imaginary parts of the function, ''u'' and ''v'', this is equivalent to the pair of equations &lt;math&gt;u_x = v_y&lt;/math&gt; and &lt;math&gt;u_y=-v_x&lt;/math&gt;, where the subscripts indicate partial differentiation.  However, it is important to note that functions satisfying the Cauchy-Riemann conditions are not necessarily holomorphic, unless additional continuity conditions are met (see [[Looman–Menchoff theorem|Looman-Menchoff Theorem]] for a discussion).

Holomorphic functions exhibit some remarkable features.  For instance, [[Picard theorem|Picard's theorem]] asserts that the range of an entire function can only take three possible forms: &lt;math&gt;\mathbb{C}&lt;/math&gt;, &lt;math&gt;\mathbb{C}\setminus\{z_0\}&lt;/math&gt;, or &lt;math&gt;\{z_0\}&lt;/math&gt; for some &lt;math&gt;z_0\in\mathbb{C}&lt;/math&gt;.  In other words, if two distinct complex numbers &lt;math&gt;z&lt;/math&gt; and &lt;math&gt;w&lt;/math&gt; are not in the range of entire function &lt;math&gt;f&lt;/math&gt;, then &lt;math&gt;f&lt;/math&gt; is a constant function.  Moreover, given a holomorphic function &lt;math&gt;f&lt;/math&gt; defined on an open set &lt;math&gt;U&lt;/math&gt;, the [[analytic continuation]] of &lt;math&gt;f&lt;/math&gt; to a larger open set &lt;math&gt;V\supset U&lt;/math&gt; is unique.  As a result, the value of a holomorphic function over an arbitrarily small region in fact determines the value of the function everywhere to which it can be extended as a holomorphic function.

''See also'': [[analytic function]], [[coherent sheaf]] and [[vector bundle]]s.

== Major results ==
One of the central tools in complex analysis is the [[line integral]]. The line integral around a closed path of a function that is holomorphic everywhere inside the area bounded by the closed path is always zero, which is what the [[Cauchy integral theorem]] states. The values of such a holomorphic function inside a disk can be computed by a path integral on the disk's boundary (as shown in [[Cauchy's integral formula]]). Path integrals in the complex plane are often used to determine complicated real integrals, and here the theory of [[residue (complex analysis)|residue]]s among others is applicable (see [[methods of contour integration]]). A "pole" (or [[isolated singularity]]) of a function is a point where the function's value becomes unbounded, or "blows up". If a function has such a pole, then one can compute the function's residue there, which can be used to compute path integrals involving the function; this is the content of the powerful [[residue theorem]]. The remarkable behavior of holomorphic functions near essential singularities is described by [[Picard theorem#Big Picard|Picard's Theorem]]. Functions that have only poles but no [[Essential singularity|essential singularities]] are called [[meromorphic]]. [[Laurent series]] are the complex-valued equivalent to [[Taylor series]], but can be used to study the behavior of functions near singularities through infinite sums of more well understood functions, such as polynomials.

A [[bounded function]] that is holomorphic in the entire complex plane must be constant; this is [[Liouville's theorem (complex analysis)|Liouville's theorem]]. It can be used to provide a natural and short proof for the [[Fundamental Theorem of Algebra|fundamental theorem of algebra]] which states that the [[field (mathematics)|field]] of complex numbers is [[algebraically closed field|algebraically closed]].

If a function is holomorphic throughout a [[Connected space|connected]] domain then its values are fully determined by its values on any smaller subdomain.  The function on the larger domain is said to be [[analytic continuation|analytically continued]] from its values on the smaller domain.  This allows the extension of the definition of functions, such as the [[Riemann zeta function]], which are initially defined in terms of infinite sums that converge only on limited domains to almost the entire complex plane.  Sometimes, as in the case of the [[natural logarithm]], it is impossible to analytically continue a holomorphic function to a non-simply connected domain in the complex plane but it is possible to extend it to a holomorphic function on a closely related surface known as a [[Riemann surface]].

All this refers to complex analysis in one variable. There is also a very rich theory of [[several complex variables|complex analysis in more than one complex dimension]] in which the analytic properties such as [[power series]] expansion carry over whereas most of the geometric properties of holomorphic functions in one complex dimension (such as [[conformality]]) do not carry over. The [[Riemann mapping theorem]] about the conformal relationship of certain domains in the complex plane, which may be the most important result in the one-dimensional theory, fails dramatically in higher dimensions.

== See also ==
* [[Analytic continuation]]
* [[Complex dynamics]]
* [[List of complex analysis topics]]
* [[Monodromy theorem]]
* [[Real analysis]]
* [[Runge's theorem]]
* [[Several complex variables]]

== References ==
{{reflist}}
*  [[Lars Ahlfors|Ahlfors, L.]], ''Complex Analysis, 3 ed.'' (McGraw-Hill, 1979).
*  [[Stephen D. Fisher]], ''Complex Variables, 2 ed.'' (Dover, 1999).
*  [[Constantin Carathéodory|Carathéodory, C.]], ''Theory of Functions of a Complex Variable'' (Chelsea, New York). [2 volumes.]
*  [[Peter Henrici (mathematician)|Henrici, P.]], ''Applied and Computational Complex Analysis'' (Wiley).  [Three volumes: 1974, 1977, 1986.]
*  [[Erwin Kreyszig|Kreyszig, E.]], ''Advanced Engineering Mathematics, 10 ed.'', Ch.13-18 (Wiley, 2011).
*  Markushevich, A.I.,''Theory of Functions of a Complex Variable'' (Prentice-Hall, 1965). [Three volumes.]
*  [[Jerrold E. Marsden|Marsden]] &amp; Hoffman, ''Basic Complex Analysis. 3 ed.'' (Freeman, 1999).
*  [[Tristan Needham|Needham, T.]], ''Visual Complex Analysis'' (Oxford, 1997).
*  [[Walter Rudin|Rudin, W.]], ''Real and Complex Analysis, 3 ed.'' (McGraw-Hill, 1986).
*  Scheidemann, V., ''Introduction to complex analysis in several variables'' (Birkhauser, 2005)
*  Shaw, W.T., ''Complex Analysis with Mathematica'' (Cambridge, 2006).
*  [[Murray R. Spiegel|Spiegel, Murray R.]] ''Theory and Problems of Complex Variables - with an introduction to Conformal Mapping and its applications'' (McGraw-Hill, 1964).
*  [[Elias M. Stein|Stein]] &amp; Shakarchi, ''Complex Analysis'' (Princeton, 2003).
*  [[Mark J. Ablowitz|Ablowitz]] &amp; [[Athanassios S. Fokas|Fokas]], ''Complex Variables: Introduction and Applications'' (Cambridge, 2003).

== External links ==
{{Sister project links| wikt=complex analysis | commons=Category:Complex analysis | b=no | n=no | q=Complex analysis | s=no | v=no | voy=no | species=no | d=no}}
*[http://mathworld.wolfram.com/ComplexAnalysis.html Wolfram Research's MathWorld Complex Analysis Page]

{{DEFAULTSORT:Complex Analysis}}
[[Category:Complex analysis| ]]</text>
      <sha1>fstq4vuvulp31d19pwwjuo2hqo02tcv</sha1>
    </revision>
  </page>
  <page>
    <title>Condensation lemma</title>
    <ns>0</ns>
    <id>20506691</id>
    <revision>
      <id>856580169</id>
      <parentid>619088066</parentid>
      <timestamp>2018-08-26T06:41:54Z</timestamp>
      <contributor>
        <ip>2001:569:73C1:F100:D0E3:A6B7:2E0F:1122</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1260">In [[set theory]], a branch of mathematics, the '''condensation lemma''' is a result about sets in the
[[constructible universe]].

It states that if ''X'' is a [[transitive set]] and is an [[elementary submodel]] of some level of the constructible hierarchy L&lt;sub&gt;&amp;alpha;&lt;/sub&gt;, that is, &lt;math&gt;(X,\in)\prec (L_\alpha,\in)&lt;/math&gt;, then in fact there is some ordinal &lt;math&gt;\beta\leq\alpha&lt;/math&gt; such that &lt;math&gt;X=L_\beta&lt;/math&gt;.

More can be said: If ''X'' is not transitive, then its [[transitive collapse]] is equal to some &lt;math&gt;L_\beta&lt;/math&gt;, and the hypothesis of elementarity can be weakened to elementarity only for formulas which are &lt;math&gt;\Sigma_1&lt;/math&gt; in the [[Lévy hierarchy]].  Also, the assumption that ''X'' be transitive automatically holds when &lt;math&gt;\alpha=\omega_1&lt;/math&gt;.

The lemma was formulated and proved by [[Kurt Gödel]] in his proof that the [[axiom of constructibility]] implies [[Continuum hypothesis#The generalized continuum hypothesis|GCH]].

== References ==
*{{cite book
 | last=Devlin
 | first=Keith
 | authorlink=Keith Devlin
 | year = 1984
 | title = Constructibility
 | publisher = Springer
 | isbn = 3-540-13258-9
}} (theorem II.5.2 and lemma II.5.10)

[[Category:Set theory]]
[[Category:Lemmas]]


{{settheory-stub}}</text>
      <sha1>0jlgm2rsgfm8r40ef5wo98fivs2rii1</sha1>
    </revision>
  </page>
  <page>
    <title>Convex curve</title>
    <ns>0</ns>
    <id>29747989</id>
    <revision>
      <id>850231370</id>
      <parentid>756630623</parentid>
      <timestamp>2018-07-14T16:04:48Z</timestamp>
      <contributor>
        <ip>141.161.225.112</ip>
      </contributor>
      <comment>/* Definition by supporting lines */ to --&gt; into</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9100">{{Distinguish|Convex function}}
[[File:Convex polygon illustration1.svg|thumb|A convex curve is the boundary of a [[convex set]].]]
[[File:Parabola.svg|right|thumb|A [[parabola]], a simple example of a convex curve]]

In [[geometry]], a '''convex curve''' is a [[curve]] in the [[Euclidean plane]] which lies completely on one side of each and every one of its [[tangent line]]s.

The [[boundary (topology)|boundary]] of a [[convex set]] is always a convex curve.

==Definitions==

=== Definition by supporting lines ===
Any straight line ''L'' divides the Euclidean plane into two [[half-plane]]s whose union is the entire plane and whose intersection is ''L'' . We say that a curve ''C'' "lies on one side of ''L''" if it is entirely contained in one of the half-planes. A plane curve is called '''convex''' if it lies on one side of each of its tangent lines.&lt;ref name="Gray1998"&gt;{{cite book | last = Gray | first = Alfred | title = Modern differential geometry of curves and surfaces with Mathematica | publisher = CRC Press | location = Boca Raton | year = 1998 | isbn = 0849371643|page=163 | url = http://webmath2.unito.it/paginepersonali/sergio.console/CurveSuperfici/}}&lt;/ref&gt; In other words, a convex curve is a curve that has a [[supporting line]] through each of its points.

=== Definition by convex sets ===
A convex curve may be defined as the [[boundary (topology)|boundary]] of a [[convex set]] in the [[Euclidean plane]]. This definition is more restrictive than the definition in terms of tangent lines; in particular, with this definition, a convex curve can have no endpoints.&lt;ref name="Toponogov"&gt;{{citation|title=Differential Geometry of Curves and Surfaces: A Concise Guide|first=Victor Andreevich|last=Toponogov|publisher=Springer|year=2006|isbn=9780817643843|page=15|url=https://books.google.com/books?id=bwwRg7I02-4C&amp;pg=PA15}}.&lt;/ref&gt;

Sometimes, a looser definition is used, in which a convex curve is a curve that forms ''a subset'' of the boundary of a convex set. For this variation, a convex curve may have endpoints.

=== Strictly convex curve ===

A '''strictly convex curve''' is a convex curve that does not contain any [[line segment]]s. Equivalently, a strictly convex curve is a curve that  intersects any line in at most two points,&lt;ref&gt;{{citation|title=Spectral Theory of Random Matrices|first=Vyacheslav L.|last=Girko|publisher=Academic Press|year=1975|isbn=9780080873213|url=https://books.google.com/books?id=brRi5uZfgg4C&amp;pg=PA352|page=352}}.&lt;/ref&gt;&lt;ref name="baer"&gt;{{citation|title=Elementary Differential Geometry|first=Christian|last=Bär|publisher=Cambridge University Press|year=2010|isbn=9780521896719|page=49|url=https://books.google.com/books?id=By9XnQnc-5EC&amp;pg=PA49}}.&lt;/ref&gt; or a simple curve in [[convex position]], meaning that none of its points is a [[convex combination]] of any other subset of its points.

==Properties==
Every convex curve that is the boundary of a closed convex set has a well-defined finite [[length]]. That is, these curves are a subset of the [[rectifiable curve]]s.&lt;ref name="Toponogov"/&gt;

According to the [[four-vertex theorem]], every [[smooth curve|smooth]] convex curve that is the boundary of a closed convex set has at least four [[Vertex (curve)|vertices]], points that are local minima or local maxima of [[curvature]].&lt;ref name="baer"/&gt;&lt;ref&gt;{{citation
 | last1 = DeTruck | first1 = D.
 | last2 = Gluck | first2 = H.
 | last3 = Pomerleano | first3 = D.
 | last4 = Vick | first4 = D.S.
 | arxiv = math/0609268
 | bibcode = 2006math......9268D
 | issue = 2
 | journal = Notices of the American Mathematical Society
 | page = 9268
 | title = The four vertex theorem and its converse
 | url = http://www.ams.org/notices/200702/fea-gluck.pdf
 | volume = 54
 | year = 2007}}.&lt;/ref&gt;

=== Parallel tangents ===
A curve ''C'' is convex if and only if there are no three different points in ''C'' such that the tangents in these points are parallel.

'''Proof''':

'''⇒''' If there are three parallel tangents, then one of them, say ''L'', must be between the other two. This means that ''C'' lies on both sides of ''L'', so it cannot be convex.

'''⇐''' If ''C'' is not convex, then by definition there is point ''p'' on ''C'' such that the tangent line at ''p'' (call it ''L'') has ''C'' on both sides of it. Since ''C'' is closed, if we trace the part of ''C'' that lies on one side of ''L'' we eventually get at a point ''q1'' which is farthest from ''L''.&lt;ref name="Gray1998"/&gt; The tangent to ''C'' at ''q1'' (call it ''L1'') must be parallel to ''L''. The same is true in the other side of ''L'' - there is a point ''q2'' and a tangent ''L2'' which is parallel to ''L''. Thus there are three different points, {''p'',''q1'',''q2''}, such that their tangents are parallel.

=== Monotonicity of turning angle ===
A curve is called [[simple curve|simple]] if it does not intersect itself.  A closed regular plane simple curve ''C'' is convex ''if and only if'' its [[curvature]] is either always non-negative or always non-positive—i.e., if and only if the ''turning angle'' (the angle of the tangent to the curve) is a weakly monotone function of the parametrization of the curve.&lt;ref&gt;{{cite book | last = Gray | first = Alfred | title = Modern differential geometry of curves and surfaces with Mathematica | publisher = CRC Press | location = Boca Raton | year = 1998 | isbn = 0849371643|pages=163–165}}&lt;/ref&gt;

'''Proof''':

'''⇐''' If ''C'' is not convex, then by the [[#Parallel tangents|parallel tangents lemma]] there are three points {''p'',''q1'',''q2''} such that the tangents at these points are parallel. At least two must have their signed tangents pointing in the same direction. [[Without loss of generality]], assume that these points are ''q1'' and ''q2''. This means that the difference in the turning angle when going from ''q1'' to ''q2'' is a multiple of 2π. There are two possibilities:
* The difference in turning angle from ''q1'' to ''q2'' is 0. Then, if the turning angle would be a monotone function, it should be constant between ''q1'' and ''q2'', so that the curve between these two lines should be a straight line. But this would mean that the two tangent lines ''L1'' and ''L2'' are the same line—a contradiction.
* The difference in turning angle from ''q1'' to ''q2'' is a non-zero multiple of 2π. Because the curve is simple (does not intersect itself), the entire change in the turning angle around the curve must be ''exactly'' 2π.&lt;ref&gt;This is by a theorem by [[Heinz Hopf]]: the turning number of a simple closed plane curve is either +1 or -1.&lt;/ref&gt; This means that the difference in the turning angle from ''q2'' to ''q1'' must be 0, so by the same reasoning as before we get at a contradiction.
Thus we have proved that if ''C'' is not convex, the turning angle cannot be a monotone function.

'''⇒''' Assume that the turning angle is not monotone. Then we can find three points on the curve, ''s1''&lt;''s0''&lt;''s2'', such that the turning angle at ''s1'' and ''s2'' is the same and different than the turning angle at ''s0''. In a simple closed curve, all turning angles are covered. In particular, there is a point ''s3'' in which the turning angle is minus the turning angle at ''s1''. Now we have three points, {''s1'',''s2'',''s3''}, whose turning angle differs in a multiple of π. There are two possibilities:
* If the tangents at these three points are all distinct, then they are parallel, and by the [[#Parallel tangents|parallel tangents lemma]], ''C'' is not convex.
* Otherwise, there are two distinct points of ''C'', say ''p'' and ''q'', that lie on the same tangent line, ''L''. There are two sub-cases:
** If ''L'' is not contained in ''C'', then consider the line perpendicular to ''L'' at a certain point, ''r'', which is not a point of ''C''. This perpendicular line intersects ''C'' at two points, say ''r1'' and ''r2''. The tangent to ''C'' at ''r1'' has at least one of the points {''p'',''q'',''r2''} on each side, so ''C'' is not convex.
** If ''L'' is contained in ''C'', then the two points ''p'' and ''q'' have the same turning angle and so they must be ''s1'' and ''s2''. But this contradicts the assumption that there is a point ''s0'' between ''s1'' and ''s2'' with a different turning angle.
Thus we have proved that if the turning angle is not monotone, the curve cannot be convex.

==Related shapes==
[[Smooth curve|Smooth]] convex curves with an [[axis of symmetry]] may sometimes be called [[oval]]s.&lt;ref&gt;{{citation|title=The Words of Mathematics: An Etymological Dictionary of Mathematical Terms Used in English|series=MAA Spectrum|first=Steven|last=Schwartzman|publisher=Mathematical Association of America|year=1994|isbn=9780883855119|page=156}}.&lt;/ref&gt; However, in finite [[projective geometry]], [[Oval (projective plane)|ovals]] are instead defined as sets for which each point has a unique line disjoint from the rest of the set, a property that in Euclidean geometry is true of the smooth strictly convex closed curves.

== See also ==
* [[List of convexity topics]]

==References==
{{reflist}}

[[Category:Convex geometry]]</text>
      <sha1>qtgrgx3v0prm1mmnon93prr92ijly0g</sha1>
    </revision>
  </page>
  <page>
    <title>Dual number</title>
    <ns>0</ns>
    <id>42169</id>
    <revision>
      <id>862929831</id>
      <parentid>860244019</parentid>
      <timestamp>2018-10-07T17:00:46Z</timestamp>
      <contributor>
        <username>Tamchow</username>
        <id>16602907</id>
      </contributor>
      <comment>Added explanation for differentiation property</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14939">{{for|dual grammatical number found in some languages|Dual (grammatical number)}}

In [[linear algebra]], the '''dual numbers''' extend the [[real number]]s by adjoining one new element ε with the property ε&lt;sup&gt;2&lt;/sup&gt; = 0  (ε is [[nilpotent]]). The collection of dual numbers forms a particular two-[[Hamel dimension|dimensional]] [[commutative]] [[unital algebra|unital]] [[associative algebra]] over the real numbers. Every dual number has the form ''z'' = ''a'' + ''b''ε where ''a'' and ''b'' are uniquely determined real numbers. The dual numbers can also be thought of as the [[exterior algebra]] of a one-dimensional vector space; the general case of ''n'' dimensions leads to the [[Grassmann number]]s.

The [[algebra over a field|algebra]] of dual numbers is a [[ring (mathematics)|ring]] that is a [[local ring]] since the [[principal ideal]] generated by ε is its only [[maximal ideal]].
Dual numbers form the [[coefficient]]s of [[dual quaternion]]s.

==History==
Dual numbers were introduced in 1873 by [[William Kingdon Clifford|William Clifford]], and were used at the beginning of the twentieth century by the German mathematician [[Eduard Study]], who used them to represent the dual angle which measures the relative position of two skew lines in space. Study defined a dual angle as &lt;math&gt;\vartheta + d\varepsilon&lt;/math&gt;, where &lt;math&gt;\vartheta&lt;/math&gt; is the angle between the directions of two lines in three-dimensional space and &lt;math&gt;d&lt;/math&gt; is a distance between them. The ''n''-dimensional generalization, the [[Grassmann number]], was introduced by [[Hermann Grassmann]] in the late 19th century.

==Linear representation==
Using [[Matrix (mathematics)|matrices]], dual numbers can be represented as
:&lt;math&gt;\varepsilon=\begin{pmatrix}0 &amp; 1 \\0 &amp; 0 \end{pmatrix}\quad\text{and}\quad a + b\varepsilon = \begin{pmatrix}a &amp; b \\ 0 &amp; a \end{pmatrix}&lt;/math&gt;.

The sum and product of dual numbers are then calculated with ordinary [[matrix addition]] and [[matrix multiplication]]; both operations are commutative and associative within the algebra of dual numbers.

This correspondence is analogous to the usual [[Complex_number#Matrix_representation_of_complex_numbers|matrix representation of complex numbers]].
However, it is ''not'' the only representation with [[2 × 2 real matrices]], as is shown in the [[2 × 2 real matrices#Profile|profile of 2 × 2 real matrices]]. Like the [[complex plane]] and [[split-complex number]] plane, the dual numbers are one of the realizations of planar algebra.

==Geometry==
The "unit circle" of dual numbers consists of those with ''a'' = 1 or −1 since these satisfy  ''z z''* = 1  where ''z''* = ''a'' − ''b''ε. However, note that
:&lt;math&gt; \exp(b \varepsilon) = \left(\sum^\infty_{n=0} (b\varepsilon)^n / n!\right) = 1 + b \varepsilon &lt;/math&gt;,
so the [[exponential map (Lie theory)|exponential map]] applied to the ε-axis covers only half the "circle".

Let ''z'' = ''a'' + ''b'' ε. If ''a'' ≠ 0 and ''m'' = ''b'' /''a'', then ''z'' = ''a''(1 + ''m'' ε) is the [[polar decomposition#Alternative planar decompositions|polar decomposition]] of the dual number ''z'', and the [[slope]] ''m'' is its angular part.
The concept of a ''rotation'' in the dual number plane is equivalent to a vertical [[shear mapping]] since (1 + ''p'' ε)(1 + ''q'' ε) = 1 + (''p''+''q'') ε.

In [[absolute space and time]] the [[Galilean transformation]]
:&lt;math&gt;(t',x') = (t,x)\begin{pmatrix}1 &amp; v \\0 &amp; 1 \end{pmatrix} \ ,&lt;/math&gt; that is &lt;math&gt;\ \ t'=t,\ \  x' = vt + x , &lt;/math&gt;
relates the resting coordinates system to a moving frame of reference of [[velocity]] ''v''.
With dual numbers ''t'' + ''x'' ε representing [[event (relativity)|event]]s along one space dimension and time,
the same transformation is effected with multiplication by (1 + ''v'' ε).

===Cycles===
Given two dual numbers ''p'', and ''q'', they determine the set of ''z'' such that the difference in slopes ("Galilean angle") between the lines from ''z'' to ''p'' and ''q'' is constant. This set is a '''cycle''' in the dual number plane; since the equation setting the difference in slopes of the lines to a constant is a [[quadratic equation]] in the real part of ''z'', a cycle is a [[parabola]]. The "cyclic rotation" of the dual number plane occurs as a motion of the [[projective line over a ring|projective line over dual numbers]]. According to [[Isaak Yaglom#A simple non-euclidean geometry and its physical basis (1979)|Yaglom]] (pp.&amp;nbsp;92,3), the cycle Z = {z : y = α x&lt;sup&gt;2&lt;/sup&gt;} is invariant under the composition of the shear
:&lt;math&gt;x_1 = x ,\ \  y_1 = vx + y &lt;/math&gt; with the [[translation (geometry)|translation]]
:&lt;math&gt;x' = x_1 = v/2a  ,\ \  y' = y_1 + v^2/4a &lt;/math&gt;.
This composition is a '''cyclic rotation'''; the concept has been further developed by V. V. Kisil.&lt;ref&gt;V.V. Kisil (2007) "Inventing a Wheel, the Parabolic One" [https://arxiv.org/abs/0707.4024 arXiv:0707.4024]&lt;/ref&gt;

==Algebraic properties==
In [[abstract algebra]] terms, the dual numbers can be described as the [[quotient ring|quotient]] of the [[polynomial ring]] '''R'''[''X''] by the [[ideal (ring theory)|ideal]] generated by the [[polynomial]] ''X''&lt;sup&gt;2&lt;/sup&gt;,

:'''R'''[''X'']/(''X''&lt;sup&gt;2&lt;/sup&gt;).

The image of ''X'' in the quotient is the unit ε. With this description, it is clear that the dual numbers form a [[commutative ring]] with [[characteristic (algebra)|characteristic]] 0. The inherited multiplication gives the dual numbers the structure of a commutative and [[associative algebra]] over the reals of dimension two. The algebra is ''not'' a [[division algebra]] or [[field (mathematics)|field]] since the elements of the form {{nowrap|0 + ''b''ε}} are not invertible. All elements of this form are [[zero divisor]]s (also see the section "[[#Division|Division]]"). The algebra of dual numbers is isomorphic to the [[exterior algebra]] of &lt;math&gt;\mathbb{R}^1&lt;/math&gt;.

==Generalization==
This construction can be carried out more generally: for a [[commutative ring]] ''R'' one can define the dual numbers over ''R'' as the [[quotient ring|quotient]] of the [[polynomial ring]] ''R''[''X''] by the [[ideal (ring theory)|ideal]] (''X''&lt;sup&gt;2&lt;/sup&gt;): the image of ''X'' then has square equal to zero and corresponds to the element ε from above.

This ring and its generalisations play an important part in the algebraic theory of [[derivation (abstract algebra)|derivations]] and [[Kähler differential]]s (purely algebraic [[differential form]]s).

Over any ring ''R'', the dual number ''a'' + ''b''ε is a [[unit (ring theory)|unit]] (i.e. multiplicatively invertible) if and only if ''a'' is a unit in ''R''. In this case, the inverse of ''a'' + ''b''ε is ''a''&lt;sup&gt;−1&lt;/sup&gt; − ''ba''&lt;sup&gt;−2&lt;/sup&gt;ε. As a consequence, we see that the dual numbers over any [[field (mathematics)|field]] (or any commutative [[local ring]]) form a local ring, its maximal ideal being the [[principal ideal]] generated by ε.

A narrower generalization is that of introducing ''n'' anti-commuting generators; these are the [[Grassmann number]]s or ''supernumbers'', discussed below.

==Superspace==
Dual numbers find applications in [[physics]], where they constitute one of the simplest non-trivial examples of a [[superspace]]. Equivalently, they are [[Grassmann number|supernumbers]] with just one generator; supernumbers generalize the concept to {{math|''n''}} distinct generators ε, each anti-commuting, possibly taking {{math|''n''}} to infinity. Superspace generalizes supernumbers slightly, by allowing multiple commuting dimensions. 

The motivation for introducing dual numbers into physics follows from the [[Pauli exclusion principle]] for  fermions. The direction along ε is termed the "fermionic" direction, and the real component is termed the "bosonic" direction. The fermionic direction earns this name from the fact that [[fermion]]s obey the Pauli exclusion principle: under the exchange of coordinates, the quantum mechanical wave function changes sign, and thus vanishes if two coordinates are brought together; this physical idea is captured by the algebraic relation ε&lt;sup&gt;2&lt;/sup&gt; = 0.

==Differentiation==
One application of dual numbers is [[automatic differentiation]]. Consider the real dual numbers above. Given any real polynomial ''P''(''x'')&amp;nbsp;= ''p''&lt;sub&gt;0&lt;/sub&gt;+''p''&lt;sub&gt;1&lt;/sub&gt;''x''+''p''&lt;sub&gt;2&lt;/sub&gt;''x''&lt;sup&gt;2&lt;/sup&gt;+...+''p''&lt;sub&gt;''n''&lt;/sub&gt;''x''&lt;sup&gt;''n''&lt;/sup&gt;, it is straightforward to extend the domain of this polynomial from the reals to the dual numbers. Then we have this result:
:&lt;math&gt;
\begin{align}
P(a+b\varepsilon)=&amp;p_0 + p_1(a + b\varepsilon) + \ldots + p_n(a + b\varepsilon)^n\\
=&amp;p_0 + p_1 a + p_2 a^2 + \ldots + p_n a^n\\
&amp; + p_1 b\varepsilon + 2 p_2 a b\varepsilon + \ldots + n p_n a^{n-1} b\varepsilon\\
=&amp;P(a)+bP^\prime(a)\varepsilon,
\end{align}
&lt;/math&gt;

where &lt;math&gt;P^\prime&lt;/math&gt; is the derivative of &lt;math&gt;P&lt;/math&gt;.&lt;ref&gt;{{cite web|last=Berland|first=Håvard|title=Automatic differentiation|url=http://www.pvv.ntnu.no/~berland/resources/autodiff-triallecture.pdf|accessdate=13 May 2013}}&lt;/ref&gt;

By computing over the dual numbers, rather than over the reals, we can use this to compute derivatives of polynomials.

More generally, we can extend any (analytic) real function to the dual numbers by looking at its [[Taylor series]]: &lt;math&gt;f(a+b\varepsilon)=\sum_{n=0}^{\infty} {{f^{(n)} (a)b^n \varepsilon^n} \over {n!}}=f(a)+bf'(a)\varepsilon&lt;/math&gt;, since any terms of involving &lt;math&gt;\varepsilon^2&lt;/math&gt; or greater are trivially &lt;math&gt;0&lt;/math&gt; by the definition of &lt;math&gt;\varepsilon&lt;/math&gt;.&lt;br&gt;
By computing compositions of these functions over the dual numbers and examining the coefficient of ε in the result we find we have automatically computed the derivative of the composition.

A similar method works for polynomials of n variables, using the exterior algebra of an n-dimensional vector space.

==Division==
Division of dual numbers is defined when the real part of the denominator is non-zero. The division process is analogous to [[Complex number|complex division]] in that the denominator is multiplied by its conjugate in order to cancel the non-real parts.

Therefore, to divide an equation of the form:
:&lt;math&gt;{a+b\varepsilon \over c+d\varepsilon}&lt;/math&gt;
We multiply the top and bottom by the conjugate of the denominator:
:&lt;math&gt;= {(a+b\varepsilon)(c-d\varepsilon) \over (c+d\varepsilon)(c-d\varepsilon)}
= {ac-ad\varepsilon+bc\varepsilon-bd\varepsilon^2 \over (c^2+cd\varepsilon-cd\varepsilon-d^2\varepsilon^2)}
= {ac-ad\varepsilon+bc\varepsilon-0 \over c^2-0}&lt;/math&gt;
:&lt;math&gt;= {ac + \varepsilon(bc - ad) \over c^2}&lt;/math&gt;
:&lt;math&gt;= {a \over c} + {(bc - ad) \over c^2}\varepsilon&lt;/math&gt;
Which is defined [[Division by zero|when c is non-zero]].

If, on the other hand, c is zero while d is not, then the equation
:&lt;math&gt;{a+b\varepsilon = (x+y\varepsilon) d\varepsilon} = {xd\varepsilon + 0}&lt;/math&gt;
# has no solution if a is nonzero
# is otherwise solved by any dual number of the form
:&lt;math&gt;{b \over d} + {y\varepsilon}&lt;/math&gt;.
This means that the non-real part of the "quotient" is arbitrary and division is therefore not defined for purely nonreal dual numbers. Indeed, they are (trivially) [[zero divisors]] and clearly form an [[Ideal (ring theory)|ideal]] of the associative [[Algebra over a field|algebra]] (and thus [[Ring (mathematics)|ring]]) of the dual numbers.

==Projective line==
The idea of a projective line over dual numbers was advanced by Grünwald&lt;ref&gt;Josef Grünwald (1906) "Über duale Zahlen und ihre Anwendung in der Geometrie", ''Monatshefte für Mathematik'' 17: 81–136&lt;/ref&gt; and [[Corrado Segre]].&lt;ref&gt;[[Corrado Segre]] (1912) "Le geometrie proiettive nei campi di numeri duali", Paper XL of ''Opere'', also ''Atti della R. Academia della Scienze di Torino'', vol XLVII.&lt;/ref&gt;

Just as the [[Riemann sphere]] needs a north pole [[point at infinity]] to close up the [[complex projective line]], so a [[line at infinity]] succeeds in closing up the plane of dual numbers to a [[cylinder (geometry)|cylinder]]. &lt;ref&gt;I. M. Yaglom (1979) ''A Simple Non-Euclidean Geometry and its Physical Basis'', pp 149–53, Springer, {{ISBN|0387-90332-1}}, {{MathSciNet|id=520230}}&lt;/ref&gt;

Suppose D is the ring of dual numbers ''x'' + ''y'' &amp;epsilon; and U is the subset with ''x'' ≠ 0. Then U is the [[group of units]] of D. Let B = {(''a,b'') in D x D : ''a'' ∈ U or ''b'' ∈ U}. A [[relation (mathematics)|relation]]  is defined on B as follows: (''a,b'') ~ (''c,d'') when there is a ''u'' in U such that ''ua''=''c'' and ''ub''=''d''. This relation is in fact an [[equivalence relation]]. The points of the projective line over D are [[equivalence class]]es in B under this relation: P(D) = B/ ~.

Consider the [[embedding]] D → P(D) by ''z'' → U(''z'',1) where U(''z'',1) is the equivalence class of (''z'',1). Then points U(1,''n''), ''n''&lt;sup&gt;2&lt;/sup&gt; = 0, are in P(D) but are not the image of any point under the embedding. P(D) is projected onto a [[cylinder (geometry)|cylinder]] by  [[projection (mathematics)|projection]]: Take a cylinder tangent to the double number plane on the line {''y'' &amp;epsilon;: ''y'' ∈ ℝ}, &amp;epsilon;&lt;sup&gt;2&lt;/sup&gt; = 0. Now take the opposite line on the cylinder for the axis of a pencil of planes. The planes intersecting the dual number plane and cylinder provide a correspondence of points between these surfaces. The plane parallel to the dual number plane corresponds to points U(1,''n''), ''n''&lt;sup&gt;2&lt;/sup&gt; = 0 in the projective line over dual numbers.

==See also==

* [[Grassmann number]]
* [[Perturbation theory]]
* [[Smooth infinitesimal analysis]]
* [[Screw theory]]

==References==
{{Reflist}}
* Bencivenga, Ulderico (1946) "Sulla rappresentazione geometrica delle algebre doppie dotate di modulo", ''Atti della Reale Accademia delle Scienze e Belle-Lettere di Napoli'', Ser (3) v.2 No7. {{MathSciNet|id=0021123}}.
* [[William Kingdon Clifford]] (1873) ''Preliminary Sketch of Bi-quaternions'', [[Proceedings of the London Mathematical Society]] 4:381–95
* Anthony A. Harkin &amp; Joseph B. Harkin (2004) [http://people.rit.edu/harkin/research/articles/generalized_complex_numbers.pdf Geometry of Generalized Complex Numbers], [[Mathematics Magazine]] 77(2):118–29.
* William Miller &amp; Rochelle Boehning (1968) "Gaussian, Parabolic and Hyperbolic Numbers", [[The Mathematics Teacher]] 61(4): 377–82.
* [[Eduard Study]] (1903) [http://ebooks.library.cornell.edu/cgi/t/text/text-idx?c=math;cc=math;view=toc;subview=short;idno=03150002 Geometrie der Dynamen], page 196, from ''Cornell Historical Mathematical Monographs'' at [[Cornell University]].
* [[Isaak Yaglom]] (1968) ''Complex Numbers in Geometry'', pp 12&amp;ndash;18, [[Academic Press]].


{{Number systems}}
{{Infinitesimals}}

{{DEFAULTSORT:Dual Number}}
[[Category:Linear algebra]]
[[Category:Hypercomplex numbers]]
[[Category:Commutative algebra]]
[[Category:Differential algebra]]</text>
      <sha1>d0knjeo8ifzzsm5c1mz6odraqg8pe2l</sha1>
    </revision>
  </page>
  <page>
    <title>Extrapolation</title>
    <ns>0</ns>
    <id>546415</id>
    <revision>
      <id>862998711</id>
      <parentid>862998426</parentid>
      <timestamp>2018-10-08T01:48:59Z</timestamp>
      <contributor>
        <username>Nathan2055</username>
        <id>14860824</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/42.108.2.211|42.108.2.211]] ([[User talk:42.108.2.211|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11761">{{about||the journal of speculative fiction|Extrapolation (journal)|the John McLaughlin album|Extrapolation (album)}}

In [[mathematics]], '''extrapolation''' is the process of estimating, beyond the original observation range, the value of a variable on the basis of its relationship with another variable. It is similar to [[interpolation]], which produces estimates between known observations, but extrapolation is subject to greater [[uncertainty]] and a higher risk of producing meaningless results.  Extrapolation may also mean extension of a [[wikt:method|method]], assuming similar methods will be applicable. Extrapolation may also apply to human [[experience]] to project, extend, or expand known experience into an area not known or previously experienced so as to arrive at a (usually conjectural) knowledge of the unknown &lt;ref name="merrian-webster"&gt;[http://www.merriam-webster.com/dictionary/extrapolation Extrapolation], entry at [[Webster's Dictionary|Merriam–Webster]]&lt;/ref&gt; (e.g. a driver extrapolates road conditions beyond his sight while driving). The extrapolation method can be applied in the [[interior reconstruction]] problem.

[[Image:Extrapolation example.svg|thumb|right|Example illustration of the extrapolation problem, consisting of assigning a meaningful value at the blue box, at &lt;math&gt;x=7&lt;/math&gt;, given the red data points.]]

==Methods==

A sound choice of which extrapolation method to apply relies on ''a prior knowledge'' of the process that created the existing data points. Some experts have proposed the use of causal forces in the evaluation of extrapolation methods.&lt;ref&gt;{{cite journal|url=http://marketing.wharton.upenn.edu/ideas/pdf/armstrong2/causal.pdf | title = Causal Forces: Structuring Knowledge for Time-series Extrapolation |author1=J. Scott Armstrong |author2=Fred Collopy | journal = Journal of Forecasting | volume = 12 | pages = 103–115 | year = 1993 | doi=10.1002/for.3980120205}}&lt;/ref&gt; Crucial questions are, for example, if the data can be assumed to be continuous, smooth, possibly periodic etc.

===Linear===

Linear extrapolation means creating a tangent line at the end of the known data and extending it beyond that limit. Linear extrapolation will only provide good results when used to extend the graph of an approximately linear function or not too far beyond the known data.

If the two data points nearest the point &lt;math&gt;x_*&lt;/math&gt; to be extrapolated are &lt;math&gt;(x_{k-1},y_{k-1})&lt;/math&gt; and &lt;math&gt;(x_k, y_k)&lt;/math&gt;, linear extrapolation gives the function:

:&lt;math&gt;y(x_*) = y_{k-1} + \frac{x_* - x_{k-1}}{x_{k}-x_{k-1}}(y_{k} - y_{k-1}).&lt;/math&gt;

(which is identical to [[linear interpolation]] if &lt;math&gt;x_{k-1} &lt; x_* &lt; x_k&lt;/math&gt;). It is possible to include more than two points, and averaging the slope of the linear interpolant, by [[Regression analysis|regression]]-like techniques, on the data points chosen to be included. This is similar to [[linear prediction]].

===Polynomial===
[[File:Lagrange polynomials for continuations of sequence 1,2,3.gif|thumb|right|Lagrange extrapolations of the sequence 1,2,3. Extrapolating by 4 leads to a polynomial of minimal degree ({{color|#006060|cyan}} line).]]
A polynomial curve can be created through the entire known data or just near the end.  The resulting curve can then be extended beyond the end of the known data.  Polynomial extrapolation is typically done by means of  [[Lagrange interpolation]] or using Newton's method of [[finite differences]] to create a [[Newton series]] that fits the data. The resulting polynomial may be used to extrapolate the data.

High-order polynomial extrapolation must be used with due care. For the example data set and problem in the figure above, anything above order 1 (linear extrapolation) will possibly yield unusable values; an error estimate of the extrapolated value will grow with the degree of the polynomial extrapolation. This is related to [[Runge's phenomenon]].

===Conic===

A [[conic section]] can be created using five points near the end of the known data.  If the conic section created is an [[ellipse]] or [[circle]], when extrapolated it will loop back and rejoin itself.  An extrapolated [[parabola]] or [[hyperbola]] will not rejoin itself, but may curve back relative to the X-axis.  This type of extrapolation could be done with a conic sections template (on paper) or with a computer.

===French curve===

[[French curve]] extrapolation is a method suitable for any distribution that has a tendency to be exponential, but with accelerating or decelerating factors.&lt;ref&gt;[http://www.AIDSCJDUK.info AIDSCJDUK.info Main Index&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; This method has been used successfully in providing forecast projections of the growth of HIV/AIDS in the UK since 1987 and variant CJD in the UK for a number of years. Another study has shown that extrapolation can produce the same quality of forecasting results as more complex forecasting strategies.&lt;ref&gt;{{cite journal|url=http://marketing.wharton.upenn.edu/documents/research/Forecasting%20by%20extrapolation-25%20years.pdf | title = Forecasting by Extrapolation: Conclusions from Twenty-Five Years of Research | author = J. Scott Armstrong| journal = Interfaces | volume = 14 | pages = 52–66 | year = 1984 | doi=10.1287/inte.14.6.52}}&lt;/ref&gt;

==Quality==

Typically, the quality of a particular method of extrapolation is limited by the assumptions about the function made by the method.  If the method assumes the data are smooth, then a non-[[smooth function]] will be poorly extrapolated.

In terms of complex time series, some experts have discovered that extrapolation is more accurate when performed through the decomposition of causal forces.&lt;ref&gt;{{cite web|url= http://www.forecastingprinciples.com/paperpdf/Decomposition%20by%20Causal%20Forces.pdf | title = Decomposition by Causal Forces: A Procedure for Forecasting Complex Time Series |author1=J. Scott Armstrong |author2=Fred Collopy |author3=J. Thomas Yokum | year = 2004}}&lt;/ref&gt;

Even for proper assumptions about the function, the extrapolation can diverge severely from the function.  The classic example is truncated [[power series]] representations of sin(''x'') and related [[trigonometric function]]s.  For instance, taking only data from near the ''x''&amp;nbsp;=&amp;nbsp;0, we may estimate that the function behaves as sin(''x'')&amp;nbsp;~&amp;nbsp;''x''.  In the neighborhood of ''x''&amp;nbsp;=&amp;nbsp;0, this is an excellent estimate.  Away from ''x''&amp;nbsp;=&amp;nbsp;0 however, the extrapolation moves arbitrarily away from the ''x''-axis while sin(''x'') remains in the [[interval (mathematics)|interval]] [&amp;minus;1,{{nbsp}}1].  I.e., the error increases without bound.

Taking more terms in the power series of sin(''x'') around ''x''&amp;nbsp;=&amp;nbsp;0 will produce better agreement over a larger interval near ''x''&amp;nbsp;=&amp;nbsp;0, but will produce extrapolations that eventually diverge away from the ''x''-axis even faster than the linear approximation.

This divergence is a specific property of extrapolation methods and is only circumvented when the functional forms assumed by the extrapolation method (inadvertently or intentionally due to additional information) accurately represent the nature of the function being extrapolated.  For particular problems, this additional information may be available, but in the general case, it is impossible to satisfy all possible function behaviors with a workably small set of potential behavior.

==In the complex plane==

In [[complex analysis]], a problem of extrapolation may be converted into an [[interpolation]] problem by the change of variable &lt;math&gt;\hat{z} = 1/z&lt;/math&gt;.  This transform exchanges the part of the [[complex plane]] inside the [[unit circle]] with the part of the complex plane outside of the unit circle.  In particular, the [[compactification (mathematics)|compactification]] [[point at infinity]] is mapped to the origin and vice versa.  Care must be taken with this transform however, since the original function may have had "features", for example [[pole (complex analysis)|poles]] and other [[mathematical singularity|singularities]], at infinity that were not evident from the sampled data.

Another problem of extrapolation is loosely related to the problem of [[analytic continuation]], where (typically) a [[power series]] representation of a [[function (mathematics)|function]] is expanded at one of its points of [[limit of a function|convergence]] to produce a [[power series]] with a larger [[radius of convergence]].  In effect, a set of data from a small region is used to extrapolate a function onto a larger region.

Again, [[analytic continuation]] can be thwarted by [[function (mathematics)|function]] features that were not evident from the initial data.

Also, one may use   [[sequence transformation]]s like [[Padé approximant]]s and [[Levin-type sequence transformation]]s as extrapolation methods that lead to a [[summation]] of  [[power series]] that are divergent outside the original [[radius of convergence]]. In this case, one often obtains 
[[rational approximant]]s.

==Fast==
The extrapolated data often convolute to a kernel function. After data is extrapolated, the size of data is increased N times, here N is approximately 2–3. If this data needs to be convoluted to a known kernel function, the numerical calculations will increase N{{nbsp}}log(N) times even with fast Fourier transform (FFT). There exists an algorithm, it analytically calculates the contribution from the part of the extrapolated data. The calculation time can be omitted compared with the original convolution calculation. Hence with this algorithm the calculations of a convolution using the extrapolated data is nearly not increased. This is referred as the fast extrapolation. The fast extrapolation has been applied to CT image reconstruction.&lt;ref&gt;
{{cite web
 | url = http://imrecons.com/wp-content/uploads/2013/02/extrapolation.pdf
 | title = Reconstruction from truncated projections using mixed extrapolations of exponential and quadratic functions.
 | author1 = Shuangren Zhao
 | author2 = Kang Yang
 | author3 = Xintie Yang
 | journal = J Xray Sci Technol.
 | volume = 19 | issue = 2 | pages = 155–72 | year = 2011
}}&lt;/ref&gt;

==Extrapolation arguments==
{{split section|date=April 2018}}
Extrapolation arguments are informal and unquantified arguments which assert that something is true beyond the range of values for which it is known to be true. For example, we believe in the reality of what we see through magnifying glasses because it agrees with what we see with the naked eye but extends beyond it; we believe in what we see through light microscopes because it agrees with what we see through magnifying glasses but extends beyond it; and similarly for electron microscopes.

Like [[slippery slope]] arguments, extrapolation arguments may be strong or weak depending on such factors as how far the extrapolation goes beyond the known range.&lt;ref&gt;J. Franklin, [http://ojs.uwindsor.ca/ojs/leddy/index.php/informal_logic/article/view/3610/3000 Arguments whose strength depends on continuous variation], ''Journal of Informal Logic'' 33 (2013), 33-56.&lt;/ref&gt;

==See also==
{{Wiktionary|extrapolation}}
{{Commons category|Extrapolation}}
*[[Forecasting]]
*[[Minimum polynomial extrapolation]]
*[[Multigrid method]]
*[[Prediction interval]]
*[[Regression analysis]]
*[[Richardson extrapolation]]
*[[Static analysis]]
*[[Trend estimation]]
*[[Extrapolation domain analysis]]
*[[Dead reckoning]]
*[[Interior reconstruction]]
*[[Extreme value theory]]

==Notes==
{{reflist}}

==References==
*''Extrapolation Methods. Theory and Practice'' by C. Brezinski and M. Redivo Zaglia, North-Holland, 1991.

[[Category:Interpolation]]
[[Category:Asymptotic analysis]]</text>
      <sha1>t5j89x4j6a6kkytaijx9wyht1lnytye</sha1>
    </revision>
  </page>
  <page>
    <title>Formal holomorphic function</title>
    <ns>0</ns>
    <id>52590134</id>
    <revision>
      <id>755448405</id>
      <parentid>755022490</parentid>
      <timestamp>2016-12-18T02:23:20Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1533">In algebraic geometry, a '''formal holomorphic function''' along a subvariety ''V'' of an algebraic variety ''W'' is an algebraic analog of a [[holomorphic function]] defined in a neighborhood of ''V''. They are sometimes just called holomorphic functions when no confusion can arise. They were introduced by {{harvs|txt|first=Oscar |last=Zariski|authorlink=Oscar Zariski|year1=1949|year2=1951}}.

The theory of formal holomorphic functions has largely been replaced by the theory of [[formal scheme]]s which generalizes it: a formal holomorphic function on a variety is essentially just a section of the structure sheaf of a related formal scheme.

==Definition==

If ''V'' is an affine subvariety of the affine variety ''W'' defined by an ideal ''I'' of the coordinate ring ''R'' of ''W'', then a formal holomorphic function along ''V'' is just an element of the completion of ''R'' at the ideal ''I''. 

In general holomorphic functions along a subvariety ''V'' of ''W'' are defined by gluing together holomorphic functions on affine subvarieties. 

==References==

*{{citation|mr=0041488 
|last=Zariski|first= Oscar
|title=A fundamental lemma from the theory of holomorphic functions on an algebraic variety 
|journal=Ann. Mat. Pura Appl. (4)|volume= 29|year=1949|pages=187–198}} 
*{{citation|mr=0041487 
|last=Zariski|first= Oscar
|title=Theory and applications of holomorphic functions on algebraic varieties over arbitrary ground fields 
|series=Mem. Amer. Math. Soc.|volume= 5 |year=1951}}
 
[[Category:Algebraic geometry]]</text>
      <sha1>6teehjwwzkr001dg883u2tleibjdtby</sha1>
    </revision>
  </page>
  <page>
    <title>Gertrude Mary Cox</title>
    <ns>0</ns>
    <id>2168672</id>
    <revision>
      <id>861600753</id>
      <parentid>858652695</parentid>
      <timestamp>2018-09-28T16:30:01Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Rescued 1 archive link; remove 1 link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9438">{{Infobox scientist
| honorific_prefix  = 
| name              = Gertrude Mary Cox
| honorific_suffix  = 
| native_name       = 
| native_name_lang  = 
| image             = Gertrude Mary Cox.jpg
| image_size        = 
| image_upright     = 
| alt               = 
| caption           = 
| birth_name        = &lt;!-- if different from "name" --&gt;
| birth_date        = {{Birth date|1900|1|13}}
| birth_place       = [[Dayton, Iowa]]
| death_date        = {{Death date and age|1978|10|17|1900|1|13}}
| death_place       = [[Durham, North Carolina]]
| death_cause       = 
| resting_place     = 
| resting_place_coordinates = &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names       = 
| pronounce         =
| residence         = 
| citizenship       = 
| nationality       = 
| fields            = [[Statistics]], [[Mathematics]]
| workplaces        = Professor of Statistics, [[North Carolina State University]]; Director of Statistics, [[Research Triangle Institute]]
| patrons           = 
| education         = B.S. in Mathematics, 1929; Masters in statistics, 1931
| alma_mater        = [[Iowa State College]], [[University of California at Berkeley]]
| thesis_title      = &lt;!--(or  | thesis1_title =  and  | thesis2_title = )--&gt;
| thesis_url        = &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year       = &lt;!--(or  | thesis1_year =   and  | thesis2_year =  )--&gt;
| doctoral_advisor  = &lt;!--(or  | doctoral_advisors = )--&gt;
| academic_advisors = 
| doctoral_students = 
| notable_students  = 
| known_for         = First female elected into the [[International Statistical Institute]]; [[president of the American Statistical Association]]; experimental statistics.
| influences        = 
| influenced        = 
| awards            = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse            = &lt;!--(or | spouses = )--&gt;
| partner           = &lt;!--(or | partners = )--&gt;
| children          = 
| signature         = &lt;!--(filename only)--&gt;
| signature_alt     = 
| website           = &lt;!--{{URL|www.example.com}}--&gt;

&lt;!-- notable works = ''Experimental Designs'', with [[William Gemmell Cochran]]&lt;ref name="CochranCox1950"/&gt; --&gt;
}}
'''Gertrude Mary Cox''' (January 13, 1900 – October 17, 1978) was an [[United States|American]] [[statistics|statistician]] and founder of the department of Experimental Statistics at [[North Carolina State University]]. She was later appointed director of both the Institute of Statistics of the [[University of North Carolina|Consolidated University of North Carolina]] and the Statistics Research Division of North Carolina State University.  Her most important and influential research dealt with [[experimental design]]; she wrote an important book on the subject with [[William Gemmell Cochran|W. G. Cochran]]. In 1949 Cox became the first female elected into the [[International Statistical Institute]] and in 1956 was [[President of the American Statistical Association]].

==Early life and education==
Gertrude Cox was born in [[Dayton, Iowa]] on January 13, 1900.&lt;ref name=Anderson1990&gt;{{Citation
 |publisher=National Academies Press 
 |last=Anderson 
 |first=Richard L 
 |title=Gertrude Mary Cox, 1900-1978: A Biographical Memoir 
 |accessdate=2018-04-25 
 |year=1990 
 |url=http://www.nasonline.org/publications/biographical-memoirs/memoir-pdfs/cox-gertrude.pdf
|archive-url=https://web.archive.org/web/20150326021456/http://www.nasonline.org/publications/biographical-memoirs/memoir-pdfs/cox-gertrude.pdf
|dead-url=yes
|archive-date=2015-03-26
}}&lt;/ref&gt;  She studied at [[Perry High School (Iowa)|Perry High School]] in [[Perry, Iowa]], graduating in 1918. At this time she decided to become a deaconess in the [[Methodist Church]] and worked towards that end.&lt;ref name=Riddle2014&gt;{{Citation
| publisher = Agnes Scott College
| last = Riddle
| first = Larry
| title = Biographies of Women Mathematicians: Gertrude Mary Cox
| accessdate = 2018-04-25
| year = 2014
| url = http://www.agnesscott.edu/lriddle/women/cox.htm
}}&lt;/ref&gt; However, in 1925, she decided to continue her education at [[Iowa State College]] in Ames where she studied mathematics and statistics and was awarded a B.S. in 1929 and a Master's degree in statistics in 1931.&lt;ref name="Riddle2014"/&gt;

From 1931 to 1933 Cox undertook graduate studies in psychological statistics at the [[University of California at Berkeley]], then returned to Iowa State College to assist in establishing the new Statistical Laboratory&lt;ref name="wayne2011"&gt;{{cite book|last1=Wayne|first1=Tiffany K.|title=American women of science since 1900|date=2011|publisher=ABC-CLIO|location=Santa Barbara, Calif.|isbn=9781598841589|pages=324-325}}&lt;/ref&gt;. Here she worked on the [[design of experiments]].

==Academic career==
In 1939 Cox was appointed assistant professor of statistics at [[Iowa State College]].&lt;ref name=Bailey1994&gt;{{cite book|last1=Bailey|first1=Martha J.|title=American Women in Science|date=1994|publisher=ABC-CLIO|location=Santa Barbara|isbn=0-87436-740-9|page=72}}&lt;/ref&gt;
In 1940 Cox was appointed professor of statistics at North Carolina State College (now [[North Carolina State University]]) at Raleigh. There she headed the new department of Experimental Statistics, the first female head of any department at this institution.&lt;ref name="wayne2011" /&gt; In 1945 she became director of the Institute of Statistics of the [[University of North Carolina|Consolidated University of North Carolina]], and the Statistics Research Division of the North Carolina State College which was run by [[William Gemmell Cochran]].  In the same year of 1945 Cox became the editor of ''Biometrics Bulletin'' and of ''[[Biometrics (journal)|Biometrics]]'' and she held this editorship for 10 years. In 1947 she was a founder member of the [[International Biometric Society]].&lt;ref name="Bailey1994"/&gt;

In 1960 she took up her final post as Director of Statistics at the [[Research Triangle Institute]] in Durham, North Carolina. She held this post until she retired in 1965.&lt;ref name="Bailey1994"/&gt; After retirement, then worked as a consultant to promote the development of statistical programs in Egypt and Thailand. &lt;ref name="Riddle2014" /&gt;&lt;ref&gt;{{cite web|title=Cox biography|url=http://www-groups.dcs.st-and.ac.uk/history/Biographies/Cox.html|website=www-groups.dcs.st-and.ac.uk|publisher=University of St Andrews, Scotland|accessdate=26 April 2018}}&lt;/ref&gt;

==Book==
In 1950 she published a joint work with William Cochran, ''Experimental Design'',&lt;ref name=CochranCox1950&gt;{{cite book|last1=Cochran|first1=William G.|last2=Cox|first2=Gertrude M.|title=Experimental Designs|date=1950|publisher=Wiley|location=New York}}&lt;/ref&gt; which became the major reference work on the [[design of experiments]] for statisticians for years afterwards.

==Recognition==
Cox received many honors. In 1949 she became the first woman elected into the [[International Statistical Institute]]. In 1956 she was elected President of the [[American Statistical Association]] while in 1975 she was elected to the [[United States National Academy of Sciences|National Academy of Sciences]].
She was also a Fellow of the [[Institute of Mathematical Statistics]].&lt;ref&gt;{{citation|url=http://www.imstat.org/awards/honored_fellows.htm|title=Honored Fellows|publisher=Institute of Mathematical Statistics|accessdate=2017-11-24|archive-url=https://web.archive.org/web/20140302125855/http://www.imstat.org/awards/honored_fellows.htm|archive-date=2014-03-02|dead-url=yes|df=}}&lt;/ref&gt; 

The [[University of North Carolina|University of North Carolina system]] named her an O. Max Gardner Award recipient in 1959. [[North Carolina State University]] honored Cox by naming Cox Hall in her honor in 1970, and awarding her a Watauga Medal in 1977. The Caucus of Women in Statistics also established a Gertrude M. Cox Scholarship fund in recognition of her work in 1986. &lt;ref name="wayne2011" /&gt;

==References==
{{Reflist}}

==External links==
*[http://www.lib.ncsu.edu/findingaids/mc00117 Gertrude Mary Cox Collection, 1918-1983] (North Carolina State University Libraries)
*[http://www.agnesscott.edu/lriddle/women/cox.htm "Gertrude Cox", Biographies of Women Mathematicians], [[Agnes Scott College]]
*[http://www-groups.dcs.st-and.ac.uk/~history/Mathematicians/Cox.html MacTutor biography]
*[http://www.amstat.org/about/statisticiansinhistory/index.cfm?fuseaction=biosinfo&amp;BioID=2 ASA: Gertrude M. Cox]
*[http://www.ncsu.edu/gertrudecox NC State University Gertrude Cox Award]

{{PlanetMath attribution|id=8946|title=Gertrude Cox}}

{{Authority control}}

{{DEFAULTSORT:Cox, Gertrude Mary}}
[[Category:1900 births]]
[[Category:1978 deaths]]
[[Category:American statisticians]]
[[Category:20th-century American mathematicians]]
[[Category:Women mathematicians]]
[[Category:Women statisticians]]
[[Category:American women scientists]]
[[Category:20th-century women scientists]]
[[Category:Fellows of the American Statistical Association]]
[[Category:Fellows of the Institute of Mathematical Statistics]]
[[Category:Presidents of the American Statistical Association]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Iowa State University alumni]]
[[Category:People from Webster County, Iowa]]
[[Category:People from Raleigh, North Carolina]]
[[Category:People from Perry, Iowa]]
[[Category:Elected Members of the International Statistical Institute]]
[[Category:University of California, Berkeley alumni]]</text>
      <sha1>sqezcj1t4kttmazdwt9va23wfddjuj2</sha1>
    </revision>
  </page>
  <page>
    <title>Glivenko's theorem (probability theory)</title>
    <ns>0</ns>
    <id>51376302</id>
    <revision>
      <id>753896916</id>
      <parentid>752428992</parentid>
      <timestamp>2016-12-09T19:42:18Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>added [[Category:Probability theorems]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="757">{{one source|date=December 2016}}

In [[probability theory]], '''Glivenko's theorem''' states that if &lt;math&gt;\varphi_n, n\in \mathbb N&lt;/math&gt;, &lt;math&gt;\varphi&lt;/math&gt; are the characteristic functions of some [[probability distribution]]s &lt;math&gt;\mu_n, \mu&lt;/math&gt; respectively and &lt;math&gt;\varphi_n \to \varphi&lt;/math&gt; almost everywhere, then &lt;math&gt;\mu_n \to \mu&lt;/math&gt; in the sense of probability distributions.&lt;ref name ="ito" /&gt;

== References ==
&lt;references&gt;
&lt;ref name="ito"&gt;{{cite book |last=Itô |first=Kiyoshi |year=1984 |title=Introduction to Probability Theory |publisher=Cambridge University Press |page=87 |isbn=0 521 26960 1}}&lt;/ref&gt;
&lt;/references&gt;


[[Category:Theory of probability distributions]]
[[Category:Probability theorems]]


{{mathematics-stub}}</text>
      <sha1>h4mave8w6t862aqqv9nz4sy341i7nzz</sha1>
    </revision>
  </page>
  <page>
    <title>Gromov product</title>
    <ns>0</ns>
    <id>12942590</id>
    <revision>
      <id>862709237</id>
      <parentid>854801516</parentid>
      <timestamp>2018-10-06T05:19:32Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5105">
In [[mathematics]], the '''Gromov product''' is a concept in the theory of [[metric space]]s named after the  mathematician [[Mikhail Gromov (mathematician)|Mikhail Gromov]]. The Gromov product can also be used to define [[δ-hyperbolic space|''&amp;delta;''-hyperbolic metric spaces]] in the sense of Gromov.

==Definition==

Let (''X'',&amp;nbsp;''d'') be a metric space and let ''x'', ''y'', ''z''&amp;nbsp;∈&amp;nbsp;''X''. Then the '''Gromov product''' of ''y'' and ''z'' at ''x'', denoted (''y'',&amp;nbsp;''z'')&lt;sub&gt;''x''&lt;/sub&gt;, is defined by

:&lt;math&gt;(y, z)_{x} = \frac1{2} \big( d(x, y) + d(x, z) - d(y, z) \big).&lt;/math&gt;

==Motivation==
[[File:Inkreis mit Strecken.svg|right|250px]]
Given three points ''x'', ''y'', ''z'' in the metric space ''X'', by the triangle inequality there exist non-negative numbers ''a'', ''b'', ''c'' such that &lt;math&gt;d(x,y) = a + b, \ d(x,z) = a + c, \ d(y,z) =  b + c&lt;/math&gt;. Then the Gromov products are &lt;math&gt;(y,z)_x = a, \ (x,z)_y = b, \ (x,y)_z = c&lt;/math&gt;. In the case that the points ''x'', ''y'', ''z'' are the outer nodes of a [[Tripod (mathematics)|tripod]] then these Gromov products are the lengths of the edges.

In the hyperbolic, spherical or euclidean plane, the Gromov product (''A'',&amp;nbsp;''B'')&lt;sub&gt;''C''&lt;/sub&gt; equals the distance ''p'' between ''C'' and the point where the [[incircle]] of the geodesic triangle ''ABC'' touches the edge ''CB''  or ''CA''. Indeed from the diagram {{math|1= ''c'' = (''a'' – ''p'') + (''b'' – ''p'')}}, so that {{math|1=''p'' = (''a'' + ''b'' – ''c'')/2 = (''A'',''B'')&lt;sub&gt;''C''&lt;/sub&gt;}}. Thus for any metric space, a geometric interpretation of (''A'',&amp;nbsp;''B'')&lt;sub&gt;''C''&lt;/sub&gt; is obtained by isometrically embedding (A, B, C) into the euclidean plane&lt;ref&gt;{{Cite journal|date=2005-09-15|title=Gromov hyperbolic spaces|url=https://www.sciencedirect.com/science/article/pii/S0723086905000113|journal=Expositiones Mathematicae|language=en|volume=23|issue=3|pages=187–231|doi=10.1016/j.exmath.2005.01.010|issn=0723-0869}}&lt;/ref&gt;.

==Properties==

* The Gromov product is symmetric: (''y'',&amp;nbsp;''z'')&lt;sub&gt;''x''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;(''z'',&amp;nbsp;''y'')&lt;sub&gt;''x''&lt;/sub&gt;.
* The Gromov product degenerates at the endpoints: (''y'',&amp;nbsp;''z'')&lt;sub&gt;''y''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;(''y'',&amp;nbsp;''z'')&lt;sub&gt;''z''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0.
* For any points ''p'', ''q'', ''x'', ''y'' and ''z'',

::&lt;math&gt;d(x, y) = (x, z)_{y} + (y, z)_{x},&lt;/math&gt;
::&lt;math&gt;0 \leq (y, z)_{x} \leq \min \big\{ d(y, x), d(z, x) \big\},&lt;/math&gt;
::&lt;math&gt;\big| (y, z)_{p} - (y, z)_{q} \big| \leq d(p, q),&lt;/math&gt;
::&lt;math&gt;\big| (x, y)_{p} - (x, z)_{p} \big| \leq d(y, z).&lt;/math&gt;

==Points at infinity==

Consider [[hyperbolic space]] '''H'''&lt;sup&gt;''n''&lt;/sup&gt;. Fix a base point ''p'' and let &lt;math&gt;x_\infty&lt;/math&gt; and &lt;math&gt;y_\infty&lt;/math&gt; be two distinct points at infinity. Then the limit 
::&lt;math&gt;\liminf_{x \to x_\infty \atop y \to y_\infty} (x,y)_p&lt;/math&gt;
exists and is finite, and therefore can be considered as a generalized Gromov product. It is actually given by the formula 
::&lt;math&gt;(x_\infty, y_\infty)_{p} = \log \csc (\theta/2),&lt;/math&gt; 
where &lt;math&gt;\theta&lt;/math&gt; is the angle between the [[geodesic]] rays &lt;math&gt;px_\infty&lt;/math&gt; and &lt;math&gt;py_\infty&lt;/math&gt;.&lt;ref&gt;{{cite book|last1=Roe|first1=John|title=Lectures on coarse geometry|date=2003|publisher=American Mathematical Society|location=Providence|isbn=0-8218-3332-4|page=114}}&lt;/ref&gt;

==δ-hyperbolic spaces and divergence of geodesics==

The Gromov product can be used to define [[δ-hyperbolic space|''&amp;delta;''-hyperbolic spaces]] in the sense of Gromov.: (''X'',&amp;nbsp;''d'') is said to be '''''δ''-hyperbolic''' if, for all ''p'', ''x'', ''y'' and ''z'' in ''X'',

::&lt;math&gt;(x, z)_{p} \geq \min \big\{ (x, y)_{p}, (y, z)_{p} \big\} - \delta.&lt;/math&gt;

In this case. Gromov product measures how long geodesics remain close together. Namely, if ''x'', ''y'' and ''z'' are three points of a ''δ''-hyperbolic metric space then the initial segments of length (''y'',&amp;nbsp;''z'')&lt;sub&gt;''x''&lt;/sub&gt; of geodesics from ''x'' to ''y'' and ''x'' to ''z'' are no further than 2''δ'' apart (in the sense of the [[Hausdorff distance]] between closed sets).

==Notes==
{{reflist}}
==References==
*{{citation|language=fr|last1=Coornaert|first=M.|last2=Delzant|first2=T.|last3= Papadopoulos|first3= A.|title=Géométrie et théorie des groupes. Les groupes hyperboliques de Gromov|series=Lecture Notes in Mathematics|volume= 1441|publisher=Springer-Verlag|year= 1990|isbn=3-540-52977-2}}
* {{cite book
| last = Kapovich
| first = Ilya
|author2=Benakli, Nadia
| chapter = Boundaries of hyperbolic groups
| title = Combinatorial and geometric group theory (New York, 2000/Hoboken, NJ, 2001)
| series = Contemp. Math. 296
| pages = 39&amp;ndash;93
| publisher = Amer. Math. Soc.
| location = Providence, RI
| year = 2002
|mr=1921706
}}
* {{cite web|last=Väisälä|first=Jussi|title=Gromov hyperbolic spaces|url=https://www.sciencedirect.com/science/article/pii/S0723086905000113|format=PDF|date=|year=2005|website=|archive-url=|archive-date=|dead-url=|accessdate=2018-08-10}}

[[Category:Metric geometry]]
[[Category:Δ-hyperbolic space]]</text>
      <sha1>9khp7kbze9o2oawhw9j19hzlzcdj5be</sha1>
    </revision>
  </page>
  <page>
    <title>Group-stack</title>
    <ns>0</ns>
    <id>54651193</id>
    <revision>
      <id>841663219</id>
      <parentid>841652916</parentid>
      <timestamp>2018-05-17T06:56:27Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <comment>no longer orphans</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2186">In algebraic geometry, a '''group-stack''' is an [[algebraic stack]] whose categories of points have group structures or even [[groupoid]] structures in a compatible way.&lt;ref&gt;https://mathoverflow.net/questions/231313/are-picard-stacks-group-objects-in-the-category-of-algebraic-stacks&lt;/ref&gt; It generalizes a [[group scheme]], which is a scheme whose sets of points have group structures in a compatible way.

== Examples ==
*A group scheme is a group-stack. More generally, a '''group algebraic-space''', an algebraic-space analog of a group scheme, is a group-stack.
*Over a field ''k'', a '''vector bundle stack''' &lt;math&gt;\mathcal{V}&lt;/math&gt; on a Deligne–Mumford stack ''X'' is a group-stack such that there is a vector bundle ''V'' over ''k'' on ''X'' and a presentation &lt;math&gt;V \to \mathcal{V}&lt;/math&gt;. It has an action by the affine line &lt;math&gt;\mathbb{A}^1&lt;/math&gt; corresponding to scalar multiplication.
*A [[Picard stack]] is an example of a group-stack (or groupoid-stack).

== Actions of group-stacks ==
The definition of a [[group action]] of a group-stack is a bit tricky. First, given an algebraic stack ''X'' and a group scheme ''G'' on a base scheme ''S'', a right action of ''G'' on ''X'' consists of
# a [[morphism of algebraic stacks|morphism]] &lt;math&gt;\sigma: X \times G \to X&lt;/math&gt;,
# (associativity) a natural isomorphism &lt;math&gt;\sigma \circ (m \times 1_X) \overset{\sim}\to \sigma \circ (1_X \times \sigma)&lt;/math&gt;, where ''m'' is the multiplication on ''G'',
# (identity) a natural isomorphism &lt;math&gt;1_X \overset{\sim}\to \sigma \circ (1_X \times e)&lt;/math&gt;, where &lt;math&gt;e: S \to G&lt;/math&gt; is the identity section of ''G'',
that satisfy the typical compatibility conditions.

If, more generally, ''G'' is a group-stack, one then extends the above using local presentations.

== Notes ==
{{reflist}}

== References ==
*{{Cite journal|last=Behrend|first=K.|last2=Fantechi|first2=B.|date=1997-03-01|title=The intrinsic normal cone|url=https://link.springer.com/article/10.1007/s002220050136|journal=Inventiones mathematicae|language=en|volume=128|issue=1|pages=45–88|doi=10.1007/s002220050136|issn=0020-9910}}

[[Category:Algebraic geometry]]


{{algebraic-geometry-stub}}</text>
      <sha1>hfbrre0vftur94olvjcah5xcz8cjkk1</sha1>
    </revision>
  </page>
  <page>
    <title>Henry Martyn</title>
    <ns>0</ns>
    <id>250835</id>
    <revision>
      <id>857247059</id>
      <parentid>847178806</parentid>
      <timestamp>2018-08-30T14:02:47Z</timestamp>
      <contributor>
        <username>Frietjes</username>
        <id>13791031</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15141">{{About|the Anglican missionary|the English cricketer|Henry Martyn (cricketer)|other people of a similar name|Henry Martin (disambiguation)}}
{{Use dmy dates|date=May 2012}}
{{Use British English|date=May 2012}}

{{Infobox saint
|name= Henry Martyn
| birth_date  = {{Birth date|1781|2|18|df=y}}
| death_date  = {{death date and age|1812|10|16|1781|2|18|df=y}}
|feast_day=19 October
|venerated_in= [[Anglican Communion]]
|image=Henry Martyn.jpg
|caption=&lt;!--Missionary to India, Persia, and China--&gt;
| birth_place = [[Truro]], [[Cornwall]], [[England]]
| death_place = [[Tokat]], [[Ottoman Empire]]
|titles=Missionary to India and Persia
|beatified_date=
|beatified_place=
|beatified_by=
|canonized_date=
|canonized_place=
|canonized_by=
|attributes=
|patronage=
|major_shrine=
|suppressed_date=
|issues=
}}

'''Henry Martyn''' (18 February 1781 – 16 October 1812) was an [[Anglican]] priest and [[missionary]] to the peoples of [[British Raj|India]] and [[Qajar dynasty|Persia]]. Born in [[Truro, Cornwall|Truro]], [[Cornwall]], he was educated at [[Truro Grammar School]] and [[St John's College, Cambridge]].&lt;ref&gt;{{acad|id=MRTN797H|name=Martyn, Henry}}&lt;/ref&gt; A chance encounter with [[Charles Simeon]] led him to become a missionary. He was ordained a priest in the [[Church of England]] and became a chaplain for the [[British East India Company]].

Martyn arrived in India in April 1806, where he preached and occupied himself in the study of linguistics. He translated the whole of the [[New Testament]] into [[Urdu]], [[Persian language|Persian]] and [[Judeo-Iranian languages|Judaeo-Persic]]. He also translated the [[Psalms]] into Persian and the [[Book of Common Prayer]] into Urdu. From India, he set out for [[Bushire]], [[Shiraz, Iran|Shiraz]], [[Isfahan (city)|Isfahan]], and [[Tabriz]].

Martyn was seized with fever, and, though the plague was raging at [[Tokat]], he was forced to stop there, unable to continue. On 16 October 1812 he died. He was remembered for his courage, selflessness and his religious devotion. In parts of the [[Anglican Communion]] he is celebrated with a [[Lesser Festival (Church of England)|Lesser Festival]] on 19 October.

==Early life==
Martyn was born in [[Truro, Cornwall|Truro]], [[Cornwall]]. His father, John Martyn, was a "captain" or mine-agent at [[Gwennap]]. As a boy, he was educated at Truro grammar school under Dr. Cardew and he entered [[St John's College, Cambridge]], in the autumn of 1797, and was [[Senior Wrangler|senior wrangler]] and first Smith's prizeman in 1801. In 1802, he was chosen as a fellow of his college.&lt;ref name="ODCC"&gt;{{cite book | last = | first = | authorlink = | editors = F. L. Cross, E. A. Livingstone | title =The Oxford Dictionary of the Christian Church, 3rd edition
 | publisher =Oxford University Press | date =13 March 1997 | location =USA
 | pages =1046 | url = | doi =   | isbn = 019211655X}}&lt;/ref&gt;

He had intended to go to the bar, but in the October term of 1802 he chanced to hear [[Charles Simeon]] speaking of the good done in India by a single [[Mission (Christian)|missionary]], [[William Carey (missionary)|William Carey]], and some time afterwards he read the life of [[David Brainerd]], a missionary to the [[Indigenous peoples of the Americas|Native Americans]]. He resolved, accordingly, to become a missionary himself. On 22 October 1803, he was ordained deacon at [[Ely, Cambridgeshire|Ely]], and afterwards priest, and served as Simeon's curate at the [[Holy Trinity Church, Cambridge|Church of Holy Trinity]], taking charge of the neighbouring parish of [[Lolworth]].&lt;ref name="ODCC" /&gt;

==Missionary work==
Martyn wanted to offer his services to the [[Church Missionary Society]], when a financial disaster in Cornwall deprived him and his unmarried sister of the income  their father had left for them. It was necessary for Martyn to earn an income that would support his sister as well as himself.&lt;ref name="DNB"&gt;{{cite DNB|wstitle=Martyn, Henry|volume=36}}&lt;/ref&gt;  He accordingly obtained a chaplaincy under the [[British East India Company]] and left for [[British Raj|India]] on 5 July 1805.&lt;ref name="ODCC" /&gt; On his voyage to the East, Martyn happened to be present at the [[British Empire|British]] [[Battle of Blaauwberg|conquest]] of the [[Cape Colony]] on 8 January 1806. He spent that day tending to the dying soldiers and was distressed by seeing the horrors of war. He would come away feeling that it was Britain's destiny to convert, not colonize, the world.&lt;ref name="OIHC"&gt;(1990) McManners, John. ''Oxford Illustrated History of Christianity''. Oxford University Press, 457. {{ISBN|0-19-822928-3}}&lt;/ref&gt; He wrote in his diary:

{{quote|I prayed that…[[England]] whilst she sent the thunder of her arms to distant regions of the globe, might not remain proud and ungodly at home; but might show herself great indeed, by sending forth the ministers of her church to diffuse the gospel of peace.&lt;ref name="OIHC" /&gt;}}

===India===
Martyn arrived in India in April 1806, and for some months he was stationed at Aldeen, near [[Serampur]]. In October 1806, he proceeded to [[Danapur|Dinapur]], where he was soon able to conduct worship among the locals in the vernacular, and established schools.&lt;ref name="let"&gt;(1837) [[Samuel Wilberforce|Wilberforce, Samuel]] (ed.). [http://justus.anglican.org/resources/pc/india/martyn/journal.html ''Journal and Letters of the Rev. Henry Martyn B.D.'']. London: Seeley and Burnside.&lt;/ref&gt; In April 1809, he was transferred to [[Cawnpore]], where he preached to British and Indians in his own compound, in spite of interruptions and threats from local non-Christians.&lt;ref name="DNB" /&gt;

He occupied himself in linguistic study, and had already, during his residence at Dinapur, been engaged in revising the sheets of his [[Hindustani language|Hindustani]] version of the [[New Testament]]. He now translated the whole of the New Testament into [[Urdu]] also, and into [[Persian language|Persian]] twice. He translated the [[Psalms]] into Persian, the Gospels into Judaeo-Persic, and the [[Book of Common Prayer]] into Urdu, in spite of ill-health and "the pride, pedantry and fury of his chief munshi Sabat."&lt;ref name="EB1911" /&gt; Ordered by the doctors to take a sea voyage, he obtained leave to go to Persia and correct his Persian New Testament. From there, he wanted to go to [[Arabia]], and there compose an [[Arabic language|Arabic]] version.&lt;ref name="ODCC" /&gt; On 1 October 1810, having seen his work at Cawnpore rewarded on the previous day by the opening of a church, he left for [[Calcutta]], from where he sailed on 7 January 1811 for [[Bombay]]. The ship reached port on his thirtieth birthday.&lt;ref name="let" /&gt;

==Final voyage and death==
From Bombay he set out for [[Bushire]], bearing letters from [[John Malcolm|Sir John Malcolm]] to men of position there, as also at [[Shiraz, Iran|Shiraz]] and [[Isfahan (city)|Isfahan]]. After an exhausting journey from the coast he reached Shiraz, and was soon plunged into discussion with the disputants of all classes, "Sufi, Muslim, Jew, and Jewish Muslim, even Armenian, all anxious to test their powers of argument with the first English priest who had visited them."&lt;ref name="EB1911"&gt;{{EB1911|wstitle=Martyn, Henry|volume=17|page=804}}&lt;/ref&gt; He next traveled to [[Tabriz]] to attempt to present the [[Shah]] with his translation of the New Testament, which proved unsuccessful. Sir [[Gore Ouseley]], the British ambassador to the Shah, was unable to bring about a meeting, but did deliver the manuscript. Although Martyn could not present the Bible in person, the Shah later wrote him a letter:

{{quote|In truth (said the royal letter of thanks to the ambassador) through the learned and unremitted exertions of the Reverend Henry Martyn it has been translated in a style most befitting sacred books, that is in an easy and simple diction...The whole of the New Testament is completed in a most excellent manner, a source of pleasure to our enlightened and august mind.&lt;ref name="cp"&gt;{{cite book | last =Padwick | first =Constance | authorlink = | coauthors = | title =Henry Martyn, Confessor of the Faith
 | publisher =Inter-Varsity Fellowship | year =1953 | location =London  | pages =172 | url = | doi =   | isbn = }}&lt;/ref&gt;}}

At this time, he was seized with fever, and after a temporary recovery, had to seek a change of climate. He set off for [[Istanbul|Constantinople]], where he intended to return on furlough to England to regain his strength and recruit help for the missions in India.&lt;ref name="DNB" /&gt; On 12 September 1812, he started with two [[Armenia]]n servants and crossed the [[Aras River]]. Urged on from place to place by their  [[Tatar]] guide, they rode from Tabriz to [[Yerevan|Erivan]], from Erivan to [[Kars]], and from Kars to [[Erzurum]]. They departed Erzurum and though the plague was raging at [[Tokat]], he was forced to stop there, unable to continue. He wrote his final journal entry on 6 October. It read, in part:

{{quote|Oh! when shall time give place to eternity? When shall appear that new heaven and new earth wherein dwelleth righteousness? There, there shall in no wise enter in any thing that defileth: none of that wickedness which has made men worse than wild beasts, none of those corruptions which add still more to the miseries of mortality, shall be seen or heard of any more.&lt;ref name="let" /&gt;}}

On 16 October 1812 he died and was given a [[Christian burial]] by [[Armenian Apostolic Church|Armenian clergy]].&lt;ref name="ODCC" /&gt;

He was heard to say, "Let me burn out for God".  An indication of his zeal for the things of God.

==Legacy==
His devotion to his tasks won him much admiration in Great Britain and he was the hero of a number of literary publications.&lt;ref name="ODCC" /&gt; [[Thomas Babington Macaulay, 1st Baron Macaulay|Thomas Babington Macaulay]]'s ''Epitaph'', composed early in 1813, testified to the impression made by his career:

{{cquote|Epitaph on Henry Martyn

&lt;br /&gt;  Here Martyn lies. In Manhood's early bloom
&lt;br /&gt;  The Christian Hero finds a Pagan tomb.
&lt;br /&gt;  Religion, sorrowing o'er her favourite son,
&lt;br /&gt;  Points to the glorious trophies that he won.
&lt;br /&gt;  Eternal trophies! not with carnage red,
&lt;br /&gt;  Not stained with tears by hapless captives shed,
&lt;br /&gt;  But trophies of the Cross! for that dear name,
&lt;br /&gt;  Through every form of danger, death, and shame,
&lt;br /&gt;  Onward he journeyed to a happier shore,
&lt;br /&gt;  Where danger, death, and shame assault no more.

}}

An institution was established in his name in India, called the Henry Martyn Institute: An Interfaith Centre for Reconciliation and Research, Hyderabad, India.&lt;ref&gt;[http://www.hmiindia.org www.hmiindia.org]&lt;/ref&gt; [[John McManners]] wrote in his ''Oxford Illustrated History of Christianity'' that Martyn was a man remembered for his courage, selflessness and his religious devotion.&lt;ref name="OIHC" /&gt;  In parts of the [[Anglican Communion]] he is celebrated with a [[Lesser Festival (Church of England)|Lesser Festival]] on 19 October.&lt;ref name="ODCC" /&gt;

The [http://www.martynmission.cam.ac.uk Henry Martyn Trust] based in Cambridge, England can trace its history back to 1897, at a time of great enthusiasm in Cambridge for overseas missions, when an appeal was launched for a 'Proposed Missionary Library for Cambridge University', to be housed in the Henry Martyn Hall, erected ten years previously.

The Henry Martyn Library opened in the Hall in 1898, and there it remained as a small collection of missionary biographies and other books until 1995. The evolution of the Henry Martyn Library into the present [http://www.martynmission.cam.ac.uk Henry Martyn Centre] began in 1992, when Canon Graham Kings was appointed as the first Henry Martyn Lecturer in Missiology in the Cambridge Theological Federation.

In 1999 the Centre became an Associate Institute of the [http://www.theofed.cam.ac.uk/index.html Cambridge Theological Federation], one of the largest providers of theological education in the United Kingdom. The Library and the Henry Martyn Centre are now housed at Westminster College. Today, the Centre continues to seek to promote the study of mission and world Christianity, developing strong links with mission study centres around the world and fulfilling the same aim that was stated by the founders of the Library in 1897.&lt;ref name="Spencer-Thomas2018"&gt;{{Cite web | title = Henry Martin (1781–1812) | last = Spencer-Thomas | first = Owen | work = Owen Spencer-Thomas | date = 2018 | accessdate = 2018-02-07 | url = http://sayitstraight.co.uk/local-history/biographies/henry-martyn-1781-1812/ | quote =  }}&lt;/ref&gt;

==See also==
{{Portal|Anglicanism|Saints}}
*[[Henry Martyn Hall, Cambridge]], built 1887
*[[Saints in Anglicanism]]
*[[Church Missionary Society in India]]
*[[List of Protestant missionaries in India]]
*[[John Gilchrist (linguist)]]
*[[James Hawkes (missionary)]]

==References==
{{Reflist}}

==Further reading==
*Padwick, Constance. ''Henry Martyn: Confessor of the Faith'', Inter-Varsity Fellowship: London (1953).
*Bentley-Taylor, David. ''My Love Must Wait: the Story of Henry Martyn'', Downers Grove: IVP (1975).
*Henry, B. V. ''Forsaking All for Christ: A Biography of Henry Martyn'' London: Chapter Two, 2003.
*[[John Sargent (priest)|Sargent, John]].  ''Memoir of the Rev. Henry Martyn B. D.'', London: Hatchard (1816). Links to editions from [https://books.google.com/books?id=msEEAAAAYAAJ 1820] and [https://books.google.com/books?id=vsAEAAAAYAAJ 1844]
*Kellsye M. Finnie, ''Beyond the Minarets: A Biography of Henry Martyn'' Bromley: STL Books, 1988
*Smith, George. [https://books.google.com/books?id=abirsyBToxQC&amp;printsec=frontcover&amp;dq=%22henry+martyn%22 ''Henry Martyn, Saint and Scholar''], London: Religious Tract Society (1892).
*Isaac, Peter. ''A history of Evangelical Christianity in Cornwall'', Privately published; Polperro, Cornwall (1999) &amp;ndash; contains a chapter about Martyn, who was born in [[Cornwall]].

==External links==
* [http://www.martynmission.cam.ac.uk Henry Martyn Centre]
* [http://www.lcms.org/ca/www/cyclopedia/02/display.asp?t1=m&amp;word=MARTYN.HENRY Martyn, Henry] in the Christian Cyclopedia
* [[s:The missionaries - Martyn, Huc, Livingstone, Selwyn|The missionaries - Martyn, Huc, Livingstone, Selwyn]] - [[Once a Week (magazine)]].
{{Protestant missions to India}}
{{Christianity in Iran}}
{{good article}}

{{Authority control}}

{{DEFAULTSORT:Martyn, Henry}}
[[Category:1781 births]]
[[Category:1812 deaths]]
[[Category:English Anglican missionaries]]
[[Category:Anglican missionaries in India]]
[[Category:Translators of the Bible into Persian]]
[[Category:Translators of the Bible into Urdu]]
[[Category:Anglican missionaries in Iran]]
[[Category:19th-century English Anglican priests]]
[[Category:Alumni of St John's College, Cambridge]]
[[Category:Fellows of St John's College, Cambridge]]
[[Category:People from Truro]]
[[Category:People educated at Truro Cathedral School]]
[[Category:Anglican saints]]
[[Category:Senior Wranglers]]
[[Category:19th-century Christian saints]]
[[Category:British expatriates in Iran]]
[[Category:Cornish Christian missionaries]]</text>
      <sha1>3pl2uygrdx8y97gaechi0zmjdvmceak</sha1>
    </revision>
  </page>
  <page>
    <title>Heteroclinic orbit</title>
    <ns>0</ns>
    <id>3948758</id>
    <revision>
      <id>720566111</id>
      <parentid>669639037</parentid>
      <timestamp>2016-05-16T17:38:29Z</timestamp>
      <contributor>
        <username>Izno</username>
        <id>2927383</id>
      </contributor>
      <comment>clean &lt;b/&gt;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3220">[[Image:Heteroclinic orbit in pendulum phaseportrait.png|thumb|right|The [[phase portrait]] of the [[pendulum]] equation {{var|x'&lt;nowiki/&gt;'}} + sin&amp;nbsp;''x'' = 0. The highlighted curve shows the heteroclinic orbit from (''x'', ''x')'' = (&amp;minus;π, 0) to (''x'', ''x')'' = (π, 0). This orbit corresponds with the (rigid) pendulum starting upright, making one revolution through its lowest position, and ending upright again.]]

In [[mathematics]], in the [[phase portrait]] of a [[dynamical system]], a '''heteroclinic orbit''' (sometimes called a [[heteroclinic connection]]) is a path in phase space which joins two different [[equilibrium point]]s. If the equilibrium points at the start and end of the orbit are the same, the orbit is a [[homoclinic orbit]].

Consider the continuous dynamical system described by the [[Ordinary Differential Equation|ODE]]
::&lt;math&gt;\dot x=f(x)&lt;/math&gt;
Suppose there are equilibria at &lt;math&gt;x=x_0&lt;/math&gt; and &lt;math&gt;x=x_1&lt;/math&gt;, then a solution &lt;math&gt;\phi(t)&lt;/math&gt; is a heteroclinic orbit from &lt;math&gt;x_0&lt;/math&gt; to &lt;math&gt;x_1&lt;/math&gt; if
::&lt;math&gt;\phi(t)\rightarrow x_0\quad \mathrm{as}\quad t\rightarrow-\infty&lt;/math&gt;
and
::&lt;math&gt;\phi(t)\rightarrow x_1\quad \mathrm{as}\quad t\rightarrow+\infty&lt;/math&gt;

This implies that the orbit is contained in the [[stable manifold]] of &lt;math&gt;x_1&lt;/math&gt; and the [[unstable manifold]] of &lt;math&gt;x_0&lt;/math&gt;.

==Symbolic dynamics==
By using the [[Markov partition]], the long-time behaviour of [[hyperbolic system]] can be studied using the techniques of [[symbolic dynamics]]. In this case, a heteroclinic orbit has a particularly simple and clear representation. Suppose that &lt;math&gt;S=\{1,2,\ldots,M\}&lt;/math&gt; is a [[finite set]] of ''M'' symbols. The dynamics of a point ''x'' is then represented by a [[bi-infinite string]] of symbols 

:&lt;math&gt;\sigma =\{(\ldots,s_{-1},s_0,s_1,\ldots) : s_k \in S \; \forall k \in \mathbb{Z} \}&lt;/math&gt;

A [[periodic point]] of the system is simply a recurring sequence of letters. A heteroclinic orbit is then the joining of two distinct periodic orbits. It may be written as

:&lt;math&gt;p^\omega s_1 s_2 \cdots s_n q^\omega&lt;/math&gt;

where &lt;math&gt;p= t_1 t_2 \cdots t_k&lt;/math&gt; is a sequence of symbols of length ''k'', (of course, &lt;math&gt;t_i\in S&lt;/math&gt;), and &lt;math&gt;q = r_1 r_2 \cdots r_m&lt;/math&gt; is another sequence of symbols, of length ''m'' (likewise, &lt;math&gt;r_i\in S&lt;/math&gt;). The notation &lt;math&gt;p^\omega&lt;/math&gt; simply denotes the repetition of ''p'' an infinite number of times. Thus, a heteroclinic orbit can be understood as the transition from one periodic orbit to another.  By contrast, a [[homoclinic orbit]] can be written as 

:&lt;math&gt;p^\omega s_1 s_2 \cdots s_n p^\omega&lt;/math&gt;

with the intermediate sequence &lt;math&gt;s_1 s_2 \cdots s_n&lt;/math&gt; being non-empty, and, of course, not being ''p'', as otherwise, the orbit would simply be &lt;math&gt;p^\omega&lt;/math&gt;.

== See also ==

* [[Heteroclinic connection]]
* [[Heteroclinic cycle]]
* [[Heteroclinic bifurcation]]
* [[Homoclinic orbit]]

== References ==

* [[John Guckenheimer]] and [[Philip Holmes]], ''Nonlinear Oscillations, Dynamical Systems, and Bifurcations of Vector Fields'', (Applied Mathematical Sciences Vol. '''42'''), Springer

[[Category:Dynamical systems]]</text>
      <sha1>1dj1e099hrc58s2s21ql0rhdtgcqeun</sha1>
    </revision>
  </page>
  <page>
    <title>Jacobi's four-square theorem</title>
    <ns>0</ns>
    <id>18808748</id>
    <revision>
      <id>868952644</id>
      <parentid>868952617</parentid>
      <timestamp>2018-11-15T13:28:15Z</timestamp>
      <contributor>
        <username>The Anome</username>
        <id>76</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/The Anomebot2|The Anomebot2]] ([[User talk:The Anomebot2|talk]]) to last version by Seahawk01</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3658">{{dablink|For other theorems of Jacobi see [[Jacobi's theorem (disambiguation)]].}}

'''Jacobi's four-square theorem''' gives a formula for the number of ways that a given positive integer ''n'' can be represented as the sum of four squares.

==History==
The theorem was proved in 1834 by [[Carl Gustav Jakob Jacobi]].

==Theorem==
Two representations are considered different if their terms are in different order or if the integer being squared (not just the square) is different; to illustrate, these are three of the eight different ways to represent 1:

:&lt;math&gt;
\begin{align}
&amp; 1^2 + 0^2 + 0^2 + 0^2 \\
&amp; 0^2 + 1^2 + 0^2 + 0^2 \\
&amp; (-1)^2 + 0^2 + 0^2 + 0^2.
\end{align}
&lt;/math&gt;

The number of ways to represent n as the sum of four squares is eight times the sum of the [[divisor]]s of ''n'' if ''n'' is odd and 24 times the sum of the odd divisors of ''n'' if ''n'' is even (see [[divisor function]]), i.e.

: &lt;math&gt;r_4(n)=\begin{cases}8\sum\limits_{m|n}m&amp;\text{if }n\text{ is odd}\\[12pt]
24\sum\limits_{\begin{smallmatrix} m|n \\ m\text{ odd} \end{smallmatrix}}m&amp;\text{if }n\text{ is even}.
\end{cases}&lt;/math&gt;

Equivalently, it is eight times the sum of all its divisors which are not divisible by 4, i.e.

:&lt;math&gt;r_4(n)=8\sum_{m\mid n ,\, 4 \nmid m}m.&lt;/math&gt;

We may also write this as

:&lt;math&gt;r_4(n) = 8 \sigma(n) -32 \sigma(n/4) \ , &lt;/math&gt;
where the second term is to be taken as zero if ''n'' is not divisible by 4. In particular, for a [[prime number]] ''p'' we have the explicit formula&amp;nbsp;''r''&lt;sub&gt;4&lt;/sub&gt;(''p'')&amp;nbsp;=&amp;nbsp;8(''p''&amp;nbsp;+&amp;nbsp;1).&lt;ref name="Williams_2011"&gt;{{harvnb|Williams|2011|p=119}}.&lt;/ref&gt;

Some values of ''r''&lt;sub&gt;4&lt;/sub&gt;(''n'') occur infinitely often as ''r''&lt;sub&gt;4&lt;/sub&gt;(''n'')&amp;nbsp;=&amp;nbsp;''r''&lt;sub&gt;4&lt;/sub&gt;(2&lt;sup&gt;''m''&lt;/sup&gt;''n'') whenever ''n'' is even. The values of ''r''&lt;sub&gt;4&lt;/sub&gt;(''n'')/''n'' can be arbitrarily large: indeed, ''r''&lt;sub&gt;4&lt;/sub&gt;(''n'')/''n'' is infinitely often larger than 8{{radic|log ''n''}}.&lt;ref name="Williams_2011" /&gt;

==Proof==
The theorem can be proved by elementary means starting with the [[Jacobi triple product]].&lt;ref&gt;{{Cite journal|last=Hirschhorn|first=Michael D.|date=2000|title=Partial Fractions and Four Classical Theorems of Number Theory|jstor=2589321|journal=The American Mathematical Monthly|volume=107|issue=3|pages=260–264|doi=10.2307/2589321}}&lt;/ref&gt;

The proof shows that the [[Theta series#Generalizations|Theta series]] for the [[lattice (discrete subgroup)|lattice]] '''Z'''&lt;sup&gt;4&lt;/sup&gt; is a [[modular form]] of a certain level, and hence equals a [[linear combination]] of [[Eisenstein series]].

== See also ==
*[[Lagrange's four-square theorem]]
*[[Lambert series]]
*[[Sum of squares function]]

==Notes==
{{reflist}}

==References==
*{{cite journal|first=Michael D.|last=Hirschhorn|author2=James A. Mcgowan|title=Algebraic consequences of Jacobi’s two– and four–square theorems|url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.26.9028|journal=Ismail (eds), Developments in Mathematics|pages=107–132}}
*{{cite journal|first=Michael D.|last=Hirschhorn|title=A simple proof of Jacobi’s four-square theorem|date=1987|journal=Proc. Amer. Math. Soc.|doi=10.1090/s0002-9939-1987-0908644-9}}
* {{cite book | last=Williams | first=Kenneth S. | title=Number theory in the spirit of Liouville | zbl=1227.11002 | series=London Mathematical Society Student Texts | volume=76 | location=Cambridge | publisher=[[Cambridge University Press]] | isbn=978-0-521-17562-3 | year=2011 }}

== External links ==

*{{MathWorld|id=SumofSquaresFunction|title=Sum of Squares Function}}

[[Category:Squares in number theory]]
[[Category:Theorems in number theory]]</text>
      <sha1>l06xoj6jcz7h1fjoq0n14yme5f04w8z</sha1>
    </revision>
  </page>
  <page>
    <title>Julia F. Knight</title>
    <ns>0</ns>
    <id>40816534</id>
    <revision>
      <id>781579459</id>
      <parentid>777764474</parentid>
      <timestamp>2017-05-22T02:13:53Z</timestamp>
      <contributor>
        <username>Cstanford.math</username>
        <id>11063468</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1877">[[File:Knight julia.jpg|thumb|Julia F. Knight, 2012]]
'''Julia Frandsen Knight''' is an American mathematician, specializing in [[model theory]] and [[computability theory]].&lt;ref name="profile"&gt;[http://math.nd.edu/people/faculty/julia-f-knight/ Faculty profile], Notre Dame, retrieved 2013-10-16.&lt;/ref&gt; She is the Charles L. Huisking Professor of Mathematics at the [[University of Notre Dame]] and director of the graduate program in mathematics there.&lt;ref name="huisking"&gt;[http://professorships.nd.edu/professorships/the-charles-l-huisking-professor-of-mathematics-1/ Julia Knight – Named professorships and directorships at Notre Dame] {{webarchive|url=https://web.archive.org/web/20131017121320/http://professorships.nd.edu/professorships/the-charles-l-huisking-professor-of-mathematics-1/ |date=2013-10-17 }}, retrieved 2013-10-16.&lt;/ref&gt;

Knight did her undergraduate studies at [[Utah State University]], graduating in 1964, and earned her Ph.D. from the [[University of California, Berkeley]] in 1972 under the supervision of [[Robert Lawson Vaught]].&lt;ref name="profile"/&gt;&lt;ref&gt;{{mathgenealogy|id=11628}}&lt;/ref&gt;

In 2012 she became a [[fellow]] of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of AMS Fellows], retrieved 2013-10-16.&lt;/ref&gt;

==References==
{{reflist}}

{{Authority control}}
{{DEFAULTSORT:Knight, Julia Frandsen}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Women mathematicians]]
[[Category:Utah State University alumni]]
[[Category:University of California, Berkeley alumni]]
[[Category:University of Notre Dame faculty]]
[[Category:Model theorists]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Tarski lecturers]]

{{mathematician-stub}}</text>
      <sha1>jyinm0fs545yu3esjrokjpzeggyxdsp</sha1>
    </revision>
  </page>
  <page>
    <title>Law of total covariance</title>
    <ns>0</ns>
    <id>23950557</id>
    <revision>
      <id>855891193</id>
      <parentid>831934163</parentid>
      <timestamp>2018-08-21T14:39:59Z</timestamp>
      <contributor>
        <ip>212.126.224.100</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3105">In [[probability theory]], the '''law of total covariance''',&lt;ref&gt;Matthew R. Rudary, ''On Predictive Linear Gaussian Models'', ProQuest, 2009, page 121.&lt;/ref&gt; '''covariance decomposition formula''', or '''conditional covariance formula''' states that if ''X'', ''Y'', and ''Z'' are [[random variable]]s on the same [[probability space]], and the [[covariance]] of ''X'' and ''Y'' is finite, then

:&lt;math&gt;\operatorname{cov}(X,Y)=\operatorname{E}(\operatorname{cov}(X,Y \mid Z))+\operatorname{cov}(\operatorname{E}(X\mid Z),\operatorname{E}(Y\mid Z)).&lt;/math&gt;

The nomenclature in this article's title parallels the phrase ''[[law of total variance]]''.  Some writers on probability call this the "'''conditional covariance''' formula"&lt;ref&gt;Sheldon M. Ross, ''A First Course in Probability'', sixth edition, Prentice Hall, 2002, page 392.&lt;/ref&gt; or use other names.

(The [[conditional expected value]]s E( ''X'' | ''Z'' ) and E( ''Y'' | ''Z'' ) are random variables whose values depend on the value of ''Z''.  Note that the conditional expected value of ''X'' given the ''event''  ''Z'' = ''z'' is a function of ''z''.  If we write E( ''X'' | ''Z'' = ''z'') = ''g''(''z'') then the random variable E( ''X'' | ''Z'' ) is ''g''(''Z''). Similar comments apply to the conditional covariance.)

==Proof==

The law of total covariance can be proved using the [[law of total expectation]]:  First,

:&lt;math&gt;\operatorname{cov}[X,Y] = \operatorname{E}[XY] - \operatorname{E}[X]\operatorname{E}[Y]&lt;/math&gt;

from the definition of covariance.  Then we apply the law of total expectation by conditioning on the random variable ''Z'':

::&lt;math&gt;= \operatorname{E}[\operatorname{E}[XY\mid Z]] - \operatorname{E}[\operatorname{E}[X\mid Z]]\operatorname{E}[\operatorname{E}[Y\mid Z]]&lt;/math&gt;

Now we rewrite the term inside the first expectation using the definition of covariance:

::&lt;math&gt;= \operatorname{E}\!\left[\operatorname{cov}[X,Y\mid Z] + \operatorname{E}[X\mid Z]\operatorname{E}[Y\mid Z]\right] - \operatorname{E}[\operatorname{E}[X\mid Z]]\operatorname{E}[\operatorname{E}[Y\mid Z]]&lt;/math&gt;

Since expectation of a sum is the sum of expectations, we can regroup the terms:

::&lt;math&gt;= \operatorname{E}\!\left[\operatorname{cov}[X,Y\mid Z]] + \operatorname{E}[\operatorname{E}[X\mid Z]\operatorname{E}[Y\mid Z]\right] - \operatorname{E}[\operatorname{E}[X\mid Z]]\operatorname{E}[\operatorname{E}[Y\mid Z]]&lt;/math&gt;

Finally, we recognize the final two terms as the covariance of the conditional expectations E[''X''|''Z''] and E[''Y''|''Z'']:

::&lt;math&gt;= \operatorname{E}(\operatorname{cov}(X,Y \mid Z))+\operatorname{cov}(\operatorname{E}(X\mid Z),\operatorname{E}(Y\mid Z))&lt;/math&gt;

==See also==
*[[Law of total variance]], a special case corresponding to&amp;nbsp;''X''&amp;nbsp;=&amp;nbsp;''Y''.

== Notes and references ==
{{reflist}}

==External links==

{{DEFAULTSORT:Law Of Total Covariance}}
[[Category:Algebra of random variables]]
[[Category:Covariance and correlation]]
[[Category:Articles containing proofs]]
[[Category:Theory of probability distributions]]
[[Category:Statistical theorems]]
[[Category:Statistical laws]]</text>
      <sha1>fzb4p5whj15n59d2f831eunb03q724x</sha1>
    </revision>
  </page>
  <page>
    <title>Lawrence–Krammer representation</title>
    <ns>0</ns>
    <id>19234105</id>
    <revision>
      <id>862709679</id>
      <parentid>852443849</parentid>
      <timestamp>2018-10-06T05:22:50Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6136">In [[mathematics]] the '''Lawrence–Krammer representation''' is a [[group representation|representation]] of the [[braid group]]s.  It fits into a family of representations called the Lawrence representations.  The first Lawrence representation is the [[Burau representation]] and the second is the Lawrence–Krammer representation.

The Lawrence–Krammer representation is named after [[Ruth Lawrence]] and Daan Krammer.&lt;ref&gt;{{citation | last = Bigelow| first= Stephen| authorlink=Stephen Bigelow| contribution=The Lawrence–Krammer representation |title= Topology and geometry of manifolds| series=Proc. Sympos. Pure Math.| volume=71| pages= 51–68| year=2003|publisher=Amer. Math. Soc.|location=Providence, RI | mr=2024629}} &lt;/ref&gt;

== Definition ==

Consider the [[braid group]] &lt;math&gt;B_n&lt;/math&gt; to be the [[mapping class group]] of a disc with ''n'' marked points, &lt;math&gt;P_n&lt;/math&gt;.  The Lawrence–Krammer representation is defined as the action of &lt;math&gt;B_n&lt;/math&gt; on the homology of a certain [[covering map|covering]] space of the [[Configuration space (physics)|configuration space]] &lt;math&gt;C_2 P_n&lt;/math&gt;.  Specifically, the first integral [[Homology (mathematics)|homology group]] of &lt;math&gt;C_2 P_n&lt;/math&gt; is isomorphic to &lt;math&gt;\mathbb Z^{n+1}&lt;/math&gt;, and the subgroup of &lt;math&gt; H_1 (C_2 P_n,\mathbb{Z})&lt;/math&gt; invariant under the action of &lt;math&gt;B_n&lt;/math&gt; is primitive, free abelian, and of rank 2.  Generators for this invariant subgroup  are denoted by &lt;math&gt;q, t&lt;/math&gt;.

The covering space of &lt;math&gt;C_2 P_n&lt;/math&gt; corresponding to the kernel of the projection map

:&lt;math&gt;\pi_1 (C_2 P_n) \to \mathbb{Z}^2 \langle q,t \rangle &lt;/math&gt;

is called the Lawrence–Krammer cover and is denoted &lt;math&gt;\overline{C_2 P_n}&lt;/math&gt;. [[Diffeomorphism]]s of&lt;math&gt;P_n&lt;/math&gt; act on &lt;math&gt;P_n&lt;/math&gt;, thus also on &lt;math&gt;C_2 P_n&lt;/math&gt;, moreover they lift uniquely to diffeomorphisms of &lt;math&gt;\overline{C_2 P_n}&lt;/math&gt; which restrict to the identity on the co-dimension two boundary stratum (where both points are on the boundary circle).  The action of &lt;math&gt;B_n&lt;/math&gt; on

:&lt;math&gt;H_2 (\overline{C_2 P_n},\mathbb{Z}),&lt;/math&gt;

thought of as a

:&lt;math&gt;\mathbb Z\langle t^{\pm},q^{\pm}\rangle&lt;/math&gt;-module,

is the Lawrence–Krammer representation. The group &lt;math&gt;H_2 (\overline{C_2 P_n},\mathbb{Z})&lt;/math&gt; is known to be a free &lt;math&gt;\mathbb Z\langle t^{\pm},q^{\pm}\rangle&lt;/math&gt;-module, of rank &lt;math&gt;n (n-1)/ 2&lt;/math&gt;.

== Matrices ==

Using Bigelow's conventions for the Lawrence–Krammer representation, generators for the group &lt;math&gt;H_2 (\overline{C_2 P_n},\mathbb{Z})&lt;/math&gt; are denoted &lt;math&gt;v_{j,k}&lt;/math&gt; for &lt;math&gt;1 \leq j &lt; k \leq n&lt;/math&gt;.  Letting &lt;math&gt;\sigma_i&lt;/math&gt; denote the standard Artin generators of the [[braid group]], we obtain the expression:

&lt;math&gt;\sigma_i\cdot v_{j,k} = \left\{
\begin{array}{lr}
v_{j,k} &amp; i\notin \{j-1,j,k-1,k\}, \\
qv_{i,k} + (q^2-q)v_{i,j} + (1-q)v_{j,k} &amp; i=j-1 \\
v_{j+1,k} &amp; i=j\neq k-1, \\
qv_{j,i} + (1-q)v_{j,k} - (q^2-q)tv_{i,k} &amp; i=k-1\neq j,\\
v_{j,k+1} &amp; i=k,\\
-tq^2v_{j,k} &amp; i=j=k-1.
\end{array}
\right.&lt;/math&gt;

== Faithfulness ==

[[Stephen Bigelow]] and Daan Krammer have given independent proofs that the Lawrence–Krammer representation is [[group representation|faithful]].

== Geometry ==

The Lawrence–Krammer representation preserves a non-degenerate [[sesquilinear form]] which is known to be negative-definite Hermitian provided &lt;math&gt;q, t&lt;/math&gt; are specialized to suitable unit complex numbers (''q'' near 1 and ''t'' near ''i'').  Thus the braid group is a subgroup of the [[unitary group]] of square matrices of size &lt;math&gt;n(n-1)/2&lt;/math&gt;. Recently it has been shown that the image of the Lawrence–Krammer representation is a [[dense set|dense subgroup]] of the [[unitary group]] in this case.

The sesquilinear form has the explicit description:

&lt;math&gt; \langle v_{i,j}, v_{k,l}\rangle = -(1-t)(1+qt)(q-1)^2t^{-2}q^{-3}
\left\{
\begin{array}{lr}
-q^2t^2(q-1) &amp; i=k&lt;j&lt;l \text{ or } i&lt;k&lt;j=l \\
-(q-1) &amp; k=i&lt;l&lt;j \text{ or } k&lt;i&lt;j=l \\
t(q-1) &amp; i&lt;j=k&lt;l \\
q^2t(q-1) &amp; k&lt;l=i&lt;j \\
-t(q-1)^2(1+qt) &amp; i&lt;k&lt;j&lt;l \\
(q-1)^2(1+qt) &amp; k&lt;i&lt;l&lt;j \\
(1-qt)(1+q^2t) &amp; k=i, j=l \\
0 &amp; \text{otherwise} \\
\end{array}
\right.&lt;/math&gt;

== References ==
{{reflist}}

==Further reading==
* {{citation | last = Bigelow| first= Stephen| authorlink=Stephen Bigelow| title=Braid groups are linear| journal=[[Journal of the American Mathematical Society]]|volume= 14| year=2001 | issue=2|pages =471–486|mr=1815219|doi=10.1090/S0894-0347-00-00361-1}}
* {{citation | last = Bigelow| first= Stephen| authorlink=Stephen Bigelow| contribution=The Lawrence–Krammer representation |title= Topology and geometry of manifolds| series=Proceedings of Symposia in Pure Mathematics | volume=71| pages= 51–68| year=2003|publisher=American Mathematical Society|location=Providence, RI | mr=2024629|doi=10.1090/pspum/071}} 
* {{citation | last= Budney| first=Ryan| title=On the image of the Lawrence–Krammer representation| journal= [[Journal of Knot Theory and Its Ramifications]]| year=2005 | volume=14|issue=6| pages= 773–789| doi=10.1142/S0218216505004044|mr= 2172897 |arxiv=math/0202246}}
* {{citation | last = Krammer |first=Daan| year = 2002 | title = Braid groups are linear | journal = [[Annals of Mathematics]] | volume = 155 | issue = 1 | pages = 131–156 | doi=10.2307/3062152 | mr=1888796| arxiv=math/0405198}}
*  {{citation | last = Lawrence| first= Ruth| authorlink=Ruth  Lawrence | year = 1990 | title = Homological representations of the Hecke algebra | url = | journal = [[Communications in Mathematical Physics]] | volume = 135 | issue = 1 | pages = 141–191 | doi=10.1007/bf02097660| mr=1086755| bibcode= 1990CMaPh.135..141L}}
* {{cite journal | last1 = Paoluzzi|first1= Luisa|last2= Paris|first2= Luis | year = 2002 | title = A note on the Lawrence–Krammer–Bigelow representation | url = | journal = [[Algebraic and Geometric Topology]] | volume = 2 | issue = | pages = 499–518 | doi=10.2140/agt.2002.2.499 | arxiv=math/0111186|mr=1917064}}

{{DEFAULTSORT:Lawrence-Krammer representation}}
[[Category:Braid groups]]
[[Category:Representation theory]]</text>
      <sha1>qomws2keqafpwk3lrijytldlsxg4tbs</sha1>
    </revision>
  </page>
  <page>
    <title>Linear function</title>
    <ns>0</ns>
    <id>152111</id>
    <revision>
      <id>865223185</id>
      <parentid>865223156</parentid>
      <timestamp>2018-10-22T15:27:50Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/170.211.188.149|170.211.188.149]] to version by D.Lazard. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3518089) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4587">In [[mathematics]], the term '''linear function''' refers to two distinct but related notions:&lt;ref&gt;"The term ''linear function'' means a linear form in some textbooks and an affine function in others." Vaserstein 2006, p. 50-1&lt;/ref&gt;
* In [[calculus]] and related areas, a linear function is a [[function (mathematics)|function]] whose [[graph of a function|graph]] is a [[straight line]], that is a [[polynomial function]] of degree at most one.&lt;ref&gt;Stewart 2012, p. 23&lt;/ref&gt;
* In [[linear algebra]], [[mathematical analysis]]&lt;ref&gt;{{cite book|author=T. M. Apostol|title=Mathematical Analysis|year=1981|publisher=Addison-Wesley|page=345}}&lt;/ref&gt;, and [[functional analysis]], a linear function is a [[linear map]].&lt;ref&gt;Shores 2007, p. 71&lt;/ref&gt; In this case, and in case of possible ambiguity, the name [[Affine transformation|affine function]] is often used for the concept above.&lt;ref&gt;{{cite book|author=A. Kurosh|title=Higher Algebra|year=1975|publisher=Mir Publishers|page=214}}&lt;/ref&gt;

== As a polynomial function ==
{{main article|Linear function (calculus)}}
[[File:Linear Function Graph.svg|thumb|Graphs of two linear (polynomial) functions.]]

In calculus, [[analytic geometry]] and related areas, a linear function is a polynomial of degree one or less, including the [[zero polynomial]] (the latter not being considered to have degree zero).

When the function is of only one [[variable (mathematics)|variable]], it is of the form
:&lt;math&gt;f(x)=ax+b,&lt;/math&gt;
where {{mvar|''a''}} and {{mvar|''b''}} are [[constant (mathematics)|constant]]s, often [[real number]]s. The [[graph of a function|graph]] of such a function of one variable is a nonvertical line. {{mvar|''a''}} is frequently referred to as the slope of the line, and {{mvar|''b''}} as the intercept.

For a function &lt;math&gt;f(x_1, \ldots, x_k)&lt;/math&gt; of any finite number of [[independent variable]]s, the general formula is
:&lt;math&gt;f(x_1, \ldots, x_k) = b + a_1 x_1 + \ldots + a_k x_k&lt;/math&gt;,
and the graph is a [[hyperplane]] of dimension {{nowrap|''k''}}.

A [[constant function]] is also considered linear in this context, as it is a polynomial of degree zero or is the zero polynomial. Its graph, when there is only one independent variable, is a horizontal line.

In this context, the other meaning (a linear map) may be referred to as a [[homogeneous function|homogeneous]] linear function or a [[linear form]].  In the context of linear algebra, this meaning (polynomial functions of degree 0 or 1) is a special kind of [[affine map]].

== As a linear map ==
{{main article|Linear map}}
[[File:Integral as region under curve.svg|thumb|The [[integral]] of a function is a linear map from the vector space of integrable functions to the real numbers.]]

In linear algebra, a linear function is a map ''f'' between two [[vector space]]s that preserves [[vector addition]] and [[scalar multiplication]]:
:&lt;math&gt;f(\mathbf{x} + \mathbf{y}) = f(\mathbf{x}) + f(\mathbf{y}) &lt;/math&gt;
:&lt;math&gt;f(a\mathbf{x}) = af(\mathbf{x}). &lt;/math&gt;
Here {{math|''a''}} denotes a constant belonging to some [[field (mathematics)|field]] {{math|''K''}} of [[Scalar (mathematics)|scalar]]s (for example, the [[real number]]s) and {{math|'''x'''}} and {{math|'''y'''}} are elements of a [[vector space]], which might be {{math|''K''}} itself.

Some authors use "linear function" only for linear maps that take values in the scalar field;&lt;ref&gt;Gelfand 1961&lt;/ref&gt; these are also called [[linear functional]]s.

The "linear functions" of calculus qualify as "linear maps" when (and only when) &lt;math&gt;f([0,\ldots,0]) = 0&lt;/math&gt;, or, equivalently, when the constant &lt;math&gt;b = 0&lt;/math&gt;.  Geometrically, the graph of the function must pass through the origin.

== See also ==
* [[Homogeneous function]]
* [[Nonlinear system]]
* [[Piecewise linear function]]
* [[Linear interpolation]]
* [[Discontinuous linear map]]

== Notes ==
&lt;references/&gt;

== References ==
* Izrail Moiseevich Gelfand (1961), ''Lectures on Linear Algebra'', Interscience Publishers, Inc., New York. Reprinted by Dover, 1989. {{isbn|0-486-66082-6}}
* Thomas S. Shores (2007), ''Applied Linear Algebra and Matrix Analysis'', [[Undergraduate Texts in Mathematics]], Springer. {{isbn|0-387-33195-6}}
*James Stewart (2012), ''Calculus: Early Transcendentals'', edition 7E, Brooks/Cole. {{isbn|978-0-538-49790-9}}
* Leonid N. Vaserstein (2006), "Linear Programming", in Leslie Hogben, ed., ''Handbook of Linear Algebra'', Discrete Mathematics and Its Applications, Chapman and Hall/CRC, chap. 50.  {{isbn|1-584-88510-6}}

== External links ==
{{Polynomials}}

[[Category:Polynomial functions]]</text>
      <sha1>hss78ukdhbcu4o1nks4dyik70cllxns</sha1>
    </revision>
  </page>
  <page>
    <title>List of arbitrary-precision arithmetic software</title>
    <ns>0</ns>
    <id>44390320</id>
    <revision>
      <id>870548337</id>
      <parentid>870548281</parentid>
      <timestamp>2018-11-25T15:16:16Z</timestamp>
      <contributor>
        <ip>2601:240:8480:5041:24DA:A0A4:4E43:713C</ip>
      </contributor>
      <comment>/* Libraries */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14670">This article lists libraries, applications, and other software which enable or support [[arbitrary-precision arithmetic]].

==Libraries==
&lt;!-- TABLE GUIDELINES:
In the "Number type" column just enter one (or more) of the following: Integer, Floats, Rational, Naturals, Reals, Complex floats, Complex rational. If known, the type may be further qualified with the radix of the internal representation – decimal or binary. Don't confuse Rationals with Reals. --&gt;
{| class="sortable wikitable"
|-
!Package-library name
!Number type
!Language
!License
|-
|[[Boost (C++ libraries)|Boost]] Multiprecision Library
|Integers, [[rational data type|rationals]], floats, and complex
|[[C++]] and backends using GMP/MPFR
|[[Boost Software License|Boost]]
|-
|TTMath
|Integers, floats
|[[C++]]
|[[BSD licenses|BSD]]
|-
|[[GNU Multi-Precision Library]] (and [[MPFR]])
|Integers, rationals, and floats
|C and C++ with bindings
|[[GNU Lesser General Public License|LGPL]]
|-
|[[Class Library for Numbers|CLN]]
|Integers, rationals, floats, and complex
|C++
|[[GNU General Public License|GPL]]
|-
|[http://crd-legacy.lbl.gov/~dhbailey/mpdist/ ARPREC]
|Integers, floats, and complex
|C++
|[[BSD licenses|BSD-type]]
|-
|[https://github.com/LuaDist/mapm MAPM], [http://gnuwin32.sourceforge.net/packages/mapm.htm MAPM]
|Integers, decimal and complex floats
|[[C (programming language)|C]] (bindings for [[C++]])
|[[Freeware]]
|-
|[[MPIR (mathematics software)]]
|Integers, rationals, and floats
|C and C++ with bindings
|[[GNU Lesser General Public License|LGPL]]
|-
|[http://www.libtom.net/ LibTomMath]
|Integers
|C
|[[Public domain software|Public Domain]] or [[WTFPL]] ([[dual-licensed]])
|-
|[[libgcrypt]]
|Integers
|C
|LGPL
|-
|[[OpenSSL]]
|Integers
|C
|[https://www.openssl.org/blog/blog/2017/03/22/license/ Apache License v2]
|-
|[https://github.com/hlibc/arbitraire Arbitraire]
|Floats
|C
|[[MIT License]]
|-
|[[mbed TLS]]
|Integers
|C
|[[Apache License|Apache License v2]] and [[GNU General Public License|GPL]]
|-
|[http://jscience.org/ JScience]
|Integers, rationals, and floats
||[[Java (programming language)|Java]]
|[[BSD licenses|BSD-type]]
|-
|[http://krum.rz.uni-mannheim.de/jas JAS]
|Integers, rationals, and complex numbers
|Java
|[[GNU Lesser General Public License|LGPL]]
|-
|[http://jlinalg.sourceforge.net JLinAlg]
|Decimals, rational numbers, and complex numbers
|Java
|[[GNU Lesser General Public License|LGPL]]
|-
|[http://www.apfloat.org/ Apfloat]
|Integers, rationals, floats, and complex numbers
|Java, C++
|[[GNU Lesser General Public License|LGPL]]
|-
|-
|[http://www.wolfgang-ehrhardt.de/mp_intro.html MPArith]
|Integers, rationals, floats, and complex numbers
|Pascal, Delphi
|[[Zlib License|Zlib]]
|-
|[https://sercantutar.github.io/infint/ InfInt]
|Integers
|C++
|[[GNU Lesser General Public License|LGPL]]
|-
|[https://sourceforge.net/projects/bigz bigz]
|Integers, rationals
|[[C (programming language)|C]] (bindings for [[C++]])
|[[BSD licenses|BSD-type]]
|-
|[https://sourceforge.net/projects/cpp-bigint C++ BigInt Class]
|Integers
|C++
|[[GNU General Public License|GPL]]
|-
|[https://github.com/Aatch/ramp ramp]
|Integers
|[[Rust (programming language)|Rust]]
|[[Apache License|Apache License v2]]
|-
|[https://github.com/huonw/float float]
|Floats
|[[Rust (programming language)|Rust]]
|[[Apache License|Apache License v2]]
|-
|[https://stuff.mit.edu/afs/sipb/project/stk/src/STk-2.2.0/Mp/fgmp-1.0b5/ fgmp]
|Integers
|C
|[[Public domain software|Public Domain]]
|-
|[https://github.com/creachadair/imath imath]
|Integers, rationals
|[[ANSI C]]
|[[MIT License|MIT]]
|-
|[https://github.com/suiginsoft/hebimath hebimath]
|Integers, rationals, naturals, floats
|C ([[C99]])
|[[MIT License|MIT]]
|-
|[https://github.com/wbhart/bsdnt bsdnt]
|Integers, naturals
|C
||[[BSD licenses|BSD]] (2-clause)
|-
|[https://ghc.haskell.org/trac/ghc/wiki/ReplacingGMPNotes integer-simple]
|Integers
|[[Haskell (programming language)|Haskell]]
|[http://git.haskell.org/packages/integer-simple.git/blob_plain/HEAD:/LICENSE BSD] (3-clause)
|-
|[https://github.com/def-/nim-bigints bigints]
|Integers
|[[Nim (programming language)|Nim]]
|[https://github.com/def-/nim-bigints/blob/master/bigints.nimble MIT]
|-
|[https://libs.suckless.org/libzahl libzahl] [https://suckless.org/sucks/ (WIP)]
|Integers
|C
|[[ISC license|ISC]]
|-
|[https://github.com/ericlagergren/decimal decimal]
|Decimals
|[[Go (programming language)|Go]]
|[[BSD licenses|BSD]] (3-clause)
|-
|[http://mpmath.org/ mpmath]
|Floats and complex
|[[Python (programming language)|Python]]
|[[BSD licenses|BSD]]
|}

==Stand-alone application software==
Software that supports arbitrary precision computations:

*[[bc (programming language)|bc]] the [[POSIX]] arbitrary-precision arithmetic language that comes standard on most [[Unix-like]] systems.
**[[dc (computer program)|dc]]: "Desktop Calculator" arbitrary-precision RPN calculator that comes standard on most [[Unix-like]] systems.
*[[KCalc]], Linux based scientific calculator
*[[Maxima (software)|Maxima]]: a [[computer algebra system]] which ''bignum'' integers are directly inherited from its implementation language [[Common Lisp]]. In addition, it supports arbitrary-precision floating-point numbers, ''bigfloats''.
*[[Maple (language)|Maple]], [[Mathematica]], and several other [[computer algebra]] software include arbitrary-precision arithmetic. Mathematica employs [[GNU Multi-Precision Library|GMP]] for approximate number computation.
*[[PARI/GP]], an [[Open-source software|open source]] computer algebra system that supports arbitrary precision.
*[[SageMath]], an open-source [[computer algebra system]]
*[[SymPy]], a CAS
*Symbolic Math toolbox ([[MATLAB]])
*[http://oroptimizer.com/smartxml SmartXML], a free programming language with integrated development environment (IDE) for mathematical calculations. Variables of BigNumber type can be used, or regular numbers can be converted to big numbers using conversion operator # (e.g., #2.3^2000.1). SmartXML big numbers can have up to 100,000,000 decimal digits and up to 100,000,000 whole digits.
**The SmartXML program file editor supports [[autocomplete|code completion]] and most typing is replaced by code completion. Only minimal typing is required when writing a program. Other than constant values, such as 5 or 'Some Text', everything else is supported by code completion.
**Operations with big numbers are done using operators, such as +, -, *, /, ^, etc. (e.g., (#2.3^2000.3 / #2.3^1999.3 - 1)).
**SmartXML maintains pool of big numbers, from which big numbers are retrieved (i.e., when there are used in code), and the numbers are released back to the pool, when a big number goes out of scope. The programmer does not have to worry about retrieving or releasing big numbers, since it is done internally by SmartXML.
*[[Windows Calculator]], since Windows 98, uses arbitrary precision for basic operations (addition, subtraction, multiplication, division) and 32 digits of precision for advanced operations (square root, transcendental functions).

==Languages==
Programming languages that supports arbitrary precision computations, either built-in, or in the standard library of the language:

*[[Agda (programming language)|Agda]]: the ''BigInt'' datatype on [https://web.archive.org/web/20120722024513/http://www.cs.st-andrews.ac.uk/~eb/epic.php Epic] backend implements arbitrary-precision arithmetic.
*[[Common Lisp]]: The ANSI Common Lisp standard supports arbitrary precision integer, ratio, and complex numbers.
*[[C Sharp (programming language)|C#]]: [http://msdn.microsoft.com/en-us/library/system.numerics.biginteger%28v=vs.100%29.aspx System.Numerics.BigInteger], from [[.NET Framework]] 4.0
*[[ColdFusion]]: the built-in ''PrecisionEvaluate()'' function evaluates one or more string expressions, dynamically, from left to right, using BigDecimal precision arithmetic to calculate the values of arbitrary precision arithmetic expressions.
*[[D (programming language)|D]]: standard library module ''[http://dlang.org/phobos/std_bigint.html std.bigint]''
*[[Dart (programming language)|Dart]]: the built-in ''int'' datatype implements arbitrary-precision arithmetic.
*[[Erlang (programming language)|Erlang]]: the built-in ''Integer'' datatype implements arbitrary-precision arithmetic.
*[[Go (programming language)|Go]]: the standard library package ''[http://golang.org/pkg/math/big/ math/big]'' implements arbitrary-precision integers (''Int'' type), rational numbers (''Rat'' type), and floating-point numbers (''Float'' type)
*[[GNU Guile|Guile]]: the built-in ''exact'' numbers are of arbitrary precision. Example: (expt 10 100) produces the expected (large) result. Exact numbers also include rationals, so (/ 3 4) produces 3/4. One of the languages implemented in Guile is [[Scheme (programming language)|Scheme]].
*[[Haskell (programming language)|Haskell]]: the built-in ''Integer'' datatype implements arbitrary-precision arithmetic and the standard ''Data.Ratio'' module implements rational numbers.
*[[Idris (programming language)|Idris]]: the built-in ''Integer'' datatype implements arbitrary-precision arithmetic.
*[[ISLISP]]: The ISO/IEC 13816:1997(E) [[ISLISP]] standard supports arbitrary precision integer numbers.
*[[J (programming language)|J]]: built-in ''extended precision''
*[[Java (programming language)|Java]]: [http://docs.oracle.com/javase/8/docs/api/java/math/BigInteger.html Class java.math.BigInteger] (integer), [http://docs.oracle.com/javase/8/docs/api/java/math/BigDecimal.html Class java.math.BigDecimal] (decimal)
*[[JavaScript]]: the [//code.google.com/p/gwt-math/ gwt-math] library provides an interface to java.math.BigDecimal, and libraries such as [https://archive.is/20130127215203/http://leemon.com/crypto/BigInt.html BigInt] and [http://crunch.secureroom.net/ Crunch] support arbitrary-precision integers.
*[[Julia (programming language)|Julia]]: the built-in "[http://docs.julialang.org/en/release-0.2/stdlib/base/#bigfloats BigFloat]" and "BigInt" types provide arbitrary-precision floating point and integer arithmetic respectively.
*[[newRPL]]: integers and floats can be of arbitrary precision (up to at least 2000 digits); maximum number of digits configurable (default 32 digits)
*[[Nim (programming language)|Nim]]: [https://github.com/def-/nim-bigints bigints] and multiple [https://nimble.directory/search?query=GMP GMP bindings].
*[[OCaml]]: The [https://archive.is/20130213110842/http://caml.inria.fr/pub/docs/manual-ocaml/manual036.html Num] library supports arbitrary-precision integers and rationals.
*[[OpenLisp]]: supports arbitrary precision integer numbers.
*[[Perl]]: The [http://perldoc.perl.org/bignum.html bignum] and [http://perldoc.perl.org/bigrat.html bigrat] pragmas provide BigNum and BigRational support for Perl.
*[[Perl6]]: [http://rakudo.org Rakudo] supports [//doc.perl6.org/type/Int Int] and [//doc.perl6.org/type/FatRat FatRat] data types that promote to arbitrary-precision integers and rationals.
*[[PHP]]: The [//php.net/manual/en/book.bc.php BC Math] module provides arbitrary precision mathematics.
*[[PicoLisp]]: supports arbitrary precision integers.
*[[Pike (programming language)|Pike]]: the built-in ''int'' type will silently change from machine-native integer to arbitrary precision as soon as the value exceeds the former's capacity.
*[[Prolog]]: ISO standard compatible Prolog systems can check the Prolog flag "bounded". Most of the major Prolog systems support arbitrary precision integer numbers.
*[[Python (programming language)|Python]]: the built-in ''int'' (3.x) / ''long'' (2.x) integer type is of arbitrary precision. The ''Decimal'' class in the standard library module ''decimal'' has user definable precision and limited mathematical operations (exponentiation, square root, etc. but no trigonometric functions). The ''Fraction'' class in the module ''fractions'' implements rational numbers. More extensive arbitrary precision floating point arithmetic is available with the third-party "mpmath" and "bigfloat" packages.
*[[Racket (programming language)|Racket]]: the built-in ''exact'' numbers are of arbitrary precision. Example: (expt 10 100) produces the expected (large) result. Exact numbers also include rationals, so (/ 3 4) produces 3/4.
*[[Rexx]]: variants including Open Object Rexx and NetRexx
*[[RPL (programming language)|RPL]] (only on [[HP 49/50 series]] in ''exact mode''): calculator treats numbers entered without decimal point as integers rather than floats; integers are of arbitrary precision only limited by the available memory.
*[[Ruby (programming language)|Ruby]]: the built-in ''Bignum'' integer type is of arbitrary precision. The ''BigDecimal'' class in the standard library module ''bigdecimal'' has user definable precision.
*[[Scheme (programming language)|Scheme]]: R&lt;sup&gt;5&lt;/sup&gt;RS encourages, and R&lt;sup&gt;6&lt;/sup&gt;RS requires, that exact integers and exact rationals be of arbitrary precision.
*[[Scala (programming language)|Scala]]: [http://www.scala-lang.org/api/current/index.html#scala.math.BigInt Class BigInt] and [http://www.scala-lang.org/api/current/index.html#scala.math.BigDecimal Class BigDecimal].
*[[Seed7]]: [http://seed7.sourceforge.net/manual/types.htm#bigInteger bigInteger] and [http://seed7.sourceforge.net/manual/types.htm#bigRational bigRational].
*[[Self (programming language)|Self]]: arbitrary precision integers are supported by the built-in ''bigInt'' type.
*[[Smalltalk]]: variants including [[Squeak]], [[Smalltalk/X]], [[GNU Smalltalk]], [[Dolphin Smalltalk]], etc.
*[[Standard ML]]: The optional built-in [http://www.standardml.org/Basis/int-inf.html IntInf] structure implements the ''INTEGER'' signature and supports arbitrary-precision integers.
*[[Wolfram Language]], like [[Mathematica]], employs GMP for approximate number computation.
*[http://oroptimizer.com/smartxml SmartXML], a free programming language with integrated development environment (IDE) for mathematical calculations. Variables of BigNumber type can be used, or regular numbers can be converted to big numbers using conversion operator # (e.g., #2.3^2000.1). SmartXML big numbers can have up to 100,000,000 decimal digits and up to 100,000,000 whole digits.

==Online calculators==
For once-off calculations. Runs on server or in browser. No installation or compilation required.
*https://apfloat.appspot.com/ arbitrary (same as input)
*https://www.mathsisfun.com/calculator-precision.html 200 places
*http://birrell.org/andrew/ratcalc/ arbitrary; select rational or fixed-point and number of places

{{DEFAULTSORT:Arbitrary precision arithmetic software}}
[[Category:Lists of software]]
[[Category:Computer arithmetic]]</text>
      <sha1>0cozktedoyqz3ndsxkvjn3blq7w6o72</sha1>
    </revision>
  </page>
  <page>
    <title>Mean of a function</title>
    <ns>0</ns>
    <id>43258526</id>
    <revision>
      <id>816792787</id>
      <parentid>816760387</parentid>
      <timestamp>2017-12-23T18:53:32Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <comment>Reverted to revision 622163417 by [[Special:Contributions/Yobot|Yobot]] ([[User talk:Yobot|talk]]): [[WP:FRINGE]], possible [[WP:COI]], uses only primary sources and appears to be self-promotion. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2686">In [[calculus]], and especially [[multivariable calculus]], the '''mean of a function''' is loosely defined as the average value of the function over its [[domain (mathematics)|domain]]. In one variable, the mean of a function ''f''(''x'') over the interval (''a,b'') is defined by

: &lt;math&gt;\bar{f}=\frac{1}{b-a}\int_a^bf(x)\,dx.&lt;/math&gt;

Recall that a defining property of the average value &lt;math&gt;\bar{y}&lt;/math&gt; of finitely many numbers &lt;math&gt;y_1, y_2, \dots, y_n&lt;/math&gt;
is that &lt;math&gt;n\bar{y} = y_1 + y_2 + \cdots + y_n&lt;/math&gt;. In other words, &lt;math&gt;\bar{y}&lt;/math&gt; is the ''constant'' value which when
''added'' to itself &lt;math&gt;n&lt;/math&gt; times equals the result of adding the &lt;math&gt;n&lt;/math&gt; terms of &lt;math&gt;y_i&lt;/math&gt;. By analogy, a
defining property of the average value &lt;math&gt;\bar{f}&lt;/math&gt; of a function over the interval &lt;math&gt;[a,b]&lt;/math&gt; is that

: &lt;math&gt;\int_a^b\bar{f}\,dx = \int_a^bf(x)\,dx&lt;/math&gt;

In other words, &lt;math&gt;\bar{f}&lt;/math&gt; is the ''constant'' value which when ''integrated'' over &lt;math&gt;[a,b]&lt;/math&gt; equals the result of
integrating &lt;math&gt;f(x)&lt;/math&gt; over &lt;math&gt;[a,b]&lt;/math&gt;. But by the second [[fundamental theorem of calculus]], the integral of a constant
&lt;math&gt;\bar{f}&lt;/math&gt; is just

: &lt;math&gt;\int_a^b\bar{f}\,dx = \bar{f}x\bigr|_a^b = \bar{f}b - \bar{f}a = (b - a)\bar{f}&lt;/math&gt;

See also the [[Mean value theorem#First mean value theorem for integration|first mean value theorem for integration]], which guarantees
that if &lt;math&gt;f&lt;/math&gt; is continuous then there exists a point &lt;math&gt;c \in (a, b)&lt;/math&gt; such that

: &lt;math&gt;\int_a^bf(x)\,dx = f(c)(b - a)&lt;/math&gt;

The point &lt;math&gt;f(c)&lt;/math&gt; is called the mean value of &lt;math&gt;f(x)&lt;/math&gt; on &lt;math&gt;[a,b]&lt;/math&gt;. So we write
&lt;math&gt;\bar{f} = f(c)&lt;/math&gt; and rearrange the preceding equation to get the above definition.

In several variables, the mean over a [[relatively compact]] [[neighborhood (mathematics)|domain]] ''U'' in a [[Euclidean space]] is defined by

:&lt;math&gt;\bar{f}=\frac{1}{\hbox{Vol}(U)}\int_U f.&lt;/math&gt;

This generalizes the '''arithmetic''' mean. On the other hand, it is also possible to generalize the '''geometric''' mean to functions by defining the geometric mean of ''f'' to be

:&lt;math&gt;\exp\left(\frac{1}{\hbox{Vol}(U)}\int_U \log f\right).&lt;/math&gt;

More generally, in [[measure theory]] and [[probability theory]], either sort of mean plays an important role. In this context, [[Jensen's inequality]] places sharp estimates on the relationship between these two different notions of the mean of a function.

There is also a ''harmonic average'' of functions and a ''quadratic average'' (or ''root mean square'') of functions.

==See also==
*[[Mean]]

[[Category:Means]]
[[Category:Calculus]]</text>
      <sha1>o68h2pfmni83v8omzkh7m1k8qx5slnn</sha1>
    </revision>
  </page>
  <page>
    <title>Minimal algebra</title>
    <ns>0</ns>
    <id>55000798</id>
    <revision>
      <id>871741052</id>
      <parentid>808604266</parentid>
      <timestamp>2018-12-03T03:41:30Z</timestamp>
      <contributor>
        <username>PVTrung</username>
        <id>29441267</id>
      </contributor>
      <comment>Classification of minimal algebras</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1957">{{orphan|date=August 2017}}
{{unreferenced|date=August 2017}}

A '''minimal algebra''' is a finite [[Algebraic_structure#Universal_algebra|algebra]] with more than one element, in which every non-constant unary polynomial is a permutation on its domain. A minimal algebra &lt;math&gt;\mathbb M &lt;/math&gt; falls into one of the following types &lt;ref name="unarypolynomial"&gt;{{cite journal |last1=Pálfy |first1=P. P. |title=Unary polynomials in algebras. I |journal=Algebra Universalis |date=1984 |volume=18 |issue=3 |pages=262-273}}&lt;/ref&gt; &lt;ref&gt;{{cite book |last1=Hobby |first1=David |last2=McKenzie |first2=Ralph |title=The structure of finite algebras |date=1988 |publisher=American Mathematical Society |location=Providence, RI |isbn=0-8218-5073-3 |page=xii+203 pp}}&lt;/ref&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;math&gt; \mathbb M &lt;/math&gt; is of type &lt;math&gt; \bf 1&lt;/math&gt;, or '''unary type''', iff &lt;math&gt;{\rm Pol} ~\mathbb M={\rm Pol} \langle M,G\rangle&lt;/math&gt;, where &lt;math&gt; M &lt;/math&gt; denotes the domain of &lt;math&gt; \mathbb M &lt;/math&gt;, &lt;math&gt; \rm Pol~ \mathbb A &lt;/math&gt; denotes the set of all polynomials of an algebra &lt;math&gt; \mathbb A &lt;/math&gt; and &lt;math&gt; G &lt;/math&gt; is a [[subgroup]] of the [[symmetric group]] over &lt;math&gt; M &lt;/math&gt;.
 &lt;/li&gt;
&lt;li&gt;
&lt;math&gt; \mathbb M &lt;/math&gt; is of type &lt;math&gt;\bf 2 &lt;/math&gt;, or '''affine type''', iff &lt;math&gt; \mathbb M &lt;/math&gt; is polynomially equivalent to a [[vector space]].
&lt;/li&gt;
&lt;li&gt;
&lt;math&gt;\mathbb M&lt;/math&gt; is of type &lt;math&gt;\bf 3&lt;/math&gt;, or '''Boolean type''', iff &lt;math&gt;\mathbb M&lt;/math&gt; is polynomially equivalent to a two-element [[Boolean algebra]].
&lt;/li&gt;
&lt;li&gt;
&lt;math&gt;\mathbb M &lt;/math&gt; is of type &lt;math&gt; \bf  4 &lt;/math&gt;, or '''lattice type''', iff &lt;math&gt;\mathbb M&lt;/math&gt; is polynomially equivalent to a two-element [[Lattice_(order)|lattice]].
&lt;/li&gt;
&lt;li&gt;
&lt;math&gt;\mathbb M&lt;/math&gt; is of type &lt;math&gt;\bf 5&lt;/math&gt;, or '''semilattice type''', iff &lt;math&gt;\mathbb M&lt;/math&gt; is polynomially equivalent to a two-element [[semilattice]].
&lt;/li&gt;
&lt;/ul&gt;
==References==
[[Category:Algebra]]</text>
      <sha1>3bqrgy1juan6do9kvmwhjlguekp9t6b</sha1>
    </revision>
  </page>
  <page>
    <title>Mixed mating model</title>
    <ns>0</ns>
    <id>24065513</id>
    <revision>
      <id>750836625</id>
      <parentid>724549696</parentid>
      <timestamp>2016-11-21T23:06:05Z</timestamp>
      <contributor>
        <username>Choess</username>
        <id>245519</id>
      </contributor>
      <minor/>
      <comment>link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1750">The '''mixed mating model''' is a [[mathematical model]] that describes the [[mating system]] of a [[plant]] [[population]] in terms of the degree of [[self-fertilisation]] present. It is a fairly simplistic model, employing several simplifying assumptions, most notably the assumption that every fertilisation event may be classed as either self-fertilisation, or [[outcrossing]] with a completely [[random]] mate. Thus the only model [[parameter]] to be [[parameter estimation|estimated]] is the [[probability]] of self-fertilisation.&lt;ref name="Brown 1989"&gt;{{cite book | author = Brown, A. H. D.| year = 1989 | chapter = Isozyme analysis of plant mating systems |editor1=[[Soltis, D. E.]] |editor2=[[Soltis, P. S.]] | title = Isozymes in Plant Biology | pages = 73–86 | publisher = Dioscorides Press | location = Portland|display-authors=etal}}&lt;/ref&gt;

The mixed mating model originated in the 1910s, with [[plant breeding|plant breeders]] who were seeking evidence of [[outcrossing]] contamination of self-pollinating [[crop]]s, but a formal description of the model and its parameter estimation was not published until 1951. The model is still in common use today, though a number of more complex models are also now in use. For example, a weakness of the model lies in its assumption that [[inbreeding]] occurs only as a result of self-fertilisation; in reality, inbreeding may also occur through outcrossing between closely related individuals. The [[effective selfing model]] relaxes this assumption by seeking also to estimate the degree of shared ancestry of outcrossing mates.&lt;ref name="Brown 1989"/&gt;

==References==
{{reflist}}

[[Category:Plant sexuality]]
[[Category:Mating systems]]
[[Category:Mathematical modeling]]


{{botany-stub}}</text>
      <sha1>d47zkcqrh2q4hm6e8ghm3hiounvakuu</sha1>
    </revision>
  </page>
  <page>
    <title>Module spectrum</title>
    <ns>0</ns>
    <id>41276205</id>
    <revision>
      <id>691549501</id>
      <parentid>687981945</parentid>
      <timestamp>2015-11-20T15:36:10Z</timestamp>
      <contributor>
        <username>Swpb</username>
        <id>1921264</id>
      </contributor>
      <comment>added [[Category:Homotopy theory]]; removed {{uncategorized}} using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1096">In algebra, a '''module spectrum''' is a [[spectrum (topology)|spectrum]] with an action of a [[ring spectrum]]; it generalizes a [[module (mathematics)|module]] in abstract algebra.

The ∞-category of (say right) module spectra is [[stable ∞-category|stable]]; hence, it can be considered as either analog or generalization of the [[derived category]] of modules over a ring.

== K-theory ==
Lurie defines the [[K-theory]] of a ring spectrum ''R'' to be the [[K-theory of the ∞-category]] of [[perfect module]]s over ''R'' (a perfect module being defined as a compact object in the ∞-category of module spectra.)&lt;!--
Note this ''does not'' generalize [[Q-construction|Quillen's K-theory]] of a ring.;&lt;ref&gt;Warning 5 in http://www.math.harvard.edu/~lurie/281notes/Lecture20-Lower.pdf&lt;/ref&gt; it is rather a generalization of a [[Waldhausen K-theory]].--&gt;

== See also ==
*[[G-spectrum]]

== References ==
{{Reflist}}
*J. Lurie, [http://www.math.harvard.edu/~lurie/281notes/Lecture19-Rings.pdf Lecture 19: Algebraic K-theory of Ring Spectra]


{{algebra-stub}}



[[Category:Homotopy theory]]</text>
      <sha1>990cyrvyg0dmlb4fhplai0bkdzixyu2</sha1>
    </revision>
  </page>
  <page>
    <title>Mosco convergence</title>
    <ns>0</ns>
    <id>9755509</id>
    <revision>
      <id>828629150</id>
      <parentid>655701964</parentid>
      <timestamp>2018-03-03T19:38:17Z</timestamp>
      <contributor>
        <username>Jmath666</username>
        <id>3550640</id>
      </contributor>
      <comment>In finite dimensional spaces, Mosco convergence coincides with [[epi-convergence]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3365">In [[mathematical analysis]], '''Mosco convergence''' is a notion of convergence for [[functional (mathematics)|functionals]] that is used in [[nonlinear|nonlinear analysis]] and [[set-valued analysis]]. It is a particular case of [[Γ-convergence]]. Mosco convergence is sometimes phrased as “weak Γ-liminf and strong Γ-limsup” convergence since it uses both the [[Weak_topology#The_strong_and_weak_topologies|weak and strong topologies]] on a [[topological vector space]] ''X''. In finite dimensional spaces, Mosco convergence coincides with [[epi-convergence]].

''Mosco convergence'' is named after [[Italy|Italian]] [[mathematician]] [[Umberto Mosco]], a current Harold J. Gay&lt;ref&gt;http://www.wpi.edu/Campus/Faculty/Awards/Professorship/gayprofship.html&lt;/ref&gt; professor of mathematics at [[Worcester Polytechnic Institute]].

==Definition==

Let ''X'' be a topological vector space and let ''X''&lt;sup&gt;∗&lt;/sup&gt; denote the [[continuous dual space|dual space]] of [[continuous linear functional]]s on ''X''. Let ''F''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;:&amp;nbsp;''X''&amp;nbsp;→&amp;nbsp;[0,&amp;nbsp;+∞] be functionals on ''X'' for each ''n''&amp;nbsp;=&amp;nbsp;1, 2, ... The sequence (or, more generally, [[net (topology)|net]]) (''F''&lt;sub&gt;''n''&lt;/sub&gt;) is said to '''Mosco converge''' to another functional ''F''&amp;nbsp;:&amp;nbsp;''X''&amp;nbsp;→&amp;nbsp;[0,&amp;nbsp;+∞] if the following two conditions hold:

* lower bound inequality: for each sequence of elements ''x''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;∈&amp;nbsp;''X'' [[weak convergence of measures|converging weakly]] to ''x''&amp;nbsp;∈&amp;nbsp;''X'',

::&lt;math&gt;\liminf_{n \to \infty} F_{n} (x_{n}) \geq F(x);&lt;/math&gt;

* upper bound inequality: for every ''x''&amp;nbsp;∈&amp;nbsp;''X'' there exists an approximating sequence of elements ''x''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;∈&amp;nbsp;''X'', converging strongly to ''x'', such that

::&lt;math&gt;\limsup_{n \to \infty} F_{n} (x_{n}) \leq F(x).&lt;/math&gt;

Since lower and upper bound inequalities of this type are used in the definition of Γ-convergence, Mosco convergence is sometimes phrased as “weak Γ-liminf and strong Γ-limsup” convergence.  Mosco convergence is sometimes abbreviated to '''M-convergence''' and denoted by

:&lt;math&gt;\mathop{\text{M-lim}}_{n \to \infty} F_{n} = F \text{ or } F_{n} \xrightarrow[n \to \infty]{\mathrm{M}} F.&lt;/math&gt;

==References==

* {{cite journal | last=Mosco | first=Umberto | title=Approximation of the solutions of some variational inequalities | journal=Ann. Scuola Normale Sup. | location=Pisa | volume=21 | year=1967 | pages=373&amp;ndash;394 }}
* {{cite journal | last=Mosco | first=Umberto | title=Convergence of convex sets and of solutions of variational inequalities | journal=Advances in Mathematics | volume=3 | year=1969 | pages=510&amp;ndash;585 | doi=10.1016/0001-8708(69)90009-7 | issue=4 }}
* {{cite journal | last=Borwein | first=Jonathan M. |author2=Fitzpatrick, Simon | year=1989 | title=Mosco convergence and the Kadec property | journal=Proc. Amer. Math. Soc.| volume=106 | pages=843&amp;ndash;851 | doi=10.2307/2047444 | issue=3 | publisher=American Mathematical Society | jstor=2047444 }}
* {{Cite web  | last = Mosco | first = Umberto  | title = Worcester Polytechnic Institute Faculty Directory | url = http://www.wpi.edu/academics/facultydir/uxm.html | publisher =  | accessdate = }}

== Notes ==
{{Reflist}}

[[Category:Calculus of variations]]
[[Category:Variational analysis]]</text>
      <sha1>2jjnx4e666kkpmj1qkhpyuqnbdm54fh</sha1>
    </revision>
  </page>
  <page>
    <title>Multibody simulation</title>
    <ns>0</ns>
    <id>40547030</id>
    <revision>
      <id>865504767</id>
      <parentid>865504075</parentid>
      <timestamp>2018-10-24T10:02:15Z</timestamp>
      <contributor>
        <username>Widefox</username>
        <id>1588193</id>
      </contributor>
      <minor/>
      <comment>/* top */ bold alt article name per MOS</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5666">'''Multibody simulation''' ('''MBS''') is a method of [[computer simulation|numerical simulation]] in which [[multibody system]]s are composed of various [[rigid body|rigid]] or [[elasticity (physics)|elastic]] bodies. Connections between the bodies can be modeled with [[kinematics|kinematic]] constraints (such as joints) or force elements (such as spring dampers). Unilateral constraints and [[friction|Coulomb-friction]] can also be used to model frictional contacts between bodies.&lt;ref&gt;{{cite web|last=Schindler|first=Thorsten|title=Multi-Body Simulation|url=http://www.amm.mw.tum.de/index.php?L=1&amp;id=34|work=Courses: Technische Universität München|publisher=Technische Universität München|accessdate=20 August 2013}}&lt;/ref&gt;
Multibody simulation is a useful tool for conducting motion analysis. It is often used during [[new product development|product development]] to evaluate characteristics of comfort, safety, and performance.&lt;ref&gt;{{cite web|last=Larsson|first=Tobias|title=Multibody Dynamic Simulation  in Product Development|url=http://pure.ltu.se/portal/files/155880/LTU-DT-0107-SE.pdf|work=Division of Computer Aided Design  Department of Mechanical Engineering  Luleå University of Technology|publisher=Luleå University of Technology|accessdate=29 August 2013}}&lt;/ref&gt;  For example, multibody simulation has been widely used since the 1990s as a component of [[automotive suspension design]].&lt;ref&gt;{{cite book|last=Blundell|first=Mike and Damian Harty|title=The Multibody Systems Approach to Vehicle Dynamics|year=2004|publisher=Elsevier Butterworth-Heinemann|location=Oxford, MA|isbn=0750651121|url=https://books.google.com/books?id=FlBgF8w9CegC&amp;pg=PP2&amp;dq=multibody+simulation+automotive+suspension+design#v=onepage&amp;q=multibody%20simulation%20automotive%20suspension%20design&amp;f=false}}&lt;/ref&gt;  It can also be used to study issues of [[biomechanics]], with applications including [[sports medicine]], [[osteopathy]], and human-machine interaction.&lt;ref&gt;{{cite journal|last=Al Nazar|first=R.|author2=T. Rantalainen |author3=A. Heinonen |author4=H. Sievänend |author5=A. Mikkola |title=Flexible multibody simulation approach in the analysis of tibial strain during walking|journal=Journal of Biomechanics|year=2008|volume=41|issue=5|pages=1036–1043|doi=10.1016/j.jbiomech.2007.12.002|pmid=18191865}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=O’Riordain|first=K. |author2=P.M. Thomas |author3=J.P. Phillips |author4=M.D. Gilchrist|title=Reconstruction of real world head injury accidents resulting from falls using multibody dynamics|journal=Clinical Biomechanics|date=August 2003|volume=18|issue=7|pages=590–600|doi=10.1016/S0268-0033(03)00111-6|pmid=12880706}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=Industrial Sectors: Biomechanics|url=http://www.simpack.com/industrial_sectors_biomechanics.html|work=SIMPACK|publisher=SIMPACK AG|accessdate=27 August 2013}}&lt;/ref&gt;

The heart of any multibody simulation software program is the [[solver]]. The solver is a set of computation [[algorithm]]s that solve equations of motion. Types of components that can be studied through multibody simulation range from electronic [[control systems]] to noise, vibration and harshness.&lt;ref&gt;{{cite web|title=Definition of MultiBody Dynamics Simulation|url=http://www.functionbay.de/|publisher=Function Bay: Recurdyn|accessdate=20 August 2013}}&lt;/ref&gt;  Complex models such as engines are composed of individually designed components, e.g. [[piston]]s/[[crankshaft]]s.&lt;ref&gt;{{cite web|title=SimMechanics Introduction|url=http://www.mathworks.com/videos/simmechanics-introduction-69809.html|work=MathWorks|accessdate=20 August 2013}}&lt;/ref&gt;

The MBS process often can be divided in 5 main activities. The first activity of the MBS process chain is the” 3D CAD master model”, in which product developers, designers and engineers are using the CAD system to generate a CAD model and its assembly structure related to given specifications. This 3D CAD master model is converted during the activity “Data transfer” to the MBS input data formats i.e. [[ISO 10303|STEP]]. The “MBS Modeling” is the most complex activity in the process chain. Following rules and experiences, the 3D model in MBS format, multiple boundaries, kinematics, forces, moments or degrees of freedom are used as input to generate the MBS model. Engineers have to use MBS software and their knowledge and skills in the field of engineering mechanics and machine dynamics to build the MBS model including joints and links. The generated MBS model is used during the next activity “Simulation”. Simulations, which are specified by time increments and boundaries like starting conditions are run by MBS Software i.e. MSC ADAMS. The last activity is the “Analysis and evaluation”. Engineers use case-dependent directives to analyze and evaluate moving paths, speeds, accelerations, forces or moments. The results are used to enable releases or to improve the MBS model, in case the results are insufficient. One of the most important benefits of the MBS process chain is the usability of the results to optimize the 3D CAD master model components. Due to the fact that the process chain enables the optimization of component design, the resulting loops can be used to achieve a high level of design and MBS model optimization in an iterative process.&lt;ref&gt;Faath, A. and Anderl, R. Interdisciplinary and Consistent Use of a 3D CAD Model for CAx Education in Engineering Studies. In ''ASME 2016 International Mechanical Engineering Congress and Exposition'' (pp. V005T06A031-V005T06A031). American Society of Mechanical Engineers. November 2016&lt;/ref&gt;

== References ==

{{reflist}}

[[Category:Dynamical systems]]</text>
      <sha1>8o1kzaezly1daqts94jw4qeuftvay9c</sha1>
    </revision>
  </page>
  <page>
    <title>One-time pad</title>
    <ns>0</ns>
    <id>22210</id>
    <revision>
      <id>870909505</id>
      <parentid>870638684</parentid>
      <timestamp>2018-11-27T19:04:54Z</timestamp>
      <contributor>
        <username>GünniX</username>
        <id>237572</id>
      </contributor>
      <comment>/* Notes */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="49948">{{Distinguish|One-time password}}
[[File:NSA DIANA one time pad.tiff|thumb|A format of one-time pad used by the U.S. [[National Security Agency]], code named DIANA. The table on the right is an aid for converting between plaintext and ciphertext using the characters at left as the key.]]

In [[cryptography]], the '''one-time pad''' ('''OTP''') is an [[encryption]] technique that cannot be [[cryptanalysis|cracked]], but requires the use of a one-time [[pre-shared key]] the same size as, or longer than, the message being sent. In this technique, a [[plaintext]] is paired with a random secret [[key (cryptography)|key]] (also referred to as ''a one-time pad''). Then, each bit or character of the plaintext is encrypted by combining it with the corresponding bit or character from the pad using [[Modular arithmetic|modular addition]]. If the key is truly [[random]], is at least as long as the plaintext, is never reused in whole or in part, and is kept completely [[secret]], then the resulting [[ciphertext]] will be impossible to decrypt or break.&lt;ref name="Numbers Stations"&gt;{{cite web |url=http://www.numbers-stations.com/intro |title=Intro to Numbers Stations |accessdate=13 September 2014 |deadurl=yes |archiveurl=https://web.archive.org/web/20141018031055/http://www.numbers-stations.com/intro |archivedate=18 October 2014 |df=dmy-all }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.cryptomuseum.com/crypto/otp.htm |title=One-Time Pad (OTP) |publisher=Cryptomuseum.com |accessdate=2014-03-17 |deadurl=yes |archiveurl=https://web.archive.org/web/20140314175211/http://www.cryptomuseum.com/crypto/otp.htm |archivedate=2014-03-14 |df= }}&lt;/ref&gt; It has also been proven that any cipher with the perfect secrecy property must use keys with effectively the same requirements as OTP keys.&lt;ref name="shannon"&gt;{{cite journal| last=Shannon| first=Claude| title=Communication Theory of Secrecy Systems| journal=Bell System Technical Journal| volume=28| issue=4| pages=656–715| year=1949| doi=10.1002/j.1538-7305.1949.tb00928.x}}&lt;/ref&gt;  Digital versions of one-time pad ciphers have been used by nations for some critical [[diplomatic communications|diplomatic]] and [[military communication]], but the problems of secure [[key distribution]] have made them impractical for most applications.

First described by [[Frank Miller (cryptographer)|Frank Miller]] in 1882,&lt;ref&gt;{{cite book|last=Miller|first=Frank|title=Telegraphic code to insure privacy and secrecy in the transmission of telegrams|year=1882|publisher=C.M. Cornwell}}&lt;/ref&gt;&lt;ref name="BELLOVIN1"&gt;{{cite journal |journal = Cryptologia |last = Bellovin |first = Steven M. |title = Frank Miller: Inventor of the One-Time Pad |volume = 35 |issue = 3 |issn = 0161-1194 |year = 2011 |doi = 10.1080/01611194.2011.583711 |pages = 203–222 |url = http://www.tandfonline.com/doi/abs/10.1080/01611194.2011.583711 |deadurl = no |archiveurl = https://web.archive.org/web/20150917025158/http://www.tandfonline.com/doi/abs/10.1080/01611194.2011.583711 |archivedate = 2015-09-17 |df =  }}&lt;/ref&gt; the one-time pad was re-invented in 1917. On July 22, 1919, U.S. Patent 1,310,719 was issued to [[Gilbert Vernam|Gilbert S. Vernam]] for the [[Exclusive or|XOR]] operation used for the encryption of a one-time pad.&lt;ref name=Google&gt;{{cite web|url=http://www.google.com/patents/US1310719|website=google.com|access-date=3 February 2016|title='Secret signaling system patent' on Google.Com|deadurl=no|archiveurl=https://web.archive.org/web/20160311030400/http://www.google.com/patents/US1310719|archivedate=11 March 2016|df=}}&lt;/ref&gt; Derived from his ''Vernam cipher'', the system was a cipher that combined a message with a key read from a [[punched tape]]. In its original form, Vernam's system was vulnerable because the key tape was a loop, which was reused whenever the loop made a full cycle. One-time use came later, when [[Joseph Mauborgne]] recognized that if the key tape were totally random, then [[cryptanalysis]] would be impossible.&lt;ref&gt;{{cite book| last=Kahn| first=David| title=[[The Codebreakers]]| publisher=[[Macmillan Publishers (United States)|Macmillan]]| year=1996| isbn=0-684-83130-9| pages=397&amp;ndash;8 |authorlink=David Kahn (writer)}}&lt;/ref&gt;

The "pad" part of the name comes from early implementations where the key material was distributed as a [[wikt:pad#Noun|pad]] of paper, so that the top sheet could be easily torn off and destroyed after use. For ease of concealment, the pad was sometimes reduced to such a small size that a powerful [[loupe|magnifying glass]] was required to use it. The [[KGB]] used pads of such size that they could fit in the palm of a hand,&lt;ref&gt;{{cite web| url=http://www.ranum.com/security/computer_security/papers/otp-faq| title=One-Time-Pad (Vernam's Cipher) Frequently Asked Questions, with photo| accessdate=2006-05-12| deadurl=no| archiveurl=https://web.archive.org/web/20060507212354/http://www.ranum.com/security/computer_security/papers/otp-faq/| archivedate=2006-05-07| df=}}&lt;/ref&gt; or in a [[walnut]] shell.&lt;ref&gt;{{cite web| url=http://users.telenet.be/d.rijmenants/pics/otpbooklet1.jpg| language=German| title=Chiffriergerätebau : One-Time-Pad, with photo| author=Savory, Stuart| year=2001| accessdate=2006-07-24| deadurl=no| archiveurl=https://web.archive.org/web/20110530202013/http://users.telenet.be/d.rijmenants/pics/otpbooklet1.jpg| archivedate=2011-05-30| df=}}&lt;/ref&gt; To increase security, one-time pads were sometimes printed onto sheets of highly flammable [[nitrocellulose]], so that they could be quickly burned after use.

There is some ambiguity to the term "Vernam cipher" because some sources use "Vernam cipher" and "one-time pad" synonymously, while others refer to any additive [[stream cipher]] as a "Vernam cipher", including those based on a [[cryptographically secure pseudorandom number generator]] (CSPRNG).&lt;ref name="kahn"&gt;{{cite book| last=Kahn| first=David| title=[[The Codebreakers]]| publisher=[[Macmillan Publishers (United States)|Macmillan]]| year=1967| isbn=0-684-83130-9| pages=398 ff |authorlink=David Kahn (writer)}}&lt;/ref&gt;

== History==
[[Frank Miller (cryptography)|Frank Miller]] in 1882 was the first to describe the one-time pad system for securing telegraphy.&lt;ref name="BELLOVIN1"/&gt;&lt;ref name=bio&gt;{{cite news |author=[[John Markoff]] |title=Codebook Shows an Encryption Form Dates Back to Telegraphs |url=https://www.nytimes.com/2011/07/26/science/26code.html?ref=science |quote= |newspaper=[[The New York Times]] |date=July 25, 2011 |accessdate=2011-07-26 |deadurl=no |archiveurl=https://web.archive.org/web/20130521201312/http://www.nytimes.com/2011/07/26/science/26code.html?ref=science |archivedate=May 21, 2013 |df= }}&lt;/ref&gt;

The next one-time pad system was electrical. In 1917, [[Gilbert Vernam]] (of [[AT&amp;T Corporation]]) invented and later patented in 1919 ({{US patent|1310719}}) a cipher based on [[teleprinter]] technology. Each character in a message was electrically combined with a character on a [[Punched tape|punched paper tape]] key. [[Joseph Mauborgne]] (then a [[Captain (U.S. Army)|captain]] in the [[U.S. Army]] and later chief of the [[Signal Corps (United States Army)|Signal Corps]]) recognized that the character sequence on the key tape could be completely random and that, if so, cryptanalysis would be more difficult. Together they invented the first one-time tape system.&lt;ref name="kahn" /&gt;

The next development was the paper pad system. Diplomats had long used [[code]]s and [[cipher]]s for confidentiality and to minimize [[Telegraphy|telegraph]] costs. For the codes, words and phrases were converted to groups of numbers (typically 4 or 5 digits) using a dictionary-like [[codebook]]. For added security, secret numbers could be combined with (usually modular addition) each code group before transmission, with the secret numbers being changed periodically (this was called [[superencryption]]). In the early 1920s, three German cryptographers (Werner Kunze, Rudolf Schauffler and Erich Langlotz), who were involved in breaking such systems, realized that they could never be broken if a separate randomly chosen additive number was used for every code group. They had duplicate paper pads printed with lines of random number groups. Each page had a serial number and eight lines. Each line had six 5-digit numbers. A page would be used as a work sheet to encode a message and then destroyed. The serial number of the page would be sent with the encoded message. The recipient would reverse the procedure and then destroy his copy of the page. The German foreign office put this system into operation by 1923.&lt;ref name="kahn"/&gt;

A separate notion was the use of a one-time pad of letters to encode plaintext directly as in the example below. [[Leo Marks]] describes inventing such a system for the British [[Special Operations Executive]] during [[World War II]], though he suspected at the time that it was already known in the highly compartmentalized world of cryptography, as for instance at [[Bletchley Park]].&lt;ref name="marks"&gt;{{cite book| last=Marks| first=Leo| title=Between Silk and Cyanide: a Codemaker's Story, 1941-1945| publisher=HarperCollins| year=1998| isbn=0-684-86780-X}}&lt;/ref&gt;

The final discovery was made by information theorist [[Claude Shannon]] in the 1940s who recognized and proved the theoretical significance of the one-time pad system. Shannon delivered his results in a classified report in 1945, and published them openly in 1949.&lt;ref name="shannon" /&gt; At the same time, Soviet information theorist [[Vladimir Kotelnikov]] had independently proved absolute security of the one-time pad; his results were delivered in 1941 in a report that apparently remains classified.&lt;ref name="kotelnikov"&gt;{{cite journal|author=Sergei N Molotkov (Institute of Solid-State Physics, Russian Academy of Sciences, Chernogolovka, Moscow region, Russian Federation)|date=22 February 2006|title=Quantum cryptography and V A Kotel'nikov's one-time key and sampling theorems|url=http://www.turpion.org/php/paper.phtml?journal_id=pu&amp;paper_id=6050|journal=Physics-Uspekhi|language=|location=|publisher=Institute of Solid-State Physics, Russian Academy of Sciences, Chernogolovka, Moscow region, Russian Federation|volume=49|issue=7|pages=750–761|bibcode=2006PhyU...49..750M|doi=10.1070/PU2006v049n07ABEH006050|oclc=|pmid=|id=|accessdate=2009-05-03|laysource=|laydate=|quote=|quotes=|laysummary=}} PACS numbers: 01.10.Fv, 03.67.Dd, 89.70.+c&lt;!-- S. N. Molotkov, “Quantum cryptography and V. A. Kotel’nikov’s one-time key and sampling theorems,” PHYS-USP '''49''', 750-761 (2006), article available to journal subscribers in&amp;nbsp;English [http://www.turpion.org/php/paper.phtml?journal_id=pu&amp;paper_id=6050] --&gt; and openly in&amp;nbsp;Russian [http://www.ufn.ru/ru/articles/2006/7/k/ Квантовая криптография и теоремы В.А. Котельникова об одноразовых ключах и об отсчетах. УФН]&lt;/ref&gt;

== Example ==

Suppose [[Alice and Bob|Alice]] wishes to send the message "HELLO" to [[Alice and Bob|Bob]]. Assume two pads of paper containing identical random sequences of letters were somehow previously produced and securely issued to both. Alice chooses the appropriate unused page from the pad. The way to do this is normally arranged for in advance, as for instance 'use the 12th sheet on 1 May', or 'use the next available sheet for the next message'.

The material on the selected sheet is the ''key'' for this message. Each letter from the pad will be combined in a predetermined way with one letter of the message. (It is common, but not required, to [[Character encoding|assign each letter a numerical value]], e.g., "A" is 0, "B" is 1, and so on.)

In this example, the technique is to combine the key and the message using [[modular arithmetic|modular addition]]. The numerical values of corresponding message and key letters are added together, modulo 26.  So, if key material begins with "XMCKL" and the message is "HELLO", then the coding would be done as follows:

       H       E       L       L       O  message
    7 (H)   4 (E)  11 (L)  11 (L)  14 (O) message
 + 23 (X)  12 (M)   2 (C)  10 (K)  11 (L) key
 = 30      16      13      21      25     message + key
 =  4 (E)  16 (Q)  13 (N)  21 (V)  25 (Z) (message + key) mod 26
       E       Q       N       V       Z  → ciphertext

If a number is larger than 26, then the remainder after subtraction of 26 is taken in modular arithmetic fashion.  This simply means that if the computations "go past" Z, the sequence starts again at A.

The ciphertext to be sent to Bob is thus "EQNVZ". Bob uses the matching key page and the same process, but in reverse, to obtain the [[plaintext]]. Here the key is ''subtracted'' from the ciphertext, again using modular arithmetic:

        E       Q       N       V       Z  ciphertext
     4 (E)  16 (Q)  13 (N)  21 (V)  25 (Z) ciphertext
 -  23 (X)  12 (M)   2 (C)  10 (K)  11 (L) key
 = -19       4      11      11      14     ciphertext&amp;nbsp;– key
 =   7 (H)   4 (E)  11 (L)  11 (L)  14 (O) ciphertext&amp;nbsp;– key (mod 26)
        H       E       L       L       O  → message

Similar to the above, if a number is negative then 26 is added to make the number zero or higher.

Thus Bob recovers Alice's plaintext, the message "HELLO". Both Alice and Bob destroy the key sheet immediately after use, thus preventing reuse and an attack against the cipher. The [[KGB]] often issued its [[espionage|agents]] one-time pads printed on tiny sheets of "flash paper"—paper chemically converted to [[nitrocellulose]], which burns almost instantly and leaves no ash.&lt;ref&gt;{{cite book
|author = Robert Wallace and H. Keith Melton, with Henry R. Schlesinger
|title = Spycraft: The Secret History of the CIA's Spytechs, from Communism to al-Qaeda
|location = New York
|publisher = [[Dutton Penguin|Dutton]]
|year = 2008
|isbn = 0-525-94980-1 
|page = 452}}&lt;/ref&gt;

The classical one-time pad of espionage used actual pads of minuscule, easily concealed paper, a sharp pencil, and some [[mental arithmetic]].  The method can be implemented now as a software program, using data files as input (plaintext), output (ciphertext) and key material (the required random sequence). The [[XOR]] operation is often used to combine the plaintext and the key elements, and is especially attractive on computers since it is usually a native machine instruction and is therefore very fast. It is, however, difficult to ensure that the key material is actually random, is used only once, never becomes known to the opposition, and is completely destroyed after use. The auxiliary parts of a software one-time pad implementation present real challenges: secure handling/transmission of plaintext, truly random keys, and one-time-only use of the key.

=== Attempt at cryptanalysis ===
To continue the example from above, suppose Eve intercepts Alice's ciphertext: "EQNVZ". If Eve had infinite time, she would find that the key "XMCKL" would produce the plaintext "HELLO", but she would also find that the key "TQURI" would produce the plaintext "LATER", an equally plausible message:
     4 (E)  16 (Q)  13 (N)  21 (V)  25 (Z) ciphertext
 −  19 (T)  16 (Q)  20 (U)  17 (R)   8 (I) possible key
 = −15       0      −7       4      17     ciphertext-key
 =  11 (L)   0 (A)  19 (T)   4 (E)  17 (R) ciphertext-key (mod 26)
In fact, it is possible to "decrypt" out of the ciphertext any message whatsoever with the same number of characters, simply by using a different key, and there is no [[Information content|information]] in the ciphertext that will allow Eve to choose among the various possible readings of the ciphertext.

== Perfect secrecy ==
One-time pads are "[[Information-theoretic security|information-theoretically secure]]" in that the encrypted message (i.e., the [[ciphertext]]) provides no information about the original message to a [[cryptanalyst]] (except the maximum possible length&lt;ref&gt;The actual length of a plaintext message can hidden by the addition of extraneous parts, called [[Padding (cryptography)|padding]]. For instance, a 21-character ciphertext could conceal a 5-character message with some padding convention (e.g. "-PADDING- HELLO -XYZ-") as much as an actual 21-character message: an observer can thus only deduce the maximum possible length of the significant text, not its exact length.&lt;/ref&gt; of the message). This is a very strong notion of security first developed during WWII by [[Claude Shannon]] and proved, mathematically, to be true for the one-time pad by Shannon about the same time. His result was published in the ''Bell Labs Technical Journal'' in 1949.&lt;ref name="Shannon"&gt;{{cite journal
 |last        = Shannon
 |first       = Claude E.
 |title       = Communication Theory of Secrecy Systems
 |journal     = Bell System Technical Journal
 |volume      = 28
 |issue       = 4
 |pages       = 656–715
 |publisher   = AT&amp;T Corporation
 |location    = USA
 |date        = October 1949
 |url         = http://www3.alcatel-lucent.com/bstj/vol28-1949/articles/bstj28-4-656.pdf
 |issn        = 
 |doi         = 10.1002/j.1538-7305.1949.tb00928.x
 |id          = 
 |accessdate  = 2011-12-21
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20120120001953/http://www.alcatel-lucent.com/bstj/vol28-1949/articles/bstj28-4-656.pdf#
 |archivedate = 2012-01-20
 |df          = 
}}&lt;/ref&gt; Properly used, one-time pads are secure in this sense even against adversaries with infinite computational power.

Claude Shannon proved, using [[information theory]] considerations, that the one-time pad has a property he termed ''perfect secrecy''; that is, the ciphertext ''C'' gives absolutely no additional [[information]] about the [[plaintext]].&lt;ref group="note"&gt;That is to say, the "'''information gain'''" or [[Kullback–Leibler divergence]] of the plaintext message from the cyphertext message is zero.&lt;/ref&gt; This is because, given a truly random key that is used only once, a ciphertext can be translated into ''any'' plaintext of the same length, and all are equally likely. Thus, the ''[[a priori (philosophy)|a priori]]'' probability of a plaintext message ''M'' is the same as the ''[[empirical knowledge|a posteriori]]'' probability of a plaintext message ''M'' given the corresponding ciphertext. 

Mathematically, this is expressed as &lt;math display="inline"&gt;\Eta(M)=\Eta(M|C)&lt;/math&gt;, where &lt;math display="inline"&gt;\Eta(M)&lt;/math&gt; is the [[Entropy (information theory)|information entropy]] of the plaintext and &lt;math display="inline"&gt;\Eta(M|C)&lt;/math&gt; is the [[conditional entropy]] of the plaintext given the ciphertext ''C''.  (Here, '''Η''&lt;nowiki/&gt;' is the capital greek letter [[eta]].) This implies that for every message ''M'' and corresponding ciphertext ''C'', there must be at least one key ''K'' that binds them as a one-time pad. Mathematically speaking, this means &lt;math display="inline"&gt;|K| \geq |C| \geq |M|&lt;/math&gt;, where &lt;math display="inline"&gt;|M|&lt;/math&gt; denotes the length of message ''M''. In other words, if you need to be able to go from any plaintext in message space ''M'' to any cipher in cipher-space ''C'' (encryption) and from any cipher in cipher-space ''C'' to a plain text in message space ''M'' (decryption), you need at least &lt;math&gt;|M| = |C|&lt;/math&gt; keys (all keys used [[Discrete uniform distribution|with equal probability]] of &lt;math&gt;1/|K|&lt;/math&gt; to ensure perfect secrecy).

Another way of stating perfect secrecy is based on the idea that for all messages &lt;math&gt;m_1, m_2&lt;/math&gt; in message space ''M'', and for all ciphers ''c'' in cipher space ''C'', we have &lt;math&gt;\underset{k \Leftarrow \Kappa}\operatorname{Pr}[E_k(m_1) = c] = \underset{k \Leftarrow \Kappa}\operatorname{Pr}[E_k(m_2) = c]&lt;/math&gt;, where &lt;math display="inline"&gt;\operatorname{Pr}&lt;/math&gt; represents the probabilities, taken over a choice of &lt;math&gt;k&lt;/math&gt; in key space &lt;math&gt;\Kappa&lt;/math&gt; over the coin tosses of a [[probabilistic algorithm]], &lt;math&gt;E&lt;/math&gt;. Perfect secrecy is a strong notion of cryptanalytic difficulty.&lt;ref name="shannon" /&gt;

Conventional [[Symmetric encryption|symmetric encryption algorithms]] use complex patterns of [[Substitution cipher|substitution]] and [[Transposition cipher|transpositions]]. For the best of these currently in use, it is not known whether there can be a cryptanalytic procedure that can reverse (or, usefully, [[Partial inverse|partially reverse]]) these transformations without knowing the key used during encryption. Asymmetric encryption algorithms depend on mathematical problems that are [[Super-polynomial time|thought to be difficult]] to solve, such as [[integer factorization]] and [[discrete logarithm]]s. However, there is no proof that these problems are hard, and a mathematical breakthrough could make existing systems vulnerable to attack.&lt;ref group="note"&gt;Most asymmetric encryption algorithms rely on the facts that the best known algorithms for prime factorization and computing discrete logarithms are superpolynomial time. There is a strong belief that these problems are not solvable by a Turing machine in time that scales polynomially with input length, rendering them difficult (hopefully, prohibitively so) to be broken via cryptographic attacks. However, this has not been proven. This amounts to the problem of [[P vs. NP]].&lt;/ref&gt;

{{For|further context on the unproven computational intractability of conventional asymmetric encryption algorithms|P versus NP problem}}

Given perfect secrecy, in contrast to conventional symmetric encryption, OTP is immune even to brute-force attacks. Trying all keys simply yields all plaintexts, all equally likely to be the actual plaintext. Even with known plaintext, like part of the message being known, brute-force attacks cannot be used, since an attacker is unable to gain any information about the parts of the key needed to decrypt the rest of the message. The parts that are known will reveal ''only'' the parts of the key corresponding to them, and they correspond on a [[Bijection|strictly one-to-one basis]]; no part of the key is [[Independence (probability theory)|dependent]] on any other part.

== Problems ==
Despite Shannon's proof of its security, the one-time pad has serious drawbacks in practice because it requires:

* Truly random, as opposed to [[Pseudorandomness|''pseudorandom'']], one-time pad values, which is a non-trivial requirement. See [[pseudorandom number generator]] and [[random number generation]].
**[[True random number generator|True random number generators]] exist, but are typically slower and more specialized.
* Secure generation and exchange of the one-time pad values, which must be at least as long as the message.
**The security of the one-time pad is only as secure as the security of the one-time pad exchange, because if an attacker is able to intercept the one-time pad value and know it is a one-time pad, they can decrypt the one-time pad's message.
* Careful treatment to make sure that the one-time pad values continue to remain secret, and are disposed of correctly preventing any reuse in whole or part—hence "one time". See [[data remanence]] for a discussion of difficulties in completely erasing computer media.

One-time pads solve few current practical problems in cryptography. High quality ciphers are widely available and their security is not considered a major worry at present.&lt;ref&gt;{{cite book   | title = The Block Cipher Companion | author1 = Lars R. Knudsen | author2 = Matthew Robshaw |  last-author-amp = yes | publisher = Springer Science &amp; Business Media | location=   |url = https://books.google.com/books?id=YiZKt_FcmYQC&amp;pg=PA11&amp;dq=security+concerns+for+high+quality+cipher&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwilmZytsKfVAhXrgFQKHfzFAXsQ6AEILjAB#v=onepage&amp;q=security%20concerns%20for%20high%20quality%20cipher&amp;f=false | date = 2011 | pages =  1–14 | isbn =  9783642173424 | access-date = 26 July 2017 }}&lt;/ref&gt; Such ciphers are almost always easier to employ than one-time pads; the amount of key material that must be properly generated and securely distributed is far smaller, and [[public key cryptography]] overcomes this problem.&lt;ref name="schneierotp"&gt;{{cite web| url=http://www.schneier.com/crypto-gram-0210.html#7| title=One-Time Pads| first=Bruce| last=Schneier| deadurl=no| archiveurl=https://web.archive.org/web/20050403200231/http://www.schneier.com/crypto-gram-0210.html#7| archivedate=2005-04-03| df=}}&lt;/ref&gt; 

[[Quantum computing|Quantum computers]] have been shown [[Shor's algorithm|by Peter Shor]] and others to be much faster at solving some of the difficult problems that grant asymmetric encryption its security. If quantum computers are built with enough [[Qubit|qubits]], and overcoming some limitations to error-correction; traditional public key cryptography will become obsolete. One-time pads, however, will remain secure. See [[quantum cryptography]] and [[post-quantum cryptography]] for further discussion of the ramifications of quantum computers to information security.

===True randomness===
High-quality random numbers are difficult to generate.  The random number generation functions in most [[programming language]] libraries are not suitable for cryptographic use.  Even those generators that are suitable for normal cryptographic use, including [[/dev/random]] and many [[hardware random number generator]]s, may make some use of cryptographic functions whose security has not been proven.  An example of how true randomness can be achieved is by measuring [[Radioactive decay|radioactive emissions]].&lt;ref&gt;{{Cite book|title=The Code Book|last=Singh|first=Simon|publisher=Anchor Books|year=2000|isbn=978-0-385-49532-5|location=United States|pages=123}}&lt;/ref&gt;

In particular, one-time use is absolutely necessary. If a one-time pad is used just twice, simple mathematical operations can reduce it to a [[running key cipher]].{{Elaboration needed|reason=Example?|date=November 2018}} If both plaintexts are in a [[natural language]] (e.g., English or Russian) then, even though both are secret, each stands a very high chance of being recovered by [[heuristic]] cryptanalysis, with possibly a few ambiguities. Of course, a longer message can only be broken for the portion that overlaps a shorter message, plus perhaps a little more by completing a word or phrase. The most famous exploit of this vulnerability occurred with the [[Venona project]].&lt;ref name="nsa"&gt;{{cite news|title=The Translations and KGB Cryptographic Systems|curly=|author=|first=|last=|authorlink=|author2=|author3=|author4=|author5=|author6=|author7=|url=http://www.nsa.gov/about/_files/cryptologic_heritage/publications/coldwar/venona_story.pdf|format=PDF|agency=|work=The Venona Story|publisher=[[National Security Agency]]|location=[[Fort Meade, Maryland]]|isbn=|issn=|oclc=|pmid=|pmd=|bibcode=|doi=|id=|date=2004-01-15|pages=26–27 (28–29th of 63 in PDF)|accessdate=2009-05-03|language=|archiveurl=https://web.archive.org/web/20090510052927/http://www.nsa.gov/about/_files/cryptologic_heritage/publications/coldwar/venona_story.pdf|archivedate=2009-05-10|quote=...KGB's cryptographic material manufacturing center in the Soviet Union apparently reused some of the pages from one-time pads. This provided [[Arlington Hall]] with an opening.|deadurl=no|df=}}&lt;/ref&gt;

===Key distribution===
{{further|Key distribution}}

Because the pad, like all [[shared secret]]s, must be passed and kept secure, and the pad has to be at least as long as the message, there is often no point in using one-time padding, as one can simply send the plain text instead of the pad (as both can be the same size and have to be sent securely). However, once a very long pad has been securely sent (e.g., a computer disk full of random data), it can be used for numerous future messages, until the sum of their sizes equals the size of the pad. [[Quantum key distribution]] also proposes a solution to this problem, assuming [[Fault tolerance|fault-tolerant]] quantum computers.

Distributing very long one-time pad keys is inconvenient and usually poses a significant security risk.&lt;ref name="Numbers Stations"/&gt; The pad is essentially the encryption key, but unlike keys for modern ciphers, it must be extremely long and is much too difficult for humans to remember. Storage media such as [[thumb drive]]s, [[DVD-R]]s or personal [[digital audio player]]s can be used to carry a very large one-time-pad from place to place in a non-suspicious way, but even so the need to transport the pad physically is a burden compared to the key negotiation protocols of a modern public-key cryptosystem, and such  media cannot reliably be erased securely by any means short of physical destruction (e.g., incineration). A 4.7 GB DVD-R full of one-time-pad data, if shredded into particles 1 {{Convert|1|mm2||abbr=on}} in size, leaves over 4 [[megabit]]s of (admittedly hard to recover, but not impossibly so) data on each particle. {{citation needed|date=November 2010}} In addition, the risk of compromise during transit (for example, a [[pickpocket]] swiping, copying and replacing the pad) is likely to be much greater in practice than the likelihood of compromise for a cipher such as [[Advanced Encryption Standard|AES]]. Finally, the effort needed to manage one-time pad key material [[Scalability|scales]] very badly for large networks of communicants—the number of pads required goes up as the square of the number of users freely exchanging messages. For communication between only two persons, or a [[star network]] topology, this is less of a problem.

The key material must be securely disposed of after use, to ensure the key material is never reused and to protect the messages sent.&lt;ref name="Numbers Stations"/&gt;  Because the key material must be transported from one endpoint to another, and persist until the message is sent or received, it can be more vulnerable to [[computer forensics|forensic recovery]] than the transient plaintext it protects (see [[data remanence]]).

===Authentication===
As traditionally used, one-time pads provide no [[authentication|message authentication]], the lack of which can pose a security threat in real-world systems. For example, an attacker who knows that the message contains "meet jane and me tomorrow at three thirty pm" can derive the corresponding codes of the pad directly from the two known elements (the encrypted text and the known plaintext). The attacker can then replace that text by any other text of exactly the same length, such as "three thirty meeting is canceled, stay home." The attacker's knowledge of the one-time pad is limited to this byte length, which must be maintained for any other content of the message to remain valid. This is a little different from [[malleability (cryptography)|malleability]]&lt;ref&gt;{{cite web|url=https://books.google.com/books?id=ySZwUT4nyPsC&amp;lpg=PA223&amp;ots=FL9b9hl1LF&amp;dq=malleable+one+time+pad&amp;pg=PR1#v=onepage&amp;q=malleable+one+time+pad&amp;f=false|title=Information Theoretic Security: Third International Conference, ICITS 2008, Calgary, Canada, August 10-13, 2008, Proceedings|first=Reihaneh|last=Safavi-Naini|date=22 July 2008|publisher=Springer Science &amp; Business Media|via=Google Books}}&lt;/ref&gt; where it is not taken necessarily that the plaintext is known. ''See also'' [[stream cipher attack]].

Standard techniques to prevent this, such as the use of a [[message authentication code]] can be used along with a one-time pad system to prevent such attacks, as can classical methods such as variable length [[padding (cryptography)|padding]] and [[Russian copulation]], but they all lack the perfect security the OTP itself has. [[Universal hashing]] provides a way to authenticate messages up to an arbitrary security bound (i.e., for any &lt;math display="inline"&gt;p &gt; 0&lt;/math&gt;, a large enough hash ensures that even a computationally unbounded attacker's likelihood of successful forgery is less than ''p''), but this uses additional random data from the pad, and removes the possibility of implementing the system without a computer.

==Uses==
{{Expand section|uses in [[quantum cryptography|quantum]] and [[post-quantum cryptography]]|date=November 2018|small=no}}

=== Applicability ===

[[File:PersonalStorageDevices.agr.jpg|thumb|Any digital [[data storage device]] can be used to transport one-time pad data.]]

Despite its problems, the one-time-pad retains some practical interest. In some hypothetical espionage situations, the one-time pad might be useful because it can be computed by hand with only pencil and paper. Indeed, nearly all other high quality ciphers are entirely impractical without computers. Spies can receive their pads in person from their "handlers."  In the modern world, however, computers (such as those embedded in personal electronic devices such as [[mobile phone]]s) are so ubiquitous that possessing a computer suitable for performing conventional encryption (for example, a phone that can run concealed cryptographic software) will usually not attract suspicion.

* The one-time-pad is the optimum cryptosystem with theoretically perfect secrecy.
* The one-time-pad is one of the most practical methods of encryption where one or both parties must do all work by hand, without the aid of a computer.  This made it important in the pre-computer era, and it could conceivably still be useful in situations where possession of a computer is illegal or incriminating or where trustworthy computers are not available.
* One-time pads are practical in situations where two parties in a secure environment must be able to depart from one another and communicate from two separate secure environments with perfect secrecy.
* The one-time-pad can be used in [[superencryption]].&lt;ref&gt;A "way to combine multiple block algorithms" so that "a cryptanalyst must break both algorithms" in §15.8 of Applied Cryptography, Second Edition: Protocols, Algorithms, and Source Code in C by Bruce Schneier. Wiley Computer Publishing, John Wiley &amp; Sons, Inc.&lt;/ref&gt;
* The algorithm most commonly associated with [[quantum key distribution]] is the one-time pad.
* The one-time pad is mimicked by [[stream cipher]]s.
* The one-time pad can be a part of an introduction to cryptography.&lt;ref&gt;Introduction to modern cryptography, J Katz, Y Lindell – 2008 – cs.biu.ac.il&lt;/ref&gt;

=== Historical uses ===

One-time pads have been used in special circumstances since the early 1900s. In 1923, it was employed for diplomatic communications by the German diplomatic establishment.&lt;ref&gt;{{cite book| last=Kahn| first=David| title=[[The Codebreakers]]| publisher=[[Macmillan Publishers (United States)|Macmillan]]| year=1996| isbn=0-684-83130-9| pages=402&amp;ndash;3 |authorlink=David Kahn (writer)}}&lt;/ref&gt; The [[Weimar Republic]] Diplomatic Service began using the method in about 1920. The breaking of poor [[Union of Soviet Socialist Republics|Soviet]] cryptography by the [[United Kingdom|British]], with messages made public for political reasons in two instances in the 1920s ([[All Russian Co-operative Society#The Arcos Affair of 1927|ARCOS case]]), appear to have induced the U.S.S.R. to adopt one-time pads for some purposes by around 1930. [[KGB]] spies are also known to have used pencil and paper one-time pads more recently. Examples include Colonel [[Rudolf Abel]], who was arrested and convicted in [[New York City]] in the 1950s, and the 'Krogers' (i.e., [[Morris Cohen (spy)|Morris]] and [[Lona Cohen]]), who were arrested and convicted of espionage in the [[United Kingdom]] in the early 1960s. Both were found with physical one-time pads in their possession.

A number of nations have used one-time pad systems for their sensitive traffic. [[Leo Marks]] reports that the British [[Special Operations Executive]] used one-time pads in World War II  to encode traffic between its offices. One-time pads for use with its overseas agents were introduced late in the war.&lt;ref name="marks" /&gt; A few British one-time tape cipher machines include the [[Rockex]] and [[Noreen]].  The German [[Stasi]] Sprach Machine was also capable of using one time tape that East Germany, Russia, and even Cuba used to send encrypted messages to their agents.&lt;ref name="Sprach Machine"&gt;{{cite news |title=Stasi Sprach Morse Machine |url=http://www.numbers-stations.com/sprach-machine |publisher=The Numbers Stations Research and Information Center |accessdate=March 1, 2015 |deadurl=yes |archiveurl=https://web.archive.org/web/20150313143905/http://www.numbers-stations.com/sprach-machine |archivedate=March 13, 2015 |df=mdy-all }}&lt;/ref&gt;

The [[World War II]] voice [[scrambler]] [[SIGSALY]] was also a form of one-time system. It added noise to the signal at one end and removed it at the other end. The noise was distributed to the channel ends in the form of large shellac records that were manufactured in unique pairs. There were both starting synchronization and longer-term phase drift problems that arose and were solved before the system could be used.

The [[Moscow-Washington hotline|hotline]] between [[Moscow]] and [[Washington D.C.]], established in 1963 after the [[Cuban missile crisis]], used [[teleprinter]]s protected by a commercial one-time tape system. Each country prepared the keying tapes used to encode its messages and delivered them via their embassy in the other country. A unique advantage of the OTP in this case was that neither country had to reveal more sensitive encryption methods to the other.&lt;ref&gt;
{{cite book| last=Kahn| title=[[The Codebreakers]] |page=715}}
&lt;/ref&gt;

U.S. Army Special Forces used one-time pads in Vietnam. By using Morse code with one-time pads and continuous wave radio transmission (the carrier for Morse code), they achieved both secrecy and reliable communications.{{Citation needed|date=March 2016}}

During the 1983 [[Invasion of Grenada]], U.S. forces found a supply of pairs of one-time pad books in a Cuban warehouse.&lt;ref&gt;[http://www.seas.harvard.edu/courses/emr12/4.pdf{{deadurl|date=September 2017}} http://www.seas.harvard.edu/courses/emr12/4.pdf] page 91&lt;/ref&gt;{{Dead link|date=November 2018}}

Starting in 1988, the [[African National Congress]] (ANC) used disk-based one-time pads as part of a [[secure communication]] system between ANC leaders outside [[South Africa]] and in-country operatives as part of [[Operation Vula]], a successful effort to build a resistance network inside South Africa. Random numbers on the disk were erased after use.  A Belgian airline stewardess acted as courier to bring in the pad disks. A regular resupply of new disks was needed as they were used up fairly quickly. One problem with the system was that it could not be used for secure data storage. Later Vula added a stream cipher keyed by book codes to solve this problem.&lt;ref&gt;
{{Cite journal
 |first       = Tim
 |last        = Jenkin
 |date        = May–October 1995
 |title       = Talking to Vula: The Story of the Secret Underground Communications Network of Operation Vula
 |quote       = Our system was based on the one-time pad, though instead of having paper pads the random numbers were on a disk.
 |journal     = Mayibuye
 |url         = http://www.anc.org.za/show.php?id=4693
 |accessdate  = {{date|2014-08-24}}
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20140826115901/http://www.anc.org.za/show.php?id=4693
 |archivedate = 2014-08-26
 |df          = 
}}&lt;/ref&gt;

A related notion is the [[code (cryptography)#One-time code|one-time code]]—a signal, used only once, e.g., "Alpha" for "mission completed", "Bravo" for "mission failed" or even "Torch" for "[[Operation Torch|Allied invasion of French Northern Africa]]"&lt;ref&gt;{{cite book
|title=The Secret Wireless War – The story of MI6 Communications 1939-1945
|last = Pidgeon |first = Geoffrey
|publisher = UPSO Ltd |isbn = 1-84375-252-2
|page = 249
|chapter = Chapter 28: Bill Miller – Tea with the Germans
|year = 2003 }}&lt;/ref&gt; cannot be "decrypted" in any reasonable sense of the word. Understanding the message will require additional information, often 'depth' of repetition, or some [[traffic analysis]]. However, such strategies (though often used by real operatives, and [[baseball]] coaches){{citation needed|date=February 2018}} are not a cryptographic one-time pad in any significant sense.

===NSA===
At least into the 1970s, the U.S. [[National Security Agency]] (NSA) produced a variety of manual one-time pads, both general purpose and specialized,  with 86,000 one-time pads produced in fiscal year 1972. Special purpose pads were produced for what NSA called "pro forma" systems, where “the basic framework, form or format of every message text is identical or nearly so; the same kind of information, message after message, is to be presented in the same order, and only specific values, like numbers, change with each message.” Examples included nuclear launch messages and radio direction finding reports (COMUS).&lt;ref name=boaklectures1&gt;{{Cite book
 |last        = Boak
 |first       = David G.
 |title       = A History of U.S. Communications Security; the David G. Boak Lectures, Vol. I
 |orig-year   = 1966
 |url         = https://www.governmentattic.org/18docs/Hist_US_COMSEC_Boak_NSA_1973u.pdf
 |format      = pdf
 |access-date = 2017-04-23
 |edition     = 2015 declassification review
 |date        = July 1973
 |publisher   = U.S. National Security Agency
 |location    = Ft. George G. Meade, MD
 |pages       = 
 |chapter     = 
 |quote       = 
 |deadurl     = no
 |archiveurl  = https://web.archive.org/web/20170525181251/http://www.governmentattic.org/18docs/Hist_US_COMSEC_Boak_NSA_1973u.pdf
 |archivedate = 2017-05-25
 |df          = 
}}&lt;/ref&gt;{{rp|pp. 16–18}}

General purpose pads were produced in several formats, a simple list of random letters (DIANA) or just numbers (CALYPSO), tiny pads for covert agents (MICKEY MOUSE), and pads designed for more rapid encoding of short messages, at the cost of lower density. One example, ORION, had 50 rows of plaintext alphabets on one side and the corresponding random cipher text letters on the other side. By placing a sheet on top of a piece of [[carbon paper]] with the carbon face up, one could circle one letter in each row on one side and the corresponding letter one the other side would be circled by the carbon paper. Thus one ORION sheet could quickly encode or decode a message up to 50 characters long. Production of ORION pads required printing both sides in exact registration, a difficult process, so NSA switched to another pad format, MEDEA, with 25 rows of paired alphabets and random characters. (''See'' [[Commons:Category:NSA one-time pads]] for illustrations.)
 
The NSA also built automated systems for the “centralized headquarters of CIA and Special Forces units so that they can efficiently process the many separate one-time pad messages to and from individual pad holders in the field.”&lt;ref name=boaklectures1 /&gt;{{rp|pp. 21–26}}

During World War II and into the 1950s, the U.S. made extensive use of one-time tape systems. In addition to providing confidentiality, circuits secured by  one-time tape ran continually, even when there was no traffic, thus protecting against [[traffic analysis]]. In 1955, NSA produced some 1,660,000 rolls of one time tape. Each roll was 8 inches in diameter, contained 100,000 characters, lasted 166 minutes and cost $4.55 to produce. By 1972, only 55,000 rolls were produced, as one-time tapes were replaced by [[rotor machine]]s such as SIGTOT, and later by electronic devices based on [[shift registers]].&lt;ref name=boaklectures1 /&gt;{{rp|pp. 39–44}} The NSA describes one-time tape systems like [[5-UCO]] and SIGTOT as being used for intelligence traffic until the introduction of the electronic cipher based [[KW-26]] in 1957.&lt;ref&gt;{{cite web| url=http://www.nsa.gov/publications/publi00017.pdf| title=Securing Record Communications: The TSEC/KW-26| year=2003| format=PDF| accessdate=2006-05-12| first=Melville| last=Klein| publisher=NSA |archiveurl = https://web.archive.org/web/20060213165531/http://www.nsa.gov/publications/publi00017.pdf &lt;!-- Bot retrieved archive --&gt; |archivedate = 2006-02-13}}&lt;/ref&gt;

===Exploits===
While one-time pads provide perfect secrecy if generated and used properly, small mistakes can lead to successful cryptanalysis:
*In 1944–1945, the [[U.S. Army]]'s [[Signals Intelligence Service]] was able to solve a one-time pad system used by the German Foreign Office for its high-level traffic, codenamed GEE.&lt;ref&gt;Erskine, Ralph, "Enigma's Security: What the Germans Really Knew", in "Action this Day", edited by Ralph Erskine and Michael Smith, pp 370–386, 2001.&lt;/ref&gt; GEE was insecure because the pads were not completely random—the machine used to generate the pads produced predictable output.
*In 1945, the US discovered that [[Canberra]]–[[Moscow]] messages were being encrypted first using a code-book and then using a one-time pad. However, the one-time pad used was the same one used by Moscow for [[Washington, D.C.]]–Moscow messages. Combined with the fact that some of the Canberra–Moscow messages included known British government documents, this allowed some of the encrypted messages to be broken.
*One-time pads were employed by [[Soviet Union|Soviet]] espionage agencies for covert communications with agents and agent controllers. Analysis has shown that these pads were generated by typists using actual typewriters. This method is of course not truly random, as it makes certain convenient key sequences more likely than others, yet it proved to be generally effective because while a person will not produce truly random sequences they equally do not follow the same kind of structured mathematical rules that a machine would either, and each person generates ciphers in a different way making attacking any message challenging. Without copies of the key material used, only some defect in the generation method or reuse of keys offered much hope of cryptanalysis. Beginning in the late 1940s, US and UK intelligence agencies were able to break some of the Soviet one-time pad traffic to [[Moscow]] during WWII as a result of errors made in generating and distributing the key material. One suggestion is that Moscow Centre personnel were somewhat rushed by the presence of German troops just outside Moscow in late 1941 and early 1942, and they produced more than one copy of the same key material during that period. This decades-long effort was finally codenamed [[Venona project|VENONA]] (BRIDE had been an earlier name); it produced a considerable amount of information, including more than a little about some of the Soviet [[atom spies]]. Even so, only a small percentage of the intercepted messages were either fully or partially decrypted (a few thousand out of several hundred thousand).&lt;ref&gt;{{cite news|title=The Venona Translations|curly=|author=|first=|last=|authorlink=|author2=|author3=|author4=|author5=|author6=|author7=|url=http://www.nsa.gov/about/_files/cryptologic_heritage/publications/coldwar/venona_story.pdf|format=PDF|agency=|work=The Venona Story|publisher=[[National Security Agency]]|location=[[Fort Meade, Maryland]]|isbn=|issn=|oclc=|pmid=|pmd=|bibcode=|doi=|id=|date=2004-01-15|page=17th (of 63 in PDF) but marked 15|pages=|accessdate=2009-05-03|language=|archiveurl=https://web.archive.org/web/20090510052927/http://www.nsa.gov/about/_files/cryptologic_heritage/publications/coldwar/venona_story.pdf|archivedate=2009-05-10|quote=Arlington Hall's ability to read the VENONA messages was spotty, being a function of the underlying code, key changes, and the lack of volume. Of the message traffic from the KGB New York office to Moscow, 49 percent of the 1944 messages and 15 percent of the 1943 messages were readable, but this was true of only 1.8 percent of the 1942 messages. For the 1945 KGB Washington office to Moscow messages, only 1.5 percent were readable. About 50 percent of the 1943 GRU-Naval Washington to Moscow/Moscow to Washington messages were read but none from any other year.|deadurl=no|df=}}&lt;/ref&gt;
*The one-time tape systems used by the U.S. employed electromechanical mixers to combine bits from the message and the one-time tape. These mixers radiated considerable electromagnetic energy that could be picked up by an adversary at some distance from the encryption equipment. This effect, first noticed by [[Bell Labs]] during World War II, could allow interception and recovery of the plaintext of messages being transmitted, a vulnerability code-named [[Tempest (codename)|Tempest]].&lt;ref name=boaklectures1 /&gt;{{rp|pp. 89 ff}}

== See also ==
{{Portal|Computer security}}

{{Div col|colwidth=25em}}
* ''[[Agrippa (A Book of the Dead)]]''
* [[Information theoretic security]]
* [[Numbers station]]
* [[One-time password]]
* [[Session key]]
* [[Steganography]]
* [[Tradecraft]]
* [[Unicity distance]]
{{div col end}}

== Notes ==
{{reflist|group=note}}

== References ==
{{Reflist|30em}}

== Further reading ==
{{refbegin}}
* {{cite journal |journal = Cryptologia |last = Rubina |first = Frank |title = One-Time Pad cryptography |volume = 20 |issue = 4 |issn = 0161-1194
|year = 1996 |doi = 10.1080/0161-119691885040 |pages = 359–364}}
* {{cite journal |journal = Cryptologia |last = Fostera |first = Caxton C. |title = Drawbacks of the One-time Pad |volume = 21 |issue = 4 |issn = 0161-1194 |year = 1997 |doi = 10.1080/0161-119791885986 |pages = 350–352}}
{{refend}}

== External links ==
* Detailed [http://users.telenet.be/d.rijmenants/en/onetimepad.htm description and history of One-time Pad] with examples and images on [http://users.telenet.be/d.rijmenants Cipher Machines and Cryptology]
* The [[FreeS/WAN]] [http://www.freeswan.org/freeswan_trees/freeswan-2.06/doc/glossary.html#OTP glossary entry] with a discussion of OTP weaknesses
{{Clear}}
{{cryptography navbox | classical}}

{{DEFAULTSORT:One-Time Pad}}
[[Category:Information-theoretically secure algorithms]]
[[Category:Stream ciphers]]
[[Category:Cryptography]]
[[Category:1882 introductions]]</text>
      <sha1>m1hteoashq9fcqv4uvq80s9uq003u5x</sha1>
    </revision>
  </page>
  <page>
    <title>Operational semantics</title>
    <ns>0</ns>
    <id>270062</id>
    <revision>
      <id>862667383</id>
      <parentid>828784982</parentid>
      <timestamp>2018-10-05T21:46:24Z</timestamp>
      <contributor>
        <ip>68.39.100.192</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14668">'''Operational semantics''' is a category of [[Semantics (computer science)|formal programming language semantics]] in which certain desired properties of a program, such as correctness, safety or security, are [[formal verification|verified]] by constructing proofs from logical statements about its execution and procedures, rather than by attaching mathematical meanings to its terms ([[denotational semantics]]). Operational semantics are classified in two categories: '''structural operational semantics''' (or '''small-step semantics''') formally describe how the ''individual steps'' of a [[computation]] take place in a computer-based system; by opposition '''natural semantics''' (or '''big-step semantics''') describe how the ''overall results'' of the executions are obtained. Other approaches to providing a [[formal semantics of programming languages]] include [[axiomatic semantics]] and [[denotational semantics]].

The operational semantics for a programming language describes how a valid program is interpreted as sequences of computational steps.
These sequences then ''are'' the meaning of the program.
In the context of [[functional program]]s, the final step in a terminating
sequence returns the value of the program.  (In general there can be many return values for a single program,
because the program could be [[Nondeterministic algorithm|nondeterministic]], and even for a deterministic program there can be many computation sequences since the semantics may not specify exactly what sequence of operations arrives at that value.)

Perhaps the first formal incarnation of operational semantics was the use of the [[lambda calculus]] to define the semantics of [[LISP]].&lt;ref&gt;{{Cite web| title=Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I| author=[[John McCarthy (computer scientist)|John McCarthy]]| url=http://www-formal.stanford.edu/jmc/recursive.html| accessdate=2006-10-13| deadurl=yes| archiveurl=https://web.archive.org/web/20131004215327/http://www-formal.stanford.edu/jmc/recursive.html| archivedate=2013-10-04| df=}}&lt;/ref&gt; [[Abstract machine]]s in the tradition of the [[SECD machine]] are also closely related.

== History ==

The concept of operational semantics was used for the first time in defining the semantics of [[Algol 68]].
The following statement is a quote from the revised ALGOL 68 report:

&lt;blockquote&gt;
The meaning of a program in the strict language is explained in terms of a hypothetical computer
which performs the set of actions which constitute the elaboration of that program. ([[#algol68|Algol68]], Section 2)
&lt;/blockquote&gt;

The first use of the term "operational semantics" in its present meaning is attributed to
[[Dana Scott]] ([[#plotkin04|Plotkin04]]).
What follows is a quote from Scott's seminal paper on formal semantics,
in which he mentions the "operational" aspects of semantics.

&lt;blockquote&gt;
It is all very well to aim for a more ‘abstract’ and a ‘cleaner’ approach to
semantics, but if the plan is to be any good, the operational aspects cannot
be completely ignored. ([[#scott70|Scott70]])
&lt;/blockquote&gt;

== Approaches ==
[[Gordon Plotkin]] introduced the structural operational semantics, Robert Hieb and [[Matthias Felleisen]] the reduction contexts,&lt;ref&gt;{{cite journal |title=The Revised Report on the Syntactic Theories of Sequential Control and State | journal=Theoretical Computer Science | last1=Felleisen | first1=M. | last2=Hieb | first2=R. | doi = 10.1016/0304-3975(92)90014-7 }}&lt;/ref&gt; and [[Gilles Kahn]] the natural semantics.

=== Small-step semantics ===

==== Structural operational semantics ====
'''Structural operational semantics''' (also called '''structured operational semantics''' or '''small-step semantics''') was introduced by [[Gordon Plotkin]] in ([[#plotkin81|Plotkin81]])  as a logical means to define operational semantics. The basic idea behind SOS is to define the behavior of a program in terms of the behavior of its parts, thus providing a structural, i.e., syntax-oriented and [[inductive definition|inductive]], view on operational semantics.  An SOS specification defines the behavior of a program in terms of a (set of) [[State transition system|transition relation]](s). SOS specifications take the form of a set of [[inference rule]]s that define the valid transitions of a composite piece of syntax in terms of the transitions of its components.

For a simple example, we consider part of the semantics of a simple programming language; proper illustrations are given in [[#plotkin81|Plotkin81]] and [[#hennessybook|Hennessy90]], and other textbooks. Let &lt;math&gt;C_1, C_2&lt;/math&gt; range over programs of the language, and let &lt;math&gt;s&lt;/math&gt; range over states (e.g. functions from memory locations to values). If we have expressions (ranged over by &lt;math&gt;E&lt;/math&gt;), values {{nobreak|(&lt;math&gt;V&lt;/math&gt;)}} and locations (&lt;math&gt;L&lt;/math&gt;), then a memory update command would have semantics:

&lt;math&gt;
\frac{\langle E,s\rangle \Rightarrow V}{\langle L:=E\,,\,s\rangle\longrightarrow (s\uplus (L\mapsto V))}
&lt;/math&gt;
&lt;!-- NOTE: This is only a fragment of a full semantics. I've tried to include enough to illustrate the points but not so much that it takes a disproportionate amount of space.  --&gt;

Informally, the rule says that "'''if''' the expression &lt;math&gt;E&lt;/math&gt; in state &lt;math&gt;s&lt;/math&gt; reduces to value &lt;math&gt;V&lt;/math&gt;, '''then''' the program &lt;math&gt;L:=E&lt;/math&gt; will update the state &lt;math&gt;s&lt;/math&gt; with the assignment &lt;math&gt;L=V&lt;/math&gt;".

The semantics of sequencing can be given by the following three rules:

&lt;math&gt;
\frac{\langle C_1,s\rangle \longrightarrow s'}
{\langle C_1;C_2 \,,s\rangle\longrightarrow \langle C_2, s'\rangle}
\quad\quad
\frac{\langle C_1,s\rangle \longrightarrow \langle C_1',s'\rangle}
{\langle C_1;C_2 \,,s\rangle\longrightarrow \langle C_1';C_2\,, s'\rangle}
\quad\quad
\frac{}
{\langle \mathbf{skip} ,s\rangle\longrightarrow s}
&lt;/math&gt;

Informally, the first rule says that,
if program &lt;math&gt;C_1&lt;/math&gt; in state &lt;math&gt;s&lt;/math&gt; finishes in state &lt;math&gt;s'&lt;/math&gt;, then the program &lt;math&gt;C_1;C_2&lt;/math&gt; in state &lt;math&gt;s&lt;/math&gt; will reduce to the program &lt;math&gt;C_2&lt;/math&gt; in state &lt;math&gt;s'&lt;/math&gt;.
(You can think of this as formalizing "You  can run &lt;math&gt;C_1&lt;/math&gt;, and then run &lt;math&gt;C_2&lt;/math&gt;
using the resulting memory store.)
The second rule says that
if the program &lt;math&gt;C_1&lt;/math&gt; in state &lt;math&gt;s&lt;/math&gt; can reduce to the program &lt;math&gt;C_1'&lt;/math&gt;  with state &lt;math&gt;s'&lt;/math&gt;, then the program &lt;math&gt;C_1;C_2&lt;/math&gt; in state &lt;math&gt;s&lt;/math&gt; will reduce to the program &lt;math&gt;C_1';C_2&lt;/math&gt; in state &lt;math&gt;s'&lt;/math&gt;.
(You can think of this as formalizing the principle for an optimizing compiler:
"You are allowed to transform &lt;math&gt;C_1&lt;/math&gt; as if it were stand-alone, even if it is just the
first part of a program.")
The semantics is structural, because the meaning of the sequential program &lt;math&gt;C_1;C_2&lt;/math&gt;, is defined by the meaning of &lt;math&gt;C_1&lt;/math&gt; and the meaning of &lt;math&gt;C_2&lt;/math&gt;.

If we also have Boolean expressions over the state, ranged over by &lt;math&gt;B&lt;/math&gt;, then we can define the semantics of the '''while''' command:
&lt;math&gt;
\frac{\langle B,s\rangle \Rightarrow \mathbf{true}}{\langle\mathbf{while}\ B\ \mathbf{ do }\ C,s\rangle\longrightarrow \langle C;\mathbf{while}\ B\ \mathbf{do}\ C,s\rangle}
\quad
\frac{\langle B,s\rangle \Rightarrow \mathbf{false}}{\langle\mathbf{while}\ B\ \mathbf{ do }\ C,s\rangle\longrightarrow s}
&lt;/math&gt;

Such a definition allows formal analysis of the behavior of programs, permitting the study of [[Relation (mathematics)|relations]] between programs. Important relations include [[simulation preorder]]s and [[bisimulation]].
These are especially useful in the context of [[Concurrency (computer science)|concurrency theory]].

Thanks to its intuitive look and easy-to-follow structure,
SOS has gained great popularity and has become a de facto standard in defining
operational semantics. As a sign of success, the original report (so-called Aarhus
report) on SOS ([[#plotkin81|Plotkin81]]) has attracted more than 1000 citations according to the CiteSeer [http://citeseer.ist.psu.edu/673965.html],
making it one of the most cited technical reports in [[Computer Science]].

==== Reduction semantics ====
'''Reduction semantics''' are an alternative presentation of operational semantics using so-called reduction contexts. The method was introduced by Robert Hieb and [[Matthias Felleisen]] in 1992 as a technique for formalizing an [[equational theory]] for [[control flow|control]] and [[program state|state]]. For example, the grammar of a simple [[call-by-value]] [[lambda calculus]] and its contexts can be given as:

&lt;math&gt;
e = v \;|\; (e\; e) \;|\; x \quad\quad v = \lambda x.e \quad\quad C = \left[\,\right] \;|\; (C\; e) \;|\; (v\; C)
&lt;/math&gt;

The contexts &lt;math&gt;C&lt;/math&gt; include a hole &lt;math&gt;\left[\,\right]&lt;/math&gt; where a term can be plugged in.
The shape of the contexts indicate where reduction can occur (i.e., a term can be plugged into a term).
To describe a semantics for this language, axioms or reduction rules are provided:

&lt;math&gt;
(\lambda x.e)\; v \longrightarrow e\,\left[x / v\right] \quad (\mathrm{\beta})
&lt;/math&gt;

This single axiom is the beta rule from the lambda calculus. The reduction contexts show how this rule composes
with more complicated terms. In particular, this rule can trigger for the argument position of an
application like &lt;math&gt;((\lambda x.x \; \lambda x.x) \lambda x.(x\;x))&lt;/math&gt; because there is a context &lt;math&gt;([\,]\; \lambda x.(x\;x))&lt;/math&gt;
that matches the term. In this case, the contexts uniquely decompose terms so that only one reduction is possible
at any given step. Extending the axiom to match the reduction contexts gives the ''compatible closure''. Taking the
reflexive, transitive closure of this relation gives the ''reduction relation'' for this language.

The technique is useful for the ease in which reduction contexts can model state or control constructs (e.g., [[continuations]]). In addition, reduction semantics have been used to model [[object-oriented]] languages,&lt;ref&gt;{{cite book|title=A Theory of Objects|last1=Abadi|first1=M.|last2=Cardelli|first2=L.}}&lt;/ref&gt; [[design by contract|contract systems]], and other language features.

=== Big-step semantics ===

==== Natural semantics  ====

Big-step structural operational semantics is also known under the names '''natural semantics''', '''relational semantics''' and '''evaluation semantics'''.&lt;ref&gt;[http://fsl.cs.illinois.edu/images/6/63/CS422-Spring-2010-BigStep.pdf]&lt;/ref&gt; Big-step operational semantics was introduced under the name ''natural semantics'' by [[Gilles Kahn]] when presenting Mini-ML, a pure dialect of the [[ML language]].

One can view big-step definitions as definitions of functions, or more generally of relations, interpreting each language construct in an appropriate domain. Its intuitiveness makes it a popular choice for semantics specification in programming languages, but it has some drawbacks that make it inconvenient or impossible to use in many situations, such as languages with control-intensive features or concurrency.

A big-step semantics describes in a divide-and-conquer manner how final evaluation results of language constructs can be obtained by combining the evaluation results of their syntactic counterparts (subexpressions, substatements, etc.).

== Comparison ==
There are a number of distinctions between small-step and big-step semantics that influence whether one or the other forms a more suitable basis for specifying the semantics of a programming language.

Big-step semantics have the advantage of often being simpler (needing fewer inference rules) and often directly correspond to an efficient implementation of an interpreter for the language (hence Kahn calling them "natural".) Both can lead to simpler proofs, for example when proving the preservation of correctness under some [[program transformation]].&lt;ref name="leroy-coinductivebigstep"&gt;[[Xavier Leroy]]. "Coinductive big-step operational semantics".&lt;/ref&gt;

The main disadvantage of big-step semantics is that non-terminating ([[divergence (computer science)|diverging]]) computations do not have an inference tree, making it impossible to state and prove properties about such computations.&lt;ref name="leroy-coinductivebigstep" /&gt;

Small-step semantics give more control of the details and order of evaluation. In the case of instrumented operational semantics, this allows the operational semantics to track and the semanticist to state and prove more accurate theorems about the run-time behaviour of the language. These properties make small-step semantics more convenient when proving [[type soundness]] of a type system against an operational semantics.&lt;ref name="leroy-coinductivebigstep" /&gt;

== See also ==

* [[Algebraic semantics (computer science)|Algebraic semantics]]
* [[Axiomatic semantics]]
* [[Denotational semantics]]
* [[Formal semantics of programming languages]]

== References ==
{{reflist}}
* [[Gilles Kahn]]. "Natural Semantics". ''Proceedings of the 4th Annual Symposium on Theoretical Aspects of Computer Science''. Springer-Verlag. London. 1987.
* &lt;cite id=plotkin81&gt; [[Gordon Plotkin|Gordon D. Plotkin.]] [http://citeseer.ist.psu.edu/673965.html A Structural Approach to Operational Semantics]. (1981) Tech. Rep. DAIMI FN-19, Computer Science Department, Aarhus University, Aarhus, Denmark. (Reprinted with corrections in J. Log. Algebr. Program. 60-61: 17-139 (2004), [http://homepages.inf.ed.ac.uk/gdp/publications/sos_jlap.pdf preprint]). &lt;/cite&gt;
* &lt;cite id=plotkin04&gt; [[Gordon Plotkin|Gordon D. Plotkin.]] The Origins of Structural Operational Semantics.  J. Log. Algebr. Program. 60-61:3-15, 2004.  ([http://homepages.inf.ed.ac.uk/gdp/publications/Origins_SOS.pdf preprint]). &lt;/cite&gt;
* &lt;cite id=scott70&gt;  [[Dana Scott|Dana S. Scott.]] Outline of a Mathematical Theory of Computation, Programming Research Group, Technical Monograph PRG–2, Oxford University, 1970.&lt;/cite&gt;
* &lt;cite id=algol68&gt; [[Adriaan van Wijngaarden]]  et al. [[ALGOL 68|Revised Report on the Algorithmic Language ALGOL 68. IFIP. 1968.]] ([http://vestein.arb-phys.uni-dortmund.de/~wb/RR/rr.pdf]{{dead link|date=March 2018 |bot=InternetArchiveBot |fix-attempted=yes }})&lt;/cite&gt;
* &lt;cite id=hennessybook&gt;[[Matthew Hennessy]]. Semantics of Programming Languages. Wiley, 1990. [https://www.cs.tcd.ie/matthew.hennessy/splexternal2015/resources/sembookWiley.pdf available online].&lt;/cite&gt;

{{Authority control}}

[[Category:Formal specification languages]]
[[Category:Logic in computer science]]
[[Category:Programming language semantics]]
[[Category:Operational semantics| ]]</text>
      <sha1>4fzsykaps03wqk801vt7a0ttql4t0sd</sha1>
    </revision>
  </page>
  <page>
    <title>Paratopological group</title>
    <ns>0</ns>
    <id>17359307</id>
    <revision>
      <id>830043580</id>
      <parentid>645215855</parentid>
      <timestamp>2018-03-12T11:44:53Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1221">In [[mathematics]], &lt;!-- especially in the area of MAJOR FIELD, known as MINOR FIELD --&gt; a '''paratopological group''' is a [[topological semigroup]] that is algebraically a [[group (mathematics)|group]].&lt;ref&gt;Artur Hideyuki Tomita. [http://tatra.mat.savba.sk/Full/14/10tomita.ps On sequentially compact both-sides cancellative semigroups with sequentially continuous addition.]&lt;/ref&gt; In other words, it is a group ''G'' with a topology such that the group's product operation is a [[continuous function]] from ''G''&amp;nbsp;&amp;times;&amp;nbsp;''G'' to ''G''. This differs from the definition of a [[topological group]] in that the group inverse is not required to be continuous.

As with topological groups, some authors require the topology to be [[Hausdorff space|Hausdorff]].&lt;ref&gt;A. V. Arhangelskii. [http://atlas-conferences.com/c/a/v/h/18.htm Topological spaces connected to algebraic structures] {{webarchive|url=https://web.archive.org/web/20110608074634/http://atlas-conferences.com/c/a/v/h/18.htm |date=2011-06-08 }}&lt;/ref&gt;

Compact paratopological groups are automatically topological groups.

== References ==
{{reflist}}
{{refimprove|date=May 2008}}

[[Category:Topological groups]]


{{algebra-stub}}
{{topology-stub}}</text>
      <sha1>jt0tzh9yfq1gq33d4gouzy34omwgxu6</sha1>
    </revision>
  </page>
  <page>
    <title>Positional notation</title>
    <ns>0</ns>
    <id>437052</id>
    <revision>
      <id>865485575</id>
      <parentid>865485306</parentid>
      <timestamp>2018-10-24T07:37:22Z</timestamp>
      <contributor>
        <username>Cedar101</username>
        <id>374440</id>
      </contributor>
      <minor/>
      <comment>/* Sexagesimal system */ &amp;prime;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="40940">[[File:Positional notation glossary-en.svg|thumb|300px|Glossary of terms used in the positional numeral systems.]]
{{numeral systems}}
'''Positional notation''' or '''place-value notation''' is a method of representing or encoding [[number]]s. Positional notation is distinguished from other notations (such as [[Roman numerals]]) for its use of the same symbol for the different [[orders of magnitude]] (for example, the "ones place", "tens place", "hundreds place"). This greatly simplified [[arithmetic]], leading to the rapid spread of the notation across the world.

With the use of a [[radix point]] (decimal point in base-10), the notation can be extended to include [[fraction (mathematics)|fraction]]s and the numeric expansions of [[real number]]s.

The [[Babylonian Numerals|Babylonian numeral system]], base-60, was the first positional system developed, and its influence is present today in the way time and angles are counted in tallies related to 60, like 60 minutes in an hour, 360 degrees in a circle. The [[Hindu–Arabic numeral system]], [[decimal representation|base-10]], is the most commonly used system in the world today for most calculations. The [[binary number|binary numeral system]], base-2, is straightforwardly implemented in [[digital electronics|digital electronic circuitry]] and used by almost all computer systems and electronics for calculations and representations.

==History==
[[File:abacus 6.png|thumb|[[Suanpan]] (the number represented in the picture is 6,302,715,408)]]
Today, the base-10 ([[decimal]]) system, which is likely motivated by counting with the ten [[finger]]s, is ubiquitous. Other bases have been used in the past, and some continue to be used today. For example, the [[Babylonian numerals|Babylonian numeral system]], credited as the first positional numeral system, was [[base-60]], but it lacked a real 0 value. Zero was indicated by a space between sexagesimal numerals. By 300&amp;nbsp;BC, a punctuation symbol (two slanted wedges) was co-opted as a [[Free variables and bound variables|placeholder]] in the same system. In a tablet unearthed at [[Kish (Sumer)|Kish]] (dating from about 700&amp;nbsp;BC), the scribe Bêl-bân-aplu wrote his zeros with three hooks, rather than two slanted wedges.&lt;ref name="multiref1"&gt;Kaplan, Robert. (2000). ''The Nothing That Is: A Natural History of Zero''. Oxford: Oxford University Press.&lt;/ref&gt; The Babylonian placeholder was not a true zero because it was not used alone. Nor was it used at the end of a number. Thus numbers like 2 and 120 (2×60), 3 and 180 (3×60), 4 and 240 (4×60), looked the same because the larger numbers lacked a final sexagesimal placeholder. Only context could differentiate them.

The polymath [[Archimedes]] (ca. 287–212 BC) invented a decimal positional system in his [[The Sand Reckoner|Sand Reckoner]] which was based on 10&lt;sup&gt;8&lt;/sup&gt;&lt;ref name="Greek numerals"&gt;[http://www-gap.dcs.st-and.ac.uk/~history/HistTopics/Greek_numbers.html Greek numerals]&lt;/ref&gt; and later led the German mathematician [[Carl Friedrich Gauss]] to lament what heights science would have already reached in his days if Archimedes had fully realized the potential of his ingenious discovery.&lt;ref&gt;[[Karl Menninger (mathematics)|Menninger, Karl]]: ''Zahlwort und Ziffer. Eine Kulturgeschichte der Zahl'', Vandenhoeck und Ruprecht, 3rd. ed., 1979, {{isbn|3-525-40725-4}}, pp. 150-153&lt;/ref&gt;

Before positional notation became standard, simple additive systems ([[sign-value notation]]) such as [[Roman numerals]] were used, and accountants in ancient Rome and during the Middle Ages used the [[abacus]] or stone counters to do arithmetic.&lt;ref&gt;Ifrah, page 187&lt;/ref&gt;

[[File:Chounumerals.svg|thumb|right|280px|The world's earliest positional decimal system&lt;br&gt; Upper row vertical form&lt;br&gt; Lower row horizontal form]]
[[Counting rods]] and most [[abacus]]es have been used to represent numbers in a positional numeral system. With counting rods or abacus to perform arithmetic operations, the writing of the starting, intermediate and final values of a calculation could easily be done with a simple additive system in each position or column. This approach required no memorization of tables (as does positional notation) and could produce practical results quickly. For four centuries (from the 13th to the 16th) there was strong disagreement between those who believed in adopting the positional system in writing numbers and those who wanted to stay with the additive-system-plus-abacus. Although electronic calculators have largely replaced the abacus, the latter continues to be used in Japan and other Asian countries.{{citation needed|date=November 2017}}

After the [[French Revolution]] (1789-1799), the new French government promoted the extension of the decimal system.&lt;ref&gt;
L. F. Menabrea.
Translated by Ada Augusta, Countess of Lovelace.
[http://www.fourmilab.ch/babbage/sketch.html "Sketch of The Analytical Engine Invented by Charles Babbage"].
1842.
&lt;/ref&gt;
Some of those pro-decimal efforts—such as [[decimal time]] and the [[decimal calendar]]—were unsuccessful.
Other French pro-decimal efforts—currency [[decimalisation]] and the [[metrication]] of weights and measures—spread widely out of France to almost the whole world.

=== History of positional fractions ===
{{Main|Decimal}}

J. Lennart Berggren notes that positional decimal fractions were used for the first time by Arab mathematician [[Abu'l-Hasan al-Uqlidisi]] as early as the 10th century.&lt;ref name=Berggren&gt;{{cite book | first=J. Lennart | last=Berggren | title=The Mathematics of Egypt, Mesopotamia, China, India, and Islam: A Sourcebook | chapter=Mathematics in Medieval Islam | publisher=Princeton University Press | year=2007 | isbn=978-0-691-11485-9 | page=518 }}&lt;/ref&gt; The Jewish mathematician [[Immanuel Bonfils]] used decimal fractions around 1350, anticipating [[Simon Stevin]], but did not develop any notation to represent them.&lt;ref&gt;[[Solomon Gandz|Gandz, S.]]: The invention of the decimal fractions and the application of the exponential calculus by Immanuel Bonfils of Tarascon (c. 1350), Isis 25 (1936), 16–45.&lt;/ref&gt; The Persian mathematician [[Jamshīd al-Kāshī]] claimed to have discovered decimal fractions himself in the 15th century.&lt;ref name=Berggren /&gt;[[Al Khwarizmi]] introduced fractions to Islamic countries in the early 9th century; his fraction presentation was an exact copy of traditional Chinese mathematical fractions from [[Sunzi Suanjing]].&lt;ref name=Lam&gt;[[Lam Lay Yong]], "The Development of Hindu-Arabic and Traditional Chinese Arithmetic", ''Chinese Science'', 1996 p38, Kurt Vogel notation&lt;/ref&gt; This form of fraction with numerator on top and denominator at bottom without a horizontal bar was also used by 10th century [[Abu'l-Hasan al-Uqlidisi]] and 15th century [[Jamshīd al-Kāshī]]'s work "Arithmetic Key".&lt;ref name=Lam/&gt;&lt;ref&gt;[[Lam Lay Yong]], "A Chinese Genesis, Rewriting the history of our numeral system", ''Archive for History of Exact Science'' 38: 101–108.&lt;/ref&gt;
&lt;div style="float: right;"&gt;[[File:Stevin-decimal notation.svg]]&lt;/div&gt;
A forerunner of modern European decimal notation was introduced by [[Simon Stevin]] in the 16th century.&lt;ref name=van&gt;{{Cite book | author = [[Bartel Leendert van der Waerden|B. L. van der Waerden]] | year = 1985 | title = A History of Algebra. From Khwarizmi to Emmy Noether | publisher = Springer-Verlag | place = Berlin}}&lt;/ref&gt;

==Issues==
A key argument against the positional system was its susceptibility to easy [[cheque fraud|fraud]] by simply putting a number at the beginning or end of a quantity, thereby changing (e.g.) 100 into 5100, or 100 into 1000. Modern [[cheque]]s require a natural language spelling of an amount, as well as the decimal amount itself, to prevent such fraud. For the same reason the Chinese also use natural language numerals, for example 100 is written as 壹佰, which can never be forged into 壹仟(1000) or 伍仟壹佰(5100).

Many of the advantages claimed for the metric system could be realized by any consistent positional notation.
[[Duodecimal#Advocacy and "dozenalism"|Dozenal advocates]] say dozenal has several advantages over decimal, although the [[switching cost]] appears to be high.

==Mathematics==
{{unreferenced section|date=March 2013}}

===Base of the numeral system===
In [[numeral system|mathematical numeral systems]] the base or radix is usually the number of unique [[Numerical digit|digits]], including zero, that a positional numeral system uses to represent numbers.  For example, for the decimal system the radix is 10, because it uses the 10 digits from 0 through 9. When a number "hits" 9, the next number will not be another different symbol, but a "1" followed by a "0". In binary, the radix is 2, since after it hits "1", instead of "2" or another written symbol, it jumps straight to "10", followed by "11" and "100".

The highest symbol of a positional numeral system usually has the value one less than the value of the base of that numeral system. The standard positional numeral systems differ from one another only in the base they use.

The base is an integer that is greater than 1 (or less than negative 1), since a radix of zero would not have any digits, and a radix of 1 would only have the zero digit. Negative bases are rarely used. In a system with a negative radix, numbers may have many different possible representations.

(In certain [[non-standard positional numeral systems]], including [[bijective numeration]], the definition of the base or the allowed digits deviates from the above.)

In base-10 (decimal) positional notation, there are 10 [[decimal digit]]s and the number
:&lt;math&gt;2506 = (2 \times 10^3) + (5 \times 10^2) + (0 \times 10^1) + (6 \times 10^0)&lt;/math&gt;.
In base-16 ([[hexadecimal]]), there are 16 hexadecimal digits (0–9 and A–F) and the number
:&lt;math&gt;171\mathrm{B} = (1 \times 16^3) + (7 \times 16^2) + (1 \times 16^1) + (\mathrm{B} \times 16^0) &lt;/math&gt; (where B represents the number eleven as a single symbol)

In general, in base-''b'', there are ''b'' digits and the number
:&lt;math&gt;a_3 a_2 a_1 a_0 = (a_3 \times b^3) + (a_2 \times b^2) + (a_1 \times b^1) + (a_0 \times b^0) &lt;/math&gt; (Note that &lt;math&gt;a_3 a_2 a_1 a_0&lt;/math&gt; represents a sequence of digits, not [[multiplication]])

===Notation===
When describing base in [[mathematical notation]], the letter ''b'' is generally used as a [[symbol]] for this concept, so, for a [[Binary numeral system|binary]] system, ''b'' [[equality (mathematics)|equals]] 2. Another common way of expressing the base is writing it as a '''decimal''' subscript after the number that is being represented (this notation is used in this article). 1111011&lt;sub&gt;2&lt;/sub&gt; implies that the number 1111011 is a base-2 number, equal to 123&lt;sub&gt;10&lt;/sub&gt; (a [[decimal notation]] representation), 173&lt;sub&gt;8&lt;/sub&gt; ([[octal]]) and 7B&lt;sub&gt;16&lt;/sub&gt; ([[hexadecimal]]). In books and articles, when using initially the written abbreviations of number bases, the base is not subsequently printed: it is assumed that binary 1111011 is the same as 1111011&lt;sub&gt;2&lt;/sub&gt;.

The base ''b'' may also be indicated by the phrase "base-''b''". So binary numbers are "base-2"; octal numbers are "base-8"; decimal numbers are "base-10"; and so on.

To a given radix ''b'' the set of digits {0, 1, ..., ''b''−2, ''b''−1} is called the standard set of digits. Thus, binary numbers have digits {0, 1}; decimal numbers have digits {{nowrap|{0, 1, 2, ..., 8, 9};}} and so on. Therefore, the following are notational errors: 52&lt;sub&gt;2&lt;/sub&gt;, 2&lt;sub&gt;2&lt;/sub&gt;, 1A&lt;sub&gt;9&lt;/sub&gt;. (In all cases, one or more digits is not in the set of allowed digits for the given base.)

===Exponentiation===
Positional numeral systems work using [[exponentiation]] of the base. A digit's value is the digit multiplied by the value of its place. Place values are the number of the base raised to the ''n''th power, where ''n'' is the number of other digits between a given digit and the [[radix point]]. If a given digit is on the left hand side of the radix point (i.e. its value is an [[integer]]) then ''n'' is positive or zero; if the digit is on the right hand side of the radix point (i.e., its value is fractional) then ''n'' is negative.

As an example of usage, the number 465 in its respective base ''b'' (which must be at least base 7 because the highest digit in it is 6) is equal to:
:&lt;math&gt;4\times b^2 + 6\times b^1 + 5\times b^0&lt;/math&gt;

If the number 465 was in base-10, then it would equal:
:&lt;math&gt;4\times 10^2 + 6\times 10^1 + 5\times 10^0 = 4\times 100 + 6\times 10 + 5\times 1 = 465&lt;/math&gt;
(465&lt;sub&gt;10&lt;/sub&gt; = 465&lt;sub&gt;10&lt;/sub&gt;)

If however, the number were in base 7, then it would equal:
:&lt;math&gt;4\times 7^2 + 6\times 7^1 + 5\times 7^0 = 4\times 49 + 6\times 7 + 5\times 1 = 243&lt;/math&gt;
(465&lt;sub&gt;7&lt;/sub&gt; = 243&lt;sub&gt;10&lt;/sub&gt;)

10&lt;sub&gt;''b''&lt;/sub&gt; = ''b'' for any base ''b'', since 10&lt;sub&gt;''b''&lt;/sub&gt; = 1×''b''&lt;sup&gt;1&lt;/sup&gt; + 0×''b''&lt;sup&gt;0&lt;/sup&gt;. For example, 10&lt;sub&gt;2&lt;/sub&gt; = 2; 10&lt;sub&gt;3&lt;/sub&gt; = 3; 10&lt;sub&gt;16&lt;/sub&gt; = 16&lt;sub&gt;10&lt;/sub&gt;. Note that the last "16" is indicated to be in base 10. The base makes no difference for one-digit numerals.

This concept can be demonstrated using a diagram. One object represents one unit. When the number of objects is equal to or greater than the base ''b'', then a group of objects is created with ''b'' objects.  When the number of these groups exceeds ''b'', then a group of these groups of objects is created with ''b'' groups of ''b'' objects; and so on. Thus the same number in different bases will have different values:

 241 in base 5:
    2 groups of 5&lt;sup&gt;2&lt;/sup&gt; (25)           4 groups of 5          1 group of 1
    ooooo    ooooo
    ooooo    ooooo                ooooo   ooooo
    ooooo    ooooo         +                         +         o
    ooooo    ooooo                ooooo   ooooo
    ooooo    ooooo

 241 in base 8:
    2 groups of 8&lt;sup&gt;2&lt;/sup&gt; (64)          4 groups of 8          1 group of 1
  oooooooo  oooooooo
  oooooooo  oooooooo
  oooooooo  oooooooo         oooooooo   oooooooo
  oooooooo  oooooooo    +                            +        o
  oooooooo  oooooooo
  oooooooo  oooooooo         oooooooo   oooooooo
  oooooooo  oooooooo
  oooooooo  oooooooo

The notation can be further augmented by allowing a leading minus sign. This allows the representation of negative numbers. For a given base, every representation corresponds to exactly one [[real number]] and every real number has at least one representation. The representations of rational numbers are those representations that are finite, use the bar notation, or end with an infinitely repeating cycle of digits.

===Digits and numerals===
A ''digit'' is what is used as a position in place-value notation, and a ''numeral'' is one or more digits. Today's most common digits are the [[Arabic numerals|decimal digits]] "0", "1", "2", "3", "4", "5", "6", "7", "8", and "9". The distinction between a digit and a numeral is most pronounced in the context of a number base.

A non-zero ''numeral'' with more than one digit position will mean a different number in a different number base, but in general, the ''digits'' will mean the same.&lt;ref&gt;The digit will retain its meaning in other number bases, in general, because a higher number base would normally be a notational extension of the lower number base in any systematic organization. In the [[mathematical science]]s there is virtually only one positional-notation numeral system for each base below 10, and this extends with few, if insignificant, variations on the choice of alphabetic digits for those bases above 10.&lt;/ref&gt; The base-8 numeral 23&lt;sub&gt;8&lt;/sub&gt; contains two digits, "2" and "3", and with a base number (subscripted) "8", means 19. In our notation here, the subscript "&lt;sub&gt;8&lt;/sub&gt;" of the numeral 23&lt;sub&gt;8&lt;/sub&gt; is part of the numeral, but this may not always be the case. Imagine the numeral "23" as having [[#Non-standard positional numeral systems|an ambiguous base]] number. Then "23" could likely be any base, base-4 through base-60. In base-4 "23" means 11, and in base-60 it means the number 123. The numeral "23" then, in this case, corresponds to the set of numbers {11, 13, 15, 17, 19, 21, '''23''', ..., 121, 123} while its digits "2" and "3" always retain their original meaning: the "2" means "two of", and the "3" three.

In certain applications when a numeral with a fixed number of positions needs to represent a greater number, a higher number-base with more digits per position can be used. A three-digit, decimal numeral can represent only up to '''999'''. But if the number-base is increased to 11, say, by adding the digit "A", then the same three positions, maximized to "AAA", can represent a number as great as '''1330'''. We could increase the number base again and assign "B" to 11, and so on (but there is also a possible encryption between number and digit in the number-digit-numeral hierarchy). A three-digit numeral "ZZZ" in base-60 could mean '''{{val|215999}}'''. If we use the entire collection of our [[alphanumerics]] we could ultimately serve a base-''62'' numeral system, but we remove two digits, uppercase "I" and uppercase "O", to reduce confusion with digits "1" and "0".&lt;ref&gt;We do ''not'' usually remove the ''lowercase'' digits "l" and lowercase "o", for in most fonts they are discernible from the digits "1" and "0".&lt;/ref&gt;
We are left with a base-60, or sexagesimal numeral system utilizing 60 of the 62 standard alphanumerics. (But see ''[[#Sexagesimal system|Sexagesimal system]]'' below.) In general, the number of possible values that can be represented by a &lt;math&gt;d&lt;/math&gt; digit number in base &lt;math&gt;r&lt;/math&gt; is &lt;math&gt;r^d&lt;/math&gt;.

The common numeral systems in computer science are binary (radix 2), octal (radix 8), and hexadecimal (radix 16). In [[Binary numeral system|binary]] only digits "0" and "1" are in the numerals. In the [[octal]] numerals, are the eight digits 0–7. [[Hexadecimal|Hex]] is 0–9 A–F, where the ten numerics retain their usual meaning, and the alphabetics correspond to values 10–15, for a total of sixteen digits. The numeral "10" is binary numeral "2", octal numeral "8", or hexadecimal numeral "16".

===Radix point===
{{main|Radix point}}
The notation can be extended into the negative exponents of the base ''b''. Thereby the so-called radix point, mostly ».«, is used as separator of the positions with non-negative from those with negative exponent.

Numbers that are not [[integer]]s use places beyond the [[radix point]]. For every position behind this point (and thus after the units digit), the exponent ''n'' of the power ''b''&lt;sup&gt;''n''&lt;/sup&gt; decreases by 1 and the power approaches 0. For example, the number 2.35 is equal to:
:&lt;math&gt;2\times 10^0 + 3\times 10^{-1} + 5\times 10^{-2}&lt;/math&gt;

===Sign===
{{main|Sign (mathematics)}}
If the base and all the digits in the set of digits are non-negative, negative numbers cannot be expressed. To overcome this, a [[Negative number|minus sign]], here »-«, is added to the numeral system. In the usual notation it is prepended to the string of digits representing the otherwise non-negative number.

===Base conversion===
&lt;!-- This section is the target of a redirect --&gt;
{{expand section|date=March 2017}}
The conversion to a base &lt;math&gt;b_2&lt;/math&gt; of an integer {{math|''n''}} represented in base &lt;math&gt;b_1&lt;/math&gt; can be done by a succession of [[Euclidean division]]s by &lt;math&gt;b_2:&lt;/math&gt; the right-most digit in base &lt;math&gt;b_2&lt;/math&gt; is the remainder of the division of {{math|''n''}} by &lt;math&gt;b_2;&lt;/math&gt; the second right-most digit is the remainder of the division of the quotient by &lt;math&gt;b_2,&lt;/math&gt; and so on. More precisely, the {{math|''k''}}th digit from the right is the remainder of the division by &lt;math&gt;b_2&lt;/math&gt; of the  {{math|(''k''−1)}}th quotient.

For example: converting A10B&lt;sub&gt;Hex&lt;/sub&gt; to decimal (41227):
 0xA10B/10 = 0x101A R: 7 (ones place)
 0x101A/10 = 0x19C  R: 2 (tens place)
  0x19C/10 = 0x29   R: 2 (hundreds place)
   0x29/10 = 0x4    R: 1  ...
    0x4/10 = 0x0    R: 4

When converting to a larger base (such as from binary to decimal), the remainder represents &lt;math&gt;b_2&lt;/math&gt; as a single digit, using digits from &lt;math&gt;b_1&lt;/math&gt;. For example: converting 0b11111001 (binary) to 249 (decimal):
 0b11111001/10 = 0b11000 R: 0b1001 (0b1001 = "9" for ones place)
    0b11000/10 = 0b10    R: 0b100  (0b100 =  "4" for tens)
       0b10/10 = 0b0     R: 0b10   (0b10 =   "2" for hundreds)

===Terminating fractions===
The numbers which have a finite representation form the [[semiring]]
:&lt;math&gt;\frac{\N_0}{b^{\N_0}} := \left\{mb^{-\nu}\mid m\in \N_0 \wedge \nu\in \N_0 \right\} .&lt;/math&gt;
More explicitly, if &lt;math&gt;p_1^{\nu_1} \cdot \ldots \cdot p_n^{\nu_n} := b&lt;/math&gt; is a [[factorization]] of &lt;math&gt;b&lt;/math&gt; into the primes &lt;math&gt;p_1, \ldots ,p_n \in \mathbb P&lt;/math&gt; with exponents {{nowrap|&lt;math&gt;\nu_1, \ldots ,\nu_n \in \N&lt;/math&gt;,&lt;ref&gt;The exact size of the &lt;math&gt;\nu_1, \ldots ,\nu_n&lt;/math&gt; does not matter. They only have to be &amp;ge; 1.&lt;/ref&gt;}} then with the non-empty set of denominators &lt;math&gt; S := \{ p_1, \ldots, p_n \} &lt;/math&gt;
we have
:&lt;math&gt; \Z_S := \left\{x \in \Q \left | \, \exists \mu_i \in \Z : x \prod_{i=1}^n {p_i}^{\mu_i} \in \Z \right . \right\} = b^{\Z} \, \Z = {\langle S\rangle}^{-1}\Z &lt;/math&gt;
where &lt;math&gt;\langle S\rangle&lt;/math&gt; is the group generated by the &lt;math&gt;p\in S&lt;/math&gt; and &lt;math&gt; {\langle S\rangle}^{-1}\Z &lt;/math&gt; is the so-called [[Localization (algebra)#Localization of a ring|localization]] of &lt;math&gt;\Z&lt;/math&gt; with respect to {{nowrap|&lt;math&gt;S&lt;/math&gt;.}}

The [[Fraction (mathematics)|denominator]] of an element of &lt;math&gt; \Z_S &lt;/math&gt; contains if reduced to lowest terms only prime factors out of &lt;math&gt;S&lt;/math&gt;.
This [[Ring (mathematics)|ring]] of all terminating fractions to base &lt;math&gt;b&lt;/math&gt; is [[Dense set|dense]] in the field of [[rational number]]s &lt;math&gt;\Q&lt;/math&gt;. Its [[Complete metric space|completion]] for the usual (Archimedean) metric is the same as for &lt;math&gt;\Q&lt;/math&gt;, namely the real numbers &lt;math&gt;\R&lt;/math&gt;. So, if &lt;math&gt; S = \{ p\} &lt;/math&gt; then &lt;math&gt; \Z_{\{ p\}} &lt;/math&gt; has not to be confused with &lt;math&gt;\Z_{(p)} &lt;/math&gt;, the [[discrete valuation ring]] for the [[prime number|prime]] &lt;math&gt;p&lt;/math&gt;, which is equal to &lt;math&gt;\Z_{T} &lt;/math&gt; with &lt;math&gt; T = \mathbb P \setminus \{ p\} &lt;/math&gt;.

If &lt;math&gt;b&lt;/math&gt; divides &lt;math&gt;c&lt;/math&gt;, we have &lt;math&gt; b^{\Z} \, \Z \subseteq c^{\Z} \, \Z.&lt;/math&gt;

===Infinite representations===
{{unreferenced section|date=January 2013}}
The representation of non-integers can be extended to allow an infinite string of digits beyond the point. For example, 1.12112111211112&amp;nbsp;... base-3 represents the sum of the infinite [[series (mathematics)|series]]:
:&lt;math&gt;\begin{array}{l}
1\times 3^{0\,\,\,} + {}\\
1\times 3^{-1\,\,} + 2\times 3^{-2\,\,\,} + {}\\
1\times 3^{-3\,\,} + 1\times 3^{-4\,\,\,} + 2\times 3^{-5\,\,\,} + {}\\
1\times 3^{-6\,\,} + 1\times 3^{-7\,\,\,} + 1\times 3^{-8\,\,\,} + 2\times 3^{-9\,\,\,} + {}\\
1\times 3^{-10} + 1\times 3^{-11} + 1\times 3^{-12} + 1\times 3^{-13} + 2\times 3^{-14} + \cdots
\end{array}&lt;/math&gt;

Since a complete infinite string of digits cannot be explicitly written, the trailing ellipsis (...) designates the omitted digits, which may or may not follow a pattern of some kind. One common pattern is when a finite sequence of digits repeats infinitely. This is designated by drawing a [[Vinculum (symbol)|vinculum]] across the repeating block:
:&lt;math&gt;2.42\overline{314}_5 = 2.42314314314314314\dots_5&lt;/math&gt;

For base-10 it is called a [[recurring decimal]] or repeating decimal.

An [[irrational number]] has an infinite non-repeating representation in all integer bases. Whether a [[rational number]] has a finite representation or requires an infinite repeating representation depends on the base. For example, one third can be represented by:
:&lt;math&gt;0.1_3&lt;/math&gt;
:&lt;math&gt;0.\overline3_{10} = 0.3333333\dots_{10}&lt;/math&gt;
::or, with the base implied:
::&lt;math&gt;0.\overline3 = 0.3333333\dots&lt;/math&gt;
:&lt;math&gt;0.\overline{01}_2 = 0.010101\dots_2&lt;/math&gt;
:&lt;math&gt;0.2_6&lt;/math&gt;

For integers ''p'' and ''q'' with [[greatest common divisor|''gcd'']](''p'', ''q'') = 1, the [[fraction (mathematics)|fraction]] ''p''/''q'' has a finite representation in base ''b'' if and only if each [[prime factor]] of ''q'' is also a prime factor of ''b''.

For a given base, any number that can be represented by a finite number of digits (without using the bar notation) will have multiple representations, including one or two infinite representations:
:1. A finite or infinite number of zeroes can be appended:
::&lt;math&gt;3.46_7 = 3.460_7 = 3.460000_7 = 3.46\overline0_7&lt;/math&gt;
:2. The last non-zero digit can be reduced by one and an infinite string of digits, each corresponding to one less than the base, are appended (or replace any following zero digits):
::&lt;math&gt;3.46_7 = 3.45\overline6_7&lt;/math&gt;
::&lt;math&gt;1_{10} = 0.\overline9_{10}&lt;/math&gt;
::&lt;math&gt;220_5 = 214.\overline4_5&lt;/math&gt;

==Applications==

===Decimal system===
{{Main|Decimal representation}}
In the [[decimal]] (base-10) [[Hindu–Arabic numeral system]], each position starting from the right is a higher power of 10. The first position represents [[1 E0|10&lt;sup&gt;0&lt;/sup&gt;]] (1), the second position [[1 E1|10&lt;sup&gt;1&lt;/sup&gt;]] (10), the third position [[1 E2|10&lt;sup&gt;2&lt;/sup&gt;]] ({{nowrap|10 × 10}} or 100), the fourth position [[1000 (number)|10&lt;sup&gt;3&lt;/sup&gt;]] ({{nowrap|10 × 10 × 10}} or 1000), and so on.

[[Decimal|Fraction]]al values are indicated by a [[Decimal separator|separator]], which can vary in different locations. Usually this separator is a period or [[full stop]], or a [[comma (punctuation)|comma]]. Digits to the right of it are multiplied by 10 raised to a negative power or exponent. The first position to the right of the separator indicates [[1 E-1|10&lt;sup&gt;−1&lt;/sup&gt;]] (0.1), the second position [[1 E-2|10&lt;sup&gt;−2&lt;/sup&gt;]] (0.01), and so on for each successive position.

As an example, the number 2674 in a base-10 numeral system is:
:(2 × 10&lt;sup&gt;3&lt;/sup&gt;) + (6 × 10&lt;sup&gt;2&lt;/sup&gt;) + (7 × 10&lt;sup&gt;1&lt;/sup&gt;) + (4 × 10&lt;sup&gt;0&lt;/sup&gt;)

or
:(2 × 1000) + (6 × 100) + (7 × 10) + (4 × 1).

===Sexagesimal system===
The [[sexagesimal]] or base-60 system was used for the integral and fractional portions of [[Babylonian numerals]] and other mesopotamian systems, by [[Hellenistic]] astronomers using [[Greek numerals]] for the fractional portion only, and is still used for modern time and angles, but only for minutes and seconds. However, not all of these uses were positional.

Modern time separates each position by a colon or point. For example, the time might be 10:25:59 (10 hours 25 minutes 59 seconds). Angles use similar notation. For example, an angle might be 10°25'59" (10 [[degree (angle)|degree]]s 25 [[minute (angle)|minute]]s 59 [[second (angle)|second]]s). In both cases, only minutes and seconds use sexagesimal notation—angular degrees can be larger than 59 (one rotation around a circle is 360°, two rotations are 720°, etc.), and both time and angles use decimal fractions of a second. This contrasts with the numbers used by Hellenistic and [[Renaissance]] astronomers, who used [[third (angle)|third]]s, [[fourth (angle)|fourth]]s, etc. for finer increments. Where we might write 10°25'59.392", they would have written 10°25′59″23‴31⁗12&amp;prime;&amp;prime;&amp;prime;&amp;prime;&amp;prime; or 10°25&lt;sup&gt;I&lt;/sup&gt;59&lt;sup&gt;II&lt;/sup&gt;23&lt;sup&gt;III&lt;/sup&gt;31&lt;sup&gt;IV&lt;/sup&gt;12&lt;sup&gt;V&lt;/sup&gt;.

Using a digit set of digits with upper and lowercase letters allows short notation for sexagesimal numbers, e.g. 10:25:59 becomes 'ARz' (by omitting I and O, but not i and o), which is useful for use in URLs, etc., but it is not very intelligible to humans.

In the 1930s, [[Otto Neugebauer]] introduced a modern notational system for Babylonian and Hellenistic numbers that substitutes modern decimal notation from 0 to 59 in each position, while using a semicolon (;) to separate the integral and fractional portions of the number and using a comma (,) to separate the positions within each portion. For example, the mean [[synodic month]] used by both Babylonian and Hellenistic astronomers and still used in the [[Hebrew calendar]] is 29;31,50,8,20 days, and the angle used in the example above would be written 10;25,59,23,31,12 degrees.

===Computing===
In [[computing]], the [[Binary numeral system|binary]] (base-2), octal (base-8) and [[hexadecimal]] (base-16) bases are most commonly used. Computers, at the most basic level, deal only with sequences of conventional zeroes and ones, thus it is easier in this sense to deal with powers of two. The hexadecimal system is used as "shorthand" for binary—every 4 binary digits (bits) relate to one and only one hexadecimal digit. In hexadecimal, the six digits after 9 are denoted by A, B, C, D, E, and F (and sometimes a, b, c, d, e, and f).

The [[octal]] numbering system is also used as another way to represent binary numbers. In this case the base is 8 and therefore only digits 0, 1, 2, 3, 4, 5, 6, and 7 are used. When converting from binary to octal every 3 bits relate to one and only one octal digit.

Hexadecimal, decimal, octal, and a wide variety of other bases have been used for [[binary-to-text encoding]], implementations of [[arbitrary-precision arithmetic]], and other applications.

''For a list of bases and their applications, see [[list of numeral systems]].''

===Other bases in human language===
Base-12 systems ([[duodecimal]] or dozenal) have been popular because multiplication and division are easier than in base-10, with addition and subtraction being just as easy. Twelve is a useful base because it has many [[divisor|factors]]. It is the smallest common multiple of one, two, three, four and six. There is still a special word for "dozen" in English, and by analogy with the word for 10&lt;sup&gt;2&lt;/sup&gt;, ''hundred'', commerce developed a word for 12&lt;sup&gt;2&lt;/sup&gt;, ''gross''. The standard 12-hour clock and common use of 12 in English units emphasize the utility of the base. In addition, prior to its conversion to decimal, the old British currency [[Pound Sterling]] (GBP) ''partially'' used base-12; there were 12 pence (d) in a shilling (s), 20 shillings in a pound (£), and therefore 240 pence in a pound. Hence the term LSD or, more properly, [[£sd]].

The [[Maya civilization]] and other civilizations of [[pre-Columbian]] [[Mesoamerica]] used base-20 ([[vigesimal]]), as did several North American tribes (two being in southern California). Evidence of base-20 counting systems is also found in the languages of central and western [[Africa]].

Remnants of a [[Gaulish language|Gaulish]] base-20 system also exist in French, as seen today in the names of the numbers from 60 through 99. For example, sixty-five is ''soixante-cinq'' (literally, "sixty [and] five"), while seventy-five is ''soixante-quinze'' (literally, "sixty [and] fifteen"). Furthermore, for any number between 80 and 99, the "tens-column" number is expressed as a multiple of twenty. For example, eighty-two is ''quatre-vingt-deux'' (literally, four twenty[s] [and] two), while ninety-two is ''quatre-vingt-douze'' (literally, four twenty[s] [and] twelve). In Old French, forty was expressed as two twenties and sixty was three twenties, so that fifty-three was expressed as two twenties [and] thirteen, and so on.

In English the same base-20 counting appears in the use of "[[20 (number)|scores]]".  Although mostly historical it is occasionally used colloquially.  Verse 10 of Pslam 90 in the King James Version of the Bible starts: "The days of our years are threescore years and ten; and if by reason of strength they be fourscore years, yet is their strength labour and sorrow".  The Gettysburg Address starts: "Four score and seven years ago".

The [[Irish language]] also used base-20 in the past, twenty being ''fichid'', forty ''dhá fhichid'', sixty ''trí fhichid'' and eighty ''ceithre fhichid''. A remnant of this system may be seen in the modern word for 40, ''daoichead''.

The [[Welsh language]] continues to use a [[vigesimal|base-20]] [[Welsh language#Counting system|counting system]], particularly for the age of people, dates and in common phrases. 15 is also important, with 16–19 being "one on 15", "two on 15" etc. 18 is normally "two nines". A decimal system is commonly used.

[[Danish language#Numerals|Danish numerals]] display a similar [[vigesimal|base-20]] structure.

The Maori language of New Zealand also has evidence of an underlying base-20 system as seen in the terms ''Te Hokowhitu a Tu'' referring to a war party (literally "the seven 20s of Tu") and ''Tama-hokotahi'', referring to a great warrior ("the one man equal to 20").

[[Binary numeral system|The binary system]] was used in the Egyptian Old Kingdom, 3000&amp;nbsp;BC to 2050&amp;nbsp;BC. It was cursive by rounding off rational numbers smaller than 1 to {{nowrap|1/2 + 1/4 + 1/8 + 1/16 + 1/32 + 1/64}}, with a 1/64 term thrown away (the system was called the [[Eye of Horus#Mathematics|Eye of Horus]]).

A number of [[Australian Aboriginal languages]] employ binary or binary-like counting systems. For example, in [[Kala Lagaw Ya]], the numbers one through six are ''urapon'', ''ukasar'', ''ukasar-urapon'', ''ukasar-ukasar'', ''ukasar-ukasar-urapon'', ''ukasar-ukasar-ukasar''.

North and Central American natives used base-4 ([[Quaternary numeral system|quaternary]]) to represent the four cardinal directions. Mesoamericans tended to add a second base-5 system to create a modified base-20 system.

A base-5 system ([[quinary]]) has been used in many cultures for counting. Plainly it is based on the number of digits on a human hand. It may also be regarded as a sub-base of other bases, such as base-10, base-20, and base-60.

A base-8 system ([[octal]]) was devised by the [[Yuki tribe]] of Northern California, who used the spaces between the fingers to count, corresponding to the digits one through eight.&lt;ref&gt;{{citation|page=38|title=Pi in the sky: counting, thinking, and being|first=John D.|last=Barrow|publisher=Clarendon Press|year=1992|isbn=9780198539568}}.&lt;/ref&gt; There is also linguistic evidence which suggests that the Bronze Age [[Proto-Indo European]]s (from whom most European and Indic languages descend) might have replaced a base-8 system (or a system which could only count up to 8) with a base-10 system. The evidence is that the word for 9, ''newm'', is suggested by some to derive from the word for "new", ''newo-'', suggesting that the number 9 had been recently invented and called the "new number".&lt;ref&gt;(Mallory &amp; Adams 1997) [[Encyclopedia of Indo-European Culture]]&lt;/ref&gt;

Many ancient counting systems use five as a primary base, almost surely coming from the number of fingers on a person's hand. Often these systems are supplemented with a secondary base, sometimes ten, sometimes twenty. In some [[African languages]] the word for five is the same as "hand" or "fist" ([[Dyola language]] of [[Guinea-Bissau]], [[Banda languages|Banda language]] of [[Central Africa]]). Counting continues by adding 1, 2, 3, or 4 to combinations of 5, until the secondary base is reached. In the case of twenty, this word often means "man complete". This system is referred to as ''quinquavigesimal''. It is found in many languages of the [[Sudan]] region.

The [[Telefol language]], spoken in [[Papua New Guinea]], is notable for possessing a base-27 numeral system.

==Non-standard positional numeral systems==
{{Main|Non-standard positional numeral systems}}
Interesting properties exist when the base is not fixed or positive and when the digit symbol sets denote negative values. There are many more variations. These systems are of practical and theoretic value to computer scientists.

[[Balanced ternary]] uses a base of 3 but the digit set is {{mset|{{overline|1}},0,1}} instead of {0,1,2}. The "{{overline|1}}" has an equivalent value of −1. The negation of a number is easily formed by switching the {{overline|&amp;nbsp;&amp;nbsp;}} on the 1s. This system can be used to solve the [[balance problem]], which requires finding a minimal set of known counter-weights to determine an unknown weight. Weights of 1, 3, 9, ... 3&lt;sup&gt;''n''&lt;/sup&gt; known units can be used to determine any unknown weight up to 1 + 3 + ... + 3&lt;sup&gt;''n''&lt;/sup&gt; units. A weight can be used on either side of the balance or not at all. Weights used on the balance pan with the unknown weight are designated with {{overline|1}}, with 1 if used on the empty pan, and with 0 if not used. If an unknown weight ''W'' is balanced with 3 (3&lt;sup&gt;1&lt;/sup&gt;) on its pan and 1 and 27 (3&lt;sup&gt;0&lt;/sup&gt; and 3&lt;sup&gt;3&lt;/sup&gt;) on the other, then its weight in decimal is 25 or 10{{overline|1}}1 in balanced base-3. 
:{{math|10{{overline|1}}1&lt;sub&gt;3&lt;/sub&gt; {{=}} 1 × 3&lt;sup&gt;3&lt;/sup&gt; + 0 × 3&lt;sup&gt;2&lt;/sup&gt; − 1 × 3&lt;sup&gt;1&lt;/sup&gt; + 1 × 3&lt;sup&gt;0&lt;/sup&gt; {{=}} 25.}}

The [[factorial number system]] uses a varying radix, giving [[factorial]]s as place values; they are related to [[Chinese remainder theorem]] and [[residue number system]] enumerations. This system effectively enumerates permutations. A derivative of this uses the [[Towers of Hanoi]] puzzle configuration as a counting system. The configuration of the towers can be put into 1-to-1 correspondence with the decimal count of the step at which the configuration occurs and vice versa.

{|class="wikitable" style="text-align:center;" border="1"
!align="left" |Decimal equivalents
|width="6%" |−3
|width="6%" |−2
|width="6%" |−1
|width="6%" |0
|width="6%" |1
|width="6%" |2
|width="6%" |3
|width="6%" |4
|width="6%" |5
|width="8%" |6
|width="8%" |7
|width="8%" |8
|-
!align="left" |Balanced base 3
|{{overline|1}}0
|{{overline|1}}1
|{{overline|1}}
|0
|1
|1{{overline|1}}
|10
|11
|1{{overline|1}}{{overline|1}}
|1{{overline|1}}0
|1{{overline|1}}1
|10{{overline|1}}
|-
!align="left" |Base −2
|1101
|10
|11
|0
|1
|110
|111
|100
|101
|11010
|11011
|11000
|-
!align="left" |Factoroid
| || || ||0 ||10 ||100 ||110 ||200 ||210 ||1000 ||1010 ||1100
|}

==Non-positional positions==
Each position does not need to be positional itself. Babylonian sexagesimal numerals were positional, but in each position were groups of two kinds of wedges representing ones and tens (a narrow vertical wedge ( | ) and an open left pointing wedge (&lt;))—up to 14 symbols per position (5 tens (&lt;&lt;&lt;&lt;&lt;) and 9 ones ( ||||||||| ) grouped into one or two near squares containing up to three tiers of symbols, or a place holder (\\) for the lack of a position).&lt;ref&gt;Ifrah, pages 326, 379&lt;/ref&gt; Hellenistic astronomers used one or two alphabetic Greek numerals for each position (one chosen from 5 letters representing 10–50 and/or one chosen from 9 letters representing 1–9, or a [[Greek numerals#Hellenistic zero|zero symbol]]).&lt;ref&gt;Ifrah, pages 261-264&lt;/ref&gt;

==See also==

Examples:
*[[List of numeral systems]]
*[[:Category:Positional numeral systems]]

Related topics:
*[[Numeral system]]
*[[Hindu-Arabic numeral system]]
*[[Non-standard positional numeral systems]]
*[[Mixed radix]]
*[[Scientific notation]]
*[[Algorism]]
*[[Subtractive notation]]

==Notes==
{{Reflist}}

==References==
*{{Cite web
|last=O'Connor
|first=John
|last2=Robertson
|first2=Edmund
|title=Babylonian Numerals
|date=December 2000
|url=http://www-groups.dcs.st-and.ac.uk/~history/HistTopics/Babylonian_numerals.html
|accessdate=21 August 2010
|postscript=.}}
*{{Cite journal
|last=Kadvany
|first=John
|title=Positional Value and Linguistic Recursion
|journal=Journal of Indian Philosophy
|date=December 2007}}
*{{Cite book
|last=Knuth
|first=Donald
|authorlink=Donald Knuth
|title=The art of Computer Programming
|volume=2
|pages=195–213
|publisher=Addison-Wesley
|year=1997
|isbn=0-201-89684-2}}
*{{Cite book
|last=Ifrah
|first=George
|title=The Universal History of Numbers: From Prehistory to the Invention of the Computer
|publisher=Wiley
|year=2000
|isbn=0-471-37568-3}}
*{{Cite book
|last=Kroeber
|first=Alfred
|authorlink=Alfred Kroeber
|title=Handbook of the Indians of California
|publisher=Courier Dover Publications
|year=1976
|origyear=1925
|page=176
|url=https://books.google.com/books?id=Plqf_OTz4ukC
|isbn=9780486233680}}

==External links==

{{Commonscat|Positional numeral systems}}

*[http://ultrastudio.org/en/MechengburakalkanApplet-1.7.zip Accurate Base Conversion]
*[http://www.ibrarian.net/navon/paper/The_Development_of_Hindu_Arabic_and_Traditional_C.pdf?paperid=1247217 The Development of Hindu Arabic and Traditional Chinese Arithmetics]
*[http://www.cut-the-knot.org/recurrence/conversion.shtml Implementation of Base Conversion] at [[cut-the-knot]]
*[http://www.intuitor.com/counting/ Learn to count other bases on your fingers]
*[http://thedevtoolkit.com/tools/base_conversion Online Arbitrary Precision Base Converter]
{{Use dmy dates|date=September 2010}}

{{DEFAULTSORT:Positional Notation}}
[[Category:Positional numeral systems| ]]
[[Category:Mathematical notation]]
[[Category:Articles containing proofs]]</text>
      <sha1>9ec3x5yogq8yl8bcmfehm7yz8ohpovr</sha1>
    </revision>
  </page>
  <page>
    <title>Quantifier rank</title>
    <ns>0</ns>
    <id>35975525</id>
    <revision>
      <id>742552603</id>
      <parentid>739365537</parentid>
      <timestamp>2016-10-04T11:03:41Z</timestamp>
      <contributor>
        <username>Emlili</username>
        <id>29132004</id>
      </contributor>
      <minor/>
      <comment>/* Examples */ LaTeX added.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3301">In [[mathematical logic]], the '''quantifier rank''' of a [[Formula (mathematical logic)|formula]] is the depth of nesting of its [[Quantifier (logic)|quantifiers]]. It plays an essential role in [[model theory]].

Notice that the quantifier rank is a property of the formula itself (i.e. the expression in a language).  Thus two [[Logical equivalence|logically equivalent]] formulae can have different quantifier ranks, when they express the same thing in different ways.

==Definition==
'''Quantifier Rank of a Formula in [[First-order language]] (FO)'''

Let φ be a FO formula. The quantifier rank of φ, written qr(φ), is defined as
* &lt;math&gt;qr(\varphi) = 0&lt;/math&gt;, if φ is atomic.
* &lt;math&gt;qr(\varphi_1 \land \varphi_2) = qr(\varphi_1 \lor \varphi_2) = max(qr(\varphi_1), qr(\varphi_2))&lt;/math&gt;.
* &lt;math&gt;qr(\lnot \varphi) = qr(\varphi)&lt;/math&gt;.
* &lt;math&gt;qr(\exists_x \varphi) = qr(\varphi) + 1&lt;/math&gt;.

'''Remarks'''
* We write FO[n] for the set of all [[First-order logic|first-order]] formulas φ with &lt;math&gt;qr(\varphi) \le n&lt;/math&gt;.
* Relational FO[n] (without function symbols) is always of finite size, i.e. contains a finite number of formulas
* Notice that in [[Prenex normal form]] the Quantifier Rank of φ is exactly the number of quantifiers appearing in φ.

'''Quantifier Rank of a higher order Formula'''
* For [[Fixpoint logic]], with a least fix point operator LFP:
: &lt;big&gt;qr([LFP&lt;sub&gt;&amp;phi;&lt;/sub&gt;]y) = 1 + qr( &amp;phi;)&lt;/big&gt;
...

==Examples==
* A sentence of quantifier rank 2:
: &lt;math&gt;\forall x\exists y R(x, y)&lt;/math&gt; 
* A formula of quantifier rank 1:
: &lt;math&gt;\forall x R(y, x) \wedge \exists x R(x, y)&lt;/math&gt;
* A formula of quantifier rank 0:
: &lt;math&gt;R(x, y) \wedge x \neq y&lt;/math&gt;
* A sentence in [[prenex normal form]] of quantifier rank 3:
: &lt;math&gt;\forall x \exists y \exists z ((x \neq y \wedge x R y) \wedge (x \neq z \wedge z R x)) &lt;/math&gt; 
* A sentence, equivalent to the previous, although of quantifier rank 2:
: &lt;math&gt;\forall x (\exists y (x \neq y \wedge x R y)) \wedge \exists z (x \neq z \wedge z R x )) &lt;/math&gt;

==See also==
* [[Prenex normal form]]
* [[Ehrenfeucht game]]
* [[Quantifier (logic)|Quantifier]]

==References==
* {{Citation
  | last1=Ebbinghaus
  | first1=Heinz-Dieter
  | authorlink1=Heinz-Dieter Ebbinghaus
  | last2=Flum
  | first2=Jörg
  | title=Finite Model Theory
  | publisher=[[Springer Publishing|Springer]]
  | isbn=978-3-540-60149-4
  | year=1995
 }}.
* {{citation | last1=Grädel | first1=Erich | last2=Kolaitis | first2=Phokion G. | last3=Libkin | first3=Leonid | author3-link=Leonid Libkin | last4=Maarten | first4=Marx | last5=Spencer | first5=Joel | author5-link=Joel Spencer | last6=Vardi | first6=Moshe Y. | author6-link=Moshe Y. Vardi | last7=Venema | first7=Yde | last8=Weinstein | first8=Scott | title=Finite model theory and its applications | zbl=1133.03001 | series=Texts in Theoretical Computer Science. An EATCS Series | location=Berlin | publisher=[[Springer-Verlag]] | isbn=978-3-540-00428-8 | year=2007 | page=133 }}.

==External links==
* [https://web.archive.org/web/20100704135152/http://www.math.upenn.edu/%7Enate/papers/thesis/thesis.pdf Quantifier Rank Spectrum of L-infinity-omega] BA Thesis, 2000


[[Category:Model theory]]
[[Category:Finite model theory]]
[[Category:Predicate logic]]
[[Category:Quantification]]</text>
      <sha1>i8hlajleer8tb28dido0v2bvuudittk</sha1>
    </revision>
  </page>
  <page>
    <title>Quasiregular map</title>
    <ns>0</ns>
    <id>34304924</id>
    <revision>
      <id>832549421</id>
      <parentid>790774195</parentid>
      <timestamp>2018-03-26T17:34:24Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* Rickman's theorem */[[User:JCW-CleanerBot#Logic|task]]:, replaced: Acta math → Acta Math using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6267">In the mathematical field of [[mathematical analysis|analysis]], '''quasiregular maps''' are a class of continuous maps between Euclidean spaces '''R'''&lt;sup&gt;''n''&lt;/sup&gt; of the same dimension or, more generally, between [[Riemannian manifold]]s of the same dimension, which share some of the basic properties with [[holomorphic function]]s of one complex variable.

==Motivation==

The theory of holomorphic (=[[analytic function|analytic]]) functions of one complex variable is one of the most beautiful and most useful parts of the whole mathematics.

One drawback of this theory is that it deals only with maps between two-dimensional spaces ([[Riemann surfaces]]). The theory of functions
of several complex variables has a different character, mainly because analytic functions of several variables are not [[conformal map|conformal]]. Conformal maps can be defined between Euclidean spaces of arbitrary dimension, but when the dimension is greater than 2, this class of maps is very small: it consists of [[Möbius transformations]] only.
This is a theorem of [[Joseph Liouville]]; relaxing the smoothness assumptions does not help, as proved by [[Yurii Reshetnyak]].&lt;ref name="resh"&gt;{{cite book|author=Yu. G. Reshetnyak|title=Stability theorems in geometry and analysis|publisher=[[Kluwer Academic Publishers|Kluwer]]|year=1994}}&lt;/ref&gt;

This suggests the search of a generalization of the property of conformality which would give a rich and interesting class of maps in higher dimension.

==Definition==

A [[differentiable map]] ''f'' of a region ''D'' in '''R'''&lt;sup&gt;''n''&lt;/sup&gt; to '''R'''&lt;sup&gt;''n''&lt;/sup&gt; is called ''K''-quasiregular if the following inequality holds at all points in ''D'':

:&lt;math&gt; \| Df(x)\|^n\leq K|J_f(x)| &lt;/math&gt;.

Here ''K''&amp;nbsp;≥&amp;nbsp;1 is a constant, ''J''&lt;sub&gt;''f''&lt;/sub&gt; is the [[Jacobian determinant]], ''Df'' is the derivative, that is the linear map defined by the [[Jacobian matrix and determinant|Jacobi matrix]], and ||·|| is the usual (Euclidean) [[matrix norm|norm]] of the matrix.

The development of the theory of such maps showed that it is unreasonable to restrict oneself to differentiable maps in the classical sense, and that the "correct" class of maps consists of continuous maps in the [[Sobolev space]] ''W''{{su|p=1,''n''|b=loc}} whose partial derivatives in the sense of [[distribution (mathematics)|distributions]] have locally summable ''n''-th power, and such that the above inequality is satisfied [[almost everywhere]]. This is a formal definition of a ''K''-quasiregular map. A map is called '''quasiregular''' if it is ''K''-quasiregular with some ''K''. Constant maps are excluded from the class of quasiregular maps.

==Properties==

The fundamental theorem about quasiregular maps was proved by Reshetnyak:&lt;ref name="resh2" /&gt;

:''Quasiregular maps are open and discrete''.

This means that the images of [[open set]]s are open and that preimages of points consist of isolated points. In dimension 2, these two properties give a topological characterization of the class of non-constant analytic functions:
every continuous open and discrete map of a plane domain to the plane can be pre-composed with a [[homeomorphism]], so that the result is an analytic function. This is a theorem of [[Simion Stoilov]].

Reshetnyak's theorem implies that all pure topological results about analytic functions (such that the Maximum Modulus Principle, Rouché's theorem etc.) extend to quasiregular maps.

Injective quasiregular maps are called [[quasiconformal]]. A simple example of non-injective quasiregular map is given in cylindrical coordinates in 3-space by the formula

:&lt;math&gt; (r,\theta,z)\mapsto (r,2\theta,z). &lt;/math&gt;

This map is 2-quasiregular. It is smooth everywhere except the ''z''-axis. A remarkable fact is that all smooth quasiregular maps are local homeomorphisms. Even more remarkable is that every quasiregular local homeomorphism '''R'''&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;→&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt;, where ''n''&amp;nbsp;≥&amp;nbsp;3, is a homeomorphism (this is a [[Zorich's theorem|theorem of Vladimir Zorich]]&lt;ref name="resh2"&gt;{{cite book|author=Yu. G. Reshetnyak|title=Space mappings with bounded distortion|
publisher=[[American Mathematical Society]]|year=1989}}&lt;/ref&gt;).

This explains why in the definition of quasiregular maps it is not reasonable to restrict oneself to smooth maps: all smooth quasiregular maps of '''R'''&lt;sup&gt;''n''&lt;/sup&gt; to itself are quasiconformal.

==Rickman's theorem==

Many theorems about geometric properties of holomorphic functions of one complex variable have been extended to quasiregular maps. These extensions are usually highly non-trivial.

Perhaps the most famous result of this sort is the extension of [[Picard's theorem]] which is due to Seppo Rickman:&lt;ref&gt;{{cite book|author=S. Rickman|title=Quasiregular mappings|publisher=[[Springer Verlag]]|year=1993}}&lt;/ref&gt;

:''A K-quasiregular map'' '''R'''&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;&amp;rarr;&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt; ''can omit at most a finite set''.

When ''n''&amp;nbsp;=&amp;nbsp;2, this omitted set can contain at most two points (this is a simple extension of Picard's theorem). But when ''n''&amp;nbsp;&gt;&amp;nbsp;2, the omitted set can contain more than two points, and its cardinality can be estimated from above in terms of ''n'' and&amp;nbsp;''K''. In fact, any finite set
can be omitted, as shown by David Drasin and Pekka Pankka.&lt;ref&gt;{{cite news|author1=D. Drasin|author2=Pekka Pankka|title=Sharpness of Rickman's Picard theorem in all dimensions|journal=Acta Math.|year=2015|volume=214|pages=209–306}}&lt;/ref&gt;

==Connection with potential theory==

If ''f'' is an analytic function, then log&amp;nbsp;''|f|'' is [[subharmonic function|subharmonic]], and [[harmonic function|harmonic]] away from the zeros of ''f''. The corresponding fact for quasiregular maps is that log&amp;nbsp;''|f|'' satisfies a certain non-linear [[partial differential equation]] of [[elliptic operator|elliptic type]].
This discovery of Reshetnyak stimulated the development of '''non-linear potential theory''', which treats this kind of equations
as the usual [[potential theory]] treats harmonic and subharmonic functions.

==See also==
* [[Yurii Reshetnyak]]
* [[Vladimir Zorich]]

==References==

&lt;references/&gt;

[[Category:Mathematical analysis]]</text>
      <sha1>pzxtd8sl8uiuspbw0uv04jys6ibeg8t</sha1>
    </revision>
  </page>
  <page>
    <title>Reification (computer science)</title>
    <ns>0</ns>
    <id>232423</id>
    <revision>
      <id>836338628</id>
      <parentid>813302995</parentid>
      <timestamp>2018-04-14T04:38:25Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 3 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17567">{{Other uses|Reification (disambiguation)}}

'''Reification''' is the process by which an abstract idea about a [[computer program]] is turned into an explicit [[data model]] or other object created in a [[programming language]]. A computable/addressable object — a resource — is created in a system as a proxy for a non computable/addressable object. By means of reification, something that was previously implicit, unexpressed, and possibly inexpressible is explicitly formulated and made available to conceptual (logical or computational) manipulation. Informally, reification is often referred to as "making something a [[first-class citizen]]" within the scope of a particular system. Some aspect of a system can be reified at ''language design time'', which is related to [[Reflection (computer science)|reflection]] in programming languages. It can be applied as a [[stepwise refinement]] at ''system design time''. Reification is one of the most frequently used techniques of [[conceptual analysis]] and [[knowledge representation]].

== Reflective programming languages ==
In the context of [[programming language]]s, reification is the process by which a user program or any aspect of a programming language that was implicit in the translated program and the run-time system, are  expressed in the language itself. This process makes it available to the program, which can inspect all these aspects as ordinary [[data]]. In [[Reflection (computer science)|reflective languages]], reification data is causally connected to the related reified aspect such that a modification to one of them affects the other. Therefore, the reification data is always a faithful representation of the related reified aspect {{clarification needed|date=April 2017}}. Reification data is often said to be made a [[first class object]]{{citation needed|date=April 2017}}. Reification, at least partially, has been experienced in many languages to date: in early [[Lisp (programming language)|Lisp dialects]] and in current [[Prolog| Prolog dialects]], programs have been treated as data, although the causal connection has often been left to the responsibility of the programmer. In [[Smalltalk]]-80, the compiler from the source text to bytecode has been part of the run-time system since the very first implementations of the language.&lt;ref&gt;J. Malenfant, M. Jacques and F.-N. Demers, [http://www2.parc.com/csl/groups/sda/projects/reflection96/docs/malenfant/ref96/ref96.html A Tutorial on Behavioral Reflection and its Implementation] {{webarchive|url=https://web.archive.org/web/20100528214857/http://www2.parc.com/csl/groups/sda/projects/reflection96/docs/malenfant/ref96/ref96.html |date=2010-05-28 }}&lt;/ref&gt;

* The [[C (programming language)|C programming language]] reifies the low-level detail of [[memory address]]es.{{paragraph break}}Many programming language designs encapsulate the details of memory allocation in the compiler and the run-time system. In the design of the C programming language, the memory address is reified and is available for direct manipulation by other language constructs. For example, the following code may be used when implementing a memory-mapped device driver. The buffer pointer is a proxy for the memory address 0xB800000.{{paragraph break}}&lt;source lang="c"&gt;
 char* buffer = (char*) 0xB800000;
 buffer[0] = 10; 
&lt;/source&gt;
* [[Functional programming languages]] based on [[lambda-calculus]] reify the concept of a procedure abstraction and procedure application in the form of the [[Lambda calculus#Lambda calculus and programming languages|Lambda expression]].
* The [[Scheme (programming language)|Scheme]] programming language reifies [[continuations]] (approximately, the call stack).
* In [[C Sharp (programming language)|C#]], reification is used to make [[parametric polymorphism]] implemented as generics as a first-class feature of the language.
* In the [[Java (programming language)|Java]] programming language, there exist "reifiable types" that are "completely available at run time" (i.e. their information is not erased during compilation).&lt;ref&gt;[http://docs.oracle.com/javase/specs/jls/se7/html/jls-4.html#jls-4.7 The Java Language Specification, section 4.7], Java SE 7 Edition&lt;/ref&gt;
* [[REBOL]] reifies code as data and vice versa.
* Many languages, such as [[Lisp (programming language)|Lisp]], [[JavaScript]], and [[Curl (programming language)|Curl]], provide an [[eval|&lt;code&gt;eval&lt;/code&gt; or &lt;code&gt;evaluate&lt;/code&gt; procedure]] that effectively reifies the language interpreter.
* The [[Logtalk]] framework for [[Prolog]] offers a means to explore reification in the context of [[logic programming]].
* [[Smalltalk]] and [[Actor model|Actor languages]] permit the reification of blocks and [[message passing|messages]],&lt;ref&gt;{{cite web|url=http://c2.com/cgi/wiki?SmalltalkBlocksAndClosures |title=Smalltalk Blocks And Closures |publisher=C2.com |date=2009-10-15 |accessdate=2010-10-09}}&lt;/ref&gt; which are equivalent of lambda expressions in Lisp, and [[thisContext]] which is a reification of the current executing block.
* [[Homoiconicity|Homoiconic languages]] reify the syntax of the language itself in the form of an [[abstract syntax tree]], typically together with &lt;code&gt;eval&lt;/code&gt;.

== Data reification vs. data refinement ==
Data reification ([[stepwise refinement]]) involves finding a more concrete representation of the [[abstract data type]]s used in a [[formal specification]].

Data reification is the terminology of the [[Vienna Development Method]] (VDM) that most other people would call data refinement. An example is taking a step towards an implementation by replacing a data representation without a counterpart in the intended implementation language, such as sets, by one that does have a counterpart (such as maps with fixed domains that can be implemented by arrays), or at least one that is closer to having a counterpart, such as sequences. The VDM community prefers the word "reification" over "refinement", as the process has more to do with concretising an idea than with refining it.&lt;ref&gt;[https://www.cs.tcd.ie/FME/original/FAQ/vdm/part13.html Formal Methods Europe, Frequently Asked Questions, part 13] {{webarchive|url=https://web.archive.org/web/20050312031255/http://www.cs.tcd.ie/FME/original/FAQ/vdm/part13.html |date=2005-03-12 }}.&lt;/ref&gt;

For similar usages, see [[Reification (linguistics)]].

== In conceptual modeling ==
Reification is widely used in [[Conceptual model (computer science)|conceptual modeling]].&lt;ref&gt;Antoni Olivé, Conceptual Modeling of Information Systems, Springer Verlag, 2007.&lt;/ref&gt; Reifying a relationship means viewing it as an entity. The purpose of reifying a relationship is to make it explicit, when additional information needs to be added to it. Consider the relationship type ''&lt;code&gt;IsMemberOf(member:Person, Committee)&lt;/code&gt;''. An instance of ''&lt;code&gt;IsMemberOf&lt;/code&gt;'' is a relationship that represents the fact that a person is a member of a committee. The figure below shows an example population of ''&lt;code&gt;IsMemberOf&lt;/code&gt;'' relationship in tabular form. Person ''P1'' is a member of committees ''C1'' and ''C2''. Person ''P2'' is a member of committee ''C1'' only. [[File:reification example1.png|500px|thumb|Example population of &lt;code&gt;IsMemberOf&lt;/code&gt; relationship in tabular form. Person P1 is a member of committees C1 and C2. Person P2 is a member of committee C1 only.]]

The same fact, however, could also be viewed as an entity. Viewing a relationship as an entity, one can say that the entity reifies the relationship. This is called reification of a relationship. Like any other entity, it must be an instance of an entity type. In the present example, the entity type has been named &lt;code&gt;Membership&lt;/code&gt;. For each instance of ''&lt;code&gt;IsMemberOf&lt;/code&gt;'', there is one and only one instance of ''&lt;code&gt;Membership&lt;/code&gt;'', and vice versa. Now, it becomes possible to add more information to the original relationship. As an example, we can express the fact that "person p1 was nominated to be the member of committee c1 by person p2". Reified relationship ''&lt;code&gt;Membership&lt;/code&gt;'' can be used as the source of a new relationship ''&lt;code&gt;IsNominatedBy(Membership, Person)&lt;/code&gt;''.

For related usages see [[Reification (knowledge representation)]].

== In Unified Modeling Language (UML) ==
[[File:reification example2.png|400px|thumb|The UML [[class diagram]] for the Membership example.]] [[Unified Modeling Language|UML]] provides an ''association class'' construct for defining reified relationship types. The association class is a single model element that is both a kind of association and a kind of a class.&lt;ref&gt;''Unified Modeling Language, UML superstructure'', Object Management Group, 2007-11-02.&lt;/ref&gt; The association and the entity type that reifies are both the same model element. Note that attributes cannot be reified.

== On Semantic Web ==

=== RDF and OWL ===
In [[Semantic Web]] languages, such as [[Resource Description Framework]] (RDF) and [[Web Ontology Language]] (OWL), a statement is a binary relation. It is used to link two individuals or an individual and a value. Applications sometimes need to describe other RDF statements, for instance, to record information like when statements were made, or who made them, which is sometimes called "[[provenance]]" information. As an example, we may want to represent properties of a relation, such as our certainty about it, severity or strength of a relation, relevance of a relation, and so on.

The example from the conceptual modeling section describes a particular person with &lt;code&gt;URIref person:p1&lt;/code&gt;, who is a member of the &lt;code&gt;committee:c1&lt;/code&gt;. The RDF triple from that description is
&lt;source lang="sparql"&gt;
  person:p1   committee:isMemberOf   committee:c1 .
&lt;/source&gt;
Consider to store two further facts: (i) to record who nominated this particular person to this committee (a statement about the membership itself), and (ii) to record who added the fact to the database (a statement about the statement).

The first case is a case of classical reification like above in UML: reify the membership and store its attributes and roles etc.:

&lt;source lang="sparql"&gt;
 committee:Membership        rdf:type              owl:Class .
 committee:membership12345   rdf:type              committee:Membership .
 committee:membership12345   committee:ofPerson    person:p1 .
 committee:membership12345   committee:inCommittee committee:c1 .
 person:p2                   committee:nominated   committee:membership12345 .  
&lt;/source&gt;

Additionally, RDF provides a built-in vocabulary intended for describing RDF statements. A description of a statement using this vocabulary is called a reification of the statement. The RDF reification vocabulary consists of the type &lt;code&gt;rdf:Statement&lt;/code&gt;, and the properties &lt;code&gt;rdf:subject&lt;/code&gt;, &lt;code&gt;rdf:predicate&lt;/code&gt;, and &lt;code&gt;rdf:object&lt;/code&gt;.&lt;ref name="rdf"&gt;{{cite web|url=http://www.w3.org/TR/2004/REC-rdf-primer-20040210/#reification |title=RDF Primer |publisher=W3.org |date= |accessdate=2010-10-09}}&lt;/ref&gt;

Using the reification vocabulary, a reification of the statement about the person's membership would be given by assigning the statement a URIref such as &lt;code&gt;committee:membership12345&lt;/code&gt; so that describing statements can be written as follows:
&lt;source lang="sparql"&gt;
 committee:membership12345Stat   rdf:type        rdf:Statement .
 committee:membership12345Stat   rdf:subject     person:p1 .
 committee:membership12345Stat   rdf:predicate   committee:isMemberOf . 
 committee:membership12345Stat   rdf:object      committee:c1 .
&lt;/source&gt;
These statements say that the resource identified by the &lt;code&gt;URIref committee:membership12345Stat&lt;/code&gt; is an RDF statement, that the subject of the statement refers to the resource identified by &lt;code&gt;person:p1&lt;/code&gt;, the predicate of the statement refers to the resource identified by &lt;code&gt;committee:isMemberOf&lt;/code&gt;, and the object of the statement refers to the resource &lt;code&gt;committee:c1&lt;/code&gt;. Assuming that the original statement is actually identified by &lt;code&gt;committee:membership12345&lt;/code&gt;, it should be clear by comparing the original statement with the reification that the reification actually does describe it. The conventional use of the RDF reification vocabulary always involves describing a statement using four statements in this pattern. Therefore, they are sometimes referred to as the "reification quad".&lt;ref name="rdf"/&gt;

Using reification according to this convention, we could record the fact that &lt;code&gt;person:p3&lt;/code&gt; added the statement to the
database by
&lt;source lang="sparql"&gt;
  person:p3    committee:addedToDatabase    committee:membership12345Stat .
&lt;/source&gt;
It is important to note that in the conventional use of reification, the subject of the reification triples is assumed to identify a particular instance  of a triple in a particular RDF document, rather than some arbitrary triple having the same subject, predicate, and object. This particular convention is used because reification is intended for expressing properties such as dates of composition and source information, as in the examples given already, and these properties need to be applied to specific instances of triples. 
Note that the described triple &lt;code&gt;(subject predicate object)&lt;/code&gt; itself is not implied by such a reification quad (and it is not necessary that it actually exists in the database). This allows also to use this mechanism to express which triples do ''not'' hold.

The power of the reification vocabulary in RDF is restricted by the lack of a built-in means for assigning URIrefs to statements, so in order to express "provenance" information of this kind in RDF, one has to use some mechanism (outside of RDF) to assign URIs to individual RDF statements, then make further statements about those individual statements, using their URIs to identify them.&lt;ref name="rdf"/&gt;

=== In Topic Maps ===
In an [[Topic Maps|XML Topic Map]] (XTM), only a topic can have a name or play a role in an association. One may use an association to make an assertion about a topic, but one cannot directly make assertions about that assertion. However, it is possible to create a topic that reifies a non-topic construct in a map, thus enabling the association to be named and treated as a topic itself.&lt;ref&gt;[http://www.techquila.com/practical_intro.html Practical Introduction into Topic Maps] {{webarchive|url=https://web.archive.org/web/20090203202441/http://techquila.com/practical_intro.html |date=2009-02-03 }}.&lt;/ref&gt;

=== n-ary relations ===
In Semantic Web languages, such as RDF and OWL, a property is a binary relation used to link two individuals or an individual and a value. However, in some cases, the natural and convenient way to represent certain concepts is to use relations to link an individual to more than just one individual or value. These relations are called [[n-ary relations]]. Examples are representing relations among multiple individuals, such as a committee, a person who is a committee member and another person who has nominated the first person to become the committee member, or a buyer, a seller, and an object that was bought when describing a purchase of a book.

A more general approach to reification is to create an explicit new class and n new properties to represent an n-ary relation, making an instance of the relation linking the n individuals an instance of this class. This approach can also be used to represent provenance information and other properties for an individual relation instance.&lt;ref&gt;{{cite web|url=http://www.w3.org/TR/swbp-n-aryRelations/ |title=W3C Defining N-ary relations on Semantic Web |publisher=W3.org |date= |accessdate=2010-10-09}}&lt;/ref&gt;
&lt;source lang="turtle"&gt;
 :p1
      a       :Person ;
      :has_membership _:membership_12345 .
 _:membership_12345
      a       :Membership ;
      :committee :c1;
      :nominated_by :p2 .
&lt;/source&gt;

=== Vs. quotation ===
It is also important to note that the reification described here is not the same as "quotation" found in other languages. Instead, the reification describes the relationship between a particular instance of a triple and the resources the triple refers to. The reification can be read intuitively as saying "this RDF triple talks about these things", rather than (as in quotation) "this RDF triple has this form." For instance, in the reification example used in this section, the triple:
&lt;source lang="sparql"&gt;
  committee:membership12345   rdf:subject   person:p1 .
&lt;/source&gt;
describing the &lt;code&gt;rdf:subject&lt;/code&gt; of the original statement says that the subject of the statement is the resource (the person) identified by the URIref &lt;code&gt;person:p1&lt;/code&gt;. It does not state that the subject of the statement is the URIref itself (i.e., a string beginning with certain characters), as quotation would.

==See also==
{{Wiktionary|reification}}
* [[Denotational semantics]]
* [[Formal semantics of programming languages]]
* [[Meta-circular evaluator]]
* [[Metamodeling]]
* [[Metaobject]]
* [[Metaprogramming]]
* [[Normalization by evaluation]]
* [[Operational semantics]]
* [[Reflection (computer science)]]
* [[Resource Description Framework]]
* [[Self-interpreter]]
* [[Topic Maps]]

==References==
{{reflist}}

&lt;!--Interwikies--&gt;

{{DEFAULTSORT:Reification (Computer Science)}}
&lt;!--Categories--&gt;
[[Category:Object-oriented programming]]
[[Category:Formal methods terminology]]
[[Category:Knowledge representation]]

[[de:Reifikation#Informatik]]
[[fr:Réification]]</text>
      <sha1>2px801fp4ojuocujgwxhb8k2n4ldexm</sha1>
    </revision>
  </page>
  <page>
    <title>Rotation map</title>
    <ns>0</ns>
    <id>28396062</id>
    <revision>
      <id>841541762</id>
      <parentid>831967013</parentid>
      <timestamp>2018-05-16T13:36:14Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2729">{{distinguish|Rotation (mathematics)}}
In [[mathematics]], a '''rotation map''' is a function that represents an undirected edge-[[labeled graph]], where each vertex enumerates its outgoing neighbors. Rotation maps were first introduced by Reingold, Vadhan and Wigderson (“Entropy waves, the zig-zag graph product, and new constant-degree expanders”, 2002) in order to conveniently define the [[zig-zag product]] and prove its properties.
Given a vertex &lt;math&gt;v&lt;/math&gt; and an edge label &lt;math&gt;i&lt;/math&gt;, the rotation map returns the &lt;math&gt;i&lt;/math&gt;'th neighbor of &lt;math&gt;v&lt;/math&gt; and the edge label that would lead back to &lt;math&gt;v&lt;/math&gt;.

==Definition==
For a ''D''-regular graph ''G'', the rotation map &lt;math&gt;\mathrm{Rot}_G : [N] \times [D] \rightarrow [N] \times [D]&lt;/math&gt; is defined as follows: &lt;math&gt;\mathrm{Rot}_G (v,i)=(w,j)&lt;/math&gt; if the ''i'' th edge leaving ''v'' leads to ''w'', and the ''j'' th edge leaving ''w'' leads to&amp;nbsp;''v''.

==Basic properties==
From the definition we see that &lt;math&gt;\mathrm{Rot}_G&lt;/math&gt; is a permutation, and moreover &lt;math&gt;\mathrm{Rot}_G \circ \mathrm{Rot}_G&lt;/math&gt; is the identity map (&lt;math&gt;\mathrm{Rot}_G&lt;/math&gt; is an [[involution (mathematics)|involution]]).

==Special cases and properties ==
* A rotation map is consistently labeled if all of the edges leaving each vertex are labeled in such a way that at each vertex, the labels of the incoming edges are all distinct. Every regular graph has some consistent labeling.
* A rotation map is &lt;math&gt;\pi&lt;/math&gt;-consistent if &lt;math&gt;\forall v \ \mathrm{Rot}_G(v,i)=(v[i],\pi (i))&lt;/math&gt;. From the definition, a &lt;math&gt;\pi&lt;/math&gt;-consistent rotation map is consistently labeled.

==See also==
*[[Zig-zag product]]
*[[Rotation system]]

==References==
{{Refbegin}}
* {{Citation
| first1=O. | last1=Reingold
| first2=S. | last2=Vadhan
| first3=A. | last3=Widgerson
| title=Entropy waves, the zig-zag graph product, and new constant-degree expanders and extractors
| journal=41st Annual Symposium on Foundations of Computer Science
| year=2000
| doi=10.1109/SFCS.2000.892006
| pages=3–13
| arxiv=math/0406038}}

* {{Citation
| first=O
| last=Reingold
| title=Undirected connectivity in log-space
| journal=[[Journal of the ACM]]
| year=2008
| volume=55
| issue=4
| pages=Article 17, 24 pages
| doi=10.1145/1391289.1391291
}}

* {{Citation
| first1=O. | last1=Reingold
| first2=L. | last2=Trevisan
| first3=S. | last3=Vadhan
| title=Pseudorandom walks on regular digraphs and the RL vs. L problem
| journal=Proceedings of the thirty-eighth annual ACM symposium on Theory of computing
| year=2006
| doi=10.1145/1132516.1132583
| pages=457
}}

{{Refend}}

[[Category:Extensions and generalizations of graphs]]
[[Category:Graph operations]]</text>
      <sha1>qjbpiila59he0sg4kxif5dhxaioicti</sha1>
    </revision>
  </page>
  <page>
    <title>Scale factor (computer science)</title>
    <ns>0</ns>
    <id>4252019</id>
    <revision>
      <id>840108231</id>
      <parentid>715798488</parentid>
      <timestamp>2018-05-07T19:39:49Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11813">{{refimprove|date=July 2007}}

A '''scale factor''' is used in [[computer science]] when a real world set of numbers needs to be represented on a different scale in order to fit a specific [[Computer numbering formats|number format]]. For instance, a 16 bit [[signedness|unsigned]] [[integer]] (''uint16'') can only hold a value as large as 65,535&lt;sub&gt;10&lt;/sub&gt;. If uint16's are to be used to represent values from 0 to 131,070&lt;sub&gt;10&lt;/sub&gt;, then a scale factor of 1/2 would be introduced. Notice that while the scale factor extends the range, it also decreases the [[Precision (computer science)|precision]]. In this example, for instance, the number 3 could not be represented because a stored ''1'' represents a real world 2, and a stored ''2'' represents a real world 4.

==Uses==
Certain number formats may be chosen for an application for convenience in programming, or because of certain advantages offered by the hardware for that number format. For instance, early processors did not natively support the [[IEEE]] [[Floating_point|floating point standard]] for representing fractional values, so integers were used to store representations of the real world values by applying a scale factor to the real value. By necessity, this was done in [[software]], since the hardware did not support fractional value.

==Operations on Scaled Values==
Once the scaled representation of a real value is stored, the scaling can '''''often''''' be ignored until the value needs to come back into the "real world". For instance, adding two scaled values is just as valid as unscaling the values, adding the real values, and then scaling the result, and the former is much easier and faster. For other operations, however, the scaling is very important.

Multiplication, for instance, needs to take account of the fact that both numbers are scaled. As an example, consider two real world values ''A'' and ''B''. The real world multiplication of these real world values is:
&lt;pre&gt;A * B = P
&lt;/pre&gt;
Now suppose we're storing the values with a scale factor of ''Z''. If we simply multiply the stored representations we'll get the following:
&lt;pre&gt;AZ * BZ = Q
&lt;/pre&gt;
Note how ''AZ'' is the scaled real world value of ''A'' or simply the product of ''A * Z'', and likewise, ''BZ'' is the scaled representation of ''B''. Also note that we didn't write ''PZ'' as the answer, the reason is simple: PZ is ''not'' the answer. You can see this by rearranging the statement, where each line in the following is equivalent:
&lt;pre&gt;AZ * BZ = Q
A * Z * B * Z = Q
(A * B) * Z * Z = Q
P * Z * Z = Q
PZ * Z = Q
&lt;/pre&gt;
Note how we substituted ''P'' for ''A * B'' on line 4. You can now see that the result of ''AZ * BZ'' (which is ''Q'') is NOT ''PZ'', it's ''PZ * Z''. If ''PZ'' '''''were''''' the answer, we could simply store it directly, since it has the scale factor built in, as is the case with addition and subtraction. For multiplication, however, you can see that the product of two scaled values has an extra scaling built in. As long as this is taken into account, there's still no need to convert ''AZ'' and ''BZ'' into ''A'' and ''B'' before performing the operation, you just need to divide the result by ''Z'' before storing it back. You will then have ''PZ'' stored as the result of the multiplication, which is fine because you weren't storing the result of ''AZ * BZ'', you were storing the scaled representation of the result of ''A * B''.

==Common Scaling Scenarios==
===Fractional Values Scaled to Integers===
As already mentioned, many older processors (and possibly some current ones) do not natively support fractional mathematics. In this case, fractional values can be scaled into integers by multiplying them by ten to the power of whatever decimal precision you want to retain. In other words, if you want to preserve ''n'' digits to the right of the decimal point, you need to multiply the entire number by 10&lt;sup&gt;''n''&lt;/sup&gt;. (Or if you're working in binary and you want to save ''m'' digits to the right of the [[binary point]], then you would multiply the number by 2&lt;sup&gt;''m''&lt;/sup&gt;, or alternately, [[bit shift]] the value ''m'' places to the left). For example, consider the following set of real world fractional values:
&lt;pre&gt;15.400, 0.133, 4.650, 1.000, 8.001
&lt;/pre&gt;
Notice how they all have ''3'' digits to the right of the decimal place. If we want to save all of that information (in other words, not lose any [[Precision (computer science)|precision]]), we need to multiply these numbers by 10&lt;sup&gt;''3''&lt;/sup&gt;, or 1,000, giving us integer values of:
&lt;pre&gt;15400, 133, 4650, 1000, 8001
&lt;/pre&gt;
(also note that these numbers cannot be stored in 8bit integers, it will require at least 14 bits, or, more realistically, 16.)

===Integer values to Fractional===
Certain processors, particularly [[Digital signal processor|DSPs]] common in the [[embedded system]] industry, have built in support for the [[fixed-point arithmetic|fixed point]] arithmetic, such as [[Q (number format)|Q]] and [[IQ (number format)|IQ]] formats.

Since the fractional part of a number takes up some bits in the field, the range of values possible in a fixed point value is less than the same number of bits would provide to an integer. For instance, in an 8 bit field, an unsigned integer can store values from &lt;nowiki&gt;[0, 255]&lt;/nowiki&gt; but an unsigned fixed point with 5 fractional bits only has 3 bits left over for the integer value, and so can only store integer values from &lt;nowiki&gt;[0, 7]&lt;/nowiki&gt; (note that the ''number'' of values that the two fields can store is the same, 2&lt;sup&gt;8&lt;/sup&gt; = 256, because the fixed point field can also store 32 fractional values for each integer value). It is therefore common that a scaling factor is used to store real world values that may be larger than the maximum value of the fixed point format.

As an example, assume we are using an unsigned 8 bit fixed point format with 4 fractional bits, and 4 integer bits. As mentioned, the highest integer value it can store is 15, and the highest mixed value it can store is 15.9375 (0xF.F or 1111.1111&lt;sub&gt;b&lt;/sub&gt;). If the real world values we want to manipulate are in the range [0,160], we need to scale these values in order to get them into fixed point. Note that we ''can not'' use a scale factor of 1/10 here because scaling 160 by 1/10 gives us 16, which is greater than the greatest value we can store in our fixed point format. 1/11 will work as a scale factor, however, because 160/11 = 14.5454... which fits in our range. Let's use this scale factor to convert the following real world values into scaled representations:
&lt;pre&gt;154, 101, 54, 3, 0, 160
&lt;/pre&gt;
Scaling these with the scale factor (1/11) gives us the following values:
&lt;pre&gt;154/11 = 14
101/11 = 9.1818...
54/11 = 4.9090...
3/11 = 0.2727...
0/11 = 0
160/11 = 14.5454...
&lt;/pre&gt;
Note however, that many of these values have been truncated because they contain repeating fractions. When we try to store these in our fixed point format, we're going to lose some of our precision (which didn't seem all that precise when they were just integers). This is an interesting problem because we said we could fit 256 different values into our 8 bit format, and we're only trying to store values from a range with 161 possible values (0 through 160). As it turns out, the problem was our scale factor, 11, which introduced unnecessary precision requirements. The resolution of the problem is to find a better scaling factor. For more information, [[#Picking a Scale Factor|read on]].

==Picking a Scale Factor==
An example above illustrated how certain scale factors can cause unnecessary precision loss. We will revisit this example to further explore the situation.

We're storing representations of real data in 8 bit unsigned fixed point fields with 4 integer bits and 4 fractional bits. This gives us a range of &lt;nowiki&gt;[0, 15.9375]&lt;/nowiki&gt; in decimal, or &lt;nowiki&gt;[0x0.0, 0xF.F]&lt;/nowiki&gt; in [[hexadecimal|hex]]. Our real world data is all integers and in the range [0, 160] in decimal. Note that there are only 161 unique values that we may want to store, so our 8 bit field should be plenty, since 8 bits can have 256 unique configurations.

In the example given [[#Integer values to Fractional|above]], we picked a scale factor of 11 so that all the numbers would be small enough to fit in the range. However, when we began scaling the following real world data:
&lt;pre&gt;154, 101, 54, 3, 0, 160
&lt;/pre&gt;
We discovered that the precision of these fractions is going to be a problem. The following box illustrates this showing the original data, its scaled decimal values, and the binary equivalent of the scaled value.
&lt;pre&gt;154/11 = 14 = 1110.0
101/11 = 9.1818... = 1001.00101110...
54/11 = 4.9090... = 100.111010...
3/11 = 0.2727... = 0.010010...
0/11 = 0 = 0.0
160/11 = 14.5454... = 1110.10010...
&lt;/pre&gt;
Notice how several of the binary fractions require more than the 4 fractional bits provided by our fixed point format. To fit them into our fields, we would simply truncate the remaining bits, giving us the following stored representations:
&lt;pre&gt;1110.0000
1001.0010
0100.1110
0000.0100
0000.0000
1110.1001
&lt;/pre&gt;
Or in decimal:
&lt;pre&gt;14.0
9.125
4.875
0.25
0.0
14.5625
&lt;/pre&gt;
And when we need to bring them back into the real world, we need to divide by our scale factor, 1/11, giving the following "real world" values:
&lt;pre&gt;154.0
100.375
53.625
2.75
0
160.1875
&lt;/pre&gt;
Notice how they've changed? For one thing, they aren't all integers anymore, immediately indicating that an error was introduced in the storage, due to a poor choice of scaling factor.

===Picking a better Scale Factor===
Most [[data set]]s will not have a perfect scale factor; you will probably always get some error introduced by the scaling process. However it certainly may be possible to pick a better scaling factor. For one thing, note that dividing a number by a power of two is the same as shifting all the bits to the right once for each power of two. (It's the same thing in decimal, when you divide by 10, you shift all the decimal digits one place to the right, when you divide by 100, you shift them all two places to the right). The pattern of bits doesn't change, it just moves. On the other hand, when you divide by a number that is NOT an integer power of 2, you are changing the bit pattern. This is likely to produce a bit pattern with even more bits to the right of the binary point, artificially introducing required precision. Therefore, it is almost always preferable to use a scale factor that is a power of two. You may still lose bits that get shifted right off the end of the field, but at least you won't be introducing ''new'' bits that will be shifted off the end.

To illustrate the use of powers of two in the scale factor, let's use a factor of 1/16 with the above data set. The binary value for our original data set is given below:
&lt;pre&gt;154 = 1001 1010
101 = 0110 0101
54 =  0011 0110
3 =   0000 0011
0 =   0000 0000
160 = 1010 0000
&lt;/pre&gt;
As we already knew, they all fit in 8 bits. Scaling these by 1/16 is the same as dividing by 16, which is the same as shifting the bits 4 places to the right. All that really means is inserting a binary point between the first four and last four bits of each number. Conveniently, that's the exact format of our fixed point fields. So just as we suspected, since all these numbers don't require more than 8 bits to represent them as integers, it doesn't have to take more than 8 bits to scale them down and fit them in a fixed point format.

==References==
 1. [https://web.archive.org/web/20150912013429/http://www.digitalsignallabs.com/fp.pdf Fixed-Point Arithmetic: An Introduction, Randy Yates, July 7, 2009 -- www.digitalsignallabs.com] 

{{DEFAULTSORT:Scale Factor (Computer Science)}}
[[Category:Theory of computation]]</text>
      <sha1>jy47s9nikig5wv5imoazyanh2rztmn8</sha1>
    </revision>
  </page>
  <page>
    <title>Self-financing portfolio</title>
    <ns>0</ns>
    <id>25283233</id>
    <revision>
      <id>859798133</id>
      <parentid>859797601</parentid>
      <timestamp>2018-09-16T10:07:14Z</timestamp>
      <contributor>
        <username>Loraof</username>
        <id>22399950</id>
      </contributor>
      <comment>ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2331">In [[financial mathematics]], a '''self-financing portfolio''' is a [[portfolio (finance)|portfolio]] having the feature that, if there is no exogenous infusion or withdrawal of money, the purchase of a new asset must be financed by the sale of an old one.

== Mathematical definition ==
Let &lt;math&gt; h_i(t) &lt;/math&gt; denote the number of shares of stock number 'i' in the portfolio at time &lt;math&gt; t &lt;/math&gt;, and &lt;math&gt; S_i(t) &lt;/math&gt; the price of stock number 'i' in a [[frictionless market]] with trading in continuous time. Let

:&lt;math&gt; 
V(t) = \sum_{i=1}^{n} h_i(t) S_i(t).
&lt;/math&gt;

Then the portfolio &lt;math&gt; (h_1(t), \dots, h_n(t)) &lt;/math&gt; is self-financing if

:&lt;math&gt;
dV(t) = \sum_{i=1}^{n} h_i(t) dS_{i}(t).
&lt;/math&gt;&lt;ref&gt;{{cite book|first=Tomas|last=Björk|title=Arbitrage theory in continuous time|edition=3rd|page=87|publisher=Oxford University Press|year=2009|isbn=978-0-19-877518-8}}&lt;/ref&gt;

=== Discrete time ===
Assume we are given a discrete [[filtered probability space]] &lt;math&gt;(\Omega,\mathcal{F},\{\mathcal{F}_t\}_{t=0}^T,P)&lt;/math&gt;, and let &lt;math&gt;K_t&lt;/math&gt; be the [[solvency cone]] (with or without [[transaction costs]]) at time ''t'' for the market.  Denote by &lt;math&gt;L_d^p(K_t) = \{X \in L_d^p(\mathcal{F}_T): X \in K_t \; P-a.s.\}&lt;/math&gt;.  Then a portfolio &lt;math&gt;(H_t)_{t=0}^T&lt;/math&gt; (in physical units, i.e. the number of each stock) is self-financing (with trading on a finite set of times only) if 
: for all &lt;math&gt;t \in \{0,1,\dots,T\}&lt;/math&gt; we have that &lt;math&gt;H_t - H_{t-1} \in -K_t \; P-a.s.&lt;/math&gt; with the convention that &lt;math&gt;H_{-1} = 0&lt;/math&gt;.&lt;ref&gt;{{cite journal|last=Hamel|first=Andreas|last2=Heyde|first2=Frank|last3=Rudloff|first3=Birgit|date=November 30, 2010|title=Set-valued risk measures for conical market models|url=https://arxiv.org/PS_cache/arxiv/pdf/1011/1011.5986v1.pdf|accessdate=February 2, 2011|format=pdf}}&lt;/ref&gt;

If we are only concerned with the set that the portfolio can be at some future time then we can say that &lt;math&gt;H_{\tau} \in -K_0 - \sum_{k=1}^{\tau} L_d^p(K_k)&lt;/math&gt;.

If there are transaction costs then only discrete trading should be considered, and in continuous time then the above calculations should be taken to the limit such that &lt;math&gt;\Delta t \to 0&lt;/math&gt;.

==See also==
* [[Replicating portfolio]]

==References==
{{Reflist}}

[[Category:Mathematical finance]]</text>
      <sha1>bndwuvn8kbipv71mvular28hwd1wk2s</sha1>
    </revision>
  </page>
  <page>
    <title>Straightedge</title>
    <ns>0</ns>
    <id>147854</id>
    <revision>
      <id>866621233</id>
      <parentid>866602805</parentid>
      <timestamp>2018-10-31T13:42:32Z</timestamp>
      <contributor>
        <username>Pbsouthwood</username>
        <id>10044298</id>
      </contributor>
      <comment>/* See also */ convert to annotated links</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2625">{{short description|A tool for drawing straight lines or assessing the staightness or flatness of a surface}}
{{For|the subculture|Straight edge}}
{{No footnotes|date=May 2010}}
[[File:Architectural scale.jpg|thumb|right|A triangular [[architect's scale]]]]
A '''straightedge''' or '''straight edge''' is a tool used for drawing straight lines, or checking their straightness. If it has equally spaced markings along its length, it is usually called a [[ruler]].

Straightedges are used in the automotive service and machining industry to check the flatness of machined mating surfaces.

True straightness can in some cases be checked by using a [[laser line level]] as an optical straightedge: it can illuminate an accurately straight line on a flat surface such as the edge of a plank or shelf.

A pair of straightedges called [[winding stick]]s are used in woodworking to amplify twist (wind) in pieces of wood.

== Compass-and-straightedge construction ==
{{Main|Compass and straightedge}}
An idealized straightedge is used in [[compass-and-straightedge construction]]s in [[Euclidean geometry|plane geometry]]. 
It may be used:
*Given two points, to draw the line connecting them.
*Given a point and a circle, to draw either tangent.
*Given two circles, to draw any of their common tangents.
It may not be marked or used together with the [[Compass (drafting)|compass]] so as to transfer the length of one segment to another.

It is possible to [[Mohr-Mascheroni theorem|do all compass and straightedge constructions without the straightedge]]. That is, it is possible, using only a compass, to find the intersection of two lines given two points on each, and to find the tangent points to circles. It is not, however, possible to do all constructions using only a straightedge. It ''is'' possible to [[Poncelet–Steiner theorem|do them with straightedge alone given one circle and its center]].

==See also==
*{{annotated link|Chalk line}}
*{{annotated link|Geometrography}}

== References ==
&lt;references /&gt;
* [[Wayne Moore (swimmer)|Wayne R. Moore]], ''Foundations of Mechanical Accuracy'', Moore Special Tool Company, Bridgeport, CT (1970)

== External links ==
{{Commonscat|Straightedges}}
* [https://web.archive.org/web/20151002160522/http://home.comcast.net/~jaswensen/machines/straight_edge/straight_edge.html Making Accurate Straight-Edges from Scratch] 
{{Metalworking navbox|toolopen}}
{{Measuring and alignment tools}}
[[Category:Mathematical tools]]
[[Category:Metalworking measuring instruments]]
[[Category:Stonemasonry tools]]
[[Category:Technical drawing]]
[[Category:Woodworking measuring instruments]]</text>
      <sha1>qxwt2leq23mq1s0xn7ei5ub8sdk6v9d</sha1>
    </revision>
  </page>
  <page>
    <title>Strategic Network Formation</title>
    <ns>0</ns>
    <id>39469026</id>
    <revision>
      <id>869918082</id>
      <parentid>841545973</parentid>
      <timestamp>2018-11-21T06:02:17Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: url. Add: issue, isbn. Removed accessdate with no specified URL. Removed parameters. Formatted [[WP:ENDASH|dashes]]. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12109">{{Orphan|date=June 2013}}

'''Strategic Network Formation''' defines how and why networks take particular forms. In many networks, the relation between nodes is determined by the choice of the participating players involved, not by an arbitrary rule. A “strategic” modeling of network requires defining a network’s costs and benefits and predicts how individual preferences become outcomes.

== Introduction ==

[[File:15th Century Florentine Marriges Data from Padgett and Ansell.pdf|300px|thumbnail|right|15th Century Florentine Marriages Data from Padgett and Ansell]]
A strategic network formation requires that individuals create relations that are beneficial and drop those that are not. One of the most well-known examples in this context is the marriage network of sixteen families in Florence, which showed how the Medici family gained power and took control of Florence by creating a high number of inter-marriages with the other families.&lt;ref&gt;{{cite book|last=J.F|first=Padgett|title=Marriage and Elite Structure in Renaissance Florence|year=1994}}&lt;/ref&gt; “Thus, decisions about profitable relations are not a situation of choice, but a situation of strategic interaction – an aspect that is best covered by [[Game Theory]]”.&lt;ref name=buchel&gt;{{cite book|last=Buchel|first=Berno|title=Advances in Strategic Network Formation: Preferences, Centrality, and Externalities|year=2009|publisher=Bielefeld|url=https://books.google.com/?id=_GTfQgAACAAJ|isbn=9783838112176}}&lt;/ref&gt;{{rp|2}} In these kinds of settings, the nodes are usually called players, where &lt;math&gt;N = &lt;/math&gt;{1, 2,… &lt;math&gt;n&lt;/math&gt;} is a set of players that have formed links in a network. [[Social Network]]s have diverse settings, however the simplest ones can be described by an undirected graph whereas more complicated situations are represented by directed graphs.&lt;ref name=jackson&gt;{{cite book|last=O Jackson|first=Matthew|title=A survey of models of network formation: Stability and Efficiency|year=2003|publisher=[[Princeton University Press]]|url=http://www.stanford.edu/~jacksonm/netsurv.pdf}}&lt;/ref&gt;  There are fundamental differences in the way these games are modeled depending on their graph structure. If a link exists between player &lt;math&gt;i&lt;/math&gt; and player &lt;math&gt;j&lt;/math&gt; it is noted as &lt;math&gt;ij&lt;/math&gt;. In cases of undirected networks, &lt;math&gt;ij&lt;/math&gt; is considered  equal to &lt;math&gt;ji&lt;/math&gt;. A network &lt;math&gt;g&lt;/math&gt; represents a list of all the links between players. In a more formal setting, a network &lt;math&gt;g&lt;/math&gt; is defined as a set of unordered pairs {&lt;math&gt;i, j&lt;/math&gt;}, with &lt;math&gt;i,j&lt;/math&gt; element of &lt;math&gt;\mathbb{N}&lt;/math&gt;.&lt;ref name=buchel/&gt;{{rp|7}}The set of all possible graphs on the set of players &lt;math&gt;N&lt;/math&gt; is denoted with &lt;math&gt;G&lt;/math&gt;. The benefits that they receive from the network are represented by utility functions. That is, the payoff to a player i is represented by a function &lt;math&gt;u_i&lt;/math&gt; : &lt;math&gt;G(N)&lt;/math&gt; &lt;math&gt;\rightarrow&lt;/math&gt; &lt;math&gt;\mathbb{R}&lt;/math&gt;, where &lt;math&gt;u_i&lt;/math&gt; (&lt;math&gt;g&lt;/math&gt;) represents the net benefit that i receives if network &lt;math&gt;g&lt;/math&gt; is in place.&lt;ref name=jackson/&gt;{{rp|203}}   To model strategic network formation the notion of network games is used. A network game is a set of linked players and their utility functions.

== Modeling Network Formation ==

Network games can be modeled in different ways. Some of the modeling methods that separate the utility allocation from the network formation process are extensive form games, simultaneous move games, Pariwise stability concept etc.

=== Extensive form game modeling ===

If a network is modeled according to the extensive form game concept then the players of the network first propose to create links one after the other and afterwards they make decisions to create a link or not. In such settings, a couple of players decide to either form a link or not by being aware of all the previous players’ decisions and by making predictions for the decisions of the following players.

=== Simultaneous move game modeling ===

In simultaneous move game settings, all the players declare at the same time to whom they want to link. Even though these sorts of games are easy to understand and analyze, their drawback is that they have multiple [[Nash Equilibrium|Nash Equilibria]].

=== Pairwise Stability ===

In social networks, a link between two players is formed only if both of them decide to do so, however either of them can make the decision to delete a link without the other player’s approval. The concept of Nash equilibrium has a drawback in this case since it does not take into consideration the fact that the players can discuss their decisions. To model such a situation a stability concept that takes this fact into account is required. A useful stability concept in this case is Pairwise Stability, which accounts for the mutual approval of both players. A network is considered pairwise stable if:

(i) for all &lt;math&gt;ij&lt;/math&gt; ∈ &lt;math&gt;g&lt;/math&gt;, &lt;math&gt;u_i&lt;/math&gt;(&lt;math&gt;g&lt;/math&gt;) &lt;math&gt;\ge&lt;/math&gt; &lt;math&gt;u_i&lt;/math&gt;(&lt;math&gt;g&lt;/math&gt;-&lt;math&gt;ij&lt;/math&gt;) and &lt;math&gt;u_j&lt;/math&gt;(&lt;math&gt;g&lt;/math&gt;) &lt;math&gt;\ge&lt;/math&gt; &lt;math&gt;u_j&lt;/math&gt; (&lt;math&gt;g&lt;/math&gt;-&lt;math&gt;ij&lt;/math&gt;), and

(ii) for all &lt;math&gt;ij&lt;/math&gt; ∉ &lt;math&gt;g&lt;/math&gt;, if &lt;math&gt;u_i&lt;/math&gt;(&lt;math&gt;g+ij&lt;/math&gt;) &gt; &lt;math&gt;u_i&lt;/math&gt;(&lt;math&gt;g&lt;/math&gt;) then &lt;math&gt;u_j&lt;/math&gt;(&lt;math&gt;g+ij&lt;/math&gt;) &lt; &lt;math&gt;u_j&lt;/math&gt;(&lt;math&gt;g&lt;/math&gt;)&lt;ref name=jackson/&gt;{{rp|205}}

Therefore, a network in which there are no two players that want to create a link and where neither one of them wants to delete a link is pairwise stable. Some of the drawbacks that make the pariwise stability concept weak, are the fact that is does not consider changes of multiple links at a time, but it only looks at changes that happen between single links. The fact that it considers movements for only a couple of players at a given time can be considered as an additional weakness.

== Network Efficiency ==

[[File:An Example of Effcient, Pareto Effcient, and Pairwise Stable Networks in a Four Person Society.pdf|450px|thumbnail|right|An Example of Efficient, Pareto Efficient, and Pairwise Stable Networks in a Four Person Society]]
There is a difference between networks that maximize the social welfare and networks that are based on personal incentives. In strategic network formation it is important to look at the overall social benefit and to see if networks that players create manage to be efficient for the society in general. A network &lt;math&gt;g&lt;/math&gt; is efficient relative to a profile of utility functions (&lt;math&gt;u_1&lt;/math&gt;,..., &lt;math&gt;u_n&lt;/math&gt;) if &lt;math&gt;\textstyle \sum_{i}u_i (g)\ge \textstyle \sum_{i} u_i (g')&lt;/math&gt; for all &lt;math&gt;g' \in G(N)&lt;/math&gt;.&lt;ref name=jackson/&gt;{{rp|32}}

[[Pareto Efficiency]] is another efficiency concept used by economists to study the overall social welfare. 
A network &lt;math&gt;g&lt;/math&gt; is Pareto efficient relative to (&lt;math&gt;u_1&lt;/math&gt;,... &lt;math&gt;u_n&lt;/math&gt;) if there does not exist any &lt;math&gt;g' \in G&lt;/math&gt; such that &lt;math&gt;u_i&lt;/math&gt;(&lt;math&gt;g'&lt;/math&gt;) &lt;math&gt;\ge&lt;/math&gt; &lt;math&gt;u_i&lt;/math&gt;(&lt;math&gt;g&lt;/math&gt;) for all &lt;math&gt;i&lt;/math&gt; with strict inequality for some &lt;math&gt;i&lt;/math&gt;.&lt;ref name=jackson/&gt;{{rp|206}} The Pareto efficiency notion is more reasonable in settings in which allocation rules are fixed.&lt;ref name=jackson/&gt;{{rp|32}} A network can Pareto dominate another network if it has strictly larger benefits for one individual and weakly larger benefits for all individuals. If there exists a network which is not Pareto dominated by another network then it is a Pareto efficient network. In the figure "An Example of Effcient, Pareto Effcient, and Pairwise Stable Networks in a Four Person Society" an example with four players is given, where the payoffs of the players are noted by the numbers next to the nodes. If an arrow is pointing away from a network, it means that the network is not stable, since there would be benefit from deleting a link from a player or by creating a new link from two players of the network. The network in red is Efficient and Pareto efficient, since all the other link combinations offer lower payoffs to some of the players. The network in green is Pareto efficient since the payoffs are higher but it is not Pairwise Stable because the players that have created only one link would also benefit by adding links to one another. The only Pairwise Stable network in the figure is the dark blue colored one since none of the players involved would benefit by deleting or creating a link.

Jackson and Wolinsky showed that for homogeneous connection cost, the efficient network can only take one of three forms: a complete graph, a star or an empty graph depending on connection cost and benefits. Finding general analytical solutions for the efficient networks with heterogeneous costs can be intractable. However, for particular cost structures, such as Island-connection&lt;ref&gt;{{cite journal   | first = Matthew
  | last = Jackson
  | authorlink = 
  |author2=Brian W. Rogers
  | title = THE ECONOMICS OF SMALL WORLDS
  | journal = Journal of the European Economic Association
  | pages = 617–627
  | year = 2005
  |volume= 3
  | issue = 2–3
  | doi=10.1162/jeea.2005.3.2-3.617}}
&lt;/ref&gt; and Separable Heterogeneous connection costs,&lt;ref name=":0" /&gt; the efficient network can identified based on the heterogeneous connection costs and benefits. For the latter the efficient network has "generalized star" structure.&lt;ref name=":0"&gt;{{cite journal
  | first = Babak
  | last = Heydari
  | authorlink = 
  |author2=Mosleh, Mohsen
  |author3=Dalili, Kia
  | title = Efficient network structures with separable heterogeneous connection costs
  | journal = Economic Letters
  | pages = 82–85
  | year = 2015
  | url = http://www.sciencedirect.com/science/article/pii/S0165176515002645
  | accessdate =
  | doi=10.1016/j.econlet.2015.06.014
  | volume=134| arxiv=1504.06634}}
&lt;/ref&gt;

== Distance-Based Utility ==

The utility the players receive does not just come from the direct links that they form with each other, but also from their indirect relations. The benefit function &lt;math&gt;b&lt;/math&gt;: {1,… &lt;math&gt;n-1&lt;/math&gt;} &lt;math&gt;\rightarrow&lt;/math&gt; &lt;math&gt;\mathbb{R}&lt;/math&gt; measures the indirect benefit that players obtain from being close to other players in the network. When we consider distance, the utility function takes the form

&lt;math&gt;u_i (g)= \sum_{j\ne i:j \in N^{n-1}(g)} b(l_{ij} (g))-d_i(g)c&lt;/math&gt;, where &lt;math&gt;l_{ij}(g)&lt;/math&gt; represents the shortest path length between player &lt;math&gt;i&lt;/math&gt; and player &lt;math&gt;j&lt;/math&gt;.&lt;ref name=jackson/&gt;{{rp|209}}

The distance-based utility assumes that all players’ utility functions are alike and it takes into account only the benefits from indirect links that depend on minimum path length. These two features are considered as drawbacks of the distance-based utility.

== Externalities ==

Externalities show that players’ benefits depend heavily on other players’ commitment decisions. The distance-based utility showed that the payoffs of players do not just depend on the direct links that they form, but also on the links that other players have created in the network. Players may confront positive or negative externalities in networks. The distance-based utility model is an example of positive externalities, since players can only get more benefits when other players increase their number of connections. On the other hand, a model that faces players with negative externalities is the so-called “Co-Author model” presented by Jackson and Wolinsky in the paper of 1996. Given that working on a research paper requires time and devotion, two researchers can benefit more if are only working with each other at a given period of time and not with many other people. Therefore, in the “Co-Author model” researchers benefit more if their other colleagues have fewer links. In this model, if a player’s neighbors have many links, it will bring negative externalities to them. In different models, positive or negative externalities lead to inefficiency.

== References ==

{{reflist}}

[[Category:Network theory]]</text>
      <sha1>s5rgymkwnmg75f5eljl6ltr0yet13h5</sha1>
    </revision>
  </page>
  <page>
    <title>Størmer number</title>
    <ns>0</ns>
    <id>15991830</id>
    <revision>
      <id>857634040</id>
      <parentid>857634023</parentid>
      <timestamp>2018-09-02T00:51:15Z</timestamp>
      <contributor>
        <ip>74.104.136.171</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3242">In mathematics, a '''Størmer number''' or '''arc-cotangent irreducible number''', named after [[Carl Størmer]], is a positive integer ''n'' for which the greatest prime factor of ''n''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;1 is greater than or equal to 2''n''.

==Sequence==
The first few Størmer numbers are:
: [[1 (number)|1]], [[2 (number)|2]], [[4 (number)|4]], [[5 (number)|5]], [[6 (number)|6]], [[9 (number)|9]], [[10 (number)|10]], [[11 (number)|11]], [[12 (number)|12]], [[14 (number)|14]], [[15 (number)|15]], [[16 (number)|16]], [[19 (number)|19]], [[20 (number)|20]], ... {{OEIS|id=A005528}}. 

==Density==
[[John Todd (computer scientist)|John Todd]] proved that this sequence is neither [[finite set|finite]] nor [[cofinite]].{{r|t}}

{{unsolved|mathematics|What is the natural density of the Størmer numbers?}}
More precisely, the [[natural density]] of the Størmer numbers lies between 0.5324 and 0.905.
It has been conjectured that their natural density is the [[natural logarithm of 2]], approximately 0.693, but this remains unproven.{{r|eh}}
Because the Stormer numbers have positive density, the Stormer numbers form a [[Large set (combinatorics)|large set]].
==Restrictions==
A number of the form 2x&lt;sup&gt;2&lt;/sup&gt; for x&gt;1 cannot be a Stormer number. This is because (2x&lt;sup&gt;2&lt;/sup&gt;)&lt;sup&gt;2&lt;/sup&gt;+1 = 4x&lt;sup&gt;4&lt;/sup&gt;+1 = (2x&lt;sup&gt;2&lt;/sup&gt;-2x+1)(2x&lt;sup&gt;2&lt;/sup&gt;+2x+1).

==Application==
The Størmer numbers arise in connection with the problem of representing the [[Gregory number]]s ([[arctangent]]s of [[rational number]]s) &lt;math&gt;G_{a/b}=\arctan\frac{b}{a}&lt;/math&gt;  as sums of Gregory numbers for integers (arctangents of [[unit fraction]]s). The Gregory number &lt;math&gt;G_{a/b}&lt;/math&gt; may be decomposed by repeatedly multiplying the [[Gaussian integer]] &lt;math&gt;a+bi&lt;/math&gt; by numbers of the form &lt;math&gt;n\pm i&lt;/math&gt;, in order to cancel prime factors ''p'' from the imaginary part; here &lt;math&gt;n&lt;/math&gt; is chosen to be a Størmer number such that &lt;math&gt;n^2+1&lt;/math&gt; is divisible by &lt;math&gt;p&lt;/math&gt;.{{r|cg}}

==References==
{{reflist|refs=

&lt;ref name=cg&gt;{{citation
 | last1 = Conway | first1 = John H. | author1-link = John Horton Conway
 | last2 = Guy | first2 = R. K. | author2-link = Richard K. Guy
 | location = New York
 | pages = 245–248
 | publisher = Copernicus Press
 | title = The Book of Numbers
 | year = 1996}}. See in particular p. 245, para. 3.&lt;/ref&gt;

&lt;ref name=eh&gt;{{citation
 | last1 = Everest | first1 = Graham
 | last2 = Harman | first2 = Glyn
 | arxiv = math/0701234
 | contribution = On primitive divisors of &lt;math&gt;n^2+b&lt;/math&gt;
 | doi = 10.1017/CBO9780511721274.011
 | mr = 2428520
 | pages = 142–154
 | publisher = Cambridge Univ. Press, Cambridge
 | series = London Math. Soc. Lecture Note Ser.
 | title = Number theory and polynomials
 | volume = 352
 | year = 2008}}. See in particular Theorem 1.4 and Conjecture 1.5.&lt;/ref&gt;

&lt;ref name=t&gt;{{citation
 | last = Todd | first = John | authorlink = John Todd (computer scientist)
 | doi = 10.2307/2305526
 | journal = [[American Mathematical Monthly]]
 | mr = 0031496
 | pages = 517–528
 | title = A problem on arc tangent relations
 | volume = 56
 | year = 1949}}.&lt;/ref&gt;

}}

{{Classes of natural numbers}}

{{DEFAULTSORT:Stormer Number}}
[[Category:Integer sequences]]</text>
      <sha1>er2xc5fz4bkta0yt6rt0hwqutdofqkx</sha1>
    </revision>
  </page>
  <page>
    <title>Superabundant number</title>
    <ns>0</ns>
    <id>1759187</id>
    <revision>
      <id>867691348</id>
      <parentid>835947266</parentid>
      <timestamp>2018-11-07T11:14:29Z</timestamp>
      <contributor>
        <ip>217.33.61.67</ip>
      </contributor>
      <comment>/* References */ added Briggs reference</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5051">In [[mathematics]], a '''superabundant number''' (sometimes abbreviated as '''SA''') is a certain kind of [[natural number]]. A natural number ''n'' is called superabundant precisely when, for all ''m'' &amp;lt; ''n''

:&lt;math&gt;\frac{\sigma(m)}{m} &lt; \frac{\sigma(n)}{n}&lt;/math&gt;

where ''σ'' denotes the [[divisor function|sum-of-divisors function]] (i.e., the sum of all positive divisors of ''n'', including ''n'' itself). The first few superabundant numbers are [[1 (number)|1]], [[2 (number)|2]], [[4 (number)|4]], [[6 (number)|6]], [[12 (number)|12]], [[24 (number)|24]], [[36 (number)|36]], [[48 (number)|48]], [[60 (number)|60]], [[120 (number)|120]], ... {{OEIS|id=A004394}}. For example, the number 5 is not a superabundant number because for 1, 2, 3, 4, and 5, the sigma is 1, 3, 4, 7, 6, and 7/4 &gt; 6/5.

Superabundant numbers were defined by {{harvs|first1=Leonidas|last1=Alaoglu|author1-link=Leonidas Alaoglu|first2=Paul|last2=Erdős|author2-link=Paul Erdős|year=1944|txt=yes}}. Unknown to Alaoglu and Erdős, about 30 pages of Ramanujan's 1915 paper "Highly Composite Numbers" were suppressed.  Those pages were finally published in The Ramanujan Journal 1 (1997), 119–153.  In section 59 of that paper, Ramanujan defines generalized [[highly composite number]]s, which include the superabundant numbers.

== Properties ==
{{harvs|first1=Leonidas|last1=Alaoglu|author1-link=Leonidas Alaoglu|first2=Paul|last2=Erdős|author2-link=Paul Erdős|year=1944|txt=yes}} proved that if ''n'' is superabundant, then there exist a ''k'' and ''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;, ..., ''a''&lt;sub&gt;''k''&lt;/sub&gt; such that

:&lt;math&gt;n=\prod_{i=1}^k (p_i)^{a_i}&lt;/math&gt;

where ''p''&lt;sub&gt;i&lt;/sub&gt; is the ''i''-th prime number, and

:&lt;math&gt;a_1\geq a_2\geq\dotsb\geq a_k\geq 1.&lt;/math&gt;

That is, they proved that if ''n'' is superabundant, the prime decomposition of ''n'' has non-increasing exponents (the exponent of a larger prime is never more than that a smaller prime) and that all primes up to &lt;math&gt;p_k&lt;/math&gt; are factors of ''n''.  Then in particular any superabundant number is an even integer, and it is a multiple of the ''k''-th [[primorial]] &lt;math&gt;p_k\#.&lt;/math&gt;

In fact, the last exponent ''a''&lt;sub&gt;''k''&lt;/sub&gt; is equal to 1 except when n is 4 or 36.

Superabundant numbers are closely related to [[highly composite number]]s. Not all superabundant numbers are highly composite numbers. In fact, only 449 superabundant and highly composite numbers are the same {{OEIS|id=A166981}}. For instance, 7560 is highly composite but not superabundant. Conversely, 1163962800 is superabundant but not highly composite.

Alaoglu and Erdős observed that all superabundant numbers are [[highly abundant number|highly abundant]]. 

Not all superabundant numbers are [[Harshad number]]s. The first exception is the 105th SA number, 149602080797769600.  The digit sum is 81, but 81 does not divide evenly into this SA number.

Superabundant numbers are also of interest in connection with the [[Riemann hypothesis]], and with [[Robin's theorem]] that the Riemann hypothesis is equivalent to the statement that
:&lt;math&gt;\frac{\sigma(n)}{e^\gamma n\log\log n} &lt; 1&lt;/math&gt;
for all ''n'' greater than the largest known exception, the superabundant number 5040. If this inequality has a larger counterexample, proving the Riemann hypothesis to be false, the smallest such counterexample must be a superabundant number {{harv|Akbary|Friggstad|2009}}.

Not all superabundant numbers are [[Colossally abundant number|colossally abundant]].

== Extension ==
The '''generalized &lt;math&gt;k&lt;/math&gt;-super abundant numbers''' are those such that &lt;math&gt;\frac{\sigma_k(m)}{m^k} &lt; \frac{\sigma_k(n)}{n^k}&lt;/math&gt; for all &lt;math&gt;m &lt; n&lt;/math&gt;, where &lt;math&gt;\sigma_k(n)&lt;/math&gt; is the sum of the &lt;math&gt;k&lt;/math&gt;-th powers of the divisors of &lt;math&gt;n&lt;/math&gt;.

1-super abundant numbers are superabundant numbers. 0-super abundant numbers are highly composite numbers.

For example, generalized 2-super abundant numbers are 1, 2, 4, 6, 12, 24, 48, 60, 120, 240, … [https://oeis.org/A208767 (A208767 in OEIS)]

== References ==
*{{citation|first1=Keith|last1=Briggs|title=Abundant numbers and the Riemann hypothesis|journal=Experimental Mathematics|volume=15|year=2006|pages=251–256}}.
*{{citation|doi=10.4169/193009709X470128|first1=Amir|last1=Akbary|first2=Zachary|last2=Friggstad|title=Superabundant numbers and the Riemann hypothesis|journal=American Mathematical Monthly|volume=116|issue=3|year=2009|pages=273–275}}.
*{{citation|first1=Leonidas|last1=Alaoglu|author1-link=Leonidas Alaoglu|first2=Paul|last2=Erdős|author2-link=Paul Erdős|year=1944|title=On highly composite and similar numbers|journal=[[Transactions of the American Mathematical Society]]|volume=56|issue=3|pages=448–469|doi=10.2307/1990319|publisher=American Mathematical Society|jstor=1990319}}.

== External links ==
* [http://mathworld.wolfram.com/SuperabundantNumber.html MathWorld: Superabundant number]


{{Divisor classes}}
{{Classes of natural numbers}}

[[Category:Divisor function]]
[[Category:Integer sequences]]</text>
      <sha1>i5yby3ovxtqt2fspph3fqf9qytdn1xu</sha1>
    </revision>
  </page>
  <page>
    <title>Tail sequence</title>
    <ns>0</ns>
    <id>12196164</id>
    <revision>
      <id>624335850</id>
      <parentid>358407798</parentid>
      <timestamp>2014-09-05T21:02:53Z</timestamp>
      <contributor>
        <username>Mark viking</username>
        <id>17698045</id>
      </contributor>
      <comment>Added wl</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="515">{{Unreferenced|date=December 2008}}In [[mathematics]], specifically [[set theory]], a '''''tail sequence''''' is an [[unbounded]] sequence of contiguous ordinals.  Formally, let β be a [[limit ordinal]].  Then a γ-sequence &lt;math&gt;s \equiv \langle s_{\alpha}| \alpha &lt; \gamma\rangle&lt;/math&gt; is a '''''tail sequence''''' in β if there exists an ε &lt; β such that ''s'' is a [[normal function|normal sequence]] assuming all values in &lt;math&gt;\beta \setminus \epsilon.&lt;/math&gt;

[[Category:Set theory]]

{{settheory-stub}}</text>
      <sha1>me7lebe90l8potqw6lk8w98xg28hr6k</sha1>
    </revision>
  </page>
  <page>
    <title>Timeline of number theory</title>
    <ns>0</ns>
    <id>19373832</id>
    <revision>
      <id>848393328</id>
      <parentid>822813895</parentid>
      <timestamp>2018-07-01T16:57:41Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6245">A timeline of '''[[number theory]]'''.

==Before 1000 BC==
* ca. [[Upper Paleolithic|20,000 BC]] — [[Nile Valley]], [[Ishango Bone]]: possibly the earliest reference to [[prime number]]s and [[Egyptian multiplication]] although this is disputed.&lt;ref&gt;{{cite book|last=Rudman|first=Peter Strom|title=How Mathematics Happened: The First 50,000 Years|year=2007|publisher=Prometheus Books|isbn=978-1-59102-477-4|page=64}}&lt;/ref&gt;
==About 300 BC==
* 300 BC — [[Euclid]] proves [[Euclid's theorem|the number of prime numbers is infinite]].

==1st millennium AD==
* 250 — [[Diophantus]] writes ''[[Arithmetica]]'', one of the earliest treatises on algebra.
* 500 — [[Aryabhata]] solves the general linear [[diophantine equation]].
* ca. 650 — Mathematicians in India create the [[Hindu-Arabic numeral system]] we use, including the zero,the decimals and negative numbers.

==1000&amp;ndash;1500==
*ca. 1000 — [[Abu-Mahmud al-Khujandi]] first states a special case of [[Fermat's Last Theorem]].
* 895 — [[Thabit ibn Qurra]] gives a [[Thabit number|theorem]] by which pairs of [[amicable number]]s can be found, (i.e., two numbers such that each is the sum of the proper divisors of the other).
* 975 — The earliest triangle of [[binomial coefficient]]s (Pascal triangle) occur in the 10th century in commentaries on the Chandas Shastra.
* 1150 — [[Bhaskara II]] gives first general method for solving [[Pell's equation]]
* 1260 — [[Al-Farisi]] gave a new proof of [[Thābit ibn Qurra]]'s theorem, introducing important new ideas concerning [[factorization]] and [[Combinatorics|combinatorial]] methods.  He also gave the pair of amicable numbers 17296 and 18416 which have also been jointly attributed to [[Fermat]] as well as Thabit ibn Qurra.&lt;ref&gt;[http://amicable.homepage.dk/apstat.htm#discoverer Various AP Lists and Statistics] {{Webarchive|url=https://web.archive.org/web/20120728163824/http://amicable.homepage.dk/apstat.htm#discoverer |date=2012-07-28 }}&lt;/ref&gt;

==17th century==
* 1637 -  Pierre de Fermat claims to have proven [[Fermat's Last Theorem]] in his copy of [[Diophantus]]' ''Arithmetica''.

==18th century==
* 1742 -  [[Christian Goldbach]] conjectures that every even number greater than two can be expressed as the sum of two primes, now known as [[Goldbach's conjecture]].
* 1770 - [[Joseph Louis Lagrange]] proves the [[Lagrange's four-square theorem|four-square theorem]], that every positive integer is the sum of four squares of integers. In the same year, [[Edward Waring]] conjectures [[Waring's problem]], that for any positive integer ''k'', every positive integer is the sum of a fixed number of ''k''&lt;sup&gt;th&lt;/sup&gt; powers.
* 1796 -  [[Adrien-Marie Legendre]] conjectures the [[prime number theorem]].

==19th century==
* 1801 -  ''[[Disquisitiones Arithmeticae]]'', Carl Friedrich Gauss's [[number theory]] treatise, is published in Latin.
* 1825 -  [[Peter Gustav Lejeune Dirichlet]] and Adrien-Marie Legendre prove Fermat's Last Theorem for ''n'' = 5.
* 1832 -  Lejeune Dirichlet proves Fermat's Last Theorem for ''n'' = 14.
* 1835 -  Lejeune Dirichlet proves [[Dirichlet's theorem on arithmetic progressions|Dirichlet's theorem]] about prime numbers in arithmetical progressions.
* 1859 -  Bernhard Riemann formulates the [[Riemann hypothesis]] which has strong implications about the distribution of [[prime number]]s.
* 1896 -  [[Jacques Hadamard]] and [[Charles Jean de la Vallée-Poussin]] independently prove the [[prime number theorem]].
* 1896 -  [[Hermann Minkowski]] presents ''Geometry of numbers''.

==20th century==
* 1903 - [[Edmund Georg Hermann Landau]] gives considerably simpler proof of the prime number theorem.
* 1909 - [[David Hilbert]] proves [[Waring's problem]].
* 1912 - Josip Plemelj publishes simplified proof for the Fermat's Last Theorem for exponent ''n'' = 5.
* 1913 - [[Srinivasa Aaiyangar Ramanujan]] sends a long list of complex theorems without proofs to [[G. H. Hardy]].
* 1914 - Srinivasa Aaiyangar Ramanujan publishes ''Modular Equations and Approximations to π''.
* 1910s - Srinivasa Aaiyangar Ramanujan develops over 3000 theorems, including properties of [[highly composite number]]s, the [[partition function (number theory)|partition function]] and its [[asymptotics]], and [[Ramanujan theta function|mock theta functions]]. He also makes major breakthroughs and discoveries in the areas of [[gamma function]]s, [[modular form]]s, [[divergent series]], [[Generalized hypergeometric series|hypergeometric series]] and prime number theory.
* 1919 - [[Viggo Brun]] defines [[Brun's constant]] ''B''&lt;sub&gt;2&lt;/sub&gt; for [[twin prime]]s.
* 1937 - [[I. M. Vinogradov]] proves [[Vinogradov's theorem]] that every sufficiently large odd integer is the sum of three primes, a close approach to proving [[Goldbach's weak conjecture]].
* 1949 - [[Atle Selberg]] and [[Paul Erdős]] give the first elementary proof of the [[prime number theorem]].
* 1966 - [[Chen Jingrun]] proves [[Chen's theorem]], a close approach to proving the [[Goldbach conjecture]].
* 1967 - [[Robert Langlands]] formulates the influential [[Langlands program]] of conjectures relating number theory and representation theory.
* 1983 -  [[Gerd Faltings]] proves the [[Mordell conjecture]] and thereby shows that there are only finitely many whole number solutions for each exponent of Fermat's Last Theorem.
* 1994 -  [[Andrew Wiles]] proves part of the [[Taniyama–Shimura conjecture]] and thereby proves [[Fermat's Last Theorem]].
* 1999 - the full Taniyama–Shimura conjecture is proved.

==21st century==
* 2002 - [[Manindra Agrawal]], [[Nitin Saxena]], and [[Neeraj Kayal]] of [[IIT Kanpur]] present an unconditional deterministic [[polynomial time]] algorithm to determine whether a given number is [[prime number|prime]].
* 2002 - [[Preda Mihăilescu]] proves [[Catalan's conjecture]].
* 2004 - [[Ben J. Green|Ben Green]] and [[Terence Tao]] prove the [[Green–Tao theorem]], which states that the sequence of prime numbers contains arbitrarily long arithmetic progressions.

==References==
{{Reflist}}&lt;!--added above categories/infobox footers by script-assisted edit--&gt;

{{DEFAULTSORT:Timeline Of Number Theory}}
[[Category:Mathematics timelines|Number theory]]
[[Category:Number theory|*]]</text>
      <sha1>ib0ssmrs8vs2tb1bghp7ve8hxtq9g1a</sha1>
    </revision>
  </page>
  <page>
    <title>United Kingdom Mathematics Trust</title>
    <ns>0</ns>
    <id>552624</id>
    <revision>
      <id>848052576</id>
      <parentid>836980956</parentid>
      <timestamp>2018-06-29T13:59:28Z</timestamp>
      <contributor>
        <username>WillUnicorn</username>
        <id>34098256</id>
      </contributor>
      <minor/>
      <comment>changed incorrect information and updated for 2018</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17279">{{Use dmy dates|date=February 2015}}
{{Use British English|date=February 2015}}
&lt;!--  Commented out because image was deleted: [[File:UKMT.JPG|thumb|right|90px|UKMT Logo]] --&gt;
The '''United Kingdom Mathematics Trust''' (UKMT) is a charity founded in 1996 to help with the [[education]] of [[children]] in [[mathematics]] within the [[United Kingdom|UK]].

==History==
The national mathematics competitions existed prior to the formation of the UKMT, but the foundation of the UKMT in the [[summer]] of 1996 enabled them to be run collectively. The Senior Mathematical Challenge was formerly the National Mathematics Contest. Founded in 1961, it was run by the Mathematical Association from 1975 until its adoption by the UKMT in 1996. The Junior and Intermediate Mathematical Challenges were the initiative of [[Tony Gardiner|Dr Tony Gardiner]] in 1987 and were run by him under the name of the United Kingdom Mathematics Foundation until 1996. The popularity of the UK national mathematics competitions is largely due to the publicising efforts of [[Tony Gardiner|Dr Gardiner]] in the years 1987-1995. Hence, in 1995, he advertised for the formation of a committee and for a host institution that would lead to the establishment of the UKMT, enabling the challenges to be run effectively together under one organisation.

==Mathematical Challenges==
The UKMT run a series of mathematics challenges to encourage children's interest in mathematics and develop their skills:
* '''Junior Mathematical Challenge''' (UK year 8/S2 and below)
* '''Intermediate Mathematical Challenge''' (UK year 11/S4 and below)
* '''Senior Mathematical Challenge''' (UK year 13/S6 and below)&lt;ref&gt;[http://www.mathcomp.leeds.ac.uk/] ''United Kingdom Mathematics Trust'', Thursday 19 April 2012&lt;/ref&gt;

==Certificates==
In the Junior and Intermediate Challenges the top scoring 40% of the entrants receive bronze, silver or gold certificates based on their mark in the paper. In the Senior Mathematical Challenge these certificates are awarded to top scoring 60% of the entries. In each case bronze, silver and gold certificates are awarded in the ratio 3 : 2 : 1.
So in the Junior and Intermediate Challenges
* The '''Gold''' award is achieved by the top 6-7% of the entrants.
* The '''Silver''' award is achieved by 13-14% of the entrants.
* The '''Bronze''' award is achieved by 21% of the entrants.
For the Senior Challenge these percentages are 10%, 20% and 30%, respectively.&lt;ref&gt;
[http://www.mathcomp.leeds.ac.uk/individual-competitions/] ''United Kingdom Mathematics Trust'' , ''Individual Competitions'', Thursday 6 October 2016&lt;/ref&gt;

==Junior Mathematical Challenge==
The Junior Mathematical Challenge (JMC) is an introductory challenge for pupils in Years 8 or below (aged 13) or below. This takes the form of twenty-five multiple choice questions to be sat in exam conditions, to be completed within one hour. The first fifteen questions are designed to be easier, and a pupil will gain '''5''' marks for getting a question in this section correct. Questions 16-20 are more difficult and are worth '''6''' marks, with a penalty of '''1''' point for a wrong answer which tries to stop pupils guessing. The last five questions are intended to be the most challenging and so are also '''6''' marks, but with a '''2''' point penalty for an incorrectly answered question. Questions to which no answer is entered will gain (and lose) '''0''' marks.&lt;ref&gt;[http://www.mathcomp.leeds.ac.uk/individual-competitions/junior-challenge/] ''United Kingdom Mathematics Trust'' , ''Junior Challenge'', Thursday 19 April 2012&lt;/ref&gt;

===Junior Mathematical Olympiad===
The top 40% of students get a certificate of varying levels (Gold, Silver or Bronze) based on their score. The highest 1200 scorers are also invited to take part in the Junior Mathematical Olympiad (JMO). Like the JMC, the JMO is sat in schools. This is also divided into two sections. Part A is composed of ten questions in which the candidate gives just the answer (not multiple choice), worth 10 marks (each question 1 mark). Part B consists of 6 questions and encourages students to write out full solutions. Each B question is marked out of 10 and students are encouraged to write complete answers to 2-4 questions rather than hurry through incomplete answers to all 6. If the solution is judged to be incomplete, it is marked on a 0+ basis, maximum 3 marks. If it has an evident logical strategy, it is marked on a 10- basis. The total mark is out of 70. Everyone who participates in this challenge will gain a certificate (Participation 75%, Distinction 25%); the top 200 or so gaining medals (Gold, Silver, Bronze); with the top fifty winning a book prize.&lt;ref&gt;[http://www.mathcomp.leeds.ac.uk/individual-competitions/junior-mathematical-olympiad/] ''United Kingdom Mathematics Trust'' , ''Junior Mathematical Olympiad'', Thursday 19 April 2012&lt;/ref&gt;

==Intermediate Mathematical Challenge==
The Intermediate Mathematical Challenge (IMC) is aimed at school years equivalent to English Years 9-11. Following the same structure as the JMC, this paper presents the student with twenty-five multiple choice questions to be done under exam conditions in one hour.  The first fifteen questions are designed to be easier, and a pupil will gain '''5''' marks for getting a question in this section correct. Questions 16-20 are more difficult and are worth '''6''' marks, with a penalty of '''1''' point for a wrong answer which tries to stop pupils guessing. The last five questions are intended to be the most challenging and so are also '''6''' marks, but with a '''2''' point penalty for an incorrectly answered question. Questions to which no answer is entered will gain (and lose) '''0''' marks.&lt;ref&gt;[http://www.mathcomp.leeds.ac.uk/individual-competitions/intermediate-challenge/] ''United Kingdom Mathematics Trust'' , ''Intermediate Challenge'', Thursday 19 April 2012&lt;/ref&gt;

Again, the top 40% of students taking this challenge get a certificate. There are two follow-on rounds to this competition: The European Kangaroo and the Intermediate Mathematical Olympiad.

===Intermediate Mathematical Olympiad===
To prevent this getting confused with the [[International Mathematical Olympiad]], this is often abbreviated to the ''IMOK Olympiad'' (IMOK = Intermediate Mathematical Olympiad and Kangaroo).

The IMOK is sat by the top 500 scorers from each school year in the Intermediate Maths Challenge and consists of three papers, '[[Arthur Cayley|Cayley]]', '[[Colin Maclaurin|Maclaurin]]' and '[[William Rowan Hamilton|Hamilton]]' named after famous mathematicians. The paper the student will undertake depends on the year group that student is in (Cayley for those in year 9 and below, Hamilton for year 10 and Maclaurin for year 11).&lt;ref&gt;[http://www.mathcomp.leeds.ac.uk/individual-competitions/intermediate-mathematical-olympiad/] ''United Kingdom Mathematics Trust'' , ''Intermediate Mathematical Olympiad'', Saturday 26 May 2012&lt;/ref&gt;

Each paper contains six questions. Each solution is marked out of 10 on a 0+ and 10- scale; that is to say, if an answer is judged incomplete or unfinished, it is awarded a few marks for progress and relevant observations, whereas if it is presented as complete and correct, marks are deducted for faults, poor reasoning, or unproven assumptions. As a result, it is quite uncommon for an answer to score a middling mark (e.g. 4–6). This makes the maximum mark out of 60. For a student to get two questions fully correct is considered "very good". All people taking part in this challenge will get a certificate (participation for the bottom 50%, merit for the next 25% and distinction for the top 25%). The mark boundaries for these certificates change every year, but normally around 30 marks will gain a Distinction. Those scoring highly (the top 50) will gain a [[book]] prize; again, this changes every year, with 44 marks required in the Maclaurin paper in 2006. Also, the top 100 candidates will receive a [[medal]]; [[bronze]] for Cayley, [[silver]] for Hamilton and [[gold]] for Maclaurin.&lt;ref&gt;[http://www.mathcomp.leeds.ac.uk/individual-competitions/intermediate-mathematical-olympiad/] ''United Kingdom Mathematics Trust'' , ''Intermediate Mathematical Olympiad'', Thursday 19 April 2012&lt;/ref&gt;

In addition to the book prize, each year approximately two x forty students are chosen to go to a National Mathematics Summer School in July (two separate summer schools each of 1 week). At this summer school the students are stretched, with daily lectures going beyond the normal [[GCSE]] syllabus and exploring some of the wider (and more appealing) aspects of mathematics.&lt;ref&gt;[http://www.mathcomp.leeds.ac.uk/docs/Summer%20School.pdf] ''United Kingdom Mathematics Trust'', Thursday 19 April 2012&lt;/ref&gt;

===European Kangaroo===
{{main|European Kangaroo}}

The [[Europe]]an Kangaroo is a competition which follows the same structure as the AMC ([[Australian Mathematics Competition]]). There are twenty-five multiple-choice questions and no penalty marking. This paper is taken throughout [[Europe]] by over 3 million pupils from more than 37 countries. Two different Kangaroo papers follow on from the Intermediate Maths Challenge and the next 5500 highest scorers below the Olympiad threshold are invited to take part (both papers are by invitation only). The ''Grey Kangaroo'' is sat by students in year 9 and below and the ''Pink Kangaroo'' is sat by those in years 10 and 11. The top 25% of scorers in each paper receive a certificate of merit and the rest receive a certificate of participation. All those who sit either ''Kangaroo'' also receive a [[Keychain#Key fob|keyfob]] containing a different mathematical [[puzzle]] each year. ([http://www.arbelos.co.uk/keyfobs.html The puzzles along with solutions])&lt;ref&gt;[http://www.mathcomp.leeds.ac.uk/individual-competitions/intermediate-kangaroo/] ''United Kingdom Mathematics Trust'' , ''Intermediate Kangaroo'', Thursday 19 April 2012&lt;/ref&gt;

==Senior Mathematical Challenge==
The Senior Mathematical Challenge (SMC) is open to students who are in Year 13 (aged 18) or below. The paper has twenty-five multiple choice questions. A correct answer is worth '''4''' marks, while '''1''' mark is deducted from a starting total of 25 for an incorrect answer. This gives a score between 0 and 125 marks.

Unlike the JMC and IMC, the top 60% get a certificate, the 1000 (approx.) highest scorers are invited to compete in the [[British Mathematical Olympiad]] and the next 2000 (approx.) highest scorers are invited to sit the Senior Kangaroo. Mathematics teachers may also, on payment of a fee, enter students who did not score quite well enough in the SMC, but who might cope well in the next round.&lt;ref&gt;[http://www.mathcomp.leeds.ac.uk/individual-competitions/senior-challenge/] ''United Kingdom Mathematics Trust'' , ''Senior Challenge'', Thursday 19 April 2012&lt;/ref&gt;

===British Mathematical Olympiad===
{{main|British Mathematical Olympiad}}

Round 1 of the Olympiad is a three-and-a-half hour examination including six more difficult, long answer questions, which serve to test entrants' puzzle-solving skills. As of 2005, a more accessible first question was added to the paper; before this, it only consisted of 5 questions. Around one hundred high scoring entrants from BMO1 are invited to sit the [[British Mathematical Olympiad#BMO Round 2|second round]], with the same time limit, in which 4 questions are posed. The twenty top scoring students from the [[British Mathematical Olympiad#BMO Round 2|second round]] are subsequently invited to a training camp at [[Trinity College, Cambridge]] for the first stage of the [[International Mathematical Olympiad]] UK team selection.&lt;ref&gt;[http://www.bmoc.maths.org/home/bmo.shtml] ''British Mathematical Olympiad Subtrust'', Thursday 19 April 2012&lt;/ref&gt;

===Senior Kangaroo===
The Senior Kangaroo is a one-hour examination to which the next 1500 (approx.) highest scorers below the Olympiad threshold are invited and unlike the Olympiad, a fee cannot be paid for entry. The paper consists of twenty questions, each of which require three digit answers ([[leading zeros]] are used if the answer is less than 100, since the paper is marked by [[machine]]). The top 25% of candidates receive a certificate of merit and the rest receive a certificate of participation.&lt;ref&gt;[http://www.mathcomp.leeds.ac.uk/individual-competitions/senior-kangaroo/] ''United Kingdom Mathematics Trust'' , ''Senior Kangaroo'', Thursday 19 April 2012&lt;/ref&gt;

==Team Challenge==
The UKMT Team Maths Challenge is an annual event. One team from each participating school, comprising four pupils selected from year 8 and 9 (ages 12–14), competes in a regional round. No more than 2 pupils on a team may be from Year 9. There are over 60 regional competitions in the UK, held between February and May. The winning team in each regional round, as well as a few high-scoring runners-up from throughout the country, are then invited to the National Final in London, usually in late June.&lt;ref&gt;[http://www.mathcomp.leeds.ac.uk/team-challenges/] ''United Kingdom Mathematics Trust'' , ''Team Challenges'', Thursday 19 April 2012&lt;/ref&gt;

There are 4 rounds: 
* Group Questions
* Cross-Numbers
* Shuttle (NB: The previous Head-to-Head Round has been replaced with another, similar to the Mini-Relay used in the 2007 and 2008 National Finals.)
* Relay

In the National Final however an additional 'Poster Round' is added at the beginning. The poster round is a separate competition, however, since 2018 it is worth up to six marks towards the main event.  Four schools have won the Junior Maths Team competition at least twice: Queen Mary's Grammar School in Walsall, City of London School, St Olave's Grammar School, and Westminster Under School.

{| class="wikitable"
|-
! '''Year'''
! '''2010'''
! '''2011'''
! '''2013'''
! '''2014'''
!2015
!2016
!2017
!2018
|-
| '''Winner'''
| [[Magdalen College School, Oxford]]
| [[St Paul's Girls' School]]
| [[City of London School]]
| [[City of London School]]
| [[Westminster Under School]]
| [[Westminster Under School]]
|[[St Olave's Grammar School]]
|[[Westminster Under School]]
|-
| '''2nd Place'''
| [[Queen Elizabeth's Grammar School for Boys]]
| [[Magdalen College School, Oxford]]
| [[King Edward's School, Birmingham]]
| [[Reading School]] &amp; [[Colchester Royal Grammar School]]
| [[Bancroft's School]]
| -
|[[The Judd School]]
| -
|-
| '''3rd Place'''
| [[Clifton College]]
| [[City of London School]]
| [[Magdalen College School, Oxford]]
| -
| [[University College School]]
|[[St Olave's Grammar School]]
|[[Westminster Under School]]
| -
|}

==Senior Team Challenge==

A pilot event for a competition similar to the Team Challenge, aimed at 16- to 18-year-olds, was launched in the Autumn of 2007.  The format is much the same, with a limitation of 2 year 13 (upper sixth-form) pupils per team.  There were 19 regional heats held in November, with the winning team from each heat going to a national final held in London on 7 February 2008, with the winners being Torquay Boys' Grammar School. The 2009 final was held in February, with the winners this time being Westminster School.  The 2010 final was held in February, and Westminster School retained their title.

In 2011 Harrow School won the 2011 final, after scoring 178/180 in the main competition itself.&lt;ref&gt;[http://www.mathcomp.leeds.ac.uk/team-challenges/senior-team-challenge/] ''United Kingdom Mathematics Trust'' , ''Senior Team Challenge'', Thursday 19 April 2012&lt;/ref&gt;

The 2013 National Final concluded on 5 February at the Camden Centre in London. 62 teams were invited to the final which was won by Westminster School for the third time (2009, 2010, 2013). There was a three-way tie for second place between City of London School, Eton College and Magdalen College School.

==British Mathematical Olympiad Subtrust==
''For more information see [[British Mathematical Olympiad Subtrust]].''

The ''British Mathematical Olympiad Subtrust'' is run by the '''UKMT''', it runs the [[British Mathematical Olympiad]] as well as the [[UK Mathematical Olympiad for Girls]], several training camps throughout the year such as a winter camp in [[Hungary]], an Easter camp at [[Trinity College, Cambridge]], and other training and selection of the IMO team.

==See also==
* [[European Kangaroo]]
* [[British Mathematical Olympiad]]
* [[International Mathematical Olympiad]]
* [[International Mathematics Competition for University Students]]

==References==

{{Reflist}}

==External links==
* [http://www.ukmt.org.uk United Kingdom Mathematics Trust website]
* [http://www.bmoc.maths.org/home/bmo.shtml British Mathematical Olympiad Committee site]
* [http://www.imc-math.org.uk International Mathematics Competition for University Students (IMC) site]
* [http://www.wpr3.co.uk/UKMT/jmc.html Junior Mathematical Challenge Sample Paper]
* [http://www.wpr3.co.uk/UKMT/imc.html Intermediate Mathematical Challenge Sample Paper]
* [http://www.wpr3.co.uk/UKMT/smc.html Senior Mathematical Challenge Sample Paper]

[[Category:1996 establishments in the United Kingdom]]
[[Category:Competitions in the United Kingdom]]
[[Category:Mathematics competitions]]
[[Category:Mathematics education in the United Kingdom]]</text>
      <sha1>ng79md1w83hpldkqdulr7ktptnzcrko</sha1>
    </revision>
  </page>
  <page>
    <title>Universality probability</title>
    <ns>0</ns>
    <id>47412478</id>
    <revision>
      <id>864726720</id>
      <parentid>864344694</parentid>
      <timestamp>2018-10-19T02:02:14Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Add: pmid. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[User:NessieVL|NessieVL]]; [[Category:Articles containing self-references]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10305">{{multiple issues|
{{Inappropriate person|date=May 2017}}
{{Self-reference|date=May 2017}}
{{essay-like|date=May 2017}}
{{more footnotes|date=May 2017}}
{{technical|date=May 2017}}
{{rewrite|date=May 2017}}
}}
== Background ==
A [[Turing machine]] is a basic model of [[computation]].  Some [[Turing machine]]s might be specific to doing particular calculations.  For example, a Turing machine might take input which comprises two numbers and then produce output which is the product of their [[multiplication]].  Another Turing machine might take input which is a list of numbers and then give output which is those numbers [[sorting|sorted]] in order.

A [[Turing machine]] which has the ability to simulate any other Turing machine is called [[Computationally universal|universal]] - in other words, a Turing machine (TM) is said to be a [[universal Turing machine]] (or UTM) if, given any other TM, there is a some input (or "header") such that the first TM given that input "header" will forever after behave like the second TM.

An interesting [[mathematical]] and [[philosophical]] question then arises.  If a [[universal Turing machine]] is given random input (for suitable definition of [[random]]), how probable is it that it remains universal forever?

== Definition ==
Given a [[prefix-free code|prefix-free]] [[Turing machine]], the '''universality probability''' of it is the [[probability]] that it remains [[universal Turing machine|universal]] even when every input of it (as a [[binary string]]) is prefixed by a random binary string. More formally, it is the [[probability measure]] of reals (infinite binary sequences) which have the property that every initial segment of them preserves the [[universal Turing machine|universality]] of the given Turing machine. This notion was introduced by the computer scientist [[Chris Wallace (computer scientist)|Chris Wallace]] and was first explicitly  discussed in print in an article by Dowe&lt;ref&gt;*{{cite journal |author=Dowe, D.L. |title=Foreword re C. S. Wallace |journal=Computer Journal |volume=51 |issue=5 |pages=523–560 |date=5 September 2008 |doi=10.1093/comjnl/bxm117 |url=http://comjnl.oxfordjournals.org/cgi/content/full/51/5/523 }} (and [http://www.csse.monash.edu.au/~dld/Publications/2008/DLDowe_ForewordReCSWallace_CompJVol51Num5Sept2008pp523-560.pdf here])&lt;/ref&gt; (and a subsequent article&lt;ref&gt;*Dowe, D. L. (2011), "[http://www.csse.monash.edu.au/~dld/Publications/2010/Dowe2010_MML_HandbookPhilSci_Vol7_HandbookPhilStat_MML+hybridBayesianNetworkGraphicalModels+StatisticalConsistency+InvarianceAndUniqueness_pp901-982.pdf MML, hybrid Bayesian network graphical models, statistical consistency, invariance and uniqueness"], Handbook of the Philosophy of Science - (HPS Volume 7) Philosophy of Statistics, P.S. Bandyopadhyay and M.R. Forster (eds.), Elsevier, pp901-982&lt;/ref&gt;). However, relevant discussions also appear in an earlier article by Wallace and Dowe.&lt;ref&gt;Wallace, C. S. &amp; Dowe, D. L. 1999 ''[http://comjnl.oxfordjournals.org/content/42/4/270 Minimum message length and Kolmogorov complexity]'' Computer J. 42, 270–283&lt;/ref&gt;

== Universality probabilities of prefix-free UTMs are non-zero ==
Although the universality probability of a [[Universal Turing Machine|UTM]] (UTM) was originally suspected to be zero, relatively simple proofs exist that the [[supremum]] of the set of universality probabilities is equal to 1, such as a proof based on [[random walk]]s&lt;ref&gt;*Hernandez-Orallo, J. &amp; Dowe, D. L. (2013), "On Potential Cognitive Abilities in the Machine Kingdom", [https://www.springer.com/computer/ai/journal/11023 Minds and Machines], Vol. 23, Issue 2, [https://dx.doi.org/10.1007/s11023-012-9299-6 pp179-210]&lt;/ref&gt; and a proof in Barmpalias and Dowe (2012).
Once one has one [[prefix-free code|prefix-free]] UTM with a non-zero universality probability, it immediately follows that all [[prefix-free code|prefix-free]] [[Universal Turing Machine|UTM]]s have non-zero universality probability.
Further, because the [[supremum]] of the set of universality probabilities is 1 and because the set {{math|{ {{sfrac|''m''| 2&lt;sup&gt;''n''&lt;/sup&gt;}} {{!}} 0 &amp;lt; ''n'' &amp;amp; 0 &amp;lt; ''m'' &amp;lt; 2&lt;sup&gt;''n''&lt;/sup&gt;} }}
is [[dense set|dense]] in the interval [0, 1],
suitable constructions of UTMs
(e.g., if ''U'' is a UTM, define a
UTM ''U''&lt;sub&gt;2&lt;/sub&gt; by ''U''&lt;sub&gt;2&lt;/sub&gt;(0''s'') halts for all strings ''s'',
U&lt;sub&gt;2&lt;/sub&gt;(1''s'') = ''U''(''s'') for all s) gives that the set of universality probabilities is
[[dense set|dense]] in the open interval (0, 1).

== Characterization and randomness of universality probability ==
Universality probability was thoroughly studied and characterized by Barmpalias and Dowe in 2012.&lt;ref&gt;{{cite journal |author=Barmpalias, G. and Dowe D.L. |title=Universality probability of a prefix-free machine |journal=Philosophical Transactions of the Royal Society A |volume=370 |issue=1 | pages=3488–3511 |date=2012 |doi=10.1098/rsta.2011.0319|pmid=22711870 |bibcode=2012RSPTA.370.3488B }}&lt;/ref&gt;
Seen as [[real number]]s, these probabilities were completely characterized in terms of notions in [[computability theory]]
and [[algorithmic information theory]].
It was shown that when the underlying machine is universal, these numbers are highly [[Algorithmically random sequence|algorithmically random]]. More specifically, it is [[Per Martin-Löf|Martin-Löf]] random relative to the third iteration of the [[halting problem]]. In other words, they are random relative to null sets that can be defined with four quantifiers in [[Peano arithmetic]]. Vice versa, given such a highly random number{{clarify|date=August 2015}} (with appropriate approximation properties) there is a Turing machine with universality probability that number.

== Relation with Chaitin's constant ==
Universality probabilities are very related to the [[Chaitin's constant|Chaitin constant]], which is the halting probability of a universal prefix-free machine. In a sense, they are complementary to the halting probabilities of universal machines relative to the third iteration of the [[halting problem]]. In particular, the universality probability can be seen as the non-halting probability of a machine with oracle the third iteration of the halting problem. Vice versa, the non-halting probability of any prefix-free machine with this highly non-computable oracle is the universality probability of some prefix-free machine.

== Probabilities of machines as examples of highly random numbers ==
Universality probability provides a concrete and somewhat natural example of a highly random number (in the sense of [[algorithmic information theory]]). In the same sense, Chaitin's constant provides a concrete example of a random number (but for a much weaker notion of algorithmic randomness).

== See also ==
* [[Incompleteness theorem]]
* [[Kolmogorov complexity]]
* [[Algorithmic probability]]
* [[Kolmogorov complexity]]
* [[Minimum message length]]
* [[Inductive inference]]
* [[Solomonoff's theory of inductive inference]]
* [[History of randomness]]

== References ==
{{Reflist}}

== External links ==
*{{cite journal |author=Barmpalias, G. and Dowe D.L. |title=Universality probability of a prefix-free machine |journal=Philosophical Transactions of the Royal Society A |volume=370 |issue=1 |pages=3488–3511 (Theme Issue 'The foundations of computation, physics and mentality: the Turing legacy' compiled and edited by Barry Cooper and Samson Abramsky) |date=2012 |url=http://rsta.royalsocietypublishing.org/content/370/1971/3488|bibcode=2012RSPTA.370.3488B |doi=10.1098/rsta.2011.0319 |pmid=22711870 }}
*{{cite journal |author=Dowe, D.L. |title=Foreword re C. S. Wallace |journal=Computer Journal |volume=51 |issue=5 |pages=523–560 |date=5 September 2008 |doi=10.1093/comjnl/bxm117 |url=http://comjnl.oxfordjournals.org/cgi/content/full/51/5/523 }} (and [http://www.csse.monash.edu.au/~dld/Publications/2008/DLDowe_ForewordReCSWallace_CompJVol51Num5Sept2008pp523-560.pdf here]).
* Dowe, D. L. (2011), "[http://www.csse.monash.edu.au/~dld/Publications/2010/Dowe2010_MML_HandbookPhilSci_Vol7_HandbookPhilStat_MML+hybridBayesianNetworkGraphicalModels+StatisticalConsistency+InvarianceAndUniqueness_pp901-982.pdf MML, hybrid Bayesian network graphical models, statistical consistency, invariance and uniqueness"], Handbook of the Philosophy of Science - (HPS Volume 7) Philosophy of Statistics, P.S. Bandyopadhyay and M.R. Forster (eds.), Elsevier, pp901-982.
* Wallace, C. S. &amp; Dowe, D. L. 1999 ''[http://comjnl.oxfordjournals.org/content/42/4/270 Minimum message length and Kolmogorov complexity]''. Computer J. 42, 270–283.
* Hernandez-Orallo, J. &amp; Dowe, D. L. (2013), "On Potential Cognitive Abilities in the Machine Kingdom", [https://www.springer.com/computer/ai/journal/11023 Minds and Machines], Vol. 23, Issue 2, [https://dx.doi.org/10.1007/s11023-012-9299-6 pp179-210] (and [http://users.dsic.upv.es/~flip/papers/MINDS-MACHINES-potential.pdf here])
* Barmpalias, G. (June 2015), [http://math.uni-heidelberg.de/logic/conferences/ccr2015/Slides%20CCR/Barmpalias_CCR_2015.pdf slides from talk] entitled [http://math.uni-heidelberg.de/logic/conferences/ccr2015/Slides%20CCR/Barmpalias_CCR_2015.pdf ``Randomness, probabilities and machines''] at the [http://math.uni-heidelberg.de/logic/conferences/ccr2015 Tenth International Conference on Computability, Complexity and Randomness] ([http://math.uni-heidelberg.de/logic/conferences/ccr2015 CCR 2015]) conference, 22–26 June 2015, Heidelberg, Germany.
* Cristian S. Calude, Michael J. Dinneen, and Chi-Kou Shu. ''[http://www.cs.auckland.ac.nz/~cristian/Calude361_370.pdf Computing a Glimpse of Randomness].''

== Further reading==
* Ming Li and Paul Vitányi (1997).  ''An Introduction to Kolmogorov Complexity and Its Applications''. Springer. [http://citeseer.ist.psu.edu/li97introduction.html Introduction chapter full-text].
* Cristian S. Calude (2002). ''Information and Randomness: An Algorithmic Perspective'', second edition. Springer.  {{ISBN|3-540-43466-6}}
* R. Downey, and D. Hirschfeldt (2010), ''Algorithmic Randomness and Complexity'', Springer-Verlag.

[[Category:Articles created via the Article Wizard]]
[[Category:Algorithmic information theory]]
[[Category:Theory of computation]]
[[Category:Real transcendental numbers]]</text>
      <sha1>imt4p4llugi9knf2d2a2bgcs482l66p</sha1>
    </revision>
  </page>
  <page>
    <title>Wayne Snyder</title>
    <ns>0</ns>
    <id>43939832</id>
    <revision>
      <id>837898261</id>
      <parentid>772367990</parentid>
      <timestamp>2018-04-23T17:58:20Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (2 sources from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5697">{{Infobox scientist
| name        = Wayne Snyder
| native_name = 
| native_name_lang = 
| image       =   &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| imagesize   = 
| alt         = 
| caption     = 
| birth_date  =   &lt;!--{{birth date |YYYY|MM|DD}}--&gt;
| birth_place = 
| death_date  =   &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place = 
| death_cause = 
| resting_place = 
| resting_place_coordinates =  &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names = 
| residence   = Rich Hall
| citizenship = 
| nationality = 
| fields      = 
| workplaces  = 
| patrons     =
| alma_mater  = 
| thesis_title = Complete Sets of Transformations for General Unification
| thesis_url  =   &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year = 1988
| doctoral_advisor = [[Jean Henri Gallier]]
| academic_advisors = 
| doctoral_students = 
| notable_students = 
| known_for   = 
| influences  = 
| influenced  = 
| awards      = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse      =   &lt;!--(or | spouses = )--&gt;
| partner     =   &lt;!--(or | partners = )--&gt;
| children    = John Henry, Matthew
| signature   =   &lt;!--(filename only)--&gt;
| signature_alt = 
| website     = {{URL|http://www.cs.bu.edu/~snyder/}}
| footnotes   = 
}}

'''Wayne Snyder''' is an associate professor at [[Boston University]] known for his work in [[E-unification]] theory.

He was raised in [[Yardley, Pennsylvania]], worked in his father's aircraft shop, attended the [[Berklee School of Music]], and obtained an MA in [[Augustan poetry]] at [[Tufts University]].
He then studied computer science, and earned his Ph.D. at the [[University of Pennsylvania]] in 1988.
In 1987 he came to [[Boston University]], teaching introductory computer science, and researching on [[automated reasoning]], and, more particularly, [[E-unification]].
&lt;ref&gt;[http://www.cs.bu.edu/~snyder/personal.html Personal information page]&lt;/ref&gt;

==Selected publications==

* {{cite book |author1=Gallier, J.H.  |author1-link= Jean Gallier |author2=Snyder, W.  |lastauthoramp=yes | contribution=A General Complete E-Unification Procedure | pages=216–227 | year=1987 | editor=Lescanne, Pierre | title=[[Rewriting Techniques and Applications]], 2nd Int. Conf., RTA-87 | series=[[LNCS]] | volume=256 | publisher=Springer}}
* {{cite journal |author1=Jean H. Gallier  |author2=Wayne Snyder  |lastauthoramp=yes | title=Complete Sets of Transformations for General E-Unification | journal=[[Theoretical Computer Science (journal)|Theoretical Computer Science]] | volume=67 | pages=203–260 | url=http://www.sciencedirect.com/science/article/pii/0304397589900042/pdf?md5=28f5773631f4da449f493ddf610a57ee&amp;pid=1-s2.0-0304397589900042-main.pdf | year=1989 | doi=10.1016/0304-3975(89)90004-2}}
* {{cite book | author=Snyder, W. | contribution=Efficient Ground Completion: An O(n log n) Algorithm for Generating Reduced Sets of Ground Rewrite Rules Equivalent to a Set of Ground Equations E | pages=419–433 | year=1989 | editor=[[Nachum Dershowitz]] | title=Rewriting Techniques and Applications, 3rd Int. Conf., RTA-89 | series=LNCS | volume=355 | publisher=Springer}}
* {{cite book | author=Wayne Snyder | contribution=Higher order E-unification | title=Proc. 10th [[Conference on Automated Deduction]] | publisher=Springer | series=LNAI | volume=449 | pages=573–587 |date=Jul 1990 }}
* {{cite journal | author=Jean H. Gallier and Paliath Narendran and [[David A. Plaisted]] and Wayne Snyder | title=Rigid E-Unification:  NP-Completeness and Applications to Equational Matings | journal=Inf. Comput. | volume=87 | number=1/2 | pages=129–195 | url=http://www.sciencedirect.com/science/article/pii/089054019090061L/pdf?md5=5e3c837622767182f01513376905359e&amp;pid=1-s2.0-089054019090061L-main.pdf | year=1990 | doi=10.1016/0890-5401(90)90061-l}}
* {{cite book |author1=Snyder, W.  |author2=Lynch, C.  |lastauthoramp=yes | contribution=Goal Directed Strategies for Paramodulation | pages=150–161 | year=1991 | editor=[[Ronald V. Book]] | title=Rewriting Techniques and Applications, 4th Int. Conf., RTA-91 | series=LNCS | volume=488 | publisher=Springer}}
* {{cite book |author1=Lynch, C.  |author2=Snyder, W.  |lastauthoramp=yes | contribution=Redundancy Criteria for Constrained Completion | pages=2–16 | year=1993 | editor=Kirchner, Claude | title=Rewriting Techniques and Applications, 5th Int. Conf., RTA-93 | series=LNCS | volume=690 | publisher=Springer}}
* {{cite journal | author=Jean H. Gallier and Paliath Narendran and David A. Plaisted and Stan Raatz and Wayne Snyder | title=An Algorithm for Finding Canonical Sets of Ground Rewrite Rules in Polynomial Time | journal=[[J. ACM]] | volume=40 | number=1 | pages=1–16 | url=http://cs-pub.bu.edu/fac/snyder/publications/groundcompletionJACMr.pdf | year=1993 | doi=10.1145/138027.138032}}
* {{cite book | author=[[Franz Baader]] and Wayne Snyder | contribution=Unification Theory | pages=439–526 | title=[[Handbook of Automated Reasoning]] | editor=[[John Alan Robinson|Alan Robinson]] and [[Andrei Voronkov]] | publisher=MIT Press + Elsevier | year=2001 | contribution-url=http://www.cs.bu.edu/~snyder/publications/UnifChapter.pdf}}

==References==
{{Reflist}}

==External links==
* [http://www.cs.bu.edu/~snyder Home page]
* [http://dblp.uni-trier.de/pers/hd/s/Snyder:Wayne Publications] at [[DBLP]]
* [http://www.cs.bu.edu/~snyder/pubs.html Publications] at Snyder's home page
* {{mathGenealogy|103996}}

{{Authority control}}

{{DEFAULTSORT:Snyder, Wayne}}
[[Category:Theoretical computer scientists]]
[[Category:American computer scientists]]
[[Category:Living people]]


{{compu-scientist-stub}}</text>
      <sha1>7og6svm9qcs1zszip2uzxjg6woreelj</sha1>
    </revision>
  </page>
  <page>
    <title>Wirtinger's inequality for functions</title>
    <ns>0</ns>
    <id>1461534</id>
    <revision>
      <id>787641175</id>
      <parentid>782439749</parentid>
      <timestamp>2017-06-26T16:34:54Z</timestamp>
      <contributor>
        <username>BD2412</username>
        <id>196446</id>
      </contributor>
      <comment>Intentional disambig linking as required by [[WP:INTDABLINK]], to prevent link from disrupting lists of errors needing repair.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2822">: ''For other inequalities named after Wirtinger, see [[Wirtinger's inequality (disambiguation)|Wirtinger's inequality]].''

In [[mathematics]], historically '''Wirtinger's inequality''' for real functions was an [[inequality (mathematics)|inequality]] used in [[Fourier analysis]]. It was named after [[Wilhelm Wirtinger]]. It was used in 1904  to prove the [[isoperimetric inequality]].  A variety of closely related results are today known as Wirtinger's inequality.

==Theorem==
===First version===
Let &lt;math&gt;f : \mathbb{R} \to \mathbb{R}&lt;/math&gt; be a [[periodic function]] of period 2π, which is continuous and has a continuous derivative throughout '''R''', and such that

:&lt;math&gt;\int_0^{2\pi}f(x) \, dx = 0.&lt;/math&gt;

Then

:&lt;math&gt;\int_0^{2\pi}f'^2(x) \, dx \ge \int_0^{2\pi}f^2(x) \, dx&lt;/math&gt;

with equality [[if and only if]] ''f''(''x'') = ''a'' sin(''x'') + ''b'' cos(''x'') for some ''a'' and ''b'' (or equivalently ''f''(''x'') = ''c'' sin (''x'' + ''d'') for some ''c'' and ''d'').

This version of the Wirtinger inequality is the one-dimensional [[Poincaré inequality]], with optimal constant.

===Second version===
The following related inequality is also called Wirtinger's inequality {{harv|Dym|McKean|1985}}:

:&lt;math&gt;\pi^{2}\int_0^a |f|^2 \le a^2 \int_0^a|f'|^2&lt;/math&gt;

whenever ''f'' is a C&lt;sup&gt;1&lt;/sup&gt; function such that ''f''(0)&amp;nbsp;=&amp;nbsp;''f''(''a'')&amp;nbsp;=&amp;nbsp;0.  In this form, Wirtinger's inequality is seen as the one-dimensional version of [[Friedrichs' inequality]].

===Proof===
The proof of the two versions are similar.  Here is a proof of the first version of the inequality.  Since [[Dirichlet's conditions]] are met, we can write

:&lt;math&gt;f(x)=\frac{1}{2}a_0+\sum_{n\ge 1}\left(a_n\frac{\sin nx}{\sqrt{\pi}}+b_n\frac{\cos nx}{\sqrt{\pi}}\right),&lt;/math&gt;

and moreover ''a''&lt;sub&gt;0&lt;/sub&gt; = 0 since the integral of ''f'' vanishes. By [[Parseval's identity]],

:&lt;math&gt;\int_0^{2\pi}f^2(x)dx=\sum_{n=1}^\infty(a_n^2+b_n^2)&lt;/math&gt;

and

:&lt;math&gt;\int_0^{2\pi}f'^2(x) \, dx = \sum_{n=1}^\infty n^2(a_n^2+b_n^2)&lt;/math&gt;

and since the summands are all ≥ 0, we get the desired inequality, with equality if and only if ''a&lt;sub&gt;n&lt;/sub&gt;'' = ''b&lt;sub&gt;n&lt;/sub&gt;'' = 0 for all ''n'' ≥ 2.

==References==
*{{citation|first1=H|last1=Dym|authorlink1=Harry Dym|first2=H|last2=McKean|title=Fourier series and integrals|publisher=Academic press|year=1985|isbn=978-0-12-226451-1}}
* [[Paul J. Nahin]] (2006) ''Dr. Euler's Fabulous Formula'', page 183, [[Princeton University Press]] {{ISBN|0-691-11822-1}}

*[[Vadim Komkov|Komkov, Vadim]] (1983) Euler's buckling formula and Wirtinger's inequality. Internat. J. Math. Ed. Sci. Tech. 14, no. 6, 661—668. 

{{PlanetMath attribution|id=5393|title=Wirtinger's inequality}}

[[Category:Fourier analysis]]
[[Category:Inequalities]]
[[Category:Theorems in analysis]]</text>
      <sha1>l5vlay2fm2k389erza9nsb0xmpqkb45</sha1>
    </revision>
  </page>
</mediawiki>
