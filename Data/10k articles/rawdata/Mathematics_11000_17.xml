<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>159 (number)</title>
    <ns>0</ns>
    <id>2885420</id>
    <revision>
      <id>859261301</id>
      <parentid>839482066</parentid>
      <timestamp>2018-09-12T21:21:24Z</timestamp>
      <contributor>
        <username>Timrollpickering</username>
        <id>32005</id>
      </contributor>
      <minor/>
      <comment>/* top */date tag template, replaced: {{examplefarm}} → {{example farm|date=September 2018}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5366">{{example farm|date=September 2018}}
{{Infobox number
| number = 159
| divisor=1, 3, 53, 159
}}

'''159''' ('''one hundred [and] fifty-nine''') is a [[natural number]] following [[158 (number)|158]] and preceding [[160 (number)|160]].

==In mathematics==
'''159''' is:

*the sum of 3 consecutive [[prime number]]s: 47 + 53 + 59.
*a [[Woodall number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A003261|title=Sloane's A003261 : Woodall (or Riesel) numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-28}}&lt;/ref&gt;
*equal to the sum of the squares of the digits of its own square in base 15.&lt;ref&gt;{{Cite web|url=https://oeis.org/A270304|title=Sloane's A270304 : Numbers that equal the sum of the squares of the digits of their own square in base 15|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
:Only 5 numbers (greater than 1) have this property in base 15, none in base 10.
*written CLIX in [[Roman numeral]], which spells a [[Clix (disambiguation)|proper noun with multiple meanings]].

Given 159, the [[Mertens function]] returns 0.&lt;ref&gt;{{Cite web|url=https://oeis.org/A028442|title=Sloane's A028442 : Numbers n such that Mertens' function is zero|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-28}}&lt;/ref&gt;

==In astronomy==
* [[159 Aemilia]] is a large [[Asteroid belt|Main belt]] [[asteroid]]
* [[List of NGC objects (1-999)|NGC]] 159 is a [[galaxy]] in the [[constellation]] of [[Phoenix (constellation)|Phoenix]]
*The [[Saros number|Saros]] number of the [[solar eclipse]] series which will begin on May 23, [[22nd century|2134]] and end June 17, [[4th millennium|3378]]. The duration of Saros series 159 is 1244.0 years, and it will contain 70 solar eclipses
*The Saros number of the [[lunar eclipse]] series, which will begin on September 9, 2147 and end November 7, 3445. The duration of Saros series 159 is 1298.1 years, and it will contain 73 [[lunar eclipse]]s
* [[159P/LONEOS]] is a [[Orbital period|periodic]] [[comet]] in our [[solar system]]

==In geography==
* The state of [[Georgia (U.S. state)|Georgia]] has 159 [[List of counties in Georgia (U.S. state)|counties]]
* [[Sherwood No. 159, Saskatchewan]] is a rural municipality in [[Saskatchewan, Canada]]

==In the military==
* [[Aero L-159 ALCA]] (Advanced Light Combat Aircraft) is a [[Czechoslovakia]]n-built multi-role combat [[aircraft]] in service with the [[Czech Air Force]]
* {{USS|Antrim|AK-159}} was a [[United States Navy]] {{sclass-|Alamosa|cargo ship|1}} during [[World War II]]
* {{USS|Change|AM-159}} was a United States Navy {{sclass-|Admirable|minesweeper|1}} during World War II
* {{USS|Darke|APA-159}} was a United States Navy {{sclass-|Haskell|attack transport|1}} during World War II
* {{USS|Feldspar|IX-159}} was a United States Navy [[concrete barge]] during World War II
* {{USS|General Stuart Heintzelman|AP-159}} was a United States Navy concrete barge following World War II
* {{USS|Laning|DE-159}} was a United States Navy {{sclass-|Buckley|destroyer escort|1}} during World War II
* {{USS|Schenck|DD-159}} was a United States Navy {{sclass-|Wickes|destroyer|1}} during World War II

==In sports==
* In professional [[darts]], 159 is the lowest score a player can achieve with no available checkout.&lt;ref&gt;{{Cite web|url=http://www.dartshop.com.au/pages/peg-out-chart.html|title=Peg Out Chart {{!}} Dart Check Out Chart {{!}} Dart Shop|last=Shop|first=Dart|website=www.dartshop.com.au|access-date=2017-08-01}}&lt;/ref&gt;

==In transportation==
* The [[Alfa Romeo 159]] [[compact executive car]] produced from 2005 to 2011
* The [[Ferrari 159 S]] [[racecar]]
* The [[Peugeot Type 159]] was produced in 1919
*The [[British Rail Class 159]], a member of the [[Sprinter (train)|Sprinter]] family), is a [[diesel multiple unit]], produced from 1989–1993
* [[London Buses route 159]]
* [[TWA Flight 159]], a [[Boeing 707]], while on its takeoff roll from [[Greater Cincinnati Airport]], passed Delta Flight 379, a [[DC-9]] on the runway on November 6, 1967

==In other fields==
'''159''' is also:
* The year [[159|AD 159]] or [[159 BC]]
* 159 AH is a year in the [[Islamic calendar]] that corresponds to 775 &amp;ndash; 776 [[Common Era|CE]]
* The [[atomic number]] of an element temporarily called [http://www.flw.com/datatools/periodic/001.php?id=159 Unpentennium]
* The chemical element [[terbium]] has a stable Isotope of 159 [[neutrons]]
* [[Financial Accounting Standards Board]] (FASB) Number 159, The Fair Value Option for Financial Assets and Financial Liabilities

==See also==
* [[List of highways numbered 159]]
* [[United Nations Security Council Resolution 159]]
* [[List of United States Supreme Court cases, volume 159|United States Supreme Court cases, Volume 159]]

== References ==
{{Reflist}}

==External links==
{{Commons category|159 (number)}}
* [http://athensohio.net/reference/number/159 Number Facts and Trivia: 159]
* [http://www.numdic.com/159 The Number 159]
* [http://www.virtuescience.com/159.html VirtueScience: 159]
* [http://159thdustoff.net 159th Medical Detachment]
* [http://www.urban75.org/brixton/history/routemaster1.html Farewell to Routemaster Bus 159]

{{Integers|1}}

{{DEFAULTSORT:159 (Number)}}
[[Category:Integers]]</text>
      <sha1>1b4iqxjq3rjblpcc96ye88lcz7p4psi</sha1>
    </revision>
  </page>
  <page>
    <title>3G MIMO</title>
    <ns>0</ns>
    <id>13546761</id>
    <revision>
      <id>871304777</id>
      <parentid>861131532</parentid>
      <timestamp>2018-11-30T04:43:11Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 4 sources and tagging 0 as dead. #IABot (v2.0beta10ehf1) ([[User:Hayholt|Hayholt]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13168">{{multiple issues|
{{refimprove|date=May 2012}}
{{prose|date=May 2012}}
{{no footnotes|date=May 2012}}
{{external links|date=May 2012}}
}}
'''3G MIMO''' describes [[MIMO]] techniques which have been considered as [[3G]] standard techniques.
 
'''[[MIMO]]''', as the state of the art of '''Intelligent antenna (IA)''', improves the performance of radio systems by embedding electronics [[intelligence]] into the spatial processing unit. Spatial processing includes spatial precoding at the transmitter and spatial postcoding at the receiver, which are dual each other from information signal processing theoretic point of view. Intelligent antenna is technology which represents [[smart antenna]], [[multiple antenna research|multiple antenna]] ([[Multiple-input multiple-output communications|MIMO]]), self-tracking directional antenna, [[Cooperative wireless communications|cooperative virtual antenna]] and so on.

== Technology ==
Spatial precoding of intelligent antenna includes spatial beamforming and spatial coding. In wireless communications, spatial precoding has been developing for high reliability, high rate and lower interference as shown in the following table.

=== Summary of 3G MIMO ===
The table summarizes the history of 3G MIMO techniques candidated for 3G standards. Although the table additionally contains the future part but the contents are not clearly filled out since the future is not precisely predictable.

{| class="sortable wikitable"
|- bgcolor="#CCCCCC"
! Generation !! 3G !! 3G evolution !! Beyond 3G !! Future
|-
! Deployment || 2003/4 || 2005~6/2007~8/2009~10 || 2012~2015 || 2015~2020
|-
! Standard || WCDMA || HSPA/HSPA+/LTE || IMT-Advanced || Beyond IMT-Adv
|-
! Total rate || 384kbit/s || 14/42/65~250Mbit/s || 1Gbit/s || &gt;10Gbit/s
|-
! Bandwidth || 5&amp;nbsp;MHz || 5&amp;nbsp;MHz/20&amp;nbsp;MHz || 20~100&amp;nbsp;MHz || &gt;100&amp;nbsp;MHz
|-
! Requirement Paradigm
| High reliability (High quality)
| High rate (High capacity)
| Lower interference
| High intelligence
|-
! Method
| Spatial diversity
| Spatial multiplexing
| Spatial cancellation
| Ambient intelligence
|- 
! Spatial coding (SC)
| Spatial diversity coding
| Spatial multiplexing coding
| Spatial cancellation coding
| Ambient intelligence coding
|- 
! Spatial beamforming (SB)
| Single-stream beamforming
| Multi-stream beamforming
| Interference nulling beamforming
| Ambient intelligence beamforming
|- 
! Examples
| SC: Alamouti coding, SB: TxAA
| SC: BLAST coding, SB: SVD 
| SC: DPC, SB: MU-BF
| Such as [[cooperative MIMO]]
|}

=== IA in ad hoc networking ===
{{main|Wireless ad hoc network}}
IA technology enables client terminals, which have either multiple antennas or a self-tracking directional antenna, to communicate to each other with as high as possible signal-to-interference-and-noise ratio (SINR). Assume that there is a source terminal, a destination terminal, and some candidate interference terminals. Compared to conventional approaches, an advanced IA based terminal will perform spatial precoding (spatial beamforming and/or spatial coding) not only to enhance the signal power at the destination terminal but also to diminish the interfering power at interference terminals. As a human does, the advanced IA terminal is given to know that occurring high interference to other terminals will eventually degrade the performance of the associated wireless network.

== Comparisons ==

=== Intelligent antenna (IA) vs. Cognitive radio (CR) ===
However, it requires intelligent multiple or [[cooperation|cooperative]] antenna array. On the contrary, [[cognitive radio]] (CR) allows user terminals to sense the other service usage of spectrum beans to share the spectrum among users, which is so, cognitive spectrum sharing technology. The following table compares the different points between two approach for future wireless systems: Intelligent antenna (IA) vs. Cognitive radio (CR).

{| class="sortable wikitable"
|- bgcolor="#CCCCCC"
! Point !! Intelligence antenna (IA) !! Cognitive radio (CR) 
|-
! Interference processing
| Cancellation by spatial pre/post-coding
| Avoidance by spectrum sensing
|-
! Key cost 
| Multiple or cooperative antenna arrays
| Spectrum sensing and multi-band RF
|- 
! Solution
| Intelligent spatial beamforming/coding tech
| Cognitive spectrum management tech
|- 
! Application
| Ambient Spatial Reuse
| Open Spectrum Sharing
|- 
! Applied theory
| Dirty paper and Wyner-Ziv coding (DP-WZ coding)
| Software radio and cognition
|- 
! Summary
| Intelligent spectrum reuse technology
| Cognitive spectrum sharing technology
|}

=== Fundamental concepts and theories ===
* '''[[Intelligence]]''' is a property of mind that includes many related abilities.
* '''[[Cooperation]]''' is the practice of social elements working in common, instead of working individually.
* '''[[Cognition]]''' can be interpreted as understanding and responding to the world.
* '''[[Ambient intelligence]] (AmI)''' refers to artificial environments that responses to the movement of people, the paradigm of which builds upon [[Ubiquitous computing]].
* '''[[Ubiquitous computing|Wireless ubiquitous computing]] (WUC)''' is post-desktop computing where information processing is integrated into anytime and anywhere human activities.
* '''[[Game theory]]''' is a mathematical theory that studies the strategic interaction between players, which are usually organized into a friend group and an enemy group.

== Principal Issues of Research ==

The following items list the issues of the multiple antenna research aims to improve the performance of radio communications.

* [[Intelligent antenna]]
* [[Smart antenna]]
* [[Multiple-input multiple-output communications|Multiple-input multiple-output (MIMO)]]
* [[Beamforming]]
* [[Diversity combining]]
* [[Diversity scheme]]
* [[Space–time code]]
* [[Spatial multiplexing]]
* [[Space-division multiple access|Space-division multiple access (SDMA)]]
* [[Advanced MIMO communications]]
* [[Multi-user MIMO]]
* [[Precoding]]
* [[Dirty paper coding (DPC)]]
* [[Cooperative wireless communications]]
* [[Cooperative diversity]]

== Principal Definitions ==

=== Definitions ===
Here are the definition of principal keywords to clarify the objective and the operations of intelligent antenna.

{| class="wikitable"
|-
! Terminology
! Definition 
|-
! [[Intelligent antenna]]
| Antenna technology that uses some sort of [[electronic intelligence]] to enhance wireless system performance. Electronic intelligence is implemented by spatial pre/post-coding techniques such as spatial information coding and spatial signal beamforming. Notice that smart antenna has been more widely used to represent the similar meaning. 
|-
! [[Smart antenna]]
| In the narrow sense, antenna technology that employs array antennas with beamforming techniques to enhance wireless system performance. In the wide sense, equivalent terminology to intelligent antenna.
|-
! [[MIMO]] 
| Wide sense and well-known: MIMO is the state of the art of IA and SA.
* Narrow sense: Antenna systems that employ multiple antennas at both the transmitter and the receiver.
|}

=== Reference Web Sites ===
The following items list the web sites related to the multiple antenna research.

* MARS, Bell Laboratories — https://web.archive.org/web/20071001030428/http://mars.bell-labs.com/
** '''Multiple Antenna Research and Solutions (MARS)''' is a research group on multiple antenna and space time coding
* Lucent — http://www.cdg.org/news/events/CDMASeminar/cdg_tech_forum_02/3_lucent_ia_blast_final_release.pdf
** The goal of intelligent antennas is to achieve higher capacity noting that advanced solutions provide higher capacity than basic solutions.
{| class="wikitable"
|-
! Types
! Antenna configuration
! Basic solution 
! Advanced solution 
|-
| Diversity 
| d &gt; wavelength
| Rx: MRC, MMSE, etc., Tx: STTD, CLTD
| BLAST (spatial multiplexing)
|- 
| Phased Array
| d &lt; wavelength
| Switched beams
| Steered beams
|}

* IMEC — https://web.archive.org/web/20071004235801/http://www.imec.be/wireless/mimo/
** '''Multiple antenna systems''' are the key to the high-capacity wireless universe. Indeed, they allow increasing the rate, improving the robustness, or accommodating more users in the cell.
* Georgia Institute of Technology — https://web.archive.org/web/20070627033614/http://users.ece.gatech.edu/~mai/tutorial_sa_def.htm
** '''A smart antenna''' is an array of antenna elements connected to a digital signal processor
* IEC — https://web.archive.org/web/20070928011627/http://www.iec.org/online/tutorials/smart_ant/index.html, https://web.archive.org/web/20070928011846/http://www.iec.org/online/tutorials/acrobat/smart_ant.pdf
** '''A smart antenna system''' combines multiple antenna elements with a signal-processing capability to optimize its radiation and/or reception pattern automatically in response to the signal environment.
** '''Spatial division multiple access (SDMA)''' — Among the most sophisticated utilizations of smart antenna technology is SDMA, which employs advanced processing techniques to, in effect, locate and track fixed or mobile terminals, adaptively steering transmission signals toward users and away from interferers.
* SearchMobileComputing.com — http://searchmobilecomputing.techtarget.com/sDefinition/0,290660,sid40_gci1026138,00.html
** '''A smart antenna''' is a digital wireless communications antenna system that takes advantage of diversity effect at the source (transmitter), the destination (receiver), or both.
** '''MIMO''' is an antenna technology for wireless communications in which multiple antennas are used at both the source (transmitter) and the destination (receiver).
* Smart Antennas Research Group, Stanford Univ. — http://www.stanford.edu/group/sarg/
** Our research goal is to advance the state-of-the-art in the applications of '''multiple antennas and space-time signal processing''' in mobile wireless networks, and to improve network performance and economics.
* CDG — http://www.cdg.org/technology/cdma_technology/smart_antennas/index.asp, http://www.cdmatech.com/products/how_mimo_works.jsp
** '''Smart antennas''' provide greater capacity and performance benefits than standard antennas because they can be used to customize and fine-tune antenna coverage patterns that match the traffic conditions in a wireless network or that are better suited for complex radio frequency (RF) environments.
** '''MIMO''' employs multiple, spatially separated antennas (at both TX and RX) to take advantage of these "virtual wires" and transfer more data.
* Nortel — https://web.archive.org/web/20070526153007/http://www2.nortel.com/go/solution_content.jsp?segId=0&amp;catId=0&amp;parId=0&amp;prod_id=61701
** '''MIMO''' is an antenna technology that is used both in transmission and receiver equipment for wireless radio communication.
** '''MIMO''' is the only advanced antenna technology that simultaneously offers high bandwidth, improved range, and high mobility at a lower cost.
* Visant Strategies — https://web.archive.org/web/20070928045359/http://www.visantstrategies.com/market_research/mimo_intelligent_antenna.html, http://www.researchandmarkets.com/reports/c21454
** '''Intelligent antennas''' are antenna systems that use some sort of computational or electronic resource to enhance system performance.
** According to the amounts of intelligence employed, antenna diversity represents the simplest form in the progressive complexity chain, followed by basic beamforming, which is the process of narrowing radiated energy, which is then followed by the more complex space-time processing and finally by MIMO.
* Magnetic Sciences — https://web.archive.org/web/20071014181902/http://www.magneticsciences.com/SatelliteTrackingUnits.html
** '''Satellite tracking systems and self-steering antennas''' are used aboard ships, vehicles, or aircraft to maintain contact  with satellites.

==See also==
* [[Antenna diversity]]
* [[Smart antenna]]
* [[Multiple antenna research]]
* [[Multiple-input multiple-output communications]]
* [[Cooperative wireless communications]]
* [[Precoding]] includes spatial coding (SC) and spatial beamforming (SB)
** [[Space–time code]]
** [[Spatial multiplexing]]
** [[Dirty paper coding (DPC)]]
** [[Beamforming]]
* [[Wsdma]]
* [[Smart antenna]] for 3G MIMO benefits

==References==
* [http://www.itu-apt.org/prez/ericsson_presentation.pdf Dr. Erik Dahlman, LTE, 3G Long Term Evolution]
* {{cite web |url= http://www.ist-winner.org/WINNER2-Deliverables/D3.4.1.pdf |title= The WINNER II Air Interface: Refined Spatial-Temporal Processing Solutions |date= 30 Nov 2006 |publisher= [[WINNER]] II |access-date= 2008-09-06 |archive-url= https://web.archive.org/web/20090730205247/http://www.ist-winner.org/WINNER2-Deliverables/D3.4.1.pdf |archive-date= 2009-07-30 |dead-url= yes |df=  }}

==External links==
* https://web.archive.org/web/20071007145422/http://www.wireless-world-research.org/fileadmin/sites/default/files/about_the_forum/WG/WG4/Briefings/WWRF-WG4_SmartAntennas_briefing.pdf

{{Mobile telecommunications standards}}

[[Category:IEEE 802]]
[[Category:Information theory]]
[[Category:Radio resource management]]</text>
      <sha1>69r92mninjxiox50qfckff5f4cgih0j</sha1>
    </revision>
  </page>
  <page>
    <title>Annick Horiuchi</title>
    <ns>0</ns>
    <id>57774049</id>
    <revision>
      <id>852140246</id>
      <parentid>847930710</parentid>
      <timestamp>2018-07-26T22:24:52Z</timestamp>
      <contributor>
        <username>Josvebot</username>
        <id>14967932</id>
      </contributor>
      <minor/>
      <comment>/* References */Fixing [[WP:CHECKWIKI]] #16: unicode contol charater (and other minor genral edits caused by AWB), replaced: →</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5737">'''Annick Mito Horiuchi''' is a French [[history of mathematics|historian of mathematics]] and [[history of science|historian of science]]. She is a professor at [[Paris Diderot University]], where she is associated with the Centre de recherche sur les civilisations de l'Asie orientale (CRCAO).{{r|crcao}}

Horiuchi completed a doctorate in 1990; her dissertation, ''Etude de seki takakazu (?-1708) et takebe katahiro (1664-1739), deux mathematiciens de l'epoque d'edo'', was directed by Paul Akamatsu.{{r|theses}}
She was an invited speaker at the 1990 [[International Congress of Mathematicians]].{{r|icm}}

==Books==
Horiuchi's books include:
*''Les mathématiques japonaises à l’époque d’Edo (1600-1868) — une étude des travaux de Seki Takakazu (?-1708) et de Takebe Katahiro (1664-1739)'', Mathesis 1994, translated into English as ''Japanese Mathematics in the Edo Period (1600–1868): A study of the works of Seki Takakazu (?–1708) and Takebe Katahiro (1664–1739)'', Birkhäuser 2010.{{r|edo}}
*''Repenser l'ordre, repenser l'héritage: Paysage intellectuel du Japon (xviie-xixe siècles)'', edited with Frédéric Girard and Mieko Macé, Droz 2002.{{r|rorh}}
*''Traduire, transposer, naturaliser: La formation d’une langue scientifique moderne hors des frontières de l’Europe au XIXe siècle'', edited with Pascal Crozet, l'Harmattan, 2004.{{r|ttn}}
*''Listen, Copy, Read: Popular Learning in Early Modern Japan'', edited with Matthias Hayek, Brill, 2014.{{r|lcr}}

==References==
{{reflist|refs=

&lt;ref name=crcao&gt;{{citation|url=http://www.crcao.fr/spip.php?article150|title=Annick Horiuchi|publisher=CRCAO|accessdate=2018-06-26}}&lt;/ref&gt;

&lt;ref name=edo&gt;
Reviews of ''Les mathématiques japonaises à l'époque d'Edo'':
*{{citation|first=Dénes|last=Nagy|journal=Monumenta Nipponica|volume=50|issue=4|date=Winter 1995|pages=586–590|doi=10.2307/2385608|title=none}}
*{{citation|first=Shôkichi|last=Iyanaga|journal=Ebisu – Études Japonaises|year=1995|volume=9|pages=131–132|language=French|title=Compte-rendu|url=https://www.persee.fr/doc/ebisu_1340-3656_1995_num_9_1_933}}
*{{citation|last = Eberhard | first = Andrea|date = August 1996|doi = 10.1006/hmat.1996.0032|issue = 3|journal = Historia Mathematica|pages = 327–329|title = none|volume = 23}}
*{{citation|first=Karine|last=Chemla|journal=Isis|volume=87|issue=3|date=September 1996|pages=548–549|jstor=236018|title=none}}
*{{citation|first=Catherine|last=Jami|journal=Revue d'histoire des sciences|volume=50|issue=3|date=July–September 1997|page=386|title=none|jstor=23633372|language=French}}
*{{citation|first=Herman|last=Ooms|journal=Chinese Science|volume=14|year=1997|pages=144–147|jstor=43290414|title=none}}
Review of ''Japanese Mathematics in the Edo Period'':
*{{citation|first=Jiří|last=Hudeček|journal=East Asian Science, Technology, and Medicine|volume=37|url=http://www.eastm.org/index.php/journal/article/view/651|year=2013–2014|pages=73–81|title=Review|jstor=43686748}}
&lt;/ref&gt;

&lt;ref name=icm&gt;{{citation|url=https://www.mathunion.org/icm-plenary-and-invited-speakers|title=ICM Plenary and Invited Speakers|publisher=International Mathematical Union|accessdate=2018-06-26}}&lt;/ref&gt;

&lt;ref name=lcr&gt;Reviews of ''Listen, Copy, Read'':
*{{citation|last = Arntzen | first = Sonja|date = June 2015|doi = 10.1017/s1356186315000322|issue = 04|journal = Journal of the Royal Asiatic Society|pages = 743–746|title = none|volume = 25}}
*{{citation|last = Yonemoto | first = Marcia|date = August 2015|doi = 10.1163/22106286-12341281|issue = 2|journal = East Asian Publishing and Society|pages = 228–238|title = none|volume = 5}}
*{{citation|last = Platt | first = Brian|doi = 10.1353/mni.2015.0029|issue = 2|journal = Monumenta Nipponica|pages = 309–314|title = none|volume = 70|year = 2015}}
*{{citation|last = Eubanks | first = Charlotte|doi = 10.1353/jjs.2017.0011|issue = 1|journal = The Journal of Japanese Studies|pages = 148–152|title = none|volume = 43|year = 2017}}
&lt;/ref&gt;

&lt;ref name=rorh&gt;Reviews of ''Repenser l'ordre, repenser l'héritage'':
*{{citation|first=Karine|last=Marandjian|journal=Monumenta Nipponica|volume=58|issue=2|date=Summer 2003|pages=267–268|jstor=25066219|title=none}}
*{{citation|first=Joseph S.|last=O'Leary|journal=Japanese Journal of Religious Studies|volume=31|issue=1|year=2004|pages=213–216|jstor=30233749|title=none}}
*{{citation|last=L'Aminot|first=Tanguy|journal=Dix-Huitième Siècle|year=2003|volume=35|page=570|title=Compte-rendu|language=French|url=https://www.persee.fr/doc/dhs_0070-6760_2003_num_35_1_2577_t1_0570_0000_5}}
*{{citation|title=Review|first=Sonia|last=Engberts|language=French|journal=Social History|volume=37|issue=73|year=2004|url=https://hssh.journals.yorku.ca/index.php/hssh/article/view/4388/3586|pages=117–119}}
&lt;/ref&gt;

&lt;ref name=theses&gt;{{citation|url=http://theses.fr/1990PA070021|title=Etude de seki takakazu (?-1708) et takebe katahiro (1664-1739), deux mathematiciens de l'epoque d'edo|publisher=theses.fr|first=Annick|last=Horiuchi}}&lt;/ref&gt;

&lt;ref name=ttn&gt;
Reviews of ''Traduire, transposer, naturaliser'':
*{{citation|first=Jon|last=Sigurdson|journal=Isis|title=none|volume=96|issue=1|pages=127–128|year=2005|doi=10.1086/433014}}
*{{citation|first=Viatcheslav|last=Vetrov|journal=East Asian Science, Technology, and Medicine|volume=41|year=2015|pages=121–126|jstor=eastasiascietech.41.121|title=none}}
&lt;/ref&gt;

}}

{{Authority control}}

{{DEFAULTSORT:Horiuchi, Annick}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:French historians]]
[[Category:French mathematicians]]
[[Category:Women mathematicians]]
[[Category:Historians of mathematics]]
[[Category:University of Paris Diderot University faculty]]</text>
      <sha1>5e8rq5ouw6g53kltic3fx5pxk7vopkz</sha1>
    </revision>
  </page>
  <page>
    <title>Asset/liability modeling</title>
    <ns>0</ns>
    <id>22852793</id>
    <revision>
      <id>851870583</id>
      <parentid>793672113</parentid>
      <timestamp>2018-07-25T03:34:41Z</timestamp>
      <contributor>
        <username>Darwin Naz</username>
        <id>33688010</id>
      </contributor>
      <comment>new section (Introduction)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8120">{{Multiple issues|
{{tone|date=June 2009}}
{{recentism|date=June 2009}}
{{cleanup|date=June 2009}}
}}
Asset/liability modelling is defined as the process used to manage the business and financial objectives of a [[financial institution]] or an individual through an assessment of the portfolio [[Assets and Liabilities|assets and liabilities]] in an integrated manner.&lt;ref name=":0"&gt;{{Cite news|url=https://financetrainingcourse.com/education/alm/|title=Asset Liability Modeling|work=Finance Training Course|access-date=2018-07-25|language=en-US}}&lt;/ref&gt; The process is characterized by an on-going review, modification, and revision of [[Asset and liability management|asset liability management]] strategies so that sensitivity to interest rate changes are confined within acceptable tolerance levels.&lt;ref name=":0" /&gt; There are different models used and some use different elements, according to specific needs and contexts. For instance, an individual or an organization may keep parts of the ALM process and outsource the modeling function or adapt the model according to the requirements and capabilities of relevant institutions such as banks, which often have their in-house modeling process.&lt;ref&gt;{{Cite news|url=http://hbpanalytics.com/asset-liability-modeling/|title=Asset Liability Modeling - HBP Analytics|work=HBP Analytics|access-date=2018-07-25|language=en-US}}&lt;/ref&gt; For pensioners, asset/liability modeling is all about determining the best allocation for specific situations. There is a vast array of models available today for practical asset and liability modeling and these have been the subject of several research and studies.&lt;ref&gt;{{Cite book|title=Handbook of Asset and Liability Management: Applications and Case Studies|last=Zenios|first=Stavros|last2=Ziemba|first2=William|publisher=Elsevier|year=2007|isbn=9780444528025|location=Amsterdam|pages=xi}}&lt;/ref&gt; 

==Asset/liability modeling (pension)==

The ongoing financial crisis drove the 100 largest corporate [[pension]] plans to a record $300 billion loss of funded status in 2008.&lt;ref&gt;http://hr.cch.com/news/pension/040709.asp&lt;/ref&gt; In the wake of these losses, many pension plan sponsors have been led to re-examine their pension plan asset allocation strategies, to consider the risk exposures to the plans and to the sponsors.  A recent study indicates that many corporate [[defined benefit]] plans fail to address the full range of risks facing them, especially the ones related to liabilities. Too often, the study says, corporate pensions are distracted by concerns that have nothing to do with the long-term health of the fund.&lt;ref&gt;http://www.whymetlife.com/downloads/MetLife_US_PensionRiskBehaviorIndex.pdf&lt;/ref&gt;  Asset/liability modeling is an approach to examining pension risks and allows the sponsor to set informed policies for funding, benefit design, and asset allocation.

Asset/liability modeling goes beyond traditional, asset-only analysis of the asset allocation decision. Traditional asset-only models analyze risk and reward in terms of investment performance. Asset/liability models take a comprehensive approach to analyze risk and reward in terms of the overall pension plan impact. An actuary or investment consultant may look at expectations and [[downside risk]] measures on the present value of contributions, plan surplus, excess returns (asset return less liability return), asset returns, and any number of other variables. The model may consider measures over 5, 10 or 20 year horizons, as well as quarterly or annual [[value at risk]] measures.

Pension plans face a variety of liability risks including price and wage inflation risk, [[interest rate]] risk and longevity risk. While some of these risks materialize slowly over time, others – such as interest rate risk – are felt with each measurement period. Liabilities are the actuarial present value of future plan cash flows, discounted at current interest rates.  Thus, asset/liability management strategies often include [[Bond (finance)|bonds]] and [[Swap (finance)|swaps]] or other [[Derivative (finance)|derivatives]] to accomplish some degree of interest rate hedging (immunization, cash flow matching, duration matching, etc.). Such approaches are sometimes called [[liability driven investment|“liability-driven investment” (LDI)]] strategies. In 2008, plans with such approaches strongly outperformed those with traditional “total return” seeking investment policies.&lt;ref&gt;http://www.cfo.com/article.cfm/13052428&lt;/ref&gt;

==Asset/liability studies==

Successful asset/liability studies:
Increase a plan sponsor’s understanding of the pension plan’s current situation and likely future trends
* Highlight key asset and liability risks that should be considered
* Help establish a cohesive risk management framework
* Analyze surplus return, standard deviation, funded status, contribution requirements and balance sheet impacts
* Consider customized risk measures based on the plan sponsor, plan design and time horizon
* Help design an appropriate strategic investment strategy
* Provide insight into current market dislocations and practical implications for the near term

Historically, most pension plan sponsors conducted comprehensive asset/liability studies every three to five years or after a significant change in demographics, plan design, funded status, sponsor circumstances, or funding legislation. Recent trends suggest more frequent studies, and/or a desire for regular tracking of key asset/liability risk metrics in between formal studies.

==Additional challenges==

In the United States, the [[Pension Protection Act]] of 2006 (PPA) has introduced stricter standards on pension plans, requiring higher funding targets and larger contributions from plan sponsors. With growing deficits and PPA funding requirements looming large, there is an unprecedented need for asset/liability modeling and overall pension risk management.

==Asset/liability modeling for individuals==

Some financial advisors offer [[Monte Carlo simulation]] tools aimed at helping individuals model the odds they will be able to retire when they want with the amount of money they want. These tools are designed to model the individual’s likelihood of assets surpassing expenses (liabilities).

Proponents of Monte Carlo simulation contend that these tools are valuable because they offer simulation using randomly ordered returns based on a set of reasonable parameters. For example, the tool can model retirement cash flows 500 or 1,000 times, thus reflecting a range of possible outcomes.&lt;ref&gt;http://www.nysscpa.org/cpajournal/2005/905/perspectives/p12.htm&lt;/ref&gt;

Some critics of these tools claim that the consequences of failure are not laid out and argue that these tools are no better than typical retirement tools that use standard assumptions. Recent financial turmoil has fueled the claims of critics who believe that Monte Carlo simulation tools are inaccurate and overly optimistic.&lt;ref&gt;https://www.wsj.com/articles/SB124121875397178921&lt;/ref&gt;

==External links==
* [http://www.soa.org/library/newsletters/risks-and-rewards/2008/february/rar-2008-iss51-wouters.pdf  Implementing Asset/Liability Management - A User’s Guide to ALM, LDI and Other Three-Letter Words], Society of Actuaries
* [http://www.soa.org/library/research/actuarial-research-clearing-house/2000-09/2002/arch-1/arch02v36-5.pdf  Application of a Linear Regression Model to the Proactive Investment Strategy of a Pension Fund], Society of Actuaries
* [https://archive.is/20091010211036/http://www.jpmorgan.com/cbs/insight/retirement_plans/Beyond_Rebalancing_June_2009  Beyond Rebalancing: Rethinking long-term asset allocation], J.P. Morgan [PAGE NOT FOUND]
* [http://www.whymetlife.com/downloads/MetLife_US_PensionRiskBehaviorIndex.pdf  MetLife U.S. Pension Behavior IndexSM], MetLife

==References==
{{Reflist}}

{{DEFAULTSORT:Asset liability modeling}}
[[Category:Actuarial science]]
[[Category:Pensions]]
[[Category:Investment]]
[[Category:Liability (financial accounting)]]
[[Category:Retirement|Plan]]
[[Category:Personal finance]]
[[Category:Asset]]</text>
      <sha1>tjyo6e4wobdy37r4dz8xg451gfuvdku</sha1>
    </revision>
  </page>
  <page>
    <title>Backtesting</title>
    <ns>0</ns>
    <id>10283346</id>
    <revision>
      <id>852955999</id>
      <parentid>852955936</parentid>
      <timestamp>2018-08-01T13:39:43Z</timestamp>
      <contributor>
        <username>LordOfPens</username>
        <id>3914242</id>
      </contributor>
      <minor/>
      <comment>/* Hindcast  */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6593">'''Backtesting''' is a term used in modeling to refer to testing a [[predictive modelling|predictive model]] on historical data.  Backtesting is a type of [[retrodiction]], and a special type of [[Cross-validation (statistics)|cross-validation]] applied to previous time period(s).

== Financial analysis==
In a trading strategy, investment strategy, or risk modeling, backtesting seeks to estimate the performance of a strategy or model if it had been employed during a past period. This requires simulating past conditions with sufficient detail, making one limitation of backtesting the need for detailed historical data.  A second limitation is the inability to model strategies that would affect historic prices. Finally, backtesting, like other modeling, is limited by potential [[overfitting]]. That is, it is often possible to find a strategy that would have worked well in the past, but will not work well in the future.&lt;ref&gt;{{cite web|title=Does Backtesting Really Work?|url=http://www.backtestbroker.com/backtestingfaq.aspx|author=BacktestBroker}}&lt;/ref&gt; Despite these limitations, backtesting provides information not available when models and strategies are tested on synthetic data.

Backtesting has historically only been performed by large institutions and professional money managers due to the expense of obtaining and using detailed datasets. However, backtrading is increasingly used on a wider basis, and independent web-based backtesting platforms have emerged. Although the technique is widely used, it is prone to weaknesses.&lt;ref&gt;{{cite web|title=Issues related to back testing|url=http://www.financialtrading.com/issues-related-to-back-testing/|author=FinancialTrading}}&lt;/ref&gt; [[Basel Accords|Basel financial regulations]] require large financial institutions to backtest certain risk models.

== Hindcast &lt;!--[[Hindcast]] redirects here --&gt; ==
[[File:Hindcasting.jpeg|200px|thumb|right|Temporal representation of hindcasting.&lt;ref&gt;Taken from p.145 of [https://ia601502.us.archive.org/17/items/TECA2004/TECA-%282004%29.pdf Yeates, L.B., ''Thought Experimentation: A Cognitive Approach'',  Graduate Diploma in Arts (By Research) dissertation, University of New South Wales, 2004.]&lt;/ref&gt;]]

In [[oceanography]]&lt;ref&gt;{{cite web|title= Hindcast approach|url= http://www.oceanweather.com/research/HindcastApproach.html|publisher= OceanWeather Inc.|accessdate= 22 January 2013}}&lt;/ref&gt; and [[meteorology]],&lt;ref&gt;{{cite journal|last= Huijnen|first= V. |author2= J. Flemming |author3= J. W. Kaiser |author4= A. Inness |author5= J. Leitão |author6= A. Heil |author7= H. J. Eskes |author8= M. G. Schultz |author9= A. Benedetti |author10= J. Hadji-Lazaro |author11= G. Dufour |author12= M. Eremenko|title= Hindcast experiments of tropospheric composition during the summer 2010 fires over western Russia|journal= Atmos. Chem. Phys.|year= 2012|volume= 12|pages= 4341–4364|url= http://www.atmos-chem-phys.net/12/4341/2012/acp-12-4341-2012.html|accessdate= 22 January 2013|doi= 10.5194/acp-12-4341-2012}}&lt;/ref&gt; ''backtesting'' is also known as ''hindcasting'': a '''hindcast''' is a way of testing a [[mathematical model]]; researchers enter known or closely estimated inputs for past events into the model to see how well the output matches the known results.

Hindcasting usually refers to a [[computer simulation|numerical-model]] integration of a historical period where no observations have been [[data assimilation|assimilated]]. This distinguishes a hindcast run from a [[meteorological reanalysis|reanalysis]]. Oceanographic observations of [[salinity]] and [[temperature]] as well as observations of [[ocean surface wave|surface-wave parameters]] such as the [[significant wave height]] are much scarcer than meteorological observations, making hindcasting more common in oceanography than in meteorology. Also, since surface waves represent a forced system where the wind is the only generating force, [[wind wave model|wave hindcasting]] is often considered adequate for generating a reasonable representation of the wave [[climate]] with little need for a full reanalysis. Hydrologists use hindcasting for model stream flows.&lt;ref&gt;{{cite web|title= Guidance on Conducting  Streamflow Hindcasting in  CHPS|url= http://www.nws.noaa.gov/om/water/RFC_support/HEFS_doc/Streamflow_Hindcasting_Guidance_V3.pdf|publisher= NOAA|accessdate= 22 January 2013}}&lt;/ref&gt;

An example of hindcasting would be entering [[climate]] forcings (events that force change) into a [[climate model]]. If the hindcast showed reasonably-accurate climate response, the model would be considered successful.

The [[ECMWF re-analysis]] is an example of a combined atmospheric reanalysis coupled with a wave-model integration where no wave parameters were assimilated, making the wave part a hindcast run.

In 2003, Dake Chen and his colleagues “trained” a computer using the data of the surface temperature of the oceans from the last 20 years.&lt;ref&gt;Chen, D., Cane, M.A., Kaplan, A., Zebiak, S.E. &amp; Huang, D., "Predictability of El Niño Over the Past 148 Years", ''Nature'', Vol.428, No.6984, (15 April 2004), pp.733-736; Anderson, D., "Testing Time for El Niño", ''Nature'', Vol.428, No.6984, (15 April 2004), pp.709, 711.&lt;/ref&gt; Then, using data that had been collected on the surface temperature of the oceans for the period 1857 to 2003, they went through a hindcasting exercise and discovered that their simulation not only accurately predicted every [[El Niño]] event for the last 148 years, it also identified the (up to 2 years) looming foreshadow of every single one of those El Niño events.&lt;ref&gt;
Not only did hindcasting demonstrate that the computerized simulation models could predict the onset of El Niño climatic events from changes in the temperature of the ocean's surface temperature that occur up to two years earlier — meaning that there was now, potentially, at least 2 years' lead time — but the results also implied that El Niño events seemed to be the effects of some causal regularity; and, therefore, were not due to simple chance, or to some other "chaotic" event.
&lt;/ref&gt;

==See also==
{{Div col}}
* [[Algorithmic trading]]
* [[Black box|Black box model]]
* [[Climate]]
* [[ECMWF re-analysis]]
* [[Forecasting]]
* [[NCEP/NCAR reanalysis|NCEP re-analysis]]
* [[Program trading]]
* [[Retrodiction]]
* [[Statistical arbitrage]]
* [[Thought Experiment]]
{{Div col end}}

==References==
{{reflist}}

[[Category:Tests]]
[[Category:Technical analysis]]
[[Category:Mathematical modeling]]
[[Category:Numerical climate and weather models]]
[[Category:Statistical forecasting]]</text>
      <sha1>76mex0xah0q73n88hi300ouew9b9z9k</sha1>
    </revision>
  </page>
  <page>
    <title>Cardinality of the continuum</title>
    <ns>0</ns>
    <id>1574901</id>
    <revision>
      <id>861084830</id>
      <parentid>861084410</parentid>
      <timestamp>2018-09-25T00:27:36Z</timestamp>
      <contributor>
        <username>Hairy Dude</username>
        <id>274535</id>
      </contributor>
      <comment>/* Sets with cardinality of the continuum */don't mix list types</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14871">In [[set theory]], the '''cardinality of the continuum''' is the [[cardinality]] or "size" of the [[Set (mathematics)|set]] of [[real numbers]] &lt;math&gt;\mathbb R&lt;/math&gt;, sometimes called the [[Continuum (set theory)|continuum]]. It is an [[Infinite set|infinite]] [[cardinal number]] and is denoted by &lt;math&gt;|\mathbb R|&lt;/math&gt; or &lt;math&gt;\mathfrak c&lt;/math&gt; (a lowercase [[fraktur (script)|fraktur script]] "c").

The real numbers &lt;math&gt;\mathbb R&lt;/math&gt; are more numerous than the [[natural numbers]] &lt;math&gt;\mathbb N&lt;/math&gt;. Moreover, &lt;math&gt;\mathbb R&lt;/math&gt; has the same number of elements as the [[power set]] of &lt;math&gt;\mathbb N&lt;/math&gt;. Symbolically, if the cardinality of &lt;math&gt;\mathbb N&lt;/math&gt; is denoted as [[aleph number#Aleph-naught|&lt;math&gt;\aleph_0&lt;/math&gt;]], the cardinality of the continuum is
{{block indent|&lt;math&gt;\mathfrak c = 2^{\aleph_0} &gt; \aleph_0 \,. &lt;/math&gt;}}
This was proven by [[Georg Cantor]] in his [[Cantor's first uncountability proof|1874 uncountability proof]], part of his groundbreaking study of different infinities; the inequality was later stated more simply in his [[Cantor's diagonal argument|diagonal argument]]. Cantor defined cardinality in terms of [[bijective function]]s: two sets have the same cardinality if and only if there exists a bijective function between them.

Between any two real numbers ''a''&amp;nbsp;&lt;&amp;nbsp;''b'', no matter how close they are to each other, there are always infinitely many other real numbers, and Cantor showed that they are as many as those contained in the whole set of real numbers. In other words, the [[open interval]] (''a'',''b'') is [[equinumerous]] with &lt;math&gt;\mathbb R.&lt;/math&gt; This is also true for several other infinite sets, such as any ''n''-dimensional [[Euclidean space]] &lt;math&gt;\mathbb R^n&lt;/math&gt; (see [[space filling curve]]). That is,
{{block indent|&lt;math&gt;|(a,b)| = |\mathbb R| = |\mathbb R^n|.&lt;/math&gt;}}

The smallest infinite cardinal number is &lt;math&gt;\aleph_0&lt;/math&gt; ([[aleph number#Aleph-naught|aleph-null]]). The second smallest is &lt;math&gt;\aleph_1&lt;/math&gt; ([[aleph number#Aleph-one|aleph-one]]). The [[continuum hypothesis]], which asserts that there are no sets whose cardinality is strictly between &lt;math&gt;\aleph_0&lt;/math&gt; and {{nowrap|&lt;math&gt;\mathfrak c&lt;/math&gt;,}} implies that &lt;math&gt;\mathfrak c = \aleph_1&lt;/math&gt;.

==Properties==

===Uncountability===
[[Georg Cantor]] introduced the concept of [[cardinality]] to compare the sizes of infinite sets. He famously showed that the set of real numbers is [[uncountably infinite]]; i.e. &lt;math&gt;{\mathfrak c}&lt;/math&gt; is strictly greater than the cardinality of the [[natural numbers]], &lt;math&gt;\aleph_0&lt;/math&gt;:
{{block indent|&lt;math&gt;\aleph_0 &lt; \mathfrak c.&lt;/math&gt;}}
In other words, there are strictly more real numbers than there are integers. Cantor proved this statement in several different ways. See [[Cantor's first uncountability proof]] and [[Cantor's diagonal argument]].

===Cardinal equalities===
A variation on Cantor's diagonal argument can be used to prove [[Cantor's theorem]] which states that the cardinality of any set is strictly less than that of its [[power set]], i.e. &lt;math&gt;|A| &lt; 2^{|A|}&lt;/math&gt;, and so the power set &lt;math&gt;\wp(\mathbb N)&lt;/math&gt; of the [[natural number]]s &lt;math&gt;\mathbb N&lt;/math&gt; is uncountable. In fact, it can be shown{{citation_needed|date=September 2017}} that the cardinality of &lt;math&gt;\wp(\mathbb N)&lt;/math&gt; is equal to &lt;math&gt;{\mathfrak c}&lt;/math&gt;:
#Define a map &lt;math&gt;f:\mathbb R\to\wp(\mathbb Q)&lt;/math&gt; from the reals to the power set of the [[rationals]], &lt;math&gt;\mathbb Q&lt;/math&gt; by sending each real number &lt;math&gt;x&lt;/math&gt; to the set &lt;math&gt;\{q \in \mathbb{Q}: q \leq x\}&lt;/math&gt; of all rationals less than or equal to &lt;math&gt;x&lt;/math&gt; (with the reals viewed as [[Dedekind cut]]s, this is nothing other than the [[inclusion map]] in the set of sets of rationals). This map is [[Injective function|injective]] since the rationals are [[Dense set|dense]] in '''R'''. Since the rationals are countable we have that &lt;math&gt;\mathfrak c \le 2^{\aleph_0}&lt;/math&gt;.
#Let &lt;math&gt;\{0,2\}^{\mathbb N}&lt;/math&gt; be the set of infinite [[sequence]]s with values in set &lt;math&gt;\{0,2\}&lt;/math&gt;. This set has cardinality &lt;math&gt;2^{\aleph_0}&lt;/math&gt; (the natural [[bijection]] between the set of binary sequences and &lt;math&gt;\wp(\mathbb N)&lt;/math&gt; is given by the [[indicator function]]). Now associate to each such sequence &lt;math&gt;(a_i)_{i\in\mathbb N}&lt;/math&gt; the unique real number in the [[unit interval|interval]] &lt;math&gt;[0,1]&lt;/math&gt; with the [[Ternary numeral system|ternary]]-expansion given by the digits &lt;math&gt;a_1,a_2,\dotsc&lt;/math&gt;, i.e., &lt;math&gt;\sum_{i=1}^\infty a_i3^{-i}&lt;/math&gt;, the &lt;math&gt;i&lt;/math&gt;-th digit after the fractional point is &lt;math&gt;a_i&lt;/math&gt; with respect to base &lt;math&gt;3&lt;/math&gt;. The image of this map is called the [[Cantor set]]. It is not hard to see that this map is injective, for by avoiding points with the digit 1 in their ternary expansion we avoid conflicts created by the fact that the ternary-expansion of a real number is not unique. We then have that &lt;math&gt;2^{\aleph_0} \le \mathfrak c&lt;/math&gt;.
By the [[Cantor–Bernstein–Schroeder theorem]] we conclude that
{{block indent|&lt;math&gt;\mathfrak c = |\wp(\mathbb{N})| = 2^{\aleph_0}.&lt;/math&gt;}}

The cardinal equality &lt;math&gt;\mathfrak{c}^2 = \mathfrak{c}&lt;/math&gt; can be demonstrated using [[cardinal arithmetic]]:
{{block indent|&lt;math&gt;\mathfrak{c}^2 = (2^{\aleph_0})^2 = 2^{2\times{\aleph_0}} = 2^{\aleph_0} = \mathfrak{c}.&lt;/math&gt;}}

By using the rules of cardinal arithmetic one can also show that
{{block indent|&lt;math&gt;\mathfrak c^{\aleph_0} = {\aleph_0}^{\aleph_0} = n^{\aleph_0} = \mathfrak c^n = \aleph_0 \mathfrak c = n \mathfrak c = \mathfrak c,&lt;/math&gt;}}
where ''n'' is any finite cardinal ≥ 2, and
{{block indent|&lt;math&gt; \mathfrak c ^{\mathfrak c}  =  (2^{\aleph_0})^{\mathfrak c}  = 2^{\mathfrak c\times\aleph_0} = 2^{\mathfrak c},&lt;/math&gt;}}
where &lt;math&gt;2 ^{\mathfrak c}&lt;/math&gt; is the cardinality of the power set of '''R''', and &lt;math&gt;2 ^{\mathfrak c} &gt; \mathfrak c &lt;/math&gt;.

===Alternative explanation for &lt;math&gt;{\mathfrak c} = 2^{\aleph_0}&lt;/math&gt;===
Every real number has at least one infinite [[decimal expansion]].  For example,
{{block indent|1=1/2 = 0.50000...}}
{{block indent|1=1/3 = 0.33333...}}
{{block indent|1=π = 3.14159....}}
(This is true even when the expansion repeats as in the first two examples.)
In any given case, the number of digits is [[countable set|countable]] since they can be put into a [[one-to-one correspondence]] with the set of natural numbers &lt;math&gt;\mathbb{N}&lt;/math&gt;. This fact makes it sensible to talk about (for example) the first, the one-hundredth, or the millionth digit of π. Since the natural numbers have cardinality &lt;math&gt;\aleph_0,&lt;/math&gt; each real number has &lt;math&gt;\aleph_0&lt;/math&gt; digits in its expansion.

Since each real number can be broken into an integer part and a decimal fraction, we get
{{block indent|&lt;math&gt;{\mathfrak c} \leq \aleph_0 \cdot 10^{\aleph_0} \leq 2^{\aleph_0} \cdot {(2^4)}^{\aleph_0} = 2^{\aleph_0 + 4 \cdot \aleph_0} = 2^{\aleph_0} &lt;/math&gt;}}

since
{{block indent|&lt;math&gt;\aleph_0 + 4 \cdot \aleph_0 = \aleph_0 \,.&lt;/math&gt;}}

On the other hand, if we map &lt;math&gt;2 = \{0, 1\}&lt;/math&gt; to &lt;math&gt;\{3, 7\}&lt;/math&gt; and consider that decimal fractions containing only 3 or 7 are only a part of the real numbers, then we get
{{block indent|&lt;math&gt;2^{\aleph_0} \leq {\mathfrak c} \,.&lt;/math&gt;}}

and thus
{{block indent|&lt;math&gt;{\mathfrak c} = 2^{\aleph_0} \,.&lt;/math&gt;}}

==Beth numbers==
{{main|Beth number}}
The sequence of beth numbers is defined by setting &lt;math&gt;\beth_0 = \aleph_0&lt;/math&gt; and &lt;math&gt;\beth_{k+1} = 2^{\beth_k}&lt;/math&gt;. So &lt;math&gt;{\mathfrak c}&lt;/math&gt; is the second beth number, '''beth-one''':
{{block indent|&lt;math&gt;\mathfrak c = \beth_1.&lt;/math&gt;}}
The third beth number, '''beth-two''', is the cardinality of the power set of '''R''' (i.e. the set of all subsets of the [[real line]]):
{{block indent|&lt;math&gt;2^\mathfrak c = \beth_2.&lt;/math&gt;}}

==The continuum hypothesis==
{{main|Continuum hypothesis}}

The famous continuum hypothesis asserts that &lt;math&gt;{\mathfrak c}&lt;/math&gt; is also the second [[aleph number]]  &lt;math&gt;\aleph_1&lt;/math&gt;. In other words, the continuum hypothesis states that there is no set &lt;math&gt;A&lt;/math&gt; whose cardinality lies strictly between &lt;math&gt;\aleph_0&lt;/math&gt; and &lt;math&gt;{\mathfrak c}&lt;/math&gt;
{{block indent|&lt;math&gt;\nexists A \quad:\quad \aleph_0 &lt; |A| &lt; \mathfrak c.&lt;/math&gt;}}
This statement is now known to be independent of the axioms of [[Zermelo–Fraenkel set theory]] with the axiom of choice (ZFC). That is, both the hypothesis and its negation are consistent with these axioms. In fact, for every nonzero [[natural number]] ''n'', the equality &lt;math&gt;{\mathfrak c}&lt;/math&gt; = &lt;math&gt;\aleph_n&lt;/math&gt; is independent of ZFC (the case &lt;math&gt;n=1&lt;/math&gt; is the continuum hypothesis). The same is true for most other alephs, although in some cases equality can be ruled out by [[König's theorem (set theory)|König's theorem]] on the grounds of [[cofinality]], e.g.,  &lt;math&gt;\mathfrak{c}\neq\aleph_\omega.&lt;/math&gt; In particular,  &lt;math&gt;\mathfrak{c}&lt;/math&gt; could be either &lt;math&gt;\aleph_1&lt;/math&gt; or  &lt;math&gt;\aleph_{\omega_1}&lt;/math&gt;, where &lt;math&gt;\omega_1&lt;/math&gt; is the [[first uncountable ordinal]], so it could be either a [[successor cardinal]] or a [[limit cardinal]], and either a [[regular cardinal]] or a [[singular cardinal]].

==Sets with cardinality of the continuum==

A great many sets studied in mathematics have cardinality equal to &lt;math&gt;{\mathfrak c}&lt;/math&gt;. Some common examples are the following:

{{unordered list
|the [[real number]]s &lt;math&gt;\mathbb{R}&lt;/math&gt;
|any ([[Degeneracy (mathematics)|nondegenerate]]) closed or open [[Interval (mathematics)|interval]] in &lt;math&gt;\mathbb{R}&lt;/math&gt; (such as the [[unit interval]] &lt;math&gt;[0,1]&lt;/math&gt;)

For instance, for all &lt;math&gt;a,b \in \mathbb{R}&lt;/math&gt; such that &lt;math&gt;a &lt; b&lt;/math&gt; we can define the bijection
{{block indent|&lt;math&gt;\begin{align}
 f\colon \mathbb{R} &amp;\to (a,b)\\
 x &amp;\mapsto \frac{\arctan x + \frac{\pi}{2}}{\pi}\cdot(b - a) + a
\end{align}&lt;/math&gt;}}
Now we show the cardinality of an infinite interval. For all &lt;math&gt;a \in \mathbb{R}&lt;/math&gt; we can define the bijection
{{block indent|&lt;math&gt;\begin{align}
 f\colon \mathbb{R} &amp;\to (a,\infty)\\
 x &amp;\mapsto \begin{cases}
\arctan x + \frac{\pi}{2} + a &amp; \mbox{if } x &lt; 0 \\
x + \frac{\pi}{2} + a &amp; \mbox{if } x \ge 0
\end{cases}
\end{align}&lt;/math&gt;}}
and similarly for all &lt;math&gt;b \in \mathbb{R}&lt;/math&gt;
{{block indent|&lt;math&gt;\begin{align}
 f\colon \mathbb{R} &amp;\to (-\infty,b)\\
 x &amp;\mapsto \begin{cases}
x - \frac{\pi}{2} + b &amp; \mbox{if } x &lt; 0 \\
\arctan x - \frac{\pi}{2} + b &amp; \mbox{if } x \ge 0
\end{cases}
\end{align}&lt;/math&gt;}}
|the [[irrational number]]s
|the [[transcendental numbers]]

We note that the set of real [[algebraic number]]s is countably infinite (assign to each formula its [[Gödel numbering|Gödel number]].) So the cardinality of the real algebraic numbers is &lt;math&gt;\aleph_0&lt;/math&gt;. Furthermore, the real algebraic numbers and the real transcendental numbers are disjoint sets whose union is &lt;math&gt;\mathbb R&lt;/math&gt;. Thus, since the cardinality of &lt;math&gt;\mathbb R&lt;/math&gt; is &lt;math&gt;\mathfrak c&lt;/math&gt;, the cardinality of the real transcendental numbers is &lt;math&gt;\mathfrak c - \aleph_0 = \mathfrak c&lt;/math&gt;. A similar result follows for complex transcendental numbers, once we have proved that  &lt;math&gt;\left\vert \mathbb{C} \right\vert = \mathfrak c&lt;/math&gt;.
|the [[Cantor set]]
|[[Euclidean space]] &lt;math&gt;\mathbb{R}^n&lt;/math&gt;&lt;ref name=Gouvea&gt;[http://www.maa.org/sites/default/files/pdf/pubs/AMM-March11_Cantor.pdf Was Cantor Surprised?], [[Fernando Q. Gouvêa]], ''[[American Mathematical Monthly]]'', March 2011.&lt;/ref&gt;
|the [[complex number]]s &lt;math&gt;\mathbb{C}&lt;/math&gt;

We note that, per Cantor's proof of the cardinality of Euclidean space,&lt;ref name=Gouvea /&gt; &lt;math&gt;\left\vert \mathbb{R}^2 \right\vert = \mathfrak c&lt;/math&gt;. By definition, any &lt;math&gt;c\in \mathbb{C}&lt;/math&gt; can be uniquely expressed as &lt;math&gt;a + bi&lt;/math&gt; for some &lt;math&gt;a,b \in \mathbb{R}&lt;/math&gt;. We therefore define the bijection
{{block indent|&lt;math&gt;\begin{align}
 f\colon \mathbb{R}^2 &amp;\to \mathbb{C}\\
 (a,b) &amp;\mapsto a+bi
\end{align}&lt;/math&gt;}}
|the [[power set]] of the [[natural number]]s &lt;math&gt;\mathcal{P}(\mathbb{N})&lt;/math&gt; (the set of all subsets of the natural numbers)
|the set of [[sequences]] of integers (i.e. all functions &lt;math&gt;\mathbb{N} \rightarrow \mathbb{Z}&lt;/math&gt;, often denoted &lt;math&gt;\mathbb{Z}^\mathbb{N}&lt;/math&gt;)
|the set of sequences of real numbers, &lt;math&gt;\mathbb{R}^\mathbb{N}&lt;/math&gt;
|the set of all [[continuous function|continuous]] functions from &lt;math&gt;\mathbb{R}&lt;/math&gt; to &lt;math&gt;\mathbb{R}&lt;/math&gt;
|the [[Euclidean topology]] on &lt;math&gt;\mathbb{R}^n&lt;/math&gt; (i.e. the set of all [[open set]]s in &lt;math&gt;\mathbb{R}^n&lt;/math&gt;)
|the [[Borel algebra|Borel σ-algebra]] on &lt;math&gt;\mathbb{R}&lt;/math&gt; (i.e. the set of all [[Borel set]]s in &lt;math&gt;\mathbb{R}&lt;/math&gt;).
}}

==Sets with greater cardinality==

Sets with cardinality greater than &lt;math&gt;{\mathfrak c}&lt;/math&gt; include:

*the set of all subsets of &lt;math&gt;\mathbb{R}&lt;/math&gt; (i.e., power set &lt;math&gt;\mathcal{P}(\mathbb{R})&lt;/math&gt;)
*the set [[Power set#Representing subsets as functions|2&lt;sup&gt;'''R'''&lt;/sup&gt;]] of [[indicator function]]s defined on subsets of the reals (the set &lt;math&gt;2^{\mathbb{R}}&lt;/math&gt; is [[isomorphic]] to &lt;math&gt;\mathcal{P}(\mathbb{R})&lt;/math&gt;&amp;nbsp;– the indicator function chooses elements of each subset to include)
*the set &lt;math&gt;\mathbb{R}^\mathbb{R}&lt;/math&gt; of all functions from &lt;math&gt;\mathbb{R}&lt;/math&gt; to &lt;math&gt;\mathbb{R}&lt;/math&gt;
*the [[Lebesgue measure|Lebesgue σ-algebra]] of &lt;math&gt;\mathbb{R}&lt;/math&gt;, i.e., the set of all [[Lebesgue measurable]] sets in &lt;math&gt;\mathbb{R}&lt;/math&gt;.
*the set of all [[Lebesgue integration|Lebesgue-integrable]] functions from &lt;math&gt;\mathbb{R}&lt;/math&gt; to &lt;math&gt;\mathbb{R}&lt;/math&gt;
*the set of all [[Measurable function|Lebesgue-measurable]] functions from &lt;math&gt;\mathbb{R}&lt;/math&gt; to &lt;math&gt;\mathbb{R}&lt;/math&gt;
*the [[Stone–Čech compactification]]s of &lt;math&gt;\mathbb{N}&lt;/math&gt;, &lt;math&gt;\mathbb{Q}&lt;/math&gt; and &lt;math&gt;\mathbb{R}&lt;/math&gt;
*the set of all automorphisms of the (discrete) field of complex numbers.

These all have cardinality &lt;math&gt;2^\mathfrak c = \beth_2&lt;/math&gt; ([[Beth number#Beth two|beth two]]).

==References==
&lt;references/&gt;
*[[Paul Halmos]], ''Naive set theory''. Princeton, NJ: D. Van Nostrand Company, 1960. Reprinted by Springer-Verlag, New York, 1974. {{ISBN|0-387-90092-6}} (Springer-Verlag edition).
*[[Thomas Jech|Jech, Thomas]], 2003. ''Set Theory: The Third Millennium Edition, Revised and Expanded''.  Springer.  {{ISBN|3-540-44085-2}}.
*[[Kenneth Kunen|Kunen, Kenneth]], 1980. ''[[Set Theory: An Introduction to Independence Proofs]]''. Elsevier.  {{ISBN|0-444-86839-9}}.

{{PlanetMath attribution|urlname=CardinalityOfTheContinuum|title=cardinality of the continuum}}

[[Category:Cardinal numbers]]
[[Category:Set theory]]
[[Category:Infinity]]</text>
      <sha1>7ujo6dyfoiwaeuao2yvekq4lx1t2rbb</sha1>
    </revision>
  </page>
  <page>
    <title>Codress message</title>
    <ns>0</ns>
    <id>1062532</id>
    <revision>
      <id>649140484</id>
      <parentid>601673840</parentid>
      <timestamp>2015-02-27T21:34:09Z</timestamp>
      <contributor>
        <username>Vrac</username>
        <id>3095329</id>
      </contributor>
      <comment>rmv orphan tag</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="258">{{unreferenced|date=April 2010}}

In military [[cryptography]], a '''codress message''' is an [[encryption|encrypted]] message whose address is also encrypted. This is usually done to prevent [[traffic analysis]].

[[Category:Cryptography]]


{{crypto-stub}}</text>
      <sha1>dmv2n6y558gyz30trwbdpembkl6uhej</sha1>
    </revision>
  </page>
  <page>
    <title>Convex lattice polytope</title>
    <ns>0</ns>
    <id>11502578</id>
    <revision>
      <id>850571917</id>
      <parentid>829109069</parentid>
      <timestamp>2018-07-16T17:59:00Z</timestamp>
      <contributor>
        <username>Watchduck</username>
        <id>5530646</id>
      </contributor>
      <comment>add table with four (semi-)regular polyheda as examples</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2775">{| class="wikitable" align="right"
| [[File:Polyhedron 6.png|120px]]
| [[File:Polyhedron 6-8.png|120px]]
| [[File:Polyhedron 8.png|120px]]
| [[File:Polyhedron truncated 8.png|120px]]
|-
| [[File:3D chess moves 111.png|120px]]
| [[File:3D chess moves 011.png|120px]]
| [[File:3D chess moves 001.png|120px]]
| [[File:3D chess moves 012.png|120px]]
|-
| [[Cube]]
| [[Cuboctahedron]]
| [[Octahedron]]
| [[Truncated octahedron|Truncated&lt;br&gt;octahedron]]
|-
| (±1, ±1, ±1)
| (0, ±1, ±1)
| (0, 0, ±1)
| (0, ±1, ±2)
|-
!colspan="4"| Four convex lattice polytopes in three dimensions
|}

A '''convex lattice polytope''' (also called '''Z-polyhedron''' or '''Z-polytope''') is a [[geometry|geometric]] object playing an important role in [[discrete geometry]] and [[combinatorial commutative algebra]]. It is a [[polytope]] in a Euclidean space '''R'''&lt;sup&gt;n&lt;/sup&gt; which is a [[convex hull]] of finitely many points in the [[integer lattice]] '''Z'''&lt;sup&gt;n&lt;/sup&gt; &amp;sub; '''R'''&lt;sup&gt;n&lt;/sup&gt;. Such objects are prominently featured in the theory of [[toric variety|toric varieties]], where they correspond to polarized projective toric varieties.

== Examples ==
* An ''n''-dimensional [[simplex]] &amp;Delta; in '''R'''&lt;sup&gt;n+1&lt;/sup&gt; is the convex hull of ''n''+1 points that do not lie on a single affine hyperplane. The simplex is a convex lattice polytope if (and only if) the vertices have integral coordinates. The corresponding toric variety is the ''n''-dimensional [[projective space]] '''P'''&lt;sup&gt;n&lt;/sup&gt;.
* The [[unit cube]] in '''R'''&lt;sup&gt;n&lt;/sup&gt;, whose vertices are the ''2''&lt;sup&gt;n&lt;/sup&gt; points all of whose coordinates are ''0'' or ''1'', is a convex lattice polytope. The corresponding toric variety is the [[Segre embedding]] of the ''n''-fold product of the projective line '''P'''&lt;sup&gt;1&lt;/sup&gt;.
* In the special case of two-dimensional convex lattice polytopes in '''R'''&lt;sup&gt;2&lt;/sup&gt;, they are also known as '''convex lattice polygons'''.
* In [[algebraic geometry]], an important instance of lattice polytopes called the [[Newton polytope]]s are the convex hulls of the set &lt;math&gt;A&lt;/math&gt; which consists of all the exponent vectors appearing in a collection of monomials. For example, consider the polynomial of the form &lt;math&gt;axy+bx^2+cy^5+d&lt;/math&gt; with &lt;math&gt;a,b,c,d \neq 0&lt;/math&gt; has a lattice equal to the triangle
:&lt;math&gt;{\rm conv}(\{(1,1),(2,0),(0,5),(0,0)\}).&lt;/math&gt;

== See also ==

* [[Normal polytope]]
* [[Pick's theorem]]
* [[Ehrhart polynomial]]
* [[Integer points in convex polyhedra]]

== References ==
* Ezra Miller, [[Bernd Sturmfels]], ''Combinatorial commutative algebra''. Graduate Texts in Mathematics, 227. Springer-Verlag, New York, 2005. xiv+417 pp. {{ISBN|0-387-22356-8}}

[[Category:Polytopes]]
[[Category:Lattice points]]


{{geometry-stub}}</text>
      <sha1>7sxo2nt39t143ch86dm09hv373huttj</sha1>
    </revision>
  </page>
  <page>
    <title>Deblurring</title>
    <ns>0</ns>
    <id>47824679</id>
    <revision>
      <id>851030064</id>
      <parentid>809002027</parentid>
      <timestamp>2018-07-19T16:07:26Z</timestamp>
      <contributor>
        <username>CommonsDelinker</username>
        <id>2304267</id>
      </contributor>
      <comment>Removing [[:c:File:Deblerring.png|Deblerring.png]], it has been deleted from Commons by [[:c:User:Jcb|Jcb]] because: Copyright violation; see [[:c:COM:Licensing|Commons:Licensing]] -.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2112">'''Deblurring''' is the process of removing blurring artifacts from images, such as blur caused by [[defocus aberration]] or [[motion blur]]. The blur is typically modeled as the [[convolution]] of a (sometimes space- or time-varying) [[point spread function]] with a hypothetical sharp input image, where both the sharp input image (which is to be recovered) and the point spread function are unknown. This is an example of an [[inverse problem]]. In almost all cases, there is insufficient information in the blurred image to uniquely determine a plausible original image, making it an [[ill-posed problem]]. In addition the blurred image contains additional noise which complicates the task of determining the original image. This is generally solved by the use of a [[regularization (physics)|regularization]] term to attempt to eliminate implausible solutions. This problem is analogous to [[echo removal]] in the signal processing domain. Nevertheless, when coherent beam is used for imaging, the [[point spread function]] can be modeled mathematically.&lt;ref&gt;{{Cite journal|last=Ahi|first=Kiarash|date=26 May 2016|title=Modeling of terahertz images based on x-ray images: a novel approach for verification of terahertz images and identification of objects with fine details beyond terahertz resolution|url=https://www.researchgate.net/publication/303563365_Modeling_of_terahertz_images_based_on_x-ray_images_a_novel_approach_for_verification_of_terahertz_images_and_identification_of_objects_with_fine_details_beyond_terahertz_resolution|journal=Proc. SPIE 9856, Terahertz Physics, Devices, and Systems X: Advanced Applications in Industry and Defense, 985610|volume=|issue=|doi=10.1117/12.2228685|pmid=|access-date=26 May 2016|via=}}&lt;/ref&gt; As the figure on the right illustrates, by proper [[deconvolution]] of the  [[point spread function]] and the image, the resolution can be enhanced several times.

== See also ==
* [[Blind deconvolution]]
* [[Modulation transfer function]]
* [[Denoising]]
* [[Super-resolution]]

==References==
{{Reflist}}

[[Category:Image processing]]


{{Signal-processing-stub}}</text>
      <sha1>33lhal0ls1oo5xlc3icozpwi5ktiecc</sha1>
    </revision>
  </page>
  <page>
    <title>Derived tensor product</title>
    <ns>0</ns>
    <id>54501194</id>
    <revision>
      <id>826259675</id>
      <parentid>824642402</parentid>
      <timestamp>2018-02-18T03:54:19Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <comment>/* top */ switch to simpler notions</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1155">In algebra, given a [[differential graded algebra]] ''A'' over a [[commutative ring]] ''R'', the '''derived tensor product''' functor is
:&lt;math&gt;- \otimes_A^{\textbf{L}} - : D(\mathsf{M}_A) \times D({}_A \mathsf{M}) \to D({}_R \mathsf{M})&lt;/math&gt;
where &lt;math&gt;\mathsf{M}_A&lt;/math&gt; and &lt;math&gt;{}_A \mathsf{M}&lt;/math&gt; are the [[category of modules|categories of right ''A''-modules]] and left ''A''-modules and ''D'' refers to the homotopy category (i.e., [[derived category]]).&lt;ref&gt;{{cite arxiv|last=Hinich|first=Vladimir|date=1997-02-11|title=Homological algebra of homotopy algebras|eprint=q-alg/9702015}}&lt;/ref&gt; By definition, it is the left derived functor of the [[tensor product of modules|tensor product functor]] &lt;math&gt;- \otimes_A - : \mathsf{M}_A \times {}_A \mathsf{M} \to {}_R \mathsf{M}&lt;/math&gt;.

== See also ==
*[[derived scheme]] (derived tensor product gives a derived version of a [[scheme-theoretic intersection]].)

== Notes ==
{{reflist}}

== References ==
*Lurie, J., ''[http://www.math.harvard.edu/~lurie/papers/SAG-rootfile.pdf Spectral Algebraic Geometry (under construction)]''

[[Category:Algebraic geometry]]


{{algebraic-geometry-stub}}</text>
      <sha1>b5xa0ro8qzohks3f3qpd8dxsk95v6jh</sha1>
    </revision>
  </page>
  <page>
    <title>Dimension (vector space)</title>
    <ns>0</ns>
    <id>38267</id>
    <revision>
      <id>859480816</id>
      <parentid>859478172</parentid>
      <timestamp>2018-09-14T09:32:32Z</timestamp>
      <contributor>
        <username>Zundark</username>
        <id>70</id>
      </contributor>
      <comment>undo last edit - please don't mess up the formatting just to make a comment (use the [[Talk:Dimension (vector space)|Talk page]] instead)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8430">In [[mathematics]], the '''dimension''' of a [[vector space]] ''V'' is the [[cardinality]] (i.e. the number of vectors) of a [[basis (linear algebra)|basis]] of ''V'' over its base [[field (mathematics)|field]].&lt;ref&gt;{{cite book|author=Itzkov, Mikhail|title=Tensor Algebra and Tensor Analysis for Engineers: With Applications to Continuum Mechanics|publisher=Springer|year=2009|isbn=978-3-540-93906-1|page=4|url=https://books.google.com/books?id=8FVk_KRY7zwC&amp;pg=PA4}}&lt;/ref&gt; It is sometimes called '''Hamel dimension''' (after [[Georg Hamel]]) or '''algebraic dimension''' to distinguish it from other types of [[dimension]].

For every vector space there exists a basis,{{efn|if one assumes the [[axiom of choice]]}} and all bases of a vector space have equal cardinality;{{efn|see [[dimension theorem for vector spaces]]}} as a result, the dimension of a vector space is uniquely defined. We say ''V'' is '''{{visible anchor|finite-dimensional}}''' if the dimension of ''V'' is [[wiktionary:finite|finite]], and '''{{visible anchor|infinite-dimensional}}''' if its dimension is [[infinity|infinite]].

The dimension of the vector space ''V'' over the field ''F'' can be written as dim&lt;sub&gt;''F''&lt;/sub&gt;(''V'') or as [V : F], read "dimension of ''V'' over ''F''". When ''F'' can be inferred from context, dim(''V'') is typically written.

== Examples ==

The vector space '''R'''&lt;sup&gt;3&lt;/sup&gt; has 

:&lt;math&gt;\left \{  \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix}  , \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix} , \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} \right \}&lt;/math&gt;

as a [[Basis (linear algebra)|basis]], and therefore we have dim&lt;sub&gt;'''R'''&lt;/sub&gt;('''R'''&lt;sup&gt;3&lt;/sup&gt;) = 3. More generally, dim&lt;sub&gt;'''R'''&lt;/sub&gt;('''R'''&lt;sup&gt;''n''&lt;/sup&gt;) = ''n'', and even more generally, dim&lt;sub&gt;''F''&lt;/sub&gt;(''F''&lt;sup&gt;''n''&lt;/sup&gt;) = ''n'' for any [[field (mathematics)|field]] ''F''.

The [[complex number]]s '''C''' are both a real and complex vector space; we have dim&lt;sub&gt;'''R'''&lt;/sub&gt;('''C''') = 2 and dim&lt;sub&gt;'''C'''&lt;/sub&gt;('''C''') = 1. So the dimension depends on the base field.

The only vector space with dimension 0 is {0}, the vector space consisting only of its zero element.

== Facts ==

If ''W'' is a [[linear subspace]] of ''V'', then dim(''W'') ≤ dim(''V'').

To show that two finite-dimensional vector spaces are equal, one often uses the following criterion: if ''V'' is a finite-dimensional vector space and ''W'' is a linear subspace of ''V'' with dim(''W'') = dim(''V''), then ''W'' = ''V''.

'''R'''&lt;sup&gt;''n''&lt;/sup&gt; has the standard basis {'''e'''&lt;sub&gt;1&lt;/sub&gt;, ..., '''e'''&lt;sub&gt;''n''&lt;/sub&gt;}, where '''e'''&lt;sub&gt;''i''&lt;/sub&gt; is the ''i''-th column of the corresponding [[identity matrix]]. Therefore '''R'''&lt;sup&gt;''n''&lt;/sup&gt; 
has dimension ''n''.

Any two vector spaces over ''F'' having the same dimension are [[isomorphic]]. Any [[bijective]] map between their bases can be uniquely extended to a bijective linear map between the vector spaces. If ''B'' is some set, a vector space with dimension |''B''| over ''F'' can be constructed as follows: take the set ''F''&lt;sup&gt;(''B'')&lt;/sup&gt; of all functions ''f'' : ''B'' → ''F'' such that ''f''(''b'') = 0 for all but finitely many ''b'' in ''B''. These functions can be added and multiplied with elements of ''F'', and we obtain the desired ''F''-vector space. 

An important result about dimensions is given by the [[rank–nullity theorem]] for [[linear map]]s.

If ''F''/''K'' is a [[field extension]], then ''F'' is in particular a vector space over ''K''. Furthermore, every ''F''-vector space ''V'' is also a ''K''-vector space. The dimensions are related by the formula
:dim&lt;sub&gt;''K''&lt;/sub&gt;(''V'') = dim&lt;sub&gt;''K''&lt;/sub&gt;(''F'') dim&lt;sub&gt;''F''&lt;/sub&gt;(''V'').
In particular, every complex vector space of dimension ''n'' is a real vector space of dimension 2''n''.

Some simple formulae relate the dimension of a vector space with the [[cardinality]] of the base field and the cardinality of the space itself.
If ''V'' is a vector space over a field ''F'' then, denoting the dimension of ''V'' by dim ''V'', we have:

:If dim ''V'' is finite, then |''V''| = |''F''|&lt;sup&gt;dim ''V''&lt;/sup&gt;.
:If dim ''V'' is infinite, then |''V''| = max(|''F''|, dim ''V'').

== Generalizations ==

One can see a vector space as a particular case of a [[matroid]], and in the latter there is a well-defined notion of dimension. The [[length of a module]] and the [[rank of an abelian group]] both have several properties similar to the dimension of vector spaces.

The [[Krull dimension]] of a commutative [[ring (algebra)|ring]], named after [[Wolfgang Krull]] (1899&amp;ndash;1971), is defined to be the maximal number of strict inclusions in an increasing chain of [[prime ideal]]s in the ring.

=== Trace ===
{{see also|Trace (linear algebra)}}
The dimension of a vector space may alternatively be characterized as the [[Trace (linear algebra)|trace]] of the [[identity operator]]. For instance, &lt;math&gt;\operatorname{tr}\ \operatorname{id}_{\mathbf{R}^2} = \operatorname{tr} \left(\begin{smallmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{smallmatrix}\right) = 1 + 1 = 2.&lt;/math&gt; This appears to be a circular definition, but it allows useful generalizations.

Firstly, it allows one to define a notion of dimension when one has a trace but no natural sense of basis. For example, one may have an [[Algebra over a field|algebra]] ''A'' with maps &lt;math&gt;\eta\colon K \to A&lt;/math&gt; (the inclusion of scalars, called the ''unit'') and a map &lt;math&gt;\epsilon \colon A \to K&lt;/math&gt; (corresponding to trace, called the ''[[counit]]''). The composition &lt;math&gt;\epsilon\circ \eta \colon K \to K&lt;/math&gt; is a scalar (being a linear operator on a 1-dimensional space) corresponds to "trace of identity", and gives a notion of dimension for an abstract algebra. In practice, in [[bialgebra]]s one requires that this map be the identity, which can be obtained by normalizing the counit by dividing by dimension (&lt;math&gt;\epsilon := \textstyle{\frac{1}{n}} \operatorname{tr}&lt;/math&gt;), so in these cases the normalizing constant corresponds to dimension.

Alternatively, one may be able to take the trace of operators on an infinite-dimensional space; in this case a (finite) trace is defined, even though no (finite) dimension exists, and gives a notion of "dimension of the operator". These fall under the rubric of "[[trace class]] operators" on a [[Hilbert space]], or more generally [[nuclear operator]]s on a [[Banach space]].

A subtler generalization is to consider the trace of a ''family'' of operators as a kind of "twisted" dimension. This occurs significantly in [[representation theory]], where the [[Character (mathematics)|character]] of a representation is the trace of the representation, hence a scalar-valued function on a [[group (mathematics)|group]] &lt;math&gt;\chi\colon G \to K,&lt;/math&gt; whose value on the identity &lt;math&gt;1 \in G&lt;/math&gt; is the dimension of the representation, as a representation sends the identity in the group to the identity matrix: &lt;math&gt;\chi(1_G) = \operatorname{tr}\ I_V = \dim V.&lt;/math&gt; One can view the other values &lt;math&gt;\chi(g)&lt;/math&gt; of the character as "twisted" dimensions, and find analogs or generalizations of statements about dimensions to statements about characters or representations. A sophisticated example of this occurs in the theory of [[monstrous moonshine]]: the [[j-invariant|''j''-invariant]] is the [[graded dimension]] of an infinite-dimensional graded representation of the [[Monster group]], and replacing the dimension with the character gives the [[McKay–Thompson series]] for each element of the Monster group.&lt;ref name="gannon"&gt;{{Citation | first = Terry | last = Gannon | title = Moonshine beyond the Monster: The Bridge Connecting Algebra, Modular Forms and Physics | year = 2006 | isbn = 0-521-83531-3}}&lt;/ref&gt;

== See also ==
*[[Basis (linear algebra)]]
*[[Topological dimension]], also called Lebesgue covering dimension
*[[Fractal dimension]]
*[[Krull dimension]]
*[[Matroid rank]]
*[[Rank (linear algebra)]]

== Notes ==
{{notelist}}

== References ==
{{reflist}}

==External links==
* [http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/lecture-9-independence-basis-and-dimension/ MIT Linear Algebra Lecture on Independence, Basis, and Dimension by Gilbert Strang] at MIT OpenCourseWare

{{DEFAULTSORT:Dimension (Vector Space)}}
[[Category:Linear algebra]]
[[Category:Dimension]]
[[Category:Vectors (mathematics and physics)]]</text>
      <sha1>lt38usidi6tq8kexforecolokwxlrr2</sha1>
    </revision>
  </page>
  <page>
    <title>Dissipation factor</title>
    <ns>0</ns>
    <id>634785</id>
    <revision>
      <id>837347818</id>
      <parentid>802478705</parentid>
      <timestamp>2018-04-20T08:01:43Z</timestamp>
      <contributor>
        <username>Jmv2009</username>
        <id>11634193</id>
      </contributor>
      <comment>/* Explanation */ loss tangent</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4616">In [[physics]], the '''dissipation factor''' (DF) is a measure of loss-rate of [[energy]] of a mode of [[oscillation]] (mechanical, electrical, or electromechanical) in a [[dissipative system]].  It is the reciprocal of [[quality factor]], which represents the "quality" or durability of oscillation.

==Explanation==
[[Electrical potential energy]] is dissipated in all [[dielectric]] materials, usually in the form of [[heat]].  In a [[capacitor]] made of a dielectric placed between conductors, the typical [[lumped element model]] includes a lossless ideal capacitor in series with a resistor termed the [[equivalent series resistance]] (ESR) as shown below.&lt;ref&gt;{{cite web |url=http://www.cartage.org.lb/en/themes/sciences/physics/electromagnetism/electrostatics/Capacitors/Applications/BasicConsiderations/BasicConsiderations.htm |title=Archived copy |accessdate=2008-11-29 |deadurl=yes |archiveurl=https://web.archive.org/web/20090822191220/http://www.cartage.org.lb/en/themes/sciences/physics/electromagnetism/electrostatics/Capacitors/Applications/BasicConsiderations/BasicConsiderations.htm |archivedate=2009-08-22 |df= }}&lt;/ref&gt;  The ESR represents losses in the capacitor.  In a good capacitor the ESR is very small, and in a poor capacitor the ESR is large. However, ESR is sometimes a minimum value to be required.  Note that the ESR is ''not'' simply the resistance that would be measured across a capacitor by an [[ohmmeter]].  The ESR is a derived quantity with physical origins in both the dielectric's conduction electrons and dipole relaxation phenomena.  In dielectric only one of either the conduction electrons or the dipole relaxation typically dominates loss.&lt;ref&gt;S. Ramo, J.R. Whinnery, and T. Van Duzer, ''Fields and Waves in Communication Electronics'', 3rd ed., (John Wiley and Sons, New York, 1994).  {{ISBN|0-471-58551-3}}&lt;/ref&gt;  For the case of the conduction electrons being the dominant loss, then

&lt;math&gt; \text{ESR} = \frac {\sigma} {\varepsilon \omega^2 C} &lt;/math&gt;

where

: &lt;math&gt; \sigma &lt;/math&gt; is the dielectric's bulk [[electrical conductivity|conductivity]],
: &lt;math&gt; \omega &lt;/math&gt; is the [[angular frequency]] of the AC current ''i'',
: &lt;math&gt; \varepsilon &lt;/math&gt; is the lossless [[permittivity]] of the dielectric, and
: &lt;math&gt; C &lt;/math&gt; is the lossless capacitance.

[[Image:Loss tangent phasors 1.svg|frame|A real capacitor has a lumped element model of a lossless ideal capacitor in series with an equivalent series resistance (ESR). The loss tangent is defined by the angle between the capacitor's impedance vector and the negative reactive axis.]]

If the capacitor is used in an [[alternating current|AC]] circuit, the dissipation factor due to the non-ideal capacitor is expressed as the ratio of the [[Electrical resistance|resistive]] power loss in the ESR to the [[Reactance (electronics)|reactive]] power oscillating in the capacitor, or

&lt;math&gt; \text{DF} = \frac {i^2 \text{ESR}} {i^2 |X_{c}|} = \omega C \cdot \text{ESR} = \frac {\sigma} {\varepsilon \omega} = \frac{1}{Q} &lt;/math&gt;

When representing the electrical circuit parameters as vectors in a [[Complex number|complex]] plane, known as [[Phasor (sine waves)|phasors]], a capacitor's dissipation factor is equal to the [[tangent (trigonometric function)|tangent]] of the angle between the capacitor's impedance vector and the negative reactive axis, as shown in the adjacent diagram.  This gives rise to the parameter known as the [[loss tangent]] tan ''δ'' where

&lt;math&gt; \frac{1}{Q}=\tan\delta = \frac{\text{ESR}}{\left|X_c\right|} = \text{DF} &lt;/math&gt;

Alternatively, ''ESR'' can be derived from frequency at which loss tangent was determined and capacitance

&lt;math&gt; \text{ESR} = \tan\delta\cdot\frac {1} {2\pi f C} &lt;/math&gt;

Since the ''DF'' in a good capacitor is usually small, ''δ'' ~ ''DF'', and ''DF'' is often expressed as a percentage.

''DF'' approximates to the [[power factor]] when &lt;math&gt;\text{ESR}&lt;/math&gt; is far less than &lt;math&gt;X_c&lt;/math&gt;, which is usually the case.

''DF'' will vary depending on the dielectric material and the frequency of the electrical signals.  In low [[dielectric constant]] ([[low-κ dielectric|low-κ]]), temperature compensating ceramics, ''DF'' of 0.1% to 0.2% is typical.  In high dielectric constant ceramics, ''DF'' can be 1% to 2%.  However, lower ''DF'' is usually an indication of quality capacitors when comparing similar dielectric material.

==See also==
* [[Dielectric withstand test]]
* [[Impulse generator]]

==References==
{{reflist}}

==References==

[[Category:Electromagnetism]]
[[Category:Electrical engineering]]
[[Category:Dynamical systems]]</text>
      <sha1>34uuazean7b342r4xgog3w2t0v61pip</sha1>
    </revision>
  </page>
  <page>
    <title>Ehrling's lemma</title>
    <ns>0</ns>
    <id>7260876</id>
    <revision>
      <id>607152294</id>
      <parentid>601475251</parentid>
      <timestamp>2014-05-05T11:09:32Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>/* References */[[WP:CHECKWIKI]] error fixes using [[Project:AWB|AWB]] (10093)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2606">In [[mathematics]], '''Ehrling's lemma''' is a result concerning [[Banach space]]s. It is often used in [[functional analysis]] to demonstrate the [[norm (mathematics)#Properties|equivalence]] of certain [[norm (mathematics)|norms]] on [[Sobolev space]]s. It was proposed by Gunnar Ehrling.

==Statement of the lemma==

Let (''X'',&amp;nbsp;||&amp;middot;||&lt;sub&gt;''X''&lt;/sub&gt;), (''Y'',&amp;nbsp;||&amp;middot;||&lt;sub&gt;''Y''&lt;/sub&gt;) and (''Z'',&amp;nbsp;||&amp;middot;||&lt;sub&gt;''Z''&lt;/sub&gt;) be three Banach spaces. Assume that:
* ''X'' is [[compactly embedded]] in ''Y'': i.e. ''X''&amp;nbsp;&amp;sube;&amp;nbsp;''Y'' and every ||&amp;middot;||&lt;sub&gt;''X''&lt;/sub&gt;-[[bounded function|bounded]] [[sequence]] in ''X'' has a [[subsequence]] that is ||&amp;middot;||&lt;sub&gt;''Y''&lt;/sub&gt;-[[Limit (mathematics)|convergent]]; and
* ''Y'' is [[continuously embedded]] in ''Z'': i.e. ''Y''&amp;nbsp;&amp;sube;&amp;nbsp;''Z'' and there is a constant ''k'' so that ||''y''||&lt;sub&gt;''Z''&lt;/sub&gt;&amp;nbsp;&amp;le;&amp;nbsp;''k''||''y''||&lt;sub&gt;''Y''&lt;/sub&gt; for every ''y''&amp;nbsp;&amp;isin;&amp;nbsp;''Y''.
Then, for every ''&amp;epsilon;''&amp;nbsp;&amp;gt;&amp;nbsp;0, there exists a constant ''C''(''&amp;epsilon;'') such that, for all ''x''&amp;nbsp;&amp;isin;&amp;nbsp;''X'',

:&lt;math&gt;\| x \|_{Y} \leq \varepsilon \| x \|_{X} + C(\varepsilon) \| x \|_{Z}&lt;/math&gt;

==Corollary (equivalent norms for Sobolev spaces)==

Let &amp;Omega;&amp;nbsp;&amp;sub;&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt; be [[open set|open]] and [[bounded set|bounded]], and let ''k''&amp;nbsp;&amp;isin;&amp;nbsp;'''N'''. Suppose that the Sobolev space ''H''&lt;sup&gt;''k''&lt;/sup&gt;(&amp;Omega;) is compactly embedded in ''H''&lt;sup&gt;''k''&amp;minus;1&lt;/sup&gt;(&amp;Omega;). Then the following two norms on ''H''&lt;sup&gt;''k''&lt;/sup&gt;(&amp;Omega;) are equivalent:

:&lt;math&gt;\| \cdot \| : H^{k} (\Omega) \to \mathbf{R}: u \mapsto \| u \| := \sqrt{\sum_{| \alpha | \leq k} \| \mathrm{D}^{\alpha} u \|_{L^{2} (\Omega)}^{2}}&lt;/math&gt;

and

:&lt;math&gt;\| \cdot \|' : H^{k} (\Omega) \to \mathbf{R}: u \mapsto \| u \|' := \sqrt{\| u \|_{L^{1} (\Omega)}^{2} + \sum_{| \alpha | = k} \| \mathrm{D}^{\alpha} u \|_{L^{2} (\Omega)}^{2}}.&lt;/math&gt;

For the subspace of ''H''&lt;sup&gt;''k''&lt;/sup&gt;(&amp;Omega;) consisting of those Sobolev functions with [[trace operator|zero trace]] (those that are "zero on the boundary" of &amp;Omega;), the ''L''&lt;sup&gt;1&lt;/sup&gt; norm of ''u'' can be left out to yield another equivalent norm.

==References==

* {{cite book 
| last1 = Renardy
| first1 = Michael
| last2 = Rogers
| first2 = Robert C. 
| title = An Introduction to Partial Differential Equations 
| publisher = Springer-Verlag
| location = Berlin 
| year=1992 
| isbn=978-3-540-97952-4 
}}

[[Category:Banach spaces]]
[[Category:Sobolev spaces]]
[[Category:Lemmas]]


{{mathanalysis-stub}}</text>
      <sha1>t0i1svccenkfx3y5rnhvjesxhn39lsf</sha1>
    </revision>
  </page>
  <page>
    <title>Escaping set</title>
    <ns>0</ns>
    <id>29115268</id>
    <revision>
      <id>848715912</id>
      <parentid>848715860</parentid>
      <timestamp>2018-07-03T20:10:21Z</timestamp>
      <contributor>
        <username>Pym1507</username>
        <id>16024349</id>
      </contributor>
      <comment>/* History */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6087">In mathematics, and particularly [[complex dynamics]], the '''escaping set''' of an [[entire function]] ƒ consists of all points that tend to infinity under the [[iterated function|repeated application]] of ƒ.&lt;ref name="RS"&gt;
{{cite journal|first1=P. J.|last1=Rippon|first2=G|last2=Stallard|author2-link= Gwyneth Stallard|
title=On questions of Fatou and Eremenko|journal=Proc. Amer. Math. Soc.|year=2005|volume=133|pages=1119–1126|doi=10.1090/s0002-9939-04-07805-0}}&lt;/ref&gt;
That is, a complex number &lt;math&gt;z_0\in\mathbb{C}&lt;/math&gt; belongs to the escaping set if and only if the sequence defined by &lt;math&gt;z_{n+1} := f(z_n)&lt;/math&gt; converges to infinity as &lt;math&gt;n&lt;/math&gt; gets large. The escaping set of &lt;math&gt;f&lt;/math&gt; is denoted by &lt;math&gt;I(f)&lt;/math&gt;.&lt;ref name="RS" /&gt;

For example, for &lt;math&gt;f(z)=e^z&lt;/math&gt;, the origin belongs to the escaping set, since the sequence 
:&lt;math&gt;0,1,e,e^e,e^{e^e},\dots&lt;/math&gt;
tends to infinity.

== History ==
The iteration of transcendental entire functions was first studied by [[Pierre Fatou]] in 1926&lt;ref name="Fatou"&gt;
{{cite journal|first=P.|last=[[Pierre Fatou|Fatou]]|title=Sur l'itération des fonctions transcendantes Entières|journal=Acta Math.|year=1926|volume=47|pages=337–370|doi=10.1007/bf02559517}}&lt;/ref&gt;
The escaping set occurs implicitly in his study of the explicit entire functions &lt;math&gt;f(z)=z+1+\exp(-z)&lt;/math&gt; and &lt;math&gt;f(z)=c\sin(z)&lt;/math&gt;.

{{unsolved|mathematics|Can the escaping set of a transcendental entire function have a bounded component?}}
The first study of the escaping set for a general transcendental entire function is due to [[Alexandre Eremenko]] who used [[Wiman-Valiron theory]]&lt;ref name="E"&gt;
{{cite journal
|last=[[Alexandre Eremenko|Eremenko]]|first=A|title=On the iteration of entire functions|year=1987|
journal=Banach center publications, Warsawa, PWN|volume=23|pages=339–345|url=http://www.math.purdue.edu/~eremenko/dvi/banach.pdf}}&lt;/ref&gt;.
He conjectured that every [[connected component (topology)|connected component]] of the escaping set of a transcendental entire function is unbounded. This has become known
as ''Eremenko's conjecture''.&lt;ref name="RS" /&gt;&lt;ref name="RRRS"&gt;{{cite journal|first1=G|last1=Rottenfußer|
first2=J|last2=Rückert|first3=L|last3=[[Lasse Rempe|Rempe]]|first4=D|last4=Schleicher|
title=Dynamic rays of bounded-type entire functions|journal=Ann. of Math.|volume=173|year=2011|pages=77–125|
arxiv=0704.3213|doi=10.4007/annals.2010.173.1.3}}&lt;/ref&gt; There are many partial results
on this problem but as of 2013 the conjecture is still open.

Eremenko also asked whether every escaping point can be connected to infinity by a curve in the escaping set; it was later shown that this is not the case. Indeed,
there exist entire functions whose escaping sets do not contain any curves at all.&lt;ref name="RRRS" /&gt;

== Properties ==
The following properties are known to hold for the escaping set of any non-constant and non-linear entire function. (Here ''nonlinear'' means that the function is not of the form &lt;math&gt;f(z)=az+b&lt;/math&gt;.)

* The escaping set contains at least one point.&lt;ref name="E" /&gt;
* The [[boundary (topology)|boundary]] of the escaping set is exactly the [[Julia set]].&lt;ref name="E" /&gt; In particular, the escaping set is never [[closed set|closed]].
* For a transcendental entire function, the escaping set always intersects the Julia set.&lt;ref name="E" /&gt; In particular, the escaping set is [[open set|open]] if and only if &lt;math&gt;f&lt;/math&gt; is a polynomial.
* Every connected component of the closure of the escaping set is unbounded.&lt;ref name="E" /&gt;
* The escaping set always has at least one connected component.&lt;ref name="RS" /&gt;
* For a transcendental entire function, the escaping set is connected or it has infinitely many components.&lt;ref name="RS2" /&gt;
* The set &lt;math&gt;I(f)\cup \{\infty\}&lt;/math&gt; is connected.&lt;ref name="RS2"&gt;
{{cite journal|first1=P. J.|last1=Rippon|first2=G|last2=Stallard|
title=Boundaries of escaping Fatou components|journal=Proc. Amer. Math. Soc.|year=2011|volume=139|pages=2807–2820|doi=10.1090/s0002-9939-2011-10842-6|arxiv=1009.4450}}&lt;/ref&gt;

Note that the final statement does not imply Eremenko's Conjecture. (Indeed, there exist connected spaces in which the removal of a single [[dispersion point]] leaves the remaining space totally disconnected.)

== Examples ==

=== Polynomials ===

For a [[polynomial]] of degree at least 2, the point at infinity is an [[Fixed point (mathematics)|(super-)attracting fixed point]], and the escaping set is precisely the [[attractor|basin of attraction]] of this fixed point ( infinity). Hence in this case, &lt;math&gt;I(f)&lt;/math&gt; is an [[open set|open]] and [[connected space|connected]] subset of the complex plane, and the [[Julia set]] is the boundary of this basin.

For instance the escaping set of the [[complex quadratic polynomial]] &lt;math&gt;f(z) = z^2&lt;/math&gt; consists precisely of those points whose [[absolute value]] is greater than 1

:&lt;math&gt;I(f) = \{z : abs(z) &gt; 1 \} &lt;/math&gt;

===Transcendental entire functions===
[[File:Exp-esc.png|thumb|Escaping set of (exp&amp;nbsp;''x''&amp;nbsp;&amp;minus;&amp;nbsp;1)/2.]]

For [[Transcendental function|transcendental entire functions]], the escaping set is much more complicated than for polynomials: in the simplest cases like the one illustrated in the picture it consists on uncountably many curves, called ''hairs'' or ''rays''. In other examples the structure of the escaping set can be very different (a ''spider's web'').&lt;ref&gt;{{cite journal|first=D.J.|last=Sixsmith|title= Entire functions for which the escaping set is a spider's web|year=2012|arxiv=1012.1303|doi=10.1017/S0305004111000582|bibcode=2011MPCPS.151..551S}}&lt;/ref&gt; As mentioned above, there are examples of entire functions whose escaping set contains no curves.&lt;ref name="RRRS" /&gt;

==See also ==
* [[Mandelbrot set#Escape time algorithm|escape condition or bailout]]
* [[target set]]

== References ==
{{reflist}}

==External links==
*{{cite web|author=[[Lasse Rempe]]|title=A poem on Eremenko conjecture|url=http://www.math.purdue.edu/~eremenko/rempe-abstr}}

[[Category:Complex analysis]]</text>
      <sha1>5fahudzr193su2fnuqjtrzcwzld6p0k</sha1>
    </revision>
  </page>
  <page>
    <title>Fibonacci numbers in popular culture</title>
    <ns>0</ns>
    <id>8009218</id>
    <revision>
      <id>861031416</id>
      <parentid>861025577</parentid>
      <timestamp>2018-09-24T18:15:12Z</timestamp>
      <contributor>
        <username>Rich Smith</username>
        <id>13314572</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/117.98.166.154|117.98.166.154]] identified as test/vandalism using [[WP:STiki|STiki]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19073">The '''[[Fibonacci number]]s''' are a [[sequence]] of [[integer]]s, starting with 0, 1 and continuing 1, 2, 3, 5, 8, 13, ..., each new number being the sum of the previous two. The Fibonacci numbers, and in conjunction the [[golden ratio]], are a popular theme in culture. They have been mentioned in novels, films, television shows, and songs. The numbers have also been used in the creation of music, visual art, and architecture.

==Finance==
* Stock traders frequently look to the "[[Fibonacci retracement]]" when predicting future share prices.

==Architecture==
* The sequence has been used in the design of a building, the Core, at the [[Eden Project]], near [[St Austell]], [[Cornwall]], [[England]].&lt;ref&gt;{{cite book |last=Smith |first=Peter |title=Sustainability at the Cutting Edge, Second Edition: Emerging Technologies for low energy buildings  |publisher=[[Elsevier]] |isbn=0-7506-8300-7 |page=151|type= |date=December 2007}}&lt;/ref&gt;&lt;ref&gt;[[The Engineer (magazine)|''The Engineer'']], [http://www.theengineer.co.uk/Articles/293054/Eden+Project+gets+into+flower+power.htm "Eden Project gets into flower power"].&lt;/ref&gt;

&lt;gallery widths=250 heights=175&gt;
File:Fibonacci Terrace, Science Centre Singapore - 20151121.jpg|The Fibonacci Terrace at the [[Science Centre Singapore]]. The tiles making up the terrace are arranged to form shapes with sides in proportion to Fibonacci number.
File:Fibonacci molle.JPG|Fibonacci numbers at the [[Mole Antonelliana]] in [[Turin]]
File:Unna Lindenbrauerei Kamin Fibonacci IMGP3083.jpg|The Fibonacci numbers at the [[Lindenbrauerei]] in [[Unna]] created by [[Mario Merz]].
File:Fibonacci numbers in Zurich HB.jpg|Fibonacci numbers in the [[Zürich Hauptbahnhof]].
File:Fibonacci numbers at Zurich Main Station.jpg|Detailed view of the Fibonacci numbers in the [[Zürich Hauptbahnhof]].
&lt;/gallery&gt;

==Cinema==
* &lt;!--1970--&gt;In ''[[The Phantom Tollbooth (film)]]'' (1970), Milo ([[Butch Patrick]]) is given a set of numbers to identify in order to gain entry to the "Numbers Mine", and correctly answers noting that its the Fibonacci sequence.
* &lt;!--1998--&gt;Along with the [[golden rectangle]] and [[golden spiral]], the Fibonacci sequence is mentioned in [[Darren Aronofsky]]'s independent film ''[[Pi (film)|Pi]]'' (1998). They are used to find the name of God.
* &lt;!--2006--&gt;In ''[[The Da Vinci Code (film)|The Da Vinci Code]]'' (2006), the numbers are used to unlock a safe. They are also placed out of order in a message to indicate that the message is also out of order ([[anagram]]).
* &lt;!--2007--&gt;In ''[[Mr. Magorium's Wonder Emporium]]'' (2007), Magorium hires accountant Henry Weston ([[Jason Bateman]]) after an interview in which he demonstrates knowledge of Fibonacci numbers.
* &lt;!--2008-02--&gt;In ''[[L: Change the World]]'' (2008), [[Near (Death Note)|Near]] is seen arranging sugar cubes in a Fibonacci sequence.
* &lt;!--2008-03--&gt;In ''[[21 (2008 film)|21]]'' (2008), the first seven numbers in the Fibonacci Sequence are drawn in icing on Ben's (Jim Sturgess) Birthday cake. The 8th term, 21, is left out. Ben and Miles (Josh Gad) quickly figure it out.   
* &lt;!--2013--&gt;In ''[[Nymphomaniac (film)|Nymphomaniac]]'' (2013), the character Seligman ([[Stellan Skarsgård]]) notes that when Joe ([[Charlotte Gainsbourg]]) loses her virginity, the boy who deflowers her does so in a sequence of thrusts that are Fibonacci numbers.
* &lt;!--2016--&gt;In ''[[Arrival (film)|Arrival]]'' (2016), character Ian Donnelly ([[Jeremy Renner]]) checks if the aliens have communicated with humans in any of the following approaches: "shapes, patterns, numbers, fibonacci".

==Comic strips==
* In the February 8, 2009 edition of ''[[FoxTrot]]'' by [[Bill Amend]], characters Jason and Marcus take one nacho from a bowl, one more nacho, then two nachos, three nachos, five nachos, eight nachos, etc., calling it 'Fibonacho.'
* In a strip of ''[[Frazz]]'' by [[Jef Mallett]], Frazz and a student are discussing her knitted hat. The student says, "Mom sewed one sparkly here and here. Two sparklies here. Three sparklies. Five sparklies. Eight sparklies. Thirteen..." To which Frazz replies, "Fibonacci sequins, of course."

==Human development==
John Waskom postulated that stages of human development followed the Fibonacci sequence, and that the unfolding psychology of human life would ideally be a "living proof" of the Golden Mean. This theory was originally developed and published by Norman Rose in two articles. The first article, which laid out the general theory, was entitled "Design and Development of Wholeness: Waskom's Paradigm."&lt;ref&gt;The Educational Forum, 55, 3 (Spring 1991), 243-259 http://whizkidz.org/design/DevelopmentDesign.pdf)&lt;/ref&gt; The second article laid out the applications and implications of the theory to the topic of moral development, and was entitled "Moral Development: The Experiential Perspective."&lt;ref&gt;Journal of Moral Education, 21, 1 (Winter, 1992), 29-40 http://whizkidz.org/design/MoralDevelopment.pdf&lt;/ref&gt;

==Literature==
* The Fibonacci sequence plays a small part in [[Dan Brown|Dan Brown's]] bestselling novel (and film) ''[[The Da Vinci Code]]''.
* In [[Philip K. Dick]]'s novel ''[[VALIS]]'', the Fibonacci sequence (as well as the Fibonacci constant) are used as identification signs by an organization called the "Friends of God".
* In the collection of poetry ''alfabet'' by the Danish poet [[Inger Christensen]], the Fibonacci sequence is used to define the number of lines in each poem.
* It was briefly included (and recognized by [[Charles Wallace Murry]]) in the [[A Wrinkle in Time (2003 film)|television film adaptation]] of ''[[A Wrinkle in Time]]''.
* The Fibonacci sequence is frequently referenced in the 2001 book ''The Perfect Spiral'' by Jason S. Hornsby.
* A youthful Fibonacci is one of the main characters in the novel ''[[Crusade in Jeans]]'' (1973). He was left out of the 2006 [[Crusade in Jeans (film)|movie version]], however.
* The Fibonacci sequence and golden ratio are briefly described in [[John Fowles]]'s 1985 novel ''[[A Maggot]]''
* The Fibonacci sequence is explored in Emily Gravett's 2009 book ''The Rabbit Problem''
* The Rabbit Problem is also described in Marina Lewycka's book "Various Pets Alive and Dead"
* "Ice Station" a novel by Australian writer [[Matthew Reilly]] involves a partially completed access code, the remaining numbers of which can only be found by extrapolating a Fibonacci pattern.
* The Fibonacci sequence is used by a serial killer to attract the protagonist Special Agent Pendergast in the Preston/Childs novel   ''[[Two Graves]]'' (2012).
* [[Eleanor Catton]]'s novel ''[[The Luminaries]]'' (2013), winner of the [[2013 Man Booker Prize]], is structured around an inverse Fibonacci sequence, with each part of the book half the length of the one preceding it.

==Music==
*[[Hip hop music|Hip hop]] duo [[Black Star (group)|Black Star]]'s song "Astronomy (8th Light)" from the 1998 album ''[[Mos Def &amp; Talib Kweli are Black Star]]'', features the Fibonacci sequence in the chorus:
&lt;poem&gt;
:Now everybody hop on the one, the sounds of the two
:It's the third eye vision, five side dimension
:The 8th Light, is gonna shine bright tonight
&lt;/poem&gt;
* [[Tool (band)|Tool]]'s song "[[Lateralus (song)|Lateralus]]" from the album of the same name features the Fibonacci sequence symbolically in the verses of the song. The syllables in the first verse count 1, 1, 2, 3, 5, 8, 5, 13, 13, 8, 5, 3. The missing section (2, 1, 1, 2, 3, 5, 8) is later filled in during the second verse.&lt;ref&gt;{{cite web| author=Di Carlo, Christopher| year=2001| title=Interview with Maynard James Keenan| url=http://www.cdicarlo.com/paper_04maynard.htm| accessdate=2007-05-22| deadurl=yes| archiveurl=https://www.webcitation.org/674Q4juoH?url=http://www.cdicarlo.com/paper_04maynard.htm| archivedate=2012-04-20| df=}}&lt;/ref&gt;&lt;ref&gt;. An exposition of how the fibonacci sequence appears in [[Lateralus]] set to pictures from the Hubble telescope: https://www.youtube.com/watch?v=wS7CZIJVxFY&lt;/ref&gt; The [[time signatures]] of the chorus change from 9/8 to 8/8 to 7/8; as drummer [[Danny Carey]] says, "It was originally titled 9-8-7. For the time signatures. Then it turned out that 987 was the 16th number of the Fibonacci sequence. So that was cool."&lt;ref&gt;{{cite web| author=Norris, Chris| year=2001| title=Hammer Of The Gods| url=http://toolshed.down.net/articles/text/spinmag.jun.2001.html| accessdate=2007-04-25| deadurl=yes| archiveurl=https://www.webcitation.org/674Q3LBDv?url=http://toolshed.down.net/articles/text/spinmag.jun.2001.html| archivedate=2012-04-20| df=}}&lt;/ref&gt;
[[Image:Bartok - Sonata for two pianos and percussion, 3rd mov. fibonacci.png|350px|thumb|[[Fibonacci number|Fibonacci]] intervals (counting in semitones) in Bartók's [[Sonata for Two Pianos and Percussion]], 3rd mov. (1937).&lt;ref&gt;Maconie, Robin (2005). ''Other Planets'', 26 &amp; 28. {{ISBN|0-8108-5356-6}}. Citing Lendvai (1972). "Einführung in die Formen- und Harmonienwelt Bartóks" (1953), ''Béla Bartók: Weg und Werk'', p.105-49. [[Bence Szabolcsi]], ed.&lt;/ref&gt; {{audio|Bartok - Sonata for two pianos and percussion, 3rd mov. fibonacci.mid|Play}}]]
* [[Ernő Lendvai]] analyzes [[Béla Bartók]]'s works as being based on two opposing systems, that of the [[golden ratio]] and the [[acoustic scale]].&lt;ref&gt;*{{cite book |last=Lendvai |first=Ernő |authorlink=Ernő Lendvai |title=Béla Bartók: An Analysis of his Music |others=introd. by [[Alan Bush]] |year=1971 |publisher=Kahn &amp; Averill |location=London |isbn=0-900707-04-6 |oclc=240301}}&lt;/ref&gt; In the third movement of Bartók's ''[[Music for Strings, Percussion and Celesta]]'', the opening xylophone passage uses Fibonacci rhythm as such: 1:1:2:3:5:8:5:3:2:1:1.&lt;ref name=Smith&gt;Smith, Peter F. ''The Dynamics of Delight: Architecture and Aesthetics'' (New York: Routledge, 2003) p. 83, {{ISBN|0-415-30010-X}}&lt;/ref&gt;
* The Fibonacci numbers are also apparent in the organisation of the sections in the music of [[Debussy]]'s ''Image, Reflections in Water'', in which the sequence of keys is marked out by the intervals 34, 21, 13 and 8.&lt;ref name=Smith /&gt;
* Italian composer and mathematical-physicist [[Matteo Sommacal]] wrote in 2002 the eight-movement suite ''Fibonacci's Piranhas'',&lt;ref&gt;M. Sommacal, ''Fibonacci's Piranhas'' - [https://www.myspace.com/valeriadimatteo/music/song/fibonacci-s-piranhas-di-matteo-sommacal-61405750-67047663 ''5th Movement''], performed by Valeria Di Matteo&lt;/ref&gt;&lt;ref&gt;M. Sommacal, ''Fibonacci's Piranhas'' - [https://www.youtube.com/watch?v=A2ZR8az1c9U ''5th Movement''], performed by Taglieri Genitoni Duo, live recording, "Concerti e Colline", Nizza Monferrato, 31 January 2012&lt;/ref&gt; for piano 4, 5 and 6 hands, which makes an extensive use of the Fibonacci numbers for deriving and developing the whole melodic, rhythmic and harmonic structure of the piece.&lt;ref&gt;M.G. Ortore, [http://venezian.altervista.org/ContributiScienza/61__Ortore_musica.pdf "Musica, Fisica e Matematica: intervista a Matteo Sommacal"], ''Ticonzero'', Article 61, April 2015, ISSN 2420-8442&lt;/ref&gt;
* Polish composer [[Krzysztof Meyer]] structured the values in his ''Trio for clarinet, cello and piano'' according to the Fibonacci sequence.&lt;ref&gt;Weselmann, Thomas (2003) ''Musica incrostata''. Poznan&lt;/ref&gt;
* Fibonacci's name was adopted by a [[Los Angeles]]-based [[art rock]] group [[The Fibonaccis]], that recorded from 1981 to 1987.
* American musician [[BT (musician)|BT]] also recorded a song titled "Fibonacci Sequence". The narrator in the song goes through all the numbers of the sequence from 1 to 21 (0 is not mentioned). The track appeared on a limited edition version of his 1999 album ''[[Movement in Still Life]]'', and is also featured on the second disc of the ''[[Global Underground 013|Global Underground 013: Ibiza]]'' compilation mixed by [[Sasha (DJ)|Sasha]].&lt;ref&gt;{{YouTube|id=CFsd4IubweU|title=BT - Fibonacci Sequence}}&lt;/ref&gt;
* Voiceover and recording artist [[Ken Nordine]] described Fibonacci numbers in a word jazz piece called "Fibonacci Numbers" on his album ''A Transparent Mask''.&lt;ref&gt;[https://www.amazon.com/gp/product/B000URZG2U/ref=dm_mu_dp_trk16 Fibonacci Numbers: Ken Nordine] at Amazon.com.&lt;/ref&gt;
* Australian electronic group [[Angelspit]] uses the Fibonnaci in the song "Vermin." The lyrics start with, "1, 2 3 5 8, Who do we decapitate?" and continues through a few more iterations of the sequence.
* Avant garde composer [[Elliott Sharp]] used fibonacci numbers in his compositions.&lt;ref name="ambrose"&gt;Ambrose, P. [http://www.themorningnews.org/archives/interviews/elliott_sharps_instrumental_vision.php Elliott Sharp’s Instrumental Vision] [[The Morning News (online magazine)|The Morning News]], October 4, 2005&lt;/ref&gt;
* Composer [[Dave Soldier]]'s opera with [[Komar and Melamid]], Naked Revolution, contains a soprano aria titled "Sing of Nature, Sing of Numbers" with lyrics and music based on the Fibonacci series, sung in character by [[Isadora Duncan]].

==Visual arts==
[[File:Fibonaccis Traum.jpg|thumb|Martina Schettina: ''Fibonaccis Dream'', 2008, 40 x 40 cm]]
[[File:Diepholz Skulpturenpfad Fibonacci.JPG|thumb|Petra Paffenholz: ''Fibonacci Cubes'', 2014, 10 cm to 6.8 m&lt;ref&gt;{{cite web|title=FIBONACCI CUBES|url=http://petra-paffenholz.de/?page_id=9|website=PETRA PAFFENHOLZ|accessdate=15 July 2017}}&lt;/ref&gt;]]
* Artist [[Mario Merz]] made the Fibonacci sequence a recurring theme in his work.&lt;ref&gt;{{cite news|url=https://www.theguardian.com/news/2003/nov/13/guardianobituaries.italy|title=Obituary: Mario Merz|accessdate=2008-09-14 | work=The Guardian | location=London | date=2003-11-13}}&lt;/ref&gt; Examples are the Chimney of Turku Energia, in Turku, Finland, featuring the start of the Fibonacci sequence in 2m high neon lights, and the representation of the first Fibonacci numbers with red neon lights on one of the four-faced dome of the  [[Mole Antonelliana]] in [[Turin]], Italy, part of the artistic work Il volo dei Numeri ("Flight of the numbers").
* Fibonacci numbers have also been used in knitting to create aesthetically appealing patterns.&lt;ref&gt;{{cite web |url=http://www.diynetwork.com/diy/na_knitting/article/0,2025,DIY_14141_4956504,00.html |title=Fibonacci Accessories: Scarf |accessdate=2007-12-31 |deadurl=yes |archiveurl=https://web.archive.org/web/20071222121638/http://www.diynetwork.com/diy/na_knitting/article/0,2025,DIY_14141_4956504,00.html |archivedate=2007-12-22 |df= }}&lt;/ref&gt;
* The artist [[Martina Schettina]] uses Fibonacci numbers in her paintings.&lt;ref&gt;[http://www.mathematik.uni-dortmund.de/ieem/BzMU/BzMU2009/Beitraege/LEHMANN_Ingmar_2009_Fibonacci.pdf Ingmar Lehman: „Fibonacci-numbers in visual arts and literature"] (German)(last called on November 7, 2009)&lt;/ref&gt;&lt;ref&gt;2009: Martina Schettina:''Mathemagische Bilder - Bilder und Texte''. Vernissage Verlag Brod Media, Wien 2009, {{ISBN|978-3-200-01743-6}} (German)&lt;/ref&gt; Her "Mathemagic paintings" were shown at the [[Museumsquartier]] [[Vienna]] in 2010.&lt;ref&gt;[http://oe1.orf.at/programm/20100222801.html About the exhibition, interview on Radio [[Ö1]]] {{webarchive|url=https://web.archive.org/web/20110605033822/http://oe1.orf.at/programm/20100222801.html |date=2011-06-05 }}(recalled at February 28, 2010)&lt;/ref&gt;
* Visual artist [[Marisa Ferreira]] used the Fibonacci numeral sequence to create the geometric shapes of her piece [http://www.marisa-ferreira.com/Rear-Window-2015 Rear Window], installed from February to August 2015 on the façade of [[Oslo Central Station]], Norway. The artist used the sequence to express the walking pattern and rhythm of footsteps of pedestrian traffic in and out of the station.&lt;ref&gt;{{cite web|title=Rear Window 2015|url=http://www.marisa-ferreira.com/Rear-Window-2015|website=Marisa Ferreira|accessdate=6 June 2015}}&lt;/ref&gt;

==Television==
* The scientist character [[Walter Bishop (Fringe)|Walter Bishop]] in the television show ''[[Fringe (TV series)|Fringe]]'' recites the Fibonacci sequence to fall asleep. It is later revealed to be the key sequence identifying a series of safe deposit boxes he had maintained.
* ''[[Square One Television]]''{{'}}s ''[[Mathnet]]'' series had a storyline that featured a parrot belonging to a deceased individual who was fascinated by the Fibonacci numbers.  When "1, 1, 2, 3" is said in the parrot's presence, it responds "5, eureka!"  This proves to be the key to case; tiles in a garden wall are found to follow the Fibonacci sequence, with a secret compartment hidden behind the lone misplaced tile.
* The ''[[Criminal Minds]]'' episode "Masterpiece" in [[Criminal Minds (season 4)|season 4]] features a serial killer who uses Fibonacci sequences to choose both the number of victims he kills at a given time, as well as the location of their hometowns.
* Aliens use Fibonacci's sequence in the ''[[Taken (TV miniseries)|Taken]]'' episode "God's Equation".
* In the Disney Channel TV show ''[[So Weird]]'', the Fibonacci sequence is used to build a house. The house becomes a nexus for lost spirits.  One character, Fiona, is given a choice to use it to free her father as well as the builder of the house, but ultimately chooses to free the spirits, and destroys the nexus.
* The Fibonacci sequence is a main plot theme in the 2012 television show ''[[Touch (2012 TV series)|Touch]]'', produced by [[Fox Network]] and starring [[Kiefer Sutherland]] It revolves around a number sequence (318 5296 3287 9.5 22 975 6 1188 1604 55124... and on. These numbers are calculated from using the Fibonacci sequence in some way to reveal patterns in both natural and artificial systems, essentially allowing the characters to predict the future.
* In the CBS show ''[[Numb3rs]]'' episode "Thirteen", a Fibonacci sequence is embedded in a numeric code left behind by a serial killer.
* On the TV show, ''[[Adventure Time]]'', the sequence of 8, 13, 21, is shown on the back of the Enchiridion in certain episodes.
*On the ''[[Cartoon Network]]'' special ''[[The Powerpuff Girls]]:  Dance Pantsed'', one of the kidnapping victims is named Fibonacci Sequins (voiced by [[Ringo Starr]]).
* In the Japanese [[anime]] ''Aguu: Tensai Ningyou'', a Fibonacci sequence is rapidly fired back-and-forth in a battle of wits between two archenemies (Episode 11).

==References==
{{reflist}}

==External links==
* Subhash Kak, ''[https://arxiv.org/abs/physics/0411195 The Golden Mean and the Physics of Aesthetics]'', Archive of Physics, (2004).
* [http://www.sju.edu/~rhall/Rhythms/Poets/arcadia.pdf Math for Poets and Drummers] – Rachael Hall surveys rhythm and Fibonacci numbers and also the Hemachandra connection. [[Saint Joseph's University]], 2005.
* Rachel Hall, ''[http://www.sju.edu/~rhall/Multi/rhythm2.pdf Hemachandra's application to Sanskrit poetry]'', (undated; 2005 or earlier).
* ''[https://web.archive.org/web/20090228042058/http://www.mcs.surrey.ac.uk/Personal/R.Knott/Fibonacci/fibInArt.html Fibonacci Numbers and The Golden Section in Art, Architecture and Music]'', which lists a number of academic sources.

{{Fibonacci}}

[[Category:Fibonacci numbers]]
[[Category:Mathematics-related topics in popular culture]]</text>
      <sha1>5xvwtkcab8wqoqgnbr126dtexvc2ww7</sha1>
    </revision>
  </page>
  <page>
    <title>First case of Fermat's Last Theorem</title>
    <ns>0</ns>
    <id>35735143</id>
    <revision>
      <id>608365100</id>
      <parentid>590425961</parentid>
      <timestamp>2014-05-13T11:39:56Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <minor/>
      <comment>/* References */Added 5 dois to journal cites using [[Project:AWB|AWB]] (10159)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3110">The first case of [[Fermat's last theorem]] says that for three integers ''x'', ''y'' and ''z'' and a [[prime number]] ''p'', where ''p'' does not divide the [[Product (mathematics)|product]] ''xyz'', there are no solutions to the [[equation]] ''x&lt;sup&gt;p&lt;/sup&gt;'' + ''y&lt;sup&gt;p&lt;/sup&gt;'' + ''z&lt;sup&gt;p&lt;/sup&gt;'' = 0.

Using the [[Fundamental theorem of ideal theory in number fields|Theorem of unique factorization of ideals in '''Q'''(ξ)]] it was shown that if the first case has solutions ''x'', ''y'', ''z'', then ''x''+''y''+''z'' is divisible by ''p'' and (''x'', ''y''), (''y'', ''z'') and (''z'', ''x'') are elements of ''H&lt;sub&gt;p&lt;/sub&gt;'', where ''H&lt;sub&gt;p&lt;/sub&gt;'' denotes a set of pairs of integers with special properties.&lt;ref name="Granville, Monagan"&gt;{{Citation | first1=A. | last1=Granville | first2=M. B. | last2=Monagan | title=The First Case of Fermat's Last Theorem is true for all prime exponents up to 714,591,416,091,389 | journal=Transactions of the American Mathematical Society | volume=306 | issue=1 | year=1988 | pages=329–359 | doi=10.1090/S0002-9947-1988-0927694-5 | postscript=.}}&lt;/ref&gt;

==Notes==
{{Reflist}}

==References==
* 
* {{Citation | last=Coppersmith | first=D. | authorlink=Don Coppersmith | title=Fermat's Last Theorem (Case I) and the Wieferich Criterion | journal=Math. Comp.  | volume=54 | issue=190  | pages=895–902 | publisher=[[American Mathematical Society|AMS]] | year=1990  | jstor=2008518 |url=http://www.ams.org/journals/mcom/1990-54-190/S0025-5718-1990-1010598-2/S0025-5718-1990-1010598-2.pdf | postscript=. | doi=10.1090/s0025-5718-1990-1010598-2}}
* {{Citation | last=Cikánek | first=P. | title=A Special Extension of Wieferich's Criterion  | journal=Math. Comp.  | volume=62  | issue=206 | pages=923–930 | jstor=3562296 | publisher=[[American Mathematical Society|AMS]] | year=1994 | url=http://www.ams.org/journals/mcom/1994-62-206/S0025-5718-1994-1216257-9/S0025-5718-1994-1216257-9.pdf | postscript=. | doi=10.2307/2153550}}
* {{Citation | last1=Dilcher | first1=K. | last2=Skula | first2=L. | title=A new criterion for the first case of Fermat's last theorem | journal=Math. Comp. | volume=64 | issue=209 | pages=363–392 | jstor=2153341 | publisher=AMS | year=1995 | doi=10.1090/s0025-5718-1995-1248969-6}}
* {{Citation | last1=Lehmer | first1=D. H. | last2=Lehmer | first2=E. | title=On the first case of Fermat's last theorem | journal=Bull. Amer. Math. Soc. | volume=47 | issue=2 | pages=139–142 | year=1941 | url=http://projecteuclid.org/euclid.bams/1183503473 | doi=10.1090/s0002-9904-1941-07393-3}}
* {{Citation | last=Rosser | first=B. | title=On the first case of Fermat's last theorem | journal=Bull. Amer. Math. Soc. | volume=45 | issue=8 | pages=636–640 | year=1939 | url=http://projecteuclid.org/euclid.bams/1183502014 | doi=10.1090/s0002-9904-1939-07058-4}}
* {{Citation | last=Jha | first=V. | title=On Krasnér's theorem for the first case of Fermat's last theorem | journal=Colloqium Mathematicum | volume=67  | pages=25–31 | year=1994 | url=http://matwbn.icm.edu.pl/ksiazki/cm/cm67/cm6714.pdf}}


[[Category:Fermat's Last Theorem]]</text>
      <sha1>ijxfv7miepqs81bvt3813p9erwwdpue</sha1>
    </revision>
  </page>
  <page>
    <title>Ghost Leg</title>
    <ns>0</ns>
    <id>6838326</id>
    <revision>
      <id>846555789</id>
      <parentid>829303075</parentid>
      <timestamp>2018-06-19T13:47:29Z</timestamp>
      <contributor>
        <username>WereSpielChequers</username>
        <id>4071608</id>
      </contributor>
      <minor/>
      <comment>/* In popular culture */[[WP:AWB/T|Typo fixing]], replaced: trough → through using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11994">{{Refimprove|date=June 2013}}
[[Image:Amidakuji2.png|thumb|right|243px|An example of how an amidakuji can be used.]]
'''Ghost Leg''' ({{zh|畫鬼腳}}), known in Japan as '''{{nihongo|Amidakuji|阿弥陀籤||"[[Amitābha|Amida]] lottery", so named because the paper was folded into a fan shape resembling Amida's halo&lt;ref&gt;https://books.google.com/books?id=p2QnPijAEmEC&amp;pg=PA28&amp;lpg=PA28&amp;dq=amidakuji+amitabha&amp;source=bl&amp;ots=gZKuvAdnqX&amp;sig=KaJfqNEWjHnoy6Z0A0tGHTlc3Z8&amp;hl=en&amp;sa=X&amp;ei=fiXAVJCwAcfCgwS-hIRA&amp;ved=0CDYQ6AEwBA#v=onepage&amp;q=amidakuji%20amitabha&amp;f=false&lt;/ref&gt;}}''' or in Korea as '''Sadaritagi''' (사다리타기, literally "ladder climbing"), is a method of lottery designed to create random pairings between two sets of any number of things, as long as the number of elements in each set is the same.  This is often used to distribute things among people, where the number of things distributed is the same as the number of people.  For instance, chores or prizes could be assigned fairly and randomly this way.

It consists of vertical lines with horizontal lines connecting two adjacent vertical lines scattered randomly along their length; the horizontal lines are called "legs".  The number of vertical lines equals the number of people playing, and at the bottom of each line there is an item - a thing that will be paired with a player.  The general rule for playing this game is: choose a line on the top, and follow this line downwards.  When a horizontal line is encountered, follow it to get to another vertical line and continue downwards.  Repeat this procedure until reaching the end of the vertical line.  Then the player is given the thing written at the bottom of the line.

If the elements written above the Ghost Leg are treated as a [[sequence]], and after the Ghost Leg is used, the same elements are written at the bottom, then the starting [[sequence]] has been transformed to another [[permutation]].  Hence, Ghost Leg can be treated as a kind of permuting operator.

==Process==
As an example, consider assigning roles in a play to actors.

# To start with, the two sets are enumerated horizontally across a board. The actors' names would go on top, and the roles on the bottom.  Then, vertical lines are drawn connecting each actor with the role directly below it.
# The names of the actors and/or roles are then concealed so that people do not know which actor is on which line, or which role is on which line.
# Next, each actor adds a leg to the board. Each leg must connect two adjacent vertical lines, and must not touch any other horizontal line.
# Once this is done, a path is traced from top of each vertical line to the bottom. As you follow the line down, if you come across a leg, you must follow it to the adjacent vertical line on the left or right, then resume tracing down. You continue until you reach the bottom of a vertical line, and the top item you started from is now paired with the bottom item you ended on.

Another process involves creating the ladder beforehand, then concealing it.  Then people take turns choosing a path to start from at the top.  If no part of the amidakuji is concealed, then it is possible to fix the system so that you are guaranteed to get a certain pairing, thus defeating the idea of random chance.

==Mathematics==
Part of the appeal for this game is that, unlike random chance games like [[rock, paper, scissors]], amidakuji will always create a 1:1 correspondence, and can handle arbitrary numbers of pairings (although pairing sets with only two items each would be fairly boring).  It is guaranteed that two items at the top will never have the same corresponding item at the bottom, nor will any item on the bottom ever lack a corresponding item at the top.

It also works regardless of how many horizontal lines are added. Each person could add one, two, three, or any number of lines, and the 1:1 correspondence would remain.

One way of realizing how this works is to consider the analogy of coins in cups.  You have ''n'' coins in ''n'' cups, representing the items at the bottom of the amidakuji.  Then, each leg that is added represents swapping the position of two adjacent cups.  Thus, it is obvious that in the end there will still be ''n'' cups, and each cup will have one coin, regardless of how many swaps you perform.

==Properties==

===Permutation===
A Ghost Leg transforms an input sequence into an output sequence with the same number of elements with (possibly) different order.
Thus, it can be regarded a permutation of ''n'' symbols, where ''n'' is the number of vertical lines in the Ghost Leg.,&lt;ref&gt;Ho 2012, p.31&lt;/ref&gt; hence it can be represented by the corresponding [[permutation matrix]].

===Periodicity===
Applying a Ghost Leg a finite number of times to an input sequence eventually generates an output sequence identical to the original input sequence.

i.e. If '''M''' is a matrix representing a particular Ghost Leg, then '''M'''&lt;sup&gt;''n''&lt;/sup&gt;='''I''' for some finite ''n''.

===Reversibility===
For any Ghost Leg with matrix representation '''M''', there exists a Ghost Leg with representation '''M'''&lt;sup&gt;−1&lt;/sup&gt;,
such that '''M''' '''M'''&lt;sup&gt;−1&lt;/sup&gt;='''I'''

===Odd/Even property of permutation===
As each leg exchanges the two neighboring elements at its ends, the number of legs indicates the [[Parity of a permutation|odd/even permutation]] property of the Ghost Leg. An odd number of legs represents an odd permutation, and an even number of legs gives an even permutation.

===Infinite Ghost Legs with same permutation===
It is possible to express every permutation as a Ghost Leg, but the expression is not one-to-one, i.e. a particular permutation does not correspond to a unique Ghost Leg.
An infinite number of Ghost Legs represents the same permutation.

==Prime==
As there are an infinite number of Ghost Legs representing a particular permutation, it is obvious those Ghost Legs have a kind of equivalence.  Among those equivalent Ghost Legs, the one(ones) which have smallest number of legs are called Prime.

===Bubble sort and highest simplicity===
A Ghost Leg can be constructed arbitrarily, but such a Ghost Leg is not necessarily prime.  It can be proven that only those Ghost Legs constructed by [[bubble sort]] contains the least number of legs, and hence is prime.  This is equivalent to saying that bubble sort performs the minimum number of adjacent exchanges to sort a sequence.

===Maximum number of legs of prime===
For a permutation with ''n'' elements, the maximum number of neighbor exchanging = &lt;math&gt;\frac{n(n-1)}{2}&lt;/math&gt;

In the same way, the maximum number of legs in a prime with ''n'' tracks = &lt;math&gt;\frac{n(n-1)}{2}&lt;/math&gt;

===Bubblization===
For an arbitrary Ghost Leg, it is possible to transform it into prime by a procedure called '''bubblization'''.
When bubblization operates, the following two identities are repeatedly applied in order to move and eliminate "useless" legs.
#[[Image:GhostLeg4.svg|64 px]] ⇒ [[Image:GhostLeg5.svg|64 px]]
#[[Image:GL6.svg|64 px]] ⇒ [[Image:GhostLeg7.svg|64 px]]

When the two identities cannot be applied any more, the ghost leg is proven to be exactly the same as the Ghost Leg constructed by [[bubble sort]], thus bubblization can reduce Ghost Legs to primes.

==Randomness==
Since, as mentioned above, an odd number of legs produces an [[Parity of a permutation|odd permutation]] and an even number of legs produces an even permutation, a given number of legs can produce a maximum of half the total possible permutations (less than half if the number of legs is small relative to the number of tracks, reaching half as the number of legs increases beyond a certain critical number).

If the legs are drawn randomly (for reasonable definitions of "drawn randomly"), the evenness of the distribution of permutations increases with the number of legs. If the number of legs is small relative to number of tracks, the probabilities of different attainable permutations may vary greatly; for large numbers of legs the probabilities of different attainable permutations approach equality.

== In popular culture ==
{{In popular culture|date=August 2017}}
The 1981 arcade game [[Amidar]] programmed by [[Konami]] and published by [[Stern (game company)|Stern]] used the same lattice as a maze. The game even took its name from Amidakuji and most of the enemy movement conformed to the lot drawing game's rules

An early [[Sega Master System]] game called ''[[Psycho Fox]]'' uses the mechanics of an Amidakuji board as a means to bet a bag of coins on a chance at a prize at the top of the screen. Later [[Sega Genesis]] games based on the same game concept [[DecapAttack]] and its Japanese predecessor "Magical Hat no Buttobi Tabo! Daibōken" follow the same game mechanics, including the Amidakuji bonus levels. 

''[[Super Mario Land 2: 6 Golden Coins]]'' features an Amidakuji-style bonus game that rewards the player with a power-up. ''[[New Super Mario Bros.]]'' and ''[[Wario: Master of Disguise]]'' feature an Amidakuji-style minigame in which the player uses the [[Nintendo DS|stylus]] to trace lines that will lead the character down the right path.

In ''[[Mario Party]]'' there is a mini game where one of the four players pours money into an Amidakuji made out of pipes. The goal is to try to choose the path leading to the character controlled by the player.

The BoSpider in ''[[Mega Man X (video game)|Mega Man X]]'' and ''[[Mega Man X (video game)#Mega Man Maverick Hunter X|Maverick Hunter X]]'' descends onto the player via an Amidakuji path.

In ''[[Super Monkey Ball 2]]'', there is a level in the Advanced-Extra difficulty named "Amida Lot" (Advanced-EX 7) that features a floor resembling an Amidakuji board, which bumper travels around the way and may knock off the player if they happen to hit them. The goal only travels through one of the vertical lines and the player must reach the goal using the ghost legs while avoiding the bumpers to not fall out.

In ''[[WarioWare, Inc.: Mega Microgames!]]'', the microgame "Noodle Cup" features Amidakuji-style gameplay.

Azalea Gym in [[Pokémon HeartGold and SoulSilver|''Pokémon HeartGold'' and ''SoulSilver'']] was redesigned with an Amidakuji-based system of carts to cross.  The correct choices lead to the gym leader; the wrong ones lead to other trainers to fight.

''[[Phantasy Star Online 2]]'' uses the principle of Amidakuji for a randomly appearing bomb-defusing minigame. One must trace an Amidakuji path around each bomb to determine which button defuses it; incorrect selections knock players away for a few seconds, wasting time.

In the manga ''[[Liar Game]]'' (vol 17), an Amidakuji is used for determinate the rank of each participant to the penultimate stage of the game.

In the Japanese drama ''[[Don Quixote (TV series)|Don Quixote]]'' (episode 10), the character Shirota ([[Shota Matsuda]]) uses Amidakuji to help decide between candidate families for an adoption.

In the anime ''[[Cardcaptor Sakura]]'' (episode 41), the character [[List of Cardcaptor Sakura characters#Kaho Mizuki|Kaho Mizuki]], Sakura's teacher, uses Amidakuji in order to choose which student will play each role in a certain school play.

In the anime '' [[Magic Kyun Renassiance]]'' (episode 10), the characters used Amidakuji to determine which rooms they'd get while at the villa after the Art Session.

==Notes==
{{Reflist}}

==External links==
{{commons category|Ghost leg}}
* https://www.webcitation.org/query?url=http://www.geocities.com/Athens/Acropolis/7247/amidakuji.html&amp;date=2009-10-25+05:45:20
* [http://www2.edc.org/makingmath/studentWork/amidaKuji/AmidaKujiByDavidSenft.pdf Ladders: A Research Paper by David Senft] (PDF)
* Man-Kit Ho, Hoi-Kwan Lau, Ting-Fai Man, Shek Yeung (2012). "Ghost Leg", ''Hang Lung Mathematics Awards Collection of Winning Papers, 2004''. International Press. {{ISBN|978-1-57146-254-1}}.

[[Category:Mathematical games]]
[[Category:Permutations]]
[[Category:Japanese games]]</text>
      <sha1>pkg8tjsn9dbqepeqyozbyj3ch0y1pv7</sha1>
    </revision>
  </page>
  <page>
    <title>Half-precision floating-point format</title>
    <ns>0</ns>
    <id>23552810</id>
    <revision>
      <id>871230001</id>
      <parentid>871229061</parentid>
      <timestamp>2018-11-29T19:19:56Z</timestamp>
      <contributor>
        <username>Pjacklam</username>
        <id>131168</id>
      </contributor>
      <comment>/* Half precision examples */ Add subscripts and hex representations</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13946">In [[computing]], '''half precision''' is a [[binary (computing)|binary]] [[floating-point]] [[computer number format]] that occupies [[16 bit]]s (two bytes in modern computers) in [[computer memory]].

In the [[IEEE 754-2008]] standard, the 16-bit [[radix|base-2]] format is referred to as '''binary16'''. It is intended for storage of floating-point values in applications where higher precision is not essential for performing arithmetic computations.

Although implementations of the IEEE Half-precision floating point are relatively new, several earlier 16-bit floating point formats have existed including that of Hitachi's HD61810 DSP&lt;ref&gt;{{cite web|url=https://archive.org/details/bitsavers_hitachidatlSignalProcessorUsersManual_4735688 |title=hitachi :: dataBooks :: HD61810 Digital Signal Processor Users Manual |website=Archive.org |date= |accessdate=2017-07-14}}&lt;/ref&gt; of 1982, Scott's WIF&lt;ref&gt;{{cite journal|last1=Scott|first1=Thomas J.|title=Mathematics and Computer Science at Odds over Real Numbers|journal=SIGCSE '91 Proceedings of the twenty-second SIGCSE technical symposium on Computer science education|date=March 1991|volume=23|issue=1|pages=130–139|url=https://dl.acm.org/citation.cfm?id=107029}}&lt;/ref&gt; and the [[3dfx Interactive|3dfx Voodoo Graphics processor]].&lt;ref&gt;{{cite web|url=http://www.gamers.org/dEngine/xf3D/glide/glidepgm.htm |title=/home/usr/bk/glide/docs2.3.1/GLIDEPGM.DOC |website=Gamers.org |date= |accessdate=2017-07-14}}&lt;/ref&gt;

[[Nvidia]] and [[Microsoft]] defined the '''half''' [[datatype]] in the [[Cg (programming language)|Cg language]], released in early 2002, and implemented it in silicon in the [[GeForce FX]], released in late 2002.&lt;ref&gt;{{cite web|title=vs_2_sw|url=https://developer.download.nvidia.com/cg/vs_2_sw.html|website=Cg 3.1 Toolkit Documentation|publisher=Nvidia|accessdate=17 August 2016}}&lt;/ref&gt; [[Industrial Light &amp; Magic|ILM]] was searching for an image format that could handle a wide [[dynamic range]], but without the hard drive and memory cost of floating-point representations that are commonly used for floating-point computation (single and double precision).&lt;ref name="exr"&gt;{{cite web|url=http://www.openexr.com/about.html |title=OpenEXR |publisher=OpenEXR |date= |accessdate=2017-07-14}}&lt;/ref&gt; The hardware-accelerated programmable shading group led by John Airey at [[Silicon Graphics|SGI (Silicon Graphics)]] invented the s10e5 data type in 1997 as part of the 'bali' design effort. This is described in a [[SIGGRAPH]] 2000 paper&lt;ref name="sgi"&gt;{{cite web|url=https://people.csail.mit.edu/ericchan/bib/pdf/p425-peercy.pdf |format=PDF |title=Interactive Multi-Pass Programmable Shading |author1=Mark S. Peercy |author2=Marc Olano |author3=John Airey |author4=P. Jeffrey Ungar |website=People.csail.mit.edu |accessdate=2017-07-14}}&lt;/ref&gt; (see section 4.3) and further documented in US patent 7518615.&lt;ref name="patent"&gt;{{cite web|url=https://www.google.com/patents/US7518615 |title=Patent US7518615 - Display system having floating point rasterization and floating point ... - Google Patents |website=Google.com |date= |accessdate=2017-07-14}}&lt;/ref&gt;

This format is used in several [[computer graphics]] environments including [[OpenEXR]], [[JPEG XR]], [[GIMP]], [[OpenGL]], [[Cg (programming language)|Cg]], and [[D3DX]].  The advantage over 8-bit or 16-bit binary integers is that the increased [[dynamic range]] allows for more detail to be preserved in highlights and [[shadow]]s for images.  The advantage over 32-bit [[single-precision]] binary formats is that it requires half the storage and [[bandwidth (computers)|bandwidth]] (at the expense of precision and range).&lt;ref name="exr"/&gt;

The [[F16C]] extension allows x86 processors to convert half-precision floats to and from [[Single-precision floating-point format|single-precision floats]].

{{Floating-point}}

== IEEE 754 half-precision binary floating-point format: binary16 ==
&lt;!-- "significand", with a d at the end, is a technical term, please do not confuse with "significant" --&gt;

The IEEE 754 standard specifies a '''binary16''' as having the following format:
* [[Sign bit]]: 1 bit
* [[Exponent]] width: 5 bits
* [[Significand]] [[precision (arithmetic)|precision]]: 11 bits (10 explicitly stored)

The format is laid out as follows:

[[File:IEEE 754r Half Floating Point Format.svg]]

The format is assumed to have an implicit lead bit with value 1 unless the exponent field is stored with all zeros. Thus only 10 bits of the [[significand]] appear in the memory format but the total precision is 11 bits. In IEEE 754 parlance, there are 10 bits of significand, but there are 11 bits of significand precision (log&lt;sub&gt;10&lt;/sub&gt;(2&lt;sup&gt;11&lt;/sup&gt;) ≈ 3.311 decimal digits, or 4 digits ± slightly less than 5 [[unit in the last place|units in the last place]]).

=== Exponent encoding ===
The half-precision binary floating-point exponent is encoded using an [[offset-binary]] representation, with the zero offset being 15; also known as exponent bias in the IEEE 754 standard.

* E&lt;sub&gt;min&lt;/sub&gt; = 00001&lt;sub&gt;2&lt;/sub&gt; − 01111&lt;sub&gt;2&lt;/sub&gt; = −14
* E&lt;sub&gt;max&lt;/sub&gt; = 11110&lt;sub&gt;2&lt;/sub&gt; − 01111&lt;sub&gt;2&lt;/sub&gt; = 15
* [[Exponent bias]] = 01111&lt;sub&gt;2&lt;/sub&gt; = 15

Thus, as defined by the offset binary representation, in order to get the true exponent the offset of 15 has to be subtracted from the stored exponent.

The stored exponents 00000&lt;sub&gt;2&lt;/sub&gt; and 11111&lt;sub&gt;2&lt;/sub&gt; are interpreted specially.

{|class="wikitable" style="text-align:center"
|-
! Exponent !! Significand = zero !! Significand ≠ zero !! Equation
|-
| 00000&lt;sub&gt;2&lt;/sub&gt; || [[0 (number)|zero]], [[−0]] || [[subnormal numbers]] || (−1)&lt;sup&gt;signbit&lt;/sup&gt; × 2&lt;sup&gt;−14&lt;/sup&gt; × 0.significantbits&lt;sub&gt;2&lt;/sub&gt;
|-
| 00001&lt;sub&gt;2&lt;/sub&gt;, ..., 11110&lt;sub&gt;2&lt;/sub&gt; ||colspan=2| normalized value || (−1)&lt;sup&gt;signbit&lt;/sup&gt; × 2&lt;sup&gt;exponent−15&lt;/sup&gt; × 1.significantbits&lt;sub&gt;2&lt;/sub&gt;
|-
| 11111&lt;sub&gt;2&lt;/sub&gt; || ±[[infinity]] || [[NaN]] (quiet, signalling) ||
|}

The minimum strictly positive (subnormal) value is
2&lt;sup&gt;−24&lt;/sup&gt; ≈ 5.96 × 10&lt;sup&gt;−8&lt;/sup&gt;.
The minimum positive normal value is 2&lt;sup&gt;−14&lt;/sup&gt; ≈ 6.10 × 10&lt;sup&gt;−5&lt;/sup&gt;.
The maximum representable value is (2−2&lt;sup&gt;−10&lt;/sup&gt;) × 2&lt;sup&gt;15&lt;/sup&gt; = 65504.

=== Half precision examples ===
These examples are given in bit representation
of the floating-point value. This includes the sign bit, (biased) exponent, and significand.

 0 00000 0000000001&lt;sub&gt;2&lt;/sub&gt; = 0001&lt;sub&gt;16&lt;/sub&gt; = 2&lt;sup&gt;−14&lt;/sup&gt; × 2&lt;sup&gt;−10&lt;/sup&gt; = 2&lt;sup&gt;−24&lt;/sup&gt; ≈ 0.000000059605
                               (smallest positive subnormal number)

 0 00000 1111111111&lt;sub&gt;2&lt;/sub&gt; = 03ff&lt;sub&gt;16&lt;/sub&gt; = 2&lt;sup&gt;−14&lt;/sup&gt; × (1 − 2&lt;sup&gt;−10&lt;/sup&gt;) ≈ 0.000060976
                               (largest subnormal number)

 0 00001 0000000000&lt;sub&gt;2&lt;/sub&gt; = 0400&lt;sub&gt;16&lt;/sub&gt; = 2&lt;sup&gt;−14&lt;/sup&gt; ≈ 0.000061035
                               (smallest positive normal number)

 0 11110 1111111111&lt;sub&gt;2&lt;/sub&gt; = 7bff&lt;sub&gt;16&lt;/sub&gt; = 2&lt;sup&gt;15&lt;/sup&gt; × (2 − 2&lt;sup&gt;−10&lt;/sup&gt;) ≈ 65504
                               (largest normal number)

 0 01110 1111111111&lt;sub&gt;2&lt;/sub&gt; = 3bff&lt;sub&gt;16&lt;/sub&gt; = 1 − 2&lt;sup&gt;−11&lt;/sup&gt; ≈ 0.99951
                               (largest number less than one)

 0 01111 0000000000&lt;sub&gt;2&lt;/sub&gt; = 3c00&lt;sub&gt;16&lt;/sub&gt; = 1 (one)

 0 01111 0000000001&lt;sub&gt;2&lt;/sub&gt; = 3c01&lt;sub&gt;16&lt;/sub&gt; = 1 + 2&lt;sup&gt;−10&lt;/sup&gt; ≈ 1.001
                               (smallest number larger than one)

 1 10000 0000000000&lt;sub&gt;2&lt;/sub&gt; = c000&lt;sub&gt;16&lt;/sub&gt; = −2
 
 0 00000 0000000000&lt;sub&gt;2&lt;/sub&gt; = 0000&lt;sub&gt;16&lt;/sub&gt; = 0
 1 00000 0000000000&lt;sub&gt;2&lt;/sub&gt; = 8000&lt;sub&gt;16&lt;/sub&gt; = −0
 
 0 11111 0000000000&lt;sub&gt;2&lt;/sub&gt; = 7c00&lt;sub&gt;16&lt;/sub&gt; = infinity
 1 11111 0000000000&lt;sub&gt;2&lt;/sub&gt; = fc00&lt;sub&gt;16&lt;/sub&gt; = −infinity
 
 0 01101 0101010101&lt;sub&gt;2&lt;/sub&gt; = 3555&lt;sub&gt;16&lt;/sub&gt; = 0.333251953125 ≈ 1/3

By default, 1/3 rounds down like for [[double precision]], because of the odd number of bits in the significand. So the bits beyond the rounding point are &lt;code&gt;0101...&lt;/code&gt; which is less than 1/2 of a [[unit in the last place]].

=== Precision limitations on decimal values in [0, 1] ===
* Decimals between 2&lt;sup&gt;−24&lt;/sup&gt; (minimum positive subnormal) and 2&lt;sup&gt;−14&lt;/sup&gt; (maximum subnormal): fixed interval 2&lt;sup&gt;−24&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−14&lt;/sup&gt; (minimum positive normal) and 2&lt;sup&gt;−13&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−24&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−13&lt;/sup&gt; and 2&lt;sup&gt;−12&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−23&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−12&lt;/sup&gt; and 2&lt;sup&gt;−11&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−22&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−11&lt;/sup&gt; and 2&lt;sup&gt;−10&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−21&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−10&lt;/sup&gt; and 2&lt;sup&gt;−9&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−20&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−9&lt;/sup&gt; and 2&lt;sup&gt;−8&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−19&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−8&lt;/sup&gt; and 2&lt;sup&gt;−7&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−18&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−7&lt;/sup&gt; and 2&lt;sup&gt;−6&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−17&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−6&lt;/sup&gt; and 2&lt;sup&gt;−5&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−16&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−5&lt;/sup&gt; and 2&lt;sup&gt;−4&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−15&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−4&lt;/sup&gt; and 2&lt;sup&gt;−3&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−14&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−3&lt;/sup&gt; and 2&lt;sup&gt;−2&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−13&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−2&lt;/sup&gt; and 2&lt;sup&gt;−1&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−12&lt;/sup&gt;
* Decimals between 2&lt;sup&gt;−1&lt;/sup&gt; and 2&lt;sup&gt;−0&lt;/sup&gt;: fixed interval 2&lt;sup&gt;−11&lt;/sup&gt;

=== Precision limitations on decimal values in [1, 2048] ===
* Decimals between 1 and 2: fixed interval 2&lt;sup&gt;−10&lt;/sup&gt; (1+2&lt;sup&gt;−10&lt;/sup&gt; is the next largest float after 1)
* Decimals between 2 and 4: fixed interval 2&lt;sup&gt;−9&lt;/sup&gt;
* Decimals between 4 and 8: fixed interval 2&lt;sup&gt;−8&lt;/sup&gt;
* Decimals between 8 and 16: fixed interval 2&lt;sup&gt;−7&lt;/sup&gt;
* Decimals between 16 and 32: fixed interval 2&lt;sup&gt;−6&lt;/sup&gt;
* Decimals between 32 and 64: fixed interval 2&lt;sup&gt;−5&lt;/sup&gt;
* Decimals between 64 and 128: fixed interval 2&lt;sup&gt;−4&lt;/sup&gt;
* Decimals between 128 and 256: fixed interval 2&lt;sup&gt;−3&lt;/sup&gt;
* Decimals between 256 and 512: fixed interval 2&lt;sup&gt;−2&lt;/sup&gt;
* Decimals between 512 and 1024: fixed interval 2&lt;sup&gt;−1&lt;/sup&gt;
* Decimals between 1024 and 2048: fixed interval 2&lt;sup&gt;0&lt;/sup&gt;

=== Precision limitations on integer values ===
* Integers between 0 and 2048 can be exactly represented (and also between −2048 and 0)
* Integers between 2048 and 4096 round to a multiple of 2 (even number)
* Integers between 4096 and 8192 round to a multiple of 4
* Integers between 8192 and 16384 round to a multiple of 8
* Integers between 16384 and 32768 round to a multiple of 16
* Integers between 32768 and 65519 round to a multiple of 32&lt;ref&gt;{{cite web|title=Mediump float calculator|trans-title=|periodical=|publisher=|url=https://oletus.github.io/float16-simulator.js/|format=|accessdate=2016-07-26|last=|date=|year=|month=|day=|language=|pages=|quote=}}&amp;#32;Half precision floating point calculator&lt;/ref&gt;
* Integers equal to or above 65520 are rounded to "infinity" (if using round-to-even, or equal to or above 65536 if using round-to-zero, or strictly above 65504 if using round-to-infinity).

== ARM alternative half-precision ==
ARM processors support (via a floating point [[control register]] bit) an "alternative half-precision" format, which does away with the special case for an exponent value of 31 (11111&lt;sub&gt;2&lt;/sub&gt;).&lt;ref&gt;{{cite book |chapter-url=http://infocenter.arm.com/help/topic/com.arm.doc.dui0205j/CIHGAECI.html |title=RealView Compilation Tools Compiler User Guide |chapter= Half-precision floating-point number support |date=10 December 2010 |accessdate=2015-05-05}}&lt;/ref&gt;  It is almost identical to the IEEE format, but there is no encoding for infinity or NaNs; instead, an exponent of 31 encodes normalized numbers in the range 65536 to 131008.

== See also ==
* [[bfloat16 floating-point format]]: Alternative 16-bit floating-point format with 8 bits of exponent and 7 bits of mantissa
* [[IEEE 754]]:  IEEE standard for floating-point arithmetic (IEEE 754)
* [[ISO/IEC 10967]], Language Independent Arithmetic
* [[Primitive data type]]
* [[RGBE image format]]

== References ==
{{Reflist}}

== Further reading ==
* [https://www.khronos.org/registry/DataFormat/specs/1.2/dataformat.1.2.html#16bitfp Khronos Vulkan signed 16-bit floating point format]

== External links ==
{{External links|date=July 2017}}
* [https://www.mrob.com/pub/math/floatformats.html#minifloat Minifloats] (in ''Survey of Floating-Point Formats'')
* [http://www.openexr.org/ OpenEXR site]
* [https://technet.microsoft.com/en-us/library/bb147247(v=vs.85).aspx Half precision constants] from [[D3DX]]
* [https://oss.sgi.com/projects/ogl-sample/registry/ARB/half_float_pixel.txt OpenGL treatment of half precision]
* [ftp://ftp.fox-toolkit.org/pub/fasthalffloatconversion.pdf Fast Half Float Conversions]
* [http://www.analog.com/static/imported-files/processor_manuals/ADSP_2136x_PGR_rev1-1.pdf Analog Devices variant]{{dead link|date=October 2017 |bot=InternetArchiveBot |fix-attempted=yes }} (four-bit exponent)
* [https://www.mathworks.com/matlabcentral/fileexchange/23173 C source code to convert between IEEE double, single, and half precision can be found here]
* [http://csharp-half.svn.sourceforge.net/viewvc/csharp-half/ C# source code implementing a half-precision floating-point data type can be found here]{{dead link |date=October 2018}}
* [https://stackoverflow.com/a/6162687/237321 Java source code for half-precision floating-point conversion]
* [https://gcc.gnu.org/onlinedocs/gcc/Half-Precision.html  Half precision floating point for one of the extended GCC features]

{{data types}}

{{DEFAULTSORT:Half-Precision Floating-Point Format}}
[[Category:Binary arithmetic]]
[[Category:Floating point types]]</text>
      <sha1>pz388o44k8hcwt0gesqhbmbu7vv3kqg</sha1>
    </revision>
  </page>
  <page>
    <title>Heron's formula</title>
    <ns>0</ns>
    <id>194123</id>
    <revision>
      <id>869317939</id>
      <parentid>869314283</parentid>
      <timestamp>2018-11-17T21:20:16Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/92.99.64.240|92.99.64.240]] ([[User talk:92.99.64.240|talk]]) to last version by Oiyarbepsy</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14416">{{about|calculating the area of a triangle|calculating a square root|Heron's method}}
[[Image:Triangle with notations 2.svg|thumb|198px|A triangle with sides ''a'', ''b'', and ''c''.]]
In [[geometry]], '''Heron's formula''' (sometimes called Hero's formula), named after [[Hero of Alexandria]],&lt;ref&gt;{{cite web|title=Fórmula de Herón para calcular el área de cualquier triángulo|url=http://recursostic.educacion.es/descartes/web/materiales_didacticos/formula_heron/formula_de_Heron.htm|language=Spanish|accessdate=30 June 2012}}&lt;/ref&gt; gives the [[area]] of a [[triangle]] when the length of all three sides are known. Unlike other formulas, there is no need to calculate other distances in the triangle first.

==Formulation==
Heron's formula states that the [[area]] of a [[triangle]] whose sides have lengths {{math|''a''}}, {{math|''b''}}, and {{math|''c''}} is

:&lt;math&gt;A = \sqrt{s(s-a)(s-b)(s-c)},&lt;/math&gt;

where {{math|''s''}} is the [[semiperimeter]] of the triangle; that is,

:&lt;math&gt;s=\frac{a+b+c}{2}.&lt;/math&gt;&lt;ref&gt;{{cite journal|author=Kendig, Keith|title=Is a 2000-Year-Old Formula Still Keeping Some Secrets?|journal=Amer. Math. Monthly|volume=107|year=2000|pages=402–415|url=http://www.maa.org/programs/maa-awards/writing-awards/is-a-2000-year-old-formula-still-keeping-some-secrets|doi=10.2307/2695295}}&lt;/ref&gt;

Heron's formula can also be written as

:&lt;math&gt;A=\frac{1}{4}\sqrt{(a+b+c)(-a+b+c)(a-b+c)(a+b-c)}&lt;/math&gt;
:&lt;math&gt;A=\frac{1}{4}\sqrt{2(a^2 b^2+a^2c^2+b^2c^2)-(a^4+b^4+c^4)}&lt;/math&gt;
:&lt;math&gt;A=\frac{1}{4}\sqrt{(a^2+b^2+c^2)^2-2(a^4+b^4+c^4)}&lt;/math&gt;
:&lt;math&gt;A=\frac{1}{4}\sqrt{4(a^2b^2+a^2c^2+b^2c^2)-(a^2+b^2+c^2)^2}.&lt;/math&gt;

==Example==

Let {{math|△''ABC''}} be the triangle with sides {{math|''a'' {{=}} 4}}, {{math|''b'' {{=}} 13}} and {{math|''c'' {{=}} 15}}. 
The semiperimeter is {{math|''s'' {{=}} {{sfrac|1|2}}(''a'' + ''b'' + ''c'') {{=}} {{sfrac|1|2}}(4 + 13 + 15) {{=}} 16}}, and the area is

:&lt;math&gt;
\begin{align}
A &amp;= \sqrt{s\left(s-a\right)\left(s-b\right)\left(s-c\right)} = \sqrt{16 \cdot (16-4) \cdot (16-13) \cdot (16-15)}\\
&amp;= \sqrt{16 \cdot 12 \cdot 3 \cdot 1} = \sqrt{576} = 24.
\end{align}
&lt;/math&gt;

In this example, the side lengths and area are all [[integer]]s, making it a [[Heronian triangle]]. However, Heron's formula works equally well in cases where one or all of these numbers is not an integer.

== History ==

The formula is credited to [[Hero of Alexandria|Heron (or Hero) of Alexandria]], and a proof can be found in his book, ''Metrica'', written {{circa}} CE 60. It has been suggested that [[Archimedes]] knew the formula over two centuries earlier,&lt;ref&gt;{{cite book
| author=Heath, Thomas L.
| title=A History of Greek Mathematics (Vol II)
| publisher=Oxford University Press
| year=1921
| pages=321–323}}&lt;/ref&gt; and since ''Metrica'' is a collection of the mathematical knowledge available in the ancient world, it is possible that the formula predates the reference given in that work.&lt;ref&gt;{{MathWorld |urlname=HeronsFormula |title=Heron's Formula}}&lt;/ref&gt;

A formula equivalent to Heron's, namely

:&lt;math&gt;A=\frac1{2}\sqrt{a^2c^2-\left(\frac{a^2+c^2-b^2}{2}\right)^2}&lt;/math&gt;, where {{math|''a'' ≥ ''b'' ≥ ''c''}},

was discovered by the Chinese independently{{citation needed|date=October 2017}} of the Greeks. It was published in ''Shushu Jiuzhang'' (“[[Mathematical Treatise in Nine Sections]]”), written by [[Qin Jiushao]] and published in 1247.

== Proofs ==
Heron's original proof made use of [[cyclic quadrilateral]]s, while other arguments appeal to [[trigonometry]] as below, or to the [[incenter]] and one [[excircle]] of the triangle [http://www.math.dartmouth.edu/~doyle/docs/heron/heron.txt].

===Trigonometric proof using the law of cosines===
A modern proof, which uses [[algebra]] and is quite unlike the one provided by Heron (in his book Metrica), follows.&lt;ref&gt;{{cite book
| author=Niven, Ivan
| title=Maxima and Minima Without Calculus
| publisher=The Mathematical Association of America
| year=1981
| pages=7–8}}&lt;/ref&gt;
Let {{math|''a''}}, {{math|''b''}}, {{math|''c''}} be the sides of the triangle and {{math|''α''}}, {{math|''β''}}, {{math|''γ''}} the [[angle]]s opposite those sides.
Applying the [[law of cosines]] we get

:&lt;math&gt;\cos \gamma = \frac{a^2+b^2-c^2}{2ab}&lt;/math&gt;

From this proof we get the algebraic statement that

:&lt;math&gt;\sin \gamma = \sqrt{1-\cos^2 \gamma} = \frac{\sqrt{4a^2 b^2 -(a^2 +b^2 -c^2)^2 }}{2ab}.&lt;/math&gt;

The [[altitude (triangle)|altitude]] of the triangle on base {{math|''a''}} has length {{math|''b'' sin ''γ''}}, and it follows

: &lt;math&gt;
\begin{align}
A &amp; = \frac{1}{2} (\mbox{base}) (\mbox{altitude}) \\
&amp; = \frac{1}{2} ab\sin \gamma \\
&amp; = \frac{1}{4}\sqrt{4a^2 b^2 -(a^2 +b^2 -c^2)^2} \\
&amp; = \frac{1}{4}\sqrt{(2a b -(a^2 +b^2 -c^2))(2a b +(a^2 +b^2 -c^2))} \\
&amp; = \frac{1}{4}\sqrt{(c^2 -(a -b)^2)((a +b)^2 -c^2)} \\
&amp; = \sqrt{\frac{(c -(a -b))(c +(a -b))((a +b) -c)((a +b) +c)}{16}} \\
&amp; = \sqrt{\frac{(b + c - a)}{2}\frac{(a + c - b)}{2}\frac{(a + b - c)}{2}\frac{(a + b + c)}{2}} \\
&amp; = \sqrt{\frac{(a + b + c)}{2}\frac{(b + c - a)}{2}\frac{(a + c - b)}{2}\frac{(a + b - c)}{2}} \\
&amp; = \sqrt{s(s-a)(s-b)(s-c)}.
\end{align}
&lt;/math&gt;

The [[difference of two squares]] factorization was used in two different steps.

===Algebraic proof using the Pythagorean theorem===
[[Image:Triangle with notations 3.svg|thumb|270px|Triangle with altitude {{math|''h''}} cutting base {{math|''c''}} into {{math|''d'' + (''c'' − ''d'')}}.]]
The following proof is very similar to one given by Raifaizen.&lt;ref&gt;{{Cite journal
  | last = Raifaizen
  | first = Claude H.
  | title = A Simpler Proof of Heron's Formula
  | journal = Mathematics Magazine
  | volume = 44
  | number = 1
  | pages = 27–28
  | year = 1971
}}&lt;/ref&gt;
By the [[Pythagorean theorem]] we have {{math|''b''{{sup|2}} {{=}} ''h''{{sup|2}} + ''d''{{sup|2}}}} and {{math|''a''{{sup|2}} {{=}} ''h''{{sup|2}} + (''c'' − ''d''){{sup|2}}}} according to the figure at the right. Subtracting these yields {{math|''a''{{sup|2}} − ''b''{{sup|2}} {{=}} ''c''{{sup|2}} − 2''cd''}}. This equation allows us to express {{math|''d''}} in terms of the sides of the triangle:
:&lt;math&gt;d=\frac{-a^2+b^2+c^2}{2c}&lt;/math&gt;
For the height of the triangle we have that {{math|''h''{{sup|2}} {{=}} ''b''{{sup|2}} − ''d''{{sup|2}}}}. By replacing {{math|''d''}} with the formula given above and applying the [[difference of squares]] identity we get
:&lt;math&gt;
\begin{align}
h^2 &amp; = b^2-\left(\frac{-a^2+b^2+c^2}{2c}\right)^2\\
&amp; = \frac{(2bc-a^2+b^2+c^2)(2bc+a^2-b^2-c^2)}{4c^2}\\
&amp; = \frac{((b+c)^2-a^2)(a^2-(b-c)^2)}{4c^2}\\
&amp; = \frac{(b+c-a)(b+c+a)(a+b-c)(a-b+c)}{4c^2}\\
&amp; = \frac{2(s-a)\cdot 2s\cdot 2(s-c)\cdot 2(s-b)}{4c^2}\\
&amp; = \frac{4s(s-a)(s-b)(s-c)}{c^2}
\end{align}
&lt;/math&gt;

We now apply this result to the formula that calculates the area of a triangle from its height:
:&lt;math&gt;
\begin{align}
A &amp; = \frac{ch}{2}\\
&amp; = \sqrt{\frac{c^2}{4}\cdot \frac{4s(s-a)(s-b)(s-c)}{c^2}}\\
&amp; = \sqrt{s(s-a)(s-b)(s-c)}
\end{align}
&lt;/math&gt;

===Trigonometric proof using the law of cotangents===
[[File:Herontriangle2greek.svg|thumb|270px|right|Geometrical significance of {{math|''s'' − ''a''}}, {{math|''s'' − ''b''}}, and {{math|''s'' − ''c''}}.  See the [[Law of cotangents]] for the reasoning behind this.]]
From the first part of the [[Law of cotangents]] proof,&lt;ref&gt;The second part of the Law of cotangents proof depends on Heron's formula itself, but this article depends only on the first part.&lt;/ref&gt; we have that the triangle's area is both
:&lt;math&gt;
\begin{align}
A &amp;= r\big((s-a) + (s-b) + (s-c)\big) = r^2\left(\frac{s-a}{r} + \frac{s-b}{r} + \frac{s-c}{r}\right) \\
&amp;= r^2\left(\cot{\frac{\alpha}{2}} + \cot{\frac{\beta}{2}} + \cot{\frac{\gamma}{2}}\right) \\
\end{align}
&lt;/math&gt;
and {{math|''A'' {{=}} ''rs''}}, but, since the sum of the half-angles is {{sfrac|{{pi}}|2}}, the [[Proofs of trigonometric identities#Miscellaneous -- the triple cotangent identity|triple cotangent identity]] applies, so the first of these is
:&lt;math&gt;
\begin{align}
A &amp;= r^2\left(\cot{\frac{\alpha}{2}} \cot{\frac{\beta}{2}} \cot{\frac{\gamma}{2}}\right) = r^2\left( \frac{s-a}{r}\cdot \frac{s-b}{r}\cdot \frac{s-c}{r}\right) \\
&amp;= \frac{(s-a)(s-b)(s-c)}{r} \\
\end{align}
&lt;/math&gt;

Combining the two, we get
:&lt;math&gt;A^2 = s(s-a)(s-b)(s-c)&lt;/math&gt;
from which the result follows.

== Numerical stability ==
Heron's formula as given above is [[Numerical stability|numerically unstable]] for triangles with a very small angle when using floating point arithmetic. A stable alternative&lt;ref&gt;{{cite book |author-first=Pat H. |author-last=Sterbenz |title=Floating-Point Computation |date=1974-05-01 |edition=1st |series=Prentice-Hall Series in Automatic Computation |publisher=[[Prentice Hall]] |location=Englewood Cliffs, New Jersey, USA |isbn=0-13-322495-3&lt;!-- 978-0-13-322495-5 --&gt;}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.cs.berkeley.edu/~wkahan/Triangle.pdf |title=Miscalculating Area and Angles of a Needle-like Triangle |author=William M. Kahan |date=24 March 2000}}&lt;/ref&gt; involves arranging the lengths of the sides so that {{math|''a'' ≥ ''b'' ≥ ''c''}} and computing
:&lt;math&gt;A = \frac{1}{4}\sqrt{(a+(b+c)) (c-(a-b)) (c+(a-b)) (a+(b-c))}.&lt;/math&gt;
The brackets in the above formula are required in order to prevent numerical instability in the evaluation.

==Other area formulae resembling Heron's formula==

Three other area formulae have the same structure as Heron's formula but are expressed in terms of different variables. First, denoting the medians from sides {{math|''a''}}, {{math|''b''}}, and {{math|''c''}} respectively as {{math|''m&lt;sub&gt;a&lt;/sub&gt;''}}, {{math|''m&lt;sub&gt;b&lt;/sub&gt;''}}, and {{math|''m&lt;sub&gt;c&lt;/sub&gt;''}} and their semi-sum {{math|{{sfrac|1|2}}(''m&lt;sub&gt;a&lt;/sub&gt;'' + ''m&lt;sub&gt;b&lt;/sub&gt;'' + ''m&lt;sub&gt;c&lt;/sub&gt;'')}} as {{math|''σ''}}, we have&lt;ref&gt;Benyi, Arpad, "A Heron-type formula for the triangle," ''Mathematical Gazette" 87, July 2003, 324–326.&lt;/ref&gt;
:&lt;math&gt;A = \frac{4}{3} \sqrt{\sigma (\sigma - m_a)(\sigma - m_b)(\sigma - m_c)}.&lt;/math&gt;

Next, denoting the altitudes from sides {{math|''a''}}, {{math|''b''}}, and {{math|''c''}} respectively as {{math|''h&lt;sub&gt;a&lt;/sub&gt;''}}, {{math|''h&lt;sub&gt;b&lt;/sub&gt;''}}, and {{math|''h&lt;sub&gt;c&lt;/sub&gt;''}}, and denoting the semi-sum of the reciprocals of the altitudes as {{math|''H'' {{=}} {{sfrac|1|2}}(''h''{{su|b=''a''|p=−1}} + ''h''{{su|b=''b''|p=−1}} + ''h''{{su|b=''c''|p=−1}})}} we have&lt;ref&gt;Mitchell, Douglas W., "A Heron-type formula for the reciprocal area of a triangle," ''Mathematical Gazette'' 89, November 2005, 494.&lt;/ref&gt;
:&lt;math&gt;A^{-1} = 4 \sqrt{H(H-h_a^{-1})(H-h_b^{-1})(H-h_c^{-1})}.&lt;/math&gt;

Finally, denoting the semi-sum of the angles' sines as {{math|''S'' {{=}} {{sfrac|1|2}}(sin ''α'' + sin ''β'' + sin ''γ'')}}, we have&lt;ref&gt;Mitchell, Douglas W., "A Heron-type area formula in terms of sines," ''Mathematical Gazette'' 93, March 2009, 108–109.&lt;/ref&gt;
:&lt;math&gt;A = D^{2} \sqrt{S(S-\sin \alpha)(S-\sin \beta)(S-\sin \gamma)}&lt;/math&gt;

where {{math|''D''}} is the diameter of the circumcircle: {{math|''D'' {{=}} {{sfrac|''a''|sin ''α''}} {{=}} {{sfrac|''b''|sin ''β''}} {{=}} {{sfrac|''c''|sin ''γ''}}}}.

== Generalizations ==
Heron's formula is a special case of [[Brahmagupta's formula]] for the area of a [[cyclic quadrilateral]]. Heron's formula and Brahmagupta's formula are both special cases of [[Bretschneider's formula]] for the area of a [[quadrilateral]]. Heron's formula can be obtained from Brahmagupta's formula or Bretschneider's formula by setting one of the sides of the quadrilateral to zero.

Heron's formula is also a special case of the [[trapezoid#Area|formula]] for the area of a trapezoid or trapezium based only on its sides. Heron's formula is obtained by setting the smaller parallel side to zero.

Expressing Heron's formula with a [[Cayley–Menger determinant]] in terms of the squares of the [[distance]]s between the three given vertices,
:&lt;math&gt; A =  \frac{1}{4} \sqrt{- \begin{vmatrix} 
  0 &amp; a^2 &amp; b^2 &amp; 1 \\
a^2 &amp; 0   &amp; c^2 &amp; 1 \\
b^2 &amp; c^2 &amp; 0   &amp; 1 \\
  1 &amp;   1 &amp;   1 &amp; 0
\end{vmatrix} } &lt;/math&gt;
illustrates its similarity to [[Tartaglia's formula]] for the [[volume]] of a [[Simplex|three-simplex]].

Another generalization of Heron's formula to pentagons and hexagons inscribed in a circle was discovered by [[David P. Robbins]].&lt;ref&gt;D. P. Robbins, "Areas of Polygons Inscribed in a Circle", Discr. Comput. Geom. 12, 223-236, 1994.&lt;/ref&gt;

=== Heron-type formula for the volume of a tetrahedron ===
If {{math|''U''}}, {{math|''V''}}, {{math|''W''}}, {{math|''u''}}, {{math|''v''}}, {{math|''w''}} are lengths of edges of the tetrahedron (first three form a triangle; {{math|''u''}} opposite to {{math|''U''}} and so on), then&lt;ref&gt;W. Kahan, "What has the Volume of a Tetrahedron to do with Computer Programming Languages?", [http://www.cs.berkeley.edu/~wkahan/VtetLang.pdf], pp.&amp;nbsp;16–17.&lt;/ref&gt;
:&lt;math&gt;
\text{volume} = \frac{\sqrt {\,( - a + b + c + d)\,(a - b + c + d)\,(a + b - c + d)\,(a + b + c - d)}}{192\,u\,v\,w}&lt;/math&gt;
where
: &lt;math&gt;
    \begin{align} a &amp; = \sqrt {xYZ} \\ b &amp; = \sqrt {yZX} \\ c &amp; = \sqrt {zXY} \\ d &amp; = \sqrt {xyz} \\ X &amp; = (w - U + v)\,(U + v + w) \\ x &amp; = (U - v + w)\,(v - w + U) \\ Y &amp; = (u - V + w)\,(V + w + u) \\ y &amp; = (V - w + u)\,(w - u + V) \\ Z &amp; = (v - W + u)\,(W + u + v) \\ z &amp; = (W - u + v)\,(u - v + W). \end{align} 
&lt;/math&gt;

==See also==
*[[Shoelace formula]]

== References ==
&lt;references/&gt;

== External links  ==
*[http://www.cut-the-knot.org/pythagoras/herons.shtml A Proof of the Pythagorean Theorem From Heron's Formula] at [[cut-the-knot]]
*[http://www.mathopenref.com/heronsformula.html Interactive applet and area calculator using Heron's Formula]
*[http://www.math.dartmouth.edu/~doyle/docs/heron/heron.txt J.H. Conway discussion on Heron's Formula]
*{{MathPages|id=home/kmath196/kmath196|title=Heron's Formula and Brahmagupta's Generalization}}
*[http://jwilson.coe.uga.edu/EMT668/EMAT6680.2000/Umberger/MATH7200/HeronFormulaProject/GeometricProof/geoproof.html A Geometric Proof of Heron's Formula]
*[http://www.maa.org/sites/default/files/0746834212944.di020798.02p0691h.pdf An alternative proof of Heron's Formula without words]
*[http://www.maa.org/sites/default/files/Pratt-CMJ0902994.pdf Factoring Heron]

{{DEFAULTSORT:Heron's Formula}}
[[Category:Triangle geometry]]
[[Category:Articles containing proofs]]
[[Category:Area]]
[[Category:Theorems in plane geometry]]
&lt;!-- dummy edit --&gt;</text>
      <sha1>i95klg186x924jd2cwwb9lp9045n4p2</sha1>
    </revision>
  </page>
  <page>
    <title>Hoeffding's independence test</title>
    <ns>0</ns>
    <id>27318656</id>
    <revision>
      <id>807722266</id>
      <parentid>790710100</parentid>
      <timestamp>2017-10-29T19:36:24Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v475)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2022">In [[statistics]], '''Hoeffding's test of independence''', named after [[Wassily Hoeffding]], is a test based on the population measure of deviation from independence

:&lt;math&gt;H = \int (F_{12}-F_1F_2)^2 \, dF_{12} &lt;/math&gt;

where &lt;math&gt;F_{12}&lt;/math&gt; is the [[joint distribution function]] of two random variables, and &lt;math&gt;F_1&lt;/math&gt; and &lt;math&gt;F_2&lt;/math&gt; are their [[marginal distribution]] functions.
Hoeffding derived an [[unbiased estimator]] of &lt;math&gt;H&lt;/math&gt; that can be used to test for [[independence (probability theory)|independence]], and is [[consistent estimator|consistent]] for any continuous [[alternative hypothesis|alternative]]. The test should only be applied to data drawn from a [[continuous probability distribution|continuous distribution]], since &lt;math&gt;H&lt;/math&gt; has a defect for discontinuous &lt;math&gt;F_{12}&lt;/math&gt;, namely that it is not necessarily zero when &lt;math&gt;F_{12}=F_1F_2&lt;/math&gt;.

A recent paper&lt;ref&gt;Wilding, G.E., Mudholkar, G.S. (2008) [http://www.sciencedirect.com/science/article/B7CRS-4PJ04Y7-1/2/e10c0f978e665a0d5ffd41a594f9a9ba "Empirical approximations for Hoeffding's test of bivariate independence using two Weibull extensions"], ''Statistical Methodology'', 5 (2), 160-&amp;ndash;170&lt;/ref&gt; describes both the calculation of a sample based version of this measure for use as a test statistic, and calculation of the null distribution of this test statistic.

==See also==

{{Portal|Statistics}}
* [[Correlation]]
* [[Kendall's tau]]
* [[Spearman's rank correlation coefficient]]
*[[Distance correlation]]

==Notes==
{{Reflist}}

==Primary sources==
* Wassily Hoeffding, A non-parametric test of independence, ''Annals of Mathematical Statistics'' '''19''': 293&amp;ndash;325, 1948. ([https://www.jstor.org/stable/2236021 JSTOR])
* Hollander and Wolfe, Non-parametric statistical methods (Section 8.7), 1999. Wiley.

{{DEFAULTSORT:Hoeffding's Independence Test}}
[[Category:Covariance and correlation]]
[[Category:Nonparametric statistics]]
[[Category:Statistical tests]]

{{statistics-stub}}</text>
      <sha1>7fhygsehmu97bk3kzl6ihr0bg50fv18</sha1>
    </revision>
  </page>
  <page>
    <title>Hypercomplex analysis</title>
    <ns>0</ns>
    <id>26666199</id>
    <revision>
      <id>815040615</id>
      <parentid>785945127</parentid>
      <timestamp>2017-12-12T11:41:18Z</timestamp>
      <contributor>
        <username>Souravdas1998</username>
        <id>28702393</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4087">In mathematics, '''hypercomplex analysis''' is the extension of [[real analysis]] and [[complex analysis]] to the study of functions where the [[argument of a function|argument]] is a [[hypercomplex number]]. The first instance is functions of a [[quaternion variable]], where the argument is a [[quaternion]].  A second instance involves functions of a [[motor variable]] where arguments are [[split-complex number]]s.

In [[mathematical physics]], there are hypercomplex systems called [[Clifford algebra]]s. The study of functions with arguments from a Clifford algebra is called [[Clifford analysis]].

A [[matrix (mathematics)|matrix]] may be considered a hypercomplex number. For example, study of [[2 × 2 real matrices#Functions of 2 × 2 real matrices|functions of 2 × 2 real matrices]] shows that the [[topology]] of the [[space (mathematics)|space]] of hypercomplex numbers determines the function theory. Functions such as [[square root of a matrix]], [[matrix exponential]], and [[logarithm of a matrix]] are basic examples of hypercomplex analysis.&lt;ref&gt;[[Felix Gantmacher]] (1959) ''The Theory of Matrices'', two volumes, translator: [[Kurt Hirsch]], [[Chelsea Publishing]], chapter 5: functions of matrices, chapter 8: roots and logarithms of matrices&lt;/ref&gt; 
The function theory of [[diagonalizable matrices]] is particularly transparent since they have [[eigendecomposition]]s.&lt;ref&gt;Shaw, Ronald (1982) ''Linear Algebra and Group Representations'', v. 1, § 2.3, Diagonalizable linear operators, pages 78–81, [[Academic Press]] {{ISBN|0-12-639201-3}}.&lt;/ref&gt; Suppose &lt;math&gt;\textstyle T = \sum _{i=1}^N \lambda_i E_i&lt;/math&gt; where the E&lt;sub&gt;i&lt;/sub&gt; are [[projection (linear algebra)|projection]]s. Then for any [[polynomial]]  &lt;math&gt;\textstyle f, \quad f(T) = \sum_{i=1}^N  f(\lambda_i ) E_i .&lt;/math&gt; 

Modern terminology is ''algebra'' for "system of hypercomplex numbers", and the  algebras used in applications are often [[Banach algebra]]s since [[Cauchy sequence]]s can be taken to be convergent. Then the function theory is enriched by [[sequence]]s and [[series (mathematics)|series]]. In this context the extension of holomorphic functions of a complex variable is developed as the [[holomorphic functional calculus]].  Hypercomplex analysis on Banach algebras is called [[functional analysis]].

==See also==
* [[Giovanni Battista Rizza]]

==References==
{{Reflist}}

* Daniel Alpay (editor) (2006) ''Wavelets, Multiscale systems and Hypercomplex Analysis'', Springer, {{ISBN|9783764375881}} .
* Enrique Ramirez de Arellanon (1998) ''Operator theory for complex and hypercomplex analysis'', [[American Mathematical Society]] (Conference proceedings from a meeting in Mexico City in December 1994).
* Geoffrey Fox (1949) ''Elementary Function Theory of a Hypercomplex Variable and the Theory of Conformal Mapping in the Hyperbolic Plane'', M.A. thesis, [[University of British Columbia]].
* Sorin D. Gal (2004) ''Introduction to the Geometric Function theory of Hypercomplex variables'', Nova Science Publishers, {{ISBN|1-59033-398-5}}.
* R. Lavika &amp; A.G. O’ Farrell &amp; I. Short(2007) "Reversible maps in the group of quaternionic Möbius transformations", [[Mathematical Proceedings of the Cambridge Philosophical Society]] 143:57–69.
* Birkhauser Mathematics (2011) ''Hypercomplex Analysis and Applications'', series with editors Irene Sabadini and Franciscus Sommen.
* Irene Sabadini &amp; Michael V. Shapiro &amp; F. Sommen (editors) (2009) ''Hypercomplex Analysis'', Birkhauser {{ISBN|978-3-7643-9892-7}}.
* Springer (2012) ''Advances in Hypercomplex Analysis'', eds Sabadini, Sommen, Struppa.

==External links==
* [https://www.chapman.edu/scst/about/centers-of-excellence/cecha/ Center of excellence in hypercomplex analysis] at [[Chapman University]], Daniele Struppa, Chancellor, Chapman faculty, and several "external faculty".
* Roman Lavika (2011) [https://www.karlin.mff.cuni.cz/~lavicka/publikace/habilitation1-54.pdf Hypercomplex Analysis: Selected Topics] ([[Habilitation]] Thesis) [[Charles University in Prague]].


[[Category:Functions and mappings]]</text>
      <sha1>lasabaiwnndlw7sufmkxipdqsf9vp1o</sha1>
    </revision>
  </page>
  <page>
    <title>Ib Holm Sørensen</title>
    <ns>0</ns>
    <id>34846125</id>
    <revision>
      <id>861258274</id>
      <parentid>845277433</parentid>
      <timestamp>2018-09-26T05:22:30Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4133">Dr '''Ib Holm Sørensen''' (1949–2012) was a [[computer scientist]] who made contributions to the [[Z notation]] and [[B-Method]].&lt;ref name="in-memoriam"&gt;{{cite web | url=http://www.cs.ox.ac.uk/news/448-full.html | title=Ib Sorensen – In memoriam | publisher=[[Department of Computer Science, University of Oxford]], UK | date=8 February 2012 | accessdate=February 22, 2012 |last=Roscoe | first=Bill | authorlink=Bill Roscoe}}&lt;/ref&gt;

Originally from [[Denmark]], Ib Sørensen started his academic career in the 1970s at [[Aarhus University]], where he worked on the Rikke-Mathilda [[microassembler]]s and [[Computer simulator|simulator]]s running on the [[DECSystem-10]] computer.&lt;ref&gt;{{cite book | title=RIKKE-MATHILDA microassemblers and simulators on the DECSystem-10 | url=http://www.bitsavers.org/pdf/aarhusUniversity/md/MD-28_RIKKE-MATHILDA_Microassemblers_and_Simulators_on_the_DECSystem-10_Dec77.pdf | publisher=[[Aarhus University]], Denmark | last1=Sørensen | first1=Ib  Holm | last2=Kresse | first2=Eric | date=December 1977 | volume=DAIMI MD-28}}&lt;/ref&gt;

In 1979, Sørensen joined the [[Programming Research Group]], part of the Oxford University Computing Laboratory (now the [[Oxford University Department of Computer Science]]) in [[England]]. There he worked with [[Jean-Raymond Abrial]] and others, making contributions to the early development of the [[formal specification]] language Z. He gained a [[DPhil]] degree from the [[University of Oxford]]&lt;ref&gt;{{cite book | title=Topics in programme specification and design: specification and design of distributed systems | publisher=[[Wolfson College, Oxford|Wolfson College]], [[University of Oxford]], UK | last=Sørensen | first=Ib Holm | year=1981 | url=https://books.google.com/books?id=T_ZlLQAACAAJ}}&lt;/ref&gt; and was a co-author of the seminal ''Specification Case Studies'' book on Z, first published in 1987 (second edition in 1993).&lt;ref&gt;{{cite book | title=Specification Case Studies | publisher=Prentice Hall International Series in Computer Science | edition=2nd | date=1993 | isbn=978-0-13-832544-2 | url=http://red.cs.nott.ac.uk/~rxq/files/SpecificationCaseStudies.pdf | editor=Hayes, Ian}}&lt;/ref&gt;

From the late 1980s, Sørensen was central in the development of the B-Method, a leading [[formal method]]. He left [[Oxford University]] to lead a team at [[BP]] developing the [[B-Tool]] to provide tool support for the B approach. He then founded the company B-Core (UK) Limited&lt;ref&gt;{{cite web | url=http://www.cdrex.com/b-core-uk-limited-712649.html | title=B-Core (UK) Limited | publisher=[http://www.cdrex.com/ Company Data Rex] | accessdate=February 22, 2012}}&lt;/ref&gt; to support the [[B-Toolkit]],&lt;ref&gt;{{cite web|url=http://www.b-core.com/ONLINEDOC/BToolkit.html |title=The B-Toolkit |publisher=[[Archive.org]] |work=B-Core (UK) Limited |year=2004 |accessdate=February 22, 2012 |deadurl=yes |archiveurl=https://web.archive.org/web/20041012141220/http://www.b-core.com/ONLINEDOC/BToolkit.html |archivedate=October 12, 2004 }}&lt;/ref&gt; a set of programming tools designed to support the use of the B-Tool, and undertake B-related projects.

Latterly Sørensen returned to the University of Oxford. From 1999, he worked on the B-based ''Booster'' models of requirements. He died in 2012, before he was able to retire.&lt;ref name="in-memoriam" /&gt;

==References==
{{Reflist}}

==External links==
* [http://www.cs.ox.ac.uk/people/ib.sorensen/ Personal home page]
* {{AcademicSearch|3329359}}
* {{DBLP |name=Ib Holm Sørensen}}


{{authority control}}

{{DEFAULTSORT:Sorensen, Ib Holm}}
[[Category:1939 births]]
[[Category:2012 deaths]]
[[Category:Danish expatriates in England]]
[[Category:British people of Danish descent]]
[[Category:Aarhus University faculty]]
[[Category:Alumni of Wolfson College, Oxford]]
[[Category:Fellows of Wolfson College, Oxford]]
[[Category:Danish computer scientists]]
[[Category:British computer scientists]]
[[Category:Formal methods people]]
[[Category:Software engineers]]
[[Category:Members of the Department of Computer Science, University of Oxford]]
[[Category:Z notation]]


{{UK-compu-bio-stub}}
{{UK-academic-bio-stub}}</text>
      <sha1>byxky687f82njva0k1dmxbp2w61j6eu</sha1>
    </revision>
  </page>
  <page>
    <title>Interference channel</title>
    <ns>0</ns>
    <id>59052958</id>
    <revision>
      <id>868954220</id>
      <parentid>868821754</parentid>
      <timestamp>2018-11-15T13:43:16Z</timestamp>
      <contributor>
        <username>Jmertel23</username>
        <id>32942831</id>
      </contributor>
      <comment>Stub-sorting. [[Wikipedia:WikiProject Stub sorting|You can help!]]; Copyedit (minor)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3682">
In [[information theory]], the '''interference channel''' is the basic model used to analyze the effect of [[Interference (communication)|interference]] in communication channels. The model consists of two pairs of users communicating through a shared channel. The problem of interference between two mobile users in close proximity or [[crosstalk]] between two parallel [[landline|landlines]] are two examples where this model is applicable.

Unlike in the [[Point-to-point (telecommunications)|point-to-point channel]], where the amount of information that can be sent through the channel is limited by the noise that distorts the transmitted signal, in the interference channel, it is mainly the signal from the other user that hinders the communication. However, the transmitted signals are not purely random (otherwise they would not be decodable), and, therefore, the users can reduce the effect of the interference by decoding the undesired signal.

== Discrete memoryless interference channel ==
The mathematical model for this channel is the following:

[[File:Interference channel model.svg|center|800px|Interference channel model]]

where, for &lt;math&gt;i\in\{1,2\}&lt;/math&gt;:
* &lt;math&gt;W_i&lt;/math&gt; is the message to be transmitted by user &lt;math&gt;i&lt;/math&gt;;
* &lt;math&gt;X_i&lt;/math&gt; is the channel input symbol (&lt;math&gt;X_i^n&lt;/math&gt; is a sequence of &lt;math&gt;n&lt;/math&gt; symbols) of user &lt;math&gt;i&lt;/math&gt;;
* &lt;math&gt;Y_i&lt;/math&gt; is the channel output symbol (&lt;math&gt;Y_i^n&lt;/math&gt; is a sequence of &lt;math&gt;n&lt;/math&gt; symbols) of user &lt;math&gt;i&lt;/math&gt;;
* &lt;math&gt;\hat{W}_i&lt;/math&gt; is the estimate of the transmitted message by user &lt;math&gt;i&lt;/math&gt;; and
* &lt;math&gt;p(y_1,y_2|x_1,x_2)&lt;/math&gt; is the noisy memoryless channel, which is modeled by a [[conditional probability distribution]].

The capacity of this channel model is not known in general; only for special cases of &lt;math&gt;p(y_1,y_2|x_1,x_2)&lt;/math&gt; the capacity has been calculated, e.g., in the case of strong interference or deterministic channels.&lt;ref&gt;{{cite book |author= [[Abbas El Gamal|A. El Gamal]], Y.-H. Kim |title= Network Information Theory |publisher= Cambridge University Press |isbn= 978-1-107-00873-1 |year=2011}}&lt;/ref&gt;

==References==
{{reflist}}
&lt;!-- * [[Abbas El Gamal|A. El Gamal]], Y.-H. Kim, ''Network Information Theory'', [[Cambridge University Press]], 2011. {{ISBN|978-1-107-00873-1}} --&gt;

===Further references===
{{refbegin}}
* [[Rudolf Ahlswede|R. Ahlswede]], “The Capacity Region of a Channel with Two Senders and Two Receivers,” [[The Annals of Probability]], vol. 2, No. 5, pp. 805–814, Oct. 1974.
* [[Te Sun Han|T. S. Han]] and K. Kobayashi, “A New Achievable Rate Region for the Interference Channel,” [[IEEE Trans. Inf. Theory]], vol. 27, No. 1, pp. 49–60, Jan. 1981.
* R. H. Etkin, [[David Tse|D. Tse]], and H. Wang, “Gaussian Interference Channel Capacity to Within One Bit,” [[IEEE Trans. Inf. Theory]], vol. 54, no. 12, pp. 5534–5562, Dec. 2008.
{{refend}}

===Extensions===
{{refbegin}}
* O. Sahin and E. Erkip, “Achievable Rates for the Gaussian Interference Relay Channel,” in [[Global_Communications_Conference|IEEE Global Telecommunications Conference, 2007]], Nov. 2007, pp. 1627–1631.
* I. Marić, R. Dabora, and A. J. Goldsmith, “Relaying in the Presence of Interference: Achievable Rates, Interference Forwarding, and Outer Bounds,” [[IEEE Trans. Inf. Theory]], vol. 58, no. 7, pp. 4342–4354, Jul. 2012.
* G. Bassi, P. Piantanida, and S. Yang, “Capacity Bounds for a Class of Interference Relay Channels,” [[IEEE Trans. Inf. Theory]], vol. 61, no. 7, pp. 3698–3721, Jul. 2015.
{{refend}}

[[Category:Information theory]]
[[Category:Telecommunication theory]]


{{Telecomm-stub}}</text>
      <sha1>44oyk2qw8tcx48qi6po6a1nc73sw3hu</sha1>
    </revision>
  </page>
  <page>
    <title>Intermediate value theorem</title>
    <ns>0</ns>
    <id>14884</id>
    <revision>
      <id>854696210</id>
      <parentid>854694100</parentid>
      <timestamp>2018-08-13T04:35:28Z</timestamp>
      <contributor>
        <username>MarginalCost</username>
        <id>13423146</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/210.212.217.202|210.212.217.202]] ([[User talk:210.212.217.202|talk]]) to last version by PrimeBOT</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16056">{{distinguish|text=the [[Mean value theorem]]}}
[[File:Illustration for the intermediate value theorem.svg|thumb|Intermediate value theorem: Let ''f'' be a defined continuous function on [''a'', ''b''] and let ''s'' be a number with ''f''(''a'') &lt; ''s'' &lt; ''f''(''b''). Then there exists at least one ''x'' with ''f''(''x'') = ''s'']]
In [[mathematical analysis]], the '''intermediate value theorem''' states that if a [[continuous function]], ''f'', with an [[interval (mathematics)|interval]], [''a'', ''b''], as its [[domain of a function|domain]], takes values ''f''(''a'') and ''f''(''b'') at each end of the interval, then it also takes any value between ''f''(''a'') and ''f''(''b'') at some point within the interval.

This has two important [[corollary|corollaries]]: 

# If a continuous function has values of opposite sign inside an interval, then it has a root in that interval ('''Bolzano's theorem''').&lt;ref&gt;{{MathWorld |title=Bolzano's Theorem |urlname=BolzanosTheorem}}&lt;/ref&gt; 
# The [[image (mathematics)|image]] of a continuous function over an interval is itself an interval.

==Motivation==
[[Image:Intermediatevaluetheorem.svg|thumb|280px|The intermediate value theorem]]

This captures an intuitive property of continuous functions: given ''f'' continuous on [1, 2] with the known values ''f''(1) = 3 and ''f''(2) = 5. Then the graph of ''y'' = ''f''(''x'') must pass through the horizontal line ''y'' = 4 while ''x'' moves from 1 to 2. It represents the idea that the graph of a continuous function on a closed interval can be drawn without lifting your pencil from the paper.

==Theorem==
The intermediate value theorem states the following.

Consider an interval &lt;math&gt;I=[a,b]&lt;/math&gt; in the [[real number]]s &lt;math&gt;\R&lt;/math&gt; and a continuous function &lt;math&gt;f:I\to\R&lt;/math&gt;. Then,

*''Version I.'' if &lt;math&gt;u&lt;/math&gt; is a number between &lt;math&gt;f(a)&lt;/math&gt; and &lt;math&gt;f(b)&lt;/math&gt;,
::that is, &lt;math&gt;\min(f(a),f(b))&lt;u&lt;\max(f(a),f(b))&lt;/math&gt;,
:then there is a &lt;math&gt;c\in (a,b)&lt;/math&gt; such that &lt;math&gt;f(c)=u&lt;/math&gt;.

*''Version II.'' the image set &lt;math&gt;f(I)&lt;/math&gt; is also an interval, and either it contains &lt;math&gt;\bigl[f(a),f(b)\bigr]&lt;/math&gt;, or it contains &lt;math&gt;\bigl[f(b),f(a)\bigr]&lt;/math&gt;; that is,
::&lt;math&gt;f(I)\supseteq\bigl[f(a),f(b)\bigr]\ \mbox{ or }\ f(I)\supseteq\bigl[f(b),f(a)\bigr]&lt;/math&gt;.

'''Remark:''' ''Version II'' states that the set of function values has no gap. For any two function values &lt;math&gt;c&lt;d&lt;/math&gt;, even if they are outside the interval between &lt;math&gt;f(a)&lt;/math&gt; and &lt;math&gt;f(b)&lt;/math&gt;, all points in the interval &lt;math&gt;\bigl[c,d\bigr]&lt;/math&gt; are also function values,
::&lt;math&gt;\bigl[c,d\bigr]\subseteq f(I)&lt;/math&gt;.
A subset of the real numbers with no internal gap is an interval. ''Version I'' is naturally contained in ''Version II''.

==Relation to completeness==
The theorem depends on, and is equivalent to, the [[completeness of the real numbers]]. The intermediate value theorem does not apply to the [[rational number]]s ℚ because gaps exist between rational numbers; [[irrational numbers]] fill those gaps. For example, the function &lt;math&gt;f(x)=x^2-2&lt;/math&gt; for &lt;math&gt;x\in\Q&lt;/math&gt; satisfies &lt;math&gt;f(0)=-2&lt;/math&gt; and &lt;math&gt;f(2)=2&lt;/math&gt;. However, there is no rational number &lt;math&gt;x&lt;/math&gt; such that &lt;math&gt;f(x)=0&lt;/math&gt;, because &lt;math&gt;\sqrt2&lt;/math&gt; is an irrational number.

==Proof==&lt;!-- This section is linked from [[Continuity property]] --&gt;
The theorem may be proven as a consequence of the [[completeness (order theory)|completeness]] property of the real numbers as follows:&lt;ref&gt;Essentially follows {{cite book |title=Foundations of Analysis|first=Douglas A.|last=Clarke|publisher=Appleton-Century-Crofts|year=1971|page=284}}&lt;/ref&gt;

We shall prove the first case, &lt;math&gt;f(a)&lt;u&lt;f(b)&lt;/math&gt;. The second case is similar.

Let &lt;math&gt;S&lt;/math&gt; be the set of all &lt;math&gt;x\in[a,b]&lt;/math&gt; such that &lt;math&gt;f(x)\leq u&lt;/math&gt;. Then &lt;math&gt;S&lt;/math&gt; is non-empty since &lt;math&gt;a&lt;/math&gt; is an element of &lt;math&gt;S&lt;/math&gt;, and &lt;math&gt;S&lt;/math&gt; is bounded above by &lt;math&gt;b&lt;/math&gt;. Hence, by completeness, the [[supremum]] &lt;math&gt;c=\sup S&lt;/math&gt; exists. That is, &lt;math&gt;c&lt;/math&gt; is the lowest number that is greater than or equal to every member of &lt;math&gt;S&lt;/math&gt;. We claim that &lt;math&gt;f(c)=u&lt;/math&gt;.

Fix some &lt;math&gt;\varepsilon&gt;0&lt;/math&gt;. Since &lt;math&gt;f&lt;/math&gt; is continuous, there is a &lt;math&gt;\delta&gt;0&lt;/math&gt; such that &lt;math&gt;\Big|f(x)-f(c)\Big|&lt;\varepsilon&lt;/math&gt; whenever &lt;math&gt;|x-c|&lt;\delta&lt;/math&gt;. This means that
::&lt;math&gt;f(x)-\varepsilon&lt;f(c)&lt;f(x)+\varepsilon&lt;/math&gt;
for all &lt;math&gt;x\in(c-\delta,c+\delta)&lt;/math&gt;. By the properties of the supremum, there exist &lt;math&gt;a^*\in (c-\delta,c]&lt;/math&gt; that is contained in &lt;math&gt;S&lt;/math&gt;, so that for that &lt;math&gt;a^*&lt;/math&gt;
::&lt;math&gt;f(c)&lt;f(a^*)+\varepsilon\le u+\varepsilon&lt;/math&gt;.
Choose &lt;math&gt;a^{**}\in[c,c+\delta)&lt;/math&gt; that will obviously not be contained in &lt;math&gt;S&lt;/math&gt;, so we have
::&lt;math&gt;f(c)&gt;f(a^{**})-\varepsilon\ge u-\varepsilon&lt;/math&gt;.
Both inequalities
::&lt;math&gt;u-\varepsilon&lt;f(c)&lt;u+\varepsilon&lt;/math&gt;
are valid for all &lt;math&gt;\varepsilon&gt;0&lt;/math&gt;, from which we deduce &lt;math&gt;f(c)=u&lt;/math&gt; as the only possible value, as stated.

The intermediate value theorem is an easy consequence of the basic properties of connected sets: the preservation of connectedness under continuous functions and the characterization of connected subsets of ℝ as intervals (''see below for details'' ''and alternate proof'')''.''  The latter characterization is ultimately a consequence of the least-upper-bound property of the real numbers.

The intermediate value theorem can also be proved using the methods of [[non-standard analysis]], which places "intuitive" arguments involving infinitesimals on a rigorous footing.  (''See the article:'' [[non-standard calculus]].)

==History==
For ''u'' = 0 above, the statement is also known as ''Bolzano's theorem.'' This theorem was first proved by [[Bernard Bolzano]] in 1817. [[Augustin-Louis Cauchy]] provided a proof in 1821.&lt;ref name="grabiner"&gt;{{Cite journal
|title=Who Gave You the Epsilon? Cauchy and the Origins of Rigorous Calculus
|first=Judith V.
|last=Grabiner
|journal=The American Mathematical Monthly
|date=March 1983
|volume=90
|pages=185–194
|url=http://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/Grabiner185-194.pdf
|doi=10.2307/2975545
|issue=3
|publisher=Mathematical Association of America
|jstor=2975545
|postscript=&lt;!-- Bot inserted parameter. Either remove it or change its value to "." for the cite to end in a ".", as necessary. --&gt;{{inconsistent citations}}
}}&lt;/ref&gt; Both were inspired by the goal of formalizing the analysis of functions and the work of [[Joseph-Louis Lagrange]]. The idea that continuous functions possess the intermediate value property has an earlier origin. [[Simon Stevin]] proved the intermediate value theorem for polynomials (using a cubic as an example) by providing an algorithm for constructing the decimal expansion of the solution.  The algorithm iteratively subdivides the interval into 10 parts, producing an additional decimal digit at each step of the iteration.&lt;ref&gt;Karin Usadi Katz and [[Mikhail Katz|Mikhail G. Katz]] (2011) A Burgessian Critique of Nominalistic Tendencies in Contemporary Mathematics and its Historiography. [[Foundations of Science]]. {{doi|10.1007/s10699-011-9223-1}} See [http://www.springerlink.com/content/tj7j2810n8223p43/ link]&lt;/ref&gt; Before the formal definition of continuity was given, the intermediate value property was given as part of the definition of a continuous function. Proponents include [[Louis Arbogast]], who assumed the functions to have no jumps, satisfy the intermediate value property and have increments whose sizes corresponded to the sizes of the increments of the variable.&lt;ref&gt;{{MacTutor Biography|id=Arbogast}}&lt;/ref&gt;
Earlier authors held the result to be intuitively obvious and requiring no proof.  The insight of Bolzano and Cauchy was to define a general notion of continuity (in terms of [[infinitesimal]]s in Cauchy's case and using real inequalities in Bolzano's case), and to provide a proof based on such definitions.

==Generalizations==

The intermediate value theorem is closely linked to the topological notion of [[Connectedness (topology)|connectedness]] and follows from the basic properties of connected sets in metric spaces and connected subsets of ℝ in particular:
* If &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; are [[metric space]]s, &lt;math&gt;f:X\to Y&lt;/math&gt; is a continuous map, and &lt;math&gt;E\subset X&lt;/math&gt; is a [[Connected space|connected]] subset, then &lt;math&gt;f(E)&lt;/math&gt; is connected. (*)
* A subset &lt;math&gt;E\subset\mathbb{R}&lt;/math&gt; is connected if and only if it satisfies the following property: &lt;math&gt;x,y\in E,\ x&lt;r&lt;y \implies r\in E&lt;/math&gt;. (**)

In fact, connectedness is a [[topological property]] and (*) generalizes to topological spaces: ''If &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; are [[topological space]]s, &lt;math&gt;f:X\to Y&lt;/math&gt; is a continuous map, and &lt;math&gt;X&lt;/math&gt; is a [[connected space]], then &lt;math&gt;f(X)&lt;/math&gt; is connected.''  The preservation of connectedness under continuous maps can be thought of as a generalization of the intermediate value theorem, a property of real valued functions of a real variable, to continuous functions in general spaces.

Recall the first version of the intermediate value theorem, stated previously:

'''Intermediate value theorem.''' ''(Version I). Consider a closed interval &lt;math&gt;I=[a,b]&lt;/math&gt; in the real numbers &lt;math&gt;\R&lt;/math&gt; and a continuous function &lt;math&gt;f:I\to\R&lt;/math&gt;. Then, if &lt;math&gt; u&lt;/math&gt; is a real number such that &lt;math&gt;\min(f(a),f(b))&lt; u &lt; \max(f(a),f(b))&lt;/math&gt;, there exists &lt;math&gt;c\in(a,b)&lt;/math&gt; such that &lt;math&gt;f(c)=u&lt;/math&gt;.''

The intermediate value theorem is an immediate consequence of these two properties of connectedness:&lt;ref&gt;{{Cite book|url=https://archive.org/details/1979RudinW|title=Principles of Mathematical Analysis|last=Rudin|first=Walter|publisher=McGraw-Hill|year=1976|isbn=978-0-07-054235-8|location=New York|pages=42, 93|quote=|via=}}&lt;/ref&gt;

'''''Proof:''''' By (**), &lt;math&gt;I=[a,b]&lt;/math&gt; is a connected set.  It follows from  (*) that the image, &lt;math&gt;f(I)&lt;/math&gt;, is also connected.  For convenience, assume that &lt;math&gt;f(a)&lt;f(b)&lt;/math&gt;.  Then once more invoking (**), &lt;math&gt;f(a)&lt;u&lt;f(b)&lt;/math&gt; implies that &lt;math&gt;u\in f(I)&lt;/math&gt;, or &lt;math&gt;f(c)=u&lt;/math&gt; for some &lt;math&gt;c\in I&lt;/math&gt;.  Since &lt;math&gt;u\neq f(a), f(b)&lt;/math&gt;, &lt;math&gt;c\in(a,b)&lt;/math&gt; must actually hold, and the desired conclusion follows.  The same argument applies if &lt;math&gt;f(b)&lt;f(a)&lt;/math&gt;, so we are done.&lt;math&gt;\ \ \blacksquare&lt;/math&gt;

The intermediate value theorem generalizes in a natural way: Suppose that ''X'' is a connected topological space and (''Y'', &lt;) is a [[total order|totally ordered]] set equipped with the [[order topology]], and let ''f'' : ''X'' → ''Y'' be a continuous map. If ''a'' and ''b'' are two points in ''X'' and ''u'' is a point in ''Y'' lying between ''f''(''a'') and ''f''(''b'') with respect to &lt;, then there exists ''c'' in ''X'' such that ''f''(''c'') = ''u''.  The original theorem is recovered by noting that ℝ is connected and that its natural topology is the order topology.

The [[Brouwer fixed-point theorem]] is a related theorem that, [[Brouwer fixed-point theorem#One-dimensional case|in one dimension]] gives a special case of the intermediate value theorem.

==Converse is false==

A "[[Darboux function]]" is a real-valued function ''f'' that has the "intermediate value property", i.e., that satisfies the conclusion of the intermediate value theorem: for any two values ''a'' and ''b'' in the domain of ''f'', and any ''y'' between ''f''(''a'') and ''f''(''b''), there is some ''c'' between ''a'' and ''b'' with ''f''(''c'') = ''y''.  The intermediate value theorem says that every continuous function is a Darboux function.  However, not every Darboux function is continuous; i.e., the converse of the intermediate value theorem is false.

As an example, take the function ''f'' : [0, ∞) → [&amp;minus;1, 1] defined by ''f''(''x'') = sin(1/''x'') for ''x'' &gt; 0 and f(0) = 0. This function is not continuous at ''x'' = 0 because the [[limit of a function|limit]] of ''f''(''x'') as ''x'' tends to 0 does not exist; yet the function has the intermediate value property.  Another, more complicated example is given by the [[Conway base 13 function]].

Historically, this intermediate value property has been suggested as a ''definition'' for continuity of real-valued functions&lt;ref&gt;{{Cite book|url=https://books.google.co.in/books?id=lnuhDgAAQBAJ&amp;pg=PA51&amp;lpg=PA51&amp;dq=Historically,+this+intermediate+value+property+has+been+suggested+as+a+definition+for+continuity+of+real-valued+functions&amp;source=bl&amp;ots=77BNBThFH6&amp;sig=ldlleSGvtuqqcrLcX5D_YIon-gg&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjdksmEo97YAhXFTbwKHaJ-Aa8Q6AEIRDAE#v=onepage&amp;q=Historically,%20this%20intermediate%20value%20property%20has%20been%20suggested%20as%20a%20definition%20for%20continuity%20of%20real-valued%20functions&amp;f=false|title=MVT: A Most Valuable Theorem|last=Smorynski|first=Craig|date=2017-04-07|publisher=Springer|isbn=9783319529561|language=en}}&lt;/ref&gt;{{citation needed|date=October 2011}}; this definition was not adopted.

[[Darboux's theorem (analysis)|Darboux's theorem]] states that all functions that result from the [[derivative|differentiation]] of some other function on some interval have the [[intermediate value property]] (even though they need not be continuous).

==Practical applications==

The theorem implies that on any [[great circle]] around the world, for the [[temperature]], [[pressure]], [[elevation]], [[carbon dioxide]] concentration, if the [[Quantum#Beyond_electromagnetic_radiation|simplification]] is taken that this varies continuously, there will always exist two [[antipodal points]] that share the same value for that variable.

''Proof:'' Take ''f'' to be any continuous function on a circle. Draw a line through the center of the circle, intersecting it at two opposite points ''A'' and ''B''. Let ''d'' be defined by the difference ''f''(''A'') &amp;minus; ''f''(''B''). If the line is rotated 180 degrees, the value &amp;minus;''d'' will be obtained instead. Due to the intermediate value theorem there must be some intermediate rotation angle for which ''d'' = 0, and as a consequence ''f''(''A'') = ''f''(''B'') at this angle.

This is a special case of a more general result called the [[Borsuk–Ulam theorem]].

Another generalization for which this holds is for any closed convex n (n &gt; 1) dimensional shape. Specifically, for any continuous function whose domain is the given shape, and any point inside the shape (not necessarily its center), there exist two antipodal points with respect to the given point whose functional value is the same. The proof is identical to the one given above.

The theorem also underpins the explanation of why rotating a wobbly table will bring it to stability (subject to certain easily  met constraints).&lt;ref&gt;[[Keith Devlin]] (2007) [http://www.maa.org/external_archive/devlin/devlin_02_07.html How to stabilize a wobbly table]&lt;/ref&gt;

==See also==
*[[Mean value theorem]]
*[[Hairy ball theorem]]
*[[Brouwer fixed point theorem]]

==References==
&lt;references/&gt;

==External links==
{{ProofWiki|id=Intermediate_Value_Theorem|title=Intermediate value Theorem}}
* [http://www.cut-the-knot.org/Generalization/ivt.shtml Intermediate value Theorem - Bolzano Theorem] at [[cut-the-knot]]
* [http://demonstrations.wolfram.com/BolzanosTheorem/ Bolzano's Theorem] by Julio Cesar de la Yncera, [[Wolfram Demonstrations Project]].
* {{MathWorld |title=Intermediate Value Theorem |urlname=IntermediateValueTheorem}}
* [http://math.stackexchange.com/questions/95843/generalization-of-easy-1-d-proof-of-brouwer-fixed-point-theorem/95867#95867 Two-dimensional version of the Intermediate Value Theorem], by Jim Belk at Math Stack Exchange.
* [[Mizar system]] proof: http://mizar.org/version/current/html/topreal5.html#T4

[[Category:Continuous mappings]]
[[Category:Articles containing proofs]]
[[Category:Theorems in calculus]]
[[Category:Theorems in real analysis]]</text>
      <sha1>6wtsdja2zhyfr2i19joce6mqp5bun6t</sha1>
    </revision>
  </page>
  <page>
    <title>Isometry group</title>
    <ns>0</ns>
    <id>1101694</id>
    <revision>
      <id>821805456</id>
      <parentid>821803419</parentid>
      <timestamp>2018-01-22T19:05:03Z</timestamp>
      <contributor>
        <username>TheKing44</username>
        <id>17262741</id>
      </contributor>
      <comment>/* Examples */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3567">In [[mathematics]], the '''isometry group''' of a [[metric space]] is the [[Set (mathematics)|set]] of all [[bijective]] [[isometry|isometries]] (i.e. bijective, distance-preserving maps) from the metric space onto itself, with the [[function composition]] as [[group (mathematics)|group]] operation. Its [[identity element]] is the [[identity function]].&lt;ref&gt;{{citation
 | last1 = Burago | first1 = Dmitri
 | last2 = Burago | first2 = Yuri
 | last3 = Ivanov | first3 = Sergei
 | isbn = 0-8218-2129-6
 | mr = 1835418
 | page = 75
 | publisher = American Mathematical Society
 | location = Providence, RI
 | series = [[Graduate Studies in Mathematics]]
 | title = A course in metric geometry
 | url = https://books.google.com/books?id=afnlx8sHmQIC&amp;pg=PA75
 | volume = 33
 | year = 2001}}.&lt;/ref&gt;

A (generalized) isometry on a [[pseudo-Euclidean space]] preserves magnitude.

Every isometry group of a metric space is a [[subgroup]] of isometries. It represents in most cases a possible set of [[symmetry|symmetries]] of objects/figures in the space, or functions defined on the space. See [[symmetry group]].

A discrete isometry group is an isometry group such that for every point of the space the set of images of the point under the isometries is a [[discrete set]].

==Examples==

* The isometry group of the subspace of a [[metric space]] consisting of the points of a [[Triangle#Types_of_triangle|scalene triangle]] is the [[trivial group]]. A similar space for an isosceles triangle is the [[cyclic group]] of order two, C&lt;sub&gt;2&lt;/sub&gt;. A similar space for an equilateral triangle is the [[dihedral group]] of order three, D&lt;sub&gt;3&lt;/sub&gt;.
* The isometry group of a two-dimensional [[sphere]] is the [[orthogonal group]] O(3).&lt;ref&gt;{{citation
 | last = Berger | first = Marcel
 | doi = 10.1007/978-3-540-93816-3
 | isbn = 3-540-17015-4
 | mr = 882916
 | page = 281
 | publisher = Springer-Verlag
 | location = Berlin
 | series = Universitext
 | title = Geometry. II
 | url = https://books.google.com/books?id=6WZHAAAAQBAJ&amp;pg=PA281
 | year = 1987}}.&lt;/ref&gt;

* The isometry group of the ''n''-dimensional [[Euclidean space]] is the [[Euclidean group]] E(''n'').&lt;ref&gt;{{citation
 | last = Olver | first = Peter J. |author-link=Peter J. Olver 
 | doi = 10.1017/CBO9780511623660
 | isbn = 0-521-55821-2
 | mr = 1694364
 | page = 53
 | publisher = Cambridge University Press
 | location = Cambridge
 | series = London Mathematical Society Student Texts
 | title = Classical invariant theory
 | url = https://books.google.com/books?id=1GlHYhNRAqEC&amp;pg=PA53
 | volume = 44
 | year = 1999}}.&lt;/ref&gt;
* The isometry group of the [[hyperbolic plane]] is PGL(2,'''R''') = [[PSL(2,R)|PSL(2,'''R''').2]].

* The isometry group of [[Minkowski space]] is the [[Poincaré group]].&lt;ref&gt;{{citation
 | last1 = Müller-Kirsten | first1 = Harald J. W.
 | last2 = Wiedemann | first2 = Armin
 | doi = 10.1142/7594
 | edition = 2nd
 | isbn = 978-981-4293-42-6
 | mr = 2681020
 | page = 22
 | publisher = World Scientific Publishing Co. Pte. Ltd.
 | location = Hackensack, NJ
 | series = World Scientific Lecture Notes in Physics
 | title = Introduction to supersymmetry
 | url = https://books.google.com/books?id=RU-hsrWp9isC&amp;pg=PA22
 | volume = 80
 | year = 2010}}.&lt;/ref&gt;

* [[Riemannian symmetric space]]s are important cases where the isometry group is a [[Lie group]].

==See also==
*[[point groups in two dimensions]]
*[[point groups in three dimensions]]
*[[fixed points of isometry groups in Euclidean space]]

==References==
{{reflist}}

[[Category:Metric geometry]]


{{geometry-stub}}</text>
      <sha1>bwscffbwv28rpnwdwoiim9dmnrrn3ft</sha1>
    </revision>
  </page>
  <page>
    <title>Jacobus Naveros</title>
    <ns>0</ns>
    <id>17262516</id>
    <revision>
      <id>780321707</id>
      <parentid>744446243</parentid>
      <timestamp>2017-05-14T09:21:51Z</timestamp>
      <contributor>
        <username>Crispulop</username>
        <id>18684401</id>
      </contributor>
      <minor/>
      <comment>/* References */ Wikilink added</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1451">'''Jacob Naveros''' (fl. ca. 1533) was an early sixteenth-century Spanish logician. He is now known for his concern about the attribution of the logical works of [[Duns Scotus]].  Naveros found inconsistencies between the logical works and Scotus' commentary on the [[Sentences]] that caused him to doubt whether he had written any of these works.

Naveros was born at the end of the 15th century, at [[Castronuño]].&lt;ref&gt;{{cite book|author=Gonzalo Díaz Díaz|title=Hombres y Documentos de la Filosofía Española|url=https://books.google.com/books?id=cIKi5cPKOGwC&amp;pg=PA782|accessdate=26 May 2012|year=1995|publisher=CSIC|isbn=978-84-00-07504-0|pages=781–2|language=es}}&lt;/ref&gt; He wrote a number of works in Latin.&lt;ref&gt;{{cite book|author=Alexander S. Wilkinson|title=Iberian Books: Books Published in Spanish Or Portuguese Or on the Iberian Peninsula Before 1601|url=https://books.google.com/books?id=BqYf_3z8qW4C&amp;pg=PA531|accessdate=26 May 2012|date=15 December 2010|publisher=BRILL|isbn=978-90-04-17027-8|page=531}}&lt;/ref&gt;

== References ==

* Ashworth, E. J., 'Jacobus Naveros (fl. ca. 1533) on the Question: "Do Spoken Words Signify Concepts or Things?",' ''Logos and Pragma. Essays on the Philosophy of Language in Honour of Professor Gabriel Nuchelmans'', ed. de Rijk and [[Henk Braakhuis|Braakhuis]] (Nijmegen: Ingenium, 1987): 189–214.

==Notes==
{{reflist}}

[[Category:Scholasticism]]
[[Category:History of logic]]


{{spain-writer-stub}}</text>
      <sha1>ci4o6yyngefjmgi2biy6tbakz2uvqdi</sha1>
    </revision>
  </page>
  <page>
    <title>Kynea number</title>
    <ns>0</ns>
    <id>3691216</id>
    <revision>
      <id>859422721</id>
      <parentid>844164581</parentid>
      <timestamp>2018-09-13T23:30:27Z</timestamp>
      <contributor>
        <ip>75.87.166.10</ip>
      </contributor>
      <comment>Add base 12 prime</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6136">A '''Kynea number''' is an integer of the form

:&lt;math&gt;4^n + 2^{n + 1} - 1&lt;/math&gt;.

An equivalent formula is

:&lt;math&gt;(2^n + 1)^2 - 2&lt;/math&gt;.

This indicates that a Kynea number is the ''n''th power of 4 plus the (''n'' + 1)th [[Mersenne number]]. 
Kynea numbers were studied by Cletus Emmanuel who named them after a baby girl.&lt;ref&gt;[http://tech.groups.yahoo.com/group/primenumbers/message/14584 Cletus Emmanuel's statement on Yahoo group PrimeNumbers]&lt;/ref&gt;

The sequence of Kynea numbers starts with:
: [[7 (number)|7]], [[23 (number)|23]], [[79 (number)|79]], 287, 1087, 4223, 16639, 66047, 263167, 1050623, 4198399, 16785407, ... {{OEIS|id=A093069}}.

== Properties ==

The [[Binary numeral system|binary representation]] of the ''n''th Kynea number is a single leading one, followed by ''n'' - 1 consecutive zeroes, followed by ''n'' + 1 consecutive ones, or to put it algebraically:

:&lt;math&gt;4^n + \sum_{i = 0}^n 2^i.&lt;/math&gt;

So, for example, 23 is 10111 in binary, 79 is 1001111, etc. The difference between the ''n''th Kynea number and the ''n''th [[Carol number]] is the (''n'' + 2)th [[power of two]].

== Prime Kynea numbers ==
{| class="infobox" style="width: 15em; font-size: 90%; text-align: center;"
|-----
| colspan="3" align="center" | '''Kynea numbers'''
|-----
| '''n''' || Decimal || Binary
|-----
| '''1''' || 7 || 111
|-----
| '''2''' || 23 || 10111
|-----
| '''3''' || 79 || 1001111
|-----
| '''4''' || 287 || 100011111
|-----
| '''5''' || 1087 || 10000111111
|-----
| '''6''' || 4223 || 1000001111111
|-----
| '''7''' || 16639 || 100000011111111
|-----
| '''8''' || 66047 || 10000000111111111
|-----
| '''9''' || 263167 || 1000000001111111111
|}
Starting with 7, every third Kynea number is a multiple of 7. Thus, for a Kynea number to be a [[prime number]], its index ''n'' cannot be of the form 3''x'' + 1 for ''x'' &gt; 0. The first few Kynea numbers that are also prime are 7, 23, 79, 1087, 66047, 263167, 16785407 {{OEIS|id=A091514}}.

{{As of|2018|2}}, the largest known prime Kynea number has index ''n'' = 661478, which has 398250 digits.&lt;ref&gt;[http://primes.utm.edu/primes/page.php?id=121801 Entry for 661478th Kynea number] at [[Prime Pages]]&lt;/ref&gt;&lt;ref&gt;[http://www.noprimeleftbehind.net/Carol-Kynea-prime-search.htm Carol and Kynea Prime Search] by Mark Rodenkirch&lt;/ref&gt; It was found by Mark Rodenkirch in June 2016 using the programs CKSieve and PrimeFormGW.  It is the 50th Kynea prime.


{{Col-begin}}
{{Col-1-of-2}}

{{Col-2-of-2}}
{{Portal|Mathematics}}
{{Col-end}}

== Generalizations ==

A '''generalized Kynea number base ''b''''' is defined to be a number of the form (''b''&lt;sup&gt;''n''&lt;/sup&gt;+1)&lt;sup&gt;2&lt;/sup&gt; − 2 with ''n'' ≥ 1, a generalized Kynea number base ''b'' can be prime only if ''b'' is even, since if ''b'' is odd, then all generalized Kynea numbers base ''b'' are even and thus not prime. A generalized Kynea number to base ''b''&lt;sup&gt;''n''&lt;/sup&gt; is also a generalized Kynea number to base ''b''.

Least ''n'' ≥ 1 such that ((2''b'')&lt;sup&gt;''n''&lt;/sup&gt;+1)&lt;sup&gt;2&lt;/sup&gt; − 2 is prime are
:1, 1, 1, 1, 22, 1, 1, 2, 1, 1, 3, 24, 1, 1, 2, 1, 1, 1, 6, 2, 1, 3, 1, 1, 4, 3, 1, 8, 2, 1, 1, 2, 172, 1, 1, 354, 1, 1, 3, 29, 3, 423, 8, 1, 11, 1, 5, 2, 4, 11, 1, 6, 1, 3, 57, 24, 368, 1, 1, 1, 11, 19, 1, 3, 1, 13, 1, 12, 1, 41, 3, 1, 3, 4, 4, 2, 1, 152, 1893, 1, 12, 6, 2, 1, 11, 1, 2, 1, 3, 14, 1, 2, 6, 2, 1, 1017, 3, 30, 6, 3, ...

{|class="wikitable"
|''b''
|numbers ''n'' ≥ 1 such that (''b''&lt;sup&gt;''n''&lt;/sup&gt;+1)&lt;sup&gt;2&lt;/sup&gt; − 2 is prime (these ''n'' are checked up to 30000)
|[[OEIS]] sequence
|-
|2
|1, 2, 3, 5, 8, 9, 12, 15, 17, 18, 21, 23, 27, 32, 51, 65, 87, 180, 242, 467, 491, 501, 507, 555, 591, 680, 800, 1070, 1650, 2813, 3281, 4217, 5153, 6287, 6365, 10088, 10367, 37035, 45873, 69312, 102435, 106380, 108888, 110615, 281621, 369581, 376050, 442052, 621443, 661478, ...
|{{OEIS link|id=A091513}}
|-
|4
|1, 4, 6, 9, 16, 90, 121, 340, 400, 535, 825, 5044, 34656, 53190, 54444, 188025, 221026, 330739, ...
|
|-
|6
|1, 2, 3, 4, 9, 12, 30, 49, 56, 115, 118, 376, 432, 1045, 1310, 6529, 7768, 8430, 21942, 26930, 33568, 50800, ...
|{{OEIS link|id=A100902}}
|-
|8
|1, 3, 4, 5, 6, 7, 9, 17, 29, 60, 167, 169, 185, 197, 550, 12345, 15291, 23104, 34145, 35460, 36296, 125350, ...
|
|-
|10
|22, 351, 1061, ...
|{{OEIS link|id=A100904}}
|-
|12
|1, 2, 8, 60, 513, 1047, 7021, 7506, 78858, ...
|
|-
|14
|1, 5, 60, 72, 118, 181, 245, 310, 498, 820, 962, 2212, 3928, 5844, 5937, ...
|{{OEIS link|id=A100906}}
|-
|16
|2, 3, 8, 45, 170, 200, 2522, 17328, 26595, 27222, 110513, ...
|
|-
|18
|1, 10, 21, 25, 31, 1083, 40485, ...
|
|-
|20
|1, 15, 44, 77, 141, 208, 304, 1169, 3359, 5050, 22431, 34935, ...
|
|-
|22
|3, 166, 814, 1851, 2197, 3172, 3865, 19791, ...
|{{OEIS link|id=A100908}}
|-
|24
|24, 321, 971, 984, ...
|
|-
|26
|1, 2, 8, 78, 79, 111, 5276, 8226, 19545, 75993, ...
|
|-
|28
|1, 2, 11, 15, 586, 993, 5048, 24990, ...
|
|-
|30
|2, 3, 57, 129, 171, 9837, 30359, 157950, ...
|
|-
|32
|1, 3, 13, 36, 111, 136, 160, 214, 330, 1273, 7407, 20487, 21276, 22123, 75210, ...
|
|-
|34
|1, 2, 14, 29, 61, 146, 2901, 6501, 8093, ...
|
|-
|36
|1, 2, 6, 15, 28, 59, 188, 216, 655, 3884, 4215, 10971, 13465, 16784, 25400, ...
|
|-
|38
|6, 279, 3490, ...
|
|-
|40
|2, 49, 144, 825, 2856, 2996, 5166, 7824, 9392, 40778, ...
|
|-
|42
|1, 3, 4, 81, 119, 2046, 2466, 4020, 7907, 8424, 25002, ...
|
|-
|44
|3, 195, 1482, 8210, 20502, 60212, 95940, ...
|
|-
|46
|1, 54, 2040, 3063, ...
|
|-
|48
|1, 207, 329, 1153, 4687, 13274, 25978, ...
|
|-
|50
|4, 38, 93, 120, 4396, 11459, 25887, ...
|
|}

{{As of|2018|2}}, the largest known generalized Kynea prime is (30&lt;sup&gt;157950&lt;/sup&gt;+1)&lt;sup&gt;2&lt;/sup&gt; − 2.

==References==
&lt;references/&gt;

==External links==
* {{MathWorld|title=Near-Square Prime|urlname=Near-SquarePrime}}
* [http://primes.utm.edu/primes/page.php?id=121801 Prime Database entry for Kynea(661478)]
* [http://harvey563.tripod.com/Carol_Kynea.txt Carol and Kynea Primes]
* [http://www.noprimeleftbehind.net/Carol-Kynea-prime-search.htm Carol and Kynea Prime Search]

{{Prime number classes|state=collapsed}}
{{Classes of natural numbers}}

{{DEFAULTSORT:Kynea Number}}
[[Category:Integer sequences]]</text>
      <sha1>n4omuwqp85nfw8a5h6mdrtb8xbi4t1a</sha1>
    </revision>
  </page>
  <page>
    <title>List of formal systems</title>
    <ns>0</ns>
    <id>33382445</id>
    <revision>
      <id>616003650</id>
      <parentid>455316645</parentid>
      <timestamp>2014-07-07T21:42:45Z</timestamp>
      <contributor>
        <ip>74.111.50.112</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1625">This is a list of [[formal system]]s, also known as logical calculi.

==Mathematical==
* [[Domain relational calculus]], a calculus for the relational data model
* [[Functional calculus]], a way to apply various types of functions to operators
* [[Join calculus]], a theoretical model for distributed programming
* [[Lambda calculus]], a formulation of the theory of reflexive functions that has deep connections to computational theory
* [[Matrix calculus]], a specialized notation for multivariable calculus over spaces of matrices
* [[Modal μ-calculus]], a common temporal logic used by formal verification methods such as model checking
* [[Pi-calculus]], a formulation of the theory of concurrent, communicating processes that was invented by Robin Milner
* [[Predicate calculus]], specifies the rules of inference governing the logic of predicates
* [[Propositional calculus]], specifies the rules of inference governing the logic of propositions
* [[Refinement calculus]], a way of refining models of programs into efficient programs
* [[Rho calculus]], introduced as a general means to uniformly integrate rewriting and lambda calculus
* [[Tuple calculus]], a calculus for the relational data model, inspired the SQL language
* [[Umbral calculus]], the combinatorics of certain operations on polynomials
* [[Vector calculus]] (also called vector analysis), comprising specialized notations for multivariable analysis of vectors in an inner-product space

==Other formal systems==
* [[Formal ethics]]

==See also==
* [[Formal system]]

[[Category:Formal systems]]
[[Category:Mathematics-related lists|Formal systems]]</text>
      <sha1>sfcywyp1gglvljnjhs44bkjw2st7fuq</sha1>
    </revision>
  </page>
  <page>
    <title>List of mathematicians (L)</title>
    <ns>0</ns>
    <id>5971816</id>
    <revision>
      <id>871735750</id>
      <parentid>871295000</parentid>
      <timestamp>2018-12-03T03:09:34Z</timestamp>
      <contributor>
        <username>Mathbot</username>
        <id>234358</id>
      </contributor>
      <comment>Daily update. See [[User:Mathbot/Changes to mathlists]] for changes.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30328">__NOTOC__
{{MathTopicTOC}}

== L   ==

* [[Maurice L'Abbé|L'Abbé, Maurice]] (Canada, 1920–2006)
* [[Simon Antoine Jean L'Huilier|L'Huilier, Simon Antoine Jean]] (Switzerland, 1750–1840)
* [[Jean-Baptiste de La Chapelle|de La Chapelle, Jean-Baptiste]] (France, ?–?)
* [[Charles Marie de La Condamine|de La Condamine, Charles Marie]] (France, 1701–1774)
* [[Philippe de La Hire|de La Hire, Philippe]] (France, 1640–1719)
* [[Estienne de La Roche|de La Roche, Estienne]] (France, 1470–1530)
* [[Izabella Łaba|Łaba, Izabella]] (Canada/Poland, born 1966)
* [[Charles Labelye|Labelye, Charles]] (Switzerland, 1705–1781)
* [[Notker Labeo|Labeo, Notker]] (?, 950–1022)
* [[François Labourie|Labourie, François]] (France, born 1960)
* [[Carole Lacampagne|Lacampagne, Carole]] (?, ?–?)
* [[Michael Lacey|Lacey, Michael]] (USA, born 1959)
* [[Marc Lackenby|Lackenby, Marc]] (England, ?–?)
* [[Marius Lacombe|Lacombe, Marius]] (Switzerland, 1862–1938)
* [[Sylvestre François Lacroix|Lacroix, Sylvestre François]] (France, 1765–1843)
* [[Miklós Laczkovich|Laczkovich, Miklós]] (Hungary, born 1948)
* [[Christine Ladd-Franklin|Ladd-Franklin, Christine]] (USA, 1847–1930)
* [[Jeanne LaDuke|LaDuke, Jeanne]] (USA, born 1938)
* [[Olga Ladyzhenskaya|Ladyzhenskaya, Olga]] (Russia/Soviet Union, 1922–2004)
* [[Laurent Lafforgue|Lafforgue, Laurent]] (France, born 1966)
* [[Vincent Lafforgue|Lafforgue, Vincent]] (France, born 1974)
* [[Jeffrey Lagarias|Lagarias, Jeffrey]] (?, born 1949)
* [[Paco Lagerstrom|Lagerstrom, Paco]] (Sweden, 1914–1989)
* [[Thomas Fantet de Lagny|de Lagny, Thomas Fantet]] (France, 1660–1734)
* [[Joseph-Louis Lagrange|Lagrange, Joseph-Louis]] (?, 1736–1813)
* [[Edmond Laguerre|Laguerre, Edmond]] (France, 1834–1886)
* [[Ivo Lah|Lah, Ivo]] (Slovenia, 1896–1979)
* [[Radha Laha|Laha, Radha]] (India, 1930–1999)
* [[Ming-Jun Lai|Lai, Ming-Jun]] (USA, ?–?)
* [[Xuejia Lai|Lai, Xuejia]] (?, ?–?)
* [[Ying-Cheng Lai|Lai, Ying-Cheng]] (?, ?–?)
* [[Nan Laird|Laird, Nan]] (USA, born 1943)
* [[Charles-Ange Laisant|Laisant, Charles-Ange]] (France, 1841–1920)

== Lak ==

* [[Imre Lakatos|Lakatos, Imre]] (Hungary, 1922–1974)
* [[V. Lakshmibai|Lakshmibai, V.]] (India, ?–?)
* [[Dan Laksov|Laksov, Dan]] (Norway/Sweden, 1940–2013)
* [[Traian Lalescu|Lalescu, Traian]] (Romania, 1882–1929)
* [[Lalla]] (Medieval India, 720–790)
* [[Antoine de Laloubère|de Laloubère, Antoine]] (France, 1600–1664)
* [[Clement W. H. Lam|Lam, Clement W. H.]] (Canada, ?–?)
* [[Tsit Yuen Lam|Lam, Tsit Yuen]] (China, born 1942)
* [[Gerard Laman|Laman, Gerard]] (Netherlands, 1924–2009)
* [[Horace Lamb|Lamb, Horace]] (Britain, 1849–1934)
* [[John Lamb (priest)|Lamb, John]] (?, 1789–1850)
* [[Joachim Lambek|Lambek, Joachim]] (Canada, 1922–2014)
* [[Lambert of Auxerre]] (?, ?–?)
* [[Johann Heinrich Lambert|Lambert, Johann Heinrich]] (Switzerland, 1728–1777)
* [[Gabriel Lamé|Lamé, Gabriel]] (France, 1795–1870)
* [[Leslie Lamport|Lamport, Leslie]] (USA, born 1941)
* [[Bernard Lamy|Lamy, Bernard]] (France, 1640–1715)
* [[Henry Oliver Lancaster|Lancaster, Henry Oliver]] (Australia, 1913–2001)
* [[Cornelius Lanczos|Lanczos, Cornelius]] (Ireland, 1893–1974)
* [[Ailsa Land|Land, Ailsa]] (Britain, ?–?)
* [[Frank William Land|Land, Frank William]] (Britain, ?–?)
* [[Edmund Landau|Landau, Edmund]] (Germany, 1877–1938)
* [[Henry Landau|Landau, Henry]] (USA, ?–?)
* [[Susan Landau|Landau, Susan]] (USA, born 1954)
* [[John Landen|Landen, John]] (Britain, 1719–1790)
* [[Eric Lander|Lander, Eric]] (USA, born 1957)
* [[Evgenii Landis|Landis, Evgenii]] (Russia/Soviet Union, 1921–1997)
* [[Peter Landrock|Landrock, Peter]] (Denmark, born 1948)
* [[Georg Landsberg|Landsberg, Georg]] (Germany, 1865–1912)
* [[Peter Landweber|Landweber, Peter]] (USA, born 1940)
* [[Ernest Preston Lane|Lane, Ernest Preston]] (?, 1886–1969)
* [[Saunders Mac Lane|Lane, Saunders Mac]] (USA, 1909–2005)
* [[Oscar Lanford|Lanford, Oscar]] (?, 1940–2013)
* [[Peter Redford Scott Lang|Lang, Peter Redford Scott]] (Britain, 1850–1926)
* [[Serge Lang|Lang, Serge]] (USA, 1927–2005)
* [[Fredrik Lange-Nielsen|Lange-Nielsen, Fredrik]] (Norway, 1891–1980)
* [[Tanja Lange|Lange, Tanja]] (Germany, ?–?)
* [[Rudolf Ernest Langer|Langer, Rudolf Ernest]] (USA, 1894–1968)
* [[Rutger von Langerfeld|von Langerfeld, Rutger]] (Netherlands, 1635–1695)
* [[Stefan Langerman|Langerman, Stefan]] (Belgium, ?–?)
* [[Robert Langlands|Langlands, Robert]] (Canada, born 1936)
* [[Karl Christian von Langsdorf|von Langsdorf, Karl Christian]] (Germany, 1757–1834)
* [[Christian Lantuéjoul|Lantuéjoul, Christian]] (France, born 1950)
* [[Johann Lantz|Lantz, Johann]] (Germany, 1564–1638)

== Lap ==

* [[Giorgio Lapazaya|Lapazaya, Giorgio]] (Italy, 1490s–1570s)
* [[Erez Lapid|Lapid, Erez]] (Israel, born 1971)
* [[Pierre-Simon Laplace|Laplace, Pierre-Simon]] (France, 1749–1827)
* [[Glenda Lappan|Lappan, Glenda]] (USA, born 1939)
* [[Ari Laptev|Laptev, Ari]] (Ukraine, born 1950)
* [[Mohammad-Javad Larijani|Larijani, Mohammad-Javad]] (Iran, born 1951)
* [[Jill H. Larkin|Larkin, Jill H.]] (USA, born 1943)
* [[Joseph Larmor|Larmor, Joseph]] (Ireland, 1857–1942)
* [[Lawrence L. Larmore|Larmore, Lawrence]] (USA, ?–?)
* [[Michael J. Larsen|Larsen, Michael J.]] (USA, ?–?)
* [[Jean A. Larson|Larson, Jean A.]] (?, ?–?)
* [[Ron Larson|Larson, Ron]] (USA, born 1941)
* [[Nathan D'Laryea|D'Laryea, Nathan]] (?, born 1985)
* [[Alain Lascoux|Lascoux, Alain]] (France, 1944–2013)
* [[Richard Lashof|Lashof, Richard]] (USA, 1922–2010)
* [[Irena Lasiecka|Lasiecka, Irena]] (Poland, born 1948)
* [[Václav Láska|Láska, Václav]] (Czech Republic, 1862–1943)
* [[Renu C. Laskar|Laskar, Renu C.]] (India, ?–?)
* [[Emanuel Lasker|Lasker, Emanuel]] (Germany, 1868–1941)
* [[Étienne Laspeyres|Laspeyres, Étienne]] (?, 1834–1913)
* [[Yves Laszlo|Laszlo, Yves]] (France, ?–?)
* [[John Hiram Lathrop|Lathrop, John Hiram]] (?, 1799–1866)
* [[Claiborne Latimer|Latimer, Claiborne]] (USA, 1893–1960)
* [[Vito Latora|Latora, Vito]] (?, ?–?)
* [[Klavdiya Latysheva|Latysheva, Klavdiya]] (Soviet Union/Ukraine, 1897–1956)
* [[Arnfinn Laudal|Laudal, Arnfinn]] (Norway, born 1936)
* [[Henry Laufer|Laufer, Henry]] (USA, born 1940s)
* [[Detlef Laugwitz|Laugwitz, Detlef]] (Germany, 1932–2000)
* [[Gérard Laumon|Laumon, Gérard]] (France, born 1952)
* [[Wilhelm Launhardt|Launhardt, Wilhelm]] (Germany, 1832–1918)
* [[Monique Laurent|Laurent, Monique]] (France/Netherlands, ?–?)
* [[Paul Matthieu Hermann Laurent|Laurent, Paul Matthieu Hermann]] (France, 1841–1908)
* [[Pierre Alphonse Laurent|Laurent, Pierre Alphonse]] (France, 1813–1854)
* [[Giuseppe Lauricella|Lauricella, Giuseppe]] (Sicily, 1867–1913)
* [[Ben Laurie|Laurie, Ben]] (?, ?–?)
* [[Steffen Lauritzen|Lauritzen, Steffen]] (England, born 1947)
* [[Kristin Lauter|Lauter, Kristin]] (USA, born 1969)

== Lav ==

* [[Richard Laver|Laver, Richard]] (USA, 1942–2012)
* [[Mikhail Lavrentyev|Lavrentyev, Mikhail]] (Russia/Soviet Union, 1900–1980)
* [[Alexander Lavut|Lavut, Alexander]] (Soviet Union, 1929–2013)
* [[John Law (bishop)|Law, John]] (England, 1745–1810)
* [[Derek Frank Lawden|Lawden, Derek Frank]] (New Zealand/England, 1919–2008)
* [[Greg Lawler|Lawler, Greg]] (?, born 1955)
* [[Charles Lawrence (mathematician)|Lawrence, Charles]] (USA, ?–?)
* [[Ruth Lawrence|Lawrence, Ruth]] (England/Israel, born 1971)
* [[Duncan Lawson|Lawson, Duncan]] (Britain, ?–?)
* [[H. Blaine Lawson|Lawson, H. Blaine]] (USA, born 1942)
* [[William Lawvere|Lawvere, William]] (USA, born 1937)
* [[Anneli Cahn Lax|Lax, Anneli Cahn]] (USA, 1922–1999)
* [[Gaspar Lax|Lax, Gaspar]] (Spain, 1487–1560)
* [[Peter Lax|Lax, Peter]] (Hungary, born 1926)
* [[William Lax|Lax, William]] (England, 1761–1836)
* [[Anita Layton|Layton, Anita]] (Hong Kong, ?–?)
* [[Daniel Lazard|Lazard, Daniel]] (France, born 1941)
* [[Michel Lazard|Lazard, Michel]] (France, 1924–1985)
* [[Robert Lazarsfeld|Lazarsfeld, Robert]] (USA, born 1953)
* [[Yang Le|Le, Yang]] (China, born 1939)
* [[Imre Leader|Leader, Imre]] (Britain, born 1963)
* [[Jeffery J. Leader|Leader, Jeffery J.]] (?, born 1963)
* [[Francisco Santos Leal|Leal, Francisco Santos]] (Spain, born 1968)
* [[Léopold Leau|Leau, Léopold]] (France, 1868–1943)
* [[Nikolai Andreevich Lebedev|Lebedev, Nikolai Andreevich]] (Russia, 1919–1982)
* [[Vyacheslav Ivanovich Lebedev|Lebedev, Vyacheslav Ivanovich]] (Russia/Soviet Union, 1930–2010)
* [[Wilhelm Leber|Leber, Wilhelm]] (Germany, born 1947)
* [[Henri Lebesgue|Lebesgue, Henri]] (France, 1875–1941)
* [[Victor-Amédée Lebesgue|Lebesgue, Victor-Amédée]] (?, 1791–1875)
* [[Auguste-Savinien Leblond|Leblond, Auguste-Savinien]] (France, 1760–1811)
* [[Joel Lebowitz|Lebowitz, Joel]] (?, born 1930)
* [[Claude LeBrun|LeBrun, Claude]] (USA, ?–?)

== Lec ==

* [[Giovanni Antonio Lecchi|Lecchi, Giovanni Antonio]] (Italy, ?–?)
* [[Cristobal Lechuga|Lechuga, Cristobal]] (Spain, 1557–1622)
* [[Noether Lecture|Lecture, Noether]] (?, ?–?)
* [[AWM/MAA Falconer Lecturer|Lecturer, AWM/MAA Falconer]] (?, ?–?)
* [[Gilah Leder|Leder, Gilah]] (?, ?–?)
* [[Leon M. Lederman|Lederman, Leon M.]] (USA, 1922–2018)
* [[Walter Ledermann|Ledermann, Walter]] (Germany/Britain, 1911–2009)
* [[Michel Ledoux|Ledoux, Michel]] (France, born 1958)
* [[Alice Lee (mathematician)|Lee, Alice (mathematician)]] (Britain, 1858–1939)
* [[John M. Lee|Lee, John M.]] (?, born 1950)
* [[Jon Lee (mathematician)|Lee, Jon]] (USA, born 1960)
* [[Pil Joong Lee|Lee, Pil Joong]] (?, ?–?)
* [[John Leech (mathematician)|Leech, John]] (?, 1926–1992)
* [[Charles Leedham-Green|Leedham-Green, Charles]] (Britain, ?–?)
* [[Bram van Leer|van Leer, Bram]] (?, born 1940s)
* [[Edith de Leeuw|de Leeuw, Edith]] (Netherlands, born 1962)
* [[Marc van Leeuwen|van Leeuwen, Marc]] (Netherlands, born 1960)
* [[Vladimir Lefebvre|Lefebvre, Vladimir]] (Russia, born 1936)
* [[Solomon Lefschetz|Lefschetz, Solomon]] (USA, 1884–1972)
* [[Joceline Lega|Lega, Joceline]] (France, ?–?)
* [[Marcel Légaut|Légaut, Marcel]] (France, 1900–1990)
* [[Adrien-Marie Legendre|Legendre, Adrien-Marie]] (France, 1752–1833)
* [[Émile Léger|Léger, Émile]] (France, 1795–1838)
* [[Anne M. Leggett|Leggett, Anne M.]] (?, ?–?)
* [[Erich Leo Lehmann|Lehmann, Erich Leo]] (USA, 1917–2009)
* [[Derrick Henry Lehmer|Lehmer, Derrick Henry]] (USA, 1905–1991)
* [[Derrick Norman Lehmer|Lehmer, Derrick Norman]] (USA, 1867–1938)
* [[Emma Lehmer|Lehmer, Emma]] (USA, 1906–2007)
* [[C. L. Lehmus|Lehmus, C. L.]] (Germany, 1780–1863)
* [[Joseph Lehner|Lehner, Joseph]] (USA, 1912–2013)
* [[John Lehoczky|Lehoczky, John]] (USA, ?–?)
* [[Marguerite Lehr|Lehr, Marguerite]] (USA, 1898–1987)
* [[Tom Lehrer|Lehrer, Tom]] (USA, born 1928)
* [[Olli Lehto|Lehto, Olli]] (Finland, born 1925)

== Lei ==

* [[Tan Lei|Lei, Tan]] (China/France, 1963–2016)
* [[Richard Leibler|Leibler, Richard]] (USA, 1914–2003)
* [[Gottfried Wilhelm Leibniz|Leibniz, Gottfried Wilhelm]] (Germany, 1646–1716)
* [[Éric Leichtnam|Leichtnam, Éric]] (France, ?–?)
* [[Kurt Leichtweiss|Leichtweiss, Kurt]] (Germany, 1927–2013)
* [[Wolfgang Leinberer|Leinberer, Wolfgang]] (Germany, 1635–1693)
* [[Felix Leinen|Leinen, Felix]] (Germany, born 1957)
* [[William Leitch (scientist)|Leitch, William]] (Scotland, 1814–1864)
* [[Louis Leithold|Leithold, Louis]] (USA, 1924–2005)
* [[Joan Leitzel|Leitzel, Joan]] (USA, born 1936)
* [[Miriam Leiva|Leiva, Miriam]] (?, ?–?)
* [[Franciszek Leja|Leja, Franciszek]] (Poland, 1885–1979)
* [[Peter Gustav Lejeune Dirichlet|Lejeune Dirichlet, Peter Gustav]] (Germany, 1805–1859)
* [[Mary de Lellis Gough|de Lellis Gough, Mary]] (USA, 1892–1983)
* [[Pierre Lelong|Lelong, Pierre]] (France, 1912–2011)
* [[Mariusz Lemańczyk|Lemańczyk, Mariusz]] (Poland, ?–?)
* [[Moses Lemans|Lemans, Moses]] (Netherlands, 1785–1832)
* [[Claude Lemaréchal|Lemaréchal, Claude]] (France, ?–?)
* [[Carlton E. Lemke|Lemke, Carlton E.]] (?, 1920–2004)
* [[Émile Lemoine|Lemoine, Émile]] (France, 1840–1912)
* [[László Lempert|Lempert, László]] (Hungary, born 1952)
* [[Ernő Lendvai|Lendvai, Ernő]] (Hungary, 1925–1993)
* [[Wilfrid Leng|Leng, Wilfrid]] (England, 1952–2002)
* [[Thomas Lengauer|Lengauer, Thomas]] (Germany, born 1952)
* [[Suzanne Lenhart|Lenhart, Suzanne]] (?, ?–?)
* [[John Lennard-Jones|Lennard-Jones, John]] (Britain, 1894–1954)
* [[John Lennox|Lennox, John]] (Ireland, born 1943)
* [[Arjen Lenstra|Lenstra, Arjen]] (Netherlands, born 1956)
* [[Hendrik Lenstra|Lenstra, Hendrik]] (Netherlands, born 1949)
* [[Jan Karel Lenstra|Lenstra, Jan Karel]] (Netherlands, born 1947)
* [[Hanfried Lenz|Lenz, Hanfried]] (?, 1916–2013)

== Leo ==

* [[Andries Mac Leod|Leod, Andries Mac]] (Belgium, 1891–1977)
* [[Leodamas of Thasos]] (Ancient Greece, ?–?)
* [[Leon (mathematician)|Leon]] (Greece, ?–?)
* [[Alexey Fedorovich Leontiev|Leontiev, Alexey Fedorovich]] (Soviet Union, ?–?)
* [[Heinrich-Wolfgang Leopoldt|Leopoldt, Heinrich-Wolfgang]] (Germany, 1927–2011)
* [[Vincent Leotaud|Leotaud, Vincent]] (France, 1595–1672)
* [[Théophile Lepage|Lepage, Théophile]] (Belgium, 1901–1991)
* [[James Lepowsky|Lepowsky, James]] (USA, born 1944)
* [[Jean Leray|Leray, Jean]] (France, 1906–1998)
* [[Mathias Lerch|Lerch, Mathias]] (Czech Republic, 1860–1922)
* [[Oswald Leroy|Leroy, Oswald]] (Belgium, born 1935)
* [[C. E. V. Leser|Leser, C. E. V.]] (?, 1915–1998)
* [[Frank Matthews Leslie|Leslie, Frank Matthews]] (Scotland, 1935–2000)
* [[John Leslie (physicist)|Leslie, John]] (Scotland, 1766–1832)
* [[Stanisław Leśniewski|Leśniewski, Stanisław]] (Poland, 1886–1939)
* [[Aleksey Letnikov|Letnikov, Aleksey]] (Russia, 1837–1888)
* [[Jacob Leupold|Leupold, Jacob]] (Germany, 1674–1727)
* [[Jean Leurechon|Leurechon, Jean]] (France, 1591–1670)
* [[Gijsbert de Leve|de Leve, Gijsbert]] (Netherlands, 1926–2009)
* [[Vladimir Levenshtein|Levenshtein, Vladimir]] (Russia/Soviet Union, 1935–2017)
* [[Randall J. LeVeque|LeVeque, Randall J.]] (USA, ?–?)
* [[William J. LeVeque|LeVeque, William J.]] (USA, 1923–2007)
* [[Libera Trevisani Levi-Civita|Levi-Civita, Libera Trevisani]] (Italy, 1890–1973)
* [[Tullio Levi-Civita|Levi-Civita, Tullio]] (Italy, 1873–1941)
* [[Beppo Levi|Levi, Beppo]] (Argentina, 1875–1961)
* [[Eugenio Elia Levi|Levi, Eugenio Elia]] (Italy, 1883–1917)
* [[Friedrich Wilhelm Levi|Levi, Friedrich Wilhelm]] (Germany, 1888–1966)
* [[Howard Levi|Levi, Howard]] (USA, 1916–2002)
* [[Boris Levin|Levin, Boris]] (Soviet Union, 1906–1993)
* [[Janna Levin|Levin, Janna]] (?, ?–?)
* [[Leonid Levin|Levin, Leonid]] (Russia/Soviet Union, born 1948)
* [[Harold Levine|Levine, Harold]] (USA, ?–2017)
* [[Jerome Levine|Levine, Jerome]] (USA, 1937–2006)
* [[Norman Levinson|Levinson, Norman]] (USA, 1912–1975)
* [[Boris Levit|Levit, Boris]] (Russia/Canada/Moldova, ?–?)
* [[Boris Levitan|Levitan, Boris]] (?, 1914–2004)
* [[Norman Levitt|Levitt, Norman]] (?, 1943–2009)
* [[Jacob Levitzki|Levitzki, Jacob]] (Israel, 1904–1956)
* [[Azriel Lévy|Lévy, Azriel]] (Israel, born 1934)
* [[Hyman Levy|Levy, Hyman]] (Scotland, 1889–1975)
* [[Maurice Lévy|Lévy, Maurice]] (France, 1838–1910)
* [[Paul Lévy (mathematician)|Lévy, Paul]] (France, 1886–1971)
* [[Tony Lévy|Lévy, Tony]] (?, born 1943)

== Lew ==

* [[Marta Lewicka|Lewicka, Marta]] (Poland, ?–?)
* [[Mathieu Lewin|Lewin, Mathieu]] (France, born 1977)
* [[Alain A. Lewis|Lewis, Alain A.]] (USA, born 1947)
* [[Donald John Lewis|Lewis, Donald John]] (USA, 1926–2015)
* [[Enoch Lewis (mathematician)|Lewis, Enoch]] (USA, 1776–1856)
* [[Florence Lewis|Lewis, Florence]] (USA, born 1877)
* [[Harry R. Lewis|Lewis, Harry R.]] (?, born 1947)
* [[John T. Lewis|Lewis, John T.]] (Ireland/Wales, 1932–2004)
* [[Tony Lewis (mathematician)|Lewis, Tony]] (England, ?–?)
* [[Richard Lewontin|Lewontin, Richard]] (USA, born 1929)
* [[Hans Lewy|Lewy, Hans]] (Germany, 1904–1988)
* [[Anders Johan Lexell|Lexell, Anders Johan]] (Imperial Russia, 1740–1784)
* [[Wilhelm Lexis|Lexis, Wilhelm]] (Germany, 1837–1914)
* [[William Leybourn|Leybourn, William]] (England, 1626–1716)
* [[Paul Leyland|Leyland, Paul]] (Britain, ?–?)
* [[C. C. Li|Li, C. C.]] (China/USA, 1912–2003)
* [[David X. Li|Li, David X.]] (?, ?–?)
* [[Jun Li (mathematician)|Li, Jun]] (China, ?–?)
* [[Michael Li|Li, Michael]] (?, ?–?)
* [[Sherry Li|Li, Sherry]] (China, ?–?)
* [[Tien-Yien Li|Li, Tien-Yien]] (?, born 1945)
* [[Winnie Li|Li, Winnie]] (China, born 1948)
* [[You-Dong Liang|Liang, You-Dong]] (China, born 1935)
* [[Joseph Liberman|Liberman, Joseph]] (Soviet Union, 1917–1941)
* [[Paulette Libermann|Libermann, Paulette]] (France, 1919–2007)
* [[Anatoly Libgober|Libgober, Anatoly]] (USA/Russia/Soviet Union, born 1949)
* [[André Lichnerowicz|Lichnerowicz, André]] (France, 1915–1998)
* [[Stephen Lichtenbaum|Lichtenbaum, Stephen]] (USA, born 1939)
* [[Gabriel Judah Lichtenfeld|Lichtenfeld, Gabriel Judah]] (Poland, 1811–1887)
* [[Leon Lichtenstein|Lichtenstein, Leon]] (Poland, 1878–1933)
* [[W. B. R. Lickorish|Lickorish, W. B. R.]] (?, born 1935)

== Lid ==

* [[Duncan Liddel|Liddel, Duncan]] (Scotland, 1561–1613)
* [[Victor Lidskii|Lidskii, Victor]] (Russia/Soviet Union/Ukraine, 1924–2008)
* [[Sophus Lie|Lie, Sophus]] (Norway, 1842–1899)
* [[Elliott H. Lieb|Lieb, Elliott H.]] (USA, born 1932)
* [[Lillian Rosanoff Lieber|Lieber, Lillian Rosanoff]] (Ukraine, 1886–1986)
* [[Magnhild Lien|Lien, Magnhild]] (Norway, ?–?)
* [[Jiang Lifu|Lifu, Jiang]] (China, 1890–1978)
* [[Thomas M. Liggett|Liggett, Thomas M.]] (?, born 1944)
* [[N. M. H. Lightfoot|Lightfoot, N. M. H.]] (Britain, 1902–1962)
* [[James Lighthill|Lighthill, James]] (Britain, 1924–1998)
* [[A. H. Lightstone|Lightstone, A. H.]] (Canada, 1926–1976)
* [[Daniel Lightwing|Lightwing, Daniel]] (England, born 1988)
* [[Rensis Likert|Likert, Rensis]] (USA, 1903–1981)
* [[Hubert Lilliefors|Lilliefors, Hubert]] (USA, 1928–2008)
* [[Elon Lages Lima|Lima, Elon Lages]] (Brazil, 1929–2017)
* [[Chia-Chiao Lin|Lin, Chia-Chiao]] (China/USA, 1916–2013)
* [[Michael Lin (mathematician)|Lin, Michael]] (Israel, born 1942)
* [[Baruch Lindau|Lindau, Baruch]] (Germany, 1759–1849)
* [[Jarl Waldemar Lindeberg|Lindeberg, Jarl Waldemar]] (Finland, 1876–1932)
* [[Ernst Leonard Lindelöf|Lindelöf, Ernst Leonard]] (Finland, 1870–1946)
* [[Lorenz Leonard Lindelöf|Lindelöf, Lorenz Leonard]] (Finland, 1827–1908)
* [[Ferdinand von Lindemann|von Lindemann, Ferdinand]] (Germany, 1852–1939)
* [[Paul Linden|Linden, Paul]] (?, born 1947)
* [[Adolf Lindenbaum|Lindenbaum, Adolf]] (Poland, 1904–1941)
* [[Elon Lindenstrauss|Lindenstrauss, Elon]] (Israel, born 1970)
* [[Joram Lindenstrauss|Lindenstrauss, Joram]] (Israel, 1936–2012)
* [[Harry Lindgren|Lindgren, Harry]] (Australia, 1912–1992)
* [[Dennis Lindley|Lindley, Dennis]] (England, born 1923)
* [[Anders Lindstedt|Lindstedt, Anders]] (Sweden, 1854–1939)
* [[Per Lindström|Lindström, Per]] (Sweden, 1936–2009)
* [[Edward Linfoot|Linfoot, Edward]] (England, 1905–1982)
* [[Nati Linial|Linial, Nati]] (Israel, born 1953)
* [[Seppo Linnainmaa|Linnainmaa, Seppo]] (Finland, born 1945)
* [[Yuri Linnik|Linnik, Yuri]] (Russia/Soviet Union, 1915–1972)
* [[Harold A. Linstone|Linstone, Harold A]] (USA, born 1924)
* [[J. H. van Lint|van Lint, J. H.]] (?, 1932–2004)
* [[Adam Lintz|Lintz, Adam]] (Netherlands, 1630s–1705)

== Lio ==

* [[François Le Lionnais|Le Lionnais, François]] (France, 1901–1984)
* [[Jacques-Louis Lions|Lions, Jacques-Louis]] (France, 1928–2001)
* [[Pierre-Louis Lions|Lions, Pierre-Louis]] (France, born 1956)
* [[Joseph Liouville|Liouville, Joseph]] (France, 1809–1882)
* [[Yom Tov Lipman Lipkin|Lipkin, Yom Tov Lipman]] (Lithuania, 1846–1876)
* [[Joseph Lipman|Lipman, Joseph]] (Canada, born 1938)
* [[Rudolf Lipschitz|Lipschitz, Rudolf]] (Germany, 1832–1903)
* [[Seymour Lipschutz|Lipschutz, Seymour]] (USA, ?–?)
* [[Richard Lipton|Lipton, Richard]] (?, born 1946)
* [[Robert B. Lisek|Lisek, Robert B.]] (Poland, ?–?)
* [[Jules Antoine Lissajous|Lissajous, Jules Antoine]] (France, 1822–1880)
* [[List of mathematicians (W)|List of mathematicians]] (?, ?–?)
* [[Johann Benedict Listing|Listing, Johann Benedict]] (Germany, 1808–1882)
* [[Peter Littelmann|Littelmann, Peter]] (Germany, ?–?)
* [[Charles Newton Little|Little, Charles Newton]] (?, 1858–1923)
* [[Dudley E. Littlewood|Littlewood, Dudley E.]] (Britain, 1903–1976)
* [[John Edensor Littlewood|Littlewood, John Edensor]] (England, 1885–1977)
* [[Elizaveta Litvinova|Litvinova, Elizaveta]] (Russia, 1845–1919)
* [[Marie Litzinger|Litzinger, Marie]] (?, 1899–1952)
* [[Andy Liu|Liu, Andy]] (Canada, ?–?)
* [[Chiu-Chu Melissa Liu|Liu, Chiu-Chu Melissa]] (Taiwan, born 1974)
* [[Kefeng Liu|Liu, Kefeng]] (China, born 1965)
* [[Sifeng Liu|Liu, Sifeng]] (China, born 1955)
* [[Tai-Ping Liu|Liu, Tai-Ping]] (Taiwan, born 1945)
* [[George Henry Livens|Livens, George Henry]] (Britain, 1886–1950)
* [[Mikhail Samuilovich Livsic|Livsic, Mikhail Samuilovich]] (Ukraine/Israel, 1917–2007)
* [[Wilhelm Ljunggren|Ljunggren, Wilhelm]] (Norway, 1905–1973)
* [[Bartholomew Lloyd|Lloyd, Bartholomew]] (Ireland, 1772–1837)
* [[Ramon Llull|Llull, Ramon]] (Medieval Spain, 1230s–1315)
* [[Martin Lo|Lo, Martin]] (USA, ?–?)

== Loa ==

* [[Charles F. Van Loan|Loan, Charles F. Van]] (USA, 19??–?)
* [[Martin Löb|Löb, Martin]] (Germany, 1921–2006)
* [[Nikolai Lobachevsky|Lobachevsky, Nikolai]] (Russia, 1792–1856)
* [[Rehuel Lobatto|Lobatto, Rehuel]] (Netherlands, 1797–1866)
* [[Klara Löbenstein|Löbenstein, Klara]] (Germany, born 1883)
* [[Juan Caramuel y Lobkowitz|y Lobkowitz, Juan Caramuel]] (Spain, 1606–1682)
* [[Deborah Frank Lockhart|Lockhart, Deborah Frank]] (?, ?–?)
* [[J. B. Lockhart|Lockhart, J. B.]] (Britain, 1886–1969)
* [[James Lockhart (banker)|Lockhart, James]] (England, 1763–1852)
* [[Jean-Louis Loday|Loday, Jean-Louis]] (France, 1946–2012)
* [[Alfred Lodge|Lodge, Alfred]] (England, 1854–1937)
* [[Derek Lodge|Lodge, Derek]] (England, 1929–1996)
* [[Peter A. Loeb|Loeb, Peter A.]] (?, ?–?)
* [[Clive Loehnis|Loehnis, Clive]] (?, 1902–1992)
* [[Susan Loepp|Loepp, Susan]] (?, ?–?)
* [[François Loeser|Loeser, François]] (France, born 1958)
* [[Michel Loève|Loève, Michel]] (France, 1907–1979)
* [[Charles Loewner|Loewner, Charles]] (Czech Republic, 1893–1968)
* [[Alfred Loewy|Loewy, Alfred]] (Germany, 1873–1935)
* [[Adam Logan|Logan, Adam]] (Canada, born 1975)
* [[George Logemann|Logemann, George]] (USA, 1938–2012)
* [[Apollodorus Logisticus|Logisticus, Apollodorus]] (Ancient Greece, ?–?)
* [[Mayme Logsdon|Logsdon, Mayme]] (?, born 1881)
* [[Aleksandr Logunov (mathematician)|Logunov, Aleksandr (mathematician)]] (Russia, ?–?)
* [[Po-Shen Loh|Loh, Po-Shen]] (?, ?–?)
* [[Arthur J. Lohwater|Lohwater, Arthur J.]] (USA, 1922–1982)
* [[Stanisław Łojasiewicz|Łojasiewicz, Stanisław]] (Poland, 1926–2002)
* [[Henk Lombaers|Lombaers, Henk]] (Netherlands, 1920–2007)
* [[Lucio Lombardo-Radice|Lombardo-Radice, Lucio]] (Italy, 1916–1982)
* [[Antoni Łomnicki|Łomnicki, Antoni]] (Poland, 1881–1941)
* [[Samuel J. Lomonaco Jr.|Lomonaco Jr., Samuel J.]] (USA, ?–?)
* [[Victor Lomonosov|Lomonosov, Victor]] (Russia, 1946–2018)
* [[Igor Lomov|Lomov, Igor]] (Russia, ?–?)

== Lon ==

* [[S. L. Loney|Loney, S. L.]] (England, 1860–1939)
* [[Ling Long (mathematician)|Long, Ling (mathematician)]] (China, ?–?)
* [[Lynette Long|Long, Lynette]] (USA, born 1948)
* [[Gaston Albert Gohierre de Longchamps|de Longchamps, Gaston Albert Gohierre]] (France, 1842–1906)
* [[Mountifort Longfield|Longfield, Mountifort]] (Ireland, 1802–1884)
* [[Giovanni Lodovico Longo|Longo, Giovanni Lodovico]] (Italy, ?–?)
* [[Michael S. Longuet-Higgins|Longuet-Higgins, Michael S.]] (England, 1925–2016)
* [[Judith Q. Longyear|Longyear, Judith Q.]] (?, 1938–1995)
* [[Adam Lonicer|Lonicer, Adam]] (Germany, 1528–1586)
* [[Eduard Looijenga|Looijenga, Eduard]] (Netherlands, born 1948)
* [[Elias Loomis|Loomis, Elias]] (?, 1811–1889)
* [[Elisha Scott Loomis|Loomis, Elisha Scott]] (USA, 1852–1940)
* [[Lynn Harold Loomis|Loomis, Lynn Harold]] (USA, 1915–1994)
* [[Leiki Loone|Loone, Leiki]] (Estonia, born 1944)
* [[Yaroslav Lopatinskii|Lopatinskii, Yaroslav]] (Russia, 1906–1981)
* [[Artur Oscar Lopes|Lopes, Artur Oscar]] (Brazil, born 1950)
* [[Helena J. Nussenzveig Lopes|Lopes, Helena J. Nussenzveig]] (Brazil, ?–?)
* [[Santiago López de Medrano|López de Medrano, Santiago]] (Mexico, born 1942)
* [[Edgar Lorch|Lorch, Edgar]] (USA, 1907–1990)
* [[Lee Lorch|Lorch, Lee]] (Canada, 1915–2014)
* [[Frederic M. Lord|Lord, Frederic M.]] (?, 1912–2000)
* [[Edward Norton Lorenz|Lorenz, Edward Norton]] (USA, 1917–2008)
* [[Ludvig Lorenz|Lorenz, Ludvig]] (Denmark, 1829–1891)
* [[Paul Lorenzen|Lorenzen, Paul]] (Germany, 1915–1994)
* [[Antonio Maria Lorgna|Lorgna, Antonio Maria]] (?, 1735–1796)
* [[Gino Loria|Loria, Gino]] (Italy, 1862–1954)
* [[Peter James Lorimer|Lorimer, Peter James]] (New Zealand, 1939–2010)
* [[Jerzy Łoś|Łoś, Jerzy]] (Poland, 1920–1998)
* [[María Falk de Losada|de Losada, María Falk]] (Colombia, ?–?)
* [[Alfred J. Lotka|Lotka, Alfred J.]] (USA, 1880–1949)
* [[John Lott (mathematician)|Lott, John]] (USA, born 1959)

== Lou ==

* [[Simon de la Loubère|de la Loubère, Simon]] (?, 1642–1729)
* [[Carlos Lousto|Lousto, Carlos]] (Argentina, ?–?)
* [[László Lovász|Lovász, László]] (Hungary, born 1948)
* [[Augustus Edward Hough Love|Love, Augustus Edward Hough]] (Britain, 1863–1940)
* [[Clyde E. Love|Love, Clyde E.]] (USA, 1882–1960)
* [[Ada Lovelace|Lovelace, Ada]] (England, 1815–1852)
* [[Donald W. Loveland|Loveland, Donald W.]] (USA, born 1934)
* [[David Lovelock|Lovelock, David]] (Britain, born 1938)
* [[Joseph Lovering|Lovering, Joseph]] (USA, 1813–1892)
* [[Edgar Odell Lovett|Lovett, Edgar Odell]] (USA, 1871–1957)
* [[Benedikt Löwe|Löwe, Benedikt]] (Germany, born 1972)
* [[Leopold Löwenheim|Löwenheim, Leopold]] (Germany, 1878–1957)
* [[Baruch Solomon Löwenstein|Löwenstein, Baruch Solomon]] (?, ?–?)
* [[David Lowery (musician)|Lowery, David]] (USA, born 1960)
* [[Tom Lowrie (professor)|Lowrie, Tom]] (?, born 1964)
* [[Sergey Lozhkin|Lozhkin, Sergey]] (Russia, born 1951)
* [[Guozhen Lu|Lu, Guozhen]] (USA, born 1963)
* [[Liu Lu|Lu, Liu]] (China, ?–?)
* [[Zhen Luan|Luan, Zhen]] (Medieval China, 535–566)
* [[R. A. Schwaller de Lubicz|de Lubicz, R. A. Schwaller]] (?, 1887–1961)
* [[Charles-Benjamin de Lubières|de Lubières, Charles-Benjamin]] (?, 1714–1790)
* [[Jonathan Lubin|Lubin, Jonathan]] (USA, born 1936)
* [[Katarzyna Lubnauer|Lubnauer, Katarzyna]] (Poland, born 1969)
* [[Alexander Lubotzky|Lubotzky, Alexander]] (Israel, born 1956)
* [[Michael Luby|Luby, Michael]] (?, ?–?)
* [[Florian Luca|Luca, Florian]] (Romania, born 1969)
* [[Édouard Lucas|Lucas, Édouard]] (France, 1842–1891)
* [[Edith Hirsch Luchins|Luchins, Edith Hirsch]] (USA, 1921–2002)
* [[Yuri Luchko|Luchko, Yuri]] (Germany, ?–?)
* [[Wolfgang Lück|Lück, Wolfgang]] (Germany, born 1957)
* [[Stephan Luckhaus|Luckhaus, Stephan]] (Germany, ?–?)
* [[Stefan Lucks|Lucks, Stefan]] (?, ?–?)
* [[Tomasz Łuczak|Łuczak, Tomasz]] (Poland, born 1963)

== Lud ==

* [[Antonio Ludeña|Ludeña, Antonio]] (Spain, 1740–1820)
* [[William Ludlam|Ludlam, William]] (England, 1717–1788)
* [[Malcolm Ludvigsen|Ludvigsen, Malcolm]] (Britain, born 1946)
* [[Monika Ludwig|Ludwig, Monika]] (Austria, born 1966)
* [[John Edwin Luecke|Luecke, John Edwin]] (USA, ?–?)
* [[David Luenberger|Luenberger, David]] (USA, born 1937)
* [[Eugene Lukacs|Lukacs, Eugene]] (Hungary, 1906–1987)
* [[Jan Łukasiewicz|Łukasiewicz, Jan]] (Poland, 1878–1956)
* [[Yudell Luke|Luke, Yudell]] (USA, 1918–1983)
* [[Eugene M. Luks|Luks, Eugene M.]] (USA, ?–?)
* [[Günter Lumer|Lumer, Günter]] (Germany/Uruguay/Belgium, 1929–2005)
* [[Alessandra Lunardi|Lunardi, Alessandra]] (Italy, born 1958)
* [[Filip Lundberg|Lundberg, Filip]] (Sweden, 1876–1965)
* [[Rudolf Luneburg|Luneburg, Rudolf]] (?, 1903–1949)
* [[Frank Luntz|Luntz, Frank]] (USA, born 1962)
* [[Hua Luogeng|Luogeng, Hua]] (China, 1910–1985)
* [[Oleg Lupanov|Lupanov, Oleg]] (Russia/Soviet Union, 1932–2006)
* [[Alexandru Ioan Lupaș|Lupaș, Alexandru Ioan]] (Romania, 1942–2007)
* [[Ernesto Lupercio|Lupercio, Ernesto]] (Mexico, ?–?)
* [[Lupitus of Barcelona]] (?, ?–?)
* [[Anatoliy Lure|Lure, Anatoliy]] (?, 1901–1980)
* [[Jacob Lurie|Lurie, Jacob]] (USA, born 1977)
* [[Jacob Lüroth|Lüroth, Jacob]] (Germany, 1844–1910)
* [[George Lusztig|Lusztig, George]] (Romania, born 1946)
* [[Erwin Lutwak|Lutwak, Erwin]] (USA, born 1946)
* [[Élisabeth Lutz|Lutz, Élisabeth]] (France, 1914–2008)
* [[Jack Lutz|Lutz, Jack]] (?, ?–?)
* [[Julie Lutz|Lutz, Julie]] (?, ?–?)
* [[Jesper Lützen|Lützen, Jesper]] (?, born 1951)
* [[Andres Luure|Luure, Andres]] (Estonia, born 1959)

== Lux ==

* [[Wilhelmus Luxemburg|Luxemburg, Wilhelmus]] (USA, born 1929)
* [[Nikolai Luzin|Luzin, Nikolai]] (Soviet Union/Russia, 1883–1950)
* [[Cyprián Karásek Lvovický|Lvovický, Cyprián Karásek]] (Czech Republic, 1510s–1574)
* [[Aleksandr Lyapunov|Lyapunov, Aleksandr]] (Ukraine/Russia, 1857–1918)
* [[Alexey Lyapunov|Lyapunov, Alexey]] (Soviet Union, 1911–1973)
* [[Thomas Lydiat|Lydiat, Thomas]] (England, 1572–1646)
* [[Arnold Lynch|Lynch, Arnold]] (?, 1914–2004)
* [[Peter Lynch (meteorologist)|Lynch, Peter]] (Ireland, ?–?)
* [[Roger Lyndon|Lyndon, Roger]] (USA, 1917–1988)
* [[Hilda Lyon|Lyon, Hilda]] (Britain, 1896–1946)
* [[Israel Lyons|Lyons, Israel]] (England, 1739–1775)
* [[Richard Lyons (mathematician)|Lyons, Richard]] (USA, born 1945)
* [[Terry Lyons (mathematician)|Lyons, Terry]] (Britain, born 1953)
* [[Mikhail Lyubich|Lyubich, Mikhail]] (USA/Ukraine/Soviet Union, born 1959)
* [[Alexander Lyudskanov|Lyudskanov, Alexander]] (Bulgaria, 1926–1976)
* [[Lazar Lyusternik|Lyusternik, Lazar Aronovich]] (Soviet Union, 1899–1981)

[[Category:Mathematics-related lists]]</text>
      <sha1>33xb2l36pbe2r4if0y122u72f51ukvh</sha1>
    </revision>
  </page>
  <page>
    <title>List of topics related to π</title>
    <ns>0</ns>
    <id>659169</id>
    <revision>
      <id>867466231</id>
      <parentid>743830416</parentid>
      <timestamp>2018-11-05T22:05:13Z</timestamp>
      <contributor>
        <username>The Man in Question</username>
        <id>835170</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3228">{{DISPLAYTITLE: List of topics related to {{pi}}}}
{{Pi box}}
This is a '''list of topics related to [[pi]] ({{pi}}), the fundamental [[mathematical constant]].

&lt;!-- the invisible links to talk pages are explained at [[Wikipedia:Lists_within_articles#Advantages_of_lists]] --&gt;
*[[2π theorem|2{{pi}} theorem]] [[Talk:2π theorem| ]]
*[[Approximations of π|Approximations of {{pi}}]] [[Talk:Approximations of π| ]]
*[[Arithmetic–geometric mean]] [[Talk:Arithmetic-geometric mean| ]]
*[[Bailey–Borwein–Plouffe formula]] [[Talk:Bailey–Borwein–Plouffe formula| ]]
*[[Basel problem]] [[Talk:Basel problem| ]]
*[[Borwein's algorithm]][[Talk:Borwein's algorithm| ]]
*[[Buffon's needle]] [[Talk:Buffon's needle| ]]
*[[Cadaeic Cadenza]] [[Talk:Cadaeic Cadenza| ]]
*[[Chronology of computation of π|Chronology of computation of {{pi}}]] [[Talk:Chronology of computation of π| ]]
*[[Circle]] [[Talk:Circle| ]]
*[[Euler's identity]] [[Talk:Euler's identity| ]]
*[[Six nines in pi]] [[Talk:Six nines in pi| ]]
*[[Gauss–Legendre algorithm]] [[Talk:Gauss–Legendre algorithm| ]]
*[[Gaussian function]][[Talk:Gaussian function| ]]
*[[History of π|History of {{pi}}]]
*''[[A History of Pi]]'' [[Talk: A History of Pi| ]] (book)
*[[Indiana Pi Bill]] [[Talk:Indiana Pi Bill| ]]
*[[Leibniz formula for pi]] [[Talk:Leibniz formula for pi| ]]
*[[Lindemann–Weierstrass theorem]] [[Talk:Lindemann–Weierstrass theorem| ]] (Proof that {{pi}} is transcendental)
*[[List of circle topics]] [[Talk:List of circle topics| ]]
*[[List of formulae involving π|List of formulae involving {{pi}}]] [[Talk:List of formulae involving π| ]]
*[[Liu Hui's π algorithm|Liu Hui's {{pi}} algorithm]] [[Talk:Liu Hui's π algorithm| ]]
*[[Mathematical constant (sorted by continued fraction representation)]] [[Talk:Mathematical constant (sorted by continued fraction representation)| ]]
*[[Mathematical constants and functions]]
*[[Method of exhaustion]] [[Talk:Method of exhaustion| ]]
*[[Milü]][[Talk:Milü| ]]
*[[Pi]] [[Talk:Pi| ]]
*[[Pi (art project)]]
*[[Pi (letter)]] [[Talk:Pi (letter)| ]]
*[[Pi Day]] [[Talk:Pi Day| ]]
*[[PiFast]] [[Talk:PiFast| ]]
*[[PiHex]] [[Talk:PiHex| ]]
*[[Pi in the Sky]]
*[[Pilish]]
*[[Pimania]] [[Talk:Pimania| ]](computer game)
*[[Piphilology]] [[Talk:Piphilology| ]]
*[[Proof that π is irrational|Proof that {{pi}} is irrational]] [[Talk:Proof that π is irrational| ]]
*[[Proof that 22/7 exceeds π|Proof that 22/7 exceeds {{pi}}]] [[Talk:Proof that 22/7 exceeds π| ]]
*[[Proof of Wallis product]] [[Talk:Proof of Wallis product| ]]
*[[Rabbi Nehemiah]] [[Talk:Rabbi Nehemiah| ]]
*[[Radian]] [[Talk:Radian| ]]
*[[Ramanujan–Sato series]]
*[[Rhind Mathematical Papyrus]] [[Talk:Rhind Mathematical Papyrus| ]]
*[[Salamin–Brent algorithm]] [[Talk:Salamin–Brent algorithm| ]]
*[[Software for calculating π|Software for calculating {{pi}}]]
*[[Squaring the circle]] [[Talk:Squaring the circle| ]]
*[[Turn (geometry)]] [[Talk:Turn (geometry)| ]]
*[[Viète's formula]] [[Talk:Viète's formula| ]]

{{Expand list|date=August 2008}}

{{DEFAULTSORT:Topics Related To Pi, List Of}}
[[Category:Mathematics-related lists|Pi]]
[[Category:Pi|*List]]
[[Category:Wikipedia outlines|Pi]]
[[Category:Lists of topics|Pi]]</text>
      <sha1>r93p571aoh5obqfjnft42p8d0p9zykt</sha1>
    </revision>
  </page>
  <page>
    <title>Mean field annealing</title>
    <ns>0</ns>
    <id>40059937</id>
    <revision>
      <id>783966756</id>
      <parentid>723517971</parentid>
      <timestamp>2017-06-05T18:55:33Z</timestamp>
      <contributor>
        <username>Innisfree987</username>
        <id>26121454</id>
      </contributor>
      <comment>Added {{[[Template:one source|one source]]}} and {{[[Template:technical|technical]]}} tags to article ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="829">{{one source|date=June 2017}}
{{technical|date=June 2017}}
'''Mean field annealing''' is a [[deterministic]] [[approximation]] to the [[simulated annealing]] technique of solving [[optimization]] problems.&lt;ref&gt;{{cite journal | url=http://www.ece.ncsu.edu/imaging/Publications/1992/BilbroSnyderTNN.pdf | title=Mean field annealing: a formalism for constructing GNC-like algorithms |author1=Bilbro, G.L. |author2=Snyder, W.E. |author3=Garnier, S.J. |author4=Gault, J.W. | journal=IEEE Transactions on Neural Networks |date=Jan 1992 | volume=3 | issue=1 | pages=131–138 | doi=10.1109/72.105426}}&lt;/ref&gt; This method uses [[mean field theory]] and is based on [[Trace inequalities#Peierls.E2.80.93Bogoliubov inequality|Peierls' inequality]].

==References==
{{reflist}}

[[Category:Mathematical optimization]]


{{applied-math-stub}}</text>
      <sha1>2horsawecxgjzbsjt7ntmf99q3tod2j</sha1>
    </revision>
  </page>
  <page>
    <title>Monster Math Squad</title>
    <ns>0</ns>
    <id>39508690</id>
    <revision>
      <id>866200985</id>
      <parentid>863654149</parentid>
      <timestamp>2018-10-28T22:46:44Z</timestamp>
      <contributor>
        <username>Bearcat</username>
        <id>24902</id>
      </contributor>
      <minor/>
      <comment>/* Broadcast history */clean up</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2384">{{Infobox television
 | show_name = Monster Math Squad
 | runtime = 30 minutes
 | producer = [[DHX Media]]&lt;br&gt;[[CBC Television]]
 | voices = Jeff Rosen
 | opentheme = 'Monster Math Squad' composed &amp; produced by Tim Baker of [[Hey Rosetta!]], lyrics by Jeff Rosen
 | country = Canada
 | company =
 | network = [[CBC Television|CBC]] (Canada)&lt;br&gt;[[Discovery Kids (Latin America)|Discovery Kids]] (Latin America)
 | first_aired = 2012
 | last_aired = 2016
 | website = 
}}

'''Monster Math Squad''' is a Canadian [[Computer-generated-imagery|CGI]] [[animated series]], created by Jeff Rosen and produced by [[DHX Media]] for [[CBC Television]]. It follows the adventures of three monsters who go on missions that require math equations. Together, they solve math problems to complete missions.

== Plot ==
The series takes place in the city of Monstrovia, where all sorts of monsters live. Three monsters (Max, Lily and Goo), are always ready to help their friends, solving math problems and learning math equations.

==Broadcast history==
US
* [[Discovery Familia]] (2013–present)
* [[Starz|Starz Kids and Family]] (2017)
* [[Qubo]] (2018–present)&lt;ref&gt;https://ionmedia.com/press/imn/ion-media-announces-12-new-programming-acquisitions-for-qubo-and-ion-life&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://qubo.com/show/monster-math-squad|title=Monster Math Squad {{!}} Qubo - Qubo is the nation’s only 24/7 over-the-air network for children.|website=Qubo|language=en-US|access-date=2018-10-12}}&lt;/ref&gt;
Canada
* [[CBC Television]] (2012–2016)
* [[Aboriginal Peoples Television Network|APTN]] (as part of the block, APTN Kids)
* [[Ici Radio-Canada Télé]]

Latin America
* [[Discovery Kids (Latin America)|Discovery Kids]] (2012–16)

UK
*[[Tiny Pop]]

==References==
&lt;references/&gt;

==External links==
*{{IMDb title|2289057}}

{{CBC Television Shows (current and upcoming)}}

[[Category:CBC Television shows]]
[[Category:Mathematics education television series]]
[[Category:Canadian children's animated adventure television series]]
[[Category:Canadian children's animated fantasy television series]]
[[Category:2010s Canadian animated television series]]
[[Category:2012 Canadian television series debuts]]
[[Category:2016 Canadian television series endings]]
[[Category:Canadian computer-animated television series]]
[[Category:Television series by DHX Media]]
[[Category:Qubo]]


{{CBC-stub}}</text>
      <sha1>78tsysulvtr5zuu2hc1g9mnfjbl07nc</sha1>
    </revision>
  </page>
  <page>
    <title>Non-negative matrix factorization</title>
    <ns>0</ns>
    <id>3681279</id>
    <revision>
      <id>865677622</id>
      <parentid>864308950</parentid>
      <timestamp>2018-10-25T13:31:16Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>[[User:JCW-CleanerBot#Logic|task]], replaced: Astronomy and Astrophyics →  	Astronomy &amp; Astrophysics (2)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="57176">{{machine learning bar}}
[[File:NMF.png|thumb|400px|Illustration of approximate non-negative matrix factorization: the matrix {{math|'''V'''}} is represented by the two smaller matrices {{math|'''W'''}} and {{math|'''H'''}}, which, when multiplied, approximately reconstruct {{math|'''V'''}}.]]

'''Non-negative matrix factorization''' ('''NMF''' or '''NNMF'''), also '''non-negative matrix approximation'''&lt;ref name="dhillon"/&gt;&lt;ref&gt;{{cite journal|last1=Tandon|first1=Rashish|author2=Suvrit Sra|title=Sparse nonnegative matrix approximation: new formulations and algorithms|year=2010|series=TR|url=ftp://ftp.kyb.tuebingen.mpg.de/pub/mpi-memos/pdf/nmftr.pdf}}&lt;/ref&gt; is a group of [[algorithm]]s in [[multivariate analysis]] and [[linear algebra]] where a [[matrix (mathematics)|matrix]] {{math|'''V'''}} is [[Matrix decomposition|factorized]] into (usually) two matrices {{math|'''W'''}} and {{math|'''H'''}}, with the property that all three matrices have no negative elements. This non-negativity makes the resulting matrices easier to inspect. Also, in applications such as processing of audio spectrograms or muscular activity, non-negativity is inherent to the data being considered. Since the problem is not exactly solvable in general, it is commonly approximated numerically.

NMF finds applications in such fields as [[astronomy]],&lt;ref name="ReferenceA"&gt;{{Cite journal
 | author1 = Olivier Berné
 | author2 = C. Joblin et al.
 | title= Analysis of the emission of very small dust particles from Spitzer spectro-imagery data using blind signal separation methods
 | journal = [[Astronomy &amp; Astrophysics]]
 | volume = 469
 | issue = 2
 | year = 2007
 | page = 575
 }}&lt;/ref&gt;&lt;ref name="blantonRoweis07"/&gt;&lt;ref name="ren18"/&gt; [[computer vision]], document [[Cluster analysis|clustering]],&lt;ref name="dhillon"/&gt; [[chemometrics]], [[audio signal processing]], [[recommender system]]s,&lt;ref name="gemulla"&gt;{{cite conference |author=Rainer Gemulla |author2=Erik Nijkamp |author3=Peter J Haas |author4=Yannis Sismanis |title=Large-scale matrix factorization with distributed stochastic gradient descent |conference=Proc. ACM SIGKDD Int'l Conf. on Knowledge discovery and data mining |url=http://www.mpi-inf.mpg.de/~rgemulla/publications/rj10481rev.pdf |year=2011 |pages=69–77}}&lt;/ref&gt;&lt;ref&gt;{{cite conference |author=Yang Bao|title=TopicMF: Simultaneously Exploiting Ratings and Reviews for Recommendation |conference=AAAI |url=http://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8273 |year=2014 |pages=|display-authors=etal}}&lt;/ref&gt; and [[bioinformatics]].&lt;ref&gt;{{cite journal |author=Ben Murrell|title=Non-Negative Matrix Factorization for Learning Alignment-Specific Models of Protein Evolution |journal=PLoS ONE |volume=6 |issue=12 |year=2011 |pages=e28898|display-authors=etal|doi=10.1371/journal.pone.0028898 |pmid=22216138 |pmc=3245233 }}&lt;/ref&gt;

== History ==
In [[chemometrics]] non-negative matrix factorization has a long history under the name "self modeling curve resolution".&lt;ref&gt;{{Cite journal
 | author1 = William H. Lawton
 | author-link1 = William H. Lawton
 | author2 = Edward A. Sylvestre
 | author-link2 = Edward A. Sylvestre
 | title= Self modeling curve resolution
 | journal = [[Technometrics]]
 | volume = 13
 | issue = 3
 | year = 1971
 | page = 617+
| doi=10.2307/1267173
| jstor = 1267173
 }}&lt;/ref&gt;
In this framework the vectors in the right matrix are continuous curves rather than discrete vectors.
Also early work on non-negative matrix factorizations was performed by a Finnish group of researchers in the middle of the 1990s under the name ''positive matrix factorization''.&lt;ref&gt;{{Cite journal
 |author1=P. Paatero |author2=U. Tapper | title = Positive matrix factorization: A non-negative factor model with optimal utilization of error estimates of data values
 | journal = [[Environmetrics]]
 | volume = 5
 | pages = 111–126
 | year = 1994
 | doi = 10.1002/env.3170050203
 | issue = 2
}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal
 | author = Pia Anttila
 | author-link = Pia Anttila
 | author2 = Pentti Paatero
 | author2-link = Pentti Paatero
 | author3 = Unto Tapper
 | author4 = Olli Järvinen
 | title = Source identification of bulk wet deposition in Finland by positive matrix factorization
 | journal = [[Atmospheric Environment (journal)|Atmospheric Environment]]
 | volume = 29
 | issue = 14
 | pages = 1705&amp;ndash;1718
 | year = 1995
 | doi = 10.1016/1352-2310(94)00367-T
| bibcode = 1995AtmEn..29.1705A
 }}&lt;/ref&gt;
It became more widely known as ''non-negative matrix factorization'' after Lee and Seung investigated
the properties of the algorithm and published some simple and useful
algorithms for two types of factorizations.&lt;ref name="lee-seung"&gt;{{Cite journal
 | author = Daniel D. Lee
 | author2 = H. Sebastian Seung
 | author2-link = Sebastian Seung
 | last-author-amp = yes
 | year = 1999
 | title = Learning the parts of objects by non-negative matrix factorization
 | journal = [[Nature (journal)|Nature]]
 | volume = 401
 | issue = 6755
 | pages = 788&amp;ndash;791
 | doi = 10.1038/44565
 | pmid = 10548103
| bibcode = 1999Natur.401..788L
 }}&lt;/ref&gt;&lt;ref name="lee2001algorithms"&gt;{{Cite conference
 |author1=Daniel D. Lee  |author2=H. Sebastian Seung
  |lastauthoramp=yes | year = 2001
 | url = http://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf
 | title = Algorithms for Non-negative Matrix Factorization
 | conference = Advances in Neural Information Processing Systems 13: Proceedings of the 2000 Conference
 | pages = 556&amp;ndash;562
 | publisher = [[MIT Press]]
}}&lt;/ref&gt;

== Background ==

Let matrix {{math|'''V'''}} be the product of the matrices {{math|'''W'''}} and {{math|'''H'''}},
:&lt;math&gt;\mathbf{V} = \mathbf{W} \mathbf{H} \,.&lt;/math&gt;

Matrix multiplication can be implemented as computing the column vectors of {{math|'''V'''}} as linear combinations of the column vectors in {{math|'''W'''}} using coefficients supplied by columns of {{math|'''H'''}}.  That is, each column of {{math|'''V'''}} can be computed as follows:
:&lt;math&gt;\mathbf{v}_i = \mathbf{W} \mathbf{h}_{i} \,,&lt;/math&gt;

where {{math|'''v'''&lt;sub&gt;''i''&lt;/sub&gt;}} is the {{math|''i''}}-th column vector of the product matrix {{math|'''V'''}} and {{math|'''h'''&lt;sub&gt;''i''&lt;/sub&gt;}} is the {{math|''i''}}-th column vector of the matrix {{math|'''H'''}}.

When multiplying matrices, the dimensions of the factor matrices may be significantly lower than those of the product matrix and it is this property that forms the basis of NMF. NMF generates factors with significantly reduced dimensions compared to the original matrix. For example, if {{math|'''V'''}} is an {{math|''m'' × ''n''}} matrix, {{math|'''W'''}} is an {{math|''m'' × ''p''}} matrix, and {{math|'''H'''}} is a {{math|''p'' × ''n''}} matrix then {{math|''p''}} can be significantly less than both {{math|''m''}} and {{math|''n''}}.

Here is an example based on a text-mining application: 
* Let the input matrix (the matrix to be factored) be {{math|'''V'''}} with 10000 rows and 500 columns where words are in rows and documents are in columns. That is, we have 500 documents indexed by 10000 words. It follows that a column vector {{math|'''v'''}} in {{math|'''V'''}} represents a document.
* Assume we ask the algorithm to find 10 features in order to generate a ''features matrix'' {{math|'''W'''}} with 10000 rows and 10 columns and a ''coefficients matrix'' {{math|'''H'''}} with 10 rows and 500 columns.
* The product of {{math|'''W'''}} and {{math|'''H'''}} is a matrix with 10000 rows and 500 columns, the same shape as the input matrix {{math|'''V'''}} and, if the factorization worked, it is a reasonable approximation to the input matrix {{math|'''V'''}}.
* From the treatment of matrix multiplication above it follows that each column in the product matrix {{math|'''WH'''}} is a linear combination of the 10 column vectors in the features matrix {{math|'''W'''}} with coefficients supplied by the coefficients matrix {{math|'''H'''}}.

This last point is the basis of NMF because we can consider each original document in our example as being built from a small set of hidden features. NMF generates these features.

It is useful to think of each feature (column vector) in the features matrix {{math|'''W'''}} as a document archetype comprising a set of words where each word's cell value defines the word's rank in the feature: The higher a word's cell value the higher the word's rank in the feature. A column in the coefficients matrix {{math|'''H'''}} represents an original document with a cell value defining the document's rank for a feature. We can now reconstruct a document (column vector) from our input matrix by a linear combination of our features (column vectors in {{math|'''W'''}}) where each feature is weighted by the feature's cell value from the document's column in {{math|'''H'''}}.

== Clustering property ==
NMF has an inherent clustering property,&lt;ref name="DingSDM2005" /&gt; i.e., it automatically clusters the columns of input data 
&lt;math&gt;\mathbf{V} = (v_1, \cdots, v_n) &lt;/math&gt;. It is this property that drives most applications of NMF.

More specifically, the approximation of &lt;math&gt;\mathbf{V}&lt;/math&gt; by
&lt;math&gt;\mathbf{V} \simeq \mathbf{W}\mathbf{H}&lt;/math&gt; is achieved by minimizing the error function

&lt;math&gt; \min_{W,H} || V - WH ||_F,&lt;/math&gt; subject to &lt;math&gt;W \geq 0, H \geq 0.&lt;/math&gt;

&lt;code&gt;&lt;!-- "If we add additional orthogonality constraint on &lt;math&gt;  H &lt;/math&gt; and &lt;math&gt;  W &lt;/math&gt; , 
i.e., &lt;math&gt;  W = H H^T &lt;/math&gt;, then the above minimization is mathematically equivalent to the minimization of [[K-means clustering]]&lt;ref&gt;{{Cite book|url=http://epubs.siam.org/doi/abs/10.1137/1.9781611972757.70|title=Proceedings of the 2005 SIAM International Conference on Data Mining|last=Ding|first=C.|last2=He|first2=X.|last3=Simon|first3=H.|date=2005-04-21|publisher=Society for Industrial and Applied Mathematics|isbn=9780898715934|series=Proceedings|pages=606–610|doi=10.1137/1.9781611972757.70}}&lt;/ref&gt; )." is false as HH^t is square and W is not! to this line should not be ekpt until it is fixed. I think it should be HH^t = I  --&gt;&lt;/code&gt;

Furthermore, the computed &lt;math&gt;  H &lt;/math&gt; gives the [[cluster indicator]], i.e.,
if &lt;math&gt;\mathbf{H}_{kj} &gt; 0 &lt;/math&gt;, that fact indicates 
input data &lt;math&gt; v_j &lt;/math&gt;
belongs to &lt;math&gt;k^{th}&lt;/math&gt; cluster. 
And the computed &lt;math&gt;W&lt;/math&gt; gives the cluster centroids, i.e., 
the &lt;math&gt;k^{th}&lt;/math&gt; column 
gives the cluster centroid of
&lt;math&gt;k^{th}&lt;/math&gt; cluster. This centroid's representation can be significantly enhanced by convex NMF.

When the orthogonality &lt;math&gt;  H H^T = I &lt;/math&gt; is not explicitly imposed, the orthogonality holds to a large extent, and the clustering property holds too. Clustering is the main objective of most [[data mining]] applications of NMF.{{citation needed|date=April 2015}}

When the error function to be used is [[Kullback–Leibler divergence]], NMF is identical to the [[Probabilistic latent semantic analysis]], a popular document clustering method.&lt;ref&gt;C Ding, T Li, W Peng, [http://users.cis.fiu.edu/~taoli/pub/NMFpLSIequiv.pdf " On the equivalence between non-negative matrix factorization and probabilistic latent semantic indexing"] Computational Statistics &amp; Data Analysis 52, 3913-3927&lt;/ref&gt;

== Types ==

=== Approximate non-negative matrix factorization ===
Usually the number of columns of {{math|'''W'''}} and the number of rows of {{math|'''H'''}} in NMF are selected so the product {{math|'''WH'''}} will become an approximation to {{math|'''V'''}}.  The full decomposition of {{math|'''V'''}} then amounts to the two non-negative matrices {{math|'''W'''}} and {{math|'''H'''}} as well as a residual {{math|'''U'''}}, such that: {{math|1='''V''' = '''WH''' + '''U'''}}. The elements of the residual matrix can either be negative or positive.

When {{math|'''W'''}} and {{math|'''H'''}} are smaller than {{math|'''V'''}} they become easier to store and manipulate. Another reason for factorizing {{math|'''V'''}} into smaller matrices {{math|'''W'''}} and {{math|'''H'''}}, is that if one is able to approximately represent the elements of {{math|'''V'''}} by significantly less data, then one has to infer some latent structure in the data.

=== Convex non-negative matrix factorization ===

In standard NMF, matrix factor {{math|'''W''' ∈ ℝ&lt;sub&gt;+&lt;/sub&gt;&lt;sup&gt;''m'' × ''k''&lt;/sup&gt;}}， i.e., {{math|'''W'''}} can be anything in that space.  Convex NMF&lt;ref name="ding"&gt;C Ding, T Li, MI Jordan, Convex and semi-nonnegative matrix factorizations, IEEE Transactions on Pattern Analysis and Machine Intelligence,  32, 45-55, 2010&lt;/ref&gt; restricts the columns of {{math|'''W'''}} to [[convex combination]]s of the input data vectors &lt;math&gt; (v_1, \cdots, v_n) &lt;/math&gt;. This greatly improves the quality of data representation of {{math|'''W'''}}. Furthermore, the resulting matrix factor {{math|'''H'''}} becomes more sparse and orthogonal.

=== Nonnegative rank factorization ===
In case the [[Nonnegative rank (linear algebra)|nonnegative rank]] of {{math|'''V'''}} is equal to its actual rank, {{math|1='''V''' = '''WH'''}} is called a nonnegative rank factorization.&lt;ref name=BermanPlemmons74&gt;{{cite journal|last=Berman|first=A.|author2=R.J. Plemmons |title=Inverses of nonnegative matrices|journal=Linear and Multilinear Algebra|year=1974|volume=2|issue=2|pages=161–172|doi=10.1080/03081087408817055}}&lt;/ref&gt;&lt;ref name=BermanPlemmons94&gt;{{cite book|author1=A. Berman |author2=R.J. Plemmons |title=Nonnegative matrices in the Mathematical Sciences|year=1994|publisher=SIAM|location=Philadelphia}}&lt;/ref&gt;&lt;ref name=Thomas74&gt;{{cite journal|last=Thomas|first=L.B.|title=Problem 73-14, Rank factorization of nonnegative matrices|journal=SIAM Rev.|year=1974|volume=16|issue=3|pages=393–394|doi=10.1137/1016064}}&lt;/ref&gt; The problem of finding the NRF of {{math|'''V'''}}, if it exists, is known to be NP-hard.&lt;ref name=Vavasis09&gt;{{cite journal|last=Vavasis|first=S.A.|title=On the complexity of nonnegative matrix factorization|journal=SIAM J. Optim.|year=2009|volume=20|issue=3|pages=1364–1377|doi=10.1137/070709967|arxiv=0708.4149}}&lt;/ref&gt;

=== Different cost functions and regularizations ===

There are different types of non-negative matrix factorizations.
The different types arise from using different [[Loss function|cost function]]s for measuring the divergence between {{math|'''V'''}} and {{math|'''WH'''}} and possibly by [[regularization (mathematics)|regularization]] of the {{math|'''W'''}} and/or {{math|'''H'''}} matrices.&lt;ref name="dhillon"&gt;{{Cite conference | author = Inderjit S. Dhillon | author-link = Inderjit S. Dhillon  | author2 = Suvrit Sra| author2-link = Suvrit Sra | url = http://books.nips.cc/papers/files/nips18/NIPS2005_0203.pdf |format=PDF|title = Generalized Nonnegative Matrix Approximations with Bregman Divergences | conference = [[Conference on Neural Information Processing Systems|NIPS]] | year = 2005}}&lt;/ref&gt;

Two simple divergence functions studied by Lee and Seung are the squared error (or [[Frobenius norm]]) and an extension of the Kullback–Leibler divergence to positive matrices (the original [[Kullback–Leibler divergence]] is defined on probability distributions).
Each divergence leads to a different NMF algorithm, usually minimizing the divergence using iterative update rules.

The factorization problem in the squared error version of NMF may be stated as:
Given a matrix &lt;math&gt;\mathbf{V}&lt;/math&gt; find nonnegative matrices W and H that minimize the function
: &lt;math&gt;F(\mathbf{W},\mathbf{H}) = \|\mathbf{V} - \mathbf{WH}\|^2_F&lt;/math&gt;

Another type of NMF for images is based on the [[total variation norm]].&lt;ref&gt;{{Cite journal | last1 = Zhang | first1 = T. | last2 = Fang | first2 = B. | last3 = Liu | first3 = W. | last4 = Tang | first4 = Y. Y. | last5 = He | first5 = G. | last6 = Wen | first6 = J. | doi = 10.1016/j.neucom.2008.01.022 | title = Total variation norm-based nonnegative matrix factorization for identifying discriminant representation of image patterns | journal = [[Neurocomputing (journal)|Neurocomputing]]| volume = 71 | issue = 10–12 | pages = 1824–1831| year = 2008 | pmid =  | pmc = }}&lt;/ref&gt;

When [[Tikhnov regularization|L1 regularization]] (akin to [[Lasso (statistics)|Lasso]]) is added to NMF with the mean squared error cost function, the resulting problem may be called '''non-negative sparse coding''' due to the similarity to the [[sparse coding]] problem,&lt;ref name="hoyer02"&gt;{{cite conference |last=Hoyer |first=Patrik O. |title=Non-negative sparse coding |conference=Proc. IEEE Workshop on Neural Networks for Signal Processing |year=2002 |url=https://arxiv.org/pdf/cs/0202009}}&lt;/ref&gt;&lt;ref name="Leo Taslaman and Björn Nilsson 2012 e46331"&gt;{{Cite journal
 |author1=Leo Taslaman  |author2=Björn Nilsson
  |lastauthoramp=yes | title = A framework for regularized non-negative matrix factorization, with application to the analysis of gene expression data
 | journal = [[PLoS One]]
 | volume = 7
 | issue = 11
 | year = 2012
 | pages = e46331
 | doi = 10.1371/journal.pone.0046331
 | pmid = 23133590
 | pmc=3487913
|bibcode=2012PLoSO...746331T
  }}&lt;/ref&gt;
although it may also still be referred to as NMF.&lt;ref&gt;{{Cite conference | last1 = Hsieh | first1 = C. J. | last2 = Dhillon | first2 = I. S. | doi = 10.1145/2020408.2020577 | title = Fast coordinate descent methods with variable selection for non-negative matrix factorization | conference = Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '11 | pages = 
1064| year = 2011 | isbn = 9781450308137 | pmid =  | pmc = | url = http://www.cs.utexas.edu/~cjhsieh/nmf_kdd11.pdf}}&lt;/ref&gt;

===Online NMF===
Many standard NMF algorithms analyze all the data together; i.e., the whole matrix is available from the start. This may be unsatisfactory in applications where there are too many data to fit into memory or where the data are provided in [[Data stream|streaming]] fashion. One such use is for [[collaborative filtering]] in [[recommendation systems]], where there may be many users and many items to recommend, and it would be inefficient to recalculate everything when one user or one item is added to the system. The cost function for optimization in these cases may or may not be the same as for standard NMF, but the algorithms need to be rather different.&lt;ref&gt;http://www.ijcai.org/papers07/Papers/IJCAI07-432.pdf&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://dl.acm.org/citation.cfm?id=1339264.1339709|title=Online Discussion Participation Prediction Using Non-negative Matrix Factorization|first1=Yik-Hing|last1=Fung|first2=Chun-Hung|last2=Li|first3=William K.|last3=Cheung|date=2 November 2007|publisher=IEEE Computer Society|pages=284–287|via=dl.acm.org}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|author=Naiyang Guan|author2=Dacheng Tao|author3=Zhigang Luo|author4=Bo Yuan|last-author-amp=yes|date=July 2012|title=Online Nonnegative Matrix Factorization With Robust Stochastic Approximation|url=|journal=IEEE Transactions on Neural Networks and Learning Systems |issue=7 |doi=10.1109/TNNLS.2012.2197827|pmid=24807135|volume=23|pages=1087–1099}}&lt;/ref&gt;

== Algorithms ==
There are several ways in which the {{math|'''W'''}} and {{math|'''H'''}} may be found: Lee and Seung's [[Multiplicative Weight Update Method|multiplicative update rule]]&lt;ref name="lee2001algorithms"/&gt; has been a popular method due to the simplicity of implementation.  This algorithm is:
:initialize: {{math|'''W'''}} and {{math|'''H'''}} non negative.
:Then update the values in {{math|'''W'''}} and {{math|'''H'''}} by computing the following, with &lt;math&gt;n&lt;/math&gt; as an index of the iteration. 
:&lt;math&gt; H_{[i,j]}^{n+1} \leftarrow H_{[i,j]}^n \frac{((W^n)^TV)_{[i,j]}}{((W^n)^TW^nH^n)_{[i,j]}}&lt;/math&gt;
:and
:&lt;math&gt; W_{[i,j]}^{n+1} \leftarrow W_{[i,j]}^n \frac{(V(H^{n+1})^T)_{[i,j]}}{(W^nH^{n+1}(H^{n+1})^T)_{[i,j]}}&lt;/math&gt;
:Until {{math|'''W'''}} and {{math|'''H'''}} are stable.
Note that the updates are done on an element by element basis not matrix multiplication.

We note that {{math|'''W'''}} and {{math|'''H'''}} multiplicative factor is [[identity matrix]] when V = W H.

More recently other algorithms have been developed.
Some approaches are based on alternating [[non-negative least squares]]: in each step of such an algorithm, first {{math|'''H'''}} is fixed and {{math|'''W'''}} found by a non-negative least squares solver, then {{math|'''W'''}} is fixed and {{math|'''H'''}} is found analogously. The procedures used to solve for {{math|'''W'''}} and {{math|'''H'''}} may be the same&lt;ref name="lin07"/&gt; or different, as some NMF variants regularize one of {{math|'''W'''}} and {{math|'''H'''}}.&lt;ref name="hoyer02"/&gt; Specific approaches include the projected [[gradient descent]] methods,&lt;ref name="lin07"&gt;{{Cite journal | last1 = Lin | first1 = Chih-Jen| title = Projected Gradient Methods for Nonnegative Matrix Factorization | doi = 10.1162/neco.2007.19.10.2756 | journal = [[Neural Computation (journal)|Neural Computation]]| volume = 19 | issue = 10 | pages = 2756–2779 | year = 2007 | pmid =  17716011| pmc = | url = http://www.csie.ntu.edu.tw/~cjlin/papers/pgradnmf.pdf| citeseerx = 10.1.1.308.9135}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal | last1 = Lin | first1 = Chih-Jen| doi = 10.1109/TNN.2007.895831 | title = On the Convergence of Multiplicative Update Algorithms for Nonnegative Matrix Factorization | journal = IEEE Transactions on Neural Networks| volume = 18 | issue = 6 | pages = 1589–1596 | year = 2007 | pmid =  | pmc = | citeseerx = 10.1.1.407.318}}&lt;/ref&gt; the [[active set]] method,&lt;ref name="gemulla"/&gt;&lt;ref name="kim2008nonnegative"&gt;{{Cite journal
 | author = Hyunsoo Kim
 | author2 = Haesun Park
 | author2-link = Haesun Park
 | last-author-amp = yes
 | title = Nonnegative Matrix Factorization Based on Alternating Nonnegativity Constrained Least Squares and Active Set Method
 | journal = [[SIAM Journal on Matrix Analysis and Applications]]
 | volume = 30
 | issue = 2
 | year = 2008
 | pages = 713&amp;ndash;730
 | url = http://www.cc.gatech.edu/~hpark/papers/simax-nmf.pdf
 | doi=10.1137/07069239x
| citeseerx = 10.1.1.70.3485
 }}&lt;/ref&gt; the optimal gradient method,&lt;ref&gt;{{Cite journal|author=Naiyang Guan|author2=Dacheng Tao|author3=Zhigang Luo, Bo Yuan|date=June 2012|title=NeNMF: An Optimal Gradient Method for Nonnegative Matrix Factorization|url=|journal=IEEE Transactions on Signal Processing |issue=6 |doi=10.1109/TSP.2012.2190406|pmid=|volume=60|pages=2882–2898|bibcode=2012ITSP...60.2882G}}&lt;/ref&gt; and the block principal pivoting method&lt;ref name="kim2011fast"&gt;{{Cite journal
 |author1=Jingu Kim  |author2=Haesun Park
  |lastauthoramp=yes | title = Fast Nonnegative Matrix Factorization: An Active-set-like Method and Comparisons
 | journal = [[SIAM Journal on Scientific Computing]]
 | volume = 58
 | issue = 6
 | year = 2011
 | pages = 3261&amp;ndash;3281
 | url = http://www.cc.gatech.edu/~jingu/docs/2011_paper_sisc_nmf.pdf
 | doi=10.1137/110821172
|citeseerx=10.1.1.419.798
  }}&lt;/ref&gt; among several others.&lt;ref name="kim2013unified"&gt;{{Cite journal
 |author1=Jingu Kim  |author2=Yunlong He |author3=Haesun Park
  |lastauthoramp=yes | title = Algorithms for nonnegative matrix and tensor factorizations: A unified view based on block coordinate descent framework
 | journal = [[Journal of Global Optimization]]
 | volume = 33
 | issue = 2
 | year = 2013
 | pages = 285&amp;ndash;319
 | url =https://smallk.github.io/papers/nmf_review_jgo.pdf
 | doi=10.1007/s10898-013-0035-4
}}&lt;/ref&gt;

Current algorithms are sub-optimal in that they only guarantee finding a local minimum, rather than a global minimum of the cost function. A provably optimal algorithm is unlikely in the near future as the problem has been shown to generalize the k-means clustering problem which is known to be [[NP-complete]].&lt;ref&gt;{{Cite book
  | title = On the equivalence of nonnegative matrix factorization and spectral clustering
  | author = Ding, C.
  | author2 = He, X.
  | author3 = Simon, H.D.
  | last-author-amp = yes
  | journal = Proc. SIAM Data Mining Conf
  | volume = 4
  | pages = 606&amp;ndash;610
  | year = 2005
  | doi=10.1137/1.9781611972757.70
| isbn = 978-0-89871-593-4
  }}&lt;/ref&gt; However, as in many other data mining applications, a local minimum may still prove to be useful.

[[File:Fractional_Residual_Variances_comparison,_PCA_and_NMF.pdf|thumb|500px|Fractional residual variance (FRV) plots for PCA and sequential NMF;&lt;ref name="ren18"/&gt; for PCA, the theoretical values are the contribution from the residual eigenvalues. In comparison, the FRV curves for PCA reaches a flat plateau where no signal are captured effectively; while the NMF FRV curves are declining continuously, indicating a better ability to capture signal. The FRV curves for NMF also converges to higher levels than PCA, indicating the less-overfitting property of NMF.]]

=== Sequential NMF ===
The sequential construction of NMF components ({{math|'''W'''}} and {{math|'''H'''}}) was firstly used to relate NMF with [[Principal Component Analysis]] (PCA) in astronomy.&lt;ref name="zhu16"/&gt; The contribution from the PCA components are ranked by the magnitude of their corresponding eigenvalues; for NMF, its components can be ranked empirically when they are constructed one by one (sequentially), i.e., learn the &lt;math&gt; (n+1)&lt;/math&gt;-th component with the first &lt;math&gt;n&lt;/math&gt; components constructed.

The contribution of the sequential NMF components can be compared with the [[Karhunen–Loève theorem]], an application of PCA, using the plot of eigenvalues. A typical choice of the number of components with PCA is based on the "elbow" point, then the existence of the flat plateau is indicating that PCA is not capturing the data efficiently, and at last there exists a sudden drop reflecting the capture of random noise and falls into the regime of overfitting.&lt;ref name="soummer12"/&gt;&lt;ref name="pueyo16"/&gt; For sequential NMF, the plot of eigenvalues is approximated by the plot of the fractional residual variance curves, where the curves decreases continuously, and converge to a higher level than PCA,&lt;ref name="ren18"/&gt; which is the indication of less over-fitting of sequential NMF.

=== Exact NMF ===
Exact solutions for the variants of NMF can be expected (in polynomial time) when additional constraints hold for matrix {{math|'''V'''}}. A polynomial time algorithm for solving nonnegative rank factorization if {{math|'''V'''}} contains a monomial sub matrix of rank equal to its rank was given by Campbell and Poole in 1981.&lt;ref name=CampbellPoole81&gt;{{cite journal|last=Campbell|first=S.L.|author2=G.D. Poole |title=Computing nonnegative rank factorizations|journal=Linear Algebra Appl.|year=1981|volume=35|pages=175–182|doi=10.1016/0024-3795(81)90272-x}}&lt;/ref&gt; Kalofolias and Gallopoulos (2012)&lt;ref name=KalofoliasGallopoulos2012&gt;{{cite journal|last=Kalofolias|first=V.|author2=Gallopoulos, E. |title=Computing symmetric nonnegative rank factorizations|journal=Linear Algebra Appl|year=2012|volume=436|issue=2|pages=421–435|url=http://www.sciencedirect.com/science/article/pii/S0024379511002199#|doi=10.1016/j.laa.2011.03.016}}&lt;/ref&gt; solved the symmetric counterpart of this problem, where {{math|'''V'''}} is symmetric and contains a diagonal principal sub matrix of rank r. Their algorithm runs in O(rm^2) time in the dense case. Arora, Ge, Halpern, Mimno, Moitra, Sontag, Wu, &amp; Zhu (2013) give a polynomial time algorithm for exact NMF that works for the case where one of the factors W satisfies the separability condition.&lt;ref name=Arora2013&gt;{{Cite conference
| last1 = Arora | first1 = Sanjeev
| last2 = Ge | first2 = Rong
| last3 = Halpern | first3 = Yoni
| last4 = Mimno | first4 = David
| last5 = Moitra | first5 = Ankur
| last6 = Sontag | first6 = David
| last7 = Wu | first7 = Yichen
| last8 = Zhu | first8 = Michael
| title = A practical algorithm for topic modeling with provable guarantees
| url = http://jmlr.csail.mit.edu/proceedings/papers/v28/arora13.html
| arxiv = 1212.4777
| conference = Proceedings of the 30th International Conference on Machine Learning
| year =2013
| bibcode = 2012arXiv1212.4777A}}&lt;/ref&gt;

== Relation to other techniques ==

In ''Learning the parts of objects by non-negative matrix factorization'' Lee and Seung&lt;ref&gt;{{Cite journal
 | author = Lee, Daniel D and Seung, H Sebastian
 | title = Learning the parts of objects by non-negative matrix factorization
 | journal = [[Nature (journal)|Nature]]
 | volume = 401
 | issue = 6755
 | year = 1999
 | doi = 10.1038/44565
 | pmid = 10548103
 | url = http://www.columbia.edu/~jwp2128/Teaching/E4903/papers/nmf_nature.pdf
 | pages = 788–791
| bibcode = 1999Natur.401..788L
 }}&lt;/ref&gt; proposed NMF mainly for parts-based decomposition of images.  It compares NMF to [[vector quantization]] and [[principal component analysis]], and shows that although the three techniques may be written as factorizations, they implement different constraints and therefore produce different results.

[[Image:Restricted Boltzmann machine.svg|thumb|NMF as a probabilistic graphical model: visible units ({{math|'''V'''}}) are connected to hidden units ({{math|'''H'''}}) through weights {{math|'''W'''}}, so that {{math|'''V'''}} is [[Generative model|generated]] from a probability distribution with mean &lt;math&gt;\sum_a W_{ia}h_a&lt;/math&gt;.&lt;ref name="lee-seung"/&gt;{{rp|5}}]]
It was later shown that some types of NMF are an instance of a more general probabilistic model called "multinomial PCA".&lt;ref&gt;{{Cite conference
 | author = Wray Buntine
 | url = http://cosco.hiit.fi/Articles/ecml02.pdf
 | format=PDF| title = Variational Extensions to EM and Multinomial PCA
 | conference = Proc. European Conference on Machine Learning (ECML-02)
 | series = LNAI
 | volume = 2430
 | pages = 23–34
 | year = 2002
}}&lt;/ref&gt;
When NMF is obtained by minimizing the [[Kullback–Leibler divergence]], it is in fact equivalent to another instance of multinomial PCA, [[probabilistic latent semantic analysis]],&lt;ref&gt;{{Cite conference
 |author1=Eric Gaussier  |author2=Cyril Goutte
  |lastauthoramp=yes | year = 2005
 | url = http://eprints.pascal-network.org/archive/00000971/01/39-gaussier.pdf
 | format=PDF| title = Relation between PLSA and NMF and Implications
 | conference = Proc. 28th international ACM SIGIR conference on Research and development in information retrieval (SIGIR-05)
 | pages = 601–602
}}&lt;/ref&gt;
trained by [[maximum likelihood]] estimation.
That method is commonly used for analyzing and clustering textual data and is also related to the [[latent class model]].

NMF with the least-squares objective is equivalent to a relaxed form of [[K-means clustering]]: the matrix factor {{math|'''W'''}} contains cluster centroids and {{math|'''H'''}} contains cluster membership indicators.&lt;ref name="DingSDM2005"&gt;C. Ding, X. He, H.D. Simon (2005). [http://ranger.uta.edu/~chqding/papers/NMF-SDM2005.pdf "On the Equivalence of Nonnegative Matrix Factorization and Spectral Clustering"]. Proc. SIAM Int'l Conf. Data Mining, pp. 606-610. May 2005&lt;/ref&gt;&lt;ref&gt;Ron Zass and [[Amnon Shashua]] (2005). "[http://www.cs.huji.ac.il/~zass/papers/cp-iccv05.pdf A Unifying Approach to Hard and Probabilistic Clustering]". International Conference on Computer Vision (ICCV)  Beijing, China, Oct., 2005.&lt;/ref&gt;  This provides a theoretical foundation for using NMF for data clustering. However, k-means does not enforce non-negativity on its centroids, so the closest analogy is in fact with "semi-NMF".{{r|ding}}

NMF can be seen as a two-layer [[Bayesian network|directed graphical]] model with one layer of observed random variables and one layer of hidden random variables.&lt;ref&gt;{{cite conference |author=Max Welling|title=Exponential Family Harmoniums with an Application to Information Retrieval |conference=NIPS|url=http://papers.nips.cc/paper/2672-exponential-family-harmoniums-with-an-application-to-information-retrieval |year=2004|pages=|display-authors=etal}}&lt;/ref&gt;

NMF extends beyond matrices to tensors of arbitrary order.&lt;ref&gt;{{Cite journal
 | author = Pentti Paatero
 | author-link = Pentti Paatero
 | title = The Multilinear Engine: A Table-Driven, Least Squares Program for Solving Multilinear Problems, including the n-Way Parallel Factor Analysis Model
 | journal = [[Journal of Computational and Graphical Statistics]]
 | volume = 8
 | issue = 4
 | pages = 854&amp;ndash;888
 | year = 1999
 | doi = 10.2307/1390831
 | jstor = 1390831
}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal
 |author1=Max Welling  |author2=Markus Weber
  |lastauthoramp=yes | year = 2001
 | title = Positive Tensor Factorization
 | journal = [[Pattern Recognition Letters]]
 | volume = 22
 | issue = 12
 | pages = 1255&amp;ndash;1261
 | doi = 10.1016/S0167-8655(01)00070-8
|citeseerx=10.1.1.21.24
  }}&lt;/ref&gt;&lt;ref&gt;{{Cite conference
  |author1=Jingu Kim  |author2=Haesun Park
   |lastauthoramp=yes | title = Fast Nonnegative Tensor Factorization with an Active-set-like Method
  | publisher = Springer
  | pages = 311&amp;ndash;326
  | url = http://www.cc.gatech.edu/~hpark/papers/2011_paper_hpscbook_ntf.pdf
  | year = 2012
  | conference = High-Performance Scientific Computing: Algorithms and Applications }}
&lt;/ref&gt; This extension may be viewed as a non-negative counterpart to, e.g., the [[PARAFAC]] model.

Other extensions of NMF include joint factorisation of several data matrices and tensors where some factors are shared. Such models are useful for sensor fusion and relational learning.&lt;ref&gt;{{Cite conference
| author = Kenan Yilmaz
| author2 = A. Taylan Cemgil
| author3 = Umut Simsekli
| last-author-amp = yes 
| title = Generalized Coupled Tensor Factorization
| url = http://books.nips.cc/papers/files/nips24/NIPS2011_1189.pdf
| conference = NIPS
| year =2011
}}
&lt;/ref&gt;

NMF is an instance of nonnegative [[quadratic programming]] ([[NQP]]), just like the [[support vector machine]] (SVM). However, SVM and NMF are related at a more intimate level than that of NQP, which allows direct application of the solution algorithms developed for either of the two methods to problems in both domains.&lt;ref&gt;{{Cite conference
 | author = Vamsi K. Potluru
 | author2 = Sergey M. Plis
 | author3 = Morten Morup
 | author4 = Vince D. Calhoun
 | author5 = Terran Lane
 | last-author-amp = yes
 | title = Efficient Multiplicative updates for Support Vector Machines
 | year = 2009
 | conference = Proceedings of the 2009 SIAM Conference on Data Mining (SDM)
 | pages = 1218–1229
}}&lt;/ref&gt;

== Uniqueness ==
The factorization is not unique: A matrix and its [[inverse matrix|inverse]] can be used to transform the two factorization matrices by, e.g.,&lt;ref&gt;{{Cite conference
 | author = Wei Xu
 | author2 = Xin Liu
 | author3 = Yihong Gong
 | last-author-amp = yes
 | title = Document clustering based on non-negative matrix factorization
 | publisher = [[Association for Computing Machinery]]
 | location = New York
 | year = 2003
 | conference = Proceedings of the 26th annual international ACM SIGIR conference on Research and development in information retrieval
 | pages = 267&amp;ndash;273
 | url = http://portal.acm.org/citation.cfm?id=860485
}}&lt;/ref&gt;
: &lt;math&gt;\mathbf{WH} = \mathbf{WBB}^{-1}\mathbf{H}&lt;/math&gt;
If the two new matrices &lt;math&gt;\mathbf{\tilde{W} = WB}&lt;/math&gt; and &lt;math&gt;\mathbf{\tilde{H}}=\mathbf{B}^{-1}\mathbf{H}&lt;/math&gt; are [[non-negative matrix|non-negative]] they form another parametrization of the factorization.

The non-negativity of &lt;math&gt;\mathbf{\tilde{W}}&lt;/math&gt; and &lt;math&gt;\mathbf{\tilde{H}}&lt;/math&gt; applies at least if {{math|'''B'''}} is a non-negative [[monomial matrix]].
In this simple case it will just correspond to a scaling and a [[permutation]].

More control over the non-uniqueness of NMF is obtained with sparsity constraints.&lt;ref&gt;Julian Eggert, Edgar Körner, "[https://dx.doi.org/10.1109/IJCNN.2004.1381036 Sparse coding and NMF]", ''Proceedings. 2004 IEEE International Joint Conference on Neural Networks, 2004, pp. 2529-2533, 2004.&lt;/ref&gt;

== Applications ==

=== Astronomy ===
In astronomy, NMF is a promising method for [[dimension reduction]] in the sense that astrophysical signals are non-negative. NMF has been applied to the spectroscopic observations &lt;ref name="ReferenceA"/&gt;&lt;ref name="blantonRoweis07"&gt;{{Cite journal|arxiv=astro-ph/0606170|last1= Blanton|first1= Michael R.|title= K-corrections and filter transformations in the ultraviolet, optical, and near infrared |journal= The Astronomical Journal|volume= 133|issue= 2|pages= 734–754|last2=  Roweis|first2= Sam |year= 2007|doi= 10.1086/510127|bibcode = 2007AJ....133..734B }}&lt;/ref&gt; and the direct imaging observations &lt;ref name = "ren18"&gt;{{Cite journal|arxiv=1712.10317|last1= Ren|first1= Bin |title= 
Non-negative Matrix Factorization: Robust Extraction of Extended Structures|journal= The Astrophysical Journal|volume= 852|issue= 2|pages= 104|last2=  Pueyo|first2= Laurent|last3= Zhu | first3 = Guangtun B.|last4=  Duchêne|first4= Gaspard |year= 2018|doi= 10.3847/1538-4357/aaa1f2|bibcode = 2018ApJ...852..104R }}&lt;/ref&gt; as a method to study the common properties of astronomical objects and post-process the astronomical observations. The advances in the spectroscopic observations by Blanton &amp; Roweis (2007) &lt;ref name="blantonRoweis07" /&gt; takes into account of the uncertainties of astronomical observations, which is later improved by Zhu (2016) &lt;ref name="zhu16"&gt;{{Cite arXiv|last=Zhu|first=Guangtun B.|date=2016-12-19|title=Nonnegative Matrix Factorization (NMF) with Heteroscedastic Uncertainties and Missing data |eprint=1612.06037|class=astro-ph.IM}}&lt;/ref&gt; where missing data are also considered and [[parallel computing]] is enabled. Their method is then adopted by Ren et al. (2018) &lt;ref name="ren18" /&gt; to the direct imaging field as one of the [[methods of detecting exoplanets]], especially for the direct imaging of [[circumstellar disks]].

Ren et al. (2018) &lt;ref name="ren18" /&gt; are able to prove the stability of NMF components when they are constructed sequentially (i.e., one by one), which enables the [[linearity]] of the NMF modeling process; the [[linearity]] property is used to separate the stellar light and the light scattered from the [[exoplanets]] and [[circumstellar disks]].

In direct imaging, to reveal the faint exoplanets and circumstellar disks from bright the surrounding stellar lights, which has a typical contrast from 10⁵ to 10¹⁰, various statistical methods have been adopted,&lt;ref&gt;{{Cite journal|arxiv= 0902.3247 |last1= 	
Lafrenière|first1= David |title= HST/NICMOS Detection of HR 8799 b in 1998 |journal= The Astrophysical Journal Letters |volume= 694|issue= 	2|pages= L148 |last2=  Maroid|first2= Christian|last3= Doyon | first3 = René| last4=Barman|first4=Travis|year= 2009|doi= 10.1088/0004-637X/694/2/L148|bibcode = 2009ApJ...694L.148L }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|arxiv=1207.6637|last1= Amara|first1= Adam |title= PYNPOINT: an image processing package for finding exoplanets|journal= Monthly Notices of the Royal Astronomical Society|volume= 427|issue= 2|pages= 948|last2=  Quanz|first2= Sascha P.|year= 2012|doi= 10.1111/j.1365-2966.2012.21918.x|bibcode = 2012MNRAS.427..948A}}&lt;/ref&gt;&lt;ref name = "soummer12"&gt;{{Cite journal|arxiv=1207.4197|last1= Soummer|first1= Rémi |title= 
Detection and Characterization of Exoplanets and Disks Using Projections on Karhunen-Loève Eigenimages|journal= The Astrophysical Journal Letters |volume= 755|issue= 2|pages= L28|last2=  Pueyo|first2= Laurent|last3= Larkin | first3 = James|year= 2012|doi= 10.1088/2041-8205/755/2/L28|bibcode = 2012ApJ...755L..28S }}&lt;/ref&gt; however the light from the exoplanets or circumstellar disks are usually over-fitted, where forward modeling have to be adopted to recover the true flux.&lt;ref&gt;{{Cite journal|arxiv= 1502.03092 |last1= Wahhaj|first1= Zahed |title= Improving signal-to-noise in the direct imaging of exoplanets and circumstellar disks with MLOCI |last2=Cieza|first2=Lucas A.|last3=Mawet|first3=Dimitri|last4=Yang|first4=Bin|last5=Canovas|first5=Hector|last6= de Boer|first6=Jozua|last7=Casassus|first7=Simon|last8= Ménard|first8= François|last9=Schreiber|first9=Matthias R.|last10=Liu|first10=Michael C.|last11=Biller|first11=Beth A.|last12=Nielsen|first12=Eric L.|last13=Hayward|first13=Thomas L.|journal= Astronomy &amp; Astrophysics|volume= 581|issue= 24|pages= A24|year= 2015|doi= 10.1051/0004-6361/201525837|bibcode = 2015A&amp;A...581A..24W}}&lt;/ref&gt;&lt;ref name="pueyo16"&gt;{{Cite journal|arxiv= 1604.06097 |last1= Pueyo|first1= Laurent |title= Detection and Characterization of Exoplanets using Projections on Karhunen Loeve Eigenimages: Forward Modeling |journal= The Astrophysical Journal |volume= 824|issue= 2|pages= 117|year= 2016|doi= 10.3847/0004-637X/824/2/117|bibcode = 2016ApJ...824..117P}}&lt;/ref&gt; Forward modeling is currently optimized for point sources,&lt;ref name="pueyo16"/&gt; however not for extended sources, especially for irregularly shaped structures such as circumstellar disks. In this situation, NMF has been an excellent method, being less over-fitting in the sense of the non-negativity and [[sparsity]] of the NMF modeling coefficients, therefore forward modeling can be performed with a few scaling factors,&lt;ref name="ren18" /&gt; rather than a computationally intensive data re-reduction on generated models.

=== Text mining ===
NMF can be used for [[text mining]] applications.
In this process, a [[document-term matrix|''document-term'' matrix]] is constructed with the weights of various terms (typically weighted word frequency information) from a set of documents.
This matrix is factored into a ''term-feature'' and a ''feature-document'' matrix.
The features are derived from the contents of the documents, and the feature-document matrix describes [[Data clustering|data clusters]] of related documents.

One specific application used hierarchical NMF on a small subset of scientific abstracts from [[PubMed]].&lt;ref&gt;{{Cite journal
 | last1 = Nielsen
 | first1 = Finn Årup
 | last2 = Balslev
 | first2 = Daniela
 | last3 = Hansen
 | first3 = Lars Kai
 | title = Mining the posterior cingulate: segregation between memory and pain components
 | journal = [[NeuroImage]]
 | volume = 27
 | issue = 3
 | pages = 520–522
 | year = 2005
 | doi = 10.1016/j.neuroimage.2005.04.034
 | pmid = 15946864
}}&lt;/ref&gt;
Another research group clustered parts of the [[Enron]] email dataset&lt;ref&gt;{{Cite web
 | last1 = Cohen
 | first1 = William
 | title = Enron Email Dataset
 | url = http://www.cs.cmu.edu/~enron/
 | date = 2005-04-04
 | accessdate = 2008-08-26
}}&lt;/ref&gt;
with 65,033 messages and 91,133 terms into 50 clusters.&lt;ref&gt;{{Cite journal
 | last1 = Berry
 | first1 = Michael W.
 | last2 = Browne
 | title = Email Surveillance Using Non-negative Matrix Factorization
 | journal = [[Computational and Mathematical Organization Theory]]
 | volume = 11
 | issue = 3
 | pages = 249&amp;ndash;264
 | year = 2005
 | doi = 10.1007/s10588-005-5380-5
 | first2 = Murray
}}&lt;/ref&gt;
NMF has also been applied to citations data, with one example clustering [[English Wikipedia]] articles and [[scientific journal]]s based on the outbound scientific citations in English Wikipedia.&lt;ref&gt;{{Cite conference
 | last1 = Nielsen
 | first = Finn Årup
 | title = Clustering of scientific citations in Wikipedia
 | conference = [[Wikimania]]
 | year = 2008
 | url = http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=5666
}}&lt;/ref&gt;

Arora, Ge, Halpern, Mimno, Moitra, Sontag, Wu, &amp; Zhu (2013) have given polynomial-time algorithms to learn topic models using NMF. The algorithm assumes that the topic matrix satisfies a separability condition that is often found to hold in these settings.&lt;ref name=Arora2013 /&gt;

=== Spectral data analysis ===
NMF is also used to analyze spectral data; one such use is in the classification of space objects and debris.&lt;ref name="BerryM2006Algorithm"&gt;{{Cite journal
 | author = Michael W. Berry| title = Algorithms and Applications for Approximate Nonnegative Matrix Factorization
 | year = 2006
|display-authors=etal}}&lt;/ref&gt;

=== Scalable Internet distance prediction ===
NMF is applied in scalable Internet distance (round-trip time) prediction. For a network with &lt;math&gt;N&lt;/math&gt; hosts, with the help of NMF, the distances of all the &lt;math&gt;N^2&lt;/math&gt; end-to-end links can be predicted after conducting only &lt;math&gt;O(N)&lt;/math&gt; measurements. This kind of method was firstly introduced in Internet
Distance Estimation Service (IDES).&lt;ref name="IDES_Mao06"&gt;{{Cite journal
 |author1=Yun Mao
 |author2=Lawrence Saul
  |author3=Jonathan M. Smith
  |lastauthoramp=yes | title = IDES: An Internet Distance Estimation Service for Large Networks
 | journal = [[IEEE Journal on Selected Areas in Communications]]
 | volume = 24
 | issue = 12
 | pages = 2273&amp;ndash;2284
 | year = 2006
 | doi = 10.1109/JSAC.2006.884026
|citeseerx=10.1.1.136.3837
  }}&lt;/ref&gt; Afterwards, as a fully decentralized approach, Phoenix network coordinate system&lt;ref name="Phoenix_Chen11"&gt;{{Cite journal
 |author          = Yang Chen
 |author2         = Xiao Wang
 |author3         = Cong Shi
 |last-author-amp = yes
 |url             = http://www.cs.duke.edu/~ychen/Phoenix_TNSM.pdf
 |format          = PDF
 |title           = Phoenix: A Weight-based Network Coordinate System Using Matrix Factorization
 |journal         = [[IEEE Transactions on Network and Service Management]]
 |volume          = 8
 |issue           = 4
 |pages           = 334–347
 |year            = 2011
 |doi             = 10.1109/tnsm.2011.110911.100079
 |display-authors = etal
 |deadurl         = yes
 |archiveurl      = https://web.archive.org/web/20111114191220/http://www.cs.duke.edu/~ychen/Phoenix_TNSM.pdf
 |archivedate     = 2011-11-14
 |df              = 
|citeseerx         = 10.1.1.300.2851
 }}&lt;/ref&gt;
is proposed. It achieves better overall prediction accuracy by introducing the concept of weight.

=== Non-stationary speech denoising ===

Speech denoising has been a long lasting problem in [[audio signal processing]]. There are lots of algorithms for denoising if the noise is stationary. For example, the [[Wiener filter]] is suitable for additive [[Gaussian noise]]. However, if the noise is non-stationary, the classical denoising algorithms usually have poor performance because the statistical information of the non-stationary noise is difficult to estimate. Schmidt et al.&lt;ref&gt;Schmidt, M.N., J. Larsen, and F.T. Hsiao. (2007). "Wind noise reduction using non-negative sparse coding", ''Machine Learning for Signal Processing,  IEEE Workshop on'', 431–436&lt;/ref&gt; use NMF to do speech denoising under non-stationary noise, which is completely different from classical statistical approaches. The key idea is that clean speech signal can be sparsely represented by a speech dictionary, but non-stationary noise cannot. Similarly, non-stationary noise can also be sparsely represented by a noise dictionary, but speech cannot.

The algorithm for NMF denoising goes as follows. Two dictionaries, one for speech and one for noise, need to be trained offline. Once a noisy speech is given, we first calculate the magnitude of the Short-Time-Fourier-Transform. Second, separate it into two parts via NMF, one can be sparsely represented by the speech dictionary, and the other part can be sparsely represented by the noise dictionary. Third, the part that is represented by the speech dictionary will be the estimated clean speech.

=== Bioinformatics ===

NMF has been successfully applied in [[bioinformatics]] for clustering [[gene expression]] and [[DNA methylation]] data and finding the genes most representative of the clusters.&lt;ref name="Leo Taslaman and Björn Nilsson 2012 e46331"/&gt;&lt;ref&gt;{{Cite journal
 | author = Devarajan, K.
 | title = Nonnegative Matrix Factorization: An Analytical and Interpretive Tool in Computational Biology
 | journal = [[PLoS Computational Biology]]
| volume = 4
 | issue = 7
 | year = 2008
 | doi=10.1371/journal.pcbi.1000029
 | pmid = 18654623
 | pmc = 2447881
 | pages=e1000029
| bibcode = 2008PLSCB...4E0029D
 }}&lt;/ref&gt;&lt;ref name="kim2007sparse"&gt;{{Cite journal
 |author1=Hyunsoo Kim  |author2=Haesun Park
  |lastauthoramp=yes | title = Sparse non-negative matrix factorizations via alternating non-negativity-constrained least squares for microarray data analysis
 | journal = [[Bioinformatics (journal)|Bioinformatics]]
 | volume = 23
 | issue = 12
 | pages = 1495&amp;ndash;1502
 | year = 2007
 | doi = 10.1093/bioinformatics/btm134
 | url = http://bioinformatics.oxfordjournals.org/cgi/content/abstract/23/12/1495
 | pmid = 17483501
}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal
 | author = Schwalbe, E.
 | title = DNA methylation profiling of medulloblastoma allows robust sub-classification and improved outcome prediction using formalin-fixed biopsies
 | journal = [[Acta Neuropathologica]]
 | volume = 125
 | issue = 3
 | year = 2013
 | pages = 359&amp;ndash;371
 | doi =10.1007/s00401-012-1077-2
 | pmid = 23291781
 | pmc=4313078
}}&lt;/ref&gt; In the analysis of cancer mutations it has been used to identify common patterns of mutations that occur in many cancers and that probably have distinct causes.&lt;ref&gt;{{Cite journal|last=Alexandrov|first=Ludmil B.|last2=Nik-Zainal|first2=Serena|last3=Wedge|first3=David C.|last4=Campbell|first4=Peter J.|last5=Stratton|first5=Michael R.|date=2013-01-31|title=Deciphering signatures of mutational processes operative in human cancer|journal=Cell Reports|volume=3|issue=1|pages=246–259|doi=10.1016/j.celrep.2012.12.008|issn=2211-1247|pmc=3588146|pmid=23318258}}&lt;/ref&gt;

=== Nuclear imaging ===
NMF, also referred in this field as factor analysis, has been used since the [[1980s]]&lt;ref&gt;{{Cite journal|last=DiPaola|first=|last2=Bazin|last3=Aubry|last4=Aurengo|last5=Cavailloles|last6=Herry|last7=Kahn|date=|year=1982|title=Handling of dynamic sequences in nuclear medicine|url=|journal=[[IEEE Trans Nucl Sci]]|volume=NS-29|issue=4|pages=1310–21|bibcode=1982ITNS...29.1310D|doi=10.1109/tns.1982.4332188|pmid=|via=}}&lt;/ref&gt; to analyze sequences of images in [[SPECT]] and [[Positron emission tomography|PET]] dynamic medical imaging. Non-uniqueness of NMF was addressed using sparsity constraints.&lt;ref&gt;{{Cite journal
 | last1 = Sitek
| last2 = Gullberg 
|last3 = Huesman
 | title = Correction for ambiguous solutions in factor analysis using a penalized least squares objective 
 | journal = [[IEEE Trans Med Imaging]]
| volume = 21
| issue = 3
 | year = 2002
| pages = 216–25
 | doi=10.1109/42.996340
| pmid = 11989846 
}}&lt;/ref&gt;

== Current research ==
Current research (since 2010) in nonnegative matrix factorization includes, but is not limited to,

# Algorithmic: searching for global minima of the factors and factor initialization.&lt;ref&gt;{{Cite journal
 |author1=C. Boutsidis  |author2=E. Gallopoulos
  |lastauthoramp=yes | title = SVD based initialization: A head start for nonnegative matrix factorization
 | journal = Pattern Recognition
 | volume = 41
 | issue = 4
 | pages = 1350–1362
 | year = 2008
 | doi = 10.1016/j.patcog.2007.09.010
|citeseerx=10.1.1.137.8281
  }}&lt;/ref&gt;
# Scalability: how to factorize million-by-billion matrices, which are commonplace in Web-scale data mining, e.g., see Distributed Nonnegative Matrix Factorization (DNMF)&lt;ref&gt;{{Cite journal
 |author1=Chao Liu |author2=Hung-chih Yang |author3=Jinliang Fan |author4=Li-Wei He |author5=Yi-Min Wang  |last-author-amp=yes | title = Distributed Nonnegative Matrix Factorization for Web-Scale Dyadic Data Analysis on MapReduce
 | journal = Proceedings of the 19th International World Wide Web Conference
 | year = 2010
 | url = http://research.microsoft.com/pubs/119077/DNMF.pdf
}}&lt;/ref&gt; and Scalable Nonnegative Matrix Factorization (ScalableNMF)&lt;ref&gt;{{Cite journal
 | author = Jiangtao Yin
 | author2 = Lixin Gao
 | author3 = Zhongfei (Mark) Zhang
 | last-author-amp = yes
 | title = Scalable Nonnegative Matrix Factorization with Block-wise Updates
 | journal = Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases
 | year = 2014
 | url = http://rio.ecs.umass.edu/mnilpub/papers/ecmlpkdd2014-yin.pdf
}}&lt;/ref&gt;
# Online: how to update the factorization when new data comes in without recomputing from scratch, e.g., see online CNSC&lt;ref&gt;{{Cite journal
|author1=Dong Wang |author2=Ravichander Vipperla |author3=Nick Evans |author4=Thomas Fang Zheng | title = Online Non-Negative Convolutive Pattern Learning for Speech Signals
| journal = IEEE Transactions on Signal Processing
| year = 2013
| url = http://cslt.riit.tsinghua.edu.cn:8081/homepages/wangd/public/pdf/cnsc-tsp.pdf
| doi=10.1109/tsp.2012.2222381
| volume=61
|issue=1 | pages=44–56
|bibcode=2013ITSP...61...44W|citeseerx=10.1.1.707.7348 }}&lt;/ref&gt;
# Collective (joint) factorization: factorizing multiple interrelated matrices for multiple-view learning, e.g. multi-view clustering, see CoNMF&lt;ref&gt;{{Cite journal
 | author = Xiangnan He
 | author2 = Min-Yen Kan
 | author3 = Peichu Xie
 | author4 = Xiao Chen
 | last-author-amp = yes
 | title = Comment-based Multi-View Clustering of Web 2.0 Items
 | journal = Proceedings of the 23rd International World Wide Web Conference
 | year = 2014
 | url = http://www.comp.nus.edu.sg/~xiangnan/files/www2014-he.pdf
}}&lt;/ref&gt; and MultiNMF&lt;ref&gt;{{Cite book
 | author = Jialu Liu
 | author2 = Chi Wang
 | author3 = Jing Gao
 | author4 = Jiawei Han
 | last-author-amp = yes
 | title = Multi-View Clustering via Joint Nonnegative Matrix Factorization
 | journal = Proceedings of SIAM Data Mining Conference
 | year = 2013
 | url = http://jialu.cs.illinois.edu/paper/sdm2013-liu.pdf
 | doi=10.1137/1.9781611972832.28
 | pages=252–260
| isbn = 978-1-61197-262-7
 | citeseerx = 10.1.1.301.1771
 }}&lt;/ref&gt;
# Cohen and Rothblum 1993 problem: whether a rational matrix always has an NMF of minimal inner dimension whose factors are also rational. Recently, this problem has been answered negatively.&lt;ref&gt;{{Cite arXiv|last=Chistikov|first=Dmitry|last2=Kiefer|first2=Stefan|last3=Marušić|first3=Ines|last4=Shirmohammadi|first4=Mahsa|last5=Worrell|first5=James|date=2016-05-22|title=Nonnegative Matrix Factorization Requires Irrationality |eprint=1605.06848|class=cs.CC}}&lt;/ref&gt;

==See also==
*[[Multilinear algebra]]
*[[Multilinear subspace learning]]
*[[Tensor]]
*[[Tensor decomposition]]
*[[Tensor software]]

== Sources and external links ==

=== Notes ===
{{Reflist|2}}

=== Others ===
{{refbegin}}
* {{Cite journal
 |author1=J. Shen |author2=G. W. Israël | title = A receptor model using a specific non-negative transformation technique for ambient aerosol
 | journal = [[Atmospheric Environment (journal)|Atmospheric Environment]]
 | volume = 23
 | issue = 10
 | pages = 2289&amp;ndash;2298
 | year = 1989
 | doi = 10.1016/0004-6981(89)90190-X
|bibcode=1989AtmEn..23.2289S }}
* {{Cite journal
 | author = Pentti Paatero
 | author-link = Pentti Paatero
 | title = Least squares formulation of robust non-negative factor analysis
 | journal = [[Chemometrics and Intelligent Laboratory Systems]]
 | volume = 37
 | issue = 1
 | pages = 23&amp;ndash;35
 | year = 1997
 | doi = 10.1016/S0169-7439(96)00044-5
}}
* {{Cite journal
 | author = Raul Kompass
 | title = A Generalized Divergence Measure for Nonnegative Matrix Factorization
 | journal = [[Neural Computation (journal)|Neural Computation]]
 | volume = 19
 | issue = 3
 | year = 2007
 | pages = 780&amp;ndash;791
 | pmid = 17298233
 | doi = 10.1162/neco.2007.19.3.780
}}
* {{Cite journal
|  title=Nonnegative Matrix Factorization and its applications in pattern recognition
|  author=Liu, W.X.
|  author2=Zheng, N.N.
|  author3=You, Q.B.
|  last-author-amp=yes
|  journal=[[Chinese Science Bulletin]]
|  volume=51
|  pages=7&amp;ndash;18
|  year=2006
|  url = http://www.springerlink.com/index/7285V70531634264.pdf
|  doi=10.1007/s11434-005-1109-6
|  issue=17&amp;ndash;18
|  bibcode=2006ChSBu..51....7L
}}
* {{Cite arXiv
 | author = Ngoc-Diep Ho
 | author2 = Paul Van Dooren
 | author3 = Vincent Blondel
 | last-author-amp = yes
 | title = Descent Methods for Nonnegative Matrix Factorization
 | year = 2008
 | eprint = 0801.3199
 | class = cs.NA
}}
* {{Cite journal
 | author = Andrzej Cichocki
 | author-link = Andrzej Cichocki
 | author2 = Rafal Zdunek
 | author3 = Shun-ichi Amari
 | author3-link = Shun-ichi Amari
 | last-author-amp = yes
 | title = Nonnegative Matrix and Tensor Factorization
 | journal = [[IEEE Signal Processing Magazine]]
 | volume = 25
 | issue = 1
 | year = 2008
 | pages = 142&amp;ndash;145
 | doi = 10.1109/MSP.2008.4408452
| bibcode = 2008ISPM...25R.142C
 }}
* {{Cite journal
 | title = Nonnegative Matrix Factorization with the Itakura-Saito Divergence: With Application to Music Analysis
 |author1=Cédric Févotte |author2=Nancy Bertin |author3=Jean-Louis Durrieu  |last-author-amp=yes | journal = [[Neural Computation (journal)|Neural Computation]]
 | volume = 21
 | issue = 3
 | year = 2009
| pmid=18785855
 | doi=10.1162/neco.2008.04-08-771
 | pages=793–830
}}
* {{Cite journal
 | author = Ali Taylan Cemgil
 | title = Bayesian Inference for Nonnegative Matrix Factorisation Models
 | journal = [[Computational Intelligence and Neuroscience]]
 | volume = 2009
 | issue = 2
 | year = 2009
 | doi = 10.1155/2009/785152
 | url = http://www.hindawi.com/journals/cin/2009/785152.abs.html
 | pages = 1–17
 | pmid = 19536273
 | pmc = 2688815
}}
{{refend}}

[[Category:Linear algebra]]
[[Category:Matrix theory]]
[[Category:Machine learning algorithms]]</text>
      <sha1>5bmzyrp8vp3tmhomu2tycn7wm7ho4zw</sha1>
    </revision>
  </page>
  <page>
    <title>PLS (complexity)</title>
    <ns>0</ns>
    <id>4669257</id>
    <revision>
      <id>844149090</id>
      <parentid>801660021</parentid>
      <timestamp>2018-06-02T23:17:10Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3760">In [[computational complexity theory]], Polynomial Local Search ('''PLS''') is a [[complexity class]] that models the difficulty of finding a [[local optimum|locally optimal]] solution to an [[optimization problem]].

A PLS problem &lt;math&gt;L&lt;/math&gt; has a set &lt;math&gt;D_L&lt;/math&gt; of instances which are encoded using [[String (computer science)|strings]] over a finite [[Alphabet (computer science)|alphabet]] &lt;math&gt;\Sigma&lt;/math&gt;. For each instance &lt;math&gt;x&lt;/math&gt; there exists a finite solution set &lt;math&gt;F_L(x)&lt;/math&gt;. Each solution &lt;math&gt;s \in F_L(x)&lt;/math&gt; has a non negative integer cost given by a function &lt;math&gt;c_L(s, x)&lt;/math&gt; and a neighborhood &lt;math&gt;N(s, x) \subseteq F_L(x)&lt;/math&gt;. Additionally, the existence of the following three [[Polynomial time algorithm#Polynomial time|polynomial time]] algorithms is required:

* Algorithm &lt;math&gt;A_L&lt;/math&gt; produces some solution &lt;math&gt;A_L(x) \in F_L(x)&lt;/math&gt;.
* Algorithm &lt;math&gt;B_L&lt;/math&gt; determines the value of &lt;math&gt;c_L(s, x)&lt;/math&gt;.
* Algorithm &lt;math&gt;C_L&lt;/math&gt; maps a solution &lt;math&gt;s \in F_L(x)&lt;/math&gt; to an element &lt;math&gt;s' \in N(s, x)&lt;/math&gt; such that &lt;math&gt;c_L(s', x) &lt; c_L(s, x)&lt;/math&gt; if such an element exists. Otherwise &lt;math&gt;C_L&lt;/math&gt; reports that no such element exists.

An instance &lt;math&gt;D_L&lt;/math&gt; has the structure of an [[implicit graph]], the vertices being the solutions with two solutions &lt;math&gt;s, s' \in F_L(x)&lt;/math&gt; connected by a directed arc iff &lt;math&gt;s' \in N(s, x)&lt;/math&gt;. The most interesting computational problem is the following:

''Given some instance &lt;math&gt;x&lt;/math&gt; of a PLS problem &lt;math&gt;L&lt;/math&gt;, find a local optimum of &lt;math&gt;c_L(s, x)&lt;/math&gt;, i.e. a solution &lt;math&gt;s \in F_L(x)&lt;/math&gt; such that &lt;math&gt;c_L(s', x) \geq c_L(s, x)&lt;/math&gt; for all &lt;math&gt;s' \in N(s, x)&lt;/math&gt;''

The problem can be solved using the following algorithm:

# Use &lt;math&gt;A_L&lt;/math&gt; to find an initial solution &lt;math&gt;s&lt;/math&gt;
# Use algorithm &lt;math&gt;C_L&lt;/math&gt; to find a better solution &lt;math&gt;s' \in N(s, x)&lt;/math&gt;. If such a solution exists, replace &lt;math&gt;s&lt;/math&gt; by &lt;math&gt;s'&lt;/math&gt;, else return &lt;math&gt;s&lt;/math&gt;

Unfortunately, it generally takes an exponential number of improvement steps to find a local optimum even if the problem &lt;math&gt;L&lt;/math&gt; can be solved exactly in polynomial time.

Examples of PLS-complete problems include local-optimum relatives of the [[travelling salesman problem]], [[maximum cut]] and [[satisfiability]], as well as finding a pure [[Nash equilibrium]] in a [[congestion game]].&lt;ref&gt;{{cite journal|last1=Fabrikant|first1=Alex|last2=Papadimitriou|author2link=Christos_Papadimitriou|first2=Christos|last3=Talwar|first3=Kunal|title=The complexity of pure Nash equilibria|journal=STOC '04 Proceedings of the thirty-sixth annual ACM symposium on Theory of computing|pages=604–612|doi=10.1145/1007352.1007445|url=http://dl.acm.org/citation.cfm?id=1007445|accessdate=11 June 2017|publisher=ACM}}&lt;/ref&gt;

PLS is a subclass of [[TFNP]], a complexity class closely related to [[NP (complexity)|NP]] that describes computational problems in which a solution is guaranteed to exist and can be recognized in polynomial time. For a problem in PLS, a solution is guaranteed to exist because the minimum-cost vertex of the entire graph is a valid solution, and the validity of a solution can be checked by computing its neighbors and comparing the costs of each one.

== References ==
{{reflist}}

== Further reading ==
* {{Citation | last1=Yannakakis | first1=Mihalis | author1-link=Mihalis Yannakakis | title=Equilibria, fixed points, and complexity classes | publisher=[[Elsevier]] | year=2009 | journal=Computer Science Review | volume=3 | issue=2 | pages=71–85 | doi=10.1016/j.cosrev.2009.03.004| arxiv=0802.2831 }}.

[[Category:Complexity classes]]


{{comp-sci-theory-stub}}</text>
      <sha1>4gokcjlu2sqtngforwyntodxkevom3y</sha1>
    </revision>
  </page>
  <page>
    <title>Poincaré series (modular form)</title>
    <ns>0</ns>
    <id>24146591</id>
    <revision>
      <id>840579847</id>
      <parentid>627025306</parentid>
      <timestamp>2018-05-10T19:43:26Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>/* top */[[User:PrimeBOT/24|Task 24]] - replace template usage following [[Wikipedia:Templates for discussion/Log/2018 February 19|a TFD]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2800">{{distinguish|text=the [[Hilbert–Poincaré series]]}} 

In [[number theory]], a '''Poincaré series''' is a [[series (mathematics)|mathematical series]] generalizing the classical [[theta series]] that is associated to any [[discrete group]] of symmetries of a [[complex domain]], possibly of [[several complex variables]].  In particular, they generalize classical [[Eisenstein series]].  They are named after [[Henri Poincaré]].

If &amp;Gamma; is a [[finite group]] acting on a domain ''D'' and ''H''(''z'') is any [[meromorphic function]] on ''D'', then one obtains an [[automorphic function]] by averaging over &amp;Gamma;:
:&lt;math&gt;\sum_{\gamma\in\Gamma} H(\gamma(z)).&lt;/math&gt;
However, if &amp;Gamma; is a [[discrete group]], then additional factors must be introduced in order to assure convergence of such a series.  To this end, a '''Poincaré series''' is a series of the form
:&lt;math&gt;\theta_k(z) = \sum_{\gamma\in\Gamma^*} (J_\gamma(z))^k H(\gamma(z))&lt;/math&gt;
where ''J''&lt;sub&gt;&amp;gamma;&lt;/sub&gt; is the [[Jacobian determinant]] of the group element &amp;gamma;,&lt;ref&gt;Or a more general [[factor of automorphy]] as discussed in {{harvnb|Kollár|1995|loc=§5.2}}.&lt;/ref&gt; and the asterisk denotes that the summation takes place only over coset representatives yielding distinct terms in the series.

The classical '''Poincaré series''' of weight 2''k'' of a [[Fuchsian group]] &amp;Gamma; is defined by the series
:&lt;math&gt;\theta_k(z) = \sum_{\gamma\in\Gamma^*} (cz+d)^{-2k}H\left(\frac{az+b}{cz+d}\right)&lt;/math&gt;
the summation extending over congruence classes of fractional linear transformations
:&lt;math&gt;\gamma=\begin{pmatrix}a&amp;b\\c&amp;d\end{pmatrix}&lt;/math&gt;
belonging to &amp;Gamma;.  Choosing ''H'' to be a [[character (group theory)|character]] of the [[cyclic group]] of order ''n'', one obtains the so-called Poincaré series of order ''n'':
:&lt;math&gt;\theta_{k,n}(z) = \sum_{\gamma\in\Gamma^*} (cz+d)^{-2k}\exp\left(2\pi i n\frac{az+b}{cz+d}\right)&lt;/math&gt;
The latter Poincaré series converges absolutely and uniformly on compact sets (in the upper halfplane), and is a [[modular form]] of weight 2''k'' for &amp;Gamma;.  Note that, when &amp;Gamma; is the full [[modular group]] and ''n''&amp;nbsp;=&amp;nbsp;0, one obtains the Eisenstein series of weight 2''k''.  In general, the Poincaré series is, for ''n''&amp;nbsp;≥&amp;nbsp;1, a [[cusp form]].

==Notes==
&lt;references/&gt;

==References==
*{{Citation | last1=Kollár | first1=János | title=Shafarevich maps and automorphic forms | publisher=[[Princeton University Press]] | series=M. B. Porter Lectures | isbn=978-0-691-04381-4 |mr=1341589 | year=1995|authorlink=János Kollár}}.
*{{Springer|title=Theta-series|id=T/t092610|first=E.D.|last=Solomentsev}}.

{{DEFAULTSORT:Poincare series (modular form)}}
[[Category:Automorphic forms]]
[[Category:Modular forms]]
[[Category:Mathematical series]]</text>
      <sha1>m9ntqwj1xnvpaqiwpa5zjuonz50g7mp</sha1>
    </revision>
  </page>
  <page>
    <title>Profit at risk</title>
    <ns>0</ns>
    <id>49043127</id>
    <revision>
      <id>764460584</id>
      <parentid>754488641</parentid>
      <timestamp>2017-02-09T01:23:53Z</timestamp>
      <contributor>
        <username>PsychoMaple</username>
        <id>30200133</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3579">{{Distinguish|Profit risk}}

'''Profit-at-Risk (PaR)''' is a [[risk management]] quantity most often used for electricity portfolios that contain some mixture of generation assets, trading contracts and end-user consumption. It is used to provide a measure of the downside risk to profitability of a portfolio of physical and financial assets, analysed by time periods in which the energy is delivered. For example, the expected profitability and associated downside risk (PaR) might be calculated and monitored for each of the forward looking 24 months. The measure considers both [[price risk]] and [[volume risk]] (e.g. due to uncertainty in electricity generation volumes or consumer demand).&lt;ref name=ARTdef&gt;{{cite web|title=What is Profit-at-Risk (PaR)?|url=http://www.arbitrage-trading.com/ARTicles_WhatIsPaR.htm|website=.arbitrage-trading.com|publisher=ART Ltd|accessdate=8 January 2016}}&lt;/ref&gt; Mathematically, the PaR is the quantile of the profit distribution of a portfolio. Since weather related volume risk drivers can be represented in the form of historical weather records over many years, a [[Monte-Carlo simulation]] approach is often used.

== Example ==
If the confidence interval for evaluating the PaR is 95%, there is a 5% probability that due to changing commodity volumes and prices, the
profit outcome for a specific period (e.g. December next year) will fall short of the expected profit result by more than the PaR value.

Note that the concept of a set 'holding period' does not apply since the period is always up until the realisation of the profit outcome through the delivery of energy. That is the holding period is different for each of the specific delivery time periods being analysed e.g. it might be six months for December and therefore seven months for January.

== History ==
The PaR measure was originally pioneered at Norsk Hydro in Norway as part of an initiative to prepare for deregulation of the electricity market. Petter Longva and Greg Keers co-authored a paper "Risk Management in the Electricity Industry" (IAEE 17th Annual International Conference, 1994) which introduced the PaR method. This led to it being adopted as the basis for electricity market risk management at Norsk Hydro and later by most of the other electricity generating utilities in the Nordic region. The approach was based on monte-carlo simulations of paired reservoir inflow and spot price outcomes to produce a distribution of expected profit in future reporting periods. This tied directly with the focus of management reporting on profitability of operations, unlike the Value-at-Risk approach that had been pioneered by JP Morgan for banks focused on their balance sheet risks.

== Critics ==
As is the case with ''[[Value at Risk]]'', for risk measures like the PaR, [[Earnings at risk|Earnings-at-Risk]] (EaR), the [[Liquidity at risk|Liquidity-at-Risk]] (LaR) or the [[Margin at risk|Margin-at-Risk]] (MaR), the exact ([[algorithmic trading|algorithmic]]) implementation rule vary from firm to firm.&lt;ref name=EnBW&gt;{{cite web|last1=Burger|first1=Markus|title=Risk measures for large portfolios and their applications in energy trading|url=http://www.risklab.es/es/jornadas/2011/RiskLab2011_Burger.pdf|website=risklab.es|publisher=EnBW Energie Baden-Württemberg AG|accessdate=8 January 2016}}&lt;/ref&gt;

== See also ==
* [[Value at risk]]
* [[Margin at risk]]
* [[Liquidity at risk]]

== References ==
{{reflist}}

{{Financial risk}}

[[Category:Mathematical finance]]
[[Category:Financial risk management]]
[[Category:Monte Carlo methods in finance]]</text>
      <sha1>l5jifdx3kd69qppl7wkro2ecdz5dtxo</sha1>
    </revision>
  </page>
  <page>
    <title>Pseudoelementary class</title>
    <ns>0</ns>
    <id>12747956</id>
    <revision>
      <id>861737617</id>
      <parentid>855503811</parentid>
      <timestamp>2018-09-29T17:16:06Z</timestamp>
      <contributor>
        <username>Mattproof</username>
        <id>12568436</id>
      </contributor>
      <comment>/* Examples */Typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6770">In [[logic]], a '''pseudoelementary class''' is a class of [[structure (mathematical logic)|structure]]s derived from an [[elementary class]] (one definable in first-order logic) by omitting some of its sorts and relations.  It is the [[mathematical logic]] counterpart of the notion in [[category theory]] of (the [[codomain]] of) a [[forgetful functor]], and in [[physics]] of (hypothesized) [[hidden variable theory|hidden variable]] theories purporting to explain [[quantum mechanics]].  Elementary classes are (vacuously) pseudoelementary but the converse is not always true; nevertheless pseudoelementary classes share some of the properties of elementary classes such as being closed under [[ultraproduct]]s.

==Definition==
A '''pseudoelementary class''' is a [[reduct]] of an [[elementary class]].  That is, it is obtained by omitting some of the sorts and relations of a (many-sorted) elementary class.

==Examples==
*1.  The theory with equality of sets under union and intersection, whose structures are of the form (''W'', ∪, ∩), can be understood [[naive set theory|naively]] as the pseudoelementary class formed from the two-sorted elementary class of structures of the form (''A'', ''W'', ∪, ∩, ∈) where ∈ ⊆ ''A''×''W'' and ∪ and ∩ are binary operations (''qua'' ternary relations) on ''W''.  The theory of the latter class is axiomatized by
:∀''X,Y''∈''W''.∀''a''∈''A''.[ ''a'' ∈ ''X''∪''Y'' &amp;nbsp; &amp;hArr; &amp;nbsp; ''a'' ∈ ''X'' &amp;or; ''a'' ∈ ''Y'']
:∀''X,Y''∈''W''.∀''a''∈''A''.[ ''a'' ∈ ''X''∩''Y'' &amp;nbsp; &amp;hArr; &amp;nbsp; ''a'' ∈ ''X'' &amp;and; ''a'' ∈ ''Y'']
:∀''X,Y''∈''W''.[ (∀''a''∈''A''.[''a'' ∈ ''X'' &amp;nbsp; &amp;hArr; &amp;nbsp; ''a'' ∈ ''Y'']) → ''X'' = ''Y'']

:In the intended interpretation ''A'' is a set of atoms ''a,b'',..., ''W'' is a set of sets of atoms ''X,Y,...'' and ∈ is the membership relation between atoms and sets.  The consequences of these axioms include all the laws of [[distributive lattice]]s.  Since the latter laws make no mention of atoms they remain meaningful for the structures obtained from the models of the above theory by omitting the sort ''A'' of atoms and the membership relation ∈.  All distributive lattices are representable as sets of sets under union and intersection, whence this pseudoelementary class is in fact an elementary class, namely the [[Variety (universal algebra)|variety]] of distributive lattices.

:In this example both classes (respectively before and after the omission) are finitely axiomatizable elementary classes.  But whereas the standard approach to axiomatizing the latter class uses nine equations to axiomatize a distributive lattice, the former class only requires the three axioms above, making it faster to define the latter class as a reduct of the former than directly in the usual way.

*2.  The theory with equality of binary relations under union ''R''∪''S'', intersection ''R''∩''S'', complement ''R''&lt;sup&gt;&amp;minus;&lt;/sup&gt;, relational composition ''R'';''S'', and relational converse ''R''&lt;sup&gt;&lt;math&gt;\breve{\ }&lt;/math&gt;&lt;/sup&gt;, whose structures are of the form (''W'', ∪, ∩, &amp;minus;, ;, &lt;sup&gt;&lt;math&gt;\breve{\ }&lt;/math&gt;&lt;/sup&gt;), can be understood as the pseudoelementary class formed from the three-sorted elementary class of structures of the form (''A'', ''P'', ''W'', ∪, ∩, &amp;minus;, ;, &lt;sup&gt;&lt;math&gt;\breve{\ }&lt;/math&gt;&lt;/sup&gt;, λ, ρ, π, ∈).  The intended interpretation of the three sorts are atoms, pairs of atoms, and sets of pairs of atoms, π: ''A''×;''A'' → ''P'' and λ,ρ: ''P'' → ''A'' are the evident pairing constructors and destructors, and ∈ ⊆ ''P''×;''W'' is the membership relation between pairs and relations (as sets of pairs).  By analogy with Example 1, the purely relational connectives defined on ''W'' can be axiomatized naively in terms of atoms and pairs of atoms in the customary manner of introductory texts.  The pure theory of binary relations can then be obtained as the theory of the pseudoelementary class of reducts of models of this elementary class obtained by omitting the atom and pair sorts and all relations involving the omitted sorts.

:In this example both classes are elementary, but only the former class is finitely axiomatizable, though the latter class (the reduct) was shown by Tarski in 1955 to be nevertheless a [[Variety (universal algebra)|variety]], namely '''RRA''', the representable [[relation algebra]]s.

*3.  A [[primitive ring]] is a generalization of the notion of [[simple ring]].  It is definable in elementary (first-order) language in terms of the elements and ideals of a ring, giving rise to an elementary class of two-sorted structures comprising rings and ideals.  The class of primitive rings is obtained from this elementary class by omitting the sorts and language associated with the ideals, and is hence a pseudoelementary class.

:In this example it is an open question whether this pseudoelementary class is elementary.

*4. The class of [[exponentially closed field]]s is a pseudoelementary class that is not elementary.

==Applications==
A [[quasivariety]] defined logically as the class of models of a [[universal Horn theory]] can equivalently be defined algebraically as a class of structures closed under [[isomorphism]]s, [[subalgebra]]s, and [[reduced product]]s.  Since the notion of reduced product is more intricate than that of [[direct product]], it is sometimes useful to blend the logical and algebraic characterizations in terms of pseudoelementary classes.  One such blended definition characterizes a quasivariety as a pseudoelementary class closed under isomorphisms, subalgebras, and direct products (the pseudoelementary property allows "reduced" to be simplified to "direct").

A corollary of this characterization is that one can (nonconstructively) prove the existence of a universal Horn axiomatization of a class by first axiomatizing some expansion of the structure with auxiliary sorts and relations and then showing that the pseudoelementary class obtained by dropping the auxiliary constructs is closed under subalgebras and direct products.  This technique works for Example 2 because subalgebras and direct products of algebras of binary relations are themselves algebras of binary relations, showing that the class '''RRA''' of representable [[relation algebra]]s is a quasivariety (and ''a fortiori'' an elementary class).  This short proof is an effective application of [[abstract nonsense]]; the stronger result by Tarski that '''RRA''' is in fact a variety required more honest toil.

==References==
* Paul C. Eklof (1977), Ultraproducts for Algebraists, in ''Handbook of Mathematical Logic'' (ed. [[Jon Barwise]]), North-Holland.

[[Category:Model theory]]
[[Category:Universal algebra]]</text>
      <sha1>5gpstjng3z241ooo8d82vxrzkfw7eej</sha1>
    </revision>
  </page>
  <page>
    <title>Random tree</title>
    <ns>0</ns>
    <id>22192834</id>
    <revision>
      <id>751554464</id>
      <parentid>751554389</parentid>
      <timestamp>2016-11-26T12:19:04Z</timestamp>
      <contributor>
        <username>Allforrous</username>
        <id>12120664</id>
      </contributor>
      <minor/>
      <comment>/* =External links */ Minor edit.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1709">{{Probabilistic}}
In [[mathematics]] and [[computer science]], a '''random tree''' is a [[tree (graph theory)|tree]] or [[Arborescence (graph theory)|arborescence]] that is formed by a [[stochastic process]]. Types of random trees include:
*[[Uniform spanning tree]], a spanning tree of a given graph in which each different tree is equally likely to be selected
*[[Random minimal spanning tree]], spanning trees of a graph formed by choosing random edge weights and using the minimum spanning tree for those weights
*[[Random binary tree]], binary trees with a given number of nodes, formed by inserting the nodes in a random order or by selecting all possible trees uniformly at random
*[[Recursive tree|Random recursive tree]], increasingly labelled trees, which can be generated using a simple stochastic growth rule.
*[[Treap]] or randomized binary search tree, a data structure that uses random choices to simulate a random binary tree for non-random update sequences
*[[Rapidly exploring random tree]], a fractal space-filling pattern used as a data structure for searching high-dimensional spaces
*[[Brownian tree]], a fractal tree structure created by diffusion-limited aggregation processes
*[[Random forest]], a machine-learning classifier based on choosing random subsets of variables for each tree and using the most frequent tree output as the overall classification
*[[Branching process]], a model of a population in which each individual has a random number of children

==See also==
*[[Brownian tree]]
*[[Lightning tree]]

==External links==
*{{Commonscat-inline}}

{{set index article}}

[[Category:Trees (graph theory)]]
[[Category:Probabilistic data structures]]
[[Category:Random graphs]]</text>
      <sha1>4lgzhiwb8yenoyahpfwd5ie8cklweil</sha1>
    </revision>
  </page>
  <page>
    <title>Richard A. Brualdi</title>
    <ns>0</ns>
    <id>22929637</id>
    <revision>
      <id>857596403</id>
      <parentid>733793304</parentid>
      <timestamp>2018-09-01T18:56:58Z</timestamp>
      <contributor>
        <username>GoingBatty</username>
        <id>11555324</id>
      </contributor>
      <minor/>
      <comment>clean up</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5874">{{Infobox scientist
|name              = Richard Brualdi
|image             =
|birth_date        = {{Birth date and age|1939|9|2}}
|birth_place       = [[Derby]], [[Connecticut]], United States
|death_date        = 
|death_place       = 
|residence         = 
|citizenship       = United States
|nationality       = 
|ethnicity         = 
|fields            = [[Mathematics]]
|workplaces        = [[University of Wisconsin - Madison]]
|alma_mater        = [[Syracuse University]]
|doctoral_advisor  = 
|academic_advisors = 
|doctoral_students = 
|notable_students  = [[Jia-yu Shao]], [[Bryan Shader]], [[T.S. Michael]], [[John Goldwasser]]
|known_for         = [[Matrix Theory]], [[Combinatorics]],&lt;br /&gt;
 [[graph theory]]
|author_abbrev_bot = 
|author_abbrev_zoo = 
|influences        = 
|influenced        = 
|awards            = [[Euler Medal]] (2000), [[International Linear Algebra (ILAS) Hans Schneider Prize]] (2006)

|religion          =
|signature         = &lt;!--(filename only)--&gt;
|footnotes         = 
}}

'''R. A. Brualdi''' is a professor emeritus of [[combinatorics|combinatorial mathematics]] at the [[University of Wisconsin–Madison]].

Brualdi received his Ph.D. from [[Syracuse University]] in 1964; his advisor was [[H. J. Ryser]].&lt;ref&gt;{{MathGenealogy|id=9051}}&lt;/ref&gt; Brualdi is an Editor-in-Chief of the [[Electronic Journal of Combinatorics]]. He has over 200 publications in several mathematical journals. According to current on-line database of Mathematics Genealogy Project, Richard Brualdi has 37 Ph.D. students and 48 academic descendants. The concept of [[incidence coloring]] was introduced in 1993 by Brualdi and Massey.

He received the [[Euler medal]] from the [[Institute of Combinatorics and its Applications]] in 2000. In 2012 he was elected a fellow of the Society for Industrial and Applied Mathematics. In 2012 he became an inaugural fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2012-11-10.&lt;/ref&gt;

==Books==
* (with Herbert J. Ryser) [https://books.google.com/books/about/Combinatorial_Matrix_Theory.html?id=vVTdbb6930EC ''Combinatorial Matrix Theory''], Cambridge Univ. Press
* Richard A. Brualdi, ''Introductory Combinatorics'', Prentice-Hall, Upper Saddle River, N.J.
* V. Pless, R. A. Brualdi, and W. C. Huffman, ''Handbook of Coding Theory'', Elsevier Science, New York, 1998
*{{cite book | zbl=1106.05001 | last=Brualdi | first=Richard A. | title=Combinatorial Matrix Classes | series=Encyclopedia of Mathematics and Its Applications | volume=108 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2006 | isbn=0-521-86565-4 | url=https://books.google.com/books/about/Combinatorial_Matrix_Classes.html?id=xdP9d8S1BxQC}}
* Richard A. Brualdi and Dragos Cvetkovic, ''A Combinatorial Approach to Matrix Theory and Its Applications'', CRC Press, Boca Raton Fla., 2009.
* Richard A. Brualdi and [[Bryan Shader]], ''Matrices of Sign-Solvable Linear Systems'', Cambridge Tracts in Mathematics, Vol. 116, Cambridge Univ. Press, 1995.
* Richard A. Brualdi, ''The Mutually Beneficial Relationship Between Graphs and Matrices'', American Mathematical Society, CBMS Series, 2012.

==Selected articles==
* {{cite journal|title=On the permanent and maximal characteristic root of a nonnegative matrix|journal=Proc. Amer. Math. Soc.|year=1966|volume=17|pages=1413–1416|mr=0204444|doi=10.1090/s0002-9939-1966-0204444-2}}
* {{cite journal|title=A very general theorem on systems of distinct representatives|journal=Trans. Amer. Math. Soc.|year=1969|volume=140|pages=149–160|mr=0249304|doi=10.1090/s0002-9947-1969-0249304-3}}
* {{cite journal|title=An extension of Banach's mapping theorem|journal=Proc. Amer. Math. Soc.|year=1969|volume=20|pages=520–526|mr=0236029|doi=10.1090/s0002-9939-1969-0236029-9}}
* {{cite journal|title=Induced matroids|journal=Proc. Amer. Math. Soc.|year=1971|volume=29|pages=213–221|mr=0289335|doi=10.1090/s0002-9939-1971-0289335-5}}
* {{cite journal|title=Weighted join semilattices and transversal matroids|journal=Trans. Amer. Math. Soc.|year=1974|volume=191|pages=317–328|mr=0382039|doi=10.1090/s0002-9947-1974-0382039-7}}
* {{cite journal|title=On fundamental transversal matroids|journal=Proc. Amer. Math. Soc.|year=1974|volume=45|pages=151–156|mr=0387087|doi=10.1090/s0002-9939-1974-0387087-4}}
* {{cite journal|title=The DAD theorem for arbitrary row sums|journal=Proc. Amer. Math. Soc.|year=1974|volume=45|pages=189–194|mr=0354737|doi=10.1090/s0002-9939-1974-0354737-8}}
* with Jeffrey A. Ross: {{cite journal|title=Invariant sets for classes of matrices of zeros and ones|journal=Proc. Amer. Math. Soc.|year=1980|volume=80|pages=706–710|mr=587961|doi=10.1090/s0002-9939-1980-0587961-2}}
* with J. Csima: {{cite journal|title=On the plane term rank of a three dimensional matrix|journal=Proc. Amer. Math. Soc.|year=1976|volume=54|pages=471–473|mr=0387319|doi=10.1090/s0002-9939-1976-0387319-4}}
* with Bo Lian Liu: {{cite journal|title=Fully indecomposable exponents of primitive matrices|journal=Proc. Amer. Math. Soc.|year=1991|volume=112|pages=1193–1201|mr=1065941|doi=10.1090/s0002-9939-1991-1065941-8}}

==References==
{{reflist}}

==External links==
* [http://www.math.wisc.edu/~brualdi/ Richard Brualdi] at [https://www.math.wisc.edu/ University of Wisconsin- Madison] website

{{Authority control}}

{{DEFAULTSORT:Brualdi, Richard A.}}
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Combinatorialists]]
[[Category:Syracuse University alumni]]
[[Category:University of Wisconsin–Madison faculty]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Living people]]
[[Category:1939 births]]
[[Category:Fellows of the Society for Industrial and Applied Mathematics]]</text>
      <sha1>bgpcix3ft5626bvx7syhax9u9v0r7ni</sha1>
    </revision>
  </page>
  <page>
    <title>Scarborough criterion</title>
    <ns>0</ns>
    <id>44276996</id>
    <revision>
      <id>840123006</id>
      <parentid>773772264</parentid>
      <timestamp>2018-05-07T21:41:49Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5089">{{Orphan|date=April 2017}}

The '''Scarborough criterion''' is used for satisfying convergence of a solution while solving [[linear equations]] using an [[iterative method]].

==Introduction==
Analytical solutions for certain systems of equations can be difficult or impossible to obtain. A well known example are the Navier-Stokes equations describing the flow of Newtonian fluids. Solutions of such equations can be obtained [[numerically]], at discrete points of the solution domain (e.g. at discrete time points and points in space). Numerical solutions based on the integration of the equations at discrete control volumes of the solution domain (for example the [[Finite volume method|Finite Volume Method]]) result in a system of algebraic equations, one for each ''nodal point'' (corresponding to a particular control volume). These algebraic equations are usually referred to as ''discretised equations''. The '''Scarborough criterion''' formulated by Scarborough (1958), can be expressed in terms of the values of the coefficients of the discretised equations:&lt;ref name="Scarborough1955"&gt;{{cite book|author=James Blaine Scarborough|title=Numerical Mathematical Analysis|url=https://books.google.com/books?id=zpaVLfzPgfIC|year=1955|publisher=Johns Hopkins Press}}&lt;/ref&gt;&lt;ref name="Pearson Education Limited"&gt;{{cite book|author1=Henk Kaarle Versteeg|author2=Weeratunge Malalasekera|title=An Introduction to Computational Fluid Dynamics: The Finite Volume Method|url=https://books.google.com/books?id=RvBZ-UMpGzIC|date=1 January 2007|publisher=Pearson Education Limited|isbn=978-0-13-127498-3}}&lt;/ref&gt;
:&lt;math&gt; \frac{\sum |a_{nb}|}{|a'_{p}|} \begin{cases}
    \leq 1, &amp; \text{at all nodes}\\
    &lt;1, &amp; \text{at one node at least}
  \end{cases} &lt;/math&gt;
Here {{math|&lt;var&gt;a'&lt;sub&gt;p&lt;/sub&gt;&lt;/var&gt;}} is the net coefficient of a random central node ''P'' and the summation in the numerator is taken over all the neighbouring nodes. For a one, two and three-dimensional problem there will be two (east &amp; west), four (east, west, south &amp; north), and six (east, west, south north, top &amp; bottom) neighbours for each node, respectively.

==Comments==
* This is a sufficient condition, not a necessary one. This means that we can get convergence, even if, at times, we violate the criterion.&lt;ref name="Patankar1980"&gt;{{cite book|author=Suhas Patankar|title=Numerical Heat Transfer and Fluid Flow|url=https://books.google.com/books?id=5JMYZMX3OVcC&amp;pg=PA64|date=1 January 1980|publisher=CRC Press|isbn=978-0-89116-522-4|pages=64–}}&lt;/ref&gt;
* The satisfaction of this criterion ensures that the equations will be converged by at least one iterative method.&lt;ref name="Patankar1980"/&gt;

==Gauss–Seidel method==
If Scarborough criterion is not satisfied then [[Gauss–Seidel method|Gauss–Seidel method iterative procedure]] is not guaranteed to converge a solution. This criterion is a sufficient condition,&lt;ref name="Patankar1980"/&gt; not a necessary one. If this criterion is satisfied then it means equation will be converged by at least one [[iterative method]]. The Scarborough criterion is used as a sufficient condition for convergent iterative method.  The [[finite volume method]] uses this criterion for obtaining a convergent solution and implementing [[boundary condition]]s.

==Diagonal dominance==
If the differencing scheme produces coefficients that satisfy the above criterion the resulting matrix of coefficients is [[diagonally dominant]].&lt;ref name="Minkowycz1988"&gt;{{cite book|author=W. J. Minkowycz|title=Handbook of Numerical Heat Transfer|url=https://books.google.com/books?id=0AUHXswbSbYC|date=28 March 1988|publisher=Wiley|isbn=978-0-471-83093-1}}&lt;/ref&gt; To achieve diagonal dominance we need large values of net coefficient so the linearisation practice of source terms should ensure that ''S''&lt;sub&gt;''P''&lt;/sub&gt; is always negative. If this is the case –''S''&lt;sub&gt;''P''&lt;/sub&gt; is always positive and adds to ''a''&lt;sub&gt;''P''&lt;/sub&gt;. Diagonal dominance is a desirable feature for satisfying the [[bounded poset|boundedness]] criterion. This states that in the absence of sources the internal nodal values of the property ''ф'' should be bounded by its boundary values. Hence in a steady state conduction problem without sources and with boundary temperatures of 500&amp;nbsp;°C and 200&amp;nbsp;°C all interior values of ''T'' should be less than 500&amp;nbsp;°C and greater than 200&amp;nbsp;°C.&lt;ref name="Pearson Education Limited"/&gt;

==See also==
* [[Computational fluid dynamics]]
* [[Linear equation]]

==References==
{{reflist}}

==External links ==
* [https://web.archive.org/web/20120303230200/http://nptel.iitm.ac.in/courses/112105045/  Introduction to Computational Fluid Dynamics and Principles of Conservation - video lecture]
* [https://engineering.purdue.edu/ME608/webpage/l5.pdf  Overview of Numerical Methods]
* [http://web.iitd.ac.in/~prabal/BC-FVM-lecturenotes-9-10.pdf Implementation of BC in FVM]

[[Category:Computational fluid dynamics]]
[[Category:Numerical analysis]]
[[Category:Applied mathematics]]
[[Category:Functional analysis]]
[[Category:Convergence (mathematics)]]</text>
      <sha1>bhvj27ohj5ct050srxsda0a3crmcxc2</sha1>
    </revision>
  </page>
  <page>
    <title>Shape theory (mathematics)</title>
    <ns>0</ns>
    <id>18767352</id>
    <revision>
      <id>829058358</id>
      <parentid>829047086</parentid>
      <timestamp>2018-03-06T11:12:03Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Clarify}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4548">'''Shape theory''' is a branch of [[topology]], which provides a more global view of the topological spaces than [[homotopy theory]]. The two coincide on compacta dominated homotopically by finite polyhedra. Shape theory associates with the Čech homology theory while homotopy theory associates with the singular homology theory.

==Background==

Shape theory was reinvented, further developed and promoted by the Polish mathematician [[Karol Borsuk]] in 1968. Actually, the name ''shape theory'' was coined by Borsuk.

===Warsaw Circle===

Borsuk lived and worked in [[Warsaw]], hence the name of one of the fundamental examples of the area, the Warsaw circle. This is a compact subset of the plane produced by "closing up" a [[topologist's sine curve]] with an arc.
[[File:Warsaw Circle.png|thumb|The Warsaw Circle.]]  It has [[homotopy group]]s [[group isomorphism|isomorphic]] to those of a point, but is not [[homotopy equivalence|homotopy equivalent]] to a point—instead, the Warsaw circle is shape-equivalent to a circle (one dimensional sphere). [[Whitehead theorem|Whitehead's theorem]] does not apply to Warsaw circle because it is not a CW complex.

==Development==

Borsuk's shape theory was generalized onto arbitrary (non-metric) compact spaces, and even onto general categories, by Włodzimierz Holsztyński in year 1968/1969, and published in Fund. Math. '''70''' , 157-168, y.1971 (see Jean-Marc Cordier, Tim Porter, (1989) below). This was done in a ''continuous style'', characteristic for the Čech homology rendered by [[Samuel Eilenberg]] and Norman Steenrod in their monograph ''Foundations of Algebraic Topology''. Due to the circumstance{{Clarify|date=March 2018}}, Holsztyński's paper was hardly noticed, and instead a great popularity in the field was gained by a much less advanced (more naive) paper by [[Sibe Mardešić]] and Jack Segal, which was published a little later, Fund. Math. '''72''', 61-68, y.1971. Further developments are reflected by the references below, and by their contents.

For some purposes, like dynamical systems, more sophisticated invariants were developed under the name '''strong shape'''. Generalizations to [[noncommutative geometry]], e.g. the shape theory for [[operator algebra]]s have been found.

==References==
*{{cite journal | first = Sibe | last = Mardešić | title = Thirty years of shape theory | url = http://hrcak.srce.hr/file/2848 | format = [[PDF]] | journal = Mathematical Communications | volume = 2 | year = 1997 | pages = 1–12}}
*{{nlab|id=shape%20theory|title=shape theory}}
* Jean-Marc Cordier, Tim Porter, (1989), Shape Theory: Categorical Methods of Approximation, Mathematics and its Applications, Ellis Horwood. Reprinted Dover (2008)
* A. Deleanu and P.J. Hilton, On the categorical shape of a functor, Fund. Math. 97 (1977) 157 - 176.
* A. Deleanu, P.J. Hilton, Borsuk's shape and Grothendieck categories of pro-objects, Math. Proc. Camb. Phil. Soc. 79 (1976) 473-482.
* Sibe Mardešić, Jack Segal, Shapes of compacta and ANR-systems, Fund. Math. 72 (1971) 41-59,
* K. Borsuk, Concerning homotopy properties of compacta, Fund Math. 62 (1968) 223-254
* K. Borsuk, Theory of Shape, Monografie Matematyczne Tom 59,Warszawa 1975.
* D.A. Edwards and H. M. Hastings, [http://projecteuclid.org/DPubS?verb=Display&amp;version=1.0&amp;service=UI&amp;handle=euclid.rmjm/1250128825&amp;page=record Čech Theory: its Past, Present, and Future], Rocky Mountain Journal of Mathematics, Volume 10, Number 3, Summer 1980
* D.A. Edwards and H. M. Hastings, (1976), [http://www.math.uga.edu/%7Edavide/Cech_and_Steenrod_Homotopy_Theories_with_Applications_to_Geometric_Topology.pdf Čech and Steenrod homotopy theories with applications to geometric topology], Lecture Notes in Maths. 542, Springer-Verlag.
* Tim Porter, Čech homotopy I, II, Jour. London Math. Soc., 1, 6, 1973, pp.&amp;nbsp;429–436; 2, 6, 1973, pp.&amp;nbsp;667–675.
* J.T. Lisica, S. Mardešić, Coherent prohomotopy and strong shape theory, Glasnik Matematički 19(39) (1984) 335–399.
* Michael Batanin, Categorical strong shape theory, Cahiers Topologie Géom. Différentielle Catég. 38 (1997), no. 1, 3–66, [http://www.numdam.org/numdam-bin/fitem?id=CTGDC_1997__38_1_3_0 numdam]
* Marius Dādārlat, Shape theory and asymptotic morphisms for C*-algebras, Duke Math. J., 73(3):687-711, 1994.
* Marius Dādārlat, Terry A. Loring, Deformations of topological spaces predicted by E-theory, In Algebraic methods in operator theory, p.&amp;nbsp;316-327. Birkhäuser 1994.

[[Category:Topology]]
[[Category:Homotopy theory]]</text>
      <sha1>pj2hwkpjekrutybdudipclphhglnsle</sha1>
    </revision>
  </page>
  <page>
    <title>Sphere–cylinder intersection</title>
    <ns>0</ns>
    <id>32364281</id>
    <revision>
      <id>843538541</id>
      <parentid>624814440</parentid>
      <timestamp>2018-05-29T20:01:10Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Category:Spherical geometry]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4277">{{unreferenced|date=July 2011}}
In the theory of [[analytic geometry]] for real three-dimensional space, the intersection between a [[sphere]] and a [[cylinder (geometry)|cylinder]] can be a [[circle]], a [[point (geometry)|point]], the [[empty set]], or a special type of curve.

For the analysis of this situation, assume ([[without loss of generality]]) that the axis of the cylinder coincides with the ''z''-axis; points on the cylinder (with radius &lt;math&gt;r&lt;/math&gt;) satisfy

:&lt;math&gt;x^2 + y^2 = r^2.&lt;/math&gt;

We also assume that the sphere, with radius &lt;math&gt;R&lt;/math&gt; is centered at a point on the positive x-axis, at point &lt;math&gt;(a, 0, 0)&lt;/math&gt;. Its points satisfy

:&lt;math&gt;(x-a)^2 + y^2 + z^2 = R^2.&lt;/math&gt;

The intersection is the collection of points satisfying both equations.

== Trivial cases ==

=== Sphere lies entirely within cylinder ===
If &lt;math&gt;a+R &lt; r&lt;/math&gt;, the sphere lies entirely in the interior of the cylinder. The intersection is the empty set.

=== Sphere touches cylinder in one point ===
If the sphere is smaller than the cylinder (&lt;math&gt;R &lt; r&lt;/math&gt;) and &lt;math&gt;a+R = r&lt;/math&gt;, the sphere lies in the interior of
the cylinder except for one point. The intersection is the single point &lt;math&gt;(r, 0, 0)&lt;/math&gt;.

=== Sphere centered on cylinder axis ===
If the center of the sphere lies on the axis of the cylinder, &lt;math&gt;a = 0&lt;/math&gt;. In that case, the intersection consists of
two circles of radius &lt;math&gt;r&lt;/math&gt;. These circles lie in the planes
:&lt;math&gt;z = \pm\sqrt{R^2 - r^2};&lt;/math&gt;

If &lt;math&gt;r = R&lt;/math&gt;, the intersection is a single circle in the plane &lt;math&gt;z = 0&lt;/math&gt;.

== Non-trivial cases ==
Subtracting the two equations given above gives

:&lt;math&gt;z^2 + (r^2 - R^2 + a^2) = 2ax.&lt;/math&gt;

Since &lt;math&gt;x&lt;/math&gt; is a quadratic function of &lt;math&gt;z&lt;/math&gt;, the projection of the intersection onto the xz-plane is the section of an orthogonal parabola; it is only a section due to the fact that &lt;math&gt;-r &lt; x &lt; r&lt;/math&gt;.
The vertex of the parabola lies at point &lt;math&gt;(-b, 0, 0)&lt;/math&gt;, where

:&lt;math&gt;b = \frac{R^2 - r^2 - a^2}{2a}.&lt;/math&gt;

=== Intersection consists of two closed curves ===
If &lt;math&gt;R &gt; r + a&lt;/math&gt;, the condition &lt;math&gt;x &lt; r&lt;/math&gt; cuts the parabola into two segments.  In this case, the intersection of sphere and cylinder consists of two closed curves, which are mirror images of each other.
Their projection in the ''xy''-plane are circles of radius &lt;math&gt;r&lt;/math&gt;.

Each part of the intersection can be parametrized by an angle &lt;math&gt;\phi&lt;/math&gt;:

:&lt;math&gt;(x,y,z) = \left(r\cos\phi,r\sin\phi,\pm\sqrt{2a(b + r\cos\phi)}\right).&lt;/math&gt;

The curves contain the following extreme points:

:&lt;math&gt;\left(-r, 0, \pm\sqrt{R^2 - (r+a)^2}\right);\quad
       \left(0, \pm r, \pm\sqrt{R^2 - (r-a)(r+a)}\right);\quad
       \left(+r, 0, \pm\sqrt{R^2 - (r-a)^2}\right).&lt;/math&gt;

=== Intersection is a single closed curve ===
If &lt;math&gt;R &lt; r + a&lt;/math&gt;, the intersection of sphere and cylinder consists of a single closed curve.
It can be described by the same parameter equation as in the previous section, but the angle &lt;math&gt;\phi&lt;/math&gt;
must be restricted to &lt;math&gt;-\phi_0 &lt; \phi &lt; +\phi_0&lt;/math&gt;, where &lt;math&gt;\cos\phi_0 = -b/r&lt;/math&gt;.

The curve contains the following extreme points:
:&lt;math&gt;\left(-b, \pm\sqrt{r^2-b^2}, 0\right);\quad 
       \left(0, \pm r, \pm\sqrt{R^2 - (r-a)(r+a)}\right);\quad
       \left(+r, 0, \pm\sqrt{R^2 - (r-a)^2}\right).&lt;/math&gt;

=== Limiting case ===
[[Image:Viviani curve.png|thumb|right|200px|Viviani's curve as intersection of a sphere and a cylinder]]
In the case &lt;math&gt;R = r + a&lt;/math&gt;, the cylinder and sphere are tangential to each other at point &lt;math&gt;(r, 0, 0)&lt;/math&gt;.
The intersection resembles a figure eight: it is a closed curve which intersects itself. The above parametrization becomes

:&lt;math&gt;(x,y,z) = \left(r\cos\phi,r\sin\phi,2\sqrt{ar}\cos\frac{\phi}{2}\right),&lt;/math&gt;

where &lt;math&gt;\phi&lt;/math&gt; now goes through two full revolutions.

In the special case &lt;math&gt;a = r, R = 2r&lt;/math&gt;, the intersection is known as [[Viviani's curve]]. Its parameter representation is

:&lt;math&gt;(x,y,z) = \left(r\cos\phi,r\sin\phi,R\cos\frac\phi2\right).&lt;/math&gt;

== See also ==
*[[Viviani's curve]]

{{DEFAULTSORT:Sphere-cylinder intersection}}
[[Category:Analytic geometry]]
[[Category:Spherical geometry]]</text>
      <sha1>f68wbzmh8idim7uwb98cm635w8pzibx</sha1>
    </revision>
  </page>
  <page>
    <title>Sudoku</title>
    <ns>0</ns>
    <id>1365807</id>
    <revision>
      <id>870378025</id>
      <parentid>869779447</parentid>
      <timestamp>2018-11-24T11:24:05Z</timestamp>
      <contributor>
        <username>Neils51</username>
        <id>16416757</id>
      </contributor>
      <minor/>
      <comment>/* Mathematics of Sudoku */ grammar/usage - fewest=' lowest number of ' - ' number of ' is redundant</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="38086">{{Use mdy dates|date=August 2013}}
{{Multiple image
| direction = vertical
| align = right
| image1 = Sudoku Puzzle by L2G-20050714 standardized layout.svg
| image2 = Sudoku Puzzle by L2G-20050714 solution standardized layout.svg
| width = 250
| caption1 = A typical Sudoku puzzle
| caption2 = And its solution
| alt1 = A typical Sudoku puzzle, with nine rows and nine columns that intersect at square spaces. Some of the cells are filled with a number; others are blank cells to be solved.
| alt2 = The previous puzzle, showing its solution.
}}
{{nihongo|'''Sudoku'''|数独|sūdoku|digit-single|}} ({{IPAc-en|s|uː|ˈ|d|oʊ|k|uː}}, {{IPAc-en|-|ˈ|d|ɒ|k|-}}, {{IPAc-en|s|ə|-}}, originally called '''Number Place''')&lt;ref name="time magazine"&gt;{{cite web |last=Grossman |first=Lev |title=The Answer Men |url= http://www.time.com/time/magazine/article/0,9171,2137423,00.html |newspaper=[[Time (magazine)|Time]] |location= New York |accessdate=March 4, 2013 |date=March 11, 2013}}{{registration required}}&lt;/ref&gt; is a [[logic]]-based,&lt;ref&gt;{{cite news |last=Arnoldy |first=Ben |title=Sudoku Strategies|work=The Home Forum |publisher=''The Christian Science Monitor''}}&lt;/ref&gt;&lt;ref&gt;{{cite news|last=Schaschek|first=Sarah|title=Sudoku champ's surprise victory |date=March 22, 2006 |newspaper=The Prague Post |url= http://www.praguepost.com/P03/2006/Art/0323/news5.php |accessdate=February 18, 2009 |archiveurl= https://web.archive.org/web/20060813145953/http://www.praguepost.com/P03/2006/Art/0323/news5.php |archivedate = August 13, 2006}}&lt;/ref&gt; [[combinatorics|combinatorial]]&lt;ref&gt;{{cite book |last1=Lawler|first1=E. L. |authorlink1=Eugene Lawler|title=The Traveling Salesman Problem: A Guided Tour of Combinatorial Optimization|location=West Sussex|publisher=John Wiley &amp; Sons|year=1985|isbn=0-471-90413-9}}&lt;/ref&gt; number-placement [[puzzle]]. The objective is to fill a 9×9 grid with digits so that each column, each row, and each of the nine 3×3 subgrids that compose the grid (also called "boxes", "blocks", or "regions") contains all of the digits from 1 to 9. The puzzle setter provides a partially completed grid, which for a well-posed puzzle has a single solution.

Completed games are always a type of [[Latin square]] with an additional constraint on the contents of individual regions. For example, the same single integer may not appear twice in the same row, column, or any of the nine 3×3 subregions of the 9x9 playing board.

French newspapers featured variations of the puzzles in the 19th century, and the puzzle has appeared since 1979 in [[Puzzle book|puzzle books]] under the name Number Place.&lt;ref name=Smith /&gt; However, the modern Sudoku only started to become mainstream in 1986 by the Japanese puzzle company [[Nikoli (publisher)|Nikoli]], under the name Sudoku, meaning "single number".&lt;ref&gt;{{cite journal |title=Unwed Numbers |first=Brian |last=Hayes |journal=American Scientist |volume=94 |issue=1 |year=2006 |pages=12–15 |doi=10.1511/2006.57.3475}}&lt;/ref&gt; It first appeared in a US newspaper and then ''[[The Times]]'' (London) in 2004, from the efforts of [[Wayne Gould]], who devised a computer program to rapidly produce distinct puzzles.

== History ==
[[File:Sudoku.jpg|thumb|upright|From ''La France'' newspaper, July 6, 1895: The puzzle instructions read, "Use the numbers 1 to 9 each nine times to complete the grid in such a way that the horizontal, vertical, and two main diagonal lines all add up to the same total."]]

===Predecessors===
Number puzzles appeared in newspapers in the late 19th century, when French puzzle setters began experimenting with removing numbers from [[magic squares]]. ''[[Le Siècle]]'', a Paris daily, published a partially completed 9×9 magic square with 3×3 subsquares on November 19, 1892.&lt;ref name="Le_Siècle_185672"&gt;{{cite journal
|last=Boyer
|first=Christian
|date=May 2006
|title=Supplément de l'article "Les ancêtres français du sudoku"
|journal=Pour la Science
|pages=1–6
|url=http://cboyer.club.fr/multimagie/SupplAncetresSudoku.pdf
|format=PDF
|accessdate=August 3, 2009 |archiveurl=https://web.archive.org/web/20061210103525/http://cboyer.club.fr/multimagie/SupplAncetresSudoku.pdf |archivedate=December 10, 2006}}&lt;/ref&gt; It was not a Sudoku because it contained double-digit numbers and required arithmetic rather than logic to solve, but it shared key characteristics: each row, column and subsquare added up to the same number.

On July 6, 1895, ''Le Siècle''{{'s}} rival, ''[[La France (French newspaper)|La France]]'', refined the puzzle so that it was almost a modern Sudoku. It simplified the 9×9 magic square puzzle so that each row, column, and [[broken diagonal]]s contained only the numbers 1–9, but did not mark the subsquares. Although they are unmarked, each 3×3 subsquare does indeed comprise the numbers 1–9 and the additional constraint on the broken diagonals leads to only one solution.&lt;ref&gt;{{cite web
|last=Boyer
|first=Christian
|title=Sudoku's French ancestors
|url=http://cboyer.club.fr/multimagie//English/SudokuAncestors.htm
|year=2007
|publisher=(personal webpage)
|accessdate=August 3, 2009 |archiveurl=https://web.archive.org/web/20071010081626/http://cboyer.club.fr/multimagie/English/SudokuAncestors.htm |archivedate=October 10, 2007}}&lt;/ref&gt;

These weekly puzzles were a feature of French newspapers such as ''L'Echo de Paris'' for about a decade, but disappeared about the time of [[World War I]].&lt;ref name=L&gt;{{cite news |first=Jack |last=Malvern |title=Les fiendish French beat us to Su Doku |url=http://www.timesonline.co.uk/article/0,,2-2208881,00.html |work=Times Online |date=June 3, 2006 |accessdate=September 16, 2006 |location=London}}&lt;/ref&gt;

===Modern Sudoku===
The modern Sudoku was most likely designed anonymously by [[Howard Garns]], a 74-year-old retired architect and freelance puzzle constructor from [[Connersville, Indiana]], and first published in 1979 by [[Dell Magazines]] as Number Place (the earliest known examples of modern Sudoku).&lt;ref name="time magazine"/&gt; Garns's name was always present on the list of contributors in issues of ''Dell Pencil Puzzles and Word Games'' that included Number Place, and was always absent from issues that did not.&lt;ref name="Garns"&gt;{{cite web |url=http://www.mathpuzzle.com/MAA/41-Sudoku%20Variations/mathgames_09_05_05.html |title=Ed Pegg Jr.'s Math Games: Sudoku Variations |accessdate=October 3, 2006 |last=Pegg |first=Ed, Jr. |date=September 15, 2005 |work=MAA Online |publisher=[[The Mathematical Association of America]]}}&lt;/ref&gt; He died in 1989 before getting a chance to see his creation as a worldwide phenomenon.&lt;ref name="Garns"/&gt; Whether or not Garns was familiar with any of the French newspapers listed above is unclear.

The puzzle was introduced in Japan by Nikoli in the paper ''Monthly Nikolist'' in April 1984&lt;ref name="Garns"/&gt; as {{nihongo|''Sūji wa dokushin ni kagiru''|数字は独身に限る|}}, which also can be translated as "the digits must be single" or "the digits are limited to one occurrence" (In Japanese, ''dokushin'' means an "unmarried person"). At a later date, the name was abbreviated to ''Sudoku'' (数独) by {{nihongo|[[Maki Kaji]]|鍜治 真起|Kaji Maki}}, taking only the first [[kanji]] of compound words to form a shorter version.&lt;ref name="Garns"/&gt; "Sudoku" is a registered trademark in Japan&lt;ref name="jp_trademark_5056856"&gt;{{cite web |url=https://www.j-platpat.inpit.go.jp/web/TR/JPT_5056856/F9A8AC1B402D5E9F6E7B4E7246A6CE85 |title=Reg. No. 5056856 |work=Japanese Trademark 5056856 |accessdate=October 3, 2018 |publisher=Japan Platform for Trademark Information}}&lt;/ref&gt; and the puzzle is generally referred to as {{nihongo|Number Place|ナンバープレース|Nanbāpurēsu}} or, more informally, a [[portmanteau]] of the two words, {{nihongo|Num(ber) Pla(ce)|ナンプレ|''Nanpure''}}. In 1986, Nikoli introduced two innovations: the number of givens was restricted to no more than 32, and puzzles became "symmetrical" (meaning the givens were distributed in [[Rotational symmetry|rotationally symmetric cells]]). It is now published in mainstream Japanese periodicals, such as the ''[[Asahi Shimbun]]''.

=== Spread outside Japan ===

In 1997, Hong Kong judge [[Wayne Gould]] saw a partly completed puzzle in a Japanese bookshop. Over six years, he developed a computer program to produce unique puzzles rapidly.&lt;ref name=Smith /&gt; Knowing that British newspapers have a long history of publishing [[crossword]]s and other puzzles, he promoted Sudoku to ''[[The Times]]'' in Britain, which launched it on November 12, 2004 (calling it Su Doku). The first letter to ''The Times'' regarding Su Doku was published the following day on November 13 from Ian Payn of [[Brentford]], complaining that the puzzle had caused him to miss his stop on the [[London Underground|tube]].&lt;ref&gt;[http://www.timesonline.co.uk/tol/comment/letters/article390381.ece "Letters"]. Timesonline.co.uk. November 14, 2004. {{paywall|date=August 2013}}&lt;/ref&gt; Sudoku puzzles rapidly spread to other newspapers as a regular feature.&lt;ref name=Smith&gt;{{cite news|url=https://www.theguardian.com/media/2005/may/15/pressandpublishing.usnews |title=So you thought Sudoku came from the Land of the Rising Sun ...|first=David |last=Smith |newspaper=The Observer |date=May 15, 2005 |accessdate=June 13, 2008 |quote=The puzzle gripping the nation actually began at a small New York magazine}}&lt;/ref&gt;&lt;ref&gt;{{cite news |last=Devlin |first=Keith |title=The Numbers Game (book review of Taking Sudoku Seriously by Jason Rosenhouse et al.) |newspaper=[[The Wall Street Journal]] |location=Weekend Edition |page=C5 |date=January 28–29, 2012}}&lt;/ref&gt; 

The rapid rise of Sudoku in Britain from relative obscurity to a front-page feature in national newspapers attracted commentary in the media and parody (such as when ''The Guardian''{{'s}} ''G2'' section advertised itself as the first newspaper supplement with a Sudoku grid on every page).&lt;ref name=G2&gt;{{cite news |title=G2, home of the discerning Sudoku addict |url=https://www.theguardian.com/g2/story/0,,1482817,00.html |work=The Guardian |date=May 13, 2005 |accessdate=September 16, 2006 |location=London}}&lt;/ref&gt; Recognizing the different psychological appeals of easy and difficult puzzles, ''The Times'' introduced both, side by side, on June 20, 2005. From July 2005, [[Channel 4]] included a daily Sudoku game in their [[teletext]] service. On August 2, the BBC's program guide ''[[Radio Times]]'' featured a weekly [[Super Sudoku]] with a 16×16 grid.

In the United States, the first newspaper to publish a Sudoku puzzle by Wayne Gould was ''[[The Conway Daily Sun]]'' (New Hampshire), in 2004.&lt;ref&gt;{{cite news|url=https://www.nytimes.com/2007/03/21/business/worldbusiness/21sudoku.html?pagewanted=2&amp;_r=1&amp;sq&amp;st=cse%22Conway%20Daily%20Sun&amp;scp=1%22%202004%20gould |title=Correction attached to "Inside Japan's Puzzle Palace" |publisher=The New York Times |date=March 21, 2007}}&lt;/ref&gt;

[[File:SudokuLive2.jpg|thumb|The world's first live TV Sudoku show, July 1, 2005, ''[[Sky One]]'']]

The world's first live TV Sudoku show, ''Sudoku Live'', was a [[puzzle contest]] first broadcast on July 1, 2005, on [[Sky One]]. It was presented by [[Carol Vorderman]]. Nine teams of nine players (with one celebrity in each team) representing geographical regions competed to solve a puzzle. Each player had a hand-held device for entering numbers corresponding to answers for four cells. Phil Kollin of Winchelsea, England, was the series grand prize winner, taking home over £23,000 over a series of games. The audience at home was in a separate interactive competition, which was won by Hannah Withey of Cheshire.

Later in 2005, the [[BBC]] launched ''[[SUDO-Q]]'', a [[game show]] that combined Sudoku with general knowledge. However, it used only 4×4 and 6×6 puzzles. Four seasons were produced before the show ended in 2007.

In 2006, a Sudoku website published songwriter Peter Levy's Sudoku tribute song,&lt;ref&gt;{{cite news |url=http://www.sudoku.org.uk/news.htm |title=Sudoku the song, by Peter Levy |date=August 17, 2006 |work=Sudoku.org.uk |accessdate=October 5, 2008}}&lt;/ref&gt; but quickly had to take down the [[MP3 file]] due to heavy traffic. British and Australian radio picked up the song, which is to feature in a British-made Sudoku documentary. The Japanese Embassy also nominated the song for an award, with Levy doing talks with Sony in Japan to release the song as a single.&lt;ref&gt;{{cite news |url=http://www.heraldsun.com.au/news/hit-song-has-the-numbers/story-e6frf7jo-1111112155196 |title=Hit Song Has the Numbers |date=August 17, 2006 |work=[[The Herald Sun]] |accessdate=October 5, 2008}}&lt;/ref&gt;

Sudoku software is very popular on PCs, websites, and mobile phones. It comes with many distributions of [[Linux]]. Software has also been released on video game consoles, such as the [[Nintendo DS]], [[PlayStation Portable]], the [[Game Boy Advance]], Xbox Live Arcade, the [[Nook]] e-book reader, Kindle Fire tablet, several [[iPod]] models, and the [[iPhone]]. Many [[Nokia]] phones also had Sudoku. In fact, just two weeks after [[Apple Inc.]] debuted the online [[App Store (iOS)|App Store]] within its [[iTunes Store]] on July 11, 2008, nearly 30 different Sudoku games were already in it, created by various software developers, specifically for the iPhone and iPod Touch. One of the most popular video games featuring Sudoku is ''[[Brain Age: Train Your Brain in Minutes a Day!]]''. Critically and commercially well-received, it generated particular praise for its Sudoku implementation&lt;ref&gt;{{cite web|url=http://www.gamerankings.com/htmlpages2/931667.asp |title=Brain Age: Train Your Brain in Minutes a Day! |website=Gamerankings.com}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.gamespot.com/ds/puzzle/brainagetrainyourbraininminutesaday/review.html |title=Brain Age: ... Review" |website=Gamespot.com}}&lt;/ref&gt;&lt;ref&gt;[http://ds.ign.com/articles/702/702057p1.html "Brain Age: ... Review"]. IGN.com.&lt;/ref&gt; and sold more than 8 million copies worldwide.&lt;ref&gt;{{cite web |url=http://www.gamespot.com/news/6160557.html |title=Nintendo posts $456.6 million profit |last=Thorsen |first=Tor |date=October 26, 2006 |publisher=[[GameSpot]] |accessdate=March 29, 2013}}&lt;/ref&gt; Due to its popularity, Nintendo made a second ''Brain Age'' game titled ''Brain Age&lt;sup&gt;2&lt;/sup&gt;'', which has over 100 new Sudoku puzzles and other activities.

In June 2008, an Australian drugs-related jury trial costing over [[Australian dollar|A$]] 1 million was aborted when it was discovered that five of the twelve jurors had been playing Sudoku instead of listening to evidence.&lt;ref&gt;{{cite news |url=http://www.smh.com.au/news/national/jurors-get-1-million-trial-aborted/2008/06/10/1212863636766.html |title=The game's up: jurors playing Sudoku abort trial |last=Knox |first=Malcolm |date=June 11, 2008 |work=[[The Sydney Morning Herald]] |accessdate=June 11, 2008}}&lt;/ref&gt;

== Variants ==
{{Multiple image|direction=vertical|align=right|image1=A nonomino sudoku.svg|image2=A nonomino sudoku solution.svg|width=150|caption1=A ''[[nonomino]]'' or [[Jigsaw puzzle|jigsaw]] Sudoku, as seen in ''[[The Sunday Telegraph]]''|caption2=And its solution (red numbers)|alt1=A Sudoku puzzle grid with many colours, with nine rows and nine columns that intersect at square spaces. Some of the spaces are filled with a digit; others are blank spaces to be solved.|alt2=The previous puzzle, solved with digits in the blanks spaces.}}

=== Variations of grid sizes ===
Although the 9×9 grid with 3×3 regions is by far the most common, many other variations exist. Sample puzzles can be 4×4 grids with 2×2 regions; 5×5 grids with ''[[pentomino]]'' regions have been published under the name Logi-5; the [[World Puzzle Championship]] has featured a 6×6 grid with 2×3 regions and a 7×7 grid with six ''[[heptomino]]'' regions and a disjoint region. Larger grids are also possible. ''The Times'' offers a 12×12-grid "Dodeka Sudoku" with 12 regions of 4×3 squares. Dell Magazines regularly publishes 16×16 "Number Place Challenger" puzzles (using the numbers 1–16 or the letters A-P). Nikoli offers 25×25 "Sudoku the Giant" behemoths. A 100×100-grid puzzle dubbed Sudoku-zilla was published in 2010.&lt;ref&gt;{{cite book |last=Eisenhauer |first=William |title=Sudoku-zilla |year=2010 |publisher=CreateSpace |page=220 |isbn=978-1-4515-1049-2}}&lt;/ref&gt;

==== Mini Sudoku ====

Under the name "Mini Sudoku", a 6×6 variant with 3×2 regions appears in the American newspaper ''[[USA Today]]'' and elsewhere. The object is the same as that of standard Sudoku, but the puzzle only uses the numbers 1 through 6. A similar form, for younger solvers of puzzles, called "The Junior Sudoku", has appeared in some newspapers, such as some editions of ''The Daily Mail''.

=== Imposing additional constraints ===
Another common variant is to add limits on the placement of numbers beyond the usual row, column, and box requirements. Often, the limit takes the form of an extra "dimension"; the most common is to require the numbers in the main diagonals of the grid to also be unique. The aforementioned "Number Place Challenger" puzzles are all of this variant, as are the Sudoku X puzzles in ''[[The Daily Mail]]'', which use 6×6 grids.

=== Killer Sudoku ===
{{Multiple image|direction=horizontal|align=right|image1=Killersudoku color.svg|image2=Killersudoku  color solution.svg|width=150|caption1=A Killer Sudoku puzzle|caption2=And its solution}}
{{Main article|Killer sudoku}}

The Killer Sudoku variant combines elements of Sudoku and [[Kakuro]].

=== Alphabetical Sudoku ===
{{Multiple image|direction=horizontal|align=right|image1=Wordoku puzzle.svg|image2=Wordoku puzzle solution.svg|width=150|caption1=A Wordoku puzzle|caption2=And its solution (red characters)}}

Alphabetical variations have emerged, sometimes called Wordoku; no functional difference exists in the puzzle unless the letters spell something. Some variants, such as in the ''[[TV Guide]]'', include a word reading along a main diagonal, row, or column once solved; determining the word in advance can be viewed as a solving aid. A Wordoku might contain words other than the main word.

"''Quadratum latinum''" is a Sudoku variation with Roman numerals (I, II, III, IV, ..., IX) proposed by ''[[Hebdomada aenigmatum]]'', a monthly magazine of Latin puzzles and crosswords. Like the Wordoku, it presents no functional difference from a normal Sudoku, but adds the visual difficulty of using Roman numerals.

=== Kaodoku ===
{{Multiple image|direction=horizontal|align=right|image1=Kaodoku example.png|image2=Kaodoku example solution.png|width=150|caption1=A Kaodoku puzzle|caption2=And its solution (blue smileys)}}

Kaodokus (顔独) use partially given smiley faces instead of digits. The smileys can have three possible shapes and three possible mouths, for a total of nine unique combinations. In easy puzzles some full smileys may be given, but the harder ones only contain partial cells with either a mouth or a shape. One may, for example, deduce the presence of a square on the intersection of a row with three circles and a column with three triangles, even though the mouth is still undetermined. The concept of kaodoku may be combined with other variations like additional constraints, jigsaw areas, overlapping puzzles, etcetera. The name of the puzzle comes from the Japanese word for face, "kao".

=== Hyper Sudoku ===
{{Multiple image|direction=horizontal|align=right|image1=Oceans Hypersudoku18 Puzzle.svg|image2=Oceans Hypersudoku18 Solution.svg|width=150|caption1=Hypersudoku puzzle|caption2=And its solution|alt1=A Sudoku puzzle grid with four blue quadrants and nine rows and nine columns that intersect at square spaces. Some of the spaces are filled with one number each; others are blank spaces to be solved.|alt2=The previous puzzle, solved with numbers in the blanks spaces.}}

Hyper Sudoku uses the classic 9×9 grid with 3×3 regions, but defines four additional interior 3×3 regions in which the numbers 1–9 must appear exactly once. It was invented by ''Peter Ritmeester'' and first published by him in Dutch Newspaper ''NRC Handelsblad'' in October 2005, and since April 2007 on a daily basis in ''The International New York Times'' (International Herald Tribune). The first time it was called Hyper Sudoku was in ''Will Shortz's Favorite Sudoku Variations'' (February 2006). It is also known as Windoku because with the grid's four interior regions shaded, it resembles a window with glazing bars.&lt;ref&gt;{{cite web|url=http://www.sudoku-space.com/hyper-sudoku/hyper-sudoku.php |publisher=www.sudoku-space.com |title=What is Hyper Sudoku?|language=en|accessdate=August 27, 2017}}&lt;/ref&gt;

=== Twin Sudoku ===
In Twin Sudoku two regular grids share a 3×3 box. This is one of many possible types of [[Glossary of Sudoku#Sudoku variants|overlapping grids]]. The rules for each individual grid are the same as in normal Sudoku, but the digits in the overlapping section are shared by each half. In some compositions neither individual grid can be solved alone – the complete solution is only possible after each individual grid has at least been partially solved.

=== Other variants===
Puzzles constructed from more than two grids are also common. Five 9×9 grids that overlap at the corner regions in the shape of a ''[[quincunx]]'' is known in Japan as ''Gattai'' 5 (five merged) Sudoku. In ''The Times'', ''[[The Age]]'', and ''[[The Sydney Morning Herald]]'', this form of puzzle is known as Samurai SuDoku. ''[[The Baltimore Sun]]'' and the ''[[Toronto Star]]'' publish a puzzle of this variant (titled High Five) in their Sunday edition. Often, no givens are placed in the overlapping regions. Sequential grids, as opposed to overlapping, are also published, with values in specific locations in grids needing to be transferred to others.

[[File:Comparison Sudoku.png|thumb|250px|An example of Greater Than Sudoku]]
A tabletop version of Sudoku can be played with a standard 81-card Set deck (see [[Set game]]). A three-dimensional Sudoku puzzle was published in ''[[The Daily Telegraph]]'' in May 2005. ''The Times'' also publishes a three-dimensional version under the name Tredoku. Also, a Sudoku version of the [[Rubik's Cube]] is named [[Sudoku Cube]].

Many other variants have been developed.&lt;ref&gt;*{{cite book |last=Snyder |first=Thomas |last2=Huang |first2=Wei-Hwa |title=Mutant Sudoku |publisher=Puzzlewright Press |year=2009 |isbn=978-1-402765025}}&lt;/ref&gt;&lt;ref&gt;{{cite book |last=Conceptis |first=Puzzles |title=Amazing Sudoku Variants |publisher=Puzzlewright |year=2013 |isbn=978-1454906520}}&lt;/ref&gt;&lt;ref&gt;{{cite book |last=Murali |first=A V |title=A Collection of Fascinating Games and Puzzles |publisher=CreateSpace Independent Publishing Platform |year=2014 |isbn=978-1500216429}}&lt;/ref&gt; Some are different shapes in the arrangement of overlapping 9×9 grids, such as butterfly, windmill, or flower.&lt;ref name="ja1"&gt;{{cite web |url=http://www.janko.at/Raetsel/Zahlenraetsel.htm |title=Zahlenraetsel |publisher=www.janko.at}}&lt;/ref&gt; Others vary the logic for solving the grid. One of these is "Greater Than Sudoku". In this, a 3×3 grid of the Sudoku is given with 12 symbols of Greater Than (&gt;) or Less Than (&lt;) on the common line of the two adjacent numbers.&lt;ref name="Garns"/&gt; Another variant on the logic of solution is "Clueless Sudoku", in which nine 9×9 Sudoku grids are each placed in a 3×3 array. The center cell in each 3×3 grid of all nine puzzles is left blank and form a tenth Sudoku puzzle without any cell completed; hence, "clueless".&lt;ref name="ja1"/&gt; Examples and other variants can be found in the [[Glossary of Sudoku]].

== Mathematics of Sudoku ==
[[File:Sudoku Puzzle (an automorphic puzzle with 18 clues).svg|thumb|220px|An [[Mathematics of Sudoku#Automorphic Sudokus|automorphic]] Sudoku with 18 clues and two-way diagonal symmetry.]]

{{Main article|Mathematics of Sudoku}}

This section refers to classic Sudoku, disregarding jigsaw, hyper, and other variants.

A completed Sudoku grid is a special type of [[Latin square]] with the additional property of no repeated values in any of the nine blocks (or ''boxes'' of 3×3 cells). The relationship between the two theories is known, after it was proven that a [[First-order logic|first-order]] formula that does not mention blocks is valid for Sudoku if and only if it is valid for Latin squares.&lt;ref&gt;{{cite book |title=The Hidden Logic of Sudoku |first1=Denis |last1=Berthier |publisher=LULU PR |year=2007 |isbn=1-84753-472-4 |page=76   N|url=https://books.google.com/books?id=ME9oJwAACAAJ|quote=p.&amp;nbsp;76.: "''any block-free resolution rule is already valid in the theory of Latin Squares extended to candidates''". Restated more explicitly in the second edition, p.&amp;nbsp;86, as: "a block-free formula is valid for Sudoku if and only if it is valid for Latin squares"}}&lt;/ref&gt;

The general problem of solving Sudoku puzzles on ''n''&lt;sup&gt;2&lt;/sup&gt;×''n''&lt;sup&gt;2&lt;/sup&gt; grids of ''n''×''n'' blocks is known to be [[NP-complete]].&lt;ref&gt;{{cite web|url=http://www-imai.is.s.u-tokyo.ac.jp/~yato/data2/SIGAL87-2.pdf |title=NP complete – Sudoku|language=en|publisher=Imai.is.su-tokyo.ac.jp |accessdate=2013-10-20}}&lt;/ref&gt; Many [[Sudoku solving algorithms|computer algorithms]], such as [[Sudoku solving algorithms#Sudoku brute force|backtracking]] and [[dancing links]] can solve most 9×9 puzzles efficiently, but [[combinatorial explosion]] occurs as ''n'' increases, creating limits to the properties of Sudokus that can be constructed, analyzed, and solved as ''n'' increases. A Sudoku puzzle can be expressed as a [[graph coloring]] problem.&lt;ref name="Lewis2015"&gt;Lewis, R. ''A Guide to Graph Colouring: Algorithms and Applications''. Springer International Publishers, 2015.&lt;/ref&gt; The aim is to construct a 9-coloring of a particular graph, given a partial 9-coloring.

The fewest clues possible for a proper Sudoku is 17 (proven January 2012, and confirmed September 2013).&lt;ref&gt;G. McGuire, B. Tugemann, G. Civario. [https://arxiv.org/abs/1201.0749 "There is no 16-Clue Sudoku: Solving the Sudoku Minimum Number of Clues Problem"]. Arxiv.org.&lt;/ref&gt;&lt;ref&gt;H.H. Lin, I-C. Wu. [http://sudoku.nctu.edu.tw "No 16-clue Sudoku puzzles by sudoku@vtaiwan project"], September, 2013.&lt;/ref&gt; Over 49,000 Sudokus with 17 clues have been found, many by Japanese enthusiasts.&lt;ref name=seventeen3&gt;{{cite web |url=http://www.csse.uwa.edu.au/~gordon/sudokumin.php |title=Minimum Sudoku |accessdate=February 28, 2012 |last= Royle |first=Gordon}}&lt;/ref&gt;&lt;ref name=seventeen1&gt;{{cite web |url=http://www2.ic-net.or.jp/~takaken/auto/guest/bbs46.html |script-title=ja:プログラミングパズルに関心のある人は雑談しましょう |accessdate=September 16, 2006 |work=プログラミングパズル雑談コーナー / Programming Puzzle Idle Talk Corner |language=Japanese}}&lt;/ref&gt; Sudokus with 18 clues and rotational symmetry have been found, and there is at least one Sudoku that has 18 clues, exhibits two-way diagonal symmetry and is [[Mathematics of Sudoku#Automorphic Sudokus|automorphic]]. The maximum number of clues that can be provided while still not rendering a unique solution is four short of a full grid (77); if two instances of two numbers each are missing from cells that occupy the corners of an orthogonal rectangle, and exactly two of these cells are within one region, the numbers can be assigned two ways. Since this applies to Latin squares in general, most variants of Sudoku have the same maximum.

The number of classic 9×9 Sudoku solution grids is 6,670,903,752,021,072,936,960 {{OEIS|id=A107739}}, or around {{val|6.67|e=21}}. This is roughly {{val|1.2|e=-6}} times the number of 9×9 Latin squares.&lt;ref name=Jarvis_2006-07-31&gt;{{cite web |url=http://www.afjarvis.staff.shef.ac.uk/sudoku/ |title=Sudoku enumeration problems |accessdate=September 16, 2006 |last=Jarvis |first=Frazer |date=July 31, 2006 |work=Frazer Jarvis's home page}} Detailed calculation of this figure.&lt;/ref&gt; Various other grid sizes have also been enumerated—see the [[Mathematics of Sudoku#Enumeration results|main article]] for details. The number of essentially different solutions, when [[symmetries]] such as rotation, reflection, permutation, and relabelling are taken into account, was shown to be just 5,472,730,538&lt;ref name=Jarvis_and_Russell&gt;{{cite web |url=http://www.afjarvis.staff.shef.ac.uk/sudoku/sudgroup.html |title=There are 5472730538 essentially different Sudoku grids ... and the Sudoku symmetry group |accessdate= September 16, 2006 |last=Jarvis |first=Frazer |first2=Ed |last2=Russell |date=September 7, 2005 |work=Frazer Jarvis's home page}}&lt;/ref&gt; {{OEIS|id=A109741}}.

Unlike the number of complete Sudoku grids, the number of minimal 9×9 Sudoku puzzles is not precisely known. (A minimal puzzle is one in which no clue can be deleted without losing uniqueness of the solution.) However, statistical techniques combined with a puzzle generator&lt;ref name="UnbiasedStat"&gt;{{cite book | first = Denis | last = Berthier | url = http://hal.archives-ouvertes.fr/hal-00641955 |date=December 4, 2009 |title=Innovations in Computing Sciences and Software Engineering |editor= Elleithy, Khaled |pages=165–70 |chapter=Unbiased Statistics of a CSP – A Controlled-Bias Generator |accessdate = December 4, 2009 }}&lt;/ref&gt; show that about (with 0.065% relative error) 3.10&amp;nbsp;×&amp;nbsp;10&lt;sup&gt;37&lt;/sup&gt; minimal puzzles and 2.55&amp;nbsp;×&amp;nbsp;10&lt;sup&gt;25&lt;/sup&gt; nonessentially equivalent minimal puzzles exist.

== Competitions ==
[[File:Sudokujf.JPG|thumb|right|175px|Sudoku competition at [[SM City Baliuag]]]]

*The first [[World Sudoku Championship]] was held in [[Lucca]], [[Italy]], from March 10 to 12, 2006. The winner was Jana Tylová of the [[Czech Republic]].&lt;ref name=first_world_championship&gt;{{cite news |title=Sudoku title for Czech accountant |url=http://news.bbc.co.uk/1/hi/world/europe/4797540.stm |work=BBC News |date=March 11, 2006 |accessdate=September 11, 2006}}&lt;/ref&gt; The competition included numerous variants.&lt;ref&gt;{{cite news |title=World Sudoku Championship 2006 Instructions Booklet |url=http://news.bbc.co.uk/2/shared/bsp/hi/pdfs/10_03_06_sudoku.pdf |format=PDF |work=BBC News |accessdate=May 24, 2010}}&lt;/ref&gt;
*The second World Sudoku Championship was held in [[Prague]] from March 28 to April 1, 2007.&lt;ref name=second_world_championship&gt;{{cite news |title=Report on the 8th General Assembly of the World Puzzle Federation |url=http://www.worldpuzzle.org/championships/2006/report.html |work=World Puzzle Federation |date=October 30, 2006 |accessdate=November 15, 2006 |deadurl=yes |archiveurl=https://web.archive.org/web/20070926231538/http://www.worldpuzzle.org/championships/2006/report.html |archivedate=September 26, 2007 |df=mdy-all }}&lt;/ref&gt; The individual champion was [[Thomas Snyder]] of the USA. The team champion was Japan.&lt;ref name=wsc2_resultsSummary&gt;{{cite news |title=Thomas Snyder wins World Sudoku Championship |url=http://wpc.puzzles.com/press/index.htm#2007-2 |work=US Puzzle Team |date=March 31, 2007 |accessdate=April 18, 2008}}&lt;/ref&gt;
*The third World Sudoku Championship was held in [[Goa, India]], from April 14 to 16, 2008. Thomas Snyder repeated as the individual overall champion, and also won the first ever Classic Trophy (a subset of the competition counting only classic Sudoku). The Czech Republic won the team competition.&lt;ref name=wsc3_summaryTimes&gt;{{cite news |title=It's a puzzle but sun, sea and beer can't compete with Sudoku for British team |url=http://entertainment.timesonline.co.uk/tol/arts_and_entertainment/games_and_puzzles/article3761511.ece |work=TimesOnline |date=April 17, 2008 |accessdate=April 18, 2008 |location=London |first=Michael |last=Harvey}}&lt;/ref&gt;
*The fourth World Sudoku Championship was held in [[Žilina]], [[Slovakia]], from April 24 to 27, 2009. After past champion Thomas Snyder of the USA won the general qualification, Jan Mrozowski of Poland emerged from a 36-competitor playoff to become the new World Sudoku Champion. Host nation Slovakia emerged as the top team in a separate competition of three-membered squads.&lt;ref name=wsc4_summaryTimes&gt;{{cite news |title=Su Doku battle goes a little off the wall |url=http://entertainment.timesonline.co.uk/tol/arts_and_entertainment/games_and_puzzles/sudoku/article6175809.ece |work=TimesOnline |date=April 27, 2009 |accessdate=April 27, 2009 |location=London |first=Jack |last=Malvern}}&lt;/ref&gt;
*The fifth World Sudoku Championship was held in [[Philadelphia]] from April 29 to May 2, 2010. Jan Mrozowski of Poland successfully defended his world title in the individual competition, while Germany won a separate team event. The puzzles were written by Thomas Snyder and [[Wei-Hwa Huang]], both past US Sudoku champions.&lt;ref name=wsc5_summary&gt;{{cite news |title=Pole, 23, repeats as Sudoku world champ |url=http://www.philly.com/philly/news/local/92606119.html |work=PhillyInquirer |date=May 2, 2009 |archiveurl=https://web.archive.org/web/20100505145443/http://www.philly.com/philly/news/local/92606119.html |archivedate=2010-05-05|accessdate=August 3, 2013}}&lt;/ref&gt;
* The 12th World Sudoku Championship (WSC) was held in [[Bangalore, India]] from Oct 15 to 22, 2017. Kota Morinishi of Japan won the Individual WSC and [[China]] won the team event.&lt;ref&gt;http://wspc2017.logicmastersindia.com/&lt;/ref&gt;
* The 13th World Sudoku Championship will take place in Czech Republic.&lt;ref&gt;http://www.worldpuzzle.org/championships/wsc/&lt;/ref&gt;
* In the United States, [[The Philadelphia Inquirer Sudoku National Championship|''The Philadelphia Inquirer ''Sudoku National Championship]] has been held three times, each time offering a $10,000 prize to the advanced division winner and a spot on the U.S. National Sudoku Team traveling to the world championships. The winners of the event were Thomas Snyder (2007),&lt;ref name=USChampionship1&gt;{{cite news |title=Thomas Snyder, World Sudoku champion |url=http://www.philly.com/philly/comics_games/sudoku/Thomas_Snyder__World_Sudoku_champion.html |work=The Philadelphia Inquirer |date=October 21, 2007 |accessdate= October 21, 2007}}&lt;/ref&gt; Wei-Hwa Huang (2008), and Tammy McLeod (2009).&lt;ref name=USChampionship3&gt;{{cite news |title=Going for 2d, she wins 1st |first=Howard |last=Shapiro |url=http://www.philly.com/philly/news/local/65922787.html |work=The Philadelphia Inquirer |date=October 25, 2009 |archiveurl=https://web.archive.org/web/20091102064249/http://www.philly.com/philly/news/local/65922787.html |archivedate=2009-11-02 |accessdate=August 3, 2013}}&lt;/ref&gt; In the 2009 event, the third-place finalist in the advanced division, Eugene Varshavsky, performed quite poorly onstage after setting a very fast qualifying time on paper, which caught the attention of organizers and competitors including past champion Thomas Snyder, who requested organizers reconsider his results due to a suspicion of cheating.&lt;ref name="USChampionship 3-cheat"&gt;{{cite news |title=Possible cheating probed at Sudoku National Championship |url=http://www.philly.com/inquirer/local/20091027_Possible_cheating_probed_at_Sudoku_tournament.html |first=John |last=Timpane |work=The Philadelphia Inquirer |date=October 27, 2009 |archiveurl=https://web.archive.org/web/20091101002443/http://www.philly.com/philly/news/local/20091027_Possible_cheating_probed_at_Sudoku_tournament.html |archivedate=2009-11-01  |accessdate=August 3, 2013}}&lt;/ref&gt; Following an investigation and a retest of Varshavsky, the organizers disqualified him and awarded Chris Narrikkattu third place.&lt;ref name="USChampionship 3-cheat2"&gt;{{cite news |title=3rd-place winner disqualified in sudoku scandal |url=http://www.philly.com/philly/news/local/20091124_3d-place_winner_disqualified_in_Sudoku_scandal.html |work=The Philadelphia Inquirer |date=November 24, 2009 |archiveurl=https://web.archive.org/web/20091127061702/http://www.philly.com/philly/news/local/20091124_3d-place_winner_disqualified_in_Sudoku_scandal.html |archivedate=2009-11-27 |accessdate=August 3, 2013}}&lt;/ref&gt;

== See also ==
{{div col|colwidth=22em}}
*[[36 Cube]]
*[[Blendoku]]
*[[Constraint satisfaction problem]]
*[[Futoshiki]]
*[[Glossary of Sudoku]]
*[[Hashiwokakero]]
*[[Hidato]]
*[[KenKen]]
*[[List of Nikoli puzzle types]]
*[[Logic puzzle]]
*[[Mathematics of Sudoku]]
*[[Nonogram]]
*[[Str8ts]]
*[[Sudoku solving algorithms]]
{{div col end}}

== References ==
{{Reflist|30em}}

== Further reading ==
*Delahaye, Jean-Paul, [http://www.cs.virginia.edu/~robins/The_Science_Behind_SudoKu.pdf "The Science Behind Sudoku"], ''[[Scientific American]]'' magazine, June 2006.
*Provan, J. Scott, "Sudoku: Strategy Versus Structure", ''American Mathematical Monthly'', October 2009. Published also as a [[University of North Carolina]] technical report [http://stat-or.unc.edu/research/Current%20Reports/techpdf/TR_08_04.pdf UNC/STOR/08/04], 2008.

== External links ==
{{Commons category|Sudoku}}
*{{dmoz|Games/Puzzles/Brain_Teasers/Sudoku|Sudoku}} – An active listing of Sudoku links
*[http://news.bbc.co.uk/2/hi/asia-pacific/6745433.stm 'Father of Sudoku' puzzles next move] ([[BBC]])
&lt;!--===========================(NoMoreLinks)===============================--&gt;
&lt;!--| DO NOT ADD MORE LINKS TO THIS ARTICLE. WIKIPEDIA IS NOT A COLLECTION OF |--&gt;
&lt;!--| LINKS. If you think that your link might be useful, do not add it here, |--&gt;
&lt;!--| but put it on this article's discussion page first or submit your link  |--&gt;
&lt;!--| to the appropriate category at the Open Directory Project (www.dmoz.org)|--&gt;
&lt;!--| and link back to that category using the {{dmoz}} template.             |--&gt;
&lt;!--|                                                                         |--&gt;
&lt;!--|           Links that have not been verified WILL BE DELETED.            |--&gt;
&lt;!--|  See [[Wikipedia:External links]] and [[Wikipedia:Spam]] for details    |--&gt;
&lt;!--===========================(NoMoreLinks)===============================--&gt;

[[Category:Sudoku]]
[[Category:Puzzles]]
[[Category:Latin squares]]
[[Category:Logic puzzles]]
[[Category:NP-complete problems]]
[[Category:Abstract strategy games]]
[[Category:Recreational mathematics]]</text>
      <sha1>hazyo38ibe2r83v5lc0w45p09zweu6e</sha1>
    </revision>
  </page>
  <page>
    <title>Supermodular function</title>
    <ns>0</ns>
    <id>905850</id>
    <revision>
      <id>841576100</id>
      <parentid>825702587</parentid>
      <timestamp>2018-05-16T17:43:47Z</timestamp>
      <contributor>
        <username>Nemo bis</username>
        <id>2584239</id>
      </contributor>
      <comment>Added free to read link in citations with [[WP:OABOT|OAbot]] #oabot</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6013">In [[mathematics]], a function
:&lt;math&gt;f\colon \mathbb{R}^k \to \mathbb{R}&lt;/math&gt;
is '''supermodular''' if
:&lt;math&gt;
f(x \uparrow y) + f(x \downarrow y) \geq f(x) + f(y)
&lt;/math&gt;
for all &lt;math&gt;x&lt;/math&gt;, &lt;math&gt;y \isin \mathbb{R}^{k}&lt;/math&gt;, where &lt;math&gt;x \uparrow y&lt;/math&gt; denotes the componentwise maximum and &lt;math&gt;x \downarrow y&lt;/math&gt; the componentwise minimum of &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt;.

If &amp;minus;''f'' is supermodular then ''f'' is called '''submodular''', and if the inequality is changed to an equality the function is '''modular'''.

If ''f'' is twice continuously differentiable, then supermodularity is equivalent to the condition&lt;ref&gt;The equivalence between the definition of supermodularity and its calculus formulation is sometimes called [[Topkis's theorem|Topkis' characterization theorem]]. See {{cite journal |first=Paul |last=Milgrom |first2=John |last2=Roberts |year=1990 |title=Rationalizability, Learning, and Equilibrium in Games with Strategic Complementarities |journal=[[Econometrica]] |volume=58 |issue=6 |pages=1255–1277 [p. 1261] |jstor=2938316 }}&lt;/ref&gt;

:&lt;math&gt; \frac{\partial ^2 f}{\partial z_i\, \partial z_j} \geq 0 \mbox{ for all } i \neq j.&lt;/math&gt;

==Supermodularity in economics and game theory==
The concept of supermodularity is used in the social sciences to analyze how one [[Agent (economics)|agent's]] decision affects the incentives of others.

Consider a [[symmetric game]] with a smooth payoff function &lt;math&gt;\,f&lt;/math&gt; defined over actions &lt;math&gt;\,z_i&lt;/math&gt; of two or more players &lt;math&gt;i \in {1,2,\dots,N}&lt;/math&gt;. Suppose the action space is continuous; for simplicity, suppose each action is chosen from an interval: &lt;math&gt;z_i \in [a,b]&lt;/math&gt;. In this context, supermodularity of &lt;math&gt;\,f&lt;/math&gt; implies that an increase in player &lt;math&gt;\,i&lt;/math&gt;'s choice &lt;math&gt;\,z_i&lt;/math&gt; increases the marginal payoff &lt;math&gt;df/dz_j&lt;/math&gt; of action &lt;math&gt;\,z_j&lt;/math&gt; for all other players &lt;math&gt;\,j&lt;/math&gt;. That is, if any player &lt;math&gt;\,i&lt;/math&gt; chooses a higher &lt;math&gt;\,z_i&lt;/math&gt;, all other players &lt;math&gt;\,j&lt;/math&gt; have an incentive to raise their choices &lt;math&gt;\,z_j&lt;/math&gt; too. Following the terminology of Bulow, [[John Geanakoplos|Geanakoplos]], and [[Paul Klemperer|Klemperer]] (1985), economists call this situation [[strategic complements|strategic complementarity]], because players' strategies are complements to each other.&lt;ref&gt;{{cite journal |first=Jeremy I. |last=Bulow |first2=John D. |last2=Geanakoplos |first3=Paul D. |last3=Klemperer |year=1985 |title=Multimarket Oligopoly: Strategic Substitutes and Complements |journal=[[Journal of Political Economy]] |volume=93 |issue=3 |pages=488–511 |doi=10.1086/261312 |citeseerx=10.1.1.541.2368 }}&lt;/ref&gt; This is the basic property underlying examples of [[General equilibrium#Uniqueness|multiple equilibria]] in [[coordination game]]s.&lt;ref&gt;{{cite journal |first=Russell |last=Cooper |first2=Andrew |last2=John |year=1988 |title=Coordinating coordination failures in Keynesian models |journal=[[Quarterly Journal of Economics]] |volume=103 |issue=3 |pages=441–463 |doi=10.2307/1885539 }}&lt;/ref&gt;

The opposite case of submodularity of &lt;math&gt;\,f&lt;/math&gt; corresponds to the situation of [[strategic complements|strategic substitutability]]. An increase in &lt;math&gt;\,z_i&lt;/math&gt; lowers the marginal payoff to all other player's choices &lt;math&gt;\,z_j&lt;/math&gt;, so strategies are substitutes. That is, if &lt;math&gt;\,i&lt;/math&gt; chooses a higher &lt;math&gt;\,z_i&lt;/math&gt;, other players have an incentive to pick a ''lower'' &lt;math&gt;\,z_j&lt;/math&gt;.

For example, Bulow et al. consider the interactions of many [[Imperfect competition|imperfectly competitive]] firms. When an increase in output by one firm raises the marginal revenues of the other firms, production decisions are strategic complements. When an increase in output by one firm lowers the marginal revenues of the other firms, production decisions are strategic substitutes.


A supermodular [[utility function]] is often related to [[complementary goods]]. However, this view is disputed.&lt;ref&gt;{{Cite journal|doi=10.1016/j.jet.2008.06.004 |title=Supermodularity and preferences |journal=[[Journal of Economic Theory]] |volume=144 |issue=3 |pages=1004 |year=2009 |last1=Chambers |first1=Christopher P. |last2=Echenique |first2=Federico }}&lt;/ref&gt;

==Submodular functions of subsets==
Supermodularity and submodularity are also defined for functions defined over subsets of a larger set.  Intuitively, a submodular function over the subsets demonstrates "diminishing returns".  There are specialized techniques for optimizing submodular functions.

Let ''S'' be a finite set.  A function &lt;math&gt;f\colon 2^S \to \mathbb{R}&lt;/math&gt; is submodular if for any &lt;math&gt;A \subset B \subset S&lt;/math&gt; and &lt;math&gt;x \in S \setminus B&lt;/math&gt;, &lt;math&gt;f(A \cup \{x\})-f(A) \geq f(B \cup \{x\})-f(B)&lt;/math&gt;.  For supermodularity, the inequality is reversed.
&lt;!--
A simple illustrative example motivates this definition of submodular.  Let S be a set of different foods, &lt;math&gt;M \subset  S&lt;/math&gt; a meal, and &lt;math&gt;f(M)&lt;/math&gt; the "goodness" of that meal.  Then A above is one meal, and B is A but with even more options.  Let x be ice cream.  Adding ice cream to a meal is always good, but it is best if there is not already a dessert.  If A and B either both have a dessert or both do not, then adding ice cream to them is comparably good.  But if A does not have dessert and B does, then the effect of adding ice cream is more pronounced in A.
--&gt;

The definition of submodularity can equivalently be formulated as
:&lt;math&gt; f(A)+f(B) \geq f(A \cap B) + f(A \cup B) &lt;/math&gt;
for all subsets ''A'' and ''B'' of ''S''.

==See also==
* [[Pseudo-Boolean function]]
* [[Topkis's theorem]]
* [[Submodular set function]]
* [[Superadditive]]
* [[Utility functions on indivisible goods]]

==Notes and references==
{{Reflist}}

{{DEFAULTSORT:Supermodular Function}}
[[Category:Order theory]]
[[Category:Optimization of ordered sets]]
[[Category:Generalized convexity]]
[[Category:Supermodular functions]]</text>
      <sha1>2irlsp4kv6r8qb4kpebf06rv21htlg6</sha1>
    </revision>
  </page>
  <page>
    <title>Szemerédi–Trotter theorem</title>
    <ns>0</ns>
    <id>1051627</id>
    <revision>
      <id>859014774</id>
      <parentid>859002493</parentid>
      <timestamp>2018-09-11T04:31:32Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* Proof of the first formulation */ ce to avoid 1st person</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10535">The '''Szemerédi–Trotter theorem''' is a [[mathematics|mathematical]] result in the field of [[combinatorial geometry]]. It asserts that given {{mvar|n}}  points and {{mvar|m}} lines in the [[Euclidean plane]], the number of [[Incidence (geometry)|incidences]] (''i.e.'', the number of point-line pairs, such that the point lies on the line) is

:&lt;math&gt;O \left ( n^{\frac{2}{3}} m^{\frac{2}{3}} + n + m \right ),&lt;/math&gt;

this bound cannot be improved, except in terms of the implicit constants. As for the implicit constants, it was shown by [[János Pach]], Radoš Radoičić, [[Gábor Tardos]], and Géza Tóth&lt;ref&gt;{{cite journal | last1=Pach | first1=János | authorlink1= János Pach |first2=Radoš|last2= Radoičić |last3=Tardos | first3=Gábor |authorlink3= Gábor Tardos| last4=Tóth | first4=Géza |year=2006 | title=Improving the Crossing Lemma by Finding More Crossings in Sparse Graphs | journal=[[Discrete &amp; Computational Geometry]]| volume = 36 | issue = 4 | pages = 527–552 | url = https://link.springer.com/article/10.1007/s00454-006-1264-9 | doi=10.1007/s00454-006-1264-9}}&lt;/ref&gt; that the upper bound &lt;math&gt; 2.5n^{2/3} m^{2/3} + n + m&lt;/math&gt; holds. On the other hand, Pach and Tóth&lt;ref&gt;{{cite journal | last1=Pach | first1=János | authorlink1= János Pach|last2=Tóth | first2=Géza |year=1997 | title=Graphs drawn with few crossings per edge | journal=[[Combinatorica]]| volume = 17 | issue = 3 | pages = 427–439 | url = https://link.springer.com/article/10.1007/BF01215922 | doi=10.1007/BF01215922}}&lt;/ref&gt; showed that the statement does not hold true if one replaces the coefficient 2.5 with 0.42.  

An equivalent formulation of the theorem is the following. Given {{mvar|n}}  points and an integer {{math|''k'' ≥ 2}}, the number of lines which pass through at least {{mvar|k}} of the points is

:&lt;math&gt;O \left( \frac{n^2}{k^3} + \frac{n}{k} \right ).&lt;/math&gt;

The original proof of [[Endre Szemerédi]] and [[William T. Trotter]]&lt;ref name="Szemerédi"&gt;{{cite journal | last1=Szemerédi | first1=Endre | authorlink1=Endre Szemerédi |first2=William T. |last2=Trotter|authorlink2= William T. Trotter | year=1983 | title=Extremal problems in discrete geometry | journal=[[Combinatorica]] | volume=3 | doi=10.1007/BF02579194 | pages=381–392 | issue=3–4 | mr=0729791}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1=Szemerédi | first1=Endre | authorlink1=Endre Szemerédi |first2=William T. |last2=Trotter  | authorlink2= William T. Trotter | year=1983 | title = A Combinatorial Distinction Between the Euclidean and Projective Planes| journal = [[European Journal of Combinatorics]]| volume = 4 | issue = 4 | pages = 385–394 | url = http://people.math.gatech.edu/~trotter/papers/37.pdf | doi=10.1016/S0195-6698(83)80036-5}}&lt;/ref&gt; was somewhat complicated, using a combinatorial technique known as ''[[cell decomposition]]''.  Later, László Székely discovered a much simpler proof using the [[crossing number inequality]] for [[Graph (discrete mathematics)|graphs]].&lt;ref name="Székely"&gt;{{cite journal| last=Székely | first=László A. | year=1997 | title=Crossing numbers and hard Erdős problems in discrete geometry | journal=[[Combinatorics, Probability and Computing]] | volume=6 | issue=3 | pages=353–358 | url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.125.1484 | doi=10.1017/S0963548397002976 | mr=1464571}}&lt;/ref&gt; (See below.)

The Szemerédi–Trotter theorem has a number of consequences, including [[Beck's theorem (geometry)|Beck's theorem]] in [[incidence geometry]].

== Proof of the first formulation ==
We may discard the lines which contain two or fewer of the points, as they can contribute at most {{math|2''m''}} incidences to the total number. Thus we may assume that every line contains at least three of the points.

If a line contains {{mvar|k}} points, then it will contain {{math|''k'' − 1}} line segments which connect two consecutive points along the line. Because {{math|''k'' ≥ 3}} after discarding the two-point lines, it follows that {{math|''k'' − 1 ≥ ''k''/2}}, so the number of these line segments on each line is at least half the number of incidences on that line. Summing over all of the lines, the number of these line segments is again at least half the total number of incidences. Thus if {{mvar|e}} denotes the number of such line segments, it will suffice to show that

:&lt;math&gt;e = O \left ( n^{\frac{2}{3}} m^{\frac{2}{3}} + n + m \right).&lt;/math&gt;

Now consider the [[Graph (discrete mathematics)|graph]] formed by using the {{mvar|n}}  points as vertices, and the {{mvar|e}} line segments as edges. Since each line segment lies on one of {{mvar|m}} lines, and any two lines intersect in at most one point, the [[Crossing number (graph theory)|crossing number]] of this graph is at most the number of points where two lines intersect, which is at most {{math|''m''(''m'' &amp;minus; 1)/2}}. The [[crossing number inequality]] implies that either {{math|''e'' ≤ 7.5''n''}}, or that {{math|''m''(''m'' &amp;minus; 1)/2 ≥ ''e''&lt;sup&gt;3&lt;/sup&gt; / 33.75''n''&lt;sup&gt;2&lt;/sup&gt;}}. In either case {{math|''e'' ≤ 3.24(''nm'')&lt;sup&gt;2/3&lt;/sup&gt; + 7.5''n''}}, giving the desired bound

:&lt;math&gt;e = O \left ( n^{\frac{2}{3}} m^{\frac{2}{3}} + n + m \right ).&lt;/math&gt;

== Proof of the second formulation ==
Since every pair of points can be connected by at most one line, there can be at most {{math|''n''(''n'' − 1)/2}} lines which can connect at {{mvar|k}} or more points, since {{math|''k'' ≥ 2}}. This bound will prove the theorem when {{mvar|k}} is small (e.g. if {{math|''k'' ≤ ''C''}} for some absolute constant {{mvar|C}}).  Thus, we need only consider the case when {{mvar|k}} is large, say {{math|''k'' ≥ ''C''}}.

Suppose that there are ''m'' lines that each contain at least {{mvar|k}} points. These lines generate at least {{mvar|mk}} incidences, and so by the first formulation of the Szemerédi–Trotter theorem, we have

:&lt;math&gt;mk = O \left ( n^{\frac{2}{3}} m^{\frac{2}{3}} + n + m \right ),&lt;/math&gt;

and so at least one of the statements &lt;math&gt;mk = O( n^{2/3} m^{2/3} ), mk = O(n)&lt;/math&gt;, or &lt;math&gt;mk = O(m)&lt;/math&gt; is true.  The third possibility is ruled out since {{mvar|k}} was assumed to be large, so we are left with the first two.  But in either of these two cases, some elementary algebra will give the bound &lt;math&gt;m = O( n^2 / k^3 + n/k )&lt;/math&gt; as desired.

== Optimality ==
Except for its constant, the Szemerédi–Trotter incidence bound cannot be improved. To see this, consider for any positive integer {{math|''N'' ∈ '''Z'''&lt;sup&gt;+&lt;/sup&gt;}} a set of points on the integer [[Lattice (group)|lattice]]

:&lt;math&gt;P = \left \{ (a, b) \in \mathbf{Z}^2 \ : \ 1 \leq a \leq N; 1 \leq b \leq 2N^2 \right \},&lt;/math&gt;

and a set of lines

:&lt;math&gt;L = \left \{ (x, mx + b) \ : \ m, b \in \mathbf{Z}; 1 \leq m \leq N; 1 \leq b \leq N^2 \right \}.&lt;/math&gt;

Clearly, &lt;math&gt;|P| = 2N^3&lt;/math&gt; and &lt;math&gt;|L| = N^3&lt;/math&gt;. Since each line is incident to {{mvar|N}} points (i.e., once for each &lt;math&gt;x \in \{1, \cdots, N\}&lt;/math&gt;), the number of incidences is &lt;math&gt;N^4&lt;/math&gt; which matches the upper bound.&lt;ref&gt;{{cite web|url=http://terrytao.wordpress.com/tag/szemeredi-trotter-theorem/|author=Terence Tao|title=An incidence theorem in higher dimensions|author-link=Terence Tao|date=March 17, 2011|accessdate=August 26, 2012}}&lt;/ref&gt;

==Generalization to {{math|'''R'''&lt;sup&gt;''d''&lt;/sup&gt;}}==
One generalization of this result to arbitrary dimension, {{math|'''R'''&lt;sup&gt;''d''&lt;/sup&gt;}}, was found by Agarwal and Aronov.&lt;ref&gt;{{cite journal|last1=Agarwal|first1=Pankaj|last2=Aronov|first2=Boris|author1-link=Pankaj K. Agarwal|author2-link=Boris Aronov|title=Counting facets and incidences|year=1992|journal=[[Discrete and Computational Geometry]]| publisher=Springer|volume=7|issue=1|pages=359–369|doi=10.1007/BF02187848}}&lt;/ref&gt; Given a set of {{mvar|n}} points, {{mvar|S}}, and the set of {{mvar|m}} hyperplanes, {{mvar|H}}, which are each spanned by {{mvar|S}}, the number of incidences between {{mvar|S}} and {{mvar|H}} is bounded above by

:&lt;math&gt;O \left (m^{\frac{2}{3}}n^{\frac{d}{3}}+n^{d-1} \right ).&lt;/math&gt;

Equivalently, the number of hyperplanes in {{mvar|H}} containing {{mvar|k}}  or more points is bounded above by

:&lt;math&gt;O\left( \frac{n^d}{k^3} + \frac{n^{d-1}}{k} \right ).&lt;/math&gt;

A construction due to Edelsbrunner shows this bound to be asymptotically optimal.&lt;ref&gt;{{cite book|title=Algorithms in Combinatorial Geometry|last=Edelsbrunner|first=Herbert|author-link=Herbert Edelsbrunner|publisher=Springer-Verlag|year=1987|chapter=6.5 Lower bounds for many cells|isbn=3-540-13722-X}}&lt;/ref&gt;

[[József Solymosi]] and [[Terence Tao]] obtained near sharp upper bounds for the number of incidences between points and algebraic varieties in higher dimensions. Their proof uses the [[Polynomial Ham Sandwich Theorem]].&lt;ref&gt;{{Cite journal|last1=Solymosi|first1=József|author1-link= József Solymosi |last2=Tao|first2=Terence|author2-link=Terence Tao|title=An incidence theorem in higher dimensions|date=September 2012|journal=[[Discrete and Computational Geometry]]| issue=2| volume=48| doi=10.1007/s00454-012-9420-x|arxiv=1103.2926}}&lt;/ref&gt;

==Analogs over other fields== 
There has been some interest in proving analogs to the Szemerédi–Trotter theorem in planes over fields other than {{math|'''R'''}}. All known proofs of the Szemerédi–Trotter theorem over {{math|'''R'''}} rely in a crucial way on the topology of Euclidean space, so do not extend easily to other fields. Nevertheless, the following results have been obtained:  
* Tóth&lt;ref&gt;{{cite journal  | last = Tóth | first = Csaba D.| title = The Szemerédi-Trotter Theorem in the Complex Plane| journal = [[Combinatorica]] | volume = 35 | issue = 1 | pages = 95&amp;ndash;126 | year = 2015 | doi=10.1007/s00493-014-2686-2| arxiv = math/0305283}}&lt;/ref&gt; successfully generalized the original proof of Szemerédi and Trotter to the complex plane {{math|'''C'''&lt;sup&gt;''2''&lt;/sup&gt;}} by introducing additional ideas. This result was also obtained independently and through a different method by Joshua Zahl&lt;ref&gt;{{cite journal  | last = Zahl | first = Joshua | title = A Szemerédi-Trotter Type Theorem in ℝ4| journal = [[Discrete &amp; Computational Geometry]] | volume = 54 | issue = 3 | pages = 513&amp;ndash;572 | year = 2015 | doi=10.1007/s00454-015-9717-7}}&lt;/ref&gt;.

== References ==
{{reflist}}

{{DEFAULTSORT:Szemeredi-Trotter theorem}}
[[Category:Euclidean plane geometry]]
[[Category:Theorems in discrete geometry]]
[[Category:Theorems in combinatorics]]
[[Category:Articles containing proofs]]</text>
      <sha1>tl5j8q14v3lx4tdwi69e0mxzno2zo30</sha1>
    </revision>
  </page>
  <page>
    <title>Test Template Framework</title>
    <ns>0</ns>
    <id>27267184</id>
    <revision>
      <id>797237924</id>
      <parentid>721912317</parentid>
      <timestamp>2017-08-25T19:34:39Z</timestamp>
      <contributor>
        <username>Bellerophon5685</username>
        <id>1258165</id>
      </contributor>
      <comment>/* Notes */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13569">The '''Test Template Framework''' ('''TTF''') is a [[model-based testing]] (MBT) framework proposed by Phil Stocks and David Carrington in {{Harv|Stocks|Carrington|1996}} for the purpose of [[software testing]]. Although the TTF was meant to be notation-independent, the original presentation was made using the [[Z notation|Z formal notation]]. It is one of the few MBT frameworks approaching [[unit testing]].

==Introduction==
The TTF is a specific proposal of [[model-based testing]] (MBT). It considers models to be [[Z notation|Z specifications]]. Each operation within the specification is analyzed to derive or generate [[#Abstract test case|''abstract test cases'']]. This analysis consists of the following steps:

# Define the [[#Input space|''input space'']] (IS) of each operation.
# Derive the [[#Valid input space|''valid input space'']] (VIS) from the [[#Input space|IS]] of each operation.
# Apply one or more [[#Testing tactic|''testing tactics'']],&lt;ref name="testing strategy"&gt;Stocks and Carrington use the term ''testing strategies'' in {{Harv|Stocks|Carrington|1996}}.&lt;/ref&gt; starting from each [[#Valid input space|VIS]], to build a [[#Testing tree|''testing tree'']] for each operation. Testing trees are populated with nodes called [[#Test class|''test classes'']].
# [[#Pruning testing trees|''Prune'']] each of the resulting [[#Testing tree|testing trees]].
# Find one or more [[#Abstract test case|''abstract test cases'']] from each leaf in each [[#Testing tree|testing tree]].

One of the main advantages of the TTF is that all of these concepts are expressed in the same notation of the specification, i.e. the [[Z notation]]. Hence, the engineer has to know only one notation to perform the analysis down to the generation of [[#Abstract test case|abstract test cases]].

==Important concepts==
In this section the main concepts defined by the TTF are described.

===Input space===
Let &lt;math&gt;Op&lt;/math&gt; be a Z operation. Let &lt;math&gt;x_{1} \dots x_{n}&lt;/math&gt; be all the input and (non-primed) state variables referenced in &lt;math&gt;Op&lt;/math&gt;, and &lt;math&gt;T_{1} \dots T_{n}&lt;/math&gt; their corresponding types. The ''Input Space'' (IS) of &lt;math&gt;Op&lt;/math&gt;, written &lt;math&gt;IS_{Op}&lt;/math&gt;, is the Z schema box defined by &lt;math&gt;[x_{1}:T_{1} \dots x_{n}:T_{n}]&lt;/math&gt;.

===Valid input space===
Let &lt;math&gt;Op&lt;/math&gt; be a Z operation. Let &lt;math&gt;\text{pre } Op&lt;/math&gt; be the [[precondition]] of &lt;math&gt;Op&lt;/math&gt;. The ''Valid Input Space'' (VIS) of &lt;math&gt;Op&lt;/math&gt;, written &lt;math&gt;VIS_{Op}&lt;/math&gt;, is the Z schema box defined by &lt;math&gt;[IS_{Op} | \text{pre } Op]&lt;/math&gt;.

===Test class===
Let &lt;math&gt;Op&lt;/math&gt; be a Z operation and let &lt;math&gt;P&lt;/math&gt; be any [[Predicate (mathematical logic)|predicate]] depending on one or more of the variables defined in &lt;math&gt;VIS_{Op}&lt;/math&gt;. Then, the Z schema box &lt;math&gt;[VIS_{Op} | P]&lt;/math&gt; is a ''test class'' of &lt;math&gt;Op&lt;/math&gt;. Note that this schema is equivalent to &lt;math&gt;[IS_{Op} | \text{pre } Op \land P]&lt;/math&gt;. This observation can be generalized by saying that if &lt;math&gt;C_{Op}&lt;/math&gt; is a test class of &lt;math&gt;Op&lt;/math&gt;, then the Z schema box defined by &lt;math&gt;[C_{Op} | P]&lt;/math&gt; is also a test class of &lt;math&gt;Op&lt;/math&gt;. According to this definition the VIS is also a test class.

If &lt;math&gt;C_{Op}&lt;/math&gt; is a test class of &lt;math&gt;Op&lt;/math&gt;, then the predicate &lt;math&gt;P&lt;/math&gt; in &lt;math&gt;C'_{Op} == [C_{Op} | P]&lt;/math&gt; is said to be the ''characteristic'' predicate of &lt;math&gt;C'_{Op}&lt;/math&gt; or &lt;math&gt;C'_{Op}&lt;/math&gt; is ''characterized'' by &lt;math&gt;P&lt;/math&gt;.

Test classes are also called test objectives {{Harv|Utting|Legeard|2007}}, test templates {{Harv|Stocks|Carrington|1996}} and test specifications.

===Testing tactic===
In the context of the TTF a ''[[testing tactic]]''&lt;ref name="testing strategy"/&gt; is a means to [[Partition of a set|partition]] any [[#Test class|test class]] of any operation. However, some of the testing tactics used in practice actually do not always generate a partition of some test classes.

Some testing tactics originally proposed for the TTF are the following:

*[[Disjunctive Normal Form]] (DNF). By applying this tactic the operation is written in [[Disjunctive Normal Form]] and the [[#Test class|test class]] is divided in as many test classes as terms are in the resulting operation's predicate. The predicate added to each new test class is the [[precondition]] of one of the terms in the operation's predicate.
*[[Standard Partitions]] (SP). This tactic uses a predefined partition of some mathematical operator {{Harv|Stocks|1993}}. For example, the following is a good partition for expressions of the form &lt;math&gt;S \spadesuit T&lt;/math&gt; where &lt;math&gt;\spadesuit&lt;/math&gt; is one of &lt;math&gt;\cup&lt;/math&gt;, &lt;math&gt;\cap&lt;/math&gt; and &lt;math&gt;\setminus&lt;/math&gt; (see [[Set theory]]).
*:&lt;math&gt;
\begin{array}{l|l}
S = \emptyset, T = \emptyset &amp; 
S \neq \emptyset, T \neq \emptyset, S \subset T \\
\hline
S = \emptyset, T \neq \emptyset &amp; 
S \neq \emptyset, T \neq \emptyset, T \subset S \\
\hline
S \neq \emptyset, T = \emptyset &amp;
S \neq \emptyset, T \neq \emptyset, T = S \\
\hline
S \neq \emptyset, T \neq \emptyset, S \cap T = \emptyset &amp;
S \neq \emptyset, T \neq \emptyset, S \cap T \neq \emptyset, \lnot (S \subseteq T), \lnot (T \subseteq S), S \neq T
\end{array}
&lt;/math&gt;
*:As can be noticed, standard partitions might change according to how much testing the engineer wants to perform.
*[[Sub-domain Propagation]] (SDP). This tactic is applied to expressions containing:
*# Two or more mathematical operators for which there are already defined standard partitions, or 
*# Mathematical operators which are defined in terms of other mathematical operators.
*:In any of these cases, the standard partitions of the operators appearing in the expression or in the definition of a complex one, are combined to produce a partition for the expression. If the tactic is applied to the second case, then the resulting partition can be considered as the standard partition for that operator. Stocks and Carrington in {{Harv|Stocks|Carrington|1996}} illustrate this situation with &lt;math&gt;R \oplus G = (\text{dom } G \ntriangleleft R)\cup G&lt;/math&gt;, where &lt;math&gt;\ntriangleleft&lt;/math&gt; means [[Restriction (mathematics)|domain anti-restriction]], by giving standard partitions for &lt;math&gt;\ntriangleleft&lt;/math&gt; and &lt;math&gt;\cup&lt;/math&gt; and propagating them to calculate a partition for &lt;math&gt;\oplus&lt;/math&gt;.
*[[Specification Mutation]] (SM). The first step of this tactic consists in generating a ''mutant'' of the Z operation. A mutant of a Z operation is similar in concept to a [[Mutation testing|mutant of a program]], i.e. it is a modified version of the operation. The modification is introduced by the engineer with the intention of uncovering an error in the implementation. The mutant should be the specification that the engineer guesses the programmer has implemented. Then, the engineer has to calculate the subset of the VIS that yields different results in both specifications. The predicate of this set is used to derive a new test class.

Some other testing tactics that may also be used are the following:

*[[In Set Extension]] (ISE). It applies to predicates of the form &lt;math&gt;expr \in \{expr_{1}, \dots, expr_{n}\}&lt;/math&gt;. In this case, it generates {{mvar|n}} test classes such that a predicate of the form &lt;math&gt;expr = expr_{i}&lt;/math&gt; is added to each of them.
*[[Mandatory Test Set]] (MTS). This tactic associates a set of constant values to a VIS' variable and generates as many test classes as elements are in the set. Each test class is characterized by a predicate of the form &lt;math&gt;var = val&lt;/math&gt; where {{mvar|var}} is the name of the variable and {{mvar|val}} is one of the values of the set.
*[[Numeric Range]]s (NR). This tactic applies only to VIS' variables of type &lt;math&gt;\mathbb{Z}&lt;/math&gt; (or its "subtype" &lt;math&gt;\mathbb{N}&lt;/math&gt;). It consists in associating a range to a variable and deriving test classes by comparing the variable with the limits of the range in some ways. More formally, let {{mvar|n}} be a variable of type &lt;math&gt;\mathbb{Z}&lt;/math&gt; and let &lt;math&gt;[i,j]&lt;/math&gt; be the associated range. Then, the tactic generates the test classes characterized by the following predicates: &lt;math&gt;n&lt;i&lt;/math&gt;, &lt;math&gt;n=i&lt;/math&gt;, &lt;math&gt;i&lt;n \land n&lt;j&lt;/math&gt;, &lt;math&gt;n=j&lt;/math&gt;, &lt;math&gt;n&gt;j&lt;/math&gt;.
*[[Free Type]] (FT). This tactic generates as many test classes as elements a free (enumerated) type has. In other words, if a model defines type {{math|COLOUR ::{{=}} red {{!}} blue {{!}} green}} and some operation uses {{mvar|c}} of type {{math|COLOUR}}, then by applying this tactic each test class will by divided into three new test classes: one in which {{mvar|c}} equals {{math|red}}, the other in which {{mvar|c}} equals {{math|blue}}, and the third where {{mvar|c}} equals {{math|green}}.
*[[Proper Subset of Set Extension]] (PSSE). This tactic uses the same concept of ISE but applied to set inclusions. PSSE helps to test operations including predicates like &lt;math&gt;expr \subset \{expr_{1}, \dots, expr_{n}\}&lt;/math&gt;. When PSSE is applied it generates &lt;math&gt;2^{n} - 1&lt;/math&gt; test classes where a predicate of the form &lt;math&gt;expr = A_{i}&lt;/math&gt; with &lt;math&gt;i \in [1, 2^{n} -1]&lt;/math&gt; and &lt;math&gt;A_{i} \in \mathbb{P} \{expr_{1}, \dots, expr_{n}\} \setminus \{\{expr_{1}, \dots, expr_{n}\}\}&lt;/math&gt;, is added to each class. &lt;math&gt;\{expr_{1}, \dots, expr_{n}\}&lt;/math&gt; is excluded from &lt;math&gt;\mathbb{P} \{expr_{1}, \dots, expr_{n}\}&lt;/math&gt; because {{mvar|expr}} is a proper subset of &lt;math&gt;\{expr_{1}, \dots, expr_{n}\}&lt;/math&gt;.
*[[Subset of Set Extension]] (SSE). It is identical to PSSE but it applies to predicates of the form &lt;math&gt;expr \subseteq \{expr_{1}, \dots, expr_{n}\}&lt;/math&gt; in which case it generates &lt;math&gt;2^{n}&lt;/math&gt; by considering also &lt;math&gt;\{expr_{1}, \dots, expr_{n}\}&lt;/math&gt;.

===Testing tree&amp; ===
The application of a testing tactic to the VIS generates some test classes. If some of these test classes are further partitioned by applying one or more testing tactics, a new set of test classes is obtained. This process can continue by applying testing tactics to the test classes generated so far. Evidently, the result of this process can be drawn as a [[Tree (data structure)|tree]] with the VIS as the root node, the test classes generated by the first testing tactic as its children, and so on. Furthermore, Stocks and Carrington in {{Harv|Stocks|Carrington|1996}} propose to use the Z notation to build the tree, as follows.

&lt;math&gt;
\begin{align}
VIS &amp; == [IS | P]\\
TCL_{T_{1}}^{1} &amp; == [VIS | P_{T_{1}}^{1}]\\
&amp;\dots\\
TCL_{T_{1}}^{n} &amp; == [VIS | P_{T_{1}}^{n}]\\
TCL_{T_{2}}^{1} &amp; == [TCL_{T_{1}}^{i} | P_{T_{2}}^{1}]\\
&amp;\dots\\
TCL_{T_{2}}^{m} &amp; == [TCL_{T_{1}}^{i} | P_{T_{2}}^{m}]\\
&amp;\dots\\
TCL_{T_{3}}^{1} &amp; == [TCL_{T_{2}}^{j} | P_{T_{3}}^{1}]\\
&amp;\dots\\
TCL_{T_{3}}^{k} &amp; == [TCL_{T_{2}}^{j} | P_{T_{3}}^{k}]\\
&amp;\dots\\
&amp;\dots\\
&amp;\dots
\end{align}
&lt;/math&gt;

===Pruning testing trees===
In general a test class' predicate is a conjunction of two or more predicates. It is likely, then, that some test classes are empty because their predicates are contradictions. These test classes must be pruned from the testing tree because they represent impossible combinations of input values, i.e. no [[#Abstract test case|abstract test case]] can be derived out of them.

===Abstract test case===
An abstract test case is an element belonging to a [[#Test class|test class]]. The TTF prescribes that abstract test cases should be derived only from the leaves of the [[#Testing tree|testing tree]]. Abstract test cases can also be written as Z schema boxes. Let &lt;math&gt;Op&lt;/math&gt; be some operation, let &lt;math&gt;VIS_{Op}&lt;/math&gt; be the [[#Valid input space|VIS]] of &lt;math&gt;Op&lt;/math&gt;, let &lt;math&gt;x_{1}:T_{1} \dots x_{n}:T_{n}&lt;/math&gt; be all the variables declared in &lt;math&gt;VIS_{Op}&lt;/math&gt;, let &lt;math&gt;C_{Op}&lt;/math&gt; be a (leaf) test class of the testing tree associated to &lt;math&gt;Op&lt;/math&gt;, let &lt;math&gt;P_{1} \dots P_{m}&lt;/math&gt; be the [[#Test class|characteristic predicates]] of each test class from &lt;math&gt;C_{Op}&lt;/math&gt; up to &lt;math&gt;VIS_{Op}&lt;/math&gt; (by following the [[Tree (data structure)|edges from child to parent]]), and let &lt;math&gt;v_{1}:T_{1} \dots v_{n}:T_{n}&lt;/math&gt; be &lt;math&gt;n&lt;/math&gt; constant values satisfying &lt;math&gt;P_{1}  \land \dots \land P_{m}&lt;/math&gt;. Then, an abstract test case of &lt;math&gt;C_{Op}&lt;/math&gt; is the Z schema box defined by &lt;math&gt;[C_{Op} | x_{1} = v_{1} \land \dots \land x_{n} = v_{n}]&lt;/math&gt;.

==See also==
*[[Model-based testing]]
*[[Fastest]]

==References==
*{{Citation | last1=Stocks | last2=Carrington | first1=Phil | first2=David | title=A framework for specification-based testing | journal=IEEE Transactions on Software Engineering | volume=22 | number=11 | year=1996 | pages=777&amp;ndash;793 | doi=10.1109/32.553698}}.
*{{Citation | last1=Utting | last2=Legeard | first1=Mark | first2=Bruno | title=Practical Model-Based Testing: A Tools Approach | publisher=[[Morgan Kaufmann]] | year=2007 | isbn=0-12-372501-1 | edition=1st}}.
*{{Citation | last1=Stocks | first1=Phil | title=Applying Formal Methods to Software Testing | publisher=Department of Computer Science, University of Queensland, PhD thesis | year=1993}}.
&lt;!-- {{Citation | last1=Ebbinghaus | first1=Heinz-Dieter | last2=Flum | first2=Jörg | last3=Thomas | first3=Wolfgang | title=Mathematical Logic | publisher=[[Springer-Verlag]] | location=Berlin, New York | edition=2nd | series=Undergraduate Texts in Mathematics | isbn=978-0-387-94258-2 | year=1994}} --&gt;

==Notes==
{{reflist}}

[[Category:Computer-related introductions in 1996]]
[[Category:Software testing]]
[[Category:Z notation]]</text>
      <sha1>pppf1n2vewvwflbvmu08oqh7j0l13ej</sha1>
    </revision>
  </page>
  <page>
    <title>The Fractal Geometry of Nature</title>
    <ns>0</ns>
    <id>29229128</id>
    <revision>
      <id>863755870</id>
      <parentid>817529211</parentid>
      <timestamp>2018-10-12T20:12:36Z</timestamp>
      <contributor>
        <username>Lexy-lou</username>
        <id>8759132</id>
      </contributor>
      <minor/>
      <comment>Updated link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2240">{{Infobox book
| name          = The Fractal Geometry of Nature
| image         = The Fractal Geometry of Nature - bookcover.jpg
| caption       = Cover of the hardcover edition
| author        = [[Benoît Mandelbrot]]
| country       = United States
| language      = English
| subject       = [[Mathematics]]
| publisher     = [[W. H. Freeman and Co.]]
| release_date  = 1982
| media_type    = Print
| pages         = 
| isbn          =  0-7167-1186-9
| oclc          = 
}}

'''''The Fractal Geometry of Nature''''' is a 1982 book by the Franco-American [[mathematics|mathematician]] [[Benoît Mandelbrot]].&lt;ref&gt;{{cite web|title=THE FRACTAL GEOMETRY OF NATURE|url=https://us.macmillan.com/books/9780716711865|publisher=us.macmillan.com|accessdate=12 October 2018}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=The Fractal Geometry of Nature by Benoît B. Mandelbrot|url=http://www.goodreads.com/book/show/558059.The_Fractal_Geometry_of_Nature|website=[[Goodreads]]|publisher=goodreads.com|accessdate=25 October 2016}}&lt;/ref&gt;

==Overview==
''The Fractal Geometry of Nature'' is a revised and enlarged version of his 1977 book entitled ''Fractals: Form, Chance and Dimension'', which in turn was a revised, enlarged, and translated version of his 1975 French book, ''Les Objects Fractals: Forme, Hasard et Dimension''. ''[[American Scientist]]'' put the book in its one hundred books of 20th century science.&lt;ref&gt;[http://www.americanscientist.org/bookshelf/pub/100-or-so-books-that-shaped-a-century-of-science 100 or so Books that shaped a Century of Science » American Scientist&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

As technology has improved mathematically accurate, computer-drawn fractals have become more detailed. Early drawings were low-resolution black and white; later drawings were higher resolution and in color. Many examples were created by programmers working with Mandelbrot, primarily at [[IBM Research]]. These visualizations have added to persuasiveness of the books and their impact on the scientific community.{{CN|date=September 2016}}

== See also ==
* [[Chaos theory]]

==References==
{{Reflist}}

{{Fractals}}

{{DEFAULTSORT:Fractal Geometry of Nature, The}}
[[Category:1982 books]]
[[Category:Mathematics books]]
[[Category:Fractals]]</text>
      <sha1>npt6ejxuescqkkpctdqd1ani20ihhs3</sha1>
    </revision>
  </page>
  <page>
    <title>Twelf</title>
    <ns>0</ns>
    <id>2058228</id>
    <revision>
      <id>676081946</id>
      <parentid>672053541</parentid>
      <timestamp>2015-08-14T15:22:15Z</timestamp>
      <contributor>
        <ip>130.225.98.201</ip>
      </contributor>
      <comment>/* Logic programming */ mention HHF, lambda prolog</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6546">'''Twelf''' is an implementation of the logical framework [[LF (logical framework)|LF]]. It is used for logic programming and for the formalization of programming language theory.

==Introduction==
&lt;!-- to do: introduce LF theory --&gt;
At its simplest, a Twelf program (called a "signature") is a collection of declarations of type families and constants that inhabit those type families. For example, the following is the standard definition of the [[natural numbers]], with &lt;code&gt;z&lt;/code&gt; standing for zero and &lt;code&gt;s&lt;/code&gt; the successor operator.

 nat : type.
 
 z : nat.
 s : nat -&gt; nat.

Here &lt;code&gt;nat&lt;/code&gt; is a type, and &lt;code&gt;z&lt;/code&gt; and &lt;code&gt;s&lt;/code&gt; are constant terms. As a [[dependent type|dependently typed]] system, types can be indexed by terms, which allows the definition of more interesting type families (relations). Here is a definition of addition:

 plus : nat -&gt; nat -&gt; nat -&gt; type.
 
 plus_zero : {M:nat} plus M z M.
 
 plus_succ : {M:nat} {N:nat} {P:nat}
             plus M (s N) (s P)
          &lt;- plus M N P.

The type family &lt;code&gt;plus&lt;/code&gt; is read as a relation between three natural numbers &lt;code&gt;M&lt;/code&gt;, &lt;code&gt;N&lt;/code&gt; and &lt;code&gt;P&lt;/code&gt;, such that M + N = P. We then give the constants that define the relation: &lt;code&gt;plus_zero&lt;/code&gt; indicates that any natural number &lt;code&gt;M&lt;/code&gt; plus zero is still &lt;code&gt;M&lt;/code&gt;. The quantifier &lt;code&gt;{M:nat}&lt;/code&gt; can be read as "for all &lt;code&gt;M&lt;/code&gt; of type &lt;code&gt;nat&lt;/code&gt;".

The constant &lt;code&gt;plus_succ&lt;/code&gt; defines the case for when the second argument is the successor of some other number &lt;code&gt;N&lt;/code&gt; (see [[pattern matching]]). The result is the successor of &lt;code&gt;P&lt;/code&gt;, where &lt;code&gt;P&lt;/code&gt; is the sum of &lt;code&gt;M&lt;/code&gt; and &lt;code&gt;N&lt;/code&gt;. This [[recursion|recursive]] call is made via the subgoal &lt;code&gt;plus M N P&lt;/code&gt;, introduced with &lt;code&gt;&amp;lt;-&lt;/code&gt;. The arrow can be understood operationally as Prolog's &lt;code&gt;:-&lt;/code&gt;, or as logical implication ("if M + N = P, then M + (s N) = (s P)"), or most faithfully to the type theory, as the type of the constant &lt;code&gt;plus_succ&lt;/code&gt; ("when given a term of type &lt;code&gt;plus M N P&lt;/code&gt;, return a term of type &lt;code&gt;plus M (s N) (s P)&lt;/code&gt;").

Twelf features type reconstruction and supports implicit parameters, so in practice one usually does not need to explicitly write &lt;code&gt;{M:nat}&lt;/code&gt; (etc.) above.

These simple examples do not display LF's higher-order features, nor any of its theorem checking capabilities. See the Twelf distribution for its included examples.
&lt;!-- to-do: example that is higher order --&gt;
&lt;!-- to-do: concept of canonical forms --&gt;

==Uses==
Twelf is used in several different ways.

===Logic programming===
Twelf signatures can be executed via a search procedure, so Twelf can be used as a [[logic programming]] language. Its core is more sophisticated than [[Prolog]], since it is higher-order and dependently typed, but it is restricted to pure operators: there is no cut or other extralogical operators (such as ones for performing [[input/output|I/O]]) as are often found in Prolog implementations, which may make it less well-suited for practical logic programming applications.  Some of the use of cut rule as used in Prolog is obtained through the ability to declare that certain operators belong to deterministic type families, which avoids recalculation. Also, like [[λProlog]], Twelf generalizes the [[Horn clause]]s underlying Prolog to [[Harrop formula#Hereditary Harrop formulae and logic programming|hereditary Harrop formulas]], which allow for logically well-founded operational notions of fresh-name generation and scoped extension of the clause database.
&lt;!-- theorem prover?? --&gt;

===Formalizing mathematics===
Twelf's main use today is as a system for formalizing mathematics (especially the metatheory of [[programming language]]s). Used this way it is closely related to [[Coq]] and [[Isabelle theorem prover|Isabelle]]/[[HOL theorem prover|HOL]]/[[HOL Light]]. However, unlike those systems, Twelf proofs are typically developed by hand. Despite this, for the problem domains at which it excels, Twelf proofs are often shorter and easier to develop than in the automated, general-purpose systems.

Twelf is particularly well suited to the encoding of programming languages and logics, because it has a built-in notion of binding and substitution. Most logics and programming languages of interest make use of binding and substitution. When implemented in Twelf, binders can often be directly encoded using the technique of [[higher-order abstract syntax]] (HOAS), in which the meta-language (Twelf) binders are used to represent the object-level binders. As a consequence, standard theorems such as type-preserving substitution and [[Lambda calculus#α-conversion|alpha conversion]] come "for free".

Twelf has been used to formalize many different logics and programming languages (examples are included with the distribution). Among the larger projects are a proof of safety for the [[Standard ML]] programming language,&lt;ref&gt;{{cite conference
 | first = Daniel
 | last = Lee |author2=Karl Crary |author3=[[Robert Harper (computer scientist)|Robert Harper]]
 | title = Towards a Mechanized Metatheory of Standard ML
 | conference = Proceedings of the 2007 Symposium on the [[POPL|Principles of Programming Languages]]
 | date = January 2007
 | location = [[Nice]], [[France]]
 | url = http://www.cs.cmu.edu/~dklee/papers/tslf-popl.pdf
 | accessdate = 2007-02-08
|format=PDF}}&lt;/ref&gt; a foundational [[typed assembly language]] system from CMU,&lt;ref&gt;{{cite conference
 | first = Karl
 | last = Crary
 | title = Toward a Foundational Typed Assembly Language
 | conference = Proceedings of the 2003 Symposium on the [[POPL|Principles of Programming Languages]]
 | year = 2003
 | accessdate = 2007-02-08
 | url = http://www.cs.cmu.edu/~crary/papers/2003/talt/talt.pdf
}}&lt;/ref&gt; and a foundational [[proof carrying code]] system from Princeton.

==Implementation==
&lt;!-- to-do: history: ELF --&gt;

Twelf is written in [[Standard ML]] and binaries are available for [[Linux]] and [[Microsoft Windows]]. {{asof|2006}} it is under active development (mostly at [[Carnegie Mellon University]]).

== References ==
&lt;references/&gt;
&lt;!-- to-do: references, esp "a framework for defining logics" --&gt;

==External links==
* [http://twelf.org/ Twelf Project wiki]

[[Category:Dependently typed languages]]
[[Category:Logic programming languages]]
[[Category:Theorem proving software systems]]
[[Category:Type theory]]
[[Category:Logic in computer science]]</text>
      <sha1>hchjxn56ooa8756oou7pawdk7ok9yxp</sha1>
    </revision>
  </page>
  <page>
    <title>VeRoLog</title>
    <ns>0</ns>
    <id>49222617</id>
    <revision>
      <id>824761275</id>
      <parentid>773165651</parentid>
      <timestamp>2018-02-09T09:30:55Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Management science]] using [[WP:HC|HotCat]] not mentioned in article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3755">{{Infobox organization
| name = VeRoLog, European Working Group on Vehicle Routing and Logistics Optimization
| image =
| formation     = 2011
| status        = Working group
| purpose       = To promote research and favor contact with industry on routing optimization
| region        = Europe
| parent_organization = [[Association of European Operational Research Societies]] 
| website       = {{url|http://www.verolog.eu/}}
}}

The '''European Working Group on Vehicle Routing and Logistics Optimization''' (also, '''EWG VeRoLog''', or simply '''VeRoLog''') is a [[working group]] within EURO, the [[Association of European Operational Research Societies]]&lt;ref&gt;{{cite web|url=http://www.euro-online.org/ |title=EURO - The Association of European Operational Research Societies - Home |website=Euro-online.org |date=2012-07-10 |accessdate=2016-01-26}}&lt;/ref&gt; whose objective is to promote the application of [[operations research]] models, methods and tools to the field of [[vehicle routing]] and [[logistics]], and to encourage the exchange of information among practitioners, end-users, and researchers, stimulating the work on new and important problems with sound scientific methods.&lt;ref&gt;{{cite web|url=http://www.euro-online.org/web/ewg/34/verolog-ewg-on-vehicle-routing-and-logistics-optimization |title=EURO - The Association of European Operational Research Societies - VeRoLog, EWG on Vehicle Routing and Logistics Optimization |website=Euro-online.org |date=2014-11-21 |accessdate=2016-01-26}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.verolog.eu |title=What is VeRoLog|website=Verolog.eu |date= |accessdate=2016-01-26}}&lt;/ref&gt;

== History ==
VeRoLog is one of the working groups of EURO, the [[Association of European Operational Research Societies]].  The Group was founded in 2011 by Daniele Vigo, Marielle Christiansen, Angel Corberan,  Wout Dullaert, Richard Eglese, Geir Hasle, Stefan Irnich,  Frederic Semet and Maria Grazia Speranza.		
								
==Governance==
The group is managed by a Coordinator and an Advisory Board including the founding members. The current coordinator is Daniele Vigo.&lt;ref&gt;{{cite web|url=http://or.dei.unibo.it/staff/daniele-vigo |title=Daniele Vigo &amp;#124; Operations Research Group Bologna |website=Or.dei.unibo.it |date= |accessdate=2016-01-26}}&lt;/ref&gt;

==Membership==
The group is suitable for people who are presently engaged in Vehicle Routing and Logistics, either in theoretical aspects or in business, industry or public administration applications. Currently (2015), the group has about 1,500 members from 67 countries.

==Conferences==
VeRoLog holds conferences on a regular basis (once a year during Summer) and issues every year an award to the best doctoral dissertation on vehicle routing and logistics optimization.

==Publications==
In most cases, the annual conference is followed by a peer reviewed special issue of an international journal, presenting a selection of the contributions presented at the meeting. Recent special issues appeared on ''[[European Journal of Operational Research]]'',&lt;ref&gt;{{cite web|url=http://www.sciencedirect.com/science/journal/03772217/236/3 |title=European Journal of Operational Research |volume=236 |pages=787–1008 |date=1 August 2014 |website=ScienceDirect.com |accessdate=2016-01-26}}&lt;/ref&gt; and ''Computers and Operations Research''.&lt;ref&gt;{{cite web|url=http://www.sciencedirect.com/science/journal/03050548/55 |title=Computers &amp; Operations Research |volume=55 |pages=1–240 |date=March 2015 |website=ScienceDirect.com |accessdate=2016-01-26}}&lt;/ref&gt;

A newsletter is emailed to all members every month.

==References==
{{Reflist}}

[[Category:Operations research]]
[[Category:Working groups]]
[[Category:Organizations established in 2011]]


{{Europe-org-stub}}</text>
      <sha1>47hre31k2abz9ygvy8qlu1wsdf4pcrl</sha1>
    </revision>
  </page>
  <page>
    <title>Vitali covering lemma</title>
    <ns>0</ns>
    <id>10102876</id>
    <revision>
      <id>827682467</id>
      <parentid>827682435</parentid>
      <timestamp>2018-02-26T03:15:45Z</timestamp>
      <contributor>
        <username>Timmy Chan</username>
        <id>33174037</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22928">
In [[mathematics]], the '''Vitali covering lemma''' is a [[combinatorial geometry|combinatorial and geometric]] result commonly used in [[measure theory]] of [[Euclidean space]]s. This lemma is an intermediate step, of independent interest, in the proof of the '''Vitali covering theorem'''. The covering theorem is credited to the [[Italy|Italian]] mathematician [[Giuseppe Vitali]].&lt;ref name="Vitali.1908"&gt;{{harv|Vitali|1908}}.&lt;/ref&gt; The theorem states that it is possible to cover, up to a [[Null set|Lebesgue-negligible set]], a given subset ''E''&amp;thinsp; of '''R'''&lt;sup&gt;''d''&lt;/sup&gt; by a disjoint family extracted from a ''Vitali covering'' of ''E''.

== Vitali covering lemma ==
[[File:Vitali Covering Lemma in R1.gif|thumb|right|300px|Visualization of the lemma in &lt;math&gt; \R^1&lt;/math&gt;.]]
[[File:Vitali covering lemma.svg|thumb|right|300px|On the top: a collection of balls; the green balls are the disjoint subcollection. On the bottom: the subcollection with three times the radius covers all the balls.]]


=== Statement of the lemma ===
* '''Finite version:''' Let &lt;math&gt; B_{1}, \ldots, B_{n} &lt;/math&gt; be any finite collection of  [[Ball (mathematics)|balls]]  contained in d-[[dimension]]al [[Euclidean space]] '''R'''&lt;sup&gt;''d''&lt;/sup&gt; (or, more generally, in an arbitrary [[metric space]]). Then there exists a subcollection &lt;math&gt; B_{j_{1}}, B_{j_{2}}, \dots, B_{j_{m}} &lt;/math&gt; of these balls which are [[Disjoint sets|disjoint]] and satisfy

:: &lt;math&gt; B_{1}\cup B_{2}\cup\ldots \cup B_{n}\subseteq 3B_{j_{1}}\cup 3B_{j_{2}}\cup\ldots \cup 3B_{j_{m}}&lt;/math&gt;

:where &lt;math&gt; 3B_{j_{k}}&lt;/math&gt; denotes the ball with the same center as &lt;math&gt;B_{j_{k}}&lt;/math&gt; but with three times the radius.

*'''Infinite version:''' Let &lt;math&gt; \{B_{j}:j\in J\}&lt;/math&gt; be an arbitrary collection  of balls in '''R'''&lt;sup&gt;''d''&lt;/sup&gt; (or, more generally, in a metric space) such that

::: &lt;math&gt; \sup \, \{ \mathrm{rad}(B_j) : j \in J \} &lt;\infty &lt;/math&gt;

:where &lt;math&gt; \mathrm{rad}(B_j) &lt;/math&gt; denotes the radius of the ball ''B&lt;sub&gt;j&lt;/sub&gt;''. Then there exists a countable subcollection

:::&lt;math&gt; \{B_j:j\in J'\}, \quad J'\subset J&lt;/math&gt;

:of balls from the original collection which are disjoint and satisfy

:::&lt;math&gt; \bigcup_{j\in J} B_{j}\subseteq \bigcup_{j\in J'} 5\,B_{j}. &lt;/math&gt;

'''Comments'''.
*The balls can have the form ''B''&amp;nbsp;= {''y''&amp;nbsp;:&amp;nbsp;''d''(''y'',&amp;nbsp;''c'')&amp;nbsp;&lt;&amp;nbsp;''r''} (an open ball with center ''c'' and radius ''r'') or ''B''&amp;nbsp;= {''y''&amp;nbsp;:&amp;nbsp;''d''(''y'',&amp;nbsp;''c'')&amp;nbsp;≤&amp;nbsp;''r''}.  Then 3&amp;nbsp;''B'' (or 5&amp;nbsp;''B'') denotes the ball of the same form, with 3&amp;nbsp;''r'' (or 5&amp;nbsp;''r'') replacing ''r''.  Notice that the [[Ball (mathematics)#Balls in general metric spaces|definition of balls]] requires ''r''&amp;nbsp;&gt;&amp;nbsp;0.
*In the ''infinite version'', the collection of balls can be [[countable]] or [[uncountable]].
*The result may fail if the radii are not bounded: consider the family of all balls centered at 0 in '''R'''&lt;sup&gt;''d''&lt;/sup&gt;; any disjoint subfamily consists of only one ball ''B'', and 5&amp;nbsp;''B'' does not contain all the balls in this family.
*In the context of a general metric space the resulting subcollection may not be countably infinite.

===Proof===

====Finite version====

Without loss of generality, we assume that the collection of balls is not empty; that is, ''n''&amp;nbsp;&gt; 0. Let &lt;math&gt;B_{j_1}&lt;/math&gt; be the ball of largest radius. Inductively, assume that &lt;math&gt;B_{j_1},\dots,B_{j_k}&lt;/math&gt; have been chosen. If there is some ball in &lt;math&gt;B_1,\dots,B_n&lt;/math&gt; that is disjoint from &lt;math&gt;B_{j_1}\cup B_{j_2}\cup\cdots\cup B_{j_k}&lt;/math&gt;, let &lt;math&gt;B_{j_{k+1}}&lt;/math&gt; be such ball with maximal radius (breaking ties arbitrarily), otherwise, we set ''m''&amp;nbsp;:= ''k'' and terminate the inductive definition.

Now set &lt;math&gt;X:=\bigcup_{k=1}^m 3\,B_{j_k}&lt;/math&gt;. It remains to show that &lt;math&gt; B_i\subset X&lt;/math&gt; for every &lt;math&gt;i=1,2,\dots,n&lt;/math&gt;. This is clear if &lt;math&gt;i\in\{j_1,\dots,j_m\}&lt;/math&gt;. Otherwise, there necessarily is some &lt;math&gt;k\in\{1,\dots,m\}&lt;/math&gt; such that ''B''&lt;sub&gt;''i''&lt;/sub&gt; intersects &lt;math&gt;B_{j_k}&lt;/math&gt; and the radius of &lt;math&gt;B_{j_k}&lt;/math&gt; is at least as large as that of ''B''&lt;sub&gt;''i''&lt;/sub&gt;. The [[triangle inequality]] then easily implies that &lt;math&gt;B_i\subset 3\,B_{j_k}\subset X&lt;/math&gt;, as needed. This completes the proof of the finite version.

====Infinite version====

Let '''F''' denote the collection of all balls ''B&lt;sub&gt;j&lt;/sub&gt;'', ''j''&amp;nbsp;∈ ''J'', that are given in the statement of the ''covering lemma''.  The following result provides a certain disjoint subcollection '''G''' of '''F'''. If this subcollection '''G''' is described as &lt;math&gt;\{ B_j, j \in J'\}&lt;/math&gt;, the property of '''G''', stated below, readily proves that
::&lt;math&gt; \bigcup_{j\in J} B_j \subseteq \bigcup_{j \in J'} 5\,B_{j}.&lt;/math&gt;

'''Precise form of the covering lemma.''' ''Let''&amp;thinsp; '''F''' ''be a collection of (nondegenerate) balls in a metric space, with bounded radii. There exists a disjoint subcollection''&amp;thinsp; '''G''' ''of''&amp;thinsp; '''F''' ''with the following property:''
::''every ball B in''&amp;thinsp; '''F''' ''intersects a ball C in''&amp;thinsp; '''G''' ''such that B&amp;nbsp;⊂&amp;nbsp;5&amp;nbsp;C.''

(''Degenerate balls'' only contain the center; they are excluded from this discussion.)&lt;br /&gt;
Let ''R''&amp;thinsp; be the supremum of the radii of balls in '''F'''.  Consider the partition of '''F''' into subcollections '''F'''&lt;sub&gt;''n''&lt;/sub&gt;, ''n''&amp;nbsp;≥ 0, consisting of balls ''B''&amp;thinsp; whose radius is in (2&lt;sup&gt;−''n''−1&lt;/sup&gt;''R'', 2&lt;sup&gt;−''n''&lt;/sup&gt;''R''].  A sequence '''G'''&lt;sub&gt;''n''&lt;/sub&gt;, with '''G'''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;⊂ '''F'''&lt;sub&gt;''n''&lt;/sub&gt;, is defined inductively as follows.  First, set '''H'''&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;= '''F'''&lt;sub&gt;0&lt;/sub&gt; and let '''G'''&lt;sub&gt;0&lt;/sub&gt; be a maximal disjoint subcollection of '''H'''&lt;sub&gt;0&lt;/sub&gt;. Assuming that '''G'''&lt;sub&gt;0&lt;/sub&gt;,...,'''G'''&lt;sub&gt;''n''&lt;/sub&gt; have been selected, let
:&lt;math&gt; \mathbf{H}_{n+1} = \{ B \in \mathbf{F}_{n+1} : \ B \cap C = \emptyset, \ \ \forall C \in \mathbf{G}_0 \cup \mathbf{G}_1 \cup \ldots \cup \mathbf{G}_n \}, &lt;/math&gt;
and let '''G'''&lt;sub&gt;''n''+1&lt;/sub&gt; be a maximal disjoint subcollection of  '''H'''&lt;sub&gt;''n''+1&lt;/sub&gt;. The subcollection
::&lt;math&gt;\mathbf{G} := \bigcup_{n=0}^\infty \mathbf{G}_n&lt;/math&gt;
of '''F''' satisfies the requirements: '''G''' is a disjoint collection, and every ball ''B''&amp;nbsp;∈ '''F''' intersects a ball ''C''&amp;nbsp;∈ '''G''' such that ''B''&amp;nbsp;⊂&amp;nbsp;5&amp;nbsp;''C''.&lt;br /&gt;
Indeed, let ''n''&amp;thinsp; be such that ''B''&amp;thinsp; belongs to '''F'''&lt;sub&gt;''n''&lt;/sub&gt;.  Either ''B''&amp;thinsp; does not belong to '''H'''&lt;sub&gt;''n''&lt;/sub&gt;, which implies ''n''&amp;nbsp;&gt; 0 and means that ''B''&amp;thinsp; intersects a ball from the union of '''G'''&lt;sub&gt;0&lt;/sub&gt;,...,'''G'''&lt;sub&gt;''n''−1&lt;/sub&gt;, or ''B''&amp;nbsp;∈ '''H'''&lt;sub&gt;''n''&lt;/sub&gt; and by maximality of '''G'''&lt;sub&gt;''n''&lt;/sub&gt;, ''B''&amp;thinsp; intersects a ball in  '''G'''&lt;sub&gt;''n''&lt;/sub&gt;.  In any case, ''B''&amp;thinsp; intersects a ball ''C''&amp;thinsp; that belongs to the union of '''G'''&lt;sub&gt;0&lt;/sub&gt;,...,'''G'''&lt;sub&gt;''n''&lt;/sub&gt;.  Such a ball ''C''&amp;thinsp; has radius &gt;&amp;nbsp;2&lt;sup&gt;−''n''−1&lt;/sup&gt;''R''.  Since the radius of ''B''&amp;thinsp; is ≤&amp;nbsp;2&lt;sup&gt;−''n''&lt;/sup&gt;''R'', it is less than twice that of ''C''&amp;thinsp; and the conclusion ''B''&amp;nbsp;⊂ 5&amp;nbsp;''C''&amp;thinsp; follows from the triangle inequality as in the finite version.&lt;ref&gt;The proof given is based on {{harv|Evans|Gariepy|1992|loc= section 1.5.1}}&lt;/ref&gt;

====Remarks====
*The constant 5 is not optimal. If the scale ''c''&lt;sup&gt;−''n''&lt;/sup&gt;, ''c''&amp;nbsp;&gt; 1, is used instead of 2&lt;sup&gt;−''n''&lt;/sup&gt; for defining '''F'''&lt;sub&gt;''n''&lt;/sub&gt;, the final value is 1&amp;nbsp;+&amp;nbsp;2''c'' instead of 5. Any constant larger than 3 gives a correct statement of the lemma, but not 3.
*In the most general case of an arbitrary metric space, the selection of a maximal disjoint subcollection requires a form of [[Zorn's lemma]].
*Using a finer analysis, when the original collection '''F''' is a ''Vitali covering'' of a subset ''E''&amp;thinsp; of '''R'''&lt;sup&gt;''d''&lt;/sup&gt;, one shows that the subcollection '''G''', defined in the above proof, covers ''E''&amp;thinsp; up to a Lebesgue-negligible set. &lt;ref&gt;See the [[Vitali covering lemma#From the covering lemma to the covering theorem|"''From the covering lemma to the covering theorem''"]] section of this entry.
&lt;/ref&gt;
===Applications and method of use===

An application of the Vitali lemma is in proving the [[Hardy–Littlewood maximal inequality]]. As in this proof, the Vitali lemma is frequently used when we are, for instance, considering the ''d''-dimensional [[Lebesgue measure]], &lt;math&gt;\lambda_d&lt;/math&gt;, of a [[Set (mathematics)|set]] ''E''&amp;nbsp;⊂ '''R'''&lt;sup&gt;''d''&lt;/sup&gt;, which we know is contained in the union of a certain collection of balls &lt;math&gt; \{B_{j}:j\in J\}&lt;/math&gt;, each of which has a measure we can more easily compute, or has a special property one would like to exploit. Hence, if we compute the measure of this union, we will have an upper bound on the measure of ''E''. However, it is difficult to compute the measure of the union of all these balls if they overlap. By the Vitali lemma, we may choose a subcollection &lt;math&gt; \{B_{j}:j\in J'\} &lt;/math&gt; which is disjoint and such that &lt;math&gt;\bigcup_{j\in J'}5 B_j\supset \bigcup_{j\in J} B_j\supset E&lt;/math&gt;. Therefore,

:&lt;math&gt; \lambda_d(E)\leq \lambda_d \Bigl( \bigcup_{j\in J}B_{j} \Bigr) \leq \lambda_d \Bigl( \bigcup_{j\in J'}5B_{j} \Bigr)\leq \sum_{j\in J'} \lambda_d(5 B_{j}).&lt;/math&gt;

Now, since increasing the radius of a ''d''-dimensional ball by a factor of five increases its volume by a factor of 5&lt;sup&gt;''d''&lt;/sup&gt;, we know that

:&lt;math&gt; \sum_{j\in J'} \lambda_d(5B_{j}) = 5^d \sum_{j\in J'} \lambda_d(B_{j})&lt;/math&gt;

and thus

:&lt;math&gt; \lambda_d(E) \leq 5^{d} \sum_{j\in J'}\lambda_d(B_{j}). &lt;/math&gt;

==Vitali covering theorem==

In the covering theorem, the aim is to cover, ''up to''&amp;thinsp; a "negligible set", a given set ''E''&amp;nbsp;⊆&amp;nbsp;'''R'''&lt;sup&gt;''d''&lt;/sup&gt; by a disjoint subcollection extracted from a  ''Vitali covering'' for&amp;nbsp;''E''&amp;nbsp;: a '''Vitali class''' or '''Vitali covering''' &lt;math&gt; \mathcal{V} &lt;/math&gt; for ''E''&amp;thinsp; is a collection of sets such that, for every ''x''&amp;nbsp;∈&amp;nbsp;''E''&amp;thinsp; and ''δ''&amp;nbsp;&amp;gt;&amp;nbsp;0, there is a set ''U''&amp;thinsp; in the collection &lt;math&gt;\mathcal{V}&lt;/math&gt; such that ''x''&amp;nbsp;∈&amp;nbsp;''U''&amp;thinsp; and the [[diameter]] of ''U''&amp;thinsp; is non-zero and less than&amp;nbsp;''δ''.

In the classical setting of Vitali,&lt;ref name="Vitali.1908" /&gt; the negligible set is a ''Lebesgue negligible set'', but measures other than the Lebesgue measure, and spaces other than '''R'''&lt;sup&gt;''d''&lt;/sup&gt; have also been considered, as is shown in the relevant section below.

The following observation is useful: if &lt;math&gt;\mathcal{V}&lt;/math&gt; is a Vitali covering for ''E''&amp;thinsp; and if ''E''&amp;thinsp; is contained in an open set ''Ω''&amp;nbsp;⊆&amp;nbsp;'''R'''&lt;sup&gt;''d''&lt;/sup&gt;, then the subcollection of sets ''U''&amp;thinsp; in &lt;math&gt;\mathcal{V}&lt;/math&gt; that are contained in ''Ω''&amp;thinsp; is also a Vitali covering for ''E''.

===Vitali's covering theorem for the Lebesgue measure===

The next covering theorem for the Lebesgue measure ''λ''&lt;sub&gt;''d''&lt;/sub&gt; is due to {{harvtxt|Lebesgue|1910}}.  A collection &lt;math&gt; \mathcal{V} &lt;/math&gt; of measurable subsets of '''R'''&lt;sup&gt;''d''&lt;/sup&gt; is a ''regular family'' (in the sense of [[Henri Lebesgue|Lebesgue]]) if there exists a constant ''C''&amp;thinsp; such that
:&lt;math&gt;\mathrm{diam}(V)^d \le C \, \lambda_d(V)&lt;/math&gt;
for every set ''V''&amp;thinsp; in the collection &lt;math&gt;\mathcal{V}&lt;/math&gt;.&lt;br /&gt;
The family of cubes is an example of regular family &lt;math&gt;\mathcal{V}&lt;/math&gt;, as is the family &lt;math&gt;\mathcal{V}&lt;/math&gt;(''m'') of rectangles in '''R'''&lt;sup&gt;2&lt;/sup&gt; such that the ratio of sides stays between ''m''&lt;sup&gt;−1&lt;/sup&gt; and ''m'', for some fixed ''m''&amp;nbsp;≥&amp;nbsp;1. If an arbitrary norm is given on '''R'''&lt;sup&gt;''d''&lt;/sup&gt;, the family of balls for the metric associated to the norm is another example. To the contrary, the family of ''all''&amp;thinsp; rectangles in '''R'''&lt;sup&gt;2&lt;/sup&gt; is ''not''&amp;thinsp; regular.

'''Theorem.''' Let ''E''&amp;nbsp;⊆&amp;nbsp;'''R'''&lt;sup&gt;''d''&lt;/sup&gt; be a measurable set with finite Lebesgue measure, and let &lt;math&gt;\mathcal{V}&lt;/math&gt; be a regular family of closed subsets of '''R'''&lt;sup&gt;''d''&lt;/sup&gt; that is a Vitali covering for ''E''. Then there exists a finite or countably infinite disjoint subcollection &lt;math&gt;\{U_{j}\}\subseteq \mathcal{V}&lt;/math&gt; such that

:&lt;math&gt; \lambda_d \Bigl( E \setminus \bigcup_{j}U_{j} \Bigr) = 0.&lt;/math&gt;

The original result of {{harvtxt|Vitali|1908}} is a special case of this theorem, in which ''d''&amp;nbsp;= 1 and &lt;math&gt;\mathcal{V}&lt;/math&gt; is a collection of intervals that is a Vitali covering for a measurable subset ''E''&amp;thinsp; of the real line having finite measure.
&lt;br /&gt;
The theorem above remains true without assuming that ''E''&amp;thinsp; has finite measure.  This is obtained by applying the covering result in the finite measure case, for every integer ''n''&amp;nbsp;≥&amp;nbsp;0, to the portion of ''E''&amp;thinsp; contained in the open annulus ''Ω&lt;sub&gt;n&lt;/sub&gt;'' of points ''x'' such that ''n''&amp;nbsp;&lt; |''x''|&amp;nbsp;&lt; ''n''+1.&lt;ref&gt;See {{harv|Evans|Gariepy|1992}}.&lt;/ref&gt;

A somewhat related covering theorem is the [[Besicovitch covering theorem]]. To each point ''a'' of a subset ''A''&amp;nbsp;⊆&amp;nbsp;'''R'''&lt;sup&gt;''d''&lt;/sup&gt;, a Euclidean ball  ''B''(''a'',&amp;nbsp;''r&lt;sub&gt;a&lt;/sub&gt;'') with center ''a'' and positive radius ''r&lt;sub&gt;a&lt;/sub&gt;'' is assigned. Then, as in the Vitali theorem, a subcollection of these balls is selected in order to cover ''A'' in a specific way. The main differences with the Vitali covering theorem are that on one hand, the disjointness requirement of Vitali is relaxed to the fact that the number ''N''&lt;sub&gt;''x''&lt;/sub&gt; of the selected balls containing an arbitrary point ''x''&amp;nbsp;∈&amp;nbsp;'''R'''&lt;sup&gt;''d''&lt;/sup&gt; is bounded by a constant ''B''&lt;sub&gt;''d''&lt;/sub&gt;&amp;thinsp; depending only upon the dimension ''d''; on the other hand, the selected balls do cover the set ''A'' of all the given centers.&lt;ref&gt;{{harvtxt|Vitali|1908}} allowed a negligible error.&lt;/ref&gt;

===Vitali's covering theorem for the Hausdorff measure===

One may have a similar objective when considering [[Hausdorff measure]] instead of Lebesgue measure.  The following theorem applies in that case.&lt;ref&gt;{{harv|Falconer|1986}}.&lt;/ref&gt;

'''Theorem.''' Let ''H''&lt;sup&gt;''s''&lt;/sup&gt; denote ''s''-dimensional Hausdorff measure, let ''E''&amp;nbsp;⊆&amp;nbsp;'''R'''&lt;sup&gt;''d''&lt;/sup&gt; be an ''H''&lt;sup&gt;''s''&lt;/sup&gt;-[[measurable]] set and &lt;math&gt;\mathcal{V}&lt;/math&gt; a Vitali class
of closed sets for ''E''. Then there exists a (finite or countably infinite) disjoint subcollection &lt;math&gt;\{U_{j}\}\subseteq \mathcal{V}&lt;/math&gt; such that either

:&lt;math&gt; H^{s} \left( E\backslash \bigcup_{j}U_{j} \right)=0 \  \mbox{ or }\sum_{j} \mathrm{diam} (U_{j})^{s}=\infty.&lt;/math&gt;

Furthermore, if ''E''&amp;thinsp; has finite ''s''-dimensional Hausdorff measure, then for any ''ε''&amp;nbsp;&amp;gt;&amp;nbsp;0, we may choose this subcollection {''U''&lt;sub&gt;''j''&lt;/sub&gt;} such that

:&lt;math&gt; H^{s}(E)\leq \sum_{j} \mathrm{diam} (U_{j})^{s}+\varepsilon.&lt;/math&gt;

This theorem implies the result of Lebesgue given above.  Indeed, when ''s''&amp;nbsp;= ''d'', the Hausdorff measure ''H''&lt;sup&gt;''s''&lt;/sup&gt; on  '''R'''&lt;sup&gt;''d''&lt;/sup&gt; coincides with a multiple of the ''d''-dimensional Lebesgue measure.  If a disjoint collection &lt;math&gt;\{U_{j}\}&lt;/math&gt; is regular and contained in a measurable region ''B''&amp;thinsp; with finite Lebesgue measure, then

:&lt;math&gt;\sum_j \mathrm{diam}(U_j)^d \le C \sum_j \lambda_d(U_j) \le C \, \lambda_d(B) &lt; +\infty&lt;/math&gt;

which excludes the second possibility in the first assertion of the previous theorem.  It follows that ''E''&amp;thinsp; is covered, up to a Lebesgue-negligible set, by the selected disjoint subcollection.

===From the covering lemma to the covering theorem===

The covering lemma can be used as intermediate step in the proof of the following basic form of the Vitali covering theorem. Actually, a little more is needed, namely the ''precised form of the covering lemma'' obtained in the [[Vitali covering lemma#Infinite version|"proof of the infinite version"]].

:'''Theorem.''' ''For every subset E of''&amp;thinsp; '''R'''&lt;sup&gt;d&lt;/sup&gt; ''and every Vitali cover of E by a  collection''&amp;thinsp; '''F''' ''of closed balls, there exists a disjoint subcollection''&amp;thinsp; '''G''' ''which covers E up to a Lebesgue-negligible set.''

Without loss of generality, one can assume that all balls in '''F''' are nondegenerate and have radius  ≤&amp;nbsp;1. By the ''precised form of the covering lemma'', there exists a disjoint subcollection '''G''' of '''F''' such that every ball ''B''&amp;nbsp;∈ '''F''' intersects a ball ''C''&amp;nbsp;∈ '''G''' for which ''B''&amp;nbsp;⊂&amp;nbsp;5&amp;nbsp;''C''. Let ''r''&amp;nbsp;&gt; 0 be given, and let ''Z''&amp;thinsp; denote the set of points ''z''&amp;nbsp;∈ ''E''&amp;thinsp; that are not contained in any ball from  '''G''' and belong to the ''open'' ball ''B''(''r'') of radius ''r'', centered at 0. It is enough to show that ''Z''&amp;thinsp; is Lebesgue-negligible, for every given ''r''.

Let ''G''&amp;thinsp; denote the subcollection of those balls in '''G''' that meet ''B''(''r'').  Consider the partition of ''G''&amp;thinsp; into sets ''G&lt;sub&gt;n&lt;/sub&gt;'', ''n''&amp;nbsp;≥ 0, consisting of balls that have radius in (2&lt;sup&gt;−n−1&lt;/sup&gt;,&amp;nbsp;2&lt;sup&gt;−n&lt;/sup&gt;].  Any ball ''B''&amp;thinsp; in '''F''' that meets ''B''(''r'') is contained in ''B''(''r''+2).  It follows from the disjointness property of '''G''' that

:&lt;math&gt; \sum \{ \lambda_d(C) : C \in G \} = \sum_{n=0}^\infty \Bigl(\sum \{ \lambda_d(C) : C \in G_n \} \Bigr) \le \lambda_d(B(r+2)) &lt; +\infty.&lt;/math&gt;

This implies that ''G&lt;sub&gt;n&lt;/sub&gt;'' is a finite set for every ''n''. Given
''ε''&amp;nbsp;&gt; 0, we may select ''N''&amp;thinsp; such that

:&lt;math&gt; \sum \{ \lambda_d(C) : C \in G_n, \, n &gt; N \} &lt; \varepsilon. &lt;/math&gt;

Let ''z''&amp;nbsp;∈ ''Z''&amp;thinsp; be fixed.  By definition of ''Z'', this point ''z'' does not belong to the closed set ''K''&amp;thinsp; equal to the (finite) union of balls in ''G&lt;sub&gt;k&lt;/sub&gt;'', ''k''&amp;nbsp;≤ ''N''.  By the Vitali cover property, one can find a ball ''B''&amp;nbsp;∈ '''F''' containing ''z'', contained in ''B''(''r'') and disjoint from ''K''.  By the property of '''G''', the ball ''B''&amp;thinsp; meets ''C''&amp;thinsp; and is included in  5&amp;nbsp;''C''&amp;thinsp; for some ball ''C''&amp;nbsp;∈ '''G'''. One sees that ''C''&amp;nbsp;∈ ''G''&amp;thinsp; because ''C''&amp;thinsp; intersects ''B''(''r''), but ''C''&amp;thinsp; does not belong to any family ''G&lt;sub&gt;k&lt;/sub&gt;'', ''k''&amp;nbsp;≤ ''N'', since ''B''&amp;thinsp; meets ''C''&amp;thinsp; but is disjoint from ''K''.  This proves that every point ''z''&amp;nbsp;∈ ''Z''&amp;thinsp; is contained in the union of 5&amp;nbsp;''C'', when ''C''&amp;thinsp; varies in ''G&lt;sub&gt;n&lt;/sub&gt;'', ''n''&amp;nbsp;&gt; ''N'', hence

:&lt;math&gt; Z \subset U_N := \bigcup \, \{ 5 \, C : C \in G_n, \, n &gt; N \}&lt;/math&gt;

and

:&lt;math&gt; \lambda_d(U_N) \le \sum \{ \lambda_d(5 \, C) : C \in G_n, \, n &gt; N \} = 5^d \sum \{ \lambda_d(C) : C \in G_n, \, n &gt; N \} &lt; 5^d \varepsilon. &lt;/math&gt;

Since ''ε''&amp;nbsp;&gt; 0 is arbitrary, this shows that ''Z''&amp;thinsp; is negligible.&lt;ref&gt;The proof given is based on {{Harv|Natanson|1955}}, with some notation taken from {{Harv|Evans|Gariepy|1992}}.&lt;/ref&gt;

===Infinite-dimensional spaces===

The Vitali covering theorem is not valid in infinite-dimensional settings. The first result in this direction was given by [[David Preiss]] in 1979:&lt;ref&gt;{{harv|Preiss|1979}}.&lt;/ref&gt; there exists a [[Gaussian measure]] ''γ'' on an (infinite-dimensional) [[separable space|separable]] [[Hilbert space]] ''H'' so that the Vitali covering theorem fails for (''H'',&amp;nbsp;Borel(''H''),&amp;nbsp;''γ''). This result was strengthened in 2003 by Jaroslav Tišer: the Vitali covering theorem in fact fails for ''every'' infinite-dimensional Gaussian measure on any (infinite-dimensional) separable Hilbert space.&lt;ref&gt;{{harv|Tišer|2003}}.&lt;/ref&gt;

==See also==
*[[Besicovitch covering theorem]]

==Notes==
{{reflist|30em}}

==References==
*{{Citation
|last=Evans
|first=Lawrence C.
|last2=Gariepy
|first2=Ronald F.
|title=Measure Theory and Fine Properties of Functions
|series=Studies in Advanced Mathematics
|place=[[Boca Raton, FL]]
|publisher=[[CRC Press]]
|year=1992
|pages=viii+268
|isbn =0-8493-7157-0 
|mr=1158660
|zbl=0804.28001
}}.
*{{citation
|last=Falconer
|first=Kenneth J.
|author-link=Kenneth Falconer (mathematician)
|title=The geometry of fractal sets
|series=Cambridge Tracts in Mathematics
|volume=85
|publisher=[[Cambridge University Press]]
|place=Cambridge
|year=1986
|pages=xiv+162
|isbn=0-521-25694-1
|mr=867284
|zbl=0587.28004
}}.
*{{springer|title=Vitali theorem|id=p/v096780}}
*{{citation
|last=Lebesgue
|first=Henri
|author-link=Henri Lebesgue
|title=Sur l'intégration des fonctions discontinues
|url=http://www.numdam.org/item?id=ASENS_1910_3_27__361_0
|journal=[[Annales Scientifiques de l'École Normale Supérieure]]
|volume=27
|year=1910
|pages=361–450
|jfm=41.0457.01
}}
*{{Citation
|last = Natanson
|first = I. P
|author-link=Isidor Natanson
|title = Theory of functions of a real variable
|publisher = [[Frederick Ungar Publishing Co.]]
|place = New York
|year = 1955
|pages = 277
|mr=0067952
|zbl=0064.29102
}}.
*{{citation
|last=Preiss
|first=David
|title=Gaussian measures and covering theorems
|journal=[[Commentatione Mathematicae Universitatis Carolinae]]
|volume=20
|year=1979
|issue=1
|pages=95–99
|issn=0010-2628
|mr=526149
|zbl=0386.28015
}}.
*{{cite book
|last = Stein
|first = Elias M.
|author-link=Elias Stein
|last2=Shakarchi
|first2=Rami
|title = Real analysis. Measure theory, integration, and Hilbert spaces
|series = Princeton Lectures in Analysis, III
|publisher = Princeton University Press
|location = [[Princeton, NJ]]
|year = 2005
|pages = xx+402
|isbn = 0-691-11386-6
|mr=2129625
|zbl=1081.28001
}}.
*{{citation
|last = Tišer
|first = Jaroslav
|title = Vitali covering theorem in Hilbert space
|journal = [[Transactions of the American Mathematical Society]]
|volume = 355
|year = 2003
|pages = 3277–3289 (electronic)
|doi = 10.1090/S0002-9947-03-03296-3
|issue = 8
|mr=1974687
|zbl=1042.28014
}}
*{{Citation
|last = Vitali
|first = Giuseppe
|author-link= Giuseppe Vitali
|title = Sui gruppi di punti e sulle funzioni di variabili reali
|journal = [[Atti dell'Accademia delle Scienze di Torino]]
|origyear = 17 December 1907
|year = 1908
|volume = 43
|pages = 75–92
|url = https://archive.org/stream/attidellarealeac43real#page/228/mode/2up
|language=Italian
|jfm = 39.0101.05
}}. (Title translation) "''On groups of points and functions of real variables''" is the paper containing the first proof of [[Vitali covering theorem]].

[[Category:Articles with inconsistent citation formats]]
[[Category:Covering lemmas]]
[[Category:Measure theory]]
[[Category:Real analysis]]</text>
      <sha1>n1w8nnl76npduhxg363lpk6v9bm2tcq</sha1>
    </revision>
  </page>
</mediawiki>
