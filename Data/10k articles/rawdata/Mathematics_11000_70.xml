<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Abdus Salam Award</title>
    <ns>0</ns>
    <id>27751051</id>
    <revision>
      <id>858376482</id>
      <parentid>807456677</parentid>
      <timestamp>2018-09-06T18:45:58Z</timestamp>
      <contributor>
        <username>Plucas58</username>
        <id>9766640</id>
      </contributor>
      <comment>copy-edit to avoid repetition</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5408">{{Infobox award
| name           =Abdus Salam Award
| current_awards =
| image          =
| imagesize      =
| alt            =
| caption        =
| description    =
| presenter      =[[ICTP|ICTP Chapter Pakistan]]
| country        ={{PAK}}
| location       =[[Islamabad]]
| year           =1981
| year2          =2012
| holder         =
| website        =
}}

The '''Abdus Salam Award''' (sometimes called the '''Salam Prize'''), is a most prestigious [[award]] that is awarded annually to [[Pakistan]]i nationals&lt;ref&gt;{{Cite web| last =   | first =   | authorlink =   | coauthors =   | title =Nominations sought for Abdus Salam Prize in Biology.   | work =   | publisher =   | date =   | url = http://www.thefreelibrary.com/Nominations+sought+for+Abdus+Salam+Prize+in+Biology.-a0197013559  | format =   | doi =   | accessdate = }}&lt;/ref&gt; to the field of [[chemistry]], [[mathematics]], [[physics]], [[biology]]. The award is awarded to the scientists who are resident in Pakistan, below 35 years of age on 31 December of the year for which the Prize was to be awarded.&lt;ref&gt;{{Cite web| last =   | first =   | authorlink =   | coauthors =   | title =Nominations sought for Abdus Salam Prize   | work =   | publisher =   | date =April 27, 2010   | url =http://news.wateen.com/modules/news/article.php?storyid=12829   | format =   | doi =   | accessdate = }}&lt;/ref&gt; It is to consist of a certificate giving a citation and a cash award of [[United States Dollar|US$]]1,000.&lt;ref&gt;{{Cite news| last =Staff Report | first = | coauthors = | title =Nominations for Salam Prize invited | newspaper =[[Daily Times (Pakistan)|The Daily Times]] | location =[[Islamabad]], [[Islamabad Capital Territory]] | pages = | publisher =[[Salmaan Taseer|Governor Salmaan Taseer]] | date =April 28, 2010 | url =http://www.dailytimes.com.pk/default.asp?page=2010%5C04%5C28%5Cstory_28-4-2010_pg11_6 | accessdate =4 October 2016 | archiveurl=https://web.archive.org/web/20110607024916/http://www.dailytimes.com.pk/default.asp?page=2010%5C04%5C28%5Cstory_28-4-2010_pg11_6 | archivedate = 7 June 2011 }}&lt;/ref&gt; It is to be awarded on the basis of the collected research and/or a technical essay written specially for the Prize&lt;ref name=tribute&gt;{{Cite web
  | last =Qadir
  | first =Asghar
  | authorlink =Asghar Qadir
  | coauthors =
  | title =Tribute to Abdus Salam
  | work =
  | publisher =www.chowk.com
  | date =January 11, 1998
  | url =http://www.chowk.com/articles/4109
  | doi =
  | accessdate =4 October 2016| archiveurl= https://web.archive.org/web/20100410044346/http://www.chowk.com/articles/4109| archivedate= 10 April 2010 &lt;!--DASHBot--&gt;| deadurl= yes}}&lt;/ref&gt;

The Award is a brainchild of [[Professor]] [[Abdus Salam]]'s students Dr. [[Riazuddin (physicist)|Riazuddin]], Dr. [[Fayyazuddin]] and Dr. [[Asghar Qadir]] who first presented the idea to [[Abdus Salam]] in 1979. Abdus Salam, who felt that he had no right to use the [[Nobel Prize|Prize money]] for personal purposes but that it must be used to further his mission of development of Science in the Third World. Abdus Salam specially put aside money to help Pakistan and Pakistani students. In 1980, Prof. Salam asked Prof. Fayyazuddin and Dr. Asghar Qadir to formulate the rules and procedures for a Prize to be awarded to young Pakistani scientists for their research in the basic sciences.&lt;ref name=tribute/&gt; Professor [[Asghar Qadir]] is currently the Secretary of Salam Prize Committee at [[NUST School of Natural Sciences|School of Natural Sciences (SNS)]] in [[National University of Sciences and Technology, Pakistan|National University of Sciences and Technology]] [[National University of Sciences and Technology (Pakistan)|(NUST)]]. 
==Recipients==
*1981: Dr. Nazma Ikram (Maiden name: Dr. Nazma Masud) – (Physics)
*''No award was given by Abdus Salam in 1982. According to him none of the nominations came close to the 1981 award winner Dr. Nazma Ikram.''
*1984: Dr. [[Pervaiz Hoodbhoy|Pervaiz Amirali Hoodbhoy]] – (Mathematics)
*1985: Dr. [[Mujahid Kamran]] - (Physics)
*1985: Dr. [[Mujaddid Ahmed Ijaz]] – (Physics)
*1986: Dr. [[Mohammad Suhail Zubairy|Muhammad Suhail Zubairy]] – (Physics)
*1986: Dr. Bina S. Siddiqui – (Chemistry)
*1987: Dr. [[Qaiser Mushtaq]] – (Mathematics)
*1990: Dr. M. Iqbal Choudhry– (Chemistry)
*1991: Dr. Ashfaque H. Bokhari – (Mathematics)
*1994: Dr. Anwar-ul Hassan Gilani – (Biology)
*1997: Dr. [[Asghar Qadir]] - (Mathematics)
*1998: Dr. Naseer Shahzad – (Mathematics)
*1999: Dr. [[Tasawar Hayat]] – {Mathematics)
*2000: Dr. Rabia Hussain – (Biology)
*2002: Dr. Muhammad Arif Malik - (Chemistry)
*2003: Dr. Ghulam Shabbir - (Mathematics)
*2009: Dr. Naseer-Ud-Din Shams – (Physics)
*2009: Dr. Tayyab Kamran – (Mathematics)
*2010: Dr. Muhammad Tahir - (Biology)
*2012: Dr. [[Amer Iqbal]] — (Physics)
*2012: Dr. Hafiz Zia-ur-Rehman - (Chemistry), Department of Chemistry, Quaid-i-Azam University, Islamabad.
*2013: Dr. Rahim Umar - (Mathematics), Faculty of Engineering Sciences, Ghulam Ishaq Khan Institute of Engineering Sciences and Technology.

==Resources==
{{Reflist}}

{{DEFAULTSORT:Salam Award}}
[[Category:Physics awards]]
[[Category:Mathematics awards]]
[[Category:Chemistry awards]]
[[Category:Biology awards]]
[[Category:Pakistani science and technology awards]]
[[Category:Civil awards and decorations of Pakistan]]
[[Category:Awards established in 1980]]
[[Category:Abdus Salam]]</text>
      <sha1>pury4cdrs0maslw1185bibjg1cpy1lk</sha1>
    </revision>
  </page>
  <page>
    <title>Algorithmics</title>
    <ns>0</ns>
    <id>99861</id>
    <revision>
      <id>690305369</id>
      <parentid>688981267</parentid>
      <timestamp>2015-11-12T15:29:38Z</timestamp>
      <contributor>
        <username>Qwertyus</username>
        <id>196471</id>
      </contributor>
      <comment>removing undue weight on a single application</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="600">{{Main|algorithm}}

'''Algorithmics''' is the science of [[algorithm]]s. It includes [[algorithm design]], the art of building a procedure which can solve efficiently a specific problem or a class of problem, [[algorithmic complexity theory]], the study of estimating the hardness of problems by studying the properties of algorithm that solves them, or [[algorithm analysis]], the science of studying the properties of a problem, such as quantifying resources in time and memory space needed by this algorithm to solve this problem.

{{Computer science}}

[[Category:Algorithms]]

[[de:Algorithmik]]</text>
      <sha1>7wmwldz7i4plu34kj2810ry766vu9sy</sha1>
    </revision>
  </page>
  <page>
    <title>Anabelian geometry</title>
    <ns>0</ns>
    <id>27119265</id>
    <revision>
      <id>868656526</id>
      <parentid>864372440</parentid>
      <timestamp>2018-11-13T16:36:16Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Reformat 1 archive link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3659">'''Anabelian geometry''' is a theory in [[number theory]], which describes the way to which [[algebraic fundamental group]] ''G'' of a certain [[arithmetic variety]] ''V'', or some related geometric object, can help to restore ''V''. The first traditional conjectures, originating from [[Alexander Grothendieck]] and introduced in ''[[Esquisse d'un Programme]]'' were about how topological homomorphisms between two groups of two hyperbolic curves over number fields correspond to maps between the curves. These Grothendieck conjectures  were partially solved by H. Nakamura, A. Tamagawa, and complete proofs were given by [[Shinichi Mochizuki]]. Before anabelian geometry proper began with the famous letter to [[Gerd Faltings|Faltings]] and ''[[Esquisse d'un Programme]]'', the [[Neukirch–Uchida theorem]] hinted at the program from the perspective of Galois groups, which themselves can be shown to be étale fundamental groups.

More recently, [[Shinichi Mochizuki]] introduced and developed a so called mono-anabelian geometry which restores, for a certain class of hyperbolic curves over number fields, the curve from its algebraic fundamental group. Key results of mono-anabelian geometry were published in Mochizuki's "Topics in Absolute Anabelian Geometry."


==Formulation of a conjecture of Grothendieck on curves==
The "anabelian question" has been formulated as

{{cquote|How much information about the isomorphism class of the variety ''X'' is contained in the knowledge of the [[étale fundamental group]]?&lt;ref&gt;http://www.math.jussieu.fr/~leila/SchnepsLM.pdf, p. 2.&lt;/ref&gt;}}

A concrete example is the case of curves, which may be affine as well as projective. Suppose given a hyperbolic curve ''C'', i.e. the complement of ''n'' points in a projective [[algebraic curve]] of [[genus (curve)|genus]] ''g'', taken to be smooth and irreducible, defined over a field ''K'' that is finitely generated (over its [[prime field]]), such that

:&lt;math&gt;2 - 2g - n &lt; 0&lt;/math&gt;.

Grothendieck conjectured that the algebraic fundamental group ''G'' of ''C'', a [[profinite group]], determines ''C'' itself (i.e. the isomorphism class of ''G'' determines that of ''C''). This was proved by Mochizuki.&lt;ref&gt;{{cite journal | first=Shinichi | last=Mochizuki | authorlink=Shinichi Mochizuki| title=The profinite Grothendieck conjecture for closed hyperbolic curves over number fields | journal=J. Math. Sci. Univ. Tokyo | volume=3  | year=1996 | pages=571–627 | issue=3 | mr=1432110 | hdl=2261/1381}}&lt;/ref&gt; An example is for the case of ''g'' = 0 (the [[projective line]]) and ''n'' = 4, when the isomorphism class of ''C'' is determined by the [[cross-ratio]] in ''K'' of the four points removed (almost, there being an order to the four points in a cross-ratio, but not in the points removed).&lt;ref&gt;http://www.math.sci.osaka-u.ac.jp/~nakamura/zoo/lion/INanabel.pdf, p. 2.&lt;/ref&gt; There are also results for the case of ''K'' a [[local field]].&lt;ref&gt;{{Cite web |url=http://www.math.uiuc.edu/documenta/vol-kato/mochizuki.dm.pdf |title=Archived copy |access-date=2010-04-26 |archive-url=https://web.archive.org/web/20100620165417/http://www.math.uiuc.edu/documenta/vol-kato/mochizuki.dm.pdf |archive-date=2010-06-20 |dead-url=yes |df= }}&lt;/ref&gt;

==See also==

*[[Neukirch–Uchida theorem]]

==Notes==
{{reflist}}

==External links==
*{{cite web|url=http://www.renyi.hu/~szamuely/heid.pdf|title=Heidelberg Lectures on Fundamental Groups|author=Tamás Szamuely|at=section 5}}

*{{cite web|url=https://github.com/carmonamateo/NotesAnabeliennes|title=Notes Anabéliennes|author=Alexander Grothendieck}}

{{DEFAULTSORT:Anabelian Geometry}}
[[Category:Algebraic geometry]]</text>
      <sha1>3747mx2qydf6l6yj0izopoe05tmxw9e</sha1>
    </revision>
  </page>
  <page>
    <title>Astrid an Huef</title>
    <ns>0</ns>
    <id>53960754</id>
    <revision>
      <id>794429494</id>
      <parentid>794330293</parentid>
      <timestamp>2017-08-08T00:09:15Z</timestamp>
      <contributor>
        <username>KasparBot</username>
        <id>24420788</id>
      </contributor>
      <comment>Authority control moved to Wikidata</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3052">'''Astrid an Huef''' is a German-born New Zealand mathematician who holds a Professorship at [[Victoria University of Wellington]].&lt;ref&gt;{{Cite web|url=http://www.victoria.ac.nz/sms/about/staff|title=VUW Maths Department Staff|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;   Until 2017 she held the Chair of Pure Mathematics at the [[University of Otago]]. Her research interests include [[functional analysis]], [[operator algebra]]s, and [[dynamical system]]s.{{r|staff}} She is the president of the [[New Zealand Mathematical Society]] for the 2016–2017 term.{{r|nzms|nzms-admin}}  

==Education and career==
An Huef was born in [[Karlsruhe]] and lived in New Zealand for two years as a teenager before moving to Australia in 1985. Because of the disruption to her education caused by these international moves, she was advised not to take higher mathematics in high school, but did so anyway. She began her undergraduate studies in [[computer science]] at the [[University of Newcastle (Australia)|University of Newcastle]], but ended up doing a double degree, with honours in mathematics. While there, she met [[Dartmouth College]] professor Dana Williams, who became her doctoral advisor at Dartmouth beginning in 1994.{{r|nzms}} She completed her doctorate in 1999.{{r|nzms|mgp}}

She took a tenure track position at the [[University of Denver]], and then worked at the [[University of New South Wales]] for eight years, before being given the chair at Otago in 2008.{{r|nzms}}  She currently coordinates the Women in Mathematics community of the New Zealand Mathematical Society.&lt;ref&gt;{{Cite web|url=https://nzmathsoc.org.nz/?wim|title=Association of women in mathematics nz|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;

==References==
{{reflist|refs=

&lt;ref name=mgp&gt;{{mathgenealogy|id=38404}}&lt;/ref&gt;

&lt;ref name=nzms&gt;{{citation|url=https://nzmathsoc.org.nz/downloads/centrefolds/NZMScentrefold127_Astrid_an_Huef.pdf|title=Profile: Astrid an Huef|journal=NZMS Newsletter|issue=127|pages=11–12|first=Miguel|last=Moyers|date=August 2016}}&lt;/ref&gt;

&lt;ref name=nzms-admin&gt;[https://nzmathsoc.org.nz/?membership Administration and Council], New Zealand Mathematical Society, retrieved 2017-05-04.&lt;/ref&gt;

&lt;ref name=staff&gt;[https://www.maths.otago.ac.nz/?people_maths Academic Mathematics Staff], [[University of Otago]], retrieved 2017-05-04.&lt;/ref&gt;

}}

{{Authority control}}

{{DEFAULTSORT:an Huef, Astrid}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:People from Karlsruhe]]
[[Category:New Zealand mathematicians]]
[[Category:Women mathematicians]]
[[Category:University of Newcastle (Australia) alumni]]
[[Category:Dartmouth College alumni]]
[[Category:University of Denver faculty]]
[[Category:University of New South Wales faculty]]
[[Category:University of Otago faculty]]
[[Category:20th-century New Zealand mathematicians]]
[[Category:21st-century New Zealand mathematicians]]
[[Category:German emigrants to New Zealand]]</text>
      <sha1>ci86rdbafzlommfquu6898ngupaw9gu</sha1>
    </revision>
  </page>
  <page>
    <title>Biased graph</title>
    <ns>0</ns>
    <id>2472880</id>
    <revision>
      <id>854931167</id>
      <parentid>810226717</parentid>
      <timestamp>2018-08-14T19:37:18Z</timestamp>
      <contributor>
        <username>Cycle space</username>
        <id>33365527</id>
      </contributor>
      <minor/>
      <comment>/* Matroids */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10275">In [[mathematics]], a '''biased graph''' is a [[graph theory|graph]] with a list of distinguished circles (edge sets of [[simple cycle]]s), such that if two circles in the list are contained in a [[glossary of graph theory|theta graph]], then the third circle of the theta graph is also in the list.  A biased graph is a generalization of the combinatorial essentials of a [[gain graph]] and in particular of a [[signed graph]].

Formally, a '''biased graph''' Ω is a pair (''G'', '''''B''''') where '''''B''''' is a '''linear class''' of circles; this by definition is a class of circles that satisfies the theta-graph property mentioned above.

A [[Glossary of graph theory#Subgraphs|subgraph]] or edge set whose circles are all in '''''B''''' (and which contains no [[Graph (discrete mathematics)|half-edges]]) is called '''balanced'''.  For instance, a circle belonging to '''''B''''' is ''balanced'' and one that does not belong to '''''B''''' is ''unbalanced''.

Biased graphs are interesting mostly because of their [[matroid]]s, but also because of their connection with multiary [[quasigroups]].  See below.

==Technical notes==

A biased graph may have [[Graph (discrete mathematics)|half-edges]] (one endpoint) and [[Graph (discrete mathematics)|loose edges]] (no endpoints).  The edges with two endpoints are of two kinds: a link has two distinct endpoints, while a loop has two coinciding endpoints.

Linear classes of circles are a special case of linear subclasses of circuits in a [[matroid]].

==Examples==

* If every circle belongs to '''''B''''', and there are no half-edges, Ω is balanced.  A balanced biased graph is (for most purposes) essentially the same as an ordinary graph.
* If '''''B''''' is empty, Ω is called '''contrabalanced'''.  Contrabalanced biased graphs are related to [[bicircular matroid]]s.
* If '''''B''''' consists of the circles of even length, Ω is called '''antibalanced''' and is the biased graph obtained from an all-negative [[signed graph]].
* The linear class '''''B''''' is '''additive''', that is, closed under repeated [[symmetric difference]] (when the result is a circle), [[if and only if]] '''''B''''' is the class of positive circles of a signed graph.
* Ω may have underlying graph that is a cycle of length ''n'' ≥ 3 with all edges doubled.  Call this a '''biased 2''C&lt;sub&gt;n&lt;/sub&gt;''''' .  Such biased graphs in which no [[digon]] (circle of length 2) is balanced lead to spikes and swirls (see Matroids, below).
* Some kinds of biased graph are obtained from [[gain graph]]s or are generalizations of special kinds of gain graph.  The latter include '''biased expansion graphs''', which generalize [[gain graph|group expansion graph]]s.

==Minors==

A [[Minor (graph theory)|minor]] of a biased graph Ω = (''G'', '''''B''''') is the result of any sequence of taking subgraphs and contracting edge sets.  For biased graphs, as for graphs, it suffices to take a subgraph (which may be the whole graph) and then contract an edge set (which may be the empty set).

A '''subgraph''' of Ω consists of a subgraph ''H'' of the underlying graph ''G'', with balanced circle class consisting of those balanced circles that are in ''H''.  The '''deletion''' of an edge set ''S'', written Ω &amp;minus; ''S'', is the subgraph with all vertices and all edges except those of ''S''.

'''Contraction''' of Ω is relatively complicated.  To contract one edge ''e'', the procedure depends on the kind of edge ''e'' is.  If ''e'' is a link, contract it in ''G''.  A circle ''C'' in the contraction ''G''/''e'' is balanced if either ''C'' or &lt;math&gt;C \cup e&lt;/math&gt; is a balanced circle of ''G''.   If ''e'' is a balanced loop or a loose edge, it is simply deleted.  If it is an unbalanced loop or a half-edge, it and its vertex ''v'' are deleted; each other edge with ''v'' as an endpoint loses that endpoint, so a link with ''v'' as one endpoint becomes a half-edge at its other endpoint, while a loop or half-edge at ''v'' becomes a loose edge.

In the contraction Ω/''S'' by an arbitrary edge set ''S'', the edge set is ''E'' &amp;minus; ''S''.  (We let ''G'' = (''V'', ''E'').)  The vertex set is the class of vertex sets of balanced components of the subgraph (''V'', ''S'') of Ω.  That is, if (''V'', ''S'') has balanced components with vertex sets ''V''&lt;sub&gt;1&lt;/sub&gt;, ..., ''V''&lt;sub&gt;''k''&lt;/sub&gt;, then Ω/''S'' has ''k'' vertices ''V''&lt;sub&gt;1&lt;/sub&gt;, ..., ''V''&lt;sub&gt;''k''&lt;/sub&gt; .  An edge ''e'' of Ω, not in ''S'', becomes an edge of Ω/''S'' and each endpoint ''v''&lt;sub&gt;''i''&lt;/sub&gt; of ''e'' in Ω that belongs to some ''V&lt;sub&gt;i&lt;/sub&gt;'' becomes the endpoint ''V&lt;sub&gt;i&lt;/sub&gt;'' of ''e'' in Ω/''S'' ; thus, an endpoint of ''e'' that is not in a balanced component of (''V'', ''S'') disappears.  An edge with all endpoints in unbalanced components of (''V'', ''S'') becomes a loose edge in the contraction.  An edge with only one endpoint in a balanced component of (''V'', ''S'') becomes a half-edge.  An edge with two endpoints that belong to different balanced components becomes a link, and an edge with two endpoints that belong to the same balanced component becomes a loop.

==Matroids==

There are two kinds of [[matroid]] associated with a biased graph, both of which generalize the cycle matroid of a graph (Zaslavsky, 1991).

===The frame matroid===

The '''frame matroid''' (sometimes called '''bias matroid''') of a biased graph, ''M''(Ω), (Zaslavsky, 1989) has for its ground set the edge set ''E''.  An edge set is independent if each component contains either no circles or just one circle, which is unbalanced.  (In matroid theory a half-edge acts like an unbalanced loop and a loose edge acts like a balanced loop.)  ''M''(Ω) is a [[Matroid#Additional terminology|frame matroid]] in the abstract sense, meaning that it is a submatroid of a matroid in which, for at least one basis, the set of lines generated by pairs of basis elements covers the whole matroid. Conversely, every abstract frame matroid is the frame matroid of some biased graph.

The circuits of the matroid are called '''frame circuits''' or '''bias circuits'''.  There are four kinds.  One is a balanced circle.  Two other kinds are a pair of unbalanced circles together with a connecting simple path, such that the two circles are either disjoint (then the connecting path has one end in common with each circle and is otherwise disjoint from both) or share just a single common vertex (in this case the connecting path is that single vertex).  The fourth kind of circuit is a theta graph in which every circle is unbalanced.

The rank of an edge set ''S'' is ''n'' &amp;minus; ''b'', where ''n'' is the number of vertices of ''G'' and ''b'' is the number of balanced components of ''S'', counting isolated vertices as balanced components.

Minors of the frame matroid agree with minors of the biased graph; that is, ''M''(Ω&amp;minus;''S'') = ''M''(Ω)&amp;minus;''S'' and ''M''(Ω/''S'') = ''M''(Ω)/''S''.

Frame matroids generalize the [[Dowling geometry|Dowling geometries]] associated with a group (Dowling, 1973).  The frame matroid of a biased 2''C''&lt;sub&gt;''n''&lt;/sub&gt; (see Examples, above) which has no balanced digons is called a '''swirl'''.  It is important in matroid structure theory.

===The lift matroid===

The '''extended lift matroid''' ''L''&lt;sub&gt;0&lt;/sub&gt;(Ω) has for its ground set the set ''E''&lt;sub&gt;0&lt;/sub&gt;, which is the union of ''E'' with an '''extra point''' ''e''&lt;sub&gt;0&lt;/sub&gt;.  The '''lift matroid''' ''L''(Ω) is the extended lift matroid restricted to ''E''.  The extra point acts exactly like an unbalanced loop or a half-edge, so we describe only the lift matroid.

An edge set is independent if it contains either no circles or just one circle, which is unbalanced.

A circuit is a balanced circle, a pair of unbalanced circles that are either disjoint or have just a common vertex, or a theta graph whose circles are all unbalanced.

The rank of an edge set ''S'' is ''n'' &amp;minus; ''c'' + ε, where ''c'' is the number of components of ''S'', counting isolated vertices, and ε is 0 if ''S'' is balanced and 1 if it is not.

Minors of the lift and extended lift matroids agree in part with minors of the biased graph.  Deletions agree: ''L''(Ω&amp;minus;''S'') = ''L''(Ω)&amp;minus;''S''.  Contractions agree only for balanced edge sets: ''M''(Ω/''S'') = ''M''(Ω)/''S'' if ''S'' is balanced, but not if it is unbalanced.  If ''S'' is unbalanced, ''M''(Ω/''S'') = ''M''(''G'')/''S'' = ''M''(''G''/''S'') where ''M'' of a graph denotes the ordinary [[Matroid#Matroids from graph theory|graphic matroid]].

The lift matroid of a 2''C''&lt;sub&gt;''n''&lt;/sub&gt; (see Examples, above) which has no balanced digons is called a '''spike'''.  Spikes are quite important in matroid structure theory.

==Multiary quasigroups==

Just as a group expansion of a complete graph ''K''&lt;sub&gt;''n''&lt;/sub&gt; encodes the group (see [[Dowling geometry]]), its combinatorial analog expanding a simple cycle of length ''n'' + 1 encodes an ''n''-ary (multiary) [[Quasigroup#Polyadic or multiary quasigroups|quasigroup]].  It is possible to prove theorems about multiary quasigroups by means of biased graphs (Zaslavsky, t.a.)

==References==

*T. A. Dowling (1973),  A class of geometric lattices based on finite groups.  ''Journal of Combinatorial Theory, Series B'', Vol. 14, pp.&amp;nbsp;61&amp;ndash;86.
*Thomas Zaslavsky (1989),  Biased graphs.  I.  Bias, balance, and gains.  ''Journal of Combinatorial Theory, Series B'', Vol. 47, pp.&amp;nbsp;32&amp;ndash;52.
*Thomas Zaslavsky (1991),  Biased graphs.  II.  The three matroids.  ''Journal of Combinatorial Theory, Series B'', Vol. 51, pp.&amp;nbsp;46&amp;ndash;72.
*Thomas Zaslavsky (1999).  A mathematical bibliography of signed and gain graphs and allied areas.  1999 edition: [https://web.archive.org/web/20100912123133/http://www.combinatorics.org/Surveys/index.html ''Electronic Journal of Combinatorics'', Dynamic Surveys in Combinatorics, #DS8, archived].  Current edition:  [http://www.combinatorics.org/issue/view/Surveys  ''Electronic Journal of Combinatorics'', Dynamic Surveys in Combinatorics, #DS8].
*Thomas Zaslavsky (2012),  Associativity in multiary quasigroups: the way of biased expansions.  ''[[Aequationes Mathematicae]]'', Vol. 83, pp.&amp;nbsp;1–66.

[[Category:Graph families]]
[[Category:Matroid theory]]</text>
      <sha1>ryjjqlvmiy9oqxixyqm7bhva4j1a5lz</sha1>
    </revision>
  </page>
  <page>
    <title>Biased representation (arithmetics)</title>
    <ns>0</ns>
    <id>49342088</id>
    <redirect title="Offset binary" />
    <revision>
      <id>703601263</id>
      <parentid>703600436</parentid>
      <timestamp>2016-02-06T13:34:06Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+cats</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="110">#redirect [[Offset binary]] {{R from other name}}

[[Category:Numeral systems]]
[[Category:Binary arithmetic]]</text>
      <sha1>pk3f6vvcht14341rzs72e9z703407id</sha1>
    </revision>
  </page>
  <page>
    <title>Braided vector space</title>
    <ns>0</ns>
    <id>32518704</id>
    <revision>
      <id>790661699</id>
      <parentid>616439124</parentid>
      <timestamp>2017-07-15T06:26:59Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* top */LaTeX spacing clean up, replaced: \;&lt;/math&gt; → &lt;/math&gt; (7) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2440">In mathematics, a '''braided''' vectorspace &lt;math&gt;\;V&lt;/math&gt; is a [[vector space]] together with an additional structure map &lt;math&gt;\tau&lt;/math&gt; symbolizing '''interchanging''' of two vector [[tensor product|tensor copies]]:

::&lt;math&gt;\tau:\; V\otimes V\longrightarrow V\otimes V &lt;/math&gt;

such that the [[Yang–Baxter equation]] is fulfilled. Hence drawing [[Penrose graphical notation|tensor diagram]]s with &lt;math&gt;\tau&lt;/math&gt; an '''overcrossing''' the corresponding composed morphism is unchanged when a [[Reidemeister move]] is applied to the tensor diagram and thus they present a representation of the [[braid group]].
 
As first example, every vector space is braided via the trivial braiding (simply flipping). A [[superspace]] has a braiding with negative sign in braiding two '''odd''' vectors. More generally, a '''diagonal braiding''' means that for a &lt;math&gt;\;V&lt;/math&gt;-base &lt;math&gt;x_i&lt;/math&gt; we have

::&lt;math&gt;\tau(x_i\otimes x_j)=q_{ij}(x_j\otimes x_i) &lt;/math&gt;

A good source for braided vector spaces entire [[braided monoidal category|braided monoidal categories]] with braidings  between any objects &lt;math&gt;\tau_{V,W}&lt;/math&gt;, most importantly the modules over [[quasitriangular Hopf algebra]]s and [[Yetter–Drinfeld category|Yetter–Drinfeld modules]] over finite groups (such as &lt;math&gt;\mathbb{Z}_2&lt;/math&gt; above)

If &lt;math&gt;V&lt;/math&gt; additionally possesses an [[braided Hopf algebra|algebra structure inside the braided category]] ("braided algebra") one has a '''braided commutator''' (e.g. for a [[superspace]] the [[Commutator|anticommutator]]): 

::&lt;math&gt;\;[x,y]_\tau:=\mu((x\otimes y)-\tau(x\otimes y))\qquad \mu(x\otimes y):=xy&lt;/math&gt;

Examples of such braided algebras (and even [[braided Hopf algebra|Hopf algebras]]) are the [[Nichols algebra]]s, that are by definition generated by a given braided vectorspace. They appear as quantum Borel part of [[quantum group]]s and often (e.g. when finite or over an abelian group) possess an [[Root system|arithmetic root system]], multiple [[Dynkin diagram]]s and a [[Poincaré–Birkhoff–Witt theorem|PBW-basis]] made up of braided commutators just like the ones in [[semisimple Lie algebra]]s.

&lt;ref name=AS02&gt;Andruskiewitsch, Schneider: ''Pointed Hopf algebras'',  New directions in Hopf algebras,  1–68, Math. Sci. Res. Inst. Publ., 43, Cambridge Univ. Press, Cambridge, 2002.&lt;/ref&gt;
&lt;references/&gt;

[[Category:Hopf algebras]]
[[Category:Quantum groups]]


{{algebra-stub}}</text>
      <sha1>nso8ztg97yga7uan1b3v0gmsw202laf</sha1>
    </revision>
  </page>
  <page>
    <title>Brocard's conjecture</title>
    <ns>0</ns>
    <id>2620525</id>
    <revision>
      <id>863797543</id>
      <parentid>834189320</parentid>
      <timestamp>2018-10-13T03:15:22Z</timestamp>
      <contributor>
        <username>Seahawk01</username>
        <id>34873291</id>
      </contributor>
      <minor/>
      <comment>added category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1569">{{single source|date=September 2015}}

{{Distinguish|Brocard's problem}}
In [[number theory]], '''Brocard's conjecture''' is a [[conjecture]] that there are at least four [[prime number]]s between (''p''&lt;sub&gt;''n''&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt; and (''p''&lt;sub&gt;''n''+1&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;, for ''n'' &lt;math&gt;\geq&lt;/math&gt; 2, where ''p''&lt;sub&gt;''n''&lt;/sub&gt; is the ''n''&lt;sup&gt;th&lt;/sup&gt; prime number.&lt;ref&gt;{{mathworld|urlname=BrocardsConjecture|title=Brocard's Conjecture}}&lt;/ref&gt;  It is widely believed that this conjecture is true. However, it remains unproven as of 2017.

{| class="wikitable" style="float:right; margin:10px;"
|-
! n !! &lt;math&gt;p_n&lt;/math&gt; !! &lt;math&gt;p_n^2&lt;/math&gt; !! Prime numbers !! &lt;math&gt;\Delta&lt;/math&gt;
|-
| 1 || 2 || 4 || 5, 7 || '''2'''
|-
| 2 || 3 || 9 || 11, 13, 17, 19, 23 || 5
|-
| 3 || 5 || 25 || 29, 31, 37, 41, 43, 47 || 6
|-
| 4 || 7 || 49 || 53, 59, 61, 67, 71… || 15
|-
| 5 || 11 || 121 || 127, 131, 137, 139, 149… || 9
|-
|colspan=5| &lt;math&gt;\Delta&lt;/math&gt; stands for &lt;math&gt;\pi(p_{n+1}^2) - \pi(p_n^2)&lt;/math&gt;.
|}

The number of primes between prime squares is 2, 5, 6, 15, 9, 22, 11, 27, ... {{OEIS2C|id=A050216}}.

[[Legendre's conjecture]] that there is a prime between consecutive integer squares directly implies that there are at least two primes between prime squares for ''p''&lt;sub&gt;''n''&lt;/sub&gt; ≥ 3 since ''p''&lt;sub&gt;''n''+1&lt;/sub&gt; - ''p''&lt;sub&gt;''n''&lt;/sub&gt; ≥ 2.

==Notes==
{{reflist}}

==See also==
*[[Prime counting function]]

{{Prime number conjectures}}

[[Category:Conjectures about prime numbers]]
[[Category:Squares in number theory]]

{{Numtheory-stub}}</text>
      <sha1>423h9b1z1pktxwmc9yv5llfl4d8d8gk</sha1>
    </revision>
  </page>
  <page>
    <title>Calculus</title>
    <ns>0</ns>
    <id>5176</id>
    <revision>
      <id>871515852</id>
      <parentid>871509784</parentid>
      <timestamp>2018-12-01T16:41:23Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>Reverted [[WP:AGF|good faith]] edits by [[Special:Contributions/Bert Niehaus|Bert Niehaus]]: This is a pretty figure, but it disturbs reading. If there was a way for stopping it, I would not revert its inclusion. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="55282">{{About|the branch of mathematics}}
{{pp-move-indef}}
{{short description|Branch of mathematics}}
{{Use dmy dates|date=May 2016}}
{{Calculus}}
'''Calculus''' (from [[Latin]] ''calculus'', literally 'small pebble', used for counting and calculations, as on an [[abacus]])&lt;ref name="oxdic"&gt;{{cite web|title=Calculus|url=http://www.oxforddictionaries.com/us/definition/american_english/calculus|website=OxfordDictionaries|accessdate=15 September 2017}}&lt;/ref&gt; is the [[mathematics|mathematical]] study of &lt;!-- Please, do not link "continuous", it has the common-language meaning, and does not refer to the technical mathematical concept --&gt;continuous change, in the same way that [[geometry]] is the study of shape and [[algebra]] is the study of generalizations of [[arithmetic operations]].

It has two major branches, [[differential calculus]] (concerning instantaneous rates of change and slopes of curves),&lt;ref&gt;{{cite web|url=http://www.merriam-webster.com/dictionary/differential%20calculus|title=Differential Calculus - Definition of Differential calculus by Merriam-Webster|accessdate=15 September 2017}}&lt;/ref&gt; and [[integral calculus]] (concerning accumulation of quantities and the areas under and between curves).&lt;ref&gt;{{cite web|url=http://www.merriam-webster.com/dictionary/integral+calculus?show=0&amp;t=1421520369|title=Integral Calculus - Definition of Integral calculus by Merriam-Webster|accessdate=15 September 2017}}&lt;/ref&gt; These two branches are related to each other by the [[fundamental theorem of calculus]]. Both branches make use of the fundamental notions of [[convergence (mathematics)|convergence]] of [[infinite sequence]]s and [[Series (mathematics)|infinite series]] to a well-defined [[limit (mathematics)|limit]].

Generally, modern calculus is considered to have been developed in the 17th century by [[Isaac Newton]] and [[Gottfried Wilhelm Leibniz]].&lt;ref&gt;{{cite book|last1=Eves|first1=Howard|title=An Introduction to the History of Mathematics|date=1976|publisher=[[Holt, Rinehart and Winston]]|location=New York, N.Y.|isbn=0-03-089539-1|page=305|edition=4th}}&lt;/ref&gt; Today, calculus has widespread uses in [[science]], [[engineering]], and [[economics]].&lt;ref&gt;{{cite book|author=Fisher, Irving|authorlink=Irving Fisher|title=A brief introduction to the infinitesimal calculus|year=1897|location=New York|publisher=The Macmillan Company|url=http://catalog.hathitrust.org/Record/000578981}}&lt;/ref&gt;{{Better source|date=February 2018|reason=the source for the use of calculus TODAY should not be a book from 1897.}}

Calculus is a part of modern [[mathematics education]]. A course in calculus is a gateway to other, more advanced courses in mathematics devoted to the study of [[Function (mathematics)|functions]] and limits, broadly called [[mathematical analysis]]. Calculus has historically been called "the calculus of [[infinitesimal]]s", or "infinitesimal calculus". The term ''calculus'' (plural ''calculi'') is also used for naming specific methods of calculation or notation as well as some theories, such as [[propositional calculus]], [[Ricci calculus]], [[calculus of variations]], [[lambda calculus]], and [[process calculus]].

== History ==
&lt;!--
Attention: leave dates as they are. We're not really that bothered, as the majority of Wikipedia dates state "BC". Just think of it as "Before Cronholm".
--&gt;
{{Main|History of calculus}}

Modern calculus was developed in 17th-century Europe by [[Isaac Newton]] and [[Gottfried Wilhelm Leibniz]] (independently of each other, first publishing around the same time) but elements of it appeared in ancient Greece, then in China&lt;!-- Alphabetically, so please don't change the order, thank you --&gt; and the Middle East, and still later again in medieval Europe and in India.

=== Ancient ===
[[File:Parabolic segment and inscribed triangle.svg|thumb|150px|right|Archimedes used the [[method of exhaustion]] to calculate the area under a parabola.]]
The ancient period introduced some of the ideas that led to [[integral]] calculus, but does not seem to have developed these ideas in a rigorous and systematic way. Calculations of [[volume]] and [[area]], one goal of integral calculus, can be found in the [[Egyptian mathematics|Egyptian]] [[Moscow Mathematical Papyrus|Moscow papyrus]] ([[13th dynasty]], {{circa|1820}}&amp;nbsp;BC), but the formulas are simple instructions, with no indication as to method, and some of them lack major components.&lt;ref&gt;Morris Kline, ''[https://books.google.com/books?id=-OsRDAAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Mathematical thought from ancient to modern times]'', Vol. I&lt;/ref&gt;

From the age of [[Greek mathematics]], [[Eudoxus of Cnidus|Eudoxus]] ({{circa|408–355}}&amp;nbsp;BC) used the [[method of exhaustion]], which foreshadows the concept of the limit, to calculate areas and volumes, while [[Archimedes]] ({{circa|287–212}}&amp;nbsp;BC) [[Archimedes' use of infinitesimals|developed this idea further]], inventing [[heuristics]] which resemble the methods of integral calculus.&lt;ref&gt;Archimedes, ''Method'', in ''The Works of Archimedes'' {{isbn|978-0-521-66160-7}}&lt;/ref&gt;

The [[method of exhaustion]] was later discovered independently in [[Chinese mathematics|China]] by [[Liu Hui]] in the 3rd century AD in order to find the area of a circle.&lt;ref&gt;{{cite journal
|series=Chinese studies in the history and philosophy of science and technology|volume=130|title=A comparison of Archimdes' and Liu Hui's studies of circles|first1=Liu|last1=Dun|first2=Dainian|last2=Fan|first3=Robert Sonné|last3=Cohen|publisher=Springer|year=1966|isbn=0-7923-3463-9|page=279|url=https://books.google.com/books?id=jaQH6_8Ju-MC}},[https://books.google.com/books?id=jaQH6_8Ju-MC&amp;pg=PA279 Chapter , p. 279]&lt;/ref&gt; In the 5th century AD, [[Zu Gengzhi]], son of [[Zu Chongzhi]], established a method&lt;ref&gt;{{cite book|last1=Katz|first1=Victor J.|title=A history of mathematics|date=2008|publisher=Addison-Wesley|location=Boston, Mass.|isbn=0-321-38700-7|pages=203|edition=3rd}}&lt;/ref&gt;&lt;ref&gt;{{cite book|title=Calculus: Early Transcendentals|edition=3|first1=Dennis G.|last1=Zill|first2=Scott|last2=Wright|first3=Warren S.|last3=Wright|publisher=Jones &amp; Bartlett Learning|year=2009|isbn=0-7637-5995-3|page=xxvii|url=https://books.google.com/books?id=R3Hk4Uhb1Z0C}} [https://books.google.com/books?id=R3Hk4Uhb1Z0C&amp;pg=PR27 Extract of page 27]&lt;/ref&gt; that would later be called [[Cavalieri's principle]] to find the volume of a [[sphere]].

=== Medieval ===
In the Middle East, Hasan Ibn al-Haytham, Latinized as [[Alhazen]] ({{c.|lk=no|965|1040}}&amp;nbsp;{{sc|ce}}) derived a formula for the sum of [[fourth power]]s. He used the results to carry out what would now be called an [[Integral|integration]] of this function, where the formulae for the sums of integral squares and fourth powers allowed him to calculate the volume of a [[paraboloid]].&lt;ref name=katz&gt;Katz, V. J.  1995.  "Ideas of Calculus in Islam and India."  ''Mathematics Magazine'' (Mathematical Association of America), 68(3):163–174.&lt;/ref&gt;

In the 14th century, Indian mathematicians gave a non-rigorous method, resembling differentiation, applicable to some trigonometric functions. [[Madhava of Sangamagrama]] and the [[Kerala School of Astronomy and Mathematics]] thereby stated components of calculus. A complete theory encompassing these components is now well known in the Western world as the ''[[Taylor series]]'' or ''[[infinite series]] approximations''.&lt;ref&gt;{{cite web|url=http://www-history.mcs.st-andrews.ac.uk/HistTopics/Indian_mathematics.html|title=Indian mathematics|publisher=}}&lt;/ref&gt; However, they were not able to "combine many differing ideas under the two unifying themes of the [[derivative]] and the [[integral]], show the connection between the two, and turn calculus into the great problem-solving tool we have today".&lt;ref name=katz/&gt;

=== Modern ===
{{quote box|width=30em|align=right|quote="The calculus was the first achievement of modern mathematics and it is difficult to overestimate its importance. I think it defines more unequivocally than anything else the inception of modern mathematics, and the system of mathematical analysis, which is its logical development, still constitutes the greatest technical advance in exact thinking."|author=—[[John von Neumann]]&lt;ref&gt;von Neumann, J., "The Mathematician", in Heywood, R. B., ed., ''The Works of the Mind'', University of Chicago Press, 1947, pp. 180–196.  Reprinted in Bródy, F., Vámos, T., eds., ''The Neumann Compendium'', World Scientific Publishing Co. Pte. Ltd., 1995, {{isbn|981-02-2201-7}}, pp. 618–626.&lt;/ref&gt;}}
In Europe, the foundational work was a treatise written by [[Bonaventura Cavalieri]], who argued that volumes and areas should be computed as the sums of the volumes and areas of infinitesimally thin cross-sections. The ideas were similar to Archimedes' in ''[[The Method of Mechanical Theorems|The Method]]'', but this treatise is believed to have been lost in the 13th century, and was only rediscovered in the early 20th century, and so would have been unknown to Cavalieri. Cavalieri's work was not well respected since his methods could lead to erroneous results, and the infinitesimal quantities he introduced were disreputable at first.

The formal study of calculus brought together Cavalieri's infinitesimals with the [[calculus of finite differences]] developed in Europe at around the same time. [[Pierre de Fermat]], claiming that he borrowed from [[Diophantus]], introduced the concept of [[adequality]], which represented equality up to an infinitesimal error term.&lt;ref&gt;[[André Weil]]: Number theory. An approach through history. From Hammurapi to Legendre. Birkhauser Boston, Inc., Boston, MA, 1984, {{isbn|0-8176-4565-9}}, p. 28.&lt;/ref&gt; The combination was achieved by [[John Wallis]], [[Isaac Barrow]], and [[James Gregory (astronomer and mathematician)|James Gregory]], the latter two proving the [[Fundamental theorem of calculus|second fundamental theorem of calculus]] around 1670.

[[File:GodfreyKneller-IsaacNewton-1689.jpg|thumb|200px|right|[[Isaac Newton]] developed the use of calculus in his [[Newton's laws of motion|laws of motion]] and [[gravitation]].]]
The [[product rule]] and [[chain rule]],&lt;ref&gt;{{cite book |title=Calculus: Single Variable, Volume 1 |edition=illustrated |first1=Brian E. |last1=Blank |first2=Steven George |last2=Krantz |publisher=Springer Science &amp; Business Media |year=2006 |isbn=978-1-931914-59-8 |page=248 |url=https://books.google.com/books?id=hMY8lbX87Y8C}} [https://books.google.com/books?id=hMY8lbX87Y8C&amp;pg=PA248 Extract of page 248]&lt;/ref&gt; the notions of [[higher derivative]]s and [[Taylor series]],&lt;ref&gt;{{cite book |title=The Rise and Development of the Theory of Series up to the Early 1820s |edition=illustrated |first1=Giovanni |last1=Ferraro |publisher=Springer Science &amp; Business Media |year=2007 |isbn=978-0-387-73468-2 |page=87 |url=https://books.google.com/books?id=vLBJSmA9zgAC}} [https://books.google.com/books?id=vLBJSmA9zgAC&amp;pg=PA87 Extract of page 87]&lt;/ref&gt; and of [[analytic function]]s{{citation needed|date=August 2017}} were introduced by [[Isaac Newton]] in an idiosyncratic notation which he used to solve problems of [[mathematical physics]]. In his works, Newton rephrased his ideas to suit the mathematical idiom of the time, replacing calculations with infinitesimals by equivalent geometrical arguments which were considered beyond reproach. He used the methods of calculus to solve the problem of planetary motion, the shape of the surface of a rotating fluid, the oblateness of the earth, the motion of a weight sliding on a [[cycloid]], and many other problems discussed in his ''[[Philosophiæ Naturalis Principia Mathematica|Principia Mathematica]]'' (1687). In other work, he developed series expansions for functions, including fractional and irrational powers, and it was clear that he understood the principles of the [[Taylor series]]. He did not publish all these discoveries, and at this time infinitesimal methods were still considered disreputable.

[[File:Gottfried Wilhelm Leibniz, Bernhard Christoph Francke.jpg|thumb|200px|left|[[Gottfried Wilhelm Leibniz]] was the first to state clearly the rules of calculus.]]

These ideas were arranged into a true calculus of infinitesimals by [[Gottfried Wilhelm Leibniz]], who was originally accused of [[plagiarism]] by Newton.&lt;ref name=leib&gt;Leibniz, Gottfried Wilhelm. ''The Early Mathematical Manuscripts of Leibniz''. Cosimo, Inc., 2008.  Page 228. [https://books.google.com/books?hl=en&amp;lr=&amp;id=7d8_4WPc9SMC&amp;oi=fnd&amp;pg=PA3&amp;dq=Gottfried+Wilhelm+Leibniz+accused+of+plagiarism+by+Newton&amp;ots=09h9BdTlbE&amp;sig=hu5tNKpBJxHcpj8U3kR_T2bZqrY#v=onepage&amp;q=plagairism&amp;f=false|Online Copy]&lt;/ref&gt; He is now regarded as an [[Multiple discovery|independent inventor]] of and contributor to calculus. His contribution was to provide a clear set of rules for working with infinitesimal quantities, allowing the computation of second and higher derivatives, and providing the [[product rule]] and [[chain rule]], in their differential and integral forms. Unlike Newton, Leibniz paid a lot of attention to the formalism, often spending days determining appropriate symbols for concepts.

Today, [[Gottfried Leibniz|Leibniz]] and [[Isaac Newton|Newton]] are usually both given credit for independently inventing and developing calculus. Newton was the first to apply calculus to general [[physics]] and Leibniz developed much of the notation used in calculus today. The basic insights that both Newton and Leibniz provided were the laws of differentiation and integration, second and higher derivatives, and the notion of an approximating polynomial series. By Newton's time, the fundamental theorem of calculus was known.

When Newton and Leibniz first published their results, there was [[Newton v. Leibniz calculus controversy|great controversy]] over which mathematician (and therefore which country) deserved credit. Newton derived his results first (later to be published in his ''[[Method of Fluxions]]''), but Leibniz published his "[[Nova Methodus pro Maximis et Minimis]]" first. Newton claimed Leibniz stole ideas from his unpublished notes, which Newton had shared with a few members of the [[Royal Society]]. This controversy divided English-speaking mathematicians from continental European mathematicians for many years, to the detriment of English mathematics.{{citation needed|date=February 2018}} A careful examination of the papers of Leibniz and Newton shows that they arrived at their results independently, with Leibniz starting first with integration and Newton with differentiation.  It is Leibniz, however, who gave the new discipline its name. Newton called his calculus "[[Method of fluxions|the science of fluxions]]".

Since the time of Leibniz and Newton, many mathematicians have contributed to the continuing development of calculus. One of the first and most complete works on both infinitesimal and [[integral calculus]] was written in 1748 by [[Maria Gaetana Agnesi]].&lt;ref&gt;{{cite book |title=A Biography of Maria Gaetana Agnesi, an Eighteenth-century Woman Mathematician |edition=illustrated |first1=Antonella |last1=Cupillari |publisher=Edwin Mellen Press |year=2007 |isbn=978-0-7734-5226-8 |page=iii |url=https://books.google.com/books?id=urEfAQAAIAAJ&amp;q=most+complete|contributor-last=Allaire|contributor-first=Patricia R.|contribution=Foreword}}&lt;/ref&gt;&lt;ref&gt;{{cite web| url=http://www.agnesscott.edu/lriddle/women/agnesi.htm| title=Maria Gaetana Agnesi| first=Elif| last=Unlu|date=April 1995| publisher   =[[Agnes Scott College]]}}&lt;/ref&gt;
[[File:Maria Gaetana Agnesi.jpg|thumb|150px|right|[[Maria Gaetana Agnesi]]]]

=== Foundations ===
In calculus, ''foundations'' refers to the [[Rigorous#Mathematical rigour|rigorous]] development of the subject from [[axiom]]s and definitions.  In early calculus the use of [[infinitesimal]] quantities was thought unrigorous, and was fiercely criticized by a number of authors, most notably [[Michel Rolle]] and [[George Berkeley|Bishop Berkeley]]. Berkeley famously described infinitesimals as the [[ghosts of departed quantities]] in his book ''[[The Analyst]]'' in 1734.  Working out a rigorous foundation for calculus occupied mathematicians for much of the century following Newton and Leibniz, and is still to some extent an active area of research today.

Several mathematicians, including [[Colin Maclaurin|Maclaurin]], tried to prove the soundness of using infinitesimals, but it would not be until 150 years later when, due to the work of [[Augustin Louis Cauchy|Cauchy]] and [[Karl Weierstrass|Weierstrass]], a way was finally found to avoid mere "notions" of infinitely small quantities.&lt;ref&gt;{{Cite book |last= Russell |first= Bertrand |authorlink= Bertrand Russell |year= 1946 |title= [[A History of Western Philosophy|History of Western Philosophy]] |location= London |publisher= [[George Allen &amp; Unwin Ltd]] |page= [https://archive.org/stream/westernphilosoph035502mbp#page/n857/mode/2up 857] |quote= The great mathematicians of the seventeenth century were optimistic and anxious for quick results; consequently they left the foundations of analytical geometry and the infinitesimal calculus insecure. Leibniz believed in actual infinitesimals, but although this belief suited his metaphysics it had no sound basis in mathematics. Weierstrass, soon after the middle of the nineteenth century, showed how to establish the calculus without infinitesimals, and thus at last made it logically secure. Next came Georg Cantor, who developed the theory of continuity and infinite number. "Continuity" had been, until he defined it, a vague word, convenient for philosophers like Hegel, who wished to introduce metaphysical muddles into mathematics. Cantor gave a precise significance to the word, and showed that continuity, as he defined it, was the concept needed by mathematicians and physicists. By this means a great deal of mysticism, such as that of Bergson, was rendered antiquated. }}&lt;/ref&gt; The foundations of differential and integral calculus had been laid. In Cauchy's ''[[Cours d'Analyse]]'', we find a broad range of foundational approaches, including a definition of [[continuous function|continuity]] in terms of infinitesimals, and a (somewhat imprecise) prototype of an [[(ε, δ)-definition of limit]] in the definition of differentiation.&lt;ref&gt;{{cite book |first=Judith V. |last=Grabiner |title=The Origins of Cauchy's Rigorous Calculus |location=Cambridge |publisher=MIT Press |year=1981 |isbn=0-387-90527-8 }}&lt;/ref&gt; In his work Weierstrass formalized the concept of [[Limit of a function|limit]]&lt;!--correct link?--&gt; and eliminated infinitesimals (although his definition can actually validate [[nilsquare]] infinitesimals). Following the work of Weierstrass, it eventually became common to base calculus on limits instead of infinitesimal quantities, though the subject is still occasionally called "infinitesimal calculus". [[Bernhard Riemann]] used these ideas to give a precise definition of the integral. It was also during this period that the ideas of calculus were generalized to [[Euclidean space]] and the [[complex plane]].

In modern mathematics, the foundations of calculus are included in the field of [[real analysis]], which contains full definitions and [[mathematical proof|proof]]s of the theorems of calculus.  The reach of calculus has also been greatly extended. [[Henri Lebesgue]] invented [[measure theory]] and used it to define integrals of all but the most [[Pathological (mathematics)|pathological]] functions.  [[Laurent Schwartz]] introduced [[Distribution (mathematics)|distribution]]s, which can be used to take the derivative of any function whatsoever.

Limits are not the only rigorous approach to the foundation of calculus. Another way is to use [[Abraham Robinson]]'s [[non-standard analysis]]. Robinson's approach, developed in the 1960s, uses technical machinery from [[mathematical logic]] to augment the real number system with [[infinitesimal]] and [[Infinity|infinite]] numbers, as in the original Newton-Leibniz conception. The resulting numbers are called [[hyperreal number]]s, and they can be used to give a Leibniz-like development of the usual rules of calculus. There is also [[smooth infinitesimal analysis]], which differs from non-standard analysis in that it mandates neglecting higher power infinitesimals during derivations.

=== Significance ===
While many of the ideas of calculus had been developed earlier in [[Greek mathematics|Greece]], [[Chinese mathematics|China]], [[Indian mathematics|India]], [[Islamic mathematics|Iraq, Persia]], and [[Japanese mathematics|Japan]], the use of calculus began in Europe, during the 17th century, when [[Isaac Newton]] and [[Gottfried Wilhelm Leibniz]] built on the work of earlier mathematicians to introduce its basic principles. The development of calculus was built on earlier concepts of instantaneous motion and area underneath curves.

Applications of differential calculus include computations involving [[velocity]] and [[acceleration]], the [[slope]] of a curve, and [[Mathematical optimization|optimization]]. Applications of integral calculus include computations involving area, [[volume]], [[arc length]], [[center of mass]], [[work (physics)|work]], and [[pressure]]. More advanced applications include [[power series]] and [[Fourier series]].

Calculus is also used to gain a more precise understanding of the nature of space, time, and motion. For centuries, mathematicians and philosophers wrestled with paradoxes involving [[division by zero]] or sums of infinitely many numbers. These questions arise in the study of [[Motion (physics)|motion]] and area. The [[ancient Greek]] philosopher [[Zeno of Elea]] gave several famous examples of such [[Zeno's paradoxes|paradoxes]]. Calculus provides tools, especially the [[Limit (mathematics)|limit]] and the [[infinite series]], that resolve the paradoxes.

== Principles ==

=== Limits and infinitesimals ===
{{Main|Limit of a function|Infinitesimal}}
Calculus is usually developed by working with very small quantities. Historically, the first method of doing so was by [[infinitesimal]]s. These are objects which can be treated like real numbers but which are, in some sense, "infinitely small".  For example, an infinitesimal number could be greater than 0, but less than any number in the sequence 1, 1/2, 1/3, ... and thus less than any positive [[real number]]. From this point of view, calculus is a collection of techniques for manipulating infinitesimals.  The symbols '''&lt;math&gt;dx&lt;/math&gt;''' and &lt;math&gt;dy&lt;/math&gt; were taken to be infinitesimal, and the derivative &lt;math&gt;dy/dx&lt;/math&gt; was simply their ratio.

The infinitesimal approach fell out of favor in the 19th century because it was difficult to make the notion of an infinitesimal precise. However, the concept was revived in the 20th century with the introduction of [[non-standard analysis]] and [[smooth infinitesimal analysis]], which provided solid foundations for the manipulation of infinitesimals.

In the late 19th century, infinitesimals were replaced within academia by the [[epsilon, delta]] approach to [[Limit of a function|limit]]s. Limits describe the value of a [[function (mathematics)|function]] at a certain input in terms of its values at nearby inputs. They capture small-scale behavior in the context of the [[real number|real number system]]. In this treatment, calculus is a collection of techniques for manipulating certain limits. Infinitesimals get replaced by very small numbers, and the infinitely small behavior of the function is found by taking the limiting behavior for smaller and smaller numbers. Limits were thought to provide a more rigorous foundation for calculus, and for this reason they became the standard approach during the twentieth century.

=== Differential calculus ===
{{Main|Differential calculus}}
[[File:Tangent derivative calculusdia.svg|thumb|300px|Tangent line at {{math|(''x'', ''f''(''x''))}}. The derivative {{math|''f′''(''x'')}} of a curve at a point is the slope (rise over run) of the line tangent to that curve at that point.]]

Differential calculus is the study of the definition, properties, and applications of the [[derivative]] of a function. The process of finding the derivative is called ''differentiation''. Given a function and a point in the domain, the derivative at that point is a way of encoding the small-scale behavior of the function near that point. By finding the derivative of a function at every point in its domain, it is possible to produce a new function, called the ''derivative function'' or just the ''derivative'' of the original function. In formal terms, the derivative is a [[linear operator]] which takes a function as its input and produces a second function as its output. This is more abstract than many of the processes studied in elementary algebra, where functions usually input a number and output another number. For example, if the doubling function is given the input three, then it outputs six, and if the squaring function is given the input three, then it outputs nine. The derivative, however, can take the squaring function as an input. This means that the derivative takes all the information of the squaring function—such as that two is sent to four, three is sent to nine, four is sent to sixteen, and so on—and uses this information to produce another function. The function produced by deriving the squaring function turns out to be the doubling function.

In more explicit terms the "doubling function" may be denoted by {{math|''g''(''x'') {{=}} 2''x''}} and the "squaring function" by {{math|''f''(''x'') {{=}} ''x''&lt;sup&gt;2&lt;/sup&gt;}}. The "derivative" now takes the function {{math|''f''(''x'')}}, defined by the expression "{{math|''x''&lt;sup&gt;2&lt;/sup&gt;}}", as an input, that is all the information—such as that two is sent to four, three is sent to nine, four is sent to sixteen, and so on—and uses this information to output another function, the function {{math|''g''(''x'') {{=}} 2''x''}}, as will turn out.

The most common symbol for a derivative is an [[apostrophe]]-like mark called [[prime (symbol)|prime]]. Thus, the derivative of a function called {{math|''f''}} is denoted by {{math|''f′''}}, pronounced "f prime". For instance, if {{math|''f''(''x'') {{=}} ''x''&lt;sup&gt;2&lt;/sup&gt;}} is the squaring function, then {{math|''f′''(''x'') {{=}} 2''x''}} is its derivative (the doubling function {{math|''g''}} from above). This notation is known as [[Lagrange's notation]].

If the input of the function represents time, then the derivative represents change with respect to time. For example, if {{math|''f''}} is a function that takes a time as input and gives the position of a ball at that time as output, then the derivative of {{math|''f''}} is how the position is changing in time, that is, it is the [[velocity]] of the ball.

If a function is [[linear function|linear]] (that is, if the [[Graph of a function|graph]] of the function is a straight line), then the function can be written as {{math|''y'' {{=}} ''mx'' + ''b''}}, where {{math|''x''}} is the independent variable, {{math|''y''}} is the dependent variable, {{math|''b''}} is the ''y''-intercept, and:

:&lt;math&gt;m= \frac{\text{rise}}{\text{run}}= \frac{\text{change in } y}{\text{change in } x} = \frac{\Delta y}{\Delta x}.&lt;/math&gt;

This gives an exact value for the slope of a straight line. If the graph of the function is not a straight line, however, then the change in {{math|''y''}} divided by the change in {{math|''x''}} varies. Derivatives give an exact meaning to the notion of change in output with respect to change in input. To be concrete, let {{math|''f''}} be a function, and fix a point {{math|''a''}} in the domain of {{math|''f''}}. {{math|(''a'', ''f''(''a''))}} is a point on the graph of the function. If {{math|''h''}} is a number close to zero, then {{math|''a'' + ''h''}} is a number close to {{math|''a''}}. Therefore, {{math|(''a'' + ''h'', ''f''(''a'' + ''h''))}} is close to {{math|(''a'', ''f''(''a''))}}. The slope between these two points is

:&lt;math&gt;m = \frac{f(a+h) - f(a)}{(a+h) - a} = \frac{f(a+h) - f(a)}{h}.&lt;/math&gt;

This expression is called a ''[[difference quotient]]''. A line through two points on a curve is called a ''secant line'', so {{math|''m''}} is the slope of the secant line between {{math|(''a'', ''f''(''a''))}} and {{math|(''a'' + ''h'', ''f''(''a'' + ''h''))}}. The secant line is only an approximation to the behavior of the function at the point {{math|''a''}} because it does not account for what happens between {{math|''a''}} and {{math|''a'' + ''h''}}. It is not possible to discover the behavior at {{math|''a''}} by setting {{math|''h''}} to zero because this would require [[dividing by zero]], which is undefined. The derivative is defined by taking the [[limit (mathematics)|limit]] as {{math|''h''}} tends to zero, meaning that it considers the behavior of {{math|''f''}} for all small values of {{math|''h''}} and extracts a consistent value for the case when {{math|''h''}} equals zero:

:&lt;math&gt;\lim_{h \to 0}{f(a+h) - f(a)\over{h}}.&lt;/math&gt;

Geometrically, the derivative is the slope of the [[tangent line]] to the graph of {{math|''f''}} at {{math|''a''}}. The tangent line is a limit of secant lines just as the derivative is a limit of difference quotients. For this reason, the derivative is sometimes called the slope of the function {{math|''f''}}.

Here is a particular example, the derivative of the squaring function at the input 3. Let {{math|''f''(''x'') {{=}} ''x''&lt;sup&gt;2&lt;/sup&gt;}} be the squaring function.

[[File:Sec2tan.gif|thumb|300px|The derivative {{math|''f′''(''x'')}} of a curve at a point is the slope of the line tangent to that curve at that point. This slope is determined by considering the limiting value of the slopes of secant lines. Here the function involved (drawn in red) is {{math|''f''(''x'') {{=}} ''x''&lt;sup&gt;3&lt;/sup&gt; − ''x''}}. The tangent line (in green) which passes through the point {{nowrap|(−3/2, −15/8)}} has a slope of 23/4. Note that the vertical and horizontal scales in this image are different.]]

:&lt;math&gt;\begin{align}f'(3) &amp;=\lim_{h \to 0}{(3+h)^2 - 3^2\over{h}} \\
&amp;=\lim_{h \to 0}{9 + 6h + h^2 - 9\over{h}} \\
&amp;=\lim_{h \to 0}{6h + h^2\over{h}} \\
&amp;=\lim_{h \to 0} (6 + h) \\
&amp;= 6
\end{align}
&lt;/math&gt;

The slope of the tangent line to the squaring function at the point (3, 9) is 6, that is to say, it is going up six times as fast as it is going to the right. The limit process just described can be performed for any point in the domain of the squaring function. This defines the ''derivative function'' of the squaring function, or just the ''derivative'' of the squaring function for short. A computation similar to the one above shows that the derivative of the squaring function is the doubling function.

=== Leibniz notation ===
{{Main|Leibniz's notation}}

A common notation, introduced by Leibniz, for the derivative in the example above is
:&lt;math&gt;
\begin{align}
y&amp;=x^2 \\
\frac{dy}{dx}&amp;=2x.
\end{align}
&lt;/math&gt;
In an approach based on limits, the symbol {{math|{{sfrac|''dy''|''dx''}}}} is to be interpreted not as the quotient of two numbers but as a shorthand for the limit computed above. Leibniz, however, did intend it to represent the quotient of two infinitesimally small numbers, {{math|''dy''}} being the infinitesimally small change in {{math|''y''}} caused by an infinitesimally small change {{math|''dx''}} applied to {{math|''x''}}. We can also think of {{math|{{sfrac|''d''|''dx''}}}} as a differentiation operator, which takes a function as an input and gives another function, the derivative, as the output. For example:
:&lt;math&gt;
\frac{d}{dx}(x^2)=2x.
&lt;/math&gt;

In this usage, the {{math|''dx''}} in the denominator is read as "with respect to {{math|''x''}}". Another example of correct notation could be:

&lt;math&gt;\begin{align}
g(t) = t^2 + 2t + 4 \\ \\
{d \over dt}g(t) = 2t + 2
\end{align}
&lt;/math&gt;

Even when calculus is developed using limits rather than infinitesimals, it is common to manipulate symbols like {{math|''dx''}} and {{math|''dy''}} as if they were real numbers; although it is possible to avoid such manipulations, they are sometimes notationally convenient in expressing operations such as the [[total derivative]].

=== Integral calculus ===
{{Main|Integral}}

''Integral calculus'' is the study of the definitions, properties, and applications of two related concepts, the ''indefinite integral'' and the ''definite integral''. The process of finding the value of an integral is called ''integration''. In technical language, integral calculus studies two related [[linear operator]]s.

The ''indefinite integral'', also known as the ''[[antiderivative]]'', is the inverse operation to the derivative. {{math|''F''}} is an indefinite integral of {{math|''f''}} when {{math|''f''}} is a derivative of {{math|''F''}}.  (This use of lower- and upper-case letters for a function and its indefinite integral is common in calculus.)

The ''definite integral'' inputs a function and outputs a number, which gives the algebraic sum of areas between the graph of the input and the [[x-axis]]. The technical definition of the definite integral involves the [[limit (mathematics)|limit]] of a sum of areas of rectangles, called a [[Riemann sum]].

A motivating example is the distances traveled in a given time.

:&lt;math&gt;\mathrm{Distance} = \mathrm{Speed} \cdot \mathrm{Time}&lt;/math&gt;

If the speed is constant, only multiplication is needed, but if the speed changes, a more powerful method of finding the distance is necessary. One such method is to approximate the distance traveled by breaking up the time into many short intervals of time, then multiplying the time elapsed in each interval by one of the speeds in that interval, and then taking the sum (a [[Riemann sum]]) of the approximate distance traveled in each interval. The basic idea is that if only a short time elapses, then the speed will stay more or less the same. However, a Riemann sum only gives an approximation of the distance traveled. We must take the limit of all such Riemann sums to find the exact distance traveled.

[[File:Constant velocity.png|left|thumb|Constant velocity]]
[[File:Integral as region under curve.svg|right|thumb|280px|Integration can be thought of as measuring the area under a curve, defined by {{math|''f''(''x'')}}, between two points (here {{math|''a''}} and {{math|''b''}}).]]
When velocity is constant, the total distance traveled over the given time interval can be computed by multiplying velocity and time.  For example, travelling a steady 50&amp;nbsp;mph for 3 hours results in a total distance of 150 miles.  In the diagram on the left, when constant velocity and time are graphed, these two values form a rectangle with height equal to the velocity and width equal to the time elapsed.  Therefore, the product of velocity and time also calculates the rectangular area under the (constant) velocity curve.  This connection between the area under a curve and distance traveled can be extended to ''any'' irregularly shaped region exhibiting a fluctuating velocity over a given time period. If {{math|''f''(''x'')}} in the diagram on the right represents speed as it varies over time, the distance traveled (between the times represented by {{math|''a''}} and {{math|''b''}}) is the area of the shaded region&amp;nbsp;{{math|''s''}}.

To approximate that area, an intuitive method would be to divide up the distance between {{math|''a''}} and {{math|''b''}} into a number of equal segments, the length of each segment represented by the symbol {{math|Δ''x''}}. For each small segment, we can choose one value of the function {{math|''f''(''x'')}}. Call that value {{math|''h''}}. Then the area of the rectangle with base {{math|Δ''x''}} and height {{math|''h''}} gives the distance (time {{math|Δ''x''}} multiplied by speed {{math|''h''}}) traveled in that segment.   Associated with each segment is the average value of the function above it, {{math|''f''(''x'') {{=}} ''h''}}. The sum of all such rectangles gives an approximation of the area between the axis and the curve, which is an approximation of the total distance traveled. A smaller value for {{math|Δ''x''}} will give more rectangles and in most cases a better approximation, but for an exact answer we need to take a limit as {{math|Δ''x''}} approaches zero.

The symbol of integration is &lt;math&gt;\int &lt;/math&gt;, an [[long s|elongated ''S'']] (the ''S'' stands for "sum"). The definite integral is written as:

:&lt;math&gt;\int_a^b f(x)\, dx.&lt;/math&gt;

and is read "the integral from ''a'' to ''b'' of ''f''-of-''x'' with respect to ''x''."  The Leibniz notation {{math|''dx''}} is intended to suggest dividing the area under the curve into an infinite number of rectangles, so that their width {{math|Δ''x''}} becomes the infinitesimally small {{math|''dx''}}.  In a formulation of the calculus based on limits, the notation

:&lt;math&gt;\int_a^b \cdots\, dx&lt;/math&gt;

is to be understood as an operator that takes a function as an input and gives a number, the area, as an output. The terminating differential, {{math|''dx''}}, is not a number, and is not being multiplied by {{math|''f''(''x'')}}, although, serving as a reminder of the {{math|Δ''x''}} limit definition, it can be treated as such in symbolic manipulations of the integral. Formally, the differential indicates the variable over which the function is integrated and serves as a closing bracket for the integration operator.

The indefinite integral, or antiderivative, is written:

:&lt;math&gt;\int f(x)\, dx.&lt;/math&gt;

Functions differing by only a constant have the same derivative, and it can be shown that the antiderivative of a given function is actually a family of functions differing only by a constant. Since the derivative of the function {{math|''y'' {{=}} ''x''&lt;sup&gt;2&lt;/sup&gt; + ''C''}}, where {{math|''C''}} is any constant, is {{math|''y′'' {{=}} 2''x''}}, the antiderivative of the latter given by:
:&lt;math&gt;\int 2x\, dx = x^2 + C.&lt;/math&gt;
The unspecified constant {{math|''C''}} present in the indefinite integral or antiderivative is known as the [[constant of integration]].

=== Fundamental theorem ===
{{Main|Fundamental theorem of calculus}}
The [[fundamental theorem of calculus]] states that differentiation and integration are inverse operations. More precisely, it relates the values of antiderivatives to definite integrals. Because it is usually easier to compute an antiderivative than to apply the definition of a definite integral, the fundamental theorem of calculus provides a practical way of computing definite integrals. It can also be interpreted as a precise statement of the fact that differentiation is the inverse of integration.

The fundamental theorem of calculus states: If a function {{math|''f''}} is [[continuous function|continuous]] on the interval {{math|[''a'', ''b'']}} and if {{math|''F''}} is a function whose derivative is {{math|''f''}} on the interval {{math|(''a'', ''b'')}}, then

:&lt;math&gt;\int_{a}^{b} f(x)\,dx = F(b) - F(a).&lt;/math&gt;

Furthermore, for every {{math|''x''}} in the interval {{math|(''a'', ''b'')}},

:&lt;math&gt;\frac{d}{dx}\int_a^x f(t)\, dt = f(x).&lt;/math&gt;

This realization, made by both [[Isaac Newton|Newton]] and [[Gottfried Leibniz|Leibniz]], who based their results on earlier work by [[Isaac Barrow]], was key to the proliferation of analytic results after their work became known. The fundamental theorem provides an algebraic method of computing many definite integrals—without performing limit processes—by finding formulas for [[antiderivative]]s. It is also a prototype solution of a [[differential equation]]. Differential equations relate an unknown function to its derivatives, and are ubiquitous in the sciences.

== Applications ==
[[File:NautilusCutawayLogarithmicSpiral.jpg|thumb|right|The [[logarithmic spiral]] of the [[Nautilus|Nautilus shell]] is a classical image used to depict the growth and change related to calculus.]]
Calculus is used in every branch of the physical sciences, [[actuarial science]], computer science, statistics, engineering, economics, business, medicine, [[demography]], and in other fields wherever a problem can be [[mathematical model|mathematically modeled]] and an [[optimization (mathematics)|optimal]] solution is desired. It allows one to go from (non-constant) rates of change to the total change or vice versa, and many times in studying a problem we know one and are trying to find the other.

[[Physics]] makes particular use of calculus; all concepts in [[classical mechanics]] and [[electromagnetism]] are related through calculus. The [[mass]] of an object of known [[density]], the [[moment of inertia]] of objects, as well as the total energy of an object within a conservative field can be found by the use of calculus. An example of the use of calculus in mechanics is [[Newton's laws of motion|Newton's second law of motion]]: historically stated it expressly uses the term "change of motion" which implies the derivative saying ''The'' '''change''' ''of momentum of a body is equal to the resultant force acting on the body and is in the same direction.'' Commonly expressed today as Force&amp;nbsp;=&amp;nbsp;Mass&amp;nbsp;×&amp;nbsp;acceleration, it implies differential calculus because acceleration is the time derivative of velocity or second time derivative of trajectory or spatial position. Starting from knowing how an object is accelerating, we use calculus to derive its path.

Maxwell's theory of [[electromagnetism]] and [[Albert Einstein|Einstein]]'s theory of [[general relativity]] are also expressed in the language of differential calculus. Chemistry also uses calculus in determining reaction rates and radioactive decay. In biology, population dynamics starts with reproduction and death rates to model population changes.

Calculus can be used in conjunction with other mathematical disciplines. For example, it can be used with [[linear algebra]] to find the "best fit" linear approximation for a set of points in a domain. Or it can be used in [[probability theory]] to determine the probability of a continuous random variable from an assumed density function. In [[analytic geometry]], the study of graphs of functions, calculus is used to find high points and low points (maxima and minima), slope, [[Concave function|concavity]] and [[inflection points]].

[[Green's Theorem]], which gives the relationship between a line integral around a simple closed curve C and a double integral over the plane region D bounded by C, is applied in an instrument known as a [[planimeter]], which is used to calculate the area of a flat surface on a drawing. For example, it can be used to calculate the amount of area taken up by an irregularly shaped flower bed or swimming pool when designing the layout of a piece of property.

[[Discrete Green's Theorem]], which gives the relationship between a double integral of a function around a simple closed rectangular curve ''C'' and a linear combination of the antiderivative's values at corner points along the edge of the curve, allows fast calculation of sums of values in rectangular domains.  For example, it can be used to efficiently calculate sums of rectangular domains in images, in order to rapidly extract features and detect object; another algorithm that could be used is the [[summed area table]].

In the realm of medicine, calculus can be used to find the optimal branching angle of a blood vessel so as to maximize flow. From the decay laws for a particular drug's elimination from the body, it is used to derive dosing laws. In nuclear medicine, it is used to build models of radiation transport in targeted tumor therapies.

In economics, calculus allows for the determination of maximal profit by providing a way to easily calculate both [[marginal cost]] and [[marginal revenue]].

Calculus is also used to find approximate solutions to equations; in practice it is the standard way to solve differential equations and do root finding in most applications. Examples are methods such as [[Newton's method]], [[fixed point iteration]], and [[linear approximation]]. For instance, spacecraft use a variation of the [[Euler method]] to approximate curved courses within zero gravity environments.

==Varieties==
Over the years, many reformulations of calculus have been investigated for different purposes.

=== Non-standard calculus ===
{{Main|Non-standard calculus}}
Imprecise calculations with infinitesimals were widely replaced with the rigorous [[(ε, δ)-definition of limit]] starting in the 1870s. Meanwhile, calculations with infinitesimals persisted and often led to correct results. This led [[Abraham Robinson]] to investigate if it were possible to develop a number system with infinitesimal quantities over which the theorems of calculus were still valid. In 1960, building upon the work of [[Edwin Hewitt]] and [[Jerzy Łoś]], he succeeded in developing [[non-standard analysis]]. The theory of non-standard analysis is rich enough to be applied in many branches of mathematics.  As such, books and articles dedicated solely to the traditional theorems of calculus often go by the title [[non-standard calculus]].

=== Smooth infinitesimal analysis ===
{{Main|Smooth infinitesimal analysis}}
This is another reformulation of the calculus in terms of [[infinitesimal]]s. Based on the ideas of [[F. W. Lawvere]] and employing the methods of [[category theory]], it views all functions as being [[continuous function|continuous]] and incapable of being expressed in terms of [[Discrete mathematics|discrete]] entities.  One aspect of this formulation is that the [[law of excluded middle]] does not hold in this formulation.

=== Constructive analysis ===
{{Main|Constructive analysis}}

[[Constructive mathematics]] is a branch of mathematics that insists that proofs of the existence of a number, function, or other mathematical object should give a construction of the object. As such constructive mathematics also rejects the [[law of excluded middle]]. Reformulations of calculus in a constructive framework are generally part of the subject of [[constructive analysis]].

== See also ==
* {{Portal inline|size=tiny|Calculus}}
{{Main|Outline of calculus}}

=== Lists ===
* [[Glossary of calculus]]
* [[List of calculus topics]]
* [[List of derivatives and integrals in alternative calculi]]
* [[List of differentiation identities]]
* [[List of publications in mathematics#Calculus|Publications in calculus]]
* [[Table of integrals]]

=== Other related topics ===
* [[Calculus of finite differences]]
* [[Calculus with polynomials]]
* [[Complex analysis]]
* [[Differential equation]]
* [[Differential geometry and topology|Differential geometry]]
* ''[[Elementary Calculus: An Infinitesimal Approach]]''
* [[Fourier series]]
* [[Integral equation]]
* [[Mathematical analysis]]
* [[Multiplicative calculus]]
* [[Multivariable calculus]]
* [[Non-classical analysis]]
* [[Multiplicative calculus|Non-Newtonian calculus]]
* [[Non-standard analysis]]
* [[Non-standard calculus]]
* [[Precalculus]] ([[Mathematics education|mathematical education]])
* [[Product integral]]
* [[Stochastic calculus]]
* [[Taylor series]]

== References ==
{{Reflist|30em}}

==Further reading==

=== Books ===
&lt;!-- Please use APA style; it's a lot easier for it to stay universally readable. --&gt;
{{Refbegin|2}}
* [[Carl Benjamin Boyer|Boyer, Carl Benjamin]] (1949). [https://books.google.com/books?id=KLQSHUW8FnUC&amp;printsec=frontcover ''The History of the Calculus and its Conceptual Development'']. Hafner. Dover edition 1959, {{isbn|0-486-60509-4}}
* [[Richard Courant|Courant, Richard]] {{isbn|978-3-540-65058-4}} ''Introduction to calculus and analysis 1.''
* [[Edmund Landau]]. {{isbn|0-8218-2830-4}} ''Differential and Integral Calculus'', [[American Mathematical Society]].
* Robert A. Adams. (1999). {{isbn|978-0-201-39607-2}} ''Calculus: A complete course''.
* Albers, Donald J.; Richard D. Anderson and Don O. Loftsgaarden, ed. (1986) ''Undergraduate Programs in the Mathematics and Computer Sciences: The 1985–1986 Survey'', Mathematical Association of America No. 7.
* [[John Lane Bell]]: ''A Primer of Infinitesimal Analysis'', Cambridge University Press, 1998. {{isbn|978-0-521-62401-5}}. Uses [[synthetic differential geometry]] and nilpotent infinitesimals.
* [[Florian Cajori]], "The History of Notations of the Calculus." ''Annals of Mathematics'', 2nd Ser., Vol. 25, No. 1 (Sep. 1923), pp.&amp;nbsp;1–46.
* Leonid P. Lebedev and Michael J. Cloud: "Approximating Perfection: a Mathematician's Journey into the World of Mechanics, Ch. 1: The Tools of Calculus", Princeton Univ. Press, 2004.
* [[Cliff Pickover]]. (2003). {{isbn|978-0-471-26987-8}} ''Calculus and Pizza: A Math Cookbook for the Hungry Mind''.
* [[Michael Spivak]]. (September 1994). {{isbn|978-0-914098-89-8}}'' Calculus''. Publish or Perish publishing.
* [[Tom M. Apostol]]. (1967). {{isbn|978-0-471-00005-1}} ''Calculus, Volume 1, One-Variable Calculus with an Introduction to Linear Algebra''. Wiley.
* [[Tom M. Apostol]]. (1969). {{isbn|978-0-471-00007-5}} ''Calculus, Volume 2, Multi-Variable Calculus and Linear Algebra with Applications''. Wiley.
* [[Silvanus P. Thompson]] and [[Martin Gardner]]. (1998). {{isbn|978-0-312-18548-0}} ''Calculus Made Easy''.
* [[Mathematical Association of America]]. (1988). ''Calculus for a New Century; A Pump, Not a Filter'', The Association, Stony Brook, NY. ED 300 252.
* Thomas/Finney. (1996). {{isbn|978-0-201-53174-9}} ''Calculus and Analytic geometry 9th'', Addison Wesley.
* Weisstein, Eric W. [http://mathworld.wolfram.com/SecondFundamentalTheoremofCalculus.html "Second Fundamental Theorem of Calculus."] From MathWorld—A Wolfram Web Resource.
*Howard Anton, Irl Bivens, Stephen Davis:"Calculus", John Willey and Sons Pte. Ltd., 2002. {{ISBN|978-81-265-1259-1}}
* [[Ron Larson (mathematician)|Larson, Ron]], Bruce H. Edwards (2010). ''Calculus'', 9th ed., Brooks Cole Cengage Learning. {{isbn|978-0-547-16702-2}}
* McQuarrie, Donald A. (2003). ''Mathematical Methods for Scientists and Engineers'', University Science Books. {{isbn|978-1-891389-24-5}}
* {{Cite book |last1= Salas |first1= Saturnino L. |last2= Hille |first2= Einar |author2-link= Einar Hille |last3= Etgen |first3= Garret J. |year= 2007 |title= Calculus: One and Several Variables |edition= 10th |location= [[John Wiley &amp; Sons|Wiley]] |isbn= 978-0-471-69804-3 }}
* [[James Stewart (mathematician)|Stewart, James]] (2012). ''Calculus: Early Transcendentals'', 7th ed., Brooks Cole Cengage Learning. {{isbn|978-0-538-49790-9}}
* [[George B. Thomas|Thomas, George B.]], Maurice D. Weir, [[Joel Hass]], Frank R. Giordano (2008), ''Calculus'', 11th ed., Addison-Wesley. {{isbn|0-321-48987-X}}
{{Refend}}

=== Online books ===
{{Refbegin|2}}
* {{cite book |author=Boelkins, M. |year=2012 |title=Active Calculus: a free, open text |access-date=1 February 2013 |url=http://gvsu.edu/s/km |archive-url=https://web.archive.org/web/20130530024317/http://faculty.gvsu.edu/boelkinm/Home/Download_files/Active%20Calculus%20ch1-8%20%28v.1.1%20W13%29.pdf |archive-date=30 May 2013 |deadurl=yes |df=dmy-all }}
* Crowell, B. (2003). "''Calculus''". Light and Matter, Fullerton. Retrieved 6 May 2007 from [http://www.lightandmatter.com/calc/calc.pdf http://www.lightandmatter.com/calc/calc.pdf]
* Garrett, P. (2006). "''Notes on first year calculus''". University of Minnesota. Retrieved 6 May 2007 from [http://www.math.umn.edu/~garrett/calculus/first_year/notes.pdf &lt;nowiki&gt;http://www.math.umn.edu/~garrett/calculus/first_year/notes.pdf&lt;/nowiki&gt;]
* Faraz, H. (2006). "''Understanding Calculus''". Retrieved 6 May 2007 from UnderstandingCalculus.com, URL http://www.understandingcalculus.com (HTML only)
* Keisler, H. J. (2000). "''Elementary Calculus: An Approach Using Infinitesimals''". Retrieved 29 August 2010 from [http://www.math.wisc.edu/~keisler/calc.html &lt;nowiki&gt;http://www.math.wisc.edu/~keisler/calc.html&lt;/nowiki&gt;]
* Mauch, S. (2004). "''Sean's Applied Math Book''" (pdf). California Institute of Technology. Retrieved 6 May 2007 from [https://web.archive.org/web/20070614183657/http://www.cacr.caltech.edu/~sean/applied_math.pdf &lt;nowiki&gt;https://web.archive.org/web/20070614183657/http://www.cacr.caltech.edu/~sean/applied_math.pdf&lt;/nowiki&gt;]
* Sloughter, Dan (2000). "''Difference Equations to Differential Equations: An introduction to calculus''". Retrieved 17 March 2009 from [http://synechism.org/drupal/de2de/ http://synechism.org/drupal/de2de/]
* Stroyan, K.D. (2004). "''A brief introduction to infinitesimal calculus''". University of Iowa. Retrieved 6 May 2007 from https://web.archive.org/web/20050911104158/http://www.math.uiowa.edu/~stroyan/InfsmlCalculus/InfsmlCalc.htm (HTML only)
* Strang, G. (1991). "''Calculus''" Massachusetts Institute of Technology. Retrieved 6 May 2007 from [http://ocw.mit.edu/ans7870/resources/Strang/strangtext.htm http://ocw.mit.edu/ans7870/resources/Strang/strangtext.htm]
* Smith, William V. (2001). "''The Calculus''". Retrieved 4 July 2008 [http://www.math.byu.edu/~smithw/Calculus/] (HTML only).
{{Refend}}

== External links ==
{{Sister project links|Calculus}}
* {{springer|title=Calculus|id=p/c020050}}
* {{MathWorld | urlname=Calculus | title=Calculus}}
* {{PlanetMath | urlname=TopicsOnCalculus | title=Topics on Calculus | id=7592}}
* [http://djm.cc/library/Calculus_Made_Easy_Thompson.pdf Calculus Made Easy (1914) by Silvanus P. Thompson] Full text in PDF
* {{In Our Time|Calculus|b00mrfwq|Calculus}}
* [http://www.calculus.org Calculus.org: The Calculus page] at University of California, Davis&amp;nbsp;– contains resources and links to other sites
*[http://cow.math.temple.edu/ COW: Calculus on the Web] at Temple University&amp;nbsp;– contains resources ranging from pre-calculus and associated algebra
*[http://www.economics.soton.ac.uk/staff/aldrich/Calculus%20and%20Analysis%20Earliest%20Uses.htm Earliest Known Uses of Some of the Words of Mathematics: Calculus &amp; Analysis]
*[http://integrals.wolfram.com/ Online Integrator (WebMathematica)] from Wolfram Research
*[http://www.ericdigests.org/pre-9217/calculus.htm The Role of Calculus in College Mathematics] from ERICDigests.org
*[http://ocw.mit.edu/OcwWeb/Mathematics/index.htm OpenCourseWare Calculus] from the [[Massachusetts Institute of Technology]]
* [http://www.encyclopediaofmath.org/index.php?title=Infinitesimal_calculus&amp;oldid=18648 Infinitesimal Calculus]&amp;nbsp;– an article on its historical development, in ''Encyclopedia of Mathematics'', ed. [[Michiel Hazewinkel]].
* {{cite web |url=http://math.mit.edu/~djk/calculus_beginners/ |title=Calculus for Beginners and Artists |author=Daniel Kleitman, MIT}}
*[http://www.math.ucdavis.edu/~kouba/ProblemsList.html Calculus Problems and Solutions] by D. A. Kouba
*[http://www.math.tamu.edu/~dallen/history/calc1/calc1.html Donald Allen's notes on calculus]
*[http://www.imomath.com/index.php?options=277 Calculus training materials at imomath.com]
*{{en icon}} {{ar icon}} [http://www.wdl.org/en/item/4327/ The Excursion of Calculus], 1772

{{Integral}}
{{Infinitesimals}}
{{Calculus topics}}
{{Areas of mathematics}}
{{Isaac Newton}}
{{Glossaries of science and engineering}}

{{Authority control}}

[[Category:Calculus| ]]</text>
      <sha1>5ltn0dnen2lh25lkqpaopr76lx4haby</sha1>
    </revision>
  </page>
  <page>
    <title>Cauchy index</title>
    <ns>0</ns>
    <id>2079538</id>
    <revision>
      <id>802689967</id>
      <parentid>710470401</parentid>
      <timestamp>2017-09-27T20:35:06Z</timestamp>
      <contributor>
        <username>Shaded0</username>
        <id>5264861</id>
      </contributor>
      <minor/>
      <comment>/* Examples */clean up and formatting, [[WP:AWB/T|typo(s) fixed]]: Therefore → Therefore, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2858">In [[mathematical analysis]], the '''Cauchy index''' is an [[integer]] associated to a real [[rational function]] over an [[Interval (mathematics)|interval]].  By the [[Routh–Hurwitz theorem]], we have the following interpretation: the Cauchy index of

:''r''(''x'') = ''p''(''x'')/''q''(''x'')

over the [[real line]] is the difference between the number of roots of ''f''(''z'') located in the right half-plane and those located in the left half-plane.  The complex polynomial ''f''(''z'') is such that

:''f''(''iy'') = ''q''(''y'') + ''ip''(''y'').

We must also assume that ''p'' has degree less than the degree of ''q''.

==Definition==

* The '''Cauchy index''' was first defined for a pole ''s'' of the rational function ''r'' by [[Augustin Louis Cauchy]] in 1837 using [[one-sided limit]]s as:
:&lt;math&gt; I_sr = \begin{cases}
+1, &amp; \text{if } \displaystyle\lim_{x\uparrow s}r(x)=-\infty \;\land\; \lim_{x\downarrow s}r(x)=+\infty, \\
-1, &amp; \text{if } \displaystyle\lim_{x\uparrow s}r(x)=+\infty \;\land\; \lim_{x\downarrow s}r(x)=-\infty, \\
0, &amp; \text{otherwise.}
\end{cases}&lt;/math&gt;

* A generalization over the compact interval [''a'',''b''] is direct (when neither ''a'' nor ''b'' are poles of ''r''(''x'')): it is the sum of the Cauchy indices &lt;math&gt;I_s&lt;/math&gt; of ''r'' for each ''s'' located in the interval.  We usually denote it by &lt;math&gt;I_a^br&lt;/math&gt;.
* We can then generalize to intervals of type &lt;math&gt;[-\infty,+\infty]&lt;/math&gt; since the number of poles of ''r'' is a finite number (by taking the limit of the Cauchy index over [''a'',''b''] for ''a'' and ''b'' going to infinity).

==Examples==

[[Image:cauchyindex.png|thumb|300px|A rational function]]
* Consider the rational function:
:&lt;math&gt;r(x)=\frac{4x^3 -3x}{16x^5 -20x^3 +5x}=\frac{p(x)}{q(x)}.&lt;/math&gt;
We recognize in ''p''(''x'') and ''q''(''x'') respectively the [[Chebyshev polynomials]] of degree 3 and 5.  Therefore, ''r''(''x'') has poles &lt;math&gt;x_1=0.9511&lt;/math&gt;, &lt;math&gt;x_2=0.5878&lt;/math&gt;, &lt;math&gt;x_3=0&lt;/math&gt;, &lt;math&gt;x_4=-0.5878&lt;/math&gt; and &lt;math&gt;x_5=-0.9511&lt;/math&gt;, i.e. &lt;math&gt;x_j=\cos((2i-1)\pi/2n)&lt;/math&gt; for &lt;math&gt;j = 1,...,5&lt;/math&gt;.  We can see on the picture that &lt;math&gt;I_{x_1}r=I_{x_2}r=1&lt;/math&gt; and &lt;math&gt;I_{x_4}r=I_{x_5}r=-1&lt;/math&gt;.  For the pole in zero, we have &lt;math&gt;I_{x_3}r=0&lt;/math&gt; since the left and right limits are equal (which is because ''p''(''x'') also has a root in zero).  
We conclude that &lt;math&gt;I_{-1}^1r=0=I_{-\infty}^{+\infty}r&lt;/math&gt; since ''q''(''x'') has only five roots, all in [&amp;minus;1,1].  We cannot use here the Routh–Hurwitz theorem as each complex polynomial with ''f''(''iy'')&amp;nbsp;=&amp;nbsp;''q''(''y'')&amp;nbsp;+&amp;nbsp;''ip''(''y'') has a zero on the [[imaginary number|imaginary line]] (namely at the origin).

==External links==
* [http://deslab.mit.edu/DesignLab/itango/multi/sld008.htm The Cauchy Index]

[[Category:Mathematical analysis]]</text>
      <sha1>dx7m170eu7vt2e1wwf9jzmh8h3pr5f9</sha1>
    </revision>
  </page>
  <page>
    <title>Causal inference</title>
    <ns>0</ns>
    <id>37103476</id>
    <revision>
      <id>863622682</id>
      <parentid>862366596</parentid>
      <timestamp>2018-10-11T23:22:29Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>[[User:AnomieBOT/docs/TemplateSubster|Substing templates]]: {{Incomplete}}. See [[User:AnomieBOT/docs/TemplateSubster]] for info.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11181">{{expertneeded}}

'''Causal inference''' is the process of drawing a conclusion about a [[causal]] connection based on the conditions of the occurrence of an effect. The main difference between causal inference and inference of [[association (statistics)|association]] is that the former analyzes the response of the effect variable when the cause is changed.&lt;ref name=Pearl_Journal&gt;{{cite journal|last=Pearl|first=Judea|title=Causal inference in statistics: An overview|journal=Statistics Surveys|date=1 January 2009|volume=3|issue=|pages=96–146|doi=10.1214/09-SS057|url=http://ftp.cs.ucla.edu/pub/stat_ser/r350.pdf}}&lt;/ref&gt;&lt;ref name=Morgan_book&gt;{{cite book|last=Morgan|first=Stephen|author2=Winship, Chris|title=Counterfactuals and Causal inference|publisher=Cambridge University Press|year=2007|isbn=978-0-521-67193-4}}&lt;/ref&gt; The science of why things occur is called [[etiology]].  Causal inference is an example of [[causal reasoning]].

==Definition==
Inferring the [[cause]] of something has been described as:
*"...reason[ing] to the conclusion that something is, or is likely to be, the cause of something else".&lt;ref name=EB&gt;{{cite web|title=causal inference|url=http://www.britannica.com/EBchecked/topic/1442615/causal-inference|publisher=Encyclopædia Britannica, Inc.|accessdate=24 August 2014}}&lt;/ref&gt;
*"Identification of the cause or causes of a phenomenon, by establishing covariation of cause and effect, a time-order relationship with the cause preceding the effect, and the elimination of plausible alternative causes."&lt;ref name=psy&gt;{{cite book|author1=John Shaughnessy|author2=Eugene Zechmeister|author3=Jeanne Zechmeister|title=Research Methods in Psychology|date=2000|publisher=McGraw-Hill Humanities/Social Sciences/Languages|isbn=0077825365|pages=Chapter 1 : Introduction|url=http://www.mhhe.com/socscience/psychology/shaugh/ch01_concepts.html|accessdate=24 August 2014}}&lt;/ref&gt;

==Methods==
Epidemiological studies employ different [[epidemiological method]]s of collecting and measuring evidence of risk factors and effect and different ways of measuring association between the two. A [[hypothesis]] is formulated, and then tested with statistical methods (see [[Statistical hypothesis testing]]). It is [[statistical inference]] that helps decide if data are due to chance, also called [[random variation]], or indeed correlated and if so how strongly. However, [[correlation does not imply causation]], so further methods must be used to infer causation.

Common frameworks for causal inference are [[structural equation modeling]] and the [[Rubin causal model]].{{citation needed|date=August 2014}}

==In epidemiology==
[[Epidemiology]] studies patterns of health and disease in defined populations of [[living beings]] in order to [[infer]] causes and effects. An association between an [[Exposure (environmental hazard)|exposure]] to a putative [[risk factor]] and a disease may be suggestive of, but is not equivalent to causality because [[correlation does not imply causation]]. Historically, [[Koch's postulates]] have been used since the 19th century to decide if a microorganism was the cause of a disease. In the 20th century the [[Bradford Hill criteria]], described in 1965&lt;ref name="bh65"&gt;{{cite journal |last=Hill |first=Austin Bradford |year=1965 |title=The Environment and Disease: Association or Causation? |journal=[[Proceedings of the Royal Society of Medicine]] |volume=58 |pages=295–300 |url=http://www.edwardtufte.com/tufte/hill |pmid=14283879 |pmc=1898525 |issue=5}}&lt;/ref&gt; have been used to assess causality of variables outside microbiology, although even these criteria are not exclusive ways to determine causality.

In [[molecular epidemiology]] the phenomena studied are on a [[molecular biology]] level, including genetics, where [[biomarkers]] are evidence of cause or effects.

A recent trend{{when|date=August 2014}} is to identify [[evidence]] for influence of the exposure on [[molecular pathology]] within diseased [[Tissue (biology)|tissue]] or cells, in the emerging interdisciplinary field of [[molecular pathological epidemiology]] (MPE).{{third-party-inline|date=August 2014}} Linking the exposure to molecular pathologic signatures of the disease can help to assess causality. {{third-party-inline|date=August 2014}} Considering the inherent nature of [[heterogeneity]] of a given disease, the unique disease principle, disease phenotyping and subtyping are trends in biomedical and [[public health]] sciences, exemplified as [[personalized medicine]] and [[precision medicine]].{{third-party-inline|date=August 2014}}

==In computer science==
Determination of cause and effect from joint observational data for two time-independent variables, say X and Y, has been tackled using asymmetry between evidence for some model in the directions, X → Y and Y → X. One idea is to incorporate an independent noise term in the model to compare the evidences of the two directions.

Here are some of the noise models for the hypothesis Y → X with the noise E:
* Additive noise:&lt;ref&gt;Hoyer, Patrik O., et al. "Nonlinear causal discovery with additive noise models." NIPS. Vol. 21. 2008.&lt;/ref&gt; &lt;math&gt;Y = F(X)+E&lt;/math&gt;
* Linear noise:&lt;ref&gt;Shimizu, Shohei, et al. "DirectLiNGAM: A direct method for learning a linear non-Gaussian structural equation model." The Journal of Machine Learning Research 12 (2011): 1225-1248.&lt;/ref&gt; &lt;math&gt;Y = pX + qE&lt;/math&gt;
* Post-non-linear:&lt;ref&gt;Zhang, Kun, and Aapo Hyvärinen. "On the identifiability of the post-nonlinear causal model." Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. AUAI Press, 2009.&lt;/ref&gt; &lt;math&gt;Y = G(F(X)+E)&lt;/math&gt;
* Heteroskedastic noise: &lt;math&gt;Y = F(X)+E.G(X)&lt;/math&gt;
* Functional noise:&lt;ref name="Mooij"&gt;Mooij, Joris M., et al. "Probabilistic latent variable models for distinguishing between cause and effect." NIPS. 2010.&lt;/ref&gt; &lt;math&gt;Y = F(X,E)&lt;/math&gt;

The common assumption in these models are:
* There are no other causes of Y.
* X and E have no common causes.
* Distribution of cause is independent from causal mechanisms.

On an intuitive level, the idea is that the factorization of the joint distribution P(Cause,Effect) into  P(Cause)*P(Effect | Cause) typically yields models of lower total complexity than the factorization into  P(Effect)*P(Cause | Effect). Although the notion of “complexity” is intuitively appealing, it is not obvious how it should be precisely defined.&lt;ref name="Mooij"/&gt; A different family of methods attempt to discover causal "footprints" from large amounts of labeled data, and allow the prediction of more flexible causal relations.&lt;ref&gt;Lopez-Paz, David, et al. "Towards a learning theory of cause-effect inference" ICML. 2015&lt;/ref&gt;

==In statistics and economics==
{{Main|Causality#Statistics and economics}}

In [[statistics]] and [[economics]], causality is often tested for using [[regression analysis|regression]]. Several methods can be used to distinguish actual causality from spurious indications of causality. First, the [[explanatory variable]] could be one that conceptually could not be caused by the [[dependent variable]], thereby avoiding the possibility of being misled by [[reverse causation]]: for example, if the independent variable is rainfall and the dependent variable is the [[futures price]] of some agricultural commodity. Second, the [[instrumental variables]] technique may be employed to remove any reverse causation by introducing a role for other variables (instruments) that are known to be unaffected by the dependent variable. Third, the principle that effects cannot precede causes can be invoked, by including on the right side of the regression only variables that precede in time the dependent variable. Fourth, other regressors are included to ensure that [[confounding variable]]s are not causing a regressor to spuriously appear to be significant. Correlation by coincidence, as opposed to correlation reflecting actual causation, can be ruled out by using large [[sample size|samples]] and by performing [[cross-validation (statistics)|cross validation]] to check that correlations are maintained on data that were not used in the regression.

==Education==
Graduate courses on causal inference have been introduced to the curriculum of many schools.

*[[Arizona State University]], Department of Statistics
*[[Duke University]], Department of Political Science&lt;ref&gt;{{Cite news|url=https://polisci.duke.edu/courses/POLSCI748|title=Introduction to Causal Inference|date=2015-05-21|work=Political Science|access-date=2018-08-26|language=en}}&lt;/ref&gt;
*[[Saint Louis University]], College of Public Health &amp; Social Justice
* [[Carnegie Mellon University]], Department of Philosophy
* [[Harvard University]], School of Public Health
* [[Johns Hopkins University]], Department of Computer Science, Bloomberg School of Public Health
* [[London School of Hygiene &amp; Tropical Medicine]]
* [[Karolinska Institutet]], Department of Medical Epidemiology and Biostatistics
* [[McGill University]], Department of Epidemiology, Biostatistics and Occupational Health
* [[New York University]], Department of Applied Statistics, Social Sciences, and Humanities
* [[Northwestern University]], Department of Sociology and Kellogg School of Management
* [[University of Pittsburgh]], Department of Psychology in Education
* [[University of Groningen]], Department of Statistics &amp; Measurement Theory
* [[University of California, Los Angeles]], Department of Epidemiology and Department of Computer Science
* [[University of California, Berkeley]], School of Public Health
* [[University of Copenhagen]], Department of Public Health
* [[University of Pennsylvania]], Department of Biostatistics and Epidemiology
* [[University of Texas]], Department of Educational Psychology &lt;ref&gt;https://education.utexas.edu/departments/educational-psychology/graduate-programs/quantitative-methods/required-courses-doctoral&lt;/ref&gt;
* [[The University of British Columbia]], School of Population and Public Health
* [[Vanderbilt University]], Department of Leadership, Policy, and Organizations, Department of Biostatistics
* [[Stevens Institute of Technology]], Department of Computer Science &lt;ref&gt;http://www.skleinberg.org/teaching/CI15/index.html&lt;/ref&gt;
* [[University of North Carolina at Chapel Hill]], Department of Biostatistics &lt;ref&gt;http://www.bios.unc.edu/~mhudgens/bios/776/2017/bios776.html&lt;/ref&gt;
* [[University of California, Irvine]], Department of Statistics &lt;ref&gt;https://www.ics.uci.edu/~sternh/courses/265/&lt;/ref&gt;

== See also ==
* [[Granger causality]]
* [[Multivariate statistics]]
* [[Partial least squares regression]]
* [[Pathogenesis]]
* [[Pathology]]
* [[Regression analysis]]
* [[Transfer entropy]]

== References ==
{{Reflist}}

==External links==
{{Commonscat}}
*[http://clopinet.com/isabelle/Projects/NIPS2013/ NIPS 2013 Workshop on Causality]
*[http://webdav.tuebingen.mpg.de/causality/ Causal inference at the Max-Planck-Institute for Intelligent Systems Tübingen]

{{Portal bar|Science}}

[[Category:Causal inference| ]]
[[Category:Graphical models]]
[[Category:Regression analysis]]
[[Category:Inductive reasoning]]
[[Category:Philosophy of statistics]]</text>
      <sha1>gw9rw35ku8v5c0f79xvrn698qdwinw7</sha1>
    </revision>
  </page>
  <page>
    <title>Community Z Tools</title>
    <ns>0</ns>
    <id>2668560</id>
    <revision>
      <id>795020482</id>
      <parentid>745041561</parentid>
      <timestamp>2017-08-11T14:10:55Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.5beta)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1701">The '''Community Z Tools''' ('''CZT''') initiative is based around a [[SourceForge]] project to build a set of tools for the [[Z notation]], a [[formal methods|formal method]] useful in [[software engineering]]. Tools include support for editing, typechecking and animating Z specifications. There is some support for extensions such as [[Object-Z]] and [[TCOZ]]. The tools are built using the [[Java (programming language)|Java programming language]].

CZT was proposed by [[Andrew Martin (computer scientist)|Andrew Martin]] of [[Oxford University]] in 2001.&lt;ref&gt;{{cite article| first=Andrew | last=Martin | authorlink=Andrew Martin (computer scientist) | url=http://www.cs.ox.ac.uk/andrew.martin/CZT/proposal.html | title=Proposal: Community Z Tools Project (CZT) | publisher=[[University of Oxford]] | location=UK | date=25 September 2001 }}&lt;/ref&gt;

==References==
{{reflist}}

==External links==
* [http://czt.sourceforge.net/ CZT SourceForge website]
* [http://www.cs.ox.ac.uk/people/andrew.martin/CZT/ CZT initiative] information by [[Andrew Martin (computer scientist)|Andrew Martin]]
* [https://web.archive.org/web/20061025194002/http://linux.softpedia.com/get/Programming/Code-Generators/Community-Z-Tools-4494.shtml Softpedia information]
* ''[http://www.cs.waikato.ac.nz/~marku/papers/zb2005_czt.pdf CZT: A Framework for Z Tools]'' by Petra Malik and Mark Utting ([[Portable Document Format|PDF]])

[[Category:2001 establishments in England]]
[[Category:2001 software]]
[[Category:Z notation]]
[[Category:Research projects]]
[[Category:Free software programmed in Java (programming language)]]
[[Category:Department of Computer Science, University of Oxford]]

{{programming-software-stub}}</text>
      <sha1>mloewy1d9ibn4hgaau7f7e30huw64sa</sha1>
    </revision>
  </page>
  <page>
    <title>Crossing number inequality</title>
    <ns>0</ns>
    <id>50834770</id>
    <revision>
      <id>795538447</id>
      <parentid>741268115</parentid>
      <timestamp>2017-08-14T21:41:36Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.5beta)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9089">In the mathematics of [[graph drawing]], the '''crossing number inequality''' or '''crossing lemma''' gives a [[lower bound]] on the [[Crossing number (graph theory)|minimum number of crossings]] of a given [[Graph (discrete mathematics)|graph]], as a function of the number of edges and vertices of the graph. It states that, for graphs where the number {{mvar|e}} of edges is sufficiently larger than the number {{mvar|n}} of vertices, the crossing number is at least proportional to {{math|''e''&lt;sup&gt;3&lt;/sup&gt;/''n''&lt;sup&gt;2&lt;/sup&gt;}}.

It has applications in [[VLSI]] design and [[combinatorial geometry]],
and was discovered independently by [[Miklós Ajtai|Ajtai]], [[Václav Chvátal|Chvátal]], Newborn, and [[Endre Szemerédi|Szemerédi]]&lt;ref&gt;{{citation
 | last1 = Ajtai | first1 = M. | author1-link = Miklós Ajtai
 | last2 = Chvátal | first2 = V. | author2-link = Václav Chvátal
 | last3 = Newborn | first3 = M. M.
 | last4 = Szemerédi | first4 = E. | author4-link = Endre Szemerédi
 | contribution = Crossing-free subgraphs
 | mr = 806962
 | pages = 9–12
 | publisher = North-Holland, Amsterdam
 | series = North-Holland Mathematics Studies
 | title = Theory and practice of combinatorics
 | volume = 60
 | year = 1982}}.&lt;/ref&gt;
and by [[F. Thomson Leighton|Leighton]].&lt;ref name="leighton"&gt;{{citation
 | last = Leighton | first = T. | author-link = F. Thomson Leighton
 | location = Cambridge, MA
 | publisher = MIT Press
 | series = Foundations of Computing Series
 | title = Complexity Issues in VLSI
 | year = 1983}}.&lt;/ref&gt;

==Statement and history==
The crossing number inequality states that, for an undirected [[simple graph]] {{mvar|G}} with {{mvar|n}} vertices and {{mvar|e}} edges such that {{math|''e'' &gt; 7''n''}}, the [[Crossing number (graph theory)|crossing number]] {{math|cr(''G'')}} obeys the [[Inequality (mathematics)|inequality]] 
:&lt;math&gt;\operatorname{cr}(G) \geq \frac{e^3}{29 n^2}.&lt;/math&gt;

The constant {{math|29}} is the best known to date, and is due to Ackerman.&lt;ref name="pt"&gt;{{citation
 | last = Ackerman
 | first = Eyal
 | title = On topological graphs with at most four crossings per edge
 | url = http://sci.haifa.ac.il/~ackerman/publications/4crossings.pdf
 | year = 2013
 | deadurl = yes
 | archiveurl = https://web.archive.org/web/20140714181310/http://sci.haifa.ac.il/~ackerman/publications/4crossings.pdf
 | archivedate = 2014-07-14
 | df = 
 }}.&lt;/ref&gt;
For earlier results with weaker constants see {{harvtxt|Pach|Tóth|1997}} and {{harvtxt|Pach|Radoičić|Tardos|Tóth|2006}}.&lt;ref&gt;{{citation
 | last1 = Pach | first1 = János | author1-link = János Pach
 | last2 = Tóth | first2 = Géza
 | doi = 10.1007/BF01215922
 | issue = 3
 | journal = [[Combinatorica]]
 | mr = 1606052
 | pages = 427–439
 | title = Graphs drawn with few crossings per edge
 | volume = 17
 | year = 1997}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last1 = Pach | first1 = János | author1-link = János Pach
 | last2 = Radoičić | first2 = Radoš
 | last3 = Tardos | first3 = Gábor
 | last4 = Tóth | first4 = Géza
 | doi = 10.1007/s00454-006-1264-9
 | issue = 4
 | journal = [[Discrete and Computational Geometry]]
 | mr = 2267545
 | pages = 527–552
 | title = Improving the crossing lemma by finding more crossings in sparse graphs
 | volume = 36
 | year = 2006}}.&lt;/ref&gt;
 
The constant {{math|7}} can be lowered to {{math|4}}, but at the expense of replacing {{math|29}} with the worse constant of {{math|64}}.

==Applications==
The motivation of Leighton in studying crossing numbers was for applications to [[VLSI]] design in theoretical computer science.&lt;ref name="leighton"/&gt;

Later, {{harvtxt|Székely|1997}} realized that this inequality yielded very simple proofs of some important theorems in [[Incidence (geometry)|incidence geometry]]. For instance, the [[Szemerédi–Trotter theorem]], an [[upper bound]] on the number of incidences that are possible between given numbers of points and lines in the plane,
follows by constructing a graph whose vertices are the points and whose edges are the segments of lines between incident points. If there were more incidences than the Szemerédi–Trotter bound, this graph would necessarily have more crossings than the total number of pairs of lines, an impossibility.
The inequality can also be used to prove [[Beck's theorem (geometry)|Beck's theorem]], that if a finite point set does not have a linear number of collinear points, then it determines a quadratic number of distinct lines.&lt;ref&gt;{{citation
 | last = Székely | first = L. A.
 | doi = 10.1017/S0963548397002976
 | issue = 3
 | journal = [[Combinatorics, Probability and Computing]]
 | mr = 1464571
 | pages = 353–358
 | title = Crossing numbers and hard Erdős problems in discrete geometry
 | volume = 6
 | year = 1997}}.&lt;/ref&gt;
Similarly, Tamal Dey used it to prove upper bounds on [[K-set (geometry)|geometric ''k''-sets]].&lt;ref&gt;{{citation
 | last = Dey | first = T. L.
 | doi = 10.1007/PL00009354
 | issue = 3
 | journal = [[Discrete and Computational Geometry]]
 | mr = 1608878
 | pages = 373–382
 | title = Improved bounds for planar {{mvar|k}}-sets and related problems
 | volume = 19
 | year = 1998}}&lt;/ref&gt;

==Proof==
We first give a preliminary estimate: for any graph {{mvar|G}} with {{mvar|n}} vertices and {{mvar|e}} edges, we have

: &lt;math&gt;\operatorname{cr}(G) \geq e - 3n.&lt;/math&gt;

To prove this, consider a diagram of {{mvar|G}} which has exactly {{math|cr(''G'')}} crossings.  Each of these crossings can be removed by removing an edge from {{mvar|G}}. Thus we can find a graph with at least {{math|''e'' − cr(''G'')}} edges and {{mvar|n}} vertices with no crossings, and is thus a [[planar graph]]. But from [[planar graph|Euler's formula]] we must then have {{math|''e'' − cr(''G'') ≤ 3''n''}}, and the claim follows. (In fact we have {{math|''e'' − cr(''G'') ≤ 3''n'' − 6}} for {{math|''n'' ≥ 3}}).

To obtain the actual crossing number inequality, we now use a [[probabilistic method|probabilistic argument]]. We let {{math|0 &lt; ''p'' &lt; 1}} be a [[probability]] parameter to be chosen later, and construct a [[random graph|random subgraph]] {{mvar|H}} of {{mvar|G}} by allowing each vertex of {{mvar|G}} to lie in {{mvar|H}} independently with probability {{mvar|p}}, and allowing an edge of {{mvar|G}} to lie in {{mvar|H}} if and only if its two vertices were chosen to lie in {{mvar|H}}. Let {{mvar|e&lt;sub&gt;H&lt;/sub&gt;, n&lt;sub&gt;H&lt;/sub&gt;}} and {{math|cr&lt;sub&gt;''H''&lt;/sub&gt;}} denote the number of edges, vertices and crossings of {{mvar|H}}, respectively. Since {{mvar|H}} is a subgraph of {{mvar|G}}, this diagram contains a diagram of {{mvar|H}}. By the preliminary crossing number inequality, we have

:&lt;math&gt;\operatorname{cr}_H \geq e_H - 3n_H.&lt;/math&gt;

Taking [[expected value|expectation]]s we obtain

:&lt;math&gt;\mathbf{E}[\operatorname{cr}_H] \geq \mathbf{E}[e_H] - 3 \mathbf{E}[n_H].&lt;/math&gt;

Since each of the {{mvar|n}} vertices in {{mvar|G}} had a probability {{mvar|p}} of being in {{mvar|H}}, we have {{math|'''E'''[''n&lt;sub&gt;H&lt;/sub&gt;''] {{=}} ''pn''}}. Similarly, each of the edges in {{mvar|G}} has a probability {{math|''p''&lt;sup&gt;2&lt;/sup&gt;}} of remaining in {{mvar|H}} since both endpoints need to stay in {{mvar|H}}, therefore {{math|'''E'''[''e&lt;sub&gt;H&lt;/sub&gt;''] {{=}} ''p''&lt;sup&gt;2&lt;/sup&gt;''e''}}. Finally, every crossing in the diagram of {{mvar|G}} has a probability {{math|''p''&lt;sup&gt;4&lt;/sup&gt;}} of remaining in {{mvar|H}}, since every crossing involves four vertices. To see this consider a diagram of {{mvar|G}} with {{math|cr(''G'')}} crossings. We may assume that any two edges in this diagram with a common vertex are disjoint, otherwise we could interchange the intersecting parts of the two edges and reduce the crossing number by one. Thus every crossing in this diagram involves four distinct vertices of {{mvar|G}}. Therefore, {{math|'''E'''[cr&lt;sub&gt;''H''&lt;/sub&gt;] {{=}} ''p''&lt;sup&gt;4&lt;/sup&gt;cr(''G'')}} and we have

: &lt;math&gt; p^4 \operatorname{cr}(G) \geq p^2 e - 3 p n.&lt;/math&gt;

Now if we set {{math|''p'' {{=}} 4''n''/''e'' &lt; 1}} (since we assumed that {{math|''e'' &gt; 4''n''}}), we obtain after some algebra

: &lt;math&gt; \operatorname{cr}(G) \geq \frac{e^3}{64 n^2}.&lt;/math&gt;

A slight refinement of this argument allows one to replace {{math|64}} by {{math|33.75}} for {{math|''e'' &gt; 7.5''n''}}.&lt;ref name="pt"/&gt;

==Variations==
For graphs with [[Girth (graph theory)|girth]] larger than {{math|2''r''}} and {{math|''e'' ≥ 4''n''}}, {{harvtxt|Pach|Spencer|Tóth|2000}} demonstrated an improvement of this inequality to&lt;ref&gt;{{citation
 | last1 = Pach | first1 = J. | author1-link = János Pach
 | last2 = Spencer | first2 = J. | author2-link = Joel Spencer
 | last3 = Tóth | first3 = G.
 | doi = 10.1145/304893.304943
 | issue = 4
 | journal = [[Discrete and Computational Geometry]]
 | mr = 1799605
 | pages = 623–644
 | title = New bounds on crossing numbers
 | volume = 24
 | year = 2000}}.&lt;/ref&gt;
:&lt;math&gt;\operatorname{cr}(G) \geq c_r\frac{e^{r+2}}{n^{r+1}}.&lt;/math&gt;

==References==
{{reflist|30em}}

[[Category:Topological graph theory]]
[[Category:Inequalities]]
[[Category:Articles containing proofs]]
[[Category:Graph drawing]]</text>
      <sha1>nv01oe5yc1hxreynjxsj9azu0myya1w</sha1>
    </revision>
  </page>
  <page>
    <title>Curtis Greene</title>
    <ns>0</ns>
    <id>34818925</id>
    <revision>
      <id>857348696</id>
      <parentid>795658657</parentid>
      <timestamp>2018-08-31T04:02:01Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* References */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4892">'''Curtis Greene''' is an American [[mathematician]], specializing in [[algebraic combinatorics]]. He is the J. McLain King Professor of Mathematics at [[Haverford College]] in [[Pennsylvania]].&lt;ref name="hc"&gt;[http://www.haverford.edu/faculty/cgreene Faculty profile] and [http://www.haverford.edu/math/cgreene.html home page] {{webarchive|url=https://web.archive.org/web/20120413060546/http://www.haverford.edu/math/cgreene.html |date=2012-04-13 }}, Haverford College, retrieved 2012-02-20.&lt;/ref&gt;

Greene did his undergraduate studies at [[Harvard University]], and earned his Ph.D. in 1969 from the [[California Institute of Technology]] under the supervision of [[Robert P. Dilworth]].&lt;ref name="hc"/&gt;&lt;ref&gt;{{mathgenealogy|id=10410}}&lt;/ref&gt; He held positions at the [[Massachusetts Institute of Technology]] and the [[University of Pennsylvania]] before moving to Haverford.

Greene has written highly cited research papers on [[Sperner family|Sperner families]],&lt;ref&gt;{{citation
 | last1 = Greene | first1 = Curtis
 | last2 = Kleitman | first2 = Daniel J. | author2-link = Daniel Kleitman
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]] | series = Series A
 | mr = 0398844
 | pages = 41–68
 | title = The structure of Sperner ''k''-families
 | volume = 20
 | year = 1976 | doi=10.1016/0097-3165(76)90077-7}}. {{citation
 | last1 = Greene | first1 = Curtis
 | last2 = Kleitman | first2 = Daniel J. | author2-link = Daniel Kleitman
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]] | series = Series A
 | mr = 0389608
 | pages = 80–88
 | title = Strong versions of Sperner's theorem
 | volume = 20
 | year = 1976 | doi=10.1016/0097-3165(76)90079-0}}. {{citation
 | last = Greene | first = Curtis
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]] | series = Series A
 | mr = 0398912
 | pages = 69–79
 | title = Some partitions associated with a partially ordered set
 | volume = 20
 | year = 1976
 | doi=10.1016/0097-3165(76)90078-9}}&lt;/ref&gt; [[Young tableau]]x,&lt;ref&gt;{{citation
 | last = Greene | first = Curtis
 | journal = Advances in Mathematics
 | mr = 0354395
 | pages = 254–265
 | title = An extension of Schensted's theorem
 | volume = 14
 | year = 1974
 | doi=10.1016/0001-8708(74)90031-0}}. {{citation
 | last1 = Edelman | first1 = Paul
 | last2 = Greene | first2 = Curtis
 | doi = 10.1016/0001-8708(87)90063-6
 | issue = 1
 | journal = Advances in Mathematics
 | mr = 871081
 | pages = 42–99
 | title = Balanced tableaux
 | volume = 63
 | year = 1987}}. {{citation
 | last1 = Greene | first1 = Curtis
 | last2 = Nijenhuis | first2 = Albert | author2-link = Albert Nijenhuis
 | last3 = Wilf | first3 = Herbert S. | author3-link = Herbert Wilf
 | doi = 10.1016/0001-8708(79)90023-9
 | issue = 1
 | journal = Advances in Mathematics
 | mr = 521470
 | pages = 104–109
 | title = A probabilistic proof of a formula for the number of Young tableaux of a given shape
 | volume = 31
 | year = 1979}}.&lt;/ref&gt; and [[bijective proof|combinatorial equivalences]] between [[Arrangement of hyperplanes|hyperplane arrangement]]s, [[Zonohedron|zonotopes]], and [[Strong orientation|graph orientations]].&lt;ref&gt;{{citation
 | last1 = Greene | first1 = Curtis
 | last2 = Zaslavsky | first2 = Thomas | author2-link = Thomas Zaslavsky
 | doi = 10.2307/1999604
 | issue = 1
 | journal = [[Transactions of the American Mathematical Society]]
 | mr = 712251
 | pages = 97–126
 | title = On the interpretation of Whitney numbers through arrangements of hyperplanes, zonotopes, non-Radon partitions, and orientations of graphs
 | volume = 280
 | year = 1983}}.&lt;/ref&gt; With [[Daniel Kleitman]], he has also written a highly cited survey paper on [[combinatorial proof]] techniques.&lt;ref&gt;{{citation
 | last1 = Greene | first1 = Curtis
 | last2 = Kleitman | first2 = Daniel J. | author2-link = Daniel Kleitman
 | contribution = Proof techniques in the theory of finite sets
 | location = Washington, D.C.
 | mr = 513002
 | pages = 22–79
 | publisher = Math. Assoc. America
 | series = MAA Stud. Math.
 | title = Studies in combinatorics
 | volume = 17
 | year = 1978}}.&lt;/ref&gt;

In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-01-19.&lt;/ref&gt;

==References==
{{reflist}}

{{authority control}}

{{DEFAULTSORT:Greene, Curtis}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Harvard University alumni]]
[[Category:California Institute of Technology alumni]]
[[Category:Massachusetts Institute of Technology faculty]]
[[Category:University of Pennsylvania faculty]]
[[Category:Haverford College faculty]]
[[Category:Combinatorialists]]
[[Category:Fellows of the American Mathematical Society]]</text>
      <sha1>7kg1yc8qa6dwtt4025xvxvmxeryeocm</sha1>
    </revision>
  </page>
  <page>
    <title>Cyborg Foundation</title>
    <ns>0</ns>
    <id>35749872</id>
    <revision>
      <id>869934851</id>
      <parentid>868801782</parentid>
      <timestamp>2018-11-21T09:15:32Z</timestamp>
      <contributor>
        <username>Seemabashir</username>
        <id>33775359</id>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9088">The '''Cyborg Foundation''' is a [[nonprofit organization]] created in 2010 by [[cyborg]] activists and artists [[Moon Ribas]] and [[Neil Harbisson]].&lt;ref&gt;García, F.C. [http://www.lavanguardia.es/vida/20110301/54121537968/nace-una-fundacion-dedicada-a-convertir-humanos-en-ciborgs.html "Nace una fundación dedicada a convertir humanos en ciborgs"], ''[[La Vanguardia]]'', 1 March 2011.&lt;/ref&gt; The foundation is a platform for the research, creation and promotion of projects related to extending and creating new senses and perceptions by applying technology to the human body.&lt;ref&gt;Rottenschlage, Andreas [http://www.redbull.com/cs/Satellite/en_INT/Article/Thesoundofthecyborg-021242963775427 "The Sound of the Cyborg"] ''[[The Red Bulletin]]'', 1 Mar 2011.&lt;/ref&gt; The Cyborg Foundation was first housed in [[Tecnocampus]] [[scientific park|Scientific Park]] (Barcelona) and is currently based in [[New York City]]. It collaborates with several institutions, universities and research centers around the world.&lt;ref&gt;Redacción [http://v7.yucatan.com.mx/2/nota-7/200214-asombrados-por-un-cyborg.htm "Asombrados por un cyborg. La Universidad Modelo recibe a Neil Harbisson"]{{dead link|date=August 2017 |bot=InternetArchiveBot |fix-attempted=yes }}, [[Diario de Yucatan]], 17 November 2011&lt;/ref&gt;

Their mission is to assist humans in becoming cyborgs, promote the use of cybernetics as part of the human body and defend cyborg rights.&lt;ref&gt;Molinsky, Eric [http://www.studio360.org/2011/nov/04/neil-harbisson/ "Neil Harbisson, cyborg"] {{webarchive|url=https://web.archive.org/web/20120428172134/http://www.studio360.org/2011/nov/04/neil-harbisson/ |date=2012-04-28 }}, [[Studio 360]], [[WNYC]], 4 November 2011&lt;/ref&gt; 
They have donated [[Cyborg antenna|cyborg antennas]] to blind communities and has taught colour to blind children to help them develop the sense of colour.&lt;ref&gt;EFE [http://www.prensa.com/impreso/tecnologia-%C2%B4cyborg%C2%B4-para-la-vision/35482 "Tecnologia cyborg para la vision"], [[EFE]], 27 October 2011&lt;/ref&gt;The foundation believes that some cybernetic extensions should be treated as body parts, not as devices.&lt;ref&gt;Maia, Rafael [http://tecnologia.terra.com.br/campus-party/2012/noticias/0,,OI5602708-EI19138,00-Nao+quero+vender+olhos+diz+ciborgue+que+ouve+as+cores.html "Nao quero vender olhos"], [[Terra Networks]], 9 February 2012.&lt;/ref&gt;

==History==
[[File:Republica 2013 - How to become a Cyborg.webm|thumb|Neil Harbisson and Moon Ribas at the [[Berlin]] based [[re:publica]] 2013 conference: "Life with extra Senses &amp;ndash; How to become a Cyborg"|thumbtime=11:17|upright=1.2]]
The foundation was created as a response to the growing number of letters and emails that [[Neil Harbisson]] received from people around the world interested in becoming a cyborg.&lt;ref&gt;Calls, Albert [http://www.tribunamaresme.com/noticies/noticia.php?id=6672 "“Les noves tecnologies seran part del nostre cos i extensió del cervell”"]{{dead link|date=August 2017 |bot=InternetArchiveBot |fix-attempted=yes }} ''La Tribuna'', 3 Jan 2011.&lt;/ref&gt; Since its creation the foundation has kick-started several new-sense development projects and has donated [[Cyborg antenna|cyborg antennas]] to blind communities in Europe, Asia and America.&lt;ref&gt;EFE [http://www.prensa.com/impreso/tecnologia-%C2%B4cyborg%C2%B4-para-la-vision/35482 "Tecnologia cyborg para la vision"], [[EFE]], 27 October 2011&lt;/ref&gt; The first blind person to try out an eyeborg was [[Sabriye Tenberken]] followed by blind students from [[Braille Without Borders]] in Tibet and members of the Sociedad de Ciegos de Pichincha in Ecuador.&lt;ref&gt;Redacción [http://elcomercio.pe/tecnologia/721054/noticia-fundacion-se-dedica-convertir-humanos-ciborgs "Una fundación se dedica a convertir humanos en ciborgs"] ''[[El Comercio (Peru)]]'', 1 Mar 2011.&lt;/ref&gt; 
In 2010, the foundation was the overall winner of the Cre@tic Awards, organized by Tecnocampus Mataró.&lt;ref&gt;Martínez, Ll. [http://www.avui.cat/noticia/article/2-societat/5-societat/333597-la-fundacio-cyborg-sendu-el-primer-premi-dels-cretic.html "La Fundació Cyborg s'endú el primer premi dels Cre@tic"], ''[[Avui]]'', 20 Nov 2010&lt;/ref&gt;
In 2012, Spanish film director Rafel Duran Torrent, created a short film about the Cyborg Foundation. In 2013, the film won the Grand Jury Prize at the [[Sundance Film Festival]]'s Focus Forward Filmmakers Competition.&lt;ref&gt;Pond, Steve [https://http "Cyborg Foundation" wins $100K Focus Forward prize]  {{webarchive|url=https://web.archive.org/web/20160114075411/https://http/|date=January 14, 2016}}, ''[[Chicago Tribune]]'', 22 January 2013&lt;/ref&gt;

===Partnerships and Collaborations===
* In 2016, Cyborg Foundation together with [[Parsons/New School|Parsons School of Design]], [[The New School]], Sensorium Works and [[Pioneer Works]] launched [http://www.cyborgfutures.com Cyborg Futures], a cyborg residency program in New York designed to further the Cyborg Foundation’s mission to support the use of cybernetics as part of the body and begin to introduce the diverse possibilities for artistic practices that utilize extended sensory capabilities.&lt;ref&gt;{{Cite news|url=https://howwegettonext.com/sense-hacking-the-real-life-cyborgs-of-the-diy-augmentation-scene-e339ac9855bf|title=Sense Hacking: The Real-Life Cyborgs of the DIY Augmentation Scene|date=2017-08-15|work=How We Get To Next|access-date=2017-12-06}}&lt;/ref&gt; 

* A number of collaborations exist with Ecuador, since its president [[Lenin Moreno]] announced that his government would collaborate with the Cyborg Foundation to create new sensory organs.&lt;ref&gt;Redaccion [http://www.eltiempo.com.ec/noticias-cuenca/81856-gobierno-impulsara-plan-para-no-videntes/ "Gobierno impulsara plan para no videntes"], [[El Tiempo (Ecuador)]], 30 October 2011.&lt;/ref&gt; 

* In 2012,&lt;ref&gt;Redação [http://www.diariodepernambuco.com.br/nota.asp?materia=20120430114940 "Primeiro ciborgue do mundo estará nesta quarta na UPE"] {{webarchive|url=https://web.archive.org/web/20120512032546/http://diariodepernambuco.com.br/nota.asp?materia=20120430114940|date=2012-05-12}}, ''[[Diário de Pernambuco]]'', 30 April 2012&lt;/ref&gt; the Cyborg Foundation signed a partnership to create new cybernetic extensions in collaboration with [[Universidade de Pernambuco]] in Brazil.&lt;ref&gt;Lins, Letícia [http://oglobo.globo.com/tecnologia/homem-ciborgue-desenvolve-projeto-no-brasil-4794658 "Homem-ciborgue desenvolve projeto no Brasil"], ''[[O Globo]]'', 2 May 2012&lt;/ref&gt; 
* In 2016, together with [http://mesa.do/cyborg Mesa &amp; Cadeira], a group of people (which included a dental surgeon, engineers and a psychologist) created “Design Yourself” – a visual identity, tagline and website for the Foundation. The site explores the different human relationships with technology, and offers tools for expanding senses and abilities, and in the process, for becoming a cyborg. The group also developed a dental implant, that uses bluetooth technology and morse code to communicate. The first demonstration of the Transdental Communication System was presented in Sao Paulo.[https://mesacyborg.splashthat.com]

== Cyborg Rights ==
In 2014, the Cyborg Foundation participated in the European Union commission for Robotic Laws.[http://www.robolaw.eu]

In 2016 together with electronic civil rights and civil liberties researcher and activist Rich MacKinnon, a list of Cyborg Civil Rights where exposed and proposed at [[South by Southwest]].  The rights exposed the redefinition and defence of cyborg civil liberties and the sanctity of cyborg bodies. And foresaw a battle for the ownership, licensing, and control of augmented, alternative, and synthetic anatomies; the communication, data and telemetry produced by them; and the very definition of what it means to be human.[https://schedule.sxsw.com/2017/events/PP62399]

==See Also==
{{div col|colwidth=30em}}
* [[Moon Ribas]]
* [[Cyborg art]]
* [[Neil Harbisson]]
* [[Manel Muñoz]]
{{div col end}}

==References==
{{Reflist|2}}

==External links==
{{Commons category|Cyborg Foundation}}
*[http://www.cyborgfoundation.com/ Cyborg Foundation website]
*[http://blog.ted.com/2012/06/27/listening-to-picasso-neil-harbisson-at-tedglobal2012 TED Global: "Listening to Picasso"]
*[http://www.lavanguardia.es/vida/20110301/54121537968/nace-una-fundacion-dedicada-a-convertir-humanos-en-ciborgs.html La Vanguardia: "Nace una fundación dedicada a convertir humanos en ciborgs"]
*[http://bits.blogs.nytimes.com/2012/07/02/a-surgical-implant-for-seeing-colors-through-sound The New York Times: "A surgical implant for seeing colors through sound"]
*[http://www.focusforwardfilms.com/contest/13/cyborg-foundation-rafel-duran-torrent Cyborg Foundation Rafel Duran Torrent]
*[https://www.foundationguide.org/foundations-trust/the-cyborg-foundation/ Foundation Guide]

{{Robotics}}

[[Category:Biotechnology organizations]]
[[Category:Biocybernetics]]
[[Category:Cybernetics]]
[[Category:Futurology]]
[[Category:Implants (medicine)]]
[[Category:Neurotechnology]]
[[Category:Robotics organizations]]
[[Category:Cyborgs]]
[[Category:Articles containing video clips]]</text>
      <sha1>do0c944xd1mtk4ivgh76mcme90k5163</sha1>
    </revision>
  </page>
  <page>
    <title>Direct method in the calculus of variations</title>
    <ns>0</ns>
    <id>24499402</id>
    <revision>
      <id>852376747</id>
      <parentid>852376573</parentid>
      <timestamp>2018-07-28T15:19:36Z</timestamp>
      <contributor>
        <ip>45.125.41.204</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9222">In the [[calculus of variations]], a topic in [[mathematics]], '''the direct method''' is a general method for constructing a proof of the existence of a minimizer for a given [[Functional (mathematics)|functional]],&lt;ref&gt;Dacorogna, pp. 1&amp;ndash;43.&lt;/ref&gt; introduced by Zaremba and [[David Hilbert]] around 1900. The method relies on methods of [[functional analysis]] and [[topology]]. As well as being used to prove the existence of a solution, direct methods may be used to compute the solution to desired accuracy.&lt;ref&gt;{{cite book |title=Calculus of Variations |author=I. M. Gelfand |author2=S. V. Fomin |year=1991 |publisher=Dover Publications |isbn=978-0-486-41448-5}}&lt;/ref&gt;

== The method ==
The calculus of variations deals with functionals &lt;math&gt;J:V \to \bar{\mathbb{R}}&lt;/math&gt;, where &lt;math&gt;V&lt;/math&gt; is some [[function space]] and &lt;math&gt;\bar{\mathbb{R}} = \mathbb{R} \cup \{\infty\}&lt;/math&gt;. The main interest of the subject is to find ''minimizers'' for such functionals, that is, functions &lt;math&gt;v \in V&lt;/math&gt; such that:&lt;math&gt;J(v) \leq J(u)\forall u \in V. &lt;/math&gt;

The standard tool for obtaining necessary conditions for a function to be a minimizer is the [[Euler&amp;ndash;Lagrange equation]]. But seeking a minimizer amongst functions satisfying these may lead to false conclusions if the existence of a minimizer is not established beforehand.

The functional &lt;math&gt;J&lt;/math&gt; must be bounded from below to have a minimizer. This means

:&lt;math&gt;\inf\{J(u)|u\in V\} &gt; -\infty.\,&lt;/math&gt;

This condition is not enough to know that a minimizer exists, but it shows the existence of a ''minimizing sequence'', that is, a sequence &lt;math&gt;(u_n)&lt;/math&gt; in &lt;math&gt;V&lt;/math&gt; such that &lt;math&gt;J(u_n) \to \inf\{J(u)|u\in V\}.&lt;/math&gt;

The direct method may broken into the following steps
# Take a minimizing sequence &lt;math&gt;(u_n)&lt;/math&gt; for &lt;math&gt;J&lt;/math&gt;.
# Show that &lt;math&gt;(u_n)&lt;/math&gt; admits some [[subsequence]] &lt;math&gt;(u_{n_k})&lt;/math&gt;, that converges to a &lt;math&gt;u_0\in V&lt;/math&gt; with respect to a topology  &lt;math&gt;\tau&lt;/math&gt; on &lt;math&gt;V&lt;/math&gt;.
# Show that &lt;math&gt;J&lt;/math&gt; is sequentially [[lower semi-continuous]] with respect to the topology &lt;math&gt;\tau&lt;/math&gt;.

To see that this shows the existence of a minimizer, consider the following characterization of sequentially lower-semicontinuous functions.
:The function &lt;math&gt;J&lt;/math&gt; is sequentially lower-semicontinuous if
::&lt;math&gt;\liminf_{n\to\infty} J(u_n) \geq J(u_0)&lt;/math&gt; for any convergent sequence &lt;math&gt;u_n \to u_0&lt;/math&gt; in &lt;math&gt;V&lt;/math&gt;.

The conclusions follows from
:&lt;math&gt;\inf\{J(u)|u\in V\} = \lim_{n\to\infty} J(u_n) = \lim_{k\to \infty} J(u_{n_k}) \geq J(u_0) \geq \inf\{J(u)|u\in V\}&lt;/math&gt;,
in other words
:&lt;math&gt;J(u_0) = \inf\{J(u)|u\in V\}&lt;/math&gt;.

== Details ==

=== Banach spaces ===
The direct method may often be applied with success when the space &lt;math&gt;V&lt;/math&gt; is a subset of a [[separable space|separable]] [[reflexive space|reflexive]] [[Banach space]] &lt;math&gt;W&lt;/math&gt;. In this case the  [[Banach&amp;ndash;Alaoglu theorem#Sequential Banach–Alaoglu theorem|sequential Banach–Alaoglu theorem]] implies that any bounded sequence &lt;math&gt;(u_n)&lt;/math&gt; in &lt;math&gt;V&lt;/math&gt; has a subsequence that converges to some &lt;math&gt;u_0&lt;/math&gt; in &lt;math&gt;W&lt;/math&gt; with respect to the [[weak topology]]. If &lt;math&gt;V&lt;/math&gt; is sequentially closed in &lt;math&gt;W&lt;/math&gt;, so that &lt;math&gt;u_0&lt;/math&gt; is in &lt;math&gt;V&lt;/math&gt;, the direct method may be applied to a functional &lt;math&gt;J:V\to\bar{\mathbb{R}}&lt;/math&gt; by showing
# &lt;math&gt;J&lt;/math&gt; is bounded from below,
# any minimizing sequence for &lt;math&gt;J&lt;/math&gt; is bounded, and
# &lt;math&gt;J&lt;/math&gt; is weakly sequentially lower semi-continuous, i.e., for any weakly convergent sequence &lt;math&gt;u_n \to u_0&lt;/math&gt; it holds that &lt;math&gt;\liminf_{n\to\infty} J(u_n) \geq J(u_0)&lt;/math&gt;.
The second part is usually accomplished by showing that &lt;math&gt;J&lt;/math&gt; admits some growth condition. An example is
:&lt;math&gt;J(x) \geq \alpha \lVert x \rVert^q - \beta&lt;/math&gt; for some &lt;math&gt;\alpha &gt; 0&lt;/math&gt;, &lt;math&gt;q \geq 1&lt;/math&gt; and &lt;math&gt;\beta \geq 0&lt;/math&gt;.
A functional with this property is sometimes called coercive. Showing sequential lower semi-continuity is usually the most difficult part when applying the direct method. See below for some theorems for a general class of functionals.

=== Sobolev spaces ===
The typical functional in the calculus of variations is an integral of the form
:&lt;math&gt;J(u) = \int_\Omega F(x, u(x), \nabla u(x))dx&lt;/math&gt;
where &lt;math&gt;\Omega&lt;/math&gt; is a subset of &lt;math&gt;\mathbb{R}^n&lt;/math&gt; and &lt;math&gt;F&lt;/math&gt; is a real-valued function on &lt;math&gt;\Omega \times \mathbb{R}^m \times \mathbb{R}^{mn}&lt;/math&gt;. The argument of &lt;math&gt;J&lt;/math&gt; is a differentiable function &lt;math&gt;u:\Omega \to \mathbb{R}^m&lt;/math&gt;, and its [[Jacobian matrix and determinant|Jacobian]] &lt;math&gt;\nabla u(x)&lt;/math&gt; is identified with a &lt;math&gt;mn&lt;/math&gt;-vector.

When deriving the Euler&amp;ndash;Lagrange equation, the common approach is to assume &lt;math&gt;\Omega&lt;/math&gt; has a &lt;math&gt;C^2&lt;/math&gt; boundary and let the domain of definition for &lt;math&gt;J&lt;/math&gt; be &lt;math&gt;C^2(\Omega, \mathbb{R}^m)&lt;/math&gt;. This space is a Banach space when endowed with the [[supremum norm]], but it is not reflexive. When applying the direct method, the functional is usually defined on a [[Sobolev space]] &lt;math&gt;W^{1,p}(\Omega, \mathbb{R}^m)&lt;/math&gt; with &lt;math&gt;p &gt; 1&lt;/math&gt;, which is a reflexive Banach space. The derivatives of &lt;math&gt;u&lt;/math&gt; in the formula for &lt;math&gt;J&lt;/math&gt; must then be taken as [[weak derivative]]s. The next section presents two theorems regarding weak sequential lower semi-continuity of functionals of the above type.

== Sequential lower semi-continuity of integrals ==
As many functionals in the calculus of variations are of the form
:&lt;math&gt;J(u) = \int_\Omega F(x, u(x), \nabla u(x))dx&lt;/math&gt;,
where &lt;math&gt;\Omega \subseteq \mathbb{R}^n&lt;/math&gt; is open, theorems characterizing functions &lt;math&gt;F&lt;/math&gt; for which &lt;math&gt;J&lt;/math&gt; is weakly sequentially lower-semicontinuous in &lt;math&gt;W^{1,p}(\Omega, \mathbb{R}^m)&lt;/math&gt; is of great importance.

In general we have the following&lt;ref&gt;Dacorogna, pp. 74&amp;ndash;79.&lt;/ref&gt;
:Assume that &lt;math&gt;F&lt;/math&gt; is a function such that
:# The function &lt;math&gt;(y, p) \mapsto F(x, y, p)&lt;/math&gt; is continuous for [[almost every]] &lt;math&gt;x \in \Omega&lt;/math&gt;,
:# the function &lt;math&gt;x \mapsto F(x, y, p)&lt;/math&gt; is [[measurable]] for every &lt;math&gt;(y, p) \in \mathbb{R}^m \times \mathbb{R}^{mn}&lt;/math&gt;, and
:# &lt;math&gt;F(x, y, p) \geq a(x)\cdot p + b(x)&lt;/math&gt; for a fixed &lt;math&gt;a\in L ^q(\Omega, \mathbb{R}^{mn})&lt;/math&gt; where &lt;math&gt;1/q + 1/p = 1&lt;/math&gt;, a fixed &lt;math&gt;b \in L^1(\Omega)&lt;/math&gt;, for a.e. &lt;math&gt;x \in \Omega&lt;/math&gt; and every &lt;math&gt;(y, p) \in \mathbb{R}^m \times \mathbb{R}^{mn}&lt;/math&gt; (here &lt;math&gt;a(x) \cdot p&lt;/math&gt; means the inner product of &lt;math&gt;a(x)&lt;/math&gt; and &lt;math&gt;p&lt;/math&gt; in &lt;math&gt;\mathbb{R}^{mn}&lt;/math&gt;).
:The following holds. If the function &lt;math&gt;p \mapsto F(x, y, p)&lt;/math&gt; is convex for a.e. &lt;math&gt;x \in \Omega&lt;/math&gt; and every &lt;math&gt;y\in \mathbb{R}^m&lt;/math&gt;,
:then &lt;math&gt;J&lt;/math&gt; is sequentially weakly lower semi-continuous.
When &lt;math&gt;n = 1&lt;/math&gt; or &lt;math&gt;m = 1&lt;/math&gt; the following converse-like theorem holds&lt;ref&gt;Dacorogna, pp. 66&amp;ndash;74.&lt;/ref&gt;
:Assume that &lt;math&gt;F&lt;/math&gt; is continuous and satisfies
::&lt;math&gt;| F(x, y, p) | \leq a(x, | y |, | p |)&lt;/math&gt;
:for every &lt;math&gt;(x, y, p)&lt;/math&gt;, and a fixed function &lt;math&gt;a(x, y, p)&lt;/math&gt; increasing in &lt;math&gt;y&lt;/math&gt; and &lt;math&gt;p&lt;/math&gt;, and locally integrable in &lt;math&gt;x&lt;/math&gt;. It then holds, if &lt;math&gt;J&lt;/math&gt; is sequentially weakly lower semi-continuous, then for any given &lt;math&gt;(x, y) \in \Omega \times \mathbb{R}^m&lt;/math&gt; the function &lt;math&gt;p \mapsto F(x, y, p)&lt;/math&gt; is convex.

In conclusion, when &lt;math&gt;m = 1&lt;/math&gt; or &lt;math&gt;n = 1&lt;/math&gt;, the functional &lt;math&gt;J&lt;/math&gt;, assuming reasonable growth and boundedness on &lt;math&gt;F&lt;/math&gt;, is weakly sequentially lower semi-continuous if, and only if, the function &lt;math&gt;p \mapsto F(x, y, p)&lt;/math&gt; is convex. If both &lt;math&gt;n&lt;/math&gt; and &lt;math&gt;m&lt;/math&gt; are greater than 1, it is possible to weaken the necessity of convexity to generalizations of convexity, namely [[polyconvex function|polyconvexity]] and quasiconvexity.&lt;ref&gt;Dacorogna, pp. 87&amp;ndash;185.&lt;/ref&gt;

== Notes ==
{{reflist}}

== References and further reading ==
* {{cite book | first = Bernard | last = Dacorogna | year = 1989 | title = Direct Methods in the Calculus of Variations | publisher = Springer-Verlag | isbn = 0-387-50491-5 }}
* {{cite book | first = Irene | last = Fonseca | authorlink = Irene Fonseca |author2=Giovanni Leoni | year = 2007 | title = Modern Methods in the Calculus of Variations: &lt;math&gt;L^p&lt;/math&gt; Spaces | publisher = Springer | isbn = 978-0-387-35784-3 }}
* Morrey, C. B., Jr.: ''Multiple Integrals in the Calculus of Variations''. Springer, 1966 (reprinted 2008), Berlin {{ISBN|978-3-540-69915-6}}.
* Jindřich Nečas: ''Direct Methods in the Theory of Elliptic Equations''. (Transl. from French original 1967 by A.Kufner and G.Tronel), Springer, 2012, {{ISBN|978-3-642-10455-8}}.
*{{cite news|author=T. Roubíček|title= Direct method for parabolic problems|journal=Adv. Math. Sci. Appl.|volume=10|year=2000|pages=57–65|mr=1769181}}

{{DEFAULTSORT:Direct Method In The Calculus Of Variations}}
[[Category:Calculus of variations]]</text>
      <sha1>l4rcc8quqw2l0e1fynfy743cabiktil</sha1>
    </revision>
  </page>
  <page>
    <title>Donsker's theorem</title>
    <ns>0</ns>
    <id>3828419</id>
    <revision>
      <id>842101015</id>
      <parentid>790702360</parentid>
      <timestamp>2018-05-20T06:52:02Z</timestamp>
      <contributor>
        <username>Mr.gondolier</username>
        <id>8348511</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6103">In [[probability theory]], '''Donsker's theorem''' (also known as '''Donsker's invariance principle''', or the '''functional central limit theorem'''), named after [[Monroe D. Donsker]], is a functional extension of the [[central limit theorem]]. 

Let &lt;math&gt;X_1, X_2, X_3, \ldots&lt;/math&gt; be a sequence of [[Independent and identically distributed random variables|independent and identically distributed]] (i.i.d.) [[Random variable|random variables]] with mean 0 and variance 1. Let &lt;math&gt;S_n:=\sum_{i=1}^n X_i&lt;/math&gt;. The stochastic process &lt;math&gt;S:=(S_n)_{n\in\N}&lt;/math&gt; is known as a [[random walk]]. Define the diffusively rescaled random walk (partial-sum process) by

: &lt;math&gt;W^{(n)}(t) := \frac{S_{\lfloor nt\rfloor}}{\sqrt{n}}, \qquad t\in [0,1].&lt;/math&gt;

The [[central limit theorem]] asserts that &lt;math&gt;W^{(n)}(1)&lt;/math&gt; [[converges in distribution]] to a standard [[Gaussian random variable]] &lt;math&gt;W(1)&lt;/math&gt; as &lt;math&gt;n\to\infty&lt;/math&gt;. Donsker's invariance principle&lt;ref&gt;{{Cite journal|url = |title = An invariance principle for certain probability limit theorems|last = Donsker|first = M.D.|date = 1951|journal = Memoirs of the American Mathematical Society, 1951, no. 6|doi = |pmid = |access-date = |author-link = Monroe D. Donsker}}&lt;/ref&gt;&lt;ref name=":0" /&gt; extends this convergence to the whole function &lt;math&gt;W^{(n)}:=(W^{(n)}(t))_{t\in [0,1]}&lt;/math&gt;. More precisely, in its modern form, Donsker's invariance principle states that: As [[Random variable|random variables]] taking values in the [[Skorokhod space]] &lt;math&gt;\mathcal{D}[0,1]&lt;/math&gt;, the random function &lt;math&gt;W^{(n)}&lt;/math&gt; converges in distribution to a [[Wiener process|standard Brownian motion]] &lt;math&gt;W:=(W(t))_{t\in [0,1]}&lt;/math&gt; as &lt;math&gt;n\to \infty.&lt;/math&gt;

==History==
Let ''F''&lt;sub&gt;''n''&lt;/sub&gt; be the  [[empirical distribution function]] of the sequence of i.i.d. random variables  &lt;math&gt;X_1, X_2, X_3, \ldots&lt;/math&gt; with distribution function ''F.'' Define the centered and scaled version of ''F''&lt;sub&gt;''n''&lt;/sub&gt; by

: &lt;math&gt; G_n(x)= \sqrt n ( F_n(x) - F(x) ) &lt;/math&gt;

indexed by ''x''&amp;nbsp;∈&amp;nbsp;'''R'''. By the classical [[central limit theorem]], for fixed ''x'', the random variable ''G''&lt;sub&gt;''n''&lt;/sub&gt;(''x'') [[converges in distribution]] to a [[normal distribution|Gaussian (normal)]] [[random variable]] ''G''(''x'') with zero mean and variance ''F''(''x'')(1&amp;nbsp;−&amp;nbsp;''F''(''x'')) as the sample size ''n'' grows.

'''Theorem''' (Donsker, Skorokhod, Kolmogorov) The sequence of ''G''&lt;sub&gt;''n''&lt;/sub&gt;(''x''), as random elements of the [[Skorokhod space]] &lt;math&gt;\mathcal{D}(-\infty,\infty)&lt;/math&gt;, [[convergence in distribution|converges in distribution]] to a [[Gaussian process]] ''G'' with zero mean and covariance given by

: &lt;math&gt;\operatorname{cov}[G(s), G(t)] = E[G(s) G(t)] = \min\{F(s), F(t)\} - F(s)F(t). &lt;/math&gt;

The process ''G''(''x'') can be written as ''B''(''F''(''x'')) where ''B'' is a standard [[Brownian bridge]] on the unit interval.

Kolmogorov (1933) showed that when ''F'' is [[continuous function|continuous]], the supremum &lt;math&gt;\scriptstyle\sup_t G_n(t)&lt;/math&gt; and supremum of absolute value, &lt;math&gt;\scriptstyle\sup_t |G_n(t)|&lt;/math&gt; [[convergence in distribution|converges in distribution]] to the laws of the same functionals of the [[Brownian bridge]] ''B''(''t''), see the [[Kolmogorov–Smirnov test]]. In 1949 Doob asked whether the convergence in distribution held for more general functionals, thus formulating a problem of [[weak convergence of measures|weak convergence]] of random functions in a suitable [[function space]].&lt;ref&gt;{{cite journal
 |first=Joseph L. |last=Doob|authorlink=Joseph L. Doob
 |title=Heuristic approach to the Kolmogorov–Smirnov theorems
 |journal=[[Annals of Mathematical Statistics]]
 |volume=20 |issue= |pages=393–403 |year=1949
 |doi=10.1214/aoms/1177729991 |mr=30732 | zbl = 0035.08901
}}&lt;/ref&gt;

In 1952 Donsker stated and proved (not quite correctly)&lt;ref name="dudley1999"&gt;{{cite book
 |first=R.M. |last=Dudley|authorlink=Richard M. Dudley
 |title=Uniform Central Limit Theorems
 |publisher=Cambridge University Press
 |year=1999
 |isbn=0-521-46102-2
}}&lt;/ref&gt; a general extension for the Doob-Kolmogorov heuristic approach. In the original paper, Donsker proved that the  convergence in law of ''G&lt;sub&gt;n&lt;/sub&gt;'' to the Brownian bridge holds for [[uniform distribution (continuous)|Uniform[0,1]]] distributions with respect to uniform convergence in ''t'' over the interval [0,1].&lt;ref name=":0"&gt;{{cite journal
 |first=M. D. |last=Donsker |authorlink=Monroe D. Donsker
 |title=Justification and extension of Doob's heuristic approach to the Kolmogorov–Smirnov theorems
 |journal=[[Annals of Mathematical Statistics]]
 |volume=23 |issue= |pages=277–281 |year=1952
 |doi=10.1214/aoms/1177729445 |mr=47288 | zbl = 0046.35103
}}&lt;/ref&gt;

However Donsker's formulation was not quite correct because of the problem of measurability of the functionals of discontinuous processes. In 1956 Skorokhod and Kolmogorov defined a separable metric ''d'', called the ''Skorokhod metric'', on the space of [[cadlag function]]s on [0,1], such that convergence for ''d'' to a continuous function is equivalent to convergence for the sup norm, and showed that ''G&lt;sub&gt;n&lt;/sub&gt;'' converges in law in &lt;math&gt;\mathcal{D}[0,1]&lt;/math&gt; to the Brownian bridge.

Later Dudley reformulated Donsker's result to avoid the problem of measurability and the need of the Skorokhod metric. One can prove&lt;ref name="dudley1999" /&gt; that there exist ''X&lt;sub&gt;i&lt;/sub&gt;'', iid uniform in [0,1] and a sequence of sample-continuous Brownian bridges ''B''&lt;sub&gt;''n''&lt;/sub&gt;, such that
:&lt;math&gt;\|G_n-B_n\|_\infty&lt;/math&gt;
is measurable and [[convergence in probability|converges in probability]] to 0. An improved version of this result, providing more detail on the rate of convergence, is the [[Komlós–Major–Tusnády approximation]].

==See also==
*[[Glivenko–Cantelli theorem]]
*[[Kolmogorov–Smirnov test]]

== References ==
{{reflist}}

{{DEFAULTSORT:Donsker's Theorem}}
[[Category:Probability theorems]]
[[Category:Statistical theorems]]
[[Category:Empirical process]]</text>
      <sha1>6skqc3kdo8znnmfltdnru66mtz1fvpg</sha1>
    </revision>
  </page>
  <page>
    <title>ESAIM: Control, Optimisation and Calculus of Variations</title>
    <ns>0</ns>
    <id>9123977</id>
    <revision>
      <id>664915255</id>
      <parentid>573560656</parentid>
      <timestamp>2015-05-31T20:41:02Z</timestamp>
      <contributor>
        <username>Magioladitis</username>
        <id>1862829</id>
      </contributor>
      <minor/>
      <comment>/* External links */clean up using [[Project:AWB|AWB]] (11023)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="331">{{Italic title}}
'''''ESAIM: Control, Optimisation and Calculus of Variations''''' is a [[scientific journal]] in the field of [[applied mathematics]].

==External links==
* {{Official website|http://www.esaim-cocv.org/}}

[[Category:Mathematics journals]]
[[Category:EDP Sciences academic journals]]


{{mathematics-journal-stub}}</text>
      <sha1>bw80eo2l2lmu8u0g01xrziitbm3emax</sha1>
    </revision>
  </page>
  <page>
    <title>Effective topos</title>
    <ns>0</ns>
    <id>30939514</id>
    <revision>
      <id>701612539</id>
      <parentid>693100268</parentid>
      <timestamp>2016-01-25T15:43:15Z</timestamp>
      <contributor>
        <ip>137.194.160.26</ip>
      </contributor>
      <comment>link to a simple presentation of the effective topos (that could be used to fill in this stub)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1444">In mathematics, the '''effective topos''' is a [[topos]] introduced by {{harvs|txt|first=Martin|last=Hyland|authorlink=Martin Hyland|year=1982}}, based on [[Stephen Kleene|Kleene's]] notion of recursive realizability, that captures the idea of [[computability|effectivity]] in mathematics.

==References==

*{{Citation | last1=Hyland | first1=J. M. E. | editor1-last=Troelstra | editor1-first=A. S. | editor2-last=Dalen | editor2-first=D. van | title=The L.E.J. Brouwer Centenary Symposium (Noordwijkerhout, 1981) | publisher=North-Holland | location=Amsterdam | series=Studies in Logic and the Foundations of Mathematics | isbn=978-0-444-86494-9 | doi=10.1016/S0049-237X(09)70129-6  | mr=717245 | year=1982 | volume=110 | chapter=The effective topos | pages=165–216}}
* {{cite journal | last = Kleene | first = S. C. | year = 1945 | title = On the interpretation of intuitionistic number theory | jstor = 2269016 | journal = Journal of Symbolic Logic | volume = 10 | issue = 4 | pages = 109–124 | doi = 10.2307/2269016}}
*{{citation|url=http://www.lfcs.inf.ed.ac.uk/reports/92/ECS-LFCS-92-208/|first=Wesley|last=Phoa|title=An introduction to fibrations, topos theory, the effective topos and modest sets|year=1992}}
* {{Cite arXiv | last=Bernadet | first=Alexis | last2=Graham-Lengrand | first2=Stéphane | eprint=1307.3832 | title=A simple presentation of the effective topos | year=2013 }}

[[Category:Topos theory]]


{{cattheory-stub}}</text>
      <sha1>rjm5bb4sp4flg8bkxibz5xglt8pg5jc</sha1>
    </revision>
  </page>
  <page>
    <title>Eigengap</title>
    <ns>0</ns>
    <id>23039174</id>
    <revision>
      <id>607535127</id>
      <parentid>594040940</parentid>
      <timestamp>2014-05-07T20:51:42Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>Task 3: Fix [[Help:CS1_errors#deprecated_params|CS1 deprecated coauthor parameter errors]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="919">In [[linear algebra]], the '''eigengap''' of a [[linear operator]] is the difference between two successive [[eigenvalues]], where eigenvalues are sorted in ascending order.

The Davis&amp;ndash;Kahan theorem, named after [[Chandler Davis]] and [[William Kahan]], uses the eigengap to show how eigenspaces of an operator change under [[Perturbation theory|perturbation]].&lt;ref&gt;{{cite journal |last=Davis |first=C. |author2=W. M. Kahan|date=March 1970 |title=The rotation of eigenvectors by a perturbation. III. |journal=SIAM J. Numerical Analysis |volume=7 |issue=1 |pages=1&amp;ndash;46 |id= |url=  |quote= |doi=10.1137/0707001 }}&lt;/ref&gt; In [[spectral clustering]], the eigengap is often referred to as the ''[[spectral gap]]''; although the spectral gap may often be defined in a broader sense than that of the eigengap.

== See also ==
* [[Eigenvalue perturbation]]

== References ==
{{reflist|1}}

[[Category:Linear algebra]]</text>
      <sha1>jlg6gzqlim4e186aktu8u6l4nz4eo97</sha1>
    </revision>
  </page>
  <page>
    <title>Emma Castelnuovo</title>
    <ns>0</ns>
    <id>46508864</id>
    <revision>
      <id>856144469</id>
      <parentid>835209083</parentid>
      <timestamp>2018-08-23T05:26:35Z</timestamp>
      <contributor>
        <ip>217.112.98.185</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3609">{{Infobox scientist
| birth_name=Emma Castelnuovo
| birth_date            = {{birth date|1913|12|12|df=y}}
| birth_place           =[[Rome]], [[Italy]]
| death_date            = {{death date and age|2014|4|13|1913|12|12|df=y}}
| death_place           = [[Rome]], [[Italy]]
| nationality       = [[Italy]]
| fields            = [[Mathematics]]
}}

'''Emma Castelnuovo''' (12 December 1913 &amp;ndash; 13 April 2014) was an Italian secondary school teacher, daughter of the mathematician [[Guido Castelnuovo]] whose life was intermingled with events that changed the approach to the problems of mathematics in the second half of the twentieth century.&lt;ref&gt;{{cite news|last1=Orlando|first1=Lucia|title=Emma Castelnuovo, la matematica per antonomasia|url=https://www.democratica.com/europaquotidiano/emma-castelnuovo-la-matematica-per-antonomasia/|accessdate=23 August 2018|agency=europaquotidiano|date=14 April 2014|language=Italian}}&lt;/ref&gt;
[[International Commission on Mathematical Instruction]] (ICMI) in the past created two awards, the [[Felix Klein]] Award- honouring a lifetime achievement, and the [[Hans Freudenthal]] Award- recognizing a major cumulative program of research. In 2013, to celebrate her 100th birthday ICMI decided to add a third award named after Emma Castelnuovo- to recognize outstanding achievements made in the practice of mathematical education.&lt;ref&gt;{{cite web|title=Emma Castelnuovo Award|url=https://www.mathunion.org/icmi/awards/icmi-emma-castelnuovo-award-excellence-practice-mathematics-education/|publisher=[[International Commission on Mathematical Instruction]]}} &lt;/ref&gt;

==Biography==
Emma Castelnuovo was born in Rome on 12 December 1913 to Elbina and [[Guido Castelnuovo]]; her father and her uncle [[Federigo Enriques]] were both professors of mathematics.&lt;ref&gt;{{MacTutor|id=Castelnuovo_Emma}}&lt;/ref&gt; In 1908 Guido was the chairman of the fourth International Congress of Mathematicians in Rome.

Castelnuovo graduated from the University of Rome in 1936 with a thesis on [[algebraic geometry]]. After this she worked as a librarian at the same university. She won a permanent position in 1938, but on account of the racial laws against Jews, she was suspended from work. At the beginning of her career, Castelnuovo was looking into the possibility of teaching which would include involving her students.

The textbook 'Geometria intuitiva, per le scuole medie inferiori' (Intuitive geometry for lower secondary schools), first published in 1948, had various editions till 1964 and was translated into Spanish and English. It launched Castelnuovo to international level so that she was invited to join working groups and meetings.

Castelnuovo was one of the two representatives from Italy taking an active part in discussing Modern Mathematics. Castelnuovo was recognized as an international member when she was appointed as member of the [[International Commission on Mathematical Instruction|ICMI]] during the period 1975-1978.

Castelnuovo was a well-respected and a brilliant mathematician. In her many years of teaching, she not only influenced her students but also the young colleagues present at her university. She was emotionally involved in her lectures and transmitted her enthusiasm and motivation to her peers.

==References==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Castelnuovo, Emma}}
[[Category:1913 births]]
[[Category:2014 deaths]]
[[Category:Italian centenarians]]
[[Category:Italian Jews]]
[[Category:Italian mathematicians]]
[[Category:Women mathematicians]]
[[Category:20th-century women scientists]]
[[Category:20th-century Italian women]]</text>
      <sha1>5sz65oamjjb81qnmlq4sqblzq6l1r65</sha1>
    </revision>
  </page>
  <page>
    <title>Excess-6</title>
    <ns>0</ns>
    <id>57911772</id>
    <redirect title="Offset binary" />
    <revision>
      <id>850448837</id>
      <timestamp>2018-07-15T23:07:03Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>[[WP:AES|←]]Redirected page to [[Offset binary#Excess-6]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="145">#redirect [[Offset binary#Excess-6]] {{R to related topic}} {{R with possibilities}}

[[Category:Binary arithmetic]]
[[Category:Numeral systems]]</text>
      <sha1>cp9zwf03unrunaggb7hw88il22y40l8</sha1>
    </revision>
  </page>
  <page>
    <title>Fundamental theorem of finitely generated abelian groups</title>
    <ns>0</ns>
    <id>1182520</id>
    <redirect title="Finitely generated abelian group" />
    <revision>
      <id>784485929</id>
      <parentid>673114282</parentid>
      <timestamp>2017-06-08T15:59:59Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Redirect category shell|Redirect category shell]]}}, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="145">#REDIRECT [[Finitely generated abelian group#Classification]]

{{Redirect category shell|1=
{{R to section}}
}}

[[Category:Theorems in algebra]]</text>
      <sha1>25z3fenqrwe3mmog69ciknmjaywtdsz</sha1>
    </revision>
  </page>
  <page>
    <title>General insurance</title>
    <ns>0</ns>
    <id>1555443</id>
    <revision>
      <id>870255012</id>
      <parentid>839423066</parentid>
      <timestamp>2018-11-23T14:49:43Z</timestamp>
      <contributor>
        <ip>96.228.33.106</ip>
      </contributor>
      <comment>/* Market trends */Removed an irrelevant fact.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3613">{{Globalise/UK|date=September 2016|talk=Talk:General insurance#UK_focus}}
{{refimprove|date=August 2017}}
[[Image:2005nonlife_premia.PNG|thumb|right|Non-life insurance premia written in 2005]]
'''General insurance''' or non-life insurance policies, including automobile and homeowners policies, provide payments depending on the loss from a particular financial event. General insurance is typically defined as any insurance that is not determined to be [[life insurance]]. It is called '''[[Property insurance|property]] and [[Casualty insurance|casualty]] insurance''' in the [[United States]] and Canada and '''non-life insurance''' in Continental Europe.

In the [[United Kingdom]], insurance is broadly divided into three areas: personal lines, commercial lines and London market.

The [[London market]] insures large commercial risks such as supermarkets, football players and other very specific risks.  It consists of a number of insurers, reinsurers, [[Protection and indemnity insurance|P&amp;I Clubs]], brokers and other companies that are typically physically located in the [[City of London]].  [[Lloyd's of London]] is a big participant in this market.&lt;ref&gt;http://www.iii.org/commerciallines/global/lloyds/&lt;/ref&gt;  The London market also participates in personal lines and commercial lines, domestic and foreign, through [[reinsurance]].

[[Commercial lines]] products are usually designed for relatively small legal entities. These would include workers' compensation (employers liability), public liability, [[product liability]], commercial fleet and other general insurance products sold in a relatively standard fashion to many organisations. There are many companies that supply comprehensive commercial insurance packages for a wide range of different industries, including shops, restaurants and hotels.

[[Personal lines]] products are designed to be sold in large quantities. This would include [[auto insurance|autos]] (private car), [[home insurance|homeowners]] (household), pet insurance, creditor insurance and others.

[[ACORD]], which is the insurance industry global standards organization, has standards for personal and commercial lines and has been working with the Australian General Insurers to develop those XML standards, standard applications for insurance, and certificates of currency.

==Types of general insurance==
General insurance can be categorised in to following:
* Motor Insurance: Motor Insurance can be divided into two groups, two and four wheeled vehicle insurance.
* Health Insurance: Common types of health insurance includes: individual health insurance, family floater health insurance, comprehensive health insurance and critical illness insurance.
* Travel Insurance: Travel insurance can be broadly grouped into: individual travel policy, family travel policy, student travel insurance, and senior citizen health insurance.
* Home Insurance: Home insurance protects a house and its contents.
* Marine Insurance: Marine cargo insurance covers goods, freight, cargo, and other interests against loss or damage during transit by rail, road, sea and/or air.
* Commercial Insurance: Commercial insurance encompasses solutions for all sectors of the industry arising out of business operations.

==Market trends==
The United States was the largest market for non-life insurance premiums written in 2005 followed by the [[European Union]] and Japan.

==See also==
*[[Insurance]]
*[[Outstanding claims reserves]]

==References==
{{Reflist}}

{{New Zealand Insurance Companies}}

{{Authority control}}

[[Category:Types of insurance]]
[[Category:Actuarial science]]</text>
      <sha1>3vhzua1woa4qlvrdte9kiy183i5x7eu</sha1>
    </revision>
  </page>
  <page>
    <title>George Andrews (mathematician)</title>
    <ns>0</ns>
    <id>3356273</id>
    <revision>
      <id>840210615</id>
      <parentid>830632807</parentid>
      <timestamp>2018-05-08T12:31:23Z</timestamp>
      <contributor>
        <username>Mitch Ames</username>
        <id>6326132</id>
      </contributor>
      <comment>Remove supercategory of existing diffusing category per [[WP:SUBCAT]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8001">{{Infobox scientist
|image = George Andrews Washington 2009.jpg
|name = George Eyre Andrews
|fields = [[Mathematical analysis|Analysis]] and [[Combinatorics]]
|workplaces = [[Pennsylvania State University]]
|alma_mater = [[University of Pennsylvania]]
|doctoral_advisor = [[Hans Rademacher]]
|known_for = [[Ramanujan's lost notebook]]
}}

'''George Eyre Andrews''' (born December 4, 1938 in [[Salem, Oregon]])&lt;ref name="rlc"/&gt; is an American [[mathematician]] working in [[mathematical analysis|analysis]] and [[combinatorics]].

==Education and career==
He is currently an Evan Pugh Professor of Mathematics at [[Pennsylvania State University]].&lt;ref name="nas"/&gt;&lt;ref&gt;[http://www.research.psu.edu/about/faculty-staff-resources/faculty-honors-1/evan-pugh-professors Evan Pugh Professors] {{webarchive|url=https://web.archive.org/web/20131203003230/http://www.research.psu.edu/about/faculty-staff-resources/faculty-honors-1/evan-pugh-professors |date=2013-12-03 }}, PSU, retrieved 2013-11-21.&lt;/ref&gt; He did his undergraduate studies at [[Oregon State University]]&lt;ref name="nas"/&gt; and received his PhD in 1964 at the [[University of Pennsylvania]] where his advisor was [[Hans Rademacher]].&lt;ref name="rlc"/&gt;&lt;ref&gt;{{MathGenealogy |id=7528}}&lt;/ref&gt;

During 2008-2009 he was president&lt;ref&gt;[http://www.ams.org/about-us/presidents/60-andrews AMS presidents, a timeline]&lt;/ref&gt; of the [[American Mathematical Society]].

==Contributions==
Andrews's contributions include several monographs and over 250 research and popular articles on [[q-series]], [[special functions]], [[combinatorics]] and applications.&lt;ref name="mactutor"/&gt;&lt;ref&gt;[http://www.emis.de/journals/SLC/wpapers/s42askey.pdf The work of George Andrews: a Madison perspective] – by [[Richard Askey]], in "The Andrews Festschrift (Maratea, 1998)", Sem. Lothar. Combin. vol. 42 (1999), Art. B42b, 24 pp.
&lt;/ref&gt; He is considered to be the world's leading expert in the theory of [[integer partition]]s.&lt;ref name="rlc"&gt;{{citation|title=Ramanujan: Letters and Commentary|volume=9|series=History of Mathematics|editor1-first=Bruce C.|editor1-last=Berndt|editor2-first=Robert Alexander|editor2-last=Rankin|publisher=American Mathematical Society|year=1995|isbn=9780821891254|page=305|url=https://books.google.com/books?id=Of5G0r6DQiEC&amp;pg=PA305|quote=Andrews is generally recognized as the world's leading authority on partitions and is the author of the foremost treatise on the subject.}}&lt;/ref&gt;&lt;ref&gt;{{citation|title=Ramanujan's Place in the World of Mathematics: Essays Providing a Comparative Study|first=Krishnaswami|last=Alladi|authorlink= Krishnaswami Alladi |publisher=Springer|year=2012|isbn=9788132207672|page=122|url=https://books.google.com/books?id=XLNJDylP53QC&amp;pg=PA122|quote=George Andrews of the Pennsylvania State University, the world authority on partitions and ''q''-geometric series}}.&lt;/ref&gt; In 1976 he discovered [[Ramanujan]]'s [[Ramanujan's lost notebook|Lost Notebook]].&lt;ref name="nas"/&gt; He is highly interested in mathematical pedagogy.&lt;ref name="nas"/&gt;

His book ''The Theory of Partitions'' is the standard reference on the subject of [[integer partition]]s.&lt;ref name="rlc"/&gt;

==Awards and honors==
Andrews is a member of the [[United States National Academy of Sciences|National Academy of Sciences]].&lt;ref name="nas"&gt;[http://www.pnas.org/cgi/content/full/102/13/4663 Inaugural Biography Article at the National Academy of Sciences].&lt;/ref&gt; He was elected a Fellow of the [[American Academy of Arts and Sciences]] in 1997.&lt;ref name=AAAS&gt;{{cite web|title=Book of Members, 1780-2010: Chapter A|url=http://www.amacad.org/publications/BookofMembers/ChapterA.pdf|publisher=American Academy of Arts and Sciences|accessdate=18 April 2011}}&lt;/ref&gt; In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2012-11-03.&lt;/ref&gt;

He was given honorary doctorates from the [[University of Parma]] in 1998, the [[University of Florida]] in 2002, the [[University of Waterloo]] in 2004, [[SASTRA University]] in [[Kumbakonam]], India in 2012, and [[University of Illinois at Urbana–Champaign]] in 2014&lt;ref name="mactutor"&gt;{{MacTutor Biography|id=Andrews}}&lt;/ref&gt;&lt;ref&gt;[http://lists.siam.org/pipermail/siam-opsf/2013-January/000077.html Honorary doctorates for Andrews, Askey and Berndt]&lt;/ref&gt;&lt;ref&gt;[http://news.illinois.edu/news/14/0505commencement_2014.html]&lt;/ref&gt;

==Publications==
* ''Selected Works of George E Andrews (With Commentary)'' (World Scientific Publishing, 2012, {{ISBN|978-1-84816-666-0}})
* [https://books.google.com/books/about/Number_Theory.html?id=eVwvvwZeBf4C ''Number Theory''] (Dover, 1994, {{ISBN|0-486-68252-8}})
* ''The Theory of Partitions'' (Cambridge University Press, 1998, {{ISBN|0-521-63766-X}})&lt;ref&gt;{{cite journal|author=Askey, Richard|title=Review: George E. Andrew, ''The theory of partitions''|journal=Bull. Amer. Math. Soc. (N.S.)|year=1979|volume=1|issue=1|pages=203–210|url=http://projecteuclid.org/euclid.bams/1183542336|doi=10.1090/s0273-0979-1979-14556-7}}&lt;/ref&gt;
* ''Integer Partitions'' (with Eriksson, Kimmo) (Cambridge University Press, 2004, {{ISBN|0-521-84118-6}})
* ''Ramanujan's Lost Notebook: Part I'' (with [[Bruce C. Berndt]]) (Springer, 2005, {{ISBN|0-387-25529-X}})&lt;ref&gt;{{cite journal|author=Bressoud, David|authorlink=David Bressoud|title=Review: ''Ramanujan's Lost Notebook, Part I'', by George Andrews and Bruce C. Berndt|journal=Bull. Amer. Math. Soc. (N.S.)|year=2006|volume=43|issue=4|pages=585–591|url=http://www.ams.org/journals/bull/2006-43-04/S0273-0979-06-01110-4/S0273-0979-06-01110-4.pdf|doi=10.1090/s0273-0979-06-01110-4}}&lt;/ref&gt;
* ''Ramanujan's Lost Notebook: Part II'', (with Bruce C. Berndt) (Springer, 2008, {{ISBN|978-0-387-77765-8}})
* ''Ramanujan's Lost Notebook: Part III'', (with Bruce C. Berndt) (Springer, 2012, {{ISBN|978-1-4614-3809-0}})
* ''Ramanujan's Lost Notebook: Part IV'', (with Bruce C. Berndt) (Springer, 2013, {{ISBN|978-1-4614-4080-2}})
* "Special functions" by George Andrews, [[Richard Askey]], and Ranjan Roy, ''Encyclopedia of Mathematics and Its Applications'', The University Press, Cambridge, 1999.&lt;ref&gt;{{cite journal|author=Wimp, Jet|title=Review: ''Special functions'', by George Andrews, Richard Askey, and Ranjan Roy|journal=Bull. Amer. Math. Soc. (N.S.)|year=2000|volume=37|issue=4|pages=499–510|url=http://www.ams.org/journals/bull/2000-37-04/S0273-0979-00-00879-X/S0273-0979-00-00879-X.pdf | doi = 10.1090/S0273-0979-00-00879-X }}&lt;/ref&gt;

==References==
{{reflist|30em}}

==External links==
* [http://www.math.psu.edu/andrews/ George Andrews's homepage]
* [https://zbmath.org/authors/?q=ai:andrews.george-eyre Author profile] in the database [[Zentralblatt MATH|zbMATH]]
* [https://www.youtube.com/watch?v=y_0NuOBNobk "The Meaning of Ramanujan and His Lost Notebook" by George E. Andrews, Center for Advanced Study, U. of Illinois at Urbana-Champaign, YouTube, 2014]
* [https://www.youtube.com/watch?v=thxHlOZlib4 "Partitions, Dyson, and Ramanujan" - George Andrews, videosfromIAS, YouTube, 2016]

{{AMS Presidents}}

{{Authority control}}

{{DEFAULTSORT:Andrews, George}}
[[Category:1938 births]]
[[Category:Living people]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Mathematical analysts]]
[[Category:Number theorists]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Oregon State University alumni]]
[[Category:University of Pennsylvania alumni]]
[[Category:Pennsylvania State University faculty]]
[[Category:People from Salem, Oregon]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Fellows of the Society for Industrial and Applied Mathematics]]
[[Category:Additive combinatorialists]]
[[Category:Presidents of the American Mathematical Society]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:Guggenheim Fellows]]
[[Category:Mathematicians from Oregon]]</text>
      <sha1>g390k9eusxkretjcdrpl2bkrxb1mu81</sha1>
    </revision>
  </page>
  <page>
    <title>Gingerbreadman map</title>
    <ns>0</ns>
    <id>5732549</id>
    <revision>
      <id>696268403</id>
      <parentid>562037121</parentid>
      <timestamp>2015-12-22T00:56:07Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>source</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1286">[[Image:GBM.png|thumb|right|Gingerbreadman map for subset &lt;math&gt;Q^2, [-10..10,-10..10]&lt;/math&gt;:
the color of each point is related to the relative orbit period.
To view the gingerbread man, you must rotate the image 135 degrees clockwise.]]
In [[dynamical systems theory]], the '''Gingerbreadman map''' is a [[chaos theory|chaotic]] two-dimensional map. It is given by the [[Piecewise linear function|piecewise linear]] transformation:&lt;ref&gt;{{citation
 | last = Devaney | first = Robert L. | authorlink = Robert L. Devaney
 | editor1-last = Peitgen | editor1-first = Heinz-Otto | editor1-link = Heinz-Otto Peitgen
 | editor2-last = Saupe | editor2-first = Dietmar | editor2-link = Dietmar Saupe
 | contribution = Fractal patterns arising in chaotic dynamical systems
 | doi = 10.1007/978-1-4612-3784-6_3
 | pages = 137–168
 | publisher = Springer-Verlag
 | title = The Science of Fractal Images
 | year = 1988}}. See in particular Fig. 3.3.&lt;/ref&gt;

:&lt;math&gt;
\begin{cases}
x_{n+1} = 1 - y_n + |x_n|\\
y_{n+1} = x_n
\end{cases}
&lt;/math&gt;

==See also== 
* [[List of chaotic maps]]

==References==
{{reflist}}

==External links==
*{{mathworld|id=GingerbreadmanMap|title=Gingerbreadman Map}}

{{Chaos theory}}

[[Category:Chaotic maps]]
[[Category:Exactly solvable models]]

{{Mathapplied-stub}}</text>
      <sha1>1j7vdnjm6smdab2pezimv5p220hj07u</sha1>
    </revision>
  </page>
  <page>
    <title>Grothendieck local duality</title>
    <ns>0</ns>
    <id>38470542</id>
    <revision>
      <id>862709255</id>
      <parentid>852442700</parentid>
      <timestamp>2018-10-06T05:19:38Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1436">In [[commutative algebra]], '''Grothendieck local duality''' is a [[duality theorem]] for [[cohomology]] of [[module (mathematics)|modules]] over [[local ring]]s, analogous to [[Serre duality]] of [[coherent sheaf|coherent sheaves]].

==Statement==

Suppose that ''R'' is a [[Cohen–Macaulay ring|Cohen–Macaulay]] local ring of dimension ''d'' with maximal ideal ''m'' and residue field ''k''&amp;nbsp;=&amp;nbsp;''R''/''m''. Let ''E''(''k'') be a [[Matlis module]], an [[injective hull]] of ''k'', and let {{overline|Ω}} be the completion of its [[dualizing module]]. Then for any ''R''-module ''M'' there is an isomorphism of modules over the completion of ''R'':

: &lt;math&gt;\operatorname{Ext}_R^i(M,\overline\Omega) \cong \operatorname{Hom}_R(H_m^{d-i}(M),E(k))&lt;/math&gt;

where ''H''&lt;sub&gt;''m''&lt;/sub&gt; is a [[local cohomology]] group.

There is a generalization to Noetherian local rings that are not Cohen–Macaulay, that replaces the dualizing module with a [[dualizing complex]].

==See also==

*[[Matlis duality]]

==References==

*{{Citation | last1=Bruns | first1=Winfried | last2=Herzog | first2=Jürgen | title=Cohen–Macaulay rings | url=https://books.google.com/books?id=LF6CbQk9uScC | publisher=[[Cambridge University Press]] | series=Cambridge Studies in Advanced Mathematics | isbn=978-0-521-41068-7 |mr=1251956 | year=1993 | volume=39}}

[[Category:Commutative algebra]]
[[Category:Duality theories]]

{{abstract-algebra-stub}}</text>
      <sha1>hugl5hewzxqsi21v82t4f444v3vt3ke</sha1>
    </revision>
  </page>
  <page>
    <title>Information algebra</title>
    <ns>0</ns>
    <id>5259526</id>
    <revision>
      <id>800469685</id>
      <parentid>800469672</parentid>
      <timestamp>2017-09-13T19:03:06Z</timestamp>
      <contributor>
        <username>My name is not dave</username>
        <id>19079409</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/12.156.43.232|12.156.43.232]] ([[User talk:12.156.43.232|talk]]) to last version by RJGray</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19145">The term "'''information algebra'''" refers to mathematical techniques of [[information processing]]. Classical [[information theory]] goes back to [[Claude Shannon]]. It is a theory of information transmission, looking at communication and storage. However, it has not been considered so far that information comes from different sources and that it is therefore usually combined. It has furthermore been neglected in classical information theory that one wants to extract those parts out of a piece of information that are relevant to specific questions.

A mathematical phrasing of these operations leads to an '''algebra of information''', describing basic modes of information processing. Such an algebra involves several formalisms of [[computer science]], which seem to be different on the surface: relational databases, multiple systems of formal logic or numerical problems of linear algebra. It allows the development of generic procedures of information processing and thus a unification of basic methods of computer science, in particular of [[distributed information processing]].

Information relates to precise questions, comes from different sources, must be aggregated, and can be focused on questions of interest. Starting from these considerations, information algebras {{Harv|Kohlas|2003}} are [[Structure (mathematical logic)#Many-sorted structures|two-sorted]] algebras &lt;math&gt;(\Phi,D)\,&lt;/math&gt;, where &lt;math&gt;\Phi\,&lt;/math&gt; is a [[semigroup]], representing combination or aggregation of information, &lt;math&gt;D\,&lt;/math&gt; is a [[lattice (order)|lattice]] of [[Domain (mathematics)|domain]]s (related to questions) whose [[partial order]] reflects the granularity of the domain or the question, and a [[mixed operation]] representing focusing or extraction of information.

== Information and its operations ==
More precisely, in the two-sorted algebra &lt;math&gt;(\Phi,D)\,&lt;/math&gt;, the following operations are defined

{| border=1 style="border:0px"
| style="border:1px solid #448800; padding:0.4em; background-color:#EEFFEE" |
; Combination : &lt;math&gt;\otimes: \Phi \otimes \Phi \rightarrow \Phi,~ (\phi,\psi) \mapsto \phi \otimes \psi\,&lt;/math&gt;
; Focusing :   &lt;math&gt;\Rightarrow: \Phi \otimes D \rightarrow \Phi,~ (\phi,x) \mapsto \phi^{\Rightarrow x}\,&lt;/math&gt;
| style="border:1px" | &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
|}

Additionally, in &lt;math&gt;D\,&lt;/math&gt; the usual lattice operations (meet and join) are defined.

== Axioms and definition ==
The axioms of the two-sorted algebra &lt;math&gt;(\Phi,D)\,&lt;/math&gt;, in addition to the axioms of the lattice &lt;math&gt;D\,&lt;/math&gt;:

{| border=1 style="border:0px"
| style="border:1px solid #448800; padding:0.4em; background-color:#EEFFEE" |
; Semigroup : &lt;math&gt;\Phi\,&lt;/math&gt; is a commutative semigroup under combination with a neutral element (representing vacuous information).
; Distributivity of Focusing over Combination : &lt;math&gt;(\phi^{\Rightarrow x} \otimes \psi)^{\Rightarrow x} = \phi^{\Rightarrow x} \otimes \psi^{\Rightarrow x}\,&lt;/math&gt;
To focus an information on &lt;math&gt;x\,&lt;/math&gt; combined with another information to domain &lt;math&gt;x\,&lt;/math&gt;, one may as well first focus the second information to &lt;math&gt;x\,&lt;/math&gt; and combine then.
; Transitivity of Focusing : &lt;math&gt;(\phi^{\Rightarrow x})^{\Rightarrow y} = \phi^{\Rightarrow x \wedge y}\,&lt;/math&gt;
To focus an information on &lt;math&gt;x\,&lt;/math&gt; and &lt;math&gt;y\,&lt;/math&gt;, one may focus it to &lt;math&gt;x \wedge y\,&lt;/math&gt;.
; Idempotency : &lt;math&gt;\phi \otimes \phi^{\Rightarrow x} = \phi\,&lt;/math&gt;
An information combined with a part of itself gives nothing new.
; Support : &lt;math&gt;\forall \phi \in \Phi,~ \exists x \in D\,&lt;/math&gt; such that &lt;math&gt;\phi = \phi^{\Rightarrow x}\,&lt;/math&gt;
Each information refers to at least one domain (question).
| style="border:1px" | &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
|}

A two-sorted algebra &lt;math&gt;(\Phi,D)\,&lt;/math&gt; satisfying these axioms is called an '''Information Algebra'''.

== Order of information ==
A partial order of information can be introduced by defining &lt;math&gt;\phi \leq \psi\,&lt;/math&gt; if &lt;math&gt;\phi \otimes \psi = \psi\,&lt;/math&gt;. This means that &lt;math&gt;\phi\,&lt;/math&gt; is less informative than &lt;math&gt;\psi\,&lt;/math&gt; if it adds no new information to &lt;math&gt;\psi\,&lt;/math&gt;. The semigroup &lt;math&gt;\Phi\,&lt;/math&gt; is a semilattice relative to this order, i.e. &lt;math&gt;\phi \otimes \psi = \phi \vee \psi\,&lt;/math&gt;. Relative to any domain (question) &lt;math&gt;x \in D\,&lt;/math&gt; a partial order can be introduced by defining &lt;math&gt;\phi \leq_{x} \psi\,&lt;/math&gt;  if &lt;math&gt;\phi^{\Rightarrow x} \leq \psi^{\Rightarrow x}\,&lt;/math&gt;. It represents the order of information content of &lt;math&gt;\phi\,&lt;/math&gt; and &lt;math&gt;\psi\,&lt;/math&gt; relative to the domain (question) &lt;math&gt;x\,&lt;/math&gt;.

== Labeled information algebra ==
The pairs &lt;math&gt;(\phi,x) \ \,&lt;/math&gt;, where &lt;math&gt;\phi \in \Phi\,&lt;/math&gt; and &lt;math&gt;x \in D\,&lt;/math&gt; such that &lt;math&gt;\phi^{\Rightarrow x} = \phi\,&lt;/math&gt; form a '''labeled Information Algebra'''. More precisely, in the two-sorted algebra &lt;math&gt;(\Phi,D) \ \,&lt;/math&gt;, the following operations are defined
{| border=1 style="border:0px"
| style="border:1px solid #448800; padding:0.4em; background-color:#EEFFEE" |
; Labeling : &lt;math&gt;d(\phi,x) = x \ \,&lt;/math&gt;
; Combination : &lt;math&gt;(\phi,x) \otimes (\psi,y) = (\phi \otimes \psi,x \vee y)~~~~\,&lt;/math&gt;
; Projection : &lt;math&gt;(\phi,x)^{\downarrow y} = (\phi^{\Rightarrow y},y)\text{ for }y \leq x\,&lt;/math&gt;
| style="border:1px" | &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
|}

== Models of information algebras ==
Here follows an incomplete list of instances of information algebras:
*[[Relational algebra]]: The reduct of a relational algebra with natural join as combination and the usual projection is a labeled information algebra, see [[#Worked-out example: relational algebra|Example]].
*[[Constraint system]]s: Constraints form an information algebra {{Harv|Jaffar|Maher|1994}}.
*[[Semiring valued algebra]]s: C-Semirings induce information algebras {{Harv|Bistarelli|Montanari|Rossi1997}};{{Harv|Bistarelli|Fargier|Montanari|Rossi|Schiex|Verfaillie|1999}};{{Harv|Kohlas|Wilson|2006}}. 
*[[Logic]]: Many logic systems induce information algebras {{Harv|Wilson|Mengin|1999}}. Reducts of [[cylindric algebra]]s {{Harv|Henkin|Monk|Tarski|1971}} or [[polyadic algebra]]s are information algebras related to [[predicate logic]] {{Harv|Halmos|2000}}.
*[[Module (mathematics)|Module algebra]]s: {{Harv|Bergstra|Heering|Klint|1990}};{{Harv|de Lavalette|1992}}.
*[[Linear system]]s: Systems of linear equations or linear inequalities induce information algebras {{Harv|Kohlas|2003}}.

=== Worked-out example: relational algebra ===
{{cleanup section|reason=\texttt|date=August 2014}}
Let &lt;math&gt;{\mathcal A}\,&lt;/math&gt; be a set of symbols, called ''attributes'' (or ''column
names''). For each &lt;math&gt;\alpha\in{\mathcal A}\,&lt;/math&gt; let &lt;math&gt;U_\alpha\,&lt;/math&gt; be a non-empty set, the
set of all possible values of the attribute &lt;math&gt;\alpha\,&lt;/math&gt;. For example, if 
&lt;math&gt;{\mathcal A}= \{\texttt{name},\texttt{age},\texttt{income}\}\,&lt;/math&gt;, then &lt;math&gt;U_{\texttt{name}}\,&lt;/math&gt; could
be the set of strings, whereas &lt;math&gt;U_{\texttt{age}}\,&lt;/math&gt; and &lt;math&gt;U_{\texttt{income}}\,&lt;/math&gt; are both
the set of non-negative integers.

Let &lt;math&gt;x\subseteq{\mathcal A}\,&lt;/math&gt;. An ''&lt;math&gt;x\,&lt;/math&gt;-tuple'' is a function &lt;math&gt;f\,&lt;/math&gt; so that
&lt;math&gt;\hbox{dom}(f)=x\,&lt;/math&gt; and &lt;math&gt;f(\alpha)\in U_\alpha\,&lt;/math&gt; for each &lt;math&gt;\alpha\in x\,&lt;/math&gt; The set
of all &lt;math&gt;x\,&lt;/math&gt;-tuples is denoted by &lt;math&gt;E_x\,&lt;/math&gt;. For an &lt;math&gt;x\,&lt;/math&gt;-tuple &lt;math&gt;f\,&lt;/math&gt; and a subset
&lt;math&gt;y\subseteq x\,&lt;/math&gt; the restriction &lt;math&gt;f[y]\,&lt;/math&gt; is defined to be the
&lt;math&gt;y\,&lt;/math&gt;-tuple &lt;math&gt;g\,&lt;/math&gt; so that &lt;math&gt;g(\alpha)=f(\alpha)\,&lt;/math&gt; for all &lt;math&gt;\alpha\in y\,&lt;/math&gt;.

A ''relation &lt;math&gt;R\,&lt;/math&gt; over &lt;math&gt;x\,&lt;/math&gt;'' is a set of &lt;math&gt;x\,&lt;/math&gt;-tuples, i.e. a subset of &lt;math&gt;E_x\,&lt;/math&gt;.
The set of attributes &lt;math&gt;x\,&lt;/math&gt; is called the ''domain'' of &lt;math&gt;R\,&lt;/math&gt; and denoted by
&lt;math&gt;d(R)\,&lt;/math&gt;. For &lt;math&gt;y\subseteq d(R)\,&lt;/math&gt; the ''projection'' of &lt;math&gt;R\,&lt;/math&gt; onto &lt;math&gt;y\,&lt;/math&gt; is defined
as follows:
:&lt;math&gt;\pi_y(R):=\{f[y]\mid f\in R\}.\,&lt;/math&gt;
The ''join'' of a relation &lt;math&gt;R\,&lt;/math&gt; over &lt;math&gt;x\,&lt;/math&gt; and a relation &lt;math&gt;S\,&lt;/math&gt; over &lt;math&gt;y\,&lt;/math&gt; is
defined as follows:
:&lt;math&gt;R\bowtie S:=\{f\mid f \quad (x\cup y)\hbox{-tuple},\quad f[x]\in R,
  \;f[y]\in S\}.\,&lt;/math&gt;
As an example, let &lt;math&gt;R\,&lt;/math&gt; and &lt;math&gt;S\,&lt;/math&gt; be the following relations:
:&lt;math&gt;R=
   \begin{matrix}
    \texttt{name} &amp; \texttt{age} \\
    \texttt{A} &amp; \texttt{34} \\
    \texttt{B} &amp; \texttt{47} \\
    \end{matrix}\qquad
   S=
   \begin{matrix}
    \texttt{name} &amp; \texttt{income} \\
    \texttt{A} &amp; \texttt{20'000} \\
    \texttt{B} &amp; \texttt{32'000} \\
   \end{matrix}\,&lt;/math&gt;
Then the join of &lt;math&gt;R\,&lt;/math&gt; and &lt;math&gt;S\,&lt;/math&gt; is:
:&lt;math&gt;R\bowtie S=
   \begin{matrix}
    \texttt{name} &amp; \texttt{age} &amp; \texttt{income} \\
    \texttt{A} &amp; \texttt{34} &amp; \texttt{20'000} \\
    \texttt{B} &amp; \texttt{47} &amp; \texttt{32'000} \\
   \end{matrix}\,&lt;/math&gt;
A relational database with natural join &lt;math&gt;\bowtie\,&lt;/math&gt; as combination and the usual projection &lt;math&gt;\pi\,&lt;/math&gt; is an information algebra.
The operations are well defined since
* &lt;math&gt;d(R\bowtie S)=d(R)\cup d(S)\,&lt;/math&gt;
* If &lt;math&gt;x\subseteq d(R)\,&lt;/math&gt;, then &lt;math&gt;d(\pi_x(R))=x\,&lt;/math&gt;.
It is easy to see that relational databases satisfy the axioms of a labeled
information algebra:
; semigroup : &lt;math&gt;(R_1\bowtie R_2)\bowtie R_3=R_1\bowtie(R_2\bowtie R_3)\,&lt;/math&gt; and &lt;math&gt;R\bowtie S=S\bowtie R\,&lt;/math&gt;
; transitivity : If &lt;math&gt;x\subseteq y\subseteq d(R)\,&lt;/math&gt;, then &lt;math&gt;\pi_x(\pi_y(R))=\pi_x(R)\,&lt;/math&gt;.
; combination : If &lt;math&gt;d(R)=x\,&lt;/math&gt; and &lt;math&gt;d(S)=y\,&lt;/math&gt;, then &lt;math&gt;\pi_x(R\bowtie S)=R\bowtie\pi_{x\cap y}(S)\,&lt;/math&gt;.
; idempotency : If &lt;math&gt;x\subseteq d(R)\,&lt;/math&gt;, then &lt;math&gt;R\bowtie\pi_x(R)=R\,&lt;/math&gt;.
; support : If &lt;math&gt; x = d(R)\,&lt;/math&gt;, then &lt;math&gt;\pi_x(R)=R\,&lt;/math&gt;.

== Connections ==
{{expand section|date=March 2014}}
; Valuation algebras : Dropping the idempotency axiom leads to [[valuation algebra]]s. These axioms have been introduced by {{Harv|Shenoy|Shafer|1990}} to generalize ''local computation schemes'' {{Harv|Lauritzen|Spiegelhalter|1988}} from Bayesian networks to more general formalisms, including belief function, possibility potentials, etc. {{Harv|Kohlas |Shenoy|2000}}. For a book-length exposition on the topic see {{Harvtxt|Pouly|Kohlas|2011}}.
; Domains and information systems: ''Compact Information Algebras'' {{Harv|Kohlas|2003}} are related to [[Scott domain]]s and [[Scott information system]]s  {{Harv|Scott|1970}};{{Harv|Scott|1982}};{{Harv|Larsen|Winskel|1984}}.
; Uncertain information : Random variables with values in information algebras represent ''[[probabilistic argumentation]] systems'' {{Harv|Haenni|Kohlas|Lehmann|2000}}.
; Semantic information : Information algebras introduce semantics by relating information to questions through focusing and combination {{Harv|Groenendijk|Stokhof|1984}};{{Harv|Floridi|2004}}.
; Information flow : Information algebras are related to information flow, in particular classifications  {{Harv|Barwise|Seligman|1997}}.
; Tree decomposition : ...
; Semigroup theory : ...
; Compositional models: Such models may be defined within the framework of information algebras: https://arxiv.org/abs/1612.02587
; Extended axiomatic foundations of information and valuation algebras: The concept of conditional independence is basic for information algebras and a new axiomatic foundation of information algebras, based on conditional independence, extending the old one (see above) is available: https://arxiv.org/abs/1701.02658

== Historical Roots ==
The axioms for information algebras are derived from 
the axiom system proposed in (Shenoy and Shafer, 1990), see also (Shafer, 1991).

== References ==
* {{Citation | first1=J. | last1= Barwise | author1link=Jon Barwise | first2=J. | last2=Seligman | title=Information Flow: The Logic of Distributed Systems | year=1997 | publisher=Number 44 in Cambridge Tracts in Theoretical Computer Science, Cambridge University Press | place=Cambridge U.K. }}
* {{Citation | first1=J.A. | last1=Bergstra | first2=J.| last2=Heering | first3=P. | last3=Klint | title=Module algebra | journal=J. of the assoc. for Computing Machinery|volume=73|issue=2|pages=335–372 | year=1990}}
* {{Citation | first1=S. | last1=Bistarelli | first2=H. | last2=Fargier | first3=U. | last3=Montanari | first4=F. | last4=Rossi | first5=T. |last5=Schiex | first6=G.|last6=Verfaillie| title=Semiring-based CSPs and valued CSPs: Frameworks, properties, and comparison | journal=Constraints |volume=4 |issue=3 | pages=199&amp;ndash;240 | year=1999 | url=ftp://ftp.irit.fr/pub/IRIT/RPDMP/PapersFargier/valuatedItaliens.ps.gz}}
* {{Citation | first1=Stefano | last1=Bistarelli | first2=Ugo |last2=Montanari |first3=Francesca | last3=Rossi |title=Semiring-based constraint satisfaction and optimization | journal=Journal of the ACM |volume=44 |issue=2 | pages=201–236 | year=1997 |  url=ftp://ftp.di.unipi.it/pub/Papers/rossi/jacm.ps.gz | doi=10.1145/256303.256306}}
* {{Citation | first=Gerard R. Renardel | last=de Lavalette | chapter= Logical semantics of modularisation | editor=Egon Börger |editor2=Gerhard Jäger |editor3=Hans Kleine Büning |editor4=Michael M. Richter | title=CSL: 5th Workshop on Computer Science Logic  | pages=306–315 | publisher=Volume 626 of Lecture Notes in Computer Science, Springer | year=1992 | ISBN=3-540-55789-X |
url=http://citeseer.ist.psu.edu/484529.html}}
* {{Citation | first=Luciano | last= Floridi | title=Outline of a theory of strongly semantic information | journal=Minds and Machines |volume=14 |issue=2 | pages=197–221 | year=2004 | doi=10.1023/b:mind.0000021684.50925.c9}} 
* {{Citation | first1=J. | last1=Groenendijk | first2=M. | last2=Stokhof | title=Studies on the Semantics of Questions and the Pragmatics of Answers | publisher=PhD thesis, Universiteit van Amsterdam | year=1984}}
* {{Citation|first1=R. |last1=Haenni |first2=J. |last2=Kohlas |first3=N. |last3=Lehmann |chapter=Probabilistic argumentation systems |editor=J. Kohlas |editor2=S. Moral |title=Handbook of Defeasible Reasoning and Uncertainty Management Systems |pages=221–287 |publisher=Volume 5: Algorithms for Uncertainty and Defeasible Reasoning, Kluwer |place=Dordrecht |year=2000 |url=http://diuf.unifr.ch/tcs/publications/ps/hkl2000.pdf |deadurl=yes |archiveurl=https://web.archive.org/web/20050125040324/http://diuf.unifr.ch/tcs/publications/ps/hkl2000.pdf |archivedate=January 25, 2005 }}
* {{Citation | first=Paul R. | last=Halmos | authorlink=Paul R. Halmos  | title=An autobiography of polyadic algebras | journal=Logic Journal of the IGPL |volume=8 |issue=4 | year=2000 }} 
* {{Citation | first1=L. | last1=Henkin | author1link=Leon Henkin | first2=J. D. | last2=Monk | first3=A. | last3=Tarski | author3link=Alfred Tarski | title=Cylindric Algebras | publisher=North-Holland | place=Amsterdam | year= 1971 | ISBN =0-7204-2043-1}}
* {{Citation | first1=J. | last1=Jaffar | first2= M. J. | last2=Maher | title= Constraint logic programming: A survey | journal= J. of Logic Programming |volume= 19/20 | pages=503–581 | year= 1994 | doi=10.1016/0743-1066(94)90033-7}} 
* {{Citation | first=J. | last=Kohlas | title= Information Algebras: Generic Structures for Inference | publisher=Springer-Verlag | year= 2003 | ISBN = 1-85233-689-7}}
* {{Citation | first1=J. | last1=Kohlas | first2= P.P. | last2=Shenoy | chapter=Computation in valuation algebras | editor=J. Kohlas |editor2=S. Moral | title=Handbook of Defeasible Reasoning and Uncertainty Management Systems, Volume 5: Algorithms for Uncertainty and Defeasible Reasoning |pages=5–39|publisher=Kluwer | place=Dordrecht | year= 2000}} 
* {{Citation|first1=J. |last1=Kohlas |first2=N. |last2=Wilson |title=Exact and approximate local computation in semiring-induced valuation algebras |publisher=Technical Report 06-06, Department of Informatics, University of Fribourg |year=2006 |url=http://diuf.unifr.ch/tcs/publications/ps/kohlaswilson06.pdf |deadurl=yes |archiveurl=https://web.archive.org/web/20060924230816/http://diuf.unifr.ch/tcs/publications/ps/kohlaswilson06.pdf |archivedate=September 24, 2006 }} 
* {{Citation | first1=K. G. | last1=Larsen | first2=G. |last2=Winskel | chapter=Using information systems to solve recursive domain equations effectively | editor=Gilles Kahn |editor2=David B. MacQueen |editor3=Gordon D. Plotkin | title=Semantics of Data Types, International Symposium, Sophia-Antipolis, France, June 27&amp;ndash;29, 1984, Proceedings |volume=173 of Lecture Notes in Computer Science | pages=109–129 | location=Berlin | year= 1984 | publisher=Springer}}
* {{Citation | first1=S. L. | last1= Lauritzen |first2=D. J.|last2=Spiegelhalter | title=Local computations with probabilities on graphical structures and their application to expert systems | journal= Journal of the Royal Statistical Society, Series B |volume= 50 | pages=157–224 | year= 1988}} 
* {{citation|first1=Marc |last1=Pouly | first2=Jürg |last2=Kohlas|title=Generic Inference: A Unifying Theory for Automated Reasoning|year=2011|publisher=John Wiley &amp; Sons|isbn=978-1-118-01086-0}}
* {{Citation | first=Dana S. | last= Scott | authorlink=Dana Scott | title= Outline of a mathematical theory of computation | publisher=Technical Monograph PRG–2, Oxford University Computing Laboratory, Programming Research Group | year=1970}} 
* {{Citation | first=D.S. | last=Scott | chapter=Domains for denotational semantics | editor= M. Nielsen |editor2=E.M. Schmitt | title= Automata, Languages and Programming | pages= 577–613 | publisher= Springer | year= 1982}} 
* {{Citation | first=G. | last= Shafer | title=An axiomatic study of computation in hypertrees | publisher=Working Paper 232, School of Business, University of Kansas | year= 1991}} 
* {{Citation | first1=P. P. | last1=Shenoy | first2=G. | last2=Shafer | chapter=Axioms for probability and belief-function proagation | editor=Ross D. Shachter |editor2=Tod S. Levitt |editor3=Laveen N. Kanal |editor4=John F. Lemmer | title= Uncertainty in Artificial Intelligence 4 |volume= 9 | journal= Machine intelligence and pattern recognition |pages = 169–198 | place=Amsterdam | year= 1990 | publisher=Elsevier | ISBN= 0-444-88650-8}}
* {{Citation | first1=Nic | last1=Wilson |first2= Jérôme | last2= Mengin | chapter=Logical deduction using the local computation framework | editor=Anthony Hunter |editor2=Simon Parsons | title=Symbolic and Quantitative Approaches to Reasoning and Uncertainty, European Conference, ECSQARU’99, London, UK, July 5&amp;ndash;9, 1999, Proceedings, volume 1638 of Lecture Notes in Computer Science | pages= 386–396 | publisher= Springer | year= 1999 | ISBN = 3-540-66131-X | url = http://springerlink.metapress.com/openurl.asp?genre=article&amp;amp;issn=0302-9743&amp;amp;volume=1638&amp;amp;spage=0386}}

[[Category:Information theory]]
[[Category:Abstract algebra]]</text>
      <sha1>fqw6pabk44rsmkbgx6qd0lfghxhxxwp</sha1>
    </revision>
  </page>
  <page>
    <title>International Symposium on Fundamentals of Computation Theory</title>
    <ns>0</ns>
    <id>39584195</id>
    <revision>
      <id>860435551</id>
      <parentid>845827438</parentid>
      <timestamp>2018-09-20T17:23:52Z</timestamp>
      <contributor>
        <username>Narky Blert</username>
        <id>22041646</id>
      </contributor>
      <comment>dab tag removed (good link)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3848">'''FCT''', the International Symposia on '''Fundamentals of Computation Theory''' is a biennial series of [[academic conference|conferences]] in the field of [[theoretical computer science]]. It was established in 1977 for researchers interested in all aspects of theoretical computer science, and in particular [[algorithms]], [[computational complexity]], [[formal methods|formal]] and logical methods. FCT was previously held at the following institutions.

{| class="wikitable"
! year
! institution
! location
|-
| 1977 || -- || [[Poznań, Poland]]
|-
| 1979 || -- || [[Wendisch-Rietz, Germany]]
|-
| 1981 || [[University of Szeged]] || [[Szeged|Szeged, Hungary]]
|-
| 1983 || -- || [[Borgholm|Borgholm, Sweden]]
|-
| 1985 || -- || [[Cottbus|Cottbus, Germany]]
|-
| 1987 || [[Kazan State University]] || [[Kazan, Russia]]
|-
| 1989 || [[University of Szeged]] || [[Szeged|Szeged, Hungary]]
|-
| 1991 || -- || [[Gosen-Neu Zittau|Gosen]]-[[Berlin, Germany]]
|-
| 1993 || [[University of Szeged]] || [[Szeged|Szeged, Hungary]]
|-
| 1995 || [[Technische Universität Dresden]] || [[Dresden, Germany]]
|-
| 1997 || [[Jagiellonian University]] || [[Kraków, Poland]]
|-
| 1999 || [[Alexandru Ioan Cuza University]] || [[Iasi, Romania]]
|-
| 2001 || [[University of Latvia]] || [[Riga, Latvia]]
|-
| 2003 || [[Malmö University]] || [[Malmö, Sweden]]
|-
| 2005 || [[University of Lübeck]] || [[Lübeck, Germany]]
|-
| 2007 || [[Hungarian Academy of Sciences]] || [[Budapest, Hungary]]
|-
| 2009 || [[University of Wrocław]] || [[Wrocław, Poland]]
|-
| 2011 || [[University of Oslo]]&lt;ref&gt;[http://fct11.ifi.uio.no/ FCT 2011 page at University of Oslo]&lt;/ref&gt;&lt;ref&gt;Fundamentals of Computation Theory: 18th International Symposium, FCT 2011, Oslo, Norway, August 22–25, 2011: Proceedings. Springer Lecture Notes in Computer Science ([[LNCS]]) 6914 (2011), {{ISBN|978-3-642-22952-7}} (print), {{ISBN|978-3-642-22953-4}} (online)&lt;/ref&gt; || [[Oslo, Norway]]
|-
| 2013 || [[Liverpool University]]&lt;ref name="fct2013"&gt;[http://fct2013.csc.liv.ac.uk/ FCT 2013 web page at Liverpool University (retrieved 2013-07-11)]&lt;/ref&gt; || [[Liverpool, UK]]
|-
| 2015 || [[Gdańsk University of Technology]] || [[Gdańsk, Poland]]&lt;ref name="fct2015"&gt;[https://sites.google.com/site/fct2015gdansk// FCT 2015 web page (retrieved 2014-10-22)]&lt;/ref&gt;
|-
| 2017 || [[University of Bordeaux]] || [[Bordeaux]], France&lt;ref name="fct2017"&gt;[http://fct2017.labri.fr/practical.html FCT 2017 web page (retrieved 2016-09-27)]&lt;/ref&gt;
|-
| 2019 || [[University of Copenhagen]] || [[Copenhagen]], Denmark &lt;ref name="fct2019"&gt;[http://www.diku.dk/fct2019 FCT 2019 web page (retrieved 2017-10-09) ]&lt;/ref&gt;
|-
| 2021 || [[National Technical University of Athens]] || [[Athens]], Greece &lt;ref name="fct2021"&gt;[http://www.corelab.ntua.gr/fct2021 FCT 2021 web page (retrieved 2018-06-14) ]&lt;/ref&gt;
|}

== See also ==

* [[Theoretical computer science#Conferences|Conferences]] in theoretical computer science.
* The [[list of computer science conferences]] contains other academic conferences in computer science.

== References ==

{{reflist}}
 
== External links==
* [http://fct2013.csc.liv.ac.uk/steering.html FCT steering committee].
* [http://www.informatik.uni-trier.de/~ley/db/conf/fct/ FCT proceedings information] in [[DBLP]].
* [http://sites.google.com/site/fct2015gdansk/ FCT 2015 web site].
* [http://fct2013.csc.liv.ac.uk/ FCT 2013 web site].
* [http://fct11.ifi.uio.no/ FCT 2011 web site].
* [http://fct2009.im.pwr.wroc.pl/ FCT 2009 web site].
* [http://www.conferences.hu/fct2007/ FCT 2007 web site].
* [http://www.tcs.uni-luebeck.de/sonderseiten/veranstaltungen/fct2005/ FCT 2005 web site].
* [http://www.lumii.lv/Pages/MIIE_staff/rusins/fct.htm FCT 2001 web site].

{{DEFAULTSORT:fct}}
[[Category:Theoretical computer science conferences]]
[[Category:Recurring events established in 1977]]</text>
      <sha1>f7zyqrg8qq3dgj1drjjlhw0xpiqjaz3</sha1>
    </revision>
  </page>
  <page>
    <title>Jean Bartik</title>
    <ns>0</ns>
    <id>5178038</id>
    <revision>
      <id>868876896</id>
      <parentid>866068744</parentid>
      <timestamp>2018-11-15T00:49:23Z</timestamp>
      <contributor>
        <username>Equinox</username>
        <id>24880950</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="25086">{{Good article}}
{{Infobox person
| honorific_prefix          = 
| name                      = Jean Bartik
| honorific_suffix          = 
| image                     = Jean_Bartik.jpg
| image_size                = 
| alt                       = 
| caption                   = 
| native_name               = 
| native_name_lang          = 
| birth_name                = Betty Jean Jennings
| birth_date                = {{birth date |1924|12|27}}
| birth_place               = [[Gentry County, Missouri]]
| death_date                = {{death date and age |2011|03|23 |1924|12|27}} 
| nationality               = American
| alma_mater                = [[Northwest Missouri State University|Northwest Missouri State Teachers College]] (honorary D. Sc., 2002), [[University of Pennsylvania]] (B.S., 1945; Master's 1967)
| awards                    = [[Computer Pioneer Award]] &lt;small&gt;(2008)&lt;/small&gt;
| module                    = {{infobox engineering career
| discipline           = 
| institutions         = 
| practice_name        = 
| employer             = [[University of Pennsylvania]],&lt;br&gt;[[Eckert–Mauchly Computer Corporation]],&lt;br&gt;[[Auerbach Publishers]],&lt;br&gt;Data Decisions
| significant_projects = [[ENIAC]]
| significant_design   = 
| significant_advance  = 
| significant_awards   = [[WITI Hall of Fame]] &lt;br&gt; [[Computer History Museum]] Fellow (2008)
}}
| spouse                    = William Bartik
}}

'''Jean Jennings Bartik''' (December 27, 1924 – March 23, 2011) was one of the original programmers for the [[ENIAC]] computer. She studied mathematics in school then began work at the [[University of Pennsylvania]], first manually calculating [[Ballistics|ballistics trajectories]], then using ENIAC to do so. She and her colleagues developed and codified many of the fundamentals of [[Programming language|programming]] while working on the ENIAC, since it was the first computer of its kind. After her work on ENIAC, Bartik went on to work on [[BINAC]] and [[UNIVAC]], and spent time at a variety of technical companies as a writer, manager, engineer and programmer. She spent her later years as a real estate agent and died in 2011 from congestive heart failure complications.

==Early life and education==
Born '''Betty Jean Jennings''' in [[Gentry County, Missouri]], in 1924, she was the sixth of seven children. Her father, William Smith Jennings (1893-1971) was from [[Alanthus Grove, Missouri|Alanthus Grove]], where he was a schoolteacher as well as a farmer. Her mother, Lula May Spainhower (1887-1988) was from [[Alanthus, Missouri|Alanthus]]. Jennings had three older brothers, William (January 10, 1915) Robert (March 15, 1918); and Raymond (January 23, 1922); two older sisters, Emma (August 11, 1916) and Lulu (August 22, 1919), and one younger sister, Mable (December 15, 1928).&lt;ref name=":0"&gt;{{cite web|url=http://www.computerhistory.org/fellowawards/hall/bios/Jean,Bartik/|title=Jean Bartik|website=Computer History Museum|accessdate=October 31, 2016|deadurl=yes|archiveurl=https://web.archive.org/web/20160311163614/http://www.computerhistory.org/fellowawards/hall/bios/Jean,Bartik/|archivedate=March 11, 2016|df=}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www-history.mcs.st-and.ac.uk/Biographies/Bartik.html|title=Bartik biography|website=www-history.mcs.st-and.ac.uk|access-date=2017-11-19}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://archive.computerhistory.org/resources/text/Oral_History/Bartik_Jean/102658322.05.01.acc.pdf|title=Oral History: Jean Bartik|last=|first=|date=|website=|access-date=}}&lt;/ref&gt;

In her childhood, she would ride on horseback to visit her grandmother, who bought the young girl a newspaper to read every day and became a role model for the rest of her life. She began her education at a local [[one-room school]], and gained local attention for her [[softball]] skill. In order to attend high school, she lived with her older sister in the neighboring town, where the school was located, and then began to drive every day despite being only 14. She graduated from Stanberry High School in 1941, aged 16.&lt;ref name=":1"&gt;{{Cite web|url=http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Bartik.html|title=Jean Bartik biography|last=O'Connor|first=J. J.|last2=Robertson|first2=E.F.|website=www-groups.dcs.st-and.ac.uk|accessdate=2016-06-26}}&lt;/ref&gt;&lt;ref name=":5"&gt;{{Cite book|url=https://www.worldcat.org/oclc/938387267|title=Computer scientist Jean Bartik|last=1967-|first=Reed, Jennifer,|isbn=1512413100|location=Minneapolis|oclc=938387267}}&lt;/ref&gt;&lt;ref name=:autobio&gt;{{cite book|last=Bartik|first=Jean Jennings|editor1-last=Rickman|editor1-first=Jon T.|editor2-last=Todd|editor2-first=Kim D.|authorlink=Jean Jennings Bartik|year=2013|title=Pioneer programmer: Jean Jennings Bartik and the computer that changed the world|publisher=Truman State University Press|location=Kirksville, Missouri|isbn=9781612480862|oclc=854828754|ref=harv}}&lt;/ref&gt;

She attended [[Northwest Missouri State University|Northwest Missouri State Teachers College]] now known [[Northwest Missouri State University]], majoring in mathematics with a minor in English and graduating in 1945. Jennings was awarded the only mathematics degree in her class.&lt;ref name=":0"/&gt; Although she had originally intended to study journalism, she decided to change to mathematics because she had a bad relationship with her adviser.&lt;ref name="ieee"/&gt; Later in her life, she earned a master's degree in English at the [[University of Pennsylvania]] in 1967 and was awarded an honorary doctorate degree from [[Northwest Missouri State University]] in 2002.&lt;ref name=":0"/&gt;&lt;ref name=":6"&gt;{{Cite book|url=https://www.worldcat.org/oclc/935185503|title=Jean Jennings Bartik computer pioneer|last=D.,|first=Todd, Kim|isbn=1612481450|location=Kirksville, Missouri|oclc=935185503}}&lt;/ref&gt;

==Career==
[[File:Two women operating ENIAC.gif|right|thumbnail|upright=1.5|thumb|Programmers Betty Jean Jennings (left) and [[Fran Bilas]] (right) operate the ENIAC's main control panel.]]
{{Listen|type=speech|pos=right|filename=The ENIAC Programmers (As Told By U.S. Chief Technology Officer Megan Smith).ogg|title=The ENIAC Programmers (As Told By U.S. Chief Technology Officer Megan Smith)|description= }}
In 1945, the Army was recruiting mathematicians from universities to aid in the war effort; despite a warning by her adviser that she would be just "a cog in a wheel" with the Army, and despite encouragement to become a mathematics teacher instead, Bartik known as Betty Jennings at the time decided to become a [[human computer]]. Her calculus professor, encouraged Bartik to take the job at University of Pennsylvania because they had a differential analyzer.&lt;ref name="ieee"/&gt;&lt;ref name=":autobio"/&gt;

She applied to both [[IBM]] and the University of Pennsylvania at the age of 20. Although rejected by IBM, Jennings was hired by the [[University of Pennsylvania]] to work for Army Ordnance at [[Aberdeen Proving Ground]], calculating [[ballistics]] [[trajectory|trajectories]] by hand.&lt;ref name=":1"/&gt;&lt;ref name="NYTobit"&gt;{{Cite web|url=https://www.nytimes.com/2011/04/08/business/08bartik.html|title=Jean Bartik, Software Pioneer, Dies at 86|last=Lohr|first=Steve|date=2011-04-07|work=[[The New York Times]]|accessdate=2011-04-08}}&lt;/ref&gt; While working there, Bartik met her husband, William Bartik, who was an engineer working on a Pentagon project at the University of Pennsylvania. They married in December 1946.&lt;ref name="ieee"/&gt;&lt;ref name=NYTobit/&gt;

When the Electronic Numeric Integrator and Computer (ENIAC) was developed for the purpose of calculating the ballistic trajectories human computers like Bartik had been doing by hand, she applied to become a part of the project and was eventually selected to be one of its first programmers. Bartik was asked to set up problems for the ENIAC without being taught any techniques.&lt;ref name=":2" /&gt;  Six women, including [[Jean Jennings Bartik]], [[Betty Holberton]], [[Marlyn Meltzer|Marlyn Wescoff]], [[Kathleen Antonelli|Kathleen McNulty]], [[Ruth Teitelbaum]], and [[Frances Spence]], were chosen to be the main programmers for the ENIAC.&lt;ref name=":autobio" /&gt; Many other women who are often unrecognized contributed to the ENIAC during a period of wartime male labor shortage.&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/813929041|title=Recoding gender : women's changing participation in computing|last=Janet.|first=Abbate,|date=2012|publisher=MIT Press|isbn=9780262018067|location=Cambridge, Mass.|oclc=813929041}}&lt;/ref&gt; Bartik, who became the co-lead programmer (with [[Betty Holberton]]), and the other four original programmers became extremely adept at running the ENIAC; with no manual to rely on, the group reviewed diagrams of the device, interviewed the engineers who had built it, and used this information to teach themselves the skills they needed.&lt;ref name=ieee&gt;{{cite journal|last=Barkley Fritz|first=W.|title=The Women of ENIAC|journal=IEEE Annals of the History of Computing|date=1996|volume=18|issue=3|doi=10.1109/85.511940|pages=13–28}}&lt;!--|accessdate=21 April 2014--&gt;&lt;/ref&gt; Initially, they were not allowed to see the ENIAC's hardware at all since it was still classified and they had not received security clearance; they had to learn how to program the machine solely through studying schematic diagrams.&lt;ref name="witi"/&gt; The six-woman team was also not initially given space to work together, so they found places to work where they could, in abandoned classrooms and fraternity houses.&lt;ref name="ieee"/&gt;

While the six women worked on ENIAC, they developed [[subroutine]]s, [[Nesting (computing)|nesting]], and other fundamental programming techniques, and arguably invented the discipline of programming digital computers.&lt;ref name=":1"/&gt;&lt;ref name="NYTobit"/&gt;&lt;ref name=":7"&gt;{{Cite book|url=https://www.worldcat.org/oclc/876012030|title=The innovators : how a group of hackers, geniuses, and geeks created the digital revolution|last=Walter|first=Isaacson|isbn=1476708703|edition=First Simon &amp; Schuster hardcover |location=New York|oclc=876012030}}&lt;/ref&gt; Bartik and the other ENIAC female programmers learned to physically modify the machine, moving switches and rerouting cables, in order to program it.&lt;ref name="witi" /&gt;&lt;ref name=":7" /&gt;  In addition to performing the original ballistic trajectories they were hired to compute, the six female programmers soon became operators on the [[Los Alamos National Laboratory|Los Alamos]] nuclear calculations, and generally expanded the programming repertoire of the machine.&lt;ref name="ieee" /&gt; Bartik's programming partner on the important trajectory program for the military that would prove that the ENIAC worked to specification was [[Betty Holberton]] known at the time as Betty Snyder.  Bartik and Holberton's program was chosen to introduce the ENIAC to the public and larger scientific community.  That demonstration occurred on February 15, 1946 and was a tremendous success.  The ENIAC proved that it operated faster than the [[Harvard Mark I|Mark I]], a well known electromechanical machine at Harvard, and also showed that the work that would take a "human computer" 40 hours to complete could be done in 20 seconds.&lt;ref name=":6" /&gt;&lt;ref name=":autobio" /&gt;

Bartik described the first public demonstration of the ENIAC in 1946:{{blockquote|The day ENIAC was introduced to the world was one of the most exciting days of my life. The demonstration was fabulous. ENIAC calculated the trajectory faster than it took the bullet to travel. We handed out copies of the calculations as they were run. ENIAC was 1,000 times faster than any machine that existed prior to that time. With its flashing lights, it also was an impressive machine illustrating graphically how fast it was actually computing.&lt;ref name=ieee/&gt;}}

The public demonstration was a success, but most of the congratulations on its turnout were given to its engineers, [[John Mauchly|Mauchly]] and [[Eckert–Mauchly Computer Corporation|Eckert]].&lt;ref name=":autobio" /&gt;

Bartik was later asked to form and lead a group of programmers to convert the ENIAC into a stored program computer, working closely with [[John von Neumann|John Von Neumann]], [https://www.computer.org/web/awards/pioneer-richard-clippinger Dick Clippinger] and [[Adele Goldstine]].&lt;ref name=":6" /&gt;

Bartik converted the ENIAC into a stored program computer by March 1948.&lt;ref name=":6" /&gt;&lt;ref name=":autobio" /&gt; As head of this process, Bartik was charged with the conversion that allowed the ENIAC to be turned into rudimentary stored program computer to assist with Clippinger's wind tunnel programs, which allowed the ENIAC to operate more quickly, efficiently, and accurately.&lt;ref name=":autobio" /&gt;  Letters between Bartik and Adele Goldstine were discovered by authors Thomas Haigh and Mark Priestley during the time of the project, as well as, the fact that much of the [http://ftp.arl.army.mil/mike/comphist/48eniac-coding/sec8.html 60-order Code] was in Bartik's handwriting.&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/1002291949|title=ENIAC IN ACTION : making and remaking the modern computer.|last=CRISPIN.|first=HAIGH, THOMAS. PRIESTLEY, MARK. ROPE,|date=2018|publisher=MIT PRESS|isbn=0262535173|location=[S.l.]|oclc=1002291949}}&lt;/ref&gt;

After the end of the war, Bartik went on to work with the ENIAC designers [[J. Presper Eckert|John Eckert]] and [[John Mauchly]],&lt;ref name=":2"&gt;{{Cite book|title=Grace Hopper and the Invention of the Information Age|last=Beyer|first=Kurt|publisher=MIT Press|year=2009|isbn=978-0-262-01310-9|location=|pages=178–181|quote=|via=}}&lt;/ref&gt; and helped them develop the [[BINAC]] and [[UNIVAC I]] computers.&lt;ref name=":1" /&gt;&lt;ref name="NYTobit" /&gt; BINAC was the first computer to use [[Magnetic tape data storage|magnetic tape]] instead of [[Punched card|punch cards]] to store data and the first computer to utilize the twin unit concept.  The BINAC, which was the first stored program computer hardware wise, worked successfully.  BINAC was purchased by [[Northrop Corporation|Northrop Aircraft]] to guide the Snark missile, but the BINAC proved to be too large for their purposes.  However, according to a Northrop Aircraft programmer, despite claims that the BINAC didn't work once it was moved to Northrop Aircraft were erroneous and the BINAC was working well into the mid-1950s.&lt;ref name=":autobio" /&gt;  Besides, BINAC, Jean's more important work involved her responsibilities in designing the UNIVAC's [[Logic gate|logic circuits]] among other UNIVAC programming and design tasks.&lt;ref name=":1" /&gt; Bartik also co-programmed with her life-long friend [[Betty Holberton]] the first generative programming system ([[Sort Merge Generator|SORT/MERGE]]) for a computer.&lt;ref name=":5" /&gt;  Recalling her time working with Eckert and Mauchly on these projects, she described their close group of computer engineers as a "technical Camelot."&lt;ref name="NYTobit" /&gt;&lt;ref name=":autobio" /&gt;&lt;ref name="YA Bio" &gt;{{cite book|last1=Reed|first1=Jennifer|title=Computer Scientist Jean Bartik (STEM Trailblazer Bios)|publisher=Lerner Publications|isbn=1512413100}}&lt;/ref&gt;&lt;ref name=":autobio" /&gt;&lt;ref name=":6" /&gt;

In the early 1950s, once the [[Eckert–Mauchly Computer Corporation|Eckert-Mauchly Corporation]] was sold to [[Remington Rand]] Bartik went on to help train on how to program and use the UNIVAC for the first six UNIVACs sold, including the programmers at the United States Census Bureau (first UNIVAC sold) and Atomic Energy Commission.&lt;ref name=":autobio" /&gt;  Later, Bartik moved to Philadelphia when her husband, William "Bill" Bartik,took a job with Remington Rand.  Unfortunately, due to a company policy at the time about husbands and wives working together, Jean Bartik, was asked to resign from the company. Between 1951 and 1954, prior to her first child's birth, Jean did mostly free-lance programming assignments for [[John Mauchly]] and was a helpmate to her husband.  Once her son was born, Jean walked away from her career in computing to concentrate on raising a family, during which time she had two other children with her husband.&lt;ref name=":1" /&gt;&lt;ref name=":autobio" /&gt;&lt;ref name="YA Bio" /&gt;&lt;ref name=":6" /&gt;&lt;ref name=":5" /&gt;

Even though Bartik played an integral part in developing ENIAC, her work at University of Pennsylvania and on the ENIAC was completely hidden until her pioneering work was documented by columnist [https://www.wsj.com/articles/SB848618358629375500 Tom Petzinger] in several articles for the [[Wall Street Journal]] on Bartik and Holberton.&lt;ref name=":autobio" /&gt;&lt;ref name="YA Bio" /&gt;&lt;ref name=":6" /&gt;&lt;ref name=":autobio" /&gt; Later, a film called [[Top Secret Rosies: The Female "Computers" of WWII]] helped shed even more light on Bartik's pioneering work in computing along with Kathy Kleiman's [http://eniacprogrammers.org/ ENIAC Programmers Project].

==Later life==
After getting her Masters degree from the [[University of Pennsylvania]] in 1967 and making the decision to divorce her husband, Bartik joined the [https://www.nytimes.com/1992/12/26/nyregion/isaac-l-auerbach-is-dead-at-71-was-early-advocate-of-computers.html Auerbach Corporation] writing and editing technical reports on [[minicomputer]]s.&lt;ref name=":1"/&gt;&lt;ref name=ieee/&gt; It was at this time that Jean began going by the name "Jean" rather than "Betty" which is what she had been known as during her ENIAC, UNIVAC and Remington-Rand years.  The name change was the result of wanting to be taken more seriously by her male co-workers.  Bartik remained with Auerbach for eight years, then moved among positions with a variety of other companies for the rest of her career as a manager, writer, and engineer.&lt;ref name=":1"/&gt; Jean Bartik and William Bartik divorced by 1968.&lt;ref name="NYTobit"/&gt; Bartik ultimately retired from the computing industry in 1986 when her final employer, Data Decisions (a publication of Ziff-Davis), was sold; Bartik spent the following 25 years as a real estate agent.

Starting in 1996, once the importance of their role in the development of computing was re-discovered, Bartik along with Betty Holberton and Bartik's other friend of over 60 years [[Kay Mauchly]] (ENIAC programmer and wife of ENIAC co-inventor [[John Mauchly]]) began to finally receive the acknowledgement and honors for their pioneering work in the early field of computing.  Bartik and Kay Mauchly became invited speakers both at home and abroad to share their experiences working with the ENIAC,BINAC and UNIVAC.  Bartik especially went on to receive many honors and awards for her pioneering role programming the ENIAC, BINAC and UNIVAC, the latter of which helped to launch the commercial computer industry, and for turning the ENIAC into the world's first stored program computer.  The [https://www.nwmissouri.edu/archives/computing/index.htm Jean Jennings Bartik Computing Museum] was opened in 2002 on the campus of [[Northwest Missouri State University]], Bartik's alma mater, in her honoror.  Bartik was inducted into the [[Computer History Museum|Computer History Museum's]] distinguished Hall of Fellows along with [[Linus Torvalds]], creator and principal developer of the Linux kernel and [[Robert Metcalf]], father of Ethernet, in 2008.  Bartik wrote her autobiography "[https://www.amazon.com/Pioneer-Programmer-Jennings-Computer-Changed/dp/1612480861/ref=sr_1_1?ie=UTF8&amp;qid=1518753785&amp;sr=8-1&amp;keywords=Jean+Bartik Pioneer Programmer:  Jean Jennings Bartik and the Computer that Changed the World]" prior to her death in 2011 with the help of long-time colleagues, Dr. Jon T. Rickman and Kim D. Todd.  The autobiography was published in 2013 by [http://tsup.truman.edu/?s=Jean+Bartik Truman State Press] to positive reviews.  Bartik died from [[Heart failure|congestive heart failure]] in a [[Poughkeepsie, New York]] nursing home on March 23, 2011.  She was 86.&lt;ref name=":autobio" /&gt;&lt;ref name="YA Bio" /&gt;&lt;ref name=":autobio" /&gt;&lt;ref name=":6" /&gt;&lt;ref name=":5" /&gt;

Jean wrote that one of the best pieces of advice she ever received was:  "Don't ever let anyone tell you that you can't do something because they think you can't.  You can do anything, achieve anything, if you think you can and you educate yourself to succeed."[http://tsup.truman.edu/product/jean-jennings-bartik-computer-pioneer/]  Encouraging girls and women to follow their dreams, she said, "If my life has proved anything, it is that women (and girls) should never be afraid to take risks and try new things."&lt;ref name=":6" /&gt;

==Awards and honors==
* Inductee, [[Women in Technology International]] [[WITI Hall of Fame|Hall of Fame]] (1997).&lt;ref name="witi"&gt;{{cite web|title=ENIAC Programmers|url=http://www.witi.com/center/witimuseum/halloffame/298369/ENIAC-Programmers-Kathleen-McNulty,-Mauchly-Antonelli,-Jean-Jennings-Bartik,-Frances-Synder-Holber-Marlyn-Wescoff-Meltzer,-Frances-Bilas-Spence-and-Ruth-Lichterman-Teitelbaum/|work=WITI Hall of Fame|publisher=Women in Technology International (WITI)|accessdate=22 April 2014}}&lt;/ref&gt;
* Fellow, [[Computer History Museum]] (2008)&lt;ref&gt;{{cite web
 |url         = http://www.computerhistory.org/fellowawards/hall/bios/Jean,Bartik/
 |title       = Jean Bartik
 |publisher   = Computer History Museum
 |accessdate  = 2013-05-23
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20160311163614/http://www.computerhistory.org/fellowawards/hall/bios/Jean,Bartik/
 |archivedate = 2016-03-11
 |df          = 
}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://googleblog.blogspot.com/2008/12/jean-bartik-untold-story-of-remarkable.html|title=Jean Bartik: the untold story of a remarkable ENIAC programmer|last=Kleiman|first=Kathy|website=Official Google Blog|access-date=2016-06-27}}&lt;/ref&gt;
* [[IEEE Computer Pioneer Award]], [[IEEE Computer Society]] (2008)&lt;ref name="award"&gt;{{cite web|url=https://www.computer.org/web/awards/pioneer-betty-jean-bartik|title=Betty Jean Jennings Bartik|publisher=IEEE Computer Society|work=IEEE Computer Society Awards|accessdate=22 April 2014}}&lt;/ref&gt; 
* Korenman Award from the Multinational Center for Development of Women in Technology (2009)&lt;ref name=":1" /&gt;&lt;ref name="award" /&gt;
The Jean Jennings Bartik Computing Museum at [[Northwest Missouri State University]] in [[Maryville, Missouri]] is dedicated to the history of computing and Bartik's career.&lt;ref&gt;{{Cite web|url=http://www.nwmissouri.edu/archives/computing/index.htm|title=Jean Jennings Bartik Computing Museum {{!}} Special Collections &amp; Archives {{!}} Northwest|last=University|first=Northwest Missouri State|website=www.nwmissouri.edu|access-date=2016-06-27}}&lt;/ref&gt;

Content-management framework [[Drupal]]'s default theme, ''Bartik,'' is named in honor of her.&lt;ref&gt;{{Cite web|title = Bartik {{!}} Drupal.org|url = https://www.drupal.org/project/bartik|website = www.drupal.org|accessdate = 2015-11-16}}&lt;/ref&gt;

==See also==
* [[Adele Goldstine]]
* [[Betty Holberton]]
* [[Frances Spence]]
* [[Ruth Teitelbaum]]
* [[Marlyn Wescoff]]
* [[Kathleen McNulty]]
* [[List of pioneers in computer science]]
* [[Timeline of women in science]]

==References==
{{Reflist}}

*[Pioneer Programmer:  Jean Jennings Bartik and the Computer that Changed the World", Jean Jennings Bartik autobiography, edited by Dr. Jon Rickman and Kim D. Todd, Truman State Press, 2013.]
*[Jean Jennings Bartik:  Computer Pioneer, Kim D. Todd, 2015, Notable Missourians, Truman State Press.]
*[Computer Scientist Jean Barik (STEM Trailblazer Bios), 2016, Lerner Classroom.]
*[The Innovators:  How a Group of Hackers, Geniuses, and Geeks Created the Digital Revolution, Walter Isaacson, 2015, Simon &amp; Schuster.]
*[ENIAC in Action: Making and Remaking the Modern Computer (History of Computing), Thomas Haigh, Mark Priestly and Crispin Rope, 2018, The MIT Pres.]

==External links==
{{external media
|video1=[https://www.youtube.com/watch?v=aPweFhhXFvY Jean Bartik and the ENIAC Women], "Computer History Museum", November 10, 2010
|video2= [https://www.youtube.com/watch?v=buAYHonF968 Jean Jennings Bartik - ENIAC Pioneer], ''Computer History Museum'', October 22, 2008}}
* [http://www.eniacprogrammers.org/ ENIAC Programmers documentary] 
* [http://purl.umn.edu/104288 Oral history from Bartik at the UNIVAC conference], [[Charles Babbage Institute]]
* [http://www.nwmissouri.edu/archives/computing/index.htm Jean Jennings Bartik Computing Museum at NWMSU]
* [https://www.youtube.com/watch?v=82EifuJ7O8U Bartik receives the Computer Pioneer Award]
* [http://archive.computerhistory.org/resources/text/Oral_History/Bartik_Jean/102658322.05.01.acc.pdf Oral history given by Bartik to the Computer History Museum in 2008]

{{Timelines of computing}}
{{Authority control}}

{{DEFAULTSORT:Bartik, Jean}}
[[Category:1924 births]]
[[Category:2011 deaths]]
[[Category:People from Gentry County, Missouri]]
[[Category:Disease-related deaths in New York (state)]]
[[Category:American computer programmers]]
[[Category:University of Pennsylvania alumni]]
[[Category:Northwest Missouri State University alumni]]
[[Category:Women computer scientists]]
[[Category:Women mathematicians]]
[[Category:20th-century women scientists]]
[[Category:American real estate brokers]]</text>
      <sha1>ndsv91oc5mc5qamggh1a6645qsj4tzr</sha1>
    </revision>
  </page>
  <page>
    <title>Kahan summation algorithm</title>
    <ns>0</ns>
    <id>373216</id>
    <revision>
      <id>865046110</id>
      <parentid>864811230</parentid>
      <timestamp>2018-10-21T10:05:57Z</timestamp>
      <contributor>
        <username>NickyMcLean</username>
        <id>433669</id>
      </contributor>
      <comment>Undid revision 864811230 by [[Special:Contributions/Summentier|Summentier]] ([[User talk:Summentier|talk]])  Writing "for term in terms" really doesn't help.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20841">In [[numerical analysis]], the '''Kahan summation algorithm''' (also known as '''compensated summation'''&lt;ref&gt;Strictly, there exist other variants of compensated summation as well: see {{cite book|first=Nicholas | last=Higham |title=Accuracy and Stability of Numerical Algorithms (2 ed)| publisher=SIAM|year=2002 | pages=110–123 | isbn=0-89871-521-0}}&lt;/ref&gt;) significantly reduces the [[numerical error]] in the total obtained by adding a [[sequence]] of finite [[decimal precision|precision]] [[floating point number]]s, compared to the obvious approach. This is done by keeping a separate ''running compensation'' (a variable to accumulate small errors).

In particular, simply summing ''n'' numbers in sequence has a worst-case error that grows proportional to ''n'', and a [[root mean square]] error that grows as &lt;math&gt;\sqrt{n}&lt;/math&gt; for random inputs (the roundoff errors form a [[random walk]]).&lt;ref name=Higham93&gt;{{Citation | title=The accuracy of floating point summation | first1=Nicholas J. | last1=Higham | journal=[[SIAM Journal on Scientific Computing]] |
volume=14 | issue=4 | pages=783–799 | doi=10.1137/0914050 | year=1993 | citeseerx=10.1.1.43.3535 | url=https://pdfs.semanticscholar.org/5c17/9d447a27c40a54b2bf8b1b2d6819e63c1a69.pdf
}}&lt;/ref&gt;  With compensated summation, the worst-case [[error bound]] is independent of ''n'', so a large number of values can be summed with an error that only depends on the floating-point [[precision (arithmetic)|precision]].&lt;ref name=Higham93/&gt;

The [[algorithm]] is attributed to [[William Kahan]].&lt;ref name="kahan65"&gt;{{Citation|last=Kahan|first=William|title=Further remarks on reducing truncation errors|date=January 1965|url=http://mgnet.org/~douglas/Classes/na-sc/notes/kahan.pdf|journal=[[Communications of the ACM]]|volume=8|issue=1|page=40|pages=|archive-url=https://web.archive.org/web/20180209003010/http://mgnet.org/~douglas/Classes/na-sc/notes/kahan.pdf|doi=10.1145/363707.363723|archive-date=9 February 2018}}
&lt;/ref&gt; Similar, earlier techniques are, for example, [[Bresenham's line algorithm]], keeping track of the accumulated error in integer operations (although first documented around the same time&lt;ref&gt;{{cite journal |first=Jack E. |last=Bresenham |url=http://www.research.ibm.com/journal/sj/041/ibmsjIVRIC.pdf |title=Algorithm for computer control of a digital plotter |journal=IBM Systems Journal |volume=4 |issue=1 |date=January 1965 |pages=25–30}}&lt;/ref&gt;) and the [[delta-sigma modulation]]&lt;ref&gt;{{cite journal |first1=H. |last1=Inose |first2=Y. |last2=Yasuda |first3=J. |last3=Murakami |title=A Telemetering System by Code Manipulation – ΔΣ Modulation |journal=IRE Trans. on Space Electronics and Telemetry |date=September 1962 |pages=204–209}}&lt;/ref&gt; (integrating, not just summing the error).

==The algorithm==
In [[pseudocode]], the algorithm is:

 '''function''' KahanSum(input)
     '''var''' sum = 0.0
     '''var''' c = 0.0                 // A running compensation for lost low-order bits.
     '''for''' i = 1 '''to''' input.length '''do'''
         '''var''' y = input[i] - c    // So far, so good: ''c'' is zero.
         '''var''' t = sum + y         // Alas, ''sum'' is big, ''y'' small, so low-order digits of ''y'' are lost.
         c = (t - sum) - y       // ''(t - sum)'' cancels the high-order part of ''y''; subtracting ''y'' recovers negative (low part of ''y'')
         sum = t                 // Algebraically, ''c'' should always be zero. Beware overly-aggressive optimizing compilers!
     '''next''' i                      // Next time around, the lost low part will be added to ''y'' in a fresh attempt.
     '''return''' sum

===Worked example===
This example will be given in decimal. Computers typically use binary arithmetic, but the principle being illustrated is the same. Suppose we are using six-digit decimal floating point arithmetic, ''sum'' has attained the value 10000.0, and the next two values of ''input(i)'' are 3.14159 and 2.71828. The exact result is 10005.85987, which rounds to 10005.9. With a plain summation, each incoming value would be aligned with ''sum'' and many low order digits lost (by truncation or rounding). The first result, after rounding, would be 10003.1. The second result would be 10005.81828 before rounding, and 10005.8 after rounding. This is not correct.

However, with compensated summation, we get the correct rounded result of 10005.9.

Assume that ''c'' has the initial value zero.
   y = 3.14159 - 0                   ''y = input[i] - c''
   t = 10000.0 + 3.14159
     = 10003.14159                   But only six digits are retained.
     = 10003.1                       Many digits have been lost!
   c = (10003.1 - 10000.0) - 3.14159 This '''must''' be evaluated as written! 
     = 3.10000 - 3.14159             The assimilated part of ''y'' recovered, vs. the original full ''y''.
     = -.0415900                     Trailing zeros shown because this is six-digit arithmetic.
 sum = 10003.1                       Thus, few digits from ''input(i'') met those of ''sum''.

The sum is so large that only the high-order digits of the input numbers are being accumulated. But on the next step, ''c'' gives the error.
   y = 2.71828 - -.0415900           The shortfall from the previous stage gets included.
     = 2.75987                       It is of a size similar to ''y'': most digits meet.
   t = 10003.1 + 2.75987             But few meet the digits of ''sum''.
     = 10005.85987                   And the result is rounded
     = 10005.9                       To six digits.
   c = (10005.9 - 10003.1) - 2.75987 This extracts whatever went in.
     = 2.80000 - 2.75987             In this case, too much.
     = .040130                       But no matter, the excess would be subtracted off next time.
 sum = 10005.9                       Exact result is 10005.85987, this is correctly rounded to 6 digits.

So the summation is performed with two accumulators: ''sum'' holds the sum, and ''c'' accumulates the parts not assimilated into ''sum'', to nudge the low-order part of ''sum'' the next time around. Thus the summation proceeds with "guard digits" in ''c'' which is better than not having any but is not as good as performing the calculations with double the precision of the input. However, simply increasing the precision of the calculations is not practical in general; if ''input'' is already double precision, few systems supply [[quadruple precision]] and if they did,  ''input'' could then be quadruple precision.

==Accuracy==
A careful analysis of the errors in compensated summation is needed to appreciate its accuracy characteristics.  While it is more accurate than naive summation, it can still give large relative errors for ill-conditioned sums.

Suppose that one is summing ''n'' values ''x''&lt;sub&gt;''i''&lt;/sub&gt;, for ''i''=1,...,''n''.  The exact sum is:
:&lt;math&gt;S_n=\sum_{i=1}^n x_i&lt;/math&gt; (computed with infinite precision)
With compensated summation, one instead obtains &lt;math&gt;S_n+E_n&lt;/math&gt;, where the error &lt;math&gt;E_n&lt;/math&gt; is bounded by:&lt;ref name=Higham93/&gt;
:&lt;math&gt;|E_n|\le\left[2\varepsilon + O(n\varepsilon^2)\right]\sum_{i=1}^n |x_i|&lt;/math&gt;
where ε is the [[machine precision]] of the arithmetic being employed (e.g. ε≈10&lt;sup&gt;&amp;minus;16&lt;/sup&gt; for IEEE standard [[double precision]] floating point).  Usually, the quantity of interest is the [[relative error]] &lt;math&gt;|E_n|/|S_n|&lt;/math&gt;, which is therefore bounded above by:
:&lt;math&gt;\frac{|E_n|}{|S_n|}\le\left[2\varepsilon + O(n\varepsilon^2)\right] \frac{\sum\limits_{i=1}^n |x_i|}{\left|\sum\limits_{i=1}^n x_i\right|}. &lt;/math&gt;

In the expression for the relative error bound, the fraction Σ|''x&lt;sub&gt;i&lt;/sub&gt;''|/|Σ''x&lt;sub&gt;i&lt;/sub&gt;''| is the [[condition number]] of the summation problem.  Essentially, the condition number represents the ''intrinsic'' sensitivity of the summation problem to errors, regardless of how it is computed.&lt;ref&gt;{{cite book |first1=Lloyd N. |authorlink1=Lloyd N. Trefethen |last1=Trefethen |first2=David |last2=Bau |title=Numerical Linear Algebra |publisher=SIAM |location=Philadelphia, |year=1997 |isbn=0-89871-361-7}}&lt;/ref&gt;  The relative error bound of ''every'' ([[backwards stable]]) summation method by a fixed algorithm in fixed precision (i.e. not those that use [[arbitrary precision]] arithmetic, nor algorithms whose memory and time requirements change based on the data), is proportional to this condition number.&lt;ref name=Higham93/&gt;  An ''ill-conditioned'' summation problem is one in which this ratio is large, and in this case even compensated summation can have a large relative error.  For example, if the summands ''x&lt;sub&gt;i&lt;/sub&gt;'' are uncorrelated random numbers with zero mean, the sum is a [[random walk]] and the condition number will grow proportional to &lt;math&gt;\sqrt{n}&lt;/math&gt;.  On the other hand, for random inputs with nonzero mean the condition number asymptotes to a finite constant as &lt;math&gt;n\to\infty&lt;/math&gt;.  If the inputs are all [[non-negative]], then the condition number is 1.

Given a condition number, the relative error of compensated summation is effectively independent of ''n''.  In principle, there is the O(''n''ε&lt;sup&gt;2&lt;/sup&gt;) that grows linearly with ''n'', but in practice this term is effectively zero: since the final result is rounded to a precision ε, the ''n''ε&lt;sup&gt;2&lt;/sup&gt; term rounds to zero unless ''n'' is roughly 1/ε or larger.&lt;ref name=Higham93/&gt;  In double precision, this corresponds to an ''n'' of roughly 10&lt;sup&gt;16&lt;/sup&gt;, much larger than most sums.  So, for a fixed condition number, the errors of compensated summation are effectively ''O''(ε), independent of ''n''.

In comparison, the relative error bound for naive summation (simply adding the numbers in sequence, rounding at each step) grows as &lt;math&gt;O(\varepsilon n)&lt;/math&gt; multiplied by the condition number.&lt;ref name=Higham93/&gt;  This worst-case error is rarely observed in practice, however, because it only occurs if the rounding errors are all in the same direction. In practice, it is much more likely that the rounding errors have a random sign, with zero mean, so that they form a random walk; in this case, naive summation has a [[root mean square]] relative error that grows as &lt;math&gt;O(\varepsilon \sqrt{n})&lt;/math&gt; multiplied by the condition number.&lt;ref name=Tasche&gt;Manfred Tasche and Hansmartin Zeuner ''Handbook of Analytic-Computational Methods in Applied Mathematics'' Boca Raton, FL: CRC Press, 2000).&lt;/ref&gt;  This is still much worse than compensated summation, however.  Note, however, that if the sum can be performed in twice the precision, then ε is replaced by ε&lt;sup&gt;2&lt;/sup&gt; and naive summation has a worst-case error comparable to the O(''n''ε&lt;sup&gt;2&lt;/sup&gt;) term in compensated summation at the original precision.

By the same token, the Σ|''x&lt;sub&gt;i&lt;/sub&gt;''| that appears in &lt;math&gt;E_n&lt;/math&gt; above is a worst-case bound that occurs only if all the rounding errors have the same sign (and are of maximum possible magnitude).&lt;ref name=Higham93/&gt;  In practice, it is more likely that the errors have random sign, in which case terms in Σ|''x&lt;sub&gt;i&lt;/sub&gt;''| are replaced by a random walk&amp;mdash;in this case, even for random inputs with zero mean, the error &lt;math&gt;E_n&lt;/math&gt; grows only as &lt;math&gt;O(\varepsilon \sqrt{n})&lt;/math&gt; (ignoring the ''n''ε&lt;sup&gt;2&lt;/sup&gt; term), the same rate the sum &lt;math&gt;S_n&lt;/math&gt; grows, canceling the &lt;math&gt;\sqrt{n}&lt;/math&gt; factors when the relative error is computed.  So, even for asymptotically ill-conditioned sums, the relative error for compensated summation can often be much smaller than a worst-case analysis might suggest.

==Further enhancements==
Neumaier&lt;ref name=Neumaier74&gt;{{cite journal |first=A. |last=Neumaier |doi=10.1002/zamm.19740540106 |title=Rundungsfehleranalyse einiger Verfahren zur Summation endlicher Summen |trans-title=Rounding Error Analysis of Some Methods for Summing Finite Sums |language=de |journal=Zeitschrift für Angewandte Mathematik und Mechanik |volume=54 |issue=1 |date=1974 |pages=39–51 |url=http://www.mat.univie.ac.at/~neum/scan/01.pdf}}&lt;/ref&gt;  introduced a slight modification of Kahan's algorithm that also covers the case when the next term to be added is larger in absolute value than the running sum, effectively swapping the role of what is large and what is small. In [[pseudocode]], the algorithm is:
 
  '''function''' NeumaierSum(input)
     '''var''' sum = input[1]
     '''var''' c = 0.0                 // A running compensation for lost low-order bits.
     '''for''' i = 2 '''to''' input.length '''do'''
         '''var''' t = sum + input[i]
         '''if''' |sum| &gt;= |input[i]| '''do'''
             c += (sum - t) + input[i] // If ''sum'' is bigger, low-order digits of ''input[i]'' are lost.
         '''else'''
             c += (input[i] - t) + sum // Else low-order digits of ''sum'' are lost
         sum = t
     '''return''' sum + c              // Correction only applied once in the very end

For many sequences of numbers, both algorithms agree but a simple example due to Peters&lt;ref name="python_fsum" /&gt; shows how they can differ. For summing &lt;math&gt;[1.0, +10^{100}, 1.0, -10^{100}]&lt;/math&gt; in double precision, Kahan's algorithm yields 0.0 whereas Neumaier's algorithm yields the correct value 2.0.

==Alternatives==
Although Kahan's algorithm achieves &lt;math&gt;O(1)&lt;/math&gt; error growth for summing ''n'' numbers, only slightly worse &lt;math&gt;O(\log n)&lt;/math&gt; growth can be achieved by [[pairwise summation]]: one [[recursively]] divides the set of numbers into two halves, sums each half, and then adds the two sums.&lt;ref name=Higham93/&gt;  This has the advantage of requiring the same number of arithmetic operations as the naive summation (unlike Kahan's algorithm, which requires four times the arithmetic and has a latency of four times a simple summation) and can be calculated in parallel.  The base case of the recursion could in principle be the sum of only one (or zero) numbers, but to [[amortize]] the overhead of recursion one would normally use a larger base case.  The equivalent of pairwise summation is used in many [[fast Fourier transform]] (FFT) algorithms, and is responsible for the logarithmic growth of roundoff errors in those FFTs.&lt;ref&gt;S. G. Johnson and M. Frigo, "[http://cnx.org/content/m16336/latest/ Implementing FFTs in practice], in ''[http://cnx.org/content/col10550/ Fast Fourier Transforms]'', edited by [[C. Sidney Burrus]](2008).&lt;/ref&gt; In practice, with roundoff errors of random signs, the root mean square errors of pairwise summation actually grow as &lt;math&gt;O(\sqrt{\log n})&lt;/math&gt;.&lt;ref name=Tasche/&gt;

Another alternative is to use [[arbitrary precision arithmetic]], which in principle need no rounding at all with a cost of much greater computational effort.  A way of performing exactly rounded sums using arbitrary precision is to extend adaptively using multiple floating-point components. This will minimize computational cost in common cases where high precision is not needed.&lt;ref&gt;Jonathan R. Shewchuk, [http://www.cs.berkeley.edu/~jrs/papers/robustr.pdf Adaptive Precision Floating-Point Arithmetic and Fast Robust Geometric Predicates], ''Discrete and Computational Geometry'', vol. 18, pp. 305–363 (October 1997).&lt;/ref&gt;&lt;ref name="python_fsum"&gt;Raymond Hettinger, [http://code.activestate.com/recipes/393090/ Recipe 393090: Binary floating point summation accurate to full precision], Python implementation of algorithm from Shewchuk (1997) paper (28 March 2005).&lt;/ref&gt;  Another method that uses only integer arithmetic, but a large accumulator was described by Kirchner and Kulisch;&lt;ref&gt;R. Kirchner, U. W. Kulisch, ''Accurate arithmetic for vector processors'', Journal of Parallel and Distributed Computing 5 (1988) 250-270&lt;/ref&gt; a hardware implementation was described by Müller, Rüb and Rülling.&lt;ref&gt;M. Muller, C. Rub, W. Rulling [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=145535&amp;isnumber=3902], ''Exact accumulation of floating-point numbers'', Proceedings [[10th IEEE Symposium on Computer Arithmetic]] (Jun 1991), doi 10.1109/ARITH.1991.145535&lt;/ref&gt;

==Possible invalidation by compiler optimization==
In principle, a sufficiently aggressive [[Compiler optimization|optimizing compiler]] could destroy the effectiveness of Kahan summation: for example, if the compiler simplified expressions according to the [[associativity]] rules of real arithmetic, it might "simplify" the second step in the sequence &lt;code&gt;t = sum + y; c = (t - sum) - y;&lt;/code&gt; to &lt;code&gt;((sum + y) - sum) - y;&lt;/code&gt; then to &lt;code&gt;c = 0;&lt;/code&gt;, eliminating the error compensation.&lt;ref name=Goldberg91&gt;{{Citation | title=What every computer scientist should know about floating-point arithmetic |first1=David | last1=Goldberg |
journal=[[ACM Computing Surveys]] | volume=23 | issue=1 | pages=5–48 | date=March 1991 |
doi=10.1145/103162.103163 | url=http://www.validlab.com/goldberg/paper.pdf |format=PDF}}&lt;/ref&gt;  In practice, many compilers do not use associativity rules (which are only approximate in floating-point arithmetic) in simplifications unless explicitly directed to do so by compiler options enabling "unsafe" optimizations,&lt;ref&gt;[[GNU Compiler Collection]] manual, version 4.4.3: [https://gcc.gnu.org/onlinedocs/gcc-4.4.3/gcc/Optimize-Options.html 3.10 Options That Control Optimization], ''-fassociative-math'' (Jan. 21, 2010).&lt;/ref&gt;&lt;ref&gt;''[http://h21007.www2.hp.com/portal/download/files/unprot/Fortran/docs/unix-um/dfumperf.htm Compaq Fortran User Manual for Tru64 UNIX and Linux Alpha Systems]'', section 5.9.7 Arithmetic Reordering Optimizations (retrieved March 2010).&lt;/ref&gt;&lt;ref&gt;Börje Lindh, [http://www.sun.com/blueprints/0302/optimize.pdf Application Performance Optimization], ''Sun BluePrints OnLine'' (March 2002).&lt;/ref&gt;&lt;ref&gt;Eric Fleegal, "[http://msdn.microsoft.com/en-us/library/aa289157%28VS.71%29.aspx Microsoft Visual C++ Floating-Point Optimization]", ''Microsoft Visual Studio Technical Articles''  (June 2004).&lt;/ref&gt; although the [[Intel C++ Compiler]] is one example that allows associativity-based transformations by default.&lt;ref&gt;Martyn J. Corden, "[http://software.intel.com/en-us/articles/consistency-of-floating-point-results-using-the-intel-compiler/ Consistency of floating-point results using the Intel compiler]," ''Intel technical report'' (Sep. 18, 2009).&lt;/ref&gt;  The original [[K&amp;R C]] version of the [[C programming language]] allowed the compiler to re-order floating-point expressions according to real-arithmetic associativity rules, but the subsequent [[ANSI C]] standard prohibited re-ordering in order to make C better suited for numerical applications (and more similar to [[Fortran]], which also prohibits re-ordering),&lt;ref&gt;{{cite journal |first=Tom |last=MacDonald |title=C for Numerical Computing |journal=Journal of Supercomputing |volume=5 |issue=1 |pages=31–48 |year=1991 |doi=10.1007/BF00155856}}&lt;/ref&gt; although in practice compiler options can re-enable re-ordering as mentioned above.

==Support by libraries==
In general, built-in "sum" functions in computer languages typically provide no guarantees that a particular summation algorithm will be employed, much less Kahan summation.{{Citation needed|date=February 2010}}  The [[BLAS]] standard for [[linear algebra]] subroutines explicitly avoids mandating any particular computational order of operations for performance reasons,&lt;ref&gt;[http://www.netlib.org/blas/blast-forum/ BLAS Technical Forum], section 2.7 (August 21, 2001), [https://web.archive.org/web/20040410160918/http://www.netlib.org/blas/blast-forum/chapter2.pdf#page=17 Archived on Wayback Machine].&lt;/ref&gt; and BLAS implementations typically do not use Kahan summation.
 
The standard library of the [[Python (programming language)|Python]] computer language specifies an [https://docs.python.org/library/math.html#math.fsum fsum] function for exactly rounded summation, using the [[Jonathan Shewchuk|Shewchuk]] algorithm&lt;ref name="python_fsum"/&gt; to track multiple partial sums.

In the [[Julia (programming language)|Julia]] language, the default implementation of the &lt;code&gt;sum&lt;/code&gt; function does [[pairwise summation]] for high accuracy with good performance,&lt;ref&gt;https://docs.julialang.org/en/stable/stdlib/collections/?highlight=sum#Base.sum &lt;/ref&gt; but the standard library also has an implementation of Neumaier's variant named &lt;code&gt;sum_kbn&lt;/code&gt; for the cases when the highest accuracy is needed.&lt;ref&gt;https://docs.julialang.org/en/stable/stdlib/arrays/?highlight=sum_kbn#Base.sum_kbn&lt;/ref&gt;

==See also==
* [[Algorithms for calculating variance]], which includes stable summation

==References==
{{reflist|30em}}

==External links==
* [http://www.ddj.com/cpp/184403224 Floating-point Summation, Dr. Dobb's Journal September, 1996]

{{DEFAULTSORT:Kahan Summation Algorithm}}
[[Category:Computer arithmetic]]
[[Category:Numerical analysis]]
[[Category:Articles with example pseudocode]]</text>
      <sha1>i93bbe2cf5t3nsnex6gcd2i07zmywjt</sha1>
    </revision>
  </page>
  <page>
    <title>List of animals featuring external asymmetry</title>
    <ns>0</ns>
    <id>34625854</id>
    <revision>
      <id>846662335</id>
      <parentid>839662024</parentid>
      <timestamp>2018-06-20T04:38:49Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 2 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9325">[[File:Anarhynchus frontalis head 1869.jpg|thumb|right|The beak of a [[wrybill]] is bent towards the right]]
This is a list of animals that markedly feature external [[asymmetry#In organisms|asymmetry]] in some form. They are exceptions to the general pattern of [[symmetry in biology]]. In particular, these animals do not exhibit [[bilateral symmetry]] which permits streamlining and is common in animals.&lt;ref name=Columbia&gt;[http://www.factmonster.com/ce6/sci/A0847482.html Symmetry, biological], cited at FactMonster.com from ''[[The Columbia Electronic Encyclopedia]]'' (2007).&lt;/ref&gt;
{{Expand list|date=April 2013}}

==Birds==
The [[crossbill]] has an unusual [[beak]] in which the upper and lower tips cross each other.&lt;ref name=nzbirds/&gt;

The [[wrybill]] is the only species of bird in the world with a beak that is bent sideways (always to the right).&lt;ref name=nzbirds&gt;[http://www.nzbirds.com/birds/wrybill.html Ngutuparore, the wrybill]. Narena Olliver, New Zealand Birds Limited. Retrieved 8 February 2012.&lt;/ref&gt;

Many [[owl]] species, such as the [[barn owl]], have asymmetrically positioned ears that enhance sound positioning.

==Fish==
[[File:Dorsal view of right-bending and left-bending mouth morphs of the cichlid Perissodus microlepis - journal.pone.0044670.g001.png|200px|thumb|Fish: Dorsal view of right-bending (left) and left-bending (right) jaw morphs&lt;ref name=Lee2012 /&gt;]]
Many flatfish, such as [[flounder]]s, have eyes placed asymmetrically in the adult fish. The fish has the usual symmetrical body structure when it is young, but as it matures and moves to living close to the sea bed, the fish lies on its side, and the head twists so that both eyes are on the top.&lt;ref&gt;[http://www.dfo-mpo.gc.ca/science/publications/uww-msm/articles/plaice-plie-eng.htm American Plaice], Canadian Fisheries. Retrieved 8 February 2012.&lt;/ref&gt;

The [[Fish jaw|jaws]] of the scale-eating [[cichlid]] ''[[Perissodus microlepis]]'' occur in two distinct [[Morphology (biology)|morphological]] forms. One morph has its jaw twisted to the left, allowing it to eat scales more readily on its victim’s right flank. The other morph has its jaw twisted to the right, which makes it easier to eat scales on its victim’s left flank. The relative abundance of the two morphs in populations is regulated by [[frequency-dependent selection]].&lt;ref name=Lee2012&gt;{{cite journal | last1 = Lee | first1 = H. J. | last2 = Kusche | first2 = H. | last3 = Meyer | first3 = A. | date = 2012 | title = Handed Foraging Behavior in Scale-Eating Cichlid Fish: Its Potential Role in Shaping Morphological Asymmetry | journal = PLoS ONE | volume = 7 | issue = 9| page = e44670 | doi = 10.1371/journal.pone.0044670 | pmid=22970282 | pmc=3435272| bibcode = 2012PLoSO...744670L }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last = Hori | first = M. | date = 1993 | url = http://www.sciencemag.org/cgi/content/abstract/260/5105/216 | title = Frequency-dependent natural selection in the handedness of scale-eating cichlid fish | journal = [[Science (journal)|Science]] | volume = 260 | pages = 216–219 | doi=10.1126/science.260.5105.216| bibcode = 1993Sci...260..216H }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Stewart | first1 = T. A. | last2 = Albertson | first2 = R. C. | date = 2010 | title = Evolution of a unique predatory feeding apparatus: functional anatomy, development and a genetic locus for jaw laterality in Lake Tanganyika scale-eating cichlids | url = http://www.biomedcentral.com/1741-7007/8/8 | journal = BMC Biology | volume = 8 | issue = 1| page = 8 | doi = 10.1186/1741-7007-8-8 }}&lt;/ref&gt;

==Mammals==
The [[narwhal]] has a [[helix|helical]] tusk on its upper left jaw.  ''[[Odobenocetops]]'', an extinct toothed whale, may have possessed similar asymmetrical dentition, though it differed from the narwhal in possessing two erupted, rear-facing tusks with the right significantly longer than the left.

The [[sperm whale]](''Physeter macrocephalus'') has a single [[nostril]] on its upper left head. The right nostril forms a phonic lip. The source of the air forced through the phonic lips is the right nasal passage. While the left nasal passage opens to the blow hole, the right nasal passage has evolved to supply air to the phonic lips. It is thought that the nostrils of the land-based ancestor of the sperm whale migrated through evolution to their current functions, the left nostril becoming the blowhole and the right nostril becoming the phonic lips.

The [[fin whale]] (''Balaenoptera physalus'') has complex and asymmetrical coloration on its head. 

[[Honey badger]]s of the subspecies ''signata'' have a second lower molar on the left side of their jaws, but not the right.&lt;ref name="r114"&gt;{{Harvnb|Rosevear|1974|pp=114–16}}&lt;/ref&gt;

==Reptiles==
[[File:Skull of Pareas iwasakii.jpg|thumb|right|Skull of ''Pareas iwasakii'']]
[[Iwasaki's snail-eater]] snake (''Pareas iwasakii'') is a snail-eating specialist; even newly hatched individuals feed on snails. It has asymmetric jaws, which facilitates feeding on snails with dextral (clockwise coiled) shells. A consequence of this asymmetry is that this snake is much less adept at preying on sinistral (counterclockwise coiled) snails.

==Non-avian dinosaurs==
[[Stegosaurus| ''Stegosaurus stenops'' ]] had two ''staggered'' rows of plates on its back, thus defying mirror symmetry.&lt;ref name="Cameron"&gt;{{Cite arxiv|last=Cameron|first=Robert P.|last2=Cameron|first2=John A.|last3=Barnett|first3=Stephen M.|date=2015-08-15|title=Were there two forms of Stegosaurus? |eprint=1508.03729|class=q-bio.PE}}&lt;/ref&gt;&lt;ref name="arxiv.org"&gt;{{Cite arxiv|last=Cameron|first=R. P.|last2=Cameron|first2=J. A.|last3=Barnett|first3=S. M.|date=2016-11-26|title=Stegosaurus chirality |eprint=1611.08760|class=q-bio.PE}}&lt;/ref&gt;

==Invertebrates==
[[Fiddler crab]]s and [[hermit crab]]s have one claw much larger than the other. If a male fiddler loses its large claw, it will grow another on the opposite side after [[moulting]]. A soft abdomen is also present in a hermit crab as an asymmetrical modification.

All [[gastropod]]s are asymmetrical.  This is easily seen in [[snail]]s and [[sea snail]]s, which have helical shells. At first glance [[slug]]s appear externally symmetrical, but their [[pneumostome]] (breathing hole) is always on the right side. The origin of asymmetry in gastropods is a subject of scientific debate.&lt;ref name="gastropod development"&gt;{{cite journal|author=Louise R. Page |title=Modern insights on gastropod development: Reevaluation of the evolution of a novel body plan |journal=Integrative and Comparative Biology |year=2006 |volume=46 |issue=2 |url=http://intl-icb.oxfordjournals.org/cgi/content/full/46/2/134 |pages=134–143 |doi=10.1093/icb/icj018 |pmid=21672730 |accessdate=8 February 2012 |deadurl=yes |archiveurl=https://web.archive.org/web/20090412204751/http://intl-icb.oxfordjournals.org/cgi/content/full/46/2/134 |archivedate=12 April 2009 |df= }}&lt;/ref&gt; Other gastropods develop external asymmetry, such as ''[[Glaucus atlanticus]]'' that develops asymmetrical [[cerata]] as they mature.

''[[Histioteuthis]]'' is a genus of [[squid]], commonly known as the cock-eyed squid, because in all species the right eye is normal-sized, round, blue and sunken; whereas the left eye is at least twice the diameter of the right eye, tubular, yellow-green, faces upward, and bulges out of the head.

[[Sessility (zoology)|Sessile]] animals such as [[sponge]]s are asymmetrical.&lt;ref name=Columbia/&gt;

[[Coral]]s build [[Colony (biology)|colonies]] that are not symmetrical, but the individual [[polyp]]s exhibit [[radial symmetry]].

[[Alpheidae]] feature asymmetrical claws that lack pincers, the larger of which can grow on either side of the body, and if lost can develop on the opposite arm instead.

Certain [[polyopisthocotylea]]n [[monogenea]]ns are asymmetrical, as an adaptation to their attachment to the [[gill]] of their [[fish]] [[host (biology)|hosts]]. 

Certain [[parasitic]] [[copepod]]s which live inside the [[gill]] chamber of their [[fish]] [[host (biology)|hosts]] are asymmetrical.

==Gallery==
&lt;gallery&gt;
Image:Fi Kreuzschnabel m Kopf.jpg|Head of a male [[crossbill]]
Image:Bul01Birdlxxib.jpg|Side and top view of a [[wrybill]]'s beak
Image:Pseudopleuronectes americanus.jpg|A [[winter flounder]]
Image:Uca arcuata by OpenCage.jpg|A Fiddler crab
Image:Diogenes pugilator.jpg|Hermit crabs also have different sized claws
Image:Grapevinesnail 01a.jpg|A [[Roman snail]]
Image:Chicoreus palmarosae.jpg|''[[Chicoreus palmarosae]]'', a sea snail
Image:Orange slug.jpg|A [[red slug]], clearly showing the [[pneumostome]]
Image:Histioteuthis NOAA.jpg|A cock-eyed squid with the bottom eye larger than the top.
Image:Red Tube Sponge.jpg|A sponge
Image:Coral1.JPG|Coral
Protocotyle euzetmaillardi body.jpg|''Protocotyle euzetmaillardi'', a [[polyopisthocotylea]]n [[monogenea]]n
Heteromicrocotyloides megaspinosus Body.jpg|''Heteromicrocotyloides megaspinosus'', a [[polyopisthocotylea]]n [[monogenea]]n
Journal.pone.0079155.g004_Only_silhouettes_of_bodies.png|[[Silhouette]]s of bodies of 8 species of [[polyopisthocotylea]]n [[monogenea]]ns, all asymmetrical
&lt;/gallery&gt;

==See also==
*[[Symmetry in biology]]

==References==
{{reflist}}

[[Category:Lists of animals|Asymmetry]]
[[Category:Symmetry|Animals, Asymmetry]]
[[Category:Animal anatomy|Asymmetry]]</text>
      <sha1>mz98hxi05n24b1gp6574eaw9c8qfqkx</sha1>
    </revision>
  </page>
  <page>
    <title>List of continuity-related mathematical topics</title>
    <ns>0</ns>
    <id>169589</id>
    <revision>
      <id>860409011</id>
      <parentid>817732649</parentid>
      <timestamp>2018-09-20T13:51:09Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <minor/>
      <comment>minor fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1727">{{Other uses|Continuity (disambiguation){{!}}Continuity}}
In mathematics, the terms '''continuity''', '''continuous''', and '''continuum''' are used in a variety of related ways.

== Continuity of functions and measures ==

* [[Continuous function]].
* [[Absolute continuity|Absolutely continuous function]].
* [[Absolute continuity#Absolute continuity of measures|Absolute continuity of a measure with respect to another measure]].
* [[Continuous probability distribution]].  Sometimes this term is used to mean a probability distribution whose [[cumulative distribution function]] (c.d.f.) is (simply) continuous.  Sometimes it has a less inclusive meaning: a distribution whose c.d.f. is [[absolute continuity|absolutely continuous]] with respect to [[Lebesgue measure]].  This less inclusive sense is equivalent to the condition that every set whose Lebesgue measure is 0 has probability&amp;nbsp;0.

== Continuum ==

* [[Continuum (set theory)]], the [[real line]] or the corresponding cardinal number.
* [[Linear continuum]], any ordered set that shares certain properties of the real line.
* [[Continuum (topology)]], a nonempty compact connected [[metric space]] (sometimes a [[Hausdorff space]]).
* [[Continuum hypothesis]], a conjecture of Georg Cantor that there is no cardinal number between that of countably infinite sets and the cardinality of the set of all real numbers.  The latter cardinality is equal to the cardinality of the set of all subsets of a countably infinite set.
* [[Cardinality of the continuum]], a cardinal number that represents the size of the set of real numbers.

{{DEFAULTSORT:Continuity-related mathematical topics}}
[[Category:Mathematical analysis]]
[[Category:Mathematics-related lists]]</text>
      <sha1>73682phjd1n3ooddmqhogvkxkcweykq</sha1>
    </revision>
  </page>
  <page>
    <title>Lévy–Prokhorov metric</title>
    <ns>0</ns>
    <id>6789891</id>
    <revision>
      <id>769634588</id>
      <parentid>721755992</parentid>
      <timestamp>2017-03-10T19:12:26Z</timestamp>
      <contributor>
        <ip>109.98.118.210</ip>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3677">In [[mathematics]], the '''Lévy–Prokhorov metric''' (sometimes known just as the '''Prokhorov metric''') is a [[metric (mathematics)|metric]] (i.e., a definition of distance) on the collection of [[probability measure]]s on a given [[metric space]]. It is named after the French mathematician [[Paul Lévy (mathematician)|Paul Lévy]] and the Soviet mathematician [[Yuri Vasilyevich Prokhorov]]; Prokhorov introduced it in 1956 as a generalization of the earlier [[Lévy metric]].

==Definition==

Let &lt;math&gt;(M, d)&lt;/math&gt; be a [[metric space]] with its [[Borel sigma algebra]] &lt;math&gt;\mathcal{B} (M)&lt;/math&gt;. Let &lt;math&gt;\mathcal{P} (M)&lt;/math&gt; denote the collection of all [[probability measure]]s on the [[measurable space]] &lt;math&gt;(M, \mathcal{B} (M))&lt;/math&gt;.

For a [[subset]] &lt;math&gt;A \subseteq M&lt;/math&gt;, define the [[epsilon-neighborhood|ε-neighborhood]] of &lt;math&gt;A&lt;/math&gt; by
:&lt;math&gt;A^{\varepsilon} := \{ p \in M ~|~ \exists q \in A, \ d(p, q) &lt; \varepsilon \} = \bigcup_{p \in A} B_{\varepsilon} (p).&lt;/math&gt;

where &lt;math&gt;B_{\varepsilon} (p)&lt;/math&gt; is the [[open ball]] of radius &lt;math&gt;\varepsilon&lt;/math&gt; centered at &lt;math&gt;p&lt;/math&gt;.

The '''Lévy–Prokhorov metric''' &lt;math&gt;\pi : \mathcal{P} (M)^{2} \to [0, + \infty)&lt;/math&gt; is defined by setting the distance between two probability measures &lt;math&gt;\mu&lt;/math&gt; and &lt;math&gt;\nu&lt;/math&gt; to be
:&lt;math&gt;\pi (\mu, \nu) := \inf \left\{ \varepsilon &gt; 0 ~|~ \mu(A) \leq \nu (A^{\varepsilon}) + \varepsilon \ \text{and} \ \nu (A) \leq \mu (A^{\varepsilon}) + \varepsilon \ \text{for all} \ A \in \mathcal{B}(M) \right\}.&lt;/math&gt;

For probability measures clearly &lt;math&gt;\pi (\mu, \nu) \le 1&lt;/math&gt;.

Some authors omit one of the two inequalities or choose only [[open set|open]] or [[closed set|closed]] &lt;math&gt;A&lt;/math&gt;; either inequality implies the other, and &lt;math&gt;(\bar{A})^\varepsilon = A^\varepsilon&lt;/math&gt;, but restricting to open sets may change the metric so defined (if &lt;math&gt;M&lt;/math&gt; is not [[Polish_space|Polish]]).

==Properties==

* If &lt;math&gt;(M, d)&lt;/math&gt; is [[separable space|separable]], convergence of measures in the Lévy–Prokhorov metric is equivalent to [[weak convergence of measures]]. Thus, &lt;math&gt;\pi&lt;/math&gt; is a [[Metrization theorem|metrization]] of the topology of weak convergence on &lt;math&gt;\mathcal{P} (M)&lt;/math&gt;.
* The metric space &lt;math&gt;\left( \mathcal{P} (M), \pi \right)&lt;/math&gt; is [[separable space|separable]] [[if and only if]] &lt;math&gt;(M, d)&lt;/math&gt; is separable.
* If &lt;math&gt;\left( \mathcal{P} (M), \pi \right)&lt;/math&gt; is [[complete space|complete]] then &lt;math&gt;(M, d)&lt;/math&gt; is complete. If all the measures in &lt;math&gt;\mathcal{P} (M)&lt;/math&gt; have separable [[support (measure theory)|support]], then the converse implication also holds: if &lt;math&gt;(M, d)&lt;/math&gt; is complete then &lt;math&gt;\left( \mathcal{P} (M), \pi \right)&lt;/math&gt; is complete.
* If &lt;math&gt;(M, d)&lt;/math&gt; is separable and complete, a subset &lt;math&gt;\mathcal{K} \subseteq \mathcal{P} (M)&lt;/math&gt; is [[relatively compact]] if and only if its &lt;math&gt;\pi&lt;/math&gt;-closure is &lt;math&gt;\pi&lt;/math&gt;-compact.

==See also==

* [[Lévy metric]]
* [[Prokhorov's theorem]]
* [[Tightness of measures]]
* [[weak convergence of measures]]
* [[Wasserstein metric]]
* [[Radon_measure#Metric_space_structure | Radon distance]]

==References==

* {{cite book | author=Billingsley, Patrick | title=Convergence of Probability Measures | publisher=John Wiley &amp; Sons, Inc., New York | year=1999 | isbn=0-471-19745-9 | oclc=41238534}}
* {{springer|author=Zolotarev, V.M.|id=l/l058320|title=Lévy–Prokhorov metric}}

{{DEFAULTSORT:Levy-Prokhorov metric}}
[[Category:Measure theory]]
[[Category:Metric geometry]]
[[Category:Probability theory]]
[[Category:Paul Lévy (mathematician)]]</text>
      <sha1>1a4css53k31heheatdhbzsy3u0537hh</sha1>
    </revision>
  </page>
  <page>
    <title>Medical underwriting</title>
    <ns>0</ns>
    <id>6691129</id>
    <revision>
      <id>850973586</id>
      <parentid>836049299</parentid>
      <timestamp>2018-07-19T06:35:35Z</timestamp>
      <contributor>
        <ip>223.228.152.205</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17669">'''Medical underwriting''' is a [[health insurance]] term referring to the use of medical or health information in the evaluation of an applicant for coverage, typically for [[life insurance insurance|life]] or [[health insurance]]. As part of the [[underwriting]] process, an individual's health information may be used in making two decisions: whether to offer or deny coverage and what premium rate to set for the policy. The two most common methods of medical underwriting are known as moratorium underwriting, a relatively simple process, and full medical underwriting, a more indepth analysis of a client's health information.&lt;ref&gt;{{cite web|url=http://www.health401k.com/index.php/2011/12/23/medical-underwriting-health-insurance-underwriting/|title=Medical Underwriting – Health Insurance Underwriting|date=23 December 2011|publisher=Health 401k|accessdate=19 January 2012}}&lt;/ref&gt; The use of medical underwriting may be restricted by law in certain insurance markets. If allowed, the criteria used should be objective, clearly related to the likely cost of providing coverage, practical to administer, consistent with applicable law, and designed to protect the long-term viability of the insurance system.&lt;ref&gt;[http://www.actuarialstandardsboard.org/pdf/asops/asop012_101.pdf "Risk Classification (for All Practice Areas),"] Actuarial Standard of Practice No. 12, Actuarial Standards Board, December 2005&lt;/ref&gt;

It is the process in which underwriter takes the notice of the health conditions of the person who is applying for the insurance, keeping in mind certain factors like health condition, age, nature of work, and geographical zone. After looking at all the factors, underwriter suggest whether policy should be given to the person and, if so, what will be the premium.

== Health insurance ==
Underwriting is the process that a health insurer uses to weigh potential health risks in its pool of insured people against potential costs of providing coverage.

To search the medical underwriting, an insurer asks people who apply for coverage (typically people applying for individual or family coverage) about pre-existing medical conditions. In most US states, insurance companies are allowed to ask questions about a person's medical history to decide whom to offer coverage, whom to deny and if additional charges should apply to individually-purchased coverage.

While most discussions of medical underwriting in health insurance are about medical expense insurance, similar considerations apply for other forms of individually-purchased health insurance, such as disability income and longterm care insurance.&lt;ref&gt;[http://www.actuary.org/pdf/health/issue_genetic_021601.pdf "Risk Classification in Voluntary Individual Disability Income and Long-Term Care Insurance"], [[American Academy of Actuaries]], Winter 2001&lt;/ref&gt;

===Purpose===
From the insurers' point of view, medical underwriting is necessary to prevent people from purchasing health insurance coverage only when they are sick, pregnant or need medical care. [[Adverse selection]] is a system that attracts high-users and discourages low-users from participating. Proponents of underwriting believe that if given the ability to purchase coverage without regard for pre-existing medical conditions (no underwriting), people would wait to purchase health insurance until they got sick or needed medical care. Waiting to obtain health insurance coverage until one needs coverage then creates a pool of insureds with "high use," which then increases the premiums that insurance companies must charge to pay for the claims incurred. In turn, high premiums further discourage healthy people from obtaining coverage, particularly when they realize that they will be able to obtain coverage when they need medical care.

===Effects===
Proponents of medical underwriting thus argue that it ensures that individual health insurance premiums are kept as low as possible.&lt;ref name="AAA Risk"&gt;[http://www.actuary.org/pdf/health/risk.pdf "Risk Classification in Individually Purchased Voluntary Medical Expense Insurance"], [[American Academy of Actuaries]], February 1999&lt;/ref&gt; Critics of medical underwriting believe that it unfairly prevents people with relatively minor and treatable pre-existing conditions from obtaining health insurance.&lt;ref&gt;{{cite news |url=http://www.cbsnews.com/stories/2007/05/23/cbsnews_investigates/main2843007.shtml |title=The "Uninsurables" |accessdate=2007-06-27 |work=CBS News | date=2007-05-23}}&lt;/ref&gt; Diseases that can make an individual uninsurable include serious conditions, such as [[arthritis]], [[cancer]], and [[heart disease]] but also such common ailments as [[acne]], being 20 lb. over or under the ideal weight, and old sports injuries.&lt;ref&gt;{{cite web |url=http://health.usnews.com/usnews/health/articles/070820/20preconditions.b1.htm |title=The Untouchables |accessdate=2007-10-27 |last=Michelle |first=Andrews |date=2007-08-07 |work=Health |publisher=U.S. News and World Report |deadurl=yes |archiveurl=https://web.archive.org/web/20071012031902/http://health.usnews.com/usnews/health/articles/070820/20preconditions.b1.htm |archivedate=2007-10-12 |df= }}&lt;/ref&gt; An estimated 5 million of those without health insurance are considered "uninsurable" because of pre-existing conditions.&lt;ref name="Bloomberg"&gt;{{cite news |first=Aliza |last=Marcus |title=Baby Kendra's $300,000 Bill Pains Insurers, Inspires Candidates  |url=https://www.bloomberg.com/apps/news?pid=newsarchive&amp;sid=a4BEIIi_OauQ |work= |publisher=Bloomberg News |date=2008-05-07 |accessdate=2008-05-10 }}&lt;/ref&gt;

One large industry survey, from 2004, found that roughly 13% of those who applied for individual health insurance were denied coverage after undergoing medical underwriting. Declination rates increased significantly with age, rising from 5% for individuals 18 and under to just under a third for individuals to 64.&lt;ref&gt;Teresa Chovan, Hannah Yoo and Tom Wildsmith,
[http://www.ahipresearch.org/pdfs/Individual_Insurance_Survey_Report8-26-2005.pdf "Individual Health Insurance: A Comprehensive Survey of Affordability, Access, and Benefits"] {{webarchive|url=https://web.archive.org/web/20071127151140/http://www.ahipresearch.org/pdfs/Individual_Insurance_Survey_Report8-26-2005.pdf |date=2007-11-27 }}, [[America's Health Insurance Plans]], August 2005. A prior industry survey, conducted in 2002, had similar results: Thomas D. Musco and Thomas F. Wildsmith, [http://downloads.heartland.org/15320.pdf "Individual Health Insurance: Access and Affordability"], Health Insurance Association of America, October 2002.&lt;/ref&gt; The same study found that among those who received offers for coverage, 76% received offers at standard rates 22% were quoted higher rates. The frequency of increased premiums also increased with age so for applicants over 40, roughly half were affected by medical underwriting, either in the form of denial or increased premiums. The study did not address how many applicants offered coverage at higher premiums decided to decline the policy. A study conducted by the [[Commonwealth Fund]] in 2001 found that, among those 19 to 64 who sought individual health insurance during the previous three years, the majority found it expensive, and less than a third ended up purchasing insurance. However, the study did not distinguish between consumers who were quoted increased rates by medical underwriting and those who qualified for standard or preferred premiums.&lt;ref&gt;{{cite web | url=http://www.commonwealthfund.org/publications/publications_show.htm?doc_id=221522 |title= Experiences of Working-Age Adults in the Individual Insurance Market |accessdate=2007-10-27 |author1=Lisa Duchon |author2=Cathy Schoen |date=2001-12-01 |work=Issue Brief |publisher=Commonwealth Fund}}&lt;/ref&gt;

Measuring the percentage of applicants who were denied coverage does not capture any effect that occurs before an application is submitted. If individuals with serious health conditions never apply because they expect that they will be denied coverage, they will not show up in the declination rate.&lt;ref&gt;Mark V. Pauly and Len M. Nichols,"The Nongroup Health Insurance Market: Short On Facts, Long On Opinions And Policy Disputes," Health Affairs - Web Exclusive, October 23, 2002, note 27&lt;/ref&gt; Conversely, if they apply with multiple insurers in hopes of finding one that will issue them a policy, they will be overrepresented in the declination rate.&lt;ref&gt;Thomas D. Musco and Thomas F. Wildsmith, [http://downloads.heartland.org/15320.pdf "Individual Health Insurance: Access and Affordability"], Health Insurance Association of America, October 2002&lt;/ref&gt; The 2001 Commonwealth Fund study found that a majority of adults reported that it was at least somewhat difficult to find an affordable health insurance policy. Among adults over 30, the percentage reporting difficulty did not vary significantly by age. Those with health problems were somewhat more likely to report having difficulty obtaining affordable health insurance (77% versus 64% of those in good health).&lt;ref&gt;{{cite web | url=http://www.commonwealthfund.org/publications/publications_show.htm?doc_id=221522 |title= Experiences of Working-Age Adults in the Individual Insurance Market |accessdate=2007-10-27 |author1=Lisa Duchon |author2=Cathy Schoen |date=2001-12-01 |work=Issue Brief |publisher=Commonwealth Fund}}, Figure 1&lt;/ref&gt;

Some American states have made medical underwriting illegal as a prerequisite for health coverage, which means anyone who asks for health insurance and pays for it will get it. States that have outlawed medical underwriting include [[New York (state)|New York]], [[New Jersey]], [[Maine]], [[Massachusetts]], and [[Vermont]], which also have the highest premiums for individual health insurance.&lt;ref&gt;Teresa Chovan, Hannah Yoo and Tom Wildsmith, [http://www.ahipresearch.org/pdfs/Individual_Insurance_Survey_Report8-26-2005.pdf "Individual Health Insurance: a Comprehensive Survey of Affordability, Access, and Benefits"] {{webarchive|url=https://web.archive.org/web/20071127151140/http://www.ahipresearch.org/pdfs/Individual_Insurance_Survey_Report8-26-2005.pdf |date=2007-11-27 }}, see Tables 2 and 3. [[America’s Health Insurance Plans]], August 2005&lt;/ref&gt;&lt;ref&gt;Leigh Wachenheim and Hans Leida, [http://www.ahip.org/content/fileviewer.aspx?docid=20794&amp;linkid=179392 "The Impact of Guaranteed Issue and Community Rating Reforms on Individual Insurance Markets,"] report prepared by Milliman, Inc. on behalf of [[America’s Health Insurance Plans]], August 2007&lt;/ref&gt;

===Renewals===
Prior to the passage of the [[Affordable Care Act]] in 2010, health insurance was primarily regulated by the states. Some states mandated individual health insurance policies as "guaranteed renewable:" once a policy had been issued, the policyholder could keep it forever regardless of medical conditions as long as the required premiums were paid. There had been instances in which insurers increased premiums at annual renewals based on an individual's claim history or changes in their health status.&lt;ref&gt;Terhune, Chad  [https://www.wsj.com/articles/SB1018305700460249160?mod=article-outset-box "Health Insurer's Premium Practices Add to Profit Surge, Roil Customers"], The Wall Street Journal, April 9, 2002&lt;/ref&gt; That was possible when coverage was marketed to individuals by discretionary group trusts, escaping some states' rules governing the individual health insurance market.&lt;ref&gt;[http://www.familiesusa.org/assets/pdfs/Disc_brief_summary350f.pdf "The Illusion of Group Health Insurance: Discretionary Associations"], FamiliesUSA, March 2004&lt;/ref&gt;&lt;ref&gt;Terhune, Chad [https://www.wsj.com/articles/SB1018316884421632800?mod=article-outset-box "Insurers Avoid State Regulations By Selling Via Groups Elsewhere"], The Wall Street Journal, April 9, 2002&lt;/ref&gt; The insurer that was first identified by ''The Wall Street Journal'' as reunderwriting policyholders has since publicly stated it will discontinue the practice.&lt;ref&gt;[http://www.kaisernetwork.org/daily_reports/rep_index.cfm?DR_ID=12773 Health Care Marketplace | American Medical Security Group Says It Will Cease 'Reunderwriting' Practices - Kaisernetwork.org&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;&lt;ref&gt;[http://www.rvhometown.com/HTML/Health/WSJ_Reunderwriting.htm WSJ Reunderwriting&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

However, in most cases, an insurer's ability to "re-underwrite" an existing guaranteed renewable policy is limited by contract provisions and the Affordable Care Act (previously by state law). Even so, premiums fluctuated significantly for existing policies if the average health of the policyholders with a particular product deteriorated, as often happened when rising premiums drove healthier individuals (who were able to buy other policies on more favorable terms) out of the product, leaving those who were relatively less healthy.&lt;ref name="AAA Risk"/&gt; One factor that drove that is the increase in costs, as individuals who initially pass underwriting develop health problems. In general, claim costs rose significantly over the first five years that an individual health insurance policy is in force.&lt;ref&gt;Leigh Wachenheim, [http://www.soa.org/research/files/pdf/IH%20Durational%20Study_Final%201006.pdf "Variation by Duration in Individual Health Medical Insurance Claims,"] {{webarchive|url=https://web.archive.org/web/20071129091247/http://www.soa.org/research/files/pdf/IH%20Durational%20Study_Final%201006.pdf |date=2007-11-29 }} [[Society of Actuaries]], October 3, 2006. A similar occurrence had been observed in the small group health insurance market. Stephen Brink, James Modaff and Steven Sherman, [http://www.soa.org/library/research/transactions,-reports-of-mortality,-moribidity-and-experience/1990-99/1991/january/tsr919.pdf "Variation by Duration in Small Group Medical Claims], Transactions of the [Society of Actuaries], 1991-92 Reports.&lt;/ref&gt;

Several solutions were proposed for the "closed block" problem, including requiring insurers to "pre-fund" for cost increases over the lifetime of a product, providing cross-subsidies between blocks of products by pooling products across durations, providing cross-subsidies by placing limits on the allowed variation in premiums between products, or creating state-sponsored risk pools for individuals trapped in a closed block. The [[American Academy of Actuaries]] performed a study of the proposed solutions for the [[National Association of Insurance Commissioners]] and modeled the likely impact of each. All of the solutions would increase the initial cost of a new policy and reduce cost increases over time.&lt;ref&gt;[http://actuary.org/pdf/health/rate_may04.pdf "Individual health insurance: Closed block solutions"], [[American Academy of Actuaries]], May 2004&lt;/ref&gt;

===Rescissions===
Insurers have the right to cancel individually purchased insurance if the insurer finds that the applicant provided incomplete or inaccurate information on the application, thereby affecting the medical underwriting process. The practice, called [[Rescission (contract law)|rescission]], protects insurers from intentional fraud and affects only about 1% of individual policyholders but appears to be on the increase.&lt;ref&gt;Updegrave, Walter and Ashford, Kate [http://money.cnn.com/2007/02/12/magazines/moneymag/insurance_rescission.moneymag/index.htm "The neutron bomb of health insurance"] Money Magazine, February 13, 2007&lt;/ref&gt; Rescission practices by several large insurers have attracted media attention, class-action lawsuits, and regulatory attention in several states. In 2007, California passed legislation to tighten the rules governing rescissions.&lt;ref&gt;[http://www.leginfo.ca.gov/pub/07-08/bill/asm/ab_1301-1350/ab_1324_bill_20071014_chaptered.html California Legislative database: AB1324, chaptered October 14, 2007]&lt;/ref&gt;  In December 2007, a California appeals court ruled that a health insurer could not rescind coverage without showing that either the policyholder willfully misrepresented health or that the insurer had investigated the application before issuing coverage.&lt;ref&gt;Lisa Girion, [http://www.latimes.com/news/science/la-fi-rescind25dec25,1,6638779.story?ctrack=1&amp;cset=true "Court curbs insurers' ability to rescind medical policies,"] The [[Los Angeles Times]], December 25, 2007&lt;/ref&gt;

==Life insurance underwriting==
{{details|life insurance}}

A distinction between underwriting of individually purchased life insurance and the underwriting of health insurance is generally recognized in US state-specific regulation of insurance. The general legal posture is for states to view life insurance as less of a necessity than health coverage.

== Moratorium Underwriting ==
Moratorium underwriting is an alternative method of health insurance which primarily allows for applicants to receive cover without disclosing their entire medical history. Instead, individuals will typically have any pre-existing medical conditions excluded if those have developed within the past five years. If related symptoms occur within a set period of time, then this will affect the final policy.&lt;ref&gt;[https://www.generalandmedical.com/cms/private-health-insurance/moratorium-underwriting/ General &amp; Medical]&lt;/ref&gt;

Moratorium underwriting is, therefore, best suited for healthy individuals who don’t foresee any medical difficulties developing.

==See also==
* [[Body mass index]] (BMI)
* [[Rohrer's index]]

==References==
{{reflist|2}}

{{DEFAULTSORT:Medical Underwriting}}
[[Category:Health insurance in the United States]]
[[Category:Actuarial science]]
[[Category:Life insurance|Underwriting, Medical]]
[[Category:Underwriting]]</text>
      <sha1>adnu57mz3i631q5o981oyohmvwa84qf</sha1>
    </revision>
  </page>
  <page>
    <title>Michael Aschbacher</title>
    <ns>0</ns>
    <id>1652651</id>
    <revision>
      <id>846633373</id>
      <parentid>846633320</parentid>
      <timestamp>2018-06-19T23:55:15Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>added [[Category:People from Little Rock, Arkansas]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9208">{{Redirect|Aschbacher|the similar name Äschbacher|Aeschbacher}}
{{Infobox scientist  	
| name = Michael Aschbacher 	
| image = Michael Aschbacher.jpg
| image_size = 165px
| birth_date = {{Birth date and age|1944|4|8|mf=y}} 	
| birth_place = [[Little Rock, Arkansas]] 	
| residence = [[United States]] 	
| nationality = [[United States|American]]
| death_date = 	
| death_place = 	
| field = [[Mathematics]] 	
| work_institutions = [[California Institute of Technology]] 	
| alma_mater = [[California Institute of Technology]] &lt;br&gt; [[University of Wisconsin–Madison]]
| doctoral_advisor = [[Richard Hubert Bruck]]
| doctoral_students = 
| known_for = [[Group Theory]]
| prizes = [[Cole Prize]] (1980) &lt;br&gt; [[Rolf Schock Prize]] (2011) &lt;br&gt;[[Leroy P. Steele Prize]] (2012)&lt;br&gt; [[Wolf Prize in Mathematics]] (2012)
| religion =  
| footnotes = 	
}}

'''Michael George Aschbacher''' (born April 8, 1944) is an [[United States|American]] [[mathematician]] best known for his work on [[finite group]]s. He was a leading figure in the completion of the [[classification of finite simple groups]] in the 1970s and 1980s. It later turned out that the classification was incomplete, because the case of [[quasithin group]]s had not been finished. This gap was fixed by Aschbacher and Stephen D. Smith in 2004, in a pair of books comprising about 1300 pages. Aschbacher is currently the Shaler Arthur Hanisch Professor of Mathematics at the [[California Institute of Technology]].

== Education and career ==
Aschbacher received his B.S. at the [[California Institute of Technology]] in 1966 and his [[Ph.D.]] at the [[University of Wisconsin–Madison]] in 1969.&lt;ref&gt;{{MathGenealogy |id=9075}}&lt;/ref&gt; He joined the faculty of the California Institute of Technology in 1970 and became a full professor in 1976. He was a visiting scholar at the [[Institute for Advanced Study]] in 1978-79.&lt;ref&gt;[http://www.ias.edu/people/cos/frontpage?page=5 Institute for Advanced Study: A Community of Scholars] {{webarchive|url=https://web.archive.org/web/20130106144349/http://www.ias.edu/people/cos/frontpage?page=5 |date=2013-01-06 }}&lt;/ref&gt; He was awarded the [[Cole Prize]] in 1980, and was elected to the [[United States National Academy of Sciences|National Academy of Sciences]] in 1990. In 1992, Aschbacher was elected a Fellow of the [[American Academy of Arts and Sciences]].&lt;ref name=AAAS&gt;{{cite web|title=Book of Members, 1780-2010: Chapter A|url=http://www.amacad.org/publications/BookofMembers/ChapterA.pdf|publisher=American Academy of Arts and Sciences|accessdate=25 April 2011}}&lt;/ref&gt; He was awarded the [[Rolf Schock Prize]] for Mathematics by the [[Royal Swedish Academy of Sciences]] in 2011.&lt;ref&gt;[http://www.kva.se/en/pressroom/Press-releases-2011/Michael-Aschbacher-is-being-awarded-The-Rolf-Schock-Prize-in-Mathematics/ Michael Aschbacher is being awarded The Rolf Schock Prize in Mathematics],  [[Royal Swedish Academy of Sciences]] press release, March 23, 2011.&lt;/ref&gt; In 2012 he received the [[Leroy P. Steele Prize]] for Mathematical Exposition and the [[Wolf Prize in Mathematics]], and became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2012-11-03.&lt;/ref&gt;

== Classification of finite simple groups ==

In 1973, Aschbacher became a leading figure in the [[classification of finite simple groups]]. Aschbacher considered himself somewhat of an outsider in the world of conventional group theory, claiming that he was not "plugged into the system at that point in time."  &lt;ref&gt;{{cite journal| last=Steingart| first=Alma| title=A group theory of group theory|journal=Social Studies of Science|volume = 42|issue = 2|pages=197|publisher =sagepub|year=2012| doi=10.1177/0306312712436547}}&lt;/ref&gt;  
Although he had access to several preprints that were shared among the practitioners of the field, he reproduced many proofs that had already been discovered by other researchers and published them in his early papers. Aschbacher only became interested in [[finite simple groups]] as a postdoctorate. He wrote his dissertation in [[combinatorics]] and was able to utilize many techniques developed in this area to make early contributions to the study of [[finite simple groups]] which surprised the community of researchers. In particular, [[Daniel Gorenstein]], another leader of the [[classification of finite simple groups]], said that Aschbacher's entrance was "dramatic." &lt;ref&gt;{{cite journal| last=Steingart| first=Alma| title=A group theory of group theory|journal=Social Studies of Science|volume = 42|issue = 2|pages=200|publisher =sagepub|year=2012| doi=10.1177/0306312712436547}}&lt;/ref&gt;

In fact, the rate of Aschbacher's results proved so astounding that many other mathematicians decided to leave the field to pursue other problems. Aschbacher was proving one major result after another and when he announced his progress at the Duluth conference, mathematicians were convinced that the problem was almost solved. This conference represented a turning point for the problem as many mathematicians (in particular those relatively new to the field) decided to leave the field to pursue other problems.&lt;ref&gt;{{cite journal| last=Steingart| first=Alma| title=A group theory of group theory|journal=Social Studies of Science|volume = 42|issue = 2|pages=203|publisher =sagepub|year=2012| doi=10.1177/0306312712436547}}&lt;/ref&gt;

However, Aschbacher's entrance into the field did not come without difficulties. Aschbacher's papers, beginning with the first he wrote in the field for publication, were very difficult to read. Some commented that his proofs lacked explanations of very sophisticated [[counting]] arguments. As Aschbacher's proofs became longer, it became even more difficult for others to understand his proofs. Even some of his own coauthors had trouble reading their own papers. From that point on, researchers no longer read papers as independent documents, but rather ones that required the context of its author. As a result, responsibility of finding errors in the classification problem was up to the entire community of researchers rather than just peer-reviewers alone. That Aschbacher's proofs were hard to read was not due to a lack of ability, but rather to the astounding complexity of the ideas he was able to produce.&lt;ref&gt;{{cite journal| last=Steingart| first=Alma| title=A group theory of group theory|journal=Social Studies of Science|volume = 42|issue = 2|pages=201|publisher =sagepub|year=2012| doi=10.1177/0306312712436547}}&lt;/ref&gt;

== Books ==

*''Finite group theory'' {{ISBN|0-521-78675-4}}
*''Sporadic groups'' {{ISBN|0-521-42049-0}}
*''3-Transposition groups'' {{ISBN|0-521-57196-0}}
*''The finite simple groups and their classification'' {{ISBN|0-300-02449-5}}
*''Overgroups of Sylow subgroups in sporadic groups'' {{ISBN|0-8218-2344-2}}
*{{Citation | last1=Aschbacher | first1=Michael | author1-link=Michael Aschbacher | last2=Smith | first2=Stephen D. | title=The classification of quasithin groups. I Structure of Strongly Quasithin K-groups | url=http://www.ams.org/bookstore-getitem/item=SURV-111 | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=Mathematical Surveys and Monographs | isbn=978-0-8218-3410-7 | mr=2097623 | year=2004 | volume=111}}
*{{Citation | last1=Aschbacher | first1=Michael | author1-link=Michael Aschbacher | last2=Smith | first2=Stephen D. | title=The classification of quasithin groups. II Main theorems: the classification of simple QTKE-groups. | url=http://www.ams.org/bookstore-getitem/item=SURV-112 | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=Mathematical Surveys and Monographs | isbn=978-0-8218-3411-4 | mr=2097624 | year=2004b | volume=112}}
*{{citation|url=http://www.ams.org/bull/2006-43-01/S0273-0979-05-01071-2 | last=Solomon|first = Ronald|authorlink=Ronald Solomon|journal=[[Bulletin of the American Mathematical Society]]|volume= 43 |year=2006|pages= 115–121 |title= Review of The classification of quasithin groups. I, II by Aschbacher and Smith |doi=10.1090/s0273-0979-05-01071-2}}

&lt;!--
*Geometries and groups (editor) ISBN 90-277-2623-X
--&gt;

== References ==
{{Reflist}}

== External links ==
*[http://www.math.caltech.edu/people/asch.html Aschbacher's webpage at Caltech]

{{Wolf Prize in Mathematics}}
{{Schock Prize laureates}}

{{Authority control}}

{{DEFAULTSORT:Aschbacher, Michael}}
[[Category:1944 births]]
[[Category:Living people]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Group theorists]]
[[Category:California Institute of Technology alumni]]
[[Category:California Institute of Technology faculty]]
[[Category:University of Wisconsin–Madison alumni]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:Wolf Prize in Mathematics laureates]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Mathematicians from Arkansas]]
[[Category:People from Little Rock, Arkansas]]</text>
      <sha1>lx72w2etxpf4iqeqi2271dsralij8ha</sha1>
    </revision>
  </page>
  <page>
    <title>Module of covariants</title>
    <ns>0</ns>
    <id>42992981</id>
    <revision>
      <id>781279723</id>
      <parentid>753549033</parentid>
      <timestamp>2017-05-20T07:07:22Z</timestamp>
      <contributor>
        <username>John of Reading</username>
        <id>11308236</id>
      </contributor>
      <comment>/* References */Typo/[[WP:AWB/GF|general]] fixes, replaced: covarariants → covariants (surely?) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="661">In [[algebra]], given an [[algebraic group]] ''G'', a [[group representation|''G''-module]] ''M'' and a ''G''-algebra ''A'', all over a [[field (mathematics)|field]] ''k'', the '''module of covariants''' of type ''M'' is the &lt;math&gt;A^G&lt;/math&gt;-module

: &lt;math&gt;(M \otimes_k A)^G.&lt;/math&gt;

== See also ==
*[[Local cohomology]]

== References ==
* M. Brion, ''Sur les modules de covariants'', Ann. Sci. École Norm. Sup. (4) 26 (1993), 1 21.
* M. Van den Bergh, ''Modules of covariants'', Proceedings of the International Congress of Mathematicians, Vol. 1, 2 (Zurich, 1994), Birkhauser, Basel, pp.&amp;nbsp;352–362, 1995.

[[Category:Module theory]]


{{algebra-stub}}</text>
      <sha1>2gwtkgngmr0ljb8igj4igvlv0e4b1bt</sha1>
    </revision>
  </page>
  <page>
    <title>Moser–de Bruijn sequence</title>
    <ns>0</ns>
    <id>52299655</id>
    <revision>
      <id>868654463</id>
      <parentid>868630919</parentid>
      <timestamp>2018-11-13T16:21:20Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/99.203.11.193|99.203.11.193]] ([[User talk:99.203.11.193|talk]]) to last version by Gehenna1510</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15500">[[File:Moser–de Bruijn addition.svg|thumb|upright=1.35|The addition table for &lt;math&gt;x+2y&lt;/math&gt; where &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; both belong to the Moser–de Bruijn sequence, and the [[Z-order curve]] that connects the sums in numerical order]]
In [[number theory]], the '''Moser–de Bruijn sequence''' is an [[integer sequence]] named after [[Leo Moser]] and [[Nicolaas Govert de Bruijn]], consisting of the sums of distinct powers of 4. It begins
:0, 1, 4, 5, 16, 17, 20, 21, 64, 65, 68, 69, 80, 81, 84, 85, 256, ... {{OEIS|A000695}}
For instance, 69 belongs to this sequence because it equals 64 + 4 + 1, a sum of three distinct powers of 4.

==Binary and related representations==
Another definition of the Moser–de Bruijn sequence is that it is the ordered sequence of numbers whose [[binary representation]] has nonzero digits only in the even positions. For instance, 69 belongs to the sequence, because its binary representation 1000101&lt;sub&gt;2&lt;/sub&gt; has nonzero digits in the positions for 2&lt;sup&gt;6&lt;/sup&gt;, 2&lt;sup&gt;2&lt;/sup&gt;, and 2&lt;sup&gt;0&lt;/sup&gt;, all of which have even exponents. The numbers in the sequence can also be described as the numbers whose [[Quaternary numeral system|base-4 representation]] uses only the digits 0 or 1.&lt;ref name="oeis"&gt;{{Cite OEIS|A000695|name=Moser-de Bruijn sequence}}&lt;/ref&gt; For a number in this sequence, the base-4 representation can be found from the binary representation by skipping the binary digits in odd positions, which should all be zero. Another way of looking at it is that these are numbers whose [[hexadecimal]] representation contains only the digits 0, 1, 4, 5. For instance, 69 = 1011&lt;sub&gt;4&lt;/sub&gt; = 45&lt;sub&gt;16&lt;/sub&gt;.

Equivalently, they are the numbers whose binary and [[negabinary]] representations are equal.&lt;ref name="oeis"/&gt;&lt;ref name="arndt"&gt;{{citation|last=Arndt|first=Jörg|title=Matters Computational: Ideas, Algorithms, Source Code|publisher=Springer|year=2011|url=http://jjj.de/fxt/fxtbook.pdf|pages=59, 750}}.&lt;/ref&gt;

[[File:Moser–de Bruijn counts.svg|thumb|upright=1.65|Plot of the number of sequence elements up to &lt;math&gt;n&lt;/math&gt; divided by &lt;math&gt;\sqrt n&lt;/math&gt;, on a logarithmic horizontal scale]]
It follows from either the binary or base-4 definitions of these numbers that they grow roughly in proportion to the [[square number]]s. The number of elements in the Moser–de Bruijn sequence that are below any given threshold &lt;math&gt;n&lt;/math&gt; is proportional to &lt;math&gt;\sqrt n&lt;/math&gt;,&lt;ref name="golomb"/&gt;
a fact which is also true of the square numbers. In fact the numbers in the Moser–de Bruijn sequence are the squares for a version of arithmetic without [[Carry (arithmetic)|carrying]] on binary numbers, in which the addition and multiplication of single bits are respectively the [[exclusive or]] and [[logical conjunction]] operations.&lt;ref&gt;{{citation
 | last1 = Applegate | first1 = David | author1-link = David Applegate
 | last2 = LeBrun | first2 = Marc
 | last3 = Sloane | first3 = N. J. A. | author3-link = Neil Sloane
 | issue = 9
 | journal = [[Journal of Integer Sequences]]
 | mr = 2859992
 | page = Article 11.9.8, 34
 | title = Dismal arithmetic
 | url = http://emis.ams.org/journals/JIS/VOL14/Sloane/carry2.pdf
 | volume = 14
 | year = 2011| bibcode = 2011arXiv1107.1130A
 | arxiv = 1107.1130
 }}.&lt;/ref&gt;

In connection with the [[Furstenberg–Sárközy theorem]] on sequences of numbers with no square difference, [[Imre Z. Ruzsa]] found a construction for large square-difference-free sets that, like the binary definition of the Moser–de Bruijn sequence, restricts the digits in alternating positions in the base-&lt;math&gt;b&lt;/math&gt; numbers.&lt;ref&gt;{{citation
 | last = Ruzsa | first = I. Z. | authorlink = Imre Z. Ruzsa
 | doi = 10.1007/BF02454169
 | issue = 3
 | journal = Periodica Mathematica Hungarica
 | mr = 756185
 | pages = 205–209
 | title = Difference sets without squares
 | volume = 15
 | year = 1984}}.&lt;/ref&gt; When applied to the base &lt;math&gt;b=2&lt;/math&gt;, Ruzsa's construction generates the Moser–de Bruijn sequence multiplied by two, a set that is again square-difference-free. However,
this set is too sparse to provide nontrivial lower bounds for the Furstenberg–Sárközy theorem.

==Unique representation as sums==
The Moser–de Bruijn sequence obeys a property similar to that of a [[Sidon sequence]]: the sums &lt;math&gt;x+2y&lt;/math&gt;, where &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; both belong to the Moser–de Bruijn sequence, are all unique. No two of these sums have the same value. Moreover, every integer &lt;math&gt;n&lt;/math&gt; can be represented as a sum &lt;math&gt;x+2y&lt;/math&gt;, where &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; both belong to the Moser–de Bruijn sequence. To find the sum that represents &lt;math&gt;n&lt;/math&gt;, compute &lt;math&gt;x=n\ \&amp;\ \mathrm{0x55555555}&lt;/math&gt;, the [[bitwise operation|bitwise Boolean and]] of &lt;math&gt;n&lt;/math&gt; with a binary value (expressed here in [[hexadecimal]]) that has ones in all of its even positions, and set &lt;math&gt;y=(n-x)/2&lt;/math&gt;.&lt;ref name="oeis"/&gt;&lt;ref name="32bit"&gt;The constants in this formula are expressed in [[hexadecimal]] and based on a 32-bit word size. The same bit pattern should be extended or reduced in the obvious way to handle other word sizes.&lt;/ref&gt;

The Moser–de Bruijn sequence is the only sequence with this property, that all integers have a unique expression as &lt;math&gt;x+2y&lt;/math&gt;. It is for this reason that the sequence was originally studied by {{harvtxt|Moser|1962}}.&lt;ref&gt;{{citation
 | last = Moser | first = Leo | authorlink = Leo Moser
 | issue = 1
 | journal = [[Mathematics Magazine]]
 | jstor = 2689100
 | mr = 1571147
 | pages = 37–38
 | title = An application of generating series
 | volume = 35
 | year = 1962}}.&lt;/ref&gt; Extending the property, {{harvtxt|de Bruijn|1964}} found infinitely many other linear expressions like &lt;math&gt;x+2y&lt;/math&gt; that, when &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; both belong to the Moser–de Bruijn sequence, uniquely represent all integers.&lt;ref&gt;{{citation
 | last = de Bruijn | first = N. G. | authorlink = Nicolaas Govert de Bruijn
 | journal = [[Mathematics of Computation]]
 | mr = 0167447
 | pages = 537–546
 | title = Some direct decompositions of the set of integers
 | volume = 18
 | year = 1964}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last1 = Eigen | first1 = S. J.
 | last2 = Ito | first2 = Y.
 | last3 = Prasad | first3 = V. S.
 | doi = 10.1016/j.jnt.2004.04.001
 | issue = 2
 | journal = Journal of Number Theory
 | mr = 2072392
 | pages = 322–334
 | title = Universally bad integers and the 2-adics
 | volume = 107
 | year = 2004}}.&lt;/ref&gt;

==Z-order curve and successor formula==
Decomposing a number &lt;math&gt;n&lt;/math&gt; into &lt;math&gt;n=x+2y&lt;/math&gt;, and then applying to &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; an order-preserving map from the Moser–de Bruijn sequence to the integers (by replacing the powers of four in each number by the corresponding powers of two) gives a [[bijection]] from non-negative integers to [[ordered pair]]s of non-negative integers. The inverse of this bijection gives a linear ordering on the points in the plane with non-negative integer coordinates, which may be used to define the [[Z-order curve]].&lt;ref name="oeis"/&gt;&lt;ref name="morton"&gt;{{citation
 | last1 = Thiyagalingam | first1 = Jeyarajan
 | last2 = Beckmann | first2 = Olav
 | last3 = Kelly | first3 = Paul H. J.
 | date = September 2006
 | doi = 10.1002/cpe.v18:11
 | issue = 11
 | journal = Concurrency and Computation: Practice and Experience
 | pages = 1509–1539
 | title = Is Morton layout competitive for large two-dimensional arrays yet?
 | url = http://www.doc.ic.ac.uk/~ob3/Publications/CandCPEMorton2004.pdf
 | volume = 18}}.&lt;/ref&gt;

In connection with this application, it is convenient to have a formula to generate each successive element of the Moser–de Bruijn sequence from its predecessor.
This can be done as follows. If &lt;math&gt;x&lt;/math&gt; is an element of the sequence, then the next member after &lt;math&gt;x&lt;/math&gt; can be obtained by filling in the bits in odd positions of the binary representation of &lt;math&gt;x&lt;/math&gt; by ones, adding one to the result,
and then masking off the filled-in bits. Filling the bits and adding one can be combined into a single addition operation. That is, the next member is the number given by the formula
:&lt;math&gt;(x + \textrm{0xaaaaaaab})\ \&amp;\ \textrm{0x55555555}&lt;/math&gt;.&lt;ref name="oeis"/&gt;&lt;ref name="32bit"/&gt;&lt;ref name="morton"/&gt;
The two hexadecimal constants appearing in this formula can be interpreted as the [[p-adic number|2-adic numbers]] &lt;math&gt;1/3&lt;/math&gt; and &lt;math&gt;-1/3&lt;/math&gt;, respectively.&lt;ref name="oeis"/&gt;

==Subtraction game==
{{harvtxt|Golomb|1966}} investigated a game, analogous to [[subtract a square]], based on this sequence. In Golomb's game, two players take turns removing coins from a pile of &lt;math&gt;n&lt;/math&gt; coins. In each move, a player may remove any number of coins that belongs to the Moser–de Bruijn sequence. Removing any other number of coins is not allowed. The winner is the player who removes the last coin.
As Golomb observes, the "cold" positions of this game (the ones in which the player who is about to move is losing) are exactly the positions of the form &lt;math&gt;2y&lt;/math&gt; where &lt;math&gt;y&lt;/math&gt; belongs to the Moser–de Bruijn sequence. A winning strategy for playing this game is to decompose the current number of coins, &lt;math&gt;n&lt;/math&gt;, into &lt;math&gt;x+2y&lt;/math&gt; where &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; both belong to the Moser–de Bruijn sequence, and then (if &lt;math&gt;x&lt;/math&gt; is nonzero) to remove &lt;math&gt;x&lt;/math&gt; coins, leaving a cold position to the other player. If &lt;math&gt;x&lt;/math&gt; is zero, this strategy is not possible, and there is no winning move.&lt;ref name="golomb"&gt;{{citation
 | last = Golomb | first = Solomon W. | authorlink = Solomon W. Golomb
 | doi = 10.1016/S0021-9800(66)80016-9
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 0209015
 | pages = 443–458
 | title = A mathematical investigation of games of "take-away"
 | volume = 1
 | issue = 4 | year = 1966}}.&lt;/ref&gt;

==Decimal reciprocals==
The Moser–de Bruijn sequence forms the basis of an example of an [[irrational number]] &lt;math&gt;x&lt;/math&gt; with the unusual property that the decimal representations of &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;1/x&lt;/math&gt; can both be written simply and explicitly. Let &lt;math&gt;E&lt;/math&gt; denote the Moser–de Bruijn sequence itself, and &lt;math&gt;2E&lt;/math&gt; denote the numbers in this sequence multiplied by two: &lt;math&gt;\{0, 2, 8, 10, \dots\}&lt;/math&gt;. Then for
:&lt;math&gt;x = 3\sum_{e\in E} 10^{-e} = 3.300330000000000330033\dots,&lt;/math&gt;
a decimal number whose nonzero digits are in the positions given by the Moser–de Bruijn sequence, it follows that the nonzero digits of its reciprocal are in the positions given by &lt;math&gt;2E&lt;/math&gt;:
:&lt;math&gt;\frac{1}{x}=3\sum_{e\in 2E} 10^{-e-1} = 0.30300000303\dots\ .&lt;/math&gt;&lt;ref name="vdp"&gt;{{citation
 | last = van der Poorten | first = A. J. | authorlink = Alfred van der Poorten
 | contribution = Continued fractions of formal power series
 | contribution-url = http://web.williams.edu/Mathematics/sjmiller/public_html/book/papers/vdp/Poorten_ContFracsOfFormalPowerSeries.pdf
 | mr = 1368441
 | pages = 453–466
 | publisher = Oxford Univ. Press, New York
 | series = Oxford Sci. Publ.
 | title = Advances in number theory (Kingston, ON, 1991)
 | year = 1993}}.&lt;/ref&gt;&lt;ref name="bmf"&gt;{{citation
 | last1 = Blanchard | first1 = André
 | last2 = Mendès France | first2 = Michel
 | issue = 3
 | journal = Bulletin des Sciences Mathématiques
 | mr = 680277
 | pages = 325–335
 | title = Symétrie et transcendance
 | volume = 106
 | year = 1982}}. As cited by {{harvtxt|van der Poorten|1993}}.&lt;/ref&gt;

Similar examples also work in other bases. For instance, the two [[binary number]]s whose nonzero bits are in the same positions as the nonzero digits of the two decimal numbers above are also irrational reciprocals.&lt;ref&gt;{{citation
 | last1 = Bailey | first1 = David H. | author1-link = David H. Bailey
 | last2 = Borwein | first2 = Jonathan M. | author2-link = Jonathan Borwein
 | last3 = Crandall | first3 = Richard E. | author3-link = Richard Crandall
 | last4 = Pomerance | first4 = Carl | author4-link = Carl Pomerance
 | issue = 3
 | journal = Journal de Théorie des Nombres de Bordeaux
 | mr = 2144954
 | pages = 487–518
 | title = On the binary expansions of algebraic numbers
 | url = http://jtnb.cedram.org/item?id=JTNB_2004__16_3_487_0
 | volume = 16
 | year = 2004}}. See in particular the discussion following Theorem 4.2.&lt;/ref&gt; These binary and decimal numbers, and the numbers defined in the same way for any other base by repeating a single nonzero digit in the positions given by the Moser–de Bruijn sequence, are [[transcendental number]]s. Their transcendence can be proven from the fact that the long strings of zeros in their digits allow them to be [[Diophantine approximation|approximated]] more accurately by [[rational number]]s than would be allowed by [[Roth's theorem]] if they were [[algebraic number]]s.&lt;ref name="bmf"/&gt;

==Generating function==
The [[generating function]]
:&lt;math&gt;F(x)=\prod_{i=0}^{\infty}(1+x^{4^i})=1+x+x^4+x^5+x^{16}+x^{17}+\cdots,&lt;/math&gt;
whose exponents in the expanded form are given by the Moser–de Bruijn sequence,
obeys the [[functional equation]]s
:&lt;math&gt;F(x)F(x^2)=\frac{1}{1-x}&lt;/math&gt;&lt;ref name="oeis"/&gt;&lt;ref name="arndt"/&gt;
and
:&lt;math&gt;F(x)=(1+x)F(x^4).&lt;/math&gt;&lt;ref name="lmp"&gt;{{citation
 | last1 = Lehmer | first1 = D. H. | author1-link = Derrick Henry Lehmer
 | last2 = Mahler | first2 = K. | author2-link = Kurt Mahler
 | last3 = van der Poorten | first3 = A. J. | author3-link = Alfred van der Poorten
 | doi = 10.2307/2008006
 | issue = 174
 | journal = [[Mathematics of Computation]]
 | mr = 829638
 | pages = 683–689
 | title = Integers with digits 0 or 1
 | volume = 46
 | year = 1986}}.&lt;/ref&gt;
For example, this function can be used to describe the two decimal reciprocals given above: one is &lt;math&gt;3 F(1/10)&lt;/math&gt; and the other is &lt;math&gt;\tfrac{3}{10} F(1/100)&lt;/math&gt;. The fact that they are reciprocal is an instance of the first of the two functional equations.
The [[partial product]]s of the product form of the generating function can be used to generate the convergents of the [[continued fraction]] expansion of these numbers.&lt;ref name="vdp"/&gt;

==Recurrence and regularity==
The Moser–de Bruijn sequence obeys a [[recurrence relation]] that allows the {{mvar|n}}th value of the sequence, &lt;math&gt;S(n)&lt;/math&gt; (starting at &lt;math&gt;S(0)=0&lt;/math&gt;) to be determined from the value at position &lt;math&gt;\lfloor n/2\rfloor&lt;/math&gt;:
:&lt;math&gt;S(2n)=4S(n)&lt;/math&gt;
:&lt;math&gt;S(2n+1)=4S(n)+1&lt;/math&gt;
Iterating this recurrence allows any subsequence of the form &lt;math&gt;S(2^i n + j)&lt;/math&gt; to be expressed as a linear function of the original sequence, meaning that the Moser–de Bruijn sequence is a [[k-regular sequence|2-regular sequence]].&lt;ref&gt;{{citation
 | last1 = Allouche | first1 = Jean-Paul
 | last2 = Shallit | first2 = Jeffrey | author2-link = Jeffrey Shallit
 | doi = 10.1016/0304-3975(92)90001-V
 | issue = 2
 | journal = [[Theoretical Computer Science (journal)|Theoretical Computer Science]]
 | mr = 1166363
 | pages = 163–197
 | title = The ring of {{mvar|k}}-regular sequences
 | volume = 98
 | year = 1992}}. Example 13, p.&amp;nbsp;188.&lt;/ref&gt;

==See also==
*[[Cantor set]], a fractal defined similarly using base-3 representations

==Notes==
{{reflist|30em}}

==External links==
*{{mathworld|id=Moser-deBruijnSequence|title=Moser-de Bruijn Sequence}}

{{DEFAULTSORT:Moser-de Bruijn sequence}}
[[Category:Integer sequences]]
[[Category:Binary arithmetic]]</text>
      <sha1>j4e9ir50ppre04e0rb26qhbw4jeqfr1</sha1>
    </revision>
  </page>
  <page>
    <title>Noneism</title>
    <ns>0</ns>
    <id>7201629</id>
    <revision>
      <id>841668205</id>
      <parentid>815322258</parentid>
      <timestamp>2018-05-17T07:54:10Z</timestamp>
      <contributor>
        <username>Maksim Otstavnov</username>
        <id>2507295</id>
      </contributor>
      <minor/>
      <comment>title of a book corrected according to LOC data</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1942">'''Noneism''', also known as '''modal Meinongianism''',&lt;ref name="SEP-no"/&gt; is a theory in [[logic]] and [[metaphysics]] first coined by [[Richard Routley]] and appropriated again in 2005 by [[Graham Priest]].&lt;ref&gt;{{Cite book  | last1 = Priest | first1 = Graham | title = Towards non-being: the logic and metaphysics of intentionality | year = 2005 | publisher = Clarendon  | location = Oxford  | isbn = 0-19-926254-3 | pages =  }}&lt;/ref&gt;

==Overview==
Noneism holds that some things do not exist. That is, we can quantify over non-existent things using the so-called [[particular quantifier]]{{clarify|date=January 2017}} (also known—misleadingly in the view of noneists—as the [[existential quantifier]]). They also hold that "there is" is like "exist", rather than like the particular quantifier. Thus, they deny that ''there are'' things that do not exist. On this theory, there are no empty names, wherefore the "problem of empty names" that afflicts many theories about names (in particular, Millianism), is not a problem at all.&lt;ref name="SEP-no"&gt;{{cite SEP |url-id=nonexistent-objects/#OthWorStr |title=Nonexistent Objects}}&lt;/ref&gt;

While Priest also espouses [[dialetheism]], he maintains that his dialetheism is mostly capable of being separated out from his noneism. The connection is that impossible objects may exist in impossible worlds, much as nonexistent objects may exist in possible (but not actual) worlds.

Routley's book, ''Exploring Meinong's Jungle and Beyond: An Investigation of Noneism and the Theory of Items'', was published in 1980, while Priest's 2005 book is entitled ''Towards Non-Being: The Logic and Metaphysics of Intentionality''.

==See also==
{{Portal|Philosophy}}
*[[Meinong's jungle]]
*[[Plato's beard]]
*[[Possible world]]
*[[Round square copula]]

==References==
{{Reflist}}

[[Category:20th-century philosophy]]
[[Category:Non-classical logic]]
[[Category:Metaphysical theories]]


{{philo-stub}}</text>
      <sha1>9zhp9qyq41zryfqq76ycdyyqgjjvtsu</sha1>
    </revision>
  </page>
  <page>
    <title>Prefuse</title>
    <ns>0</ns>
    <id>6172530</id>
    <revision>
      <id>861373300</id>
      <parentid>738000412</parentid>
      <timestamp>2018-09-26T23:35:13Z</timestamp>
      <contributor>
        <ip>2001:14BA:80D2:6F00:0:0:0:1EC</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6017">
{{Infobox software
| name                   = 
| title                  = 
| logo                   = Visualization of wiki structure using prefuse visualization package.png
| logo caption           = Visualization of a link structure in a wiki, created with Prefuse. Node size represents the amount of activity on the wiki on a given day.
| logo_size              = 300
| logo_alt               = 
| screenshot             = &lt;!-- Image name is enough --&gt;
| caption                = 
| screenshot_size        = 
| screenshot_alt         = 
| collapsible            = 
| author                 = 
| developer              =  [[Jeffrey Heer]]
| released               = &lt;!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} --&gt;
| discontinued           = 
| latest release version = 
| latest release date    = &lt;!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} --&gt;
| latest preview version = 
| latest preview date    = &lt;!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} --&gt;
| status                 = 
| programming language   = [[Java (software platform)|Java]]
| operating system       = 
| platform               = 
| size                   = 
| language               = 
| language count         = &lt;!-- DO NOT include this parameter unless you know what it does --&gt;
| language footnote      = 
| genre                  = 
| license                = BSD
| alexa                  = 
| website                = {{URL|prefuse.org}}
| standard               = 
| AsOf                   = 
}}
'''Prefuse''' is a [[Java (software platform)|Java]]-based [[toolkit]] for building interactive [[information visualization]] applications. It supports a rich set of features for [[data modeling]], visualization and interaction. It provides optimized [[data structure]]s for [[table (information)|tables]], [[graph (data structure)|graphs]], and [[tree (data structure)|trees]], a host of layout and visual encoding techniques, and support for [[Computer animation|animation]], dynamic queries, integrated search, and database connectivity. 

Prefuse uses the [[Java 2D]] [[graphics library]], and is easily integrated into [[Swing (Java)|Swing]] applications or [[Java applet]]s. Prefuse is licensed under the terms of a [[BSD license]], and can be used freely for commercial and non-commercial purposes.

== Overview ==
{{noref|section|date=May 2011}}
Prefuse is a [[Java (software platform)|Java]]-based extensible [[software framework]] for creating interactive [[information visualization]] applications. It can be used to build standalone applications, visual components and [[Java applet]]s. Prefuse intends to simplify the processes of visualizing, handling and mapping of data, as well as user interaction.

Some of Prefuse's features include:

* [[table (information)|Table]], [[graph (data structure)|graph]], and [[tree (data structure)|tree]] [[data structure]]s supporting arbitrary data attributes, data indexing, and selection queries, all with an efficient memory footprint.
* Components for layout, color, size, and shape encodings, distortion techniques and more.
* A library of controls for common interactive, direct-manipulation operations.
* Animation support through a general activity scheduling mechanism.
* View transformations supporting panning and zooming, including both geometric and semantic zooming.
* Dynamic [[query language|queries]] for interactive filtering of data.
* Integrated text search using a number of available [[search engines]].
* A physical force [[Computer simulation|simulation]] engine for dynamic layout and animation (s.a. [[Force-directed graph drawing]])
* Flexibility for multiple views, including "overview+detail" and "small multiples" displays.
* A built in, [[SQL]]-like expression language for writing queries to prefuse data structures and creating derived data fields.
* Support for issuing queries to [[SQL database]]s and mapping query results into prefuse data structures.
(and perhaps most importantly)
* Simple, developer-friendly [[application programming interface]]s (APIs) for creating custom processing, interaction, and rendering components.

Prefuse has been used in school course projects, academic and industrial research, and commercial [[software development]].

==Architecture==
The design of the prefuse toolkit is based upon the [[information visualization reference model]], a software architecture pattern that breaks up the visualization process into a series of discrete steps. "Prefuse: a toolkit for interactive information visualization" provides more details on implementation and evaluation.&lt;ref&gt;Jeffrey Heer, [[Stuart K. Card]] and James A. Landay (2005). [http://bid.berkeley.edu/files/papers/2005-prefuse-CHI.pdf " prefuse: a toolkit for interactive information visualization"]. In: ''Proceedings of the SIGCHI conference on Human factors in computing systems'': 421-430, Portland, Oregon, USA: ACM.&lt;/ref&gt;

The information visualization reference model was developed in the Ph.D. thesis work of Ed Chi, under the name of the [[data state model]]. Chi showed that the framework successfully modeled a wide array of visualization applications. Later, Chi's work showed that the model was functionally equivalent to the data flow model used in existing graphics toolkits such as VTK. In their work, "Readings in Information Visualization: Using Vision to Think", Stuart K. Card, Jock D. Mackinlay, and Ben Shneiderman present their own interpretation of this pattern, dubbing it the "information visualization reference model".&lt;ref&gt; [[Jock D. Mackinlay]] Stuart K. Card, Ben Shneiderman (eds.) (1999). ''Readings in information visualization: using vision to think''. Morgan Kaufmann Publishers Inc, p.686.&lt;/ref&gt;

==See also==
* [[Rhizome Navigation]]

==References==
{{reflist}}

== External links ==
* {{Official website|http://prefuse.org/|Prefuse official website}}


{{Visualization}}

[[Category:Computational science]]
[[Category:Free data visualization software]]
[[Category:Free software programmed in Java (programming language)]]</text>
      <sha1>ryje2305gzw4ryglcrad3bryubvyib5</sha1>
    </revision>
  </page>
  <page>
    <title>Principal branch</title>
    <ns>0</ns>
    <id>972441</id>
    <revision>
      <id>814864829</id>
      <parentid>814863789</parentid>
      <timestamp>2017-12-11T11:05:23Z</timestamp>
      <contributor>
        <username>Purgy Purgatorio</username>
        <id>22035051</id>
      </contributor>
      <comment>Undid revision 814863789 by [[Special:Contributions/130.238.10.8|130.238.10.8]] ([[User talk:130.238.10.8|talk]])It's the "atan2", mimicing the "arg", and not the "Atan", I think</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3308">In [[mathematics]], a '''principal branch''' is a function which selects one [[branch point|branch]] ("slice") of a [[multi-valued function]].  Most often, this applies to functions defined on the [[complex plane]].

== Examples ==
[[File:Principle branch of arg on Riemann.svg|thumbnail|right|Principal branch of arg(z)]]

=== Trigonometric inverses ===

Principal branches are used in the definition of many [[inverse trigonometric functions]], such as the selection either to define that
:&lt;math&gt;\arcsin:[-1,+1]\rightarrow\left[-\frac{\pi}{2},\frac{\pi}{2}\right]&lt;/math&gt;
or that
:&lt;math&gt;\arccos:[-1,+1]\rightarrow[0,\pi]&lt;/math&gt;.

=== Exponentiation to fractional powers ===

A more familiar principal branch function, limited to real numbers, is that of a positive real number raised to the power of {{math|1/2}}.

For example, take the relation {{math|''y'' {{=}} ''x''&lt;sup&gt;1/2&lt;/sup&gt;}}, where {{math|''x''}} is any positive real number.

This relation can be satisfied by any value of {{math|''y''}} equal to a [[square root]] of {{math|''x''}} (either positive or negative).  By convention, {{sqrt|x}} is used to denote the positive square root of {{math|''x''}}.

In this instance, the positive square root function is taken as the principal branch of the multi-valued relation {{math|''x''&lt;sup&gt;1/2&lt;/sup&gt;}}.

=== Complex logarithms ===

One way to view a principal branch is to look specifically at the [[exponential function]], and the [[logarithm]], as it is defined in [[complex analysis]].

The exponential function is single-valued, where {{math|''e&lt;sup&gt;z&lt;/sup&gt;''}} is defined as:

:&lt;math&gt;e^z = e^a \cos b + i e^a \sin b&lt;/math&gt;
where &lt;math&gt;z = a + i b&lt;/math&gt;.

However, the periodic nature of the trigonometric functions involved makes it clear that the logarithm is not so uniquely determined.  One way to see this is to look at the following:

:&lt;math&gt;\operatorname{Re} (\log z) = \log \sqrt{a^2 + b^2}&lt;/math&gt;

and

:&lt;math&gt;\operatorname{Im} (\log z) = \operatorname{atan2}(b, a) + 2 \pi k&lt;/math&gt;
where {{math|''k''}} is any integer and [[atan2|{{math|atan2}}]] continues the values of the {{math|arctan(b/a)}}-function from their principal value range &lt;math&gt;(-\pi/2,\; \pi/2]&lt;/math&gt;, corresponding to &lt;math&gt;a &gt; 0&lt;/math&gt; into the principal value range of the {{math|arg(z)}}-function &lt;math&gt;(-\pi,\; \pi]&lt;/math&gt;, covering all four quadrants in the complex plane.

Any number {{math|log ''z''}} defined by such criteria has the property that {{math|''e''&lt;sup&gt;log ''z''&lt;/sup&gt; {{=}} ''z''}}.

In this manner log function is a [[multi-valued function]] (often referred to as a "multifunction" in the context of complex analysis).  A branch cut, usually along the negative real axis, can limit the imaginary part so it lies between {{math|−π}} and {{math|π}}. These are the chosen [[principal value]]s.

This is the principal branch of the log function.  Often it is defined using a capital letter, {{math|Log ''z''}}.

==See also==
*[[Branch point]]
* [[Branch cut]]
*[[Complex logarithm]]
*[[Riemann surface]]

==External links==
* {{MathWorld | urlname= PrincipalBranch | title= Principal Branch }}
* [https://web.archive.org/web/20061209014913/http://math.fullerton.edu/mathews/c2003/ComplexFunBranchMod.html Branches of Complex Functions Module by John H. Mathews] 

[[Category:Complex analysis]]</text>
      <sha1>af4uhco6b50ze0c7ivkdwmnic8m7d53</sha1>
    </revision>
  </page>
  <page>
    <title>Proof compression</title>
    <ns>0</ns>
    <id>35066763</id>
    <revision>
      <id>833753356</id>
      <parentid>727613473</parentid>
      <timestamp>2018-04-02T07:38:51Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 0 sources and tagging 1 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5865">In [[proof theory]], an area of [[mathematical logic]], '''proof compression''' is the problem of [[algorithm]]ically compressing formal proofs. The developed algorithms can be used to improve the proofs generated by [[automated theorem proving]] tools such as [[SAT solver|sat-solvers]], [[SMT solver|SMT-solvers]], [[first-order theorem provers]] and [[proof assistant]]s.
 
==Problem Representation==
In [[propositional logic]] a [[resolution (logic)|resolution]] proof of a clause &lt;math&gt;\kappa&lt;/math&gt; from a set of clauses C is a [[directed acyclic graph]] (DAG): the input nodes are axiom inferences (without premises) whose conclusions are elements of C, the resolvent nodes are resolution inferences, and the proof has a node with conclusion &lt;math&gt;\kappa&lt;/math&gt;.&lt;ref&gt;Fontaine, Pascal; Merz, Stephan; Woltzenlogel Paleo, Bruno. ''Compression of Propositional Resolution Proofs via Partial Regularization''. 23rd International Conference on Automated Deduction, 2011.&lt;/ref&gt;

The DAG contains an edge from a node &lt;math&gt;\eta_{1}&lt;/math&gt; to a node &lt;math&gt;\eta_{2}&lt;/math&gt; if and only if a premise of &lt;math&gt;\eta_{1}&lt;/math&gt; is the conclusion of &lt;math&gt;\eta_{2}&lt;/math&gt;. In this case, &lt;math&gt;\eta_{1}&lt;/math&gt; is a child of &lt;math&gt;\eta_{2}&lt;/math&gt;, and &lt;math&gt;\eta_{2}&lt;/math&gt; is a parent of &lt;math&gt;\eta_{1}&lt;/math&gt;. A node with no children is a root.

A proof compression algorithm will try to create a new DAG with fewer nodes that represents a valid proof of &lt;math&gt;\kappa&lt;/math&gt; or, in some cases, a valid proof of a subset of &lt;math&gt;\kappa&lt;/math&gt;.

===A simple example===
Let's take a resolution proof for the clause &lt;math&gt;\left\{ a,b,c\right\}&lt;/math&gt; from the set of clauses

:&lt;math&gt;\left\{ \eta_{1}:\left\{ a,b,p\right\} ,\eta_{2}:\left\{ c,\neg p\right\} \right\} \quad
\frac{\eta_{1}: a,b,p \quad\quad \eta_{2}: c,\neg p}
{\eta_{3}: a,b,c} p
&lt;/math&gt;

Here we can see:
* &lt;math&gt;\eta_{1}&lt;/math&gt; and &lt;math&gt;\eta_{2}&lt;/math&gt; are input nodes. 
* The node &lt;math&gt;\eta_{3}&lt;/math&gt; has a pivot &lt;math&gt;p&lt;/math&gt;, 
** left resolved literal &lt;math&gt;p&lt;/math&gt;
** right resolved literal &lt;math&gt;\neg p&lt;/math&gt;
* &lt;math&gt;\eta_{3}&lt;/math&gt; conclusion is the clause &lt;math&gt;\left\{ a,b,c\right\} &lt;/math&gt;
* &lt;math&gt;\eta_{3}&lt;/math&gt; premises are the conclusion of nodes &lt;math&gt;\eta_{1}&lt;/math&gt; and &lt;math&gt;\eta_{2}&lt;/math&gt; (its parents)
* The DAG would be
:&lt;math&gt;
\begin{array}{ccc}
\eta_{1} &amp;  &amp; \eta_{2}\\
 &amp; \nwarrow\nearrow\\
 &amp; \eta_{3}\end{array}
&lt;/math&gt;
* &lt;math&gt;\eta_{1}&lt;/math&gt; and &lt;math&gt;\eta_{2}&lt;/math&gt; are parents of &lt;math&gt;\eta_{3}&lt;/math&gt;
* &lt;math&gt;\eta_{3}&lt;/math&gt; is a child of &lt;math&gt;\eta_{1}&lt;/math&gt; and &lt;math&gt;\eta_{2}&lt;/math&gt;
* &lt;math&gt;\eta_{3}&lt;/math&gt; is a root of the proof

A (resolution) refutation of C is a resolution proof of &lt;math&gt;\bot&lt;/math&gt; from C. It is a common that given a node &lt;math&gt;\eta&lt;/math&gt;, to refer to the clause &lt;math&gt;\eta&lt;/math&gt; or &lt;math&gt;\eta&lt;/math&gt;’s clause meaning the conclusion clause of &lt;math&gt;\eta&lt;/math&gt;, and (sub)proof &lt;math&gt;\eta&lt;/math&gt; meaning the (sub)proof having &lt;math&gt;\eta&lt;/math&gt; as its only root.

In some works it can be found an algebraic representation of a [[resolution inference]]. The resolvent of &lt;math&gt;\kappa_{1}&lt;/math&gt; and &lt;math&gt;\kappa_{2}&lt;/math&gt; with pivot &lt;math&gt;p&lt;/math&gt; can be denoted as &lt;math&gt;\kappa_{1}\odot_{p}\kappa_{2}&lt;/math&gt;. When the pivot is uniquely defined or irrelevant, we omit it and write simply &lt;math&gt;\kappa_{1}\odot\kappa_{2}&lt;/math&gt;. In this way, the set of clauses can be seen as an algebra with a commutative operator; and terms in the corresponding term algebra denote resolution proofs in a notation style that is more compact and more convenient for describing resolution proofs than the usual graph notation.

In our last example the notation of the DAG would be &lt;math&gt;\left\{ a,b,p\right\} \odot_{p}\left\{ c,\neg p\right\}&lt;/math&gt; or simply &lt;math&gt;\left\{ a,b,p\right\} \odot\left\{ c,\neg p\right\}. &lt;/math&gt;

We can identify &lt;math&gt;\underbrace{\overbrace{\left\{ a,b,p\right\} }^{\eta_{1}}\odot\overbrace{\left\{ c,\neg p\right\} }^{\eta_{2}}}_{\eta_{3}} &lt;/math&gt;

==Compression algorithms==
Algorithms for compression of [[sequent calculus]] proofs include [[Cut-introduction]] and [[Cut-elimination]].

Algorithms for compression of propositional [[resolution (logic)|resolution]] proofs include 
[[RecycleUnits]],&lt;ref&gt;Bar-Ilan, O.; Fuhrmann, O.; Hoory, S. ; Shacham, O. ; Strichman, O. ''Linear-time Reductions of Resolution Proofs''. Hardware and Software: Verification and Testing, p. 114–128, Springer, 2011.&lt;/ref&gt;
[[RecyclePivots]],&lt;ref&gt;Bar-Ilan, O.; Fuhrmann, O.; Hoory, S. ; Shacham, O. ; Strichman, O. ''Linear-time Reductions of Resolution Proofs''. Hardware and Software: Verification and Testing, p. 114–128, Springer, 2011.&lt;/ref&gt;
[[RecyclePivotsWithIntersection]],&lt;ref&gt;Fontaine, Pascal; Merz, Stephan; Woltzenlogel Paleo, Bruno. ''Compression of Propositional Resolution Proofs via Partial Regularization''. 23rd International Conference on Automated Deduction, 2011.&lt;/ref&gt;
[[LowerUnits]],&lt;ref&gt;Fontaine, Pascal; Merz, Stephan; Woltzenlogel Paleo, Bruno. ''Compression of Propositional Resolution Proofs via Partial Regularization''. 23rd International Conference on Automated Deduction, 2011.&lt;/ref&gt;
[[LowerUnivalents]],&lt;ref&gt;https://github.com/Paradoxika/Skeptik/tree/develop/doc/papers/LUniv{{dead link|date=April 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;
[[Resolution proof compression by splitting|Split]],&lt;ref&gt;Cotton, Scott. "Two Techniques for Minimizing Resolution Proofs". 13th International Conference on Theory and Applications of Satisfiability Testing, 2010.&lt;/ref&gt;
[[Resolution proof reduction via local context rewriting|Reduce&amp;Reconstruct]],&lt;ref&gt;Simone, S.F. ; Brutomesso, R. ; Sharygina, N. "An Efficient and Flexible Approach to Resolution Proof Reduction". 6th Haifa Verification Conference, 2010.&lt;/ref&gt; and [[Subsumption (logic)|Subsumption]].

==Notes==
{{reflist}}

[[Category:Proof theory]]</text>
      <sha1>s547ze58ag73t6mw0a4as4vokh4cun3</sha1>
    </revision>
  </page>
  <page>
    <title>Proper forcing axiom</title>
    <ns>0</ns>
    <id>6250799</id>
    <revision>
      <id>670670192</id>
      <parentid>639438776</parentid>
      <timestamp>2015-07-09T12:40:48Z</timestamp>
      <contributor>
        <ip>66.59.127.89</ip>
      </contributor>
      <comment>/* Statement */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5988">In the mathematical field of [[set theory]], the '''proper forcing axiom''' (''PFA'') is a significant strengthening of [[Martin's axiom]], where [[forcing (set theory)|forcing]]s with the [[countable chain condition]] (ccc) are replaced by proper forcings.

== Statement ==

A [[forcing (set theory)|forcing]] or [[partially ordered set]] P is '''proper''' if for all [[regular cardinal|regular]] uncountable [[cardinal number|cardinals]] &lt;math&gt; \lambda &lt;/math&gt;, [[forcing (mathematics)|forcing]] with P preserves [[stationary set|stationary subsets]] of &lt;math&gt; [\lambda]^\omega &lt;/math&gt;.

The '''proper forcing axiom''' asserts that if P is proper and D&lt;sub&gt;&amp;alpha;&lt;/sub&gt; is a dense subset of P for each &amp;alpha;&lt;&amp;omega;&lt;sub&gt;1&lt;/sub&gt;, then there is a filter G &lt;math&gt;\subseteq&lt;/math&gt; P such that D&lt;sub&gt;&amp;alpha;&lt;/sub&gt;&amp;nbsp;∩&amp;nbsp;G is nonempty for all &amp;alpha;&lt;&amp;omega;&lt;sub&gt;1&lt;/sub&gt;.

The class of proper forcings, to which PFA can be applied, is rather large. For example, standard arguments show that if P is [[countable chain condition|ccc]] or [[&amp;omega;-closed]], then P is proper. If P is a [[iterated forcing|countable support iteration]] of proper forcings, then P is proper. Crucially, all proper forcings preserve [[cardinal number|&lt;math&gt;\aleph_1 &lt;/math&gt;]].

== Consequences ==
PFA directly implies its version for ccc forcings, [[Martin's axiom]]. In [[Cardinal number|cardinal arithmetic]], PFA implies &lt;math&gt; 2^{\aleph_0} = \aleph_2 &lt;/math&gt;. PFA implies any two &lt;math&gt; \aleph_1&lt;/math&gt;-dense subsets of R are isomorphic,&lt;ref&gt;Moore (2011)&lt;/ref&gt; any two [[Aronszajn tree]]s are club-isomorphic,&lt;ref&gt;Abraham, U., and Shelah, S., Isomorphism types of Aronszajn trees (1985) Israel Journal of Mathematics (50) 75 -- 113&lt;/ref&gt; and every automorphism of the [[Boolean algebra]] &lt;math&gt;P(\omega)&lt;/math&gt;/fin is trivial.&lt;ref&gt;Moore (2011)&lt;/ref&gt; PFA implies that the [[Singular cardinals hypothesis|Singular Cardinals Hypothesis]] holds.  An especially notable consequence proved by  [[John R. Steel]] is that the [[axiom of determinacy]] holds in [[L(R)]], the smallest [[inner model]] containing the real numbers. Another consequence is the failure of [[square principle]]s and hence existence of inner models with many [[Woodin cardinal]]s.

== Consistency strength ==

If there is a [[supercompact cardinal]], then there is a model of set theory in which PFA holds.  The proof uses the fact that proper forcings are preserved under countable support iteration, and the fact that if &lt;math&gt; \kappa &lt;/math&gt; is supercompact, then there exists a [[Laver function]] for &lt;math&gt; \kappa &lt;/math&gt;.

It is not yet known how much large cardinal strength comes from PFA.

== Other forcing axioms ==

The '''bounded proper forcing axiom''' (BPFA) is a weaker variant of PFA which instead of arbitrary dense subsets applies only to maximal [[antichain]]s of size &amp;omega;&lt;sub&gt;1&lt;/sub&gt;. '''[[Martin's maximum]]''' is the strongest possible version of a forcing axiom.

Forcing axioms are viable candidates for extending the axioms of set theory as an alternative to [[large cardinal]] axioms.

== The Fundamental Theorem of Proper Forcing ==

The Fundamental Theorem of Proper Forcing, due to [[Saharon Shelah|Shelah]], states that any [[iterated forcing|countable support iteration]] of proper forcings is itself proper.  This follows from the Proper Iteration Lemma, which states that whenever &lt;math&gt;\langle P_\alpha\,\colon\alpha\leq\kappa\rangle&lt;/math&gt; is a countable support forcing iteration based on &lt;math&gt;\langle Q_\alpha\,\colon
\alpha&lt;\kappa\rangle&lt;/math&gt; and &lt;math&gt;N&lt;/math&gt; is a countable elementary substructure of &lt;math&gt;H_\lambda&lt;/math&gt; for a sufficiently large regular cardinal &lt;math&gt;\lambda&lt;/math&gt;, and &lt;math&gt;P_\kappa\in N&lt;/math&gt; and &lt;math&gt;\alpha\in \kappa\cap N&lt;/math&gt; and &lt;math&gt;p&lt;/math&gt; is &lt;math&gt;(N,P_\alpha)&lt;/math&gt;-generic and &lt;math&gt;p&lt;/math&gt; forces "&lt;math&gt;q\in P_\kappa/G_{P_\alpha}\cap N[G_{P_\alpha}]&lt;/math&gt;," then there exists &lt;math&gt;r\in P_\kappa&lt;/math&gt; such that &lt;math&gt;r&lt;/math&gt; is &lt;math&gt;N&lt;/math&gt;-generic and the restriction of &lt;math&gt;r&lt;/math&gt; to &lt;math&gt;P_\alpha&lt;/math&gt; equals &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;p&lt;/math&gt; forces the restriction of &lt;math&gt;r&lt;/math&gt; to &lt;math&gt;[\alpha,\kappa)&lt;/math&gt; to be stronger or equal to &lt;math&gt;q&lt;/math&gt;.

This version of the Proper Iteration Lemma, in which the name &lt;math&gt;q&lt;/math&gt; is not assumed to be in &lt;math&gt; N&lt;/math&gt;, is due to Schlindwein.&lt;ref&gt;Schlindwein, C., "Consistency of Suslin's hypothesis, a non-special Aronszajn tree, and GCH", (1994), Journal of Symbolic Logic (59) pp. 1 -- 29&lt;/ref&gt;

The Proper Iteration Lemma is proved by a fairly straightforward induction on &lt;math&gt;\kappa&lt;/math&gt;, and the Fundamental Theorem of Proper Forcing follows by taking &lt;math&gt;\alpha=0&lt;/math&gt;.

== See also ==
* [[Stevo Todorčević]]

== References ==
{{reflist}}
* {{cite book|last=Jech | first=Thomas|title=Set theory | edition=Third millennium (revised and expanded)|publisher=Springer|year=2002|isbn=3-540-44085-2|authorlink=Thomas Jech | zbl=1007.03002 | doi=10.1007/3-540-44761-X }}
* {{cite book | last=Kunen | first=Kenneth | authorlink=Kenneth Kunen | title=Set theory | zbl=1262.03001 | series=Studies in Logic | volume=34 | location=London | publisher=College Publications | isbn=978-1-84890-050-9 | year=2011 }}
* {{cite book | last=Moore | first=Justin Tatch | chapter=Logic and foundations: the proper forcing axiom | zbl=1258.03075 | editor1-last=Bhatia | editor1-first=Rajendra | title=Proceedings of the international congress of mathematicians (ICM 2010), Hyderabad, India, August 19–27, 2010. Vol. II: Invited lectures | location=Hackensack, NJ | publisher=World Scientific | isbn=978-981-4324-30-4| pages=3–29 | year=2011 | url=http://www.math.cornell.edu/~justin/Ftp/ICM.pdf}}
* {{cite journal|last=Steel|first=John R.|journal=Journal of Symbolic Logic|year=2005|title=PFA implies AD^L(R)|volume=70|issue=4|pages=1255–1296|authorlink=John R. Steel|doi=10.2178/jsl/1129642125}}

[[Category:Axioms of set theory]]
[[Category:Forcing (mathematics)]]</text>
      <sha1>ovtc8r7g6e6bi8vghblckxi7dhqaa09</sha1>
    </revision>
  </page>
  <page>
    <title>Randomization function</title>
    <ns>0</ns>
    <id>3578575</id>
    <revision>
      <id>633524377</id>
      <parentid>580711448</parentid>
      <timestamp>2014-11-12T14:03:35Z</timestamp>
      <contributor>
        <ip>146.52.254.208</ip>
      </contributor>
      <comment>/* Uses */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3325">{{Unreferenced|date=April 2009}}
In [[computer science]], a '''randomization function''' or '''randomizing function''' is an [[algorithm]] or [[Subroutine|procedure]] that implements a [[random]]ly chosen [[function (mathematics)|function]] between two specific [[set (mathematics)|set]]s, suitable for use in a [[randomized algorithm]].

Randomizing functions are related to [[random number generator]]s and [[hash function]]s, but have somewhat different requirements and uses, and often need specific algorithms.

==Uses==

Randomizing functions are used to turn algorithms that have good [[expected value|expected]] performance for ''random'' inputs, into algorithms that have the same performance for ''any'' input.

For example, consider a [[sorting algorithm]] like [[quicksort]], which has small expected running time when the input items are presented in random order, but is very slow when they are presented in certain unfavorable orders. A randomizing function from the integers 1 to ''n'' to the integers 1 to ''n'' can be used to rerrange the ''n'' input items in "random" order, before calling that algorithm.  This modified (randomized) algorithm will have small expected running time, whatever the input order.

==Requirements==

===Randomness===
In theory, randomization functions are assumed to be truly random, and yield an unpredictably different function every time the algorithm is executed.  The randomization technique would not work if, at every execution of the algorithm, the randomization function always performed the same mapping, or a mapping entirely determined by some externally observable parameter (such as the program's startup time).  With such a "pseudo-randomization" function, one could in principle construct a sequence of calls such that the function would always yield a "bad" case for the underlying deterministic algorithm.  For that sequence of calls, the average cost would be closer to the worst-case cost, rather than the average cost for random inputs.

In practice, however, the main concern is that some "bad" cases for the deterministic algorithm may occur in practice much more often than it would be predicted by chance.  For example, in a naive variant of quicksort, the worst case is when the input items are already sorted — which is a very common occurrence in many applications.  For such algorithms, even a fixed pseudo-random permutation may be good enough.  Even though the resulting "pseudo-randomized" algorithm would still have as many "bad" cases as the original, they will be certain peculiar orders that would be quite unlikely to arise in real applications.  So, in practice one often uses randomization functions that are derived from [[pseudo-random number generator]]s, preferably [[random seed|seeded]] with external "random" data such as the program's startup time.

===Uniformity===
The uniformity requirements for a randomizing function are usually much weaker than those of hash functions and pseudo-random generators.  The minimum requirement is that it maps any input of the deterministic algorithm into a "good" input with a sufficiently high probability.  (However, analysis is usually simpler if the randomizing function implements each possible mapping with uniform probability.)

==References==
{{comp-sci-stub}}
[[Category:Algorithms]]</text>
      <sha1>fu3eijsz6vci445vxa4yp0up957gq7d</sha1>
    </revision>
  </page>
  <page>
    <title>Realized kernel</title>
    <ns>0</ns>
    <id>28345620</id>
    <revision>
      <id>836034222</id>
      <parentid>594941174</parentid>
      <timestamp>2018-04-12T08:26:59Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1244">The '''realized kernel''' (RK) is an estimator of volatility. The estimator is typically computed with high frequency return data, such as second-by-second returns. Unlike the [[realized variance]], the realized kernel is a robust estimator of volatility, in the sense that the realized kernel estimates the appropriate volatility quantity, even when the returns are contaminated with noise.
&lt;ref&gt;{{Cite journal |last=Barndorff-Nielsen |first=Ole E. |last2=Hansen |first2=Peter Reinhard |last3=Lunde |first3=Asger |last4=Shephard |first4=Neil |authorlink=Ole Barndorff-Nielsen |authorlink2=Peter Reinhard Hansen |authorlink4=Neil Shephard |date=November 2008 |title=Designing realised kernels to measure the ex-post variation of equity prices in the presence of noise |pages=1481–1536 |doi=10.3982/ECTA6495 |url=http://www.econometricsociety.org/abstract.asp?ref=0012-9682&amp;vid=76&amp;iid=6&amp;aid=9&amp;s=-9999 |accessdate= |quote= |journal=Econometrica |volume=76 |deadurl=yes |archiveurl=https://web.archive.org/web/20110726230752/http://www.econometricsociety.org/abstract.asp?ref=0012-9682&amp;vid=76&amp;iid=6&amp;aid=9&amp;s=-9999 |archivedate=2011-07-26 |df= }}&lt;/ref&gt;

==See also==
*[[Realized variance]]

==Notes==
{{Reflist}}

[[Category:Mathematical finance]]</text>
      <sha1>9wdfuhtvwhpt4mosj3nyo3ibsma2rvv</sha1>
    </revision>
  </page>
  <page>
    <title>Sally Elizabeth Carlson</title>
    <ns>0</ns>
    <id>55831372</id>
    <revision>
      <id>864824253</id>
      <parentid>864518674</parentid>
      <timestamp>2018-10-19T18:20:57Z</timestamp>
      <contributor>
        <username>Jmertel23</username>
        <id>32942831</id>
      </contributor>
      <comment>infobox added; short description added</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4980">{{short description|American mathematician}}
{{Infobox academic
| honorific_prefix   = &lt;!-- see [[MOS:HONORIFIC]] --&gt;
| name               = 
| honorific_suffix   = 
| image              = 
| image_size         = 
| alt                = 
| caption            = 
| native_name        = 
| native_name_lang   = 
| birth_name         = &lt;!-- use only if different from full/othernames --&gt;
| birth_date         = {{birth date|1896|10|02}}
| birth_place        = [[Minneapolis, Minnesota]]
| death_date         = {{death date and age|2000|11|01|1896|10|02}}
| death_place        = 
| death_cause        = 
| region             = 
| nationality        = American
| citizenship        = 
| residence          = 
| other_names        = 
| occupation         = 
| period             = 
| known_for          = 
| home_town          = 
| title              = 
| boards             = &lt;!--board or similar positions extraneous to main occupation--&gt;
| spouse             = 
| children           = 
| parents            =
| relatives          =
| awards             = &lt;!--notable national level awards only--&gt;
| website            = 
| education          = 
| alma_mater         = [[University of Minnesota]]
| thesis_title       = The Convergence of Certain Methods of Closest Approximation
| thesis_url         = 
| thesis_year        = 1924
| school_tradition   = 
| doctoral_advisor   = [[Dunham Jackson]]
| academic_advisors  = 
| influences         = &lt;!--must be referenced from a third party source--&gt;
| era                = 
| discipline         = [[Mathematics]]
| sub_discipline     = [[Functional analysis]]
| workplaces         = [[University of Minnesota]]
| doctoral_students  = &lt;!--only those with WP articles--&gt;
| notable_students   = [[Margaret P. Martin]]
| main_interests     = 
| notable_works      = 
| notable_ideas      = 
| influenced         = &lt;!--must be referenced from a third party source--&gt;
| signature          = 
| signature_alt      = 
| signature_size     = 
| footnotes          = 
}}

'''Sally Elizabeth Carlson''' (October 2, 1896 – November 1, 2000) was an American mathematician,{{r|pioneer}} the first woman and one of the first two people to obtain a doctorate in mathematics from the [[University of Minnesota]].{{r|pioneer|asc}}

Carlson was born in [[Minneapolis]] to a large working-class family of Swedish immigrants. She became her high school valedictorian in 1913, graduated from the [[University of Minnesota]] in 1917, and earned a master's degree there in 1918. After teaching mathematics for two years, she returned to graduate study in 1920, and completed her Ph.D. at Minnesota in 1924. Both students were supervised by [[Dunham Jackson]];{{r|pioneer}} Carlson's dissertation, in [[functional analysis]], was ''On The Convergence of Certain Methods of Closest Approximation''.{{r|mgp}}

She joined the Minnesota faculty, and remained there until her retirement in 1965 as a full professor.{{r|pioneer}}
She has no record of supervising doctoral dissertations,{{r|mgp}}
and published little research after the work of her own dissertation.
However, she supervised several master's students, won a Distinguished Teacher Award,{{r|pioneer}}
and was described as a mentor by [[Margaret P. Martin]], who completed her Ph.D. at Minnesota in 1944.{{r|wbm}}

After her 2000 death, the library of the University of Minnesota memorialized her in an exhibit, titled "Elizabeth Carlson, notable alumna".{{r|pioneer}}

==References==
{{reflist|refs=

&lt;ref name=asc&gt;{{citation|url=https://www.agnesscott.edu/lriddle/women/firstPhDs.htm|title=The First Ph.D.'s|work=Biographies of Women Mathematicians|publisher=Agnes Scott College|first=Larry|last=Riddle|date= June 2, 2016|accessdate=2017-11-18}}&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=38987}}&lt;/ref&gt;

&lt;ref name=pioneer&gt;{{citation
 | last1 = Green | first1 = Judy | author1-link = Judy Green (mathematician)
 | last2 = LaDuke | first2 = Jeanne | author2-link = Jeanne LaDuke
 | contribution = Carlson, Elizabeth
 | isbn = 978-0-8218-4376-5
 | pages = 153–154
 | publisher = [[American Mathematical Society]], The [[London Mathematical Society]]
 | series = History of Mathematics
 | title = Pioneering Women in American Mathematics: The Pre-1940 PhD's
 | url = https://books.google.com/books?id=IRbOAwAAQBAJ&amp;pg=PA153
 | volume = 34
 | year = 2008}}&lt;/ref&gt;

&lt;ref name=wbm&gt;{{citation|title=Women Becoming Mathematicians: Creating a Professional Identity in Post-World War II America|first=Margaret A. M.|last=Murray|publisher=MIT Press|year=2001|isbn=9780262632461|page=100|url=https://books.google.com/books?id=Sz78C8-PGUQC&amp;pg=PA100}}&lt;/ref&gt;

}}

{{authority control}}

{{DEFAULTSORT:Carlson, Sally Elizabeth}}
[[Category:1896 births]]
[[Category:2000 deaths]]
[[Category:American mathematicians]]
[[Category:Women mathematicians]]
[[Category:University of Minnesota alumni]]
[[Category:University of Minnesota faculty]]
[[Category:American people of Swedish descent]]
[[Category:American centenarians]]</text>
      <sha1>6oatl5h7zqcr0mefchyznnyu6n0dzye</sha1>
    </revision>
  </page>
  <page>
    <title>Schröder–Bernstein theorem</title>
    <ns>0</ns>
    <id>44218028</id>
    <revision>
      <id>866638534</id>
      <parentid>866539108</parentid>
      <timestamp>2018-10-31T15:57:05Z</timestamp>
      <contributor>
        <username>Jochen Burghardt</username>
        <id>17350134</id>
      </contributor>
      <comment>/* Proof */ better avoid 'left'/'right' denoting directions in the picture, since it is used also for directions in the sequence ("may terminate to the left or not")</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19037">In [[set theory]], the '''Schröder–Bernstein theorem''' states that, if there exist [[injective function]]s {{math|''f'' : ''A'' → ''B''}} and {{math|''g'' : ''B'' → ''A''}} between the [[Set (mathematics)|sets]] {{math|''A''}} and {{math|''B''}}, then there exists a [[bijection|bijective]] function {{math|''h'' : ''A'' → ''B''}}. In terms of the [[cardinality]] of the two sets, this means that if {{math|{{!}}''A''{{!}}&amp;nbsp;≤&amp;nbsp;{{!}}''B''{{!}}}} and {{math|{{!}}''B''{{!}}&amp;nbsp;≤&amp;nbsp;{{!}}''A''{{!}}}}, then {{math|1={{!}}''A''{{!}}&amp;nbsp;=&amp;nbsp;{{!}}''B''{{!}}}}; that is, {{math|''A''}} and {{math|''B''}} are [[equipotent]]. This is a useful feature in the ordering of [[cardinal number]]s.

This theorem does not rely on the [[axiom of choice]]. However, its various proofs are [[Constructive proof|non-constructive]], as they depend on the [[law of excluded middle]], and are therefore rejected by [[intuitionist]]s.&lt;ref&gt;{{cite book |title=Mathematics and Logic in History and in Contemporary Thought |author=Ettore Carruccio |publisher=Transaction Publishers |year=2006 |page=354 |isbn=978-0-202-30850-0}}&lt;/ref&gt;

The theorem is named after [[Felix Bernstein (mathematician)|Felix Bernstein]] and [[Ernst Schröder]].  It is also known as '''Cantor–Bernstein theorem''', or '''Cantor–Schröder–Bernstein''', after [[Georg Cantor]] who first published it without proof.

==Proof==
[[Image:Cantor-Bernstein.png|thumb|400px|König's definition of a bijection {{color|#00c000|''h''}}:''A''&amp;nbsp;→&amp;nbsp;''B'' from given example injections {{color|#c00000|''f''}}:''A''&amp;nbsp;→&amp;nbsp;''B'' and {{color|#0000c0|''g''}}:''B''&amp;nbsp;→&amp;nbsp;''A''. An element in ''A'' and ''B'' is denoted by a number and a letter, respectively. The sequence 3&amp;nbsp;→&amp;nbsp;e&amp;nbsp;→&amp;nbsp;6&amp;nbsp;→&amp;nbsp;... is an ''A''-stopper, leading to the definitions {{color|#00c000|''h''}}(3)&amp;nbsp;=&amp;nbsp;{{color|#c00000|''f''}}(3)&amp;nbsp;=&amp;nbsp;''e'', {{color|#00c000|''h''}}(6)&amp;nbsp;=&amp;nbsp;{{color|#c00000|''f''}}(6), .... The sequence ''d''&amp;nbsp;→&amp;nbsp;5&amp;nbsp;→&amp;nbsp;''f''&amp;nbsp;→&amp;nbsp;... is a ''B''-stopper, leading to {{color|#00c000|''h''}}(5)&amp;nbsp;=&amp;nbsp;{{color|#0000c0|''g''}}&lt;sup&gt;−1&lt;/sup&gt;(5)&amp;nbsp;=&amp;nbsp;''d'', .... The sequence ...&amp;nbsp;→&amp;nbsp;''a''&amp;nbsp;→&amp;nbsp;1&amp;nbsp;→&amp;nbsp;''c''&amp;nbsp;→&amp;nbsp;4&amp;nbsp;→&amp;nbsp;... is doubly infinite, leading to {{color|#00c000|''h''}}(1)&amp;nbsp;=&amp;nbsp;{{color|#0000c0|''g''}}&lt;sup&gt;−1&lt;/sup&gt;(1)&amp;nbsp;=&amp;nbsp;''a'', {{color|#00c000|''h''}}(4)&amp;nbsp;=&amp;nbsp;{{color|#0000c0|''g''}}&lt;sup&gt;−1&lt;/sup&gt;(4)&amp;nbsp;=&amp;nbsp;''c'',&amp;nbsp;.... The sequence ''b''&amp;nbsp;→&amp;nbsp;2&amp;nbsp;→&amp;nbsp;''b'' is cyclic, leading to {{color|#00c000|''h''}}(2)&amp;nbsp;=&amp;nbsp;{{color|#0000c0|''g''}}&lt;sup&gt;−1&lt;/sup&gt;(2)&amp;nbsp;=&amp;nbsp;''b''.]]
The following proof is attributed to [[Julius König]].&lt;ref&gt;{{cite journal| author=J. König| title=Sur la théorie des ensembles| journal=Comptes rendus hebdomadaires des séances de l'Académie des sciences| volume=143| pages=110–112| year=1906| url=http://gallica.bnf.fr/ark:/12148/bpt6k30977.image.f110.langEN}}&lt;/ref&gt;

Assume without loss of generality that ''A'' and ''B'' are [[disjoint set|disjoint]]. For any ''a'' in ''A'' or ''b'' in ''B'' we can form a unique two-sided sequence of elements that are alternately in ''A'' and ''B'', by repeatedly applying &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g^{-1}&lt;/math&gt; to go from ''A'' to ''B'' and &lt;math&gt;g&lt;/math&gt; and &lt;math&gt;f^{-1}&lt;/math&gt; to go from ''B'' to ''A'' (where defined).

:''&lt;math&gt; \cdots \rightarrow  f^{-1}(g^{-1}(a)) \rightarrow g^{-1}(a) \rightarrow   a  \rightarrow  f(a) \rightarrow  g(f(a)) \rightarrow \cdots &lt;/math&gt;''

For any particular ''a'', this sequence may terminate to the left or not, at a point where &lt;math&gt;f^{-1}&lt;/math&gt; or &lt;math&gt;g^{-1}&lt;/math&gt; is not defined.

By the fact that &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt; are injective functions, each ''a'' in ''A'' and ''b'' in ''B'' is in exactly one such sequence to within identity: if an element occurs in two sequences, all elements to the left and to the right must be the same in both, by the definition of the sequences. Therefore, the sequences form a [[Partition of a set|partition]] of the (disjoint) union of ''A'' and ''B''. Hence it suffices to produce a bijection between the elements of ''A'' and ''B'' in each of the sequences separately, as follows:

Call a sequence an ''A-stopper'' if it stops at an element of ''A'', or a ''B-stopper'' if it stops at an element of ''B''. Otherwise, call it ''[[doubly infinite]]'' if all the elements are distinct or ''cyclic'' if it repeats. See the picture for examples.

* For an ''A-stopper'', the function ''&lt;math&gt;f&lt;/math&gt;'' is a bijection between its elements in ''A'' and its elements in ''B''.
* For a ''B-stopper'', the function ''&lt;math&gt;g&lt;/math&gt;'' is a bijection between its elements in ''B'' and its elements in ''A''.
* For a ''doubly infinite'' sequence or a ''cyclic'' sequence, either ''&lt;math&gt;f&lt;/math&gt;'' or ''&lt;math&gt;g&lt;/math&gt;'' will do (&lt;math&gt;g&lt;/math&gt; is used in the picture).
{{Clear}}

==Original proof==
An earlier proof by [[Georg Cantor|Cantor]] relied, in effect, on the [[axiom of choice]] by inferring the result as a [[corollary]] of the [[well-ordering theorem]].&lt;ref&gt;{{cite journal |author=Georg Cantor |title=Beiträge zur Begründung der transfiniten Mengenlehre (1) |url=http://gdz.sub.uni-goettingen.de/index.php?id=img&amp;no_cache=1&amp;IDDOC=36218&amp;IDDOC=36218&amp;branch=&amp;L=1|journal=Mathematische Annalen |volume=46 |pages=481–512 |year=1895 |doi=10.1007/bf02124929}}&lt;BR&gt;
{{cite journal |author=Georg Cantor |title=Beiträge zur Begründung der transfiniten Mengenlehre (2) |url=http://gdz.sub.uni-goettingen.de/index.php?id=11&amp;PPN=PPN235181684_0049&amp;DMDID=DMDLOG_0024&amp;L=1 |journal=Mathematische Annalen |volume=49 |pages=207–246 |year= 1897|doi=10.1007/bf01444205 }}&lt;/ref&gt; The argument given above shows that the result can be proved without using the axiom of choice. Note however that the principle of excluded middle is used to do the analysis into cases, so this proof does not work in non-classical logic. 

There is also a proof which uses [[Knaster–Tarski theorem|Tarski's fixed point theorem]].&lt;ref&gt;R. Uhl, "[http://mathworld.wolfram.com/TarskisFixedPointTheorem.html Tarski's Fixed Point Theorem]", from ''MathWorld''–a Wolfram Web Resource, created by Eric W. Weisstein. (Example 3)&lt;/ref&gt;

== History ==

The traditional name "Schröder–Bernstein" is based on two proofs published independently in 1898.
Cantor is often added because he first stated the theorem in 1887,
while Schröder's name is often omitted because his proof turned out to be flawed
while the name of [[Richard Dedekind]], who first proved it, is not connected with the theorem.
According to Bernstein, Cantor had suggested the name ''equivalence theorem'' (Äquivalenzsatz).&lt;ref name="Brieskorn.Chatterji.2002"&gt;{{citation | author=[[Felix Hausdorff]] | editor=[[Egbert Brieskorn]] |editor2=Srishti D. Chatterji| title=Grundzüge der Mengenlehre | edition=1. | publisher=Springer | location=Berlin/Heidelberg | year=2002 | pages=587 | ISBN=3-540-42224-2| url=https://books.google.com/books?id=3nth_p-6DpcC|display-editors=etal}} – [https://jscholarship.library.jhu.edu/handle/1774.2/34091 Original edition (1914)]&lt;/ref&gt;

[[File:CantorEquivalenceTheorem1887b.gif|thumb|right|Cantor's first statement of the theorem (1887)&lt;ref name="Cantor.1932"/&gt;]]

* '''1887''' '''Cantor''' publishes the theorem, however without proof.&lt;ref name="Cantor.1932"&gt;{{citation | author=Georg Cantor | title=Mitteilungen zur Lehre vom Transfiniten |journal=[[Zeitschrift für Philosophie und philosophische Kritik]]| volume=91 |pages=81–125 |year=1887 }}&lt;BR&gt;Reprinted in: {{citation | author=Georg Cantor |editor1=Adolf Fraenkel (Lebenslauf) |editor2=Ernst Zermelo | title=Gesammelte Abhandlungen mathematischen und philosophischen Inhalts| publisher= Springer | location=Berlin | year=1932 | pages=378–439 | url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN237853094&amp;DMDID=DMDLOG_0060}} Here: p.413 bottom&lt;/ref&gt;&lt;ref name="Brieskorn.Chatterji.2002"/&gt;
* '''1887''' On July 11, '''Dedekind''' proves the theorem (not relying on the [[axiom of choice]])&lt;ref&gt;{{citation | author=Richard Dedekind | editor=[[Robert Fricke]] |editor2=Emmy Noether |editor3=Øystein Ore | title=Gesammelte mathematische Werke | volume=3 | publisher=Friedr. Vieweg &amp; Sohn | location=Braunschweig | year=1932 | pages=447–449 (Ch.62) | url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN23569441X}}&lt;/ref&gt; but neither publishes his proof nor tells Cantor about it. [[Ernst Zermelo]] discovered Dedekind's proof and in 1908&lt;ref&gt;{{citation | author=Ernst Zermelo |editor1=Felix Klein |editor2=[[Walther von Dyck]] |editor3=David Hilbert |editor4=[[Otto Blumenthal]] | title=Untersuchungen über die Grundlagen der Mengenlehre I | journal=[[Mathematische Annalen]] | volume=65 | number=2 | publisher=B.&amp;nbsp;G. Teubner | location=Leipzig | year=1908 | pages=261–281; here: p.271–272 | ISSN=0025-5831 | url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN235181684_0065&amp;DMDID=DMDLOG_0018 | doi=10.1007/bf01449999}}&lt;/ref&gt; he publishes his own proof based on the ''chain theory'' from Dedekind's paper ''Was sind und was sollen die Zahlen?''&lt;ref name="Brieskorn.Chatterji.2002"/&gt;&lt;ref&gt;{{citation | author=Richard Dedekind | title=Was sind und was sollen die Zahlen? | publisher=Friedr. Vieweg &amp; Sohn | location=Braunschweig | year=1888 | url=http://echo.mpiwg-berlin.mpg.de/MPIWG:01MGQHHN |edition=2., unchanged (1893)}}&lt;/ref&gt;
* '''1895''' '''Cantor''' states the theorem in his first paper on set theory and transfinite numbers. He obtains it as an easy consequence of the linear order of cardinal numbers.&lt;ref name="Cantor.1895"&gt;{{citation | author=Georg Cantor |editor1=Adolf Fraenkel (Lebenslauf) |editor2=Ernst Zermelo | title=Gesammelte Abhandlungen mathematischen und philosophischen Inhalts | publisher= Springer | location=Berlin | year=1932 | pages=285 ("Satz B")| url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN237853094}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author=Georg Cantor |title=Beiträge zur Begründung der transfiniten Mengenlehre (1) |url=http://gdz.sub.uni-goettingen.de/index.php?id=img&amp;no_cache=1&amp;IDDOC=36218&amp;IDDOC=36218&amp;branch=&amp;L=1|journal=[[Mathematische Annalen]] |volume=46 |pages=481–512 (Theorem see "Satz B", p.484) |year=1895 |doi=10.1007/bf02124929}}&lt;BR&gt;({{cite journal |author=Georg Cantor |title=Beiträge zur Begründung der transfiniten Mengenlehre (2) |url=http://gdz.sub.uni-goettingen.de/index.php?id=11&amp;PPN=PPN235181684_0049&amp;DMDID=DMDLOG_0024&amp;L=1 |journal=[[Mathematische Annalen]] |volume=49 |pages=207–246 |year= 1897|doi=10.1007/bf01444205 }})&lt;/ref&gt; However, he couldn't prove the latter theorem, which is shown in 1915 to be equivalent to the [[axiom of choice]] by [[Friedrich Moritz Hartogs]].&lt;ref name="Brieskorn.Chatterji.2002"/&gt;&lt;ref&gt;{{citation | author=Friedrich M. Hartogs |editor1=Felix Klein |editor2=Walther von Dyck |editor3=David Hilbert |editor4=Otto Blumenthal | title=Über das Problem der Wohlordnung | journal=[[Mathematische Annalen]] | volume=76 | number=4 | publisher=B.&amp;nbsp;G. Teubner | location=Leipzig | year=1915 | pages=438–443 | ISSN=0025-5831 |url=http://gdz.sub.uni-goettingen.de/index.php?id=11&amp;PPN=PPN235181684_0076&amp;DMDID=DMDLOG_0037&amp;L=1 | doi=10.1007/bf01458215}}&lt;/ref&gt;
* '''1896''' '''Schröder''' announces a proof (as a corollary of a theorem by [[William Stanley Jevons|Jevons]]).&lt;!---taken from 31 Jan 2014 version of [[:en:Cantor–Bernstein–Schroeder theorem#History]], without further sources, and not mentioning Jevons--- ---probably, following source was meant:---&gt;&lt;ref&gt;{{cite journal | author=Ernst Schröder | title=Über G. Cantorsche Sätze | journal=[[Jahresbericht der Deutschen Mathematiker-Vereinigung]] | volume=5 | pages=81–82 | url=http://gdz.sub.uni-goettingen.de/en/dms/loader/img/?PID=GDZPPN002115506 | year=1896 }}&lt;/ref&gt;
* '''1896''' '''Schröder''' publishes a proof sketch&lt;ref&gt;{{citation | author=Ernst Schröder | editor=Kaiserliche Leopoldino-Carolinische Deutsche Akademie der Naturforscher | title=Ueber zwei Definitionen der Endlichkeit und G. Cantor’sche Sätze | journal=Nova Acta | volume=71 | number=6 | publisher=Johann Ambrosius Barth Verlag | location=Halle a.&amp;nbsp;S. | year=1898 | pages=303–376 (proof: p.336–344) | url=https://www.biodiversitylibrary.org/item/45265#page/331/mode/1up}}&lt;/ref&gt; which, however, is shown to be faulty by [[Alwin Reinhold Korselt]] in 1911&lt;ref&gt;{{citation | author=Alwin R. Korselt |editor1=Felix Klein |editor2=Walther von Dyck |editor3=David Hilbert |editor4=Otto Blumenthal | title=Über einen Beweis des Äquivalenzsatzes | journal=[[Mathematische Annalen]] | volume=70 | number=2 | publisher=B.&amp;nbsp;G. Teubner | location=Leipzig | year=1911 | pages=294–296 | ISSN=0025-5831 | url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN235181684_0070&amp;DMDID=DMDLOG_0029 | doi=10.1007/bf01461161}}&lt;/ref&gt; (confirmed by Schröder).&lt;ref name="Brieskorn.Chatterji.2002"/&gt;&lt;ref&gt;Korselt (1911), p.295&lt;/ref&gt;
* '''1897''' '''Bernstein''', a 19 years old student in Cantor's Seminar, presents his proof.&lt;ref name="Deiser.2010"&gt;{{citation | author=Oliver Deiser | title=Einführung in die Mengenlehre – Die Mengenlehre Georg Cantors und ihre Axiomatisierung durch Ernst Zermelo | edition=3rd, corrected | publisher=Springer | location=Berlin/Heidelberg | year=2010 | pages=71, 501 | ISBN=978-3-642-01444-4 | DOI=10.1007/978-3-642-01445-1}}&lt;/ref&gt;&lt;ref name="Suppes.1972"&gt;{{citation | author=[[Patrick Suppes]] | title=Axiomatic Set Theory | edition=1. | publisher=Dover Publications | location=New York | year=1972 | pages=95&amp;nbsp;f. | ISBN=0-486-61630-4 }}&lt;/ref&gt;
* '''1897''' Almost simultaneously, but independently, '''Schröder''' finds a proof.&lt;ref name="Deiser.2010"/&gt;&lt;ref name="Suppes.1972"/&gt;
* '''1897''' After a visit by Bernstein, '''Dedekind''' independently proves the theorem a second time.&lt;!---taken from 31 Jan 2014 version of [[:en:Cantor–Bernstein–Schroeder theorem#History]], without further sources---&gt;
* '''1898''' '''Bernstein''''s proof (not relying on the axiom of choice) is published by [[Émile Borel]] in his book on functions.&lt;ref&gt;{{citation | author=Émile Borel | title=Leçons sur la théorie des fonctions | publisher=Gauthier-Villars et fils | location=Paris | year=1898 | pages=103&amp;nbsp;ff. | url=https://archive.org/stream/leconstheoriefon00borerich#page/n115/mode/2up}}&lt;/ref&gt; (Communicated by Cantor at the 1897 [[International Congress of Mathematicians]] in Zürich.) In the same year, the proof also appears in '''Bernstein''''s dissertation.&lt;ref&gt;{{citation | author=Felix Bernstein | title=Untersuchungen aus der Mengenlehre | publisher=Buchdruckerei des Waisenhauses | location=Halle a.&amp;nbsp;S. | year=1901 | url=https://archive.org/details/untersuchungena00berngoog}}&lt;BR&gt;Reprinted in: {{citation | author=Felix Bernstein |editor1=Felix Klein |editor2=Walther von Dyck |editor3=David Hilbert | title=Untersuchungen aus der Mengenlehre | journal=[[Mathematische Annalen]] | volume=61 | number=1 | publisher=B.&amp;nbsp;G. Teubner | location=Leipzig | year=1905 | pages=117–155, (Theorem see "Satz 1" on p.121) | ISSN=0025-5831  | url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN235181684_0061&amp;DMDID=DMDLOG_0015 | doi=10.1007/bf01457734}}&lt;/ref&gt;&lt;ref name="Brieskorn.Chatterji.2002"/&gt;

Both proofs of Dedekind are based on his famous memoir ''Was sind und was sollen die Zahlen?'' and derive it as a corollary of a proposition equivalent to statement C in Cantor's paper,&lt;ref name="Cantor.1895"/&gt; which reads ''A''&amp;nbsp;⊆&amp;nbsp;''B''&amp;nbsp;⊆&amp;nbsp;''C'' and |''A''|&amp;nbsp;=&amp;nbsp;|''C''| implies |''A''|&amp;nbsp;=&amp;nbsp;|''B''|&amp;nbsp;=&amp;nbsp;|''C''|. Cantor observed this property as early as 1882/83 during his studies in set theory and transfinite numbers and was therefore (implicitly) relying on the [[Axiom of Choice]].&lt;!---taken from 31 Jan 2014 version of [[:en:Cantor–Bernstein–Schroeder theorem#History]], without further sources---&gt;

== Statement C and a transparent proof ==
Statement C  is the special case of the Schröder–Bernstein theorem where the second function ''g'' is the identity (and, hence, the second set ''B'' is a subset of ''A''). 

It is easy to see that statement C implies the general form of the theorem (with ''g'' and ''B'' arbitrary):

Assume that ''ƒ'' injects ''A'' into ''B'' and ''g'' injects ''B'' into ''A''. Then their composition ''gf'' injects ''A'' into ''g''[''B'']. However, ''g''[''B''] is a subset of ''A''. Thus, from statement ''C'', we obtain that ''A'' and ''g''[''B''] are equipotent. Obviously, ''B'' and ''g''[''B''] are equipotent as well. It follows, that ''A'' and ''B'' are equipotent.

A proof of statement ''C'' can be obtained by translating the König proof for the general case above to the present situation. The result becomes much more transparent than the original, and looks as follows.

Assume that ''ƒ'' injects ''A'' into its subset ''C''. Consider the subset ''D'' of ''A'' (the set of ''A''-stoppers, in the König terminology above) which is the union of the infinitely many sets ''A''&amp;nbsp;−&amp;nbsp;''C'', ''ƒ''[''A''&amp;nbsp;−&amp;nbsp;''C''], ''ƒƒ''[''A''&amp;nbsp;−&amp;nbsp;''C'']],&amp;nbsp;...

Consider the function from ''A'' to ''C'' that (i) maps elements ''a'' of ''D'' to their ''ƒ''-image ''ƒ''(''a''), whereas (ii) on ''A''&amp;nbsp;−&amp;nbsp;''D'' it acts as the identity, mapping elements to themselves.

We claim that this function is a bijection from ''A'' onto ''C''. For this, it should be verified that every element of ''C'' has exactly one original. However, if it belongs to ''D'', it has one original which also is an ''f''-original, and if it doesn't belong to ''D'' the only original is the element itself.

== See also ==
* [[Myhill isomorphism theorem]]
* [[Schröder–Bernstein theorem for measurable spaces]]
* [[Schröder–Bernstein theorems for operator algebras]]
* [[Schröder–Bernstein property]]

== Notes ==
{{Reflist|30em}}

== References ==
* ''Proofs from THE BOOK'', p.&amp;nbsp;90. {{isbn|3-540-40460-0}}
*{{citation|mr=3026479|last=Hinkis|first= Arie
|title=Proofs of the Cantor-Bernstein theorem. A mathematical excursion|series= Science Networks. Historical Studies
|volume= 45|publisher= Birkhäuser/Springer|place= Heidelberg|year= 2013
|isbn= 978-3-0348-0223-9|url=https://link.springer.com/book/10.1007/978-3-0348-0224-6/page/1|doi=10.1007/978-3-0348-0224-6 }}

==External links==
*{{MathWorld|title=Schröder-Bernstein Theorem|urlname=Schroeder-BernsteinTheorem}}
*{{nlab|id=Cantor-Schroeder-Bernstein+theorem|title=Cantor-Schroeder-Bernstein theorem}}
* [https://link.springer.com/content/pdf/10.1007%2Fs00283-011-9242-3.pdf Cantor-Bernstein’s Theorem in a Semiring] by Marcel Crabbé.
*{{Citizendium|title=Schröder-Bernstein_theorem}}

{{DEFAULTSORT:Schroeder-Bernstein theorem}}
[[Category:Theorems in the foundations of mathematics]]
[[Category:Cardinal numbers]]
[[Category:Articles containing proofs]]</text>
      <sha1>8ebub41hmhe3zfev01oeec53we103y9</sha1>
    </revision>
  </page>
  <page>
    <title>Sheffer sequence</title>
    <ns>0</ns>
    <id>218596</id>
    <revision>
      <id>862710438</id>
      <parentid>852437477</parentid>
      <timestamp>2018-10-06T05:28:41Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6434">In [[mathematics]], a '''Sheffer sequence''' or '''poweroid''' is a [[polynomial sequence]], i.e., a sequence {&amp;nbsp;''p''&lt;sub&gt;''n''&lt;/sub&gt;(''x'')&amp;nbsp;: ''n''&amp;nbsp;=&amp;nbsp;0,&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;3,&amp;nbsp;.&amp;nbsp;.&amp;nbsp;.&amp;nbsp;} of [[polynomial]]s in which the index of each polynomial equals its [[Degree of a polynomial|degree]], satisfying conditions related to the [[umbral calculus]] in combinatorics. They are named for [[Isador M. Sheffer]].

==Definition==
Fix a polynomial sequence ''p''&lt;sub&gt;''n''&lt;/sub&gt;. Define a linear operator ''Q'' on polynomials in ''x'' by

:&lt;math&gt;Qp_n(x) = np_{n-1}(x)\, .&lt;/math&gt;

This determines ''Q'' on all polynomials. The polynomial sequence ''p''&lt;sub&gt;''n''&lt;/sub&gt; is a ''Sheffer sequence'' if the linear operator ''Q'' just defined is ''shift-equivariant''. Here, we define a linear operator ''Q'' on polynomials to be ''shift-equivariant'' if, whenever ''f''(''x'') = ''g''(''x'' + ''a'') = ''T''&lt;sub&gt;''a''&lt;/sub&gt; ''g''(''x'') is a "shift" of ''g''(''x''), then (''Qf'')(''x'') = (''Qg'')(''x'' + ''a''); i.e., ''Q'' commutes with every [[shift operator]]: ''T''&lt;sub&gt;''a''&lt;/sub&gt;''Q'' =''QT''&lt;sub&gt;''a''&lt;/sub&gt;. Such a ''Q'' is a [[delta operator]].

==Properties==

The set of all Sheffer sequences is a [[group (mathematics)|group]] under the operation of '''umbral composition''' of polynomial sequences, defined as follows. Suppose {&amp;nbsp;''p''&lt;sub&gt;''n''&lt;/sub&gt;(x) : ''n'' = 0, 1, 2, 3,&amp;nbsp;...&amp;nbsp;} and {&amp;nbsp;''q''&lt;sub&gt;''n''&lt;/sub&gt;(x) : ''n'' = 0, 1, 2, 3,&amp;nbsp;...&amp;nbsp;} are polynomial sequences, given by

:&lt;math&gt;p_n(x)=\sum_{k=0}^n a_{n,k}x^k\ \mbox{and}\ q_n(x)=\sum_{k=0}^n b_{n,k}x^k.&lt;/math&gt;

Then the umbral composition &lt;math&gt;p \circ q&lt;/math&gt; is the polynomial sequence whose ''n''th term is

:&lt;math&gt;(p_n\circ q)(x)=\sum_{k=0}^n a_{n,k}q_k(x)=\sum_{0\le k \le \ell \le n} a_{n,k}b_{k,\ell}x^\ell&lt;/math&gt;

(the subscript ''n'' appears in ''p''&lt;sub&gt;''n''&lt;/sub&gt;, since this is the ''n'' term of that sequence, but not in ''q'', since this refers to the sequence as a whole rather than one of its terms).

The neutral element of this group is the standard monomial basis

:&lt;math&gt;e_n(x) = x^n = \sum_{k=0}^n \delta_{n,k} x^k.&lt;/math&gt;

Two important subgroups are the group of [[Appell sequence]]s, which are those sequences for which the operator ''Q'' is mere differentiation, and the group of sequences of [[binomial type]], which are those that satisfy the identity
:&lt;math&gt;p_n(x+y)=\sum_{k=0}^n{n \choose k}p_k(x)p_{n-k}(y).&lt;/math&gt;
A Sheffer sequence {&amp;nbsp;''p''&lt;sub&gt;''n''&lt;/sub&gt;(''x'')&amp;nbsp;: ''n''&amp;nbsp;=&amp;nbsp;0,&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;.&amp;nbsp;.&amp;nbsp;.&amp;nbsp;} is of binomial type if and only if both

:&lt;math&gt;p_0(x) = 1\,&lt;/math&gt;

and

:&lt;math&gt;p_n(0) = 0\mbox{ for } n \ge 1. \,&lt;/math&gt;

The group of Appell sequences is [[abelian group|abelian]]; the group of sequences of binomial type is not. The group of Appell sequences is a [[normal subgroup]]; the group of sequences of binomial type is not. The group of Sheffer sequences is a [[semidirect product]] of the group of Appell sequences and the group of sequences of binomial type. It follows that each [[coset]] of the group of Appell sequences contains exactly one sequence of binomial type. Two Sheffer sequences are in the same such coset if and only if the operator ''Q'' described above &amp;ndash; called the "[[delta operator]]" of that sequence &amp;ndash; is the same linear operator in both cases. (Generally, a ''delta operator'' is a shift-equivariant linear operator on polynomials that reduces degree by one. The term is due to F. Hildebrandt.)

If ''s''&lt;sub&gt;''n''&lt;/sub&gt;(''x'') is a Sheffer sequence and ''p''&lt;sub&gt;''n''&lt;/sub&gt;(''x'') is the one sequence of binomial type that shares the same delta operator, then

:&lt;math&gt;s_n(x+y)=\sum_{k=0}^n{n \choose k}p_k(x)s_{n-k}(y).&lt;/math&gt;

Sometimes the term ''Sheffer sequence'' is ''defined'' to mean a sequence that bears this relation to some sequence of binomial type. In particular, if {&amp;nbsp;''s''&lt;sub&gt;''n''&lt;/sub&gt;(''x'') } is an Appell sequence, then

:&lt;math&gt;s_n(x+y)=\sum_{k=0}^n{n \choose k}x^ks_{n-k}(y).&lt;/math&gt;

The sequence of [[Hermite polynomials]], the sequence of [[Bernoulli polynomials]], and the [[monomial]]s { ''x&lt;sup&gt;n&lt;/sup&gt;'' : ''n'' = 0, 1, 2, ... } are examples of Appell sequences.

A Sheffer sequence ''p''&lt;sub&gt;''n''&lt;/sub&gt; is characterised by its [[exponential generating function]]

:&lt;math&gt; \sum_{n=0}^\infty \frac{p_n(x)}{n!} t^n = A(t) \exp(x B(t)) \, &lt;/math&gt;

where ''A'' and ''B'' are (formal) power series in ''t''. Sheffer sequences are thus examples of [[generalized Appell polynomials]] and hence have an associated [[recurrence relation]].

==Examples==
Examples of polynomial sequences which are Sheffer sequences include:
* The [[Abel polynomials]];
* The [[Bernoulli polynomials]];
* The central factorial polynomials;
* The [[Hermite polynomials]];
* The [[Laguerre polynomials]];
* The [[Mahler polynomials]];
* The [[monomial]]s { ''x&lt;sup&gt;n&lt;/sup&gt;'' : ''n'' = 0, 1, 2, ... } ;
* The [[Mott polynomials]];

==References==
*{{cite journal |last1=Rota |first1=G.-C. |authorlink1=Gian-Carlo Rota |last2=Kahaner |first2=D. |last3=Odlyzko |first3=A. |authorlink3=Andrew Odlyzko |title=On the Foundations of Combinatorial Theory VIII: Finite Operator Calculus |journal=Journal of Mathematical Analysis and Its Applications |volume=42 |issue=3 |date=June 1973 |pages=684–750 |doi=10.1016/0022-247X(73)90172-8}} Reprinted in the next reference.
*{{cite book |last1=Rota |first1=G.-C. |authorlink1=Gian-Carlo Rota |last2=Doubilet |first2=P. |last3=Greene |first3=C. |last4=Kahaner |first4=D. |last5=Odlyzko |first5=A. |last6=Stanley |first6=R. |title=Finite Operator Calculus |publisher=Academic Press |year=1975 |isbn=0-12-596650-4}}
*{{cite journal |last=Sheffer |first=I. M. |authorlink=Isador M. Sheffer |title=Some Properties of Polynomial Sets of Type Zero |journal=[[Duke Mathematical Journal]] |volume=5 |issue=3 |pages=590–622 |year=1939 |doi=10.1215/S0012-7094-39-00549-1}}
*{{Cite book |last=Roman |first=Steven |title=The Umbral Calculus |publisher=Academic Press Inc. [Harcourt Brace Jovanovich Publishers] |location=London |series=Pure and Applied Mathematics |isbn=978-0-12-594380-2 |mr=741185  |year=1984 |volume=111 |url=https://books.google.com/books?id=JpHjkhFLfpgC}} Reprinted by Dover, 2005.

==External links==
*{{MathWorld|ittle=Sheffer Sequence|id=ShefferSequence}}

[[Category:Polynomials]]
[[Category:Factorial and binomial topics]]</text>
      <sha1>evazk2ykxuy4leili0gnuu384n19b8h</sha1>
    </revision>
  </page>
  <page>
    <title>Virtual manipulatives for mathematics</title>
    <ns>0</ns>
    <id>17533891</id>
    <revision>
      <id>860316637</id>
      <parentid>860276001</parentid>
      <timestamp>2018-09-19T20:43:16Z</timestamp>
      <contributor>
        <username>XOR'easter</username>
        <id>30746614</id>
      </contributor>
      <comment>simplest way to disambiguate here is to delete the word</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6486">{{advert|type=advocacy for this technology|date=December 2016}}
In [[mathematics education]], '''virtual manipulatives''' are a relatively new technology modeled after existing [[manipulative (mathematics education)|manipulative]]s such as [[base ten blocks]], [[coins]], [[Toy block|blocks]], [[tangrams]], [[rulers]], [[fraction bars]], [[algebra tiles]], [[geoboard]]s, [[Plane (geometry)|geometric plane]], and [[geometric solid|solids figures]]. They are usually in the form of [[Java applet|Java]] or [[Adobe Flash|Flash]] applets. Virtual manipulatives allow teachers to allow for efficient use of [[Multiple representations (mathematics education)|multiple representations]] and to provide concrete models of abstract mathematical concepts for learners of mathematics. Research suggests that students may also develop more connected understandings of mathematical concepts when they use virtual manipulatives (Moyer, Niezgoda, &amp; Stanley, 2005).&lt;ref&gt;[http://my.nctm.org/eresources/article_summary.asp?URI=TCM2002-02-372a&amp;from=B What are Virtual Manipulatives?]&lt;/ref&gt;

Many{{who|date=December 2016}} believe that virtual manipulatives can be particularly helpful to students with language difficulties, including [[English Language Learners]] (ELL). ELL students usually have trouble explaining what they are learning in mathematics classes. With virtual manipulatives, such students may be able to clarify their thoughts and demonstrate it to others in a much more effective way. For example, with base ten blocks, students may use the place-value layout to show their understanding.

Manipulatives by themselves have little meaning. It is important for teachers to make the mathematical meaning of manipulatives clear and help the  students to build connections between the concrete materials and abstract symbols. Virtual manipulatives usually have this built-in structure. Many virtual manipulative activities give students hints and feedback with pop-ups and help features. More traditional concrete manipulatives are not conducive to comprehension without direct instructor assistance. For example, in using tangrams, students can practically copy a design made from pattern blocks. When a block is near a correct location, it will snap into place. This virtual manipulative includes a hint function that will show the correct location of all the blocks.

Although relatively new, virtual manipulatives can support learning mathematics for all students which includes those with [[learning disabilities]] and ELL learners. Virtual manipulatives can be included into the general academic curriculum and not just used as an extra student activity. If they are used wisely, virtual manipulatives can provide students with opportunities for guided discovery which can help them to build a better understanding of mathematical concepts and ultimately exhibit measurable learning skills.

==Notable collections of virtual manipulatives==
'''[[Wolfram Demonstrations Project]]'''

http://demonstrations.wolfram.com/

[[Wolfram Demonstrations Project]] contains around 11,000 Virtual manipulatives for math, science and engineering. They are provided in [[Computable Document Format|CDF]] format together with source code.

'''Didax Free Manipulatives Library'''

http://www.didax.com/virtual-manipulatives-for-math

Didax is the U.S. branch of Philip &amp; Tacey, Ltd of Hampshire, UK, who developed Unifix₢ Cubes in 1960, a popular math manipulative used throughout the world to teach counting and operations. Unifix cubes were created as a replacement for poppet beads, which rolled off student desks and were expensive to manufacture. The virtual manipulatives in this library are designed to be faithful to their physical counterparts and include minimal navigation or symbolic content.

'''Shodor Interactivate Activities'''

http://www.shodor.org/interactivate/activities/

[[Shodor Education Foundation|Shodor]] is a national resource for computational science education. They have offered online education tools such as Interactivate and the Computational Science Education Reference Desk (CSERD) since 1994. The activities are sorted from Grade 3 through Undergraduate.

'''National Library of Virtual Manipulatives'''

http://nlvm.usu.edu/

Utah State University has offered this collection of internet-based manipulatives since 1999. The activities are sorted from Pre-Kindergarten through High School.

'''Illuminations: Activities'''

http://illuminations.nctm.org/Default.aspx

Illuminations has been found on a section of the website for the National Council of Teachers of Mathematics since 2000. Students and teachers from Pre-Kindergarten through High School can use these interactivities.

'''MSTE at the University of Illinois'''
* The Office for Mathematics, Science, and Technology Education (MSTE) at the University of Illinois at Urbana-Champaign has two good resources. The [http://mste.illinois.edu/resources/ MSTE Online Resource Catalog] has existed since 1994. Also, M2T2 includes an extensive [http://mste.illinois.edu/m2t2/appletslist.html List of Mathematics Applets].

According to their [http://mste.illinois.edu/m2t2/aboutm2t2.html website], "Mathematics Materials for Tomorrow's Teachers (M2T2) are a set of mathematics modules created in the spring of 2000 by a team consisting of teachers, administrators, university researchers, mathematicians, graduate students, and members of the Illinois State Board of Education." They are five modules. Each module is connected to one of the goals for mathematics in the Illinois Learning Standards. The content is at a middle school level.

==References==
{{Reflist}}
* Moyer, P. S., Bolyard, J. J., &amp; Spikell, M. A. (2000). What are virtual manipulatives? [Online]. ''Teaching Children Mathematics,'' 8(6), 372-377. Available: [http://my.nctm.org/eresources/article_summary.asp?URI=TCM2002-02-372a&amp;from=B]
* Moyer, P. S., Niezgoda, D., &amp; Stanley, J. (2005). Young children's use of virtual manipulatives and other forms of mathematical representations. In W. J. Masalaski &amp; P. C. Elliot (Eds.), ''Technology-Supported Mathematics Learning Environments'' (pp.&amp;nbsp;17–34). Reston, VA: National Council of Teachers of Mathematics.

==External links==
* [http://plaza.ufl.edu/youngdj/talks/vms_paper.doc Virtual Manipulatives in Mathematics Education.]
* [http://www.tojet.net/articles/5112.htm Virtual manipulatives in mathematics education: A theoretical framework.]

[[Category:Mathematics education]]</text>
      <sha1>gjkb4h5emthq4hefrca9zgct46vctaa</sha1>
    </revision>
  </page>
  <page>
    <title>Volatility tax</title>
    <ns>0</ns>
    <id>56553748</id>
    <revision>
      <id>840352489</id>
      <parentid>838543887</parentid>
      <timestamp>2018-05-09T10:10:57Z</timestamp>
      <contributor>
        <username>GSS</username>
        <id>26778615</id>
      </contributor>
      <minor/>
      <comment>/* References */[[WP:CHECKWIKI|Checkwiki]] error fix #17. Unnecessary duplicate categories found using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5105">{{sources exist|date=March 2018}}

The '''volatility tax''' is a [[mathematical finance]] term, formalized by [[hedge fund]] manager [[Mark Spitznagel]], describing the effect of large investment losses (or [[Volatility (finance)|volatility]]) on [[Compound interest|compound returns]].&lt;ref name="VolTax1"&gt;[http://www.pionline.com/article/20171120/ONLINE/171119874/commentary-not-all-risk-mitigation-is-created-equal Not all risk mitigation is created equal], ''Pensions &amp; Investments'', November 20, 2017&lt;/ref&gt; It has also been called “volatility drag”.&lt;ref&gt;https://blogs.cfainstitute.org/investor/2015/03/23/the-myth-of-volatility-drag-part-1/&lt;/ref&gt;

==Overview==
As Spitznagel wrote:
{{quote|It is well known that steep portfolio losses crush long-run [[Compound annual growth rate|compound annual growth rates (CAGRs)]]. It just takes too long to recover from a much lower starting point: lose 50% and you need to make 100% to get back to even. I call this cost that transforms, in this case, a portfolio’s +25% average arithmetic return into a zero CAGR (and hence leaves the portfolio with zero profit) the “volatility tax”: it is a hidden, deceptive fee levied on investors by the negative compounding of the markets’ swings.&lt;ref name="VolTax1"/&gt;}}

Quantitatively, the volatility tax is the difference between the [[Arithmetic mean|arithmetic]] and [[Geometric mean|geometric average]] (or “[[ensemble average]]” and “time average”) returns of an asset or portfolio. It thus represents the degree of “[[Ergodic process|non-ergodicity]]” of the geometric average.

Standard quantitative finance assumes that a portfolio’s [[net asset value]] changes follow a [[geometric Brownian motion]] (and thus are [[Log-normal distribution|log-normally distributed]]) with arithmetic average return (or “[[Stochastic drift|drift]]”) &lt;math&gt;\mu&lt;/math&gt;, [[standard deviation]] (or “volatility”) &lt;math&gt;\sigma&lt;/math&gt;, and geometric average return

:&lt;math&gt;\mu-\sigma^2/2&lt;/math&gt;

So the geometric average return is the difference between the arithmetic average return and a function of volatility. This function of volatility

:&lt;math&gt;\sigma^2/2&lt;/math&gt;

represents the volatility tax. (Though this is under the assumption of log-normality, the volatility tax is in fact independent of the assumed or actual return distribution.)

The mathematics behind the volatility tax is such that a very large portfolio loss has a disproportionate impact on the volatility tax that it pays and, as Spitznagel wrote, this is why the most effective risk mitigation focuses on large losses:
{{quote|We can see how this works by considering that the compound (or geometric) average return is mathematically just the average of the [[logarithms]] of the arithmetic price changes. Because the logarithm is a [[concave function]] (it curves down), it increasingly penalizes negative arithmetic returns the more negative they are, and thus the more negative they are, the more they lower the compound average relative to the arithmetic average—and raise the volatility tax.&lt;ref name="VolTax3"&gt;[http://www.pionline.com/article/20180309/ONLINE/180309846/commentary-thanks-to-volatility-you-cant-always-get-what-you-want-in-investing Thanks to volatility, you can’t always get what you want in investing], ''Pensions &amp; Investments'', March 9, 2018&lt;/ref&gt;}}

According to Spitznagel, the goal of risk mitigation strategies is to solve this “vexing non-ergodicity, volatility tax problem” and thus raise a portfolio’s geometric average return, or CAGR, by lowering its volatility tax (and “narrow the gap between our ensemble and time averages”).&lt;ref name="VolTax3"/&gt; This is “the very name of the game in successful investing. It is the key to the kingdom, and explains in a nutshell [[Warren Buffett]]’s cardinal rule, ‘Don’t lose money.’”&lt;ref name="VolTax2"&gt;[https://www.scribd.com/document/370967187/Universa-Mark-Spitznagel-Volatility-Tax ''The Volatility Tax''], Universa Investments, February 2018&lt;/ref&gt; Moreover, “the good news is the entire hedge fund industry basically exists to help with this—to help save on volatility taxes paid by portfolios. The bad news is they haven't done that, not at all.”&lt;ref name="VolTax3"/&gt;

As [[Nassim Nicholas Taleb]] wrote in his 2018 book ''[[Skin in the Game (book)|Skin in the Game]]'', “more than two decades ago, practitioners such as Mark Spitznagel and myself built our entire business careers around the effect of the difference between ensemble and time.”&lt;ref&gt;{{cite book|last1=Taleb|first1=Nassim Nicholas|title=Skin in the Game: Hidden Asymmetries in Daily Life|date=2018|publisher=[[Random House]]|isbn=9780425284629|language=en}}&lt;/ref&gt;

== See also ==
* [[Annual growth %]]
* [[Arithmetic mean]]
* [[Compound interest]]
* [[Exponential growth]]
* [[Geometric Brownian motion]]
* [[Geometric mean]]
* [[Log-normal distribution]]
* [[Mathematical finance]]
* [[Rate of return]]

==References==
{{reflist}}

[[Category:Interest]]
[[Category:Mathematical finance]]
[[Category:Exponentials]]
[[Category:Risk management]]</text>
      <sha1>htync66gn56iekqecm19es9d931ur7d</sha1>
    </revision>
  </page>
</mediawiki>
