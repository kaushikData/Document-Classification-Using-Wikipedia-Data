<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Affine Hecke algebra</title>
    <ns>0</ns>
    <id>10361630</id>
    <revision>
      <id>853006049</id>
      <parentid>846480689</parentid>
      <timestamp>2018-08-01T20:04:25Z</timestamp>
      <contributor>
        <username>CitationCleanerBot</username>
        <id>15270283</id>
      </contributor>
      <minor/>
      <comment>/* References */Various citation &amp; identifier cleanup, plus AWB genfixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3268">In mathematics, an '''affine Hecke algebra''' is the algebra associated to an [[affine Weyl group]], and can be used to prove [[Macdonald's constant term conjecture]] for [[Macdonald polynomial]]s.

==Definition==
Let &lt;math&gt;V&lt;/math&gt; be a Euclidean space of a finite dimension and &lt;math&gt;\Sigma&lt;/math&gt; an [[affine root system]] on &lt;math&gt;V&lt;/math&gt;.  An '''affine Hecke algebra''' is a certain [[associative algebra]] that deforms the [[group algebra]] &lt;math&gt;\mathbb{C}[W]&lt;/math&gt; of the [[Weyl group]] &lt;math&gt; W&lt;/math&gt; of &lt;math&gt;\Sigma&lt;/math&gt; (the [[affine Weyl group]]). It is usually denoted by &lt;math&gt; H(\Sigma,q)&lt;/math&gt;, where &lt;math&gt;q:\Sigma\rightarrow \mathbb{C}&lt;/math&gt; is [[multiplicity function]] that plays the role of deformation parameter. For &lt;math&gt;q\equiv 1&lt;/math&gt; the affine Hecke algebra &lt;math&gt; H(\Sigma,q)&lt;/math&gt; indeed reduces to &lt;math&gt;\mathbb{C}[W]&lt;/math&gt;.

==Generalizations==
[[Ivan Cherednik]] introduced generalizations of affine Hecke algebras, the so-called [[double affine Hecke algebra]] (usually referred to as DAHA). Using this he was able to give a proof of Macdonald's constant term conjecture for [[Macdonald polynomial]]s (building on work of [[Eric Opdam]]). Another main inspiration for Cherednik to consider the double affine Hecke algebra was the [[quantum KZ equations]].

==References==
*{{Cite journal| last1=Cherednik | first1=Ivan  | year=2005 | title=Double affine Hecke algebras | publisher=[[Cambridge University Press]] | series=London Mathematical Society Lecture Note Series  | volume=319 | isbn=978-0-521-60918-0 | mr=2133033}}
*{{cite journal |last1=Nagayoshi |first1=Iwahori |last2=Hideya |first2=Matsumoto |year=1965 |title=On some Bruhat decomposition and the structure of the Hecke rings of p-adic Chevalley groups |url=http://www.numdam.org/item?id=PMIHES_1965__25__5_0 |journal=[[Publications Mathématiques de l'IHÉS]] |volume=25 |pages=5–48 |mr=185016 |zbl=0228.20015 |doi=10.1007/bf02684396}}
*{{cite journal |last1=Kazhdan |first1=David |last2=Lusztig |first2=George |year=1987 |title=Proof of the Deligne-Langlands conjecture for Hecke algebras |journal=[[Inventiones Mathematicae]] |volume=87 |issue=1 |pages=153–21 |mr=862716 |doi=10.1007/BF01389157  |bibcode=1987InMat..87..153K }}
*{{cite journal |last1=Kirillov |first1=Alexander A., Jr |year=1997 |url=http://www.ams.org/bull/1997-34-03/S0273-0979-97-00727-1/home.html |title=Lectures on affine Hecke algebras and Macdonald's conjectures |journal=[[Bulletin of the American Mathematical Society]] |volume=34 |pages=251–292 |doi=10.1090/S0273-0979-97-00727-1 |mr=1441642 |issue=3}}
*{{cite journal |last1=Lusztig |first1=George |title=Notes on affine Hecke algebras  |journal=[[Lecture Notes in Mathematics]] |volume=1804 |pages=71–103 |doi=10.1007/978-3-540-36205-0_3 |mr=1979925}}
*{{cite arxiv |last1=Lusztig |first1=George |year=2001 |title=Lectures on affine Hecke algebras with unequal parameters |eprint=math.RT/0108172}}
*{{cite book |last1=Macdonald |first1=I. G. |year=2003 |title=Affine Hecke Algebras and Orthogonal Polynomials |series=[[Cambridge Tracts in Mathematics]] |volume=157 |publisher=[[Cambridge University Press]] |doi=10.2277/0521824729 |isbn=0-521-82472-9 |mr=1976581}}

[[Category:Algebras]]
[[Category:Representation theory]]</text>
      <sha1>91dvvzxzzj1efnon8kjjkyt05gk3r9t</sha1>
    </revision>
  </page>
  <page>
    <title>Alexander Meduna</title>
    <ns>0</ns>
    <id>45431688</id>
    <revision>
      <id>861121366</id>
      <parentid>831021915</parentid>
      <timestamp>2018-09-25T07:29:58Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2902">{{Multiple issues|
{{BLP sources|date=April 2015}}
{{orphan|date=April 2015}}
}}

'''Alexander Meduna''' (born 1957 in [[Olomouc]], [[Czech Republic]]) is a theoretical computer scientist and expert on compiler design, formal languages and automata. He is a professor of Computer Science at the [[Brno University of Technology]]. Formerly, he taught theoretical computer science at various European and American universities, including the [[University of Missouri]], where he spent a decade teaching advanced topics of formal language theory. He is the author of several books and over sixty papers related to the subject matter.&lt;ref name="Alexander Meduna's Vita"&gt;{{cite web|title=Alexander Meduna's Work (Vita)|url=http://www.fit.vutbr.cz/~meduna/work/doku.php?id=vita:vita|accessdate=24 December 2016}}&lt;/ref&gt;

Meduna is also an artist, who is primarily interested in visual art.&lt;ref name="Alexander Meduna's Work"&gt;{{cite web|title=Alexander Meduna's Work (Art)|url=http://www.fit.vutbr.cz/~meduna/work/doku.php?id=art:art|accessdate=24 December 2016}}&lt;/ref&gt; He had several exhibitions in the USA and Europe. He often performs poetry reading as well.

==Publications==
*{{cite book|last1=Meduna|first1=Alexander|title=Automata and Languages: Theory and Applications|date=2000|publisher=Springer Science &amp; Business Media|isbn=9781852330743}}
*{{cite book|last1=Meduna|first1=Alexander|title=Elements of Compiler Design|date=2007|publisher=CRC Press|isbn=9781420063233}}
*{{cite book|last1=Meduna|first1=Alexander|title=Formal Languages and Computation: Models and Their Applications|date=2014|publisher=CRC Press|isbn=9781466513457}}
*{{cite book|last1=Meduna|first1=Alexander|last2=Švec|first2=Martin|title=Grammars with Context Conditions and Their Applications|date=2005|publisher=John Wiley &amp; Sons|isbn=9780471736554}}
*{{cite book|last1=Meduna|first1=Alexander|last2=Techet|first2=Jiří|title=Scattered Context Grammars and Their Applications|date=2010|publisher=WIT Press|isbn=9781845644260}}
*{{cite book|last1=Meduna|first1=Alexander|last2=Zemek|first2=Petr|title=Regulated Grammars and Automata|date=2014|publisher=Springer|isbn=9781493903696}}
*{{cite book|last1=Meduna|first1=Alexander|last2=Soukup|first2=Ondřej|title=Modern Language Models and Computation: Theory with Applications|date=2017|publisher=Springer|isbn=9783319630991}}

==References==
{{Reflist}}

==External links==
* [http://www.fit.vutbr.cz/~meduna/ Official website]
* [http://dblp.uni-trier.de/pers/hd/m/Meduna:Alexander Publications at DBLP Database]
* [https://link.springer.com/search?facet-author=%22Alexander+Meduna%22 Springer Link]
* [https://www.amazon.com/Alexander-Meduna/e/B001HPP0R0/ Author Page on Amazon.com]

{{authority control}}

{{DEFAULTSORT:Meduna, Alexander}}
[[Category:Living people]]
[[Category:Czech computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:1957 births]]</text>
      <sha1>96fzob7sm58c1hb49ogh47vk0cz9io1</sha1>
    </revision>
  </page>
  <page>
    <title>Alfred George Greenhill</title>
    <ns>0</ns>
    <id>11176721</id>
    <revision>
      <id>810492657</id>
      <parentid>810488882</parentid>
      <timestamp>2017-11-15T16:14:16Z</timestamp>
      <contributor>
        <username>Suslindisambiguator</username>
        <id>12329968</id>
      </contributor>
      <comment>added ref for 1904 ICM</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6158">{{Use dmy dates|date=September 2017}}
{{Use British English|date=September 2017}}
'''Sir (Alfred) George Greenhill''', [[Fellow of the Royal Society|F.R.S.]] (29 November 1847 in [[London]] – 10 February 1927 in London), was a [[Great Britain|British]] [[mathematician]].

George Greenhill was educated at [[Christ's Hospital|Christ's Hospital School]] and from there he went up to [[St John's College, Cambridge]] in 1866.&lt;ref&gt;{{acad|id=GRNL866GA|name=Greenhill, George Alfred}}&lt;/ref&gt; In 1876, Greenhill was appointed professor of mathematics at the [[Royal Military Academy, Woolwich|Royal Military Academy (RMA) at Woolwich]], London, UK.&lt;ref&gt;{{MacTutor Biography|id=Greenhill}}&lt;/ref&gt; He held this chair until his retirement in 1908. His 1892 textbook on applications of [[elliptic functions]] is of acknowledged excellence. He was one of the world's leading experts on applications of elliptic integrals in electromagnetic theory.&lt;ref&gt;{{cite journal|author=Greenhill, Alfred George|title=The elliptic integral in electromagnetic theory|journal=Bull. Amer. Math. Soc.|year=1907|volume=8|pages=447–534|mr=1500798|doi=10.1090/s0002-9947-1907-1500798-2}}&lt;/ref&gt; He was a Plenary Speaker of the [[International Congress of Mathematicians|ICM]] in 1904 at Heidelberg&lt;ref&gt;{{cite book|chapter=''The Mathematical Theory of the Top considered historically'' by A. G. Greenhill|pages=100–108|title=Verhandlungen des dritten Mathematiker-Kongresses in Heidelberg von 8. bis 13. August 1904|location=Leipzig|publisher=B. G. Teubner|year=1905|chapter-url=https://babel.hathitrust.org/cgi/pt?id=miun.aag4063.0004.001;view=1up;seq=114}}&lt;/ref&gt; and an Invited Speaker of the ICM in 1908 at Rome, in 1920 at Strasbourg,&lt;ref&gt;{{cite book|chapter-url=http://www.mathunion.org/ICM/ICM1920/Main/icm1920.0636.0655.ocr.pdf|pages=636–655|year=1921|title=Compte rendu du Congrès international des mathématiciens tenu à Strasbourg du 22 au 30 Septembre 1920|chapter=''The Fourier and Bessel Functions contrasted'' by G. Greenhill}}&lt;/ref&gt; and in 1924 at Toronto.

In 1879, Greenhill developed a [[rule of thumb]] for calculating the optimal [[Rifling#Twist rate|twist]] rate for lead-core bullets. This shortcut uses the bullet's length, needing no allowances for weight or nose shape.&lt;ref&gt;Mosdell, Matthew. ''The Greenhill Formula''. {{cite web|url=http://www.mamut.net/MarkBrooks/newsdet35.htm |title=Archived copy |accessdate=2009-08-19 |deadurl=yes |archiveurl=https://web.archive.org/web/20110718205935/http://www.mamut.net/MarkBrooks/newsdet35.htm |archivedate=2011-07-18 }} (Accessed 2009 AUG 19)&lt;/ref&gt; Greenhill applied this theory to account for the steadiness of flight conferred upon an elongated projectile by [[rifling]]. The eponymous ''Greenhill Formula'', still used today, is:
[[File:3CastBullets.png|thumb|right|[[Cast bullet]]s as cast (left), with gas check (center) and lubricated (right).]]

&lt;math&gt;Twist = \frac{C D^2}{L} \times \sqrt{\frac{SG}{10.9}}&lt;/math&gt;

where:
*C = 150 (use 180 for muzzle velocities higher than 2,800 f/s)
*D = bullet's diameter in inches
*L = bullet's length in inches
*SG = bullet's [[specific gravity]] (10.9 for lead-core bullets, which cancels out the second half of the equation)

The original value of C was 150, which yields a twist rate in inches per turn, when given the diameter D and the length L of the bullet in inches.  This works to velocities of about 840&amp;nbsp;m/s (2800&amp;nbsp;ft/s); above those velocities, a C of 180 should be used.  For instance, with a velocity of 600&amp;nbsp;m/s (2000&amp;nbsp;ft/s), a diameter of {{convert|0.5|in|mm}} and a length of {{convert|1.5|in|mm}}, the Greenhill formula would give a value of 25, which means 1 turn in {{convert|25|in|mm}}.

==Textbooks==
* A. G. Greenhill ''Differential and integral calculus, with applications'' ( London, MacMillan, 1886) [https://archive.org/details/differentialinte00greeuoft archive.org]
* A. G. Greenhill, ''The applications of elliptic functions'' (MacMillan &amp; Co, New York, 1892)&lt;ref&gt;{{cite journal|author=Harkness, J.|authorlink=James Harkness|title=Review: ''The Applications of Elliptic Functions'' by Alfred George Greenhill|journal=Bull. Amer. Math. Soc.|year=1893|volume=2|issue=7|pages=151–157|url=http://www.ams.org/journals/bull/1893-02-07/S0002-9904-1893-00129-8/S0002-9904-1893-00129-8.pdf|doi=10.1090/s0002-9904-1893-00129-8}}&lt;/ref&gt; [http://quod.lib.umich.edu/cgi/t/text/text-idx?c=umhistmath;idno=ACQ7072 University of Michigan Historical Mathematical Collection]
* A. G. Greenhill, ''A treatise on hydrostatics'' (MacMillan, London, 1894) [https://archive.org/details/treatiseonhydros00greeuoft archive.org]
* A. G. Greenhill, ''The dynamics of mechanical flight'' (Constable, London, 1912) [https://archive.org/details/dynamicsofmechan00greerich archive.org]
* A. G. Greenhill, [https://catalog.hathitrust.org/Record/008915822 ''Report on gyroscopic theory''] (Darling &amp; Son, 1914)&lt;ref&gt;{{cite journal|author=Wilson, Edwin Bidwell|authorlink=Edwin Bidwell Wilson|title=Review: ''Report on Gyroscopic Theory'' by Sir G. Greenhill|journal=Bull. Amer. Math. Soc.|year=1917|volume=23|issue=5|pages=241–244|url=http://www.ams.org/journals/bull/1917-23-05/S0002-9904-1917-02930-8/S0002-9904-1917-02930-8.pdf|doi=10.1090/s0002-9904-1917-02930-8}}&lt;/ref&gt;

==References==
{{reflist}}

==External links==
{{Wikisource author}}
* {{wikiquote-inline}}
* Alfred George Greenhill. [http://www.icmihistory.unito.it/portrait/greenhill.php The First Century of the ICMI (1909 - 2008) ]

{{Authority control}}

{{DEFAULTSORT:Greenhill, Alfred George}}
[[Category:1847 births]]
[[Category:1927 deaths]]
[[Category:People from London]]
[[Category:People educated at Christ's Hospital]]
[[Category:Alumni of St John's College, Cambridge]]
[[Category:19th-century British mathematicians]]
[[Category:20th-century British mathematicians]]
[[Category:Royal Medal winners]]
[[Category:Second Wranglers]]
[[Category:Fellows of the Royal Aeronautical Society]]
[[Category:Fellows of the Royal Society]]
[[Category:Knights Bachelor]]
[[Category:Members of the French Academy of Sciences]]
[[Category:De Morgan Medallists]]
[[Category:Ballistics experts]]</text>
      <sha1>q3ul1swcbbvz1n34woh9d25xr7uuv45</sha1>
    </revision>
  </page>
  <page>
    <title>Auxiliary function</title>
    <ns>0</ns>
    <id>11826062</id>
    <revision>
      <id>846241609</id>
      <parentid>835263030</parentid>
      <timestamp>2018-06-17T11:15:22Z</timestamp>
      <contributor>
        <username>ThomasHales</username>
        <id>33894759</id>
      </contributor>
      <minor/>
      <comment>/* A proof of the Hermite–Lindemann theorem */ link to Lindemann-Weierstrass theorem added.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16248">In [[mathematics]], '''auxiliary functions''' are an important construction in [[transcendental number theory]].  They are [[Function (mathematics)|functions]] that appear in most proofs in this area of mathematics and that have specific, desirable properties, such as taking the value zero for many arguments, or having a zero of high [[Multiplicity (mathematics)|order]] at some point.&lt;ref&gt;Waldschmidt (2008).&lt;/ref&gt;

==Definition==

Auxiliary functions are not a rigorously defined kind of function, rather they are functions which are either explicitly constructed or at least shown to exist and which provide a contradiction to some assumed hypothesis, or otherwise prove the result in question.  Creating a function during the course of a proof in order to prove the result is not a technique exclusive to transcendence theory, but the term "auxiliary function" usually refers to the functions created in this area.

==Explicit functions==

===Liouville's transcendence criterion===

Because of the naming convention mentioned above, auxiliary functions can be dated back to their source simply by looking at the earliest results in transcendence theory.  One of these first results was [[Joseph Liouville|Liouville's]] proof that [[transcendental numbers]] exist when he showed that the so called [[Liouville number]]s were transcendental.&lt;ref&gt;Liouville (1844).&lt;/ref&gt;  He did this by discovering a transcendence criterion which these numbers satisfied.  To derive this criterion he started with a general [[algebraic number]] α and found some property that this number would necessarily satisfy. The auxiliary function he used in the course of proving this criterion was simply the [[Minimal polynomial (field theory)|minimal polynomial]] of α, which is the [[Irreducibility (mathematics)|irreducible]] polynomial ''f'' with integer coefficients such that ''f''(α)&amp;nbsp;=&amp;nbsp;0.  This function can be used to estimate how well the algebraic number α can be estimated by [[rational number]]s ''p''/''q''.  Specifically if α has degree ''d'' at least two then he showed that

:&lt;math&gt;\left|f\left(\frac{p}{q}\right)\right|\geq\frac{1}{q^d},&lt;/math&gt;

and also, using the [[mean value theorem]], that there is some constant depending on α, say ''c''(α), such that

:&lt;math&gt;\left|f\left(\frac{p}{q}\right)\right| \leq c(\alpha)\left|\alpha-\frac{p}{q}\right|.&lt;/math&gt;

Combining these results gives a property that the algebraic number must satisfy; therefore any number not satisfying this criterion must be transcendental.

The auxiliary function in Liouville's work is very simple, merely a polynomial that vanishes at a given algebraic number.  This kind of property is usually the one that auxiliary functions satisfy.  They either vanish or become very small at particular points, which is usually combined with the assumption that they do not vanish or can't be too small to derive a result.

===Fourier's proof of the irrationality of ''e''===

Another simple, early occurrence is in [[Joseph Fourier|Fourier's]] proof of the irrationality of ''e'',&lt;ref&gt;Hermite (1873).&lt;/ref&gt; though the notation used usually disguises this fact.  Fourier's proof used the power series of the [[exponential function]]:
:&lt;math&gt;e^x=\sum_{n=0}^{\infty} \frac{x^n}{n!}.&lt;/math&gt;
By truncating this power series after, say, ''N''&amp;nbsp;+&amp;nbsp;1 terms we get a polynomial with rational coefficients of degree ''N'' which is in some sense "close" to the function ''e''&lt;sup&gt;''x''&lt;/sup&gt;.  Specifically if we look at the auxiliary function defined by the remainder:
:&lt;math&gt;R(x)=e^x-\sum_{n=0}^{N} \frac{x^n}{n!}&lt;/math&gt;
then this function—an [[exponential polynomial]]—should take small values for ''x'' close to zero.  If ''e'' is a rational number then by letting ''x''&amp;nbsp;=&amp;nbsp;1 in the above formula we see that ''R''(1) is also a rational number.  However, Fourier proved that ''R''(1) could not be rational by eliminating every possible denominator.  Thus ''e'' cannot be rational.

===Hermite's proof of the irrationality of ''e''&lt;sup&gt;''r''&lt;/sup&gt;===

[[Hermite]] extended the work of Fourier by approximating the function ''e''&lt;sup&gt;''x''&lt;/sup&gt; not with a polynomial but with a [[rational function]], that is a quotient of two polynomials.  In particular he chose polynomials ''A''(''x'') and ''B''(''x'') such that the auxiliary function ''R'' defined by

:&lt;math&gt;R(x)=B(x)e^x-A(x)&lt;/math&gt;

could be made as small as he wanted around ''x''&amp;nbsp;=&amp;nbsp;0.  But if ''e''&lt;sup&gt;''r''&lt;/sup&gt; were rational then ''R''(''r'') would have to be rational with a particular denominator, yet Hermite could make ''R''(''r'') too small to have such a denominator, hence a contradiction.

===Hermite's proof of the transcendence of ''e''===

To prove that ''e'' was in fact transcendental, Hermite took his work one step further by approximating not just the function ''e''&lt;sup&gt;''x''&lt;/sup&gt;, but also the functions ''e''&lt;sup&gt;''kx''&lt;/sup&gt; for integers ''k''&amp;nbsp;=&amp;nbsp;1,...,''m'', where he assumed ''e'' was algebraic with degree ''m''.  By approximating ''e''&lt;sup&gt;''kx''&lt;/sup&gt; by rational functions with integer coefficients and with the same denominator, say ''A''&lt;sub&gt;''k''&lt;/sub&gt;(''x'')&amp;nbsp;/&amp;nbsp;''B''(''x''), he could define auxiliary functions ''R''&lt;sub&gt;''k''&lt;/sub&gt;(''x'') by

:&lt;math&gt;R_k(x)=B(x)e^{kx}-A_k(x).&lt;/math&gt;
For his contradiction Hermite supposed that ''e'' satisfied the polynomial equation with integer coefficients ''a''&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;+&amp;nbsp;''a''&lt;sub&gt;1&lt;/sub&gt;''e''&amp;nbsp;+&amp;nbsp;...&amp;nbsp;+&amp;nbsp;''a''&lt;sub&gt;''m''&lt;/sub&gt;''e''&lt;sup&gt;''m''&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;0.  Multiplying this expression through by ''B''(1) he noticed that it implied

:&lt;math&gt;R=a_0+a_1 R_1(1) + \cdots +a_m R_m(1)=a_1 A_1(1)+ \cdots +a_m A_m(1).&lt;/math&gt;

The right hand side is an integer and so, by estimating the auxiliary functions and proving that 0&amp;nbsp;&lt;&amp;nbsp;|''R''|&amp;nbsp;&lt;&amp;nbsp;1 he derived the necessary contradiction.

==Auxiliary functions from the pigeonhole principle==
{{main|Siegel's lemma}}
The auxiliary functions sketched above can all be explicitly calculated and worked with.  A breakthrough by [[Axel Thue]] and [[Carl Ludwig Siegel]] in the twentieth century was the realisation that these functions don't necessarily need to be explicitly known &amp;ndash; it can be enough to know they exist and have certain properties.  Using the [[Pigeonhole Principle]] Thue, and later Siegel, managed to prove the existence of auxiliary functions which, for example, took the value zero at many different points, or took high order zeros at a smaller collection of points.  Moreover they proved it was possible to construct such functions without making the functions too large.&lt;ref&gt;Thue  (1977) and Siegel (1929).&lt;/ref&gt;  Their auxiliary functions were not explicit functions, then, but by knowing that a certain function with certain properties existed, they used its properties to simplify the transcendence proofs of the nineteenth century and give several new results.&lt;ref&gt;Siegel (1932).&lt;/ref&gt;

This method was picked up on and used by several other mathematicians, including [[Alexander Gelfond]] and [[Theodor Schneider]] who used it independently to prove the [[Gelfond–Schneider theorem]].&lt;ref&gt;Gel'fond (1934) and Schneider (1934).&lt;/ref&gt;  [[Alan Baker (mathematician)|Alan Baker]] also used the method in the 1960s for his work on linear forms in logarithms and ultimately [[Baker's theorem]].&lt;ref&gt;Baker and Wüstholz (2007).&lt;/ref&gt;  Another example of the use of this method from the 1960s is outlined below.

===Auxiliary polynomial theorem===
Let β equal the cube root of ''b/a'' in the equation ''ax''&lt;sup&gt;3&lt;/sup&gt; + ''bx''&lt;sup&gt;3&lt;/sup&gt; = ''c'' and assume ''m'' is an integer that satisfies ''m'' + 1 &gt; 2''n''/3 ≥ ''m'' ≥ 3 where ''n'' is a positive integer.

Then there exists

: &lt;math&gt;F(X,Y) = P(X) + Y*Q(X)&lt;/math&gt;

such that

: &lt;math&gt;\sum_{i=0}^{m+n} u_i X^i = P(X),&lt;/math&gt;

: &lt;math&gt;\sum_{i=0}^{m+n} v_i X^i = Q(X).&lt;/math&gt;

The auxiliary polynomial theorem states

: &lt;math&gt;\max_{0 \le i \le m+n} {(|u_i|,|v_i|)}\le 2b^{9(m+n)}.&lt;/math&gt;

===A theorem of Lang===
{{main|Schneider–Lang theorem}}
In the 1960s [[Serge Lang]] proved a result using this non-explicit form of auxiliary functions.  The theorem implies both the [[Hermite–Lindemann theorem|Hermite–Lindemann]] and [[Gelfond–Schneider theorem]]s.&lt;ref&gt;Lang (1966).&lt;/ref&gt;  The theorem deals with a [[number field]] ''K'' and [[meromorphic]] functions ''f''&lt;sub&gt;1&lt;/sub&gt;,...,''f''&lt;sub&gt;''N''&lt;/sub&gt; of [[Entire function|order]] at most ''ρ'', at least two of which are algebraically independent, and such that if we differentiate any of these functions then the result is a polynomial in all of the functions.  Under these hypotheses the theorem states that if there are ''m'' distinct [[complex number]]s ω&lt;sub&gt;1&lt;/sub&gt;,...,ω&lt;sub&gt;''m''&lt;/sub&gt; such that ''f''&lt;sub&gt;''i''&lt;/sub&gt;&amp;nbsp;(ω&lt;sub&gt;''j''&amp;nbsp;&lt;/sub&gt;) is in ''K'' for all combinations of ''i'' and ''j'', then ''m'' is bounded by
:&lt;math&gt;m\leq 20\rho [K:\mathbb{Q}].&lt;/math&gt;

To prove the result Lang took two algebraically independent functions from ''f''&lt;sub&gt;1&lt;/sub&gt;,...,''f''&lt;sub&gt;''N''&lt;/sub&gt;, say ''f'' and ''g'', and then created an auxiliary function which was simply a polynomial ''F'' in ''f'' and ''g''.  This auxiliary function could not be explicitly stated since ''f'' and ''g'' are not explicitly known.  But using [[Siegel's lemma]] Lang showed how to make ''F'' in such a way that it vanished to a high order at the ''m'' complex numbers
ω&lt;sub&gt;1&lt;/sub&gt;,...,ω&lt;sub&gt;''m''&lt;/sub&gt;.  Because of this high order vanishing it can be shown that a high-order derivative of ''F'' takes a value of small size one of the ω&lt;sub&gt;''i''&lt;/sub&gt;s, "size" here referring to an algebraic property of a number.  Using the [[maximum modulus principle]] Lang also found a separate way to estimate the absolute values of derivatives of ''F'', and using standard results comparing the size of a number and its absolute value he showed that these estimates were contradicted unless the claimed bound on ''m'' holds.

==Interpolation determinants==

After the myriad of successes gleaned from using existent but not explicit auxiliary functions, in the 1990s Michel Laurent introduced the idea of interpolation determinants.&lt;ref&gt;Laurent (1991).&lt;/ref&gt;  These are alternants &amp;ndash; determinants of matrices of the form
:&lt;math&gt;\mathcal{M}=\left(\varphi_i(\zeta_j)\right)_{1\leq i,j\leq N}&lt;/math&gt;
where φ&lt;sub&gt;''i''&lt;/sub&gt; are a set of functions interpolated at a set of points ζ&lt;sub&gt;''j''&lt;/sub&gt;.  Since a determinant is just a polynomial in the entries of a matrix, these auxiliary functions succumb to study by analytic means.  A problem with the method was the need to choose a basis before the matrix could be worked with.  A development by Jean-Benoît Bost removed this problem with the use of [[Arakelov theory]],&lt;ref&gt;Bost (1996).&lt;/ref&gt; and research in this area is ongoing.  The example below gives an idea of the flavour of this approach.

===A proof of the Hermite–Lindemann theorem===

One of the simpler applications of this method is a proof of the real version of the [[Lindemann–Weierstrass theorem|Hermite–Lindemann theorem]].  That is, if α is a non-zero, real algebraic number, then ''e''&lt;sup&gt;α&lt;/sup&gt; is transcendental.  First we let ''k'' be some natural number and ''n'' be a large multiple of ''k''.  The interpolation determinant considered is the determinant '''Δ''' of the ''n''&lt;sup&gt;4&lt;/sup&gt;&amp;times;''n''&lt;sup&gt;4&lt;/sup&gt; matrix
:&lt;math&gt;\left(\{\exp(j_2x)x^{j_1-1}\}^{(i_1-1)}\Big|_{x=(i_2-1)\alpha}\right).&lt;/math&gt;
The rows of this matrix are indexed by 1&amp;nbsp;≤&amp;nbsp;''i''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;≤&amp;nbsp;''n''&lt;sup&gt;4&lt;/sup&gt;/''k'' and 1&amp;nbsp;≤&amp;nbsp;''i''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;≤&amp;nbsp;''k'', while the columns are indexed by 1&amp;nbsp;≤&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;≤&amp;nbsp;''n''&lt;sup&gt;3&lt;/sup&gt; and 1&amp;nbsp;≤&amp;nbsp;''j''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;≤&amp;nbsp;''n''.  So the functions in our matrix are monomials in ''x'' and ''e''&lt;sup&gt;''x''&lt;/sup&gt; and their derivatives, and we are interpolating at the ''k'' points 0,α,2α,...,(''k''&amp;nbsp;&amp;minus;&amp;nbsp;1)α.  Assuming that ''e''&lt;sup&gt;α&lt;/sup&gt; is algebraic we can form the number field '''Q'''(α,''e''&lt;sup&gt;α&lt;/sup&gt;) of degree ''m'' over '''Q''', and then multiply '''Δ''' by a suitable [[denominator]] as well as all its images under the embeddings of the field '''Q'''(α,''e''&lt;sup&gt;α&lt;/sup&gt;) into '''C'''.  For algebraic reasons this product is necessarily an integer, and using arguments relating to [[Wronskian]]s it can be shown that it is non-zero, so its absolute value is an integer Ω&amp;nbsp;≥&amp;nbsp;1.

Using a version of the [[mean value theorem]] for matrices it is possible to get an analytic bound on Ω as well, and in fact using [[Big O notation|big-O]] notation we have
:&lt;math&gt;\Omega=O\left(\exp\left(\left(\frac{m+1}{k}-\frac{3}{2}\right)n^8\log n\right)\right).&lt;/math&gt;
The number ''m'' is fixed by the degree of the field '''Q'''(α,''e''&lt;sup&gt;α&lt;/sup&gt;), but ''k'' is the number of points we are interpolating at, and so we can increase it at will.  And once ''k''&amp;nbsp;&gt;&amp;nbsp;2(''m''&amp;nbsp;+&amp;nbsp;1)/3 we will have Ω&amp;nbsp;→&amp;nbsp;0, eventually contradicting the established condition Ω&amp;nbsp;≥&amp;nbsp;1.  Thus ''e''&lt;sup&gt;α&lt;/sup&gt; cannot be algebraic after all.&lt;ref&gt;Adapted from Pila (1993).&lt;/ref&gt;

==Notes==
{{Reflist}}

==References==
* {{cite web | last=Waldschmidt | first=Michel | title=An Introduction to Irrationality and Transcendence Methods | url=http://www.math.jussieu.fr/~miw/articles/pdf/AWSLecture1.pdf}}
* {{cite journal | last=Liouville | first=Joseph | authorlink=Joseph Liouville | title=Sur des classes très étendues de quantités dont la valeur n'est ni algébrique, ni même réductible à des irrationnelles algébriques | journal=J. Math. Pures et Appl. | volume=18 | pages=883–885, and 910–911 | year=1844}}
* {{cite journal | last=Hermite | first=Charles | authorlink=Charles Hermite | title=Sur la fonction exponentielle | journal=C. R. Acad. Sci. Paris | volume=77 | year=1873}}
* {{cite book | last=Thue | first=Axel | authorlink=Axel Thue | title=Selected Mathematical Papers | publisher=Universitetsforlaget | location=Oslo | year=1977}}
* {{cite journal | last=Siegel | first=Carl Ludwig | authorlink=Carl Ludwig Siegel | title=Über einige Anwendungen diophantischer Approximationen | journal=Abhandlungen Akad. Berlin | volume=1 | page=70 | year=1929}}
* {{cite journal | last=Siegel | first=Carl Ludwig | title=Über die Perioden elliptischer Funktionen | journal=Journal für die reine und angewandte Mathematik | volume=167 | pages=62–69 | year=1932 |doi=10.1515/crll.1932.167.62}}
* {{cite journal | last=Gel'fond | first=A. O. | authorlink=Alexander Gelfond | title=Sur le septième Problème de D. Hilbert | journal=Izv. Akad. Nauk SSSR | volume=7 | pages=623–630 | year=1934}}
* {{cite journal | last=Schneider | first=Theodor | authorlink=Theodor Schneider | title=Transzendenzuntersuchungen periodischer Funktionen. I. Transzendend von Potenzen | journal=J. reine angew. Math. | volume=172 | pages=65–69 | year=1934}}
* {{Citation | last1=Baker | first1=Alan | authorlink=Alan Baker (mathematician) | last2=Wüstholz | first2=G. | title=Logarithmic forms and Diophantine geometry | periodical=New Mathematical Monographs | volume=9 | publisher=Cambridge University Press | page=198 | year=2007}}
* {{cite book | last=Lang | first=Serge | authorlink=Serge Lang | title=Introduction to Transcendental Numbers | publisher=Addison–Wesley Publishing Company | year=1966}}
* {{cite journal | last=Laurent | first=Michel | title=Sur quelques résultats récents de transcendance | journal=Astérisque | volume=198–200 | pages=209–230 | year=1991}}
* {{cite journal | last=Bost | first=Jean-Benoît | title=Périodes et isogénies des variétés abéliennes sur les corps de nombres (d'après D. Masser et G. Wüstholz) | journal=Astérisque | volume=237 | page=795 | year=1996}}
* {{cite journal |authorlink=Jonathan Pila | last=Pila | first=Jonathan | title=Geometric and arithmetic postulation of the exponential function | journal=J. Austral. Math. Soc. |series=A | volume=54 | pages=111–127 | year=1993 | doi=10.1017/s1446788700037022}}

{{DEFAULTSORT:Auxiliary Function}}
[[Category:Number theory]]
[[Category:Diophantine approximation]]</text>
      <sha1>nwd5h0yx491973id9c6t2wqkcqtww54</sha1>
    </revision>
  </page>
  <page>
    <title>Behrens–Fisher problem</title>
    <ns>0</ns>
    <id>2908018</id>
    <revision>
      <id>871578957</id>
      <parentid>867231632</parentid>
      <timestamp>2018-12-02T01:51:40Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16450">{{unsolved|statistics|Only approximate solutions are known}}

In [[statistics]], the '''Behrens–Fisher problem''', named after [[Walter Behrens (statistician)|Walter Behrens]] and [[Ronald Fisher]], is the problem of [[interval estimation]] and [[hypothesis testing]] concerning the difference between the means of two [[normal distribution|normally distributed]] populations when the [[variance]]s of the two populations are not assumed to be equal, based on two [[statistical independence|independent]] samples.

==Specification==
One difficulty with discussing the Behrens–Fisher problem and proposed solutions, is that there are many different interpretations of what is meant by "the Behrens–Fisher problem". These differences involve not only what is counted as being a relevant solution, but even the basic statement of the context being considered.

===Context===
Let ''X''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''X''&lt;sub&gt;''n''&lt;/sub&gt; and ''Y''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''Y''&lt;sub&gt;''m''&lt;/sub&gt; be [[i.i.d.]] samples from two populations which both come from the same [[location-scale family]] of distributions. The scale parameters are assumed to be unknown and not necessarily equal, and the problem is to assess whether the location parameters can reasonably be treated as equal. Lehmann&lt;ref&gt;Lehmann (1975) p.95&lt;/ref&gt; states that "the Behrens–Fisher problem" is used both for this general form of model when the family of distributions is arbitrary and for when the restriction to a [[normal distribution]] is made. While Lehmann discusses a number of approaches to the more general problem, mainly based on nonparametrics,&lt;ref&gt;Lehmann (1975) Section 7&lt;/ref&gt; most other sources appear to use "the Behrens–Fisher problem" to refer only to the case where the distribution is assumed to be normal: most of this article makes this assumption.

===Requirements of solutions===
Solutions to the Behrens–Fisher problem have been presented that make use of either a [[frequentist inference|classical]] or a [[Bayesian inference]] point of view and either solution would be notionally invalid judged from the other point of view. If consideration is restricted to classical statistical inference only, it is possible to seek solutions to the inference problem that are simple to apply in a practical sense, giving preference to this simplicity over any inaccuracy in the corresponding probability statements. Where exactness of the significance levels of statistical tests is required, there may be an additional requirement that the procedure should make maximum use of the statistical information in the dataset. It is well known that an exact test can be gained by randomly discarding data from the larger dataset until the sample sizes are equal, assembling data in pairs and taking differences, and then using an ordinary [[t-test]] to test for the mean-difference being zero: clearly this would not be "optimal" in any sense.

The task of specifying interval estimates for this problem is one where a frequentist approach fails to provide an exact solution, although some approximations are available. Standard Bayesian approaches also fail to provide an answer that can be expressed as straightforward simple formulae, but modern computational methods of Bayesian analysis do allow essentially exact solutions to be found.{{Citation needed|date=July 2014}} Thus study of the problem can be used to elucidate the differences between the frequentist and Bayesian approaches to interval estimation.

==Outline of different approaches==

===Behrens and Fisher approach===
[[Ronald Fisher]] in 1935 introduced [[fiducial inference]]&lt;ref&gt;{{cite journal | last1 = Fisher | first1 = R. A. | year = 1935 | title = The fiducial argument in statistical inference | url = | journal = Annals of Eugenics | volume = 8 | issue = | pages = 391–398 }}&lt;/ref&gt;&lt;ref&gt;[http://www.hss.cmu.edu/philosophy/seidenfeld/relating%20to%20Fisher/Fisher's%20Fiducial%20Argument%20and%20Bayes%20Theorem.pdf R. A. Fisher's Fiducial Argument and Bayes' Theorem by Teddy Seidenfeld]&lt;/ref&gt; in order to apply it to this problem. He referred to an earlier paper by [[Walter Ulrich Behrens]] from 1929. Behrens and Fisher proposed to find the [[probability distribution]] of

:&lt;math&gt; T \equiv {\bar x_1 - \bar x_2 \over \sqrt{s_1^2/n_1 + s_2^2/n_2}} &lt;/math&gt;

where &lt;math&gt; \bar x_1 &lt;/math&gt; and &lt;math&gt; \bar x_2 &lt;/math&gt; are the two [[sample mean]]s, and ''s''&lt;sub&gt;1&lt;/sub&gt; and ''s''&lt;sub&gt;2&lt;/sub&gt; are their [[standard deviation]]s.  See [[Behrens–Fisher distribution]].  Fisher approximated the distribution of this by ignoring the random variation of the relative sizes of the standard deviations,

: &lt;math&gt; {s_1 / \sqrt{n_1} \over \sqrt{s_1^2/n_1 + s_2^2/n_2}}. &lt;/math&gt;

Fisher's solution provoked controversy because it did not have the property that the hypothesis of equal means would be [[significance level|rejected with probability α]] if the means were in fact equal. Many other methods of treating the problem have been proposed since, and the effect on the resulting confidence intervals have been investigated.&lt;ref&gt;[https://www.researchgate.net/publication/313652727_Comparison_of_confidence_intervals_for_the_behrens_fisher_problem Sezer, A. et al. Comparison of confidence intervals for the Behrens-Fisher Problem ''Comm. Stats.'' 2015]&lt;/ref&gt;

===Welch's approximate t solution===
{{Main|Welch's t test|Welch–Satterthwaite equation}}
A widely used method is that of [[B. L. Welch]],&lt;ref&gt;Welch (1938, 1947)&lt;/ref&gt; who, like Fisher, was at [[University College London]]. The variance of the mean difference

: &lt;math&gt;\bar d =\bar x_1 - \bar x_2 &lt;/math&gt;

results in

: &lt;math&gt; s_{\bar d}^2 = \frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}. &lt;/math&gt;

Welch (1938) approximated the distribution of &lt;math&gt;s_{\bar d}^2&lt;/math&gt; by the Type III [[Pearson distribution]] (a scaled [[chi-squared distribution]]) whose first two [[Moment (mathematics)|moments]] agree with that of &lt;math&gt;s_{\bar d}^2&lt;/math&gt;. This applies to the following number of degrees of freedom (d.f.), which is generally non-integer:

:&lt;math&gt; \nu \approx {(\gamma_1 + \gamma_2)^2 \over \gamma_1^2/(n_1-1) + \gamma_2^2/(n_2-1)} \quad \text{ where }\gamma_i = \sigma_i^2/n_i. &lt;/math&gt;

Under the null hypothesis of equal expectations, {{nowrap|''μ''&lt;sub&gt;1&lt;/sub&gt; {{=}} ''μ''&lt;sub&gt;2&lt;/sub&gt;}}, the distribution of the Behrens-Fisher statistic ''T'', which also depends on the variance ratio ''σ''&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;/''σ''&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;, could now be approximated by [[Student's t distribution]] with these ''ν'' degrees of freedom. But this ''ν'' contains the population variances ''σ&lt;sub&gt;i&lt;/sub&gt;''&lt;sup&gt;2&lt;/sup&gt;, and these are unknown. The following estimate only replaces the population variances by the sample variances:

:&lt;math&gt;\hat\nu \approx {(g_1 + g_2)^2 \over g_1^2/(n_1-1) + g_2^2/(n_2-1)} \quad \text{ where } g_i = s_i^2/n_i.&lt;/math&gt;

This &lt;math&gt;\hat\nu&lt;/math&gt; is a random variable. A t distribution with a random number of degrees of freedom does not exist.  Nevertheless, the Behrens-Fisher ''T'' can be compared with a corresponding quantile of [[Student's t distribution]] with these estimated number of degrees of freedom, &lt;math&gt;\hat\nu&lt;/math&gt;, which is generally non-integer. In this way, the boundary between acceptance and rejection region of the test statistic ''T'' is calculated based on the empirical variances ''s&lt;sub&gt;i&lt;/sub&gt;''&lt;sup&gt;2&lt;/sup&gt;, in a way that is a smooth function of these.

This method also does not give exactly the nominal rate, but is generally not too far off.{{Citation needed|date=September 2010}} However, if the population variances are equal, or if the samples are rather small and the population variances can be assumed to be approximately equal, it is more accurate to use [[Student's t-test]],{{Citation needed|date=September 2010}}.

===Other approaches===
A number of different approaches to the general problem have been proposed, some of which claim to "solve" some version of the problem. Among these are,&lt;ref name=DMMS/&gt;
:*that of Chapman in 1950,&lt;ref&gt;{{cite journal |last=Chapman |first=D. G. |year=1950 |title=Some two sample tests |journal=[[Annals of Mathematical Statistics]] |volume=21 |issue=4 |pages=601–606 |doi=10.1214/aoms/1177729755 |jstor= }}&lt;/ref&gt;
:*that of Prokof’yev and Shishkin in 1974,&lt;ref&gt;{{cite journal |last=Prokof'yev |first=V. N. |last2=Shishkin |first2=A. D. |year=1974 |title=Successive classification of normal sets with unknown variances |journal=Radio Engng. Electron. Phys |volume=19 |issue=2 |pages=141–143 |doi= }}&lt;/ref&gt;
:*that of Dudewicz and Ahmed in 1998.&lt;ref&gt;Dudewicz &amp; Ahmed (1998, 1999)&lt;/ref&gt;
In Dudewicz’s comparison of selected methods,&lt;ref name=DMMS&gt;Dudewicz, Ma, Mai, and Su (2007)&lt;/ref&gt; it was found that the Dudewicz–Ahmed procedure is recommended for practical use.

==Variants==
A minor variant of the Behrens–Fisher problem has been studied.&lt;ref&gt;Young, G. A., Smith, R. L. (2005) ''Essentials of Statistical Inference'', CUP. {{ISBN|0-521-83971-8}} (page 204)&lt;/ref&gt;  In this instance the problem is, assuming that the two population-means are in fact the same, to make inferences about the common mean: for example, one could require a [[confidence interval]] for the common mean.

==Generalisations==
The immediate generalisation of the problem involves [[multivariate normal distribution]]s with unknown covariance matrices, and is known as the [[multivariate Behrens–Fisher problem]].&lt;ref&gt;Belloni &amp; Didier (2008)&lt;/ref&gt; The [[Nonparametric statistics|nonparametric]] Behrens-Fisher problem does not assume that the distributions are normal.&lt;ref name="Brunner2000"&gt;{{cite journal|last1=Brunner|first1=E.|title=Nonparametric Behrens-Fisher Problem: Asymptotic Theory and a Small Sample Approximation|journal=Biometrical Journal|date=2000|volume=42|pages=17–25|doi=10.1002/(SICI)1521-4036(200001)42:1&lt;17::AID-BIMJ17&gt;3.0.CO;2-U}}&lt;/ref&gt;&lt;ref name="nparcomp"&gt;{{cite journal|last1=Konietschke|first1=Frank|title=nparcomp: An R Software Package for Nonparametric Multiple Comparisons and Simultaneous Confidence Intervals|journal=JSS Journal of Statistical Software|date=2015|volume=64|issue=9|doi=10.18637/jss.v064.i09|url=https://www.jstatsoft.org/article/view/v064i09|accessdate=26 September 2016}}&lt;/ref&gt;

==Notes==
&lt;references/&gt;
{{More footnotes|date=February 2010}}

==References==
*{{cite journal |authorlink=Walter Ulrich Behrens |last=Behrens |first=W. U. |title=Ein Beitrag zur Fehlerberechnung bei wenigen Beobachtungen |journal=Landwirtschaftliche Jahrbücher |volume=68 |year=1929 |pages=807–37 |trans-title=A contribution to error estimation with few observations |publisher=Wiegandt and Hempel |location=Berlin |url=http://catalog.hathitrust.org/Record/007924569 }}
*{{cite journal | last1 = Bellon | first1 = A. | last2 = Didier | first2 = G. | year = 2008 | title = On the Behrens–Fisher Problem: A Globally Convergent Algorithm and a Finite-Sample Study of the [[Wald test|Wald]], [[LR test|LR]] and [[LM test|LM Test]]s | url = | journal = [[Annals of Statistics]] | volume = 36 | issue = 5| pages = 2377–2408 | doi = 10.1214/07-AOS528 | arxiv = 0811.0672 }}
*{{cite journal | last1 = Chang | first1 = CH | last2 = Pal | first2 = N | year = 2008 | title = A revisit to the Behrens-Fisher problem: Comparison of five test methods | url = | journal = Communications in Statistics-Simulation and Computation | volume = 37 | issue = 6| pages = 1064–1085 | doi = 10.1080/03610910802049599 }}
*{{cite journal | last1 = Dudewicz | first1 = E. J. | last2 = Ahmed | first2 = S. U. | year = 1998 | title = New exact and asymptotically optimal solution to the Behrens–Fisher problem, with tables | url = | journal = American Journal of Mathematical and Management Sciences | volume = 18 | issue = | pages = 359–426 | doi=10.1080/01966324.1998.10737471}}
*{{cite journal | last1 = Dudewicz | first1 = E. J. | last2 = Ahmed | first2 = S. U. | year = 1999 | title = New exact and asymptotically optimal heteroscedastic statistical procedures and tables, II. | url = | journal = American Journal of Mathematical and Management Sciences | volume = 19 | issue = | pages = 157–180 | doi=10.1080/01966324.1999.10737478}}
*{{cite journal | last1 = Dudewicz | first1 = E. J. | last2 = Ma | first2 = Y. | last3 = Mai | first3 = S. E. | last4 = Su | first4 = H. | year = 2007 | title = Exact solutions to the Behrens–Fisher problem: Asymptotically optimal and finite sample efficient choice among | url = | journal = Journal of Statistical Planning and Inference | volume = 137 | issue = 5| pages = 1584–1605 | doi = 10.1016/j.jspi.2006.09.007 }}
*{{cite journal | last1 = Fisher | first1 = R. A. | year = 1935 | title = The fiducial argument in statistical inference | url = | journal = Annals of Eugenics | volume = 8 | issue = | pages = 391–398 }}
*{{cite journal | last1 = Fisher | first1 = R. A. | year = 1941 | title = The Asymptotic Approach to Behrens' Integral with further Tables for the d Test of Significance | url = | journal = Annals of Eugenics | volume = 11 | issue = | pages = 141–172 | doi=10.1111/j.1469-1809.1941.tb02281.x}}
*{{cite journal | last1 = Fraser | first1 = D. A. S. | authorlink2 = Judith Rousseau | last2 = Rousseau | first2 = J. | year = 2008 | title = Studentization and deriving accurate p-values | url = | journal = [[Biometrika]] | volume = 95 | issue = 1| pages = 1–16 | doi = 10.1093/biomet/asm093 }}
*Lehmann, E. L. (1975) ''Nonparametrics: Statistical Methods Based on Ranks'', Holden-Day {{Listed Invalid ISBN|0-8162-4996-6}}, McGraw-Hill {{ISBN|0-07-037073-7}}
*[[Harold Ruben|Ruben, H.]] (2002)[http://sankhya.isical.ac.in/search/servlet/SSearch?s_order=2&amp;choice1=author&amp;text1=Ruben&amp;opt1=And&amp;choice2=title&amp;text2=&amp;opt2=And&amp;choice3=title&amp;text3=&amp;opt3=And&amp;choice4=keyword&amp;text4=&amp;rel_yr=equalto&amp;yearsrch=2002&amp;rel_vol=equalto&amp;volumesrch=64&amp;series=on&amp;part=on&amp;amssrch=&amp;num=20&amp;cntr=0 "A simple conservative and robust solution of the Behrens–Fisher problem"], ''[[Sankhya (journal)|Sankhyā:The Indian Journal of Statistics]]'', Series A, 64 (1),139–155.
*{{cite journal | last1 = Pardo | first1 = JA | last2 = Pardo | first2 = MD | year = 2007 | title = A simulation study of a new family of test statistics for the Behrens-Fisher problem | url = | journal = Kybernetes | volume = 36 | issue = 5–6| pages = 806–816 | doi = 10.1108/03684920710749866 }}
*{{cite journal | last1 = Sawilowsky | first1 = Shlomo S | year = 2002 | title = Fermat, Schubert, Einstein, and Behrens–Fisher: The Probable Difference Between Two Means When σ&lt;sub&gt;1&lt;/sub&gt; ≠ σ&lt;sub&gt;2&lt;/sub&gt; | url = http://education.wayne.edu/jmasm/sawilowsky_behrens_fisher.pdf | format = PDF | journal = Journal of Modern Applied Statistical Methods | volume = 1 | issue = 2 | access-date = 2012-03-08 | archive-url = https://web.archive.org/web/20120425091706/http://education.wayne.edu/jmasm/sawilowsky_behrens_fisher.pdf | archive-date = 2012-04-25 | dead-url = yes | df =  }}
*{{cite journal | last1 = Welch | first1 = B. L. | year = 1938 | title = The significance of the difference between two means when the population variances are unequal | url = | journal = [[Biometrika]] | volume = 29 | issue = | pages = 350–62 | doi=10.2307/2332010}}
* {{Citation | last = Welch| first =B. L. | title = The generalization of "Student's" problem when several different population variances are involved | journal = [[Biometrika]] | volume = 34 |issue=1–2 | pages = 28–35 | year = 1947 |doi =10.1093/biomet/34.1-2.28 |mr=19277}}
* {{cite journal | last1 = Voinov | first1 = V. | last2 = Nikulin | first2 = M. | year = 1995 | title = On the problem of means of weighted normal populations | url = | journal = Questiio | volume = 19 | issue = 2| pages = 7–20 }}
*{{cite journal | last1 = Zheng | first1 = SR | last2 = Shi | first2 = NZ | last3 = Ma | first3 = WQ | year = 2010 | title = Statistical inference on difference or ratio of means from heteroscedastic normal populations | url = | journal = Journal of Statistical Planning and Inference | volume = 140 | issue = 5| pages = 1236–1242 | doi = 10.1016/j.jspi.2009.11.010 }}

==External links==
* Dong, B.L. (2004) [http://web.uvic.ca/econ/research/papers/pdfs/ewp0404.pdf The Behrens–Fisher Problem: An Empirical Likelihood Approach] Econometrics Working Paper EWP0404, University of Victoria

{{DEFAULTSORT:Behrens-Fisher Problem}}
[[Category:Mathematical problems]]
[[Category:Statistical hypothesis testing]]</text>
      <sha1>4zrcae1ds5vs93jmfod2otllx4au0c4</sha1>
    </revision>
  </page>
  <page>
    <title>Bicone</title>
    <ns>0</ns>
    <id>13953265</id>
    <revision>
      <id>772504131</id>
      <parentid>772504074</parentid>
      <timestamp>2017-03-27T17:49:28Z</timestamp>
      <contributor>
        <username>Tompop888</username>
        <id>30152266</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/89.154.174.102|89.154.174.102]] ([[User talk:89.154.174.102|talk]]) to last version by Loraof</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1409">[[Image:Bicone.svg|thumb|100px|right]]

A '''bicone''' or '''dicone''' (''bi- ''comes from Latin,'' di-'' from Greek) is the [[dimension|three-dimensional]] [[surface of revolution]] of a [[rhombus]] around one of its [[axes of symmetry]]. Equivalently, a bicone is the surface created by joining two [[Congruence (geometry)|congruent]] [[Cone (geometry)|right circular cones]] base-to-base.

A bicone has [[circular symmetry]] and orthogonal [[bilateral symmetry]].

== Geometry ==
For a circular bicone with radius ''R'' and height center-to-top ''H'', the formula for volume becomes

:&lt;math&gt;V = \frac{2}{3} \pi R^2 H. &lt;/math&gt;

For a right circular cone, the surface area is 
:&lt;math&gt;SA =2\pi R S\,&lt;/math&gt; &amp;nbsp; where &amp;nbsp; &lt;math&gt;S = \sqrt{R^2 + H^2}&lt;/math&gt; &amp;nbsp; is the [[slant height]].

== Related polyhedra ==
A ''bicone'' can be seen as a [[polyhedron|polyhedral]] limiting case of an [[regular polygon|n-gonal]] [[bipyramid]] where ''n'' approaches infinity. It can also be seen as a [[dual polyhedron|dual]] of a [[cylinder (geometry)|cylinder]] as an infinite-side [[Prism (geometry)|prism]].&lt;ref&gt;http://mathworld.wolfram.com/Bicone.html&lt;/ref&gt;

{{Bipyramids}}

==See also==
* [[Sphericon]]
* [[Biconical antenna]]

==References==
{{reflist}}

== External links ==
* {{MathWorld | urlname=Bicone | title=Bicone}}

[[Category:Elementary geometry]]
[[Category:Surfaces]]

{{Elementary-geometry-stub}}</text>
      <sha1>e6dv0lg95vadbnv7a65pjk1o004p0yg</sha1>
    </revision>
  </page>
  <page>
    <title>Bijection, injection and surjection</title>
    <ns>0</ns>
    <id>1830142</id>
    <revision>
      <id>868431993</id>
      <parentid>868431405</parentid>
      <timestamp>2018-11-12T04:36:33Z</timestamp>
      <contributor>
        <username>Cedar101</username>
        <id>374440</id>
      </contributor>
      <minor/>
      <comment>/* Properties */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11027">{| class="wikitable" style="{{float right}}; text-align:center"
! !! surjective !! non-surjective
|-
!injective
|[[File:Bijection.svg|frameless|150x150px]]
'''bijective'''

|[[File:Injection.svg|frameless|150x150px]]
'''injective-only'''
|-

!non-
injective
|[[File:Surjection.svg|frameless|150x150px]]
'''surjective-only'''

|[[File:Total_function.svg|frameless|150x150px]]
''' '''
|}

{| style="margin: 0 0 0 0; float:right"
|- valign="top"
|
|
|- valign="top"
|
|
|}

In [[mathematics]], '''injections''', '''surjections''' and '''bijections''' are classes of [[function (mathematics)|functions]] distinguished by the manner in which ''[[parameter|arguments]]'' (input [[expression (mathematics)|expressions]] from the [[domain (mathematics)|domain]]) and ''[[image (mathematics)|images]]'' (output expressions from the [[codomain]]) are related or ''mapped to'' each other.

A function [[Map (mathematics)|maps]] elements from its domain to elements in its codomain. Given a function &lt;math&gt;f: \; X \to Y&lt;/math&gt;

*The function is '''[[injective function|injective]]''' ('''one-to-one''') if each element of the codomain is mapped to by ''at most'' one element of the domain. An injective function is an '''injection'''. Notationally:
:&lt;math&gt;\forall x, x' \in X, f(x) = f(x') \Rightarrow x = x'.&lt;/math&gt;
: Or, equivalently (using [[Transposition (logic)|logical transposition]]),
:&lt;math&gt;\forall x,x' \in X, x \neq x' \Rightarrow f(x) \neq f(x').&lt;/math&gt;

*The function is '''[[surjective function|surjective]]''' ('''onto''') if each element of the codomain is mapped to by ''at least'' one element of the domain.  (That is, the image and the codomain of the function are equal.) A surjective function is a '''surjection'''. Notationally:
:&lt;math&gt;\forall y \in Y, \exists x \in X \text{ such that } y = f(x).&lt;/math&gt;

*The function is '''[[bijective function|bijective]]''' ('''one-to-one and onto''' or '''one-to-one correspondence''') if each element of the codomain is mapped to by ''exactly'' one element of the domain.  (That is, the function is ''both'' injective and surjective.) A bijective function is a '''bijection'''.

An injective function need not be surjective (not all elements of the codomain may be associated with arguments), and a surjective function need not be injective (some images may be associated with ''more than one'' argument). The four possible combinations of injective and surjective features are illustrated in the adjacent diagrams.

==Injection==
{{main|Injective function}}
{{details|topic=notation|Function (mathematics)#Notation}}
[[Image:Injective composition.svg|thumb|300px|Injective composition: the second function need not be injective.]]
A function is '''injective''' ('''one-to-one''') if each possible element of the codomain is mapped to by at most one argument. Equivalently, a function is injective if it maps distinct arguments to distinct images. An injective function is an '''injection'''. The formal definition is the following.

:The function &lt;math&gt;f: X \to Y&lt;/math&gt; is injective [[iff]] for all &lt;math&gt;x,x' \in X&lt;/math&gt;, we have &lt;math&gt;f(x) = f(x') \Rarr x = x'.&lt;/math&gt;

*A function ''f'' : ''X'' → ''Y'' is injective if and only if ''X'' is empty or ''f'' is left-[[Inverse function|invertible]]; that is, there is a function g : f(X) → X such that ''g'' o ''f'' = identity  function on ''X''. Here f(X) is the image of f.
*Since every function is surjective when its [[codomain]] is restricted to its [[image (mathematics)|image]], every injection induces a bijection onto its image. More precisely, every injection ''f'' : ''X'' → ''Y'' can be factored as a bijection followed by an inclusion as follows. Let ''f''&lt;sub&gt;''R''&lt;/sub&gt; : ''X'' → ''f''(''X'') be ''f'' with codomain restricted to its image, and let ''i'' : ''f''(''X'') → ''Y'' be the inclusion map from ''f''(''X'') into ''Y''. Then ''f'' = ''i'' o ''f''&lt;sub&gt;''R''&lt;/sub&gt;. A dual factorisation is given for surjections below.
*The composition of two injections is again an injection, but if ''g'' o ''f'' is injective, then it can only be concluded that ''f'' is injective. See the figure at right.
*Every [[embedding]] is injective.

==Surjection==
{{main|Surjective function}}
[[Image:Surjective composition.svg|thumb|300px|Surjective composition: the first function need not be surjective.]]
A function is '''surjective''' ('''onto''') if each possible image is mapped to by at least one argument. In other words, each element in the codomain has non-empty [[preimage]]. Equivalently, a function is surjective if its image is equal to its codomain. A surjective function is a '''surjection'''. The formal definition is the following.

:The function &lt;math&gt;f: X \to Y&lt;/math&gt; is surjective [[iff]] for all &lt;math&gt;y \in Y&lt;/math&gt;, there is &lt;math&gt;x \in X&lt;/math&gt; such that &lt;math&gt;f(x) = y.&lt;/math&gt;

*A function ''f'' : ''X'' → ''Y'' is surjective if and only if it is right-invertible, that is, if and only if there is a function ''g'': ''Y'' → ''X'' such that ''f'' o ''g'' = identity  function on ''Y''. (This statement is equivalent to the [[axiom of choice]].)
*By collapsing all arguments mapping to a given fixed image, every surjection induces a bijection defined on a quotient of its domain. More precisely, every surjection ''f'' : ''X'' → ''Y'' can be factored as a non-bijection followed by a bijection as follows. Let ''X''/~ be the equivalence classes of ''X'' under the following equivalence relation: ''x'' ~ ''y'' if and only if ''f''(''x'') = ''f''(''y''). Equivalently, ''X''/~ is the [[Set (mathematics)|set]] of all preimages under ''f''. Let ''P''(~) : ''X'' → ''X''/~ be the projection map which sends each ''x'' in ''X'' to its equivalence class [''x'']&lt;sub&gt;~&lt;/sub&gt;, and let ''f''&lt;sub&gt;''P''&lt;/sub&gt; : ''X''/~ → ''Y'' be the well-defined function given by ''f''&lt;sub&gt;''P''&lt;/sub&gt;([''x'']&lt;sub&gt;~&lt;/sub&gt;) = ''f''(''x''). Then ''f'' = ''f''&lt;sub&gt;''P''&lt;/sub&gt; o ''P''(~). A dual factorisation is given for injections above.
*The composition of two surjections is again a surjection, but if ''g'' o ''f'' is surjective, then it can only be concluded that ''g'' is surjective. See the figure.

==Bijection==
{{main|Bijective function}}
[[Image:Bijective composition.svg|thumb|300px|Bijective composition: the first function need not be surjective and the second function need not be injective.]]
A function is '''bijective''' if it is both injective and surjective. A bijective function is a '''bijection''' ('''one-to-one correspondence'''). A function is bijective [[if and only if]] every possible image is mapped to by exactly one argument. This equivalent condition is formally expressed as follow.

:The function &lt;math&gt;f: X \to Y&lt;/math&gt; is bijective [[iff]] for all &lt;math&gt;y \in Y&lt;/math&gt;, there is a unique &lt;math&gt;x \in X&lt;/math&gt; such that &lt;math&gt;f(x) = y.&lt;/math&gt;

*A function ''f'' : ''X'' → ''Y'' is bijective if and only if it is invertible, that is, there is a function ''g'': ''Y'' → ''X'' such that ''g'' o ''f'' = identity  function on ''X'' and ''f'' o ''g'' = identity  function on ''Y''. This function maps each image to its unique preimage.
*The composition of two bijections is again a bijection, but if ''g'' o ''f'' is a bijection, then it can only be concluded that ''f'' is injective and ''g'' is surjective. (See the figure at right and the remarks above regarding injections and surjections.)
*The bijections from a set to itself form a [[group (mathematics)|group]] under composition, called the [[symmetric group]].

==Cardinality==
Suppose you want to define what it means for two sets to "have the same number of elements". One way to do this is to say that two sets "have the same number of elements" if and only if all the elements of one set can be paired with the elements of the other, in such a way that each element is paired with exactly one element. Accordingly, we can define two sets to "have the same number of elements" if there is a bijection between them. We say that the two sets have the same [[cardinality]].

Likewise, we can say that set &lt;math&gt;X&lt;/math&gt; "has fewer than or the same number of elements" as set &lt;math&gt;Y&lt;/math&gt; if there is an injection from &lt;math&gt;X&lt;/math&gt; to &lt;math&gt;Y&lt;/math&gt;. We can also say that set &lt;math&gt;X&lt;/math&gt; "has fewer than the number of elements" in set &lt;math&gt;Y&lt;/math&gt; if there is an injection from &lt;math&gt;X&lt;/math&gt; to &lt;math&gt;Y&lt;/math&gt; but not a bijection between &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt;.

==Examples==
It is important to specify the domain and codomain of each function since by changing these, functions which we think of as the same may have different ''jectivity''. &lt;!-- someone change this wording please. MarSch --&gt;

===Injective and surjective (bijective)===
* For every set ''X'' the identity function id&lt;sub&gt;''X''&lt;/sub&gt; and thus specifically &lt;math&gt;\mathbf{R} \to \mathbf{R} : x \mapsto x&lt;/math&gt;.
* &lt;math&gt;\mathbf{R}^+ \to \mathbf{R}^+ : x \mapsto x^2&lt;/math&gt; and thus also its inverse &lt;math&gt;\mathbf{R}^+ \to \mathbf{R}^+ : x \mapsto \sqrt{x}&lt;/math&gt;.
* The [[exponential function]] &lt;math&gt;\exp : \mathbf{R} \to \mathbf{R}^+ : x \mapsto \mathrm{e}^x&lt;/math&gt; and thus also its inverse the [[natural logarithm]] &lt;math&gt;\ln : \mathbf{R}^+ \to \mathbf{R} : x \mapsto \ln{x}&lt;/math&gt;

===Injective and non-surjective===
* The exponential function &lt;math&gt;\exp : \mathbf{R} \to \mathbf{R} : x \mapsto \mathrm{e}^x&lt;/math&gt;

===Non-injective and surjective===
* &lt;math&gt;\mathbf{R} \to \mathbf{R} : x \mapsto (x-1)x(x+1) = x^3 - x &lt;/math&gt;
* &lt;math&gt;\mathbf{R} \to [-1,1] : x \mapsto \sin(x)&lt;/math&gt;

===Non-injective and non-surjective===

* &lt;math&gt;\mathbf{R} \to \mathbf{R}: x \mapsto \sin(x)&lt;/math&gt;

==Properties==
* For every function ''f'', subset ''X'' of the domain and subset ''Y'' of the codomain we have ''X'' ⊂ ''f''{{i sup|−1}}(''f''(''X'')) and ''f''(''f''{{i sup|−1}}(''Y'')) ⊂ ''Y''. If ''f'' is injective we have ''X'' = ''f''{{i sup|−1}}(''f''(''X'')) and if ''f'' is surjective we have ''f''(''f''{{i sup|−1}}(''Y'')) = ''Y''.
* For every function ''h'' : ''X'' → ''Y'' we can define a surjection ''H'' : ''X'' → ''h''(''X'') : ''x'' → ''h''(''x'') and an injection {{math|''I'' : ''h''(''X'') → ''Y'' : ''x'' → ''x''}}. It follows that {{tmath|1=H = I \circ H}}. This decomposition is unique [[up to isomorphism]].

==Category theory==
In the [[category (mathematics)|category]] of [[Set (mathematics)|sets]], injections, surjections, and bijections correspond precisely to [[monomorphism]]s, [[epimorphism]]s, and [[isomorphism]]s, respectively.

==History==
This terminology was originally coined by the [[Bourbaki group]].

==See also==
*[[Bijective function]]
*[[Horizontal line test]]
*[[Injective module]]
*[[Injective function]]
*[[Permutation]]
*[[Surjective function]]

==External links==
*[http://jeff560.tripod.com/i.html Earliest Uses of Some of the Words of Mathematics: entry on Injection, Surjection and Bijection has the history of Injection and related terms.]

[[Category:Basic concepts in set theory]]
[[Category:Mathematical relations]]
[[Category:Functions and mappings]]</text>
      <sha1>ghgyoqxrpa3sscexaq5cj268c96fdk2</sha1>
    </revision>
  </page>
  <page>
    <title>Category of finite-dimensional Hilbert spaces</title>
    <ns>0</ns>
    <id>7185509</id>
    <revision>
      <id>642180725</id>
      <parentid>619296808</parentid>
      <timestamp>2015-01-12T17:32:28Z</timestamp>
      <contributor>
        <username>John of Reading</username>
        <id>11308236</id>
      </contributor>
      <minor/>
      <comment>Typo/[[WP:AWB/GF|general]] fixing, replaced: Accodring → According using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1264">In [[mathematics]], the [[category (mathematics)|category]] '''FdHilb''' has all finite-dimensional [[Hilbert spaces]] for [[object (category theory)|objects]] and the [[linear transformations]] between them as [[morphism]]s.

==Properties==

This category
* is [[monoidal category|monoidal]],
* possesses finite [[biproduct]]s, and
* is [[dagger compact category|dagger compact]].

According to a theorem of Selinger, the category of finite-dimensional Hilbert spaces is complete in the [[dagger compact category]].&lt;ref&gt;P. Selinger, ''[http://www.mscs.dal.ca/~selinger/papers.html#finhilb  Finite dimensional Hilbert spaces are complete for dagger compact closed categories]'', Proceedings of the 5th International Workshop on Quantum Programming Languages, Reykjavik (2008).&lt;/ref&gt;&lt;ref&gt;M. Hasegawa, M. Hofmann and G. Plotkin, "Finite dimensional vector spaces are complete for traced symmetric monoidal categories", LNCS '''4800''', (2008), pp. 367–385.&lt;/ref&gt; Many ideas from Hilbert spaces, such as the [[no-cloning theorem]], hold in general for dagger compact categories. See that article for additional details.

==References==
{{reflist}}

[[Category:Monoidal categories]]
[[Category:Dagger categories]]
[[Category:Hilbert space]]


{{categorytheory-stub}}</text>
      <sha1>oxo9iyrwzcpdwq1sgg1qo0ni0q1c6oz</sha1>
    </revision>
  </page>
  <page>
    <title>Chasles' theorem (kinematics)</title>
    <ns>0</ns>
    <id>42392462</id>
    <revision>
      <id>868689726</id>
      <parentid>863067268</parentid>
      <timestamp>2018-11-13T20:23:51Z</timestamp>
      <contributor>
        <ip>161.28.90.112</ip>
      </contributor>
      <comment>The theorem as stated seemed misleading (it would imply objects only have 4 degrees of freedom in position+orientation) and did not match the actual statements of the theorem in the literature.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4644">{{Other uses|Chasles' theorem (disambiguation)}}
[[Image:pure screw.svg|thumb|A [[screw axis]].  Mozzi–Chasles' theorem says that every [[Euclidean motion]] is a [[screw displacement]] along some screw axis.]]In [[kinematics]], '''Chasles' theorem''', or '''Mozzi–Chasles' theorem''', says that the most general rigid body displacement can be produced by a [[translation (mathematics)|translation]] along a line (called its [[screw axis]] or Mozzi axis) followed (or preceded) by a [[rotation]] about an axis parallel to that line.&lt;ref&gt;{{cite web|last= Kumar | first=V. |title = MEAM 520 notes: The theorems of Euler and Chasles |url= http://www.seas.upenn.edu/~meam520/notes02/EulerChasles4.pdf | publisher= University of Pennsylvania | accessdate=6 August 2014}}&lt;/ref&gt;&lt;ref&gt;{{cite book | last=Heard | first=William B.| year=2006 | title=Rigid Body Mechanics | publisher=Wiley | page= 42 | isbn=3-527-40620-4}}&lt;/ref&gt;

==History==
The proof that a spatial displacement can be decomposed into a rotation and slide around and along a line is attributed to the astronomer and mathematician [[Giulio Mozzi]] (1763), in fact the screw axis is traditionally called '''asse di Mozzi''' in Italy. However, most textbooks refer to a subsequent similar work by [[Michel Chasles]] dating 1830.&lt;ref&gt;{{cite journal | last=Chasles | first=M. | year=1830 | title=Note sur les propriétés générales du système de deux corps semblables entr'eux | journal=Bulletin des Sciences Mathématiques, Astronomiques, Physiques et Chemiques | volume=14 | pages=321–326 | language=French | url=https://books.google.com/books?id=ERcAAAAAMAAJ&amp;pg=PA321 }}&lt;/ref&gt;&lt;!--date given in article is 5 Feb 1831--&gt; Several other scholars contemporaries of M. Chasles obtained the same or similar results around that time, including G. Giorgini, Cauchy, Poinsot, Poisson and Rodrigues.  An account of the 1763 proof by Giulio Mozzi and some of its history can be found here.&lt;ref&gt;
{{cite book | last=Mozzi | first=Giulio | year=1763 | title=Discorso matematico sopra il rotamento momentaneo dei corpi | publisher=Stamperia di Donato Campo | place=Napoli | url=https://archive.org/stream/discorsomatemat00mozzgoog#page/n5/mode/2up | language=Italian }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last=Ceccarelli  | first=Marco | year=2000 | title=Screw axis defined by Giulio Mozzi in 1763 and early studies on helicoidal motion | journal=Mechanism and Machine Theory | volume=35 | pages=761–770 }}&lt;/ref&gt;

==Proof==
Mozzi considers a rigid body undergoing first a rotation about an axis passing through the center of mass and then a translation of displacement D in an arbitrary direction. Any rigid motion can be accomplished in this way due to a theorem by Euler on the existence of an axis of rotation. 
The displacement D of the center of mass can be decomposed into components parallel and perpendicular to the axis. The perpendicular (and parallel) component acts on all points of the rigid body but Mozzi shows that for some points the previous rotation acted exactly with an opposite displacement, so those points are translated parallel to the axis of rotation. These points lie on the Mozzi axis through which the rigid motion can be accomplished through a screw motion.

Another elementary proof of Mozzi–Chasles' theorem was given by [[E. T. Whittaker]] in 1904.&lt;ref&gt;[[E. T. Whittaker]] (1904) {{Google books|epH1hCB7N2MC|A Treatise on Analytical Dynamics of Particles and Rigid Bodies| page=4}}&lt;/ref&gt; Suppose ''A'' is to be transformed into ''B''. Whittaker suggests that line ''AK'' be selected parallel to the axis of the given rotation, with ''K'' the foot of a perpendicular from ''B''. The appropriate screw displacement is about an axis parallel to ''AK'' such that ''K'' is moved to ''B''. The method corresponds to [[Euclidean plane isometry]] where a composition of rotation and translation can be replaced by rotation about an [[Euclidean plane isometry#Isometries in the complex plane|appropriate center]]. In Whittaker's terms, "A rotation about any axis is equivalent to a rotation through the same angle about any axis parallel to it, together with a simple translation in a direction perpendicular to the axis."

== References ==
{{Reflist}}
==Further reading==
* [[Benjamin Peirce]] (1872) [https://archive.org/details/asystemanalytic01peirgoog A System of Analytical Mechanics], III. Combined Motions of Rotation and Translation, especially § 32 and § 39, [[David van Nostrand]] &amp; Company, link from [[Internet Archive]]

[[Category:Mathematical theorems]]
[[Category:Kinematics]]
[[Category:Euclidean solid geometry]]
[[Category:Rotation in three dimensions]]</text>
      <sha1>pvd5sw4x01sv5xialhy7m22d0stjefv</sha1>
    </revision>
  </page>
  <page>
    <title>Collapsing algebra</title>
    <ns>0</ns>
    <id>43222035</id>
    <revision>
      <id>615789032</id>
      <parentid>615773623</parentid>
      <timestamp>2014-07-06T06:49:00Z</timestamp>
      <contributor>
        <username>Deltahedron</username>
        <id>16759019</id>
      </contributor>
      <minor/>
      <comment>/* References */ expand bibliodata</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2049">In mathematics, a '''collapsing algebra''' is a type of [[Boolean algebra (structure)|Boolean algebra]] sometimes used in [[Forcing (mathematics)|forcing]] to reduce ("collapse") the size of [[Cardinal number|cardinals]]. The [[poset]]s used to generate collapsing algebras were introduced by {{harvs|txt|first=Azriel|last= Lévy|authorlink=Azriel Lévy|year=1963}}.

The collapsing algebra of λ&lt;sup&gt;ω&lt;/sup&gt; is a [[complete Boolean algebra]] with at least λ elements but generated by a countable number of elements. As the size of countably generated complete Boolean algebras is unbounded, this shows that there is no [[Free algebra|free]] complete Boolean algebra on a countable number of elements.

==Definition==

There are several slightly different sorts of collapsing algebras. 

If κ and λ are cardinals, then the Boolean algebra of [[regular open set]]s of the [[product space]] κ&lt;sup&gt;λ&lt;/sup&gt; is a collapsing algebra. Here κ and λ are both given the [[discrete topology]]. There are several different options for the topology of 
κ&lt;sup&gt;λ&lt;/sup&gt;. The simplest option is to take the usual product topology. Another option is to take the topology generated by open sets consisting of functions whose value is specified on less than λ elements of λ.

==References==

* {{cite book | last=Bell | first=J. L. | year=1985 | title=Boolean-Valued Models and Independence Proofs in Set Theory | edition=2nd | location=Oxford | publisher=Oxford University Press (Clarendon Press) | series=Oxford Logic Guides | volume=12 | isbn=0-19-853241-5 | zbl=0585.03021 }}
* {{cite book | authorlink=Thomas Jech|last=Jech | first=Thomas| title=Set theory | edition=third millennium (revised and expanded) | publisher=[[Springer-Verlag]] | year=2003 | isbn=3-540-44085-2 | oclc=174929965 | zbl=1007.03002}}
* {{cite journal | last=Lévy | first=Azriel |title=Independence results in set theory by Cohen's method. IV, | journal=Notices Amer. Math. Soc. |volume=10 |year=1963|page= 593}} 

[[Category:Boolean algebra]]
[[Category:Forcing (mathematics)]]</text>
      <sha1>7dbt5dkplaizqrbfusyjxa88n5kjdzs</sha1>
    </revision>
  </page>
  <page>
    <title>Compactly-supported homology</title>
    <ns>0</ns>
    <id>2574552</id>
    <revision>
      <id>746854842</id>
      <parentid>675190364</parentid>
      <timestamp>2016-10-30T00:05:28Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1503">In [[mathematics]], a [[Homology (mathematics)|homology theory]] in [[algebraic topology]] is '''compactly supported''' if, in every degree ''n'', the [[relative homology]] group H&lt;sub&gt;''n''&lt;/sub&gt;(''X'', ''A'') of every [[pair of spaces]]

:(''X'', ''A'')

is [[naturally isomorphic]] to the [[direct limit]] of the ''n''th relative homology groups of pairs (''Y'', ''B''), where ''Y'' varies over [[compact subspace]]s of ''X'' and ''B'' varies over compact subspaces of ''A''.&lt;ref name="kreck"&gt;{{citation|title=Differential Algebraic Topology: From Stratifolds to Exotic Spheres|volume=110|series=[[Graduate Studies in Mathematics]]|first=Matthias|last=Kreck|publisher=American Mathematical Society|year=2010|isbn=9780821848982|page=95|url=https://books.google.com/books?id=iYyDAwAAQBAJ&amp;pg=PA95}}.&lt;/ref&gt;

[[Singular homology]] is compactly supported, since each singular chain is a finite sum of [[simplices]], which are compactly supported.&lt;ref name="kreck"/&gt; [[Strong homology]] is not compactly supported.

If one has defined a homology theory over compact pairs, it is possible to extend it into a compactly supported homology theory in the wider category of Hausdorff pairs (''X'', ''A'') with ''A'' closed in ''X'', by defining that the homology of a Hausdorff pair (''X'', ''A'') is the direct limit over pairs (''Y'', ''B''), where ''Y'', ''B'' are compact, ''Y'' is a subset of ''X'', and ''B'' is a subset of ''A''.

==References==
{{reflist}}

{{topology-stub}}
[[Category:Homology theory]]</text>
      <sha1>icof3whbsg735zq82vvu7c7y3mpobmn</sha1>
    </revision>
  </page>
  <page>
    <title>D'Alembert's principle</title>
    <ns>0</ns>
    <id>499429</id>
    <revision>
      <id>862708683</id>
      <parentid>861539484</parentid>
      <timestamp>2018-10-06T05:15:02Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13633">{{Classical mechanics|cTopic=Fundamental concepts}}
[[Image:Alembert.jpg|thumb|right|[[Jean d'Alembert]] (1717—1783)]]
'''D'Alembert's principle''', also known as the '''Lagrange–d'Alembert principle''', is a statement of the fundamental [[classical physics|classical]] laws of motion. It is named after its discoverer, the [[France|French]] [[physicist]] and [[mathematician]] [[Jean le Rond d'Alembert]].  It is the dynamic analogue to the ''principle of [[virtual work]] for applied forces'' in a static system and in fact is  more general than [[Hamilton's principle]], avoiding restriction to [[holonomic system]]s.&lt;ref name=Lanczos&gt;{{cite book |last=Lanczos |first=Cornelius |title=The Variational Principles of Mechanics |edition=4th |year=1970 |isbn=0-486-65067-7 |publisher=Dover Publications Inc. |location=New York |url=https://books.google.com/books?id=ZWoYYr8wk2IC&amp;pg=PA92&amp;dq=%22d%27Alembert%27s+principle%22 |page=92}}&lt;/ref&gt; A holonomic constraint depends only on the coordinates and time. It does not depend on the velocities. If the negative terms in accelerations are recognized as ''[[inertial force]]s'', the statement of d'Alembert's principle becomes ''The total virtual work of the impressed forces plus the inertial forces vanishes for reversible displacements''.&lt;ref name=Lanczos2&gt;{{cite book |title=p. 90 |author=Cornelius Lanczos   |isbn=0-486-65067-7 |year=1970 |url=https://books.google.com/books?id=ZWoYYr8wk2IC&amp;printsec=frontcover&amp;dq=%22d%27Alembert%27s+principle%22#PPA90,M1}}&lt;/ref&gt;  The principle does not apply for irreversible displacements, such as sliding [[friction]], and more general specification of the irreversibility is required.&lt;ref&gt;{{cite journal | last1 = Udwadia | first1 = F. E. | last2 = Kalaba | first2 = R. E. | title = On the Foundations of Analytical Dynamics | journal = Intl. Journ. Nonlinear Mechanics | volume = 37 | issue = 6 | pages = 1079–1090 | date = 2002 | url = http://ae-www.usc.edu/bio/udwadia/papers/On_foundation_of_analytical_dynamics.pdf | doi = 10.1016/S0020-7462(01)00033-6 | bibcode = 2002IJNLM..37.1079U | deadurl = yes | archiveurl = https://web.archive.org/web/20100613031338/http://ae-www.usc.edu/bio/udwadia/papers/On_foundation_of_analytical_dynamics.pdf | archivedate = 2010-06-13 | df =  }}&lt;/ref&gt;

The principle states that the sum of the differences between the [[force]]s acting on a system of mass particles and the time [[derivative]]s of the [[momentum|momenta]] of the system itself projected onto any [[virtual displacement]] consistent with the constraints of the system is zero. Thus, in symbols d'Alembert's principle is written as following,

:&lt;math&gt;\sum_{i} ( \mathbf {F}_{i} - m_i \mathbf{a}_i )\cdot \delta \mathbf r_i = 0,&lt;/math&gt;

where :

:{|
|-
| &lt;math&gt;i&lt;/math&gt; || is an integer used to indicate (via subscript) a variable corresponding to a particular particle in the system,
|-
| &lt;math&gt;\mathbf {F}_i&lt;/math&gt; || is the total applied force (excluding constraint forces) on the &lt;math&gt;i&lt;/math&gt;-th particle,
|-
| &lt;math&gt; m_i \scriptstyle&lt;/math&gt; || is the mass of the &lt;math&gt;i&lt;/math&gt;-th particle,
|-
| &lt;math&gt;\mathbf a_i&lt;/math&gt; || is the acceleration of the &lt;math&gt;i&lt;/math&gt;-th particle,
|-
| &lt;math&gt;m_i \mathbf a_i&lt;/math&gt;&amp;nbsp; || together as product represents the time derivative of the momentum of the &lt;math&gt;i&lt;/math&gt;-th particle if the masses do not change with time, and
|-
| &lt;math&gt;\delta \mathbf r_i&lt;/math&gt; || is the virtual displacement of the &lt;math&gt;i&lt;/math&gt;-th particle, consistent with the constraints.
|}

This above equation is often called d'Alembert's principle, but it was first written in this variational form by [[Joseph Louis Lagrange]].&lt;ref&gt;[[Arnold Sommerfeld]] (1956), ''Mechanics:  Lectures on Theoretical Physics'', Vol 1, p. 53&lt;/ref&gt;  D'Alembert's contribution was to demonstrate that in the totality of a dynamic system the forces of constraint vanish.  That is to say that the [[generalized forces]] &lt;math&gt;{\mathbf Q}_{j}&lt;/math&gt; need not include constraint forces.  It is equivalent to the somewhat more cumbersome [[Gauss's principle of least constraint]].

==General case with changing masses==
The general statement of d'Alembert's principle mentions "the time [[derivative]]s of the [[momentum|momenta]] of the system". The momentum of the ''i''-th mass is the product of its mass and velocity:

:&lt;math&gt;\mathbf p_i = m_i \mathbf v_i&lt;/math&gt;

and its time derivative is

:&lt;math&gt;\dot{\mathbf{p}_i} = \dot{m}_i \mathbf{v}_i + m_i \dot{\mathbf{v}}_i&lt;/math&gt;.

In many applications, the masses are constant and this equation reduces to

:&lt;math&gt;\dot{\mathbf{p}_i} = m_i \dot{\mathbf{v}}_i = m_i \mathbf{a}_i&lt;/math&gt;,

which appears in the formula given above. However, some applications involve changing masses (for example, chains being rolled up or being unrolled) and in those cases both terms &lt;math&gt;\dot{m}_i \mathbf{v}_i&lt;/math&gt; and &lt;math&gt;m_i \dot{\mathbf{v}}_i&lt;/math&gt; have to remain present, giving

:&lt;math&gt;\sum_{i} ( \mathbf {F}_{i} - m_i \mathbf{a}_i - \dot{m}_i \mathbf{v}_i)\cdot \delta \mathbf r_i = 0.&lt;/math&gt;

==Derivation for special cases==
To date, nobody has shown that D'Alembert's principle is equivalent to [[Newton's second law of motion|Newton's Second Law]]. D'Alembert's principle is a more general case .  And it is true only for some very special cases e.g. rigid body constraints.  However, an approximate solution to this problem does exist.&lt;ref name="Rebhan2006"&gt;{{cite book |last=Rebhan |first=Eckhard |title=Mechanik |series=Theoretische Physik |year=2006 |publisher=Spektrum Akademischer Verlag |location=Heidelberg, Germany  |isbn=978-3-8274-1716-9 |chapter=Exkurs 5.1: Ableitung des d'Alembert Prinzips}}&lt;/ref&gt;

Consider Newton's law for a system of particles, i. The total force on each particle is&lt;ref name="Torby1984"&gt;{{cite book |last=Torby |first=Bruce |title=Advanced Dynamics for Engineers |series=HRW Series in Mechanical Engineering |year=1984 |publisher=CBS College Publishing |location=United States of America  |isbn=0-03-063366-4 |chapter=Energy Methods}}&lt;/ref&gt;

:&lt;math&gt;\mathbf {F}_{i}^{(T)} = m_i \mathbf {a}_i,&lt;/math&gt;

where

:{|
|-
| &lt;math&gt;\mathbf {F}_{i}^{(T)}&lt;/math&gt; || are the total forces acting on the system's particles,
|-
| &lt;math&gt;m_i \mathbf {a}_i&lt;/math&gt;&amp;nbsp; || are the inertial forces that result from the total forces.
|}

Moving the inertial forces to the left gives an expression that can be considered to represent quasi-static equilibrium, but which is really just a small algebraic manipulation of Newton's law:&lt;ref name="Torby1984"/&gt;

:&lt;math&gt;\mathbf {F}_{i}^{(T)} - m_i \mathbf {a}_i = \mathbf 0.&lt;/math&gt;

Considering the [[virtual work]], &lt;math&gt;\delta W&lt;/math&gt;, done by the total and inertial forces together through an arbitrary virtual displacement, &lt;math&gt;\delta \mathbf r_i&lt;/math&gt;, of the system leads to a zero identity, since the forces involved sum to zero for each particle.&lt;ref name="Torby1984"/&gt;

:&lt;math&gt;\delta W = \sum_{i} \mathbf {F}_{i}^{(T)} \cdot \delta \mathbf r_i - \sum_{i} m_i \mathbf{a}_i \cdot \delta \mathbf r_i = 0&lt;/math&gt;

The original vector equation could be recovered by recognizing that the work expression must hold for arbitrary displacements. Separating the total forces into applied forces, &lt;math&gt;\mathbf F_i&lt;/math&gt;, and constraint forces, &lt;math&gt;\mathbf C_i&lt;/math&gt;, yields&lt;ref name="Torby1984"/&gt;

:&lt;math&gt;\delta W = \sum_{i} \mathbf {F}_{i} \cdot \delta \mathbf r_i + \sum_{i} \mathbf {C}_{i} \cdot \delta \mathbf r_i - \sum_{i} m_i \mathbf{a}_i \cdot \delta \mathbf r_i = 0.&lt;/math&gt;

If arbitrary virtual displacements are assumed to be in directions that are orthogonal to the constraint forces (which is not usually the case, so this derivation works only for special cases), the constraint forces do no work. Such displacements are said to be ''consistent'' with the constraints.&lt;ref&gt;{{Cite conference|title = Teaching Students Work and Virtual Work Method in Statics:A Guiding Strategy with Illustrative Examples|first = Ing-Chang|last = Jong|conference = 2005 American Society for Engineering Education Annual Conference &amp; Exposition|year = 2005|url = http://search.asee.org/search/fetch?url=file%3A%2F%2Flocalhost%2FE%3A%2Fsearch%2Fconference%2F29%2FAC%25202005Paper1212.pdf&amp;index=conference_papers&amp;space=129746797203605791716676178&amp;type=application%2Fpdf&amp;charset=|accessdate = June 24, 2014|section = Improving Mechanics of Materials}}&lt;/ref&gt; This leads to the formulation of ''d'Alembert's principle'', which states that the difference of applied forces and inertial forces for a dynamic system does no virtual work:.&lt;ref name="Torby1984"/&gt;

:&lt;math&gt;\delta W = \sum_{i} ( \mathbf {F}_{i} - m_i \mathbf{a}_i )\cdot \delta \mathbf r_i = 0.&lt;/math&gt;

There is also a corresponding principle for static systems called the [[virtual work#Principle of virtual work for applied forces|principle of virtual work for applied forces]].

==D'Alembert's principle of inertial forces==
D'Alembert showed that one can transform an accelerating rigid body into an equivalent static system by adding the so-called "[[inertial force]]"  and "[[inertial torque]]" or moment. The inertial force must act through the center of mass and the inertial torque can act anywhere. The system can then be analyzed exactly as a static system subjected to this "inertial force and moment" and the external forces. The advantage is that, in the equivalent static system one can take moments about any point (not just the center of mass). This often leads to simpler calculations because any force (in turn) can be eliminated from the moment equations by choosing the appropriate point about which to apply the moment equation (sum of moments = zero). Even in the course of Fundamentals of Dynamics and Kinematics of machines, this principle helps in analyzing the forces that act on a link of a mechanism when it is in motion. In textbooks of engineering dynamics this is sometimes referred to as ''d'Alembert's principle''.

===Example for 1D motion of a rigid body===
[[File:Dalembert example.JPG|thumb|280x280px|Free body diagram of a wire pulling on a mass with weight W, showing the d’Alembert inertia “force” ma.
]]
To illustrate the concept of ''d'Alembert's principle'', let's use a simple model with a weight''' '''&lt;math&gt;W&lt;/math&gt;, suspended from a wire. The weight is subjected to a gravitational force, &lt;math&gt;W=mg&lt;/math&gt;, and a tension force &lt;math&gt;T&lt;/math&gt;''' '''in the wire. The mass accelerates upward with an acceleration &lt;math&gt;a&lt;/math&gt;. [[Newton's second law of motion|Newton's Second Law]] becomes &lt;math&gt;T-W=ma&lt;/math&gt;''''' '''''or &lt;math&gt;T=W+ma&lt;/math&gt;. As an observer with feet planted firmly on the ground, we see that the force &lt;math&gt;T&lt;/math&gt; accelerates the weight, &lt;math&gt;W&lt;/math&gt;, but, if we are moving with the wire we don’t see the acceleration, we feel it. The tension in the wire seems to counteract an acceleration “force” &lt;math&gt;ma&lt;/math&gt; or &lt;math&gt;(W/g)a&lt;/math&gt;.
[[File:Rigid Body in Free Fall with Angular Velocity.JPG|thumb|300x300px|Free body diagram depicting an inertia moment and an inertia force on a rigid body in free fall with an angular velocity.]]

===Example for plane 2D motion of a rigid body===
For a planar rigid body, moving in the plane of the body (the ''x''–''y'' plane), and subjected to forces and torques causing rotation only in this plane, the inertial force is

:&lt;math&gt; \mathbf{F}_i = - m\ddot{\mathbf{r}}_c&lt;/math&gt;

where &lt;math&gt;\mathbf{r}_c&lt;/math&gt; is the position vector of the centre of mass of the body, and &lt;math&gt;m&lt;/math&gt; is the mass of the body. The inertial torque (or moment) is

:&lt;math&gt;T_i = -I\ddot{\theta}&lt;/math&gt;

where &lt;math&gt;I&lt;/math&gt; is the [[moment of inertia]] of the body. If, in addition to the external forces and torques acting on the body, the inertia force acting through the center of mass is added and the inertial torque is added (acting around the centre of mass is as good as anywhere) the system is equivalent to one in static equilibrium. Thus the equations of static equilibrium

:&lt;math&gt;\begin{align}
  \sum F_x &amp;= 0,
  \\
  \sum F_y &amp;= 0,
  \\
  \sum T &amp;= 0
\end{align}
&lt;/math&gt;

hold. The important thing is that &lt;math&gt;\sum T&lt;/math&gt; is the sum of torques (or moments, including the inertial moment and the moment of the inertial force) taken about ''any'' point. The direct application of Newton's laws requires that the angular acceleration equation be applied ''only'' about the center of mass.

===Dynamic equilibrium===
D'Alembert's form of the principle of virtual work states that a system of rigid bodies is in dynamic equilibrium when the virtual work of the sum of the applied forces and the inertial forces is zero for any virtual displacement of the system.  Thus, dynamic equilibrium of a system of n rigid bodies with m generalized coordinates requires that is to be
:&lt;math&gt; \delta W = (Q_1 + Q^*_1)\delta q_1 + \ldots + (Q_m + Q^*_m)\delta q_m = 0,&lt;/math&gt;
for any set of virtual displacements δq&lt;sub&gt;j&lt;/sub&gt;.  This condition yields m equations,
:&lt;math&gt; Q_j + Q^*_j = 0, \quad j=1, \ldots, m,&lt;/math&gt;
which can also be written as
:&lt;math&gt;  \frac{d}{dt} \frac{\partial T}{\partial \dot{q}_j} -\frac{\partial T}{\partial q_j} = Q_j, \quad j=1,\ldots,m.&lt;/math&gt;
The result is a set of m equations of motion that define the dynamics of the rigid body system.

==References&lt;ref&gt;{{Cite book|title = Aerospace Structures - an Introduction to Fundamental Problems|last = Weisshaar|first = Terry|publisher = |year = 2009|isbn = |location = Purdue University|pages = 50, 58}}&lt;/ref&gt;==
&lt;references/&gt;

{{DEFAULTSORT:D'alembert'S Principle}}
[[Category:Classical mechanics]]
[[Category:Dynamical systems]]
[[Category:Lagrangian mechanics]]
[[Category:Principles]]</text>
      <sha1>rav9lw0c9xjhfqxo1qu8r7xeg4wg771</sha1>
    </revision>
  </page>
  <page>
    <title>Derivative test</title>
    <ns>0</ns>
    <id>742352</id>
    <revision>
      <id>861808728</id>
      <parentid>841193945</parentid>
      <timestamp>2018-09-30T05:00:48Z</timestamp>
      <contributor>
        <username>DivermanAU</username>
        <id>24496035</id>
      </contributor>
      <comment>fix reference link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10956">In [[calculus]], a '''derivative test''' uses the [[derivative]]s of a function to locate the [[stationary point|critical point]]s of a function and determine whether each point is a [[local maximum]], a [[local minimum]], or a [[saddle point]]. Derivative tests can also give information about the [[Concave function|concavity]] of a function.

The usefulness of derivatives to find extrema is proved mathematically by [[Fermat's theorem (stationary points)|Fermat's theorem of stationary points]].

==First derivative test==
The first derivative test examines a function's [[monotonic function|monotonic]] properties (where the function is increasing or decreasing) focusing on a particular point in its domain. If the function "switches" from increasing to decreasing at the point, then the function will achieve a highest value at that point. Similarly, if the function "switches" from decreasing to increasing at the point, then it will achieve a least value at that point. If the function fails to "switch", and remains increasing or remains decreasing, then no highest or least value is achieved.

One can examine a function's monotonicity without calculus. However, calculus is usually helpful because there are [[necessary and sufficient conditions|sufficient conditions]] that guarantee the monotonicity properties above, and these conditions apply to the vast majority of functions one would encounter.

===Precise statement of monotonicity properties===

Stated precisely, suppose ''f'' is a real-valued function of a real variable, defined on some interval containing the point ''x''.

*If there exists a positive number ''r'' such that ''f'' is weakly increasing on (''x'' − ''r'', ''x''] and weakly decreasing on [''x'', ''x'' + ''r''), then ''f'' has a local maximum at ''x''.
*If there exists a positive number ''r'' such that ''f'' is strictly increasing on (''x'' − ''r'', ''x''] and strictly increasing on [''x'', ''x'' + ''r''), then ''f'' is strictly increasing on (''x'' − ''r'', ''x'' + ''r'') and does not have a local maximum or minimum at ''x''.

Note that in the first two cases, ''f'' is not required to be strictly increasing or strictly decreasing to the left or right of ''x'', while in the last two cases, ''f'' is required to be strictly increasing or strictly decreasing. The reason is that in the definition of local maximum and minimum, the inequality is not required to be strict: e.g. every value of a constant function is considered both a local maximum and a local minimum.

===Precise statement of first derivative test===

The first derivative test depends on the "increasing-decreasing test", which is itself ultimately a consequence of the [[mean value theorem]].

Suppose ''f'' is a real-valued function of a real variable defined on some interval containing the critical point ''a''. Further suppose that ''f'' is [[continuous function|continuous]] at ''a'' and [[differentiable function|differentiable]] on some open interval containing ''a'', except possibly at ''a'' itself.

*If there exists a positive number ''r'' such that for every ''x'' in (''a'' − ''r'', ''a'') we have {{nobr|''{{′|f}}''(''x'') ≥ 0,}} and for every ''x'' in (''a'', ''a'' + ''r'') we have {{nobr|''{{′|f}}''(''x'') ≤ 0,}} then ''f'' has a local maximum at ''a''.
*If there exists a positive number ''r'' such that for every ''x'' in (''a'' − ''r'', ''a'') ∪ (''a'', ''a'' + ''r'') we have {{nobr|''{{′|f}}''(''x'') &gt; 0,}} then ''f'' is strictly increasing at ''a'' and has neither a local maximum nor a local minimum there.
*If none of the above conditions hold, then the test fails. (Such a condition is not [[vacuous truth|vacuous]]; there are functions that satisfy none of the first three conditions such as ''f''(''x'') = ''x''&lt;sup&gt;2&lt;/sup&gt;⋅sin(1/''x'').

Again, corresponding to the comments in the section on monotonicity properties, note that in the first two cases, the inequality is not required to be strict, while in the next two, strict inequality is required.

===Applications===

The first derivative test is helpful in solving [[optimization problem]]s in physics, economics, and engineering. In conjunction with the [[extreme value theorem]], it can be used to find the absolute maximum and minimum of a real-valued function defined on a closed, bounded interval. In conjunction with other information such as concavity, inflection points, and asymptotes, it can be used to sketch the graph of a function.

==Second derivative test (single variable)==
After establishing the [[critical point (mathematics)|critical points]] of a function, the ''second derivative test'' uses the value of the [[second derivative]] at those points to determine whether such points are a local [[Maxima and minima|maximum]] or a local [[Maxima and minima|minimum]]. If the function ''f'' is twice [[Differentiable function|differentiable]] at a critical point ''x'' (i.e. ''{{prime|f}}(x) = 0''), then:

* If &lt;math&gt;\ f^{\prime\prime}(x) &lt; 0&lt;/math&gt; then &lt;math&gt;f&lt;/math&gt; has a local maximum at &lt;math&gt;x&lt;/math&gt;.
* If &lt;math&gt;\ f^{\prime\prime}(x) &gt; 0&lt;/math&gt; then &lt;math&gt;f&lt;/math&gt; has a local minimum at &lt;math&gt;x&lt;/math&gt;.
* If &lt;math&gt;\ f^{\prime\prime}(x) = 0&lt;/math&gt;, the test is inconclusive.

In the last case, [[Taylor's theorem#Taylor's theorem in one real variable|Taylor's Theorem]] may be used to determine the behavior of ''f'' near ''x'' using [[higher derivative]]s.

===Proof of the second derivative test===
Suppose we have &lt;math&gt;f''(x) &gt; 0&lt;/math&gt; (the proof for &lt;math&gt;f''(x) &lt; 0&lt;/math&gt; is analogous). By assumption, &lt;math&gt;f'(x) = 0&lt;/math&gt;. Then

:&lt;math&gt;0 &lt; f''(x) = \lim_{h \to 0} \frac{f'(x + h) - f'(x)}{h} = \lim_{h \to 0} \frac{f'(x + h) - 0}{h} = \lim_{h \to 0} \frac{f'(x+h)}{h}.&lt;/math&gt;

Thus, for ''h'' sufficiently small we get

:&lt;math&gt;\frac{f'(x+h)}{h} &gt; 0&lt;/math&gt;
which means that
&lt;math&gt;f'(x+h) &lt; 0&lt;/math&gt; if ''h'' &lt; 0 (intuitively, f is decreasing as it approaches ''x'' from the left), and that &lt;math&gt;f'(x+h) &gt; 0&lt;/math&gt; if ''h'' &gt; 0 (intuitively, f is increasing as we go right from ''x''). Now, by the [[first derivative test]], &lt;math&gt;f&lt;/math&gt; has a local minimum at &lt;math&gt;x&lt;/math&gt;.

=== Concavity test ===

A related but distinct use of second derivatives is to determine whether a function is [[Concave function|concave up]] or [[Concave function|concave down]] at a point. It does not, however, provide information about [[inflection points]]. Specifically, a twice-differentiable function ''f'' is concave up if &lt;math&gt;f''(x) &gt; 0&lt;/math&gt; and concave down if &lt;math&gt;f''(x) &lt; 0&lt;/math&gt;. Note that if &lt;math&gt;f(x) = x^4&lt;/math&gt;, then &lt;math&gt;x=0&lt;/math&gt; has zero second derivative, yet is not an inflection point, so the second derivative alone does not give enough information to determine if a given point is an inflection point.

===Higher-order derivative test===
The ''higher-order derivative test'' or ''general derivative test'' is able to determine whether a function's critical points are maxima, minima, or points of inflection for a wider variety of functions than the second-order derivative test. As shown below, the second derivative test is mathematically identical to the special case of n=1 in the higher-order derivative test.

Let ''f'' be a real-valued, sufficiently [[differentiable function]] on the interval &lt;math&gt;I \subset \R, \; c \in I&lt;/math&gt; and &lt;math&gt;n \ge 1&lt;/math&gt; an integer. Also let all the derivatives of ''f'' at ''c'' be zero up to and including the ''n''th derivative, but with the (''n''+1)th derivative being non-zero:

&lt;math&gt;f'(c)=\cdots=f^{(n)}(c)=0\quad \text{and}\quad f^{(n+1)}(c)\,\not= 0&lt;/math&gt;.

There are four possibilities, the first two cases where ''c'' is an extremum, the second two where c is a (local) saddle point:
* If ''n'' is odd and &lt;math&gt;f^{(n+1)}(c)&lt;0&lt;/math&gt;, then ''c'' is a local maximum.
* If ''n'' is odd and &lt;math&gt;f^{(n+1)}(c)&gt;0&lt;/math&gt;, then ''c'' is a local minimum.
* If ''n'' is even and &lt;math&gt;f^{(n+1)}(c)&lt;0&lt;/math&gt;, then ''c'' is a strictly decreasing point of inflection.
* If ''n'' is even and &lt;math&gt;f^{(n+1)}(c)&gt;0&lt;/math&gt;, then ''c'' is a strictly increasing point of inflection.

Since ''n'' must be either odd or even, this analytical test classifies any stationary point of ''f'', so long as a nonzero derivative shows up eventually.

===Example===
Say we want to perform the general derivative test on the function &lt;math&gt;f(x)=x^6+5&lt;/math&gt; at the point &lt;math&gt;x=0&lt;/math&gt;. To do this, we calculate the derivatives of the function and then evaluate them at the point of interest until the result is nonzero.

:&lt;math&gt;f'(x)=6x^5&lt;/math&gt;, &lt;math&gt;f'(0)=0&lt;/math&gt;

:&lt;math&gt;f''(x)=30x^4&lt;/math&gt;, &lt;math&gt;f''(0)=0&lt;/math&gt;

:&lt;math&gt;f^{(3)}(x)=120x^3&lt;/math&gt;, &lt;math&gt;f^{(3)}(0)=0&lt;/math&gt;

:&lt;math&gt;f^{(4)}(x)=360x^2&lt;/math&gt;, &lt;math&gt;f^{(4)}(0)=0&lt;/math&gt;

:&lt;math&gt;f^{(5)}(x)=720x&lt;/math&gt;, &lt;math&gt;f^{(5)}(0)=0&lt;/math&gt;

:&lt;math&gt;f^{(6)}(x)=720&lt;/math&gt;, &lt;math&gt;f^{(6)}(0)=720&lt;/math&gt;

As shown above, at the point &lt;math&gt;x=0&lt;/math&gt;, the function &lt;math&gt;x^6+5&lt;/math&gt; has all of its derivatives at 0 equal to 0 except for the 6th derivative, which is positive. Thus n=5, and by the test, there is a local minimum at 0.

== Multivariable case ==
{{main article|Second partial derivative test}}
For a function of more than one variable, the second derivative test generalizes to a test based on the [[eigenvalue]]s of the function's [[Hessian matrix]] at the critical point. In particular, assuming that all second order partial derivatives of ''f'' are continuous on a neighbourhood of a critical point ''x'', then if the eigenvalues of the Hessian at ''x'' are all positive, then ''x'' is a local minimum.  If the eigenvalues are all negative, then ''x'' is a local maximum, and if some are positive and some negative, then the point is a [[saddle point]].  If the Hessian matrix is [[singular matrix|singular]], then the second derivative test is inconclusive.

==See also==
{{Div col|colwidth=25em}}
* [[Fermat's theorem (stationary points)]]
* [[Maxima and minima]]
* [[Karush–Kuhn–Tucker conditions]]
* [[Phase line (mathematics)|Phase line]] – virtually identical diagram, used in the study of ordinary differential equations
* [[Hessian matrix#Bordered Hessian|Bordered Hessian]]
* [[Optimization (mathematics)]]
* [[Differentiability]]
* [[Convex function]]
* [[Second partial derivative test]]
* [[Saddle point]]
* [[Inflection point]]
* [[Stationary point]]
{{div col end}}

==References==
* [http://mathworld.wolfram.com/SecondDerivativeTest.html "Second Derivative Test" at Mathworld]
* [http://www.math.hmc.edu/calculus/tutorials/secondderiv/ Concavity and the Second Derivative Test]
* [https://www.maa.org/press/periodicals/convergence/thomas-simpson-and-maxima-and-minima Thomas Simpson's use of Second Derivative Test to Find Maxima and Minima] at Convergence
* [[James Stewart (mathematician)|Stewart, James]] (2008). ''Calculus: Early Transcendentals'', 6th ed., Brooks Cole Cengage Learning. {{ISBN|978-0-495-01166-8}}

[[Category:Differential calculus]]</text>
      <sha1>60qvmuetwzk6nlxtzypbhd1pab1e4km</sha1>
    </revision>
  </page>
  <page>
    <title>Direct sum of topological groups</title>
    <ns>0</ns>
    <id>43854082</id>
    <revision>
      <id>803997407</id>
      <parentid>803991028</parentid>
      <timestamp>2017-10-06T00:55:20Z</timestamp>
      <contributor>
        <ip>141.224.232.133</ip>
      </contributor>
      <comment>I fixed what I believe is a typo, I believe it was meant that "H splits topologically from G" not that "H splits topologically form G". I also changed the mapping of the cartesian product of H sub 1 with itself to H sub 1 and H sub 2.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2327">In [[mathematics]], a [[topological group]] ''G'' is called the '''topological direct sum'''&lt;ref&gt;E. Hewitt and K. A. Ross, Abstract harmonic analysis. Vol. I, second edition, Grundlehren der Mathematischen Wissenschaften, 115, Springer, Berlin, 1979. MR0551496 (81k:43001)&lt;/ref&gt; of two [[subgroup]]s ''H''&lt;sub&gt;1&lt;/sub&gt; and ''H''&lt;sub&gt;2&lt;/sub&gt; if
the map
:&lt;math&gt;\begin{align}
H_1\times H_2 &amp;\longrightarrow G \\
(h_1,h_2)     &amp;\longmapsto     h_1 h_2
\end{align}
&lt;/math&gt;
is a topological isomorphism.

More generally, ''G'' is called the direct sum of a finite set of [[subgroup]]s  &lt;math&gt;H_i, i=1,\ldots, n&lt;/math&gt; of the map
:&lt;math&gt;\begin{align}
\prod^n_{i=1} H_i&amp;\longrightarrow G \\
(h_i)_{i\in I}    &amp;\longmapsto     h_1 h_2 \cdots h_n
\end{align}
&lt;/math&gt;

Note that if a topological group ''G'' is the topological direct sum of the family of subgroups &lt;math&gt;H_i &lt;/math&gt; then in particular, as an abstract group (without topology) it is also the [[Direct sum of groups|direct sum]] (in the usual way) of the family &lt;math&gt;H_i &lt;/math&gt;.

==Topological direct summands==
Given a topological group ''G'', we say that a subgroup ''H'' is a '''topological direct summand''' of ''G'' (or that '''splits topologically''' from ''G'') if and only if there exist another subgroup ''K''&amp;nbsp;≤&amp;nbsp;''G'' such that ''G'' is the direct sum of the subgroups ''H'' and ''K''.

A the subgroup ''H'' is a topological direct summand if and only if the [[Extension of a topological group|extension of topological groups]]

:&lt;math&gt;0 \to H\stackrel{i}{{} \to {}} G\stackrel{\pi}{{} \to {}} G/H\to 0&lt;/math&gt;

splits, where &lt;math&gt;i&lt;/math&gt; is the natural inclusion and &lt;math&gt;\pi&lt;/math&gt; is the natural projection.

==Examples==

*Suppose that &lt;math&gt;G&lt;/math&gt; is a [[Locally compact group|locally compact abelian group]] that contains the [[unit circle]] &lt;math&gt;\mathbb T&lt;/math&gt; as a subgroup. Then &lt;math&gt;\mathbb T&lt;/math&gt; is a topological direct summand of ''G''. The same assertion is true for the [[real numbers]] &lt;math&gt;\mathbb R&lt;/math&gt;&lt;ref&gt;Armacost, David L. The structure of locally compact abelian groups. Monographs and Textbooks in Pure and Applied Mathematics, 68. Marcel Dekker, Inc., New York, 1981. vii+154 pp. {{isbn|0-8247-1507-1}} MR0637201 (83h:22010)&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Topological groups]]
[[Category:Topology]]</text>
      <sha1>4ekm8umf2mat0ighwab5sntm74584lc</sha1>
    </revision>
  </page>
  <page>
    <title>Discrete-time Fourier transform</title>
    <ns>0</ns>
    <id>1216914</id>
    <revision>
      <id>871213927</id>
      <parentid>871203124</parentid>
      <timestamp>2018-11-29T17:25:57Z</timestamp>
      <contributor>
        <username>Bob K</username>
        <id>586364</id>
      </contributor>
      <minor/>
      <comment>use \triangleq</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="31119">{{distinguish|text=the [[discrete Fourier transform]]}}
{{Fourier transforms}}

In [[mathematics]], the '''discrete-time Fourier transform''' ('''DTFT''') is a form of [[Fourier analysis]] that is applicable to the uniformly-spaced samples of a continuous function.  The term ''discrete-time'' refers to the fact that the transform operates on discrete data (samples) whose interval often has units of time.  From only the samples, it produces a function of frequency that is a [[periodic summation]] of the [[continuous Fourier transform]] of the original continuous function.  Under certain theoretical conditions, described by the [[sampling theorem]], the original continuous function can be recovered perfectly from the DTFT and thus from the original discrete samples.  The DTFT itself is a continuous function of frequency, but discrete samples of it can be readily calculated via the [[discrete Fourier transform]] (DFT) (see [[Discrete-time Fourier transform#Sampling the DTFT|Sampling the DTFT]]), which is by far the most common method of modern Fourier analysis.

Both transforms are invertible.  The inverse DTFT is the original sampled data sequence.  The inverse DFT is a periodic summation of the original sequence.  The [[fast Fourier transform]] (FFT) is an algorithm for computing one cycle of the DFT, and its inverse produces one cycle of the inverse DFT.

== Definition ==
The discrete-time Fourier transform of a discrete set of real or complex numbers {{math|''x''[''n'']}}, for all [[Number#Integers|integers]] {{mvar|n}}, is a [[Fourier series]], which produces a periodic function of a frequency variable.  When the frequency variable, ω, has [[Normalized frequency (digital signal processing)|normalized units]] of ''radians/sample'', the periodicity is {{math|2π}}, and the Fourier series is:

{{NumBlk|:|&lt;math&gt;X_{2\pi}(\omega) = \sum_{n=-\infty}^{\infty} x[n] \,e^{-i \omega n}.&lt;/math&gt;|{{EquationRef|Eq.1}}}}

The utility of this frequency domain function is rooted in the [[Poisson summation formula]].  Let {{math|''X''(''f'')}} be the Fourier transform of any function, {{math|''x''(''t'')}}, whose samples at some interval {{mvar|T}} (''seconds'') are equal (or proportional to) the {{math|''x''[''n'']}} sequence, i.e. {{math|''T''⋅''x''(''nT'') {{=}} ''x''[''n'']}}.  Then the periodic function represented by the Fourier series is a periodic summation of {{math|''X''(''f'')}} In terms of frequency {{mvar|f}} in [[hertz]] (''cycles/sec''):

{{NumBlk|:|&lt;math&gt;
X_{1/T}(f) = X_{2\pi}(2\pi f T)\ \triangleq
\sum_{n=-\infty}^{\infty} \underbrace{T\cdot x(nT)}_{x[n]}\ e^{-i 2\pi f T n}\;
\stackrel{\mathrm{Poisson\;f.}}{=} \;
 \sum_{k=-\infty}^{\infty} X\left(f - k/T\right).
&lt;/math&gt;|{{EquationRef|Eq.2}}}}

[[File:Fourier transform, Fourier series, DTFT, DFT.gif|thumb|400px|Fig 1. Depiction of a Fourier transform (upper left) and its periodic summation (DTFT) in the lower left corner. The lower right corner depicts samples of the DTFT that are computed by a discrete Fourier transform (DFT).]]

The integer {{mvar|k}} has units of ''cycles/sample'', and {{math|1/''T''}} is the sample-rate, {{mvar|f&lt;sub&gt;s&lt;/sub&gt;}} (''samples/sec'').  So {{math|''X''&lt;sub&gt;1/''T''&lt;/sub&gt;(''f'')}} comprises exact copies of {{math|''X''(''f'')}} that are shifted by multiples of {{mvar|f&lt;sub&gt;s&lt;/sub&gt;}} hertz and combined by addition. For sufficiently large {{mvar|f&lt;sub&gt;s&lt;/sub&gt;}} the {{math|''k'' {{=}} 0}} term can be observed in the region {{math|[−''f&lt;sub&gt;s&lt;/sub&gt;/2, f&lt;sub&gt;s&lt;/sub&gt;/2'']}} with little or no distortion ([[aliasing]]) from the other terms.  In Fig.1, the extremities of the distribution in the upper left corner are masked by aliasing in the periodic summation (lower left).

We also note that {{math|''e''&lt;sup&gt;−''i2πfTn''&lt;/sup&gt;}} is the Fourier transform of {{math|''δ''(''t'' − ''nT'')}}.  Therefore, an alternative definition of DTFT is:&lt;ref group=note&gt;In fact {{EquationNote|Eq.2}} is often justified as follows:

:&lt;math&gt;\begin{align}
\mathcal{F}\left \{\sum_{n=-\infty}^{\infty} T\cdot x(nT) \cdot \delta(t-nT)\right \} &amp;=\mathcal{F}\left \{x(t)\cdot T \sum_{n=-\infty}^{\infty} \delta(t-nT)\right \}\\
&amp;= X(f) * \mathcal{F}\left \{T \sum_{n=-\infty}^{\infty} \delta(t-nT)\right \} \\
&amp;= X(f) * \sum_{k=-\infty}^{\infty} \delta \left(f - \frac{k}{T}\right) \\
&amp;= \sum_{k=-\infty}^{\infty} X\left(f - \frac{k}{T}\right).
\end{align}&lt;/math&gt;&lt;/ref&gt;

{{NumBlk|:|&lt;math&gt;X_{1/T}(f) = \mathcal{F}\left \{\sum_{n=-\infty}^{\infty} x[n] \cdot \delta(t-nT)\right \}
&lt;/math&gt;|{{EquationRef|Eq.3}}}}

The modulated [[Dirac comb]] function is a mathematical abstraction sometimes referred to as ''impulse sampling''.&lt;ref name="Rao"/&gt;

== Inverse transform ==
An operation that recovers the discrete data sequence from the DTFT function is called an ''inverse DTFT''.  For instance, the inverse continuous Fourier transform of both sides of {{EquationNote|Eq.3}} produces the sequence in the form of a modulated Dirac comb function:

:&lt;math&gt;\sum_{n=-\infty}^{\infty} x[n]\cdot \delta(t-n T) = \mathcal{F}^{-1}\left \{X_{1/T}(f)\right\} \ \triangleq \int_{-\infty}^\infty X_{1/T}(f)\cdot e^{i 2 \pi f t} df.&lt;/math&gt;

However, noting that {{math|''X''&lt;sub&gt;1/''T''&lt;/sub&gt;(''f'')}} is periodic, all the necessary information is contained within any interval of length {{math|1/''T''}}.  In both {{EquationNote|Eq.1}} and {{EquationNote|Eq.2}}, the summations over n are a [[Fourier series#Complex Fourier coefficients|Fourier series]], with coefficients {{math|''x''[''n'']}}.  The standard formulas for the Fourier coefficients are also the inverse transforms:

:&lt;math&gt;\begin{align}
x[n] &amp;= T \int_{\frac{1}{T}} X_{1/T}(f)\cdot e^{i 2 \pi f nT} df \quad \scriptstyle{\text{(integral over any interval of length }1/T\textrm{)}} \\
\displaystyle &amp;= \frac{1}{2 \pi}\int_{2\pi} X_{2\pi}(\omega)\cdot e^{i \omega n} d\omega \quad \scriptstyle{\text{(integral over any interval of length }2\pi\textrm{)}}
\end{align}&lt;/math&gt;

== Periodic data ==
When the input data sequence {{math|''x''[''n'']}} is {{mvar|n}}-periodic, {{EquationNote|Eq.2}} can be computationally reduced to a discrete Fourier transform (DFT), because:
* All the available information is contained within {{mvar|n}} samples.
* {{math|''X''&lt;sub&gt;1/''T''&lt;/sub&gt;(''f'')}} converges to zero everywhere except at integer multiples of {{math|1/(''NT'')}}, known as [[harmonic]] frequencies.
* The DTFT is periodic, so the maximum number of unique harmonic amplitudes is {{math|(1/''T'') / (1/(''NT'')) {{=}} ''N''}} 

The kernel {{math|''x''[''n''] ''e''&lt;sup&gt;−''i2πfTn''&lt;/sup&gt;}} is {{mvar|N}}-periodic at the harmonic frequencies, {{math|''f'' {{=}} ''k''/(''NT'')}}. Introducing the notation &lt;math&gt;\sum_{N}&lt;/math&gt; to represent a sum over any {{mvar|n}}-sequence of length {{mvar|N}}, we can write''':'''

:&lt;math&gt;
\begin{align}
X_{1/T}\left(\frac{k}{NT}\right) &amp;= \sum_{m=-\infty}^{\infty} \left(\sum_{N} x[n-mN]\cdot e^{-i 2 \pi \frac{k}{N}(n-mN)}\right) \\
&amp;= \sum_{m=-\infty}^{\infty} \left(\sum_{N} x[n]\cdot e^{-i 2 \pi \frac{k}{N}n}\right)
= T \underbrace{\left(\sum_{N} x(nT)\cdot e^{-i 2 \pi \frac{k}{N}n}\right)}_{X[k] \quad \text{(DFT)}} \cdot \left(\sum_{m=-\infty}^{\infty}1\right).
\end{align}
&lt;/math&gt;

Therefore, the DTFT diverges at the harmonic frequencies, but at different frequency-dependent rates.  And those rates are given by the DFT of one cycle of the {{math|''x''[''n'']}} sequence.  In terms of a Dirac comb function, this is represented by''':'''

:&lt;math&gt;X_{1/T}(f) =  \sum_{k=-\infty}^{\infty} (T\cdot X[k])\ \cdot\  \frac{1}{NT}\delta\left(f-\frac{k}{NT}\right)
= \underbrace{\frac{1}{N} \sum_{k=-\infty}^{\infty} X[k]\ \cdot\ \delta\left(f-\frac{k}{NT}\right)}_{\text{DTFT of a periodic sequence}}. &lt;/math&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;ref group=note&gt;Substituting this expression into formula &amp;nbsp;&lt;math&gt;x(nT) = \int_{\frac{1}{T}} X_{1/T}(f)\cdot e^{i 2 \pi f nT} df&lt;/math&gt;&amp;nbsp; produces the correctly scaled inverse DFT for the {{math|''x''(''nT'')}} sequence.&lt;/ref&gt;&lt;ref group=note&gt;The [[generalized function]] &lt;math&gt;\delta\left(f-\tfrac{k}{NT}\right)&lt;/math&gt; is not unitless.  It has the same units as {{mvar|''T''}}.&lt;/ref&gt;

== Sampling the DTFT ==
When the DTFT is continuous, a common practice is to compute an arbitrary number of samples ({{mvar|N}}) of one cycle of the periodic function {{math|''X''&lt;sub&gt;1/''T''&lt;/sub&gt;}}:

:&lt;math&gt;\begin{align}
\underbrace{X_{1/T}\left(\frac{k}{NT}\right)}_{X_k} &amp;= \sum_{n=-\infty}^\infty x[n]\cdot e^{-i 2\pi \frac{kn}{N}} \quad \quad k = 0, \dots, N-1 \\
&amp;= \underbrace{\sum_{N} x_N[n]\cdot e^{-i 2\pi \frac{kn}{N}},}_{DFT}\quad \scriptstyle{\text{(sum over any }n\text{-sequence of length }N)}
\end{align} &lt;/math&gt;

where {{math|''x''&lt;sub&gt;''N''&lt;/sub&gt;}} is a periodic summation''':'''

:&lt;math&gt;x_N[n]\ \triangleq\ \sum_{m=-\infty}^{\infty} x[n-mN].&lt;/math&gt;

The {{math|''x''&lt;sub&gt;''N''&lt;/sub&gt;}} sequence is the inverse DFT.  Thus, our sampling of the DTFT causes the inverse transform to become periodic.  The array of {{math|{{mabs|''X''&lt;sub&gt;''k''&lt;/sub&gt;}}&lt;sup&gt;2&lt;/sup&gt;}} is known as a '''[[periodogram]]''', where parameter {{mvar|N}} is known to Matlab users as NFFT.&lt;ref name="Matlab"/&gt;

In order to evaluate one cycle of {{math|''x''&lt;sub&gt;''n''&lt;/sub&gt;}} numerically, we require a finite-length {{math|''x''[''n'']}} sequence.  For instance, a long sequence might be truncated by a [[window function]] of length {{mvar|L}} resulting in two cases worthy of special mention: {{math|''L'' ≤ ''N''}} and {{math|''L'' {{=}} ''N'' ⋅ ''I''}}, for some integer {{mvar|I}} (typically 6 or 8).  For notational simplicity, consider the {{math|''x''[''n'']}} values below to represent the modified values.

[[Image:zeropad.png|thumb|350px|Fig 2. DFT of {{math|''e''&lt;sup&gt;i2πn/8&lt;/sup&gt;}} for {{math|''L'' {{=}} 64}} and {{math|''N'' {{=}} 256}}]]
[[Image:no-zeropad.png|thumb|350px|Fig 3. DFT of {{math|''e''&lt;sup&gt;i2πn/8&lt;/sup&gt;}} for {{math|''L'' {{=}} 64}} and {{math|''N'' {{=}} 64}}]]

When {{math|''L'' {{=}} ''N'' ⋅ ''I''}}, a cycle of  {{math|''x&lt;sub&gt;N&lt;/sub&gt;''}} reduces to a summation of {{mvar|I}} ''blocks'' of length {{mvar|N}}.  This goes by various names, such as''':'''&lt;ref name="Gumas"/&gt;&lt;ref name="Lyons"/&gt;&lt;ref name="Lillington"/&gt;&lt;ref name="Chennamangalam"/&gt;&lt;ref name="Dahl"/&gt;
*''window-presum FFT''
*''Weight, overlap, add (WOLA)''&lt;ref group=note&gt;WOLA is not to be confused with the [[Overlap-add method]] of piecewise convolution.&lt;/ref&gt;
*''polyphase FFT''
*''multiple block windowing''
*''time-aliasing''.

An interesting way to understand/motivate the technique is to recall that decimation of sampled data in one domain (time or frequency) produces aliasing in the other, and vice versa.  The ''x&lt;sub&gt;N&lt;/sub&gt;'' summation is mathematically equivalent to aliasing, leading to decimation in frequency, leaving only DTFT samples least affected by [[spectral leakage]].  That is usually a priority when implementing an FFT [[filter bank|filter-bank]] (channelizer).  With a conventional window function of length ''L'', [[Spectral leakage#Window tradeoffs|scalloping loss]] would be unacceptable.  So multi-block windows are created using [[FIR filter]] design tools.&lt;ref&gt;{{cite journal | last1 =Lin | first1 =Yuan-Pei | last2 =Vaidyanathan | first2 =P.P. | title =A Kaiser Window Approach for the Design of Prototype Filters of Cosine Modulated Filterbanks | journal =IEEE Signal Processing Letters | volume =5 | issue =6 | pages =132–134 | date =June 1998 | url =http://authors.library.caltech.edu/6891/1/LINieeespl98.pdf | access-date =2017-03-16}}&lt;/ref&gt;&lt;ref&gt;{{Citation | title =cmfb.m | publisher =Caltech | url =http://www.systems.caltech.edu/dsp/software/conventional/cmfb.m | access-date = 2017-03-16}}&lt;/ref&gt;&amp;nbsp;  Their frequency profile is flat at the highest point and falls off quickly at the midpoint between the remaining DTFT samples.  The larger the value of parameter {{mvar|I}}, the better the potential performance.  We note that the same results can be obtained by computing and decimating an {{mvar|L}}-length DFT, but that is not computationally efficient.

When {{math|''L'' ≤ ''N''}} the DFT is usually written in this more familiar form:

:&lt;math&gt;X_k = \sum_{n=0}^{N-1} x[n]\cdot e^{-i 2\pi \frac{kn}{N}}.&lt;/math&gt;

In order to take advantage of a fast Fourier transform algorithm for computing the DFT, the summation is usually performed over all {{mvar|N}} terms, even though {{math|''N'' − ''L''}} of them are zeros.  Therefore, the case {{math|''L'' &lt; ''N''}} is often referred to as "zero-padding".

Spectral leakage, which increases as {{mvar|L}} decreases, is detrimental to certain important performance metrics, such as resolution of multiple frequency components and the amount of noise measured by each DTFT sample.  But those things don't always matter, for instance when the {{math|''x''[''n'']}} sequence is a noiseless sinusoid (or a constant), shaped by a window function.  Then it is a common practice to use ''zero-padding'' to graphically display and compare the detailed leakage patterns of window functions.  To illustrate that for a rectangular window, consider the sequence:

:&lt;math&gt;x[n] = e^{i 2\pi \frac{1}{8} n},\quad &lt;/math&gt; and &lt;math&gt;L=64.&lt;/math&gt;

'''Figures 2 and 3''' are plots of the magnitude of two different sized DFTs, as indicated in their labels.  In both cases, the dominant component is at the signal frequency: {{math|''f'' {{=}} 1/8 {{=}} 0.125}}.  Also visible in '''Fig 2''' is the spectral leakage pattern of the {{math|''L'' {{=}} 64}} rectangular window.  The illusion in '''Fig 3''' is a result of sampling the DTFT at just its zero-crossings.  Rather than the DTFT of a finite-length sequence, it gives the impression of an infinitely long sinusoidal sequence.  Contributing factors to the illusion are the use of a rectangular window, and the choice of a frequency (1/8 = 8/64) with exactly 8 (an integer) cycles per 64 samples.  A [[Window_function#Hann_window|Hann window]] would produce a similar result, except the peak would be widened to 3 samples (see [https://commons.wikimedia.org/wiki/File:DFT-even_Hann_window_&amp;_spectral_leakage.png DFT-even Hann window]).

== Convolution ==
The [[convolution theorem]] for sequences is:

:&lt;math&gt;x * y\ =\ \scriptstyle \text{DTFT}^{-1} \displaystyle \left[\scriptstyle \text{DTFT} \displaystyle \{x\}\cdot \scriptstyle \text{DTFT} \displaystyle \{y\}\right].&lt;/math&gt;

An important special case is the [[circular convolution]] of sequences {{mvar|x}} and {{mvar|y}} defined by {{math|''x''&lt;sub&gt;''N''&lt;/sub&gt; * ''y''}} where {{math|''x''&lt;sub&gt;''N''&lt;/sub&gt;}} is a periodic summation.  The discrete-frequency nature of {{math|DTFT{''x''&lt;sub&gt;''N''&lt;/sub&gt;}}} "selects" only discrete values from the continuous function {{math|DTFT{''y''}}}, which results in considerable simplification of the inverse transform.  As shown at [[Convolution theorem#Functions of discrete variable sequences]]:

:&lt;math&gt;x_N * y\ =\ \scriptstyle \text{DTFT}^{-1} \displaystyle \left[\scriptstyle \text{DTFT} \displaystyle \{x_N\}\cdot \scriptstyle \text{DTFT} \displaystyle \{y\}\right]\ =\ \scriptstyle \text{DFT}^{-1} \displaystyle \left[\scriptstyle \text{DFT} \displaystyle \{x_N\}\cdot \scriptstyle \text{DFT} \displaystyle \{y_N\}\right].&lt;/math&gt;

For {{mvar|x}} and {{mvar|y}} sequences whose non-zero duration is less than or equal to {{mvar|n}}, a final simplification is:

:&lt;math&gt;x_N * y\ =\ \scriptstyle \text{DFT}^{-1} \displaystyle  \left[\scriptstyle \text{DFT} \displaystyle \{x\}\cdot \scriptstyle \text{DFT} \displaystyle \{y\}\right].&lt;/math&gt;

The significance of this result is expounded at [[Circular convolution#Example|Circular convolution]] and [[Convolution#Fast convolution algorithms|Fast convolution algorithms]].

== DTFT of real and purely imaginary signals ==
*A complex discrete-time signal {{math|''x''[''n'']}} is a real signal (i.e. if &lt;math&gt;x[n] \in \mathbb{R} \quad \forall n \in \mathbb{N}&lt;/math&gt;) if and only if its DTFT {{math|''X''&lt;sub&gt;2π&lt;/sub&gt;(ω)}} is [[Even and odd functions|even symmetric]].
:&lt;math&gt;x[n] \in \mathbb{R} \quad \forall n \in \mathbb{N} \quad \iff \quad X_{2\pi}(\omega) = \overline{X_{2\pi}(-\omega)} \quad \forall \omega \in [0,2\pi]&lt;/math&gt;

*A complex discrete-time signal {{math|''x''[''n'']}} is a purely imaginary signal (i.e. if &lt;math&gt;x[n] \in i \mathbb{R} \quad \forall n \in \mathbb{N}&lt;/math&gt;) if and only if its DTFT {{math|''X''&lt;sub&gt;2π&lt;/sub&gt;(ω)}} is [[Even and odd functions|odd symmetric]].
:&lt;math&gt;x[n] \in i \mathbb{R} \quad \forall n \in \mathbb{N} \quad \iff \quad X_{2\pi}(\omega) = -\overline{X_{2\pi}(-\omega)} \quad \forall \omega \in [0,2\pi]&lt;/math&gt;

== DTFT of even and odd symmetric signals ==
*If a complex discrete-time signal {{math|''x''[''n'']}} is an [[Even and odd functions|even symmetric]] signal (i.e. if &lt;math&gt;x[n] = \overline{x[-n]} \quad \forall n \in \mathbb{N}&lt;/math&gt;), then the DTFT {{math|''X''&lt;sub&gt;2π&lt;/sub&gt;(ω)}} is real for all {{math|ω}}.
:&lt;math&gt;x[n] = \overline{x[-n]} \quad \forall n \in \mathbb{N} \implies X_{2\pi}(\omega) \in \mathbb{R} \quad \forall \omega \in \mathbb{R}&lt;/math&gt;

*If a complex discrete-time signal {{math|''x''[''n'']}} is an [[Even and odd functions|odd symmetric]] signal (i.e. if &lt;math&gt;x[n] = -\overline{x[-n]} \quad \forall n \in \mathbb{N}&lt;/math&gt;), then the DTFT {{math|''X''&lt;sub&gt;2π&lt;/sub&gt;(ω)}} is purely imaginary for all {{math|ω}}.
:&lt;math&gt;x[n] = -\overline{x[-n]} \quad \forall n \in \mathbb{N} \implies X_{2\pi}(\omega) \in i \mathbb{R} \quad \forall \omega \in \mathbb{R}&lt;/math&gt;

== Relationship to the Z-transform ==
&lt;math&gt;X_{2\pi}(\omega)&lt;/math&gt; is a [[Fourier series]] that can also be expressed in terms of the bilateral [[Z-transform]].&amp;nbsp; I.e.:

:&lt;math&gt;X_{2\pi}(\omega) = \left. \widehat X(z) \, \right|_{z = e^{i \omega}} = \widehat X(e^{i \omega}),&lt;/math&gt;

where the &lt;math&gt;\widehat X&lt;/math&gt; notation distinguishes the Z-transform from the Fourier transform.  Therefore, we can also express a portion of the Z-transform in terms of the Fourier transform:

:&lt;math&gt;
\begin{align}
\widehat X(e^{i \omega}) &amp;= \ X_{1/T}\left(\tfrac{\omega}{2\pi T}\right)
 \ = \ \sum_{k=-\infty}^{\infty} X\left(\tfrac{\omega}{2\pi T} - k/T\right)\\
&amp;= \sum_{k=-\infty}^{\infty} X\left(\tfrac{\omega - 2\pi k}{2\pi T} \right).
\end{align}
&lt;/math&gt;

Note that when parameter {{mvar|T}} changes, the terms of &lt;math&gt;X_{2\pi}(\omega)&lt;/math&gt; remain a constant separation &lt;math&gt;2 \pi&lt;/math&gt; apart, and their width scales up or down. The terms of {{math|''X''&lt;sub&gt;1/''T''&lt;/sub&gt;(''f'')}} remain a constant width and their separation {{math|1/''T''}} scales up or down.

== Table of discrete-time Fourier transforms ==
Some common transform pairs are shown in the table below.  The following notation applies:

*&lt;math&gt;\omega=2 \pi f T&lt;/math&gt; is a real number representing continuous angular frequency (in radians per sample). (&lt;math&gt;f&lt;/math&gt; is in cycles/sec, and &lt;math&gt;T&lt;/math&gt; is in sec/sample.)  In all cases in the table, the DTFT is 2π-periodic (in &lt;math&gt;\omega&lt;/math&gt;).
*&lt;math&gt;X_{2\pi}(\omega)&lt;/math&gt; designates a function defined on &lt;math&gt;-\infty &lt; \omega &lt; \infty &lt;/math&gt;.
*&lt;math&gt;X_o(\omega)&lt;/math&gt; designates a function defined on &lt;math&gt;-\pi &lt; \omega \le \pi&lt;/math&gt;, and zero elsewhere.  Then:
::&lt;math&gt;X_{2\pi}(\omega)\ \triangleq \sum_{k=-\infty}^{\infty} X_o(\omega - 2\pi k).&lt;/math&gt;

* &lt;math&gt;\delta ( \omega )&lt;/math&gt; is the [[Dirac delta function]]
* &lt;math&gt;\operatorname{sinc} (t)&lt;/math&gt;  is the normalized [[sinc function]]
* &lt;math&gt;\operatorname{rect}(t)&lt;/math&gt; is the [[rectangle function]]
* &lt;math&gt;\operatorname{tri} (t)&lt;/math&gt; is the [[triangle function]]
* {{mvar|n}} is an integer representing the discrete-time domain (in samples)
* &lt;math&gt;u[n]&lt;/math&gt; is the discrete-time [[Heaviside step function#Discrete form|unit step function]]
* &lt;math&gt;\delta[n]&lt;/math&gt; is the [[Kronecker delta]] &lt;math&gt;\delta_{n,0}&lt;/math&gt;

{| class="wikitable"
|-
! Time domain &lt;br /&gt; ''x''[''n'']
! Frequency domain &lt;br /&gt;X&lt;sub&gt;2π&lt;/sub&gt;(ω)
! Remarks
|-
| &lt;math&gt;\delta[n]&lt;/math&gt;
| &lt;math&gt;X_{2\pi}(\omega) = 1&lt;/math&gt;
| 
|-
| &lt;math&gt;\delta[n-M]&lt;/math&gt;
| &lt;math&gt;X_{2\pi}(\omega) = e^{-i\omega M}&lt;/math&gt;
| integer &lt;math&gt;M&lt;/math&gt;
|-
|&lt;math&gt;\sum_{m = -\infty}^{\infty} \delta[n - M m] \!&lt;/math&gt;
|&lt;math&gt;X_{2\pi}(\omega) = \sum_{m = -\infty}^{\infty} e^{-i \omega M m} = \frac{2\pi}{M}\sum_{k = -\infty}^{\infty} \delta \left( \omega - \frac{2\pi k}{M} \right) \,&lt;/math&gt;&lt;br&gt;
&lt;math&gt;X_o(\omega) = \frac{2\pi}{M}\sum_{k = -(M-1)/2}^{(M-1)/2} \delta \left(\omega - \frac{2\pi k}{M} \right) \,&lt;/math&gt; &amp;nbsp; &amp;nbsp; odd ''M''&lt;br&gt;
&lt;math&gt;X_o(\omega) = \frac{2\pi}{M}\sum_{k = -M/2+1}^{M/2} \delta \left(\omega - \frac{2\pi k}{M} \right) \,&lt;/math&gt; &amp;nbsp; &amp;nbsp; even ''M''&lt;br&gt;
| integer &lt;math&gt;M &gt; 0 &lt;/math&gt;
|-
| &lt;math&gt;u[n]&lt;/math&gt;
| &lt;math&gt;X_{2\pi}(\omega) = \frac{1}{1-e^{-i \omega}} + \pi \sum_{k=-\infty}^{\infty} \delta (\omega - 2\pi k)\!&lt;/math&gt;&lt;br&gt;
&lt;math&gt;X_o(\omega) = \frac{1}{1-e^{-i \omega}} + \pi \cdot \delta (\omega)\!&lt;/math&gt;
|The &lt;math&gt;1/(1-e^{-i \omega})&lt;/math&gt; term must be interpreted as a [[distribution (mathematics)|distribution]] in the sense of a [[Cauchy principal value]] around its [[pole (complex analysis)|poles]] at &lt;math&gt;\omega=2 \pi k&lt;/math&gt;.
|-
| &lt;math&gt;a^n u[n]&lt;/math&gt;
| &lt;math&gt;X_{2\pi}(\omega) = \frac{1}{1-a e^{-i \omega}}\!&lt;/math&gt;
| &lt;math&gt;0 &lt; |a| &lt; 1 &lt;/math&gt;
|-
| &lt;math&gt;e^{-i a n}&lt;/math&gt;
| &lt;math&gt;X_o(\omega) = 2\pi\cdot \delta (\omega +a),&lt;/math&gt; &amp;nbsp; &amp;nbsp; -π &lt; a &lt; π&lt;br&gt;
&lt;math&gt;X_{2\pi}(\omega) = 2\pi \sum_{k=-\infty}^{\infty} \delta (\omega +a -2\pi k)&lt;/math&gt;
| real number &lt;math&gt;a&lt;/math&gt;
|-
| &lt;math&gt;\cos(a\cdot n)&lt;/math&gt;
| &lt;math&gt;X_o(\omega) = \pi \left[\delta \left(\omega -a\right)+\delta \left(\omega +a\right)\right],&lt;/math&gt;&lt;br&gt;
&lt;math&gt;X_{2\pi}(\omega)\ \triangleq \sum_{k=-\infty}^{\infty} X_o(\omega - 2\pi k)&lt;/math&gt;
| real number &lt;math&gt;a&lt;/math&gt; with &lt;math&gt;-\pi &lt; a &lt; \pi&lt;/math&gt;
|-
| &lt;math&gt;\sin(a\cdot n)&lt;/math&gt;
| &lt;math&gt;X_o(\omega) = \frac{\pi}{i} \left[\delta \left(\omega -a\right)-\delta \left(\omega +a\right)\right]&lt;/math&gt;
| real number &lt;math&gt;a&lt;/math&gt; with &lt;math&gt;-\pi &lt; a &lt; \pi&lt;/math&gt;
|-
| &lt;math&gt;\operatorname{rect} \left[ { n - M/2 \over M  } \right] &lt;/math&gt;
| &lt;math&gt;X_o(\omega) = { \sin[ \omega (M+1) / 2 ] \over \sin( \omega / 2 ) } \,  e^{ -\frac{i \omega M}{2} } \!&lt;/math&gt;
| integer &lt;math&gt;M&lt;/math&gt;
|-
| &lt;math&gt;\operatorname{sinc} ( W (n+a))&lt;/math&gt;
| &lt;math&gt;X_o(\omega) =  \frac{1}{W} \operatorname{rect} \left( { \omega \over 2\pi W } \right) e^{ia\omega}&lt;/math&gt;
| real numbers &lt;math&gt;W,a&lt;/math&gt; with &lt;math&gt;0 &lt; W &lt; 1&lt;/math&gt;
|-
| &lt;math&gt;\operatorname{sinc}^2(W n)\,&lt;/math&gt;
| &lt;math&gt;X_o(\omega) = \frac{1}{W} \operatorname{tri} \left( { \omega \over 2\pi W } \right)&lt;/math&gt;
| real number &lt;math&gt;W&lt;/math&gt;, &lt;math&gt;0 &lt; W &lt; 0.5&lt;/math&gt;
|-
| &lt;math&gt; \begin{cases}
0 &amp; n=0 \\
\frac{(-1)^n}{n} &amp; \mbox{elsewhere}
\end{cases}&lt;/math&gt;
| &lt;math&gt;X_o(\omega) = j \omega&lt;/math&gt;
|it works as a [[differentiator]] filter
|-
| &lt;math&gt;\frac{1}{(n + a)} \left\{ \cos [ \pi W (n+a)] - \operatorname{sinc} [ W (n+a)] \right\}&lt;/math&gt;
| &lt;math&gt;X_o(\omega) = \frac{j \omega}{W} \cdot \operatorname{rect} \left( { \omega \over \pi W } \right) e^{j a \omega}&lt;/math&gt;
| real numbers &lt;math&gt;W,a&lt;/math&gt; with &lt;math&gt;0 &lt; W &lt; 1 &lt;/math&gt;
|-
| &lt;math&gt;\begin{cases}
\frac{\pi}{2}  &amp; n = 0 \\
\frac{(-1)^n - 1}{\pi n^2} &amp; \mbox{ otherwise}
\end{cases}&lt;/math&gt;
| &lt;math&gt;X_o(\omega) = |\omega|&lt;/math&gt;
|
|-
| &lt;math&gt;\begin{cases}
0; &amp; n \text{ even} \\
\frac{2}{\pi n} ; &amp; n \text{ odd}
\end{cases}&lt;/math&gt;
| &lt;math&gt;X_o(\omega) = \begin{cases}
j &amp; \omega &lt; 0 \\
0 &amp; \omega = 0 \\
-j &amp; \omega &gt; 0
\end{cases}&lt;/math&gt;
|[[Hilbert transform]]
|-
| &lt;math&gt;\frac{C (A + B)}{2 \pi} \cdot \operatorname{sinc} \left[ \frac{A - B}{2\pi} n \right] \cdot \operatorname{sinc} \left[ \frac{A + B}{2\pi} n \right]&lt;/math&gt;
| &lt;math&gt;X_o(\omega) = &lt;/math&gt;[[Image:Trapezoid signal.svg|250px]]
| real numbers &lt;math&gt;A,B&lt;/math&gt; &lt;br /&gt; complex &lt;math&gt;C&lt;/math&gt;
|}

==Properties==
This table shows some mathematical operations in the time domain and the corresponding effects in the frequency domain.
* &lt;math&gt;*\!&lt;/math&gt; is the [[Convolution#Discrete convolution|discrete convolution]] of two sequences
* &lt;math&gt;x[n]^{*}&lt;/math&gt; is the [[complex conjugate]] of {{math|''x''[''n'']}}.

{| class="wikitable"
|-
! Property
! Time domain&lt;br/&gt;{{math|''x''[''n'']}}
! Frequency domain&lt;br/&gt;&lt;math&gt;X_{2\pi}(\omega)&lt;/math&gt;
! Remarks
! Reference
|-
| Linearity
| &lt;math&gt;a\cdot x[n] + b\cdot y[n]&lt;/math&gt;
| &lt;math&gt;a\cdot X_{2\pi}(\omega) + b\cdot Y_{2\pi}(\omega)&lt;/math&gt;
| complex numbers &lt;math&gt;a,b&lt;/math&gt;
| &lt;ref name=ProakisManolakis&gt;Proakis, John G., Manollakis, Dimitri G., ''Digital Signal Processing'', Prentice-Hall International, 1996.&lt;/ref&gt;{{rp|p. 294}}
|-
| Shift in time / Modulation in frequency
| &lt;math&gt;x[n-k]&lt;/math&gt;
| &lt;math&gt;X_{2\pi}(\omega)\cdot e^{-i\omega k}&lt;/math&gt;
| integer {{mvar|k}}
| &lt;ref name=ProakisManolakis/&gt;{{rp|p. 296}}
|-
| Shift in frequency / Modulation in time
| &lt;math&gt;x[n]\cdot e^{ian} \!&lt;/math&gt;
| &lt;math&gt;X_{2\pi}(\omega-a) \!&lt;/math&gt;
| real number &lt;math&gt;a&lt;/math&gt;
| &lt;ref name=ProakisManolakis/&gt;{{rp|p. 300}}
|-
| Decimation
| &lt;math&gt;x[nM]&lt;/math&gt;
| &lt;math&gt;\frac{1}{M}\sum_{m=0}^{M-1} X_{2\pi}\left(\tfrac{\omega - 2\pi m}{M}\right) \!&lt;/math&gt;&amp;nbsp; &lt;ref group=note&gt;This expression is derived as follows:
:&lt;math&gt;
\begin{align}
\sum_{n=-\infty}^{\infty} x(nMT)\ e^{-i\omega n}
&amp;= \frac{1}{MT}\sum_{k=-\infty}^{\infty} X\left(\tfrac{\omega}{2\pi MT} - \tfrac{k}{MT}\right)\\
&amp;= \frac{1}{MT}\sum_{m=0}^{M-1} \quad \sum_{n=-\infty}^{\infty} X\left(\tfrac{\omega}{2\pi MT} - \tfrac{m}{MT} - \tfrac{n}{T}\right),
\quad \text{where} \quad k \rightarrow m + nM\\
&amp;=\frac{1}{M}\sum_{m=0}^{M-1} \quad \frac{1}{T}\sum_{n=-\infty}^{\infty}X\left(\tfrac{(\omega - 2\pi m)/M}{2\pi T} - \tfrac{n}{T}\right)\\
&amp;= \frac{1}{M}\sum_{m=0}^{M-1} \quad X_{2\pi}\left(\tfrac{\omega - 2\pi m}{M}\right)
\end{align}
&lt;/math&gt;&lt;/ref&gt;
| integer &lt;math&gt;M&lt;/math&gt;
|
|-
| Time Expansion
| &lt;math&gt; \scriptstyle \begin{cases}
x[n/M] &amp; n=\text{multiple of M} \\
0 &amp; \text{otherwise}
\end{cases}&lt;/math&gt;
| &lt;math&gt;X_{2\pi}(M \omega) \!&lt;/math&gt;
| integer &lt;math&gt;M&lt;/math&gt;
|
|-
| Time reversal / Frequency reversal
| &lt;math&gt;x[-n]&lt;/math&gt;
| &lt;math&gt;X_{2\pi}(-\omega) \!&lt;/math&gt;
|
| &lt;ref name=ProakisManolakis/&gt;{{rp|p. 297}}
|-
| Time conjugation
| &lt;math&gt;x[n]^*&lt;/math&gt;
| &lt;math&gt;X_{2\pi}(-\omega)^* \!&lt;/math&gt;
|
| &lt;ref name=ProakisManolakis/&gt;{{rp|p. 291}}
|-
| Time reversal &amp; conjugation
| &lt;math&gt;x[-n]^*&lt;/math&gt;
| &lt;math&gt;X_{2\pi}(\omega)^* \!&lt;/math&gt;
|
| &lt;ref name=ProakisManolakis/&gt;{{rp|p. 291}}
|-
| Derivative in frequency
| &lt;math&gt;\frac{n}{i} x[n] \!&lt;/math&gt;
| &lt;math&gt;\frac{d X_{2\pi}(\omega)}{d \omega} \!&lt;/math&gt;
|
| &lt;ref name=ProakisManolakis/&gt;{{rp|p. 303}}
|-
| Integration in frequency
| &lt;math&gt; \!&lt;/math&gt;
| &lt;math&gt; \!&lt;/math&gt; 
|
|
|-
| Differencing in time
| &lt;math&gt; x[n]-x[n-1] \!&lt;/math&gt; 
| &lt;math&gt; \left( 1-e^{-i \omega} \right) X_{2\pi}(\omega)  \!&lt;/math&gt;
|
|
|-
| Summation in time
| &lt;math&gt; \sum_{m=-\infty}^{n} x[m] \!&lt;/math&gt; 
| &lt;math&gt; \frac{1}{\left( 1-e^{-i \omega} \right)} X_{2\pi}(\omega) + \pi X(0) \sum_{k=-\infty}^{\infty} \delta(\omega-2\pi k) \!&lt;/math&gt;
|
|
|-
| Convolution in time / Multiplication in frequency
| &lt;math&gt;x[n] * y[n] \!&lt;/math&gt;
| &lt;math&gt;X_{2\pi}(\omega) \cdot Y_{2\pi}(\omega) \!&lt;/math&gt;
|
| &lt;ref name=ProakisManolakis/&gt;{{rp|p. 297}}
|-
| Multiplication in time / Convolution in frequency
| &lt;math&gt;x[n] \cdot y[n] \!&lt;/math&gt;
| &lt;math&gt;\frac{1}{2\pi}\int_{-\pi}^{\pi}X_{2\pi}(\nu) \cdot Y_{2\pi}(\omega-\nu) d\nu \!&lt;/math&gt;
| [[Periodic convolution]]
| &lt;ref name=ProakisManolakis/&gt;{{rp|p. 302}}
|-
| [[Cross correlation]]
| &lt;math&gt;\rho_{xy} [n] = x[-n]^* * y[n] \!&lt;/math&gt;
| &lt;math&gt;R_{xy} (\omega) = X_{2\pi}(\omega)^* \cdot Y_{2\pi}(\omega) \!&lt;/math&gt; 
|
|
|-
| [[Parseval's theorem]]  
| &lt;math&gt;E_{xy} = \sum_{n=-\infty}^{\infty} {x[n] \cdot y[n]^*} \!&lt;/math&gt;
| &lt;math&gt;E_{xy} = \frac{1}{2\pi}\int_{-\pi}^{\pi}{X_{2\pi}(\omega) \cdot Y_{2\pi}(\omega)^* d\omega} \!&lt;/math&gt;
|
| &lt;ref name=ProakisManolakis/&gt;{{rp|p. 302}}
|}

==See also==

* [[Multidimensional transform]]
* [[Zak transform]]

== Notes ==
{{reflist|group=note}}

== References ==
{{reflist|refs=

&lt;ref name="Rao"&gt;{{cite book |title=Signals and Systems |author=Rao, R. |isbn=9788120338593 |url=https://books.google.com/books?id=4z3BrI717sMC |publisher=Prentice-Hall Of India Pvt. Limited}}&lt;/ref&gt;

&lt;ref name="Matlab"&gt;{{cite web|url=https://www.mathworks.com/help/signal/ref/periodogram.html|title=Periodogram power spectral density estimate - MATLAB periodogram}}&lt;/ref&gt;

&lt;ref name="Gumas"&gt;{{cite journal|last1=Gumas |first1=Charles Constantine |date=July 1997 |title=Window-presum FFT achieves high-dynamic range, resolution |journal=Personal Engineering &amp; Instrumentation News |pages=58–64 |url=http://www.chipcenter.com/dsp/DSP000315F1.html |deadurl=bot: unknown |archiveurl=https://web.archive.org/web/20010210052902/http://www.chipcenter.com/dsp/DSP000315F1.html |archivedate=2001-02-10 |df= }}&lt;/ref&gt;

&lt;ref name="Lillington"&gt;{{Cite web |last=Lillington|first=John |title=Comparison of Wideband Channelisation Architectures |publisher=RF Engines Ltd |date= |url=http://www.edn.com/Pdf/ViewPdf?contentItemId=4133641 | access-date =2016-10-30
}}&lt;/ref&gt;

&lt;ref name="Chennamangalam"&gt;{{Cite web |last=Chennamangalam|first=Jayanth|title=The Polyphase Filter Bank Technique |publisher=CASPER Group |date=2016-10-18 |url=https://casper.berkeley.edu/wiki/The_Polyphase_Filter_Bank_Technique | access-date =2016-10-30
}}&lt;/ref&gt;

&lt;ref name="Lyons"&gt;{{Cite web |last=Lyons |first=Richard G. |title=DSP Tricks: Building a practical spectrum analyzer |publisher=EE Times |date=June 2008 |url=http://www.embedded.com/design/real-time-and-performance/4007611/DSP-Tricks-Building-a-practical-spectrum-analyzer}} &amp;nbsp; Note however, that it contains a link labeled ''weighted overlap-add structure'' which incorrectly goes to [[Overlap-add method]].&lt;/ref&gt;

&lt;ref name="Dahl"&gt;{{cite thesis |last=Dahl |first=Jason F. |date=2003-02-06 |title=Time Aliasing Methods of Spectrum Estimation |type=Ph.D. |publisher=Brigham Young University |url=http://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=1049&amp;context=etd |access-date=2016-10-31}}&lt;/ref&gt;
}}
{{refbegin|}}

== Further reading==
* {{cite book|title =Multirate Digital Signal Processing|last1 =Crochiere|first1 =R.E.|last2 =Rabiner|first2 =L.R.|date =1983|publisher =Prentice Hall|year=|isbn =0-13-605162-6|location = Englewood Cliffs, NJ|pages =313–326}}
* {{cite book|title=Discrete-Time Signal Processing|last=Oppenheim|first=Alan V.|last2=Schafer|first2=Ronald W.|publisher=Prentice Hall Signal Processing Series|year=1999|isbn=0-13-754920-2|edition=2nd|location=|pages=}}
* {{cite book|title=A Course in Digital Signal Processing|last=Porat|first=Boaz|date=1996|publisher=John Wiley and Sons|year=|isbn=0-471-14961-6|location=|pages=27–29 and 104–105}}
* {{cite book|title=Circuits, Signals, and Systems|last=Siebert|first=William M.|publisher=MIT Press|year=1986|isbn=0262690950|location=MIT Electrical Engineering and Computer Science Series.  Cambridge, MA|pages=}}
* {{cite book|title=Understanding Digital Signal Processing|last=Lyons|first=Richard G.|publisher=Prentice Hall|year=2010|isbn=978-0137027415|edition=3rd|location=|pages=}}

{{refend}}

{{DSP}}

[[Category:Transforms]]
[[Category:Fourier analysis]]
[[Category:Digital signal processing]]</text>
      <sha1>h9adyjqcl590wyzqj2smslii26h7vtz</sha1>
    </revision>
  </page>
  <page>
    <title>Fibration</title>
    <ns>0</ns>
    <id>316826</id>
    <revision>
      <id>846324250</id>
      <parentid>841519341</parentid>
      <timestamp>2018-06-18T00:30:51Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>specify Witold Hurewicz, some tex</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16102">{{About|fibrations in algebraic topology|fibrations in category theory, as used in descent theory and categorical logic|Fibred category}}

In [[topology]], a branch of mathematics, a '''fibration''' is a generalization of the notion of a [[fiber bundle]]. A fiber bundle makes precise the idea of one [[topological space]] (called a fiber) being "parameterized" by another topological space (called a base). A fibration is like a fiber bundle, except that the fibers need not be the same space, nor even [[homeomorphic]]; rather, they are just [[homotopy equivalent]]. Weak fibrations discard even this equivalence for a more technical property.

Fibrations do not necessarily have the local [[Cartesian product]] structure that defines the more restricted fiber bundle case, but something weaker that still allows "sideways" movement from fiber to fiber. Fiber bundles have a particularly simple [[homotopy theory]] that allows topological information about the bundle to be inferred from information about one or both of these constituent spaces. A fibration satisfies an additional condition (the [[homotopy lifting property]]) guaranteeing that it will behave like a fiber bundle from the point of view of homotopy theory.

Fibrations are dual to [[cofibration]]s, with a correspondingly dual notion of the [[homotopy extension property]]; this is loosely known as [[Eckmann–Hilton duality]].

== Formal definition ==
A '''fibration''' (or '''Hurewicz fibration''' or '''Hurewicz fiber space''', so named after [[Witold Hurewicz]]) is a [[continuous function (topology)|continuous mapping]] &lt;math&gt;p \colon E \to B&lt;/math&gt; satisfying the [[homotopy lifting property]] with respect to any space. [[Fiber bundle]]s (over [[paracompact]] bases) constitute important examples. In [[homotopy theory]], any mapping is 'as good as' a fibration—i.e. any map can be decomposed as a homotopy equivalence into a "[[mapping path space]]" followed by a fibration into [[homotopy fiber]]s.

The ''fibers'' are by definition the subspaces of {{mvar|E}} that are the inverse images of points {{mvar|b}} of {{mvar|B}}. If the base space {{mvar|B}} is path connected, it is a consequence of the definition that the fibers of two different points &lt;math&gt;b_1&lt;/math&gt; and &lt;math&gt;b_2&lt;/math&gt; in {{mvar|B}} are [[homotopy equivalence|homotopy equivalent]]. Therefore, one usually speaks of "the fiber" {{mvar|F}}.

== Serre fibrations ==
A continuous mapping with the homotopy lifting property for [[CW complex]]es (or equivalently, just cubes &lt;math&gt;I^n&lt;/math&gt;) is called a '''Serre fibration''' or a '''weak fibration''', in honor of the part played by the concept in the thesis of [[Jean-Pierre Serre]]. This thesis firmly established in [[algebraic topology]] the use of [[spectral sequence]]s, and clearly separated the notions of fiber bundles and fibrations from the notion of [[sheaf (mathematics)|sheaf]] (both concepts together having been implicit in the pioneer treatment of [[Jean Leray]]). Because a sheaf (thought of as an [[étalé space]]) can be considered a [[local homeomorphism]],  the notions were closely interlinked at the time. One of the main desirable properties of the [[Serre spectral sequence]] is to account for the action of the [[fundamental group]] of the base {{mvar|B}} on the homology of the "total space" {{mvar|E}}.

Note that Serre fibrations are strictly weaker than fibrations in general: the homotopy lifting property need only hold on cubes (or CW complexes), and not on all spaces in general. As a result, the fibers might not even be homotopy equivalent; an explicit example is given below.

== Examples ==
In the following examples, a fibration is denoted
:{{math|''F'' → ''E'' → ''B''}},
where the first map is the inclusion of "the" fiber {{mvar|F}} into the total space {{mvar|E}} and the second map is the fibration onto the basis {{mvar|B}}.  This is also referred to as a fibration sequence.

*The projection map from a product space is very easily seen to be a fibration.
*[[Fiber bundle]]s have ''local trivializations,'' i.e. Cartesian product structures exist [[locally]] on {{mvar|B}}, and this is usually enough to show that a fiber bundle is a fibration. More precisely, if there are local trivializations over a [[numerable open cover]] of {{mvar|B}}, the bundle is a fibration.  Any open cover of a [[paracompact]] space has a numerable refinement. For example, any open cover of a metric space has a [[locally finite collection|locally finite refinement]], so any bundle over such a space is a fibration. The local triviality also implies the existence of a [[well-defined]] ''fiber'' ([[up to]] [[homeomorphism]]), at least on each [[connected space|connected component]] of {{mvar|B}}.
* The [[Hopf fibration]] {{math|''S''&lt;sup&gt;1&lt;/sup&gt; → ''S''&lt;sup&gt;3&lt;/sup&gt; → ''S''&lt;sup&gt;2&lt;/sup&gt;}} was historically one of the earliest non-trivial examples of a fibration.
* Hopf fibrations generalize to fibrations over [[complex projective space]], with a fibration {{math|''S''&lt;sup&gt;1&lt;/sup&gt; → ''S''&lt;sup&gt;2''n''+1&lt;/sup&gt; → [[complex projective space|'''CP'''&lt;sup&gt;''n''&lt;/sup&gt;]]}}. The above example is a special case, for n=1, since [[complex projective space|'''CP'''&lt;sup&gt;''1''&lt;/sup&gt;]] is homeomorphic to {{math| ''S''&lt;sup&gt;2&lt;/sup&gt;}}.
* Hopf fibrations generalize to fibrations over [[quaternionic projective space]], with a fibration {{math|''Sp''&lt;sup&gt;1&lt;/sup&gt; → ''S''&lt;sup&gt;4''n''+3&lt;/sup&gt; → [[quaternionic projective space|'''HP'''&lt;sup&gt;''n''&lt;/sup&gt;]]}}.  The fiber here is the group of unit quaternions ''Sp''&lt;sup&gt;1&lt;/sup&gt;.
* The Serre fibration {{math|SO(2) → SO(3) → ''S''&lt;sup&gt;2&lt;/sup&gt;}} comes from the action of the [[rotation group SO(3)|rotation group {{math|SO(3)}}]]  on the [[sphere|2-sphere]] {{math|''S''&lt;sup&gt;2&lt;/sup&gt;}}. Note that {{math|SO(3)}} is homeomorphic to the real projective space [[real projective space|{{math|'''R'''P&lt;sup&gt;3&lt;/sup&gt;}}]], and so {{math|''S''&lt;sup&gt;3&lt;/sup&gt;}} is a double-cover of {{math|SO(3)}}, and so the Hopf fibration is the universal cover. 
* The previous example can also be generalized to a fibration {{math|SO(''n'') → SO(''n''+1) → ''S''&lt;sup&gt;''n''&lt;/sup&gt;}} for any non-negative integer {{mvar|n}} (though they only have a fiber that isn't just a point when {{math|''n'' &gt; 1}}) that comes from the action of the [[orthogonal group|special orthogonal group {{math|SO(''n''+1)}}]] on the {{mvar|n}}-sphere.

=== Weak fibration example ===
The previous examples all have fibers that are homotopy equivalent. This must be the case for fibrations in general, but not necessarily for weak fibrations. The notion of a weak fibration is strictly weaker than a fibration, as the following example illustrates: the fibers might not even have the same [[homotopy type]].

Consider the subset of the real plane &lt;math&gt;\mathbb{R}^2&lt;/math&gt; given by
:&lt;math&gt;E = \{(x,y) : x=y, x\in I \} \cup \bigcup_{n\in \mathbb{N} \atop n&gt;0} \{(x,y) : x\in I, y=1+1/n \}&lt;/math&gt;
and the base space given by the unit interval &lt;math&gt;B=I=\{x : 0\leq x\leq 1 \}&lt;/math&gt;, the projection by &lt;math&gt;p(x,y)=x&lt;/math&gt;.  One can easily see that this is a Serre fibration. However, the fiber &lt;math&gt;p^{-1}(0)&lt;/math&gt; and the fiber at &lt;math&gt;p^{-1}(1)&lt;/math&gt; are not homotopy equivalent. The space &lt;math&gt;p^{-1}(1) \times I&lt;/math&gt; has an obvious injection into the total space &lt;math&gt;E&lt;/math&gt; and has an obvious homotopy (the constant function) in the base space &lt;math&gt;B&lt;/math&gt;; however, it cannot be lifted, and thus the example cannot be a fibration in general.

== Long exact sequence of homotopy groups ==
Choose a base point {{math|''b''&lt;sub&gt;0&lt;/sub&gt; ∈ ''B''}}.  Let {{mvar|F}} refer to the fiber over {{math|''b''&lt;sub&gt;0&lt;/sub&gt;}}, i.e. {{math|''F'' {{=}} ''p''&lt;sup&gt;−1&lt;/sup&gt;({''b''&lt;sub&gt;0&lt;/sub&gt;})}}; and let {{mvar|i}} be the inclusion {{math|''F'' → ''E''}}.  Choose a base point {{math|''f''&lt;sub&gt;0&lt;/sub&gt; ∈ ''F''}} and let {{math|''e''&lt;sub&gt;0&lt;/sub&gt; {{=}} ''i''(''f''&lt;sub&gt;0&lt;/sub&gt;)}}.  In terms of these base points, the [[Puppe sequence]] can be used to show that there is a [[long exact sequence]]
:&lt;math&gt;\cdots\to\pi_n(F)\to\pi_n(E)\to\pi_n(B)\to\pi_{n-1}(F)\to\cdots \to \pi_{0}(F) \to \pi_{0}(E).
&lt;/math&gt;
It is constructed from the [[homotopy group]]s of the fiber {{mvar|F}}, total space {{mvar|E}}, and base space {{mvar|B}}.  The homomorphisms {{math|''π''&lt;sub&gt;''n''&lt;/sub&gt;(''F'') → ''π''&lt;sub&gt;''n''&lt;/sub&gt;(''E'')}} and {{math|''π''&lt;sub&gt;''n''&lt;/sub&gt;(''E'') → ''π''&lt;sub&gt;''n''&lt;/sub&gt;(''B'')}} are just the induced homomorphisms from {{mvar|i}} and {{mvar|p}}, respectively. The maps involving π&lt;sub&gt;0&lt;/sub&gt; are not group [[homomorphism]]s because the π&lt;sub&gt;0&lt;/sub&gt; are not groups, but they are exact in the sense that the image equals the kernel (here the "neutral element" is the connected component containing the base point).

This sequence holds for both fibrations, and for weak fibrations, although the proof of the two cases is slightly different.

===Proof===
One possible way to demonstrate that the sequence above is well-defined and exact, while avoiding contact with the Puppe sequence, is to proceed directly, as follows.
The third set of homomorphisms {{math|''β''&lt;sub&gt;''n''&lt;/sub&gt; : ''π''&lt;sub&gt;''n''&lt;/sub&gt;(''B'') → ''π''&lt;sub&gt;''n''&amp;minus;1&lt;/sub&gt;(''F'')}} (called the "connecting homomorphisms" (in reference to the [[snake lemma]]) or the "boundary maps") is not an induced map and is defined directly in the corresponding homotopy groups with the following steps.
# First, a little terminology: let {{math|''δ''&lt;sub&gt;''n''&lt;/sub&gt; : ''S''&lt;sup&gt;''n''&lt;/sup&gt; → ''D''&lt;sup&gt;''n''+1&lt;/sup&gt;}} be the inclusion of the boundary [[n-sphere|{{mvar|n}}-sphere]] into the [[n-sphere#n-ball|{{math|(''n''+1)}}-ball]].  Let {{math|''γ''&lt;sub&gt;''n''&lt;/sub&gt; : ''D''&lt;sup&gt;''n''&lt;/sup&gt; → ''S''&lt;sup&gt;''n''&lt;/sup&gt;}} be the map that collapses the image of {{math|''δ''&lt;sub&gt;''n''&amp;minus;1&lt;/sub&gt;}} in {{math|''D''&lt;sup&gt;''n''&lt;/sup&gt;}} to a point.
# Let {{math|''φ'' : ''S''&lt;sup&gt;''n''&lt;/sup&gt; → ''B''}} be a representing map for an element of {{math|''π''&lt;sub&gt;''n''&lt;/sub&gt;(''B'')}}.
# Because {{math|''D''&lt;sup&gt;''n''&lt;/sup&gt;}} is homeomorphic to the {{mvar|n}}-dimensional cube, we can apply the homotopy lifting property to construct a lift {{math|''λ'' : ''D''&lt;sup&gt;''n''&lt;/sup&gt; → ''E''}} of {{math|''φ'' ∘ ''γ''&lt;sub&gt;''n''&lt;/sub&gt;}} (i.e., a map {{mvar|λ}} such that {{math|''p'' ∘ ''λ'' {{=}} ''φ'' ∘ ''γ''&lt;sub&gt;''n''&lt;/sub&gt;}}) with initial condition {{math| ''f''&lt;sub&gt;''0''&lt;/sub&gt;}}.
# Because {{math|''γ''&lt;sub&gt;''n''&lt;/sub&gt; ∘ ''δ''&lt;sub&gt;''n''&amp;minus;1&lt;/sub&gt;}} is a point map (hereafter referred to as "{{math|pt}}"), {{math|pt {{=}} ''φ'' ∘ ''γ''&lt;sub&gt;''n''&lt;/sub&gt; ∘ ''δ''&lt;sub&gt;''n''&amp;minus;1&lt;/sub&gt; {{=}} ''p'' ∘ ''λ'' ∘ ''δ''&lt;sub&gt;''n''&amp;minus;1&lt;/sub&gt;}}, which implies that the image of {{math|''λ'' ∘ ''δ''&lt;sub&gt;''n''&amp;minus;1&lt;/sub&gt;}} is in {{mvar|F}}.  Therefore, there exists a map {{math|''ψ'' : ''S''&lt;sup&gt;''n''&amp;minus;1&lt;/sup&gt; → ''F''}} such that {{math|''i'' ∘ ''ψ'' {{=}} ''λ'' ∘ ''δ''&lt;sub&gt;''n''&amp;minus;1&lt;/sub&gt;}}.
# We define {{math|''β''&lt;sub&gt;''n''&lt;/sub&gt; [''φ''] {{=}} [''ψ'']}}.
The above is summarized in the following [[commutative diagram]]:
:[[File:Fibration homotopy groups LES connecting morphism diagram.svg|300px]]

Repeated application of the homotopy lifting property is used to prove that {{math|''β''&lt;sub&gt;''n''&lt;/sub&gt;}} is well-defined (does not depend on a particular lift), depends only on the homotopy class of its argument, it is a homomorphism and that the long sequence is exact.

Alternatively, one can use relative homotopy groups to obtain the long exact sequence on homotopy of a fibration from the long exact sequence on relative homotopy&lt;ref&gt;{{citation
|title=Algebraic Topology
|first=Allen
|last=Hatcher
|journal=Cambridge University Press
|year=2002
|url=https://www.math.cornell.edu/~hatcher/AT/AT.pdf
|issue=1
}}&lt;/ref&gt; of the pair &lt;math&gt;F \subseteq E&lt;/math&gt;.  One uses that the n-th homotopy group of  &lt;math&gt;E&lt;/math&gt; relative to  &lt;math&gt;F&lt;/math&gt; is isomorphic to the n-th homotopy group of the base &lt;math&gt;B&lt;/math&gt;.

===Example===
One may also proceed in the reverse direction. When the fibration is the [[homotopy fiber|mapping fibre]] (dual to the [[mapping cone (topology)|mapping cone]], a [[cofibration]]), then one obtains the exact [[Puppe sequence]].  In essence, the long exact sequence of homotopy groups follows from the fact that the homotopy groups can be obtained as suspensions, or dually, [[loop space]]s.

== Euler characteristic ==
{{Main|Euler characteristic}}
The [[Euler characteristic]] {{mvar|χ}} is multiplicative for [[fibrations]] with certain conditions.

If {{math|''p'' : ''E'' → ''B''}} is a fibration with fiber {{mvar|F}}, with the base {{mvar|B}} [[path-connected]], and the fibration is orientable over a field {{mvar|K}}, then the Euler characteristic with coefficients in the field {{mvar|K}} satisfies the product property:&lt;ref&gt;{{citation
|title=Algebraic Topology
|first=Edwin Henry
|last=Spanier
|authorlink=Edwin Spanier
|publisher=Springer
|year=1982
|isbn=978-0-387-94426-5
|url=https://books.google.com/books?id=h-wc3TnZMCcC
}}, [https://books.google.com/books?id=h-wc3TnZMCcC&amp;pg=PA481 Applications of the homology spectral sequence, p. 481]&lt;/ref&gt;
:{{math|''χ''(''E'') {{=}} ''χ''(''F'') · ''χ''(''B'')}}.
This includes product spaces and covering spaces as special cases,
and can be proven by the [[Serre spectral sequence]] on homology of a fibration.

For fiber bundles, this can also be understood in terms of a [[transfer map]] {{math|''τ'' : ''H''&lt;sub&gt;&amp;#x2217;&lt;/sub&gt;(''B'') → ''H''&lt;sub&gt;&amp;#x2217;&lt;/sub&gt;(''E'')}}—note that this is a lifting and goes "the wrong way"—whose composition with the projection map {{math|''p''&lt;sub&gt;&amp;#x2217;&lt;/sub&gt; : ''H''&lt;sub&gt;&amp;#x2217;&lt;/sub&gt;(''E'') → ''H''&lt;sub&gt;&amp;#x2217;&lt;/sub&gt;(''B'')}} is multiplication by the Euler characteristic of the fiber:&lt;ref&gt;{{citation
|title=Fibre bundles and the Euler characteristic
|first=Daniel Henry
|last=Gottlieb
|journal=Journal of Differential Geometry
|volume=10
|year=1975
|pages=39–48
|url=http://www.math.purdue.edu/~gottlieb/Bibliography/17FibreBundlesAndtheEulerCharacteristic.pdf
|issue=1
|doi=10.4310/jdg/1214432674
}}&lt;/ref&gt;
{{math|''p''&lt;sub&gt;&amp;#x2217;&lt;/sub&gt; ∘ ''τ'' {{=}} ''χ''(''F'') · 1}}.

== Fibrations in closed model categories ==
Fibrations of topological spaces fit into a more general framework, the so-called [[closed model category|closed model categories]], following from the [[acyclic model]]s theorem. In such categories, there are distinguished classes of morphisms, the so-called ''fibrations'', ''[[cofibration]]s'' and ''[[weak equivalence (homotopy theory)|weak equivalence]]s''. Certain [[axiom]]s, such as stability of fibrations under composition and  [[pullback (category theory)|pullbacks]], factorization of every morphism into the composition of an acyclic cofibration followed by a fibration or a cofibration followed by an acyclic fibration, where the word "acyclic" indicates that the corresponding arrow is also a weak equivalence, and other requirements are set up to allow the abstract treatment of homotopy theory. (In the original treatment, due to [[Daniel Quillen]], the word "trivial" was used instead of "acyclic.")

It can be shown that the category of topological spaces is in fact a model category, where (abstract) fibrations are just the Serre fibrations introduced above and weak equivalences are weak [[homotopy equivalence]]s.&lt;ref&gt;{{citation
|title=Handbook of algebraic topology
|first1=William G.
|last1=Dwyer
|first2=J.
|last2=Spaliński
|authorlink=William G. Dwyer
|publisher=North-Holland
|location=Amsterdam
|year=1995
|chapter=Homotopy theories and model categories
|pages=73–126
|mr=1361887
|url=http://hopf.math.purdue.edu/cgi-bin/generate?/Dwyer-Spalinski/theories
|doi=10.1016/B978-044481779-2/50003-1
}}&lt;/ref&gt;

== See also ==
* [[Homotopy colimit]]
* [[Homotopy fiber]]
* [[Quasi-fibration]]
* [[Hopf fibration]]
* [[Change of fiber]]
* [[G-fibration]]

== References ==
&lt;references/&gt;

[[Category:Algebraic topology]]
[[Category:Homotopy theory]]
[[Category:Differential topology]]
[[Category:Category theory]]</text>
      <sha1>hf2apra3bbieugqc58197jy01zf6cj3</sha1>
    </revision>
  </page>
  <page>
    <title>Four-dimensional space</title>
    <ns>0</ns>
    <id>1364622</id>
    <revision>
      <id>863823893</id>
      <parentid>863823432</parentid>
      <timestamp>2018-10-13T08:54:31Z</timestamp>
      <contributor>
        <username>Purgy Purgatorio</username>
        <id>22035051</id>
      </contributor>
      <comment>typos</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32277">{{Multiple issues|
{{Technical|date=December 2016}}
{{Refimprove|date=December 2016}}
}}
[[File:8-cell-simple.gif|frame|The 4D equivalent of a [[cube]], known as a [[tesseract]]. The tesseract is rotating in four-dimensional space, and it is displayed here projected into two dimensions.|alt=Animation of a transforming tesseract or 4-cube]]

A '''four-dimensional space''' or '''4D space''' is a mathematical extension of the concept of three-dimensional or 3D space. [[Three-dimensional space]] is the simplest possible generalization of the observation that one only needs three numbers, called ''dimensions'', to describe the sizes or locations of objects in the everyday world. For example, the volume of a rectangular box is found by measuring its length (often labeled ''x''), width (''y''), and depth (''z'').

The idea of adding a fourth dimension began with [[Joseph-Louis Lagrange]] in the mid-1700s and culminated in a precise formalization of the concept in 1854 by [[Bernhard Riemann]]. In 1880 [[Charles Howard Hinton]] popularized these insights in an essay titled ''[[s:What is the Fourth Dimension?|What is the Fourth Dimension?]]'', which explained the concept of a four-dimensional cube with a step-by-step generalization of the properties of lines, squares, and cubes. The simplest form of Hinton's method is to draw two ordinary cubes separated by an "unseen" distance, and then draw lines between their equivalent vertices. This can be seen in the accompanying animation, whenever it shows a smaller inner cube inside a larger outer cube. The eight lines connecting the vertices of the two cubes in that case represent a single direction in the "unseen" fourth dimension.

Higher dimensional spaces have since become one of the foundations for formally expressing modern mathematics and physics. Large parts of these topics could not exist in their current forms without the use of such spaces. [[Albert Einstein|Einstein's]] concept of [[spacetime]] uses such a 4D space, though it has a [[Minkowski space|Minkowski]] structure that is a bit more complicated than [[Euclidean geometry|Euclidean]] 4D space.

Single locations in 4D space can be given as [[Vector space|vectors]] or ''[[n-tuples]]'', i.e. as ordered lists of numbers such as ''(t,x,y,z)''. It is only when such locations are linked together into more complicated shapes that the full richness and geometric complexity of 4D and higher dimensional spaces emerge. A hint to that complexity can be seen in the accompanying animation of one of simplest possible 4D objects, the 4D cube or [[tesseract]].

==History==
[[Joseph-Louis Lagrange|Lagrange]] wrote in his ''Mécanique analytique'' (published 1788, based on work done around 1755) that [[mechanics]] can be viewed as operating in a four-dimensional space &amp;mdash; three dimensions of space, and one of time.&lt;ref&gt;{{cite book|last1=Bell|first1=E.T.|title=Men of Mathematics|date=1965|publisher=Simon and Schuster|location=New York|isbn=978-0-671-62818-5|page=154|edition=1st}}&lt;/ref&gt; In 1827 [[August Ferdinand Möbius|Möbius]] realized that a fourth dimension would allow a three-dimensional form to be rotated onto its mirror-image,&lt;ref name="Coxeter"&gt;{{cite book|last1=Coxeter|first1=H.S.M.|title=Regular Polytopes|date=1973|publisher=Dover Publishing|location=New York|isbn=978-0-486-61480-9|edition=3rd}}&lt;/ref&gt;{{rp|141}} and by 1853 [[Ludwig Schläfli]] had discovered many [[polytope]]s in higher dimensions, although his work was not published until after his death.&lt;ref name="Coxeter"/&gt;{{rp|142–143}} Higher dimensions were soon put on firm footing by [[Bernhard Riemann]]'s 1854 [[Habilitationsschrift|thesis]], ''Über die Hypothesen welche der Geometrie zu Grunde liegen'', in which he considered a "point" to be any sequence of coordinates (''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''n''&lt;/sub&gt;). The possibility of geometry in [[higher dimension]]s, including four dimensions in particular, was thus established.

An arithmetic of four dimensions called [[quaternion]]s was defined by [[William Rowan Hamilton]] in 1843. This [[associative algebra]] was the source of the science of [[vector analysis]] in three dimensions as recounted in ''[[A History of Vector Analysis]]''. Soon after [[tessarine]]s and [[coquaternion]]s were introduced as other four-dimensional [[algebra over a field|algebras over '''R''']].

One of the first major expositors of the fourth dimension was [[Charles Howard Hinton]], starting in 1880 with his essay ''What is the Fourth Dimension?''; published in the [[Dublin University]] magazine.&lt;ref&gt;{{cite book|last1=Hinton|first1=Charles Howard|authorlink1=Charles Howard Hinton|title=Speculations on the Fourth Dimension: Selected writings of Charles H. Hinton|date=1980|editor-first=Rudolf v. B.|editor-last=Rucker|publisher=Dover|location=New York|isbn=978-0-486-23916-3|page=vii}}&lt;/ref&gt; He coined the terms ''[[tesseract]]'', ''ana'' and ''kata'' in his book ''[[A New Era of Thought]]'', and introduced a method for visualising the fourth dimension using cubes in the book ''Fourth Dimension''.&lt;ref name="Hinton"&gt;{{cite book|last1=Hinton|first1=Charles Howard|title=The Fourth Dimension|orig-year=1904|date=1993|publisher=Health Research|location=Pomeroy, Washington|isbn=978-0-7873-0410-2|page=14|url=https://books.google.com/books?id=_ZG3MA1wvjIC&amp;pg=PA14|accessdate=17 February 2017|language=en}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Gardner|first1=Martin|title=Mathematical Carnival: From Penny Puzzles. Card Shuffles and Tricks of Lightning Calculators to Roller Coaster Rides into the Fourth Dimension|date=1975|publisher=[[Knopf Publishing|Knopf]]|location=New York|isbn=978-0-394-49406-7|pages=42, 52–53|edition=1st}}&lt;/ref&gt;

Hinton's ideas inspired a fantasy about a "Church of the Fourth Dimension" featured by [[Martin Gardner]] in his January 1962 "[[Mathematical Games column]]" in ''[[Scientific American]]''. In 1886 [[Victor Schlegel]] described&lt;ref&gt;[[Victor Schlegel]] (1886) ''Ueber Projectionsmodelle der regelmässigen vier-dimensionalen Körper'', Waren&lt;/ref&gt; his method of visualizing four-dimensional objects with [[Schlegel diagram]]s.

In 1908, [[Hermann Minkowski]] presented a paper&lt;ref&gt;{{Citation|author=Minkowski, Hermann|year=1909|title=Raum und Zeit|journal=Physikalische Zeitschrift|volume=10|pages=75–88|title-link=s:de:Raum und Zeit (Minkowski)}}
*Various English translations on Wikisource: [[s:Space and Time|Space and Time]]
&lt;/ref&gt; consolidating the role of time as the fourth dimension of [[spacetime]], the basis for [[Albert Einstein|Einstein's]] theories of [[Special relativity|special]] and [[general relativity]].&lt;ref name="Møller"&gt;{{cite book|last1=Møller|first1=C.|title=The Theory of Relativity|date=1972|publisher=Clarendon Press|location=Oxford|isbn=978-0-19-851256-1|page=93|edition=2nd}}&lt;/ref&gt; But the geometry of spacetime, being [[non-Euclidean]], is profoundly different from that popularised by Hinton. The study of [[Minkowski space]] required new mathematics quite different from that of four-dimensional Euclidean space, and so developed along quite different lines. This separation was less clear in the popular imagination, with works of fiction and philosophy blurring the distinction, so in 1973 [[H. S. M. Coxeter]] felt compelled to write:
{{quote|Little, if anything, is gained by representing the fourth Euclidean dimension as ''time''. In fact, this idea, so attractively developed by [[The Time Machine|H. G. Wells in ''The Time Machine'']], has led such authors as [[An Experiment with Time|John William Dunne (''An Experiment with Time'')]] into a serious misconception of the theory of Relativity. Minkowski's geometry of space-time is ''not'' Euclidean, and consequently has no connection with the present investigation.
|[[H. S. M. Coxeter]]|''Regular Polytopes''&lt;ref name="Coxeter"/&gt;{{rp|119}}}}

==Vectors==
Mathematically four-dimensional space is simply a space with four spatial dimensions, that is a [[space (mathematics)|space]] that needs four parameters to specify a [[point (geometry)|point]] in it. For example, a general point might have position [[Euclidean vector|vector]] '''a''', equal to
: &lt;math&gt;\mathbf{a} = \begin{pmatrix} a_1 \\ a_2 \\ a_3 \\ a_4 \end{pmatrix}.&lt;/math&gt;
This can be written in terms of the four [[standard basis]] vectors ('''e'''&lt;sub&gt;1&lt;/sub&gt;, '''e'''&lt;sub&gt;2&lt;/sub&gt;, '''e'''&lt;sub&gt;3&lt;/sub&gt;, '''e'''&lt;sub&gt;4&lt;/sub&gt;), given by
:&lt;math&gt;\mathbf{e}_1 = \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix}; \mathbf{e}_2 = \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}; \mathbf{e}_3 = \begin{pmatrix} 0 \\ 0 \\ 1 \\ 0 \end{pmatrix}; \mathbf{e}_4 = \begin{pmatrix} 0 \\ 0 \\ 0 \\ 1 \end{pmatrix}, &lt;/math&gt;
so the general vector '''a''' is
: &lt;math&gt; \mathbf{a} = a_1\mathbf{e}_1 + a_2\mathbf{e}_2 + a_3\mathbf{e}_3 + a_4\mathbf{e}_4.&lt;/math&gt;
Vectors add, subtract and scale as in three dimensions.

The [[dot product]] of Euclidean three-dimensional space generalizes to four dimensions as
: &lt;math&gt;\mathbf{a} \cdot \mathbf{b} = a_1 b_1 + a_2 b_2 + a_3 b_3 + a_4 b_4.&lt;/math&gt;
It can be used to calculate the [[norm (mathematics)|norm]] or [[Euclidean distance|length]] of a vector,
:&lt;math&gt; \left| \mathbf{a} \right| = \sqrt{\mathbf{a} \cdot \mathbf{a} } = \sqrt{a_1^2 + a_2^2 + a_3^2 + a_4^2},&lt;/math&gt;
and calculate or define the [[angle]] between two non-zero vectors as
:&lt;math&gt; \theta = \arccos{\frac{\mathbf{a} \cdot \mathbf{b}}{\left|\mathbf{a}\right| \left|\mathbf{b}\right|}}.&lt;/math&gt;

Minkowski spacetime is four-dimensional space with geometry defined by a non-degenerate [[pairing]] different from the dot product:
: &lt;math&gt;\mathbf{a} \cdot \mathbf{b} = a_1 b_1 + a_2 b_2 + a_3 b_3 - a_4 b_4.&lt;/math&gt;
As an example, the distance squared between the points (0,0,0,0) and (1,1,1,0) is 3 in both the Euclidean and Minkowskian 4-spaces, while the distance squared between (0,0,0,0) and (1,1,1,1) is 4 in Euclidean space and 2 in Minkowski space; increasing &lt;math&gt;b_4&lt;/math&gt; actually decreases the metric distance.  This leads to many of the well-known apparent "paradoxes" of relativity.

The [[cross product]] is not defined in four dimensions. Instead the [[exterior product]] is used for some applications, and is defined as follows:
: &lt;math&gt; \begin{align}
\mathbf{a} \wedge \mathbf{b} = (a_1b_2 - a_2b_1)\mathbf{e}_{12} + (a_1b_3 - a_3b_1)\mathbf{e}_{13} + (a_1b_4 - a_4b_1)\mathbf{e}_{14} + (a_2b_3 - a_3b_2)\mathbf{e}_{23} \\
+ (a_2b_4 - a_4b_2)\mathbf{e}_{24} + (a_3b_4 - a_4b_3)\mathbf{e}_{34}. \end{align}&lt;/math&gt;
This is [[bivector]] valued, with bivectors in four dimensions forming a [[six-dimensional space|six-dimensional]] linear space with basis ('''e'''&lt;sub&gt;12&lt;/sub&gt;, '''e'''&lt;sub&gt;13&lt;/sub&gt;, '''e'''&lt;sub&gt;14&lt;/sub&gt;, '''e'''&lt;sub&gt;23&lt;/sub&gt;, '''e'''&lt;sub&gt;24&lt;/sub&gt;, '''e'''&lt;sub&gt;34&lt;/sub&gt;). They can be used to generate rotations in four dimensions.

==Orthogonality and vocabulary==
In the familiar three-dimensional space in which we live there are three [[coordinate system|coordinate axes]]—usually labeled ''x'', ''y'', and ''z''—with each axis [[orthogonal]] (i.e. perpendicular) to the other two. The six cardinal directions in this space can be called ''up'', ''down'', ''east'', ''west'', ''north'', and ''south''. Positions along these axes can be called ''altitude'', ''longitude'', and ''latitude''. Lengths measured along these axes can be called ''height'', ''width'', and ''depth''.

Comparatively, four-dimensional space has an extra coordinate axis, orthogonal to the other three, which is usually labeled ''w''. To describe the two additional cardinal directions, [[Charles Howard Hinton]] coined the terms ''ana'' and ''kata'', from the Greek words meaning "up toward" and "down from", respectively. A position along the ''w'' axis can be called ''spissitude'', as coined by [[Henry More]].

==Geometry==
{{See also|Rotations in 4-dimensional Euclidean space}}
The geometry of four-dimensional space is much more complex than that of three-dimensional space, due to the extra degree of freedom.

Just as in three dimensions there are [[polyhedron|polyhedra]] made of two dimensional [[polygon]]s, in four dimensions there are [[4-polytope]]s made of polyhedra. In three dimensions, there are 5 regular polyhedra known as the [[Platonic solid]]s. In four dimensions, there are 6 [[convex regular 4-polytope]]s, the analogues of the Platonic solids. Relaxing the conditions for regularity generates a further 58 convex [[uniform 4-polytope]]s, analogous to the 13 semi-regular [[Archimedean solid]]s in three dimensions. Relaxing the conditions for convexity generates a further 10 nonconvex regular 4-polytopes.

{| class=wikitable
|+ Regular polytopes in four dimensions&lt;br&gt;(Displayed as orthogonal projections in each [[Coxeter plane]] of symmetry)
|-
!A&lt;sub&gt;4&lt;/sub&gt;, [3,3,3]
!colspan=2|B&lt;sub&gt;4&lt;/sub&gt;, [4,3,3]
!F&lt;sub&gt;4&lt;/sub&gt;, [3,4,3]
!colspan=2|H&lt;sub&gt;4&lt;/sub&gt;, [5,3,3]
|- align=center
|[[File:4-simplex t0.svg|altN=4-simplex|120px]]&lt;br&gt;[[5-cell]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node}}&lt;BR&gt;{3,3,3}
|[[File:4-cube t0.svg|altN=4-cube|120px]]&lt;br&gt;[[tesseract]]&lt;br&gt;{{CDD|node_1|4|node|3|node|3|node}}&lt;BR&gt;{4,3,3}
|[[File:4-cube t3.svg|altN=4-orthoplex|120px]]&lt;br&gt;[[16-cell]]&lt;br&gt;{{CDD|node_1|3|node|3|node|4|node}}&lt;BR&gt;{3,3,4}
|[[File:24-cell graph.svg|altN=24-cell|120px]]&lt;br&gt;[[24-cell]]&lt;br&gt;{{CDD|node_1|3|node|4|node|3|node}}&lt;BR&gt;{3,4,3}
|[[File:120-cell graph H4.svg|altN=120-cell|120px]]&lt;br&gt;[[120-cell]]&lt;br&gt;{{CDD|node_1|5|node|3|node|3|node}}&lt;BR&gt;{5,3,3}
|[[File:600-cell graph H4.svg|altN=600-cell|120px]]&lt;br&gt;[[600-cell]]&lt;br&gt;{{CDD|node_1|3|node|3|node|5|node}}&lt;BR&gt;{3,3,5}
|}

In three dimensions, a circle may be [[extrude]]d to form a [[cylinder (geometry)|cylinder]]. In four dimensions, there are several different cylinder-like objects. A sphere may be extruded to obtain a spherical cylinder (a cylinder with spherical "caps", known as a [[spherinder]]), and a cylinder may be extruded to obtain a cylindrical prism (a [[cubinder]]). The [[Cartesian product]] of two circles may be taken to obtain a [[duocylinder]]. All three can "roll" in four-dimensional space, each with its own properties.

In three dimensions, curves can form [[knot (mathematics)|knot]]s but surfaces cannot (unless they are self-intersecting). In four dimensions, however, knots made using curves can be trivially untied by displacing them in the fourth direction—but 2D surfaces can form non-trivial, non-self-intersecting knots in 4D space.&lt;ref&gt;{{cite book|last1=Carter|first1=J.Scott|last2=Saito|first2=Masahico|title=Knotted Surfaces and Their Diagrams|publisher=American Mathematical Society|isbn=978-0-8218-7491-2|url=https://books.google.com/books?id=TIGVq4GeEM4C}}&lt;/ref&gt;{{Page needed|date=December 2016}} Because these surfaces are two-dimensional, they can form much more complex knots than strings in 3D space can. The [[Klein bottle]] is an example of such a knotted surface.{{citation needed|date=January 2013}} Another such surface is the [[real projective plane]].{{citation needed|date=January 2013}} &lt;!-- did a google search and can't find anything on these as examples of knotted surfaces.  This book https://books.google.com/books?id=TIGVq4GeEM4C seems to talk about the Klein bottle as an unknotted surface. Presumably if knotted has to be knotted relative to some other surface it is homeomorphic to which is unknotted, which surface is that? --&gt;

===Hypersphere===
[[File:Clifford-torus.gif|thumb|right|256px|[[Stereographic projection]] of a [[Clifford torus]]: the set of points (cos(''a''), sin(''a''), cos(''b''), sin(''b'')), which is a subset of the [[3-sphere]].]]
{{Main article|Hypersphere}}
The set of points in [[Euclidean space|Euclidean 4-space]] having the same distance R from a fixed point P&lt;sub&gt;0&lt;/sub&gt; forms a [[hypersurface]] known as a [[3-sphere]]. The hyper-volume of the enclosed space is:

: &lt;math&gt; \mathbf V = \begin{matrix} \frac{1}{2} \end{matrix} \pi^2 R^4&lt;/math&gt;

This is part of the [[Friedmann–Lemaître–Robertson–Walker metric]] in [[General relativity]] where ''R'' is substituted by function ''R(t)'' with ''t'' meaning the cosmological age of the universe. Growing or shrinking ''R'' with time means expanding or collapsing universe, depending on the mass density inside.&lt;ref&gt;{{cite book|last1=D'Inverno|first1=Ray|title=Introducing Einstein's Relativity|date=1998|publisher=Clarendon Press|location=Oxford|isbn=978-0-19-859653-0|page=319|edition=Reprint}}&lt;/ref&gt;

==Cognition==
Research using [[virtual reality]] finds that humans, in spite of living in a three-dimensional world, can, without special practice, make spatial judgments about line segments, embedded in four-dimensional space, based on their length (one dimensional) and the angle (two dimensional) between them.&lt;ref name="Ambinder"&gt;{{cite journal|last1=Ambinder|first1=Michael S.|last2=Wang|first2=Ranxiao Frances|last3=Crowell|first3=James A.|last4=Francis|first4=George K.|last5=Brinkmann|first5=Peter|title=Human four-dimensional spatial intuition in virtual reality|journal=Psychonomic Bulletin &amp; Review|date=October 2009|volume=16|issue=5|pages=818–823|doi=10.3758/PBR.16.5.818|pmid=19815783|url=http://pbr.psychonomic-journals.org/content/16/5/818/suppl/DC1|accessdate=17 February 2017}}&lt;/ref&gt; The researchers noted that "the participants in our study had minimal practice in these tasks, and it remains an open question whether it is possible to obtain more sustainable, definitive, and richer 4D representations with increased perceptual experience in 4D virtual environments."&lt;ref name="Ambinder"/&gt; In another study,&lt;ref name="Aflalo"&gt;{{cite journal|last1=Aflalo|first1=T. N.|last2=Graziano|first2=M. S. A.|title=Four-dimensional spatial reasoning in humans|journal=Journal of Experimental Psychology: Human Perception and Performance|date=2008|volume=34|issue=5|pages=1066–1077|doi=10.1037/0096-1523.34.5.1066|pmid=18823195|url=http://www.princeton.edu/~graziano/Aflalo_08.pdf|accessdate=17 February 2017|citeseerx=10.1.1.505.5736}}&lt;/ref&gt; the ability of humans to orient themselves in 2D, 3D and 4D mazes has been tested. Each maze consisted of four path segments of random length and connected with orthogonal random bends, but without branches or loops (i.e. actually [[labyrinth]]s). The graphical interface was based on John McIntosh's free 4D Maze game.&lt;ref name=McIntosh&gt;{{cite web|url=http://www.urticator.net/maze/ |title=4D Maze Game |publisher=urticator.net |date= |accessdate=2016-12-16}}&lt;/ref&gt; The participating persons had to navigate through the path and finally estimate the linear direction back to the starting point. The researchers found that some of the participants were able to mentally integrate their path after some practice in 4D (the lower-dimensional cases were for comparison and for the participants to learn the method).

==Dimensional analogy==
[[File:Tesseract net.svg|thumb|A net of a tesseract]]

To understand the nature of four-dimensional space, a device called ''dimensional analogy'' is commonly employed. Dimensional analogy is the study of how (''n'' − 1) dimensions relate to ''n'' dimensions, and then inferring how ''n'' dimensions would relate to (''n'' + 1) dimensions.&lt;ref&gt;{{cite book|last1=Kaku|first1=Michio|authorlink=Michio Kaku|title=Hyperspace: A Scientific Odyssey Through Parallel Universes, Time Warps, and the Tenth Dimension|date=1995|publisher=Oxford University Press|location=Oxford|isbn=978-0-19-286189-4|pages=Part I, Chapter 3|edition=reissued|title-link=Hyperspace (book)}}&lt;/ref&gt;

Dimensional analogy was used by [[Edwin Abbott Abbott]] &lt;!--yes, his middle name is the same as his surname--&gt; in the book ''[[Flatland]]'', which narrates a story about a square that lives in a two-dimensional world, like the surface of a piece of paper. From the perspective of this square, a three-dimensional being has seemingly god-like powers, such as ability to remove objects from a safe without breaking it open (by moving them across the third dimension), to see everything that from the two-dimensional perspective is enclosed behind walls, and to remain completely invisible by standing a few inches away in the third dimension.

By applying dimensional analogy, one can infer that a four-dimensional being would be capable of similar feats from our three-dimensional perspective. [[Rudy Rucker]] illustrates this in his novel ''[[Spaceland (novel)|Spaceland]]'', in which the protagonist encounters four-dimensional beings who demonstrate such powers.

===Cross-sections===
As a three-dimensional object passes through a two-dimensional plane, a two-dimensional being would only see a [[Cross section (geometry)|cross-section]] of the three-dimensional object. For example, if a spherical balloon passed through a sheet of paper, a being on the paper would see first a single point, then a circle gradually growing larger, then smaller again until it shrank to a point and then disappeared. Similarly, if a four-dimensional object passed through three dimensions, we would see a three-dimensional cross-section of the four-dimensional object&amp;mdash;for example, a hypersphere would appear first as a point, then as a growing sphere, with the sphere then shrinking to a single point and then disappearing.&lt;ref&gt;{{cite book|last1=Rucker|first1=Rudy|title=The Fourth Dimension: A Guided Tour of the Higher Universe|date=1996|publisher=Houghton Mifflin|location=Boston|isbn=978-0-395-39388-8|page=18}}&lt;/ref&gt; This means of visualizing aspects of the fourth dimension was used in the novel ''Flatland'' and also in several works of [[Charles Howard Hinton]].&lt;ref name="Hinton"/&gt;{{rp|11–14}}

===Projections===
A useful application of dimensional analogy in visualizing higher dimensions is in [[Graphical projection|projection]]. A projection is a way for representing an ''n''-dimensional object in {{math|''n'' − 1}} dimensions. For instance, computer screens are two-dimensional, and all the photographs of three-dimensional people, places and things are represented in two dimensions by projecting the objects onto a flat surface. By doing this, the dimension orthogonal to the screen (''depth'') is removed and replaced with indirect information. The [[retina]] of the [[human eye|eye]] is also a two-dimensional [[Array data structure|array]] of [[Sensory receptor|receptor]]s but the [[brain]] is able to perceive the nature of three-dimensional objects by inference from indirect information (such as shading, [[foreshortening]], [[binocular vision]], etc.). [[Artist]]s often use [[perspective (graphical)|perspective]] to give an illusion of three-dimensional depth to two-dimensional pictures. The ''shadow'', cast by a fictitious grid model of a rotating tesseract on a plane surface, as shown in the figures, is also the result of projections.

Similarly, objects in the fourth dimension can be mathematically projected to the familiar three dimensions, where they can be more conveniently examined. In this case, the 'retina' of the four-dimensional eye is a three-dimensional array of receptors. A hypothetical being with such an eye would perceive the nature of four-dimensional objects by inferring four-dimensional depth from indirect information in the three-dimensional images in its retina.

The perspective projection of three-dimensional objects into the retina of the eye introduces artifacts such as foreshortening, which the brain interprets as depth in the third dimension. In the same way, perspective projection from four dimensions produces similar foreshortening effects. By applying dimensional analogy, one may infer four-dimensional "depth" from these effects.

As an illustration of this principle, the following sequence of images compares various views of the three-dimensional [[cube]] with analogous projections of the four-dimensional tesseract into three-dimensional space.

{|class="wikitable"
|-
!Cube
!Tesseract
!Description
|-
|[[File:Cube-face-first.png|160px]]
|[[File:Tesseract-perspective-cell-first.png|160px]]
|The image on the left is a cube viewed face-on. The analogous viewpoint of the tesseract in 4 dimensions is the '''cell-first perspective projection''', shown on the right. One may draw an analogy between the two: just as the cube projects to a square, the tesseract projects to a cube.

Note that the other 5 faces of the cube are not seen here. They are ''obscured'' by the visible face. Similarly, the other 7 cells of the tesseract are not seen here because they are obscured by the visible cell.
|-
|[[File:Cube-edge-first.png|160px]]
|[[File:Tesseract-perspective-face-first.png|160px]]
|The image on the left shows the same cube viewed edge-on. The analogous viewpoint of a tesseract is the '''face-first perspective projection''', shown on the right. Just as the edge-first projection of the cube consists of two [[trapezoid]]s, the face-first projection of the tesseract consists of two [[frustum]]s.
The nearest edge of the cube in this viewpoint is the one lying between the red and green faces. Likewise, the nearest face of the tesseract is the one lying between the red and green cells.
|-
|[[File:Cube-vertex-first.png|160px]]
|[[File:Tesseract-perspective-edge-first.png|160px]]
|On the left is the cube viewed corner-first. This is analogous to the '''edge-first perspective projection''' of the tesseract, shown on the right. Just as the cube's vertex-first projection consists of 3 [[kite (geometry)|deltoids]] surrounding a vertex, the tesseract's edge-first projection consists of 3 [[hexahedron|hexahedral]] volumes surrounding an edge. Just as the nearest vertex of the cube is the one where the three faces meet, so the nearest edge of the tesseract is the one in the center of the projection volume, where the three cells meet.
|-
|[[File:Cube-edge-first.png|160px]]
|[[File:Tesseract-perspective-edge-first.png|160px]]
|A different analogy may be drawn between the edge-first projection of the tesseract and the edge-first projection of the cube. The cube's edge-first projection has two trapezoids surrounding an edge, while the tesseract has ''three'' hexahedral volumes surrounding an edge.
|-
|[[File:Cube-vertex-first.png|160px]]
|[[File:Tesseract-perspective-vertex-first.png|160px]]
|On the left is the cube viewed corner-first. The '''vertex-first perspective projection''' of the tesseract is shown on the right. The cube's vertex-first projection has three tetragons surrounding a vertex, but the tesseract's vertex-first projection has ''four'' hexahedral volumes surrounding a vertex. Just as the nearest corner of the cube is the one lying at the center of the image, so the nearest vertex of the tesseract lies not on boundary of the projected volume, but at its center ''inside'', where all four cells meet.
Note that only three faces of the cube's 6 faces can be seen here, because the other 3 lie ''behind'' these three faces, on the opposite side of the cube. Similarly, only 4 of the tesseract's 8 cells can be seen here; the remaining 4 lie ''behind'' these 4 in the fourth direction, on the far side of the tesseract.
|}

===Shadows===
A concept closely related to projection is the casting of shadows.

[[File:Schlegel wireframe 8-cell.png|right|200px]]
If a light is shone on a three-dimensional object, a two-dimensional shadow is cast. By dimensional analogy, light shone on a two-dimensional object in a two-dimensional world would cast a one-dimensional shadow, and light on a one-dimensional object in a one-dimensional world would cast a zero-dimensional shadow, that is, a point of non-light. Going the other way, one may infer that light shone on a four-dimensional object in a four-dimensional world would cast a three-dimensional shadow.

If the wireframe of a cube is lit from above, the resulting shadow is a square within a square with the corresponding corners connected. Similarly, if the wireframe of a tesseract were lit from “above” (in the fourth dimension), its shadow would be that of a three-dimensional cube within another three-dimensional cube. (Note that, technically, the visual representation shown here is actually a two-dimensional image of the three-dimensional shadow of the four-dimensional wireframe figure.)

===Bounding volumes===
Dimensional analogy also helps in inferring basic properties of objects in higher dimensions. For example, two-dimensional objects are bounded by one-dimensional boundaries: a square is bounded by four edges. Three-dimensional objects are bounded by two-dimensional surfaces: a cube is bounded by 6 square faces. By applying dimensional analogy, one may infer that a four-dimensional cube, known as a [[tesseract]], is bounded by three-dimensional volumes. And indeed, this is the case: mathematics shows that the tesseract is bounded by 8 cubes. Knowing this is key to understanding how to interpret a three-dimensional projection of the tesseract. The boundaries of the tesseract project to ''volumes'' in the image, not merely two-dimensional surfaces.

===Visual scope===
Being three-dimensional, we are only able to see the world with our eyes in two dimensions. A four-dimensional being would be able to see the world in three dimensions. For example, it would be able to see all six sides of an opaque box simultaneously, and in fact, what is inside the box at the same time, just as we can see the interior of a square on a piece of paper. It would be able to see all points in 3-dimensional space simultaneously, including the inner structure of solid objects and things obscured from our three-dimensional viewpoint. Our brains receive images in two dimensions and use reasoning to help us "picture" three-dimensional objects.

===Limitations===
Reasoning by analogy from familiar lower dimensions can be an excellent intuitive guide, but care must be exercised not to accept results that are not more rigorously tested. For example, consider the formulas for the circumference of a circle
&lt;math&gt;C = 2\pi r&lt;/math&gt;
and the surface area of a sphere:
&lt;math&gt;A = 4\pi r^2&lt;/math&gt;.
One might be tempted to suppose that the surface volume of a hypersphere is &lt;math&gt;V=6\pi r^3&lt;/math&gt;, or perhaps &lt;math&gt;V=8\pi r^3&lt;/math&gt;, but either of these would be wrong. The correct formula is &lt;math&gt;V = 2\pi^2 r^3&lt;/math&gt;.&lt;ref name="Coxeter"/&gt;{{rp|119}}

==See also==
{{div col|colwidth=20em}}
*[[4-manifold]]
*[[Exotic R4|Exotic '''R'''&lt;sup&gt;4&lt;/sup&gt;]]
*[[Four-dimensionalism]]
*[[Fourth dimension in art]]
*[[Fourth dimension in literature]]
*[[List of four-dimensional games]]
{{div col end}}

==References==
{{reflist|30em}}

==Further reading==
* {{cite journal|author-last=Archibald|author-first=R. C|author-link=Raymond Clare Archibald|title=Time as a Fourth Dimension|journal=[[American Mathematical Society]]|pages=409–412|year=1914|url=https://www.ams.org/journals/bull/1914-20-08/S0002-9904-1914-02511-X/S0002-9904-1914-02511-X.pdf}}
* [[Andrew Forsyth]] (1930) [https://archive.org/details/geometryoffourdi032760mbp Geometry of Four Dimensions], link from [[Internet Archive]].
* {{cite book |title=One Two Three . . . Infinity: Facts and Speculations of Science |edition=3rd |first1=George |last1=Gamow |authorlink=George Gamow|publisher=Courier Dover Publications |year=1988 |isbn=978-0-486-25664-1 |page=68 |url=https://books.google.com/books?id=EZbcwk6SkhcC}} [https://books.google.com/books?id=EZbcwk6SkhcC&amp;pg=PA68 Extract of page 68]
* [[E. H. Neville]] (1921) [http://quod.lib.umich.edu/u/umhistmath/ABR2619.0001.001?rgn=works;view=toc;rgn1=author;q1=Neville ''The Fourth Dimension''], [[Cambridge University Press]], link from [[University of Michigan]] Historical Math Collection.

==External links==
{{Wikibooks|Special Relativity}}
*[http://www.dimensions-math.org "Dimensions" videos, showing several different ways to visualize four dimensional objects]
*[http://www.sciencenews.org/index/generic/activity/view/id/35740/title/Math_Trek__Seeing_in_four_dimensions ''Science News'' article summarizing the "Dimensions" videos, with clips]
*[[s:Flatland (second edition)|''Flatland: a Romance of Many Dimensions'' (second edition)]]
*[http://www.math.union.edu/~dpvc/math/4D/welcome.html Frame-by-frame animations of 4D - 3D analogies]

{{Dimension topics}}

{{DEFAULTSORT:Fourth Dimension}}
[[Category:Dimension]]
[[Category:Four-dimensional geometry| ]]
[[Category:Multi-dimensional geometry]]
[[Category:Special relativity]]</text>
      <sha1>2lnboxxy63bvblm6tvo3oq5h5acnqoh</sha1>
    </revision>
  </page>
  <page>
    <title>Generalized flag variety</title>
    <ns>0</ns>
    <id>385339</id>
    <revision>
      <id>800722971</id>
      <parentid>748062088</parentid>
      <timestamp>2017-09-15T08:17:18Z</timestamp>
      <contributor>
        <username>Blue Pingu</username>
        <id>30062164</id>
      </contributor>
      <comment>/* Flags in a vector space */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16697">In [[mathematics]], a '''generalized flag variety''' (or simply '''flag variety''') is a [[homogeneous space]] whose points are [[flag (linear algebra)|flags]] in a finite-dimensional [[vector space]] ''V'' over a [[field (mathematics)|field]] '''F'''. When '''F''' is the real or complex numbers, a generalized flag variety is a [[smooth manifold|smooth]] or [[complex manifold]], called a '''real''' or '''complex''' '''flag manifold'''. Flag varieties are naturally [[projective variety|projective varieties]].

Flag varieties can be defined in various degrees of generality. A prototype is the variety of complete flags in a vector space ''V'' over a field '''F''', which is a flag variety for the [[special linear group]] over '''F'''. Other flag varieties arise by considering partial flags, or by restriction from the special linear group to subgroups such as the [[symplectic group]]. For partial flags, one needs to specify the sequence of dimensions of the flags under consideration. For subgroups of the linear group, additional conditions must be imposed on the flags.

The most general concept of a generalized flag variety is a [[conjugacy class]] of [[parabolic subgroup]]s of a [[semisimple algebraic group|semisimple]] [[linear algebraic group|algebraic]] or [[Lie group]] ''G'': ''G'' acts transitively on such a conjugacy class by conjugation, and the stabilizer of a parabolic ''P'' is ''P'' itself, so that the generalized flag variety is isomorphic to ''G''/''P''. It may also be realised as the orbit of a [[highest weight|highest]] [[weight space]] in a projectivized [[group representation|representation]] of ''G''. In the algebraic setting, generalized flag varieties are precisely the homogeneous spaces for ''G'' which are [[complete variety|complete]] as algebraic varieties. In the smooth setting, generalized flag manifolds are the [[compact space|compact]] flat model spaces for [[Cartan connection#Parabolic Cartan connections|Cartan geometries]] of parabolic type, and are homogeneous [[Riemannian manifold]]s under any maximal compact subgroup of ''G''.

Flag manifolds can be [[symmetric space]]s. Over the complex numbers, the corresponding flag manifolds are the [[Hermitian symmetric space]]s. Over the real numbers, an ''R''-space is a synonym for a real flag manifold and the corresponding symmetric spaces are called symmetric ''R''-spaces.

==Flags in a vector space==

{{main|flag (linear algebra)}}

A flag in a finite dimensional vector space ''V'' over a field '''F''' is an increasing sequence of [[Linear subspace|subspace]]s, where "increasing" means each is a proper subspace of the next (see [[filtration (abstract algebra)|filtration]]):
:&lt;math&gt;\{0\} = V_0 \sub V_1 \sub V_2 \sub \cdots \sub V_k = V.&lt;/math&gt;
If we write the dim ''V''&lt;sub&gt;''i''&lt;/sub&gt; = ''d''&lt;sub&gt;''i''&lt;/sub&gt; then we have
:&lt;math&gt;0 = d_0 &lt; d_1 &lt; d_2 &lt; \cdots &lt; d_k = n,&lt;/math&gt;
where ''n'' is the [[dimension (linear algebra)|dimension]] of ''V''. Hence, we must have ''k'' ≤ ''n''. A flag is called a ''complete flag'' if ''d''&lt;sub&gt;''i''&lt;/sub&gt; = ''i'' for all ''i'', otherwise it is called a ''partial flag''. The ''signature'' of the flag is the sequence (''d''&lt;sub&gt;1&lt;/sub&gt;, …, ''d''&lt;sub&gt;''k''&lt;/sub&gt;).

A partial flag can be obtained from a complete flag by deleting some of the subspaces. Conversely, any partial flag can be completed (in many different ways) by inserting suitable subspaces.

==Prototype: the complete flag variety==

According to basic results of [[linear algebra]], any two complete flags in an ''n''-dimensional vector space ''V'' over a field '''F''' are no different from each other from a geometric point of view. That is to say, the [[general linear group]] [[group action|acts]] transitively on the set of all complete flags.

Fix an ordered [[basis (linear algebra)|basis]] for ''V'', identifying it with '''F'''&lt;sup&gt;''n''&lt;/sup&gt;, whose general linear group is the group GL(''n'','''F''') of ''n'' &amp;times; ''n'' invertible matrices. The standard flag associated with this basis is the one where the ''i''&amp;thinsp;th subspace is spanned by the first ''i'' vectors of the basis. Relative to this basis, the [[stabilizer (group theory)|stabilizer]] of the standard flag is the [[group (mathematics)|group]] of nonsingular [[upper triangular matrix|upper triangular matrices]], which we denote by ''B''&lt;sub&gt;''n''&lt;/sub&gt;. The complete flag variety can therefore be written as a [[homogeneous space]] GL(''n'','''F''') / ''B''&lt;sub&gt;''n''&lt;/sub&gt;, which shows in particular that it has dimension ''n''(''n''&amp;minus;1)/2 over '''F'''.

Note that the multiples of the identity act trivially on all flags, and so one can restrict attention to the [[special linear group]] SL(''n'','''F''') of matrices with determinant one, which is a semisimple algebraic group; the set of upper triangular matrices of determinant one is a [[Borel subgroup]].

If the field '''F''' is the real or complex numbers we can introduce an [[inner product]] on ''V'' such that the chosen basis is [[orthonormal]]. Any complete flag then splits into a direct sum of one-dimensional subspaces by taking orthogonal complements. It follows that the complete flag manifold over the complex numbers is the [[homogeneous space]]
:&lt;math&gt;U(n)/T^n&lt;/math&gt;
where U(''n'') is the [[unitary group]] and T&lt;sup&gt;''n''&lt;/sup&gt; is the ''n''-torus of diagonal unitary matrices. There is a similar description over the real numbers with U(''n'') replaced by the orthogonal group O(''n''), and T&lt;sup&gt;''n''&lt;/sup&gt;  by the diagonal orthogonal matrices (which have diagonal entries ±1).

==Partial flag varieties==

The partial flag variety
:&lt;math&gt; F(d_1,d_2,\ldots d_k, \mathbb F)&lt;/math&gt;
is the space of all flags of signature (''d''&lt;sub&gt;1&lt;/sub&gt;, ''d''&lt;sub&gt;2&lt;/sub&gt;, … ''d''&lt;sub&gt;''k''&lt;/sub&gt;) in a vector space ''V'' of dimension ''n'' = ''d''&lt;sub&gt;''k''&lt;/sub&gt; over '''F'''. The complete flag variety is the special case that ''d''&lt;sub&gt;''i''&lt;/sub&gt; = ''i'' for all ''i''. When ''k''=2, this is a [[Grassmannian]] of ''d''&lt;sub&gt;1&lt;/sub&gt;-dimensional subspaces of ''V''.

This is a homogeneous space for the general linear group ''G'' of ''V'' over '''F'''. To be explicit, take ''V'' = '''F'''&lt;sup&gt;''n''&lt;/sup&gt; so that ''G'' = GL(''n'','''F'''). The stabilizer of a flag of nested subspaces ''V''&lt;sub&gt;''i''&lt;/sub&gt; of dimension ''d''&lt;sub&gt;''i''&lt;/sub&gt; can be taken to be the group of nonsingular [[block matrix|block]] upper triangular matrices, where the dimensions of the blocks are ''n''&lt;sub&gt;''i''&lt;/sub&gt; := ''d''&lt;sub&gt;''i''&lt;/sub&gt; &amp;minus; ''d''&lt;sub&gt;''i''&amp;minus;1&lt;/sub&gt; (with ''d''&lt;sub&gt;0&lt;/sub&gt; = 0).

Restricting to matrices of determinant one, this is a parabolic subgroup ''P'' of SL(''n'','''F'''), and thus the partial flag variety is isomorphic to the homogeneous space SL(''n'','''F''')/''P''.

If '''F''' is the real or complex numbers, then an inner product can be used to split any flag into a direct sum, and so the partial flag variety is also isomorphic to the homogeneous space
:&lt;math&gt; U(n)/U(n_1)\times\cdots \times U(n_k)&lt;/math&gt;
in the complex case, or
:&lt;math&gt; O(n)/O(n_1)\times\cdots\times O(n_k)&lt;/math&gt;
in the real case.

== Generalization to semisimple groups ==
The upper triangular matrices of determinant one are a Borel subgroup of SL(''n'','''F'''), and hence the stabilizers of partial flags are parabolic subgroups. Furthermore, a partial flag is determined by the parabolic subgroup which stabilizes it.

Hence, more generally, if ''G'' is a [[semisimple group|semisimple]] [[linear algebraic group|algebraic]] or [[Lie group]], then the (generalized) flag variety for ''G'' is ''G''/''P'' where ''P'' is a parabolic subgroup of ''G''. The correspondence between parabolic subgroups and generalized flag varieties allows each to be understood in terms of the other.

The extension of the terminology "flag variety" is reasonable, because points of ''G''/''P'' can still be described using flags. When ''G'' is a [[classical Lie group|classical group]], such as a [[symplectic group]] or [[orthogonal group]], this is particularly transparent. If (''V'', ''&amp;omega;'') is a [[symplectic vector space]] then a partial flag in ''V'' is ''[[isotropic]]'' if the symplectic form vanishes on proper subspaces of ''V'' in the flag. The stabilizer of an isotropic flag is a parabolic subgroup of the symplectic group Sp(''V'',''&amp;omega;''). For orthogonal groups there is a similar picture, with a couple of complications. First, if '''F''' is not algebraically closed, then isotropic subspaces may not exist: for a general theory, one needs to use the [[split orthogonal group]]s. Second, for vector spaces of even dimension 2''m'', isotropic subspaces of dimension ''m'' come in two flavours ("self-dual" and "anti-self-dual") and one needs to distinguish these to obtain a homogeneous space.

==Cohomology==

If ''G'' is a compact, connected Lie group, it contains a [[maximal torus]] ''T'' and the space ''G''/''T'' of left cosets with the quotient topology is a compact real manifold. If ''H'' is any other closed, connected subgroup of ''G'' containing ''T'', then ''G''/''H'' is another compact real manifold. (Both are actually complex homogeneous spaces in a canonical way through [[Complexification (Lie group)#Complex structures on homogeneous spaces | complexification]].) 

The presence of a complex structure and [[Cellular homology|cellular (co)homology]] make it easy to see that the [[cohomology ring]] of ''G''/''H'' is concentrated in even degrees, but in fact, something much stronger can be said. Because ''G'' → ''G/H'' is a [[principal bundle | principal ''H''-bundle]], there exists a classifying map ''G''/''H'' → ''BH'' with target the [[classifying space]] ''BH''. If we replace ''G''/''H'' with the [[Equivariant cohomology#Homotopy quotient|homotopy quotient]] ''G''&lt;sub&gt;''H''&lt;/sub&gt; in the sequence ''G'' → ''G/H'' → ''BH'', we obtain a principal ''G''-bundle called the [[Equivariant cohomology#Homotopy quotient|Borel fibration]] of the right multiplication action of ''H'' on ''G'', and we can use the cohomological [[Serre spectral sequence]] of this bundle to understand the fiber-restriction [[homomorphism]] ''H''*(''G''/''H'') → ''H''*(''G'')
and the characteristic map ''H''*(''BH'') → ''H''*(''G''/''H''), so called because its image, the ''characteristic subring'' of ''H''*(''G''/''H''), carries the [[characteristic class]]es of the original bundle ''H'' → ''G'' → ''G''/''H''.

Let us now restrict our coefficient ring to be a field ''k'' of characteristic zero, so that,
by [[Hopf algebra#Cohomology of Lie groups|Hopf's theorem]], ''H''*(''G'') is an [[exterior algebra]] on generators of odd degree (the subspace of [[Primitive element (co-algebra)|primitive elements]]). It follows that the edge homomorphisms 

:&lt;math&gt;E_{r+1}^{0,r} \to E_{r+1}^{r+1,0}&lt;/math&gt;

of the spectral sequence must eventually take the space of primitive elements in the left column ''H''*(''G'') of the page ''E''&lt;sub&gt;2&lt;/sub&gt; bijectively into the bottom row ''H''*(''BH''): we know ''G'' and ''H'' have the same [[Cartan subgroup | rank]],
so if the collection of edge homomorphisms were ''not'' full rank on the primitive subspace, then the image of the bottom row ''H''*(''BH'') in the final page ''H''*(''G''/''H'') of the sequence would be infinite-dimensional as a ''k''-vector space, which is impossible, for instance by [[cellular homology|cellular cohomology]] again, because a compact homogeneous space admits a finite [[CW complex|CW structure]].

Thus the ring map ''H''*(''G''/''H'') → ''H''*(''G'') is trivial in this case, and the characteristic map is surjective, so that ''H''*(''G''/''H'') is a quotient of ''H''*(''BH''). The kernel of the map is the ideal generated by the images of primitive elements under the edge homomorphisms, which is also the ideal generated by positive-degree elements in the image of the canonical map ''H''*(''BG'') → ''H''*(''BH'') induced by the inclusion of ''H'' in ''G''. 

The map ''H''*(''BG'') → ''H''*(''BT'') is injective, and likewise for ''H'', with image the subring ''H''*(''BT'')&lt;sup&gt;''W''(''G'')&lt;/sup&gt; of elements invariant under the action of the [[Weyl group]], so one finally obtains the concise description

:&lt;math&gt;H^*(G/H) \cong H^*(BT)^{W(H)}/\big(\widetilde{H}^*(BT)^{W(G)}\big),&lt;/math&gt;

where &lt;math&gt;\widetilde H^*&lt;/math&gt; denotes positive-degree elements and the parentheses the generation of an ideal. For example, for the complete complex flag manifold ''U''(''n'')/''T''&lt;sup&gt;''n''&lt;/sup&gt;, one has 

:&lt;math&gt;H^*\big(U(n)/T^n\big) \cong \mathbb{Q}[t_1,\ldots,t_n]/(\sigma_1,\ldots,\sigma_n),&lt;/math&gt;

where the ''t''&lt;sub&gt;''j''&lt;/sub&gt; are of degree 2 and the σ&lt;sub&gt;''j''&lt;/sub&gt; are the first ''n'' [[elementary symmetric polynomials]] in the variables ''t''&lt;sub&gt;''j''&lt;/sub&gt;. For a more concrete example, take ''n'' = 2, so that ''U''(''2'')/[''U''(1) × ''U''(1)] is the complex [[Grassmannian]] Gr(1,ℂ&lt;sup&gt;2&lt;/sup&gt;) ≈ ℂ''P''&lt;sup&gt;1&lt;/sup&gt; ≈ ''S''&lt;sup&gt;2&lt;/sup&gt;. Then we expect the cohomology ring to be an exterior algebra on a generator of degree two (the [[fundamental class]]), and indeed,

:&lt;math&gt;H^*\big(U(2)/T^2\big) \cong \mathbb{Q}[t_1,t_2]/(t_1 + t_2, t_1 t_2)
 \cong \mathbb{Q}[t_1]/(t_1^2),&lt;/math&gt;

as hoped.

==Highest weight orbits and homogeneous projective varieties==

If ''G'' is a semisimple algebraic group (or Lie group) and ''V'' is a (finite dimensional) highest weight representation of ''G'', then the highest weight space is a point in the [[projective space]] P(''V'') and its orbit under the action of ''G'' is a [[projective algebraic variety]]. This variety is a (generalized) flag variety, and furthermore, every (generalized) flag variety for ''G'' arises in this way.

[[Armand Borel]] showed that this characterizes the flag varieties of a general semisimple algebraic group ''G'': they are precisely the [[complete variety|complete]] homogeneous spaces of ''G'', or equivalently (in this context), the projective ''G''-varieties.

==Symmetric spaces==
{{main|Symmetric space}}
Let ''G'' be a semisimple Lie group with maximal compact subgroup ''K''. Then ''K'' acts transitively on any conjugacy class of parabolic subgroups, and hence the generalized flag variety ''G''/''P'' is a compact homogeneous [[Riemannian manifold]] ''K''/(''K''&amp;cap;''P'') with isometry group ''K''. Furthermore, if ''G'' is a complex Lie group, ''G''/''P'' is a homogeneous [[Kähler manifold]].

Turning this around, the Riemannian homogeneous spaces

:''M'' = ''K''/(''K''&amp;cap;''P'')

admit a strictly larger Lie group of transformations, namely ''G''. Specializing to the case that ''M'' is a [[symmetric space]], this observation yields all symmetric spaces admitting such a larger symmetry group, and these spaces have been classified by Kobayashi and Nagano.

If ''G'' is a complex Lie group, the symmetric spaces ''M'' arising in this way are the compact [[Hermitian symmetric space]]s: ''K'' is the isometry group, and ''G'' is the biholomorphism group of ''M''.

Over the real numbers, a real flag manifold is also called an R-space, and the R-spaces which are Riemannian symmetric spaces under ''K'' are known as symmetric R-spaces. The symmetric R-spaces which are not Hermitian symmetric are obtained by taking ''G'' to be a [[real form]] of the biholomorphism group ''G''&lt;sup&gt;c&lt;/sup&gt; of a Hermitian symmetric space ''G''&lt;sup&gt;c&lt;/sup&gt;/''P''&lt;sup&gt;c&lt;/sup&gt; such that ''P'' := ''P''&lt;sup&gt;c&lt;/sup&gt;&amp;cap;''G'' is a parabolic subgroup of ''G''.  Examples include [[projective space]]s (with ''G'' the group of [[projective transformation]]s) and [[sphere]]s (with ''G'' the group of [[conformal transformation]]s).

==See also==

* [[Parabolic Lie algebra]]

==References==

* Robert J. Baston and Michael G. Eastwood, ''The Penrose Transform: its Interaction with Representation Theory'', Oxford University Press, 1989.
* Jürgen Berndt, ''[http://www.mth.kcl.ac.uk/~berndt/sophia.pdf Lie group actions on manifolds]'', Lecture notes, Tokyo, 2002.
* Jürgen Berndt, Sergio Console and Carlos Olmos, ''[https://books.google.com/books?id=u3w4f63rmU8C Submanifolds and Holonomy]'', Chapman &amp; Hall/CRC Press, 2003.
* Michel Brion, ''[http://www-fourier.ujf-grenoble.fr/~mbrion/notes.html Lectures on the geometry of flag varieties]'', Lecture notes, Varsovie, 2003.
* James E. Humphreys, ''[https://books.google.com/books?id=hNgRLxlwL8oC Linear Algebraic Groups]'', Graduate Texts in Mathematics, 21, Springer-Verlag, 1972.
* S. Kobayashi and T. Nagano, ''On filtered Lie algebras and geometric structures'' I, II, J. Math. Mech. '''13''' (1964), 875–907, '''14''' (1965) 513–521.

{{Authority control}}
[[Category:Differential geometry]]
[[Category:Algebraic homogeneous spaces]]</text>
      <sha1>8xnye85yhwdodwgy7o74j37lnakcuk0</sha1>
    </revision>
  </page>
  <page>
    <title>Godunov's theorem</title>
    <ns>0</ns>
    <id>5678057</id>
    <revision>
      <id>790709277</id>
      <parentid>629042350</parentid>
      <timestamp>2017-07-15T15:39:57Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* The theorem */LaTeX spacing clean up, replaced: \ &lt;/math&gt; → &lt;/math&gt; (23) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8068">In [[numerical analysis]] and [[computational fluid dynamics]], '''Godunov's theorem''' — also known as '''Godunov's order barrier theorem''' — is a mathematical [[theorem]] important in the development of the theory of [[high resolution scheme]]s for the numerical solution of [[partial differential equations]].

The theorem states that: 

:''Linear numerical schemes for solving [[partial differential equations]] (PDE's), having the property of not generating new extrema ([[monotone scheme]]), can be at most first-order accurate.''

Professor [[Sergei K. Godunov]] originally proved the theorem as a Ph.D. student at [[Moscow State University]]. It is his most influential work in the area of applied and numerical mathematics and  has had a major impact on science and engineering, particularly in the development of methods used in [[computational fluid dynamics]] (CFD) and other computational fields. One of his major contributions was to prove the theorem (Godunov, 1954; Godunov, 1959), that bears his name.

==The theorem==
We generally follow Wesseling (2001).

'''Aside'''

Assume a continuum problem described by a [[partial differential equations|PDE]] is to be computed using a numerical scheme based upon a uniform computational grid and a one-step, constant step-size, ''M'' grid point, integration algorithm, either implicit or explicit. Then if &lt;math&gt; x_{j}  = j\,\Delta x &lt;/math&gt;  and &lt;math&gt;t^{n}  = n\,\Delta t &lt;/math&gt;, such a scheme can be described by

:&lt;math&gt;
\sum\limits_{m=1}^{M} {\beta _m } \varphi _{j + m}^{n + 1}  = \sum\limits_{m=1}^{M} {\alpha _m \varphi _{j + m}^n }. 
\quad  \quad ( 1) &lt;/math&gt;

In other words, the solution &lt;math&gt;\varphi _j^{n + 1} &lt;/math&gt; at time &lt;math&gt;n + 1&lt;/math&gt; and location &lt;math&gt;j&lt;/math&gt; is a linear function of the solution at the previous time step &lt;math&gt;n&lt;/math&gt;. We assume that &lt;math&gt;\beta _m &lt;/math&gt; determines &lt;math&gt;\varphi _j^{n + 1} &lt;/math&gt; uniquely. Now, since the above equation represents a linear relationship between &lt;math&gt; \varphi _j^{n } &lt;/math&gt; and &lt;math&gt; \varphi _j^{n + 1} &lt;/math&gt; we can perform a linear transformation to obtain the following equivalent form,

:&lt;math&gt;\varphi _j^{n + 1}  = \sum\limits_m^{M} {\gamma _m \varphi _{j + m}^n }. \quad  \quad ( 2)
&lt;/math&gt;

'''Theorem 1:''' ''Monotonicity preserving''

The above scheme of equation (2) is monotonicity preserving if and only if

:&lt;math&gt;\gamma _m  \ge 0,\quad \forall m . \quad  \quad ( 3)&lt;/math&gt;

''Proof'' - Godunov (1959)

'''Case 1: (sufficient condition)''' 

Assume (3) applies and that &lt;math&gt;\varphi _j^n &lt;/math&gt; is monotonically increasing with &lt;math&gt;j &lt;/math&gt;.

Then, because &lt;math&gt;\varphi _j^n  \le \varphi _{j + 1}^n  \le \cdots  \le \varphi _{j + m}^n &lt;/math&gt; it therefore follows that &lt;math&gt;\varphi _j^{n + 1}  \le \varphi _{j + 1}^{n + 1} \le \cdots  \le \varphi _{j + m}^{n + 1} &lt;/math&gt; because

:&lt;math&gt;
\varphi _j^{n + 1}  - \varphi _{j - 1}^{n + 1}  = \sum\limits_m^{M} {\gamma _m \left( {\varphi _{j + m}^n  - \varphi _{j + m - 1}^n } \right)}  \ge 0 . \quad  \quad ( 4)&lt;/math&gt;

This means that monotonicity is preserved for this case.

'''Case 2: (necessary condition)''' 

We prove the necessary condition by contradiction. Assume that &lt;math&gt;\gamma _p^{}  &lt; 0 &lt;/math&gt; for some &lt;math&gt;p &lt;/math&gt; and choose the following monotonically increasing &lt;math&gt;\varphi_j^n \quad &lt;/math&gt;,

:&lt;math&gt;\varphi _i^n  = 0, \quad i &lt; k;\quad \varphi _i^n  = 1, \quad i \ge k . \quad  \quad ( 5) &lt;/math&gt;

Then from equation (2) we get

:&lt;math&gt; \varphi _j^{n + 1}  - \varphi _{j-1}^{n+1}  = \sum\limits_m^M {\gamma _m } \left( {\varphi _{j + m}^{n}  - \varphi _{j + m - 1}^{n} } \right) = \left\{ {\begin{array}{*{20}c}
   {0,} &amp; {\left[ {j + m \ne k} \right]}  \\
   {\gamma _m ,} &amp; {\left[ {j + m = k} \right]}  \\
\end{array}} \right . \quad  \quad ( 6)&lt;/math&gt;

Now choose &lt;math&gt; j=k-p &lt;/math&gt;, to give

			
:&lt;math&gt;
\varphi _{k-p}^{n + 1}  - \varphi _{k-p-1}^{n + 1}  =  {\gamma _p \left( {\varphi _{k}^n  - \varphi _{k - 1}^n } \right)}  &lt; 0  , \quad  \quad ( 7)&lt;/math&gt;

which implies that &lt;math&gt;\varphi _j^{n + 1} &lt;/math&gt; is '''NOT''' increasing, and we have a contradiction. Thus, monotonicity is '''NOT''' preserved for &lt;math&gt;\gamma _p  &lt; 0 &lt;/math&gt;, which completes the proof.

'''Theorem 2:''' ''Godunov’s Order Barrier Theorem''

Linear one-step second-order accurate numerical schemes for the convection equation 

:&lt;math&gt; {{\partial \varphi } \over {\partial t}} + c{ { \partial \varphi } \over {\partial x}} = 0 , \quad t &gt; 0, \quad x \in \mathbb{R} \quad  \quad (10)&lt;/math&gt;

cannot be monotonicity preserving unless
		
:&lt;math&gt;\sigma  = \left| c \right|{{\Delta t} \over {\Delta x}} \in \mathbb{ N} , \quad  \quad (11)&lt;/math&gt;

where &lt;math&gt; \sigma &lt;/math&gt; is the signed [[Courant–Friedrichs–Lewy condition]] (CFL) number.

''Proof'' - Godunov (1959)

Assume a numerical scheme of the form described by equation (2) and choose

:&lt;math&gt;\varphi \left( {0,x} \right) = \left( {{x \over {\Delta x}} - {1 \over 2}} \right)^2  - {1 \over 4}, \quad \varphi _j^0  = \left( {j - {1 \over 2}} \right)^2  - {1 \over 4} . \quad  \quad (12)&lt;/math&gt;

The exact solution is
			
:&lt;math&gt;
\varphi \left( {t,x} \right) = \left( {{{x - ct} \over {\Delta x}} - {1 \over 2}} \right)^2  - {1 \over 4} . \quad  \quad (13)
&lt;/math&gt;

If we assume the scheme to be at least second-order accurate, it should produce the following solution exactly

:&lt;math&gt;
\varphi _j^1  = \left( {j - \sigma  - {1 \over 2}} \right)^2  - {1 \over 4}, \quad \varphi _j^0  = \left( {j - {1 \over 2}} \right)^2  - {1 \over 4}. \quad  \quad (14)
&lt;/math&gt;

Substituting into equation (2) gives:

:&lt;math&gt;
\left( {j - \sigma  - {1 \over 2}} \right)^2  - {1 \over 4} = \sum\limits_m^{M} {\gamma _m \left\{ {\left( {j + m - {1 \over 2}} \right)^2  - {1 \over 4}} \right\}}. \quad  \quad (15)
&lt;/math&gt;

Suppose that the scheme '''IS''' monotonicity preserving, then according to the theorem 1 above, &lt;math&gt;\gamma _m  \ge 0 &lt;/math&gt;.  

Now, it is clear from equation (15) that

:&lt;math&gt; \left( {j - \sigma  - {1 \over 2}} \right)^2  - {1 \over 4} \ge 0, \quad \forall j . \quad  \quad (16)&lt;/math&gt;

Assume &lt;math&gt;\sigma  &gt; 0, \quad \sigma  \notin \mathbb{ N} &lt;/math&gt; and choose &lt;math&gt;j &lt;/math&gt; such that &lt;math&gt; j &gt; \sigma  &gt; \left( j - 1 \right) &lt;/math&gt; . This implies that &lt;math&gt;\left( {j - \sigma } \right) &gt; 0 &lt;/math&gt; and &lt;math&gt;\left( {j - \sigma  - 1} \right) &lt; 0 &lt;/math&gt; .

It therefore follows that,

:&lt;math&gt;
\left( {j - \sigma  - {1 \over 2}} \right)^2  - {1 \over 4} = \left( j - \sigma \right) \left(j - \sigma - 1 \right) &lt; 0, \quad   \quad (17) &lt;/math&gt;

which contradicts equation (16) and completes the proof.

The exceptional situation whereby &lt;math&gt;\sigma  = \left| c \right|{{\Delta t} \over {\Delta x}} \in \mathbb{N} &lt;/math&gt; is only of theoretical interest, since this cannot be realised with variable coefficients. Also, integer [[Courant–Friedrichs–Lewy condition|CFL]] numbers greater than unity would not be feasible for practical problems.

==See also==
*[[Finite volume method]]
*[[Flux limiter]]
*[[Total variation diminishing]]

==References==
*'''Godunov, Sergei K.''' (1954), ''Ph.D. Dissertation: Different Methods for Shock Waves'',  Moscow State University.
*'''Godunov, Sergei K.''' (1959), A Difference Scheme for Numerical Solution of Discontinuous Solution of Hydrodynamic Equations, ''Math. Sbornik, 47, 271-306'', translated US Joint Publ. Res. Service, JPRS 7226, 1969.
*'''Wesseling, Pieter ''' (2001), ''Principles of Computational Fluid Dynamics'', Springer-Verlag.

==Further reading==
*'''Hirsch, C.''' (1990), ''Numerical Computation of Internal and External Flows'', vol 2, Wiley.
*'''Laney, Culbert B.''' (1998), ''Computational Gas Dynamics'', Cambridge University Press.
*'''Toro, E. F.''' (1999), ''Riemann Solvers and Numerical Methods for Fluid Dynamics'', Springer-Verlag.
*'''Tannehill, John C., et al.,''' (1997), ''Computational Fluid mechanics and Heat Transfer'', 2nd Ed., Taylor and Francis.

[[Category:Numerical differential equations]]
[[Category:Theorems in analysis]]
[[Category:Computational fluid dynamics]]</text>
      <sha1>bsrbyn8x3zcoutsut8jwtumy7qtmpa9</sha1>
    </revision>
  </page>
  <page>
    <title>Greek letters used in mathematics, science, and engineering</title>
    <ns>0</ns>
    <id>1943892</id>
    <revision>
      <id>867482637</id>
      <parentid>863825013</parentid>
      <timestamp>2018-11-06T00:37:03Z</timestamp>
      <contributor>
        <ip>104.163.176.136</ip>
      </contributor>
      <comment>/* Ωω (omega) */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33681">{{Greek Alphabet}}

[[Greek letters]] are used in [[mathematics]], [[science]], [[engineering]], and other areas where mathematical notation is used as symbols for [[Mathematical constant|constant]]s, [[special function]]s, and also conventionally for [[Variable (mathematics)|variables]] representing certain quantities. In these contexts, the capital letters and the small letters represent distinct and unrelated entities. Those Greek letters which have the same form as [[Latin letters]] are rarely used: capital A, B, E, Z, H, I, K, M, N, O, P, T, Y, X. Small ι, ο and υ are also rarely used, since they closely resemble the Latin letters i, o and u. Sometimes font variants of Greek letters are used as distinct symbols in mathematics, in particular for ε/ϵ and π/ϖ. The archaic letter [[digamma]] (Ϝ/ϝ/ϛ) is sometimes used.

The [[Bayer designation]] naming scheme for [[star]]s typically uses the first Greek letter, α, for the brightest star in each constellation, and runs through the alphabet before switching to Latin letters.

In [[mathematical finance]], [[Greeks (finance)|the Greeks]] are the variables denoted by Greek letters used to describe the risk of certain investments.

==Typography==

The Greek letter forms used in mathematics are often different from those used in [[Greek language|Greek-language]] text: they are designed to be used in isolation, not connected to other letters, and some use variant forms which are not normally used in current Greek typography.

The [[OpenType]] font format has the feature tag 'mgrk' "Mathematical Greek" to identify a [[glyph]] as representing a Greek letter to be used in mathematical (as opposed to Greek language) contexts.

The table below shows a comparison of Greek letters rendered in [[TeX]] and HTML.
The font used in the TeX rendering is an italic style. This is in line with the convention that variables should be italicized. As Greek letters are more often than not used as variables in mathematical formulas, a Greek letter appearing similar to the TeX rendering is more likely to be encountered in works involving mathematics.

{| class="wikitable"
|-
! colspan="19" | Greek letters
|-
! Name
! TeX
! HTML
!
! Name
! TeX
! HTML
!
! Name
! TeX
! HTML
!
! Name
! TeX
! HTML
!
! Name
! TeX
! HTML
|-
|[[#Αα (alpha)|Alpha]]
|&lt;math&gt;\Alpha \, \alpha &lt;/math&gt;
|Α α
|
|[[#Ϝϝ (digamma)|Digamma]]
|&lt;math&gt;\Digamma \, \digamma &lt;/math&gt;
|Ϝ ϝ
|
|[[#Κκ (kappa)|Kappa]]
|&lt;math&gt;\Kappa \, \kappa \, \varkappa &lt;/math&gt;
|Κ κ ϰ
|
|[[#Οο (omicron)|Omicron]]
|&lt;math&gt;\Omicron \, \omicron &lt;/math&gt;
|Ο ο
|
|[[#Υυ (upsilon)|Upsilon]]
|&lt;math&gt;\Upsilon \, \upsilon &lt;/math&gt;
|Υ υ
|-
|[[#Ββ (beta)|Beta]]
|&lt;math&gt;\Beta \, \beta &lt;/math&gt;
|Β β
|
|[[#Ζζ (zeta)|Zeta]]
|&lt;math&gt;\Zeta \, \zeta &lt;/math&gt;
|Ζ ζ
|
|[[#Λλ (lambda)|Lambda]]
|&lt;math&gt;\Lambda \, \lambda &lt;/math&gt;
|Λ λ
|
|[[#Ππ (pi)|Pi]]
|&lt;math&gt;\Pi \, \pi \, \varpi &lt;/math&gt;
|Π π ϖ
|
|[[#Φ&amp;#x3c6; (phi)|Phi]]
|&lt;math&gt;\Phi \, \phi \, \varphi &lt;/math&gt;
|Φ ϕ φ
|-
|[[#Γγ (gamma)|Gamma]]
|&lt;math&gt;\Gamma \, \gamma &lt;/math&gt;
|Γ γ
|
|[[#Ηη (eta)|Eta]]
|&lt;math&gt;\Eta \, \eta &lt;/math&gt;
|Η η
|
|[[#Μμ (mu)|Mu]]
|&lt;math&gt;\Mu \, \mu &lt;/math&gt;
|Μ μ
|
|[[#Ρρ (rho)|Rho]]
|&lt;math&gt;\Rho \, \rho \, \varrho &lt;/math&gt;
|Ρ ρ ϱ
|
|[[#Χχ (chi)|Chi]]
|&lt;math&gt;\Chi \, \chi &lt;/math&gt;
|Χ χ
|-
|[[#Δδ (delta)|Delta]]
|&lt;math&gt;\Delta \, \delta &lt;/math&gt;
|Δ δ
|
|[[#Θθ (theta)|Theta]]
|&lt;math&gt;\Theta \, \theta \, \vartheta &lt;/math&gt;
|Θ θ ϑ
|
|[[#Νν (nu)|Nu]]
|&lt;math&gt;\Nu \, \nu &lt;/math&gt;
|Ν ν
|
|[[#Σσ (sigma)|Sigma]]
|&lt;math&gt;\Sigma \, \sigma \, \varsigma &lt;/math&gt;
|Σ σ ς
|
|[[#Ψψ (psi)|Psi]]
|&lt;math&gt;\Psi \, \psi &lt;/math&gt;
|Ψ ψ
|-
|[[#Εε (epsilon)|Epsilon]]
|&lt;math&gt;\Epsilon \, \epsilon \, \varepsilon &lt;/math&gt;
|Ε ϵ ε
|
|[[#Ιι (iota)|Iota]]
|&lt;math&gt;\Iota \, \iota &lt;/math&gt;
|Ι ι
|
|[[#Ξξ (xi)|Xi]]
|&lt;math&gt;\Xi \, \xi &lt;/math&gt;
|Ξ ξ
|
|[[#Ττ (tau)|Tau]]
|&lt;math&gt;\Tau \, \tau &lt;/math&gt;
|Τ τ
|
|[[#Ωω (omega)|Omega]]
|&lt;math&gt;\Omega \, \omega &lt;/math&gt;
|Ω ω
|}

==Concepts represented by a Greek letter==

===Αα (alpha)===
{{see also|Alpha (disambiguation)}}
* &lt;math&gt;\alpha&lt;/math&gt; represents:
** the first [[angle]] in a [[triangle]], opposite the side ''A''
** the ratio of collector current to emitter current in a bipolar junction [[transistor]] (BJT) in electronics
** the [[statistical significance]] of a result
** the [[type I and type II errors|false positive rate]] in statistics ("Type I" error)
** the [[fine structure constant]] in physics
** the [[angle of attack]] of an aircraft
** an [[alpha particle]] (He&lt;sup&gt;2+&lt;/sup&gt;)
** [[angular acceleration]] in physics
** the [[Coefficient of thermal expansion|linear thermal expansion coefficient]]
** the [[thermal diffusivity]]
**  In [[organic chemistry]] the α-carbon is the backbone carbon next to the carbonyl carbon, most often for [[amino acids]]
** [[right ascension]] in [[astronomy]]
** the brightest star in a constellation
** [[Allotropes of iron|Iron ferrite]] and numerous phases within materials science
** the [[Alpha (investment)|return in excess of the compensation for the risk borne]] in investment
** the [[Lambda calculus#α-conversion|α-conversion]] in [[lambda calculus]]
** the [[independence number]] of a graph

===Ββ (beta)===
{{see also|Beta (disambiguation)}}
*Β represents the [[beta function]]
*&lt;math&gt;\beta&lt;/math&gt; represents:
** the [[thermodynamic beta]], equal to (''k''&lt;sub&gt;B&lt;/sub&gt;''T'')&lt;sup&gt;−1&lt;/sup&gt;, where ''k''&lt;sub&gt;B&lt;/sub&gt; is Boltzmann's constant and ''T'' is the absolute temperature.
** the second angle in a [[triangle]], opposite the side ''B''
** one root of a [[quadratic equation]], where α represents the other
** the [[standardized coefficient|standardized regression coefficient]] for predictor or independent variables in [[linear regression]] (unstandardized regression coefficients are represented with the lower-case Latin b, but are often called "betas" as well)
** the ratio of collector current to base current in a bipolar junction [[transistor]] (BJT) in electronics (current gain)
** the [[type I and type II errors|false negative rate]] in statistics ("Type II" error)
** the [[beta coefficient]], the non-diversifiable risk, of an asset in [[mathematical finance]]
** the [[sideslip]] angle of an airplane
** the first-order effects of variations in [[Coriolis force]] with [[latitude]] in planetary dynamics
** a [[beta particle]] (e&lt;sup&gt;−&lt;/sup&gt; or e&lt;sup&gt;+&lt;/sup&gt;)
** [[sound intensity]]
** velocity divided by the speed of light in [[special relativity]]
** the beta brain wave in [[brain]] or [[cognitive sciences]]
** [[ecliptic latitude]] in [[astronomy]]
** The ratio of [[Beta (plasma physics)|plasma pressure to magnetic pressure]] in [[plasma physics]]
** [[β-reduction]] in [[lambda calculus]]
** The ratio of the velocity of an object to the [[speed of light]] as used in the [[Lorentz factor]]
** In organic chemistry, β represents the second carbon from a functional group

===Γγ (gamma)===
{{see also|Gamma (disambiguation)}}
*Γ represents:
** the [[Circulation (fluid dynamics)|circulation]] in [[fluid dynamics]]
** the [[reflection coefficient]] of a transmission or telecommunication line.
** the [[confinement factor]] of an optical mode in a [[waveguide]]
** the [[gamma function]], a generalization of the [[factorial]]
** the [[incomplete gamma function|upper incomplete gamma function]]
** the [[modular group]], the group of fractional linear transformations
** the [[gamma distribution]], a continuous probability distribution defined using the [[gamma function]]
** [[Greeks (finance)#Gamma|second-order sensitivity to price]] in [[mathematical finance]]
** the [[Christoffel symbols]] of the second kind
** the [[neighbourhood (graph theory)|neighbourhood]] of a vertex in a [[Graph (discrete mathematics)|graph]]
** the stack alphabet in the formal definition of a [[pushdown automaton]]
*&lt;math&gt;\gamma&lt;/math&gt; represents:
** the [[Circulation (fluid dynamics)|circulation strength]] in [[fluid dynamics]]
** the [[Structural engineering theory#Safety factors|partial safety factors]] applied to loads and materials in [[structural engineering]]
** the [[specific weight]] of substances
** the [[incomplete gamma function|lower incomplete gamma function]]
** the third angle in a [[triangle]], opposite the side ''C''
** the [[Euler–Mascheroni constant]] in mathematics
** [[gamma ray]]s and the [[photon]]
** the [[heat capacity ratio]] in [[thermodynamics]]
** the [[Lorentz factor]] in special relativity
** the [[damping constant]] (kg/s)

===Δδ (delta)===
{{see also|Delta (disambiguation)}}
*Δ represents:
** a [[finite difference]]
** a [[difference operator]]
** a [[symmetric difference]]
** the [[Laplace operator]]
** the angle that subtends the arc of a circular curve in [[surveying]]
** the [[determinant]] of an inverse [[matrix (mathematics)|matrix]]
** the maximum [[degree (graph theory)|degree]] of any vertex in a given [[Graph (discrete mathematics)|graph]]
** the difference or change in a given variable, e.g. ∆v means a difference or change in [[velocity]]
** [[Greeks (finance)|sensitivity to price]] in [[mathematical finance]]
** distance to Earth, measured in [[astronomical unit]]s
** [[heat]] in a chemical formula
** the discriminant in the quadratic formula which determines the nature of the roots
** the [[degrees of freedom (statistics)|degrees of freedom]] in a non-pooled statistical hypothesis test of two population means
*&lt;math&gt;\delta&lt;/math&gt; represents:
** [[Approximation error|percent error]] 
** a variation in the [[calculus of variations]]
** the [[Kronecker delta]] function
** the [[Feigenbaum constant]]
** the [[compound interest|force of interest]] in [[mathematical finance]]
** the [[Dirac delta function]]
** the [[receptor (biochemistry)|receptor]] which [[enkephalins]] have the highest affinity for in [[pharmacology]]&lt;ref name="Katzung"&gt;Katzung &amp; Trevor's Pharmacology Examination &amp; Board Review (9th Edition.). Anthony J. Trevor, Bertram G. Katzung, Susan B. Masters {{ISBN|978-0-07-170155-6}}. B. Opioid Peptides + 268 pp.&lt;/ref&gt;
** the [[Skorokhod integral]] in [[Malliavin calculus]], a subfield of stochastic analysis
** the minimum [[Degree (graph theory)|degree]] of any vertex in a given [[Graph (discrete mathematics)|graph]]
** a partial charge. δ− represents a negative partial charge, and δ+ represents a positive partial charge [[chemistry]] (See also: [[Solvation]])
** the [[Chemical shift]] of an atomic nucleus in NMR spectroscopy. For protons, this is relative to tetramethylsilane = 0.
** [[Isotope analysis#Stable isotope analysis in aquatic ecosystems|stable isotope compositions]]
** [[declination]] in [[astronomy]]
** the Turner function in computational material science
** depreciation in macroeconomics
** noncentrality measure in [[statistics]]&lt;ref&gt;Applied Linear Statistical Models (5th ed.).

Michael H. Kutner, Christopher J. Nachtsheim, John Neter, &amp; William Li. New York: McGraw-Hill, 2005. {{ISBN|0-07-310874-X}}. xxviii + 1396 pp.&lt;/ref&gt;
* Not to be confused with [[∂]] which is based on the Latin letter d but often called a "script delta."

===Εε (epsilon)===
{{see also|Epsilon (disambiguation)}}
*&lt;math&gt;\epsilon&lt;/math&gt; represents:
** a small positive quantity; see [[limit (mathematics)|limit]]
** a random error in [[regression analysis]]
** the absolute value of an error&lt;ref name="GOLUB_MAT_COMP2.2.3"&gt;{{cite book|last=Golub|first=Gene|authorlink=Gene_H._Golub|author2=Charles F. Van Loan|title=Matrix Computations – Third Edition|publisher=The Johns Hopkins University Press|year=1996|location=Baltimore|pages=53|isbn=0-8018-5413-X}}&lt;/ref&gt;
** in [[set theory]], the limit [[ordinal number|ordinal]] of the sequence &lt;math&gt;\omega,\omega^{\omega},\omega^{\omega^{\omega}},\dots&lt;/math&gt;
** in [[computer science]], the [[String (computer science)|empty string]]
** the [[Levi-Civita symbol]]
** in [[electromagnetics]], [[dielectric]] [[permittivity]]
** [[emissivity]]
** [[Deformation (mechanics)|strain]] in [[continuum mechanics]]
** [[permittivity]]
** the Earth's [[axial tilt]] in [[astronomy]]
** [[elasticity (economics)|elasticity]] in [[economics]]
** [[expected value]] in [[probability theory]] and [[statistics]]
** [[electromotive force]]
** in [[chemistry]], the [[molar extinction coefficient]] of a [[chromophore]].
* [[Set (mathematics)|set]] membership symbol ∈ is based on ε

==={{lang|grc|Ϝϝ}} (digamma)===
{{see also|Digamma}}

*{{lang|grc|Ϝ}} is sometimes used to represent the [[digamma function]], though the Latin letter F (which is nearly identical) is usually substituted.
*A hypothetical particle Ϝ speculated to be implicated in the [[750 GeV diphoton excess]], now known to be simply a statistical anomaly

===Ζζ (zeta)===
{{see also|Zeta (disambiguation)}}
*&lt;math&gt;\zeta&lt;/math&gt; represents:
** the [[Riemann zeta function]] and other [[zeta function (disambiguation)|zeta function]]s in mathematics
** the coefficient of [[viscosity|viscous friction]] in [[polymer]] dynamics
** the [[damping ratio]]
** relative vertical [[vorticity]] in fluid dynamics

===Ηη (eta)===
{{see also|Eta (disambiguation)}}
*Η represents:
** the Eta function of  [[Ludwig Boltzmann]]'s [[H-theorem]] ("Eta" theorem), in [[statistical mechanics]]
** [[Entropy (information theory)|Information theoretic (Shannon) entropy]]
*&lt;math&gt;\eta&lt;/math&gt; represents:
** the intrinsic [[wave impedance]] of a medium (e.g. the [[impedance of free space]])
** the partial [[regression analysis|regression]] [[correlation ratio|coefficient]] in statistics
** [[elasticity (economics)|elasticities]] in economics
** the absolute vertical vorticity (relative vertical vorticity + [[Coriolis effect]]) in fluid dynamics
** an [[index of refraction]]
** the [[eta meson]]
** [[viscosity]]
** [[energy conversion efficiency]]
** [[Efficiency#In science and technology|efficiency (physics)]]
** the [[Minkowski metric]] tensor in relativity
** noise in communication system models
** [[Lambda calculus#η-conversion|η-conversion]] in [[lambda calculus]]
** Cost-push supply side shocks in the Phillips curve equation (economics){{citation needed|reason= occurrences of the letter eta appear nowhere in the wiki pages [[Phillips curve]] and [[cost-push inflation]] |date=January 2015}}
** A [[right angle]], i.e., π/2, as a follow-up to the tau/pi argument&lt;ref name="Butler"&gt;Pi, Tau and Eta. David Butler, Making Your Own Sense (blog). https://blogs.adelaide.edu.au/maths-learning/2011/06/08/pi-tau-and-eta/&lt;/ref&gt;

===Θθ (theta)===
{{see also|Theta (disambiguation)}}
*Θ (uppercase) represents:
** an asymptotically tight bound related to [[big O notation]].
** [[Debye temperature]] in solid state physics
** [[Greeks (finance)#Theta|sensitivity to the passage of time]] in [[mathematical finance]]
** in [[Θ (set theory)|set theory]], a certain [[ordinal number]]
** in [[econometrics]] and [[statistics]], a space of parameters from which estimates are drawn
*&lt;math&gt;\theta&lt;/math&gt; (lowercase) represents:
** a [[angle|plane angle]] in [[geometry]]
** the [[angle]] to the x [[Coordinate axis|axis]] in the xy-[[Plane (mathematics)|plane]] in [[spherical coordinates|spherical]] or [[cylindrical coordinates]] (mathematics)
** the [[angle]] to the z [[Coordinate axis|axis]] in [[spherical coordinates]] (physics)
** Bragg's angle of diffraction
** the [[potential temperature]] in thermodynamics
** the [[mean time between failure]] in [[reliability engineering]]
** soil water contents in soil science
** in [[mathematical statistics]], an unknown parameter
** [[theta function]]s
** the angle of a scattered photon during a [[Compton scattering]] interaction
* ϑ ("script theta"), the cursive form of theta, often used in handwriting, represents
** the first [[Chebyshev function]] in [[number theory]]

===Ιι (iota)===
{{see also|Iota (disambiguation)}}
* &lt;math&gt;\iota&lt;/math&gt; represents:
** an [[inclusion map]] in [[set theory]]
** the [[APL syntax|index generator function]] in [[A Programming Language|APL]] (in the form ⍳)
** the [[orbital inclination]] in [[celestial mechanics]].

===Κκ (kappa)===
{{see also|Kappa (disambiguation)}}
*Κ represents:
** the [[Kappa number]], indicating lignin content in pulp
*&lt;math&gt;\kappa&lt;/math&gt; represents:
** the [[Von Kármán constant]], describing the velocity profile of turbulent flow 
** the [[kappa curve]], a two-dimensional algebraic curve
** the [[condition number]] of a [[matrix (mathematics)|matrix]] in [[numerical analysis]]
** the [[Connectivity (graph theory)|connectivity]] of a [[Graph (discrete mathematics)|graph]] in [[graph theory]]
** [[curvature]]
** [[dielectric constant]] &lt;math&gt;(\varepsilon / \varepsilon_0)&lt;/math&gt;
** [[thermal conductivity]] (usually a lowercase Latin k)
** [[thermal diffusivity]]
** a [[spring constant]] (usually a lowercase Latin k)
** the [[heat capacity ratio]] in thermodynamics (usually γ)
** the [[receptor (biochemistry)|receptor]] which [[dynorphins]] have the highest affinity for in [[pharmacology]]&lt;ref name="Katzung" /&gt;

===Λλ (lambda)===
{{see also|Lambda (disambiguation)}}
*Λ represents:
** the [[von Mangoldt function]] in [[number theory]]
** the set of logical axioms in the [[axiomatic method]] of logical deduction in [[first-order logic]]
** the [[cosmological constant]]
** the [[lambda baryon]]
** a diagonal matrix of [[eigenvalue]]s in [[linear algebra]]
** the [[permeance]] of a material in [[electromagnetism]]
** a [[Lattice (group)|lattice]]
*&lt;math&gt;\lambda&lt;/math&gt; represents:
** one [[wavelength]] of electromagnetic radiation
** the [[decay constant]] in radioactivity
** function expressions in the [[lambda calculus]]
** a general [[eigenvalue]] in [[linear algebra]]
** the expected number of occurrences in a [[Poisson distribution]] in probability
** the [[arrival rate]] in [[queueing theory]]
** the average lifetime or rate parameter in an [[exponential distribution]] (commonly used across [[statistics]], [[physics]], and [[engineering]])
** the [[failure rate]] in [[reliability engineering]]
** the fundamental length of a fabrication process in [[VLSI]] design
** the [[mean]] or average value (probability and statistics)
** the [[latent heat of fusion]]
** the [[lagrange multiplier]] in the [[mathematical optimization]] method, known as the [[shadow price]] in economics
** the [[Lebesgue measure]] denotes the volume or measure of a Lebesgue measurable set
** [[longitude]] in [[geodesy]]
** [[linear density]]
** [[ecliptic longitude]] in [[astronomy]]
** the [[Liouville function]] in [[number theory]]
** the [[Carmichael function]] in [[number theory]]
** a [[units of measurement|unit of measure]] of [[volume]] equal to one [[microlitre]] (1 μL) or one cubic millimetre (1&amp;nbsp;mm³)
** the [[empty string]] in [[formal grammar]]
** a [[lambda calculus|formal system]] in mathematical logic
** the [[thermal conductivity]].

===Μμ (mu)===
{{see also|Mu (disambiguation)}}
*&lt;math&gt;\mu&lt;/math&gt; represents:
** the [[Möbius function]] in [[number theory]]
** the ring [[Representation (mathematics)|representation]] of a representation module
** the population [[mean]] or [[expected value]] in [[probability]] and [[statistics]]
** a [[measure (mathematics)|measure]] in [[measure theory]]
** [[micro-]], an [[SI prefix]] denoting 10&lt;sup&gt;−6&lt;/sup&gt; (one millionth)
** the [[coefficient of friction]] in [[physics]]
** the [[service rate]] in [[queueing theory]]
** the [[dynamic viscosity]] in physics
** magnetic [[permeability (electromagnetism)|permeability]] in [[electromagnetics]]
** a [[muon]]
** [[reduced mass]]
** chemical potential in [[condensed matter]] physics
** the [[electrical mobility|ion mobility]] in [[plasma physics]]
** the [[Standard gravitational parameter]] in [[celestial mechanics]]
** the [[refractive index]] of a medium with respect to another medium or [[vacuum]].

===Νν (nu)===
{{see also|Nu (disambiguation)}}
*&lt;math&gt;\nu&lt;/math&gt; represents:
** [[frequency]] in physics in [[hertz]] (Hz)
** [[Degrees of freedom (statistics)|degrees of freedom]] in statistics
** [[Poisson's ratio]] in material science
** a [[neutrino]]
** [[kinematic viscosity]] of liquids
** [[stoichiometric coefficient]] in chemistry
** dimension of nullspace in mathematics
** [[true anomaly]] in [[celestial mechanics]]
** the [[Matching (graph theory)|matching number]] of a [[Graph (discrete mathematics)|graph]]

===Ξξ (xi)===
{{see also|Xi (disambiguation)}}
* Ξ represents:
** the original [[Riemann Xi function]], i.e. Riemann's lower case ξ, as denoted by [[Edmund Landau]] and currently
** the [[grand canonical ensemble]] found in [[statistical mechanics]]
** the [[xi baryon]]
*&lt;math&gt;\xi&lt;/math&gt; represents:
** the original [[Riemann Xi function]]
** the modified definition of Riemann xi function, as denoted by Edmund Landau and currently 
** a [[random variable]]
** the extent of a chemical reaction
** [[coherence length]]
** the [[damping]] ratio
** universal set

===Οο (omicron)===
{{see also|Omicron (disambiguation)}}
* Ο represents:
** [[big O notation]] (may be represented by an uppercase Latin O)
* &lt;math&gt;\omicron&lt;/math&gt; represents:
** [[big O notation|small o notation]] (may be represented by a lowercase Latin o)

===Ππ (pi)===
{{see also|Pi (disambiguation)}}
*Π represents:
** the [[Multiplication#Products of sequences|product]] operator in mathematics
** a [[plane (mathematics)|plane]]
** the unary projection operation in [[relational algebra]]
** [[osmotic pressure]]
*&lt;math&gt;\pi&lt;/math&gt; represents:
** [[Archimedes' constant]], the ratio of a [[circle]]'s [[circumference]] to its [[diameter]]
** the [[prime-counting function]]
** [[Profit (economics)|profit]] in [[microeconomics]] and [[game theory]]
** [[inflation]] in [[macroeconomics]], expressed as a constant with respect to time
** the state distribution of a [[Markov chain]]
** in [[reinforcement learning]], a policy function defining how a [[software agent]] behaves for each possible state of its environment
** a type of [[covalent bond]] in chemistry ([[pi bond]])
** a [[pion]] (pi meson) in particle physics
** in [[statistics]], the [[population proportion]]
** [[nucleotide diversity]] in molecular genetics
** in electronics, a special type of [[small signal model]] is referred to as a [[hybrid-pi model]]
** in [[relational algebra]] for databases, represents projection
*ϖ (a graphic variant, see [[pomega]]) represents:
** [[angular frequency]] of a [[ocean surface wave|wave]], in [[fluid dynamics]] (angular frequency is usually represented by &lt;math&gt;\omega&lt;/math&gt; but this may be confused with [[vorticity]] in a fluid dynamics context)
** [[longitude of pericenter]], in [[astronomy]]&lt;ref&gt;[http://scienceworld.wolfram.com/physics/Pomega.html Pomega - from Eric Weisstein's World of Physics&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;
** [[comoving distance]], in cosmology&lt;ref&gt;[http://odin.physastro.mnsu.edu/~eskridge/astr225/week14.html Outline for Weeks 14&amp;15, Astronomy 225 Spring 2008&lt;!-- Bot generated title --&gt;] {{webarchive|url=https://web.archive.org/web/20100615221333/http://odin.physastro.mnsu.edu/~eskridge/astr225/week14.html |date=2010-06-15 }}&lt;/ref&gt;

===Ρρ (rho)===
{{see also|Rho (disambiguation)}}
*Ρ represents:
** one of the [[Leopold Gegenbauer|Gegenbauer]] functions in analytic number theory (may be replaced by the capital form of the Latin letter P).
*&lt;math&gt;\rho&lt;/math&gt; represents:
** one of the [[Leopold Gegenbauer|Gegenbauer]] functions in analytic number theory.
** the [[Dickman function|Dickman-de Bruijn function]]
** the [[radius]] in a [[polar coordinate system|polar]], [[cylindrical coordinate system|cylindrical]], or [[spherical coordinate system]]
** the [[Spearman's rank correlation coefficient|correlation coefficient]] in [[statistics]]
** the [[Greeks (finance)#Rho|sensitivity to interest rate]] in [[mathematical finance]]
** [[density]] (mass or charge per unit volume; may be replaced by the capital form of the Latin letter D)
** [[resistivity]]
** the [[APL syntax|shape and reshape operators]] in [[A Programming Language|APL]] (in the form ⍴)
** the [[utilization]] in [[queueing theory]]
** the [[rank of a matrix]]
** the [[Rename_(relational_algebra)|rename]] operator in [[Relational_algebra#Rename_.28.CF.81.29|relational algebra]]

===Σσς (sigma)===
{{see also|Sigma (disambiguation)}}
*Σ represents:
** the [[summation]] operator
** the [[covariance matrix]]
** the set of [[terminal symbol]]s in a [[formal grammar]]
*&lt;math&gt;\sigma&lt;/math&gt; represents:
** [[Stefan–Boltzmann constant]] in [[blackbody radiation]]
** the [[divisor function]] in [[number theory]]
**the [[real part]] of the [[complex number|complex]] variable ''s'' = σ + ''i'' ''t''  in [[analytic number theory]]
** the sign of a permutation in the theory of finite groups
** the population [[standard deviation]], a measure of [[Statistical dispersion|spread]] in [[probability]] and [[statistics]]
** a type of [[covalent bond]] in chemistry ([[sigma bond]])
** the selection operator in [[relational algebra]]
** [[stress (physics)|stress]] in mechanics
** [[electrical conductivity]]
** [[area density]]
** [[nuclear cross section]]
** [[surface charge]] density for microparticles

===Ττ (tau)===
{{see also|Tau (disambiguation)}}
*&lt;math&gt;\tau&lt;/math&gt; represents:
** [[torque]], the net rotational force in [[mechanics]]
** the elementary [[tau lepton]] in [[particle physics]]
** a [[mean lifetime]], of an [[exponential decay]] or [[spontaneous emission]] process
** the [[time constant]] of any device, such as an [[RC circuit]]
** [[proper time]] in [[Theory of relativity|relativity]]
** one [[Turn (geometry)|turn]]: the [[mathematical constant|constant]] ratio of a [[circle]]'s [[circumference]] to its [[radius]], with value 2π (6.283...).&lt;ref&gt;{{cite web | url=http://www.tauday.com/tau-manifesto | title=Tau Day - No, really, pi is wrong: The Tau Manifesto by Michael Hartl | date=2010 | accessdate=2015-03-20 }}&lt;/ref&gt;
** [[Kendall tau rank correlation coefficient]], a measure of [[rank correlation]] in statistics
** [[Ramanujan's tau function]] in [[number theory]]
** a measure of [[Opacity (optics)|opacity]], or how much sunlight cannot penetrate the atmosphere
** the intertwining operator in representation theory
** [[shear stress]] in [[continuum mechanics]]
** an internal system step in [[State transition system|transition systems]]
** a type variable in type theories, such as the [[simply typed lambda calculus]]
** path [[tortuosity]] in reservoir engineering
** in [[topology]], a given topology
** the [[Tau (protein)|tau]] in [[biochemistry]], a [[protein]] associated to [[microtubule]]s
** the [[golden ratio]] 1.618... (although [[phi (letter)|&amp;#x3c6;]] (phi) is more common)
** the number of divisors of highly composite numbers {{OEIS|id=A000005}}
**in proton NMR spectroscopy, τ was formerly used for physical shift

===Υυ (upsilon)===
{{see also|Upsilon (disambiguation)}}
*Υ represents:
** the [[upsilon meson]]

===Φ&amp;#x3c6; (phi)===
{{see also|Phi (disambiguation)}}
*Φ represents:
** the [[work function]] in physics; the energy required by a photon to remove an electron from the surface of a metal
** [[magnetic flux]]
** the [[cumulative distribution function]] of the [[normal distribution]] in statistics
** [[phenyl]] functional group
** the [[Multiplicative inverse|reciprocal]] of the [[golden ratio]] (represented by φ, below), also represented as 1/φ
** the value of the integration of information in a system (based on [[integrated information theory]])
** [[Geopotential]]
note: a symbol for the [[empty set]], &lt;math&gt;\varnothing&lt;/math&gt;, resembles Φ but is not Φ
*&lt;math&gt;\phi&lt;/math&gt; represents:
** the [[golden ratio]] 1.618... in mathematics, art, and architecture
** [[Euler's totient function]] in number theory
** a holomorphic map on an analytic space
** the argument of a [[complex number]] in mathematics
** the value of a [[angle|plane angle]] in physics and mathematics
** the [[angle]] to the z [[Coordinate axis|axis]] in [[spherical coordinates]] (mathematics)
** the [[angle]] to the x [[Coordinate axis|axis]] in the xy-[[Plane (mathematics)|plane]] in [[spherical coordinates|spherical]] or [[cylindrical coordinates]] (physics)
** [[latitude]] in [[geodesy]]
** a [[scalar field]]
** [[radiant flux]]
** [[electric potential]]
** the [[probability density function]] of the [[normal distribution]] in statistics
** a feature of a syntactic node giving that node characteristics such as [[Grammatical gender|gender]], [[Grammatical number|number]] and [[Grammatical person|person]] in [[syntax]]
** the diameter of a vessel (engineering)
** capacity reduction factor of materials in [[structural engineering]]

===Χχ (chi)===
{{see also|Chi (disambiguation)}}
*&lt;math&gt;\chi&lt;/math&gt; represents:
**the [[chi distribution]] in [[statistics]] (&lt;math&gt;\chi^2&lt;/math&gt; is the more frequently encountered [[chi-squared distribution]])
** the [[chromatic number]] of a graph in [[graph theory]]
** the [[Euler characteristic]] in [[algebraic topology]]
** [[electronegativity]] in the [[periodic table]]
** the [[Rabi frequency]]
** the [[spinor]] of a fundamental particle
** the Fourier transform of a [[linear response function]]
** a [[character (mathematics)|character]] in [[mathematics]]; especially a [[Dirichlet character]] in [[number theory]]
** the Sigma vectors in the [[unscented transform]] used in the [[unscented Kalman filter]]
** sometimes the [[mole fraction]]
** a characteristic or [[indicator function]] in mathematics
** the [[Magnetic susceptibility]] of a material in physics

===Ψψ (psi)===
{{see also|Psi (disambiguation)}}
*Ψ represents:
** [[water potential]]
** a quaternary combinator in [[combinatory logic]]
*&lt;math&gt;\psi&lt;/math&gt; represents:
** the [[wave function]] in the [[Schrödinger equation]] of [[quantum mechanics]]
** the [[stream function]] in fluid dynamics
** yaw angle in vehicle dynamics
** the angle between the x-axis and the tangent to the curve in the intrinsic coordinates system
** the [[reciprocal Fibonacci constant]]
** the second [[Chebyshev function]] in [[number theory]]
** the [[polygamma function]] in [[mathematics]]
** load combination factor in [[structural engineering]]
** [[Supergolden ratio|the supergolden ratio]]&lt;ref&gt;[https://www.jstor.org/stable/3620208?seq=1#page_scan_tab_contents "A supergolden rectangle"]&lt;/ref&gt;

===Ωω (omega)===
{{see also|Omega (disambiguation)}}
*Ω represents:
** the [[SI unit]] measure of [[electrical resistance]], the [[Ohm (unit)|ohm]]
** [[angular velocity]] / [[angular velocity|radian frequency]] (rev/min)
** the [[right ascension of the ascending node]] (RAAN) or [[Longitude of the ascending node]] in [[astronomy]] and [[orbital mechanics]]
** the rotation rate of an object, particularly a planet, in dynamics
** the [[omega constant]] 0.5671432904097838729999686622...
** an asymptotic lower bound related to [[big O notation]]
** in [[probability theory]] and [[statistical mechanics]], the [[Support_(mathematics)|support]]
** a [[solid angle]]
** the [[omega baryon]]
** the [[arithmetic function#Ω(n), ω(n), νp(n) – prime power decomposition|arithmetic function]] counting a number's prime factors
** the [[density parameter]] in [[Physical cosmology|cosmology]]
*&lt;math&gt;\omega&lt;/math&gt; represents:
** [[angular velocity]] / [[angular velocity|radian frequency]] (rad/sec)
** the [[argument of periapsis]] in [[astronomy]] and [[orbital mechanics]]
** a [[Complex number|complex]] [[cube root|cube]] [[root of unity]] — the other is ω² — (used to describe various ways of calculating the [[discrete Fourier transform]])
** the differentiability class (''i.e.'' &lt;math&gt;C^\omega&lt;/math&gt;) for functions that are infinitely differentiable because they are [[Analytic function|complex analytic]]
** the first [[Infinity|infinite]] [[ordinal number|ordinal]]
** the [[omega meson]]
** the set of [[natural number]]s in [[set theory]] (although &lt;math&gt;\mathbb{N}&lt;/math&gt; or '''N''' is more common in other areas of mathematics)
** an asymptotically dominant quantity related to [[big O notation]]
** in [[probability theory]], a possible outcome of an experiment
** in economics, the total wealth of an agent in general equilibrium theory
** vertical velocity in [[geopotential height|pressure-based]] coordinate systems (commonly used in atmospheric dynamics)
** the [[arithmetic function#Ω(n), ω(n), νp(n) – prime power decomposition|arithmetic function]] counting a number's distinct prime factors
** a differential form (esp. on an analytic space)
**the symbol ϖ, a graphic variant of π, is sometimes construed as omega with a bar over it; see [[#Ππ (pi)|π]]
**the last carbon atom of a chain of carbon atoms is sometimes called the ω (omega) position, reflecting that ω is the last letter of the Greek alphabet. This nomenclature can be useful in describing unsaturated fatty acids.

==See also==
* [[Blackboard bold letters used in mathematics]]
* [[English pronunciation of Greek letters]]
* [[Greeks (finance)]] (Greek letters used in mathematical finance, including several invented names similar to Greek letters)
* [[Latin letters used in mathematics]]
* [[List of letters used in mathematics and science]]
* [[List of mathematical symbols]]
* [[Mathematical Alphanumeric Symbols]] (a [[Unicode block]])
* [[Typographical conventions in mathematical formulae]]

==References==
{{reflist}}

==External links==
* [http://www.skyandtelescope.com/astronomy-resources/the-greek-alphabet/ A pronunciation guide with audio]

{{DEFAULTSORT:Greek Letters Used In Mathematics, Science, And Engineering}}
[[Category:Mathematical notation|*]]
[[Category:Greek letters]]</text>
      <sha1>3dmlbb4ssb14fsk5enja7ydeitultzf</sha1>
    </revision>
  </page>
  <page>
    <title>Hyperbolic angle</title>
    <ns>0</ns>
    <id>1139981</id>
    <revision>
      <id>856343811</id>
      <parentid>856257771</parentid>
      <timestamp>2018-08-24T15:12:36Z</timestamp>
      <contributor>
        <username>Pingku</username>
        <id>1323877</id>
      </contributor>
      <comment>+definition in lead</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13380">{{multiple image
|width=190
|image1=Cartesian hyperbolic triangle.svg
|caption1=The hyperbolic angle ''u'' is  a real number that is the argument of the [[hyperbolic function]]s sinh and cosh. It determines a [[hyperbolic sector]] (red) that has area ''u'' (defined to be negative for the case shown here because ''x'' &lt; 1 at the point on the hyperbola). The legs of the [[hyperbolic sector#Hyperbolic triangle|hyperbolic triangle]] (yellow) are proportional to sinh(''u'') and cosh(''u'').
|image2=Hyperbolic angle2.svg
|caption2='''Top:''' Positive and negative hyperbolic angles. '''Bottom:''' The difference between the two positive angles is shown as Δ''u'' = ''u''&lt;sub&gt;2&lt;/sub&gt; − ''u''&lt;sub&gt;1&lt;/sub&gt;.
}}

In [[mathematics]], a '''hyperbolic angle''' is a geometric figure that defines a section of a [[hyperbola]]. The relationship of a hyperbolic angle to a hyperbola parallels the relationship of an "ordinary" [[angle]] to a [[circle]].

Hyperbolic angle is defined in terms of the "standard" rectangular hyperbola: ''y'' = 1/''x'', for positive ''x''. It can be described as the angle subtended at the origin by a given interval on the hyperbola, while its magnitude is defined as the magnitude of the area so subtended - that is, the area bounded on two sides by rays from the origin to the endpoints of the interval and on the third side by the curve of the interval itself.

Hyperbolic angle is used as the [[dependent and independent variables|independent variable]] for the [[hyperbolic function]]s sinh, cosh, and tanh, because these functions may be premised on hyperbolic analogies to the corresponding circular trigonometric functions by regarding a hyperbolic angle as defining a [[hyperbolic sector#Hyperbolic triangle|hyperbolic triangle]].
The parameter thus becomes one of the most useful in the [[calculus]] of [[real number|real]] variables.

==Definition==
We consider the rectangular hyperbola &lt;math&gt;\textstyle\{(x,\frac 1 x): x&gt;0\}&lt;/math&gt;, and (by convention) pay particular attention to the ''branch'' &lt;math&gt;x &gt; 1&lt;/math&gt;.

We first define:
* The hyperbolic angle in ''standard position'' is the [[angle]] at &lt;math&gt;(0, 0)&lt;/math&gt; between the ray to &lt;math&gt;(1, 1)&lt;/math&gt; and the ray to &lt;math&gt;\textstyle(x, \frac 1 x)&lt;/math&gt;, where &lt;math&gt;x &gt; 1&lt;/math&gt;.
* The magnitude of this angle is the [[area]] of the corresponding [[hyperbolic sector]], which turns out to be &lt;math&gt;\operatorname{ln}x&lt;/math&gt;.

Note that, because of the role played by the [[natural logarithm]]:
* Unlike the circular angle, the hyperbolic angle is ''unbounded'' (because &lt;math&gt;\operatorname{ln}x&lt;/math&gt; is unbounded); this is related to the fact that the [[harmonic series (mathematics)|harmonic series]] is unbounded.
* The formula for the magnitude of the angle suggests that, for &lt;math&gt;0 &lt; x &lt; 1&lt;/math&gt;, the hyperbolic angle should be negative. This reflects the fact that, as defined, the angle is ''directed''.

Finally, we extend the definition of ''hyperbolic angle'' to that subtended by any interval on the hyperbola. Suppose &lt;math&gt;a, b, c, d&lt;/math&gt; are [[real number]]s such that &lt;math&gt;ab = cd = 1&lt;/math&gt; and &lt;math&gt;c &gt; a &gt; 1&lt;/math&gt;, so that &lt;math&gt;(a, b)&lt;/math&gt; and &lt;math&gt;(c, d)&lt;/math&gt; are points on the hyperbola &lt;math&gt;xy=1&lt;/math&gt; and determine an interval on it. Then the [[squeeze mapping]] &lt;math&gt;\textstyle f:(x, y)\to(bx, ay)&lt;/math&gt; maps the angle &lt;math&gt;\angle\!\left ((a, b), (0,0), (c, d)\right)&lt;/math&gt; to the ''standard position'' angle &lt;math&gt;\angle\!\left ((1, 1), (0,0), (bc, ad)\right)&lt;/math&gt;. By the result of [[Gregoire de Saint-Vincent]], the hyperbolic sectors determined by these angles have the same area, which is taken to be the magnitude of the angle. This magnitude is &lt;math&gt;\operatorname{ln}{(bc)}=\operatorname{ln}(c/a) =\operatorname{ln}c-\operatorname{ln}a&lt;/math&gt;.

==Comparison with circular angle==
[[Image:Hyperbolic functions-2.svg|thumb|200px|right|The unit hyperbola has a sector with an area half of the hyperbolic angle]]

[[File:HyperbolicAnimation.gif|thumb|right|Circular vs. hyperbolic angle]]

A [[unit circle]] &lt;math&gt; x^2 + y^2 = 1 &lt;/math&gt; has a [[circular sector]] with an area half of the circular angle in radians. Analogously, a [[unit hyperbola]] &lt;math&gt; x^2 - y^2 = 1 &lt;/math&gt; has a [[hyperbolic sector]] with an area half of the hyperbolic angle.

There is also a projective resolution between circular and hyperbolic cases: both curves are [[conic section]]s, and hence are treated as [[projective range]]s in [[projective geometry]]. Given an origin point on one of these ranges, other points correspond to angles. The idea of addition of angles, basic to science, corresponds to addition of points on one of these ranges as follows:

Circular angles can be characterised geometrically by the property that if two [[chord (geometry)|chord]]s ''P''&lt;sub&gt;0&lt;/sub&gt;''P''&lt;sub&gt;1&lt;/sub&gt; and ''P''&lt;sub&gt;0&lt;/sub&gt;''P''&lt;sub&gt;2&lt;/sub&gt; subtend angles ''L''&lt;sub&gt;1&lt;/sub&gt; and ''L''&lt;sub&gt;2&lt;/sub&gt; at the centre of a circle, their sum {{nowrap|''L''&lt;sub&gt;1&lt;/sub&gt; + ''L''&lt;sub&gt;2&lt;/sub&gt;}} is the angle subtended by a chord ''PQ'', where ''PQ'' is required to be parallel to ''P''&lt;sub&gt;1&lt;/sub&gt;''P''&lt;sub&gt;2&lt;/sub&gt;.

The same construction can also be applied to the hyperbola.  If ''P''&lt;sub&gt;0&lt;/sub&gt; is taken to be the point {{nowrap|(1, 1)}}, ''P''&lt;sub&gt;1&lt;/sub&gt; the point {{nowrap|(''x''&lt;sub&gt;1&lt;/sub&gt;, 1/''x''&lt;sub&gt;1&lt;/sub&gt;)}}, and ''P''&lt;sub&gt;2&lt;/sub&gt; the point {{nowrap|(''x''&lt;sub&gt;2&lt;/sub&gt;, 1/''x''&lt;sub&gt;2&lt;/sub&gt;)}}, then the parallel condition requires that ''Q'' be the point {{nowrap|(''x''&lt;sub&gt;1&lt;/sub&gt;''x''&lt;sub&gt;2&lt;/sub&gt;, 1/''x''&lt;sub&gt;1&lt;/sub&gt;1/''x''&lt;sub&gt;2&lt;/sub&gt;)}}.  It thus makes sense to define the hyperbolic angle from ''P''&lt;sub&gt;0&lt;/sub&gt; to an arbitrary point on the curve as a logarithmic function of the point's value of ''x''.&lt;ref&gt;Bjørn Felsager, [http://www.dynamicgeometry.com/Documents/advancedSketchGallery/minkowski/Minkowski_Overview.pdf Through the Looking Glass – A glimpse of Euclid's twin geometry, the Minkowski geometry], ICME-10 Copenhagen 2004; p.14.  See also example sheets [http://www.dynamicgeometry.com/documents/advancedSketchGallery/minkowski/Minkowski_Workshop_1.pdf] [http://www.dynamicgeometry.com/documents/advancedSketchGallery/minkowski/Minkowski_Workshop_2.pdf] exploring Minkowskian parallels of some standard Euclidean results&lt;/ref&gt;&lt;ref&gt;Viktor Prasolov and Yuri Solovyev (1997) ''Elliptic Functions and Elliptic Integrals'', page 1, Translations of Mathematical Monographs volume 170, [[American Mathematical Society]]&lt;/ref&gt;

Whereas in Euclidean geometry moving steadily in an orthogonal direction to a ray from the origin traces out a circle, in a [[pseudo-Euclidean space|pseudo-Euclidean plane]] steadily moving orthogonally to a ray from the origin traces out a hyperbola. In Euclidean space, the  multiple of a given angle traces equal distances around a circle while it traces exponential distances upon the hyperbolic line.&lt;ref&gt;[http://www.math.cornell.edu/~web4520/CG15-0.pdf Hyperbolic Geometry] pp 5–6, Fig 15.1&lt;/ref&gt;

Both circular and hyperbolic angle provide instances of an [[invariant measure]]. Arcs with an angular magnitude on a circle generate a [[measure (mathematics)|measure]] on certain [[measurable set]]s on the circle whose magnitude does not vary as the circle turns or [[rotation|rotates]]. For the hyperbola the turning is by [[squeeze mapping]], and the hyperbolic angle magnitudes stay the same when the plane is squeezed by a mapping
:(''x'', ''y'') ↦ (''rx'', ''y'' / ''r''), with ''r'' &gt; 0 .

==History==
The [[quadrature (mathematics)|quadrature]] of the [[hyperbola]] is the evaluation of the area of a [[hyperbolic sector]]. It can be shown to be equal to the corresponding area against an [[asymptote]]. The quadrature was first accomplished by [[Gregoire de Saint-Vincent]] in 1647 in his momentous ''Opus geometricum quadrature circuli et sectionum coni''. As expressed by a historian,
: [He made the] quadrature of a hyperbola to its [[asymptote]]s, and showed that as the [[area]] increased in [[arithmetic series]] the [[abscissa]]s increased in [[geometric series]].&lt;ref&gt;[[David Eugene Smith]] (1925) ''History of Mathematics'', pp. 424,5  v. 1&lt;/ref&gt;

[[A. A. de Sarasa]] interpreted the quadrature as a [[logarithm]] and thus the geometrically defined [[natural logarithm]] (or "hyperbolic logarithm") is understood as the area under {{nowrap|1=''y'' = 1/''x''}} to the right of {{nowrap|1=''x'' = 1}}.  As an example of a [[transcendental function]], the logarithm is more familiar than its motivator, the hyperbolic angle. Nevertheless, the hyperbolic angle plays a role when the [[Squeeze mapping#Bridge to transcendentals|theorem of Saint-Vincent]] is advanced with [[squeeze mapping]].

Circular [[trigonometry]] was extended to the hyperbola by [[Augustus De Morgan]] in his [[textbook]] ''Trigonometry and Double Algebra''.&lt;ref&gt;[[Augustus De Morgan]] (1849) [https://books.google.com/books?id=7UwEAAAAQAAJ Trigonometry and Double Algebra], Chapter VI: "On the connection of common and hyperbolic trigonometry"&lt;/ref&gt; In 1878 [[William Kingdon Clifford|W.K. Clifford]] used the hyperbolic angle to [[parametric equation|parametrize]] a [[unit hyperbola]], describing it as "quasi-[[harmonic oscillator|harmonic motion]]".

In 1894 [[Alexander Macfarlane]] circulated his essay "The Imaginary of Algebra", which used hyperbolic angles to generate [[versor#Hyperbolic versor|hyperbolic versors]], in his book ''Papers on Space Analysis''.&lt;ref&gt;[[Alexander Macfarlane]](1894) [https://archive.org/details/principlesalgeb01macfgoog ''Papers on Space Analysis''], B. Westerman, New York&lt;/ref&gt; The following year [[Bulletin of the American Mathematical Society]] published [[Mellen W. Haskell]]'s outline of the [[hyperbolic function]]s.&lt;ref&gt;[[Mellen W. Haskell]] (1895) [http://www.ams.org/journals/bull/1895-01-06/S0002-9904-1895-00266-9/S0002-9904-1895-00266-9.pdf On the introduction of the notion of hyperbolic functions] [[Bulletin of the American Mathematical Society]] 1(6):155–9&lt;/ref&gt;

When [[Ludwik Silberstein]] penned his popular 1914 textbook on the new [[theory of relativity]], he used the [[rapidity]] concept based on hyperbolic angle ''a'', where {{nowrap|1=[[tanh]] ''a'' = ''v''/''c''}}, the ratio of velocity ''v'' to the [[speed of light]]. He wrote:

:It seems worth mentioning that to ''unit'' rapidity corresponds a huge velocity, amounting to 3/4 of the velocity of light; more accurately we have {{nowrap|1=''v'' = (.7616)''c''}} for {{nowrap|1=''a'' = 1}}.
:[...] the rapidity {{nowrap|1=''a'' = 1}}, [...] consequently will represent the velocity .76&amp;nbsp;''c'' which is a little above the velocity of light in water.

Silberstein also uses [[Nikolai Lobachevsky|Lobachevsky]]'s concept of [[angle of parallelism]] Π(''a'') to obtain {{nowrap|1=cos Π(''a'') = ''v''/''c''}}.&lt;ref&gt;[[Ludwik Silberstein]] (1914) [[List of important publications in physics#The Theory of Relativity|Theory of Relativity]], Cambridge University Press, pp.&amp;nbsp;180–1&lt;/ref&gt;

==Imaginary circular angle==
The hyperbolic angle is often presented as if it were an [[imaginary number]]. Thus, if ''x'' is a real number and {{nowrap|1=''i''&lt;sup&gt;2&lt;/sup&gt; = −1}}, then
:&lt;math&gt; \cos(i x) = \cosh(x) \quad \text{and} \quad  \sin(i x) = i \sinh(x)&lt;/math&gt;
so that the [[hyperbolic function]]s cosh and sinh can be presented through the circular functions. But these identities do not arise from a circle or rotation, rather they can be understood in terms of [[infinite series]]. In particular, the one expressing the [[exponential function]] (&lt;math&gt; e^x = \cosh x + \sinh x\! &lt;/math&gt; ) consists of even and odd terms, the former comprise the cosh function (&lt;math&gt;\textstyle\cosh x = \sum_{n=0}^\infty\frac{x^{2n}}{(2n)!}&lt;/math&gt;), the latter the sinh function (&lt;math&gt;\textstyle\sinh x = \sum_{n=0}^\infty\frac{x^{2n+1}}{(2n+1)!}&lt;/math&gt;). The infinite series for cosine is derived from cosh by turning it into an [[alternating series]], and the series for sine comes from making sinh into an alternating series. The above identities use the number ''i'' to remove the alternating factor (−1)&lt;sup&gt;''n''&lt;/sup&gt; from terms of the series to restore the full halves of the exponential series. Nevertheless, in the theory of [[holomorphic function]]s, the hyperbolic sine and cosine functions are incorporated into the [[complex number|complex]] sine and cosine functions.

==See also==
*[[Transcendent angle]]

==Notes==
{{Reflist}}

==References==
{{wikibooks|Associative Composition Algebra|Transcendental paradigm|Hyperbolic angle}}
* [[Janet Barnett|Janet Heine Barnett]] (2004) "Enter, stage center: the early drama of the hyperbolic functions", available in (a) [[Mathematics Magazine]] 77(1):15–30 or (b) chapter 7 of ''Euler at 300'', RE Bradley, LA D'Antonio, CE Sandifer editors, [[Mathematical Association of America]] {{ISBN|0-88385-565-8}} .
* [[Arthur Kennelly]] (1912) [https://archive.org/details/applicationofhyp00kennrich Application of hyperbolic functions to electrical engineering problems]
* William Mueller, ''Exploring Precalculus'', § The Number e, [http://www.wmueller.com/precalculus/e/e5.html Hyperbolic Trigonometry].
* [[John Stillwell]] (1998) ''Numbers and Geometry'' exercise 9.5.3, p.&amp;nbsp;298, Springer-Verlag {{ISBN|0-387-98289-2}}.

{{DEFAULTSORT:Hyperbolic Angle}}
[[Category:Angle]]
[[Category:Differential calculus]]
[[Category:Integral calculus]]</text>
      <sha1>4r30ldl9pwt9cr45lz7e8821sckxqq1</sha1>
    </revision>
  </page>
  <page>
    <title>Injection locking</title>
    <ns>0</ns>
    <id>13623185</id>
    <revision>
      <id>864524309</id>
      <parentid>864320192</parentid>
      <timestamp>2018-10-17T19:41:55Z</timestamp>
      <contributor>
        <username>Josvebot</username>
        <id>14967932</id>
      </contributor>
      <minor/>
      <comment>v2.0b - [[WP:WCW]] project (Unicode control characters)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11355">'''Injection locking''' and '''injection pulling''' are the frequency effects that can occur when a [[harmonic oscillator]] is disturbed by a second oscillator operating at a nearby frequency.  When the coupling is strong enough and the frequencies near enough, the second oscillator can capture the first oscillator, causing it to have essentially identical frequency as the second.  This is injection locking.  When the second oscillator merely disturbs the first but does not capture it, the effect is called injection pulling.  Injection locking and pulling effects are observed in numerous types of physical systems, however the terms are most often associated with [[electronic oscillators]] or [[laser resonator]]s.

Injection locking has been used in beneficial and clever ways in the design of early [[television set]]s and [[oscilloscope]]s, allowing the equipment to be synchronized to external signals at a relatively low cost.  Injection locking has also been used in high performance frequency doubling circuits. However, injection locking and pulling, when unintended, can degrade the performance of [[phase locked loop]]s and [[radio frequency|RF]] [[integrated circuit]]s.

==Injection from grandfather clocks to lasers==
Injection pulling and injection locking can be observed in numerous physical systems where pairs of oscillators are coupled together.  Perhaps the first to document these effects was [[Christiaan Huygens]], the inventor of the [[pendulum clock]], who was surprised to note that two pendulum clocks which normally would keep slightly different time nonetheless became perfectly synchronized when hung from a common beam.  Modern researchers have [[odd sympathy|confirmed his suspicion]] that the pendulums were coupled by tiny back-and-forth vibrations in the wooden beam.&lt;ref&gt;http://phys.org/news/2016-03-huygens-pendulum-synchronization.html - Researchers prove Huygens was right about pendulum synchronization&lt;/ref&gt;  The two clocks became injection locked to a common frequency.

[[Image:Cross coupled LC oscillator.svg|thumb|Cross coupled LC oscillator with output on top]]
In a modern-day [[voltage-controlled oscillator]] an injection-locking signal may override its low-frequency control voltage, resulting in loss of control.  When intentionally employed, injection locking provides a means to significantly reduce power consumption and possibly reduce [[phase noise]] in comparison to other [[frequency synthesizer]] and [[PLL]] design techniques.  In similar fashion, the frequency output of large lasers can be purified by injection locking them with high accuracy reference lasers (see [[injection seeder]]).

==Injection-locked oscillator==
An '''injection-locked oscillator''' ('''ILO''') is usually based on cross-coupled [[LC circuit|LC]] [[electronic oscillator|oscillator]]. It has been employed for frequency division &lt;ref&gt;M. Tiebout, "A CMOS direct injection-locked oscillator topology as high-frequency low-power frequency divider," IEEE Journal of Solid-State Circuits, vol. 39, pp. 1170-1174, 2004.&lt;/ref&gt; or jitter reduction in [[PLL]], with the input of pure sinusoidal waveform. It was employed in continuous mode clock and data recovery (CDR) or [[clock recovery]] to perform clock restoration from the aid of either preceding pulse generation circuit to convert non-return-to-zero (NRZ) data to pseudo-return-to-zero (PRZ) format&lt;ref&gt;M. De Matos, J. B. Begueret, H. Lapuyade, D. Belot, L. Escotte, and Y. Deval, "A 0.25um SiGe receiver front-end for 5GHz applications," SBMO/IEEE MTT-S International Conference on Microwave and Optoelectronics 2005, pp. 213-217.&lt;/ref&gt; or nonideal retiming circuit residing at the transmitter side to couple the clock signal into the data.&lt;ref&gt;[54]	T. Gabara, "An 0.25 μm CMOS injection locked 5.6 Gbit/s clock and data recovery cell," in Symposium on Integrated Circuits and Systems Design 1999, pp. 84 - 87.&lt;/ref&gt; Recently, the ILO was employed for burst mode clock recovery scheme.&lt;ref&gt;J. Lee and M. Liu, "A 20Gbit/s burst-mode CDR circuit using injection-locking technique," in IEEE International Solid-State Circuits Conference (ISSCC), pp. 46–586, 2007.&lt;/ref&gt;

The operation of ILO is based on the fact that the local oscillation can be locked to the frequency and phase of external injection signal under proper conditions.

==Unwanted injection locking==
High-speed logic signals and their harmonics are potential threats to an oscillator.  The leakage of these and other high frequency signals into an oscillator through a substrate concomitant with an unintended lock is unwanted injection locking.

==Gain by injection locking==
Injection locking can also provide a means of gain at a low power cost in certain applications.

{{Anchor|Injection pulling}}

==Injection pulling==
{{Listen
|filename=InjectionLockedOscillators.ogg
|title="Injection Locking and Pulling"
|description=Injection pulling and locking heard alternatively when one oscillator of two sweeps in frequency
|format=[[Ogg]]}}

Injection (aka frequency) pulling occurs when an interfering frequency source disturbs an oscillator but is unable to injection lock it. The frequency of the oscillator is pulled towards the frequency source as can be seen in the spectrogram. The failure to lock may be due to insufficient coupling, or because the injection source frequency lies outside the locking window of the oscillator.
[[Image:InjectionLockedOscillatorsSpectrogram.png|thumb|Spectrogram of the above audio]]

==Entrainment==
'''Entrainment''' has been used to refer to the process of mode locking of coupled driven oscillators, which is the process whereby two interacting [[oscillation|oscillating]] systems, which have different periods when they function independently, assume a common period. The two oscillators may fall into [[Synchronization|synchrony]], but other phase relationships are also possible.  The system with the greater frequency slows down, and the other speeds up.

Dutch physicist [[Christiaan Huygens]], the inventor of the [[pendulum clock]], introduced the concept after he noticed, in 1666, that the pendulums of two clocks mounted on a common board had synchronized, and subsequent experiments duplicated this phenomenon.  He described this effect as "[[odd sympathy]]".  The two pendulum clocks synchronized with their pendulums swinging in opposite directions, 180° [[out of phase]], but in-phase states can also result.  Entrainment occurs because small amounts of energy are transferred between the two systems when they are out of phase in such a way as to produce [[negative feedback]]. As they assume a more stable phase relationship, the amount of energy gradually reduces to zero. In the realm of physics, Huygens' observations are related to [[resonance]] and the [[resonant]] coupling of [[harmonic oscillators]], which also gives rise to [[sympathetic resonance|sympathetic vibrations]].

A 2002 study of Huygens' observations show that an antiphase stable oscillation was somewhat fortuitous, and that there are other possible stable solutions, including a "death state" where a clock stops running, depending on the strength of the coupling between the clocks.&lt;ref&gt;M Bennett, M F Schatz, H Rockwood, andK Wiesenfeld, Proc. Roy. Soc. Lond. A 458 (2002) 563-579.&lt;/ref&gt;

Mode locking between driven oscillators can be easily demonstrated using mechanical [[metronome]]s on a common, easily movable surface.&lt;ref&gt;J. Pantaleone, "Synchronization of Metronomes," American Journal of Physics, vol 70 (2002) 992–1000.&lt;/ref&gt;&lt;ref&gt;[http://www.cbsnews.com/8301-504784_162-57520822-10391705/watch-the-synchronisation-of-32-metronomes-with-an-explanation-behind-it/ Watch the synchronization of 32 metronomes] CBS News, 2013 Sept 10&lt;/ref&gt; Such mode locking is important for many biological systems including the proper operation of [[Biological pacemaker|pacemakers]].&lt;ref&gt;G. B. Ermentrout and J. Rinzel, "Beyond a pacemaker's entrainment limit: phase walk-through," American Journal of Physiology. Regulatory, Integrative and Comparative Physiology, Vol 246 (1984) R102–R106.&lt;/ref&gt;

The use of the word entrainment in the modern Physics literature most often refers to the movement of one fluid, or collection of particulates, by another (see [[Entrainment (hydrodynamics)]]).  The use of the word to refer to mode locking of non-linear coupled oscillators appears mostly after about 1980, and remains relatively rare in comparison.

A similar coupling phenomenon was characterized in [[hearing aid]]s when the [[adaptive feedback cancellation]] is used. This [[Chaos theory|chaotic]] artifact (entrainment) is observed when correlated input signals are presented to an adaptive feedback canceller.

In recent years, aperiodic entrainment has been identified as an alternative form of entrainment that is of interest in biological rhythms.&lt;ref&gt;Mainen, Z. F., and Sejnowski, T. J. (1995) Reliability of spike timing in neocortical neurons. Science 268, 1503−1506.&lt;/ref&gt;&lt;ref&gt;Mori, T., and Kai, S. (2002) Noise-Induced Entrainment and Stochastic Resonance in Human Brain Waves. Phys. Rev. Lett. 88, 218101.&lt;/ref&gt;&lt;ref&gt;N.C. Butzin, P. Hochendoner, C.T. Ogle, P. Hill, and W.H. Mather. Marching along to an Offbeat Drum: Entrainment of Synthetic Gene Oscillators by a Noisy Stimulus. ACS Syn. Bio. (2015).&lt;/ref&gt;

==See also==
*[[Frequency divider#Injection-locked frequency divider|Injection-locked frequency divider]]
*[[Injection-locked PLL]]
*[[LC oscillator]]
*[[Electronic oscillator]]
*[[Burst mode clock and data recovery]]
*[[Entrainment (hydrodynamics)]]
*[[Brainwave synchronization]]
*[[Synchronization of chaos]]
*[[odd sympathy]]

==References==
&lt;references /&gt;
*Filter Entrainment Avoidance with a Frequency Domain Transform Algorithm [http://www.wipo.int/pctdb/en/wo.jsp?IA=WO2008051571&amp;WO=2008051571&amp;DISPLAY=DESC]
*Entrainment Avoidance with Pole Stabilization [http://www.wipo.int/pctdb/en/wo.jsp?IA=WO2008051569&amp;WO=2008051569&amp;DISPLAY=DESC]
*Entrainment Avoidance with a Transform Domain Algorithm [http://www.freshpatents.com/Entrainment-avoidance-with-a-transform-domain-algorithm-dt20080424ptan20080095388.php]
*Entrainment Avoidance with an Auto Regressive Filter [http://www.wipo.int/pctdb/en/wo.jsp?IA=WO2008051570&amp;WO=2008051570&amp;DISPLAY=STATUS]

==Further reading==
&lt;cite id=#Wol1991&gt;* Wolaver, Dan H. 1991. ''Phase-Locked Loop Circuit Design'', Prentice Hall, {{ISBN|0-13-662743-9}}, pages 95–105 &lt;/cite&gt;
*{{cite journal |last=Adler |first=Robert |title=A Study of Locking Phenomena in Oscillators |journal=Proceedings of the IRE |volume=34 |issue=6 |date=June 1946 |pages=351–357 |doi=10.1109/JRPROC.1946.229930 }}
*{{cite journal |last=Kurokawa |first=K. |title=Injection locking of microwave solid-state oscillators |journal=Proceedings of the IEEE |volume=61 |issue=10 |date=October 1973 |pages=1386–1410 |doi=10.1109/PROC.1973.9293 }}
&lt;cite id=#Lee2004&gt;* [[Thomas H. Lee (engineering professor)|Lee, Thomas H.]] 2004. ''The Design of CMOS Radio-Frequency Integrated Circuits'', Cambridge, {{ISBN|0-521-83539-9}}, pages 563–566 &lt;/cite&gt;

==External links==
* [https://www.youtube.com/watch?v=W1TMZASCR-I Demonstration of injection locking.]
* [https://www.youtube.com/watch?v=suxu1bmPm2g Injection locking of 100 metronomes]

[[Category:Electronic oscillators]]
[[Category:Time]]
[[Category:Dynamical systems]]</text>
      <sha1>s8paifphlav10rhmneicepcykbkzxus</sha1>
    </revision>
  </page>
  <page>
    <title>Integrated mathematics</title>
    <ns>0</ns>
    <id>7426218</id>
    <revision>
      <id>855386458</id>
      <parentid>855386409</parentid>
      <timestamp>2018-08-17T22:31:24Z</timestamp>
      <contributor>
        <username>Cymru.lass</username>
        <id>12407053</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/47.155.145.249|47.155.145.249]] ([[User talk:47.155.145.249|talk]]) to last version by Cymru.lass</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5887">'''''Integrated mathematics''''' is the term used in the United States to describe the style of [[mathematics education]] which integrates many topics or strands of mathematics throughout each year of secondary school. Each math course in [[secondary school]] covers topics in algebra, geometry, trigonometry and analysis. Nearly all countries throughout the world, except the United States, follow this type of curriculum.&lt;ref&gt;{{Citation | last=Seeley | first=Cathy | title=A Journey in Algebraic Thinking | year=2004 | url = https://www.nctm.org/News-and-Calendar/Messages-from-the-President/Archive/Cathy-Seeley/A-Journey-in-Algebraic-Thinking/ | access-date =May 15, 2018}}&lt;/ref&gt;&lt;ref&gt;{{Citation | last =Hodgen | last2 =Pepper | last3 =Sturman | last4 =Ruddock | title =An international comparison of upper secondary mathematics education  | year =2010 | url =https://www.nuffieldfoundation.org/sites/default/files/files/Country_profiles_outlier_NuffieldFoundation18_04_11.pdf}}&lt;/ref&gt;&lt;ref&gt;http://www.corestandards.org/assets/CCSSI_Mathematics_Appendix_A.pdf&lt;/ref&gt;

In the United States, topics are usually integrated throughout elementary school up to the eighth grade. Beginning with high school level courses, topics are usually separated so that one year a student focuses entirely on [[algebra]], the next year entirely on [[geometry]], and then another year of algebra and later an optional fifth year of [[Mathematical analysis|analysis]] (calculus). The one exception in the American high school curriculum is the fourth year of math, typically referred to as [[precalculus]], which usually integrates algebra, analysis, trigonometry, and geometry topics. Statistics may be integrated into all the courses or presented as a separate course.

[[Mathematics_education_in_New_York#Math_A_(former_course)|New York State]] began using integrated math curricula in the 1980s,&lt;ref&gt;[{{cite news | last =Brooke | first =James | title =EDUCATION; NEW MATH CURRICULUM COMES UNDER ATTACK | newspaper =New York Times | date =April 30, 1985 | url =https://www.nytimes.com/1985/04/30/science/education-new-math-curriculum-comes-under-attack.html | access-date =May 1, 2018 }}]&lt;/ref&gt; but recently returned to a traditional curriculum. A few other localities in the United States have also tried such integrated curricula,&lt;ref&gt;{{Cite book | last = Hirsch | first = Christian R. |author2=Zweng, Marilyn J. | title = The Secondary School Curriculum | publisher = National Council of Teachers of Mathematics | year = 1985 | location = Reston, VA}}&lt;/ref&gt; including Georgia, which mandated them in 2008 but subsequently made them optional.&lt;ref&gt;{{Citation | last = Zehr | first = Mary Ann | title = Georgia Adopts Integrated Math | newspaper = Education Week | pages = 20 | date = May 25, 2005}}&lt;/ref&gt; More recently, a few other states have mandated that all districts change to integrated curricula, including North Carolina, West Virginia and Utah.&lt;ref&gt;{{cite web|last=Robelen &amp; Gewertz|title=N.C. Moving to Integrated High School Math With Common Core|url=http://blogs.edweek.org/edweek/curriculum/2013/07/nc_moves_to_integrated_high_sc.html|publisher=Education Week|accessdate=18 November 2013}}&lt;/ref&gt;&lt;ref&gt;{{cite web | last=Will | first=Madeline | title=In Transition to Common Core, Some High Schools Turn to 'Integrated' Math | newspaper=Education Week | date=November 10, 2014 | url=http://www.edweek.org/ew/articles/2014/11/12/12cc-integratedmath.h34.html}}&lt;/ref&gt; Some districts in other states, including California, have either switched or are considering switching to an integrated curriculum.&lt;ref&gt;{{cite web|last=Fensterwald|first=John|title=Districts confirm they're moving ahead with Common Core|url=http://edsource.org/today/2013/districts-confirm-theyre-moving-ahead-with-common-core/40830|publisher=EdSource|accessdate=18 November 2013}}&lt;/ref&gt;

Under the [[Common Core State Standards Initiative|Common Core Standards]] adopted by most states in 2012, high school mathematics may be taught using either a traditional American approach or an integrated curriculum. The only difference would be the order in which the topics are taught. Supporters of using integrated curricula in the United States believe that students will be able to see the connections between algebra and geometry better in an integrated curriculum.

''General mathematics'' is another term for a mathematics course organized around different branches of mathematics, with topics arranged according to the main objective of the course.&lt;ref&gt;{{cite web
 |url=https://www.jstor.org/discover/10.2307/27953136?uid=2&amp;uid=4&amp;sid=21102570571221
 |title=What Is General Mathematics?
 |author=Kenneth E. Brown
 |year=1946}}&lt;/ref&gt;
When applied to primary education, the term ''general mathematics'' may encompass mathematical concepts more complex than basic arithmetic, like number notation, addition and multiplication tables, fractions and related operations, measurement units.&lt;ref&gt;{{cite web |url=http://www.math.com/tables/general/ |title=General Math Tables |deadurl=no |accessdate=1 September 2013}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.webmath.com/index2.html |title=General Math |deadurl=no |accessdate=1 September 2013}}&lt;/ref&gt;
When used in context of higher education, the term may encompass mathematical terminology and concepts, finding and applying appropriate techniques to solve routine problems, interpreting and representing practical information given in various forms, interpreting and using mathematical models, and constructing mathematical arguments to solve familiar and unfamiliar problems.&lt;ref&gt;{{cite web |url=http://www.boardofstudies.nsw.edu.au/syllabus_hsc/pdf_doc/general-maths-a-and-r-stage6-from2012.pdf |format=pdf |title=Assessment and Reporting in General Mathematics Stage 6 |deadurl=no |accessdate=1 September 2013}}&lt;/ref&gt;

==References==
&lt;references/&gt;

[[Category:Mathematics education]]</text>
      <sha1>h1jzvssrf8c5xv3oc1yzs63ujjdfh1m</sha1>
    </revision>
  </page>
  <page>
    <title>Intersection theorem</title>
    <ns>0</ns>
    <id>5626232</id>
    <revision>
      <id>825936753</id>
      <parentid>666647886</parentid>
      <timestamp>2018-02-16T07:18:45Z</timestamp>
      <contributor>
        <username>Dpirozhkov</username>
        <id>27098751</id>
      </contributor>
      <comment>"New Intersection Theorem" is also a standard name for a commutative algebra result, which was once a conjecture</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2869">{{about|projective geometry|a result on [[tensor product]]s of [[module (mathematics)|modules]]|Homological conjectures in commutative algebra}}

In [[projective geometry]], an '''intersection theorem''' or '''incidence theorem''' is a statement concerning an [[incidence structure]] – consisting of points, lines, and possibly higher-dimensional objects and their incidences – together with a pair of objects {{math|''A''}} and {{math|''B''}} (for instance, a point and a line). The "[[theorem]]" states that, whenever a set of objects satisfies the incidences (''i.e.'' can be identified with the objects of the incidence structure in such a way that incidence is preserved), then the objects {{math|''A''}} and {{math|''B''}} must also be incident. An intersection theorem is not necessarily true in all projective geometries; it is a property that some geometries satisfy but others don't.

For example, [[Desargues' theorem]] can be stated using the following incidence structure:
*Points: &lt;math&gt;\{A,B,C,a,b,c,P,Q,R,O\}&lt;/math&gt;
*Lines: &lt;math&gt;\{AB,AC,BC,ab,ac,bc,Aa,Bb,Cc,PQ\}&lt;/math&gt;
*Incidences (in addition to obvious ones such as &lt;math&gt;(A,AB)&lt;/math&gt;): &lt;math&gt;\{(O,Aa),(O,Bb),(O,Cc),(P,BC),(P,bc),(Q,AC),(Q,ac),(R,AB),(R,ab)\}&lt;/math&gt;
The implication is then &lt;math&gt;(R,PQ)&lt;/math&gt;—that point {{math|''R''}} is incident with line {{math|{{overbar|''PQ''}}}}.

== Famous examples ==
[[Desargues' theorem]] holds in a projective plane {{math|''P''}} [[if and only if]] {{math|''P''}} is the projective plane over some [[division ring]] (skewfield} {{math|''D''}} — &lt;math&gt;P=\mathbb{P}_{2}D&lt;/math&gt;. The projective plane is then called ''[[Desarguesian plane|desarguesian]]''.
A theorem of [[Shimshon Amitsur|Amitsur]] and Bergman states that, in the context of desarguesian projective planes, for every intersection theorem there is a [[rational identity]] such that the plane {{math|''P''}} satisfies the intersection theorem if and only if the division ring {{math|''D''}} satisfies the rational identity.
*[[Pappus's hexagon theorem]] holds in a desarguesian projective plane &lt;math&gt;\mathbb{P}_{2}D&lt;/math&gt; if and only if {{math|''D''}} is a [[field (mathematics)|field]]; it corresponds to the identity &lt;math&gt;\forall a,b\in D, \quad a\cdot b=b\cdot a&lt;/math&gt;.
*[[Fano plane|Fano's axiom]] (which states a certain intersection does ''not'' happen) holds in &lt;math&gt;\mathbb{P}_{2}D&lt;/math&gt; if and only if {{math|''D''}} has [[characteristic (algebra)|characteristic]] &lt;math&gt;\neq 2&lt;/math&gt;; it corresponds to the identity {{math|1=''a'' + ''a'' = 0}}.

== References ==
*L. H. Rowen; ''Polynomial Identities in Ring Theory''. Academic Press: New York, 1980.
*S. A. Amitsur; "Rational Identities and Applications to Algebra and Geometry", ''Journal of Algebra'' '''3''' no. 3 (1966), 304–359.

[[Category:Incidence geometry]]
[[Category:Theorems in projective geometry]]</text>
      <sha1>90p4zx9edklsw33ppb490p1tvbk5gha</sha1>
    </revision>
  </page>
  <page>
    <title>Invariance of domain</title>
    <ns>0</ns>
    <id>210731</id>
    <revision>
      <id>838214868</id>
      <parentid>809434463</parentid>
      <timestamp>2018-04-25T16:51:36Z</timestamp>
      <contributor>
        <username>Vmavanti</username>
        <id>25128382</id>
      </contributor>
      <minor/>
      <comment>Disambiguated: [[Open mapping theorem]] → [[Open mapping theorem (complex analysis)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4635">'''Invariance of domain''' is a theorem in [[topology]] about [[homeomorphic]] [[subset]]s of [[Euclidean space]] '''R'''&lt;sup&gt;''n''&lt;/sup&gt;. It states: 
:If ''U'' is an [[open set|open subset]] of '''R'''&lt;sup&gt;''n''&lt;/sup&gt; and ''f'' : ''U'' &amp;rarr; '''R'''&lt;sup&gt;''n''&lt;/sup&gt; is an [[injective]] [[continuous map]], then ''V'' = ''f''(''U'') is open and ''f'' is a [[homeomorphism]] between ''U'' and ''V''.

The theorem and its proof are due to [[L. E. J. Brouwer]], published in 1912.&lt;ref&gt;{{aut|[[L.E.J. Brouwer|Brouwer L.E.J.]]}} Beweis der Invarianz des ''n''-dimensionalen Gebiets, ''[[Mathematische Annalen]]'' 71 (1912), pages 305–315; see also 72 (1912), pages 55–56&lt;/ref&gt; The proof uses tools of [[algebraic topology]], notably the [[Brouwer fixed point theorem]].

== Notes ==
The conclusion of the theorem can equivalently be formulated as: "''f'' is an [[open map]]".

Normally, to check that ''f'' is a homeomorphism, one would have to verify that both ''f'' and its [[inverse function]] ''f''&lt;sup&gt;&amp;nbsp;−1&lt;/sup&gt; are continuous; the theorem says that if the domain is an ''open'' subset of '''R'''&lt;sup&gt;''n''&lt;/sup&gt; and the image is also in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, then continuity of ''f''&lt;sup&gt;&amp;nbsp;−1&lt;/sup&gt; is automatic. Furthermore, the theorem says that if two subsets ''U'' and ''V'' of '''R'''&lt;sup&gt;''n''&lt;/sup&gt; are homeomorphic, and ''U'' is open, then ''V'' must be open as well. (Note that V is
open as a subset of '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, and not just in the subspace topology. Openness of V in the subspace topology is automatic.
) Both of these statements are not at all obvious and are not generally true if one leaves Euclidean space.

[[File:A map which is not a homeomorphism onto its image.png|thumb|alt=Not a homeomorphism onto its image|A map which is not a homeomorphism onto its image: ''g'' : (−1.1, 1) → '''R'''&lt;sup&gt;2&lt;/sup&gt; with&amp;nbsp;''g''(''t'')&amp;nbsp;=&amp;nbsp;(''t''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1,&amp;nbsp;''t''&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;''t'')]]
It is of crucial importance that both [[domain of a function|domain]] and [[range (mathematics)|range]] of ''f'' are contained in Euclidean space ''of the same dimension''. Consider for instance the map ''f'' : [[interval (mathematics)|(0,1)]] → '''R'''&lt;sup&gt;2&lt;/sup&gt; with ''f''(''t'') = (''t'',0). This map is injective and continuous, the domain is an open subset of '''R''', but the image is not open in '''R'''&lt;sup&gt;2&lt;/sup&gt;. A more extreme example is ''g'' : (−1.1,1) → '''R'''&lt;sup&gt;2&lt;/sup&gt; with ''g''(''t'') = (''t''&lt;sup&gt;&amp;nbsp;2&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1, ''t''&lt;sup&gt;&amp;nbsp;3&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;''t'') because here ''g'' is injective and continuous but does not even yield a homeomorphism onto its image.

The theorem is also not generally true in infinite dimensions. Consider for instance the [[Banach space]] [[lp space|''l''&lt;sup&gt;&amp;infin;&lt;/sup&gt;]] of all bounded real [[sequence]]s. Define ''f'' : ''l''&lt;sup&gt;∞&lt;/sup&gt; → ''l''&lt;sup&gt;∞&lt;/sup&gt; as the shift ''f''(''x''&lt;sub&gt;1&lt;/sub&gt;,''x''&lt;sub&gt;2&lt;/sub&gt;,...) = (0, ''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;,...). Then ''f'' is injective and continuous, the domain is open in ''l''&lt;sup&gt;∞&lt;/sup&gt;, but the image is not.

== Consequences ==
An important consequence of the domain invariance theorem is that '''R'''&lt;sup&gt;''n''&lt;/sup&gt; cannot be homeomorphic to '''R'''&lt;sup&gt;''m''&lt;/sup&gt; if ''m'' ≠ ''n''. Indeed, no non-empty open subset of '''R'''&lt;sup&gt;''n''&lt;/sup&gt; can be homeomorphic to any open subset of '''R'''&lt;sup&gt;''m''&lt;/sup&gt; in this case.

== Generalizations ==
The domain invariance theorem may be generalized to [[manifold]]s: if ''M'' and ''N'' are topological ''n''-manifolds without boundary and ''f'' : ''M'' → ''N'' is a continuous map which is locally one-to-one (meaning that every point in ''M'' has a [[neighborhood (topology)|neighborhood]] such that ''f'' restricted to this neighborhood is injective), then ''f'' is an [[open map]] (meaning that ''f''(''U'') is open in ''N'' whenever ''U'' is an open subset of ''M'') and a [[local homeomorphism]].

There are also generalizations to certain types of continuous maps from a [[Banach space]] to itself.&lt;ref&gt;{{aut|[[Jean Leray|Leray J.]]}} Topologie des espaces abstraits de M. Banach. ''C. R. Acad. Sci. Paris'', 200 (1935)  pages 1083–1093&lt;/ref&gt;

==See also==
*[[Open mapping theorem (complex analysis)|Open mapping theorem]] for other conditions that ensure that a given continuous map is open.

==References==
&lt;references/&gt;

==External links==
* {{SpringerEOM| title=Domain invariance | id=Domain_invariance | oldid=16623 | first=J. van | last=Mill }}

[[Category:Algebraic topology]]
[[Category:Homeomorphisms]]
[[Category:Theorems in topology]]</text>
      <sha1>s7zzy19shcc55gawq9hj0gcjub6pbpf</sha1>
    </revision>
  </page>
  <page>
    <title>Journal of Symbolic Computation</title>
    <ns>0</ns>
    <id>6528528</id>
    <revision>
      <id>841461908</id>
      <parentid>724813303</parentid>
      <timestamp>2018-05-16T00:42:16Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <comment>| abbreviation=J. Symb. Comput. | mathscinet=J. Symbolic Comput.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2273">{{Infobox Journal
| cover = [[File:Journalcover Jsc.gif|File:Journalcover_Jsc.gif]]
| editor = [[Hoon Hong]]
| abbreviation=J. Symb. Comput.
| mathscinet=J. Symbolic Comput.
| discipline = [[Computer science]]
| publisher = [[Elsevier]]
| country =
| frequency = Monthly
| history = 1985-present
| impact = 0.853
| impact-year = 2009
| website = http://www.elsevier.com/locate/jsc
| link1 = http://www.sciencedirect.com/science/journal/07477171
| link1-name = Online access
| OCLC = 10791050
| LCCN = 85644369
| CODEN = 
| ISSN = 0747-7171
| eISSN = 
}}
The '''''Journal of Symbolic Computation''''' is a [[Peer review|peer-reviewed]] monthly [[scientific journal]] covering all aspects of [[symbolic computation]]  published by [[Academic Press]] and then by [[Elsevier]]. It is targeted to both [[mathematician]]s and [[computer scientist]]s. It was established in 1985 by [[Bruno Buchberger]], who served as its [[Editor-in-chief|editor]] until 1994.

The journal covers a wide variety of topics, including:
* [[Computer algebra system|Computer algebra]], for which it is considered the top journal&lt;ref&gt;{{cite book |title=Computer Algebra and Symbolic Computation: Mathematical Methods |last=Cohen |first=Joel S. |authorlink= |coauthors= |year=2003 |publisher=AK Peters, Ltd. |location= |isbn=978-1-56881-159-8 |page=14 |url= }}&lt;/ref&gt;
* [[Computational geometry]]
* [[Automated theorem proving]]
* Applications of symbolic computation in education, science, and industry

According to the ''[[Journal Citation Reports]]'', its 2009 [[impact factor]] is 0.853.&lt;ref name=WoS&gt;{{cite web |url=http://isiwebofknowledge.com |title=Web of Science |year=2011 |accessdate=2011-05-26}}&lt;/ref&gt; The journal is abstracted and indexed by [[Scopus]] and the [[Science Citation Index]].

== See also ==
* ''[[Higher-Order and Symbolic Computation]]''
* [[International Symposium on Symbolic and Algebraic Computation]]

== References ==
{{reflist}}

== External links ==
* {{Official website|http://www.elsevier.com/locate/jsc}}

[[Category:Mathematics journals]]
[[Category:Computer science journals]]
[[Category:Publications established in 1985]]
[[Category:Elsevier academic journals]]
[[Category:Monthly journals]]
[[Category:English-language journals]]
[[Category:Computer algebra]]</text>
      <sha1>glp9sdtotor2zbmjkgnldj7t1mu1pfl</sha1>
    </revision>
  </page>
  <page>
    <title>Line code</title>
    <ns>0</ns>
    <id>41317</id>
    <revision>
      <id>869994946</id>
      <parentid>856942509</parentid>
      <timestamp>2018-11-21T18:42:03Z</timestamp>
      <contributor>
        <username>Kvng</username>
        <id>910180</id>
      </contributor>
      <comment>review: more columns</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15465">{{stack|
[[File:NRZcode.png|thumb|An example of coding a binary signal using rectangular [[pulse amplitude modulation]] with polar [[non-return-to-zero]] code]]
[[File:Ami encoding.svg|thumb|An example of [[Bipolar encoding]], or AMI.]]
[[File:Manchester code.svg|thumb|Encoding of 11011000100 in [[Manchester encoding]] ]]
[[File:Differential_manchester_encoding_Workaround.svg|thumb|An example of [[Differential Manchester encoding]]]]
[[File:Biphase Mark Code.svg|thumb|An example of [[Biphase mark code]] ]]
[[File:MLT3encoding.svg|thumb|An example of [[MLT-3 encoding]].]]
}}
In [[telecommunication]], a '''line code''' is a pattern of voltage, current, or photons used to represent digital data [[transmission (telecommunications)|transmitted]] down a [[transmission line]]. This repertoire of signals is usually called a '''constrained code''' in data storage systems. Some signals are more prone to error than others when conveyed over a [[communication channel]] as the physics of the communication or [[storage medium]] constrains the repertoire of signals that can be used reliably.&lt;ref name="optics"&gt;{{Cite journal 
|journal= IEEE Journal on Selected Areas of Communications
|volume=19
|date=2001
|title=A Survey of Codes for Optical Disk Recording
|author=K. Schouhamer Immink
|authorlink=Kees Schouhamer Immink 
|url=https://www.researchgate.net/publication/3234561_A_survey_of_codes_for_optical_disk_recording
|pages=751-764
|accessdate=2018-02-05
}}&lt;/ref&gt; 

Common line encodings are [[Unipolar encoding|unipolar]], [[Polar encoding|polar]], [[Bipolar encoding|bipolar]], and [[Manchester code]].

== Transmission and storage ==
After line coding, the signal is put through a physical communication channel, either a [[transmission medium]] or [[data storage medium]].&lt;ref name="paulsen"&gt;
Karl Paulsen. [http://www.tvtechnology.com/media-servers/0150/coding-for-magnetic-storage-mediums/186738 "Coding for Magnetic Storage Mediums"].2007.&lt;/ref&gt;&lt;ref&gt;{{citation|author1=Abdullatif Glass |author2=Nidhal Abdulaziz |author3=and Eesa Bastaki |url=http://ro.uow.edu.au/cgi/viewcontent.cgi?article=1285&amp;context=dubaipapers|title=Slope line coding for telecommunication networks|year=2007|p=1537|journal=IEEE International Conference on Signal Processing and Communication|publisher=IEEE|location=Dubai|quote=Line codes ... facilitates the transmission of data over telecommunication and computer networks and its storage in multimedia systems.}}&lt;/ref&gt; The most common physical channels are:
* the line-coded signal can directly be put on a [[transmission line]], in the form of variations of the voltage or current (often using [[differential signaling]]).
* the line-coded signal (the "[[baseband]] signal") undergoes further [[pulse shaping]] (to reduce its frequency bandwidth) and then [[modulation|modulated]] (to shift its frequency) to create an "RF signal" that can be sent through free space.
* the line-coded signal can be used to turn on and off a light source in [[free-space optical communication]], most commonly used in an infrared [[remote control]].
* the line-coded signal can be printed on paper to create a [[bar code]].
* the line-coded signal can be converted to magnetized spots on a [[hard drive]] or [[tape drive]].
* the line-coded signal can be converted to pits on an [[optical disc]].

Some of the more common binary line codes include:
{| class="wikitable"
|-
! Signal !! Comments !! 1 state !! 0 state
|-
| NRZ–L || Non return to zero level. This is the standard positive logic signal format used in digital circuits.
| forces a high level
| forces a low level
|-
| NRZ–M || Non return to zero mark
| forces a transition
| does nothing (keeps sending the previous level)
|-
| NRZ–S  || Non return to zero space
| does nothing (keeps sending the previous level)
| forces a transition
|-
| RZ  || Return to zero
| goes high for half the bit period and returns to low
| stays low for the entire period
|-
| Biphase–L  || Manchester. Two consecutive bits of the same type force a transition at the beginning of a bit period.
| forces a negative transition in the middle of the bit
| forces a positive transition in the middle of the bit
|-
| Biphase–M || Variant of Differential Manchester. There is always a transition halfway between the conditioned transitions.
| forces a transition
| keeps level constant
|-
| Biphase–S  || Differential Manchester used in Token Ring. There is always a transition halfway between the conditioned transitions.
| keeps level constant
| forces a transition
|-
| Differential Manchester (Alternative)|| Need a Clock, always a transition in the middle of the clock period
| is represented by no transition.
| is represented by a transition at the beginning of the clock period.
|-
| Bipolar || The positive and negative pulses alternate.
| forces a positive or negative pulse for half the bit period
| keeps a zero level during bit period
|}&lt;!--[[User:Kvng/RTH]]--&gt;

[[File:Binary Line Code Waveforms.png|framed|center|An arbitrary bit pattern in various binary line code formats]]

Each line code has advantages and disadvantages. The particular line code used is chosen to meet one or more of the following criteria:
* Minimize transmission hardware
* Facilitate synchronization
* Ease error detection and correction
* Minimize spectral content
* Eliminate a DC component

== Disparity ==

The '''disparity''' of a bit pattern is the difference in the number of one bits vs the number of zero bits. The '''running disparity''' is the [[running total]] of the disparity of all previously transmitted words.&lt;ref&gt;
Jens Kröger.
[https://www.psi.ch/mu3e/ThesesEN/BachelorKroeger.pdf "Data Transmission at High Rates via Kapton Flexprints for the Mu3e Experiment"].
2014.
p. 16
&lt;/ref&gt;

Unfortunately, most long-distance communication channels cannot reliably transport a [[DC component]]. The DC component is also called the disparity, the bias, or the [[DC coefficient]]. The simplest possible line code, [[Unipolar encoding|unipolar]], gives too many errors on such systems, because it has an unbounded DC component.

Most line codes eliminate the DC component{{snd}} such codes are called [[DC-balanced]], zero-DC, or DC-free.
There are three ways of eliminating the DC component:

* Use a [[constant-weight code]]. In other words, each transmitted [[code word]] is corrected such that every code word that contains some positive or negative levels also contains enough of the opposite levels, such that the average level over each code word is zero. For example, [[Manchester code]] and [[Interleaved 2 of 5]].
* Use a [[paired disparity code]]. In other words, the transmitter has to make sure that every code word that averages to a negative level is paired with another code word that averages to a positive level. Therefore, it must keep track of the running DC buildup, and always pick the code word that pushes the DC level back towards zero. The receiver is designed so that either code word of the pair decodes to the same data bits. For example, [[Alternate Mark Inversion|AMI]], [[8B10B]], [[4B3T]], etc.
* Use a [[scrambler]]. For example, the scrambler specified in RFC 2615 for [[64b/66b encoding]].

== Polarity ==
Bipolar line codes have two polarities, are generally implemented as RZ, and have a radix of three since there are three distinct output levels. One of the principle advantages of this type of code is that it can completely eliminate any DC component. This is important if the signal must pass through a transformer or a long transmission line.

Unfortunately, several long-distance communication channels have polarity ambiguity.
To compensate, several people have designed polarity-insensitive transmission systems.&lt;ref&gt;
Peter E. K. Chow.
[https://www.google.com.ar/patents/US4387366 "Code converter for polarity-insensitive transmission systems"].
1983.
&lt;/ref&gt;&lt;ref&gt;
David A. Glanzer, [[Fieldbus Foundation]].
[http://www.fieldbus.org/images/stories/enduserresources/technicalreferences/documents/wiringinstallationguide.pdf "Fieldbus Application Guide ... Wiring and Installation"].
Section "4.7 Polarity".
p. 10
&lt;/ref&gt;&lt;ref&gt;
George C. Clark Jr., and J. Bibb Cain.
[https://books.google.com/books?id=wgzyBwAAQBAJ "Error-Correction Coding for Digital Communications"].
2013.
p. 255.
quote:
"When PSK data modulation is used, the potential exists for an ambiguity in the polarity of the received channel symbols.
This problem can be solved in one of two ways.
First ... a so-called ''transparent'' code. ..."
&lt;/ref&gt;&lt;ref&gt;
Prakash C. Gupta.
[https://books.google.com/books?id=Zr1nAgAAQBAJ "Data Communications and Computer Networks"].
2013.
p. 13.
quote:
"Another benefit of differential encoding is its insensitivity to polarity of the signal. ...
If the leads of a twisted pair are accidentally reversed..."
&lt;/ref&gt;
There are three ways of providing unambiguous reception of "0" bits or "1" bits over such channels:
* Pair each code word with the polarity-inverse of that code word. The receiver is designed so that either code word of the pair decodes to the same data bits, such as [[alternate mark inversion]], [[Differential Manchester encoding]], [[coded mark inversion]], [[Miller encoding]], etc.
* [[differential coding]] each symbol relative to the previous symbol, such as [[MLT-3 encoding]], [[NRZI]], etc.
* invert the whole stream when inverted [[syncword]]s are detected

==Run-length limited codes==
For reliable [[clock recovery]] at the receiver, a [[Run-length limited|maximum run length constraint]] may be imposed on the generated channel sequence, i.e., the maximum number of consecutive ones or zeros is bounded to a reasonable number. A clock period is recovered by observing transitions in the received sequence, so that a maximum run length guarantees such clock recovery, while sequences without such a constraint could seriously hamper the detection quality.

Run-length limited&lt;ref&gt;{{Cite journal 
|journal=Proceedings of the IEEE
|volume=78 
|issue=11 
|date=December 1990 |title=Runlength-Limited Sequences
|author=Kees Schouhamer Immink
|authorlink=Kees Schouhamer Immink 
|url=https://www.researchgate.net/profile/Kees_Schouhamer_Immink/publication/2984369_Runlength-Limited_Sequences/links/02e7e537af43a30b34000000/Runlength-Limited-Sequences.pdf
|pages=1745-1759
|quote=A detailed description is furnished of the limiting properties of runlength limited sequences.}}&lt;/ref&gt; or RLL coding is a line coding technique that is used to send arbitrary data over a communications channel with [[Bandwidth (signal processing)|bandwidth]] limits.  RLL codes are defined by four main parameters: ''m'', ''n'', ''d'', ''k''. The first two, ''m''/''n'', refer to the rate of the code, while the remaining two specify the minimal ''d'' and maximal ''k'' number of zeroes between consecutive ones. This is used in both [[telecommunication]] and storage systems that move a medium past a fixed [[recording head]].

Specifically, RLL bounds the length of stretches (runs) of repeated bits during which the signal does not change.  If the runs are too long, [[clock recovery]] is difficult; if they are too short, the high frequencies might be attenuated by the communications channel.  By [[Modulation|modulating]] the [[data]], RLL reduces the timing uncertainty in [[:wikt:decode|decoding]] the stored data, which would lead to the possible erroneous insertion or removal of bits when reading the data back. This mechanism ensures that the boundaries between bits can always be accurately found (preventing [[bit slip]]), while efficiently using the media to reliably store the maximal amount of data in a given space.

Early disk drives used very simple encoding schemes, such as RLL (0,1) FM code, followed by RLL (1,3) MFM code which were widely used in [[hard disk drive]]s until the mid-1980s and are still used in digital optical discs such as [[CD]], [[DVD]], [[Minidisc|MD]], [[Hi-MD]] and [[Blu-ray]] using [[Eight-to-Fourteen Modulation|EFM]] and [[EFMPLus]]&lt;ref&gt;{{Cite journal 
|journal=IEEE Trans. on Consumer Electronics
|volume=CE-41 
|date=1995
|title=EFMPlus: The Coding Format of the MultiMedia Compact Disc
|author=Kees Schouhamer Immink
|authorlink=Kees Schouhamer Immink 
|url=https://www.researchgate.net/publication/3179483_EFMPIus_The_coding_format_of_the_multimedia_compact_disc
|pages=491-497
|quote=A high-density alternative to EFM is described.}}&lt;/ref&gt; codes. Higher density RLL (2,7) and RLL (1,7) codes became the ''de&amp;nbsp;facto'' industry standard for hard disks by the early 1990s.

== Synchronization ==
{{main | clock recovery}}

Line coding should make it possible for the receiver to synchronize itself to the [[Phase (waves)|phase]] of the received signal. If the synchronization is not ideal, then the signal to be decoded will not have optimal differences (in amplitude) between the various digits or symbols used in the line code. This will increase the error probability in the received data.&lt;br /&gt;
Biphase line codes require at least one transition per bit time. This makes it easier to synchronize the transceivers and detect errors, however, the baud rate is greater than that of NRZ codes.

== Other considerations ==
It is also preferred for the line code to have a structure that will enable error detection.
Note that the line-coded signal and a signal produced at a [[terminal (telecommunication)|terminal]] may differ, thus requiring translation.

A line code will typically reflect technical requirements of the [[transmission medium]], such as [[optical fiber]] or [[shielded twisted pair]].  These requirements are unique for each medium, because each one has different behavior related to interference, distortion, capacitance and loss of amplitude.{{citation needed|date=May 2014}}

== Common line codes ==
{{Div col|colwidth=30em}}
* [[Alternate Mark Inversion|AMI]]
* [[Modified AMI code]]s: B8ZS, B6ZS, B3ZS, HDB3
* [[2B1Q]]
* [[4B5B]]
* [[4B3T]]
* [[6b/8b encoding]]
* [[Hamming Code]]
* [[8b/10b encoding]]
* [[64b/66b encoding]]
* [[128b/130b encoding]]
* [[Coded mark inversion]] (CMI)
* [[Conditioned Diphase]]
* [[Eight-to-Fourteen Modulation]] (EFM), used in [[Compact Disc]]s
* [[EFMPlus]], used in [[DVD]]s
* RZ{{snd}} [[Return-to-zero]]
* NRZ{{snd}} [[Non-return-to-zero]]
* NRZI{{snd}} [[Non-return-to-zero, inverted]]
* [[Manchester code]], with its variants [[Differential Manchester encoding|Differential Manchester]] and [[Biphase mark code]]
* [[pulse-position modulation]], a generalization of Manchester code
* [[Miller encoding]], also known as Delay encoding or [[Modified Frequency Modulation]], with Modified Miller encoding as a variant
* [[MLT-3 Encoding]]
* [[Hybrid Ternary Codes]]
* [[Surround by complement]] (SBC)
* [[TC-PAM]]
{{div col end}}

Optical line codes:
* [[Carrier-Suppressed Return-to-Zero]]
* [[Alternate-Phase Return-to-Zero]]
* [[IEEE 1355#Slice: TS-FO-02|Three of Six, Fiber Optical]] (TS-FO)

== See also ==
* [[Channel coding]]
* [[Source coding]]
* [[Modulation]]
* [[Physical layer]]
* [[Self-synchronizing code]] and bit synchronization

== References ==
{{reflist}}
* {{FS1037C MS188}}

==External links==
* [http://www.electronics.dit.ie/staff/amoloney/lecture-9.pdf Line Coding Lecture No. 9] 
* [http://www.fiberoptics4sale.com/wordpress/line-coding-in-digital-communication/ Line Coding in Digital Communication]

{{Bit-encoding}}

[[Category:Line codes|*]]
[[Category:Physical layer protocols]]
[[Category:Coding theory]]</text>
      <sha1>31p7e3il9ondc0zvc7zvh72eo8qw9q9</sha1>
    </revision>
  </page>
  <page>
    <title>List of Chinese mathematicians</title>
    <ns>0</ns>
    <id>30654226</id>
    <revision>
      <id>861729756</id>
      <parentid>861729553</parentid>
      <timestamp>2018-09-29T16:05:44Z</timestamp>
      <contributor>
        <ip>100.19.38.28</ip>
      </contributor>
      <comment>/* Modern Chinese mathematicians */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2347">This is a list of [[Chinese mathematics|Chinese mathematicians]]. With a history spanning over three millennia, Chinese mathematics is believed to have initially developed largely independently of other cultures.
{{Expand list|date=December 2016}}

==Classical Chinese mathematicians==
*[[Jing Fang]]: 78 to 37 BC, 
*[[Liu Xin (scholar)|Liu Xin]]: c. 50 BC to 23 AD
*[[Zhang Heng]]: 78 to 139 AD
*[[Liu Hong (astronomer)|Liu Hong]]: 129 to 210 AD
*[[Cai Yong]]: 132 to 192 AD
*[[Liu Hui]]: 225 to 295 AD 
*[[Wang Fan]]: 228 to 266 AD
*[[Liu Hui]]: 3rd century AD
*[[Sun Tzu (mathematician)|Sun Tzu]]: c. 3rd–5th century AD
*[[Zu Chongzhi]]: 429 to 500 AD
*[[Zu Gengzhi]]: c. 450 – c. 520 AD

==Middle Imperial Chinese mathematicians==
*[[Zhen Luan]]: 535–566
*[[Wang Xiaotong]]: 580–640
*[[Li Chunfeng]]: 602–670
*[[Yi Xing]]: 683–727
*[[Wei Pu]]: 11th century
*[[Jia Xian]]: 1010–1070
*[[Su Song]]: 1020–1101
*[[Shen Kuo]]: 1031–1095
*[[Li Zhi (mathematician)|Li Zhi]]: 1192–1279
*[[Qin Jiushao]]: c. 1202–1261
*[[Guo Shoujing]]: 1231–1316
*[[Yang Hui]]: c. 1238–1298
*[[Zhu Shijie]]: 1249–1314

==Late Imperial Chinese mathematicians==
*[[Cheng Dawei]]: 1533–1606
*[[Zhu Zaiyu]]: 1536–1611
*[[Xu Guangqi]]: 1562–1633
*[[Li Rui (mathematician)|Li Rui]]: 1768–1817
*[[Li Shanlan]]: 1810–1882
*[[Xiong Qinglai]]: 1893–1969
*[[Su Buqing]]: 1902–2003
*[[Pao-Lu Hsu]]: 1910–1970
*[[Hua Luogeng]]: 1910–1985
*[[Ke Zhao]]: 1910–2002
*[[Shiing-Shen Chern]]: 1911–2004
*[[Wei-Liang Chow]]: 1911–1995

==Modern Chinese mathematicians==
*[[Chien Wei-zang]]: 1912–2010
*[[Ky Fan]]: 1914–2010
*[[Chia-Chiao Lin]]: 1916–2013
*[[Wu Wenjun]]: 1919-2017
*[[Yuan-Shih Chow]]: 1924
*[[Gu Chaohao]]: 1926–2012
*[[Daoxing Xia]]: b. 1930
*[[Wang Yuan (mathematician)|Wang Yuan]]: b. 1930
*[[Chen Jingrun]]: 1933–1996
*[[Pan Chengdong]]: 1934–1997
*[[Yum-Tong Siu]]: b. 1943
*[[Peng Shige]]: b. 1947
*[[Shing-Tung Yau]]: b. 1949, [[Fields medal]] recipient.
*[[Yitang Zhang]]: b. 1955
*[[Gang Tian]]: b. 1958
*[[Jeffrey Yi-Lin Forrest]]: b. 1959
*[[Huai-Dong Cao]]: b. 1959
*[[Shou-Wu Zhang]]: b. 1962
*[[Weinan E]]: b. 1963
*[[Kefeng Liu]] b. 1965
*[[Wei Zhang (mathematician)|Wei Zhang]] b. 1981
*[[Zhiwei Yun]] b. 1982

[[Category:Chinese mathematicians|*]]
[[Category:Lists of mathematicians|Chinese]]</text>
      <sha1>a0przvpnlnapshyrzinqo7o7s9wjymv</sha1>
    </revision>
  </page>
  <page>
    <title>Lists of mathematics topics</title>
    <ns>0</ns>
    <id>527369</id>
    <revision>
      <id>867467861</id>
      <parentid>862473594</parentid>
      <timestamp>2018-11-05T22:18:10Z</timestamp>
      <contributor>
        <username>The Man in Question</username>
        <id>835170</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18814">{{MathTopicTOC}}

This article itemizes the various '''lists''' of '''[[mathematics]] topics'''. Some of these lists link to hundreds of articles; some link only to a few. The template to the right includes links to alphabetical lists of all mathematical articles. This article brings together the same content organized in a manner better suited for browsing.

The purpose of this list is ''not'' similar to that of the [[Mathematics Subject Classification]] formulated by the [[American Mathematical Society]]. Many mathematics journals ask authors of research papers and expository articles to list subject codes from the Mathematics Subject Classification in their papers. The subject codes so listed are used by the two major reviewing databases, ''[[Mathematical Reviews]]'' and ''[[Zentralblatt MATH]]''. This list has some items that would not fit in such a classification, such as [[list of exponential topics]] and [[list of factorial and binomial topics]], which may surprise the reader with the diversity of their coverage.

==Basic Mathematics==
This branch is typically taught in secondary education or in the first year of university.
* [[Outline of discrete mathematics]]
* [[List of calculus topics]]
* [[List of geometry topics]]
** [[Outline of geometry]]
** [[List of trigonometry topics]]
*** [[Outline of trigonometry]]
*** [[List of trigonometric identities]]
* [[List of topics in logic]]

==Areas of advanced mathematics==
See also [[Areas of mathematics]] and [[Glossary of areas of mathematics]].

As a rough guide this list is divided into pure and applied sections although in reality these branches are overlapping and intertwined.

===Pure mathematics===

====Algebra====
[[Algebra]] includes the study of algebraic structures, which are sets and operations defined on these sets satisfying certain axioms. The field of algebra is further divided according to which structure is studied; for instance, group theory concerns an algebraic structure called ''group''.
* [[Outline of algebra]]
* [[List of abstract algebra topics]]
* [[List of algebraic structures]]
* [[List of Boolean algebra topics]]
* [[List of category theory topics]]
* [[List of commutative algebra topics]]
* [[List of homological algebra topics]]
* [[List of group theory topics]]
* [[List of representation theory topics]]
* [[List of linear algebra topics]]
* [[List of reciprocity laws]]
* [[Glossary of field theory]]
* [[Glossary of group theory]]
* [[Glossary of linear algebra]]
* [[Glossary of ring theory]]
* [[List of cohomology theories]]

====Calculus and analysis====
[[File:Gibbs phenomenon 10.png|thumb|200px|right|[[Fourier series]] approximation of square wave in five steps.]]

[[Calculus]] studies the computation of limits, derivatives, and integrals of functions of real numbers, and in particular studies instantaneous rates of change. [[Mathematical analysis|Analysis]] evolved from calculus.
* [[List of complex analysis topics]]
* [[List of functional analysis topics]]
** [[List of vector spaces in mathematics]]
* [[List of integration and measure theory topics]]
* [[List of harmonic analysis topics]]
** [[List of Fourier analysis topics]]
* [[List of multivariable calculus topics]]
* [[List of q-analogs]]
* [[List of real analysis topics]]
* [[List of variational topics]]
* [[Glossary of tensor theory]]
* [[List of mathematical series]]
* See also [[#Dynamical systems and differential equations|Dynamical systems and differential equations]] section below.

====Geometry and topology====
[[File:Ford circles.svg|200px|right|thumb|[[Ford circle]]s—A circle rests upon each fraction in lowest terms. Each touches its neighbors without crossing.]]
[[Geometry]] is initially the study of spatial figures like circles and cubes, though it has been generalized considerably. [[Topology]] developed from geometry; it looks at those properties that do not change even when the figures are deformed by stretching and bending, like dimension.
* [[List of geometry topics]]
* [[List of geometric shapes]]
* [[List of curves topics]]
* [[List of triangle topics]]
* [[List of circle topics]]
** [[List of topics related to pi]]
* [[List of general topology topics]]
* [[List of differential geometry topics]]
* [[List of algebraic geometry topics]]
** [[List of algebraic surfaces]]
* [[List of algebraic topology topics]]
** [[List of cohomology theories]]
* [[List of geometric topology topics]]
* [[List of knot theory topics]]
* [[List of Lie group topics]]
* [[Glossary of differential geometry and topology]]
* [[Glossary of general topology]]
* [[List of mathematical properties of points]]
* [[Glossary of Riemannian and metric geometry]]
* [[Glossary of scheme theory]]

====Combinatorics====
[[Combinatorics]] concerns the study of [[Countable set|discrete]] (and usually [[Finite set|finite]]) objects. Aspects include "counting" the objects satisfying certain criteria (''[[enumerative combinatorics]]''), deciding when the criteria can be met, and constructing and analyzing objects meeting the criteria (as in ''[[combinatorial design]]s and [[matroid]] theory''), finding "largest", "smallest", or "optimal" objects (''[[extremal combinatorics]]'' and ''[[combinatorial optimization]]''), and finding [[algebra]]ic structures these objects may have (''[[algebraic combinatorics]]'').
* [[Outline of combinatorics]]
* [[List of graph theory topics]]
* [[Glossary of graph theory]]

====Logic====
[[File:Venn A intersect B.svg|thumb|200px|right|[[Venn diagram]]s are illustrations of set theoretical, mathematical or logical relationships.]]
[[Logic]] is the foundation which underlies [[mathematical logic]] and the rest of mathematics. It tries to formalize valid reasoning. In particular, it attempts to define what constitutes a proof.
* [[List of Boolean algebra topics]]
* [[List of first-order theories]]
* [[List of large cardinal properties]]
* [[List of mathematical logic topics]]
* [[Glossary of order theory]]
* [[List of set theory topics]]

====Number theory====
[[Number theory]] studies the natural, or whole, numbers. One of the central concepts in number theory is that of the [[prime number]], and there are many questions about primes that appear simple but whose resolution continues to elude mathematicians.
* [[List of algebraic number theory topics]]
* [[List of number theory topics]]
* [[List of recreational number theory topics]]
* [[Glossary of arithmetic and Diophantine geometry]]
* [[List of prime numbers]]&amp;mdash;not just a table, but a list of various ''kinds'' of prime numbers (each with an accompanying table)
* [[List of zeta functions]]

===Applied mathematics===

====Dynamical systems and differential equations====
[[File:Limitcycle.svg|right|200px|thumb|Phase portrait of a continuous-time dynamical system, the [[Van der Pol oscillator]].]]
A [[differential equation]] is an equation involving an unknown function and its derivatives.

In a [[dynamical system]], a fixed rule describes the time dependence of a point in a geometrical space. The mathematical models used to describe the swinging of a clock pendulum, the flow of water in a pipe, or the number of fish each spring in a lake are examples of dynamical systems.
* [[List of dynamical systems and differential equations topics]]
* [[List of partial differential equation topics]]
* [[List of nonlinear partial differential equations]]

====Mathematical physics====
[[Mathematical physics]] is concerned with "the application of mathematics to problems in physics and the development of mathematical methods suitable for such applications and for the formulation of physical theories".{{ref|1|1}}
* [[List of mathematical topics in classical mechanics]]
* [[List of mathematical topics in quantum theory]]
* [[List of mathematical topics in relativity]]
* [[List of string theory topics]]
* [[Index of wave articles]]

====Computation====
[[File:Raytraced image jawray.jpg|thumb|200px|right|[[Ray tracing (graphics)|Ray tracing]] is a process based on [[computational mathematics]].]]
The fields of mathematics and computing intersect both in [[computer science]], the study of algorithms and data structures, and in [[scientific computing]], the study of algorithmic methods for solving problems in mathematics, science and engineering.
* [[List of algorithm general topics]]
* [[List of computability and complexity topics]]
* Lists for computational topics in geometry and graphics
** [[List of combinatorial computational geometry topics]]
** [[List of computer graphics and descriptive geometry topics]]
** [[List of numerical computational geometry topics]]
* [[List of computer vision topics]]
* [[List of formal language and literal string topics]]
* [[List of numerical analysis topics]]
* [[List of terms relating to algorithms and data structures]]

====Information theory and signal processing====
[[Information theory]] is a branch of [[applied mathematics]] and [[electrical engineering]] involving the quantification of [[information]]. Historically, information theory was developed to find fundamental limits on compressing and reliably [[communication|communicating]] data.

[[Signal processing]] is the analysis, interpretation, and manipulation of [[signal (electrical engineering)|signal]]s. Signals of interest include [[audio signal processing|sound]], [[image processing|images]], biological signals such as [[ECG]], [[radar]] signals, and many others. Processing of such signals includes [[filter (signal processing)|filtering]], storage and reconstruction, separation of information from [[noise]], [[data compression|compression]], and [[feature extraction]].
* [[List of information theory topics]]
* [[List of algebraic coding theory topics]]
* [[Wikipedia:WikiProject Cryptography/List of cryptography topics|List of cryptography topics]]

====Probability and statistics====
[[File:Normal approximation to binomial.svg|200px|right|thumb|The "bell curve"—the probability density function of the [[normal distribution]].]]
{{Main|Lists of statistics topics}}
[[Probability theory]] is the formalization and study of the mathematics of uncertain events or knowledge. The related field of [[mathematical statistics]] develops [[statistical theory]] with mathematics. [[Statistics]], the science concerned with collecting and analyzing data, is an autonomous discipline (and not a subdiscipline of [[applied mathematics]]).
* [[List of probability topics]]
* [[List of stochastic processes topics]]
* [[List of probability distributions]]
* [[Catalog of articles in probability theory]]
* [[List of statistics topics]]
* [[Outline of regression analysis]]

====Game theory====
[[Game theory]] is a branch of [[mathematics]] that uses [[model (abstract)|models]] to study interactions with formalized incentive structures ("games"). It has applications in a variety of fields, including [[economics]], [[evolutionary biology]], [[political science]], [[social psychology]] and [[military strategy]].
* [[Glossary of game theory]]
* [[List of games in game theory]]

====Operations research====
[[Operations research]] is the study and use of mathematical models, statistics and algorithms to aid in decision-making, typically with the goal of improving or optimizing performance of real-world systems.
* [[List of network theory topics]]
* [[List of knapsack problems]]

==Methodology==
* [[List of graphical methods]]
* [[List of mathematics-based methods]]
* [[List of rules of inference]]

==Mathematical statements==
A mathematical statement amounts to a [[Proposition (mathematics)|proposition]] or assertion of some mathematical fact, formula, or construction. Such statements include axioms and the theorems that may be proved from them, conjectures that may be unproven or even unprovable, and also algorithms for computing the answers to questions that can be expressed mathematically.
* [[List of algorithms]]
* [[List of axioms]]
* [[List of conjectures]]
** [[List of conjectures by Paul Erdős]]
* [[Combinatorial principles]]
* [[List of equations]]
* [[List of formulae involving pi]]
* [[List of mathematical identities]]
* [[List of inequalities]]
* [[List of lemmas]]
* [[List of mathematical proofs]]

==General concepts==
* [[List of convexity topics]]
* [[List of dualities]]
* [[List of exceptional set concepts]]
* [[List of exponential topics]]
* [[List of factorial and binomial topics]]
* [[List of fractal topics]]
* [[List of logarithm topics]]
* [[List of numeral system topics]]
* [[List of order topics]]
* [[List of partition topics]]
* [[List of polynomial topics]]
* [[List of properties of sets of reals]]
* [[List of transforms]]
* [[List of permutation topics]]

==Mathematical objects==
Among mathematical objects are numbers, functions, sets, a great variety of things called "spaces" of one kind or another, algebraic structures such as rings, groups, or fields, and many other things.
* [[List of mathematical examples]]
* [[List of curves]]
* [[List of complex reflection groups]]
* [[List of complexity classes]]
* [[List of examples in general topology]]
* [[List of finite simple groups]]
* [[List of Fourier-related transforms]]
* [[List of mathematical functions]]
* [[List of mathematical knots and links]]
* [[List of manifolds]]
* [[List of mathematical shapes]]
* [[List of matrices]]
* [[List of numbers]]
* [[List of polygons, polyhedra and polytopes]]
* [[List of regular polytopes]]
* [[List of simple Lie groups]]
* [[List of small groups]]
* [[List of special functions and eponyms]]
* [[List of algebraic surfaces]]
* [[List of surfaces]]
* [[Table of Lie groups]]

==Equations named after people==
* [[Scientific equations named after people]]

==About mathematics==
* [[List of mathematical societies]]
* [[List of letters used in mathematics and science]]
* [[List of mathematics competitions]]
* [[List of mathematics history topics]]
* [[List of publications in mathematics]]

===Mathematicians===
{{main|List of mathematicians}}
[[Mathematician]]s study and research in all the different areas of mathematics. The publication of new discoveries in mathematics continues at an immense rate in hundreds of scientific journals, many of them devoted to mathematics and many devoted to subjects to which mathematics is applied (such as theoretical [[computer science]] and [[theoretical physics]]).
* [[List of geometers]]
* [[List of logicians]]
* [[List of game theorists]]
* [[List of mathematicians]]
* [[List of mathematical probabilists]]
* [[List of statisticians]]

===Work of particular mathematicians===
{{See also|:Category:Lists of things named after mathematicians}}
* [[List of things named after Niels Henrik Abel]]
* [[List of things named after Archimedes]]
* [[List of things named after Emil Artin]]
* [[List of things named after Thomas Bayes]]
* [[List of things named after Élie Cartan]]
* [[List of things named after Augustin-Louis Cauchy]]
* [[List of things named after Arthur Cayley]]
* [[List of things named after Richard Dedekind]]
* [[List of things named after Pierre Deligne]]
* [[List of things named after Peter Gustav Lejeune Dirichlet]]
* [[List of things named after Albert Einstein]]
* [[List of things named after Euclid]]
* [[List of things named after Leonhard Euler]]
* [[List of things named after Paul Erdős]]
* [[List of things named after Fibonacci]]
* [[List of things named after Ferdinand Georg Frobenius]]
* [[List of things named after Carl Friedrich Gauss]]
* [[List of things named after Évariste Galois]]
* [[List of things named after Jacques Hadamard]]
* [[List of things named after Erich Hecke]]
* [[List of things named after Eduard Heine]]
* [[List of things named after Charles Hermite]]
* [[List of things named after W. V. D. Hodge]]
* [[List of things named after Carl Gustav Jacob Jacobi]]
* [[List of things named after Felix Klein]]
* [[List of things named after Joseph-Louis Lagrange]]
* [[List of things named after Pierre-Simon Laplace]]
* [[List of things named after Adrien-Marie Legendre]]
* [[List of things named after Gottfried Leibniz]]
* [[List of things named after John Milnor]]
* [[List of things named after Isaac Newton]]
* [[List of things named after Henri Poincaré]]
* [[List of things named after Siméon Denis Poisson]]
* [[List of things named after Pythagoras]]
* [[List of things named after Srinivasa Ramanujan]]
* [[List of things named after Bernhard Riemann]]
* [[List of things named after Jean-Pierre Serre]]
* [[List of things named after James Joseph Sylvester]]
* [[List of things named after Alfred Tarski]]
* [[List of things named after Karl Weierstrass]]
* [[List of things named after André Weil]]
* [[List of things named after Hermann Weyl]]
* [[List of things named after Ernst Witt]]
* [[List of things named after John von Neumann]]

==Reference tables==
* [[List of mathematical reference tables]]
* [[List of moments of inertia]]
* [[Table of derivatives]]

===Integrals===
In calculus, the [[integral]] of a function is a generalization of area, mass, volume, sum, and total. The following pages list the integrals of many different functions.
* [[Lists of integrals]]
* [[List of integrals of exponential functions]]
* [[List of integrals of hyperbolic functions]]
* [[List of integrals of inverse hyperbolic functions]]
* [[List of integrals of inverse trigonometric functions]]
* [[List of integrals of irrational functions]]
* [[List of integrals of logarithmic functions]]
* [[List of integrals of rational functions]]
* [[List of integrals of trigonometric functions]]

==Journals==
*[[List of mathematics journals]]
*[[List of mathematics education journals]]
*[[:Category:History of science journals]]
*[[:Category:Philosophy of science literature]]

==Meta-lists==
* [[List of important publications in mathematics]]
* [[List of important publications in statistics]]
* [[List of mathematical theories]]
* [[List of mathematics categories]]
* [[Table of mathematical symbols]]
* [[Table of logic symbols]]

==Others==
* [[Lists of unsolved problems in mathematics]]
* [[List of topics related to π]]
* [[List of order theory topics]]

==Notes==
* {{note|1|Note 1}}:  Definition from the ''Journal of Mathematical Physics'' [https://web.archive.org/web/20061003233339/http://jmp.aip.org/jmp/staff.jsp].

==External links and references==
* [http://www.ams.org/msc 2000 Mathematics Subject Classification] from the [[American Mathematical Society]], a scheme authors find many mathematics research journals asking them to use to classify their submissions; those published then include these classifications.
* [http://www.math-atlas.org The Mathematical Atlas]


{{Areas of mathematics}}

[[Category:Mathematics-related lists| ]]
[[Category:Lists of lists|Mathematics]]
[[Category:Wikipedia outlines|Mathematics]]
[[Category:Lists of topics|Mathematics]]</text>
      <sha1>ksm2bhlwnxdjhnmc3awb0v42tsug231</sha1>
    </revision>
  </page>
  <page>
    <title>Loss network</title>
    <ns>0</ns>
    <id>38246589</id>
    <revision>
      <id>818937738</id>
      <parentid>811598152</parentid>
      <timestamp>2018-01-06T13:42:44Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.1)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4703">In [[queueing theory]], a '''loss network''' is a [[stochastic model]] of a [[telephony network]] in which calls are routed around a network between nodes. The links between nodes have finite capacity and thus some calls arriving may find no route available to their destination. These calls are lost from the network, hence the name loss networks.&lt;ref name="harr"&gt;{{Cite book | last = Harrison | first = Peter G. | authorlink = Peter G. Harrison | last2 = Patel | first2 = Naresh M. | title = Performance Modelling of Communication Networks and Computer Architectures | publisher = Addison-Wesley | date = 1992 | isbn = 0201544199 | page=417}}&lt;/ref&gt;

The loss network was first studied by [[Agner Krarup Erlang|Erlang]] for a single telephone link.&lt;ref&gt;{{Cite book | last1 = Zachary | first1 = S. | last2 = Ziedins | first2 = I. | chapter = Loss Networks | doi = 10.1007/978-1-4419-6472-4_16 | title = Queueing Networks | series = International Series in Operations Research &amp; Management Science | volume = 154 | pages = 701 | year = 2011 | isbn = 978-1-4419-6471-7 | pmid =  | pmc = }}&lt;/ref&gt; [[Frank Kelly (mathematician)|Frank Kelly]] was awarded the [[Frederick W. Lanchester Prize]]&lt;ref&gt;{{cite web|url=http://www.informs.org/Recognize-Excellence/INFORMS-Prizes-Awards/Frederick-W.-Lanchester-Prize|title=Frederick W. Lanchester Prize|publisher=informs|accessdate=2010-11-17|deadurl=yes|archiveurl=https://web.archive.org/web/20101231231640/http://www.informs.org/Recognize-Excellence/INFORMS-Prizes-Awards/Frederick-W.-Lanchester-Prize|archivedate=2010-12-31|df=}}&lt;/ref&gt; for his 1991 paper ''Loss Networks''&lt;ref&gt;{{cite web|url=http://www.statslab.cam.ac.uk/~frank/loss/|title=Loss networks|publisher=Frank Kelly|accessdate=2010-11-17}}&lt;/ref&gt;&lt;ref name="ln"&gt;{{Cite journal | last1 = Kelly | first1 = F. P. | authorlink1 = Frank Kelly (mathematician)| title = Loss Networks | doi = 10.1214/aoap/1177005872 | journal = The Annals of Applied Probability | volume = 1 | issue = 3 | pages = 319 | year = 1991 | jstor=2959742| pmid =  | pmc = }}&lt;/ref&gt; where he demonstrated the behaviour of loss networks can exhibit [[hysteresis]].

==Model==

===Fixed routing===

Consider a network with ''J'' links labelled 1, 2, …, ''J'' and that each link ''j'' has ''C''&lt;sub&gt;''j''&lt;/sub&gt; [[circuit switching|circuits]]. Let ''R'' be the set of all possible routes in the network (combinations of links a call might use) and each route ''r'', write ''A''&lt;sub&gt;''jr''&lt;/sub&gt; for the number of circuits route ''r'' uses on link ''j'' (''A'' is therefore a ''J'' x |''R''| matrix). Consider the case where all elements of ''A'' are either 0 or 1 and for each route ''r'' calls requiring use of the route arrive according to a [[Poisson process]] of rate ''v''&lt;sub&gt;''r''&lt;/sub&gt;. When a call arrives if there is sufficient capacity remaining on all the required links the call is accepted and occupies the network for an [[exponentially distributed]] length of time with parameter 1. If there is insufficient capacity on any individual link to accept the call it is rejected (lost) from the network.&lt;ref name="ln" /&gt;

Write ''n''&lt;sub&gt;''r''&lt;/sub&gt;(''t'') for the number of calls on route ''r'' in progress at time ''t'', ''n''(''t'') for the vector (''n''&lt;sub&gt;''r''&lt;/sub&gt;(''t'') : ''r'' in ''R'') and ''C'' = (''C''&lt;sub&gt;1&lt;/sub&gt;, ''C''&lt;sub&gt;2&lt;/sub&gt;, ... , ''C''&lt;sub&gt;''J''&lt;/sub&gt;). Then the [[continuous-time Markov process]] ''n''(''t'') has unique stationary distribution&lt;ref name="ln" /&gt;
::&lt;math&gt;\pi(n) = G(C)^{-1} \prod_{r \in R} \frac{v_r^{n_r}}{n_r!} \text { for } n \in S(C)&lt;/math&gt;
where
::&lt;math&gt;S(C) = \{ n \in \mathbb Z_+^R : An \leq C\}&lt;/math&gt;
and
::&lt;math&gt;G(C) = \left( \sum_{n \in S(C)} \prod_{r \in R} \frac{v_r^{n_r}}{n_r!} \right).&lt;/math&gt;

From this result loss probabilities for calls arriving on different routes can be calculated by summing over appropriate states.

==Computing loss probabilities==

There are common algorithms for computing the loss probabilities in loss networks&lt;ref&gt;{{Cite book | last1 = Jung | first1 = K. | last2 = Lu | first2 = Y. | last3 = Shah | first3 = D. | last4 = Sharma | first4 = M. | last5 = Squillante | first5 = M. S. | doi = 10.1145/1375457.1375503 | chapter = Revisiting stochastic loss networks | title = Proceedings of the 2008 ACM SIGMETRICS international conference on Measurement and modeling of computer systems  - SIGMETRICS '08 | pages = 407 | year = 2008 | isbn = 9781605580050 | url = http://web.mit.edu/devavrat/www/lossnet.pdf| pmid =  | pmc = }}&lt;/ref&gt;
# Erlang fixed-point approximation
# Slice method
# 3-point slice method

==Notes==

{{Reflist}}

{{Queueing theory}}

[[Category:Queueing theory]]
[[Category:Application-specific graphs]]


{{probability-stub}}</text>
      <sha1>f354tj6ht7g9amsvg445ap8thwinjpc</sha1>
    </revision>
  </page>
  <page>
    <title>MESH (cipher)</title>
    <ns>0</ns>
    <id>7972057</id>
    <revision>
      <id>814159664</id>
      <parentid>814159474</parentid>
      <timestamp>2017-12-07T05:31:08Z</timestamp>
      <contributor>
        <username>Sha-rach</username>
        <id>32522247</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2172">{{about|the block cipher||Mesh (disambiguation)}}
{{Infobox block cipher
| name          = MESH
| designers     = [[Jorge Nakahara, Jr.|Nakahara]], [[Vincent Rijmen|Rijmen]], [[Bart Preneel|Preneel]], [[Joos Vandewalle|Vandewalle]]
| publish date  = 2002
| derived from  = [[International Data Encryption Algorithm|IDEA]]
| key size      = 128, 192, or 256 bits
| block size    = 64, 96, or 128 bits
| structure     = [[Lai-Massey scheme]]
| rounds        = 8.5, 10.5, or 12.5
| cryptanalysis = 2 rounds can be broken using 128, 161, or 225 [[known-plaintext attack|known plaintexts]]
}}

In cryptography, '''MESH''' is a [[block cipher]] designed in 2002 by [[Jorge Nakahara, Jr.]], [[Vincent Rijmen]], [[Bart Preneel]], and [[Joos Vandewalle]]. MESH is based directly on [[International Data Encryption Algorithm|IDEA]] and uses the same basic operations.

MESH is actually a family of 3 variant ciphers with [[block size (cryptography)|block size]]s of 64, 96, and 128 bits. &lt;ref&gt;{{Cite book|title=The MESH Block Ciphers|last=|first=|publisher=|year=|isbn=|location=Austria|pages=2}}&lt;/ref&gt;The [[key size]] is twice the block size. The number of rounds is 8.5, 10.5, or 12.5, depending on the block size. The algorithm uses a [[Lai-Massey scheme]] based on IDEA's, but with a larger round structure, or "MA-box".  MESH also has a more complex [[key schedule]] than IDEA, intended to prevent [[weak key]]s and other insecure patterns in subkeys.

==References==
* {{cite journal
    |author1=J. Nakahara, Jr |author2=V. Rijmen |author3=B. Preneel |author4=J. Vandewalle | title = The MESH Block Ciphers
    | year = 2002
    | url = http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.2249
    | format = PDF/PostScript
    | accessdate = 8 February 2007 }}
* {{cite journal
    |author1=J. Nakahara Jr. |author2=B. Preneel |author3=J. Vandewalle  |last-author-amp=yes | title = The Biryukov-Demirci Attack on IDEA and MESH Ciphers
    | year = 2003
    | url = http://citeseer.ist.psu.edu/600837.html
    | format = PDF/PostScript
    | accessdate = 4 October 2007 }}
*
&lt;references /&gt;

{{Cryptography navbox | block}}

[[Category:Block ciphers]]


{{crypto-stub}}</text>
      <sha1>63qymlrv81b7vi1ywop3xdzumm8dfjl</sha1>
    </revision>
  </page>
  <page>
    <title>Mary P. Dolciani</title>
    <ns>0</ns>
    <id>11916611</id>
    <revision>
      <id>821424702</id>
      <parentid>738629731</parentid>
      <timestamp>2018-01-20T11:27:01Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 1 as dead. #IABot (v1.6.2)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4208">'''Mary P. Dolciani''' (1923–1985) was an [[United States|American]] [[mathematician]], known for her work with secondary-school mathematics teachers.

Dolciani earned her [[Bachelor of Arts]] degree (B.A.) at [[Hunter College]] in [[New York City]], and she completed her [[doctor of philosophy]] (Ph.D.) at [[Cornell University]] in 1947 with [[Burton Wadsworth Jones|B. W. Jones]] as thesis advisor. She taught briefly at [[Vassar College]] before returning to Hunter, where she spent the next forty years. Dolciani taught mathematics there, and at times, she also served as a [[Dean (education)|Dean]] or the Provost.

Beginning in the 1960s Mary Dolciani wrote a series of high school mathematics textbook, ''Structure and Method'', which in 2000 - 2010 has experienced a resurgence of popularity.

Shortly before her death in 1985, Dolciani also co-wrote (along with two other mathematics educators) ''Pre-Algebra: An Accelerated Course''. This textbook was widely used in the later 1980s through the 1990s. In addition to teaching the pure mathematics, it emphasized the usefulness of algebra in various practical applications.

The [[Mathematical Association of America]] publishes a series of mathematical books named for her: ''The Dolciani Mathematical Expositions''. Also, the Association's headquarters building in [[Washington D.C.]] is named The Dolciani Mathematical Center in her honor.

Although Dolciani is not well known by the general public, she was influential in developing the basic modern method used for teaching basic algebra in the United States (called "Dolciani algebra", which teaches it on the basis of drill like arithmetic, rather than on the basis of proofs as in [[Euclidean geometry]]). Dolciani  also popularized the short-form names of the Properties that are familiar to many high school algebra students, e.g. the "Zero Property".

==Mary P. Dolciani Halloran Foundation==

In 1982, Dr. Mary P. Dolciani Halloran, with her husband James J. Halloran and Eugene J. Callahan as Trustees, established the Mary P. Dolciani Halloran Foundation to further the study of mathematics and mathematics education.&lt;ref name="Mary P. Dolciani Halloran Foundation"&gt;{{cite web | last = Mary P. Dolciani Halloran Foundation | title = The Foundation | publisher = Mary P. Dolciani Halloran Foundation | url= http://dolcianihalloran.squarespace.com/the-foundation/ | accessdate = 1 February 2013}}&lt;/ref&gt;

==References==

{{reflist}}

==External links==
* {{cite web|title=Mary P. Dolciani |url=http://www.coe.ufl.edu/webtech/greatideas/pages/peoplepage/dolciani.htm |deadurl=yes |archiveurl=https://web.archive.org/web/20050315033853/http://www.coe.ufl.edu/webtech/GreatIdeas/pages/peoplepage/dolciani.htm |archivedate=March 15, 2005 }}
* {{cite web | title = The Mary P.Dolciani :: Mathematics Learning Center | url = http://math.hunter.cuny.edu/dolciani/}}
* {{cite web | title = About Mary P. Dolciani | url = http://math.hunter.cuny.edu/dolciani/about_mpd_exp01.html | deadurl = yes | archiveurl = https://web.archive.org/web/20100613025850/http://math.hunter.cuny.edu/dolciani/about_mpd_exp01.html | archivedate = 2010-06-13 | df =  }}
* {{cite web | title = Mary P. Dolciani Biography | url = http://www.nctm.org/resources/content.aspx?id=2912 }}
* {{cite journal | last = Anonymous | title = Professor Mary P. Dolciani-Halloran, March 3, 1923 - August 5, 1985 | journal = The Hunter Magazine | date = Fall 1986 | url = http://library.hunter.cuny.edu/sites/default/files/pdf/archive_articles/professor_mary_p_colciani_hallroran_fall1986.pdf | accessdate = 1 February 2013 }}{{dead link|date=January 2018 |bot=InternetArchiveBot |fix-attempted=yes }}
* {{cite web | title = Mary P. Dolciani Halloran Foundation: Meet Mary | url = http://dolcianihalloran.squarespace.com/meet-mary/ | accessdate = 1 February 2013}}

{{Authority control}}

{{DEFAULTSORT:Dolciani, Mary P.}}
[[Category:Hunter College alumni]]
[[Category:Women mathematicians]]
[[Category:20th-century American mathematicians]]
[[Category:Cornell University alumni]]
[[Category:Vassar College faculty]]
[[Category:Hunter College faculty]]
[[Category:1985 deaths]]
[[Category:1923 births]]


{{US-mathematician-stub}}</text>
      <sha1>etme3j1me8iu86vj9t3b0p6rng3ne4r</sha1>
    </revision>
  </page>
  <page>
    <title>Michel Broué</title>
    <ns>0</ns>
    <id>27210822</id>
    <revision>
      <id>870503861</id>
      <parentid>806503077</parentid>
      <timestamp>2018-11-25T07:03:00Z</timestamp>
      <contributor>
        <username>George Ho</username>
        <id>595371</id>
      </contributor>
      <comment>chg img</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1715">{{Infobox scientist
| name              = Michel Broué
| image             = Michel Broué 2008 (headshot).jpg
| image_size        = 
| caption           = 
| birth_date        = {{birth date and age|1946|10|28}}
| birth_place       = 
| death_date        = 
| death_place       = 
| nationality       = [[France|French]]
| fields            = [[Mathematics]]
| workplaces        = [[Paris Diderot University]]
| alma_mater        = [[University of Paris]]
| doctoral_advisor  = [[Claude Chevalley]]&lt;br&gt;[[Jean-Pierre Serre]]
| doctoral_students = [[Raphaël Rouquier]]
| known_for         = 
| awards            = 
}}
'''Michel Broué''' (born October 28, 1946) is a [[France|French]] [[mathematician]]. He holds a chair at [[Paris Diderot University]]. Broué has made contributions to [[algebraic geometry]] and [[representation theory]].

In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2012-11-10.&lt;/ref&gt;

He is the son of French historian [[Pierre Broué]] and the father of French director and screenwriter [[Isabelle Broué]] and of French journalist and radio producer [[Caroline Broué]].

==References==
{{reflist}}

==External links==
*[http://www.math.jussieu.fr/~broue/ Website at Paris Diderot University]
*{{MathGenealogy |id=44660 }}

{{Authority control}}

{{DEFAULTSORT:Broue, Michel}}
[[Category:1946 births]]
[[Category:Living people]]
[[Category:20th-century French mathematicians]]
[[Category:21st-century French mathematicians]]
[[Category:University of Paris alumni]]
[[Category:Fellows of the American Mathematical Society]]


{{France-mathematician-stub}}</text>
      <sha1>redfndf2yu43ea38qg8tvlb0o0dj9oq</sha1>
    </revision>
  </page>
  <page>
    <title>Nearest neighbor search</title>
    <ns>0</ns>
    <id>7309022</id>
    <revision>
      <id>865938449</id>
      <parentid>857158885</parentid>
      <timestamp>2018-10-27T05:06:35Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* Sources */ authorlinks</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="25996">'''Nearest neighbor search''' ('''NNS'''), as a form of proximity search,  is the [[optimization problem]] of finding the point in a given set that is closest (or most similar) to a given point. Closeness is typically expressed in terms of a dissimilarity function: the less similar the objects, the larger the function values. Formally, the nearest-neighbor (NN) search problem is defined as follows: given a set ''S'' of points in a space ''M'' and a query point ''q''&amp;nbsp;∈&amp;nbsp;''M'', find the closest point in ''S'' to ''q''. [[Donald Knuth]] in vol. 3 of ''[[The Art of Computer Programming]]'' (1973) called it the '''post-office problem''', referring to an application of assigning to a residence the nearest post office. A direct generalization of this problem is a ''k''-NN search, where we need to find the ''k'' closest points.

Most commonly ''M'' is a  [[metric space]] and dissimilarity is expressed as a [[distance metric]], which is symmetric and satisfies the [[triangle inequality]]. Even more common, ''M'' is taken to be the ''d''-dimensional [[vector space]] where dissimilarity is measured using the [[Euclidean distance]], [[Taxicab geometry|Manhattan distance]] or other [[Statistical distance|distance metric]]. However, the dissimilarity function can be arbitrary. One example are asymmetric [[Bregman divergence]]s, for which the triangle inequality does not hold.&lt;ref name=Cayton2008&gt;{{Cite journal
 | last1 = Cayton | first1 = Lawerence
 | year = 2008
 | title =  Fast nearest neighbor retrieval for bregman divergences
 | journal = Proceedings of the 25th International Conference on Machine Learning
 | pages = 112–119
}}&lt;/ref&gt;

==Applications==
The nearest neighbor search problem arises in numerous fields of application, including:
* [[Pattern recognition]] – in particular for [[optical character recognition]]
* [[Statistical classification]] – see [[k-nearest neighbor algorithm]]
* [[Computer vision]]
* [[Computational geometry]] – see [[Closest pair of points problem]]
* [[Database]]s – e.g. [[content-based image retrieval]]
* [[Coding theory]] – see [[Decoding methods|maximum likelihood decoding]]
* [[Data compression]] – see [[MPEG-2]] standard
* [[Robotic]] sensing&lt;ref name=panSearch&gt;{{cite conference|last1=Bewley|first1=A.|last2=Upcroft|first2=B.|date=2013|title=Advantages of Exploiting Projection Structure for Segmenting Dense 3D Point Clouds|conference=Australian Conference on Robotics and Automation |url=http://www.araa.asn.au/acra/acra2013/papers/pap148s1-file1.pdf}}&lt;/ref&gt;
* [[Recommender system|Recommendation systems]], e.g. see [[Collaborative filtering]]
* [[Internet marketing]] – see [[contextual advertising]] and [[behavioral targeting]]
* [[DNA sequencing]]
* [[Spell checking]] – suggesting correct spelling
* [[Plagiarism detection]]
* [[Contact searching algorithms in FEA]]
* [[Similarity score]]s for predicting career paths of professional athletes.
* [[Cluster analysis]] – assignment of a set of observations into subsets (called clusters) so that observations in the same cluster are similar in some sense, usually based on [[Euclidean distance]]
* [[Chemical similarity]]
* [[Motion planning#Sampling-based algorithms|Sampling-based motion planning]]
* [[Intermodal freight transport]]&lt;ref&gt;{{cite journal|last1=Munim|first1=Ziaul Haque|last2=Haralambides|first2= Hercules |title= Competition and cooperation for intermodal container transhipment: A network optimization approach|journal=Research in Transportation Business &amp; Management|date=2018|pages=87–99|doi= 10.1016/j.rtbm.2018.03.004|url= https://www.sciencedirect.com/science/article/pii/S2210539517301001|volume=26}}&lt;/ref&gt;

==Methods==

Various solutions to the NNS problem have been proposed.  The quality and usefulness of the algorithms are determined by the time complexity of queries as well as the space complexity of any search data structures that must be maintained. The informal observation usually referred to as the [[curse of dimensionality]] states that there is no general-purpose exact solution for NNS in high-dimensional Euclidean space using polynomial preprocessing and polylogarithmic search time.

=== Exact methods ===

====Linear search====
The simplest solution to the NNS problem is to compute the distance from the query point to every other point in the database, keeping track of the "best so far".  This algorithm, sometimes referred to as the naive approach, has a [[running time]] of ''O''(''dN'') where ''N'' is the [[cardinality]] of ''S'' and ''d'' is the dimensionality of ''M''.  There are no search data structures to maintain, so linear search has no space complexity beyond the storage of the database. Naive search can, on average, outperform space partitioning approaches on higher dimensional spaces.&lt;ref&gt;{{cite journal|title=A quantitative analysis and performance study for similarity search methods in high dimensional spaces|last1=Weber|first1=Roger|last2=Schek|first2=Hans-J.|last3=Blott|first3=Stephen | url=http://www.vldb.org/conf/1998/p194.pdf}}&lt;/ref&gt;

====Space partitioning====
Since the 1970s, [[branch and bound]] methodology has been applied to the problem. In the case of Euclidean space this approach is known as [[spatial index]] or spatial access methods. Several [[Space partitioning|space-partitioning]] methods have been developed for solving the NNS problem.  Perhaps the simplest is the [[k-d tree]], which iteratively bisects the search space into two regions containing half of the points of the parent region.  Queries are performed via traversal of the tree from the root to a leaf by evaluating the query point at each split. Depending on the distance specified in the query, neighboring branches that might contain hits may also need to be evaluated. For constant dimension query time, average complexity is ''O''(log&amp;nbsp;''N'') &lt;ref&gt;{{cite web|title=An introductory tutorial on KD trees|author=Andrew Moore | url=http://www.autonlab.com/autonweb/14665/version/2/part/5/data/moore-tutorial.pdf?branch=main&amp;language=en}}&lt;/ref&gt; in the case of randomly distributed points, worst case complexity is ''O''(''kN''^(1-1/''k''))&lt;ref name=Lee1977&gt;{{Cite journal
 | last1 = Lee | first1 = D. T. | author1-link = Der-Tsai Lee
 | last2 = Wong | first2 = C. K.
 | year = 1977
 | title = Worst-case analysis for region and partial region searches in multidimensional binary search trees and balanced quad trees
 | journal = Acta Informatica
 | volume = 9
 | issue = 1
 | pages = 23–29
 | doi = 10.1007/BF00263763
 | postscript = .
}}&lt;/ref&gt;
Alternatively the [[R-tree]] data structure was designed to support nearest neighbor search in dynamic context, as it has efficient algorithms for insertions and deletions such as the [[R* tree]].&lt;ref&gt;{{Cite conference | doi = 10.1145/223784.223794| chapter = Nearest neighbor queries| title = Proceedings of the 1995 ACM SIGMOD international conference on Management of data  – SIGMOD '95| pages = 71| year = 1995| last1 = Roussopoulos | first1 = N. | last2 = Kelley | first2 = S. | last3 = Vincent | first3 = F. D. R. | isbn = 0897917316}}&lt;/ref&gt; R-trees can yield nearest neighbors not only for Euclidean distance, but can also be used with other distances.

In case of general metric space branch and bound approach is known under the name of [[metric trees]]. Particular examples include [[vp-tree]] and [[BK-tree]].

Using a set of points taken from a 3-dimensional space and put into a [[Binary space partitioning|BSP tree]], and given a query point taken from the same space, a possible solution to the problem of finding the nearest point-cloud point to the query point is given in the following description of an algorithm.  (Strictly speaking, no such point may exist, because it may not be unique.  But in practice, usually we only care about finding any one of the subset of all point-cloud points that exist at the shortest distance to a given query point.)  The idea is, for each branching of the tree, guess that the closest point in the cloud resides in the half-space containing the query point.  This may not be the case, but it is a good heuristic.  After having recursively gone through all the trouble of solving the problem for the guessed half-space, now compare the distance returned by this result with the shortest distance from the query point to the partitioning plane.  This latter distance is that between the query point and the closest possible point that could exist in the half-space not searched.  If this distance is greater than that returned in the earlier result, then clearly there is no need to search the other half-space.  If there is such a need, then you must go through the trouble of solving the problem for the other half space, and then compare its result to the former result, and then return the proper result.  The performance of this algorithm is nearer to logarithmic time than linear time when the query point is near the cloud, because as the distance between the query point and the closest point-cloud point nears zero, the algorithm needs only perform a look-up using the query point as a key to get the correct result.

=== Approximation methods ===
An approximate nearest neighbor search algorithm is allowed to return points, whose distance from the query is at most &lt;math&gt;c&lt;/math&gt; times the distance from the query to its nearest points. The appeal of this approach is that, in many cases, an approximate nearest neighbor is almost as good as the exact one. In particular, if the distance measure accurately captures the notion of user quality, then small differences in the distance should not matter.&lt;ref&gt;{{Cite book|last=Andoni|first=A.|last2=Indyk|first2=P.|date=2006-10-01|title=Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions|url=http://ieeexplore.ieee.org/document/4031381/|journal=2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS'06)|pages=459–468|doi=10.1109/FOCS.2006.49|isbn=978-0-7695-2720-8|citeseerx=10.1.1.142.3471}}&lt;/ref&gt;

====Greedy search in proximity neighborhood graphs====
Proximity graph methods (such as HNSW&lt;ref name=":0"&gt;{{cite arxiv|last=Malkov|first=Yury|last2=Yashunin|first2=Dmitry|date=2016|title=Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs|eprint=1603.09320|class=cs.DS}}&lt;/ref&gt;) are considered the current state-of-the-art for the approximate nearest neighbors search.&lt;ref name=":0" /&gt;&lt;ref&gt;{{Cite web|url=https://erikbern.com/2018/06/17/new-approximate-nearest-neighbor-benchmarks.html|title=New approximate nearest neighbor benchmarks|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.benfrederickson.com/approximate-nearest-neighbours-for-recommender-systems/|title=Approximate Nearest Neighbours for Recommender Systems|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;

The methods are based on greedy traversing in proximity neighborhood graphs &lt;math&gt;G(V,E)&lt;/math&gt;in which every point &lt;math&gt;x_i \in S &lt;/math&gt; is uniquely associated with vertex &lt;math&gt;v_i \in V &lt;/math&gt;. The search for the nearest neighbors to a query ''q'' in the set ''S'' takes the form of searching for the vertex in the graph &lt;math&gt;G(V,E)&lt;/math&gt;.
The basic algorithm - greedy search, works as follows: search starts from an enter-point vertex &lt;math&gt;v_i \in V &lt;/math&gt; by computing the distances from the query q to each vertex of its the neighborhood &lt;math&gt;\{v_j:(v_i,v_j) \in E\}&lt;/math&gt;, and then finds a vertex with the minimal distance value. If the distance value between the query and the selected vertex is smaller than the one between the query and the current element, then the algorithm moves to the selected vertex, and it becomes new enter-point. The algorithm stops when it reaches a local minimum: a vertex whose neighborhood does not contain a vertex that is closer to the query than the vertex itself.

The idea of proximity neighborhood graphs was exploited in multiple publications, including the seminal paper by Arya and Mount,&lt;ref&gt;{{cite journal|last1=Arya|first1=Sunil|last2=Mount|first2=David|date=1993|title=Approximate Nearest Neighbor Queries in Fixed Dimensions|journal=Proceedings of the Fourth Annual {ACM/SIGACT-SIAM} Symposium on Discrete Algorithms, 25–27 January 1993, Austin, Texas.|pages=271–280}}&lt;/ref&gt; in the VoroNet system for the plane,&lt;ref name="voroNet"&gt;{{Cite journal|last1=Olivier|first1=Beaumont|last2=Kermarrec|first2=Anne-Marie|last3=Marchal|first3=Loris|last4=Rivière|first4=Etienne|year=2006|title=VoroNet: A scalable object network based on Voronoi tessellations|journal=INRIA|volume=RR-5833|issue=1|pages=23–29|doi=10.1007/BF00263763|postscript=.}}&lt;/ref&gt; in the RayNet system for the &lt;math&gt;\mathbb{E}^n&lt;/math&gt;,&lt;ref name="rayNet"&gt;{{Cite book|last1=Olivier|first1=Beaumont|last2=Kermarrec|first2=Anne-Marie|last3=Rivière|first3=Etienne|year=2007|title=Peer to Peer Multidimensional Overlays: Approximating Complex Structures|journal=Principles of Distributed Systems|volume=4878|issue=|pages=315–328|doi=10.1007/978-3-540-77096-1_23|isbn=978-3-540-77095-4|postscript=.|citeseerx=10.1.1.626.2980}}&lt;/ref&gt; in the Metrized Small World&lt;ref name="msw2014"&gt;{{Cite journal|last1=Malkov|first1=Yury|last2=Ponomarenko|first2=Alexander|last3=Krylov|first3=Vladimir|last4=Logvinov|first4=Andrey|year=2014|title=Approximate nearest neighbor algorithm based on navigable small world graphs|journal=Information Systems|volume=45|pages=61–68|doi=10.1016/j.is.2013.10.006|postscript=.}}&lt;/ref&gt;  and HNSW&lt;ref name=":0" /&gt; algorithms for the general case of spaces with a distance function. These works were preceded by a pioneering paper by Toussaint, where he introduced a concept of a ''relative neighborhood'' graph.&lt;ref&gt;{{cite journal|last1=Toussaint|first1=Godfried|date=1980|title=The relative neighbourhood graph of a finite planar set|journal=Pattern Recognition|volume=12|issue=4|pages=261–268}}&lt;/ref&gt;

====Locality sensitive hashing====

[[Locality sensitive hashing]] (LSH) is a technique for grouping points in space into 'buckets' based on some distance metric operating on the points. Points that are close to each other under the chosen metric are mapped to the same bucket with high probability.&lt;ref&gt;{{cite web|author1=A. Rajaraman  |author2=J. Ullman |lastauthoramp=yes | url=http://infolab.stanford.edu/~ullman/mmds.html |title=Mining of Massive Datasets, Ch. 3 |year=2010}}&lt;/ref&gt;

====Nearest neighbor search in spaces with small intrinsic dimension====

The [[cover tree]] has a theoretical bound that is based on the dataset's [[doubling constant]]. The bound on search time is ''O''(''c''&lt;sup&gt;12&lt;/sup&gt;&amp;nbsp;log&amp;nbsp;''n'') where ''c''  is the [[Expansivity constant|expansion constant]] of the dataset.

====Projected radial search====

In the special case where the data is a dense 3D map of geometric points, the projection geometry of the sensing technique can be used to dramatically simplify the search problem.
This approach requires that the 3D data is organized by a projection to a two dimensional grid and assumes that the data is spatially smooth across neighboring grid cells with the exception of object boundaries.
These assumptions are valid when dealing with 3D sensor data in applications such as surveying, robotics and stereo vision but may not hold for unorganized data in general.
In practice this technique has an average search time of ''O''(''1'')  or ''O''(''K'')  for the ''k''-nearest neighbor problem when applied to real world stereo vision data.
&lt;ref name=panSearch/&gt;

====Vector approximation files====

In high dimensional spaces, tree indexing structures become useless because an increasing percentage of the nodes need to be examined anyway. To speed up linear search, a compressed version of the feature vectors stored in RAM is used to prefilter the datasets in a first run. The final candidates are determined in a second stage using the uncompressed data from the disk for distance calculation.&lt;ref&gt;{{cite journal|title=An Approximation-Based Data Structure for Similarity Search|last1=Weber|first1=Roger|last2=Blott|first2=Stephen|url=https://pdfs.semanticscholar.org/83e4/e3281411ffef40654a4b5d29dae48130aefb.pdf}}&lt;/ref&gt;

====Compression/clustering based search====
The VA-file approach is a special case of a compression based search, where each feature component is compressed uniformly and independently. The optimal compression technique in multidimensional spaces is [[Vector Quantization]] (VQ), implemented through clustering. The database is clustered and the most "promising" clusters are retrieved. Huge gains over VA-File, tree-based indexes and sequential scan have been observed.&lt;ref&gt;{{cite journal|title=Adaptive cluster-distance bounding for similarity search in image databases|last1=Ramaswamy|first1=Sharadh|last2=Rose|first2=Kenneth|journal=ICIP|date=2007}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Adaptive cluster-distance bounding for high-dimensional indexing|last1=Ramaswamy|first1=Sharadh|last2=Rose|first2=Kenneth|journal=TKDE|date=2010}}&lt;/ref&gt; Also note the parallels between clustering and LSH.

==Variants==

There are numerous variants of the NNS problem and the two most well-known are the [[K-nearest neighbor algorithm|''k''-nearest neighbor search]] and the [[ε-approximate nearest neighbor search]].

===&lt;span id="K-nearest neighbor"&gt; ''k''-nearest neighbors &lt;/span&gt;===

[[K-nearest neighbor algorithm|''k''-nearest neighbor search]] identifies the top ''k'' nearest neighbors to the query.  This technique is commonly used in predictive analytics to estimate or classify a point based on the consensus of its neighbors. ''k''-nearest neighbor graphs are graphs in which every point is connected to its ''k'' nearest neighbors.

===Approximate nearest neighbor===
In some applications it may be acceptable to retrieve a "good guess" of the nearest neighbor. In those cases, we can use an algorithm which doesn't guarantee to return the actual nearest neighbor in every case, in return for improved speed or memory savings. Often such an algorithm will find the nearest neighbor in a majority of cases, but this depends strongly on the dataset being queried.

Algorithms that support the approximate nearest neighbor search include [[Locality-sensitive hashing#LSH algorithm for nearest neighbor search|locality-sensitive hashing]], [[best bin first]] and [[balanced box-decomposition tree]] based search.&lt;ref&gt;{{cite journal|first1=S.|last1=Arya|author2-link=David Mount|first2=D. M.|last2=Mount|author3-link=Nathan Netanyahu|first3=N. S.|last3=Netanyahu|first4=R.|last4=Silverman|first5=A.|last5=Wu|title=An optimal algorithm for approximate nearest neighbor searching|journal= Journal of the ACM|volume=45|number=6|pages=891–923|date=1998|url=http://www.cse.ust.hk/faculty/arya/pub/JACM.pdf|doi=10.1145/293347.293348|citeseerx=10.1.1.15.3125}}&lt;/ref&gt;

===Nearest neighbor distance ratio===

[[Nearest neighbor distance ratio]] do not apply the threshold on the direct distance from the original point to the challenger neighbor but on a ratio of it depending on the distance to the previous neighbor. It is used in [[Content-based image retrieval|CBIR]] to retrieve pictures through a "query by example" using the similarity between local features. More generally it is involved in several [[Pattern matching|matching]] problems.

===Fixed-radius near neighbors===

[[Fixed-radius near neighbors]] is the problem where one wants to efficiently find all points given in [[Euclidean space]] within a given fixed distance from a specified point. The data structure should work on a distance which is fixed however the query point is arbitrary.

===All nearest neighbors===

For some applications (e.g. [[entropy estimation]]), we may have ''N'' data-points and wish to know which is the nearest neighbor ''for every one of those N points''. This could of course be achieved by running a nearest-neighbor search once for every point, but an improved strategy would be an algorithm that exploits the information redundancy between these ''N'' queries to produce a more efficient search. As a simple example: when we find the distance from point ''X'' to point ''Y'', that also tells us the distance from point ''Y'' to point ''X'', so the same calculation can be reused in two different queries.

Given a fixed dimension, a semi-definite positive norm (thereby including every  [[lp space|L&lt;sup&gt;p&lt;/sup&gt; norm]]), and ''n'' points in this space, the nearest neighbour of every point can be found in ''O''(''n''&amp;nbsp;log&amp;nbsp;''n'') time and the ''m'' nearest neighbours of every point can be found in ''O''(''mn''&amp;nbsp;log&amp;nbsp;''n'') time.&lt;ref&gt;{{citation
 | last = Clarkson | first = Kenneth L. | author-link = Kenneth L. Clarkson
 | contribution = Fast algorithms for the all nearest neighbors problem
 | doi = 10.1109/SFCS.1983.16
 | pages = 226–232
 | title = 24th IEEE Symp. Foundations of Computer Science, (FOCS '83)
 | year = 1983| isbn = 978-0-8186-0508-6 }}.&lt;/ref&gt;&lt;ref name=Vaidya&gt;{{Cite journal
 | doi = 10.1007/BF02187718
 | last1 = Vaidya | first1 = P. M.
 | year = 1989
 | title = An ''O''(''n''&amp;nbsp;log&amp;nbsp;''n'') Algorithm for the All-Nearest-Neighbors Problem
 | journal = [[Discrete and Computational Geometry]]
 | volume = 4
 | issue = 1
 | pages = 101–115
 | url = http://www.springerlink.com/content/p4mk2608787r7281/?p=09da9252d36e4a1b8396833710ef08cc&amp;pi=8
 | postscript = .
}}&lt;/ref&gt;

==See also==
{{div col|colwidth=20em}}
* [[Ball tree]]
* [[Closest pair of points problem]]
* [[Cluster analysis]]
* [[Content-based image retrieval]]
* [[Curse of dimensionality]]
* [[Digital signal processing]]
* [[Dimension reduction]]
* [[Fixed-radius near neighbors]]
* [[Fourier analysis]]
* [[Instance-based learning]]
* [[k-nearest neighbor algorithm|''k''-nearest neighbor algorithm]]
* [[Linear least squares (mathematics)|Linear least squares]]
* [[Locality sensitive hashing]]
* [[MinHash]]
* [[Multidimensional analysis]]
* [[Nearest-neighbor interpolation]]
* [[Neighbor joining]]
* [[Principal component analysis]]
* [[Range search]]
* [[Set cover problem]]
* [[Similarity learning]]
* [[Singular value decomposition]]
* [[Sparse distributed memory]]
* [[Statistical distance]]
* [[Time series]]
* [[Voronoi diagram]]
* [[Wavelet]]

{{div col end}}

== Open source implementations ==
* [[Accord.NET]] has C# implementation of KNN classifier
* [[ALGLIB]] has C# and C++ implementations of nearest neighbor and approximate nearest neighbor algorithms
* [https://www.cs.umd.edu/~mount/ANN/ ANN] library (LGPL license) implements exact and approximate NN search in C++
* [https://github.com/spotify/annoy Annoy] (Apache license) is an implementation in C++ with Python binding from [[Spotify]]
* [https://falconn-lib.org/ FALCONN] (MIT license) is an LSH-based implementation in C++ with a Python wrapper
* [https://www.cs.ubc.ca/research/flann/ FLANN] library (BSD license) implements special fast approximate NN algorithms for high-dimensional problems
* [http://www.cgal.org/Pkg/SpatialSearchingD dD Spatial Searching] in [[CGAL]] – the Computational Geometry Algorithms Library
* [https://github.com/searchivarius/NonMetricSpaceLib Non-Metric Space Library] – An open source similarity search library containing realisations of various Nearest neighbor search methods.

== References ==
=== Citations ===
{{Reflist}}

=== Sources ===
* {{cite journal |last= Andrews |first=L. |title= A template for the nearest neighbor problem |journal = C/C++ Users Journal |volume=19 |number=11 |date= November 2001 |pages=40–49 |issn = 1075-2838 |url = http://www.ddj.com/architect/184401449}}
* {{cite journal |last1=Arya|first1=S. |first2=D.M. |last2=Mount|author2-link=David Mount |first3=N. S. |last3=Netanyahu|author3-link=Nathan Netanyahu |first4=R. |last4=Silverman|author4-link=Ruth Silverman |first5=A. Y. |last5=Wu|author5-link=Angela Y. Wu |title = An Optimal Algorithm for Approximate Nearest Neighbor Searching in Fixed Dimensions |journal= Journal of the ACM |volume = 45 |number=6 |pages= 891–923 |doi=10.1145/293347.293348|year=1998 |citeseerx=10.1.1.15.3125 }}
* {{cite journal |last1=Beyer |first1=K. |last2= Goldstein |first2=J. |last3= Ramakrishnan |first3=R. |last4=Shaft |first4=U. |year = 1999 |title=When is nearest neighbor meaningful? |journal=Proceedings of the 7th ICDT }}
* {{cite journal |first1=Chung-Min |last1= Chen |first2=Yibei |last2=Ling|title=A Sampling-Based Estimator for Top-k Query |journal=ICDE |date=2002 |pages = 617–627 }}
* {{cite book |last=Samet |first=H.|authorlink=Hanan Samet |year = 2006 |title= Foundations of Multidimensional and Metric Data Structures |publisher= Morgan Kaufmann |isbn = 978-0-12-369446-1 }}
* {{cite book |last1=Zezula |first1=P. |last2= Amato |first2=G. |last3=Dohnal |first3=V. |last4=Batko |first4=M. |title= Similarity Search – The Metric Space Approach|publisher=Springer |year=2006 |isbn = 978-0-387-29146-8 }}

==Further reading==
* {{cite book | last = Shasha | first = Dennis | title = High Performance Discovery in Time Series | publisher = Springer | location = Berlin | year = 2004 | isbn = 978-0-387-00857-8 }}

==External links==
{{commons category|Nearest neighbours search}}
* [http://simsearch.yury.name/tutorial.html Nearest Neighbors and Similarity Search] – a website dedicated to educational materials, software, literature, researchers, open problems and events related to NN searching. Maintained by Yury Lifshits
* [http://sswiki.tierra-aoi.net Similarity Search Wiki] – a collection of links, people, ideas, keywords, papers, slides, code and data sets on nearest neighbours

{{DEFAULTSORT:Nearest Neighbor Search}}
[[Category:Approximation algorithms]]
[[Category:Classification algorithms]]
[[Category:Data mining]]
[[Category:Discrete geometry]]
[[Category:Geometric algorithms]]
[[Category:Machine learning]]
[[Category:Mathematical optimization]]
[[Category:Search algorithms]]</text>
      <sha1>1z9r7ha51qvxfdqqb5z2dlkyy60ipnn</sha1>
    </revision>
  </page>
  <page>
    <title>Network theory in risk assessment</title>
    <ns>0</ns>
    <id>33572770</id>
    <revision>
      <id>787323857</id>
      <parentid>762373747</parentid>
      <timestamp>2017-06-24T19:08:06Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic_links|magic links]] with templates per [[Special:PermaLink/772743896#Future_of_magic_links|local RfC]] - [[User:PrimeBOT/13|BRFA]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19469">A '''network''' is an abstract structure capturing only the basics of connection patterns and little else. Because it is a generalized pattern, tools developed for analyzing, [[Mathematical model|modeling]] and understanding networks can theoretically be implemented across disciplines. As long as a system can be represented by a network, there is an extensive set of tools – [[Mathematics#Applied mathematics|mathematical]], [[computation]]al, and [[Statistics#Statistical methods|statistical]] – that are well-developed and if understood can be applied to the analysis of the system of interest. 
[[File:"Bow-tie" diagram of components in a directed network SVG.svg|thumb|Figure 1: A "bow-tie" diagram of components in a directed network]]

Tools that are currently employed in [[risk assessment]] are often sufficient, but model complexity and limitations of computational power can tether risk assessors to involve more causal connections and account for more '''[[black swan theory|Black Swan]]''' event outcomes. By applying [[network theory]] tools to risk assessment, computational limitations may be overcome and result in broader coverage of events with a narrowed range of uncertainties.&lt;ref&gt;Newman, Mark E. J. ''Networks: an Introduction''. Oxford: Oxford UP, 2010. p.2&lt;/ref&gt;

Decision-making processes are not incorporated into routine risk assessments; however, they play a critical role in such processes.&lt;ref&gt;National Research Council (NRC). ''Red Book Paradigm''.  Risk Assessment in the Federal Government: Understanding the Process. Washington D.C.: National Academy Press, 1983.&lt;/ref&gt; It is therefore very important for risk assessors to minimize [[confirmation bias]] by carrying out their analysis and publishing their results with minimal involvement of external factors such as politics, media, and advocates. In reality, however, it is nearly impossible to break the [[Iron triangle (US politics)|iron triangle]] among politicians, scientists (in this case, risk assessors), and advocates and media.&lt;ref&gt;Pielke Jr., Roger A. ''Policy, Politics and Perspective.'' Nature 416 (2002): 367-68.&lt;/ref&gt; Risk assessors need to be sensitive to the difference between risk studies and risk perceptions.&lt;ref&gt;Slovic, Paul. ''Perception of Risk.'' Science 236 (1987): 280-85.&lt;/ref&gt;&lt;ref&gt;National Research Council (NRC). ''Orange Book Paradigm''.  Understanding Risk: Informing Decisions in a Democratic Society. Washington D.C.: National Academy Press, 1996.&lt;/ref&gt; One way to bring the two closer is to provide decision-makers with data they can easily rely on and understand. Employing networks in the risk analysis process can visualize causal relationships and identify heavily-weighted or important contributors to the probability of the critical event.&lt;ref&gt;Rausand, Marvin. ''Risk Assessment: Theory, Methods, and Applications''. Hoboken, NJ: John Wiley &amp; Sons, 2011. p.295.&lt;/ref&gt;

A "bow-tie" diagram, cause-and-effect diagram, [[Bayesian network]] (a ''directed acyclic'' network) and [[fault trees]] are few examples of how network theories can be applied in risk assessment.&lt;ref&gt;Rausand, Marvin. ''Risk Assessment: Theory, Methods, and Applications''. Hoboken, NJ: John Wiley &amp; Sons, 2011. p.266-302.&lt;/ref&gt;

In epidemiology risk assessments (Figure 7 and 9), once a network model was constructed, we can visually see then quantify and evaluate the potential exposure or infection risk of people related to the well-connected patients (Patient 1, 6, 35, 130 and 127 in Figure 7) or high-traffic places (Hotel M in Figure 9). In ecological risk assessments (Figure 8), through a network model we can identify the [[keystone species]] and determine how widespread the impacts will extend from the potential hazards being investigated.

==Risk assessment key components==
{{Main|Risk assessment}}
[[File:Risk Analysis, evaluation, assesment, and management.jpg|thumb|Figure 2: Risk Analysis, evaluation, assessment, and management]]
Risk assessment is a method for dealing with uncertainty. For it to be beneficial to the overall risk management and decision making process, it must be able to capture extreme and catastrophic events. Risk assessment involves two parts: risk analysis and risk evaluation, although the term “''risk assessment''” can be seen used indistinguishable with “''risk analysis''”. In general, risk assessment can be divided into these steps:&lt;ref&gt;Rausand, Marvin. "Chapter 5 Risk Management." ''Risk Assessment: Theory, Methods, and Applications''. Hoboken, NJ: John Wiley &amp; Sons, 2011. p.117-36.&lt;/ref&gt;

# Plan and prepare the risk analysis.
# Define and delimit the system and the scope of the analysis.
# Identify hazards and potential hazardous events.
# Determine causes and frequency of each hazardous event.
# Identify accident scenarios (i.e. even sequences) that may be initiated by each hazardous event.
# Select relevant and typical accident scenarios. [[File:Bow-tie diagram.jpg|thumb|Figure 3: Bow-tie diagram of risk management]]
# Determine the consequences of each accident scenario.
# Determine the frequency of each accident scenario.
# Assess the uncertainty.
# Establish and describe the risk picture.
# Report the analysis.
# Evaluate the risk against risk acceptance criteria
# Suggest and evaluate potential risk-reducing measures.

Naturally, the number of steps required varies with each assessment. It depends on the scope of the analysis and the complexity of the study object.&lt;ref&gt;Rausand, Marvin. ''Risk Assessment: Theory, Methods, and Applications''. Hoboken, NJ: John Wiley &amp; Sons, 2011. p.124.&lt;/ref&gt; Because these is always varies degrees of uncertainty involved in any risk analysis process, sensitivity and uncertainty analysis are usually carried out to mitigate the level of uncertainty and therefore improve the overall risk assessment result.

==Network theory key components==
{{Main|Network theory}}

A network is a simplified representation that reduces a system to an abstract structure. Simply put, it is a collection of points linked together by lines. Each point is known as a “[[Vertex (graph theory)|vertex]]''” (multiple: “''vertices''”) or “''nodes''”, and each line as “''edges''” or “''links''”.&lt;ref&gt;Newman, Mark E. J. ''Networks: an Introduction''. Oxford: Oxford UP, 2010. p.1&lt;/ref&gt;  Network modeling and studying have already been applied in many areas, including computer, physical, biological, ecological, logistical and social science. Through the studying of these models, we gain insights into the nature of individual components (i.e. vertices), connections or interactions between those components (i.e. edges), as well as the pattern of connections (i.e. network).

Undoubtedly, modifications of the structure (or pattern) of any given network can have a big effect on the behavior of the system it depicts. For example, connections in a social network affect how people communicate, exchange news, travel, and, less obviously, spread diseases. In order to gain better understanding of how each of these systems functions, some knowledge of the structure of the network is necessary.

===Basic terminology===
'''Small-World Effect''' {{Details|Small-world network}}
:The small-world effect is one of the most remarkable network phenomena. It describes a finding that in many (perhaps most) networks the mean path distances between vertices are surprisingly small.&lt;ref&gt;Newman, Mark E. J. ''Networks: an Introduction''. Oxford: Oxford UP, 2010. p.241&lt;/ref&gt; It has many implications in various areas of network studies. For instance, in [[social network]], one can ruminate how fast a rumor (or a contagious disease) is spread in a community. From a mathematical point of view, since path lengths in networks are typically scale as log ''n'' (where ''n'' = number of network vertices), it is only logical it remains a small number even with large complex networks.

:Another idea comes along with the [[small world effect|small-world effect]] is called ''funneling''.&lt;ref&gt;Newman, Mark E. J. ''Networks: an Introduction''. Oxford: Oxford UP, 2010. p.243&lt;/ref&gt; It was derived from a [[Small world experiment|social network experiment]] conducted by the experimental psychologist [[Stanley Milgram]] in the 1960s. In that experiment he concluded, along with the [[small world effect|small-world effect]] phenomenon, that in any given social network, there were always few that were especially well connected. These few individuals were therefore responsible for the connection between any members and the rest of the world.
  
'''Degree, Hubs, and Paths'''
[[File:A small network with both multiedges and self-edges.svg|thumb|Figure 4: A small network with both multiedges and self-edges]]
:Degree of a vertex is the number of edges connected to it. For example, on Figure 4, vertex 3 has a degree of five. Hubs are vertices in a network with a relatively higher degree. Vertex 3 again is a good example. In a social network, hubs can mean individuals with many acquaintances. In risk assessment, it can mean a hazardous event with multiple triggers (or the causal part of a bow-tie diagram). A path in a network is a route between a vertex and another across the network. From the same figure, an example of a path from vertex 1 to 6 can be 1→5→3→6.
[[File:Disconnected network.svg|thumb|left|Figure 5: A disconnected directed network with two components (shaded)]]
'''Centrality'''

:[[Centrality]] is a measure of how important (or ''central'') certain vertices are in a network. It can be measured by counting the number of edges connected to it (i.e its ''degree''). The vertices with the highest degree therefore have a high ''degree centrality''.
:''[[Centrality#Degree centrality|Degree centrality]]'' can have many implications. In a social network, a person with high degree centrality may have more influence over others, more access to information, or more opportunities than those with fewer connections. In a citation network, a paper with high degree centrality may suggest it is more influential and thus has a greater impact on its respective area of research.&lt;ref&gt;Newman, Mark E. J. ''Networks: an Introduction''. Oxford: Oxford UP, 2010. p.168&lt;/ref&gt;
[[File:ConnectedNetwork.svg|thumb|Figure 6: A connected directed network with two components (shaded)]]
:[[Eigenvector centrality]] is an extension of the concept of degree centrality, based on the fact that in many networks not all vertices have the same weight or importance. A vertex's importance in its network increases if it has more connections to important vertices. [[Eigenvector centrality]], therefore, can be view as a centrality scoring system for not just one but its neighboring vertices as well.

'''Components'''
:Subgroups, or subsets of vertices, in a disconnected network. ''Disconnected network'' means in such network, there is at least a pair of vertices that no path connecting between them at all. Vice verse is known as a ''connected network'', where all vertices within are connected by at least one path. One can therefore say a connected network has only one component.

'''Directed Networks''' 
[[File:M218a1f2.gif|thumb|Figure 7. An example of acyclic directed network in epidemiology by CDC.]]
{{main|Directed graph}}
:Networks of which each edge has a direction from one vertex to another. The edges are therefore known as ''directed edges''. Example of such network include a link from the reference section on this page which will leads you to another, but not the other way around. In terms of food web, a prey eaten by a predator is another example.
 
:Directed networks can be ''cyclic'' or ''acyclic''. A ''cyclic'' directed network is one with a closed loop of edges. An ''acyclic'' directed network does not contain such loop. Since a ''self-edge'' – an edge connecting a vertex to itself – is considered a cycle, it is therefore absent from any acyclic network.

:A [[Bayesian network]] is an example of an acyclic directed network.

'''Weighted Network'''
{{main|weighted network}}
:In reality, not all edges shares the same importance or weight (connections in a social network and keystone species in a food web, for example). A weighted network adds such element to its connections. It is widely used in genomic and systems biologic applications.

'''Trees'''
:Undirected networks with no closed loops. A ''tree'' can be part of a network but isolated as a separate component. If all parts of a network are trees, such network is called a ''forest''. An administrative body can sometime be viewed as a forest.

==Other Examples of Network Theory Application==

===Social network===
{{main|Social Network}}
Early social network studies can be traced back to the end of the nineteenth century. However well-documented studies and foundation of this field are usually attributed to a psychiatrist named Jacob Moreno. He published a book entitled ''Who Whall Survive?'' in 1934 which laid out the foundation for ''sociometry'' (later known as ''social network analysis'').

Another famous contributor to the early development of social network analysis is a perimental psychologist known as [[Stanley Milgram]]. His [[small world experiment|"small-world" experiments]] gave rise to concepts such as [[six degrees of separation]] and well-connected acquaintances (also known as "sociometric superstars"). This experiment was recently repeated by Dodds ''et al.'' by means of email messages, and the basic results were similar to Milgram's. The estimated true average path length (that is, the number of edges the email message has to pass from one unique individual to the intended targets in different countries) for the experiment was around five to seven, which is not much deviated from the original six degree of separation.&lt;ref&gt;Newman, Mark E. J. ''Networks: an Introduction''. Oxford: Oxford UP, 2010. p.54-58&lt;/ref&gt;

===Food web===
[[File:East River Valley Trophic Web.jpg|thumb|Figure 8. East River Valley Trophic Web]]
{{see also|ecological network}}

A [[food web]], or [[food chain]], is an example of directed network which describes the prey-predator relationship in a given ecosystem. Vertices in this type of network represent species, and the edges the prey-predator relationship. A collection of species may be represented by a single vertex if all members in that collection prey upon and are preyed on by the same organisms. A food web is often acyclic, with few exceptions such as adults preys on juveniles and parasitism.&lt;ref&gt;Newman, Mark E. J. “Chapter 5.3  Ecological Networks”.  ''Networks: an Introduction''. Oxford: Oxford UP, 2010. p.99-104&lt;/ref&gt;

:''Note: In the [[food web]] main article, a food web was depicted as cyclic. That is based on the flow of the carbon and energy sources in a given ecosystem. The food web described here based solely on prey-predator roles; Organisms active in the [[Carbon cycle|carbon]] and [[nitrogen cycle]]s (such as decomposers and fixers) are not considered in this description.''

===Epidemiology===
[[File:Chain of transmission among guests at Hotel M -- Hong Kong, 2003.jpg|thumb|Figure 9. Chain of transmission among guests at Hotel M -- Hong Kong, 2003]]
{{main|epidemic model}}
{{details|compartmental models in epidemiology}}

[[Epidemiology]] is closely related to social network. Contagious diseases can spread through connection networks such as work space, transportation, intimate body contacts and water system (see Figure 7 and 9). Though it only exists virtually, a computer viruses spread across internet networks are not much different from their physical counterparts. Therefore, understanding each of these network patterns can no doubt aid us in more precise prediction of the outcomes of epidemics and preparing better disease prevention protocols.

The simplest model of infection is presented as a ''SI'' (''susceptible - infected'') model. Most diseases, however, do not behave in such simple manner. Therefore, many modifications to this model were made such as the ''SIR'' (''susceptible – infected – recovered''), the ''SIS'' (the second ''S'' denotes ''reinfection'') and ''SIRS'' models. The idea of [[Latency period|latency]] is taken into accounts in models such as ''SEIR'' (where ''E'' stands for ''exposed''). The SIR model is also known as the '''Reed-Frost model'''.&lt;ref&gt;http://www.stat.columbia.edu/~regina/research/risk.pdf&lt;/ref&gt;

To factor these into an outbreak network model, one must consider the degree distributions of vertices in the giant component of the network (outbreaks in small components are isolation and die out quickly, which does not allow the outbreaks to become epidemics). Theoretically, weighted network can provide more accurate information on exposure probability of vertices but more proofs are needed. Pastor-Satorras ''et al.'' pioneered much work in this area, which began with the simplest form (the ''SI'' model) and applied to networks drawn from the configuration model.&lt;ref&gt;Newman, Mark E. J. ''Networks: an Introduction''. Oxford: Oxford UP, 2010. p.657-664&lt;/ref&gt;

The biology of how an infection causes disease in an individual is complicated and is another type of disease pattern specialists are interested in (a process known as [[pathogenesis]] which involves immunology of the host and [[virulence factor]]s of the pathogen).

==Notes==
{{reflist}}

==References==

* Dolgoarshinnykh, Regina. "Criticality in Epidemic Models". Columbia University, New York. [http://www.stat.columbia.edu/~regina/research/risk.pdf Criticality in Epidemic Models]
* Legrain, Amaury, and Tom Auwers. ''The Principal-agent Model and the Network Theory as Framework for Administrative Procedures: Social Security in Belgium.'' EGPA Conference "Public Manager under Pressure: between Politics, Professionalism and Civil Society" (2006): 1-40
* Martinez, Neo, and Dunne, Jennifer. "Foodwebs.org". Pacific Ecoinformatics and Computational Ecology Lab., 2011. [http://www.foodwebs.org foodwebs.org]
* Meyers, Lauren A., M.E.J. Newman, and Stephanie Schrag. ''Applying Network Theory to Epidemics: Control Measures for Mycoplasma Pneumoniae Outbreaks.'' Emerging Infectious Diseases 9.2 (2003): 204-10
* National Research Council (NRC). ''Risk Assessment in the Federal Government: Understanding the Process''. Washington D.C.: National Academy Press, 1983.
* National Research Council (NRC). ''Understanding Risk: Informing Decisions in a Democratic Society''. Washington D.C.: National Academy Press, 1996.
* Newman, Mark E. J. ''Networks: an Introduction.'' Oxford: Oxford UP, 2010, {{ISBN|978-0199206650}} .
* Pielke Jr., Roger A. ''Policy, Politics and Perspective''. Nature 416 (2002): 367-68.
* Rausand, Marvin. ''Risk Assessment: Theory, Methods, and Applications.'' Hoboken, NJ: John Wiley &amp; Sons, 2011.
* Rothman, Kenneth J., Sander Greenland, and Timothy L. Lash. ''Modern Epidemiology''. 3rd ed. Philadelphia: Wolters Kluwer Health/Lippincott Williams &amp; Wilkins, 2008.
* Rowland, Todd and Weisstein, Eric W. "Causal Network." From ''MathWorld''—A Wolfram Web Resource. [http://mathworld.wolfram.com/CausalNetwork.html Causal Network]
* Slovic, Paul. ''Perception of Risk''. Science 236 (1987): 280-85.
* Taleb, Nassim N. ''Errors, Robustness, and the Fourth Quadrant.'' International Journal of Forecasting 25.4 (2009): 744-59
* Wolfram, Stephen. ''A New Kind of Science''. Champaign, IL: Wolfram Media, 2002.

[[Category:Risk analysis methodologies]]
[[Category:Network theory]]</text>
      <sha1>19zbnpnq5b6qkgtoh18ylknpg8st3s1</sha1>
    </revision>
  </page>
  <page>
    <title>Numerische Mathematik</title>
    <ns>0</ns>
    <id>30666710</id>
    <revision>
      <id>812287024</id>
      <parentid>799318533</parentid>
      <timestamp>2017-11-27T02:22:14Z</timestamp>
      <contributor>
        <username>Worldbruce</username>
        <id>7329773</id>
      </contributor>
      <comment>fixed deprecated image syntax, corrected ISO abbreviation, updated impact factor, added ref</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1619">{{Infobox journal
| title = Numerische Mathematik
| cover = Numerische Mathematik.jpg
| abbreviation = Numer. Math.
| discipline = [[Numerical analysis]]
| editor = [[Franco Brezzi]], [[Tony F. Chan]], [[Michael Griebel]]
| publisher = [[Springer Science+Business Media]]
| frequency = Monthly
| history = 1959–present
| impact = 2.152
| impact-year = 2016
| website = https://www.springer.com/mathematics/numerical+and+computational+mathematics/journal/211
| link1 = http://www.springerlink.com/content/0945-3245/ 
| link1-name = Online access
| ISSN = 0029-599X
| eISSN = 0945-3245
| CODEN = NUMMA7
| LCCN = 64000635
| OCLC = 1760917
}}
'''''Numerische Mathematik''''' is a [[peer review|peer-reviewed]] [[mathematics journal]] on [[numerical analysis]]. It was established in 1959 and is published by [[Springer Science+Business Media]]. The journal is indexed by ''[[Mathematical Reviews]]'' and [[Zentralblatt MATH]]. Its 2009 [[Mathematical Citation Quotient|MCQ]] was 1.06, and its 2016 [[impact factor]] was 2.152.&lt;ref name=WoS&gt;{{cite book |year=2017 |chapter=Numerische Mathematik |title=2016 [[Journal Citation Reports]] |publisher=[[Thomson Reuters]] |edition=Science |series=[[Web of Science]] |postscript=.}}&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*{{Official|1=https://www.springer.com/mathematics/numerical+and+computational+mathematics/journal/211}}

[[Category:Mathematics journals]]
[[Category:Publications established in 1959]]
[[Category:English-language journals]]
[[Category:Springer Science+Business Media academic journals]]
[[Category:Monthly journals]]


{{math-journal-stub}}</text>
      <sha1>gk1d2s2k7hhj4mopyams77tsstqwjfo</sha1>
    </revision>
  </page>
  <page>
    <title>Object theory</title>
    <ns>0</ns>
    <id>1441528</id>
    <revision>
      <id>858506407</id>
      <parentid>853553050</parentid>
      <timestamp>2018-09-07T17:32:48Z</timestamp>
      <contributor>
        <username>Mark viking</username>
        <id>17698045</id>
      </contributor>
      <comment>Adding [[Wikipedia:Short description|short description]]: "A theory in philosophy of mathematics" ([[User:Galobtter/Shortdesc helper|Shortdesc helper]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19485">{{short description|A theory in philosophy of mathematics}}
{{Distinguish|Abstract object theory}}
{{For|the concept of objects in philosophy|Object (philosophy)}}
'''Object theory''' is a theory in [[philosophy]] and [[mathematical logic]] concerning objects and the statements that can be made about objects.{{citation needed|date=July 2012}}

In some cases "objects" can be concretely thought of as symbols and strings of symbols, here illustrated by a string of four symbols " ←←↑↓←→←↓" as composed from the 4-symbol alphabet { ←, ↑, →, ↓ } . When they are "known only through the relationships of the system [in which they appear], the system is [said to be] ''abstract'' ... what the objects are, in any respect other than how they fit into the structure, is left unspecified." (Kleene 1952:25) A further specification of the objects results in a '''model''' or '''representation''' of the abstract system, "i.e. a system of objects which satisfy the relationships of the abstract system and have some further status as well" (ibid).

A system, in its general sense, is a collection of '''objects''' O = {o&lt;sub&gt;1&lt;/sub&gt;, o&lt;sub&gt;2&lt;/sub&gt;, ... o&lt;sub&gt;n&lt;/sub&gt;, ... } and (a specification of) the '''relationship''' ''r'' or relationships r&lt;sub&gt;1&lt;/sub&gt;, r&lt;sub&gt;2&lt;/sub&gt;, ... r&lt;sub&gt;n&lt;/sub&gt; between the objects: 
: Example: Given a simple system = { { ←, ↑, →, ↓ }, '''∫''' } for a very simple relationship between the objects as signified by the symbol '''∫''' :&lt;ref&gt;Abstractly, the relationship '''∫''' is defined by the collection of ordered pairs { ( →, ↑ ), ( ↑, ← ), ( ←, ↓ ), (↓, →) }&lt;/ref&gt;
:: '''∫'''→ =&gt; ↑, '''∫'''↑ =&gt; ←, '''∫'''← =&gt; ↓, '''∫'''↓ =&gt; →

A model of this system would occur when we assign, for example the familiar natural numbers { 0, 1, 2, 3 }, to the symbols { ←, ↑, →, ↓ }, i.e. in this manner: → = 0, ↑ = 1, ← = 2, ↓ = 3 . Here, the symbol '''∫''' indicates the "successor function"  (often written as an apostrophe ' to distinguish it from +) operating on a collection of only 4 objects, thus 0' = 1, 1' = 2, 2' = 3, 3' = 0. 

:Or, we might specify that '''∫''' represents 90-degree counter-clockwise rotations of a simple object → .

== The genetic versus axiomatic method ==

The following is an example of the '''genetic''' or '''constructive'''  method of making objects in a system, the other being the '''axiomatic''' or '''postulational''' method. Kleene states that a genetic method is intended to "generate" all the objects of the system and thereby "determine the abstract structure of the system completely" and uniquely (and thus define the system '''categorically'''). If axioms rather than a genetic method is used, such axiom-sets are said to be '''categorical'''.&lt;ref&gt;Kleene 1952:26. This distinction between the constructive and axiomatic methods, and the words used to describe them, are Kleene's per his reference to Hilbert 1900.&lt;/ref&gt;

Unlike the '''∫''' example above, the following creates an unbounded number of objects. The fact that O is a set, and □ is an element of O, and ■ is an operation, must be specified at the outset; this is being done in the language of the [[metatheory]] (see below):
: Given the system ( O, □, ■ ): O = { □, ■□, ■■□, ■■■□, ■■■■□, ■■■■■□, ..., ■&lt;sup&gt;n&lt;/sup&gt;□, etc. }

== Abbreviations ==

The object ■&lt;sup&gt;n&lt;/sup&gt;□ demonstrates the use of "abbreviation", a way to simplify the denoting of objects, and consequently discussions about them, once they have been created "officially". Done correctly the definition would proceed as follows:
::: ■□ ≡ ■&lt;sup&gt;1&lt;/sup&gt;□, ■■□ ≡ ■&lt;sup&gt;2&lt;/sup&gt;□, ■■■□ ≡ ■&lt;sup&gt;3&lt;/sup&gt;□, etc, where the notions of ≡ ("defined as") and "number" are presupposed to be understood intuitively in the metatheory.

Kurt Gödel 1931 virtually constructed the entire proof of his [[incompleteness theorem]]s (actually he proved Theorem IV and sketched a proof of Theorem XI) by use of this tactic, proceeding from his axioms using substitution, concatenation and deduction of ''modus ponens'' to produce a collection of 45 "definitions" (derivations or theorems more accurately) from the axioms.

A more familiar tactic is perhaps the design of subroutines that are given names, e.g. in Excel the subroutine " =INT(A1)" that returns to the cell where it is typed (e.g. cell B1) the integer it finds in cell A1.

==Models==

A '''model''' of the above example is a left-ended [[Post–Turing machine]] tape with its fixed "head" located on the left-end square; the system's relation is equivalent to: "To the left end, tack on a new square □, right-shift the tape, then print ■ on the new square". Another model is the natural numbers as created by the "successor" function. Because the objects in the two systems e.g. ( □, ■□, ■■□, ■■■□ ... ) and (0, 0′, 0′′, 0′′′, ...) can be put into a 1-1 correspondence, the systems are said to be (simply) '''[[isomorphic]]''' (meaning "same shape"). Yet another isomorphic model is the little sequence of instructions for a [[counter machine]] e.g. "Do the following in sequence: (1) Dig a hole. (2) Into the hole, throw a pebble. (3) Go to step 2."

As long as their objects can be placed in one-to-one correspondence ("while preserving the relationships") models can be considered "equivalent" no matter how their objects are generated (e.g. genetically or axiomatically):
:"Any two simply isomorphic systems constitute representations [models] of the same abstract system, which is obtained by abstracting from either of them, i.e. by leaving out of account all relationships and properties except the ones to be considered for the abstract system." (Kleene 1935:25)

== Tacit assumptions, tacit knowledge ==

An alert reader may have noticed that writing symbols □, ■□, ■■□, ■■■□, etc. by concatenating a marked square, i.e. ■, to an existing string is different from writing the completed symbols one after another on a Turing-machine tape. Another entirely possible scenario would be to generate the symbol-strings one after another on different sections of tape e.g. after three symbols: ■■■□■■□■□□. The proof that these two possibilities are different is easy: they require different "programs". But in a sense both versions create the same objects; in the second case the objects are preserved on the tape. In the same way, if a person were to write 0, then erase it, write 1 in the same place, then erase it, write 2, erase it, ad infinitum, the person is generating the same objects as if they were writing down 0 1 2 3 ... writing one symbol after another to the right on the paper. 

Once the step has been taken to write down the symbols 3 2 1 0 one after another on a piece of paper (writing the new symbol on the left  this time), or writing ∫∫∫※∫∫※∫※※ in a similar manner, then putting them in 1-1 correspondence with the Turing-tape symbols seems obvious. Digging holes one after the other, starting with a hole at "the origin", then a hole to its left with one pebble in it, then a hole to ''its'' left with two pebbles in it, ad infinitum, raises practical questions, but in the abstract it too can be seen to be conducive to the same 1-1 correspondence.   

However, nothing in particular in the definition of genetic versus axiomatic methods clears this up—these are issues to be discussed in the metatheory. The mathematician or scientist is to be held responsible for sloppy specifications. Breger cautions that axiomatic methods are susceptible to tacit knowledge, in particular, the sort that involves "know-how of a human being" (Breger 2000:227).

== A formal system ==

In general, in mathematics a [[formal system]] or "formal theory" consists of "objects" in a structure: 
* The symbols to be concatenated (adjoined),
* The formation-rules (completely specified, i.e. formal rules of [[syntax]]) that dictate how the symbols and the assemblies of symbols are to be formed into assemblies (e.g. sequences) of symbols (called terms, formulas, sentences, propositions, theorems, etc.) so that they are in "well-formed" patterns (e.g. can a symbol be concatenated at its left end only, at its right end only, or both ends simultaneously? Can a collection of symbols be substituted for (put in place of) one or more symbols that may appear anywhere in the target symbol-string?),
* Well-formed "propositions" (called "theorems" or assertions or sentences) assembled per the formation rules,
* A few [[axiom]]s that are stated up front and may include "undefinable notions" (examples: "set", "element", "belonging" in set theory; "0" and " ' " (successor) in number theory),
* At least one rule of [[deductive inference]] (e.g. [[modus ponens]]) that allow one to pass from one or more of the axioms and/or propositions to another proposition.

== Informal theory, object theory, and metatheory ==

A [[metatheory]] exists outside the formalized object theory—the meaningless symbols and relations and (well-formed-) strings of symbols. The metatheory comments on (describes, interprets, illustrates) these meaningless objects using "intuitive" notions and "ordinary language". Like the object theory, the metatheory should be disciplined, perhaps even quasi-formal itself, but in general the interpretations of objects and rules are intuitive rather than formal. Kleene requires that the methods of a metatheory (at least for the purposes of [[metamathematics]]) be finite, conceivable, and performable; these methods cannot appeal to the [[completed infinite]]. "Proofs of existence shall give, at least implicitly, a method for constructing the object which is being proved to exist."&lt;ref&gt;This is an [[intuitionist]] requirement: It formally proscribes the use of the [[law of excluded middle]] over infinite collections (sets) of objects."&lt;/ref&gt; (p.&amp;nbsp;64)

Kleene summarizes this as follows: "In the full picture there will be three separate and distinct "theories""
:"(a) the informal theory of which the formal system constitutes a formalization
:"(b) the formal system or '''object theory''', and
:"(c) the metatheory, in which the formal system is described and studied" (p. 65)

He goes on to say that object theory (b) is not a "theory" in the conventional sense, but rather is "a system of symbols and of objects built from symbols (described from (c))". &lt;!-- This object theory (b) he calls (perhaps confusingly) a "model" of the informal theory (a).--&gt;

== Expansion of the notion of formal system ==

=== Well-formed objects ===
If a collection of objects (symbols and symbol-sequences) is to be considered "well-formed", an algorithm must exist to determine, by halting with a "yes" or "no" answer, whether or not the object is well-formed (in mathematics a '''wff''' abbreviates [[well-formed formula]]). This algorithm, in the extreme, might require (or be) a [[Turing machine]] or [[Turing completeness|Turing-equivalent]] machine that "[[parse]]s" the symbol-string as presented as "data" on its tape; before a [[universal Turing machine]] can execute an instruction on its tape, it must parse the symbols to determine the exact nature of the instruction and/or datum encoded there. In simpler cases a [[finite state machine]] or a [[pushdown automaton]] can do the job. Enderton describes the use of "trees" to determine whether or not a logic formula (in particular a string of symbols with parentheses) is well formed.&lt;ref&gt;Enderton 2002:30&lt;/ref&gt; [[Alonzo Church]] 1934&lt;ref&gt;Church 1934 reprinted in Davis 1965:88ff&lt;/ref&gt; describes the construction of "formulas" (again: sequences of symbols) as written in his λ-calculus by use of a [[Recursion|recursive]] description of how to start a formula and then build on the starting-symbol using concatenation and substitution.

Example: Church specified his λ-calculus as follows (the following is simplified version leaving out notions of free- and bound-variable). This example shows how an object theory begins with a specification of an ''object system'' of symbols and relations (in particular by use of concatenation of symbols):
 
:(1) Declare the symbols: '''{''', '''}''', '''(''', ''')''', '''λ''', '''[''', ''']''' plus an infinite number of ''variables'' '''a''', '''b''', '''c''', ..., '''x''', ...
 
:(2) Define ''formula'': a sequence of symbols

:(3) Define the notion of "well-formed formula" (wff) recursively starting with the "basis" (3.i):

:*(3.1) (basis) A variable '''x''' is a wff
:*(3.2) If '''F''' and '''X''' are wffs, then '''{F}(X)''' is a wff; if '''x''' occurs in '''F''' or '''X''' then it is said to be a variable in '''{F}(X)'''.
:*(3.3) If '''M''' is well-formed and '''x''' occurs in '''M''' then '''λx[M]''' is a wff.
  
:(4) Define various abbreviations:

:* '''{F}[X]''' abbreviates to '''F(X)''' if '''F''' is a single symbol
:* '''&lt;math&gt;{{F}[X]}[Y]&lt;/math&gt;''' abbreviates to '''{F}(X,Y)''' or '''F(X,Y)''' if '''F''' is a single symbol
:* '''λx&lt;sub&gt;1&lt;/sub&gt;λx&lt;sub&gt;2&lt;/sub&gt;[...λx&lt;sub&gt;n&lt;/sub&gt;[M]...]''' abbreviates to '''λx&lt;sub&gt;1&lt;/sub&gt;x&lt;sub&gt;2&lt;/sub&gt;...x&lt;sub&gt;n&lt;/sub&gt;•M'''
:* '''λab•a(b)''' abbreviates to '''1'''
:* '''λab•a(a(b))''' abbreviates to '''2''', etc.

:(5) Define the notion of "substitution" of formula '''N''' for variable '''x''' throughout '''M'''&lt;ref&gt;The substitution gets complicated and requires more information (e.g. definitions of "free-" and "bound-" variables and three varieties of substitution) than has been given in this brief example.&lt;/ref&gt; (Church 1936)
&lt;!-- :(6) If the system is going to start with some undefined symbols and some axioms and then create (make) objects in a (logically) deductive manner, the system must specify some relations that are [amount to] logical deduction (e.g. [[modus ponens]]). The "schemata" [??] is a Transformation rules e.g. the rules of logical deduction: Define binary and ternary relations that such as "immediate consequence of" (Godel 1931, Kleene 1952), or "conversion" (Church 1934) with respect to two or three objects a and b and c e.g. the binary operation (a, b) and the [[ternary operation]] ( (a, b), c) where (a, b) are an ordered pair of objects and c is the outcome:

Example: [[Kurt Gödel]] 1931&lt;ref&gt;Gödel 1931 reprinted in van Heijenoort 1976:601.&lt;/ref&gt; specified the following two forms of "immediate consequence of" with respect to his "objects" that he called "formulas". 
::In the following the symbol ≡ signifies "is defined as", ~ signifies the logical NOT, V signifies the logical [[inclusive-OR]] and → signifies "IF ... THEN ..." (logical implication):
: (1) Given a ≡ ( b → c ) ≡ ( ~(b) V c ) then by [[modus ponens]] i.e. b &amp; ( b → c ) → c
: then b &amp; a → c is a tautology -- true in all circumstances  
: (2) Given ''a'' is a formula with ''v'' a variable, then ''c'' is an immediate consequence when any value for v plugged into ''a(v)'', i.e. (∀v: a(v)) ≡ c --&gt;

=== Undefined (primitive) objects ===
Certain objects may be "undefined" or "primitive" and receive definition (in the terms of their behaviors) by the introduction of the [[axioms]].

In the next example, the undefined symbols will be { ※, '''ↀ''', '''∫''' }. The axioms will describe their ''behaviors''.

=== Axioms ===
Kleene observes that the axioms are made up of two sets of symbols: (i) the undefined or primitive objects and those that are previously known. In the following example, it is previously known in the following system ( O, ※, '''ↀ''', '''∫''' ) that O constitutes a set of objects (the "domain"), ※ is an object in the domain, '''ↀ''' and '''∫''' are symbols for relations between the objects, =&gt; indicates the "IF THEN" logical operator, ε is the symbol that indicates "is an element of the set O", and "n" will be used to indicate an arbitrary element of set-of-objects O.

After (i) a definition of "string '''S'''"—an object that is a symbol ※ or concatenated symbols ※, ↀ or ∫, and (ii) a definition of "well-formed" strings -- (basis) ※ and ↀ'''S''', ∫'''S''' where '''S''' is any string, come the axioms: 
* ↀ※ =&gt; ※, in words: "IF ↀ is applied to object ※ THEN object ※ results."
* ∫n ε O, in words "IF ∫ is applied to arbitrary object "n" in O THEN this object ∫n is an element of O".
* ↀn ε O, "IF ↀ is applied to arbitrary object "n" in O THEN this object ↀn is an element of O".
* ↀ∫n =&gt; n, "IF ↀ is applied to object ∫n THEN object n results."
* ∫ↀn =&gt; n, "IF ∫ is applied to object ↀn THEN object n results."

So what might be '''the (intended) interpretation'''&lt;ref&gt;Kleene defines '''the intended interpretation''' as "the meanings which are intended to be attached to the symbols, formulas, etc. of a given formal system, in consideration of the system as a formalization of an informal theory....(p. 64)&lt;/ref&gt; of these symbols, definitions, and axioms?

If we define ※ as "0", ∫ as "successor", and ↀ as "predecessor" then ↀ※ =&gt; ※ indicates "proper subtraction" (sometimes designated by the symbol ∸, where "predecessor" subtracts a unit from a number, thus 0 ∸1 = 0). The string " ↀ∫n =&gt; n " indicates that if first the successor is applied to an arbitrary object n and then the predecessor ↀ is applied to ∫n, the original n results." 

Is this set of axioms "adequate"? The proper answer would be a question: "Adequate to describe what, in particular?" "The axioms determine to which systems, defined from outside the theory, the theory applies." (Kleene 1952:27). In other words, the axioms may be sufficient for one system but not for another.

In fact, it is easy to see that this axiom set is not a very good one—in fact, it is [[inconsistent]] (that is, it yields inconsistent outcomes, no matter what its interpretation):
: Example: Define ※ as 0, ∫※ as 1, and ↀ1 = 0. From the first axiom, ↀ※ = 0, so ∫ↀ※ = ∫0 = 1. But the last axiom specifies that for any arbitrary n including ※ = 0, ∫ↀn =&gt; n, so this axiom stipulates that ∫ↀ0 =&gt; 0, not 1.

Observe also that the axiom set does not specify that ∫n ≠ n. Or, excepting the case n = ※, ↀn ≠ n. If we were to include these two axioms we would need to describe the intuitive notions "equals" symbolized by = and not-equals symbolized by ≠.

== See also ==
*[[Metatheory]]
*[[Object language]]

== Footnotes ==
&lt;references/&gt;

== References ==
*Herbert Breger 2000, ''Tacit Knowledge and Mathematical Progress'', in E. Groshoz and H. Breger (eds.) 2000, ''The Growth of Mathematical Knowledge, 221-230. Kluwer Academic Publishers. Dordrecht, Netherlands. {{ISBN|0-7923-6151-2}}
*[[Alonzo Church]] 1936 ''An Unsolvable Problem of Elementary Number Theory'', reprinted in [[Martin Davis]] 1965, ''The Undecidable'', Raven Press, NY. No ISBN.
*Herbert B. Enderton 2001, ''A Mathematical Introduction to Logic: Second Edition'', Harcort Academic Press, Burlington MA. {{ISBN|978-0-12-238452-3}}.
*[[Stephen C. Kleene]] 1952, 6th reprint 1971, 10th impression 1991, ''Introduction to Metamathematics'', North-Holland Publishing Company, Amsterdam NY, {{ISBN|0-7204-2103-9}}.

==External links==
*[http://mally.stanford.edu/theory.html The Theory of Abstract Objects] at the Stanford Metaphysical Research Lab.

{{DEFAULTSORT:Object Theory}}
[[Category:Metalogic]]
[[Category:Theories of deduction]]</text>
      <sha1>inmk6gdaat3ec5ex1axht6yc4o3sbih</sha1>
    </revision>
  </page>
  <page>
    <title>Paul Jean Joseph Barbarin</title>
    <ns>0</ns>
    <id>56352872</id>
    <revision>
      <id>823044475</id>
      <parentid>822360839</parentid>
      <timestamp>2018-01-29T23:34:21Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7790">'''Paul Jean Joseph Barbarin''' (20 October 1855, [[Tarbes]] – 28 September 1931) was a French mathematician, specializing in geometry.&lt;ref name=Halsted&gt;{{cite journal|author=Halsted, G. B.|title=Biographical Sketch of Paul Barbarin|journal=The American Mathematical Monthly|date=November 1908|volume=15|issue=11|pages=195–196|url=https://books.google.com/books?id=MIvxAAAAMAAJ&amp;pg=PA195}}&lt;/ref&gt;&lt;ref name=BAMS&gt;{{cite journal|title=Notes|journal=Bulletin of the American Mathematical Society|year=1932|volume=38|pages=481–485|doi=10.1090/S0002-9904-1932-05456-8}} (See p. 484.)&lt;/ref&gt;

==Education and career==
Barbarin studied mathematics for a brief time at the [[École Polytechnique]] but changed, at the age of 19{{frac|2}}, to the [[École Normale Supérieure]], where he studied mathematics under Briot, Bouquet, Tannery, and Darboux. After graduation, Barbarin became a professor of mathematics at the Lyceum of [[Nice]] and then at the School of St.-Cyr of the Lyceum of Toulon. In 1891 he became a professor at the Lyceum of Bordeaux, where he taught for many years.&lt;ref name=Halsted/&gt; At the time of his death he was a professor at the [[École Spéciale des Travaux Publics]] in Paris.&lt;ref name=BAMS/&gt;

In 1903 the Kazan Physical and Mathematical Society of [[Kazan State University]] awarded the [[Lobachevsky Prize]] to [[David Hilbert|Hilbert]] but the Society cited Barbarin as the second choice among the nominees considered.&lt;ref name=Halsted/&gt; When Hilbert received the Society's award, [[Henri Poincaré]] contributed a report on the work of Hilbert, and Professor Mansion of Ghent contributed a report on the work of Barbarin. In a 1904 article published in the journal ''Science'', [[G. B. Halsted]] gave an English summary of the two French reports.&lt;ref&gt;{{cite journal|author=Halsted, G. B.|title=The Lobachevsky Prize|journal=Science|date=16 September 1904|volume=20|issue=507|pages=353–367|url=https://books.google.com/books?id=1JMCAAAAYAAJ&amp;pg=PA353}} (report on Barbarin's work, pp. 363–367)&lt;/ref&gt;

Athanase Papadopoulos edited and translated Lobachevsky's ''Pangéométrie ou Précis de géométrie fondée sur une théorie générale et rigoureuse des parallèles'' (''Pangeometry'') and provided a footnote concerning Barbarin:&lt;ref&gt;{{cite book|author=Lobachevsky, Nikolai I.|title=Pangeometry|year=2010|publisher=European Mathematical Society|isbn=978-3-03719-087-6|page=288|url=https://books.google.com/books?id=p15epMkyx0UC&amp;pg=PA288|postscript=; translated and edited by Athanase Papadopoulos}}&lt;/ref&gt;

{{blockquote|P. Barbarin, ''La géométrie non euclidienne'' ... This is an excellent introductory textbook on hyperbolic geometry, although it presents some of the results without complete proofs. The book also contains interesting historical remarks. The third edition of the book (1928) contains supplementary chapters by [[Adolphe Buhl|A. Buhl]] on the relation between non-Euclidean geometry and physics. ... Barbarin was a high-school teacher in Bordeaux. We owe him several results on hyperbolic geometry, in particular, the first complete classification of conics and quadrics in the non-Euclidean plane, and new formulae for volumes of tetrahedra.}}

Barbarin was an Invited Speaker of the [[International Congress of Mathematicians|ICM]] in 1928 in Bologna.

==Selected publications==
===Articles===
*[https://eudml.org/doc/99474 "Note sur le planimètre polaire."] Nouvelles annales de mathématiques: journal des candidats aux écoles polytechnique et normale 19 (1880): 212–215.
*[https://eudml.org/doc/99695 "Note sur les coordonnées bipolaires."] Nouvelles annales de mathématiques: journal des candidats aux écoles polytechnique et normale 1 (1882): 15–28.
*''Sur le droite de Simson.'' Mathesis 2 (1882) [https://babel.hathitrust.org/cgi/pt?id=uc1.b3976416;view=1up;seq=110 Part I], 106–108, [https://babel.hathitrust.org/cgi/pt?id=uc1.b3976416;view=1up;seq=126 Part II], 122–129. (See [[Robert Simson]].)
*[https://eudml.org/doc/100105 ''Note sur l'herpolhodie.''] Nouvelles annales de mathématiques: journal des candidats aux écoles polytechnique et normale 4 (1885): 538–556.
*[https://books.google.com/books?id=ow5PAAAAYAAJ&amp;pg=PA89 ''Systèmes isogonaux du triangle.''] Association française pour l'avancement des sciences 2 (1896) 89–105.
*[https://babel.hathitrust.org/cgi/pt?id=uc1.b3976430;view=1up;seq=145 ''Triangles dont les bissectrices ont des longueurs données.''] Mathesis 16 (1896) 143–150.
*[https://babel.hathitrust.org/cgi/pt?id=mdp.39015046050517;view=1up;seq=361 ''Une généralisation de théorème de Joachimstal''] Revue de mathématiques spéciales 4 (1897) 353–354. (See [[Ferdinand Joachimstal]].)
*''Constructions sphériques a la règle et au compas.'' Mathesis 19 (1899) [https://babel.hathitrust.org/cgi/pt?id=uc1.b3976433;view=1up;seq=61 Part I], 57–60, [https://babel.hathitrust.org/cgi/pt?id=uc1.b3976433;view=1up;seq=85 Part II], 81–85.
*[https://babel.hathitrust.org/cgi/pt?id=uc1.b3627625;view=1up;seq=177 ''On the Utility of Studying Non-Euclidean Geometry.''] The American Mathematical Monthly 8, no. 8/9 (1901) 161–163. (trans. by G. B. Halsted)
*[https://babel.hathitrust.org/cgi/pt?id=uc1.b3976435;view=1up;seq=185 ''Le cinquième livre de la Métagéométrie''] Mathesis 21 (1901) 177–191.
*[https://babel.hathitrust.org/cgi/pt?id=uc1.b3976436;view=1up;seq=195 ''Bilatères et trilatères en Metagéométrie''] Mathesis 22 (1902) 187–193.
*[https://babel.hathitrust.org/cgi/pt?id=mdp.39015035408221;view=1up;seq=131 ''Les cosegments et les volumes en géométrie non euclidienne.''] Mémoires de la Société des sciences physiques et naturelles de Bordeaux, série 6, tome 2 (1902) 25–44.
*[https://babel.hathitrust.org/cgi/pt?id=hvd.32044102938727;view=1up;seq=175 ''Polygones réguliers sphériques et non-euclidiens.''] Le matematiche pure ed applicate 2 (1902) 137–145.
*[https://babel.hathitrust.org/cgi/pt?id=hvd.32044106221146;view=1up;seq=271 ''Calculs abrégés de sinus et cosinus circulaires ou hyperboliques''] Mémoires de la Société des sciences physiques et naturelles de Bordeaux, série 6, tome 2 (1904) 163–188.

===Books===
*{{cite book|title=Études de géométrie analytique non euclidienne|location=Bruxelles|year=1900}}
*{{cite book|title=Géométrie infinitésimal non euclidienne|location=Lisbonne|year=1901}} 
*{{cite book|title=La géométrie non euclidienne|location=Paris|year=1902|url=https://books.google.com/books/about/La_géométrie_non_euclidienne.html?id=GpMtAQAAMAAJ}}&lt;ref&gt;{{cite journal|author=Halsted, G. B.|title=Review of ''La Géométrie non-euclidienne'' par P. Barbarin|journal=The American Mathematical Monthly|year=1902|volume=9|issue=6/7|pages=153–159|url=https://babel.hathitrust.org/cgi/pt?id=uc1.b3627626;view=1up;seq=165}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=Buhl, A.|title=critique de livre: ''Géométrie non euclidienne'' par P. Barbarin|volume=série 1, tome 4|journal=L'Enseignement mathématique|year=1902|pages=223–226|url=https://babel.hathitrust.org/cgi/pt?id=mdp.39015009228266;view=1up;seq=233}}&lt;/ref&gt; {{cite book|title=deuxième édition|year=1907|url=https://catalog.hathitrust.org/Record/100104213}} {{cite book|title=troisième édition|year=1928|postscript=; notes détaillées par Adolphe Buhl}}&lt;ref&gt;{{cite journal|author=Allen, Edward Switzer|title=Three books on non-euclidean geometry|journal=Bull. Amer. Math. Soc.|volume=35|year=1929|pages=271–276|doi=10.1090/S0002-9904-1929-04726-8}}(See pp. 275–276.)&lt;/ref&gt;

==References==
{{reflist}}

{{authority control}}
{{DEFAULTSORT:Barbarin, Paul Jean Joseph}}
[[Category:1855 births]]
[[Category:1931 deaths]]
[[Category:19th-century French mathematicians]]
[[Category:20th-century French mathematicians]]
[[Category:Geometers]]</text>
      <sha1>6rn9bexwgh95evr4nep3m2ty7cmu1vw</sha1>
    </revision>
  </page>
  <page>
    <title>Picard–Lindelöf theorem</title>
    <ns>0</ns>
    <id>666177</id>
    <revision>
      <id>868050486</id>
      <parentid>867853019</parentid>
      <timestamp>2018-11-09T17:41:19Z</timestamp>
      <contributor>
        <username>Wham Bam Rock II</username>
        <id>11701950</id>
      </contributor>
      <comment>Streamlined wording</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13211">In [[mathematics]]&amp;nbsp;– specifically, in [[differential equation]]s&amp;nbsp;– the '''Picard–Lindelöf theorem''', '''Picard's existence theorem''', '''Cauchy–Lipschitz theorem''', or '''existence and [[uniqueness quantification|uniqueness]] theorem''' gives a set of conditions under which an [[initial value problem]] has a unique solution.

The theorem is named after [[Émile Picard]], [[Ernst Lindelöf]], [[Rudolf Lipschitz]] and [[Augustin-Louis Cauchy]].

Consider the [[initial value problem]]

:&lt;math&gt;y'(t)=f(t,y(t)),\qquad y(t_0)=y_0.&lt;/math&gt;

Suppose {{math|&amp;thinsp;''f''&amp;thinsp;}} is uniformly [[Lipschitz continuous]] in {{mvar|y}} (meaning the Lipschitz constant can be taken independent of {{mvar|t}}) and [[continuous function|continuous]] in {{mvar|t}}, then for some value {{math|''ε'' &gt; 0}}, there exists a unique solution {{math|''y''(''t'')}} to the initial value problem on the interval &lt;math&gt;[t_0-\varepsilon, t_0+\varepsilon]&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Coddington|Levinson|1955}}, Theorem I.3.1&lt;/ref&gt;

== Proof sketch ==
The proof relies on transforming the differential equation, and applying fixed-point theory. By integrating both sides, any function satisfying the differential equation must also satisfy the integral equation

:&lt;math&gt; y(t) - y(t_0) = \int_{t_0}^t f(s,y(s)) \, ds. &lt;/math&gt;

A simple [[Mathematical proof|proof]] of existence of the solution is obtained by successive approximations. In this context, the method is known as [[Picard iteration]].

Set

:&lt;math&gt;\varphi_0(t)=y_0&lt;/math&gt;

and

:&lt;math&gt;\varphi_{k+1}(t)=y_0+\int_{t_0}^t f(s,\varphi_k(s))\,ds.&lt;/math&gt;

It can then be shown, by using the [[Banach fixed point theorem]], that the sequence of "Picard iterates" {{math|''φ&lt;sub&gt;k&lt;/sub&gt;''}} is [[Limit of a sequence|convergent]] and that the [[Limit (mathematics)|limit]] is a solution to the problem. An application of [[Grönwall's lemma]] to {{math|{{!}}''φ''(''t'') − ''ψ''(''t''){{!}}}}, where {{mvar|φ}} and {{mvar|ψ}} are two solutions, shows that {{math|''φ''(''t'') {{=}} ''ψ''(''t'')}}, thus proving the global uniqueness (the local uniqueness is a consequence of the uniqueness of the Banach fixed point).

== Example ==
Let &lt;math&gt;y(t) = \tan(t)&lt;/math&gt; and &lt;math&gt;t_0=0&lt;/math&gt;, so &lt;math&gt;y'=1+y^2, \ y_0 = 0, \ \varphi_0(t)=0, \ \varphi_{k+1}(t)=\int_0^t (1+(\varphi_k(s))^2)\,ds&lt;/math&gt; and &lt;math&gt; \varphi_n(t) \to y(t)&lt;/math&gt;

&lt;math&gt;\varphi_1(t)=\int_0^t (1+0^2)\,ds = t&lt;/math&gt;

&lt;math&gt;\varphi_2(t)=\int_0^t (1+t^2)\,ds = t + \frac{t^3}{3}&lt;/math&gt;

&lt;math&gt;\varphi_3(t)=\int_0^t (1+(t + \frac{t^3}{3})^2)\,ds = t + \frac{t^3}{3} + \frac{2t^5}{15} + \frac{t^7}{63}&lt;/math&gt;

and so on

This is calculating the series expansion of &lt;math&gt;\tan&lt;/math&gt;, an alternative method is to use Bernoulli's numbers

== Intuitive understanding of the theorem ==
The idea behind the theorem is the following.&lt;ref&gt;{{cite book |first=V. I. |last=Arnold |authorlink=Vladimir Arnold |title=Ordinary Differential Equations |publisher=The MIT Press |year=1978 |isbn=0-262-51018-9 }}&lt;/ref&gt; A differential equation can possess a stationary point. For example, for the equation {{math|{{sfrac|''dy''|''dt''}} {{=}} ''ay''}} the stationary solution is {{math|''y''(''t'') {{=}} 0}}, which is obtained for the initial condition {{math|''y''(0) {{=}} 0}}. Beginning with another initial condition {{math|''y''(0) {{=}} ''y''&lt;sub&gt;0&lt;/sub&gt; ≠ 0}}, the stationary solution is reached after an infinite time and therefore the uniqueness of solution is guaranteed. However, if the stationary solution is reached after a ''finite'' time, the uniqueness is violated. This happens for example for the equation {{math|{{sfrac|''dy''|''dt''}} {{=}} ''ay''&lt;sup&gt;&amp;thinsp;{{sfrac|2|3}}&lt;/sup&gt;}}, the solution corresponding to the initial condition {{math|''y''(0) {{=}} 0}} can be either {{math|''y''(''t'') {{=}} 0}} or

:&lt;math&gt;y(t)=\begin{cases} \left (\tfrac{at}{3} \right )^{3} &amp; t&lt;0\\ 0 &amp; t \ge 0 \end{cases}&lt;/math&gt;

One can note that the function {{math|&amp;thinsp;''f''&amp;thinsp;(''y'') {{=}} ''y''&lt;sup&gt;&amp;thinsp;{{sfrac|2|3}}&lt;/sup&gt;}} has an infinite slope at {{math|''y'' {{=}} 0}} and therefore is  not Lipschitz continuous. The Lipschitz continuity condition rules  out this type of differential equation.

==Detailed proof==
Let

:&lt;math&gt;C_{a,b}=\overline{I_a(t_0)}\times\overline{B_b(y_0)}&lt;/math&gt;

where:

:&lt;math&gt;\begin{align}
\overline{I_a(t_0)}&amp;=[t_0-a,t_0+a] \\
\overline{B_b(y_0)}&amp;=[y_0-b,y_0+b].
\end{align}&lt;/math&gt;

This is  the compact cylinder where {{math|&amp;thinsp;''f''&amp;thinsp;}} is defined. Let

:&lt;math&gt;M=\sup_{C_{a,b}}\|f\|,&lt;/math&gt;

this is, the maximum slope of the function in modulus. Finally, let ''L'' be the Lipschitz constant of {{math|&amp;thinsp;''f''&amp;thinsp;}} with respect to the second variable.

We will proceed to apply [[Banach fixed point theorem]] using the metric on &lt;math&gt;\mathcal{C}(I_{a}(t_0),B_b(y_0))&lt;/math&gt; induced by the uniform norm

:&lt;math&gt;\| \varphi \|_\infty = \sup_{t \in I_a} | \varphi(t)|.&lt;/math&gt;

We define an operator between two functional spaces of continuous functions, Picard's operator, as follows:

:&lt;math&gt;\Gamma:\mathcal{C}(I_{a}(t_0),B_b(y_0)) \longrightarrow \mathcal{C}(I_{a}(t_0),B_b(y_0))&lt;/math&gt;

defined by:

:&lt;math&gt;\Gamma \varphi(t) = y_0 + \int_{t_0}^{t} f(s,\varphi(s)) \, ds.&lt;/math&gt;

We must show that this operator maps a complete non-empty metric space X into itself and also is a [[contraction mapping]].

We first show that, given certain restrictions on &lt;math&gt;a&lt;/math&gt;, &lt;math&gt;\Gamma&lt;/math&gt; takes &lt;math&gt;\overline{B_\epsilon(y_0)}&lt;/math&gt; into itself in the space of continuous functions with uniform norm. Here, &lt;math&gt;\overline{B_\epsilon(y_0)}&lt;/math&gt; is a closed ball in the space of continuous (and bounded) functions "centered" at the constant function &lt;math&gt;y_0&lt;/math&gt;. Hence we need to show that 

:&lt;math&gt;\| \varphi_1 \|_\infty \le b.&lt;/math&gt;
implies

:&lt;math&gt;\left \| \Gamma\varphi(t)-y_0 \right \|=\left \|\int_{t_0}^t f(s,\varphi(s)) \, ds \right \|\leq \int_{t_0}^{t'} \left \|f(s,\varphi(s))\right \| ds \leq M \left |t'-t_0 \right|\leq M a\leq b&lt;/math&gt;
where &lt;math&gt;t'&lt;/math&gt; is some number in &lt;math&gt;[t_0-a, t_0 +a]&lt;/math&gt; where the maximum is achieved. 
The last step is true if we impose the requirement {{math|''a'' &lt; {{sfrac|''b''|''M''}}}}.

Now let's try to prove that this operator is a contraction.

Given two functions &lt;math&gt;\varphi_1,\varphi_2\in\mathcal{C}(I_{a}(t_0),B_b(y_0))&lt;/math&gt;, in order to apply the [[Banach fixed point theorem]] we want

:&lt;math&gt; \left \| \Gamma \varphi_1 - \Gamma \varphi_2 \right\|_\infty \le q  \left\| \varphi_1 - \varphi_2 \right\|_\infty,&lt;/math&gt;

for some ''q'' &lt; 1. So let ''t'' be such that

:&lt;math&gt;\| \Gamma \varphi_1 - \Gamma \varphi_2 \|_\infty =  \left \| \left (\Gamma\varphi_1 - \Gamma\varphi_2 \right )(t) \right \|&lt;/math&gt;

then using the definition of Γ

:&lt;math&gt;\begin{align}
 \left \|\left (\Gamma\varphi_1 - \Gamma\varphi_2 \right )(t) \right \| &amp;= \left \|\int_{t_0}^t \left ( f(s,\varphi_1(s))-f(s,\varphi_2(s)) \right )ds \right \|\\
&amp;\leq \int_{t_0}^t \left \|f \left (s,\varphi_1(s)\right )-f\left (s,\varphi_2(s) \right ) \right \| ds  \\
&amp;\leq L \int_{t_0}^t \left \|\varphi_1(s)-\varphi_2(s) \right \|ds  &amp;&amp; f \text{ is Lipschitz-continuous} \\
&amp;\leq L a \left \|\varphi_1-\varphi_2 \right \|_\infty
\end{align}&lt;/math&gt;

This is a contraction if {{math|''a'' &lt; {{sfrac|1|''L''}}}}.

We have established that the Picard's operator is a contraction on the Banach spaces with the metric induced by the uniform norm. This allows us to apply  the Banach fixed point theorem to conclude that the operator has a unique fixed point. In particular, there is a unique function

:&lt;math&gt;\varphi\in \mathcal{C}(I_a (t_0),B_b(y_0))&lt;/math&gt;

such that {{math|Γ''φ'' {{=}} ''φ''}}. This function is the unique solution of the initial value problem, valid on the interval ''I&lt;sub&gt;a&lt;/sub&gt;'' where ''a'' satisfies the condition 
:&lt;math&gt;a &lt; \min\{ b/M,1/L\}.&lt;/math&gt;

==Optimization of the solution's interval==
Nevertheless, there is a corollary of the Banach fixed point theorem that states that if an operator ''T&lt;sup&gt;n&lt;/sup&gt;'' is a contraction for some ''n'' in '''N''' then ''T'' has a unique fixed point. We will try to apply this theorem to the Picard's operator. But before doing that, let us recall a lemma that will be very useful to apply the aforementioned corollary.

&lt;blockquote&gt;
'''Lemma:'''&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;math&gt;\left \| \Gamma^m \varphi_1 - \Gamma^m\varphi_2 \right \| \leq \frac{L^m\alpha^m}{m!}\left \|\varphi_1-\varphi_2\right \|&lt;/math&gt;
&lt;/blockquote&gt;

''Proof.'' We will prove this by induction. For the base of the induction {{math|(''m'' {{=}} 1)}} we have already seen this, so suppose the inequality holds for {{math|''m'' − 1}}, then we have: 

: &lt;math&gt;\begin{align}
\left \| \Gamma^m \varphi_1 - \Gamma^m\varphi_2 \right \| &amp;= \left \|\Gamma\Gamma^{m-1} \varphi_1 - \Gamma\Gamma^{m-1}\varphi_2 \right \| \\
&amp;\leq \left| \int_{t_0}^t \left \| f \left (s,\Gamma^{m-1}\varphi_1(s) \right )-f \left (s,\Gamma^{m-1}\varphi_2(s) \right )\right \| ds \right| \\
&amp;\leq L \left| \int_{t_0}^t  \left \|\Gamma^{m-1}\varphi_1(s)-\Gamma^{m-1}\varphi_2(s)\right \| ds\right| \\
&amp;\leq \frac{L^m\alpha^m}{m!} \left \|\varphi_1 - \varphi_2 \right \|.
\end{align}&lt;/math&gt;

Therefore, taking into account this inequality we can assure that for some ''m'' large enough, 

:&lt;math&gt;\frac{L^m\alpha^m}{m!}&lt;1,&lt;/math&gt; 

and hence Γ&lt;sup&gt;''m''&lt;/sup&gt; will be a contraction. So by the previous corollary Γ will have a unique fixed point. So, finally, we have been able to optimize the interval of the solution by taking {{math|''α'' {{=}} min{''a'', {{sfrac|''b''|''M''}}}.}}

The importance of this result is that the interval of definition of the solution does eventually not depend on the Lipschitz constant of the field, but essentially depends on the interval of definition of the field and its maximum absolute value of it.

== Other existence theorems ==
The Picard–Lindelöf theorem shows that the solution exists and that it is unique. The [[Peano existence theorem]] shows only existence, not uniqueness, but it assumes only that {{math|&amp;thinsp;''f''&amp;thinsp;}} is continuous in {{mvar|y}}, instead of Lipschitz continuous. For example, the right-hand side of the equation {{math|{{sfrac|''dy''|''dt''}} {{=}} ''y''&lt;sup&gt;&amp;thinsp;{{sfrac|1|3}}&lt;/sup&gt;}} with initial condition {{nowrap|1=''y''(0) = 0}} is continuous but not Lipschitz continuous. Indeed, rather than being unique, this equation has three families of solutions:&lt;ref&gt;{{harvtxt|Coddington|Levinson|1955}}, p. 7&lt;/ref&gt;

:&lt;math&gt;y(t) = 0, \qquad y(t) = \pm\left (\tfrac23(t-a)\right)^{\frac{3}{2}}&lt;/math&gt;, where &lt;math&gt;a&lt;/math&gt; is any nonnegative real number.

Even more general is [[Carathéodory's existence theorem]], which proves existence (in a more general sense) under weaker conditions on {{math|&amp;thinsp;''f''&amp;thinsp;}}. Although these conditions are only sufficient, there also exist necessary and sufficient conditions for the solution of an initial value problem to be unique, such as [[Hiroshi Okamura|Okamura]]'s theorem.&lt;ref&gt;{{cite book |first1=Ravi P. |last1=Agarwal |first2=V. |last2=Lakshmikantham |title=Uniqueness and Nonuniqueness Criteria for Ordinary Differential Equations |url=https://books.google.com/books?id=q4OkW4H8BCUC&amp;pg=PA159 |year=1993 |publisher=World Scientific |isbn=981-02-1357-3 |page=159 }}&lt;/ref&gt;

== See also ==
* [[Frobenius theorem (differential topology)]]
* [[Integrability conditions for differential systems]]

== Notes ==
{{Reflist}}

== References ==
* {{Cite book | last1=Coddington | first1=Earl A. |authorlink=Earl A. Coddington | last2=Levinson | first2=Norman |authorlink2=Norman Levinson | title=Theory of Ordinary Differential Equations | publisher=[[McGraw-Hill]] | location=New York | year=1955}}.
* {{cite journal |first=E. |last=Lindelöf |title=Sur l'application de la méthode des approximations successives aux équations différentielles ordinaires du premier ordre |journal=Comptes rendus hebdomadaires des séances de l'Académie des sciences |volume=116 |year=1894 |pages=454–457 |url=http://gallica.bnf.fr/ark:/12148/bpt6k3074r/f454.table }} (In that article Lindelöf discusses a generalization of an earlier approach by Picard.)
* {{cite book| last = Teschl| given = Gerald|authorlink=Gerald Teschl| title = Ordinary Differential Equations and Dynamical Systems| publisher=[[American Mathematical Society]]| place = [[Providence, Rhode Island|Providence]]| year = 2012| isbn= 978-0-8218-8328-0| url = http://www.mat.univie.ac.at/~gerald/ftp/book-ode/}}

== External links ==
* [https://www.encyclopediaofmath.org/index.php/Cauchy-Lipschitz_theorem ''Cauchy-Lipschitz theorem''] at [[Encyclopedia of Mathematics]].
* [https://web.archive.org/web/20100616152308/http://www.krellinst.org/UCES/archive/classes/CNA/dir2.6/uces2.6.html Fixed Points and the Picard Algorithm], recovered from http://www.krellinst.org/UCES/archive/classes/CNA/dir2.6/uces2.6.html.
* [http://www.math.byu.edu/~grant/courses/m634/f99/lec4.pdf Proof of the Picard–Lindelöf theorem]

{{Differential equations topics}}

{{DEFAULTSORT:Picard-Lindelof theorem}}
[[Category:Lipschitz maps]]
[[Category:Ordinary differential equations]]
[[Category:Theorems in analysis]]</text>
      <sha1>nr6ltk520k0b0f631qjer6w8gnylxpe</sha1>
    </revision>
  </page>
  <page>
    <title>Pieter Hendrik Schoute</title>
    <ns>0</ns>
    <id>6022750</id>
    <revision>
      <id>780589525</id>
      <parentid>708279662</parentid>
      <timestamp>2017-05-16T01:24:56Z</timestamp>
      <contributor>
        <username>Red Director</username>
        <id>1261736</id>
      </contributor>
      <minor/>
      <comment>v1.42 - Minor cleanup</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1441">[[File:Pieter Hendrik Schoute, 1911.jpg|thumb|Pieter Hendrik Schoute]]
'''Pieter Hendrik Schoute''' (21 January 1846, [[Wormerveer]] &amp;ndash; 18 April 1923, [[Groningen (city)|Groningen]]) was a [[Netherlands|Dutch]] [[mathematician]] known for his work on [[regular polytope]]s and [[Euclidean geometry]].

In 1886, he became member of the [[Royal Netherlands Academy of Arts and Sciences]].&lt;ref&gt;{{cite web|author= |url=http://www.dwc.knaw.nl/biografie/pmknaw/?pagetype=authorDetail&amp;aId=PE00002887 |title=Pieter Hendrik Schoute (1846 - 1913) |publisher=Royal Netherlands Academy of Arts and Sciences |date= |accessdate=30 July 2015}}&lt;/ref&gt;

==External links and references==
* {{MacTutor Biography|id=Schoute}}

== References ==
{{reflist}}

== Sources ==
* Pieter Hendrik Schoute, ''Analytical treatment of the polytopes regularly derived from the regular polytopes.'', 1911, published by J. Muller in Amsterdam, Written in English. - 82 pages

==External links==
* {{MathGenealogy|id=49650}}

{{Authority control}}

{{DEFAULTSORT:Schoute, Pieter Hendrik}}
[[Category:19th-century mathematicians]]
[[Category:20th-century Dutch mathematicians]]
[[Category:Geometers]]
[[Category:1846 births]]
[[Category:1923 deaths]]
[[Category:Members of the Royal Netherlands Academy of Arts and Sciences]]
[[Category:People from Zaanstad]]
[[Category:Delft University of Technology alumni]]


{{Netherlands-scientist-stub}}
{{Europe-mathematician-stub}}</text>
      <sha1>t9f4ppsjzfrxu550gg79s0eghvxa7oj</sha1>
    </revision>
  </page>
  <page>
    <title>RegularChains</title>
    <ns>0</ns>
    <id>29309766</id>
    <revision>
      <id>871622370</id>
      <parentid>871621183</parentid>
      <timestamp>2018-12-02T10:12:22Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>Nominated for deletion; see [[:Wikipedia:Articles for deletion/RegularChains]]. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5220">&lt;!-- Please do not remove or change this AfD message until the discussion has been closed. --&gt;
{{Article for deletion/dated|page=RegularChains|timestamp=20181202101222|year=2018|month=December|day=2|substed=yes|help=off}}
&lt;!-- Once discussion is closed, please place on talk page: {{Old AfD multi|page=RegularChains|date=2 December 2018|result='''keep'''}} --&gt;
&lt;!-- End of AfD message, feel free to edit beyond this point --&gt;
{{expert needed|date=December 2018|reason=Too technical for simple reading}}
The '''RegularChains''' package in the [[computer algebra]] software package [[Maple (software)|Maple]] is a collection of commands for solving [[systems of polynomial equations]], inequations and inequalities symbolically. This package also allows the user to manipulate and study the solutions of such systems.  

== Main Features == 
The main two commands are 'Triangularize' and 'RealTriangularize'. Each of them computes from a system of polynomials &lt;math&gt;S&lt;/math&gt; a set of simpler systems &lt;math&gt;S_1,\ldots, S_n&lt;/math&gt; such that a point is a solution of &lt;math&gt;S&lt;/math&gt; if and only if it is a solution of one of the systems &lt;math&gt;S_1,\ldots, S_n&lt;/math&gt;. Each of these simpler systems is called a [[regular chain]] in the case of Triangularize and a [[regular semi-algebraic system]] in the case of RealTriangularize. In both cases, each of these simpler systems has a triangular shape and remarkable properties. For this reason, the set &lt;math&gt;S_1,\ldots, S_n&lt;/math&gt; is called a [[triangular decomposition]] of the system &lt;math&gt;S&lt;/math&gt;.

In addition to its main functions 'Triangularize' and 'RealTriangularize', the package has six subpackages and other commands.

The 'MatrixTools' subpackage provides commands for solving linear systems of equations modulo the saturated ideal of a regular chain. Among other operations are computations of matrix inverses and lower echelon forms. These commands are considered here in a non-standard context. Indeed, the coefficients of these matrices are polynomials and the computations are performed modulo (the saturated ideal of) a regular chain. Since this latter is not required to be a prime ideal, the commands of this subpackage allows you to do linear algebra computations over non-integral domains.

The 'ConstructibleSetTools' subpackage provides a large set of commands for manipulating constructible sets. Constructible sets are the fundamental objects of [[Algebraic Geometry]], and they play there the role that ideals play in Polynomial Algebra. In broad terms, a constructible set is the solution set of a system of polynomial equations and inequations. Constructible sets appear naturally in many questions, from high-school problems to advanced research topics.

The 'SemiAlgebraicSetTools' subpackage contains a collection of commands for isolating and counting real roots of zero-dimensional semi-algebraic systems or regular chains  (that is regular chains with a finite number of complex solutions). It also offers various commands for studying the real solutions  of polynomial systems of positive dimension or with parameters. In particular, commands for real root classification, cylindrical algebraic decomposition and partial cylindrical algebraic decomposition sampling are available. Several inspection functions on semi-algebraic systems and their solution sets (namely, semi-algebraic sets) are also provided. They are intended to support the command 'RealRootClassification', 'RealTriangularize', 'LazyRealTriangularize' and 'SamplePoints'.

The 'ParametricSystemTools' subpackage provides commands for solving systems of equations that depend on parameters. Given a parametric polynomial system &lt;math&gt;F&lt;/math&gt;, this subpackage can be used to answer questions such as: for which values of the parameters does &lt;math&gt;F&lt;/math&gt; have solutions? finitely many solutions? &lt;math&gt;N&lt;/math&gt; real solutions, for a given &lt;math&gt;N&lt;/math&gt;?

The 'ChainTools' subpackage provides advanced operations on regular chains. Most of these commands allow you to inspect, construct and transform regular chains, or to check the properties of a polynomial with respect to a regular chain. Some commands operate transformations  on a set of regular chains. They can be used to analyze the results computed by the command 'Triangularize'.

The 'FastArithmeticTools' subpackage contains a collection of commands for computing with regular chains in prime characteristic using asymptotically fast algorithms. Most of the underlying polynomial arithmetic is performed at C level and relies on (multi-dimensional) Fast Fourier Transform (FFT). This imposes some constraints on the characteristic. One of the main purposes of this subpackage is to offer efficient basic routines in order to suppor the implementation of modular algorithms for computing with regular chains and algebraic numbers.

== See also ==
*[[Regular chain]]
*[[Regular semi-algebraic system]]
*[[Triangular decomposition]]
*[[Wu's method of characteristic set]]

== References ==
* Francois Lemaire and Marc Moreno-Maza and Yuzhen Xie. The RegularChains library. Maple Conference 2005.

[[Category:Equations]]
[[Category:Polynomials]]
[[Category:Computer algebra]]
[[Category:Computer algebra systems]]</text>
      <sha1>jnpmgi4d2bl1w0m2j27jx69x1tbrao1</sha1>
    </revision>
  </page>
  <page>
    <title>S. B. Rao</title>
    <ns>0</ns>
    <id>18066908</id>
    <revision>
      <id>868299134</id>
      <parentid>853886836</parentid>
      <timestamp>2018-11-11T09:09:36Z</timestamp>
      <contributor>
        <username>InTheWildWest</username>
        <id>32869866</id>
      </contributor>
      <comment>added citations and took out tag</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3336">{{Use dmy dates|date=January 2018}}
{{Use Indian English|date=January 2018}}
{{Infobox scientist
| name             = Siddani Bhaskara Rao
| image            = 
| birth_date       = 1943
| birth_place      = India
| death_date       = 
| death_place      = 
| residence        = [[Hyderabad, Andhra Pradesh|Hyderabad]]
| citizenship      = [[India]]n
| ethnicity        = 
| occupation       = Professor of Mathematics
| salary           = 
| spouse           = 
| field            = [[Graph Theory]]
| work_institution = [[Indian Statistical Institute]], &lt;br/&gt; [[University of Mumbai]], &lt;br/&gt; [[Kings College, Aberdeen]], &lt;br/&gt; [[Ohio State University]]
| alma_mater       = [[Indian Statistical Institute]]
| doctoral_advisor = [[C. R. Rao]]&lt;ref&gt;{{MathGenealogy|id=48999}}&lt;/ref&gt;
| known_for        = [[Frequency partition]], &lt;br/&gt;[[Line graphs of hypergraphs|Line graphs]], &lt;br/&gt; [[Degree sequence]]s
| prizes           = 
| website          = 
}}
'''Siddani Bhaskara Rao''' a Graph theorist is a [[Professor Emeritus]] and director of the [[Indian Statistical Institute]] (ISI), [[Calcutta]]&lt;!-- see MathSciNet --&gt;.  Rao is the first director of the [[CR Rao Advanced Institute of Mathematics, Statistics and Computer Science]].&lt;ref&gt;[http://www.crraoaimscs.org/director_message.html  S. B. Rao the director of C. R. Rao Advanced Institute of Mathematics, India]&lt;/ref&gt; S. B. Rao is known for his work on [[Line graphs of hypergraphs|line graphs]], [[frequency partition]]s and [[degree sequence]]s.&lt;ref&gt;{{Cite web|url=http://www.crraoaimscs.org/faculty/sb-rao/|title=Dr. S.B. Rao {{!}} crrao|website=www.crraoaimscs.org|language=en-US|access-date=2018-11-11}}&lt;/ref&gt;

Rao hails from [[Andhra Pradesh]] and completed his M.A. (1965) in mathematics from  [[Andhra University]].&lt;ref&gt;{{Cite web|url=http://www.crraoaimscs.org/faculty/sb-rao/|title=Dr. S.B. Rao {{!}} crrao|website=www.crraoaimscs.org|language=en-US|access-date=2018-11-11}}&lt;/ref&gt; He received his Ph.D. (1971) from the Indian Statistical Institute, [[Calcutta]] under the supervision of renowned Statistician [[CR Rao]]. After completing his Ph.D., he moved to the [[University of Mumbai]] to work with [[S. S. Shrikhande]]. At the same time, he visited [[King's College, Aberdeen]] to work with [[Crispin St. J. A. Nash-Williams]]. From the University of  Mumbai, Rao went back to the Indian Statistical Institute (ISI). While at ISI, he visited [[Ohio State University]]. Rao has guided students for their Ph.D.s in graph theory. He was the director of ISI Calcutta from 1995 to 2000. After retirement from ISI, he went to [[University of Hyderabad]] to work as the first director of the C. R. Rao Advanced Institute of Mathematics, Statistics and Computer Science, [[Hyderabad, Andhra Pradesh|Hyderabad]].&lt;ref&gt;{{Cite web|url=https://www.researchgate.net/scientific-contributions/49988972_SB_Rao|title=S.B. Rao's research works {{!}} University of Hyderabad, Hyderabad (UoH) and other places|website=ResearchGate|language=en|access-date=2018-11-11}}&lt;/ref&gt;

==References==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Rao, S. B.}}
[[Category:Living people]]
[[Category:Graph theorists]]
[[Category:1943 births]]
[[Category:Alumni of the University of Aberdeen]]
[[Category:Andhra University alumni]]
[[Category:Indian combinatorialists]]


{{India-academic-bio-stub}}</text>
      <sha1>bmzdos89qfnh3t4jw8igzzs3oky03oa</sha1>
    </revision>
  </page>
  <page>
    <title>Senior Wrangler (University of Cambridge)</title>
    <ns>0</ns>
    <id>19355609</id>
    <revision>
      <id>869436334</id>
      <parentid>869436169</parentid>
      <timestamp>2018-11-18T16:28:12Z</timestamp>
      <contributor>
        <username>Bashereyre</username>
        <id>3604604</id>
      </contributor>
      <comment>}}{{</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="66993">[[File:Senior Wrangler 1842.jpg|thumb|200px|The Senior Wrangler, achiever of "academic supremacy", is admitted to his degree, 1842]]
[[File:Mathmo results.jpg|right|thumb|200px|In accordance with tradition, results of the [[Cambridge Mathematical Tripos|Mathematical Tripos]] are thrown from the [[Senate House (University of Cambridge)|Senate House]] balcony, 2005]]

The '''Senior Wrangler''' is the top [[mathematics]] [[undergraduate]] at [[University of Cambridge|Cambridge University]] in [[England]], a position which has been described as "the greatest intellectual achievement attainable in Britain."&lt;ref name="Forfar 1996"&gt;{{cite journal |last=Forfar |first=David |title=What became of the Senior Wranglers?|journal=Mathematical Spectrum |volume=29 |issue=1 |year=1996}}&lt;/ref&gt;

Specifically, it is the person who achieves the highest overall mark among the [[Wrangler (University of Cambridge)|Wranglers]] – the [[student]]s at Cambridge who gain [[British undergraduate degree classification|first-class]] [[Academic degree|degrees]] in mathematics. The Cambridge undergraduate mathematics course, or [[Cambridge Mathematical Tripos|Mathematical Tripos]], is famously difficult.

Many Senior Wranglers have become world-leading figures in mathematics, [[physics]], and other fields. They include [[George Biddell Airy|George Airy]], [[John Herschel]], [[Arthur Cayley]], [[James Inman]], [[George Gabriel Stokes|George Stokes]], [[Isaac Todhunter]], [[Morris Birkbeck Pell|Morris Pell]], [[Lord Rayleigh]], [[Arthur Stanley Eddington|Arthur Eddington]], [[John Edensor Littlewood|J. E. Littlewood]], [[Jayant Narlikar]], [[Frank P. Ramsey|Frank Ramsey]], [[Donald Coxeter]], [[Jacob Bronowski]], [[Lee Hsien Loong]], [[Kevin Buzzard]], [[Christopher Budd (mathematician)|Christopher Budd]], [[Ben J. Green|Ben Green]], and [[John Polkinghorne]].

Senior Wranglers were once fêted with torchlit processions and took pride of place in the University's [[graduation]] [[ceremony]].&lt;ref name="Moore 2005"&gt;{{cite journal |last=Moore |first=Gregory |title=Masters of Theory and its Relevance to the History of Economic Thought|journal=History of Economics Review|volume=42 |issue=2 |year=2005 |pages=77–99}}&lt;/ref&gt; Years in Cambridge were often remembered by who had been Senior Wrangler that year.&lt;ref name="Forfar 1996"/&gt;

The annual ceremony in which the Senior Wrangler becomes known was first held in the [[18th century]]. Standing on the [[balcony]] of the University's [[Senate House (University of Cambridge)|Senate House]], the examiner reads out the [[British undergraduate degree classification|class results]] for mathematics,&lt;ref&gt;{{cite web|title=Peter Guthrie Tait|url=http://www.robertnowlan.com/pdfs/Tait,%20Peter%20Guthrie.pdf}}&lt;/ref&gt; and printed copies of the results are then thrown to the audience below. The examiner no longer announces the students' exact rankings, but they still identify the Senior Wrangler, nowadays by [[Hat tip|tipping]] their [[Square academic cap|academic hat]] when reading out the person's name.

==Others who finished in the top 12==
The difficulty of the examinations is illustrated by the identities of some of those who have performed well, but less well than the Senior Wrangler.

Those who have achieved second place, known as Second Wranglers, include [[Alfred Marshall]], [[James Clerk Maxwell]], [[J. J. Thomson]], [[Lord Kelvin]], [[William Kingdon Clifford|William Clifford]], and [[William Whewell]].

Those who have finished between third and 12th include [[Karl Pearson]] and [[William Henry Bragg]] (third), [[George Green (mathematician)|George Green]] and [[G. H. Hardy]] (fourth), [[Adam Sedgwick]] (fifth), [[John Venn]] (sixth), [[Bertrand Russell]] and [[Nevil Maskelyne]] (seventh), [[Thomas Robert Malthus|Thomas Malthus]] (ninth), and [[John Maynard Keynes]] (12th).

==History==
Between 1748 and 1909, the University publicly announced the ranking,&lt;ref name="Craik 2007"&gt;{{cite book|title=Mr Hopkins' Men|publisher=Springer London|year=2007|first=A.D.D.|last=Craik|isbn=978-1-84628-790-9|doi=10.1007/978-1-84628-791-6}}&lt;/ref&gt; which was then reported in newspapers such as ''[[The Times]]''. The examination was considered to be by far the most important in Britain and the Empire. The prestige of being a high Wrangler was great; the respect accorded to the Senior Wrangler was immense. Andrew Warwick, author of ''Masters of Theory'', describes the term 'Senior Wrangler' as "synonymous with academic supremacy".&lt;ref&gt;{{cite book |title=Masters of Theory: Cambridge and the Rise of Mathematical Physics |last=Warwick |first=Andrew |year=2003 |publisher=University Of Chicago Press |isbn=0-226-87375-7 |page=205 }}&lt;/ref&gt;

Since 1910, successful students in the examinations have been told their rankings privately, and not all Senior Wranglers have become publicly known as such. In recent years, the custom of discretion regarding ranking has progressively vanished, and all Senior Wranglers since 2010 have announced their identity publicly.

The youngest person to be Senior Wrangler is probably [[Arran Fernandez]], who came top in 2013, aged 18 years and 0 months.&lt;ref name="ReferenceA"&gt;{{cite news |title=Student, 18, youngest ever to come top in Cambridge maths finals |newspaper=[[The Daily Telegraph|Daily Telegraph]] |date= 21 June 2013}}&lt;/ref&gt; The previous youngest was probably [[James H. Wilkinson|James Wilkinson]] in 1939, aged 19 years and 9 months.&lt;ref&gt;[http://dl.acm.org/citation.cfm?id=1074920 Wilkinson, James H.] {{cite book|title=Encyclopedia of Computer Science|publisher=Springer London|year=2003|first=Sven|last=Hammarling|isbn=0-470-86412-5}}&lt;/ref&gt; The youngest up to 1909 were [[Alfred William Flux|Alfred Flux]] in 1887, aged 20 years and 2 months&lt;ref&gt;{{cite news |date=24 June 1899 |title=To the Editor of the ''Spectator'' |url=http://archive.spectator.co.uk/article/24th-june-1899/32/to-the-editor-of-the-spectator- |newspaper=[[The Spectator]] |accessdate=6 December 2013 }}&lt;/ref&gt; and [[Peter Guthrie Tait|Peter Tait]] in 1852, aged 20 years and 8 months.&lt;ref&gt;{{cite book |title=Arthur Cayley: mathematician laureate of the Victorian age |last=Crilly |first=Tony |year=2006 |publisher=Johns Hopkins University Press |location= |isbn=0-8018-8011-4 |page=160 }}&lt;/ref&gt;

Two individuals have placed first without becoming known as Senior Wrangler. One was the student [[Philippa Fawcett]] in 1890. At that time, although the University allowed women to take the examinations, it did not allow them to be members of the University, nor to receive degrees. Therefore they could not be known as 'Wranglers', and were merely told how they had performed compared to the male candidates, for example, "equal to the Third Wrangler", or "between the Seventh and Eighth Wranglers". Having gained the highest mark, Fawcett was declared to have finished "above the Senior Wrangler".

The other was the mathematics professor [[George Pólya]]. As he had contributed to reforming the Tripos with the aim that an excellent performance would be less dependent on solving hard problems and more so on showing a broad mathematical understanding and knowledge, [[G.H. Hardy]] asked Pólya to sit the examinations himself, unofficially, during his stay in England in 1924–5. Pólya did so, and to Hardy's surprise, received the highest mark, an achievement which, had he been a student, would have made him the Senior Wrangler.&lt;ref&gt;{{cite book |title=The random walks of George Pólya |first=Gerald L.| last1=Alexanderson|authorlink=Gerald L. Alexanderson|year=2000 |publisher=Cambridge University Press |location=Cambridge |page=68}}&lt;/ref&gt;

==Derived uses of the term==
Senior Wrangler's Walk is a path in Cambridge, the walk to and along which was considered to be sufficient [[walking|constitutional exercise]] for a student aspiring to become the Senior Wrangler. The route was shorter than other walks, such as Wranglers' Walk and the [[Grantchester]] Grind, undertaken by undergraduates whose aspirations were lower.&lt;ref&gt;{{cite book |title=Science incarnate: historical embodiments of natural knowledge |editor1-first=Stephen |editor1-last=Shapin |editor2-first=Christopher |editor2-last=Lawrence |year=1998 |publisher=University of Chicago Press |location=Chicago |isbn=0-226-47014-8 |page=303 }}&lt;/ref&gt;

Senior Wrangler sauce is a Cambridge term for brandy butter, a type of [[hard sauce]] made from [[brandy]], [[butter]], and [[sugar]], traditionally served in [[United Kingdom|Britain]] with [[Christmas pudding]] and warm [[mince pie]]s.&lt;ref&gt;{{cite web|title=Brandy butter|url=http://www.az-encyclopedia.info/b/511431_Brandy_butter/|archive-url=https://web.archive.org/web/20160303225616/http://www.az-encyclopedia.info/b/511431_Brandy_butter/|dead-url=yes|archive-date=2016-03-03|accessdate=2011-12-09}}&lt;/ref&gt;

Senior Wrangler is also the name of a [[solitaire]] [[card game]], alternatively known as Mathematics and Double Calculation, played with two [[Standard 52-card deck|decks]] of [[playing cards|cards]] and involving elementary [[modular arithmetic]].&lt;ref&gt;{{cite book |title=100 Games of Solitaire (Complete with layouts for playing) |last=Coops |first=Helen L |year=1939 |publisher=Whitman Publishing Company |page=205 }}&lt;/ref&gt;&lt;ref&gt;{{cite book |title=Goren's Hoyle Encyclopedia of Games: With Official Rules and Pointers on Play, Including the Latest Laws of Contract Bridge |last=Goren |first=Charles Henry |year=1961 |publisher=Greystone Press |page=643 }}&lt;/ref&gt;

== Literary references ==
Fictional Senior Wranglers appearing in [[novel]]s include Roger Hamley, a character in [[Elizabeth Gaskell]]'s ''Wives and Daughters'', and Tom Jericho, the [[cryptanalyst]] in [[Robert Harris (novelist)|Robert Harris]]'s novel ''[[Enigma (novel)|Enigma]]'', who is described as having been Senior Wrangler in 1938.

In [[George Bernard Shaw]]'s play ''[[Mrs. Warren's Profession]]'', the title character's daughter Vivie is praised for "tieing with the third wrangler," and she comments that "the mathematical tripos" means "grind, grind, grind for six to eight hours a day at mathematics, and nothing but mathematics."

In [[Ford Madox Ford]]'s ''[[Parade's End]]'', the character [[Christopher Tietjens]] is described as having settled deliberately for only being Second Wrangler, in order to avoid the weight of expectation that the title would create.

In his [[Discworld]] series of [[novel]]s, [[Terry Pratchett]] has a character called the Senior Wrangler, a [[Faculty (teaching staff)|faculty]] member at the [[Unseen University]], whose first name is Horace.

The compiler of [[crossword]]s for ''The Leader'' in the 1930s used 'Senior Wrangler' as a [[pseudonym]].&lt;ref&gt;{{cite book |title=The Handy Crossword Companion |author="Senior Wrangler" of the Leader |year=1932 |publisher=Odhams Press }}&lt;/ref&gt;

== Coaches ==
The two most successful 19th-century coaches of Senior Wranglers were [[William Hopkins]] and [[Edward Routh]]. Hopkins, the 'Senior Wrangler Maker', who himself was the 7th Wrangler, coached 17 Senior Wranglers. Routh, who had himself been the Senior Wrangler, coached 27.&lt;ref&gt;{{cite book  |last1=Davis | first1=Ted| last2=Stuerwer| first2=Roger| first3=Rutherford (ed.)| last3=Aris |title=Springs of Scientific Creativity: Essays on Founders of Modern Science  |publisher=University of Minnesota Press|date=1983–2005|page=164}}&lt;/ref&gt;  Another, described by his student (and Senior Wrangler) [[J.E. Littlewood]] as “the last of the great coaches”, was another Senior Wrangler, [[Robert Alfred Herman]].&lt;ref&gt;{{cite book | title = A Mathematician's Miscellany | last1 = Littlewood | first1 = John Edensor | publisher = [[Methuen Publishing]] | year = 1953 | page = 70 | authorlink = J.E. Littlewood }}&lt;/ref&gt;

== Senior Wranglers and runners up, 1748–1909 ==
During 1748–1909, the top two colleges in terms of number of Senior Wranglers were [[Trinity College, Cambridge|Trinity]] and [[St John's College, Cambridge|St John's]] with 56 and 54 respectively. [[Gonville and Caius College, Cambridge|Gonville and Caius]] was third with 13.

[[File:WilliamPaley.jpg|right|upright|thumb|[[William Paley]], Senior Wrangler, 1763.]]
[[File:FrederickPollock.jpg|thumb|upright|right|[[Sir Frederick Pollock, 1st Baronet]], Senior Wrangler, 1806.]]
[[File:John Herschel by Jula Margaret Cameron, Abril 1867.jpg|thumb|upright|right|[[John Herschel]], Senior Wrangler, 1813.]]
[[File:George Biddell Airy.jpg|right|upright|thumb|[[George Biddell Airy]], Senior Wrangler, 1823.]]
[[File:George Gabriel Stokes.jpg|thumb|upright|right|[[George Gabriel Stokes]], Senior Wrangler, 1841.]]
[[File:Arthur Cayley.jpg|thumb|upright|right|[[Arthur Cayley]], Senior Wrangler, 1842.]]
[[File:John Couch Adams.jpg|thumb|upright|right|[[John Couch Adams]], Senior Wrangler, 1843.]]
[[File:Todhunter Isaac.jpg|thumb|upright|right|[[Isaac Todhunter]], Senior Wrangler, 1848.]]
[[File:Tait Peter Guthrie.jpg|thumb|upright|right|[[Peter Guthrie Tait]], who at 20 years 8 months in 1852 was younger than all previous Senior Wranglers.]]
[[File:Edward J Routh.jpg|thumb|upright|right|[[Edward Routh]], Senior Wrangler in 1854 and coach to many subsequent Senior Wranglers.]]
[[File:John William Strutt.jpg|thumb|upright|right|[[John Strutt, 3rd Baron Rayleigh]], Senior Wrangler, 1865.]]
[[File:Young Donald MacAlister.jpg|thumb|upright|right|[[Donald MacAlister]], Senior Wrangler, 1877. The postcard portrait is a sign of the fame associated with the position of Senior Wrangler.]]
[[File:Phillipafawcett.jpg|thumb|upright|right|[[Philippa Fawcett]], ranked "above the Senior Wrangler" in 1890.]]
[[File:Thomas John Bromwich.jpg|thumb|upright|right|[[Thomas John I'Anson Bromwich]], Senior Wrangler, 1895.]]
[[File:Arthur Stanley Eddington.jpg|thumb|upright|right|[[Arthur Eddington]], Senior Wrangler, 1904]]
[[File:Peter Swinnerton-Dyer.jpeg|thumb|upright|right|[[Peter Swinnerton-Dyer]], Senior Wrangler in the 1940s]]
[[File:Michael Edward Ash.jpg|thumb|upright|right|[[Michael Edward Ash]], Senior Wrangler, 1948]]
[[File:Jayant Vishnu Narlikar - Kolkata 2007-03-20 07324.jpg|thumb|upright|right|[[Jayant Narlikar]], Senior Wrangler, 1959]]
[[File:Lee Hsien-Loong - World Economic Forum Annual Meeting 2012 cropped.jpg|thumb|upright|right|[[Lee Hsien Loong]], Senior Wrangler, 1973]]
[[File:Kevin buzzard in 2007.jpg|thumb|upright|right|[[Kevin Buzzard]], Senior Wrangler, 1990]]
[[File:Ben Green.jpg|thumb|upright|right|[[Ben Joseph Green]], Senior Wrangler, 1998]]

{| class="wikitable sortable"
! Year !! Senior Wrangler(s)&lt;ref name="senwrang"&gt;{{cite book |last=Neale |first=Charles Montague |year=1907 |title= The senior wranglers of the University of Cambridge, from 1748 to 1907. With biographical, &amp; c., notes |url=https://archive.org/details/senoirwranglerso00nealrich |publisher=Groom and Son |location=Bury St. Edmunds}}&lt;/ref&gt;{{#tag:ref|In years where there was a tie, individuals tied have been shown as Senior Wrangler, with the next placed candidate(s) as Proxime Accessit; strictly speaking, if ''n'' individuals are tied as Senior Wrangler, any runner up is ''(n+1)-st'' Wrangler .|group=note}} !! College !! Proxime Accessit !! College
|-
| 1748 || {{sortname|John|Bates|John Bates (rector)}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || John Cranwell || [[Sidney Sussex College, Cambridge|Sidney Sussex]]
|-
| 1749 || {{sortname|John|Greene|John Greene (mathematician)}} || [[Corpus Christi College, Cambridge|Corpus Christi]] || Francis Coventry || [[Magdalene College, Cambridge|Magdalene]]
|-
| 1750 || {{sort|Hazeland, William|William Hazeland}} || [[St John's College, Cambridge|St John's]] || John Gooch || [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 1751 || {{sort|Hewthwaite, John|John Hewthwaite}} || [[Christ's College, Cambridge|Christ's]] || William Cardale || [[Pembroke College, Cambridge|Pembroke]]
|-
| 1752 || {{sort|Best, Henry|Henry Best}} || [[Magdalene College, Cambridge|Magdalene]] || {{sort|Cay, John|John Cay}} || [[Clare College, Cambridge|Clare]]
|-
| 1753 || {{sort|Disney, William|[[William Disney]]}} || [[Trinity College, Cambridge|Trinity]] || William Preston || [[Trinity College, Cambridge|Trinity]]
|-
| 1754 || {{sort|Abbott, William|William Abbot}} || [[St John's College, Cambridge|St John's]] || Samuel Hallifax || [[Jesus College, Cambridge|Jesus]]
|-
| 1755 || {{sort|Castley, Thomas|Thomas Castley}} || [[Jesus College, Cambridge|Jesus]] || [[John Hatsell]] || [[Queens' College, Cambridge|Queens']]
|-
| 1756 || {{sort|Webster, John|John Webster}} || [[Corpus Christi College, Cambridge|Corpus Christi]] || William Bearcroft || [[Peterhouse, Cambridge|Peterhouse]]
|-
| 1757 || {{sortname|Edward|Waring}} || [[Magdalene College, Cambridge|Magdalene]] || {{sortname|John|Jebb|John Jebb (1736–1786)}} || [[Peterhouse, Cambridge|Peterhouse]]
|-
| 1758 || {{sortname|Robert|Thorp|Robert Thorp (archdeacon)}} || [[Peterhouse, Cambridge|Peterhouse]] || {{sortname|George|Wollaston|George Wollaston}} || [[Sidney Sussex College, Cambridge|Sidney Sussex]]
|-
| 1759 || {{sort|Massey, Joshua|Joshua Massey}} || [[St John's College, Cambridge|St John's]] || {{sortname|Richard|Watson|Richard Watson (bishop)}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1760 || {{sort|Cross, George|George Cross}} || [[Clare College, Cambridge|Clare]] || Anthony Hamilton || [[Corpus Christi College, Cambridge|Corpus Christi]]
|-
| 1761 || {{sortname|John|Wilson|John Wilson (mathematician)}} || [[Peterhouse, Cambridge|Peterhouse]] || Timothy Lowten || [[St John's College, Cambridge|St John's]]
|-
| 1762 || {{sort|Haighton, Richard|Richard Haighton}} || [[Christ's College, Cambridge|Christ's]] || Jeremiah Pemberton || [[Pembroke College, Cambridge|Pembroke]]
|-
| 1763 || {{sortname|William|Paley}} || [[Christ's College, Cambridge|Christ's]] || {{sortname|John|Frere}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 1764 || {{sort|Heslop, Luke|Luke Heslop}} || [[Corpus Christi College, Cambridge|Corpus Christi]] || John Fairfax Francklin || [[Emmanuel College, Cambridge|Emmanuel]]
|-
| 1765 || {{sort|White, John| John White}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || John Clement Ives || [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 1766 || {{sort|Arnald, William|William Arnald}} || [[St John's College, Cambridge|St John's]] || [[John Law (bishop)|John Law]] || [[Christ's College, Cambridge|Christ's]]
|-
| 1767 || {{sortname|Joseph|Turner|Joseph Turner (dean)}} || [[Pembroke College, Cambridge|Pembroke]] || George Dutens || [[Queens' College, Cambridge|Queens']]
|-
| 1768 || {{sortname|Thomas|Kipling|Thomas Kipling}} || [[St John's College, Cambridge|St John's]] || George Fielding || [[Trinity College, Cambridge|Trinity]]
|-
| 1769 || {{sortname|Thomas|Parkinson|Thomas Parkinson (archdeacon)}} || [[Christ's College, Cambridge|Christ's]] || William Burslem || [[St John's College, Cambridge|St John's]]
|-
| 1770 || {{sort|Hughes, Lewis|Lewis Hughes}} || [[St John's College, Cambridge|St John's]] || {{sort|Smith, William|William Smith}} || [[St John's College, Cambridge|St John's]]
|-
| 1771 || {{sort|Starkie, Thomas|Thomas Starkie}} || [[St John's College, Cambridge|St John's]] || {{sort|Kedington, Roger|Roger Kedington}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 1772 || {{sortname|George Pretyman|Tomline}} || [[Pembroke College, Cambridge|Pembroke]] || {{sort|Stephenson, Mark Anthony|Mark Anthony Stephenson}} || [[Clare College, Cambridge|Clare]]
|-
| 1773 || {{sort|Brundish, John Jelland|John Jelland Brundish}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || {{sort|Whitmore, George|George Whitmore}} || [[St John's College, Cambridge|St John's]]
|-
| 1774 || {{sortname|Isaac|Milner}} || [[Queens' College, Cambridge|Queens']] || {{sort|Mounsey, George|George Mounsey}} || [[Peterhouse, Cambridge|Peterhouse]]
|-
| 1775 || {{sortname|Samuel|Vince}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || {{sortname|Henry William|Coulthurst}} || [[St John's College, Cambridge|St John's]]
|-
| 1776 || {{sortname|John|Oldershaw|John Oldershaw}} || [[Emmanuel College, Cambridge|Emmanuel]] || {{sortname|Gilbert|Wakefield}} || [[Jesus College, Cambridge|Jesus]]
|-
| 1777 || {{sortname|David|Owen|David Owen (judge)}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Cautley, Thomas|Thomas Cautley}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1778 || {{sortname|William|Farish|William Farish (professor)}} || [[Magdalene College, Cambridge|Magdalene]] || {{sort|Taylor, William|William Taylor}} || [[Emmanuel College, Cambridge|Emmanuel]]
|-
| 1779 || {{sortname|Thomas|Jones|Thomas Jones (mathematician)}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|Herbert|Marsh}}{{#tag:ref|Thomas Jones, the Senior Wrangler that year, acted as his tutor.|group=note}} || [[St John's College, Cambridge|St John's]]
|-
| 1780 || {{sort|Priest, St John|St John Priest}} || [[Pembroke College, Cambridge|Pembroke]] || {{sortname|William|Frend|William Frend (social reformer)}} || [[Christ's College, Cambridge|Christ's]]
|-
| 1781 || {{sortname|Henry|Ainslie}} || [[Pembroke College, Cambridge|Pembroke]] || {{sort|Ainslie, Montague Farrer|Montague Farrer Ainslie}} &amp; {{sort|Law, George Henry|George Henry Law}} || [[Trinity College, Cambridge|Trinity]] &amp; [[Queens' College, Cambridge|Queens']]
|-
| 1782 || {{sortname|James|Wood|James Wood (mathematician)}} || [[St John's College, Cambridge|St John's]] || {{sortname|John|Hailstone}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1783 || {{sortname|Francis John Hyde|Wollaston}} || [[Sidney Sussex College, Cambridge|Sidney Sussex]] || {{sort|Buck, Richard|Richard Buck}} || [[Magdalene College, Cambridge|Magdalene]]
|-
| 1784 || {{sortname|Robert Acklom|Ingram}} || [[Queens' College, Cambridge|Queens']] || {{sort|Holden, John|John Holden}} || [[Sidney Sussex College, Cambridge|Sidney Sussex]]
|-
| 1785 || {{sortname|William|Lax|William Lax}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Dudley, John|John Dudley}} || [[Clare College, Cambridge|Clare]]
|-
| 1786 || {{sortname|John|Bell|John Bell (barrister)}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Otter, Edward|Edward Otter}} || [[Jesus College, Cambridge|Jesus]]
|-
| 1787 || {{sortname|Joseph|Littledale|Joseph Littledale}} || [[St John's College, Cambridge|St John's]] || {{sort|Frampton, Algernon|Algernon Frampton}} || [[St John's College, Cambridge|St John's]]
|-
| 1788 || {{sortname|John|Brinkley|John Brinkley (astronomer)}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || {{sort|Outram, Edmund|Edmund Outram}} || [[St John's College, Cambridge|St John's]]
|-
| 1789 || {{sort|Millers, William|William Millers}} || [[St John's College, Cambridge|St John's]] || {{sort|Bewsher, Joseph|Joseph Bewsher}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1790 || {{sortname|Bewick|Bridge}} || [[Peterhouse, Cambridge|Peterhouse]] || Fletcher Raincock || [[Pembroke College, Cambridge|Pembroke]]
|-
| 1791 || {{sort|Peacock, Daniel Mitford|Daniel Mitford Peacock}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|William|Gooch|William Gooch (astronomer)}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 1792 || {{sort|Palmer, John|John Palmer}} || [[St John's College, Cambridge|St John's]] || {{sort|Tavel, George Frederick|George Frederick Tavel}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1793 || {{sort|Harrison, Thomas|Thomas Harrison}} || [[Queens' College, Cambridge|Queens']] || {{sort|Strickland, Thomas|Thomas Strickland}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1794 || {{sortname|George|Butler|George Butler (headmaster)}} || [[Sidney Sussex College, Cambridge|Sidney Sussex]] || {{sortname|John Singleton|Copley|Lord Lyndhurst}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1795 || {{sortname|Robert|Woodhouse}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || {{sort|Atthill, William|William Atthill}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 1796 || {{sortname|John|Kempthorne|John Kempthorne (hymnwriter)}} || [[St John's College, Cambridge|St John's]] || {{sort|Dealtry, William|[[William Dealtry]]}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1797 || {{sortname|John|Hudson|John Hudson (mathematician)}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Lowthian, John|John Lowthian}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1798 || {{sort|Sowerby, Thomas|Thomas Sowerby}} || [[Trinity College, Cambridge|Trinity]] || Robert Martin || [[Trinity College, Cambridge|Trinity]]
|-
| 1799 || {{sortname|William Fuller|Boteler|William Fuller Boteler}} || [[St John's College, Cambridge|St John's]] || {{sort|Brown, John|John Brown}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1800 || {{sortname|James|Inman}} || [[St John's College, Cambridge|St John's]] || {{sort|D'Oyly, George|[[George D'Oyly]]}} || [[Corpus Christi College, Cambridge|Corpus Christi]]
|-
| 1801 || {{sortname|Henry|Martyn}} || [[St John's College, Cambridge|St John's]] || {{sort|Woodall, William|William Woodall}} || [[Pembroke College, Cambridge|Pembroke]]
|-
| 1802 || {{sortname|Thomas Penny|White}} || [[Queens' College, Cambridge|Queens']] || {{sort|Grisdale, John|John Grisdale}} || [[Christ's College, Cambridge|Christ's]]
|-
| 1803 || {{sortname|Thomas|Starkie}} || [[St John's College, Cambridge|St John's]] || {{sortname|Charles James|Hoare}} || [[St John's College, Cambridge|St John's]]
|-
| 1804 || {{sortname|John|Kaye|John Kaye (bishop)}} || [[Christ's College, Cambridge|Christ's]] || {{sort|Garratt, William Albin|William Albin Garratt}}&lt;ref&gt;It appears that '22nd wrangler' in the entry for William Albin Garratt in Venn. {{acad|id=GRT800WA|name=Garratt, William Albin}} is a misprint for '2nd wrangler'; cf Neale, Charles Montague (1907), ''The Senior Wranglers of the University of Cambridge, from 1748 to 1907: With Biographical, etc., Notes'' (Bury St. Edmunds: F.T. Groom and Son; 61pp), [https://archive.org/stream/senoirwranglerso00nealrich#page/26/mode/1up p. 26]; at all events, Garratt took the First Smith's Prize in 1804, with the Senior Wrangler, Kaye, placing Second, although Kaye also took the Senior Classical Medal (for reference without prejudice, at the time, other things being equal, undergraduates at Trinity were given preference for the Smith's Prizes)&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-
| 1805 || {{sortname|Thomas|Turton}} || [[St Catharine's College, Cambridge|St Catharine's]] || {{sortname|Samuel Hunter|Christie}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1806 || {{sortname|Frederick|Pollock|Sir Frederick Pollock, 1st Baronet}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Walter, Henry|Henry Walter}} || [[St John's College, Cambridge|St John's]]
|-
| 1807 || {{sort|Gipps, Henry|Henry Gipps}} || [[St John's College, Cambridge|St John's]] || {{sort|Carr, John|John Carr}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1808 || {{sortname|Henry|Bickersteth|}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || {{sort|Bland, Miles|[[Miles Bland]]}} || [[St John's College, Cambridge|St John's]]
|-
| 1809 || {{sortname|Edward Hall|Alderson}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || {{sort|Standly, John|John Standly}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 1810 || {{sortname|William Henry|Maule}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|Thomas Shaw|Brandreth}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1811 || {{sortname|Thomas Edward|Dicey|Thomas Edward Dicey}} || [[Trinity College, Cambridge|Trinity]] || {{sort|French, William|William French}} || Caius
|-
| 1812 || {{sortname|Cornelius|Neale}} || [[St John's College, Cambridge|St John's]] || {{sort|Jordan, Joseph William|Joseph William Jordan}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1813 || {{sortname|John|Herschel}} || [[St John's College, Cambridge|St John's]] || {{sortname|George|Peacock}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1814 || {{sort|Gwatkin, Richard|Richard Gwatkin}} || [[St John's College, Cambridge|St John's]] || {{sort|Wilkinson, Henry|Henry Wilkinson}} || [[St John's College, Cambridge|St John's]]
|-
| 1815 || {{sort|Leicester, Charles George Frederick|Charles George Frederick Leicester}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Calvert, Frederick|Frederick Calvert}} || [[Jesus College, Cambridge|Jesus]]
|-
| 1816 || {{sortname|Edward|Jacob|Edward Jacob (barrister)}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || {{sortname|William|Whewell}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1817 || {{sort|Austen, John Thomas|John Thomas Austen}} || [[St John's College, Cambridge|St John's]] || {{sortname|Temple|Chevallier}} || [[Pembroke College, Cambridge|Pembroke]]
|-
| 1818 || {{sortname|John George|Shaw-Lefevre|John Shaw-Lefevre}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Hind, John|John Hind}} || [[St John's College, Cambridge|St John's]]
|-
| 1819 || {{sortname|Joshua|King}} || [[Queens' College, Cambridge|Queens']] || {{sort|Cooper, George Miles|George Miles Cooper}} || [[St John's College, Cambridge|St John's]]
|-
| 1820 || {{sortname|Henry|Coddington}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Maddy, Watkin|Watkin Maddy}} || [[St John's College, Cambridge|St John's]]
|-
| 1821 || {{sort|Atkinson, Solomon|Solomon Atkinson}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|Henry|Melvill}} || [[St John's College, Cambridge|St John's]]
|-
| 1822 || {{sort|Holditch, Hamnett|[[Hamnett Holditch]]}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || {{sort|Peacock, Mitford|Mitford Peacock}} || [[Corpus Christi College, Cambridge|Corpus Christi]]
|-
| 1823 || {{sortname|George Biddell|Airy}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Jeffreys, Charles|Charles Jeffreys}} || [[St John's College, Cambridge|St John's]]
|-
| 1824&lt;ref&gt;Classical Tripos established.&lt;/ref&gt; || {{sort|Cowling, John|John Cowling}} || [[St John's College, Cambridge|St John's]] || {{sort|Bowstead, James|James Bowstead}} || [[Corpus Christi College, Cambridge|Corpus Christi]]
|-
| 1825 || {{sortname|James|Challis}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Williamson, William|William Williamson}} || [[Clare College, Cambridge|Clare]]
|-
| 1826 || {{sort|Law, William|William Law}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|John|Hymers}}&lt;ref&gt;Founded [[Hymers College]].&lt;/ref&gt; || [[St John's College, Cambridge|St John's]]
|-
| 1827 || {{sortname|Henry Percy|Gordon|Sir Henry Percy Gordon, 2nd Baronet}} || [[Peterhouse, Cambridge|Peterhouse]] || {{sort|Turner, Thomas|Thomas Turner}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1828 || {{sortname|Charles|Perry|Charles Perry (bishop)}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Baily, John|John Baily}} || [[St John's College, Cambridge|St John's]]
|-
| 1829 || {{sortname|Henry|Philpott|Henry Philpott (bishop)}} || [[St Catharine's College, Cambridge|St Catharine's]] || {{sortname|William|Cavendish|William Cavendish, 7th Duke of Devonshire}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1830 || {{sort|Whitley, Charles Thomas|Charles Thomas Whitley}} || [[St John's College, Cambridge|St John's]] || {{sort|Heaviside, James William Lucas|James William Lucas Heaviside}} || [[Sidney Sussex College, Cambridge|Sidney Sussex]]
|-
| 1831 || {{sortname|Samuel|Earnshaw}} || [[St John's College, Cambridge|St John's]] || {{sort|Gaskin, Thomas|[[Thomas Gaskin]]}} || [[St John's College, Cambridge|St John's]]
|-
| 1832 || {{sort|Heath, Douglas Denon|[[Douglas Denon Heath]]}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|Samuel|Laing|Samuel Laing (science writer)}} || [[St John's College, Cambridge|St John's]]
|-
| 1833 || {{sort|Ellice, Alexander|Alexander Ellice}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || {{sort|Bowstead, Joseph|Joseph Bowstead}} || [[Pembroke College, Cambridge|Pembroke]]
|-
| 1834 || {{sortname|Philip|Kelland}} || [[Queens' College, Cambridge|Queens']] || {{sortname|Thomas Rawson|Birks}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1835 || {{sortname|Henry|Cotterill|Henry Cotterill}} || [[St John's College, Cambridge|St John's]] || {{sortname|Henry|Goulburn}}{{#tag:ref|Also senior classic.|group=note}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1836 || {{sortname|Archibald|Smith}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|John William|Colenso}} || [[St John's College, Cambridge|St John's]]
|-
| 1837 || {{sort|Griffin, William Nathaniel|William Nathaniel Griffin}} || [[St John's College, Cambridge|St John's]] || {{sortname|James Joseph|Sylvester}} || [[St John's College, Cambridge|St John's]]
|-
| 1838 || {{sort|Main, Thomas John|Thomas John Main}} || [[St John's College, Cambridge|St John's]] || {{sort|Mould, James George|James George Mould}} || [[Corpus Christi College, Cambridge|Corpus Christi]]
|-
| 1839 || {{sortname|Benjamin Morgan|Cowie}} || [[St John's College, Cambridge|St John's]] || {{sortname|Percival|Frost}} || [[St John's College, Cambridge|St John's]]
|-
| 1840 || {{sortname|Robert Leslie|Ellis}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Goodwin, Harvey|Harvey Goodwin}} || Caius
|-
| 1841 || {{sortname|George Gabriel|Stokes}} || [[Pembroke College, Cambridge|Pembroke]] || {{sort|Jones, Henry Cadman|[[Henry Cadman Jones]]}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1842 || {{sortname|Arthur|Cayley}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Simpson, Charles Turner|Charles Turner Simpson}} || [[St John's College, Cambridge|St John's]]
|-
| 1843 || {{sortname|John Couch|Adams}} || [[St John's College, Cambridge|St John's]] || {{sort|Bashforth, Francis|[[Francis Bashforth]]}} || [[St John's College, Cambridge|St John's]]
|-
| 1844 || {{sort|Hemming, George Wirgman|[[George Wirgman Hemming]]}} || [[St John's College, Cambridge|St John's]] || {{sort|Hopkins, William Bonner|William Bonner Hopkins}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 1845 || {{sortname|Stephen|Parkinson}} || [[St John's College, Cambridge|St John's]] || {{sortname|William|Thomson|William Thomson, 1st Baron Kelvin}} (later known as Lord Kelvin){{#tag:ref|According to legend, Kelvin was so confident he had come top that he asked his servant to run to the Senate House and check who the Second Wrangler was. The servant returned and told him, "You, sir"! Kelvin was reportedly beaten largely on the basis of Parkinson's superior exam technique. The result was reversed in the Smith Prize.  This story has also been attributed to J.J. Thomson in 1880, and others.&lt;ref&gt;[https://www.maths.cam.ac.uk/about/history A History of Mathematics in Cambridge]&lt;/ref&gt;|name=YouSir|group=note}} || [[Peterhouse, Cambridge|Peterhouse]]
|-
| 1846 || {{sort|Hensley, Lewis|Lewis Hensley}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Airey, John Alfred|John Alfred Airey (or Lumb)}} || [[Pembroke College, Cambridge|Pembroke]]
|-
| 1847 || {{sort|Wilson, William Parkinson|William Parkinson Wilson}} || [[St John's College, Cambridge|St John's]] || {{sort|Walker, Robert|Robert Walker}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1848 || {{sortname|Isaac|Todhunter}} || [[St John's College, Cambridge|St John's]] || {{sort|Mackenzie, Charles|[[Charles Mackenzie (bishop)|Charles Mackenzie]]}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 1849 || {{sort|Pell, Morris Birkbeck|[[Morris Birkbeck Pell]]}} || [[St John's College, Cambridge|St John's]] || {{sort|Phear, Henry Carlyon|Henry Carlyon Phear}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 1850 || {{sort|Besant, William|[[William Henry Besant]]}} || [[Corpus Christi College, Cambridge|Corpus Christi]] || {{sortname|Henry William|Watson}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1851 || {{sortname|Norman Macleod|Ferrers}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || {{sort|Evans, William Charles|William Charles Evans}} || [[St John's College, Cambridge|St John's]]
|-
| 1852 || {{sortname|Peter Guthrie|Tait}} || [[Peterhouse, Cambridge|Peterhouse]] || {{sort|Steele, William John|William John Steele}} || [[Peterhouse, Cambridge|Peterhouse]]
|-
| 1853 || {{sort|Sprague, Thomas Bond|[[Thomas Bond Sprague]]}} || [[St John's College, Cambridge|St John's]] || {{sort|Batty, Robert Braithwaite|Robert Braithwaite Batty}} || [[Emmanuel College, Cambridge|Emmanuel]]
|-
| 1854 || {{sortname|Edward|Routh}}{{#tag:ref|Routh found more fame subsequently as a coach of other Senior Wranglers. Indeed for twenty-two consecutive years from 1862, one of his pupils was Senior Wrangler, and he coached twenty-seven in all. His first pupil in 1856 was Third Wrangler, and in 1858 both the Senior and Second Wrangler were coached by him.&lt;ref&gt;{{cite web|title=Routh biography|url=http://www-history.mcs.st-and.ac.uk/Biographies/Routh.html|last=O'Connor|first=J. J.|author2=Robertson, E. F. |accessdate=6 July 2013|date=October 2003}}&lt;/ref&gt;|group=note}} || [[Peterhouse, Cambridge|Peterhouse]] || {{sortname|James Clerk|Maxwell}} || [[Peterhouse, Cambridge|Peterhouse]] &amp; [[Trinity College, Cambridge|Trinity]]
|-
| 1855 || {{sort|Savage, James|James Savage}} || [[St John's College, Cambridge|St John's]] || {{sortname|Leonard|Courtney|Leonard Courtney, 1st Baron Courtney of Penwith}} || [[St John's College, Cambridge|St John's]]
|-
| 1856 || {{sortname|Augustus Vaughton|Hadley|Augustus Vaughton Hadley}} || [[St John's College, Cambridge|St John's]] || {{sortname|John|Rigby|John Rigby (politician)}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1857 || {{sort|Finch, Gerard Brown|Gerard Brown Finch}} || [[Queens' College, Cambridge|Queens']] || {{sort|Savage, Thomas|Thomas Savage}} || [[Pembroke College, Cambridge|Pembroke]]
|-
| 1858 || {{sort|Slesser, George Middleton|George Middleton Slesser}} || [[Queens' College, Cambridge|Queens']] || {{sort|Smith, Charles Abercrombie|Charles Abercrombie Smith}} || [[Peterhouse, Cambridge|Peterhouse]]
|-
| 1859 || {{sortname|James|Wilson|James Wilson (Archdeacon of Manchester)}} || [[St John's College, Cambridge|St John's]] || {{sort|Brown, Frederick|Frederick Brown}} &amp; {{sort|Steel, Anthony William Wilson|Anthony William Wilson Steel}} || [[Trinity College, Cambridge|Trinity]] &amp; [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 1860 || {{sortname|James|Stirling|James Stirling (judge)}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Baily, Walter|Walter Baily}} || [[St John's College, Cambridge|St John's]]
|-
| 1861 || {{sort|Aldis, William Steadman|William Steadman Aldis}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Bond, John|John Bond}} || [[Magdalene College, Cambridge|Magdalene]]
|-
| 1862 || {{sort|Barker, Thomas|[[Thomas Barker (mathematician)|Thomas Barker]]}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Laing, John George|John George Laing}} || [[St John's College, Cambridge|St John's]]
|-
| 1863 || {{sortname|Robert|Romer}} || [[Trinity Hall, Cambridge|Trinity Hall]] || {{sortname|Edward Tucker|Leeke}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1864 || {{sort|Purkiss, Henry John|Henry John Purkiss}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Turnbull, William Peverill|William Peverill Turnbull}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1865 || {{sortname|John|Strutt|John Strutt, 3rd Baron Rayleigh}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|Alfred|Marshall}} || [[St John's College, Cambridge|St John's]]
|-
| 1866 || {{sort|Morton, Robert|Robert Morton}} || [[Peterhouse, Cambridge|Peterhouse]] || {{sort|Aldis, Thomas Steadman|Thomas Steadman Aldis}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1867 || {{sort|Niven, Charles|Charles Niven}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|William Kingdon|Clifford}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1868 || {{sortname|John Fletcher|Moulton}} || [[St John's College, Cambridge|St John's]] || {{sortname|George|Darwin}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1869 || {{sortname|Numa Edward|Hartog}}{{#tag:ref|First Jewish Senior Wrangler. A special grace was passed to allow him to be graduated using a special form of the wording in order to not offend his religious beliefs.|group=note}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Eliot, John|John Eliot}} || [[St John's College, Cambridge|St John's]]
|-
| 1870 || {{sortname|Richard|Pendlebury}} || [[St John's College, Cambridge|St John's]] || {{sortname|Alfred George|Greenhill}} || [[St John's College, Cambridge|St John's]]
|-
| 1871 || {{sortname|John|Hopkinson}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|James Whitbread Lee|Glaisher}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1872 || {{sort|Webb, Robert Rumsey|[[Robert Rumsey Webb]]}} || [[St John's College, Cambridge|St John's]] || {{sortname|Horace|Lamb}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1873 || {{sort|Harding, Thomas Oliver|Thomas Oliver Harding}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Nanson, Edward John|Edward John Nanson}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1874 || {{sort|Calliphronas, George Constantine|George Constantine Calliphronas}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || {{sortname|W. W. Rouse|Ball}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1875 || {{sort|Lord, John William|John William Lord}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|William|Burnside}} &amp; [[George Chrystal]] || [[Pembroke College, Cambridge|Pembroke]] &amp; [[Peterhouse, Cambridge|Peterhouse]]
|-
| 1876 || {{sort|Ward, Joseph Timmis|Joseph Timmis Ward}} || [[St John's College, Cambridge|St John's]] || [[William Mollison (Master of Clare College, Cambridge)|William Loudon Mollison]] || [[Clare College, Cambridge|Clare]]
|-
| 1877 || {{sortname|Donald|MacAlister}} || [[St John's College, Cambridge|St John's]] || {{sort|Gibbons, Frederic Brian De Malbisse|Frederic Brian De Malbisse Gibbons}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 1878 || {{sortname|E. W.|Hobson}} || [[Christ's College, Cambridge|Christ's]] || {{sort|Steggall, John Edward Aloysius|[[John Edward Aloysius Steggall]]}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1879 || {{sort|Allen, Andrew James Campbell|[[Andrew James Campbell Allen]]}} || [[Peterhouse, Cambridge|Peterhouse]] || {{sort|Walker, George Francis|George Francis Walker}} || [[Queens' College, Cambridge|Queens']]
|-
| 1880 || {{sortname|Joseph|Larmor}} || [[St John's College, Cambridge|St John's]] || {{sortname|J. J.|Thomson}}&lt;ref name=YouSir group=note /&gt; || [[Trinity College, Cambridge|Trinity]]
|-
| 1881 || {{sortname|Andrew|Forsyth}}{{#tag:ref|Forsyth was one of the men who were principally responsible for the reform of the Tripos system that led to the end of the Tripos ranking.|group=note}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Heath, Robert Samuel|Robert Samuel Heath}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1882&lt;ref&gt;An account exists of the 1882 graduation ceremony. {{cite news|url=http://www.casebook.org/press_reports/times/18820130.html|title=University Intelligence|work=The Times|accessdate=2008-09-25|date=30 January 1882}}&lt;/ref&gt; || {{sort|Herman, Robert Alfred|[[Robert Alfred Herman]]}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Yeo, John Shapland|John Shapland Yeo}} || [[St John's College, Cambridge|St John's]]
|-
| 1882{{#tag:ref|Regulations were changed to split the class list into Parts I &amp; II, and Part III. The examinations for the former were held in June and retained the ordered class list (in contrast to Part III), so two sets of results exist for this year.|group=note}} || {{sort|Welsh, William|William Welsh}} || [[Jesus College, Cambridge|Jesus]] || {{sortname|Herbert Hall|Turner}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1883 || {{sortname|George Ballard|Mathews}} || [[St John's College, Cambridge|St John's]] || {{sort|Gallop, Edward Gurner|Edward Gurner Gallop}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1884 || {{sortname|William Fleetwood|Sheppard}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Workman, Walter Percy|Walter Percy Workman}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1885 || {{sort|Berry, Arthur|Arthur Berry}} || [[King's College, Cambridge|King's]] || {{sortname|Augustus Edward Hough|Love}} || [[St John's College, Cambridge|St John's]]
|-
| 1886 || {{sortname|Alfred Cardew|Dixon}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Fletcher, William Charles|William Charles Fletcher}} || [[St John's College, Cambridge|St John's]]
|-
| 1887 || {{sortname|H. F.|Baker}}, [[A. William Flux|Sir Alfred William Flux]], [[John Henry Michell]] &amp; John Cyril Iles || [[St John's College, Cambridge|St John's]], [[St John's College, Cambridge|St John's]], [[Trinity College, Cambridge|Trinity]] &amp; [[Trinity College, Cambridge|Trinity]] || {{sort|Peace, James Bennet|James Bennet Peace}} || [[Emmanuel College, Cambridge|Emmanuel]]
|-
| 1888 || {{sortname|William McFadden|Orr}} || [[St John's College, Cambridge|St John's]] || {{sort|Brunyate, William Edwin|William Edwin Brunyate}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1889 || {{sortname|Gilbert|Walker}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|Frank Watson|Dyson}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1890 || {{sort|Bennett, Geoffrey Thomas|Geoffrey Thomas Bennett}};&lt;br /&gt;[[Philippa Fawcett]] placed "Above the Senior Wrangler"{{#tag:ref|Women were allowed to take the Tripos from 1881, when [[Charlotte Scott]] achieved the eighth highest mark (but was not officially ranked as eighth wrangler); but their results were published on a separate list and they were not officially ranked among the wranglers, so Fawcett was not officially Senior Wrangler despite receiving the highest mark on the tripos.  Women students were finally admitted as full members of the university in 1948.  |group=note}} || [[St John's College, Cambridge|St John's]]&lt;br /&gt;(Fawcett: [[Newnham College, Cambridge|Newnham]]) || {{sort|Segar, Hugh William|Hugh William Segar}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1891 || {{sort|Goodwillie, James|James Goodwillie}} || [[Corpus Christi College, Cambridge|Corpus Christi]] || {{sort|Mair, David Beveridge|David Beveridge Mair}} &amp; {{sort|Mayall, Robert Hume Davison|Robert Hume Davison Mayall}} || [[Christ's College, Cambridge|Christ's]] &amp; [[Sidney Sussex College, Cambridge|Sidney Sussex]]
|-
| 1892 || {{sortname|Philip Herbert|Cowell}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Sharpe, Francis Robert|Francis Robert Sharpe}} || [[Christ's College, Cambridge|Christ's]]
|-
| 1893 || {{sort|Manley, George Thomas|George Thomas Manley}} || [[Christ's College, Cambridge|Christ's]] || {{sort|Hurst, Gilbert Harrison John|Gilbert Harrison John Hurst}} &amp; {{sort|Sanger, Charles Percy|[[Charles Percy Sanger]]}} || [[King's College, Cambridge|King's]] &amp; [[Trinity College, Cambridge|Trinity]]
|-
| 1894 || {{sort|Adie, Walter Sibbald|Walter Sibbald Adie}} &amp; William Fellows Sedgwick || [[Trinity College, Cambridge|Trinity]] &amp; [[Trinity College, Cambridge|Trinity]] || {{sort|Philip, William Edward|William Edward Philip}} || [[Clare College, Cambridge|Clare]]
|-
| 1895 || {{sortname|Thomas John I'Anson|Bromwich}} || [[St John's College, Cambridge|St John's]] || {{sort|Grace, John Hilton|John Hilton Grace}} &amp; [[E. T. Whittaker]] || [[Peterhouse, Cambridge|Peterhouse]] &amp; [[Trinity College, Cambridge|Trinity]]
|-
| 1896 || {{sort|Fraser, William Garden|William Garden Fraser}} || [[Queens' College, Cambridge|Queens']] || {{sortname|Ernest William|Barnes}}, {{sort|Carson, George Edward St Lawrence|George Edward St Lawrence Carson}} &amp; {{sort|Wilkinson, Algernon Charles Legge|Algernon Charles Legge Wilkinson}} || [[Trinity College, Cambridge|Trinity]], [[Trinity College, Cambridge|Trinity]] &amp; [[Trinity College, Cambridge|Trinity]]
|-
| 1897 || {{sort|Austin, William Henry|William Henry Austin}} || [[Trinity College, Cambridge|Trinity]] || {{sortname|Francis John Welsh|Whipple}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1898 || {{sort|Hudson, Ronald William Henry Turnbull|Ronald William Henry Turnbull Hudson}} || [[St John's College, Cambridge|St John's]] || {{sortname|John Forbes|Cameron|J. F. Cameron}} &amp; [[James Hopwood Jeans]] || [[Gonville and Caius College, Cambridge|Gonville and Caius]] &amp; [[Trinity College, Cambridge|Trinity]]
|-
| 1899 || {{sort|Birtwhistle, George|George Birtwhistle}} &amp; [[R. P. Paranjpye]]{{#tag:ref|First Indian Senior Wrangler.|group=note}} || [[Pembroke College, Cambridge|Pembroke]] &amp; [[St John's College, Cambridge|St John's]] || {{sort|McLaren, Samuel Bruce|Samuel Bruce McLaren}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1900 || {{sort|Wright, Joseph Edmund|Joseph Edmund Wright}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Aldis, Arthur Cyril Webb|Arthur Cyril Webb Aldis}} || [[Trinity Hall, Cambridge|Trinity Hall]]
|-
| 1901 || {{sort|Brown, Alexander|Alexander Brown}} || [[Gonville and Caius College, Cambridge|Gonville and Caius]] || {{sort|Knapman, Herbert|Herbert Knapman}} || [[Emmanuel College, Cambridge|Emmanuel]]
|-
| 1902 || {{sortname|Ebenezer|Cunningham}} || [[St John's College, Cambridge|St John's]] || {{sort|Slator, Frank|Frank Slator}} || [[St John's College, Cambridge|St John's]]
|-
| 1903 || {{sortname|Harry|Bateman}} &amp; Philip Edward Marrack || [[Trinity College, Cambridge|Trinity]] &amp; [[Trinity College, Cambridge|Trinity]] || {{sort|Barnes, James Sidney|James Sidney Barnes}}, Ernest Gold, George Frederic Sowden Hills and Sidney Hill Phillips || [[Trinity College, Cambridge|Trinity]], [[St John's College, Cambridge|St John's]], [[Trinity College, Cambridge|Trinity]] and [[St John's College, Cambridge|St John's]]
|-
| 1904 || {{sortname|Arthur Stanley|Eddington}}{{#tag:ref|Eddington was the first person to be Senior Wrangler after only two years of study.&lt;ref&gt;{{cite web|url=http://silas.psfc.mit.edu/eddington/|title=Astrophysics and Mysticism: the life of Arthur Stanley Eddington|last=Hutchinson|first=Ian H.|date=December 2002|accessdate=2008-09-25|deadurl=yes|archiveurl=https://web.archive.org/web/20080922185046/http://silas.psfc.mit.edu/eddington/|archivedate=2008-09-22|df=}}&lt;/ref&gt;|group=note}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Blanco-White, G. R.|G. R. Blanco-White}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1905 || {{sortname|John Edensor|Littlewood}} &amp; [[James Mercer (mathematician)|James Mercer]] || [[Trinity College, Cambridge|Trinity]] &amp; [[Trinity College, Cambridge|Trinity]] || {{sort|Smith, H.|H. Smith}} || [[Trinity Hall, Cambridge|Trinity Hall]]
|-
| 1906 || {{sort|Rajan, Arunachala Tyaga|Arunachala Tyaga Rajan}} &amp; {{sort|Sewell, Clarence John Threlkeld|Clarence John Threlkeld Sewell}} || [[Trinity College, Cambridge|Trinity]] &amp; [[Trinity College, Cambridge|Trinity]] || {{sort|Harrison, W. J.|W. J. Harrison}} || [[Clare College, Cambridge|Clare]]
|-
| 1907 || {{sortname|G. N.|Watson}} || [[Trinity College, Cambridge|Trinity]] || {{sort|Turnbull, Herbert Westren|Herbert Westren Turnbull}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1908 || {{sortname|Selig|Brodetsky}} &amp; A. W. Ibbotson || [[Trinity College, Cambridge|Trinity]] &amp; [[Pembroke College, Cambridge|Pembroke]] || {{sort|Minson, H.|H. Minson}} || [[Christ's College, Cambridge|Christ's]]
|-
| 1909 || {{sortname|Percy John|Daniell}} || [[Trinity College, Cambridge|Trinity]] || [[E. H. Neville]] || [[Trinity College, Cambridge|Trinity]]
|}

== Senior Wranglers since 1910 ==
{| class="wikitable sortable"
! Year !! Senior Wrangler !! College
|-
| 1914 || {{sort|Molony, Brian Charles|Brian Charles Molony}}&lt;ref&gt;{{cite web|url=http://www.saxonlodge.net/getperson.php?personID=I0168&amp;tree=Tatham |title=Brian Charles Molony (1892–1963)|accessdate=6 July 2013}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-
| 1923 || {{sort|Ramsey, Frank|[[Frank P. Ramsey|Frank Ramsey]]}}&lt;ref&gt;{{cite book |last1=Krantz |first1=Stephen |last2=Parks |first2=Harold |date=2014 |title=A Mathematical Odyssey: Journey from the Real to the Complex |publisher=Springer |page=64 |isbn=1461489385}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-
| 1928 || {{sort|Coxeter, Donald|[[Harold Scott MacDonald Coxeter|Donald Coxeter]]}}&lt;ref&gt;{{cite web|url=http://rsbm.royalsocietypublishing.org/content/52/45.full.pdf|title=Biographical Memoirs of Fellows of the Royal Society|accessdate=6 July 2013|publisher=[[Royal Society]]}}&lt;/ref&gt;|| [[Trinity College, Cambridge|Trinity]]
|-
| 1930 || {{sortname|Jacob|Bronowski}}&lt;ref&gt;Bronowski's biography at the MacTutor History of Mathematics Archive: {{cite web|url=http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Bronowski.html|title=Jacob Bronowski|accessdate=6 July 2013|publisher=[[University of St Andrews]]}}&lt;/ref&gt;|| [[Jesus College, Cambridge|Jesus]]
|-
| 1939 || {{sort|Wilkinson, James|[[James H. Wilkinson|James Wilkinson]]}}&lt;ref&gt;Wilkinson's biography at the MacTutor History of Mathematics Archive: {{cite web|url=http://www.gap-system.org/~history/Biographies/Wilkinson.html|title=James Hardy Wilkinson|accessdate=6 July 2013|publisher=[[University of St Andrews]]|deadurl=yes|archiveurl=https://web.archive.org/web/20081122044557/http://www.gap-system.org/~history/Biographies/Wilkinson.html|archivedate=22 November 2008|df=}}&lt;/ref&gt;|| [[Trinity College, Cambridge|Trinity]]
|-
| 1940 || {{sortname|Hermann|Bondi}}&lt;ref&gt;{{cite web|url=http://www.aip.org/history/ohilist/4519.html| title=Oral History Transcript — Dr. Hermann Bondi |accessdate=6 July 2013| publisher=[[American Institute of Physics]]}}&lt;/ref&gt;|| [[Trinity College, Cambridge|Trinity]]
|-
| 1948 || {{sort|Ash, Michael|[[Michael Edward Ash]]}}&lt;ref&gt;Trinity College Cambridge,[https://www.trin.cam.ac.uk/alumni/publications/the-fountain/the-fountain-issue-23/#guinness "Making Guinness Guinness – Michael Ash"], ''The Fountain, Issue 23”&lt;/ref&gt;||  [[Trinity College, Cambridge|Trinity]]
|-
| 1952 || {{sortname|John|Polkinghorne}}{{Citation needed|date=May 2012}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1953 || {{sortname|Crispin|Nash-Williams}}&lt;ref&gt;{{cite web|url=http://www-history.mcs.st-and.ac.uk/Biographies/Nash-Williams.html|title=Crispin St John Alvah Nash-Williams|accessdate=6 July 2013|publisher=[[University of St Andrews]]}}&lt;/ref&gt; || [[Trinity Hall, Cambridge|Trinity Hall]]
|-
| 1959 || {{sort|Narlikar, Jayant|[[Jayant Narlikar]]}}&lt;ref&gt;{{cite book|title=Fred Hoyle: A Life in Science|publisher=Aurum|year=2005|first=Simon|last=Mitton|isbn=978-1-85410-961-3|pages=275}}&lt;/ref&gt;||(non-collegiate)
|- 
| 1966 || {{sort |Kalton, Nigel|[[Nigel Kalton]]}}{{Citation needed |date= August 2016 }} ||[[Trinity College, Cambridge|Trinity]]
|-
| 1970 || {{sort|Wanless, Derek|[[Derek Wanless]]}}&lt;ref&gt;{{cite news |title=Profile: Banking's boy wonder: Derek Wanless – NatWest's chief has a personal touch but a pragmatic vision, says William Kay|newspaper=[[The Independent|Independent]] |date= 27 March 1994}}&lt;/ref&gt; ||[[King's College, Cambridge|King's]]
|-
| 1972 || {{sort |Woo, Gordon|[[Gordon Woo]]}}&lt;ref&gt;{{cite book|title=The Mathematics of Natural Catastrophes|publisher=Imperial College Press|year=1999|first=Gordon|last=Woo|isbn=1-86094-182-6|p=292}}&lt;/ref&gt; ||[[Christ's College, Cambridge|Christ's]]
|-
|-
| 1973 || {{sort|Loong, Lee Hsien|[[Lee Hsien Loong]]}}&lt;ref&gt;{{cite book|title=From Third World to First: The Singapore Story: 1965-2000|publisher=Harper|year=2000|first=Lee|last=Kuan Yew|isbn=978-0-06019-776-6|pages=750–751}}&lt;/ref&gt;&lt;ref&gt;{{cite news |title=Dennis Marrian, University Tutor |author=Neo Hui Min |url=http://newspapers.nl.sg/Digitised/Article/straitstimes20040812-1.2.29.2.3.3.aspx |newspaper=[[Straits Times]] |date=12 August 2004 |accessdate=2 June 2013}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-
| 1977 || {{sortname|Glyn|Moody}}&lt;ref&gt;{{cite web|url=http://opendotdotdot.blogspot.com/2009/01/seven-things-people-didnt-know-about-me.html|title=Seven things people didn't know about me|accessdate=2011-01-06}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://mobile.twitter.com/glynmoody/status/173694096559452160|title=(correction by author)|accessdate=2012-02-26}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-
| 1982 || {{sort|Budd, Christopher|[[Christopher Budd (mathematician)|Christopher Budd]]}}{{citation needed|date=October 2017}} || [[St John's College, Cambridge|St John's]]
|-
| 1983 || {{sort|Lister, John|John Lister}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1985 || {{sort|Mee, Nick|Nick Mee}}&lt;ref&gt;{{cite web|url=http://plus.maths.org/content/whirlpool-numbers|title=Whirlpool numbers|accessdate=6 July 2013|publisher=[[Plus Magazine]]}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
&lt;!-- note to future editors: make sure to follow [[Wikipedia:Biographies of living persons]] strictly when adding entries for years where the person concerned is likely to be living (likely to have been born in the past 115 years and no source for their death, as stated in the BLP policy), do not add entries without a reliable, non-self-published source independent of the person named, and remove any existing entries not supported by such a source; if you wish to seek help finding suitable sources for a possible name without such sources, raise the matter on the talk page without listing the name here --&gt;
|-
| 1990 || {{sortname|Kevin|Buzzard}}&lt;ref&gt;{{cite web|url=http://wwwf.imperial.ac.uk/~buzzard/stuff/cv.pdf|title=CV of Kevin Buzzard|accessdate=16 September 2014}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-	
| 1992 || {{sort|Hendry, Ruth|Ruth Hendry}}&lt;ref&gt;{{cite web|url=http://www.damtp.cam.ac.uk/user/sjc1/Senior-Wrangler/Hendry-1992.pdf|title=Letter of confirmation of first place 1992 pt II mathematical tripos|accessdate=2015-04-06}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.queens.cam.ac.uk/sites/www.queens.cam.ac.uk/files/publicationFiles/final_mu20301_queens_bridge_-_march_2016_-_low_res_2.pdf|title=Where are they now? Ruth Hendry (1989): the only known female Senior Wrangler in history|accessdate=2016-09-09}}&lt;/ref&gt; || [[Queens' College, Cambridge|Queens']]
|-
| 1993 || {{sortname|Ian |Dowker}} || [[Trinity College, Cambridge|Trinity]]
|-
|1994
|Wee Tek Gan
|[[Churchill College, Cambridge|Churchill]]
|-
|1995
|Balazs Szendroi
|[[Trinity College, Cambridge|Trinity]]
|-
|1996
|David W. Essex
|[[Trinity College, Cambridge|Trinity]]
|-
| 1997 || {{sortname|Alexander G.|Barnard}} || [[Trinity College, Cambridge|Trinity]]
|-
| 1998 || {{sortname|Ben Joseph|Green}}&lt;ref&gt;{{cite web|url=http://www.claymath.org/fas/research_fellows/Green/bio.pdf|title=Mathematical biography of Ben Green|accessdate=2011-01-06|publisher=[[Clay Mathematics Institute]]}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-
| 1999 || {{sort|Russell Paul|Paul Russell}} || [[Peterhouse, Cambridge|Peterhouse]]
|-
| 2000 || {{sort|Gee, Toby|Toby Gee}}&lt;ref&gt;{{cite web|url=http://www.math.northwestern.edu/~gee/Index_files/cv.pdf|title=Toby Gee|accessdate=2011-01-06|deadurl=yes|archiveurl=https://web.archive.org/web/20110927222100/http://www.math.northwestern.edu/~gee/Index_files/cv.pdf|archivedate=2011-09-27|df=}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://gowers.wordpress.com/2013/04/14/answers-results-of-polls-and-a-brief-description-of-the-program/|author=[[Timothy Gowers]]|title=Answers, results of polls, and a brief description of the program|accessdate=2013-05-11}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-
| 2001 || {{sortname|Mohan|Ganesalingam}}&lt;ref&gt;{{cite web|url=http://www.cs.ru.nl/~freek/talks/lsfa.pdf|title=The Next Generation of Proof Assistants|accessdate=6 July 2013 |publisher=Computing Science Department – Radboud University Nijmegen}}&lt;/ref&gt;|| [[Trinity College, Cambridge|Trinity]]
|-
| 2002 || {{sort|Young, Jeremy|Jeremy Young}}|| [[Trinity College, Cambridge|Trinity]]
|-
| 2003 || {{sortname|Thomas|Barnet-Lamb}}&lt;ref&gt;{{cite web|url=http://www.imo-register.org.uk/2005-report.tex|title=The 46th International Mathematical Olympiad in Mexico|accessdate=2011-01-19}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-
| 2004 || {{sort|Loeffler, David|David Loeffler}}&lt;ref&gt;{{cite web|url=https://www2.warwick.ac.uk/fac/sci/maths/people/staff/david_loeffler/cv.pdf|title=David Loeffler Curriculum Vitae|accessdate=1 October 2015}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-
|2005
|Tim Austin
|[[Trinity College, Cambridge|Trinity]]
|-
|2006
|Antonio Lei
|[[Trinity College, Cambridge|Trinity]]
|-
| 2007 || {{sort|Jefferys, Paul|[[Paul Jefferys]]}}&lt;ref&gt;{{cite web|url=http://archive.varsity.co.uk/649v100.pdf|title=Varsity 100 |accessdate=2012-08-10|publisher=Mercer Management Consulting}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-
| 2008 || {{sort|Viet Bao, Le Hung|Le Hung Viet Bao}}&lt;ref&gt;{{cite web|url=http://tuoitre.vn/Nhip-song-tre/241024/Dau-an-Viet-o-Cambridge.html|title=Dấu ấn Việt ở Cambridge |accessdate=2012-03-18|publisher=[[Tuoi Tre|Tuổi Trẻ Online]]}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-
| 2009 || {{sort|Beck, Thomas|Thomas Beck}}&lt;ref&gt;{{cite web|url=http://www.trinhall.cam.ac.uk/news/archive-detail.asp?ItemID=2251|title=Trinity Hall rises to 7th in the Baxter tables|accessdate=6 July 2013|publisher=[[Trinity Hall, Cambridge|Trinity Hall]]}}&lt;/ref&gt; || [[Trinity Hall, Cambridge|Trinity Hall]]
|-
| 2010 || {{sort|Liu, Zihan Hans|Zihan Hans Liu}}&lt;ref&gt;{{cite web|url=http://scienceandtech.fulbrightonline.org/images/grantee_photos/2011/cv/cv_Liu_ZilhanHans.pdf?ml=5&amp;mlt=system&amp;tmpl=component|publisher=[[Trinity College, Cambridge|Trinity]]|title=CV Zihan Hans Liu}}&lt;/ref&gt; || [[Trinity College, Cambridge|Trinity]]
|-
| 2011 || {{sort|Eberhard, Sean|Sean Eberhard}}&lt;ref&gt;{{cite web|url=http://www.bishopodowd.org/admin/?p=2337|title=Sean Eberhard ’08 Reaches Pinnacle at Cambridge|accessdate=2011-10-05|deadurl=yes|archiveurl=https://web.archive.org/web/20120401130227/http://www.bishopodowd.org/admin/?p=2337|archivedate=2012-04-01|df=}}&lt;/ref&gt; || [[Gonville and Caius College, Cambridge|Gonville and Caius]]
|-
| 2012 || {{sort|Moss, Sean|Sean Moss}}&lt;ref&gt;{{cite web|url=http://www.havering-sfc.ac.uk/site/CollegeNews/PressReleases/Sean%20Moss%20-%20Top%20at%20Cambridge.pdf|title=Sean is Cambridge University's Top Maths Student|accessdate=2012-12-06|publisher=Havering Sixth Form College|deadurl=yes|archiveurl=https://web.archive.org/web/20130527033652/http://www.havering-sfc.ac.uk/site/CollegeNews/PressReleases/Sean%20Moss%20-%20Top%20at%20Cambridge.pdf|archivedate=2013-05-27|df=}}&lt;/ref&gt;|| [[Trinity College, Cambridge|Trinity]]
|-
| 2013 || {{sort|Fernandez, Arran|[[Arran Fernandez]]}}&lt;ref name="ReferenceA"/&gt;&lt;ref&gt;{{cite web|url=http://ccl.soc.srcf.net/2013/Maths/II.pdf|title=Mathematics Tripos, Part II, 2013|accessdate=2013-06-20}}{{dead link|date=May 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;|| [[Fitzwilliam College, Cambridge|Fitzwilliam]]
|-
| 2014 || {{sort|Li, Yang|Yang Li}}&lt;ref&gt;{{cite web|url=http://www.dow.cam.ac.uk/index.php/about/news/397-seniorwrangler|title=Downing College News – Senior Wrangler|accessdate=2014-06-22|deadurl=yes|archiveurl=https://web.archive.org/web/20140716164133/http://www.dow.cam.ac.uk/index.php/about/news/397-seniorwrangler|archivedate=2014-07-16|df=}}&lt;/ref&gt;|| [[Downing College, Cambridge|Downing]]
|-
| 2015 || {{sort|Large, Timothy|Timothy Large}}&lt;ref&gt;{{cite web|url=https://share.trin.cam.ac.uk/sites/public/Alumni/Annual%20Records/TRINITY%20ANNUAL%20RECORD%202015%20WEB.pdf|title=Trinity College Cambridge Annual Record 2014–2015|accessdate=2016-06-10|deadurl=yes|archiveurl=https://web.archive.org/web/20160808014531/https://share.trin.cam.ac.uk/sites/public/Alumni/Annual%20Records/TRINITY%20ANNUAL%20RECORD%202015%20WEB.pdf|archivedate=2016-08-08|df=}}&lt;/ref&gt;|| [[Trinity College, Cambridge|Trinity]]
|-
| 2016 || {{sort|Lai, Leo|Leo Lai}}|| [[Churchill College, Cambridge|Churchill]]
|-
| 2017 || {{sort|Zheng, Jonathan|Jonathan Zheng}}|| [[Trinity College, Cambridge|Trinity]]
|-
| 2018 || {{sort|Janzer, Barnabas| Barnabas Janzer}} || [[Trinity College, Cambridge|Trinity]]
|}
Senior Wranglers since 1910 also include:
* David Hobson&lt;ref&gt;{{cite web|url=http://www.timesonline.co.uk/tol/comment/obituaries/article6200849.ece|title=David Hobson: senior partner of Coopers &amp; Lybrand (obituary)|accessdate=6 January 2011|publisher=[[The Times]]}}{{subscription required}}&lt;/ref&gt; (Christ's College) (1940s)
* [[Peter Swinnerton-Dyer]]&lt;ref&gt;{{cite web|url=http://sportsillustrated.cnn.com/vault/article/magazine/MAG1080327/index.htm|title=Sir Peter is Unhorsed|accessdate=6 July 2013|publisher=[[Sports Illustrated]]}}&lt;/ref&gt; (Trinity College) (1940s)
* Michael Hall&lt;ref&gt;{{cite web|url=http://www.shrewsbury.org.uk/features/michael-hall-obituary|title=F M Hall (1935–2005) (obituary)|accessdate=6 July 2013|publisher=[[Shrewsbury School]]}}&lt;/ref&gt; (Trinity College) (1950s)
* Colin Myerscough&lt;ref&gt;{{cite web|url=http://www.rgs.saund.co.uk/rgsawards.html|title=University Awards as listed on the Honours Boards in the Queen's Hall|accessdate=29 November 2013}}&lt;/ref&gt; (Churchill College) (1960s)

== See also ==
* [[Wooden spoon (award)]]

== Notes ==
{{Reflist|group=note}}

== References ==
{{reflist|2}}
* {{cite book|title=The World of Mathematics|last=Galton|first=Francis |authorlink=Francis Galton|url=https://books.google.com/books?id=se5iE4DMPioC|isbn=0-486-41150-8|publisher=Courier Dover Publications|year=2000|volume=2|chapter=Classification of Men According to their Natural Gifts|editor=James Roy Newman}}
* {{cite book |editor=''ed.'' H.C.G Matthew and Brian Harrison |title=Oxford Dictionary of National Biography |url=http://www.oxforddnb.com |year=2004 |publisher=[[Oxford University Press]]}}
* {{cite book |last=Tanner |first=Joseph Robson|title=The historical register of the University of Cambridge, being a supplement to the Calendar with a record of University offices, honours and distinctions to the year 1910|url=https://archive.org/details/1910historicalreg00univuoft|format=PDF|publisher=[[Cambridge University Press]]|accessdate=2008-09-19|year=1917}}
* {{cite book | title=[[Alumni Cantabrigienses]] |last=Venn |first=John |authorlink=John Venn|year=1922–27 |publisher=Cambridge University Press}}
* {{cite book | last=Paul |first=Margaret |title=Frank Ramsey (1903–1930): A Sister's Memoir |year=2012 |publisher=Smith-Gordon}}

{{DEFAULTSORT:Wranglers Of The University of Cambridge}}
[[Category:History of the University of Cambridge]]
[[Category:Lists of people associated with the University of Cambridge]]
[[Category:Lists of mathematicians]]
[[Category:Senior Wranglers|*]]
[[Category:Second Wranglers|*]]</text>
      <sha1>6179jayumn1y3q0mxhrqb2y2vxsp1jc</sha1>
    </revision>
  </page>
  <page>
    <title>Series-parallel networks problem</title>
    <ns>0</ns>
    <id>873839</id>
    <revision>
      <id>832699136</id>
      <parentid>832585560</parentid>
      <timestamp>2018-03-27T14:24:56Z</timestamp>
      <contributor>
        <username>DePiep</username>
        <id>199625</id>
      </contributor>
      <minor/>
      <comment>OEIS in section external links: use dedicated {{OEIS el}} (via [[WP:JWB]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2961">In [[combinatorics|combinatorial]] [[mathematics]], the '''series-parallel networks problem''' asks for the number of [[series-parallel network]]s that can be formed using a given number of edges.  The edges can be distinguishable or indistinguishable.

==Indistinguishable edges==

When the edges are indistinguishable, we look for the number of [[topology|topologically]] different networks on ''n'' edges.

==Solution==

The idea is to break-down the problem by classifying the networks as essentially series and essentially parallel networks.

* An '''essentially series network''' is a network which can be broken down into two or more '''subnetworks''' in series.
* An '''essentially parallel network''' is a network which can be broken down into two or more '''subnetworks''' in parallel.

By the duality of networks, it can be proved that the number of essentially series networks is equal to the number of essentially parallel networks. Thus for all ''n'' &gt; 1, the number of networks in ''n'' edges is twice the number of essentially series networks. For ''n'' = 1, the number of networks is 1.

Define
* &lt;math&gt;a_n&lt;/math&gt; as the number of series-parallel networks on ''n'' indistinguishable edges.
* &lt;math&gt;b_n&lt;/math&gt; as the number of essentially series networks.

Then
:&lt;math&gt;a_n=\left\{\begin{matrix} 1, &amp; \mbox{if }n\mbox{ is 1} \\ 2b_n, &amp; \mbox{otherwise}\end{matrix}\right.&lt;/math&gt;

&lt;math&gt;b_n&lt;/math&gt; can be found out by enumerating the [[partition of an integer|partitions]] of &lt;math&gt;n&lt;/math&gt;.

Consider a partition, &lt;math&gt;\{p_i\}&lt;/math&gt; of ''n'':

:&lt;math&gt;\sum_i{ip_i}=n.&lt;/math&gt;

Consider the essentially series networks whose components correspond to the partition above. That is the number of components with ''i'' edges is &lt;math&gt;p_i&lt;/math&gt;. The number of such networks can be computed as

: &lt;math&gt;\prod_{i}{{b_i+p_i-1}\choose{p_i}}.&lt;/math&gt;

Hence

:&lt;math&gt;b_n=\sum_{p_i}{\prod_{i}{{b_i+p_i-1}\choose{p_i}}}&lt;/math&gt;

where the summation is over all partitions, &lt;math&gt;p_i&lt;/math&gt; of ''n'' except for the trivial partition consisting of only ''n''.

This gives a recurrence for computing &lt;math&gt;b_n&lt;/math&gt;.  Now &lt;math&gt;a_n&lt;/math&gt; can be computed as above.

[''TODO: Generating function for &lt;math&gt;a_n&lt;/math&gt; and &lt;math&gt;b_n&lt;/math&gt; are explained in the external links.'']

== External links ==
*{{OEIS el|sequencenumber=A000084|name=Number of series-parallel networks with n unlabeled edges|formalname=Number of series-parallel networks with n unlabeled edges. Also called yoke-chains by Cayley and MacMahon}}
*{{OEIS el|sequencenumber=A000669|name=Number of series-reduced planted trees with n leaves|formalname=Number of series-reduced planted trees with n leaves. Also the number of essentially series series-parallel networks with n edges; also the number of essentially parallel series-parallel networks with n edges}}
*[https://arxiv.org/abs/cond-mat/9707023 Asymptotic behavior of two-terminal series-parallel networks]

[[Category:Graph enumeration]]</text>
      <sha1>rurb334yf8i5sne34bif79l9w1mnymx</sha1>
    </revision>
  </page>
  <page>
    <title>System identification</title>
    <ns>0</ns>
    <id>552466</id>
    <revision>
      <id>870044264</id>
      <parentid>855607282</parentid>
      <timestamp>2018-11-22T00:54:28Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: isbn, template type, issue. Add: pmid. Removed parameters. Formatted [[WP:ENDASH|dashes]]. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13633">{{Black-box}}

The field of '''system identification'''{{ref|a|Note a}} uses [[statistical method]]s to build [[mathematical model]]s of [[dynamical system]]s from measured data.&lt;ref&gt;{{Cite book|title=System identification|last=Torsten|first=Söderström|last2=Stoica|first2=P.|date=1989|publisher=Prentice Hall|isbn=978-0138812362|location=New York|pages=|oclc=16983523|author-link2=Peter Stoica}}&lt;/ref&gt; System identification also includes the [[optimal design#System identification and stochastic approximation|optimal]] [[design of experiments]] for efficiently generating informative data for [[regression analysis|fitting]] such models as well as model reduction.

== Overview ==
A dynamical mathematical model in this context is a mathematical description of the dynamic behavior of a [[system]] or process in either the time or frequency domain. Examples include:

* [[physical system|physical]] processes such as the movement of a falling body under the influence of [[gravity]];
* [[economic system|economic]] processes such as [[stock market]]s that react to external influences.

One of the many possible applications of system identification is in [[Control theory|control systems]]. For example, it is the basis for modern [[data-driven control system]]s, in which concepts of system identification are integrated into the controller design, and lay the foundations for formal controller optimality proofs.

===Input-output vs output-only===
System identification techniques can utilize both input and output data (e.g. [[eigensystem realization algorithm]]) or can include only the output data (e.g. [[frequency domain decomposition]]).  Typically an input-output technique would be more accurate, but the input data is not always available.

===Optimal design of experiments===
{{Main|Optimal design#System identification and stochastic approximation}}
The quality of system identification depends on the quality of the inputs, which are under the control of the systems engineer. Therefore, systems engineers have long used the principles of the [[design of experiments]]. In recent decades, engineers have increasingly used the theory of [[optimal design|optimal experimental design]] to specify inputs that yield [[efficient estimator|maximally precise]] [[estimator]]s.&lt;ref&gt;{{cite book|title=Dynamic System Identification: Experiment Design and Data Analysis|author1=Goodwin|first=Graham C.|author2=Payne|first2=Robert L.|publisher=Academic Press|year=1977|isbn=978-0-12-289750-4|location=|pages=|lastauthoramp=yes}}&lt;/ref&gt;&lt;ref&gt;{{cite book|title=Identification of Parametric Models from Experimental Data|author1=Walter|first=Éric|author2=Pronzato|first2=Luc|publisher=Springer|year=1997|isbn=|location=|pages=|lastauthoramp=yes}}
&lt;/ref&gt;

==White- and black-box==
One could build a so-called [[white-box testing|white-box]] model based on [[first principles]], e.g. a model for a physical process from the [[Newton's laws of motion|Newton equations]], but in many cases such models will be overly complex and possibly even impossible to obtain in reasonable time due to the complex nature of many systems and processes.

A much more common approach is therefore to start from measurements of the behavior of the system and the external influences (inputs to the system) and try to determine a mathematical relation between them without going into the details of what is actually happening inside the system.  This approach is called system identification.  Two types of models are common in the field of system identification:

* '''grey box model:''' although the peculiarities of what is going on inside the system are not entirely known, a certain model based on both insight into the system and experimental data is constructed. This model does however still have a number of unknown free [[parameter]]s which can be estimated using system identification.&lt;ref name="Nielsen"&gt;{{Cite journal|last=Nielsen|first=Henrik Aalborg|last2=Madsen|first2=Henrik|date=December 2000|title=Predicting the Heat Consumption in District Heating Systems using Meteorological Forecasts|url=https://pdfs.semanticscholar.org/797f/e008adf5fa2b8ccb6977299c2faa6c99c454.pdf|journal=|location=Lyngby|publisher=Department of Mathematical Modelling, Technical University of Denmark|volume=|pages=|via=}}&lt;/ref&gt;&lt;ref name="Nielsen2"&gt;{{Cite journal|last=Nielsen|first=Henrik Aalborg|last2=Madsen|first2=Henrik|date=January 2006|title=Modelling the heat consumption in district heating systems using a grey-box approach|url=http://linkinghub.elsevier.com/retrieve/pii/S0378778805000745|journal=Energy and Buildings|volume=38|issue=1|pages=63–71|doi=10.1016/j.enbuild.2005.05.002|issn=0378-7788|via=}}&lt;/ref&gt; One example&lt;ref&gt;{{Cite journal|last=Wimpenny|first=J.W.T.|date=April 1997|title=The Validity of Models|journal=Advances in Dental Research|language=en|volume=11|issue=1|pages=150–159|doi=10.1177/08959374970110010601|pmid=9524451|issn=0895-9374}}&lt;/ref&gt; uses the [[Monod equation|Monod saturation model]] for microbial growth. The model contains a simple hyperbolic relationship between substrate concentration and growth rate, but this can be justified by molecules binding to a substrate without going into detail on the types of molecules or types of binding. Grey box modeling is also known as semi-physical modeling.&lt;ref&gt;{{Cite journal|last=Forssell|first=U.|last2=Lindskog|first2=P.|date=July 1997|title=Combining Semi-Physical and Neural Network Modeling: An Example ofIts Usefulness|url=http://linkinghub.elsevier.com/retrieve/pii/S1474667017429387|journal=IFAC Proceedings Volumes|volume=30|issue=11|pages=767–770|doi=10.1016/s1474-6670(17)42938-7|issn=1474-6670|via=}}&lt;/ref&gt;

* '''[[Black box (systems)|black box]] model:''' No prior model is available.  Most system identification algorithms are of this type.

In the context of [[nonlinear system identification]] Jin et al.&lt;ref&gt;{{Cite book|last=Gang Jin|last2=Sain|first2=M.K.|last3=Pham|first3=K.D.|last4=Billie|first4=F.S.|last5=Ramallo|first5=J.C.|date=2001|title=Modeling MR-dampers: a nonlinear blackbox approach|url=http://ieeexplore.ieee.org/document/945582/|journal=Proceedings of the 2001 American Control Conference. (Cat. No.01CH37148)|language=en-US|publisher=IEEE|doi=10.1109/acc.2001.945582|isbn=978-0780364950}}&lt;/ref&gt; describe greybox modeling by assuming a model structure a priori and then estimating the model parameters. Parameter estimation is relatively easy if the model form is known but this is rarely the case. Alternatively the structure or model terms for both linear and highly complex nonlinear models can be identified using [[Nonlinear system identification#NARMAX methods|NARMAX]] methods.&lt;ref&gt;{{Cite book|last=Billings|first=Stephen A|date=2013-07-23|title=Nonlinear System Identification: NARMAX Methods in the Time, Frequency, and Spatio–Temporal Domains|isbn= 9781118535561|journal=|language=en|volume=|pages=|doi=10.1002/9781118535561}}&lt;/ref&gt; This approach is completely flexible and can be used with grey box models where the algorithms are primed with the known terms, or with completely black box models where the model terms are selected as part of the identification procedure. Another advantage of this approach is that the algorithms will just select linear terms if the system under study is linear, and nonlinear terms if the system is nonlinear, which allows a great deal of flexibility in the identification.

== Identification for control ==
In [[Control theory|control systems]] applications, the objective of engineers is to obtain a [[Control theory#Control specification|good performance]] of the [[Control theory#Open-loop and closed-loop (feedback) control|closed-loop]] system, which is the one comprising the physical system, the feedback loop and the controller. This performance is typically achieved by designing the control law relying on a model of the system, which needs to be identified starting from experimental data. If the model identification procedure is aimed at control purposes, what really matters is not to obtain the best possible model that fits the data, as in the classical system identification approach, but to obtain a model satisfying enough for the closed-loop performance. This more recent approach is called '''identification for control''', or '''I4C''' in short.

The idea behind I4C can be better understood by considering the following simple example.&lt;ref&gt;{{Cite journal|last=Gevers|first=Michel|date=January 2005|title=Identification for Control: From the Early Achievements to the Revival of Experiment Design*|url=http://linkinghub.elsevier.com/retrieve/pii/S0947358005710414|journal=European Journal of Control|volume=11|issue=4–5|pages=335–352|doi=10.3166/ejc.11.335-352|issn=0947-3580|via=}}&lt;/ref&gt; Consider a system with ''true'' transfer function &lt;math&gt;G_0(s)&lt;/math&gt;:
:&lt;math&gt;G_0(s) = \frac{1}{s+1}&lt;/math&gt;
and an identified model &lt;math&gt;\hat{G}(s)&lt;/math&gt;:
:&lt;math&gt;\hat{G}(s) = \frac{1}{s}.&lt;/math&gt;
From a classical system identification perspective, &lt;math&gt;\hat{G}(s)&lt;/math&gt; is ''not'', in general, a ''good'' model for &lt;math&gt;G_0(s)&lt;/math&gt;. In fact, modulus and phase of &lt;math&gt;\hat{G}(s)&lt;/math&gt; are different from those of &lt;math&gt;G_0(s)&lt;/math&gt; at low frequency. What is more, while &lt;math&gt;G_0(s)&lt;/math&gt; is an [[Lyapunov stability|asymptotically stable]] system, &lt;math&gt;\hat{G}(s)&lt;/math&gt; is a simply stable system. However, &lt;math&gt;\hat{G}(s)&lt;/math&gt; may still be a model good enough for control purposes. In fact, if one wants to apply a [[PID controller|purely proportional]] negative feedback controller with high gain &lt;math&gt;K&lt;/math&gt;, the closed-loop transfer function from the reference to the output is, for &lt;math&gt;G_0(s)&lt;/math&gt;
:&lt;math&gt;\frac{KG_0(s)}{1+KG_0(s)} = \frac{K}{s+1+K}&lt;/math&gt;
and for &lt;math&gt;\hat{G}(s)&lt;/math&gt;
:&lt;math&gt;\frac{K\hat{G}(s)}{1+K\hat{G}(s)} = \frac{K}{s+K}.&lt;/math&gt;
Since &lt;math&gt;K&lt;/math&gt; is very large, one has that &lt;math&gt;1+K \approx K&lt;/math&gt;. Thus, the two closed-loop transfer functions are indistinguishable. In conclusion, &lt;math&gt;\hat{G}(s)&lt;/math&gt; is a ''perfectly acceptable'' identified model for the ''true'' system if such feedback control law has to be applied.

In conclusion, whether or not a model is ''appropriate'' for control design depends not only on the plant/model mismatch, but also on the controller that will be implemented. As such, in the I4C framework, given a control performance objective, the control engineer has to design the identification phase in such a way that the performance achieved by the model-based controller on the ''true'' system is as high as possible.

Sometimes, it is even convenient to design a controller without explicitly identifying a model of the system, but directly working on experimental data. This is the case of ''direct'' [[data-driven control system]]s.

==See also==
{{Div col}}
* [[Black box]]
* [[Generalized filtering]]
* [[Hysteresis]]
* [[Identifiability]]
* [[System realization]]
* [[Parameter estimation]]
* [[LTI system theory|Linear time-invariant system theory]]
* [[Model selection]]
* [[Nonlinear autoregressive exogenous model]]
* [[Open system (systems theory)]]
* [[Pattern recognition]]
* [[System dynamics]]
* [[Systems theory]]
* [[Model order reduction]]
* [[Grey box completion and validation]]
* [[Data-driven control system]]
{{Div col end}}

==Notes==
{{note|a|a|In some situations the term ''model identification'' is applied. Model identification apparently is used in a more general and modern sense, what makes system identification a special case.{{cn|date=December 2016}}}}

==References==
{{reflist}}

== Further reading ==
* {{cite book |author1=Goodwin, Graham C.  |author2=Payne, Robert L. |lastauthoramp=yes |title=Dynamic System Identification: Experiment Design and Data Analysis | publisher=Academic Press | year=1977}}
* Daniel Graupe: ''Identification of Systems'', Van Nostrand Reinhold, New York, 1972 (2nd ed., Krieger Publ. Co., Malabar, FL, 1976)
* Eykhoff, Pieter:  ''System Identification – Parameter and System Estimation'', John Wiley &amp; Sons, New York, 1974.  {{ISBN|0-471-24980-7}}
* [[Lennart Ljung (engineer)|Lennart Ljung]]: ''System Identification — Theory For the User'', 2nd ed, PTR [[Prentice Hall]], Upper Saddle River, N.J., 1999.
* Jer-Nan Juang: ''Applied System Identification'', Prentice Hall, Upper Saddle River, N.J., 1994.
* {{cite book |author=[[Harold J. Kushner|Kushner, Harold J.]] and Yin, G. George|title=Stochastic Approximation and Recursive Algorithms and Applications |edition=Second | publisher=Springer  | year=2003}}
* Oliver Nelles: ''Nonlinear System Identification'', Springer, 2001. {{ISBN|3-540-67369-5}}
* T. Söderström, [[Peter Stoica|P. Stoica]], System Identification, Prentice Hall, Upper Saddle River, N.J., 1989. {{ISBN|0-13-881236-5}}
* R. Pintelon, J. Schoukens, ''System Identification: A Frequency Domain Approach'', 2nd Edition, IEEE Press, Wiley, New York, 2012. {{ISBN|978-0-470-64037-1}}
* {{cite book |author1=Walter, Éric  |author2=Pronzato, Luc  |lastauthoramp=yes |title=Identification of Parametric Models from Experimental Data |publisher=Springer |year=1997}}

==External links==
* [http://www.control.isy.liu.se/~ljung/seoul2dvinew/plenary2.pdf L. Ljung: Perspectives on System Identification, July 2008]
* [http://gramian.de System Identification and Model Reduction via Empirical Gramians]

{{Statistics|applications|state=collapsed}}

[[Category:Classical control theory]]
[[Category:Dynamical systems|Identification]]
[[Category:Engineering statistics]]
[[Category:Systems engineering|Identification]]
[[Category:Systems theory|Identification]]
[[Category:Biological models]]</text>
      <sha1>su4i8ifa0f5virf663o75hwprzb5xlk</sha1>
    </revision>
  </page>
  <page>
    <title>Translation of axes</title>
    <ns>0</ns>
    <id>47331006</id>
    <revision>
      <id>812463090</id>
      <parentid>812462204</parentid>
      <timestamp>2017-11-27T23:57:58Z</timestamp>
      <contributor>
        <username>Anita5192</username>
        <id>13220696</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/2405:204:7145:2A71:5E08:AD44:4EB4:100F|2405:204:7145:2A71:5E08:AD44:4EB4:100F]] ([[User talk:2405:204:7145:2A71:5E08:AD44:4EB4:100F|talk]]) to last version by Headbomb</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9345">In [[mathematics]], a '''translation of axes''' in two dimensions is a [[map (mathematics)|mapping]] from an ''xy''-[[Cartesian coordinate system]] to an ''x'y&lt;nowiki&gt;'&lt;/nowiki&gt;''-Cartesian coordinate system in which the ''x&lt;nowiki&gt;'&lt;/nowiki&gt;'' axis is [[parallel (geometry)|parallel]] to the ''x'' axis and ''k'' units away, and the ''y&lt;nowiki&gt;'&lt;/nowiki&gt;'' axis is parallel to the ''y'' axis and ''h'' units away.  This means that the [[origin (mathematics)|origin]] ''O&lt;nowiki&gt;'&lt;/nowiki&gt;'' of the new coordinate system has coordinates (''h'', ''k'') in the original system.  The positive ''x&lt;nowiki&gt;'&lt;/nowiki&gt;'' and ''y&lt;nowiki&gt;'&lt;/nowiki&gt;'' directions are taken to be the same as the positive ''x'' and ''y'' directions.  A point ''P'' has coordinates (''x'', ''y'') with respect to the original system and coordinates (''x&lt;nowiki&gt;'&lt;/nowiki&gt;'', ''y&lt;nowiki&gt;'&lt;/nowiki&gt;'') with respect to the new system, where

:&lt;math&gt; &lt;/math&gt;
:{{NumBlk|:|&lt;math&gt; x = x' + h &lt;/math&gt; {{spaces|4}} and {{spaces|4}} &lt;math&gt; y = y' + k &lt;/math&gt;|{{EquationRef|1}}}}

or equivalently

:{{NumBlk|:|&lt;math&gt; x' = x - h &lt;/math&gt; {{spaces|4}} and {{spaces|4}} &lt;math&gt; y' = y - k .&lt;/math&gt;&lt;ref&gt;{{harvtxt|Anton|1987|p=107}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Protter|Morrey|1970|p=315}}&lt;/ref&gt;|{{EquationRef|2}}}}

In the new coordinate system, the point ''P'' will appear to have been translated in the opposite direction.  For example, if the ''xy''-system is translated a distance ''h'' to the right and a distance ''k'' upward, then ''P'' will appear to have been translated a distance ''h'' to the left and a distance ''k'' downward in the ''x'y&lt;nowiki&gt;'&lt;/nowiki&gt;''-system .  A translation of axes in more than two dimensions is defined similarly.&lt;ref&gt;{{harvtxt|Protter|Morrey|1970|pp=585–588}}&lt;/ref&gt;   A translation of axes is a [[rigid transformation]], but not a [[linear map]].  (See [[Affine transformation]].)

== Motivation ==
Coordinate systems are essential for studying the equations of [[curve (geometry)|curve]]s using the methods of [[analytic geometry]].  To use the method of coordinate geometry, the axes are placed at a convenient position with respect to the curve under consideration.  For example, to study the equations of [[ellipse]]s and [[hyperbola]]s, the [[focus (geometry)|foci]] are usually located on one of the axes and are situated symmetrically with respect to the origin.  If the curve (hyperbola, [[parabola]], ellipse, etc.) is ''not'' situated conveniently with respect to the axes, the coordinate system should be changed to place the curve at a convenient and familiar location and orientation.  The process of making this change is called a [[Coordinate system#Transformations|transformation of coordinates]].&lt;ref&gt;{{harvtxt|Protter|Morrey|1970|pp=314–315}}&lt;/ref&gt;

The solutions to many problems can be simplified by translating the coordinate axes to obtain new axes parallel to the original ones.&lt;ref&gt;{{harvtxt|Anton|1987|p=107}}&lt;/ref&gt;

== Translation of conic sections ==
{{Main|Conic section}}
Through a change of coordinates, the equation of a conic section can be put into a [[Conic section#Standard forms in Cartesian coordinates|standard form]], which is usually easier to work with.   For the most general equation of the second degree, it is always possible to perform a [[rotation of axes]] in such a way that in the new system the equation takes the form

:{{NumBlk|:|&lt;math&gt; Ax^2 + Cy^2 + Dx + Ey + F = 0 &lt;/math&gt; {{spaces|4}} (&lt;math&gt;A&lt;/math&gt; and &lt;math&gt;C&lt;/math&gt; not both zero);|{{EquationRef|3}}}}

that is, there is no ''xy'' term.&lt;ref&gt;{{harvtxt|Protter|Morrey|1970|p=322}}&lt;/ref&gt;  Next, a translation of axes can reduce an equation of the form ({{EquationNote|3}}) to an equation of the same form but with new variables (''x&lt;nowiki&gt;'&lt;/nowiki&gt;'', ''y&lt;nowiki&gt;'&lt;/nowiki&gt;'') as coordinates, and with ''D'' and ''E'' both equal to zero (with certain exceptions—for example, parabolas).  The principal tool in this process is "completing the square."&lt;ref&gt;{{harvtxt|Protter|Morrey|1970|p=316}}&lt;/ref&gt;  In the examples that follow, it is assumed that a rotation of axes has already been performed.

=== Example 1 ===
Given the equation

:&lt;math&gt; 9x^2 + 25y^2 + 18x - 100y - 116 = 0 ,&lt;/math&gt;

by using a translation of axes, determine whether the [[locus (mathematics)|locus]] of the equation is a parabola, ellipse, or hyperbola.  Determine foci (or focus), [[vertex (geometry)|vertices]] (or vertex), and [[eccentricity (mathematics)|eccentricity]].

'''Solution:'''  To complete the square in ''x'' and ''y'', write the equation in the form

:&lt;math&gt; 9(x^2 + 2x \qquad ) + 25(y^2 - 4y \qquad ) = 116 .&lt;/math&gt;

Complete the squares and obtain

:&lt;math&gt; 9(x^2 + 2x + 1) + 25(y^2 - 4y + 4) = 116 + 9 + 100 &lt;/math&gt;
:&lt;math&gt; \Leftrightarrow 9(x + 1)^2 + 25(y - 2)^2 = 225 .&lt;/math&gt;

Define

:&lt;math&gt; x' = x + 1 &lt;/math&gt; {{spaces|4}} and {{spaces|4}} &lt;math&gt; y' = y - 2 .&lt;/math&gt;

That is, the translation in equations ({{EquationNote|2}}) is made with &lt;math&gt; h = -1, k = 2 .&lt;/math&gt;  The equation in the new coordinate system is

:{{NumBlk|:|&lt;math&gt; 9x'^2 + 25y'^2 = 225 .&lt;/math&gt;|{{EquationRef|4}}}}

Divide equation ({{EquationNote|4}}) by 225 to obtain

:&lt;math&gt; \frac{x'^2}{25} + \frac{y'^2}{9} = 1 ,&lt;/math&gt;

which is recognizable as an ellipse with &lt;math&gt; a = 5, b = 3, c^2 = a^2 - b^2 = 16, c = 4, e = \tfrac{4}{5} .&lt;/math&gt;  In the ''x'y&lt;nowiki&gt;'&lt;/nowiki&gt;''-system, we have:  center &lt;math&gt; (0, 0) &lt;/math&gt;; vertices &lt;math&gt; (\pm 5, 0) &lt;/math&gt;; foci &lt;math&gt; (\pm 4, 0) .&lt;/math&gt;

In the ''xy''-system, use the relations &lt;math&gt; x = x' - 1, y = y' + 2 &lt;/math&gt; to obtain:  center &lt;math&gt; (-1, 2) &lt;/math&gt;; vertices &lt;math&gt; (4, 2), (-6, 2) &lt;/math&gt;; foci &lt;math&gt; (3, 2), (-5, 2) &lt;/math&gt;; eccentricity &lt;math&gt; \tfrac{4}{5} .&lt;/math&gt;&lt;ref&gt;{{harvtxt|Protter|Morrey|1970|pp=316–317}}&lt;/ref&gt;

== Generalization to several dimensions ==
For an ''xyz''-Cartesian coordinate system in three dimensions, suppose that a second Cartesian coordinate system is introduced, with axes ''x&lt;nowiki&gt;'&lt;/nowiki&gt;'', ''y&lt;nowiki&gt;'&lt;/nowiki&gt;'' and ''z&lt;nowiki&gt;'&lt;/nowiki&gt;'' so located that the ''x&lt;nowiki&gt;'&lt;/nowiki&gt;'' axis is parallel to the ''x'' axis and ''h'' units from it, the ''y&lt;nowiki&gt;'&lt;/nowiki&gt;'' axis is parallel to the ''y'' axis and ''k'' units from it, and the ''z&lt;nowiki&gt;'&lt;/nowiki&gt;'' axis is parallel to the ''z'' axis and ''l'' units from it.  A point ''P'' in space will have coordinates in both systems.  If its coordinates are (''x'', ''y'', ''z'') in the original system and (''x&lt;nowiki&gt;'&lt;/nowiki&gt;'', ''y&lt;nowiki&gt;'&lt;/nowiki&gt;'', ''z&lt;nowiki&gt;'&lt;/nowiki&gt;'') in the second system, the equations

:{{NumBlk|:|&lt;math&gt; x' = x - h, \qquad y' = y - k, \qquad z' = z - l &lt;/math&gt;|{{EquationRef|5}}}}

hold.&lt;ref&gt;{{harvtxt|Protter|Morrey|1970|pp=585–586}}&lt;/ref&gt;  Equations ({{EquationNote|5}}) define a translation of axes in three dimensions where (''h'', ''k'', ''l'') are the ''xyz''-coordinates of the new origin.&lt;ref&gt;{{harvtxt|Anton|1987|p=107}}&lt;/ref&gt;  A translation of axes in any finite number of dimensions is defined similarly.

== Translation of quadric surfaces ==
{{Main|Quadric surface}}
In three-space, the most general equation of the second degree in ''x'', ''y'' and ''z'' has the form

:{{NumBlk|:|&lt;math&gt; Ax^2 + By^2 + Cz^2 + Dxy + Exz + Fyz + Gx + Hy + Kz + L = 0 ,&lt;/math&gt;|{{EquationRef|6}}}}

where the quantities &lt;math&gt; A, B, C, \ldots , L &lt;/math&gt; are positive or negative numbers or zero.  The points in space satisfying such an equation all lie on a [[surface (geometry)|surface]].  Any second-degree equation which does not reduce to a cylinder, plane, line, or point corresponds to a surface which is called quadric.&lt;ref&gt;{{harvtxt|Protter|Morrey|1970|p=579}}&lt;/ref&gt;

As in the case of plane analytic geometry, the method of translation of axes may be used to simplify second-degree equations, thereby making evident the nature of certain quadric surfaces.  The principal tool in this process is "completing the square."&lt;ref&gt;{{harvtxt|Protter|Morrey|1970|p=586}}&lt;/ref&gt;

=== Example 2 ===
Use a translation of coordinates to identify the quadric surface

:&lt;math&gt; x^2 + 4y^2 + 3z^2 + 2x - 8y + 9z = 10 .&lt;/math&gt;

'''Solution:'''  Write the equation in the form

:&lt;math&gt; x^2 + 2x \qquad + 4(y^2 - 2y \qquad ) + 3(z^2 + 3z \qquad ) = 10 .&lt;/math&gt;

Complete the square to obtain

:&lt;math&gt; (x + 1)^2 + 4(y - 1)^2 + 3(z + \tfrac{3}{2})^2 = 10 + 1 + 4 + \tfrac{27}{4} .&lt;/math&gt;

Introduce the translation of coordinates

:&lt;math&gt; x' = x + 1, \qquad y' = y - 1, \qquad z' = z + \tfrac{3}{2} .&lt;/math&gt;

The equation of the surface takes the form

:&lt;math&gt; x'^2 + 4y'^2 + 3z'^2 = \tfrac{87}{4} ,&lt;/math&gt;

which is recognizable as the equation of an [[ellipsoid]].&lt;ref&gt;{{harvtxt|Protter|Morrey|1970|p=586}}&lt;/ref&gt;

== See also ==
* [[Translation (geometry)]]

== Notes ==
&lt;references/&gt;

== References ==
* {{ citation | first1 = Howard | last1 = Anton | year = 1987 | isbn = 0-471-84819-0 | title = Elementary Linear Algebra | edition = 5th | publisher = [[John Wiley &amp; Sons|Wiley]] | location = New York }}
* {{ citation | first1 = Murray H. | last1 = Protter | first2 = Charles B. | last2 = Morrey, Jr. | year = 1970 | lccn = 76087042 | title = College Calculus with Analytic Geometry | edition = 2nd | publisher = [[Addison-Wesley]] | location = Reading }}

[[Category:Functions and mappings]]
[[Category:Euclidean geometry]]
[[Category:Linear algebra]]
[[Category:Transformation (function)]]</text>
      <sha1>gr8ynq5mprbua136h7gi0q4zp4g9q9r</sha1>
    </revision>
  </page>
  <page>
    <title>Trigonometry</title>
    <ns>0</ns>
    <id>18717261</id>
    <revision>
      <id>871472720</id>
      <parentid>871472289</parentid>
      <timestamp>2018-12-01T08:59:28Z</timestamp>
      <contributor>
        <username>William Avery</username>
        <id>1398</id>
      </contributor>
      <minor/>
      <comment>([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26766">{{redirect|Trig}}
{{pp-move-indef}}
[[File:Circle-trig6.svg|thumb|350px|right|All of the [[trigonometric function]]s of an angle ''θ'' can be constructed geometrically in terms of a unit circle centered at ''O''.]]
{{Trigonometry}}

'''Trigonometry''' (from [[Ancient Greek|Greek]] ''[[wikt:τρίγωνον|trigōnon]]'', "triangle" and ''[[wikt:μέτρον|metron]]'', "measure"&lt;ref&gt;{{cite web|url=http://www.etymonline.com/index.php?term=trigonometry|title=trigonometry|publisher=Online Etymology Dictionary}}&lt;/ref&gt;) is a branch of [[mathematics]] that studies relationships involving lengths and [[angle]]s of [[triangle]]s. The field emerged in the [[Hellenistic period|Hellenistic  world]] during the 3rd century BC from applications of [[geometry]] to [[Astronomy|astronomical studies]].&lt;ref&gt;R. Nagel (ed.), ''Encyclopedia of Science'', 2nd Ed., The Gale Group (2002)&lt;/ref&gt;

The 3rd-century [[astronomers]] first noted that the lengths of the sides of a [[right-angle triangle]] and the [[angle]]s between those sides have fixed relationships: that is, if at least the length of one side and the value of one angle is known, then all other angles and lengths can be determined algorithmically. These calculations soon came to be defined as the [[trigonometric functions]] and today are pervasive in both [[pure mathematics|pure]] and [[applied mathematics|applied]] mathematics: fundamental methods of analysis such as the [[Fourier transform]], for example, or the [[wave equation]], use trigonometric functions to understand [[periodic function|cyclical]] phenomena across many applications in fields as diverse as physics, [[mechanical engineering|mechanical]] and [[electrical engineering]], music and acoustics, astronomy, ecology, and biology. Trigonometry is also the foundation of [[surveying]].

Trigonometry is most simply associated with [[Plane (geometry)|planar]] [[right angle|right-angle]] triangles (each of which is a two-dimensional triangle with one angle equal to 90 degrees). The applicability to non-right-angle triangles exists, but, since any non-right-angle triangle (on a flat plane) can be bisected to create two right-angle triangles, most problems can be reduced to calculations on right-angle triangles. Thus the majority of applications relate to right-angle triangles. One exception to this is [[spherical trigonometry]], the study of triangles on [[sphere]]s, surfaces of constant positive [[curvature]], in [[elliptic geometry]] (a fundamental part of [[astronomy]] and [[navigation]]). Trigonometry on surfaces of negative curvature is part of [[hyperbolic geometry]].

Trigonometry basics are often taught in schools, either as a separate course or as a part of a [[precalculus]] course.

== History ==
{{main|History of trigonometry}}
[[File:Hipparchos 1.jpeg|thumb|upright|left|[[Hipparchus]], credited with compiling the first [[Trigonometric tables|trigonometric table]], has been described as "the father of trigonometry".&lt;ref&gt;{{cite book |last=Boyer |authorlink=Carl Benjamin Boyer |title=A History of Mathematics |year=1991 |chapter=Greek Trigonometry and Mensuration |page=162}}&lt;/ref&gt;]]

[[Sumer]]ian astronomers studied angle measure, using a division of circles into 360 degrees.&lt;ref&gt;Aaboe, Asger. Episodes from the Early History of Astronomy. New York: Springer, 2001. {{isbn|0-387-95136-9}}&lt;/ref&gt; They, and later the [[Babylonians]], studied the ratios of the sides of [[Similarity (geometry)|similar]] triangles and discovered some properties of these ratios but did not turn that into a systematic method for finding sides and angles of triangles. The [[Nubia|ancient Nubians]] used a similar method.&lt;ref&gt;{{cite book|author=Otto Neugebauer |title=A history of ancient mathematical astronomy. 1 |url=https://books.google.com/books?id=vO5FCVIxz2YC&amp;pg=PA744 |year=1975 |publisher=Springer-Verlag |isbn=978-3-540-06995-9 |pages=744–}}&lt;/ref&gt;

In the 3rd century BC, [[Greek mathematics|Hellenistic mathematicians]] such as [[Euclid]] and [[Archimedes]] studied the properties of [[chord (geometry)|chords]] and [[inscribed angle]]s in circles, and they proved theorems that are equivalent to modern trigonometric formulae, although they presented them geometrically rather than algebraically. In 140 BC, [[Hipparchus]] (from [[Nicaea]], Asia Minor) gave the first tables of chords, analogous to modern [[trigonometric tables|tables of sine values]], and used them to solve problems in trigonometry and [[spherical trigonometry]].&lt;ref&gt;Thurston, [https://books.google.com/books?id=rNpHjqxQQ9oC&amp;pg=PA235#v=onepage&amp;q&amp;f=false pp. 235–236].&lt;/ref&gt; In the 2nd century AD, the Greco-Egyptian astronomer [[Ptolemy]] (from Alexandria, Egypt) constructed detailed trigonometric tables ([[Ptolemy's table of chords]]) in Book 1, chapter 11 of his ''[[Almagest]]''.&lt;ref name=toomer&gt;{{Citation|title=Ptolemy's Almagest|last1=Toomer|first1=G. J.|authorlink=Gerald J. Toomer|publisher=Princeton University Press|year= 1998|ISBN =0-691-00260-6}}&lt;/ref&gt; Ptolemy used [[chord (geometry)|chord]] length to define his trigonometric functions, a minor difference from the [[sine]] convention we use today.&lt;ref&gt;Thurston, [https://books.google.com/books?id=rNpHjqxQQ9oC&amp;pg=PA239#v=onepage&amp;q&amp;f=false pp. 239–243].&lt;/ref&gt; (The value we call sin(θ) can be found by looking up the chord length for twice the angle of interest (2θ) in Ptolemy's table, and then dividing that value by two.) Centuries passed before more detailed tables were produced, and Ptolemy's treatise remained in use for performing trigonometric calculations in astronomy throughout the next 1200 years in the medieval [[Byzantine]], [[Islamic Golden Age|Islamic]], and, later, Western European worlds.

The modern sine convention is first attested in the ''[[Surya Siddhanta]]'', and its properties were further documented by the 5th century (AD) [[Indian mathematics|Indian mathematician]] and astronomer [[Aryabhata]].&lt;ref&gt;Boyer p. 215&lt;/ref&gt; These Greek and Indian works were translated and expanded by [[Mathematics in medieval Islam|medieval Islamic mathematicians]]. By the 10th century, Islamic mathematicians were using all six trigonometric functions, had tabulated their values, and were applying them to problems in [[spherical geometry]].{{Citation needed|date=November 2011}} At about the same time, [[Chinese mathematics|Chinese]] mathematicians developed trigonometry independently, although it was not a major field of study for them. The [[Persian people|Persian]] [[Polymath|polymath]] [[Nasir al-Din al-Tusi]] has been described as the creator of trigonometry as a mathematical discipline in its own right.&lt;ref&gt;{{Cite web|url=http://www-history.mcs.st-andrews.ac.uk/Biographies/Al-Tusi_Nasir.html|title=Al-Tusi_Nasir biography|website=www-history.mcs.st-andrews.ac.uk|access-date=2018-08-05|quote=One of al-Tusi's most important mathematical contributions was the creation of trigonometry as a mathematical discipline in its own right rather than as just a tool for astronomical applications. In Treatise on the quadrilateral al-Tusi gave the first extant exposition of the whole system of plane and spherical trigonometry. This work is really the first in history on trigonometry as an independent branch of pure mathematics and the first in which all six cases for a right-angled spherical triangle are set forth.}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.cambridge.org/core/books/the-cambridge-history-of-science/islamic-mathematics/4BF4D143150C0013552902EE270AF9C2|title=the cambridge history of science|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.iranicaonline.org/articles/tusi-nasir-al-din-bio|title=ṬUSI, NAṢIR-AL-DIN i. Biography – Encyclopaedia Iranica|last=electricpulp.com|website=www.iranicaonline.org|language=en|access-date=2018-08-05|quote=His major contribution in mathematics (Nasr, 1996, pp. 208-14) is said to be in trigonometry, which for the first time was compiled by him as a new discipline in its own right. Spherical trigonometry also owes its development to his efforts, and this includes the concept of the six fundamental formulas for the solution of spherical right-angled triangles.}}&lt;/ref&gt; Knowledge of trigonometric functions and methods reached [[Western Europe]] via [[Latin translations of the 12th century|Latin translations]] of Ptolemy's Greek ''Almagest'' as well as the works of [[Astronomy in medieval Islam|Persian and Arabic astronomers]] such as [[Muhammad ibn Jābir al-Harrānī al-Battānī|Al Battani]] and [[Nasir al-Din al-Tusi]].&lt;ref&gt;Boyer pp. 237, 274&lt;/ref&gt; One of the earliest works on trigonometry by a northern European mathematician is ''De Triangulis'' by the 15th century [[Germany|German]] mathematician [[Regiomontanus]], who was encouraged to write, and provided with a copy of the ''Almagest'', by the [[Byzantine scholars in Renaissance|Byzantine Greek scholar]] cardinal [[Basilios Bessarion]] with whom he lived for several years.&lt;ref&gt;{{cite web|url=http://www-history.mcs.st-and.ac.uk/Biographies/Regiomontanus.html |title=Regiomontanus biography |publisher=History.mcs.st-and.ac.uk |accessdate=2017-03-08}}&lt;/ref&gt; At the same time, another translation of the ''Almagest'' from Greek into Latin was completed by the Cretan [[George of Trebizond]].&lt;ref&gt;N.G. Wilson, ''From Byzantium to Italy. Greek Studies in the Italian Renaissance'', London, 1992. {{isbn|0-7156-2418-0}}&lt;/ref&gt; Trigonometry was still so little known in 16th-century northern Europe that [[Nicolaus Copernicus]] devoted two chapters of ''[[De revolutionibus orbium coelestium]]'' to explain its basic concepts.

Driven by the demands of [[navigation]] and the growing need for accurate maps of large geographic areas, trigonometry grew into a major branch of mathematics.&lt;ref&gt;{{cite book | last = Grattan-Guinness | first = Ivor | year = 1997 | title = The Rainbow of Mathematics: A History of the Mathematical Sciences | publisher = W.W. Norton | isbn = 0-393-32030-8}}&lt;/ref&gt; [[Bartholomaeus Pitiscus]] was the first to use the word, publishing his ''Trigonometria'' in 1595.&lt;ref&gt;{{cite book|author=Robert E. Krebs |title=Groundbreaking Scientific Experiments, Inventions, and Discoveries of the Middle Ages and the Renaissance |url=https://books.google.com/books?id=MTXdplfiz-cC&amp;pg=PA153 |year=2004 |publisher=Greenwood Publishing Group |isbn=978-0-313-32433-8 |pages=153–}}&lt;/ref&gt; [[Gemma Frisius]] described for the first time the method of [[triangulation]] still used today in surveying. It was [[Leonhard Euler]] who fully incorporated [[complex number]]s into trigonometry. The works of the Scottish mathematicians [[James Gregory (astronomer and mathematician)|James Gregory]] in the 17th century and [[Colin Maclaurin]] in the 18th century were influential in the development of [[trigonometric series]].&lt;ref&gt;William Bragg Ewald (2007). ''[https://books.google.com/books?id=AcuF0w-Qg08C&amp;pg=PA93 From Kant to Hilbert: a source book in the foundations of mathematics]''. [[Oxford University Press US]]. p. 93. {{isbn|0-19-850535-3}}&lt;/ref&gt; Also in the 18th century, [[Brook Taylor]] defined the general [[Taylor series]].&lt;ref&gt;Kelly Dempski (2002). ''[https://books.google.com/books?id=zxdigX-KSZYC&amp;pg=PA29 Focus on Curves and Surfaces]''. p. 29. {{isbn|1-59200-007-X}}&lt;/ref&gt;

== Overview ==
{{main|Trigonometric function}}
[[File:TrigonometryTriangle.svg|thumb|245px|In this right triangle: {{nowrap|1= sin ''A'' = ''a''/''c'';}} {{nowrap|1= cos ''A'' = ''b''/''c'';}} {{nowrap|1= tan ''A'' = ''a''/''b''.}}]]

If one [[angle]] of a triangle is 90 degrees and one of the other angles is known, the third is thereby fixed, because the three angles of any triangle add up to 180 degrees. The two acute angles therefore add up to 90 degrees: they are [[complementary angles]]. The [[shape]] of a triangle is completely determined, except for [[Similarity (geometry)|similarity]], by the angles. Once the angles are known, the [[ratio]]s of the sides are determined, regardless of the overall size of the triangle. If the length of one of the sides is known, the other two are determined. These ratios are given by the following [[trigonometric function]]s of the known angle ''A'', where ''a'', '' b'' and ''c'' refer to the lengths of the sides in the accompanying figure:

*'''[[Sine]]''' function (sin), defined as the ratio of the side opposite the angle to the [[hypotenuse]].
:: &lt;math&gt;\sin A=\frac{\textrm{opposite}}{\textrm{hypotenuse}}=\frac{a}{\,c\,}\,.&lt;/math&gt;
*'''[[Cosine]]''' function (cos), defined as the ratio of the [[adjacent side (right triangle)|adjacent]] leg (the side of the triangle joining the angle to the right angle) to the hypotenuse.
:: &lt;math&gt;\cos A=\frac{\textrm{adjacent}}{\textrm{hypotenuse}}=\frac{b}{\,c\,}\,.&lt;/math&gt;
*'''[[Tangent (trigonometric function)|Tangent]]''' function (tan), defined as the ratio of the opposite leg to the adjacent leg.

::&lt;math&gt;\tan A=\frac{\textrm{opposite}}{\textrm{adjacent}}=\frac{a}{\,b\,}=\frac{a}{\,c\,}\cdot\frac{c}{\,b\,}=\frac{a}{\,c\,} / \frac{b}{\,c\,}=\frac{\sin A}{\cos A}\,.&lt;/math&gt;

The '''hypotenuse''' is the side opposite to the 90 degree angle in a right triangle; it is the longest side of the triangle and one of the two sides adjacent to angle ''A''. The '''adjacent leg''' is the other side that is adjacent to angle ''A''. The '''opposite side''' is the side that is opposite to angle ''A''. The terms '''perpendicular''' and '''base''' are sometimes used for the opposite and adjacent sides respectively.(see below under [[#Mnemonics|Mnemonics]]).

The [[Multiplicative inverse|reciprocals]] of these functions are named the '''cosecant''' (csc), '''secant''' (sec), and '''cotangent''' (cot), respectively:
:&lt;math&gt;\csc A=\frac{1}{\sin A}=\frac{\textrm{hypotenuse}}{\textrm{opposite}}=\frac{c}{a} ,&lt;/math&gt;

:&lt;math&gt;\sec A=\frac{1}{\cos A}=\frac{\textrm{hypotenuse}}{\textrm{adjacent}}=\frac{c}{b} ,&lt;/math&gt;

:&lt;math&gt;\cot A=\frac{1}{\tan A}=\frac{\textrm{adjacent}}{\textrm{opposite}}=\frac{\cos A}{\sin A}=\frac{b}{a} .&lt;/math&gt;

The [[Inverse trigonometric function|inverse functions]] are called the '''arcsine''', '''arccosine''', and '''arctangent''', respectively. There are arithmetic relations between these functions, which are known as [[trigonometric identities]]. The cosine, cotangent, and cosecant are so named because they are respectively the sine, tangent, and secant of the complementary angle abbreviated to "co-".

With these functions, one can answer virtually all questions about arbitrary triangles by using the [[law of sines]] and the [[law of cosines]]. These laws can be used to compute the remaining angles and sides of any triangle as soon as two sides and their included angle or two angles and a side or three sides are known. These laws are useful in all branches of geometry, since every [[polygon]] may be described as a finite combination of triangles.

=== Extending the definitions ===
[[File:Sin-cos-defn-I.png|right|thumb|240px|Fig. 1a – Sine and cosine of an angle θ defined using the unit circle.]]
The above definitions only apply to angles between 0 and 90 degrees (0 and π/2 [[radian]]s). Using the [[unit circle]], one can extend them to all positive and negative arguments (see [[trigonometric function]]). The trigonometric functions are [[periodic function|periodic]], with a period of 360 degrees or 2π radians. That means their values repeat at those intervals. The tangent and cotangent functions also have a shorter period, of 180 degrees or π radians.

The trigonometric functions can be defined in other ways besides the geometrical definitions above, using tools from [[calculus]] and [[infinite series]]. With these definitions the trigonometric functions can be defined for [[complex number]]s. The complex exponential function is particularly useful.

: &lt;math&gt;e^{x+iy} = e^x(\cos y + i \sin y).&lt;/math&gt;

See [[Euler's formula|Euler's]] and [[De Moivre's formula|De Moivre's]] formulas.

&lt;gallery&gt;
Image:Sine curve drawing animation.gif|Graphing process of ''y'' = sin(''x'') using a unit circle.
Image:csc drawing process.gif|Graphing process of ''y'' = csc(''x''), the reciprocal of sine, using a unit circle.
Image:tan drawing process.gif|Graphing process of ''y'' = tan(''x'') using a unit circle.
&lt;/gallery&gt;

=== {{anchor|SOHCAHTOA}}Mnemonics ===
&lt;!--------
  Please note: The one mnemonic already provided is enough. DO NOT ADD YOUR OWN MNEMONICS, especially ridiculous ones such as "Sex on holidays Comes after having Tons of alcohol", etcetera. Such edits DO NOT improve the article but add obfuscation and, in some cases, constitute subversive vandalism. They WILL be reverted.
 ---------&gt;
{{main|Mnemonics in trigonometry}}
A common use of [[mnemonic]]s is to remember facts and relationships in trigonometry. For example, the ''sine'', ''cosine'', and ''tangent'' ratios in a right triangle can be remembered by representing them and their corresponding sides as strings of letters. For instance, a mnemonic is SOH-CAH-TOA:&lt;ref&gt;{{MathWorld|title=SOHCAHTOA|urlname=SOHCAHTOA}}&lt;/ref&gt;

:'''S'''ine = '''O'''pposite ÷ '''H'''ypotenuse
:'''C'''osine = '''A'''djacent ÷ '''H'''ypotenuse
:'''T'''angent = '''O'''pposite ÷ '''A'''djacent

One way to remember the letters is to sound them out phonetically (i.e., ''SOH-CAH-TOA'', which is pronounced 'so-kə-'''toe'''-uh' {{IPAc-en|s|oʊ|k|ə|ˈ|t|oʊ|ə}}). Another method is to expand the letters into a sentence, such as "'''S'''ome '''O'''ld '''H'''ippie '''C'''aught '''A'''nother '''H'''ippie '''T'''rippin' '''O'''n '''A'''cid".&lt;ref&gt;A sentence more appropriate for high schools is "'''S'''ome '''O'''ld '''H'''orse '''C'''ame '''A'''''''H'''opping '''T'''hrough '''O'''ur '''A'''lley". {{cite book |title=Memory: A Very Short Introduction|first=Jonathan K.|last=Foster|publisher=Oxford|year=2008|isbn=0-19-280675-0|page=128}}&lt;/ref&gt;

=== Calculating trigonometric functions ===
{{main|Trigonometric tables}}
Trigonometric functions were among the earliest uses for [[mathematical table]]s. Such tables were incorporated into mathematics textbooks and students were taught to look up values and how to [[interpolate]] between the values listed to get higher accuracy. [[Slide rule]]s had special scales for trigonometric functions.

Today, [[scientific calculator]]s have buttons for calculating the main trigonometric functions (sin, cos, tan, and sometimes [[Euler's formula|cis]] and their inverses). Most allow a choice of angle measurement methods: [[degree (angle)|degrees]], radians, and sometimes [[gradians]]. Most computer [[programming language]]s provide function libraries that include the trigonometric functions. The [[floating point unit]] hardware incorporated into the microprocessor chips used in most personal computers has built-in instructions for calculating trigonometric functions.&lt;ref name=Intel2013&gt;{{cite book |title=Intel® 64 and IA-32 Architectures Software Developer’s Manual Combined Volumes: 1, 2A, 2B, 2C, 3A, 3B and 3C |year=2013 |publisher=Intel |url=http://download.intel.com/products/processor/manual/325462.pdf}}&lt;/ref&gt;

== Applications ==
{{uncited section|date=March 2016}}
[[File:Frieberger drum marine sextant.jpg|thumb|200px|[[Sextant]]s are used to measure the angle of the sun or stars with respect to the horizon. Using trigonometry and a [[marine chronometer]], the position of the ship can be determined from such measurements.]]
{{main|Uses of trigonometry}}

There is an enormous number of uses of trigonometry and trigonometric functions. For instance, the technique of [[triangulation]] is used in [[astronomy]] to measure the distance to nearby stars, in [[geography]] to measure distances between landmarks, and in [[satellite navigation system]]s. The sine and cosine functions are fundamental to the theory of [[periodic function]]s, such as those that describe sound and [[light]] waves.

Fields that use trigonometry or trigonometric functions include [[astronomy]] (especially for locating apparent positions of celestial objects, in which spherical trigonometry is essential) and hence [[navigation]] (on the oceans, in aircraft, and in space), [[music theory]], [[audio synthesis]], [[acoustics]], [[optics]], [[electronics]], [[biology]], [[medical imaging]] ([[CT scan]]s and [[ultrasound]]), [[pharmacy]], [[chemistry]], [[number theory]] (and hence [[cryptology]]), [[seismology]], [[meteorology]], [[oceanography]], many [[physical science]]s, land [[surveying]] and [[geodesy]], [[architecture]], [[image compression]], [[phonetics]], [[economics]], [[electrical engineering]], [[mechanical engineering]], [[civil engineering]], [[computer graphics]], [[cartography]], [[crystallography]] and [[game development]].

== Pythagorean identities ==

The following [[Identity (mathematics)|identities]] are related to the [[Pythagorean theorem]] and hold for any value:&lt;ref&gt;{{cite book |title=Technical Mathematics with Calculus |edition=illustrated |first1=John C. |last1=Peterson |publisher=Cengage Learning |year=2004 |isbn=978-0-7668-6189-3 |page=856 |url=https://books.google.com/books?id=PGuSDjHvircC}} [https://books.google.com/books?id=PGuSDjHvircC&amp;pg=PA856 Extract of page 856]&lt;/ref&gt;

:&lt;math&gt;\sin^2 A + \cos^2 A = 1 \ &lt;/math&gt;

:&lt;math&gt;\tan^2 A + 1 = \sec^2 A \ &lt;/math&gt;

:&lt;math&gt;\cot^2 A + 1 = \csc^2 A  \ &lt;/math&gt;

== Angle transformation formulae ==

:&lt;math&gt;\sin (A \pm B) = \sin A \ \cos B \pm \cos A \ \sin B&lt;/math&gt;

:&lt;math&gt;\cos (A \pm B) = \cos A \ \cos B \mp \sin A \ \sin B&lt;/math&gt;

:&lt;math&gt;\tan (A \pm B) = \frac{ \tan A \pm \tan B }{ 1 \mp \tan A \ \tan B}&lt;/math&gt;

:&lt;math&gt;\cot (A \pm B) = \frac{ \cot A \ \cot B \mp 1}{ \cot B \pm \cot A } &lt;/math&gt;

== Common formulae ==
{{Anchor|Triangle identities|Common formulas}}
[[File:Triangle ABC with Sides a b c 2.png|thumb|240px|right|Triangle with sides ''a'',''b'',''c'' and respectively opposite angles ''A'',''B'',''C'']]

Certain equations involving trigonometric functions are true for all angles and are known as ''trigonometric identities''. Some identities equate an expression to a different expression involving the same angles. These are listed in [[List of trigonometric identities]]. Triangle identities that relate the sides and angles of a given triangle are listed below.

In the following identities, ''A'', ''B'' and ''C'' are the angles of a triangle and ''a'', ''b'' and ''c'' are the lengths of sides of the triangle opposite the respective angles (as shown in the diagram).

=== Law of sines ===
The '''[[law of sines]]''' (also known as the "sine rule") for an arbitrary triangle states:

:&lt;math&gt;\frac{a}{\sin A} = \frac{b}{\sin B} = \frac{c}{\sin C} = 2R = \frac{abc}{2\Delta},&lt;/math&gt;
where &lt;math&gt;\Delta&lt;/math&gt; is the area of the triangle and ''R'' is the radius of the [[circumscribed circle]] of the triangle:

:&lt;math&gt;R = \frac{abc}{\sqrt{(a+b+c)(a-b+c)(a+b-c)(b+c-a)}}.&lt;/math&gt;

Another law involving sines can be used to calculate the area of a triangle. Given two sides ''a'' and ''b'' and the angle between the sides ''C'', the area of the triangle is given by half the product of the lengths of two sides and the sine of the angle between the two sides:

:&lt;math&gt;\mbox{Area} = \Delta = \frac{1}{2}a b\sin C.&lt;/math&gt;

=== Law of cosines ===
The '''[[law of cosines]]''' (known as the cosine formula, or the "cos rule") is an extension of the Pythagorean theorem to arbitrary triangles:

:&lt;math&gt;c^2=a^2+b^2-2ab\cos C ,\,&lt;/math&gt;

or equivalently:

:&lt;math&gt;\cos C=\frac{a^2+b^2-c^2}{2ab}.\,&lt;/math&gt;

The law of cosines may be used to prove [[Heron's formula]], which is another method that may be used to calculate the area of a triangle. This formula states that if a triangle has sides of lengths ''a'', ''b'', and ''c'', and if the semiperimeter is

:&lt;math&gt;s=\frac{1}{2}(a+b+c),&lt;/math&gt;

then the area of the triangle is:

:&lt;math&gt;\mbox{Area} = \Delta = \sqrt{s(s-a)(s-b)(s-c)} = \frac{abc}{4R}&lt;/math&gt;,
where R is the radius of the [[circumcircle]] of the triangle.

=== Law of tangents ===
The '''[[law of tangents]]''':

:&lt;math&gt;\frac{a-b}{a+b}=\frac{\tan\left[\tfrac{1}{2}(A-B)\right]}{\tan\left[\tfrac{1}{2}(A+B)\right]}&lt;/math&gt;

=== Euler's formula ===
[[Euler's formula]], which states that &lt;math&gt;e^{ix} = \cos x + i \sin x&lt;/math&gt;, produces the following [[mathematical analysis|analytical]] identities for sine, cosine, and tangent in terms of ''[[e (mathematics)|e]]'' and the [[imaginary unit]] ''i'':
:&lt;math&gt;\sin x = \frac{e^{ix} - e^{-ix}}{2i}, \qquad \cos x = \frac{e^{ix} + e^{-ix}}{2}, \qquad \tan x = \frac{i(e^{-ix} - e^{ix})}{e^{ix} + e^{-ix}}.&lt;/math&gt;
&lt;!-- Note: the expression of tan(x) has i in the numerator, not in the denominator, because the order of the terms (and thus the sign) of the numerator is changed w.r.t. the expression of sin(x). --&gt;

== See also ==
{{div col|colwidth=22em}}

* {{Portal-inline|Trigonometry}}
* [[Aryabhata's sine table]]
* [[Generalized trigonometry]]
* [[Lénárt sphere]]
* [[List of triangle topics]]
* [[List of trigonometric identities]]
* [[Rational trigonometry]]
* [[Skinny triangle]]
* [[Small-angle approximation]]
* [[Trigonometric functions]]
* [[Unit circle]]
* [[Uses of trigonometry]]
{{div col end}}

== References ==
{{reflist|30em}}

== Bibliography ==
*{{cite book |first=Carl B. |last=Boyer |authorlink=Carl Benjamin Boyer |title=A History of Mathematics |edition=Second |publisher=John Wiley &amp; Sons, Inc. |year=1991 |isbn=0-471-54397-7}}
*{{Springer |title=Trigonometric functions |id=p/t094210}}
*Christopher M. Linton (2004). From Eudoxus to Einstein: A History of Mathematical Astronomy . Cambridge University Press.
*{{MathWorld|title=Trigonometric Addition Formulas|urlname=TrigonometricAdditionFormulas|author=Weisstein, Eric W.}}

== External links ==
{{Sister project links|Trigonometry}}
{{Library resources box |by=no |onlinebooks=no |others=no |about=yes |label=Trigonometry}}
* [http://www.khanacademy.org/math/trigonometry Khan Academy: Trigonometry, free online micro lectures]
* [https://web.archive.org/web/20071104225720/http://baqaqi.chi.il.us/buecher/mathematics/trigonometry/index.html Trigonometry] by Alfred Monroe Kenyon and Louis Ingold, The Macmillan Company, 1914. In images, full text presented.
* [http://www.maa.org/publications/periodicals/convergence/benjamin-bannekers-trigonometry-puzzle-introduction Benjamin Banneker's Trigonometry Puzzle] at [http://www.maa.org/loci-category/convergence?page=1 Convergence]
* [http://www.clarku.edu/~djoyce/trig/ Dave's Short Course in Trigonometry] by David Joyce of [[Clark University]]
*[http://www.mecmath.net/trig/trigbook.pdf Trigonometry, by Michael Corral, Covers elementary trigonometry, Distributed under GNU Free Documentation License]

{{Areas of mathematics | state=collapsed}}

{{Authority control}}

[[Category:Trigonometry| ]]</text>
      <sha1>0b75rxez91vmsj04mfwlha5fah0nzx7</sha1>
    </revision>
  </page>
  <page>
    <title>Universal chord theorem</title>
    <ns>0</ns>
    <id>52167339</id>
    <revision>
      <id>856482271</id>
      <parentid>854771034</parentid>
      <timestamp>2018-08-25T15:04:48Z</timestamp>
      <contributor>
        <ip>151.51.170.63</ip>
      </contributor>
      <comment>The previous theorem was wrong as stated, either the interval needs to be [0,1] or the 1/n needed to be scaled. Current version is at least correct, whole article needs cleanup though.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2333">
[[File:Chord graph.png|thumb| A chord (in red) of length 0.3 on a sinusoidal function. The universal chord
theorem guarantees the existence of chords of length 1/''n'' for functions satisfying certain conditions.]]

In [[mathematical analysis]], the '''universal chord theorem''' states that if a function ''f'' is continuous on [''a'',''b''] and satisfies &lt;math&gt; f(a) = f(b) &lt;/math&gt;, then for every [[natural number]] &lt;math&gt;n&lt;/math&gt;, there exists some &lt;math&gt; x \in [a,b] &lt;/math&gt; such that &lt;math&gt; f(x) = f\left(x + \frac{b-a}{n}\right) &lt;/math&gt;.&lt;ref&gt;Rosenbaum, J. T. (May, 1971) ''The American Mathematical Monthly'', Vol. 78, No. 5, pp. 509–513&lt;/ref&gt;

==History==
The theorem was published by [[Paul Lévy (mathematician)|Paul Lévy]] in 1934 as a generalization of [[Rolle's Theorem]].&lt;ref&gt;[[Paul Lévy (mathematician)|Paul Levy]], "Sur une Généralisation du Théorème de Rolle", C. R. Acad. Sci., Paris, 198 (1934) 424–425.&lt;/ref&gt;

==Statement of the theorem==
Let &lt;math&gt; H(f) = \{ h \in [0, 1] : f(x) = f(x+h) \text{ for some } x \} &lt;/math&gt; denote the '''chord set''' of the function ''f''. If ''f'' is a continuous function and &lt;math&gt; h \in H(f) &lt;/math&gt;, then &lt;math&gt; \frac h n \in H(f)&lt;/math&gt;
for all natural numbers ''n''.
&lt;ref&gt;{{cite journal|last1=Oxtoby|first1=J.C.|title=Horizontal Chord Theorems|journal=The American Mathematical Monthly|date=May 1978|volume=79|pages=468–475|doi=10.2307/2317564}}&lt;/ref&gt;

==Case of ''n'' = 2==
The case when ''n'' = 2 can be considered an application of the [[Borsuk–Ulam theorem]] to the real line. It says that if &lt;math&gt; f(x) &lt;/math&gt; is continuous on some
interval &lt;math&gt; I = [a,b] &lt;/math&gt; with the condition that &lt;math&gt; f(a) = f(b) &lt;/math&gt;, then there exists some &lt;math&gt; x \in [a,b] &lt;/math&gt; such that &lt;math&gt; f\left(x + \frac{b-a}{2}\right) &lt;/math&gt;. 

In less generality, if &lt;math&gt;  f : [0,1] \rightarrow \R &lt;/math&gt; is [[Continuous function|continuous]] and &lt;math&gt; f(0) = f(1) &lt;/math&gt;, then there exists &lt;math&gt; x \in \left[0,\frac{1}{2}\right]&lt;/math&gt; that satisfies &lt;math&gt; f(x) = f(x+1/2) &lt;/math&gt;.

==Proof of ''n'' = 2==
{{empty section|date=August 2017}}

==Proof of general case==
{{empty section|date=August 2017}}

==See also==
*[[Intermediate value theorem]]
*[[Borsuk–Ulam theorem]]
*[[Rolle's theorem]]

==References==
&lt;references/&gt;

[[Category:Mathematical theorems]]</text>
      <sha1>ku1vufl4shawe4kqrxlbhd7d67li465</sha1>
    </revision>
  </page>
  <page>
    <title>Vector algebra relations</title>
    <ns>0</ns>
    <id>28810270</id>
    <revision>
      <id>858655202</id>
      <parentid>838656142</parentid>
      <timestamp>2018-09-08T18:58:57Z</timestamp>
      <contributor>
        <username>Widefox</username>
        <id>1588193</id>
      </contributor>
      <minor/>
      <comment>fix sect [[WP:ORDER]] ,</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9895">{{See also|Vector calculus identities}}
The relations below apply to [[Euclidean vector|vectors]] in a three-dimensional [[Euclidean space]].&lt;ref name=Albright&gt;See, for example, {{cite book |title=Albright's chemical engineering handbook |author=Lyle Frederick Albright |url=https://books.google.com/books?id=HYB3Udjx_FYC&amp;pg=PA68 |page=68 |isbn=0-8247-5362-3 |publisher=CRC Press |chapter=§2.5.1 Vector algebra |year=2008}}
&lt;/ref&gt; Some, but not all of them, extend to vectors of higher dimensions. In particular, the cross product of two vectors is not available in all dimensions. See [[Seven-dimensional cross product]].
==Magnitudes==

The magnitude of a vector '''A''' is determined by its three components along three orthogonal directions using [[Pythagoras' theorem]]:

:&lt;math&gt;\|\mathbf A \|^2 = A_1^2 + A_2^2 +A_3^2 &lt;/math&gt;

The magnitude also can be expressed using the [[dot product]]:

:&lt;math&gt;\|\mathbf A \|^2 = \mathbf {A \cdot A} &lt;/math&gt;

==Inequalities==

:&lt;math&gt;\frac{ \mathbf{A \cdot B}}{\|\mathbf A \| \|\mathbf B \|} \le 1 &lt;/math&gt;;  [[Cauchy–Schwarz inequality]]  in three dimensions
:&lt;math&gt;\|\mathbf{A + B}\| \le \| \mathbf{A}\| + \|\mathbf{B}\| &lt;/math&gt;; the [[triangle inequality]] in three dimensions
:&lt;math&gt;\|\mathbf{A - B}\| \ge \| \mathbf{A}\| - \|\mathbf{B}\| &lt;/math&gt;; the [[Triangle_inequality#Reverse_triangle_inequality |reverse triangle inequality]]
Here the notation ('''A&amp;thinsp;·&amp;thinsp;B''') denotes the [[dot product]] of vectors '''A''' and '''B'''.

==Angles==

The vector product and the scalar product of two vectors define the angle between them, say θ:&lt;ref name=Albright/&gt;&lt;ref name=Hildebrand&gt;

{{cite book |title=Methods of applied mathematics |author=Francis Begnaud Hildebrand |page=24 |url=https://books.google.com/books?id=17EZkWPz_eQC&amp;pg=PA24|isbn=0-486-67002-3 |edition=Reprint of Prentice-Hall 1965 2nd|publisher=Courier Dover Publications |year=1992}}
&lt;/ref&gt;

:&lt;math&gt;\sin \theta =\frac{\|\mathbf{A \times B}\|}{\|\mathbf A \| \|\mathbf B \|} \ \ ( -\pi &lt; \theta \le \pi ) &lt;/math&gt; 
To satisfy the [[right-hand rule]], for positive θ, vector '''B''' is counter-clockwise from '''A''', and for negative θ it is clockwise.
:&lt;math&gt;\cos \theta = \frac{ \mathbf{A \cdot B}}{\|\mathbf A \| \|\mathbf B \|} \ \ ( -\pi &lt; \theta \le \pi )&lt;/math&gt;
Here the notation '''A&amp;thinsp;×&amp;thinsp;B''' denotes the vector [[cross product]] of vectors '''A''' and '''B'''.
The [[Pythagorean trigonometric identity]] then provides:

:&lt;math&gt;  \|\mathbf{A \times B}\|^2 +(\mathbf{A \cdot B})^2 = \|\mathbf A \|^2   \|\mathbf B \|^2 &lt;/math&gt;

If a vector '''A''' = (''A&lt;sub&gt;x&lt;/sub&gt;, A&lt;sub&gt;y&lt;/sub&gt;, A&lt;sub&gt;z&lt;/sub&gt;'') makes angles α, β, γ with an orthogonal set of ''x-'', ''y-'' and ''z-''axes, then:

:&lt;math&gt; \cos \alpha = \frac{ A_x }{ \sqrt {A_x^2 +A_y^2 +A_z^2} }  = \frac {A_x} {\| \mathbf A \|} \ , &lt;/math&gt;
and analogously for angles β, γ. Consequently:
:&lt;math&gt;\mathbf A = \|\mathbf A \|\left( \cos \alpha \  \hat{\mathbf  i}  +  \cos \beta\  \hat{\mathbf  j} +  \cos \gamma \ \hat{\mathbf  k}  \right) \ ,&lt;/math&gt;
with &lt;math&gt;\hat{\mathbf  i}, \ \hat{\mathbf  j}, \ \hat{\mathbf  k}&lt;/math&gt; unit vectors along the axis directions.

==Areas and volumes==

The area Σ of a [[parallelogram]] with sides ''A'' and ''B'' containing the angle θ is:
:&lt;math&gt; \Sigma = AB \ \sin \theta \ , &lt;/math&gt;
which will be recognized as the magnitude of the vector cross product of the vectors '''A''' and '''B''' lying along the sides of the parallelogram. That is:
:&lt;math&gt;\Sigma = \|\mathbf { A \times B } \| = \sqrt{ \|\mathbf A\|^2 \|\mathbf B\|^2 -(\mathbf{A \cdot B} )^2} \ . &lt;/math&gt;
The square of this expression is:&lt;ref name=Courant&gt;

{{cite book |title=Introduction to calculus and analysis, Volume II |author=Richard Courant, Fritz John |url=https://books.google.com/books?id=ngkQxS4eicgC&amp;pg=PA191 |pages=190–195 |chapter=Areas of parallelograms and volumes of parallelepipeds in higher dimensions  |isbn=3-540-66569-2 |year=2000 |publisher=Springer |edition=Reprint of original 1974 Interscience}}

&lt;/ref&gt;
:&lt;math&gt;\Sigma^2 = (\mathbf{A \cdot A })(\mathbf{B \cdot B })-(\mathbf{A \cdot B })(\mathbf{B \cdot A })=\Gamma(\mathbf A,\ \mathbf B ) \ , &lt;/math&gt;
where Γ('''A''', '''B''') is the [[Gram determinant]] of '''A''' and '''B''' defined by:

:&lt;math&gt;\Gamma(\mathbf A,\ \mathbf B )=\begin{vmatrix} \mathbf{A\cdot A} &amp; \mathbf{A\cdot B} \\
 \mathbf{B\cdot A} &amp; \mathbf{B\cdot B}  \end{vmatrix} \ . &lt;/math&gt;
In a similar fashion, the squared volume ''V'' of a [[parallelepiped]] spanned by the three vectors '''A''', '''B''' and '''C''' is given by the Gram determinant of the three vectors:&lt;ref name=Courant/&gt;
:&lt;math&gt;V^2 =\Gamma ( \mathbf A ,\ \mathbf B ,\  \mathbf C ) = \begin{vmatrix} \mathbf{A\cdot A} &amp; \mathbf{A\cdot B} &amp; \mathbf{A\cdot C} \\\mathbf{B\cdot A} &amp; \mathbf{B\cdot B} &amp; \mathbf{B\cdot C}\\
 \mathbf{C\cdot A} &amp; \mathbf{C\cdot B} &amp; \mathbf{C\cdot C}  \end{vmatrix} \ . &lt;/math&gt;
This process can be extended to ''n''-dimensions.

==Addition and multiplication of vectors==

Some of the following algebraic relations refer to the [[dot product]] and the [[cross product]] of vectors. These relations can be found in a variety of sources, for example, see Albright.&lt;ref name=Albright/&gt;
*&lt;math&gt; c (\mathbf{A}+\mathbf{B})=c\mathbf{A}+c\mathbf{B} &lt;/math&gt;; distributivity of multiplication by a scalar and addition
*&lt;math&gt; \mathbf{A}+\mathbf{B}=\mathbf{B}+\mathbf{A} &lt;/math&gt;; commutativity of addition
*&lt;math&gt; \mathbf{A}+(\mathbf{B}+\mathbf{C})=(\mathbf{A}+\mathbf{B})+\mathbf{C} &lt;/math&gt;; associativity of addition
*&lt;math&gt; \mathbf{A}\cdot\mathbf{B}=\mathbf{B}\cdot\mathbf{A} &lt;/math&gt;; commutativity of scalar (dot) product
*&lt;math&gt; \mathbf{A}\times\mathbf{B}=\mathbf{-B}\times\mathbf{A} &lt;/math&gt;; anticommutativity of vector cross product 
*&lt;math&gt; \left(\mathbf{A}+\mathbf{B}\right)\cdot\mathbf{C}=\mathbf{A}\cdot\mathbf{C}+\mathbf{B}\cdot\mathbf{C} &lt;/math&gt;; distributivity of addition wrt scalar product
*&lt;math&gt; \left(\mathbf{A}+\mathbf{B}\right)\times\mathbf{C}=\mathbf{A}\times\mathbf{C}+\mathbf{B}\times\mathbf{C} &lt;/math&gt;; distributivity of addition wrt vector cross product
*&lt;math&gt; \mathbf{A}\cdot\left(\mathbf{B}\times\mathbf{C}\right)=\mathbf{B}\cdot\left(\mathbf{C}\times\mathbf{A}\right)=\left(\mathbf{A}\times\mathbf{B}\right)\cdot\mathbf{C}&lt;/math&gt;
::::&lt;math&gt;=\left|\begin{array}{ccc}
A_{x} &amp; B_{x} &amp; C_{x}\\
A_{y} &amp; B_{y} &amp; C_{y}\\
A_{z} &amp; B_{z} &amp; C_{z}\end{array}\right| = [\mathbf{A, \ B,\  C }] &lt;/math&gt; ; [[scalar triple product]]
*&lt;math&gt; \mathbf{A\times}\left(\mathbf{B}\times\mathbf{C}\right)=\left(\mathbf{A}\cdot\mathbf{C}\right)\mathbf{B}-\left(\mathbf{A}\cdot\mathbf{B}\right)\mathbf{C} &lt;/math&gt;; [[vector triple product]]
*&lt;math&gt; \mathbf{\left(A\times B\right)\cdot}\left(\mathbf{C}\times\mathbf{D}\right)=\left(\mathbf{A}\cdot\mathbf{C}\right)\left(\mathbf{B}\cdot\mathbf{D}\right)-\left(\mathbf{B}\cdot\mathbf{C}\right)\left(\mathbf{A}\cdot\mathbf{D}\right) &lt;/math&gt;; [[Binet–Cauchy identity]] in three dimensions
:In particular, when '''A''' = '''C'''  and '''B''' = '''D''', the above reduces to:
::&lt;math&gt;(\mathbf{A} \times \mathbf{B}) \cdot (\mathbf{A} \times \mathbf{B}) = |\mathbf{A} \times \mathbf{B}|^2  =   (\mathbf{A} \cdot \mathbf{A}) (\mathbf{B} \cdot \mathbf{B})-(\mathbf{A} \cdot \mathbf{B})^2&lt;/math&gt;; [[Lagrange's identity]] in three dimensions  
*&lt;math&gt;[\mathbf{A},\mathbf{B},\mathbf{C}]\mathbf{D}=\left(\mathbf{A}\cdot\mathbf{D}\right)\left(\mathbf{B}\times\mathbf{C}\right)+\left(\mathbf{B}\cdot\mathbf{D}\right)\left(\mathbf{C}\times\mathbf{A}\right)+\left(\mathbf{C}\cdot\mathbf{D}\right)\left(\mathbf{A}\times\mathbf{B}\right)&lt;/math&gt;
*A vector quadruple product, which is also a vector, can be defined, which satisfies the following identities:&lt;ref name=Soni&gt;

{{cite book |title=Mechanics and relativity |author=Vidwan Singh Soni |url=https://books.google.com/books?id=-3H5V0LGBOgC&amp;pg=PA11 |pages=11–12 |chapter=§1.10.2 Vector quadruple product |publisher=PHI Learning Pvt. Ltd. |isbn=81-203-3713-1 |year=2009}}

&lt;/ref&gt;&lt;ref name=Gibbs&gt;This formula is applied to spherical trigonometry by 

{{cite book |title=Vector analysis: a text-book for the use of students of mathematics |author=Edwin Bidwell Wilson, Josiah Willard Gibbs |url=https://books.google.com/books?id=RC8PAAAAIAAJ&amp;pg=PA77 |chapter=§42 in ''Direct and skew products of vectors'' |publisher=Scribner |year=1901 |pages=77 ''ff''}}

&lt;/ref&gt;
: &lt;math&gt;(\mathbf{A} \times \mathbf{B}) \times (\mathbf{C} \times \mathbf{D}) = [\mathbf{A},\mathbf{B}, \mathbf{D}]\mathbf{C}-[\mathbf{A},\mathbf{B}, \mathbf{C}]\mathbf{D}=
[\mathbf{A},\mathbf{C}, \mathbf{D}]\mathbf{B}-[\mathbf{B}, \mathbf{C},\mathbf{D}]\mathbf{A}&lt;/math&gt;
:where ['''A''', '''B''', '''C'''] is the scalar [[triple product]] '''A''' · ('''B''' × '''C''') or the [[determinant]] of the [[matrix (mathematics)|matrix]] {'''A''', '''B''', '''C'''} with the components of these vectors as columns .
*In 3 dimensions, given any three non-coplanar vectors '''A''', '''B''', '''C''', any other vector '''D''' can be expressed in terms of these as:&lt;ref name=Coffin&gt;

{{cite book |title=Vector analysis: an introduction to vector-methods and their various applications to physics and mathematics |author=Joseph George Coffin |url=https://books.google.com/books?id=9mgGAQAAIAAJ&amp;pg=PA56 |page=56 |year=1911 |publisher=Wiley |edition=2nd}}

&lt;/ref&gt;
:&lt;math&gt;\mathbf D = \frac{\mathbf{D} \cdot (\mathbf{B} \times \mathbf{C})}{[\mathbf{A},\ \mathbf{B}, \ \mathbf{C}]}\ \mathbf A +\frac{\mathbf{D} \cdot (\mathbf{C} \times \mathbf{A})}{[\mathbf{A},\ \mathbf{B}, \ \mathbf{C}]}\ \mathbf B + \frac{\mathbf{D} \cdot (\mathbf{A} \times \mathbf{B})}{[\mathbf{A},\ \mathbf{B}, \ \mathbf{C}]}\ \mathbf C \ .&lt;/math&gt;

==See also==
*[[Vector space]]
*[[Geometric algebra]]

==References==
{{Reflist}}

[[Category:Vectors (mathematics and physics)]]
[[Category:Mathematical identities]]
[[Category:Mathematics-related lists]]</text>
      <sha1>jlj977tbo5shtq7f6dph08earzbedgp</sha1>
    </revision>
  </page>
  <page>
    <title>Well-pointed category</title>
    <ns>0</ns>
    <id>9501159</id>
    <revision>
      <id>702894605</id>
      <parentid>584323494</parentid>
      <timestamp>2016-02-02T07:21:09Z</timestamp>
      <contributor>
        <username>RileyBot</username>
        <id>18289815</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:Bot|Bot]]: Correcting [[MOS:HEADCAPS|capitalization]] or [[WP:LAYOUT|standardizing]] section headings) ([[User:RileyBot/16|Task 16]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="827">In [[category theory]], a category with a [[terminal object]] &lt;math&gt;1&lt;/math&gt; is '''well-pointed''' if for every pair of arrows &lt;math&gt;f,g:A\to B&lt;/math&gt; such that &lt;math&gt;f\neq g&lt;/math&gt;, there is an arrow &lt;math&gt;p:1\to A&lt;/math&gt; such that &lt;math&gt;f\circ p\neq g\circ p&lt;/math&gt;. (The arrows &lt;math&gt;p&lt;/math&gt; are called the [[global element]]s or ''points'' of the category; a well-pointed category is thus one that has "enough points" to distinguish non-equal arrows.)

==See also==
* [[Pointed category]]

==References==
* {{cite book | title=Nominal Sets: Names and Symmetry in Computer Science | volume=57 | series=Cambridge Tracts in Theoretical Computer Science | first=Andrew M. | last=Pitts | publisher=[[Cambridge University Press]] | year=2013 | isbn=1107017785 | page=16 }}

[[Category:Category theory]]


{{Categorytheory-stub}}</text>
      <sha1>1ec0h3pv4zwaje3yl9shoxrq5tlhw4c</sha1>
    </revision>
  </page>
</mediawiki>
