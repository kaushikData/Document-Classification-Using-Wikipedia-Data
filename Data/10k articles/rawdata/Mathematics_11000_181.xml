<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Algebraic theory</title>
    <ns>0</ns>
    <id>24497685</id>
    <revision>
      <id>816334878</id>
      <parentid>813977499</parentid>
      <timestamp>2017-12-20T18:24:04Z</timestamp>
      <contributor>
        <username>Siddharthist</username>
        <id>28122572</id>
      </contributor>
      <minor/>
      <comment>/* Category-based model-theoretical interpretation */ Remove duplicate See Also</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3270">Informally in [[mathematical logic]], an '''algebraic theory''' is one that uses axioms stated entirely in terms of equations between terms with [[free variable]]s.  Inequalities and quantifiers are specifically disallowed.  [[Sentential logic]] is the subset of [[first-order logic]] involving only algebraic sentences.

The notion is very close to the notion of [[algebraic structure]], which, arguably, may be just a synonym.

Saying that a theory is algebraic is a stronger condition than saying it is [[elementary theory|elementary]].

==Informal interpretation==

An algebraic theory consists of a collection of ''n''-ary functional terms with additional rules (axioms).

E.g. a group theory is an algebraic theory because it has three functional terms: a binary operation ''a * b'', a nullary operation ''1'' (neutral element), and a unary operation ''x'' → ''x&lt;sup&gt;−1&lt;/sup&gt;'' with the rules of associativity, neutrality and inversion respectively.

This is opposed to [[geometric theory]] which involves partial functions (or binary relationships) or existential quantors - see e.g. [[Euclidean geometry]] where the existence of points or lines is postulated.

==Category-based model-theoretical interpretation==
{{See also|Lawvere theory|Equational logic}}

An Algebraic Theory '''T''' is a [[category theory|category]] whose objects are natural numbers 0, 1, 2,..., and which, for each n, has an n-tuple of [[morphism]]s:

''proj&lt;sub&gt;i&lt;/sub&gt;'': ''n'' → 1, ''i'' = 1,..., ''n''

This allows interpreting ''n'' as a [[cartesian product]] of ''n'' copies of 1.

Example. Let's define an algebraic theory '''T''' taking hom(''n'', ''m'') to be ''m''-tuples of polynomials of ''n'' free variables ''X&lt;sub&gt;1&lt;/sub&gt;'',..., ''X&lt;sub&gt;n&lt;/sub&gt;'' with integer coefficients and with substitution as composition. In this case ''proj&lt;sub&gt;i&lt;/sub&gt;'' is the same as ''X&lt;sub&gt;i&lt;/sub&gt;''. This theory ''T'' is called the theory of [[commutative ring]]s.

In an algebraic theory, any morphism ''n'' → ''m'' can be described as ''m'' morphisms of signature ''n'' → 1. These latter morphisms are called ''n''-ary ''operations'' of the theory.

If ''E'' is a category with finite Cartesian products, the full subcategory Alg('''T''', ''E'') of the category of [[functor]]s ['''T''', ''E''] consisting of those functors that preserve finite products is called ''the category of'' '''T'''-''models'' or '''T'''-''algebras''.

Note that for the case of operation 2 → 1, the appropriate algebra ''A'' will define a morphism

''A''(2) ≈ ''A''(1)×''A''(1) → ''A''(1)

==See also==
*[[Algebraic sentence]]
*[[Algebraic definition]]

==References==
* [[F. W. Lawvere|Lawvere, F. W.]], 1963, ''[http://tac.mta.ca/tac/reprints/articles/5/tr5abs.html Functorial Semantics of Algebraic Theories, Proceedings of the National Academy of Sciences 50, No. 5 (November 1963), 869-872]''
* Adámek, J., Rosický, J., Vitale, E. M., ''[http://www.iti.cs.tu-bs.de/~adamek/algebraic.theories.pdf Algebraic Theories. A Categorical Introduction To General Algebra]''
* Kock, A., Reyes, G., Doctrines in categorical logic, in Handbook of Mathematical Logic, ed. [[Jon Barwise|J. Barwise]], North Holland 1977
* {{nlab|id=algebraic+theory|title=Algebraic theory}}

[[Category:Mathematical logic]]</text>
      <sha1>9zrouuo57uw33rquzbrkl1t4buqk5iz</sha1>
    </revision>
  </page>
  <page>
    <title>Asaṃkhyeya</title>
    <ns>0</ns>
    <id>1558470</id>
    <revision>
      <id>864432890</id>
      <parentid>864432612</parentid>
      <timestamp>2018-10-17T05:04:02Z</timestamp>
      <contributor>
        <ip>47.41.218.227</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1793">An '''{{IAST|asaṃkhyeya}}''' (Sanskrit: असंख्येय) is a [[Hindu]]/[[Buddhist]] name for the number 10&lt;sup&gt;140&lt;/sup&gt; or alternatively for the number &lt;math&gt;10^{(a\cdot2^b)}&lt;/math&gt; as it is listed in the [[Avatamsaka Sutra]].&lt;ref name="EncH"&gt;{{cite book |last=Garg |first=Ganga Ram |date=October 1, 1992 |title=Encyclopaedia of the Hindu World: Ar-Az|publisher=South Asia Books|isbn=8170223768 }}&lt;!--|accessdate=November 24, 2013--&gt;&lt;/ref&gt; Depending on the translation, the value is different. It is &lt;math&gt;10^{(5\cdot2^{103})}&lt;/math&gt; in the translation of Buddhabhadra, &lt;math&gt;10^{(7\cdot2^{103})}&lt;/math&gt; in that of Shikshananda and &lt;math&gt;10^{(10\cdot2^{104})}&lt;/math&gt; in that of Thomas Cleary, who may have made an error in calculation.{{cn|date=July 2014}}

Asamkhyeya is a Sanskrit word that appears often in the Buddhist texts. For example, [[Shakyamuni Buddha]] is said to have practiced for four great asamkhyeya kalpas before becoming a [[Buddha (title)|Buddha]]. Asamkhyeya means ‘incalculable’.&lt;ref name="VBS1"&gt;{{cite journal |last=Yong |first=Bhikshu Jin |date= |title=How Large is One Asamkhyeya  |url=http://www.drbachinese.org/vbs/publish/462/vbs462p042.pdf|journal=Vajra Bodhi Sea |publisher= |volume= |issue=November 2008 |pages=42-44 |doi= |accessdate=24 November 2013}}&lt;/ref&gt;

The word "{{IAST|asaṃkhyeya}}" literally means "innumerable" in the sense of "infinite" in Sanskrit.&lt;ref name="EncH"/&gt;
It is also a title of Vishnu and of Shiva.
The word comes up in [[Vishnu Sahasranama]] Stanza 27, "Asankyeyo-aprameyaatmaa:" one who has innumerable names and forms.

==See also==
*[[History of large numbers]]

==References==
{{reflist}}

{{Buddhism topics}}

{{DEFAULTSORT:Asamkhyeya}}
[[Category:Buddhist terminology]]
[[Category:Large integers]]


{{Num-stub}}</text>
      <sha1>dt4yuefvdzsyy2nz3tumrk1mdqix3zj</sha1>
    </revision>
  </page>
  <page>
    <title>Asymmetric norm</title>
    <ns>0</ns>
    <id>13341540</id>
    <revision>
      <id>838543833</id>
      <parentid>837164528</parentid>
      <timestamp>2018-04-27T17:47:53Z</timestamp>
      <contributor>
        <username>Josvebot</username>
        <id>14967932</id>
      </contributor>
      <minor/>
      <comment>v1.43b - [[WP:WCW]] project (Unicode control characters)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4045">In [[mathematics]], an '''asymmetric norm''' on a [[vector space]] is a generalization of the concept of a [[norm (mathematics)|norm]].

==Definition==

An '''asymmetric norm''' on a [[real number|real]] [[vector space]] ''V'' is a [[function (mathematics)|function]] &lt;math&gt; p:V\to[0,+\infty) &lt;/math&gt; that has the following properties:

* '''[[Subadditivity]]''', or the [[triangle inequality]]: ''p''(''v''&amp;nbsp;+&amp;nbsp;''w'')&amp;nbsp;≤&amp;nbsp;''p''(''v'')&amp;nbsp;+&amp;nbsp;''p''(''w'') for every two vectors ''v'',''w''&amp;nbsp;∈&amp;nbsp;''V''.
* '''[[homogeneous function|Homogeneity]]''': ''p''(''&amp;lambda;v'')&amp;nbsp;=&amp;nbsp;''&amp;lambda;p''(''v'') for every vector ''v''&amp;nbsp;∈&amp;nbsp;''X'' and every non-negative real number ''&amp;lambda;''&amp;nbsp;≥&amp;nbsp;0.
* '''[[Positive-definite function|Positive definiteness]]''': ''p''(''v'')&amp;nbsp;&gt;&amp;nbsp;0 unless ''v''&amp;nbsp;=&amp;nbsp;0.

Asymmetric norms differ from [[norm (mathematics)|norms]] in that they need not satisfy the equality ''p''(-''v'')&amp;nbsp;=&amp;nbsp;''p''(''v'').

If the condition of positive definiteness is omitted, then ''p'' is an '''asymmetric seminorm'''. A weaker condition than positive definiteness is '''non-degeneracy''': that for ''v''&amp;nbsp;≠&amp;nbsp;0, at least one of the two numbers ''p''(''v'') and ''p''(-''v'') is not zero.

== Examples ==

* On the [[real line]] '''R''', the function ''p'' given by

::&lt;math&gt;p(x) = \begin{cases} |x|, &amp; x \leq 0; \\ 2 |x|, &amp; x \geq 0; \end{cases}&lt;/math&gt;

:is an asymmetric norm but not a norm.

* In a real vector space &lt;math&gt; V &lt;/math&gt;, the ''Minkowski functional'' &lt;math&gt; p_B &lt;/math&gt; of a convex subset &lt;math&gt; B\subseteq V &lt;/math&gt; that contains the origin is defined by the formula

::&lt;math&gt; p_B(v) = \inf \left\{r \geq 0: v \in r B \right\}\,&lt;/math&gt; for &lt;math&gt; v\in V&lt;/math&gt;

:This functional is an asymmetric seminorm if &lt;math&gt; B &lt;/math&gt; is an absorbing set, which means that &lt;math&gt; \textstyle{ \bigcup_{r\geq 0} r B = V }&lt;/math&gt;, and ensures that &lt;math&gt; p(v) &lt;/math&gt; is finite for each &lt;math&gt; v\in V &lt;/math&gt;.

== Corresponce between asymmetric seminorms and convex subsets of the dual space ==

If &lt;math&gt; B^* \subseteq \mathbb R^n &lt;/math&gt; is a [[convex set]] that contains the origin, then an asymmetric seminorm &lt;math&gt; p &lt;/math&gt; can be defined on &lt;math&gt; \mathbb R^n &lt;/math&gt; by the formula
::&lt;math&gt;\textstyle{ p(v) = \max_{\varphi\in B^*} \langle \varphi,v\rangle }&lt;/math&gt;.
For instance, if &lt;math&gt; B^*\subseteq\mathbb R^2 &lt;/math&gt; is the square with vertices &lt;math&gt; (\pm 1,\pm 1) &lt;/math&gt;, then &lt;math&gt; p &lt;/math&gt; is the [[taxicab norm]] &lt;math&gt; v=(v_0,v_1) \mapsto |v_0|+|v_1| &lt;/math&gt;. Different convex sets yield different seminorms, and every asymmetric seminorm on &lt;math&gt; \mathbb R^n &lt;/math&gt; can be obtained from some convex set, called its '''dual unit ball'''. Therefore, asymmetric seminorms are in [[bijection|one-to-one correspondence]] with convex sets that contain the origin. The seminorm &lt;math&gt; p &lt;/math&gt; is 
* positive definite if and only if &lt;math&gt; B^* &lt;/math&gt; contains the origin in its [[interior (mathematics)|interior]],
* degenerate if and only if &lt;math&gt; B^* &lt;/math&gt; is contained in a [[linear subspace]] of dimension less than &lt;math&gt; n &lt;/math&gt;, and
* symmetric if and only if &lt;math&gt; B^*=-B^* &lt;/math&gt;.

More generally, if &lt;math&gt; V &lt;/math&gt; is a [[finite-dimensional]] real vector space and &lt;math&gt; B^* \subseteq V^* &lt;/math&gt; is a compact convex subset of the [[dual space]] &lt;math&gt; V^* &lt;/math&gt; that contains the origin, then &lt;math&gt;\textstyle{ p(v) = \max_{\varphi\in B^*} \varphi(v) }&lt;/math&gt; is an asymmetric seminorm on &lt;math&gt; V &lt;/math&gt;.

==References==

* {{cite journal
| last = Cobzaş
| first = S.
| title = Compact operators on spaces with asymmetric norm
| journal = Stud. Univ. Babeş-Bolyai Math.
| volume= 51
| year = 2006
| issue = 4
| pages = 69&amp;ndash;87
| issn = 0252-1938
| mr = 2314639
}}
* S. Cobzas, ''Functional Analysis in Asymmetric Normed Spaces'', Frontiers in Mathematics, Basel: Birkhäuser, 2013; {{ISBN|978-3-0348-0477-6}}.  

[[Category:Linear algebra]]
[[Category:Norms (mathematics)]]


{{Linear-algebra-stub}}</text>
      <sha1>arc0tc9ptmwr8d69ivmqguap6vjf929</sha1>
    </revision>
  </page>
  <page>
    <title>Calogero–Degasperis–Fokas equation</title>
    <ns>0</ns>
    <id>16815031</id>
    <revision>
      <id>857263505</id>
      <parentid>748870756</parentid>
      <timestamp>2018-08-30T16:13:29Z</timestamp>
      <contributor>
        <ip>132.72.23.23</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="620">In mathematics, the '''Calogero–Degasperis–Fokas equation''' is the nonlinear [[partial differential equation]]

:&lt;math&gt;\displaystyle u_t=u_{xxx}-\frac{1}{8}u_x^3 + u_x\left(Ae^u+Be^{-u}\right).&lt;/math&gt;

This equation was named after [[F. Calogero]], [[A. Degasperis]], and [[A. Fokas]].

==See also ==
*[[Boomeron equation]]
*[[Zoomeron equation]]

==External links==
* {{mathworld|urlname=Calogero-Degasperis-FokasEquation|title=Calogero–Degasperis–Fokas Equation}}

{{DEFAULTSORT:Calogero-Degasperis-Fokas equation}}
[[Category:Partial differential equations]]
[[Category:Integrable systems]]
{{analysis-stub}}</text>
      <sha1>ph9lsxcijp6ikfou70v6d0i7buc4hxu</sha1>
    </revision>
  </page>
  <page>
    <title>Carry flag</title>
    <ns>0</ns>
    <id>5503176</id>
    <revision>
      <id>859269297</id>
      <parentid>855727393</parentid>
      <timestamp>2018-09-12T22:35:36Z</timestamp>
      <contributor>
        <ip>99.110.54.152</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8694">In [[computer processor]]s the '''carry flag''' (usually indicated as the '''C''' flag) is a single [[bit]] in a system [[Status register|status (flag) register]] used to indicate when an [[arithmetic]] [[Carry (arithmetic)|carry]] or borrow has been generated out of the [[Most significant bit|most significant]] [[Arithmetic logic unit|ALU]] bit position. The carry flag enables numbers larger than a single ALU width to be added/subtracted by carrying (adding) a binary digit from a partial addition/subtraction to the [[least significant bit]] position of a more significant word. It is also used to extend [[bit shift]]s and rotates in a similar manner on many processors (sometimes done via a dedicated '''X''' flag). For subtractive operations, two (opposite) conventions are employed as most machines set the carry flag on borrow while some machines (such as the [[MOS Technology 6502|6502]] and the [[PIC microcontroller|PIC]]) instead reset the carry flag on borrow (and vice versa).

== Uses ==
The carry flag is affected by the result of most arithmetic (and typically several bit wise) instructions and is also used as an input to many of them. Several of these instructions have two forms which either read or ignore the carry. In [[assembly language]]s these instructions are represented by [[Assembly language#Opcode mnemonics and extended mnemonics|mnemonics]] such as ADD/SUB, ADC/SBC (ADD/SUB including carry), SHL/SHR ([[bit shift]]s), ROL/ROR (bit rotates), RCR/RCL (rotate through carry), and so on.&lt;ref name = "intel"&gt;{{cite web |url=http://download.intel.com/design/PentiumII/manuals/24319102.PDF|format = PDF| title=Intel Architecture Software Developer's Manual, Volume 2: Instruction Set Reference Manual|accessdate=2007-10-25}}&lt;/ref&gt; The use of the carry flag in this manner enables multi-[[Word (data type)|word]] add, subtract, shift, and rotate operations.

An example is what happens if one were to add 255 and 255 using [[8-bit]] registers. The result should be 510 which is 1_1111_1110 in binary, requiring 9 bits. The 8 least significant bits always stored in the register would be 1111_1110 binary (254 decimal) but since there is carry out of bit 7 (the eight bit), the carry is set, indicating that the result needs 9 bits. The valid 9-bit result is the concatenation of the carry flag with the result.

For x86 ALU size of 8 bits, an 8-bit two's complement interpretation, the addition operation 1111_1111 + 1111_1111 results in 1_1111_1110, Carry_Flag set, Sign_Flag set, and Overflow_Flag clear.

If 1111_1111 represents two's complement signed integer -1 (ADD al,-1), then the interpertation of the result is 1111_1110 because Overflow_Flag is clear, and Carry_Flag is ignored. The sign of the result is negative, because Sign_Flag is set. 1111_1110 is the two's complement form of signed integer -2.

If 1111_1111 represents unsigned integer binary number 255 (ADD al,255), then the interpertation of the result that the Carry_Flag cannot be ignored. The Overflow_Flag and the Sign_Flag are ignored.

Another example may be an 8-bit [[Processor register|register]] with the bit pattern 0101_0101 and the carry flag set; if we execute a ''rotate left through carry'' instruction, the result would be 1010_1011 with the carry flag cleared because the most significant bit (bit 7) was rotated into the carry while the carry was rotated into the least significant bit (bit 0).

The early microprocessors [[Intel 4004]] and [[Intel 8008]] had specific instructions to set as well as reset the carry flag explicitly. However, the later [[Intel 8080]] (and [[Z80]]) did not include an explicit reset carry opcode as this could be done equally fast via one of the bitwise AND, OR or XOR instructions (which do not use the carry flag).

The carry flag is also often used following comparison instructions, which are typically implemented by subtractive operations,  to allow a decision to be made about which of the two compared values is lower than (or greater or equal to) the other.  Branch instructions which examine the carry flag are often represented by [[Assembly language#Opcode mnemonics and extended mnemonics|mnemonics]] such as BCC and BCS to branch if the carry is clear, or branch if the carry is set respectively. When used in this way the carry flag provides a mechanism for comparing the values as unsigned integers. This is in contrast to the [[overflow flag]] which provides a mechanism for comparing the values as signed integer values.

== Carry flag vs. borrow flag ==
{{Refimprove section|date=July 2015|talk=How to improve references in "Carry flag vs. borrow flag"}}
While the carry flag is well-defined for addition, there are two ways in common use to use the carry flag for subtraction operations.

The first uses the bit as a borrow flag, setting it if ''a''&amp;lt;''b'' when computing ''a''−''b'', and a borrow must be performed.  If ''a''≥''b'', the bit is cleared.  A '''subtract with borrow''' (SBB) instruction will compute ''a''−''b''−''C'' = ''a''−(''b''+''C''), while a subtract without borrow (SUB) acts as if the borrow bit were clear.  The [[8080]], [[Z80]], [[Intel MCS-51|8051]], [[x86]]&lt;ref name=intel/&gt; and [[68k]] families (among others) use a borrow bit.

The second takes advantage of the identity that −''x'' = [[Bitwise NOT|not]](''x'')+1 and computes ''a''−''b'' as ''a''+not(''b'')+1.  The carry flag is set according to this addition, and '''subtract with carry''' computes ''a''+not(''b'')+''C'', while subtract without carry acts as if the carry bit were set.  The result is that the carry bit is set if ''a''≥''b'', and clear if ''a''&amp;lt;''b''.  The [[System/360]],&lt;ref&gt;{{cite book |title=IBM System/360 Principles of Operation |url=http://bitsavers.informatik.uni-stuttgart.de/pdf/ibm/360/princOps/A22-6821-0_360PrincOps.pdf |page=28 |id=IBM Form A22-6821-0}}&lt;/ref&gt; [[MOS Technology 6502|6502]], [[MSP430]], [[ARM architecture|ARM]] and [[PowerPC]] processors use this convention.  The 6502 is a particularly well-known example because it does not have a subtract ''without'' carry operation, so programmers must ensure that the carry flag is set before every subtract operation where a borrow is not required.
{| class="wikitable" style="margin: 0 auto; text-align: center;"
|+ Summary of different uses of carry flag in subtraction
|-
! Carry or&lt;br/&gt;borrow bit
! Subtract without&lt;br/&gt;carry/borrow
! Subtract&lt;br/&gt;with borrow
! Subtract&lt;br/&gt;with carry
|-
! ''C'' = 0
|rowspan=2 | ''a'' − ''b''&lt;br/&gt;= ''a'' + not(''b'') + '''1'''
| ''a'' − ''b'' − '''0'''&lt;br/&gt;= ''a'' + not(''b'') + '''1'''
| ''a'' + not(''b'') + '''0'''&lt;br/&gt;= ''a'' − ''b'' − '''1'''
|-
! ''C'' = 1

| ''a'' − ''b'' − '''1'''&lt;br/&gt;= ''a'' + not(''b'') + '''0'''
| ''a'' + not(''b'') + '''1'''&lt;br/&gt;= ''a'' − ''b'' − '''0'''
|}

Most commonly, the first alternative is referred to as a "subtract with borrow", while the second is called a "subtract with carry".  However, there are exceptions in both directions; the [[VAX]], [[NS320xx]], and [[Atmel AVR]] architectures use the borrow bit convention, but call their ''a''−''b''−''C'' operation "subtract with carry" (&lt;code&gt;SBWC&lt;/code&gt;, &lt;code&gt;SUBC&lt;/code&gt; and &lt;code&gt;SBC&lt;/code&gt;).  The [[PA-RISC]] and [[PICmicro]] architectures use the carry bit convention, but call their ''a''+not(''b'')+''C'' operation "subtract with borrow" (&lt;code&gt;SUBB&lt;/code&gt; and &lt;code&gt;SUBWFB&lt;/code&gt;).
&lt;!-- SPARC also uses a borrow bit, and although the opcode is SUBX ("subtract extended"), the text calls it "subtract with carry".--&gt;

The [[ST6/ST7]] 8-bit microcontrollers are perhaps the most confusing of all.  Although they do not have any sort of "subtract with carry" instruction, they do have a carry bit which is set by a subtract instruction, and the convention depends on the processor model.  The ST60 processor uses the "carry" convention, while the ST62 and ST63 processors use the "borrow" convention.&lt;ref&gt;{{cite web |title=ST6 Family Programming Manual |version=Revision 2.0 |date=October 2004 |publisher=[[STMicroelectronics]] |url=http://www.st.com/content/ccc/resource/technical/document/programming_manual/4d/05/d1/a5/a0/9e/40/8b/CD00004606.pdf/files/CD00004606.pdf/jcr:content/translations/en.CD00004606.pdf#page=42 |page=42 |accessdate=2017-02-28}}&lt;/ref&gt;

==See also==
* [[Binary arithmetic]]
* [[Half-carry flag]]
* [[Status register]]

==References==
{{reflist}}

==External links==
* [http://teaching.idallen.com/dat2343/10f/notes/040_overflow.txt Carry Flag and Overflow Flag in binary arithmetic]
* [https://brodowsky.it-sky.net/2013/12/22/carry-bit-how-does-it-work/ Carry Bit: How does it work?]

{{X86 assembly topics}}

[[Category:Computer arithmetic]]</text>
      <sha1>9906lpb7kqjzapl4fcx2hrkb94zkihf</sha1>
    </revision>
  </page>
  <page>
    <title>Cavalieri's quadrature formula</title>
    <ns>0</ns>
    <id>30839740</id>
    <revision>
      <id>870074553</id>
      <parentid>856722857</parentid>
      <timestamp>2018-11-22T05:45:25Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 2 sources and tagging 0 as dead. #IABot (v2.0beta10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16764">{{dablink|Not to be confused with [[Cavalieri's principle]].}}
[[File:X cubed plot.svg|thumb|Cavalieri's quadrature formula computes the area under the [[cubic curve]], together with other higher powers.]]
In [[calculus]], '''Cavalieri's quadrature formula''', named for 17th-century Italian mathematician [[Bonaventura Cavalieri]], is the [[integral]]

:&lt;math&gt;\int_0^a x^n\,dx = \tfrac{1}{n+1}\, a^{n+1} \qquad n \geq 0,&lt;/math&gt;

and generalizations thereof. This is the [[definite integral]] form; the [[indefinite integral]] form is:

:&lt;math&gt;\int x^n\,dx = \tfrac{1}{n+1}\, x^{n+1} + C \qquad n \neq -1.&lt;/math&gt;

There are additional [[#Forms|forms]], listed below. Together with the [[linearity]] of the integral, this formula allows one to compute the integrals of all polynomials.

The term "[[Numerical integration|quadrature]]" is a traditional term for [[area]]; the integral is geometrically interpreted as the area under the curve ''y''&amp;nbsp;=&amp;nbsp;''x''&lt;sup&gt;''n''&lt;/sup&gt;. Traditionally important cases are ''y''&amp;nbsp;=&amp;nbsp;''x''&lt;sup&gt;2&lt;/sup&gt;, the quadrature of the [[parabola]], known in antiquity, and ''y''&amp;nbsp;=&amp;nbsp;1/''x'', the quadrature of the hyperbola, whose value is a [[logarithm]].

== Forms ==
=== Negative ''n'' ===
For negative values of ''n'' (negative powers of ''x''), there is a [[Mathematical singularity|singularity]] at ''x''&amp;nbsp;=&amp;nbsp;0, and thus the definite integral is based at 1, rather than 0, yielding:

:&lt;math&gt;\int_1^a x^n\,dx = \frac{1}{n+1} (a^{n+1} - 1) \qquad n \neq -1.&lt;/math&gt;

Further, for negative fractional (non-integer) values of ''n,'' the power ''x''&lt;sup&gt;''n''&lt;/sup&gt; is not [[well-defined]], hence the indefinite integral is only defined for positive ''x.'' However, for ''n'' a negative integer the power ''x''&lt;sup&gt;''n''&lt;/sup&gt; is defined for all non-zero ''x,'' and the indefinite integrals and definite integrals are defined, and can be computed via a symmetry argument, replacing ''x'' by &amp;minus;''x,'' and basing the negative definite integral at&amp;nbsp;&amp;minus;1.

Over the complex numbers the definite integral (for negative values of ''n'' and ''x'') can be defined via [[contour integration]], but then depends on choice of path, specifically [[winding number]] – the geometric issue is that the function defines a [[covering space]] with a singularity at&amp;nbsp;0.

=== ''n'' = &amp;minus;1 ===
There is also the exceptional case ''n''&amp;nbsp;=&amp;nbsp;&amp;minus;1, yielding a [[logarithm]] instead of a power of&amp;nbsp;''x:''

:&lt;math&gt;\int_1^a \frac{1}{x}\,dx = \ln a,&lt;/math&gt;
:&lt;math&gt;\int \frac{1}{x}\,dx = \ln x + C, \qquad x &gt; 0&lt;/math&gt;

(where "ln" means the [[natural logarithm]], i.e. the logarithm to the base ''[[e (mathematical constant)|e]]''&amp;nbsp;=&amp;nbsp;2.71828...).

The improper integral is often extended to negative values of ''x'' via the conventional choice:

:&lt;math&gt;\int \frac{1}{x}\,dx = \ln |x| + C, \qquad x \neq 0.&lt;/math&gt;

Note the use of the [[absolute value]] in the indefinite integral; this is to provide a unified form for the integral, and means that the integral of this odd function is an even function, though the logarithm is only defined for positive inputs, and in fact, different constant values of ''C'' can be chosen on either side of 0, since these do not change the derivative. The more general form is thus:&lt;ref&gt;"[http://golem.ph.utexas.edu/category/2012/03/reader_survey_logx_c.html Reader Survey: log|''x''| + ''C'']", Tom Leinster, ''The ''n''-category Café'', March 19, 2012&lt;/ref&gt;
:&lt;math&gt;\int\frac{1}{x} \, dx= \begin{cases}
\ln |x| + C^- &amp; x &lt; 0 \\
\ln |x| + C^+ &amp; x &gt; 0
\end{cases}&lt;/math&gt;
Over the complex numbers there is not a global antiderivative for 1/''x'', due this function defining a non-trivial [[covering space]]; this form is special to the real numbers.

Note that the definite integral starting from 1 is not defined for negative values of ''a,'' since it passes through a singularity, though since 1/''x'' is an [[odd function]], one can base the definite integral for negative powers at&amp;nbsp;&amp;minus;1. If one is willing to use [[improper integral]]s and compute the [[Cauchy principal value]], one obtains &lt;math&gt;\int_{-c}^c \frac{1}{x}\,dx = 0,&lt;/math&gt; which can also be argued by symmetry (since the logarithm is odd), so &lt;math&gt;\int_{-1}^1 \frac{1}{x}\,dx = 0,&lt;/math&gt; so it makes no difference if the definite integral is based at 1 or&amp;nbsp;&amp;minus;1. As with the indefinite integral, this is special to the real numbers, and does not extend over the complex numbers.

=== Alternative forms ===
The integral can also be written with indexes shifted, which simplify the result and make the relation to ''n''-dimensional differentiation and the ''n''-cube clearer:
:&lt;math&gt;\int_0^a x^{n-1}\,dx = \tfrac{1}{n} a^n \qquad n \geq 1.&lt;/math&gt;
:&lt;math&gt;\int x^{n-1}\,dx = \tfrac{1}{n} x^n + C \qquad n \neq 0.&lt;/math&gt;

More generally, these formulae may be given as:
:&lt;math&gt;\int (ax + b)^n dx= \frac{(ax + b)^{n+1}}{a(n + 1)} + C \qquad\mbox{(for } n\neq -1\mbox{)}\,\!&lt;/math&gt;
:&lt;math&gt;\int\frac{1}{ax + b} dx= \frac{1}{a}\ln\left|ax + b\right| + C&lt;/math&gt;
:More generally:
::&lt;math&gt;\int\frac{1}{ax + b} \, dx= \begin{cases}
\frac{1}{a}\ln\left|ax + b\right| + C^- &amp; x &lt; -b/a \\
\frac{1}{a}\ln\left|ax + b\right| + C^+ &amp; x &gt; -b/a
\end{cases}&lt;/math&gt;

== Proof ==
The modern proof is to use an anti-derivative: the derivative of ''x''&lt;sup&gt;''n''&lt;/sup&gt; is shown to be ''nx''&lt;sup&gt;''n''&amp;minus;1&lt;/sup&gt; – for non-negative integers. This is shown from the [[binomial formula]] and the [[definition of the derivative]] – and thus by the [[fundamental theorem of calculus]] the [[antiderivative]] is the integral. This method fails for &lt;math&gt;\int \frac{1}{x}\,dx,&lt;/math&gt; as the [[candidate solution|candidate]] antiderivative is &lt;math&gt;\frac{1}{0} \cdot x^0&lt;/math&gt;, which is undefined due to division by zero. The [[logarithm]] function, which is the actual antiderivative of 1/''x'', must be introduced and examined separately.

[[Image:BinomialTheorem.png|right|315px|thumb|The derivative &lt;math&gt;(x^n)'=nx^{n-1}&lt;/math&gt; can be geometrized as the infinitesimal change in volume of the ''n''-cube, which is the area of ''n'' faces, each of dimension ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1.&lt;br /&gt;
Integrating this picture – stacking the faces – geometrizes the fundamental theorem of calculus, yielding a decomposition of the ''n''-cube into ''n'' pyramids, which is a geometric proof of Cavalieri's quadrature formula.]]
For positive integers, this proof can be geometrized:&lt;ref&gt;{{Harv|Barth|2004}}, {{Harv|Carter|Champanerkar|2006}}&lt;/ref&gt; if one considers the quantity ''x''&lt;sup&gt;''n''&lt;/sup&gt; as the volume of the ''n''-cube (the [[hypercube]] in ''n'' dimensions), then the derivative is the change in the volume as the side length is changed – this is ''x''&lt;sup&gt;''n''&amp;minus;1&lt;/sup&gt;, which can be interpreted as the area of ''n'' faces, each of dimension ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 (fixing one vertex at the origin, these are the ''n'' faces not touching the vertex), corresponding to the cube increasing in size by growing in the direction of these faces – in the 3-dimensional case, adding 3 infinitesimally thin squares, one to each of these faces. Conversely, geometrizing the fundamental theorem of calculus, stacking up these infinitesimal (''n''&amp;nbsp;&amp;minus;&amp;nbsp;1) cubes yields a (hyper)-pyramid, and ''n'' of these pyramids form the ''n''-cube, which yields the formula. Further, there is an ''n''-fold cyclic symmetry of the ''n''-cube around the diagonal cycling these pyramids (for which a pyramid is a [[fundamental domain]]). In the case of the cube (3-cube), this is how the volume of a pyramid was originally rigorously established: the cube has 3-fold symmetry, with fundamental domain a pyramids, dividing the cube into 3 pyramids, corresponding to the fact that the volume of a pyramid is one third of the base times the height. This illustrates geometrically the equivalence between the quadrature of the parabola and the volume of a pyramid, which were computed classically by different means.

Alternative proofs exist – for example, [[Pierre de Fermat|Fermat]] computed the area via an algebraic trick of dividing the domain into certain intervals of unequal length;&lt;ref&gt;See Rickey.&lt;/ref&gt; alternatively, one can prove this by recognizing a symmetry of the graph ''y''&amp;nbsp;=&amp;nbsp;''x''&lt;sup&gt;''n''&lt;/sup&gt; under inhomogeneous dilation (by ''d'' in the ''x'' direction and ''d''&lt;sup&gt;''n''&lt;/sup&gt; in the ''y'' direction, algebraicizing the ''n'' dimensions of the ''y'' direction),&lt;ref&gt;{{Harv|Wildberger|2002}}&lt;/ref&gt; or deriving the formula for all integer values by expanding the result for ''n''&amp;nbsp;=&amp;nbsp;&amp;minus;1 and comparing coefficients.&lt;ref&gt;{{Harv|Bradley|2003}}&lt;/ref&gt;

== History ==
[[Image:Parabolic Segment.svg|thumb|Archimedes computed the area of parabolic segments in his ''[[The Quadrature of the Parabola]]''.]]
A detailed discussion of the history, with original sources, is given in {{Harv|Laubenbacher|Pengelley|1998|loc=Chapter 3, Analysis: Calculating Areas and Volumes}}; see also [[history of calculus]] and [[Integral#History|history of integration]].

The case of the parabola was proven in antiquity by the ancient Greek mathematician [[Archimedes]] in his ''[[The Quadrature of the Parabola]]'' (3rd century BC), via the [[method of exhaustion]]. Of note is that Archimedes computed the area ''inside'' a parabola – a so-called "parabolic segment" – rather than the area under the graph ''y''&amp;nbsp;=&amp;nbsp;''x''&lt;sup&gt;2&lt;/sup&gt;, which is instead the perspective of [[Cartesian geometry]]. These are equivalent computations, but reflect a difference in perspective. The Ancient Greeks, among others, also computed the volume of a [[pyramid (geometry)|pyramid]] or [[cone (geometry)|cone]], which is mathematically equivalent.

In the 11th century, the [[Islamic mathematics|Islamic mathematician]] [[Ibn al-Haytham]] (known as ''Alhazen'' in Europe) computed the integrals of [[cubic polynomial|cubics]] and [[quartic polynomial|quartics]] (degree three and four) via [[mathematical induction]], in his ''[[Book of Optics]]''.&lt;ref name=Katz&gt;Victor J. Katz (1995), "Ideas of Calculus in Islam and India", ''Mathematics Magazine'' '''68''' (3): 163–174 [165–9 &amp; 173–4]&lt;/ref&gt;

The case of higher integers was computed by Cavalieri for ''n'' up to 9, using his method of indivisibles ([[Cavalieri's principle]]).&lt;ref&gt;{{Harv|Struik|1986|loc=pp. 215–216}}&lt;/ref&gt; He interpreted these as higher integrals as computing higher-dimensional volumes, though only informally, as higher-dimensional objects were as yet unfamiliar.&lt;ref&gt;{{Harv|Laubenbacher|Pengelley|1998}} – see [http://www.math.nmsu.edu/~history/book/analysissynopsis.html Informal pedagogical synopsis of the Analysis chapter] for brief form&lt;/ref&gt; This method of quadrature was then extended by Italian mathematician [[Evangelista Torricelli]] to other curves such as the [[cycloid]], then the formula was generalized to fractional and negative powers by English mathematician [[John Wallis]], in his ''[[Arithmetica Infinitorum]]'' (1656), which also standardized the notion and notation of rational powers – though Wallis incorrectly interpreted the exceptional case ''n''&amp;nbsp;=&amp;nbsp;&amp;minus;1 (quadrature of the hyperbola) – before finally being put on rigorous ground with the development of [[integral calculus]].

Prior to Wallis's formalization of fractional and negative powers, which allowed ''explicit'' functions &lt;math&gt;y=x^{p/q},&lt;/math&gt; these curves were handled ''implicitly,'' via the equations &lt;math&gt;x^p=ky^q&lt;/math&gt; and &lt;math&gt;x^py^q=k&lt;/math&gt; (''p'' and ''q'' always positive integers) and referred to respectively as '''higher parabolae''' and '''higher hyperbolae''' (or "higher parabolas" and "higher hyperbolas"). [[Pierre de Fermat]] also computed these areas (except for the exceptional case of &amp;minus;1) by an algebraic trick – he computed the quadrature of the higher hyperbolae via dividing the line into equal intervals, and then computed the quadrature of the higher parabolae by using a division into ''unequal'' intervals, presumably by inverting the divisions he used for hyperbolae.&lt;ref&gt;See Rickey reference for discussion and further references.&lt;/ref&gt; However, as in the rest of his work, Fermat's techniques were more ad hoc tricks than systematic treatments, and he is not considered to have played a significant part in the subsequent development of calculus.

Of note is that Cavalieri only compared areas to areas and volumes to volumes – these always having ''dimensions,'' while the notion of considering an area as consisting of ''units'' of area (relative to a standard unit), hence being unitless, appears to have originated with Wallis;&lt;ref&gt;Ball, 281&lt;/ref&gt;&lt;ref&gt;Britannica, 171&lt;/ref&gt; Wallis studied fractional and negative powers, and the alternative to treating the computed values as unitless numbers was to interpret fractional and negative dimensions.

The exceptional case of &amp;minus;1 (the standard hyperbola) was first successfully treated by [[Grégoire de Saint-Vincent]] in his ''Opus geometricum quadrature circuli et sectionum coni'' (1647), though a formal treatment had to wait for the development of the [[natural logarithm]], which was accomplished by [[Nicholas Mercator]] in his ''Logarithmotechnia'' (1668).

== References ==
{{reflist}}

=== History ===
{{refbegin}}
* Cavalieri, ''Geometria indivisibilibus (continuorum nova quadam ratione promota)'' (Geometry, exposed in a new manner with the aid of indivisibles of the continuous), 1635.
* Cavalieri, ''Exercitationes Geometricae Sex'' ("Six Geometrical Exercises"), 1647
** in [[Dirk Jan Struik]], editor, ''A source book in mathematics, 1200–1800'' (Princeton University Press, Princeton, New Jersey, 1986). {{ISBN|0-691-08404-1}}, {{ISBN|0-691-02397-2}} (pbk).
* ''Mathematical expeditions: chronicles by the explorers,'' Reinhard Laubenbacher, David Pengelley, 1998, Section 3.4: "Cavalieri Calculates Areas of Higher Parabolas", [https://books.google.com/books?id=ubFg7DI83JoC&amp;pg=PA125 pp. 123–127/128]
* ''A short account of the history of mathematics,'' Walter William Rouse Ball, "Cavalieri", [https://books.google.com/books?id=_sT_psl3uYkC&amp;pg=PA278 p. 278–281]
* "[http://eom.springer.de/i/i050950.htm Infinitesimal calculus]", ''Encyclopaedia of Mathematics''
* ''The Britannica Guide to Analysis and Calculus,'' by Educational Britannica Educational, [https://books.google.com/books?id=ML5Uuo16D58C&amp;pg=PA171 p. 171] – discusses Wallace primarily
{{refend}}

=== Proofs ===
{{refbegin}}
* "[https://web.archive.org/web/20110720101905/http://www.math.usma.edu/people/rickey/hm/CalcNotes/Fermat-Integration.pdf Fermat's Integration of Powers]", in ''[https://web.archive.org/web/20110720102613/http://www.math.usma.edu/people/rickey/hm/CalcNotes/default.htm Historical Notes for Calculus Teachers]'' by [https://web.archive.org/web/20110720102654/http://www.math.usma.edu/people/rickey/ V. Frederick Rickey] – gives Fermat's algebraic proof of the formula in modern language
* {{cite journal
|last1=Wildberger
|first1=N. J.
|title=A new proof of Cavalieri's quadrature formula
|journal=The American Mathematical Monthly
|volume=109
|issue=9
|pages=843–845
|year=2002
|doi=10.2307/3072373
|jstor=3072373
}}
* {{Cite journal
| last = Bradley
| first = David M.
| title = Remark on Cavalieri's quadrature formula
| arxiv = math/0505059
| journal = The American Mathematical Monthly
| volume = 110| issue = 5| page = 437
|date=May 2003
| bibcode = 2005math......5059B
| postscript =, appeared in print at end of [https://www.jstor.org/pss/3647831 Zeros of the Alternating Zeta Function on the Line R(S) = 1]
}}
*{{cite journal
|last1 = Barth
|first1 = N. R.
|title = Computing Cavalieri's quadrature formula by a symmetry of the n-cube
|journal = The American Mathematical Monthly
|volume = 111
|issue = 9
|pages = 811–813
|year = 2004
|doi = 10.2307/4145193
|jstor = 4145193
}}
*{{Cite arxiv
| last1 = Carter
| first1 = J. Scott
| last2 = Champanerkar
| first2 = Abhijit
| title = A geometric method to compute some elementary integrals
| eprint = math/0608722
| year = 2006
}}
* ''A geometric proof of Cavalieri's quadrature formula,'' [http://www.lix.polytechnique.fr/Labo/Ilan.Vardi/index.html Ilan Vardi] &lt;!-- unpublished, a short exposition of “dividing a cube from the center” into 2n pyramids --&gt;
{{refend}}

== External links ==
* {{mathworld |title=Cavalieri's Quadrature Formula |id=CavalierisQuadratureFormula }}
* [http://researchspace.csir.co.za/dspace/bitstream/10204/5267/1/Grobler5_2011.pdf Cavalieri Integration]
* [https://books.google.com/books?id=XmRsZhJZGhEC&amp;lpg=PA214&amp;hl=fr&amp;pg=PA214#v=onepage&amp;q&amp;f=false D. J. Struik, ''A Source Book in Mathematics, 1200-1800'', p. 214]

[[Category:Integrals]]
[[Category:Polynomials]]</text>
      <sha1>q9765mymfw8x88w17ipb8jrbv4z7q0i</sha1>
    </revision>
  </page>
  <page>
    <title>Closed-loop transfer function</title>
    <ns>0</ns>
    <id>40885</id>
    <revision>
      <id>843164049</id>
      <parentid>800635574</parentid>
      <timestamp>2018-05-27T09:23:01Z</timestamp>
      <contributor>
        <username>Störm</username>
        <id>25154634</id>
      </contributor>
      <minor/>
      <comment>Moving from [[Category:Control theory]] to [[Category:Classical control theory]] using [[c:Help:Cat-a-lot|Cat-a-lot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1375">A '''closed-loop transfer function''' in [[control theory]] is a mathematical expression ([[algorithm]]) describing the net result of the effects of a closed ([[feedback]]) [[loop (telecommunication)|loop]] on the input [[signal (information theory)|signal]] to the circuits enclosed by the loop.

== Overview ==
The closed-loop [[transfer function]] is measured at the output. The output signal [[waveform]] can be calculated from the closed-loop transfer function and the input signal waveform.

An example of a closed-loop transfer function is shown below:

The summing node and the ''G''(''s'') and ''H''(''s'') blocks can all be combined into one block, which would have the following transfer function:

: &lt;math&gt;\dfrac{Y(s)}{X(s)} = \dfrac{G(s)}{1 + G(s) H(s)}&lt;/math&gt;

==Derivation==
We define an intermediate signal Z shown as follows:

[[Image:Closed Loop Block Deriv.png]]

Using this figure we write:

: &lt;math&gt;Y(s) = Z(s)G(s) &lt;/math&gt;

: &lt;math&gt;Z(s) = X(s)-Y(s)H(s)&lt;/math&gt;

: &lt;math&gt;Y(s) = (X(s)-Y(s)H(s))G(s) = X(s)G(s) - Y(s)H(s)G(s)&lt;/math&gt;

: &lt;math&gt;Y(s)+Y(s)H(s)G(s) = X(s)G(s)&lt;/math&gt;

: &lt;math&gt;Y(s)(1+H(s)G(s)) = X(s)G(s)&lt;/math&gt;

: &lt;math&gt;\Rightarrow \dfrac{Y(s)}{X(s)} = \dfrac{G(s)}{1+H(s)G(s)}&lt;/math&gt;

==See also==
*[[Federal Standard 1037C]]
*[[Open-loop controller]]

== References ==
*{{FS1037C}}

[[Category:Classical control theory]]
[[Category:Cybernetics]]</text>
      <sha1>7sk6st8yny9nic8rrhem1qy4vujqgwv</sha1>
    </revision>
  </page>
  <page>
    <title>Codd's theorem</title>
    <ns>0</ns>
    <id>18900634</id>
    <revision>
      <id>797080427</id>
      <parentid>783493952</parentid>
      <timestamp>2017-08-24T21:02:55Z</timestamp>
      <contributor>
        <username>Me, Myself, and I are Here</username>
        <id>17619453</id>
      </contributor>
      <comment>/* top */ overlink</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3797">'''Codd's theorem''' states that [[relational algebra]] and the domain-independent [[relational calculus]] queries, two well-known foundational query languages for the relational model, are precisely equivalent in expressive power. That is, a database query can be formulated in one language if and only if it can be expressed in the other.

The theorem is named after [[Edgar F. Codd]], the father of the [[relational model]] for database management.

The domain independent [[relational calculus]] queries are precisely those relational calculus queries that are invariant under choosing domains of values beyond those appearing in the database itself. That is, queries that may return different results for different domains are excluded. An example of such a forbidden query is the query "select all tuples other than those occurring in relation R", where R is a relation in the database. Assuming different domains, i.e., sets of atomic data items from which tuples can be constructed, this query returns different results and thus is clearly not domain independent.

Codd's Theorem is notable since it establishes the equivalence of two syntactically quite dissimilar languages: [[relational algebra]] is a variable-free language, while relational calculus is a logical language with variables and [[Quantification (science)|quantification]].

Relational calculus is essentially equivalent to [[first-order logic]]{{Citation needed|date=October 2014}}, and indeed, Codd's Theorem had been known to logicians since the late 1940s.&lt;ref&gt;L.H. Chin and A. Tarski. Remarks on Projective Algebras. Bulletin of the AMS, 54:80-81, 1948.&lt;/ref&gt;&lt;ref&gt;A. Tarski and F.B. Thompson. Some general properties of [[cylindric algebra]]s. Bulletin of the AMS, 58:65, 1952.&lt;/ref&gt;

Query languages that are equivalent in expressive power to relational algebra were called '''relationally complete''' by Codd.  By Codd's Theorem, this includes relational calculus. Relational completeness clearly does not imply that any interesting database query can be expressed in relationally complete languages. Well-known examples of inexpressible queries include simple [[Aggregate function|aggregations]] (counting tuples, or summing up values occurring in tuples, which are operations expressible in SQL but not in relational algebra) and computing the [[transitive closure]] of a graph given by its binary edge relation (see also [[expressive power (computer science)|expressive power]]). Codd's theorem also doesn't consider [[Null (SQL)|SQL nulls]] and the [[three-valued logic]] they entail; the logical treatment of nulls remains mired in controversy. (For recent work extending Codd's theorem in this direction see the 2012 paper of Franconi and Tessaris.&lt;ref&gt;Enrico Franconi and Sergio Tessaris, [http://ceur-ws.org/Vol-866/paper8.pdf On the Logic of SQL Nulls],  Proceedings of the 6th Alberto Mendelzon International Workshop on Foundations of Data Management, Ouro Preto, Brazil, June 27-30, 2012. pp. 114-128&lt;/ref&gt;) Additionally, SQL allows duplicate rows (has [[multiset]] semantics.) Nevertheless, relational completeness constitutes an important yardstick by which the expressive power of query languages can be compared.

== Notes ==
&lt;references/&gt;

==References==
* [[Serge Abiteboul]], [[Richard B. Hull]], and [[Victor Vianu]]: ''Foundations of Databases''. Addison-Wesley, 1995.
* E. F. Codd, "Relational completeness of data base sublanguages", in R. Rustin, (ed.) ''Data Base Systems'', Proceedings of 6th Courant Computer Science Symposium (May 24-25, 1971: New York, N.Y.), pp. 65-98, Prentice-Hall, 1972, {{ISBN|013196741X}}

== External links ==
* http://www.dbai.tuwien.ac.at/staff/pichler/dbt/slides/dbt03.pdf

[[Category:Relational model]]
[[Category:Theorems in the foundations of mathematics]]</text>
      <sha1>e2jcnrub0z6ox0gxtojchikn9jh0r1y</sha1>
    </revision>
  </page>
  <page>
    <title>Colin de Verdière graph invariant</title>
    <ns>0</ns>
    <id>3124950</id>
    <revision>
      <id>833347839</id>
      <parentid>833286976</parentid>
      <timestamp>2018-03-31T00:57:29Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>full names, copy-edit</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9068">'''Colin de Verdière's invariant''' is a graph parameter &lt;math&gt;\mu(G)&lt;/math&gt; for any [[Graph (discrete mathematics)|graph]] ''G,'' introduced by [[Yves Colin de Verdière]] in 1990. It was motivated by the study of the maximum multiplicity of the second [[eigenvalue]] of certain [[Schrödinger operator]]s.&lt;ref name="hls99"/&gt;

==Definition==
Let &lt;math&gt;G=(V,E)&lt;/math&gt; be a [[Loop (graph theory)|loopless]] simple graph. Assume without loss of generality that &lt;math&gt;V=\{1,\dots,n\}&lt;/math&gt;. Then &lt;math&gt;\mu(G)&lt;/math&gt; is the largest [[corank]] of any [[symmetric matrix]] &lt;math&gt;M=(M_{i,j})\in\mathbb{R}^{(n)}&lt;/math&gt; such that:
* (M1) for all &lt;math&gt;i,j&lt;/math&gt; with &lt;math&gt;i\neq j&lt;/math&gt;: &lt;math&gt;M_{i,j}&lt;0&lt;/math&gt; if &lt;math&gt;\{i,j\}\in E&lt;/math&gt;, and &lt;math&gt;M_{i,j}=0&lt;/math&gt; if &lt;math&gt;\{i,j\}\notin E&lt;/math&gt;;
* (M2) ''M'' has exactly one negative eigenvalue, of multiplicity 1;
* (M3) there is no nonzero matrix &lt;math&gt;X=(X_{i,j})\in\mathbb{R}^{(n)}&lt;/math&gt; such that &lt;math&gt;MX=0&lt;/math&gt; and such that &lt;math&gt;X_{i,j}=0&lt;/math&gt; if either &lt;math&gt;i=j&lt;/math&gt; or &lt;math&gt;M_{i,j}\neq 0&lt;/math&gt; hold.&lt;ref name="hls99"/&gt;&lt;ref name="cdv90"/&gt;

==Characterization of known graph families==
Several well-known families of graphs can be characterized in terms of their Colin de Verdière invariants:
*{{nowrap|&amp;mu; ≤ 0}} if and only if ''G'' has [[empty graph|no edges]];&lt;ref name="hls99"&gt;{{harvtxt|van der Holst|Lovász|Schrijver|1999}}.&lt;/ref&gt;&lt;ref name="cdv90"/&gt;
*{{nowrap|&amp;mu; ≤ 1}} if and only if ''G'' is a [[linear forest]] (disjoint union of paths);&lt;ref name="hls99"/&gt;&lt;ref&gt;{{harvtxt|Colin de Verdière|1990}} does not state this case explicitly, but it follows from his characterization of these graphs as the graphs with no [[triangle graph]] or [[claw (graph theory)|claw]] minor.&lt;/ref&gt;
*{{nowrap|&amp;mu; ≤ 2}} if and only if ''G'' is [[outerplanar graph|outerplanar]];&lt;ref name="hls99"/&gt;&lt;ref name="cdv90"/&gt;
*{{nowrap|&amp;mu; ≤ 3}} if and only if ''G'' is [[planar graph|planar]];&lt;ref name="hls99"/&gt;&lt;ref name="cdv90"&gt;{{harvtxt|Colin de Verdière|1990}}.&lt;/ref&gt;
*{{nowrap|&amp;mu; ≤ 4}} if and only if ''G'' is [[linkless embedding|linklessly embeddable graph]]&lt;ref name="hls99"/&gt;&lt;ref name="ls98"&gt;{{harvtxt|Lovász|Schrijver|1998}}.&lt;/ref&gt;

These same families of graphs also show up in connections between the Colin de Verdière invariant of a graph and the structure of its [[complement graph]]:
*If the complement of an ''n''-vertex graph is a linear forest, then {{nowrap|&amp;mu; ≥ ''n'' &amp;minus; 3}};&lt;ref name="hls99"/&gt;&lt;ref name="klv97"&gt;{{harvtxt|Kotlov|Lovász|Vempala|1997}}.&lt;/ref&gt;
*If the complement of an ''n''-vertex graph is outerplanar, then {{nowrap|&amp;mu; ≥ ''n'' &amp;minus; 4}};&lt;ref name="hls99"/&gt;&lt;ref name="klv97"/&gt;
*If the complement of an ''n''-vertex graph is planar, then {{nowrap|&amp;mu; ≥ ''n'' &amp;minus; 5}}.&lt;ref name="hls99"/&gt;&lt;ref name="klv97"/&gt;

==Graph minors==
A [[Minor (graph theory)|minor]] of a graph is another graph formed from it by contracting edges and by deleting edges and vertices. The Colin de Verdière invariant is minor-monotone, meaning that taking a minor of a graph can only decrease or leave unchanged its invariant:
:If ''H'' is a minor of ''G'' then &lt;math&gt;\mu(H)\leq\mu(G)&lt;/math&gt;.&lt;ref name="cdv90"/&gt;
By the [[Robertson–Seymour theorem]], for every ''k'' there exists a finite set ''H'' of graphs such that the graphs with invariant at most ''k'' are the same as the graphs that do not have any member of ''H'' as a minor. {{harvtxt|Colin de Verdière|1990}} lists these sets of [[forbidden minor]]s for ''k''&amp;nbsp;≤&amp;nbsp;3; for ''k''&amp;nbsp;=&amp;nbsp;4 the set of forbidden minors consists of the seven graphs in the [[Petersen family]], due to the two characterizations of the [[linkless embedding|linklessly embeddable graph]]s as the graphs with &amp;mu;&amp;nbsp;≤&amp;nbsp;4 and as the graphs with no Petersen family minor.&lt;ref name="ls98"/&gt;

==Chromatic number==
{{harvtxt|Colin de Verdière|1990}} conjectured that any graph with Colin de Verdière invariant &amp;mu; may be [[graph coloring|colored]] with at most &amp;mu;&amp;nbsp;+&amp;nbsp;1 colors. For instance, the linear forests have invariant 1, and can be [[bipartite graph|2-colored]]; the [[outerplanar graph]]s have invariant two, and can be 3-colored; the [[planar graph]]s have invariant 3, and (by the [[four color theorem]]) can be 4-colored.

For graphs with Colin de Verdière invariant at most four, the conjecture remains true; these are the [[linkless embedding|linklessly embeddable graph]]s, and the fact that they have chromatic number at most five is a consequence of a proof by {{harvs|txt|last1=Robertson | first1=Neil | author1-link=Neil Robertson (mathematician) | last2=Seymour | first2=Paul | author2-link=Paul Seymour (mathematician) | last3=Thomas | first3=Robin | author3-link=Robin Thomas (mathematician) |year=1993}} of the [[Hadwiger conjecture (graph theory)|Hadwiger conjecture]] for ''K''&lt;sub&gt;6&lt;/sub&gt;-minor-free graphs.

==Other properties==
If a graph has [[crossing number (graph theory)|crossing number]] &lt;math&gt;k&lt;/math&gt;, it has Colin de Verdière invariant at most &lt;math&gt;k+3&lt;/math&gt;. For instance, the two [[Kazimierz Kuratowski|Kuratowski]] graphs &lt;math&gt;K_5&lt;/math&gt; and &lt;math&gt;K_{3,3}&lt;/math&gt; can both be drawn with a single crossing, and have Colin de Verdière invariant at most four.&lt;ref name="cdv90"/&gt;

[[Louis Esperet]] proved the following connection between the Colin de Verdière invariant and boxicity of the same graph:
:&lt;math&gt;\operatorname{box}(G) = O(\mu(G)^4(\log(\mu(G))^2)&lt;/math&gt;,
and conjectured that the boxicity of ''G'' is at most the Colin de Verdière invariant of ''G''.&lt;ref&gt;{{cite arXiv |last=Esperet |first=Louis |date=2015 |title=Boxicity and Topological Invariants|eprint=1503.05765 |class=math.CO}}&lt;/ref&gt;

==Influence==
Colin de Verdière invariant is defined from a special class of matrices corresponding to a graph instead of just a single matrix related to the graph. Along the same lines other graph parameters are defined and studied, such as [[minimum rank of a graph]], [[minimum semidefinite rank of a graph]] and [[minimum skew rank of a graph]].

==Notes==
{{reflist}}

== References ==
*{{citation
 | last = Colin de Verdière | first = Yves | author-link = Yves Colin de Verdière
 | doi = 10.1016/0095-8956(90)90093-F
 | issue = 1
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | pages = 11–21
 | title = Sur un nouvel invariant des graphes et un critère de planarité
 | volume = 50
 | year = 1990}}. Translated by Neil Calkin as {{citation
 | last = Colin de Verdière | first = Yves | author-link = Yves Colin de Verdière
 | contribution = On a new graph invariant and a criterion for planarity
 | editor1-last = Robertson | editor1-first = Neil | editor1-link = Neil Robertson (mathematician)
 | editor2-last = Seymour | editor2-first = Paul | editor2-link = Paul Seymour (mathematician)
 | pages = 137–147
 | publisher = American Mathematical Society
 | series = Contemporary Mathematics
 | title = Graph Structure Theory: Proc. AMS–IMS–SIAM Joint Summer Research Conference on Graph Minors
 | volume = 147
 | year = 1993}}.
*{{citation
 | last1 = van der Holst | first1 = Hein
 | last2 = Lovász | first2 = László | author2-link = László Lovász
 | last3 = Schrijver | first3 = Alexander | author3-link = Alexander Schrijver
 | contribution = The Colin de Verdière graph parameter
 | location = Budapest
 | pages = 29–85
 | publisher = János Bolyai Math. Soc.
 | series = Bolyai Soc. Math. Stud.
 | title = Graph Theory and Combinatorial Biology (Balatonlelle, 1996)
 | url = http://www.cs.elte.hu/~lovasz/colinsurv.ps
 | volume = 7
 | year = 1999}}.
*{{citation
 | last1 = Kotlov | first1 = Andrew
 | last2 = Lovász | first2 = László | author2-link = László Lovász
 | last3 = Vempala | first3 = Santosh
 | doi = 10.1007/BF01195002
 | issue = 4
 | journal = Combinatorica
 | pages = 483–521
 | title = The Colin de Verdiere number and sphere representations of a graph
 | url = http://oldwww.cs.elte.hu/~lovasz/sphere.ps
 | volume = 17
 | year = 1997}}
*{{citation
 | last1 = Lovász | first1 = László | author1-link = László Lovász
 | last2 = Schrijver | first2 = Alexander | author2-link = Alexander Schrijver
 | doi = 10.1090/S0002-9939-98-04244-0
 | issue = 5
 | journal = [[Proceedings of the American Mathematical Society]]
 | pages = 1275–1285
 | title = A Borsuk theorem for antipodal links and a spectral characterization of linklessly embeddable graphs
 | volume = 126
 | year = 1998}}.
*{{citation | last1=Robertson | first1=Neil | author1-link=Neil Robertson (mathematician) | last2=Seymour | first2=Paul | author2-link=Paul Seymour (mathematician) | last3=Thomas | first3=Robin | author3-link=Robin Thomas (mathematician) | title=Hadwiger's conjecture for K&lt;sub&gt;6&lt;/sub&gt;-free graphs | url=http://www.math.gatech.edu/~thomas/PAP/hadwiger.pdf | year=1993 | journal=[[Combinatorica]] | volume=13 | pages=279–361 | doi=10.1007/BF01202354}}.

{{DEFAULTSORT:Colin de Verdiere graph invariant}}
[[Category:Graph invariants]]
[[Category:Graph minor theory]]</text>
      <sha1>gdtfh0dge2dxke57xjqhq24ichk9z6z</sha1>
    </revision>
  </page>
  <page>
    <title>Conserved current</title>
    <ns>0</ns>
    <id>1097925</id>
    <revision>
      <id>840045615</id>
      <parentid>770610868</parentid>
      <timestamp>2018-05-07T11:01:13Z</timestamp>
      <contributor>
        <ip>2A02:C7D:B910:3D00:41C8:4D00:9278:9572</ip>
      </contributor>
      <comment>removed merge tag see talk page</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3295">{{Unreferenced|date=December 2009}}
In [[physics]] a '''conserved current''' is a current, &lt;math&gt;j^\mu&lt;/math&gt;, that satisfies the [[continuity equation]] &lt;math&gt;\partial_\mu j^\mu=0&lt;/math&gt;. The continuity equation represents a conservation law, hence the name.

Indeed, integrating the continuity equation over a volume &lt;math&gt;V&lt;/math&gt;, large enough to have no net currents through its surface, leads to the conservation law
:&lt;math&gt; {\partial\over\partial t}Q=0\;,&lt;/math&gt;
where &lt;math&gt;Q=\int_V j^0dV&lt;/math&gt; is the [[charge (physics)|conserved quantity]].

In [[gauge theory|gauge theories]] the gauge fields couple to conserved currents. For example, the [[electromagnetic field]] couples to the [[charge conservation|conserved electric current]].

==Conserved quantities and symmetries==
Conserved current is the flow of the [[canonical conjugate]] of a quantity possessing a [[continuous function|continuous]] [[translational symmetry]].  The [[continuity equation]] for the conserved current is a statement of a ''[[Conservation law (physics)|conservation law]]''.
Examples of canonical conjugate quantities are:
*[[Time]] and [[energy]] - the continuous translational symmetry of time implies the [[conservation of energy]].
*[[Space]] and [[momentum]] - the continuous translational symmetry of space implies the [[conservation of momentum]]
*Space and [[angular momentum]] - the continuous ''rotational'' symmetry of space implies the [[conservation of angular momentum]]
*[[Wave function]] [[Phase (waves)|phase]] and [[electric charge]] - the continuous phase angle symmetry of the wave function implies the [[Electric charge#Conservation of charge|conservation of electric charge]]

Conserved currents play an extremely important role in [[theoretical physics]], because [[Noether's theorem]] connects the existence of a conserved current to the existence of a [[symmetry]] of some quantity in the system under study. In practical terms, all conserved currents are the [[Noether current]]s, as the existence of a conserved current implies the existence of a symmetry.  Conserved currents play an important role in the theory of [[partial differential equation]]s, as the existence of a conserved current points to the existence of [[constants of motion]], which are required to define a [[foliation]] and thus an [[integrable system]].  The conservation law is expressed as the vanishing of a 4-[[divergence]], where the Noether charge forms the zeroth component of the [[four-current|4-current]].

==Conserved currents in electromagnetism==
The ''conservation of charge'', for example, in the notation of [[Maxwell's equations]],

:&lt;math&gt;
\frac{\partial \rho} {\partial t} + \nabla \cdot \mathbf{J} = 0
&lt;/math&gt;

where:

ρ is the ''free'' electric charge density (in units of C/m³)

'''J''' is the '''current density''':

:'''J''' = &lt;math&gt;  \rho &lt;/math&gt;'''v'''

'''v''' is the velocity of the charges.

The equation would apply equally to masses (or other conserved quantities), where the word ''mass'' is substituted for the words ''electric charge'' above.

== See also ==
* [[Conservation law (physics)]]
* [[Noether's theorem]]

{{DEFAULTSORT:Conserved Current}}
[[Category:Electromagnetism]]
[[Category:Theoretical physics]]
[[Category:Conservation equations]]
[[Category:Symmetry]]</text>
      <sha1>gt7qbukw9av0md6ikybslorrv0kxt4z</sha1>
    </revision>
  </page>
  <page>
    <title>Crypto API (Linux)</title>
    <ns>0</ns>
    <id>2555833</id>
    <revision>
      <id>819321563</id>
      <parentid>795570555</parentid>
      <timestamp>2018-01-08T18:54:04Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.1) ([[User:Balon Greyjoy|Balon Greyjoy]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5030">'''Crypto API''' is a [[cryptography]] [[framework (software)|framework]] in the [[Linux kernel]], for various parts of the kernel that deal with cryptography, such as [[IPsec]] and [[dm-crypt]]. It was introduced in kernel version 2.5.45&lt;ref&gt;{{cite web
 | url = https://lwn.net/Articles/13587/
 | title = Kernel development
 | year = 2002 | accessdate = 2013-09-29
 | publisher = [[LWN.net]]
}}&lt;/ref&gt; and has since expanded to include essentially all popular [[block cipher]]s and [[hash function]]s.

== Userspace interfaces ==
Many platforms that provide hardware acceleration of [[AES encryption]] expose this to programs through an extension of the [[instruction set architecture]] (ISA) of the various chipsets (e.g. [[AES instruction set]] for [[x86]]). With this sort of implementation any program ([[kernel-mode]] or [[user-space]]) may utilize these features directly.

Some platforms, such as the ARM Kirkwood [[SheevaPlug]] and [[AMD Geode]] processors, however, are not implemented as ISA extensions, and are only accessible through kernel-mode drivers. In order for user-mode applications that utilize encryption, such as [[OpenSSL]] or [[GnuTLS]], to take advantage of such acceleration, they must interface with the kernel.

; AF_ALG
: A [[netlink]]-based interface that adds an &lt;tt&gt;AF_ALG&lt;/tt&gt; address family;&lt;ref&gt;{{cite web
 |last=Edge
 |first=Jake
 |title=A netlink-based user-space crypto API
 |url=https://lwn.net/Articles/410763/
 |publisher=[[LWN.net]]
 |accessdate=29 December 2011
 |date=October 20, 2010
}}&lt;/ref&gt; it was merged into version 2.6.38 of the [[Linux kernel mainline]].&lt;ref&gt;[http://kernelnewbies.org/Linux_2_6_38#head-6bd372b9e646453417be976d4ff1f31086429b7a Linux_2_6_38 changes]&lt;/ref&gt;&lt;ref&gt;
[https://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commitdiff;h=03c8efc1ffeb6b82a22c1af8dd908af349563314 03c8efc] {{webarchive|url=https://archive.is/20130415101617/http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commitdiff;h=03c8efc1ffeb6b82a22c1af8dd908af349563314 |date=2013-04-15 }}
[https://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commitdiff;h=fe869cdb89c95d060c77eea20204d6c91f233b53 fe869cd] {{webarchive|url=https://archive.is/20130415052116/http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commitdiff;h=fe869cdb89c95d060c77eea20204d6c91f233b53 |date=2013-04-15 }}
[https://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commitdiff;h=8ff590903d5fc7f5a0a988c38267a3d08e6393a2 8ff5909] {{webarchive|url=https://archive.is/20130415061420/http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commitdiff;h=8ff590903d5fc7f5a0a988c38267a3d08e6393a2 |date=2013-04-15 }}&lt;/ref&gt; There was once a plugin to [[OpenSSL]] to support AF_ALG,&lt;ref&gt;{{cite web
 |author=Markus 
 |title=OpenSSL - AF_ALG 
 |url=http://carnivore.it/2011/04/23/openssl_-_af_alg 
 |accessdate=29 December 2011 
 |date=2011-10-22 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20110928014250/http://carnivore.it/2011/04/23/openssl_-_af_alg 
 |archivedate=28 September 2011 
 |df= 
}}&lt;/ref&gt; which has been submitted for merging.&lt;ref&gt;{{cite web
 |author=Markus &amp;lt;nepenthesdev at gmail.com&amp;gt;
 |title=#2554: Patch: AF_ALG dynamic engine for linux &gt;= 2.6.38
 |url=http://rt.openssl.org/Ticket/Display.html?id=2554&amp;user=guest&amp;pass=guest
 |work=[[OpenSSL]]
 |accessdate=29 December 2011
 |date=2011-07-03 &lt;!-- at 21:24:59 --&gt;
}}&lt;/ref&gt; In version 1.1.0, OpenSSL landed another patch for AF_ALG contributed by Intel. &lt;ref&gt;{{cite web
 |author=clucey
 |title= ALG: Add AFALG engine 
 |url=https://github.com/openssl/openssl/commit/7f458a48ff3a231d5841466525d2aacbcd4f6b77#commitcomment-18836199
 |work=[[OpenSSL]]
 |accessdate=31 August 2016
 |date=2016-02-17 &lt;!-- 13:38 --&gt;
}}&lt;/ref&gt;

; cryptodev
: The [[OpenBSD Cryptographic Framework]] &lt;tt&gt;/dev/crypto&lt;/tt&gt; interface of OpenBSD was ported to Linux,&lt;ref&gt;{{cite web
 |last=Ludvig
 |first=Michal
 |title=CryptoDev for Linux
 |url=http://www.logix.cz/michal/devel/cryptodev/
 |accessdate=29 December 2011
}}&lt;/ref&gt;&lt;ref&gt;{{cite web
 |last        = Mavrogiannopoulos
 |first       = Nikos
 |title       = cryptodev-linux
 |url         = http://home.gna.org/cryptodev-linux/
 |accessdate  = 12 January 2012
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20120320070655/http://home.gna.org/cryptodev-linux/
 |archivedate = 20 March 2012
 |df          = 
}}&lt;/ref&gt;&lt;ref&gt;{{cite web
 |last=Edge
 |first=Jake
 |title=An API for user-space access to kernel cryptography
 |url=https://lwn.net/Articles/401548/
 |publisher=[[LWN.net]]
 |accessdate=29 December 2011
 |date=August 25, 2010
}}&lt;/ref&gt; but never merged.

== See also ==
{{Portal|Cryptography|Free software|Linux}}

* [[Microsoft CryptoAPI]]

== References ==
{{Reflist|30em}}

{{Linux kernel}}

{{DEFAULTSORT:Crypto Api (Linux)}}
[[Category:Application programming interfaces]]
[[Category:Cryptographic software]]
[[Category:Linux security software]]
[[Category:Linux kernel features]]


{{Crypto-stub}}
{{Linux-stub}}</text>
      <sha1>7mj61th4lbahx0odzp1n39462olgbsm</sha1>
    </revision>
  </page>
  <page>
    <title>Cyclometric function</title>
    <ns>0</ns>
    <id>1960545</id>
    <redirect title="Inverse trigonometric functions" />
    <revision>
      <id>795314211</id>
      <parentid>221784356</parentid>
      <timestamp>2017-08-13T12:41:35Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+cats</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="159">#REDIRECT [[Inverse trigonometric functions]]

[[Category:Trigonometry]]
[[Category:Inverse trigonometric functions]]
[[Category:Elementary special functions]]</text>
      <sha1>q83jwy5pi4h0fsgqhq048wux24ykkxu</sha1>
    </revision>
  </page>
  <page>
    <title>Dehn plane</title>
    <ns>0</ns>
    <id>4207234</id>
    <revision>
      <id>829973161</id>
      <parentid>826899910</parentid>
      <timestamp>2018-03-11T23:18:07Z</timestamp>
      <contributor>
        <ip>120.20.97.240</ip>
      </contributor>
      <comment>/* Dehn's semi-Euclidean geometry */ corrected page reference in Rucker</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4224">In [[geometry]], Dehn introduced two examples of planes, a '''semi-Euclidean geometry''' and a '''non-Legendrian geometry''', that have infinitely many lines parallel to a given one that pass through a given point, but where the sum of the angles of a triangle is at least π.  A similar phenomenon occurs in [[hyperbolic geometry]], except that the sum of the angles of a triangle is less than π.   Dehn's examples use a non-Archimedean field, so that the [[Archimedean axiom]] is violated.  They were introduced by {{harvs|txt|authorlink=Max Dehn|first=Max |last=Dehn|year=1900}} and discussed by {{harvtxt|Hilbert|1902|loc=p.127–130, or p. 42-43 in some later editions}}.

==Dehn's non-archimedean field Ω(''t'')==

To construct his geometries, Dehn used a [[Archimedean property|non-Archimedean]] ordered [[Pythagorean field]] Ω(''t''), a [[Pythagorean closure]] of the field of rational functions '''R'''(''t''),  consisting of the smallest field of real-valued functions on the real line containing the real constants, the identity function ''t'' (taking any real number to itself) and closed under the operation ω → {{radic|1+ω&lt;sup&gt;2&lt;/sup&gt;}}. The field Ω(''t'') is ordered by putting ''x''&gt;''y'' if the function ''x'' is larger than ''y'' for sufficiently large reals. An element ''x'' of Ω(''t'') is called '''finite''' if ''m''&lt;''x''&lt;''n'' for some integers ''m'',''n'', and is called '''infinite''' otherwise.

==Dehn's semi-Euclidean geometry==

The set of all pairs (''x'',&amp;nbsp;''y''), where ''x'' and ''y'' are any (possibly infinite) elements of the field Ω(''t''), and with the usual [[metric (mathematics)|metric]]

: &lt;math&gt;||(x,y)|| = \sqrt{x^2+y^2}, &lt;/math&gt;

which takes values in Ω(''t''), gives a model of [[Euclidean geometry]]. The parallel postulate is true in this model, but if the deviation from the perpendicular is infinitesimal (meaning smaller than any positive rational number), the intersecting lines intersect at a point that is not in the finite part of the plane.  Hence, if the model is restricted to the finite part of the plane (points (''x'',''y'') with ''x'' and ''y'' finite), a geometry is obtained in which the parallel postulate fails but the sum of the angles of a triangle is π. This is Dehn's semi-Euclidean geometry. It is discussed in {{harvtxt|Rucker|1982|loc=pages 91-2}}.

==Dehn's non-Legendrian geometry==

In the same paper, Dehn also constructed an example of a non-Legendrian geometry where there are infinitely many lines through a point not meeting another line, but the sum of the angles in a triangle exceeds π. Riemann's [[elliptic geometry]] over Ω(''t'') consists of the projective plane over Ω(''t''), which can be identified with the affine plane of points (''x'':''y'':1) together with the "line at infinity", and has the property that the sum of the angles of any triangle is greater than π The non-Legendrian geometry consists of the points  (''x'':''y'':1) of this affine subspace such that ''tx'' and ''ty'' are finite (where as above ''t'' is the element of Ω(''t'') represented by the identity function). [[Saccheri–Legendre theorem|Legendre's theorem]] states that the sum of the angles of a triangle is at most π, but assumes Archimedes's axiom, and Dehn's example shows that Legendre's theorem need not hold if Archimedes' axiom is dropped.

==References==

*{{Citation | last1=Dehn | first1=Max | author1-link=Max Dehn | title=Die Legendre'schen Sätze über die Winkelsumme im Dreieck | url=https://books.google.com/books?id=vEbWAAAAMAAJ&amp;pg=PA404 | doi=10.1007/BF01448980 | jfm=31.0471.01 | year=1900 | journal=[[Mathematische Annalen]] | issn=0025-5831 | volume=53 | issue=3 | pages=404–439}}
*{{Citation | last1=Hilbert | first1=David | author1-link=David Hilbert | title=The foundations of geometry | year=1902 | publisher=The Open Court Publishing Co., La Salle, Ill. | mr=0116216 |url=http://www.gutenberg.org/files/17384/17384-pdf.pdf}}
*{{citation|mr=0658492
|last=Rucker|first= Rudy
|title=Infinity and the mind.  The science and philosophy of the infinite|publisher= Birkhäuser|place= Boston, Mass.|year= 1982|isbn= 3-7643-3034-1 }}

[[Category:Geometry]]
[[Category:Non-Euclidean geometry]]
{{SIA|mathematics}}</text>
      <sha1>4eg1gvy4drm4o2y911j45cioewfi9vu</sha1>
    </revision>
  </page>
  <page>
    <title>Desargues's theorem</title>
    <ns>0</ns>
    <id>358488</id>
    <revision>
      <id>845900180</id>
      <parentid>840834438</parentid>
      <timestamp>2018-06-14T22:03:58Z</timestamp>
      <contributor>
        <ip>2601:445:437F:FE66:A97B:E721:C3FA:28DD</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14160">[[Image:Desargues theorem alt.svg|thumb|350px|Perspective triangles. Corresponding sides of the triangles, when extended, meet at points on a line called the axis of perspectivity. The lines which run through corresponding vertices on the triangles meet at a point called the center of perspectivity. Desargues's theorem states that the truth of the first condition is [[necessary and sufficient]] for the truth of the second.]]
In [[projective geometry]], '''Desargues's theorem''', named after [[Girard Desargues]], states:

:Two [[triangle]]s are in perspective ''axially'' [[if and only if]] they are in [[perspective (geometry)|perspective]] ''centrally''.

Denote the three [[vertex (geometry)|vertices]] of one triangle by {{math|''a'', ''b''}} and {{math|''c''}}, and those of the other by {{math|''A'', ''B''}}  and {{math|''C''}}.  Axial [[perspectivity]] means that lines {{math|{{overline|''ab''}}}} and {{math|{{overline|''AB''}}}} meet in a point, lines {{math|{{overline|''ac''}}}} and {{math|{{overline|''AC''}}}} meet in a second point, and lines {{math|{{overline|''bc''}}}} and {{math|{{overline|''BC''}}}} meet in a third point, and that these three points all lie on a common line called the ''axis of perspectivity''.  Central perspectivity means that the three lines {{math|{{overline|''Aa''}}, {{overline|''Bb''}}}} and {{math|{{overline|''Cc''}}}} are concurrent, at a point called the ''center of perspectivity''.

This [[intersection theorem]] is true in the usual [[Euclidean plane]] but special care needs to be taken in exceptional cases, as when a pair of sides are parallel, so that their "point of intersection" recedes to infinity.  Commonly, to remove these exceptions, mathematicians "complete" the Euclidean plane by "adding" points at infinity following [[Jean-Victor Poncelet]]. This results in a [[projective plane]].

Desargues's theorem is true for the [[real projective plane]], for any projective space defined arithmetically from a [[field (mathematics)|field]] or [[division ring]], for any projective space of dimension unequal to two, and for any projective space in which [[Pappus's hexagon theorem|Pappus's theorem]] holds. However, there are some [[non-Desarguesian plane]]s in which Desargues's theorem is false.

==History==
Desargues never published this theorem, but it appeared in an appendix entitled ''Universal Method of M. Desargues for Using Perspective (Maniére universelle de M. Desargues pour practiquer la perspective)'' of a practical book on the use of perspective published in 1648&lt;ref&gt;{{harvtxt|Smith|1959|loc=p. 307}}&lt;/ref&gt; by his friend and pupil Abraham Bosse (1602–1676).&lt;ref&gt;{{harvtxt|Katz|1998|loc=p. 461}}&lt;/ref&gt;

==Projective versus affine spaces==
In an [[affine space]] such as the [[Euclidean plane]] a similar statement is true, but only if one lists various exceptions involving parallel lines. Desargues's theorem is therefore one of the simplest geometric theorems whose natural home is in projective rather than affine space.

==Self-duality==
By definition, two triangles are [[Perspective (geometry)|perspective]] if and only if they are in perspective centrally (or, equivalently according to this theorem, in perspective axially). Note that perspective triangles need not be [[similarity (geometry)|similar]].

Under the standard [[duality (projective geometry)|duality of plane projective geometry]] (where points correspond to lines and collinearity of points corresponds to concurrency of lines), the statement of Desargues's theorem is self-dual:&lt;ref&gt;This is due to the modern way of writing the theorem. Historically, the theorem only read, "In a projective space, a pair of centrally perspective triangles is axially perspective" and the dual of this statement was called the [[theorem#Converse|converse]] of Desargues's theorem and was always referred to by that name. See {{harv|Coxeter|1964|loc= pg. 19}}&lt;/ref&gt; axial perspectivity is translated into central perspectivity and vice versa. The Desargues configuration (below) is a self-dual configuration.&lt;ref&gt;{{harv|Coxeter|1964}}  pp.&amp;nbsp;26–27.&lt;/ref&gt;

==Proof of Desargues's theorem==
Desargues's theorem holds for projective space of any dimension over any field or division ring, and also holds for abstract projective spaces of dimension at least 3. In dimension 2 the planes for which it holds are called [[Desarguesian plane]]s and are the same as the planes that can be given coordinates over a division ring. There are also many [[non-Desarguesian plane]]s where Desargues's theorem does not hold.

===Three-dimensional proof===
Desargues's theorem is true for any projective space of dimension at least&amp;nbsp;3, and more generally for any projective space that can be embedded in a space of dimension at least&amp;nbsp;3.

Desargues's theorem can be stated as follows:

:If lines {{math|{{overline|''Aa''}}, {{overline|''Bb''}}}} and {{math|{{overline|''Cc''}}}} are concurrent (meet at a point), then
:the points {{math|{{overline|''AB''}} ∩ {{overline|''ab''}}, {{overline|''AC''}} ∩ {{overline|''ac''}}}} and {{math|{{overline|''BC''}} ∩ {{overline|''bc''}}}} are [[collinear]].

The points {{math|''A'', ''B'', ''a''}} and {{math|''b''}} are coplanar (lie in the same plane) because of the assumed concurrency of {{math|{{overline|''Aa''}}}} and {{math|{{overline|''Bb''}}}}. Therefore, the lines {{math|{{overline|''AB''}}}} and {{math|{{overline|''ab''}}}} belong to the same plane and must intersect. Further, if the two triangles lie on different planes, then the point {{math|{{overline|''AB''}} ∩ {{overline|''ab''}}}} belongs to both planes. By a symmetric argument, the points {{math|{{overline|''AC''}} ∩ {{overline|''ac''}}}} and {{math|{{overline|''BC''}} ∩ {{overline|''bc''}}}} also exist and belong to the planes of both triangles. Since these two planes intersect in more than one point, their intersection is a line that contains all three points.

This proves Desargues's theorem if the two triangles are not contained in the same plane. If they are in the same plane, Desargues's theorem can be proved by choosing a point not in the plane, using this to lift the triangles out of the plane so that the argument above works, and then projecting back into the plane. 
The last step of the proof fails if the projective space has dimension less than 3, as in this case it may not be possible to find a point outside the plane.

[[Monge's theorem]] also asserts that three points lie on a line, and has a proof using the same idea of considering it in three rather than two dimensions and writing the line as an intersection of two planes.

===Two-dimensional proof===
As there are [[non-Desarguesian projective plane]]s in which Desargues's theorem is not true,&lt;ref&gt;The smallest examples of these can be found in {{harvnb|Room|Kirkpatrick|1971}}.&lt;/ref&gt;  some extra conditions need to be met in 
order to prove it. These conditions usually take the form of assuming the existence of sufficiently many [[collineation]]s of a certain type, which in turn leads to showing that the underlying algebraic coordinate system must be a [[division ring]] (skewfield).&lt;ref&gt;{{harv|Albert|Sandler|1968}}, {{harv|Hughes|Piper|1973}}, and {{harv|Stevenson|1972}}.&lt;/ref&gt;

==Relation to Pappus's theorem==
[[Pappus's hexagon theorem]] states that, if a [[hexagon]] {{math|''AbCaBc''}} is drawn in such a way that vertices {{math|''a'', ''b''}} and {{math|''c''}} lie on a line and vertices {{math|''A'', ''B''}} and {{math|''C''}} lie on a second line, then each two opposite sides of the hexagon lie on two lines that meet in a point and the three points constructed in this way are collinear. A plane in which Pappus's theorem is universally true is called ''Pappian''.
{{harvtxt|Hessenberg|1905}}&lt;ref&gt;According to {{harv|Dembowski|1968|loc= pg. 159, footnote 1}}, Hessenberg's original proof is not complete; he disregarded the possibility that some additional incidences could occur in the Desargues configuration. A complete proof is provided by {{harvnb|Cronheim|1953}}.&lt;/ref&gt; showed that Desargues's theorem can  be deduced from three applications of Pappus's theorem.&lt;ref&gt;{{harvnb|Coxeter|1969|loc=p. 238, section 14.3}}&lt;/ref&gt;

The [[Theorem#Converse|converse]] of this result is not true, that is, not all Desarguesian planes are Pappian. Satisfying Pappus's theorem universally is equivalent to having the underlying coordinate system be [[commutative]]. A plane defined over a non-commutative division ring (a division ring that is not a field) would therefore be Desarguesian but not Pappian. However, due to [[Wedderburn's little theorem]], which states that all ''finite'' division rings are fields, all ''finite'' Desarguesian planes are Pappian. There is no known completely geometric proof of this fact, although {{harvtxt|Bamberg|Penttila|2015}} give a proof that uses only "elementary" algebraic facts (rather than the full strength of Wedderburn's little theorem).

==The Desargues configuration==
{{main|Desargues configuration}}
[[Image:Mutually-inscribed-pentagons.svg|thumb|The Desargues configuration viewed as a pair of mutually inscribed pentagons: each pentagon vertex lies on the line through one of the sides of the other pentagon.]]
The ten lines involved in Desargues's theorem (six sides of triangles, the three lines {{math|{{overline|''Aa''}}, {{overline|''Bb''}}}} and {{math|{{overline|''Cc''}}}}, and the axis of perspectivity) and the ten points involved (the six vertices, the three points of intersection on the axis of perspectivity, and the center of perspectivity) are so arranged that each of the ten lines passes through three of the ten points, and each of the ten points lies on three of the ten lines. Those ten points and ten lines make up the [[Desargues configuration]], an example of a [[projective configuration]]. Although Desargues's theorem chooses different roles for these ten lines and points, the Desargues configuration itself is more [[symmetry|symmetric]]: ''any'' of the ten points may be chosen to be the center of perspectivity, and that choice determines which six points will be the vertices of triangles and which line will be the axis of perspectivity.

==See also==
* [[Pascal's theorem]]

==Notes==
{{reflist}}

==References==
*{{Citation | last1 = Albert | first1 = A. Adrian | last2 = Sandler | first2 = Reuben | title = An Introduction to Finite Projective Planes | publisher = Holt, Rinehart and Winston | place = New York | year = 1968}}
* {{Citation | last1 = Bamberg | first1 = John | last2 = Penttila | first2 = Tim | title = Completing Segre's proof of Wedderburn's little theorem | journal = Bulletin of the London Mathematical Society | year = 2015 | volume = 47 | pages = 483–492 | doi = 10.1112/blms/bdv021}}
* {{Citation | last = Casse | first = Rey | title = Projective Geometry: An Introduction | publisher = Oxford University Press | place = Oxford | year = 2006 | isbn =0-19-929886-6 }}
* {{citation|last=Coxeter|first=H.S.M.|title=Projective Geometry|year=1964|publisher=Blaisdell|location=New York}}
*{{Citation | last1=Coxeter | first1=Harold Scott MacDonald | author1-link=Harold Scott MacDonald Coxeter | title=Introduction to Geometry | publisher=[[John Wiley &amp; Sons]] | location=New York | edition=2nd | isbn=978-0-471-50458-0 | mr=123930 | year=1969}}
*  {{citation|last=Cronheim|first=A.|title=A proof of Hessenberg's theorem|journal=Proceedings of the American Mathematical Society|year=1953|volume=4|pages=219–221|doi=10.2307/2031794}}
*{{Citation | last = Dembowski | first = Peter | title = Finite Geometries | publisher = Springer Verlag | place = Berlin | year = 1968}}
*{{citation|title= Beweis des Desarguesschen Satzes aus dem Pascalschen
|journal=Mathematische Annalen
|publisher=Springer |place=Berlin / Heidelberg
|issn=1432-1807 
|volume =61|issue=  2 |year= 1905
|doi=10.1007/BF01457558
|pages=161–172
|first=Gerhard|last= Hessenberg}}
* {{Citation
  | author = [[David Hilbert|Hilbert, David]]; [[Stephan Cohn-Vossen|Cohn-Vossen, Stephan]]
  | title = Geometry and the Imagination
  | edition = 2nd
  | year = 1952
  | publisher = Chelsea
  | isbn = 0-8284-1087-9
  | pages = 119–128}}
*{{citation| last1=Hughes|first1=Dan|last2=Piper|first2=Fred| title=Projective Planes | publisher=Springer-Verlag | year=1973 | isbn=0-387-90044-6}}
*{{Citation | last = Kárteszi | first = F. | title = Introduction to Finite Geometries| publisher = North-Holland | place = Amsterdam | year = 1976 | isbn = 0-7204-2832-7}}
*{{Citation | last = Katz |first=Victor J.|title=A History of Mathematics:An Introduction|edition=2nd|publisher=Addison Wesley Longman|place=Reading, Mass.|year=1998|isbn=0-321-01618-1}}
*{{Citation | authorlink1=T. G. Room | last1 = Room | first1 = T. G. | last2 = Kirkpatrick | first2 = P. B. | title = Miniquaternion Geometry | publisher = Cambridge University Press | place = Cambridge | year = 1971 |isbn = 0-521-07926-8}}
*{{Citation |last= Smith|first=David Eugene|title=A Source Book in Mathematics|publisher=Dover|place=New York|year=1959|isbn=0-486-64690-4}}
*{{Citation | last = Stevenson | first = Frederick W. | title = Projective Planes | publisher = W.H. Freeman and Company | place = San Francisco |year = 1972 | isbn = 0-7167-0443-9}}
*{{eom|id=d/d031320|first=M.I.|last= Voitsekhovskii|title=Desargues assumption}}

== External links ==
*[http://mathworld.wolfram.com/DesarguesTheorem.html Desargues Theorem] at [[MathWorld]]
* [http://www.cut-the-knot.org/Curriculum/Geometry/Desargues.shtml Desargues's Theorem] at [[cut-the-knot]]
* [http://www.cut-the-knot.org/Curriculum/Geometry/MongeTheorem.shtml Monge via Desargues] at [[cut-the-knot]]
* [http://planetmath.org/?op=getobj&amp;from=objects&amp;id=4514 Proof of Desargues's theorem] at [[PlanetMath]]
* [http://math.kennesaw.edu/~mdevilli/desargues.html Desargues's Theorem] at [https://web.archive.org/web/20090321024112/http://math.kennesaw.edu/~mdevilli/JavaGSPLinks.htm Dynamic Geometry Sketches]

[[Category:Theorems in projective geometry]]
[[Category:Proof without words]]
[[Category:Theorems in geometry]]
[[Category:Theorems in plane geometry]]
[[Category:Euclidean plane geometry]]</text>
      <sha1>08gst3qduh6u5vhtro2ckaqqz8vnfm7</sha1>
    </revision>
  </page>
  <page>
    <title>Eccentricity (mathematics)</title>
    <ns>0</ns>
    <id>1239472</id>
    <revision>
      <id>860496458</id>
      <parentid>860496404</parentid>
      <timestamp>2018-09-21T02:00:01Z</timestamp>
      <contributor>
        <username>Shellwood</username>
        <id>2366721</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/Alextice18|Alextice18]] ([[User talk:Alextice18|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10873">[[Image:Eccentricity.svg|thumb|right|All types of conic sections, arranged with increasing eccentricity. Note that curvature decreases with eccentricity, and that none of these curves intersect.]]
In [[mathematics]], the '''eccentricity, ''' denoted  ''e'' or &lt;math&gt;\varepsilon&lt;/math&gt;, is a [[parameter]] associated with every [[Conic section#Eccentricity|conic section]]. It can be thought of as a measure of how much the conic section deviates from being circular.

In particular,
*The eccentricity of a [[circle]] is zero.
*The eccentricity of an [[ellipse]] which is not a circle is greater than zero but less than 1.
*The eccentricity of a [[parabola]] is 1.
*The eccentricity of a [[hyperbola]] is greater than 1.

Furthermore, two conic sections are [[similarity (geometry)|similar]] (identically shaped) [[if and only if]] they have the same eccentricity.

==Definitions==
[[File:Exzentr3d-s.svg|175px|thumb|plane section of a cone]]
Any conic section can be defined as the locus of points whose distances to a point (the focus) and a line (the directrix) are in a constant ratio. That ratio is called the eccentricity, commonly denoted as ''e''.

The eccentricity can also be defined in terms of the intersection of a plane and a [[Cone (geometry)|double-napped cone]] associated with the conic section. If the cone is oriented with its axis  vertical, the eccentricity is&lt;ref&gt;Thomas, George B.; Finney, Ross L. (1979), Calculus and Analytic Geometry (fifth ed.), Addison-Wesley, p. 434. {{ISBN|0-201-07540-7}}&lt;/ref&gt;

:&lt;math&gt; e = \frac{\sin \beta}{\sin \alpha}, \ \ 0&lt;\alpha&lt;90^\circ, \ 0\le\beta\le90^\circ \ , &lt;/math&gt;
where β  is the angle between the plane and the horizontal and  α is the angle between the cone's slant generator and the horizontal. For &lt;math&gt;\beta=0&lt;/math&gt; the plane section is a circle, for &lt;math&gt;\beta=\alpha&lt;/math&gt; a parabola. (The plane must not meet the vertex of the cone.)

The '''linear eccentricity''' of an ellipse or hyperbola, denoted ''c'' (or sometimes ''f'' or ''e''), is the distance between its center and either of its two [[focus (geometry)|foci]]. The eccentricity can be defined as the ratio of the linear eccentricity to the [[semimajor axis]] ''a'': that is, &lt;math&gt; e = \frac{c}{a} &lt;/math&gt;. (Lacking a center, the linear eccentricity for parabolas is not defined.)

==Alternative names==
The eccentricity is sometimes called the '''first eccentricity''' to distinguish it from the '''second eccentricity''' and '''third eccentricity''' defined for ellipses (see below). The eccentricity is also sometimes called the '''numerical eccentricity'''.

In the case of ellipses and hyperbolas the linear eccentricity is sometimes called the '''half-focal separation'''.

==Notation==
Three notational conventions are in common use:
#''e'' for the eccentricity and ''c'' for the linear eccentricity.
#&lt;math&gt;\varepsilon&lt;/math&gt; for the eccentricity and ''e'' for the linear eccentricity.
#''e'' or &lt;math&gt;\epsilon&lt;/math&gt; for the eccentricity and ''f'' for the linear eccentricity (mnemonic for half-''f''ocal separation).
This article uses the first notation.

==Values==
{| class="wikitable"
! conic section !! equation !! eccentricity (''e'') !! linear eccentricity (''c'')
|-
| [[Circle]] || &lt;math&gt;x^2+y^2=r^2&lt;/math&gt; || &lt;math&gt;0&lt;/math&gt; || &lt;math&gt;0&lt;/math&gt;
|-
| [[Ellipse]] || &lt;math&gt;\frac{x^2}{a^2}+\frac{y^2}{b^2}=1&lt;/math&gt; || &lt;math&gt;\sqrt{1-\frac{b^2}{a^2}}&lt;/math&gt; || &lt;math&gt;\sqrt{a^2-b^2}&lt;/math&gt;
|-
| [[Parabola]] || &lt;math&gt;x^2=4ay&lt;/math&gt; || &lt;math&gt;1&lt;/math&gt; || &lt;math&gt;-&lt;/math&gt;
|-
| [[Hyperbola]] || &lt;math&gt;\frac{x^2}{a^2}-\frac{y^2}{b^2}=1&lt;/math&gt; || &lt;math&gt;\sqrt{1+\frac{b^2}{a^2}}&lt;/math&gt; || &lt;math&gt;\sqrt{a^2+b^2}&lt;/math&gt;
|}

Here, for the ellipse and the hyperbola, ''a'' is the length of the semi-major axis and ''b'' is the length of the semi-minor axis.

When the conic section is given in the general quadratic form

:&lt;math&gt;Ax^2 + Bxy + Cy^2 +Dx + Ey + F = 0,&lt;/math&gt;

the following formula gives the eccentricity ''e'' if the conic section is not a parabola (which has eccentricity equal to 1), not a [[Degenerate conic|degenerate hyperbola or degenerate ellipse]], and not an imaginary ellipse:&lt;ref&gt;Ayoub, Ayoub B., "The eccentricity of a conic section", ''[[The College Mathematics Journal]]'' 34(2), March 2003, 116-121.&lt;/ref&gt;

:&lt;math&gt;e=\sqrt{\frac{2\sqrt{(A-C)^2 + B^2}}{\eta (A+C) + \sqrt{(A-C)^2 + B^2}}}&lt;/math&gt;

where &lt;math&gt;\eta = 1&lt;/math&gt; if the determinant of the 3×3 matrix

:&lt;math&gt;\begin{bmatrix}A &amp; B/2 &amp; D/2\\B/2 &amp; C &amp; E/2\\D/2&amp;E/2&amp;F\end{bmatrix}&lt;/math&gt;

is negative or &lt;math&gt;\eta = -1&lt;/math&gt; if that determinant is positive.

[[File:Ellipse and hyperbola.gif|thumb|250px|Ellipse and hyperbola with constant ''a'' and changing eccentricity ''e''.]]

==Ellipses==

The eccentricity of an [[ellipse]] is strictly less than 1. When circles (which have eccentricity 0) are counted as ellipses, the eccentricity of an ellipse is greater than or equal to 0; if circles are given a special category and are excluded from the category of ellipses, then the eccentricity of an ellipse is strictly greater than 0.

For any ellipse, let ''a'' be the length of its [[semi-major axis]] and ''b'' be the length of its [[semi-minor axis]].

We define a number of related additional concepts (only for ellipses):

{| class="wikitable"
! name !! symbol !! in terms of ''a'' and ''b'' !! in terms of ''e''
|-
| &amp;nbsp; '''first eccentricity''' || &amp;nbsp; &lt;math&gt;e&lt;/math&gt; || &amp;nbsp; &lt;math&gt;\sqrt{1-\frac{b^2}{a^2}}&lt;/math&gt; || &amp;nbsp; &lt;math&gt;e&lt;/math&gt;
|-
| &amp;nbsp; '''second eccentricity''' || &amp;nbsp; &lt;math&gt;e'&lt;/math&gt; || &amp;nbsp; &lt;math&gt;\sqrt{\frac{a^2}{b^2}-1}&lt;/math&gt; || &amp;nbsp; &lt;math&gt;\frac{e}{\sqrt{1-e^2}}&lt;/math&gt;
|-
| &amp;nbsp; '''third eccentricity''' || &amp;nbsp; &lt;math&gt;e''=\sqrt m&lt;/math&gt; || &amp;nbsp;&lt;math&gt;\frac{\sqrt{a^2-b^2}}{\sqrt{a^2+b^2}}&lt;/math&gt; || &amp;nbsp; &lt;math&gt; \frac{e}{\sqrt{2-e^2}} &lt;/math&gt;
|-
| &amp;nbsp; '''[[angular eccentricity]]''' || &amp;nbsp; &lt;math&gt;\alpha&lt;/math&gt; ||&amp;nbsp; &lt;math&gt;\cos^{-1}\left(\frac{b}{a}\right)&lt;/math&gt; || &amp;nbsp; &lt;math&gt;\sin^{-1} e&lt;/math&gt;
|}

===Other formulae for the eccentricity of an ellipse===

The eccentricity of an ellipse is, most simply, the ratio of the distance ''f'' between the center of the ellipse and each focus to the length of the semimajor axis ''a''.

:&lt;math&gt;e = \frac{f}{a}.&lt;/math&gt;

The eccentricity is also the ratio of the semimajor axis ''a'' to the distance ''d'' from the center to the directrix:

:&lt;math&gt;e = \frac{a}{d}.&lt;/math&gt;

The eccentricity can be expressed in terms of the [[flattening]] ''g'' (defined as ''g'' = 1 – ''b''/''a'' for semimajor axis ''a'' and semiminor axis ''b''):
:&lt;math&gt;e = \sqrt{g(2-g)}.&lt;/math&gt;
(Flattening is denoted by ''f'' in some subject areas, particularly geodesy.)

Define the maximum and minimum radii &lt;math&gt;r_\text{max}&lt;/math&gt; and &lt;math&gt;r_\text{min}&lt;/math&gt; as the maximum and minimum distances from either focus to the ellipse (that is, the distances from either focus to the two ends of the major axis). Then with semimajor axis ''a'', the eccentricity is given by

:&lt;math&gt;e = \frac{r_\text{max}-r_\text{min}}{r_\text{max}+r_\text{min}} = \frac{r_\text{max}-r_\text{min}}{2a},&lt;/math&gt;

which is the distance between the foci divided by the length of the major axis.

==Hyperbolas==

The eccentricity of a [[hyperbola]] can be any real number greater than 1, with no upper bound. The eccentricity of a [[rectangular hyperbola]] is &lt;math&gt;\sqrt{2}&lt;/math&gt;.

==Quadrics==
[[Image:Cubic surface.gif|thumb|right|Ellipses, hyperbolas with all possible eccentricities from zero to infinity and a parabola on one cubic surface.]]
The eccentricity of a three-dimensional [[quadric]] is the eccentricity of a designated [[Cross section (geometry)|section]] of it. For example, on a triaxial ellipsoid, the ''meridional eccentricity'' is that of the ellipse formed by a section containing both the longest and the shortest axes (one of which will be the polar axis), and the ''equatorial eccentricity'' is the eccentricity of the ellipse formed by a section through the centre, perpendicular to the polar axis (i.e. in the equatorial plane). But: conic sections may occur on surfaces of higher order, too (see image).

==Celestial mechanics==
{{main|Orbital eccentricity}}
In [[celestial mechanics]], for bound orbits in a spherical potential, the definition above is informally generalized. When the [[apocenter]] distance is close to the [[pericenter]] distance, the orbit is said to have low eccentricity; when they are very different, the orbit is said be eccentric or having eccentricity near unity. This definition coincides with the mathematical definition of eccentricity for ellipses, in Keplerian, i.e., &lt;math&gt;1/r&lt;/math&gt; potentials.

== Analogous classifications ==
{{Expand section|date=March 2009}}
A number of classifications in mathematics use derived terminology from the classification of conic sections by eccentricity:
*[[SL2(R)#Classification of elements|Classification of elements]] of [[SL2(R)|SL&lt;sub&gt;2&lt;/sub&gt;(R)]] as elliptic, parabolic, and hyperbolic – and similarly for [[Möbius transformation#Classification|classification of elements]] of PSL&lt;sub&gt;2&lt;/sub&gt;(R), the real [[Möbius transformation]]s.
*Classification of discrete distributions by [[variance-to-mean ratio]]; see [[Cumulant#Cumulants of some discrete probability distributions|cumulants of some discrete probability distributions]] for details.
*Classification of [[partial differential equations]] is by analogy with the conic sections classification; see [[Elliptic partial differential equation|elliptic]], [[Parabolic partial differential equation|parabolic]] and [[Hyperbolic partial differential equation|hyperbolic]] partial differential equations.&lt;ref name="ornl.gov"&gt;{{cite web | url=http://www.phy.ornl.gov/csep/pde/node3.html | title=Classification of Linear PDEs in Two Independent Variables | accessdate=2 July 2013}}&lt;/ref&gt;

==Eccentricity for data shapes==
The eccentricity is also a concept which is used to characterize statistical distribution of data points around a common axis. For example, the eccentricity can be used to characterize shapes of jets of many particles.&lt;ref&gt;S.Chekanov, J.Proudfoot, "Searches for TeV-scale particles at the LHC using jet shapes", Phys. Rev. D 81:114038, (2010). arXiv:1002.3982&lt;/ref&gt;

The definition closely follows the original "geometrical" concept, with one important difference – data points can have "weights". Such weights can lead to a deviation from the standard geometrical concept that assumes that all data  points have the same contributions.

==See also==
*[[Kepler orbit]]s
*[[Eccentricity vector]]
*[[Orbital eccentricity]]
*[[Roundness (object)]]

==References==
{{reflist}}

==External links==
{{commons category|Eccentricity}}
*[http://mathworld.wolfram.com/Eccentricity.html MathWorld: Eccentricity]

{{orbits}}

{{DEFAULTSORT:Eccentricity (Mathematics)}}
[[Category:Conic sections]]
[[Category:Analytic geometry]]</text>
      <sha1>7a42f6m2aby4s85wa7k004k4aujmtd8</sha1>
    </revision>
  </page>
  <page>
    <title>Generic flatness</title>
    <ns>0</ns>
    <id>26374518</id>
    <revision>
      <id>864867305</id>
      <parentid>864864708</parentid>
      <timestamp>2018-10-20T01:17:57Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <minor/>
      <comment>/* Generic freeness */ move the link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3083">In [[algebraic geometry]] and [[commutative algebra]], the theorems of '''generic flatness''' and '''generic freeness''' state that under certain hypotheses, a [[sheaf (mathematics)|sheaf]] of [[module (mathematics)|module]]s on a [[scheme (mathematics)|scheme]] is [[flat morphism|flat]] or [[free module|free]]. They are due to [[Alexander Grothendieck]].

Generic flatness states that if ''Y'' is an integral locally noetherian scheme, {{nowrap|''u'' : ''X'' &amp;rarr; ''Y''}} is a finite type morphism of schemes, and ''F'' is a coherent ''O''&lt;sub&gt;''X''&lt;/sub&gt;-module, then there is a non-empty open subset ''U'' of ''Y'' such that the restriction of ''F'' to ''u''&lt;sup&gt;&amp;minus;1&lt;/sup&gt;(''U'') is flat over ''U''.&lt;ref&gt;EGA IV&lt;sub&gt;2&lt;/sub&gt;, Théorème 6.9.1&lt;/ref&gt;

Because ''Y'' is integral, ''U'' is a dense open subset of ''Y''. This can be applied to deduce a variant of generic flatness which is true when the base is not integral.&lt;ref&gt;EGA IV&lt;sub&gt;2&lt;/sub&gt;, Corollaire 6.9.3&lt;/ref&gt; Suppose that ''S'' is a noetherian scheme, {{nowrap|''u'' : ''X'' &amp;rarr; ''S''}} is a finite type morphism, and ''F'' is a coherent ''O''&lt;sub&gt;''X''&lt;/sub&gt; module. Then there exists a partition of ''S'' into locally closed subsets ''S''&lt;sub&gt;1&lt;/sub&gt;, ..., ''S''&lt;sub&gt;''n''&lt;/sub&gt; with the following property: Give each ''S''&lt;sub&gt;''i''&lt;/sub&gt; its reduced scheme structure, denote by ''X''&lt;sub&gt;''i''&lt;/sub&gt; the [[fiber product of schemes|fiber product]] {{nowrap|''X'' &amp;times;&lt;sub&gt;''S''&lt;/sub&gt; ''S''&lt;sub&gt;''i''&lt;/sub&gt;}}, and denote by ''F''&lt;sub&gt;''i''&lt;/sub&gt; the restriction {{nowrap|''F'' &amp;otimes;&lt;sub&gt;''O''&lt;sub&gt;''S''&lt;/sub&gt;&lt;/sub&gt; ''O''&lt;sub&gt;''S''&lt;sub&gt;''i''&lt;/sub&gt;&lt;/sub&gt;}}; then each ''F''&lt;sub&gt;''i''&lt;/sub&gt; is flat.

== Generic freeness ==
Generic flatness is a consequence of the generic freeness lemma. Generic freeness states that if ''A'' is a [[noetherian ring|noetherian]] [[integral domain]], ''B'' is a finite type ''A''-algebra, and ''M'' is a finite type ''B''-module, then there exists a non-zero element ''f'' of ''A'' such that ''M''&lt;sub&gt;''f''&lt;/sub&gt; is a free ''A''&lt;sub&gt;''f''&lt;/sub&gt;-module.&lt;ref&gt;EGA IV&lt;sub&gt;2&lt;/sub&gt;, Lemme 6.9.2&lt;/ref&gt; Generic freeness can be extended to the graded situation: If ''B'' is graded by the natural numbers, ''A'' acts in degree zero, and ''M'' is a graded ''B''-module, then ''f'' may be chosen such that each graded component of ''M''&lt;sub&gt;''f''&lt;/sub&gt; is free.&lt;ref&gt;Eisenbud, Theorem 14.4&lt;/ref&gt;

Generic freeness is proved using Grothendieck's technique of [[dévissage]]. See [[Noether's normalization lemma#Illustrative application : generic freeness]] for a proof of a version of generic freeness.

== References ==
&lt;references/&gt;

== Bibliography ==
* {{Citation | last1=Eisenbud | first1=David | author1-link=David Eisenbud | title=Commutative algebra with a view toward algebraic geometry | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Graduate Texts in Mathematics | isbn=978-0-387-94268-1 |mr=1322960 | year=1995 | volume=150}}
* {{EGA|book=IV-2}}

[[Category:Algebraic geometry]]
[[Category:Commutative algebra]]
[[Category:Theorems in abstract algebra]]</text>
      <sha1>e0f0eniauucyzup6dm45pewmv9tpi1t</sha1>
    </revision>
  </page>
  <page>
    <title>Graded-commutative ring</title>
    <ns>0</ns>
    <id>52405825</id>
    <revision>
      <id>785237884</id>
      <parentid>785128440</parentid>
      <timestamp>2017-06-12T10:42:40Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1322">In algebra, a '''graded-commutative ring''' (also called a '''skew-commutative ring''') is a [[graded ring]] that is commutative in the graded sense; that is, homogeneous elements ''x'', ''y'' satisfy
:&lt;math&gt;xy = (-1)^{|x||y|} yx ,&lt;/math&gt;
where |''x''|, |''y''| denote the degrees of ''x'', ''y''.

A [[commutative ring|commutative (non-graded) ring]], with trivial grading, is a basic example. An [[exterior algebra]] is an example of a graded-commutative ring that is not commutative in the non-graded sense.

A [[cup product]] on cohomology satisfies the skew-commutative relation; hence, a [[cohomology ring]] is graded-commutative. In fact, many&lt;!-- majority? --&gt; examples of graded-commutative rings come from [[algebraic topology]] and [[homological algebra]].

== References ==
* [[David Eisenbud]], ''Commutative Algebra. With a view toward algebraic geometry'', [[Graduate Texts in Mathematics]], vol 150, [[Springer-Verlag]], New York, 1995.  {{ISBN|0-387-94268-8}}
*{{Cite arxiv|last=Beck|first=Kristen A.|last2=Sather-Wagstaff|first2=Sean|date=2013-07-01|title=A somewhat gentle introduction to differential graded commutative algebra|eprint=1307.0369|class=math.AC}}

== See also ==
*[[DG algebra]]
*[[graded-symmetric algebra]]
*[[supercommutative algebra]]

[[Category:Abstract algebra]]


{{algebra-stub}}</text>
      <sha1>atkx57z70cskngrm68ftc3qzkog1imu</sha1>
    </revision>
  </page>
  <page>
    <title>Guard (computer science)</title>
    <ns>0</ns>
    <id>1186249</id>
    <revision>
      <id>806914754</id>
      <parentid>805001659</parentid>
      <timestamp>2017-10-24T22:42:20Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 2 sources and tagging 0 as dead. #IABot (v1.6beta3)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7405">{{more footnotes|date=September 2010}}

In computer programming, a '''guard''' is a [[Boolean datatype|boolean]] [[expression (programming)|expression]] that must evaluate to true if the program execution is to continue in the branch in question.

Regardless of which programming language is used, '''guard code''' or a '''guard clause''' is a check of integrity [[precondition]]s used to avoid errors during execution. A typical example is checking that a reference about to be processed be not null, which avoids null-pointer failures. Other uses include using a boolean field for [[idempotence]] (so subsequent calls are nops), as in the [[dispose pattern]]. Guard code provides an [[early exit]] from a [[subroutine]], and is a commonly used deviation from [[structured programming]], removing one level of nesting and resulting in flatter code:&lt;ref name="beck"&gt;{{cite book |title=Smalltalk Best Practice Patterns, |first=Kent |last=Beck |authorlink=Kent Beck |year=1997 |section=Guard Clause |pages=178–179}}&lt;/ref&gt; replacing &lt;code&gt;if guard { ... }&lt;/code&gt; with &lt;code&gt;if not guard: return; ...&lt;/code&gt;.

The term is used with specific meaning in [[APL (programming language)|APL]], [[Haskell (programming language)|Haskell]], [[Clean programming language|Clean]], [[Erlang programming language|Erlang]], [[Occam (programming language)|occam]], [[Promela]], [[OCaml]], [[Swift (programming language)|Swift]]&lt;ref&gt;{{Cite web
| url = http://nshipster.com/guard-and-defer/
| title = guard &amp; defer
| last = Cook
| first = Nate
| website = NSHipster
| access-date = 2016-02-26
}}&lt;/ref&gt; and [[Scala (programming language)|Scala]] programming languages.{{Citation needed|date=March 2012}} In [[Mathematica]], guards are called ''constraints''. Guards are the fundamental concept in [[Guarded Command Language]], a language in [[formal methods]]. Guards can be used to augment [[pattern matching]] with the possibility to skip a pattern even if the structure matches. Boolean expressions in [[Conditional (programming)|conditional statement]]s usually also fit this definition of a guard although they are called ''conditions''.

In the following Haskell example, the guards occur between each pair of "|" and "=":

&lt;source lang="haskell"&gt;
f x
 | x &gt; 0 = 1
 | otherwise = 0
&lt;/source&gt;

This is similar to the respective mathematical notation:

&lt;math&gt;
f(x) = \left\{ \begin{matrix}
 1 &amp; \mbox{if } x&gt;0 \\
 0 &amp; \mbox{otherwise}
 \end{matrix}
 \right.
&lt;/math&gt;

In this case the guards are in the "if" and "otherwise" clauses.

If there are several parallel guards, such as in the example above, they are normally tried in a top-to-bottom order, and the branch of the first to pass is chosen. Guards in a list of cases are typically parallel.

However, in Haskell [[list comprehension]]s the guards are in series, and if any of them fails, the list element is not produced. This would be the same as combining the separate guards with [[logical conjunction|logical AND]], except that there can be other list comprehension clauses among the guards.

==Evolution==
A simple conditional expression, already present in [[CPL programming language|CPL]] in 1963, has a guard on first sub-expression, and another sub-expression to use in case the first one cannot be used. Some common ways to write this:
 (x&gt;0) -&gt; 1/x; 0
 x&gt;0 ? 1/x : 0

If the second sub-expression can be a further simple conditional expression, we can give more alternatives to try before the last ''fall-through'':
 (x&gt;0) -&gt; 1/x; (x&lt;0) -&gt; -1/x; 0

In 1966 [[ISWIM]] had a form of conditional expression without an obligatory fall-through case, thus separating guard from the concept of choosing either-or. In the case of ISWIM, if none of the alternatives could be used, the value was to be ''undefined'', which was defined to never compute into a value.

[[Kent Recursive Calculator|KRC]], a "miniaturized version"&lt;ref&gt;{{cite web|last1=Turner|first1=D. A.|title=Some History of Functional Programming Languages|url=https://www.cs.kent.ac.uk/people/staff/dat/tfp12/tfp12.pdf}}&lt;/ref&gt; of [[SASL programming language|SASL]] (1976), was one of the first programming languages to use the term "guard". Its function definitions could have several clauses, and the one to apply was chosen based on the guards that followed each clause:

&lt;!-- SASL isn't Haskell, of course, but the syntax is close enough... --&gt;
&lt;source lang="haskell"&gt;
 fac n = 1,               n = 0
       = n * fac (n-1),   n &gt; 0
&lt;/source&gt;
&lt;!-- add something on how Guarded commands fit in --&gt;

Use of guard clauses, and the term "guard clause", dates at least to [[Smalltalk]] practice in the 1990s, as codified by [[Kent Beck]].&lt;ref name="beck"/&gt;

In 1996, Dyalog APL adopted an alternative pure functional style in which the guard is the only control structure.&lt;ref&gt;{{Cite web|url=http://www.dyalog.com/uploads/documents/Papers/dfns.pdf|title=Direct Functions in Dyalog APL|last=Scholes|first=John|date=|website=|publisher=|access-date=}}&lt;/ref&gt; This example, in APL, computes the parity of the input number:&lt;syntaxhighlight lang="apl"&gt;
parity←{
        2∣⍵ : 'odd'
              'even'
        }
&lt;/syntaxhighlight&gt;

==Pattern guard==
In addition to a guard attached to a pattern, '''pattern guard''' can refer to the use of [[pattern matching]] in the context of a guard. In effect, a match of the pattern is taken to mean pass. This meaning was introduced in a proposal for Haskell by [[Simon Peyton Jones]] titled [http://research.microsoft.com/Users/simonpj/Haskell/guards.html A new view of guards] in April 1997 and was used in the implementation of the proposal. The feature provides the ability to use patterns in the guards of a pattern.

An example in extended Haskell:

&lt;source lang="haskell"&gt;
 clunky env var1 var2
 | Just val1 &lt;- lookup env var1
 , Just val2 &lt;- lookup env var2
 = val1 + val2
 -- ...other equations for clunky...
&lt;/source&gt;

This would read: "Clunky for an environment and two variables, ''in case the lookups of the variables from the environment produce values'', is the sum of the values. ..." As in [[list comprehension]]s, the guards are in series, and if any of them fails the branch is not taken.

== Example ==
&lt;source lang="csharp"&gt;
public string Foo(string username) {
    if (username == null)
    {
        throw new ArgumentNullException(nameof(username));
    }
    // Rest of the method code follows here...
}
&lt;/source&gt;

==See also==
* [[Assertion (computing)|Assertion]]
* [[Logical conditional]]
* [[Switch statement]]
* [[Iverson bracket]]
* [[Guarded suspension]]

==References==
{{Reflist}}

==External links==
* [http://foldoc.org/guard Guard] in ''Free On-Line Dictionary of Computing - FOLDOC'', Denis Howe (editor).
* [http://c2.com/cgi/wiki?GuardClause Guard Clause], [[WikiWikiWeb]]
* ''The Haskell 98 Report'', chapter [http://haskell.org/onlinereport/exps.html 3 Expressions].
* ''The Mathematica Book,'' section [https://web.archive.org/web/20050408114902/http://documents.wolfram.com/mathematica/book/section-2.3.5 2.3.5 Putting Constraints on Patterns]
* ''The Glorious Glasgow Haskell Compilation System User's Guide'', Version 6.4, section [https://web.archive.org/web/20051129140339/http://www.haskell.org/ghc/docs/latest/html/users_guide/syntax-extns.html#pattern-guards 7.3.2. Pattern guards]

[[Category:Conditional constructs]]
[[Category:Formal methods terminology]]
[[Category:Articles with example Haskell code]]</text>
      <sha1>2hulcyvrvz67i46xo5x9dilpogwfti4</sha1>
    </revision>
  </page>
  <page>
    <title>Haar space</title>
    <ns>0</ns>
    <id>51716359</id>
    <revision>
      <id>841708417</id>
      <parentid>768507970</parentid>
      <timestamp>2018-05-17T14:58:39Z</timestamp>
      <contributor>
        <username>Rudolf.hellmuth</username>
        <id>7761083</id>
      </contributor>
      <minor/>
      <comment>link to supremum norm</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="836">{{one source|date=February 2017}}
In [[approximation theory]], a '''Haar space''' or '''Chebyshev space''' is a finite-dimensional subspace &lt;math&gt;V&lt;/math&gt; of &lt;math&gt;\mathcal C(X, \mathbb K)&lt;/math&gt;, where &lt;math&gt;X&lt;/math&gt; is a [[compact space]] and &lt;math&gt;\mathbb K&lt;/math&gt; either the [[real numbers]] or the [[complex numbers]], such that for any given &lt;math&gt;f \in \mathcal C(X, \mathbb K)&lt;/math&gt; there is exactly one element of &lt;math&gt;V&lt;/math&gt; that approximates &lt;math&gt;f&lt;/math&gt; "best", i.e. with minimum distance to &lt;math&gt;f&lt;/math&gt; in [[supremum norm]].&lt;ref name="shapiro" /&gt;

== References ==
&lt;references&gt;
&lt;ref name="shapiro"&gt;{{cite book |last=Shapiro |first=Harold |year=1971 |title=Topics in Approximation Theory |publisher=Springer |pages=19–22 |isbn=3-540-05376-X}}&lt;/ref&gt;
&lt;/references&gt;

[[Category:Approximation theory]]


{{math-stub}}</text>
      <sha1>gvlp4acjw1ijcvdm9gurkrkn6ugja5y</sha1>
    </revision>
  </page>
  <page>
    <title>Hadamard matrix</title>
    <ns>0</ns>
    <id>507553</id>
    <revision>
      <id>864079498</id>
      <parentid>854218748</parentid>
      <timestamp>2018-10-14T23:53:59Z</timestamp>
      <contributor>
        <username>Maximillion Pegasus</username>
        <id>3208603</id>
      </contributor>
      <minor/>
      <comment>c/e</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18328">{{Use dmy dates|date=July 2013}}
In [[mathematics]], a '''Hadamard matrix''', named after the French [[mathematician]] [[Jacques Hadamard]], is a [[square matrix]] whose entries are either +1 or &amp;minus;1 and whose rows are mutually [[orthogonal]]. In geometric terms, this means that each pair of rows in a Hadamard matrix represents two [[perpendicular]] [[vector space|vector]]s, while in [[combinatorics|combinatorial]] terms, it means that each pair of rows has matching entries in exactly half of their columns and mismatched entries in the remaining columns. It is a consequence of this definition that the corresponding properties hold for columns as well as rows. The ''n''-dimensional [[parallelepiped|parallelotope]] spanned by the rows of an ''n''×''n'' Hadamard matrix has the maximum possible ''n''-dimensional [[volume]] among parallelotopes spanned by vectors whose entries are bounded in [[absolute value]] by 1. Equivalently, a Hadamard matrix has maximal [[determinant]] among matrices with entries of absolute value less than or equal to 1 and so is an extremal solution of [[Hadamard's maximal determinant problem]].

Certain Hadamard matrices can almost directly be used as an [[error-correcting code]] using a [[Hadamard code]] (generalized in [[Reed–Muller code]]s), and are also used in [[balanced repeated replication]] (BRR), used by [[statistician]]s to estimate the [[variance]] of a [[parameter]] [[estimator]].

==Properties==
Let ''H'' be a Hadamard matrix of order ''n''. The transpose of ''H'' is closely related to its inverse. In fact:

:&lt;math&gt; H H^{\mathrm{T}} = n I_n \ &lt;/math&gt;

where ''I&lt;sub&gt;n&lt;/sub&gt;'' is the ''n'' &amp;times; ''n'' [[identity matrix]] and ''H''&lt;sup&gt;T&lt;/sup&gt; is the [[transpose]] of ''H''. To see that this is true, notice that the rows of ''H'' are all orthogonal vectors over the field of real numbers and each have length &lt;math&gt;\sqrt n&lt;/math&gt;. Dividing ''H'' through by this length gives an [[orthogonal matrix]] whose transpose is thus its inverse. Multiplying by the length again gives the equality above. As a result,

:&lt;math&gt; \operatorname{det}(H) = \pm n^{\frac{n}{2}}, &lt;/math&gt;

where det(''H'') is the [[determinant]] of ''H''.

Suppose that ''M'' is a complex matrix of order ''n'', whose entries are bounded by |''M&lt;sub&gt;ij&lt;/sub&gt;''| ≤1, for each ''i'', ''j'' between 1 and ''n''. Then [[Hadamard's inequality|Hadamard's determinant bound]] states that

:&lt;math&gt; |\operatorname{det}(M)| \leq n^{n/2}. &lt;/math&gt;

Equality in this bound is attained for a real matrix ''M'' if and only if ''M'' is a Hadamard matrix.

The order of a Hadamard matrix must be 1, 2, or a multiple of 4.

==Sylvester's construction==
Examples of Hadamard matrices were actually first constructed by [[James Joseph Sylvester]] in 1867. Let ''H'' be a Hadamard matrix of order ''n''. Then the partitioned matrix
:&lt;math&gt;\begin{bmatrix} H &amp; H\\ H &amp; -H\end{bmatrix}&lt;/math&gt;
is a Hadamard matrix of order 2''n''. This observation can be applied repeatedly and leads to the following sequence of matrices, also called [[Walsh matrix|Walsh matrices]].

:&lt;math&gt;
H_1 = \begin{bmatrix}
1      \end{bmatrix},
&lt;/math&gt;

:&lt;math&gt;
H_2 = \begin{bmatrix}
1 &amp;  1 \\
1 &amp; -1 \end{bmatrix},
&lt;/math&gt;

:&lt;math&gt;
H_4 = \begin{bmatrix}
1 &amp;  1 &amp;  1 &amp;  1\\
1 &amp; -1 &amp;  1 &amp; -1\\
1 &amp;  1 &amp; -1 &amp; -1\\
1 &amp; -1 &amp; -1 &amp;  1\end{bmatrix},
&lt;/math&gt;

and

:&lt;math&gt;
H_{2^k} = \begin{bmatrix}
H_{2^{k-1}} &amp;  H_{2^{k-1}}\\
H_{2^{k-1}}  &amp; -H_{2^{k-1}}\end{bmatrix} = H_2\otimes H_{2^{k-1}},
&lt;/math&gt;

for &lt;math&gt; 2 \le k \in N &lt;/math&gt;, where &lt;math&gt; \left.\otimes\right. &lt;/math&gt; denotes the [[Kronecker product]].

In this manner, Sylvester constructed Hadamard matrices of order 2&lt;sup&gt;''k''&lt;/sup&gt; for every non-negative integer ''k''.&lt;ref&gt;J.J. Sylvester. ''Thoughts on inverse orthogonal matrices, simultaneous sign successions, and tessellated pavements in two or more colours, with applications to Newton's rule, ornamental tile-work, and the theory of numbers.'' [[Philosophical Magazine]], 34:461–475, 1867&lt;/ref&gt;

Sylvester's matrices have a number of special properties. They are [[Symmetric matrix|symmetric]] and, when ''k''&amp;nbsp;≥&amp;nbsp;1, have [[Trace (linear algebra)|trace]] zero. The elements in the first column and the first row are all [[Positive number|positive]]. The elements in all the other rows and columns are evenly divided between [[sign (mathematics)|positive and negative]]. Sylvester matrices are closely connected with [[Walsh function]]s.

==Alternative construction==
If we map the elements of the Hadamard matrix using the [[group homomorphism]] &lt;math&gt; \{1,-1,\times\}\mapsto \{0,1,\oplus\} &lt;/math&gt;, we can describe an alternative construction of Sylvester's Hadamard matrix. First consider the matrix &lt;math&gt; F_n &lt;/math&gt;, the &lt;math&gt; n\times 2^n &lt;/math&gt; matrix whose columns consist of all ''n''-bit numbers arranged in ascending counting order. We may define &lt;math&gt; F_n &lt;/math&gt; recursively by

:&lt;math&gt;
F_1=\begin{bmatrix}
0 &amp; 1\end{bmatrix}
&lt;/math&gt;

:&lt;math&gt;
F_n=\begin{bmatrix}
0_{1\times 2^{n-1}} &amp; 1_{1\times 2^{n-1}} \\
F_{n-1}             &amp; F_{n-1}             \end{bmatrix}.
&lt;/math&gt;

It can be shown by induction that the image of the Hadamard matrix under the above homomorphism is given by

:&lt;math&gt;
H_{2^n}=F_n^{\rm T}F_n.
&lt;/math&gt;

This construction demonstrates that the rows of the Hadamard matrix &lt;math&gt; H_{2^n} &lt;/math&gt; can be viewed as a length &lt;math&gt; 2^n &lt;/math&gt; linear [[Error Correcting Code|error-correcting code]] of [[Linear code#Popular notation|rank]] ''n'', and [[Linear code#Properties|minimum distance]] &lt;math&gt; 2^{n-1} &lt;/math&gt; with [[Linear code#Popular notation|generating matrix]] &lt;math&gt; F_n. &lt;/math&gt;

This code is also referred to as a [[Walsh code]]. The [[Hadamard code]], by contrast, is constructed from the Hadamard matrix &lt;math&gt; H_{2^n} &lt;/math&gt; by a slightly different procedure.

==Hadamard conjecture==
The most important open question in the theory of Hadamard matrices is that of existence. The '''Hadamard conjecture''' proposes that a Hadamard matrix of order 4''k'' exists for every positive integer ''k''. The Hadamard conjecture has also been attributed to Paley, although it was considered implicitly by others prior to Paley's work.&lt;ref&gt;{{cite journal
 | last1 = Hedayat | first1 = A.
 | last2 = Wallis | first2 = W. D.
 | issue = 6
 | journal = [[Annals of Statistics]]
 | jstor = 2958712
 | mr = 523759
 | pages = 1184–1238
 | title = Hadamard matrices and their applications
 | url = http://projecteuclid.org/euclid.aos/1176344370
 | volume = 6
 | year = 1978
 | doi=10.1214/aos/1176344370}}.&lt;/ref&gt;

A generalization of Sylvester's construction proves that if &lt;math&gt;H_n&lt;/math&gt; and &lt;math&gt;H_m&lt;/math&gt; are Hadamard matrices of orders ''n'' and ''m'' respectively, then &lt;math&gt;H_n \otimes H_m&lt;/math&gt; is a Hadamard matrix of order ''nm''. This result is used to produce Hadamard matrices of higher order once those of smaller orders are known.

Sylvester's 1867 construction yields Hadamard matrices of order 1, 2, 4, 8, 16, 32, etc. Hadamard matrices of orders 12 and 20 were subsequently constructed by Hadamard (in 1893).&lt;ref&gt;{{cite journal |first=J. |last=Hadamard |title=Résolution d'une question relative aux déterminants |journal=[[Bulletin des Sciences Mathématiques]] |volume=17 |issue= |pages=240–246 |year=1893 |doi= }}&lt;/ref&gt; In 1933, [[Raymond Paley]] discovered the [[Paley construction]], which produces a Hadamard matrix of order ''q''+1 when ''q'' is any [[prime number|prime]] power that is [[Congruence relation|congruent]] to 3 modulo 4 and that produces a Hadamard matrix of order 2(''q''+1) when ''q'' is a prime power that is congruent to 1 modulo 4.&lt;ref&gt;{{cite journal |first=R. E. A. C. |last=Paley |title=On orthogonal matrices |journal=[[Journal of Mathematics and Physics]] |volume=12 |issue= |pages=311–320 |year=1933 |doi= }}&lt;/ref&gt; His method uses [[finite field]]s.

The smallest order that cannot be constructed by a combination of Sylvester's and Paley's methods is 92. A Hadamard matrix of this order was found using a computer by [[Leonard Baumert|Baumert]], [[Solomon W. Golomb|Golomb]], and [[Marshall Hall (mathematician)|Hall]] in 1962 at [[JPL]].&lt;ref&gt;{{cite journal |first=L. |last=Baumert |first2=S. W. |last2=Golomb |first3=M., Jr. |last3=Hall |title=Discovery of an Hadamard Matrix of Order 92 |journal=[[Bulletin of the American Mathematical Society]] |volume=68 |issue=3 |pages=237–238 |year=1962 |doi=10.1090/S0002-9904-1962-10761-7 |mr=0148686 }}&lt;/ref&gt; They used a construction, due to [[John Williamson (mathematician)|Williamson]],&lt;ref&gt;{{cite journal |first=J. |last=Williamson |title=Hadamard’s determinant theorem and the sum of four squares |journal=[[Duke Mathematical Journal]] |volume=11 |issue=1 |pages=65–81 |year=1944 |doi=10.1215/S0012-7094-44-01108-7 |mr=0009590 }}&lt;/ref&gt; that has yielded many additional orders. Many other methods for constructing Hadamard matrices are now known.

In 2005, Hadi Kharaghani and Behruz Tayfeh-Rezaie published their construction of a Hadamard matrix of order 428.&lt;ref&gt;{{cite journal |first=H. |last=Kharaghani |first2=B. |last2=Tayfeh-Rezaie |title=A Hadamard matrix of order 428 |journal=Journal of Combinatorial Designs |volume=13 |year=2005 |issue=6 |pages=435–440 |doi=10.1002/jcd.20043 }}&lt;/ref&gt; As a result, the smallest order for which no Hadamard matrix is presently known is 668. &lt;!-- Anon contributor: please go to the article's talk page and discuss your objection to this claim; properly sourced material cannot be removed from Wikipedia without a good reason. --&gt;

{{As of|2008}}, there are 13 multiples of 4 less than or equal to 2000 for which no Hadamard matrix of that order is known.&lt;ref name="dokovic"&gt;{{Cite journal| doi=10.1007/s00493-008-2384-z| last=Đoković| first=Dragomir Ž| title=Hadamard matrices of order 764 exist| journal=Combinatorica| year=2008| volume=28| issue=4|pages=487–489| arxiv=math/0703312}}&lt;/ref&gt; They are:
668, 716, 892, 1004, 1132, 1244, 1388, 1436, 1676, 1772, 1916, 1948, and 1964.

==Equivalence of Hadamard matrices==
Two Hadamard matrices are considered [[equivalence relation|equivalent]] if one can be obtained from the other by negating rows or columns, or by interchanging rows or columns. Up to equivalence, there is a unique Hadamard matrix of orders 1, 2, 4, 8, and 12. There are 5 inequivalent matrices of order 16, 3 of order 20, 60 of order 24, and 487 of order 28. Millions of inequivalent matrices are known for orders 32, 36, and 40. Using a [[equivalence relation#Comparing equivalence relations|coarser]] notion of equivalence that also allows [[transpose|transposition]], there are 4 inequivalent matrices of order 16, 3 of order 20, 36 of order 24, and 294 of order 28.&lt;ref&gt;{{cite journal|last=Wanless|first=I.M.|title=Permanents of matrices of signed ones|journal=Linear and Multilinear Algebra |year=2005 |volume=53 |pages=427–433 |doi=10.1080/03081080500093990}}&lt;/ref&gt;

==Skew Hadamard matrices==
A Hadamard matrix ''H'' is ''skew'' if &lt;math&gt;H^{\rm T} + H= 2I. \, &lt;/math&gt;

Reid and Brown in 1972 showed that there exists a "doubly regular [[tournament (graph theory)|tournament]] of order ''n''" if and only if there exists a skew Hadamard matrix of order ''n'' + 1.

==Generalizations and special cases==
Many generalizations and special cases of Hadamard matrices have been investigated in the mathematical literature. One basic generalization is the [[weighing matrix]], a square matrix in which entries may also be zero and which satisfies &lt;math&gt;WW^{T}=wI&lt;/math&gt; for some w, its weight. A weighing matrix with its weight equal to its order is a Hadamard matrix.

Another generalization defines a [[complex Hadamard matrix]] to be a matrix in which the entries are complex numbers of unit [[absolute value|modulus]] and which satisfies ''H H&lt;sup&gt;*&lt;/sup&gt;= n I&lt;sub&gt;n&lt;/sub&gt;'' where ''H&lt;sup&gt;*&lt;/sup&gt;'' is the [[conjugate transpose]] of ''H''. Complex Hadamard matrices arise in the study of [[operator algebras]] and the theory of [[quantum computation]].
[[Butson-type Hadamard matrices]] are complex Hadamard matrices in which the entries are taken to be ''q''&lt;sup&gt;th&lt;/sup&gt; [[roots of unity]]. The term "complex Hadamard matrix" has been used by some authors to refer specifically to the case ''q'' = 4.

[[Regular Hadamard matrices]] are real Hadamard matrices whose row and column sums are all equal. A necessary condition on the existence of a regular ''n''×''n'' Hadamard matrix is that ''n'' be a perfect square. A [[circulant]] matrix is manifestly regular, and therefore a circulant Hadamard matrix would have to be of perfect square order. Moreover, if an ''n''×''n'' circulant Hadamard
matrix existed with ''n'' &gt; 1 then ''n'' would necessarily have to be of the form 4''u''&lt;sup&gt;2&lt;/sup&gt; with ''u'' odd.&lt;ref&gt;{{cite journal |first=R. J. |last=Turyn |title=Character sums and difference sets |journal=[[Pacific Journal of Mathematics]] |volume=15 |issue=1 |pages=319–346 |year=1965 |mr=0179098 |doi=10.2140/pjm.1965.15.319}}&lt;/ref&gt;&lt;ref&gt;{{cite book |first=R. J. |last=Turyn |chapter=Sequences with small correlation |editor-first=H. B. |editor-last=Mann |title=Error Correcting Codes |publisher=Wiley |location=New York |year=1969 |pages=195–228 }}&lt;/ref&gt;

The circulant Hadamard matrix conjecture, however, asserts that, apart from the known 1×1 and 4×4 examples, no such matrices exist. This was verified for all but 26 values of ''u'' less than 10&lt;sup&gt;4&lt;/sup&gt;.&lt;ref&gt;{{cite journal |first=B. |last=Schmidt |title=Cyclotomic integers and finite geometry |journal=[[Journal of the American Mathematical Society]] |volume=12 |issue=4 |pages=929–952 |year=1999 |doi=10.1090/S0894-0347-99-00298-2  |jstor=2646093 }}&lt;/ref&gt;

==Practical applications==
*[[Olivia MFSK]] – an amateur-radio digital protocol designed to work in difficult (low signal-to-noise ratio plus multipath propagation) conditions on shortwave bands.
*[[balanced repeated replication|Balanced Repeated Replication]] (BRR) – a technique used by statisticians to estimate the [[variance]] of a [[statistical estimator]].
*[[Coded aperture]] spectrometry – an instrument for measuring the spectrum of light. The mask element used in coded aperture spectrometers is often a variant of a Hadamard matrix.
*Feedback Delay Networks – Digital reverberation devices which use Hadamard matrices to blend sample values
*[[Plackett–Burman design]] of experiments for investigating the dependence of some measured quantity on a number of independent variables.
*[[Robust parameter design (RPD)|Robust parameter designs]] for investigating noise factor impacts on responses
*[[Compressed Sensing]] for signal processing and undetermined linear systems (inverse problems)
*[[Hadamard transform#Hadamard gate operations|Quantum Hadamard gate]]

==See also==
*[[Hadamard transform]]
*[[Combinatorial design]]
*[[Quincunx matrix]]

==Notes==
{{reflist|2}}

==Further reading==
*{{cite journal|first1=L. D. | last1=Baumert | first2=Marshall | last2=Hall
|title=Hadamard matrices of the Williamson type
|journal=Math. Comp. | year=1965 | volume=19 | number=91 | pages=442–447
|doi=10.1090/S0025-5718-1965-0179093-2  |mr=0179093}}
*{{cite book |first=S. |last=Georgiou |first2=C. |last2=Koukouvinos |first3=J. |last3=Seberry |chapter=Hadamard matrices, orthogonal designs and construction algorithms |pages=133–205 |title=Designs 2002: Further computational and constructive design theory |location=Boston |publisher=Kluwer |year=2003 |isbn=1-4020-7599-5 }}
*{{cite journal | first1=J. M. |last1=Goethals | first2=J. J. | last2=Seidel
|title=A skew Hadamard matrix of order 36 | journal=J. Austral. math. Soc.
|year=1970 | volume=11 | number=3 | pages=343–344
|doi=10.1017/S144678870000673X }}
*{{cite journal|first1=Hiroshi | last1=Kimura
|title=New Hadamard matrix of order 24
|journal=[[Graphs and Combinatorics]] | year=1989 | volume=5 |
pages=235–242 | number=1|doi=10.1007/BF01788676}}
* {{cite journal|doi=10.1214/aoms/1177730883 |first1=Alexander M.
|last1=Mood
|journal=Annals of Mathematical Statistics
|year=1964
|volume=17 |number=4 | title=On Hotelling's Weighing Problem
|pages=432–446}}
*{{cite journal |first=K. B. |last=Reid |first2=E. |last2=Brown |title=Doubly regular tournaments are equivalent to skew Hadamard matrices |journal=J. Combin. Theory Ser. A |volume=12 |year=1972 |issue=3 |pages=332–338 |doi=10.1016/0097-3165(72)90098-2 }}
*{{cite journal| first1=Jennifer | last1=Seberry Wallis
|title=On the existence of Hadamard matrices
|year=1976 | journal=J. Combinat. Theory A | volume=21 | number=2 | doi=10.1016/0097-3165(76)90062-5
|pages=188–195}}
*{{cite journal|first1=Jennifer | last1=Seberry
|title=A construction for generalized hadamard matrices
|year=1980 | journal=J. Statist. Plann. Infer. | volume=4 | number=4 | doi=10.1016/0378-3758(80)90021-X 
|pages=365–368}}
*{{cite journal |first=J. |last=Seberry |first2=B. |last2=Wysocki |first3=T. |last3=Wysocki |title=On some applications of Hadamard matrices |journal=Metrika |volume=62 |year=2005 |issue=2–3 |pages=221–239 |doi=10.1007/s00184-005-0415-y }}
* {{cite journal| first1=Edward | last1=Spence
|title=Classification of hadamard matrices of order 24 and 28
|journal=Discrete Math.
|year=1995 | volume=140 | number=1-3 | pages=185–242 | doi=10.1016/0012-365X(93)E0169-5 
}}
*{{cite book |first=R. K. |last=Yarlagadda |first2=J. E. |last2=Hershey |title=Hadamard Matrix Analysis and Synthesis |year=1997 |location=Boston |publisher=Kluwer |isbn=0-7923-9826-2 }}

==External links==
*[http://rangevoting.org/SkewHad.html Skew Hadamard matrices] of all orders up to 100, including every type with order up to 28;
* {{cite web | url = http://oeis.org/search?q=Hadamard+Matrix | title=Hadamard Matrix}} in [[OEIS]]
* {{cite web | author=[[N. J. A. Sloane]]
|url=http://neilsloane.com/hadamard
|title=Library of Hadamard Matrices}}
*[http://www.iasri.res.in/design/WebHadamard/ On-line utility] to obtain all orders up to 1000, except 668, 716, 876 &amp; 892.
* [http://blogs.jpl.nasa.gov/2013/08/slice-of-history-hadamard-matrix/ JPL: In 1961, mathematicians from NASA’s Jet Propulsion Laboratory and Caltech worked together to construct a Hadamard Matrix containing 92 rows and columns]

{{DEFAULTSORT:Hadamard Matrix}}
[[Category:Design theory]]
[[Category:Matrices]]
[[Category:Unsolved problems in mathematics]]</text>
      <sha1>0ilyf56p17xoblorfhl2y0f9vt0xcz2</sha1>
    </revision>
  </page>
  <page>
    <title>Hattori–Stong theorem</title>
    <ns>0</ns>
    <id>34712196</id>
    <revision>
      <id>846059258</id>
      <parentid>833514150</parentid>
      <timestamp>2018-06-16T00:45:59Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <minor/>
      <comment>fix typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1126">In [[algebraic topology]], the '''Hattori–Stong theorem''', proved by {{harvs|txt|last=Stong|first=Robert Evert|authorlink=Robert Evert Stong|year=1965}} and {{harvs|txt|last=Hattori|first=Akio|authorlink=Akio Hattori|year=1966}},  gives an [[isomorphism]] between the [[stable homotopy]] of a [[Thom spectrum]] and the primitive elements of its [[K-homology]].

==References==

*{{Citation | last=Hattori | first=Akio |authorlink=Akio Hattori| title=Integral characteristic numbers for weakly almost complex manifolds | doi=10.1016/0040-9383(66)90010-3 |mr=0192517 | year=1966 | journal=[[Topology (journal)|Topology. An International Journal of Mathematics]] | issn=0040-9383 | volume=5 | pages=259–280}}
*{{Citation | last=Stong | first=Robert E. | authorlink=Robert Evert Stong| title=Relations among characteristic numbers. I | doi=10.1016/0040-9383(65)90011-X |mr=0192515 | year=1965 | journal=[[Topology (journal)|Topology. An International Journal of Mathematics]] | issn=0040-9383 | volume=4 | pages=267–281}}

{{DEFAULTSORT:Hattori-Stong theorem}}
[[Category:Theorems in algebraic topology]]

{{topology-stub}}</text>
      <sha1>o3i298djfu4b1y6zze1lja4rfetk3q3</sha1>
    </revision>
  </page>
  <page>
    <title>Homotopy principle</title>
    <ns>0</ns>
    <id>481119</id>
    <revision>
      <id>854422003</id>
      <parentid>836002606</parentid>
      <timestamp>2018-08-11T06:54:21Z</timestamp>
      <contributor>
        <ip>2600:1700:5F20:6970:6DB6:208F:5164:4DC3</ip>
      </contributor>
      <comment>the statement that solutions to f'(x) != 0 fail to satisfy the h-principle was utterly and completely wrong, I have written something correct.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10083">[[File:MorinSurfaceAsSphere'sInsideVersusOutside.PNG|thumb|The homotopy principle generalizes such results as Smale's proof of [[sphere eversion]].]]

In [[mathematics]], the '''homotopy principle''' (or '''h-principle''') is a very general way to solve [[partial differential equation]]s (PDEs), and more generally [[partial differential relation]]s (PDRs).  The h-principle is good for [[underdetermined system|underdetermined]] PDEs or PDRs, such as occur in the [[immersion problem]], [[isometric immersion problem]], fluid dynamics, and other areas.

The theory was started by [[Yakov Eliashberg]], [[Mikhail Gromov (mathematician)|Mikhail Gromov]] and [[Anthony V. Phillips]]. It was based on earlier results that reduced partial differential relations to [[homotopy]], particularly for immersions. The first evidence of h-principle appeared in the [[Whitney–Graustein theorem]]. This was followed by the Nash-Kuiper Isometric &lt;math&gt;C^1&lt;/math&gt; embedding theorem and the Smale-Hirsch Immersion theorem.

==Rough idea==

Assume we want to find a function ''&amp;fnof;'' on '''R'''&lt;sup&gt;''m''&lt;/sup&gt; which satisfies a partial differential equation of degree ''k'', in co-ordinates &lt;math&gt;(u_1,u_2,\dots,u_m)&lt;/math&gt;. One can rewrite it as

:&lt;math&gt;\Psi(u_1,u_2,\dots,u_m, J^k_f)=0&lt;/math&gt;

where &lt;math&gt;J^k_f&lt;/math&gt; stands for all partial derivatives of ''&amp;fnof;'' up to order&amp;nbsp;''k''. Let us exchange every variable in &lt;math&gt;J^k_f&lt;/math&gt; for new independent variables &lt;math&gt;y_1,y_2,\dots,y_N.&lt;/math&gt;
Then our original equation can be thought as a system of

:&lt;math&gt;\Psi^{}_{}(u_1,u_2,\dots,u_m,y_1,y_2,\dots,y_N)=0&lt;/math&gt;

and some number of equations of the following type 
:&lt;math&gt;y_j={\partial^k f\over \partial u_{j_1}\ldots\partial u_{j_k}}.&lt;/math&gt;

A solution of

:&lt;math&gt;\Psi^{}_{}(u_1,u_2,\dots,u_m,y_1,y_2,\dots,y_N)=0&lt;/math&gt;

is called a '''non-holonomic solution''', and a solution of the system (which is a solution of our original PDE) is called a '''holonomic solution'''.

In order to check whether a solution exists, first check if there is a non-holonomic solution (usually it is quite easy and if not then our original equation did not have any solutions).

A PDE ''satisfies the h-principle'' if any non-holonomic solution can be [[homotopy|deformed]] into a holonomic one in the class of non-holonomic solutions. Thus in the presence of h-principle, a differential topological problem reduces to an algebraic topological problem. More explicitly this means that apart from the topological obstruction there is no other obstruction to the existence of a holonomic solution. The topological problem of finding a ''non-holonomic solution'' is much easier to handle and can be addressed with the obstruction theory for topological bundles.

Many underdetermined partial differential equations satisfy the h-principle. However, the falsity of an h-principle is also an interesting statement, intuitively this means the objects being studied have non-trivial geometry that cannot be reduced to topology. As an example, embedded [[Lagrangian submanifold|Lagrangians]] in a symplectic manifold do not satisfy an h-principle, to prove this one needs to find invariants coming from [[Pseudoholomorphic curve|pseudo-holomorphic curves]].

== Simple examples ==

=== Monotone functions ===
Perhaps the simplest partial differential relation is for the derivative to not vanish: &lt;math&gt;f'(x) \neq 0.&lt;/math&gt; Properly, this is an ''ordinary'' differential relation, as this is a function in one variable. 

A holonomic solution to this relation is a function whose derivative is nowhere vanishing.  I.e., a strictly monotone differentiable functions, either increasing or decreasing.  The space of such functions consists of two disjoint [[convex set]]s: the increasing ones and the decreasing ones, and has the homotopy type of two points.

A non-holonomic solution to this relation would consist in the data of two functions, a differentiable function f(x), and a continuous function g(x), with g(x) nowhere vanishing.  A holonomic solution gives rise to a non-holonomic solution by taking g(x) = f'(x).  The space of non-holonomic solutions again consists of two disjoint convex sets, according as g(x) is positive or negative.  

Thus the inclusion of holonomic into non-holonomic solutions satisfies the h-principle. 

[[File:Winding Number Around Point.svg|thumb|The [[Whitney–Graustein theorem]] shows that immersions of the circle in the plane satisfy an h-principle, expressed by [[turning number]].]]
This trivial example has nontrivial generalizations:
extending this to immersions of a circle into itself classifies them by order (or [[winding number]]), by lifting the map to the [[universal covering space]] and applying the above analysis to the resulting monotone map – the linear map corresponds to multiplying angle: &lt;math&gt;\theta \mapsto n\theta&lt;/math&gt; (&lt;math&gt;z \mapsto z^n&lt;/math&gt; in complex numbers). Note that here there are no immersions of order 0, as those would need to turn back on themselves. Extending this to circles immersed in the plane – the immersion condition is precisely the condition that the derivative does not vanish – the [[Whitney–Graustein theorem]] classified these by [[turning number]] by considering the homotopy class of the [[Gauss map]] and showing that this satisfies an h-principle; here again order 0 is more complicated.

Smale's classification of immersions of spheres as the homotopy groups of [[Stiefel manifold]]s, and Hirsch's generalization of this to immersions of manifolds being classified as homotopy classes of maps of [[frame bundle]]s are much further-reaching generalizations, and much more involved, but similar in principle – immersion requires the derivative to have rank ''k,'' which requires the partial derivatives in each direction to not vanish and to be linearly independent, and the resulting analog of the Gauss map is a map to the Stiefel manifold, or more generally between frame bundles.

=== A car in the plane ===
As another simple example, consider a car moving in the plane. The position of a car in the plane is determined by three parameters: two coordinates &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; for the location (a good choice is the location of the midpoint between the back wheels) and an angle &lt;math&gt;\alpha&lt;/math&gt; which describes the orientation of the car. The motion of the car satisfies the equation

:&lt;math&gt;\dot x \sin\alpha=\dot y\cos \alpha.&lt;/math&gt;
since a non-skidding car must move in the direction of its wheels. In [[robotics]] terms, not all paths in the task space are [[holonomic (robotics)|holonomic]].

A non-holonomic solution in this case, roughly speaking, corresponds to a motion of the car by sliding in the plane. In this case the non-holonomic solutions are not only [[homotopic]] to holonomic ones but also can be arbitrarily well approximated by the holonomic ones (by going back and forth, like parallel parking in a limited space) – note that this approximates both the position and the angle of the car arbitrarily closely. This implies that, theoretically, it is possible to parallel park in any space longer than the length of your car. It also implies that, in a contact 3 manifold, any curve is &lt;math&gt;C^0&lt;/math&gt;-close to a [[Legendrian knot|Legendrian]] curve.
This last property is stronger than the general h-principle; it is called the &lt;math&gt;C^0&lt;/math&gt;-'''dense h-principle'''.

While this example is simple, compare to the [[Nash embedding theorem]], specifically the [[Nash–Kuiper theorem]], which says that any [[short map|short]] smooth (&lt;math&gt;C^\infty&lt;/math&gt;) embedding or immersion of &lt;math&gt;M^m&lt;/math&gt; in &lt;math&gt;\mathbf{R}^{m+1}&lt;/math&gt; or larger can be arbitrarily well approximated by an isometric &lt;math&gt;C^1&lt;/math&gt;-embedding (respectively, immersion). This is also a dense h-principle, and can be proven by an essentially similar "wrinkling" – or rather, circling – technique to the car in the plane, though it is much more involved.

==Ways to prove the h-principle==
*[[Removal of Singularities]] technique developed by Gromov and Eliashberg
*[[Sheaf technique]] based on the work of Smale and Hirsch.
*[[Convex integration]] based on the work of Nash and Kuiper

==Some paradoxes==

Here we list a few counter-intuitive results which can be proved by applying the 
h-principle:

*'''Cone Eversion'''.&lt;ref&gt;D. Fuchs, S. Tabachnikov, ''Mathematical Omnibus: Thirty Lectures on Classic Mathematics''&lt;/ref&gt; Let us consider functions ''f'' on '''R'''&lt;sup&gt;2&lt;/sup&gt; without origin ''f''(''x'')&amp;nbsp;=&amp;nbsp;|''x''|. Then there is a continuous one-parameter family of functions &lt;math&gt;f_t&lt;/math&gt; such that &lt;math&gt;f_0=f&lt;/math&gt;, &lt;math&gt;f_1=-f&lt;/math&gt; and for any &lt;math&gt;t&lt;/math&gt;, &lt;math&gt;\operatorname{grad}(f_t)&lt;/math&gt; is not zero at any point.
*Any open manifold admits a (non-complete) Riemannian metric of positive (or negative) curvature.
*[[Sphere eversion]] without creasing or tearing can be done using &lt;math&gt;C^1&lt;/math&gt; isometric embedding of &lt;math&gt;S^2&lt;/math&gt;.
*[[Nash embedding theorem]]

== References ==
* Masahisa Adachi, [https://books.google.com/books?id=JcMwHWSBSB4C Embeddings and immersions], translation Kiki Hudson
* Y. Eliashberg, N. Mishachev, [https://books.google.com/books?id=1YVLmDG55XEC Introduction to the h-principle]
*{{Citation|authorlink=Mikhail Gromov (mathematician)|first=M.|last=Gromov|title=Partial differential relations|publisher=Springer|year=1986|ISBN=3-540-12177-3}}
* M. W. Hirsch, Immersions of manifold. Trans. Amer. Math. Soc. 93 (1959)
* N. Kuiper, On &lt;math&gt;C^1&lt;/math&gt; Isometric Imbeddings I, II. Nederl. Acad. Wetensch. Proc. Ser A 58 (1955)
* John Nash, &lt;math&gt;C^1&lt;/math&gt; Isometric Imbedding. Ann. of Math(2) 60 (1954)
* S. Smale, The classification of immersions of spheres in Euclidean spaces. Ann. of Math(2) 69 (1959)
* David Spring, Convex integration theory - solutions to the h-principle in geometry and topology, Monographs in Mathematics 92, Birkhauser-Verlag, 1998
&lt;references/&gt;

{{DEFAULTSORT:Homotopy Principle}}
[[Category:Partial differential equations]]
[[Category:Mathematical principles]]</text>
      <sha1>8k2ugss01wjek07tkuutirqlv4zaiec</sha1>
    </revision>
  </page>
  <page>
    <title>Horn-satisfiability</title>
    <ns>0</ns>
    <id>1227519</id>
    <revision>
      <id>793469837</id>
      <parentid>786999500</parentid>
      <timestamp>2017-08-01T23:10:00Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <minor/>
      <comment>/* Further reading */cleanup, removed stub tag using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6712">In [[formal logic]], '''Horn-satisfiability''', or '''HORNSAT''', is the problem of deciding whether a given set of propositional [[Horn clause]]s is satisfiable or not. Horn-satisfiability and Horn clauses are named after [[Alfred Horn]].

A Horn clause is a [[Clause (logic)|clause]] with at most one positive [[literal (mathematical logic)|literal]], called the ''head'' of the clause, and any number of negative literals, forming the ''body'' of the clause. A Horn formula is a [[propositional formula]] formed by [[logical and|conjunction]] of Horn clauses.

The problem of Horn satisfiability is solvable in [[linear time]].&lt;ref&gt;{{citation
 | last1 = Dowling | first1 = William F.
 | last2 = Gallier | first2 = Jean H. | author2-link = Jean Gallier
 | doi = 10.1016/0743-1066(84)90014-1
 | issue = 3
 | journal = Journal of Logic Programming
 | mr = 770156
 | pages = 267–284
 | title = Linear-time algorithms for testing the satisfiability of propositional Horn formulae
 | volume = 1
 | year = 1984}}&lt;/ref&gt; 
The problem of deciding the truth of quantified Horn formulas can be also solved in polynomial time.&lt;ref name="buningkarpinski"&gt;{{Cite journal | last1 = Buning | first1 = H.K. | last2 = Karpinski| first2 =  Marek| last3=Flogel|first3=A.|year = 1995 | title = Resolution for Quantified Boolean Formulas | place =  | journal = Information and Computation | volume = 117 | issue = 1 | pages = 12–18 | publisher = Elsevier | jstor =  | doi= 10.1006/inco.1995.1025| format =  | accessdate = }}&lt;/ref&gt;
A polynomial-time algorithm for Horn satisfiability is based on the rule of [[unit propagation]]: if the formula contains a clause composed of a single literal &lt;math&gt;l&lt;/math&gt; (a unit clause), then all clauses containing &lt;math&gt;l&lt;/math&gt; (except the unit clause itself) are removed, and all clauses containing &lt;math&gt;\neg l&lt;/math&gt; have this literal removed. The result of the second rule may itself be a unit clause, which is propagated in the same manner. If there are no unit clauses, the formula can be satisfied by simply setting all remaining variables negative. The formula is unsatisfiable if this transformation generates a pair of opposite unit clauses &lt;math&gt;l&lt;/math&gt; and &lt;math&gt;\neg l&lt;/math&gt;.  Horn satisfiability is actually one of the "hardest" or "most expressive" problems which is known to be computable in polynomial time, in the sense that it is a [[P-complete|'''P'''-complete]] problem.&lt;ref name="CookNguyen2010"&gt;{{cite book|author1=Stephen Cook|author2=Phuong Nguyen|title=Logical foundations of proof complexity|url=https://books.google.com/books?id=2aW2sSlQj_QC&amp;pg=PA224|year=2010|publisher=Cambridge University Press|isbn=978-0-521-51729-4|page=224}}&lt;/ref&gt;

This algorithm also allows determining a truth assignment of satisfiable Horn formulae: all variables contained in a unit clause are set to the value satisfying that unit clause; all other literals are set to false. The resulting assignment is the minimal model of the Horn formula, that is, the assignment having a minimal set of variables assigned to true, where comparison is made using set containment.

Using a linear algorithm for unit propagation, the algorithm is linear in the size of the formula.

A generalization of the class of Horn formulae is that of renamable-Horn formulae, which is the set of formulae that can be placed in Horn form by replacing some variables with their respective negation. Checking the existence of such a replacement can be done in linear time; therefore, the satisfiability of such formulae is in P as it can be solved by first performing this replacement and then checking the satisfiability of the resulting Horn formula.&lt;ref&gt;{{cite journal
 | last = Lewis | first = Harry R. | authorlink = Harry R. Lewis
 | doi = 10.1145/322047.322059
 | issue = 1
 | journal = [[Journal of the ACM]]
 | mr = 0468315
 | pages = 134–135
 | title = Renaming a set of clauses as a Horn set
 | volume = 25
 | year = 1978}}.&lt;/ref&gt;&lt;ref&gt;{{cite journal
 | last = Aspvall | first = Bengt
 | doi = 10.1016/0196-6774(80)90007-3
 | issue = 1
 | journal = Journal of Algorithms
 | mr = 578079
 | pages = 97–103
 | title = Recognizing disguised NR(1) instances of the satisfiability problem
 | volume = 1
 | year = 1980}}&lt;/ref&gt;&lt;ref&gt;{{cite journal
 | last = Hébrard | first = Jean-Jacques
 | doi = 10.1016/0304-3975(94)90015-9
 | issue = 2
 | journal = [[Theoretical Computer Science (journal)|Theoretical Computer Science]]
 | mr = 1260003
 | pages = 343–350
 | title = A linear algorithm for renaming a set of clauses as a Horn set
 | volume = 124
 | year = 1994}}.&lt;/ref&gt;&lt;ref&gt;
{{cite journal
| last=Chandru
| first=Vijaya
|author2=Collette R. Coullard |author3=Peter L. Hammer |author4=Miguel Montañez |author5=Xiaorong Sun
 | title=On renamable Horn and generalized Horn functions
| journal=Annals of Mathematics and Artificial Intelligence
| year=2005
| doi=10.1007/BF01531069
| volume=1
| issue=1–4
| pages=33–47
}}&lt;/ref&gt; Horn satisfiability and renamable Horn satisfiability provide one of two important subclasses of satisfiability that are solvable in polynomial time; the other such subclass is [[2-satisfiability]].

The Horn satisfiability problem can also be asked for propositional [[many-valued logic]]s. The algorithms are not usually linear, but some are polynomial; see Hähnle (2001 or 2003) for a survey.&lt;ref&gt;{{cite book|editor=Dov M. Gabbay, Franz Günthner|title=Handbook of philosophical logic|url=https://books.google.com/books?id=_ol81ow-1s4C&amp;pg=PA373|year=2001|publisher=Springer|isbn=978-0-7923-7126-7|page=373|chapter=Advanced many-valued logics|author=Reiner Hähnle|edition=2nd|volume=2}}&lt;/ref&gt;&lt;ref name="FittingOrlowska2003"&gt;{{cite book|editor=Melvin Fitting, Ewa Orlowska|title=Beyond two: theory and applications of multiple-valued logic|year=2003|publisher=Springer|isbn=978-3-7908-1541-2|author=Reiner Hähnle|chapter=Complexity of Many-valued Logics}}&lt;/ref&gt;

==See also==

* [[Unit propagation]]
* [[Boolean satisfiability problem]]
* [[2-satisfiability]]

==References==
&lt;references /&gt;

==Further reading==
* {{cite book | last1=Grädel | first1=Erich | last2=Kolaitis | first2=Phokion G. | last3=Libkin | first3=Leonid | last4=Maarten | first4=Marx | last5=Spencer | first5=Joel | author5-link=Joel Spencer | last6=Vardi | first6=Moshe Y. | author6-link=Moshe Y. Vardi | last7=Venema | first7=Yde | last8=Weinstein | first8=Scott | title=Finite model theory and its applications | zbl=1133.03001 | series=Texts in Theoretical Computer Science. An EATCS Series | location=Berlin | publisher=[[Springer-Verlag]] | isbn=978-3-540-00428-8 | year=2007 }}

[[Category:Logic in computer science]]
[[Category:P-complete problems]]
[[Category:Satisfiability problems]]</text>
      <sha1>pi9o29g8s1fgo4emhf1lf0mw2yl6ih3</sha1>
    </revision>
  </page>
  <page>
    <title>Isometry</title>
    <ns>0</ns>
    <id>254777</id>
    <revision>
      <id>860470370</id>
      <parentid>860469618</parentid>
      <timestamp>2018-09-20T21:40:20Z</timestamp>
      <contributor>
        <username>Jeh</username>
        <id>341372</id>
      </contributor>
      <minor/>
      <comment>Undid revision 860469618 by [[Special:Contributions/TheTrueCipher|TheTrueCipher]] ([[User talk:TheTrueCipher|talk]]) was correct before (subject-verb agreement)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11927">{{About|distance-preserving functions|other mathematical uses|isometry (disambiguation)|non-mathematical uses|Isometric (disambiguation){{!}}Isometric}}
{{Distinguish|Isometric projection}}
{{refimprove|date=June 2016}}

In [[mathematics]], an '''isometry''' (or '''[[congruence (geometry)|congruence]]''', or '''congruent transformation''') is a [[distance]]-preserving transformation between [[metric spaces]], usually assumed to be [[Bijection|bijective]].&lt;ref name=CoxeterIsometryDef&gt;{{harvnb|Coxeter|1969|page=29}} &lt;p&gt;"We shall find it convenient to use the word ''transformation'' in the special sense of a one-to-one correspondence &lt;math&gt; P \to P'&lt;/math&gt; among all points in the plane (or in space), that is, a rule for associating pairs of points, with the understanding that each pair has a first member {{mvar|P}} and a second member {{mvar|P'}} and that every point occurs as the first member of just one pair and also as the second member of just one pair...&lt;p&gt;In particular, an ''isometry'' (or "congruent transformation," or "congruence") is a transformation which preserves length..."&lt;/ref&gt; 
[[File:Academ Reflections with parallel axis on wallpaper.svg|thumb|upright=1.4|A [[Function composition|composition]] of two [[Euclidean group#Direct and indirect isometries|opposite]] isometries is a direct isometry.  [[Reflection (mathematics)|A reflection]] in a line is an opposite isometry, like  {{math|''R''&lt;sub&gt; 1&lt;/sub&gt;}}  or {{math|''R''&lt;sub&gt; 2&lt;/sub&gt;}}  on the image. [[Translation (geometry)|Translation]] {{math|''T''}} is a direct isometry: [[Rigid body|a rigid motion]].&lt;ref&gt;{{harvnb|Coxeter|1969|p=46}} &lt;p&gt;'''3.51''' ''Any direct isometry is either a translation or a rotation. Any opposite isometry is either a reflection or a glide reflection.''&lt;/ref&gt;]]

==Introduction==
Given a metric space (loosely, a set and a scheme for assigning distances between elements of the set), an isometry is a [[Transformation (geometry)|transformation]] which maps elements to the same or another metric space such that the distance between the image elements in the new metric space is equal to the distance between the elements in the original metric space. In a two-dimensional or three-dimensional [[Euclidean space]], two geometric figures are [[Congruence (geometry)|congruent]] if they are related by an isometry;&lt;ref&gt;{{harvnb|Coxeter|1969|page=39}}&lt;p&gt;'''3.11''' ''Any two congruent triangles are related by a unique isometry.''&lt;/ref&gt; the isometry that relates them is either a rigid motion (translation or rotation), or a [[Function composition|composition]] of a rigid motion and a [[Reflection (mathematics)|reflection]].&lt;!--commentary: i presume "they" here means the geometric figures. still commenting out because it doesn't seem to help.--&gt; &lt;!--They are equal, up to an action of a rigid motion, if related by a [[Euclidean group#Direct and indirect isometries|direct isometry]] (orientation preserving).--&gt;

Isometries are often used in constructions where one space is [[Embedding|embedded]] in another space. For instance, the [[Complete space#Completion|completion]] of a metric space ''M'' involves an isometry from ''M'' into ''M''', a [[quotient set]] of the space of [[Cauchy sequence]]s on ''M''. The original space ''M'' is thus isometrically [[isomorphism|isomorphic]] to a subspace of a [[complete metric space]], and it is usually identified with this subspace. Other embedding constructions show that every metric space is isometrically isomorphic to a [[closed set|closed subset]] of some [[normed vector space]] and that every complete metric space is isometrically isomorphic to a closed subset of some [[Banach space]].

An isometric surjective linear operator on a [[Hilbert space]] is called a [[unitary operator]].

==Formal definitions==

Let ''X'' and ''Y'' be [[metric space]]s with metrics ''d''&lt;sub&gt;''X''&lt;/sub&gt; and ''d''&lt;sub&gt;''Y''&lt;/sub&gt;. A [[function (mathematics)|map]] ''f'' : ''X'' → ''Y'' is called an '''isometry''' or '''distance preserving''' if for any ''a'',''b'' ∈ ''X'' one has

:&lt;math&gt;d_Y\left(f(a),f(b)\right)=d_X(a,b).&lt;/math&gt;&lt;ref&gt;{{cite journal
 | last1 = Beckman | first1 = F. S.
 | last2 = Quarles | first2 = D. A., Jr.
 | journal = [[Proceedings of the American Mathematical Society]]
 | mr = 0058193
 | pages = 810–815
 | title = On isometries of Euclidean spaces
 | volume = 4
 | year = 1953
 | doi=10.2307/2032415
 | url=http://www.ams.org/journals/proc/1953-004-05/S0002-9939-1953-0058193-5/S0002-9939-1953-0058193-5.pdf
 | quote=&lt;br&gt;Let {{mvar|T}} be a transformation (possibly many-valued) of &lt;math&gt;E^n&lt;/math&gt; (&lt;math&gt;2\leq n &lt; \infty&lt;/math&gt;) into itself.&lt;br&gt;Let &lt;math&gt;d(p,q)&lt;/math&gt; be the distance between points {{mvar|p}} and {{mvar|q}} of &lt;math&gt;E^n&lt;/math&gt;, and let {{mvar|Tp}}, {{mvar|Tq}} be any images of {{mvar|p}} and {{mvar|q}}, respectively.&lt;br&gt;If there is a length {{mvar|a}} &gt; 0 such that &lt;math&gt;d(Tp,Tq)=a&lt;/math&gt; whenever &lt;math&gt;d(p,q)=a&lt;/math&gt;, then {{mvar|T}} is a Euclidean transformation of &lt;math&gt;E^n&lt;/math&gt; onto itself.}}&lt;/ref&gt;

An isometry is automatically [[Injective function|injective]];&lt;ref name=CoxeterIsometryDef/&gt; otherwise two distinct points, ''a'' and ''b'', could be mapped to the same point, thereby contradicting the coincidence axiom of the metric ''d''. This proof is similar to the proof that an [[order embedding]] between [[partially ordered set]]s is injective. Clearly, every isometry between metric spaces is a topological embedding.

A '''global isometry''', '''isometric isomorphism''' or '''congruence mapping''' is a [[bijective]] isometry. Like any other bijection, a global isometry has a [[function inverse]].  The inverse of a global isometry is also a global isometry.

Two metric spaces ''X'' and ''Y'' are called '''isometric''' if there is a bijective isometry from ''X'' to ''Y''. The [[Set (mathematics)|set]] of bijective isometries from a metric space to itself forms a [[group (mathematics)|group]] with respect to [[function composition]], called the '''[[isometry group]]'''.

There is also the weaker notion of ''path isometry'' or ''arcwise isometry'':

A '''path isometry''' or '''arcwise isometry''' is a map which preserves the [[Arc length#Definition|lengths of curves]]; such a map is not necessarily an isometry in the distance preserving sense, and it need not necessarily be bijective, or even injective. This term is often abridged to simply ''isometry'', so one should take care to determine from context which type is intended.

==Examples==
* Any [[reflection (mathematics)|reflection]], [[translation (geometry)|translation]] and [[rotation]] is a global isometry on Euclidean spaces. See also [[Euclidean group#Overview of isometries in up to three dimensions|Euclidean group]].
*The map &lt;math&gt; x\mapsto |x|&lt;/math&gt; in &lt;math&gt;{\mathbb R}&lt;/math&gt; is a path isometry but not an isometry.  Note that unlike an isometry, it is not injective.
*The isometric [[linear map]]s from '''C'''&lt;sup&gt;''n''&lt;/sup&gt; to itself are given by the [[unitary matrix|unitary matrices]].&lt;ref&gt;{{Cite journal | last1 = Roweis | first1 = S. T. | last2 = Saul | first2 = L. K. | title = Nonlinear Dimensionality Reduction by Locally Linear Embedding | doi = 10.1126/science.290.5500.2323 | journal = [[Science (journal)|Science]]| volume = 290 | issue = 5500 | pages = 2323–2326 | year = 2000 | pmid =  11125150| pmc = }}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Saul |first1=Lawrence K. |last2=Roweis |first2=Sam T. | location=http://jmlr.org/papers/v4/saul03a.html| title= Think globally, fit locally: [[Unsupervised learning]] of [[Differentiable manifolds|nonlinear manifolds]] |journal=[[Journal of Machine Learning Research]]|volume=4|issue=June|pages=119–155|year=2003|quote=Quadratic optimisation of &lt;math&gt;\mathbf M =(I-W)^\top(I-W)&lt;/math&gt; (page 135) such that &lt;math&gt;\mathbf M\equiv YY^\top&lt;/math&gt; }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last=Zhang |first=Zhenyue |last2=Zha|first2=Hongyuan  |title=Principal Manifolds and [[nonlinear dimensionality reduction|Nonlinear Dimension Reduction]] via [[Local Tangent Space Alignment]] |journal=SIAM Journal on Scientific Computing |volume=26 |issue=1 |year=2004 |pages=313–338 |doi=10.1137/s1064827502419154}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Zhang|first1=Zhenyue|last2=Wang|first2=Jing|title=MLLE: Modified Locally Linear Embedding Using Multiple Weights|journal=[[Advances in Neural Information Processing Systems]]|year=2006|volume=19|url=https://papers.nips.cc/paper/3132-mlle-modified-locally-linear-embedding-using-multiple-weights|quote=It can retrieve the ideal embedding if MLLE is applied on data points sampled from an isometric manifold.}}&lt;/ref&gt;

==Linear isometry==

Given two [[normed vector space]]s ''V'' and ''W'', a '''linear isometry''' is a [[linear map]] ''f'' : ''V'' → ''W'' that preserves the norms:
:&lt;math&gt;\|f(v)\| = \|v\|&lt;/math&gt;
for all ''v'' in ''V''.&lt;ref name="Thomsen 2017 p125"&gt;{{cite book |last=Thomsen |first=Jesper Funch |date=2017 |title=Lineær algebra |trans-title=Linear algebra |page=125 |language=Danish |location=Århus |publisher=Department of Mathematics, Aarhus University}}&lt;/ref&gt; Linear isometries are distance-preserving maps in the above sense. They are global isometries if and only if they are [[surjective]].

By the [[Mazur-Ulam theorem]], any isometry of normed vector spaces over '''R''' is [[Affine transformation|affine]].

In an inner product space, the fact that any linear isometry is an orthogonal transformation can be shown by using [[Polarization identity|polarization identities]] to
prove ''&lt;Ax, Ay&gt; = &lt;x, y&gt;''&lt;ref name="Thomsen 2017 p125"/&gt; and then applying the [[Riesz representation theorem]].

==Generalizations==
* Given a positive real number ε, an '''ε-isometry''' or '''almost isometry''' (also called a '''[[Felix Hausdorff|Hausdorff]] approximation''') is a map &lt;math&gt;f:X\to Y&lt;/math&gt; between metric spaces such that
*# for ''x'',''x''&amp;prime; ∈ ''X'' one has |''d''&lt;sub&gt;''Y''&lt;/sub&gt;(ƒ(''x''),ƒ(''x''&amp;prime;))&amp;minus;''d''&lt;sub&gt;''X''&lt;/sub&gt;(''x'',''x''&amp;prime;)| &lt; ε, and
*# for any point ''y'' ∈ ''Y'' there exists a point ''x'' ∈ ''X'' with ''d''&lt;sub&gt;''Y''&lt;/sub&gt;(''y'',ƒ(''x'')) &lt; ε

:That is, an ε-isometry preserves distances to within ε and leaves no element of the codomain further than ε away from the image of an element of the domain.  Note that ε-isometries are not assumed to be [[continuous function|continuous]].

*The '''[[restricted isometry property]]''' characterizes nearly isometric matrices for sparse vectors.
*'''[[Quasi-isometry]]''' is yet another useful generalization.
* One may also define an element in an abstract unital C*-algebra to be an isometry: 
*:&lt;math&gt; a\in\mathfrak{A}&lt;/math&gt; is an isometry if and only if &lt;math&gt; a^* \cdot a = 1 &lt;/math&gt;.
:Note that as mentioned in the introduction this is not necessarily a unitary element because one does not in general have that left inverse is a right inverse.

*On a [[pseudo-Euclidean space]], the term ''isometry'' means a linear bijection preserving magnitude. See also [[Quadratic form#Quadratic spaces|Quadratic spaces]].

==See also==
*[[Motion (geometry)]]
*[[Beckman&amp;ndash;Quarles theorem]]
*[[Semidefinite embedding]]
*[[Flat (geometry)]]
*[[Euclidean plane isometry]]
*[[Orthogonal group#3D isometries that leave the origin fixed|3D isometries that leave the origin fixed]]
*[[Space group]]
*[[Involution (mathematics)|Involution]]
*[[Symmetry in mathematics]]
*[[Homeomorphism group]]
*[[Partial isometry]]
*[[Dual norm#The second dual of a Banach space|The second dual of a Banach space as an isometric isomorphism]]

==References==
{{reflist}}

==Bibliography==
* {{cite book|last=Coxeter|first=H. S. M.|author-link1=Harold Scott MacDonald Coxeter|title=Introduction to Geometry, Second edition|year=1969|publisher=[[John Wiley &amp; Sons|Wiley]]|isbn=9780471504580|ref=harv}}

[[Category:Functions and mappings]]
[[Category:Metric geometry]]
[[Category:Symmetry]]
[[Category:Equivalence (mathematics)]]</text>
      <sha1>b3xgmdp0ogidwfh8z7mq3anjvr1zj2h</sha1>
    </revision>
  </page>
  <page>
    <title>John Brown Clark</title>
    <ns>0</ns>
    <id>48245199</id>
    <revision>
      <id>803323651</id>
      <parentid>769300307</parentid>
      <timestamp>2017-10-01T20:20:42Z</timestamp>
      <contributor>
        <username>Dl2000</username>
        <id>917223</id>
      </contributor>
      <minor/>
      <comment>en-GB</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2833">{{Use dmy dates|date=October 2017}}
{{Use British English|date=October 2017}}
'''John Brown Clark''' or '''Clarke''' CBE LLD [[FRSE]] (1861–1947) was a Scottish mathematician. He was headmaster of [[George Heriot’s School]] from 1908. He served as Vice President of the [[Royal Society of Edinburgh]] 1931–34.&lt;ref name="royalsoced1"&gt;{{cite web|url=https://www.royalsoced.org.uk/cms/files/fellows/biographical_index/fells_indexp1.pdf |format=PDF |title=Former Fellows of The Royal Society of Edinburgh : 1783-2002 |website=Royalsoced.org.uk |accessdate=2015-12-03}}&lt;/ref&gt;

==Life==
He was born in [[West Linton]] on 30 April 1861 the son of George Clark from [[Newbigging, South Lanarkshire]]. He attended West Linton School and then from 1877 the Heriot School at Abbeyhill in Edinburgh. From 1881 he trained at the Established Church Training College in Edinburgh. From 1883 to 1885 he served as an assistant teacher at St Leonards school in Edinburgh, then studied for a degree at [[Edinburgh University]], graduating MA in 1889. He then obtained a job teaching mathematics at [[George Heriot’s School]]. In 1908 he succeeded [[David Fowler Lowe]] as headmaster and served in that role until 1926.&lt;ref name="st-and1"&gt;{{cite web|url=http://www-groups.dcs.st-and.ac.uk/history/Biographies/Clark_John.html |title=Clark John; biography |publisher=Groups.dcs.st-and.ac.uk |date= |accessdate=2015-12-03}}&lt;/ref&gt; He was succeeded in his role by [[William Gentle (headmaster)|William Gentle]] [[FRSE]].&lt;ref&gt;http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Gentle.html&lt;/ref&gt;

In 1891 he was elected a Fellow of the [[Royal Society of Edinburgh]],&lt;ref&gt;{{cite web|url=http://www-groups.dcs.st-and.ac.uk/history/Societies/FRSE.html |title=Fellows of the RSE |publisher=Groups.dcs.st-and.ac.uk |date= |accessdate=2015-12-03}}&lt;/ref&gt; his proposers including [[John Murray (oceanographer)|Sir John Murray]], [[George Chrystal]], [[Peter Guthrie Tait]] and [[David Fowler Lowe]]. He served there as a Councillor 1928–31 and as their Vice-President from 1931–34. He was awarded a Commander of the Order of the British Empire in 1935.&lt;ref name="royalsoced1"/&gt;&lt;ref&gt;{{cite web|url=https://www.thegazette.co.uk/London/issue/34166/supplement/3605/data.pdf |format=PDF |title=Supplement to the London Gazette |date=3 June 1935 |website=Thegazette.co.uk |accessdate=2015-12-03}}&lt;/ref&gt;

He died on 19 July 1947.

==Family==
He married Mary Mackay in 1891.

==Other roles==
He joined the Edinburgh Mathematical Society in December 1885. He served as their Secretary 1891–96, Vice-President 1896–97 and President 1897–98.&lt;ref name="st-and1"/&gt;

==References==
{{Reflist}}

{{DEFAULTSORT:Clark, John Brown}}
[[Category:1861 births]]
[[Category:1947 deaths]]
[[Category:Fellows of the Royal Society of Edinburgh]]


{{mathematician-stub}}</text>
      <sha1>srh1a63ojcu8ex9ewhposcv6pymnvps</sha1>
    </revision>
  </page>
  <page>
    <title>List of curves topics</title>
    <ns>0</ns>
    <id>469391</id>
    <revision>
      <id>866966066</id>
      <parentid>814888678</parentid>
      <timestamp>2018-11-02T18:57:15Z</timestamp>
      <contributor>
        <ip>173.68.139.31</ip>
      </contributor>
      <comment>[[road curve]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3329">This is an alphabetical index of articles related to curves. See also [[curve]], [[list of curves]], and [[list of differential geometry topics]].
* [[acnode]]
* [[algebraic curve]]
* [[Arc (geometry)|arc]]
* [[asymptote]]
* [[asymptotic curve]]
* [[Barbier's theorem]]
* [[Bézier curve]]
* [[Bézout's theorem]]
* [[Birch and Swinnerton-Dyer conjecture]]
* [[Bitangent]]
* [[Bitangents of a quartic]]
* [[Cartesian coordinate system]]
* [[caustic (mathematics)|caustic]]
* [[Cesàro equation]]
* [[chord (geometry)]]
* [[cissoid]]
* [[circumference]]
* [[closed timelike curve]]
* [[concave function|concavity]]
* [[conchoid (mathematics)]]
* [[confocal]]
* [[contact (mathematics)]]
* [[contour line]]
* [[crunode]]
* [[cubic Hermite curve]]
* [[curvature]]
* [[curve orientation]]
* [[curve fitting]]
** [[curve-fitting compaction]]
* [[curve of constant width]]
* [[curve of pursuit]]
* [[curves in differential geometry]]
* [[cusp (singularity)|cusp]]
* [[cyclogon]]
* [[De Boor algorithm]]
* [[differential geometry of curves]]
* [[eccentricity (mathematics)]]
* [[elliptic curve cryptography]]
* [[envelope (mathematics)]]
* [[Fenchel's theorem]]
* [[genus (mathematics)]]
* [[geodesic]]
* [[geometric genus]]
* [[great-circle distance]]
* [[harmonograph]]
* [[hedgehog (curve)|hedgehog]][http://mathworld.wolfram.com/Hedgehog.html]
* [[Hilbert's sixteenth problem]]
* [[hyperelliptic curve cryptography]]
* [[inflection point]]
* [[inscribed square problem]]
* [[intercept (disambiguation)|intercept]], [[y-intercept]], [[root of a function|x-intercept]]
* [[intersection number]]
* [[intrinsic equation]]
* [[isoperimetric inequality]]
* [[Jordan curve]]
** [[Jordan curve theorem]]
* [[knot]]
* [[limit cycle]]
* [[linking coefficient]]
* [[list of circle topics]]
* [[loop (knot)]]
* [[M-curve]]
* [[Mannheim curve]][https://web.archive.org/web/20041028053740/http://www.mathcurve.com/courbes2d/mannheim/mannheim]
* [[meander (mathematics)]]
* [[Mordell conjecture]]
* [[natural representation]]
* [[opisometer]]
* [[orbital elements]]
* [[osculating circle]]
* [[osculating plane]]
* [[Osgood curve]]
* [[parallel (curve)]]
* [[parallel transport]]
* [[parametric curve]]
** [[Bézier curve]]
** [[spline (mathematics)]]
*** [[Hermite spline]]
**** [[Beta spline]]
***** [[B-spline]]
*** [[higher-order spline]]
*** [[NURBS]]
* [[perimeter]]
* [[pi]]
* [[plane curve]]
* [[Pochhammer contour]]
* [[polar coordinate system]]
* [[prime geodesic]]
* [[projective line]]
* [[Line (mathematics)#Ray|ray]]
* [[regular parametric representation]]
* [[Reuleaux triangle]]
* [[Ribaucour curve]][https://web.archive.org/web/20041028123533/http://www.mathcurve.com/courbes2d/ribaucour/ribaucour][http://www.sciences-en-ligne.com/momo/chronomath/chrono2/Ribaucour.html]
* [[Riemann–Hurwitz formula]]
* [[Riemann–Roch theorem]]
* [[Riemann surface]]
* [[road curve]]
* [[Sato–Tate conjecture]]
* [[secant (disambiguation)|secant]]
* [[singular solution]]
* [[sinuosity]]
* [[slope]]
* [[space curve]]
* [[spinode]]
* [[square wheel]]
* [[subtangent]]
* [[tacnode]]
* [[tangent]]
* [[tangent space]]
* [[tangential angle]]
* [[torsion of curves]]
* [[trajectory]]
* [[transcendental curve]]
* [[W-curve]]
* [[Whewell equation]]
* [[world line]]

{{Curves}}

[[Category:Curves| ]]
[[Category:Mathematics-related lists|Curve]]</text>
      <sha1>01fderyt6pmkznqyklwe5jszyzim42r</sha1>
    </revision>
  </page>
  <page>
    <title>Margin at risk</title>
    <ns>0</ns>
    <id>49068749</id>
    <revision>
      <id>754488313</id>
      <parentid>748644230</parentid>
      <timestamp>2016-12-12T23:00:11Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Financial risk]]; added [[Category:Financial risk management]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1761">The '''Margin-at-Risk''' (short: '''MaR''') is a quantity used to manage short-term liquidity risks due to variation of margin requirements, i.e. it is a [[financial risk]] occurring when [[commodity market|trading commodities]]. Similar to the [[Value at risk|Value-at-Risk (VaR)]], but instead of the [[Earnings before interest and taxes|EBIT]] it is a [[quantile]] of the (expected) [[cash flow]] distribution. 

== Description ==
A '''MaR''' requires (1) a currency, (2) a confidence level (e.g. 90%) and (3) a holding period (e.g. 3 days).
The idea is that a given portfolio loss will be compensated by a [[margin (finance)|margin]] call by the same amount.&lt;ref name=CircRef&gt;{{cite journal|last1=Lang|first1=Joachim|last2=Madlener|first2=Reinhard|title=Portfolio optimization for power pl ants: the impact of credit risk mitigation and margining|journal=Institute for Future Energy Consumer Needs and Behavior - Working Paper|date=September 2010|url=https://www.rwth-aachen.de/global/show_document.asp?id=aaaaaaaaaagvveh|accessdate=1 January 2016|location=Aachen, Germany}}&lt;/ref&gt;
The MaR quantifies the "worst case" margin-call and is only driven by market prices.&lt;ref name=Roeschh2013&gt;{{cite book|last1=Rösch|first1=Daniel|last2=Scheule|first2=Harald|title=Credit Securitisations and Derivatives Challenges for the Global Markets|date=2013|publisher=Wiley|location=New York|isbn=978-1-119-96604-3|page=286|edition=2nd |url=https://books.google.de/books?id=HYiB-mSkjWQC&amp;pg=PA286#v=onepage&amp;q&amp;f=false}}&lt;/ref&gt;

== See also ==
* [[Liquidity at risk]]
* [[Value at risk]]
* [[Profit at risk]]

== References ==
{{reflist}}

{{Financial risk}}

[[Category:Mathematical finance]]
[[Category:Financial risk management]]
[[Category:Monte Carlo methods in finance]]</text>
      <sha1>a0yop5q5i0iro2efo8j6n3fva0pcfpr</sha1>
    </revision>
  </page>
  <page>
    <title>Material implication (rule of inference)</title>
    <ns>0</ns>
    <id>244516</id>
    <revision>
      <id>864147435</id>
      <parentid>857234842</parentid>
      <timestamp>2018-10-15T11:53:35Z</timestamp>
      <contributor>
        <ip>81.159.164.255</ip>
      </contributor>
      <comment>Replaced ungrammatical "and can replace each other" (e.g., missing subject) with "and that either form can replace the other"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2499">{{Other uses|Material implication (disambiguation){{!}}Material implication}}
{{distinguish|Material inference}}
{{Transformation rules}}

In [[propositional logic]], '''material implication'''&lt;ref&gt;{{cite book |last=Hurley |first=Patrick |title=A Concise Introduction to Logic |edition=4th |year=1991 |publisher=Wadsworth Publishing |pages=364–5}}&lt;/ref&gt;&lt;ref&gt;{{cite book |last1=Copi |first1=Irving M. |authorlink1=Irving Copi |last2=Cohen |first2=Carl |authorlink2=Carl Cohen (professor)|title=Introduction to Logic |publisher=Prentice Hall |year=2005 |page=371}}&lt;/ref&gt; is a [[Validity (logic)|valid]] [[rule of replacement]] that allows for a [[material conditional|conditional statement]] to be replaced by a [[logical disjunction|disjunction]] in which the [[antecedent (logic)|antecedent]] is [[negation|negated]]. The rule states that ''P implies Q'' is [[Logical equivalence|logically equivalent]] to ''not-P or Q'' and that either form can replace the other in [[formal proof|logical proofs]].

:&lt;math&gt;P \to Q \Leftrightarrow \neg P \lor Q&lt;/math&gt;

Where "&lt;math&gt;\Leftrightarrow&lt;/math&gt;" is a [[metalogic]]al [[symbol (formal)|symbol]] representing "can be replaced in a proof with."

== Formal notation ==
The ''material implication'' rule may be written in [[sequent]] notation:
:&lt;math&gt;(P \to Q) \vdash (\neg P \lor Q)&lt;/math&gt;
where &lt;math&gt;\vdash&lt;/math&gt; is a metalogical symbol meaning that &lt;math&gt;(\neg P \lor Q)&lt;/math&gt; is a [[logical consequence|syntactic consequence]] of &lt;math&gt;(P \to Q)&lt;/math&gt; in some logical system;

or in [[rule of inference|rule form]]:
:&lt;math&gt;\frac{P \to Q}{\neg P \lor Q}&lt;/math&gt;
where the rule is that wherever an instance of "&lt;math&gt;P \to Q&lt;/math&gt;" appears on a line of a proof, it can be replaced with "&lt;math&gt;\neg P \lor Q&lt;/math&gt;";

or as the statement of a truth-functional [[Tautology (logic)|tautology]] or [[theorem]] of propositional logic:

:&lt;math&gt;(P \to Q) \to (\neg P \lor Q)&lt;/math&gt;

where &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;Q&lt;/math&gt; are propositions expressed in some [[formal system]].

==Example==
An example is:

: If it is a bear, then it can swim.
: Thus, it is not a bear or it can swim.

where &lt;math&gt;P&lt;/math&gt; is the statement "it is a bear" and &lt;math&gt;Q&lt;/math&gt; is the statement "it can swim".

If it was found that the bear could not swim, written symbolically as &lt;math&gt;P \land \neg Q&lt;/math&gt;, then both sentences are false but otherwise they are both true.

==References==
{{Reflist}}

[[Category:Rules of inference]]
[[Category:Theorems in propositional logic]]</text>
      <sha1>tait9rrsei21isy85fthuhhnerzw4f4</sha1>
    </revision>
  </page>
  <page>
    <title>Modular invariance</title>
    <ns>0</ns>
    <id>1372589</id>
    <revision>
      <id>542554181</id>
      <parentid>529551838</parentid>
      <timestamp>2013-03-07T09:49:22Z</timestamp>
      <contributor>
        <username>Addbot</username>
        <id>6569922</id>
      </contributor>
      <minor/>
      <comment>[[User:Addbot|Bot:]] Migrating 3 interwiki links, now provided by [[Wikipedia:Wikidata|Wikidata]] on [[d:q60367]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="634">{{Unreferenced stub|auto=yes|date=December 2009}}
In [[theoretical physics]], '''modular invariance''' is the invariance under the [[group (mathematics)|group]] such as SL(2,Z) of [[large diffeomorphism]]s of the [[torus]]. The name comes from the classical name [[modular group]] of this group, as in [[modular form]] theory.

In [[string theory]], modular invariance is an additional requirement for [[one-loop diagram]]s. This helps in getting rid of some [[global anomaly|global anomalies]] such as the [[gravitational anomaly|gravitational anomalies]].

{{DEFAULTSORT:Modular Invariance}}
[[Category:Symmetry]]


{{Physics-stub}}</text>
      <sha1>pjxlas0zw4tgrtzggzcm2wko5xjbj7u</sha1>
    </revision>
  </page>
  <page>
    <title>Neural Networks (journal)</title>
    <ns>0</ns>
    <id>21393064</id>
    <revision>
      <id>866160174</id>
      <parentid>864916689</parentid>
      <timestamp>2018-10-28T17:37:39Z</timestamp>
      <contributor>
        <username>Ethanpet113</username>
        <id>6832171</id>
      </contributor>
      <comment>Remove category (biological)neural networks</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2141">{{Primary sources|date=January 2010}}
{{Infobox journal
| title = Neural Networks
| editor = [[DeLiang Wang]], [[Kenji Doya]]
| discipline = [[Computer science]]
| abbreviation = Neural Netw.
| publisher = [[Elsevier]]
| country =
| frequency = Monthly
| history = 1988-present
| impact = 7.197
| impact-year = 2017
| website = http://www.elsevier.com/locate/neunet
| link1 = http://www.sciencedirect.com/science/journal/08936080
| link1-name = Online access
| cover =&lt;!-- Deleted image removed: [[File:neuronet.gif]] --&gt;
| OCLC = 798872932
| LCCN = 88649048
| CODEN = NNETEB
| ISSN = 0893-6080
| eISSN =
}}
'''''Neural Networks''''' is a monthly [[Peer review|peer-reviewed]] [[scientific journal]] and an official journal of the [[International Neural Network Society]], [[European Neural Network Society]], and [[Japanese Neural Network Society]]. It was established in 1988 and is published by [[Elsevier]].&lt;ref name=profile&gt;[http://www.elsevier.com/wps/find/journaldescription.cws_home/841/description#description Journal description] by Elsevier&lt;/ref&gt; The journal covers all aspects of research on [[artificial neural network]]s. The founding [[editor-in-chief]] was [[Stephen Grossberg]] ([[Boston University]]), the current editors-in-chief are [[DeLiang Wang]] ([[Ohio State University]]) and [[Kenji Doya]] ([[Okinawa Institute of Science and Technology]]). The journal is abstracted and indexed in [[Scopus]] and the [[Science Citation Index]]. According to the ''[[Journal Citation Reports]]'', the journal has a 2016 [[impact factor]] of 5.287.&lt;ref name=WoS&gt;{{cite book |year=2013 |chapter=Neural Networks |title=2012 [[Journal Citation Reports]] |publisher=[[Thomson Reuters]] |edition=Science |series=[[Web of Science]] |postscript=.}}&lt;/ref&gt;

== References ==
{{Reflist}}

== External links ==
* {{Official website|http://www.elsevier.com/locate/neunet}}


[[Category:Artificial neural networks]]
[[Category:Artificial intelligence publications]]
[[Category:Elsevier academic journals]]
[[Category:Publications established in 1988]]
[[Category:Computer science journals]]
[[Category:Monthly journals]]


{{compu-journal-stub}}</text>
      <sha1>hggvlac38immlsagveedaz3bj64ggyr</sha1>
    </revision>
  </page>
  <page>
    <title>Non-credible threat</title>
    <ns>0</ns>
    <id>20914085</id>
    <revision>
      <id>795664685</id>
      <parentid>711753510</parentid>
      <timestamp>2017-08-15T18:13:03Z</timestamp>
      <contributor>
        <ip>24.136.130.14</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1695">{{pp-move-indef}}
{{unreferenced|date=August 2009}}
[[Image:SGPNEandPlainNE_explainingexample.svg|300px|thumb|Illustration that shows the difference between a SPNE and another NE. The blue equilibrium is not subgame perfect because player two makes a non-credible threat at 2(2) to be unkind (U).]]
A '''non-credible threat''' is a term used in [[game theory]] and [[economics]] to describe a threat in a [[sequential game]] that a ''rational'' player would actually not carry out, because it would not be in his best interest to do so. 

For a simple example, suppose person A walks up, carrying a bomb, to another person B. A tells B he will set off the bomb, killing them both, unless B gives him all his money. If A is rational and non-suicidal he stands nothing to gain from setting off the bomb, so his threat cannot be considered credible. On the other hand, a person in the situation of B might give A his money, fearing that A is not rational, or might even be suicidal.

A non-credible threat is made on the hope that it will be believed, and therefore the threatening undesirable action will not need to be carried out. For a threat to be credible within an [[Solution concept|equilibrium]], whenever a [[information set (game theory)| node]] is reached where a threat should be fulfilled, it will be fulfilled. Those [[Nash equilibrium|Nash equilibria]] that rely on non-credible threats can be eliminated through [[backward induction]]; the remaining equilibria are called [[Subgame perfect Nash equilibrium|subgame perfect Nash equilibria]].

==See also==
* [[Dynamic inconsistency]]
* [[Subgame perfect equilibrium]]

{{game theory}}

[[Category:Game theory]]

{{gametheory-stub}}</text>
      <sha1>m3f6hohkrh483x1bbqpmbvi1lq8sx1k</sha1>
    </revision>
  </page>
  <page>
    <title>Object-Z</title>
    <ns>0</ns>
    <id>30872150</id>
    <revision>
      <id>799327223</id>
      <parentid>668039620</parentid>
      <timestamp>2017-09-07T01:02:05Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2345">'''Object-Z'''&lt;ref name="Object-Z Reference Manual"&gt;{{cite book|last1=Smith|first1=Graeme|title=The Object-Z Specification Language|date=2000|publisher=Springer|isbn=978-1-4615-5265-9|url=https://www.springer.com/computer/ai/book/978-0-7923-8684-1}}&lt;/ref&gt; is an [[object-oriented]] extension to the [[Z notation]] developed at the [[University of Queensland]], [[Australia]].

Object-Z extends Z by the addition of [[language construct]]s resembling the [[object-oriented]] paradigm, most notably, [[Class (computer science)|classes]]. Other object-oriented notions such as [[polymorphism (computer science)|polymorphism]] and [[Inheritance (object-oriented programming)|inheritance]] are also supported.

While not as popular as its base language Z, Object-Z has still received significant attention in the [[formal methods]] community, and research on aspects of the language are ongoing, including hybrid languages using Object-Z,&lt;ref&gt;{{cite journal|last1=Mahony|first1=B|last2=Dong|first2=Jin Song|title=Timed Communicating Object Z|journal=IEEE Transactions on Software Engineering|date=Feb 2000|volume=26|issue=2|pages=150–177|doi=10.1109/32.841115|url=http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=841115&amp;isnumber=18187}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Dong|first1=J.S.|last2=Duke|first2=R|last3=Hao|first3=P.|title=Integrating Object-Z with timed automata|journal=Engineering of Complex Computer Systems|date=2005|pages=488–497|doi=10.1109/ICECCS.2005.56|url=http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=1467931&amp;isnumber=31477}}&lt;/ref&gt; tool support (e.g., through the [[Community Z Tools]] project) and [[Refinement calculus|refinement calculi]].&lt;ref name="Object-Z Refinement"&gt;{{cite book|last1=Derrick|first1=John|last2=Boiten|first2=Eerke A.|title=Refinement in Z and Object-Z|date=2014|publisher=Springer|isbn=978-1-4471-5355-9|edition=2nd|url=https://www.springer.com/computer/theoretical+computer+science/book/978-1-4471-5354-2}}&lt;/ref&gt;

== See also ==
* [[Z++]]

== External links ==
* [http://staff.itee.uq.edu.au/smith/objectz/objectz.html The Object-Z Home Page]
* [http://czt.sourceforge.net/ Community Z Tools (CZT) project]

==References==
{{reflist}}

{{Authority control}}
[[Category:Z notation]]
[[Category:Specification languages]]
[[Category:Formal specification languages]]


{{compu-lang-stub}}</text>
      <sha1>86m9rv1c7xlkte39wv7m0qdjj525dy5</sha1>
    </revision>
  </page>
  <page>
    <title>Olinde Rodrigues</title>
    <ns>0</ns>
    <id>1003283</id>
    <revision>
      <id>869898369</id>
      <parentid>869646624</parentid>
      <timestamp>2018-11-21T02:46:54Z</timestamp>
      <contributor>
        <username>Rgdboer</username>
        <id>92899</id>
      </contributor>
      <minor/>
      <comment>/* Bibliography */ rm dup</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7477">[[image:Olinde Rodrigues.jpg|thumb|Olinde Rodrigues]]
'''Benjamin Olinde Rodrigues'''{{pronunciation-needed}} (6 October 1795 – 17 December 1851), more commonly known as '''Olinde Rodrigues''', was a French banker, [[Mathematics|mathematician]], and [[Reform movement|social reformer]].

Rodrigues was born into a well-to-do [[Sephardi Jew]]ish family&lt;ref&gt;Simon Altmann, "Rotations, Quaternions and Double Groups"(Clarendon Press, Oxford, 1986, {{ISBN|0-19-855372-2}}): "The family is often said to have been of Spanish origin, but the spelling of the family name rather suggests Portuguese descent (as indeed asserted by the 'Enciclopedia Universal Illustrada Espasa-Calpe')". For more information on the Rodrigues as Portuguese Jews in Bordeaux see also the Jewish Encyclopedia {{cite web |url=http://www.jewishencyclopedia.com/view.jsp?artid=1332&amp;letter=B |title=? |author= |date= |website= |publisher=[[Jewish Encyclopedia]] |accessdate=}}&lt;/ref&gt; in [[Bordeaux]].

Rodrigues was awarded a [[doctorate]] in mathematics on 28 June 1815 by the [[University of Paris]].&lt;ref&gt;Altmann and Ortiz(2005), p. 12&lt;/ref&gt; His dissertation contains the result now called [[Rodrigues' formula]].&lt;ref&gt;{{cite journal|title=De l'attraction des sphéroïdes|author=Olinde Rodrigues|journal=Correspondence Sur l'École Impériale Polytechnique|volume=3|issue=3|date=January 1816|pages=361–385| url = https://books.google.com/?id=dp4AAAAAYAAJ&amp;pg=PA361#v=onepage&amp;q&amp;f=false}}&lt;/ref&gt;

After graduation, Rodrigues became a banker. A close associate of the [[Claude Henri de Rouvroy, comte de Saint-Simon|Comte de Saint-Simon]], Rodrigues continued, after Saint-Simon's death in 1825, to champion the older man's [[Socialism|socialist]] ideals, a school of thought that came to be known as [[Saint-Simonianism]]. During this period, Rodrigues published writings on politics, social reform, and banking.

In 1840 he published a result on [[transformation group]]s,&lt;ref&gt;Olinde Rodrigues (1840) [https://books.google.com/books?id=f9ZGAAAAcAAJ&amp;pg=PA380#v=onepage&amp;q&amp;f=false "Des lois géométriques qui régissent les déplacements d'un système solide dans l'espace, et de la variation des coordonnées provenant de ces déplacements considérés indépendamment des causes qui peuvent les produire"] (On the geometrical laws that govern the displacements of a solid system in space, and on the change of coordinates resulting from these displacements considered independently of the causes that can produce them), ''Journal de Mathématiques Pures et Appliquées'', vol. 5, pages 380-440.&lt;/ref&gt; which applied [[Leonhard Euler]]'s [[four squares formula]], a precursor to the [[quaternions]] of [[William Rowan Hamilton]], to the problem of representing rotations in space.&lt;ref&gt;John H. Conway, Derek A. Smith, On Quaternions and Octonions: Their Geometry, Arithmetic, and Symmetry. AK Peters, 2003, {{ISBN|1-56881-134-9}}, p. 9&lt;/ref&gt; 
In 1846 [[Arthur Cayley]] acknowledged&lt;ref&gt;[[Arthur Cayley]] (1846) "Sur Quelques Proprietes des Determinants Gauches", [[Crelle's Journal]] 32: 119–23, and ''Collected Mathematical Papers of Arthur Cayley'', volume 1, page 335&lt;/ref&gt; Euler's and Rodrigues' priority describing [[orthogonal transformation]]s.

In mathematics Rodrigues is remembered for three results: [[Rodrigues' rotation formula]] for vectors, the [[Rodrigues formula]] about series of [[orthogonal polynomials]] and the [[Euler–Rodrigues parameters]]. He is also credited as originating the idea of the artist as an [[avant-garde]].&lt;ref name="Margolin"&gt;{{cite book |last1=Margolin |first1=Victor |title=The struggle for utopia: Rodchenko, Lissitzky, Moholy-Nagy, 1917-1946 |date=1997 |publisher=University of Chicago Press |location=Chicago |isbn=13 978-0-226-50516-9 }}&lt;/ref&gt; 

== Publications ==
* ''Mouvement de rotation d'un corps de révolution pesant'', Paris, 1815, [http://jubilotheque.upmc.fr/ead.html?id=TH_000165_001 Read online]
*''De l'attraction des sphéroïdes'', 1815
* ''Théorie de la caisse hypothécaire, ou Examen du sort des emprunteurs, des porteurs d'obligations et des actionnaires de cet établissement'', 1820
* ''Appel : religion saint-simonienne'', 1831
* ''L'artiste, le savant et l'industriel: Dialogue'', 1825
* ''Réunion générale de la famille : séances des 19 et 21 novembre'', 1831
* ''Son premier écrit / Saint-Simon'', 1832
* ''Le disciple de Saint-Simon aux Saint-Simoniens et au public'', 1832
* ''Aux saint-simoniens, 13 février 1832 : bases de la loi morale proposées à l'acceptation des femmes'', 1832
* ''Olinde Rodrigues à M. Michel Chevalier, rédacteur du "Globe" : religion saint-simonienne'', 1832
* ''De l'organisation des banques à propos du projet de loi sur la Banque de France'', 1840
* ''Des lois géométriques qui régissent les déplacements d'un système solide dans l'espace: et de la variation des coordonnées provenant de ces déplacements considérés indépendamment des causes qui peuvent les produire'', 1840
* ''Les Peuples et les diplomates. La Paix ou la guerre'', 1840
* ''Œuvres de Saint-Simon'', 1841
* ''Poésies sociales des ouvriers, réunies et publiées par Olinde Rodrigues'', 1841
* ''Théorie des banques'', 1848
* ''De l'Organisation du suffrage universel, proposition d'un nouveau mode électoral par Olinde Rodrigues'', 1848
* ''Organisation du travail, association du travail et du capital'', 1848
* ''Organisation du travail, bases de l'organisation des banques'', 1848

== See also ==
*[[Euler–Rodrigues formula]]
* [[Spherical harmonics]]

== References ==
{{reflist}}

== External links ==
* [http://maitron-en-ligne.univ-paris1.fr/spip.php?article37200&amp;id_mot=23 Olinde Rodrigues sur Le Maitron]
* [http://www.jewishencyclopedia.com/articles/12799-rodrigues-olinde Olinde Rodrigues sur Jewish Encyclopedia]
* [http://www.nebuleuse-rh.org/olinde.html Olinde Rodrigues] sur le site www.nebuleuse-rh.org

== Bibliography ==
* {{Cite book|language=en|first1=Simon|last1=Altmann|first2=Eduardo L.|last2=Ortiz|title=Mathematics and Social Utopias in France: Olinde Rodrigues and His Times|publisher=AMS|location=Providence RI|year=2005|isbn=978-0-821-83860-0|url=https://books.google.com/books?id=oTyJYUx8Jr4C}}
* [[Louis Gabriel Michaud]] (1863) ''Biographie universelle ancienne et moderne''
* {{cite magazine | author = Simon L. Altmann | title = Hamilton, Rodrigues and the quaternion scandal |magazine=[[Mathematics Magazine]] | year = 1989 | volume = 62 | pages = 291–308 | doi = 10.2307/2689481 | jstor = 2689481 | issue = 5 }}
* {{cite book | author=Simon L. Altmann | title= Rotations, Quaternions and Double Groups | publisher= Dover Publications | year=2005 | isbn = 978-0-486-44518-2}}
* [[Jeremy Gray|Jeremy J. Gray]] (1980) ''Olinde Rodrigues' paper of 1840 on Transformation Groups'', [[Archive for History of Exact Sciences]] 21(4): 375–385, {{doi|10.1007/BF00595376}}.

{{Authority control}}

{{portal bar|mathematics|Business and economics|France}}

{{DEFAULTSORT:Rodrigues, Olinde}}
[[Category:1795 births]]
[[Category:1851 deaths]]
[[Category:People from Bordeaux]]
[[Category:Lycée Louis-le-Grand alumni]]
[[Category:French bankers]]
[[Category:19th-century Sephardi Jews]]
[[Category:Sephardi Jews]]
[[Category:Spanish and Portuguese Jews]]
[[Category:French Jews]]
[[Category:Historical treatment of quaternions]]

[[Category:19th-century French mathematicians]]
[[Category:Saint-Simonists]]
[[Category:Burials at Père Lachaise Cemetery]]
[[Category:Social reformers]]</text>
      <sha1>31xljd0inhtawy9c0juzhhtl0dj1squ</sha1>
    </revision>
  </page>
  <page>
    <title>Olry Terquem</title>
    <ns>0</ns>
    <id>161565</id>
    <revision>
      <id>854662490</id>
      <parentid>854662362</parentid>
      <timestamp>2018-08-12T23:45:14Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>/* top */ lc</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9514">{{For|the French pharmacist and paleontologist|Olry Terquem (paleontologist)}}
{{Infobox writer
| name          = Olry Terquem
| image         = 
| image_size    = 
| alt           = 
| caption       =  
| birth_date    =  16 June 1782
| birth_place   =  [[Metz]], [[France]]
| death_date    =  6 May 1862  (aged 79)
| death_place   =  [[Paris]], [[France]]
| occupation    =  [[mathematician]], [[geometry]]
| alma_mater    =  
}}

'''Olry Terquem''' (16 June 1782 – 6 May 1862) was a [[French people|French]] [[mathematician]]. He is known for his works in [[geometry]] and for founding two [[scientific journal]]s, one of which was the first journal about the [[history of mathematics]]. He was also the [[pseudonym]]ous author (as '''Tsarphati''') of a sequence of letters advocating radical reform in Judaism.&lt;ref name="je"&gt;{{citation|contribution=Terquem, Olry|title=[[Jewish Encyclopedia]]|year=1906|publisher=Funk and Wagnalls|contribution-url=http://www.jewishencyclopedia.com/articles/14337-terquem-olry}}.&lt;/ref&gt; He was [[History of the Jews in France|French Jewish]].

==Education and career==
Terquem grew up speaking [[Yiddish]], and studying only the [[Hebrew language]] and the [[Talmud]].&lt;ref name="waterhouse"&gt;{{citation
 | last = Waterhouse | first = William C. | authorlink = William C. Waterhouse
 | doi = 10.2307/2975573
 | issue = 6
 | journal = The American Mathematical Monthly
 | mr = 707152
 | pages = 378–387
 | title = Do symmetric problems have symmetric solutions?
 | url = http://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/Waterhouse378-387.pdf
 | volume = 90
 | year = 1983}}. Biographical appendix, pp. 385–386.&lt;/ref&gt; However, after the [[French revolution]] his family came into contact with a wider society, and his studies broadened.&lt;ref name="waterhouse"/&gt; Despite his poor French he was admitted to study mathematics at the [[École Polytechnique]] in Paris, beginning in 1801, as only the second Jew to study there.&lt;ref name="je"/&gt;&lt;ref name="waterhouse"/&gt;&lt;ref name="ratcliffe"&gt;{{citation|title=Mathematics and Social Utopias in France: Olinde Rodrigues and His Times|volume=28|series=History of Mathematics|editor1-first=Simon|editor1-last=Altmann|editor2-first=Eduardo L.|editor2-last=Ortiz|publisher=American Mathematical Society|year=2006|isbn=9780821842539|contribution=Chapter 3. Towards a better understanding of Olinde Rodriguez and his circle: family and faith in his life and career|first=Barrie M.|last=Ratcliffe|pages=39–70}}. See in particular [https://books.google.com/books?id=o8hCH7R7TjMC&amp;pg=PA60 pp.&amp;nbsp;60–61].&lt;/ref&gt; He became an assistant there in 1803, and earned his doctorate in 1804.

After finishing his studies he moved to [[Mainz]] (at that time known as Mayence and part of imperial France), where he taught at the Imperial Lycée. In 1811 he moved to the [[School of Applied Artillery (France)|artillery school]] in the same city, in 1814 he moved again to the artillery school in [[Grenoble]], and in 1815 he became the librarian of the Dépôt Central de l'Artillerie in Paris, where he remained for the rest of his life. He became an officer of the [[Legion of Honor]] in 1852. After he died, his funeral was officiated by [[Lazare Isidor]], the [[Chief Rabbi]] of Paris and later of France, and attended by over 12 generals headed by [[Edmond Le Bœuf]].&lt;ref name="je"/&gt;&lt;ref name="waterhouse"/&gt;

==Mathematics==
Terquem translated works concerning [[artillery]], was the author of several textbooks, and became an expert on the history of mathematics.&lt;ref name="waterhouse"/&gt; Terquem and [[Camille-Christophe Gerono]] were the founding editors of the ''[[Nouvelles Annales de Mathématiques]]'' in 1842.&lt;ref name="je"/&gt; Terquem also founded another journal in 1855, the ''Bulletin de Bibliographie, d'Histoire et de Biographie de Mathématiques'', which was published as a supplement to the ''Nouvelles Annales'', and he continued editing it until 1861.&lt;ref name="je"/&gt;&lt;ref name="hm"/&gt; This was the first journal dedicated to the history of mathematics.&lt;ref name="hm"&gt;{{citation
 | last = Dauben | first = Joseph W.
 | doi = 10.1006/hmat.1999.2227
 | issue = 1
 | journal = Historia Mathematica
 | mr = 1677459
 | pages = 1–28
 | title = Historia Mathematica: 25 years/context and content
 | volume = 26
 | year = 1999}}.&lt;/ref&gt;

[[File:Triangle.NinePointCircle.svg|240px|thumb|The nine-point circle of a triangle. The three marked points that lie on the circle and interior to the triangle are the ones found by Terquem. The point of convergence of the three red lines through the triangle is its [[orthocenter]].]]
In [[geometry]], Terquem is known for naming the [[nine-point circle]] and fully proving its properties. This is a [[circle]] that passes through nine special points of any given triangle. [[Karl Wilhelm Feuerbach]] had previously observed that the three [[Orthic triangle|feet of the altitudes]] of a triangle and the three [[Medial triangle|midpoints of its sides]] all lie on a single circle, but Terquem was the first to prove that this circle also contains the midpoints of the [[line segment]]s connecting each vertex to the [[orthocenter]] of the triangle.&lt;ref&gt;{{citation|title=Beautiful Geometry|first1=Eli|last1=Maor|first2=Eugen|last2=Jost|publisher=Princeton University Press|year=2014|isbn=9781400848331|page=140|url=https://books.google.com/books?id=0fOKAQAAQBAJ&amp;pg=PA140}}.&lt;/ref&gt; He also gave a new proof of Feuerbach's theorem that the nine-point circle is [[Incircle and excircles of a triangle|tangent]] to the [[incircle and excircles of a triangle]].&lt;ref name="ratcliffe"/&gt;

Terquem's other contributions to mathematics include naming the [[pedal curve]] of another curve,&lt;ref name="ratcliffe"/&gt; and counting the number of [[perpendicular line]]s from a point to an [[algebraic curve]] as a function of the degree of the curve.&lt;ref name="waterhouse"/&gt; He was also the first to observe that the minimum or maximum value of a [[symmetric function]] is often obtained by setting all variables equal to each other.&lt;ref name="waterhouse"/&gt;

==Jewish activism==
Terquem has been called the first, most radical, and most outspoken of the major proponents of Jewish reform in France,&lt;ref name="meyer"&gt;{{citation|title=Response to Modernity: A History of the Reform Movement in Judaism|first=Michael A.|last=Meyer|publisher=Wayne State University Press|year=1995|isbn=9780814337554|pages=165–167|url=https://books.google.com/books?id=M12toEjI5PEC&amp;pg=PA165}}.&lt;/ref&gt;&lt;ref name="glick"&gt;{{citation|title=Marked in Your Flesh: Circumcision from Ancient Judea to Modern America|first=Leonard B.|last=Glick|publisher=Oxford University Press|year=2005|isbn=9780198039259|pages=137–138|url=https://books.google.com/books?id=SF6fbjNe0yYC&amp;pg=PA137}}.&lt;/ref&gt; "the ''enfant terrible'' of French Judaism".&lt;ref name="meyer"/&gt; He published 27 "letters of an Israelite" under the name "[[Sarfati|Tsarphati]]" (a Hebrew word for a Frenchman),&lt;ref name="glick"/&gt;&lt;ref name="albert"&gt;{{citation|title=Essays in Modern Jewish History: A Tribute to Ben Halpern|series=Herzl Press publications|editor1-first=Phyllis Cohen|editor1-last=Albert|editor2-first=Frances|editor2-last=Malino|publisher=Fairleigh Dickinson University Press|year=1982|isbn=9780838630952|contribution=Nonorthodox attitudes in nineteenth-century French Judaism|first=Phyllis Cohen|last=Albert|pages=121–141}}. See in particular [https://books.google.com/books?id=F8xaoJ2Xy0sC&amp;pg=PA123 p.&amp;nbsp;123].&lt;/ref&gt; pushing for reforms that in his view would better assimilate Jews into modern life&lt;ref name="glick"/&gt; and better accommodate working-class Jews.&lt;ref name="meyer"/&gt; The first nine of these appeared in ''L'Israélite Français'', and the remaining 18 as letters to the editor in ''Courrier de la Moselle''.&lt;ref&gt;{{citation|title=Rites and Passages: The Beginnings of Modern Jewish Culture in France, 1650–1860|series=Jewish Culture and Contexts|first=Jay R.|last=Berkovitz|publisher=University of Pennsylvania Press|year=2011|isbn=9780812200157|page=282|url=https://books.google.com/books?id=CXTGK5ZRswwC&amp;pg=PA282}}.&lt;/ref&gt; Terquem rejected the [[Talmud]],&lt;ref name="albert"/&gt;&lt;ref name="hyman"&gt;{{citation|title=The Jews of Modern France|volume=1|series=Jewish communities in the modern world|first=Paula|last=Hyman|publisher=University of California Press|year=1998|isbn=9780520919297|page=72|url=https://books.google.com/books?id=7vK-yH_0gSgC&amp;pg=PA72}}.&lt;/ref&gt; proposed to codify intermarriage between Jews and non-Jews,&lt;ref name="albert"/&gt; pushed to move the [[sabbath]] to Sunday,&lt;ref name="meyer"/&gt;&lt;ref name="hyman"/&gt; advocated using other languages than Hebrew for prayers,&lt;ref name="waterhouse"/&gt; and fought against [[circumcision]],&lt;ref name="glick"/&gt; regressive attitudes towards women,&lt;ref name="meyer"/&gt; and the [[Jewish calendar]].&lt;ref name="meyer"/&gt; However, he had little effect on the Jewish practices of the time.&lt;ref name="glick"/&gt;&lt;ref name="hyman"/&gt;

Despite Terquem's calls for reform, and despite having married a Catholic woman and raised his children as Catholic,&lt;ref name="meyer"/&gt; he requested that his funeral be held with all the proper Jewish rites.&lt;ref name="je"/&gt;

==References==
{{reflist}}

{{Authority control}}

{{DEFAULTSORT:Terquem, Olry}}
[[Category:1782 births]]
[[Category:1862 deaths]]
[[Category:19th-century French mathematicians]]
[[Category:French Jews]]
[[Category:Geometers]]
[[Category:Historians of mathematics]]
[[Category:Officiers of the Légion d'honneur]]
[[Category:French librarians]]</text>
      <sha1>77m6062i3iwo55ezn5uuj0kv9v8msw2</sha1>
    </revision>
  </page>
  <page>
    <title>Peptide computing</title>
    <ns>0</ns>
    <id>7528959</id>
    <revision>
      <id>723741623</id>
      <parentid>678077451</parentid>
      <timestamp>2016-06-04T23:09:20Z</timestamp>
      <contributor>
        <username>Dcirovic</username>
        <id>11795905</id>
      </contributor>
      <minor/>
      <comment>/* References */refs using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2462">{{no footnotes|date=January 2015}}
'''Peptide computing''' is a form of [[computing]] which uses [[peptide]]s and [[molecular biology]], instead of traditional [[silicon]]-based computer technologies. The basis of this computational model is the affinity of [[antibodies]] towards peptide sequences. Similar to [[DNA computing]], the parallel interactions of peptide sequences and antibodies have been used by this model to solve a few [[NP-complete]] problems.  Specifically, the [[hamiltonian path problem]] (HPP) and some versions of the [[set cover problem]] are a few NP-complete problems which have been solved using this computational model so far. This model of computation has also been shown to be [[Turing completeness|computationally universal]] (or Turing complete).

This model of computation has some critical advantages over [[DNA computing]]. For instance, while [[DNA]] is made of four building blocks, [[peptide]]s are made of twenty building blocks. The peptide-antibody interactions are also more flexible with respect to recognition and affinity than an interaction between a DNA strand and its reverse complement. However, unlike DNA computing, this model is yet to be practically realized. The main limitation is the availability of specific [[monoclonal antibodies]] required by the model.

== See also ==
*[[Biocomputers]]
*[[Computational gene]]
*[[Computational complexity theory]]
*[[DNA computing]]
*[[Molecular electronics]]
*[[Parallel computing]]

== References ==
*{{cite journal
 |  doi = 10.1007/3-540-48017-X_27
 |author1=M. Sakthi Balan |author2=Kamala Krithivasan |author3=Y. Sivasubramanyam |    year = 2001
 |   title = Peptide Computing - Universality and Complexity
 | journal = Lecture Notes in Computer Science
 |  volume = 2340
 |   issue = 
 |   pages = 290&amp;ndash;299
 |     url = http://www.csd.uwo.ca/~sakthi/hpp_revised.ps
 |  series = Lecture Notes in Computer Science
 |  isbn = 978-3-540-43775-8
 }}

*{{cite journal
 |author1=Hubert Hug  |author2=Rainer Schuler
  |lastauthoramp=yes |    year = 2001
 |   title = Strategies for the development of a peptide computer
 | journal = Bioinformatics
 |  volume = 17
 |   issue = 4
 |   pages = 364&amp;ndash;368
 |     url = http://bioinformatics.oxfordjournals.org/cgi/reprint/17/4/364
 |   doi = 10.1093/bioinformatics/17.4.364
| pmid=11301306}}

[[Category:Classes of computers]]
[[Category:Models of computation]]
[[Category:Molecular biology]]


{{Comp-sci-stub}}</text>
      <sha1>8ic6n0cbfff1tk7rmesuhr4euupljty</sha1>
    </revision>
  </page>
  <page>
    <title>Pseudoforest</title>
    <ns>0</ns>
    <id>13511542</id>
    <revision>
      <id>854595055</id>
      <parentid>833938473</parentid>
      <timestamp>2018-08-12T13:29:34Z</timestamp>
      <contributor>
        <ip>149.217.40.222</ip>
      </contributor>
      <comment>/* Enumeration */ corrected count of OEIS sequnce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30321">[[File:Pseudoforest.svg|thumb|upright=1.2|A 1-forest (a maximal pseudoforest), formed by three 1-trees]]
In [[graph theory]], a '''pseudoforest''' is an [[undirected graph]]&lt;ref name=multigraph&gt;The kind of undirected graph considered here is often called a [[multigraph]] or pseudograph, to distinguish it from a [[simple graph]].&lt;/ref&gt; in which every [[Connected component (graph theory)|connected component]] has at most one [[Cycle (graph theory)|cycle]]. That is, it is a system of [[Vertex (graph theory)|vertices]] and [[Edge (graph theory)|edges]] connecting pairs of vertices, such that no two  cycles of consecutive edges share any vertex with each other, nor can any two cycles be connected to each other by a path of consecutive edges.  A '''pseudotree''' is a connected pseudoforest.

The names are justified by analogy to the more commonly studied [[Tree (graph theory)|trees]] and [[Forest (graph theory)|forests]].  (A tree is a connected graph with no cycles; a forest is a disjoint union of trees.)  Gabow and Tarjan&lt;ref name="gt"&gt;{{harvtxt|Gabow|Tarjan|1988}}.&lt;/ref&gt; attribute the study of pseudoforests to Dantzig's 1963 book on [[linear programming]], in which pseudoforests arise in the solution of certain [[Flow network|network flow]] problems.&lt;ref name="dantzig"&gt;{{harvtxt|Dantzig|1963}}.&lt;/ref&gt; Pseudoforests also form graph-theoretic models of functions and occur in several [[algorithm]]ic problems. Pseudoforests are [[sparse graph]]s – they have very few edges relative to their number of vertices – and their [[matroid]] structure allows several other families of sparse graphs to be decomposed as unions of forests and pseudoforests. The name "pseudoforest" comes from {{harvtxt|Picard|Queyranne|1982}}.

==Definitions and structure==
We define an undirected graph to be a set of [[vertex (graph theory)|vertices]] and [[edge (graph theory)|edges]] such that each edge has two vertices (which may coincide) as endpoints.  That is, we allow multiple edges (edges with the same pair of endpoints) and loops (edges whose two endpoints are the same vertex).&lt;ref name=multigraph/&gt;  A [[Glossary of graph theory#Subgraphs|subgraph]] of a graph is the graph formed by any subsets of its vertices and edges such that each edge in the edge subset has both endpoints in the vertex subset.
A [[connected component (graph theory)|connected component]] of an undirected graph is the subgraph consisting of the vertices and edges that can be reached by following edges from a single given starting vertex. A graph is connected if every vertex or edge is reachable from every other vertex or edge. A [[cycle (graph theory)|cycle]] in an undirected graph is a connected subgraph in which each vertex is incident to exactly two edges, or is a loop.&lt;ref&gt;See the linked articles and the references therein for these definitions.&lt;/ref&gt;

[[File:The21.GIF|thumb|The 21 unicyclic graphs with at most six vertices]]
A pseudoforest is an undirected graph in which each connected component contains at most one cycle.&lt;ref&gt;This is the definition used, e.g., by {{harvtxt|Gabow|Westermann|1992}}.&lt;/ref&gt;  Equivalently, it is an undirected graph in which each connected component has no more edges than vertices.&lt;ref&gt;This is the definition in {{harvtxt|Gabow|Tarjan|1988}}.&lt;/ref&gt;  The components that have no cycles are just [[tree (graph theory)|trees]], while the components that have a single cycle within them are called '''1-trees''' or '''unicyclic graphs'''.  That is, a 1-tree is a connected graph containing exactly one cycle.  A pseudoforest with a single connected component (usually called a '''pseudotree''', although some authors define a pseudotree to be a 1-tree) is either a tree or a 1-tree; in general a pseudoforest may have multiple connected components as long as all of them are trees or 1-trees.

If one removes from a 1-tree one of the edges in its cycle, the result is a tree. Reversing this process, if one augments a tree by connecting any two of its vertices by a new edge, the result is a 1-tree; the path in the tree connecting the two endpoints of the added edge, together with the added edge itself, form the 1-tree's unique cycle. If one augments a 1-tree by adding an edge that connects one of its vertices to a newly added vertex, the result is again a 1-tree, with one more vertex; an alternative method for constructing 1-trees is to start with a single cycle and then repeat this augmentation operation any number of times. The edges of any 1-tree can be partitioned in a unique way into two subgraphs, one of which is a cycle and the other of which is a forest, such that each tree of the forest contains exactly one vertex of the cycle.&lt;ref&gt;See, e.g., the proof of Lemma 4 in {{harvtxt|Àlvarez|Blesa|Serna|2002}}.&lt;/ref&gt;

Certain more specific types of pseudoforests have also been studied.
:A '''1-forest''', sometimes called a '''maximal pseudoforest''', is a pseudoforest to which no more edges can be added without causing some component of the graph to contain multiple cycles. If a pseudoforest contains a tree as one of its components, it cannot be a 1-forest, for one can add either an edge connecting two vertices within that tree, forming a single cycle, or an edge connecting that tree to some other component. Thus, the 1-forests are exactly the pseudoforests in which every component is a 1-tree.

:The '''spanning pseudoforests''' of an undirected graph ''G'' are the pseudoforest [[Glossary of graph theory#Subgraphs|subgraphs]] of ''G'' that have all the vertices of ''G''.  Such a pseudoforest need not have any edges, since for example the subgraph that has all the vertices of ''G'' and no edges is a pseudoforest (whose components are trees consisting of a single vertex).

:The '''maximal pseudoforests of''' ''G'' are the pseudoforest subgraphs of ''G'' that are not contained within any larger  pseudoforest of ''G''.  A maximal pseudoforest of ''G'' is always a spanning pseudoforest, but not conversely.  If ''G'' has no connected components that are trees, then its maximal pseudoforests are 1-forests, but if ''G'' does have a tree component, its maximal pseudoforests are not 1-forests.  Stated precisely, in any graph ''G'' its maximal pseudoforests consist of every tree component of ''G'', together with one or more disjoint 1-trees covering the remaining vertices of ''G''.

==Directed pseudoforests==

Versions of these definitions are also used for [[directed graph]]s. Like an undirected graph, a directed graph consists of vertices and edges, but each edge is directed from one of its endpoints to the other endpoint. A '''directed pseudoforest''' is a directed graph in which each vertex has at most one outgoing edge; that is, it has [[outdegree]] at most one. A '''directed 1-forest''' &amp;ndash; most commonly called a '''functional graph''' (see [[#Graphs of functions|below]]), sometimes '''maximal directed pseudoforest''' &amp;ndash; is a directed graph in which each vertex has outdegree exactly one.&lt;ref&gt;{{harvtxt|Kruskal|Rudolph|Snir|1990}} instead use the opposite definition, in which each vertex has indegree one; the resulting graphs, which they call ''unicycular'', are the [[transpose graph|transposes]] of the graphs considered here.&lt;/ref&gt; If ''D'' is a directed pseudoforest, the undirected graph formed by removing the direction from each edge of ''D'' is an undirected pseudoforest.

==Number of edges==
Every pseudoforest on a set of ''n'' vertices has at most ''n'' edges, and every maximal pseudoforest on a set of ''n'' vertices has exactly ''n'' edges. Conversely, if a graph ''G'' has the property that, for every subset ''S'' of its vertices, the number of edges in the [[induced subgraph]] of ''S'' is at most the number of vertices in ''S'', then ''G'' is a pseudoforest.  1-trees can be defined as connected graphs with equally many vertices and edges.&lt;ref name="gt"/&gt;

Moving from individual graphs to graph families, if a family of graphs has the property that every subgraph of a graph in the family is also in the family, and every graph in the family has at most as many edges as vertices, then the family contains only pseudoforests. For instance, every subgraph of a [[thrackle]] (a graph [[graph drawing|drawn]] so that every pair of edges has one point of intersection) is also a thrackle, so [[Conway's thrackle conjecture|Conway's conjecture]] that every thrackle has at most as many edges as vertices can be restated as saying that every thrackle is a pseudoforest. A more precise characterization is that, if the conjecture is true, then the thrackles are exactly the pseudoforests with no four-vertex cycle and at most one odd cycle.&lt;ref&gt;{{harvtxt|Woodall|1969}}; {{harvtxt|Lovász|Pach|Szegedy|1997}}.&lt;/ref&gt;

Streinu and Theran&lt;ref name="st"&gt;{{harvtxt|Streinu|Theran|2009}}.&lt;/ref&gt; generalize the [[sparse graph|sparsity]] conditions defining pseudoforests: they define a graph as being (''k'',''l'')-sparse if every nonempty subgraph with ''n'' vertices has at most ''kn''&amp;nbsp;&amp;minus;&amp;nbsp;''l'' edges, and (''k'',''l'')-tight if it is (''k'',''l'')-sparse and has exactly ''kn''&amp;nbsp;&amp;minus;&amp;nbsp;''l'' edges. Thus, the pseudoforests are the (1,0)-sparse graphs, and the maximal pseudoforests are the (1,0)-tight graphs. Several other important families of graphs may be defined from other values of ''k'' and ''l'',
and when ''l''&amp;nbsp;≤&amp;nbsp;''k'' the (''k'',''l'')-sparse graphs may be characterized as the graphs formed as the edge-disjoint union of ''l'' forests and ''k''&amp;nbsp;&amp;minus;&amp;nbsp;''l'' pseudoforests.&lt;ref&gt;{{harvtxt|Whiteley|1988}}.&lt;/ref&gt;

Almost every sufficiently sparse [[random graph]] is pseudoforest.&lt;ref name="rg"&gt;{{harvtxt|Bollobás|1985}}. See especially Corollary 24, p.120, for a bound on the number of vertices belonging to unicyclic components in a random graph, and Corollary 19, p.113, for a bound on the number of distinct labeled unicyclic graphs.&lt;/ref&gt; That is, if ''c'' is a constant with 0 &amp;lt; ''c'' &amp;lt; 1/2, and P&lt;sub&gt;''c''&lt;/sub&gt;(''n'') is the probability that choosing uniformly at random among the ''n''-vertex graphs with ''cn'' edges results in a pseudoforest, then P&lt;sub&gt;''c''&lt;/sub&gt;(''n'') tends to one in the limit for large ''n''. However, for ''c'' &amp;gt; 1/2, almost every random graph with ''cn'' edges has a large component that is not unicyclic.

==Enumeration==

A graph is ''simple'' if it has no self-loops and no multiple edges with the same endpoints.  The number of simple 1-trees with ''n'' labelled vertices is&lt;ref&gt;{{harvtxt|Riddell|1951}}; see {{OEIS2C|A057500}} in the [[On-Line Encyclopedia of Integer Sequences]].&lt;/ref&gt;
:&lt;math&gt;n \sum_{k=1}^n \frac{(-1)^{k-1}}{k} \sum_{n_1+\cdots+n_k=n} \frac{n!}{n_1! \cdots n_k!} \binom{\binom{n_1}{2}+\cdots +\binom{n_k}{2}}{n}.&lt;/math&gt;
The values for ''n'' up to 300 can be found in sequence {{OEIS2C|A057500}} of the [[On-Line Encyclopedia of Integer Sequences]].

The number of maximal directed pseudoforests on ''n'' vertices, allowing self-loops, is ''n&lt;sup&gt;n&lt;/sup&gt;'', because for each vertex there are ''n'' possible endpoints for the outgoing edge. [[André Joyal]] used this fact to provide a [[bijective proof]] of [[Cayley's formula]], that the number of undirected trees on ''n'' nodes is ''n''&lt;sup&gt;''n''&amp;nbsp;&amp;minus;&amp;nbsp;2&lt;/sup&gt;, by finding a bijection between maximal directed pseudoforests and undirected trees with two distinguished nodes.&lt;ref&gt;{{harvtxt|Aigner|Ziegler|1998}}.&lt;/ref&gt; If self-loops are not allowed, the number of maximal directed pseudoforests is instead (''n''&amp;nbsp;&amp;minus;&amp;nbsp;1)&lt;sup&gt;''n''&lt;/sup&gt;.

==Graphs of functions==
{{redirects here|Functional graph|other uses|Graph of a function}}
[[Image:Functional graph.svg|thumb|upright=1.5|A function from the set {0,1,2,3,4,5,6,7,8} to itself, and the corresponding functional graph]]
Directed pseudoforests and [[endofunction]]s are in some sense mathematically equivalent. Any function ƒ from a set ''X'' to itself (that is, an [[endomorphism]] of ''X'') can be interpreted as defining a directed pseudoforest which has an edge from ''x'' to ''y'' whenever ƒ(''x'') = ''y''. The resulting directed pseudoforest is maximal, and may include [[Loop (graph theory)|self-loops]] whenever some value ''x'' has ƒ(''x'') = ''x''. Alternatively, omitting the self-loops produces a non-maximal pseudoforest. In the other direction, any maximal directed pseudoforest determines a function ƒ such that ƒ(''x'') is the target of the edge that goes out from ''x'', and any non-maximal directed pseudoforest can be made maximal by adding self-loops and then converted into a function in the same way. For this reason, maximal directed pseudoforests are sometimes called '''functional graphs'''.&lt;ref name="gt"/&gt; Viewing a function as a functional graph provides a convenient language for describing properties that are not as easily described from the function-theoretic point of view; this technique is especially applicable to problems involving [[iterated function]]s, which correspond to [[path (graph theory)|paths]] in functional graphs.

[[Cycle detection]], the problem of following a path in a functional graph to find a cycle in it, has applications in [[cryptography]] and [[computational number theory]], as part of [[Pollard's rho algorithm]] for [[integer factorization]] and as a method for finding collisions in [[cryptographic hash function]]s. In these applications, ƒ is expected to behave randomly; [[Philippe Flajolet|Flajolet]] and [[Andrew Odlyzko|Odlyzko]]&lt;ref&gt;{{harvtxt|Flajolet|Odlyzko|1990}}.&lt;/ref&gt; study the graph-theoretic properties of the functional graphs arising from randomly chosen mappings. In particular, a form of the [[birthday paradox]] implies that, in a random functional graph with ''n'' vertices, the path starting from a randomly selected vertex will typically loop back on itself to form a cycle within O({{radic|''n''}}) steps. [[Sergei Konyagin|Konyagin]] et al. have made analytical and computational progress on graph statistics.&lt;ref&gt;{{harvtxt|Konyagin|Luca|Mans|Mathieson|2010}}.&lt;/ref&gt;

Martin, [[Andrew Odlyzko|Odlyzko]], and [[Stephen Wolfram|Wolfram]]&lt;ref&gt;{{harvtxt|Martin|Odlyzko|Wolfram|1984}}.&lt;/ref&gt; investigate pseudoforests that model the dynamics of [[cellular automaton|cellular automata]]. These functional graphs, which they call ''state transition diagrams'', have one vertex for each possible configuration that the ensemble of cells of the automaton can be in, and an edge connecting each configuration to the configuration that follows it according to the automaton's rule. One can infer properties of the automaton from the structure of these diagrams, such as the number of components, length of limiting cycles, depth of the trees connecting non-limiting states to these cycles, or symmetries of the diagram. For instance, any vertex with no incoming edge corresponds to a [[Garden of Eden pattern]] and a vertex with a self-loop corresponds to a [[Still life (cellular automaton)|still life pattern]].

Another early application of functional graphs is in the ''trains'' used to study [[Steiner system|Steiner triple system]]s.&lt;ref&gt;{{harvtxt|White|1913}}; {{harvtxt|Colbourn|Colbourn|Rosenbaum|1982}}; {{harvtxt|Stinson|1983}}.&lt;/ref&gt; The train of a triple system is a functional graph having a vertex for each possible triple of symbols; each triple ''pqr'' is mapped by ƒ to ''stu'', where ''pqs'', ''prt'', and ''qru'' are the triples that belong to the triple system and contain the pairs ''pq'', ''pr'', and ''qr'' respectively. Trains have been shown to be a powerful invariant of triple systems although somewhat cumbersome to compute.

==Bicircular matroid==
A [[matroid]] is a mathematical structure in which certain sets of elements are defined to be [[independence system|independent]], in such a way that the independent sets satisfy properties modeled after the properties of [[linear independence]] in a [[vector space]]. One of the standard examples of a matroid is the [[graphic matroid]] in which the independent sets are the sets of edges in forests of a graph; the matroid structure of forests is important in algorithms for computing the [[minimum spanning tree]] of the graph. Analogously, we may define matroids from pseudoforests.

For any graph ''G'' = (''V'',''E''), we may define a matroid on the edges of ''G'', in which a set of edges is independent if and only if it forms a pseudoforest; this matroid is known as the '''[[bicircular matroid]]''' (or '''bicycle matroid''') of ''G''.&lt;ref&gt;{{harvtxt|Simoes-Pereira|1972}}.&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Matthews|1977}}.&lt;/ref&gt; The smallest dependent sets for this matroid are the minimal connected subgraphs of ''G'' that have more than one cycle, and these subgraphs are sometimes called bicycles. There are three possible types of bicycle: a [[Glossary of graph theory#Walks|theta graph]] has two vertices that are connected by three internally disjoint paths, a figure 8 graph consists of two cycles sharing a single vertex, and a handcuff graph is formed by two disjoint cycles connected by a path.&lt;ref&gt;[http://www.math.binghamton.edu/zaslav/Bsg/glossary.html Glossary of Signed and Gain Graphs and Allied Areas]&lt;/ref&gt;
A graph is a pseudoforest if and only if it does not contain a bicycle as a subgraph.
&lt;ref name="st"/&gt;

==Forbidden minors==
[[Image:Butterfly and diamond graphs.svg|thumb|The [[butterfly graph]] (left) and [[diamond graph]] (right), forbidden [[graph minor|minors]] for pseudoforests]]
Forming a [[Minor (graph theory)|minor]] of a pseudoforest by contracting some of its edges and deleting others produces another pseudoforest. Therefore, the family of pseudoforests is [[Closure (mathematics)|closed]] under minors, and the [[Robertson–Seymour theorem]] implies that pseudoforests can be characterized in terms of a finite set of [[forbidden minor]]s, analogously to [[Wagner's theorem]] characterizing the [[planar graph]]s as the graphs having neither the [[complete graph]] K&lt;sub&gt;5&lt;/sub&gt; nor the [[complete bipartite graph]] K&lt;sub&gt;3,3&lt;/sub&gt; as minors.
As discussed above, any non-pseudoforest graph contains as a subgraph a handcuff, figure 8, or theta graph; any handcuff or figure 8 graph may be contracted to form a ''[[butterfly graph]]'' (five-vertex figure 8), and any theta graph may be contracted to form a ''[[diamond graph]]'' (four-vertex theta graph),&lt;ref&gt;For this terminology, see the [http://www.graphclasses.org/smallgraphs.html list of small graphs] from the [http://www.graphclasses.org/ Information System on Graph Class Inclusions]. However, ''butterfly graph'' may also refer to a different family of graphs related to [[hypercube graph|hypercubes]], and the five-vertex figure 8 is sometimes instead called a ''bowtie graph''.&lt;/ref&gt; so any non-pseudoforest contains either a butterfly or a diamond as a minor, and these are the only minor-minimal non-pseudoforest graphs. Thus, a graph is a pseudoforest if and only if it does not have the butterfly or the diamond as a minor. If one forbids only the diamond but not the butterfly, the resulting larger graph family consists of the [[cactus graph]]s and disjoint unions of multiple cactus graphs.&lt;ref&gt;{{harvtxt|El-Mallah|Colbourn|1988}}.&lt;/ref&gt;

More simply, if [[multigraph]]s with [[self-loop]]s are considered, there is only one forbidden minor, a vertex with two loops.

==Algorithms==
An early algorithmic use of pseudoforests involves the ''network simplex'' algorithm and its application to generalized flow problems modeling the conversion between [[commodity|commodities]] of different types.&lt;ref name="dantzig"/&gt;&lt;ref name="amo"&gt;{{harvtxt|Ahuja|Magnanti|Orlin|1993}}.&lt;/ref&gt; In these problems, one is given as input a [[flow network]] in which the vertices model each commodity and the edges model allowable conversions between one commodity and another. Each edge is marked with a ''capacity'' (how much of a commodity can be converted per unit time), a ''flow multiplier'' (the conversion rate between commodities), and a ''cost'' (how much loss or, if negative, profit is incurred per unit of conversion). The task is to determine how much of each commodity to convert via each edge of the flow network, in order to minimize cost or maximize profit, while obeying the capacity constraints and not allowing commodities of any type to accumulate unused. This type of problem can be formulated as a [[linear program]], and solved using the [[simplex algorithm]]. The intermediate solutions arising from this algorithm, as well as the eventual optimal solution, have a special structure: each edge in the input network is either unused or used to its full capacity, except for a subset of the edges, forming a spanning pseudoforest of the input network, for which the flow amounts may lie between zero and the full capacity. In this application, unicyclic graphs are also sometimes called ''augmented trees'' and maximal pseudoforests are also sometimes called ''augmented forests''.&lt;ref name="amo"/&gt;

The ''minimum spanning pseudoforest problem'' involves finding a spanning pseudoforest of minimum weight in a larger edge-weighted graph ''G''.
Due to the matroid structure of pseudoforests, minimum-weight maximal pseudoforests may be found by [[greedy algorithm]]s similar to those for the [[minimum spanning tree]] problem. However, Gabow and Tarjan found a more efficient linear-time approach in this case.&lt;ref name="gt"/&gt;

The '''pseudoarboricity''' of a graph ''G'' is defined by analogy to the [[arboricity]] as the minimum number of pseudoforests into which its edges can be partitioned; equivalently, it is the minimum ''k'' such that ''G'' is (''k'',0)-sparse, or the minimum ''k'' such that the edges of ''G'' can be oriented to form a directed graph with outdegree at most ''k''. Due to the matroid structure of pseudoforests, the pseudoarboricity may be computed in polynomial time.&lt;ref&gt;{{harvtxt|Gabow|Westermann|1992}}. See also the faster approximation schemes of {{harvtxt|Kowalik|2006}}.&lt;/ref&gt;

A [[random graph|random]] [[bipartite graph]] with ''n'' vertices on each side of its bipartition, and with ''cn'' edges chosen independently at random from each of the ''n''&lt;sup&gt;2&lt;/sup&gt; possible pairs of vertices, is a pseudoforest with high probability whenever ''c'' is a constant strictly less than one. This fact plays a key role in the analysis of [[cuckoo hashing]], a data structure for looking up key-value pairs by looking in one of two hash tables at locations determined from the key: one can form a graph, the "cuckoo graph", whose vertices correspond to hash table locations and whose edges link the two locations at which one of the keys might be found, and the cuckoo hashing algorithm succeeds in finding locations for all of its keys if and only if the cuckoo graph is a pseudoforest.&lt;ref&gt;{{harvtxt|Kutzelnigg|2006}}.&lt;/ref&gt;

Pseudoforests also play a key role in [[parallel algorithm]]s for [[graph coloring]] and related problems.&lt;ref&gt;{{harvtxt|Goldberg|Plotkin|Shannon|1988}}; {{harvtxt|Kruskal|Rudolph|Snir|1990}}.&lt;/ref&gt;

==Notes==
{{reflist|2}}

==References==
{{refbegin|2}}
*{{citation | first1=Ravindra K. | last1=Ahuja | author1-link = Ravindra K. Ahuja | first2 = Thomas L. | last2 = Magnanti | author2-link = Thomas L. Magnanti | first3 = James B. | last3 = Orlin | author3-link = James B. Orlin | title= Network Flows: Theory, Algorithms and Applications | publisher=Prentice Hall | year=1993 | isbn=0-13-617549-X}}.
*{{citation
 | last1 = Aigner | first1 = Martin | author1-link = Martin Aigner
 | last2 = Ziegler | first2 = Günter M. | author2-link = Günter M. Ziegler
 | pages = 141–146
 | publisher = [[Springer-Verlag]]
 | title = [[Proofs from THE BOOK]]
 | year = 1998}}.
*{{citation|last1=Àlvarez|first1=Carme|last2=Blesa|first2=Maria|last3=Serna|first3=Maria|contribution=Universal stability of undirected graphs in the adversarial queueing model|title=Proc. 14th ACM [[Symposium on Parallel Algorithms and Architectures]]|year=2002|pages=183–197|doi=10.1145/564870.564903}}.
*{{citation|first=Béla|last=Bollobás|authorlink=Béla Bollobás|title=Random Graphs|publisher=Academic Press|year=1985}}.
*{{citation|last1=Colbourn|first1=Marlene J.|last2=Colbourn|first2=Charles J.|author2-link = Charles Colbourn|last3=Rosenbaum|first3=Wilf L.|title=Trains: an invariant for Steiner triple systems|journal=[[Ars Combinatoria (journal)|Ars Combinatoria]]|volume=13|year=1982|pages=149–162|mr=0666934}}.
*{{citation|first=G. B.|last=Dantzig|authorlink=George Dantzig|title=Linear Programming and Extensions|publisher=Princeton University Press|year=1963}}.
*{{citation|last1=El-Mallah|first1=Ehab|last2=Colbourn|first2=Charles J.|author2-link=Charles Colbourn|title=The complexity of some edge deletion problems|journal=IEEE Transactions on Circuits and Systems|volume=35|issue=3|year=1988|pages=354–362|doi=10.1109/31.1748}}.
*{{citation|first1=P.|last1=Flajolet|authorlink1=Philippe Flajolet|first2=A.|last2=Odlyzko|authorlink2=Andrew Odlyzko|contribution=Random mapping statistics|publisher=Springer-Verlag|series=Lecture Notes in Computer Science|title=Advances in Cryptology – EUROCRYPT '89: [[Workshop on the Theory and Application of Cryptographic Techniques]]|volume=434|pages=329–354|year=1990}}.
*{{citation|first1=H. N.|last1=Gabow|first2=R. E.|last2=Tarjan|authorlink2=Robert Tarjan|title=A linear-time algorithm for finding a minimum spanning pseudoforest|journal=Information Processing Letters|volume=27|year=1988|issue=5|pages=259–263|doi=10.1016/0020-0190(88)90089-0}}.
*{{citation|first1=H. N.|last1=Gabow|first2=H. H.|last2=Westermann|title=Forests, frames, and games: Algorithms for matroid sums and applications|journal=Algorithmica|volume=7|issue=1|year=1992|pages=465–497|doi=10.1007/BF01758774}}.
*{{citation|first1=A. V.|last1=Goldberg|author1-link=Andrew V. Goldberg|first2=S. A.|last2=Plotkin|first3=G. E.|last3=Shannon|title=Parallel symmetry-breaking in sparse graphs|journal=[[SIAM Journal on Discrete Mathematics]]|volume=1|issue=4|year=1988|pages=434–446|doi=10.1137/0401044}}.
*{{citation
|first1=Sergei
|last1=Konyagin
|first2 = Florian
|last2 = Luca
|first3 = Bernard
|last3 = Mans
|first4 = Luke
|last4 = Mathieson
|first5 = Igor E.
|last5 = Shparlinski
|title = Functional Graphs of Polynomials over Finite Fields
|year = 2010
}}
*{{citation|first=Ł.|last=Kowalik|contribution=Approximation Scheme for Lowest Outdegree Orientation and Graph Density Measures|publisher=Springer-Verlag|editor1-last=Asano|editor1-link=Tetsuo Asano|series=Lecture Notes in Computer Science|editor1-first=Tetsuo|volume=4288|title=Proceedings of the International Symposium on Algorithms and Computation|year=2006|pages=557–566|doi=10.1007/11940128}}.
*{{citation|first1=Clyde P.|last1=Kruskal|authorlink1=Clyde Kruskal|first2=Larry|last2=Rudolph|first3=Marc|last3=Snir|title=Efficient parallel algorithms for graph problems|journal=Algorithmica|year=1990|volume=5|issue=1|pages=43–64|doi=10.1007/BF01840376}}.
*{{citation
 | last1 = Picard | first1 = Jean-Claude
 | last2 = Queyranne | first2 = Maurice
 | doi = 10.1002/net.3230120206
 | issue = 2
 | journal = Networks
 | mr = 670021
 | pages = 141–159
 | title = A network flow solution to some nonlinear 0–1 programming problems, with applications to graph theory
 | volume = 12
 | year = 1982}}.
*{{citation|first=Reinhard|last=Kutzelnigg|contribution-url=https://dmtcs.episciences.org/3486|contribution=Bipartite random graphs and cuckoo hashing|title=Fourth Colloquium on Mathematics and Computer Science|series=Discrete Mathematics and Theoretical Computer Science|year=2006|volume=AG|pages=403–406}}.
*{{citation|first1=L.|last1=Lovász|authorlink1=László Lovász|first2=J.|last2=Pach|first3=M.|last3=Szegedy|authorlink3=Mario Szegedy|title=On Conway's thrackle conjecture|journal=[[Discrete and Computational Geometry]]|volume=18|issue=4|year=1997|pages=369–376|doi=10.1007/PL00009322}}.
*{{citation|first1=O.|last1=Martin|first2=A. M.|last2=Odlyzko|authorlink2=Andrew Odlyzko|first3=S.|last3=Wolfram|authorlink3=Stephen Wolfram|title=Algebraic properties of cellular automata|journal=Communications in Mathematical Physics|volume=93|issue=2|year=1984|pages=219–258|doi=10.1007/BF01223745|url=http://www.stephenwolfram.com/publications/articles/mathematics/84-properties/|bibcode = 1984CMaPh..93..219M }}.
*{{citation|first=L. R.|last=Matthews|title=Bicircular matroids|journal=The Quarterly Journal of Mathematics. Oxford. Second Series|volume=28|year=1977|issue=110|pages=213–227|mr=0505702|doi=10.1093/qmath/28.2.213}}.
*{{citation|first=R. J.|last=Riddell|title=Contributions to the Theory of Condensation|series=Ph.D. thesis|publisher=University of Michigan|place=Ann Arbor|year=1951|bibcode=1951PhDT........20R}}.
*{{citation|first=J. M. S.|last=Simoes-Pereira|title=On subgraphs as matroid cells|journal=[[Mathematische Zeitschrift]]|volume=127|year=1972|issue=4|pages=315–322|doi=10.1007/BF01111390}}.
*{{citation|last=Stinson|first=D. R.|title=A comparison of two invariants for Steiner triple systems: fragments and trains|journal=Ars Combinatoria|volume=16|year=1983|pages=69–76|doi=|mr=0734047}}.
*{{citation
| doi = 10.1007/s00373-008-0834-4 
| title = Sparsity-certifying Graph Decompositions 
| year = 2009 
| last1 = Streinu | first1 = I. | author1-link = Ileana Streinu
| last2 = Theran | first2 = L. 
| journal = [[Graphs and Combinatorics]]
| volume = 25
| issue = 2 
| pages = 219
}}.
*{{citation|last=White|first=H. S.|title=Triple-systems as transformations, and their paths among triads|journal=[[Transactions of the American Mathematical Society]]|year=1913|volume=14|issue=1|pages=6–13|doi=10.2307/1988765|jstor=1988765|publisher=American Mathematical Society}}.
*{{citation|first=W.|last=Whiteley|authorlink=Walter Whiteley|title=The union of matroids and the rigidity of frameworks|journal=[[SIAM Journal on Discrete Mathematics]]|volume=1|issue=2|pages=237–255|year=1988|doi=10.1137/0401025}}.
*{{citation|first=D. R.|last=Woodall|contribution=Thrackles and deadlock|title=Combinatorial Mathematics and Its Applications|editor-first=D. J. A.|editor-last=Welsh|publisher=Academic Press|year=1969|pages=335–348}}.
{{refend}}

==External links==
*{{mathworld | urlname = UnicyclicGraph | title = Unicyclic Graph}}

{{good article}}

[[Category:Matroid theory]]
[[Category:Graph families]]</text>
      <sha1>3n743c0i2t9xcduo9reijn4imsu506a</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum algorithm</title>
    <ns>0</ns>
    <id>632489</id>
    <revision>
      <id>864630940</id>
      <parentid>855919324</parentid>
      <timestamp>2018-10-18T13:32:25Z</timestamp>
      <contributor>
        <username>User-duck</username>
        <id>28568042</id>
      </contributor>
      <minor/>
      <comment>Remove |class=</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="31715">In [[quantum computing]], a '''quantum algorithm''' is an [[algorithm]] which runs on a realistic model of [[quantum computation]], the most commonly used model being the [[quantum circuit]] model of computation.&lt;ref&gt;
{{cite book
 | last=Nielsen |first=M.
 | last2=Chuang |first2=I.
 | year=2000
 | title=Quantum Computation and Quantum Information
 | publisher=[[Cambridge University Press]]
 | isbn=0-521-63503-9
}}&lt;/ref&gt;&lt;ref&gt;
{{cite arXiv
 | last = Mosca | first = M.
 | date = 2008
 | title = Quantum Algorithms
 | class = quant-ph
 | eprint = 0808.0369
}}&lt;/ref&gt; A classical (or non-quantum) algorithm is a finite sequence of instructions, or a step-by-step procedure for solving a problem, where each step or instruction can be performed on a classical [[computer]]. Similarly, a quantum algorithm is a step-by-step procedure, where each of the steps can be performed on a [[quantum computer]]. Although all classical algorithms can also be performed on a quantum computer,&lt;ref&gt;{{Cite book|title = Quantum Computer Science|url = https://books.google.com/?id=-wkJIuw0YRsC&amp;pg=PA23&amp;lpg=PA23&amp;dq=quantum%2520computer%2520equivalent%2520classical%2520computer#v=onepage&amp;q=quantum%2520computer%2520equivalent%2520classical%2520computer&amp;f=false|publisher = Morgan &amp; Claypool Publishers|date = 2009-01-01|isbn = 9781598297324|first = Marco|last = Lanzagorta|first2 = Jeffrey K.|last2 = Uhlmann}}&lt;/ref&gt;{{rp|126}}  the term quantum algorithm is usually used for those algorithms which seem inherently quantum, or use some essential feature of quantum computation such as [[quantum superposition]] or [[quantum entanglement]].

Problems which are [[Undecidable problem|undecidable]] using classical computers remain undecidable using quantum computers.&lt;ref name=nielchuan&gt;{{cite book|title=Quantum Computation and Quantum Information|last1=Nielsen|first1=Michael A.|last2=Chuang|first2=Isaac L.|last3=|date=|publisher=Cambridge University Press|year=2010|isbn=978-1-107-00217-3|edition=2nd|location=Cambridge|pages=|author-link=Michael A. Nielsen|author-link2=Isaac Chuang|url=https://books.google.com/books?id=-s4DEy7o-a0C&amp;printsec=frontcover#v=onepage&amp;q=undecidable%20OR%20undecidability&amp;f=false}}&lt;/ref&gt;{{rp|127}} What makes quantum algorithms interesting is that they might be able to solve some problems faster than classical algorithms{{why|date=February 2018}}.

The most well known algorithms are [[Shor's algorithm]] for factoring, and [[Grover's algorithm]] for searching an unstructured database or an unordered list. Shor's algorithms runs exponentially faster than the best known classical algorithm for factoring, the [[general number field sieve]]{{citation needed|date=February 2018}}. Grover's algorithm runs quadratically faster than the best possible classical algorithm for the same task{{citation needed|date=February 2018}}, a [[linear search]].

==Overview==
Quantum algorithms are usually described, in the commonly used circuit model of quantum computation, by a [[quantum circuit]] which acts on some input [[qubit]]s and terminates with a [[measurement]]. A quantum circuit consists of simple [[quantum gate]]s which act on at most a fixed number of qubits{{why|date=February 2018}}, usually two or three{{according to whom|date=February 2018}}. Quantum algorithms may also be stated in other models of quantum computation, such as the [[Hamiltonian oracle model]].&lt;ref name=Hamiltonian_NAND_Tree&gt;
{{cite arXiv
 | last = Farhi | first = E.
 | last2 = Goldstone |first2=J.
 | last3 = Gutmann |first3=S.
 | date = 2007
 | title = A Quantum Algorithm for the Hamiltonian NAND Tree
 | eprint = quant-ph/0702144
}}&lt;/ref&gt;

Quantum algorithms can be categorized by the main techniques used by the algorithm. Some commonly used techniques/ideas in quantum algorithms include [[phase kick-back]], [[quantum phase estimation algorithm|phase estimation]], the [[quantum Fourier transform]], [[quantum walk]]s, [[amplitude amplification]] and [[topological quantum field theory]]. Quantum algorithms may also be grouped by the type of problem solved, for instance see the survey on quantum algorithms for algebraic problems.&lt;ref&gt;
{{cite journal
 | last = Childs | first = A. M.
 | last2= van Dam |first2 = W.
 | year = 2008
 | title = Quantum algorithms for algebraic problems
 | journal = [[Reviews of Modern Physics]]
 | volume = 82 |issue= | pages = 1–52
 | arxiv = 0812.0380
 | bibcode = 2010RvMP...82....1C
 | doi = 10.1103/RevModPhys.82.1
}}&lt;/ref&gt;

==Algorithms based on the quantum Fourier transform==
The [[quantum Fourier transform]] is the quantum analogue of the [[discrete Fourier transform]], and is used in several quantum algorithms. The [[Hadamard transform]] is also an example of a quantum Fourier transform over an n-dimensional vector space over the field '''F'''&lt;sub&gt;2&lt;/sub&gt;{{Clarify|reason=What is this F^2 field?|date=February 2018}}. The quantum Fourier transform can be efficiently implemented on a quantum computer using only a polynomial number of [[quantum gate]]s{{citation needed|date=February 2018}}.

===Deutsch–Jozsa algorithm===
{{main|Deutsch–Jozsa algorithm}}

The Deutsch–Jozsa algorithm solves a [[black-box]] problem which probably requires exponentially many queries to the black box for any deterministic classical computer, but can be done with exactly one query by a quantum computer. If we allow both bounded-error quantum and classical algorithms, then there is no speedup since a classical probabilistic algorithm can solve the problem with a constant number of queries with small probability of error. The algorithm determines whether a function ''f'' is either constant (0 on all inputs or 1 on all inputs) or balanced (returns 1 for half of the input domain and 0 for the other half).

===Simon's algorithm===
{{main|Simon's algorithm}}

Simon's algorithm solves a black-box problem exponentially faster than any classical algorithm, including bounded-error probabilistic algorithms. This algorithm, which achieves an exponential speedup over all classical algorithms that we consider efficient, was the motivation for Shor's factoring algorithm.

===Quantum phase estimation algorithm===
{{main|Quantum phase estimation algorithm}}

The [[quantum phase estimation algorithm]] is used to determine the eigenphase of an eigenvector of a unitary gate given a quantum state proportional to the eigenvector and access to the gate.   The algorithm is frequently used as a subroutine in other algorithms.

===Shor's algorithm===
{{main|Shor's algorithm}}

Shor's algorithm solves the [[discrete logarithm]] problem and the [[integer factorization]] problem in polynomial time,&lt;ref&gt;
{{cite journal
 | last = Shor | first = P. W.
 | year = 1997
 | title = Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer
 | journal = [[SIAM Journal on Scientific and Statistical Computing]]
 | volume = 26 | issue = 5
 | pages = 1484–1509
 | arxiv = quant-ph/9508027
 | bibcode= 1995quant.ph..8027S
 | doi=10.1137/s0097539795293172
}}&lt;/ref&gt; whereas the best known classical algorithms take super-polynomial time. These problems are not known to be in [[P (complexity)|P]] or [[NP-complete]]. It is also one of the few quantum algorithms that solves a non&amp;ndash;black-box problem in polynomial time where the best known classical algorithms run in super-polynomial time.

===Hidden subgroup problem===
The [[Abelian group|abelian]] [[hidden subgroup problem]] is a generalization of many problems that can be solved by a quantum computer, such as Simon's problem, solving [[Pell's equation]], testing the [[principal ideal]] of a [[ring (mathematics)|ring]] R and [[integer factorization|factoring]]. There are efficient quantum algorithms known for the Abelian hidden subgroup problem.&lt;ref&gt;
{{cite conference
 |last=Boneh |first=D.
 |last2=Lipton |first2=R. J.
 |year=1995
 |title=Quantum cryptoanalysis of hidden linear functions
 |editor-last=Coppersmith |editor-first=D.
 |booktitle=Proceedings of the 15th Annual International Cryptology Conference on Advances in Cryptology
 |pages=424–437
 |publisher=[[Springer-Verlag]]
 |isbn=3-540-60221-6
}}&lt;/ref&gt; The more general hidden subgroup problem, where the group isn't necessarily abelian, is a generalization of the previously mentioned problems and [[graph isomorphism]] and certain [[lattice problems]]. Efficient quantum algorithms are known for certain non-abelian groups. However, no efficient algorithms are known for the [[symmetric group]], which would give an efficient algorithm for graph isomorphism&lt;ref&gt;
{{cite arXiv
 |last1=Moore |first1=C.|author1-link=Cris Moore
 |last2=Russell |first2=A.
 |last3=Schulman |first3=L. J.
 |year=2005
 |title=The Symmetric Group Defies Strong Fourier Sampling: Part I
 |eprint=quant-ph/0501056
}}&lt;/ref&gt; and the [[dihedral group]], which would solve certain lattice problems.&lt;ref&gt;
{{cite arXiv
 | last = Regev | first = O.
 | date = 2003
 | title = Quantum Computation and Lattice Problems
 | eprint = cs/0304005
}}&lt;/ref&gt;

===Boson sampling problem===
{{main|Boson sampling}}
The Boson Sampling Problem in an experimental configuration assumes&lt;ref&gt;{{cite web|last1=Ralph|first1=T.C.|title=Figure 1: The boson-sampling problem|url=http://www.nature.com/nphoton/journal/v7/n7/fig_tab/nphoton.2013.175_F1.html|website=Nature Photonics|publisher=Nature|accessdate=12 September 2014}}&lt;/ref&gt; an input of [[boson]]s (ex. photons of light) of moderate number getting randomly scattered into a large number of output modes constrained by a defined [[unitarity]]. The problem is then to produce a fair sample of the [[probability distribution]] of the output which is dependent on the input arrangement of bosons and the Unitarity.&lt;ref&gt;{{cite journal|last1=Lund|first1=A.P.|last2=Laing|first2=A.|last3=Rahimi-Keshari|first3=S.|last4=Rudolph|first4=T.|last5=O'Brien|first5=J.L.|last6=Ralph|first6=T.C.|title=Boson Sampling from Gaussian States|journal=Phys. Rev. Lett.|date=September 5, 2014|volume=113|issue=10|doi=10.1103/PhysRevLett.113.100502|arxiv = 1305.4346 |bibcode = 2014PhRvL.113j0502L|pmid=25238340|page=100502}}&lt;/ref&gt; Solving this problem with a classical computer algorithm requires computing the permanent{{what|date=June 2018}} of the unitary transform matrix, which may be either impossible or take a prohibitively long time. In 2014, it was proposed&lt;ref&gt;{{cite web|title=The quantum revolution is a step closer|url=http://phys.org/news/2014-09-quantum-revolution-closer.html|website=Phys.org|publisher=Omicron Technology Limited|accessdate=12 September 2014}}&lt;/ref&gt; that existing technology and standard probabilistic methods of generating single photon states could be used as input into a suitable quantum computable [[Linear optical quantum computing|linear optical network]] and that sampling of the output probability distribution would be demonstrably superior using quantum algorithms. In 2015, investigation predicted&lt;ref&gt;{{cite journal|last1=Seshadreesan|first1=Kaushik P.|last2=Olson|first2=Jonathan P.|last3=Motes|first3=Keith R.|last4=Rohde|first4=Peter P.|last5=Dowling|first5=Jonathan P.|title=Boson sampling with displaced single-photon Fock states versus single-photon-added coherent states: The quantum-classical divide and computational-complexity transitions in linear optics|journal=Physical Review A|volume=91|issue=2|page=022334|doi=10.1103/PhysRevA.91.022334|arxiv = 1402.0531 |bibcode = 2015PhRvA..91b2334S |year=2015}}&lt;/ref&gt; the sampling problem had similar complexity for inputs other than [[Fock state]] photons and identified a transition in computational complexity from classically simulatable to just as hard as the Boson Sampling Problem, dependent on the size of coherent amplitude inputs.

===Estimating Gauss sums===
A [[Gauss sum]] is a type of [[exponential sum]]. The best known classical algorithm for estimating these sums takes exponential time. Since the discrete logarithm problem reduces to Gauss sum estimation, an efficient classical algorithm for estimating Gauss sums would imply an efficient classical algorithm for computing discrete logarithms, which is considered unlikely. However, quantum computers can estimate Gauss sums to polynomial precision in polynomial time.&lt;ref&gt;
{{Cite arXiv
 | last1=van Dam |first=W.
 | last2=Seroussi |first2=G.
 | year =2002
 | title = Efficient Quantum Algorithms for Estimating Gauss Sums
 | eprint = quant-ph/0207131
}}&lt;/ref&gt;

===Fourier fishing and Fourier checking===
We have an [[Oracle machine|oracle]] consisting of n random Boolean functions mapping n-bit strings to a Boolean value. We are required to find n n-bit strings z&lt;sub&gt;1&lt;/sub&gt;,..., z&lt;sub&gt;n&lt;/sub&gt; such that for the Hadamard-Fourier transform, at least 3/4 of the strings satisfy

:&lt;math&gt;\left| \tilde{f}\left( z_i \right) \right| \geqslant 1&lt;/math&gt;

and at least 1/4 satisfies

:&lt;math&gt;\left| \tilde{f}\left( z_i \right) \right| \geqslant 2&lt;/math&gt;.

This can be done in [[BQP]].&lt;ref&gt;
{{Cite arXiv
 | last = Aaronson | first = S.
 | year = 2009
 | title = BQP and the Polynomial Hierarchy
 | class = quant-ph
 | eprint = 0910.4698
}}&lt;/ref&gt;

==Algorithms based on amplitude amplification==
[[Amplitude amplification]] is a technique that allows the amplification of a chosen subspace of a quantum state. Applications of amplitude amplification usually lead to quadratic speedups over the corresponding classical algorithms. It can be considered to be a generalization of Grover's algorithm.

===Grover's algorithm===
{{main|Grover's algorithm}}

Grover's algorithm searches an unstructured database (or an unordered list) with N entries, for a marked entry, using only &lt;math&gt;O(\sqrt{N})&lt;/math&gt; queries instead of the &lt;math&gt;O({N})&lt;/math&gt; queries required classically.&lt;ref&gt;
{{Cite arXiv
 | last = Grover | first = L. K.
 | date = 1996
 | title = A fast quantum mechanical algorithm for database search
 | eprint = quant-ph/9605043
}}&lt;/ref&gt; Classically, &lt;math&gt;O({N})&lt;/math&gt; queries are required, even if we allow bounded-error probabilistic algorithms.

[[De Broglie–Bohm theory|Bohmian Mechanics]] is a non-local hidden variable interpretation of quantum mechanics. It has been shown that a non-local hidden variable quantum computer could implement a search of an N-item database at most in &lt;math&gt;O(\sqrt[3]{N})&lt;/math&gt; steps. This is slightly faster than the &lt;math&gt;O(\sqrt{N})&lt;/math&gt; steps taken by [[Grover's algorithm]]. Neither search method will allow quantum computers to solve [[NP-completeness|NP-Complete]] problems in polynomial time.&lt;ref&gt;{{Cite web|url=https://www.scottaaronson.com/papers/qchvpra.pdf|title=Quantum Computing and Hidden Variables|last=Aaronson|first=Scott|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;

===Quantum counting===
[[Quantum counting]] solves a generalization of the search problem. It solves the problem of counting the number of marked entries in an unordered list, instead of just detecting if one exists. Specifically, it counts the number of marked entries in an &lt;math&gt;N&lt;/math&gt;-element list, with error &lt;math&gt;\epsilon&lt;/math&gt; making only &lt;math&gt;\Theta\left(\frac{1}{\epsilon} \sqrt{\frac{N}{k}}\right)&lt;/math&gt; queries, where &lt;math&gt;k&lt;/math&gt; is the number of marked elements in the list.&lt;ref&gt;
{{Cite journal
 |last = Brassard |first = G.
 |last2=Hoyer |first2=P.
 |last3=Tapp |first3=A.
 |date = 1998
 |title = Quantum Counting
 |arxiv = quant-ph/9805082
 |doi=10.1007/BFb0055105
 |journal=Lecture Notes in Computer Science
 |volume = 1443
 |pages=820–831
|series = Lecture Notes in Computer Science
 |isbn = 978-3-540-64781-2
 }}&lt;/ref&gt;&lt;ref&gt;
{{Cite book
 |last1=Brassard |first1=G.
 |last2=Hoyer |first2=P.
 |last3=Mosca |first3=M.
 |last4=Tapp |first4=A.
 |year=2002
 |chapter=Quantum Amplitude Amplification and Estimation
 |title=Quantum Computation and Quantum Information
 |editor=Samuel J. Lomonaco, Jr.
 |series=AMS Contemporary Mathematics
 |volume=305
 |pages=53–74
 |arxiv=quant-ph/0005055
|bibcode=2000quant.ph..5055B}}&lt;/ref&gt; More precisely, the algorithm outputs an estimate &lt;math&gt;k'&lt;/math&gt; for &lt;math&gt;k&lt;/math&gt;, the number of marked entries, with the following accuracy: &lt;math&gt;|k-k'| \leq \epsilon k&lt;/math&gt;.

==Algorithms based on quantum walks==
{{main|Quantum walk}}

A quantum walk is the quantum analogue of a classical [[random walk]], which can be described by a [[probability distribution]] over some states. A quantum walk can be described by a [[quantum superposition]] over states. Quantum walks are known to give exponential speedups for some black-box problems.&lt;ref&gt;
{{cite conference
 |last1=Childs |first1=A. M.
 |last2=Cleve |first2=R.
 |last3=Deotto |first3=E.
 |last4=Farhi |first4=E.
 |last5=Gutmann |first5=S.
 |last6=Spielman |first6=D. A.
 |year=2003
 |title=Exponential algorithmic speedup by quantum walk
 |booktitle=Proceedings of the 35th Symposium on Theory of Computing
 |pages=59–68
 |publisher=[[Association for Computing Machinery]]
 |arxiv=quant-ph/0209131
 |bibcode=
 |doi=10.1145/780542.780552
 |isbn=1-58113-674-9
}}&lt;/ref&gt;&lt;ref&gt;
{{cite conference
 |last1=Childs |first1=A. M.
 |last2=Schulman |first2=L. J.
 |last3=Vazirani |first3=U. V.
 |year=2007
 |title=Quantum Algorithms for Hidden Nonlinear Structures
 |booktitle=Proceedings of the 48th Annual IEEE Symposium on Foundations of Computer Science
 |pages=395–404
 |publisher=[[IEEE]]
 |arxiv=0705.2784
 |doi=10.1109/FOCS.2007.18
 |isbn=0-7695-3010-9
}}&lt;/ref&gt; They also provide polynomial speedups for many problems. A framework for the creation of quantum walk algorithms exists and is quite a versatile tool.&lt;ref name=Search_via_quantum_walk/&gt;

===Element distinctness problem===
{{main|Element distinctness problem}}

The element distinctness problem is the problem of determining whether all the elements of a list are distinct. Classically, Ω(''N'') queries are required for a list of size ''N'', since this problem is harder than the search problem which requires Ω(''N'') queries. However, it can be solved in &lt;math&gt;\Theta(N^{2/3})&lt;/math&gt; queries on a quantum computer. The optimal algorithm is by [[Andris Ambainis]].&lt;ref&gt;
{{cite journal
 |last=Ambainis |first=A.
 |year=2007
 |title=Quantum Walk Algorithm for Element Distinctness
 |journal=[[SIAM Journal on Computing]]
 |volume=37 |issue=1 |pages=210–239
 |arxiv=
 quant-ph/0311001|bibcode=
 |doi=10.1137/S0097539705447311
}}&lt;/ref&gt; [[Yaoyun Shi]] first proved a tight lower bound when the size of the range is sufficiently large.&lt;ref&gt;
{{cite conference
 | last1=Shi | first1=Y.
 | year=2002
 | title=Quantum lower bounds for the collision and the element distinctness problems
 | conference = Proceedings of the 43rd [[Symposium on Foundations of Computer Science]]
 | pages=513–519
 | arxiv = quant-ph/0112086
 | doi=10.1109/SFCS.2002.1181975}}&lt;/ref&gt; Ambainis&lt;ref&gt;
{{cite journal
 |last=Ambainis |first=A.
 |year=2005
 |title=Polynomial Degree and Lower Bounds in Quantum Complexity: Collision and Element Distinctness with Small Range
 |journal=[[Theory of Computing]]
 |volume=1 |issue=1 |pages=37–46
 |arxiv=
 |bibcode=
 |doi=10.4086/toc.2005.v001a003
}}&lt;/ref&gt; and Kutin&lt;ref&gt;
{{cite journal
 |last1=Kutin |first1=S.
 |year=2005
 |title=Quantum Lower Bound for the Collision Problem with Small Range
 |journal=[[Theory of Computing]]
 |volume=1 |issue=1 |pages=29–36
 |arxiv=
 |bibcode=
 |doi=10.4086/toc.2005.v001a002
}}&lt;/ref&gt; independently (and via different proofs) extended his work to obtain the lower bound for all functions.

===Triangle-finding problem===
{{main|Triangle finding problem}}

The triangle-finding problem is the problem of determining whether a given graph contains a triangle (a [[clique (graph theory)|clique]] of size 3). The best-known lower bound for quantum algorithms is Ω(''N''), but the best algorithm known requires O(''N''&lt;sup&gt;1.297&lt;/sup&gt;) queries,&lt;ref&gt;{{cite arXiv| eprint=1105.4024| author1=Aleksandrs Belovs| title=Span Programs for Functions with Constant-Sized 1-certificates| class=quant-ph| year=2011}}&lt;/ref&gt; an improvement over the previous best O(''N''&lt;sup&gt;1.3&lt;/sup&gt;) queries.&lt;ref name=Search_via_quantum_walk&gt;
{{cite conference
 |last1=Magniez |first1=F.
 |last2=Nayak |first2=A.
 |last3=Roland |first3=J.
 |last4=Santha |first4=M.
 |year=2007
 |title=Search via quantum walk
 |booktitle=Proceedings of the 39th Annual ACM Symposium on Theory of Computing
 |publisher=[[Association for Computing Machinery]]
 |pages=575–584
 |doi=10.1145/1250790.1250874
 |isbn=978-1-59593-631-8
|arxiv=quant-ph/0608026}}&lt;/ref&gt;&lt;ref&gt;
{{cite journal
 |last1=Magniez |first1=F.
 |last2=Santha |first2=M.
 |last3=Szegedy |first3=M.
 |year=2007
 |title=Quantum Algorithms for the Triangle Problem
 |journal=[[SIAM Journal on Computing]]
 |volume=37 |issue=2 |pages=413–424
 |arxiv=
 quant-ph/0310134|bibcode=
 |doi=10.1137/050643684
}}&lt;/ref&gt;

===Formula evaluation===
A formula is a tree with a gate at each internal node and an input bit at each leaf node. The problem is to evaluate the formula, which is the output of the root node, given oracle access to the input.

A well studied formula is the balanced binary tree with only NAND gates.&lt;ref&gt;
{{cite web
 |last=Aaronson |first=S.
 |date=3 February 2007
 |title=NAND now for something completely different
 |url=http://scottaaronson.com/blog/?p=207
 |work=Shtetl-Optimized
 |accessdate=2009-12-17
}}&lt;/ref&gt; This type of formula requires Θ(''N''&lt;sup&gt;c&lt;/sup&gt;) queries using randomness,&lt;ref&gt;
{{cite conference
 |last1=Saks |first1=M.E.
 |last2=Wigderson |first2=A.
 |year=1986
 |title=Probabilistic Boolean Decision Trees and the Complexity of Evaluating Game Trees
 |url=http://www.math.ias.edu/~avi/PUBLICATIONS/MYPAPERS/SW86/SW86.pdf
 |booktitle=Proceedings of the 27th Annual Symposium on Foundations of Computer Science
 |pages=29–38
 |publisher=[[IEEE]]
 |doi=10.1109/SFCS.1986.44
 |isbn=0-8186-0740-8
}}&lt;/ref&gt; where &lt;math&gt;c = \log_2(1+\sqrt{33})/4 \approx 0.754&lt;/math&gt;. With a quantum algorithm however, it can be solved in Θ(''N''&lt;sup&gt;0.5&lt;/sup&gt;) queries. No better quantum algorithm for this case was known until one was found for the unconventional Hamiltonian oracle model.&lt;ref name=Hamiltonian_NAND_Tree/&gt; The same result for the standard setting soon followed.&lt;ref&gt;
{{cite arXiv
 |last=Ambainis |first=A.
 |year=2007
 |title=A nearly optimal discrete query quantum algorithm for evaluating NAND formulas
 |class=quant-ph
 |eprint=0704.3628
}}&lt;/ref&gt;

Fast quantum algorithms for more complicated formulas are also known.&lt;ref&gt;
{{cite conference
 |last1=Reichardt |first1=B. W.
 |last2=Spalek |first2=R.
 |year=2008
 |title=Span-program-based quantum algorithm for evaluating formulas
 |booktitle=Proceedings of the 40th Annual ACM symposium on Theory of Computing
 |publisher=[[Association for Computing Machinery]]
 |pages=103–112
 |isbn=978-1-60558-047-0
 |doi=10.1145/1374376.1374394
|arxiv=0710.2630}}&lt;/ref&gt;

===Group commutativity===
The problem is to determine if a [[black box group]], given by ''k'' generators, is [[Commutativity|commutative]]. A black box group is a group with an oracle function, which must be used to perform the group operations (multiplication, inversion, and comparison with identity). We are interested in the query complexity, which is the number of oracle calls needed to solve the problem. The deterministic and randomized query complexities are &lt;math&gt;\Theta(k^2)&lt;/math&gt; and &lt;math&gt;\Theta(k)&lt;/math&gt; respectively.&lt;ref&gt;
{{cite journal
 |last=Pak |first=Igor |author1-link=Igor Pak
 |year=2012
 |title=Testing commutativity of a group and the power of randomization
 |journal= [[LMS Journal of Computation and Mathematics]]
 |volume=15 |pages=38–43
 |doi=10.1112/S1461157012000046
 }}&lt;/ref&gt; A quantum algorithm requires &lt;math&gt;\Omega(k^{2/3})&lt;/math&gt; queries but the best known algorithm uses &lt;math&gt;O(k^{2/3} \log k)&lt;/math&gt; queries.&lt;ref&gt;
{{cite journal
 |last1=Magniez |first1=F.
 |last2=Nayak |first2=A.
 |year=2007
 |title=Quantum Complexity of Testing Group Commutativity
 |journal=[[Algorithmica]]
 |volume=48 |issue=3 |pages=221–232
 |doi=10.1007/s00453-007-0057-8
|arxiv=quant-ph/0506265}}&lt;/ref&gt;

==BQP-complete problems==

===Computing knot invariants===
Witten had shown that the [[Chern-Simons]] [[topological quantum field theory]] (TQFT) can be solved in terms of [[Jones polynomial]]s. A quantum computer can simulate a TQFT, and thereby approximate the Jones polynomial,&lt;ref&gt;
{{Cite conference
 | last = Aharonov | first = D.
 | last2 = Jones | first2 = V.
 | last3 = Landau | first3 = Z.
 | year = 2006
 | title = A polynomial quantum algorithm for approximating the Jones polynomial
 | booktitle=Proceedings of the 38th Annual ACM symposium on Theory of Computing
 | pages = 427–436
 | publisher=[[Association for Computing Machinery]]
 | doi = 10.1145/1132516.1132579
 | isbn=
| arxiv = quant-ph/0511096}}&lt;/ref&gt; which as far as we know, is hard to compute classically in the worst-case scenario.{{citation needed|date=December 2014}}

===Quantum simulation===
The idea that quantum computers might be more powerful than classical computers originated in Richard Feynman's observation that classical computers seem to require exponential time to simulate many-particle quantum systems.&lt;ref&gt;
{{Cite journal
 | last1=Feynman | first1=R. P.
 | year=1982
 | title=Simulating physics with computers
 | journal=[[International Journal of Theoretical Physics]]
 | volume=21 | issue=6–7 | pages=467–488
 | arxiv=
 | bibcode = 1982IJTP...21..467F
 | doi = 10.1007/BF02650179
}}&lt;/ref&gt; Since then, the idea that quantum computers can simulate quantum physical processes exponentially faster than classical computers has been greatly fleshed out and elaborated. Efficient (that is, polynomial-time) quantum algorithms have been developed for simulating both Bosonic and Fermionic systems&lt;ref&gt;
{{Cite journal
 | last1=Abrams |first1=D. S.
 | last2=Lloyd | first2=S.
 | year=1997
 | title=Simulation of many-body Fermi systems on a universal quantum computer
 | journal=[[Physical Review Letters]]
 | volume=79 | issue=13 | pages=2586–2589
 | arxiv = quant-ph/9703054
 | bibcode=1997PhRvL..79.2586A
 | doi=10.1103/PhysRevLett.79.2586
}}&lt;/ref&gt; and in particular, the simulation of chemical reactions beyond the capabilities of current classical supercomputers requires only a few hundred qubits.&lt;ref&gt;
{{Cite journal
 | last1=Kassal | first1=I.
 | last2=Jordan | first2=S. P.
 | last3=Love | first3=P. J.
 | last4=Mohseni | first4=M.
 | last5=Aspuru-Guzik | first5=A.
 | year=2008
 | title=Polynomial-time quantum algorithm for the simulation of chemical dynamics
 | journal=[[Proceedings of the National Academy of Sciences of the United States of America]]
 | volume=105 |issue=48 | pages=18681–86
 | arxiv= 0801.2986
 | bibcode = 2008PNAS..10518681K
 | doi=10.1073/pnas.0808245105
 | pmc=2596249
 | pmid=19033207
}}&lt;/ref&gt; Quantum computers can also efficiently simulate topological quantum field theories.&lt;ref&gt;
{{Cite journal
 | last1=Freedman | first1=M.
 | last2=Kitaev | first2=A.
 | last3=Wang | first3=Z.
 | year=2002
 | title=Simulation of Topological Field Theories by Quantum Computers
 | journal=[[Communications in Mathematical Physics]]
 | volume=227 | issue=3 | pages=587–603
 | arxiv = quant-ph/0001071
 | bibcode = 2002CMaPh.227..587F
 | doi=10.1007/s002200200635
}}&lt;/ref&gt; In addition to its intrinsic interest, this result has led to efficient quantum algorithms for estimating [[Quantum invariant|quantum topological invariants]] such as [[Jones polynomial|Jones]]&lt;ref&gt;
{{Cite journal
 | last1=Aharonov | first1=D.
 | last2=Jones | first2=V.
 | last3=Landau | first3=Z.
 | year=2009
 | title=A polynomial quantum algorithm for approximating the Jones polynomial
 | journal=[[Algorithmica]]
 | volume=55 | issue=3 | pages=395–421
 | arxiv=quant-ph/0511096
 | bibcode=
 | doi=10.1007/s00453-008-9168-0
}}&lt;/ref&gt; and [[HOMFLY]]&lt;ref&gt;
{{Cite journal
 | last1=Wocjan |first1=P.
 | last2=Yard | first2=J.
 | year=2008
 | title=The Jones polynomial: quantum algorithms and applications in quantum complexity theory
 | journal=[[Quantum Information and Computation]]
 | volume=8 | issue=1 | pages=147–180
 | arxiv=quant-ph/0603069
 | doi=
|bibcode = 2006quant.ph..3069W }}&lt;/ref&gt; polynomials, and the [[Turaev-Viro invariant]] of three-dimensional manifolds.&lt;ref&gt;
{{Cite journal
 |last1=Alagic | first1=G.
 |last2=Jordan | first2=S.P.
 |last3=König | first3=R.
 |last4=Reichardt | first4=B. W.
 |year=2010
 |title=Approximating Turaev-Viro 3-manifold invariants is universal for quantum computation
 |journal=[[Physical Review A]]
 |volume=82 |issue=4 |pages=040302
 |arxiv=1003.0923
 |bibcode=2010PhRvA..82d0302A
 |doi=10.1103/PhysRevA.82.040302
}}&lt;/ref&gt;

==Hybrid Quantum/Classical Algorithms==
Hybrid Quantum/Classical Algorithms combine quantum state preparation and measurement with classical optimization. These algorithms generally aim to determine the ground state eigenvector and eigenvalue of a Hermitian Operator.

=== QAOA ===
The quantum approximate optimization algorithm is a toy model of quantum annealing which can be used to solve problems in graph theory.&lt;ref&gt;{{cite arxiv |last=Farhi |first=Edward |last2=Goldstone |first2=Jeffrey |last3=Gutmann |first3=Sam |date=2014-11-14 |title=A Quantum Approximate Optimization Algorithm |eprint=1411.4028 |class=quant-ph}}&lt;/ref&gt; The algorithm makes use of classical optimization of quantum operations to maximize an objective function.

=== Variational Quantum Eigensolver ===
The VQE algorithm applies classical optimization to minimize the energy expectation of an ansatz state to find the ground state energy of a molecule.&lt;ref&gt;{{Cite journal|last=Peruzzo|first=Alberto|last2=McClean|first2=Jarrod|last3=Shadbolt|first3=Peter|last4=Yung|first4=Man-Hong|last5=Zhou|first5=Xiao-Qi|last6=Love|first6=Peter J.|last7=Aspuru-Guzik|first7=Alán|last8=O’Brien|first8=Jeremy L.|date=2014-07-23|title=A variational eigenvalue solver on a photonic quantum processor|url=https://www.nature.com/articles/ncomms5213|journal=Nature Communications|language=En|volume=5|issue=1|doi=10.1038/ncomms5213|issn=2041-1723|arxiv=1304.3061|bibcode=2014NatCo...5E4213P}}&lt;/ref&gt; This can also be extended to find excited energies of molecules.&lt;ref&gt;{{cite arxiv|last=Higgott|first=Oscar|last2=Wang|first2=Daochen|last3=Brierley|first3=Stephen|date=2018-05-21|title=Variational Quantum Computation of Excited States|eprint=1805.08138|class=quant-ph}}&lt;/ref&gt;

==See also==
* [[Quantum optimization algorithms]]
* [[Quantum sort]]
* [[Primality test]]

==References==
{{reflist|2}}

==External links==
* The [http://math.nist.gov/quantum/zoo/ Quantum Algorithm Zoo]: A comprehensive list of quantum algorithms that provide a speedup over the fastest known classical algorithms.
* [https://www.cs.umd.edu/~amchilds/qa/ Andrew Childs' lecture notes on quantum algorithms]
*[https://bastion.center/the-quantum-search-algorithm/ The Quantum search algorithm - brute force].

===Surveys===
* {{Cite book | last1 = Smith | first1 = J. | last2 = Mosca | first2 = M. | doi = 10.1007/978-3-540-92910-9_43 | chapter = Algorithms for Quantum Computers | title = Handbook of Natural Computing | pages = 1451 | year = 2012 | isbn = 978-3-540-92909-3 | pmid =  | pmc = }}
* {{Cite journal | last1 = Childs | first1 = A. M. | last2 = Van Dam | first2 = W. | doi = 10.1103/RevModPhys.82.1 | title = Quantum algorithms for algebraic problems | journal = Reviews of Modern Physics | volume = 82 | pages = 1–52 | year = 2010 | pmid =  | pmc = |bibcode = 2010RvMP...82....1C }}

{{quantum computing}}
{{Use dmy dates|date=September 2011}}

{{DEFAULTSORT:Quantum Algorithm}}
[[Category:Quantum computing]]
[[Category:Quantum information science]]
[[Category:Theoretical computer science]]
[[Category:Quantum algorithms| ]]
[[Category:Emerging technologies]]</text>
      <sha1>b0vee7pboe3fsmnv8dd27aj2nufmvur</sha1>
    </revision>
  </page>
  <page>
    <title>Reed–Solomon error correction</title>
    <ns>0</ns>
    <id>45600</id>
    <revision>
      <id>871059087</id>
      <parentid>866355396</parentid>
      <timestamp>2018-11-28T17:44:02Z</timestamp>
      <contributor>
        <username>Chris the speller</username>
        <id>525927</id>
      </contributor>
      <minor/>
      <comment>punct</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="68672">{{infobox code
 | name           = Reed–Solomon codes
 | image          =
 | image_caption  =
 | namesake       = [[Irving S. Reed]] and [[Gustave Solomon]]
 | hierarchy      = [[Linear block code]]&lt;br&gt;[[Polynomial code]]&lt;br&gt;Reed–Solomon code
 | block_length   = ''n''
 | message_length = ''k''
 | distance       = ''n'' &amp;minus; ''k'' + 1
 | alphabet_size  = ''q'' = ''p''&lt;sup&gt;''m''&lt;/sup&gt; ≥ ''n''&amp;nbsp; (''p'' prime)&lt;br&gt;Often ''n'' = ''q'' &amp;minus; 1.
 | notation       = [''n'', ''k'', ''n'' &amp;minus; ''k'' + 1]&lt;sub&gt;''q''&lt;/sub&gt;-code
 | decoding       = [[Berlekamp–Massey algorithm|Berlekamp–Massey]]&lt;br&gt;[[Euclidean algorithm|Euclidean]]&lt;br&gt;''et al.''
 | properties     = [[maximum distance separable code|Maximum-distance separable code]]
}}
'''Reed–Solomon codes''' are a group of [[error-correcting code]]s that were introduced by [[Irving S. Reed]] and [[Gustave Solomon]] in 1960.&lt;ref&gt;{{Harvtxt|Reed|Solomon|1960}}&lt;/ref&gt;
They have many applications, the most prominent of which include consumer technologies such as [[CD]]s, [[DVD]]s, [[Blu-ray Disc]]s, [[QR Code]]s, [[data transmission]] technologies such as [[DSL]] and [[WiMAX]], [[Broadcasting|broadcast]] systems such as satellite communications, [[Digital Video Broadcasting|DVB]] and [[ATSC Standards|ATSC]], and storage systems such as [[RAID 6]].

Reed–Solomon codes operate on a block of data treated as a set of [[finite field]] elements called symbols. For example, a block of 4096 bytes (32,768 bits) could be treated as a set of 2731 12-bit symbols, where each symbol is a finite field element of GF(2&lt;sup&gt;12&lt;/sup&gt;), the last symbol padded with four 0 bits. Reed–Solomon codes are able to detect and correct multiple symbol errors. By adding {{mvar|t}} check symbols to the data, a Reed–Solomon code can detect any combination of up to and including {{mvar|t}} erroneous symbols, or correct up to and including {{math|⌊''t''/2⌋}} symbols. As an [[erasure code]], it can correct up to and including {{mvar|t}} known erasures, or it can detect and correct combinations of errors and erasures. Reed–Solomon codes are also suitable as multiple-[[burst error|burst]] bit-error correcting codes, since a sequence of {{math|''b''&amp;nbsp;+&amp;nbsp;1}} consecutive bit errors can affect at most two symbols of size {{mvar|b}}. The choice of {{mvar|t}} is up to the designer of the code, and may be selected within wide limits.

There are two basic types of Reed–Solomon codes, [[Reed%E2%80%93Solomon_error_correction#Reed_&amp;_Solomon's_original_view:_The_codeword_as_a_sequence_of_values|original view]] and [[Reed%E2%80%93Solomon_error_correction#The_BCH_view:_The_codeword_as_a_sequence_of_coefficients|BCH view]], with BCH view being the most common as BCH view decoders are faster and require less working storage than original view decoders.

==History==
Reed–Solomon codes were developed in 1960 by [[Irving S. Reed]] and [[Gustave Solomon]], who were then staff members of [[MIT Lincoln Laboratory]]. Their seminal article was titled "Polynomial Codes over Certain Finite Fields". {{Harvard citation|Reed|Solomon|1960}}. The original encoding scheme described in the Reed &amp; Solomon article used a variable polynomial based on the message to be encoded where only a fixed set of values (evaluation points) to be encoded are known to encoder and decoder. The original theoretical decoder generated potential polynomials based on subsets of ''k'' (unencoded message length) out of ''n'' (encoded message length) values of a received message, choosing the most popular polynomial as the correct one, which was impractical for all but the simplest of cases. This was initially resolved by changing the original scheme to a [[BCH code]] like scheme based on a fixed polynomial known to both encoder and decoder, but later, practical decoders based on the original scheme were developed, although slower than the BCH schemes. The result of this is that there are two main types of Reed Solomon codes, ones that use the original encoding scheme, and ones that use the BCH encoding scheme.

Also in 1960, a practical fixed polynomial decoder for [[BCH codes]] codes developed by [[Daniel Gorenstein]] and Neal Zierler was described in an MIT Lincoln Laboratory report by Zierler in January 1960 and later in a paper in June 1961.&lt;ref&gt;D. Gorenstein and N. Zierler, "A class of cyclic linear error-correcting codes in p^m symbols", J. SIAM, vol. 9, pp. 207-214, June 1961&lt;/ref&gt;   The Gorenstein-Zierler decoder and the related work on BCH codes are described in a book Error Correcting Codes by [[W. Wesley Peterson]] (1961).&lt;ref&gt;Error Correcting Codes by W_Wesley_Peterson, 1961&lt;/ref&gt; By 1963 (or possibly earlier), J. J. Stone (and others) recognized that Reed Solomon codes could use the BCH scheme of using a fixed generator polynomial, making such codes a special class of BCH codes,&lt;ref&gt;Error Correcting Codes by W_Wesley_Peterson, second edition, 1972&lt;/ref&gt;, but Reed Solomon codes based on the original encoding scheme, are not a class of BCH codes, and depending on the set of evaluation points, they are not even [[cyclic code | cyclic codes]].

In 1969, an improved BCH scheme decoder was developed by [[Elwyn Berlekamp]] and [[James Massey]], and is since known as the [[Berlekamp–Massey algorithm|Berlekamp–Massey decoding algorithm]].

In 1975, another improved BCH scheme decoder was developed by Yasuo Sugiyama, based on the [[extended Euclidean algorithm]].&lt;ref&gt;Yasuo Sugiyama, Masao Kasahara, Shigeichi Hirasawa, and Toshihiko Namekawa. A method for solving key equation for decoding Goppa codes. Information and Control, 27:87–99, 1975.&lt;/ref&gt;

In 1977, Reed–Solomon codes were implemented in the [[Voyager program]] in the form of [[concatenated error correction code]]s. The first commercial application in mass-produced consumer products appeared in 1982 with the [[compact disc]], where two [[forward error correction#Interleaving|interleaved]] Reed–Solomon codes are used. Today, Reed–Solomon codes are widely implemented in [[Data storage device|digital storage]] devices and [[Data transmission|digital communication]] standards, though they are being slowly replaced by more modern [[Low-density parity-check code|low-density parity-check (LDPC) code]]s or [[turbo code]]s.  For example, Reed–Solomon codes are used in the [[Digital Video Broadcasting]] (DVB) standard [[DVB-S]], but LDPC codes are used in its successor, [[DVB-S2]].

In 1986, an original scheme decoder known as the [[Berlekamp–Welch algorithm]] was developed.

In 1996, variations of original scheme decoders called list decoders or soft decoders were developed by Madhu Sudan and others, and work continues on these type of decoders – see ''[[Guruswami–Sudan list decoding algorithm]]''.

In 2002, another original scheme decoder was developed by Shuhong Gao, based on the [[Extended Euclidean algorithm]] [http://www.math.clemson.edu/~sgao/papers/RS.pdf Gao_RS.pdf] .

== Applications ==

===Data storage===
Reed–Solomon coding is very widely used in mass storage systems to correct
the burst errors associated with media defects.

Reed–Solomon coding is a key component of the [[compact disc]]. It was the first use of strong error correction coding in a mass-produced consumer product, and [[digital audio tape|DAT]] and [[DVD]] use similar schemes. In the CD, two layers of Reed–Solomon coding separated by a 28-way [[convolution]]al [[interleaver]] yields a scheme called Cross-Interleaved Reed–Solomon Coding ([[Cross-interleaved Reed–Solomon coding|CIRC]]). The first element of a CIRC decoder is a relatively weak inner (32,28) Reed–Solomon code, shortened from a (255,251) code with 8-bit symbols. This code can correct up to 2 byte errors per 32-byte block. More importantly, it flags as erasures any uncorrectable blocks, i.e., blocks with more than 2 byte errors. The decoded 28-byte blocks, with erasure indications, are then spread by the deinterleaver to different blocks of the (28,24) outer code. Thanks to the deinterleaving, an erased 28-byte block from the inner code becomes a single erased byte in each of 28 outer code blocks. The outer code easily corrects this, since it can handle up to 4 such erasures per block.

The result is a CIRC that can completely correct error bursts up to 4000 bits, or about 2.5&amp;nbsp;mm on the disc surface. This code is so strong that most CD playback errors are almost certainly caused by tracking errors that cause the laser to jump track, not by uncorrectable error bursts.&lt;ref&gt;{{Citation |first=K. A. S. |last=Immink |authorlink=Kees Immink |contribution=Reed–Solomon Codes and the Compact Disc |editor1-first=Stephen B. |editor1-last=Wicker |editor2-first=Vijay K. |editor2-last=Bhargava |title=Reed–Solomon Codes and Their Applications |publisher=[[IEEE Press]] |year=1994 |isbn=978-0-7803-1025-4 |doi= }}&lt;/ref&gt;

DVDs use a similar scheme, but with much larger blocks, a (208,192) inner code, and a (182,172) outer code.

Reed–Solomon error correction is also used in [[parchive]] files which are commonly posted accompanying multimedia files on [[USENET]]. The Distributed online storage service [[Wuala]] (discontinued in 2015) also used to make use of Reed–Solomon when breaking up files.

===Bar code===
Almost all two-dimensional bar codes such as [[PDF-417]], [[MaxiCode]], [[Datamatrix]], [[QR Code]], and [[Aztec Code]] use Reed–Solomon error correction to allow correct reading even if a portion of the bar code is damaged.  When the bar code scanner cannot recognize a bar code symbol, it will treat it as an erasure.

Reed–Solomon coding is less common in one-dimensional bar codes, but is used by the [[PostBar]] symbology.

===Data transmission===
Specialized forms of Reed–Solomon codes, specifically [[Cauchy matrix|Cauchy]]-RS and [[Vandermonde matrix|Vandermonde]]-RS, can be used to overcome the unreliable nature of data transmission over [[Binary erasure channel|erasure channels]]. The encoding process assumes a code of RS(''N'',&amp;nbsp;''K'') which results in ''N'' codewords of length ''N'' symbols each storing ''K'' symbols of data, being generated, that are then sent over an erasure channel.

Any combination of ''K'' codewords received at the other end is enough to reconstruct all of the ''N'' codewords. The code rate is generally set to 1/2 unless the channel's erasure likelihood can be adequately modelled and is seen to be less. In conclusion, ''N'' is usually 2''K'', meaning that at least half of all the codewords sent must be received in order to reconstruct all of the codewords sent.

Reed–Solomon codes are also used in [[xDSL]] systems and [[CCSDS]]'s [[Space Communications Protocol Specifications]] as a form of [[forward error correction]].

===Space transmission===
One significant application of Reed–Solomon coding was to encode the digital pictures sent back by the [[Voyager program|Voyager]] space probe.

Voyager introduced Reed–Solomon coding [[concatenated code|concatenated]] with [[convolutional code]]s, a practice that has since become very widespread in deep space and satellite (e.g., direct digital broadcasting) communications.
&lt;!-- Unsourced image removed: [[Image:NASA ECC Codes-imperfection.png|thumb|600px|none|NASA's Deep Space Missions ECC Codes (code imperfectness) {{Deletable image-caption|date=March 2012}}]] --&gt;

[[Viterbi decoder]]s tend to produce errors in short bursts. Correcting these burst errors is a job best done by short or simplified Reed–Solomon codes.

Modern versions of concatenated Reed–Solomon/Viterbi-decoded convolutional coding were and are used on the [[Mars Pathfinder]], [[Galileo probe|Galileo]], [[Mars Exploration Rover]] and [[Cassini probe|Cassini]] missions, where they perform within about 1–1.5 [[decibel|dB]] of the ultimate limit, being the [[Shannon capacity]].

These concatenated codes are now being replaced by more powerful [[turbo code]]s.

== Constructions ==

The Reed–Solomon code is actually a family of codes, where every code is characterised by three parameters: an [[Block code#The alphabet .CE.A3|alphabet]] size ''q'', a [[Block code#The block length n|block length]] ''n'', and a [[Block code#The message length k|message length]] ''k,'' with ''k &lt; n ≤ q.'' The set of alphabet symbols is interpreted as the [[finite field]] of order ''q'', and thus, ''q'' has to be a prime power. In the most useful parameterizations of the Reed–Solomon code, the block length is usually some constant multiple of the message length, that is, the [[Block code#The rate R|rate]] {{nowrap|1=''R'' = ''k''/''n''}} is some constant, and furthermore, the block length is equal to or one less than the alphabet size, that is, {{nowrap|1=''n'' = ''q''}} or {{nowrap|1=''n'' = ''q'' − 1}}.{{citation needed|date=March 2017}}

=== Reed &amp; Solomon's original view: The codeword as a sequence of values ===

There are different encoding procedures for the Reed–Solomon code, and thus, there are different ways to describe the set of all codewords.
In the original view of {{Harvtxt|Reed|Solomon|1960}}, every codeword of the Reed–Solomon code is a sequence of function values of a polynomial of degree less than ''k''. In order to obtain a codeword of the Reed–Solomon code, the message is interpreted as the description of a polynomial ''p'' of degree less than ''k'' over the finite field ''F'' with ''q'' elements.
In turn, the polynomial ''p'' is evaluated at ''n'' ≤ ''q'' distinct points &lt;math&gt;a_1,\dots,a_n&lt;/math&gt; of the field ''F'', and the sequence of values is the corresponding codeword. Common choices for a set of evaluation points include {0, 1, 2, ..., ''n'' − 1}, {0, ''α'', ''α''&lt;sup&gt;2&lt;/sup&gt;, ..., ''α''&lt;sup&gt;''n''−2&lt;/sup&gt;, 1}, {1, ''α'', ''α''&lt;sup&gt;2&lt;/sup&gt;, ..., ''α''&lt;sup&gt;''n''−2&lt;/sup&gt;}, ... , where ''α'' is a [[primitive element (finite field)|primitive element]] of ''F''. 

Formally, the set &lt;math&gt;\mathbf{C}&lt;/math&gt; of codewords of the Reed–Solomon code is defined as follows:
: &lt;math&gt;
\mathbf{C}
 = \Big\{\;
     \big( p(a_1), p(a_2), \dots, p(a_n) \big)
     \;\Big|\;
     p \text{ is a polynomial over } F \text{ of degree } &lt;k
   \;\Big\}\,.
&lt;/math&gt;
Since any two ''distinct'' polynomials of degree less than &lt;math&gt;k&lt;/math&gt; agree in at most &lt;math&gt;k-1&lt;/math&gt; points, this means that any two codewords of the Reed–Solomon code disagree in at least &lt;math&gt;n - (k-1) = n-k+1&lt;/math&gt; positions.
Furthermore, there are two polynomials that do agree in &lt;math&gt;k-2&lt;/math&gt; points but are not equal, and thus, the [[Block code#The distance d|distance]] of the Reed–Solomon code is exactly &lt;math&gt;d=n-k+1&lt;/math&gt;.
Then the relative distance is &lt;math&gt;\delta = d/n = 1-k/n + 1/n = 1-R+1/n\sim 1-R&lt;/math&gt;, where &lt;math&gt;R=k/n&lt;/math&gt; is the rate.
This trade-off between the relative distance and the rate is asymptotically optimal since, by the [[Singleton bound]], ''every'' code satisfies &lt;math&gt;\delta+R\leq 1+1/n&lt;/math&gt;.
Being a code that achieves this optimal trade-off, the Reed–Solomon code belongs to the class of [[maximum distance separable code]]s.

While the number of different polynomials of degree less than ''k'' and the number of different messages are both equal to &lt;math&gt;q^k&lt;/math&gt;, and thus every message can be uniquely mapped to such a polynomial, there are different ways of doing this encoding.
The original construction of {{Harvtxt|Reed|Solomon|1960}} interprets the message ''x'' as the ''coefficients'' of the polynomial ''p'', whereas subsequent constructions interpret the message as the ''values'' of the polynomial at the first ''k'' points &lt;math&gt;a_1,\dots,a_k&lt;/math&gt; and obtain the polynomial ''p'' by interpolating these values with a polynomial of degree less than ''k''.
The latter encoding procedure, while being slightly less efficient, has the advantage that it gives rise to a [[systematic code]], that is, the original message is always contained as a subsequence of the codeword.

==== Simple encoding procedure: The message as a sequence of coefficients ====
In the original construction of {{Harvtxt|Reed|Solomon|1960}}, the message &lt;math&gt;x=(x_1,\dots,x_k)\in F^k&lt;/math&gt; is mapped to the polynomial &lt;math&gt;p_x&lt;/math&gt; with
:&lt;math&gt;p_x(a) = \sum_{i=1}^k x_i a^{i-1} \,.&lt;/math&gt;
The codeword of &lt;math&gt;x&lt;/math&gt; is obtained by evaluating &lt;math&gt;p_x&lt;/math&gt; at &lt;math&gt;n&lt;/math&gt; different points &lt;math&gt;a_1,\dots,a_n&lt;/math&gt; of the field &lt;math&gt;F&lt;/math&gt;.
Thus the classical encoding function &lt;math&gt;C:F^k \to F^n&lt;/math&gt; for the Reed–Solomon code is defined as follows: 
:&lt;math&gt;C(x) = \big(p_x(a_1),\dots,p_x(a_n)\big)\,.&lt;/math&gt;
This function &lt;math&gt;C&lt;/math&gt; is a [[linear mapping]], that is, it satisfies &lt;math&gt;C(x) = x \cdot A&lt;/math&gt; for the following &lt;math&gt;(k\times n)&lt;/math&gt;-matrix &lt;math&gt;A&lt;/math&gt; with elements from &lt;math&gt;F&lt;/math&gt;:
:&lt;math&gt;A=\begin{bmatrix}
1         &amp; \dots  &amp; 1         &amp; \dots  &amp; 1     \\
a_1       &amp; \dots  &amp; a_k       &amp; \dots  &amp; a_n   \\
a_1^2     &amp; \dots  &amp; a_k^2     &amp; \dots  &amp; a_n^2 \\
\vdots    &amp; \dots &amp; \vdots     &amp; \dots &amp; \vdots \\
a_1^{k-1} &amp; \dots  &amp; a_k^{k-1} &amp; \dots  &amp; a_n^{k-1}
\end{bmatrix}&lt;/math&gt;

This matrix is the transpose of a [[Vandermonde matrix]] over &lt;math&gt;F&lt;/math&gt;.
In other words, the Reed–Solomon code is a [[linear code]], and in the classical encoding procedure, its [[Linear code#Properties|generator matrix]] is &lt;math&gt;A&lt;/math&gt;.

==== Systematic encoding procedure: The message as an initial sequence of values ====

There is an alternative encoding procedure that also produces the Reed–Solomon code, but that does so in a [[systematic code|systematic]] way. Here, the mapping from the message &lt;math&gt;x&lt;/math&gt; to the polynomial &lt;math&gt;p_x&lt;/math&gt; works differently: the polynomial &lt;math&gt;p_x&lt;/math&gt; is now defined as the unique polynomial of degree less than &lt;math&gt;k&lt;/math&gt; such that
:&lt;math&gt;p_x(a_i) = x_i&lt;/math&gt; holds for all &lt;math&gt;i\in\{1,\dots,k\}&lt;/math&gt;.
To compute this polynomial &lt;math&gt;p_x&lt;/math&gt; from &lt;math&gt;x&lt;/math&gt;, one can use [[Lagrange interpolation]].
Once it has been found, it is evaluated at the other points &lt;math&gt;a_{k+1},\dots,a_n&lt;/math&gt; of the field.
The alternative encoding function &lt;math&gt;C:F^k \to F^n&lt;/math&gt; for the Reed–Solomon code is then again just the sequence of values: 
:&lt;math&gt;C(x) = \big(p_x(a_1),\dots,p_x(a_n)\big)\,.&lt;/math&gt;
Since the first &lt;math&gt;k&lt;/math&gt; entries of each codeword &lt;math&gt; C(x) &lt;/math&gt; coincide with &lt;math&gt;x&lt;/math&gt;, this encoding procedure is indeed [[systematic code|systematic]].
Since Lagrange interpolation is a linear transformation, &lt;math&gt; C &lt;/math&gt; is a linear mapping. In fact, we have &lt;math&gt; C(x) = x \cdot G &lt;/math&gt;, where
:&lt;math&gt;G=
(A\text{'s left square submatrix})^{-1}\cdot A
=
\begin{bmatrix}
1         &amp; 0      &amp; 0         &amp; \dots  &amp; 0      &amp; g_{1,k+1} &amp; \dots  &amp; g_{1,n} \\
0         &amp; 1      &amp; 0         &amp; \dots  &amp; 0      &amp; g_{2,k+1} &amp; \dots  &amp; g_{2,n} \\
0         &amp; 0      &amp; 1         &amp; \dots  &amp; 0      &amp; g_{3,k+1} &amp; \dots  &amp; g_{3,n} \\
\vdots    &amp; \vdots &amp; \vdots    &amp; \vdots &amp; \vdots &amp; \vdots    &amp; \vdots &amp; \vdots  \\
0         &amp; \dots  &amp; 0         &amp; \dots  &amp; 1      &amp; g_{k,k+1} &amp; \dots  &amp; g_{k,n} 
\end{bmatrix}&lt;/math&gt;

==== Discrete Fourier transform and its inverse ====

A [[discrete Fourier transform (general)|discrete Fourier transform]] is essentially the same as the encoding procedure; it uses the generator polynomial ''p''(x) to map a set of evaluation points into the message values as shown above:

:&lt;math&gt;C(x) = \big(p_x(a_1),\dots,p_x(a_n)\big)\,.&lt;/math&gt;

The inverse Fourier transform could be used to convert an error free set of ''n'' &lt; ''q'' message values back into the encoding polynomial of ''k'' coefficients, with the constraint that in order for this to work, the set of evaluation points used to encode the message must be a set of increasing powers of ''α'': 

:&lt;math&gt;a_i = \alpha^{i-1}&lt;/math&gt;
:&lt;math&gt;a_1, \dots, a_n = \{ 1, \alpha, \alpha^2, \dots, \alpha^{n-1} \}&lt;/math&gt;

However, Lagrange interpolation performs the same conversion without the constraint on the set of evaluation points or the requirement of an error free set of message values and is used for systematic encoding, and in one of the steps of the [[Reed%E2%80%93Solomon_error_correction#Gao_decoder|Gao decoder]].

=== The BCH view: The codeword as a sequence of coefficients ===
In this view, the sender again maps the message &lt;math&gt;x&lt;/math&gt; to a polynomial &lt;math&gt;p_x&lt;/math&gt;, and for this, any of the two mappings just described can be used (where the message is either interpreted as the coefficients of &lt;math&gt;p_x&lt;/math&gt; or as the initial sequence of values of &lt;math&gt;p_x&lt;/math&gt;). Once the sender has constructed the polynomial &lt;math&gt;p_x&lt;/math&gt; in some way, however, instead of sending the ''values'' of &lt;math&gt;p_x&lt;/math&gt; at all points, the sender computes some related polynomial &lt;math&gt;s&lt;/math&gt; of degree at most &lt;math&gt;n-1&lt;/math&gt; for &lt;math&gt;n=q-1&lt;/math&gt; and sends the &lt;math&gt;n&lt;/math&gt; ''coefficients'' of that polynomial. The polynomial &lt;math&gt;s(a)&lt;/math&gt; is constructed by multiplying the message polynomial &lt;math&gt;p_x(a)&lt;/math&gt;, which has degree at most &lt;math&gt;k-1&lt;/math&gt;, with a [[generator polynomial]] &lt;math&gt;g(a)&lt;/math&gt; of degree &lt;math&gt;n-k&lt;/math&gt; that is known to both the sender and the receiver. {{^|comment - as mentioned in remarks below, methods like puncturing may omit transmission of some of the coefficients}} The generator polynomial &lt;math&gt;g(x)&lt;/math&gt; is defined as the polynomial whose roots are exactly &lt;math&gt;\alpha,\alpha^2,\dots,\alpha^{n-k}&lt;/math&gt;, i.e.,

: &lt;math&gt;g(x) = (x-\alpha)(x-\alpha^2)\cdots(x-\alpha^{n-k}) = g_0 + g_1x + \cdots + g_{n-k-1}x^{n-k-1} + x^{n-k}\,.&lt;/math&gt;

The transmitter sends the &lt;math&gt;n=q-1&lt;/math&gt; coefficients of &lt;math&gt;s(a)=p_x(a) \cdot g(a)&lt;/math&gt;. Thus, in the BCH view of Reed–Solomon codes, the set &lt;math&gt;\mathbf{C}&lt;/math&gt; of codewords is defined for &lt;math&gt;n=q-1&lt;/math&gt; as follows:&lt;ref&gt;{{cite book |first1=Rudolf |last1=Lidl |first2=Günter |last2=Pilz |title=Applied Abstract Algebra |edition=2nd |publisher=Wiley |year=1999 |page=226}}&lt;/ref&gt;

:&lt;math&gt;\mathbf{C} =
\left\{
  \left ( s_1, s_2,\dots, s_{n} \right)
  \;\Big|\;
  s(a)=\sum_{i=1}^n s_i a^{i-1}
  \text{ is a polynomial that has at least the roots } \alpha^1,\alpha^2, \dots, \alpha^{n-k}
\right\}\,.&lt;/math&gt;

==== Systematic encoding procedure ====
The encoding procedure for the BCH view of Reed–Solomon codes can be modified to yield a [[systematic code|systematic encoding procedure]], in which each codeword contains the message as a prefix. Here, instead of sending &lt;math&gt;s(x) = p(x) g(x)&lt;/math&gt;, the encoder constructs the transmitted polynomial &lt;math&gt;s(x)&lt;/math&gt; such that the coefficients of the &lt;math&gt;k&lt;/math&gt; largest monomials are equal to the corresponding coefficients of &lt;math&gt;p(x)&lt;/math&gt;, and the lower-order coefficients of &lt;math&gt;s(x)&lt;/math&gt; are chosen exactly in such a way that &lt;math&gt;s(x)&lt;/math&gt; becomes divisible by &lt;math&gt;g(x)&lt;/math&gt;. Then the coefficients of &lt;math&gt;p(x)&lt;/math&gt; are a subsequence (specifically, a prefix) of the coefficients of &lt;math&gt;s(x)&lt;/math&gt;. To get a code that is overall systematic, we construct the message polynomial &lt;math&gt;p(x)&lt;/math&gt; by interpreting the message as the sequence of its coefficients.

Formally, the construction is done by multiplying &lt;math&gt;p(x)&lt;/math&gt; by &lt;math&gt;x^t&lt;/math&gt; to make room for the &lt;math&gt;t=n-k&lt;/math&gt; check symbols, dividing that product by &lt;math&gt;g(x)&lt;/math&gt; to find the remainder, and then compensating for that remainder by subtracting it. The &lt;math&gt;t&lt;/math&gt; check symbols are created by computing the remainder &lt;math&gt;s_r(x)&lt;/math&gt;:

:&lt;math&gt;s_r(x) = p(x)\cdot x^t \ \bmod \  g(x).&lt;/math&gt;

Note that the remainder has degree at most &lt;math&gt;t-1&lt;/math&gt;, whereas the coefficients of &lt;math&gt;x^{t-1},x^{t-2},\dots,x^1,x^0&lt;/math&gt; in the polynomial &lt;math&gt;p(x)\cdot x^t&lt;/math&gt; are zero. Therefore, the following definition of the codeword &lt;math&gt;s(x)&lt;/math&gt; has the property that the first &lt;math&gt;k&lt;/math&gt; coefficients are identical to the coefficients of &lt;math&gt;p(x)&lt;/math&gt;:

:&lt;math&gt;s(x) = p(x)\cdot x^t - s_r(x)\,.&lt;/math&gt;

As a result, the codewords &lt;math&gt;s(x)&lt;/math&gt; are indeed elements of &lt;math&gt;\mathbf{C}&lt;/math&gt;, that is, they are divisible by the generator polynomial &lt;math&gt;g(x)&lt;/math&gt;:&lt;ref&gt;See {{harvtxt|Lin|Costello|1983|p=171}}, for example.&lt;/ref&gt;
:&lt;math&gt;s(x) \equiv p(x)\cdot x^t - s_r(x) \equiv s_r(x) - s_r(x) \equiv 0 \mod g(x)\,.&lt;/math&gt;

==Properties==

The Reed–Solomon code is a [''n'', ''k'', ''n'' &amp;minus; ''k'' + 1] code; in other words, it is a [[linear code|linear block code]] of length ''n'' (over ''F'') with [[Dimension (vector space)|dimension]] ''k'' and minimum [[Hamming distance]] ''n''&amp;nbsp;&amp;minus;&amp;nbsp;''k''&amp;nbsp;+&amp;nbsp;1. The Reed–Solomon code is optimal in the sense that the minimum distance has the maximum value possible for a linear code of size (''n'',&amp;nbsp;''k''); this is known as the [[Singleton bound]]. Such a code is also called a [[MDS code|maximum distance separable (MDS) code]].

The error-correcting ability of a Reed–Solomon code is determined by its minimum distance, or equivalently, by &lt;math&gt;n - k&lt;/math&gt;, the measure of redundancy in the block. If the locations of the error symbols are not known in advance, then a Reed–Solomon code can correct up to &lt;math&gt;(n-k)/2&lt;/math&gt; erroneous symbols, i.e., it can correct half as many errors as there are redundant symbols added to the block. Sometimes error locations are known in advance (e.g., "side information" in [[demodulator]] [[signal-to-noise ratio]]s)—these are called [[Erasure channel (disambiguation)|erasures]]. A Reed–Solomon code (like any [[Maximum distance separable code|MDS code]]) is able to correct twice as many erasures as errors, and any combination of errors and erasures can be corrected as long as the relation 2''E'' + ''S'' ≤ ''n'' &amp;minus; ''k'' is satisfied, where &lt;math&gt;E&lt;/math&gt; is the number of errors and &lt;math&gt;S&lt;/math&gt; is the number of erasures in the block.

For practical uses of Reed–Solomon codes, it is common to use a finite field &lt;math&gt;F&lt;/math&gt; with &lt;math&gt;2^m&lt;/math&gt; elements. In this case, each symbol can be represented as an &lt;math&gt;m&lt;/math&gt;-bit value. 
The sender sends the data points as encoded blocks, and the number of symbols in the encoded block is &lt;math&gt;n = 2^m - 1&lt;/math&gt;. Thus a Reed–Solomon code operating on 8-bit symbols has &lt;math&gt;n = 2^8 - 1 = 255&lt;/math&gt; symbols per block. (This is a very popular value because of the prevalence of [[byte-oriented]] computer systems.) The number &lt;math&gt;k&lt;/math&gt;, with &lt;math&gt;k &lt; n&lt;/math&gt;, of ''data'' symbols in the block is a design parameter. A commonly used code encodes &lt;math&gt;k = 223&lt;/math&gt; eight-bit data symbols plus 32 eight-bit parity symbols in an &lt;math&gt;n = 255&lt;/math&gt;-symbol block; this is denoted as a &lt;math&gt;(n, k) = (255,223)&lt;/math&gt; code, and is capable of correcting up to 16 symbol errors per block.

The Reed–Solomon code properties discussed above make them especially well-suited to applications where errors occur in [[burst error|burst]]s.  This is because it does not matter to the code how many bits in a symbol are in error — if multiple bits in a symbol are corrupted it only counts as a single error.  Conversely, if a data stream is not characterized by error bursts or drop-outs but by random single bit errors, a Reed–Solomon code is usually a poor choice compared to a binary code.

The Reed–Solomon code, like the [[convolutional code]], is a transparent code. This means that if the channel symbols have been [[bitwise NOT|inverted]] somewhere along the line, the decoders will still operate. The result will be the inversion of the original data. However, the Reed–Solomon code loses its transparency when the code is shortened. The "missing" bits in a shortened code need to be filled by either zeros or ones, depending on whether the data is complemented or not. (To put it another way, if the symbols are inverted, then the zero-fill needs to be inverted to a one-fill.) For this reason it is mandatory that the sense of the data (i.e., true or complemented) be resolved before Reed–Solomon decoding.

Whether the Reed–Solomon code is [[cyclic code|cyclic]] or not depends on subtle details of the construction. In the original view of Reed and Solomon, where the codewords are the values of a polynomial, one can choose the sequence of evaluation points in such a way as to make the code cyclic. In particular, if &lt;math&gt;\alpha&lt;/math&gt; is a [[primitive root modulo n|primitive root]] of the field &lt;math&gt;F&lt;/math&gt;, then by definition all non-zero elements of &lt;math&gt;F&lt;/math&gt; take the form &lt;math&gt;\alpha^i&lt;/math&gt; for  &lt;math&gt;i\in\{1,\dots,q-1\}&lt;/math&gt;, where &lt;math&gt;q=|F|&lt;/math&gt;.  Each polynomial &lt;math&gt;p&lt;/math&gt; over &lt;math&gt;F&lt;/math&gt; gives rise to a codeword &lt;math&gt;(p(\alpha^1),\dots,p(\alpha^{q-1}))&lt;/math&gt;. Since the function &lt;math&gt;a\mapsto p(\alpha a)&lt;/math&gt; is also a polynomial of the same degree, this function gives rise to a codeword &lt;math&gt;(p(\alpha^2),\dots,p(\alpha^{q}))&lt;/math&gt;; since &lt;math&gt;\alpha^{q}=\alpha^1&lt;/math&gt; holds, this codeword is the [[circular shift|cyclic left-shift]] of the original codeword derived from &lt;math&gt;p&lt;/math&gt;. So choosing a sequence of primitive root powers as the evaluation points makes the original view Reed–Solomon code [[cyclic code|cyclic]]. Reed–Solomon codes in the BCH view are always cyclic because [[BCH_code#Properties|BCH codes are cyclic]].

===Remarks===

Designers are not required to use the "natural" sizes of Reed–Solomon code blocks. A technique known as "shortening" can produce a smaller code of any desired size from a larger code. For example, the widely used (255,223) code can be converted to a (160,128) code by padding the unused portion of the source block with 95 binary zeroes and not transmitting them. At the decoder, the same portion of the block is loaded locally with binary zeroes. The Delsarte-Goethals-Seidel&lt;ref&gt;{{Citation |first=Florian |last=Pfender |first2=Günter M. |last2=Ziegler |title=Kissing Numbers, Sphere Packings, and Some Unexpected Proofs |journal=Notices of the American Mathematical Society |volume=51 |issue=8 |pages=873&amp;ndash;883 |date=September 2004 |url=http://www.ams.org/notices/200408/fea-pfender.pdf |doi= }}. Explains the Delsarte-Goethals-Seidel theorem as used in the context of the error correcting code for [[compact disc]].&lt;/ref&gt; theorem illustrates an example of an application of shortened Reed–Solomon codes. In parallel to shortening, a technique known as [[puncturing]] allows omitting some of the encoded parity symbols.

== Reed Solomon original view decoders ==

The decoders described in this section use the Reed Solomon original view of a codeword as a sequence of polynomial values where the polynomial is based on the message to be encoded. The same set of fixed values are used by the encoder and decoder, and the decoder recovers the encoding polynomial (and optionally an error locating polynomial) from the received message.

==== Theoretical decoder ====

{{Harvtxt|Reed|Solomon|1960}} described a theoretical decoder that corrected errors by finding the most popular message polynomial. The decoder only knows the set of values &lt;math&gt;a_1&lt;/math&gt; to &lt;math&gt;a_n&lt;/math&gt; and which encoding method was used to generate the codeword's sequence of values. The original message, the polynomial, and any errors are unknown. A decoding procedure could use a method like Lagrange interpolation on various subsets of n codeword values taken k at a time to repeatedly produce potential polynomials, until a sufficient number of matching polynomials are produced to reasonably eliminate any errors in the received codeword. Once a polynomial is determined, then any errors in the codeword can be corrected, by recalculating the corresponding codeword values. Unfortunately, in all but the simplest of cases, there are too many subsets, so the algorithm is impractical.  The number of subsets is the [[binomial coefficient]], &lt;math&gt;\textstyle \binom{n}{k} = {n! \over (n-k)! k!}&lt;/math&gt;, and the number of subsets is infeasible for even modest codes. For a &lt;math&gt;(255,249)&lt;/math&gt; code that can correct 3 errors, the naive theoretical decoder would examine 359 billion subsets. &lt;!-- = 255 * 254 * 253 * 252 * 251 * 250 / 720 rounded down; could say 360B --&gt;  

==== Berlekamp Welch decoder ====

In 1986, a decoder known as the [[Berlekamp–Welch algorithm]] was developed as a decoder that is able to recover the original message polynomial as well as an error "locator" polynomial that produces zeroes for the input values that correspond to errors, with time complexity O(n^3), where n is the number of values in a message. The recovered polynomial is then used to recover (recalculate as needed) the original message.

===== Example =====

Using RS(7,3), GF(929), and the set of evaluation points ''a''&lt;sub&gt;i&lt;/sub&gt; = i-1

:{{math| ''a'' {{=}} {0, 1, 2, 3, 4, 5, 6} }}

If the message polynomial is
:{{math| ''p''(''x'') {{=}} 003 ''x''&lt;sup&gt;2&lt;/sup&gt; + 002 ''x'' + 001}}

The codeword is
:{{math| ''c'' {{=}} {001, 006, 017, 034, 057, 086, 121} }}

Errors in transmission might cause this to be received instead.
:{{math| ''b'' {{=}} ''c'' + ''e'' {{=}} {001, 006, 123, 456, 057, 086, 121} }}

The key equations are:

:&lt;math&gt;b_i E(a_i) - Q(a_i) = 0 &lt;/math&gt;

Assume maximum number of errors: ''e'' = 2. The key equations become:

:&lt;math&gt;b_i(e_0 + e_1 a_i) - (q_0 + q_1 a_i + q_2 a_i^2 + q_3 a_i^3 + q_4 a_i^4) = - b_i a_i^2&lt;/math&gt;

&lt;br&gt;

:&lt;math&gt;\begin{bmatrix}
001 &amp; 000 &amp; 928 &amp; 000 &amp; 000 &amp; 000 &amp; 000 \\
006 &amp; 006 &amp; 928 &amp; 928 &amp; 928 &amp; 928 &amp; 928 \\
123 &amp; 246 &amp; 928 &amp; 927 &amp; 925 &amp; 921 &amp; 913 \\
456 &amp; 439 &amp; 928 &amp; 926 &amp; 920 &amp; 902 &amp; 848 \\
057 &amp; 228 &amp; 928 &amp; 925 &amp; 913 &amp; 865 &amp; 673 \\
086 &amp; 430 &amp; 928 &amp; 924 &amp; 904 &amp; 804 &amp; 304 \\
121 &amp; 726 &amp; 928 &amp; 923 &amp; 893 &amp; 713 &amp; 562
\end{bmatrix}
\begin{bmatrix}
e_0 \\
e_1 \\
q_0 \\
q_1 \\
q_2 \\
q_3 \\
q_4
\end{bmatrix}
=
\begin{bmatrix}
000 \\
923 \\
437 \\
541 \\
017 \\
637 \\
289
\end{bmatrix}
&lt;/math&gt;

Using [[Gaussian elimination]]:

:&lt;math&gt;
\begin{bmatrix}
001 &amp; 000 &amp; 000 &amp; 000 &amp; 000 &amp; 000 &amp; 000 \\
000 &amp; 001 &amp; 000 &amp; 000 &amp; 000 &amp; 000 &amp; 000 \\
000 &amp; 000 &amp; 001 &amp; 000 &amp; 000 &amp; 000 &amp; 000 \\
000 &amp; 000 &amp; 000 &amp; 001 &amp; 000 &amp; 000 &amp; 000 \\
000 &amp; 000 &amp; 000 &amp; 000 &amp; 001 &amp; 000 &amp; 000 \\
000 &amp; 000 &amp; 000 &amp; 000 &amp; 000 &amp; 001 &amp; 000 \\
000 &amp; 000 &amp; 000 &amp; 000 &amp; 000 &amp; 000 &amp; 001 
\end{bmatrix}
\begin{bmatrix}
e_0 \\
e_1 \\
q_0 \\
q_1 \\
q_2 \\
q_3 \\
q_4
\end{bmatrix}
=
\begin{bmatrix}
006 \\
924 \\
006 \\
007 \\
009 \\
916 \\
003
\end{bmatrix}
&lt;/math&gt;

:{{math| ''Q''(''x'') {{=}} 003 ''x''&lt;sup&gt;4&lt;/sup&gt; + 916 ''x''&lt;sup&gt;3&lt;/sup&gt; + 009 ''x''&lt;sup&gt;2&lt;/sup&gt; + 007 ''x'' + 006}}

:{{math| ''E''(''x'') {{=}} 001 ''x''&lt;sup&gt;2&lt;/sup&gt; + 924 ''x'' + 006}}

:{{math| ''Q''(''x'') / ''E''(''x'') {{=}} ''P''(''x'') {{=}} 003 ''x''&lt;sup&gt;2&lt;/sup&gt; + 002 ''x'' + 001}}

Recalculate {{math| P(x) }} where {{math| E(x) {{=}} 0 : {2, 3} }} to correct {{math| ''b''}} resulting in the corrected codeword:

:{{math| ''c'' {{=}} {001, 006, 017, 034, 057, 086, 121} }}

==== Gao decoder ====

In 2002, an improved decoder was developed by Shuhong Gao, based on the extended Euclid algorithm [http://www.math.clemson.edu/~sgao/papers/RS.pdf Gao_RS.pdf] .

===== Example =====

Using the same data as the Berlekamp Welch example above:

:&lt;math&gt;R_{-1} = \prod_{i=1}^n (x - a_i)&lt;/math&gt;
:&lt;math&gt;R_0 = &lt;/math&gt; Lagrange interpolation of &lt;math&gt;\{a_i, b(a_i)\}&lt;/math&gt; for i = 1 to ''n''
:&lt;math&gt;A_{-1} = 0&lt;/math&gt;
:&lt;math&gt;A_0 = 1&lt;/math&gt;

{| class="wikitable"
|-
! ''i''
! R&lt;sub&gt;''i''&lt;/sub&gt;
! A&lt;sub&gt;''i''&lt;/sub&gt;
|-
| −1
| 001 x&lt;sup&gt;7&lt;/sup&gt; + 908 x&lt;sup&gt;6&lt;/sup&gt; + 175 x&lt;sup&gt;5&lt;/sup&gt; + 194 x&lt;sup&gt;4&lt;/sup&gt; + 695 x&lt;sup&gt;3&lt;/sup&gt; + 094 x&lt;sup&gt;2&lt;/sup&gt; + 720 x + 000
| 000
|-
| 0
| 055 x&lt;sup&gt;6&lt;/sup&gt; + 440 x&lt;sup&gt;5&lt;/sup&gt; + 497 x&lt;sup&gt;4&lt;/sup&gt; + 904 x&lt;sup&gt;3&lt;/sup&gt; + 424 x&lt;sup&gt;2&lt;/sup&gt; + 472 x + 001
| 001
|-
| 1
| 702 x&lt;sup&gt;5&lt;/sup&gt; + 845 x&lt;sup&gt;4&lt;/sup&gt; + 691 x&lt;sup&gt;3&lt;/sup&gt; + 461 x&lt;sup&gt;2&lt;/sup&gt; + 327 x + 237
| 152 x + 237
|-
| 2
| 266 x&lt;sup&gt;4&lt;/sup&gt; + 086 x&lt;sup&gt;3&lt;/sup&gt; + 798 x&lt;sup&gt;2&lt;/sup&gt; + 311 x + 532
| 708 x&lt;sup&gt;2&lt;/sup&gt; + 176 x + 532
|-
|}

:{{math| ''Q''(''x'') {{=}} ''R''&lt;sub&gt;2&lt;/sub&gt; {{=}} 266 ''x''&lt;sup&gt;4&lt;/sup&gt; + 086 ''x''&lt;sup&gt;3&lt;/sup&gt; + 798 ''x''&lt;sup&gt;2&lt;/sup&gt; + 311 ''x'' + 532}}

:{{math| ''E''(''x'') {{=}} ''A''&lt;sub&gt;2&lt;/sub&gt; {{=}} 708 ''x''&lt;sup&gt;2&lt;/sup&gt; + 176 ''x'' + 532}}

divide ''Q''(x) and ''E''(x) by most significant coeficient of ''E''(x) = 708. (Optional)

:{{math| ''Q''(''x'') {{=}} 003 ''x''&lt;sup&gt;4&lt;/sup&gt; + 916 ''x''&lt;sup&gt;3&lt;/sup&gt; + 009 ''x''&lt;sup&gt;2&lt;/sup&gt; + 007 ''x'' + 006}}

:{{math| ''E''(''x'') {{=}} 001 ''x''&lt;sup&gt;2&lt;/sup&gt; + 924 ''x'' + 006}}

:{{math| ''Q''(''x'') / ''E''(''x'') {{=}} ''P''(''x'') {{=}} 003 ''x''&lt;sup&gt;2&lt;/sup&gt; + 002 ''x'' + 001}}

Recalculate {{math| P(x) }} where {{math| E(x) {{=}} 0 : {2, 3} }} to correct {{math| ''b''}} resulting in the corrected codeword:

:{{math| ''c'' {{=}} {001, 006, 017, 034, 057, 086, 121} }}

== BCH view decoders ==

The decoders described in this section use the BCH view of a codeword as a sequence of coefficients. They use a fixed generator polynomial known to both encoder and decoder.

=== Peterson–Gorenstein–Zierler decoder ===

{{main article|BCH code#Peterson–Gorenstein–Zierler algorithm|l1=Peterson–Gorenstein–Zierler algorithm}}

Daniel Gorenstein and Neal Zierler developed a decoder that was described in a MIT Lincoln Laboratory report by Zierler in January 1960 and later in a paper in June 1961.&lt;ref&gt;D. Gorenstein and N. Zierler, "A class of cyclic linear error-correcting codes in p^m symbols," J. SIAM, vol. 9, pp. 207-214, June 1961&lt;/ref&gt; The Gorenstein-Zierler decoder and the related work on BCH codes are described in a book Error Correcting Codes by [[W. Wesley Peterson]] (1961).&lt;ref&gt;Error Correcting Codes by W_Wesley_Peterson, 1961&lt;/ref&gt;

====Syndrome decoding====

The transmitted message is viewed as the coefficients of a polynomial ''s''(''x'') that is divisible by a generator polynomial ''g''(''x'').
:&lt;math&gt;s(x) = \sum_{i = 0}^{n-1}  c_i x^i&lt;/math&gt;
:&lt;math&gt;g(x) = \prod_{j=1}^{n-k} (x - \alpha^j), &lt;/math&gt;

where ''α'' is a primitive root.

Since ''s''(''x'') is divisible by generator ''g''(''x''), it follows that
:&lt;math&gt;s(\alpha^i) = 0, \ i=1,2,\ldots,n-k&lt;/math&gt;

The transmitted polynomial is corrupted in transit by an error polynomial ''e''(''x'') to produce the received polynomial ''r''(''x'').
:&lt;math&gt;r(x) = s(x) + e(x)&lt;/math&gt;
:&lt;math&gt;e(x) = \sum_{i=0}^{n-1} e_i   x^i &lt;/math&gt;

where ''e&lt;sub&gt;i&lt;/sub&gt;'' is the coefficient for the ''i''-th power of ''x''.  Coefficient ''e&lt;sub&gt;i&lt;/sub&gt;'' will be zero if there is no error at that power of ''x'' and nonzero if there is an error.  If there are ''ν'' errors at distinct powers ''i&lt;sub&gt;k&lt;/sub&gt;'' of ''x'', then

:&lt;math&gt;e(x) = \sum_{k=1}^\nu e_{i_k} x^{i_k}&lt;/math&gt;

The goal of the decoder is to find the number of errors (''ν''), the positions of the errors (''i&lt;sub&gt;k&lt;/sub&gt;''), and the error values at those positions (''e&lt;sub&gt;i&lt;sub&gt;k&lt;/sub&gt;&lt;/sub&gt;''). From those, e(x) can be calculated and subtracted from r(x) to get the originally sent message s(x).

The decoder starts by evaluating the polynomial as received at certain points. We call the results of that evaluation the "syndromes", ''S''&lt;sub&gt;''j''&lt;/sub&gt;. They are defined as:
:&lt;math&gt;
\begin{align}
S_j &amp;= r(\alpha^j) = s(\alpha^j) + e(\alpha^j) = 0 + e(\alpha^j) = e(\alpha^j), \ j=1,2,\ldots,n-k \\
    &amp;= \sum_{k=1}^{\nu} e_{i_k} \left( \alpha^{j} \right)^{i_k}
\end{align}
&lt;/math&gt;

The advantage of looking at the syndromes is that the message polynomial drops out. In other words, the syndromes only relate to the error, and are unaffected by the actual contents of the message being transmitted. If the syndromes are all zero, the algorithm stops here and reports that the message was not corrupted in transit.

====Error locators and error values====
&lt;!-- There's confusion between index k and the k in (n,k). Literature also has confusion? Or does it use kappa? --&gt;

For convenience, define the '''error locators''' ''X&lt;sub&gt;k&lt;/sub&gt;'' and '''error values''' ''Y&lt;sub&gt;k&lt;/sub&gt;'' as:
:&lt;math&gt; X_k = \alpha^{i_k}, \  Y_k = e_{i_k} &lt;/math&gt;

Then the syndromes can be written in terms of the error locators and error values as
:&lt;math&gt;  S_j =  \sum_{k=1}^{\nu} Y_k X_k^{j} &lt;/math&gt;

This definition of the syndrome values is equivalent to the previous since &lt;math&gt;(\alpha^j)^{i_k} = \alpha ^ {j*i_k} = (\alpha^{i_k})^j = X_k^j&lt;/math&gt;.

The syndromes give a system of ''n''&amp;nbsp;&amp;minus;&amp;nbsp;''k'' ≥ 2''ν'' equations in 2''ν'' unknowns, but that system of equations is nonlinear in the ''X&lt;sub&gt;k&lt;/sub&gt;'' and does not have an obvious solution.  However, if the ''X&lt;sub&gt;k&lt;/sub&gt;'' were known (see below), then the syndrome equations provide a linear system of equations that can easily be solved for the ''Y&lt;sub&gt;k&lt;/sub&gt;'' error values.
&lt;!--
Vandermonde comment. Matrix equation --&gt;

:&lt;math&gt;\begin{bmatrix}
X_1^1 &amp; X_2^1 &amp; \cdots &amp; X_\nu^1 \\
X_1^2 &amp; X_2^2 &amp; \cdots &amp; X_\nu^2 \\
\vdots &amp; \vdots &amp;&amp; \vdots \\
X_1^{n-k} &amp; X_2^{n-k} &amp; \cdots &amp; X_\nu^{n-k} \\
\end{bmatrix}
\begin{bmatrix}
Y_1 \\ Y_2 \\ \vdots \\ Y_\nu
\end{bmatrix}
= 
\begin{bmatrix}
S_1 \\ S_2 \\ \vdots \\ S_{n-k}
\end{bmatrix}
&lt;/math&gt;

Consequently, the problem is finding the ''X&lt;sub&gt;k&lt;/sub&gt;'', because then the leftmost matrix would be known, and both sides of the equation could be multiplied by its inverse, yielding Y''&lt;sub&gt;k&lt;/sub&gt;''

====Error locator polynomial====

There is a linear recurrence relation that gives rise to a system of linear equations. Solving those equations identifies those error locations ''X&lt;sub&gt;k&lt;/sub&gt;''.
&lt;!--This is credited to Daniel Gorenstein and Neal Zierler in the book Error Correcting Codes by Peterson - 1961 --&gt;
&lt;!--Petersons decoder is a simplified implementation for bit oriented BCH codes where the error values only have magnitude one. --&gt;

Define the '''error locator polynomial''' Λ(''x'') as

:&lt;math&gt;\Lambda(x) = \prod_{k=1}^\nu (1 - x X_k ) = 1 + \Lambda_1 x^1 + \Lambda_2 x^2 + \cdots + \Lambda_\nu x^\nu&lt;/math&gt;

The zeros of Λ(''x'') are the reciprocals &lt;math&gt;X_k^{-1}&lt;/math&gt;. This follows from the above product notation construction since if &lt;math&gt;x=X_k^{-1}&lt;/math&gt; then one of the multiplied terms will be zero &lt;math&gt;(1 - X_k^{-1} * X_k) = 1 - 1 = 0&lt;/math&gt;, making the whole polynomial evaluate to zero. Explicitly:
:&lt;math&gt; \Lambda(X_k^{-1}) = 0 &lt;/math&gt;

:&lt;math&gt;\Lambda(X_k^{-1}) = 1 + \Lambda_1 X_k^{-1} + \Lambda_2 X_k^{-2} + \cdots + \Lambda_\nu X_k^{-\nu}  = 0 &lt;/math&gt;

Multiply both sides by &lt;math&gt;Y_k X_k^{j+\nu}&lt;/math&gt; and it will still be zero. j is any number such that &lt;math&gt;1 \leq j \leq v&lt;/math&gt;.

:&lt;math&gt;
\begin{align}
&amp; Y_k X_k^{j+\nu} \Lambda(X_k^{-1}) = 0. \\
&amp; Y_k X_k^{j+\nu} (1 + \Lambda_1 X_k^{-1} + \Lambda_2 X_k^{-2} + \cdots + \Lambda_\nu X_k^{-\nu}) = 0. \\ 
\text{Hence } &amp; Y_k X_k^{j+\nu} + \Lambda_1 Y_k X_k^{j+\nu} X_k^{-1} + \Lambda_2 Y_k X_k^{j+\nu} X_k^{-2} + \cdots + \Lambda_{\nu} Y_k X_k^{j+\nu} X_k^{-\nu} = 0, \\
\text{and so } &amp; Y_k X_k^{j+\nu} + \Lambda_1 Y_k X_k^{j+\nu-1} + \Lambda_2 Y_k X_k^{j+\nu -2} + \cdots + \Lambda_{\nu} Y_k X_k^j = 0 \\
\end{align}
&lt;/math&gt;

Sum for ''k'' = 1 to ''ν''

:&lt;math&gt;\begin{align}
&amp; \sum_{k=1}^\nu ( Y_k X_k^{j+\nu} + \Lambda_1 Y_k X_k^{j+\nu-1} + \Lambda_2 Y_k X_k^{j+\nu -2} + \cdots + \Lambda_{\nu} Y_k X_k^{j} ) = 0  \\
\end{align}&lt;/math&gt;

Collect each term into its own sum, and extract the constant values of &lt;math&gt;\Lambda&lt;/math&gt; that are unaffected by the summation

:&lt;math&gt;\begin{align}
&amp; (\sum_{k=1}^\nu  Y_k X_k^{j+\nu} ) + \Lambda_1 (\sum_{k=1}^\nu Y_k X_k^{j+\nu-1}) + \Lambda_2 (\sum_{k=1}^\nu Y_k X_k^{j+\nu -2}) + \cdots + \Lambda_\nu (\sum_{k=1}^\nu Y_k X_k^j ) = 0
\end{align}&lt;/math&gt;

Note that these summations are now equivalent to the syndrome values, which we know and can substitute in! This therefore reduces to

:&lt;math&gt; S_{j + \nu} + \Lambda_1 S_{j+\nu-1} + \cdots + \Lambda_{\nu-1} S_{j+1} + \Lambda_{\nu} S_j   = 0 \, &lt;/math&gt;

Subtracting &lt;math&gt;S_{j+\nu}&lt;/math&gt; from both sides yields

:&lt;math&gt; S_j \Lambda_{\nu} + S_{j+1}\Lambda_{\nu-1} + \cdots + S_{j+\nu-1} \Lambda_1 = - S_{j + \nu} \ &lt;/math&gt;

Recall that j was chosen to be any integer between 1 and v inclusive, and this equivalence is true for any and all such values. Therefore, we have v linear equations, not just one. This system of linear equations can therefore be solved for the coefficients Λ&lt;sub&gt;''i''&lt;/sub&gt; of the error location polynomial:

:&lt;math&gt;\begin{bmatrix}
S_1 &amp; S_2 &amp; \cdots &amp; S_{\nu} \\
S_2 &amp; S_3 &amp; \cdots &amp; S_{\nu+1} \\
\vdots &amp; \vdots &amp;&amp; \vdots \\
S_{\nu} &amp; S_{\nu+1} &amp; \cdots &amp; S_{2\nu-1}
\end{bmatrix}
\begin{bmatrix}
\Lambda_{\nu} \\ \Lambda_{\nu-1} \\ \vdots \\ \Lambda_1
\end{bmatrix}
= 
\begin{bmatrix}
- S_{\nu+1} \\ - S_{\nu+2} \\ \vdots \\ - S_{\nu+\nu}
\end{bmatrix}
&lt;/math&gt;
The above assumes the decoder knows the number of errors ''ν'', but that number has not been determined yet. The PGZ decoder does not determine ''ν'' directly but rather searches for it by trying successive values. The decoder first assumes the largest value for a trial ''ν'' and sets up the linear system for that value. If the equations can be solved (i.e., the matrix determinant is nonzero), then that trial value is the number of errors. If the linear system cannot be solved, then the trial ''ν'' is reduced by one and the next smaller system is examined. {{Harv|Gill|n.d.|p=35}}

====Obtain the error locators from the error locator polynomial====

Use the coefficients Λ&lt;sub&gt;''i''&lt;/sub&gt; found in the last step to build the error location polynomial. The roots of the error location polynomial can be found by exhaustive search. The error locators ''X&lt;sub&gt;k&lt;/sub&gt;'' are the reciprocals of those roots. Note that the order of coefficients of the error location polynomial can be reversed, in which case the roots of that reversed polynomial are the error locators &lt;math&gt;X_k&lt;/math&gt; (not their reciprocals &lt;math&gt;X_k^{-1}&lt;/math&gt;). [[Chien search]] is an efficient implementation of this step.

====Calculate the error values====

Once the error locators ''X&lt;sub&gt;k&lt;/sub&gt;'' are known, the error values can be determined. This can be done by direct solution for ''Y&lt;sub&gt;k&lt;/sub&gt;'' in the [[#Error locators and error values|error equations]] matrix given above, or using the [[Forney algorithm]].

====Calculate the error locations====

Calculate ''i&lt;sub&gt;k&lt;/sub&gt;'' by taking the log base &lt;math&gt;\alpha&lt;/math&gt; of ''X&lt;sub&gt;k&lt;/sub&gt;''. This is generally done using a precomputed lookup table.

====Fix the errors====

Finally, e(x) is generated from ''i&lt;sub&gt;k&lt;/sub&gt;'' and ''e&lt;sub&gt;i&lt;sub&gt;k&lt;/sub&gt;&lt;/sub&gt;'' and then is subtracted from r(x) to get the sent message s(x).

==== Example ====

Consider the Reed&amp;ndash;Solomon code defined in {{math|''GF''(929)}} with {{math|''α'' {{=}} 3}} and {{math|''t'' {{=}} 4}} (this is used in [[PDF417]] barcodes) for a RS(7,3) code. The generator polynomial is
:&lt;math&gt;g(x) = (x-3)(x-3^2)(x-3^3)(x-3^4) = x^4+809 x^3+723 x^2+568 x+522&lt;/math&gt;
If the message polynomial is {{math|''p''(''x'') {{=}} 3 ''x''&lt;sup&gt;2&lt;/sup&gt; + 2 ''x'' + 1}}, then a systematic codeword is encoded as follows.
:&lt;math&gt;s_r(x) = p(x) \, x^t \mod g(x) = 547 x^3 + 738 x^2 + 442 x + 455&lt;/math&gt;
:&lt;math&gt;s(x) = p(x) \, x^t - s_r(x) = 3 x^6 + 2 x^5 + 1 x^4 + 382 x^3 + 191 x^2 + 487 x + 474&lt;/math&gt;
Errors in transmission might cause this to be received instead.
:&lt;math&gt;r(x) = s(x) + e(x) = 3 x^6 + 2 x^5 + 123 x^4 + 456 x^3 + 191 x^2 + 487 x + 474&lt;/math&gt;
The syndromes are calculated by evaluating ''r'' at powers of ''α''.
:&lt;math&gt;S_1 = r(3^1) = 3\cdot 3^6 + 2\cdot 3^5 + 123\cdot 3^4 + 456\cdot 3^3 + 191\cdot 3^2 + 487\cdot 3 + 474 = 732&lt;/math&gt;
:&lt;math&gt;S_2 = r(3^2) = 637,\;S_3 = r(3^3) = 762,\;S_4 = r(3^4) = 925&lt;/math&gt;

:&lt;math&gt;\begin{bmatrix}
732 &amp; 637 \\
637 &amp; 762
\end{bmatrix}
\begin{bmatrix}
\Lambda_2 \\
\Lambda_1
\end{bmatrix}
= 
\begin{bmatrix}
-762 \\ -925 
\end{bmatrix}
= 
\begin{bmatrix}
167 \\ 004 
\end{bmatrix}
&lt;/math&gt;

Using [[Gaussian elimination]]:

:&lt;math&gt;\begin{bmatrix}
001 &amp; 000 \\
000 &amp; 001
\end{bmatrix}
\begin{bmatrix}
\Lambda_2 \\
\Lambda_1
\end{bmatrix}
= 
\begin{bmatrix}
329 \\ 821 
\end{bmatrix}
&lt;/math&gt;

:Λ(x) = 329 x&lt;sup&gt;2&lt;/sup&gt; + 821 x + 001, with roots x&lt;sub&gt;1&lt;/sub&gt; = 757 = 3&lt;sup&gt;&amp;minus;3&lt;/sup&gt; and x&lt;sub&gt;2&lt;/sub&gt; = 562 = 3&lt;sup&gt;&amp;minus;4&lt;/sup&gt;&lt;br&gt;
The coefficients can be reversed to produce roots with positive exponents, but typically this isn't used:
:R(x) = 001 x&lt;sup&gt;2&lt;/sup&gt; + 821 x + 329, with roots 27 = 3&lt;sup&gt;3&lt;/sup&gt; and 81 = 3&lt;sup&gt;4&lt;/sup&gt;
with the log of the roots corresponding to the error locations (right to left, location 0 is the last term in the codeword).

To calculate the error values, apply the [[Forney algorithm]].

:Ω(x) = S(x) Λ(x) mod x&lt;sup&gt;4&lt;/sup&gt; = 546 x + 732
:Λ'(x) = 658 x + 821
:e&lt;sub&gt;1&lt;/sub&gt; = -Ω(x&lt;sub&gt;1&lt;/sub&gt;)/Λ'(x&lt;sub&gt;1&lt;/sub&gt;) = 074
:e&lt;sub&gt;2&lt;/sub&gt; = -Ω(x&lt;sub&gt;2&lt;/sub&gt;)/Λ'(x&lt;sub&gt;2&lt;/sub&gt;) = 122

Subtracting ''e''&lt;sub&gt;1&lt;/sub&gt; ''x''&lt;sup&gt;3&lt;/sup&gt; and ''e''&lt;sub&gt;2&lt;/sub&gt; ''x''&lt;sup&gt;4&lt;/sup&gt; from the received polynomial ''r'' reproduces the original codeword ''s''.

=== Berlekamp&amp;ndash;Massey decoder ===
The [[Berlekamp&amp;ndash;Massey algorithm]] is an alternate iterative procedure for finding the error locator polynomial. During each iteration, it calculates a discrepancy based on a current instance of Λ(x) with an assumed number of errors ''e'':

:&lt;math&gt; \Delta  = S_{i} + \Lambda_1 \  S_{i-1} + \cdots + \Lambda_e \  S_{i-e}&lt;/math&gt;

and then adjusts Λ(x) and ''e'' so that a recalculated Δ would be zero. The article [[Berlekamp&amp;ndash;Massey algorithm]] has a detailed description of the procedure. In the following example, C(x) is used to represent Λ(x).

==== Example ====

Using the same data as the Peterson Gorenstein Zierler example above:
{| class="wikitable"
|-
! ''n''
! ''S''&lt;sub&gt;''n''+1&lt;/sub&gt;
! ''d''
! ''C''
! ''B''
! ''b''
! ''m''
|-
| 0 || 732 || 732 || 197 ''x'' + 1 || 1 || 732 || 1
|-
| 1 || 637 || 846 || 173 ''x'' + 1 || 1 || 732 || 2
|-
| 2 || 762 || 412 || 634 ''x''&lt;sup&gt;2&lt;/sup&gt; + 173 ''x'' + 1 || 173 ''x'' + 1 || 412 || 1
|-
| 3 || 925 || 576 || 329 ''x''&lt;sup&gt;2&lt;/sup&gt; + 821 ''x'' + 1 || 173 ''x'' + 1 || 412 || 2
|}
The final value of ''C'' is the error locator polynomial, Λ(''x'').

=== Euclidean decoder ===

Another iterative method for calculating both the error locator polynomial and the error value polynomial is based on Sugiyama's adaptation of the [[Extended Euclidean algorithm]] .

Define S(x), Λ(x), and Ω(x) for ''t'' syndromes and ''e'' errors:

:&lt;math&gt; S(x) = S_{t} x^{t-1} + S_{t-1} x^{t-2} + \cdots + S_2 x + S_1 &lt;/math&gt;

:&lt;math&gt; \Lambda(x) = \Lambda_{e} x^{e} + \Lambda_{e-1} x^{e-1} + \cdots + \Lambda_{1} x + 1&lt;/math&gt;

:&lt;math&gt; \Omega(x) = \Omega_{e} x^{e} + \Omega_{e-1} x^{e-1} + \cdots + \Omega_{1} x + \Omega_{0}&lt;/math&gt;

The key equation is:

:&lt;math&gt; \Lambda(x) S(x) = Q(x) x^{t} + \Omega(x) &lt;/math&gt;

For ''t'' = 6 and ''e'' = 3:

:&lt;math&gt;\begin{bmatrix}
\Lambda_3 S_6 &amp; x^8 \\
\Lambda_2 S_6 + \Lambda_3 S_5 &amp; x^7  \\
\Lambda_1 S_6 + \Lambda_2 S_5 + \Lambda_3 S_4 &amp; x^6 \\
          S_6 + \Lambda_1 S_5 + \Lambda_2 S_4 + \Lambda_3 S_3 &amp; x^5 \\
          S_5 + \Lambda_1 S_4 + \Lambda_2 S_3 + \Lambda_3 S_2 &amp; x^4 \\
          S_4 + \Lambda_1 S_3 + \Lambda_2 S_2 + \Lambda_3 S_1 &amp; x^3 \\
          S_3 + \Lambda_1 S_2 + \Lambda_2 S_1 &amp; x^2 \\
          S_2 + \Lambda_1 S_1 &amp; x \\
          S_1 &amp;  \\
\end{bmatrix}
=
\begin{bmatrix}
Q_2 x^8 \\
Q_1 x^7 \\
Q_0 x^6 \\
0 \\
0 \\
0 \\
\Omega_2 x^2 \\
\Omega_1 x \\
\Omega_0 \\
\end{bmatrix}
&lt;/math&gt;

The middle terms are zero due to the relationship between Λ and syndromes.

The extended Euclidean algorithm can find a series of polynomials of the form

A&lt;sub&gt;i&lt;/sub&gt;(x) S(x) + B&lt;sub&gt;i&lt;/sub&gt;(x) x&lt;sup&gt;t&lt;/sup&gt; = R&lt;sub&gt;i&lt;/sub&gt;(x)

where the degree of R decreases as i increases. Once the degree of R&lt;sub&gt;i&lt;/sub&gt;(x) &lt; t/2, then

A&lt;sub&gt;i&lt;/sub&gt;(x) = Λ(x)

B&lt;sub&gt;i&lt;/sub&gt;(x) = -Q(x)

R&lt;sub&gt;i&lt;/sub&gt;(x) = Ω(x).

B(x) and Q(x) don't need to be saved, so the algorithm becomes:

:R&lt;sub&gt;−1&lt;/sub&gt; = x&lt;sup&gt;t&lt;/sup&gt;
:R&lt;sub&gt;0&lt;/sub&gt; = S(x)
:A&lt;sub&gt;−1&lt;/sub&gt; = 0
:A&lt;sub&gt;0&lt;/sub&gt; = 1
:i = 0
:while degree of R&lt;sub&gt;i&lt;/sub&gt; &gt;= t/2
::i = i + 1
::Q = R&lt;sub&gt;i-2&lt;/sub&gt; / R&lt;sub&gt;i-1&lt;/sub&gt;
::R&lt;sub&gt;i&lt;/sub&gt; = R&lt;sub&gt;i-2&lt;/sub&gt; - Q R&lt;sub&gt;i-1&lt;/sub&gt;
::A&lt;sub&gt;i&lt;/sub&gt; = A&lt;sub&gt;i-2&lt;/sub&gt; - Q A&lt;sub&gt;i-1&lt;/sub&gt; 
to set low order term of Λ(x) to 1, divide Λ(x) and Ω(x) by A&lt;sub&gt;i&lt;/sub&gt;(0):
:Λ(x) = A&lt;sub&gt;i&lt;/sub&gt; / A&lt;sub&gt;i&lt;/sub&gt;(0)
:Ω(x) = R&lt;sub&gt;i&lt;/sub&gt; / A&lt;sub&gt;i&lt;/sub&gt;(0)

A&lt;sub&gt;i&lt;/sub&gt;(0) is the constant (low order) term of A&lt;sub&gt;i&lt;/sub&gt;.

==== Example ====

Using the same data as the Peterson Gorenstein Zierler example above:

{| class="wikitable"
|-
! ''i''
! R&lt;sub&gt;''i''&lt;/sub&gt;
! A&lt;sub&gt;''i''&lt;/sub&gt;
|-
| -1
| 001 x&lt;sup&gt;4&lt;/sup&gt; + 000 x&lt;sup&gt;3&lt;/sup&gt; + 000 x&lt;sup&gt;2&lt;/sup&gt; + 000 x + 000
| 000
|-
| 0
| 925 x&lt;sup&gt;3&lt;/sup&gt; + 762 x&lt;sup&gt;2&lt;/sup&gt; + 637 x + 732
| 001
|-
| 1
| 683 x&lt;sup&gt;2&lt;/sup&gt; + 676 x + 024
| 697 x + 396 
|-
| 2
| 673 x + 596
| 608 x&lt;sup&gt;2&lt;/sup&gt; + 704 x + 544 
|-
|}

:Λ(x) = A&lt;sub&gt;2&lt;/sub&gt; / 544 = 329 x&lt;sup&gt;2&lt;/sup&gt; + 821 x + 001 
:Ω(x) =  R&lt;sub&gt;2&lt;/sub&gt; / 544 = 546 x + 732

=== Decoder using discrete Fourier transform ===

A discrete Fourier transform can be used for decoding.&lt;ref&gt;Shu Lin and Daniel J. Costello Jr, "Error Control Coding" second edition, pp. 255-262, 1982, 2004&lt;/ref&gt;  To avoid conflict with syndrome names, let c(x) = s(x) the encoded codeword. r(x) and e(x) are the same as above. Define C(x), E(x), and R(x) as the discrete Fourier transforms of c(x), e(x), and r(x). Since r(x) = c(x) + e(x), and since a discrete Fourier transform is a linear operator, R(x) = C(x) + E(x).

Transform r(x) to R(x) using discrete Fourier transform. Since the calculation for a discrete Fourier transform is the same as the calculation for syndromes, t coefficients of R(x) and E(x) are the same as the syndromes:

:&lt;math&gt;R_j = E_j = S_j = r(\alpha^j)&lt;/math&gt;
:&lt;math&gt;for \ 1 \le j \le t&lt;/math&gt;

Use &lt;math&gt;R_1&lt;/math&gt; through &lt;math&gt;R_t&lt;/math&gt; as syndromes (they're the same) and generate the error locator polynomial using the methods from any of the above decoders.

Let v = number of errors. Generate E(x) using the known coefficients &lt;math&gt;E_1&lt;/math&gt; to &lt;math&gt;E_t&lt;/math&gt;, the error locator polynomial, and these formulas

:&lt;math&gt;E_0 = - \frac{1}{\Lambda_v}(E_{v} + \Lambda_1 E_{v-1} + \cdots + \Lambda_{v-1} E_{1})&lt;/math&gt;
:&lt;math&gt;E_j = -(\Lambda_1 E_{j-1} + \Lambda_2 E_{j-2} + \cdots + \Lambda_v E_{j-v})&lt;/math&gt;
:&lt;math&gt;for \  t &lt; j &lt; n&lt;/math&gt;

Then calculate C(x) = R(x) - E(x) and take the inverse transform (polynomial interpolation) of C(x) to produce c(x).

===Decoding beyond the error-correction bound===

The [[Singleton bound]] states that the minimum distance ''d'' of a linear block code of size (''n'',''k'') is upper-bounded by ''n''&amp;nbsp;&amp;minus;&amp;nbsp;''k''&amp;nbsp;+&amp;nbsp;1. The distance ''d'' was usually understood to limit the error-correction capability to ⌊''d''/2⌋. The Reed–Solomon code achieves this bound with equality, and can thus correct up to ⌊(''n''&amp;nbsp;&amp;minus;&amp;nbsp;''k''&amp;nbsp;+&amp;nbsp;1)/2⌋ errors. However, this error-correction bound is not exact.

In 1999, [[Madhu Sudan]] and [[Venkatesan Guruswami]] at MIT published "Improved Decoding of Reed–Solomon and Algebraic-Geometry Codes" introducing an algorithm that allowed for the correction of errors beyond half the minimum distance of the code.&lt;ref&gt;{{Citation |first=V. |last=Guruswami |first2=M. |last2=Sudan |title=Improved decoding of Reed–Solomon codes and algebraic geometry codes |journal=[[IEEE Transactions on Information Theory]] |volume=45 |issue=6 |pages=1757&amp;ndash;1767 |date=September 1999 |doi=10.1109/18.782097 }}&lt;/ref&gt; It applies to Reed–Solomon codes and more generally to [[algebraic geometric code]]s. This algorithm produces a list of codewords (it is a [[list-decoding]] algorithm) and is based on interpolation and factorization of polynomials over &lt;math&gt;GF(2^m)&lt;/math&gt; and its extensions.

===Soft-decoding===

The algebraic decoding methods described above are hard-decision methods, which means that for every symbol a hard decision is made about its value.  For example, a decoder could associate with each symbol an additional value corresponding to the channel [[demodulator]]'s confidence in the correctness of the symbol. The advent of [[low-density parity-check code|LDPC]] and [[turbo code]]s, which employ iterated [[soft-decision decoding|soft-decision]] belief propagation decoding methods to achieve error-correction performance close to the [[Shannon limit|theoretical limit]], has spurred interest in applying soft-decision decoding to conventional algebraic codes. In 2003, Ralf Koetter and [[Alexander Vardy]] presented a polynomial-time soft-decision algebraic list-decoding algorithm for Reed–Solomon codes, which was based upon the work by Sudan and Guruswami.&lt;ref&gt;{{cite journal | first1=Ralf | last1=Koetter | first2=Alexander | last2=Vardy | title=Algebraic soft-decision decoding of Reed–Solomon codes | journal=[[IEEE Transactions on Information Theory]] | volume=49 | issue=11 | year=2003 | pages=2809–2825 | doi=10.1109/TIT.2003.819332}}&lt;/ref&gt;
In 2016,  Steven J. Franke and Joseph H. Taylor published a novel soft-decision decoder.&lt;ref&gt;{{cite journal | first1=Steven J. | last1=Franke | first2=Joseph H. | last2=Taylor | title=Open Source Soft-Decision Decoder for the JT65 (63,12) Reed–Solomon Code | journal=QEX | volume= | issue=May/June | year=2016 | pages=8–17 | url=http://physics.princeton.edu/pulsar/K1JT/FrankeTaylor_QEX_2016.pdf}}&lt;/ref&gt;

=== Matlab Example ===

==== Encoder ====
Here we present a simple Matlab implementation for an encoder.
&lt;source lang="matlab"&gt;
function [ encoded ] = rsEncoder( msg, m, prim_poly, n, k )
    %RSENCODER Encode message with the Reed-Solomon algorithm
    % m is the number of bits per symbol
    % prim_poly: Primitive polynomial p(x). Ie for DM is 301
    % k is the size of the message
    % n is the total size (k+redundant)
    % Example: msg = uint8('Test')
    % enc_msg = rsEncoder(msg, 8, 301, 12, numel(msg));
    
    % Get the alpha
    alpha = gf(2, m, prim_poly);
    
    % Get the Reed-Solomon generating polynomial g(x)
    g_x = genpoly(k, n, alpha);
    
    % Multiply the information by X^(n-k), or just pad with zeros at the end to
    % get space to add the redundant information
    msg_padded = gf([msg zeros(1, n-k)], m, prim_poly);
    
    % Get the remainder of the division of the extended message by the 
    % Reed-Solomon generating polynomial g(x)
    [~, remainder] = deconv(msg_padded, g_x);

    % Now return the message with the redundant information
    encoded = msg_padded - remainder;

end

% Find the Reed-Solomon generating polynomial g(x), by the way this is the
% same as the rsgenpoly function on matlab
function g = genpoly(k, n, alpha)
    g = 1;
    % A multiplication on the galois field is just a convolution
    for k = mod(1 : n-k, n)
        g = conv(g, [1 alpha .^ (k)]);
    end
end

&lt;/source&gt;

==== Decoder ====
Now the decoding part:
&lt;source lang="matlab"&gt;
function [ decoded, error_pos, error_mag, g, S ] = rsDecoder( encoded, m, prim_poly, n, k )
    %RSDECODER Decode a Reed-Solomon encoded message
    %   Example:
    % [dec, ~, ~, ~, ~] = rsDecoder(enc_msg, 8, 301, 12, numel(msg))
    max_errors = floor((n-k)/2);
    orig_vals = encoded.x;
    % Initialize the error vector
    errors = zeros(1, n);
    g = [];
    S = [];
    
    % Get the alpha
    alpha = gf(2, m, prim_poly);
    
    % Find the syndromes (Check if dividing the message by the generator
    % polynomial the result is zero)
    Synd = polyval(encoded, alpha .^ (1:n-k));
    Syndromes = trim(Synd);
    
    % If all syndromes are zeros (perfectly divisible) there are no errors
    if isempty(Syndromes.x)
        decoded = orig_vals(1:k);
        error_pos = [];
        error_mag = [];
        g = [];
        S = Synd;
        return;
    end
    
    % Prepare for the euclidean algorithm (Used to find the error locating
    % polynomials)
    r0 = [1, zeros(1, 2*max_errors)]; r0 = gf(r0, m, prim_poly); r0 = trim(r0);
    size_r0 = length(r0);
    r1 = Syndromes;
    f0 = gf([zeros(1, size_r0-1) 1], m, prim_poly);
    f1 = gf(zeros(1, size_r0), m, prim_poly);
    g0 = f1; g1 = f0;
    
    % Do the euclidean algorithm on the polynomials r0(x) and Syndromes(x) in
    % order to find the error locating polynomial
    while true
        % Do a long division
        [quotient, remainder] = deconv(r0, r1);    
        % Add some zeros
        quotient = pad(quotient, length(g1));
        
        % Find quotient*g1 and pad
        c = conv(quotient, g1);
        c = trim(c);
        c = pad(c, length(g0));
        
        % Update g as g0-quotient*g1
        g = g0 - c;
        
        % Check if the degree of remainder(x) is less than max_errors
        if all(remainder(1:end - max_errors) == 0)
            break;
        end
        
        % Update r0, r1, g0, g1 and remove leading zeros
        r0 = trim(r1); r1 = trim(remainder);
        g0 = g1; g1 = g;
    end
    
    % Remove leading zeros
    g = trim(g);
    
    % Find the zeros of the error polynomial on this galois field
    evalPoly = polyval(g, alpha .^ (n-1 : -1 : 0));
    error_pos = gf(find(evalPoly == 0), m);
    
    % If no error position is found we return the received work, because
    % basically is nothing that we could do and we return the received message
    if isempty(error_pos)
        decoded = orig_vals(1:k);
        error_mag = [];
        return;
    end
    
    % Prepare a linear system to solve the error polynomial and find the error
    % magnitudes
    size_error = length(error_pos);
    Syndrome_Vals = Syndromes.x;
    b(:, 1) = Syndrome_Vals(1:size_error);
    for idx = 1 : size_error
        e = alpha .^ (idx*(n-error_pos.x));
        err = e.x;
        er(idx, :) = err;
    end
    
    % Solve the linear system
    error_mag = (gf(er, m, prim_poly) \ gf(b, m, prim_poly))';
    % Put the error magnitude on the error vector
    errors(error_pos.x) = error_mag.x;
    % Bring this vector to the galois field
    errors_gf = gf(errors, m, prim_poly);
    
    % Now to fix the errors just add with the encoded code
    decoded_gf = encoded(1:k) + errors_gf(1:k);
    decoded = decoded_gf.x;
    
end

% Remove leading zeros from galois array
function gt = trim(g)
    gx = g.x;
    gt = gf(gx(find(gx, 1) : end), g.m, g.prim_poly);
end

% Add leading zeros
function xpad = pad(x,k)
    len = length(x);
    if (len&lt;k)
        xpad = [zeros(1, k-len) x];
    end
end
&lt;/source&gt;

==See also==
* [[BCH code]]
* [[Cyclic code]]
* [[Chien search]]
* [[Berlekamp&amp;ndash;Massey algorithm]]
* [[Forward error correction]]
* [[Berlekamp–Welch algorithm]]
* [[Folded Reed–Solomon code]]

==Notes==
{{Reflist|30em}}

==References==
*{{Citation
 |last= Gill
 |first= John
 |title= EE387 Notes #7, Handout #28
 |date= n.d.
 |accessdate= April 21, 2010
 |publisher= Stanford University
 |url= http://www.stanford.edu/class/ee387/handouts/notes7.pdf
 |doi= 
 |deadurl= yes
 |archiveurl= https://web.archive.org/web/20140630172526/http://web.stanford.edu/class/ee387/handouts/notes7.pdf
 |archivedate= June 30, 2014
 |df= 
 }}
*{{Citation
 |last= Hong
 |first= Jonathan
 |authorlink=
 |last2= Vetterli
 |first2= Martin
 |title= Simple Algorithms for BCH Decoding
 |journal= IEEE Transactions on Communications
 |date= August 1995
 |volume= 43
 |issue= 8
 |pages= 2324&amp;ndash;2333
 |url=
 https://infoscience.epfl.ch/record/33884/files/HongV95.pdf|doi= 10.1109/26.403765}}
*{{Citation
 |ref={{harvid|Lin|Costello|1983}}
 |first1=Shu
 |last1=Lin
 |first2=Daniel J.
 |last2=Costello, Jr.
 |title=Error Control Coding: Fundamentals and Applications
 |location=New Jersey, NJ
 |publisher=Prentice-Hall
 |year=1983
 |isbn=0-13-283796-X
}}
*{{Citation
 |first= J. L.
 |last= Massey
 |authorlink= James Massey
 |title= Shift-register synthesis and BCH decoding
 |journal= [[IEEE Transactions on Information Theory]]
 |volume= IT-15
 |issue= 1
 |year= 1969
 |pages= 122–127
 |doi=  10.1109/tit.1969.1054260
 |url= http://crypto.stanford.edu/~mironov/cs359/massey.pdf}}
*{{Citation
 |last= Peterson
 |first= Wesley W.
 |authorlink=Wesley Peterson
 |title= Encoding and Error Correction Procedures for the Bose-Chaudhuri Codes
 |year= 1960
 |publisher= Institute of Radio Engineers
 |journal= IRE Transactions on Information Theory
 |volume=IT-6
 |issue=
 |pages=459–470}}
*{{Citation
 |last= Reed 
 |first= Irving S.
 |authorlink= Irving S. Reed
 |last2= Solomon
 |first2= Gustave
 |authorlink2= Gustave Solomon
 |title= Polynomial Codes over Certain Finite Fields
 |journal= Journal of the Society for Industrial and Applied Mathematics ([[Society for Industrial and Applied Mathematics|SIAM]])
 |volume= 8
 |issue= 2
 |pages= 300–304
 |year= 1960
 |url=
 |doi=10.1137/0108018}}
*{{Citation
 |last= Welch
 |first= L. R.
 |title= The Original View of Reed–Solomon Codes
 |series=Lecture Notes
 |year= 1997
 |url= http://csi.usc.edu/PDF/RSoriginal.pdf
 |doi= }}

==Further reading==
*{{Citation
 |last= Berlekamp
 |first= Elwyn R.
 |authorlink= Elwyn Berlekamp
 |title= Nonbinary BCH decoding
 |year= 1967
 |series= International Symposium on Information Theory
 |place= San Remo, Italy}}
*{{Citation
 |last= Berlekamp
 |first= Elwyn R.
 |authorlink= Elwyn Berlekamp
 |title= Algebraic Coding Theory
 |place= Laguna Hills, CA
 |origyear= 1968
 |year= 1984
 |edition= Revised
 |publisher= Aegean Park Press
 |isbn=0-89412-063-8}}
*{{Citation
 |last= Cipra
 |first= Barry A.
 |author-link = Barry A. Cipra
 |title=The Ubiquitous Reed–Solomon Codes
 |journal=[[Society for Industrial and Applied Mathematics|SIAM]] News
 |volume=26
 |issue=1
 |year=1993
 |url=http://www.eccpage.com/reed_solomon_codes.html}}
*{{Citation
 |first= G.
 |last= Forney, Jr.
 |authorlink=Dave Forney
 |title= On Decoding BCH Codes
 |journal= [[IEEE Transactions on Information Theory]]
 |volume= 11
 |issue= 4
 |date= October 1965
 |pages= 549–557
 |doi= 10.1109/TIT.1965.1053825}}
*{{Citation
 |last= Koetter
 |first= Ralf
 |title= Reed–Solomon Codes
 |series= MIT Lecture Notes 6.451 (Video)
 |year= 2005
 |url= http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-451-principles-of-digital-communication-ii-spring-2005/lecture-notes/lecture-10-reed-solomon-codes/
 |doi= 
 |deadurl= yes
 |archiveurl= https://web.archive.org/web/20130313033107/http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-451-principles-of-digital-communication-ii-spring-2005/lecture-notes/lecture-10-reed-solomon-codes/
 |archivedate= 2013-03-13
 |df= 
 }}
*{{Citation
 |first= F. J.
 |last=MacWilliams
 |first2= N. J. A.
 |last2= Sloane
 |authorlink2= N. J. A. Sloane
 |title= The Theory of Error-Correcting Codes
 |location= New York, NY
 |publisher= North-Holland Publishing Company
 |year= 1977
 |isbn=
 |doi=}} 
*{{Citation
 |first= Irving S.
 |last= Reed
 |authorlink= Irving S. Reed
 |first2= Xuemin
 |last2= Chen
 |title= Error-Control Coding for Data Networks
 |location= Boston, MA
 |publisher= Kluwer Academic Publishers
 |year= 1999
 |isbn=
 |doi=}}

==External links==

===Information and Tutorials===
* [http://www.cs.cmu.edu/~guyb/realworld/reedsolomon/reed_solomon_codes.html Introduction to Reed–Solomon codes: principles, architecture and implementation] (CMU)
* [http://www.cs.utk.edu/%7Eplank/plank/papers/SPE-9-97.html A Tutorial on Reed–Solomon Coding for Fault-Tolerance in RAID-like Systems]
* [http://sidewords.files.wordpress.com/2007/12/thesis.pdf Algebraic soft-decoding of Reed–Solomon codes]
* Wikiversity: [[Wikiversity:Reed–Solomon codes for coders|Reed–Solomon codes for coders]]
* [http://www.bbc.co.uk/rd/pubs/whp/whp031.shtml BBC R&amp;D White Paper WHP031]
*{{Citation
 |last= Geisel
 |first= William A.
 |title= Tutorial on Reed–Solomon Error Correction Coding
 |date= August 1990
 |url= https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19900019023_1990019023.pdf
 |publisher= [[NASA]]
 |series= Technical Memorandum
 |id= TM-102162
 |doi=}}
*{{Citation
 |last= Gao
 |first= Shuhong
 |title= New Algorithm For Decoding Reed-Solomon Codes
 |date= January 2002
 |url= http://www.math.clemson.edu/~sgao/papers/RS.pdf
 |publisher= Clemson
 |series=
 |id=
 |doi=}}

===Implementations===
* [http://www.schifra.com Schifra Open Source C++ Reed–Solomon Codec]
* [http://rscode.sourceforge.net/ Henry Minsky's RSCode library, Reed–Solomon encoder/decoder]
* [https://code.google.com/p/rssoft/ Open Source C++ Reed–Solomon Soft Decoding library]
* [http://dept.ee.wits.ac.za/~versfeld/research_resources/sourcecode/Errors_And_Erasures_Test.zip Matlab implementation of errors and-erasures Reed–Solomon decoding]
* [https://pypi.python.org/pypi/reedsolo Pure-Python implementation of a Reed–Solomon codec]

{{DEFAULTSORT:Reed-Solomon error correction}}
[[Category:Error detection and correction]]
[[Category:Coding theory]]</text>
      <sha1>9s13yvx5d3bdw5d5we8d5ojw81c5zo6</sha1>
    </revision>
  </page>
  <page>
    <title>Robert Goldblatt</title>
    <ns>0</ns>
    <id>31375187</id>
    <revision>
      <id>863320511</id>
      <parentid>851458808</parentid>
      <timestamp>2018-10-10T01:32:35Z</timestamp>
      <contributor>
        <username>Robertian</username>
        <id>3702572</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3909">'''Robert Ian Goldblatt''' (born 1949) is a [[mathematical logic]]ian who is Emeritus Professor in the School of Mathematics and  Statistics at [[Victoria University of Wellington|Victoria University]], [[Wellington]], [[New Zealand]]. His most popular books are ''Logics of Time and Computation'' and ''Topoi: the Categorial Analysis of Logic''. He has also written a graduate level textbook on [[hyperreal number]]s which is an introduction to [[nonstandard analysis]].

He has been Coordinating Editor of The ''[[Journal of Symbolic Logic]]'' and a Managing Editor of ''[[Studia Logica]]''.
He was elected Fellow and Councillor of the [[Royal Society of New Zealand]], President of the [[New Zealand Mathematical Society]], and represented New Zealand to the [[International Mathematical Union]].
In 2012 he was awarded the 
[https://royalsociety.org.nz/what-we-do/medals-and-awards/jones-medal/ Jones Medal] for lifetime achievement in mathematics.

==Books and handbook chapters==
* 1979: ''[[Topoi]]: The Categorial Analysis of Logic'', North-Holland. Revised edition 1984. [[Dover Publications]] edition 2006. [https://projecteuclid.org/euclid.bia/1403013939 Internet edition], Project Euclid.
:: [[Benjamin C. Pierce]] recommends it as an "excellent beginner book", praising it for the use of simple set-theoretic examples and motivating intuitions, but noted that it "is sometimes criticized by category theorists for being misleading on some aspects of the subject, and for presenting long and difficult proofs where simple ones are available."&lt;ref name="Pierce1991"&gt;{{cite book|author=Benjamin C. Pierce|title=Basic category theory for computer scientists|url=https://books.google.com/books?id=ezdeaHfpYPwC&amp;pg=PA73|year=1991|publisher=[[MIT Press]]|isbn=978-0-262-66071-6|page=73}}&lt;/ref&gt;  But the preface of the Dover edition observes (p. xv) that "This is a book about logic, rather than category theory per se. It aims to explain, in an introductory way, how certain logical ideas are illuminated by a category-theoretic perspective."
* 1982: ''Axiomatising The Logic of Computer Programming'', Lecture Notes in Computer Science 130, Springer-Verlag.
* 1987: ''Orthogonality and Spacetime Geometry'', Universitext Springer-Verlag {{ISBN|0-387-96519-X}} {{mr|id=0888161}}
* 1987: ''Logics of Time and Computation''. CSLI Lecture Notes, 7. [[Stanford University]], [[Center for the Study of Language and Information]] {{mr|id=1191162}}. Second edition 1992.
* 1993: ''Mathematics of Modality'', [[CSLI Publications]], {{ISBN|978-1-881526-24-7}} {{mr|id=1317099}}
* 1998: ''Lectures on the Hyperreals: An Introduction to Nonstandard Analysis.'' [[Graduate Texts in Mathematics]], 188. Springer-Verlag.
::Reviewer Perry Smith for [[MathSciNet]] [http://ams.rice.edu/mathscinet-getitem?mr=1643950 wrote]: "The author's ideas on how to achieve both intelligibility and rigor, explained in the preface, will be useful reading for anyone intending to teach nonstandard analysis."
* 2006: "Mathematical Modal Logic: a View of its Evolution" in ''Modalities in the Twentieth Century'', Volume 7 of the ''Handbook of the History of Logic'', edited by [[Dov M. Gabbay]] and [[John Woods (logician)|John Woods]], [[Elsevier]], pp.&amp;nbsp;1–98.
* 2011: ''Quantifiers, Propositions and Identity: Admissible Semantics for Quantified Modal and Substructural Logics'', Cambridge University Press and the Association for Symbolic Logic.
 
==See also==
*[[Influence of non-standard analysis]]

==References==
{{reflist}}

==External links==
*[http://homepages.ecs.vuw.ac.nz/~rob/ Home page]

* {{MathGenealogy|id=123744}}

{{Authority control}}

{{DEFAULTSORT:Goldblatt, Robert}}
[[Category:Living people]]
[[Category:New Zealand mathematicians]]
[[Category:Mathematical logicians]]
[[Category:Victoria University of Wellington alumni]]
[[Category:Victoria University of Wellington faculty]]
[[Category:1949 births]]</text>
      <sha1>f53tzjjg224sc739gdh4tnn043sehi9</sha1>
    </revision>
  </page>
  <page>
    <title>Skew partition</title>
    <ns>0</ns>
    <id>36707156</id>
    <revision>
      <id>841538200</id>
      <parentid>683711222</parentid>
      <timestamp>2018-05-16T13:07:11Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14815">[[File:Skew partition.svg|thumb|240px|A skew partition of a [[chordal graph]]. On the left side of the partition, the top and bottom parts are disconnected from each other. On the right side of the partition, all possible edges from top to bottom exist, forming a graph whose complement is disconnected.]]
In [[graph theory]], a '''skew partition''' of a graph is a [[Partition of a set|partition]] of its vertices into two subsets, such that the [[induced subgraph]] formed by one of the two subsets is [[connected graph|disconnected]] and the induced subgraph formed by the other subset is the [[complement graph|complement]] of a disconnected graph. Skew partitions play an important role in the theory of [[perfect graph]]s.

==Definition==
A skew partition of a graph &lt;math&gt;G&lt;/math&gt; is a partition of its vertices into two subsets &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; for which the induced subgraph &lt;math&gt;G[X]&lt;/math&gt; is disconnected and the induced subgraph &lt;math&gt;G[Y]&lt;/math&gt; is the complement of a disconnected graph (co-disconnected).
Equivalently, a skew partition of a graph &lt;math&gt;G&lt;/math&gt; may be described by a partition of the vertices of  &lt;math&gt;G&lt;/math&gt; into four subsets &lt;math&gt;A&lt;/math&gt;, &lt;math&gt;B&lt;/math&gt;, &lt;math&gt;C&lt;/math&gt;, and &lt;math&gt;D&lt;/math&gt;, such that there are no edges from &lt;math&gt;A&lt;/math&gt; to &lt;math&gt;B&lt;/math&gt; and such that all possible edges from &lt;math&gt;C&lt;/math&gt; to &lt;math&gt;D&lt;/math&gt; exist; for such a partition, the induced subgraphs &lt;math&gt;G[A\cup B]&lt;/math&gt; and &lt;math&gt;G[C\cup D]&lt;/math&gt; are disconnected and co-disconnected respectively, so we may take &lt;math&gt;X=A\cup B&lt;/math&gt; and &lt;math&gt;Y=C\cup D&lt;/math&gt;.

==Examples==
Every [[path graph]] with four or more vertices has a skew partition, in which the co-disconnected set &lt;math&gt;Y&lt;/math&gt; is one of the interior edges of the path and the disconnected set &lt;math&gt;X&lt;/math&gt; consists of the vertices on either side of this edge. However, it is not possible for a [[cycle graph]] of any length to have a skew partition: no matter which subsets of the cycle are chosen as the set &lt;math&gt;X&lt;/math&gt;, the complementary set &lt;math&gt;Y&lt;/math&gt; will have the same number of connected components, so it is not possible for &lt;math&gt;X&lt;/math&gt; to be disconnected and &lt;math&gt;Y&lt;/math&gt; to be co-disconnected.

If a graph has a skew partition, so does its [[complement graph|complement]]. For instance, the complements of path graphs have skew partitions, and the complements of cycle graphs do not.

==Special cases==
If a graph is itself disconnected, then with only three simple exceptions (an [[empty graph]], a graph with one edge and three vertices, or a four-vertex [[perfect matching]]) it has a skew partition, in which the co-disconnected side of the partition consists of the endpoints of a single edge and the disconnected side consists of all other vertices. For the same reason, if the complement of a graph is disconnected, then with a corresponding set of three exceptions it must have a skew partition.&lt;ref name="r08"&gt;{{harvtxt|Reed|2008}}.&lt;/ref&gt;

If a graph has a [[clique (graph theory)|clique]] [[vertex separator|separator]] (a clique whose removal would disconnect the remaining vertices) with more than one vertex, then the partition into the clique and the remaining vertices forms a skew partition. A clique cutset with one vertex is an [[Biconnected component|articulation point]]; if such a vertex exists, then with a small number of simple exceptions, there is a skew partition in which the co-disconnected side consists of this vertex and one of its neighbors.&lt;ref name="r08"/&gt;

A ''star cutset'' in a graph &lt;math&gt;G&lt;/math&gt; is a [[vertex separator]] in which one of the separator vertices is adjacent to all the others. Every clique separator is a star cutset. Necessarily, a graph with a star cutset (with more than one vertex) has a skew partition in which the co-disconnected subgraph consists of the vertices in the star cutset and the disconnected subgraph consists of all the remaining vertices.&lt;ref name="r08"/&gt;

A [[Modular decomposition|module]] (or homogeneous set) is a nontrivial subset &lt;math&gt;H&lt;/math&gt; of the vertices of &lt;math&gt;G&lt;/math&gt; such that, for every vertex &lt;math&gt;v&lt;/math&gt; that is not in &lt;math&gt;H&lt;/math&gt;, either &lt;math&gt;v&lt;/math&gt; is adjacent to all vertices in &lt;math&gt;H&lt;/math&gt; or to none of them. If a graph &lt;math&gt;G&lt;/math&gt; has a module &lt;math&gt;H&lt;/math&gt; and, outside it, there exist both vertices adjacent to all vertices in &lt;math&gt;H&lt;/math&gt; and other vertices adjacent to none of them, then &lt;math&gt;G&lt;/math&gt; has a star cutset consisting of one vertex in the module together with its neighbors outside the module. On the other hand, if there exists a module in which one of these two subsets is empty, then the graph is disconnected or co-disconnected and again (with the three simple exceptions) it has a skew cutset.&lt;ref name="r08"/&gt;

==History==
Skew partitions were introduced by {{harvtxt|Chvátal|1985}}, in connection with [[perfect graph]]s. Chvátal proved that a minimally imperfect graph could not have a star cutset. Trivially, disconnected graphs cannot be minimally imperfect, and it was also known that graphs with clique separators or modules could not be minimally imperfect.&lt;ref&gt;{{harvtxt|Reed|2008}}. The nonexistence of modules in minimally imperfect graphs was used by {{harvtxt|Lovász|1972}} in his proof of the [[perfect graph theorem|weak perfect graph theorem]].&lt;/ref&gt; [[Claude Berge]] had conjectured in the early 1960s that perfect graphs were the same as the Berge graphs, graphs with no induced odd cycle (of length five or more) or its complement, and (because cycles and their complements do not have skew partitions) no minimal non-Berge graph can have a skew partition. Motivated by these results, Chvátal conjectured that no minimally imperfect graph could have a skew partition. Several authors proved special cases of this conjecture, but it remained unsolved for many years.&lt;ref&gt;See {{harvtxt|Cornuéjols|Reed|1993}} for the case in which the co-disconnected side of the partition is multipartite, and {{harvtxt|Roussel|Rubio|2001}} for the case in which one of the two parts of the co-disconnected side is independent.&lt;/ref&gt;

Skew partitions gained significance when they were used by {{harvtxt|Chudnovsky|Robertson|Seymour|Thomas|2006}} to prove the [[strong perfect graph theorem]] that the Berge graphs are indeed the same as the perfect graphs. Chudnovsky et al. were unable to prove Chvátal's conjecture directly, but instead proved a weaker result, that a minimal counterexample to the theorem (if it existed) could not have a balanced skew partition, a skew partition in which every [[induced path]] with endpoints on one side of the partition and interior vertices on the other side has even length. This result formed a key lemma in their proof, and the full version of Chvátal's lemma follows from their theorem.&lt;ref&gt;{{harvtxt|Seymour|2006}}.&lt;/ref&gt;

==In structural graph theory==
Skew partitions form one of the key components of a structural decomposition of perfect graphs used by {{harvtxt|Chudnovsky|Robertson|Seymour|Thomas|2006}} as part of their proof of the strong perfect graph theorem. Chudnovsky et al. showed that every perfect graph either belongs to one of five basic classes of perfect graphs, or it has one of four types of decomposition into simpler graphs, one of which is a skew partition.

A simpler example of a structural decomposition using skew partitions is given by {{harvtxt|Seymour|2006}}. He observes that every [[comparability graph]] is [[complete graph|complete]], is [[bipartite graph|bipartite]], or has a skew partition. For, if every element of a [[partially ordered set]] is either a [[minimal element]] or a maximal element, then the corresponding comparability graph is bipartite. If the ordering is a [[total order]], then the corresponding comparability graph is complete. If neither of these two cases arise, but every element that is neither minimal nor maximal is comparable to all other elements, then either the partition into the minimal and non-minimal elements (if there is more than one minimal element) or the partition into the maximal and non-maximal elements (if there is more than one maximal element) forms a star cutset. And in the remaining case, there exists an element &lt;math&gt;x&lt;/math&gt; of the partial order that is not minimal, not maximal, and not comparable with all other elements; in this case, there is a skew partition (the complement of a star cutset) in which the co-disconnected side consists of the elements comparable to &lt;math&gt;x&lt;/math&gt; (not including &lt;math&gt;x&lt;/math&gt; itself) and the disconnected side consists of the remaining elements.

The [[chordal graph]]s have an even simpler decomposition of a similar type: they are either complete or they have a clique separator.
{{harvtxt|Hayward|1985}} showed, analogously, that every connected and co-connected weakly chordal graph (a graph with no induced cycle or its complement of length greater than four) with four or more vertices has a star cutset or its complement, from which it follows by Chvátal's lemma that every such graph is perfect.

==Algorithms and complexity==
A skew partition of a given graph, if it exists, may be found in [[polynomial time]]. This was originally shown by {{harvtxt|de Figueiredo|Klein|Kohayakawa|Reed|2000}} but with an impractically large running time of &lt;math&gt;O(n^{101})&lt;/math&gt;, where &lt;math&gt;n&lt;/math&gt; is the number of vertices in the input graph. {{harvtxt|Kennedy|Reed|2008}} improved the running time to &lt;math&gt;O(n^4m)&lt;/math&gt;; here &lt;math&gt;m&lt;/math&gt; is the number of input edges.

It is [[NP-complete]] to test whether a graph contains a skew partition in which one of the parts of the co-disconnected side is independent.&lt;ref&gt;{{harvtxt|Dantas|de Figueiredo|Klein|Gravier|2004}}.&lt;/ref&gt;
Testing whether a given graph contains a balanced skew partition is also NP-complete in arbitrary graphs, but may be solved in polynomial time in perfect graphs.&lt;ref&gt;{{harvtxt|Trotignon|2008}}.&lt;/ref&gt;

==Notes==
{{reflist|colwidth=30em}}

==References==
{{refbegin|colwidth=30em}}
*{{citation
 | last1 = Chudnovsky | first1 = Maria | author1-link = Maria Chudnovsky
 | last2 = Robertson | first2 = Neil | author2-link = Neil Robertson (mathematician)
 | last3 = Seymour | first3 = Paul | author3-link = Paul Seymour (mathematician)
 | last4 = Thomas | first4 = Robin | author4-link = Robin Thomas (mathematician)
 | doi = 10.4007/annals.2006.164.51
 | issue = 1
 | journal = [[Annals of Mathematics]]
 | pages = 51–229
 | title = The strong perfect graph theorem
 | url = http://annals.princeton.edu/annals/2006/164-1/p02.xhtml
 | volume = 164
 | year = 2006| arxiv = math/0212070}}.
*{{citation
 | last = Chvátal | first = V. | author-link = Vašek Chvátal
 | doi = 10.1016/0095-8956(85)90049-8
 | issue = 3
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 815391
 | pages = 189–199
 | series = Series B
 | title = Star-cutsets and perfect graphs
 | volume = 39
 | year = 1985}}.
*{{citation
 | last1 = Cornuéjols | first1 = G. | author1-link = Gérard Cornuéjols
 | last2 = Reed | first2 = B. | author2-link = Bruce Reed (mathematician)
 | doi = 10.1006/jctb.1993.1065
 | issue = 2
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 1244930
 | pages = 191–198
 | series = Series B
 | title = Complete multi-partite cutsets in minimal imperfect graphs
 | volume = 59
 | year = 1993}}.
*{{citation
 | last1 = Dantas | first1 = Simone
 | last2 = de Figueiredo | first2 = Celina M. H.
 | last3 = Klein | first3 = Sulamita
 | last4 = Gravier | first4 = Sylvain
 | last5 = Reed | first5 = Bruce A. | author5-link = Bruce Reed (mathematician)
 | doi = 10.1016/j.dam.2004.01.001
 | issue = 1-3
 | journal = Discrete Applied Mathematics
 | mr = 2087864
 | pages = 17–22
 | title = Stable skew partition problem
 | volume = 143
 | year = 2004}}.
*{{citation
 | last1 = de Figueiredo | first1 = Celina M. H.
 | last2 = Klein | first2 = Sulamita
 | last3 = Kohayakawa | first3 = Yoshiharu|author3-link = Yoshiharu Kohayakawa
 | last4 = Reed | first4 = Bruce A. | author4-link = Bruce Reed (mathematician)
 | doi = 10.1006/jagm.1999.1122
 | issue = 2
 | journal = Journal of Algorithms
 | mr = 1788847
 | pages = 505–521
 | title = Finding skew partitions efficiently
 | volume = 37
 | year = 2000}}.
*{{citation
 | last = Hayward | first = Ryan B.
 | doi = 10.1016/0095-8956(85)90050-4
 | issue = 3
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 815392
 | pages = 200–208
 | series = Series B
 | title = Weakly triangulated graphs
 | volume = 39
 | year = 1985}}.
*{{citation
 | last1 = Kennedy | first1 = William S.
 | last2 = Reed | first2 = Bruce | author2-link = Bruce Reed (mathematician)
 | contribution = Fast skew partition recognition
 | doi = 10.1007/978-3-540-89550-3_11
 | location = Berlin
 | mr = 2672388
 | pages = 101–107
 | publisher = Springer
 | series = [[Lecture Notes in Computer Science]]
 | title = Computational Geometry and Graph Theory: International Conference, KyotoCGGT 2007, Kyoto, Japan, June 11–15, 2007, Revised Selected Papers
 | volume = 4535
 | year = 2008}}.
*{{citation
 | last = Lovász | first = László | authorlink = László Lovász
 | year = 1972
 | title = Normal hypergraphs and the perfect graph conjecture
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | volume = 2
 | issue = 3
 | pages = 253–267
 | doi = 10.1016/0012-365X(72)90006-4}}.
*{{citation
 | last = Reed | first = Bruce | authorlink = Bruce Reed (mathematician)
 | doi = 10.1016/j.dam.2007.05.054
 | issue = 7
 | journal = Discrete Applied Mathematics
 | mr = 2404228
 | pages = 1150–1156
 | title = Skew partitions in perfect graphs
 | url = http://cgm.cs.mcgill.ca/~reedbook/papers/SkewPartitionsPerfectGraphs.pdf
 | volume = 156
 | year = 2008}}.
*{{citation
 | last1 = Roussel | first1 = F.
 | last2 = Rubio | first2 = P.
 | doi = 10.1006/jctb.2001.2044
 | issue = 2
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 1866394
 | pages = 171–190
 | series = Series B
 | title = About skew partitions in minimal imperfect graphs
 | volume = 83
 | year = 2001}}.
*{{citation
 | last = Seymour | first = Paul | author-link = Paul Seymour (mathematician)
 | issue = 109
 | journal = Gazette des Mathématiciens
 | mr = 2245898
 | pages = 69–83
 | title = How the proof of the strong perfect graph conjecture was found
 | url = http://users.encs.concordia.ca/~chvatal/perfect/pds.pdf
 | year = 2006}}.
*{{citation
 | last = Trotignon | first = Nicolas
 | doi = 10.1016/j.jctb.2007.07.004
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 2368032
 | pages = 173–225
 | series = Series B
 | title = Decomposing Berge graphs and detecting balanced skew partitions
 | volume = 98
 | year = 2008}}.
{{refend}}

[[Category:Graph theory objects]]
[[Category:Perfect graphs]]</text>
      <sha1>563v19ft5hu6qy2c7ri3wfkehki181k</sha1>
    </revision>
  </page>
  <page>
    <title>Tarski's plank problem</title>
    <ns>0</ns>
    <id>16066580</id>
    <revision>
      <id>793370874</id>
      <parentid>729806971</parentid>
      <timestamp>2017-08-01T09:56:11Z</timestamp>
      <contributor>
        <username>Rocchini</username>
        <id>2453660</id>
      </contributor>
      <comment>sample image added</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2942">In [[mathematics]], '''Tarski's plank problem''' is a question about coverings of convex regions in ''n''-dimensional Euclidean space by "planks": regions between two hyperplanes. [[Alfred Tarski|Tarski]] asked if the sum of the widths of the planks must be at least the minimum width of the convex region. The question was answered affirmatively by 
{{harvs|txt=yes|first=Thøger|last=Bang|year=1950|year2=1951}}.&lt;ref&gt;{{cite journal|author=King, Jonathan L.|title=Three problems in search of a measure|journal=Amer. Math. Monthly|volume=101|year=1994|pages=609–628|url=http://www.maa.org/programs/maa-awards/writing-awards/three-problems-in-search-of-a-measure-0|doi=10.2307/2974690}}&lt;/ref&gt;

==Statement==
[[File:Tarski plank problem.svg|right|320px]]
Given a [[convex body]] ''C'' in '''R'''&lt;sup&gt;''n''&lt;/sup&gt; and a hyperplane ''H'', the width of ''C'' parallel to ''H'', ''w''(''C'',''H''), is the distance between the two [[supporting hyperplane]]s of ''C'' that are parallel to ''H''.  The smallest such distance (i.e. the [[infimum]] over all possible hyperplanes) is called the minimal width of ''C'', ''w''(''C'').

The (closed) set of points ''P'' between two distinct, parallel hyperplanes in '''R'''&lt;sup&gt;''n''&lt;/sup&gt; is called a plank, and the distance between the two hyperplanes is called the width of the plank, ''w''(''P'').  Tarski conjectured that if a convex body ''C'' of minimal width ''w''(''C'') was covered by a collection of planks, then the sum of the widths of those planks must be at least ''w''(''C'').  That is, if ''P''&lt;sub&gt;1&lt;/sub&gt;,…,''P''&lt;sub&gt;''m''&lt;/sub&gt; are planks such that
:&lt;math&gt;C\subseteq P_1\cup\ldots\cup P_m\subset \R^n,&lt;/math&gt;
then
:&lt;math&gt;\sum_{i=1}^m w(P_i)\geq w(C).&lt;/math&gt;
Bang proved this is indeed the case.

==Nomenclature==
The name of the problem, specifically for the sets of points between parallel hyperplanes, comes from the visualisation of the problem in '''R'''&lt;sup&gt;2&lt;/sup&gt;.  Here, hyperplanes are just straight lines and so planks become the space between two parallel lines.  Thus the planks can be thought of as (infinitely long) [[Plank (wood)|planks of wood]], and the question becomes how many planks does one need to completely cover a [[convex polygon|convex]] tabletop of minimal width ''w''?  Bang's theorem shows that, for example, a circular [[Table (furniture)|table]] of [[diameter]] ''d'' feet can't be covered by fewer than ''d'' planks of wood of width one foot each.

==References==
{{reflist}}
*{{citation|mr=0038085
|authorlink = Thøger Bang
|last=Bang|first= Thøger
|title=On covering by parallel-strips.
|journal=Mat. Tidsskr. B.|year= 1950|pages= 49–53}} 
*{{citation|mr=0046672
|last=Bang|first= Thøger
|title=A solution of the "plank problem"
|journal=Proc. Amer. Math. Soc.|volume= 2|year=1951|pages= 990–993
|doi=10.2307/2031721|issue=6|jstor=2031721
|url=http://www.ams.org/journals/proc/1951-002-06/S0002-9939-1951-0046672-4/}}

[[Category:Geometry]]</text>
      <sha1>1oc5ratqtnr3o8xokiel3r6u5lo1fpw</sha1>
    </revision>
  </page>
  <page>
    <title>Tennenbaum's theorem</title>
    <ns>0</ns>
    <id>13392068</id>
    <revision>
      <id>845221450</id>
      <parentid>844570212</parentid>
      <timestamp>2018-06-10T08:43:35Z</timestamp>
      <contributor>
        <username>Tea2min</username>
        <id>36029</id>
      </contributor>
      <comment>/* Proof Sketch */ Sentence case in section headers</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5946">'''Tennenbaum's theorem''', named for [[Stanley Tennenbaum]] who presented the theorem in 1959, is a result in [[mathematical logic]] that states that no [[countable set|countable]] [[Non-standard model of arithmetic|nonstandard model]] of first-order [[Peano arithmetic]] (PA) can be recursive (Kaye 1991:153ff). 

==Recursive structures for PA==
A [[model theory|structure]] &lt;math&gt;M&lt;/math&gt; in the language of PA is '''recursive''' if there are [[μ-recursive function|recursive]] functions + and &amp;times; from &lt;math&gt; N \times N&lt;/math&gt; to &lt;math&gt; N&lt;/math&gt;, a recursive two-place relation &lt; on &lt;math&gt; N&lt;/math&gt;, and distinguished constants &lt;math&gt;n_0,n_1&lt;/math&gt; such that
: &lt;math&gt;
(N, \oplus,\otimes,&lt;_M,n_{0},n_{1}) \equiv M,
&lt;/math&gt;
where &lt;math&gt;\equiv&lt;/math&gt; indicates [[isomorphism]] and &lt;math&gt;N&lt;/math&gt; is the set of (standard) [[natural numbers]]. Because the isomorphism must be a bijection, every recursive model is countable. There are many nonisomorphic countable nonstandard models of PA.

== Statement of the theorem ==
Tennenbaum's theorem states that no countable nonstandard model of PA is recursive. Moreover, neither the addition nor the multiplication of such a model can be recursive.

== Proof sketch==

This sketch follows the argument presented by Kaye (1991).   The first step in the proof is to show that, if ''M'' is any countable nonstandard model of PA, then the standard system of M (defined below) contains at least one nonrecursive set ''S''.  The second step is to show that, if either the addition or multiplication operation on ''M'' were recursive, then this set ''S'' would be recursive, which is a contradiction. 

Through the methods used to code ordered tuples, each element &lt;math&gt;x \in M&lt;/math&gt; can be viewed as a code for a set &lt;math&gt;S_x&lt;/math&gt; of elements of ''M''. In particular, if we let &lt;math&gt;p_i&lt;/math&gt; be the ''i''th prime in ''M'', then &lt;math&gt;z \in S_x \leftrightarrow M \vDash p_z | x&lt;/math&gt;.   Each set &lt;math&gt;S_x&lt;/math&gt; will be bounded in ''M'', but if ''x'' is nonstandard then the set &lt;math&gt;S_x&lt;/math&gt; may contain infinitely many standard natural numbers. The '''standard system''' of the model is the collection &lt;math&gt;\{ S_x \cap N : x \in M\}&lt;/math&gt;.   It can be shown that the standard system of any nonstandard model of PA contains a nonrecursive set, either by appealing to the [[incompleteness theorem]] or by directly considering a pair of [[Recursively inseparable sets|recursively inseparable]] r.e. sets (Kaye&amp;nbsp;1991:154).    These are disjoint r.e. sets &lt;math&gt;A,B \subseteq N&lt;/math&gt; so that that there is no recursive set &lt;math&gt;C \subseteq N&lt;/math&gt; with &lt;math&gt;A \subseteq C&lt;/math&gt; and &lt;math&gt;B \cap C = \emptyset&lt;/math&gt;. 

For the latter construction, begin with a pair of recursively inseparable r.e. sets ''A'' and ''B''.  For natural number ''x'' there is a ''y'' such that, for all ''i &lt; x'', if &lt;math&gt;i \in A&lt;/math&gt; then &lt;math&gt;p_i | y&lt;/math&gt; and if &lt;math&gt;i \in B&lt;/math&gt; then &lt;math&gt;p_i \not | y&lt;/math&gt;. By the [[overspill (arithmetic)|overspill]] property, this means that there is some nonstandard ''x'' in ''M'' for which there is a (necessarily nonstandard) ''y'' in ''M'' so that, for every &lt;math&gt;m \in M&lt;/math&gt; with &lt;math&gt;m &lt;_M x&lt;/math&gt;, we have
:&lt;math&gt;M \vDash (m \in A\to p_m |y)\land(m\in B \to p_m \not | y)&lt;/math&gt;
Let &lt;math&gt;S = N \cap S_y&lt;/math&gt; be the corresponding set in the standard system of ''M''. Because ''A'' and ''B'' are r.e., one can show that &lt;math&gt;A \subseteq S&lt;/math&gt; and &lt;math&gt;B \cap S = \emptyset&lt;/math&gt;. Hence ''S'' is a separating set for ''A'' and ''B'', and by the choice of ''A'' and ''B'' this means ''S'' is nonrecursive. 

Now, to prove Tennenbaum's theorem, begin with a nonstandard countable model ''M'' and an element ''a'' in ''M'' so that &lt;math&gt;S = N \cap S_a&lt;/math&gt; is nonrecursive. The proof method shows that, because of the way the standard system is defined, it is possible to compute the characteristic function of the set ''S'' using the addition function &lt;math&gt;\oplus&lt;/math&gt; of ''M'' as an oracle.  In particular, if &lt;math&gt;n_0&lt;/math&gt; is the element of ''M'' corresponding to 0, and &lt;math&gt;n_1&lt;/math&gt; is the element of ''M'' corresponding to 1, then for each &lt;math&gt;i \in N&lt;/math&gt; we can compute &lt;math&gt;n_i = n_1 \oplus \cdots \oplus n_1&lt;/math&gt; (''i'' times).  To decide if a number ''n'' is in ''S'', first compute ''p'', the ''n''th prime in ''N''. Then, search for an element ''y'' of ''M'' so that 
:&lt;math&gt;a = \underbrace{y \oplus y \oplus \cdots \oplus y}_{p \text{ times}} \oplus n_i&lt;/math&gt;
for some &lt;math&gt;i &lt; p&lt;/math&gt;. This search will halt because the [[Euclidean algorithm]] can be applied to any model of PA.  Finally, we have &lt;math&gt;n \in S&lt;/math&gt; if and only if the ''i'' found in the search was 0. Because ''S'' is not recursive, this means that the addition operation on ''M'' is nonrecursive. 

A similar argument shows that it is possible to compute the characteristic function of ''S'' using the multiplication of ''M'' as an oracle, so the multiplication operation on ''M'' is also nonrecursive (Kaye&amp;nbsp;1991:154).

==References==
* [[George Boolos]], [[John P. Burgess]], and [[Richard Jeffrey]] (2002) ''Computability and Logic'', 4th ed. Cambridge University Press. {{isbn|0-521-00758-5}}
* Richard Kaye (1991) ''Models of Peano arithmetic''. Oxford University Press. {{isbn|0-19-853213-X}}.
* {{cite book| author=Richard Kaye| contribution=Tennenbaum's Theorem for Models of Arithmetic|date=Sep 2011| volume=36| title=Set theory, arithmetic, and foundations of mathematics - theorems, philosophies |editor=Juliette Kennedy and Roman Kossak| series=Lecture Notes in Logic| isbn=9781107008045| url=http://web.mat.bham.ac.uk/R.W.Kaye/papers/tennenbaum/tennenbaum.pdf}}
* Stanley Tennenbaum (1959) ''Non-Archimedean models for arithmetic'', In: Notices of the American Mathematical Society 6, p. 270

{{DEFAULTSORT:Tennenbaum's Theorem}}

[[Category:Model theory]]
[[Category:Theorems in the foundations of mathematics]]</text>
      <sha1>m44j6d916p5ttl4vtzxxnr9r4ms88fm</sha1>
    </revision>
  </page>
  <page>
    <title>Teofilo F. Gonzalez</title>
    <ns>0</ns>
    <id>47231784</id>
    <revision>
      <id>818003615</id>
      <parentid>797712372</parentid>
      <timestamp>2017-12-31T23:03:42Z</timestamp>
      <contributor>
        <username>SamChambers</username>
        <id>5562657</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5723">{{BLP sources|date=September 2015}}
{{Infobox person
|name = Teofilo (Teo) Gonzalez
|birth_place = Monterrey, Mexico
|education = B.S.    ITESM (1972)
Ph.D.  University of Minnesota (1975)
|employer = UC Santa Barbara
|website = http://www.cs.ucsb.edu/~teo
|occupation = Professor of Computer Science UCSB}}

'''Teofilo Francisco Gonzalez Arce''' (born January 26, 1948 in Monterrey, Mexico) is a Mexican-American [[computer scientist]] who is professor emeritus of computer science at the [[University of California, Santa Barbara]]. 

In 1972 Gonzalez was one of the first students who earned a bachelor's degree in computer science (Ingeniero en Sistemas Computacionales) in Mexico,{{cn|date=September 2015}} at the [[Monterrey Institute of Technology and Higher Education]].{{r|cv}}
He completed his Ph.D. in 1975 from the [[University of Minnesota]] under the supervision of  [[Sartaj Sahni]].{{r|cv|mg}} He taught at the [[University of Oklahoma]] from 1975 to 1976, at the [[Pennsylvania State University]] from 1976 to 1979, at the [[Monterrey Institute of Technology and Higher Education]] from 1979 to 1980, and at the [[University of Texas at Dallas]] from 1980 to 1984, before joining the [[University of California, Santa Barbara|UCSB]] computer science faculty in 1984.{{r|cv}} He spent Sabbatical Leaves at [[Utrecht University]] (1990) in the Netherlands and the [[Monterrey Institute of Technology and Higher Education]]. Professor Gonzalez became Fellow of IASTED in 2009.

He is known for his highly cited pioneering research in the [[hardness of approximation]];{{ran|SG76}}{{r|ws11}}
for his sub-linear and best possible approximation algorithm (unless [[P = NP]]) based on the [[farthest-first traversal]] for the [[metric k-center|metric ''k''-center problem]]{{ran|G85}}{{r|ws11}} (k-tMM clustering);
and for introducing the [[open-shop scheduling]] problem as well as algorithms for its solution that have found numerous applications in several research areas as well as for his research on  [[flow shop scheduling]], and [[job shop scheduling]] [[algorithm]]s.{{ran|GS76}}{{ran|GS78}}{{r|lr13}}
He is the editor of the ''Handbook on Approximation Algorithms and Metaheuristics'',{{ran|G07}} and he is co-editor of Volume 1 (Computer Science and Software Engineering) of the ''Computing Handbook Set''.{{ran|CH}}

==Selected publications==
{{rma|GS76|{{citation
 | last1 = Gonzalez | first1 = Teofilo
 | last2 = Sahni | first2 = Sartaj | author2-link = Sartaj Sahni
 | issue = 4
 | journal = [[Journal of the ACM]]
 | mr = 0429089
 | pages = 665–679
 | title = Open shop scheduling to minimize finish time
 | volume = 23
 | year = 1976 | doi=10.1145/321978.321985}}.
|tw=4em}}

{{rma|SG76|{{citation
 | last1 = Sahni | first1 = Sartaj | author1-link = Sartaj Sahni
 | last2 = Gonzalez | first2 = Teofilo
 | issue = 3
 | journal = [[Journal of the ACM]]
 | mr = 0408313
 | pages = 555–565
 | title = ''P''-complete approximation problems
 | volume = 23
 | year = 1976 | doi=10.1145/321958.321975}}.
|tw=4em}}

{{rma|GS78|{{citation
 | last1 = Gonzalez | first1 = Teofilo
 | last2 = Sahni | first2 = Sartaj | author2-link = Sartaj Sahni
 | issue = 1
 | journal = [[Operations Research (journal)|Operations Research]]
 | mr = 0465149
 | pages = 36–52
 | title = Flowshop and jobshop schedules: complexity and approximation
 | volume = 26
 | year = 1978 | doi=10.1287/opre.26.1.36}}.
|tw=4em}}

{{rma|G85|{{citation
 | last = Gonzalez | first = T. F.
 | doi = 10.1016/0304-3975(85)90224-5
 | issue = 2-3
 | journal = [[Theoretical Computer Science (journal)|Theoretical Computer Science]]
 | mr = 807927
 | pages = 293–306
 | title = Clustering to minimize the maximum intercluster distance
 | volume = 38
 | year = 1985}}.
|tw=4em}}

{{rma|G07|{{citation|edition = 1|title = Handbook of Approximation Algorithms and Metaheuristics|publisher = Chapman and Hall/CRC|date = 2007-05-15|location = Cambridge, Mass.|isbn = 9780262633246}}
|tw=4em}}

{{rma|CH|{{citation|title = Computing Handbook, Third Edition: Two-Volume Set|publisher = CRC Press}}
|tw=4em}}

==References==
{{reflist|refs=

&lt;ref name=cv&gt;[http://www.cs.ucsb.edu/~teo/temp.pdf Curriculum vitae], retrieved 2015-07-13.&lt;/ref&gt;

&lt;ref name=lr13&gt;{{citation|title=Production Scheduling|first1=Pierre|last1=Lopez|first2=François|last2=Roubellat|publisher=John Wiley &amp; Sons|year=2013|isbn=9781118624029|contribution=10.3 Complexity of open shop problems}}.&lt;/ref&gt;

&lt;ref name=mg&gt;{{mathgenealogy|id=113396}}&lt;/ref&gt;

&lt;ref name=ws11&gt;{{citation|title=The Design of Approximation Algorithms|first1=David P.|last1=Williamson|author1-link=David P. Williamson|first2=David B.|last2=Shmoys|author2-link=David Shmoys|publisher=Cambridge University Press|year=2011|isbn=9781139498173|page=55|url=https://books.google.com/books?id=Cc_Fdqf3bBgC&amp;pg=PA55}}.&lt;/ref&gt;

}}

==External links==
*[http://www.cs.ucsb.edu/~teo/ Home page]
*[https://scholar.google.com/citations?user=bCTAqq4AAAAJ Google scholar profile]

{{Authority control}}

{{DEFAULTSORT:Gonzalez, Teofilo F.}}
[[Category:Living people]]
[[Category:American computer scientists]]
[[Category:Mexican computer scientists]]
[[Category:Mexican emigrants to the United States]]
[[Category:Theoretical computer scientists]]
[[Category:Monterrey Institute of Technology and Higher Education alumni]]
[[Category:University of Minnesota alumni]]
[[Category:University of Oklahoma faculty]]
[[Category:Pennsylvania State University faculty]]
[[Category:Monterrey Institute of Technology and Higher Education faculty]]
[[Category:University of Texas at Dallas faculty]]
[[Category:University of California, Santa Barbara faculty]]
[[Category:1948 births]]
[[Category:American academics of Mexican descent]]</text>
      <sha1>kbbhm5ta4z54uirkp51iq046o20znrf</sha1>
    </revision>
  </page>
  <page>
    <title>Tetrad formalism</title>
    <ns>0</ns>
    <id>11141222</id>
    <revision>
      <id>856665002</id>
      <parentid>856664738</parentid>
      <timestamp>2018-08-26T20:25:12Z</timestamp>
      <contributor>
        <username>Quondum</username>
        <id>12331483</id>
      </contributor>
      <comment>/* Mathematical formulation */ rm \scriptstyle</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10108">{{About|general tetrads|orthonormal tetrads|Frame fields in general relativity}}

The '''tetrad formalism''' is an approach to [[general relativity]] that replaces the choice of a [[coordinate basis]] by the less restrictive choice of a [[local basis]] for the [[tangent bundle]], i.e. a locally defined set of four linearly independent [[vector field]]s called a [[Tetrad (general relativity)|tetrad]].&lt;ref&gt;{{citation | last1=De Felice|first1=F.|last2=Clarke|first2=C.J.S. |title=Relativity on Curved Manifolds| year=1990|page=133}}&lt;/ref&gt;

In the tetrad formalism all tensors are represented in terms of a chosen [[Basis (mathematics)|basis]]. (When generalised to other than four dimensions this approach is given other names, see [[Cartan formalism (physics)|Cartan formalism]].) As a [[Formalism (mathematics)|formalism]] rather than a theory, it does not make different predictions but does allow the relevant equations to be expressed differently.

The advantage of the tetrad formalism over the standard coordinate-based approach to general relativity lies in the ability to choose the tetrad basis to reflect important physical aspects of the spacetime. The abstract index notation denotes tensors as if they were represented by their coefficients with respect to a fixed local tetrad. Compared to a completely coordinate free notation, which is often conceptually clearer, it allows an easy and computationally explicit way to denote contractions.

==Mathematical formulation==
In the tetrad formalism, a tetrad basis is chosen: a set of four independent [[vector field]]s &lt;math&gt;\{e_{(a)} = e_{(a)}^{\mu} \partial_\mu\}_{a=1\dots4}&lt;/math&gt; that together span the 4D vector [[tangent space]] at each point in [[spacetime]]. Dually, a tetrad determines (and is determined by) a dual co-tetrad—a set of four independent covectors (1-forms) &lt;math&gt;\{e^{(a)} = e^{(a)}_{\mu} dx^\mu\}_{a=1\dots4}&lt;/math&gt; such that 
:&lt;math&gt; e^{(a)} (e_{(b)}) = e^{(a)}_\mu e^\mu_{(b)} = \delta^{(a)}_{(b)},&lt;/math&gt;
where &lt;math&gt;\delta^{(a)}_{(b)}&lt;/math&gt; is the [[Kronecker delta]]. A tetrad is usually specified by its coefficients &lt;math&gt;e_{(a)}^{\mu}&lt;/math&gt; with respect to a coordinate basis, despite the fact that the choice of a tetrad does not actually require the additional choice of a set of (local) coordinates &lt;math&gt; x^\mu&lt;/math&gt;.

From a mathematical point of view, the four vector fields &lt;math&gt;\{e_{(a)}\}_{a=1\dots4}&lt;/math&gt; define a section of the 
[[frame bundle]] i.e. a [[Parallelization (mathematics)|parallelization]] of &lt;math&gt;M&lt;/math&gt; which is equivalent to an isomorphism &lt;math&gt;TM \cong M\times {\mathbb R^4}&lt;/math&gt;. Since not every manifold is parallelizable, a tetrad can generally only be chosen locally.

All tensors of the theory can be expressed in the vector and covector basis, by expressing them as linear combinations of members of the (co)tetrad. For example, the spacetime metric itself can be transformed from a coordinate basis to the [[Tetrad (general relativity)|tetrad]] [[Basis (mathematics)|basis]]. 

Popular tetrad bases include [[Frame fields in general relativity|orthonormal tetrads]] and null tetrads. Null tetrads are composed of four [[null vector]]s, so are used frequently in problems dealing with radiation, and are the basis of the [[Newman–Penrose formalism]] and the [[GHP formalism]].

==Relation to standard formalism==
The standard formalism of [[differential geometry]] (and general relativity) consists simply of using the '''coordinate tetrad''' in the tetrad formalism. The coordinate tetrad is the canonical set of vectors associated with the [[coordinate chart]]. The coordinate tetrad is commonly denoted &lt;math&gt;\{\partial_\mu\}&lt;/math&gt; whereas the dual cotetrad is denoted &lt;math&gt;\{d x^\mu\}&lt;/math&gt;. These [[tangent space|tangent vectors]] are usually defined as [[directional derivative]] operators: given a chart &lt;math&gt;{\varphi = (\varphi^1, \ldots, \varphi^n)}&lt;/math&gt; which maps a subset of the [[manifold]] into coordinate space &lt;math&gt;\mathbb R^n&lt;/math&gt;, and any [[scalar field]] &lt;math&gt;f&lt;/math&gt;, the coordinate vectors are such that:
:&lt;math&gt;\partial_\mu [f] \equiv \frac{\partial f \circ \varphi^{-1} }{\partial x^\mu}.&lt;/math&gt;
The definition of the cotetrad uses the usual abuse of notation &lt;math&gt; dx^\mu = d\varphi^\mu&lt;/math&gt; to define covectors (1-forms) on &lt;math&gt;M&lt;/math&gt;. The involvement of the coordinate tetrad is not usually made explicit in the standard formalism. In the tetrad formalism, instead of writing tensor equations out fully (including tetrad elements and [[tensor products]] &lt;math&gt;\otimes&lt;/math&gt; as above) only ''components'' of the tensors are mentioned. For example, the metric is written as "&lt;math&gt;g_{ab}&lt;/math&gt;". When the tetrad is unspecified this becomes a matter of specifying the type of the tensor called [[abstract index notation]]. It allows to easily specify contraction between tensors by repeating indices as in the Einstein summation convention.

Changing tetrads is a routine operation in the standard formalism, as it is involved in every coordinate transformation (i.e., changing from one coordinate tetrad basis to another). Switching between multiple coordinate charts is necessary because, except in trivial cases, it is not possible for a single coordinate chart to cover the entire manifold. Changing to and between general tetrads is much similar and equally necessary (except for [[parallelizable manifold]]s). Any [[tensor]] can locally be written in terms of this coordinate tetrad or a general (co)tetrad.

For example, the [[metric tensor]] &lt;math&gt;\bold g&lt;/math&gt; can be expressed as:

:&lt;math&gt;\bold g = g_{\mu\nu}dx^\mu dx^\nu \qquad \text{where}~g_{\mu\nu} = \bold g(\partial_\mu,\partial_\nu) &lt;/math&gt;

(here we use the [[Einstein summation convention]]). Likewise, the metric can be expressed with respect to an arbitrary (co)tetrad as

:&lt;math&gt; \bold g = g_{ab}e^{(a)}e^{(b)} \qquad \text{where}~g_{ab} = \bold g\left(e_{(a)},e_{(b)}\right) &lt;/math&gt;

We can translate from a general co-tetrad to the coordinate co-tetrad by expanding the covector &lt;math&gt; e^{(a)} = e^{(a)}_\mu dx^\mu &lt;/math&gt;. We then get 
 
:&lt;math&gt; \bold g = g_{ab}e^{(a)}e^{(b)} = g_{ab}e^{(a)}_\mu e^{(b)}_\nu dx^\mu dx^\nu = g_{\mu\nu}dx^{\mu}dx^{\nu}&lt;/math&gt;

from which it follows that &lt;math&gt; g_{\mu\nu} = g_{ab}e^{(a)}_\mu e^{(b)}_\nu &lt;/math&gt;. Likewise
expanding &lt;math&gt; dx^\mu = e^\mu_{(a)}e^{(a)} &lt;/math&gt; with respect to the general tetrad we get

:&lt;math&gt; \bold g =  g_{\mu\nu}dx^{\mu}dx^{\nu} = g_{\mu \nu} e_{(a)}^{\mu} e_{(b)}^{\nu} e^{(a)} e^{(b)} = g_{ab}e^{(a)}e^{(b)}  &lt;/math&gt;

which shows that &lt;math&gt; g_{ab} = g_{\mu\nu}e_{(a)}^\mu e_{(b)}^\nu &lt;/math&gt;. For notational simplicity one usually drops the round brackets around the indices, recognizing that they can both label a set of (co)vectors and tensor components with respect to the (co)tetrad defined by these (co)vectors.

The manipulation with tetrad coefficients shows that abstract index formulas can, in principle, be obtained from tensor formulas with respect to a coordinate tetrad by "replacing greek by latin indices". However care must be taken that a coordinate tetrad formula defines a genuine tensor when differentiation is involved. Since the coordinate vectorfields have vanishing [[Lie bracket of vector fields|Lie bracket]] (i.e. commute: &lt;math&gt; \partial_\mu\partial_\nu = \partial_\nu\partial_\mu &lt;/math&gt;), naive substitutions of formulas that correctly compute tensor coefficients with respect to a coordinate tetrad may not correctly define a tensor with respect to a general tetrad because the Lie bracket &lt;math&gt; [e_a, e_b] = e_a e_b - e_b e_a \ne 0&lt;/math&gt;. For example, the [[Riemann curvature tensor]] is defined for general vectorfields &lt;math&gt;X, Y&lt;/math&gt; by
:&lt;math&gt; R(X,Y) = \left(\nabla_X \nabla_Y - \nabla_Y\nabla_X - \nabla_{[X,Y]}\right) &lt;/math&gt;.

In a coordinate tetrad this gives tensor coefficients
:&lt;math&gt; R^\mu_{\ \nu\sigma\tau} = 
 dx^\mu\left((\nabla_\sigma\nabla_\tau - \nabla_\tau\nabla_\sigma)\partial_\nu\right).&lt;/math&gt; 

The naive "Greek to Latin" substitution of the latter expression
:&lt;math&gt; R^a_{\ bcd} = e^a\left((\nabla_c\nabla_d - \nabla_d\nabla_c)e_b\right) \qquad \text{(wrong!)}&lt;/math&gt;
is incorrect because for fixed ''c'' and ''d'', &lt;math&gt;\left(\nabla_c\nabla_d - \nabla_d\nabla_c\right)&lt;/math&gt; is, in general, a first order differential operator rather than a zeroth order operator which defines a tensor coefficient.  Substituting a general tetrad basis in the abstract formula we find the proper definition of the curvature in abstract index notation, however: 
:&lt;math&gt; R^a_{\ bcd}= e^a\left((\nabla_c\nabla_d - \nabla_d\nabla_c - f^e_{cd}\nabla_e)e_b\right)&lt;/math&gt;

where &lt;math&gt;[e_a, e_b] = f^c_{ab}e_c&lt;/math&gt;. Note that the expression &lt;math&gt;\left(\nabla_c\nabla_d - \nabla_d\nabla_c - f^e_{cd}\nabla_e\right)&lt;/math&gt; is indeed a zeroth order operator, hence (the (''c'' ''d'')-component of) a tensor. Since it agrees with the coordinate expression for the curvature when specialised to a coordinate tetrad it is clear, even without using the abstract definition of the curvature, that it defines the same tensor as the coordinate basis expression.

==See also==
* [[Frame bundle]]
* [[Orthonormal frame bundle]]
* [[Principal bundle]]
* [[Spin bundle]]
* [[Connection (mathematics)]]
* [[G-structure]]
* [[Spin manifold]]
* [[Spin structure]]
* [[Dirac equation in curved spacetime]]

== Notes ==
{{Reflist}}

== References ==
* {{citation | last1=De Felice|first1=F.|last2=Clarke|first2=C.J.S. | title = Relativity on Curved Manifolds| publisher=Cambridge University Press | year=1990|edition=first published 1990|isbn=0-521-26639-4}}
* {{citation | last1=Benn|first1=I.M.|last2=Tucker|first2=R.W. | title = An introduction to Spinors and Geometry with Applications in Physics| publisher=Adam Hilger | year=1987|edition=first published 1987|isbn=0-85274-169-3}}

==External links==
* [https://web.archive.org/web/20091229024331/http://casa.colorado.edu/~ajsh/phys5770_08/grtetrad.pdf General Relativity with Tetrads]

[[Category:Differential geometry]]
[[Category:Theory of relativity]]
[[Category:Mathematical notation]]</text>
      <sha1>nmr7tmc6tx427913e4h925ik6k34arb</sha1>
    </revision>
  </page>
  <page>
    <title>Tetradic number</title>
    <ns>0</ns>
    <id>58904582</id>
    <revision>
      <id>866323217</id>
      <parentid>866219266</parentid>
      <timestamp>2018-10-29T17:35:27Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>/* Tetradic primes */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3581">A '''tetradic''' '''number''', also known as a '''four-way''' '''number''', is a number that remains the same when flipped back to front, flipped front to back, mirrored up-down, or flipped up-down. The only numbers that remain the same which turned up-side-down or mirrored are 0, 1, and 8, so a tetradic number is a [[palindromic number]] containing only 0, 1, and 8 as digits. The first few tetradic numbers are 1, 8, 11, 88, 101, 111, 181, 808, 818, ... ([[On-Line Encyclopedia of Integer Sequences|OEIS]] A006072).&lt;ref&gt;Sloane, N. J. A. Sequences [[oeis:A006072|A006072]]/M4481 in "The On-Line Encyclopedia of Integer Sequences."&lt;/ref&gt;&lt;ref name=":0"&gt;{{Cite book|title=CRC Concise Encyclopedia of Mathematics|last=Weisstein|first=Eric W.|publisher=CRC Press|year=2002|isbn=978-1420035223|edition=2nd|location=|pages=}}&lt;/ref&gt;&lt;ref name=":1"&gt;{{Cite web|url=http://mathworld.wolfram.com/TetradicNumber.html|title=Tetradic Number|last=|first=|date=|website=Wolfram MathWorld|archive-url=|archive-date=|dead-url=|access-date=October 28, 2018}}&lt;/ref&gt;&lt;ref name=":2"&gt;{{Cite web|url=https://everything2.com/title/tetradic+number|title=tetradic number|last=|first=|date=January 5, 2002|website=Everthing2|archive-url=|archive-date=|dead-url=|access-date=October 28, 2018}}&lt;/ref&gt;

Tetradic numbers are also known as four-way numbers due to the fact that they have four-way [[Symmetry in mathematics|symmetry]] and can flipped back to front, flipped front to back, mirrored up-down, or flipped up-down and always stay the same. The four-way symmetry explains the name, due to [[Numeral prefix|tetra-]] being the Greek prefix for four. Tetradic numbers are both [[Strobogrammatic number|strobogrammatic]] and [[Palindromic number|palindromic]].&lt;ref name=":1" /&gt;&lt;ref name=":2" /&gt;

If you have a tetradic number, a larger one can always be generated by adding another tetradic number to each end, retaining the symmetry.

== Tetradic primes ==
Tetradic primes are a specific type of tetradic number defined as tetradic numbers that are also [[Prime number|prime numbers]]. The first few tetradic primes are 11, 101, 181, 18181, 1008001, 1180811, 1880881, 1881881, ... ([[On-Line Encyclopedia of Integer Sequences|OEIS]] A068188).&lt;ref&gt;Sloane, N. J. A. Sequences [[oeis:A068188|A068188]] in "The On-Line Encyclopedia of Integer Sequences."&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://primes.utm.edu/glossary/page.php?sort=Tetradic|title=tetradic prime|last=Caldwell|first=Chris K.|date=|website=The Prime Glossary|publisher=The University of Tennessee Martin|archive-url=|archive-date=|dead-url=|access-date=October 28, 2018}}&lt;/ref&gt;&lt;ref&gt;'''H. Dubner''' and '''R. Ondrejka''', "A PRIMEr on palindromes," ''J. Recreational Math.'', '''26''':4 (1994) 256–267.&lt;/ref&gt;&lt;ref&gt;'''R. Ondrejka''', "On tetradic or 4-way primes," ''J. Recreational Math.'', '''21''':1 (1989) 21–25.&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://primes.utm.edu/lists/top_ten/topten.pdf|title=The Top Ten Prime Numbers|last=Ondrejka|first=R|date=|website=The Prime Pages|archive-url=|archive-date=|dead-url=|access-date=October 28, 2018}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://fatphil.org/maths/palindrome/101.html|title=Totally Tetradic!|last=Carmody|first=Phil|date=|website=Fat Phil|archive-url=|archive-date=|dead-url=|access-date=October 28, 2018}}&lt;/ref&gt;

The largest known tetradic prime {{as of|2010|April|lc=on}} is 

: &lt;math&gt;10^{180054} + 8 R_{58567} \cdot 10^{60744} + 1,&lt;/math&gt;

where &lt;math&gt;R_n&lt;/math&gt; is a [[repunit]]. The prime has 180,055 decimal digits.&lt;ref name=":1" /&gt;

== References ==
{{Reflist}}

[[Category:Mathematical terminology]]</text>
      <sha1>spn3yra1qda5sif91wc71w3mk9k4gnn</sha1>
    </revision>
  </page>
  <page>
    <title>Transmission curve</title>
    <ns>0</ns>
    <id>33301481</id>
    <revision>
      <id>868975177</id>
      <parentid>849304820</parentid>
      <timestamp>2018-11-15T16:36:12Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3020">The '''transmission curve''' or '''transmission characteristic'''&lt;ref&gt;[http://onlinelibrary.wiley.com/doi/10.1002/cta.4490070110/abstract Arndt, F. and Saulich, G. (1979), Microwave filters with nonperiodic transmission characteristic. Int. J. Circ. Theor. Appl., 7: 87–96. doi: 10.1002/cta.4490070110]&lt;/ref&gt; is the [[mathematical function]] or [[Line chart|graph]] that describes the [[transmission (telecommunications)|transmission]] fraction of  an [[Filter (optics)|optical]] or [[electronic filter]] as a function of [[frequency]] or [[wavelength]].&lt;ref&gt;[http://cfcc.edu/faculty/jjenkins/courses/msc180/lectures/Spectrophotometry.ppt Introduction to Spectrophotometry, PowerPoint presentation, slide 16 and the Notes for it, cfcc.edu]{{Dead link|date=July 2018 |bot=InternetArchiveBot |fix-attempted=no }}&lt;/ref&gt; It is an instance of a [[transfer function]] but, unlike the case of, for example, an amplifier, output never exceeds input (maximum transmission is 100%). The term is often used in commerce,&lt;ref&gt;{{Cite web |url=http://www.schneiderkreuznach.com/pdf/filter/bw_filter_transmission_curves.pdf# |title=Schneider, Transmission Curves of B+W Filters |access-date=2011-10-04 |archive-url=https://web.archive.org/web/20111011120020/http://schneiderkreuznach.com/pdf/filter/bw_filter_transmission_curves.pdf# |archive-date=2011-10-11 |dead-url=yes |df= }}&lt;/ref&gt; science,&lt;ref&gt;[http://www.astro.washington.edu/groups/MRO/home.page/mro.activities/Sloan.filters.html Manastash Ridge Observatory] "show the transmission curves for our Sloan filters"&lt;/ref&gt; and technology&lt;ref&gt;[http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=4723567&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D4723567 IEEE: Research on curve fitting of transmission T of 2D photonic crystal microcavity]: "It is found that the calculated transmission curve fits the Lorentz function"&lt;/ref&gt; to characterise filters.

The term has also long been  used in fields such as [[geophysics]] and [[astronomy]] to characterise the properties of regions through which radiation passes, such as the [[ionosphere]].&lt;ref&gt;[http://tf.nist.gov/general/pdf/2416.pdf The Relation of Radio Sky-Wave Transmission to Ionosphere Measurements, N Smith, Proceedings of the I.R.E., May 1939]; discusses linear and logarithmic transmission curves of the ionosphere&lt;/ref&gt;&lt;ref&gt;Radiation transmission data for radionuclides and materials relevant to brachytherapy facility shielding, P. Papagiannis et al., 2008, American Association of Physicists in Medicine.  DOI:10.1118/1.2986153
[http://estro.org/estroactivities/Documents/Article-RadiationTransmissionpublishedinNovember2008Papagiannis-et-al-MP-35(2008)4898.pdf]. Discusses and calculates transmission curves related with screening of clinical equipment generating ionising radiation.&lt;/ref&gt;

==See also==
* [[Electronic filter]] — examples of transmission characteristics of electronic filters

==References==
{{Reflist|30em}}

[[Category:Signal processing]]


{{Signal-processing-stub}}</text>
      <sha1>a4uj28rl75xga64xpyx4a3l21ate6s5</sha1>
    </revision>
  </page>
  <page>
    <title>Unified Modeling Language</title>
    <ns>0</ns>
    <id>32169</id>
    <revision>
      <id>865506371</id>
      <parentid>862378246</parentid>
      <timestamp>2018-10-24T10:13:46Z</timestamp>
      <contributor>
        <username>Janvlug</username>
        <id>392879</id>
      </contributor>
      <comment>/* UML 2 */ Latest version of UML is 2.5.1</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20302">{{Use American English|date=January 2012}}
[[File:UML logo.svg|frameless|right|UML logo]]
The '''Unified Modeling Language''' ('''UML''') is a general-purpose, developmental,  [[modeling language]] in the field of [[software engineering]], that is intended to provide a standard way to visualize the design of a system.&lt;ref name=":1" /&gt;

The creation of UML was originally motivated by the desire to standardize the disparate notational systems and approaches to software design. It was developed by [[Grady Booch]], [[Ivar Jacobson]] and [[James Rumbaugh]] at [[Rational Software]] in 1994–1995, with further development led by them through 1996.&lt;ref name=":1" /&gt;

In 1997 UML was adopted as a standard by the [[Object Management Group]] (OMG), and has been managed by this organization ever since. In 2005 UML was also published by the [[International Organization for Standardization]] (ISO) as an approved ISO standard.&lt;ref&gt;{{cite web|url=http://www.iso.org/iso/home/store/catalogue_tc/catalogue_detail.htm?csnumber=32620 |title=ISO/IEC 19501:2005 - Information technology - Open Distributed Processing - Unified Modeling Language (UML) Version 1.4.2 |publisher=Iso.org |date=2005-04-01 |accessdate=2015-05-07}}&lt;/ref&gt; Since then the standard has been periodically revised to cover the latest revision of UML.&lt;ref&gt;{{cite web|url=http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=32624 |title=ISO/IEC 19505-1:2012 - Information technology - Object Management Group Unified Modeling Language (OMG UML) - Part 1: Infrastructure |publisher=Iso.org |date=2012-04-20 |accessdate=2014-04-10}}&lt;/ref&gt;

== History ==

[[File:OO Modeling languages history.jpg|thumb|320px|History of object-oriented methods and notation]]

=== Before UML 1.0 ===

UML has been evolving since the second half of the 1990s and has its roots in the [[object-oriented programming]] methods developed in the late 1980s and early 1990s. The timeline (see image) shows the highlights of the history of object-oriented modeling methods and notation.

It is originally based on the notations of the [[Booch method]], the [[object-modeling technique]] (OMT) and [[object-oriented software engineering]] (OOSE), which it has integrated into a single language.&lt;ref name=":0" /&gt;

[[Rational Software Corporation]] hired [[James Rumbaugh]] from [[General Electric]] in 1994 and after that the company became the source for two of the most popular object-oriented modeling approaches of the day:&lt;ref&gt;Andreas Zendler (1997) ''Advanced Concepts, Life Cycle Models and Tools for Objeckt-Oriented Software Development''. p.122&lt;/ref&gt; Rumbaugh's [[object-modeling technique]] (OMT) and [[Grady Booch]]'s method. They were soon assisted in their efforts by [[Ivar Jacobson]], the creator of the [[object-oriented software engineering]] (OOSE) method, who joined them at Rational in 1995.&lt;ref name=":1"&gt;{{cite book
 | title = Unified Modeling Language User Guide, The
 | publisher = Addison-Wesley
 | edition = 2
 | year = 2005
 | page = 496
 | url = http://www.informit.com/store/unified-modeling-language-user-guide-9780321267979
 | isbn = 0321267974
}}
, See the sample content, look for history&lt;/ref&gt;

=== UML 1.x ===

Under the technical leadership of those three (Rumbaugh, Jacobson and Booch), a consortium called the [[UML Partners]] was organized in 1996 to complete the ''Unified Modeling Language (UML)'' specification, and propose it to the Object Management Group (OMG) for standardisation. The partnership also contained additional interested parties (for example [[Hewlett-Packard|HP]], [[Digital Equipment Corporation|DEC]], [[IBM]] and [[Microsoft]]). The UML Partners' UML 1.0 draft was proposed to the OMG in January 1997 by the consortium. During the same month the UML Partners formed a group, designed to define the exact meaning of language constructs, chaired by [[Cris Kobryn]] and administered by Ed Eykholt, to finalize the specification and integrate it with other standardization efforts. The result of this work, UML 1.1, was submitted to the OMG in August 1997 and adopted by the OMG in November 1997.&lt;ref name=":1" /&gt;&lt;ref&gt;{{cite web|url=http://www.omg.org/cgi-bin/doc?ad/97-08-11 |title=UML Specification version 1.1 (OMG document ad/97-08-11) |publisher=Omg.org |accessdate=2011-09-22}}&lt;/ref&gt;

After the first release a task force was formed&lt;ref name=":1" /&gt; to improve the language, which released several minor revisions, 1.3, 1.4, and 1.5.&lt;ref&gt;{{cite web|url=http://www.omg.org/spec/UML/ |title=UML |publisher=Omg.org |accessdate=2014-04-10}}&lt;/ref&gt;

The standards it produced (as well as the original standard) have been noted as being ambiguous and inconsistent.&lt;ref&gt;Génova et alia 2004 "Open Issues in Industrial Use Case Modeling"&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.uml-forum.com/docs/papers/CACM_Jan02_p107_Kobryn.pdf |title=Will UML 2.0 Be Agile or Awkward? |format=PDF |accessdate=2011-09-22}}&lt;/ref&gt;

==== Cardinality notation ====

As with database Chen, Bachman, and ISO [[ER diagram]]s, class models are specified to use "look-across" [[Cardinality (data modeling)|cardinalities]], even though several authors ([[Merise]],&lt;ref&gt;Hubert Tardieu, Arnold Rochfeld and René Colletti La methode MERISE: Principes et outils (Paperback - 1983)&lt;/ref&gt; Elmasri &amp; Navathe&lt;ref&gt;Elmasri, Ramez, B. Shamkant, Navathe, Fundamentals of Database Systems, third ed., Addison-Wesley, Menlo Park, CA, USA, 2000.&lt;/ref&gt; amongst others&lt;ref&gt;[https://books.google.com/books?id=odZK99osY1EC&amp;pg=PA52&amp;img=1&amp;pgis=1&amp;dq=genova&amp;sig=ACfU3U3tDC_q8WOMqUJW4EZCa5YQywoYLw&amp;edge=0 ER 2004 : 23rd International Conference on Conceptual Modeling, Shanghai, China, 8-12 November 2004] {{webarchive |url=https://web.archive.org/web/20130527133330/https://books.google.com/books?id=odZK99osY1EC&amp;pg=PA52&amp;img=1&amp;pgis=1&amp;dq=genova&amp;sig=ACfU3U3tDC_q8WOMqUJW4EZCa5YQywoYLw&amp;edge=0 |date=27 May 2013 }}&lt;/ref&gt;) prefer same-side or "look-here" for roles and both minimum and maximum cardinalities. Recent researchers (Feinerer,&lt;ref&gt;{{cite web|url=http://publik.tuwien.ac.at/files/pub-inf_4582.pdf |title=A Formal Treatment of UML Class Diagrams as an Efficient Method for Configuration Management 2007 |format=PDF |accessdate=2011-09-22}}&lt;/ref&gt; Dullea et al.&lt;ref&gt;{{cite web|url=http://www.ischool.drexel.edu/faculty/song/publications/p_DKE_03_Validity.pdf |title=James Dullea, Il-Yeol Song, Ioanna Lamprou - An analysis of structural validity in entity-relationship modeling 2002 |format=PDF |accessdate=2011-09-22}}&lt;/ref&gt;) have shown that the "look-across" technique used by UML and ER diagrams is less effective and less coherent when applied to ''n''-ary relationships of order strictly greater than 2.

Feinerer says: "Problems arise if we operate under the look-across semantics as used for UML associations. Hartmann&lt;ref&gt;{{cite web|url=http://crpit.com/confpapers/CRPITV17Hartmann.pdf |title="Reasoning about participation constraints and Chen's constraints" S Hartmann - 2003 |format=PDF |accessdate=2013-08-17}}&lt;/ref&gt; investigates this situation and shows how and why different transformations fail.", and: "As we will see on the next few pages, the look-across interpretation introduces several difficulties which prevent the extension of simple mechanisms from binary to ''n''-ary associations."

=== UML 2 ===

UML 2.0 major revision replaced version 1.5 in 2005, which was developed with an enlarged consortium to improve the language further to reflect new experience on usage of its features.&lt;ref&gt;{{cite web|url=http://www.omg.org/spec/UML/2.0/ |title=UML 2.0 |publisher=Omg.org |accessdate=2011-09-22}}&lt;/ref&gt;

Although UML 2.1 was never released as a formal specification, versions 2.1.1 and 2.1.2 appeared in 2007, followed by UML 2.2 in February 2009. UML 2.3 was formally released in May 2010.&lt;ref name="spec"&gt;{{cite web|url=http://www.omg.org/spec/UML/ |title=UML |publisher=Omg.org |accessdate=2011-09-22}}&lt;/ref&gt; UML 2.4.1 was formally released in August 2011.&lt;ref name="spec"/&gt; UML 2.5 was released in October 2012 as an "In progress" version and was officially released in June 2015.&lt;ref name="spec"/&gt; Formal version 2.5.1 was adopted in December 2017.&lt;ref&gt;{{cite web|url=https://www.omg.org/spec/UML/2.5.1 |title=UML 2.5.1 specification |publisher=Omg.org |accessdate=2018-10-24}}&lt;/ref&gt;

There are four parts to the UML 2.x specification:

* The Superstructure that defines the notation and semantics for diagrams and their model elements
* The Infrastructure that defines the core metamodel on which the Superstructure is based
* The [[Object Constraint Language]] (OCL) for defining rules for model elements
* The UML Diagram Interchange that defines how UML 2 diagram layouts are exchanged

The current versions of these standards are&lt;ref name="Versions"&gt;{{cite web|author=OMG|title=OMG Formal Specifications (Modeling and Metadata paragraph)|url=http://www.omg.org/spec/#M&amp;M|accessdate = 2016-02-12}}&lt;/ref&gt;:
* UML Superstructure version 2.4.1
* UML Infrastructure version 2.4.1
* OCL version 2.3.1
* UML Diagram Interchange version 1.0.

It continues to be updated and improved by the revision task force, who resolve any issues with the language.&lt;ref&gt;{{cite web|url=http://www.omg.org/issues/uml2-rtf.open.html |title=Issues for UML 2.6 Revision task Force mailing list |publisher=Omg.org |accessdate=2014-04-10}}&lt;/ref&gt;

== Design ==

UML offers a way to visualize a system's architectural blueprints in a diagram, including elements such as:&lt;ref name=":0"&gt;{{cite web|url=http://www.omg.org/spec/UML/2.4.1/Superstructure/PDF |title=OMG Unified Modeling Language (OMG UML), Superstructure. Version 2.4.1 |publisher=Object Management Group |accessdate=9 April 2014}}&lt;/ref&gt;

* any [[Activity (UML)|activities]] (jobs);
* individual [[Component (UML)|components]] of the system;
** and how they can interact with other [[Component-based software engineering|software components]];
* how the system will run;
* how entities interact with others (components and interfaces);
* external [[user interface]].

Although originally intended for object-oriented design documentation, UML has been extended to a larger set of design documentation (as listed above),&lt;ref&gt;Satish Mishra (1997). [http://www2.informatik.hu-berlin.de/~hs/Lehre/2004-WS_SWQS/20050107_Ex_UML.ppt "Visual Modeling &amp; Unified Modeling Language (UML): Introduction to UML"]. Rational Software Corporation. Accessed 9 November 2008.&lt;/ref&gt; and been found useful in many contexts.&lt;ref name="UML, Success Stories"&gt;{{cite web|url=http://www.uml.org/uml_success_stories/index.htm|title=UML, Success Stories|accessdate=9 April 2014}}&lt;/ref&gt;

=== Software development methods ===

UML is not a development method by itself;&lt;ref&gt;John Hunt (2000). ''The Unified Process for Practitioners: Object-oriented Design, UML and Java''. Springer, 2000. {{ISBN|1-85233-275-1}}. p.5.door&lt;/ref&gt; however, it was designed to be compatible with the leading object-oriented software development methods of its time, for example [[Object-modeling technique|OMT]], [[Booch method]], [[Objectory]] and especially [[Rational Unified Process|RUP]] that it was originally intended to be used with when work began at Rational Software.

=== Modeling ===

It is important to distinguish between the UML model and the set of diagrams of a system. A diagram is a partial graphic representation of a system's model. The set of diagrams need not completely cover the model and deleting a diagram does not change the model. The model may also contain documentation that drives the model elements and diagrams (such as written use cases).

UML diagrams represent two different views of a system model:&lt;ref&gt;Jon Holt Institution of Electrical Engineers (2004). ''UML for Systems Engineering: Watching the Wheels'' IET, 2004, {{ISBN|0-86341-354-4}}. p.58&lt;/ref&gt;

* Static (or ''structural'') view: emphasizes the static structure of the system using objects, attributes, operations and relationships. It includes [[class diagram]]s and [[composite structure diagram]]s.
* Dynamic (or ''behavioral'') view: emphasizes the dynamic behavior of the system by showing collaborations among objects and changes to the internal states of objects. This view includes [[sequence diagram]]s, [[activity diagram]]s and [[UML state machine|state machine diagrams]].

UML models can be exchanged among UML tools by using the [[XML Metadata Interchange]] (XMI) format.

In UML, one of the key tools for behavior modelling is the use-case model, caused by [[OOSE]]. Use cases are a way of specifying required usages of a system. Typically, they are used to capture the requirements of a system, that is, what a system is supposed to do.&lt;ref&gt;Manuel Almendros-Jiménez, Jesús &amp; Iribarne, Luis. (2007). Describing Use-Case Relationships with Sequence Diagrams. Comput. J.. 50. 116-128. 10.1093/comjnl/bxl053. &lt;/ref&gt;

== Diagrams ==
{{UML diagram types}}

UML 2 has many types of diagrams, which are divided into two categories.&lt;ref name=":0" /&gt; Some types represent ''structural'' information, and the rest represent general types of ''behavior'', including a few that represent different aspects of ''interactions''. These diagrams can be categorized hierarchically as shown in the following class diagram:&lt;ref name=":0" /&gt;

[[File:UML diagrams overview.svg|center|600px|Hierarchy of UML 2.2 Diagrams, shown as a [[class diagram]]]]

These diagrams may all contain comments or notes explaining usage, constraint, or intent.

=== Structure diagrams ===

Structure diagrams emphasize the things that must be present in the system being modeled. Since structure diagrams represent the structure, they are used extensively in documenting the [[software architecture]] of software systems. For example, the [[component diagram]] describes how a software system is split up into components and shows the dependencies among these components.

&lt;gallery class="center"&gt;
Policy Admin Component Diagram.PNG|[[Component diagram]]
BankAccount1.svg|[[Class diagram]]
&lt;/gallery&gt;

=== Behavior diagrams ===

Behavior diagrams emphasize what must happen in the system being modeled. Since behavior diagrams illustrate the behavior of a system, they are used extensively to describe the functionality of software systems. As an example, the [[activity diagram]] describes the business and operational step-by-step activities of the components in a system.

&lt;gallery class="center"&gt;
Activity conducting.svg|[[Activity diagram]]
UML Use Case diagram.svg|[[Use case diagram]]
&lt;/gallery&gt;

=== Interaction diagrams ===

Interaction diagrams, a subset of behavior diagrams, emphasize the flow of control and data among the things in the system being modeled. For example, the [[sequence diagram]] shows how objects communicate with each other regarding a sequence of messages.

&lt;gallery class="center"&gt;
CheckEmail.svg|[[Sequence diagram]]
UML Communication diagram.svg|[[Communication diagram]]
&lt;/gallery&gt;

== Metamodeling ==
{{Main article|Meta-Object Facility}}

[[File:M0-m3.png|thumb|320px|Illustration of the Meta-Object Facility]]

The Object Management Group (OMG) has developed a [[metamodeling]] architecture to define the UML, called the [[Meta-Object Facility]].&lt;ref&gt;Iman Poernomo (2006) "[http://calcium.dcs.kcl.ac.uk/1259/1/acm-paper.pdf The Meta-Object Facility Typed]" in: ''Proceeding SAC '06 Proceedings of the 2006 ACM symposium on Applied computing''. pp. 1845-1849&lt;/ref&gt; MOF is designed as a four-layered architecture, as shown in the image at right. It provides a meta-meta model at the top, called the M3 layer. This M3-model is the language used by Meta-Object Facility to build metamodels, called M2-models.

The most prominent example of a Layer 2 Meta-Object Facility model is the UML metamodel, which describes the UML itself. These M2-models describe elements of the M1-layer, and thus M1-models. These would be, for example, models written in UML. The last layer is the M0-layer or data layer. It is used to describe runtime instances of the system.&lt;ref&gt;{{cite web|url=http://www.omg.org/spec/UML/2.4.1/Infrastructure/PDF/ |title=UML 2.4.1 Infrastructure |publisher=Omg.org |date=2011-08-05 |accessdate=2014-04-10}}&lt;/ref&gt;

The meta-model can be extended using a mechanism called [[stereotype (UML)|stereotyping]]. This has been criticised as being insufficient/untenable by [[Brian Henderson-Sellers]] and Cesar Gonzalez-Perez in "Uses and Abuses of the Stereotype Mechanism in UML 1.x and 2.0".&lt;ref name="UsesAbusesStereotype"&gt;B. Henderson-Sellers; C. Gonzalez-Perez (2006). "Uses and Abuses of the Stereotype Mechanism in UML 1.x and 2.0". in: ''Model Driven Engineering Languages and Systems''. Springer Berlin / Heidelberg.&lt;/ref&gt;

== Adoption ==

UML has been marketed for many contexts.&lt;ref name="UML, Success Stories"/&gt;&lt;ref&gt;{{Cite web|url = http://www.drdobbs.com/architecture-and-design/uml-25-do-you-even-care/240163702?queryText=uml|title = UML 2.5: Do you even care?}} "UML truly is ubiquitous"&lt;/ref&gt;

It has been treated, at times, as a design [[no silver bullet|silver bullet]], which leads to problems. UML misuse includes overuse (designing every part of the system with it, which is unnecessary) and assuming that novices can design with it.&lt;ref&gt;{{Cite web|url = http://queue.acm.org/detail.cfm?id=984495|title = Death by UML Fever}}&lt;/ref&gt;

It is considered a large language, with many [[Syntax (programming languages)|constructs]]. Some people (including [[Ivar Jacobson|Jacobson]]) feel that UML's size hinders learning (and therefore, using) it.&lt;ref&gt;{{Cite web|url = http://www.infoq.com/interviews/Ivar_Jacobson|title = Ivar Jacobson on UML, MDA, and the future of methodologies}}&lt;/ref&gt;

== See also ==
{{Portal|Software}}

* [[Applications of UML]]
* [[Business Process Model and Notation|Business Process Model and Notation (BPMN)]]
* [[Model-based testing]]
* [[Model-driven engineering]]
* [[Object Oriented Role Analysis and Modeling]]
* [[Systems Modeling Language|Systems Modeling Language (SysML)]]
* [[List of Unified Modeling Language tools]]

== References ==
{{FOLDOC}}

{{Reflist|30em}}

== Further reading ==

* {{cite book
 | first= Scott William
 | last = Ambler
 | year = 2004
 | url = http://www.ambysoft.com/books/theObjectPrimer.html
 | title = The Object Primer: Agile Model Driven Development with UML 2
 | publisher = Cambridge University Press
 | isbn=0-521-54018-6
}}
* {{cite book
 | first= Michael Jesse
 | last = Chonoles
 | author2=James A. Schardt
 | year = 2003
 | title = UML 2 for Dummies
 | publisher = Wiley Publishing
 | isbn=0-7645-2614-6
}}
* {{cite book
 | first = Martin
 | last = Fowler
 | authorlink = Martin Fowler
 | title = UML Distilled: A Brief Guide to the Standard Object Modeling Language
 | edition = 3rd
 | publisher = Addison-Wesley
 | isbn = 0-321-19368-7
}}
* {{cite book
 | first= Ivar
 | last = Jacobson |author2=Grady Booch |author3=James Rumbaugh
 | authorlink = Ivar Jacobson
 | year = 1998
 | title = The Unified Software Development Process
 | publisher = Addison Wesley Longman
 | isbn=0-201-57169-2
}}
* {{cite book
 | first = Robert Cecil
 | last = Martin
 | authorlink = Robert Cecil Martin
 | year = 2003
 | title = UML for Java Programmers
 | publisher = Prentice Hall
 | isbn = 0-13-142848-9
}}
* {{cite web
 | author = Noran, Ovidiu S.
 | url = http://www.cit.gu.edu.au/~noran/Docs/UMLvsIDEF.pdf
 | title = Business Modelling: UML vs. IDEF
 | format = PDF
 | accessdate = 2005-12-28
}}
* {{cite web
 | author = Horst Kargl
 | url = http://umlnotation.sparxsystems.eu/
 | title = Interactive UML Metamodel with additional Examples
 }}
* {{cite book
 | first = Magnus
 | last = Penker
 | author2=Hans-Erik Eriksson
 | author-link2= Hans-Erik Eriksson
 | year = 2000
 | title = Business Modeling with UML
 | publisher = John Wiley &amp; Sons
 | isbn = 0-471-29551-5
}}

== External links ==
{{Commons}}

{{Wikiversity|UML}}

* {{Official website}}

{{UML}}

{{Software engineering}}

{{ISO standards}}

{{Use dmy dates|date=July 2011}}

{{Authority control}}

[[Category:Architecture description language]]
[[Category:Data modeling languages]]
[[Category:Data modeling diagrams]]
[[Category:Diagrams]]
[[Category:Knowledge representation]]
[[Category:ISO standards]]
[[Category:Specification languages]]
[[Category:Unified Modeling Language| ]]
[[Category:Software modeling language]]
[[Category:Modeling languages]]</text>
      <sha1>ibviu6nf0z2x7rktwiu44k3cq7lcnaa</sha1>
    </revision>
  </page>
  <page>
    <title>Weak n-category</title>
    <ns>0</ns>
    <id>7349264</id>
    <revision>
      <id>846814254</id>
      <parentid>846059600</parentid>
      <timestamp>2018-06-21T01:59:27Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3281">{{DISPLAYTITLE:Weak ''n''-category}} 
In [[category theory]], a '''weak ''n''-category''' is a generalization of the notion of [[n-category|strict ''n''-category]] where composition and identities are not strictly associative and unital, but only associative and unital up to [[coherent equivalence]]. This generalisation only becomes noticeable at dimensions two and above where weak 2-, 3- and 4-categories are typically referred to as [[bicategory|bicategories]], [[tricategory|tricategories]], and [[tetracategory|tetracategories]]. The subject of weak n-categories is an area of ongoing research.

== History ==
There is currently{{when|date=July 2017}} much work to determine what the coherence laws for weak n-categories should be. Weak ''n''-categories have become the main object of study in [[higher category theory]]. There are basically two classes of theories: those in which the higher cells and higher compositions are realized algebraically (most remarkably the [[Michael Batanin]]'s theory of weak higher categories) and those in which more topological models are used (e.g. a higher category as a simplicial set satisfying some universality properties). 

In a terminology due to [[John Baez]] and James Dolan, a (''n'',''k'')-category is a weak ''n''-category, such that all ''h''-cells for ''h''&gt;''k'' are invertible. Some of the formalism for (''n'',''k'')-categories are much simpler than those for general ''n''-categories. In particular, several technically accessible formalisms of [[(infinity, 1)-category|(infinity,1)-categories]] are now known. Now the most popular such a formalism centers on a notion of [[quasi-category]], other approaches include a properly understood theory of simplicially enriched  categories and the approach via Segal categories; a class of examples of ''stable'' (infinity,1)-categories can be modeled (in the case of characteristics zero) also via pretriangulated [[A-infinity category|A-infinity categories]] of [[Maxim Kontsevich]]. [[model category|Quillen model categories]] are viewed as a [[presentation of an ∞-category|presentation]] of an (infinity,1)-category; however not all (infinity,1)-categories can be presented via model categories.

==See also==
* [[Bicategory]]
* [[Tricategory]]
* [[Tetracategory]]
* [[infinity category]]
* [[Opetope]]

==External links==
* [http://math.ucr.edu/home/baez/ncat.def.html ''n''-Categories – Sketch of a Definition] by [[John Baez]]
* [https://arxiv.org/abs/math.CT/0608420 Lectures on n-Categories and Cohomology] by [[John Baez]]
* Tom Leinster, Higher operads, higher categories, [https://arxiv.org/abs/math.CT/0305049 math.CT/0305049]
*{{cite book| last=Simpson| first=Carlos|authorlink=Carlos Simpson| title=Homotopy theory of higher categories|series=New Mathematical Monographs| volume=19 |
url=https://books.google.com/books/about/Homotopy_Theory_of_Higher_Categories.html?id=d1JTtOqBU6oC | publisher= [[Cambridge University Press]]|location=Cambridge| year= 2012|mr=2883823|arxiv=1001.4071|bibcode=2010arXiv1001.4071S}}
* [[Jacob Lurie]], Higher topos theory, [https://arxiv.org/abs/math.CT/0608040 math.CT/0608040], published version: [http://www.math.harvard.edu/~lurie/papers/highertopoi.pdf pdf]

[[Category:Higher category theory]]

{{categorytheory-stub}}</text>
      <sha1>7e77gkdl6h4ztmahtj09ebijk3pbwk4</sha1>
    </revision>
  </page>
  <page>
    <title>Yuktibhāṣā</title>
    <ns>0</ns>
    <id>5864214</id>
    <revision>
      <id>860685709</id>
      <parentid>843525579</parentid>
      <timestamp>2018-09-22T10:37:58Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: title, issue, doi-broken-date, isbn. Removed parameters. Formatted [[WP:ENDASH|dashes]]. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]]; [[Category:Pages_with_DOIs_inactive_since_2017]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16045">{{italic title}}
'''''Yuktibhāṣā''''' ({{lang-ml|യുക്തിഭാഷ}}; "Rationale in the Malayalam/Sanskrit language"&lt;ref name=sarma/&gt;) also known as '''''Gaṇitanyāyasaṅgraha''''' ("Compendium of astronomical rationale"),&lt;ref name=sarma/&gt; is a major [[treatise]] on [[Indian mathematics|mathematics]] and [[Hindu astronomy|astronomy]], written by [[India]]n astronomer [[Jyesthadeva]] of the [[Kerala school of astronomy and mathematics|Kerala school of mathematics]] in about AD 1530.&lt;ref name="sarma"&gt;{{cite journal| author1=K V Sarma |authorlink=K. V. Sarma  | author2=S Hariharan | title=Yuktibhāṣā of Jyeṣṭhadeva: A book on rationales in Indian Mathematics and Astronomy: An analytic appraisal
|url=http://www.new.dli.ernet.in/insa/INSA_1/20005ac0_185.pdf
| journal=Indian Journal of History of Science
| volume=26
| issue=2
| date=1991
| accessdate=2006-07-09
|format=PDF |archiveurl = https://web.archive.org/web/20060928203221/http://www.new.dli.ernet.in/insa/INSA_1/20005ac0_185.pdf &lt;!-- Bot retrieved archive --&gt; |archivedate = 2006-09-28}}
&lt;/ref&gt; The treatise, written in Malayalam, is a consolidation of the discoveries by [[Madhava of Sangamagrama]], [[Nilakantha Somayaji]],  [[Parameshvara]], [[Jyeshtadeva]], [[Achyuta Pisharati]] and other astronomer-mathematicians of the Kerala school. ''Yuktibhasa'' is mainly based on Nilakantha's ''[[Tantrasangraha|Tantra Samgraha]]''.&lt;ref name="infinity"&gt;{{cite web| publisher=D.P. Agrawal — Infinity Foundation  |work=Indian Mathemematics|url=http://www.infinityfoundation.com/mandala/t_es/t_es_agraw_kerala.htm| title=The Kerala School, European Mathematics and Navigation| accessdate=2006-07-09}}
&lt;/ref&gt; It is considered, possibly the first text, on the foundations of [[calculus]] and predates those of [[Europe]]an mathematicians such as [[James Gregory (mathematician)|James Gregory]] and Newton by many{{weasel inline|date=April 2017}} centuries.&lt;ref name="MAT 314"&gt;{{cite web|publisher=Canisius College|work=MAT 314|url=http://www.canisius.edu/topos/rajeev.asp|title=Neither Newton nor Leibniz - The Pre-History of Calculus and Celestial Mechanics in Medieval Kerala|accessdate=2006-07-09|deadurl=yes|archiveurl=https://web.archive.org/web/20060806040307/http://www.canisius.edu/topos/rajeev.asp|archivedate=6 August 2006|df=dmy-all}}&lt;/ref&gt;&lt;ref name="scotlnd"&gt;{{cite web| publisher=School of Mathematics and Statistics University of St Andrews, Scotland  |work=Indian Maths|url=http://www-history.mcs.st-andrews.ac.uk/HistTopics/Indian_mathematics.html| title=An overview of Indian mathematics| accessdate=2006-07-07}}&lt;/ref&gt;&lt;ref name="pdffile3"&gt;{{cite web|publisher=Prof.C.G.Ramachandran Nair|work=Government of Kerala — Kerala Call, September 2004|url=http://www.kerala.gov.in/keralcallsep04/p22-24.pdf|title=Science and technology in free India|accessdate=2006-07-09|format=PDF|deadurl=yes|archiveurl=https://web.archive.org/web/20060821195309/http://www.kerala.gov.in/keralcallsep04/p22-24.pdf|archivedate=21 August 2006|df=dmy-all}}&lt;/ref&gt;&lt;ref name="charles"&gt;{{Citation 
 | author =Charles Whish 
 | author-link =C.M. Whish
 | date = 1834
 | title = On the Hindu Quadrature of the circle and the infinite series of the proportion of the circumference to the diameter exhibited in the four Sastras, the Tantra Sahgraham, Yucti Bhasha, Carana Padhati and Sadratnamala
 | journal = Transactions of the Royal Asiatic Society of Great Britain and Ireland
 | doi=10.1017/S0950473700001221
 | volume=3
 | issue=3
 | pages=509–523
 | jstor=25581775
}}&lt;/ref&gt; The treatise was largely unnoticed as the book was written in the local language of Malayalam and it was thought that many Indian ideas in astronomy and computation lacked proofs or foundations. Yuktibhasa however demonstrates founding principles and the development and proofs of theorems.&lt;ref&gt;{{cite journal|doi=10.1007/sl0781-007-9029-l|title=The First Textbook of Calculus: "Yuktibhāṣā"| author=Divakaran, P.P.| journal=Journal of Indian Philosophy| volume=35|issue= 5–6|year=2007|pages=417–443| jstor=23497280|doi-broken-date=2018-09-22}}&lt;/ref&gt; However, both Oxford University and Royal Society of Great Britain have accepted that Calculus and many such pioneering mathematical theorems originated in India.&lt;ref name="MAT 314"&gt;{{cite web|publisher=Canisius College|work=MAT 314|url=http://www.canisius.edu/topos/rajeev.asp|title=Neither Newton nor Leibniz - The Pre-History of Calculus and Celestial Mechanics in Medieval Kerala|accessdate=2006-07-09|deadurl=yes|archiveurl=https://web.archive.org/web/20060806040307/http://www.canisius.edu/topos/rajeev.asp|archivedate=6 August 2006|df=dmy-all}}&lt;/ref&gt;&lt;ref name="scotlnd"&gt;{{cite web| publisher=School of Mathematics and Statistics University of St Andrews, Scotland  |work=Indian Maths|url=http://www-history.mcs.st-andrews.ac.uk/HistTopics/Indian_mathematics.html| title=An overview of Indian mathematics| accessdate=2006-07-07}}&lt;/ref&gt;&lt;ref name="pdffile3"&gt;{{cite web|publisher=Prof.C.G.Ramachandran Nair|work=Government of Kerala — Kerala Call, September 2004|url=http://www.kerala.gov.in/keralcallsep04/p22-24.pdf|title=Science and technology in free India|accessdate=2006-07-09|format=PDF|deadurl=yes|archiveurl=https://web.archive.org/web/20060821195309/http://www.kerala.gov.in/keralcallsep04/p22-24.pdf|archivedate=21 August 2006|df=dmy-all}}&lt;/ref&gt;&lt;ref name="charles"&gt;{{Citation 
 | author =Charles Whish 
 | author-link =C.M. Whish
 | date = 1834
 | title = On the Hindu Quadrature of the circle and the infinite series of the proportion of the circumference to the diameter exhibited in the four Sastras, the Tantra Sahgraham, Yucti Bhasha, Carana Padhati and Sadratnamala
 | journal = Transactions of the Royal Asiatic Society of Great Britain and Ireland
 | doi=10.1017/S0950473700001221
 | volume=3
 | issue=3
 | pages=509–523
 | jstor=25581775
}}&lt;/ref&gt;

The work was unique for its time, since it contained [[Mathematical proof|proof]]s and derivations of the [[theorem]]s that it presented; something that was not usually done by any Indian [[mathematicians]] of that era.&lt;ref name="jyest"&gt;{{cite web
| publisher=School of Mathematics and Statistics University of St Andrews, Scotland  |
work=Biography of Jyesthadeva
|url=http://www-gap.dcs.st-and.ac.uk/~history/Biographies/Jyesthadeva.html
| title=Jyesthardeva
| accessdate=2006-07-07
}}
&lt;/ref&gt; Some of its important developments in analysis include: the [[infinite series]] expansion of a function, the [[power series]], the [[Taylor series]], the [[trigonometric series]] for [[sine]], [[cosine]], [[tangent (trigonometric function)|tangent]] and [[arctangent]], the second and third order Taylor series approximations of [[sine]] and [[cosine]], the power series of [[π]], π/4, [[θ]], the radius, diameter and circumference, and [[Integral test for convergence|tests of convergence]].

==Contents==
''Yuktibhasa'' contains most of the developments of earlier Kerala School mathematicians, particularly [[Madhava of Sangamagrama|Madhava]] and [[Nilakantha Somayaji|Nilakantha]]. The text is divided into two parts &amp;mdash; the former deals with [[mathematical analysis]] of [[arithmetic]], [[algebra]], [[trigonometry]] and [[geometry]], [[Logistic function|logistic]]s, [[algebraic equation|algebraic problems]], [[Fraction (mathematics)|fraction]]s, [[Rule of three (mathematics)|Rule of three]], ''Kuttakaram'', [[circle]] and disquisition on R-Sine; and the latter about astronomy.&lt;ref name="sarma"/&gt;

===Mathematics===
[[Image:Yuktibhasa.svg|200px|thumb|Explanation of the [[Law of sines|sine rule]] in ''Yuktibhasa'']]
As per the old Indian tradition of starting off new chapters with elementary content, the first four chapters of the ''Yuktibhasa'' contain elementary mathematics, such as division, proof of [[Pythagorean theorem]], [[square root]] determination, etc.&lt;ref name="pdf2"&gt;{{cite web
| publisher=Dr Sarada Rajeev |
work=The Pre-History of Calculus and Celestial Mechanics in Medieval Kerala
|url=http://www.canisius.edu/topos/archives/rajeev2.pdf
| title=The Yuktibhasa Calculus Text 
| accessdate=2006-07-09
|format=PDF}}
&lt;/ref&gt; The radical ideas are not discussed until the sixth chapter on [[circumference]] of a [[circle]].
Yuktibhasa contains the derivation and proof of the [[power series]] for [[Inverse trigonometric function|inverse tangent]], discovered by Madhava.&lt;ref name="infinity"/&gt; In the text, Jyesthadeva describes Madhava's series in the following manner:
{{cquote|The first term is the product of the given sine and radius of the desired arc divided by the cosine of the arc. The succeeding terms are obtained by a process of iteration when the first term is repeatedly multiplied by the square of the sine and divided by the square of the cosine. All the terms are then divided by the odd numbers 1, 3, 5, .... The arc is obtained by adding and subtracting respectively the terms of odd rank and those of even rank. It is laid down that the sine of the arc or that of its complement whichever is the smaller should be taken here as the given sine. Otherwise the terms obtained by this above iteration will not tend to the vanishing magnitude.}}
This yields

: &lt;math&gt; r\theta={\frac {r \sin  \theta  }{\cos  \theta
 }}-(1/3)\,r\,{\frac { \left(\sin \theta   \right) ^
{3}}{ \left(\cos  \theta   \right) ^{3}}}+(1/5)\,r\,{\frac {
 \left(\sin \theta  \right) ^{5}}{ \left(\cos  
\theta  \right) ^{5}}}-(1/7)\,r\,{\frac { \left(\sin \theta
 \right) ^{7}}{ \left(\cos \theta  \right) ^{
7}}} + \cdots&lt;/math&gt;

which further yields the theorem
:&lt;math&gt;\theta = \tan \theta - (1/3) \tan^3 \theta + (1/5) \tan^5 \theta - \cdots \ ,&lt;/math&gt;

sometimes mistakenly attributed to [[James Gregory (astronomer and mathematician)|James Gregory]], who published it in 1667.

The text also elucidates Madhava's [[series (mathematics)|infinite series]] expansion of [[π]]:

:&lt;math&gt;\frac{\pi}{4} = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \cdots + \frac{(-1)^n}{2n + 1} + \cdots&lt;/math&gt;

which he obtained from the power series expansion of the arc-tangent function.

Using a rational approximation of this series, he gave values of the number [[π]] as 3.14159265359 - correct to 11 decimals; and as 3.1415926535898 - correct to 13 decimals. These were the most accurate approximations of π after almost a thousand years.&lt;ref&gt;http://www-history.mcs.st-andrews.ac.uk/HistTopics/Pi_chronology.html Archived version https://web.archive.org/web/20171120214515/http://www-history.mcs.st-andrews.ac.uk/HistTopics/Pi_chronology.html&lt;/ref&gt;

The text describes that he gave two methods for computing the value of π.

*One of these methods is to obtain a rapidly converging series by transforming the original infinite series of π. By doing so, he obtained the infinite series

:&lt;math&gt;\pi = \sqrt{12}\left(1-{1\over 3\cdot3}+{1\over5\cdot 3^2}-{1\over7\cdot 3^3}+\cdots\right)&lt;/math&gt;

and used the first 21 terms to compute an approximation of π correct to 11 decimal places as 3.14159265359.

*The other method was to add a remainder term to the original series of π. The remainder term was used

:&lt;math&gt;\frac{n^2 + 1}{4n^3 + 5n}&lt;/math&gt;

in the infinite series expansion of &lt;math&gt;\frac{\pi}{4}&lt;/math&gt; to improve the approximation of π to 13 decimal places of accuracy when n = 76.

Apart from these, the ''Yukthibhasa'' contains many [[elementary mathematics|elementary]], and complex mathematics, including,
* Proof for the expansion of the [[sine]] and [[cosine]] functions.
* Integer solutions of systems of first degree equations (solved using a system known as ''kuttakaram'')
* Rules for finding the sines and the cosines of the sum and difference of two [[angle]]s.
* The earliest statement of and the [[Taylor series]] (only some for some functions).
* Geometric derivations of series.
* Tests of [[Convergent series|convergence]] (often attributed to [[Augustin Louis Cauchy|Cauchy]])
* Fundamentals of calculus:&lt;ref name="pdffile3"/&gt; [[derivative|differentiation]], term by term [[Integral|integration]], [[iterative method]]s for solutions of [[Nonlinearity|non-linear]] equations, and the theory that the area under a curve is its integral.

Most of these results were long before their European counterparts, to whom credit was traditionally attributed.

===Astronomy===
Chapters seven to seventeen of the text deals essentially with subjects of astronomy, viz. [[Planetary orbit]], [[Celestial sphere]], [[Right ascension|ascension]], [[declination]], directions and shadows, [[spherical trigonometry|spherical triangle]]s, [[ellipse]]s and [[parallax]] correction. The planetary theory described in the book is similar to that later adopted by [[Danish people|Danish]] astronomer [[Tycho Brahe]].&lt;ref name="brahe"&gt;{{cite web
| publisher=India Resources |
work=South Asian history
|url=http://india_resource.tripod.com/mathematics.htm
| title=Science and Mathematics in India
| accessdate=2006-07-09
}}
&lt;/ref&gt;

==Modern edition of ''Yuktibhasa''==

The importance of ''Yuktibhasa'' was brought to the attention of modern scholarship by [[C.M. Whish]] in 1834 through a paper published in the ''Transactions of the Royal Asiatic Society of Great Britain and Ireland''.  However,  an edition of the mathematics part of the text (along with notes in Malayalam) was published only in 1948 by Rama Varma Maru Thampuran and Akhileswara Aiyar.&lt;ref name=sarma/&gt; For the first time, a critical edition of the entire Malayalam text, along with English translation and detailed explanatory notes, has been brought out in two volumes by [[Springer Science+Business Media|Springer]]
in  2008.&lt;ref&gt;{{cite book|last=Sarma|first=K.V.|authorlink=K. V. Sarma|author2=Ramasubramanian, K. |author3=Srinivas, M.D. |author4=Sriram, M.S. |title=Ganita-Yukti-Bhasa (Rationales in Mathematical Astronomy) of Jyesthadeva|publisher=Springer (jointly with Hindustan Book Agency, New Delhi)|date=2008|edition=1st|series=Sources and Studies in the History of Mathematics and Physical Sciences  |volume=Volume I: Mathematics Volume II: Astronomy|pages=LXVIII, 1084|isbn=978-1-84882-072-2|url=https://www.springer.com/math/history+of+mathematics/book/978-1-84882-072-2|accessdate=17 December 2009}}&lt;/ref&gt;
A third volume presenting a critical edition of the Sanskrit Ganitayuktibhasa has been brought out by the [[Indian Institute of Advanced Study]], Shimla in 2009.&lt;ref&gt;{{cite book|last=Sarma|first=K.V.|title=Ganita Yuktibhasa|publisher=[[Indian Institute of Advanced Study]], Shimla, India|date=2009|volume=Volume III|isbn=978-81-7986-052-6|url=http://www.iias.org/p_ganita_yuktibhasa_volume-III.html|accessdate=16 December 2009|language=Malayalam, English|deadurl=yes|archiveurl=https://web.archive.org/web/20100317202603/http://www.iias.org/p_ganita_yuktibhasa_volume-III.html|archivedate=17 March 2010|df=dmy-all}}&lt;/ref&gt;

==See also==
* ''[[Ganita-yukti-bhasa]]''
* [[Indian mathematics]]
* [[Kerala school of astronomy and mathematics|Kerala School]]
* [[Kerala school of astronomy and mathematics#Possibility of transmission of Kerala School results to Europe|Possible transmission of Kerala mathematics to Europe]]

==Notes==
{{Reflist}}

==References==
&lt;div style="font-size: 90%"&gt;
* {{cite book
 | author =K V Sharma
 | author2 =S Hariharan
 | last-author-amp =yes
 | date = 1990
 | title = Yuktibhasa of Jyesthadeva — A book on rationales in Indian Mathematics and Astronomy - an analytic appraisal
 | publisher = Indian Journal of History of Science
}}
&lt;/div&gt;

==External links==
* [http://www-gap.dcs.st-and.ac.uk/~history/Biographies/Jyesthadeva.html Biography of Jyesthadeva &amp;mdash; School of Mathematics and Statistics University of St Andrews, Scotland]
{{Indian mathematics}}
{{Use dmy dates|date=October 2010}}

{{Malayalam Literature |state=collapsed}}

{{DEFAULTSORT:Yuktibhasa}}
[[Category:Astronomy books]]
[[Category:Astrological texts]]
[[Category:Indian mathematics]]
[[Category:Hindu astronomy]]
[[Category:Hindu astrology]]
[[Category:History of mathematics]]
[[Category:Kerala school]]
[[Category:Mathematics manuscripts]]</text>
      <sha1>7gcbqf52jj4l34knjh8g4dzp073f087</sha1>
    </revision>
  </page>
  <page>
    <title>Zigzag code</title>
    <ns>0</ns>
    <id>15389789</id>
    <revision>
      <id>695757834</id>
      <parentid>579216922</parentid>
      <timestamp>2015-12-18T10:31:33Z</timestamp>
      <contributor>
        <username>U2fanboi</username>
        <id>20879942</id>
      </contributor>
      <minor/>
      <comment>fixed mistake an a</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1469">{{Confuse|zigzag cipher}}
In [[coding theory]], a '''zigzag code''' is a type of [[Linear code|linear]] [[error-correcting code]] introduced by {{harvtxt|Ping|Huang|Phamdo|2001}}.&lt;ref&gt;{{citation
 | last1 = Ping | first1 = Li
 | last2 = Huang | first2 = Xiaoling
 | last3 = Phamdo | first3 = Nam
 | doi = 10.1109/18.910590
 | mr = 1820492
 | issue = 2
 | journal = [[IEEE Transactions on Information Theory]]
 | pages = 800–807
 | title = Zigzag codes and concatenated zigzag codes
 | volume = 47
 | year = 2001}}.&lt;/ref&gt; They are defined by partitioning the input data into segments of fixed size, and adding sequence of check bits to the data, where each check bit is the [[exclusive or]] of the bits in a single segment and of the previous check bit in the sequence.
 
The [[code rate]] is high: {{math|''J''/(''J'' + 1)}} where {{mvar|J}} is the number of bits per segment. Its worst-case ability to correct transmission errors is very limited: in the worst case it can only detect a single bit error and cannot correct any errors. However, it works better in the [[Soft-decision decoder|soft-decision model of decoding]]: its regular structure allows the task of finding a [[Decoding methods#Maximum likelihood decoding|maximum-likelihood decoding]] or a posteriori probability decoding to be performed in constant time per input bit.
 
==References==
{{reflist}}

[[Category:Coding theory]]
[[Category:Error detection and correction]]

{{telecommunications-stub}}</text>
      <sha1>2v3ezc6lcjndoiwevfvubh4ib7ftcu4</sha1>
    </revision>
  </page>
</mediawiki>
