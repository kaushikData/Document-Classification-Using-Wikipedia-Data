<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>AA postulate</title>
    <ns>0</ns>
    <id>1406077</id>
    <revision>
      <id>813072302</id>
      <parentid>813072227</parentid>
      <timestamp>2017-12-01T16:10:38Z</timestamp>
      <contributor>
        <username>Shellwood</username>
        <id>2366721</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/205.121.85.14|205.121.85.14]] ([[User talk:205.121.85.14|talk]]) ([[WP:HG|HG]]) (3.1.22)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1571">{{one source|date=November 2010}}
[[Image:AA Postulate Helper.png|right]]
In [[Euclidean geometry]], the '''AA postulate'''  states that two [[triangle]]s are similar if they have two corresponding [[angle]]s [[congruence (geometry)|congruent]].

The AA postulate follows from the fact that the sum of the [[interior angle]]s of a [[triangle]] is always equal to 180°. By knowing two angles, such as 32° and 64° degrees, we know that the next angle is 84°, because 180-(32+64)=84. (This is sometimes referred to as the AAA Postulate—which is true in all respects, but two angles are entirely sufficient.)

The postulate can be better understood by working in reverse order.  The two triangles on grids A and B are [[Similarity (geometry)|similar]], by a 1.5 [[Scaling (geometry)|dilation]] from A to B.  If they are aligned, as in grid C, it is apparent that the angle on the origin is congruent with the other (D). We also know that the pair of sides opposite the origin are parallel.  We know this because the pairs of sides around them are similar, stem from the same point, and line up with each other. We can then look at the sides around the parallels as [[Transversal (geometry)|transversal]]s, and therefore the corresponding angles are congruent. Using this reasoning we can tell that similar triangles have congruent angles.

==References==
* http://hanlonmath.com/pdfFiles/464Chapter7Sim.Poly.pdf '''''(Unused Source)'''''

{{DEFAULTSORT:Aa Postulate}}
[[Category:Elementary geometry]]
[[Category:Triangle geometry]]
[[Category:Euclidean plane geometry]]</text>
      <sha1>rlq7o60vocp67w7d3hdkvdpirrxhuk8</sha1>
    </revision>
  </page>
  <page>
    <title>Affine action</title>
    <ns>0</ns>
    <id>7020888</id>
    <revision>
      <id>558120955</id>
      <parentid>335995592</parentid>
      <timestamp>2013-06-03T12:46:20Z</timestamp>
      <contributor>
        <username>Mark L MacDonald</username>
        <id>16852149</id>
      </contributor>
      <comment>fix disambig link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="907">Let &lt;math&gt;W&lt;/math&gt; be the [[Weyl group]] of a [[semisimple Lie algebra]] &lt;math&gt;\mathfrak{g}&lt;/math&gt; (associate to fixed choice of a [[Cartan subalgebra]] &lt;math&gt;\mathfrak{h}&lt;/math&gt;).  Assume that a set of [[Simple root (root system)|simple root]]s in &lt;math&gt;\mathfrak{h}^*&lt;/math&gt; is chosen. 

The ''affine action'' (also called the ''dot action'') of the Weyl group on the space &lt;math&gt;\mathfrak{h}^*&lt;/math&gt; is

:&lt;math&gt;w\cdot \lambda:=w(\lambda+\delta)-\delta&lt;/math&gt;

where &lt;math&gt;\delta&lt;/math&gt; is the sum of all [[fundamental weight]]s, or, equivalently, the half of the sum of all [[positive root]]s.

==References==
* {{citation|first1=Robert J.|last1=Baston|first2=Michael G.|last2=Eastwood|authorlink2=Michael Eastwood|title=The Penrose Transform: its Interaction with Representation Theory|publisher=Oxford University Press|year=1989}}.

[[Category:Representation theory of Lie algebras]]

{{algebra-stub}}</text>
      <sha1>8x0gdqrcgxspojegidnhim86lp1x33f</sha1>
    </revision>
  </page>
  <page>
    <title>Affine focal set</title>
    <ns>0</ns>
    <id>18906055</id>
    <revision>
      <id>868846857</id>
      <parentid>837637998</parentid>
      <timestamp>2018-11-14T20:48:50Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11732">{{multiple issues|
{{orphan|date=June 2010}}
{{inappropriate person|article|we|date=November 2012}}
}}

In mathematics, and especially [[affine differential geometry]], the '''affine focal set''' of a [[Smooth manifold|smooth]] [[submanifold]] ''M'' [[Embedding|embedded]] in a smooth [[manifold]] ''N'' is the [[Caustic (mathematics)|caustic]] generated by the affine normal lines. It can be realised as the bifurcation set of a certain family of [[Function (mathematics)|functions]]. The bifurcation set is the set of parameter values of the family which yield functions with degenerate [[Singularity theory|singularities]]. This is not the same as the [[bifurcation diagram]] in [[dynamical systems]].

Assume that ''M'' is an ''n''-[[dimensional]] smooth [[hypersurface]] in real (''n''+1)-space. Assume that ''M'' has no points where the [[second fundamental form]] is [[degenerate form|degenerate]]. From the article [[affine differential geometry]], there exists a unique [[Transversality (mathematics)|transverse]] [[vector field]] over ''M''. This is the affine normal vector field, or the [[Blaschke normal field]]. A special (i.e. det&amp;nbsp;=&amp;nbsp;1) [[affine transformation]] of real (''n''&amp;nbsp;+&amp;nbsp;1)-space will carry the affine normal vector field of ''M'' onto the affine normal vector field of the image of ''M'' under the transformation.

== Geometric interpretation ==
Consider a [[Local property|local]] [[parametrisation]] of ''M''. Let &lt;math&gt; U \subset \mathbb{R}^{n} &lt;/math&gt; be an [[open (topology)|open]] [[neighbourhood]] of 0 with coordinates &lt;math&gt;\mathbf{u} = (u_1,\ldots,u_n)&lt;/math&gt;, and let &lt;math&gt; \mathbf{X} : U \to \mathbb{R}^{n+1}&lt;/math&gt; be a smooth parametrisation of ''M'' in a neighbourhood of one of its points.

The affine normal [[vector field]] will be denoted by &lt;math&gt;\mathbf{A}&lt;/math&gt;. At each point of ''M'' it is [[Transversality (mathematics)|transverse]] to the [[tangent space]] of ''M'', i.e.

:&lt;math&gt; \mathbf{A} : U \to T_{\mathbf{X}(U)}\mathbb{R}^{n+1}. \,&lt;/math&gt;

For a fixed &lt;math&gt;\mathbf{u}_0 \in U&lt;/math&gt; the affine normal line to ''M'' at &lt;math&gt;\mathbf{X}(\mathbf{u}_0)&lt;/math&gt; may be parametrised by ''t'' where
:&lt;math&gt; t \mapsto \mathbf{X}(\mathbf{u}_0) + t \mathbf{A}(\mathbf{u}_0). &lt;/math&gt;
The affine focal set is given [[geometry|geometrically]] as the [[infinitesimal]] [[Line-line intersection|intersections]] of the ''n''-parameter family of affine normal lines. To calculate, choose an affine normal line, say at point ''p''; then look at the affine normal lines at points infinitesimally close to ''p'' and see if any intersect the one at ''p''. If ''p'' is infinitesimally close to &lt;math&gt;\mathbf{u} \in U&lt;/math&gt;, then it may be expressed as &lt;math&gt;\mathbf{u} + d\mathbf{u}&lt;/math&gt; where &lt;math&gt;d\mathbf{u}&lt;/math&gt; represents the infinitesimal difference. Thus &lt;math&gt;\mathbf{X}(\mathbf{u})&lt;/math&gt; and &lt;math&gt;\mathbf{X}(\mathbf{u} + d\mathbf{u})&lt;/math&gt; will be our ''p'' and its neighbour.

Solve for ''t'' and &lt;math&gt;d\mathbf{u}&lt;/math&gt;.
:&lt;math&gt; \mathbf{X}(\mathbf{u}) + t \mathbf{A}(\mathbf{u}) = \mathbf{X}(\mathbf{u} + d\mathbf{u}) + t \mathbf{A}(\mathbf{u} + d\mathbf{u}). &lt;/math&gt;
This can be done by using [[power series]] expansions, and is not too difficult; it is lengthy and has thus been omitted.

Recalling from the article [[affine differential geometry]], the affine shape operator ''S'' is a type (1,1)-[[tensor field]] on ''M'', and is given by &lt;math&gt; Sv = D_v\mathbf{A}&lt;/math&gt;, where ''D'' is the [[covariant derivative]] on real (''n''&amp;nbsp;+&amp;nbsp;1)-space (for those well read: it is the usual [[Riemann curvature tensor|flat]] and [[Torsion tensor|torsion]] free [[Affine connection|connexion]]).

The solutions to &lt;math&gt; \mathbf{X}(\mathbf{u}) + t \mathbf{A}(\mathbf{u}) = \mathbf{X}(\mathbf{u} + d\mathbf{u}) + t \mathbf{A}(\mathbf{u} + d\mathbf{u}) &lt;/math&gt; are when 1/''t'' is an [[eigenvalue]] of ''S'' and that &lt;math&gt;d\mathbf{u}&lt;/math&gt; is a corresponding [[eigenvector]]. The eigenvalues of ''S'' are not always distinct: there may be repeated roots, there may be complex roots, and ''S'' may not always be [[diagonalisable]].  For &lt;math&gt; 0 \le k \le [n/2]&lt;/math&gt;, where &lt;math&gt;[-]&lt;/math&gt; denotes the [[greatest integer function]], there will generically be (''n''&amp;nbsp;−&amp;nbsp;2''k'')-pieces of the affine focal set above each point ''p''. The −2''k'' corresponds to pairs of eigenvalues becoming complex (like the [[solution]] to &lt;math&gt;x^2 + a = 0&lt;/math&gt; as ''a'' changes from [[Negative number|negative]] to [[Positive number|positive]]).

The affine focal set need not be made up of smooth hypersurfaces. In fact, for a [[Generic property|generic]] hypersurface ''M'', the affine focal set will have [[Mathematical singularity|singularities]]. The singularities could be found by calculation, but that may be difficult, and there is no idea of what the singularity looks like up to [[diffeomorphism]]. Using [[singularity theory]] gives much more information.

== Singularity theory approach ==

The idea here is to define a family of [[Function (mathematics)|functions]] over ''M''. The family will have the ambient real (''n''&amp;nbsp;+&amp;nbsp;1)-space as its parameter space, i.e. for each choice of ambient point there is function defined over ''M''. This family is the family of affine distance functions:

:&lt;math&gt; \Delta : \mathbb{R}^{n+1} \times  M \to \mathbb{R}.\, &lt;/math&gt;

Given an ambient point &lt;math&gt;\mathbf{x}&lt;/math&gt; and a surface point ''p'', it is possible to decompose the [[Chord (geometry)|chord]] joining ''p'' to &lt;math&gt;\mathbf{x}&lt;/math&gt; as a [[tangential]] component and a transverse component [[Parallel (geometry)|parallel]] to &lt;math&gt;\mathbf{A}&lt;/math&gt;. The value of Δ is given implicitly in the equation

:&lt;math&gt; \mathbf{x} - p = Z(\mathbf{x},p) + \Delta(\mathbf{x},p) \mathbf{A}(p) &lt;/math&gt;

where ''Z'' is a [[Tangent space|tangent vector]]. We now seek the bifurcation set of the family Δ, i.e. the ambient points for which the restricted function
:&lt;math&gt; \Delta : \{\mathbf{x}\} \times M \to \mathbb{R} &lt;/math&gt;
has degenerate singularity at some ''p''. A function has degenerate singularity if both the [[Jacobian matrix and determinant|Jacobian matrix]] of first order [[partial derivatives]] and the [[Hessian matrix]] of second order partial derivatives have zero [[determinant]].

To discover if the Jacobian matrix has zero determinant we differentiate the equation ''x - p = Z + ΔA''. Let ''X'' be a tangent vector to ''M'', and differentiate in that direction:
:&lt;math&gt; D_X(\mathbf{x}-p) = D_X(Z + \Delta \mathbf{A}), &lt;/math&gt;

:&lt;math&gt; -X = \nabla_XZ + h(X,Z)\mathbf{A} + d_X\Delta \mathbf{A} - \Delta SX , &lt;/math&gt;

:&lt;math&gt; (\nabla_XZ + (I - \Delta S)X) + (h(X,Z) + d_X\Delta)\mathbf{A} = 0 , &lt;/math&gt;

where ''I'' is the [[Identity element|identity]]. This tells us that &lt;math&gt;\nabla_XZ = (\Delta S - I)X&lt;/math&gt; and &lt;math&gt; h(X,Z) = -d_X\Delta&lt;/math&gt;. The last equality says that we have the following equation of [[differential form|differential one-forms]] &lt;math&gt; h(-,Z) = d\Delta&lt;/math&gt;. The Jacobian matrix will have zero determinant if, and only if, &lt;math&gt;d\Delta&lt;/math&gt; is [[degenerate form|degenerate]] as a one-form, i.e. &lt;math&gt;d_X\Delta = 0&lt;/math&gt; for all tangent vectors ''X''.
Since &lt;math&gt; h(-,Z) = d\Delta&lt;/math&gt; it follows that &lt;math&gt;d\Delta&lt;/math&gt; is degenerate if, and only if, &lt;math&gt;h(-,Z)&lt;/math&gt; is degenerate. Since  ''h'' is a non-degenerate two-form it follows that ''Z = 0''. Notice that since ''M'' has a non-degenerate second fundamental form it follows that ''h'' is a non-degenerate two-form. Since ''Z = 0'' the set of ambient points ''x'' for which the restricted function &lt;math&gt; \Delta : \{\mathbf{x}\} \times M \to \mathbb{R} &lt;/math&gt; has a singularity at some ''p'' is the affine normal line to ''M'' at ''p''.

To compute the Hessian matrix we consider the differential two-form &lt;math&gt;(X,Y) \mapsto d_Y(d_X\Delta)&lt;/math&gt;. This is the two-form whose matrix representation is the Hessian matrix. We have already seen that &lt;math&gt; h(X,Z) = -d_X\Delta&lt;/math&gt; we see that &lt;math&gt;d_Y(d_X\Delta) = -d_Y(h(X,Z)).&lt;/math&gt; We have
:&lt;math&gt; (X,Y) \mapsto -d_Y(h(X,Z)) = -(\nabla_Yh)(X,Z) - h(\nabla_YX,Z) - h(X,\nabla_YZ) &lt;/math&gt;.
Now assume that Δ has a singularity at ''p'', i.e. Z = 0, then we have the two-form
:&lt;math&gt; (X,Y) \mapsto - h(X,\nabla_YZ) &lt;/math&gt;. 
We have also seen that &lt;math&gt;\nabla_XZ = (\Delta S - I)X&lt;/math&gt;, and so the two-form becomes
:&lt;math&gt; (X,Y) \mapsto h(X,(I- \Delta S)Y) &lt;/math&gt;. 
This is degenerate as a two-form if, and only if, there exists non-zero ''X'' for which it is zero for all ''Y''. Since ''h'' is non-degenerate it must be that &lt;math&gt;\det(I- \Delta S) = 0&lt;/math&gt; and &lt;math&gt;Y \in \ker(I- \Delta S)&lt;/math&gt;. So the singularity is degenerate if, and only if, the ambient point ''x'' lies on the affine normal line to ''p'' and the reciprocal of its distance from ''p'' is an eigenvalue of ''S'', i.e. points &lt;math&gt;\mathbf{x} = p + t\mathbf{A}&lt;/math&gt; where 1/''t'' is an eigenvalue of ''S''. The affine focal set!

== Singular points ==
The affine focal set can be the following:
:&lt;math&gt; \{ p + t \mathbf{A}(p) : p \in M, \det(I - tS) = 0\} \ . &lt;/math&gt;
To find the singular points we simply differentiate ''p + tA'' in some tangent direction ''X'':
:&lt;math&gt; D_X(p + t \mathbf{A}) = (I-tS)X + d_Xt \mathbf{A}. &lt;/math&gt;
The affine focal set is singular if, and only if, there exists non-zero ''X'' such that &lt;math&gt;D_X(p + t \mathbf{A}) = 0&lt;/math&gt;, i.e. if, and only if, ''X'' is an eigenvector of ''S'' and the derivative of ''t'' in that direction is zero. This means that the derivative of an affine [[principal curvature]] in its own affine [[principal curvature|principal direction]] is zero.

== Local structure ==

We can use the standard ideas in singularity theory to classify, up to local diffeomorphism, the affine focal set. If the family of affine distance functions can be shown to be a certain kind of family then the local structure is known. We want the family of affine distance functions to be a [[unfolding (geometry)|versal unfolding]] of the singularities which arise.

The affine focal set of a [[plane curve]] will [[generic property|generically]] consist of smooth pieces of curve and ordinary [[Cusp (singularity)|cusp]] points (semi-cubical palabara|semi-cubical parabolae).

The affine focal set of a surface in three-space will generically consist of smooth pieces of surface, [[cusp (singularity)|cuspidal cylinder points]] (&lt;math&gt;A_3&lt;/math&gt;), [[Catastrophe theory#Swallowtail catastrophe|swallowtail points]] (&lt;math&gt;A_4&lt;/math&gt;), [[Catastrophe theory#Hyperbolic umbilic catastrophe|purse points]] (&lt;math&gt;D_4^+&lt;/math&gt;), and [[Catastrophe theory#Elliptic umbilic catastrophe|pyramid points]] (&lt;math&gt;D_4^-&lt;/math&gt;).
The &lt;math&gt;A_k&lt;/math&gt; and &lt;math&gt;D_k&lt;/math&gt; series are as in [[Vladimir Arnold|Arnold's]] [[Catastrophe theory#Arnold's notation|list]].

The question of the local structure in much higher dimension is of great interest. For example, we were able to construct a discrete list of singularity types (up to local diffeomprhism). In much higher dimensions no such discrete list can be constructed, there are [[Modulus of continuity|functional modulii]].

== References ==
* [[V. I. Arnold]], S. M. Gussein-Zade and A. N. Varchenko, "Singularities of differentiable maps", Volume 1, Birkhäuser, 1985.
* J. W. Bruce and  P. J. Giblin, "Curves and singularities", Second edition, Cambridge University press, 1992.
* T. E. Cecil, "Focal points and support functions", Geom. Dedicada 50, No. 3, 291 – 300, 1994. 
* D. Davis, "Affine differential geometry and singularity theory", PhD thesis, Liverpool, 2008.
* K. Nomizu and Sasaki, "Affine differential geometry", Cambridge university press, 1994.

[[Category:Differential geometry]]</text>
      <sha1>gl4alfkhmqi0rtyf7cmm2wceub9puw8</sha1>
    </revision>
  </page>
  <page>
    <title>Arbitrarily large</title>
    <ns>0</ns>
    <id>1118832</id>
    <revision>
      <id>816894102</id>
      <parentid>749320809</parentid>
      <timestamp>2017-12-24T13:07:26Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.1) ([[User:Balon Greyjoy|Balon Greyjoy]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2682">In [[mathematics]], the phrases '''arbitrarily large''', '''arbitrarily small''', and '''arbitrarily long''' are used in statements such as:

: "&amp;fnof;(''x'') is non-negative for arbitrarily large ''x''."

which is shorthand for:

: "For every real number ''n'', &amp;fnof;(''x'') is non-negative for some values of ''x'' greater than ''n''."

"Arbitrarily large" is not equivalent to "[[sufficiently large]]". For instance, while it is true that prime numbers can be arbitrarily large since there are an [[Euclid's theorem|infinite number]] of them, it is not true that all sufficiently large numbers are prime. "Arbitrarily large" does not mean "[[infinitely large]]" because although prime numbers can be arbitrarily large, an infinitely large prime does not exist since all prime numbers (as well as all other integers) are finite.&lt;ref&gt;[http://www.xamuel.com/arbitrary-and-infinity/ Infinitely Large vs. Arbitratily Large.] {{webarchive|url=https://web.archive.org/web/20120222215520/http://www.xamuel.com/arbitrary-and-infinity/ |date=2012-02-22 }} Accessed 21 February 2012.&lt;/ref&gt;

In some cases, phrases such as "P(''x'') is true for arbitrarily large ''x''" are used primarily for emphasis, as in "P(''x'') is true for all ''x'', no matter how large ''x'' is."  In these cases, the phrase "arbitrarily large" does not have the meaning indicated above but is in fact logically synonymous with "all."

To say that there are "arbitrarily long [[primes in arithmetic progressions|arithmetic progressions of prime numbers]]" does not mean that there exists any infinitely long arithmetic progression of prime numbers (there is not), nor that there exists any particular arithmetic progression of prime numbers that is in some sense "arbitrarily long", but rather that no matter how large a number ''n'' is, there exists some arithmetic progression of prime numbers of length at least ''n''.&lt;ref&gt;[http://www.ccs.neu.edu/home/matthias/HtDP2e/htdp2e-part2.html 4 Arbitrarily Large Data.] {{webarchive |url=https://web.archive.org/web/20120222213518/http://www.ccs.neu.edu/home/matthias/HtDP2e/htdp2e-part2.html |date=February 22, 2012 }} Accessed 21 February 2012&lt;/ref&gt;

The statement "&amp;fnof;(''x'') is non-negative for arbitrarily large ''x''." could be rewritten as:

: &lt;math&gt;\forall n \in \mathbb{R} \mbox{, } \exists x \in \mathbb{R} \mbox{ such that } x &gt; n \land f(x) \ge 0&lt;/math&gt;

Using "sufficiently large" instead yields:

: &lt;math&gt;\exists n \in \mathbb{R} \mbox{ such that } \forall x \in \mathbb{R} \mbox{, } x &gt; n \Rightarrow f(x) \ge 0&lt;/math&gt;

==References==
&lt;references/&gt;

==See also==
*[[Sufficiently large]]
*[[Mathematical jargon]]

[[Category:Mathematical terminology]]</text>
      <sha1>7qesxsmelb8fxeii7q2f1g0e2g58ozs</sha1>
    </revision>
  </page>
  <page>
    <title>Arithmetic number</title>
    <ns>0</ns>
    <id>36551969</id>
    <revision>
      <id>826635033</id>
      <parentid>717122065</parentid>
      <timestamp>2018-02-20T05:42:08Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Density */√ glyph -&gt; {{radic}} using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2468">[[File:Arithmetic number Cuisenaire rods 6.png|thumb|Demonstration, with [[Cuisenaire rod]]s, of the arithmetic nature of the number 6]]

In [[number theory]], an '''arithmetic number''' is an [[integer]] for which the [[arithmetic mean|average]] of its [[positive number|positive]] [[divisor]]s is also an integer.  For instance, 6 is an arithmetic number because the average of its divisors is
:&lt;math&gt;\frac{1+2+3+6}{4}=3,&lt;/math&gt;
which is also an integer. However, 2 is not an arithmetic number because its only divisors are 1 and 2, and their average 3/2 is not an integer.

The first numbers in the [[sequence]] of arithmetic numbers are
:1, 3, 5, 6, 7, 11, 13, 14, 15, 17, 19, 20, 21, 22, 23, 27, 29, 30, 31, 33, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, ... {{OEIS|id=A003601}}.

==Density==
It is known that the [[natural density]] of such numbers is 1:&lt;ref name=G76&gt;Guy (2004) p.76&lt;/ref&gt; indeed, the proportion of numbers less than ''X'' which are not arithmetic is [[Asymptotic analysis|asymptotically]]&lt;ref name=BEPS&gt;{{cite book | zbl=0478.10027 | last1=Bateman | first1=Paul T. | author1-link=Paul T. Bateman | last2=Erdős | first2=Paul | author2-link=Paul Erdős | last3=Pomerance | first3=Carl | author3-link=Carl Pomerance | last4=Straus | first4=E.G. | author4-link=Ernst G. Straus | chapter=The arithmetic mean of the divisors of an integer| title=Analytic number theory, Proc. Conf., Temple Univ., 1980 | editor-first=M.I. | editor-last=Knopp | editor-link=Marvin Knopp | series=Lecture Notes in Mathematics | volume=899 | pages=197–220 | year=1981 | publisher=[[Springer-Verlag]] | url = http://www.math.dartmouth.edu/~carlp/PDF/31.pdf}}&lt;/ref&gt;

:&lt;math&gt; \exp\left( { -c \sqrt{\log\log X} } \right) &lt;/math&gt;

where ''c'' = 2{{radic|log 2}} + o(1).

A number ''N'' is arithmetic if the [[number of divisors]] ''d''(''N'') divides the [[Sum-of-divisors function|sum of divisors]] σ(''N'').  It is known that the [[Natural density|density]] of integers ''N'' obeying the stronger condition that ''d''(''N'')&lt;sup&gt;2&lt;/sup&gt; divides  σ(''N'') is 1/2.&lt;ref name=G76/&gt;&lt;ref name=BEPS/&gt;

==Notes==
{{reflist}}

== References ==
* {{cite book |last=Guy |first=Richard K. |authorlink=Richard K. Guy |title=Unsolved problems in number theory |publisher=[[Springer-Verlag]] |edition=3rd |year=2004 |isbn=978-0-387-20860-2 |zbl=1058.11001 |at=B2}}

{{Classes of natural numbers}}
{{Divisor classes}}

[[Category:Divisor function]]
[[Category:Integer sequences]]</text>
      <sha1>am3oji5ol0pz70zjy2ez8p5lc3jxpen</sha1>
    </revision>
  </page>
  <page>
    <title>Composition (combinatorics)</title>
    <ns>0</ns>
    <id>550741</id>
    <revision>
      <id>861179752</id>
      <parentid>861157086</parentid>
      <timestamp>2018-09-25T17:12:07Z</timestamp>
      <contributor>
        <username>Joel B. Lewis</username>
        <id>13974845</id>
      </contributor>
      <minor/>
      <comment>/* Number of compositions */ swap roles of n and k here because why not</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5647">{{Other uses of|Composition}}

In [[mathematics]], a '''composition''' of an [[integer]] ''n'' is a way of writing ''n'' as the [[summation|sum]] of a sequence of (strictly) [[positive integer]]s. Two sequences that differ in the order of their terms define different compositions of their sum, while they are considered to define the same [[partition (number theory)|partition]] of that number. Every integer has finitely many distinct compositions. Negative numbers do not have any compositions, but 0 has one composition, the empty sequence. Each positive integer ''n'' has &lt;span style="white-space:nowrap" &gt;2&lt;sup&gt;''n''−1&lt;/sup&gt;&lt;/span&gt; distinct compositions.
[[File:Binary and compositions 4.svg|thumb|center|600px|[[Bijection]] between 3 bit [[binary numeral system|binary numbers]] and compositions of 4]]
A '''weak composition''' of an integer ''n'' is similar to a composition of ''n'', but allowing terms of the sequence to be zero: it is a way of writing ''n'' as the sum of a sequence of [[non-negative integer]]s. As a consequence every positive integer admits infinitely many weak compositions (if their length is not bounded). Adding a number of terms 0 to the ''end'' of a weak composition is usually not considered to define a different weak composition; in other words, weak compositions are assumed to be implicitly extended indefinitely by terms&amp;nbsp;0.

To further generalize, an ''' ''A''-restricted composition''' of an integer ''n'', for a subset ''A'' of the (nonnegative or positive) integers, is an ordered collection of one or more elements in ''A'' whose sum is ''n''.&lt;ref&gt;
{{cite journal
 | last1=Heubach | first1=Silvia
 | last2=Mansour | first2=Toufik
 | year=2004
 | title=Compositions of n with parts in a set
 | journal=[[Congressus Numerantium]] | volume=168 | pages=33–51
 | url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.484.5148&amp;rep=rep1&amp;type=pdf
}}&lt;/ref&gt;

== Examples ==
[[File:Compositions of 6.svg|thumb|The 32 compositions of 6&lt;br&gt;&lt;br&gt;1 + 1 + 1 + 1 + 1 + 1&lt;br&gt;2 + 1 + 1 + 1 + 1&lt;br&gt;1 + 2 + 1 + 1 + 1&lt;br&gt;. . .&lt;br&gt;1 + 5&lt;br&gt;6]]
[[File:Partitions of 6.svg|thumb|The 11 partitions of 6&lt;br&gt;&lt;br&gt;1 + 1 + 1 + 1 + 1 + 1&lt;br&gt;2 + 1 + 1 + 1 + 1&lt;br&gt;3 + 1 + 1 + 1&lt;br&gt;. . .&lt;br&gt;3 + 3&lt;br&gt;6]]

The sixteen compositions of 5 are:
*5
*4 + 1
*3 + 2
*3 + 1 + 1
*2 + 3
*2 + 2 + 1
*2 + 1 + 2
*2 + 1 + 1 + 1
*1 + 4
*1 + 3 + 1
*1 + 2 + 2
*1 + 2 + 1 + 1
*1 + 1 + 3
*1 + 1 + 2 + 1
*1 + 1 + 1 + 2
*1 + 1 + 1 + 1 + 1.

Compare this with the seven partitions of 5:
*5
*4 + 1
*3 + 2
*3 + 1 + 1
*2 + 2 + 1
*2 + 1 + 1 + 1
*1 + 1 + 1 + 1 + 1.

It is possible to put constraints on the parts of the compositions.  For example the five compositions of 5 into distinct terms are:
*5
*4 + 1
*3 + 2
*2 + 3
*1 + 4.

Compare this with the three partitions of 5 into distinct terms:
*5
*4 + 1
*3 + 2.

== Number of compositions ==
Conventionally the empty composition is counted as the sole composition of 0, and there are no compositions of negative integers.
There are 2&lt;sup&gt;''n''−1&lt;/sup&gt; compositions of ''n''&amp;nbsp;&amp;ge;&amp;nbsp;1; here is a proof:

Placing either a plus sign or a comma in each of the ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 boxes of the array
:&lt;math&gt;
    \big(\,
      \overbrace{1\, \square\, 1\, \square\, \ldots\, \square\, 1\,
      \square\, 1}^n\,
    \big)
&lt;/math&gt;

produces a unique composition of ''n''. Conversely, every composition of ''n'' determines an assignment of pluses and commas. Since there are ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 binary choices, the result follows.  The same argument shows that the number of compositions of ''n'' into exactly ''k'' parts is given by the [[binomial coefficient]] &lt;math&gt;{n-1\choose k-1}&lt;/math&gt;.  Note that by summing over all possible number of parts we recover 2&lt;sup&gt;''n''−1&lt;/sup&gt; as the total number of compositions of ''n'':

: &lt;math&gt; \sum_{k=1}^n {n-1 \choose k-1} = 2^{n-1}.&lt;/math&gt;

For weak compositions, the number is &lt;math&gt;{n+k-1\choose k-1}&lt;/math&gt;, since each ''k''-composition of ''n''&amp;nbsp;+&amp;nbsp;''k'' corresponds to a weak one of&amp;nbsp;''n'' by the rule [''a''&amp;nbsp;+&amp;nbsp;''b''&amp;nbsp;+&amp;nbsp;...&amp;nbsp;+&amp;nbsp;''c''&amp;nbsp;=&amp;nbsp;''n''&amp;nbsp;+&amp;nbsp;''k'']&amp;nbsp;&amp;rarr;&amp;nbsp;[(''a''&amp;nbsp;&amp;minus;&amp;nbsp;1)&amp;nbsp;+&amp;nbsp;(''b''&amp;nbsp;&amp;minus;&amp;nbsp;1)&amp;nbsp;+&amp;nbsp;...&amp;nbsp;+&amp;nbsp;(''c''&amp;nbsp;&amp;minus;&amp;nbsp;1)&amp;nbsp;=&amp;nbsp;''n''].  It follows from this formula that the number of weak compositions of ''n'' into exactly ''k'' parts equals the number of weak compositions of ''k'' − 1 into exactly ''n'' + 1 parts.

For ''A''-restricted compositions, the number of compositions of ''n'' into exactly ''k'' parts is given by the extended binomial (or polynomial) coefficient &lt;math&gt;\binom{n}{k}_{(1)_{a\in A}}=[x^k]\left(\sum_{a\in A} x^a\right)^n&lt;/math&gt;, where the square brackets indicate the extraction of the [[coefficient]] of &lt;math&gt;x^k&lt;/math&gt; in the polynomial that follows it.&lt;ref&gt;
{{cite journal
 | last1=Eger | first1=Steffen
 | year=2013
 | title=Restricted weighted integer compositions and extended binomial coefficients
 | journal=[[Journal of Integer Sequences]] | volume=16
 | url=https://cs.uwaterloo.ca/journals/JIS/VOL16/Eger/eger6.pdf
}}&lt;/ref&gt;

== See also ==
* [[Stars and bars (combinatorics)]]

== References ==
{{reflist}}
* {{ cite book | title=Combinatorics of Compositions and Words | first1=Silvia | last1=Heubach | first2=Toufik | last2=Mansour | series=Discrete Mathematics and its Applications | location=Boca Raton, Florida | publisher=CRC Press | year=2009 | isbn=978-1-4200-7267-9 | zbl=1184.68373 }}

== External links ==
* [http://www.se16.info/js/partitions.htm Partition and composition calculator]

[[Category:Number theory]]
[[Category:Combinatorics]]</text>
      <sha1>7zuiuq0bbpnggtabxoh03tspc21uaky</sha1>
    </revision>
  </page>
  <page>
    <title>Computational transportation science</title>
    <ns>0</ns>
    <id>26910524</id>
    <revision>
      <id>795071183</id>
      <parentid>784863324</parentid>
      <timestamp>2017-08-11T20:33:17Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.5beta)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3020">{{Other uses|CTS (disambiguation){{!}}CTS}}
{{Primary sources|date=April 2010}}

'''Computational Transportation  Science''' (CTS) is an emerging discipline that combines [[computer science]] and engineering with the modeling, planning, and economic aspects of [[transport]]. The discipline studies how to improve the safety, mobility, and sustainability of the transport system by taking advantage of [[information technologies]] and [[ubiquitous computing]]. A list of subjects encompassed by CTS can be found at include.&lt;ref name="dagstuhl10"/&gt;

Computational Transportation Science is an emerging discipline going beyond vehicular technology, addressing pedestrian systems on hand-held devices but also issues such as transport [[data mining]] (or movement analysis), as well as data management aspects. CTS allows for an increasing flexibility of the system as local and autonomous negotiations between transport peers, partners and supporting infrastructure are allowed. Thus, CTS provides means to study localized computing, self-organization, cooperation and simulation of transport systems.

Several academic conferences on CTS have been held up to date:
* The Fourth ACM SIGSPATIAL International Workshop on Computational Transportation Science&lt;ref name="iwcts11"/&gt;
* The Third ACM SIGSPATIAL International Workshop on Computational Transportation Science&lt;ref name="iwcts10"/&gt;
* Dagstuhl Seminar 10121 on Computational Transportation Science&lt;ref name="dagstuhl10"/&gt;
* The Second International Workshop on Computational Transportation Science&lt;ref name="iwcts09"/&gt;
* The First International Workshop on Computational Transportation Science&lt;ref name="iwcts08"/&gt;

There is also an IGERT PHD program on Computational Transportation Science at the University of Illinois at Chicago.&lt;ref name="igertPHD"/&gt;

==References==
{{Reflist|refs=
&lt;ref name="iwcts11"&gt;[http://ctscience.org/node/13 The Fourth SIGSPATIAL International Workshop on Computational Transportation Science] {{webarchive|url=https://web.archive.org/web/20111015233518/http://www.ctscience.org/node/13 |date=2011-10-15 }}&lt;/ref&gt;
&lt;ref name="iwcts10"&gt;[http://www.ctscience.org/node/5/ The Third ACM SIGSPATIAL International Workshop on Computational Transportation Science]&lt;/ref&gt;
&lt;ref name="iwcts08"&gt;[http://cts.cs.uic.edu/iwcts.htm The First International Workshop on Computational Transportation Science]&lt;/ref&gt;
&lt;ref name="iwcts09"&gt;[http://iwcts09.cs.umn.edu/ The Second International Workshop on Computational Transportation Science]&lt;/ref&gt;
&lt;ref name="dagstuhl10"&gt;[http://www.dagstuhl.de/de/programm/kalender/semhp/?semnr=10121 Dagstuhl Seminar 10121 on Computational Transportation Science]&lt;/ref&gt;
&lt;ref name="igertPHD"&gt;[http://cts.cs.uic.edu/ PhD program in CTS] (retrieved 2010, Mar 30)&lt;/ref&gt;
}}

==External links==
* [http://www.ctscience.org Computational Transportation Science]

{{DEFAULTSORT:Computational Transportation Science}}
[[Category:Transportation engineering]]
[[Category:Computational science]]
[[Category:Computational fields of study]]</text>
      <sha1>m4g92oy58zyfsxrliggfysu68stvf02</sha1>
    </revision>
  </page>
  <page>
    <title>Conservative extension</title>
    <ns>0</ns>
    <id>1840214</id>
    <revision>
      <id>851774389</id>
      <parentid>841765600</parentid>
      <timestamp>2018-07-24T14:30:29Z</timestamp>
      <contributor>
        <username>Oo09nj76t5</username>
        <id>6086540</id>
      </contributor>
      <comment>The previous version made it sound as if extending languages implied theorem containment, which is obviously false.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4598">In [[mathematical logic]], a '''conservative extension''' is a supertheory of a [[theory (mathematical logic)|theory]] which is often convenient for proving [[theorem]]s, but proves no new theorems about the language of the original theory. Similarly, a '''non-conservative extension''' is a supertheory which is not conservative, and can prove more theorems than the original.

More formally stated, a theory &lt;math&gt;T_2&lt;/math&gt; is a ([[Proof theory|proof theoretic]]) conservative extension of a theory &lt;math&gt;T_1&lt;/math&gt; if every theorem of &lt;math&gt;T_1&lt;/math&gt; is a theorem of &lt;math&gt;T_2&lt;/math&gt;, and any theorem of &lt;math&gt;T_2&lt;/math&gt; in the language of &lt;math&gt;T_1&lt;/math&gt; is already a theorem of &lt;math&gt;T_1&lt;/math&gt;.

More generally, if &lt;math&gt;\Gamma&lt;/math&gt; is a set of formulas in the common language of &lt;math&gt;T_1&lt;/math&gt; and &lt;math&gt;T_2&lt;/math&gt;, then &lt;math&gt;T_2&lt;/math&gt; is &lt;math&gt;\Gamma&lt;/math&gt;'''-conservative''' over &lt;math&gt;T_1&lt;/math&gt; if every formula from &lt;math&gt;\Gamma&lt;/math&gt; provable in &lt;math&gt;T_2&lt;/math&gt; is also provable in &lt;math&gt;T_1&lt;/math&gt;.

Note that a conservative extension of a [[consistent]] theory is consistent. [If it were not, then by the [[principle of explosion]] ("everything follows from a contradiction"), every theorem in the original theory ''as well as its negation'' would belong to the new theory, which then would not be a conservative extension.] Hence, conservative extensions do not bear the risk of introducing new inconsistencies. This can also be seen as a [[methodology]] for writing and structuring large theories: start with a theory, &lt;math&gt;T_0&lt;/math&gt;, that is known (or assumed) to be consistent, and successively build conservative extensions &lt;math&gt;T_1&lt;/math&gt;, &lt;math&gt;T_2&lt;/math&gt;, ... of it.

The theorem provers [[Isabelle (theorem prover)|Isabelle]] and [[ACL2]] adopt this methodology by providing a language for conservative extensions by definition.

Recently, conservative extensions have been used for defining a notion of [[ontology modularization|module]] for [[Ontology (computer science)|ontologies]]: if an ontology is formalized as a logical theory, a subtheory is a module if the whole ontology is a conservative extension of the subtheory.

An extension which is not conservative may be called a '''proper extension'''.

==Examples==
* ACA&lt;sub&gt;0&lt;/sub&gt; (a subsystem of [[second-order arithmetic]]) is a conservative extension of first-order [[Peano arithmetic]].
* [[Von Neumann–Bernays–Gödel set theory]] is a conservative extension of [[Zermelo–Fraenkel set theory]] with the [[axiom of choice]] (ZFC).
* [[Internal set theory]] is a conservative extension of [[Zermelo–Fraenkel set theory]] with the [[axiom of choice]] (ZFC).
* [[Extension by definitions|Extensions by definitions]] are conservative.
* Extensions by unconstrained predicate or function symbols are conservative.
* IΣ&lt;sub&gt;1&lt;/sub&gt; (a subsystem of Peano arithmetic with induction only for [[arithmetical hierarchy|Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt;-formulas]]) is a Π&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;2&lt;/sub&gt;-conservative extension of the [[primitive recursive arithmetic]] (PRA).&lt;ref&gt;[https://projecteuclid.org/download/pdfview_1/euclid.ndjfl/1107220675A Fernando Ferreira, A Simple Proof of Parsons’ Theorem. Notre Dame Journal of Formal Logic, Vol.46, No.1, 2005.]&lt;/ref&gt;
* ZFC is a [[analytical hierarchy|Π&lt;sup&gt;1&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;3&lt;/sub&gt;]]-conservative extension of ZF by [[absoluteness (mathematical logic)|Shoenfield's absoluteness theorem]].
* ZFC with the [[continuum hypothesis]] is a Π&lt;sup&gt;2&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt;-conservative extension of ZFC.

==Model-theoretic conservative extension==
{{further information|Conservativity theorem}}

With [[Model theory|model-theoretic]] means, a stronger notion is obtained: an extension &lt;math&gt;T_2&lt;/math&gt; of a theory &lt;math&gt;T_1&lt;/math&gt; is '''model-theoretically conservative''' if every model of &lt;math&gt;T_1&lt;/math&gt; can be expanded to a model of &lt;math&gt;T_2&lt;/math&gt;. It is straightforward to see that each model-theoretic conservative extension also is a (proof-theoretic) conservative extension in the above sense. The model theoretic notion has the advantage over the proof theoretic one that it does not depend so much on the language at hand; on the other hand, it is usually harder to establish model theoretic conservativity.

==References==
{{reflist}}

==External links==
*[http://www.cs.nyu.edu/pipermail/fom/1998-October/002306.html The importance of conservative extensions for the foundations of mathematics]

[[Category:Proof theory]]
[[Category:Model theory]]</text>
      <sha1>mtrvlvcc0qroeqn3es5i3fycwbpc1j0</sha1>
    </revision>
  </page>
  <page>
    <title>Degree of a continuous mapping</title>
    <ns>0</ns>
    <id>3094450</id>
    <revision>
      <id>769246846</id>
      <parentid>752635436</parentid>
      <timestamp>2017-03-08T11:24:58Z</timestamp>
      <contributor>
        <username>Jvohn</username>
        <id>4525456</id>
      </contributor>
      <comment>/* Differential topology */ Formula</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9855">{{About|the term "degree" as used in algebraic topology||Degree (disambiguation)}}

[[File:Sphere wrapped round itself.png|200px|thumb|right|A degree two map of a [[sphere]] onto itself.]]
In [[topology]], the '''degree''' of a [[continuous function (topology)|continuous mapping]] between two [[Compact space|compact]] [[Orientability|oriented]] [[manifold]]s of the same [[dimension]] is a number that represents the number of times that the [[Domain of a function|domain]] manifold wraps around the [[Range (mathematics)|range]] manifold under the mapping.  The degree is always an [[integer]], but may be positive or negative depending on the orientations.

The degree of a map was first defined by [[Luitzen Egbertus Jan Brouwer|Brouwer]],&lt;ref&gt;{{cite journal | last = Brouwer | first = L. E. J. | authorlink = Luitzen Egbertus Jan Brouwer | title = Über Abbildung von Mannigfaltigkeiten | journal = Mathematische Annalen  | volume = 71 | issue = 1 | pages = 97–115 | year = 1911 | url = http://www.springerlink.com/content/h15uqp1w28862q47 | doi=10.1007/bf01456931}}&lt;/ref&gt; who showed that the degree is [[homotopy]] invariant ([[invariant (mathematics)|invariant]] among homotopies), and used it to prove the [[Brouwer fixed point theorem]].  In modern mathematics, the degree of a map plays an important role in topology and [[geometry]].  In [[physics]], the degree of a continuous map (for instance a map from space to some order parameter set) is one example of a [[topological quantum number]].

==Definitions of the degree==

===From ''S''&lt;sup&gt;''n''&lt;/sup&gt; to ''S''&lt;sup&gt;''n''&lt;/sup&gt;===

The simplest and most important case is the degree of a [[continuous map]] from the [[n-sphere|&lt;math&gt;n&lt;/math&gt;-sphere]] &lt;math&gt;S^n&lt;/math&gt; to itself (in the case &lt;math&gt;n=1&lt;/math&gt;, this is called the [[winding number]]):

Let &lt;math&gt;f\colon S^n\to S^n&lt;/math&gt; be a continuous map. Then &lt;math&gt;f&lt;/math&gt; induces a homomorphism &lt;math&gt;f_*\colon H_n\left(S^n\right)\to H_n\left(S^n\right)&lt;/math&gt;, where &lt;math&gt;H_n\left(\cdot\right)&lt;/math&gt; is the &lt;math&gt;n&lt;/math&gt;th [[homology group]]. Considering the fact that &lt;math&gt;H_n\left(S^n\right)\cong\mathbb{Z}&lt;/math&gt;, we see that &lt;math&gt;f_*&lt;/math&gt; must be of the form &lt;math&gt;f_*\colon x\mapsto\alpha x&lt;/math&gt; for some fixed &lt;math&gt;\alpha\in\mathbb{Z}&lt;/math&gt;.
This &lt;math&gt;\alpha&lt;/math&gt; is then called the degree of &lt;math&gt;f&lt;/math&gt;.

===Between manifolds===

==== Algebraic topology ====

Let ''X'' and ''Y'' be closed [[connected space|connected]] [[orientation (mathematics)|oriented]] ''m''-dimensional [[manifold]]s. Orientability of a manifold implies that its top [[homology group]] is isomorphic to '''Z'''. Choosing an orientation means choosing a generator of the top homology group.

A continuous map ''f'' : ''X''&amp;rarr;''Y'' induces a homomorphism ''f''&lt;sub&gt;*&lt;/sub&gt; from  ''H&lt;sub&gt;m&lt;/sub&gt;''(''X'') to ''H&lt;sub&gt;m&lt;/sub&gt;''(''Y''). Let [''X''], resp. [''Y''] be the chosen generator of ''H&lt;sub&gt;m&lt;/sub&gt;''(''X''), resp. ''H&lt;sub&gt;m&lt;/sub&gt;''(''Y'') (or the [[fundamental class]] of ''X'', ''Y''). Then the '''degree''' of ''f'' is defined to be ''f''&lt;sub&gt;*&lt;/sub&gt;([''X'']). In other words,

:&lt;math&gt;f_*([X])=\deg(f)[Y] \, .&lt;/math&gt;

If ''y'' in ''Y'' and ''f'' &lt;sup&gt;−1&lt;/sup&gt;(''y'') is a finite set, the degree of ''f'' can be computed by considering the ''m''-th [[Relative homology|local homology groups]] of ''X'' at each point in ''f'' &lt;sup&gt;−1&lt;/sup&gt;(''y'').

==== Differential topology ====

In the language of differential topology, the degree of a smooth map can be defined as follows: If ''f'' is a smooth map whose domain is a compact manifold and ''p'' is a [[regular value]] of ''f'', consider the finite set

:&lt;math&gt;f^{-1}(p)=\{x_1,x_2,\ldots,x_n\} \,.&lt;/math&gt;

By ''p'' being a regular value, in a neighborhood of each ''x''&lt;sub&gt;''i''&lt;/sub&gt; the map ''f'' is a local [[diffeomorphism]] (it is a [[covering map]]). Diffeomorphisms can be either orientation preserving or orientation reversing. Let ''r'' be the number of points ''x''&lt;sub&gt;''i''&lt;/sub&gt; at which ''f'' is orientation preserving  and ''s'' be the number at which ''f'' is orientation reversing. When the domain of ''f'' is connected, the number ''r''&amp;nbsp;&amp;minus;&amp;nbsp;''s'' is independent of the choice of ''p'' (though ''n'' is not!) and one defines the '''degree''' of ''f'' to be ''r''&amp;nbsp;&amp;minus;&amp;nbsp;''s''. This definition coincides with the algebraic topological definition above.

The same definition works for compact manifolds with [[Boundary (topology)|boundary]] but then ''f'' should send the boundary of ''X'' to the boundary of ''Y''.

One can also define '''degree modulo 2''' (deg&lt;sub&gt;2&lt;/sub&gt;(''f'')) the same way as before but taking the ''fundamental class'' in '''Z'''&lt;sub&gt;2&lt;/sub&gt; homology. In this case deg&lt;sub&gt;2&lt;/sub&gt;(''f'') is an element of '''Z'''&lt;sub&gt;2&lt;/sub&gt; (the [[GF(2)|field with two elements]]), the manifolds need not be orientable and if ''n'' is the number of preimages of ''p'' as before then deg&lt;sub&gt;2&lt;/sub&gt;(''f'') is ''n'' modulo 2.

Integration of [[differential form]]s gives a pairing between (C&lt;sup&gt;&amp;infin;&lt;/sup&gt;-)[[singular homology]] and [[de Rham cohomology]]: &lt;math&gt;\langle c, \omega\rangle = \int_c \omega&lt;/math&gt;, where &lt;math&gt;c&lt;/math&gt; is a homology class represented by a cycle &lt;math&gt;c&lt;/math&gt; and &lt;math&gt;\omega&lt;/math&gt; a closed form representing a de Rham cohomology class. For a smooth map ''f'' : ''X''&amp;rarr;''Y'' between orientable ''m''-manifolds, one has

:&lt;math&gt;\langle f_* [c], [\omega] \rangle = \langle [c], f^*[\omega] \rangle,&lt;/math&gt;

where ''f''&lt;sub&gt;*&lt;/sub&gt; and ''f''* are induced maps on chains and forms respectively. Since ''f''&lt;sub&gt;*&lt;/sub&gt;[''X''] = deg ''f'' · [''Y''], we have

:&lt;math&gt;\deg f \int_Y \omega  = \int_X f^*\omega \,&lt;/math&gt;

for any ''m''-form ''&amp;omega;'' on ''Y''.

===Maps from closed region===
If &lt;math&gt;\Omega\subset\R^n&lt;/math&gt;is a bounded [[Region (mathematical analysis)|region]], &lt;math&gt;f:\bar\Omega\to\R^n&lt;/math&gt; smooth, &lt;math&gt;p&lt;/math&gt; a [[regular value]] of &lt;math&gt;f&lt;/math&gt; and
&lt;math&gt;p\notin f(\partial\Omega)&lt;/math&gt;, then the degree &lt;math&gt;\deg(f,\Omega,p)&lt;/math&gt; is defined
by the formula
:&lt;math&gt;\deg(f,\Omega,p):=\sum_{y\in f^{-1}(p)} \sgn \det Df(y)&lt;/math&gt;
where &lt;math&gt;Df(y)&lt;/math&gt; is the [[Jacobian matrix and determinant|Jacobi matrix]] of &lt;math&gt;f&lt;/math&gt; in &lt;math&gt;y&lt;/math&gt;. 
This definition of the degree may be naturally extended for non-regular values &lt;math&gt;p&lt;/math&gt; such that &lt;math&gt;\deg(f,\Omega,p)=\deg(f,\Omega,p')&lt;/math&gt; where &lt;math&gt;p'&lt;/math&gt; is a point close to &lt;math&gt;p&lt;/math&gt;.

The degree satisfies the following properties:&lt;ref name=dancer&gt;{{cite book|last=Dancer|first=E. N.|title=Calculus of Variations and Partial Differential Equations|year=2000|publisher=Springer-Verlag|isbn=3-540-64803-8|pages=185–225}}&lt;/ref&gt; 
* If &lt;math&gt;\deg(f,\bar\Omega,p)\neq 0&lt;/math&gt;, then there exists &lt;math&gt;x\in\Omega&lt;/math&gt; such that &lt;math&gt;f(x)=p&lt;/math&gt;.
* &lt;math&gt;\deg(\operatorname{id}, \Omega, y) = 1&lt;/math&gt; for all &lt;math&gt;y \in \Omega&lt;/math&gt;.
*Decomposition property:
:&lt;math&gt;\deg(f, \Omega, y) = \deg(f, \Omega_1, y) + \deg(f, \Omega_2, y)&lt;/math&gt;, if &lt;math&gt;\Omega_1, \Omega_2&lt;/math&gt; are disjoint parts of &lt;math&gt;\Omega=\Omega_1\cup\Omega_2&lt;/math&gt; and &lt;math&gt;y \not\in f(\overline{\Omega}\setminus(\Omega_1\cup\Omega_2))&lt;/math&gt;.
* ''Homotopy invariance'': If &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt; are homotopy equivalent via a homotopy &lt;math&gt;F(t)&lt;/math&gt; such that &lt;math&gt;F(0)=f,\,F(1)=g&lt;/math&gt; and &lt;math&gt;p\notin F(t)(\partial\Omega)&lt;/math&gt;, then &lt;math&gt;\deg(f,\Omega,p)=\deg(g,\Omega,p)&lt;/math&gt;
* The function &lt;math&gt;p\mapsto \deg(f,\Omega,p)&lt;/math&gt; is locally constant on &lt;math&gt;\R^n-f(\partial\Omega)&lt;/math&gt;

These properties characterise the degree uniquely and the degree may be defined by them in an axiomatic way.

In a similar way, we could define the degree of a map between compact oriented [[Manifold#Manifold with boundary|manifolds with boundary]].

==Properties==
The degree of a map is a [[homotopy]] invariant; moreover for continuous maps from the [[n-sphere|sphere]] to itself it is a ''complete'' homotopy invariant, i.e. two maps &lt;math&gt;f,g:S^n\to S^n \,&lt;/math&gt; are homotopic if and only if &lt;math&gt;\deg(f) = \deg(g)&lt;/math&gt;.

In other words, degree is an isomorphism between &lt;math&gt;[S^n,S^n]=\pi_n S^n&lt;/math&gt; and &lt;math&gt;\mathbf{Z}&lt;/math&gt;.

Moreover, the [[Hopf theorem]] states that for any &lt;math&gt;n&lt;/math&gt;-dimensional closed oriented [[manifold]] ''M'', two maps &lt;math&gt;f,g: M\to S^n&lt;/math&gt; are homotopic if and only if &lt;math&gt;\deg(f)=\deg(g).&lt;/math&gt;

A self-map &lt;math&gt;f:S^n\to S^n&lt;/math&gt; of the ''n''-sphere is extendable to a map &lt;math&gt;F:B_n\to S^n&lt;/math&gt; from the ''n''-ball to the ''n''-sphere if and only if &lt;math&gt;\deg(f)=0&lt;/math&gt;.  (Here the function ''F'' extends ''f'' in the sense that ''f'' is the restriction of ''F'' to &lt;math&gt;S^n&lt;/math&gt;.)

==See also==
*[[Covering number]], a similarly named term. Note that it does not generalize the winding number but describes covers of a set by balls
*[[Density (polytope)]], a polyhedral analog
*[[Topological degree theory]]

==Notes==
{{reflist}}

==References==
* {{cite book|author=Flanders, H.|title=Differential forms with applications to the physical sciences|publisher=Dover|year=1989}}
* {{cite book|author=Hirsch, M.|title=Differential topology|publisher=Springer-Verlag|year=1976|isbn=0-387-90148-5}}
* {{cite book|author=Milnor, J.W.|title=Topology from the Differentiable Viewpoint|publisher=Princeton University Press|year=1997|isbn=978-0-691-04833-8}}
* {{cite book|author1=Outerelo, E.  |author2=Ruiz, J.M. |title=Mapping Degree Theory|publisher=American Mathematical Society|year=2009|isbn=978-0-8218-4915-6}}

== External links ==
* {{springer|title=Brouwer degree|id=p/b130260}}
* [http://sourceforge.net/projects/topdeg/ TopDeg]: Software tool for computing the topological degree of a continuous function (LGPL-3)

[[Category:Algebraic topology]]
[[Category:Differential topology]]
[[Category:Continuous mappings]]</text>
      <sha1>dympbwy6zw0rmzledca9hbjvjpjl2r8</sha1>
    </revision>
  </page>
  <page>
    <title>Destructive dilemma</title>
    <ns>0</ns>
    <id>1316878</id>
    <revision>
      <id>870713490</id>
      <parentid>870713462</parentid>
      <timestamp>2018-11-26T16:00:48Z</timestamp>
      <contributor>
        <username>Jebcubed</username>
        <id>33351428</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/49.147.19.227|49.147.19.227]] ([[User talk:49.147.19.227|talk]]) to last revision by Texvc2LaTeXBot. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5197">{{Transformation rules}}

'''Destructive dilemma'''&lt;ref&gt;Hurley, Patrick. A Concise Introduction to Logic With Ilrn Printed Access Card. Wadsworth Pub Co, 2008. Page 361&lt;/ref&gt;&lt;ref&gt;Moore and Parker&lt;/ref&gt; is the name of a [[Validity (logic)|valid]] [[rule of inference]] of [[propositional calculus|propositional logic]]. It is the [[inference]] that, if ''P'' implies ''Q'' and ''R'' implies ''S'' and either ''Q'' is false or ''S'' is false, then either ''P'' or ''R'' must be false. In sum, if two [[material conditional|conditionals]] are true, but one of their [[consequent]]s is false, then one of their [[Antecedent (logic)|antecedent]]s has to be false. ''Destructive dilemma'' is the [[Logical disjunction|disjunctive]] version of ''[[modus tollens]]''. The disjunctive version of ''[[modus ponens]]'' is the [[constructive dilemma]]. The rule can be stated:

:&lt;math&gt;\frac{P \to Q, R \to S, \neg Q \lor \neg S}{\therefore \neg P \lor \neg R}&lt;/math&gt;

where the rule is that wherever instances of "&lt;math&gt;P \to Q&lt;/math&gt;", "&lt;math&gt;R \to S&lt;/math&gt;", and "&lt;math&gt;\neg Q \lor \neg S&lt;/math&gt;" appear on lines of a proof, "&lt;math&gt;\neg P \lor \neg R&lt;/math&gt;" can be placed on a subsequent line.

==Formal notation==
The ''destructive dilemma'' rule may be written in [[sequent]] notation:

: &lt;math&gt;(P \to Q), (R \to S), (\neg Q \lor \neg S) \vdash (\neg P \lor \neg R)&lt;/math&gt;

where &lt;math&gt;\vdash&lt;/math&gt; is a [[metalogic]]al symbol meaning that &lt;math&gt;\neg P \lor  \neg R&lt;/math&gt; is a [[logical consequence|syntactic consequence]] of &lt;math&gt;P \to Q&lt;/math&gt;, &lt;math&gt;R \to S&lt;/math&gt;, and &lt;math&gt;\neg Q \lor \neg S&lt;/math&gt; in some [[formal system|logical system]];

and expressed as a truth-functional [[tautology (logic)|tautology]] or [[theorem]] of propositional logic:

:&lt;math&gt;(((P \to Q) \land (R \to S)) \land (\neg Q \lor \neg S)) \to (\neg P \lor \neg R)&lt;/math&gt;

where &lt;math&gt;P&lt;/math&gt;, &lt;math&gt;Q&lt;/math&gt;, &lt;math&gt;R&lt;/math&gt; and &lt;math&gt;S&lt;/math&gt; are propositions expressed in some [[formal system]].

==Natural language example==

:If it rains, we will stay inside.
:If it is sunny, we will go for a walk.
:Either we will not stay inside, or we will not go for a walk, or both.
:Therefore, either it will not rain, or it will not be sunny, or both.

==Proof==
{| align="center" border="1" cellpadding="8" cellspacing="0" style="background:lightcyan; font-weight:bold; text-align:center; width:45%"
|+ ''' '''
|- style="background:paleturquoise"
! style="width:15%" | ''Proposition''
! style="width:15%" | ''Derivation''
|-
| &lt;math&gt;(A\rightarrow B)\land (C\rightarrow D)&lt;/math&gt; || Given
|-
| &lt;math&gt;\neg B\lor\neg D&lt;/math&gt; || Given
|-
| &lt;math&gt;B\rightarrow\neg D&lt;/math&gt; || [[Material implication (rule of inference)|Material implication]]
|-
| &lt;math&gt;\neg D\rightarrow\neg C&lt;/math&gt; || [[Transposition (logic)|Transposition]]
|-
| &lt;math&gt;B\rightarrow\neg C&lt;/math&gt; || [[Hypothetical syllogism]]
|-
| &lt;math&gt;A\rightarrow B&lt;/math&gt; || [[Conjunction elimination|Simplification]]
|-
| &lt;math&gt;A\rightarrow\neg C&lt;/math&gt; || Hypothetical syllogism
|-
| &lt;math&gt;\neg A\lor\neg C&lt;/math&gt; || Material implication
|}

==Example proof==

The validity of this argument structure can be shown by using both [[conditional proof]] (CP) and [[reductio ad absurdum]] (RAA) in the following way:

{|
|-
|align=right| 1. || &lt;math&gt; ((P \rightarrow Q) \And (R \rightarrow S)) \And (\neg Q \vee \neg S) &lt;/math&gt;||(CP assumption)
|-
|align=right| 2. || &lt;math&gt; (P \rightarrow Q) \And (R \rightarrow S) &lt;/math&gt;||(1: Simplification)
|-
|align=right| 3. ||  &lt;math&gt; (P \rightarrow Q) &lt;/math&gt;||(2: simplification)
|-
|align=right| 4. ||  &lt;math&gt; (R \rightarrow S) &lt;/math&gt;||(2: simplification)
|-
|align=right| 5. ||  &lt;math&gt; (\neg Q \vee \neg S) &lt;/math&gt;||(1: simplification)
|-
|align=right| 6. ||  &lt;math&gt; \neg (\neg P \vee \neg R) &lt;/math&gt;||(RAA assumption)
|-
|align=right| 7. ||  &lt;math&gt; \neg \neg P \And \neg \neg R &lt;/math&gt;||(6: [[DeMorgan's Law]])
|-
|align=right| 8. ||  &lt;math&gt; \neg \neg P &lt;/math&gt;||(7: simplification)
|-
|align=right| 9. ||  &lt;math&gt; \neg \neg R &lt;/math&gt;||(7: simplification)
|-
|align=right| 10. ||  &lt;math&gt; P &lt;/math&gt;||(8: [[double negation]])
|-
|align=right| 11. ||  &lt;math&gt; R &lt;/math&gt;||(9: double negation)
|-
|align=right| 12. ||  &lt;math&gt; Q &lt;/math&gt;||(3,10: modus ponens)
|-
|align=right| 13. ||  &lt;math&gt; S &lt;/math&gt;||(4,11: modus ponens)
|-
|align=right| 14. ||  &lt;math&gt; \neg \neg Q &lt;/math&gt;||(12: double negation)
|-
|align=right| 15. ||  &lt;math&gt; \neg S &lt;/math&gt;||(5, 14: [[disjunctive syllogism]])
|-
|align=right| 16. ||  &lt;math&gt; S \And \neg S &lt;/math&gt;||(13,15: [[Logical conjunction|conjunction]])
|-
|align=right| 17. ||  &lt;math&gt; \neg P \vee \neg R &lt;/math&gt;||(6-16: RAA)
|-
|align=right| 
|-
|align=right| 18. ||  &lt;math&gt; (((P \rightarrow Q) \And (R \rightarrow S)) \And (\neg Q \vee \neg S))) \rightarrow \neg P \vee \neg R &lt;/math&gt;||(1-17: CP)
|}

==References==
{{reflist}}

== Bibliography ==
* Howard-Snyder, Frances; Howard-Snyder, Daniel; Wasserman, Ryan. The Power of Logic (4th ed.). McGraw-Hill, 2009, {{ISBN|978-0-07-340737-1}}, p. 414.

==External links==
*http://mathworld.wolfram.com/DestructiveDilemma.html

{{DEFAULTSORT:Destructive Dilemma}}
[[Category:Rules of inference]]
[[Category:Dilemmas]]
[[Category:Theorems in propositional logic]]</text>
      <sha1>6nn4upmjsc0ivjsjg88ph5lblwq8uye</sha1>
    </revision>
  </page>
  <page>
    <title>EqWorld</title>
    <ns>0</ns>
    <id>16628246</id>
    <revision>
      <id>799514295</id>
      <parentid>784433932</parentid>
      <timestamp>2017-09-08T04:53:56Z</timestamp>
      <contributor>
        <username>Black Falcon</username>
        <id>348521</id>
      </contributor>
      <comment>/* External links */replace category 'Free internet encyclopedias' → 'Free online encyclopedias', using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1016">'''EqWorld''' is  a free online mathematics reference site that lists information about mathematical equations.

It covers [[ordinary differential equation|ordinary differential]], [[partial differential equation|partial differential]], [[integral equation|integral]], [[functional equation|functional]], and other mathematical [[equation]]s. It also outlines some methods for solving equations, and lists many resources for solving equations, and has an  equation archive which users can add to.

==References==
*[[Science (journal)|Science]], 2005, Vol 308, Issue 5727, p.&amp;nbsp;1387.
*[[Physics Today]], July 2005, p.&amp;nbsp;35.
*A. D. Polyanin and A. V. Manzhirov, ''Handbook of Integral Equations'',  Chapman &amp; Hall/CRC Press {{MR|1790925}} 1998. xxvi+787 pp.&amp;nbsp;{{ISBN|0-8493-2876-4}}.

==External links==
*[http://eqworld.ipmnet.ru/ EqWorld] home page

[[Category:Mathematics websites]]
[[Category:Free online encyclopedias]]
[[Category:Equations]]
[[Category:Multilingual websites]]


{{mathematics-lit-stub}}</text>
      <sha1>oq0xaa38q1sm75jx629ha2xu89vs0d0</sha1>
    </revision>
  </page>
  <page>
    <title>Erdős space</title>
    <ns>0</ns>
    <id>30749895</id>
    <revision>
      <id>774044168</id>
      <parentid>712284547</parentid>
      <timestamp>2017-04-05T23:06:51Z</timestamp>
      <contributor>
        <username>AxelBoldt</username>
        <id>2</id>
      </contributor>
      <comment>links</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="994">In [[mathematics]], '''Erdős space''' is a [[topological space]] named after [[Paul Erdős]]. Erdős space is defined as the set ''E'' of points in the [[Hilbert space]] ℓ&lt;sup&gt;2&lt;/sup&gt; of square summable sequences having all coordinates [[Rational number|rational]]. 

Erdős space is a [[totally disconnected]], [[Dimension theory|one-dimensional]] [[topological space]]. The space ''E'' is [[homeomorphic]] to the [[direct product]] ''E''×''E''. Endowed with the [[compact-open topology]], the set of all [[homeomorphisms]] of the [[Euclidean space]] '''R'''&lt;sup&gt;''n''&lt;/sup&gt; leaving the set '''Q'''&lt;sup&gt;''n''&lt;/sup&gt; of vectors with rational coordinates invariant is homeomorphic to the Erdős space for ''n''&amp;nbsp;≥&amp;nbsp;2.&lt;ref&gt;Jan J. Dijkstra, Jan van Mill. Erdős Space and Homeomorphism Groups of Manifolds. Memoirs of the American Mathematical Society, Number 979.&lt;/ref&gt;

== References ==
&lt;references /&gt;

{{topology-stub}}

{{DEFAULTSORT:Erdos space}}

[[Category:Topological spaces]]</text>
      <sha1>qovxh6c4mxgyzlmfivw4fzzqd99qbt0</sha1>
    </revision>
  </page>
  <page>
    <title>Erich Hecke</title>
    <ns>0</ns>
    <id>1233990</id>
    <revision>
      <id>853791740</id>
      <parentid>853638814</parentid>
      <timestamp>2018-08-07T00:48:44Z</timestamp>
      <contributor>
        <username>Seraphim System</username>
        <id>29592562</id>
      </contributor>
      <comment>added [[Category:Mathematicians involved with Mathematische Annalen]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3051">{{short description|German mathematician}}
{{redirect|Hecke|the surname|Hecke (surname)}}
{{Infobox scientist
|name              = Erich Hecke
|image             = Erich Hecke.jpg
|image_size        = 
|caption           = Photo courtesy of MFO
|birth_date        = {{birth date|1887|9|20|df=y}}
|birth_place       = [[Buk]], [[Province of Posen]], [[German Empire]]
|death_date        = {{death date and age|1947|2|13|1887|9|20|df=y}}
|death_place       = [[Copenhagen]], [[Denmark]]
|residence         = 
|citizenship       = 
|nationality       = 
|ethnicity         = 
|fields            = [[Mathematics]]
|workplaces        = 
|alma_mater        = [[University of Göttingen]]
|doctoral_advisor  = [[David Hilbert]]
|academic_advisors = 
|doctoral_students = 
|notable_students  = [[Kurt Reidemeister]]&lt;br&gt;[[Heinrich Behnke]]&lt;br&gt;[[Hans Petersson]]
|known_for         = [[Hecke operator]]
|author_abbrev_bot = 
|author_abbrev_zoo = 
|influences        = 
|influenced        = 
|awards            = 
|religion          =
|signature         = &lt;!--(filename only)--&gt;
|footnotes         = 
}}

'''Erich Hecke''' (20 September 1887 – 13 February 1947) was a [[Germany|German]] [[mathematician]].  He obtained his doctorate in [[Georg August University of Göttingen|Göttingen]] under the supervision of [[David Hilbert]].  [[Kurt Reidemeister]] and [[Heinrich Behnke]] were among his students.

Hecke was born in [[Buk]], [[Poznań|Posen]], [[Germany]] (now [[Poznań]], [[Poland]]), and died in [[Copenhagen]], [[Denmark]].  His early work included establishing the [[functional equation (L-function)|functional equation]] for the [[Dedekind zeta function]], with a proof based on [[theta function]]s. The method extended to the [[L-function]]s associated to a class of characters now known as [[Hecke character]]s or [[idele class character]]s; such L-functions are now known as Hecke L-functions. He devoted most of his research to the theory of [[modular form]]s, creating the general theory of [[cusp form]]s ([[Holomorphic function|holomorphic]], for GL(2)), as it is now understood in the classical setting.

He was a Plenary Speaker of the [[International Congress of Mathematicians|ICM]] in 1936 in Oslo.&lt;ref&gt;{{cite book|author=Hecke, Erich|chapter=Neuere Fortschritte in der Theorie der elliptischen Modulfunktionen|title=''In:'' Comptes rendus du Congrès international des mathématiciens: Oslo, 1936|volume=vol. 1|pages=140–156|year=1937}}&lt;/ref&gt;

==See also==
* [[List of things named after Erich Hecke]]
* [[Hecke algebra (disambiguation)]]
* [[Tate's thesis]]

==References==
{{reflist}}

==External links==
*{{MathGenealogy |id=7379}}
*{{MacTutor Biography|id=Hecke}}

{{Authority control}}

{{DEFAULTSORT:Hecke, Erich}}
[[Category:1887 births]]
[[Category:1947 deaths]]
[[Category:People from Poznań County]]
[[Category:People from the Province of Posen]]
[[Category:20th-century German mathematicians]]
[[Category:Number theorists]]
[[Category:Mathematicians involved with Mathematische Annalen]]


{{Germany-academic-bio-stub}}</text>
      <sha1>i93l6p6wu87vbvpvgdjb710rvlcnlky</sha1>
    </revision>
  </page>
  <page>
    <title>Feynman–Kac formula</title>
    <ns>0</ns>
    <id>630017</id>
    <revision>
      <id>869833171</id>
      <parentid>869833122</parentid>
      <timestamp>2018-11-20T17:42:16Z</timestamp>
      <contributor>
        <username>Randy Kryn</username>
        <id>4796325</id>
      </contributor>
      <comment>fix to last edit</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9317">The '''Feynman–Kac formula''' named after [[Richard Feynman]] and [[Mark Kac]], establishes a link between [[parabolic partial differential equation]]s (PDEs) and [[stochastic process]]es. When Mark Kac and Richard Feynman were both Cornell faculty, Kac attended a lecture of Feynman's and remarked that the two of them were working on the same thing from different directions. The Feynman-Kac formula resulted, which proves rigorously the real case of Feynman's path integrals. The complex case, which occurs when a particle's spin is included, is still unproven. 

It offers a method of solving certain partial differential equations by simulating random paths of a stochastic process. Conversely, an important class of expectations of random processes can be computed by deterministic methods.

== Theorem ==
Consider the partial differential equation

:&lt;math&gt;\frac{\partial u}{\partial t}(x,t) + \mu(x,t) \frac{\partial u}{\partial x}(x,t) + \tfrac{1}{2} \sigma^2(x,t) \frac{\partial^2 u}{\partial x^2}(x,t) -V(x,t) u(x,t) + f(x,t) = 0, &lt;/math&gt;

defined for all &lt;math&gt;x \in \mathbb{R}&lt;/math&gt; and &lt;math&gt;t \in [0, T]&lt;/math&gt;, subject to the terminal condition

:&lt;math&gt;u(x,T)=\psi(x), &lt;/math&gt;

where μ, σ, ψ, ''V'', ''f'' are known functions, ''T'' is a parameter and &lt;math&gt; u:\mathbb{R}\times[0,T]\to\mathbb{R}&lt;/math&gt; is the unknown. Then the Feynman–Kac formula tells us that the solution can be written as a [[conditional expectation]]

:&lt;math&gt; u(x,t) = E^Q\left[ \int_t^T e^{-  \int_t^r V(X_\tau,\tau)\, d\tau}f(X_r,r)dr + e^{-\int_t^T V(X_\tau,\tau)\, d\tau}\psi(X_T) \Bigg| X_t=x \right] &lt;/math&gt;

under the [[probability measure]] Q such that ''X'' is an [[Itô calculus|Itô process]] driven by the equation

:&lt;math&gt;dX = \mu(X,t)\,dt + \sigma(X,t)\,dW^Q,&lt;/math&gt;

with ''W&lt;sup&gt;Q&lt;/sup&gt;''(''t'') is a [[Wiener process]] (also called [[Brownian motion]]) under ''Q'', and the initial condition for ''X''(''t'') is ''X''(t) = ''x''.

== Proof ==
A proof that the above formula is a solution of the differential equation is long, difficult and not presented here. It is however reasonably straightforward to show that, ''if a solution exists'', it must have the above form. The proof of that lesser result is as follows.

Let ''u''(''x'', ''t'') be the solution to the above partial differential equation.  Applying the [[Itô's_lemma#Product_Rule_for_Itô_processes|product rule for Itô processes]] to the process

:&lt;math&gt; Y(s) = e^{-\int_t^s V(X_\tau,\tau)\, d\tau} u(X_s,s)+ \int_t^s e^{-\int_t^r V(X_\tau,\tau)\, d\tau}f(X_r,r) \, dr&lt;/math&gt;

one gets

:&lt;math&gt;
\begin{align}
dY = {} &amp; d\left(e^{-  \int_t^s V(X_\tau,\tau)\, d\tau}\right) u(X_s,s) + e^{-  \int_t^s V(X_\tau,\tau)\, d\tau}\,du(X_s,s) \\[6pt]
&amp; {} + d\left(e^{-  \int_t^s V(X_\tau,\tau)\, d\tau}\right)du(X_s,s) + d\left(\int_t^s e^{-  \int_t^r V(X_\tau,\tau)\, d\tau}  f(X_r,r) \, dr\right)
\end{align}
&lt;/math&gt;

Since

:&lt;math&gt;d\left(e^{-  \int_t^s V(X_\tau,\tau)\, d\tau}\right) =-V(X_s,s) e^{-  \int_t^s V(X_\tau,\tau)\, d\tau} \,ds,&lt;/math&gt; 
the third term is &lt;math&gt; O(dt \, du) &lt;/math&gt; and can be dropped. We also have that

:&lt;math&gt; d\left(\int_t^s e^{-  \int_t^r V(X_\tau,\tau)\, d\tau}f(X_r,r)dr\right) = e^{-  \int_t^s V(X_\tau,\tau)\, d\tau} f(X_s,s) ds. &lt;/math&gt;

Applying Itô's lemma to &lt;math&gt;du(X_s,s)&lt;/math&gt;, it follows that

:&lt;math&gt;
\begin{align}
dY= {} &amp; e^{-\int_t^s V(X_\tau,\tau)\, d\tau}\,\left(-V(X_s,s) u(X_s,s) +f(X_s,s)+\mu(X_s,s)\frac{\partial u}{\partial X}+\frac{\partial u}{\partial s}+\tfrac{1}{2}\sigma^2(X_s,s)\frac{\partial^2 u}{\partial X^2}\right)\,ds \\[6pt]
&amp; {} + e^{- \int_t^s V(X_\tau,\tau)\, d\tau}\sigma(X,s)\frac{\partial u}{\partial X}\,dW.
\end{align}
&lt;/math&gt;

The first term contains, in parentheses, the above partial differential equation and is therefore zero.  What remains is

:&lt;math&gt;dY=e^{-\int_t^s V(X_\tau,\tau)\, d\tau}\sigma(X,s)\frac{\partial u}{\partial X}\,dW.&lt;/math&gt;

Integrating this equation from ''t'' to ''T'', one concludes that

:&lt;math&gt; Y(T) - Y(t) = \int_t^T e^{- \int_t^s V(X_\tau,\tau)\, d\tau}\sigma(X,s)\frac{\partial u}{\partial X}\,dW.&lt;/math&gt;

Upon taking expectations, conditioned on ''X&lt;sub&gt;t&lt;/sub&gt;'' = ''x'', and observing that the right side is an [[Itô calculus|Itô integral]], which has expectation zero{{citation needed|reason=the linked article 'Ito Calculus' does not appear to state that the expectation is zero. A ref to a more direct and explicit statement is needed to support the claim.|date=April 2018}}, it follows that

:&lt;math&gt;E[Y(T)\mid X_t=x] =  E[Y(t)\mid X_t=x] = u(x,t).&lt;/math&gt;

The desired result is obtained by observing that

:&lt;math&gt;E[Y(T)\mid X_t=x] = E \left [e^{-\int_t^T V(X_\tau,\tau)\, d\tau} u(X_T,T) + \int_t^T e^{-  \int_t^r V(X_\tau,\tau)\, d\tau}f(X_r,r)\,dr \,\Bigg|\, X_t=x \right ]&lt;/math&gt;

and finally

:&lt;math&gt; u(x,t) = E \left [e^{-  \int_t^T V(X_\tau,\tau)\, d\tau} \psi(X_T) + \int_t^T e^{-\int_t^s V(X_\tau,\tau)\,d\tau} f(X_s,s)\,ds \,\Bigg|\, X_t=x \right ]&lt;/math&gt;

== Remarks ==
* The proof above that a solution must have the given form is essentially that of &lt;ref&gt;http://www.math.nyu.edu/faculty/kohn/pde_finance.html&lt;/ref&gt; with modifications to account for &lt;math&gt;f(x,t)&lt;/math&gt;.
* The expectation formula above is also valid for ''N''-dimensional Itô diffusions. The corresponding partial differential equation for &lt;math&gt; u:\mathbb{R}^N\times[0,T]\to\mathbb{R}&lt;/math&gt; becomes:&lt;ref&gt;See {{cite book|last=Pham|first=Huyên|title=Continuous-time stochastic control and optimisation with financial applications|year=2009|publisher=Springer-Verlag |isbn=978-3-642-10044-4 }}&lt;/ref&gt;

::&lt;math&gt;\frac{\partial u}{\partial t} + \sum_{i=1}^N \mu_i(x,t)\frac{\partial u}{\partial x_i} + \frac{1}{2} \sum_{i=1}^N\sum_{j=1}^N\gamma_{ij}(x,t) \frac{\partial^2 u}{\partial x_i \partial x_j} -r(x,t)\,u = f(x,t), &lt;/math&gt;

:where,

::&lt;math&gt; \gamma_{ij}(x,t) =  \sum_{k=1}^N\sigma_{ik}(x,t)\sigma_{jk}(x,t),&lt;/math&gt;

:i.e. &lt;math&gt;\gamma = \sigma \sigma^{\mathrm{T}}&lt;/math&gt;, where &lt;math&gt;\sigma^{\mathrm{T}}&lt;/math&gt; denotes the [[transpose]] of &lt;math&gt;\sigma&lt;/math&gt;.

* This expectation can then be approximated using [[Monte Carlo method|Monte Carlo]] or [[quasi-Monte Carlo method]]s.
* When originally published by Kac in 1949,&lt;ref&gt;{{cite journal|last=Kac|first=Mark|title=On Distributions of Certain Wiener Functionals|journal=Transactions of the American Mathematical Society|authorlink=Mark Kac|volume=65|issue=1|pages=1–13|jstor=1990512|year=1949|doi=10.2307/1990512}} This paper is reprinted in {{cite book |title=Mark Kac: Probability, Number Theory, and Statistical Physics, Selected Papers |editor-first=K. |editor-last=Baclawski |editor2-first=M. D. |editor2-last=Donsker |publisher=The MIT Press |location=Cambridge, Massachusetts |year=1979 |pages=268–280 |isbn=0-262-11067-9 }}&lt;/ref&gt; the Feynman–Kac formula was presented as a formula for determining the distribution of certain Wiener functionals. Suppose we wish to find the expected value of the function

::&lt;math&gt; e^{-\int_0^t V(x(\tau))\, d\tau} &lt;/math&gt;

:in the case where ''x''(τ) is some realization of a diffusion process starting at ''x''(0) = 0. The Feynman–Kac formula says that this expectation is equivalent to the integral of a solution to a diffusion equation. Specifically, under the conditions that &lt;math&gt;u V(x) \geq 0&lt;/math&gt;,

::&lt;math&gt; E\left[ e^{- u \int_0^t V(x(\tau))\, d\tau} \right] = \int_{-\infty}^{\infty} w(x,t)\, dx &lt;/math&gt;

:where ''w''(''x'', 0) = δ(''x'') and

::&lt;math&gt;\frac{\partial w}{\partial t} = \frac{1}{2} \frac{\partial^2 w}{\partial x^2} - u V(x) w.&lt;/math&gt;

:The Feynman–Kac formula can also be interpreted as a method for evaluating [[functional integral]]s of a certain form. If

::&lt;math&gt; I = \int f(x(0)) e^{-u\int_0^t V(x(t))\, dt} g(x(t))\, Dx &lt;/math&gt;

:where the integral is taken over all [[random walk]]s, then

::&lt;math&gt; I = \int w(x,t) g(x)\, dx &lt;/math&gt;

:where ''w''(''x'', ''t'') is a solution to the [[parabolic partial differential equation]]

::&lt;math&gt; \frac{\partial w}{\partial t} = \frac{1}{2} \frac{\partial^2 w}{\partial x^2} - u V(x) w &lt;/math&gt;

:with initial condition ''w''(''x'', 0) = ''f''(''x'').

== Applications ==
In [[quantitative finance]], the Feynman–Kac formula is used to efficiently calculate solutions to the [[Black–Scholes equation]] to [[Valuation of options|price options]] on stocks.&lt;ref name="Brandimarte2013"&gt;{{cite book|author=Paolo Brandimarte|title=Numerical Methods in Finance and Economics: A MATLAB-Based Introduction|url=https://books.google.com/books?id=iH9ltZtOsM4C|date=6 June 2013|publisher=John Wiley &amp; Sons|isbn=978-1-118-62557-6|chapter=Chapter 1. Motivation}}&lt;/ref&gt;

== See also ==
* [[Itō's lemma]]
* [[Kunita–Watanabe inequality]]
* [[Girsanov theorem]]
* [[Kolmogorov forward equation]] (also known as Fokker–Planck equation)

== References ==
{{reflist}}

== Further reading ==
* {{cite book|last=Simon|first=Barry|authorlink=Barry Simon|title=Functional Integration and Quantum Physics|year=1979|publisher=Academic Press}}
* {{cite book |last = Hall |first = B. C. |title = Quantum Theory for Mathematicians | year = 2013 |publisher = Springer}}

{{Richard Feynman}}

{{DEFAULTSORT:Feynman-Kac Formula}}
[[Category:Richard Feynman]]
[[Category:Stochastic processes]]
[[Category:Parabolic partial differential equations]]
[[Category:Articles containing proofs]]</text>
      <sha1>hjrqsr7y4nxrw2j0p75ymjo3akf7liz</sha1>
    </revision>
  </page>
  <page>
    <title>Glossary of calculus</title>
    <ns>0</ns>
    <id>53252845</id>
    <revision>
      <id>871704696</id>
      <parentid>871704406</parentid>
      <timestamp>2018-12-02T22:33:16Z</timestamp>
      <contributor>
        <username>ScienceAndEngineering</username>
        <id>32851500</id>
      </contributor>
      <comment>/* D */ added definition from intro paragraph of Wikipedia article [[Differentiable function]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="37600">''Most of the terms listed in Wikipedia glossaries are already defined and explained within Wikipedia itself.  However, glossaries like this one are useful for looking up, comparing and reviewing large numbers of terms together.  You can help enhance this page by adding new terms or writing definitions for existing ones.''


This '''glossary of calculus''' is a list of definitions about '''[[calculus]]''', its sub-disciplines, and related fields.



{{compact ToC|side=yes|center=yes|nobreak=yes|seealso=yes|refs=yes|}}


{{Calculus}}
{{Science}}




== A ==
{{term|[[Abel's test]]}}
{{defn|defn=A method of testing for the [[Convergent series|convergence]] of an [[series (mathematics)|infinite series]].}}
{{term|[[Absolute convergence]]}}
{{defn|defn=An [[series (mathematics)|infinite series]] of numbers is said to '''converge absolutely''' (or to be '''absolutely convergent''') if the sum of the [[absolute value]]s of the summands is finite&lt;!-- don't link to [[finite set]], please --&gt;.  More precisely, a real or complex series &lt;math&gt;\textstyle\sum_{n=0}^\infty a_n&lt;/math&gt; is said to '''converge absolutely''' if &lt;math&gt;\textstyle\sum_{n=0}^\infty \left|a_n\right| = L&lt;/math&gt; for some real number &lt;math&gt;\textstyle L&lt;/math&gt;. Similarly, an [[improper integral]] of a [[function (mathematics)|function]], &lt;math&gt;\textstyle\int_0^\infty f(x)\,dx&lt;/math&gt;, is said to converge absolutely if the integral of the absolute value of the integrand is finite—that is, if &lt;math&gt;\textstyle\int_0^\infty \left|f(x)\right|dx = L.&lt;/math&gt;}}
{{term|[[Maxima and minima|Absolute maximum]]}}
{{defn|defn=}}
{{term|[[Maxima and minima|Absolute minimum]]}}
{{defn|defn=}}
{{term|[[Absolute value]]}}
{{defn|defn= The '''absolute value''' or '''modulus''' {{math|{{!}}''x''{{!}}}} of a [[real number]]&amp;nbsp;{{mvar|x}} is the [[non-negative]] value of&amp;nbsp;{{mvar|x}} without regard to its [[sign (mathematics)|sign]]. Namely, {{math|1={{!}}''x''{{!}} = ''x''}} for a [[positive number|positive]]&amp;nbsp;{{mvar|x}}, {{math|1={{!}}''x''{{!}} = −''x''}} for a [[negative number|negative]]&amp;nbsp;{{mvar|x}} (in which case {{math|−''x''}} is positive), and {{math|1={{!}}0{{!}} = 0}}. For example, the absolute value of 3 is 3, and the absolute value of −3 is also 3. The absolute value of a number may be thought of as its [[distance]] from zero.}}
{{term|[[Alternating series]]}}
{{defn|defn= An [[infinite series]] whose terms alternate between positive and negative.}}
{{term|[[Alternating series test]]}}
{{defn|defn= Is the method used to prove that an [[alternating series]] with terms that decrease in absolute value is a [[convergent series]]. The test was used by [[Gottfried Leibniz]] and is sometimes known as '''Leibniz's test''', '''Leibniz's rule''', or the '''Leibniz criterion'''.}}
{{term|[[Annulus (mathematics)|Annulus]]}}
{{defn|defn= A ring-shaped object, a region bounded by two [[concentric circles]].}}
{{term|[[Antiderivative]]}}
{{defn|defn= An '''antiderivative''', '''primitive function''', '''primitive integral''' or '''indefinite integral'''{{#tag:ref|Antiderivatives are also called '''general integrals''', and sometimes '''integrals'''. The latter term is generic, and refers not only to indefinite integrals (antiderivatives), but also to [[definite integral]]s. When the word ''integral'' is used without additional specification, the reader is supposed to deduce from the context whether it refers to a definite or indefinite integral. Some authors define the indefinite integral of a function as the set of its infinitely many possible antiderivatives. Others define it as an arbitrarily selected element of that set. Wikipedia adopts the latter approach.{{citation needed|date=June 2016}}|group=Note}} of a [[function (mathematics)|function]] {{math|''f''}} is a differentiable function {{math|''F''}} whose [[derivative]] is equal to the original function {{math|''f''}}. This can be stated symbolically as &lt;math&gt;F' = f&lt;/math&gt;.&lt;ref&gt;{{cite book | last=Stewart | first=James | authorlink=James Stewart (mathematician) | title=Calculus: Early Transcendentals |publisher=[[Brooks/Cole]] | edition=6th | year=2008 | isbn=0-495-01166-5}}&lt;/ref&gt;&lt;ref&gt;{{cite book | last1=Larson | first1=Ron | authorlink=Ron Larson (mathematician)| last2=Edwards | first2=Bruce H. | title=Calculus | publisher=[[Brooks/Cole]] | edition=9th | year=2009 | isbn=0-547-16702-4}}&lt;/ref&gt; The process of solving for antiderivatives is called '''antidifferentiation''' (or '''indefinite integration''') and its opposite operation is called differentiation, which is the process of finding a derivative.}}
{{term|[[Inverse trigonometric functions|Arcsin]]}}
{{defn|defn=}}
{{term|[[Area under a curve]]}}
{{defn|defn=}}
{{term|[[Asymptote]]}}
{{defn|defn= In [[analytic geometry]], an '''asymptote'''  of a [[curve]] is a line such that the distance between the curve and the line approaches zero as one or both of the ''x'' or ''y'' coordinates [[Limit of a function#Limits at infinity|tends to infinity]]. Some sources include the requirement that the curve may not cross the line infinitely often, but this is unusual for modern authors.&lt;ref&gt;[https://web.archive.org/web/*/http://rowdy.msudenver.edu/~talmanl/PDFs/APCalculus/OnAsymptotes.pdf "Asymptotes" by Louis A. Talman]&lt;/ref&gt; In [[projective geometry]] and related contexts, an asymptote of a curve is a line which is [[tangent]] to the curve at a [[point at infinity]].&lt;ref&gt;{{citation|title=An elementary treatise on the differential calculus|chapter=Asymptotes|first=Benjamin|last=Williamson|url=https://books.google.com/?id=znsXAAAAYAAJ&amp;pg=241|year=1899}}&lt;/ref&gt;&lt;ref&gt;{{citation|first=Jeffrey|last=Nunemacher|title=Asymptotes, Cubic Curves, and the Projective Plane|journal=Mathematics Magazine|volume=72|issue=3|year=1999|pages=183–192|jstor=2690881|doi=10.2307/2690881|citeseerx=10.1.1.502.72}}&lt;/ref&gt;}}
{{term|[[Automatic differentiation]]}}
{{defn|defn=In [[mathematics]] and [[computer algebra]], '''automatic differentiation''' ('''AD'''), also called '''algorithmic differentiation''' or '''computational differentiation''',&lt;ref&gt;{{cite journal|last=Neidinger|first=Richard D.|title=Introduction to Automatic Differentiation and MATLAB Object-Oriented Programming|journal=SIAM Review|year=2010|volume=52|issue=3|pages=545–563|url=http://academics.davidson.edu/math/neidinger/SIAMRev74362.pdf|doi=10.1137/080743627}}&lt;/ref&gt;&lt;ref name="baydin2018automatic"&gt;{{cite journal|last=Baydin|first=Atilim Gunes|last2=Pearlmutter|first2=Barak|last3=Radul|first3=Alexey Andreyevich|last4=Siskind|first4=Jeffrey|title=Automatic differentiation in machine learning: a survey|journal=Journal of Machine Learning Research|year=2018|volume=18|pages=1–43|url=http://jmlr.org/papers/v18/17-468.html}}&lt;/ref&gt; is a set of techniques to numerically evaluate the [[derivative]] of a function specified by a computer program. AD exploits the fact that every computer program, no matter how complicated, executes a sequence of elementary arithmetic operations (addition, subtraction, multiplication, division, etc.) and elementary functions (exp, log, sin, cos, etc.). By applying the [[chain rule]] repeatedly to these operations, derivatives of arbitrary order can be computed automatically, accurately to working precision, and using at most a small constant factor more arithmetic operations than the original program.}}

{{term|[[Rate (mathematics)#rate of change|Average rate of change]]}}
{{defn|defn=}}

==B==
{{glossary}}

{{term|[[Binomial coefficient]]}}
{{defn|Any of the positive [[integer]]s that occurs as a [[coefficient]] in the [[binomial theorem]] is a '''binomial coefficient'''.  Commonly, a binomial coefficient is indexed by a pair of integers {{math|''n'' ≥ ''k'' ≥ 0}} and is written &lt;math&gt;\tbinom{n}{k}.&lt;/math&gt; It is the [[coefficient]] of the {{math|''x''&lt;sup&gt;''k''&lt;/sup&gt;}} term in the [[polynomial expansion]] of the [[binomial (polynomial)|binomial]] [[exponentiation|power]] {{math|(1 + ''x'')&lt;sup&gt;''n''&lt;/sup&gt;}}, and it is given by the formula

:&lt;math&gt;\binom{n}{k} = \frac{n!}{k! (n-k)!}.&lt;/math&gt;}}
{{term|[[Binomial theorem]]''' (or '''[[binomial expansion]])}}
{{defn| Describes the algebraic expansion of [[exponentiation|powers]] of a [[binomial (polynomial)|binomial]].}}
{{term|[[Bounded function]]}}
{{defn|A [[function (mathematics)|function]] ''f'' defined on some [[Set (mathematics)|set]] ''X'' with [[real number|real]] or [[complex number|complex]] values is called '''bounded''', if the set of its values is [[bounded set|bounded]]. In other words, [[there exists]] a real number ''M'' such that 
:&lt;math&gt;|f(x)|\le M&lt;/math&gt;
[[for all]] ''x'' in ''X''. A function that is ''not'' bounded is said to be '''unbounded'''.

Sometimes, if ''f''(''x'') ≤ ''A'' for all ''x'' in ''X'', then the function is said to be '''bounded above''' by ''A''. On the other hand, if ''f''(''x'') ≥ ''B'' for all ''x'' in ''X'', then the function is said to be '''bounded below''' by ''B''.}}
{{term|[[Bounded function#bounded sequence|Bounded sequence]]}}
{{defn| .}}

==C==
{{glossary}}

{{term|[[Calculus]]}}
{{defn|(From [[Latin]] ''calculus'', literally 'small pebble', used for counting and calculations, as on an [[abacus]])&lt;ref name="oxdic"&gt;{{cite web|title=Calculus|url=http://www.oxforddictionaries.com/us/definition/american_english/calculus|website=OxfordDictionaries|accessdate=15 September 2017}}&lt;/ref&gt; is the [[mathematics|mathematical]] study of &lt;!-- Please, do not link "continuous", it has the common-language meaning, and does not refer to the technical mathematical concept --&gt;continuous change, in the same way that [[geometry]] is the study of shape and [[algebra]] is the study of generalizations of [[arithmetic operations]].}}
{{term|[[Cavalieri's principle]]}}
{{defn| In [[geometry]], '''Cavalieri's principle''', a modern implementation of the '''method of indivisibles''', named after [[Bonaventura Cavalieri]], is as follows:&lt;ref&gt;Howard Eves, "Two Surprising Theorems on Cavalieri Congruence", ''The College Mathematics Journal'', volume 22, number 2, March, 1991), pages 118&amp;ndash;124&lt;/ref&gt;
* '''2-dimensional case''': Suppose two regions in a plane are included between two parallel lines in that plane. If every line parallel to these two lines intersects both regions in line segments of equal length, then the two regions have equal areas.
* '''3-dimensional case''': Suppose two regions in three-space (solids) are included between two parallel planes. If every plane parallel to these two planes intersects both regions in [[cross section (geometry)|cross-sections]] of equal area, then the two regions have equal volumes.}}
{{term|[[Chain rule]]}}
{{defn|The '''chain rule''' is a [[formula]] for computing the [[derivative]] of the [[Function composition|composition]] of two or more [[function (mathematics)|functions]]. That is, if ''f'' and ''g'' are functions, then the chain rule expresses the derivative of their composition {{math|''f'' {{large|∘}} ''g''}} (the function which maps ''x'' to ''f''(''g''(''x'')) ) in terms of the derivatives of ''f'' and ''g'' and the [[pointwise product|product of functions]] as follows:

:&lt;math&gt;(f\circ g)'=(f'\circ g)\cdot g'.&lt;/math&gt;

This may equivalently be expressed in terms of the variable. Let {{math|1=''F'' = ''f'' {{large|∘}} ''g''}}, or equivalently, {{math|1=''F''(''x'') = ''f''(''g''(''x''))}} for all ''x''. Then one can also write
:&lt;math&gt;F'(x) = f'(g(x)) g'(x).&lt;/math&gt;

The chain rule may be written in [[Leibniz's notation]] in the following way. If a variable ''z'' depends on the variable ''y'', which itself depends on the variable ''x'', so that ''y'' and ''z'' are therefore [[dependent variable]]s, then ''z'', via the intermediate variable of ''y'', depends on ''x'' as well.  The chain rule then states,

:&lt;math&gt;\frac{dz}{dx} = \frac{dz}{dy} \cdot \frac{dy}{dx}. &lt;/math&gt;

The two versions of the chain rule are related; if &lt;math&gt;z=f(y)&lt;/math&gt; and &lt;math&gt;y=g(x)&lt;/math&gt;, then

:&lt;math&gt;\frac{dz}{dx}=\frac{dz}{dy}\cdot\frac{dy}{dx} = f'(y)g'(x) = f'(g(x))g'(x).&lt;/math&gt;

In [[integral|integration]], the counterpart to the chain rule is the [[substitution rule]].}}
{{term|[[Change of variables]]}}
{{defn| Is a basic technique used to simplify problems in which the original [[variable (mathematics)|variable]]s are replaced with [[function (mathematics)|functions]] of other variables. The intent is that when expressed in new variables, the problem  may become simpler, or equivalent to a better understood problem.}}
{{term|[[Cofunction]]}}
{{defn|defn=A [[function (mathematics)|function]] ''f'' is '''cofunction''' of a function ''g'' if ''f''(''A'') = ''g''(''B'') whenever ''A'' and ''B'' are [[complementary angles]].&lt;ref name="Hall_1909"&gt;{{cite book |title=Trigonometry |volume=Part I: Plane Trigonometry |author-first1=Arthur Graham |author-last1=Hall |author-first2=Fred Goodrich |author-last2=Frink |date=January 1909 |location=Ann Arbor, Michigan, USA |chapter=Chapter II. The Acute Angle [10] Functions of complementary angles |publisher=[[Henry Holt and Company]] / Norwood Press / J. S. Cushing Co. - Berwick &amp; Smith Co., Norwood, Massachusetts, USA |publication-place=New York, USA |pages=11-12 |url=https://archive.org/stream/planetrigonometr00hallrich#page/n26/mode/1up |access-date=2017-08-12 |dead-url=no}}&lt;/ref&gt; This definition typically applies to [[trigonometric functions]].&lt;ref name="Aufmann_Nation_2014"&gt;{{cite book |title=Algebra and Trigonometry |author-first1=Richard |author-last1=Aufmann |author-first2=Richard |author-last2=Nation |edition=8 |publisher=[[Cengage Learning]] |year=2014 |isbn=978-128596583-3 |page=528 |url=https://books.google.com/books?id=JEDAAgAAQBAJ&amp;pg=PA528 |access-date=2017-07-28}}&lt;/ref&gt;&lt;ref name="Bales_2012"&gt;{{cite web |title=5.1 The Elementary Identities |work=Precalculus |author-first=John W. |author-last=Bales |date=2012 |orig-year=2001 |url=http://jwbales.home.mindspring.com/precal/part5/part5.1.html |access-date=2017-07-30 |dead-url=no |archive-url=https://web.archive.org/web/20170730201433/http://jwbales.home.mindspring.com/precal/part5/part5.1.html |archive-date=2017-07-30}}&lt;/ref&gt; The prefix "co-" can be found already in [[Edmund Gunter]]'s ''Canon triangulorum'' (1620).&lt;ref name="Gunter_1620"&gt;{{cite book |author-first=Edmund |author-last=Gunter |author-link=Edmund Gunter |title=Canon triangulorum |date=1620}}&lt;/ref&gt;&lt;ref name="Roegel_2010"&gt;{{cite web |title=A reconstruction of Gunter's Canon triangulorum (1620) |editor-first=Denis |editor-last=Roegel |type=Research report |publisher=HAL |date=2010-12-06 |id=inria-00543938 |url=https://hal.inria.fr/inria-00543938/document |access-date=2017-07-28 |dead-url=no |archive-url=https://web.archive.org/web/20170728192238/https://hal.inria.fr/inria-00543938/document |archive-date=2017-07-28}}&lt;/ref&gt; .}}
{{term|[[Concave function]]}}
{{defn| Is the [[additive inverse|negative]] of a [[convex function]]. A concave function is also [[synonym]]ously called '''concave downwards''', '''concave down''', '''convex upwards''', '''convex cap''' or '''upper convex'''.}}
{{term|[[Constant of integration]]}}
{{defn|defn= The [[indefinite integral]] of a given function (i.e., the [[Set (mathematics)|set]] of all [[antiderivative]]s of the function) on a [[connected set|connected domain]] is only defined [[up to]] an additive constant, the '''constant of integration'''.&lt;ref&gt;{{cite book | last=Stewart | first=James | authorlink=James Stewart (mathematician) | title=Calculus: Early Transcendentals |publisher=[[Brooks/Cole]] | edition=6th | year=2008 | isbn=0-495-01166-5}}&lt;/ref&gt;&lt;ref&gt;{{cite book | last1=Larson | first1=Ron | authorlink=Ron Larson (mathematician)| last2=Edwards | first2=Bruce H. | title=Calculus | publisher=[[Brooks/Cole]] | edition=9th | year=2009 | isbn=0-547-16702-4}}&lt;/ref&gt; This constant expresses an ambiguity inherent in the construction of antiderivatives.  If a function &lt;math&gt;f(x)&lt;/math&gt; is defined on an [[interval (mathematics)|interval]] and &lt;math&gt;F(x)&lt;/math&gt; is an antiderivative of &lt;math&gt;f(x)&lt;/math&gt;, then the set of ''all'' antiderivatives of &lt;math&gt;f(x)&lt;/math&gt; is given by the functions &lt;math&gt;F(x) + C&lt;/math&gt;, where ''C'' is an arbitrary constant (meaning that ''any'' value for ''C'' makes &lt;math&gt;F(x) + C&lt;/math&gt; a valid antiderivative). The constant of integration is sometimes omitted in [[lists of integrals]] for simplicity.}}
{{term|[[Continuous function]]}}
{{defn|defn= Is a [[function (mathematics)|function]] for which sufficiently small changes in the input result in arbitrarily small changes in the output. Otherwise, a function is said to be a ''discontinuous'' function. A continuous function with a continuous [[inverse function]] is called a [[homeomorphism]].}}
{{term|[[Differentiable function#Differentiability classes|Continuously differentiable]]}}
{{defn|defn=A function ''f''  is said to be ''continuously differentiable'' if the derivative ''{{prime|f}}''(''x'') exists and is itself a continuous function.}}
{{term|[[Methods of contour integration|Contour integration]]}}
{{defn|defn= In the mathematical field of [[complex analysis]], '''contour integration''' is a method of evaluating certain [[integral]]s along paths in the complex plane.&lt;ref name=Stalker&gt;{{Cite book|title=Complex Analysis: Fundamentals of the Classical Theory of Functions |first=John |last=Stalker |page=77 | url=https://books.google.com/books?id=yl3GIXd3dFIC&amp;pg=PP12&amp;dq=%22calculus+of+residues%22#PPA77,M1|isbn=0-8176-4038-X |publisher=Springer |year=1998}}&lt;/ref&gt;&lt;ref name=Bak&gt;{{Cite book|title=Complex Analysis |first1=Joseph |last1=Bak |first2=Donald J. |last2=Newman |chapter=Chapters 11 &amp; 12 |pages=130–156 |url=https://books.google.com/books?id=JX2YSgfZwbYC&amp;pg=PA130&amp;dq=%22contour+integral%22#PPA130,M1 |isbn=0-387-94756-6 |year=1997 |publisher=Springer}}&lt;/ref&gt;&lt;ref name=Krantz&gt;{{Cite book|title=Handbook of Complex Variables |first=Steven George |last=Krantz |chapter= Chapter 2 |url=https://books.google.com/books?id=aYU2AdF_0dIC&amp;pg=PT13&amp;dq=Calculus++Residues+inauthor:krantz#PPT47,M1 |isbn=0-8176-4011-8 |year=1999 |publisher=Springer }}&lt;/ref&gt;}}
{{term|[[Convergence test]]s}}
{{defn|defn=Are methods of testing for the [[Convergent series|convergence]], [[conditional convergence]], [[absolute convergence]], [[interval of convergence]] or divergence of an [[series (mathematics)|infinite series]] &lt;math&gt;\sum_{n=1}^\infty a_n&lt;/math&gt;.}}
{{term|[[Convergent series]]}}
{{defn|defn= In [[mathematics]], a [[series (mathematics)|series]] is the [[summation|sum]] of the terms of an [[infinite sequence]] of numbers.

Given an infinite sequence &lt;math&gt;\left ( a_1,\ a_2,\ a_3,\dots \right )&lt;/math&gt;, the ''n''th [[partial sum]] &lt;math&gt;S_n&lt;/math&gt; is the sum of the first ''n'' terms of the sequence, that is,

:&lt;math&gt;S_n = \sum_{k=1}^n a_k.&lt;/math&gt;

A series is '''convergent''' if the sequence of its partial sums &lt;math&gt;\left \{ S_1,\ S_2,\ S_3,\dots \right \}&lt;/math&gt; tends to a [[limit of a sequence|limit]]; that means that the partial sums become closer and closer to a given number when the number of their terms increases. More precisely, a series converges, if there exists a number &lt;math&gt;\ell&lt;/math&gt; such that for any arbitrarily small positive number &lt;math&gt;\varepsilon&lt;/math&gt;, there is a (sufficiently large) [[integer]] &lt;math&gt;N&lt;/math&gt; such that for all &lt;math&gt;n \ge \ N&lt;/math&gt;,

:&lt;math&gt;\left | S_n - \ell \right \vert \le \ \varepsilon.&lt;/math&gt;
If the series is convergent, the number &lt;math&gt;\ell&lt;/math&gt; (necessarily unique) is called the '''sum of the series'''.

Any series that is not convergent is said to be [[Divergent series|divergent]].
}}
{{term|[[Convex function]]}}
{{defn|defn= In [[mathematics]], a [[real-valued function]] defined on an [[interval (mathematics)#Multi-dimensional intervals|''n''-dimensional interval]] is called '''convex''' (or '''convex downward''' or '''concave upward''') if the [[line segment]] between any two points on the [[graph of a function|graph of the function]] lies above or on the graph, in a [[Euclidean space]] (or more generally a [[vector space]]) of at least two dimensions. Equivalently, a function is convex if its [[epigraph (mathematics)|epigraph]] (the set of points on or above the graph of the function) is a [[convex set]]. For a twice differentiable function of a single variable, if the second derivative is always greater than or equal to zero for its entire domain then the function is convex.&lt;ref&gt;{{Cite web|url=http://www.stat.cmu.edu/~larry/=stat705/Lecture2.pdf|title=Lecture Notes 2|last=|first=|date=|website=www.stat.cmu.edu|archive-url=|archive-date=|dead-url=|access-date=3 March 2017}}&lt;/ref&gt; Well-known examples of convex functions include the [[quadratic function]] &lt;math&gt;x^2&lt;/math&gt; and the [[exponential function]] &lt;math&gt;e^x&lt;/math&gt;.}}
{{term|[[Cramer's rule]]}}
{{defn| In [[linear algebra]], '''Cramer's rule''' is an explicit formula for the solution of a [[system of linear equations]] with as many equations as unknowns, valid whenever the system has a unique solution. It expresses the solution in terms of the [[determinant]]s of the (square) coefficient [[Matrix (mathematics)|matrix]] and of matrices obtained from it by replacing one column by the column vector of right-hand-sides of the equations. It is named after [[Gabriel Cramer]] (1704&amp;ndash;1752), who published the rule for an arbitrary number of unknowns in 1750,&lt;ref&gt;{{cite web 
  | title = Introduction à l'Analyse des lignes Courbes algébriques
  | author = Cramer, Gabriel
  | year = 1750
  | location = Geneva
  | language = French
  | url = https://www.europeana.eu/resolve/record/03486/E71FE3799CEC1F8E2B76962513829D2E36B63015
  | accessdate = 2012-05-18
  | publisher = Europeana
  | pages = 656–659
}}&lt;/ref&gt;&lt;ref&gt;
{{Cite journal
 | last = Kosinski
 | first = A. A.
 | title = Cramer's Rule is due to Cramer
 | journal = Mathematics Magazine
 | volume = 74
 | pages = 310–312
 | year = 2001
 | doi = 10.2307/2691101
}}&lt;/ref&gt; although [[Colin Maclaurin]] also published special cases of the rule in 1748&lt;ref&gt;{{Cite book
  | last = MacLaurin
  | first = Colin
  | title = A Treatise of Algebra, in Three Parts.
  | url = https://archive.org/details/atreatisealgebr03maclgoog
  | year = 1748
}}&lt;/ref&gt; (and possibly knew of it as early as 1729).&lt;ref&gt;
{{Cite book
  | last = Boyer
  | first = Carl B.
  | authorlink = Carl Benjamin Boyer
  | title = A History of Mathematics
  | edition = 2nd
  | publisher = Wiley
  | year = 1968
  | pages = 431
}}
&lt;/ref&gt;&lt;ref&gt;
{{cite book
 | last = Katz
 | first = Victor
 | title = A History of Mathematics
 | publisher = Pearson Education
 | edition = Brief
 | year = 2004
 | pages = 378–379
}}
&lt;/ref&gt;&lt;ref&gt;
{{Cite journal
 | last = Hedman
 | first = Bruce A.
 | title = An Earlier Date for "Cramer's Rule"
 | journal = Historia Mathematica
 | volume = 26
 | issue =4
 | pages = 365–368
 | year = 1999
 | url = http://professorhedman.com/Cramers.Rule.pdf
 | doi = 10.1006/hmat.1999.2247
 
 }}
&lt;/ref&gt;.}}
{{term|[[Critical point (mathematics)|Critical point]]}}
{{defn|defn=A '''critical point''' or '''stationary point''' of a [[differentiable function]] of a [[Function of a real variable|real]] or [[complex variable]] is any value in its [[domain of a function|domain]] where its [[derivative]] is 0.&lt;ref&gt;{{cite book | last=Stewart | first=James | authorlink=James Stewart (mathematician) | title=Calculus: Early Transcendentals |publisher=[[Brooks/Cole]] | edition=6th | year=2008 | isbn=0-495-01166-5}}&lt;/ref&gt;&lt;ref&gt;{{cite book | last1=Larson | first1=Ron | authorlink=Ron Larson (mathematician)| last2=Edwards | first2=Bruce H. | title=Calculus | publisher=[[Brooks/Cole]] | edition=9th | year=2009 | isbn=0-547-16702-4}}&lt;/ref&gt;}}
{{term|[[Curve]]}}
{{defn|defn= A '''curve''' (also called a '''curved line''' in older texts) is, generally speaking, an object similar to a [[line (geometry)|line]] but that need not be [[Linearity|straight]].}} 
{{term|[[Curve sketching]]}}
{{defn|defn= 
 In [[geometry]], '''curve sketching''' (or '''curve tracing''') includes techniques that can be used to produce a rough idea of overall shape of a [[plane curve]] given its equation without computing the large numbers of points required for a detailed plot. It is an application of the theory of curves to find their main features. Here input is an equation.
 In [[digital geometry]] it is a method of drawing a curve pixel by pixel. Here input is an array ( digital image).}}

==D==
{{glossary}}
{{term|term='''[[Damped sine wave]]'''}}
{{defn|defn= Is a [[Sine wave|sinusoidal function]] whose amplitude approaches zero as time increases.&lt;ref&gt;Douglas C. Giancoli (2000). [''Physics for Scientists and Engineers with Modern Physics (3rd Edition)'']. Prentice Hall. {{ISBN|0-13-021517-1}}&lt;/ref&gt;}}
{{term|term='''[[Degree of a polynomial]]'''}}
{{defn|defn=Is the highest degree of its [[monomial]]s (individual terms) with non-zero coefficients. The [[degree of a monomial|degree of a term]] is the sum of the exponents of the [[Variable (mathematics)|variables]] that appear in it, and thus is a non-negative integer.}}
{{term|term='''[[Derivative]]'''}}
{{defn|defn=The '''derivative''' of a [[function of a real variable]] measures the sensitivity to change of the function value (output value) with respect to a change in its argument (input value). Derivatives are a fundamental tool of [[calculus]].  For example, the derivative of the position of a moving object with respect to [[time]] is the object's [[velocity]]: this measures how quickly the position of the object changes when time advances.}}
{{term|term='''[[Derivative test]]'''}}
{{defn|defn=A '''derivative test''' uses the [[derivative]]s of a function to locate the [[stationary point|critical point]]s of a function and determine whether each point is a [[local maximum]], a [[local minimum]], or a [[saddle point]]. Derivative tests can also give information about the [[Concave function|concavity]] of a function.}}
{{term|term='''[[Differentiable function]]'''}}
{{defn|defn=A '''differentiable function''' of one [[Real number|real]] variable is a function whose [[derivative]] exists at each point in its [[Domain of a function|domain]]. As a result, the [[Graph of a function|graph]] of a differentiable function must have a (non-[[Vertical tangent|vertical]]) [[tangent line]] at each point in its domain, be relatively smooth, and cannot contain any breaks, bends, or [[Cusp (singularity)|cusps]].}}
{{term|term='''[[Differential (mathematics)|Differential]]'''}}
{{defn|defn=.}}
{{term|term='''[[Differential (infinitesimal)]]'''}}
{{defn|defn=.}}
{{term|term='''[[Differential equation]]'''}}
{{defn|defn=.}}
{{term|term='''[[Differential operator]]'''}}
{{defn|defn=.}}
{{term|term='''[[Differential of a function]]'''}}
{{defn|defn=.}}
{{term|term='''[[Differentiation (mathematics)|Differentiation]]'''}}
{{defn|defn=.}}
{{term|term='''[[Differentiation rules]]'''}}
{{defn|defn=.}}
{{term|term='''[[Direct comparison test]]'''}}
{{defn|defn=A convergence test in which an infinite series or an improper integral is compared to one with known convergence properties.}}
{{term|term='''[[Dirichlet's test]]'''}}
{{defn|defn=.}}
{{term|term='''[[Disc integration]]'''}}
{{defn|defn=.}}
{{term|term='''[[Divergent series]]'''}}
{{defn|defn=.}}
{{term|term='''[[Discontinuity (mathematics)|Discontinuity]]'''}}
{{defn|defn=.}}
{{term|term='''[[Dot product]]'''}}
{{defn|defn=.}}
{{term|term='''[[Double integral]]'''}}

==E==
*'''[[e (mathematical constant)]]'''
*'''[[Elliptic integral]]'''
*'''[[Classification of discontinuities#Essential discontinuity|Essential discontinuity]]'''
*'''[[Euler method]]'''
*'''[[Exponential function]]'''
*'''[[Extreme value theorem]]'''
*'''[[Maxima and minima|Extremum]]'''

==F==
{{glossary}}

{{term|[[Faà di Bruno's formula]]}}
{{defn|defn=}}
{{term|[[Degree of a polynomial|First-degree polynomial]]}}
{{defn|defn=}}
{{term|[[Derivative test#First derivative test|First derivative test]]}}
{{defn|defn=}}
{{term|[[Fractional calculus]]}}
{{defn|defn=}}
{{term|[[Frustum]]}}
{{defn|defn=}}
{{term|[[Function (mathematics)|Function]]}}
{{defn|defn=}}
{{term|[[Function composition]]}}
{{defn|defn=}}
{{term|[[Fundamental theorem of calculus]]}}
{{defn|The '''fundamental theorem of calculus''' is a [[theorem]] that links the concept of [[derivative|differentiating]] a [[function (mathematics)|function]] with the concept of [[integral|integrating]] a function. The first part of the theorem, sometimes called the '''first fundamental theorem of calculus''', states that one of the [[antiderivative]]s (also called ''indefinite integral''), say ''F'', of some function ''f'' may be obtained as the integral of ''f'' with a variable bound of integration. This implies the existence of [[antiderivative]]s for [[continuous function]]s.&lt;ref&gt;{{Citation |last=Spivak|first=Michael|year=1980|title=Calculus|edition=2nd|publication-place=Houston, Texas|publisher=Publish or Perish Inc.}}&lt;/ref&gt;  Conversely, the second part of the theorem, sometimes called the '''second fundamental theorem of calculus''', states that the integral of a function ''f'' over some interval can be computed by using any one, say ''F'', of its infinitely many [[antiderivative]]s. This part of the theorem has key practical applications, because explicitly finding the antiderivative of a function by [[symbolic integration]] avoids [[numerical integration]] to compute integrals. This provides generally a better numerical accuracy.}}

==G==

*'''[[General Leibniz rule]]'''
*'''[[Maxima and minima|Global maximum]]'''
*'''[[Maxima and minima|Global minimum]]'''
*'''[[Golden spiral]]'''
*'''[[Gradient]]'''

==H==
{{glossary}}

{{term|term=[[Harmonic progression (mathematics)|Harmonic progression]]}}
{{defn|defn=In [[mathematics]], a '''harmonic progression''' (or '''harmonic sequence''') is a progression formed by taking the reciprocals of an [[arithmetic progression]]. It is a [[sequence]] of the form

:&lt;math&gt; \frac{1}{a} ,\ \frac{1}{a+d}\ , \frac{1}{a+2d}\ , \frac{1}{a+3d}\ , \cdots, \frac{1}{a+kd},&lt;/math&gt;

where &amp;minus;a/''d'' is not a [[natural number]] and ''k'' '''is''' a natural number.

Equivalently, a sequence is a harmonic progression when each term is the [[harmonic mean]] of the neighboring terms.

It is not possible for a harmonic progression (other than the trivial case where ''a'' = 1 and ''k'' = 0)  to sum to an [[integer]]. The reason is that, necessarily, at least one denominator of the progression will be divisible by a [[prime number]] that does not divide any other denominator.&lt;ref&gt;{{citation|first=P.|last= Erdős |authorlink=Paul Erdős |title=Egy Kürschák-féle elemi számelméleti tétel általánosítása|trans-title=Generalization of an elementary number-theoretic theorem of Kürschák|language=Hungarian|journal=Mat. Fiz. Lapok|volume=39|year=1932|pages=17–24|url=https://www.renyi.hu/~p_erdos/1932-02.pdf}}. As cited by {{citation
 | last = Graham | first = Ronald L. | authorlink = Ronald Graham
 | contribution = Paul Erdős and Egyptian fractions
 | doi = 10.1007/978-3-642-39286-3_9
 | mr = 3203600
 | pages = 289–309
 | publisher = János Bolyai Math. Soc., Budapest
 | series = Bolyai Soc. Math. Stud.
 | title = Erdős centennial
 | volume = 25
 | year = 2013}}.&lt;/ref&gt;}}

{{term|term=[[Derivative#Higher derivatives|Higher derivative]]}}
{{defn|defn= .}}
{{term|term=[[Homogeneous differential equation|Homogeneous linear differential equation]]}}
{{defn|defn= .}}
{{term|term=[[Hyperbolic function]]}}
{{defn|defn= .}}

==I==
*'''[[Identity function]]'''
*'''[[Imaginary number]]'''
*'''[[Implicit function]]'''
*'''[[Improper fraction]]'''
*'''[[Improper integral]]'''
*'''[[Inflection point]]''' - a point at which a plane curve's concavity changes.
*'''[[Derivative|Instantaneous rate of change]]'''
*'''[[Velocity#Instantaneous velocity|Instantaneous velocity]]'''
*'''[[Integral]]'''
*'''[[Integral symbol]]'''
*'''[[Integrand]]''' - the function to be integrated in an integral.
*'''[[Integration by parts]]'''
*'''[[Integration by substitution]]'''
*'''[[Intermediate value theorem]]'''
*'''[[Inverse trigonometric functions]]'''

==J==
*'''[[Classification of discontinuities#Jump discontinuity|Jump discontinuity]]'''

==K==


==L==
*'''[[Law of cosines]]'''
*'''[[Law of sines]]'''
*'''[[Lebesgue integration]]'''
*'''[[L'Hôpital's rule]]'''
*'''[[Limit comparison test]]'''
*'''[[Limit of a function]]'''
*'''[[Limits of integration]]'''
*'''[[Linear combination]]'''
*'''[[Linear equation]]'''
*'''[[Linear system]]'''
*'''[[List of integrals]]'''
*'''[[Logarithm]]'''
*'''[[Logarithmic differentiation]]'''
*'''[[Upper and lower bounds#Bounds of functions|Lower bound]]'''

==M==

*'''[[Mean value theorem]]'''
*'''[[Monotonic function#Monotonicity in calculus and analysis|Monotonic function]]'''
*'''[[Multiple integral]]'''
*'''[[Multiplicative calculus]]'''
*'''[[Multivariable calculus]]'''

== N ==
*'''[[Natural logarithm]]''' - The '''natural logarithm''' of a number is its [[logarithm]] to the [[base (exponentiation)|base]] of the [[mathematical constant]] [[e (mathematical constant)|''e'']], where ''e'' is an [[Irrational number|irrational]] and [[Transcendental number|transcendental]] number approximately equal to {{val|2.718281828459}}. The natural logarithm of ''x'' is generally written as {{nowrap|ln ''x''}}, {{nowrap|log&lt;sub&gt;''e''&lt;/sub&gt; ''x''}},  or sometimes, if the base ''e'' is implicit, simply {{nowrap|log ''x''}}.&lt;ref&gt;{{cite book |title=Mathematics for physical chemistry |edition=3rd |author-first=Robert G. |author-last=Mortimer |publisher=[[Academic Press]] |date=2005 |isbn=0-12-508347-5 |page=9 |url=https://books.google.com/books?id=nGoSv5tmATsC}} [https://books.google.com/books?id=nGoSv5tmATsC&amp;pg=PA9 Extract of page 9]&lt;/ref&gt; [[Parentheses]] are sometimes added for clarity, giving ln(''x''), log&lt;sub&gt;''e''&lt;/sub&gt;(''x'') or log(''x''). This is done in particular when the argument to the logarithm is not a single symbol, to prevent ambiguity.
*'''[[Multiplicative calculus#History|Non-Newtonian calculus]]'''
*'''[[Nonstandard calculus]]'''
*'''[[Notation for differentiation]]'''
*'''[[Numerical integration]]'''

==O==

*'''[[One-sided limit]]'''
*'''[[Ordinary differential equation]]'''

==P==

*'''[[Pappus's centroid theorem]]'''
*'''[[Parabola]]'''
*'''[[Paraboloid]]'''
*'''[[Partial derivative]]'''
*'''[[Partial differential equation]]'''
*'''[[Partial fraction decomposition]]'''
*'''[[Particular solution]]'''
*'''[[Piecewise|Piecewise-defined function]]''' - a function defined by multiple sub-functions that apply to certain intervals of the function's domain.
*'''[[Position (vector)|Position vector]]'''
*'''[[Power rule]]'''
*'''[[Product integral]]'''
*'''[[Product rule]]'''
*'''[[Proper fraction]]'''
*'''[[Proper rational function]]'''
*'''[[Pythagorean theorem]]'''
*'''[[Pythagorean trigonometric identity]]'''

==Q==
*'''[[Quadratic function]]'''
*'''[[Quadratic polynomial]]'''
*'''[[Quotient rule]]''' - a formula for finding the derivative of a function that is the ratio of two functions.

==R==
*'''[[Radian]]'''
*'''[[Ratio test]]'''
*'''[[Reciprocal function]]'''
*'''[[Reciprocal rule]]'''
*'''[[Riemann integral]]'''
*'''[[Related rates]]'''
*'''[[Classification of discontinuities#Removable discontinuity|Removable discontinuity]]'''
*'''[[Rolle's theorem]]'''
*'''[[Root test]]'''

==S==
*'''[[Scalar (mathematics)|Scalar]]'''
*'''[[Secant line]]'''
*'''[[Second-degree polynomial]]'''
*'''[[Second derivative]]'''
*'''[[Second derivative#Second derivative test|Second derivative test]]'''
*'''[[Differential equation#Equation order|Second-order differential equation]]'''
*'''[[Series (mathematics)|Series]]'''
*'''[[Shell integration]]'''
*'''[[Simpson's rule]]'''
*'''[[Sine]]'''
*'''[[Sine wave]]'''
*'''[[Slope field]]'''
*'''[[Squeeze theorem]]'''
*'''[[Sum rule in differentiation]]'''
*'''[[Sum rule in integration]]'''
*'''[[Summation]]'''
*'''[[Supplementary angle]]'''
*'''[[Surface area]]'''
*'''[[System of linear equations]]'''

==T==
*'''[[List of integrals|Table of integrals]]'''
*'''[[Taylor series]]'''
*'''[[Taylor's theorem]]'''
*'''[[Tangent]]'''
*'''[[Degree of a polynomial|Third-degree polynomial]]'''
*'''[[Third derivative]]'''
*'''[[Toroid]]'''
*'''[[Total differential]]'''
*'''[[Trigonometric functions]]'''
*'''[[List of trigonometric identities|Trigonometric identities]]'''
*'''[[Trigonometric integral]]'''
*'''[[Trigonometric substitution]]'''
*'''[[Trigonometry]]'''
*'''[[Triple integral]]'''

==U==
*'''[[Upper and lower bounds#Bounds of functions|Upper bound]]'''

==V==
*'''[[Variable (mathematics)|Variable]]'''
*'''[[Vector (mathematics and physics)|Vector]]'''
*'''[[Vector calculus]]'''

==W==
*'''[[Disc integration#Washer method|Washer]]'''
*'''[[Disc integration#Washer method|Washer method]]'''

==X==

==Y==



==Z==
*'''[[Zero vector]]'''

== See also ==
*'''[[Calculus]]'''
*'''[[Outline of calculus]]'''
*'''[[Glossary of areas of mathematics]]'''
*'''[[Glossary of astronomy]]'''
*'''[[Glossary of biology]]'''
*'''[[Glossary of botanical terms|Glossary of botany]]'''
*'''[[Glossary of chemistry terms|Glossary of chemistry]]'''
*'''[[Glossary of ecology]]'''
*'''[[Glossary of engineering]]'''
*'''[[Glossary of physics]]'''
*'''[[Glossary of probability and statistics]]'''

==References==
&lt;references /&gt;

==Notes==
{{reflist|group=Note}}
{{reflist|group=lower-alpha}}

{{Glossaries of science and engineering}}
{{Integral}}
{{Infinitesimals}}
{{Calculus topics}}
[[Category:Fields of mathematics|* ]]
[[Category:Glossaries of mathematics|C]]
[[Category:Wikipedia glossaries|Calculus]]</text>
      <sha1>mqlwjxc16vrcyz7qmksjqi92ez2osyi</sha1>
    </revision>
  </page>
  <page>
    <title>Graffiti (program)</title>
    <ns>0</ns>
    <id>4081806</id>
    <revision>
      <id>829004839</id>
      <parentid>764328588</parentid>
      <timestamp>2018-03-06T01:59:17Z</timestamp>
      <contributor>
        <username>Jabberjaw</username>
        <id>9895903</id>
      </contributor>
      <minor/>
      <comment>/* External links */clean up using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1125">'''Graffiti''' is a [[computer program]] which makes [[conjecture]]s in various subfields of [[mathematics]] (particularly [[graph theory]])&lt;ref&gt;{{citation|title=Mathematicians Meet Computerized Ideas|first=Gina|last=Kolata|authorlink=Gina Kolata|url=https://www.nytimes.com/1989/06/18/weekinreview/ideas-trends-mathematicians-meet-computerized-ideas.html|date=June 18, 1989|journal=[[New York Times]]}}.&lt;/ref&gt; and [[chemistry]], but can be adapted to other fields. It was written by [[Siemion Fajtlowicz]] at the [[University of Houston]]. Research on conjectures produced by Graffiti has led to over 60 publications by other mathematicians.&lt;ref&gt;{{citation|title=Look at that figure|date=January 26, 2001|journal=[[Times Higher Education]]|first=Simon|last=Colton|url=http://www.timeshighereducation.co.uk/story.asp?storycode=156777}}.&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*[http://math.uh.edu/~clarson/graffiti.html Graffiti &amp; Automated Conjecture-Making]
*[http://www.math.uh.edu/~siemion/ Siemion Fajtlowicz]

[[Category:Chemistry software]]
[[Category:Mathematical software]]


{{science-software-stub}}</text>
      <sha1>s4zx0787qxsq4dgytu8lqq9i2pzo74a</sha1>
    </revision>
  </page>
  <page>
    <title>Ground expression</title>
    <ns>0</ns>
    <id>2011627</id>
    <revision>
      <id>720438234</id>
      <parentid>715728219</parentid>
      <timestamp>2016-05-15T22:02:47Z</timestamp>
      <contributor>
        <ip>72.53.138.229</ip>
      </contributor>
      <comment>/* Ground atom */Remove vandalism?</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3992">In [[mathematical logic]], a '''ground term''' of a [[formal system]] is a [[term (logic)|term]] that does not contain any [[free variables]].

Similarly, a '''ground formula''' is a [[well formed formula|formula]] that does not contain any free variables. In [[First-order logic#Equality and its axioms|first-order logic with identity]], the sentence {{all}}&amp;nbsp;''x''&amp;nbsp;(''x''=''x'') is a ground formula.

A '''ground expression''' is a ground term or ground formula.

== Examples ==

Consider the following expressions from [[first order logic]] over a [[signature (mathematical logic)|signature]] containing a constant symbol 0 for the number 0, a unary function symbol ''s'' for the successor function and a binary function symbol + for addition.
* ''s''(0), ''s''(''s''(0)), ''s''(''s''(''s''(0))) ...  are ground terms;
* 0+1, 0+1+1, ... are ground terms.
* '''x'''+''s''(1) and ''s''('''x''') are terms, but not ground terms;
* ''s''(0)=1 and 0+0=0 are ground formulae;
* ''s''(1) and ∀'''x''':&amp;nbsp;(''s''('''x''')+1=''s''(''s''('''x'''))) are ground expressions.

== Formal definition ==

What follows is a formal definition for [[first-order language]]s. Let a first-order language be given, with &lt;math&gt;C&lt;/math&gt; the set of constant symbols, &lt;math&gt;V&lt;/math&gt; the set of (individual) variables, &lt;math&gt;F&lt;/math&gt; the set of functional operators, and &lt;math&gt;P&lt;/math&gt; the set of predicate symbols.

=== Ground terms ===
Ground terms are [[term (logic)|terms]] that contain no variables. They may be defined by logical recursion (formula-recursion):
# elements of C are ground terms;
# If ''f''∈''F'' is an ''n''-ary function symbol and α&lt;sub&gt;1&lt;/sub&gt;, α&lt;sub&gt;2&lt;/sub&gt;, ..., α&lt;sub&gt;n&lt;/sub&gt; are ground terms, then ''f''(α&lt;sub&gt;1&lt;/sub&gt;, α&lt;sub&gt;2&lt;/sub&gt;, ..., α&lt;sub&gt;n&lt;/sub&gt;) is a ground term.
# Every ground term can be given by a finite application of the above two rules (there are no other ground terms; in particular, predicates cannot be ground terms).

Roughly speaking, the [[Herbrand universe]] is the set of all ground terms.

=== Ground atom ===
A '''ground predicate''' or '''ground atom''' or '''ground literal''' is an [[atomic formula]] all of whose argument terms are ground terms.

If ''p''∈''P'' is an ''n''-ary predicate symbol and α&lt;sub&gt;1&lt;/sub&gt;, α&lt;sub&gt;2&lt;/sub&gt;, ..., α&lt;sub&gt;n&lt;/sub&gt; are ground terms, then ''p''(α&lt;sub&gt;1&lt;/sub&gt;, α&lt;sub&gt;2&lt;/sub&gt;, ..., α&lt;sub&gt;n&lt;/sub&gt;) is a ground predicate or ground atom.

Roughly speaking, the [[Herbrand base]] is the set of all ground atoms, while a [[Herbrand interpretation]] assigns a [[truth value]] to each ground atom in the base.

=== Ground formula ===
A ground formula or ground clause is a formula without free variables.

Formulas with free variables may be defined by syntactic recursion as follows:
# The free variables of an unground atom are all variables occurring in it.
# The free variables of ¬''p'' are the same as those of ''p''. The free variables of ''p''∨''q'', ''p''∧''q'', ''p''→''q'' are those free variables of ''p'' or free variables of ''q''.
# The free variables of {{all}}&amp;nbsp;''x''&amp;nbsp;''p'' and {{exist}}&amp;nbsp;''x''&amp;nbsp;''p'' are the free variables of ''p'' except ''x''.

== References ==
* {{Citation
 | title =  Handbook of discrete and combinatorial mathematics
 | contribution = Logic-based computer programming paradigms
 | year = 2000
 | editor1-last = Rosen
 | editor1-first = K.H.
 | editor2-last = Michaels
 | editor2-first = J.G.
 | last = Dalal
 | first = M.
 | page = 68
}}
* {{Citation | last1=Hodges | first1=Wilfrid | author1-link=Wilfrid Hodges | title=A shorter model theory | publisher=[[Cambridge University Press]] | isbn=978-0-521-58713-6 | year=1997}}
* [http://web.engr.oregonstate.edu/~afern/classes/cs532/notes/fo-ss.pdf First-Order Logic: Syntax and Semantics]
&lt;!-- these references are essentially random; Hodges is a standard reference but does not define all the terms used in this article --&gt;

[[Category:Mathematical logic]]
[[Category:Logical expressions]]</text>
      <sha1>ci027wsodk5z35ckm70r3h61o41xmvu</sha1>
    </revision>
  </page>
  <page>
    <title>Groupoid object</title>
    <ns>0</ns>
    <id>41910504</id>
    <revision>
      <id>847524485</id>
      <parentid>847524404</parentid>
      <timestamp>2018-06-25T23:58:58Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <minor/>
      <comment>/* Examples */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4470">In [[category theory]], a '''groupoid object''' in a category ''C'' admitting finite fiber products is a pair of objects &lt;math&gt;R, U&lt;/math&gt; together with five [[morphism]]s &lt;math&gt;s, t: R \to U, e: U \to R, m: R \times_{U, t, s} R \to R, i: R \to R&lt;/math&gt; satisfying the following groupoid axioms
# &lt;math&gt;s \circ e = t \circ e = 1_U, \, s \circ m = s \circ p_1, t \circ m = t \circ p_2&lt;/math&gt; where the &lt;math&gt;p_i: R \times_{U, t, s} R \to R&lt;/math&gt; are the two projections,
# (associativity) &lt;math&gt;m \circ (1_R \times m) = m \circ (m \times 1_R),&lt;/math&gt;
# (unit) &lt;math&gt;m \circ (e \circ s, 1_R) = m \circ (1_R, e \circ t) = 1_R,&lt;/math&gt;
# (inverse) &lt;math&gt;i \circ i = 1_R&lt;/math&gt;, &lt;math&gt;s \circ i = t, \, t \circ i = s&lt;/math&gt;, &lt;math&gt;m \circ (1_R, i) = e \circ s, \, m \circ (i, 1_R) = e \circ t&lt;/math&gt;.&lt;ref&gt;{{harvnb|Algebraic stacks|loc=Ch 3. § 1.}}&lt;/ref&gt;

== Examples ==
'''Example''': A groupoid object in the category of sets is precisely a [[groupoid]] in the usual sense: a category in which every morphism is an isomorphism. Indeed, given such a category ''C'', take ''U'' to be the set of all objects in ''C'', ''R'' the set of all arrows in ''C'', the five morphisms given by &lt;math&gt;s(x \to y) = x, \, t(x \to y) = y&lt;/math&gt;, &lt;math&gt;m(f, g) = g \circ f&lt;/math&gt;, &lt;math&gt;e(x) = 1_x&lt;/math&gt; and &lt;math&gt;i(f) = f^{-1}&lt;/math&gt;.

Incidentally, one can consider a notion of a semigroupoid (unital semigroup = a category with a single object); but, according to this example, that is nothing but a category; so a groupoid object is really a special case of a "category object", better known as a [[stack (mathematics)|stack]] (or [[prestack]]).

A '''groupoid ''S''-scheme''' is a groupoid object in the category of [[scheme (mathematics)|scheme]]s over some fixed base scheme ''S''. If &lt;math&gt;U = S&lt;/math&gt;, then a groupoid scheme (where &lt;math&gt;s = t&lt;/math&gt; are necessarily the structure map) is the same as a [[group scheme]]. A groupoid scheme is also called an '''algebraic groupoid''', for example in {{harv|Gillet|1984}}, to convey the idea it is a generalization of [[algebraic group]]s and their actions. When the term "groupoid" can naturally refer to a groupoid object in some particular category in mind, the term '''groupoid set''' is used to refer to a groupoid object in the category of sets.

'''Example''': Suppose an [[algebraic group]] ''G'' [[Group-scheme action|acts]] from the right on a scheme ''U''. Then take &lt;math&gt;R = U \times G&lt;/math&gt;, ''s'' the projection, ''t'' the given action. This determines a groupoid scheme.

== Construction ==
Given a groupoid object (''R'', ''U''), the equalizer of &lt;math&gt;R \overset{s}\underset{t}\rightrightarrows U&lt;/math&gt;, if any, is a group object called the '''inertia group''' of the groupoid. The coequalizer of the same diagram, if any, is the quotient of the groupoid.

Each groupoid object in a category ''C'' (if any) may be thought of as a contravariant functor from ''C'' to the category of groupoids. This way, each groupoid object determines a [[prestack]] in groupoids. This prestack is not a stack but it can be [[stackification|stackified]] to yield a stack.&lt;!--For example, the stackification of an algebraic group is the classifying stack BG of ''G''.--&gt;

The main use of the notion is that it provides an [[atlas (stack)|atlas]] for a [[stack (mathematics)|stack]]. More specifically, let &lt;math&gt;[R \rightrightarrows U]&lt;/math&gt; be the category of [[torsor under a groupoid|&lt;math&gt;(R \rightrightarrows U)&lt;/math&gt;-torsors]]. Then it is a [[category fibered in groupoids]]; in fact, (in a nice case), a [[Deligne–Mumford stack]]. Conversely, any DM stack is of this form.

== See also ==
*[[simplicial scheme]]

== Notes ==
{{reflist}}

== References ==
*{{citation|url=http://www.math.unizh.ch/index.php?pr_vo_det&amp;key1=1287&amp;key2=580&amp;no_cache=1 |first1=Kai|last1=Behrend|first2=Brian |last2=Conrad|first3=Dan|last3=Edidin|first4=William|last4=Fulton|first5=Barbara |last5=Fantechi|first6=Lothar|last6=Göttsche |first7=Andrew |last7=Kresch|year=2006|title=Algebraic stacks}}
*H. Gillet, [http://ac.els-cdn.com/0022404984900367/1-s2.0-0022404984900367-main.pdf?_tid=a96230a2-515a-11e7-8661-00000aab0f27&amp;acdnat=1497483728_c3a14f29c251aa4dc2b55b3abfa6ba9e Intersection theory on algebraic stacks and Q-varieties], J. Pure Appl. Algebra 34 (1984), 193–240, Proceedings of the Luminy conference on algebraic K-theory (Luminy, 1983).

[[Category:Algebraic geometry]]
[[Category:Scheme theory]]


{{algebraic-geometry-stub}}</text>
      <sha1>0mlg449sen87b5tevjmp03z4p074jpj</sha1>
    </revision>
  </page>
  <page>
    <title>Göbel's sequence</title>
    <ns>0</ns>
    <id>50045170</id>
    <revision>
      <id>762058150</id>
      <parentid>714167827</parentid>
      <timestamp>2017-01-26T11:00:47Z</timestamp>
      <contributor>
        <username>DrStrauss</username>
        <id>29858946</id>
      </contributor>
      <comment>cite-tagging;, added [[CAT:O|orphan]] tag using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1197">{{Multiple issues|
{{Orphan|date=January 2017}}
{{refimprove|date=January 2017}}
}}

In [[mathematics]], '''Göbel's sequence'''&lt;!-- WHO is Göbel? --&gt;  is a sequence of [[rational number]]s defined by the [[recurrence relation]]
:&lt;math&gt;x_n = \frac{1+x_0^2+x_1^2+\cdots+x_{n-1}^2}{n},\!\,&lt;/math&gt;
with starting value
:&lt;math&gt;x_0 = 1.&lt;/math&gt;
Göbel's sequence starts with
: 1, 1, 2, 3, 5, 10, 28, 154, 3520, 1551880, ... {{OEIS|id=A003504}}
The first non-integral value is ''x''&lt;sub&gt;43&lt;/sub&gt;.&lt;ref&gt;{{cite book|last1=Guy|first1=Richard K.|title=Unsolved Problems in Number Theory|date=1981|publisher=Springer New York|isbn=978-1-4757-1740-2|page=120}}&lt;/ref&gt;

==Generalization==
Göbel's sequence can be generalized to ''k''th powers by
:&lt;math&gt;x_n = \frac{1+x_0^k+x_1^k+\cdots+x_{n-1}^k}{n}.&lt;/math&gt;

The least indices at which the ''k''-Göbel sequences assume a non-integral value are
:43, 89, 97, 214, 19, 239, 37, 79, 83, 239, ... {{OEIS|id=A108394}}

==References==
{{Reflist}}

==External links==
*[http://mathworld.wolfram.com/GoebelsSequence.html Göbel's Sequence]

{{Classes of natural numbers}}

{{DEFAULTSORT:Gobel's sequence}}
[[Category:Integer sequences]]
[[Category:Recurrence relations]]</text>
      <sha1>jfybvkyh6tpw0753mgujwf2gnoptlep</sha1>
    </revision>
  </page>
  <page>
    <title>Hardware-based encryption</title>
    <ns>0</ns>
    <id>56358777</id>
    <revision>
      <id>866071502</id>
      <parentid>850115931</parentid>
      <timestamp>2018-10-28T02:11:18Z</timestamp>
      <contributor>
        <username>Kind Tennis Fan</username>
        <id>19339494</id>
      </contributor>
      <comment>Unused citations were causing cite errors.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14778">{{Infobox industrial process
|type=[[Cryptography]]
|sector=[[Computing]]
|technologies=[[Cryptographic hash function]], [[Encryption]]
|image = IBM4758 outside1.JPG
|caption = The [[IBM 4758]] Cryptographic Module
}}
'''Hardware-based encryption''' is the use of [[computer hardware]] to assist software, or sometimes replace software, in the process of data [[encryption]]. Typically, this is implemented as part of the [[CPU|processor]]'s instruction set. For example, the [[Advanced Encryption Standard|AES]] encryption algorithm (a modern [[cipher]]) can be implemented using the [[AES instruction set]] on the ubiquitous [[x86 architecture]].&lt;ref name="Intel AES Instructions" /&gt; Such instructions also exist on the [[ARM architecture]].&lt;ref name="cortex cryptography" /&gt; However, more unusual systems exist where the cryptography module is separate from the central processor, instead being implemented as a [[coprocessor]], in particular a [[secure cryptoprocessor]] or [[cryptographic accelerator]], of which an example is the [[IBM 4758]], or its successor, the [[IBM 4764]].&lt;ref name="IBM 4764" /&gt; Hardware implementations can be faster and less prone to exploitation than traditional software implementations, and furthermore can be protected against tampering.&lt;ref name="performance" /&gt; 
== History ==
Prior to the use of computer hardware, cryptography could be performed through various mechanical or [[electro-mechanical]] means. An early example is the [[Scytale]] used by the [[Spartan]]s.&lt;ref name="Kelly"&gt;{{Cite journal|last=Kelly|first=Thomas|title=The Myth of the Skytale|journal=Cryptologia|date=July 1998|pages=244&amp;ndash;260|doi=10.1080/0161-119891886902|volume=22}}&lt;/ref&gt; The [[Enigma machine]] was an electro-mechanical system cipher machine notably used by the Germans in [[World War II]].{{cn|date=June 2018}} After [[World War II]], purely electronic systems were developed. In 1987 the ABYSS (A Basic Yorktown Security System) project was initiated.&lt;ref name="ABYSS" /&gt;&lt;ref name="building 4758" /&gt; The aim of this project was to protect against [[software piracy]]. However, the application of computers to cryptography in general dates back to the 1940s and [[Bletchley Park]], where the [[Colossus computer]] was used to break the encryption used by German High Command during [[World War II]]. The use of computers to ''encrypt'', however, came later. In particular, until the development of the [[integrated circuit]], of which the first was produced in 1960, computers were impractical for encryption, since, in comparison to the portable [[form factor (design)|form factor]] of the [[Enigma machine]],&lt;ref name="Crypto Enigma" /&gt; [[SIGSALY|computers of the era]] took the space of an entire building. It was only with the development of the [[microcomputer]] that computer encryption became feasible, outside of niche applications. The development of the [[World Wide Web]] lead to the need for consumers to have access to encryption, as [[online shopping]] became prevalent.&lt;ref name="consumers" /&gt; The key concerns for consumers were security and speed.&lt;ref name="consumers" /&gt; This led to the eventual inclusion of the key algorithms into processors as a way of both increasing speed and security.&lt;ref name="performance" /&gt;

== Implementations ==
=== In the instruction set ===
==== x86 ====
{{Main|AES instruction set|Intel SHA extensions}}
The [[X86]] [[Computer architecture|architecture]], as a [[Complex instruction set computer|CISC (Complex Instruction Set Computer)]] Architecture, typically implements complex [[algorithms]] in hardware.&lt;ref name="Oxford" /&gt; Cryptographic algorithms are no exception. The x86 architecture implements significant components of the [[Advanced Encryption Standard|AES (Advanced&amp;nbsp;Encryption&amp;nbsp;Standard)]] algorithm,&lt;ref name="Intel AES Instructions" /&gt; which can be used by the [[NSA]] for [[Top Secret]] information.&lt;ref name="NIST National Security" /&gt; The architecture also includes support for the [[Secure Hash Algorithms|SHA]] Hashing Algorithms through the [[Intel SHA extensions]].&lt;ref name="Intel AES Instructions" /&gt; Whereas AES is a cipher, which is useful for encrypting documents, [[Hash function|hashing]] is used for verification, such as of passwords (see [[PBKDF2]]).

==== ARM ====
[[ARM processor]]s can optionally support Security Extensions. Although ARM is a [[RISC|RISC (Reduced Instruction Set Computer)]] architecture, there are several optional extensions specified by [[ARM Holdings]].&lt;ref name="cortex cryptography" /&gt;&lt;ref name="openwrt" /&gt;

=== As a coprocessor ===
* [[IBM 4758]] – The predecessor to the [[IBM 4764]].&lt;ref name="NIST approval" /&gt; This includes its own specialised processor, [[Random-access memory|memory]] and a [[Random Number Generator]].&lt;ref name="IBM 4758 datasheet" /&gt;
* [[IBM 4764]] and [[IBM 4765]], identical except for the connection used.&lt;ref name="NIST approval" /&gt; The former uses [[PCI-X]], while the latter uses [[PCI-e]].&lt;ref name="IBM 4764" /&gt; Both are [[peripheral devices]] that plug into the [[motherboard]].
=== Proliferation ===
[[Advanced Micro Devices]] (AMD) processors are also x86 devices, and have supported the [[AES instruction set|AES instructions]] since the 2011 [[Bulldozer (microarchitecture)|Bulldozer]] processor iteration. &lt;ref name="Arecibo Bulldozer" /&gt;
Due to the existence of encryption instructions on modern processors provided by both [[Intel]] and AMD, the instructions are present on most modern computers.&lt;ref name="Haifa" /&gt; They also exist on many tablets and smartphones due to their implementation in [[ARM architecture|ARM processors]].&lt;ref name="Haifa" /&gt;

== Advantages ==
Implementing cryptography in hardware means that part of the processor is dedicated to the task. This can lead to a large increase in speed.&lt;ref name="performance" /&gt; In particular, modern processor architectures that support [[Pipelining (computing)|pipelining]] can often perform other instructions concurrently with the execution of the encryption instruction. Furthermore, hardware can have methods of protecting data from software. Consequently, even if the [[operating system]] is compromised, the data may still be secure (see [[Software Guard Extensions]]).&lt;ref name="Intel SGX" /&gt;

== Disadvantages ==
If, however, the hardware implementation is compromised, major issues arise. Malicious software can retrieve the data from the (supposedly) secure hardware – a large class of method used is the [[timing attack]].&lt;ref name="BearSSL" /&gt; This is far more problematic to solve than a software bug, even within the [[operating system]]. [[Microsoft]] regularly deals with security issues through [[Windows Update]]. Similarly, regular security updates are released for [[Mac OS X]] and [[Linux]], as well as mobile operating systems like [[iOS]], [[Android (operating system)|Android]], and [[Windows Phone]]. However, hardware is a different issue. Sometimes, the issue will be fixable through updates to the processor's [[microcode]] (a low level type of software). However, other issues may only be resolvable through replacing the hardware, or a workaround in the operating system which mitigates the performance benefit of the hardware implementation, such as in the [[Spectre (security vulnerability)|Spectre exploit]].&lt;ref name="PCW-20180109" /&gt;

==See also==
* [[Disk encryption hardware]]
* [[Hardware-based full disk encryption]]
* [[Hardware security module]]

==References==
{{Reflist|30em|refs=
&lt;ref name="Intel AES Instructions"&gt;{{cite book|title=Intel® 64 and IA-32 Architectures Software Developer’s Manual|date={{date|December 2017}}|url=https://software.intel.com/sites/default/files/managed/39/c5/325462-sdm-vol-1-2abcd-3abcd.pdf|publisher=Intel|pages=303–309,410}}&lt;/ref&gt;
&lt;ref name="cortex cryptography"&gt;{{cite book|title=ARM® Cortex®-A57 MPCore Processor Cryptography Extension|date={{date|2017-12-17}}|publisher=ARM Holdings|url=http://infocenter.arm.com/help/topic/com.arm.doc.ddi0514g/DDI0514G_cortex_a57_mpcore_cryptography_trm.pdf|deadurl=no|archiveurl=https://web.archive.org/web/20161213102201/http://infocenter.arm.com/help/topic/com.arm.doc.ddi0514g/DDI0514G_cortex_a57_mpcore_cryptography_trm.pdf|archivedate=2016-12-13|df=}}&lt;/ref&gt;
&lt;ref name="IBM 4764"&gt;{{cite web|url=https://www.ibm.com/support/knowledgecenter/ssw_ibm_i_61/rzajc/rzajcco4758.htm|title=4764 Cryptographic Coprocessor|publisher=IBM|access-date={{date|2018-01-20}}|deadurl=no|archiveurl=https://web.archive.org/web/20180121000028/https://www.ibm.com/support/knowledgecenter/ssw_ibm_i_61/rzajc/rzajcco4758.htm|archivedate=2018-01-21|df=}}&lt;/ref&gt;
&lt;ref name="performance"&gt;{{cite web|title=AES-NI Performance Analyzed|url=http://www.tomshardware.com/reviews/clarkdale-aes-ni-encryption,2538.html|publisher=Tom's Hardware|year=2010|author=P. Schmid and A. Roos |accessdate={{date|2018-01-20}}}}&lt;/ref&gt;
&lt;ref name="ABYSS"&gt;{{cite web|url=https://www.computer.org/csdl/proceedings/sp/1987/0771/00/07710038.pdf|title=ABYSS: A Trusted Architecture for Software Protection|access-date={{date|2018-01-20}}|deadurl=no|archiveurl=https://web.archive.org/web/20180121071623/https://www.computer.org/csdl/proceedings/sp/1987/0771/00/07710038.pdf|archivedate=2018-01-21|df=}}&lt;/ref&gt;
&lt;ref name="building 4758"&gt;{{cite web|url=http://www.research.ibm.com/people/s/sailer/publications/2001/ibm4758.pdf|title=Building the IBM 4758 Secure Coprocessor|access-date={{date|2018-01-20}}|publisher=[[IBM]]|deadurl=no|archiveurl=https://web.archive.org/web/20170808032012/http://www.research.ibm.com/people/s/sailer/publications/2001/ibm4758.pdf|archivedate=2017-08-08|df=}}&lt;/ref&gt;
&lt;ref name="Crypto Enigma"&gt;{{cite web|url=http://www.cryptomuseum.com/kits/enigma/support/files/case.pdf|publisher=Crypto Museum|title=Enigma-E case|access-date={{date|2018-01-20}}|deadurl=no|archiveurl=https://web.archive.org/web/20161105032157/http://www.cryptomuseum.com/kits/enigma/support/files/case.pdf|archivedate=2016-11-05|df=}}&lt;/ref&gt;
&lt;ref name="consumers"&gt;{{cite web | url=http://ecommercenews.eu/consumers-online-shopping-expectations/ | title=Consumers and their online shopping expectations – Ecommerce News | date={{date|2015-2-20}} | accessdate={{date|2016-08-29}} | deadurl=no | archiveurl=https://web.archive.org/web/20160930235730/http://ecommercenews.eu/consumers-online-shopping-expectations/ | archivedate=2016-09-30 | df= }}&lt;/ref&gt;
&lt;ref name="Oxford"&gt;{{cite web|url=https://www.cs.ox.ac.uk/teaching/materials17-18/ca/lecture03.pdf|title=x86-64 Instruction Set|publisher=[[University of Oxford]]|pages=1|date={{date|2017-04-18}}|access-date={{date|2018-01-24}}}}&lt;/ref&gt;
&lt;ref name="NIST National Security"&gt;{{cite web |url=http://csrc.nist.gov/groups/ST/toolkit/documents/aes/CNSS15FS.pdf |title=National Policy on the Use of the Advanced Encryption Standard (AES) to Protect National Security Systems and National Security Information |author=Lynn Hathaway |date={{date|June 2003}} |format=PDF |access-date={{date|2011-02-15}} |deadurl=no |archiveurl=https://web.archive.org/web/20101106122007/http://csrc.nist.gov/groups/ST/toolkit/documents/aes/CNSS15FS.pdf |archivedate=2010-11-06 |df= }}&lt;/ref&gt;
&lt;ref name="IBM 4758 datasheet"&gt;{{cite web|url=ftp://www6.software.ibm.com/software/cryptocards/G221-9091-04.pdf|title=IBM 4758 Models 2 and 23 PCI Cryptographic Coprocessor|date={{date|May 2004}}|access-date={{date|2018-01-24}}|publisher=[[IBM]]}}&lt;/ref&gt;
&lt;ref name="openwrt"&gt;{{cite web|url=http://wiki.openwrt.org/doc/hardware/cryptographic.hardware.accelerators|title=Cryptographic Hardware Accelerators|publisher=OpenWRT.org|date={{date|2016-05-17}}|access-date={{date|2018-01-25}}|deadurl=no|archiveurl=https://web.archive.org/web/20180121000023/http://wiki.openwrt.org/doc/hardware/cryptographic.hardware.accelerators|archivedate=2018-01-21|df=}}&lt;/ref&gt;
&lt;ref name="NIST approval"&gt;{{cite web|url=https://csrc.nist.gov/csrc/media/projects/cryptographic-module-validation-program/documents/security-policies/140sp1505.pdf|date={{date|2012-12-10}}|access-date={{date|2018-01-20}}|title=IBM 4765 Cryptographic Coprocessor Security Module|publisher=[[National Institute of Standards and Technology]]|deadurl=no|archiveurl=https://web.archive.org/web/20180125015153/https://csrc.nist.gov/csrc/media/projects/cryptographic-module-validation-program/documents/security-policies/140sp1505.pdf|archivedate=2018-01-25|df=}}&lt;/ref&gt;
&lt;ref name="Arecibo Bulldozer"&gt;{{cite web|url=https://www.naic.edu/~phil/software/amd/New-Bulldozer-and-Piledriver-Instructions-1.pdf|date={{date|October 2012}}|access-date={{date|2018-01-25}}|title=New “Bulldozer” and “Piledriver” Instructions|publisher=[[Arecibo Observatory]]|author=Brent Hollingsworth ([[Advanced Micro Devices|AMD]])|deadurl=no|archiveurl=https://web.archive.org/web/20180209120423/https://www.naic.edu/~phil/software/amd/New-Bulldozer-and-Piledriver-Instructions-1.pdf|archivedate=2018-02-09|df=}}&lt;/ref&gt;
&lt;ref name="Haifa"&gt;{{cite web|url=https://eprint.iacr.org/2016/122.pdf|title=Simpira v2: A Family of Efficient Permutations Using the AES Round Function|date={{date|2016-11-09}}|access-date={{date|2018-01-25}}|author=Shay Gueron ([[University of Haifa]] &amp; [[Intel]]) and Nicky Mouha ([[KU Leuven]] &amp; [[NIST]])|deadurl=no|archiveurl=https://web.archive.org/web/20170716025858/https://eprint.iacr.org/2016/122.pdf|archivedate=2017-07-16|df=}}&lt;/ref&gt;
&lt;ref name="Intel SGX"&gt;{{cite web |url=https://software.intel.com/en-us/blogs/2013/09/26/protecting-application-secrets-with-intel-sgx |title=Intel SGX for Dummies (Intel SGX Design Objectives) |work=intel.com |date=2013-09-26 |deadurl=no |archiveurl=https://web.archive.org/web/20140429161139/https://software.intel.com/en-us/blogs/2013/09/26/protecting-application-secrets-with-intel-sgx |archivedate=2014-04-29 |df= }}&lt;/ref&gt;
&lt;ref name="BearSSL"&gt;{{Cite web|url=https://www.bearssl.org/constanttime.html|title=BearSSL – Constant-Time Crypto|website=www.bearssl.org|access-date=2017-01-10|deadurl=no|archiveurl=https://web.archive.org/web/20170111003347/https://www.bearssl.org/constanttime.html|archivedate=2017-01-11|df=}}&lt;/ref&gt;
&lt;ref name="PCW-20180109"&gt;{{cite web |author-last=Hachman |author-first=Mark |title=Microsoft tests show Spectre patches drag down performance on older PCs |url=https://www.pcworld.com/article/3245742/components-processors/microsoft-tests-show-spectre-patches-drag-down-performance-on-older-pcs.html |date=January 9, 2018 |work=[[PC World]] |access-date=2018-01-09 |deadurl=no |archiveurl=https://web.archive.org/web/20180209120423/https://www.pcworld.com/article/3245742/components-processors/microsoft-tests-show-spectre-patches-drag-down-performance-on-older-pcs.html |archivedate=February 9, 2018 |df= }}&lt;/ref&gt;
}}
{{Cryptography navbox | machines}}

[[Category:Computer hardware]]
[[Category:Cryptography]]</text>
      <sha1>3udorjpigmqb4hfv708nh40sj19s2uo</sha1>
    </revision>
  </page>
  <page>
    <title>Henneberg surface</title>
    <ns>0</ns>
    <id>37040656</id>
    <revision>
      <id>618352597</id>
      <parentid>542762861</parentid>
      <timestamp>2014-07-25T01:05:32Z</timestamp>
      <contributor>
        <username>Hyacinth</username>
        <id>17171</id>
      </contributor>
      <comment>/* References */ {{Minimal surfaces}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2048">[[File:Henneberg surface.jpg|thumb|Henneberg surface.]]

In [[differential geometry]], the '''Henneberg surface''' is a [[non-orientable]] [[minimal surface]]&lt;ref&gt;L. Henneberg, Über salche minimalfläche, welche eine vorgeschriebene ebene curve sur geodätishen line haben, Doctoral Dissertation, Eidgenössisches Polythechikum, Zürich, 1875&lt;/ref&gt; named after Lebrecht Henneberg.&lt;ref&gt;[[:de:Lebrecht Henneberg|Lebrecht Henneberg]] from the German-language Wikipedia. Retrieved on September 25, 2012.&lt;/ref&gt;

It has parametric equation
:&lt;math&gt;\begin{align}
x(u,v) &amp;= 2\cos(v)\sinh(u) - (2/3)\cos(3v)\sinh(3u)\\
y(u,v) &amp;= 2\sin(v)\sinh(u) + (2/3)\sin(3v)\sinh(3u)\\
z(u,v) &amp;= 2\cos(2v)\cosh(2u)
\end{align}&lt;/math&gt;
and can be expressed as an order-15 algebraic surface.&lt;ref&gt;Weisstein, Eric W. "Henneberg's Minimal Surface." From MathWorld—A Wolfram Web Resource. http://mathworld.wolfram.com/HennebergsMinimalSurface.html&lt;/ref&gt; It can be viewed as an [[immersion (mathematics)|immersion]] of a punctured [[projective plane]].&lt;ref&gt;Ulrich Dierkes, Stefan Hildebrandt, Friedrich Sauvigny, Minimal Surfaces, Volume 1. Springer 2010&lt;/ref&gt; Up until 1981 it was the only known non-orientable minimal surface.&lt;ref&gt;M. Elisa G. G. de Oliveira, Some New Examples of Nonorientable Minimal Surfaces, Proceedings of the American Mathematical Society, Vol. 98, No. 4, Dec., 1986&lt;/ref&gt;

The surface contains a [[semicubical parabola]] ("Neile's parabola") and can be derived from solving the corresponding [[Björling problem]].&lt;ref&gt;L. Henneberg, Über diejenige minimalfläche, welche die Neil'sche Paralee zur ebenen geodätischen line hat, Vierteljschr Natuforsch, Ges. Zürich 21 (1876), 66–70.&lt;/ref&gt;&lt;ref&gt;Kai-Wing Fung, Minimal Surfaces as Isotropic Curves in C3: Associated minimal surfaces and the Björling's problem. MIT BA Thesis. 2004 http://ocw.mit.edu/courses/mathematics/18-994-seminar-in-geometry-fall-2004/projects/main1.pdf&lt;/ref&gt;

== References ==
{{reflist}}

{{Minimal surfaces}}

[[Category:Minimal surfaces]]
[[Category:Differential geometry]]</text>
      <sha1>bib2ruiu82zgkm8oy5igxqvfo2zq1wl</sha1>
    </revision>
  </page>
  <page>
    <title>Hunter–Saxton equation</title>
    <ns>0</ns>
    <id>17182647</id>
    <revision>
      <id>854249646</id>
      <parentid>774178687</parentid>
      <timestamp>2018-08-10T00:04:34Z</timestamp>
      <contributor>
        <ip>193.84.204.98</ip>
      </contributor>
      <comment>/* Further reading */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11186">In [[mathematical physics]], the '''Hunter–Saxton equation'''&lt;ref name="HS91"&gt;Hunter &amp; Saxton 1991&lt;/ref&gt;
:&lt;math&gt;
(u_t + u u_x)_x = \frac{1}{2} \, u_x^2
&lt;/math&gt;

is an [[integrable system|integrable]] [[partial differential equation|PDE]] that arises in the theoretical study of [[Liquid crystal#Nematic phase|nematic liquid crystals]]. If the molecules in the liquid crystal are initially all aligned, and some of them are then wiggled slightly, this disturbance in orientation will propagate through the crystal, and the Hunter–Saxton equation describes certain aspects of such '''orientation waves'''.

== Physical background ==

In the models for liquid crystals considered here, it is assumed that there is no fluid flow, so that only the ''orientation'' of the molecules is of interest.
Within the [[Liquid crystal#Elastic continuum theory|elastic continuum theory]], the orientation is described by a field of unit vectors '''n'''(''x'',''y'',''z'',''t''). For nematic liquid crystals, there is no difference between orienting a molecule in the '''n''' direction or in the &amp;minus;'''n''' direction, and the vector field '''n''' is then called a ''director field''.
The potential energy density of a director field is usually assumed to be given by the [[Carl Wilhelm Oseen|Oseen]]–[[Charles Frank (physicist)|Frank]] energy functional &lt;ref&gt;de Gennes &amp; Prost 1994 (Ch.&amp;nbsp;3)&lt;/ref&gt;

:&lt;math&gt;
W(\mathbf{n},\nabla\mathbf{n})
= \frac12 \left(
  \alpha (\nabla \cdot \mathbf{n})^2
  + \beta (\mathbf{n} \cdot (\nabla \times \mathbf{n}))^2
  + \gamma | \mathbf{n} \times (\nabla \times \mathbf{n})|^2
\right),
&lt;/math&gt;

where the positive coefficients &lt;math&gt;\alpha&lt;/math&gt;, &lt;math&gt;\beta&lt;/math&gt;, &lt;math&gt;\gamma&lt;/math&gt; are known as the elastic coefficients of splay, twist, and bend, respectively. The kinetic energy is often neglected because of the high viscosity of liquid crystals.

== Derivation of the Hunter–Saxton equation ==

Hunter and Saxton&lt;ref name="HS91"/&gt; investigated the case when viscous damping is ignored and a kinetic energy term is included in the model. Then the governing equations for the dynamics of the director field are the [[Euler–Lagrange equations]] for the [[Lagrangian (field theory)|Lagrangian]]

:&lt;math&gt;
\mathcal{L} =
\frac{1}{2} \left| \frac{\partial\mathbf{n}}{\partial t} \right|^2
- W(\mathbf{n},\nabla\mathbf{n})
- \frac{\lambda}{2} (1-|\mathbf{n}|^2),
&lt;/math&gt;

where &lt;math&gt;\lambda&lt;/math&gt; is a [[Lagrange multiplier]] corresponding to the constraint |'''n'''|=1.
They restricted their attention to "splay waves" where the director field takes the special form

:&lt;math&gt;
\mathbf{n}(x,y,z,t) = (\cos\varphi(x,t), \sin\varphi(x,t), 0).
&lt;/math&gt;

This assumption reduces the Lagrangian to

:&lt;math&gt;
\mathcal{L} = \frac{1}{2} \left(
  \varphi_t^2 - a^2(\varphi) \varphi_x^2
\right),
\qquad
a(\varphi) := \sqrt{\alpha \sin^2 \varphi + \gamma \cos^2 \varphi},
&lt;/math&gt;

and then the Euler–Lagrange equation for the angle φ becomes

:&lt;math&gt;
  \varphi_{tt} = a(\varphi) [a(\varphi) \varphi_x]_x.
&lt;/math&gt;

There are trivial constant solutions φ=φ&lt;sub&gt;0&lt;/sub&gt;
corresponding to states where the molecules in the liquid crystal are
perfectly aligned.
Linearization around such an equilibrium leads to the linear wave equation
which allows wave propagation in both directions with speed
&lt;math&gt;a_0 := a(\varphi_0)&lt;/math&gt;,
so the nonlinear equation can be expected to behave similarly.
In order to study right-moving waves for large ''t'',
one looks for asymptotic solutions of the form

:&lt;math&gt;
  \varphi(x,t;\epsilon) =
  \varphi_0 + \epsilon \varphi_1(\theta,\tau) + O(\epsilon^2),
&lt;/math&gt;

where

:&lt;math&gt;
  \theta := x-a_0 t, \qquad \tau := \epsilon t.
&lt;/math&gt;

Inserting this into the equation, one finds at the order &lt;math&gt;\epsilon^2&lt;/math&gt; that

:&lt;math&gt;
  (\varphi_{1\tau} + a'(\varphi_0) \varphi_1 \varphi_{1\theta})_{\theta}
  = \frac{1}{2} a'(\varphi_0) \varphi_{1\theta}^2.
&lt;/math&gt;

A simple renaming and rescaling of the variables
(assuming that &lt;math&gt;a'(\varphi_0) \neq 0&lt;/math&gt;)
transforms this into the Hunter–Saxton equation.

=== Generalization ===

The analysis was later generalized by Alì and Hunter,&lt;ref name="AH06"&gt;Alì &amp; Hunter 2006&lt;/ref&gt; who allowed the director field to point in any direction, but with the spatial dependence still only in the ''x'' direction:

:&lt;math&gt;
\mathbf{n}(x,y,z,t) = (\cos\varphi(x,t), \sin\varphi(x,t) \cos\psi(x,t), \sin\varphi(x,t) \sin\psi(x,t)).
&lt;/math&gt;

Then the Lagrangian is

:&lt;math&gt;
\mathcal{L} = \frac{1}{2} \left(
  \varphi_t^2 - a^2(\varphi) \varphi_x^2
  + \sin^2 \varphi \left[ \psi_t^2 - b^2(\varphi) \psi_x^2 \right]
\right),
\qquad
a(\varphi) := \sqrt{\alpha \sin^2 \varphi + \gamma \cos^2 \varphi},
\quad
b(\varphi) := \sqrt{\beta \sin^2 \varphi + \gamma \cos^2 \varphi}.
&lt;/math&gt;

The corresponding Euler–Lagrange equations are coupled nonlinear wave equations for the angles φ and ψ, with φ corresponding to "splay waves" and ψ to "twist waves". The previous Hunter–Saxton case (pure splay waves) is recovered by taking ψ constant, but one can also consider coupled splay-twist waves where both φ and ψ vary. Asymptotic expansions similar to that above lead to a system of equations, which, after renaming and rescaling the variables, takes the form

:&lt;math&gt;
  (v_t + u v_x)_x = 0, \qquad u_{xx} = v_x^2,
&lt;/math&gt;

where ''u'' is related to &amp;phi; and ''v'' to ψ.
This system implies&lt;ref&gt;Differentiate the second equation with respect to ''t'', substitute ''v''&lt;sub&gt;''xt''&lt;/sub&gt; from the first equation, and eliminate ''v'' using the second equation again.&lt;/ref&gt; that ''u'' satisfies

:&lt;math&gt;
\left[ (u_t + u u_x)_x - \frac{1}{2} \, u_x^2 \right]_x = 0,
&lt;/math&gt;

so (rather remarkably) the Hunter–Saxton equation arises in this context too, but in a different way.

== Variational structures and integrability ==

The [[integrable system|integrability]] of the Hunter–Saxton equation, or, more precisely, that of its ''x'' derivative

:&lt;math&gt;
(u_t + u u_x)_{xx} = u_x u_{xx},
&lt;/math&gt;

was shown by Hunter and Zheng,&lt;ref name="HZ94"&gt;Hunter &amp; Zheng 1994&lt;/ref&gt; who exploited that this equation is obtained from the [[Camassa–Holm equation]]

:&lt;math&gt;
u_t - u_{xxt} + 3 u u_x = 2 u_x u_{xx} + u u_{xxx}
&lt;/math&gt;

in the "high frequency limit"

:&lt;math&gt;
(x,t) \mapsto (\epsilon x, \epsilon t), \qquad \epsilon \to 0.
&lt;/math&gt;

Applying this limiting procedure to a Lagrangian for the Camassa–Holm equation, they obtained a Lagrangian

:&lt;math&gt;
\mathcal{L}_2 = \frac{1}{2} u_x^2 + w (v_t + u v_x)
&lt;/math&gt;

which produces the Hunter–Saxton equation after elimination of ''v'' and ''w'' from the Euler–Lagrange equations for ''u'', ''v'', ''w''. Since there is also the more obvious Lagrangian

:&lt;math&gt;
\mathcal{L}_1 = u_x u_t + u u_x^2,
&lt;/math&gt;

the Hunter–Saxton has two inequivalent variational structures. Hunter and Zheng also obtained a bihamiltonian formulation and a [[Lax pair]] from the corresponding structures for the Camassa–Holm equation in a similar way.

The fact that the Hunter–Saxton equation arises physically in two different ways (as shown above) was used by Alì and Hunter&lt;ref name="AH06"/&gt; to explain why it has this bivariational (or bihamiltonian) structure.

== Notes ==
{{reflist}}

== References ==
*{{Citation
 | last = Alì
 | first = Giuseppe
 | author-link =
 | last2 = Hunter
 | first2 = John K.
 | year = 2006
 | title = Orientation waves in a director field with rotational inertia
 | arxiv = math.AP/0609189
}}
*{{Citation
 | last = de Gennes
 | first = Pierre-Gilles
 | author-link = Pierre-Gilles de Gennes
 | last2 = Prost
 | first2 = Jacques
 | author2-link =
 | year = 1994
 | title = The Physics of Liquid Crystals
 | edition = 2nd
 | volume =
 | series = International Series of Monographs on Physics
 | place =
 | publisher = Oxford University Press
 | isbn = 0-19-852024-7
}}
*{{Citation
 | last = Hunter
 | first = John K.
 | last2 = Saxton
 | first2 = Ralph
 | year = 1991
 | title = Dynamics of director fields
 | periodical = SIAM J. Appl. Math.
 | volume = 51
 | issue = 6
 | pages = 1498–1521
 | url = 
 | doi = 10.1137/0151075
}}
*{{Citation
 | last = Hunter
 | first = John K.
 | author-link =
 | last2 = Zheng
 | first2 = Yuxi
 | year = 1994
 | title = On a completely integrable nonlinear hyperbolic variational equation
 | periodical = Physica D
 | volume = 79
 | issue = 2–4
 | pages = 361–386
 | url =
 | doi = 10.1016/S0167-2789(05)80015-6
|bibcode = 1994PhyD...79..361H }}

== Further reading ==
*{{Citation
 |last=Beals 
 |first=Richard 
 |author-link= Richard Beals (mathematician)
 |last2=Sattinger 
 |first2=David H. 
 |last3=Szmigielski 
 |first3=Jacek 
 |year=2001 
 |title=Inverse scattering solutions of the Hunter–Saxton equation 
 |periodical=Applicable Analysis 
 |volume=78 
 |issue=3–4 
 |pages=255–269 
 |url=http://www.math.usu.edu/~dhs/hunter209.ps 
 |doi=10.1080/00036810108840938 
}}{{dead link|date=April 2017 |bot=InternetArchiveBot |fix-attempted=yes }}
*{{Citation
 | last = Bressan
 | first = Alberto
 | author-link = Alberto Bressan
 | last2 = Constantin
 | first2 = Adrian
 | year = 2005
 | title = Global solutions of the Hunter–Saxton equation
 | periodical = SIAM J. Math. Anal.
 | volume = 37
 | issue = 3
 | pages = 996–1026
 | arxiv = math/0502059
 | doi = 10.1137/050623036
}}
*{{Citation
 |last=Holden 
 |first=Helge 
 |authorlink=Helge Holden 
 |last2=Karlsen 
 |first2=Kenneth Hvistendahl 
 |last3=Risebro 
 |first3=Nils Henrik 
 |year=2007 
 |title=Convergent difference schemes for the Hunter–Saxton equation 
 |periodical=Math. Comp. 
 |volume=76 
 |issue=258 
 |pages=699–745 
 |url=http://www.math.uio.no/eprint/pure_math/2005/20-05/index.html 
 |doi=10.1090/S0025-5718-07-01919-9 
 |bibcode=2007MaCom..76..699H 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20070922012502/http://www.math.uio.no/eprint/pure_math/2005/20-05/index.html 
 |archivedate=2007-09-22 
 |df= 
}}
*{{Citation
 | last = Hunter
 | first = John K.
 | author-link =
 | last2 = Zheng
 | first2 = Yuxi
 | year = 1995
 | title = On a nonlinear hyperbolic variational equation. I. Global existence of weak solutions
 | periodical = Arch. Rational Mech. Anal.
 | volume = 129
 | issue = 4
 | pages = 305–353
 | url =
 | doi = 10.1007/BF00379259
|bibcode = 1995ArRMA.129..305H }}
*{{Citation
 | last = Hunter
 | first = John K.
 | author-link =
 | last2 = Zheng
 | first2 = Yuxi
 | year = 1995
 | title = On a nonlinear hyperbolic variational equation. II. The zero-viscosity and dispersion limits
 | periodical = Arch. Rational Mech. Anal.
 | volume = 129
 | issue = 4
 | pages = 355–383
 | url =
 | doi = 10.1007/BF00379260
|bibcode = 1995ArRMA.129..355H }}
*{{Citation
 | last = Lenells
 | first = Jonatan
 | author-link =
 | year = 2007
 | title = The Hunter–Saxton equation describes the geodesic flow on a sphere
 | periodical = J. Geom. Phys.
 | volume = 57
 | issue = 10
 | pages = 2049–2064
 | url =
 | doi = 10.1016/j.geomphys.2007.05.003
|bibcode = 2007JGP....57.2049L }}

{{DEFAULTSORT:Hunter-Saxton equation}}
[[Category:Mathematical physics]]
[[Category:Solitons]]
[[Category:Partial differential equations]]
[[Category:Equations of fluid dynamics]]</text>
      <sha1>h4wf7cgxyw3jxdfcutzteac3nzju6xz</sha1>
    </revision>
  </page>
  <page>
    <title>Inequation</title>
    <ns>0</ns>
    <id>89486</id>
    <revision>
      <id>864516488</id>
      <parentid>864515145</parentid>
      <timestamp>2018-10-17T18:49:25Z</timestamp>
      <contributor>
        <username>Thine Antique Pen</username>
        <id>12529706</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/Architb12|Architb12]] ([[User talk:Architb12|talk]]): [[WP:SANDBOX|editing tests]] ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3327">{{Redirect-distinguish|≠|‡|ǂ}}
{{refimprove|date=March 2010}}

In [[mathematics]], an '''inequation''' is a statement that an [[inequality (mathematics)|inequality]] holds between two values.&lt;ref&gt;{{cite book |title=The A to Z of Mathematics: A Basic Guide |author=Thomas H. Sidebotham |page=252 |publisher=John Wiley and Sons |year=2002 |isbn=0-471-15045-2}}&lt;/ref&gt; It is usually written in the form of a pair of [[expression (mathematics)|expression]]s denoting the values in question, with a relational sign between them indicating the specific inequality relation. Some examples of inequations are:
:&lt;math&gt;a &lt; b,\,&lt;/math&gt;
:&lt;math&gt;x+y+z \leq 1,\,&lt;/math&gt;
:&lt;math&gt;n &gt; 1,\,&lt;/math&gt;
:&lt;math&gt;x \neq 0.\,&lt;/math&gt;
Some authors apply the term only to inequations in which the inequality relation is specifically not-equal-to (≠).&lt;ref&gt;{{MathWorld|title=Inequation|urlname=Inequation}}&lt;/ref&gt;

==Chains of inequations==
A shorthand notation is used for the [[conjunction (logic)|conjunction]] of several inequations involving common expressions, by chaining them together. For example, the chain
:&lt;math&gt;0 \leq a &lt; b \leq 1\,&lt;/math&gt;
is shorthand for
:&lt;math&gt;0 \leq a~\mathrm{and}~a&lt; b~\mathrm{and}~b\leq 1.\,&lt;/math&gt;

==Solving inequations==

[[File:Linear Programming Feasible Region.svg|thumb|Solution set for example inequations]]
Similar to [[equation solving]], '''inequation solving''' means finding what values (numbers, functions, sets, etc.) fulfill a condition stated in the form of an inequation or a conjunction of several inequations.
These expressions contain one or more ''unknowns'', which are free variables for which values are sought that cause the condition to be fulfilled. 
To be precise, what is sought are often not necessarily actual values, but, more in general, expressions. 
A '''solution''' of the inequation is an assignment of expressions to the ''unknowns'' that satisfies the inequation(s); in other words, expressions such that, when they are substituted for the unknowns, the inequations become true propositions.
Often, an additional '''objective''' expression is given that is to be minimized by an ''optimal'' solution.

For example, 

:&lt;math&gt;0 \leq x_1 \leq 690 - 1.5 \cdot x_2 \;\land\; 0 \leq x_2 \leq 530 - x_1 \;\land\; x_1 \leq 640 - 0.75 \cdot x_2&lt;/math&gt; 

is a conjunction of inequations, partly written as chains (where &lt;math&gt;\land&lt;/math&gt; can be read as "and"); the set of its solutions is shown in blue in the picture (the red, green, and orange line corresponding to the 1st, 2nd, and 3rd conjunct, respectively).
See [[Linear programming#Example]] for a larger example.

Computer support in solving inequations is described in [[constraint programming]];
in particular,  the [[simplex algorithm]] finds optimal solutions of linear inequations. 
The programming language [[Prolog]] III supports solving algorithms for particular classes of inequalities (and other relations) as a basic language feature, see [[constraint logic programming]].

== Special ==
:&lt;math&gt;\sqrt{{f(x)}} &lt; g(x)\Leftrightarrow&lt;/math&gt;&lt;math&gt;\begin{cases}
 f(x) \ge 0 \\
 g(x) &gt; 0\\
 f(x) &lt; \left [ g(x) \right ]^2 \quad
\end{cases}&lt;/math&gt;

==See also==
{{Wiktionary}}
* [[Equation]]
* [[Equals sign]]
* [[Inequality (mathematics)]]
* [[Relational operator]]

==References==
{{reflist}}

[[Category:Elementary algebra]]</text>
      <sha1>njkm97b9fuu9v8wvqu7apbvjkieml50</sha1>
    </revision>
  </page>
  <page>
    <title>Institute of Actuaries of France</title>
    <ns>0</ns>
    <id>23581664</id>
    <revision>
      <id>867407520</id>
      <parentid>800243139</parentid>
      <timestamp>2018-11-05T14:50:26Z</timestamp>
      <contributor>
        <username>RockGuitarWizard</username>
        <id>35063919</id>
      </contributor>
      <minor/>
      <comment>Improved clarity</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1425">{{update|date=August 2012}}
The '''Institute of Actuaries''' ({{lang-fr|Institut des Actuaires}}) is the association of [[actuary|actuaries]] in [[France]]. The Institute was created in 2001 by a merger of the Institute of Actuaries of France and the French Federation of Actuaries.&lt;ref&gt;Sibley, Angus: ''Nos collègues français'', [http://www.the-actuary.org.uk The Actuary], November 2006, p. 34-35&lt;/ref&gt; The Institute is a full member of the [[International Actuarial Association]] and the [[Groupe Consultatif]]. As of 2012, it has about 3 000 full members. Current president of the Institute is Thomas Behar.

In France the education of future actuaries will be facilitated by the national education system. The actuarial profession in France, in itself, has no such responsibility any more. But accrediting the diplomas awarded to the future actuaries is the responsibility of the French actuarial profession. Note that, these diplomas which accredited by French have access to the actuarial body. &lt;ref&gt;https://www.actuariesindia.org/downloads/gcadata/7thGCA/Frech%20Approach_Jean%20Berthon.pdf&lt;/ref&gt;

==References==

{{reflist|2}}

==External links==

* [http://www.institutdesactuaires.fr Institute of Actuaries official website]
* https://gaapsblog.com/category/actuarial-societies/france/institute-of-french-actuaries/

[[Category:Actuarial associations]]


{{business-org-stub}}
{{Statistics-stub}}
{{France-stub}}</text>
      <sha1>000gxlrxjdmvleuiz6bqet4gfh8013v</sha1>
    </revision>
  </page>
  <page>
    <title>Inversion in a sphere</title>
    <ns>0</ns>
    <id>34639861</id>
    <revision>
      <id>837795432</id>
      <parentid>744010512</parentid>
      <timestamp>2018-04-23T02:36:21Z</timestamp>
      <contributor>
        <username>Pauli133</username>
        <id>146032</id>
      </contributor>
      <minor/>
      <comment>cleanup</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10356">{{Multiple issues|
{{technical|date=March 2012}}
{{refimprove|date=March 2012}}
{{essay-like|date=March 2012}}
}}

[[File:Sphere inversion.png|thumb|400px|right|Inversion of a cylinder passing through the sphere.]]

In [[geometry]], '''inversion in a sphere''' is a [[Transformation (function)|transformation]] of [[Euclidean space]] that [[Fixed point (mathematics)|fixes]] the points of a [[sphere]] while sending the points inside of the sphere to the outside of the sphere, and vice versa. Intuitively, it "swaps the inside and outside" of the sphere while leaving the points on the sphere unchanged. Inversion is a [[conformal transformation]], and is the basic operation of [[inversive geometry]].

==Definition==
Inversion in a sphere is most easily described using [[polar coordinates]].  Choose a system of [[affine coordinates]] so that the centre of the sphere is at the [[origin (mathematics)|origin]] and the [[radius]] of the sphere is 1.  Then every point can be written in the form ''r'''''v''', where ''r'' is the distance from the point to the origin and '''v''' is a [[unit vector]]; moreover, for every point apart from the origin this representation is unique.  Given such a representation of a point, its image under spherical inversion is defined to be the point ''r''&lt;sup&gt;−1&lt;/sup&gt;'''v'''. This defines a [[homeomorphism]] from &lt;math&gt;\mathbb R^n\setminus\{0\}&lt;/math&gt; to itself. As a map from Euclidean space to itself, the spherical inversion map is not defined at the origin, but we can extend it to &lt;math&gt;\overline{\mathbb R^n}&lt;/math&gt;, the [[one-point compactification]] of &lt;math&gt;\mathbb R^n&lt;/math&gt;, by specifying that 0 should be sent to infinity and infinity should be sent to 0. Thus, spherical inversion can be thought of as a homeomorphism of &lt;math&gt;\overline{\mathbb R^n}&lt;/math&gt;.

==Properties==
Inversion is [[self-inverse]], and fixes the points lying on the sphere.  The inverse of a line is a [[circle]] through the centre of the reference sphere, and vice versa. The inverse of a plane is a sphere through the centre of the reference sphere, and vice versa. Otherwise the inverse of a circle is a circle; the inverse of a sphere is a sphere.

Inversion in a sphere is a powerful transformation. One simple example is in map projection.

The usual projection of the North or South Pole is inversion from the Earth to a plane. 
If instead of making  a pole the centre, we chose a city, then Inversion could produce a map where all the shortest routes (great circles) for flying from that city would appear as straight lines, which would simplify the flight path, for passengers at least.

==Proofs==
Let the reference sphere be Σ, with centre O and radius r denoted by {O, r}. All inverses, in this paper, are in the sphere Σ.

The results in this article are dependent on three simple ideas:
:1. Similar triangles: A scale model is the same shape as the original, i.e. all angles are kept.
:2. The angle in a semicircle is a right angle. i.e. For any point on a semicircle, the diagonal makes a right angle (90&lt;sup&gt;o&lt;/sup&gt;).
:3. The angles of a triangle add up to 180&lt;sup&gt;o&lt;/sup&gt;, so an external angle equals the sum of the other two internal angles.

===Definition===
* Let P be a point at distance n &gt; 0 from O.
* If P' be a point on OP, on the same direction as OP, such that OP.OP' = r&lt;sup&gt;2&lt;/sup&gt;, then P, and P' are inverse points
* If n &gt; r, then OP' &lt; r, so P' lies inside Σ, and vice versa.
* Points on the surface of Σ are the only self-inverse points.

===Construction===
* As in inversion in a circle, the usual construction, for a point, P, outside the sphere, is to take any plane through OP,&lt;br /&gt; draw tangents, in the plane, from P to Σ, meeting it at S, T.
* The intersection of the chord ST with OP gives P'. (Triangles OPS, OSP' are similar.)
* For a point P inside Σ, take a plane through OP, draw a chord of the sphere in that plane, normal to OP at P, meeting Σ, at S, T.
* Draw tangents, in the plane, to meet at P', the inverse of P.
* In either case, The right angled triangles, OPT, OTP' are similar, so OP/OT = OT/OP'
(See fig 1)
[[File:Inver in a sphere, Fig i.pdf|thumb|centre|450px|Fig 1]]

===Inversion of a pair of points===
* Given two points A, B with inverses A', B'; OA'.OA = r&lt;sup&gt;2&lt;/sup&gt;, OB'.OB = r&lt;sup&gt;2&lt;/sup&gt;.
* So OA'/OB' = OB/OA.
* Since ∠AOB is ∠B'OA', the triangles AOB, B'OA' are similar.
* So ∠OAB = ∠OB'A', ∠OBA = ∠OA'B'.
(See fig 2)
[[File:Inverin a sphere, Fig 2.pdf|thumb|centre|450px|Fig 2]]

===Inverse of a line===
:* If the line intersects Σ, then only the two points of intersection are self-inverse.
:* If O lies on the line, then the line is self inverse;
* Else,
:* Let P be the foot of the perpendicular from O to the line, with inverse P', and let X be any point on the line, with inverse X',
:* By 'Inversion of a pair of points', ∠OX'P'  = ∠OPX = 90&lt;sup&gt;o&lt;/sup&gt;.
:* So X' lies on a circle through O, with OP' as diameter. (Angle in a semicircle is a right angle)
(See fig 3)&lt;br /&gt;
[[File:Inver in a sphere, Fig 3h.pdf|thumb|centre|450px|Fig 3]]
Note 4:	Generally, the inverse of a line is a circle through the centre of reference.

===Inverse of a plane===
* If the plane intersects Σ, then each point of the circle of intersection is self-inverse.
* If O lies on the plane, the inverse is the plane;
* Else:
:* Let the foot of the perpendicular from O to the plane be P with inverse P'.
:* Let X be any point on the plane with inverse X'.
:* By 'Inversion of a pair of points', ∠OX'P' = ∠OPX = 90&lt;sup&gt;o&lt;/sup&gt;.
:* X' lies on a sphere with diameter OP'.(angle in a semicircle is a rightangle)
Note 5:	Generally, the inverse of a plane is a sphere through the centre of reference.

===Inverse of a Sphere===
:* Let the sphere be {A, a}, i.e. centre A and radius a &gt; 0.
:* If sphere{A, a} intersects Σ, the only self-inverse points are on the circle of intersection.
:* If A is at O then the inverse of sphere{A, a} is a concentric sphere with radius r&lt;sup&gt;2&lt;/sup&gt;/a;
::(Trivially, if a = r, then every point on {A, a} is self-inverse.)
* Else
:* if O lies on sphere{A, a},
:* Then let P be a point diametrically opposite O on sphere{A, a}, with P' the inverse of P.
:* Let X be any point on sphere{A, a}, with X' as inverse.
:* Then by 'Inversion of a pair of points' ∠OP'X' = ∠OXP = 90&lt;sup&gt;o&lt;/sup&gt; (angle in a semicircle).
:* This is true for all points on sphere{A, a}.
:* So X' lies on a plane through P' normal to OP'.

* Else,
:* Let S, T be the intersections of OA and sphere{A, a}, with S', T' their inverses.
:* ST is a diameter of {A, a}.
:* Let X be any point on sphere{A, a}, with inverse X'.
:* ∠OXT = ∠OT'X', and ∠OXS = ∠OS'X'.  (inverse of a pair of points)

* If T, S lie on the same side of O.
:* ∠T'X'S' = ∠OX'S' &amp;minus; ∠OX'T'
:* = ∠OSX &amp;minus; ∠OTX  (Inversion of a pair of points).
:* = ∠TXS (external angle equals sum of internal angles)
:* = 90&lt;sup&gt;o&lt;/sup&gt; (angle in a semicircle is a right angle)
:* So X' lies on a semicircle, with T'S' as diameter.
:* This is true for every point on sphere {A, a}.
:* So X' lies on a sphere, with T'S' as diameter.
(See fig 4)&lt;br /&gt;
[[File:Fig4b.pdf|thumb|centre|450px|Fig 4]]

* If T, S lie on opposite sides of O:
:* ∠OXT + ∠OXS  = 90&lt;sup&gt;o&lt;/sup&gt; (angle in a semi-circle is a rightangle).
:* ∠T'X'S' = ∠OX'T' + ∠OX'S'
:* = ∠OTX + ∠OSX  (inverse of a pair of points).
:* = 180&lt;sup&gt;o&lt;/sup&gt; &amp;minus; ∠TXS (angles in a triangle sum to 180&lt;sup&gt;o&lt;/sup&gt;)
:* So ∠T'X'S' = 90&lt;sup&gt;o&lt;/sup&gt;, and X' lies on a semicircle, with T'S' as diameter (angle in a semicircle is a rightangle).
:* As before:
:* This is true for every point on sphere {A, a}.
:* So X' lies on a sphere, with T'S' as diameter.
(See fig 5)&lt;br /&gt;
[[File:Inver in a sphere, Fig 5.pdf|thumb|centre|450px|Fig 5]]&lt;br /&gt;
Note 6: Generally the inverse of a sphere is a sphere&lt;br /&gt;
(The only exception is when the centre of the reference sphere lies on the sphere.)

===Inverse of a circle===
:* Let the circle be c, with centre C and radius a, lying on a plane ψ .
:* If c intersects the sphere, the only self-inverse points are those two intersections.
:* Let S, T be the nearest and furthest points of c, from O, (i.e. OT &gt; OS), with T', S' their inverses,
:* If C is at O then the inverse of c is a concentric circle with radius r&lt;sup&gt;2&lt;/sup&gt;/a;
* Else
:* if O lies on c,
:* Then let OP be a diameter of c, with P' the inverse of P.
:* Let X be any point of the circle, with inverse X'.
:* By 'Inversion of a pair of points', ∠OP'X' = ∠OXP = 90&lt;sup&gt;o&lt;/sup&gt;.
:* The inverse of points of the circle lie on a line in the plane of c, normal to OP';
* Else
:* If O lies in the plane of c, then c is a great circle of sphere {C, a}, in a plane through O, S, T, so arguments that applied to inverse of a sphere also apply to the inverse of circle c, with similar results to all those of Section 6.
(Cf Figs 3, 4, 5)
* Else,
:* in the general case, where O is not on ψ,the plane of c;
:* Let A, B be two points on a line through C, perpendicular to ψ.
:* Let Λ, Ω, be two spheres through c, with centres A, B, neither through O.
:* Let a spheres, Λ', Ω', be the inverses of Λ, Ω (see Note 6).
:* Every point of the inverse of c lies on both Λ' and Ω'.
:* The intersection of the spheres Λ', Ω' is a circle c', say, the inverse of c.

:* If O lis on the line AB, the cone of projection is right circular,
::and If c lies on sphere Σ, then every point of c is self-inverse;

Note 7: Generally the inverse of a circle is a circle. 
:(The only exception is when the centre of the reference sphere lies on the circle.

==Results of inversion in a sphere==
# A line through the centre of inversion is self-inverse.
# Generally, the inverse of a line is a circle through the centre of inversion.
# The inverse of a circle through the centre of inversion is a line.
# Generally the inverse of a circle is a circle.
# A plane through the centre of inversion is self-inverse.
# Generally, the inverse of a plane is a sphere through the centre of inversion.
# The inverse of a sphere through the centre of inversion is a plane.
# Generally the inverse of a sphere is a sphere.

== See also ==
* [[Inversive geometry]]
* [[Inverse curve]]
* [[:de:Inversion (Geometrie)|Inversion of curves and surfaces (German)]]

==References==
{{reflist}}

[[Category:Inversive geometry]]</text>
      <sha1>joc33jebkf2x99cdm5tk8bv7uuyr4e7</sha1>
    </revision>
  </page>
  <page>
    <title>John M. Sullivan (mathematician)</title>
    <ns>0</ns>
    <id>45108865</id>
    <revision>
      <id>857361660</id>
      <parentid>770932052</parentid>
      <timestamp>2018-08-31T05:39:10Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2300">'''John Matthew Sullivan''' (born February 25, 1963) is an American mathematician who works in Germany as a professor at the [[Technical University of Berlin]]. His research includes work on [[knot theory]], [[constant-mean-curvature surface]]s, [[Weaire–Phelan structure|mathematical foams]], [[scientific visualization]], and [[mesh generation]].&lt;ref name="cv"&gt;[http://page.math.tu-berlin.de/~sullivan/vita2-14.pdf Curriculum vitae], retrieved 2015-01-18.&lt;/ref&gt;

Sullivan was born in [[Princeton, New Jersey]], and graduated [[summa cum laude]] from [[Harvard University]] in 1985. He earned a master's degree from the [[University of Cambridge]] in 1986, and a doctorate from [[Princeton University]] in 1990 under the supervision of [[Frederick J. Almgren, Jr.]]&lt;ref name="cv"/&gt;&lt;ref&gt;{{mathgenealogy|id=17385}}&lt;/ref&gt; After postdoctoral studies at [[The Geometry Center]] and the [[Mathematical Sciences Research Institute]], he joined the faculty of the [[University of Illinois at Urbana–Champaign]] in 1997. He moved to Berlin in 2003, and chaired the [[Berlin Mathematical School]] from 2012 to 2014.&lt;ref name="cv"/&gt;

In 2012, he became one of the inaugural [[fellow]]s of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2015-01-18.&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*[http://page.math.tu-berlin.de/~sullivan/ Home page]
*[http://gallery.bridgesmathart.org/exhibitions/2010-bridges-conference/jms Mathematical art gallery], 2010 Bridges conference
*[https://scholar.google.com/citations?user=8OxlBc8AAAAJ Google scholar profile]

{{authority control}}

{{DEFAULTSORT:Sullivan, John Matthew}}
[[Category:1963 births]]
[[Category:Living people]]
[[Category:People from Princeton, New Jersey]]
[[Category:German mathematicians]]
[[Category:Harvard University alumni]]
[[Category:Alumni of the University of Cambridge]]
[[Category:Princeton University alumni]]
[[Category:University of Illinois at Urbana–Champaign faculty]]
[[Category:Technical University of Berlin faculty]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Mathematical artists]]</text>
      <sha1>to424cl692gjnw0z171082st1hpupqr</sha1>
    </revision>
  </page>
  <page>
    <title>Law of Continuity</title>
    <ns>0</ns>
    <id>13908785</id>
    <revision>
      <id>848453170</id>
      <parentid>848453135</parentid>
      <timestamp>2018-07-02T00:17:45Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3186">{{redirects|Principle of continuity||Dedekind cut}}

The '''law of continuity''' is a heuristic principle introduced by [[Gottfried Wilhelm Leibniz|Gottfried Leibniz]] based on earlier work by [[Nicholas of Cusa]] and [[Johannes Kepler]]. It is the principle that "whatever succeeds for the finite, also succeeds for the infinite".&lt;ref&gt;Karin Usadi Katz and [[Mikhail Katz|Mikhail G. Katz]] (2011) [http://www.springerlink.com/content/tj7j2810n8223p43/ A Burgessian Critique of Nominalistic Tendencies in Contemporary Mathematics and its Historiography]. [[Foundations of Science]]. {{doi|10.1007/s10699-011-9223-1}} See [https://arxiv.org/abs/1104.0375 arxiv]&lt;/ref&gt; Kepler used The Law of Continuity to calculate the area of the circle by representing the latter as an infinite-sided polygon with infinitesimal sides, and adding the areas of infinitely-many triangles with infinitesimal bases. Leibniz used the principle to extend concepts such as arithmetic operations, from ordinary numbers to [[infinitesimal]]s, laying the groundwork for [[infinitesimal calculus]]. A mathematical implementation of the law of continuity is provided by the [[transfer principle]] in the context of the [[hyperreal number]]s.

A related law of continuity concerning [[intersection number]]s in geometry was promoted by [[Jean-Victor Poncelet]] in his "Traité des propriétés projectives des figures". &lt;ref&gt;Poncelet, Jean Victor. [https://archive.org/details/traitdespropri01poncuoft Traité des propriétés projectives des figures]: T. 1. Ouvrage utile à ceux qui s' occupent des applications de la géométrie descriptive et d'opérations géométriques sur le terrain." (1865), pp. 13–14&lt;/ref&gt;&lt;ref&gt;Fulton, William. Introduction to intersection theory in algebraic geometry. No. 54. American Mathematical Soc., 1984, p. 1&lt;/ref&gt;


==Leibniz's formulation==
Leibniz expressed the law in the following terms in 1701:
:In any supposed continuous transition, ending in any terminus, it is permissible to institute a general reasoning, in which the final terminus may also be included (''Cum Prodiisset'').&lt;ref&gt;Child, J. M. (ed.): ''The early mathematical manuscripts of Leibniz''. Translated from the Latin texts published by Carl Immanuel Gerhardt with critical and historical notes by J. M. Child. Chicago-London: The Open Court Publishing Co., 1920.&lt;/ref&gt;

In a 1702 letter to French mathematician [[Pierre Varignon]] subtitled “Justification of the Infinitesimal Calculus by that of Ordinary Algebra," Leibniz adequately summed up the true meaning of his law, stating that "the rules of the finite are found to succeed in the infinite."&lt;ref&gt;Leibniz, Gottfried Wilhelm, and Leroy E. Loemker. Philosophical Papers and Letters. 2d ed. Dordrecht: D. Reidel, 1970, p. 544 &lt;/ref&gt; 

The Law of Continuity became important to Leibniz's justification and conceptualization of the infinitesimal calculus.

==See also==
*[[Transcendental Law of Homogeneity]]

== References ==
{{reflist}}

{{Gottfried Wilhelm Leibniz}}
{{Infinitesimals}}

[[Category:Non-standard analysis]]
[[Category:Gottfried Leibniz]]
[[Category:Infinity]]
[[Category:History of calculus]]
[[Category:Mathematics of infinitesimals]]</text>
      <sha1>9iqvw43axihrcwppskyoj8k993xby5n</sha1>
    </revision>
  </page>
  <page>
    <title>Left and right (algebra)</title>
    <ns>0</ns>
    <id>37520883</id>
    <revision>
      <id>664035263</id>
      <parentid>637680455</parentid>
      <timestamp>2015-05-26T00:53:23Z</timestamp>
      <contributor>
        <username>Mild Bill Hiccup</username>
        <id>5202324</id>
      </contributor>
      <comment>/* top */ An one → A one</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4524">{{other uses|Left and right (disambiguation)}}
{{refimprove|date=November 2012}}
{| align=right class="wikitable" style="margin-left:1em"
 |{{bigmath|''s a''}}&lt;br/&gt;{{bigmath|''s b''}}&lt;br/&gt;{{bigmath|''s c''}}&lt;br/&gt;{{bigmath|''s d''}}&lt;br/&gt;{{bigmath|''s e''}}&lt;br/&gt;{{bigmath|''s f''}}&lt;br/&gt;{{bigmath|''s g''}}&lt;br/&gt;…
 | align=right |{{bigmath|''a t''}}&lt;br/&gt;{{bigmath|''b t''}}&lt;br/&gt;{{bigmath|''c t''}}&lt;br/&gt;{{bigmath|''d t''}}&lt;br/&gt;{{bigmath|''e t''}}&lt;br/&gt;{{bigmath|''f t''}}&lt;br/&gt;{{bigmath|''g t''}}&lt;br/&gt;…
 |-
 | colspan=2 style="font-size:87%; width:10em" |Left multiplication to&amp;nbsp;{{mvar|s}} and right multiplication to&amp;nbsp;{{mvar|t}}. An abstract notation without any specific sense.
 |}
In [[algebra]], the terms '''left''' and '''right''' denote the order of a [[binary operation]] (usually, but not always called "[[multiplication]]") in non-[[commutative property|commutative]] [[algebraic structure]]s.
A binary operation&amp;nbsp;∗ is usually written [[infix notation|in the infix form]]:
:{{bigmath|''s'' ∗ ''t''}}
The [[argument of a function|argument]]&amp;nbsp;{{mvar|s}} is placed on the left side, and the argument&amp;nbsp;{{mvar|t}} is on the right side. Even if the symbol of the operation is omitted, the order of {{mvar|s}} and {{mvar|t}} does matter unless ∗ is commutative.

A '''two-sided''' property is fulfilled on both sides. A '''one-sided''' property is related to one (unspecified) of two sides.

Although terms are similar, left–right distinction in algebraic parlance is not related either to [[one-sided limit|left and right limits]] in calculus, or to [[orientation (geometry)|left and right in geometry]].

== Binary operation as an operator ==
A binary operation&amp;nbsp;{{bigmath|∗}} may be considered as a [[parametric family|family]] of [[unary operation|unary]] [[operator (mathematics)|operators]] through [[currying]]
:{{bigmath|1=''R''&lt;sub&gt;''t''&lt;/sub&gt;(''s'') = ''s'' ∗ ''t''}},
depending on&amp;nbsp;{{mvar|t}} as a parameter. It is the family of ''right'' operations. Similarly,
:{{bigmath|1=''L''&lt;sub&gt;''s''&lt;/sub&gt;(''t'') = ''s'' ∗ ''t''}}
defines the family of ''left'' operations parametrized with&amp;nbsp;{{mvar|s}}.

If for some&amp;nbsp;{{mvar|e}}, the left operation&amp;nbsp;{{math|''L''&lt;sub&gt;''e''&lt;/sub&gt;}} is [[identity function|identical]], then {{mvar|e}} is called a left [[identity element|identity]]. Similarly, if {{math|1=''R''&lt;sub&gt;''e''&lt;/sub&gt; = ''id''}}, then {{mvar|e}} is a right identity.

In [[ring theory]], a subring which is [[invariant set|invariant]] under ''any'' left multiplication in a ring, is called a left [[ideal (ring theory)|ideal]]. Similarly, a right multiplications-invariant subring is a right ideal.

== Left and right modules ==
Over [[non-commutative ring]]s, the left–right distinction is applied to [[module (mathematics)|modules]], namely to specify the side where a scalar (module element) appear in the [[scalar multiplication]]. 
{| align=center class="wikitable"
 !Left module
 !Right module
 |- align=center
 |{{bigmath|1=''s''('''x''' + '''y''') = ''s'''''x''' + ''s'''''y'''}}&lt;br/&gt;{{bigmath|1=(''s''&lt;sub&gt;1&lt;/sub&gt; + ''s''&lt;sub&gt;2&lt;/sub&gt;)'''x''' = ''s''&lt;sub&gt;1&lt;/sub&gt;'''x''' + ''s''&lt;sub&gt;2&lt;/sub&gt;'''x'''}} &lt;br/&gt;{{bigmath|1=''s''(''t'''''x''') = (''s t'')'''x'''}}
 |{{bigmath|1=('''x''' + '''y''')''t'' = '''x'''''t'' + '''y'''''t''}}&lt;br/&gt; {{bigmath|1='''x'''(''t''&lt;sub&gt;1&lt;/sub&gt; + ''t''&lt;sub&gt;2&lt;/sub&gt;) = '''x'''''t''&lt;sub&gt;1&lt;/sub&gt; + '''x'''''t''&lt;sub&gt;2&lt;/sub&gt;}}&lt;br/&gt;{{bigmath|1=('''x'''''s'')''t'' = '''x'''(''s t'')}}
 |}
The distinction is not purely syntactical because implies two different associativity rules (the lowest row in the table) which link multiplication in a module with multiplication in a ring.

A [[bimodule]] is simultaneously a left and right module, with two ''different'' scalar multiplication operations, obeying an obvious associativity condition on them.

== Other examples ==
* [[left eigenvector]]s
* left and right [[group action]]s

== In category theory ==
In [[category theory]] the usage of "left" is "right" has some algebraic resemblance, but refers to left and right sides of [[morphism]]s. See [[adjoint functors]].

== See also ==
* [[Operator associativity]]

== External links ==
* {{MathWorld|RightIdeal|title=right ideal|author=[[Margherita Barile|Barile, Margherita]]}}
* {{MathWorld|LeftIdeal|title=left ideal|author=[[Margherita Barile|Barile, Margherita]]}}
* {{MathWorld|LeftEigenvector|title=left eigenvector}}

[[Category:Abstract algebra]]
[[Category:Mathematical terminology]]</text>
      <sha1>60y59xz3ec1p7917u7dl43jj27c0ycf</sha1>
    </revision>
  </page>
  <page>
    <title>Lentoid</title>
    <ns>0</ns>
    <id>16834417</id>
    <revision>
      <id>762646051</id>
      <parentid>488082211</parentid>
      <timestamp>2017-01-29T23:53:26Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1322">'''Lentoid''' is a geometric shape of a [[Three-dimensional space|three-dimensional]] body, best described as a circle viewed from one direction and a [[lens (optics)|convex lens]] viewed from every orthogonal direction.  The term is most often used in describing [[jewellery|jewelry]] and [[cell (biology)|cellular]] phenomena in [[microbiology]].

== In history ==

Since ancient times, the lentoid shape has been used to fashion [[jewellery|jewelry]] and seals for identification made from a variety of [[gemstone]]s and metals.  In [[Minoan civilization|Minoan]] [[Crete]], for example, seals have been found with complex carving on lentoid stones.&lt;ref&gt;[http://www.metmuseum.org/toah/ho/03/eus/ho_14.104.1.htm Timeline of Art History: Lentoid seal with a griffin, Minoan Crete]&lt;/ref&gt;  The lentoid shape was one of the most commonly recovered [[Minoan seal-stones|seal shapes]] from Minoan [[Knossos]] on Crete dating to the [[Bronze Age]], as evidenced by the finds at that [[Bronze Age]] palace.&lt;ref&gt;C. Michael Hogan, [http://www.themodernantiquarian.com/site/10854/knossos.html#fieldnotes ''Knossos fieldnotes'', Modern Antiquarian (2007)]&lt;/ref&gt;

== See also ==

* [[Disc (mathematics)|Disc]]
* [[Oblate spheroid|Oblate sphere]]
* [[Spheroid]]

== References ==
{{reflist}}

[[Category:Jewellery]]

{{Geometry-stub}}</text>
      <sha1>icpa1205lc6wwqz323hv0mkzt5hhmc9</sha1>
    </revision>
  </page>
  <page>
    <title>Limit point</title>
    <ns>0</ns>
    <id>226505</id>
    <revision>
      <id>870697326</id>
      <parentid>868924175</parentid>
      <timestamp>2018-11-26T13:40:34Z</timestamp>
      <contributor>
        <ip>134.59.11.233</ip>
      </contributor>
      <comment>/* Definition */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9983">In [[mathematics]], a '''limit point''' (or '''cluster point''' or '''accumulation point''') of a [[set (mathematics)|set]] ''S'' in a [[topological space]] ''X'' is a point ''x'' that can be "approximated" by points of ''S'' in the sense that every [[Neighbourhood (mathematics)|neighbourhood]] of ''x'' with respect to the [[topology]] on ''X'' also contains a point of ''S'' other than ''x'' itself. A limit point of a set ''S'' does not itself have to be an element of ''S''.

This concept profitably generalizes the notion of a [[Limit (mathematics)|limit]] and is the underpinning of concepts such as [[closed set]] and [[topological closure]]. Indeed, a set is closed if and only if it contains all of its limit points, and the topological closure operation can be thought of as an operation that enriches a set by uniting it with its limit points.

There is also a closely related concept for [[sequence|sequences]]. A '''cluster point''' (or '''accumulation point''') of a [[sequence]] (''x''&lt;sub&gt;''n''&lt;/sub&gt;)&lt;sub&gt;''n''&amp;nbsp;∈&amp;nbsp;'''N'''&lt;/sub&gt; in a [[topological space]] ''X'' is a point ''x'' such that, for every neighbourhood ''V'' of ''x'', there are infinitely many natural numbers ''n'' such that ''x&lt;sub&gt;n&lt;/sub&gt;''&amp;nbsp;∈&amp;nbsp;''V''. This concept generalizes to [[net (mathematics)|nets]] and [[filter (mathematics)|filters]]. 

==Definition==
Let ''S'' be a subset of a [[topological space]] ''X''. 
A point ''x'' in ''X'' is a '''limit point''' (or '''cluster point''' or '''accumulation point''') of ''S'' if every [[Neighbourhood (mathematics)|neighbourhood]] of ''x'' contains at least one point of ''S'' different from ''x'' itself. 

Note that it doesn't make a difference if we restrict the condition to open neighbourhoods only. It is often convenient to use the "open neighbourhood" form of the definition to show that a point is a limit point and to use the "general neighbourhood" form of the definition to derive facts from a known limit point. 

If ''X'' is a [[T1 space|''T''&lt;sub&gt;1&lt;/sub&gt; space]] (which all [[metric space|metric spaces]] are), then ''x'' &amp;isin; ''X'' is a limit point of ''S'' if and only if every neighbourhood of ''x'' contains infinitely many points of ''S''. Indeed, ''T''&lt;sub&gt;1&lt;/sub&gt; spaces are characterized by this property. 

If ''X'' is a [[sequential space#Fréchet-Urysohn space|Fréchet–Urysohn space]] (which all [[metric space|metric spaces]] and [[first-countable space|first-countable spaces]] are), then ''x'' &amp;isin; ''X'' is a limit point of ''S'' if and only if there is a [[sequence]] of points in ''S''&amp;nbsp;\&amp;nbsp;{''x''} whose [[limit of a sequence|limit]] is ''x''. Indeed, Fréchet–Urysohn spaces are characterized by this property.

==Types of limit points==
{| style="float:right"
| [[File:Diagonal argument.svg|thumb|A sequence enumerating all positive [[rational number]]s. Each positive [[real number]] is a cluster point.]]
|}
{| style="float:right"
| [[File:Rational sequence with 2 accumulation points svg.svg|thumb|400px|With respect to the usual [[Topological space#Examples of topological spaces|Euclidean topology]], the sequence of rational numbers ''x''&lt;sub&gt;''n''&lt;/sub&gt; = (-1)&lt;sup&gt;''n''&lt;/sup&gt;·{{sfrac|''n''|''n''+1}} has no ''[[Limit of a sequence#Topological spaces|limit]]'' (i.e. does not converge), but has two accumulation points (which are considered ''limit points'' here), viz. -1 and +1. Thus, thinking of sets, these points are limit points of the set {''x''&lt;sub&gt;''n''&lt;/sub&gt;}.]]
|}
If every open set containing ''x'' contains infinitely many points of ''S'' then ''x'' is a specific type of limit point called an '''ω-accumulation point of ''S'''''.

If every open set containing ''x'' contains uncountably many points of ''S'' then ''x'' is a specific type of limit point called a '''[[condensation point]] of ''S'''''.

If every open set ''U'' containing ''x'' satisfies {{nowrap|{{!}}''U'' &amp;cap; ''S''{{!}} {{=}} {{!}}''S''{{!}}}} then ''x'' is a specific type of limit point called a '''{{visible anchor|complete accumulation point}} of ''S'''''.

==For Sequences and Nets==
In a topological space &lt;math&gt;X&lt;/math&gt;, a point &lt;math&gt;x \in X&lt;/math&gt; is said to be a '''cluster point'''  (or '''accumulation point''') of a sequence &lt;math&gt;(x_n)_{n \in \mathbb{N}} &lt;/math&gt; if, for every [[Neighbourhood (mathematics)|neighbourhood]] &lt;math&gt;V&lt;/math&gt; of &lt;math&gt; x &lt;/math&gt;, there are infinitely many &lt;math&gt; n \in \mathbb{N} &lt;/math&gt; such that &lt;math&gt; x_n \in V &lt;/math&gt;. It is equivalent to say that for every [[Neighbourhood (mathematics)|neighbourhood]] &lt;math&gt;V&lt;/math&gt; of &lt;math&gt; x &lt;/math&gt; and every &lt;math&gt; n_0 \in \mathbb{N} &lt;/math&gt;, there is some &lt;math&gt; n \geq n_0 &lt;/math&gt; such that &lt;math&gt; x_n \in V &lt;/math&gt;. If &lt;math&gt;X&lt;/math&gt; is a [[metric space]] or a [[first-countable space]]  (or, more generally, a [[Fréchet–Urysohn space]]), then &lt;math&gt;x&lt;/math&gt; is cluster point of &lt;math&gt;(x_n)_{n \in \mathbb{N}} &lt;/math&gt; if and only if &lt;math&gt;x &lt;/math&gt; is a limit of some subsequence of &lt;math&gt;(x_n)_{n \in \mathbb{N}} &lt;/math&gt;. 
The set of all cluster points of a sequence is sometimes called the [[limit set]]. 

The concept of a [[net (mathematics)|net]] generalizes the idea of a [[sequence]]. A net is a function &lt;math&gt;f:(P,\le)\to X&lt;/math&gt;, where &lt;math&gt;(P,\le) &lt;/math&gt; is a [[directed set]] and &lt;math&gt; X &lt;/math&gt; is a topological space. A point &lt;math&gt;x\in X &lt;/math&gt; is said to be a '''cluster point'''  (or '''accumulation point''') of the net &lt;math&gt;f &lt;/math&gt; if, for every [[Neighbourhood (mathematics)|neighbourhood]] &lt;math&gt;V&lt;/math&gt; of &lt;math&gt; x &lt;/math&gt; and every &lt;math&gt;p_0 \in P&lt;/math&gt;, there is some &lt;math&gt; p \ge p_0  &lt;/math&gt; such that &lt;math&gt; f(p)\in V &lt;/math&gt;, equivalently, if &lt;math&gt;f&lt;/math&gt; has a [[Subnet (mathematics)|subnet]] which converges to &lt;math&gt;x&lt;/math&gt;. Cluster points in nets encompass the idea of both condensation points and ω-accumulation points. Clustering and limit points are also defined for the related topic of [[filter (mathematics)|filters]].

==Some Facts==
*We have the following characterization of limit points: ''x'' is a limit point of ''S'' if and only if it is in the [[closure (topology)|closure]] of ''S'' \ {''x''}.
**''Proof'': We use the fact that a point is in the closure of a set if and only if every neighborhood of the point meets the set. Now, ''x'' is a limit point of ''S'', if and only if every neighborhood of ''x'' contains a point of ''S'' other than ''x'', if and only if every neighborhood of ''x'' contains a point of ''S'' \ {''x''}, if and only if ''x'' is in the closure of ''S'' \ {''x''}.
*If we use L(''S'') to denote the set of limit points of ''S'', then we have the following characterization of the closure of ''S'': The closure of ''S'' is equal to the union of ''S'' and L(''S''). This fact is sometimes taken as the ''definition'' of [[closure (topology)|closure]].
**''Proof'': ("Left subset") Suppose ''x'' is in the closure of ''S''. If ''x'' is in ''S'', we are done. If ''x'' is not in ''S'', then every neighbourhood of ''x'' contains a point of ''S'', and this point cannot be ''x''. In other words, ''x'' is a limit point of ''S'' and ''x'' is in L(''S''). ("Right subset") If ''x'' is in ''S'', then every neighbourhood of ''x'' clearly meets ''S'', so ''x'' is in the closure of ''S''. If ''x'' is in L(''S''), then every neighbourhood of ''x'' contains a point of ''S'' (other than ''x''), so ''x'' is again in the closure of ''S''. This completes the proof.
*A corollary of this result gives us a characterisation of closed sets: A set ''S'' is closed if and only if it contains all of its limit points.
**''Proof'': ''S'' is closed if and only if ''S'' is equal to its closure if and only if ''S'' = ''S'' ∪ L(''S'') if and only if L(''S'') is contained in ''S''.
**''Another proof'': Let ''S'' be a closed set and ''x'' a limit point of ''S''. If ''x'' is not in ''S'',  then the complement to ''S'' comprises an open neighbourhood of ''x''. Since ''x'' is a limit point of ''S'', any open neighbourhood of ''x'' should have a non-trivial intersection with ''S''. However, a set can not have a non-trivial intersection with its complement. Conversely, assume ''S'' contains all its limit points. We shall show that the complement of ''S'' is an open set. Let ''x'' be a point in the complement of ''S''. By assumption, ''x'' is not a limit point, and hence there exists an open neighbourhood ''U'' of ''x'' that does not intersect ''S'', and so ''U'' lies entirely in the complement of ''S''. Since this argument holds for arbitrary ''x'' in the complement of ''S'', the complement of ''S'' can be expressed as a union of open neighbourhoods of the points in the complement of ''S''. Hence the complement of ''S'' is open.
*No [[isolated point]] is a limit point of any set.
**''Proof'': If ''x'' is an isolated point, then {''x''} is a neighbourhood of ''x'' that contains no points other than ''x''.
*A space ''X'' is [[discrete space|discrete]] if and only if no subset of ''X'' has a limit point.
**''Proof'': If ''X'' is discrete, then every point is isolated and cannot be a limit point of any set. Conversely, if ''X'' is not discrete, then there is a singleton {''x''} that is not open. Hence, every open neighbourhood of {''x''} contains a point ''y'' ≠ ''x'', and so ''x'' is a limit point of ''X''.
* If a space ''X'' has the [[trivial topology]] and ''S'' is a subset of ''X'' with more than one element, then all elements of ''X'' are limit points of ''S''. If ''S'' is a singleton, then every point of ''X'' \ ''S'' is still a limit point of ''S''.
**''Proof'': As long as ''S'' \ {''x''} is nonempty, its closure will be ''X''. It's only empty when ''S'' is empty or ''x'' is the unique element of ''S''.
* By definition, every limit point is an [[adherent point]].

==References==
* {{springer|title=Limit point of a set|id=p/l058880}}

==External links==
* {{planetmath reference|id=1240|title=limit point}}

[[Category:Limit sets| ]]
[[Category:Topology]]
[[Category:General topology]]</text>
      <sha1>bstzzfwb7e3v2ykc5gb3wn4v15m2wxc</sha1>
    </revision>
  </page>
  <page>
    <title>Line–sphere intersection</title>
    <ns>0</ns>
    <id>5540055</id>
    <revision>
      <id>790896076</id>
      <parentid>790445855</parentid>
      <timestamp>2017-07-16T20:43:19Z</timestamp>
      <contributor>
        <ip>174.7.100.16</ip>
      </contributor>
      <comment>Undid revision 790445855 by [[Special:Contributions/144.212.3.4|144.212.3.4]] ([[User talk:144.212.3.4|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3846">[[File:Line-Sphere Intersection Cropped.png|thumb|350px|right|The three possible line-sphere intersections:&lt;br /&gt;
1. No intersection.&lt;br /&gt;
2. Point intersection.&lt;br /&gt;
3. Two point intersection.]]

In [[analytic geometry]], a [[line (mathematics)|line]] and a [[sphere]] can [[intersection (set theory)|intersect]] in three ways: no intersection at all, at exactly one point, or in two points. Methods for distinguishing these cases, and determining equations for the points in the latter cases, are useful in a number of circumstances. For example, this is a common calculation to perform during [[ray tracing (graphics)|ray tracing]] (Eberly 2006:698).

== Calculation using vectors in 3D ==
In [[vector notation]], the equations are as follows:

Equation for a [[sphere]]
:&lt;math&gt;\left\Vert \mathbf{x} - \mathbf{c} \right\Vert^2=r^2&lt;/math&gt;
:*&lt;math&gt;\mathbf{c}&lt;/math&gt; - center point
:*&lt;math&gt;r&lt;/math&gt; - radius
:*&lt;math&gt;\mathbf{x}&lt;/math&gt; - points on the sphere

Equation for a line starting at &lt;math&gt;\mathbf{o}&lt;/math&gt;
:&lt;math&gt;\mathbf{x}=\mathbf{o} + d\mathbf{l}&lt;/math&gt;
:*&lt;math&gt;d&lt;/math&gt; - distance along line from starting point
:*&lt;math&gt;\mathbf{l}&lt;/math&gt; - direction of line (a [[unit vector]])
:*&lt;math&gt;\mathbf{o}&lt;/math&gt; - origin of the line
:*&lt;math&gt;\mathbf{x}&lt;/math&gt; - points on the line

Searching for points that are on the line and on the sphere means combining the equations and solving for &lt;math&gt;d&lt;/math&gt;:

:Equations combined
::&lt;math&gt;\left\Vert \mathbf{o} + d\mathbf{l} - \mathbf{c} \right\Vert^2=r^2 \Leftrightarrow (\mathbf{o} + d\mathbf{l} - \mathbf{c}) \cdot (\mathbf{o} + d\mathbf{l} - \mathbf{c}) = r^2&lt;/math&gt;
:Expanded
::&lt;math&gt;d^2(\mathbf{l}\cdot\mathbf{l})+2d(\mathbf{l}\cdot(\mathbf{o}-\mathbf{c}))+(\mathbf{o}-\mathbf{c})\cdot(\mathbf{o}-\mathbf{c})=r^2&lt;/math&gt;
:Rearranged
::&lt;math&gt;d^2(\mathbf{l}\cdot\mathbf{l})+2d(\mathbf{l}\cdot(\mathbf{o}-\mathbf{c}))+(\mathbf{o}-\mathbf{c})\cdot(\mathbf{o}-\mathbf{c})-r^2=0&lt;/math&gt;
:The form of a [[quadratic formula]] is now observable. (This quadratic equation is an example of Joachimsthal's Equation [http://mathworld.wolfram.com/JoachimsthalsEquation.html].)
::&lt;math&gt;a d^2 + b d + c = 0&lt;/math&gt;
:where
:*&lt;math&gt;a=\mathbf{l}\cdot\mathbf{l}=\left\Vert\mathbf{l}\right\Vert^2&lt;/math&gt;
:*&lt;math&gt;b=2(\mathbf{l}\cdot(\mathbf{o}-\mathbf{c}))&lt;/math&gt;
:*&lt;math&gt;c=(\mathbf{o}-\mathbf{c})\cdot(\mathbf{o}-\mathbf{c})-r^2=\left\Vert\mathbf{o}-\mathbf{c}\right\Vert^2-r^2&lt;/math&gt;
:Simplified
::&lt;math&gt;d=\frac{-2(\mathbf{l}\cdot(\mathbf{o}-\mathbf{c})) \pm \sqrt{(2(\mathbf{l}\cdot(\mathbf{o}-\mathbf{c})))^2-4\left\Vert\mathbf{l}\right\Vert^2(\left\Vert\mathbf{o}-\mathbf{c}\right\Vert^2-r^2)}}{2 \left\Vert\mathbf{l}\right\Vert^2}&lt;/math&gt;
:Note that &lt;math&gt;\mathbf{l}&lt;/math&gt; is a unit vector, and thus &lt;math&gt;\left\Vert\mathbf{l}\right\Vert^2=1&lt;/math&gt;. Thus, we can simplify this further to
::&lt;math&gt;d=-(\mathbf{l}\cdot(\mathbf{o}-\mathbf{c})) \pm \sqrt{(\mathbf{l}\cdot(\mathbf{o}-\mathbf{c}))^2-\left\Vert\mathbf{o}-\mathbf{c}\right\Vert^2+r^2}&lt;/math&gt;

*If the value under the square-root (&lt;math&gt;(\mathbf{l}\cdot(\mathbf{o}-\mathbf{c}))^2-\left\Vert\mathbf{o}-\mathbf{c}\right\Vert^2+r^2&lt;/math&gt;) is less than zero, then it is clear that no solutions exist, i.e. the line does not intersect the sphere (case 1).
*If it is zero, then exactly one solution exists, i.e. the line just touches the sphere in one point (case 2).
*If it is greater than zero, two solutions exist, and thus the line touches the sphere in two points (case 3).

==See also==
*[[Analytic geometry]]
*[[Line-plane intersection]]
*[[Plane (mathematics)|Line of intersection between two planes]]

== References ==
* David H. Eberly (2006), ''3D game engine design: a practical approach to real-time computer graphics'', 2nd edition, Morgan Kaufmann. {{ISBN|0-12-229063-1}}

{{DEFAULTSORT:Line-sphere intersection}}
[[Category:Analytic geometry]]</text>
      <sha1>srq9glkcf84xmbtj0rr9fiy8vyisl9a</sha1>
    </revision>
  </page>
  <page>
    <title>List of companies involved in quantum computing or communication</title>
    <ns>0</ns>
    <id>51647821</id>
    <revision>
      <id>866196160</id>
      <parentid>866195431</parentid>
      <timestamp>2018-10-28T22:05:13Z</timestamp>
      <contributor>
        <username>Geek3</username>
        <id>25288155</id>
      </contributor>
      <comment>wikilinks</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19629">{| class="wikitable sortable"
|-
! Company !! Date initiated !! Area 
!Technology!! Affiliate University or Research Institute !! Headquarters
|-

| [[1QBit]] || {{dts|2012|12|1}} || Computing 
| ||  || [[Vancouver]], Canada
|-

| [[Accenture]]&lt;ref&gt;{{Cite web|url=https://newsroom.accenture.com/news/accenture-labs-and-1qbit-work-with-biogen-to-apply-quantum-computing-to-accelerate-drug-discovery.htm|title=(Press Release) Accenture Labs and 1QBit Work with Biogen to Apply Quantum Computing to Accelerate Drug Discovery {{!}} Accenture Newsroom|last=|first=|date=|website=newsroom.accenture.com|language=en|archive-url=|archive-date=|dead-url=|access-date=2017-10-04}}&lt;/ref&gt; || {{dts|2017|06|14}} || Computing 
| ||  || 
|-
| [[Airbus]]&lt;ref&gt;{{Cite news|url=https://www.telegraph.co.uk/finance/newsbysector/industry/12065245/Airbuss-quantum-computing-brings-Silicon-Valley-to-the-Welsh-Valleys.html|title=Airbus's quantum computing brings Silicon Valley to the Welsh Valleys|last=Tovey|first=Alan|date=2015-12-26|access-date=2017-11-02|language=en-GB|issn=0307-1235}}&lt;/ref&gt; || {{dts|2015}} || Computing 
|algorithms||  || [[Blagnac]], France
|-
| [[Aliyun|Aliyun (Alibaba Cloud)]]&lt;ref name=":0"&gt;{{Cite web|url=http://www.alibabagroup.com/en/news/article?news=p150730|title=(Press Release) Alibaba Group|last=|first=|date=|website=www.alibabagroup.com|language=en|archive-url=|archive-date=|dead-url=|access-date=2017-10-04}}&lt;/ref&gt; || {{dts|2015|07|30}} || Computing/Communication&lt;ref name=":0" /&gt;&lt;ref name=":3" /&gt; 
| ||[[Chinese Academy of Sciences]] &lt;ref name=":1"&gt;{{Cite web|url=http://www.businesswire.com/news/home/20171010006804/en/Alibaba-Launches-Global-Research-Program-Cutting-Edge-Technology|title=Alibaba Launches Global Research Program for Cutting-Edge Technology Development|website=www.businesswire.com|language=en|access-date=2017-11-01}}&lt;/ref&gt;&lt;ref name=":3"&gt;{{Cite web|url=http://www.businesscloudnews.com/2015/08/03/alibaba-looks-to-quantum-computing-for-next-gen-cloud/|title=Alibaba looks to quantum computing for next-gen cloud  {{!}} Business Cloud News|website=www.businesscloudnews.com|access-date=2017-11-01}}&lt;/ref&gt;&lt;ref name=":2"&gt;{{Cite news|url=https://qz.com/1099535/alibaba-is-plowing-15-billion-into-rd-with-seven-new-research-labs-worldwide/|title=Alibaba is plowing $15 billion into R&amp;D with seven new research labs worldwide|last=Horwitz|first=Josh|work=Quartz|access-date=2017-11-01|language=en-US}}&lt;/ref&gt;
| [[Hangzhou]], China
|-
| Alpine Quantum Technologies&lt;ref&gt;{{cite web | url=https://www.aqt.eu/ | title=Alpine Quantum Technologies}}&lt;/ref&gt; || {{dts|2017|12|30}} || Computing 
|[[Trapped ion quantum computer|ions]]|| University of Innsbruck || [[Innsbruck]], Austria
|-
| [[AT&amp;T]]&lt;ref&gt;{{Cite web|url=http://www.research.att.com/articles/featured_stories/2010_12/201101_Entangled_photons.html?fbid=mOgHpwPxjjs|title=(Press Release) AT&amp;T Labs Research - Photon Entanglement over the Fiber-Optic Network|last=|first=|date=|website=www.research.att.com|archive-url=|archive-date=|dead-url=|access-date=2017-10-04}}&lt;/ref&gt; || {{dts|2011}}  || Communication 
| ||  || [[Dallas]], TX, USA
|-f
| [[Atos]]&lt;ref&gt;{{Cite news|url=https://ascent.atos.net/race-time-securing-future-data-quantum-encryption/|title=(Press Release) Race Against Time: Securing our Future Data with Quantum Encryption - Ascent|last=|first=|date=2015-03-16|work=Ascent|access-date=2017-10-04|archive-url=|archive-date=|dead-url=|language=en-US}}&lt;/ref&gt; || || Communication 
| ||  || [[Bezons]], France
|-
| [[Booz Allen Hamilton]]&lt;ref&gt;{{Cite news|url=http://www.boozallen.com/consulting/strategic-innovation/nextgen-analytics-data-science/quantum-computing|title=Press Release|last=|first=|date=|work=|access-date=|archive-url=|archive-date=|dead-url=}}&lt;/ref&gt; || || Computing 
| ||  || [[Tysons Corner]], VA, USA
|-
| [[BT Group|BT]]&lt;ref&gt;{{Cite web|url=http://www.quantumcommshub.net/wp-content/src/Tim-WHITLEY_Quantum-Hub-Launch.pdf|title=PDF|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; || || Communication 
| ||  || [[London]], UK
|-
| [[Carl Zeiss AG]]&lt;ref&gt;{{Cite web|url=http://www.uclq.org/about/industry-partners/|title=Industry Projects {{!}} UCL Quantum|website=www.uclq.org|language=en-US|access-date=2017-10-04}}&lt;/ref&gt; || || 
| || University College London || [[Oberkochen]], Germany
|-
|Cambridge Quantum Computing Limited&lt;ref&gt;{{Cite web|url=http://www.prnewswire.co.uk/news-releases/certified-true-randomness-created-by-cambridge-quantum-computing-637200823.html|title=Certified True Randomness Created by Cambridge Quantum Computing|last=Computing|first=Cambridge Quantum|website=www.prnewswire.co.uk|access-date=2017-11-04}}&lt;/ref&gt;
|
|Communication
|
|
|[[Cambridge]], UK
|-
| [[D-Wave Systems|D-Wave]] || {{dts|1999|1|1}} || Computing 
|superconducting||  || [[Burnaby]], Canada
|-
|[https://elyah.io Elyah]&lt;ref&gt;{{Cite web|url=http://www.elyah.io/|title=Elyah|website=www.elyah.io|language=en|access-date=2018-02-21}}&lt;/ref&gt;|| {{dts|2018|6|6}} || Computing 
|algorithms||  || [[Dubai, UAE]]
|-
| Everettian Technologies&lt;ref&gt;{{Cite web|url=http://www.everettian.com/|title=Everettian Technologies Inc.|website=www.everettian.com|language=en|access-date=2018-02-21}}&lt;/ref&gt; || {{dts|2017|9|1}} || Computing 
| ||  || [[Waterloo, Canada]]
|-
| [[Fujitsu]]&lt;ref&gt;{{Cite web|url=http://www.fujitsu.com/global/about/resources/news/press-releases/2015/0928-02.html|title=(press release) University of Tokyo, Fujitsu, and NEC Succeed in Quantum Key Distribution from Single-Photon Emitter at World-Record Distance of 120 km - Fujitsu Global|last=|first=|date=|website=www.fujitsu.com|language=en|archive-url=|archive-date=|dead-url=|access-date=2017-10-04}}&lt;/ref&gt; || {{dts|2015|9|28}} || Communication 
|quantum dots||[[University of Tokyo]] || [[Tokyo]], Japan
|-
| [[Google]] QuAIL&lt;ref&gt;{{Cite news|url=https://research.googleblog.com/2013/05/launching-quantum-artificial.html|title=(Press Release) Launching the Quantum Artificial Intelligence Lab|last=|first=|date=|work=Research Blog|access-date=2017-10-04|archive-url=|archive-date=|dead-url=|language=en-US}}&lt;/ref&gt; || {{dts|2013|5|16}} || Computing 
|superconducting||[[UCSB]] || [[Mountain View, California|Mountain View]], CA, USA
|-
| [[Hewlett-Packard|HP]]&lt;ref name=":6"&gt;{{Cite web|url=http://www.hpl.hp.com/research/qip/|title=HP Labs : Quantum Information Processing (QIP)|website=www.hpl.hp.com|access-date=2017-10-04}}&lt;/ref&gt;&lt;ref name=":7"&gt;{{Cite web|url=http://www.hpl.hp.com/research/idl/projects/quantum/|title=Research at HP Labs : Information Dynamics Lab : Research Areas : Quantum Computing|website=www.hpl.hp.com|language=en-us|access-date=2017-11-01}}&lt;/ref&gt; || || Computing&lt;ref name=":6" /&gt;/Communication&lt;ref name=":7" /&gt; 
|algorithms, [[Nuclear magnetic resonance quantum computer|NMR]]||  || [[Palo Alto]], CA, USA
|-
| [[Hitachi]] || || Computing 
| || University of Cambridge, University College London || Tokyo, Japan
|-
| [[Honeywell]]&lt;ref name=":4"&gt;{{Cite web|url=http://www.news.gatech.edu/2014/06/11/development-new-ion-traps-advances-quantum-computing-systems|title=(Press Release) Development of New Ion Traps Advances Quantum Computing Systems|last=|first=|date=|website=www.news.gatech.edu|language=en|archive-url=|archive-date=|dead-url=|access-date=2017-10-04}}&lt;/ref&gt;&lt;ref name=":5"&gt;{{Cite web|url=http://physicsworld.com/cws/article/news/2016/aug/03/ion-trap-quantum-computer-is-programmable-and-reconfigurable|title=Ion-trap quantum computer is programmable and reconfigurable - physicsworld.com|website=physicsworld.com|language=en-GB|access-date=2017-11-01}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.honeywell.com/quantumsolutions|title=Quantum Solutions {{!}} Honeywell|website=Honeywell|language=en|access-date=2018-10-04}}&lt;/ref&gt;||  || Computing 
|[[Trapped ion quantum computer|ions]]||[[Georgia Institute of Technology|Georgia Tech]],&lt;ref name=":4" /&gt; [[University of Maryland, College Park|University of Maryland]]&lt;ref name=":5" /&gt; || [[Morris Plains]], NJ, USA
|-
| [[HRL Laboratories]] || || Computing 
| ||  || [[Malibu, California|Malibu, CA, USA]]
|-
| [[Huawei]] Noah's Ark Lab&lt;ref&gt;{{Cite web|url=http://stuex.nju.edu.cn/en/a/Research_Organizations/20150808/483.html|title=|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; || || Communication 
| ||[[Nanjing University]] || [[Shenzhen]], China
|-
| [[IBM]]&lt;ref&gt;{{Cite web|url=http://researcher.ibm.com/researcher/view_group.php?id=5881|title=Theory of quantum computing and information group - IBM|date=2016-07-25|website=researcher.ibm.com|language=en-US|access-date=2017-10-04}}&lt;/ref&gt; || {{dts|1990|9|10}}&lt;ref&gt;C.H. Bennett et al., J. Cryptology 5, 3 (1992) doi:10.1007/BF00191318&lt;/ref&gt; || Computing 
|superconducting||[[MIT]]&lt;ref&gt;{{Cite web|url=http://mitibmwatsonailab.mit.edu|title=MIT-IBM Watson AI Lab}}&lt;/ref&gt; || [[Armonk]], NY, USA
|-
| [[ID Quantique]] || {{dts|2001|7|1}} || Communication 
| ||  || [[Geneva]], Switzerland
|-
| [[imec]]&lt;ref&gt;{{Cite web|url=https://www.imec-int.com/en/quantum-computing}}&lt;/ref&gt; || || Computing 
|superconducting||  || Belgium  
|-
| [[ionQ]]&lt;ref&gt;{{Cite news|url=https://www.wsj.com/articles/scientists-harness-quantum-physics-to-build-a-programmable-computer-1470243605|title=Scientists Harness Quantum Physics to Build a Programmable Computer|last=Hernandez|first=Daniela|date=2016-08-03|work=Wall Street Journal|access-date=2017-10-04|language=en-US|issn=0099-9660}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://www.washingtonpost.com/business/capitalbusiness/as-quantum-physicists-work-to-re-make-the-world-of-computing-investors-see-an-opportunity/2017/01/01/04b6776e-cdef-11e6-a87f-b917067331bb_story.html|title=Start-up IonQ sees opportunity in still-developing area of quantum computers|last=Gregg|first=Aaron|date=2017-01-01|work=Washington Post|access-date=2017-11-01|language=en-US|issn=0190-8286}}&lt;/ref&gt; || || Computing 
|[[Trapped ion quantum computer|ions]]||[[University of Maryland]], [[Duke University]] || [[College Park, Maryland|College Park]], MD, USA
|-
|[http://infiniquant.com/ InfiniQuant]&lt;ref&gt;{{Cite web|url=https://www.osa-opn.org/opn/media/Images/PDF/2018/0218/26-33_OPN_02_18.pdf?ext=.pdf|title=Satellite-Based QKD|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;
|
|Communication
|
|[[Max Planck Institute for the Science of Light]], [[University of Erlangen-Nuremberg]]
|[[Erlangen]], Germany
|-
| [[Intel]]&lt;ref&gt;{{Cite news|url=https://newsroom.intel.com/news-releases/intel-invests-us50-million-to-advance-quantum-computing/|title=(Press Release) Intel Invests US$50 Million to Advance Quantum Computing {{!}} Intel Newsroom|last=|first=|date=|work=Intel Newsroom|access-date=2017-10-04|archive-url=|archive-date=|dead-url=|language=en-US}}&lt;/ref&gt; || {{dts|2015|9|3}} || Computing 
| ||[[TU Delft]] || [[Santa Clara, California|Santa Clara]], CA, USA
|-
| [[KPN]]&lt;ref&gt;{{Cite web|url=http://corporate.kpn.com/pers/persberichten/kpn-implementeert-quantum-versleutelde-verbinding-qkd.htm|title=(Press Release) Pers|last=|first=|date=|website=KPN Corporate|language=nl-nl|archive-url=|archive-date=|dead-url=|access-date=2017-10-04}}&lt;/ref&gt; || || Communication 
| ||  || [[The Hague]], Netherlands
|-
| [[Lockheed Martin]] || || Computing 
| || University of Southern California, University College London || [[Bethesda, Maryland|Bethesda]], MD, USA
|-
| [[MagiQ Technologies, Inc.|MagiQ]] || || Communication 
| ||  || [[Somerville, Massachusetts|Somerville]], MA, USA
|-
| [[Microsoft Research]] QuArC || {{dts|2011|12|19}} || Computing 
|algorithms|| TU Delft, [[Niels Bohr Institute]], [[University of Sydney]], [[Purdue University]], University of Maryland, ETH Zurich, UCSB || [[Redmond, Washington|Redmond]], WA, USA
|-
| [[Microsoft Research]] Station Q || {{dts|2005|4|22}} || Computing 
|superconducting|| UCSB || [[Santa Barbara, California|Santa Barbara]], CA, USA
|-
| [[Mitsubishi]]&lt;ref&gt;{{Cite web|url=http://www.mitsubishielectric.com/company/rd/research/highlights/communications/quantum.html|title=Press Release|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; || || Communication 
| ||  || Tokyo, Japan
|-
| [[NEC|NEC Corporation]]&lt;ref&gt;{{Cite news|url=http://www.nec.com/en/press/201509/global_20150928_02.html|title=(Press Release) University of Tokyo, Fujitsu, and NEC Succeed in Quantum Key Distribution from Single-Photon Emitter at World-Record Distance of 120 km|last=|first=|date=|work=NEC|access-date=2017-10-04|archive-url=|archive-date=|dead-url=|language=en-US}}&lt;/ref&gt; || {{dts|1999|4|29}}&lt;ref&gt;Y. Nakamura, Yu. A. Pashkin, &amp; J. S. Tsai, Nature 398, 786 (1999) doi:10.1038/19718&lt;/ref&gt; || Communication 
|quantum dots|| University of Tokyo || Tokyo, Japan
|-
| [[Nokia Bell Labs]]&lt;ref&gt;{{Cite web|url=https://www.bell-labs.com/our-research/disciplines/quantum-computingcommunications/|title=Quantum Computing &amp; Communications - Bell Labs|website=www.bell-labs.com|language=en|access-date=2017-10-04}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://www.wired.com/2014/05/quantum-computing-topological-qubit/|title=The Future of Quantum Computing Could Depend on This Tricky Qubit|work=WIRED|access-date=2017-11-04|language=en-US}}&lt;/ref&gt; || || Computing 
| || University of Oxford || [[Murray Hill, New Jersey|Murray Hill]], NJ, USA
|-
| [[Northrop Grumman]]  || || Computing 
| ||  || [[West Falls Church]], VA, USA
|-
| [[Nippon Telegraph and Telephone|NTT Laboratories]]&lt;ref&gt;{{Cite journal|last=Carolan|first=Jacques|last2=Harrold|first2=Christopher|last3=Sparrow|first3=Chris|last4=Martín-López|first4=Enrique|last5=Russell|first5=Nicholas J.|last6=Silverstone|first6=Joshua W.|last7=Shadbolt|first7=Peter J.|last8=Matsuda|first8=Nobuyuki|last9=Oguma|first9=Manabu|date=2015-07-09|title=Universal linear optics|url=http://science.sciencemag.org/content/early/2015/07/08/science.aab3642|journal=Science|language=en|pages=aab3642|doi=10.1126/science.aab3642|issn=0036-8075|pmid=26160375|arxiv=1505.01182}}&lt;/ref&gt; || || Computing 
|[[Linear optical quantum computing|linear optics]]||[[Bristol University]] || Tokyo, Japan
|-
|Q-Ctrl&lt;ref&gt;{{Cite news|url=https://www.computerworld.com.au/article/629526/quantum-start-up-q-ctrl-unmixing-soup-qubit-decoherence/|title=Quantum start-up Q-Ctrl “unmixing the soup” of qubit decoherence|work=Computerworld|access-date=2017-11-27}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=http://www.afr.com/leadership/entrepreneur/csiros-main-sequence-ventures-backs-qctrl-a-quantum-computing-firmware-startup-20171031-gzc0to|title=CSIRO bid to keep 'spooky action' going|date=2017-11-02|work=Financial Review|access-date=2017-11-27|language=en-US}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://q-ctrl.tech/|title=Q-Ctrl homepage|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;
|{{dts|2017}} || Computing/Metrology 
|superconducting||  ||Sydney, Australia
|-
|Qbitlogic International&lt;ref&gt;{{Cite news|url=http://www.maltatoday.com.mt/business/business_comment/81411/innovation_hub__not_another_alice_in_wonderland|title=Innovation hub – not another Alice in Wonderland|work=MaltaToday.com.mt|access-date=2017-11-04|language=en}}&lt;/ref&gt;
|{{dts|2014}}&lt;ref name=":9"&gt;{{Cite web|url=https://www.crunchbase.com/organization/qbitlogic|title=QbitLogic {{!}} Crunchbase|website=Crunchbase|language=en|access-date=2017-11-04}}&lt;/ref&gt;
|Computing
|
|
|[[Atlanta]], GA, USA&lt;ref name=":9" /&gt;
|-
|QC Ware&lt;ref&gt;{{Cite web|url=https://www.ft.com/content/60fded2a-be5a-11e7-b8a3-38a6e068f464|title=Renaissance, DE Shaw look to quantum computing for edge|last=Wigglesworth|first=Robin|date=November 1, 2017|website=Financial Times|archive-url=|archive-date=|dead-url=|access-date=2017-11-04}}&lt;/ref&gt;
|{{dts|2014}}&lt;ref name=":10"&gt;{{Cite web|url=https://www.crunchbase.com/organization/qc-ware|title=QC Ware {{!}} Crunchbase|website=Crunchbase|language=en|access-date=2017-11-04}}&lt;/ref&gt;
|
|
|
|[[Palo Alto, California]], USA&lt;ref name=":10" /&gt;
|-
|Qilimanjaro&lt;ref&gt;{{Cite web|url=https://qilimanjaro.io/#about/|title=Qilimanjaro|access-date=2018-04-26}}&lt;/ref&gt; || {{dts|2018}} || |Computing 
| ||  || Barcelona, Spain
|-
|Qnami&lt;ref&gt;{{Cite web|url=https://qnami.ch/|title=Qnami - The quantum wave|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=2018-05-25}}&lt;/ref&gt;
|{{dts|2017}} || Metrology 
|[[Nitrogen-vacancy center|NV-centers]]||[[University of Basel]] || [[Basel]], [[Switzerland]]
|-
| Qrithm || {{dts|2016}} || Computing 
| ||  || Pasadena, California, USA
|-
|Quantum Circuits, Inc.&lt;ref&gt;{{cite news |title=Yale Professors Race Google and IBM to the First Quantum Computer |url=https://www.nytimes.com/2017/11/13/technology/quantum-computing-research.html |accessdate=1 October 2018 |publisher=New York Times}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=Quantum Circuits, Inc. |url=https://quantumcircuits.com |website=www.quantumcircuits.com |accessdate=1 October 2018}}&lt;/ref&gt;|| {{dts|2015}} || Computing 
|superconducting||[[Yale University]] || [[New Haven]], Connecticut, USA
|-
| [[Quantum-Factory]]&lt;ref&gt;{{Cite web|url=https://www.quantum-factory.de&lt;/ref&gt; || {{dts|2018}} || Computing 
| ||  ||Munich,Germany
|-
|Quantum Numbers Corp || {{dts|2016}} || Communication 
| || Université de Sherbrooke || Brossard, Quebec, Canada
|-
| [[QuintessenceLabs]] || || Communication 
| ||  || [[Deakin, Australian Capital Territory|Deakin]], ACT, Australia
|-
| [[QxBranch]] || {{dts|2014}} || Computing 
| ||  || [[Washington, D.C.]], USA
|-
| [[BBN Technologies|Raytheon/BBN]]&lt;ref&gt;{{Cite web|url=http://www.raytheon.com/capabilities/products/quantum/index.html|title=Raytheon: Quantum information|last=Communications|first=Raytheon Corporate|website=www.raytheon.com|access-date=2017-10-04}}&lt;/ref&gt; ||  || Computing/Communication 
|superconducting|| MIT || [[Cambridge, Massachusetts|Cambridge]], MA, USA
|-
| [[Rigetti Computing]] || || Computing 
|superconducting|| Berkeley || California, USA
|-
|River Lane Research || {{dts|2016}} || Computing 
| ||  || Cambridge, UK
|-
|Siemens Healthineers || || Computing 
| || University College London || [[Erlangen]], [[Germany]].
|-
| [[Delft Circuits]] || || Computing 
| || QuTech || Delft, The Netherlands
|-
| [[RIKEN]]&lt;ref&gt;{{Cite web|url=http://www.riken.jp/en/research/labs/cems/qtm_inf_electron/superconduct_qtm_sim/|title=Superconducting Quantum Simulation Research Team {{!}} RIKEN|website=www.riken.jp|language=en|access-date=2017-10-04}}&lt;/ref&gt; || || Computing 
|superconducting||[[Tokyo University of Science]] || [[Wako, Saitama|Wako]], Japan
|-
| [[Strangeworks]] || || Computing 
| || Austin || Texas, USA
|-
| [[Toshiba]]&lt;ref&gt;{{Cite web|url=http://www.toshiba.eu/eu/Cambridge-Research-Laboratory/Quantum-Information-Group/|title=Toshiba: CRL - Quantum Information|last=Limited|first=Toshiba Research Europe|website=www.toshiba.eu|language=en|access-date=2017-10-04}}&lt;/ref&gt; || || Communication 
|quantum dots|| University of Cambridge || Tokyo, Japan
|-
| Xanadu&lt;ref&gt;{{Cite web|url=https://www.xanadu.ai/|title=Xanadu Quantum Computing Inc|website=www.xanadu.ai|language=en|access-date=2018-03-25}}&lt;/ref&gt; || {{dts|2017}} || Computing 
|[[Linear optical quantum computing|linear optics]]||  || [[Toronto]], Canada
|-
| Zapata Computing&lt;ref&gt;{{Cite web|url=http://www.zapatacomputing.com/|title=Zapata Computing Inc.|website=www.zapatacomputing.com|language=en|access-date=2018-05-24}}&lt;/ref&gt; || {{dts|2018}} || Computing 
|algorithms||  || [[Cambridge,_Massachusetts|Cambridge]], Massachusetts, USA
|-
|}

==Notes==
{{Reflist|group=note|30em}}

==References==
{{Reflist|30em}}

[[Category:Quantum computing]]
[[Category:Lists of technology companies|Quantum computing]]</text>
      <sha1>sjgsd4d9tlxt8wrdvqgkpyfyx6me1d0</sha1>
    </revision>
  </page>
  <page>
    <title>List of mathematical logic topics</title>
    <ns>0</ns>
    <id>346167</id>
    <revision>
      <id>867469279</id>
      <parentid>861632043</parentid>
      <timestamp>2018-11-05T22:30:16Z</timestamp>
      <contributor>
        <username>The Man in Question</username>
        <id>835170</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13862">{{Selfref|Clicking on '''''related changes''''' shows a list of most-recent edits of articles to which this page links.  This page links to itself in order that recent changes to this page will also be included in ''related changes''.}}

This is a '''list of mathematical logic topics''', by Wikipedia page.

For traditional syllogistic logic, see the [[list of topics in logic]]. See also the [[list of computability and complexity topics]] for more theory of [[algorithm]]s.

==Working foundations==

*[[Peano axioms]]
**[[Giuseppe Peano]]
*[[Mathematical induction]]
**[[Structural induction]]
**[[Recursive definition]]
*[[Naive set theory]]
**[[Element (mathematics)]]
***[[Ur-element]]
**[[Singleton (mathematics)]]
**[[Simple theorems in the algebra of sets]]
**[[Algebra of sets]]
**[[Power set]]
**[[Empty set]]
**[[Non-empty set]]
**[[Empty function]]
*[[Universe (mathematics)]]
*[[Axiomatization]]
*[[Axiomatic system]]
**[[Axiom schema]]
*[[Axiomatic method]]
*[[Formal system]]
*[[Mathematical proof]]
**[[Direct proof]]
**[[Reductio ad absurdum]]
**[[Proof by exhaustion]]
**[[Constructive proof]]
**[[Nonconstructive proof]]
*[[Tautology (logic)|Tautology]]
*[[Consistency proof]]
*[[Arithmetization of analysis]]
*[[Foundations of mathematics]]
*[[Formal language]]
*''[[Principia Mathematica]]''
*[[Hilbert's program]]
*[[Impredicative]]
*[[Definable real number]]
*[[Algebraic logic]]
**[[Boolean algebra (logic)]]
*[[Dialectica space]]
*[[categorical logic]]

==Model theory==

*[[Finite model theory]]
**[[Descriptive complexity theory]]
**[[Model checking]]
**[[Trakhtenbrot's theorem]]
*[[Computable model theory]]
**[[Tarski's exponential function problem]]
**[[Undecidable problem]]
*[[Institutional model theory]]
**[[Institution (computer science)]]
*[[Non-standard analysis]]
**[[Non-standard calculus]]
**[[Hyperinteger]]
**[[Hyperreal number]]
**[[Transfer principle]]
**[[Overspill]]
**[[Elementary Calculus: An Infinitesimal Approach]]
**[[Criticism of non-standard analysis]]
**[[Standard part function]]
*[[Set theory]]
**[[Forcing (mathematics)]]
***[[Boolean-valued model]]
*[[Kripke semantics]]
**[[General frame]]
*[[Predicate logic]]
**[[First-order logic]]
***[[Infinitary logic]]
***[[Many-sorted logic]]
**[[Higher-order logic]]
***[[Lindström quantifier]]
***[[Second-order logic]]
*[[Soundness theorem]]
*[[Gödel's completeness theorem]]
**[[Original proof of Gödel's completeness theorem]]
*[[Compactness theorem]]
*[[Löwenheim–Skolem theorem]]
**[[Skolem's paradox]]
*[[Gödel's incompleteness theorems]]
*[[Structure (mathematical logic)]]
*[[Interpretation (logic)]]
*[[Substructure (mathematics)]]
*[[Elementary substructure]]
**[[Skolem hull]]
*[[Non-standard model]]
*[[Atomic model (mathematical logic)]]
*[[Prime model]]
*[[Saturated model]]
*[[Existentially closed model]]
*[[Ultraproduct]]
*[[Age (model theory)]]
**[[Amalgamation property]]
**[[Hrushovski construction]]
*[[Potential isomorphism]]
*[[Theory (mathematical logic)]]
**[[Complete theory]]
***[[Vaught's test]]
**[[Morley's categoricity theorem]]
***[[Stability spectrum]]
****[[Morley rank]]
****[[Stable theory]]
*****[[Forking extension]]
*****[[Strongly minimal theory]]
*****[[Stable group]]
******[[Tame group]]
***[[o-minimal theory]]
***[[Weakly o-minimal structure]]
***[[C-minimal theory]]
***[[Spectrum of a theory]]
****[[Vaught conjecture]]
**[[Model complete theory]]
**[[List of first-order theories]]
**[[Conservative extension]]
**[[Elementary class]]
***[[Pseudoelementary class]]
***[[Strength (mathematical logic)]]
*[[Differentially closed field]]
*[[Exponential field]]
*[[Ax–Grothendieck theorem]]
*[[Ax–Kochen theorem]]
*[[Peano axioms]]
*[[Non-standard model of arithmetic]]
*[[First-order arithmetic]]
*[[Second-order arithmetic]]
*[[Presburger arithmetic]]
*[[Wilkie's theorem]]
*[[Functional predicate]]
*[[T-schema]]
*[[Back-and-forth method]]
*[[Barwise compactness theorem]]
*[[Skolem normal form|Skolemization]]
*[[Lindenbaum–Tarski algebra]]
*[[Löb's theorem]]
*[[Arithmetical set]]
*[[Definable set]]
*[[Ehrenfeucht–Fraïssé game]]
*[[Herbrand interpretation]] / [[Herbrand structure]]
*[[Imaginary element]]
*[[Indiscernibles]]
*[[Interpretation (model theory)]] / [[Interpretable structure]]
*[[Pregeometry (model theory)]]
*[[Quantifier elimination]]
*[[Reduct]]
*[[Signature (logic)]]
*[[Skolem normal form]]
*[[Type (model theory)]]
*[[Zariski geometry]]

==Set theory==
* [[Algebra of sets]] [[Talk:Algebra of sets| ]]
* [[Axiom of choice]] [[Talk:Axiom of choice| ]]
** [[Axiom of countable choice]] [[Talk:Axiom of countable choice| ]]
** [[Axiom of dependent choice]] [[Talk:Axiom of dependent choice| ]]
** [[Zorn's lemma]] [[Talk:Zorn's lemma| ]]
* [[Boolean algebra (structure)]]
* [[Boolean-valued model]] [[Talk:Boolean-valued model| ]]
* [[Burali-Forti paradox]] [[Talk:Burali-Forti paradox| ]]
* [[Cantor's back-and-forth method]] [[Talk:Cantor's back-and-forth method| ]]
* [[Cantor's diagonal argument]] [[Talk:Cantor's diagonal argument| ]]
* [[Cantor's first uncountability proof]] [[Talk:Cantor's first uncountability proof| ]]
* [[Cantor's theorem]] [[Talk:Cantor's theorem| ]]
* [[Cantor–Bernstein–Schroeder theorem]] [[Talk:Cantor–Bernstein–Schroeder theorem| ]]
* [[Cardinality]] [[Talk:Cardinality| ]]
** [[Aleph number]] [[Talk:Aleph number| ]]
*** [[Aleph-null]] [[Talk:Aleph-null| ]]
*** [[Aleph-one]] [[Talk:Aleph-one| ]]
** [[Beth number]] [[Talk:Beth number| ]]
** [[Cardinal number]] [[Talk:Cardinal number| ]]
** [[Hartogs number]] [[Talk:Hartogs number| ]]
* [[Cartesian product]] [[Talk:Cartesian product| ]]
* [[Class (set theory)]] [[Talk:Class (set theory)| ]]
* [[Complement (set theory)]] [[Talk:Complement (set theory)| ]]
* [[Complete Boolean algebra]] [[Talk:Complete Boolean algebra| ]]
* [[Continuum (set theory)]] [[Talk:Continuum (set theory)| ]]
** [[Suslin's problem]] [[Talk:Suslin's problem| ]]
* [[Continuum hypothesis]] [[Talk:Continuum hypothesis| ]]
* [[Countable set]] [[Talk:Countable set| ]]
* [[Descriptive set theory]] [[Talk:Descriptive set theory| ]]
** [[Analytic set]] [[Talk:Analytic set| ]]
** [[Analytical hierarchy]] [[Talk:Analytical hierarchy| ]]
** [[Borel equivalence relation]] [[Talk:Borel equivalence relation| ]]
** [[Infinity-Borel set]] [[Talk:Infinity-Borel set| ]]
** [[Lightface analytic game]] [[Talk:Lightface analytic game| ]]
** [[Perfect set property]] [[Talk:Perfect set property| ]]
** [[Polish space]] [[Talk:Polish space| ]]
** [[Prewellordering]] [[Talk:Prewellordering| ]]
** [[Projective set]] [[Talk:Projective set| ]]
** [[Property of Baire]] [[Talk:Property of Baire| ]]
** [[Uniformization (set theory)]] [[Talk:Uniformization (set theory)| ]]
** [[Universally measurable set]] [[Talk:Universally measurable set| ]]
* [[Determinacy]] [[Talk:Determinacy| ]]
** [[AD+]] [[Talk:AD plus| ]]
** [[Axiom of determinacy]] [[Talk:Axiom of determinacy| ]]
** [[Axiom of projective determinacy]] [[Talk:Axiom of projective determinacy| ]]
** [[Axiom of real determinacy]] [[Talk:Axiom of real determinacy| ]]
* [[Empty set]] [[Talk:Empty set| ]]
* [[Forcing (mathematics)]] [[Talk:Forcing (mathematics)| ]]
* [[Fuzzy set]] [[Talk:Fuzzy set| ]]
* [[Internal set theory]] [[Talk:Internal set theory| ]]
* [[Intersection (set theory)]] [[Talk:Intersection (set theory)| ]]
* [[Constructible universe|L]] [[Talk:Constructible universe| ]]
* [[L(R)]] [[Talk:L(R)| ]]
* [[Large cardinal property]] [[Talk:Large cardinal property| ]]
* [[Set theory (music)|Musical set theory]] [[Talk:Set theory (music)| ]]
* [[Ordinal number]] [[Talk:Ordinal number| ]]
** [[Infinite descending chain]] [[Talk:Infinite descending chain| ]]
** [[Limit ordinal]] [[Talk:Limit ordinal| ]]
** [[Successor ordinal]] [[Talk:Successor ordinal| ]]
** [[Transfinite induction]] [[Talk:Transfinite induction| ]]
***[[∈-induction]] [[Talk:∈-induction| ]]
** [[Well-founded set]] [[Talk:Well-founded set| ]]
** [[Well-order]] [[Talk:Well-order| ]]
* [[Power set]] [[Talk:Power set| ]]
* [[Russell's paradox]] [[Talk:Russell's paradox| ]]
* [[Set theory]] [[Talk:Set theory| ]]
** [[Alternative set theory]] [[Talk:Alternative set theory| ]]
** [[Axiomatic set theory]] [[Talk:Axiomatic set theory| ]]
** [[Kripke–Platek set theory with urelements]] [[Talk:Kripke–Platek set theory with urelements| ]]
** [[Morse–Kelley set theory]] [[Talk:Morse–Kelley set theory| ]]
** [[Naive set theory]] [[Talk:Naive set theory| ]]
** [[New Foundations]] [[Talk:New Foundations| ]]
** [[Positive set theory]] [[Talk:Positive set theory| ]]
** [[Zermelo–Fraenkel set theory]] [[Talk:Zermelo–Fraenkel set theory| ]]
** [[Zermelo set theory]] [[Talk:Zermelo set theory| ]]
* [[Set (mathematics)]] [[Talk:Set (mathematics)| ]]
* [[Simple theorems in the algebra of sets]] [[Talk:Simple theorems in the algebra of sets| ]]
* [[Subset]] [[Talk:Subset| ]]
* [[Θ (set theory)]] [[Talk:Θ (set theory)| ]]
* [[Tree (descriptive set theory)]] [[Talk:Tree (descriptive set theory)| ]]
* [[Tree (set theory)]] [[Talk:Tree (set theory)| ]]
* [[Union (set theory)]] [[Talk:Union (set theory)| ]]
* [[Von Neumann universe]] [[Talk:Von Neumann universe| ]]
* [[Zero sharp]] [[Talk:Zero sharp| ]]

==Descriptive set theory==

*[[Analytical hierarchy]]

==Large cardinals==

*[[Almost Ramsey cardinal]]
*[[Erdős cardinal]]
*[[Extendible cardinal]]
*[[Huge cardinal]]
*[[Hyper-Woodin cardinal]]
*[[Inaccessible cardinal]]
*[[Ineffable cardinal]]
*[[Mahlo cardinal]]
*[[Measurable cardinal]]
*[[N-huge cardinal]]
*[[Ramsey cardinal]]
*[[Rank-into-rank]]
*[[Remarkable cardinal]]
*[[Shelah cardinal]]
*[[Strong cardinal]]
*[[Strongly inaccessible cardinal]]
*[[Subtle cardinal]]
*[[Supercompact cardinal]]
*[[Superstrong cardinal]]
*[[Totally indescribable cardinal]]
*[[Weakly compact cardinal]]
*[[Weakly hyper-Woodin cardinal]]
*[[Weakly inaccessible cardinal]]
*[[Woodin cardinal]]
*[[Unfoldable cardinal]]

==Recursion theory==

*[[Entscheidungsproblem]]
*[[Decision problem]]
*[[Decidability (logic)]]
*[[Church-Turing thesis]]
*[[Computable function]]
**[[Algorithm]]
**[[Recursion]]
**[[Primitive recursive function]]
**[[Mu operator]]
**[[Ackermann function]]
**[[Turing machine]]
**[[Halting problem]]
**[[Computability theory]], [[computation]]
**[[Herbrand Universe]]
**[[Markov algorithm]]
**[[Lambda calculus]]
***[[Church-Rosser theorem]]
***[[Calculus of constructions]]
**[[Combinatory logic]]
**[[Post correspondence problem]]
*[[Kleene's recursion theorem]]
*[[Recursively enumerable set]]
**[[Recursively enumerable language]]
*[[Decidable language]]
*[[Undecidable language]]
*[[Rice's theorem]]
*[[Post's theorem]]
*[[Turing degree]]
*[[Effective results in number theory]]
*[[Diophantine set]]
*[[Matiyasevich's theorem]]
*[[Word problem for groups]]
*[[Arithmetical hierarchy]]
*[[Subrecursion theory]]
**[[Presburger arithmetic]]
**[[Computational complexity theory]]
**[[Polynomial time]]
**[[Exponential time]]
**[[Complexity class]]
***[[P = NP problem|Complexity classes P and NP]]
***[[Cook's theorem]]
***[[List of complexity classes]]
***[[Polynomial hierarchy]]
***[[Exponential hierarchy]]
**[[NP-complete]]
**[[Time hierarchy theorem]]
**[[Space hierarchy theorem]]
*[[Natural proof]]
*[[Hypercomputation]]
**[[Oracle machine]]
*[[Rózsa Péter]]
*[[Alonzo Church]]
*[[Emil Post]]
*[[Alan Turing]]
*[[Jacques Herbrand]]
*[[Haskell Curry]]
*[[Stephen Cole Kleene]]
*[[Definable real number]]

==Proof theory==

*[[Metamathematics]]
*[[Cut-elimination]]
*[[Tarski's undefinability theorem]]
*[[Diagonal lemma]]
*[[Provability logic]]
*[[Interpretability logic]]
*[[Sequent]]
*[[Sequent calculus]]
*[[Analytic proof]]
*[[Structural proof theory]]
*[[Self-verifying theories]]
*[[Substructural logic]]s
**[[Structural rule]]
***[[Weakening (logic)|Weakening]]
***[[Contraction (logic)|Contraction]]
**[[Linear logic]]
***[[Intuitionistic linear logic]]
***[[Proof net]]
**[[Affine logic]]
**[[Strict logic]]
**[[Relevant logic]]
*[[Proof-theoretic semantics]]
*[[Ludics]]
*[[System F]]
*[[Gerhard Gentzen]]
*[[Gentzen's consistency proof]]
*[[Reverse mathematics]]
*[[Nonfirstorderizability]]
*[[Interpretability]]
*[[Weak interpretability]]
*[[Cointerpretability]]
*[[Tolerant sequence]]
*[[Cotolerant sequence]]
*[[Deduction theorem]]
*[[Cirquent calculus]]

==Mathematical constructivism==

*[[Nonconstructive proof]]
*[[Existence theorem]]
* [[Intuitionistic logic]]
* [[Intuitionistic type theory]]
* [[Type theory]]
* [[Lambda calculus]]
** [[Church–Rosser theorem]]
* [[Simply typed lambda calculus]]
* [[Typed lambda calculus]]
* [[Curry–Howard isomorphism]]
* [[Calculus of constructions]]
* [[Constructivist analysis]]
* [[Lambda cube]]
* [[System F]]
*[[Introduction to topos theory]]
*[[LF (logical framework)]]
*[[Computability logic]]
*[[Computable measure theory]]
*[[Finitism]]
*[[Ultraintuitionism]]
*[[Luitzen Egbertus Jan Brouwer]]

==Modal logic==

*[[Kripke semantics]]
*[[Sahlqvist formula]]
*[[Interior algebra]]

==Theorem provers==

*[[First-order resolution]]
*[[Automated theorem proving]]
*[[ACL2 theorem prover]]
*[[E equational theorem prover]]
*[[Gandalf theorem prover]]
*[[HOL theorem prover]]
*[[Isabelle theorem prover]]
*[[LCF theorem prover]]
*[[Otter theorem prover]]
*[[Paradox theorem prover]]
*[[Vampire theorem prover]]
*[[Interactive proof system]]
*[[Mizar system]]
*[[QED project]]
*[[Coq]]

==Discovery systems==

*[[Automated Mathematician]]
*[[Eurisko]]

==Historical==

*''[[Begriffsschrift]]''
*''[[Systems of Logic Based on Ordinals]]'' – [[Alan Turing|Alan Turing's]] Ph.D. thesis

==See also==
{{Portal|Logic}}
*[[Kurt Gödel]]
*[[Alfred Tarski]]
*[[Saharon Shelah]]

{{Logic}}

[[Category:Mathematics-related lists|Logic]]
[[Category:Mathematical logic| L]]
[[Category:Wikipedia outlines|Mathematical logic]]
[[Category:Lists of topics|Mathematical logic]]</text>
      <sha1>4fzt0j2fzpitltnw5px7jml25axr44v</sha1>
    </revision>
  </page>
  <page>
    <title>List of partial differential equation topics</title>
    <ns>0</ns>
    <id>634754</id>
    <revision>
      <id>792370866</id>
      <parentid>757457452</parentid>
      <timestamp>2017-07-26T03:34:15Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>/* Specific partial differential equations */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1836">This is a '''list of partial differential equation topics'''.

==General topics==

*[[Partial differential equation]]
** [[Nonlinear partial differential equation]]
***[[list of nonlinear partial differential equations]]
*[[Boundary condition]]
*[[Boundary value problem]]
**[[Dirichlet problem]], [[Dirichlet boundary condition]]
**[[Neumann boundary condition]]
**[[Stefan problem]]
**[[Wiener–Hopf problem]]
*[[Separation of variables]]
*[[Green's function]]
*[[Elliptic partial differential equation]]
*[[Singular perturbation]]
*[[Cauchy–Kovalevskaya theorem]]
*[[H-principle]]
*[[Atiyah–Singer index theorem]]
*[[Bäcklund transform]]
*[[Viscosity solution]]
*[[Weak solution]]
*[[Loewy decomposition of linear differential equations]]

==Specific partial differential equations==

*[[Broer–Kaup equations]]
*[[Euler equations]]
*[[Hamilton–Jacobi equation]], [[Hamilton–Jacobi–Bellman equation]]
*[[Heat equation]]
*[[Laplace's equation]]
**[[Laplace operator]]
**[[Harmonic function]]
**[[Spherical harmonic]]
**[[Poisson integral formula]]
*[[Klein–Gordon equation]]
*[[Korteweg–de Vries equation]]
**[[Modified KdV–Burgers equation]]
*[[Maxwell's equations]]
*[[Navier–Stokes equations]]
*[[Poisson's equation]]
*[[Primitive equations]] (hydrodynamics)
*[[Schrödinger equation]]
*[[Wave equation]]

==Numerical methods for PDEs==

*[[Finite difference]]
*[[Finite element method]]
*[[Finite volume method]]
*[[Boundary element method]]
*[[Multigrid]]
*[[Spectral method]]
*[[Computational fluid dynamics]]
*[[Alternating direction implicit]]

==Related areas of mathematics==

* [[Calculus of variations]]
* [[Harmonic analysis]]
* [[Ordinary differential equation]]
* [[Sobolev space]]

[[Category:Partial differential equations| ]]
[[Category:Mathematics-related lists|Partial differential equations]]</text>
      <sha1>34odej5ns77mbu43qxtp6zjgn0k1abo</sha1>
    </revision>
  </page>
  <page>
    <title>Napier's bones</title>
    <ns>0</ns>
    <id>252176</id>
    <revision>
      <id>869307835</id>
      <parentid>869307765</parentid>
      <timestamp>2018-11-17T19:51:53Z</timestamp>
      <contributor>
        <ip>108.211.72.195</ip>
      </contributor>
      <comment>/* Example 1 */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="36320">{{More footnotes|date=October 2007}}
{{Howto|date=April 2010}}
[[File:An 18th century set of Napier's Bones.JPG|thumb|An 18th century set of Napier's Bones]]

'''Napier's bones''' is a manually-operated calculating device created by [[John Napier]] of [[Merchiston Castle|Merchiston]] for [[calculation]] of products and [[quotient]]s of numbers. The method was based on [[Arab mathematics]] and the [[lattice multiplication]] used by [[Matrakci Nasuh]] in the [[Umdet-ul Hisab]] and [[Fibonacci]]'s work in his [[Liber Abaci]].  The technique was also called Rabdology. Napier published his version in 1617 in ''Rabdology.,'' printed in [[Edinburgh]], [[Scotland]], dedicated to his patron [[Alexander Seton, 1st Earl of Dunfermline|Alexander Seton]].

Using the multiplication tables embedded in the rods, multiplication can be reduced to addition operations and division to subtractions. More advanced use of the rods can even extract [[square root]]s.  Note that Napier's bones are not the same as [[logarithm]]s, with which Napier's name is also associated.

The complete device usually includes a base board with a rim; the user places Napier's rods inside the rim to conduct multiplication or division.  The board's left edge is divided into 9 squares, holding the numbers 1 to 9. The Napier's rods consist of strips of wood, metal or heavy cardboard.  Napier's bones are three-dimensional, square in cross section, with four different rods engraved on each one. A set of such bones might be enclosed in a convenient carrying case.

A rod's surface comprises 9 squares, and each square, except for the top one, comprises two halves divided by a diagonal line.  The first square of each rod holds a single digit, and the other squares hold this number's double, triple, quadruple, quintuple, and so on until the last square contains nine times the number in the top square. The digits of each product are written one to each side of the diagonal; numbers less than 10 occupy the lower triangle.

== Multiplication ==
To demonstrate how to use Napier's Bones for multiplication, three examples of increasing difficulty are explained below.

===Example 1===

The first example computes 425 x 6.

Start by placing the bones corresponding to the leading number of the problem into the boards.  If a 0 is used in this number, a space is left between the bones corresponding to where the 0 digit would be.  In this example, the bones 4, 2, and 5 are placed in the correct order as shown below.
[[File:Napier's Bones ex 1 pic 1.png|center|125px|First step of solving 425 x 6]]
Looking at the first column, choose the number wishing to multiply by.  In this example, that number is 6.  The row this number is located in is the only row needed to perform the remaining calculations and thus the rest of the board is cleared below to allow more clarity in the remaining steps.
[[File:Napier's Bones ex 1 pic 2.png|center|300px|Second step of solving 425 x 6]]
Starting at the right side of the row, evaluate the diagonal columns by adding the numbers that share the same diagonal column.  Single numbers simply remain that number.
[[File:Napier's Bones ex 1 pic 3.png|center|175px|Third step of solving 425 x 6]]
Once the diagonal columns have been evaluated, one must simply read from left to right the numbers calculated for each diagonal column.  For this example, reading the results of the summations from left to right produces the final answer of 2550.
 Therefore: The solution to multiplying 425 by 6 is 2550.  (425 x 6 = 2550)

===Example 2===
When multiplying by larger single digits, it is common that upon adding a diagonal column, the sum of the numbers result in a number that is 10 or greater.  The following example demonstrates how to properly carry over the tens place when this occurs.

The second example computes 6785 x 8. 

Begin just as in Example 1 above and place in the board the corresponding bones to the leading number of the problem.  For this example, the bones 6, 7, 8, and 5 are placed in the proper order as shown below. (Note that row 7 in bone 8 should read 5/6, not 5/4)
[[File:Napier's Bones ex 2 pic 1.png|center|175px|First step of solving 6785 x 8]]
In the first column, find the number wishing to multiply by.  In this example, that number is 8.  With only needing to use the row 8 is located in for the remaining calculations, the rest of the board below has been cleared for clarity in explaining the remaining steps.
[[File:Napier's Bones ex 2 pic 2.png|center|375px|Second step of solving 6785 x 8]]
Just as before, start at the right side of the row and evaluate each diagonal column.  If the sum of a diagonal column equals 10 or greater, the tens place of this sum must be carried over and added along with the numbers in the diagonal column to the immediate left as demonstrated below.
[[File:Napier's Bones ex 2 pic 3.png|center|250px|Third step of solving 6785 x 8]]
After each diagonal column has been evaluated, the calculated numbers can be read from left to right to produce a final answer.  Reading the results of the summations from left to right, in this example, produces a final answer of 54280.
 Therefore: The solution to multiplying 6785 by 8 is 54280.  (6785 x 8 = 54280)

===Example 3===

The third example computes 825 x 913.

Begin once again by placing the corresponding bones to the leading number into the board.  For this example the bones 8, 2, and 5 are placed in the proper order as shown below.
[[File:Napier's Bones ex 3 pic 1.png|center|125px|First step of solving 825 x 913]]
When the number wishing to multiply by contains multiple digits, multiple rows must be reviewed.  For the sake of this example, the rows for 9, 1, and 3 have been removed from the board, as seen below, for easier evaluation.
[[File:Napier's Bones ex 3 pic 2.png|center|300px|Second step of solving 825 x 913]]
Evaluate each row individually, adding each diagonal column as explained in the previous examples.  Reading these sums from left to right will produce the numbers needed for the long hand addition calculations to follow.  For this example, Row 9, Row 1, and Row 3 were evaluated separately to produce the results shown below.
[[File:Napier's Bones ex 3 pic 3.png|center|600px|Third step of solving 825 x 913]]
For the final step of the solution, begin by writing the numbers being multiplied one over the other, drawing a line under the second number.  
    825
 &lt;u&gt; x 913&lt;/u&gt;
Starting with the right most digit of the second number, place the results from the rows in sequential order as seen from right to left under each other while utilizing a 0 for place holders.  
     825
 &lt;u&gt;x   913&lt;/u&gt;
    2475
    8250
  742500

The rows and place holders can then be summed to produce a final answer.
     825
 &lt;u&gt;x   913&lt;/u&gt;
    2475
    8250
 &lt;u&gt;+742500&lt;/u&gt;
  753225

In this example, the final answer produced is 753225.
 Therefore: The solution to multiplying 825 by 913 is 753225.  (825 x 913 = 753225)

== Division ==
&lt;!-- Note: This section and those below it are in dire need of revision. --&gt;

Division can be performed in a similar fashion.  Let's divide 46785399 by 96431, the two numbers we used in the earlier example.  Put the bars for the divisor (96431) on the board, as shown in the graphic below.  Using the abacus, find all the products of the divisor from 1 to 9 by reading the displayed numbers.  Note that the dividend has eight digits, whereas the partial products (save for the first one) all have six.  So you must temporarily ignore the final two digits of 46785399, namely the '99', leaving the number 467853.  Next, look for the greatest partial product that is less than the truncated dividend.  In this case, it's 385724.  You must mark down two things, as seen in the diagram:  since 385724 is in the '4' row of the abacus, mark down a '4' as the left-most digit of the quotient; also write the partial product, left-aligned, under the original dividend, and subtract the two terms.  You get the difference as 8212999.  Repeat the same steps as above: truncate the number to six digits, chose the partial product immediately less than the truncated number, write the row number as the next digit of the quotient, and subtract the partial product from the difference found in the first repetition.  Following the diagram should clarify this.  Repeat this cycle until the result of subtraction is less than the divisor. The number left is the remainder.

[[Image:Napier-example-3.png|center]]

So in this example, we get a quotient of 485 with a remainder of 16364. We can just stop here and
use the fractional form of the answer &lt;math&gt;485\frac{16364}{96431}&lt;/math&gt;.

If you prefer, we can also find as many decimal places as we need by continuing the cycle as in
standard [[long division]]. Mark a decimal point after the last digit of the quotient and append a zero
to the remainder so we now have 163640. Continue the cycle, but each time appending a zero to the
result after the subtraction.

Let's work through a couple of digits. The first digit after the decimal point is
1, because the biggest partial product less than 163640 is
96431, from row 1. Subtracting 96431 from 163640, we're left with 67209.
Appending a zero, we have 672090 to consider for the next cycle (with the partial result
485.1)
The second digit after the decimal point is 6, as the biggest partial product less
than 672090 is 578586 from row 6. The partial result is now 485.16, and so on.

==Extracting square roots==
Extracting the square root uses '''an additional bone''' which looks a bit
different from the others as it has three columns on it. The first
column has the first nine squares 1, 4, 9, ... 64, 81, the second
column has the even numbers 2 through 18, and the last column just has
the numbers 1 through 9.

{| border="1" cellpadding="2" cellspacing="0" style="background:#ffd78c;border:thick double #ffc731;"
|+ Napier's rods with the square root bone
! &amp;nbsp; || 1 || 2 || 3 || 4 || 5 || 6 || 7 || 8 || 9 || √
|- align=right
| '''1''' 
|| {{frac|0|1}} 
|| {{frac|0|2}} 
|| {{frac|0|3}} 
|| {{frac|0|4}} 
|| {{frac|0|5}} 
|| {{frac|0|6}} 
|| {{frac|0|7}} 
|| {{frac|0|8}} 
|| {{frac|0|9}} 
|| {{frac|0|1}} &amp;nbsp; &amp;nbsp;&amp;nbsp;2 &amp;nbsp; 1
|- align=right
| '''2''' 
|| {{frac|0|2}} 
|| {{frac|0|4}} 
|| {{frac|0|6}} 
|| {{frac|0|8}} 
|| {{frac|1|0}} 
|| {{frac|1|2}} 
|| {{frac|1|4}} 
|| {{frac|1|6}} 
|| {{frac|1|8}} 
|| {{frac|0|4}} &amp;nbsp; &amp;nbsp;&amp;nbsp;4 &amp;nbsp; 2
|- align=right
| '''3''' 
|| {{frac|0|3}} 
|| {{frac|0|6}} 
|| {{frac|0|9}} 
|| {{frac|1|2}} 
|| {{frac|1|5}} 
|| {{frac|1|8}} 
|| {{frac|2|1}} 
|| {{frac|2|4}} 
|| {{frac|2|7}} 
|| {{frac|0|9}} &amp;nbsp; &amp;nbsp;&amp;nbsp;6 &amp;nbsp; 3
|- align=right
| '''4''' 
|| {{frac|0|4}} 
|| {{frac|0|8}} 
|| {{frac|1|2}} 
|| {{frac|1|6}} 
|| {{frac|2|0}} 
|| {{frac|2|4}} 
|| {{frac|2|8}} 
|| {{frac|3|2}} 
|| {{frac|3|6}} 
|| {{frac|1|6}} &amp;nbsp; &amp;nbsp;&amp;nbsp;8 &amp;nbsp; 4
|- align=right
| '''5''' 
|| {{frac|0|5}} 
|| {{frac|1|0}} 
|| {{frac|1|5}} 
|| {{frac|2|0}} 
|| {{frac|2|5}} 
|| {{frac|3|0}} 
|| {{frac|3|5}} 
|| {{frac|4|0}} 
|| {{frac|4|5}} 
|| {{frac|2|5}} &amp;nbsp; 10 &amp;nbsp; 5
|- align=right
| '''6''' 
|| {{frac|0|6}} 
|| {{frac|1|2}} 
|| {{frac|1|8}} 
|| {{frac|2|4}} 
|| {{frac|3|0}} 
|| {{frac|3|6}} 
|| {{frac|4|2}} 
|| {{frac|4|8}} 
|| {{frac|5|4}} 
|| {{frac|3|6}} &amp;nbsp; 12 &amp;nbsp; 6
|- align=right
| '''7''' 
|| {{frac|0|7}} 
|| {{frac|1|4}} 
|| {{frac|2|1}} 
|| {{frac|2|8}} 
|| {{frac|3|5}} 
|| {{frac|4|2}} 
|| {{frac|4|9}} 
|| {{frac|5|6}} 
|| {{frac|6|3}} 
|| {{frac|4|9}} &amp;nbsp; 14 &amp;nbsp; 7
|- align=right
| '''8''' 
|| {{frac|0|8}} 
|| {{frac|1|6}} 
|| {{frac|2|4}} 
|| {{frac|3|2}} 
|| {{frac|4|0}} 
|| {{frac|4|8}} 
|| {{frac|5|6}} 
|| {{frac|6|4}} 
|| {{frac|7|2}} 
|| {{frac|6|4}} &amp;nbsp; 16 &amp;nbsp; 8
|- align=right
| '''9''' 
|| {{frac|0|9}} 
|| {{frac|1|8}} 
|| {{frac|2|7}} 
|| {{frac|3|6}} 
|| {{frac|4|5}} 
|| {{frac|5|4}} 
|| {{frac|6|3}} 
|| {{frac|7|2}} 
|| {{frac|8|1}} 
|| {{frac|8|1}} &amp;nbsp; 18 &amp;nbsp; 9
|}

Let's find the square root of 46785399 with the bones.

First, group its digits in twos starting from the right so it looks
like this:

: 46 78 53 99

: ''Note:'' A number like 85399 would be grouped as 8 53 99

Start with the leftmost group 46. Pick the largest square on the
square root bone less than 46, which is 36 from the sixth row.

Because we picked the sixth row, the first digit of the solution is 6.

Now read the second column from the sixth row on the square root bone,
12, and set 12 on the board.

Then subtract the value in the first
column of the sixth row, 36, from 46.

Append to this the next group of
digits in the number 78, to get the remainder 1078.

At the end of this step, the board and intermediate calculations
should look like this:
{| border="0" cellpadding="2" cellspacing="0"
|- valign="top"
|
{| border="1" cellpadding="2" cellspacing="0" style="background:#ffd78c;border:thick double #ffc731;"
! &amp;nbsp; || 1 || 2 || √
|- align=right
| '''1''' 
|| {{frac|0|1}} 
|| {{frac|0|2}} 
|| {{frac|0|1}} &amp;nbsp; &amp;nbsp;&amp;nbsp;2 &amp;nbsp; 1
|- align=right
| '''2''' 
|| {{frac|0|2}} 
|| {{frac|0|4}} 
|| {{frac|0|4}} &amp;nbsp; &amp;nbsp;&amp;nbsp;4 &amp;nbsp; 2
|- align=right
| '''3''' 
|| {{frac|0|3}} 
|| {{frac|0|6}} 
|| {{frac|0|9}} &amp;nbsp; &amp;nbsp;&amp;nbsp;6 &amp;nbsp; 3
|- align=right
| '''4''' 
|| {{frac|0|4}} 
|| {{frac|0|8}} 
|| {{frac|1|6}} &amp;nbsp; &amp;nbsp;&amp;nbsp;8 &amp;nbsp; 4
|- align=right
| '''5''' 
|| {{frac|0|5}} 
|| {{frac|1|0}} 
|| {{frac|2|5}} &amp;nbsp; 10 &amp;nbsp; 5
|- align=right
| '''6''' 
|| {{frac|0|6}} 
|| {{frac|1|2}} 
|| {{frac|3|6}} &amp;nbsp; 12 &amp;nbsp; 6
|- align=right
| '''7''' 
|| {{frac|0|7}} 
|| {{frac|1|4}} 
|| {{frac|4|9}} &amp;nbsp; 14 &amp;nbsp; 7
|- align=right
| '''8''' 
|| {{frac|0|8}} 
|| {{frac|1|6}} 
|| {{frac|6|4}} &amp;nbsp; 16 &amp;nbsp; 8
|- align=right
| '''9''' 
|| {{frac|0|9}} 
|| {{frac|1|8}} 
|| {{frac|8|1}} &amp;nbsp; 18 &amp;nbsp; 9
|}
|
          _____________
         √46 78 53 99    =    6
         -36
          –-
          10 78

|}

Now, "read" the numbers in each row, ignoring the second and third columns
from the square root bone and record these. (For example, read the sixth
row as : {{frac|0|6}} {{frac|1|2}} {{frac|3|6}} → 756)

Find the largest number less than the current remainder, 1078.
You should find that 1024 from the eighth row is the largest value
less than 1078.

{| border="0" cellpadding="2" cellspacing="0"
|- valign="top"
|
{| border="1" cellpadding="2" cellspacing="0" style="background:#ffd78c;border:thick double #ffc731;"
! &amp;nbsp; || 1 || 2|| √ || ''(value)''
|- align=right
| '''1''' || {{frac|0|1}} || {{frac|0|2}} || {{frac|0|1}} &amp;nbsp; &amp;nbsp;&amp;nbsp;2 &amp;nbsp; 1 || ''121''
|- align=right
| '''2''' || {{frac|0|2}} || {{frac|0|4}} || {{frac|0|4}} &amp;nbsp; &amp;nbsp;&amp;nbsp;4 &amp;nbsp; 2 || ''244''
|- align=right
| '''3''' || {{frac|0|3}} || {{frac|0|6}} || {{frac|0|9}} &amp;nbsp; &amp;nbsp;&amp;nbsp;6 &amp;nbsp; 3 || ''369''
|- align=right
| '''4''' || {{frac|0|4}} || {{frac|0|8}} || {{frac|1|6}} &amp;nbsp; &amp;nbsp;&amp;nbsp;8 &amp;nbsp; 4 || ''496''
|- align=right
| '''5''' || {{frac|0|5}} || {{frac|1|0}} || {{frac|2|5}} &amp;nbsp; 10 &amp;nbsp; 5 || ''625''
|- align=right
| '''6''' || {{frac|0|6}} || {{frac|1|2}} || {{frac|3|6}} &amp;nbsp; 12 &amp;nbsp; 6 || ''756''
|- align=right
| '''7''' || {{frac|0|7}} || {{frac|1|4}} || {{frac|4|9}} &amp;nbsp; 14 &amp;nbsp; 7 || ''889''
|- align=right style="background:#ffefbd;"
| '''8''' || {{frac|0|8}} || {{frac|1|6}} || {{frac|6|4}} &amp;nbsp; 16 &amp;nbsp; 8 || ''1024''
|- align=right
| '''9''' || {{frac|0|9}} || {{frac|1|8}} || {{frac|8|1}} &amp;nbsp; 18 &amp;nbsp; 9 || ''1161''
|}
|
          _____________
         √46 78 53 99    =    6'''8'''
         -36
          –-
          10 78
         -'''10 24'''
          -----
             '''54'''
|}

As before, append 8 to get the next digit of the square root and
subtract the value of the eighth row 1024 from the current remainder
1078 to get 54. Read the second column of the eighth row on the square
root bone, 16, and set the number on the board as follows.

The current number on the board is 12. Add to it the first digit of
16, and append the second digit of 16 to the result. So you should set
the board to
: 12 + 1 = 13 → append 6 → 136

: ''Note:'' If the second column of the square root bone has only one digit, just append it to the current number on board.

The board and intermediate calculations now look like this.

{| border="0" cellpadding="2" cellspacing="0"
|- valign="top"
|
{| border="1" cellpadding="2" cellspacing="0" style="background:#ffd78c;border:thick double #ffc731;"
! &amp;nbsp; || 1 || 3 || 6|| √
|- align=right
| '''1''' || {{frac|0|1}} || {{frac|0|3}} || {{frac|0|6}} || {{frac|0|1}} &amp;nbsp; &amp;nbsp;&amp;nbsp;2 &amp;nbsp; 1
|- align=right
| '''2''' || {{frac|0|2}} || {{frac|0|6}} || {{frac|1|2}} || {{frac|0|4}} &amp;nbsp; &amp;nbsp;&amp;nbsp;4 &amp;nbsp; 2
|- align=right
| '''3''' || {{frac|0|3}} || {{frac|0|9}} || {{frac|1|8}} || {{frac|0|9}} &amp;nbsp; &amp;nbsp;&amp;nbsp;6 &amp;nbsp; 3
|- align=right
| '''4''' || {{frac|0|4}} || {{frac|1|2}} || {{frac|2|4}} || {{frac|1|6}} &amp;nbsp; &amp;nbsp;&amp;nbsp;8 &amp;nbsp; 4
|- align=right
| '''5''' || {{frac|0|5}} || {{frac|1|5}} || {{frac|3|0}} || {{frac|2|5}} &amp;nbsp; 10 &amp;nbsp; 5
|- align=right
| '''6''' || {{frac|0|6}} || {{frac|1|8}} || {{frac|3|6}} || {{frac|3|6}} &amp;nbsp; 12 &amp;nbsp; 6
|- align=right
| '''7''' || {{frac|0|7}} || {{frac|2|1}} || {{frac|4|2}} || {{frac|4|9}} &amp;nbsp; 14 &amp;nbsp; 7
|- align=right
| '''8''' || {{frac|0|8}} || {{frac|2|4}} || {{frac|4|8}} || {{frac|6|4}} &amp;nbsp; 16 &amp;nbsp; 8
|- align=right
| '''9''' || {{frac|0|9}} || {{frac|2|7}} || {{frac|5|4}} || {{frac|8|1}} &amp;nbsp; 18 &amp;nbsp; 9
|}
|
          _____________
         √46 78 53 99    =    68
         -36
          –-
          10 78
         -10 24
          -----
             54 53
|}

Once again, find the row with the largest value less than the current
partial remainder 5453. This time, it is the third row with 4089.

{| border="0" cellpadding="2" cellspacing="0"
|- valign="top"
|
{| border="1" cellpadding="2" cellspacing="0" style="background:#ffd78c;border:thick double #ffc731;"
! &amp;nbsp; || 1 || 3 || 6|| √ || &amp;nbsp;
|- align=right
| '''1''' || {{frac|0|1}} || {{frac|0|3}} || {{frac|0|6}} || {{frac|0|1}} &amp;nbsp; &amp;nbsp;&amp;nbsp;2 &amp;nbsp; 1 || ''1361''
|- align=right
| '''2''' || {{frac|0|2}} || {{frac|0|6}} || {{frac|1|2}} || {{frac|0|4}} &amp;nbsp; &amp;nbsp;&amp;nbsp;4 &amp;nbsp; 2 || ''2724''
|- align=right  style="background:#ffefbd;"
| '''3''' || {{frac|0|3}} || {{frac|0|9}} || {{frac|1|8}} || {{frac|0|9}} &amp;nbsp; &amp;nbsp;&amp;nbsp;6 &amp;nbsp; 3 || ''4089''
|- align=right
| '''4''' || {{frac|0|4}} || {{frac|1|2}} || {{frac|2|4}} || {{frac|1|6}} &amp;nbsp; &amp;nbsp;&amp;nbsp;8 &amp;nbsp; 4 || ''5456''
|- align=right
| '''5''' || {{frac|0|5}} || {{frac|1|5}} || {{frac|3|0}} || {{frac|2|5}} &amp;nbsp; 10 &amp;nbsp; 5 || ''6825''
|- align=right
| '''6''' || {{frac|0|6}} || {{frac|1|8}} || {{frac|3|6}} || {{frac|3|6}} &amp;nbsp; 12 &amp;nbsp; 6 || ''8196''
|- align=right
| '''7''' || {{frac|0|7}} || {{frac|2|1}} || {{frac|4|2}} || {{frac|4|9}} &amp;nbsp; 14 &amp;nbsp; 7 || ''9569''
|- align=right
| '''8''' || {{frac|0|8}} || {{frac|2|4}} || {{frac|4|8}} || {{frac|6|4}} &amp;nbsp; 16 &amp;nbsp; 8 || ''10944''
|- align=right
| '''9''' || {{frac|0|9}} || {{frac|2|7}} || {{frac|5|4}} || {{frac|8|1}} &amp;nbsp; 18 &amp;nbsp; 9 || ''12321''
|}
|
          _____________
         √46 78 53 99    =    68'''3'''
         -36
          –-
          10 78
         -10 24
          -----
             54 53
            -'''40 89'''
             -----
             '''13 64'''
|}

The next digit of the square root is 3. Repeat the same steps as
before and subtract 4089 from the current remainder 5453 to get 1364
as the next remainder. When you rearrange the board, notice that the
second column of the square root bone is 6, a single digit. So just
append 6 to the current number on the board 136
: 136 → append 6 → 1366
to set 1366 on the board.

{| border="0" cellpadding="2" cellspacing="0"
|- valign="top"
|
{| border="1" cellpadding="2" cellspacing="0" style="background:#ffd78c;border:thick double #ffc731;"
! &amp;nbsp; || 1 || 3 || 6 || 6|| √
|- align=right
| '''1''' || {{frac|0|1}} || {{frac|0|3}} || {{frac|0|6}} || {{frac|0|6}} || {{frac|0|1}} &amp;nbsp; &amp;nbsp;&amp;nbsp;2 &amp;nbsp; 1
|- align=right
| '''2''' || {{frac|0|2}} || {{frac|0|6}} || {{frac|1|2}} || {{frac|1|2}} || {{frac|0|4}} &amp;nbsp; &amp;nbsp;&amp;nbsp;4 &amp;nbsp; 2
|- align=right
| '''3''' || {{frac|0|3}} || {{frac|0|9}} || {{frac|1|8}} || {{frac|1|8}} || {{frac|0|9}} &amp;nbsp; &amp;nbsp;&amp;nbsp;6 &amp;nbsp; 3
|- align=right
| '''4''' || {{frac|0|4}} || {{frac|1|2}} || {{frac|2|4}} || {{frac|2|4}} || {{frac|1|6}} &amp;nbsp; &amp;nbsp;&amp;nbsp;8 &amp;nbsp; 4
|- align=right
| '''5''' || {{frac|0|5}} || {{frac|1|5}} || {{frac|3|0}} || {{frac|3|0}} || {{frac|2|5}} &amp;nbsp; 10 &amp;nbsp; 5
|- align=right
| '''6''' || {{frac|0|6}} || {{frac|1|8}} || {{frac|3|6}} || {{frac|3|6}} || {{frac|3|6}} &amp;nbsp; 12 &amp;nbsp; 6
|- align=right
| '''7''' || {{frac|0|7}} || {{frac|2|1}} || {{frac|4|2}} || {{frac|4|2}} || {{frac|4|9}} &amp;nbsp; 14 &amp;nbsp; 7
|- align=right
| '''8''' || {{frac|0|8}} || {{frac|2|4}} || {{frac|4|8}} || {{frac|4|8}} || {{frac|6|4}} &amp;nbsp; 16 &amp;nbsp; 8
|- align=right
| '''9''' || {{frac|0|9}} || {{frac|2|7}} || {{frac|5|4}} || {{frac|5|4}} || {{frac|8|1}} &amp;nbsp; 18 &amp;nbsp; 9
|}
|
          _____________
         √46 78 53 99    =    683
         -36
          –-
          10 78
         -10 24
          -----
             54 53
            -40 89
             -----
             13 64 99
|}

Repeat these operations once more. Now the largest value on the board
smaller than the current remainder 136499 is 123021 from the ninth
row.

In practice, you often don't need to find the value of every row to
get the answer. You may be able to guess which row has the answer by
looking at the number on the first few bones on the board and
comparing it with the first few digits of the remainder. But in these
diagrams, we show the values of all rows to make it easier to
understand.

As usual, append a 9 to the result and subtract 123021 from the
current remainder.

{| border="0" cellpadding="2" cellspacing="0"
|- valign="top"
|
{| border="1" cellpadding="2" cellspacing="0" style="background:#ffd78c;border:thick double #ffc731;"
! &amp;nbsp; || 1 || 3 || 6 || 6|| √ || &amp;nbsp;
|- align=right
| '''1''' || {{frac|0|1}} || {{frac|0|3}} || {{frac|0|6}} || {{frac|0|6}} || {{frac|0|1}} &amp;nbsp; &amp;nbsp;&amp;nbsp;2 &amp;nbsp; 1 || ''13661''
|- align=right
| '''2''' || {{frac|0|2}} || {{frac|0|6}} || {{frac|1|2}} || {{frac|1|2}} || {{frac|0|4}} &amp;nbsp; &amp;nbsp;&amp;nbsp;4 &amp;nbsp; 2 || ''27324''
|- align=right
| '''3''' || {{frac|0|3}} || {{frac|0|9}} || {{frac|1|8}} || {{frac|1|8}} || {{frac|0|9}} &amp;nbsp; &amp;nbsp;&amp;nbsp;6 &amp;nbsp; 3 || ''40989''
|- align=right
| '''4''' || {{frac|0|4}} || {{frac|1|2}} || {{frac|2|4}} || {{frac|2|4}} || {{frac|1|6}} &amp;nbsp; &amp;nbsp;&amp;nbsp;8 &amp;nbsp; 4 || ''54656''
|- align=right
| '''5''' || {{frac|0|5}} || {{frac|1|5}} || {{frac|3|0}} || {{frac|3|0}} || {{frac|2|5}} &amp;nbsp; 10 &amp;nbsp; 5 || ''68325''
|- align=right
| '''6''' || {{frac|0|6}} || {{frac|1|8}} || {{frac|3|6}} || {{frac|3|6}} || {{frac|3|6}} &amp;nbsp; 12 &amp;nbsp; 6 || ''81996''
|- align=right
| '''7''' || {{frac|0|7}} || {{frac|2|1}} || {{frac|4|2}} || {{frac|4|2}} || {{frac|4|9}} &amp;nbsp; 14 &amp;nbsp; 7 || ''95669''
|- align=right
| '''8''' || {{frac|0|8}} || {{frac|2|4}} || {{frac|4|8}} || {{frac|4|8}} || {{frac|6|4}} &amp;nbsp; 16 &amp;nbsp; 8 || ''109344''
|- align=right style="background:#ffefbd;"
| '''9''' || {{frac|0|9}} || {{frac|2|7}} || {{frac|5|4}} || {{frac|5|4}} || {{frac|8|1}} &amp;nbsp; 18 &amp;nbsp; 9 || ''123021''
|}
|
          _____________
         √46 78 53 99    =    683'''9'''
         -36
          –-
          10 78
         -10 24
          -----
             54 53
            -40 89
             -----
             13 64 99
            -'''12 30 21'''
             --------
              '''1 34 78'''
|}

You've now "used up" all the digits of our number, and you still have
a remainder. This means you've got the integer portion of the square
root but there's some fractional bit still left.

Notice that if we've really got the integer part of the square root,
the current result squared (6839² = 46771921) must be the
largest perfect square smaller than 46785899.  Why? The square root of
46785399 is going to be something like 6839.xxxx... This means
6839² is smaller than 46785399, but 6840² is
bigger than 46785399—the same thing as saying that 6839²
is the largest perfect square smaller than 46785399.

This idea is used later on to understand how the technique works, but
for now let's continue to generate more digits of the square root.

Similar to finding the fractional portion of the answer in
[[long division]], append two zeros to the remainder to get
the new remainder 1347800. The second column of the ninth row of the
square root bone is 18 and the current number on the board is 1366. So
compute
: 1366 + 1 → 1367 → append 8 → 13678
to set 13678 on the board.

The board and intermediate computations now look like this.

{| border="0" cellpadding="2" cellspacing="0"
|- valign="top"
|
{| border="1" cellpadding="2" cellspacing="0" style="background:#ffd78c;border:thick double #ffc731;"
! &amp;nbsp; || 1 || 3 || 6 || 7 || 8|| √
|- align=right
| '''1''' || {{frac|0|1}} || {{frac|0|3}} || {{frac|0|6}} || {{frac|0|7}} || {{frac|0|8}} || {{frac|0|1}} &amp;nbsp; &amp;nbsp;&amp;nbsp;2 &amp;nbsp; 1
|- align=right
| '''2''' || {{frac|0|2}} || {{frac|0|6}} || {{frac|1|2}} || {{frac|1|4}} || {{frac|1|6}} || {{frac|0|4}} &amp;nbsp; &amp;nbsp;&amp;nbsp;4 &amp;nbsp; 2
|- align=right
| '''3''' || {{frac|0|3}} || {{frac|0|9}} || {{frac|1|8}} || {{frac|2|1}} || {{frac|2|4}} || {{frac|0|9}} &amp;nbsp; &amp;nbsp;&amp;nbsp;6 &amp;nbsp; 3
|- align=right
| '''4''' || {{frac|0|4}} || {{frac|1|2}} || {{frac|2|4}} || {{frac|2|8}} || {{frac|3|2}} || {{frac|1|6}} &amp;nbsp; &amp;nbsp;&amp;nbsp;8 &amp;nbsp; 4
|- align=right
| '''5''' || {{frac|0|5}} || {{frac|1|5}} || {{frac|3|0}} || {{frac|3|5}} || {{frac|4|0}} || {{frac|2|5}} &amp;nbsp; 10 &amp;nbsp; 5
|- align=right
| '''6''' || {{frac|0|6}} || {{frac|1|8}} || {{frac|3|6}} || {{frac|4|2}} || {{frac|4|8}} || {{frac|3|6}} &amp;nbsp; 12 &amp;nbsp; 6
|- align=right
| '''7''' || {{frac|0|7}} || {{frac|2|1}} || {{frac|4|2}} || {{frac|4|9}} || {{frac|5|6}} || {{frac|4|9}} &amp;nbsp; 14 &amp;nbsp; 7
|- align=right
| '''8''' || {{frac|0|8}} || {{frac|2|4}} || {{frac|4|8}} || {{frac|5|6}} || {{frac|6|4}} || {{frac|6|4}} &amp;nbsp; 16 &amp;nbsp; 8
|- align=right
| '''9''' || {{frac|0|9}} || {{frac|2|7}} || {{frac|5|4}} || {{frac|6|3}} || {{frac|7|2}} || {{frac|8|1}} &amp;nbsp; 18 &amp;nbsp; 9
|}
|
          _____________
         √46 78 53 99    =    6839.
         -36
          –-
          10 78
         -10 24
          -----
             54 53
            -40 89
             -----
             13 64 99
            -12 30 21
             --------
              1 34 78 00
|}

The ninth row with 1231101 is the largest value smaller than the
remainder, so the first digit of the fractional part of the square
root is 9.

{| border="0" cellpadding="2" cellspacing="0"
|- valign="top"
|
{| border="1" cellpadding="2" cellspacing="0" style="background:#ffd78c;border:thick double #ffc731;"
! &amp;nbsp; || 1 || 3 || 6 || 7 || 8|| √ || &amp;nbsp;
|- align=right
| '''1''' || {{frac|0|1}} || {{frac|0|3}} || {{frac|0|6}} || {{frac|0|7}} || {{frac|0|8}} || {{frac|0|1}} &amp;nbsp; &amp;nbsp;&amp;nbsp;2 &amp;nbsp; 1 || ''136781''
|- align=right
| '''2''' || {{frac|0|2}} || {{frac|0|6}} || {{frac|1|2}} || {{frac|1|4}} || {{frac|1|6}} || {{frac|0|4}} &amp;nbsp; &amp;nbsp;&amp;nbsp;4 &amp;nbsp; 2 || ''273564''
|- align=right
| '''3''' || {{frac|0|3}} || {{frac|0|9}} || {{frac|1|8}} || {{frac|2|1}} || {{frac|2|4}} || {{frac|0|9}} &amp;nbsp; &amp;nbsp;&amp;nbsp;6 &amp;nbsp; 3 || ''410349''
|- align=right
| '''4''' || {{frac|0|4}} || {{frac|1|2}} || {{frac|2|4}} || {{frac|2|8}} || {{frac|3|2}} || {{frac|1|6}} &amp;nbsp; &amp;nbsp;&amp;nbsp;8 &amp;nbsp; 4 || ''547136''
|- align=right
| '''5''' || {{frac|0|5}} || {{frac|1|5}} || {{frac|3|0}} || {{frac|3|5}} || {{frac|4|0}} || {{frac|2|5}} &amp;nbsp; 10 &amp;nbsp; 5 || ''683925''
|- align=right
| '''6''' || {{frac|0|6}} || {{frac|1|8}} || {{frac|3|6}} || {{frac|4|2}} || {{frac|4|8}} || {{frac|3|6}} &amp;nbsp; 12 &amp;nbsp; 6 || ''820716''
|- align=right
| '''7''' || {{frac|0|7}} || {{frac|2|1}} || {{frac|4|2}} || {{frac|4|9}} || {{frac|5|6}} || {{frac|4|9}} &amp;nbsp; 14 &amp;nbsp; 7 || ''957509''
|- align=right
| '''8''' || {{frac|0|8}} || {{frac|2|4}} || {{frac|4|8}} || {{frac|5|6}} || {{frac|6|4}} || {{frac|6|4}} &amp;nbsp; 16 &amp;nbsp; 8 || ''1094304''
|- align=right  style="background:#ffefbd;"
| '''9''' || {{frac|0|9}} || {{frac|2|7}} || {{frac|5|4}} || {{frac|6|3}} || {{frac|7|2}} || {{frac|8|1}} &amp;nbsp; 18 &amp;nbsp; 9 || ''1231101''
|}
|
          _____________
         √46 78 53 99    =    6839.'''9'''
         -36
          –-
          10 78
         -10 24
          -----
             54 53
            -40 89
             -----
             13 64 99
            -12 30 21
             --------
              1 34 78 00
             -'''1 23 11 01'''
              ----------
                '''11 66 99'''
|}

Subtract the value of the ninth row from the remainder and append a
couple more zeros to get the new remainder 11669900. The second column
on the ninth row is 18 with 13678 on the board, so compute
: 13678 + 1 → 13679 → append 8 → 136798
and set 136798 on the board.

{| border="0" cellpadding="2" cellspacing="0"
|- valign="top"
|
{| border="1" cellpadding="2" cellspacing="0" style="background:#ffd78c;border:thick double #ffc731;"
! &amp;nbsp; || 1 || 3 || 6 || 7 || 9 || 8|| √
|- align=right
| '''1''' || {{frac|0|1}} || {{frac|0|3}} || {{frac|0|6}} || {{frac|0|7}} || {{frac|0|9}} || {{frac|0|8}} || {{frac|0|1}} &amp;nbsp; &amp;nbsp;&amp;nbsp;2 &amp;nbsp; 1
|- align=right
| '''2''' || {{frac|0|2}} || {{frac|0|6}} || {{frac|1|2}} || {{frac|1|4}} || {{frac|1|8}} || {{frac|1|6}} || {{frac|0|4}} &amp;nbsp; &amp;nbsp;&amp;nbsp;4 &amp;nbsp; 2
|- align=right
| '''3''' || {{frac|0|3}} || {{frac|0|9}} || {{frac|1|8}} || {{frac|2|1}} || {{frac|2|7}} || {{frac|2|4}} || {{frac|0|9}} &amp;nbsp; &amp;nbsp;&amp;nbsp;6 &amp;nbsp; 3
|- align=right
| '''4''' || {{frac|0|4}} || {{frac|1|2}} || {{frac|2|4}} || {{frac|2|8}} || {{frac|3|6}} || {{frac|3|2}} || {{frac|1|6}} &amp;nbsp; &amp;nbsp;&amp;nbsp;8 &amp;nbsp; 4
|- align=right
| '''5''' || {{frac|0|5}} || {{frac|1|5}} || {{frac|3|0}} || {{frac|3|5}} || {{frac|4|5}} || {{frac|4|0}} || {{frac|2|5}} &amp;nbsp; 10 &amp;nbsp; 5
|- align=right
| '''6''' || {{frac|0|6}} || {{frac|1|8}} || {{frac|3|6}} || {{frac|4|2}} || {{frac|5|4}} || {{frac|4|8}} || {{frac|3|6}} &amp;nbsp; 12 &amp;nbsp; 6
|- align=right
| '''7''' || {{frac|0|7}} || {{frac|2|1}} || {{frac|4|2}} || {{frac|4|9}} || {{frac|6|3}} || {{frac|5|6}} || {{frac|4|9}} &amp;nbsp; 14 &amp;nbsp; 7
|- align=right
| '''8''' || {{frac|0|8}} || {{frac|2|4}} || {{frac|4|8}} || {{frac|5|6}} || {{frac|7|2}} || {{frac|6|4}} || {{frac|6|4}} &amp;nbsp; 16 &amp;nbsp; 8
|- align=right
| '''9''' || {{frac|0|9}} || {{frac|2|7}} || {{frac|5|4}} || {{frac|6|3}} || {{frac|8|1}} || {{frac|7|2}} || {{frac|8|1}} &amp;nbsp; 18 &amp;nbsp; 9
|}
|
          _____________
         √46 78 53 99    =    6839.9
         -36
          –-
          10 78
         -10 24
          -----
             54 53
            -40 89
             -----
             13 64 99
            -12 30 21
             --------
              1 34 78 00
             -1 23 11 01
              ----------
                11 66 99 00
|}

You can continue these steps to find as many digits as you need and
you stop when you have the precision you want, or if you find that the
remainder becomes zero which means you have the exact square root.

Having found the desired number of digits, you can easily determine whether or not you need to round up; i.e., increment the last digit.  You don't need to find another digit to see if it is equal to or greater than five.  Simply append 25 to the root and compare that to the remainder; if it is less than or equal to the remainder, then the next digit will be at least five and round up is needed.  In the example above, we see that 6839925 is less than 11669900, so we need to round up the root to 6840.0.

There's only one more trick left to describe. If you want to find the
square root of a number that isn't an integer, say 54782.917.
Everything is the same, except you start out by grouping the digits
to the left and right of the decimal point in groups of two.

That is, group 54782.917 as

: 5 47 82 . 91 7

and proceed to extract the square root from these groups of digits.

== Diagonal modification ==
During the 19th century, Napier's bones underwent a transformation to make them easier to read. The rods began to be made with an angle of about 65° so that the triangles that had to be added were aligned vertically.  In this case, in each square of the rod the unit is to the right and the ten (or the zero) to the left.

[[Image:Napier Modification.png]]

The rods were made such that the vertical and horizontal lines were more visible than the line where the rods touched, making the two components of each digit of the result much easier to read. Thus, in the picture it is immediately clear that:
:987654321 × 5 = 4938271605

== Genaille–Lucas rulers ==
{{Main|Genaille–Lucas rulers}}

In 1891, [[Henri Genaille]] invented a variant of Napier's bones which became known as [[Genaille–Lucas rulers]]. By representing the [[Carry (arithmetic)|carry]] graphically, the user can read off the results of simple multiplication problems directly, with no intermediate mental calculations.

The following example is calculating 52749&amp;nbsp;×&amp;nbsp;4&amp;nbsp;=&amp;nbsp;210996.

[[Image:Genaille-Lucas rulers example 5.png]]

==Card abacus==
{{unreferenced section|date=October 2013}}
[[File:Ábacos neperianos (M.A.N. Madrid) 01.jpg|thumb|290px|The two Napier's abacuses at the [[National Archaeological Museum of Spain]] in Madrid.]]

In addition to the previously-described "bones" abacus, Napier also constructed a [[card abacus]]. Both devices are reunited in a piece held by the [[National Archaeological Museum of Spain]] in [[Madrid]].

The apparatus is a box of wood with inlays of bone. In the top section it contains the "bones" abacus, and in the bottom section is the card abacus. This card abacus consists of 300 stored cards in 30 drawers.  One hundred of these cards are covered with numbers (referred to as the "number cards"). The remaining two hundred cards contain small triangular holes, which, when laid on top of the number cards, allow the user to see only certain numbers.  By the capable positioning of these cards, multiplications can be made up to the limit of a number 100 digits in length, by another number 200 digits in length.

In addition, the doors of the box contain the first powers of the digits, the coefficients of the terms of the first powers of the [[binomial (polynomial)|binomial]] and the numeric data of the regular [[polyhedron|polyhedra]].&lt;ref&gt;''[[Diccionario enciclopédico hispano-americano de literatura, ciencias y artes]]'', Mountainer y Simón Editores, Barcelona, 1887, Tomo I, pp.&amp;nbsp;19–20.&lt;/ref&gt;

It is not known who was the author of this piece, nor if it is of Spanish origin or came from a foreigner, although it is probable that it originally belonged to the [[Spanish Royal Academy of Sciences|Spanish Academy of Mathematics]] (which was created by [[Philip II of Spain|Philip II]]) or was a gift from the [[Prince of Wales]].  The only thing that is sure is that it was conserved in the Palace, whence it was passed to the [[Biblioteca Nacional de España|National library]] and later to the National Archaeological Museum, where it is still conserved.

In 1876, the Spanish government sent the apparatus to the exhibition of scientific instruments in [[Kensington]], where it received so much attention that several societies consulted the Spanish representation about the origin and use of the apparatus.
{{Rabdology}}

==See also==
* [[Genaille–Lucas rulers]]
* [[Pascal's calculator]]
* [[Slide rule]]

==References==
{{reflist}}

==External links==
* [http://www.cut-the-knot.org/blue/Napier.shtml Java implementation of Napier bones in various number systems] at [[cut-the-knot]]
* [http://www.peterkernwein.de/Rechengeraete-Sammlung/mechcal.htm Napier and other bones and many calculators]
* [http://www.giraldi.org/nepero.html How Napier bones work (interactive simulator)]

[[Category:Mechanical calculators]]
[[Category:Scottish inventions]]
[[Category:Multiplication]]</text>
      <sha1>nxytlg3c7nqyolz1b8twtj6h5vs81qd</sha1>
    </revision>
  </page>
  <page>
    <title>Oscillation (mathematics)</title>
    <ns>0</ns>
    <id>475449</id>
    <revision>
      <id>716721723</id>
      <parentid>704838759</parentid>
      <timestamp>2016-04-23T12:36:21Z</timestamp>
      <contributor>
        <username>Stephan Kulla</username>
        <id>17146887</id>
      </contributor>
      <comment>/* Examples */ add image fitting better to one of the given examples</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7159">[[File:LimSup.svg|right|thumb|300px|Oscillation of a sequence (shown in blue) is the difference between the limit superior and limit inferior of the sequence.]]

In [[mathematics]], the '''oscillation''' of a function or a sequence is a number that quantifies how much a sequence or function varies between its extreme values as it approaches infinity or a point. As is the case with [[limit (mathematics)|limit]]s there are several definitions that put the intuitive concept into a form suitable for a mathematical treatment: oscillation of a [[sequence]] of [[real number]]s, oscillation of a real valued [[function (mathematics)|function]] at a point, and oscillation of a function on an [[interval (mathematics)|interval]] (or [[open set]]).

==Definitions==

===Oscillation of a sequence===
Let &lt;math&gt;(a_n)&lt;/math&gt; be a sequence of real numbers. The oscillation &lt;math&gt;\omega(a_n)&lt;/math&gt; of that sequence is defined as the difference (possibly infinite) between the [[limit superior and limit inferior]] of &lt;math&gt;(a_n)&lt;/math&gt;:

:&lt;math&gt;\omega(a_n) = \limsup_{n\to\infty} a_n - \liminf_{n\to\infty} a_n&lt;/math&gt;.

The oscillation is zero if and only if the sequence converges. It is undefined if &lt;math&gt;\limsup_{n\to\infty}&lt;/math&gt; and &lt;math&gt;\liminf_{n\to\infty}&lt;/math&gt; are both equal to +∞ or both equal to −∞, that is, if the sequence tends to +∞ or −∞.

===Oscillation of a function on an open set===
Let &lt;math&gt;f&lt;/math&gt; be a real-valued function of a real variable.  The oscillation of &lt;math&gt;f&lt;/math&gt; on an interval &lt;math&gt;I&lt;/math&gt; in its domain is the difference between the [[supremum]] and [[infimum]] of &lt;math&gt;f&lt;/math&gt;:
:&lt;math&gt;\omega_f(I) = \sup_{x\in I} f(x) - \inf_{x\in I} f(x).&lt;/math&gt;
More generally, if &lt;math&gt;f:X\to\mathbb{R}&lt;/math&gt; is a function on a [[topological space]] &lt;math&gt;X&lt;/math&gt; (such as a [[metric space]]), then the oscillation of &lt;math&gt;f&lt;/math&gt; on an [[open set]] &lt;math&gt;U&lt;/math&gt; is
:&lt;math&gt;\omega_f(U) = \sup_{x\in U} f(x) - \inf_{x\in U}f(x).&lt;/math&gt;

===Oscillation of a function at a point===
The oscillation of a function &lt;math&gt;f&lt;/math&gt; of a real variable at a point &lt;math&gt;x_0&lt;/math&gt; is defined as the limit as &lt;math&gt;\epsilon\to 0&lt;/math&gt; of the oscillation of &lt;math&gt;f&lt;/math&gt; on an &lt;math&gt;\epsilon&lt;/math&gt;-neighborhood of &lt;math&gt;x_0&lt;/math&gt;:
:&lt;math&gt;\omega_f(x_0) = \lim_{\epsilon\to 0} \omega_f(x_0-\epsilon,x_0+\epsilon).&lt;/math&gt;
This is the same as the difference between the limit superior and limit inferior of the function at &lt;math&gt;x_0&lt;/math&gt;, ''provided'' the point &lt;math&gt;x_0&lt;/math&gt; is not excluded from the limits.

More generally, if &lt;math&gt;f:X\to\mathbb{R}&lt;/math&gt; is a real-valued function on a [[metric space]], then the oscillation is
:&lt;math&gt;\omega_f(x_0) = \lim_{\epsilon\to 0} \omega_f(B_\epsilon(x_0)).&lt;/math&gt;

==Examples==
[[File:The function sin(1 over x).svg|thumb|sin (1/''x'') (the [[topologist's sine curve]]) has oscillation 2 at ''x'' = 0, and 0 elsewhere.]]
*1/''x'' has oscillation ∞ at ''x'' = 0, and oscillation 0 at other finite ''x'' and at −∞ and +∞.
*sin (1/''x'') (the [[topologist's sine curve]]) has oscillation 2 at ''x'' = 0, and 0 elsewhere.
*sin ''x'' has oscillation 0 at every finite ''x'', and 2 at −∞ and +∞.
*The sequence 1, &amp;minus;1, 1, &amp;minus;1, 1, &amp;minus;1, ... has oscillation 2.

In the last example the sequence is [[Frequency|periodic]], and any sequence that is periodic without being constant will have non-zero oscillation. However, non-zero oscillation does not usually indicate periodicity.

Geometrically, the graph of an oscillating function on the real numbers follows some  path in the ''xy''-plane, without settling into ever-smaller regions. In [[well-behaved]] cases the path might look like a loop coming back on itself, that is, periodic behaviour; in the worst cases quite irregular movement covering a whole region.

== Continuity ==
Oscillation can be used to define [[continuous function|continuity of a function]], and is easily equivalent to the usual ''ε''-''δ'' definition (in the case of functions defined everywhere on the real line): a function ƒ is continuous at a point ''x''&lt;sub&gt;0&lt;/sub&gt; if and only if the oscillation is zero;&lt;ref&gt;''[http://ramanujan.math.trinity.edu/wtrench/texts/TRENCH_REAL_ANALYSIS.PDF Introduction to Real Analysis],'' updated April 2010, William F. Trench, Theorem 3.5.2, p. 172&lt;/ref&gt; in symbols, &lt;math&gt;\omega_f(x_0) = 0.&lt;/math&gt; A benefit of this definition is that it ''quantifies'' discontinuity: the oscillation gives how ''much'' the function is discontinuous at a point.

For example, in the [[classification of discontinuities]]:
* in a removable discontinuity, the distance that the value of the function is off by is the oscillation;
* in a jump discontinuity, the size of the jump is the oscillation (assuming that the value ''at'' the point lies between these limits from the two sides);
* in an essential discontinuity, oscillation measures the failure of a limit to exist.

This definition is useful in [[descriptive set theory]] to study the set of discontinuities and continuous points – the continuous points are the intersection of the sets where the oscillation is less than ''ε'' (hence a [[G-delta set|G&lt;sub&gt;δ&lt;/sub&gt; set]]) – and gives a very quick proof of one direction of the [[Lebesgue integrability condition]].&lt;ref&gt;''[http://ramanujan.math.trinity.edu/wtrench/texts/TRENCH_REAL_ANALYSIS.PDF Introduction to Real Analysis],'' updated April 2010, William F. Trench, 3.5 "A More Advanced Look at the Existence of the Proper Riemann Integral", pp. 171–177&lt;/ref&gt;

The oscillation is equivalence to the ''ε''-''δ'' definition by a simple re-arrangement, and by using a limit ([[lim sup]], [[lim inf]]) to define oscillation: if (at a given point) for a given ''ε''&lt;sub&gt;0&lt;/sub&gt; there is no ''δ'' that satisfies the ''ε''-''δ'' definition, then the oscillation is at least ''ε''&lt;sub&gt;0&lt;/sub&gt;, and conversely if for every ''ε'' there is a desired ''δ,'' the oscillation is 0. The oscillation definition can be naturally generalized to maps from a topological space to a metric space.

==Generalizations==
More generally, if ''f'' : ''X'' → ''Y'' is a function from a [[topological space]] ''X'' into a [[metric space]] ''Y'', then the '''oscillation of ''f''''' is defined at each ''x'' ∈ ''X'' by

:&lt;math&gt;\omega(x) = \inf\left\{\mathrm{diam}(f(U))\mid U\mathrm{\ is\ a\  neighborhood\ of\ }x\right\}&lt;/math&gt;

== See also ==
* [[Wave equation]]
* [[Wave envelope]]
* [[Grandi's series]]
* [[Bounded mean oscillation]]

==References==
{{reflist}}
{{refbegin}}
*{{cite book|author=Hewitt and Stromberg|title=Real and abstract analysis|page=78|publisher=Springer-Verlag|year=1965}}
*{{cite book|author=Oxtoby, J|title=Measure and category|publisher=Springer-Verlag|edition=4th|year=1996|pages=31–35|isbn=978-0-387-90508-2}}
*{{cite book
 | last       = Pugh
 | first      = C. C.
 | title      = Real mathematical analysis
 | publisher  = New York: Springer
 | date       = 2002
 | pages      = 164–165 
 | isbn       = 0-387-95297-7
}}
{{refend}}

[[Category:Real analysis]]
[[Category:Limits (mathematics)]]
[[Category:Sequences and series]]
[[Category:Functions and mappings]]</text>
      <sha1>tbqq4nogh227fskrvldsj9616lqw7n6</sha1>
    </revision>
  </page>
  <page>
    <title>Paraproduct</title>
    <ns>0</ns>
    <id>30058480</id>
    <revision>
      <id>799458347</id>
      <parentid>713766430</parentid>
      <timestamp>2017-09-07T21:09:17Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1675">{{Orphan|date=February 2013}}

In [[mathematics]], a '''paraproduct''' is a [[non-commutative]] [[bilinear operator]] acting on [[function (mathematics)|functions]] that in some sense is like the [[product (mathematics)|product]] of the two functions it acts on.  According to [[Svante Janson]] and Jaak Peetre, in an article from 1988,&lt;ref&gt;Svante Janson and Jaak Peetre, [https://www.jstor.org/stable/2000875 "Paracommutators-Boundedness and Schatten-Von Neumann Properties"], ''Transactions of the American Mathematical Society'', Vol. 305, No. 2 (Feb., 1988), pp. 467–504.&lt;/ref&gt; "the name 'paraproduct' denotes an idea rather than a unique definition; several versions exist and can be used for the same purposes."

This said, for a given operator &lt;math&gt;\Lambda&lt;/math&gt; to be defined as a paraproduct, it is normally required to satisfy the following properties:
* It should "reconstruct the product" in the sense that for any pair of functions, &lt;math&gt;(f, g)&lt;/math&gt; in its domain,
:: &lt;math&gt;fg = \Lambda(f, g) + \Lambda(g, f).&lt;/math&gt;
* For any appropriate functions, &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;h&lt;/math&gt; with &lt;math&gt;h(0)=0&lt;/math&gt;, it is the case that &lt;math&gt;h(f) = \Lambda(f, h'(f))&lt;/math&gt;.
* It should satisfy some form of the [[Product rule|Leibniz rule]].

A paraproduct may also be required to satisfy some form of [[Hölder's inequality]].

==Notes==
{{Reflist}}

==Further references==
* Árpád Bényi, Diego Maldonado, and Virginia Naibo, [http://www.ams.org/notices/201007/rtx100700858p.pdf "What is a Paraproduct?"], ''Notices of the American Mathematical Society'', Vol. 57, No. 7 (Aug., 2010), pp.&amp;nbsp;858–860.

[[Category:Bilinear operators]]


{{algebra-stub}}</text>
      <sha1>tmxia7t6smnyn69sj5opnotk2lbwkqm</sha1>
    </revision>
  </page>
  <page>
    <title>Pathwidth</title>
    <ns>0</ns>
    <id>5133142</id>
    <revision>
      <id>846711044</id>
      <parentid>841549402</parentid>
      <timestamp>2018-06-20T12:39:32Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="64337">In [[graph theory]], a '''path decomposition''' of a graph ''G'' is, informally, a representation of ''G'' as a "thickened" [[path graph]],&lt;ref&gt;{{harvtxt|Diestel|Kühn|2005}}.&lt;/ref&gt; and the '''pathwidth''' of ''G'' is a number that measures how much the path was thickened to form&amp;nbsp;''G''. More formally, a path-decomposition is
a sequence of subsets of vertices of ''G'' such that the endpoints of each edge appear in one of the subsets and such that each vertex appears in a contiguous subsequence of the subsets,&lt;ref name="rs83"&gt;{{harvtxt|Robertson|Seymour|1983}}.&lt;/ref&gt; and the pathwidth is one less than the size of the largest set in such a decomposition.
Pathwidth is also known as '''interval thickness''' (one less than the [[maximum clique]] size in an [[interval graph|interval]] [[Glossary of graph theory#Subgraphs|supergraph]] of ''G''), '''vertex separation number''', or '''node searching number'''.&lt;ref&gt;{{harvtxt|Bodlaender|1998}}.&lt;/ref&gt;

Pathwidth and path-decompositions are closely analogous to [[treewidth]] and [[tree decomposition]]s. They play a key role in the theory of [[graph minor]]s: the families of graphs that are closed under [[graph minor]]s and do not include all [[tree (graph theory)|forest]]s may be characterized as having bounded pathwidth,&lt;ref name="rs83"/&gt; and the "vortices" appearing in the general [[Graph structure theorem|structure theory for minor-closed graph families]] have bounded pathwidth.&lt;ref name="Robertson 2003"&gt;{{harvtxt|Robertson|Seymour|2003}}.&lt;/ref&gt; Pathwidth, and graphs of bounded pathwidth, also have applications in [[VLSI]] design, [[graph drawing]], and [[computational linguistics]].

It is [[NP-hard]] to find the pathwidth of arbitrary graphs, or even to approximate it accurately.&lt;ref name="npc"/&gt;&lt;ref name="bghk92"&gt;{{harvtxt|Bodlaender|Gilbert|Hafsteinsson|Kloks|1992}}.&lt;/ref&gt; However, the problem is [[fixed-parameter tractable]]: testing whether a graph has pathwidth ''k'' can be solved in an amount of time that depends linearly on the size of the graph but superexponentially on&amp;nbsp;''k''.&lt;ref name="bounded-tw-algs"/&gt; Additionally, for several special classes of graphs, such as [[tree (graph theory)|trees]], the pathwidth may be computed in polynomial time without dependence on&amp;nbsp;''k''.&lt;ref&gt;{{harvtxt|Bodlaender|1994}}.&lt;/ref&gt;&lt;ref name="tree-algs"/&gt;
Many problems in graph algorithms may be solved efficiently on graphs of bounded pathwidth, by using [[dynamic programming]] on a path-decomposition of the graph.&lt;ref name="Arnborg 1985"&gt;{{harvtxt|Arnborg|1985}}.&lt;/ref&gt; Path decomposition may also be used to measure the [[space complexity]] of dynamic programming algorithms on graphs of bounded [[treewidth]].&lt;ref name="apt00"&gt;{{harvtxt|Aspvall|Proskurowski|Telle|2000}}.&lt;/ref&gt;

==Definition==
[[File:Pathwidth.JPG|thumb|upright=1.5|An example graph G with pathwidth 2 and its path-decomposition of width 2. The bottom portion of the image is the same graph and path-decomposition with color added for emphasis. (This example is an adaptation of the graph presented in,&lt;ref&gt;{{Cite journal|url = |title = A tourist guide through treewidth|last = Bodlaender|first = Hans L.|date = 1994|journal = Acta Cybernetica |volume=11 |pages=1–2|doi = |pmid = |access-date = |issue = }}&lt;/ref&gt; emphasis added)]]
In the first of their famous series of papers on [[graph minor]]s, {{harvs | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician) | last2 = Seymour | first2 = Paul | author2-link = Paul Seymour (mathematician) | year = 1983 | txt}} define a path-decomposition of a graph ''G'' to be a sequence of subsets ''X&lt;sub&gt;i&lt;/sub&gt;'' of vertices of ''G'', with two properties:
#For each edge of ''G'', there exists an ''i'' such that both endpoints of the edge belong to subset ''X&lt;sub&gt;i&lt;/sub&gt;'', and
#For every three indices ''i'' ≤ ''j'' ≤ ''k'', {{nowrap|''X&lt;sub&gt;i&lt;/sub&gt;'' ∩ ''X&lt;sub&gt;k&lt;/sub&gt;'' ⊆ ''X&lt;sub&gt;j&lt;/sub&gt;''.}}
The second of these two properties is equivalent to requiring that the subsets containing any particular vertex form a contiguous subsequence of the whole sequence. In the language of the later papers in Robertson and Seymour's graph minor series, a path-decomposition is a [[tree decomposition]] (''X'',''T'') in which the underlying tree ''T'' of the decomposition is a [[path graph]].

The width of a path-decomposition is defined in the same way as for tree-decompositions, as max&lt;sub&gt;''i''&lt;/sub&gt;&amp;nbsp;|''X&lt;sub&gt;i&lt;/sub&gt;''|&amp;nbsp;−&amp;nbsp;1, and the pathwidth of ''G'' is the minimum width of any path-decomposition of&amp;nbsp;''G''. The subtraction of one from the size of ''X&lt;sub&gt;i&lt;/sub&gt;'' in this definition makes little difference in most applications of pathwidth, but is used to make the pathwidth of a [[path graph]] be equal to one.

==Alternative characterizations==
As {{harvtxt|Bodlaender|1998}} describes, pathwidth can be characterized in many  equivalent ways.

===Gluing sequences===
A path decomposition can be described as a sequence of graphs ''G&lt;sub&gt;i&lt;/sub&gt;'' that are glued together by identifying pairs of vertices from consecutive graphs in the sequence, such that the result of performing all of these gluings is ''G''. The graphs ''G&lt;sub&gt;i&lt;/sub&gt;'' may be taken as the [[induced subgraph]]s of the sets ''X&lt;sub&gt;i&lt;/sub&gt;'' in the first definition of path decompositions, with two vertices in successive induced subgraphs being glued together when they are induced by the same vertex in ''G'', and in the other direction one may recover the sets ''X&lt;sub&gt;i&lt;/sub&gt;'' as the vertex sets of the graphs ''G&lt;sub&gt;i&lt;/sub&gt;''. The width of the path decomposition is then one less than the maximum number of vertices in one of the graphs ''G&lt;sub&gt;i&lt;/sub&gt;''.&lt;ref name="rs83"/&gt;

===Interval thickness===
[[File:Interval graph.svg|thumb|upright=1.25|An [[interval graph]] with pathwidth two, one less than the cardinality of its four maximum cliques ''ABC'', ''ACD'', ''CDE'', and ''CDF''.]]
The pathwidth of any graph ''G'' is equal to one less than the smallest clique number of an [[interval graph]] that contains ''G'' as a subgraph.&lt;ref&gt;{{harvtxt|Bodlaender|1998}}, Theorem 29, p. 13.&lt;/ref&gt; That is, for every path decomposition of ''G'' one can find an interval supergraph of ''G'', and for every interval supergraph of ''G'' one can find a path decomposition of ''G'', such that the width of the decomposition is one less than the clique number of the interval graph.

In one direction, suppose a path decomposition of ''G'' is given. Then one may represent the nodes of the decomposition as points on a line (in path order) and represent each vertex ''v'' as a closed interval having these points as endpoints. In this way, the path decomposition nodes containing ''v'' correspond to the representative points in the interval for ''v''. The [[intersection graph]] of the intervals formed from the vertices of ''G'' is an interval graph that contains ''G'' as a subgraph. Its maximal cliques are given by the sets of intervals containing the representative points, and its maximum clique size is one plus the pathwidth of ''G''.

In the other direction, if ''G'' is a subgraph of an interval graph with clique number ''p''&amp;nbsp;+&amp;nbsp;1, then ''G'' has a path decomposition of width ''p'' whose nodes are given by the [[maximal clique]]s of the interval graph. For instance, the interval graph shown with its interval representation in the figure has a path decomposition with five nodes, corresponding to its five maximal cliques ''ABC'', ''ACD'', ''CDE'', ''CDF'', and ''FG''; the maximum clique size is three and the width of this path decomposition is two.

This equivalence between pathwidth and interval thickness is closely analogous to the equivalence between treewidth and the minimum clique number (minus one) of a [[chordal graph]] of which the given graph is a subgraph. Interval graphs are a special case of chordal graphs, and chordal graphs can be represented as intersection graphs of subtrees of a common tree generalizing the way that interval graphs are intersection graphs of subpaths of a path.

===Vertex separation number===
Suppose that the vertices of a graph ''G'' are [[linear order|linearly ordered]]. Then the vertex separation number of ''G'' is the smallest number ''s'' such that, for each vertex ''v'', at most ''s'' vertices are earlier than ''v'' in the ordering but that have ''v'' or a later vertex as a neighbor.
The vertex separation number of ''G'' is the minimum vertex separation number of any linear ordering of ''G''. The vertex separation number was defined by {{harvtxt|Ellis|Sudborough|Turner|1983}}, and is equal to the pathwidth of ''G''.&lt;ref&gt;{{harvtxt|Kinnersley|1992}}; {{harvtxt|Bodlaender|1998}}, Theorem 51.&lt;/ref&gt;
This follows from the earlier equivalence with interval graph clique numbers: if ''G'' is a subgraph of an interval graph ''I'', represented (as in the figure) in such a way that all interval endpoints are distinct, then the ordering of the left endpoints of the intervals of ''I'' has vertex separation number one less than the clique number of ''I''. And in the other direction, from a linear ordering of ''G'' one may derive an interval representation in which the left endpoint of the interval for a vertex ''v'' is its position in the ordering and the right endpoint is the position of the neighbor of ''v'' that comes last in the ordering.

===Node searching number===
The node searching game on a graph is a form of [[pursuit-evasion]] in which a set of searchers collaborate to track down a fugitive hiding in a graph. The searchers are placed on vertices of the graph while the fugitive may be in any edge of the graph, and the fugitive's location and moves are hidden from the searchers. In each turn, some or all of the searchers may move (arbitrarily, not necessarily along edges) from one vertex to another, and then the fugitive may move along any path in the graph that does not pass through a searcher-occupied vertex. The fugitive is caught when both endpoints of his edge are occupied by searchers. The node searching number of a graph is the minimum number of searchers needed to ensure that the fugitive can be guaranteed to be caught, no matter how he moves. As {{harvtxt|Kirousis|Papadimitriou|1985}} show, the node searching number of a graph equals its interval thickness. The optimal strategy for the searchers is to move the searchers so that in successive turns they form the separating sets of a linear ordering with minimal vertex separation number.

==Bounds==
[[File:Caterpillar tree.svg|thumb|A [[caterpillar tree]], a maximal graph with pathwidth one.]]
Every ''n''-vertex graph with pathwidth ''k'' has at most {{nowrap|''k''(''n'' − ''k'' + (''k'' − 1)/2))}} edges, and the [[maximal element|maximal]] pathwidth-''k'' graphs (graphs to which no more edges can be added without increasing the pathwidth) have exactly this many edges. A maximal pathwidth-''k'' graph must be either a ''k''-path or a ''k''-caterpillar, two special kinds of ''k''-tree. A ''k''-tree is a [[chordal graph]] with exactly {{nowrap|''n'' − ''k''}} [[maximal clique]]s, each containing {{nowrap|''k'' + 1}} vertices; in a ''k''-tree that is not itself a {{nowrap|(''k'' + 1)-clique}}, each maximal clique either separates the graph into two or more components, or it contains a single leaf vertex, a vertex that belongs to only a single maximal clique. A ''k''-path is a ''k''-tree with at most two leaves, and a ''k''-caterpillar is a ''k''-tree that can be partitioned into a ''k''-path and a set of ''k''-leaves each adjacent to a separator ''k''-clique of the ''k''-path. In particular the maximal graphs of pathwidth one are exactly the [[caterpillar tree]]s.&lt;ref&gt;{{harvtxt|Proskurowski|Telle|1999}}.&lt;/ref&gt;

Since path-decompositions are a special case of tree-decompositions, the pathwidth of any graph is greater than or equal to its [[treewidth]]. The pathwidth is also less than or equal to the [[cutwidth]], the minimum number of edges that cross any cut between lower-numbered and higher-numbered vertices in an optimal linear arrangement of the vertices of a graph; this follows because the vertex separation number, the number of lower-numbered vertices with higher-numbered neighbors, can at most equal the number of cut edges.&lt;ref&gt;{{harvtxt|Korach|Solel|1993}}, Lemma 3 p.99; {{harvtxt|Bodlaender|1998}}, Theorem 47, p. 24.&lt;/ref&gt; For similar reasons, the cutwidth is at most the pathwidth times the [[degree (graph theory)|maximum degree]] of the vertices in a given graph.&lt;ref&gt;{{harvtxt|Korach|Solel|1993}}, Lemma 1, p. 99; {{harvtxt|Bodlaender|1998}}, Theorem 49, p. 24.&lt;/ref&gt;

Any ''n''-vertex [[tree (graph theory)|forest]] has pathwidth O(log&amp;nbsp;''n'').&lt;ref&gt;{{harvtxt|Korach|Solel|1993}}, Theorem 5, p. 99; {{harvtxt|Bodlaender|1998}}, Theorem 66, p. 30. {{harvtxt|Scheffler|1992}} gives a tighter upper bound of log&lt;sub&gt;3&lt;/sub&gt;(2''n''&amp;nbsp;+&amp;nbsp;1) on the pathwidth of an ''n''-vertex forest.&lt;/ref&gt; For, in a forest, one can always find a constant number of vertices the removal of which leaves a forest that can be partitioned into two smaller subforests with at most 2''n''/3 vertices each. A linear arrangement formed by recursively partitioning each of these two subforests, placing the separating vertices between them, has logarithmic vertex searching number. The same technique, applied to a tree-decomposition of a graph, shows that, if the treewidth of an ''n''-vertex graph ''G'' is ''t'', then the pathwidth of ''G'' is O(''t''&amp;nbsp;log&amp;nbsp;''n'').&lt;ref&gt;{{harvtxt|Korach|Solel|1993}}, Theorem 6, p. 100; {{harvtxt|Bodlaender|1998}}, Corollary 24, p.10.&lt;/ref&gt; Since [[outerplanar graph]]s, [[series-parallel graph]]s, and [[Halin graph]]s all have bounded treewidth, they all also have at most logarithmic pathwidth.

As well as its relations to treewidth, pathwidth is also related to [[clique-width]] and [[cutwidth]], via [[line graph]]s; the line graph ''L''(''G'') of a graph ''G'' has a vertex for each edge of ''G'' and two vertices in ''L''(''G'') are adjacent when the corresponding two edges of ''G'' share an endpoint. Any family of graphs has bounded pathwidth if and only if its line graphs have bounded linear clique-width, where linear clique-width replaces the disjoint union operation from clique-width with the operation of adjoining a single new vertex.&lt;ref&gt;{{harvtxt|Gurski|Wanke|2007}}.&lt;/ref&gt; If a connected graph with three or more vertices has maximum degree three, then its cutwidth equals the vertex separation number of its line graph.&lt;ref&gt;{{harvtxt|Golovach|1993}}.&lt;/ref&gt;

In any [[planar graph]], the pathwidth is at most proportional to the square root of the number of vertices.&lt;ref&gt;{{harvtxt|Bodlaender|1998}}, Corollary 23, p. 10.&lt;/ref&gt; One way to find a path-decomposition with this width is (similarly to the logarithmic-width path-decomposition of forests described above) to use the [[planar separator theorem]] to find a set of O({{radic|''n''}}) vertices the removal of which separates the graph into two subgraphs of at most 2''n''/3 vertices each, and concatenate recursively-constructed path decompositions for each of these two subgraphs. The same technique applies to any class of graphs for which a similar separator theorem holds.&lt;ref&gt;{{harvtxt|Bodlaender|1998}}, Theorem 20, p. 9.&lt;/ref&gt; Since, like planar graphs, the graphs in any fixed minor-closed graph family have separators of size O({{radic|''n''}}),&lt;ref&gt;{{harvtxt|Alon|Seymour|Thomas|1990}}.&lt;/ref&gt; it follows that the pathwidth of the graphs in any fixed minor-closed family is again O({{radic|''n''}}). For some classes of planar graphs, the pathwidth of the graph and the pathwidth of its [[dual graph]] must be within a constant factor of each other: bounds of this form are known for  biconnected outerplanar graphs&lt;ref&gt;{{harvtxt|Bodlaender|Fomin|2002}}; {{harvtxt|Coudert|Huc|Sereni|2007}}.&lt;/ref&gt; and for polyhedral graphs.&lt;ref&gt;{{harvtxt|Fomin|Thilikos|2007}}; {{harvtxt|Amini|Huc|Pérennes|2009}}.&lt;/ref&gt; For 2-connected planar graphs, the pathwidth of the dual graph is less than the pathwidth of the line graph.&lt;ref&gt;{{harvtxt|Fomin|2003}}.&lt;/ref&gt; It remains open whether the pathwidth of a planar graph and its dual are always within a constant factor of each other in the remaining cases.

In some classes of graphs, it has been proven that the pathwidth and treewidth are always equal to each other: this is true for [[cograph]]s,&lt;ref name="bm90"&gt;{{harvtxt|Bodlaender|Möhring|1990}}.&lt;/ref&gt; [[permutation graph]]s,&lt;ref name="bkk93"&gt;{{harvtxt|Bodlaender|Kloks|Kratsch|1993}}.&lt;/ref&gt; the [[complement graph|complements]] of [[comparability graph]]s,&lt;ref name="hm94"&gt;{{harvtxt|Habib|Möhring|1994}}.&lt;/ref&gt; and the comparability graphs of [[interval order]]s.&lt;ref name="g95"&gt;{{harvtxt|Garbe|1995}}.&lt;/ref&gt;

{{unsolved|mathematics|What is the largest possible pathwidth of an &lt;math&gt;n&lt;/math&gt;-vertex [[cubic graph]]?}}
In any [[cubic graph]], or more generally any graph with maximum vertex degree three, the pathwidth is at most ''n''/6&amp;nbsp;+&amp;nbsp;o(''n''), where ''n'' is the number of vertices in the graph. There exist cubic graphs with pathwidth 0.082''n'', but it is not known how to reduce this gap between this [[lower bound]] and the ''n''/6 upper bound.&lt;ref name="fh06"&gt;{{harvtxt|Fomin|Høie|2006}}.&lt;/ref&gt;

==Computing path-decompositions==
It is [[NP-complete]] to determine whether the pathwidth of a given graph is at most ''k'', when ''k'' is a variable given as part of the input.&lt;ref name="npc"&gt;{{harvtxt|Kashiwabara|Fujisawa|1979}}; {{harvtxt|Ohtsuki|Mori|Kuh|Kashiwabara|1979}}; {{harvtxt|Lengauer|1981}}; {{harvtxt|Arnborg|Corneil|Proskurowski|1987}}.&lt;/ref&gt; The best known worst-case time bounds for computing the pathwidth of arbitrary ''n''-vertex graphs are of the form O(2&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;''n''&lt;sup&gt;''c''&lt;/sup&gt;) for some constant&amp;nbsp;''c''.&lt;ref&gt;{{harvtxt|Fomin|Kratsch|Todinca|Villanger|2008}}.&lt;/ref&gt; Nevertheless, several algorithms are known to compute path-decompositions more efficiently when the pathwidth is small, when the class of input graphs is limited, or approximately.

===Fixed-parameter tractability===
Pathwidth is [[fixed-parameter tractable]]: for any constant ''k'', it is possible to test whether the pathwidth is at most ''k'', and if so to find a path-decomposition of width ''k'', in linear time.&lt;ref name="bounded-tw-algs"/&gt; In general, these algorithms operate in two phases. In the first phase, the assumption that the graph has pathwidth ''k'' is used to find a path-decomposition or tree-decomposition that is not optimal, but whose width can be bounded as a function of ''k''. In the second phase, a [[dynamic programming]] algorithm is applied to this decomposition in order to find the optimal decomposition.
However, the time bounds for known algorithms of this type are exponential in ''k''&lt;sup&gt;2&lt;/sup&gt;, impractical except for the smallest values of ''k''.&lt;ref&gt;{{harvtxt|Downey|Fellows|1999}}, p.12.&lt;/ref&gt; For the case ''k''&amp;nbsp;=&amp;nbsp;2 an explicit linear-time algorithm based on a structural decomposition of pathwidth-2 graphs is given by {{harvtxt|de Fluiter|1997}}.

===Special classes of graphs===
{{harvtxt|Bodlaender|1994}} surveys the complexity of computing the pathwidth on various special classes of graphs. Determining whether the pathwidth of a graph ''G'' is at most ''k'' remains NP-complete when ''G'' is restricted to bounded-degree graphs,&lt;ref name="ms88"&gt;{{harvtxt|Monien|Sudborough|1988}}.&lt;/ref&gt; [[planar graph]]s,&lt;ref name="ms88"/&gt; planar graphs of bounded degree,&lt;ref name="ms88"/&gt; [[chordal graph]]s,&lt;ref&gt;{{harvtxt|Gustedt|1993}}.&lt;/ref&gt; chordal dominoes,&lt;ref&gt;{{harvtxt|Kloks|Kratsch|Müller|1995}}. A chordal domino is a chordal graph in which every vertex belongs to at most two maximal cliques.&lt;/ref&gt; the [[complement graph|complements]] of [[comparability graph]]s,&lt;ref name="hm94"/&gt;
and [[bipartite graph|bipartite]] [[distance-hereditary graph]]s.&lt;ref name="kbmk"&gt;{{harvtxt|Kloks|Bodlaender|Müller|Kratsch|1993}}.&lt;/ref&gt; It follows immediately that it is also NP-complete for the graph families that contain the bipartite distance-hereditary graphs, including the bipartite graphs, chordal bipartite graphs, distance-hereditary graphs, and [[circle graph]]s.&lt;ref name="kbmk"/&gt;

However, the pathwidth may be computed in linear time for trees and forests,.&lt;ref name="tree-algs"&gt;{{harvtxt|Möhring|1990}}; {{harvtxt|Scheffler|1990}}; {{harvtxt|Ellis|Sudborough|Turner|1994}}; {{harvtxt|Coudert|Huc|Mazauric|1998}}; {{harvtxt|Peng|Ho|Hsu|Ko|1998}}; {{harvtxt|Skodinis|2000}}; {{harvtxt|Skodinis|2003}}.&lt;/ref&gt; It may also be computed in polynomial time for graphs of bounded treewidth including [[series-parallel graph]]s, [[outerplanar graph]]s, and [[Halin graph]]s,&lt;ref name="bounded-tw-algs"&gt;{{harvtxt|Bodlaender|1996}}; {{harvtxt|Bodlaender|Kloks|1996}}&lt;/ref&gt; as well as for [[split graph]]s,&lt;ref&gt;{{harvtxt|Kloks|Bodlaender|1992}}; {{harvtxt|Gustedt|1993}}.&lt;/ref&gt; for the complements of chordal graphs,&lt;ref&gt;{{harvtxt|Garbe|1995}} credits this result to the 1993 Ph.D. thesis of Ton Kloks; Garbe's polynomial time algorithm for comparability graphs of interval orders generalizes this result, since any chordal graph must be a comparability graph of this type.&lt;/ref&gt; for [[permutation graph]]s,&lt;ref name="bkk93"/&gt; for [[cograph]]s,&lt;ref name="bm90"/&gt; for [[circular-arc graph]]s,&lt;ref&gt;{{harvtxt|Suchan|Todinca|2007}}.&lt;/ref&gt; for the comparability graphs of interval orders,&lt;ref name="g95"/&gt; and of course for [[interval graph]]s themselves, since in that case the pathwidth is just one less than the maximum number of intervals covering any point in an interval representation of the graph.

===Approximation algorithms===
It is NP-hard to approximate the pathwidth of a graph to within an additive constant.&lt;ref name="bghk92"/&gt;
The best known [[approximation ratio]] of a polynomial time approximation algorithm for pathwidth is O((log&amp;nbsp;''n'')&lt;sup&gt;3/2&lt;/sup&gt;).&lt;ref&gt;{{harvtxt|Feige|Hajiaghayi|Lee|2005}}.&lt;/ref&gt;
For earlier approximation algorithms for pathwidth, see {{harvtxt|Bodlaender|Gilbert|Hafsteinsson|Kloks|1992}} and {{harvtxt|Guha|2000}}. For approximations on restricted classes of graphs, see {{harvtxt|Kloks|Bodlaender|1992}}.

==Graph minors==
A [[graph minor|minor]] of a graph ''G'' is another graph formed from ''G'' by contracting edges, removing edges, and removing vertices. Graph minors have a deep theory in which several important results involve pathwidth.

===Excluding a forest===
If a family ''F'' of graphs is closed under taking minors (every minor of a member of ''F'' is also in ''F''), then by the [[Robertson–Seymour theorem]] ''F'' can be characterized as the graphs that do not have any minor in ''X'', where ''X'' is a finite set of [[Forbidden graph characterization|forbidden minors]].&lt;ref name="gm20"&gt;{{harvtxt|Robertson|Seymour|2004}}.&lt;/ref&gt; For instance, [[Wagner's theorem]] states that the [[planar graph]]s are the graphs that have neither the [[complete graph]] ''K''&lt;sub&gt;5&lt;/sub&gt; nor the [[complete bipartite graph]] ''K''&lt;sub&gt;3,3&lt;/sub&gt; as minors. In many cases, the properties of ''F'' and the properties of ''X'' are closely related, and the first such result of this type was by {{harvtxt|Robertson|Seymour|1983}},&lt;ref name="rs83"/&gt; and relates bounded pathwidth with the existence of a [[tree (graph theory)|forest]] in the family of forbidden minors. Specifically, define a family ''F'' of graphs to have ''bounded pathwidth'' if there exists a constant ''p'' such that every graph in ''F'' has pathwidth at most ''p''. Then, a minor-closed family ''F'' has bounded pathwidth if and only if the set ''X'' of forbidden minors for ''F'' includes at least one forest.

In one direction, this result is straightforward to prove: if ''X'' does not include at least one forest, then the ''X''-minor-free graphs do not have bounded pathwidth. For, in this case, the ''X''-minor-free graphs include all forests, and in particular they include the [[perfect binary tree]]s. But a perfect binary tree with 2''k''&amp;nbsp;+&amp;nbsp;1 levels has pathwidth ''k'', so in this case the ''X''-minor-free-graphs have unbounded pathwidth. In the other direction, if ''X'' contains an ''n''-vertex forest, then the ''X''-minor-free graphs have pathwidth at most ''n''&amp;nbsp;−&amp;nbsp;2.&lt;ref&gt;{{harvtxt|Bienstock|Robertson|Seymour|Thomas|1991}}; {{harvtxt|Diestel|1995}}; {{harvtxt|Cattell|Dinneen|Fellows|1996}}.&lt;/ref&gt;

===Obstructions to bounded pathwidth===
[[File:Pathwidth-1 obstructions.svg|thumb|The forbidden minors for graphs of pathwidth&amp;nbsp;1.]]
The property of having pathwidth at most ''p'' is, itself, closed under taking minors: if ''G'' has a path-decomposition with width at most ''p'', then the same path-decomposition remains valid if any edge is removed from ''G'', and any vertex can be removed from ''G'' and from its path-decomposition without increasing the width. Contraction of an edge, also, can be accomplished without increasing the width of the decomposition, by merging the sub-paths representing the two endpoints of the contracted edge. Therefore, the graphs of pathwidth at most ''p'' can be characterized by a set ''X&lt;sub&gt;p&lt;/sub&gt;'' of excluded minors.&lt;ref name="gm20"/&gt;&lt;ref name="obstructions"&gt;{{harvtxt|Kinnersley|1992}}; {{harvtxt|Takahashi|Ueno|Kajitani|1994}}; {{harvtxt|Bodlaender|1998}}, p. 8.&lt;/ref&gt;

Although ''X&lt;sub&gt;p&lt;/sub&gt;'' necessarily includes at least one forest, it is not true that all graphs in ''X&lt;sub&gt;p&lt;/sub&gt;'' are forests: for instance, ''X''&lt;sub&gt;1&lt;/sub&gt; consists of two graphs, a seven-vertex tree and the triangle ''K''&lt;sub&gt;3&lt;/sub&gt;. However, the set of trees in ''X&lt;sub&gt;p&lt;/sub&gt;'' may be precisely characterized: these trees are exactly the trees that can be formed from three trees in ''X''&lt;sub&gt;''p''&amp;nbsp;−&amp;nbsp;1&lt;/sub&gt; by connecting a new root vertex by an edge to an arbitrarily chosen vertex in each of the three smaller trees. For instance, the seven-vertex tree in ''X''&lt;sub&gt;1&lt;/sub&gt; is formed in this way from the two-vertex tree (a single edge) in ''X''&lt;sub&gt;0&lt;/sub&gt;. Based on this construction, the number of forbidden minors in ''X''&lt;sub&gt;''p''&lt;/sub&gt; can be shown to be at least (''p''!)&lt;sup&gt;2&lt;/sup&gt;.&lt;ref name="obstructions"/&gt; The complete set ''X''&lt;sub&gt;2&lt;/sub&gt; of forbidden minors for pathwidth-2 graphs has been computed; it contains 110 different graphs.&lt;ref&gt;{{harvtxt|Kinnersley|Langston|1994}}.&lt;/ref&gt;

===Structure theory===
The [[graph structure theorem]] for minor-closed graph families states that, for any such family ''F'', the graphs in ''F'' can be decomposed into [[clique-sum]]s of graphs that can be [[Graph embedding|embedded]] onto surfaces of bounded [[Genus (mathematics)|genus]], together with a bounded number of apexes and vortices for each component of the clique-sum. An apex is a vertex that may be adjacent to any other vertex in its component, while a vortex is a graph of bounded pathwidth that is glued into one of the faces of the bounded-genus embedding of a component. The cyclic ordering of the vertices around the face into which a vortex is embedded must be compatible with the path decomposition of the vortex, in the sense that breaking the cycle to form a linear ordering must lead to an ordering with bounded vertex separation number.&lt;ref name="Robertson 2003"/&gt; This theory, in which pathwidth is intimately connected to arbitrary minor-closed graph families, has important algorithmic applications.&lt;ref&gt;{{harvtxt|Demaine|Hajiaghayi|Kawarabayashi|2005}}.&lt;/ref&gt;

==Applications==

===VLSI===
In [[VLSI]] design, the vertex separation problem was originally studied as a way to partition circuits into smaller subsystems, with a small number of components on the boundary between the subsystems.&lt;ref name="ms88"/&gt;

{{harvtxt|Ohtsuki|Mori|Kuh|Kashiwabara|1979}} use interval thickness to model the number of tracks needed in a one-dimensional layout of a VLSI circuit, formed by a set of modules that need to be interconnected by a system of nets. In their model, one forms a graph in which the vertices represent nets, and in which two vertices are connected by an edge if their nets both connect to the same module; that is, if the modules and nets are interpreted as forming the nodes and hyperedges of a [[hypergraph]] then the graph formed from them is its [[Line graph of a hypergraph|line graph]]. An interval representation of a supergraph of this line graph, together with a [[graph coloring|coloring]] of the supergraph, describes an arrangement of the nets along a system of horizontal tracks (one track per color) in such a way that the modules can be placed along the tracks in a linear order and connect to the appropriate nets. The fact that interval graphs are [[perfect graph]]s&lt;ref&gt;{{harvtxt|Berge|1967}}.&lt;/ref&gt; implies that the number of colors needed, in an optimal arrangement of this type, is the same as the clique number of the interval completion of the net graph.

Gate matrix layout&lt;ref&gt;{{harvtxt|Lopez|Law|1980}}.&lt;/ref&gt; is a specific style of [[CMOS]] VLSI layout for [[Boolean logic]] circuits. In gate matrix layouts, signals are propagated along "lines" (vertical line segments) while each gate of the circuit is formed by a sequence of device features that lie along a horizontal line segment. Thus, the horizontal line segment for each gate must cross the vertical segments for each of the lines that form inputs or outputs of the gate. As in the layouts of {{harvtxt|Ohtsuki|Mori|Kuh|Kashiwabara|1979}}, a layout of this type that minimizes the number of vertical tracks on which the lines are to be arranged can be found by computing the pathwidth of a graph that has the lines as its vertices and pairs of lines sharing a gate as its edges.&lt;ref name="fl89"&gt;{{harvtxt|Fellows|Langston|1989}}.&lt;/ref&gt; The same algorithmic approach can also be used to model folding problems in [[programmable logic array]]s.&lt;ref&gt;{{harvtxt|Möhring|1990}}; {{harvtxt|Ferreira|Song|1992}}.&lt;/ref&gt;

===Graph drawing===
Pathwidth has several applications to [[graph drawing]]:
*The minimal graphs that have a given [[crossing number (graph theory)|crossing number]] have pathwidth that is bounded by a function of their crossing number.&lt;ref name="h03"&gt;{{harvtxt|Hliněny|2003}}.&lt;/ref&gt;
*The number of parallel lines on which the vertices of a tree can be drawn with no edge crossings (under various natural restrictions on the ways that adjacent vertices can be placed with respect to the sequence of lines) is proportional to the pathwidth of the tree.&lt;ref&gt;{{harvtxt|Suderman|2004}}.&lt;/ref&gt;
*A ''k''-crossing ''h''-layer drawing of a graph ''G'' is a placement of the vertices of ''G'' onto ''h'' distinct horizontal lines, with edges routed as monotonic polygonal paths between these lines, in such a way that there are at most ''k'' crossings. The graphs with such drawings have pathwidth that is bounded by a function of ''h'' and ''k''. Therefore, when ''h'' and ''k'' are both constant, it is possible in linear time to determine whether a graph has a ''k''-crossing ''h''-layer drawing.&lt;ref name="dfkl08"&gt;{{harvtxt|Dujmović|Fellows|Kitching|Liotta|2008}}.&lt;/ref&gt;
*A graph with ''n'' vertices and pathwidth ''p'' can be embedded into a three-dimensional grid of size {{nowrap|''p'' × ''p'' × ''n''}} in such a way that no two edges (represented as straight line segments between grid points) intersect each other. Thus, graphs of bounded pathwidth have embeddings of this type with linear volume.&lt;ref&gt;{{harvtxt|Dujmović|Morin|Wood|2003}}.&lt;/ref&gt;

===Compiler design===
In the [[compiler|compilation]] of [[high-level programming language]]s, pathwidth arises in the problem of reordering sequences of straight-line code (that is, code with no [[control flow]] branches or loops) in such a way that all the values computed in the code can be [[Register allocation|placed in machine registers]] instead of having to be spilled into main memory. In this application, one represents the code to be compiled as a [[directed acyclic graph]] in which the nodes represent the input values to the code and the values computed by the operations within the code. An edge from node ''x'' to node ''y'' in this DAG represents the fact that value ''x'' is one of the inputs to operation ''y''. A [[topological ordering]] of the vertices of this DAG represents a valid reordering of the code, and the number of registers needed to evaluate the code in a given ordering is given by the vertex separation number of the ordering.&lt;ref name="bgt98"&gt;{{harvtxt|Bodlaender|Gustedt|Telle|1998}}.&lt;/ref&gt;

For any fixed number ''w'' of machine registers, it is possible to determine in linear time whether a piece of straight-line code can be reordered in such a way that it can be evaluated with at most ''w'' registers. For, if the vertex separation number of a topological ordering is at most ''w'', the minimum vertex separation among all orderings can be no larger, so the undirected graph formed by ignoring the orientations of the DAG described above must have pathwith at most ''w''. It is possible to test whether this is the case, using the known fixed-parameter-tractable algorithms for pathwidth, and if so to find a path-decomposition for the undirected graph, in linear time given the assumption that ''w'' is a constant. Once a path decomposition has been found, a topological ordering of width ''w'' (if one exists) can be found using dynamic programming, again in linear time.&lt;ref name="bgt98"/&gt;

===Linguistics===
{{harvtxt|Kornai|Tuza|1992}} describe an application of path-width in [[natural language processing]]. In this application, sentences are modeled as graphs, in which the vertices represent words and the edges represent relationships between words; for instance if an adjective modifies a noun in the sentence then the graph would have an edge between those two words. Due to the limited capacity of human short-term memory,&lt;ref&gt;{{harvtxt|Miller|1956}}.&lt;/ref&gt; Kornai and Tuza argue that this graph must have bounded pathwidth (more specifically, they argue, pathwidth at most six), for otherwise humans would not be able to parse speech correctly.

===Exponential algorithms===
Many problems in graph algorithms may be solved efficiently on graphs of low pathwidth, by using [[dynamic programming]] on a path-decomposition of the graph.&lt;ref name="Arnborg 1985"/&gt; For instance, if a linear ordering of the vertices of an ''n''-vertex graph ''G'' is given, with vertex separation number ''w'', then it is possible to find the maximum independent set of ''G'' in time {{nowrap|O(2&lt;sup&gt;''w''&lt;/sup&gt; ''n'').}}&lt;ref name="fh06"/&gt; On graphs of bounded pathwidth, this approach leads to fixed-parameter tractable algorithms, parametrized by the pathwidth.&lt;ref name="fl89"/&gt; Such results are not frequently found in the literature because they are subsumed by similar algorithms parametrized by the treewidth; however, pathwidth arises even in treewidth-based dynamic programming algorithms in measuring the [[space complexity]] of these algorithms.&lt;ref name="apt00"/&gt;

The same dynamic programming method also can be applied to graphs with unbounded pathwidth, leading to algorithms that solve unparametrized graph problems in [[exponential time]]. For instance, combining this dynamic programming approach with the fact that cubic graphs have pathwidth ''n''/6&amp;nbsp;+&amp;nbsp;o(''n'') shows that, in a cubic graph, the maximum independent set can be constructed in time O(2&lt;sup&gt;''n''/6&amp;nbsp;+&amp;nbsp;o(''n'')&lt;/sup&gt;), faster than previous known methods.&lt;ref name="fh06"/&gt; A similar approach leads to improved exponential-time algorithms for the [[maximum cut]] and [[minimum dominating set]] problems in cubic graphs,&lt;ref name="fh06"/&gt; and for several other NP-hard optimization problems.&lt;ref&gt;{{harvtxt|Kneis|Mölle|Richter|Rossmanith|2005}}; {{harvtxt|Björklund|Husfeldt|2008}}.&lt;/ref&gt;

==See also==
*[[Boxicity]], a different way of measuring the complexity of an arbitrary graph in terms of interval graphs
*[[Tree-depth]], a number that is bounded for a minor-closed graph family if and only if the family excludes a path
*[[Degeneracy (graph theory)|Degeneracy]], a measure of the sparsity of a graph that is at most equal to its path width
*[[Graph bandwidth]], a different NP-complete optimization problem involving linear layouts of graphs
*[[Strahler number]], a measure of the complexity of rooted trees defined similarly to pathwidth of unrooted trees

==Notes==
{{reflist|30em}}

==References==
{{refbegin|30em}}
*{{citation
 | last1 = Alon | first1 = Noga | author1-link = Noga Alon
 | last2 = Seymour | first2 = Paul | author2-link = Paul Seymour (mathematician)
 | last3 = Thomas | first3 = Robin | author3-link = Robin Thomas (mathematician)
 | contribution = A separator theorem for graphs with an excluded minor and its applications
 | doi = 10.1145/100216.100254
 | pages = 293–299
 | title = Proc. 22nd ACM Symp. on Theory of Computing (STOC 1990)
 | year = 1990| isbn = 0897913612 }}.
*{{citation
 | last1 = Amini | first1 = Omid
 | last2 = Huc | first2 = Florian
 | last3 = Pérennes | first3 = Stéphane
 | doi = 10.1137/060670146
 | issue = 3
 | journal = [[SIAM Journal on Discrete Mathematics]]
 | pages = 1311–1316
 | title = On the path-width of planar graphs
 | volume = 23
 | year = 2009}}.
*{{citation
 | last = Arnborg | first = Stefan
 | doi = 10.1007/BF01934985
 | issue = 1
 | journal = BIT
 | pages = 2–23
 | title = Efficient algorithms for combinatorial problems on graphs with bounded decomposability – A survey
 | volume = 25
 | year = 1985}}.
*{{citation
 | last1 = Arnborg | first1 = Stefan
 | last2 = Corneil | first2 = Derek G. | author2-link = Derek Corneil
 | last3 = Proskurowski | first3 = Andrzej
 | doi = 10.1137/0608024
 | issue = 2
 | journal = SIAM Journal on Algebraic and Discrete Methods
 | pages = 277–284
 | title = Complexity of finding embeddings in a $k$-tree
 | volume = 8
 | year = 1987}}.
*{{citation
 | last1 = Aspvall | first1 = Bengt
 | last2 = Proskurowski | first2 = Andrzej
 | last3 = Telle | first3 = Jan Arne
 | doi = 10.1007/s004530010025
 | journal = [[Algorithmica]]
 | pages = 382–394
 | title = Memory requirements for table computations in partial ''k''-tree algorithms
 | volume = 27
 | year = 2000
 | issue = 3}}.
*{{citation
 | last = Berge | first = Claude | author-link = Claude Berge
 | contribution = Some classes of perfect graphs
 | location = New York
 | pages = 155–165
 | publisher = Academic Press
 | title = Graph Theory and Theoretical Physics
 | year = 1967}}.
*{{citation
 | last1 = Bienstock | first1 = Dan
 | last2 = Robertson | first2 = Neil | author2-link = Neil Robertson (mathematician)
 | last3 = Seymour | first3 = Paul | author3-link = Paul Seymour (mathematician)
 | last4 = Thomas | first4 = Robin | author4-link = Robin Thomas (mathematician)
 | doi = 10.1016/0095-8956(91)90068-U
 | issue = 2
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | pages = 274–283
 | title = Quickly excluding a forest
 | volume = 52
 | year = 1991}}.
*{{citation
 | last1 = Björklund | first1 = Andreas
 | last2 = Husfeldt | first2 = Thore
 | doi = 10.1007/s00453-007-9149-8
 | issue = 2
 | journal = [[Algorithmica]]
 | pages = 226–249
 | title = Exact algorithms for exact satisfiability and number of perfect matchings
 | volume = 52
 | year = 2008}}.
*{{citation
 | last = Bodlaender | first = Hans L. | authorlink = Hans L. Bodlaender
 | contribution = A tourist guide through treewidth
 | editor1-last = Dassow | editor1-first = Jürgen
 | editor2-last = Kelemenová | editor2-first = Alisa
 | pages = 1–20
 | publisher = Gordon and Breach
 | series = Topics in Computer Mathematics
 | title = Developments in Theoretical Computer Science (Proc. 7th International Meeting of Young Computer Scientists, Smolenice, 16–20 November 1992)
 | volume = 6
 | year = 1994}}.
*{{citation
 | last = Bodlaender | first = Hans L. | authorlink = Hans L. Bodlaender
 | doi = 10.1137/S0097539793251219
 | issue = 6
 | journal = [[SIAM Journal on Computing]]
 | pages = 1305–1317
 | title = A linear-time algorithm for finding tree-decompositions of small treewidth
 | volume = 25
 | year = 1996}}.
*{{citation
 | last = Bodlaender | first = Hans L. | authorlink = Hans L. Bodlaender
 | doi = 10.1016/S0304-3975(97)00228-4
 | issue = 1–2
 | journal = [[Theoretical Computer Science (journal)|Theoretical Computer Science]]
 | pages = 1–45
 | title = A partial ''k''-arboretum of graphs with bounded treewidth
 | volume = 209
 | year = 1998}}.
*{{citation
 | last1 = Bodlaender | first1 = Hans L. | author1-link = Hans L. Bodlaender
 | last2 = Fomin | first2 = Fedor V.
 | doi = 10.1016/S0196-6774(02)00001-9
 | issue = 2
 | journal = Journal of Algorithms
 | pages = 190–200
 | title = Approximation of pathwidth of outerplanar graphs
 | volume = 43
 | year = 2002}}.
*{{citation
 | last1 = Bodlaender | first1 = Hans L. | author1-link = Hans L. Bodlaender
 | last2 = Gilbert | first2 = John R.
 | last3 = Hafsteinsson | first3 = Hjálmtýr
 | last4 = Kloks | first4 = Ton
 | contribution = Approximating treewidth, pathwidth, and minimum elimination tree height
 | doi = 10.1007/3-540-55121-2_1
 | pages = 1–12
 | series = [[Lecture Notes in Computer Science]]
 | title = Graph-Theoretic Concepts in Computer Science
 | volume = 570
 | year = 1992| isbn = 978-3-540-55121-8 }}.
*{{citation
 | last1 = Bodlaender | first1 = Hans L. | author1-link = Hans L. Bodlaender
 | last2 = Gustedt | first2 = Jens
 | last3 = Telle | first3 = Jan Arne
 | contribution = Linear-time register allocation for a fixed number of registers
 | pages = 574–583
 | title = Proc. 9th ACM–SIAM Symposium on Discrete Algorithms (SODA '98)
 | url = http://www.ii.uib.no/~telle/bib/BGT.pdf
 | year = 1998}}.
*{{citation
 | last1 = Bodlaender | first1 = Hans L. | author1-link = Hans L. Bodlaender
 | last2 = Kloks | first2 = Ton
 | doi = 10.1006/jagm.1996.0049
 | issue = 2
 | journal = Journal of Algorithms
 | pages = 358–402
 | title = Efficient and constructive algorithms for the pathwidth and treewidth of graphs
 | volume = 21
 | year = 1996}}.
*{{citation
 | last1 = Bodlaender | first1 = Hans L. | author1-link = Hans L. Bodlaender
 | last2 = Kloks | first2 = Ton
 | last3 = Kratsch | first3 = Dieter
 | contribution = Treewidth and pathwidth of permutation graphs
 | doi = 10.1007/3-540-56939-1_66
 | pages = 114–125
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = [[International Colloquium on Automata, Languages and Programming|Proc. 20th International Colloquium on Automata, Languages and Programming (ICALP 1993)]]
 | volume = 700
 | year = 1993| isbn = 978-3-540-56939-8 }}.
*{{citation
 | last1 = Bodlaender | first1 = Hans L. | author1-link = Hans L. Bodlaender
 | last2 = Möhring | first2 = Rolf H.
 | contribution = The pathwidth and treewidth of cographs
 | doi = 10.1007/3-540-52846-6_99
 | title = [[SWAT and WADS conferences|Proc. 2nd Scandinavian Workshop on Algorithm Theory]]
 | pages = 301–309
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | volume = 447
 | year = 1990| isbn = 978-3-540-52846-3 }}.
*{{citation
 | last1 = Cattell | first1 = Kevin
 | last2 = Dinneen | first2 = Michael J.
 | last3 = Fellows | first3 = Michael R. | author3-link = Michael Fellows
 | doi = 10.1016/0020-0190(95)00190-5
 | issue = 4
 | journal = [[Information Processing Letters]]
 | pages = 197–203
 | title = A simple linear-time algorithm for finding path-decompositions of small width
 | volume = 57
 | year = 1996| arxiv = math/9410211}}.
*{{citation
 | last1 = Coudert | first1 = David
 | last2 = Huc | first2 = Florian
 | last3 = Mazauric | first3 = Dorian
 | contribution = A distributed algorithm for computing and updating the process number of a forest
 | doi = 10.1007/978-3-540-87779-0_36
 | pages = 500–501
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = Proc. 22nd Int. Symp. Distributed Computing
 | volume = 5218
 | year = 1998
 | arxiv = 0806.2710| isbn = 978-3-540-87778-3
 }}.
*{{citation
 | last1 = Coudert | first1 = David
 | last2 = Huc | first2 = Florian
 | last3 = Sereni | first3 = Jean-Sébastien
 | doi = 10.1002/jgt.20218
 | issue = 1
 | journal = [[Journal of Graph Theory]]
 | pages = 27–41
 | title = Pathwidth of outerplanar graphs
 | volume = 55
 | year = 2007}}.
*{{citation
 | last = Diestel | first = Reinhard
 | doi = 10.1017/S0963548300001450
 | issue = 1
 | journal = [[Combinatorics, Probability and Computing]]
 | pages = 27–30
 | title = Graph Minors I: a short proof of the path-width theorem
 | volume = 4
 | year = 1995}}.
*{{citation
 | last1 = Diestel | first1 = Reinhard
 | last2 = Kühn | first2 = Daniela | author2-link = Daniela Kühn
 | doi = 10.1016/j.dam.2004.01.010
 | issue = 2
 | journal = [[Discrete Applied Mathematics]]
 | pages = 167–182
 | title = Graph minor hierarchies
 | volume = 145
 | year = 2005}}.
*{{citation
 | last1 = Demaine | first1 = Erik D. | author1-link = Erik Demaine
 | last2 = Hajiaghayi | first2 = MohammadTaghi | author2-link = Mohammad Hajiaghayi
 | last3 = Kawarabayashi | first3 = Ken-ichi | author3-link = Ken-ichi Kawarabayashi
 | contribution = Algorithmic graph minor theory: decomposition, approximation, and coloring
 | doi = 10.1109/SFCS.2005.14
 | pages = 637–646
 | title = [[Symposium on Foundations of Computer Science|Proc. 46th IEEE Symposium on Foundations of Computer Science (FOCS 2005)]]
 | year = 2005| isbn = 0-7695-2468-0 }}.
*{{citation
 | last1 = Downey | first1 = Rod G. | author1-link = Rod Downey
 | last2 = Fellows | first2 = Michael R. | author2-link = Michael Fellows
 | isbn = 0-387-94883-X
 | publisher = Springer-Verlag
 | title = Parameterized Complexity
 | year = 1999}}.
*{{citation
 | last1 = Dujmović | first1 = V.
 | last2 = Fellows | first2 = M.R. | author2-link = Michael Fellows
 | last3 = Kitching | first3 = M.
 | last4 = Liotta | first4 = G.
 | last5 = McCartin | first5 = C.
 | last6 = Nishimura | first6 = N.
 | last7 = Ragde | first7 = P.
 | last8 = Rosamond | first8 = F.
 | last9 = Whitesides | first9 = S. | author9-link = Sue Whitesides
 | last10 = Wood
 | first10 = David R.
 | doi = 10.1007/s00453-007-9151-1
 | issue = 2
 | journal = [[Algorithmica]]
 | pages = 267–292
 | title = On the parameterized complexity of layered graph drawing
 | volume = 52
 | year = 2008
 }}.
*{{citation
 | last1 = Dujmović | first1 = Vida
 | last2 = Morin | first2 = Pat
 | last3 = Wood | first3 = David R.
 | contribution = Path-width and three-dimensional straight-line grid drawings of graphs
 | pages = 42–53
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = [[International Symposium on Graph Drawing|Proc. 10th International Symposium on Graph Drawing (GD 2002)]]
 | contribution-url = http://cg.scs.carleton.ca/~vida/pubs/papers/DMW-GD02.pdf
 | volume = 2528
 | year = 2003}}.
*{{citation
 | last1 = Ellis | first1 = J. A.
 | last2 = Sudborough | first2 = I. H.
 | last3 = Turner | first3 = J. S.
 | contribution = Graph separation and search number
 | title = Proc. 1983 Allerton Conf. on Communication, Control, and Computing
 | year = 1983}}. As cited by {{harvtxt|Monien|Sudborough|1988}}.
*{{citation
 | last1 = Ellis | first1 = J. A.
 | last2 = Sudborough | first2 = I. H.
 | last3 = Turner | first3 = J. S.
 | doi = 10.1006/inco.1994.1064
 | issue = 1
 | journal = [[Information and Computation]]
 | pages = 50–79
 | title = The vertex separation and search number of a tree
 | volume = 113
 | year = 1994}}.
*{{citation
 | last1 = Feige | first1 = Uriel | author1-link = Uriel Feige
 | last2 = Hajiaghayi | first2 = Mohammadtaghi | author2-link = Mohammad Hajiaghayi
 | last3 = Lee | first3 = James R.
 | contribution = Improved approximation algorithms for minimum-weight vertex separators
 | doi = 10.1145/1060590.1060674
 | pages = 563–572
 | title = [[Symposium on Theory of Computing|Proc. 37th ACM Symposium on Theory of Computing (STOC 2005)]]
 | year = 2005| isbn = 1581139608 }}.
*{{citation
 | last1 = Fellows | first1 = Michael R. | author1-link = Michael Fellows
 | last2 = Langston | first2 = Michael A. | author2-link = Michael Langston
 | contribution = On search decision and the efficiency of polynomial-time algorithms
 | doi = 10.1145/73007.73055
 | pages = 501–512
 | title = [[Symposium on Theory of Computing|Proc. 21st ACM Symposium on Theory of Computing]]
 | year = 1989| isbn = 0897913078 }}.
*{{citation
 | last1 = Ferreira | first1 = Afonso G.
 | last2 = Song | first2 = Siang W.
 | contribution = Achieving optimality for gate matrix layout and PLA folding: a graph theoretic approach
 | doi = 10.1007/BFb0023825
 | pages = 139–153
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = Proc. 1st Latin American Symposium on Theoretical Informatics (LATIN '92)
 | volume = 583
 | year = 1992| isbn = 3-540-55284-7
 }}.
*{{citation
 | last = de Fluiter | first = Babette
 | isbn = 90-393-1528-0
 | publisher = [[Utrecht University]]
 | series = Ph.D. thesis
 | title = Algorithms for Graphs of Small Treewidth
 | url = http://igitur-archive.library.uu.nl/dissertations/01847381/full.pdf
 | year = 1997}}.
*{{citation
 | last = Fomin | first = Fedor V.
 | doi = 10.1007/s00373-002-0490-z
 | issue = 1
 | journal = [[Graphs and Combinatorics]]
 | pages = 91–99
 | title = Pathwidth of planar and line graphs
 | volume = 19
 | year = 2003}}.
*{{citation
 | last1 = Fomin | first1 = Fedor V.
 | last2 = Høie | first2 = Kjartan
 | doi = 10.1016/j.ipl.2005.10.012
 | issue = 5
 | journal = [[Information Processing Letters]]
 | pages = 191–196
 | title = Pathwidth of cubic graphs and exact algorithms
 | volume = 97
 | year = 2006}}.
*{{citation
 | last1 = Fomin | first1 = Fedor V.
 | last2 = Kratsch | first2 = Dieter
 | last3 = Todinca | first3 = Ioan
 | last4 = Villanger | first4 = Yngve
 | doi = 10.1137/050643350
 | issue = 3
 | journal = [[SIAM Journal on Computing]]
 | pages = 1058–1079
 | title = Exact algorithms for treewidth and minimum fill-in
 | volume = 38
 | year = 2008}}.
*{{citation
 | last1 = Fomin | first1 = Fedor V.
 | last2 = Thilikos | first2 = Dimitrios M.
 | doi = 10.1002/jgt.20219
 | issue = 1
 | journal = [[Journal of Graph Theory]]
 | pages = 42–54
 | title = On self duality of pathwidth in polyhedral graph embeddings
 | volume = 55
 | year = 2007}}.
*{{citation
 | last = Garbe | first = Renate
 | contribution = Tree-width and path-width of comparability graphs of interval orders
 | doi = 10.1007/3-540-59071-4_35
 | pages = 26–37
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = Proc. 20th International Workshop Graph-Theoretic Concepts in Computer Science (WG'94)
 | volume = 903
 | year = 1995| isbn = 978-3-540-59071-2
 }}.
*{{citation
 | last = Golovach | first = P. A.
 | doi = 10.1515/dma.1993.3.5.517
 | issue = 5
 | journal = Discrete Mathematics and Applications
 | pages = 517–522
 | title = The cutwidth of a graph and the vertex separation number of the line graph
 | volume = 3
 | year = 1993}}.
*{{citation
 | last = Guha | first = Sudipto
 | doi = 10.1109/SFCS.2000.892072
 | title = [[Symposium on Foundations of Computer Science|Proc. 41st IEEE Symposium on Foundations of Computer Science (FOCS 2000)]]
 | page = 126
 | contribution = Nested graph dissection and approximation algorithms
 | year = 2000| isbn = 0-7695-0850-2
 }}.
*{{citation
 | last1 = Gurski | first1 = Frank
 | last2 = Wanke | first2 = Egon
 | doi = 10.1016/j.disc.2007.01.020
 | issue = 22
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 2734–2754
 | title = Line graphs of bounded clique-width
 | volume = 307
 | year = 2007}}.
*{{citation
 | last = Gustedt | first = Jens
 | doi = 10.1016/0166-218X(93)90012-D
 | issue = 3
 | journal = [[Discrete Applied Mathematics]]
 | pages = 233–248
 | title = On the pathwidth of chordal graphs
 | volume = 45
 | year = 1993}}.
*{{citation
 | last1 = Habib | first1 = Michel
 | last2 = Möhring | first2 = Rolf H.
 | doi = 10.1007/BF01462229
 | issue = 1
 | journal = [[Order (journal)|Order]]
 | pages = 47–60
 | title = Treewidth of cocomparability graphs and a new order-theoretic parameter
 | volume = 11
 | year = 1994}}.
*{{citation
 | last = Hliněny | first = Petr
 | doi = 10.1016/S0095-8956(03)00037-6
 | issue = 2
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | pages = 347–367
 | title = Crossing-number critical graphs have bounded path-width
 | volume = 88
 | year = 2003}}.
*{{citation
 | last1 = Kashiwabara | first1 = T.
 | last2 = Fujisawa | first2 = T.
 | contribution = NP-completeness of the problem of finding a minimum-clique-number interval graph containing a given graph as a subgraph
 | pages = 657–660
 | title = [[International Symposium on Circuits and Systems|Proc. International Symposium on Circuits and Systems]]
 | year = 1979}}.
*{{citation
 | last = Kinnersley | first = Nancy G.
 | doi = 10.1016/0020-0190(92)90234-M
 | issue = 6
 | journal = [[Information Processing Letters]]
 | pages = 345–350
 | title = The vertex separation number of a graph equals its path-width
 | volume = 42
 | year = 1992}}.
*{{citation
 | last1 = Kinnersley | first1 = Nancy G.
 | last2 = Langston | first2 = Michael A. | author2-link = Michael Langston
 | doi = 10.1016/0166-218X(94)90021-3
 | issue = 2–3
 | journal = [[Discrete Applied Mathematics]]
 | pages = 169–213
 | title = Obstruction set isolation for the gate matrix layout problem
 | volume = 54
 | year = 1994}}.
*{{citation
 |last1        = Kirousis
 |first1       = Lefteris M.
 |last2        = Papadimitriou
 |first2       = Christos H.
 |author2-link = Christos Papadimitriou
 |doi          = 10.1016/0012-365X(85)90046-9
 |issue        = 2
 |journal      = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 |pages        = 181–184
 |title        = Interval graphs and searching
 |url          = http://lca.ceid.upatras.gr/~kirousis/publications/j31.pdf
 |archive-url  = https://web.archive.org/web/20110721084127/http://lca.ceid.upatras.gr/~kirousis/publications/j31.pdf
 |dead-url     = yes
 |archive-date = 2011-07-21
 |volume       = 55
 |year         = 1985
}}.
*{{citation
 | last1 = Kloks | first1 = Ton
 | last2 = Bodlaender | first2 = Hans L. | author2-link = Hans L. Bodlaender
 | contribution = Approximating treewidth and pathwidth of some classes of perfect graphs
 | doi = 10.1007/3-540-56279-6_64
 | pages = 116–125
 | publisher = Springer-Verlag
 | title = Proc. 3rd International Symposium on Algorithms and Computation (ISAAC'92)
 | series = Lecture Notes in Computer Science
 | year = 1992
 | volume = 650| isbn = 978-3-540-56279-5
 }}.
*{{citation
 | last1 = Kloks | first1 = T.
 | last2 = Bodlaender | first2 = H. | author2-link = Hans L. Bodlaender
 | last3 = Müller | first3 = H.
 | last4 = Kratsch | first4 = D.
 | contribution = Computing treewidth and minimum fill-in: all you need are the minimal separators
 | doi = 10.1007/3-540-57273-2_61
 | pages = 260–271
 | publisher = Springer-Verlag
 | title = [[European Symposium on Algorithms|Proc. 1st European Symposium on Algorithms (ESA'93)]] (Lecture Notes in Computer Science)
 | volume = 726
 | year = 1993
 }}.
*{{citation
 | last1 = Kloks | first1 = Ton
 | last2 = Kratsch | first2 = Dieter
 | last3 = Müller | first3 = H.
 | contribution = Dominoes
 | doi = 10.1007/3-540-59071-4_41
 | pages = 106–120
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = Proc. 20th International Workshop Graph-Theoretic Concepts in Computer Science (WG'94)
 | volume = 903
 | year = 1995| isbn = 978-3-540-59071-2
 }}.
*{{citation
 | last1 = Kneis | first1 = Joachim
 | last2 = Mölle | first2 = Daniel
 | last3 = Richter | first3 = Stefan
 | last4 = Rossmanith | first4 = Peter
 | contribution = Algorithms based on the treewidth of sparse graphs
 | doi = 10.1007/11604686_34
 | pages = 385–396
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = Proc. 31st International Workshop on Graph-Theoretic Concepts in Computer Science (WG 2005)
 | volume = 3787
 | year = 2005| isbn = 978-3-540-31000-6
 }}.
*{{citation
 | last1 = Korach | first1 = Ephraim
 | last2 = Solel | first2 = Nir
 | doi = 10.1016/0166-218X(93)90171-J
 | issue = 1
 | journal = [[Discrete Applied Mathematics]]
 | pages = 97–101
 | title = Tree-width, path-width, and cutwidth
 | volume = 43
 | year = 1993}}.
*{{citation
 | last1 = Kornai | first1 = András
 | last2 = Tuza | first2 = Zsolt
 | doi = 10.1016/0166-218X(92)90208-R
 | issue = 1
 | journal = [[Discrete Applied Mathematics]]
 | pages = 87–92
 | title = Narrowness, path-width, and their application in natural language processing
 | volume = 36
 | year = 1992}}.
*{{citation
 | last = Lengauer | first = Thomas
 | doi = 10.1007/BF00264496
 | issue = 4
 | journal = [[Acta Informatica]]
 | pages = 465–475
 | title = Black-white pebbles and graph separation
 | volume = 16
 | year = 1981}}.
*{{citation
 | last1 = Lopez | first1 = Alexander D.
 | last2 = Law | first2 = Hung-Fai S.
 | issue = 8
 | journal = IEEE Transactions on Electron Devices
 | pages = 1671–1675
 | title = A dense gate matrix layout method for MOS VLSI
 | volume = ED-27
 | year = 1980
 | doi = 10.1109/T-ED.1980.20086
 | id = Also in the joint issue, ''IEEE Journal of Solid-State Circuits'' '''15''' (4): 736–740, 1980, {{doi|10.1109/JSSC.1980.1051462}}| bibcode = 1980ITED...27.1671L
 }}.
*{{citation
 | last = Miller | first = George A. | author-link = George Armitage Miller
 | issue = 2
 | journal = [[Psychological Review]]
 | pages = 81–97
 | title = The Magical Number Seven, Plus or Minus Two
 | url = http://www.musanim.com/miller1956/
 | volume = 63
 | year = 1956
 | doi = 10.1037/h0043158
 | pmid=13310704}}.
*{{citation
 | last = Möhring | first = Rolf H.
 | contribution = Graph problems related to gate matrix layout and PLA folding
 | editor1-last = Tinhofer | editor1-first = G.
 | editor2-last = Mayr | editor2-first = E.
 | editor3-last = Noltemeier | editor3-first = H.
 |display-editors = 3 | editor4-last = Sysło | editor4-first = M.
 | isbn = 3-211-82177-5
 | pages = 17–51
 | publisher = Springer-Verlag
 | series = Computing Supplementum
 | title = Computational Graph Theory
 | volume = 7
 | year = 1990}}.
*{{citation
 | last1 = Monien | first1 = B.
 | last2 = Sudborough | first2 = I. H.
 | doi = 10.1016/0304-3975(88)90028-X
 | issue = 1–3
 | journal = [[Theoretical Computer Science (journal)|Theoretical Computer Science]]
 | pages = 209–229
 | title = Min cut is NP-complete for edge weighted trees
 | volume = 58
 | year = 1988}}.
*{{citation
 | last1 = Ohtsuki | first1 = Tatsuo
 | last2 = Mori | first2 = Hajimu
 | last3 = Kuh | first3 = Ernest S.
 | last4 = Kashiwabara | first4 = Toshinobu
 | last5 = Fujisawa | first5 = Toshio
 | doi = 10.1109/TCS.1979.1084695
 | issue = 9
 | journal = IEEE Transactions on Circuits and Systems
 | pages = 675–684
 | title = One-dimensional logic gate assignment and interval graphs
 | volume = 26
 | year = 1979}}.
*{{citation
 | last1 = Peng | first1 = Sheng-Lung
 | last2 = Ho | first2 = Chin-Wen
 | last3 = Hsu | first3 = Tsan-sheng
 | last4 = Ko | first4 = Ming-Tat
 | last5 = Tang | first5 = Chuan Yi
 | contribution = A linear-time algorithm for constructing an optimal node-search strategy of a tree
 | pages = 197–205
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = Proc. 4th Int. Conf. Computing and Combinatorics (COCOON'98)
 | url = http://www.springerlink.com/content/lamc6dynulxv7a8n/
 | volume = 1449
 | year = 1998}}.
*{{citation
 | last1 = Proskurowski | first1 = Andrzej
 | last2 = Telle | first2 = Jan Arne
 | journal = Discrete Mathematics and Theoretical Computer Science
 | pages = 167–176
 | title = Classes of graphs with restricted interval models
 | url = http://www.emis.ams.org/journals/DMTCS/volumes/abstracts/pdfpapers/dm030404.pdf
 | volume = 3
 | year = 1999}}.
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = Paul | author2-link = Paul Seymour (mathematician)
 | doi = 10.1016/0095-8956(83)90079-5
 | issue = 1
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | pages = 39–61
 | title = Graph minors. I. Excluding a forest
 | volume = 35
 | year = 1983}}.
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = Paul | author2-link = Paul Seymour (mathematician)
 | doi = 10.1016/S0095-8956(03)00042-X
 | issue = 1
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | pages = 43–76
 | title = Graph minors. XVI. Excluding a non-planar graph
 | volume = 89
 | year = 2003}}.
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = Paul D. | author2-link = Paul Seymour (mathematician)
 | doi = 10.1016/j.jctb.2004.08.001
 | issue = 2
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | pages = 325–357
 | title = Graph Minors. XX. Wagner's conjecture
 | volume = 92
 | year = 2004}}.
*{{citation
 | last = Scheffler | first = Petra
 | contribution = A linear algorithm for the pathwidth of trees
 | editor1-last = Bodendiek | editor1-first = R.
 | editor2-last = Henn | editor2-first = R.
 | pages = 613–620
 | publisher = Physica-Verlag
 | title = Topics in Combinatorics and Graph Theory
 | year = 1990}}.
*{{citation
 | last = Scheffler | first = Petra
 | contribution = Optimal embedding of a tree into an interval graph in linear time
 | editor1-last = Nešetřil | editor1-first = Jaroslav | editor1-link = Jaroslav Nešetřil
 | editor2-last = Fiedler | editor2-first = Miroslav
 | publisher = Elsevier
 | title = Fourth Czechoslovakian Symposium on Combinatorics, Graphs and Complexity
 | year = 1992
}}.
*{{citation
 | last = Skodinis | first = Konstantin
 | contribution = Computing optimal linear layouts of trees in linear time
 | doi = 10.1007/3-540-45253-2_37
 | pages = 403–414
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = [[European Symposium on Algorithms|Proc. 8th European Symposium on Algorithms (ESA 2000)]]
 | volume = 1879
 | year = 2000| isbn = 978-3-540-41004-1
 }}.
*{{citation
 | last = Skodinis | first = Konstantin
 | doi = 10.1016/S0196-6774(02)00225-0
 | issue = 1
 | journal = Journal of Algorithms
 | pages = 40–59
 | title = Construction of linear tree-layouts which are optimal with respect to vertex separation in linear time
 | volume = 47
 | year = 2003}}.
*{{citation
 | last1 = Suchan | first1 = Karol
 | last2 = Todinca | first2 = Ioan
 | contribution = Pathwidth of circular-arc graphs
 | doi = 10.1007/978-3-540-74839-7_25
 | pages = 258–269
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = Proc. 33rd International Workshop on Graph-Theoretic Concepts in Computer Science (WG 2007)
 | volume = 4769
 | year = 2007
 }}.
*{{citation
 |last        = Suderman
 |first       = Matthew
 |doi         = 10.1142/S0218195904001433
 |issue       = 3
 |journal     = [[International Journal of Computational Geometry and Applications]]
 |pages       = 203–225
 |title       = Pathwidth and layered drawings of trees
 |url         = http://cgm.cs.mcgill.ca/~msuder/schools/mcgill/research/trees/SOCS-02-8.pdf
 |volume      = 14
 |year        = 2004
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20030503103911/http://cgm.cs.mcgill.ca/~msuder/schools/mcgill/research/trees/SOCS-02-8.pdf
 |archivedate = 2003-05-03
 |df          = 
}}.
*{{citation
 | last1 = Takahashi | first1 = Atsushi
 | last2 = Ueno | first2 = Shuichi
 | last3 = Kajitani | first3 = Yoji
 | doi = 10.1016/0012-365X(94)90092-2
 | issue = 1–3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 293–304
 | title = Minimal acyclic forbidden minors for the family of graphs with bounded path-width
 | volume = 127
 | year = 1994}}.
{{refend}}

[[Category:Graph minor theory]]
[[Category:Graph invariants]]</text>
      <sha1>spj17tilvugsfpekn2etcw2ls3ckuht</sha1>
    </revision>
  </page>
  <page>
    <title>Paul Painlevé</title>
    <ns>0</ns>
    <id>402504</id>
    <revision>
      <id>867973304</id>
      <parentid>855020510</parentid>
      <timestamp>2018-11-09T04:41:57Z</timestamp>
      <contributor>
        <username>Abcbalbuena</username>
        <id>2046264</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23153">{{Use dmy dates|date=September 2015}}
{{Infobox office holder 
|name=Paul Painlevé
|image=Paul Painlevé 1923.jpg
|caption = Paul Painlevé in 1923
|office = [[List of Finance Ministers of France|Minister of finance]]
|term_start = 29 October 1925
|term_end = 28 November 1925
|president = [[Gaston Doumergue]]
|predecessor = Joseph Cailleux
|successor = Louis Loucheur
|term_start2    =12 September 1917
|term_end2      =16 November 1917
|president2     =[[Raymond Poincaré]]
|predecessor2   =[[Alexandre Ribot]]
|successor2     =[[Georges Clemenceau]]
|office1 =[[List of Prime Ministers of France|62nd]] [[Prime Minister of France]]
|term_start1   =17 April 1925
|term_end1     =28 November 1925
|president1    =[[Gaston Doumergue]]
|predecessor1  =[[Édouard Herriot]]
|successor1    =[[Aristide Briand]]
|office3 = [[List of War Ministers of France|Minister of War]]
|term_start3   =17 April 1925
|term_end3     =29 October 1925
|president3    =[[Gaston Doumergue]]
|predecessor3  = Charles Nollet
|successor3    =[[André Maginot]]
|term_start4   = 20 March 1917
|term_end4     = 13 November 1917
|president4    =[[Raymond Poincaré]]
|predecessor4  = Lucien Lacaze
|successor4    =[[Georges Clémenceau]]
|office5 = President of the [[Chamber of deputies (France)|Chamber of Deputies]]
|term_start5   =9 June 1924
|term_end5     = 21 April 1925
|president5    = [[Gaston Doumergue]]
|predecessor5  = Raoul Péret
|successor5    = [[Édouard Herriot]]
|birth_date    =5 December 1863
|birth_place   =Paris
|death_date    ={{death date and age|1933|10|29|1863|12|5|df=y}}
|death_place   =Paris
|party=[[Republican-Socialist Party|PRS]]
}}
'''Paul Painlevé''' ({{IPA-fr|pɔl pɛ̃ləve|lang}}; 5 December 1863 – 29 October 1933) was a French mathematician and statesman. He served twice as [[Prime Minister of France|Prime Minister]] of the [[French Third Republic|Third Republic]]: 12 September – 13 November 1917 and 17 April – 22 November 1925. His entry into politics came in 1906 after a professorship at the Sorbonne that began in 1892.

His first term as prime minister lasted only nine weeks but dealt with weighty issues, such as the Russian Revolution, the American entry into the war, the failure of the [[Nivelle Offensive]], quelling the [[French Army Mutinies]] and relations with the British. In the 1920s as Minister of War he was a key figure in building the [[Maginot Line]].&lt;ref&gt;{{cite journal|author=Smart, Nick |title=The Maginot Line: An Indestructible Inheritance|journal=International Journal of Heritage Studies|year=1996|volume=2|issue=4|pages= 222–233|doi=10.1080/13527259608722177}}&lt;/ref&gt;  In his second term as prime minister he dealt with the outbreak of rebellion in Syria's Jabal Druze in July
1925 which had excited public and parliamentary anxiety over the general crisis of France's empire.&lt;ref&gt;{{cite journal|author=Thomas, Martin |title=Albert Sarraut, French Colonial Development, and the Communist Threat, 1919–1930|journal=Journal of Modern History|year=2005|volume=77|issue=4 |pages=917–955|doi=10.1086/499830 }}&lt;/ref&gt;

== Biography ==

===Early life===
Painlevé was born in Paris.&lt;ref name="mactutor"&gt;{{MacTutor Biography|id=Painleve}}&lt;/ref&gt;

Brought up within a family of skilled artisans (his father was a [[technical drawing|draughtsman]]) Painlevé showed early promise across the range of elementary studies and was initially attracted by either an engineering or political career. However, he finally entered the [[École Normale Supérieure]] in 1883 to study [[mathematics]], receiving his doctorate in 1887 following a period of study at [[Göttingen]], Germany with [[Felix Klein]] and [[Hermann Amandus Schwarz]]. Intending an academic career he became professor at [[Université Lille Nord de France|Université de Lille]], returning to Paris in 1892 to teach at the [[University of Paris|Sorbonne]], [[École Polytechnique]] and later at the [[Collège de France]] and the [[École Normale Supérieure]]. He was elected a member of the [[Académie des Sciences]] in 1900.&lt;ref name="mactutor"/&gt;

He married Marguerite Petit de Villeneuve in 1901. Marguerite died during the birth of their son [[Jean Painlevé]] in the following year.&lt;ref name="mactutor"/&gt;

Painlevé's mathematical work on [[differential equation]]s led him to encounter their application to the theory of flight and, as ever, his broad interest in engineering topics fostered an enthusiasm for the emerging field of [[aviation]]. In 1908, he became [[Wilbur Wright]]'s first airplane passenger in France and in 1909 created the first university course in [[aeronautics]].&lt;ref name="mactutor"/&gt;

===Mathematical work===
[[File:Paul Painlevé in 1915.jpg|thumb|left|Paul Painlevé as a young man]]
Some [[differential equation]]s can be solved using elementary algebraic operations that involve the [[trigonometric function|trigonometric]] and [[exponential function]]s (sometimes called [[elementary function]]s). Many interesting [[special functions]] arise as solutions of linear second [[degree of a polynomial|order]] [[Ordinary (officer)|ordinary]] differential equations. Around the turn of the century, 
Painlevé, [[Charles Émile Picard|É. Picard]], and B. Gambier showed that
of the class of [[nonlinear]] second order ordinary differential equations with [[polynomial]] [[coefficients]], those that possess a certain desirable technical property, shared by the linear equations (nowadays commonly referred to as the '[[Painlevé property]]') can always be transformed into one of fifty canonical forms.  Of these fifty equations, just six require 'new' transcendental functions for their solution.&lt;ref&gt;{{cite book | author=Painlevé, P. | location=Paris | publisher=Libraire Scientifique à Hermann | year=1897 | title=Leçons sur la théorie analytique des équations différentielles |url=http://historical.library.cornell.edu/cgi-bin/cul.math/docviewer?did=04500002&amp;seq=9 }}&lt;/ref&gt; These new transcendental functions, solving the remaining six equations, are called the [[Painlevé transcendents]], and interest in them has revived recently due to their appearance in modern geometry, integrable systems&lt;ref&gt;
Ablowitz, M. J. and Clarkson, P.A. (1991) ''Solitons, nonlinear evolution equations and inverse scattering''. Cambridge University Press&lt;/ref&gt; and [[statistical mechanics]].&lt;ref&gt;
{{cite journal |first=T. T. |last=Wu |author2=B. M. McCoy |author3=C. A. Tracy |author4=E. Barouch |doi=10.1103/PhysRevB.13.316 |title=Spin-spin correlation functions for the two-dimensional Ising model: Exact theory in the scaling region |journal=Physical Review B |volume=13 |pages=316–374 |year=1976|bibcode = 1976PhRvB..13..316W }}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal |first=Michio |last=Jimbo |author2=Tetsuji Miwa |author3=Yasuko Môri |author4=Mikio Sato |title=Density matrix of an impenetrable Bose gas and the fifth Painlevé transcendent |journal=Physica D |volume=1 |issue=1 |pages=80–158 |date=April 1980  |doi=10.1016/0167-2789(80)90006-8 |bibcode = 1980PhyD....1...80J }}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal |first=C. A. |last=Tracy |author2=H. Widom |arxiv=cond-mat/9701067 |title=On Exact Solutions to the Cylindrical Poisson-Boltzmann Equation with Applications to Polyelectrolytes |journal=Physica A |volume=244 |pages=402–413 |year=1997 |doi=10.1016/S0378-4371(97)00229-X|bibcode = 1997PhyA..244..402T }}
&lt;/ref&gt;

In 1895 he gave a series of lectures at [[Stockholm University]] on differential equations, at the end stating the [[Painlevé conjecture]] about singularities of the [[n-body problem]].&lt;ref&gt;{{cite journal|author=Diacu, Florin N. |title= Painlevé's Conjecture|journal=The Mathematical Intelligencer|volume=13|issue= 2|pages=6|year= 1993|doi=10.1007/BF03024186}}&lt;/ref&gt;

In the 1920s, Painlevé briefly turned his attention to the new theory of gravitation, [[general relativity]], which had recently been introduced by [[Albert Einstein]].  In 1921, Painlevé proposed the [[Gullstrand–Painlevé coordinates]] for the [[Schwarzschild metric]].  The modification in the coordinate system was the first to reveal clearly that the [[Schwarzschild radius]] is a mere [[coordinate singularity]] (with however, profound global significance: it represents the [[event horizon]] of a [[black hole]]). This essential point was not generally appreciated by physicists until around 1963.{{Citation needed|date=July 2007}} In his diary, [[Harry Graf Kessler]] recorded that during a later visit to Berlin, Painlevé discussed [[pacifism|pacifist]] [[international politics]] with Einstein, but there is no reference to discussions concerning the significance of the Schwarzschild radius.&lt;ref&gt;
{{cite web |url=http://www.projekt.gutenberg.de/?id=5&amp;xid=4742&amp;kapitel=8&amp;cHash=ba34547ca22#gb_found |publisher=Projekt Gutenberg |title=Berlin. 20. February 1925. Freitag |trans-title=Diary entry for Berlin 25 February 1925 |author=Harry Graf Kessler}}
&lt;/ref&gt;

===Early political career===
Between 1915 and 1917, Painlevé served as French Minister for Public Instruction and Inventions. In December 1915, he requested a scientific exchange agreement between France and Britain, resulting in Anglo-French collaboration that ultimately led to the parallel development by [[Paul Langevin]] in France and [[Robert William Boyle|Robert Boyle]] in Britain of the first active [[sonar]].&lt;ref name=Ainslie2010&gt;Michael A. Ainslie ''Principles of Sonar Performance Modelling'', Springer, 2010 {{isbn|3-540-87661-8}},  page 13&lt;/ref&gt;

===First period as French Prime Minister===
Painlevé took his aviation interests, along with those in naval and military matters, with him when he became, in 1906, Deputy for Paris's [[5th arrondissement of Paris|5th arrondissement]], the so-called [[Latin Quarter]]. By 1910, he had vacated his academic posts and World War I led to his active participation in military committees, joining [[Aristide Briand]]'s cabinet in 1915 as Minister for Public Instruction and Inventions.&lt;ref name="mactutor"/&gt;

On his appointment as War Minister in March 1917 he was immediately called upon to give his approval, albeit with some misgivings, to [[Robert Georges Nivelle]]'s wildly optimistic plans for a breakthrough offensive in [[Champagne, France|Champagne]]. Painlevé reacted to the disastrous public failure of the plan by dismissing [[Robert Georges Nivelle|Nivelle]] and controversially replacing him with [[Henri Philippe Pétain]].&lt;ref name="britannica1"&gt;[http://global.britannica.com/biography/Paul-Painleve "Paul Painlevé"] in ''[[Encyclopædia Britannica]]''&lt;/ref&gt; He was also responsible for isolating the [[Russian Expeditionary Force in France]] in the [[La Courtine]] camp, located in a remote spot on the plateau of [[Plateau de Millevaches|Millevaches]].&lt;ref name=Cockfield&gt;{{cite book|last1=Cockfield|first1=Jamie H.|title=With snow on their boots : the tragic odyssey of the Russian Expeditionary Force in France during World War I|date=1999|publisher=St. Martin's Griffin|location=New York|isbn=978-0312220822|page=137|edition=1st St. Martin's Griffin}}&lt;/ref&gt;

On 7 September 1917, Prime Minister [[Alexandre Ribot]] lost the support of the Socialists and Painlevé was called upon to form a new government.&lt;ref name="mactutor"/&gt;

Painlevé was a leading voice at the [[Rapallo conference]] that led to the establishment of the [[Supreme Allied Council]], a consultative body of [[Allies of World War I|Allied powers]] that anticipated the unified Allied command finally established in the following year. He appointed [[Ferdinand Foch]] as French representative knowing that he was the natural Allied commander. On Painlevé's return to Paris he was defeated and resigned on 13 November 1917 to be succeeded by [[Georges Clemenceau]]. [[Ferdinand Foch|Foch]] was finally made commander-in-chief of all Allied armies on the Western and Italian fronts in March 1918.&lt;ref name="mactutor"/&gt;&lt;ref name="britannica1"/&gt;&lt;ref&gt;{{Cite book |title=The First World War |last=Keegan |first=John |year=2003 |publisher=Random House |location=UK |isbn=0-7126-8040-3 |page=403}}&lt;/ref&gt;

===Second period as French Prime Minister===
Painlevé then played little active role in politics until the election of November 1919 when he emerged as a leftist critic of the right-wing [[National Bloc (France)|Bloc National]]. By the time the next election approached in May 1924 his collaboration with [[Édouard Herriot]], a fellow member of Briand's 1915 cabinet, had led to the formation of the [[Cartel des Gauches]]. Winning the election, Herriot became Prime Minister in June, while Painlevé became President of the Chamber of Deputies. Though Painlevé ran for [[President of France]] in 1924 he was defeated by [[Gaston Doumergue]]. Herriot's administration publicly recognised the Soviet Union, accepted the [[Dawes Plan]] and agreed to [[Occupation of the Ruhr|evacuate the Ruhr]]. However, a financial crisis arose from the ensuing devaluation of the [[franc]] and in April 1925, Herriot fell and Painlevé became Prime Minister for a second time on 17 April. Unfortunately, he was unable to offer convincing remedies for the financial problems and was forced to resign on 21 November.&lt;ref name="mactutor"/&gt;&lt;ref name="britannica1"/&gt;&lt;ref&gt;[http://global.britannica.com/biography/Edouard-Herriot "Édouard Herriot"] in ''Encyclopædia Britannica''&lt;/ref&gt;

===Later political career===
[[File:Paul Painlevé Wellcome.jpg|thumb|Paul Painlevé in the 1920s]]
Following Painlevé's resignation, Briand formed a new government with Painlevé as Minister for War. Though Briand was defeated by [[Raymond Poincaré]] in 1926, Painlevé continued in office. Poincaré stabilised the franc with a return to the [[gold standard]], but ultimately acceded power to Briand.&lt;ref name="mactutor"/&gt; During his tenure as Minister of War, Painlevé was instrumental in the creation of the [[Maginot Line]]. This line of military fortifications along France's Eastern border was largely designed by Painlevé, yet named for [[André Maginot]], owing to Maginot's championing of public support and funding.{{Citation needed|date=July 2007}} Painlevé remained in office as Minister for War until July 1929.&lt;ref name="mactutor"/&gt;

Though he was proposed for [[President of France]] in 1932, Painlevé withdrew before the election. He became Minister of Air later that year, making proposals for an international treaty to ban the manufacture of bomber aircraft and to establish an international air force to enforce global peace. On the fall of the government in January 1933, his political career ended.&lt;ref name="mactutor"/&gt;

Painlevé died in Paris in October of the same year.&lt;ref name="britannica1"/&gt; On 4 November, after a eulogy by Prime Minister [[Albert Sarraut]], he was interred in the [[Panthéon]].&lt;ref&gt;{{Cite news |title=Painlevé To Be Buried in Pantheon Today |newspaper=The New York Times |date=4 November 1933 |page=13 |url=https://www.nytimes.com/1933/11/04/archives/painleve-to-be-buried-in-pantheon-today-former-premier-whose-life.html |accessdate=29 August 2011 }}&lt;/ref&gt;

== Honours ==
*The aircraft carrier ''[[French aircraft carrier Painlevé|Painlevé]]'' was named in his honour.&lt;ref name="PolmarGenda2006"&gt;{{Cite book |author1=Polmar, Norman |author2=Genda, Minoru  |title=Aircraft Carriers: A History of Carrier Aviation and Its Influence on World Events |url=https://books.google.com/books?id=6z7quhWS-BoC&amp;pg=PA86 |year=2006|publisher=Potomac Books, Inc. |location=Washington, DC  |isbn=978-1-57488-664-1 |page=86}}&lt;/ref&gt;
*The asteroid [[953 Painleva]] was named in his honour.&lt;ref&gt;{{Cite book |last=Schmadel |first=Lutz D.|author2=International Astronomical Union |title=Dictionary of minor planet names |year=2003 |publisher=Springer-Verlag |location=Berlin; New York |isbn=978-3-540-00238-3 |page=84 |url=https://books.google.com/books?id=KWrB1jPCa8AC&amp;pg=PA84}}&lt;/ref&gt;
*The [[Laboratoire Paul Painlevé]] ([[:fr:Paul Painlevé|fr]]), a French mathematics research lab, is named in his honour.

== Composition of governments ==
{{unreferenced|section|date=October 2017}}
===Painlevé's First Government, 12 September – 16 November 1917===
*Paul Painlevé – President of the Council and Minister of War
*[[Alexandre Ribot]] – Minister of Foreign Affairs
*[[Louis Loucheur]] – Minister of Armaments and War Manufacturing
*[[Théodore Steeg]] – Minister of the Interior
*[[Louis Lucien Klotz]] – Minister of Finance
*[[André Renard]] – Minister of Labour and Social Security Provisions
*[[Raoul Péret]] – Minister of Justice
*[[Charles Chaumet]] – Minister of Marine
*[[Charles Daniel-Vincent]] – Minister of Public Instruction and Fine Arts
*[[Fernand David]] – Minister of Agriculture
*[[Maurice Long]] – Minister of General Supply
*[[René Besnard]] – Minister of Colonies
*[[Albert Claveille]] – Minister of Public Works and Transport
*[[Étienne Clémentel]] – Minister of Commerce, Industry, Posts, and Telegraphs
*[[Louis Barthou]] – Minister of State
*[[Léon Bourgeois]] – Minister of State
*[[Paul Doumer]] – Minister of State
*[[Jean Dupuy (politician)|Jean Dupuy]] – Minister of State

'''Changes'''
*27 September 1917 – [[Henry Franklin-Bouillon]] entered the ministry as Minister of State.
*23 October 1917 – [[Louis Barthou]] succeeded Ribot as Minister of Foreign Affairs

===Painlevé's Second Ministry, 17 April – 29 October 1925===
*Paul Painlevé – President of the Council and Minister of War
*[[Aristide Briand]] – Minister of Foreign Affairs
*[[Abraham Schrameck]] – Minister of the Interior
*[[Joseph Caillaux]] – Minister of Finance
*[[Antoine Durafour]] – Minister of Labour, Hygiene, Welfare Work, and Social Security Provisions
*[[Théodore Steeg]] – Minister of Justice
*[[Émile Borel]] – Minister of Marine
*[[Anatole de Monzie]] – Minister of Public Instruction and Fine Arts.
*[[Louis Antériou]] – Minister of Pensions
*[[Jean Durand]] – Minister of Agriculture
*[[Orly André-Hesse]] – Minister of Colonies
*[[Pierre Laval]] – Minister of Public Works
*[[Charles Chaumet]] – Minister of Commerce and Industry

'''Changes'''
*11 October 1925 – [[Anatole de Monzie]] succeeded Steeg as Minister of Justice. [[Yvon Delbos]] succeeded Monzie as Minister of Public Instruction and Fine Arts.

===Painlevé's Third Ministry, 29 October – 28 November 1925===
*Paul Painlevé – President of the Council and Minister of Finance
*[[Aristide Briand]] – Minister of Foreign Affairs
*[[Édouard Daladier]] – Minister of War
*[[Abraham Schrameck]] – Minister of the Interior
*[[Georges Bonnet]] – Minister of Budget
*[[Antoine Durafour]] – Minister of Labour, Hygiene, Welfare Work, and Social Security Provisions
*[[Camille Chautemps]] – Minister of Justice
*[[Émile Borel]] – Minister of Marine
*[[Yvon Delbos]] – Minister of Public Instruction and Fine Arts
*[[Louis Antériou]] – Minister of Pensions
*[[Jean Durand]] – Minister of Agriculture
*[[Léon Perrier]] – Minister of Colonies
*[[Anatole de Monazie]] – Minister of Public Works
*[[Charles Daniel-Vincent]] – Minister of Commerce and Industry

==Works==
* ''Sur les lignes singulières des fonctions analytiques'' - 1887/''On singular lines of analytic functions''.
* ''Mémoire sur les équations différentielles du premier ordre'' - 1892/''Memory on first order differential equations''. 
* ''Leçons sur la théorie analytique des équations différentielles'', A. Hermann (Paris), 1897/''A course on analytic theory of differential equations''. 
* ''Leçons sur les fonctions de variables réelles et les développements en séries de polynômes'' - 1905/''A course on real variable functions and polynomial development series''.
* ''Cours de mécanique et machines'' (Paris), 1907/''A course on mechanics and machines''. 
* ''Cours de mécanique et machines 2'' (Paris), 1908/''A course on mechanics and machines 2''. 
* ''Leçons sur les fonctions définies par les équations différentielles du premier ordre'', Gauthier-Villars (Paris), 1908/''A course on functions defined by first order differential equations''.
* ''L'aéroplane'', Lille, 1909/''Aeroplane''.
* ''Cours de mécanique et machines'' (Paris), 1909/''A course on mechanics and machines''.
* ''L'aviation'', Paris, Felix Alcan, 1910/''Aviation''.
* ''Les axiomes de la mécanique, examen critique'' ; ''Note sur la propagation de la lumière'' - 1922/''Mechanics axioms, a critical study'' ; ''Notes on light spread''.
* ''Leçons sur la théorie analytique des équations différentielles'', Hermann, Paris, 1897/''A course on analytical theory of differential equations''.
* ''Trois mémoires de Painlevé sur la relativité'' (1921-1922)/''Painlevé's three memories on relativity''.

==See also==
*[[List of people on the cover of Time Magazine: 1920s]]

==References==
{{reflist|30em}}

==Further reading==
* {{cite journal|last=Dutton|first=David|title=Paul Painlevé and the end of the sacred union in Wartime France|journal=Journal of Strategic Studies|date=1981|volume=4|issue=1|pages=46–59|doi=10.1080/01402398108437065}}
* {{cite journal|last=Greenhalgh|first=Elizabeth|title=Paul Painlevé and Franco-British Relations in 1917|journal=Contemporary British History|date=2011|volume=25|issue=1|pages=5–27|doi=10.1080/13619462.2011.546094}}

== External links ==
{{Commons category}}
* {{MathGenealogy|id=76358}}
* [http://asa3.univ-lille1.fr/spip/ASA_histoire/serviteurs/painleve.htm Biography (French)]
* {{PM20|FID=pe/013143}}

{{s-start}}
{{s-off}}
{{succession box|title=[[List of Prime Ministers of France|Prime Minister of France]]|before=[[Alexandre Ribot]]|after=[[Georges Clemenceau]]|years=1917}}
{{succession box|title=[[List of Prime Ministers of France|Prime Minister of France]]|before=[[Édouard Herriot]]|after=[[Aristide Briand]]|years=1925}}
{{s-end}}

{{Heads of government of France}}
{{Finance Ministers of France}}
{{Université Lille - Nord de France}}

{{Authority control}}

{{DEFAULTSORT:Painleve, Paul}}
[[Category:1863 births]]
[[Category:1933 deaths]]
[[Category:Politicians from Paris]]
[[Category:Republican-Socialist Party politicians]]
[[Category:Prime Ministers of France]]
[[Category:French Ministers of War]]
[[Category:French Ministers of Finance]]
[[Category:Members of the 10th Chamber of Deputies of the French Third Republic]]
[[Category:Members of the 11th Chamber of Deputies of the French Third Republic]]
[[Category:Members of the 12th Chamber of Deputies of the French Third Republic]]
[[Category:Members of the 13th Chamber of Deputies of the French Third Republic]]
[[Category:Members of the 14th Chamber of Deputies of the French Third Republic]]
[[Category:Members of the 15th Chamber of Deputies of the French Third Republic]]
[[Category:French mathematicians]]
[[Category:Lycée Louis-le-Grand alumni]]
[[Category:École Normale Supérieure alumni]]
[[Category:Lille University of Science and Technology faculty]]
[[Category:Members of the Institut d'Estudis Catalans]]
[[Category:Members of the French Academy of Sciences]]
[[Category:French people of World War I]]
[[Category:Burials at the Panthéon, Paris]]
[[Category:Mathematician politicians]]</text>
      <sha1>fgpjt1sa9b3m6zjybpdc6xq8m33cvf4</sha1>
    </revision>
  </page>
  <page>
    <title>Peck poset</title>
    <ns>0</ns>
    <id>26533665</id>
    <redirect title="G. W. Peck" />
    <revision>
      <id>349538458</id>
      <timestamp>2010-03-13T02:25:34Z</timestamp>
      <contributor>
        <username>Twri</username>
        <id>7976492</id>
      </contributor>
      <comment>[[WP:AES|←]]Redirected page to [[G. W. Peck]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="75">#redirect [[G. W. Peck]]
{{R with possibilities}}
[[Category:Order theory]]</text>
      <sha1>tb4if3q87aw18fmgkxxwtvj1xmqkbwf</sha1>
    </revision>
  </page>
  <page>
    <title>Quotient of subspace theorem</title>
    <ns>0</ns>
    <id>9176798</id>
    <revision>
      <id>641999940</id>
      <parentid>636531603</parentid>
      <timestamp>2015-01-11T11:27:51Z</timestamp>
      <contributor>
        <username>K9re11</username>
        <id>19647483</id>
      </contributor>
      <comment>removed [[Category:Functional analysis]] using [[WP:HC|HotCat]] as there are more specific categories</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2580">In mathematics, the '''quotient of subspace theorem''' is an important property of finite-dimensional [[normed space]]s, discovered by [[Vitali Milman]].&lt;ref&gt;The original proof appeared in {{harvtxt|Milman|1984}}. See also {{harvtxt|Pisier|1989}}.&lt;/ref&gt;

Let (''X'',&amp;nbsp;||·||) be an ''N''-dimensional normed space. There exist subspaces ''Z''&amp;nbsp;⊂&amp;nbsp;''Y''&amp;nbsp;⊂&amp;nbsp;''X'' such that the following holds:
* The [[quotient space (linear algebra)|quotient space]] ''E''&amp;nbsp;=&amp;nbsp;''Y''&amp;nbsp;/&amp;nbsp;''Z'' is of dimension dim&amp;nbsp;E&amp;nbsp;≥&amp;nbsp;''c''&amp;nbsp;''N'', where ''c''&amp;nbsp;&gt;&amp;nbsp;0 is a universal constant.
* The induced [[norm (mathematics)|norm]] ||&amp;nbsp;·&amp;nbsp;|| on ''E'', defined by

:: &lt;math&gt;\| e \| =\min_{y \in e} \| y \|, \quad e \in E, &lt;/math&gt;

is uniformly [[isomorphism|isomorphic]] to Euclidean. That is, there exists a positive [[quadratic form]] ("Euclidean structure") ''Q'' on ''E'', such that

:: &lt;math&gt;\frac{\sqrt{Q(e)}}{K} \leq \| e \| \leq K \sqrt{Q(e)}&lt;/math&gt; for &lt;math&gt;e \in E,&lt;/math&gt;

with ''K''&amp;nbsp;&gt;&amp;nbsp;1 a universal constant. 

The statement is relative easy to prove by induction on the dimension of ''Z'' (even for ''Y=Z'', ''X''=''0'', ''c=1'') with a ''K'' that depends only on ''N''; the point of the theorem is that ''K'' is independent of ''N''.

In fact, the constant ''c'' can be made arbitrarily close to 1, at the expense of the
constant ''K'' becoming large. The original proof allowed 

:&lt;math&gt; c(K) \approx 1 - \text{const} / \log \log K. &lt;/math&gt;&lt;ref&gt;See references for improved estimates.&lt;/ref&gt;

==Notes==
{{Reflist}}

== References ==
* {{citation|last=Milman|first=V.D.|author-link=Vitali Milman|title=Almost Euclidean quotient spaces of subspaces of a finite-dimensional normed space|journal=Israel seminar on geometrical aspects of functional analysis|volume=X|publisher=Tel Aviv Univ.|location=Tel Aviv|year=1984}}
* {{citation|first=Y.|last= Gordon|title=On Milman's inequality and random subspaces which escape through a mesh in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;|journal=Geometric aspects of functional analysis|pages=84&amp;ndash;106|series=Lecture Notes in Math.|volume=1317|publisher=Springer|location=Berlin|year=1988|doi=10.1007/BFb0081737|isbn=978-3-540-19353-1}}
* {{citation|first=G.|last=Pisier|author-link=Gilles Pisier|title=The volume of convex bodies and Banach space geometry|series=Cambridge Tracts in Mathematics|volume=94|publisher=Cambridge University Press|location=Cambridge|year=1989}}

[[Category:Banach spaces]]
[[Category:Asymptotic geometric analysis]]
[[Category:Theorems in functional analysis]]</text>
      <sha1>b3toz7e8xpx9hxmyc5kcc9c743topfa</sha1>
    </revision>
  </page>
  <page>
    <title>Rectifiable set</title>
    <ns>0</ns>
    <id>2644238</id>
    <revision>
      <id>846393241</id>
      <parentid>714508021</parentid>
      <timestamp>2018-06-18T13:46:19Z</timestamp>
      <contributor>
        <ip>132.64.72.117</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3996">{{otheruses4|rectifiable sets in measure theory|rectifiable curves|Arc length}}
In [[mathematics]], a '''rectifiable set''' is a set that is smooth in a certain [[measure theory|measure-theoretic]] sense. It is an extension of the idea of a [[rectifiable curve]] to higher dimensions; loosely speaking, a rectifiable set is a rigorous formulation of a piece-wise smooth set.  As such, it has many of the desirable properties of smooth [[manifold]]s, including tangent spaces that are defined [[almost everywhere]]. Rectifiable sets are the underlying object of study in [[geometric measure theory]].

==Definition==
A subset &lt;math&gt;E&lt;/math&gt; of [[Euclidean space]] &lt;math&gt;\mathbb{R}^n&lt;/math&gt; is said to be '''&lt;math&gt;m&lt;/math&gt;-rectifiable''' set if there exist a [[countable]] collection &lt;math&gt;\{f_i\}&lt;/math&gt; of continuously differentiable maps

:&lt;math&gt;f_i:\mathbb{R}^m \to \mathbb{R}^n&lt;/math&gt;

such that the &lt;math&gt;m&lt;/math&gt;-[[Hausdorff measure]] &lt;math&gt;\mathcal{H}^m&lt;/math&gt; of

:&lt;math&gt;E\setminus \bigcup_{i=0}^\infty f_i\left(\mathbb{R}^m\right)&lt;/math&gt;

is zero. The backslash here denotes the [[set difference]]. Equivalently, the &lt;math&gt;f_i&lt;/math&gt; may be taken to be [[Lipschitz continuous]] without altering the definition.&lt;ref&gt;{{harvnb|Simon|1984|p=58}}, calls this definition "countably ''m''-rectifiable".&lt;/ref&gt;

A set &lt;math&gt;E&lt;/math&gt; is said to be '''purely &lt;math&gt;m&lt;/math&gt;-unrectifiable''' if for ''every'' (continuous, differentiable)  &lt;math&gt;f:\mathbb{R}^m \to \mathbb{R}^n&lt;/math&gt;, one has

:&lt;math&gt;\mathcal{H}^m \left(E \cap f\left(\mathbb{R}^m\right)\right)=0.&lt;/math&gt;

A standard example of a purely-1-unrectifiable set in two dimensions is the cross-product of the [[Smith–Volterra–Cantor set]] times itself.

=== Rectifiable sets in metric spaces ===

{{harvtxt|Federer|1969|pp=251–252}} gives the following terminology for ''m''-rectifiable sets ''E'' in a general metric space ''X''.
# ''E'' is '''&lt;math&gt;m&lt;/math&gt; rectifiable''' when there exists a Lipschitz map &lt;math&gt;f:K \to E&lt;/math&gt; for some bounded subset &lt;math&gt;K&lt;/math&gt; of &lt;math&gt;\mathbb{R}^m&lt;/math&gt; onto &lt;math&gt;E&lt;/math&gt;.
# ''E'' is '''countably &lt;math&gt;m&lt;/math&gt; rectifiable''' when ''E'' equals the union of a countable family of &lt;math&gt;m&lt;/math&gt; rectifiable sets.
# ''E'' is '''countably &lt;math&gt;(\phi,m)&lt;/math&gt; rectifiable''' when &lt;math&gt;\phi&lt;/math&gt; is a measure on ''X'' and there is a countably &lt;math&gt;m&lt;/math&gt; rectifiable set ''F'' such that &lt;math&gt;\phi(E\setminus F)=0&lt;/math&gt;.
# ''E'' is '''&lt;math&gt;(\phi,m)&lt;/math&gt; rectifiable''' when ''E'' is countably &lt;math&gt;(\phi,m)&lt;/math&gt; rectifiable and &lt;math&gt;\phi(E)&lt;\infty&lt;/math&gt;
# ''E'' is '''purely &lt;math&gt;(\phi,m)&lt;/math&gt; unrectifiable''' when &lt;math&gt;\phi&lt;/math&gt; is a measure on ''X'' and ''E'' includes no &lt;math&gt;m&lt;/math&gt; rectifiable set ''F'' with &lt;math&gt;\phi(F)&gt;0&lt;/math&gt;.

Definition 3 with &lt;math&gt;\phi=\mathcal{H}^m&lt;/math&gt; and &lt;math&gt;X=\mathbb{R}^n&lt;/math&gt; comes closest to the above definition for subsets of Euclidean spaces.

==Notes==
{{reflist}}

==References==
* {{citation|ref=harv|last = Federer | first = Herbert | authorlink = Herbert Federer | title = Geometric measure theory| publisher = Springer-Verlag | location = New York | year = 1969 | pages = xiv+676 | isbn = 978-3-540-60656-7 | mr= 0257325 | series = Die Grundlehren der mathematischen Wissenschaften|volume=153}}
* {{springer|author=T.C.O'Neil|id=G/g130040|title=Geometric measure theory}}
* {{Citation|ref=harv
  | last = Simon
  | first = Leon
  | author-link =Leon Simon
  | title = Lectures on Geometric Measure Theory
  | place = [[Canberra]]
  | publisher = Centre for Mathematics and its Applications (CMA), [[Australian National University]]
  | series = Proceedings of the Centre for Mathematical Analysis
  | volume = 3
  | year = 1984
  | pages =VII+272 (loose errata)
  | isbn = 0-86784-429-9
  | zbl = 0546.49019
}}

==External links==
* [https://www.encyclopediaofmath.org/index.php/Rectifiable_set Rectifiable set] at [http://www.encyclopediaofmath.org/ Encyclopedia of Mathematics]

[[Category:Measure theory]]</text>
      <sha1>q1a0mxtesprurdufb4r7fvvlxi6exu0</sha1>
    </revision>
  </page>
  <page>
    <title>Recursive acronym</title>
    <ns>0</ns>
    <id>36983</id>
    <revision>
      <id>870605217</id>
      <parentid>869622098</parentid>
      <timestamp>2018-11-25T22:33:29Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13069">A '''recursive acronym''' is an [[acronym]] that [[recursion|refers to itself]]. The term was first used in print in 1979 in [[Douglas Hofstadter]]'s book ''[[Gödel, Escher, Bach|Gödel, Escher, Bach: An Eternal Golden Braid]]'', in which Hofstadter invents the acronym GOD, meaning "GOD Over Djinn", to help explain infinite series, and describes it as a recursive acronym.&lt;ref&gt;{{ cite web | url = http://www.math.cornell.edu/~mec/Summer2009/ABjorndahl/extension.html |title = Puzzles and Paradoxes: Infinity in Finite Terms |accessdate=2013-04-23 }}&lt;/ref&gt; Other references followed,&lt;ref&gt;{{ cite web | url = http://www.wordspy.com/words/recursiveacronym.asp |title = WordSpy – Recursive Acronym |accessdate=2008-12-18 }}&lt;/ref&gt; however the concept was used as early as 1968 in [[John Brunner (novelist)|John Brunner]]'s science fiction novel ''[[Stand on Zanzibar]]''. In the story, the acronym EPT (Education for Particular Task) later morphed into "Eptification for Particular Task".

Recursive acronyms typically form [[Backronym|backwardly]]: either an existing ordinary acronym is given a new explanation of what the letters stand for, or a name is turned into an acronym by giving the letters an explanation of what they stand for, in each case with the first letter standing recursively for the whole acronym.

==Computer-related examples==
In [[computing]], an early tradition in the [[Hacker (hobbyist)|hacker]] community (especially at [[Massachusetts Institute of Technology|MIT]]) was to choose acronyms and abbreviations that referred humorously to themselves or to other abbreviations. Perhaps the earliest example in this context, from 1960 the [[backronym]] "Mash Until No Good" was created to describe Mung, and a while after it was revised to "Mung Until No Good".  It lived on as a recursive command in the editing language [[Text Editor and Corrector|TECO]].&lt;sup&gt;[[Mung (computer term)|[3]]]&lt;/sup&gt; In 1977 or 1978 came TINT ("TINT Is Not [[Text Editor and Corrector|TECO]]"), an editor for [[MagicSix]] written (and named) by Ted Anderson.  This inspired the two MIT [[Lisp Machine]] editors called [[EINE]] ("EINE Is Not [[Emacs]]", German for ''one'') and [[ZWEI]] ("ZWEI Was EINE Initially", German for ''two''). These were followed by [[Richard Stallman]]'s [[GNU]] (GNU's Not [[Unix]]). Many others also include negatives, such as denials that the thing defined is or resembles something else (which the thing defined does in fact resemble or is even derived from), to indicate that, despite the similarities, it was distinct from the program on which it was based.&lt;ref&gt;[http://fsfe.org/freesoftware/transcripts/rms-fs-2006-03-09.en.html#the-name-gnu The Free Software Movement and the Future of Freedom: The name "GNU"], Richard Stallman, March 9th 2006&lt;/ref&gt;

An earlier example appears in a 1976 textbook on data structures, in which the pseudo-language SPARKS is used to define the algorithms discussed in the text. "SPARKS" is claimed to be a non-acronymic name, but "several cute ideas have been suggested" as expansions of the name. One of the suggestions is "Smart Programmers Are Required to Know SPARKS".&lt;ref&gt;Fundamentals Of Data Structures (Ellis Horowitz &amp; [[Sartaj Sahni]], Computer Science Press, 1976)&lt;/ref&gt; (this example is [[tail recursive]])

===Notable examples===
* [[Allegro library|Allegro]]&amp;nbsp;— Allegro Low LEvel Game ROutines (early versions for Atari ST were called "Atari Low Level Game Routines")
* ANX&amp;nbsp;— ANX's Not [[Microsoft XNA|XNA]]
* [[AROS]]&amp;nbsp;— AROS Research Operating System (originally Amiga Research Operating System)
* BAMF&amp;nbsp;— BAMF Application Matching Framework
* [[Bird Internet routing daemon|BIRD]]&amp;nbsp;— BIRD Internet Routing Daemon
* BOSH&amp;nbsp;— Bosh Outer Shell
* [[Cave Automatic Virtual Environment|CAVE]]&amp;nbsp;— CAVE Automatic Virtual Environment
* [[cURL]]&amp;nbsp;— Curl URL Request Library&lt;ref&gt;{{cite web |url=http://daniel.haxx.se/blog/2015/03/20/curl-17-years-old-today/ |title=curl, 17 years old today |last1=Stenberg |first1=Daniel |date=20 March 2015 |website=daniel.haxx.se |publisher= |access-date=20 March 2015}}&lt;/ref&gt;
* [[EINE]]&amp;nbsp;— EINE Is Not Emacs
* [[FIJI (software)|FIJI]]&amp;nbsp;— FIJI Is Just [[ImageJ]]
* FYBMEM&amp;nbsp;— FYBMEM Your Basic Monitor Editor Mechanism
* [[Ginac computer algebra system|GiNaC]]&amp;nbsp;— GiNaC is Not a CAS (Computer Algebra System)
* [[GNU]]&amp;nbsp;— GNU's Not Unix
* [[GPE Palmtop Environment|GPE]]&amp;nbsp;— GPE Palmtop Environment
* [[gRPC]]&amp;nbsp;— grpc Remote Procedure Calls
* HIME&amp;nbsp;— HIME Input Method Editor&lt;ref name="HIME"&gt;{{cite web|url=https://github.com/caleb-/hime/|title=HIME Input Method Editor|accessdate=2012-06-15}}{{dead link|date=April 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;
* INX&amp;nbsp;— INX's Not X (a UNIX clone)
* [[JACK Audio Connection Kit|JACK]]&amp;nbsp;— JACK Audio Connection Kit
* [[Joe's Own Editor|JOE]]&amp;nbsp;— Joe's Own Editor
* [[KGS Go Server|KGS]]&amp;nbsp;— KGS Go Server
* [[LAME]]&amp;nbsp;— LAME Ain't an [[MP3]] Encoder&lt;ref name= "lame"&gt;{{cite web| url = http://lame.sourceforge.net/about.php | title = About LAME|accessdate=2016-02-20}}&lt;/ref&gt;
* [[LiVES]]&amp;nbsp;— LiVES is a Video Editing System
* [[Mega (website)|MEGA]]&amp;nbsp;— MEGA Encrypted Global Access&lt;ref&gt;{{cite web|title=MEGA|url=https://mega.co.nz/#help|accessdate=19 January 2013}}&lt;/ref&gt;
* [[Freemacs|MINT]]&amp;nbsp;— MINT Is Not [[TRAC programming language|TRAC]]
* [[MiNT]]&amp;nbsp;— MiNT is Not TOS (later changed to "MiNT is Now TOS")
* [[Mung (computer term)|Mung]]&amp;nbsp;— Mung Until No Good&lt;ref name= "mung"&gt;{{cite web|url= http://www.catb.org/jargon/html/M/mung.html| title = The Jargon File: Mung | | accessdate = 2007-10-15}}&lt;/ref&gt;
* [[GNU nano|Nano]]&amp;nbsp;— Nano's Another editor
* [[Nagios]]&amp;nbsp;— Nagios Ain't Gonna Insist On Sainthood (a reference to the previous name of Nagios, "Netsaint"; ''agios'' [αγιος] is the Greek word for "saint")
* [[NiL]]&amp;nbsp;— NiL Isn't Liero
* [[Ninja-ide]]&amp;nbsp;– Ninja-IDE Is Not Just Another IDE
* NITE&amp;nbsp;— NITE Isn't TECO Either (the 2nd offering from the creator of TINT)
* pacc&amp;nbsp;— pacc: a compiler-compiler&lt;ref name="pacc"&gt;{{cite web| url = http://paccrat.org/| title = pacc: a compiler-compiler| accessdate = 2012-05-14| archive-url = https://web.archive.org/web/20120718051203/http://paccrat.org/| archive-date = 2012-07-18| dead-url = yes| df = }}&lt;/ref&gt;
* [[PHP]]&amp;nbsp;— PHP: Hypertext Preprocessor (from "Personal Home Page Tools," more frequently referenced as "PHP Tools."&lt;ref name="History of PHP"&gt;{{cite web|title=History of PHP|url=http://www.php.net/manual/en/history.php.php|publisher=php.net}}&lt;/ref&gt;)
* [[Pine (e-mail client)|PINE]]&amp;nbsp;— PINE Is Nearly [[Elm (e-mail client)|Elm]], originally; PINE now officially stands for "Pine Internet News and E-mail"&lt;ref name="pine-origins"&gt;{{ cite web | url = http://www.island-resort.com/pine.htm | title = What Pine Really Stands For | accessdate = 2007-03-06 | deadurl = yes | archiveurl = https://web.archive.org/web/20110607212819/http://www.island-resort.com/pine.htm | archivedate = 2011-06-07 | df =  }}&lt;/ref&gt;
* [[Pip (Python)|PIP]]&amp;nbsp;— PIP Installs Packages
* [[Piper(software)|PIPER]]&amp;nbsp;— PIPER Is PIPER Expanded Recursively (Google's internal version control system)
* [[P.I.P.S.]]&amp;nbsp;— P.I.P.S. Is POSIX on Symbian
* Qins&amp;nbsp;— Qins is not Slow&lt;ref&gt;[http://www.qins.co.za/ QINS website]&lt;/ref&gt;
* [[RPM Package Manager|RPM]]&amp;nbsp;— RPM Package Manager (originally "[[Red Hat]] Package Manager")
* [[SPARQL]]&amp;nbsp;— SPARQL Protocol And RDF Query Language
* [[PGF/TikZ|TikZ]]&amp;nbsp;– TikZ ist kein Zeichenprogramm (German; TikZ is no drawing program)
* TIARA&amp;nbsp;— TIARA is a recursive acronym&lt;ref&gt;.EXE magazine, November 1996&lt;/ref&gt;
* [[TiLP]]&amp;nbsp;— TiLP is a Linking Program
* TIP&amp;nbsp;— TIP '''i'''sn't [[Pico (text editor)|Pico]]
* [[TRESOR]]&amp;nbsp;– TRESOR Runs Encryption Securely Outside RAM
* [[UIRA#UIRA|UIRA]] &amp;nbsp;— UIRA Isn't a Recursive Acronym
* [[Wine (software)|WINE]]&amp;nbsp;— WINE Is Not an Emulator&lt;ref name="wine"&gt;
{{cite web|url=http://wiki.winehq.org/FAQ#head-8b4fbbe473bd0d51d936bcf298f5b7f0e8d25f2e|title=FAQ – The Official Wine Wiki|accessdate=2009-01-16}}&lt;/ref&gt; (initially Windows Emulator)
* [[XAMPP]]&amp;nbsp;— XAMPP Apache MariaDB PHP Perl
* [[XBMC]]&amp;nbsp;— XBMC Media Center (originally Xbox Media Center)
* [[XINU]]&amp;nbsp;— Xinu Is Not Unix
* [[Microsoft XNA|XNA]]&amp;nbsp;— XNA's Not Acronymed
* [[YAML]]&amp;nbsp;— YAML Ain't Markup Language (initially "Yet Another Markup Language")
* [[Zinf]]&amp;nbsp;— Zinf Is Not FreeAmp
* [[ZWEI]]&amp;nbsp;— ZWEI Was [[EINE]] Initially (“eins” and “zwei” are German for “one” and “two” respectively)

===Mutually recursive or otherwise special===
* The [[GNU Hurd]] project is named with a mutually recursive acronym: "Hurd" stands for "Hird of Unix-Replacing [[Daemon (computer software)|Daemon]]s", and "Hird" stands for "Hurd of Interfaces Representing Depth."
* RPM, PHP, XBMC and YAML were originally conventional acronyms which were later redefined recursively. They are examples of, or may be referred to as, [[backronym]]ization,{{Citation needed|date=September 2010|reason=There's little evidence that this word exists outside of Wikipedia.}} where the official meaning of an acronym is changed.
* [[Jini]] claims the distinction of being the first recursive anti-acronym: 'Jini Is Not Initials'.&lt;ref&gt;[http://www.artima.com/jini/faq.html#acronym ''FAQ for JINI-USERS Mailing List''], Retrieved 18 November 2013&lt;/ref&gt;&lt;ref&gt;Introduction to ''The Jini Specification,'' Arnold et al, Pearson, 1999, {{ISBN|0201616343}}&lt;/ref&gt; It might, however, be more properly termed an anti-backronym because the term "Jini" never stood for anything in the first place. The more recent "[[Microsoft XNA|XNA]]", on the other hand, was deliberately designed that way.
* Most recursive acronyms are recursive on the first letter, which is therefore an arbitrary choice, often selected for reasons of humour, ease of pronunciation, or consistency with an earlier acronym that used the same letters for different words, such as PHP, which now stands for "PHP: Hypertext Preprocessor", but was originally "Personal Home Page".  However [[Yopy|YOPY]], "Your own personal YOPY" is recursive on the last letter (hence the last letter of the acronym had to be the same as the first).

==Organizations==
Some [[organization]]s have been named or renamed in this way:
* BWIA&amp;nbsp;— [[BWIA West Indies Airways]] (formerly British West Indian Airways)
* FAIR&amp;nbsp;— [[Fairness and Accuracy in Reporting]]
* FALE&amp;nbsp;— FALE Association of Locksport Enthusiasts&lt;ref name="bsideslv"&gt;{{cite web|url=http://www.bsideslv.org/bsideslv-2013-after-action-report/|title=FALE Association of Locksport Enthusiasts|accessdate=2014-02-12|archive-url=https://web.archive.org/web/20140222141938/http://www.bsideslv.org/bsideslv-2013-after-action-report/#|archive-date=2014-02-22|dead-url=yes|df=}}&lt;/ref&gt;&lt;ref name="lowtech"&gt;{{cite book|url=https://books.google.com/books?id=qb0BkZ3X1K8C&amp;pg=PA74&amp;lpg=PA74&amp;dq=winston+salem+FALE&amp;source=bl&amp;ots=VajoVS8BLc&amp;sig=z6UvBrDcLAiJHLjUtmHf2NPO7oI&amp;hl=en&amp;sa=X&amp;ei=vmz9Ur-pOqTuyAGL2YGwCA&amp;ved=0CGEQ6AEwBw#v=onepage&amp;q=winston%20salem%20FALE&amp;f=false |title=FALE Association of Locksport Enthusiasts|accessdate=2014-02-12}}&lt;/ref&gt;
* GES&amp;nbsp;— GES Exposition Services (formerly Greyhound Exposition Services)
* hEART&amp;nbsp;— hEART the European Association for Research in Transportation
* Heil&amp;nbsp;— Heil Environmental Industries Limited, maker of [[garbage truck]]s
* VISA&amp;nbsp;— [[Visa International Service Association]]
* WAT&amp;nbsp;— WAT Automotive Technologies

==In popular culture==
* TTP - a technology project in the ''[[Dilbert]]'' comic strip. The initials stand for "The TTP Project".&lt;ref&gt;{{cite web |title=Dilbert's TTP Project |url=http://dilbert.com/strip/1994-05-18 |website=Dilbert |accessdate=9 July 2018}}&lt;/ref&gt;
* [[Grunge|GRUNGE]] - defined by [[Homer Simpson]] in ''[[The Simpsons]]'' episode "[[That '90s Show]]" as "Guitar Rock Utilizing Nihilist Grunge Energy", another uncommon example of a recursive acronym whose recursive letter is not the first letter.
* [[KOS-MOS]] - a character from the [[Xenosaga]] series of video games. "KOS-MOS" is a recursive acronym meaning "Kosmos Obey Strategical Multiple Operating Systems". It's unclear if it counts as a true recursive acronym, however, as the Kosmos referred to in the acronym may simply be an alternate spelling of [[cosmos]].

==See also==
* [[RAS syndrome]] (Redundant Acronym Syndrome syndrome)
* [[Self-reference]]
* [[Web Ontology Language]], which intentionally uses the acronym "OWL"

==References==
{{Reflist|30em}}

===General===
*{{JargonFile}}

==External links==
*{{Wiktionary-inline|recursive acronym}}

{{DEFAULTSORT:Recursive Acronym}}
[[Category:Acronyms| Recursive]]
[[Category:Recursion]]
[[Category:Rhetoric]]
[[Category:Self-reference]]
[[Category:Types of words]]
[[Category:Word play]]

[[it:Acronimo#Acronimo ricorsivo]]</text>
      <sha1>hto3mmdmlvukm7pyq5y7nliucnoztjv</sha1>
    </revision>
  </page>
  <page>
    <title>Ruled surface</title>
    <ns>0</ns>
    <id>705158</id>
    <revision>
      <id>868303751</id>
      <parentid>867915754</parentid>
      <timestamp>2018-11-11T09:53:09Z</timestamp>
      <contributor>
        <username>Ag2gaeh</username>
        <id>18237910</id>
      </contributor>
      <minor/>
      <comment>/* Examples */ remark on developable Möbius strips inserted</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17959">[[File:Bez-regelfl0.svg|300px|thumb|Definition of a ruled surface: any point lies on a line]]
In [[geometry]], a [[surface (mathematics)|surface]] ''S'' is '''ruled''' (also called a '''scroll''') if 
* through every point of ''S'' there is a straight line that lies on ''S''.  
Examples include the [[plane (mathematics)|plane]], the curved surface of a [[cylinder (geometry)|cylinder]] or [[cone (geometry)|cone]], a [[conical surface]] with [[ellipse|elliptical]] [[directrix (rational normal scroll)|directrix]], the [[right conoid]], the [[helicoid]], and the [[tangent developable]] of a smooth [[curve]] in space.

A ruled surface can be described as the set of points swept by a  moving straight line.  For example, a cone is formed by keeping one point of a line fixed whilst moving another point along a [[circle]]. A surface is ''doubly ruled'' if through every one of its points there are two distinct lines that lie on the surface.  The [[hyperbolic paraboloid]] and the [[hyperboloid of one sheet]] are doubly ruled surfaces. The plane is the only surface which contains at least three distinct lines through each of its points {{harv|Fuks|Tabachnikov|2007}}.

The properties of being ruled or doubly ruled are preserved by [[projective map]]s, and therefore are concepts of [[projective geometry]]. In algebraic geometry ruled surfaces are sometimes considered to be surfaces in affine or projective space over a field, but they are also sometimes considered as abstract algebraic surfaces without an embedding into affine or projective space, in which case "straight line" is understood to mean an affine or projective line.

== Definition and parametric representation ==
[[File:Bez-regelfl.svg|300px|thumb|Ruled surface generated by two Bezier curves as directrices (red, green)]]
; Definition
*A two dimensional [[manifold#differetiable manifold|differentiable manifold]] is called '''ruled surface''', if it is the [[set (mathematics)#unions|union]] of a one parametric family of lines. The lines of this family are the ''generators'' of the ruled surface.

;Parametric representation
A ruled surface can be described by a ''parametric representation'' of the form 
* '''(CR)''' &lt;math&gt;\quad \mathbf x(u,v)= {\color{red}\mathbf c(u)} + v\;{\color{blue}\mathbf r(u)}\ ,\ v\in \R \ , &lt;/math&gt;. 
Any curve &lt;math&gt;\;v\mapsto \mathbf x(u_0,v)\;&lt;/math&gt; with fixed parameter &lt;math&gt; u=u_0&lt;/math&gt; is a generator (line) and the curve &lt;math&gt;\; u\mapsto \mathbf c(u) \;&lt;/math&gt; is the ''directrix'' of the representation. The vectors &lt;math&gt;\; \mathbf r(u)\ne \bf 0\; &lt;/math&gt; describe the directions of the generators.

The directrix may collapse to a point (in case of a cone, see example below).

Alternatively the ruled surface '''(CR)''' can be described by
* '''(CD)''' &lt;math&gt; \quad \mathbf x(u,v)= (1-v)\;{\color{red}\mathbf c(u)} + v\; {\color{green}\mathbf d(u)}\ &lt;/math&gt;

with the second directrix &lt;math&gt;\; \mathbf d(u)= \mathbf c(u) + \mathbf r(u)\;&lt;/math&gt;.
 
Alternatively, one can start with two non intersecting curves &lt;math&gt;\mathbf c(u), \mathbf d(u)&lt;/math&gt; as directrices, and get by '''(CD)''' a ruled surface with line directions &lt;math&gt;\; \mathbf r(u)= \mathbf d(u) - \mathbf c(u)\ .&lt;/math&gt;

For the generation of a ruled surface by two directrices (or one directrix and the vectors of line directions) not only the geometric shape of these curves are essential but also the special parametric representations of them influence the shape of the ruled surface (see examples a), d)).

For theoretical investigations representation '''(CR)''' is more advantageous, because the parameter &lt;math&gt; v &lt;/math&gt; appears only once.

== Examples == 
[[File:Regelfl-zk.svg|250px|thumb|cylinder, cone]]
'''a) [[Right circular cylinder]]''' &lt;math&gt;\ x^2+y^2=a^2\ &lt;/math&gt;:

:&lt;math&gt; \mathbf x(u,v)=(a\cos u,a\sin u,v)^T&lt;/math&gt;
:::&lt;math&gt;= {\color{red}(a\cos u,a\sin u,0)^T}\; +\; v\;{\color{blue}(0,0,1)^T} &lt;/math&gt;
:::&lt;math&gt;= (1-v)\;{\color{red}(a\cos u,a\sin u,0)^T}\; + \; v\;{\color{green}(a\cos u,a\sin u,1)^T} \ .&lt;/math&gt;
with  
:&lt;math&gt;\mathbf c(u) =(a\cos u,a\sin u,0)^T\ , \ \mathbf r(u)=(0,0,1)^T \ , \ \mathbf d(u)= (a\cos u,a\sin u,1)^T \ . &lt;/math&gt;

'''b) [[Right circular cone]]''' &lt;math&gt;\ x^2+y^2=z^2\ &lt;/math&gt;:

:&lt;math&gt; \mathbf x(u,v)=(\cos u,\sin u,1)^T\; +\; v\;(\cos u,\sin u,1)^T &lt;/math&gt;
:::&lt;math&gt;= (1-v)\;(\cos u,\sin u,1)^T\; + \; v\;(2\cos u,2\sin u,2)^T .&lt;/math&gt;
with &lt;math&gt;\quad  \mathbf c(u) =(\cos u,\sin u,1)^T\; = \; \mathbf r(u) \ , \quad \mathbf d(u)= (2\cos u,2\sin u,2)^T \ . &lt;/math&gt;&lt;br&gt;
In this case one could have used the apex as the directrix, i.e.: &lt;math&gt;\ \mathbf c(u) = (0,0,0)^T\ &lt;/math&gt; and &lt;math&gt; \ \mathbf r(u)=(\cos u,\sin u,1)^T\ &lt;/math&gt; as the line directions.

For any cone one can choose the apex as the directrix. This case shows: ''The directrix of a ruled surface may degenerate to a point''.

[[File:Wendelfl-regelfl.svg|thumb|helicoid]]
'''c) [[Helicoid]]''':

:&lt;math&gt;\mathbf x(u,v)=\;(v\cos u,v\sin u, ku)^T\;&lt;/math&gt;
:::&lt;math&gt; = \; (0,0,ku)^T \; +\; v\;(\cos u, \sin u,0)^T\ &lt;/math&gt;
:::&lt;math&gt; = \; (1-v)\;(0,0,ku)^T \; + \; v\; (\cos u,\sin u, ku)^T \ .&lt;/math&gt;
The directrix &lt;math&gt;\  \mathbf c(u) =(0,0,ku)^T\;&lt;/math&gt; is the z-axis, the line directions are &lt;math&gt;  \; \mathbf r(u) =\ (\cos u, \sin u,0)^T \; &lt;/math&gt; and the second directrix &lt;math&gt; \ \mathbf d(u)=(\cos u,\sin u, ku)^T \ &lt;/math&gt; is a [[helix]].

The helicoid is a special case of the [[Generalized helicoid#Ruled generalized helicoids|ruled generalized helicoids]].

'''d) Cylinder, cone and [[hyperboloid]]s:'''

[[File:Regelfl-phi-h.svg|280px|thumb|hyperboloid of one sheet for &lt;math&gt;\varphi=63^\circ&lt;/math&gt;]]
The parametric representation 
:&lt;math&gt;\mathbf x(u,v)= (1-v)\;(\cos (u-\varphi),\sin (u-\varphi),-1)^T\; + \; v\;(\cos (u+\varphi),\sin(u+\varphi),1)^T &lt;/math&gt;
has two horizontal circles as directrices. The additional parameter &lt;math&gt;\varphi&lt;/math&gt; allows to vary the parametric representations of the circles. For
:&lt;math&gt; \varphi=0 \ &lt;/math&gt; one gets the cylinder &lt;math&gt;x^2+y^2=1&lt;/math&gt;, for
:&lt;math&gt; \varphi=\pi/2 \ &lt;/math&gt; one gets the cone &lt;math&gt;x^2+y^2=z^2&lt;/math&gt; and for
:&lt;math&gt; 0&lt;\varphi&lt;\pi/2 \ &lt;/math&gt; one gets a hyperboloid of one sheet with equation &lt;math&gt;\ \tfrac{x^2+y^2}{a^2}-\tfrac{z^2}{c^2}=1 \ &lt;/math&gt; and the semi axes &lt;math&gt; \ a=\cos\varphi\;,\; c=\cot\varphi&lt;/math&gt;.

A hyperboloid of one sheet is a ''doubly'' ruled surface.

[[File:Hyp-paraboloid-ip.svg|250px|thumb|Hyperbolic paraboloid]]
'''e) [[Hyperbolic paraboloid]]:'''

If the two directrices in '''(CD)''' are the lines 
:&lt;math&gt; \mathbf c(u) =(1-u)\mathbf a_1 + u\mathbf a_2, \quad \mathbf d(u)=(1-u)\mathbf b_1 + u\mathbf b_2 &lt;/math&gt;
one gets 
:&lt;math&gt;\mathbf x(u,v)=(1-v)\big((1-u)\mathbf a_1 + u\mathbf a_2\big)\ +\ 
    v\big((1-u)\mathbf b_1 + u\mathbf b_2\big)\ &lt;/math&gt;,
which is the hyperbolic paraboloid that interpolates the 4 points &lt;math&gt;\ \mathbf a_1,\;\mathbf a_2,\;\mathbf b_1,\;\mathbf b_2\ &lt;/math&gt; bilinearly.&lt;ref&gt;G. Farin: ''Curves and Surfaces for Computer Aided Geometric Design'', Academic Press, 1990, {{ISBN|0-12-249051-7}}, p. 250&lt;/ref&gt;

Obviously the ruled surface is a ''doubly ruled surface'', because any point lies on two lines of the surface.

For the example shown in the diagram: 
:&lt;math&gt;\ \mathbf a_1=(0,0,0)^T,\;\mathbf a_2=(1,0,0)^T,\;\mathbf b_1=(0,1,0)^T,\;\mathbf b_2=(1,1,1)^T\ &lt;/math&gt;.
The hyperbolic paraboloid has the equation &lt;math&gt; z=xy&lt;/math&gt;.

[[File:Moebius-str.svg|thumb|Möbius strip]]
'''f) [[Möbius strip]]: '''

The ruled surface
:&lt;math&gt;\mathbf x(u,v)= \mathbf c(u) + v\;\mathbf r(u) &lt;/math&gt; 
with  
:&lt;math&gt;\mathbf c(u) =(\cos2u,\sin2u,0)^T\ &lt;/math&gt; (circle as directrix),
:&lt;math&gt;\mathbf r(u)=( \cos u \cos 2 u , \cos u \sin 2 u, \sin u )^T \ , \quad 0\le u&lt; \pi\ ,&lt;/math&gt;
contains a Möbius strip.

The diagram shows the Möbius strip for &lt;math&gt; -0.3\le v \le 0.3 &lt;/math&gt;.

A simple calculation shows &lt;math&gt;\det(\mathbf \dot c(0)\;,\;\mathbf \dot r(0)\;, \;\mathbf r(0)) \; \ne \; 0 \ &lt;/math&gt; (see next section). Hence the given realization of a Möbius strip is ''not developable''. But there exist developable Möbius strips &lt;ref&gt;W. Wunderlich: ''Über ein abwickelbares Möbiusband'', Monatshefte für Mathematik 66, 1962, S. 276-289.&lt;/ref&gt;.

== Tangent planes, developable surfaces  ==
For the considerations below any necessary derivative is supposed to exist..

For the determination of the normal vector at a point one needs the [[partial derivative]]s of the representation &lt;math&gt;\quad \mathbf x(u,v)= \mathbf c(u) + v\;\mathbf r(u)&lt;/math&gt; :
:&lt;math&gt;\mathbf x_u= \mathbf \dot c(u)+ v\;\mathbf \dot r(u)\ &lt;/math&gt; ,&lt;math&gt;\quad \mathbf x_v= \;\mathbf r(u)&lt;/math&gt; 
Hence the normal vector is 
*&lt;math&gt;\mathbf n= \mathbf x_u \times \mathbf x_u =  \mathbf \dot c\times  \mathbf r + v( \mathbf \dot r \times \mathbf r) \ .&lt;/math&gt;
Because of  &lt;math&gt; \mathbf n \cdot \mathbf r = 0&lt;/math&gt; (A mixed product with two equal vectors is always 0 !), vector &lt;math&gt;\mathbf r (u_0) &lt;/math&gt; is a tangent vector at any point &lt;math&gt; \mathbf x(u_0,v)&lt;/math&gt;. The tangent planes along this line are all the same, if &lt;math&gt; \mathbf \dot r \times \mathbf r  &lt;/math&gt; is a muliple of &lt;math&gt; \mathbf \dot c\times  \mathbf r &lt;/math&gt; . This is possible only , if the three vectors &lt;math&gt; \mathbf \dot c\; ,\; \mathbf \dot r\;,\; \mathbf r\ &lt;/math&gt; lie in a plane, i.e. they are linear dependent. The linear dependency of three vectors can be checked using the determinant of these vectors:

*The tangent planes along the line &lt;math&gt; \mathbf x(u_0,v)= \mathbf c(u_0) + v\;\mathbf r(u_0)&lt;/math&gt; are equal, if 
:: &lt;math&gt;\det(\mathbf \dot c(u_0)\;,\;\mathbf \dot r(u_0)\;, \;\mathbf r(u_0)) \; = \; 0 \ .&lt;/math&gt;

The importance of this determinant condition shows the following statement:
*A ruled surface &lt;math&gt;\quad \mathbf x(u,v)= \mathbf c(u) + v\;\mathbf r(u)&lt;/math&gt; is '''developable''' into a plane, if for any point  the [[Gauss curvature]] vanishes. This is exactly the case if 
:::&lt;math&gt;\det(\mathbf \dot c\;,\;\mathbf \dot r\;, \;\mathbf r) \; = \; 0 \quad &lt;/math&gt; 
:at any point is true.&lt;ref&gt;W. Kühnel: ''Differentialgeometrie'', p. 58–60&lt;/ref&gt;

''' Properties of developable surfaces:&lt;ref&gt;G. Farin: p. 380&lt;/ref&gt;

* The generators of any ruled surface coalesce with one family of its asymptotic lines. Also forming one family of its [[Line of curvature|lines of curvature]].
*It can be shown that ''any developable'' surface is a cone, a cylinder or a surface formed by all tangents of a space curve.

== Further examples ==
* [[Conoid]]
* [[Catalan surface]]
* [[Oloid]]

== Application and History of developable surfaces ==
[[File:Torse-ee.svg|350px|thumb|Developable conection of two ellipses and its development]]
The determinant condition for developable surfaces is used to determine numerically developable connections between space curves (directrices). The diagram shows a developable connection between two ellipses contained in different planes (one horizontal, the other vertical) and its development.&lt;ref&gt;[https://www2.mathematik.tu-darmstadt.de/~ehartmann/cdgen0104.pdf E. Hartmann: ''Geometry and Algorithms for CAD'', lecture note, TU Darmstadt , p.&amp;nbsp;113]&lt;/ref&gt;

An impression of the usage of developable surfaces in ''Computer Aided Design'' ([[CAD]]) is given in  ''Interactive design of developable surfaces''&lt;ref&gt;[http://www.geometrie.tugraz.at/wallner/abw.pdf Tang,Bo, Wallner, Pottmann: ''Interactive design of developable surfaces'',ACM Trans. Graph. (MONTH 2015), DOI: 10.1145/2832906]&lt;/ref&gt;

A ''historical'' survey on developable surfaces can be found in ''Developable Surfaces: Their History and Application''&lt;ref&gt;[https://www.researchgate.net/publication/257314770_Developable_Surfaces_Their_History_and_Application Snezana Lawrence: ''Developable Surfaces: Their History and Application'', in  Nexus Network Journal 13(3) · October 2011, DOI: 10.1007/s00004-011-0087-z]&lt;/ref&gt;

==Ruled surfaces in algebraic geometry==
{{Main|Ruled variety}}
In [[algebraic geometry]], ruled surfaces were originally defined as [[projective surface]]s in [[projective space]] containing a straight line through any given point. This immediately implies that there is a projective line on the surface through any given point, and this condition is now often used as the definition of a ruled surface: ruled surfaces are  defined to be abstract projective surfaces satisfying this condition that there is a projective line through any point. This is equivalent to saying that they are [[birational]] to the product of a curve and a projective line. Sometimes a ruled surface is defined to be one satisfying the  stronger condition that it has a [[fibration]] over a curve with fibers that are projective lines. This excludes the projective plane, which has a projective line though every point but cannot be written as such a fibration.

Ruled surfaces appear in the [[Enriques classification]] of projective complex surfaces, because every algebraic surface of [[Kodaira dimension]] &lt;math&gt;-\infty&lt;/math&gt; is a ruled surface (or a projective plane, if one uses the restrictive definition of ruled surface). 
Every minimal projective ruled surface other than the projective plane is the projective bundle of a 2-dimensional vector bundle over some curve. The ruled surfaces with base curve of genus 0 are the [[Hirzebruch surface]]s.

==Ruled surfaces in architecture==
Doubly ruled surfaces are the inspiration for curved [[hyperboloid structure]]s that can be built with a [[latticework]] of straight elements, namely:
* Hyperbolic paraboloids, such as [[saddle roof]]s.
* Hyperboloids of one sheet, such as [[cooling tower]]s and some [[waste container|trash bin]]s.

The [[RM-81 Agena]] [[rocket engine]] employed straight [[cooling channel]]s that were laid out in a ruled surface to form the throat of the [[nozzle]] section.
&lt;gallery&gt;
File:Didcot power station cooling tower zootalures.jpg|Cooling [[Hyperboloid structure|hyperbolic towers]] at [[Didcot Power Station]], UK; the surface can be doubly ruled.
File:Ciechanow water tower.jpg|Doubly ruled water tower with [[Toroid (geometry)|toroidal]] tank, by Jan Bogusławski in [[Ciechanów]], Poland
File:Kobe port tower11s3200.jpg|A hyperboloid [[Kobe Port Tower]], [[Kobe]], Japan, with a double ruling.
File:First Shukhov Tower Nizhny Novgorod 1896.jpg| Hyperboloid water tower, 1896 in [[Nizhny Novgorod]].
File:Shukhov tower shabolovka moscow 02.jpg|The [[gridshell]] of [[Shukhov Tower]] in Moscow, whose sections are doubly ruled. 
File:Cremona, torrazzo interno 02 scala a chiocciola.JPG|A ruled helicoid spiral staircase inside [[Cremona]]'s [[Torrazzo of Cremona|Torrazzo]].
File:Nagytotlak.JPG|Village church in Selo, Slovenia: both the roof (conical) and the wall (cylindrical) are ruled surfaces.
File:W-wa Ochota PKP-WKD.jpg|A [[paraboloid|hyperbolic paraboloid]] roof of [[Warszawa Ochota railway station]] in [[Warsaw]], Poland.
File:Aodai-nonla-crop.jpg|A ruled [[Pointed hat|conical hat]].
File:Corrugated-fibro-roofing.jpg|Corrugated roof tiles ruled by parallel lines in one direction, and [[sinusoidal]] in the perpendicular direction
File:US Navy 091022-N-2571C-042 Seabees use a long board to screed wet concrete.jpg|Construction of a planar surface by ruling ([[screed]]ing) concrete
&lt;/gallery&gt;

== References ==
&lt;References/&gt;
* Do Carmo, Manfredo P. : ''Differential Geometry of Curves and Surfaces'', Prentice-Hall; 1 edition, 1976 {{ISBN|978-0132125895}}
*{{Citation | last1=Barth | first1=Wolf P. | last2=Hulek | first2=Klaus | last3=Peters | first3=Chris A.M. | last4=Van de Ven | first4=Antonius | title=Compact Complex Surfaces | publisher= Springer-Verlag, Berlin | series=Ergebnisse der Mathematik und ihrer Grenzgebiete. 3. Folge. | isbn=978-3-540-00832-3 |mr=2030225 | year=2004 | volume=4 | doi=10.1007/978-3-642-57739-0}} 
*{{Citation | last1=Beauville | first1=Arnaud | title=Complex algebraic surfaces | publisher=[[Cambridge University Press]] | edition=2nd | series=London Mathematical Society Student Texts | isbn=978-0-521-49510-3 |mr=1406314 | year=1996 | volume=34 | doi=10.1017/CBO9780511623936}}
*{{citation|first=W. L.|last= Edge |authorlink= William Edge (mathematician)
|title=The Theory of Ruled Surfaces
|url=https://archive.org/details/theoryofruledsur029537mbp
|via=[[Internet Archive]]
|publisher=Cambridge University Press|year= 1931}}.  Review: ''[[Bulletin of the American Mathematical Society]]'' 37 (1931), 791-793, {{doi|10.1090/S0002-9904-1931-05248-4}}
*{{citation|title=Mathematical Omnibus: Thirty Lectures on Classic Mathematics|first1=D. B.|last1=Fuks|first2=Serge|last2=Tabachnikov|author2-link=Sergei Tabachnikov|publisher=American Mathematical Society|year=2007|isbn=9780821843161|page=228|url=https://books.google.com/books?id=IiG9AwAAQBAJ&amp;pg=PA228|contribution=16.5 There are no non-planar triply ruled surfaces}}.
* {{Citation | last1=Hilbert | first1=David | author1-link=David Hilbert | last2=Cohn-Vossen | first2=Stephan | author2-link=Stephan Cohn-Vossen | title=Geometry and the Imagination | publisher=Chelsea | location=New York | edition=2nd | isbn=978-0-8284-1087-8 | year=1952 }}.
*{{SpringerEOM |id=R/r082790 |title=Ruled surface |first=V.A. |last=Iskovskikh}}
*{{citation|first=John|last= Sharp
|title=D-Forms: surprising new 3-D forms from flat curved shapes|publisher=Tarquin|year= 2008|isbn=978-1-899618-87-3}}.  Review: Séquin, Carlo H. (2009), ''Journal of Mathematics and the Arts'' 3: 229–230, {{doi|10.1080/17513470903332913}}

==External links==
* {{MathWorld |title=Ruled Surface |id=RuledSurface}}
* [http://math.arizona.edu/~models/Ruled_Surfaces Ruled surface pictures from the University of Arizona]
* [http://www.rhino3.de/design/modeling/developable/ Examples of developable surfaces on the Rhino3DE website]

[[Category:Surfaces]]
[[Category:Differential geometry]]
[[Category:Differential geometry of surfaces]]
[[Category:Complex surfaces]]
[[Category:Algebraic surfaces]]
[[Category:Geometric shapes]]
[[Category:Analytic geometry]]</text>
      <sha1>3naf6rg9or5uddffdolozpycwb2rphq</sha1>
    </revision>
  </page>
  <page>
    <title>Scale invariance</title>
    <ns>0</ns>
    <id>695241</id>
    <revision>
      <id>840211762</id>
      <parentid>812945144</parentid>
      <timestamp>2018-05-08T12:41:46Z</timestamp>
      <contributor>
        <username>Allforrous</username>
        <id>12120664</id>
      </contributor>
      <comment>added [[Category:Scale-invariant systems]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32189">[[File:Wiener process animated.gif|thumb|right|500px|The [[Wiener process]] is scale-invariant.]]

In [[physics]], [[mathematics]], [[statistics]], and [[economics]], '''scale invariance''' is a feature of objects or laws that do not change if scales of length, energy, or other variables, are multiplied by a common factor, thus represent a universality.

The technical term for this [[transformation (mathematics)|transformation]] is a '''dilatation''' (also known as '''dilation'''), and the dilatations can also form part of a larger [[conformal symmetry]].

*In mathematics, scale invariance usually refers to an invariance of individual [[function (mathematics)|functions]] or [[curve]]s. A closely related concept is [[self-similarity]], where a function or curve is invariant under a discrete subset of the dilatations. It is also possible for the [[probability distribution]]s of [[random process]]es to display this kind of scale invariance or self-similarity.
*In [[classical field theory]], scale invariance most commonly applies to the invariance of a whole theory under dilatations. Such theories typically describe classical physical processes with no characteristic length scale.
*In [[quantum field theory]], scale invariance has an interpretation in terms of [[particle physics]]. In a scale-invariant theory, the strength of particle interactions does not depend on the energy of the particles involved.
*In [[statistical mechanics]], scale invariance is a feature of [[phase transition]]s. The key observation is that near a phase transition or [[critical point (thermodynamics)|critical point]], fluctuations occur at all length scales, and thus one should look for an explicitly scale-invariant theory to describe the phenomena. Such theories are scale-invariant [[statistical field theory|statistical field theories]], and are formally very similar to scale-invariant quantum field theories.
*[[universality (dynamical systems)|Universality]] is the observation that widely different microscopic systems can display the same behaviour at a phase transition. Thus phase transitions in many different systems may be described by the same underlying scale-invariant theory.
*In general, [[dimensionless quantities]] are scale invariant. The analogous concept in [[statistics]] are [[standardized moment]]s, which are scale invariant statistics of a variable, while the unstandardized moments are not.

==Scale-invariant curves and self-similarity==
In mathematics, one can consider the scaling properties of a [[function (mathematics)|function]] or [[curve]] {{math|''f'' (''x'')}} under rescalings of the variable {{mvar|x}}.  That is, one is interested in the shape of {{math|''f'' (''λx'')}} for some scale factor {{mvar|λ}}, which can be taken to be a length or size rescaling. The requirement for  {{math|''f'' (''x'')}} to be invariant under all rescalings is usually taken to be
:&lt;math&gt;f(\lambda x)=\lambda^{\Delta}f(x)&lt;/math&gt;
for some choice of exponent {{mvar|Δ}}, and for all dilations {{mvar|λ}}. This is equivalent to {{mvar|f}} &amp;nbsp;  being a [[homogeneous function]] of degree {{mvar|Δ}}.

Examples of scale-invariant functions are the [[monomial]]s &lt;math&gt;f(x)=x^n&lt;/math&gt;, for which {{math|Δ {{=}} ''n''}}, in that clearly

:&lt;math&gt;f(\lambda x) = (\lambda x)^n = \lambda^n f(x)~.&lt;/math&gt;

An example of a scale-invariant curve is the [[logarithmic spiral]], a kind of curve that often appears in nature. In [[polar coordinates]] {{math|(''r'', ''θ'')}}, the spiral can be written as

:&lt;math&gt;\theta = \frac{1}{b} \ln(r/a)~.&lt;/math&gt;

Allowing for rotations of the curve, it is invariant under all rescalings {{mvar|λ}}; that is, {{math|''θ''(''λr'')}} is identical to a rotated version of {{math|''θ''(''r'')}}.

===Projective geometry===
The idea of scale invariance of a monomial generalizes in higher dimensions to the idea of a [[homogeneous polynomial]], and more generally to a [[homogeneous function]]. Homogeneous functions are the natural denizens of [[projective space]], and homogeneous polynomials are studied as [[projective varieties]] in [[projective geometry]].  Projective geometry is a particularly rich field of mathematics; in its most abstract forms, the geometry of [[scheme (mathematics)|schemes]], it has connections to various topics in [[string theory]].

===Fractals===
[[File:Kochsim.gif|thumb|right|250px|A [[Koch curve]] is [[self-similar]].]]
It is sometimes said that [[fractal]]s are scale-invariant, although more precisely, one should say that they are [[self-similar]]. A fractal is equal to itself typically for only a discrete set of values {{mvar|λ}}, and even then a translation and rotation may have to be applied to match the fractal up to itself.

Thus, for example, the [[Koch curve]] scales with {{math|∆ {{=}} 1}}, but the scaling holds only for values of {{math|''λ'' {{=}} 1/3&lt;sup&gt;''n''&lt;/sup&gt;}} for integer {{mvar|n}}. In addition, the Koch curve scales not only at the origin, but, in a certain sense, "everywhere": miniature copies of itself can be found all along the curve.

Some fractals may have multiple scaling factors at play at once; such scaling is studied with [[multi-fractal analysis]].

Periodic [[External ray|external and internal rays]] are invariant curves .

==Scale invariance in stochastic processes==
If {{math|''P''(''f'' )}} is the [[expectation value|average, expected]] power at frequency {{mvar|f }}, then noise scales as
:&lt;math&gt;P(f) = \lambda^{-\Delta} P(\lambda f)&lt;/math&gt;
with {{mvar|Δ}} = 0  for [[white noise]],  {{mvar|Δ}} = −1  for [[pink noise]], and  {{mvar|Δ}} = −2  for [[Brownian noise]] (and more generally, [[Brownian motion]]).

More precisely, scaling in stochastic systems concerns itself with the likelihood of choosing a particular configuration out of the set of all possible random configurations. This likelihood is given by the [[probability distribution]].

Examples of scale-invariant distributions are the [[Pareto distribution]] and the [[Zipfian distribution]].

===Scale invariant Tweedie distributions===
'''[[Tweedie distributions]]''' are a special case of '''[[exponential dispersion model]]s''', a class of statistical models used to describe error distributions for the [[generalized linear model]] and characterized by [[Closure (mathematics)|closure]] under additive and reproductive convolution as well as under scale transformation.&lt;ref name="Jørgensen1997"&gt;{{cite book |last=Jørgensen |first=B. |year=1997 |title=The Theory of Dispersion Models |publisher=Chapman &amp; Hall |location=London |isbn=0412997118 }}&lt;/ref&gt;  These include a number of common distributions: the [[normal distribution]], [[Poisson distribution]] and [[gamma distribution]], as well as more unusual distributions like the compound Poisson-gamma distribution, positive [[stable distribution]]s, and extreme stable distributions.
Consequent to their inherent scale invariance Tweedie [[random variable]]s ''Y'' demonstrate a [[variance]] var(''Y'') to [[mean]] E(''Y'')  power law:
: &lt;math&gt;\text{var}\,(Y) = a[\text{E}\,(Y)]^p&lt;/math&gt;,
where ''a'' and ''p'' are positive constants. This variance to mean power law is known in the physics literature as '''fluctuation scaling''',&lt;ref name="Eisler2008"&gt;{{cite journal |last=Eisler |first=Z. |last2=Bartos |first2=I. |last3=Kertész |first3=J. |year=2008 |title=Fluctuation scaling in complex systems: Taylor's law and beyond |journal=[[Advances in Physics|Adv Phys]] |volume=57 |issue=1 |pages=89–142 |doi=10.1080/00018730801893043 |arxiv = 0708.2053 |bibcode = 2008AdPhy..57...89E }}&lt;/ref&gt; and in the ecology literature as [[Taylor's law]].&lt;ref name="Kendal2011a"&gt;{{cite journal |last=Kendal |first=W. S. |last2=Jørgensen |first2=B. |year=2011 |title=Taylor's power law and fluctuation scaling explained by a central-limit-like convergence |journal=Phys. Rev. E |volume=83 |issue=6 |pages=066115 |doi=10.1103/PhysRevE.83.066115 |bibcode = 2011PhRvE..83f6115K }}&lt;/ref&gt;

Random sequences, governed by the Tweedie distributions and evaluated by the [[Tweedie distributions|method of expanding bins]] exhibit a [[Logical biconditional|biconditional]] relationship between the variance to mean power law and power law [[autocorrelation]]s.  The [[Wiener–Khinchin theorem]] further implies that for any sequence that exhibits a variance to mean power law under these conditions will also manifest [[pink noise|''1/f'' noise]].&lt;ref name="Kendal2011"&gt;{{cite journal |last=Kendal |first=W. S. |last2=Jørgensen |first2=B. |year=2011 |title=Tweedie convergence: A mathematical basis for Taylor's power law, 1/''f'' noise, and multifractality |journal=Phys. Rev. E |volume=84 |issue=6 |pages=066120 |doi=10.1103/PhysRevE.84.066120 |bibcode = 2011PhRvE..84f6120K |pmid=22304168}}&lt;/ref&gt;

The [[Tweedie distributions|'''Tweedie convergence theorem''']] provides a hypothetical explanation for the wide manifestation of fluctuation scaling and ''1/f'' noise.&lt;ref name="Jørgensen1994"&gt;{{cite journal |last=Jørgensen |first=B. |last2=Martinez |first2=J. R. |last3=Tsao |first3=M. |year=1994 |title=Asymptotic behaviour of the variance function |journal=[[Scandinavian Journal of Statistics|Scand J Statist]] |volume=21 |issue=3 |pages=223–243 |jstor=4616314 }}&lt;/ref&gt; It requires, in essence, that any exponential dispersion model that asymptotically manifests a variance to mean power law will be required express a [[natural exponential family|variance function]] that comes within the [[Attractor|domain of attraction]] of a Tweedie model.  Almost all distribution functions with finite [[cumulant|cumulant generating functions]] qualify as exponential dispersion models and most exponential dispersion models manifest variance functions of this form.  Hence many probability distributions have variance functions that express this [[Asymptotic expansion|asymptotic behavior]], and  the Tweedie distributions become foci of convergence for a wide range of data types.&lt;ref name="Kendal2011" /&gt;

Much as the [[central limit theorem]] requires certain kinds of random variables to have as a focus of convergence the [[normal distribution|Gaussian distribution]] and express [[white noise]], the Tweedie convergence theorem requires certain non-Gaussian random variables to express ''1/f'' noise and fluctuation scaling.&lt;ref name="Kendal2011" /&gt;

===Cosmology===&lt;!-- This section is linked from [[Cosmic inflation]] --&gt;
In [[physical cosmology]], the power spectrum of the spatial distribution of the [[cosmic microwave background]] is near to being a scale-invariant function. Although in mathematics this means that the spectrum is a power-law, in cosmology the term "scale-invariant" indicates that the amplitude, {{math|''P''(''k'')}}, of [[primordial fluctuations]] as a function of [[wave number]], {{mvar|k}}, is approximately constant, i.e. a flat spectrum. This pattern is consistent with the proposal of [[cosmic inflation]].

==Scale invariance in classical field theory==
[[Classical field theory]] is generically described by a field, or set of fields,  ''φ'', that depend on coordinates, ''x''. Valid field configurations are then determined by solving [[differential equations]] for ''φ'', and these equations are known as [[field equation]]s.

For a theory to be scale-invariant, its field equations should be invariant under a rescaling of the coordinates, combined with some specified rescaling of the fields,
:&lt;math&gt;x\rightarrow\lambda x~,&lt;/math&gt;
:&lt;math&gt;\varphi\rightarrow\lambda^{-\Delta}\varphi~.&lt;/math&gt;

The parameter ''Δ'' is known as the [[scaling dimension]] of the field, and its value depends on the theory under consideration.  Scale invariance will typically hold provided that no fixed length scale appears in the theory. Conversely, the presence of a fixed length scale indicates that a theory is '''not''' scale-invariant.

A consequence of scale invariance is that given a solution of a scale-invariant field equation, we can automatically find other solutions by rescaling both the coordinates and the fields appropriately. In technical terms, given a solution,  ''φ''(''x''), one always has other solutions of the form

:&lt;math&gt;\lambda^{\Delta}\varphi(\lambda x)&lt;/math&gt;.

===Scale invariance of field configurations===
For a particular field configuration,  ''φ''(''x''),  to be scale-invariant, we require that
:&lt;math&gt;\varphi(x)=\lambda^{-\Delta}\varphi(\lambda x)&lt;/math&gt;

where ''Δ'' is, again, the [[scaling dimension]] of the field.

We note that this condition is rather restrictive. In general, solutions even of scale-invariant field equations will '''not''' be scale-invariant, and in such cases the symmetry is said to be [[spontaneously broken]].

===Classical electromagnetism===

An example of a scale-invariant classical field theory is [[electromagnetic field|electromagnetism]] with no charges or currents. The fields are the electric and magnetic fields, '''E'''('''x''',''t'') and '''B'''('''x''',''t''), while their field equations are [[Maxwell's equations]].

With no charges or currents, [[electromagnetic field#Light as an electromagnetic disturbance|these field equations]] take the form of [[wave equation]]s
:&lt;math&gt;\nabla^2 \mathbf{E} = \frac{1}{c^2} \frac{\partial^2 \mathbf{E}}{\partial t^2}&lt;/math&gt;
:&lt;math&gt;\nabla^2\mathbf{B} = \frac{1}{c^2} \frac{\partial^2 \mathbf{B}}{\partial t^2}&lt;/math&gt;
where ''c'' is the speed of light.

These field equations are invariant under the transformation
:&lt;math&gt;x\rightarrow\lambda x,&lt;/math&gt;
:&lt;math&gt;t\rightarrow\lambda t.&lt;/math&gt;

Moreover, given solutions of Maxwell's equations, '''E'''('''x''', ''t'') and '''B'''('''x''', ''t''),  it holds that 
'''E'''(λ'''x''', λ''t'') and '''B'''(λ'''x''', λ''t'')  are also solutions.

===Massless scalar field theory===
Another example of a scale-invariant classical field theory is the massless [[scalar field theory|scalar field]] (note that the name [[scalar (physics)|scalar]] is unrelated to scale invariance). The scalar field, {{math|''φ''('''''x''''', ''t'')}} is a function of a set of spatial variables, '''''x''''', and a time variable, {{mvar|t}}.

Consider first the linear theory. Like the electromagnetic field equations above, the equation of motion for this theory is also a wave equation,
:&lt;math&gt;\frac{1}{c^2} \frac{\partial^2 \varphi}{\partial t^2}-\nabla^2 \varphi = 0,&lt;/math&gt;
and is invariant under the transformation
:&lt;math&gt;x\rightarrow\lambda x,&lt;/math&gt;
:&lt;math&gt;t\rightarrow\lambda t.&lt;/math&gt;

The name massless refers to the absence of a term &lt;math&gt;\propto m^2\varphi&lt;/math&gt; in the field equation. Such a term is often referred to as a `mass' term, and would break the invariance under the above transformation. In [[relativistic field theory|relativistic field theories]], a mass-scale, {{mvar|m}}  is physically equivalent to a fixed length scale through
:&lt;math&gt;L=\frac{\hbar}{mc},&lt;/math&gt;
and so it should not be surprising that massive scalar field theory is ''not'' scale-invariant.

====φ&lt;sup&gt;4&lt;/sup&gt; theory====
The field equations in the examples above are all [[linear]] in the fields, which has meant that the [[scaling dimension]], {{mvar|Δ}}, has not been so important. However, one usually requires that the scalar field [[action (physics)|action]] is dimensionless, and this fixes the [[scaling dimension]] of {{mvar|φ}}. In particular,
:&lt;math&gt;\Delta=\frac{D-2}{2},&lt;/math&gt;
where {{mvar|D}} is the combined number of spatial and time dimensions.

Given this scaling dimension for {{mvar|φ}}, there are certain nonlinear modifications of massless scalar field theory which are also scale-invariant. One example is massless [[Phi to the fourth|φ&lt;sup&gt;4&lt;/sup&gt; theory]] for {{mvar|D}}=4. The field equation is
:&lt;math&gt;\frac{1}{c^2} \frac{\partial^2 \varphi}{\partial t^2}-\nabla^2 \varphi+g\varphi^3=0.&lt;/math&gt;

(Note that the name {{mvar|φ}}&lt;sup&gt;4&lt;/sup&gt; derives from the form of the [[Phi to the fourth#The Lagrangian|Lagrangian]], which contains the fourth power of {{mvar|φ}}.)

When {{mvar|D}}=4 (e.g. three spatial dimensions and one time dimension), the scalar field scaling dimension is {{mvar|Δ}}=1. The field equation is then invariant under the transformation
:&lt;math&gt;x\rightarrow\lambda x,&lt;/math&gt;
:&lt;math&gt;t\rightarrow\lambda t,&lt;/math&gt;
:&lt;math&gt;\varphi (x)\rightarrow\lambda^{-1}\varphi(x).&lt;/math&gt;

The key point is that the parameter {{mvar|g}} must be dimensionless, otherwise one introduces a fixed length scale into the theory: For  {{mvar|φ}}&lt;sup&gt;4&lt;/sup&gt;  theory, this is only the case in {{mvar|D}}=4.
Note that under these transformations the argument of the function {{mvar|φ}} is unchanged.

==Scale invariance in quantum field theory==
The scale-dependence of a [[quantum field theory]] (QFT) is characterised by the way its [[coupling constant|coupling parameters]] depend on the energy-scale of a given physical process. This energy dependence is described by the [[renormalization group]], and is encoded in the [[beta-function]]s of the theory.

For a QFT to be scale-invariant, its coupling parameters must be independent of the energy-scale, and this is indicated by the vanishing of the beta-functions of the theory. Such theories are also known as [[Renormalization group|fixed points]] of the corresponding renormalization group flow.&lt;ref&gt;[[Jean Zinn-Justin|J. Zinn-Justin]] (2010)  Scholarpedia article [http://www.scholarpedia.org/article/Critical_Phenomena:_field_theoretical_approach "Critical Phenomena: field theoretical approach"].&lt;/ref&gt;

===Quantum electrodynamics===
A simple example of a scale-invariant QFT is the quantized electromagnetic field without charged particles. This theory actually has no coupling parameters (since [[photon]]s are massless and non-interacting) and is therefore scale-invariant, much like the classical theory.

However, in nature the electromagnetic field is coupled to charged particles, such as [[electron]]s. The QFT describing the interactions of photons and charged particles is [[quantum electrodynamics]] (QED), and this theory is not scale-invariant. We can see this from the [[beta-function#Quantum electrodynamics|QED beta-function]]. This tells us that the [[electric charge]] (which is the coupling parameter in the theory) increases with increasing energy. Therefore, while the quantized electromagnetic field without charged particles '''is''' scale-invariant, QED is '''not''' scale-invariant.

===Massless scalar field theory===
Free, massless [[scalar field (quantum field theory)|quantized scalar field theory]] has no coupling parameters. Therefore, like the classical version, it is scale-invariant. In the language of the renormalization group, this theory is known as the [[Gaussian fixed point]].

However, even though the classical massless ''φ''&lt;sup&gt;4&lt;/sup&gt; theory is scale-invariant in ''D''=4, the quantized version is '''not''' scale-invariant. We can see this from the [[beta-function]] for the coupling parameter, ''g''.

Even though the quantized massless ''φ''&lt;sup&gt;4&lt;/sup&gt; is not scale-invariant, there do exist scale-invariant quantized scalar field theories other than the Gaussian fixed point. One example is the '''Wilson-Fisher fixed point''', below.

===Conformal field theory===
Scale-invariant QFTs are almost always invariant under the full [[conformal symmetry]], and the study of such QFTs is [[conformal field theory]] (CFT). [[operator (physics)|Operators]] in a CFT have a well-defined [[scaling dimension]], analogous to the [[scaling dimension]], ''∆'', of a classical field discussed above. However, the scaling dimensions of operators in a CFT typically differ from those of the fields in the corresponding classical theory. The additional contributions appearing in the CFT are known as [[anomalous scaling dimension]]s.

===Scale and conformal anomalies===
The φ&lt;sup&gt;4&lt;/sup&gt; theory example above demonstrates that the coupling parameters of a quantum field theory can be scale-dependent even if the corresponding classical field theory is scale-invariant (or conformally invariant). If this is the case, the classical scale (or conformal) invariance is said to be [[conformal anomaly|anomalous]]. A classically scale invariant field theory, where scale invariance is broken by quantum effects, provides an explication of the nearly exponential expansion of the early universe called [[Inflation (cosmology)|cosmic inflation]], as long as the theory can be studied through [[perturbation theory]].&lt;ref&gt;{{cite journal|last=Salvio, Strumia|title=Agravity|journal=JHEP  |volume=6 |pages=080|date=2014-03-17|url=http://inspirehep.net/record/1286134|arxiv = 1403.4226|bibcode = 2014JHEP...06..080S|doi=10.1007/JHEP06(2014)080}}&lt;/ref&gt;

==Phase transitions==
In [[statistical mechanics]], as a system undergoes a [[phase transition]], its fluctuations are described by a scale-invariant [[statistical field theory]]. For a system in equilibrium (i.e. time-independent) in {{mvar|D}} spatial dimensions, the corresponding statistical field theory is formally similar to a {{mvar|D}}-dimensional CFT. The scaling dimensions in such problems are usually referred to as [[critical exponent]]s, and one can in principle compute these exponents in the appropriate CFT.

===The Ising model===
An example that links together many of the ideas in this article is the phase transition of the [[Ising model]], a simple model of [[ferromagnet]]ic substances. This is a statistical mechanics model, which also has a description in terms of conformal field theory. The system consists of an array of lattice sites, which form a {{mvar|D}}-dimensional periodic lattice. Associated with each lattice site is a [[magnetic moment]], or [[spin (physics)|spin]], and this spin can take either the value +1 or −1. (These states are also called up and down, respectively.)

The key point is that the Ising model has a spin-spin interaction, making it energetically favourable for two adjacent spins to be aligned. On the other hand, thermal fluctuations typically introduce a randomness into the alignment of spins. At some critical temperature, {{math|''T&lt;sub&gt;c&lt;/sub&gt;''}} , [[spontaneous magnetization]] is said to occur. This means that below {{math|''T&lt;sub&gt;c&lt;/sub&gt;''}} the spin-spin interaction will begin to dominate, and there is some net alignment of spins in one of the two directions.

An example of the kind of physical quantities one would like to calculate at this critical temperature is the correlation between spins separated by a distance {{mvar|r}}. This has the generic behaviour:
:&lt;math&gt;G(r)\propto\frac{1}{r^{D-2+\eta}},&lt;/math&gt;
for some particular value of &lt;math&gt;\eta&lt;/math&gt;, which is an example of a critical exponent.

====CFT description====
The fluctuations at temperature {{math|''T&lt;sub&gt;c&lt;/sub&gt;''}} are scale-invariant, and so the Ising model at this phase transition is expected to be described by a scale-invariant statistical field theory. In fact, this theory is the '''Wilson-Fisher fixed point''', a particular scale-invariant [[scalar field (quantum field theory)|scalar field theory]].

In this context, {{math|''G''(''r'')}} is understood as a [[correlation function]] of scalar fields,
:&lt;math&gt;\langle\phi(0)\phi(r)\rangle\propto\frac{1}{r^{D-2+\eta}}.&lt;/math&gt;
Now we can fit together a number of the ideas seen already.

From the above, one  sees that the critical exponent, {{mvar|η}}, for this phase transition, is also an '''anomalous dimension'''. This is because the classical dimension of the scalar field,
:&lt;math&gt;\Delta=\frac{D-2}{2}&lt;/math&gt;
is modified to become
:&lt;math&gt;\Delta=\frac{D-2+\eta}{2},&lt;/math&gt;
where {{mvar|D}} is the number of dimensions of the Ising model lattice.

So this '''anomalous dimension''' in the conformal field theory is the ''same'' as a particular critical exponent of the Ising model phase transition.

Note that for dimension {{math|''D'' ≡ 4−''ε''}}, {{mvar|η}} can be calculated approximately, using the '''epsilon expansion''', and one finds that
:&lt;math&gt;\eta=\frac{\epsilon^2}{54}+O(\epsilon^3)&lt;/math&gt;.

In the physically interesting case of three spatial dimensions, we have {{mvar|ε}}=1, and so this expansion is not strictly reliable. However, a semi-quantitative prediction is that {{mvar|η}} is numerically small in three dimensions.

On the other hand, in the two-dimensional case the Ising model is exactly soluble. In particular, it is equivalent to one of the [[minimal models]], a family of well-understood CFTs, and it is possible to compute {{mvar|η}} (and the other critical exponents) exactly,
:&lt;math&gt;\eta_{_{D=2}}=\frac{1}{4}&lt;/math&gt;.

===Schramm–Loewner evolution===
The anomalous dimensions in certain two-dimensional CFTs can be related to the typical [[fractal dimension]]s of random walks, where the random walks are defined via [[Schramm–Loewner evolution]] (SLE). As we have seen above, CFTs describe the physics of phase transitions, and so one can relate the critical exponents of certain phase transitions to these fractal dimensions. Examples include the 2''d'' critical Ising model and the more general 2''d'' critical [[Potts model]]. Relating other 2''d'' CFTs to SLE is an active area of research.

==Universality==
A phenomenon known as [[universality (dynamical systems)|universality]] is seen in a large variety of physical systems. It expresses the idea that different microscopic physics can give rise to the same scaling behaviour at a phase transition. A canonical example of universality involves the following two systems:
* The [[Ising model]] phase transition, described above.
* The [[liquid]]-[[vapour]] transition in classical fluids.

Even though the microscopic physics of these two systems is completely different, their critical exponents turn out to be the same. Moreover, one can calculate these exponents using the same statistical field theory. The key observation is that at a phase transition or [[critical point (thermodynamics)|critical point]], fluctuations occur at all length scales, and thus one should look for a scale-invariant statistical field theory to describe the phenomena. In a sense, universality is the observation that there are relatively few such scale-invariant theories.

The set of different microscopic theories described by the same scale-invariant theory is known as a [[universality class]]. Other examples of systems which belong to a universality class are:
* [[Avalanche]]s in piles of sand. The likelihood of an avalanche is in power-law proportion to the size of the avalanche, and avalanches are seen to occur at all size scales.
* The frequency of [[network outage]]s on the [[Internet]], as a function of size and duration.
* The frequency of citations of journal articles, considered in the network of all citations amongst all papers, as a function of the number of citations in a given paper.{{Citation needed|date=February 2017}}
* The formation and propagation of cracks and tears in materials ranging from steel to rock to paper. The variations of the direction of the tear, or the roughness of a fractured surface, are in power-law proportion to the size scale.
* The [[electrical breakdown]] of [[dielectric]]s, which resemble cracks and tears.
* The [[percolation]] of fluids through disordered media, such as [[petroleum]] through fractured rock beds, or water through filter paper, such as in [[chromatography]]. Power-law scaling connects the rate of flow to the distribution of fractures.
* The [[diffusion]] of [[molecule]]s in [[solution]], and the phenomenon of [[diffusion-limited aggregation]].
* The distribution of rocks of different sizes in an aggregate mixture that is being shaken (with gravity acting on the rocks).

The key observation is that, for all of these different systems, the behaviour resembles a [[phase transition]], and that the language of statistical mechanics and scale-invariant [[statistical field theory]] may be applied to describe them.

==Other examples of scale invariance==

===Newtonian fluid mechanics with no applied forces===

Under certain circumstances, [[fluid mechanics]] is a scale-invariant classical field theory. The fields are the velocity of the fluid flow, &lt;math&gt;\mathbf{u}(\mathbf{x},t)&lt;/math&gt;, the fluid density, &lt;math&gt;\rho(\mathbf{x},t)&lt;/math&gt;, and the fluid pressure, &lt;math&gt;P(\mathbf{x},t)&lt;/math&gt;. These fields must satisfy both the [[Navier–Stokes equation]] and the [[continuity equation#Fluid dynamics|continuity equation]]. For a [[Newtonian fluid]] these take the respective forms
:&lt;math&gt;\rho\frac{\partial \mathbf{u}}{\partial t}+\rho\mathbf{u}\cdot\nabla \mathbf{u} = -\nabla P+\mu \left(\nabla^2 \mathbf{u}+\frac{1}{3}\nabla\left(\nabla\cdot\mathbf{u}\right)\right)&lt;/math&gt;
:&lt;math&gt;\frac{\partial \rho}{\partial t}+\nabla\cdot \left(\rho\mathbf{u}\right)=0&lt;/math&gt;
where &lt;math&gt;\mu&lt;/math&gt; is the [[dynamic viscosity#Viscosity .28dynamic viscosity.29: .CE.BC|dynamic viscosity]].

In order to deduce the scale invariance of these equations we specify an [[equation of state]], relating the fluid pressure to the fluid density. The equation of state depends on the type of fluid and the conditions to which it is subjected. For example, we consider the [[isothermal]] [[ideal gas]], which satisfies
:&lt;math&gt;P=c_s^2\rho,&lt;/math&gt;
where &lt;math&gt;c_s&lt;/math&gt; is the speed of sound in the fluid. Given this equation of state, Navier–Stokes and the continuity equation are invariant under the transformations
:&lt;math&gt;x\rightarrow\lambda x,&lt;/math&gt;
:&lt;math&gt;t\rightarrow\lambda^2 t,&lt;/math&gt;
:&lt;math&gt;\rho\rightarrow\lambda^{-1} \rho,&lt;/math&gt;
:&lt;math&gt;\mathbf{u}\rightarrow\mathbf{u}.&lt;/math&gt;
Given the solutions &lt;math&gt;\mathbf{u}(\mathbf{x},t)&lt;/math&gt; and &lt;math&gt;\rho(\mathbf{x},t)&lt;/math&gt;, we automatically have that
&lt;math&gt;\lambda\mathbf{u}(\lambda\mathbf{x},\lambda^2 t)&lt;/math&gt; and &lt;math&gt;\lambda\rho(\lambda\mathbf{x},\lambda^2 t)&lt;/math&gt; are also solutions.

===Computer vision===
{{Main article|Scale space}}
In [[computer vision]] and [[biological vision]], scaling transformations arise because of the perspective image mapping and because of objects having different physical size in the world. In these areas, scale invariance refers to local image descriptors or visual representations of the image data that remain invariant when the local scale in the image domain is changed.&lt;ref name=Lin13PONE&gt;[https://dx.doi.org/10.1371/journal.pone.0066990 Lindeberg, T. (2013) Invariance of visual operations at the level of receptive fields, PLoS ONE 8(7):e66990.]&lt;/ref&gt;  
Detecting local maxima over scales of normalized derivative responses provides a general framework for obtaining scale invariance from image data.&lt;ref name=Lindeberg1998&gt;{{cite journal
 | author = Lindeberg, Tony
 | year = 1998
 | title = Feature detection with automatic scale selection
 | journal = International Journal of Computer Vision
 | volume = 30
 | issue = 2
 | pages = 79–116
 | doi = 10.1023/A:1008045108935
 | url = http://www.nada.kth.se/cvap/abstracts/cvap198.html
}}&lt;/ref&gt;&lt;ref name=Lin14CompVis&gt;T. Lindeberg (2014) [http://www.csc.kth.se/~tony/abstracts/Lin14-ScSel-CompVisRefGuide.html "Scale selection", Computer Vision: A Reference Guide, (K. Ikeuchi, Editor), Springer, pages 701-713.]&lt;/ref&gt;
Examples of applications include [[blob detection]], [[corner detection]], [[ridge detection]], and object recognition via the [[scale-invariant feature transform]].

==See also==
*[[Scale relativity]]
*[[Inverse square potential]]
* [[Multiplicative calculus]]

==References==
{{Reflist}}

==Further reading==
*{{cite book |last=Zinn-Justin |first=Jean |title=Quantum Field Theory and Critical Phenomena |publisher=Oxford University Press |year=2002 }} Extensive discussion of scale invariance in quantum and statistical field theories, applications to critical phenomena and the epsilon expansion and related topics.
*{{cite book |first=P. |last=DiFrancesco |first2=P. |last2=Mathieu |first3=D. |last3=Senechal |title=Conformal Field Theory |publisher=Springer-Verlag |year=1997 }}
*{{cite book |first=G. |last=Mussardo |title=Statistical Field Theory. An Introduction to Exactly Solved Models of Statistical Physics |publisher=Oxford University Press |year=2010 }}

[[Category:Symmetry]]
[[Category:Scaling symmetries]]
[[Category:Conformal field theory]]
[[Category:Critical phenomena]]
[[Category:Scale-invariant systems| ]]</text>
      <sha1>aj9kp5dib39x4au8t1kwwzn4ajs6udn</sha1>
    </revision>
  </page>
  <page>
    <title>Schur's theorem</title>
    <ns>0</ns>
    <id>1522286</id>
    <revision>
      <id>822416707</id>
      <parentid>821767342</parentid>
      <timestamp>2018-01-26T07:08:32Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5212">In [[discrete mathematics]], '''Schur's theorem''' is any of several theorems of the [[mathematician]] [[Issai Schur]]. In [[differential geometry]], '''Schur's theorem''' is a theorem of [[:de:Axel Schur|Axel Schur]]. In [[functional analysis]], '''Schur's theorem''' is often called [[Schur's property]], also due to Issai Schur.

== Ramsey theory ==
{{wikibooks|Combinatorics|Schur's Theorem|Proof of Schur's theorem}}
In [[Ramsey theory]], '''Schur's theorem''' states that for any [[Partition of a set|partition]] of the [[positive integer]]s into a finite number of parts, one of the parts contains three integers ''x'', ''y'', ''z'' with 

:&lt;math&gt;x + y = z.&lt;/math&gt;

Moreover, for every positive integer ''c'', there exists a number ''S''(''c''), called ''[[Schur's number]]'', such that for every partition of the integers 

:&lt;math&gt;\{1,\ldots, S(c)\}&lt;/math&gt;

into ''c'' parts, one of the parts contains integers ''x'', ''y'', and ''z'' with 

:&lt;math&gt;x + y = z.&lt;/math&gt;

[[Folkman's theorem]] generalizes Schur's theorem by stating that there exist arbitrarily large sets of integers all of whose nonempty sums belong to the same part.

== Combinatorics ==
In [[combinatorics]], '''Schur's theorem''' tells the number of ways for expressing a given number as a (non-negative, integer) linear combination of a fixed set of relatively prime numbers. In particular, if &lt;math&gt;\{a_1,\ldots,a_n\}&lt;/math&gt; is a set of integers such that &lt;math&gt; \gcd(a_1,\ldots,a_n)=1 &lt;/math&gt;, the number of different tuples of non-negative integer numbers &lt;math&gt;(c_1,\ldots,c_n)&lt;/math&gt; such that &lt;math&gt;x=c_1a_1 + \cdots + c_na_n&lt;/math&gt; when &lt;math&gt;x&lt;/math&gt; goes to infinity is:

:&lt;math&gt;\frac{x^{n-1}}{(n-1)!a_1\cdots a_n}(1+o(1)).&lt;/math&gt;

As a result, for every set of relatively prime numbers &lt;math&gt;\{a_1,\ldots,a_n\}&lt;/math&gt; there exists a value of &lt;math&gt;x&lt;/math&gt; such that every larger number is representable as a linear combination of &lt;math&gt;\{a_1,\ldots,a_n\}&lt;/math&gt; in at least one way. This consequence of the theorem can be recast in a familiar context considering the problem of changing an amount using a set of coins. If the denominations of the coins are relatively prime numbers (such as 2 and 5) then any sufficiently large amount can be changed using only these coins. (See [[Coin problem]].)

== Differential geometry ==
In [[differential geometry]], '''Schur's theorem''' compares the distance between the endpoints of a space curve &lt;math&gt;C^*&lt;/math&gt; to the distance between the endpoints of a corresponding plane curve &lt;math&gt;C&lt;/math&gt; of less curvature.

Suppose &lt;math&gt;C(s)&lt;/math&gt; is a plane curve with curvature &lt;math&gt;\kappa(s)&lt;/math&gt; which makes a convex curve when closed by the chord connecting its endpoints, and &lt;math&gt;C^*(s)&lt;/math&gt; is a curve of the same length with curvature &lt;math&gt;\kappa^*(s)&lt;/math&gt;. Let &lt;math&gt;d&lt;/math&gt; denote the distance between the endpoints of &lt;math&gt;C&lt;/math&gt; and &lt;math&gt;d^*&lt;/math&gt; denote the distance between the endpoints of &lt;math&gt;C^*&lt;/math&gt;. If &lt;math&gt;\kappa^*(s) \leq \kappa(s)&lt;/math&gt; then &lt;math&gt;d^* \geq d&lt;/math&gt;.

'''Schur's theorem''' is usually stated for &lt;math&gt;C^2&lt;/math&gt; curves, but [[John M. Sullivan (mathematician)|John M. Sullivan]] has observed that Schur's theorem applies to curves of finite total curvature (the statement is slightly different).

==  Linear algebra ==
{{main|Schur decomposition}}
In [[linear algebra]] Schur’s theorem is referred to as either the triangularization of a square matrix with complex entries, or of a square matrix with real entries and real eigenvalues.

==Functional analysis==
In [[functional analysis]] and the study of [[Banach space]]s, Schur's theorem, due to [[J. Schur]], often refers to [[Schur's property]], that for certain spaces, [[weak topology|weak convergence]] implies convergence in the norm.

== Number theory ==
In [[number theory]], Issai Schur showed in 1912 that for every nonconstant polynomial ''p''(''x'') with integer coefficients, if ''S'' is the set of all nonzero values &lt;math&gt;\begin{Bmatrix} p(n) \neq 0 : n \in \mathbb{N} \end{Bmatrix}&lt;/math&gt;, then the set of primes that divide some member of ''S'' is infinite.

==See also==

*[[Schur's lemma (from Riemannian geometry)]]

==References==

* Herbert S. Wilf (1994). [http://www.cs.utsa.edu/~wagner/CS3343/resources/gfology.pdf generatingfunctionology]. Academic Press.
* [[Shiing-Shen Chern]] (1967). Curves and Surfaces in Euclidean Space. In ''Studies in Global Geometry and Analysis.'' Prentice-Hall.
* Issai Schur (1912). Über die Existenz unendlich vieler Primzahlen in einigen speziellen arithmetischen Progressionen, Sitzungsberichte der Berliner Math.

==Further reading==
* Dany Breslauer and Devdatt P. Dubhashi (1995). [http://www.brics.dk/LS/95/4/BRICS-LS-95-4/BRICS-LS-95-4.html Combinatorics for Computer Scientists]
* [[John M. Sullivan (mathematician)|John M. Sullivan]] (2006). [https://arxiv.org/pdf/math.GT/0606007 Curves of Finite Total Curvature]. arXiv.

[[Category:Theorems in discrete mathematics]]
[[Category:Ramsey theory]]
[[Category:Additive combinatorics]]
[[Category:Theorems in combinatorics]]
[[Category:Theorems in differential geometry]]
[[Category:Theorems in linear algebra]]
[[Category:Theorems in functional analysis]]</text>
      <sha1>3hgfbwpwa6xhem6339eukyvu1tfn78m</sha1>
    </revision>
  </page>
  <page>
    <title>Stephen Stigler</title>
    <ns>0</ns>
    <id>1276686</id>
    <revision>
      <id>833427676</id>
      <parentid>806488744</parentid>
      <timestamp>2018-03-31T13:42:50Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>added [[Category:Mathematicians from Minnesota]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8567">{{Infobox scientist
| honorific_prefix =
| name        = Stephen M. Stigler
| honorific_suffix =
| native_name = 
| native_name_lang = 
| image       =         &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size  = 
| alt         = 
| caption     = 
| birth_date  =         {{birth date and age |1941|8|10}}
| birth_place = Minneapolis
| death_date  =         &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place = 
| death_cause = 
| resting_place = 
| resting_place_coordinates =  &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names = 
| residence   = 
| citizenship = 
| nationality = 
| fields      = [[History of statistics]]
| workplaces  = 
| patrons     = 
| education   = 
| alma_mater  = [[Carleton College]]&lt;small&gt; (BA)&lt;/small&gt;&lt;br&gt; [[University of California]]&lt;small&gt; (PhD)&lt;/small&gt;
| thesis_title =         Linear Functions of Order Statistics
| thesis_url  =         &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year =         1967
| doctoral_advisor =   [[Lucien Le Cam]]
| academic_advisors = 
| doctoral_students = [[Lee-Jen Wei]]
| notable_students = 
| known_for   = [[Stigler's law of eponymy]], [[History of statistics]]
| influences  = 
| influenced  = 
| awards      = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse      =         &lt;!--(or | spouses = )--&gt;
| partner     =         &lt;!--(or | partners = )--&gt;
| children    = 
| signature   =         &lt;!--(filename only)--&gt;
| signature_alt = 
| website     =         {{URL|www.galton.uchicago.edu/~stigler/}}
| footnotes   = 
}}

'''Stephen Mack Stigler''' (born August 10, 1941) is Ernest DeWitt Burton [[Distinguished Service Professor]] at the Department of [[Statistics]] of the [[University of Chicago]].&lt;ref&gt;Catherine Behan (May 28, 1998) [http://chronicle.uchicago.edu/980528/stigler.shtml 1998 Quantrell Award: Stephen Stigler] University of Chicago Chronicle. 17(17).&lt;/ref&gt;  He has authored several books on the [[history of statistics]]. 

Stigler is also known for [[Stigler's law of eponymy]] which states that no scientific discovery is named after its original discoverer (whose first formulation he credits to sociologist [[Robert K. Merton]]).  

== Biography ==

Stigler was born in Minneapolis.&lt;ref&gt;[https://books.google.com/books?id=7Q80AAAAIAAJ&amp;q=%22Stigler,+stephen+mack%22+1941&amp;dq=%22Stigler,+stephen+mack%22+1941&amp;hl=en&amp;sa=X&amp;ei=AuGYUey7HsSniAK3x4GYAw&amp;ved=0CEcQ6AEwBQ]&lt;/ref&gt; He received his [[Doctor of Philosophy|Ph.D.]] in 1967 from the [[University of California, Berkeley]]. His dissertation was on [[linear function]]s of [[order statistics]], and his advisor was [[Lucien Le Cam]]. His research has focused on statistical theory of [[robust statistics|robust estimators]] and the [[history of statistics]].  He is also known for [[Stigler's law of eponymy]].

Stigler taught at [[University of Wisconsin–Madison]] until 1979 when he joined the University of Chicago. In 2006 he was elected to membership of the [[American Philosophical Society]], and is a past president (1994) of the [[Institute of Mathematical Statistics]].

His father was the [[economist]] [[George Stigler]], and he has recently&lt;ref&gt;http://www.stat.uchicago.edu/~stigler/2014websscv.pdf&lt;/ref&gt; written on [[Milton Friedman]], who was a friend of his father.

== Bibliography ==

=== Books ===

* {{cite book | author= | title= The History of Statistics: The Measurement of Uncertainty before 1900 | publisher= Harvard University Press| location=Cambridge, MA | year= 1986| isbn= 978-0-6744-0341-3}}
* {{cite book | author= | title= Statistics on the Table: The History of Statistical Concepts and Methods | publisher= Harvard University Press| location=Cambridge, MA | year= 1999 | isbn= 978-0-6740-0979-0}}
* {{cite book | author= | title= The Seven Pillars of Statistical Wisdom | publisher= Harvard University Press| location=Cambridge, MA | year= 2016 | isbn= 978-0-6740-8891-7}}

; As editor
* {{cite book | author= Stigler, S. M. | title= American Contributions to Mathematical Statistics in the Nineteenth Century (2 Vols.) | publisher= Arno Press | location= New York | year= 1980 | isbn= 978-0-4051-2590-4}}
* {{cite book | author1= Stigler, S. M. | author2= Wong, W. H. | author3= Xu, D. | title= R. R. Bahadur's Lectures on the Theory of Estimation (Lecture Notes-Regional Monograph Series, Vol. 39) | publisher= Institute for Mathematical Statistics | location= Beachwood, OH | year= 2002 | isbn= 978-0-9406-0053-9}}

=== Selected articles ===

* {{cite journal
|title=The application of the method of least squares to the interpolation of sequences (translated by Ralph St. John and S. M. Stigler)
|author=[[Joseph Diaz Gergonne|Gergonne, J. D.]]
|journal=Historia Mathematica
|volume=1
|issue=4 &lt;!-- |month=November --&gt;
|year=1974 |origyear=1815
|pages=439–47
|editor=Ralph St. John and S. M. Stigler
|edition=translated by Ralph St. John and S. M. Stigler from the 1815 French
|doi=10.1016/0315-0860(74)90034-2
|url=http://www.sciencedirect.com/science/article/B6WG9-4D7JMHH-20/2/df451ec5fbb7c044d0f4d900af80ec86
}}
* {{cite journal
|title=Gergonne's 1815 paper on the design and analysis of polynomial regression experiments
|author=Stigler, Stephen M.
|journal=Historia Mathematica
|volume=1
|issue=4 &lt;!-- |month=November --&gt;
|year=1974
|pages=431–39
|doi=10.1016/0315-0860(74)90033-0
|url=http://www.sciencedirect.com/science/article/B6WG9-4D7JMHH-1Y/2/680c7ada0198761e9866197d53512ab4}}
* {{cite journal
|last=Stigler
|first=Stephen M.
|title=Mathematical statistics in the early States
|journal=Annals of Statistics
|date=March 1978
|volume=6
|pages=239–65
|url=http://projecteuclid.org/euclid.aos/1176344123
|doi=10.1214/aos/1176344123
|jstor=2958876
|mr=483118
|issue=2}}
** {{cite book
|authorlink=Stephen M. Stigler
|last=Stigler
|first=Stephen M.
|chapter=Mathematical Statistics in the Early States
|editor=Stephen M. Stigler
|title=American Contributions to Mathematical Statistics in the Nineteenth Century, Volumes I &amp; II
|volume=I
|publisher=Arno Press
|location=New York
|year=1980}}
** {{cite book
|authorlink=Stephen M. Stigler
|last=Stigler
|first=Stephen M.
|chapter=Mathematical Statistics in the Early States
|editor=Peter Duren
|title=A Century of Mathematics in America  &lt;!-- Part III --&gt;
|volume=III
|publisher=American Mathematical Society
|location=Providence, RI
|year=1989
|pages=537–64}}
* {{cite journal
  | doi = 10.2307/2344804
  | last = Stigler | first = Stephen M. | authorlink = Stephen M. Stigler
  | title = Francis Ysidro Edgeworth, statistician
  | year = 1978
  | journal = [[Journal of the Royal Statistical Society]], Series A
  | volume = 141 | issue = 3
  | pages = 287–322
  | jstor = 2344804
  }}
* Stigler, S. M. (1980). [[Stigler's law of eponymy]]. Transactions of the New York Academy of Sciences, 39: 147–58 (Merton Frestschrift Volume, F. Gieryn (ed))
* {{cite journal|last=Stigler|first=Stephen M.|date=November 1983|title=Who discovered Bayes's theorem?|journal=The American Statistician|volume=37|issue=4|pages=290–96|jstor=2682766|ref=harv|id=Republished in ''Statistics on the table'' ()|doi=10.2307/2682766|mr=1712969|authorlink=Stephen Stigler}}
* {{cite journal|doi=10.1086/444032|author=Stephen M. Stigler|title=A Historical View of Statistical Concepts in Psychology and Educational Research| journal=American Journal of Education| volume=101|issue=1|date=November 1992|pages=60–70}}

== See also ==
* [[Stigler's law of eponymy]]

== References ==
&lt;references/&gt;

== External links ==
* [https://galton.uchicago.edu/~stigler/SSCV2015Web.pdf Official CV of Stephen M. Stigler (September 2015)]
* [http://www.stat.uchicago.edu/faculty/stigler.shtml Homepage at the University of Chicago]
* [http://www.genealogy.math.ndsu.nodak.edu/ Mathematics Genealogy Project: Stephen Mack Stigler]

{{Authority control}}

{{DEFAULTSORT:Stigler, Stephen}}
[[Category:University of California, Berkeley alumni]]
[[Category:Presidents of the Institute of Mathematical Statistics]]
[[Category:Presidents of the International Statistical Institute]]
[[Category:Elected Members of the International Statistical Institute]]
[[Category:Fellows of the American Statistical Association]]
[[Category:American statisticians]]
[[Category:Historians of mathematics]]
[[Category:University of Chicago faculty]]
[[Category:Scientists from Minneapolis]]
[[Category:American people of German descent]]
[[Category:Living people]]
[[Category:1941 births]]
[[Category:Guggenheim Fellows]]
[[Category:Mathematicians from Minnesota]]</text>
      <sha1>fsfghthiu7uqi6zwiow3hju1vtyoln2</sha1>
    </revision>
  </page>
  <page>
    <title>Trigonometric integral</title>
    <ns>0</ns>
    <id>245560</id>
    <revision>
      <id>867676438</id>
      <parentid>867668433</parentid>
      <timestamp>2018-11-07T08:08:52Z</timestamp>
      <contributor>
        <username>Johnuniq</username>
        <id>6036800</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/128.206.146.210|128.206.146.210]] ([[User talk:128.206.146.210|talk]]) to last version by Deacon Vorbis</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14053">[[Image:sine cosine integral.svg|right|thumb|Si(x) (blue) and Ci(x) (green) plotted on the same plot.]]
In [[mathematics]], the '''trigonometric integrals''' are a [[indexed family|family]] of [[integral]]s involving [[trigonometric function]]s. A number of the basic trigonometric integrals are discussed at the [[list of integrals of trigonometric functions]].

==Sine integral==
[[Image:Sine integral.svg|thumb|right|Plot of '''Si(''x'')''' for {{math|0 ≤ ''x'' ≤ 8 ''π''}}.]]
The different [[sine]] integral definitions are
::&lt;math&gt;\operatorname{Si}(x) = \int_0^x\frac{\sin t}{t}\,dt&lt;/math&gt;
::&lt;math&gt;\operatorname{si}(x) = -\int_x^\infty\frac{\sin t}{t}\,dt.&lt;/math&gt;

Note that the integrand {{math|sin ''x'' / ''x''}} is the [[sinc function|{{math|sinc}} function]], and also the zeroth [[Bessel function#Spherical Bessel functions: jn.2C yn|spherical Bessel function]].
Since {{math| sinc}} is an [[even function|even]] [[entire function]] ([[holomorphic]] over the entire complex plane), {{math| Si}} is entire, odd, and the integral in its definition can be taken along [[Cauchy's integral theorem|any path]] connecting the endpoints.

By definition, {{math| Si(''x'')}} is the [[antiderivative]] of {{math|sin ''x'' / ''x''}} which is zero for {{math|''x'' {{=}} 0}}, and {{math|si(''x'')}} is the antiderivative of  {{math|sin ''x'' / ''x''}}  which is zero for {{math|''x'' {{=}} ∞}}. Their difference  is given by the [[Dirichlet integral]],
::&lt;math&gt;\operatorname{Si}(x) - \operatorname{si}(x) = \int_0^\infty\frac{\sin t}{t}\,dt = \frac{\pi}{2} ~.&lt;/math&gt;

In [[signal processing]], the oscillations of the sine integral cause [[overshoot (signal)|overshoot]] and [[ringing artifacts]] when using the [[sinc filter]], and [[frequency domain]] ringing if using a truncated sinc filter as a [[low-pass filter]].

Related is the [[Gibbs phenomenon]]: if the sine integral is considered as the [[convolution]] of the sinc function with the [[heaviside step function]], this corresponds to truncating the [[Fourier series]], which is the cause of the Gibbs phenomenon.

==Cosine integral==
[[Image:Cosine integral.svg|thumb|right|Plot of '''Ci(''x'')''' for 0&amp;nbsp;&lt;&amp;nbsp;''x''&amp;nbsp;≤&amp;nbsp;8π.]]
The different [[cosine]] integral definitions are
::&lt;math&gt;\operatorname{Ci}(x) = -\int_x^\infty \frac{\cos t}{t}\,dt = \gamma + \ln x + \int_0^x \frac{\cos t - 1}{t}\,dt
\qquad (|{\rm Arg}(x)|&lt;\pi)
&lt;/math&gt;
::&lt;math&gt;\operatorname{Cin}(x) = \int_0^x \frac{1 - \cos t}{t}\,dt~,&lt;/math&gt;
where {{math|''γ''}} is the [[Euler–Mascheroni constant]].  Some texts use {{math|ci}} instead of {{math|Ci}}.

{{math| Ci(''x'')}} is the antiderivative of {{math|cos ''x'' / ''x''}} (which vanishes at &lt;math&gt;x \to \infty&lt;/math&gt;). The two definitions are related by
::&lt;math&gt;\operatorname{Cin}(x) = \gamma + \ln x - \operatorname{Ci}(x)~.&lt;/math&gt;

{{math| Cin}} is an even entire function.

==Hyperbolic sine integral==
The [[hyperbolic sine]] integral is defined as
::&lt;math&gt;\operatorname{Shi}(x) =\int_0^x \frac {\sinh (t)}{t}\,dt.&lt;/math&gt;

It is related to the ordinary sine integral by
::&lt;math&gt;\operatorname{Si}(ix) = i\operatorname{Shi}(x).&lt;/math&gt;

==Hyperbolic cosine integral==
The [[hyperbolic cosine]] integral is

::&lt;math&gt;\operatorname{Chi}(x) = \gamma+\ln x + \int_0^x\frac{\cosh t-1}{t}\,dt \qquad (|{\rm Arg}(x)|&lt;\pi)&lt;/math&gt;

where &lt;math&gt;\gamma&lt;/math&gt; is the [[Euler–Mascheroni constant]].

It has the series expansion &lt;math&gt;\operatorname{Chi}(x) = \gamma + \ln(x) + \frac {1}{4} x^2 + \frac {1}{96} x^4 + \frac {1}{4320} x^6 + \frac {1}{322560} x^8 + \frac{1}{36288000} x^{10} + O(x^{12})&lt;/math&gt;.

==Auxiliary functions==
Trigonometric integrals can be understood in terms of the so-called "auxiliary functions"
:&lt;math&gt;f(x) 
\equiv \int_0^\infty \frac{\sin(t)}{t+x} dt = \int_0^\infty \frac{e^{-x t}}{t^2 + 1} dt 
= \operatorname{Ci}(x) \sin(x) + \left[\frac{\pi}{2} - \operatorname{Si}(x) \right] \cos(x) 
&lt;/math&gt;
:&lt;math&gt;
g(x)
\equiv \int_0^\infty \frac{\cos(t)}{t+x} dt = \int_0^\infty \frac{t e^{-x t}}{t^2 + 1} dt 
= -\operatorname{Ci}(x) \cos(x) + \left[\frac{\pi}{2} - \operatorname{Si}(x) \right] \sin(x)
&lt;/math&gt;.
Using these functions, the trigonometric integrals may be re-expressed as 
(cf Abramowitz &amp; Stegun, [http://people.math.sfu.ca/~cbm/aands/page_232.htm   p. 232])
:&lt;math&gt;
\begin{array}{rcl}
\operatorname{Si}(x) &amp;=&amp; \frac{\pi}{2} - f(x) \cos(x) - g(x) \sin(x) \\
\operatorname{Ci}(x) &amp;=&amp; f(x) \sin(x) - g(x) \cos(x). \\
\end{array}
&lt;/math&gt;

==Nielsen's spiral==
[[Image:Nielsen's spiral.png|thumb|right|Nielsen's spiral.]]
The [[spiral]] formed by parametric plot of {{math|si , ci}} is known as [[Nielsen's spiral]].  It is also referred to as the [[Euler spiral]], the Cornu spiral, a clothoid, or as a linear-curvature polynomial spiral.  

The spiral is also closely related to the [[Fresnel integral]]s.  This spiral has applications in vision processing, road and track construction and other areas.

==Expansion==
Various expansions can be used for evaluation of trigonometric integrals, depending on the range of the argument.

===Asymptotic series (for large argument)===
:&lt;math&gt;\operatorname{Si}(x)=\frac{\pi}{2} 
                 - \frac{\cos x}{x}\left(1-\frac{2!}{x^2}+\frac{4!}{x^4}-\frac{6!}{x^6}\cdots\right)
                 - \frac{\sin x}{x}\left(\frac{1}{x}-\frac{3!}{x^3}+\frac{5!}{x^5}-\frac{7!}{x^7}\cdots\right)&lt;/math&gt;
:&lt;math&gt;\operatorname{Ci}(x)= \frac{\sin x}{x}\left(1-\frac{2!}{x^2}+\frac{4!}{x^4}-\frac{6!}{x^6}\cdots\right)
                   -\frac{\cos x}{x}\left(\frac{1}{x}-\frac{3!}{x^{3}}+\frac{5!}{x^5}-\frac{7!}{x^7}\cdots\right) ~.&lt;/math&gt;

These series are [[Asymptotic series|asymptotic]] and divergent, although can be used for estimates and even precise evaluation at {{math|ℜ(''x'') ≫ 1}}.

===Convergent series===
:&lt;math&gt;\operatorname{Si}(x)= \sum_{n=0}^\infty \frac{(-1)^{n}x^{2n+1}}{(2n+1)(2n+1)!}=x-\frac{x^3}{3!\cdot3}+\frac{x^5}{5!\cdot5}-\frac{x^7}{7! \cdot7}\pm\cdots&lt;/math&gt;
:&lt;math&gt;\operatorname{Ci}(x)= \gamma+\ln x+\sum_{n=1}^{\infty}\frac{(-1)^{n}x^{2n}}{2n(2n)!}=\gamma+\ln x-\frac{x^2}{2!\cdot2}+\frac{x^4}{4! \cdot4}\mp\cdots&lt;/math&gt;

These series are convergent at any complex {{mvar|x}}, although for {{math|{{mabs|''x''}} ≫ 1}}, the series will converge slowly initially, requiring many terms for high precision.

==Relation with the exponential integral of imaginary argument==
The function

: &lt;math&gt; \operatorname{E}_1(z) = \int_1^\infty \frac{\exp(-zt)}{t}\,dt \qquad(\Re(z) \ge 0) &lt;/math&gt;
is called the [[exponential integral]]. It is closely related to Si and Ci,
:&lt;math&gt;
\operatorname{E}_1(i x) = i\left(-\frac{\pi}{2} + \operatorname{Si}(x)\right)-\operatorname{Ci}(x) = i \operatorname{si}(x) - \operatorname{ci}(x) \qquad (x&gt;0)~.
&lt;/math&gt;

As each respective function is analytic except for the cut at negative values of the argument, the area of validity of the relation should be extended to (Outside this range, additional terms which are integer factors of {{math|''π''}} appear in the expression.)

Cases of imaginary argument of the generalized integro-exponential function are
: &lt;math&gt;
\int_1^\infty \cos(ax)\frac{\ln x}{x} \, dx =
-\frac{\pi^2}{24}+\gamma\left(\frac{\gamma}{2}+\ln a\right)+\frac{\ln^2a}{2}
+\sum_{n\ge 1}\frac{(-a^2)^n}{(2n)!(2n)^2} ~,
&lt;/math&gt;
which is the real part of
: &lt;math&gt;
\int_1^\infty e^{iax}\frac{\ln x}{x} \, dx = -\frac{\pi^2}{24} + \gamma\left(\frac{\gamma}{2}+\ln a\right)+\frac{\ln^2 a}{2}-\frac{\pi}{2}i(\gamma+\ln a) + \sum_{n\ge 1}\frac{(ia)^n}{n!n^2}  ~.
&lt;/math&gt;

Similarly
: &lt;math&gt;
\int_1^\infty e^{iax}\frac{\ln x}{x^2}dx
=1+ia[-\frac{\pi^2}{24}+\gamma\left(\frac{\gamma}{2}+\ln a-1\right)+\frac{\ln^2 a}{2}-\ln a+1
-\frac{i\pi}{2}(\gamma+\ln a-1)]+\sum_{n\ge 1}\frac{(ia)^{n+1}}{(n+1)!n^2}~.
&lt;/math&gt;

==Efficient evaluation==
[[Padé approximant]]s of the convergent Taylor series provide an efficient way to evaluate the functions for small arguments.  The following formulae, given by Rowe et al (2015), are accurate to better than {{math|10&lt;sup&gt;−16&lt;/sup&gt;}} for {{math|0 ≤ ''x'' ≤ 4}},

&lt;math&gt;
\begin{array}{rcl}
\operatorname{Si}(x) &amp;=&amp; x \cdot \left( 
\frac{
\begin{array}{l}
1 -4.54393409816329991\cdot 10^{-2} \cdot x^2 + 1.15457225751016682\cdot 10^{-3} \cdot x^4 - 1.41018536821330254\cdot 10^{-5} \cdot x^6 \\
~~~ + 9.43280809438713025 \cdot 10^{-8} \cdot x^8 - 3.53201978997168357 \cdot 10^{-10} \cdot x^{10} + 7.08240282274875911 \cdot 10^{-13} \cdot x^{12} \\
~~~ - 6.05338212010422477 \cdot 10^{-16} \cdot x^{14}
\end{array}
}
{
\begin{array}{l}
1 + 1.01162145739225565 \cdot 10^{-2} \cdot x^2 + 4.99175116169755106 \cdot 10^{-5} \cdot x^4 + 1.55654986308745614 \cdot 10^{-7} \cdot x^6 \\
~~~ + 3.28067571055789734 \cdot 10^{-10} \cdot x^8 + 4.5049097575386581 \cdot 10^{-13} \cdot x^{10} + 3.21107051193712168 \cdot 10^{-16} \cdot x^{12}
\end{array}
}
\right)\\
&amp;~&amp;\\
\operatorname{Ci}(x) &amp;=&amp; \gamma + \ln(x) +\\
&amp;&amp; x^2 \cdot \left(
\frac{
\begin{array}{l}
-0.25 + 7.51851524438898291 \cdot 10^{-3} \cdot x^2 - 1.27528342240267686 \cdot 10^{-4} \cdot x^4 + 1.05297363846239184 \cdot 10^{-6} \cdot x^6 \\
~~~ -4.68889508144848019 \cdot 10^{-9} \cdot x^8 + 1.06480802891189243 \cdot  10^{-11} \cdot x^{10} - 9.93728488857585407 \cdot 10^{-15} \cdot x^{12} \\
\end{array}
}
{
\begin{array}{l}
1 + 1.1592605689110735 \cdot 10^{-2} \cdot x^2 + 6.72126800814254432 \cdot 10^{-5} \cdot x^4 + 2.55533277086129636 \cdot 10^{-7} \cdot x^6 \\
~~~ + 6.97071295760958946 \cdot 10^{-10} \cdot x^8 + 1.38536352772778619 \cdot 10^{-12} \cdot x^{10} + 1.89106054713059759 \cdot 10^{-15} \cdot x^{12} \\
~~~ + 1.39759616731376855 \cdot 10^{-18} \cdot x^{14} \\
\end{array}
}
\right)
\end{array}
&lt;/math&gt;

The integrals may be evaluated indirectly via auxiliary functions  &lt;math&gt;f(x)&lt;/math&gt;  and  &lt;math&gt;g(x)&lt;/math&gt;, which are defined by

&lt;math display="block"&gt;\operatorname{Si}(x)=\frac{\pi}{2}-f(x)\cos(x)-g(x)\sin(x),
&lt;/math&gt;&lt;math display="block"&gt;\operatorname{Ci}(x)=f(x)\sin(x)-g(x)\cos(x).&lt;/math&gt;

For  &lt;math&gt;x \ge 4&lt;/math&gt;  the [[Padé approximant|Padé rational functions]] given below approximate  &lt;math&gt;f(x)&lt;/math&gt;  and  &lt;math&gt;g(x)&lt;/math&gt;  with error less than 10&lt;sup&gt;−16&lt;/sup&gt;:

&lt;math&gt;
\begin{array}{rcl}
f(x) &amp;=&amp; \dfrac{1}{x} \cdot \left(\frac{
\begin{array}{l}
1 + 7.44437068161936700618 \cdot 10^2 \cdot x^{-2} + 1.96396372895146869801 \cdot 10^5 \cdot x^{-4} + 2.37750310125431834034 \cdot 10^7 \cdot x^{-6} \\
~~~ + 1.43073403821274636888 \cdot 10^9 \cdot x^{-8} + 4.33736238870432522765 \cdot 10^{10} \cdot x^{-10} + 6.40533830574022022911 \cdot 10^{11} \cdot x^{-12} \\
~~~ + 4.20968180571076940208 \cdot 10^{12} \cdot x^{-14} + 1.00795182980368574617 \cdot 10^{13} \cdot x^{-16} + 4.94816688199951963482 \cdot 10^{12} \cdot x^{-18} \\
~~~ - 4.94701168645415959931 \cdot 10^{11} \cdot x^{-20}
\end{array}
}{
\begin{array}{l}
1 + 7.46437068161927678031 \cdot 10^2 \cdot x^{-2} + 1.97865247031583951450 \cdot 10^5 \cdot x^{-4} + 2.41535670165126845144 \cdot 10^7 \cdot x^{-6} \\
~~~ + 1.47478952192985464958 \cdot 10^9 \cdot x^{-8} + 4.58595115847765779830 \cdot 10^{10} \cdot x^{-10} + 7.08501308149515401563 \cdot 10^{11} \cdot x^{-12} \\
~~~ + 5.06084464593475076774 \cdot 10^{12} \cdot x^{-14} + 1.43468549171581016479 \cdot 10^{13} \cdot x^{-16} + 1.11535493509914254097 \cdot 10^{13} \cdot x^{-18}
\end{array}
}
\right) \\
&amp; &amp;\\
g(x) &amp;=&amp; \dfrac{1}{x^2} \cdot \left(\frac{
\begin{array}{l}
1 + 8.1359520115168615 \cdot 10^2 \cdot x^{-2} + 2.35239181626478200 \cdot 10^5 \cdot x^{-4} +3.12557570795778731 \cdot 10^7 \cdot x^{-6} \\
~~~ + 2.06297595146763354 \cdot 10^9 \cdot x^{-8} + 6.83052205423625007 \cdot 10^{10} \cdot x^{-10} + 1.09049528450362786 \cdot 10^{12} \cdot x^{-12} \\
~~~ + 7.57664583257834349 \cdot 10^{12} \cdot x^{-14} + 1.81004487464664575 \cdot 10^{13} \cdot x^{-16} + 6.43291613143049485 \cdot 10^{12} \cdot x^{-18} \\
~~~ - 1.36517137670871689 \cdot 10^{12} \cdot x^{-20}
\end{array}
}{
\begin{array}{l}
1 + 8.19595201151451564 \cdot 10^2 \cdot x^{-2} + 2.40036752835578777 \cdot 10^5 \cdot x^{-4} + 3.26026661647090822 \cdot 10^7 \cdot x^{-6} \\
~~~ + 2.23355543278099360 \cdot 10^9 \cdot x^{-8} + 7.87465017341829930 \cdot 10^{10} \cdot x^{-10} + 1.39866710696414565 \cdot 10^{12} \cdot x^{-12} \\
~~~ + 1.17164723371736605 \cdot 10^{13} \cdot x^{-14} + 4.01839087307656620 \cdot 10^{13} \cdot x^{-16} + 3.99653257887490811 \cdot 10^{13} \cdot x^{-18}
\end{array}
}
\right) \\
\end{array}
&lt;/math&gt;

==See also==
* [[Logarithmic integral]]

== References ==
{{Reflist}}
*{{AS ref|5|231}}
*{{Citation | last1=Press | first1=WH | last2=Teukolsky | first2=SA | last3=Vetterling | first3=WT | last4=Flannery | first4=BP | year=2007 | title=Numerical Recipes: The Art of Scientific Computing | edition=3rd | publisher=Cambridge University Press |  publication-place=New York | isbn=978-0-521-88068-8 | chapter=Section 6.8.2. Cosine and Sine Integrals | chapter-url=http://apps.nrbook.com/empanel/index.html#pg=300}}
*{{dlmf|id=6|title=Exponential, Logarithmic, Sine, and Cosine Integrals|first=N. M. |last=Temme}}
* {{ cite arXiv|first1=R. J.
|last1=Mathar
|eprint=0912.3844
|title=Numerical evaluation of the oscillatory integral over exp(''i{{pi}}x'')&amp;middot;''x''&lt;sup&gt;1/''x''&lt;/sup&gt; between 1 and&amp;nbsp;&amp;infin;
|year=2009
|class = math.CA}}, Appendix B.
* Sine Integral Taylor series proof from Dan Sloughter's [http://de2de.synechism.org/c5/sec58.pdf Difference Equations to Differential Equations].
* {{cite journal|last1=Rowe|first1=B.|last2=et al|title=GALSIM: The modular galaxy image simulation toolkit|journal=Astronomy and Computing|date=2015|volume=10|page=121|doi=10.1016/j.ascom.2015.02.002|arxiv=1407.7676|bibcode=2015A&amp;C....10..121R}}

==External links==
* http://mathworld.wolfram.com/SineIntegral.html
* {{springer|title=Integral sine|id=p/i051650}}
* {{springer|title=Integral cosine|id=p/i051370}}

{{DEFAULTSORT:Trigonometric Integral}}
[[Category:Trigonometry]]
[[Category:Special functions]]
[[Category:Special hypergeometric functions]]
[[Category:Integrals]]

[[ru:Интегральные тригонометрические функции]]</text>
      <sha1>itgyhx3j7nudh85euslca0paef2k2g0</sha1>
    </revision>
  </page>
  <page>
    <title>Vaughan Pratt</title>
    <ns>0</ns>
    <id>1597977</id>
    <revision>
      <id>857772710</id>
      <parentid>851370230</parentid>
      <timestamp>2018-09-02T22:50:01Z</timestamp>
      <contributor>
        <username>Rich Farmbrough</username>
        <id>82835</id>
      </contributor>
      <minor/>
      <comment>Rm "alma mater" in favour of "education" in Infobox person. See [[Template talk:Infobox person]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9859">{{Infobox scientist
| name        = Vaughan Pratt
| birth_name        = Vaughan Ronald Pratt
| image       = VaughanPratt.JPG
| alt         = 
| caption     = 
| birth_date  =         {{birth date and age|1944|4|12}}
| birth_place = [[Melbourne, Australia]]
| death_date  =         &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place = 
| death_cause = 
| resting_place = 
| resting_place_coordinates =  &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names = 
| residence   = 
| citizenship = 
| nationality = 
| fields      = [[Computer science]]
| workplaces  = [[Stanford University]]&lt;br&gt;[[MIT]]
| patrons     = 
| education   = [[Stanford University]] (1972)&lt;br&gt;[[University of Sydney]] (1970)
| thesis_title =        &lt;!--(or  | thesis1_title =  and  | thesis2_title = )--&gt;
| thesis_url  =         &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year =         &lt;!--(or  | thesis1_year =   and  | thesis2_year =  )--&gt;
| doctoral_advisor =    &lt;!--(or  | doctoral_advisors = )--&gt;
| academic_advisors = [[Donald Knuth]]
| doctoral_students = 
| notable_students = 
| known_for   = [[Knuth–Morris–Pratt algorithm]]&lt;br&gt;[[Pratt certificate]]&lt;br&gt;[[Pratt parser]]
| influences  = 
| influenced  = 
| awards      = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse      =         &lt;!--(or | spouses = )--&gt;
| partner     =         &lt;!--(or | partners = )--&gt;
| children    = 
| signature   =         &lt;!--(filename only)--&gt;
| signature_alt = 
| website     =         {{URL|boole.stanford.edu/pratt.html}}
| footnotes   = 
}}
'''Vaughan Pratt''' (born April 12, 1944) is a [[Professor|Professor Emeritus]] at [[Stanford University]], who was an early pioneer in the field of [[computer science]]. Since 1969, Pratt has made several contributions to foundational areas such as [[search algorithm]]s, [[sorting algorithm]]s, and [[primality testing]]. More recently, his research has focused on formal modeling of [[concurrency (computer science)|concurrent systems]] and [[Chu space]]s. A pattern of applying models from diverse areas of mathematics such as [[geometry]], [[linear algebra]], [[abstract algebra]], and especially [[mathematical logic]] to computer science pervades his work.

== Career ==
Raised in Australia and educated at [[Knox Grammar School]], where he was [[Dux#Education|dux]] in 1961, Pratt attended [[Sydney University]] where he completed his masters thesis in 1970, related to what is now known as [[natural language processing]]. He then went to the United States, where he completed a Ph.D. thesis at Stanford University in only 20 months under the supervision of advisor [[Donald Knuth]]. His thesis focused on analysis of the [[Shellsort]] sorting algorithm and [[sorting network]]s.

Pratt was an Assistant Professor at [[Massachusetts Institute of Technology|MIT]] (1972 to 1976) and then Associate Professor (1976 to 1982). In 1974, working in collaboration with Knuth and [[James H. Morris|Morris]], Pratt completed and formalized work he had begun in 1970 as a graduate student at [[University of California, Berkeley|Berkeley]]; the coauthored result was the [[Knuth–Morris–Pratt algorithm|Knuth–Morris–Pratt pattern matching algorithm]]. In 1976, he developed the system of [[dynamic logic (modal logic)|dynamic logic]], a [[modal logic]] of structured behavior.

He went on sabbatical from MIT to [[Stanford University|Stanford]] (1980 to 1981), and was appointed a full professor at Stanford in 1981.

Pratt directed the [[SUN workstation]] project at Stanford from 1980 to 1982. He contributed in various ways to the founding and early operation of [[Sun Microsystems]], acting in the role of consultant for its first year, then, taking a leave of absence from Stanford for the next two years, becoming Director of Research, and finally resuming his role as a consultant to Sun and returning to Stanford in 1985.

He also designed the [[:Image:Sun Microsystems logo.svg|Sun logo]], which features four interleaved copies of the word "sun"; it is an [[ambigram]].

Pratt became professor emeritus at Stanford in 2000.

== Major contributions ==
A number of well-known algorithms bear Pratt's name. [[Pratt certificate]]s, short proofs of the primality of a number, demonstrated in a practical way that primality can be efficiently verified, placing the [[primality test]]ing problem in the complexity class [[NP (complexity)|NP]] and providing the first strong evidence that the problem is not [[co-NP-complete]].&lt;ref&gt;Vaughan Pratt. Every prime has a succinct certificate. ''SIAM Journal on Computing'', vol.4, pp.214–220. 1975. [http://citeseer.ist.psu.edu/context/39245/0 Citations], [http://locus.siam.org/SICOMP/volume-04/art_0204018.html Full-text] (requires paid login)&lt;/ref&gt;
The [[Knuth–Morris–Pratt algorithm]], which Pratt designed in the early 1970s together with fellow Stanford professor [[Donald Knuth]] and independently from [[James H. Morris|Morris]], is still the most efficient general [[string searching algorithm]] known today.&lt;ref&gt;Donald Knuth, James H. Morris, Jr., and Vaughan Pratt. Fast pattern matching in strings. ''SIAM Journal on Computing'', 6(2):323–350. 1977. [http://citeseer.ist.psu.edu/context/23820/0 Citations]&lt;/ref&gt; Along with [[Manuel Blum|Blum]], [[Robert Floyd|Floyd]], [[Ron Rivest|Rivest]], and [[Robert Tarjan|Tarjan]], he described [[median of medians]], the first worst-case optimal [[selection algorithm]].&lt;ref&gt;{{Cite journal | last1 = Blum | first1 = M. | authorlink1 = Manuel Blum| last2 = Floyd | first2 = R. W. | authorlink2 = Robert Floyd| last3 = Pratt | first3 = V. R. | authorlink3 = Vaughan Pratt| last4 = Rivest | first4 = R. L. | authorlink4 = Ron Rivest| last5 = Tarjan | first5 = R. E. | authorlink5 = Robert Tarjan | title = Time bounds for selection | doi = 10.1016/S0022-0000(73)80033-9 | journal = Journal of Computer and System Sciences | volume = 7 | issue = 4  | pages = 448–461 | date =August 1973 | url = http://people.csail.mit.edu/rivest/pubs/BFPRT73.pdf| ref = harv }}&lt;/ref&gt;

===Useful tool building===
Pratt built some useful tools.  In 1976, he wrote an [[Massachusetts Institute of Technology|MIT]] AI Lab working paper about [[CGOL]], an alternative syntax for [[MACLISP]] that he had designed and implemented based on his paradigm for top down operator precedence parsing.&lt;ref&gt;Pratt, V.R., Top Down Operator Precedence. [[POPL|Proceedings of the ACM Symposium on Principles of Programming Languages]]. 1973.  pp41-51.&lt;/ref&gt;  His parser is sometimes called a "[[Pratt parser]]"&lt;ref&gt;George J. Carrette [http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/lang/scheme/code/parsing/pratt/pratt.scm A simple Pratt-Parser] for [[SIOD]]. 1990.&lt;/ref&gt; and has been used in later systems, such as [[MACSYMA]]. [[Douglas Crockford]] also used it as the underlying parser for [[JSLint]].&lt;ref&gt;https://github.com/douglascrockford/JSLint/blob/40e3f73127b56f24a12e5cb091a86d9a24130926/fulljslint.js jslint source code line 2224&lt;/ref&gt;  Pratt also implemented a [[Text Editor and Corrector|TECO]]-based text editor named "DOC", which was later renamed to "ZED".&lt;ref&gt;Eric Fischer. [http://groups.google.com/group/alt.folklore.computers/msg/ee505c7d0b1d0c1e?dmode=source Emacs and Other Editors]. alt.folklore.computers. November 15, 2000.&lt;/ref&gt;

In 1999, Pratt built the world's smallest (at the time) web server—it was the size of a matchbox.&lt;ref&gt;BBC News.[http://news.bbc.co.uk/2/hi/science/nature/276762.stm Surfing on a matchbox]. 1999.&lt;/ref&gt;&lt;ref&gt;CNN News. [http://www.cnn.com/TECH/computing/9902/11/smallweb.idg/ Smallest Web server fits in shirt pocket]. 1999.&lt;/ref&gt;

===Other contributions===
Pratt was credited in a 1995 [[Byte magazine]] article for proposing that the [[Pentium FDIV bug]] might have worse consequences than either Intel or IBM was predicting at the time.&lt;ref&gt;[http://byte.com/art/9503/sec13/art2.htm "How to Bruise an Integer"] {{Webarchive|url=https://web.archive.org/web/20081007181819/http://www.byte.com/art/9503/sec13/art2.htm |date=2008-10-07 }}, Byte, March 1995.&lt;/ref&gt;&lt;ref&gt;[http://www.khd-research.net/Notes/wdv-notes_334.pdf "Chain Reaction in Pentiums"], Vaughan Pratt, 1994.  In wdv-notes334, 22 Jan, 1995.  Article is formatted from a newsgroup posting: {{cite newsgroup
  | title = "TECHNICAL: Chain reaction in Pentiums (Was: The Flaw: Pentium-Contaminated Data Persists)"
  | author = Vaughan Pratt
  | date = 1994-12-30
  | newsgroup = comp.sys.intel
  |message-id= 3e097i$952@Radon.Stanford.EDU
  | url = http://groups.google.com/group/comp.sys.intel/msg/797cf26bcfb4f67a?dmode=source
  | accessdate = 2006-06-03 }}&lt;/ref&gt;

Today Pratt has a wide influence. In addition to his Stanford professorship, he holds membership in at least seven professional organizations. He is a fellow of the [[Association for Computing Machinery]] and is on the editorial board of three major mathematics journals. He was also the founder, Chairman, and CTO of [http://www.tiqit.com/ TIQIT Computers, Inc.] for the ten years prior to when it closed its doors in 2010.

== References ==
{{reflist}}

== External links ==
* {{MathGenealogy|id=40894}}
* [http://boole.stanford.edu/pratt.html Faculty home page at Stanford University]
* [http://boole.stanford.edu/abstracts.html Abstract page], with full-text downloads of many of Pratt's publications.
* [http://javascript.crockford.com/tdop/tdop.html Douglas Crockford walks through creating a Pratt parser in JavaScript.]

{{Authority control}}

{{DEFAULTSORT:Pratt, Vaughan}}
[[Category:1944 births]]
[[Category:Living people]]
[[Category:Australian computer scientists]]
[[Category:Fellows of the Association for Computing Machinery]]
[[Category:Stanford University alumni]]
[[Category:Stanford University School of Engineering faculty]]
[[Category:Theoretical computer scientists]]</text>
      <sha1>9bf2ycj2qsr9xbzfdezddzyegv3nkft</sha1>
    </revision>
  </page>
  <page>
    <title>Word problem (mathematics education)</title>
    <ns>0</ns>
    <id>297013</id>
    <revision>
      <id>847376580</id>
      <parentid>847375661</parentid>
      <timestamp>2018-06-24T22:24:21Z</timestamp>
      <contributor>
        <ip>100.33.66.142</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7449">{{About|a type of exercise in mathematics education|other uses|Word problem (disambiguation)}}

In [[science education]], a '''word problem''' is a [[mathematical exercise]] where significant background information on the problem is presented as text rather than in [[mathematical notation]].&lt;ref&gt;L Verschaffel, B Greer, E De Corte (2000) ''Making Sense of Word Problems'', Taylor &amp; Francis&lt;/ref&gt; As word problems often involve a [[narrative]] of some sort, they are occasionally also referred to as '''story problems''' and may vary in the amount of language used.&lt;ref name="Moyer 1984"&gt;John C. Moyer; Margaret B. Moyer; Larry Sowder; Judith Threadgill-Sowder (1984) ''Story Problem Formats: Verbal versus Telegraphic'' Journal for Research in Mathematics Education, Vol. 15, No. 1. (Jan., 1984), pp. 64-68. {{jstor|748989}}&lt;/ref&gt;

== Example ==
Here is a mathematical problem in mathematical notation:

: Solve for {{italics correction|''J''}}:
:: &lt;math&gt;J=A-20&lt;/math&gt;
:: &lt;math&gt;J+5=\frac{A+5}{2}&lt;/math&gt;

The same problem might be presented in the form of a word problem as follows:

:''John is twenty years younger than Amy, and in five years' time he will be half her age. What is John's age now?''

The answer to the word problem is that John is 15 years old, while the answer to the mathematical problem is that ''J'' equals 15 (and ''A'' equals 35).

== Structure ==

Word problems can be examined on three levels:&lt;ref name="Nesher 1975"&gt;Perla Nesher Eva Teubal (1975)''Verbal Cues as an Interfering Factor in Verbal Problem Solving''  Educational Studies in Mathematics, Vol. 6, No. 1. (Mar., 1975), pp. 41-51. {{jstor|3482158}}&lt;/ref&gt;

:*Level a: the verbal formulation;
:*Level b: the underlying mathematical relations;
:*Level c: the symbolic mathematical expression.
Linguistic properties can include such variables as the number of words in the problem or the mean sentence length.&lt;ref name="Lepik 1990"&gt;Madis Lepik (1990) ''Algebraic Word Problems: Role of Linguistic and Structural Variables'',  Educational Studies in Mathematics, Vol. 21, No. 1. (Feb., 1990), pp. 83-90., {{jstor|3482220}}&lt;/ref&gt; The logico-mathematical properties can be classified in numerous ways, but one such scheme is to classify the quantities in the problem (assuming the word problem is primarily numerical) into known quantities (the values given in the text of the problem), wanted quantities (the values that need to be found) and auxiliary quantities (values that may need to be found as intermediate stages of the problem).&lt;ref name="Lepik 1990" /&gt;

The most common types of word problems are distance problems, age problems, work problems, percentage problems, mixtures problems and numbers problems.{{cn|date=September 2016}}

== Purpose and use ==

Word problems commonly include [[mathematical model]]ling questions, where data and information about a certain system is given and a student is required to develop a model. For example:{{Citation needed|date=May 2013}}

# Jane has $5.00, but uses $2.00 to buy something. How much money does she have now?
# If the water level in a cylinder with a radius of 2&amp;nbsp;m is rising at a rate of 3&amp;nbsp;m/s, what is the rate of increase of the volume of water?

These examples are not only intended to force the students into developing mathematical models on their own, but may also be used to promote mathematical interest and understanding by relating the subject to real-life situations{{Citation needed|date=May 2013}}. The relevance of these situations to the students is varying. The situation in the first example is well-known to most people and may be useful in helping [[primary school]] students to understand the concept of subtraction. The second example, however, does not necessarily have to be "real-life" to a high school student, who may find that it is easier to handle the following problem:

: Given &lt;math&gt;r=2&lt;/math&gt; and &lt;math&gt;\frac{dh}{dt}=3&lt;/math&gt; , find &lt;math&gt;\frac{d}{dt}(\pi r^2h).&lt;/math&gt;

Word problems are a common way to train and test understanding of underlying concepts within a descriptive problem, instead of solely testing the student's capability to perform algebraic manipulation or other "mechanical" skills{{Citation needed|date=May 2013}}.

==History and culture==

The modern notation that enables mathematical ideas to be expressed symbolically was developed in Europe from the sixteenth century onwards. Prior to this, all mathematical problems and solutions were written out in words; the more complicated the problem, the more laborious and convoluted the verbal explanation.

Examples of word problems can be found dating back to [[Babylonia]]n times. Apart from a few procedure texts for finding things like square roots, most Old Babylonian problems are couched in a language of measurement of everyday objects and activities. Students had to find lengths of canals dug, weights of stones, lengths of broken reeds, areas of fields, numbers of bricks used in a construction, and so on.&lt;ref name="Melville 1999"&gt;Duncan J Melville (1999) ''Old Babylonian Mathematics'' http://it.stlawu.edu/%7Edmelvill/mesomath/obsummary.html&lt;/ref&gt;

Ancient Egyptian mathematics also has examples of word problems. The [[Rhind Mathematical Papyrus]] includes a problem that can be translated as:
&lt;blockquote&gt;
There are seven houses; in each house there are seven cats; each cat kills seven mice; each mouse has eaten seven grains of barley; each grain would have produced seven [[hekat]]. What is the sum of all the enumerated things?&lt;ref name="Egypt Buffalo"&gt;[http://www.math.buffalo.edu/mad/Ancient-Africa/mad_ancient_egypt_algebra.html#rhind79 Egyptian Algebra - Mathematicians of the African Diaspora&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;
&lt;/blockquote&gt;
In more modern times the sometimes confusing and arbitrary nature of word problems has been the subject of satire. [[Gustave Flaubert]] wrote this nonsensical problem, now known as the [[Age of the captain]]:
&lt;blockquote&gt;
Since you are now studying geometry and trigonometry, I will give you a problem. A ship sails the ocean. It left Boston with a cargo of wool. It grosses 200 tons. It is bound for Le Havre. The mainmast is broken, the cabin boy is on deck, there are 12 passengers aboard, the wind is blowing East-North-East, the clock points to a quarter past three in the afternoon. It is the month of May. How old is the captain? &lt;ref name="Maths Quotes"&gt;[http://math.furman.edu/~mwoodard/ascquotf.html Mathematical Quotations - F&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;
&lt;/blockquote&gt; 

Word problems have also been satirised in ''[[The Simpsons]]'', when a lengthy word problem ("An express train traveling 60 miles per hour leaves Santa Fe bound for Phoenix, 520 miles away.  At the same time, a local train traveling 30 miles an hour carrying 40 passengers leaves Phoenix bound for Santa Fe...") trails off with a schoolboy character instead imagining that he is on the train.&lt;ref name="Simpsons"&gt;[http://homepage.smc.edu/nestler_andrew/SimpsonsMath.htm Andrew Nestler's Guide to Mathematics and Mathematicians on The Simpsons&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

==References==
{{reflist}}

== External links ==
* [http://www.cut-the-knot.org/arithmetic/WProblem.shtml Word problems that lead to simple linear equations] at [[cut-the-knot]]
* [http://www.aplusclick.com/wordproblems.htm A+Click Word Problems for grade 1 through 12]

{{DEFAULTSORT:Word Problem (Mathematics Education)}}
[[Category:Mathematics education]]</text>
      <sha1>1787gvc794up8v9vny9zqlher4pzww8</sha1>
    </revision>
  </page>
</mediawiki>
