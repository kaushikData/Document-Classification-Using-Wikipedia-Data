<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>35 (number)</title>
    <ns>0</ns>
    <id>379525</id>
    <revision>
      <id>870240401</id>
      <parentid>870237518</parentid>
      <timestamp>2018-11-23T12:35:54Z</timestamp>
      <contributor>
        <username>Certes</username>
        <id>5984052</id>
      </contributor>
      <comment>Revert IP vandal</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3517">{{about|the number||35 (disambiguation)}}
{{Infobox number
| number =  35
| divisor = 1, 5, 7, 35
}}
'''35''' ('''thirty-five''') is the [[natural number]] following [[34 (number)|34]] and preceding [[36 (number)|36]].

== In mathematics ==
[[Image:Pyramid of 35 spheres animation.gif|thumb|left|35 is a tetrahedral number]]
[[Image:All 35 free hexominoes.svg|thumb|right|245px|The 35 free hexominoes]]
35 is the sum of the first five [[triangular number]]s, making it a [[tetrahedral number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A000292|title=Sloane's A000292 : Tetrahedral numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-31}}&lt;/ref&gt;

35 is the number of ways that three things can be selected from a set of seven unique things also known
as the "[[combination]] of seven things taken three at a time".

35 is a [[centered cube number]],&lt;ref&gt;{{Cite web|url=https://oeis.org/A005898|title=Sloane's A005898 : Centered cube numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-31}}&lt;/ref&gt; a [[pentagonal number]]&lt;ref&gt;{{Cite web|url=https://oeis.org/A000326|title=Sloane's A000326 : Pentagonal numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-31}}&lt;/ref&gt; and a [[pentatope number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A000332|title=Sloane's A000332 : Binomial coefficient binomial(n,4) = n*(n-1)*(n-2)*(n-3)/24|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-31}}&lt;/ref&gt;

35 is a [[highly cototient number]], since there are more solutions to the equation ''x'' − φ(''x'') = 35 than there are for any other integers below it except 1.&lt;ref&gt;{{Cite web|url=https://oeis.org/A100827|title=Sloane's A100827 : Highly cototient numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-31}}&lt;/ref&gt;

There are 35 free [[hexomino]]es, the [[polyomino]]es made from six squares.

Since the greatest prime factor of 35&lt;sup&gt;2&lt;/sup&gt; + 1 = 1226 is 613, which is obviously more than 35 twice, 35 is a [[Størmer number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A005528|title=Sloane's A005528 : Størmer numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-31}}&lt;/ref&gt;

35 is a discrete [[semiprime]] (or biprime) (5 × 7); the tenth, and the first with 5 as the lowest non-unitary factor. The aliquot sum of 35 is 13 this being the second [[composite number]] with such an aliquot sum; the first being the cube 27. 35 is the last member of the first triple cluster of semiprimes 33, 34, 35. The second such triple discrete semiprime cluster is 85, 86, 87.

35 is the highest number one can count to on one's fingers using [[Senary#Finger counting|base 6]].

35 is the number of quasigroups of order 4

==In science==
*The [[atomic number]] of [[bromine]]

== In other fields ==
* [[35 mm film]] is the basic film gauge most commonly used for both analog [[photography]] and [[motion pictures]]
* The minimum age of presidential candidates for election to the [[United States Presidency|United States]], [[President of Ireland|Ireland]], [[President of the Russian Federation|Russia]]  and [[President of Uruguay|Uruguay]].

== References ==
{{Reflist}}

{{Integers|zero}}

[[Category:Integers]]</text>
      <sha1>9ygsd36ir6ku0bc7uxnc3zcij6d0ucl</sha1>
    </revision>
  </page>
  <page>
    <title>Acnode</title>
    <ns>0</ns>
    <id>3090256</id>
    <revision>
      <id>831351608</id>
      <parentid>831351470</parentid>
      <timestamp>2018-03-20T04:04:41Z</timestamp>
      <contributor>
        <ip>140.112.54.158</ip>
      </contributor>
      <comment>Undid revision 831351470 by [[Special:Contributions/140.112.54.158|140.112.54.158]] ([[User talk:140.112.54.158|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1844">[[Image:Isolated-point.svg|thumb|right|An acnode at the origin (curve described in text)]]

An '''acnode''' is an isolated point in the solution set of a polynomial equation in two real variables. Equivalent terms are  "[[isolated point|isolated point or hermit point]]".&lt;ref&gt;{{SpringerEOM| title=Acnode | id=Acnode | oldid=15498 | first=M. | last=Hazewinkel }}&lt;/ref&gt;

For example the equation
:&lt;math&gt;f(x,y)=y^2+x^2-x^3=0&lt;/math&gt;
has an acnode at the origin, because it is equivalent to
:&lt;math&gt;y^2 = x^2 (x-1)&lt;/math&gt;
and &lt;math&gt;x^2(x-1)&lt;/math&gt; is non-negative only when &lt;math&gt;x&lt;/math&gt; ≥ 1 or &lt;math&gt;x = 0&lt;/math&gt;.  Thus, over the ''real'' numbers the equation has no solutions for &lt;math&gt;x &lt; 1&lt;/math&gt; except for (0, 0).

In contrast, over the complex numbers the origin is not isolated since square roots of negative real numbers exist. In fact, the complex solution set of a polynomial equation in two complex variables can never have an isolated point.

An acnode is a critical point, or [[singularity theory|singularity]], of the defining polynomial function, in the sense that both partial derivatives &lt;math&gt;\partial f\over \partial x&lt;/math&gt; and &lt;math&gt;\partial f\over \partial y&lt;/math&gt; vanish. Further the [[Hessian matrix]] of second derivatives will be [[Positive-definite matrix|positive definite]] or [[Negative-definite matrix|negative definite]], since the function must have a local minimum or a local maximum at the singularity.

==See also==
*[[Singular point of a curve]]
*[[Crunode]]
*[[Cusp (singularity)|Cusp]]
*[[Tacnode]]

==References==
{{reflist}}
*{{cite book |last=Porteous |first=Ian |title=Geometric Differentiation |year=1994 |publisher=[[Cambridge University Press]] |isbn=0-521-39063-X }}

{{Algebraic curves navbox}}

[[Category:Curves]]
[[Category:Algebraic curves]]
[[Category:Singularity theory]]

{{geometry-stub}}</text>
      <sha1>32gzubl0wig9fhsmit69ax32wuvfjq3</sha1>
    </revision>
  </page>
  <page>
    <title>Auslander–Reiten theory</title>
    <ns>0</ns>
    <id>30350056</id>
    <revision>
      <id>747831554</id>
      <parentid>745555930</parentid>
      <timestamp>2016-11-04T16:59:23Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* References */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6307">In [[algebra]], '''Auslander–Reiten theory''' studies the [[representation theory]] of [[Artinian ring]]s using techniques such as '''Auslander–Reiten sequences''' (also called '''almost split sequences''') and '''Auslander–Reiten quivers'''. Auslander–Reiten theory was introduced by {{harvs|txt|first=Maurice |last=Auslander|author1-link=Maurice Auslander|first2=Idun |last2=Reiten|author2-link=Idun Reiten|year=1975}} and developed by them in several subsequent papers.

For survey articles on Auslander–Reiten theory see {{harvtxt|Auslander|1982}}, {{harvtxt|Gabriel|1980}}, {{harvtxt|Reiten|1982}}, and the book {{harvtxt|Auslander|Reiten|Smalø|1997}}. Many of the original papers on Auslander–Reiten theory are reprinted in  {{harvs|txt|last=Auslander|year1=1999a|year2=1999b}}.

==Almost-split sequences==

Suppose that ''R'' is an Artin algebra. A sequence 
:0&amp;rarr; ''A'' &amp;rarr; ''B'' &amp;rarr; ''C'' &amp;rarr; 0
of finitely generated left modules over ''R'' is called an '''almost-split sequence''' (or '''Auslander–Reiten sequence''') if it has the following properties:
*The sequence is not split
*''C'' is indecomposable and any homomorphism from an indecomposable module to ''C'' that is not an isomorphism factors through ''B''.
*''A'' is indecomposable and any homomorphism from ''A'' to an indecomposable module that is not an isomorphism factors through ''B''.

For any finitely generated left module ''C'' that is indecomposable but not projective there is an almost-split sequence as above, which is unique up to isomorphism. Similarly for any finitely generated left module ''A'' that is indecomposable but not injective there is an almost-split sequence as above, which is unique up to isomorphism.

The module ''A'' in the almost split sequence is isomorphic to D Tr ''C'', the [[Artin algebra|dual]] of the [[Artin algebra|transpose]] of ''C''.

===Example===

Suppose that ''R'' is the ring ''k''[''x'']/(''x''&lt;sup&gt;''n''&lt;/sup&gt;) for a field ''k'' and an integer ''n''≥1. The indecomposable modules are isomorphic to one of ''k''[''x'']/(''x''&lt;sup&gt;''m''&lt;/sup&gt;) for 1≤ ''m'' ≤ ''n'', and the only projective one has ''m''=''n''. The almost split sequences are isomorphic to 
:&lt;math&gt; 0 \rightarrow k[x]/(x^m) \rightarrow k[x]/(x^{m+1}) \oplus k[x]/(x^{m-1}) \rightarrow k[x]/(x^{m}) \rightarrow 0&lt;/math&gt;
for  1 ≤ ''m'' &lt; ''n''. The first morphism takes ''a'' to (''xa'', ''a'') and the second takes (''b'',''c'') to&amp;nbsp;''b''&amp;nbsp;&amp;minus;&amp;nbsp;''xc''.

==Auslander-Reiten quiver==

The '''Auslander-Reiten quiver''' of an Artin algebra has a vertex for each indecomposable module and an arrow between vertices if there is an irreducible morphism between the corresponding modules. It has a map τ = ''D Tr'' called the '''translation''' from the non-projective vertices to the non-injective vertices, where ''D'' is the dual and ''Tr'' the [[Artin algebra|transpose]].

==References==

*{{Citation | last1=Auslander | first1=Maurice | title=Representations of algebras (Puebla, 1980) | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Math. | doi=10.1007/BFb0094058 | mr=672116 | year=1982 | volume=944 | chapter=A functorial approach to representation theory | pages=105–179}}
*{{Citation | last1=Auslander | first1=Maurice | title=Proceedings of the International Congress of Mathematicians, Vol. 1 (Berkeley, Calif., 1986) | url=http://www.mathunion.org/ICM/ICM1986.1/ | publisher=Amer. Math. Soc. | location=Providence, R.I. | mr=934232 | year=1987 | chapter=The what, where, and why of almost split sequences | pages=338–345}}
*{{Citation | last1=Auslander | first1=Maurice | last2=Reiten | first2=Idun | last3=Smalø | first3=Sverre O. | title=Representation theory of Artin algebras | origyear=1995 | url=https://books.google.com/books?isbn=0521599237 | publisher=[[Cambridge University Press]] | series=Cambridge Studies in Advanced Mathematics | isbn=978-0-521-59923-8 | mr=1314422 | year=1997 | volume=36}}
*{{Citation | last1=Auslander | first1=Maurice | editor1-last=Reiten | editor1-first=Idun | editor2-last=Smalø | editor2-first=Sverre O. | editor3-last=Solberg | editor3-first=Øyvind | title=Selected works of Maurice Auslander. Part 1 | url=https://books.google.com/books?isbn=0821809989 | publisher=[[American Mathematical Society]] | location=Providence, R.I. | isbn=978-0-8218-0998-3 | mr=1674397 | year=1999a}}
*{{Citation | last1=Auslander | first1=Maurice | editor1-last=Reiten | editor1-first=Idun | editor2-last=Smalø | editor2-first=Sverre O. | editor3-last=Solberg | editor3-first=Øyvind | title=Selected works of Maurice Auslander. Part 2 | url=https://books.google.com/books?isbn=0821810006 | publisher=[[American Mathematical Society]] | location=Providence, R.I. | isbn=978-0-8218-1000-2 | mr=1674401 | year=1999b}}
*{{Citation | last1=Auslander | first1=Maurice | last2=Reiten | first2=Idun | title=Representation theory of Artin algebras. III. Almost split sequences | doi=10.1080/00927877508822046  | mr=0379599 | year=1975 | journal=Communications in Algebra | issn=0092-7872 | volume=3 | issue=3 | pages=239–294}}
*{{Citation | last1=Gabriel | first1=Peter | editor1-last=Dlab | editor1-first=Vlastimil | editor2-last=Gabriel | editor2-first=Peter | title=Representation theory, I (Proc. Workshop, Carleton Univ., Ottawa, Ont., 1979) | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Math. | doi=10.1007/BFb0089778 | mr=607140 | year=1980 | volume=831 | chapter=Auslander-Reiten sequences and representation-finite algebras | pages=1–71}}
*{{eom|id=A/a130220|title=Almost-split sequence|first=M.|last= Hazewinkel}}
*{{Citation | last1=Reiten | first1=Idun | title=Representations of algebras (Puebla, 1980) | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Math. | doi=10.1007/BFb0094057 | mr=672115 | year=1982 | volume=944 | chapter=The use of almost split sequences in the representation theory of Artin algebras | pages=29–104}}

==External links==
*{{citation|url=http://www.math.jussieu.fr/~keller/ictp2006/lecturenotes/angeleri.pdf |title=An Introduction to Auslander-Reiten Theory  |first=Lidia|last=Angeleri Hügel|year=2006}}

{{DEFAULTSORT:Auslander-Reiten theory}}
[[Category:Representation theory]]</text>
      <sha1>omplm97i5n44n94r0m71ya64h7w9qpa</sha1>
    </revision>
  </page>
  <page>
    <title>Avner Magen</title>
    <ns>0</ns>
    <id>34632550</id>
    <revision>
      <id>837623520</id>
      <parentid>797019757</parentid>
      <timestamp>2018-04-22T00:10:26Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (2 sources from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3742">{{Infobox scientist
| name                    = Avner Magen
| image = &lt;!-- only free-content images are allowed for depicting living people - see [[WP:NONFREE]] --&gt;
| image_size = 150px |
| caption                 = Avner Magen
| birth_date              = March 30, 1968
| birth_place             =
| death_date              = {{D-da|May 29, 2010|March 30, 1968}} 
| death_place             = Alaska Denali National Park
| residence               = Canada
| nationality             = Israeli
| ethnicity               = 
| field                   = [[Metric Embeddings]], [[Discrete Geometry]], [[Computational Geometry]]
| work_institution        = [[University of Toronto]]
| alma_mater              = [[Hebrew University of Jerusalem]]
| doctoral_advisor        = [[Nati Linial]]
| doctoral_students       =
| prizes                  = [[Ontario Early Researcher Award]], 2007
| known_for               =
| author_abbreviation_bot =
| author_abbreviation_zoo =
| footnotes               =
}}

'''Avner Magen''' (March 30, 1968 – May 29, 2010) was an associate professor of computer science at the [[University of Toronto]] whose research focused on the theory of metric embeddings, [[discrete geometry]] and [[computational geometry]]. He completed his undergraduate and graduate studies at the [[Hebrew University of Jerusalem]], and received his Ph.D. in Computer Science in 2002, under the supervision of [[Nati Linial]].&lt;ref&gt;{{mathgenealogy|name=Avner Magen|id=148458}}.&lt;/ref&gt; He held a postdoctoral fellowship at NEC Research in [[Princeton, New Jersey|Princeton]], [[New Jersey]], from 2000 until 2002. He joined the [[University of Toronto]] in 2002, first as a postdoctoral fellow, and then as an assistant professor in 2004. He was promoted to associate professor in 2009.&lt;ref name="bio"&gt;{{citation|url=http://www.avnermagenmemorial.com/avner-magen-biography.php|title=Biography|work=Avner Magen (1968 - 2010)|first1= John|last1=MacKenzie|first2= Toniann|last2=Pitassi|author2-link= Toniann Pitassi|first3= Richard|last3=Zemel|accessdate=2016-03-04}}.&lt;/ref&gt;

His major contributions include an algorithm for approximating the weight of the [[Euclidean minimum spanning tree]] in sublinear time, and finding a tight integrality gap for the [[vertex cover]] problem using the [[Frankl–Rödl graph]]s. He proved with his coauthors essentially that a huge class of [[semidefinite programming]] algorithms for the famous vertex cover problem will not achieve a solution of value less than the value of the optimal solution times a factor of two. With [[Nati Linial]] and [[Michael Saks (mathematician)|Michael Saks]], he showed how to embed trees into Euclidean metrics with low {{math|''O''(log log ''n'')}} [[stretch factor|distortion]]. And in a later result, he showed how to do [[Johnson–Lindenstrauss lemma|JL-style embeddings]] that preserved not only distances, but also higher order volumes.&lt;ref name="bio"/&gt;

He died in a climbing accident in [[Alaska]] on May 29, 2010, leaving behind three children and a wife.&lt;ref&gt;{{citation|title=Torontonians killed in Alaska avalanche|newspaper=[[The Globe and Mail]]|url=https://www.theglobeandmail.com/news/national/torontonians-killed-in-alaska-avalanche/article1587420/|first=Sarah|last=Boesveld|date=May 31, 2010}}.&lt;/ref&gt;

==References==
{{Reflist}}

==External links==
*[http://www.cs.toronto.edu/~avner/ Avner Magen's home page at University of Toronto].

{{Authority control}}

{{DEFAULTSORT:Magen, Avner}}
[[Category:1968 births]]
[[Category:2010 deaths]]
[[Category:Mountaineering deaths]]
[[Category:Canadian computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:Hebrew University of Jerusalem alumni]]
[[Category:University of Toronto faculty]]</text>
      <sha1>fvkv9ithkbchhu3xldsy0wn9fcalulo</sha1>
    </revision>
  </page>
  <page>
    <title>Ban number</title>
    <ns>0</ns>
    <id>8282811</id>
    <revision>
      <id>870827498</id>
      <parentid>870827257</parentid>
      <timestamp>2018-11-27T07:07:37Z</timestamp>
      <contributor>
        <username>Nixinova</username>
        <id>29717766</id>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2457">In [[recreational mathematics]], a '''ban number''' is a number that does not contain a particular letter when spelled out in English; in other words, the letter is "banned." Ban numbers are not precisely defined, since some [[large number]]s do not follow the standards of number names (such as [[googol]] and [[googolplex]]).

There are several published sequences of ban numbers:
* The '''aban numbers''' do not contain the letter [[A]]. The first few aban numbers are 1 through 999, 1,000,000 through 1,000,999, 2,000,000 through 2,000,999, ... The word "and" is not counted.
* The '''eban numbers''' do not contain the letter [[E]]. The first few eban numbers are 2, 4, 6, 30, 32, 34, 36, 40, 42, 44, 46, 50, 52, 54, 56, 60, 62, 64, 66, 2000, 2002, 2004, ... {{OEIS|A006933}}. The sequence was coined in 1990 by [[Neil Sloane]]. Coincidentally, all the numbers in the sequence are even.
* The '''iban numbers''' do not contain the letter [[I]]. The first few iban numbers are 1, 2, 3, 4, 7, 10, 11, 12, 14, 17, 20, 21, 22, 23, 24, 27, 40, ... {{OEIS|A089589}}. Since all -illion numbers contain the letter I, there are exactly 30,275 iban numbers, the largest being 777,777.
* The '''oban numbers''' do not contain the letter [[O]]. The first few oban numbers are 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 23, 25, 26, ... {{OEIS|A008521}}. Since "thousand" and all the -illion numbers contain the letter O, there are exactly 454 oban numbers, the largest being 999.
* The '''tban numbers''' do not contain the letter [[T]]. The first few tban numbers are 1, 4, 5, 6, 7, 9, 11, 100, 101, 104, 105, 106, 107, 109, 111, 400, 401, 404, 405, 406, ... {{OEIS|A008523}}.
* The '''uban numbers''' do not contain the letter [[U]]. The first few uban numbers are 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, ... {{OEIS|A089590}}.

==Further reading==
*{{cite book|last1=Hernandez|first1=J. C.|last2=Mex-Perera|first2=C.|last3=Shepherd|first3=S. J.|title=Characterization of Eban Numbers|publisher=J. Recr. Math|edition=31|page=197–200|year=2002–2003}}

==External links==
* {{MathWorld | urlname=AbanNumber | title=Aban Number}}
* {{mathworld|urlname=EbanNumber|title=Eban number}}
* {{mathworld|urlname=IbanNumber|title=Iban number}}
* {{mathworld|urlname=ObanNumber|title=Oban Number}}
* {{mathworld|urlname=UbanNumber|title=Uban number}}

{{Classes of natural numbers}}
[[Category:Integer sequences]]</text>
      <sha1>047d5uoqient2cjon63t7f62nko3lid</sha1>
    </revision>
  </page>
  <page>
    <title>Basil Gordon</title>
    <ns>0</ns>
    <id>34475270</id>
    <revision>
      <id>866526911</id>
      <parentid>829781852</parentid>
      <timestamp>2018-10-30T21:50:00Z</timestamp>
      <contributor>
        <username>Bender235</username>
        <id>88026</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3789">{{ Infobox scientist
| name              = Basil Gordon
| image             = 
| image_size        =
| caption           = 
| birth_date        = {{Birth date|1931|12|23|mf=y}}
| birth_place       =
| death_date        ={{Death date and age|2012|1|12|1931|12|23|mf=y}}
| death_place       =
| nationality       = [[United States]]
| fields            = [[Mathematics]]
| work_institutions =[[UCLA]]
| alma_mater        = [[California Institute of Technology]]
| doctoral_advisor  = [[Tom M. Apostol]]
| doctoral_students =
| notable_students  = [[Ken Ono]]
| known_for         =
}}

'''Basil Gordon''' (December 23, 1931 – January 12, 2012) was a [[mathematician]] at [[UCLA]], specializing in [[number theory]] and [[combinatorics]].&lt;ref&gt;{{cite web|url=http://www.legacy.com/obituaries/latimes/obituary.aspx?n=basil-gordon&amp;pid=155716795 |title=Basil Gordon Obituary: View Basil Gordon's Obituary by Los Angeles Times |publisher=Legacy.com |date= |accessdate=2012-03-23}}&lt;/ref&gt; He obtained his Ph.D. at [[California Institute of Technology]] under the supervision of [[Tom M. Apostol|Tom Apostol]].  [[Ken Ono]] was one of his students.

Gordon is well known for Göllnitz–Gordon identities, generalizing the [[Rogers–Ramanujan identities]].&lt;ref&gt;[[Krishnaswami Alladi]] (2013) [http://www.ams.org/notices/201307/rnoti-p856.pdf Remembering Basil Gordon], 1931-2012, [[Notices of the American Mathematical Society|NAMS]] '''60'''(7), 856-865.&lt;/ref&gt; He also posed the still-unsolved [[Gaussian moat]] problem in 1962.&lt;ref&gt;{{citation
 | last1 = Gethner | first1 = Ellen
 | last2 = Wagon | first2 = Stan | author2-link = Stan Wagon
 | last3 = Wick | first3 = Brian
 | doi = 10.2307/2589708
 | issue = 4
 | journal = The American Mathematical Monthly
 | mr = 1614871
 | pages = 327–337
 | title = A stroll through the Gaussian primes
 | volume = 105
 | year = 1998}}.&lt;/ref&gt;

Gordon was drafted into the [[US Army]], where he worked with the former [[Nazi]] [[rocket scientist]], [[Wernher von Braun]]. Gordon's calculations of the [[gravity|gravitational interactions]] of [[earth]], moon, and satellite contributed to the success and longevity of [[Explorer I]], which launched in 1958 and remained in orbit until 1970.&lt;ref&gt;{{cite web|url=http://www.legacy.com/obituaries/latimes/obituary.aspx?n=basil-gordon&amp;pid=155716795 |title=Basil Gordon Obituary: View Basil Gordon's Obituary by Los Angeles Times |publisher=Legacy.com |date= |accessdate=2012-08-16}}&lt;/ref&gt; He was the step-grandson of General [[George Barnett]] and is a descendant of the Gordon family of British [[distiller]]s, producers of [[Gordon's Gin]].

==References==
{{reflist}}

== External links ==
* {{MathGenealogy |id=1490}}
* {{MathWorld| id =Goellnitz-GordonIdentities |title= Göllnitz–Gordon identities}}
* {{cite journal
|url=http://www.mathcs.emory.edu/~ono/publications-cv/pdfs/091.pdf
|title= On the work of Basil Gordon
|first1=Krishnaswami |last1=Alladi | author1-link = Krishnaswami Alladi
|first2=George |last2=Andrews
|first3=Ken |last3=Ono
|first4=Richard J. |last4=McIntosh |volume=113 | number=1
|journal=J. Combinat. Theory, Series A
|year=2006 |pages=21–38 |doi=10.1016/j.jcta.2005.10.004
}}
* [http://www.math.ucla.edu/gordon.shtml In memoriam: Basil Gordon,Professor of Mathematics, Emeritus, 1931 – 2012], UCLA Mathematics Department website
* [http://thesis.library.caltech.edu/1063/1/Gordon_b_1956.pdf Some Tauberian Theorems connected with the Prime Number Theorem], Basil Gordon, PhD thesis, 1956
{{Authority control}}
{{DEFAULTSORT:Gordon, Basil}}
[[Category:2012 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Combinatorialists]]
[[Category:California Institute of Technology alumni]]
[[Category:1931 births]]</text>
      <sha1>1ybpe87l1cr6axfxfzjcfgr217pp9sy</sha1>
    </revision>
  </page>
  <page>
    <title>Basu's theorem</title>
    <ns>0</ns>
    <id>7807871</id>
    <revision>
      <id>837219372</id>
      <parentid>823456628</parentid>
      <timestamp>2018-04-19T13:26:05Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5898">In [[statistics]], '''Basu's theorem''' states that any [[completeness (statistics)|boundedly complete]] [[sufficient statistic]] is [[statistical independence|independent]] of any [[ancillary statistic]]. This is a 1955 result of [[Debabrata Basu]].&lt;ref&gt;Basu (1955)&lt;/ref&gt;

It is often used in statistics as a tool to prove independence of two statistics, by first demonstrating one is complete sufficient and the other is ancillary, then appealing to the theorem.&lt;ref&gt;{{citation|title=Sequential Estimation|volume=904|series=Wiley Series in Probability and Statistics|first1=Malay|last1=Ghosh|first2=Nitis|last2=Mukhopadhyay|first3=Pranab Kumar|last3=Sen|publisher=John Wiley &amp; Sons|year=2011|isbn=9781118165911|page=80|url=https://books.google.com/books?id=_5Xqo02nzO0C&amp;pg=PA80|quote=The following theorem, due to Basu ... helps us in proving independence between certain types of statistics, without actually deriving the joint and marginal distributions of the statistics involved. This is a very powerful tool and it is often used ...}}&lt;/ref&gt; An example of this is to show that the sample mean and sample variance of a normal distribution are independent statistics, which is done in the [[#Example|Example]] section below. This property (independence of sample mean and sample variance) characterizes normal distributions.

== Statement ==
Let &lt;math&gt;(P_\theta; \theta \in \Theta)&lt;/math&gt; be a family of distributions on a [[measurable space]] &lt;math&gt;(X, \mathcal{A})&lt;/math&gt; and &lt;math&gt;T,A&lt;/math&gt; measurable maps  from &lt;math&gt;(X, \mathcal{A})&lt;/math&gt; to some measurable space &lt;math&gt;(Y, \mathcal{B})&lt;/math&gt;. (Such maps are called a [[statistic]].) If &lt;math&gt;T&lt;/math&gt; is a boundedly complete sufficient statistic for &lt;math&gt;\theta&lt;/math&gt;, and &lt;math&gt;A&lt;/math&gt; is ancillary to &lt;math&gt;\theta&lt;/math&gt;, then &lt;math&gt;T&lt;/math&gt; is independent of &lt;math&gt;A&lt;/math&gt;.

=== Proof ===
Let &lt;math&gt;P_\theta^T&lt;/math&gt; and &lt;math&gt;P_\theta^A&lt;/math&gt; be the [[marginal distribution]]s of &lt;math&gt;T&lt;/math&gt; and &lt;math&gt;A&lt;/math&gt; respectively.

Denote by &lt;math&gt;A^{-1}(B)&lt;/math&gt; the [[preimage]] of a set &lt;math&gt;B&lt;/math&gt; under the map &lt;math&gt;A&lt;/math&gt;. For any measurable set &lt;math&gt;B \in \mathcal{B}&lt;/math&gt; we have

:&lt;math&gt;P_\theta^A(B) = P_\theta (A^{-1} B) = \int_{Y} P_\theta(A^{-1}(B) \mid T=t) \  P_\theta^T (dt). &lt;/math&gt;

The distribution &lt;math&gt;P_\theta^A&lt;/math&gt; does not depend on &lt;math&gt;\theta&lt;/math&gt;  because &lt;math&gt;A&lt;/math&gt;  is ancillary. Likewise, &lt;math&gt;P_\theta(\cdot \mid T = t)&lt;/math&gt; does not depend on &lt;math&gt;\theta&lt;/math&gt; because &lt;math&gt;T&lt;/math&gt; is sufficient. Therefore

:&lt;math&gt; \int_Y \big[ P(A^{-1}(B) \mid T=t) - P^A(B)  \big] \ P_\theta^T (dt) = 0. &lt;/math&gt;

Note the integrand (the function inside the integral) is a function of &lt;math&gt;t&lt;/math&gt; and not &lt;math&gt;\theta&lt;/math&gt;. Therefore, since &lt;math&gt;T&lt;/math&gt; is boundedly complete the function

:&lt;math&gt;g(t) = P(A^{-1}(B) \mid T=t) - P^A(B)&lt;/math&gt;

is zero for &lt;math&gt;P_\theta^T&lt;/math&gt; almost all values of &lt;math&gt;t&lt;/math&gt; and thus

:&lt;math&gt;P(A^{-1}(B) \mid T=t) = P^A(B)&lt;/math&gt;

for almost all &lt;math&gt;t&lt;/math&gt;. Therefore, &lt;math&gt;A&lt;/math&gt; is independent of &lt;math&gt;T&lt;/math&gt;.

==Example==

===Independence of sample mean and sample variance of a normal distribution (known variance)===
Let ''X''&lt;sub&gt;1&lt;/sub&gt;, ''X''&lt;sub&gt;2&lt;/sub&gt;, ..., ''X''&lt;sub&gt;''n''&lt;/sub&gt; be [[Independent and identically-distributed random variables|independent, identically distributed]] [[Normal distribution|normal]] [[random variable]]s with [[mean]] ''μ'' and [[variance]] ''σ''&lt;sup&gt;2&lt;/sup&gt;.

Then with respect to the parameter ''μ'', one can show that

:&lt;math&gt;\widehat{\mu}=\frac{\sum X_i}{n},&lt;/math&gt;

the sample mean, is a complete sufficient statistic – it is all the information one can derive to estimate ''μ,'' and no more – and

:&lt;math&gt;\widehat{\sigma}^2=\frac{\sum \left(X_i-\bar{X}\right)^2}{n-1},&lt;/math&gt;

the sample variance, is an ancillary statistic – its distribution does not depend on ''μ.''

Therefore, from Basu's theorem it follows that these statistics are independent.

This independence result can also be proven by [[Cochran's theorem]].

Further, this property (that the sample mean and sample variance of the normal distribution are independent) ''[[characterization (mathematics)|characterizes]]'' the normal distribution – no other distribution has this property.&lt;ref&gt;{{cite journal
 |doi=10.2307/2983669
 |first=R.C. |last=Geary |authorlink=Roy C. Geary
 |year=1936
 |title=The Distribution of the "Student's" Ratio for the Non-Normal Samples
 |journal=Supplement to the Journal of the Royal Statistical Society
 |volume=3 |issue=2 |pages=178–184
 |jfm=63.1090.03
 |jstor=2983669
}}&lt;/ref&gt;

==Notes==
{{Reflist}}
{{More footnotes|date=December 2009}}

==References==
* {{cite journal
 |last=Basu |first=D. |authorlink=Debabrata Basu
 |title=On Statistics Independent of a Complete Sufficient Statistic
 |journal= [[Sankhya (journal)|Sankhyā]]
 |volume=15 |issue=4 |year=1955 |pages=377–380
 |mr=74745
 |zbl=0068.13401
 |jstor=25048259
}}
* Mukhopadhyay, Nitis (2000). ''Probability and Statistical Inference''. Statistics: A Series of Textbooks and Monographs. '''162'''. Florida: CRC Press USA. {{ISBN|0-8247-0379-0}}.
* {{cite journal |doi=10.2307/2685927 |last=Boos |first=Dennis D.|author2=Oliver, Jacqueline M. Hughes |date=Aug 1998 |title=Applications of Basu's Theorem  |journal=[[The American Statistician]] |volume=52 |issue=3 |pages=218–221 |publisher=[[American Statistical Association]] |location=Boston |mr=1650407 |jstor=2685927}}
* {{cite journal|authorlink=Malay Ghosh|title=Basu's Theorem with Applications: A Personalistic Review|
first=Malay|last=Ghosh | journal=Sankhyā: the Indian Journal of Statistics, Series A|volume=64|number=3|date=October 2002|pages=509–531 | mr=1985397 |jstor=25051412}}

{{Statistics|state=collapsed}}

[[Category:Statistical theorems]]
[[Category:Independence (probability theory)]]
[[Category:Articles containing proofs]]</text>
      <sha1>hbbjm9lzvwhl964mdf554kwhbz55o6x</sha1>
    </revision>
  </page>
  <page>
    <title>Bio-inspired computing</title>
    <ns>0</ns>
    <id>361157</id>
    <revision>
      <id>867680766</id>
      <parentid>861842820</parentid>
      <timestamp>2018-11-07T09:08:05Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta9)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11876">{{distinguish|Computational biology}}
{{cleanup|reason=This article has potential, but is currently mostly used as a coatrack for [[WP:REFSPAM]].|date=August 2016}}
'''Bio-inspired computing''', short for '''biologically inspired computing''', is a field of study that loosely knits together subfields related to the topics of [[connectionism]], [[collective intelligence|social behaviour]] and [[emergence]]. It is often closely related to the field of [[artificial intelligence]], as many of its pursuits can be linked to [[machine learning]]. It relies heavily on the fields of [[biology]], [[computer science]] and [[mathematics]]. Briefly put, it is the use of computers to model the living phenomena, and simultaneously the study of life to improve the usage of computers. Biologically inspired computing is a major subset of [[natural computation]].

== Areas of research ==

Some areas of study encompassed under the canon of biologically inspired computing, and their biological counterparts:

*[[genetic algorithm]]s ↔ [[evolution]]
*[[biodegradability prediction]] ↔ [[biodegradation]]
*[[cellular automata]] ↔ [[life]]
*[[emergence|emergent systems]] ↔ [[ant]]s, [[termite]]s, [[bee]]s, [[wasp]]s
*[[neural networks]] ↔ the [[brain]]
*[[artificial life]] ↔ [[life]]
*[[artificial immune system]]s ↔ [[immune system]]
*[[rendering (computer graphics)]] ↔ patterning and rendering of animal skins, bird feathers, mollusk shells and bacterial colonies
*[[Lindenmayer systems]] ↔ plant structures
*[[communication networks]] and [[communication protocols|protocols]] ↔ epidemiology and the spread of disease
*[[P system|membrane computers]] ↔ intra-[[Cell membrane|membrane]] [[Molecular biology|molecular]] processes in the [[Cell (biology)|living cell]]
*[[Excitable medium|excitable media]] ↔ [[Wildfire|forest fires]], [[Audience wave|"the wave"]], [[Tachycardia|heart conditions]], [[axon]]s, etc.
*[[sensor networks]] ↔ [[sensory organs]]
*[[learning classifier system]]s ↔ [[cognition]], [[evolution]]

== Artificial intelligence ==

The way in which bio-inspired computing differs from the traditional artificial intelligence (AI) is in how it takes a more evolutionary approach to learning, as opposed to what could be described as '[[creationist]]' methods used in traditional AI. In traditional AI, intelligence is often programmed from above: the programmer is the creator, and makes something and imbues it with its intelligence. Bio-inspired computing, on the other hand, takes a more [[Top-down and bottom-up design|bottom-up]], [[decentralisation|decentralised]] approach; bio-inspired techniques often involve the method of specifying a set of simple rules, a set of simple organisms which adhere to those rules, and a method of iteratively applying those rules. For example, training a virtual insect to navigate in an unknown terrain for finding food includes six simple rules. The insect is trained to 
* turn right for target-and-obstacle left; 
* turn left for target-and-obstacle right; 
* turn left for target-left-obstacle-right; 
* turn right for target-right-obstacle-left, 
* turn left for target-left without obstacle and 
* turn right for target right without obstacle. 
The virtual insect controlled by the trained [[spiking neural network]] can find food after training in any unknown terrain.&lt;ref name="Silvia_2013"&gt;{{cite journal | author = Xu Z |author2=Ziye X |author3=Craig H |author4=Silvia F | title = Spike-based indirect training of a spiking neural network-controlled virtual insect | journal = Decision and Control (CDC), IEEE | pages = 6798–6805 |date=Dec 2013 | doi = 10.1109/CDC.2013.6760966 | isbn = 978-1-4673-5717-3 }}&lt;/ref&gt; After several generations of rule application it is usually the case that some forms of complex behaviour arise. Complexity gets built upon complexity until the end result is something markedly complex, and quite often completely counterintuitive from what the original rules would be expected to produce (see [[complex system]]s). For this reason, in [[neural network model]]s, it is necessary to accurately model an ''in vivo'' network, by live collection of "noise" coefficients that can be used to refine statistical inference and extrapolation as system complexity increases.&lt;ref&gt;{{cite web|url=http://www.duke.edu/~jme17/Joshua_E._Mendoza-Elias/Research_Interests.html#Neuroscience_-_Neural_Plasticity_in|title="Smart Vaccines" – The Shape of Things to Come|author=Joshua E. Mendoza|work=Research Interests|archiveurl=https://web.archive.org/web/20121114233853/http://people.duke.edu/~jme17/Joshua_E._Mendoza-Elias/Research_Interests.html|archivedate=November 14, 2012}}&lt;/ref&gt;

Natural evolution is a good analogy to this method–the rules of evolution ([[Selection (biology)|selection]], [[Genetic recombination|recombination]]/reproduction, [[mutation]] and more recently [[transposition (genetics)|transposition]]) are in principle simple rules, yet over millions of years have produced remarkably complex organisms. A similar technique is used in [[genetic algorithm]]s.

== See also ==
{{prose|date=December 2016}}
* [[Applications of artificial intelligence]]
* [[Artificial life]]
* [[Artificial neural network]]
* [[Behavior based robotics]]
* [[Bioinformatics]]
* [[Bionics]]
* [[Cognitive architecture]]
* [[Cognitive modeling]]
* [[Cognitive science]]
* [[Connectionism]]
* [[Digital morphogenesis]]
* [[Digital organism]]
* [[Evolutionary algorithm]]
* [[Evolutionary computation]]
* [[Fuzzy logic]]
* [[Gene expression programming]]
* [[Genetic algorithm]]
* [[Genetic programming]]
* [[Gerald Edelman]]
* [[Janine Benyus]]
* [[Learning classifier system]]
* [[Mark A. O'Neill]]
* [[Mathematical biology]]
* [[Mathematical model]]
* [[Natural computation]]
* [[Neuroevolution]]
* [[Olaf Sporns]]
* [[Organic computing]]
* [[Swarm intelligence]]

; Lists
* [[List of emerging technologies]]
* [[Outline of artificial intelligence]]

== References ==

&lt;references/&gt;

== Further reading ==

''(the following are presented in ascending order of complexity and depth, with those new to the field suggested to start from the top)''

* "[http://www.cs.uvm.edu/~jbongard/papers/2009_IEEEComp_Bongard.pdf Biologically Inspired Computing]"
* "[http://peterjbentley.com/ Digital Biology]", Peter J. Bentley.
* "[https://web.archive.org/web/20060216011353/http://bic05.fsksm.utm.my/ First International Symposium on Biologically Inspired Computing]"
* ''[https://books.google.com/books?id=Au_tLkCwExQC Emergence: The Connected Lives of Ants, Brains, Cities and Software]'', Steven Johnson.
* ''Dr. Dobb's Journal'', Apr-1991. (Issue theme: Biocomputing)
* ''[https://books.google.com/books?id=K8P1rX8T4kYC Turtles, Termites and Traffic Jams]'', Mitchel Resnick.
* ''Understanding Nonlinear Dynamics'', Daniel Kaplan and [[Leon Glass]].
* {{cite journal | first1 = E. | last1= Ridge | first2 = D. | last2 = Kudenko | first3 = D. | last3 = Kazakov | first4 = E. |last4=Curry | title = Moving Nature-Inspired Algorithms to Parallel, Asynchronous and Decentralised Environments, | citeseerx = 10.1.1.64.3403 | journal = Self-Organization and Autonomic Informatics (I) | year = 2005 | volume = 135 | pages = 35–49 }}
*''Swarms and Swarm Intelligence'' by Michael G. Hinchey, Roy Sterritt, and Chris Rouff,
* ''[https://books.google.com/books?id=2wTOBQAAQBAJ Fundamentals of Natural Computing: Basic Concepts, Algorithms, and Applications]'', L. N. de Castro, Chapman &amp; Hall/CRC, June 2006.
* "[http://mitpress.mit.edu/books/FLAOH/cbnhtml/home.html The Computational Beauty of Nature]", [http://flakenstein.net/ Gary William Flake]. MIT Press. 1998, hardcover ed.; 2000, paperback ed. An in-depth discussion of many of the topics and underlying themes of bio-inspired computing.
* Kevin M. Passino, [https://books.google.com/books?id=7ttpWS75Uo0C Biomimicry for Optimization, Control, and Automation], Springer-Verlag, London, UK, 2005.
* ''[https://books.google.com/books?id=s_Q5YZ2nh2kC Recent Developments in Biologically Inspired Computing]'', L. N. de Castro and F. J. Von Zuben, Idea Group Publishing, 2004.
*Nancy Forbes, Imitation of Life: How Biology is Inspiring Computing, MIT Press, Cambridge, MA 2004.
* M. Blowers and A. Sisti, ''Evolutionary and Bio-inspired Computation: Theory and Applications'', SPIE Press, 2007.
* X. S. Yang, Z. H. Cui, R. B. Xiao, A. H. Gandomi, M. Karamanoglu, ''Swarm Intelligence and Bio-Inspired Computation: Theory and Applications'', Elsevier, 2013. 
* "[http://informatics.indiana.edu/rocha/i-bic/ Biologically Inspired Computing Lecture Notes]", [[Luis M. Rocha]]
* ''The portable UNIX programming system (PUPS) and CANTOR: a computational envorionment for dynamical representation and analysis of complex neurobiological data'', [[Mark A. O'Neill]], and Claus-C Hilgetag, Phil Trans R Soc Lond B 356 (2001), 1259–1276
* "[https://arxiv.org/abs/cs/0512071 Going Back to our Roots: Second Generation Biocomputing]", J. Timmis, M. Amos, W. Banzhaf, and A. Tyrrell, Journal of Unconventional Computing 2 (2007) 349–378.
* {{cite book | last1=Neumann | first1=Frank | last2=Witt | first2=Carsten | title=Bioinspired computation in combinatorial optimization. Algorithms and their computational complexity | zbl=1223.68002 | series=Natural Computing Series | location=Berlin | publisher=[[Springer-Verlag]] | isbn=978-3-642-16543-6 | year=2010 }}
* {{cite book | last1=Brabazon | first1=Anthony | last2=O’Neill | first2=Michael | title=Biologically inspired algorithms for financial modelling | zbl=1117.91030 | series=Natural Computing Series | location=Berlin | publisher=[[Springer-Verlag]] | isbn=3-540-26252-0 | year=2006 }}
* C-M. Pintea, 2014, [https://www.springer.com/la/book/9783642401787 Advances in Bio-inspired Computing for Combinatorial Optimization Problem], Springer {{ISBN|978-3-642-40178-7}}
* "[https://arxiv.org/pdf/1709.09840.pdf PSA: A novel optimization algorithm based on survival rules of porcellio scaber]", Y. Zhang and S. Li

== External links ==
*[http://www2.surrey.ac.uk/computing/research/nice/ Nature Inspired Computing and Engineering (NICE)] Group, University of Surrey, UK
*[http://www.cogs.susx.ac.uk/users/ezequiel/alife-page/development.html ALife Project in Sussex]
*[https://web.archive.org/web/20130621005509/http://neurochem-project.eu/ Biologically Inspired Computation for Chemical Sensing ''Neurochem'' Project]
*[http://www.andcorporation.com AND Corporation]
*[http://www.cercia.ac.uk/ Centre of Excellence for Research in Computational Intelligence and Applications] Birmingham, UK
* [https://web.archive.org/web/20080828173733/http://dssg.cs.umb.edu/wiki/index.php/BiSNET BiSNET: Biologically-inspired architecture for Sensor NETworks]
* [https://web.archive.org/web/20090622110049/http://dssg.cs.umb.edu/wiki/index.php/BiSNET/e BiSNET/e: A Cognitive Sensor Networking Architecture with Evolutionary Multiobjective Optimization]
*[https://web.archive.org/web/20060621194332/http://www.neuralnetworksolutions.com/ Biologically inspired neural networks]
*[http://ncra.ucd.ie NCRA] UCD, Dublin Ireland
*[http://www.tumblingdice.co.uk/pupsp3 The PUPS/P3 Organic Computing Environment for Linux]
* [https://web.archive.org/web/20090329225051/http://dssg.cs.umb.edu/wiki/index.php/SymbioticSphere SymbioticSphere: A Biologically-inspired Architecture for Scalable, Adaptive and Survivable Network Systems]
* [http://www.sciencedirect.com/science/article/pii/S1568494615002756 The runner-root algorithm]
* [http://www.bionet.ufpr.br Bio-inspired Wireless Networking Team (BioNet)]
* [http://www.ai-one.com Biologically Inspired Intelligence]

{{DEFAULTSORT:Bio-Inspired Computing}}
[[Category:Theoretical computer science]]
[[Category:Artificial intelligence]]
[[Category:Natural computation]]
[[Category:Nature-inspired metaheuristics| ]]
[[Category:Bioinspiration]]</text>
      <sha1>ndrx4shau1hxmwiusnfugcd6ghxl8e8</sha1>
    </revision>
  </page>
  <page>
    <title>Boustrophedon transform</title>
    <ns>0</ns>
    <id>3027085</id>
    <revision>
      <id>865019587</id>
      <parentid>865012316</parentid>
      <timestamp>2018-10-21T04:46:07Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* As a sum */ fderp</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4163">In [[mathematics]], the '''boustrophedon transform''' is a procedure which maps one [[sequence (mathematics)|sequence]] to another. The transformed sequence is computed by filling a [[triangular array]] in [[boustrophedon]] (zig-zag) manner.

==Definition==

[[Image:Boustrophedon transform.svg|right|frame|The boustrophedon transform: Start with the original sequence (in blue), then add numbers as indicated by the arrows, and finally read off the transformed sequence on the other side (in red, with &lt;math&gt;b_0 = a_0&lt;/math&gt;).]]
Given a sequence &lt;math&gt;(a_0, a_1, a_2, \ldots)&lt;/math&gt;, the boustrophedon transform yields another sequence, &lt;math&gt;(b_0, b_1, b_2, \ldots)&lt;/math&gt;, which is constructed by filling up a triangle as pictured on the right. Number the rows in the triangle starting from 0, and fill the rows consecutively. Let ''k'' denote the number of the row currently being filled.

If ''k'' is odd, then put the number &lt;math&gt;a_k&lt;/math&gt; on the right end of the row and fill the row from the right to the left, with every entry being the sum of the number to the right and the number to the upper right. If ''k'' is even, then put the number &lt;math&gt;a_k&lt;/math&gt; on the left end and fill the row from the left to the right, with every entry being the sum of the number to the left and the number to the upper left.

Defining &lt;math&gt;b_0 = a_0&lt;/math&gt;, the numbers &lt;math&gt;b_k | k &gt; 0&lt;/math&gt; forming the transformed sequence can then be found on the left end of odd-numbered rows and on the right end of even-numbered rows, that is, opposite to the numbers &lt;math&gt;a_k&lt;/math&gt;.

==Recurrence relation==

A more formal definition uses a [[recurrence relation]]. Define the numbers &lt;math&gt;T_{k,n}&lt;/math&gt; (with ''k''&amp;nbsp;&amp;ge;&amp;nbsp;''n''&amp;nbsp;&amp;ge;&amp;nbsp;0) by
:&lt;math&gt;T_{k,0} = a_k \quad \text{for } k \ge 0, &lt;/math&gt;
:&lt;math&gt;T_{k,n} = T_{k,n-1} + T_{k-1,k-n} \quad \text{for } k \ge n &gt; 0. &lt;/math&gt;
Then the transformed sequence is defined by &lt;math&gt; b_n = T_{n,n} &lt;/math&gt;.

In the case ''a''&lt;sub&gt;0&lt;/sub&gt; = 1, ''a''&lt;sub&gt;''n''&lt;/sub&gt; = 0 (''n'' &amp;gt; 0), the resulting triangle is called the '''Seidel&amp;ndash;Entringer&amp;ndash;Arnold Triangle''' and the numbers &lt;math&gt;T_{k,n}&lt;/math&gt; are called '''Entringer numbers''' {{OEIS|id=A008281}}. In this case the numbers in the transformed sequence ''b''&lt;sub&gt;''n''&lt;/sub&gt; are called the Euler up/down numbers. This is sequence [[oeis:A000111|A000111]] on the [[On-Line Encyclopedia of Integer Sequences]]. These enumerate the number of [[alternating permutation]]s on ''n'' letters and are related to the [[Euler number]]s and the [[Bernoulli number]]s.

==As a sum==

The terms of a sequence {{math|(''a''{{sub|''n''}})}} and its boustrophedon transform {{math|(''b''{{sub|''n''}})}} are related by

:&lt;math&gt;\begin{align}
   b_n &amp;= \sum_{k=0}^n \binom{n}{k} a_k E_{n-k} \\
   a_n &amp;= \sum_{k=0}^n (-1)^{n-k} \binom{n}{k} b_k E_{n-k},
 \end{align}&lt;/math&gt;

where {{math|(''E''{{sub|''n''}})}} is the sequence of up/down numbers.

==The exponential generating function==

The [[exponential generating function]] of a sequence (''a''&lt;sub&gt;''n''&lt;/sub&gt;) is defined by
:&lt;math&gt; EG(a_n;x)=\sum _{n=0}^{\infty} a_n \frac{x^n}{n!}. &lt;/math&gt;
The exponential generating function of the boustrophedon transform (''b''&lt;sub&gt;''n''&lt;/sub&gt;) is related to that of the original sequence (''a''&lt;sub&gt;''n''&lt;/sub&gt;) by
:&lt;math&gt; EG(b_n;x) = (\sec x + \tan x) \, EG(a_n;x). &lt;/math&gt;

The exponential generating function of the unit sequence is&amp;nbsp;1, so that of the up/down numbers is sec&amp;nbsp;''x''&amp;nbsp;+&amp;nbsp;tan&amp;nbsp;''x''.

==References==

* Jessica Millar, N.J.A. Sloane, Neal E. Young, "A New Operation on Sequences: the Boustrouphedon Transform," ''Journal of Combinatorial Theory, Series A,'' volume 76, number 1, pages 44&amp;ndash;54, 1996. Also available in a slightly different version as e-print [https://arxiv.org/abs/math.CO/0205218 math.CO/0205218] on the [[arXiv]].
* {{cite book |author=Weisstein, Eric W. |title=CRC Concise Encyclopedia of Mathematics, Second Edition |publisher=Chapman &amp; Hall/CRC |year=2002 |page=273 |isbn=1-58488-347-2}}

[[Category:Integer sequences]]
[[Category:Triangles of numbers]]
[[Category:Permutations]]
[[Category:Transforms]]</text>
      <sha1>amdnpm639s06s27o1aoduu6xjupjcr5</sha1>
    </revision>
  </page>
  <page>
    <title>Conformable matrix</title>
    <ns>0</ns>
    <id>1497463</id>
    <revision>
      <id>870169845</id>
      <parentid>791428778</parentid>
      <timestamp>2018-11-22T22:20:31Z</timestamp>
      <contributor>
        <username>Bender235</username>
        <id>88026</id>
      </contributor>
      <minor/>
      <comment>restructed according to [[MOS:APPENDIX]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1770">{{Redirect|Conformable|the topic in [[geology]]|Unconformity}}

In  [[mathematics]], a [[matrix (mathematics)|matrix]]  is '''conformable''' if its dimensions are suitable for defining some operation (''e.g.'' addition, multiplication, etc.).&lt;ref&gt;{{cite book|last=Cullen|first=Charles G.|title=Matrices and linear transformations|date=1990|publisher=Dover|location=New York|isbn=0486663280|edition=2nd}}&lt;/ref&gt;

==Examples==
* If two matrices have the same dimensions (number of rows and number of columns), they are ''conformable for addition''.
* Multiplication of two matrices is defined if and only if the number of columns of the left matrix is the same as the number of rows of the right matrix. That is, if {{math|'''A'''}} is an {{math|''m'' × ''n''}} matrix and {{math|'''B'''}} is an {{math|''s'' × ''p''}} matrix, then {{math|''n''}} needs to be equal to {{math|''s''}} for the matrix product {{math|'''AB'''}} to be defined. In this case, we say that {{math|'''A'''}} and {{math|'''B'''}} are ''conformable for multiplication'' (in that sequence).
* Since squaring a matrix involves multiplying it by itself ({{math|'''A'''&lt;sup&gt;'''2'''&lt;/sup&gt; {{=}} '''AA'''}}) a matrix must be {{math|''m'' × ''m''}} (that is, it must be a [[square matrix]]) to be ''conformable for squaring''. Thus for example only a square matrix can be [[Idempotent matrix|idempotent]].
* Only a square matrix is ''conformable for [[matrix inversion]]''. However, the [[Moore-Penrose pseudoinverse]] and other [[generalized inverse]]s do not have this requirement.
* Only a square matrix is ''conformable for [[matrix exponentiation]]''.

==See also==
* [[Linear algebra]]

==References==
{{reflist}}

{{DEFAULTSORT:Conformable Matrix}}
[[Category:Linear algebra]]
[[Category:Matrices]]</text>
      <sha1>islax2xahpuxjs7qp07t2xbl7wkxtzu</sha1>
    </revision>
  </page>
  <page>
    <title>Conservative functor</title>
    <ns>0</ns>
    <id>49749141</id>
    <revision>
      <id>783063038</id>
      <parentid>766194957</parentid>
      <timestamp>2017-05-30T22:16:44Z</timestamp>
      <contributor>
        <ip>87.69.216.191</ip>
      </contributor>
      <comment>/* Examples */ Changed [[algebra]] to [[abstract algebra|algebra]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1323">In [[category theory]], a branch of [[mathematics]], a '''conservative functor''' is a [[functor]] &lt;math&gt;F: C \to D&lt;/math&gt; such that for any [[morphism]] ''f'' in ''C'', ''F''(''f'') being an [[isomorphism]] implies that ''f'' is an isomorphism.

==Examples==
The [[forgetful functor]]s in [[abstract algebra|algebra]], such as from '''Grp''' to '''Set''', are conservative. More generally, every [[monadic functor]] is conservative.&lt;ref&gt;{{cite book|last=Riehl|first=Emily|year=2016|title=Category Theory in Context|publisher=[[Courier Dover Publications]]|url=https://books.google.com/books?id=Sr09DQAAQBAJ|isbn=048680903X|access-date=18 February 2017}}&lt;/ref&gt; In contrast, the forgetful functor from '''Top''' to '''Set''' is not conservative because not every [[continuous function|continuous bijection]] is a [[homeomorphism]].

Every [[faithful functor]] from a [[balanced category]] is conservative.&lt;ref&gt;{{cite book|last=Grandis|first=Marco|year=2013|title=Homological Algebra: In Strongly Non-Abelian Settings|publisher=[[World Scientific]]|url=https://books.google.com/books?id=kvW6CgAAQBAJ|isbn=9814425931|access-date=14 January 2017}}&lt;/ref&gt;

==References==
{{reflist}}

==External links==
* {{nlab|id=conservative+functor|title=Conservative functor}}

{{Functors}}

[[Category:Category theory]]

{{cattheory-stub}}</text>
      <sha1>adjjnviss9ge6t8z5zjk88uudo2iuac</sha1>
    </revision>
  </page>
  <page>
    <title>Constance van Eeden</title>
    <ns>0</ns>
    <id>55698678</id>
    <revision>
      <id>865715207</id>
      <parentid>863621978</parentid>
      <timestamp>2018-10-25T17:50:50Z</timestamp>
      <contributor>
        <username>Jmertel23</username>
        <id>32942831</id>
      </contributor>
      <comment>infobox added</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7587">{{short description|Dutch mathematical statistician}}
{{Infobox academic
| honorific_prefix   = &lt;!-- see [[MOS:HONORIFIC]] --&gt;
| name               = 
| honorific_suffix   = 
| image              = 
| image_size         = 
| alt                = 
| caption            = 
| native_name        = 
| native_name_lang   = 
| birth_name         = &lt;!-- use only if different from full/othernames --&gt;
| birth_date         = {{birth date and age|1927|04|06}} 
| birth_place        = [[Delft]], [[South Holland]]
| death_date         = &lt;!-- {{death date and age|YYYY|MM|DD|YYYY|MM|DD}} (death date then birth date) --&gt;
| death_place        = 
| death_cause        = 
| region             = 
| nationality        = [[Netherlands|Dutch]]
| citizenship        = 
| residence          = 
| other_names        = 
| occupation         = 
| period             = 
| known_for          = 
| home_town          = 
| title              = 
| boards             = &lt;!--board or similar positions extraneous to main occupation--&gt;
| spouse             = Charles H. Kraft
| children           = 
| parents            =
| relatives          =
| awards             = &lt;!--notable national level awards only--&gt;
| website            = 
| education          = 
| alma_mater         = [[University of Amsterdam]]
| thesis_title       = Testing and Estimating Ordered Parameters of Probability Distribution
| thesis_url         = 
| thesis_year        = 1958
| school_tradition   = 
| doctoral_advisor   = [[David van Dantzig]]
| academic_advisors  = [[Jan Hemelrijk]]
| influences         = &lt;!--must be referenced from a third party source--&gt;
| era                = 
| discipline         = [[Mathematical statistics]]
| sub_discipline     = &lt;!--academic discipline specialist area – e.g. Sub-atomic research, 20th Century Danish specialist, Pauline research, Arcadian and Ugaritic specialist--&gt;
| workplaces         = [[Université de Montréal]], &lt;br&gt; [[University of Minnesota]], &lt;br&gt; [[Centrum Wiskunde &amp; Informatica]]
| doctoral_students  = &lt;!--only those with WP articles--&gt;
| notable_students   = &lt;!--only those with WP articles--&gt;
| main_interests     = [[Nonparametric statistics]], &lt;br&gt; [[Parameter space]]
| notable_works      = ''A Nonparametric Introduction to Statistics''
| notable_ideas      = 
| influenced         = &lt;!--must be referenced from a third party source--&gt;
| signature          = 
| signature_alt      = 
| signature_size     = 
| footnotes          = 
}}

'''Constance van Eeden''' (born April 6, 1927) is a Dutch [[mathematical statistics|mathematical statistician]] who made "exceptional contributions to the development of statistical sciences in Canada".{{r|ssc}} She is interested in [[nonparametric statistics]] including [[maximum likelihood estimation]] and [[robust statistics]],{{r|ubc}}
and did foundational work on [[parameter space]]s.{{r|ssc}}

==Education==
Van Eeden was born in [[Delft]],{{r|ubc|ssc}} the daughter of a schoolteacher, and spent her school years in [[Bergen op Zoom]].{{r|ssc}} She earned a bachelor's degree in 1949, master's degree in 1954, and Ph.D. in 1958 from the [[University of Amsterdam]].{{r|ubc|ssc}} Her bachelor's degree was in mathematics, physics and astronomy, and her master's degree was in actuarial science.{{r|conversation}} Her doctoral dissertation, with [[David van Dantzig]] as promoter{{r|ssc|mgp}} and [[Jan Hemelrijk]] as an unofficial mentor,{{r|conversation}} was ''Testing and Estimating Ordered Parameters of Probability Distribution''.{{r|mgp}} It would be 29 years before the next Dutch woman earned a doctorate in statistics.{{r|conversation}}

==Career==
She worked at the [[Centrum Wiskunde &amp; Informatica]] from 1954 until 1960,{{r|ubc}} when she worked as a year as visiting faculty at [[Michigan State University]], with Herman Rubin as mentor.{{r|ssc}} It was in that visit that she met and married her husband, Charles H. Kraft, another statistician;
the anti-nepotism rules then in force at many universities, including Michigan State, made it difficult for them both to find positions at the same place.{{r|conversation}} From 1961 until 1965 she was at the [[University of Minnesota]], first as a research associate and then as an associate professor, and from 1965 to 1988 she taught at the [[Université de Montréal]].
She retired in 1989, and has held visiting and honorary positions at the [[Université du Québec à Montréal]] and [[University of British Columbia]] since then.{{r|ubc}}

==Contributions==
With her husband, Charles H. Kraft, she wrote ''A Nonparametric Introduction to Statistics'' (Macmillan, 1968).{{r|npis}}
She was editor-in-chief of ''Statistical Theory and Methods Abstracts'' from 1990 to 2004.{{r|ssc}}

==Awards and honours==
She has been a fellow of the [[American Statistical Association]] and [[Institute of Mathematical Statistics]] since 1973, and an elected member of the International Statistical Institute since 1978.

The International Statistical Institute gave her their Henri Willem Methorst Medal for outstanding service in 1999.{{r|ubc|ssc}}
The [[Statistical Society of Canada]] gave her their gold medal in 1990, and made her an honorary member in 2011.{{r|ssc}}

In May 2002, a symposium was held in honour of her 75th birthday, and a [[festschrift]] published from it.{{r|conversation|festschrift}}

==References==
{{reflist|refs=

&lt;ref name=conversation&gt;{{citation|url=https://ssc.ca/en/profile/conversation-constance-van-eeden|title=A Conversation with Constance van Eeden|date=March 12, 2010|accessdate=2017-11-02}}&lt;/ref&gt;

&lt;ref name=festschrift&gt;{{citation|title=Mathematical Statistics and Applications: Festschrift for Constance Van Eeden|volume=42|series=Institute Of Mathematical Statistics Lecture Notes – Monograph Series|editor1-first=Marc|editor1-last=Moore|editor2-first=Sorana|editor2-last=Froda|editor3-first=Christian|editor3-last=Léger|publisher=CRM and IMS|year=2003|isbn=9780940600577}}&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=73217}}&lt;/ref&gt;

&lt;ref name=npis&gt;Reviews of ''A Nonparametric Introduction to Statistics'':
Jayant V. Deshpande (1970), ''[[American Mathematical Monthly]]'' 77 (2): 207–208, {{doi|10.2307/2317360}};
Alan Stuart (1970), ''Journal of the Royal Statistical Society'', Series A 133 (1): 94–97, {{doi|10.2307/2343814}};
I. R. Savage, ''Mathematical Reviews'', {{mr|0228084}}.&lt;/ref&gt;

&lt;ref name=ssc&gt;{{citation|url=https://ssc.ca/en/awards/2011/constance-van-eeden|title=Constance van Eeden, Honorary Member 2011|publisher=Statistical Society of Canada|accessdate=2017-11-02}}&lt;/ref&gt;

&lt;ref name=ubc&gt;{{citation|url=https://www.stat.ubc.ca/~vaneeden/|title=Constance van Eeden's Home Page|publisher=University of British Columbia, Department of Statistics|accessdate=2017-11-02}}&lt;/ref&gt;

}}

{{Authority control}}
{{DEFAULTSORT:Eeden, Constance Van}}

[[Category:1927 births]]
[[Category:20th-century Canadian mathematicians]]
[[Category:20th-century Dutch mathematicians]]
[[Category:Living people]]
[[Category:Dutch statisticians]]
[[Category:Dutch women mathematicians]]
[[Category:Canadian statisticians]]
[[Category:Canadian mathematicians]]
[[Category:Women statisticians]]
[[Category:Women mathematicians]]
[[Category:People from Delft]]
[[Category:University of Amsterdam alumni]]
[[Category:Michigan State University faculty]]
[[Category:University of Minnesota faculty]]
[[Category:Université de Montréal faculty]]
[[Category:Elected Members of the International Statistical Institute]]
[[Category:Fellows of the American Statistical Association]]
[[Category:Fellows of the Institute of Mathematical Statistics]]</text>
      <sha1>onqaenfpmfvfjwdbpjokx11rt5g4puc</sha1>
    </revision>
  </page>
  <page>
    <title>Equidistant</title>
    <ns>0</ns>
    <id>1532579</id>
    <revision>
      <id>824475660</id>
      <parentid>824475510</parentid>
      <timestamp>2018-02-07T16:03:02Z</timestamp>
      <contributor>
        <username>Bassan67</username>
        <id>27322577</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3773">{{redirect|Equidistance|the principle in maritime boundary claims|Equidistance principle}}
{{refimprove|date=August 2012}}

{{wiktionary}}
[[File:Perpendicular bisector.gif|right|thumb|[[Perpendicular bisector]] of a line segment. The point where the red line crosses the black line segment is equidistant from the two end points of the black line segment.]]
[[File:Circumscribed Polygon.svg|thumb|The [[cyclic polygon]] P is [[circumscribed circle|circumscribed]] by the circle C. The circumcentre O is equidistant to each point on the circle, and a fortiori to each vertex of the polygon.]]

A point is said to be '''equidistant''' from a set of objects if the [[distance]]s between that point and each object in the set are equal.&lt;ref&gt;{{cite book
 |title=The concise Oxford dictionary of mathematics
 |first1= Christopher |last1=Clapham
 |first2= James |last2=Nicholson
 |publisher=Oxford University Press
 |isbn=978-0-19-923594-0
 |year=2009
 |pages=164–165
 |url=https://books.google.com/books?id=UTCenrlmVW4C&amp;lpg=PT300&amp;pg=PT164
}}&lt;/ref&gt;

In two-dimensional [[Euclidean geometry]], the [[locus (mathematics)|locus]] of points equidistant from two given (different) points is their [[perpendicular bisector]]. In three dimensions, the locus of points equidistant from two given points is a plane, and generalising further, in [[n-dimensional space]] the locus of points equidistant from two points in [[n-space]] is an (n&amp;minus;1)-space.

For a [[triangle]] the [[circumcentre]] is a point equidistant from each of the three [[vertex (geometry)|vertices]]. Every non-degenerate triangle has such a point. This result can be generalised to [[cyclic polygon]]s: the circumcentre is equidistant from each of the vertices. Likewise, the [[incenter|incentre]] of a triangle or any other [[tangential polygon]] is equidistant from the points of tangency of the polygon's sides with the circle. Every point on a [[Bisection#Bisectors of the sides of a polygon|perpendicular bisector of the side]] of a triangle or other polygon is equidistant from the two vertices at the ends of that side. Every point on the [[Bisection#Angle bisector|bisector of an angle]] of any polygon is equidistant from the two sides that emanate from that angle.

The center of a [[rectangle]] is equidistant from all four vertices, and it is equidistant from two opposite sides and also equidistant from the other two opposite sides. A point on the [[axis of symmetry]] of a [[kite (geometry)|kite]] is equidistant between two sides.

The center of a [[circle]] is equidistant from every point on the circle. Likewise the center of a [[sphere]] is equidistant from every point on the sphere.

A [[parabola]] is the set of points in a plane equidistant from a fixed point (the [[Focus (geometry)|focus]]) and a fixed line (the directrix), where distance from the directrix is measured along a line perpendicular to the directrix.

In [[shape analysis (digital geometry)|shape analysis]], the [[topological skeleton]] or [[medial axis]] of a [[shape]] is a thin version of that shape that is equidistant from its [[boundary (topology)|boundaries]].

In [[Euclidean geometry]], [[parallel lines]] (lines that never intersect) are equidistant in the sense that the distance of any point on one line from the nearest point on the other line is the same for all points.

In [[hyperbolic geometry]] the set of points that are equidistant from and on one side of a given line form an [[hypercycle (hyperbolic geometry)|hypercycle]] (which is a curve not a line).&lt;ref&gt;{{citation|first=James R.|last=Smart|title=Modern Geometries|edition=5th|publisher=Brooks/Cole|year=1997|isbn=0-534-35188-3|page=392}}&lt;/ref&gt;

==See also==
* [[Equidistant set]]

==References==
{{reflist}}

[[Category:Elementary geometry]]</text>
      <sha1>1dxwltixjs2kdkb0qfwc2uhv8db3lcg</sha1>
    </revision>
  </page>
  <page>
    <title>Felix Thomas</title>
    <ns>0</ns>
    <id>48528973</id>
    <revision>
      <id>860809678</id>
      <parentid>860785544</parentid>
      <timestamp>2018-09-23T06:15:58Z</timestamp>
      <contributor>
        <username>BronHiggs</username>
        <id>29331605</id>
      </contributor>
      <comment>/* Further reading */ dlt stray letter; format ref</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9333">{{Infobox artist
| name          = Felix Thomas
| image         = Gabriel Tranchard-Foto 1853 Khorsabad.jpg|
| imagesize     = 160px
| caption       = The archaeological team at Khorsabad, photo by G.Tranchard, 1853
| birth_name     = 
| birth_date     = 1815
| birth_place      =[[Nantes]], [[France]]
| death_date     = 1875
| death_place    = Nantes, France
| nationality   = Frenchy
| training      = [[École nationale supérieure des Beaux-Arts|Beaux-Arts]]
| movement      = [[Orientalism|Orientalist painting and illustration]]
| known_for     = Archaeological draftsman, architect, illustrator, painter
| influenced by = 
| influenced    = 
| awards        = 
| works         = ''Nineveh et Assyria,''1867
}}
'''Félix Thomas''' (1815-1875) was a French architect and painter born in [[Nantes]], France in 1815. After graduating from high school [[Lycée Georges Clemenceau (Nantes)|Clemenceau]], he studied  architecture and drafting at the Polytechnique before being admitted to the [[École nationale supérieure des Beaux-Arts|Beaux-Arts]] where he studied art under [[Louis-Hippolyte Lebas]]. His skills as a draftsman led him to work as project architect on several major archaeological excavations in Mesopotamia and Assyria during the early 1850s. Archaeological work provided opportunities for Thomas to demonstrate his skills as an illustrator and interpreter of historic architectural buildings and he co-authored an important early book on the archaeology of Nineveh in Assyria. He turned to full-time painting in his later life and is noted for works within the Orientalist genre.

==Career==

[[File:Gegenüsberstellung der Genien Nimrud-Khorsabad.jpg|thumb|Illustration from the book,''Nineveh and Assyria'' by Victor Place and Felix Thomas, 1867]]
Initially, Thomas trained as an architect or draftsman at l'Ecole Polytechnique (1834–35). He subsequently studied art at [[École nationale supérieure des Beaux-Arts|Beaux-Arts]] where he was a pupil of [[Louis-Hippolyte Lebas]] who specialised in the history of architecture. In 1845, Thomas won the first [[Prix de Rome]] for a project in Architecture Cathedral. In 1849 he submitted 14 drawings of Neptune's Temple at Paestum which were very well received. In 1850, he travelled to Greece and on his way stopped at Constantinople and Smyrna.&lt;ref&gt;Pouillon, F., ''Dictionnaire des Orientalistes de Langue Française,'' KARTHALA, 2008, p. 923&lt;/ref&gt;

In the early 1850s, Thomas joined several archaeological expeditions in [[Mesopotamia]] and [[Assyria]] in his capacity as an architect. The first of these expeditions was led by [[Fulgence Fresnel]] and [[Julius Oppert]], commencing in 1851. Thomas was expected to describe the monuments and buildings that were discovered as well as to carry out quantity surveys, draw plans, prepare sketches and generally assist with documentation and drawings.&lt;ref&gt;Larsen, M.T., ''The Conquest of Assyria: Excavations in an Antique Land,'' Routledge, 2014, pp 307-08 and p. 315&lt;/ref&gt; He was also required to make casts and stampings of inscriptions, using the new and still secret procedure developed by Lattin de Laval. Due to ill-health, Thomas left Fresnel's Mesopotamian mission prematurely. In spite of that, he still managed to contribute twelve maps to the book of the expedition, ''Expedition Scientifique En Mésopotamie: Exécutée Par Ordre Du Gouvernement De 1851 À  1854'' by Julius Oppert.&lt;ref&gt;Pouillon, F., ''Dictionnaire des Orientalistes de Langue Française,'' KARTHALA, 2008, p. 924&lt;/ref&gt;

After recovering from his illness, Thomas rejoined the archaeological team for the Assyrian excavation in 1852. The excavations, originally started by [[Paul-Emile Botta]] in 1843, were languishing, and the French government was determined to mount a large-scale operation in Assyria to showcase its dominance in the region. [[Victor Place]], the new French Consul in Mosul hired Thomas to join the expedition as the project designer. The mission which involved the excavation of the palace of the Assyrian King [[Sargon II]] in [[Dur-Sharrukin|Khorsabad]] (formerly [[Nineveh]]), would become the first systematic excavation of the site. Thomas made substantial contributions to the success of the excavation through his acute observations, the boldness of his reconstructions and the quality of his drawings which contributed to a rich understanding of the architecture of the Palace.&lt;ref&gt;Potts, D.T. (ed), ''A Companion to the Archaeology of the Ancient Near East,'' Volume 1, John Wiley &amp; Sons, 2012, p. 51-52; Pouillon, F., ''Dictionnaire des Orientalistes de Langue Française,'' KARTHALA, 2008, p. 924&lt;/ref&gt;

Many of the Assyrian antiquities were lost when the expedition's boat sank at Qnra, on the [[Tigris]], following an attack by local rebels in May, 1855. However, Thomas, who had left earlier, retained his sketches, plans and drawings which subsequently served to illustrate a pioneering text on Assyria and the Palace of King Sargon II entitled ''Ninevah and Assyria'', jointly authored by Victor Place and Felix Thomas in around 1867.&lt;ref&gt;Maisels, C.K., ''The Near East: Archaeology in the Cradle of Civilization,'' Routledge, 2005, pp 40-41; Tanner, J.P., “Ancient Babylon: From Gradual Demise to Archaeological Rediscovery,” ''Near East Archaeological Society Bulletin,'' Vol. 47 ,2002, pp 11-20; Library notes on ''Ninive et L'Assyrie, Consul General Avec Des Essais De Restauration,'' by Victor Place and Felix Thomas, [3 volume set],  Imprimerie Imperiale, Paris, 1857, Online: https://www.iberlibro.com/buscar-libro/primera-edicion/tapa-dura/precio-min/30/vi/960590/sortby/1/; Pouillon, F., ''Dictionnaire des Orientalistes de Langue Française,'' KARTHALA, 2008, p. 924&lt;/ref&gt;  In this way, Thomas became a major collaborator and co-author of an important archaeological treatise.

On his return to France, Thomas gave up archaeology and devoted himself to painting. He joined the studio of [[Charles Gleyre]] who became his mentor. His travels in Italy, Greece, and Turkey and the Middle East inspired his artistic vision and he began painting works in the Orientalist genre. He enjoyed only modest success in his second career as a painter. Towards the end of his life, he divided his time between his studio in Nantes and [[Pornic]] on the Atlantic coast.&lt;ref&gt;Larsen, M.T., ''The Conquest of Assyria: Excavations in an Antique Land: 1840-1860,'' Psychology Press, 1996, p. 353; Pouillon, F., ''Dictionnaire des Orientalistes de Langue Française,'' KARTHALA, 2008, p. 924&lt;/ref&gt; The Baron de Girardot, in a book dedicated to him, said about him, "Modest to a fault, withdrawn and lonely, he painted for him." &lt;ref&gt;M. de Girardot, ''Felix Thomas, grand Prix de Rome Architecte, Peintre, Graveur, Sculpteur,'' Nantes, 1875&lt;/ref&gt;

Thomas died in Nantes in April 1875.

==Works==

Thomas is known for the illustrations provided to several important archaeological texts. In his later life, he produced many fine Oriental paintings. One of his works is on display in the Louvre in Paris.

===Publications and Illustrations ===
* Twelve of his illustrations were used in ''Expedition Scientifique En Mésopotamie: Exécutée Par Ordre Du Gouvernement De 1851 À 1854'' by Julius Oppert. 
* Thomas is co-author (with Victor Place), and illustrator of ''Nineveh and Assyria,'' first published in 1867

===Gallery===

&lt;gallery&gt;
File:1911 Britannica-Architecture-Khorsabad.png|Entrance to the Palace of Khorsabad, illustration by Felix Thomas
File:Grosses Basrelief.jpg|Bass Relief taken from the Palace of Khorsabad
File:Van (Arménie).jpg|The City of Van, illustration in ''Ninevah and Assyria'', 1867
File:Victor Place Khorsabad.jpg|Plan of Khorsabad in ''Ninevah and Assyria'', 1867
File:Visite du pacha de Mossoul aux fouilles de Khorsabad.jpg|''The Pacha visit the Mosul digs, c. 1863
&lt;/gallery&gt;

===Select list of paintings and drawings===

* ''The Visit of the Pacha of Mosul to the Excavations at Khorsabad''  c. 1863 (now in the Louvre, Paris)
* ''Propylées de l'Acropole de'Athènes,'' 1859 (Exhibited at the Salon in 1859)
* '' Sentinelle devant les ruines de Ninive'' [Sentinel before the ruins of Nineveh], (Private collection)
* ''Les Pecheurs,'' n.d. 
* ''Jument et Poulain au Bord,'' n.d. 
* ''Jeune Femme en Lisière de Forêt, sous les Arbres,'' n.d. 
* ''La Sentinelle devant les Ruines de Ninive,'' n.d.

==See also==
*[[List of Orientalist artists]]
*[[Orientalism]]
*[[Orientalism in early modern France]]
*[[Oriental studies]]

==References==

{{Reflist}}

==Further reading==

* Georges Perrot and Charles Chipiez, ''A History of Art in Chaldæa &amp; Assyria,'' v. 1, (trans: Walter Armstrong), 1884, Project Gutenberg edition, 2009, [http://www.gutenberg.org/files/28072/28072-h/28072-h.htm Online:]
* François Pouillon, ''Dictionnaire des Orientalistes de Langue Française,'' KARTHALA, 2008

==External links==
* World Category:Thomas Felix http://worldcat.org/identities/viaf-47617178/

{{Commons category|Félix Thomas}}

{{Authority control}}

[[Category:1815 births]]
[[Category:1875 deaths]]
[[Category:19th-century French illustrators]]
[[Category:Archaeology]]
[[Category:Architectural illustrators]]
[[Category:Drawing]]
[[Category:French illustrators]]
[[Category:Methods in archaeology]]
[[Category:Orientalist painters]]
[[Category:Technical drawing]]</text>
      <sha1>6vtbmhwzylu45otmuwt8ysdjshhk75y</sha1>
    </revision>
  </page>
  <page>
    <title>Graciela Boente</title>
    <ns>0</ns>
    <id>58071797</id>
    <revision>
      <id>853469071</id>
      <timestamp>2018-08-05T00:47:08Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>New article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2604">'''Graciela Lina Boente Boente''' is an Argentine [[mathematical statistics|mathematical statistician]] at the [[University of Buenos Aires]].{{r|uba}} She is known for her research in [[robust statistics]], and particularly for robust methods for [[principal component analysis]] and [[regression analysis]].

==Education==
Boente earned her Ph.D. in 1983 from the University of Buenos Aires. Her dissertation, ''Robust Principal Components'', was supervised by Victor J. Yohai.{{r|mgp}}

==Awards and honors==
Boente became a [[Guggenheim Fellowship|Guggenheim Fellow]] in 2001.{{r|gugg}} In 2008, the Argentine National Academy of Exact, Physical and Natural Sciences gave her their Consecration Prize in recognition of her contributions and teaching.{{r|nacion|ancefn}} She became an honored fellow of the [[Institute of Mathematical Statistics]] in 2013, "for her research in robust statistics and estimation, and for outstanding service to the statistical community".{{r|fims}}

==References==
{{reflist|refs=

&lt;ref name=ancefn&gt;{{citation|url=http://www.ancefn.org.ar/institucional/memoria_2008.html|title=Memoria 2008|publisher=Argentine National Academy of Exact, Physical and Natural Sciences|accessdate=2018-08-04}}&lt;/ref&gt;

&lt;ref name=fims&gt;{{citation|url=https://www.imstat.org/wp-content/uploads/import/awardees_2013.pdf|title=IMS Fellows 2013|publisher=[[Institute of Mathematical Statistics]]|accessdate=2018-08-04}}&lt;/ref&gt;

&lt;ref name=gugg&gt;{{citation|url=https://www.gf.org/fellows/all-fellows/graciela-lina-boente-boente/|title=Graciela Lina Boente Boente|publisher=John Simon Guggenheim Memorial Foundation|accessdate=2018-08-04}}&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=114829}}&lt;/ref&gt;

&lt;ref name=nacion&gt;{{citation|url=https://www.lanacion.com.ar/1078734-premian-a-cientificos-destacados|title=Premian a científicos destacados|newspaper=La Nacion|date=December 9, 2008}}&lt;/ref&gt;

&lt;ref name=uba&gt;{{citation|url=http://www.imas-uba-conicet.gob.ar/iim_miembros/boente-boente-graciela-lina/|title=Investigator profile|publisher=University of Buenos Aires, Institute of Mathematical Investigations|accessdate=2018-08-04}}&lt;/ref&gt;

}}

{{Authority control}}
{{DEFAULTSORT:Boente, Graciela}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:Argentine mathematicians]]
[[Category:Argentine statisticians]]
[[Category:Women mathematicians]]
[[Category:Women statisticians]]
[[Category:University of Buenos Aires alumni]]
[[Category:University of Buenos Aires faculty]]
[[Category:Fellows of the Institute of Mathematical Statistics]]
[[Category:Guggenheim Fellows]]</text>
      <sha1>fzngij0va1o0ngwzh54avhf726q7son</sha1>
    </revision>
  </page>
  <page>
    <title>Graph edit distance</title>
    <ns>0</ns>
    <id>49270083</id>
    <revision>
      <id>858411608</id>
      <parentid>841574648</parentid>
      <timestamp>2018-09-07T00:27:59Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: issue, isbn, title. Add: chapter, volume, pmid, citeseerx, hdl. Removed parameters. Formatted [[WP:ENDASH|dashes]]. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[User:Headbomb|Headbomb]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9579">In [[mathematics]] and [[computer science]], '''graph edit distance''' ('''GED''') is a [[Similarity measure|measure of similarity]] (or dissimilarity) between two [[Graph (discrete mathematics)|graphs]].
The concept of graph edit distance was first formalized mathematically by Alberto Sanfeliu and King-Sun Fu in 1983.&lt;ref&gt;{{cite journal
|first1=Alberto
|last1=Sanfeliu
|first2=King-Sun
|last2=Fu
|title=A distance measure between attributed relational graphs for pattern recognition
|journal=[[IEEE Transactions on Systems, Man and Cybernetics]]
|volume=13
|issue=3
|pages=353–363
|year=1983
|doi=10.1109/TSMC.1983.6313167}}&lt;/ref&gt;
A major application of graph edit distance is in [[inexact graph matching]], such
as error-tolerant [[pattern recognition]] in [[machine learning]].&lt;ref&gt;
{{cite journal
|first1=Xinbo
|last1=Gao
|first2=Bing
|last2=Xiao
|first3=Dacheng
|last3=Tao
|first4=Xuelong
|last4=Li
|title=A survey of graph edit distance
|journal=Pattern Analysis and Applications
|year=2010
|volume=13
|pages=113&amp;ndash;129
|doi=10.1007/s10044-008-0141-y
}}&lt;/ref&gt;

The graph edit distance between two graphs is related to the
[[Edit distance|string edit distance]] between [[String (computing)|strings]].
With the interpretation of strings as [[Connected component (graph theory)|
connected]], [[directed acyclic graph]]s of 
[[Degree (graph theory)|maximum degree]] one, classical definitions
of edit distance such as [[Levenshtein distance]],
&lt;ref&gt;{{cite journal
|author=Влади́мир И. Левенштейн
|script-title=ru:Двоичные коды с исправлением выпадений, вставок и замещений символов
|language=Russian
|trans-title=Binary codes capable of correcting deletions, insertions, and reversals
|journal=Доклады Академий Наук СCCP
|volume=163
|issue=4
|pages=845–848
|year=1965}}&lt;/ref&gt;
&lt;ref&gt;{{cite journal
|last1=Levenshtein
|first1=Vladimir I.
|title=Binary codes capable of correcting deletions, insertions, and reversals
|journal=[[Soviet Physics Doklady]]
|volume=10
|number=8
|pages=707–710
|date=February 1966}}&lt;/ref&gt;
[[Hamming distance]]&lt;ref&gt;{{cite journal
 |last=Hamming 
 |first=Richard W. 
 |author-link=Richard W. Hamming 
 |mr=0035935 
 |issue=2 
 |journal=[[Bell System Technical Journal]] 
 |pages=147–160 
 |title=Error detecting and error correcting codes 
 |url=http://www.caip.rutgers.edu/~bushnell/dsdwebsite/hamming.pdf 
 |volume=29 
 |year=1950 
 |doi=10.1002/j.1538-7305.1950.tb00463.x 
 |deadurl=bot: unknown 
 |archiveurl=https://web.archive.org/web/20060525060427/http://www.caip.rutgers.edu/~bushnell/dsdwebsite/hamming.pdf 
 |archivedate=2006-05-25 
 |df= 
|hdl=10945/46756 
 }}&lt;/ref&gt;
and [[Jaro–Winkler distance]] may be interpreted as graph edit distances
between suitably constrained graphs.  Likewise, graph edit distance is
also a generalization of '''tree edit distance''' between
[[Tree (graph theory)|rooted trees]].&lt;ref&gt;{{cite journal
|last1=Shasha
|first1=D
|last2=Zhang
|first2=K
|title=Simple fast algorithms for the editing distance between trees and related problems
|journal=[[SIAM J. Comput.]]
|volume=18
|number=6
|pages=1245–1262
|year=1989
|doi=10.1137/0218082
|citeseerx=10.1.1.460.5601
}}&lt;/ref&gt;&lt;ref&gt;{{cite journal
|last1=Zhang
|first1=K
|title=A constrained edit distance between unordered labeled trees
|journal=[[Algorithmica]]
|volume=15
|number=3
|pages=205–222
|year=1996
|doi=10.1007/BF01975866
}}&lt;/ref&gt;&lt;ref&gt;{{cite journal
|last1=Bille
|first1=P
|title=A survey on tree edit distance and related problems
|journal=[[Theor. Comput. Sci.]]
|volume=337
|issue=1–3
|pages=22–34
|year=2005
|doi=10.1016/j.tcs.2004.12.030
}}&lt;/ref&gt;&lt;ref&gt;{{cite journal
|last1=Demaine
|first1=Erik D.
|author1-link=Erik Demaine
|last2=Mozes
|first2=Shay
|last3=Rossman
|first3=Benjamin
|last4=Weimann|first4=Oren
|issue = 1
|journal = [[ACM Transactions on Algorithms]]
|mr = 2654906
|page = A2
|title = An optimal decomposition algorithm for tree edit distance
|volume = 6
|year = 2010
|doi = 10.1145/1644015.1644017
|citeseerx=10.1.1.163.6937
}}&lt;/ref&gt;

==Formal definitions and properties==
The mathematical definition of graph edit distance is dependent upon the definitions of
the graphs over which it is defined, i.e. whether and how the vertices and edges of the
graph are [[graph labeling|labeled]] and whether the edges are [[directed graph|directed]].
Generally, given a set of '''graph edit operations''' (also known as elementary [[graph operations]]), the graph edit distance between two graphs &lt;math&gt;g_{1}&lt;/math&gt; and &lt;math&gt;g_{2}&lt;/math&gt;, written as &lt;math&gt;GED(g_{1},g_{2})&lt;/math&gt; can be defined as
:&lt;math&gt; GED(g_{1},g_{2}) = \min_{(e_{1},...,e_{k}) \in \mathcal{P}(g_{1},g_{2})} \sum_{i=1}^{k} c(e_{i})&lt;/math&gt;
where &lt;math&gt;\mathcal{P}(g_{1},g_{2})&lt;/math&gt; denotes the set of edit paths transforming &lt;math&gt;g_{1}&lt;/math&gt; into (a graph [[Graph isomorphism|isomorphic]] to) &lt;math&gt;g_{2}&lt;/math&gt; and &lt;math&gt;c(e) \ge 0&lt;/math&gt; is the cost of each graph edit operation &lt;math&gt;e&lt;/math&gt;.

The set of elementary graph edit operators typically includes:

:'''vertex insertion''' to introduce a single new labeled vertex to a graph.
:'''vertex deletion''' to remove a single (often disconnected) vertex from a graph.
:'''vertex substitution''' to change the label (or color) of a given vertex.
:'''edge insertion''' to introduce a new colored edge between a pair of vertices.
:'''edge deletion''' to remove a single edge between a pair of vertices.
:'''edge substitution''' to change the label (or color) of a given edge.

Additional, but less common operators, include operations such as '''edge splitting''' that introduces a new vertex into an edge (also creating a new edge), and '''[[edge contraction]]''' that eliminates vertices of degree two between edges (of the same color).  Although such complex edit operators can be defined in terms of more elementary transformations, their use allows finer parameterization of the cost function &lt;math&gt;c&lt;/math&gt; when the operator is cheaper than the sum of its constituents.

==Applications==
Graph edit distance finds applications in [[handwriting recognition]],&lt;ref&gt;{{citation
|last1=Fischer
|first1=Andreas
|last2=Suen
|first2=Ching Y.
|last3=Frinken
|first3=Volkmar
|last4=Riesen
|first4=Kaspar
|last5=Bunke
|first5=Horst
|contribution=A Fast Matching Algorithm for Graph-Based Handwriting Recognition
|title=Graph-Based Representations in Pattern Recognition
|series=[[Lecture Notes in Computer Science]]
|volume=7877
|pages=194–203
|year=2013
|doi=10.1007/978-3-642-38221-5_21
|isbn=978-3-642-38220-8
}}&lt;/ref&gt; [[fingerprint recognition]]&lt;ref&gt;{{citation
|last1=Neuhaus
|first1=Michel
|last2=Bunke
|first2=Horst
|contribution=A Graph Matching Based Approach to Fingerprint Classification using Directional Variance
|title=Audio- and Video-Based Biometric Person Authentication
|series=[[Lecture Notes in Computer Science]]
|volume=3546
|pages=191–200
|year=2005
|doi=10.1007/11527923_20
|isbn=978-3-540-27887-0
}}&lt;/ref&gt; and [[cheminformatics]].&lt;ref&gt;{{cite journal
|last1=Birchall
|first1=Kristian
|last2=Gillet
|first2=Valerie J.
|last3=Harper
|first3=Gavin
|last4=Pickett
|first4=Stephen D.
|title=Training Similarity Measures for Specific Activities: Application to Reduced Graphs
|journal=[[Journal of Chemical Information and Modeling]]
|volume=46
|number=2
|pages=557–586
|date=Jan 2006
|doi=10.1021/ci050465e
|pmid=16562986
}}&lt;/ref&gt;

==Algorithms and Complexity==
Exact algorithms for computing the graph edit distance between a pair of graphs typically
transform the problem into one of finding the minimum cost edit path between the two graphs.
The computation of the optimal edit path is cast as a [[pathfinding]] search or [[shortest path problem]], often implemented as an [[A* search algorithm]].

In addition to exact algorithms, a number of efficient approximation algorithms are
also known.&lt;ref&gt;{{cite book
|last1=Neuhaus
|first1=Michel
|last2=Bunke
|first2=Horst
|title=Bridging the Gap between Graph Edit Distance and Kernel Machines
|series=Machine Perception and Artificial Intelligence
|volume=68
|publisher=World Scientific
|isbn=978-9812708175
|date=Nov 2007
}}&lt;/ref&gt;&lt;ref&gt;{{cite book
|last=Riesen
|first=Kaspar
|title=Structural Pattern Recognition with Graph Edit Distance: Approximation Algorithms and Applications
|series=Advances in Computer Vision and Pattern Recognition
|publisher=Springer
|isbn=978-3319272511
|date=Feb 2016 
}}&lt;/ref&gt;

Despite the above algorithms sometimes working well in practice, in general the problem of computing graph edit distance is NP-complete&lt;ref&gt;{{Cite book|title=Computers and Intractability: A Guide to the Theory of NP-Completeness|last=Garey and Johnson|first=|publisher=W. H. Freeman and Company|year=1979|isbn=978-0-7167-1045-5|location=|pages=}}&lt;/ref&gt; (for a proof that's available online, see Section 2 of [http://www.vldb.org/pvldb/2/vldb09-568.pdf Zeng et al.]), and is even hard to approximate (formally, it is [[APX]]-hard&lt;ref&gt;{{Cite book|last=Lin|first=Chih-Long|date=1994-08-25|publisher=Springer Berlin Heidelberg|isbn=9783540583257|editor-last=Du|editor-first=Ding-Zhu|series=Lecture Notes in Computer Science|pages=74–82|language=en|doi=10.1007/3-540-58325-4_168|editor-last2=Zhang|editor-first2=Xiang-Sun|title = Algorithms and Computation|volume = 834|chapter=Hardness of approximating graph transformation problem}}&lt;/ref&gt;).

==References==
{{Reflist}}

[[Category:Graph theory]]
[[Category:Graph algorithms]]
[[Category:Computational problems in graph theory]]
[[Category:Similarity and distance measures]]</text>
      <sha1>lwm9mb6bd69m3hbeecfuga181g3uf9r</sha1>
    </revision>
  </page>
  <page>
    <title>Green's function (many-body theory)</title>
    <ns>0</ns>
    <id>7864709</id>
    <revision>
      <id>863648268</id>
      <parentid>827192637</parentid>
      <timestamp>2018-10-12T02:57:13Z</timestamp>
      <contributor>
        <ip>73.39.152.248</ip>
      </contributor>
      <comment>/* Spatially uniform case */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22672">In [[many-body theory]], the term '''Green's function''' (or '''Green function''') is sometimes used interchangeably with [[Correlation function (quantum field theory)|correlation function]], but refers specifically to correlators of [[field operator]]s or [[creation and annihilation operators]].

The name comes from the [[Green's functions]] used to solve inhomogeneous [[differential equations]], to which they are loosely related. (Specifically, only two-point 'Green's functions' in the case of a non-interacting system are Green's functions in the mathematical sense; the linear operator that they invert is the [[Hamiltonian (quantum mechanics)|Hamiltonian operator]], which in the non-interacting case is quadratic in the fields.)

==Spatially uniform case==

===Basic definitions===

We consider a many-body theory with field operator (annihilation operator written in the position basis) &lt;math&gt;\psi(\mathbf{x})&lt;/math&gt;.

The [[Heisenberg picture|Heisenberg operators]] can be written in terms of [[Schrödinger picture|Schrödinger operators]] as
:&lt;math&gt;
\psi(\mathbf{x},t) = \mathrm{e}^{\mathrm{i} K t} \psi(\mathbf{x}) \mathrm{e}^{-\mathrm{i} K t},
&lt;/math&gt;
and the creation operator is &lt;math&gt;\bar\psi(\mathbf{x},t) = [\psi(\mathbf{x},t)]^\dagger&lt;/math&gt;, where &lt;math&gt;K = H - \mu N&lt;/math&gt; is the [[Grand canonical ensemble|grand-canonical]] Hamiltonian.

Similarly, for the [[Imaginary time|imaginary-time]] operators,
:&lt;math&gt;
\psi(\mathbf{x},\tau) = \mathrm{e}^{K \tau} \psi(\mathbf{x}) \mathrm{e}^{-K\tau}
&lt;/math&gt;
:&lt;math&gt;
\bar\psi(\mathbf{x},\tau) = \mathrm{e}^{K \tau} \psi^\dagger(\mathbf{x}) \mathrm{e}^{-K\tau}.
&lt;/math&gt;
[Note that the imaginary-time creation operator &lt;math&gt;\bar\psi(\mathbf{x},\tau)&lt;/math&gt; is not the [[Hermitian conjugate]] of the annihilation operator &lt;math&gt;\psi(\mathbf{x},\tau)&lt;/math&gt;.]

In real time, the &lt;math&gt;2n&lt;/math&gt;-point Green function is defined by
:&lt;math&gt;
G^{(n)}(1 \ldots n \mid 1' \ldots n')
= i^n \langle T\psi(1)\ldots\psi(n)\bar\psi(n')\ldots\bar\psi(1')\rangle,
&lt;/math&gt;
where we have used a condensed notation in which &lt;math&gt;j&lt;/math&gt; signifies &lt;math&gt;(\mathbf{x}_j, t_j)&lt;/math&gt; and &lt;math&gt;j'&lt;/math&gt; signifies &lt;math&gt;(\mathbf{x}_j', t_j')&lt;/math&gt;. The operator &lt;math&gt;T&lt;/math&gt; denotes [[time ordering]], and indicates that the field operators that follow it are to be ordered so that their time arguments increase from right to left.

In imaginary time, the corresponding definition is
:&lt;math&gt;
\mathcal{G}^{(n)}(1 \ldots n \mid 1' \ldots n')
= \langle T\psi(1)\ldots\psi(n)\bar\psi(n')\ldots\bar\psi(1')\rangle,
&lt;/math&gt;
where &lt;math&gt;j&lt;/math&gt; signifies &lt;math&gt;\mathbf{x}_j, \tau_j&lt;/math&gt;. (The imaginary-time variables &lt;math&gt;\tau_j&lt;/math&gt; are restricted to the range from &lt;math&gt;0&lt;/math&gt; to the inverse temperature &lt;math&gt;\beta=\frac{1}{k_B T}&lt;/math&gt;.)

'''Note''' regarding signs and normalization used in these definitions: The signs of the Green functions have been chosen so that [[Fourier transform]] of the two-point (&lt;math&gt;n=1&lt;/math&gt;) thermal Green function for a free particle is
:&lt;math&gt;
\mathcal{G}(\mathbf{k},\omega_n) = \frac{1}{-\mathrm{i}\omega_n + \xi_\mathbf{k}},
&lt;/math&gt;
and the retarded Green function is
:&lt;math&gt;
G^{\mathrm{R}}(\mathbf{k},\omega) = \frac{1}{-(\omega+\mathrm{i}\eta) + \xi_\mathbf{k}},
&lt;/math&gt;
where
:&lt;math&gt;
\omega_n = {[2n+\theta(-\zeta)]\pi}/{\beta}
&lt;/math&gt;
is the [[Matsubara frequency]].

Throughout, &lt;math&gt;\zeta&lt;/math&gt; is &lt;math&gt;+1&lt;/math&gt; for [[boson]]s and &lt;math&gt;-1&lt;/math&gt; for [[fermion]]s and &lt;math&gt;[\ldots,\ldots]=[\ldots,\ldots]_{-\zeta}&lt;/math&gt; denotes either a [[commutator]] or anticommutator as appropriate.

(See [[Green's function (many-body theory)#Non-interacting case|below]] for details.)

===Two-point functions===

The Green function with a single pair of arguments (&lt;math&gt;n=1&lt;/math&gt;) is referred to as the two-point function, or [[propagator]]. In the presence of both spatial and temporal translational symmetry, it depends only on the difference of its arguments. Taking the Fourier transform with respect to both space and time gives
:&lt;math&gt;
\mathcal{G}(\mathbf{x}\tau\mid\mathbf{x}'\tau') = \int_\mathbf{k} d\mathbf{k}  \frac{1}{\beta}\sum_{\omega_n} \mathcal{G}(\mathbf{k},\omega_n) \mathrm{e}^{\mathrm{i} \mathbf{k}\cdot(\mathbf{x}-\mathbf{x}')-\mathrm{i}\omega_n (\tau-\tau')},
&lt;/math&gt;
where the sum is over the appropriate [[Matsubara frequency|Matsubara frequencies]] (and the integral involves an implicit factor of &lt;math&gt;(L/2\pi)^{d}&lt;/math&gt;, as usual).

In real time, we will explicitly indicate the time-ordered function with a superscript T:
:&lt;math&gt;
G^{\mathrm{T}}(\mathbf{x} t\mid\mathbf{x}' t') = \int_\mathbf{k} d \mathbf{k} \int \frac{\mathrm{d}\omega}{2\pi} G^{\mathrm{T}}(\mathbf{k},\omega) \mathrm{e}^{\mathrm{i} \mathbf{k}\cdot(\mathbf{x} -\mathbf{x} ')-\mathrm{i}\omega(t-t')}.
&lt;/math&gt;

The real-time two-point Green function can be written in terms of 'retarded' and 'advanced' Green functions, which will turn out to have simpler analyticity properties. The retarded and advanced Green functions are defined by
:&lt;math&gt;
G^{\mathrm{R}}(\mathbf{x} t\mid\mathbf{x} 't') = -\mathrm{i}\langle[\psi(\mathbf{x} ,t),\bar\psi(\mathbf{x} ',t')]_{\zeta}\rangle\Theta(t-t')
&lt;/math&gt;
and
:&lt;math&gt;
G^{\mathrm{A}}(\mathbf{x} t\mid\mathbf{x} 't') = \mathrm{i}\langle[\psi(\mathbf{x} ,t),\bar\psi(\mathbf{x} ',t')]_{\zeta}\rangle\Theta(t'-t),
&lt;/math&gt;
respectively.

They are related to the time-ordered Green function by
:&lt;math&gt;
G^{\mathrm{T}}(\mathbf{k},\omega) = [1+\zeta n(\omega)]G^{\mathrm{R}}(\mathbf{k},\omega) - \zeta n(\omega) G^{\mathrm{A}}(\mathbf{k},\omega),
&lt;/math&gt;
where
:&lt;math&gt;
n(\omega) = \frac{1}{\mathrm{e}^{\beta \omega}-\zeta}
&lt;/math&gt;
is the [[Bose–Einstein statistics|Bose–Einstein]] or [[Fermi–Dirac statistics|Fermi–Dirac]] distribution function.

====Imaginary-time ordering and ''&amp;beta;''-periodicity====

The thermal Green functions are defined only when both imaginary-time arguments are within the range &lt;math&gt;0&lt;/math&gt; to &lt;math&gt;\beta&lt;/math&gt;. The two-point Green function has the following properties. (The position or momentum arguments are suppressed in this section.)

Firstly, it depends only on the difference of the imaginary times:
:&lt;math&gt;
\mathcal{G}(\tau,\tau') = \mathcal{G}(\tau - \tau').
&lt;/math&gt;
The argument &lt;math&gt;\tau - \tau'&lt;/math&gt; is allowed to run from &lt;math&gt;-\beta&lt;/math&gt; to &lt;math&gt;\beta&lt;/math&gt;.

Secondly, &lt;math&gt;\mathcal{G}(\tau)&lt;/math&gt; is (anti)periodic under shifts of &lt;math&gt;\beta&lt;/math&gt;. Because of the small domain within which the function is defined, this means just
:&lt;math&gt;
\mathcal{G}(\tau - \beta) = \zeta \mathcal{G}(\tau),
&lt;/math&gt;
for &lt;math&gt;0 &lt; \tau &lt; \beta&lt;/math&gt;. Time ordering is crucial for this property, which can be proved straightforwardly, using the cyclicity of the trace operation.

These two properties allow for the Fourier transform representation and its inverse,
:&lt;math&gt;
\mathcal{G}(\omega_n) = \int_0^\beta \mathrm{d}\tau \, \mathcal{G}(\tau)\, \mathrm{e}^{\mathrm{i}\omega_n \tau}.
&lt;/math&gt;

Finally, note that &lt;math&gt;\mathcal{G}(\tau)&lt;/math&gt; has a discontinuity at &lt;math&gt;\tau = 0&lt;/math&gt;; this is consistent with a long-distance behaviour of &lt;math&gt;\mathcal{G}(\omega_n) \sim 1/|\omega_n|&lt;/math&gt;.

===Spectral representation===
The [[propagator]]s in real and imaginary time can both be related to the spectral density (or spectral weight), given by
:&lt;math&gt;
\rho(\mathbf{k},\omega) = \frac{1}{\mathcal{Z}}\sum_{\alpha,\alpha'} 2\pi \delta(E_\alpha-E_{\alpha'}-\omega) |\langle \alpha \mid \psi_\mathbf{k}^\dagger\mid \alpha'\rangle|^2 \left(\mathrm{e}^{-\beta E_{\alpha'}} - \zeta\mathrm{e}^{-\beta E_{\alpha}}\right),
&lt;/math&gt;
where |{{mvar|α}}⟩ refers to a (many-body) eigenstate of the grand-canonical Hamiltonian {{math|''H''&amp;nbsp;−&amp;nbsp;''μN''}}, with eigenvalue {{math|''E&lt;sub&gt;α&lt;/sub&gt;''}}.

The imaginary-time [[propagator]] is then given by
:&lt;math&gt;
\mathcal{G}(\mathbf{k},\omega_n) = \int_{-\infty}^\infty \frac{\mathrm{d}\omega'}{2\pi}
\frac{\rho(\mathbf{k},\omega')}{-\mathrm{i}\omega_n+\omega'}~,
&lt;/math&gt;
and the retarded [[propagator]] by
:&lt;math&gt;
G^{\mathrm{R}}(\mathbf{k},\omega) = \int_{-\infty}^\infty \frac{\mathrm{d}\omega'}{2\pi}
\frac{\rho(\mathbf{k},\omega')}{-(\omega+\mathrm{i}\eta)+\omega'},
&lt;/math&gt;
where the limit as &lt;math&gt;\eta\rightarrow 0^+&lt;/math&gt; is implied.

The advanced propagator is given by the same expression, but with &lt;math&gt;-\mathrm{i}\eta&lt;/math&gt; in the denominator. 

The time-ordered function can be found in terms of &lt;math&gt;G^{\mathrm{R}}&lt;/math&gt; and &lt;math&gt;G^{\mathrm{A}}&lt;/math&gt;. As claimed above, &lt;math&gt;G^{\mathrm{R}}(\omega)&lt;/math&gt; and &lt;math&gt;G^{\mathrm{A}}(\omega)&lt;/math&gt; have simple analyticity properties: the former (latter) has all its poles and discontinuities in the lower (upper) half-plane. 

The thermal propagator &lt;math&gt;\mathcal{G}(\omega_n)&lt;/math&gt; has all its poles and discontinuities on the imaginary &lt;math&gt;\omega_n&lt;/math&gt; axis.

The spectral density can be found very straightforwardly from &lt;math&gt;G^{\mathrm{R}}&lt;/math&gt;, using the [[Sokhatsky–Weierstrass theorem]]
:&lt;math&gt;
\lim_{\eta\rightarrow 0^+}\frac{1}{x\pm\mathrm{i}\eta} = {P}\frac{1}{x}\mp i\pi\delta(x),
&lt;/math&gt;
where {{mvar|P}} denotes the [[Cauchy principal part]].
This gives
:&lt;math&gt;
\rho(\mathbf{k},\omega) = 2\mathrm{Im}\, G^{\mathrm{R}}(\mathbf{k},\omega).
&lt;/math&gt;

This furthermore implies that &lt;math&gt;G^{\mathrm{R}}(\mathbf{k},\omega)&lt;/math&gt; obeys the following relationship between its real and imaginary parts:
:&lt;math&gt;
\mathrm{Re}\, G^{\mathrm{R}}(\mathbf{k},\omega) = -2 P \int_{-\infty}^\infty \frac{\mathrm{d}\omega'}{2\pi}
\frac{\mathrm{Im}\, G^{\mathrm{R}}(\mathbf{k},\omega')}{\omega-\omega'},
&lt;/math&gt;
where &lt;math&gt;P&lt;/math&gt; denotes the principal value of the integral.

The spectral density obeys a sum rule,
:&lt;math&gt;
\int_{-\infty}^{\infty} \frac{\mathrm{d}\omega}{2\pi} \rho(\mathbf{k},\omega) = 1,
&lt;/math&gt;
which gives
:&lt;math&gt;
G^{\mathrm{R}}(\omega)\sim\frac{1}{|\omega|}
&lt;/math&gt;
as &lt;math&gt;|\omega| \rightarrow \infty&lt;/math&gt;.

====Hilbert transform====
The similarity of the spectral representations of the imaginary- and real-time Green functions allows us to define the function
:&lt;math&gt;
G(\mathbf{k},z) = \int_{-\infty}^\infty \frac{\mathrm{d} x}{2\pi} \frac{\rho(\mathbf{k},x)}{-z+x},
&lt;/math&gt;
which is related to &lt;math&gt;\mathcal{G}&lt;/math&gt; and &lt;math&gt;G^{\mathrm{R}}&lt;/math&gt; by
:&lt;math&gt;
\mathcal{G}(\mathbf{k},\omega_n) = G(\mathbf{k},\mathrm{i}\omega_n)
&lt;/math&gt;
and
:&lt;math&gt;
G^{\mathrm{R}}(\mathbf{k},\omega) = G(\mathbf{k},\omega + \mathrm{i}\eta).
&lt;/math&gt;
A similar expression obviously holds for &lt;math&gt;G^{\mathrm{A}}&lt;/math&gt;.

The relation between &lt;math&gt;G(\mathbf{k},z)&lt;/math&gt; and &lt;math&gt;\rho(\mathbf{k},x)&lt;/math&gt; is referred to as a [[Hilbert transform]].

====Proof of spectral representation====

We demonstrate the proof of the spectral representation of the propagator in the case of the thermal Green function, defined as
:&lt;math&gt;
\mathcal{G}(\mathbf{x} ,\tau\mid\mathbf{x} ',\tau') = \langle T\psi(\mathbf{x} ,\tau)\bar\psi(\mathbf{x} ',\tau')\rangle.
&lt;/math&gt;

Due to translational symmetry, it is only necessary to consider &lt;math&gt;\mathcal{G}(\mathbf{x} ,\tau\mid\mathbf{0},0)&lt;/math&gt; for &lt;math&gt;\tau &gt; 0&lt;/math&gt;, given by
:&lt;math&gt;
\mathcal{G}(\mathbf{x},\tau\mid\mathbf{0},0) = \frac{1}{\mathcal{Z}}\sum_{\alpha'} \mathrm{e}^{-\beta E_{\alpha'}}
\langle\alpha' \mid \psi(\mathbf{x},\tau)\bar\psi(\mathbf{0},0) \mid \alpha' \rangle.
&lt;/math&gt;
Inserting a complete set of eigenstates gives
:&lt;math&gt;
\mathcal{G}(\mathbf{x} ,\tau|\mathbf{0},0) = \frac{1}{\mathcal{Z}}\sum_{\alpha,\alpha'} \mathrm{e}^{-\beta E_{\alpha'}}
\langle\alpha' \mid \psi(\mathbf{x} ,\tau)\mid\alpha \rangle\langle\alpha \mid \bar\psi(\mathbf{0},0) \mid \alpha' \rangle.
&lt;/math&gt;

Since &lt;math&gt;|\alpha \rangle&lt;/math&gt; and &lt;math&gt;|\alpha' \rangle&lt;/math&gt; are eigenstates of &lt;math&gt;H-\mu N&lt;/math&gt;, the Heisenberg operators can be rewritten in terms of Schrödinger operators, giving
:&lt;math&gt;
\mathcal{G}(\mathbf{x} ,\tau|\mathbf{0},0) = \frac{1}{\mathcal{Z}}\sum_{\alpha,\alpha'} \mathrm{e}^{-\beta E_{\alpha'}}
\mathrm{e}^{\tau(E_{\alpha'} - E_\alpha)}\langle\alpha' \mid \psi(\mathbf{x} )\mid\alpha \rangle\langle\alpha \mid \psi^\dagger(\mathbf{0}) \mid \alpha' \rangle.
&lt;/math&gt;
Performing the Fourier transform then gives
:&lt;math&gt;
\mathcal{G}(\mathbf{k},\omega_n) = \frac{1}{\mathcal{Z}} \sum_{\alpha,\alpha'} \mathrm{e}^{-\beta E_{\alpha'}} \frac{1-\zeta \mathrm{e}^{\beta(E_{\alpha'} - E_\alpha)}}{-\mathrm{i}\omega_n + E_\alpha - E_{\alpha'}} \int_{\mathbf{k}'} d\mathbf{k}' \langle\alpha \mid \psi(\mathbf{k}) \mid \alpha' \rangle\langle\alpha' \mid \psi^\dagger(\mathbf{k}')\mid\alpha \rangle.
&lt;/math&gt;

Momentum conservation allows the final term to be written as (up to possible factors of the volume)
:&lt;math&gt;
|\langle\alpha' \mid\psi^\dagger(\mathbf{k})\mid\alpha \rangle|^2,
&lt;/math&gt;
which confirms the expressions for the Green functions in the spectral representation.

The sum rule can be proved by considering the expectation value of the commutator,
:&lt;math&gt;
1 = \frac{1}{\mathcal{Z}} \sum_\alpha \langle\alpha \mid \mathrm{e}^{-\beta(H-\mu N)}[\psi_\mathbf{k},\psi_\mathbf{k}^\dagger]_{-\zeta} \mid \alpha \rangle,
&lt;/math&gt;
and then inserting a complete set of eigenstates into both terms of the commutator:
: &lt;math&gt;
1 = \frac{1}{\mathcal{Z}} \sum_{\alpha,\alpha'} \mathrm{e}^{-\beta E_\alpha} \left(
\langle\alpha \mid \psi_\mathbf{k} \mid \alpha' \rangle\langle\alpha' \mid \psi_\mathbf{k}^\dagger \mid \alpha \rangle - \zeta \langle\alpha \mid \psi_\mathbf{k}^\dagger \mid \alpha' \rangle\langle\alpha' \mid \psi_\mathbf{k}\mid\alpha \rangle
\right).
&lt;/math&gt;

Swapping the labels in the first term then gives
:&lt;math&gt;
1 = \frac{1}{\mathcal{Z}} \sum_{\alpha,\alpha'}
\left(\mathrm{e}^{-\beta E_{\alpha'}} - \zeta \mathrm{e}^{-\beta E_\alpha} \right)
|\langle\alpha \mid \psi_\mathbf{k}^\dagger \mid \alpha' \rangle|^2 ~,
&lt;/math&gt;
which is exactly the result of the integration of  {{mvar|ρ}}.

====Non-interacting case====
In the non-interacting case, &lt;math&gt;\psi_\mathbf{k}^\dagger\mid\alpha' \rangle&lt;/math&gt; is an eigenstate with (grand-canonical) energy &lt;math&gt;E_{\alpha'} + \xi_\mathbf{k}&lt;/math&gt;, where &lt;math&gt;\xi_\mathbf{k} = \epsilon_\mathbf{k} - \mu&lt;/math&gt; is the single-particle dispersion relation measured with respect to the chemical potential. The spectral density therefore becomes
:&lt;math&gt;
\rho_0(\mathbf{k},\omega) = \frac{1}{\mathcal{Z}}\,2\pi\delta(\xi_\mathbf{k} - \omega) \sum_{\alpha'}\langle\alpha' \mid\psi_\mathbf{k}\psi_\mathbf{k}^\dagger\mid\alpha' \rangle(1-\zeta \mathrm{e}^{-\beta\xi_\mathbf{k}})\mathrm{e}^{-\beta E_{\alpha'}}.
&lt;/math&gt;

From the commutation relations,
:&lt;math&gt;
\langle\alpha' \mid \psi_\mathbf{k}\psi_\mathbf{k}^\dagger\mid\alpha' \rangle =
\langle\alpha' \mid(1+\zeta\psi_\mathbf{k}^\dagger\psi_\mathbf{k})\mid\alpha' \rangle,
&lt;/math&gt;
with possible factors of the volume again. The sum, which involves the thermal average of the number operator, then gives simply &lt;math&gt;[1 + \zeta n(\xi_\mathbf{k})]\mathcal{Z}&lt;/math&gt;, leaving
:&lt;math&gt;
\rho_0(\mathbf{k},\omega) = 2\pi\delta(\xi_\mathbf{k} - \omega).
&lt;/math&gt;

The imaginary-time propagator is thus
:&lt;math&gt;
\mathcal{G}_0(\mathbf{k},\omega) = \frac{1}{-\mathrm{i}\omega_n + \xi_\mathbf{k}}
&lt;/math&gt;
and the retarded propagator is
:&lt;math&gt;
G_0^{\mathrm{R}}(\mathbf{k},\omega) = \frac{1}{-(\omega+\mathrm{i} \eta) + \xi_\mathbf{k}}.
&lt;/math&gt;

====Zero-temperature limit====

As {{mvar|β}}→∞, the spectral density becomes
:&lt;math&gt;
\rho(\mathbf{k},\omega) = 2\pi\sum_{\alpha} \left[ \delta(E_\alpha - E_0 - \omega)
|\langle\alpha \mid \psi_\mathbf{k}^\dagger\mid 0 \rangle|^2
- \zeta \delta(E_0 - E_{\alpha} - \omega)
|\langle0 \mid \psi_\mathbf{k}^\dagger\mid\alpha \rangle|^2\right]
&lt;/math&gt;
where {{mvar|α}} = 0 corresponds to the ground state. Note that only the first (second) term contributes when {{mvar|ω}} is positive (negative).

==General case==

===Basic definitions===

We can use 'field operators' as above, or creation and annihilation operators associated with other single-particle states, perhaps eigenstates of the (noninteracting) kinetic energy. We then use
:&lt;math&gt;
\psi(\mathbf{x} ,\tau) = \varphi_\alpha(\mathbf{x} ) \psi_\alpha(\tau),
&lt;/math&gt;
where &lt;math&gt;\psi_\alpha&lt;/math&gt; is the annihilation operator for the single-particle state &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\varphi_\alpha(\mathbf{x} )&lt;/math&gt; is that state's wavefunction in the position basis. This gives
:&lt;math&gt;
\mathcal{G}^{(n)}_{\alpha_1\ldots\alpha_n|\beta_1\ldots\beta_n}(\tau_1 \ldots \tau_n | \tau_1' \ldots \tau_n')
= \langle T\psi_{\alpha_1}(\tau_1)\ldots\psi_{\alpha_n}(\tau_n)\bar\psi_{\beta_n}(\tau_n')\ldots\bar\psi_{\beta_1}(\tau_1')\rangle
&lt;/math&gt;
with a similar expression for &lt;math&gt;G^{(n)}&lt;/math&gt;.

===Two-point functions===

These depend only on the difference of their time arguments, so that
:&lt;math&gt;
\mathcal{G}_{\alpha\beta}(\tau\mid \tau') = \frac{1}{\beta}\sum_{\omega_n}
\mathcal{G}_{\alpha\beta}(\omega_n)\,\mathrm{e}^{-\mathrm{i}\omega_n (\tau-\tau')}
&lt;/math&gt;
and
:&lt;math&gt;
G_{\alpha\beta}(t\mid t') = \int_{-\infty}^{\infty}\frac{\mathrm{d}\omega}{2\pi}\,
G_{\alpha\beta}(\omega)\,\mathrm{e}^{-\mathrm{i}\omega(t-t')}.
&lt;/math&gt;

We can again define retarded and advanced functions in the obvious way; these are related to the time-ordered function in the same way as above.

The same periodicity properties as described in above apply to &lt;math&gt;\mathcal{G}_{\alpha\beta}&lt;/math&gt;. Specifically,
:&lt;math&gt;
\mathcal{G}_{\alpha\beta}(\tau\mid\tau') = \mathcal{G}_{\alpha\beta}(\tau-\tau')
&lt;/math&gt;
and
:&lt;math&gt;
\mathcal{G}_{\alpha\beta}(\tau) = \mathcal{G}_{\alpha\beta}(\tau + \beta),
&lt;/math&gt;
for &lt;math&gt;\tau &lt; 0&lt;/math&gt;.

===Spectral representation===

In this case,
:&lt;math&gt;
\rho_{\alpha\beta}(\omega) = \frac{1}{\mathcal{Z}}\sum_{m,n} 2\pi \delta(E_n-E_m-\omega)\;
\langle m \mid \psi_\alpha\mid n \rangle\langle n \mid \psi_\beta^\dagger\mid m \rangle
\left(\mathrm{e}^{-\beta E_m} - \zeta \mathrm{e}^{-\beta E_n}\right) ,
&lt;/math&gt;
where &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;n&lt;/math&gt; are many-body states.

The expressions for the Green functions are modified in the obvious ways:
:&lt;math&gt;
\mathcal{G}_{\alpha\beta}(\omega_n) = \int_{-\infty}^{\infty} \frac{\mathrm{d}\omega'}{2\pi}
\frac{\rho_{\alpha\beta}(\omega')}{-\mathrm{i}\omega_n+\omega'}
&lt;/math&gt;
and
:&lt;math&gt;
G^{\mathrm{R}}_{\alpha\beta}(\omega) = \int_{-\infty}^{\infty} \frac{\mathrm{d}\omega'}{2\pi}
\frac{\rho_{\alpha\beta}(\omega')}{-(\omega+\mathrm{i}\eta)+\omega'}.
&lt;/math&gt;

Their analyticity properties are identical. The proof follows exactly the same steps, except that the two matrix elements are no longer complex conjugates.

====Noninteracting case====

If the particular single-particle states that are chosen are `single-particle energy eigenstates', i.e.
:&lt;math&gt;
[H-\mu N,\psi_\alpha^\dagger] = \xi_\alpha\psi_\alpha^\dagger,
&lt;/math&gt;
then for &lt;math&gt;|n \rangle&lt;/math&gt; an eigenstate:
:&lt;math&gt;
(H-\mu N)\mid n \rangle = E_n \mid n \rangle,
&lt;/math&gt;
so is &lt;math&gt;\psi_\alpha \mid n \rangle&lt;/math&gt;:
:&lt;math&gt;
(H-\mu N)\psi_\alpha\mid n \rangle = (E_n - \xi_\alpha) \psi_\alpha \mid n \rangle,
&lt;/math&gt;
and so is &lt;math&gt;\psi_\alpha^\dagger\mid n \rangle&lt;/math&gt;:
:&lt;math&gt;
(H-\mu N)\psi_\alpha^\dagger \mid n \rangle = (E_n + \xi_\alpha) \psi_\alpha^\dagger \mid n \rangle.
&lt;/math&gt;

We therefore have
:&lt;math&gt;
\langle m \mid \psi_\alpha\mid n \rangle\langle n \mid \psi_\beta^\dagger\mid m \rangle =
\delta_{\xi_\alpha,\xi_\beta}\delta_{E_n,E_m+\xi_\alpha}\langle m \mid \psi_\alpha\mid n \rangle\langle n \mid \psi_\beta^\dagger\mid m \rangle.
&lt;/math&gt;

We then rewrite
:&lt;math&gt;
\rho_{\alpha\beta}(\omega) = \frac{1}{\mathcal{Z}}\sum_{m,n} 2\pi \delta(\xi_\alpha-\omega)
\delta_{\xi_\alpha,\xi_\beta}\langle m \mid \psi_\alpha\mid n \rangle\langle n \mid \psi_\beta^\dagger \mid m \rangle
\mathrm{e}^{-\beta E_m}\left(1 - \zeta \mathrm{e}^{-\beta \xi_\alpha}\right),
&lt;/math&gt;
therefore
:&lt;math&gt;
\rho_{\alpha\beta}(\omega)  = \frac{1}{\mathcal{Z}}\sum_m 2\pi \delta(\xi_\alpha-\omega)
\delta_{\xi_\alpha,\xi_\beta}\langle m \mid \psi_\alpha\psi_\beta^\dagger\mathrm{e}^{-\beta (H-\mu N)}\mid m \rangle
\left(1 - \zeta \mathrm{e}^{-\beta \xi_\alpha}\right),
&lt;/math&gt;
use
:&lt;math&gt;
\langle m \mid \psi_\alpha \psi_\beta^\dagger\mid m \rangle = \delta_{\alpha,\beta}\langle m \mid \zeta \psi_\alpha^\dagger \psi_\alpha + 1 \mid m \rangle
&lt;/math&gt;
and the fact that the thermal average of the number operator gives the Bose–Einstein or Fermi–Dirac distribution function.

Finally, the spectral density simplifies to give
:&lt;math&gt;
\rho_{\alpha\beta} = 2\pi \delta(\xi_\alpha - \omega)\delta_{\alpha\beta},
&lt;/math&gt;
so that the thermal Green function is
:&lt;math&gt;
\mathcal{G}_{\alpha\beta}(\omega_n) = \frac{\delta_{\alpha\beta}}{-\mathrm{i}\omega_n + \xi_\beta}
&lt;/math&gt;
and the retarded Green function is
:&lt;math&gt;
G_{\alpha\beta}(\omega) = \frac{\delta_{\alpha\beta}}{-(\omega+\mathrm{i}\eta) + \xi_\beta}.
&lt;/math&gt;
Note that the noninteracting Green function is diagonal, but this will not be true in the interacting case.

==See also==
*[[Fluctuation theorem]]
*[[Green–Kubo relations]]
*[[Linear response function]]
*[[Lindblad equation]]
*[[Propagator]]
*[[Correlation function (quantum field theory)]]

== References ==

===Books===
*Bonch-Bruevich V. L., [[Sergei Tyablikov|Tyablikov S. V.]] (1962): ''The Green Function Method in Statistical Mechanics.'' North Holland Publishing Co.
*Abrikosov, A. A., Gorkov, L. P. and Dzyaloshinski, I. E. (1963): ''Methods of Quantum Field Theory in Statistical Physics'' Englewood Cliffs: Prentice-Hall.
*Negele, J. W. and Orland, H. (1988): ''Quantum Many-Particle Systems'' AddisonWesley.
*[[Dmitry Zubarev|Zubarev D. N.]], Morozov V., Ropke G. (1996): ''Statistical Mechanics of Nonequilibrium Processes: Basic Concepts, Kinetic Theory'' (Vol. 1). John Wiley &amp; Sons. {{ISBN|3-05-501708-0}}.
*Mattuck Richard D. (1992), ''A Guide to Feynman Diagrams in the Many-Body Problem'', Dover Publications, {{ISBN|0-486-67047-3}}.

===Papers===
*[[Nikolay Bogolyubov|Bogolyubov N. N.]], [[Sergei Tyablikov|Tyablikov S. V.]] Retarded and advanced Green functions in statistical physics, Soviet Physics Doklady, Vol. '''4''', p.&amp;nbsp;589 (1959).
*[[Dmitry Zubarev|Zubarev D. N.]], [https://dx.doi.org/10.1070/PU1960v003n03ABEH003275 Double-time Green functions in statistical physics], Soviet Physics Uspekhi '''3'''(3), 320–345 (1960).

==External links==
* [http://www.cond-mat.de/events/correl14/manuscripts/pavarini.pdf Linear Response Functions] in Eva Pavarini, Erik Koch, Dieter Vollhardt, and Alexander Lichtenstein (eds.): DMFT at 25: Infinite Dimensions, Verlag des Forschungszentrum Jülich, 2014 {{ISBN|978-3-89336-953-9}}

[[Category:Quantum field theory]]
[[Category:Statistical mechanics]]
[[Category:Mathematical physics]]</text>
      <sha1>io2s4y30q7rfx7oxcjj6elthmtxka4o</sha1>
    </revision>
  </page>
  <page>
    <title>Hardy notation</title>
    <ns>0</ns>
    <id>1934369</id>
    <redirect title="Big O notation" />
    <revision>
      <id>286572195</id>
      <parentid>277128485</parentid>
      <timestamp>2009-04-28T02:41:38Z</timestamp>
      <contributor>
        <username>Kan8eDie</username>
        <id>7405267</id>
      </contributor>
      <comment>merged into [[Big O notation]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="166">#REDIRECT [[Big O notation]] {{R from merge}}

[[Category:Mathematical notation]]
[[Category:Asymptotic analysis]]

[[es:Notación de Hardy]]
[[fr:Notation de Hardy]]</text>
      <sha1>57kmpgvkw4o10awyo1q317ym7yhrb2r</sha1>
    </revision>
  </page>
  <page>
    <title>Isaac ben Moses Eli</title>
    <ns>0</ns>
    <id>57921397</id>
    <revision>
      <id>850864418</id>
      <parentid>850864350</parentid>
      <timestamp>2018-07-18T13:18:06Z</timestamp>
      <contributor>
        <username>Onel5969</username>
        <id>10951369</id>
      </contributor>
      <comment>/* References */ stub sort</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1357">'''Isaac ben Moses Eli ha-Sefaradi''' was a fifteenth century [[Spanish people|Spanish]] [[Jewish]] mathematician, born at [[Orihuela|Oriola]], [[Kingdom of Aragon|Aragon]].

According to [[Moritz Steinschneider|Steinschneider]], he may have been one of the [[Alhambra Decree|Spanish exiles of 1492]], probably leaving to [[Constantinople]]. He wrote a mathematical work entitled ''Meleket ha-Mispar'', divided into three parts: (1) a theory of numbers, dealing with the first four rules and the extraction of square roots; (2) proportion, etc.; and (3) elementary geometry. The book is an introduction to [[Euclid]], and begins with a definition of the science of figures.&lt;ref&gt;{{Cite Jewish Encyclopedia |title=Isaac ben Moses Eli (ha-Sefaradi)|url=http://www.jewishencyclopedia.com/articles/8204-isaac-ben-moses-eli-ha-sefardi|first1=Isidore|last1=Singer|first2=Max|last2=Schloessinger}}&lt;/ref&gt;

==References==
{{Reflist}}

* Steinschneider, ''Bibliotheca Mathematica'', 1901, p. 74.
* Steinschneider, ''Jewish Literature'', p. 192.
* {{JewishEncyclopedia |article=Isaac ben Moses Eli (ha-Sefaradi)|url=http://www.jewishencyclopedia.com/articles/8204-isaac-ben-moses-eli-ha-sefardi|author=Isidore Singer and Max Schloessinger}}

[[Category:15th-century mathematicians]]
[[Category:Medieval Aragonese Jews]]
[[Category:Spanish Jews]]

{{mathematician-stub}}</text>
      <sha1>1c6wjmzs7bdtrl0wf1rhcpqx22ru1po</sha1>
    </revision>
  </page>
  <page>
    <title>Joan Ferrini-Mundy</title>
    <ns>0</ns>
    <id>53725128</id>
    <revision>
      <id>870995153</id>
      <parentid>862616917</parentid>
      <timestamp>2018-11-28T07:31:20Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>1954</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4710">{{infobox scientist
  | name        = Joan Ferrini-Mundy
  | image       = File:NSF Community College Innovation Challenge finalist teams come to Washington, DC, for an “innovation boot camp” and selection of winners (44379873214) (cropped).jpg
  | caption     = Ferrini-Mundy in 2018
  | birth_date  = {{birth year|1954}}
  | birth_place = 
  | nationality       = {{flag|United States}}
  | fields            = [[Mathematics education]]
  | workplaces        = [[University of Maine]]
  | alma_mater        =  Ph.D., [[University of New Hampshire]] (1980)
  | doctoral_advisor  =  Richard Herbert Balomenos
  | known_for   = 
  }}

'''Joan Ferrini-Mundy''' (born 1954)&lt;ref&gt;Birth year from [http://www.isni.org/isni/0000000034810117 ISNI authority control file], retrieved 2018-11-27.&lt;/ref&gt; is a researcher in [[mathematics education]].  Her research interests include [[calculus]] teaching and learning, mathematics teacher learning, and [[Science, technology, engineering, and mathematics|STEM]] education policy. She is currently the president of the [[University of Maine]].

== Career and research ==
Ferrini-Mundy earned a Ph.D. in mathematics education from the [[University of New Hampshire]] (UNH) in 1980 and spent two years there as postdoctoral associate there.  After one year at [[Mount Holyoke College]], she returned to UNH as a faculty member in mathematics until joining the faculty of [[Michigan State University]] in 1999. One year later, she chaired the writing group for ''Standards 2000'', a publication from the [[National Council of Teachers of Mathematics]].&lt;ref name=":0"&gt;{{Cite web| url=http://www.ams.org/notices/200005/comm-awm.pdf| title=AWM Awards Presented in Washington, DC| last=| first=| date=| website=American Mathematical Society| archive-url=| archive-date=| dead-url=| access-date=April 8, 2017}}&lt;/ref&gt;

In 2007, Ferrini-Mundy joined the [[National Science Foundation]] (NSF) as the director of the new Division of Research on Learning in Formal and Informal Settings in the Directorate for Education and Human Resources; she remained a faculty member at Michigan State until 2010.  From 2007 to 2009, she served on the education subcommittee of the [[National Science and Technology Council]].&lt;ref&gt;{{Cite web| url=https://www.nsf.gov/mobile/staff/staff_bio.jsp?lan=jferrini| title=Joan Ferrini-Mundy {{!}} National Science Foundation| website=www.nsf.gov| language=en| access-date=2017-04-08}}&lt;/ref&gt;

In February 2011, Ferrini-Mundy became the Assistant Director of the National Science Foundation's Directorate for Education and Human Resources.&lt;ref name="SuccessfulSTEM"&gt;{{Cite web| url=http://successfulstemeducation.org/content/joan-ferrini-mundy-national-science-foundation| title=Joan Ferrini-Mundy, National Science Foundation {{!}} Successful STEM Education| website=successfulstemeducation.org| language=en| access-date=2017-04-08}}&lt;/ref&gt; In this strategic role, she set the NSF's direction for scientific education.&lt;ref name="SuccessfulSTEM" /&gt; In 2011, Ferrini-Mundy was elected as a Fellow at the [[American Association for the Advancement of Science]]&lt;ref&gt;{{Cite news| url=https://www.aaas.org/fellow/ferrini-mundy-joan| title=Ferrini-Mundy, Joan| date=2016-08-01| work=AAAS - The World's Largest General Scientific Society| access-date=2017-04-08| language=en}}&lt;/ref&gt; and in 2014 she was elected to the Executive Committee of the [[Association for Women in Mathematics]] for a 2-year term.&lt;ref&gt;{{Cite journal| last=Charney| first=Ruth| date=| title=President's Report| url=| journal=Association for Women in Mathematics Newsletter| volume=44| issue =  2| pages=1–3}}&lt;/ref&gt;

In June 2017, she was appointed the [[Chief Operating Officer]] of the NSF.  One year later, she left the NSF to become the 21st president of the University of Maine.

== Awards and recognition ==
In 2000, Ferrini-Mundy was the recipient of the [[Association for Women in Mathematics]]' [[Louise Hay Award]].&lt;ref name=":0" /&gt;&lt;ref&gt;{{Cite web| url=http://www.awm-math.org/hayaward/2000.html| title=10th Louise Hay Award: Joan Ferrini-Mundy| website=www.awm-math.org| access-date=2017-04-08}}&lt;/ref&gt;
She was elected to the 2018 class of [[fellow]]s of the [[American Mathematical Society]].&lt;ref&gt;{{citation|url=http://ams.org/profession/ams-fellows/new-fellows|title=2018 Class of the Fellows of the AMS|publisher=[[American Mathematical Society]]|accessdate=2017-11-03}}&lt;/ref&gt;

== References ==
{{Reflist}}


{{authority control}}

{{DEFAULTSORT:Ferrini-Mundy, Joan}}
[[Category:American educators]]
[[Category:American women mathematicians]]
[[Category:Living people]]
[[Category:1954 births]]
[[Category:Fellows of the American Mathematical Society]]


{{Mathematician-stub}}</text>
      <sha1>de8az9iq674he9k1jeasg5w5srn2iga</sha1>
    </revision>
  </page>
  <page>
    <title>John Adrian Bondy</title>
    <ns>0</ns>
    <id>22930177</id>
    <revision>
      <id>823520362</id>
      <parentid>812289231</parentid>
      <timestamp>2018-02-01T19:23:40Z</timestamp>
      <contributor>
        <ip>38.119.129.17</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5788">{{BLP sources|date=January 2010}}

{{Infobox person
| name          = John Adrian Bondy
| image         = &lt;!-- just the filename, without the File: or Image: prefix or enclosing [[brackets]] --&gt;
| alt           = 
| caption       = 
| birth_name    = &lt;!-- only use if different from name --&gt;
| birth_date    = 1944
| birth_place   = 
| death_date    = &lt;!-- {{Death date and age|YYYY|MM|DD|YYYY|MM|DD}} --&gt;
| death_place   = 
| nationality   = British, Canadian
| other_names   = 
| occupation    = Professor
| education     = [[University of Oxford]]
| years_active  = 
| known_for     = 
| notable_works = 
}}
'''John Adrian Bondy''', (Born 1944) a dual British and Canadian citizen, was a professor of [[graph theory]] at the [[University of Waterloo]], in Canada. He is a faculty member of [[Université Lyon 1]], France. Bondy is known for his work on [[Bondy–Chvátal theorem]] together with [[Václav Chvátal]]. His coauthors include [[Paul Erdős]].

Bondy received his Ph.D. in [[graph theory]] from [[University of Oxford]] in 1969. Bondy has served as a managing editor and co-editor-in-chief of the [[Journal of Combinatorial Theory, Series B]].&lt;ref&gt;{{Harvtxt|Cunningham|Haxell|Richter|Wormald|2004}}.&lt;/ref&gt;

Bondy was dismissed from his tenured position at Waterloo in 1995, after 28 years in which he had been a major contributor to the renown of the University's Department of Combinatorics and Optimization. The reasons for dismissal centered on "Bondy's acceptance of a teaching post in France, and the acceptability of someone who is on UW's faculty payroll holding a full-time job elsewhere."&lt;ref&gt;{{Harvtxt|UW Gazette|September 20, 1995|loc=http://www.communications.uwaterloo.ca/Gazette/1995/Gazette,%20September%2020,%201995/Faculty%20dismissal%20case%20discussed/Front%20page:%20professor%20is%20identified}}{{dead link|date=July 2014}} ([https://web.archive.org/web/20120427141236/http://www.communications.uwaterloo.ca/Gazette/1996/October02/Arbitrator%20upholds%20math%20prof%27s%20dismissal archive])&lt;/ref&gt;

Paul Erdős, at the time the world's most renowned [[combinatorics|combinatorialist]], returned his honorary doctorate to the University of Waterloo in protest.&lt;ref&gt;{{cite web|last1=Erdős|first1=Paul|authorlink1=Paul Erdős|title=Dear President Downey|url=http://ecp6.jussieu.fr/pageperso/bondy/uw/letters/erdos.pdf|accessdate=8 July 2014|archiveurl=https://web.archive.org/web/20051015141515/http://ecp6.jussieu.fr/pageperso/bondy/uw/letters/erdos.pdf|archivedate=15 October 2005|format=PDF|date=4 June 1996|quote=With a heavy heart I feel that I have to sever my connections with the University of Waterloo, including resigning my honorary degree which I received from the University in 1981 (which caused me great pleasure).  I was very upset by the treatment of Professor Adrian Bondy.  I do not maintain that Professor Bondy was innocent, but in view of his accomplishments and distinguished services to the University I feel that 'justice should be tempered with mercy.'}}&lt;/ref&gt;

==Select books and publications==
* {{citation
 | last1=Bondy | first1=John Adrian
 | last2=Murty | first2=U.S.R. | authorlink2=U. S. R. Murty
 | title=Graph Theory with Applications
 | year=1976
 | publisher=North-Holland
 | url=http://www.math.jussieu.fr/~jabondy/books/gtwa/gtwa.html
}}.&lt;ref&gt;[http://www.ams.org/mathscinet/search/publdoc.html?pg1=MR&amp;s1=411988 Review] in [[MathSciNet]].&lt;/ref&gt;&lt;ref&gt;[https://scholar.google.com/scholar?cites=16657205665212522456 Citations] in [[Google Scholar]].&lt;/ref&gt;
* {{citation
 | last1=Bondy | first1=John Adrian
 | last2=Murty | first2=U.S.R. | authorlink2=U. S. R. Murty
 | title=Graph Theory
 | year=2008
 | publisher=Springer
 | url=https://www.springer.com/mathematics/numbers/book/978-1-84628-969-9}}.
* {{citation
 | last1=Bondy | first1=John Adrian
 | title=Pancyclic graphs I
 | journal=Journal of Combinatorial Theory, Series B
 | volume=11
 | year=1971
 | pages=80–84
 | doi=10.1016/0095-8956(71)90016-5
 | issue=1
}}.&lt;ref&gt;[https://scholar.google.com/scholar?cites=2536094770406007806 Citations] in Google Scholar.&lt;/ref&gt;
* {{citation
 | last1=Bondy | first1=John Adrian
 | last2=Hemminger | first2=R. L.
 | title=Graph reconstruction – a survey
 | journal=Journal of Graph Theory
 | volume=1
 | year=1977
 | pages=227–268
 | doi=10.1002/jgt.3190010306
 | issue=3
}}.&lt;ref&gt;[https://scholar.google.com/scholar?cites=947869482351747685 Citations] in Google Scholar.&lt;/ref&gt;

==See also==
* [[Bondy's theorem]]
* [[Hamiltonian path]]
* [[Hypohamiltonian graph]]

==Notes==
{{reflist}}

==References==
* {{MathGenealogy|id=23492|title=J. Adrian (John) Bondy}}
* [http://www.ams.org/mathscinet/search/author.html?mrauthid=39150 MathSciNet: Bondy, John Adrian]{{dead link|date=November 2017 |bot=InternetArchiveBot |fix-attempted=yes }}
* [http://www.math.jussieu.fr/~jabondy/ Adrian Bondy's webpage]
* {{citation
 | journal=[[Journal of Combinatorial Theory, Series B]]
 | volume=90
 | year=2004
 | page=1
 | doi=10.1016/j.jctb.2003.10.001    
 | title=Dedication to Adrian Bondy and U.S.R. Murty
 | first1=Bill | last1=Cunningham
 | first2=Penny | last2=Haxell | author2-link = Penny Haxell
 | first3=Bruce | last3=Richter
 | first4=Nick | last4=Wormald | author4-link = Nick Wormald
 | first5=Andrew | last5=Thomason
 | issue=1
}}.

==External links==
* [https://web.archive.org/web/20120311101802/http://www.math.jussieu.fr/~jabondy/uw/letters/shallitgaz.html Critique of the dismissal] by [[Jeffrey Shallit]]

{{Authority control}}

{{DEFAULTSORT:Bondy, John Adrian}}
[[Category:Living people]]
[[Category:Graph theorists]]
[[Category:University of Waterloo faculty]]
[[Category:Alumni of the University of Oxford]]
[[Category:20th-century English mathematicians]]
[[Category:1944 births]]


{{mathematician-stub}}</text>
      <sha1>t189k16kcgq3equqij3fvqzny15i405</sha1>
    </revision>
  </page>
  <page>
    <title>K. S. Chandrasekharan</title>
    <ns>0</ns>
    <id>22907213</id>
    <revision>
      <id>849375618</id>
      <parentid>848206719</parentid>
      <timestamp>2018-07-08T15:12:03Z</timestamp>
      <contributor>
        <ip>117.204.5.173</ip>
      </contributor>
      <comment>/* Biography */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6647">{{EngvarB|date=July 2016}}
{{Use dmy dates|date=July 2016}}
{{multiple issues|
{{cleanup reorganise|date=June 2012}}
{{Refimprove|date=January 2010}}
}}
{{Infobox scientist
| name = Komaravolu Chandrasekhar
| image = Komaravolu Chandrasekharan MFO 1987.jpg
| birth_date = {{birth date|1920|11|21|df=yes}}
| birth_place = [[Bapatla]], [[Guntur District]], [[Madras Presidency]], [[British India]] (now [[Andhra Pradesh]], [[India]])
| death_date = {{death date and age|2017|4|13|1920|11|21|df=yes}}
| death_place = Zurich
|residence         = Zurich area
|citizenship       = Indian-Swiss
|ethnicity         = Asian
| occupation = Mathematician
| salary = 
| spouse = 
| field = [[Number theory]]
| work_institution = [[TIFR]], [[ETH Zurich]]
| alma_mater=[[Madras University]]
| doctoral_advisor = [[K. Ananda Rau]]
| doctoral_students = [[C. S. Seshadri]]&lt;br&gt;[[M. S. Narasimhan]]
| known_for  = Administrative intellect, Mathematics [Analytic Number Theory and Mathematical Analysis]
| prizes = Ramanujan Medal 1966, Padma Shri 1959, Shanti Swarup Bhatnagar award 1963, 
| website = 
}}

'''Komaravolu Chandrasekhar''' (21 November 1920 – 13 April 2017)&lt;ref name=TIFR&gt;
{{cite web |title=Some Famous Indian Scientists |url=http://www.tifr.res.in/~outreach/biographies/scientists.pdf |publisher=Tata Institute of Fundamental Research, Science Popularisation and Public Outreach Committee |location=Mumbai, India |page=12 |format=PDF |doi= |date=14 November 2004 |accessdate=26 May 2009 }}
&lt;/ref&gt;
was a professor at [[ETH Zurich]].&lt;ref&gt;[https://www.bi.id.ethz.ch/personensuche/detail.do?pid=17064&amp;lang=EN Komaravolu Chandrashekhar ]&lt;/ref&gt; and a founding faculty member of School of Mathematics, [[Tata Institute of Fundamental Research]] (TIFR). He is known for his work in [[number theory]] and [[summability]] and was given numerous awards including [[Padma Shri]], [[Shanti Swarup Bhatnagar Award]], [[Ramanujan]] Medal, and honorary fellow of TIFR. He was president of [[International Mathematical Union|the International Mathematical Union (IMU)]] from 1971 to 1974.

==Biography==
Chandrasekhar was born in 1920 to a school headmaster Sri Rajaiah  Padmakshamma(Mother).
Chandrasekhar completed his high school from Bapatla village in [[Guntur]] from [[Andhra Pradesh]]. He completed his M.A. in mathematics from the [[Presidency College, Chennai]] and a PhD from the Department of Mathematics, [[University of Madras]] in 1942, under the supervision of [[K. Ananda Rau]].

When Chandrasekhar was with the [[Institute for Advanced Study]], Princeton, US, [[Homi J. Bhabha|Homi Bhabha]] invited Chandrashekhar to join the School of Mathematics of the [[Tata Institute of Fundamental Research]] (TIFR). Chandrashekhar persuaded mathematicians from all over the world, to visit TIFR and deliver courses of lectures. They were [[L. Schwarz]], [[C. L. Siegel]] and many more. In 1965, Chandrasekhar, before the death of [[Homi J. Bhabha|Dr. Homi Bhabha]] in a plane crash, left the Tata Institute of Fundamental Research to join the [[ETH Zurich]],&lt;ref name=TIFR /&gt; where he retired in 1988.&lt;ref&gt;
{{cite web | title=Department of Mathematics Retired Faculty | url=http://www.math.ethz.ch/people/retired | publisher=Eidgenössische Technische Hochschule Zürich | date=  4 February 2005
 | accessdate=26 May 2009}}&lt;/ref&gt;&lt;ref&gt;
{{cite web | title=ETHistory Selbstständige Professuren | url=http://www.ethistory.ethz.ch/rueckblicke/departemente/dmath/weitere_seiten/2.2_selbstaendige_prof | publisher=Eidgenössische Technische Hochschule Zürich | year=2005 |language=German | accessdate=26 May 2009}}&lt;/ref&gt;

In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 10 November 2012.&lt;/ref&gt;

==Selected works==
*with [[Salomon Bochner]]: {{cite book|title=Fourier Transforms|publisher=Princeton University Press|year=1949}}&lt;ref&gt;{{cite journal|author=Segal, I. E.|authorlink=Irving Segal|title=Review: ''Fourier transforms'', by S. Bochner and K. Chandrasekharan|journal=Bull. Amer. Math. Soc.|year=1950|volume=56|issue=6|pages=526–528|url=http://www.ams.org/journals/bull/1950-56-06/S0002-9904-1950-09436-1/S0002-9904-1950-09436-1.pdf|doi=10.1090/s0002-9904-1950-09436-1}}&lt;/ref&gt;
*with S. Minakshisundaram: {{cite book|title=Typical means|publisher=Oxford University Press|year=1952}}&lt;ref&gt;{{cite journal|author=Kuttner, B.|authorlink=Brian Kuttner|title=Review: ''Typical means'', by K. Chandrasekharan and S. Minakshisundaram|journal=Bull. Amer. Math. Soc.|year=1954|volume=60|issue=1|pages=85–88|url=http://www.ams.org/journals/bull/1954-60-01/S0002-9904-1954-09760-4/S0002-9904-1954-09760-4.pdf|doi=10.1090/s0002-9904-1954-09760-4}}&lt;/ref&gt;
*{{cite book|title=Introduction to analytic number theory|publisher=Springer|year=1968}}&lt;ref name="StarkReview"&gt;{{cite journal|author=Stark, H. M.|authorlink=Harold Stark|title=Review: ''Introduction to analytic number theory'', by K. Chandrasekharan; ''Arithmetical functions'', by K. Chandrasekharan; ''Multiplicative number theory'', by Harold Davenport; ''Sequences'', by H. Halberstam and K. F. Roth''|journal=Bull. Amer. Math. Soc.|year=1971|volume=77|issue=6|pages=943–957|url=http://www.ams.org/journals/bull/1971-77-06/S0002-9904-1971-12812-4/S0002-9904-1971-12812-4.pdf|doi=10.1090/S0002-9904-1971-12812-4}}&lt;/ref&gt; reprinting 2012
*{{cite book|title=Arithmetical Functions|publisher=Springer|series=Grundlehren der Mathematischen Wissenschaften|year=1970}}&lt;ref name=StarkReview/&gt;
*{{cite book|title=Elliptic Functions|publisher=Springer|year=1985}}
*{{cite book|title=Classical Fourier transforms|publisher=Springer-Verlag|year=1989}}
*{{cite book|title=Course on topological groups|publisher=Hindustani Book Agency|year=2011}}

==Notes==
{{reflist}}

==References==
* [http://www.mapsofindia.com/who-is-who/science-technology/k-Chandrashekhar.html – India's who is who ]

==External links==
* {{MathGenealogy|id=79756}}

{{SSBPST recipients in Mathematical Science}}

{{Authority control}}

{{DEFAULTSORT:Chandrashekhar, Komaravolu S.}}
[[Category:20th-century Indian mathematicians]]
[[Category:Tamil scholars]]
[[Category:Recipients of the Padma Shri in literature &amp; education]]
[[Category:Indian number theorists]]
[[Category:Mathematical analysts]]
[[Category:ETH Zurich faculty]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:1920 births]]
[[Category:2017 deaths]]
[[Category:University of Madras alumni]]
[[Category:21st-century Indian mathematicians]]
[[Category:People from Guntur district]]
[[Category:Scientists from Andhra Pradesh]]</text>
      <sha1>hkonsiu3rsq1txqiqhh650f5ah3yews</sha1>
    </revision>
  </page>
  <page>
    <title>Karhunen–Loève theorem</title>
    <ns>0</ns>
    <id>767253</id>
    <revision>
      <id>857512065</id>
      <parentid>857512000</parentid>
      <timestamp>2018-09-01T03:45:37Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>/* Signal detection  in white noise */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="47897">In the theory of [[stochastic process]]es, the '''Karhunen–Loève theorem'''  (named after [[Kari Karhunen]] and [[Michel Loève]]), also known as the '''Kosambi–Karhunen–Loève theorem'''&lt;ref name="sapatnekar"&gt;{{Citation |last=Sapatnekar |first=Sachin |title= Overcoming variations in nanometer-scale technologies|journal= IEEE Journal on Emerging and Selected Topics in Circuits and Systems|volume= 1|year= 2011 |issue= 1|pages= 5–18 |doi=10.1109/jetcas.2011.2138250|bibcode=2011IJEST...1....5S}}&lt;/ref&gt;&lt;ref name="ghoman"&gt;{{Citation |last=Ghoman |first=Satyajit |last2= Wang|first2= Zhicun|last3=Chen |first3=PC |last4=Kapania|first4=Rakesh|title= A POD-based Reduced Order Design Scheme for Shape Optimization of Air Vehicles|booktitle=Proc of 53rd AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference, AIAA-2012-1808, Honolulu, Hawaii |year=2012 }}&lt;/ref&gt; is a representation of a stochastic process as an infinite linear combination of [[orthogonal function]]s, analogous to a [[Fourier series]] representation of a function on a bounded interval. The transformation is also known as Hotelling transform and eigenvector transform, and is closely related to [[principal component analysis]] (PCA) technique widely used in image processing and in data analysis in many fields.&lt;ref&gt;[http://fourier.eng.hmc.edu/e161/lectures/klt/node3.html Karhunen–Loeve transform (KLT)], Computer Image Processing and Analysis (E161) lectures, Harvey Mudd College&lt;/ref&gt;

Stochastic processes given by infinite series of this form were first considered by [[Damodar Dharmananda Kosambi]].&lt;ref name="Raju"&gt;{{Citation |first=C.K. |last=Raju |title=Kosambi the Mathematician |journal=Economic and Political Weekly |volume=44 |year=2009 |issue=20 |pages=33–45 }}&lt;/ref&gt;&lt;ref name="Kosambi"&gt;{{Citation |first=D. D. |last=Kosambi |title=Statistics in Function Space |journal=Journal of the Indian Mathematical Society |volume=7 |year=1943 |issue= |pages=76–88 |mr=9816 }}.&lt;/ref&gt;  There exist many such expansions of a stochastic process: if the process is indexed over {{math|[''a'', ''b'']}}, any [[orthonormal basis]] of {{math|''L''&lt;sup&gt;2&lt;/sup&gt;([''a'', ''b''])}} yields an expansion thereof in that form. The importance of the Karhunen–Loève theorem is that it yields the best such basis in the sense that it minimizes the total [[mean squared error]].
 
In contrast to a Fourier series where the coefficients are fixed numbers and the expansion basis consists of [[trigonometric function|sinusoidal functions]] (that is, [[sine]] and [[cosine]] functions), the coefficients in the Karhunen–Loève theorem are [[random variable]]s and the expansion basis depends on the process. In fact, the orthogonal basis functions used in this representation are determined by the [[covariance function]] of the process. One can think that the [[Karhunen–Loève transform]] adapts to the process in order to produce the best possible basis for its expansion.

In the case of a ''centered'' stochastic process {{math|{''X&lt;sub&gt;t&lt;/sub&gt;''}&lt;sub&gt;''t'' ∈ [''a'', ''b'']&lt;/sub&gt;}} (''centered'' means {{math|'''E'''[''X&lt;sub&gt;t&lt;/sub&gt;''] {{=}} 0}} for all {{math|''t'' ∈ [''a'', ''b'']}}) satisfying a technical continuity condition, {{mvar|X&lt;sub&gt;t&lt;/sub&gt;}} admits a decomposition

:&lt;math&gt; X_t = \sum_{k=1}^\infty Z_k e_k(t)&lt;/math&gt;

where {{mvar|Z&lt;sub&gt;k&lt;/sub&gt;}} are pairwise [[uncorrelated]] random variables and the functions {{mvar|e&lt;sub&gt;k&lt;/sub&gt;}} are continuous real-valued functions on {{math|[''a'', ''b'']}} that are pairwise [[orthogonal function|orthogonal]] in {{math|''L''&lt;sup&gt;2&lt;/sup&gt;([''a'', ''b''])}}. It is therefore sometimes said that the expansion is ''bi-orthogonal'' since the random coefficients {{mvar|Z&lt;sub&gt;k&lt;/sub&gt;}} are orthogonal in the probability space while the deterministic functions {{mvar|e&lt;sub&gt;k&lt;/sub&gt;}} are orthogonal in the time domain. The general case of a process {{mvar|X&lt;sub&gt;t&lt;/sub&gt;}} that is not centered can be brought back to the case of a centered process by considering {{math|''X&lt;sub&gt;t&lt;/sub&gt;'' − '''E'''[''X&lt;sub&gt;t&lt;/sub&gt;'']}} which is a centered process.

Moreover, if the process is [[Gaussian process|Gaussian]], then the random variables {{mvar|Z&lt;sub&gt;k&lt;/sub&gt;}} are Gaussian and [[stochastically independent]]. This result generalizes the ''Karhunen–Loève transform''. An important example of a centered real stochastic process on {{math|[0, 1]}} is the [[Wiener process]]; the Karhunen–Loève theorem can be used to provide a canonical orthogonal representation for it. In this case the expansion consists of sinusoidal functions.

The above expansion into uncorrelated random variables is also known as the ''Karhunen–Loève expansion'' or ''Karhunen–Loève decomposition''. The [[statistic|empirical]] version (i.e., with the coefficients computed from a sample) is known as the ''Karhunen–Loève transform'' (KLT), ''[[principal component analysis]]'', ''proper orthogonal decomposition (POD)'', ''[[empirical orthogonal functions]]'' (a term used in [[meteorology]] and [[geophysics]]), or the ''[[Harold Hotelling|Hotelling]] transform''.

== Formulation ==
*Throughout this article, we will consider a square-integrable zero-mean random process {{mvar|X&lt;sub&gt;t&lt;/sub&gt;}} defined over a [[probability space]] {{math|(Ω, ''F'', '''P''')}} and indexed over a closed interval {{math|[''a'', ''b'']}}, with covariance function {{math|''K&lt;sub&gt;X&lt;/sub&gt;''(''s'', ''t'')}}. We thus have: 
::&lt;math&gt;\forall t\in [a,b] \qquad X_t\in L^2(\Omega, F,\mathbf{P}),&lt;/math&gt;
::&lt;math&gt;\forall t\in [a,b] \qquad \mathbf{E}[X_t]=0,&lt;/math&gt;
::&lt;math&gt;\forall t,s \in [a,b] \qquad  K_X(s,t)=\mathbf{E}[X_s X_t].&lt;/math&gt;

*We associate to ''K''&lt;sub&gt;''X''&lt;/sub&gt; a [[linear operator]] ''T''&lt;sub&gt;''K''&lt;sub&gt;''X''&lt;/sub&gt;&lt;/sub&gt; defined in the following way:
::&lt;math&gt;
T_{K_X}: L^2([a,b]) \to  L^2([a,b]): f \mapsto T_{K_X}f = \int_a^b K_X(s,\cdot) f(s) \, ds
&lt;/math&gt;
:Since ''T''&lt;sub&gt;''K''&lt;sub&gt;''X''&lt;/sub&gt;&lt;/sub&gt; is a linear operator, it makes sense to talk about its eigenvalues ''λ&lt;sub&gt;k&lt;/sub&gt;'' and eigenfunctions ''e''&lt;sub&gt;''k''&lt;/sub&gt;, which are found solving the homogeneous Fredholm [[integral equation]] of the second kind 
::&lt;math&gt;\int_a^b K_X(s,t) e_k(s)\,ds=\lambda_k e_k(t)&lt;/math&gt;

== Statement of the theorem ==
'''Theorem'''. Let {{mvar|X&lt;sub&gt;t&lt;/sub&gt;}} be a zero-mean square-integrable stochastic process defined over a probability space {{math|(Ω, ''F'', '''P''')}} and indexed over a closed and bounded interval [''a'',&amp;nbsp;''b''], with continuous covariance function ''K''&lt;sub&gt;''X''&lt;/sub&gt;(''s'', ''t'').

Then ''K''&lt;sub&gt;''X''&lt;/sub&gt;(''s,t'') is a [[Mercer's theorem|Mercer kernel]] and letting ''e''&lt;sub&gt;''k''&lt;/sub&gt; be an orthonormal basis on {{math|''L''&lt;sup&gt;2&lt;/sup&gt;([''a'', ''b''])}} formed by the eigenfunctions of ''T''&lt;sub&gt;''K''&lt;sub&gt;''X''&lt;/sub&gt;&lt;/sub&gt; with respective eigenvalues {{mvar|λ&lt;sub&gt;k&lt;/sub&gt;, X&lt;sub&gt;t&lt;/sub&gt;}} admits the following representation

:&lt;math&gt;X_t=\sum_{k=1}^\infty Z_k e_k(t)&lt;/math&gt;

where the convergence is in [[Convergence of random variables#Convergence in mean|''L''&lt;sup&gt;2&lt;/sup&gt;]], uniform in ''t'' and

:&lt;math&gt;Z_k=\int_a^b X_t e_k(t)\, dt&lt;/math&gt;

Furthermore, the random variables ''Z''&lt;sub&gt;''k''&lt;/sub&gt; have zero-mean, are uncorrelated and have variance ''λ&lt;sub&gt;k&lt;/sub&gt;''

:&lt;math&gt;\mathbf{E}[Z_k]=0,~\forall k\in\mathbb{N} \qquad \mbox{and}\qquad \mathbf{E}[Z_i Z_j]=\delta_{ij} \lambda_j,~\forall i,j\in \mathbb{N}&lt;/math&gt;

Note that by generalizations of Mercer's theorem we can replace the interval [''a'', ''b''] with other compact spaces ''C'' and the Lebesgue measure on [''a'', ''b''] with a Borel measure whose support is ''C''.

==Proof==
*The covariance function ''K''&lt;sub&gt;''X''&lt;/sub&gt; satisfies the definition of a Mercer kernel. By [[Mercer's theorem]], there consequently exists a set {''λ&lt;sub&gt;k&lt;/sub&gt;'', ''e&lt;sub&gt;k&lt;/sub&gt;''(''t'')} of eigenvalues and eigenfunctions of T&lt;sub&gt;''K''&lt;sub&gt;''X''&lt;/sub&gt;&lt;/sub&gt; forming an orthonormal basis of ''L''&lt;sup&gt;2&lt;/sup&gt;([''a'',''b'']), and ''K''&lt;sub&gt;''X''&lt;/sub&gt; can be expressed as
::&lt;math&gt;K_X(s,t)=\sum_{k=1}^\infty \lambda_k e_k(s) e_k(t) &lt;/math&gt;

*The process ''X''&lt;sub&gt;''t''&lt;/sub&gt; can be expanded in terms of the eigenfunctions ''e''&lt;sub&gt;''k''&lt;/sub&gt; as:
::&lt;math&gt;X_t=\sum_{k=1}^\infty Z_k e_k(t)&lt;/math&gt;
:where the coefficients (random variables) ''Z''&lt;sub&gt;''k''&lt;/sub&gt; are given by the projection of ''X''&lt;sub&gt;''t''&lt;/sub&gt; on the respective eigenfunctions
::&lt;math&gt;Z_k=\int_a^b X_t e_k(t) \,dt&lt;/math&gt;

*We may then derive
::&lt;math&gt;\begin{align}
\mathbf{E}[Z_k] &amp;=\mathbf{E}\left[\int_a^b X_t e_k(t) \,dt\right]=\int_a^b \mathbf{E}[X_t] e_k(t) dt=0 \\ [8pt]
\mathbf{E}[Z_i Z_j]&amp;=\mathbf{E}\left[ \int_a^b \int_a^b X_t  X_s e_j(t)e_i(s)\, dt\, ds\right]\\
&amp;=\int_a^b \int_a^b \mathbf{E}\left[X_t  X_s\right] e_j(t)e_i(s) \, dt\, ds\\
&amp;=\int_a^b \int_a^b  K_X(s,t) e_j(t)e_i(s) \,dt \, ds\\
&amp;=\int_a^b e_i(s)\left(\int_a^b  K_X(s,t) e_j(t) \,dt\right) \, ds\\
&amp;=\lambda_j \int_a^b e_i(s) e_j(s) \, ds\\
&amp;=\delta_{ij}\lambda_j
\end{align}&lt;/math&gt;
:where we have used the fact that the ''e''&lt;sub&gt;''k''&lt;/sub&gt; are eigenfunctions of ''T''&lt;sub&gt;''K''&lt;sub&gt;''X''&lt;/sub&gt;&lt;/sub&gt; and are orthonormal.

*Let us now show that the convergence is in ''L''&lt;sup&gt;2&lt;/sup&gt;. Let 
::&lt;math&gt;S_N=\sum_{k=1}^N Z_k e_k(t).&lt;/math&gt;
:Then:
::&lt;math&gt;\begin{align}
\mathbf{E} \left [\left |X_t-S_N \right |^2 \right ]&amp;=\mathbf{E} \left [X_t^2 \right ]+\mathbf{E} \left [S_N^2 \right ] - 2\mathbf{E} \left [X_t S_N \right ]\\
&amp;=K_X(t,t)+\mathbf{E}\left[\sum_{k=1}^N \sum_{l=1}^N Z_k Z_\ell e_k(t)e_\ell(t) \right] -2\mathbf{E}\left[X_t\sum_{k=1}^N Z_k e_k(t)\right]\\
&amp;=K_X(t,t)+\sum_{k=1}^N \lambda_k e_k(t)^2 -2\mathbf{E}\left[\sum_{k=1}^N \int_a^b X_t X_s e_k(s) e_k(t) \,ds \right]\\
&amp;=K_X(t,t)-\sum_{k=1}^N \lambda_k e_k(t)^2
\end{align}&lt;/math&gt;
:which goes to 0 by Mercer's theorem.

== Properties of the Karhunen–Loève transform ==

=== Special case: Gaussian distribution ===
Since the limit in the mean of jointly Gaussian random variables is jointly Gaussian, and jointly Gaussian random (centered) variables are independent if and only if they are orthogonal, we can also conclude:

'''Theorem'''.  The variables {{mvar|Z&lt;sub&gt;i&lt;/sub&gt;}} have a joint Gaussian distribution and are stochastically independent if the original process {{math|{''X&lt;sub&gt;t&lt;/sub&gt;''}&lt;sub&gt;''t''&lt;/sub&gt;}} is Gaussian.

In the Gaussian case, since the variables {{mvar|Z&lt;sub&gt;i&lt;/sub&gt;}} are independent, we can say more:

:&lt;math&gt; \lim_{N \to \infty} \sum_{i=1}^N e_i(t) Z_i(\omega) = X_t(\omega) &lt;/math&gt;
almost surely.

=== The Karhunen–Loève transform decorrelates the process ===
This is a consequence of the independence of the {{mvar|Z&lt;sub&gt;k&lt;/sub&gt;}}.

=== The Karhunen–Loève expansion minimizes the total mean square error ===
In the introduction, we mentioned that the truncated Karhunen–Loeve expansion was the best approximation of the original process in the sense that it reduces the total mean-square error resulting of its truncation. Because of this property, it is often said that the KL transform optimally compacts the energy.

More specifically, given any orthonormal basis {''f''&lt;sub&gt;''k''&lt;/sub&gt;} of ''L''&lt;sup&gt;2&lt;/sup&gt;([''a'', ''b'']), we may decompose the process ''X&lt;sub&gt;t&lt;/sub&gt;'' as:

:&lt;math&gt;X_t(\omega)=\sum_{k=1}^\infty A_k(\omega) f_k(t)&lt;/math&gt;

where

:&lt;math&gt;A_k(\omega)=\int_a^b X_t(\omega) f_k(t)\,dt&lt;/math&gt;

and we may approximate ''X''&lt;sub&gt;''t''&lt;/sub&gt; by the finite sum

:&lt;math&gt;\hat{X}_t(\omega)=\sum_{k=1}^N A_k(\omega) f_k(t)&lt;/math&gt;

for some integer ''N''.

'''Claim'''. Of all such approximations, the KL approximation is the one that minimizes the total mean square error (provided we have arranged the eigenvalues in decreasing order).

&lt;div class="NavFrame collapsed"&gt;
  &lt;div class="NavHead"&gt;[Proof]&lt;/div&gt;
  &lt;div class="NavContent" style="text-align:left"&gt;
Consider the error resulting from the truncation at the ''N''-th term in the following orthonormal expansion:
:&lt;math&gt;\varepsilon_N(t)=\sum_{k=N+1}^\infty A_k(\omega) f_k(t)&lt;/math&gt;
The mean-square error ''ε''&lt;sub&gt;''N''&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;(''t'') can be written as:

:&lt;math&gt;\begin{align}
\varepsilon_N^2(t)&amp;=\mathbf{E} \left[\sum_{i=N+1}^\infty \sum_{j=N+1}^\infty A_i(\omega) A_j(\omega) f_i(t) f_j(t)\right]\\
&amp;=\sum_{i=N+1}^\infty \sum_{j=N+1}^\infty \mathbf{E}\left[\int_a^b \int_a^b X_t X_s f_i(t)f_j(s) \, ds\, dt\right] f_i(t) f_j(t)\\
&amp;=\sum_{i=N+1}^\infty \sum_{j=N+1}^\infty f_i(t) f_j(t) \int_a^b \int_a^b K_X(s,t) f_i(t)f_j(s) \, ds\, dt
\end{align}&lt;/math&gt;

We then integrate this last equality over [''a'', ''b'']. The orthonormality of the ''f&lt;sub&gt;k&lt;/sub&gt;'' yields:

:&lt;math&gt;\int_a^b \varepsilon_N^2(t) \, dt=\sum_{k=N+1}^\infty \int_a^b \int_a^b K_X(s,t) f_k(t)f_k(s) \, ds\, dt&lt;/math&gt;

The problem of minimizing the total mean-square error thus comes down to minimizing the right hand side of this equality subject to the constraint that the ''f''&lt;sub&gt;''k''&lt;/sub&gt; be normalized. We hence introduce {{mvar|β&lt;sub&gt;k&lt;/sub&gt;}}, the Lagrangian multipliers associated with these constraints, and aim at minimizing the following function:

:&lt;math&gt;Er[f_k(t),k\in\{N+1,\ldots\}]=\sum_{k=N+1}^\infty \int_a^b \int_a^b K_X(s,t) f_k(t)f_k(s) \, ds \, dt-\beta_k \left(\int_a^b f_k(t) f_k(t) \, dt -1\right)&lt;/math&gt;

Differentiating with respect to ''f''&lt;sub&gt;''i''&lt;/sub&gt;(''t'') (this is a [[functional derivative]]) and setting the derivative to 0 yields:

:&lt;math&gt;\frac{\partial Er}{\partial f_i(t)}=\int_a^b \left(\int_a^b K_X(s,t) f_i(s) \, ds -\beta_i f_i(t) \right) \, dt = 0&lt;/math&gt;

which is satisfied in particular when

:&lt;math&gt;\int_a^b K_X(s,t) f_i(s) \,ds =\beta_i f_i(t).&lt;/math&gt;

In other words, when the ''f''&lt;sub&gt;''k''&lt;/sub&gt; are chosen to be the eigenfunctions of ''T''&lt;sub&gt;''K''&lt;sub&gt;''X''&lt;/sub&gt;&lt;/sub&gt;, hence resulting in the KL expansion.
  &lt;/div&gt;
&lt;/div&gt;

=== Explained variance ===
An important observation is that since the random coefficients ''Z''&lt;sub&gt;''k''&lt;/sub&gt; of the KL expansion are uncorrelated, the [[Variance#Sum of uncorrelated variables .28Bienaym.C3.A9 formula.29|Bienaymé formula]] asserts that the variance of ''X''&lt;sub&gt;''t''&lt;/sub&gt; is simply the sum of the variances of the individual components of the sum:

:&lt;math&gt;\operatorname{var}[X_t]=\sum_{k=0}^\infty e_k(t)^2 \operatorname{var}[Z_k]=\sum_{k=1}^\infty \lambda_k e_k(t)^2&lt;/math&gt;

Integrating over [''a'', ''b''] and using the orthonormality of the ''e''&lt;sub&gt;''k''&lt;/sub&gt;, we obtain that the total variance of the process is:

:&lt;math&gt;\int_a^b \operatorname{var}[X_t] \, dt=\sum_{k=1}^\infty \lambda_k&lt;/math&gt;

In particular, the total variance of the ''N''-truncated approximation is

:&lt;math&gt;\sum_{k=1}^N \lambda_k.&lt;/math&gt;

As a result, the ''N''-truncated expansion explains

:&lt;math&gt;\frac{\sum_{k=1}^N \lambda_k}{\sum_{k=1}^\infty \lambda_k}&lt;/math&gt;

of the variance; and if we are content with an approximation that explains, say, 95% of the variance, then we just have to determine an &lt;math&gt;N\in\mathbb{N}&lt;/math&gt; such that

:&lt;math&gt;\frac{\sum_{k=1}^N \lambda_k}{\sum_{k=1}^\infty \lambda_k} \geq 0.95.&lt;/math&gt;

=== The Karhunen–Loève expansion has the minimum representation entropy property ===
Given a representation of &lt;math&gt;X_t=\sum_{k=1}^\infty W_k\varphi_k(t)&lt;/math&gt;, for some orthonormal basis &lt;math&gt;\varphi_k(t)&lt;/math&gt; and random &lt;math&gt;W_k&lt;/math&gt;, we let &lt;math&gt;p_k=\mathbb{E}[|W_k|^2]/\mathbb{E}[|X_t|_{L^2}^2]&lt;/math&gt;, so that &lt;math&gt;\sum_{k=1}^\infty p_k=1&lt;/math&gt;. We may then define the representation [[Entropy (information theory)|entropy]] to be &lt;math&gt;H(\{\varphi_k\})=\sum_i p_k \log(p_k)&lt;/math&gt;. Then we have &lt;math&gt;H(\{\varphi_k\})\ge H(\{e_k\})&lt;/math&gt;, for all choices of &lt;math&gt;\varphi_k&lt;/math&gt;. That is, the KL-expansion has minimal representation entropy.

'''Proof:'''

Denote the coefficients obtained for the basis &lt;math&gt;e_k(t)&lt;/math&gt; as &lt;math&gt;p_k&lt;/math&gt;, and for &lt;math&gt;\varphi_k(t)&lt;/math&gt; as &lt;math&gt;q_k&lt;/math&gt;.

Choose &lt;math&gt;N\ge 1&lt;/math&gt;. Note that since &lt;math&gt;e_k&lt;/math&gt; minimizes the mean squared error, we have that

: &lt;math&gt;\mathbb{E} \left|\sum_{k=1}^N Z_ke_k(t)-X_t\right|_{L^2}^2\le \mathbb{E}\left|\sum_{k=1}^N W_k\varphi_k(t)-X_t\right|_{L^2}^2&lt;/math&gt; 

Expanding the right hand size, we get:

: &lt;math&gt;\mathbb{E}\left|\sum_{k=1}^N W_k\varphi_k(t)-X_t\right|_{L^2}^2 =\mathbb{E}|X_t^2|_{L^2} + \sum_{k=1}^N \sum_{\ell=1}^N \mathbb{E}[W_\ell \varphi_\ell(t)W_k^*\varphi_k^*(t)]_{L^2}-\sum_{k=1}^N \mathbb{E}[W_k \varphi_k X_t^*]_{L^2} - \sum_{k=1}^N \mathbb{E}[X_tW_k^*\varphi_k^*(t)]_{L^2}&lt;/math&gt;

Using the orthonormality of &lt;math&gt;\varphi_k(t)&lt;/math&gt;, and expanding &lt;math&gt;X_t&lt;/math&gt; in the &lt;math&gt;\varphi_k(t)&lt;/math&gt; basis, we get that the right hand size is equal to:

: &lt;math&gt;\mathbb{E}[X_t]^2_{L^2}-\sum_{k=1}^N\mathbb{E}[|W_k|^2]&lt;/math&gt;

We may perform indentitcal analysis for the &lt;math&gt;e_k(t)&lt;/math&gt;, and so rewrite the above inequality as:

: &lt;math&gt;{\displaystyle \mathbb {E} [X_t]_{L^2}^2-\sum _{k=1}^N\mathbb {E} [|Z_k|^2]}\le {\displaystyle \mathbb {E} [X_t]_{L^2}^2-\sum _{k=1}^N\mathbb {E} [|W_k|^{2}]}  &lt;/math&gt;

Subtracting the common first term, and dividing by &lt;math&gt;\mathbb{E}[|X_t|^2_{L^2}]&lt;/math&gt;, we obtain that:

: &lt;math&gt;\sum_{k=1}^N p_k\le \sum_{k=1}^N q_k&lt;/math&gt;

This implies that:

: &lt;math&gt;-\sum_{k=1}^\infty p_k \log(p_k)\le -\sum_{k=1}^\infty q_k \log(q_k)&lt;/math&gt;

== Linear Karhunen–Loève approximations ==
Let us consider a whole class of signals we want to approximate over the first {{mvar|M}} vectors of a basis. These signals are modeled as realizations of a random vector {{math|''Y''[''n'']}} of size {{mvar|N}}. To optimize the approximation we design a basis that minimizes the average approximation error. This section proves that optimal bases are Karhunen–Loeve bases that diagonalize the covariance matrix of {{mvar|Y}}. The random vector {{mvar|Y}} can be decomposed in an orthogonal basis

:&lt;math&gt;\left\{ g_m \right\}_{0\le m\le N}&lt;/math&gt;

as follows:

:&lt;math&gt;Y=\sum_{m=0}^{N-1} \left\langle Y, g_m \right\rangle g_m,&lt;/math&gt;

where each

:&lt;math&gt;\left\langle Y, g_m \right\rangle =\sum_{n=0}^{N-1}{Y[n]} g_m^* [n]&lt;/math&gt;

is a random variable. The approximation from the first {{math|''M'' ≤ ''N''}} vectors of the basis is 
 
:&lt;math&gt;Y_M=\sum_{m=0}^{M-1} \left\langle Y, g_m \right\rangle g_m&lt;/math&gt;

The energy conservation in an orthogonal basis implies

:&lt;math&gt;\varepsilon[M]= \mathbf{E} \left\{ \left\| Y- Y_M \right\|^2 \right\} =\sum_{m=M}^{N-1} \mathbf{E}\left\{ \left| \left\langle Y, g_m \right\rangle  \right|^2 \right\}&lt;/math&gt;

This error is related to the covariance of {{mvar|Y}} defined by
  
:&lt;math&gt;R[ n,m]=\mathbf{E} \left\{ Y[n] Y^*[m] \right\}&lt;/math&gt;

For any vector {{math|''x''[''n'']}} we denote by {{mvar|K}} the covariance operator represented by this matrix,

:&lt;math&gt;\mathbf{E}\left\{\left|\langle Y,x \rangle\right|^2\right\}=\langle Kx,x \rangle =\sum_{n=0}^{N-1} \sum_{m=0}^{N-1} R[n,m]x[n]x^*[m]&lt;/math&gt;

The error {{math|''ε''[''M'']}} is therefore a sum of the last {{math|''N'' − ''M''}} coefficients of the covariance operator

:&lt;math&gt;\varepsilon [M]=\sum_{m=M}^{N-1}{\left\langle K g_m, g_m \right\rangle }&lt;/math&gt;

The covariance operator {{mvar|K}} is Hermitian and Positive and is thus diagonalized in an orthogonal basis called a Karhunen–Loève basis. The following theorem states that a Karhunen–Loève basis is optimal for linear approximations.

'''Theorem (Optimality of Karhunen–Loève basis).''' Let {{mvar|K}} be a covariance operator. For all {{math|''M'' ≥ 1}}, the approximation error

:&lt;math&gt;\varepsilon [M]=\sum_{m=M}^{N-1}\left\langle K g_m, g_m \right\rangle&lt;/math&gt;

is minimum if and only if

:&lt;math&gt;\left\{ g_m \right\}_{0\le m&lt;N}&lt;/math&gt;

is a Karhunen–Loeve basis ordered by decreasing eigenvalues.

:&lt;math&gt;\left\langle K g_m, g_m \right\rangle \ge \left\langle Kg_{m+1}, g_{m+1} \right\rangle, \qquad 0\le m&lt;N-1.&lt;/math&gt;

== Non-Linear approximation in bases ==
Linear approximations project the signal on ''M'' vectors a priori. The approximation can be made more precise by choosing the ''M'' orthogonal vectors depending on the signal properties. This section analyzes the general performance of these non-linear approximations. A signal &lt;math&gt;f\in \Eta &lt;/math&gt; is approximated with M vectors selected adaptively in an orthonormal basis for &lt;math&gt;\Eta &lt;/math&gt;

:&lt;math&gt;\Beta =\left\{ g_m \right\}_{m\in \mathbb{N}}&lt;/math&gt;

Let &lt;math&gt;f_M&lt;/math&gt; be the projection of f over M vectors whose indices are in {{mvar|I&lt;sub&gt;M&lt;/sub&gt;}}:

:&lt;math&gt;f_M=\sum_{m\in I_M} \left\langle f, g_m \right\rangle g_m&lt;/math&gt;

The approximation error is the sum of the remaining coefficients

:&lt;math&gt;\varepsilon [M]=\left\{ \left\| f- f_M \right\|^2 \right\}=\sum_{m\notin I_M}^{N-1} \left\{ \left| \left\langle f, g_m \right\rangle  \right|^2 \right\}&lt;/math&gt;

To minimize this error, the indices in {{mvar|I&lt;sub&gt;M&lt;/sub&gt;}} must correspond to the M vectors having the largest inner product amplitude

:&lt;math&gt;\left| \left\langle f, g_m \right\rangle  \right|.&lt;/math&gt;

These are the vectors that best correlate f. They can thus be interpreted as the main features of f. The resulting error is necessarily smaller than the error of a linear approximation which selects the M approximation vectors independently of f. Let us sort

:&lt;math&gt;\left\{ \left| \left\langle f, g_m \right\rangle  \right| \right\}_{m\in \mathbb{N}}&lt;/math&gt;

in decreasing order

:&lt;math&gt;\left| \left \langle f, g_{m_k} \right \rangle \right|\ge \left| \left \langle f, g_{m_{k+1}} \right \rangle  \right|.&lt;/math&gt;

The best non-linear approximation is

:&lt;math&gt;f_M=\sum_{k=1}^M \left\langle f, g_{m_k} \right\rangle g_{m_k}&lt;/math&gt;

It can also be written as inner product thresholding:

:&lt;math&gt;f_M=\sum_{m=0}^\infty \theta_T \left( \left\langle f, g_m \right\rangle  \right) g_m&lt;/math&gt;

with

:&lt;math&gt;T=\left|\left\langle f, g_{m_M} \right \rangle\right|, \qquad \theta_T(x)= \begin{cases} x &amp; |x|\ge T \\ 0 &amp; |x| &lt; T \end{cases}&lt;/math&gt;

The non-linear error is

:&lt;math&gt;\varepsilon [M]=\left\{ \left\| f- f_M \right\|^2 \right\}=\sum_{k=M+1}^{\infty} \left\{ \left| \left\langle f, g_{m_k} \right\rangle  \right|^2 \right\}&lt;/math&gt;

this error goes quickly to zero as M increases, if the sorted values of &lt;math&gt;\left| \left\langle f, g_{m_k} \right\rangle  \right|&lt;/math&gt; have a fast decay as k increases. This decay is quantified by computing the &lt;math&gt;\Iota^\Rho&lt;/math&gt; norm of the signal inner products in B:

:&lt;math&gt;\| f \|_{\Beta, p} =\left( \sum_{m=0}^\infty \left| \left\langle f, g_m \right\rangle  \right|^p \right)^{\frac{1}{p}}&lt;/math&gt;

The following theorem relates the decay of {{math|''ε''[''M'']}} to &lt;math&gt;\| f\|_{\Beta, p}&lt;/math&gt;

'''Theorem (decay of error).'''  If &lt;math&gt;\| f\|_{\Beta ,p}&lt;\infty &lt;/math&gt; with {{math|''p'' &lt; 2}} then

:&lt;math&gt;\varepsilon [M]\le \frac{\|f\|_{\Beta ,p}^2}{\frac{2}{p}-1} M^{1-\frac{2}{p}}&lt;/math&gt;
and
:&lt;math&gt;\varepsilon [M]=o\left( M^{1-\frac{2}{p}} \right).&lt;/math&gt;
Conversely, if &lt;math&gt;\varepsilon [M]=o\left( M^{1-\frac{2}{p}} \right)&lt;/math&gt; then

&lt;math&gt;\| f\|_{\Beta ,q}&lt;\infty &lt;/math&gt; for any {{math|''q'' &gt; ''p''}}.

=== Non-optimality of Karhunen–Loève bases ===
To further illustrate the differences between linear and non-linear approximations, we study the decomposition of a simple non-Gaussian random vector in a Karhunen–Loève basis. Processes whose realizations have a random translation are stationary. The Karhunen–Loève basis is then a Fourier basis and we study its performance. To simplify the analysis, consider a random vector ''Y''[''n''] of size ''N'' that is random shift modulo ''N'' of a deterministic signal ''f''[''n''] of zero mean

:&lt;math&gt;\sum_{n=0}^{N-1}f[n]=0&lt;/math&gt;
:&lt;math&gt;Y[n]=f [ (n-p)\bmod N ]&lt;/math&gt;

The random shift ''P'' is uniformly distributed on [0,&amp;nbsp;''N''&amp;nbsp;−&amp;nbsp;1]:

:&lt;math&gt;\Pr ( P=p )=\frac{1}{N}, \qquad 0\le p&lt;N&lt;/math&gt;

Clearly

:&lt;math&gt;\mathbf{E}\{Y[n]\}=\frac{1}{N} \sum_{p=0}^{N-1} f[(n-p)\bmod N]=0&lt;/math&gt;

and

:&lt;math&gt;R[n,k]=\mathbf{E} \{Y[n]Y[k] \}=\frac{1}{N}\sum_{p=0}^{N-1} f[(n-p)\bmod N] f [(k-p)\bmod N ] = \frac{1}{N} f\Theta \bar{f}[n-k], \quad \bar{f}[n]=f[-n]&lt;/math&gt;

Hence

:&lt;math&gt;R[n,k]=R_Y[n-k], \qquad R_Y[k]=\frac{1}{N}f \Theta \bar{f}[k]&lt;/math&gt;

Since R&lt;sub&gt;Y&lt;/sub&gt; is N periodic, Y is a circular stationary random vector. The covariance operator is a circular convolution with R&lt;sub&gt;Y&lt;/sub&gt; and is therefore diagonalized in the discrete Fourier Karhunen–Loève basis

:&lt;math&gt;\left\{ \frac{1}{\sqrt{N}} e^{i2\pi mn/N} \right\}_{0\le m&lt;N}.&lt;/math&gt;

The power spectrum is Fourier transform of ''R''&lt;sub&gt;''Y''&lt;/sub&gt;:

:&lt;math&gt;P_Y[m]=\hat{R}_Y[m]=\frac{1}{N} \left| \hat{f}[m] \right|^2&lt;/math&gt;

'''Example:'''  Consider an extreme case where &lt;math&gt;f[n]=\delta [n]-\delta [n-1]&lt;/math&gt;. A theorem stated above guarantees that the Fourier Karhunen–Loève basis produces a smaller expected approximation error than a canonical basis of Diracs &lt;math&gt;\left\{g_m[n]=\delta[n-m] \right\}_{0\le m&lt;N}&lt;/math&gt;. Indeed, we do not know a priori the abscissa of the non-zero coefficients of ''Y'', so there is no particular Dirac that is better adapted to perform the approximation. But the Fourier vectors cover the whole support of Y and thus absorb a part of the signal energy.

:&lt;math&gt;\mathbf{E} \left\{ \left| \left\langle Y[n],\frac{1}{\sqrt{N}} e^{i2\pi mn/N} \right\rangle  \right|^2 \right\}=P_Y[m] = \frac{4}{N}\sin^2 \left(\frac{\pi k}{N} \right)&lt;/math&gt;
 
Selecting higher frequency Fourier coefficients yields a better mean-square approximation than choosing a priori a few Dirac vectors to perform the approximation. The situation is totally different for non-linear approximations. If &lt;math&gt;f[n]=\delta[n]-\delta[n-1]&lt;/math&gt; then the discrete Fourier basis is extremely inefficient because f and hence Y have an energy that is almost uniformly spread among all Fourier vectors. In contrast, since f has only two non-zero coefficients in the Dirac basis, a non-linear approximation of Y with {{math|''M'' ≥ 2}} gives zero error.&lt;ref&gt;A wavelet tour of signal processing-Stéphane Mallat&lt;/ref&gt;

== Principal component analysis ==
{{Main article|Principal component analysis}}

We have established the Karhunen–Loève theorem and derived a few properties thereof. We also noted that one hurdle in its application was the numerical cost of determining the eigenvalues and eigenfunctions of its covariance operator through the Fredholm integral equation of the second kind

:&lt;math&gt;\int_a^b K_X(s,t) e_k(s)\,ds=\lambda_k e_k(t).&lt;/math&gt;

However, when applied to a discrete and finite process &lt;math&gt;\left(X_n\right)_{n\in\{1,\ldots,N\}}&lt;/math&gt;, the problem takes a much simpler form and standard algebra can be used to carry out the calculations.

Note that a continuous process can also be sampled at ''N'' points in time in order to reduce the problem to a finite version.

We henceforth consider a random ''N''-dimensional vector &lt;math&gt;X=\left(X_1~X_2~\ldots~X_N\right)^T&lt;/math&gt;. As mentioned above, ''X'' could contain ''N'' samples of a signal but it can hold many more representations depending on the field of application. For instance it could be the answers to a survey or economic data in an econometrics analysis.

As in the continuous version, we assume that ''X'' is centered, otherwise we can let &lt;math&gt;X:=X-\mu_X&lt;/math&gt; (where &lt;math&gt;\mu_X&lt;/math&gt; is the [[mean vector]] of ''X'') which is centered.

Let us adapt the procedure to the discrete case.

=== Covariance matrix ===
Recall that the main implication and difficulty of the KL transformation is computing the eigenvectors of the linear operator associated to the covariance function, which are given by the solutions to the integral equation written above.

Define Σ, the covariance matrix of ''X'', as an ''N'' × ''N'' matrix whose elements are given by:
:&lt;math&gt;\Sigma_{ij}= \mathbf{E}[X_i X_j],\qquad \forall i,j \in \{1,\ldots,N\}&lt;/math&gt;

Rewriting the above integral equation to suit the discrete case, we observe that it turns into:

:&lt;math&gt;\sum_{i=1}^N \Sigma_{ij} e_j=\lambda e_j \quad \Leftrightarrow \quad \Sigma e=\lambda e&lt;/math&gt;

where &lt;math&gt;e=(e_1~e_2~\ldots~e_N)^T&lt;/math&gt; is an ''N''-dimensional vector.

The integral equation thus reduces to a simple matrix eigenvalue problem, which explains why the PCA has such a broad domain of applications.

Since Σ is a positive definite symmetric matrix, it possesses a set of orthonormal eigenvectors forming a basis of &lt;math&gt;\R^N&lt;/math&gt;, and we write &lt;math&gt;\{\lambda_i,\varphi_i\}_{i\in\{1,\ldots,N\}}&lt;/math&gt; this set of eigenvalues and corresponding eigenvectors, listed in decreasing values of {{mvar|λ&lt;sub&gt;i&lt;/sub&gt;}}. Let also {{math|Φ}} be the orthonormal matrix consisting of these eigenvectors:

:&lt;math&gt;\begin{align}
\Phi &amp;:=\left(\varphi_1~\varphi_2~\ldots~\varphi_N\right)^T\\
\Phi^T \Phi &amp;=I
\end{align}&lt;/math&gt;

=== Principal component transform ===
It remains to perform the actual KL transformation, called the ''principal component transform'' in this case. Recall that the transform was found by expanding the process with respect to  the basis spanned by the eigenvectors of the covariance function. In this case, we hence have:

:&lt;math&gt;X =\sum_{i=1}^N \langle \varphi_i,X\rangle \varphi_i =\sum_{i=1}^N \varphi_i^T X \varphi_i&lt;/math&gt;

In a more compact form, the principal component transform of ''X'' is defined by:
:&lt;math&gt;\begin{cases} Y=\Phi^T X \\ X=\Phi Y \end{cases}&lt;/math&gt;

The ''i''-th component of ''Y'' is &lt;math&gt;Y_i=\varphi_i^T X&lt;/math&gt;, the projection of ''X'' on &lt;math&gt;\varphi_i&lt;/math&gt; and the inverse transform {{math|''X'' {{=}} Φ''Y''}} yields the expansion of {{mvar|X}} on the space spanned by the &lt;math&gt;\varphi_i&lt;/math&gt;:

:&lt;math&gt;X=\sum_{i=1}^N Y_i \varphi_i=\sum_{i=1}^N \langle \varphi_i,X\rangle \varphi_i&lt;/math&gt;

As in the continuous case, we may reduce the dimensionality of the problem by truncating the sum at some &lt;math&gt;K\in\{1,\ldots,N\}&lt;/math&gt; such that

:&lt;math&gt;\frac{\sum_{i=1}^K \lambda_i}{\sum_{i=1}^N \lambda_i}\geq \alpha&lt;/math&gt;

where α is the explained variance threshold we wish to set.

We can also reduce the dimensionality through the use of multilevel dominant eigenvector estimation (MDEE).&lt;ref&gt;X. Tang, “Texture information in run-length matrices,” IEEE Transactions on Image Processing, vol. 7, No. 11, pp. 1602–1609, Nov. 1998&lt;/ref&gt;

== Examples ==

=== The Wiener process ===
There are numerous equivalent characterizations of the [[Wiener process]] which is a mathematical formalization of [[Brownian motion]].  Here we regard it as the centered standard Gaussian process '''W'''&lt;sub&gt;''t''&lt;/sub&gt; with covariance function
:&lt;math&gt; K_W(t,s)  = \operatorname{cov}(W_t,W_s) = \min (s,t). &lt;/math&gt;

We restrict the time domain to [''a'', ''b'']=[0,1] without loss of generality.

The eigenvectors of the covariance kernel are easily determined.  These are
:&lt;math&gt; e_k(t) = \sqrt{2} \sin \left( \left(k - \tfrac{1}{2}\right) \pi t \right)&lt;/math&gt;
and the corresponding eigenvalues are
:&lt;math&gt; \lambda_k = \frac{1}{(k -\frac{1}{2})^2 \pi^2}. &lt;/math&gt;

&lt;div class="NavFrame collapsed"&gt;
  &lt;div class="NavHead"&gt;[Proof]&lt;/div&gt;
  &lt;div class="NavContent" style="text-align:left"&gt;
In order to find the eigenvalues and eigenvectors, we need to solve the integral equation:

:&lt;math&gt;\begin{align}
\int_a^b K_W(s,t) e(s) \,ds &amp;=\lambda e(t)\qquad \forall t, 0\leq t\leq 1\\
\int_0^1 \min(s,t) e(s) \,ds &amp;=\lambda e(t)\qquad \forall t, 0\leq t\leq 1 \\
\int_0^t s e(s) \,ds + t \int_t^1 e(s) \,ds &amp;= \lambda e(t) \qquad \forall t, 0\leq t\leq 1
\end{align}&lt;/math&gt;

differentiating once with respect to ''t'' yields:

:&lt;math&gt;\int_t^1 e(s) \, ds=\lambda e'(t)&lt;/math&gt;

a second differentiation produces the following differential equation:
:&lt;math&gt;-e(t)=\lambda e''(t)&lt;/math&gt;

The general solution of which has the form:
:&lt;math&gt;e(t)=A\sin\left(\frac{t}{\sqrt{\lambda}}\right)+B\cos\left(\frac{t}{\sqrt{\lambda}}\right)&lt;/math&gt;

where ''A'' and ''B'' are two constants to be determined with the boundary conditions. Setting ''t''&amp;nbsp;=&amp;nbsp;0 in the initial integral equation gives ''e''(0)&amp;nbsp;=&amp;nbsp;0 which implies that ''B''&amp;nbsp;=&amp;nbsp;0 and similarly, setting ''t''&amp;nbsp;=&amp;nbsp;1 in the first differentiation yields ''e' ''(1)&amp;nbsp;=&amp;nbsp;0, whence:

:&lt;math&gt;\cos\left(\frac{1}{\sqrt{\lambda}}\right)=0&lt;/math&gt;

which in turn implies that eigenvalues of ''T''&lt;sub&gt;''K''&lt;sub&gt;''X''&lt;/sub&gt;&lt;/sub&gt; are:

:&lt;math&gt;\lambda_k=\left(\frac{1}{(k-\frac{1}{2})\pi}\right)^2,\qquad k\geq 1&lt;/math&gt;

The corresponding eigenfunctions are thus of the form:

:&lt;math&gt;e_k(t)=A \sin\left((k-\frac{1}{2})\pi t\right),\qquad k\geq 1&lt;/math&gt;

''A'' is then chosen so as to normalize ''e''&lt;sub&gt;''k''&lt;/sub&gt;:

:&lt;math&gt;\int_0^1 e_k^2(t) \, dt=1\quad \implies\quad A=\sqrt{2}&lt;/math&gt;
  &lt;/div&gt;
&lt;/div&gt;

This gives the following representation of the Wiener process:

'''Theorem'''.  There is a sequence {''Z''&lt;sub&gt;''i''&lt;/sub&gt;}&lt;sub&gt;''i''&lt;/sub&gt; of independent Gaussian random variables with mean zero and variance 1 such that
:&lt;math&gt; W_t = \sqrt{2} \sum_{k=1}^\infty Z_k \frac{\sin \left(\left(k - \frac 1 2 \right) \pi t\right)}{ \left(k - \frac 1 2 \right) \pi}. &lt;/math&gt;
Note that this representation is only valid for &lt;math&gt; t\in[0,1]. &lt;/math&gt;  On larger intervals, the increments are not independent.  As stated in the theorem, convergence is in the L&lt;sup&gt;2&lt;/sup&gt; norm and uniform in&amp;nbsp;''t''.

=== The Brownian bridge ===
Similarly the [[Brownian bridge]] &lt;math&gt;B_t=W_t-tW_1&lt;/math&gt; which is a [[stochastic process]] with covariance function
:&lt;math&gt;K_B(t,s)=\min(t,s)-ts&lt;/math&gt;
can be represented as the series
:&lt;math&gt;B_t = \sum_{k=1}^\infty Z_k \frac{\sqrt{2} \sin(k \pi t)}{k \pi}&lt;/math&gt;

== Applications ==
{{Expand section|date=July 2010}}
[[Adaptive optics]] systems sometimes use K–L functions to reconstruct wave-front phase information (Dai 1996, JOSA A).
Karhunen–Loève expansion is closely related to the [[Singular Value Decomposition]]. The latter has myriad applications in image processing, radar, seismology, and the like. If one has independent vector observations from a vector valued stochastic process then the left singular vectors are [[maximum likelihood]] estimates of the ensemble KL expansion.

=== Applications in signal estimation and detection===

====Detection of a known continuous signal ''S''(''t'')====
In communication, we usually have to decide whether a signal from a noisy channel contains valuable information. The following hypothesis testing is used for detecting continuous signal ''s''(''t'') from channel output ''X''(''t''), ''N''(''t'') is the channel noise, which is usually assumed zero mean Gaussian process with correlation function &lt;math&gt;R_N (t, s) = E[N(t)N(s)]&lt;/math&gt;

:&lt;math&gt;H: X(t) = N(t), &lt;/math&gt;
:&lt;math&gt;K: X(t) = N(t)+s(t), \quad t\in(0,T)&lt;/math&gt;

====Signal detection  in white noise====
When the channel noise is white, its correlation function is

:&lt;math&gt;R_N(t) = \tfrac{1}{2} N_0 \delta (t),&lt;/math&gt;

and it has constant power spectrum density. In physically practical channel, the noise power is finite, so:

:&lt;math&gt;S_N(f) = \begin{cases} \frac{N_0}{2} &amp;|f|&lt;w \\ 0 &amp; |f|&gt;w \end{cases}&lt;/math&gt;

Then the noise correlation function is sinc function with zeros at &lt;math&gt;\frac{n}{2\omega}, n \in \mathbf{Z}.&lt;/math&gt; Since are uncorrelated and gaussian, they are independent. Thus we can take samples from ''X''(''t'') with time spacing

:&lt;math&gt; \Delta t = \frac{n}{2\omega} \text{ within } (0,''T''). &lt;/math&gt;

Let &lt;math&gt;X_i = X(i\,\Delta t)&lt;/math&gt;. We have a total of &lt;math&gt;n = \frac{T}{\Delta t} = T(2\omega) = 2\omega T&lt;/math&gt; i.i.d observations &lt;math&gt;\{X_1, X_2,\ldots,X_n\}&lt;/math&gt; to develop the likelihood-ratio test.  Define signal &lt;math&gt;S_i = S(i\,\Delta t)&lt;/math&gt;, the problem becomes,

:&lt;math&gt;H: X_i = N_i,&lt;/math&gt;

:&lt;math&gt;K: X_i = N_i + S_i, i = 1,2,\ldots,n.&lt;/math&gt;

The log-likelihood ratio

:&lt;math&gt;\mathcal{L}(\underline{x}) = \log\frac{\sum^n_{i=1} (2S_i x_i - S_i^2)}{2\sigma^2} \Leftrightarrow \Delta t \sum^n_{i = 1} S_i x_i = \sum^n_{i=1} S(i\,\Delta t)x(i\,\Delta t) \, \Delta t \gtrless \lambda_\cdot2&lt;/math&gt;

As {{math|''t'' → 0}}, let:

:&lt;math&gt;G = \int^T_0 S(t)x(t) \, dt.&lt;/math&gt;

Then ''G'' is the test statistics and the [[Neyman–Pearson lemma|Neyman–Pearson optimum detector]] is

:&lt;math&gt;G(\underline{x}) &gt; G_0 \Rightarrow K &lt; G_0 \Rightarrow H.&lt;/math&gt;

As ''G'' is Gaussian, we can characterize it by finding its mean and variances. Then we get

:&lt;math&gt;H: G \sim N \left (0,\tfrac{1}{2}N_0E \right )&lt;/math&gt;
:&lt;math&gt;K: G \sim N \left (E,\tfrac{1}{2}N_0E \right )&lt;/math&gt;

where

:&lt;math&gt;\mathbf{E} = \int^T_0 S^2(t) \, dt&lt;/math&gt;

is the signal energy.

The false alarm error

:&lt;math&gt;\alpha = \int^\infty_{G_0} N \left (0, \tfrac{1}{2}N_0E \right) \, dG \Rightarrow G_0 = \sqrt{\tfrac{1}{2} N_0E} \Phi^{-1}(1-\alpha)&lt;/math&gt;

And the probability of detection:

:&lt;math&gt;\beta = \int^\infty_{G_0} N \left (E, \tfrac{1}{2}N_0E \right) \, dG = 1-\Phi \left (\frac{G_0 - E}{\sqrt{\tfrac{1}{2} N_0 E}} \right ) = \Phi \left (\sqrt{\frac{2E}{N_0}} - \Phi^{-1}(1-\alpha) \right ),&lt;/math&gt;

where Φ is the cdf of standard normal, or Gaussian, variable.

====Signal detection in colored noise ====
When N(t) is colored (correlated in time) Gaussian noise  with zero mean and covariance function &lt;math&gt;R_N(t,s) = E[N(t)N(s)],&lt;/math&gt;  we cannot sample independent discrete observations by evenly spacing the time. Instead, we can use K–L expansion to uncorrelate the noise process and get independent Gaussian observation 'samples'.  The K–L expansion of ''N''(''t''):

:&lt;math&gt;N(t) = \sum^{\infty}_{i=1} N_i \Phi_i(t), \quad 0&lt;t&lt;T,&lt;/math&gt;

where &lt;math&gt;N_i =\int N(t)\Phi_i(t)\,dt&lt;/math&gt; and the orthonormal bases &lt;math&gt;\{\Phi_i{t}\}&lt;/math&gt; are generated by kernel &lt;math&gt;R_N(t,s)&lt;/math&gt;, i.e., solution to

:&lt;math&gt; \int ^T_0 R_N(t,s)\Phi_i(s)\,ds = \lambda_i \Phi_i(t), \quad \operatorname{var}[N_i] = \lambda_i.&lt;/math&gt;

Do the expansion:

:&lt;math&gt;S(t) = \sum^{\infty}_{i = 1}S_i\Phi_i(t),&lt;/math&gt;

where &lt;math&gt;S_i = \int^T _0 S(t)\Phi_i(t) \, dt&lt;/math&gt;, then

:&lt;math&gt;X_i = \int^T _0 X(t)\Phi_i(t) \, dt = N_i&lt;/math&gt;

under H and &lt;math&gt;N_i + S_i&lt;/math&gt; under K. Let &lt;math&gt;\overline{X} = \{X_1,X_2,\dots\}&lt;/math&gt;, we have

:&lt;math&gt;N_i&lt;/math&gt; are independent Gaussian r.v's with variance &lt;math&gt;\lambda_i&lt;/math&gt;

:under H: &lt;math&gt;\{X_i\}&lt;/math&gt; are independent Gaussian r.v's. 
::&lt;math&gt;f_H[x(t)|0&lt;t&lt;T] = f_H(\underline{x}) = \prod^\infty_{i=1} \frac{1}{\sqrt{2\pi \lambda_i}} \exp \left (-\frac{x_i^2}{2 \lambda_i} \right )&lt;/math&gt;

:under K: &lt;math&gt;\{X_i - S_i\}&lt;/math&gt; are independent Gaussian r.v's. 
::&lt;math&gt;f_K[x(t)\mid 0&lt;t&lt;T] = f_K(\underline{x}) = \prod^\infty_{i=1} \frac{1}{\sqrt{2\pi \lambda_i}} \exp \left(-\frac{(x_i - S_i)^2}{2 \lambda_i} \right)&lt;/math&gt;

Hence, the log-LR is given by

:&lt;math&gt;\mathcal{L}(\underline{x}) = \sum^{\infty}_{i=1} \frac{2S_i x_i - S_i^2}{2\lambda_i}&lt;/math&gt;

and the optimum detector is

:&lt;math&gt;G = \sum^\infty_{i=1} S_i x_i \lambda_i &gt; G_0 \Rightarrow K, &lt; G_0 \Rightarrow H.&lt;/math&gt;

Define

:&lt;math&gt;k(t) = \sum^\infty_{i=1} \lambda_i S_i \Phi_i(t), 0&lt;t&lt;T,&lt;/math&gt;

then &lt;math&gt;G = \int^T _0 k(t)x(t)\,dt.&lt;/math&gt;

=====How to find ''k''(''t'')=====
Since

:&lt;math&gt;\int^T_0 R_N(t,s)k(s) \, ds = \sum^\infty_{i=1} \lambda_i S_i \int^T _0 R_N(t,s)\Phi_i (s) \, ds = \sum^\infty_{i=1} S_i \Phi_i(t) = S(t), &lt;/math&gt;

k(t) is the solution to

:&lt;math&gt;\int^T_0 R_N(t,s)k(s)\,ds = S(t).&lt;/math&gt;

If ''N''(''t'')is wide-sense stationary,

:&lt;math&gt;\int^T_0 R_N(t-s)k(s) \, ds = S(t), &lt;/math&gt;

which is known as the [[Wiener–Hopf equation]]. The equation can be solved by taking fourier transform, but not practically realizable since infinite spectrum needs spatial factorization. A special case which is easy to calculate ''k''(''t'') is white Gaussian noise.

:&lt;math&gt;\int^T_0 \frac{N_0}{2}\delta(t-s)k(s) \, ds = S(t) \Rightarrow k(t) = C S(t), \quad 0&lt;t&lt;T.&lt;/math&gt;

The corresponding impulse response is ''h''(''t'') = ''k''(''T''&amp;nbsp;−&amp;nbsp;''t'') = ''CS''(''T''&amp;nbsp;−&amp;nbsp;''t''). Let ''C''&amp;nbsp;=&amp;nbsp;1, this is just the result we arrived at in previous section for detecting of signal in white noise.

=====Test threshold for Neyman–Pearson detector=====
Since X(t) is a Gaussian process,

:&lt;math&gt;G = \int^T_0 k(t)x(t) \, dt,&lt;/math&gt;

is a Gaussian random variable that can be characterized by its mean and variance.

:&lt;math&gt;\begin{align}
\mathbf{E}[G\mid H] &amp;= \int^T_0 k(t)\mathbf{E}[x(t)\mid H]\,dt = 0 \\
\mathbf{E}[G\mid K] &amp;= \int^T_0 k(t)\mathbf{E}[x(t)\mid K]\,dt = \int^T_0 k(t)S(t)\,dt \equiv \rho \\
\mathbf{E}[G^2\mid H] &amp;= \int^T_0 \int^T_0 k(t)k(s) R_N(t,s)\,dt\,ds = \int^T_0 k(t) \left (\int^T_0 k(s)R_N(t,s) \, ds \right) = \int^T_0 k(t)S(t) \, dt = \rho \\
\operatorname{var}[G\mid H] &amp;= \mathbf{E}[G^2\mid H] - (\mathbf{E}[G\mid H])^2 = \rho \\
\mathbf{E}[G^2\mid K] &amp;=\int^T_0\int^T_0k(t)k(s) \mathbf{E}[x(t)x(s)]\,dt\,ds = \int^T_0\int^T_0k(t)k(s)(R_N(t,s) +S(t)S(s)) \, dt\, ds = \rho + \rho^2\\
\operatorname{var}[G\mid K] &amp;= \mathbf{E}[G^2|K] - (\mathbf{E}[G|K])^2 = \rho + \rho^2 -\rho^2 = \rho
\end{align}&lt;/math&gt;

Hence, we obtain the distributions of ''H'' and ''K'':

:&lt;math&gt;H: G \sim N(0,\rho)&lt;/math&gt;
:&lt;math&gt;K: G \sim N(\rho, \rho)&lt;/math&gt;

The false alarm error is

:&lt;math&gt;\alpha = \int^\infty_{G_0} N(0,\rho)\,dG = 1 - \Phi \left (\frac{G_0}{\sqrt{\rho}} \right ).&lt;/math&gt;

So the test threshold for the Neyman–Pearson optimum detector is

:&lt;math&gt;G_0 = \sqrt{\rho} \Phi^{-1} (1-\alpha).&lt;/math&gt;

Its power of detection is

:&lt;math&gt;\beta = \int^\infty_{G_0} N(\rho, \rho) \, dG = \Phi \left (\sqrt{\rho} - \Phi^{-1}(1 - \alpha) \right) &lt;/math&gt;

When the noise is white Gaussian process, the signal power is

:&lt;math&gt;\rho = \int^T_0 k(t)S(t) \, dt = \int^T_0 S(t)^2 \, dt = E.&lt;/math&gt;

=====Prewhitening=====
For some type of colored noise, a typical practise is to add a prewhitening filter before the matched filter to transform the colored noise into white noise. For example, N(t) is a wide-sense stationary colored noise with correlation function

:&lt;math&gt;R_N(\tau) = \frac{B N_0}{4} e^{-B|\tau|}&lt;/math&gt;
:&lt;math&gt;S_N(f) = \frac{N_0}{2(1+(\frac{w}{B})^2)}&lt;/math&gt;

The transfer function of prewhitening filter is

:&lt;math&gt;H(f) = 1 + j \frac{w}{B}.&lt;/math&gt;

====Detection of a Gaussian random signal in [[Additive white Gaussian noise|Additive white Gaussian noise (AWGN)]]====
When the signal we want to detect from the noisy channel is also random, for example, a white Gaussian process ''X''(''t''), we can still implement K–L expansion to get independent sequence of observation. In this case, the detection problem is described as follows:

:&lt;math&gt;H_0 : Y(t) = N(t)&lt;/math&gt;
:&lt;math&gt;H_1 : Y(t) = N(t) + X(t), \quad 0&lt;t&lt;T. &lt;/math&gt;

''X''(''t'') is a random process with correlation function &lt;math&gt;R_X(t,s) = E\{X(t)X(s)\}&lt;/math&gt;

The K–L expansion of ''X''(''t'') is

:&lt;math&gt;X(t) = \sum^\infty_{i=1} X_i \Phi_i(t),&lt;/math&gt;

where

:&lt;math&gt;X_i = \int^T_0 X(t)\Phi_i(t)\,dt&lt;/math&gt;

and &lt;math&gt;\Phi_i(t)&lt;/math&gt; are solutions to

:&lt;math&gt; \int^T_0 R_X(t,s)\Phi_i(s)ds= \lambda_i \Phi_i(t). &lt;/math&gt;

So &lt;math&gt;X_i&lt;/math&gt;'s are independent sequence of r.v's with zero mean and variance &lt;math&gt;\lambda_i&lt;/math&gt;. Expanding ''Y''(''t'') and ''N''(''t'') by &lt;math&gt;\Phi_i(t)&lt;/math&gt;, we get

:&lt;math&gt;Y_i = \int^T_0 Y(t)\Phi_i(t) \, dt = \int^T_0 [N(t) + X(t)]\Phi_i(t) = N_i + X_i,&lt;/math&gt;

where

:&lt;math&gt;N_i = \int^T_0 N(t)\Phi_i(t)\,dt.&lt;/math&gt;

As ''N''(''t'') is Gaussian white noise, &lt;math&gt;N_i&lt;/math&gt;'s are i.i.d sequence of r.v with zero mean and variance &lt;math&gt;\tfrac{1}{2}N_0&lt;/math&gt;, then the problem is simplified as follows,

:&lt;math&gt;H_0: Y_i = N_i&lt;/math&gt;
:&lt;math&gt;H_1: Y_i = N_i + X_i&lt;/math&gt;

The Neyman–Pearson optimal test:

:&lt;math&gt;\Lambda = \frac{f_Y\mid H_1}{f_Y\mid H_0} = Ce^{-\sum^\infty_{i=1} \frac{y_i^2}{2} \frac{\lambda_i}{\tfrac{1}{2} N_0 (\tfrac{1}{2}N_0 + \lambda_i)} },&lt;/math&gt;

so the log-likelihood ratio is

:&lt;math&gt;\mathcal{L} = \ln(\Lambda) = K -\sum^\infty_{i=1}\tfrac{1}{2}y_i^2  \frac{\lambda_i}{\frac{N_0}{2} \left(\frac{N_0}{2} + \lambda_i\right)}.&lt;/math&gt;

Since

:&lt;math&gt;\widehat{X}_i = \frac{\lambda_i}{\frac{N_0}{2} \left( \frac{N_0}{2} + \lambda_i \right)}&lt;/math&gt;

is just the minimum-mean-square estimate of &lt;math&gt;X_i&lt;/math&gt; given &lt;math&gt;Y_i&lt;/math&gt;'s,

:&lt;math&gt;\mathcal{L} = K + \frac{1}{N_0} \sum^\infty_{i=1} Y_i \widehat{X}_i.&lt;/math&gt;

K–L expansion has the following property:  If

:&lt;math&gt;f(t) = \sum f_i \Phi_i(t), g(t) = \sum g_i \Phi_i(t),&lt;/math&gt;

where

:&lt;math&gt;f_i = \int_0^T f(t) \Phi_i(t)\,dt, \quad g_i = \int_0^T g(t)\Phi_i(t) \, dt.&lt;/math&gt;

then

:&lt;math&gt;\sum^\infty_{i=1} f_i g_i = \int^T_0 g(t)f(t)\,dt.&lt;/math&gt;

So let

:&lt;math&gt;\widehat{X}(t\mid T) = \sum^\infty_{i=1} \widehat{X}_i \Phi_i(t), \quad \mathcal{L} = K + \frac{1}{N_0} \int^T_0 Y(t) \widehat{X}(t\mid T) \, dt.&lt;/math&gt;

Noncausal filter ''Q''(''t'',''s'') can be used to get the estimate through

:&lt;math&gt;\widehat{X}(t\mid T) = \int^T_0 Q(t,s)Y(s)\,ds.&lt;/math&gt;

By [[orthogonality principle]], ''Q''(''t'',''s'') satisfies

:&lt;math&gt;\int^T_0 Q(t,s)R_X(s,t)\,ds + \tfrac{N_0}{2} Q(t, \lambda) = R_X(t, \lambda), 0 &lt; \lambda &lt; T, 0&lt;t&lt;T. &lt;/math&gt;

However, for practical reasons, it's necessary to further derive the causal filter ''h''(''t'',''s''), where ''h''(''t'',''s'') = 0 for ''s'' &gt; ''t'', to get estimate &lt;math&gt;\widehat{X}(t\mid t)&lt;/math&gt;. Specifically,

:&lt;math&gt;Q(t,s) = h(t,s) + h(s, t) - \int^T_0 h(\lambda, t)h(s, \lambda) \, d\lambda&lt;/math&gt;

==See also==
*[[Principal component analysis]]
*[[Proper orthogonal decomposition]]
*[[Polynomial chaos]]

==Notes==
{{Reflist}}

==References==
* {{cite book
|first1=Henry
|last1=Stark
|first2=John W.
|last2=Woods
|title=Probability, Random Processes, and Estimation Theory for Engineers
|publisher=Prentice-Hall, Inc
|year=1986
|isbn=0-13-711706-X
|url = http://openlibrary.org/books/OL21138080M/Probability_random_processes_and_estimation_theory_for_engineers
}}
*{{cite book
|first1=Roger
|last1=Ghanem
|first2=Pol
|last2=Spanos
|publisher = Springer-Verlag 
|isbn = 0-387-97456-3 
|title = Stochastic finite elements: a spectral approach 
|url = http://openlibrary.org/books/OL1865197M/Stochastic_finite_elements 
|year = 1991 
}}
* {{cite book
|first1=I.
|last1=Guikhman
|first2=A.
|last2=Skorokhod
|title=Introduction a la Théorie des Processus Aléatoires
|publisher=Éditions MIR
|year=1977
}}
* {{cite book
|first1=B.
|last1=Simon
|title=Functional Integration and Quantum Physics
|publisher=Academic Press
|year=1979
}}
* {{cite journal
|last1=Karhunen
|first1=Kari
|title=Über lineare Methoden in der Wahrscheinlichkeitsrechnung
|journal=Ann. Acad. Sci. Fennicae. Ser. A. I. Math.-Phys.
|year=1947
|volume=37
|pages=1&amp;ndash;79
}}
* {{cite book
|first1=M.
|last1=Loève
|title=Probability theory.'' Vol. II, 4th ed.
|series=Graduate Texts in Mathematics
|volume=46
|publisher=Springer-Verlag
|year=1978
|isbn=0-387-90262-7
}}
* {{cite journal
|first1=G.
|last1=Dai
|title=Modal wave-front reconstruction with Zernike polynomials and Karhunen–Loeve functions
|journal=JOSA A
|volume=13
|issue=6
|page=1218
|year=1996
|doi=10.1364/JOSAA.13.001218
|bibcode=1996JOSAA..13.1218D
}}
*Wu B., Zhu J., Najm F.(2005) "A Non-parametric Approach for Dynamic Range Estimation of Nonlinear Systems". In Proceedings of Design Automation Conference(841-844) 2005
*Wu B., Zhu J., Najm F.(2006) "Dynamic Range Estimation". IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, Vol. 25 Issue:9 (1618–1636) 2006
* {{cite journal
|title=Entropy Encoding, Hilbert Space and Karhunen–Loeve Transforms
|first1=Palle E. T.
|last1=Jorgensen
|first2=Myung-Sin
|last2=Song
|arxiv=math-ph/0701056
|year=2007
|doi=10.1063/1.2793569
|volume=48
|journal=Journal of Mathematical Physics
|page=103503

|bibcode=2007JMP....48j3503J
}}

==External links==
* ''Mathematica'' [http://reference.wolfram.com/mathematica/ref/KarhunenLoeveDecomposition.html KarhunenLoeveDecomposition] function.
* ''E161: Computer Image Processing and Analysis'' notes by Pr. Ruye Wang at [[Harvey Mudd College]] [http://fourier.eng.hmc.edu/e161/lectures/klt/klt.html]

{{DEFAULTSORT:Karhunen-Loeve theorem}}
[[Category:Probability theorems]]
[[Category:Signal estimation]]
[[Category:Statistical theorems]]

[[fr:Transformée de Karhunen-Loève]]</text>
      <sha1>nmw39m89ig7en80mu9xwgll1b30yj3s</sha1>
    </revision>
  </page>
  <page>
    <title>Kim Plofker</title>
    <ns>0</ns>
    <id>40242283</id>
    <revision>
      <id>866654558</id>
      <parentid>775469062</parentid>
      <timestamp>2018-10-31T17:53:54Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>sections</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3371">'''Kim Leslie Plofker''' (born November 25, 1964) is an American historian of mathematics, specializing in [[Indian mathematics]].

==Education and career==
Plofker received her bachelor's degree in mathematics from [[Haverford College]]. She received her Ph.D. in 1995 while studying with adviser [[David Pingree]]&lt;ref&gt;{{MathGenealogy|id=24016|title=Kim Plofker}}&lt;/ref&gt; (Mathematical Approximation by Transformation of Sine Functions in Medieval Sanskrit Astronomical Texts) from [[Brown University]], where she conducted research and then later was a guest professor.&lt;ref name="utwente"&gt;{{cite web|title=The Brouwer Lecture and the Brouwer Medal|url=http://www.utwente.nl/ewi/nmc2011/en/brouwer/|publisher=[[University of Twente]]}}&lt;/ref&gt;

In the late 1990s she was Technical Director of the American Committee for South Asian Manuscripts of the American Oriental Society, where she was also concerned with the development of programs for the text comparison. From 2000 to 2004 she was at the [[Dibner Institute for the History of Science and Technology]] at the [[Massachusetts Institute of Technology]]. During 2004 and 2005 she was a visiting professor in Utrecht and at the same time Fellow of the [[International Institute for Asian Studies]] in Leiden. She is currently an assistant professor at Union College in Schenectady.

==Contributions==
Plofker deals with the history of Indian mathematics, the topic of her 2008 book ''Mathematics in India'', which has quickly established itself as a standard work.&lt;ref name="utwente" /&gt; She is particularly interested in the exchange of mathematics and astronomy between India and Islam in the Middle Ages and generally in the exact sciences between Europe and Asia from antiquity to the 20th Century.

According to [[David Mumford]], besides her book ''Mathematics in India'', "there is only one other survey, Datta and Singh’s 1938 ''History of Hindu Mathematics''...supplemented by the equally hard to find ''Geometry in Ancient and Medieval India'' by [[Sarasvati Amma]] (1979)", where, "one can get an overview of most topics" in [[Indian mathematics]].&lt;ref name=Mumford&gt;{{cite journal|last1=Mumford|first1=David|authorlink=David Mumford|title=Book Review|journal=Notices of the AMS|date=March 2010|volume=57|issue=3|url=http://www.ams.org/notices/201003/rtx100300385p.pdf}}&lt;/ref&gt;

==Recognition==
In 2010 she gave a plenary lecture&lt;ref&gt;{{cite web|title=ICM Plenary and Invited Speakers since 1897|url=http://www.mathunion.org/db/ICM/Speakers/SortedByCongress.php|publisher=[[International Congress of Mathematicians]]}}&lt;/ref&gt; at the [[International Congress of Mathematicians]], [[Hyderabad, India|Hyderabad]] (Indian rules, Yavana rules: foreign identity and the transmission of mathematics). In 2011, she was awarded the [[Brouwer Medal]] of the [[Royal Dutch Mathematical Society]].&lt;ref name="utwente" /&gt;

==References==
{{Reflist}}

{{Authority control}}
{{DEFAULTSORT:Plofker, Kim}}
[[Category:1964 births]]
[[Category:Historians of mathematics]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Haverford College alumni]]
[[Category:Brown University alumni]]
[[Category:Brouwer Medalists]]
[[Category:Massachusetts Institute of Technology faculty]]
[[Category:Women mathematicians]]
[[Category:American Indologists]]
[[Category:Living people]]</text>
      <sha1>ptv7ze71ahgjg4n6p412ywlgl94f9ew</sha1>
    </revision>
  </page>
  <page>
    <title>List of Polish mathematicians</title>
    <ns>0</ns>
    <id>26472757</id>
    <revision>
      <id>848091425</id>
      <parentid>806501245</parentid>
      <timestamp>2018-06-29T18:47:23Z</timestamp>
      <contributor>
        <username>DeprecatedFixerBot</username>
        <id>33330201</id>
      </contributor>
      <minor/>
      <comment>Removed deprecated parameter(s) from [[Template:Div col]] using [[User:DeprecatedFixerBot| DeprecatedFixerBot]]. Questions? See [[Template:Div col#Usage of "cols" parameter]] or [[User talk:TheSandDoctor|msg TSD!]] (please mention that this is task #2!))</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3919">A list of notable [[Poland|Polish]] mathematicians:

{{div col|colwidth=18em}}

*[[Bruno Abakanowicz]] (1852-1900)
*[[Kazimierz Abramowicz]] (1889-1936)
*[[Andrzej Alexiewicz]] (1917-1995)
*[[:pl:Krzysztof_Apt|Krzysztof Apt]] (1949-)
*[[Nachman Aronszajn]] (1907-1980)
*[[Tytus Babczyński]] (1830-1910)
*[[Stefan Banach]] (1892-1945)
*[[Tadeusz Banachiewicz]] (1882-1954)
*[[Feliks Barański]] (1915-2006)
*[[Kazimierz Bartel]] (1882-1941)
*[[Tomek Bartoszyński]] (1957-)
*[[Andrzej Białynicki-Birula]] (1935-)
*[[Mieczysław Biernacki]] (1891-1959)
*[[Karol Borsuk]] (1905-1982)
*[[Jerzy Browkin]] (1934-2015)
*[[Jan Brożek]](1585-1652)
*[[Leon Chwistek]] (1884-1944)
*[[Kazimierz Cwojdziński]] (1878-1948)
*[[Adam Danielewicz]] (1846–1935)
*[[Ryszard Engelking]] (1935-)
*[[Kajetan Garbiński]] (1796–1847)
*[[Stanisław Grzepski]] (1524–1570)
*[[Edward Jan Habich]] (1835-1909)
*[[Witold Hurewicz]] (1904-1956)
*[[Henryk Iwaniec]] (1947-)
*[[Tadeusz Iwaniec]] (1947-)
*[[Zygmunt Janiszewski]] (1888-1920)
*[[Stanisław Jaśkowski]] (1906-1965)
*[[Stefan Kaczmarz]] (1895-1939)
*[[Andrzej Kapiszewski]] (1948–2007)
*[[Marek Karpinski]]
*[[Bronisław Knaster]] (1893-1980)
*[[Adam Adamandy Kochański]] (1631-1700)
*[[Stanisław Krajewski]] (1950-)
*[[Zdzisław Krygowski]] (1872-1955)
*[[Adrian Krzyżanowski]] (1788-1852)
*[[Marek Kuczma]] (1935-1991)
*[[Krystyna Kuperberg]] (1944-)
*[[Włodzimierz Kuperberg]] (1941-)
*[[Kazimierz Kuratowski]] (1896-1980)
*[[Mariusz Lemańczyk]] (1958-)
*[[Julian Ławrynowicz]] (1939-)
*[[Stanisław Łojasiewicz]] (1926-2002)
*[[Jerzy Łoś]] (1920-1998)
*[[Tomasz Łuczak]] (1963-)
*[[Jan Łukasiewicz]] (1878-1956)
*[[Zbigniew Marciniak]] (1952-)
*[[Józef Marcinkiewicz]] (1910-1940)
*[[Stefan Mazurkiewicz]] (1888-1945)
*[[Jan Mikusiński]] (1913-1987)
*[[Witold Milewski (mathematician)]] (1817-1889)
*[[Michał Misiurewicz]] (1948-)
*[[:pl:Michał_Morayne|Michał Morayne]] (1958-) [http://nauka-polska.pl/dhtml/raporty/ludzieNauki?rtype=opis&amp;objectId=39251&amp;lang=pl] (pl)
*[[Andrzej Mostowski]] (1913-1975)
*[[Jan Mycielski]] (1932-)
*[[Edward Neuman]] (1943-)
*[[Jerzy Spława-Neyman]] (1894-1981)
*[[Otto M. Nikodym]] (1887-1974)
*[[Andrew Odlyzko]] (1949-)
*[[Czesław Olech]] (1931-2015)
*[[Janusz Onyszkiewicz]] (1937-)
*[[Władysław Orlicz]] (1903-1990)
*[[Krzysztof Ostaszewski]] [http://math.illinoisstate.edu/krzysio]
*[[Zdzisław Pawlak]] (1926-2006)
*[[Marcin Poczobutt-Odlanicki]] (1728-1810)
*[[Emil Post]] (1897-1954)
*[[Przemysław Prusinkiewicz]]
*[[Feliks Przytycki]] (1951-)
*[[Józef Przytycki]] (1953-)
*[[Stanisław Radziszowski]] (1953-)
*[[Jan Rajewski]] (1857–1906)
*[[Helena Rasiowa]] (1917-1994)
*[[Jan Rusinek]] (1950-)
*[[Czesław Ryll-Nardzewski]] (1926-2015)
*[[Marcin Schroeder]] (1953-)
*[[Wacław Sierpiński]] (1882-1969)
*[[Roman Sikorski]] (1920-1983)
*[[Zdzisław Skupień]] (1938-)
*[[Joachim Stegmann]] (1595-1633)
*[[Hugo Steinhaus]] (1887-1972)
*[[:pl:Władysław_Ślebodziński|Wladyslaw Ślebodziński]] (1884-1972)
*[[Jan Śniadecki]] (1756-1830)
*[[Alfred Tarski]] (1901-1983)
*[[Andrzej Trybulec]] (1941-2013)
*[[Stanisław Trybuła]] (1932-2008)
*[[Arnold Walfisz]] (1892-1962)
*[[Mieczyslaw Warmus|Mieczysław Warmus]] (1918-2007)
*[[Witelon]]
*[[Wojbor Andrzej Woyczyński]] (1943-) [http://sites.google.com/a/case.edu/waw/]
*[[Jan Węglarz]] (1947-)
*[[Ignacy Zaborowski]] (1754-1803)
*[[Władysław Zajączkowski]] (1837-1898)
*[[Kazimierz Zarankiewicz]] (1902-1959)
*[[Olgierd Zienkiewicz]] (1921-2009)
*[[Antoni Zygmund]] (1900-1992)
*[[Teofil Żebrawski]] (1800–1887)
*[[:pl:Wiesław_Żelazko|Wieslaw Żelazko]] (1933-)
*[[Wawrzyniec Żmurko]] (1824-1889)
*[[:pl:Henryk_Żołądek|Henryk Żołądek]] (1953-)

{{div col end}}

==References==
{{Reflist}}

[[Category:Polish mathematicians| ]]
[[Category:Lists of Polish people by occupation|Mathematicians]]
[[Category:Lists of mathematicians|Polish]]</text>
      <sha1>e0p3vbl10gxbhn27k9n4bxp12l54ehr</sha1>
    </revision>
  </page>
  <page>
    <title>List of computer algebra systems</title>
    <ns>0</ns>
    <id>2230309</id>
    <revision>
      <id>868469519</id>
      <parentid>868467501</parentid>
      <timestamp>2018-11-12T11:19:56Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>/* General */ merging the two releases of CoCoA</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27717">The following tables provide a '''comparison of [[computer algebra system]]s''' (CAS).&lt;ref&gt;{{cite web|url=http://www.sigsam.org/software/index.phtml |title=Computer Algebra Software |work=Special Interest Group on Symbolic and Algebraic Manipulation |publisher=Association for Computing Machinery |date=2008-07-11 |accessdate=2012-11-16}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.computeralgebra.nl/systems_and_packages/systems_and_packages.html |title=Systems and Packages |publisher=Computer Algebra Information Network |date=1998-05-07 |accessdate=2012-11-17}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=SAC Systems Listing |url=http://www.symbolicnet.org/systems/Systems.html |publisher=SymbolicNet |accessdate=2012-11-17 |deadurl=yes |archiveurl=https://web.archive.org/web/20120415021413/http://www.symbolicnet.org/systems/Systems.html |archivedate=2012-04-15 |df= }}&lt;/ref&gt; A CAS is a package comprising a set of algorithms for performing symbolic manipulations on algebraic objects, a language to implement them, and an environment in which to use the language.&lt;ref&gt;{{cite book|last=Aladjev|first=V.Z.|title=Computer algebra systems : a new software toolbox for Maple|year=2004|publisher=Fultus Books|location=[S.l.]|isbn=9781596820005|pages=9}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Labahn|first=K.O. Geddes ; S.R. Czapor ; G.|title=Algorithms for computer algebra|year=1999|publisher=Kluwer|location=Boston|isbn=9780792392590|pages=xv|edition=6. pr.}}&lt;/ref&gt; A CAS may include a user interface and graphics capability; and to be effective may require a large library of algorithms, efficient data structures and a fast kernel.&lt;ref&gt;{{cite book|last=Gerhard|first=Joachim von Zur Gathen ; Jürgen|title=Modern computer algebra|year=2003|publisher=Cambridge Univ. Press|location=Cambridge|isbn=9780521826464|pages=4|edition=2.}}&lt;/ref&gt;

==General==
{| class="wikitable sortable" style="font-size: smaller; text-align: center; width: auto;"
|-
! style="width: 12em" | System
! Creator
! Development started
! First public release
! Latest stable version
! Latest stable release date
! data-sort-type="currency"|Cost ([[United States dollar|USD]])
! License
! Notes
|-
! [[Axiom (computer algebra system)|Axiom]]
| Richard Jenks
| 1977
| 1993 and 2002&lt;ref&gt;The first date is that of the first commercial release (to be checked), the second one is that of the first free license&lt;/ref&gt;
| || {{dts|2014|08}}&lt;ref&gt;{{cite web|url=http://www.axiom-developer.org/axiom-website/download.html |title=Axiom Computer Algebra System |accessdate=2016-04-29}}&lt;/ref&gt;
| {{free}}
| {{free|modified [[BSD licenses|BSD license]]}}
| General purpose CAS. Continuous Release using Docker Containers
|-
! [[Cadabra (computer program)|Cadabra]]
| Kasper Peeters
| 2001
| 2007
| 2.2.0 || {{dts|2018|03|29|format=dmy}}
| {{free}}
| {{GPL-lic}}
| CAS for [[tensor field]] theory
|-
! [[CoCoA]]
| John Abbott, Anna M. Bigatti, Giovanni Lagorio
| 1987
| 1995
| 5.2.0 || {{dts|2017|05|02|format=dmy}}
| {{free}}
| {{GPL-lic}}
| Specialized CAS for [[commutative algebra]]
|-
! [[Derive (computer algebra system)|Derive]]
| Soft Warehouse
| 1979
| 1988
| 6.1 || {{dts|2007|11}}
| Discontinued
| {{proprietary}}
| CAS designed for pocket calculators; it was discontinued in 2007
|-
! [[Erable]] (aka ALGB)
| Bernard Parisse, Mika Heiskanen, Claude-Nicolas Fiechter
| 1993
| 1993
| 4.20060919 || {{dts|2009|04|21|format=dmy}}
| {{free}}
| {{free|[[LGPL]]}}
| CAS designed for [[Hewlett-Packard]] scientific [[graphing calculators]] of the [[HP-48 series|HP 48]]/[[HP-49 series|49]]/[[HP-39g series|40]]/[[HP 50g|50]] series; discontinued in 2009
|-
! [[Fermat (computer algebra system)|Fermat]]
| Robert H. Lewis
| 1986
| 1993
| 6.21 || {{dts|2018|07|13|format=dmy}}
| $70 if grant money available, otherwise $0
| {{GPL-lic}}
| Specialized CAS for [[resultant]] computation and [[linear algebra]] with [[polynomial]] entries
|-
! [[FORM (symbolic manipulation system)|FORM]]
| J.A.M. Vermaseren
| 1984
| 1989
| 4.2 || {{dts|2017|7|6|format=dmy}}&lt;ref&gt;{{cite web|url=https://github.com/vermaseren/form/releases |title=Releases - vermaseren/form - GitHub |accessdate=2016-04-29}}&lt;/ref&gt;
| {{free}}
| {{GPL-lic}}
| CAS designed mainly for [[particle physics]] 
|-
! [[FriCAS]]
| Waldek Hebisch
| 2007
| 2007
| 1.3.4 || {{dts|2018|06|27|format=dmy}}
| {{free}}
| {{free|modified [[BSD licenses|BSD license]]}}
| Full-featured general purpose CAS. Especially strong at symbolic integration.
|-
! [[GAP (computer algebra system)|GAP]]
| GAP Group
| 1986
| 1986
| 4.9.3 || {{dts|2018|09|05|format=dmy}}
| {{free}}
| {{GPL-lic}}&lt;ref&gt;{{cite web|url=http://www.gap-system.org/Download/copyright.html |title=GAP Copyright |date=2012-06-14 |accessdate=2015-02-26}}&lt;/ref&gt;
| Specialized CAS for [[group theory]] and [[combinatorics]]. 
|-
! [[GiNaC]]
| Christian Bauer, Alexander Frink, Richard B. Kreckel, et al.
| 1999
| 1999
| 1.7.4 || {{dts|2018|02|19|format=dmy}}
| {{free}}
| {{GPL-lic}}
| Integrate symbolic computation into C++ programs; no high-level interface, but emphasis on interoperability.
|-
! [[KANT (software)|KANT/KASH]]
| KANT Group
| {{dunno}}
| {{dunno}}
| 3 || {{dts|2005}}/2008
| {{free|Free for non-commercial use}}
| own license
| Specialized CAS for [[algebraic number theory]]
|-
! [[Macaulay2]]
| Daniel Grayson and Michael Stillman
| 1992
| 1994
| 1.8 || {{dts|2015}}
| {{free}}
| {{GPL-lic}}
| Specialized CAS for [[algebraic geometry]] and [[commutative algebra]]
|-
! [[Macsyma]]
| [[MIT Project MAC]] and [[Symbolics]]
| 1968
| 1978
| 2.4 || {{dts|1999}}
| $500
| {{proprietary}}
| The oldest general purpose CAS. Still alive as [[Maxima (software)|Maxima]].
|-
! [[Magma (computer algebra system)|Magma]]
| [[University of Sydney]]
| data-sort-value=1990|~1990
| 1993
| 2.22-3 || {{dts|2016|07|20|format=dmy}}
| $1,440
| {{proprietary}}
| General purpose CAS, originally specialized in [[group theory]]. Works with elements of [[algebraic structure]]s rather than with non typed [[expression (mathematics)|mathematical expressions]]
|-
! [[Magnus (computer algebra system)|Magnus]]
| The New York Group Theory Cooperative
| 1994
| 1997
| || {{dts|2005}}
| {{free}}
| {{GPL-lic}}
| Specialized CAS for [[group theory]] providing facilities for doing calculations in and about [[infinite group]]s. Discontinued in 2005.
|-
! [[Maple (software)|Maple]]
| Symbolic Computation Group, [[University of Waterloo]]
| 1980
| 1984
| 2017 || {{dts|2017|05|25|format=dmy}}
| $2,275 (Commercial), $2,155 (Government), $1245 (Academic), $239 (Personal Edition), $99 (Student), $79 (Student, 12-Month term)&lt;ref&gt;{{cite web | url=https://webstore.maplesoft.com | title=Maplesoft Web Store | accessdate=2011-10-21}}&lt;/ref&gt;
| {{proprietary}}
| One of the major general purpose CAS
|-
! [[Mathcad]]
| [[Parametric Technology Corporation]]
| 1985
| 1985
| 15.0 M045 || {{dts|2015|11}}
| $1,600 (Commercial), $105 (Student), Free (Express Edition)&lt;ref&gt;{{cite web | url=http://www.ptc.com/product/mathcad/how-to-buy | title=PTC Web Store | accessdate=2015-02-01}}&lt;/ref&gt;
| {{proprietary}}
| [[Numerical software]] with some CAS capabilities
|-
! [[Mathematica]]
| [[Wolfram Research]]
| 1986
| 1988
| {{Latest stable software release/Mathematica}} || {{dts|2017|09|14|format=dmy}}
| $2,495 (Professional), $1095 (Education), $295 (Personal),&lt;ref name="Mathematica-Macworld"&gt;{{cite web|url=http://www.macworld.com/article/138664/2009/02/mathematica.html|title=Mathematica Home Edition Released|last=Cohen|first=Peter|publisher=[[Macworld]]|date=2009-02-05|accessdate=2014-07-03}}&lt;/ref&gt; $140 (Student), $69.95 (Student annual license),&lt;ref&gt;{{cite web | url=http://store.wolfram.com | title=Wolfram Worldwide Web Store | accessdate=2008-11-20}}&lt;/ref&gt; free on [[Raspberry Pi]] hardware&lt;ref name="Mathematica-Raspberry_Pi"&gt;{{cite web|url=https://www.theverge.com/2013/11/21/5130394/raspberry-pi-includes-mathematica-wolfram-language-free|title=Raspberry Pi now includes Mathematica and Wolfram Language for free|last=Kastrenakes|first=Jacob|publisher=[[The Verge]]|date=2013-11-21|accessdate=2014-07-03}}&lt;/ref&gt;
| {{proprietary}}
| One of the major general purpose CAS
|-
! [[Mathomatic]]
| George Gesslein II
| 1986
| 1987
| 16.0.5 || {{dts|2012}}
| Discontinued
| {{free|[[LGPL]]}}
| [[Elementary algebra]], [[calculus]], [[complex number]] and [[polynomial]] manipulations.
|-
! [[Maxima (software)|Maxima]]
| [[MIT Project MAC]] and [[Bill Schelter]] et al.
| 1967
| 1998
| 5.42.0 || {{dts|2018|09|28|format=dmy}}
| {{free}}
| {{GPL-lic}}
| General purpose CAS. Continuation of [[Macsyma]]; new releases occur two times a year.
|-
! [[MuMATH]]
| Soft Warehouse
| 1970s
| 1980
| MuMATH-83 ||
| Discontinued
| {{proprietary}}
| Predecessor of [[Derive (computer algebra system)|Derive]]
|-
! [[MuPAD]]
| SciFace Software
| 1989
| 2008
| 5.1 || {{dts|2008}}
| Discontinued
| {{proprietary}}
| [[MathWorks]] has incorporated MuPAD technology into Symbolic Math Toolbox
|-
! [[Axiom (computer algebra system)#History|OpenAxiom]]
| Gabriel Dos Reis
| 2007
| 2007
| 1.4.2 || {{dts|2013}}
| {{free}}
| {{free|modified [[BSD licenses|BSD license]]}}
| General purpose CAS. A fork of Axiom.
|-
! [[PARI/GP]]
| [[Henri Cohen (number theorist)|Henri Cohen]], Karim Belabas, Bill Allombert et al.
| 1985
| 1990
| 2.11.0 || {{dts|2018|07|18|format=dmy}}
| {{free}}
| {{GPL-lic}}
| Specialized CAS for [[number theory]]. 
|-
! [[Reduce (computer algebra system)|Reduce]]
| [[Anthony C. Hearn]]
| 1960s
| 1968
| || {{dts|2018}}
| {{free}}
| {{free|modified [[BSD licenses|BSD license]]}}
| Historically important general purpose CAS. Still alive, as open-sourced and freed in December 2008
|-
! [[Scilab]]
| Scilab Enterprises
| 1990
| 1990
| 6.0.1 || {{dts|2018|02|15|format=dmy}}
| {{free}}
| {{free|[[CeCILL]] (GPL-compatible)}}
| Matlab alternative. 
|-
! [[SageMath]]
| [[William A. Stein]]
| 2005
| 2005
| 8.4 || {{dts|2018|10|17|format=dmy}}&lt;ref&gt;{{cite web|url=http://www.sagemath.org/|title=SageMath – Open-Source Mathematical Software System|accessdate=2018-10-19}}&lt;/ref&gt;
| {{free}}
| {{GPL-lic}}
| Mathematics software system combining a number of existing packages, including [[numerical computation]], [[statistics]] and [[image processing]]
|-
! [[SINGULAR]]
| [[University of Kaiserslautern]]
| 1984
| 1997
| 4-1-1 || {{dts|2018|02|14|format=dmy}}
| {{free}}
| {{GPL-lic}}
| Computer algebra system for polynomial computations, with special emphasis on [[commutative algebra|commutative]] and [[non-commutative algebra]], [[algebraic geometry]], and [[singularity theory]].
|-
! [[SMath Studio]]
| Andrey Ivashov
| 2004
| 2006
| 0.99.6839 || {{dts|2018|09|22|format=dmy}}
| {{Free}}
| {{proprietary}}
| Mathematical notebook program similar to Mathcad.
|-
! Symbolic Math Toolbox ([[MATLAB]])
| [[MathWorks]]
| 1989
| 2008
| 9.4(2018a) || {{dts|2018}}
| $3,150 (Commercial), $99 (Student Suite), $700 (Academic), $194 (Home) including required [[Matlab]]
| {{proprietary}}
| Provides tools for solving and manipulating symbolic math expressions and performing variable-precision arithmetic.
|-
! [[SymPy]]
| Ondřej Čertík
| 2006
| 2007
| 1.3 || 14 September 2018
| {{free}}
| {{free|modified [[BSD license]]}}
| Python-based
|-
! [[TI-Nspire]] CAS (Computer Software)
| [[Texas Instruments]]
| 2006
| 2009
| 3.1.0.392 ||
|
| {{proprietary}}
| Successor to Derive. Based on Derive's engine used in TI-89/Voyage 200 and TI-Nspire handheld
|-
! [[Wolfram Alpha]]
| [[Wolfram Research]]
| 
| 2009
| || {{dts|2013}}
| Pro version: $4.99 / month, Pro version for students: $2.99 / month, ioRegular version: free
| {{proprietary}}
| Online [[computer algebra system]] with step-by step solutions.
|-
! [[Xcas]]/[[Giac (software)|Giac]]
| Bernard Parisse
| 2000
| 2000
| 1.2.3 || {{dts|2017|01}}
| {{free}}
| {{free|[[GPL]]}}
| General CAS, also adapted for the [[HP Prime]]. Compatible modes for Maple, MuPAD and TI89 syntax. Symbolic spreadsheets, Giac library for use with other programs. ARM ports for some PDAs with Linux or [[WinCE]]&lt;ref&gt;{{cite web
|url=http://www-fourier.ujf-grenoble.fr/~parisse/install_en#xcaswince
|title=Xcas ARM
|accessdate=2010-10-12
|format=
|work=
}}&lt;/ref&gt;
|-
! [[Yacas]]
| Ayal Pinkus et al.
| 1998&lt;ref&gt;{{cite web | url=http://yacas.sourceforge.net/homepage.html?recent.html&amp;newdesign.html | title=Big changes ahead for Yacas | accessdate=2011-04-19}}&lt;/ref&gt;
| 1999
| 1.6.1 || {{dts|2016|11|08|format=dmy}}
| {{free}}
| {{GPL-lic}}
|
|- class="sortbottom"
! style="width: 12em"|
! Creator
! Development started
! First public release
! Latest stable version
! Latest stable release date
! Cost ([[United States dollar|USD]])
! License
! Notes
|}

These computer algebra systems are sometimes combined with "front end" programs that provide a better user interface, such as the general-purpose [[GNU TeXmacs]].

===Functionality===
Below is a summary of significantly developed ''symbolic'' functionality in each of the systems.

{| class="wikitable" style="font-size: smaller; text-align: center; width: auto;" class="wikitable sortable"
|-
! rowspan="2" | System
! rowspan="2" | [[Formula editor]]
! rowspan="2" | [[Arbitrary precision]]
! colspan="2" | [[Calculus]]
! colspan="5" | [[Solver (computer science)|Solvers]]
! rowspan="2" | [[Graph theory]]
! rowspan="2" | [[Number theory]]
! rowspan="2" | [[Quantifier elimination]]
! rowspan="2" | [[Boolean algebra (logic)|Boolean algebra]]
! rowspan="2" | [[Tensors]]
! rowspan="2" | [[Probability]]
! rowspan="2" | [[Control theory]]
! rowspan="2" | [[Coding theory]]
! rowspan="2" | [[Group theory]]
! rowspan="2" | System
|-
! [[Integral|Integration]]
! [[Integral transform]]s
! [[Equation]]s
! [[Inequality (mathematics)|Inequalities]]
! [[Diophantine equation]]s
! [[Differential equation]]s
! [[Recurrence relation]]s
|-
| [[Axiom (computer algebra system)|Axiom]]
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes}}
| [[Axiom (computer algebra system)|Axiom]]
|-
| [[Cadabra (computer program)|Cadabra]]
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{yes}}
| [[Cadabra (computer program)|Cadabra]]
|-
| [[FriCAS]]
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes}}
| [[FriCAS]]
|-
| [[Magma (computer algebra system)|Magma]]
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{dunno}}
| {{dunno}}
| {{yes}}
| {{yes}}
| [[Magma (computer algebra system)|Magma]]
|-
| [[Magnus (computer algebra system)|Magnus]]
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{dunno}}
| {{dunno}}
| {{no}}
| {{dunno}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{yes}}
| [[Magnus (computer algebra system)|Magnus]]
|-
| [[Maple (software)|Maple]]
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| [[Maple (software)|Maple]]
|-
| [[Mathcad]]
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| [[Mathcad]]
|-
| [[Mathematica]]
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}&lt;ref&gt;{{cite web|url=http://reference.wolfram.com/mathematica/guide/SymbolicTensors.html|title=Symbolic Tensors|publisher=Mathematica Documentation|accessdate=2014-07-03}}&lt;/ref&gt;
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| [[Mathematica]]
|-
| [[Mathomatic]]
| {{no}}
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| [[Mathomatic]]

|-
| Symbolic Math Toolbox ([[MATLAB]])
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
| {{yes}}
| {{yes}}
| {{no}}
| {{no}}
| Symbolic Math Toolbox ([[MATLAB]])
|-
| [[Maxima (software)|Maxima]]
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| [[Maxima (software)|Maxima]]
|-
| [[SageMath]]
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}{{ref label|sagedio|A|^}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{yes}}
| [[SageMath]]
|-
| [[SMath Studio]]
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| [[SMath Studio]]
|-
| [[SymPy]]
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}&lt;ref&gt;{{cite web|url=https://github.com/sympy/sympy/wiki/release-notes-for-0.7.4|title=SymPy release notes for 0.7.4|publisher=[[GitHub]]|accessdate=2014-07-03}}&lt;/ref&gt;
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes}}
| [[SymPy]]
|-
| [[Wolfram Alpha]]
| Pro version only
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{dunno}}
| {{dunno}}
| {{no}}
| {{yes}}
| [[Wolfram Alpha]]
|-
| [[GAP (computer algebra system)|GAP]]
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes}}
| {{yes}}
| [[GAP (computer algebra system)|GAP]]
|-
| [[Xcas]]/[[Giac (software)|Giac]]
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{yes}}
| {{dunno}}
| {{no}}
| {{dunno}}
| [[Xcas]]/[[Giac (software)|Giac]]
|-
| [[Yacas]]
| {{no}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{dunno}}
| {{dunno}}
| {{no}}
| {{no}}
| [[Yacas]]
|-
| [[Reduce (computer algebra system)|Reduce]]
| {{no}}
| {{yes}}
| {{yes}}
| {{dunno}}
| {{yes}}
| {{yes}}
| {{dunno}}
| {{yes}}
| {{dunno}}
| {{dunno}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{dunno}}
| {{dunno}}
| {{dunno}}
| {{dunno}}
|[[Reduce (computer algebra system)|Reduce]]
|}
{|
&lt;ol type="A"&gt;
&lt;li&gt;{{note label|sagedio|A|^}} via SymPy
&lt;/ol&gt;
|}
Those which do not "edit equations" may have a [[GUI]], plotting, ASCII graphic formulae and math font printing. The ability to generate plaintext files is also a sought-after feature because it allows a work to be understood by people who do not have a computer algebra system installed.

===Operating system support===
The software can run under their respective [[operating system]]s natively without [[emulator|emulation]]. Some systems must be compiled first using an appropriate compiler for the source language and target platform. For some platforms, only older releases of the software may be available.

{| class="wikitable" style="font-size: smaller; text-align: center; width: auto;" class="wikitable sortable"
|-
! style="width: 12em" | System
! [[DOS]]
! [[Microsoft Windows|Windows]]
! [[macOS]]
! [[Linux]]
! [[Berkeley Software Distribution|BSD]]
! [[Solaris (operating system)|Solaris]]
! [[Android (operating system)|Android]]
! [[iOS]]
| [[Software_as_a_service|SaaS]]
! Other
|-
! [[Axiom (computer algebra system)|Axiom]]
| {{dunno}}
| {{No|Emulator}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[Cadabra (computer program)|Cadabra]]
| {{no}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{no}}
| {{no}}
| {{No}}
|-
! [[CoCoA]]
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{dunno}}
| {{No}}
| [[Tru64 UNIX]], [[HP-UX]], [[IRIX]]
|-
! [[Derive (computer algebra system)|Derive]]
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[Erable]]
| {{No}}
| {{No|Emulator}}
| {{No|Emulator}}
| {{No|Emulator}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
| [[System RPL]] on [[HP-48 series|HP 48]]/[[HP-49 series|49]]/[[HP 50g|50]]/[[HP-39 series|40]] series
|-
! [[Euler (software)|Euler]]
| {{dunno}}
| {{Yes}}
| {{No}}
| {{Yes}}
| {{No}}
| {{No}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[Fermat (computer algebra system)|Fermat]]
| {{dunno}}
| {{No|[[Cygwin]]}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[FORM (symbolic manipulation system)|FORM]]
| {{dunno}}
| {{No|[[Cygwin]]}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[FriCAS]]
| {{dunno}}
| {{Yes|[[Cygwin]]+native}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[GAP (computer algebra system)|GAP]]
| {{dunno}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[KANT (mathematics)|KANT/KASH]]
| {{dunno}}
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{no}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[Macaulay2]]
| {{dunno}}
| {{No|[[Cygwin]]}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[Magma (computer algebra system)|Magma]]
| {{dunno}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[Magnus (computer algebra system)|Magnus]]
| {{No}}
| {{Yes}}
| {{dunno}}
| {{Yes}}
| {{dunno}}
| {{Yes}}
| {{No}}
| {{No}}
| {{No}}
| [[Sunos|SunOs]]
|-
! [[Maple (software)|Maple]]
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
|-
! [[Mathcad]]
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
|-
! [[Mathematica]]
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
| {{Yes}}
| [[Raspberry Pi]]&lt;ref name="Mathematica-Raspberry_Pi"/&gt;
|-
! [[Mathomatic]]
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{Yes}}
| {{No}}
| All [[POSIX]] platforms
|-
! [[Maxima (software)|Maxima]]
| {{dunno}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{No}}
| All POSIX platforms with [[Common Lisp]]
|-
! [[MuMATH]]
| {{Yes}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[OpenAxiom]]
| {{dunno}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[PARI/GP]]
| {{dunno}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{No}}
|-
! [[Reduce (computer algebra system)|Reduce]]
| {{dunno}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[SageMath]]
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| 
|-
! [[SINGULAR]]
| {{dunno}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! [[SMath Studio]]
| {{No}}
| {{Yes}}
| {{Yes|[[Mono (software)|Mono]]}}
| {{Yes|[[Mono (software)|Mono]]}}
| {{Yes|[[Mono (software)|Mono]]}}
| {{Yes|[[Mono (software)|Mono]]}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| [[Universal Windows Platform]]
|-
! [[SymbolicC++]]
| {{dunno}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{dunno}}
| {{No}}
|-
! Symbolic Math Toolbox ([[MATLAB]])
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
| {{Yes}}
|-
! [[SymPy]]
| {{dunno}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}&lt;ref&gt;Through [http://www.sympygamma.com/ SymPy Gamma]&lt;/ref&gt;
| Any system that supports [[Python (programming language)|Python]]
|-
! [[TI-Nspire]] (desktop software)
| {{No}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{No}}
| {{No}}
| {{Yes}}
| {{No}}
|-
! [[Xcas]]/[[Giac (software)|Giac]]
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{No}}
| [[HP Prime CAS]], [[KhiCAS]] for TI Nspire
|-
! [[Yacas]]
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{dunno}}
| {{dunno}}
| {{No}}
|}

==Graphing calculators==
Some [[graphing calculator]]s have CAS features.

{| class="wikitable sortable" style="font-size: smaller; text-align: center; width: auto;"
|-
! style="width: 12em" | System
! Creator
! Development started
! First public release / OS version
! Latest stable version / OS version
! Notes
|-
! [[Casio graphic calculators#9850 series (9750/9850/9950/9970)|Casio CFX-9970G]]
| [[Casio|CASIO Computer Co.]]
| {{dunno}}
| 1998
|
|
|-
! [[Casio graphic calculators#Algebra FX series|Casio Algebra FX 2.0]]
| CASIO Computer Co.
| {{dunno}}
| 1999
|
|
|-
! [[Casio ClassPad 300]], [[Casio ClassPad 300|Casio ClassPad 300 Plus]], [[Casio ClassPad 330]], [[Casio ClassPad 300|Casio ClassPad 330 Plus]], [[Casio ClassPad 300|Casio ClassPad fx-CP400]] &lt;br/&gt;Casio ClassPad Manager
| [[Casio|CASIO Computer Co.]]
| 2002
| 2003
| 3.06.4000
| ClassPad Manager is an emulator which runs on a PC.
|- 
! [[HP 49G]], [[HP 49g+]], [[HP 48gII]], [[HP 50g]], [[HP 40G]], [[HP 40gs]]
| [[Hewlett-Packard]]
| 1993&lt;!-- start of ALGB/Erable development, not the HP integration --&gt;
| 1.??&lt;!-- first 49G firmware version --&gt;(1999)&lt;!-- introduction of 49G, not first release of Erable --&gt;&amp;nbsp;/ 4&lt;!-- first integrated Erable version --&gt;
| 2.15&lt;!-- firmware version --&gt; (2006-09-19, 2009-04-21) / 4&lt;!-- CAS version --&gt;
| Based on [[Erable]], which is also available as an add-on for the [[HP 48S]], [[HP 48SX]], [[HP 48G]], [[HP 48G+]], [[HP 48GX]]. Intended for problems which occur in engineering applications. Source code openly available.
|-
! [[HP Prime]]
| [[Hewlett-Packard]]
| 2000&lt;!-- start of Xcas/Giac development, not the HP Prime adaptation --&gt;
| 2013&lt;!-- introduction of the HP Prime --&gt;
| 6975 (2014-12-03) / v1.1.0-46 (2014-03-31)
| Based on [[Xcas]]/[[Giac (software)|Giac]]. Source code openly available.
|-
! [[TI-89]]
| [[Texas Instruments]]
| 1995
| 1996
| 2.09
|
|-
! [[TI-89 Titanium]]
| [[Texas Instruments]]
| 2003
| 2004
| 7/18/2005 v3.10
|
|-
! [[TI-92]]
| [[Texas Instruments]]
| 1994
| 1995
| {{dunno}}
|
|-
! [[TI-92 Plus]]
| [[Texas Instruments]]
| 1997
| 1998
| 3/27/2003 v2.09
|
|-
! [[TI-Nspire CAS]], [[TI-Nspire series|TI-Nspire CX CAS]]
| [[Texas Instruments]]
| 2006
| 2008
| 2014 v3.6.0.550
|
|-
! [[Voyage 200]]
| [[Texas Instruments]]
| 2001
| 2002
| 7/18/2005 v3.10
|
|}

&lt;references group="h" /&gt;

==See also==
* [[:Category:Computer algebra systems]]
* [[Comparison of numerical analysis software]]
* [[Comparison of statistical packages]]
* [[List of information graphics software]]
* [[List of numerical analysis software]]
* [[List of numerical libraries]]
* [[List of statistical packages]]
* [[Mathematical software]]
* [[Web-based simulation]]

==References==
{{Reflist}}

==External links==
* {{webarchive |url=https://web.archive.org/web/20110718004430/http://directory.google.com/Top/Science/Math/Algebra/Software/ |date=July 18, 2011 |title=Google Directory - Science &gt; Math &gt; Algebra &gt; Software }}
* {{dmoz|Science/Math/Software|Math Software}}
* [http://www.cs.ru.nl/~freek/digimath/xindex.html Alphabetically sorted list compiled by Freed Wiedijk]
* [http://www.mat.univie.ac.at/~slc/divers/software.html Combinatorial Software and Databases] (Séminaire Lotharingien de Combinatoire)
* [http://axiom-wiki.newsynthesis.org/RosettaStone Rosetta Stone for Computer Algebra Systems]
{{Computer algebra systems}}

[[Category:Comparisons of mathematical software|Computer algebra systems]]
[[Category:Computer algebra systems|Comparison]]
[[Category:Mathematics-related lists|Computer algebra systems]]</text>
      <sha1>5yjmku5py8icup6scfhyvqmwsmhfh1y</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after Joseph Fourier</title>
    <ns>0</ns>
    <id>43667725</id>
    <revision>
      <id>757543828</id>
      <parentid>751985221</parentid>
      <timestamp>2016-12-31T07:34:34Z</timestamp>
      <contributor>
        <username>Zingvin</username>
        <id>29985174</id>
      </contributor>
      <comment>added [[Category:Joseph Fourier]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2086">This is a '''list of things named after Joseph Fourier''':

==Mathematics==
*[[Budan–Fourier theorem]], see [[Budan's theorem]]
*[[Fourier's theorem]]
*[[Fourier–Motzkin elimination]]
* [[Fourier algebra]] 
*[[Fourier division]]

===Analysis===
*[[Fourier analysis]]
*[[Fourier series]] ([[Generalized Fourier series]])
**[[Fourier–Bessel series]]
**Laplace–Fourier series, see [[Laplace series]]
**Legendre–Fourier series, see [[Laplace series]]
*[[Fourier transform]] ([[List of Fourier-related transforms]]):
***[[Discrete-time Fourier transform]] (DTFT), the reverse of the Fourier series, a special case of the Z-transform around the unit circle in the complex plane
***[[Discrete Fourier transform]] (DFT), occasionally called the finite Fourier transform, the Fourier transform of a discrete periodic sequence (yielding discrete periodic frequencies), which can also be thought of as the DTFT of a finite-length sequence evaluated at discrete frequencies
***[[Fast Fourier transform]] (FFT), a fast algorithm for computing a Discrete Fourier transform
***[[Finite Fourier transform (disambiguation)|Finite Fourier transform]]&lt;!--DFT already listed separately--&gt;
***[[Fractional Fourier transform]] (FRFT), a linear transformation generalizing the Fourier transform, used in the area of harmonic analysis
** [[Fourier–Deligne transform]] 
** [[Fourier–Mukai transform]]

==In physics and engineering==
*[[Fourier's law of heat conduction]]
*[[Fourier number]] (&lt;math&gt;\mathit{Fo}&lt;/math&gt;) (also known as the Fourier modulus), a ratio &lt;math&gt;\alpha t/d^2&lt;/math&gt; of the rate of heat conduction &lt;math&gt;\alpha t&lt;/math&gt; to the rate of thermal energy storage &lt;math&gt;d^2&lt;/math&gt;
*[[Fourier optics]]
*[[Fourier transform spectroscopy]], a measurement technique whereby spectra are collected based on measurements of the temporal coherence of a radiative source

==Other==
*[[Joseph Fourier University]] 
*[[10101 Fourier]]

==See also==
*[[Fourier (disambiguation)]]
*{{Intitle|Fourier}}

[[Category:Lists of things named after mathematicians|Fourier]]
[[Category:Joseph Fourier]]</text>
      <sha1>c6psxsw2td3sxq3jhd0nb6hmsbmvx83</sha1>
    </revision>
  </page>
  <page>
    <title>Maris–McGwire–Sosa pair</title>
    <ns>0</ns>
    <id>2470260</id>
    <revision>
      <id>832706746</id>
      <parentid>813065732</parentid>
      <timestamp>2018-03-27T15:18:33Z</timestamp>
      <contributor>
        <username>DePiep</username>
        <id>199625</id>
      </contributor>
      <minor/>
      <comment>OEIS in external links: use dedicated {{OEIS el}} template (via [[WP:JWB]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2736">{{Redirect|MMS pair|the pairing used in medicinal chemistry|Matched molecular pair analysis}}
In [[recreational mathematics]], '''Maris–McGwire–Sosa pairs''' ('''MMS pairs''', also '''MMS numbers''')&lt;ref name="cad"&gt;{{cite web|url=http://www.cadaeic.net/maris.htm|title=Maris-McGwire-Sosa Numbers|first=Mike|last=Keith|authorlink=Mike Keith (mathematician) | year=1998|website=cadeic.net|accessdate=6 June 2017}}&lt;/ref&gt; {{OEIS|id=A045759}} are two consecutive [[natural number]]s such that adding each number's digits (in [[base 10]]) to the digits of its [[prime factorization]] gives the same sum.

:Thus  61 –&gt; 6 + 1 (the sum of its digits) + 6 + 1 (since 61 is its prime factorization)
:and   62 –&gt; 6 + 2 (the sum of its digits) + 3 + 1 + 2 (since 31 &amp;times; 2 is its prime factorization).

The above two sums are equal (= 14), so 61 and 62 form an MMS pair.

MMS pairs are so named because in [[1998 Major League Baseball home run record chase|1998]] the [[baseball]] players [[Mark McGwire]] and [[Sammy Sosa]] both hit their 62nd [[home run]]s for the season, passing the old record of 61, held by [[Roger Maris]]. American engineer [[Mike Keith (mathematician)|Mike Keith]] noticed this property of these numbers and named pairs of numbers like these MMS pairs.&lt;ref&gt;{{cite book
|url=https://books.google.com/books?id=iDUeKkkcy3sC&amp;dq=Maris-McGwire-Sosa+pair&amp;q=mms#v=snippet&amp;q=mms&amp;f=false
|title=Adam Spencer's Book of Numbers
|author=Adam Spencer
|year=2004
|publisher=Thunder's Mouth Press
|p=101
}}&lt;/ref&gt;

==See also==
* [[Ruth-Aaron pair]]

==References==
{{reflist}}

==External links==
*[[Mike Keith (mathematician)|Mike Keith]]. [http://www.cadaeic.net/maris.htm Maris–McGwire–Sosa Numbers].
*[[Ivars Peterson]]. [http://www.maa.org/mathland/mathtrek_9_28_98.html MathTrek – Home Run Numbers]. {{webarchive | url=https://web.archive.org/web/20130702054338/https://www.maa.org/mathland/mathtrek_9_28_98.html | date=2 July 2013}}
*Hans Havermann. [http://chesswanks.com/pxp/seven.html Maris–McGwire–Sosa 7-tuples, 8-tuples, &amp; 9-tuples]
* {{OEIS el|1=A045759|2=Maris-McGwire numbers|formalname=Maris-McGwire numbers: f(n)=f(n+1), where f(n) = sum of digits of n + sum of digits of prime factors of n (including multiplicities)}}
* {{OEIS el|1=A045760|2=Smallest Maris-McGwire k-tuple (k&gt;1)|formalname=Smallest Maris-McGwire k-tuple (k&gt;1) for each k: f(n) = f(n+1) = ... = f(n+k-1), where f is defined in comments}}
* {{OEIS el|1=A039945|2=Maris-McGwire numbers(2)|formalname=Maris-McGwire numbers(2): f(n)=f(n+1), where f(n) = sum of digits of n + sum of digits of prime factors of n}}

{{DEFAULTSORT:Maris-McGwire-Sosa pair}}
[[Category:Base-dependent integer sequences]]
[[Category:Recreational mathematics]]</text>
      <sha1>kc97tuln7rrcnql62w4x0lz4dhg0ymc</sha1>
    </revision>
  </page>
  <page>
    <title>Matroid</title>
    <ns>0</ns>
    <id>244321</id>
    <revision>
      <id>869955831</id>
      <parentid>857867988</parentid>
      <timestamp>2018-11-21T13:05:17Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: isbn. Add: series, volume, location. Removed parameters. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="53611">In [[combinatorics]], a branch of [[mathematics]], a '''matroid''' {{IPAc-en|ˈ|m|eɪ|t|r|ɔɪ|d}} is a structure that abstracts and generalizes the notion of [[linear independence]] in [[vector space]]s. There are many equivalent ways to define a matroid, the most significant being in terms of independent sets, bases, circuits, closed sets or flats, closure operators, and rank functions.

Matroid theory borrows extensively from the terminology of [[linear algebra]] and [[graph theory]], largely because it is the abstraction of various notions of central importance in these fields. Matroids have found applications in geometry, [[topology]], [[combinatorial optimization]], [[network theory]] and [[coding theory]].&lt;ref name=Neel2009&gt;{{cite journal|last1=Neel|first1=David L.|last2=Neudauer|first2=Nancy Ann|title=Matroids you have known|journal=Mathematics Magazine|date=2009|volume=82|issue=1|pages=26–41|url=http://www.maa.org/sites/default/files/pdf/shortcourse/2011/matroidsknown.pdf|accessdate=4 October 2014|doi=10.4169/193009809x469020}}&lt;/ref&gt;&lt;ref name=Kashyap2009&gt;{{cite web|last1=Kashyap|first1=Navin|last2=Soljanin|first2=Emina|last3=Vontobel|first3=Pascal|title=Applications of Matroid Theory and Combinatorial Optimization to Information and Coding Theory|url=https://www.birs.ca/workshops/2009/09w5103/report09w5103.pdf|website=www.birs.ca|accessdate=4 October 2014}}&lt;/ref&gt;

==Definition==&lt;!-- [[Hereditary property (matroid)]] redirects to this section title--&gt;
There are many equivalent ([[Cryptomorphism|cryptomorphic]]) ways to define a (finite) matroid.&lt;ref name="oxley"&gt;A standard source for basic definitions and results about matroids is Oxley (1992).  An older standard source is Welsh (1976).  See Brylawski's appendix in White (1986), pp.&amp;nbsp;298–302, for a list of equivalent axiom systems.&lt;/ref&gt;

===Independent sets===
In terms of independence, a finite matroid &lt;math&gt;M&lt;/math&gt; is a pair &lt;math&gt;(E,\mathcal{I})&lt;/math&gt;, where &lt;math&gt;E&lt;/math&gt; is a [[finite set]] (called the '''ground set''') and &lt;math&gt;\mathcal{I}&lt;/math&gt; is a [[family of sets|family]] of [[subset]]s of &lt;math&gt;E&lt;/math&gt; (called the '''independent sets''') with the following properties:&lt;ref name="w7-9"&gt;{{harvtxt|Welsh|1976}}, Section 1.2, "Axiom Systems for a Matroid", pp. 7–9.&lt;/ref&gt;
# The [[empty set]] is independent, i.e., &lt;math&gt;\emptyset\in\mathcal{I}&lt;/math&gt;. Alternatively, at least one subset of &lt;math&gt;E&lt;/math&gt; is independent, i.e., &lt;math&gt;\mathcal{I}\neq\emptyset&lt;/math&gt;.
# Every subset of an independent set is independent, i.e., for each &lt;math&gt;A'\subset A\subset E&lt;/math&gt;, if &lt;math&gt;A\in\mathcal{I}&lt;/math&gt; then &lt;math&gt;A'\in\mathcal{I}&lt;/math&gt;.  This is sometimes called the '''hereditary property'''.
# If &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; are two independent sets (i.e., each set is independent) and &lt;math&gt;A&lt;/math&gt; has more elements than &lt;math&gt;B&lt;/math&gt;, then there exists &lt;math&gt;x\in A \backslash B&lt;/math&gt; such that &lt;math&gt;B \cup \{x\}&lt;/math&gt; is in &lt;math&gt;\mathcal{I}&lt;/math&gt;. This is sometimes called the '''augmentation property''' or the '''independent set exchange property'''.

The first two properties define a combinatorial structure known as an [[independence system]] (or [[abstract simplicial complex]]).

===Bases and circuits===
A subset of the ground set &lt;math&gt;E&lt;/math&gt; that is not independent is called '''dependent'''.  A maximal independent set—that is, an independent set which becomes dependent on adding any element of &lt;math&gt;E&lt;/math&gt;—is called a '''basis''' for the matroid. A '''circuit''' in a matroid &lt;math&gt;M&lt;/math&gt; is a minimal dependent subset of &lt;math&gt;E&lt;/math&gt;—that is, a dependent set whose proper subsets are all independent.  The terminology arises because the circuits of [[graphic matroid]]s are cycles in the corresponding graphs.&lt;ref name="w7-9"/&gt;

The dependent sets, the bases, or the circuits of a matroid characterize the matroid completely: a set is independent if and only if it is not dependent, if and only if it is a subset of a basis, and if and only if it does not contain a circuit. The collection of dependent sets, or of bases, or of circuits each has simple properties that may be taken as axioms for a matroid.  For instance, one may define a matroid &lt;math&gt;M&lt;/math&gt; to be a pair &lt;math&gt;(E,\mathcal{B})&lt;/math&gt;, where &lt;math&gt;E&lt;/math&gt; is a finite set as before and &lt;math&gt;\mathcal{B}&lt;/math&gt; is a collection of subsets of &lt;math&gt;E&lt;/math&gt;, called "bases", with the following properties:&lt;ref name="w7-9"/&gt;
# &lt;math&gt;\mathcal{B}&lt;/math&gt; is nonempty.
# If &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; are distinct members of &lt;math&gt;\mathcal{B}&lt;/math&gt; and &lt;math&gt;a\in A\setminus B&lt;/math&gt;, then there exists an element &lt;math&gt;b\in B\setminus A&lt;/math&gt; such that &lt;math&gt;A \setminus \{ a \} \cup \{b\} \in \mathcal{B}&lt;/math&gt;.  This property is called the '''basis exchange property'''.
It follows from the basis exchange property that no member of &lt;math&gt;\mathcal{B}&lt;/math&gt; can be a proper subset of another.

===Rank functions===
It is a basic result of matroid theory, directly analogous to a similar theorem of [[basis (linear algebra)|bases in linear algebra]], that any two bases of a matroid &lt;math&gt;M&lt;/math&gt; have the same number of elements.  This number is called the '''[[matroid rank|rank]]''' of&amp;nbsp;&lt;math&gt;M&lt;/math&gt;. If &lt;math&gt;M&lt;/math&gt; is a matroid on &lt;math&gt;E&lt;/math&gt;, and &lt;math&gt;A&lt;/math&gt; is a subset of &lt;math&gt;E&lt;/math&gt;, then a matroid on &lt;math&gt;A&lt;/math&gt; can be defined by considering a subset of &lt;math&gt;A&lt;/math&gt; to be independent if and only if it is independent in &lt;math&gt;M&lt;/math&gt;. This allows us to talk about '''submatroids''' and about the rank of any subset of &lt;math&gt;E&lt;/math&gt;. The rank of a subset &lt;math&gt;A&lt;/math&gt; is given by the '''[[matroid rank|rank function]]''' &lt;math&gt;r(A)&lt;/math&gt; of the matroid, which has the following properties:&lt;ref name="w7-9"/&gt;
*The value of the rank function is always a non-negative [[integer]].
*For any subset &lt;math&gt;A&lt;/math&gt; of &lt;math&gt;E&lt;/math&gt;, &lt;math&gt;r(A) \le |A|&lt;/math&gt;.
*For any two subsets &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; of &lt;math&gt;E&lt;/math&gt;, &lt;math&gt;r(A\cup B)+r(A\cap B)\le r(A)+r(B)&lt;/math&gt;. That is, the rank is a [[submodular function]].
*For any set &lt;math&gt;A&lt;/math&gt; and element &lt;math&gt;x&lt;/math&gt;, &lt;math&gt;r(A)\le r(A\cup\{x\})\le r(A)+1&lt;/math&gt;. From the first of these two inequalities it follows more generally that, if &lt;math&gt;A\subset B\subset E&lt;/math&gt;, then &lt;math&gt;r(A)\leq r(B)\leq r(E)&lt;/math&gt;. That is, the rank is a [[monotonic function]].
These properties can be used as one of the alternative definitions of a finite matroid: if &lt;math&gt;(E,r)&lt;/math&gt; satisfies these properties, then the independent sets of a matroid over &lt;math&gt;E&lt;/math&gt; can be defined as those subsets &lt;math&gt;A&lt;/math&gt; of &lt;math&gt;E&lt;/math&gt; with &lt;math&gt;r(A)=|A|&lt;/math&gt;.

The difference &lt;math&gt;|A|-r(A)&lt;/math&gt; is called the '''nullity''' or '''corank''' of the subset &lt;math&gt;A&lt;/math&gt;. It is the minimum number of elements that must be removed from &lt;math&gt;A&lt;/math&gt; to obtain an independent set. The nullity of &lt;math&gt;E&lt;/math&gt; in &lt;math&gt;M&lt;/math&gt; is called the nullity or corank of &lt;math&gt;M&lt;/math&gt;.

===Closure operators===
Let &lt;math&gt;M&lt;/math&gt; be a matroid on a finite set &lt;math&gt;E&lt;/math&gt;, with rank function &lt;math&gt;r&lt;/math&gt; as above.  The '''closure'''  &lt;math&gt;\operatorname{cl}(A)&lt;/math&gt;  of a subset &lt;math&gt;A&lt;/math&gt; of &lt;math&gt;E&lt;/math&gt; is the set
:&lt;math&gt;\operatorname{cl}(A) = \Bigl\{x\in E\mid r(A)=r\bigl(A\cup\{x\}\bigr)\Bigr\}&lt;/math&gt;.
This defines a [[closure operator]] &lt;math&gt;\operatorname{cl}: \mathcal{P}(E)\to \mathcal{P}(E)&lt;/math&gt; where &lt;math&gt;\mathcal{P}&lt;/math&gt; denotes the [[power set]], with the following properties:
* For all subsets &lt;math&gt;X&lt;/math&gt; of &lt;math&gt;E&lt;/math&gt;, &lt;math&gt;X\subseteq \operatorname{cl}(X)&lt;/math&gt;.
* For all subsets &lt;math&gt;X&lt;/math&gt; of &lt;math&gt;E&lt;/math&gt;, &lt;math&gt;\operatorname{cl}(X)= \operatorname{cl}(\operatorname{cl}(X))&lt;/math&gt;.
* For all subsets &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; of &lt;math&gt;E&lt;/math&gt; with &lt;math&gt;X\subseteq Y&lt;/math&gt;, &lt;math&gt;\operatorname{cl}(X)\subseteq \operatorname{cl}(Y)&lt;/math&gt;.
* For all elements &lt;math&gt;a&lt;/math&gt;, and &lt;math&gt;b&lt;/math&gt; of &lt;math&gt;E&lt;/math&gt;  and all subsets &lt;math&gt;Y&lt;/math&gt; of &lt;math&gt;E&lt;/math&gt;, if &lt;math&gt;a\in\operatorname{cl}(Y\cup \{b\}) \setminus \operatorname{cl}(Y)&lt;/math&gt; then &lt;math&gt;b\in\operatorname{cl}(Y\cup \{a\}) \setminus \operatorname{cl}(Y)&lt;/math&gt;.
The first three of these properties are the defining properties of a closure operator. The fourth is sometimes called the '''Mac Lane–Steinitz exchange property'''. These properties may be taken as another definition of matroid: every function &lt;math&gt;\operatorname{cl}: \mathcal{P}(E)\to \mathcal{P}(E)&lt;/math&gt; that obeys these properties determines a matroid.&lt;ref name="w7-9"/&gt;

===Flats===
A set whose closure equals itself is said to be '''closed''', or a '''flat''' or '''subspace''' of the matroid.&lt;ref&gt;{{harvtxt|Welsh|1976}}, Section 1.8, "Closed sets = Flats = Subspaces", pp. 21–22.&lt;/ref&gt;  A set is closed if it is [[maximal element|maximal]] for its rank, meaning that the addition of any other element to the set would increase the rank. The closed sets of a matroid are characterized by a covering partition property:
* The whole point set &lt;math&gt;E&lt;/math&gt; is closed.
* If &lt;math&gt;S&lt;/math&gt; and &lt;math&gt;T&lt;/math&gt; are flats, then &lt;math&gt;S\cap T&lt;/math&gt; is a flat.
* If &lt;math&gt;S&lt;/math&gt; is a flat, then the flats &lt;math&gt;T&lt;/math&gt; that [[Covering relation|cover]] &lt;math&gt;S&lt;/math&gt; (meaning that &lt;math&gt;T&lt;/math&gt; properly contains &lt;math&gt;S&lt;/math&gt; but there is no flat &lt;math&gt;U&lt;/math&gt; between &lt;math&gt;S&lt;/math&gt; and &lt;math&gt;T&lt;/math&gt;), partition the elements of&amp;nbsp;&lt;math&gt;E\setminus S&lt;/math&gt;.

The class &lt;math&gt;\mathcal{L}(M)&lt;/math&gt; of all flats, [[partially ordered set|partially ordered]] by set inclusion, forms a [[matroid lattice]].
Conversely, every matroid lattice &lt;math&gt;L&lt;/math&gt; forms a matroid over its set &lt;math&gt;E&lt;/math&gt; of [[Atom (order theory)|atoms]] under the following closure operator:  for a set &lt;math&gt;S&lt;/math&gt; of atoms with join &lt;math&gt;\bigvee S&lt;/math&gt;,
:&lt;math&gt;\operatorname{cl}(S) = \{ x\in E\mid x\le\bigvee S \}&lt;/math&gt;.
The flats of this matroid correspond one-for-one with the elements of the lattice; the flat corresponding to lattice element &lt;math&gt;y&lt;/math&gt; is the set
:&lt;math&gt;\{ x\in E\mid x\le y\}&lt;/math&gt;.
Thus, the lattice of flats of this matroid is naturally isomorphic to&amp;nbsp;&lt;math&gt;L&lt;/math&gt;.

===Hyperplanes===
In a matroid of rank &lt;math&gt;r&lt;/math&gt;, a flat of rank &lt;math&gt;r-1&lt;/math&gt; is called a '''hyperplane'''.  (Hyperplanes are also called '''coatoms''' or '''copoints'''.) These are the maximal proper flats; that is, the only superset of a hyperplane that is also a flat is the set &lt;math&gt;E&lt;/math&gt; of all the elements of the matroid.  An equivalent definition:  A coatom is a subset of ''E'' that does not span ''M'', but such that adding any other element to it does make a spanning set.&lt;ref name="w38-39"&gt;{{harvtxt|Welsh|1976}}, Section 2.2, "The Hyperplanes of a Matroid", pp. 38–39.&lt;/ref&gt;

The family &lt;math&gt;\mathcal{H}&lt;/math&gt; of hyperplanes of a matroid has the following properties, which may be taken as yet another axiomatization of matroids:&lt;ref name="w38-39"/&gt;
*There do not exist distinct sets &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; in &lt;math&gt;\mathcal{H}&lt;/math&gt; with &lt;math&gt;X\subset Y&lt;/math&gt;. That is, the hyperplanes form a [[Sperner family]].
*For every &lt;math&gt;x\in E&lt;/math&gt; and distinct &lt;math&gt;Y,Z\in\mathcal{H}&lt;/math&gt; with &lt;math&gt;x\notin Y\cup Z&lt;/math&gt;, there exists &lt;math&gt;X\in\mathcal{H}&lt;/math&gt; with &lt;math&gt;(Y\cap Z)\cup\{x\}\subseteq X&lt;/math&gt;.

===Graphoids===

Minty (1966) defined a '''graphoid''' as a triple &lt;math&gt;(L, C, D)&lt;/math&gt; in which &lt;math&gt;C&lt;/math&gt; and &lt;math&gt;D&lt;/math&gt; are classes of nonempty subsets of &lt;math&gt;L&lt;/math&gt; such that 
*no element of &lt;math&gt;C&lt;/math&gt; (called a "circuit") contains another, 
*no element of &lt;math&gt;D&lt;/math&gt; (called a "cocircuit") contains another, 
*no set in &lt;math&gt;C&lt;/math&gt; and set in &lt;math&gt;D&lt;/math&gt; intersect in exactly one element, and 
*whenever &lt;math&gt;L&lt;/math&gt; is represented as the disjoint union of subsets &lt;math&gt;R, G, B&lt;/math&gt; with &lt;math&gt;G=\{g\}&lt;/math&gt; (a singleton set), then either an &lt;math&gt;X \in C&lt;/math&gt; exists such that &lt;math&gt;g \in X \subseteq R \cup G&lt;/math&gt; or a &lt;math&gt;Y \in D&lt;/math&gt; exists such that &lt;math&gt;g \in Y \subseteq B \cup G.&lt;/math&gt;

He proved that there is a matroid for which &lt;math&gt;C&lt;/math&gt; is the class of circuits and &lt;math&gt;D&lt;/math&gt; is the class of cocircuits.  Conversely, if &lt;math&gt;C&lt;/math&gt; and &lt;math&gt;D&lt;/math&gt; are the circuit and cocircuit classes of a matroid &lt;math&gt;M&lt;/math&gt; with ground set &lt;math&gt;E&lt;/math&gt;, then &lt;math&gt;(E, C, D)&lt;/math&gt; is a graphoid.  Thus, graphoids give a self-dual cryptomorphic axiomatization of matroids.

== Examples ==

===Uniform matroids===

Let &lt;math&gt;E&lt;/math&gt; be a finite set and &lt;math&gt;k&lt;/math&gt; a [[natural number]].  One may define a matroid on &lt;math&gt;E&lt;/math&gt; by taking every &lt;math&gt;k&lt;/math&gt;-element subset of &lt;math&gt;E&lt;/math&gt; to be a basis.  This is known as the [[uniform matroid]] of rank &lt;math&gt;k&lt;/math&gt;.  A uniform matroid with rank &lt;math&gt;k&lt;/math&gt; and with &lt;math&gt;n&lt;/math&gt; elements is denoted &lt;math&gt;U_{k,n}&lt;/math&gt;. All uniform matroids of rank at least 2 are simple. The uniform matroid of rank 2 on &lt;math&gt;n&lt;/math&gt; points is called the &lt;math&gt;n&lt;/math&gt;-'''point line'''. A matroid is uniform if and only if it has no circuits of size less than one plus the rank of the matroid. The direct sums of uniform matroids are called [[partition matroid]]s.

In the uniform matroid &lt;math&gt;U_{0,n}&lt;/math&gt;, every element is a loop (an element that does not belong to any independent set), and in the uniform matroid &lt;math&gt;U_{n,n}&lt;/math&gt;, every element is a coloop (an element that belongs to all bases). The direct sum of matroids of these two types is a partition matroid in which every element is a loop or a coloop; it is called a '''discrete matroid'''. An equivalent definition of a discrete matroid is a matroid in which every proper, non-empty subset of the ground set &lt;math&gt;E&lt;/math&gt; is a separator.

===Matroids from linear algebra===
[[File:fano plane.svg|thumb|The Fano matroid, derived from the [[Fano plane]]. It is [[GF(2)]]-linear but not real-linear.]]
[[File:Vamos matroid.svg|thumb|The [[Vámos matroid]], not linear over any field]]
Matroid theory developed mainly out of a deep examination of the properties of independence and dimension in vector spaces.  There are two ways to present the matroids defined in this way:
* If &lt;math&gt;E&lt;/math&gt; is any finite subset of a [[vector space]] &lt;math&gt;V&lt;/math&gt;, then we can define a matroid &lt;math&gt;M&lt;/math&gt; on &lt;math&gt;E&lt;/math&gt; by taking the independent sets of &lt;math&gt;M&lt;/math&gt; to be the [[linear independence|linearly independent]] subsets of &lt;math&gt;E&lt;/math&gt;. The validity of the independent set axioms for this matroid follows from the [[Steinitz exchange lemma]].  If &lt;math&gt;M&lt;/math&gt; is a matroid that can be defined in this way, we say the set &lt;math&gt;E&lt;/math&gt; '''[[matroid representation|represents]]''' &lt;math&gt;M&lt;/math&gt;.  Matroids of this kind are called '''vector matroids'''. An important example of a matroid defined in this way is the Fano matroid, a rank-three matroid derived from the [[Fano plane]], a [[finite geometry]] with seven points (the seven elements of the matroid) and seven lines (the nontrivial flats of the matroid). It is a linear matroid whose elements may be described as the seven nonzero points in a three-dimensional vector space over the [[finite field]] [[GF(2)]]. However, it is not possible to provide a similar representation for the Fano matroid using the [[real number]]s in place of GF(2).
* A [[matrix (mathematics)|matrix]] &lt;math&gt;A&lt;/math&gt; with entries in a [[field (mathematics)|field]] gives rise to a matroid &lt;math&gt;M&lt;/math&gt; on its set of columns.  The dependent sets of columns in the matroid are those that are linearly dependent as vectors.  This matroid is called the '''column matroid''' of &lt;math&gt;A&lt;/math&gt;, and &lt;math&gt;A&lt;/math&gt; is said to '''represent''' &lt;math&gt;M&lt;/math&gt;.  For instance, the Fano matroid can be represented in this way as a 3&amp;nbsp;&amp;times;&amp;nbsp;7 [[Logical matrix|(0,1)-matrix]]. Column matroids are just vector matroids under another name, but there are often reasons to favor the matrix representation.  (There is one technical difference: a column matroid can have distinct elements that are the same vector, but a vector matroid as defined above cannot.  Usually this difference is insignificant and can be ignored, but by letting &lt;math&gt;E&lt;/math&gt; be a [[multiset]] of vectors one brings the two definitions into complete agreement.)

A matroid that is equivalent to a vector matroid, although it may be presented differently, is called '''representable''' or '''linear'''.  If &lt;math&gt;M&lt;/math&gt; is equivalent to a vector matroid over a [[field (mathematics)|field]] &lt;math&gt;F&lt;/math&gt;, then we say &lt;math&gt;M&lt;/math&gt; is '''representable over''' &lt;math&gt;F&lt;/math&gt; &amp;nbsp;; in particular, &lt;math&gt;M&lt;/math&gt; is '''real-representable''' if it is representable over the real numbers.  For instance, although a graphic matroid (see below) is presented in terms of a graph, it is also representable by vectors over any field.  A basic problem in matroid theory is to characterize the matroids that may be represented over a given field &lt;math&gt;F&lt;/math&gt;; [[Rota's conjecture]] describes a possible characterization for every [[finite field]].  The main results so far are characterizations of [[binary matroid]]s (those representable over GF(2)) due to Tutte (1950s), of ternary matroids (representable over the 3-element field) due to Reid and Bixby, and separately to Seymour (1970s), and of quaternary matroids (representable over the 4-element field) due to Geelen, Gerards, and Kapoor (2000).  This is very much an open area.

A [[regular matroid]] is a matroid that is representable over all possible fields. The [[Vámos matroid]] is the simplest example of a matroid that is not representable over any field.

===Matroids from graph theory===
A second original source for the theory of matroids is [[graph theory]].

Every finite graph (or [[multigraph]]) &lt;math&gt;G&lt;/math&gt; gives rise to a matroid &lt;math&gt;M(G)&lt;/math&gt; as follows: take as &lt;math&gt;E&lt;/math&gt; the set of all edges in &lt;math&gt;G&lt;/math&gt; and consider a set of edges independent if and only if it is a [[tree (graph theory)|forest]]; that is, if it does not contain a [[simple cycle]]. Then &lt;math&gt;M(G)&lt;/math&gt; is called a '''cycle matroid'''. Matroids derived in this way are  '''[[graphic matroid]]s'''.  Not every matroid is graphic, but all matroids on three elements are graphic.&lt;ref name=Ox13/&gt;  Every graphic matroid is regular.

Other matroids on graphs were discovered subsequently:
*The [[bicircular matroid]] of a graph is defined by calling a set of edges independent if every connected subset contains at most one cycle.
*In any directed or undirected graph &lt;math&gt;G&lt;/math&gt; let &lt;math&gt;E&lt;/math&gt; and &lt;math&gt;F&lt;/math&gt; be two distinguished sets of vertices.  In the set &lt;math&gt;E&lt;/math&gt;, define a subset &lt;math&gt;U&lt;/math&gt; to be independent if there are |&lt;math&gt;U&lt;/math&gt;| vertex-disjoint paths from &lt;math&gt;F&lt;/math&gt; onto &lt;math&gt;U&lt;/math&gt;.  This defines a matroid on &lt;math&gt;E&lt;/math&gt; called a '''[[gammoid]]''':&lt;ref name=Ox115/&gt; a '''strict gammoid''' is one for which the set &lt;math&gt;E&lt;/math&gt; is the whole vertex set of &lt;math&gt;G&lt;/math&gt;.&lt;ref name=Ox100&gt;{{harvnb|Oxley|1992|p=100}}&lt;/ref&gt;
*In a [[bipartite graph]] &lt;math&gt;G = (U,V,E)&lt;/math&gt;, one may form a matroid in which the elements are vertices on one side &lt;math&gt;U&lt;/math&gt; of the bipartition, and the independent subsets are sets of endpoints of [[Matching (graph theory)|matchings]] of the graph. This is called a '''transversal matroid''',&lt;ref name=Ox4648&gt;{{harvnb|Oxley|1992|pp=46–48}}&lt;/ref&gt;&lt;ref name=Wh877297&gt;{{White|1987|pp=72–97}}&lt;/ref&gt; and it is a special case of a gammoid.&lt;ref name=Ox115&gt;{{harvnb|Oxley|1992|pp=115}}&lt;/ref&gt;  The transversal matroids are the [[dual matroid]]s to the strict gammoids.&lt;ref name=Ox100/&gt;
*Graphic matroids have been generalized to matroids from [[signed graph]]s, [[gain graph]]s, and [[biased graph]]s.  A graph &lt;math&gt;G&lt;/math&gt; with a distinguished linear class &lt;math&gt;B&lt;/math&gt; of cycles, known as a "biased graph" &lt;math&gt;(G, B)&lt;/math&gt;, has two matroids, known as the '''frame matroid''' and the '''lift matroid''' of the biased graph.  If every cycle belongs to the distinguished class, these matroids coincide with the cycle matroid of &lt;math&gt;G&lt;/math&gt;.  If no cycle is distinguished, the frame matroid is the bicircular matroid of &lt;math&gt;G&lt;/math&gt;. A signed graph, whose edges are labeled by signs, and a gain graph, which is a graph whose edges are labeled orientably from a group, each give rise to a biased graph and therefore have frame and lift matroids.
*The [[Laman graph]]s form the bases of the two-dimensional [[rigidity matroid]], a matroid defined in the theory of [[structural rigidity]].
*Let &lt;math&gt;G&lt;/math&gt; be a connected graph and &lt;math&gt;E&lt;/math&gt; be its edge set. Let &lt;math&gt;I&lt;/math&gt; be the collection of subsets &lt;math&gt;F&lt;/math&gt; of &lt;math&gt;E&lt;/math&gt; such that &lt;math&gt;G - F&lt;/math&gt; is still connected. Then &lt;math&gt;M^*(G)&lt;/math&gt;, whose element set is &lt;math&gt;E&lt;/math&gt; and with &lt;math&gt;I&lt;/math&gt; as its class of independent sets, is a matroid called the '''bond matroid''' of &lt;math&gt;G&lt;/math&gt;.  The rank function &lt;math&gt;r(F)&lt;/math&gt; is the [[cyclomatic number]] of the subgraph induced on the edge subset &lt;math&gt;F&lt;/math&gt;, which equals the number of edges outside a maximal forest of that subgraph, and also the number of independent cycles in it.

===Matroids from field extensions===
A third original source of matroid theory is [[field theory (mathematics)|field theory]].

An [[extension field|extension]] of a field gives rise to a matroid.  Suppose &lt;math&gt;F&lt;/math&gt; and &lt;math&gt;K&lt;/math&gt; are fields with &lt;math&gt;K&lt;/math&gt; containing &lt;math&gt;F&lt;/math&gt;.  Let &lt;math&gt;E&lt;/math&gt; be any finite subset of &lt;math&gt;K&lt;/math&gt;.  Define a subset &lt;math&gt;S&lt;/math&gt; of &lt;math&gt;E&lt;/math&gt; to be [[algebraic independence|algebraically independent]] if the extension field &lt;math&gt;F(S)&lt;/math&gt; has [[transcendence degree]] equal to &lt;math&gt;|S|&lt;/math&gt;.&lt;ref name=Ox215&gt;{{harvnb|Oxley|1992|p=215}}&lt;/ref&gt;

A matroid that is equivalent to a matroid of this kind is called an [[algebraic matroid]].&lt;ref name=Ox216&gt;{{harvnb|Oxley|1992|p=216}}&lt;/ref&gt;  The problem of characterizing algebraic matroids is extremely difficult; little is known about it. The [[Vámos matroid]] provides an example of a matroid that is not algebraic.

== Basic constructions ==
There are some standard ways to make new matroids out of old ones.

===Duality===
If ''M'' is a finite matroid, we can define the '''orthogonal''' or '''[[dual matroid]]''' ''M''* by taking the same underlying set and calling a set a ''basis'' in ''M''* if and only if its complement is a basis in ''M''.  It is not difficult to verify that ''M''* is a matroid and that the dual of ''M''* is ''M''.&lt;ref name=Whi8632&gt;{{harvnb|White|1986|p=32}}&lt;/ref&gt;

The dual can be described equally well in terms of other ways to define a matroid.  For instance:

* A set is independent in ''M''* if and only if its complement spans ''M''.
* A set is a circuit of ''M''* if and only if its complement is a coatom in ''M''.
* The rank function of the dual is &lt;math&gt;r^*(S) = |S|- r(M) + r\left(E\setminus S\right)&lt;/math&gt;.

According to a matroid version of [[Kuratowski's theorem]], the dual of a graphic matroid ''M'' is a graphic matroid if and only if ''M'' is the matroid of a [[planar graph]]. In this case, the dual of ''M'' is the matroid of the [[dual graph]] of ''G''.&lt;ref name=Whi86105&gt;{{harvnb|White|1986|p=105}}&lt;/ref&gt;  The dual of a vector matroid representable over a particular field ''F'' is also representable over ''F''. The dual of a transversal matroid is a strict gammoid and vice versa.

'''Example'''

The cycle matroid of a graph is the dual matroid of its bond matroid.

===Minors===
{{Main|Matroid minor}}
If ''M'' is a matroid with element set ''E'', and ''S'' is a subset of ''E'', the '''restriction''' of ''M'' to ''S'', written ''M''&amp;nbsp;|''S'', is the matroid on the set ''S'' whose independent sets are the independent sets of ''M'' that are contained in ''S''.  Its circuits are the circuits of ''M'' that are contained in ''S'' and its rank function is that of ''M'' restricted to subsets of ''S''. In linear algebra, this corresponds to restricting to the subspace generated by the vectors in ''S''.  Equivalently if ''T'' = ''M''−''S'' this may be termed the '''deletion''' of ''T'', written ''M''\''T'' or ''M''−''T''.   The submatroids of ''M'' are precisely the results of a sequence of deletions: the order is irrelevant.&lt;ref name=Whi86131&gt;{{harvnb|White|1986|p=131}}&lt;/ref&gt;&lt;ref name=Whi86224&gt;{{harvnb|White|1986|p=224}}&lt;/ref&gt;

The dual operation of restriction is contraction.&lt;ref name=Whi866139&gt;{{harvnb|White|1986|p=139}}&lt;/ref&gt; If ''T'' is a subset of ''E'', the '''contraction''' of ''M'' by ''T'', written ''M''/''T'', is the matroid on the underlying set ''E &amp;minus; T'' whose rank function is &lt;math&gt;r'(A) = r(A \cup T) - r(T).&lt;/math&gt;&lt;ref name=Whi86140&gt;{{harvnb|White|1986|p=140}}&lt;/ref&gt;  In linear algebra, this corresponds to looking at the quotient space by the linear space generated by the vectors in ''T'', together with the images of the vectors in ''E - T''.

A matroid ''N'' that is obtained from ''M'' by a sequence of restriction and contraction operations is called a [[matroid minor|minor]] of ''M''.&lt;ref name=Whi86224/&gt;&lt;ref name=Whi86150&gt;{{harvnb|White|1986|p=150}}&lt;/ref&gt;  We say ''M'' '''contains''' ''N'' '''as a minor'''. Many important families of matroids may be characterized by the [[minimal element|minor-minimal]] matroids that do not belong to the family; these are called '''forbidden''' or '''excluded minors'''.&lt;ref name=Whi861467&gt;{{harvnb|White|1986|pp=146–147}}&lt;/ref&gt;

===Sums and unions===
Let ''M'' be a matroid with an underlying set of elements ''E'', and let ''N'' be another matroid on an underlying set ''F''.
The '''direct sum''' of matroids ''M'' and ''N'' is the matroid whose underlying set is the [[disjoint union]] of ''E'' and ''F'', and whose independent sets are the disjoint unions of an independent set of ''M'' with an independent set of ''N''.

The '''union''' of ''M'' and ''N'' is the matroid whose underlying set is the union (not the disjoint union) of ''E'' and ''F'', and whose independent sets are those subsets which are the union of an independent set in ''M'' and one in ''N''.  Usually the term "union" is applied when ''E'' = ''F'', but that assumption is not essential.  If ''E'' and ''F'' are disjoint, the union is the direct sum.

== Additional terminology == &lt;!--Linked to by [[Simple matroid]] (redirect)--&gt;
Let ''M'' be a matroid with an underlying set of elements ''E''.
* ''E'' may be called the '''ground set''' of ''M''.  Its elements may be called the '''points''' of ''M''.
* A subset of ''E'' '''spans''' ''M'' if its closure is ''E''.  A set is said to '''span''' a closed set ''K'' if its closure is ''K''.
* The [[matroid girth|girth]] of a matroid is the size of its smallest circuit or dependent set.
* An element that forms a single-element circuit of ''M'' is called a '''loop'''. Equivalently, an element is a loop if it belongs to no basis.&lt;ref name=Ox13/&gt;&lt;ref name=Wh86130&gt;{{harvnb|White|1986|p=130}}&lt;/ref&gt;
* An element that belongs to no circuit is called a '''coloop''' or '''isthmus'''. Equivalently, an element is a coloop if it belongs to every basis.  Loop and coloops are mutually dual.&lt;ref name=Wh86130/&gt;
* If a two-element set {''f, g''} is a circuit of ''M'', then ''f'' and ''g'' are '''parallel''' in ''M''.&lt;ref name=Ox13/&gt;
* A matroid is called '''simple''' if it has no circuits consisting of 1 or 2 elements.  That is, it has no loops and no parallel elements.  The term '''combinatorial geometry''' is also used.&lt;ref name=Ox13&gt;{{harvnb|Oxley|1992|p=13}}&lt;/ref&gt;  A simple matroid obtained from another matroid ''M'' by deleting all loops and deleting one element from each 2-element circuit until no 2-element circuits remain is called a '''simplification''' of ''M''.&lt;ref name=Ox52&gt;{{harvnb|Oxley|1992|p=52}}&lt;/ref&gt;  A matroid is '''co-simple''' if its dual matroid is simple.&lt;ref name=Ox347&gt;{{harvnb|Oxley|1992|p=347}}&lt;/ref&gt;
* A union of circuits is sometimes called a '''cycle''' of ''M''.  A cycle is therefore the complement of a flat of the dual matroid.  (This usage conflicts with the common meaning of "cycle" in graph theory.)
* A '''separator''' of ''M'' is a subset ''S'' of ''E'' such that &lt;math&gt;r(S) + r(E-S) = r(M)&lt;/math&gt;.  A '''proper''' or '''non-trivial separator''' is a separator that is neither ''E'' nor the empty set.&lt;ref name=Ox128&gt;{{harvnb|Oxley|1992|p=128}}&lt;/ref&gt;  An '''irreducible separator''' is a separator that contains no other non-empty separator.  The irreducible separators partition the ground set ''E''.
* A matroid which cannot be written as the direct sum of two nonempty matroids, or equivalently which has no proper separators, is called '''connected''' or '''irreducible'''.  A matroid is connected if and only if its dual is connected.&lt;ref name=Wh86110&gt;{{harvnb|White|1986|p=110}}&lt;/ref&gt;
* A maximal irreducible submatroid of ''M'' is called a '''component''' of ''M''.  A component is the restriction of ''M'' to an irreducible separator, and contrariwise, the restriction of ''M'' to an irreducible separator is a component.  A separator is a union of components.&lt;ref name=Ox128/&gt;
* A matroid ''M'' is called a '''frame matroid''' if it, or a matroid that contains it, has a basis such that all the points of ''M'' are contained in the lines that join pairs of basis elements.&lt;ref&gt;{{cite journal | zbl=0797.05027 | last=Zaslavsky | first=Thomas | title=Frame matroids and biased graphs | journal=Eur. J. Comb. | volume=15 | number=3 | pages=303–307 | year=1994 | issn=0195-6698 | url=http://www.sciencedirect.com/science/article/pii/S0195669884710341 | doi=10.1006/eujc.1994.1034}}&lt;/ref&gt;
* A matroid is called a [[paving matroid]] if all of its circuits have size at least equal to its rank.&lt;ref name=Ox26&gt;{{harvnb|Oxley|1992|p=26}}&lt;/ref&gt;
* The [[matroid polytope]] &lt;math&gt;P_M&lt;/math&gt; is the [[convex hull]] of the [[indicator vector]]s of the bases of &lt;math&gt;M&lt;/math&gt;.

==Algorithms==

===Greedy algorithm===
A [[weighted matroid]] is a matroid together with a function from its elements to the nonnegative [[real number]]s. The weight of a subset of elements is defined to be the sum of the weights of the elements in the subset. The [[greedy algorithm]] can be used to find a maximum-weight basis of the matroid, by starting from the empty set and repeatedly adding one element at a time, at each step choosing a maximum-weight element among the elements whose addition would preserve the independence of the augmented set.&lt;ref name=Ox63&gt;{{harvnb|Oxley|1992|p=63}}&lt;/ref&gt; This algorithm does not need to know anything about the details of the matroid's definition, as long as it has access to the matroid through an [[matroid oracle|independence oracle]], a subroutine for testing whether a set is independent.

This optimization algorithm may be used to characterize matroids: if a family ''F'' of sets, closed under taking subsets, has the property that, no matter how the sets are weighted, the greedy algorithm finds a maximum-weight set in the family, then ''F'' must be the family of independent sets of a matroid.&lt;ref name=Ox64&gt;{{harvnb|Oxley|1992|p=64}}&lt;/ref&gt;

The notion of matroid has been generalized to allow for other types of sets on which a greedy algorithm gives optimal solutions; see [[greedoid]] and [[matroid embedding]] for more information.

===Matroid partitioning===
The [[matroid partitioning]] problem is to partition the elements of a matroid into as few independent sets as possible, and the matroid packing problem is to find as many disjoint spanning sets as possible. Both can be solved in polynomial time, and can be generalized to the problem of computing the rank or finding an independent set in a matroid sum.

===Matroid intersection===
The [[matroid intersection|intersection]] of two or more matroids is the family of sets that are simultaneously independent in each of the matroids. The problem of finding the largest set, or the maximum weighted set, in the intersection of two matroids can be found in [[polynomial time]], and provides a solution to many other important combinatorial optimization problems. For instance, [[maximum matching]] in [[bipartite graph]]s can be expressed as a problem of intersecting two [[partition matroid]]s. However, finding the largest set in an intersection of three or more matroids is [[NP-complete]].

===Matroid software===

Two standalone systems for calculations with matroids are Kingan's [http://userhome.brooklyn.cuny.edu/skingan/software.html Oid] and Hlineny's [http://www.fi.muni.cz/~hlineny/MACEK/ Macek]. Both of them are open sourced packages. "Oid" is an interactive, extensible software system for experimenting with matroids. "Macek" is a specialized software system with tools and routines for reasonably efficient combinatorial computations with representable matroids.

[[SageMath|SAGE]], the open source mathematics software system, contains a matroid package.

==Polynomial invariants==

There are two especially significant polynomials associated to a finite matroid ''M'' on the ground set ''E''.  Each is a '''matroid invariant''', which means that isomorphic matroids have the same polynomial.

===Characteristic polynomial===

The '''characteristic polynomial''' of ''M'' (which is sometimes called the '''chromatic polynomial''',&lt;ref name=Wh87127/&gt; although it does not count colorings), is defined to be
:&lt;math&gt;p_M(\lambda) := \sum_{S \subseteq E} (-1)^{|S|}\lambda^{r(M)-r(S)},&lt;/math&gt;
or equivalently (as long as the empty set is closed in ''M'') as
:&lt;math&gt;p_M(\lambda) := \sum_{A} \mu(\emptyset,A) \lambda^{r(M)-r(A)} \ ,&lt;/math&gt;
where μ denotes the [[Möbius function (combinatorics)|Möbius function]] of the [[geometric lattice]] of the matroid and the sum is taken over all the flats A of the matroid.&lt;ref name=Wh87120&gt;{{harvnb|White|1987|p=120}}&lt;/ref&gt;

When ''M'' is the cycle matroid ''M''(''G'') of a graph ''G'', the characteristic polynomial is a slight transformation of the [[chromatic polynomial]], which is given by χ&lt;sub&gt;''G''&lt;/sub&gt;&amp;nbsp;(λ) = λ&lt;sup&gt;c&lt;/sup&gt;''p''&lt;sub&gt;''M''(''G'')&lt;/sub&gt;&amp;nbsp;(λ), where ''c'' is the number of connected components of ''G''.

When ''M'' is the bond matroid ''M''*(''G'') of a graph ''G'', the characteristic polynomial equals the [[Tutte polynomial#Flow polynomial|flow polynomial]] of ''G''.

When ''M'' is the matroid ''M''(''A'') of an [[Arrangement of hyperplanes|arrangement]] ''A'' of linear hyperplanes in '''R'''&lt;sup&gt;''n''&lt;/sup&gt; (or ''F''&lt;sup&gt;''n''&lt;/sup&gt; where ''F'' is any field), the characteristic polynomial of the arrangement is given by ''p''&lt;sub&gt;''A''&lt;/sub&gt;&amp;nbsp;(λ) = λ&lt;sup&gt;''n''&amp;minus;''r''(''M'')&lt;/sup&gt;''p''&lt;sub&gt;''M''(''A'')&lt;/sub&gt;&amp;nbsp;(λ).

====Beta invariant====
The '''beta invariant''' of a matroid, introduced by Crapo (1967), may be expressed in terms of the characteristic polynomial ''p'' as an evaluation of the derivative&lt;ref name=Wh87123&gt;{{harvnb|White|1987|p=123}}&lt;/ref&gt;
:&lt;math&gt; \beta(M) = (-1)^{r(M)-1} p_M'(1) \  &lt;/math&gt;
or directly as&lt;ref name=Wh87124&gt;{{harvnb|White|1987|p=124}}&lt;/ref&gt;
:&lt;math&gt; \beta(M) = (-1)^{r(M)} \sum_{X \subseteq E} (-1)^{|X|} r(X) \ . &lt;/math&gt;
The beta invariant is non-negative, and is zero if and only if ''M'' is disconnected, or empty, or a loop.  Otherwise it depends only on the lattice of flats of ''M''.  If ''M'' has no loops and coloops then β(''M'') = β(''M''&lt;sup&gt;&amp;lowast;&lt;/sup&gt;).&lt;ref name=Wh87124/&gt;

===Tutte polynomial===

The '''[[Tutte polynomial]]''' of a matroid, ''T''&lt;sub&gt;''M''&lt;/sub&gt;&amp;nbsp;(''x'',''y''), generalizes the characteristic polynomial to two variables.  This gives it more combinatorial interpretations, and also gives it the duality property
:&lt;math&gt;T_{M^*}(x,y) = T_M(y,x),&lt;/math&gt;
which implies a number of dualities between properties of ''M'' and properties of ''M''&amp;nbsp;*.  One definition of the Tutte polynomial is
:&lt;math&gt;T_M(x,y) = \sum_{S \subseteq E} (x-1)^{r(M)-r(S)}(y-1)^{|S|-r(S)}.&lt;/math&gt;
This expresses the Tutte polynomial as an evaluation of the '''corank-nullity''' or '''rank generating polynomial''',&lt;ref name=Wh87126&gt;{{harvnb|White|1987|p=126}}&lt;/ref&gt;
:&lt;math&gt;R_M(u,v) = \sum_{S\subseteq E} u^{r(M)-r(S)}v^{|S|-r(S)}.&lt;/math&gt;
From this definition it is easy to see that the characteristic polynomial is, up to a simple factor, an evaluation of ''T''&lt;sub&gt;''M''&lt;/sub&gt;, specifically, 
:&lt;math&gt;p_M(\lambda) = (-1)^{r(M)} T_M(1-\lambda,0). &lt;/math&gt;

Another definition is in terms of internal and external activities and a sum over bases, reflecting the fact that ''T''(1,1) is the number of bases.&lt;ref name=Wh92188&gt;{{harvnb|White|1992|p=188}}&lt;/ref&gt;  This, which sums over fewer subsets but has more complicated terms, was Tutte's original definition.

There is a further definition in terms of recursion by deletion and contraction.&lt;ref name=Wh86260&gt;{{harvnb|White|1986|p=260}}&lt;/ref&gt;  The deletion-contraction identity is
:&lt;math&gt;F(M) = F(M-e)+F(M/e)&lt;/math&gt; when &lt;math&gt;e&lt;/math&gt; is neither a loop nor a coloop.
An invariant of matroids (i.e., a function that takes the same value on isomorphic matroids) satisfying this recursion and the multiplicative condition
:&lt;math&gt;F(M\oplus M') = F(M) F(M')&lt;/math&gt;
is said to be a '''Tutte-Grothendieck invariant'''.&lt;ref name=Wh87126/&gt; The Tutte polynomial is the most general such invariant; that is, the Tutte polynomial is a Tutte-Grothendieck invariant and every such invariant is an evaluation of the Tutte polynomial.&lt;ref name=Wh87127&gt;{{harvnb|White|1987|p=127}}&lt;/ref&gt;

The [[Tutte polynomial]] ''T''&lt;sub&gt;''G''&lt;/sub&gt;&amp;nbsp; of a graph is the Tutte polynomial ''T''&lt;sub&gt;''M''(''G'')&lt;/sub&gt; of its cycle matroid.

== Infinite matroids ==
&lt;!-- [[Infinite matroid]] redirects here. --&gt;
The theory of infinite matroids is much more complicated than that of finite matroids and forms a subject of its own.  For a long time, one of the difficulties has been that there were many reasonable and useful definitions, none of which appeared to capture all the important aspects of finite matroid theory.  For instance, it seemed to be hard to have bases, circuits, and duality together in one notion of infinite matroids.

The simplest definition of an infinite matroid is to require ''finite rank''; that is, the rank of ''E'' is finite.  This theory is similar to that of finite matroids except for the failure of duality due to the fact that the dual of an infinite matroid of finite rank does not have finite rank.  Finite-rank matroids include any subsets of finite-dimensional vector spaces and of [[Field (mathematics)|field extensions]] of finite [[transcendence degree]].

The next simplest infinite generalization is finitary matroids.  A matroid is '''finitary''' if it has the property that
:&lt;math&gt;x \in cl(Y) \Leftrightarrow (\exists Y' \subseteq Y) Y' \text{ is finite and } x \in cl(Y').&lt;/math&gt;
Equivalently, every dependent set contains a finite dependent set.
Examples are linear dependence of arbitrary subsets of infinite-dimensional [[vector space]]s (but not infinite dependencies as in [[Hilbert space|Hilbert]] and [[Banach space]]s), and algebraic dependence in arbitrary subsets of field extensions of possibly infinite transcendence degree.  Again, the class of finitary matroid is not self-dual, because the dual of a finitary matroid is not finitary.
Finitary infinite matroids are studied in [[model theory]], a branch of [[mathematical logic]] with strong ties to [[algebra]].

In the late 1960s matroid theorists asked for a more general notion that shares the different aspects of finite matroids and generalizes their duality. Many notions of infinite matroids were defined in response to this challenge, but the question remained open. One of the approaches examined by D.A. Higgs became known as ''B-matroids'' and was studied by Higgs, Oxley and others in the 1960s and 1970s. According to a recent result by {{harvs|last1=Bruhn|last2=Diestel|last3=Kriesell|last4=Pendavingh|year=2013|txt}}, it solves the problem: Arriving at the same notion independently, they provided five equivalent systems of axioms – in terms of independence, bases, circuits, closure and rank. The duality of B-matroids generalizes dualities that can be observed in infinite graphs.

The independence axioms are as follows:
# The empty set is independent.
# Every subset of an independent set is independent.
# For every [[maximal element|nonmaximal]] (under set inclusion) independent set ''I'' and maximal independent set ''J'', there is &lt;math&gt;x\in J \setminus I&lt;/math&gt; such that &lt;math&gt;I\cup\{x\}&lt;/math&gt; is independent.
# For every subset ''X'' of the base space, every independent subset ''I'' of ''X'' can be extended to a maximal independent subset of ''X''.

With these axioms, every matroid has a dual.

==History==

Matroid theory was introduced by {{harvs|last=Whitney|first=Hassler|authorlink=Hassler Whitney|year=1935|txt}}. It was also independently discovered by [[Takeo Nakasawa]], whose work was forgotten for many years {{harv|Nishimura|Kuroda|2009}}.

In his seminal paper, Whitney provided two axioms for independence, and defined any structure adhering to these axioms to be "matroids".
(Although it was perhaps implied, he did not include an axiom requiring at least one subset to be independent.)
His key observation was that these axioms provide an abstraction of "independence" that is common to both graphs and matrices.
Because of this, many of the terms used in matroid theory resemble the terms for their analogous concepts in [[linear algebra]] or [[graph theory]].

Almost immediately after Whitney first wrote about matroids, an important article was written by {{harvs|last=Mac Lane|first=Saunders|authorlink=Saunders Mac Lane|year=1936|txt}} on the relation of matroids to [[projective geometry]]. A year later, {{harvs|last=van der Waerden|first=B. L.|authorlink=Bartel Leendert van der Waerden|year=1937|txt}} noted similarities between algebraic and linear dependence in his classic textbook on Modern Algebra.

In the 1940s [[Richard Rado]] developed further theory under the name "independence systems" with an eye towards [[Transversal (combinatorics)|transversal theory]], where his name for the subject is still sometimes used.

In the 1950s [[W. T. Tutte]] became the foremost figure in matroid theory, a position he retained for many years.  His contributions were plentiful, including the characterization of [[binary matroid|binary]], [[regular matroid|regular]], and [[graphic matroid|graphic]] matroids by [[Matroid minor|excluded minors]]; the regular-matroid representability theorem; the theory of chain groups and their matroids; and the tools he used to prove many of his results, the "Path theorem" and "[[Tutte homotopy theorem|Homotopy theorem]]" (see, e.g., {{harvnb|Tutte|1965}}), which are so complex that later theorists have gone to great trouble to eliminate the necessity of using them in proofs.  (A fine example is [[A. M. H. Gerards]]' short proof ([[#CITEREFGerards1989|1989]]) of Tutte's characterization of regular matroids.)

{{harvs|first=Henry|last=Crapo|year=1969|txt}} and {{harvs|first=Thomas|last=Brylawski|year=1972|txt}} generalized to matroids Tutte's "dichromate", a graphic polynomial now known as the [[Tutte polynomial]] (named by Crapo).  Their work has recently (especially in the 2000s) been followed by a flood of papers&amp;mdash;though not as many as on the Tutte polynomial of a graph.

In 1976 [[Dominic Welsh]] published the first comprehensive book on matroid theory.

[[Paul Seymour (mathematician)|Paul Seymour]]'s decomposition theorem for regular matroids ([[#CITEREFSeymour1980|1980]]) was the most significant and influential work of the late 1970s and the 1980s.
Another fundamental contribution, by {{harvtxt|Kahn|Kung|1982}}, showed why projective geometries and Dowling geometries play such an important role in matroid theory.

By this time there were many other important contributors, but one should not omit to mention [[Geoff Whittle]]'s extension to ternary matroids of Tutte's characterization of binary matroids that are representable over the rationals {{harv|Whittle|1995}}, perhaps the biggest single contribution of the 1990s.  In the current period (since around 2000) the Matroid Minors Project of [[Jim Geelen]], Gerards, Whittle, and others, which attempts to duplicate for matroids that are representable over a finite field the success of the Robertson&amp;ndash;Seymour Graph Minors Project (see [[Robertson–Seymour theorem]]), has produced substantial advances in the structure theory of matroids.  Many others have also contributed to that part of matroid theory, which (in the first and second decades of the 21st century) is flourishing.

==Researchers==

Mathematicians who pioneered the study of matroids include [[Takeo Nakasawa]],{{sfnp|Nishimura|Kuroda|2009}} [[Saunders Mac Lane]], [[Richard Rado]], [[W. T. Tutte]], [[Bartel Leendert van der Waerden|B. L. van der Waerden]], and [[Hassler Whitney]].
Other major contributors include [[Jack Edmonds]], [[Jim Geelen]], [[Eugene Lawler]], [[László Lovász]], [[Gian-Carlo Rota]], [[Paul Seymour (mathematician)|P. D. Seymour]], and [[Dominic Welsh]].

==See also==
* [[Antimatroid]]
* [[Coxeter matroid]]
* [[Oriented matroid]]
* [[Pregeometry (model theory)]]
* [[Polymatroid]]
* [[Greedoid]]

==Notes==
{{Reflist|30em}}

== References ==
*{{citation
 | last1 = Bruhn | first1 = Henning
 | last2 = Diestel | first2 = Reinhard
 | last3 = Kriesell | first3 = Matthias
 | last4 = Pendavingh | first4 = Rudi
 | last5 = Wollan | first5 = Paul
 | arxiv = 1003.3919
 | doi = 10.1016/j.aim.2013.01.011
 | journal = Advances in Mathematics
 | mr = 3045140
 | pages = 18–46
 | title = Axioms for infinite matroids
 | volume = 239
 | year = 2013}}.
*{{citation|last1=Bryant|first1=Victor|last2=Perfect|first2=Hazel|year=1980|title=Independence Theory in Combinatorics|publisher=Chapman and Hall|location=London and New York|isbn=978-0-412-22430-0}}.
*{{citation|last=Brylawski|first=Thomas H.|year=1972|title=A decomposition for combinatorial geometries|journal=Transactions of the American Mathematical Society|volume=171|pages=235&amp;ndash;282|doi=10.2307/1996381|jstor=1996381}}.
*{{citation|last=Crapo|first=Henry H.|year=1969|title=The Tutte polynomial|journal=[[Aequationes Mathematicae]]|volume=3|issue=3|pages=211&amp;ndash;229|doi=10.1007/BF01817442}}.
*{{citation|last1=Crapo|first=Henry H.|last2=Rota|first2=Gian-Carlo|author2-link=Gian-Carlo Rota|year=1970|title=On the Foundations of Combinatorial Theory: Combinatorial Geometries|publisher=M.I.T. Press|location=Cambridge, Mass.|isbn=978-0-262-53016-3|mr=0290980}}.
*{{citation|last1=Geelen|first1=Jim|last2=Gerards|first2=A. M. H.|last3=Whittle|first3=Geoff|year=2007|contribution=Towards a matroid-minor structure theory|editor=Grimmett, Geoffrey (ed.)|title=Combinatorics, Complexity, and Chance: A Tribute to Dominic Welsh|series=Oxford Lecture Series in Mathematics and its Applications|volume=34|pages=72&amp;ndash;82|publisher=Oxford University Press|location=Oxford|display-editors=etal}}.
*{{citation|last=Gerards|first=A. M. H.|year=1989|title=A short proof of Tutte's characterization of totally unimodular matrices|journal=[[Linear Algebra and its Applications]]|volume=114/115|pages=207&amp;ndash;212|doi=10.1016/0024-3795(89)90461-8}}.
*{{citation|last1=Kahn|first1=Jeff|last2=Kung|first2=Joseph P. S.|year=1982|title=Varieties of combinatorial geometries|journal=Transactions of the American Mathematical Society|volume=271|pages=485&amp;ndash;499|doi=10.2307/1998894|issue=2|jstor=1998894}}.
*{{citation|last1=Kingan|first1=Robert|last2=Kingan|first2=Sandra | year=2005|contribution=A software system for matroids|title=Graphs and Discovery|series=DIMACS Series in Discrete Mathematics and Theoretical Computer Science|pages=287&amp;ndash;296}}.
*{{citation|editor-last=Kung|editor-first=Joseph P. S.|title=A Source Book in Matroid Theory|publisher=Birkhäuser|isbn=978-0-8176-3173-4|location=Boston|year=1986|mr=0890330|doi=10.1007/978-1-4684-9199-9}}.
*{{citation|last=Mac Lane|first=Saunders|authorlink=Saunders Mac Lane|year=1936|title=Some interpretations of abstract linear dependence in terms of projective geometry|journal=American Journal of Mathematics|volume=58|pages=236–240|doi=10.2307/2371070|issue=1|jstor=2371070}}.
*{{citation|last=Minty|first=George J.|title=On the axiomatic foundations of the theories of directed linear graphs, electrical networks and network-programming|journal=Journal of Mathematics and Mechanics|volume=15|year=1966|pages=485–520|mr=0188102}}.
*{{citation|mr=2516551|zbl=1163.01001|title=A lost mathematician, Takeo Nakasawa. The forgotten father of matroid theory|editor-first=Hirokazu |editor-last=Nishimura |editor2-first=Susumu |editor2-last=Kuroda|publisher= Birkhäuser Verlag|place= Basel|year= 2009|isbn= 978-3-7643-8572-9|url=http://www.springerlink.com/content/978-3-7643-8572-9 |doi=10.1007/978-3-7643-8573-6}}.
*{{citation|last=Oxley|first=James | authorlink = James Oxley|year=1992|title=Matroid Theory|publisher=Oxford University Press|location=Oxford|isbn=978-0-19-853563-8|mr=1207587|zbl=0784.05002}}.
*{{citation|last=Recski|first=Andr&amp;aacute;s|year=1989|title=Matroid Theory and its Applications in Electric Network Theory and in Statics|volume=6|publisher=Springer-Verlag and Akademiai Kiado|location=Berlin and Budapest|isbn=978-3-540-15285-9|mr=1027839|doi=10.1007/978-3-662-22143-3|series=Algorithms and Combinatorics}}.
*{{eom|id=M/m062870|first=A.A.|last= Sapozhenko}}
*{{citation|last=Seymour|first=Paul D.|authorlink=Paul Seymour (mathematician)|year=1980|title=Decomposition of regular matroids|journal=Journal of Combinatorial Theory, Series B|volume=28|issue=3|pages=305&amp;ndash;359|doi=10.1016/0095-8956(80)90075-1|zbl=0443.05027}}.
*{{citation|last=Truemper|first=Klaus|title=Matroid Decomposition|publisher=Academic Press|location=Boston|year=1992|isbn=978-0-12-701225-4|url=http://www.emis.de/monographs/md/index.html|mr=1170126}}.
*{{citation|last=Tutte|first=W. T.|authorlink=W. T. Tutte|year=1959|title=Matroids and graphs|journal=Transactions of the American Mathematical Society|volume=90|pages=527–552|doi=10.2307/1993185|issue=3|mr=0101527|jstor=1993185}}.
*{{citation|last=Tutte|first=W. T.|authorlink=W. T. Tutte|year=1965|title=Lectures on matroids|journal=Journal of Research of the National Bureau of Standards Section B|volume=69|pages=1&amp;ndash;47}}.
*{{citation | zbl=0231.05027 | last=Tutte | first=W.T. | authorlink=W. T. Tutte | title=Introduction to the theory of matroids | series=Modern Analytic and Computational Methods in Science and Mathematics | volume=37 | location=New York | publisher=American Elsevier Publishing Company | year=1971 }}.
*{{citation|last=Vámos|first=Peter|year=1978|title=The missing axiom of matroid theory is lost forever|journal=Journal of the London Mathematical Society|volume=18|pages=403–408|doi=10.1112/jlms/s2-18.3.403|issue=3}}.
*{{citation|last=van der Waerden|first=B. L.|authorlink=Bartel Leendert van der Waerden|year=1937|title=Moderne Algebra}}.
*{{citation|last=Welsh|first=D. J. A.|year=1976|title=Matroid Theory|publisher=Academic Press|isbn=978-0-12-744050-7|zbl=0343.05002|series=L.M.S. Monographs | volume=8}}.
*{{citation|editor-last=White|editor-first=Neil|year=1986|title=Theory of Matroids|series=Encyclopedia of Mathematics and its Applications|volume=26|publisher=Cambridge University Press|location=Cambridge|isbn=978-0-521-30937-0 | zbl=0579.00001 }}.
*{{citation | editor-last=White | editor-first=Neil | title=Combinatorial geometries | series=Encyclopedia of Mathematics and its Applications | volume=29 | location=Cambridge | publisher=[[Cambridge University Press]] | year=1987 | isbn=978-0-521-33339-9 | zbl=0626.00007 }}
*{{citation|editor-last=White|editor-first=Neil|year=1992|title=Matroid Applications|series=Encyclopedia of Mathematics and its Applications|volume=40|publisher=Cambridge University Press|location=Cambridge|isbn=978-0-521-38165-9 | zbl=0742.00052 }}.
*{{citation|last=Whitney|first=Hassler|authorlink=Hassler Whitney|year=1935|title=On the abstract properties of linear dependence|journal=American Journal of Mathematics|volume=57|pages=509–533|doi=10.2307/2371182|issue=3|mr=1507091|jstor=2371182}}. Reprinted in {{harvtxt|Kung|1986}}, pp.&amp;nbsp;55–79.
*{{citation|last=Whittle|first=Geoff|year=1995|title=A characterization of the matroids representable over ''GF''(3) and the rationals|journal=Journal of Combinatorial Theory, Series B|volume=65|issue=2|pages=222&amp;ndash;261|url=http://eprints.kfupm.edu.sa/39296/1/39296.pdf|doi=10.1006/jctb.1995.1052}}{{dead link|date=March 2018 |bot=InternetArchiveBot |fix-attempted=yes }}.

== External links ==

* {{springer|title=Matroid|id=p/m062870}}
* Kingan, Sandra : [http://userhome.brooklyn.cuny.edu/skingan/matroids/ Matroid theory]. A large bibliography of matroid papers, matroid software, and links.
* Locke, S. C. : [http://euler.math.fau.edu/locke/Greedy.htm Greedy Algorithms].
* Pagano, Steven R. : [http://www.math.binghamton.edu/zaslav/Pagano/Matridx.htm Matroids and Signed Graphs].
* Mark Hubenthal: [https://web.archive.org/web/20100812232232/http://www.math.washington.edu/~hubenjm/matroid2.pdf A Brief Look At Matroids] ([[pdf]]) (contain proofs for statements of this article)
* James Oxley : [https://www.math.lsu.edu/~oxley/survey4.pdf What is a matroid?] (pdf)
* Neil White : [https://books.google.com/books?id=uD2H-RAcBpwC&amp;lpg=PA285&amp;ots=JL6z3p--j8&amp;dq=greedoid%20theory&amp;pg=PP1#v=onepage&amp;q=greedoid%20theory&amp;f=false Matroid Applications]

[[Category:Matroid theory| ]]
[[Category:Closure operators]]
[[Category:Set families]]</text>
      <sha1>0jnt1kwdhtp8qdhlg4jdv62rtj5l6fm</sha1>
    </revision>
  </page>
  <page>
    <title>Micajah Burnett</title>
    <ns>0</ns>
    <id>50611972</id>
    <revision>
      <id>857400997</id>
      <parentid>850640596</parentid>
      <timestamp>2018-08-31T13:09:12Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* References */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6092">{{Infobox person
| honorific_prefix = [[Brother (Christian)#Shakerism|Brother]]
| name = Micajah Burnett
| image = 
| birth_date = {{Birth date|1791|5|13}}
| birth_place = [[Patrick County, Virginia|Patrick County]], [[Virginia]], [[United States]]
| death_date = {{Death date and age|1879|1|10|1791|5|13}}
| death_place = [[Pleasant Hill, Kentucky|Pleasant Hill]], [[Kentucky]], United States
| occupation = [[Architect]], [[Construction worker|builder]], [[engineer]], [[Urban planner|town planner]]
| years_active = 1813–1872
| organization = [[Pleasant Hill, Kentucky|Pleasant Hill Shaker Society]]
| home_town = [[Wayne County, Kentucky|Wayne County]], Kentucky, United States
}}

'''Micajah Burnett''' (13 May 1791 – 10 January 1879) was an [[United States|American]] [[Shakers|Shaker]] [[architect]], [[Construction worker|builder]], [[engineer]], [[Surveying|surveyor]], [[mathematician]], and [[town planner]].

== Early life ==
Burnett was born on 13 May 1791 in [[Patrick County, Virginia|Patrick County]], [[Virginia]], [[United States]].&lt;ref name=":0"&gt;{{Cite book|url=https://books.google.com/books?id=1QXe8E2tR3UC|title=The A to Z of the Shakers|last=Paterwic|first=Stephen J.|date=2009-09-28|publisher=Scarecrow Press|isbn=9780810870567|pages=26–28|language=en}}&lt;/ref&gt; He was the oldest of four children, the others being Charity, Andrew, and Zachiah.&lt;ref name=":0" /&gt; By the mid-1790s, his family had settled in [[Wayne County, Kentucky|Wayne County]], [[Kentucky]].&lt;ref name=":0" /&gt; In 1808, his parents converted to [[Shakers|Shakerism]] and joined the [[Pleasant Hill, Kentucky|Pleasant Hill Shaker Society]] with their four children.&lt;ref name=":0" /&gt;&lt;ref name=":1"&gt;{{Cite web|url=https://www.nps.gov/nr/travel/shaker/ple.HTM|title=Shakertown at Pleasant Hill Historic District Shaker Historic Trail -- National Register of Historic Places|website=www.nps.gov|access-date=2016-05-22}}&lt;/ref&gt; Burnett was 17 at the time.&lt;ref name=":0" /&gt;&lt;ref name=":1" /&gt;

== Adulthood and architecture ==
[[File:Shakertown Center Family 2005-05-27.jpeg|left|thumb|The Pleasant Hill Center Family dwelling house, designed by Burnett and constructed from 1824-1834.]]
[[File:Trustees' Building stair at Pleasant Hill.jpg|thumb|One of two spiral staircases designed by Burnett in the Trustees' House.]]
At the age of 22, Burnett changed the original layout of Pleasant Hill, much of which was on a north-south axis.&lt;ref name=":0" /&gt; He reoriented the main road to run east-west, and designed and oversaw the construction of three new dwelling houses along it. The first two were brick structures home to the East and West Families, built in 1817 and 1821, respectively.&lt;ref name=":0" /&gt; The third, construction of which began in 1824 and ended ten years later, was the dwelling of the Center Family.&lt;ref name=":0" /&gt; Built of white limestone, the building is 55 by 60 feet with an ell of 34 by 85 feet.&lt;ref name=":0" /&gt; Besides the three dwellings, Burnett designed the Pleasant Hill Shakers' Meeting House in 1820. A white [[Clapboard (architecture)|clapboard]] structure, it is 60 by 44 feet.&lt;ref name=":0" /&gt;
[[File:Shakertown Trustees House 2005-05-27.jpeg|left|thumb|The Pleasant Hill Trustees' House, designed by Burnett and built in 1839-40.]]
During the early 1830s, Burnett directed the construction of the first public waterworks west of the [[Allegheny Mountains]].&lt;ref name=":0" /&gt; Part of the project included the erection of Pleasant Hill's water tower, which Burnett designed. Completed in 1831, the tower holds a [[cypress]] tank with a capacity of 4,400 gallons of water.&lt;ref name=":0" /&gt;

The tower allowed every dwelling, shop, and barn in the Shaker village to have access to [[Tap water|running water]].&lt;ref name=":0" /&gt; Burnett's expertise in engineering and designing waterworks was such that he was consulted by Shakers at the [[South Union Shaker Center House and Preservatory|South Union Shaker Society]] when they were designing their own waterworks.&lt;ref name=":0" /&gt;

While Burnett's many designs and completed buildings awarded him renown both among Shakers and outside groups, his most famous project was that of the Pleasant Hill Trustees' House.&lt;ref name=":0" /&gt; A large brick building, it was built from 1839–1840 and is best known for its twin [[spiral staircase]]s, which have the appearance of standing unsupported.&lt;ref name=":0" /&gt;

In addition to his design and construction work, Burnett also had the important job of trustee, which took him to markets across the [[Mississippi River]] area selling Shaker good including [[Shaker Seed Company|seeds]], [[Shaker broom vise|brooms]], [[Medicinal plants|medicinal herbs]], [[Noil|raw silk]], and [[fruit preserves]].&lt;ref name=":0" /&gt; To provide better access to the [[Kentucky River]] from Pleasant Hill, he designed and oversaw the construction of a new road.&lt;ref name=":0" /&gt; In his later years, he also designed and oversaw the construction of the Pleasant Hill West Family's wash house, the West Family Sisters' Shop, the East Family Brethren's Shop, and the Pleasant Hill [[United States Postal Service|U.S. Post Office]].&lt;ref name=":0" /&gt;

In 1872, because of his old age, Burnett was released from his trustee duties.&lt;ref name=":0" /&gt; He died on 10 January 1879 at the age of 87.&lt;ref name=":0" /&gt;

== Gallery ==
&lt;gallery&gt;
File:Historic American Buildings Survey Lester Jones, Photographer August 24, 1940 VIEW FROM NORTHEAST - Shaker West Family Dwelling House (Second), North side of Village Road, North HABS KY,84-SHAKT,17-2.tif
File:Shakertown Water Tower 2005-05-27.jpeg
File:Center Family Meeting Room Shaker Village at Pleasant Hill, Kentucky.JPG
&lt;/gallery&gt;

== References ==
{{Reflist}}

{{authority control}}

{{DEFAULTSORT:Burnett, Micajah}}
[[Category:1791 births]]
[[Category:1879 deaths]]
[[Category:Shakers]]
[[Category:American Protestants]]
[[Category:Architects from Kentucky]]
[[Category:19th-century American engineers]]
[[Category:American surveyors]]
[[Category:19th-century American mathematicians]]
[[Category:Amateur mathematicians]]
[[Category:American urban planners]]</text>
      <sha1>b1casvy7dpkzodfteio01mkkfw9xh72</sha1>
    </revision>
  </page>
  <page>
    <title>Monotone class theorem</title>
    <ns>0</ns>
    <id>4719864</id>
    <revision>
      <id>826485719</id>
      <parentid>826249485</parentid>
      <timestamp>2018-02-19T11:33:52Z</timestamp>
      <contributor>
        <username>Eleuther</username>
        <id>1558984</id>
      </contributor>
      <comment>/* Definition of a monotone class */ this still seems valid</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3457">In [[Measure (mathematics)|measure theory]] and [[Probability theory|probability]], the '''monotone class theorem''' connects monotone classes and [[sigma-algebra]]s. The theorem says that the smallest monotone class containing an [[field of sets|algebra of sets]] ''G'' is precisely the smallest [[Sigma-algebra|''σ''-algebra]] containing&amp;nbsp;''G''. It is used as a type of [[transfinite induction]] to prove many other theorems, such as [[Fubini's theorem]].

==Definition of a monotone class==
A '''monotone class''' is a [[class (set theory)|class]] ''M'' of sets that is [[Closure (mathematics)|closed]] under countable monotone unions and intersections, i.e. if &lt;math&gt;A_i \in M&lt;/math&gt; and &lt;math&gt;A_1 \subset A_2 \subset \cdots&lt;/math&gt; then &lt;math display="inline"&gt; \bigcup_{i = 1}^\infty A_i \in M&lt;/math&gt;, and similarly in the other direction.

==Monotone class theorem for sets==

===Statement===
Let ''G'' be an [[field of sets|algebra of sets]] and define ''M''(''G'') to be the smallest monotone class containing&amp;nbsp;''G''. Then ''M''(''G'') is precisely the [[Sigma-algebra|''σ''-algebra]] generated by ''G'', i.e.&amp;nbsp;''σ''(''G'')&amp;nbsp;=&amp;nbsp;''M''(''G'').

==Monotone class theorem for functions==

===Statement===
Let &lt;math&gt;\mathcal{A}&lt;/math&gt; be a [[Pi system|{{pi}}-system]] that contains &lt;math&gt;\Omega\,&lt;/math&gt; and let &lt;math&gt;\mathcal{H}&lt;/math&gt; be a collection of functions from &lt;math&gt;\Omega&lt;/math&gt; to '''R''' with the following properties:

(1) If &lt;math&gt;A \in \mathcal{A}&lt;/math&gt;, then &lt;math&gt;\mathbf{1}_A \in \mathcal{H}&lt;/math&gt;

(2) If &lt;math&gt;f,g \in \mathcal{H}&lt;/math&gt;, then &lt;math&gt;f+g&lt;/math&gt; and &lt;math&gt;cf \in \mathcal{H}&lt;/math&gt; for any real number &lt;math&gt;c&lt;/math&gt;

(3) If &lt;math&gt;f_n \in \mathcal{H}&lt;/math&gt; is a sequence of non-negative functions that increase to a bounded function &lt;math&gt;f&lt;/math&gt;, then &lt;math&gt;f \in \mathcal{H}&lt;/math&gt;

Then &lt;math&gt;\mathcal{H}&lt;/math&gt; contains all bounded functions that are measurable with respect to &lt;math&gt;\sigma(\mathcal{A})&lt;/math&gt;, the sigma-algebra generated by &lt;math&gt;\mathcal{A}&lt;/math&gt;

===Proof===
The following argument originates in [[Rick Durrett]]'s Probability: Theory and Examples.
&lt;ref name="Durrett"&gt;{{cite book|last=Durrett|first=Rick|year=2010|title=Probability: Theory and Examples|edition=4th|publisher=Cambridge University Press|page=100|isbn=978-0521765398}}&lt;/ref&gt;

The assumption &lt;math&gt;\Omega\, \in \mathcal{A}&lt;/math&gt;, (2) and (3) imply that &lt;math&gt;\mathcal{G} = \{A: \mathbf{1}_{A} \in \mathcal{H}\}&lt;/math&gt; is a ''λ''-system. By (1) and the [[Dynkin system|{{pi}}−''λ'' theorem]], &lt;math&gt;\sigma(\mathcal{A}) \subset \mathcal{G}&lt;/math&gt;. (2) implies &lt;math&gt;\mathcal{H}&lt;/math&gt; contains all simple functions, and then (3) implies that &lt;math&gt;\mathcal{H}&lt;/math&gt; contains all bounded functions measurable with respect to &lt;math&gt;\sigma(\mathcal{A})&lt;/math&gt;.

==Results and applications==
As a corollary, if ''G'' is a [[Ring of sets|ring]] of sets, then the smallest monotone class containing it coincides with the sigma-ring of&amp;nbsp;''G''.

By invoking this theorem, one can use monotone classes to help verify that a certain collection of subsets is a sigma-algebra.

The monotone class theorem for functions can be a powerful tool that allows statements about particularly simple classes of functions to be generalized to arbitrary bounded and measurable functions.

==References==
&lt;references/&gt;

[[Category:Set families]]
[[Category:Theorems in measure theory]]

[[fr:Lemme de classe monotone]]</text>
      <sha1>hl6tgxn5e47oxqse1es5eko5clcz938</sha1>
    </revision>
  </page>
  <page>
    <title>Moulton plane</title>
    <ns>0</ns>
    <id>9787563</id>
    <revision>
      <id>825106507</id>
      <parentid>786598556</parentid>
      <timestamp>2018-02-11T14:51:41Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <minor/>
      <comment>sp</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3020">[[File:Moulton plane2.svg|thumb|right|upright=1.5|The ''Moulton plane''. Lines sloping down and to the right are bent where they cross the ''y''-axis.]]
In [[incidence geometry]], the '''Moulton plane''' is an example of an [[affine plane (incidence geometry)|affine plane]] in which [[Desargues's theorem]] does not hold. It is named after the American astronomer [[Forest Ray Moulton]]. The points of the Moulton plane are simply the points in the real plane '''R'''&lt;sup&gt;2&lt;/sup&gt; and the lines are the regular lines as well with the exception that for lines with a negative [[slope]], the slope doubles when they pass the ''y''-axis.

==Formal definition==
The Moulton plane is an [[incidence structure]] &lt;math&gt;\mathfrak M=\langle P, G,\textrm I\rangle&lt;/math&gt;, where &lt;math&gt;P&lt;/math&gt; denotes the set of points, &lt;math&gt;G&lt;/math&gt; the set of lines and &lt;math&gt;\textrm I&lt;/math&gt; the incidence relation "lies on":
:&lt;math&gt; P:=\mathbb R^2 \,&lt;/math&gt;
:&lt;math&gt; G:=(\mathbb R \cup \{\infty\}) \times \mathbb R,&lt;/math&gt;

&lt;math&gt;\infty&lt;/math&gt; is just a formal symbol for an element &lt;math&gt;\not\in\mathbb R&lt;/math&gt;. It is used to describe vertical lines, which you may think of as lines with an infinitely large slope.

The incidence relation is defined as follows:

For &lt;math&gt;p = (x, y) \in P&lt;/math&gt; and &lt;math&gt;g = (m, b) \in G&lt;/math&gt; we have

:&lt;math&gt;
p\,\textrm I\,g\iff\begin{cases}
x=b&amp;\text{if }m=\infty\\
y=\frac{1}{2}mx+b&amp;\text{if }m\leq 0, x\leq 0\\
y=mx+b&amp;\text{if }m\geq 0 \text{ or } x\geq 0.
\end{cases}
&lt;/math&gt;

==Application==
The Moulton plane is an affine plane in which Desargues' theorem does not hold.&lt;ref&gt;{{harvnb|Beutelspacher|Rosenbaum|1998|page=[https://books.google.com/books?id=I4OqBcaKAJ0C&amp;pg=PA77 77]}}&lt;/ref&gt; The associated projective plane is consequently non-desarguesian as well. This means that there are projective planes not isomorphic to &lt;math&gt; PG(2,F) &lt;/math&gt; for any [[Division ring|(skew) field]] ''F''.  Here &lt;math&gt; PG(2,F) &lt;/math&gt; is the [[projective plane]] &lt;math&gt; P(F^3) &lt;/math&gt; determined by a 3-dimensional vector space over the (skew) field ''F''.

==Notes==
{{reflist}}

==References==
* {{citation|last1=Beutelspacher|first1=Albrecht|last2=Rosenbaum|first2=Ute|author1-link=Albrecht Beutelspacher|title=Projective Geometry : From Foundations to Applications|year= 1998|publisher=Cambridge University Press|isbn=978-0-521-48364-3|pages=[https://books.google.com/books?id=I4OqBcaKAJ0C&amp;pg=PA76 76–78]}} 
* {{Citation | last1=Moulton | first1=Forest Ray | title=A Simple Non-Desarguesian Plane Geometry | jstor=1986419 | publisher=[[American Mathematical Society]] | location=Providence, R.I. | year=1902 | journal=[[Transactions of the American Mathematical Society]] | issn=0002-9947 | volume=3 | issue=2 | pages=192–195 | doi=10.2307/1986419}}
*Richard S. Millman, George D. Parker: ''Geometry: A Metric Approach with Models''. Springer 1991, {{isbn|9780387974125}}, pp. [https://books.google.com/books?id=KpQ49uySA-EC&amp;pg=PA97 97-104]

{{DEFAULTSORT:Moulton Plane}}
[[Category:Incidence geometry]]</text>
      <sha1>pzqs9c2m8lk1snhl63bxulhoderfvxk</sha1>
    </revision>
  </page>
  <page>
    <title>Multi-trials technique</title>
    <ns>0</ns>
    <id>29722894</id>
    <revision>
      <id>837296058</id>
      <parentid>772765872</parentid>
      <timestamp>2018-04-19T23:08:56Z</timestamp>
      <contributor>
        <username>Eggishorn</username>
        <id>3868363</id>
      </contributor>
      <comment>grammar - remove "allows to"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1990">The '''multi-trials technique''' by Schneider et al. is employed for [[distributed algorithms]] and allows breaking of symmetry efficiently. Symmetry breaking is necessary, for instance, in resource allocation problems, where many entities want to access the same resource concurrently. Many [[message passing]] algorithms typically employ one attempt to break symmetry per message exchange. The ''multi-trials technique'' transcends this approach through employing more attempts with every message exchange.&lt;ref&gt;{{harvtxt|Schneider|2010}}&lt;/ref&gt;

For example, in a simple algorithm for computing an O(Δ) [[vertex coloring]], where Δ denotes the maximum degree in the graph, every uncolored node randomly picks an available color and keeps it if no neighbor (concurrently) chooses the same color. For the multi-trials technique, a node gradually increases the number of chosen colors in every communication round. The technique can yield more than an exponential reduction in the required communication rounds. However, if the maximum degree Δ is small more efficient techniques exist, e.g. the (extended) coin-tossing technique by Richard Cole and [[Uzi Vishkin]].&lt;ref&gt;{{harvtxt|Schneider|2008}}&lt;/ref&gt;

==Notes==
{{reflist}}

== References ==
* {{Citation
 | last1=Schneider | first1=J.
 | contribution=A new technique for distributed symmetry breaking
 | title=Proceedings of the [[Symposium on Principles of Distributed Computing]]
 | year=2010
 | contribution-url = http://www.dcg.ethz.ch/publications/podcfp107_schneider_188.pdf
}}
* {{Citation
 | last1=Schneider | first1=J.
 | contribution=A log-star distributed maximal independent set algorithm for growth-bounded graphs
 | title=Proceedings of the [[Symposium on Principles of Distributed Computing]]
 | year=2008
 | contribution-url = http://www.dcg.ethz.ch/publications/podc08SW.pdf
}}

[[Category:Graph theory]]
[[Category:Graph coloring]]
[[Category:NP-complete problems]]
[[Category:Computational problems in graph theory]]</text>
      <sha1>cbfkszbryfx1nrdch1zrmt4vju6bqgx</sha1>
    </revision>
  </page>
  <page>
    <title>Non-autonomous system (mathematics)</title>
    <ns>0</ns>
    <id>38838646</id>
    <revision>
      <id>821870023</id>
      <parentid>788976962</parentid>
      <timestamp>2018-01-23T02:43:49Z</timestamp>
      <contributor>
        <ip>94.254.130.209</ip>
      </contributor>
      <comment>spelling error</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2426">In mathematics, an [[autonomous system (mathematics)|autonomous system]] is a dynamic equation on a [[smooth manifold]]. A '''non-autonomous system''' is a dynamic equation on a smooth [[fiber bundle]] &lt;math&gt;Q\to \mathbb R&lt;/math&gt; over &lt;math&gt;\mathbb R&lt;/math&gt;. For instance, this is the case of [[non-autonomous mechanics]].

An ''r''-order differential equation on a fiber bundle &lt;math&gt;Q\to \mathbb R&lt;/math&gt; is represented by a closed subbundle of a [[jet bundle]] &lt;math&gt;J^rQ&lt;/math&gt; of &lt;math&gt;Q\to \mathbb R&lt;/math&gt;. A dynamic equation on &lt;math&gt;Q\to \mathbb R&lt;/math&gt; is a differential equation which is algebraically solved for a higher-order derivatives.

In particular, a first-order dynamic equation on a fiber bundle &lt;math&gt;Q\to \mathbb R&lt;/math&gt; is a kernel of the [[covariant differential]] of some connection &lt;math&gt;\Gamma&lt;/math&gt; on &lt;math&gt;Q\to \mathbb R&lt;/math&gt;. Given bundle coordinates &lt;math&gt;(t,q^i)&lt;/math&gt; on &lt;math&gt;Q&lt;/math&gt; and the adapted coordinates &lt;math&gt;(t,q^i,q^i_t)&lt;/math&gt; on a first-order jet manifold &lt;math&gt;J^1Q&lt;/math&gt;, a first-order dynamic equation reads

: &lt;math&gt;q^i_t=\Gamma (t,q^i).&lt;/math&gt;

For instance, this is the case of [[non-autonomous mechanics| Hamiltonian non-autonomous mechanics]].

A second-order dynamic equation

: &lt;math&gt;q^i_{tt}=\xi^i(t,q^j,q^j_t)&lt;/math&gt; 

on &lt;math&gt;Q\to\mathbb R&lt;/math&gt; is defined as a holonomic
connection &lt;math&gt;\xi&lt;/math&gt; on a jet bundle &lt;math&gt;J^1Q\to\mathbb R&lt;/math&gt;. This
equation also is represented by a connection on an [[affine bundle|affine]] jet bundle &lt;math&gt;J^1Q\to Q&lt;/math&gt;. Due to the canonical
embedding &lt;math&gt;J^1Q\to TQ&lt;/math&gt;, it is equivalent to a geodesic equation
on the tangent bundle &lt;math&gt;TQ&lt;/math&gt; of &lt;math&gt;Q&lt;/math&gt;. A [[free motion equation]] in non-autonomous mechanics exemplifies a second-order non-autonomous dynamic equation.

== References ==
*  De Leon, M., Rodrigues, P., Methods of Differential Geometry in Analytical Mechanics (North Holland, 1989).
* Giachetta, G., Mangiarotti, L., [[Gennadi Sardanashvily|Sardanashvily, G.]], Geometric Formulation of Classical and Quantum Mechanics (World Scientific, 2010)   {{ISBN|981-4313-72-6}}  ([http://xxx.lanl.gov/abs/0911.0411 arXiv: 0911.0411]).

==See also==
* [[Autonomous system (mathematics)]]
* [[Non-autonomous mechanics]]
* [[Free motion equation]]
* [[Relativistic system (mathematics)]]


[[Category:Differential equations]]
[[Category:Classical mechanics]]
[[Category:Dynamical systems]]</text>
      <sha1>myb7q4kk67lf0kvdcnky6kdr6fkjox8</sha1>
    </revision>
  </page>
  <page>
    <title>Pillai prime</title>
    <ns>0</ns>
    <id>8889938</id>
    <revision>
      <id>645598809</id>
      <parentid>592022576</parentid>
      <timestamp>2015-02-04T13:20:22Z</timestamp>
      <contributor>
        <username>Jordiventura96</username>
        <id>23579466</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1560">In [[number theory]], a '''Pillai prime''' is a [[prime number]] ''p'' for which there is an integer ''n'' &gt; 0 such that the [[factorial]] of ''n'' is one less than a multiple of the prime, but the prime is not one more than a multiple of ''n''. To put it algebraically, &lt;math&gt;n! \equiv -1 \mod p&lt;/math&gt; but &lt;math&gt;p \not\equiv 1 \mod n&lt;/math&gt;. The first few Pillai primes are 

:[[23 (number)|23]], [[29 (number)|29]], [[59 (number)|59]], [[61 (number)|61]], [[67 (number)|67]], [[71 (number)|71]], [[79 (number)|79]], [[83 (number)|83]], [[109 (number)|109]], [[137 (number)|137]], [[139 (number)|139]], [[149 (number)|149]], [[193 (number)|193]], ... {{OEIS|id=A063980}} 

Pillai primes are named after the mathematician [[Subbayya Sivasankaranarayana Pillai]], who asked about these numbers. Their infinitude has been proved several times, by [[Mathukumalli V. Subbarao|Subbarao]], Erdős, and Hardy &amp; Subbarao.

==References==  
*{{Citation |first=R. K. |last=Guy |title=Unsolved Problems in Number Theory |location=New York |publisher=Springer-Verlag |year=2004 |page=A2 |edition=3rd |isbn=0-387-20860-7 }}.
*{{Citation |first=G. E. |last=Hardy |lastauthoramp=yes |first2=M. V. |last2=Subbarao |title=A modified problem of Pillai and some related questions |journal=[[American Mathematical Monthly]] |volume=109 |issue=6 |year=2002 |pages=554–559 |doi=10.2307/2695445 }}.
*{{planetmath reference|id=8739|title=Pillai prime}} 

{{Prime number classes}}

[[Category:Classes of prime numbers]]
[[Category:Factorial and binomial topics]]

{{numtheory-stub}}</text>
      <sha1>0dvq9g4wyzzwpug9wyhw0b13t75zasp</sha1>
    </revision>
  </page>
  <page>
    <title>Reed–Muller code</title>
    <ns>0</ns>
    <id>2032752</id>
    <revision>
      <id>870008155</id>
      <parentid>863919003</parentid>
      <timestamp>2018-11-21T20:27:06Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: isbn, title, template type. Add: hdl, year, doi, pages, issue, journal, citeseerx, chapter, series, volume, author pars. 1-1. Removed parameters. Formatted [[WP:ENDASH|dashes]]. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22826">{{infobox code
| name           = Reed-Muller code RM(r,m)
| image          =
| image_caption  =
| namesake       = [[Irving S. Reed]] and [[David E. Muller]]
| type           = [[Linear block code]]
| block_length   = &lt;math&gt;2^m&lt;/math&gt;
| message_length = &lt;math&gt;k=\sum_{i=0}^r \binom{m}{i}&lt;/math&gt;
| rate           = &lt;math&gt;k/2^m&lt;/math&gt;
| distance       = &lt;math&gt;2^{m-r}&lt;/math&gt;
| alphabet_size  = &lt;math&gt;2&lt;/math&gt;
| notation       = &lt;math&gt;[2^m,k,2^{m-r}]_2&lt;/math&gt;-code
}}

'''Reed–Muller codes''' are [[error-correcting code]]s that are used in wireless communications applications, particularly in deep-space communication&lt;ref&gt;{{Citation|last=Massey|first=James L.|date=1992|pages=1–17|publisher=Springer-Verlag|language=en|doi=10.1007/bfb0036046|isbn=978-3540558514|title=Advanced Methods for Satellite and Deep Space Communications|volume=182|series=Lecture Notes in Control and Information Sciences|chapter=Deep-space communications and coding: A marriage made in heaven|citeseerx=10.1.1.36.4265}}[[https://www.isiweb.ee.ethz.ch/archive/massey_pub/pdf/BI321.pdf pdf]]&lt;/ref&gt;. Moreover, the proposed [[5G|5G standard]]&lt;ref&gt;{{cite web|url=http://www.3gpp.org/ftp/tsg_ran/WG1_RL1/TSGR1_87/Report/Final_Minutes_report_RAN1%2387_v100.zip|title=3GPP RAN1 meeting #87 final report|publisher=3GPP|accessdate=31 August 2017}}&lt;/ref&gt; relies on the closely related [[Polar code (coding theory)|polar codes]]&lt;ref&gt;{{Cite journal|url=https://ieeexplore.ieee.org/abstract/document/5075875/|title=Channel Polarization: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels - IEEE Journals &amp; Magazine|journal=IEEE Transactions on Information Theory|volume=55|issue=7|pages=3051–3073|language=en-US|access-date=2018-08-31|doi=10.1109/TIT.2009.2021379|year=2009|last1=Arikan|first1=Erdal|hdl=11693/11695}}&lt;/ref&gt; for error correction in the control channel. Due to their favorable theoretical and mathematical properties, Reed–Muller codes have also been extensively studied in [[theoretical computer science]].

Reed–Muller codes generalize the [[Reed–Solomon error correction|Reed–Solomon codes]] and the [[Hadamard code|Walsh–Hadamard code]]. Reed–Muller codes are [[Linear code|linear block codes]] that are [[locally testable code|locally testable]], [[locally decodable code|locally decodable]], and [[List decoding|list decodable]]. These properties make them particularly useful in the design of [[probabilistically checkable proof]]s.

Traditional Reed–Muller codes are binary codes, which means that messages and codewords are binary strings. When ''r'' and ''m'' are integers with 0 ≤ ''r'' ≤ ''m'', the Reed–Muller code with parameters  ''r'' and ''m'' is denoted as RM(''r'',&amp;nbsp;''m''). When asked to encode a message consisting of ''k'' bits, where  &lt;math&gt;\textstyle k=\sum_{i=0}^r \binom{m}{i}&lt;/math&gt;to produce a holds, the RM(''r'',&amp;nbsp;''m'') code produces a codeword consisting of 2&lt;sup&gt;''m''&lt;/sup&gt; bits.

Reed–Muller codes are named after [[David E. Muller]], who discovered the codes in 1954&lt;ref&gt;{{Cite journal|last=Muller|first=David E.|date=1954|title=Application of Boolean algebra to switching circuit design and to error detection|url=https://ieeexplore.ieee.org/document/6499441/?reload=true|journal=Transactions of the I.R.E. Professional Group on Electronic Computers|language=en-US|volume=EC-3|issue=3|pages=6–12|doi=10.1109/irepgelc.1954.6499441|issn=2168-1740|via=}}&lt;/ref&gt;, and [[Irving S. Reed]], who proposed the first efficient decoding algorithm&lt;ref&gt;{{Cite journal|last=Reed|first=Irving S.|date=1954|title=A class of multiple-error-correcting codes and the decoding scheme|url=https://ieeexplore.ieee.org/document/1057465/?reload=true|journal=Transactions of the IRE Professional Group on Information Theory|language=en-US|volume=4|issue=4|pages=38–49|doi=10.1109/tit.1954.1057465|issn=2168-2690|via=}}&lt;/ref&gt;.

==Description using low-degree polynomials==
Reed–Muller codes can be described in several different (but ultimately equivalent) ways. The description that is based on low-degree polynomials is quite elegant and particularly suited for their application as [[locally testable code]]s and [[locally decodable code]]s.&lt;ref&gt;Prahladh Harsha et al., [[arxiv:1002.3864|Limits of Approximation Algorithms: PCPs and Unique Games (DIMACS Tutorial Lecture Notes)]], Section 5.2.1.&lt;/ref&gt;

=== Encoder ===
A [[block code]] can have one or more encoding functions &lt;math display="inline"&gt; C:\{0,1\}^k\to\{0,1\}^{n} &lt;/math&gt; that map messages &lt;math display="inline"&gt; x\in\{0,1\}^k &lt;/math&gt; to codewords &lt;math display="inline"&gt; C(x)\in\{0,1\}^{n} &lt;/math&gt;. The Reed&amp;ndash;Muller code {{nowrap|RM(''r'', ''m'')}} has [[Block code#The message length k|message length]] &lt;math&gt;\textstyle k=\sum_{i=0}^r \binom{m}{i}&lt;/math&gt; and [[Block code#The block length n|block length]]  &lt;math&gt;\textstyle n=2^m&lt;/math&gt;. One way to define an encoding for this code is based on the evaluation of [[Multilinear polynomial|multilinear polynomials]] with ''m'' variables and [[total degree]] ''r''. Every multilinear polynomial over the [[finite field]] with two elements can be written as follows:
&lt;math display="block"&gt;p_c(Z_1,\dots,Z_m) = \sum_{\underset{|S|\le r}{S\subseteq\{1,\dots,m\}}} c_S\cdot \prod_{i\in S} Z_i\,.&lt;/math&gt;
The &lt;math display="inline"&gt; Z_1,\dots,Z_m &lt;/math&gt; are the variables of the polynomial, and the values &lt;math display="inline"&gt; c_S\in\{0,1\} &lt;/math&gt; are the coefficients of the polynomial. Since there are exactly &lt;math display="inline"&gt; k &lt;/math&gt; coefficients, the message &lt;math display="inline"&gt; x\in\{0,1\}^k &lt;/math&gt; can be used as these coefficients. In this way, each message &lt;math display="inline"&gt; x &lt;/math&gt; gives rise to a unique polynomial &lt;math display="inline"&gt; p_x &lt;/math&gt; in ''m'' variables. To construct the codeword &lt;math display="inline"&gt; C(x) &lt;/math&gt;, the encoder evaluates &lt;math display="inline"&gt; p_x &lt;/math&gt; at all evaluation points &lt;math display="inline"&gt; a\in\{0,1\}^m &lt;/math&gt;, where it interprets the sum as addition modulo two in order to obtain a bit &lt;math display="inline"&gt;(p_x(a)\bmod 2) \in \{0,1\}&lt;/math&gt;. That is, the encoding function is defined via&lt;math display="block"&gt;C(x) = \left(p_x(a)\bmod 2\right)_{a\in\{0,1\}^m}\,.&lt;/math&gt;

The fact that the codeword &lt;math&gt;C(x)&lt;/math&gt; suffices to uniquely reconstruct &lt;math&gt;x&lt;/math&gt; follows from [[Lagrange polynomial|Lagrange interpolation]], which states that the coefficients of a polynomial are uniquely determined when sufficiently many evaluation points are given. Since &lt;math&gt;C(0)=0&lt;/math&gt; and &lt;math&gt;C(x+y)=C(x)+C(y) \bmod 2&lt;/math&gt; holds for all messages &lt;math&gt;x,y\in\{0,1\}^k&lt;/math&gt;, the function &lt;math&gt;C&lt;/math&gt; is a [[linear map]]. Thus the Reed&amp;ndash;Muller code is a [[linear code]].

===== Example =====
For the code {{nowrap|RM(''2'', ''4'')}}, the parameters are as follows:

&lt;math display="inline"&gt; \begin{align}
r&amp;=2\\
m&amp;=4\\
k&amp;=\textstyle\binom{4}{2}+\binom{4}{1}+\binom{4}{0}= 6+4+1=11\\
n&amp;=2^m=16\\
\end{align} &lt;/math&gt;

Let &lt;math display="inline"&gt; C:\{0,1\}^{11}\to\{0,1\}^{16} &lt;/math&gt; be the encoding function just defined. To encode the string x = 1 1010 010101 of length 11, the encoder first constructs the polynomial &lt;math display="inline"&gt; p_x &lt;/math&gt; in 4 variables:&lt;math display="block"&gt;\begin{align}
p_x(Z_1,Z_2,Z_3,Z_4)
&amp;= 1
+ (1\cdot Z_1 + 0\cdot Z_2 + 1\cdot Z_3 + 0\cdot Z_4)
+ (0\cdot Z_1 Z_2 + 1\cdot Z_1Z_3 + 0\cdot Z_1Z_4 + 1\cdot Z_2Z_3 + 0\cdot Z_2Z_4+ 1\cdot Z_3Z_4)\\
&amp;=1+Z_1+Z_3+Z_1Z_3+Z_2Z_3+Z_3Z_4
\end{align}&lt;/math&gt;Then it evaluates this polynomial at all 16 evaluation points:&lt;math display="block"&gt;p_x(0000)= 1,\;
p_x(0001)= 1,\;
p_x(0010)= 1,\;
p_x(0011)= 1,\;

p_x(0100)= 1,\;
p_x(0101)= 0,\;
p_x(0110)= 1,\;
p_x(0111)= 0,\;

p_x(1000)= 0,\;
p_x(1001)= 1,\;
p_x(1010)= 0,\;
p_x(1011)= 1,\;

p_x(1100)= 0,\;
p_x(1101)= 0,\;
p_x(1110)= 0,\;
p_x(1111)= 0\,.&lt;/math&gt;As a result, C(1 1010 010101) = 1111 1010 0101 0000 holds.

=== Decoder ===
{{Expand section|date=August 2018}}
As was already mentioned, Lagrange interpolation can be used to efficiently retrieve the message from a codeword. However, a decoder needs to work even if the codeword has been corrupted in a few positions, that is, when the received word is different from any codeword. In this case, a local decoding procedure can help.

=== Generalization to larger alphabets via low-degree polynomials ===
Using low-degree polynomials over a finite field &lt;math&gt;\mathbb F&lt;/math&gt; of size &lt;math&gt;q&lt;/math&gt;, it is possible to extend the definition of Reed&amp;ndash;Muller codes to alphabets of size &lt;math&gt;q&lt;/math&gt;. Let &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;d&lt;/math&gt; be positive integers, where &lt;math&gt;m&lt;/math&gt; should be thought of as larger than &lt;math&gt;d&lt;/math&gt;. To encode a message &lt;math display="inline"&gt;x\in\mathbb F^k&lt;/math&gt; of with &lt;math&gt;k=\textstyle\binom{m+d}{m}&lt;/math&gt;, the message is again interpreted an &lt;math&gt;m&lt;/math&gt;-variate polynomial &lt;math&gt;p_x&lt;/math&gt; of total degree at most &lt;math&gt;d&lt;/math&gt; and with coefficient from &lt;math&gt;\mathbb F&lt;/math&gt;. Such a polynomial indeed has &lt;math&gt;\textstyle\binom{m+d}{m}&lt;/math&gt; coefficients. The Reed–Muller encoding of &lt;math&gt;x&lt;/math&gt; is the list of all evaluations of &lt;math&gt;p_x(a)&lt;/math&gt; over all &lt;math&gt;a\in\mathbb F^m&lt;/math&gt;. Thus the block length is &lt;math&gt;n=q^m&lt;/math&gt;.

== Description using a generator matrix ==
{{Confusing section|date=March 2011|reason=this section uses dense notation that is not explained well for most readers}}

A generator matrix for a Reed&amp;ndash;Muller code {{nowrap|RM(''r'', ''m'')}} of length {{nowrap|1=''N'' = 2&lt;sup&gt;''m''&lt;/sup&gt;}} can be constructed as follows. Let us write the set of all ''m''-dimensional binary vectors as:

:&lt;math&gt; X = \mathbb{F}_2^m = \{ x_1, \ldots, x_{N} \}.  &lt;/math&gt;

We define in ''N''-dimensional space &lt;math&gt;\mathbb{F}_2^N&lt;/math&gt; the [[indicator vector]]s

:&lt;math&gt;\mathbb{I}_A \in \mathbb{F}_2^N&lt;/math&gt;

on subsets &lt;math&gt; A \subset X &lt;/math&gt; by:

:&lt;math&gt;\left( \mathbb{I}_A \right)_i = \begin{cases} 1 &amp; \mbox{ if } x_i \in A \\ 0 &amp; \mbox{ otherwise} \\ \end{cases} &lt;/math&gt;

together with, also in &lt;math&gt;\mathbb{F}_2^N&lt;/math&gt;, the binary operation

:&lt;math&gt; w \wedge z = (w_1 \cdot z_1, \ldots , w_N \cdot z_N ), &lt;/math&gt;

referred to as the ''wedge product'' (not to be confused with the [[wedge product]] defined in exterior algebra). Here, &lt;math&gt;w=(w_1,w_2,\ldots,w_N)&lt;/math&gt; and &lt;math&gt;z=(z_1,z_2,\ldots, z_N)&lt;/math&gt; are points in &lt;math&gt;\mathbb{F}_2^N&lt;/math&gt; (''N''-dimensional binary vectors), and the operation &lt;math&gt;\cdot&lt;/math&gt; is the usual multiplication in the field &lt;math&gt;\mathbb{F}_2&lt;/math&gt;.

&lt;math&gt;\mathbb{F}_2^m&lt;/math&gt; is an ''m''-dimensional vector space over the field &lt;math&gt;\mathbb{F}_2&lt;/math&gt;, so it is possible to write

&lt;math&gt;(\mathbb{F}_2)^m = \{ (y_m, \ldots , y_1) \mid y_i \in \mathbb{F}_2 \} .&lt;/math&gt;

We define in ''N''-dimensional space &lt;math&gt;\mathbb{F}_2^N&lt;/math&gt; the following vectors with length &lt;math&gt; N: v_0 = (1,1,\ldots,1) &lt;/math&gt; and

:&lt;math&gt; v_i = \mathbb{I}_{ H_i } ,&lt;/math&gt;

where 1 ≤ i ≤ ''m'' and the ''H''&lt;sub&gt;''i''&lt;/sub&gt; are [[hyperplane]]s in &lt;math&gt;(\mathbb{F}_2)^m&lt;/math&gt; (with dimension {{nowrap|''m'' &amp;minus; 1}}):

:&lt;math&gt;H_i = \{ y \in ( \mathbb{F}_2 ) ^m \mid y_i = 0 \} .&lt;/math&gt;

====The generator matrix====
The Reed&amp;ndash;Muller {{nowrap|RM(''r'', ''m'')}} code of order ''r'' and length ''N''&amp;nbsp;=&amp;nbsp;2&lt;sup&gt;''m''&lt;/sup&gt; is the code generated by ''v''&lt;sub&gt;0&lt;/sub&gt; and the wedge products of up to ''r'' of the ''v''&lt;sub&gt;''i''&lt;/sub&gt;, {{nowrap|1 ≤ ''i'' ≤ ''m''}}  (where by convention a wedge product of fewer than one vector is the identity for the operation). In other words, we can build a generator matrix for the {{nowrap|RM(''r'', ''m'')}} code, using vectors and their wedge product permutations up to ''r'' at a time &lt;math&gt;{v_0, v_1, \ldots, v_n, \ldots, (v_{i_1} \wedge v_{i_2}), \ldots (v_{i_1} \wedge v_{i_2} \ldots \wedge v_{i_r})}&lt;/math&gt;, as the rows of the generator matrix, where {{nowrap|1 ≤ ''i''&lt;sub&gt;''k''&lt;/sub&gt; ≤ ''m''}}.

====Example 1====

Let ''m'' = 3. Then ''N'' = 8, and

:&lt;math&gt; X = \mathbb{F}_2^3 = \{ (0,0,0), (0,0,1),  \ldots, (1,1,1) \}, &lt;/math&gt;

and

:&lt;math&gt;
\begin{align}
v_0 &amp; = (1,1,1,1,1,1,1,1) \\[2pt]
v_1 &amp; = (1,0,1,0,1,0,1,0) \\[2pt]
v_2 &amp; = (1,1,0,0,1,1,0,0) \\[2pt]
v_3 &amp; = (1,1,1,1,0,0,0,0).
\end{align}
&lt;/math&gt;

The RM(1,3) code is generated by the set

:&lt;math&gt; \{ v_0, v_1, v_2, v_3 \},\, &lt;/math&gt;

or more explicitly by the rows of the matrix:

:&lt;math&gt;
\begin{pmatrix}
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0
\end{pmatrix}
&lt;/math&gt;

====Example 2====

The RM(2,3) code is generated by the set:
:&lt;math&gt; \{ v_0, v_1, v_2, v_3, v_1 \wedge v_2, v_1 \wedge v_3, v_2 \wedge v_3 \} &lt;/math&gt;

or more explicitly by the rows of the matrix:

:&lt;math&gt;
\begin{pmatrix}
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
\end{pmatrix}
&lt;/math&gt;

===Properties===
The following properties hold:

# The set of all possible wedge products of up to ''m'' of the ''v''&lt;sub&gt;''i''&lt;/sub&gt; form a basis for &lt;math&gt;\mathbb{F}_2^N&lt;/math&gt;.
# The RM&amp;thinsp;(''r'', ''m'') code has [[linear code|rank]]
#:&lt;math&gt; \sum_{s=0}^r {m \choose s}. &lt;/math&gt;
# {{math|1=RM&amp;thinsp;(''r'', ''m'') = RM&amp;thinsp;(''r'', ''m ''&amp;minus; 1) {{!}} RM&amp;thinsp;(''r'' &amp;minus; 1, ''m'' &amp;minus; 1)}} where '|' denotes the [[bar product (coding theory)|bar product]] of two codes.
# {{math|1=RM&amp;thinsp;(''r'', ''m'')}} has minimum [[Hamming weight]] 2&lt;sup&gt;''m'' &amp;minus; ''r''&lt;/sup&gt;.

====Proof====
{{Ordered list
|
There are

::&lt;math&gt; \sum_{s=0}^m { m \choose s } = 2^m = N &lt;/math&gt;

such vectors and &lt;math&gt;\mathbb{F}_2^N&lt;/math&gt; have dimension ''N'' so it is sufficient to check that the ''N'' vectors span; equivalently it is sufficient to check that &lt;math&gt;\mathrm{RM}(m, m) = \mathbb{F}_2^N&lt;/math&gt;.

Let ''x'' be a binary vector of length ''m'', an element of ''X''.  Let (''x'')&lt;sub&gt;''i''&lt;/sub&gt; denote the ''i''&lt;sup&gt;th&lt;/sup&gt; element of ''x''.  Define

::&lt;math&gt;y_i = \begin{cases} v_i &amp; \text{ if } (x)_i = 0 \\ v_0+v_i &amp; \text{ if } (x)_i = 1 \\ \end{cases} &lt;/math&gt;
where 1 ≤ ''i'' ≤''m''.

Then &lt;math&gt;\mathbb{I}_{ \{ x \} } = y_1 \wedge \cdots \wedge y_m &lt;/math&gt;

Expansion via the distributivity of the wedge product gives &lt;math&gt; \mathbb{I}_{ \{ x \} } \in \mathrm{RM}(m,m) &lt;/math&gt;. Then since the vectors &lt;math&gt;\{ \mathbb{I}_{ \{ x \} } \mid x \in X \} &lt;/math&gt; span &lt;math&gt;\mathbb{F}_2^N&lt;/math&gt; we have &lt;math&gt;\mathrm{RM}(m,n)=\mathbb{F}_2^N&lt;/math&gt;.

|
By '''1''', all such wedge products must be linearly independent, so the rank of RM(''r, m'') must simply be the number of such vectors.

|
Omitted.

|4=
By induction.

:The {{math|1=RM(0,&amp;nbsp;''m'')}} code is the repetition code of length {{math|1=''N''&amp;nbsp;=2&lt;sup&gt;''m''&lt;/sup&gt;}} and weight ''N'' = 2&lt;sup&gt;''m''&amp;minus;0&lt;/sup&gt; = 2&lt;sup&gt;''m''&amp;minus;''r''&lt;/sup&gt;. By '''1''' &lt;math&gt;\mathrm{RM}(m,n)=\mathbb{F}_2^n&lt;/math&gt; and has weight 1 = 2&lt;sup&gt;0&lt;/sup&gt; = 2&lt;sup&gt;''m''&amp;minus;''r''&lt;/sup&gt;.

The article [[bar product (coding theory)]] gives a proof that the weight of the bar product of two codes ''C''&lt;sub&gt;1&lt;/sub&gt; , ''C''&lt;sub&gt;2&lt;/sub&gt; is given by

::&lt;math&gt;\min \{ 2w(C_1), w(C_2) \} &lt;/math&gt;

:If 0 &lt; ''r'' &lt; ''m'' and if {{Ordered list |list_style_type=lower-roman
|{{math|1=RM(''r'',''m''&amp;nbsp;&amp;minus;&amp;nbsp;1)}} has weight {{math|1=2&lt;sup&gt;''m''&amp;minus;1&amp;minus;''r''&lt;/sup&gt;}}
|{{math|1=RM(''r''&amp;nbsp;&amp;minus;&amp;nbsp;1,''m''&amp;nbsp;&amp;minus;&amp;nbsp;1)}} has weight {{math|1=2&lt;sup&gt;''m''&amp;minus;1&amp;minus;(''r''&amp;minus;1)&lt;/sup&gt; = 2&lt;sup&gt;''m''&amp;minus;''r''&lt;/sup&gt;}}
}}
:then the bar product has weight

::&lt;math&gt;\min \{ 2 \times 2^{m-1-r}, 2^{m-r} \} = 2^{m-r} .&lt;/math&gt;
}}
=== Decoding RM codes ===
RM(''r'', ''m'') codes can be decoded using [[majority logic decoding]]. The basic idea of majority logic decoding is
to build several checksums for each received code word element. Since each of the different checksums must all
have the same value (i.e. the value of the message word element weight), we can use a majority logic decoding to decipher
the value of the message word element. Once each order of the polynomial is decoded, the received word is modified
accordingly by removing the corresponding codewords weighted by the decoded message contributions, up to the present stage.
So for a ''r''th order RM code, we have to decode iteratively r+1, times before we arrive at the final
received code-word. Also, the values of the message bits are calculated through this scheme; finally we can calculate
the codeword by multiplying the message word (just decoded) with the generator matrix.

One clue if the decoding succeeded, is to have an all-zero modified received word, at the end of (''r''&amp;nbsp;+&amp;nbsp;1)-stage decoding
through the majority logic decoding. This technique was proposed by Irving S. Reed, and is more general when applied
to other finite geometry codes.

==Description using a recursive construction==

A Reed–Muller code RM(''r,m'') exists for any integers &lt;math&gt;m \ge 0&lt;/math&gt; and &lt;math&gt;0 \le r \le m&lt;/math&gt;. RM(''m'', ''m'') is defined as the universe (&lt;math&gt;2^m,2^m,1&lt;/math&gt;) code. RM(&amp;minus;1,m) is defined as the trivial code (&lt;math&gt;2^m,0,\infty&lt;/math&gt;). The remaining RM codes may be constructed from these elementary codes using the length-doubling construction

:&lt;math&gt;\mathrm{RM}(r,m) = \{(\mathbf{u},\mathbf{u}+\mathbf{v})\mid\mathbf{u} \in \mathrm{RM}(r,m-1),\mathbf{v} \in \mathrm{RM}(r-1,m-1)\}.&lt;/math&gt;

From this construction, RM(''r,m'') is a binary [[linear block code]] (''n'', ''k'', ''d'') with length {{math|1=''n''&amp;nbsp;=&amp;nbsp;2&lt;sup&gt;''m''&lt;/sup&gt;}}, dimension &lt;math&gt;k(r,m)=k(r,m-1)+k(r-1,m-1)&lt;/math&gt; and minimum distance &lt;math&gt;d = 2^{m-r}&lt;/math&gt; for &lt;math&gt;r \ge 0&lt;/math&gt;. The [[dual code]] to RM(''r,m'') is RM(''m''-''r''-1,''m''). This shows that repetition and SPC codes are duals, biorthogonal and extended Hamming codes are duals and that codes with {{math|1=''k''&amp;nbsp;=&amp;nbsp;''n''/2}} are self-dual.

==Special cases of Reed&amp;ndash;Muller codes==

=== Table of all RM(r,m) codes for m≤5 ===
All {{math|1=RM(''r'',&amp;nbsp;''m'')}} codes with &lt;math&gt;m\le 5&lt;/math&gt;  and alphabet size 2 are displayed here, annotated with the standard [n,k,d] [[Block code#Popular notation|coding theory notation]] for [[block code]]s. The code {{math|1=RM(''r'',&amp;nbsp;''m'')}} is a &lt;math&gt;\textstyle [2^m,k,2^{m-r}]_2&lt;/math&gt;-code, that is, it is a [[linear code]] over a [[binary set|binary alphabet]], has [[Block code#The block length n|block length]] &lt;math&gt;\textstyle 2^m&lt;/math&gt;, [[Block code#The message length k|message length]] (or dimension) {{mvar|k}}, and [[Block code#The distance d|minimum distance]] &lt;math&gt;\textstyle 2^{m-r}&lt;/math&gt;.

{|
|-
|
|
|
|
|
|
|{{math|1=RM(''m,m'')}}&lt;br /&gt;({{math|1=2&lt;sup&gt;''m''&lt;/sup&gt;}}, {{math|1=2&lt;sup&gt;''m''&lt;/sup&gt;}}, 1)
|universe codes
|-
|
|
|
|
|
|RM(5,5)&lt;br /&gt;(32,32,1)
|-
|
|
|
|
|RM(4,4)&lt;br /&gt;(16,16,1)
|
|{{math|1=RM(''m''&amp;nbsp;&amp;minus;&amp;nbsp;1,&amp;nbsp;''m'')}}&lt;br /&gt;{{math|1=(2&lt;sup&gt;''m''&lt;/sup&gt;, 2&lt;sup&gt;''m''&lt;/sup&gt;&amp;minus;1, 2)}}
|[[parity bit|SPC]] codes
|-
|
|
|
|RM(3,3)&lt;br /&gt;(8,8,1)
|
|RM(4,5)&lt;br /&gt;(32,31,2)
|-
|
|
|RM(2,2)&lt;br /&gt;(4,4,1)
|
|RM(3,4)&lt;br /&gt;(16,15,2)
|
|{{math|1=RM(''m''&amp;nbsp;&amp;minus;&amp;nbsp;2, ''m'')}}&lt;br /&gt;{{math|1=(2&lt;sup&gt;''m''&lt;/sup&gt;, 2&lt;sup&gt;''m''&lt;/sup&gt;&amp;minus;''m''&amp;minus;1, 4)}}
|ext. [[Hamming code]]s
|-
|
|RM(1,1)&lt;br /&gt;(2,2,1)
|
|RM(2,3)&lt;br /&gt;(8,7,2)
|
|RM(3,5)&lt;br /&gt;(32,26,4)
|-
|RM(0,0)&lt;br /&gt;(1,1,1)
|
|RM(1,2)&lt;br /&gt;(4,3,2)
|
|RM(2,4)&lt;br /&gt;(16,11,4)
|-
|
|RM(0,1)&lt;br /&gt;(2,1,2)
|
|RM(1,3)&lt;br /&gt;(8,4,4)
|
|RM(2,5)&lt;br /&gt;(32,16,8)
|
|[[self-dual code]]s
|-
|RM(&amp;minus;1,0)&lt;br /&gt;(1,0,&lt;math&gt;\infty&lt;/math&gt;)
|
|RM(0,2)&lt;br /&gt;(4,1,4)
|
|RM(1,4)&lt;br /&gt;(16,5,8)
|-
|
|RM(−1,1)&lt;br /&gt;(2,0,&lt;math&gt;\infty&lt;/math&gt;)
|
|RM(0,3)&lt;br /&gt;(8,1,8)
|
|RM(1,5)&lt;br /&gt;(32,6,16)
|-
|
|
|RM(−1,2)&lt;br /&gt;(4,0,&lt;math&gt;\infty&lt;/math&gt;)
|
|RM(0,4)&lt;br /&gt;(16,1,16)
|
|{{math|1=RM(1,''m'')}}&lt;br /&gt;{{math|1=(2&lt;sup&gt;''m''&lt;/sup&gt;, ''m''+1, 2&lt;sup&gt;''m''&amp;minus;1&lt;/sup&gt;)}}
|Punctured [[hadamard code]]s
|-
|
|
|
|RM(&amp;minus;1,3)&lt;br /&gt;(8,0,&lt;math&gt;\infty&lt;/math&gt;)
|
|RM(0,5)&lt;br /&gt;(32,1,32)
|-
|
|
|
|
|RM(&amp;minus;1,4)&lt;br /&gt;(16,0,&lt;math&gt;\infty&lt;/math&gt;)
|
|{{math|1=RM(0,''m'')}}&lt;br /&gt;{{math|1=(2&lt;sup&gt;''m''&lt;/sup&gt;, 1, 2&lt;sup&gt;''m''&lt;/sup&gt;)}}
|[[repetition code]]s
|-
|
|
|
|
|
|RM(&amp;minus;1,5)&lt;br /&gt;(32,0,&lt;math&gt;\infty&lt;/math&gt;)
|-
|
|
|
|
|
|
|{{math|1=RM(&amp;minus;1,''m'')}}&lt;br /&gt;{{math|1=(2&lt;sup&gt;''m''&lt;/sup&gt;, 0, &amp;infin;)}}
|trivial codes
|}

=== Properties of RM(r,m) codes for r≤1 or r≥m-1 ===

*{{math|1=RM(0,&amp;nbsp;''m'')}} codes are [[Repetition code|repetition codes]] of length {{math|1=''N''&amp;nbsp;=&amp;nbsp;2&lt;sup&gt;''m''&lt;/sup&gt;}}, [[code rate|rate]] &lt;math&gt;{R=\tfrac{1}{N}}&lt;/math&gt; and minimum distance &lt;math&gt;d_\min = N&lt;/math&gt;.

*{{math|1=RM(1,&amp;nbsp;''m'')}} codes are [[Low-density parity-check code|parity check codes]] of length {{math|1=''N''&amp;nbsp;=&amp;nbsp;2&lt;sup&gt;''m''&lt;/sup&gt;}}, rate &lt;math&gt;R=\tfrac{m+1}{N}&lt;/math&gt; and minimum distance &lt;math&gt;d_\min = \tfrac{N}{2}&lt;/math&gt;.

*{{math|1=RM(''m''&amp;nbsp;&amp;minus;&amp;nbsp;1,&amp;nbsp;''m'')}} codes are [[Low-density parity-check code|single parity check codes]] of length {{math|1=''N''&amp;nbsp;=&amp;nbsp;2&lt;sup&gt;''m''&lt;/sup&gt;}}, rate &lt;math&gt;R=\tfrac{N-1}{N}&lt;/math&gt; and minimum distance &lt;math&gt;d_\min = 2&lt;/math&gt;.

*{{math|1=RM(''m''&amp;nbsp;&amp;minus;&amp;nbsp;2,&amp;nbsp;''m'')}} codes are the family of [[Hamming code|extended Hamming codes]] of length {{math|1=''N''&amp;nbsp;=&amp;nbsp;2&lt;sup&gt;''m''&lt;/sup&gt;}} with minimum distance &lt;math&gt;d_\min = 4&lt;/math&gt;.&lt;ref&gt;Trellis and Turbo Coding, C. Schlegel &amp; L. Perez, Wiley Interscience, 2004, p149.&lt;/ref&gt;

== References ==
{{reflist}}

== Further reading ==

* {{cite book | author=Shu Lin |author2=Daniel Costello  | title=Error Control Coding | edition=2 | year=2005 | publisher=Pearson | isbn=978-0-13-017973-9 }} Chapter 4.
* {{cite book | author=J.H. van Lint | title=Introduction to Coding Theory | edition=2 | publisher=[[Springer-Verlag]] | series=[[Graduate Texts in Mathematics|GTM]] | volume=86 | year=1992 | isbn=978-3-540-54894-2 }} Chapter 4.5.

==External links==
* [http://ocw.mit.edu MIT OpenCourseWare], 6.451 Principles of Digital Communication II, Lecture Notes section 6.4
* [http://octave.sourceforge.net/communications/function/reedmullergen.html GPL Matlab-implementation of RM-codes ]
* [http://octave.svn.sourceforge.net/viewvc/octave/trunk/octave-forge/main/comm/inst/reedmullergen.m?revision=9852&amp;view=markup Source GPL Matlab-implementation of RM-codes]
*{{cite journal |last1=Weiss |first1=E. |title=Generalized Reed-Muller codes |journal=Information and Control |date=September 1962 |volume=5 |issue=3 |pages=213–222 |doi=10.1016/s0019-9958(62)90555-7 |issn=0019-9958}}

{{CCSDS}}

{{DEFAULTSORT:Reed-Muller code}}
[[Category:Error detection and correction]]
[[Category:Coding theory]]
[[Category:Theoretical computer science]]</text>
      <sha1>6abpmwp4i23vuydw9eerexml6v5iovi</sha1>
    </revision>
  </page>
  <page>
    <title>Robbins algebra</title>
    <ns>0</ns>
    <id>5825422</id>
    <revision>
      <id>868660685</id>
      <parentid>860811361</parentid>
      <timestamp>2018-11-13T17:02:40Z</timestamp>
      <contributor>
        <username>XOR'easter</username>
        <id>30746614</id>
      </contributor>
      <comment>/* See also */ -1 item redundant with main text; +1</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3199">{{no footnotes|date=June 2015}}
In [[abstract algebra]], a '''Robbins algebra''' is an [[Universal algebra#Basic idea|algebra]] containing a single [[binary operation]], usually denoted by &lt;math&gt;\lor&lt;/math&gt;, and a single [[unary operation]] usually denoted by &lt;math&gt;\neg&lt;/math&gt;. These operations satisfy the following [[Universal algebra#Equations|axioms]]:

For all elements ''a'', ''b'', and ''c'':
# [[Associativity]]: &lt;math&gt;a \lor \left(b \lor c \right) = \left(a \lor b \right) \lor c&lt;/math&gt;
# [[Commutativity]]: &lt;math&gt;a \lor b = b \lor a&lt;/math&gt;
# ''Robbins equation'': &lt;math&gt;\neg \left( \neg \left(a \lor b \right) \lor \neg \left(a \lor \neg b \right) \right) = a&lt;/math&gt;

For many years, it was conjectured, but unproven, that all Robbins algebras are [[Boolean algebra (structure)|Boolean algebra]]s.  This was proved in 1996, so the term "Robbins algebra" is now simply a synonym for "Boolean algebra".

== History ==
In 1933, [[Edward Huntington]] proposed a new set of axioms for Boolean algebras, consisting of (1) and (2) above, plus: 
*''Huntington's equation'': &lt;math&gt;\neg(\neg a \lor b) \lor \neg(\neg a \lor \neg b) = a.&lt;/math&gt;
From these axioms, Huntington derived the usual axioms of Boolean algebra.

Very soon thereafter, [[Herbert Robbins]] posed the "Robbins conjecture", namely that the Huntington equation could be replaced with what came to be called the Robbins equation, and the result would still be [[Boolean algebra (structure)|Boolean algebra]]. &lt;math&gt;\lor&lt;/math&gt; would interpret Boolean [[Boolean algebra (structure)#Definition|join]] and &lt;math&gt;\neg&lt;/math&gt; Boolean [[Boolean algebra (structure)#Definition|complement]]. Boolean [[Boolean algebra (structure)#Definition|meet]] and the constants 0 and 1 are easily defined from the Robbins algebra primitives. Pending verification of the conjecture, the system of Robbins was called "Robbins algebra."

Verifying the Robbins conjecture required proving Huntington's equation, or some other axiomatization of a Boolean algebra, as theorems of a Robbins algebra. Huntington, Robbins, [[Alfred Tarski]], and others worked on the problem, but failed to find a proof or counterexample.

[[William McCune]] proved the conjecture in 1996, using the [[automated theorem proving|automated theorem prover]] [[EQP]]. For a complete proof of the Robbins conjecture in one consistent notation and following McCune closely, see Mann (2003). Dahn (1998) simplified McCune's machine proof.

==See also==
* [[Algebraic structure]]
* [[Minimal axioms for Boolean algebra]]

==References==
* Dahn, B. I. (1998) Abstract to "[https://www.sciencedirect.com/science/article/pii/S0021869398974671 Robbins Algebras Are Boolean: A Revision of McCune's Computer-Generated Solution of Robbins Problem,]" ''Journal of Algebra'' 208(2): 526–32.
* Mann, Allen (2003) "[http://math.colgate.edu/~amann/MA/robbins_complete.pdf A Complete Proof of the Robbins Conjecture.]"
* [[William McCune]], "[http://calculemus.org/MathUniversalis/4/6robbins.html Robbins Algebras Are Boolean,]" With links to proofs and other papers.

{{DEFAULTSORT:Robbins Algebra}}
[[Category:Boolean algebra]]
[[Category:Formal methods]]
[[Category:Computer-assisted proofs]]</text>
      <sha1>blreafc2fgx5aw9f0bwnfoe9b2gtujk</sha1>
    </revision>
  </page>
  <page>
    <title>Ruth I. Michler Memorial Prize</title>
    <ns>0</ns>
    <id>59217697</id>
    <revision>
      <id>871548032</id>
      <parentid>871546934</parentid>
      <timestamp>2018-12-01T21:08:41Z</timestamp>
      <contributor>
        <username>Queen-washington</username>
        <id>31632445</id>
      </contributor>
      <comment>/* Winner */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2185">The '''Ruth I. Michler Memorial Prize''' is a  mathematics prize awarded by the [[Association for Women in Mathematics]].
The prize is a fellowship, and lecture at [[Cornell University]].
==Winner==
{|
!Date
!Recipient
!Lecture title
|-
|March 2018
|[[Julie Bergner]] the University of Virginia&lt;ref&gt;https://www.cbmsweb.org/wp-content/uploads/2018/05/PR-Michler-2018-Bergner-1.pdf&lt;/ref&gt;&lt;ref&gt;http://math.virginia.edu/2018/01/Bergner-Michler-prize/&lt;/ref&gt;
|
|-
|November 2017	||[[Julia Gordon]], the University of British Columbia	||Wilkie's theorem and (ineffective) uniform bounds 
|-
|March 2017	||[[Pallavi Dani]], Louisiana State University	||Large-scale geometry of right-angled Coxeter groups 
|-
|October 2015	||[[Malabika Pramanik]], University of British Columbia	||Needles, Bushes, Hairbrushes, and Polynomials 
|-
|March 2015	||[[Sema Salur]], University of Rochester	||Manifolds with G2 structure and beyond 
|-
|March 2015	||[[Megumi Harada]], McMaster University	||Newton-Okounkov bodies and integrable systems 
|-
|October 2012	||[[Ling Long (mathematician)|Ling Long]], Iowa State University||Atkin and Swinnerton-Dyer Congruences
|-
|March 2012	||[[Anna Mazzucato]], Pennsylvania State University	||The Analysis of Incompressible Fluids at High Reynolds Numbers
|-
|November 2012	||[[Patricia Hersh]], North Carolina State University	||Regular CS Complexes, Total Positivity and Bruhat Order
|-
|April 2010	||[[Maria Gordina]], University of Connecticut&lt;ref&gt;https://today.uconn.edu/2009/03/maria-gordina-ruth-i-michler-memorial-prize/&lt;/ref&gt;	||Lie's Third Theorem in Infinite Dimensions 
|-
|October 2008	||[[Irina Mitrea]], University of Virginia	||Boundary-Value Problems for Higher-Order Elliptic Operators 
|-
|September 2007	||[[Rebecca Goldin]], George Mason University	||The Geometry of Polygons 
|}&lt;ref&gt;https://math.cornell.edu/department-awards&lt;/ref&gt;

==References==
{{reflist}}
==External links==
*http://www-groups.dcs.st-and.ac.uk/history/Honours/Michler_Memorial_Prize.html
*https://www.mathprograms.org/db/programs/711
[[category:2007 establishments]]
[[Category:Mathematics awards]]
[[Category:Awards and prizes of the Association for Women in Mathematics]]</text>
      <sha1>pr1inj6r4ccl363maa2ea5aj2rdh3us</sha1>
    </revision>
  </page>
  <page>
    <title>Sociable number</title>
    <ns>0</ns>
    <id>332307</id>
    <revision>
      <id>857827525</id>
      <parentid>849085388</parentid>
      <timestamp>2018-09-03T08:19:36Z</timestamp>
      <contributor>
        <username>Xayahrainie43</username>
        <id>34489455</id>
      </contributor>
      <comment>/* List of known sociable numbers */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5403">'''Sociable numbers''' are numbers whose [[Aliquot sum#Definition|aliquot sums]] form a cyclic sequence that begins and ends with the same number. They are generalizations of the concepts of [[amicable number]]s and [[perfect number]]s. The first two sociable sequences, or sociable chains, were discovered and named by the [[Belgium|Belgian]] [[mathematics|mathematician]] [[Paul Poulet (mathematician)|Paul Poulet]] in 1918.&lt;ref&gt;P. Poulet, #4865, [[L'Intermédiaire des Mathématiciens]] '''25''' (1918), pp.&amp;nbsp;100–101. (The full text can be found at [https://proofwiki.org/wiki/Catalan-Dickson_Conjecture ProofWiki: Catalan-Dickson Conjecture].)&lt;/ref&gt; In a set of sociable numbers, each number is the sum of the [[proper factors]] of the preceding number, i.e., the sum excludes the preceding number itself. For the sequence to be sociable, the sequence must be cyclic and return to its starting point.

The [[Frequency|period]] of the sequence, or order of the set of sociable numbers, is the number of numbers in this cycle.

If the period of the sequence is 1, the number is a sociable number of order 1, or a [[perfect number]]—for example, the [[proper divisor]]s of 6 are 1, 2, and 3, whose sum is again 6. A pair of [[amicable number]]s is a set of sociable numbers of order 2.  There are no known sociable numbers of order 3, and searches for them have been made up to &lt;math&gt;5 \times 10^7&lt;/math&gt; as of 1970 &lt;ref&gt;{{Cite journal|last=Bratley|first=Paul|last2=Lunnon|first2=Fred|last3=McKay|first3=John|date=1970|title=Amicable numbers and their distribution|url=http://www.ams.org/home/page/|journal=Mathematics of Computation|language=en-US|volume=24|issue=110|pages=431–432|doi=10.1090/S0025-5718-1970-0271005-8|issn=0025-5718}}&lt;/ref&gt;.

It is an open question whether all numbers end up at either a sociable number or at a [[Prime number|prime]] (and hence 1), or, equivalently, whether there exist numbers whose [[aliquot sequence]] never terminates, and hence grows without bound.

== Example ==

An example with period 4:
:The sum of the proper divisors of &lt;math&gt;1264460&lt;/math&gt; (&lt;math&gt;=2^2\cdot5\cdot17\cdot3719&lt;/math&gt;) is:
::1 + 2 + 4 + 5 + 10 + 17 + 20 + 34 + 68 + 85 + 170 + 340 + 3719 + 7438 + 14876 + 18595 + 37190 + 63223 + 74380 + 126446 + 252892 + 316115 + 632230 = 1547860

:The sum of the proper divisors of &lt;math&gt;1547860&lt;/math&gt; (&lt;math&gt;=2^2\cdot5\cdot193\cdot401&lt;/math&gt;) is:
::1 + 2 + 4 + 5 + 10 + 20 + 193 + 386 + 401 + 772 + 802 + 965 + 1604 + 1930 + 2005 + 3860 + 4010 + 8020 + 77393 + 154786 + 309572 + 386965 + 773930 = 1727636

:The sum of the proper divisors of &lt;math&gt;1727636&lt;/math&gt; (&lt;math&gt;=2^2\cdot521\cdot829&lt;/math&gt;) is:
::1 + 2 + 4 + 521 + 829 + 1042 + 1658 + 2084 + 3316 + 431909 + 863818 = 1305184

:The sum of the proper divisors of &lt;math&gt;1305184&lt;/math&gt; (&lt;math&gt;=2^5\cdot40787&lt;/math&gt;) is:
::1 + 2 + 4 + 8 + 16 + 32 + 40787 + 81574 + 163148 + 326296 + 652592 = 1264460.

== List of known sociable numbers ==

The following categorizes all known sociable numbers as of July 2018 by the length of the corresponding aliquot sequence:

{| align="center" border="1" cellpadding="4"
|- bgcolor="#A0E0A0" align="center"
!Sequence
length
!Number of known 
sequences 
|- align="center"
|1
(''[[Perfect number]]'')
|50
|- align="center"
|2
(''[[Amicable number]]'')
|1222207191&lt;ref&gt;Sergei Chernykh [http://sech.me/ap/ Amicable pairs list]&lt;/ref&gt;
|- align="center"
|4
|5398
|- align="center"
|5
|1
|- align="center"
|6
|5
|- align="center"
|8
|4
|- align="center"
|9
|1
|- align="center"
|28
|1
|}

It is conjectured that if ''n'' = 3 mod 4, then there are no such sequence with length ''n''.

The smallest number of the only known 28-cycle is 14316.

== Searching for sociable numbers ==

The [[aliquot sequence]] can be represented as a [[directed graph]], &lt;math&gt;G_{n,s}&lt;/math&gt;, for a given integer &lt;math&gt;n&lt;/math&gt;, where &lt;math&gt;s(k)&lt;/math&gt; denotes the
sum of the proper divisors of &lt;math&gt;k&lt;/math&gt;.&lt;ref&gt;{{citation|title=Distributed cycle detection in large-scale sparse graphs|first1=Rodrigo Caetano|last1=Rocha|first2=Bhalchandra|last2=Thatte|year=2015|url=https://dx.doi.org/10.13140/RG.2.1.1233.8640|publisher=Simpósio Brasileiro de Pesquisa Operacional (SBPO)|format=PDF}}&lt;/ref&gt;
[[cycle (graph theory)|Cycles]] in &lt;math&gt;G_{n,s}&lt;/math&gt; represent sociable numbers within the interval &lt;math&gt;[1,n]&lt;/math&gt;. Two special cases are loops that represent [[perfect numbers]] and cycles of length two that represent [[amicable pairs]].

== Conjecture of the sum of sociable number cycles ==
As the number of sociable number cycles with length greater than 2 approaches infinity, the percentage of the sums of the sociable number cycles divisible by 10 approaches 100%.{{OEIS|A292217}}.

==References==
{{Reflist}}
*H. Cohen, ''On amicable and sociable numbers,'' Math. Comp. '''24''' (1970), pp.&amp;nbsp;423–429

== External links ==
*[http://djm.cc/sociable.txt A list of known sociable numbers]
*[https://web.archive.org/web/20140502102524/http://amicable.homepage.dk/tables.htm Extensive tables of perfect, amicable and sociable numbers]
*{{mathworld |urlname=SociableNumbers |title=Sociable numbers}}
*[[oeis:A003416|A003416 (smallest sociable number from each cycle)]] and [[oeis:A122726|A122726 (all sociable numbers)]] in [[OEIS]]

{{Divisor classes}}
{{Classes of natural numbers}}

[[Category:Divisor function]]
[[Category:Integer sequences]]
[[Category:Number theory]]</text>
      <sha1>g8jps8f8riokh4mem0ayu5uwdigpaun</sha1>
    </revision>
  </page>
  <page>
    <title>Special Integrals of Gradshteyn and Ryzhik: the Proofs</title>
    <ns>0</ns>
    <id>49622162</id>
    <redirect title="Gradshteyn and Ryzhik" />
    <revision>
      <id>785803589</id>
      <parentid>742984402</parentid>
      <timestamp>2017-06-15T14:20:11Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Redirect category shell|Redirect category shell]]}} for multiple-{{R}} #Rs using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="272">#REDIRECT [[Gradshteyn and Ryzhik#Proofs]]

{{Redirect category shell|1=
{{R to related topic}}
{{R to section}}
}}

[[Category:2014 books]]&lt;!-- 1st edition of volume I --&gt;
[[Category:2015 non-fiction books]]&lt;!-- 1st edition of volume II --&gt;
[[Category:Mathematics books]]</text>
      <sha1>d0srifvpikrqvpbtudx2mm1o9i7x4sx</sha1>
    </revision>
  </page>
  <page>
    <title>St-connectivity</title>
    <ns>0</ns>
    <id>2833034</id>
    <revision>
      <id>796758904</id>
      <parentid>738323263</parentid>
      <timestamp>2017-08-22T21:57:09Z</timestamp>
      <contributor>
        <username>Noamz</username>
        <id>8567556</id>
      </contributor>
      <comment>/* Complexity */ clarification</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3236">{{lowercase|st-connectivity}}
In [[computer science]] and [[computational complexity theory]], '''st-connectivity''' or '''STCON''' is a [[decision problem]] asking, for vertices ''s'' and ''t'' in a [[directed graph]], if ''t'' is [[reachability|reachable]] from ''s''.

Formally, the decision problem is given by
:{{math|1=PATH = {{mset|{{angbr|''D'',&amp;nbsp;''s'',&amp;nbsp;''t''}} | ''D'' is a directed graph with a path from vertex ''s'' to ''t''}}}}.

== Complexity ==
The problem can be shown to be in [[NL (complexity)|NL]], as a [[non-deterministic Turing machine]] can guess the next node of the path, while the only information which has to be stored is the total length of the path and which node is  currently under consideration. The algorithm terminates if either the target node ''t'' is reached, or the length of the path so far exceeds ''n'', the number of nodes in the graph.

The complement of ''st-connectivity'', known as ''st-non-connectivity'', is also in the class NL, since NL&amp;nbsp;=&amp;nbsp;coNL by the [[Immerman–Szelepcsényi theorem]].

In particular, the problem of ''st-connectivity'' is actually [[NL-complete]], that is, every problem in the class NL is reducible to connectivity under a [[log-space reduction]]. This remains true for the stronger case of [[first-order reduction]]s {{Harv|Immerman|1999|p = 51}}. The log-space reduction from any language in NL to STCON proceeds as follows: Consider the non-deterministic log-space Turing machine M that accepts a language in NL. Since there is only logarithmic space on the work tape, all possible states of the Turing machine (where a state is the state of the internal finite state machine, the position of the head and the contents of the work tape) are polynomially many. Map all possible states of the deterministic log-space machine to vertices of a graph, and put an edge between u and v if the state v can be reached from u within one step of the non-deterministic machine. Now the problem of whether the machine accepts is the same as the problem of whether there exists a path from the start state to the accepting state.

[[Savitch's theorem]] guarantees that the algorithm can be simulated in ''O''(log&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;''n'') deterministic space. 

The same problem for [[undirected graph]]s is called ''undirected s-t connectivity'' and was shown to be [[L (complexity)|L]]-complete by [[Omer Reingold]].  This research won him the 2005 [[Grace Murray Hopper Award]].  Undirected st-connectivity was previously known to be complete for the class [[SL (complexity)|SL]], so Reingold's work showed that SL is the same class as&amp;nbsp;L. On alternating graphs, the problem is [[P (complexity)|P]]-complete {{Harv|Immerman|1999|p = 54}}.

== References ==
*{{citation | last = Sipser | first = Michael | authorlink = Michael Sipser | title=Introduction to the Theory of Computation | publisher=Thompson Course Technology | year=2006 | isbn=0-534-95097-3}}
*{{citation | last = Immerman | first = Neil | authorlink = Neil Immerman | title = Descriptive Complexity | year = 1999 | publisher = Springer-Verlag | location = New York | isbn = 0-387-98600-6}}

[[Category:Graph connectivity]]
[[Category:Directed graphs]]
[[Category:NL-complete problems]]</text>
      <sha1>rlaw6nmhzfj505dl0y4wn18xpea9hy7</sha1>
    </revision>
  </page>
  <page>
    <title>The Ambidextrous Universe</title>
    <ns>0</ns>
    <id>12987835</id>
    <revision>
      <id>805831498</id>
      <parentid>786844434</parentid>
      <timestamp>2017-10-17T22:21:45Z</timestamp>
      <contributor>
        <username>Toploftical</username>
        <id>16162765</id>
      </contributor>
      <comment>add template</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5941">{{Infobox book
| name          = The Ambidextrous Universe
| title_orig    =
| translator    =
| image         = File:The Ambidextrous Universe, first edition.jpg
| caption       = Cover of the first edition
| author        = [[Martin Gardner]]
| illustrator   = John Mackey
| cover_artist  = [[Germano Facetti]]
| country       = United States
| language      = English
| series        =
| subject       = [[Symmetry]], [[Science|Scientific]], [[Mathematics]]
| genre         =
| publisher     = [[Penguin Books]]
| release_date  = 1964
| media_type    = Print ([[Paperback]])
| pages         = 276 (1st edition) &lt;br&gt;401 (3rd edition)
| isbn          = 978-0-486-44244-0
| dewey= 539.7/2 22
| congress= QC793.3.S9 G37 2005
| oclc= 57373717
| preceded_by   =
| followed_by   =
}}

'''''The Ambidextrous Universe''''' is a [[popular science]] book by [[Martin Gardner]], covering aspects of [[symmetry]] and [[asymmetry]] in human culture, science and the wider [[universe]].

Originally published in 1964, it underwent revisions in 1969, 1979, 1990 and 2005 (the last two are known as the "Third, revised edition"). Originally titled '' The Ambidextrous Universe: Mirror Asymmetry and Time-Reversed Worlds'', subsequent editions are known as ''The New Ambidextrous Universe: Symmetry and Asymmetry from Mirror Reflections to Superstrings''.

==Content==
The book begins with the subject of [[mirror reflection]], and from there passes through symmetry in [[geometry]], [[poetry]], [[art]], [[music]], [[galaxy|galaxies]], [[sun]]s, [[planet]]s and [[living organisms]]. It then moves down into the [[molecule|molecular scale]] and looks at how symmetry and asymmetry have evolved from the beginning of life on [[Earth]]. There is a chapter on [[carbon]] and its versatility and on [[chirality]] in [[biochemistry]]. Chapter 18 (and subsequent chapters) deals with a conundrum called the Ozma Problem (see below). The second half of the book concerns various aspects of [[Atomic physics|atomic]] and [[subatomic]] physics and how they relate to mirror asymmetry and the related concepts of chirality, [[antimatter]], [[magnetic polarity|magnetic]] and [[electrical polarity]], [[Parity (physics)|parity]], [[Charge (physics)|charge]] and [[Spin (physics)|spin]]. [[Time invariance]] (and [[T-symmetry|reversal]]) is discussed. Implications for [[particle physics]], [[theoretical physics]] and [[cosmology]] are covered and brought up to date (in later editions of the book) with regard to [[Grand Unified Theory|GUT]]s, [[Theory of everything|TOE]]s, [[superstring theory]] and [[M-theory]].

===The Ozma Problem===
The 18th chapter, "The Ozma Problem", poses a problem that Gardner claims would arise if Earth should ever enter into communication with life on another planet through [[Project Ozma]]. This is the problem of how to communicate the meaning of left and right, where the two communicants are conditionally not allowed to view any one object in common. The problem was first implied in [[Immanuel Kant|Immanuel Kant's]] discussion of left and right, and [[William James]] mentioned it in his chapter on "The Perception of Space" in ''[[The Principles of Psychology]]'' (1890). It is also mentioned by [[Charles Howard Hinton]]. Gardner follows the thread of several false leads on the road to the solution of the Ozma Problem, in each case presenting an apparent solution which, on closer examination, turns out to be a false one.

The solution to the Ozma Problem was finally embodied in the famous "[[Wu experiment]]", conducted in 1956 by Chinese-American physicist [[Chien-Shiung Wu]] (1912–1997), involving the [[beta decay]] of [[cobalt-60]]. This experiment was the first to disprove the conservation of [[parity (physics)|parity]]. At long last, according to Gardner, it is believed that one could carefully describe the Wu experiment to a distant extraterrestrial intelligence and thereby convey the exact meaning of left/right.

==Literary references==
===W.H. Auden===
[[W. H. Auden]] alludes to ''The Ambidextrous Universe'' in his poem "Josef Weinheber" (1965).

===Vladimir Nabokov===
'''''Pale Fire'''''&lt;br&gt;
In the original 1964 edition of ''The Ambidextrous Universe'', Gardner quoted two lines of poetry from [[Vladimir Nabokov]]'s 1962 novel ''[[Pale Fire]]'' which are supposed to have been written by a poet, "[[John Shade]]", who is actually fictional. As a joke, Gardner credited the lines only to Shade and put Shade's name in the index as if he were a real person. In his 1969 novel ''[[Ada or Ardor: A Family Chronicle]]'', Nabokov returned the favor by having the character Van Veen "quote" the Gardner book along with the two lines of verse:
&lt;blockquote&gt;"Space is a swarming in the eyes, and Time a singing in the ears," says John Shade, a modern poet, as quoted by an invented philosopher ("Martin Gardiner" {{sic}}) in ''The Ambidextrous Universe'', page 165 {{sic}}.&lt;ref&gt;Nabokov, Vladimir (1969), ''Ada or Ardor: A Family Chronicle'', [[McGraw-Hill|McGraw-Hill Book Company]], pg 577.&lt;/ref&gt;&lt;/blockquote&gt;

'''''Look at the Harlequins!'''''&lt;br&gt;
Nabokov's 1974 novel ''[[Look at the Harlequins!]]'', about a man who can't distinguish left from right, was heavily influenced by his reading of ''The Ambidextrous Universe''.&lt;ref&gt;Johnson, D. Barton (1984), "The Ambidextrous Universe of Nabakov's ''Look at the Harlequins!''"; In: Roth, Phyllis (ed.), ''Critical Essays on Vladimir Nabokov''; G.K. Hall.&lt;/ref&gt;&lt;ref&gt;Hayles, N. Katherine (1984), "Ambivalence: Symmetry, Asymmetry, and the Physics of Time Reversal in Nabokov's ''Ada''", in the same author's ''The Cosmic Web: Scientific Field Models and Literary Strategies in the Twentieth Century'', [[Cornell University Press]].&lt;/ref&gt;

==References==
&lt;references/&gt;

==External links==
{{DEFAULTSORT:Ambidextrous Universe}}
{{Martin Gardner}}

[[Category:Works by Martin Gardner]]
[[Category:1964 books]]
[[Category:Science books]]
[[Category:Symmetry]]</text>
      <sha1>bk0nv7u6c168uoc7p7q9xld73bat6ws</sha1>
    </revision>
  </page>
  <page>
    <title>The Fibonacci Association</title>
    <ns>0</ns>
    <id>11360573</id>
    <revision>
      <id>858739076</id>
      <parentid>846831528</parentid>
      <timestamp>2018-09-09T08:08:28Z</timestamp>
      <contributor>
        <username>KAugsburger</username>
        <id>16464803</id>
      </contributor>
      <comment>Updated the URL for the Fibonacci Association</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2580">{{unreferenced|date=August 2012}}
The '''Fibonacci Association''' is a mathematical organization that specializes in the [[Fibonacci number]] sequence and a wide variety of related subjects, generalizations, and applications, including recurrence relations, combinatorial identities, binomial coefficients, prime numbers, pseudoprimes, continued fractions, the golden ratio, linear algebra, geometry, real analysis, and complex analysis.

==History==
The organization was founded in 1963 by [[monk|Brother]] [[Alfred Brousseau]], F.S.C. of St. Mary's College (Moraga, California) and [[Verner Emil Hoggatt. Jr|Verner E. Hoggatt Jr.]] of San Jose State College (now San Jose State University).

Details regarding the early history of The Fibonacci Association are given Marjorie Bicknell-Johnson's "A Short History of The Fibonacci Quarterly", published in The Fibonacci Quarterly 25:1 (February 1987) 2-5, during the Twenty-Fifth Anniversary year of the journal.

==Publications==
Since the year of its founding, the Fibonacci Association has published an international [[mathematical journal]], The ''[[Fibonacci Quarterly]]'' [http://www.fq.math.ca/].

The Fibonacci Association also publishes Proceedings for its international conferences, held every two years since 1984.  The 2008 conference, formally entitled the Thirteenth International Conference on Fibonacci Numbers and Their Applications, took place at the University of Patras (Greece), preceded by conferences at San Francisco State University (USA, 2006), Technische Universität Braunschweig (Germany, 2004), Northern Arizona University (USA, 2002), and Institut Supérieur de Technologie (Luxemburg, 2000).

The 2010 Conference was held at the Instituto de Matemáticas de la UNAM, Morelia, Mexico, as announced at the Fibonacci Association website:  [http://www.mscs.dal.ca/Fibonacci/fourteenth1.pdf].  The [http://fib15.ektf.hu/ 2012 Conference] will take place during June 25–30 at the Institute of Mathematics and Informatics, Eszerházy Károly College, Eger, Hungary, with keynote speaker Neil Sloane, founder of the [https://oeis.org/ Encyclopedia of Integer Sequences].   

==External links==
*[https://www.mathstat.dal.ca/fibonacci/ The Official website of the Fibonacci Association]
*[http://www.fq.math.ca/ The Fibonacci Quarterly]
*[http://www.fq.math.ca/list-of-issues.html Up-to-date list of issues of The Fibonacci Quarterly]

{{Fibonacci}}

{{DEFAULTSORT:Fibonacci Association}}
[[Category:Fibonacci numbers]]
[[Category:Organizations established in 1963]]
[[Category:Mathematics organizations]]</text>
      <sha1>oc8vbu9826zkvjso97csntve7ams0z6</sha1>
    </revision>
  </page>
  <page>
    <title>Theory of equations</title>
    <ns>0</ns>
    <id>583600</id>
    <revision>
      <id>824519382</id>
      <parentid>824352960</parentid>
      <timestamp>2018-02-07T20:56:27Z</timestamp>
      <contributor>
        <username>Loraof</username>
        <id>22399950</id>
      </contributor>
      <comment>/* top */  ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4096">{{distinguish|equational theory}}
{{unreferenced|date=May 2014}}

In [[algebra]], the '''theory of equations''' is the study of [[algebraic equation]]s (also called “polynomial equations”), which are [[equation (mathematics)|equation]]s defined by a [[polynomial]]. The main problem of the theory of equations was to know when an algebraic equation has an [[algebraic solution]]. This problem was completely solved in 1830 by [[Évariste Galois]], by introducing what is now called [[Galois theory]].

Before Galois, there was no clear distinction between the “theory of equations” and “algebra”. Since then algebra has been dramatically enlarged to include many new subareas, and the theory of algebraic equations receives much less attention. Thus, the term "theory of equations" is mainly used in the context of the [[history of mathematics]], to avoid confusion between old and new meanings of “algebra”.

==History==
Until the end of the 19th century, "theory of equations" was almost synonymous with "algebra". For a long time, the main problem was to find the solutions of a single non-linear polynomial equation in a single [[Equation|unknown]]. The fact that a [[complex number|complex]] solution always exists is the [[fundamental theorem of algebra]], which was proved only at the beginning of the 19th century and does not have a purely algebraic proof. Nevertheless, the main concern of the algebraists was to solve in terms of radicals, that is to express the solutions by a formula which is built with the four operations of [[arithmetics]] and with [[nth root]]s. This was done up to degree four during the 16th century. [[Scipione del Ferro]] and [[Niccolò Fontana Tartaglia]] discovered solutions for [[cubic equation]]s. [[Gerolamo Cardano]] published them in his 1545 book ''[[Ars Magna (Gerolamo Cardano)|Ars Magna]]'', together with a solution for the [[quartic equation]]s, discovered by his student [[Lodovico Ferrari]]. In 1572 [[Rafael Bombelli]] published his ''L'Algebra'' in which he showed how to deal with the [[imaginary number|imaginary quantities]] that could appear in Cardano's formula for solving cubic equations.

The case of higher degrees remained open until the 19th century, when [[Niels Henrik Abel]] proved that some fifth degree equations cannot be solved in radicals (the [[Abel–Ruffini theorem]]) and [[Évariste Galois]] introduced a theory (presently called [[Galois theory]]) to decide which equations are solvable by radicals.

==Further problems==
Other classical problems of the theory of equations are the following:
* [[Linear equation]]s: this problem was solved during antiquity.
* [[System of linear equations|Simultaneous linear equations]]: The general theoretical solution was provided by [[Gabriel Cramer]] in 1750. However devising efficient methods ([[algorithms]]) to solve these systems remains an active subject of research now called [[linear algebra]].
* Finding the integer solutions of an equation or of a system of equations. These problems are now called [[Diophantine equation]]s, which are considered a part of [[number theory]] (see also [[integer programming]]).
* [[System of polynomial equations|Systems of polynomial equations]]: Because of their difficulty, these systems, with few exceptions, have been studied only since the second part of the 19th century. They have led to the development of [[algebraic geometry]].

== See also ==

* [[Root-finding algorithm]]
* [[Properties of polynomial roots]]
* [[Quintic function]]

==Further reading==

*Uspensky, James Victor, ''Theory of Equations'' (McGraw-Hill),1963 [https://www.amazon.com/Theory-Equations-James-Victor-Uspensky/dp/0070667365/ref=pd_sim_sbs_14_1?ie=UTF8&amp;refRID=0WCDZANX7RY8V3T7T8Z3]
*Dickson, Leonard E., ''Elementary Theory of Equations'' (Classic Reprint, Forgotten Books), 2012  [https://www.amazon.com/Elementary-Theory-Equations-Classic-Reprint/dp/1440075077/ref=sr_1_22?s=books&amp;ie=UTF8&amp;qid=1440946671&amp;sr=1-22&amp;keywords=The+theory+of+equations]

[[Category:History of algebra]]
[[Category:Polynomials]]
[[Category:Equations]]</text>
      <sha1>lq1r7oltwlz8e156qzlmz75kfbjovz0</sha1>
    </revision>
  </page>
  <page>
    <title>Total derivative</title>
    <ns>0</ns>
    <id>1070326</id>
    <revision>
      <id>869091268</id>
      <parentid>869091246</parentid>
      <timestamp>2018-11-16T10:16:45Z</timestamp>
      <contributor>
        <username>Gagarine</username>
        <id>11797131</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14812">{{more footnotes|date=July 2013}}

{{calculus|expanded=Differential calculus}}

In [[mathematics]], the '''total derivative''' of a function &lt;math&gt;f&lt;/math&gt; is the best [[linear approximation]] of the value of the function with respect to its arguments.  Unlike [[partial derivative]]s, the total derivative approximates the function with respect to all of its arguments, not just a single one.  In many situations, this is the same as considering all partial derivatives simultaneously.  The term "total derivative" is primarily used when &lt;math&gt;f&lt;/math&gt; is a function of several variables, because when &lt;math&gt;f&lt;/math&gt; is a function of a single variable, the total derivative is the same as the [[derivative]] of the function.&lt;ref name=Chiang&gt;{{cite book |last=Chiang |first=Alpha C. |authorlink=Alpha Chiang |title=Fundamental Methods of Mathematical Economics |location= |publisher=McGraw-Hill |edition=Third |year=1984 |isbn=0-07-010813-7 }}&lt;/ref&gt;{{rp|198–203}}

"Total derivative" is sometimes also used as a synonym for the [[material derivative]] in [[fluid mechanics]].

==The total derivative as a linear map==
Let &lt;math&gt;U\subseteq \mathbf{R}^n&lt;/math&gt; be an [[open subset]].  Then a function &lt;math&gt;f:U\rightarrow \mathbf{R}^m&lt;/math&gt; is said to be ('''totally''') '''differentiable''' at a point &lt;math&gt;a\in U&lt;/math&gt; if there exists a [[linear transformation]] &lt;math&gt;df_a:\mathbf{R}^n \rightarrow \mathbf{R}^m&lt;/math&gt;  such that

:&lt;math&gt;\lim_{x\rightarrow a}\frac{\|f(x)-f(a)-df_a(x-a)\|}{\|x-a\|}=0.&lt;/math&gt;

The linear map &lt;math&gt;df_a&lt;/math&gt; is called the ('''total''') '''derivative''' or ('''total''') '''differential''' of &lt;math&gt;f&lt;/math&gt; at &lt;math&gt;a&lt;/math&gt;.  Other notations for the total derivative include &lt;math&gt;D_a f&lt;/math&gt; and &lt;math&gt;Df(a)&lt;/math&gt;.  A function is ('''totally''') '''differentiable''' if its total derivative exists at every point in its domain.

Conceptually, the definition of the total derivative expresses the idea that &lt;math&gt;df_a&lt;/math&gt; is the best linear approximation to &lt;math&gt;f&lt;/math&gt; at the point &lt;math&gt;a&lt;/math&gt;.  This can be made precise by quantifying the error in the linear approximation determined by &lt;math&gt;df_a&lt;/math&gt;.  To do so, write
:&lt;math&gt;f(a + h) = f(a) + df_a(h) + \varepsilon(h),&lt;/math&gt;
where &lt;math&gt;\varepsilon(h)&lt;/math&gt; equals the error in the approximation.  To say that the derivative of &lt;math&gt;f&lt;/math&gt; at &lt;math&gt;a&lt;/math&gt; is &lt;math&gt;df_a&lt;/math&gt; is equivalent to the statement
:&lt;math&gt;\varepsilon(h) = o(\lVert h\rVert),&lt;/math&gt;
where &lt;math&gt;o&lt;/math&gt; is [[Big O notation#Little-o notation|Little-o notation]] and indicates that &lt;math&gt;\varepsilon(h)&lt;/math&gt; is much smaller than &lt;math&gt;\lVert h\rVert&lt;/math&gt; as &lt;math&gt;h \to 0&lt;/math&gt;.  The total derivative &lt;math&gt;df_a&lt;/math&gt; is the ''unique'' linear transformation for which the error term is this small, and this is the sense in which it is the best linear approximation to &lt;math&gt;f&lt;/math&gt;.

The function &lt;math&gt;f&lt;/math&gt; is differentiable if and only if each of its components &lt;math&gt;f_i \colon U \to \mathbf{R}&lt;/math&gt; is differentiable, so when studying total derivatives, it is often possible to work one coordinate at a time in the codomain.  However, the same is not true of the coordinates in the domain.  It is true that if &lt;math&gt;f&lt;/math&gt; is differentiable at &lt;math&gt;a&lt;/math&gt;, then each partial derivative &lt;math&gt;\partial f/\partial x_i&lt;/math&gt; exists at &lt;math&gt;a&lt;/math&gt;.  The converse is false: It can happen that all of the partial derivatives of &lt;math&gt;f&lt;/math&gt; at &lt;math&gt;a&lt;/math&gt; exist, but &lt;math&gt;f&lt;/math&gt; is not differentiable at &lt;math&gt;a&lt;/math&gt;.  This means that the function is very "rough" at &lt;math&gt;a&lt;/math&gt;, to such an extreme that its behavior cannot be adequately described by its behavior in the coordinate directions.  When &lt;math&gt;f&lt;/math&gt; is not so rough, this cannot happen.  More precisely, if all the partial derivatives of &lt;math&gt;f&lt;/math&gt; at &lt;math&gt;a&lt;/math&gt; exist and are continuous in a neighborhood of &lt;math&gt;a&lt;/math&gt;, then &lt;math&gt;f&lt;/math&gt; is differentiable at &lt;math&gt;a&lt;/math&gt;.  When this happens, then in addition, the total derivative of &lt;math&gt;f&lt;/math&gt; is the linear transformation corresponding to the [[Jacobian matrix]] of partial derivatives at that point.&lt;ref&gt;{{cite book |first=Ralph |last=Abraham |authorlink=Ralph Abraham (mathematician) |first2=J. E. |last2=Marsden |authorlink2=Jerrold E. Marsden |first3=Tudor |last3=Ratiu |authorlink3=Tudor Ratiu |title=Manifolds, Tensor Analysis, and Applications |location= |publisher=Springer Science &amp; Business Media |year=2012 |isbn= |page=78 |url=https://books.google.com/books?id=b-IlBQAAQBAJ&amp;pg=PA78 }}&lt;/ref&gt;

==The total derivative as a differential form==
When the function under consideration is real-valued, the total derivative can be recast using [[differential form]]s.  For example, suppose that &lt;math&gt;f \colon \mathbf{R}^n \to \mathbf{R}&lt;/math&gt; is a differentiable function of variables &lt;math&gt;x_1, \ldots, x_n&lt;/math&gt;.  The total derivative of &lt;math&gt;f&lt;/math&gt; at &lt;math&gt;a&lt;/math&gt; may be written in terms of its Jacobian matrix, which in this instance simplifies to the [[gradient]]:
:&lt;math&gt;df_a = \begin{pmatrix} \frac{\partial f}{\partial x_1}, &amp; \cdots &amp; , &amp; \frac{\partial f}{\partial x_n} \end{pmatrix}.&lt;/math&gt;
The linear approximation property of the total derivative implies that if
:&lt;math&gt;\Delta x = \begin{pmatrix} \Delta x_1, &amp; \cdots &amp; , &amp; \Delta x_n \end{pmatrix}^T&lt;/math&gt;
is a small vector (where the &lt;math&gt;T&lt;/math&gt; denotes transpose, so that this vector is a column vector), then
:&lt;math&gt;f(a + \Delta x) - f(a) \approx df_a(\Delta x) = \sum_{i=1}^n \frac{\partial f}{\partial x_i}\Delta x_i.&lt;/math&gt;
Heuristically, this suggests that if &lt;math&gt;dx_1, \ldots, dx_n&lt;/math&gt; are [[infinitesimal]] increments in the coordinate directions, then
:&lt;math&gt;df_a = \sum_{i=1}^n \frac{\partial f}{\partial x_i}dx_i.&lt;/math&gt;

The theory of [[differential form]]s is one way to give a precise meaning to infinitesimal increments such as &lt;math&gt;dx_i&lt;/math&gt;.  In this theory, &lt;math&gt;dx_i&lt;/math&gt; is a [[linear functional]] on the vector space &lt;math&gt;\mathbf{R}^n&lt;/math&gt;.  Evaluating &lt;math&gt;dx_i&lt;/math&gt; at a vector &lt;math&gt;h&lt;/math&gt; in &lt;math&gt;\mathbf{R}^n&lt;/math&gt; measures how much &lt;math&gt;h&lt;/math&gt; points in the &lt;math&gt;i&lt;/math&gt;th coordinate direction.  The total derivative &lt;math&gt;df_a&lt;/math&gt; is a linear combination of linear functionals and hence is itself a linear functional.  The evaluation &lt;math&gt;df_a(h)&lt;/math&gt; measures how much &lt;math&gt;h&lt;/math&gt; points in the direction determined by &lt;math&gt;f&lt;/math&gt; at &lt;math&gt;a&lt;/math&gt;, and this direction is the gradient.  This point of view makes the total derivative an instance of the [[exterior derivative]].

Suppose now that &lt;math&gt;f&lt;/math&gt; is a vector-valued function, that is, &lt;math&gt;f \colon \mathbf{R}^n \to \mathbf{R}^m&lt;/math&gt;.  In this case, the components &lt;math&gt;f_i&lt;/math&gt; of &lt;math&gt;f&lt;/math&gt; are real-valued functions, so they have associated differential forms &lt;math&gt;df_i&lt;/math&gt;.  The total derivative &lt;math&gt;df&lt;/math&gt; amalgamates these forms into a single object and is therefore an instance of a [[vector-valued differential form]].

==The chain rule for total derivatives==
{{main|Chain rule}}

The chain rule has a particularly elegant statement in terms of total derivatives.  It says that, for two functions &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt;, the total derivative of the composite &lt;math&gt;g \circ f&lt;/math&gt; at &lt;math&gt;a&lt;/math&gt; satisfies
:&lt;math&gt;d(g \circ f)_a = dg_{f(a)} \circ df_a.&lt;/math&gt;
If the total derivatives of &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt; are identified with their Jacobian matrices, then the composite on the right-hand side is simply matrix multiplication.  This is enormously useful in applications, as it makes it possible to account for essentially arbitrary dependencies among the arguments of a composite function.

===Example: Differentiation with direct dependencies===
Suppose that ''f'' is a function of two variables, ''x'' and ''y''.  If these two variables are independent, so that the domain of ''f'' is &lt;math&gt;\mathbf{R}^2&lt;/math&gt;, then the behavior of ''f'' may be understood in terms of its partial derivatives in the ''x'' and ''y'' directions.  However, in some situations, ''x'' and ''y'' may be dependent.  For example, it might happen that ''f'' is constrained to a curve &lt;math&gt;y = y(x)&lt;/math&gt;.  In this case, we are actually interested in the behavior of the composite function &lt;math&gt;f(x, y(x))&lt;/math&gt;.  The partial derivative of ''f'' with respect to ''x'' does not give the true rate of change of ''f'' with respect to changing ''x'' because changing ''x'' necessarily changes ''y''.  However, the chain rule for the total derivative takes such dependencies into account.  Write &lt;math&gt;\gamma(x) = (x, y(x))&lt;/math&gt;.  Then chain rule says
:&lt;math&gt;d(f \circ \gamma)_{x_0} = df_{(x_0, y(x_0))} \circ d\gamma_{x_0}.&lt;/math&gt;
By expressing the total derivative using Jacobian matrices, this becomes:
:&lt;math&gt;\frac{df(x, y(x))}{dx}(x_0) = \frac{\partial f}{\partial x}(x_0, y(x_0)) \cdot \frac{\partial x}{\partial x}(x_0) + \frac{\partial f}{\partial y}(x_0, y(x_0)) \cdot \frac{\partial y}{\partial x}(x_0).&lt;/math&gt;
Suppressing the evaluation at &lt;math&gt;x_0&lt;/math&gt; for legibility, we may also write this as
:&lt;math&gt;\frac{df(x, y(x))}{dx} = \frac{\partial f}{\partial x} \frac{\partial x}{\partial x} + \frac{\partial f}{\partial y} \frac{\partial y}{\partial x}.&lt;/math&gt;
This gives a straightforward formula for the derivative of &lt;math&gt;f(x, y(x))&lt;/math&gt; in terms of the partial derivatives of &lt;math&gt;f&lt;/math&gt; and the derivative of &lt;math&gt;y(x)&lt;/math&gt;.

For example, suppose
:&lt;math&gt;f(x,y)=xy.&lt;/math&gt;
The rate of change of ''f'' with respect to ''x'' is usually the partial derivative of ''f'' with respect to ''x''; in this case,
:&lt;math&gt;\frac{\partial f}{\partial x} = y.&lt;/math&gt;
However, if ''y'' depends on ''x'', the partial derivative does not give the true rate of change of ''f'' as ''x'' changes because the partial derivative assumes that ''y'' is fixed.  Suppose we are constrained to the line
:&lt;math&gt;y=x.&lt;/math&gt;
Then
:&lt;math&gt;f(x,y) = f(x,x) = x^2,&lt;/math&gt;
and the total derivative of ''f'' with respect to ''x'' is
:&lt;math&gt;\frac{df}{dx} = 2 x,&lt;/math&gt;
which we see is not equal to the partial derivative &lt;math&gt;\partial f/\partial x&lt;/math&gt;.  Instead of immediately substituting for ''y'' in terms of ''x'', however, we can also use the chain rule as above:
:&lt;math&gt;\frac{df}{dx} = \frac{\partial f}{\partial x} + \frac{\partial f}{\partial y}\frac{dy}{dx} = y+x \cdot 1 = x+y = 2x.&lt;/math&gt;

===Example: Differentiation with indirect dependencies===
While one can often perform substitutions to eliminate indirect dependencies, the [[chain rule]] provides for a more efficient and general technique.  Suppose &lt;math&gt;L(t,x_1,\dots,x_n)&lt;/math&gt; is a function of time &lt;math&gt;t&lt;/math&gt; and &lt;math&gt;n&lt;/math&gt; variables &lt;math&gt;x_i&lt;/math&gt; which themselves depend on time. Then, the time derivative of &lt;math&gt;L&lt;/math&gt; is
:&lt;math&gt;\frac{dL}{dt} = \frac{d}{dt} L \bigl(t, x_1(t), \ldots, x_n(t)\bigr).&lt;/math&gt;

The chain rule expresses this derivative in terms of the partial derivatives of &lt;math&gt;L&lt;/math&gt; and the time derivatives of the functions &lt;math&gt;x_i&lt;/math&gt;:
:&lt;math&gt;\frac{dL}{dt}
= \frac{\partial L}{\partial t} + \sum_{i=1}^n \frac{\partial L}{\partial x_i}\frac{dx_i}{dt}
= \biggl(\frac{\partial}{\partial t} + \sum_{i=1}^n \frac{dx_i}{dt}\frac{\partial}{\partial x_i}\biggr)(L).&lt;/math&gt;

This expression is often used in [[physics]] for a [[gauge transformation]] of the [[Lagrangian mechanics|Lagrangian]], as two Lagrangians that differ only by the total time derivative of a function of time and the &lt;math&gt;n&lt;/math&gt; [[generalized coordinates]] lead to the same equations of motion. An interesting example concerns the resolution of causality concerning the [[Wheeler–Feynman absorber theory#Resolution of causality issue|Wheeler–Feynman time-symmetric theory]].  The operator in brackets (in the final expression above) is also called the total derivative operator (with respect to &lt;math&gt;t&lt;/math&gt;).

For example, the total derivative of &lt;math&gt;f(x(t),y(t))&lt;/math&gt; is

:&lt;math&gt;\frac{df}{dt} = { \partial f \over \partial x}{dx \over dt} + {\partial f \over \partial y}{dy \over dt }.&lt;/math&gt;

Here there is no &lt;math&gt;\partial f / \partial t&lt;/math&gt; term since &lt;math&gt;f&lt;/math&gt; itself does not depend on the independent variable &lt;math&gt;t&lt;/math&gt; directly.

==Total differential equation==
{{main|Total differential equation}}
A ''total differential equation'' is a [[differential equation]] expressed in terms of total derivatives. Since the [[exterior derivative]] is coordinate-free, in a sense that can be given a technical meaning, such equations are intrinsic and ''geometric''.

==Application to equation systems==

In [[economics]], it is common for the total derivative to arise in the context of a system of equations.&lt;ref name=Chiang/&gt;{{rp|pp. 217–220}} For example, a simple [[supply and demand|supply-demand system]] might specify the quantity ''q'' of a product demanded as a function ''D'' of its price ''p'' and consumers' income ''I'', the latter being an [[exogenous variable]], and might specify the quantity supplied by producers as a function ''S'' of its price and two exogenous resource cost variables ''r'' and ''w''. The resulting system of equations
:&lt;math&gt;q=D(p, I),&lt;/math&gt;
:&lt;math&gt;q=S(p, r, w),&lt;/math&gt;
determines the market equilibrium values of the variables ''p'' and ''q''.  The total derivative &lt;math&gt;dp/dr&lt;/math&gt; of ''p'' with respect to ''r'', for example, gives the sign and magnitude of the reaction of the market price to the exogenous variable ''r''.  In the indicated system, there are a total of six possible total derivatives, also known in this context as [[comparative statics|comparative static derivatives]]: {{math|''dp'' / ''dr''}}, {{math|''dp'' / ''dw''}}, {{math|''dp'' / ''dI''}}, {{math|''dq'' / ''dr''}}, {{math|''dq'' / ''dw''}}, and {{math|''dq'' / ''dI''}}.  The total derivatives are found by totally differentiating the system of equations, dividing through by, say {{math|''dr''}}, treating {{math|''dq'' / ''dr''}} and {{math|''dp'' / ''dr''}} as the unknowns, setting {{math|1=''dI'' = ''dw'' = 0}}, and solving the two totally differentiated equations simultaneously, typically by using [[Cramer's rule]].

== References ==
{{reflist}}

* A. D. Polyanin and V. F. Zaitsev, ''Handbook of Exact Solutions for Ordinary Differential Equations (2nd edition)'', Chapman &amp; Hall/CRC Press, Boca Raton, 2003. {{isbn|1-58488-297-2}}
* From thesaurus.maths.org [https://web.archive.org/web/20060501183510/http://thesaurus.maths.org/mmkb/entry.html  total derivative]

== External links ==
* {{MathWorld|TotalDerivative|Total Derivative}}
* http://www.sv.rkriz.net/classes/ESM4714/methods/df2D.html

[[Category:Multivariable calculus]]
[[Category:Differential calculus]]
[[Category:Differential operators]]
[[Category:Lagrangian mechanics]]
[[Category:Mathematical analysis]]</text>
      <sha1>lg2kbck4463wlll2zk21q6pwlcjvjnz</sha1>
    </revision>
  </page>
  <page>
    <title>Transactions of the American Mathematical Society</title>
    <ns>0</ns>
    <id>1388937</id>
    <revision>
      <id>855107127</id>
      <parentid>812187157</parentid>
      <timestamp>2018-08-16T00:30:15Z</timestamp>
      <contributor>
        <ip>2604:2000:1581:552:0:5F96:E98A:5054</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1064">{{Italic title}}
[[Image:TAMS.jpg|thumb|right|''Transactions of the American Mathematical Society'', February 2006 issue.]]
The '''''Transactions of the American Mathematical Society''''' is a monthly [[peer-reviewed]] [[scientific journal]] of [[mathematics]] published by the [[American Mathematical Society]]. It was established in 1900. As a requirement, all articles must be more than 15 printed pages.

== See also ==
* ''[[Bulletin of the American Mathematical Society]]''
* ''[[Journal of the American Mathematical Society]]''
* ''[[Memoirs of the American Mathematical Society]]''
* ''[[Notices of the American Mathematical Society]]''
* ''[[Proceedings of the American Mathematical Society]]''

==External links==
* {{Official website|http://www.ams.org/journals/tran/}}
* [https://www.jstor.org/journal/tranamermathsoci ''Transactions of the American Mathematical Society''] on [[JSTOR]]

[[Category:American Mathematical Society academic journals]]
[[Category:Mathematics journals]]
[[Category:Publications established in 1900]]


{{math-journal-stub}}</text>
      <sha1>tqgk6g4cck86mwl821jfbjpgt31sf1m</sha1>
    </revision>
  </page>
  <page>
    <title>Valuation (measure theory)</title>
    <ns>0</ns>
    <id>17457007</id>
    <revision>
      <id>814411522</id>
      <parentid>805166695</parentid>
      <timestamp>2017-12-08T17:38:21Z</timestamp>
      <contributor>
        <ip>2001:AC8:36:2:0:0:0:8DE</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7428">In [[measure theory]], or at least in the approach to it via the [[domain theory]], a '''valuation''' is a [[Map (mathematics)|map]] from the class of [[open set]]s of a [[topological space]] to the set of [[positive number|positive]] [[real number]]s including [[infinity]], with certain properties. It is a concept closely related to that of a [[Measure (mathematics)|measure]], and as such, it finds applications in measure theory, [[probability theory]], and [[theoretical computer science]].

== Domain/Measure theory definition ==
Let &lt;math&gt; \scriptstyle (X,\mathcal{T})&lt;/math&gt; be a topological space: a '''valuation''' is any map 

:&lt;math&gt; v:\mathcal{T} \rightarrow \mathbb{R}^+\cup\{+\infty\} &lt;/math&gt;

satisfying the following three properties 

: &lt;math&gt;
\begin{array}{lll}
v(\varnothing) = 0 &amp; &amp; \scriptstyle{\text{Strictness property}}\\
v(U)\leq v(V) &amp; \mbox{if}~U\subseteq V\quad U,V\in\mathcal{T} &amp; \scriptstyle{\text{Monotonicity property}}\\
v(U\cup V)+ v(U\cap V) = v(U)+v(V) &amp; \forall U,V\in\mathcal{T} &amp; \scriptstyle{\text{Modularity property}}\,
\end{array}
&lt;/math&gt;

The definition immediately shows the relationship between a valuation and a measure: the properties of the two mathematical object are often very similar if not identical, the only difference being that the domain of a measure is the [[Borel algebra]] of the given topological space, while the domain of a valuation is the class of open sets. Further details and references can be found in {{Harvnb|Alvarez-Manilla|Edalat|Saheb-Djahromi|Nasser|2000}} and {{Harvnb|Goulbault-Larrecq|2002}}.

=== Continuous valuation ===
A valuation (as defined in domain theory/measure theory) is said to be '''continuous''' if for ''every directed family'' &lt;math&gt; \scriptstyle \{U_i\}_{i\in I} &lt;/math&gt; ''of [[open sets]]'' (i.e. an [[indexed family]] of open sets which is also [[Directed set|directed]] in the sense that for each pair of indexes &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt; belonging to the [[index set]] &lt;math&gt; I &lt;/math&gt;, there exists an index &lt;math&gt;k&lt;/math&gt; such that &lt;math&gt;\scriptstyle U_i\subseteq U_k&lt;/math&gt; and &lt;math&gt;\scriptstyle U_j\subseteq U_k&lt;/math&gt;) the following [[Equality (mathematics)|equality]] holds:

:&lt;math&gt; v\left(\bigcup_{i\in I}U_i\right) = \sup_{i\in I} v(U_i).&lt;/math&gt;

This property is analogous to the [[τ-additivity]] of measures.

=== Simple valuation ===
A valuation (as defined in domain theory/measure theory) is said to be '''simple''' if it is a [[Finite set|finite]] [[linear combination]] with [[non-negative number|non-negative]] [[coefficient]]s of [[valuation (measure theory)#Dirac valuation|Dirac valuations]], i.e.

:&lt;math&gt;v(U)=\sum_{i=1}^n a_i\delta_{x_i}(U)\quad\forall U\in\mathcal{T}&lt;/math&gt;

where &lt;math&gt;a_i&lt;/math&gt; is always greater than or at least equal to [[zero]] for all index &lt;math&gt;i&lt;/math&gt;. Simple valuations are obviously continuous in the above sense. The [[supremum]] of a ''directed family of simple valuations'' (i.e. an indexed family of simple valuations which is also directed in the sense that for each pair of indexes &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt; belonging to the index set &lt;math&gt; I &lt;/math&gt;, there exists an index &lt;math&gt;k&lt;/math&gt; such that &lt;math&gt;\scriptstyle v_i(U)\leq v_k(U)\!&lt;/math&gt; and &lt;math&gt;\scriptstyle v_j(U)\leq v_k(U)\!&lt;/math&gt;) is called '''quasi-simple valuation'''

:&lt;math&gt;\bar{v}(U) = \sup_{i\in I}v_i(U) \quad \forall U\in \mathcal{T}. \,&lt;/math&gt;

=== See also ===
* The '''extension problem''' for a given valuation (in the sense of domain theory/measure theory) consists in finding under what type of conditions it can be extended to a measure on a proper topological space, which may or may not be the same space where it is defined: the papers {{Harvnb|Alvarez-Manilla|Edalat|Saheb-Djahromi|2000}} and {{Harvnb|Goulbault-Larrecq|2002}} in the reference section are devoted to this aim and give also several historical details.
* The concepts of '''valuation on [[convex set]]s''' and '''valuation on [[manifold]]s''' are a generalization of valuation in the sense of [[Domain theory|domain]]/measure theory. A valuation on convex sets is allowed to assume [[complex number|complex values]], and the underlying topological space is the set of [[non-empty set|non-empty]] convex [[compact subset]]s of a [[finite-dimensional vector space]]: a valuation on manifolds is a complex valued [[finitely additive measure]] defined on a proper [[subset]] of the [[Class (mathematics)|class]] of all [[compact submanifold]]s of the given [[manifolds]].&lt;ref&gt;Details can be found in several [[arxiv]] [https://arxiv.org/find/grp_q-bio,grp_cs,grp_physics,grp_math,grp_nlin/1/AND+au:+Alesker+ti:+Valuations/0/1/0/all/0/1 papers] of prof. Semyon Alesker.&lt;/ref&gt;

== Examples ==
=== Dirac valuation ===
Let &lt;math&gt; \scriptstyle (X,\mathcal{T})&lt;/math&gt; be a topological space, and let ''&lt;math&gt;x&lt;/math&gt;'' be a point of ''&lt;math&gt;X&lt;/math&gt;'': the map

:&lt;math&gt;\delta_x(U)=
\begin{cases}
0 &amp; \mbox{if}~x\notin U\\
1 &amp; \mbox{if}~x\in U
\end{cases}
\quad\forall U\in\mathcal{T}
&lt;/math&gt;
is a valuation in the domain theory/measure theory, sense called '''[[Paul Dirac|Dirac]] valuation'''. This concept bears its origin from [[Distribution (mathematics)|distribution theory]] as it is an obvious transposition to valuation theory of [[Dirac distribution]]: as seen above, Dirac valuations are the "[[brick]]s" [[#Simple valuation|simple valuations]] are made of.

== References ==
{{Reflist}}
*{{Citation
 | last= Alvarez-Manilla | first = Maurizio | last2 = Edalat | first2 = Abbas
 | last3= Saheb-Djahromi | first3 = Nasser
 | title= An extension result for continuous valuations
 | journal = Journal of the London Mathematical Society
 | doi = 10.1112/S0024610700008681
 | volume = 61 | year = 2000 | pages = 629–640
 | url=http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=53523}}. [[Digital object identifier|DOI]]:[http://dxdoi.org/10.1112/S0024610700008681 10.1112/S0024610700008681]. The [http://www.doc.ic.ac.uk/~ae/papers/extensionofvaluations.ps.Z preprint] from the [http://www.doc.ic.ac.uk/~ae/ homepage] of the second author is freely readable.
*{{Citation
 | last = Goulbault-Larrecq  | first = Jean 
 | title = Extensions of valuations 
 | journal = Research Report LSV-02-17 
 | publisher = [http://www.lsv.ens-cachan.fr/ LSV] (Laboratoire de Spécification at Vérification), [http://www.cnrs.fr/ CNRS] &amp; [http://www.ens-cachan.fr/ ENS de Cachan]
 | place = [[France]] 
 | year = November 2002
 | url=http://www.lsv.ens-cachan.fr/Publis/RAPPORTS_LSV/PS/rr-lsv-2002-17.rr.ps}}. Published as "''[http://journals.cambridge.org/action/displayAbstract;jsessionid=2B602DA77038C1884EB0206BCAF81484.tomcat1?fromPage=online&amp;aid=289408 Extension of valuations]''", [http://journals.cambridge.org/action/displayAbstract;jsessionid=2B602DA77038C1884EB0206BCAF81484.tomcat1?fromPage=online&amp;aid=289408# Mathematical Structures in Computer Science] (2005), 15: 271-297, [[Digital object identifier|DOI]]:[https://dx.doi.org/10.1017/S096012950400461X 10.1017/S096012950400461X].

== External links ==
* Alesker, Semyon, "''[https://arxiv.org/find/grp_q-bio,grp_cs,grp_physics,grp_math,grp_nlin/1/AND+au:+Alesker+ti:+Valuations/0/1/0/all/0/1 various preprints on valuation] s''", [[arxiv]] preprint server, primary site at [[Cornell University]]. Several papers dealing with valuations on convex sets, valuations on manifolds and related topics.

[[Category:Measure theory]]</text>
      <sha1>ecjxo16zvu62is97hxe79ysjh2rsft3</sha1>
    </revision>
  </page>
  <page>
    <title>XOR swap algorithm</title>
    <ns>0</ns>
    <id>145555</id>
    <revision>
      <id>859953663</id>
      <parentid>849956853</parentid>
      <timestamp>2018-09-17T11:29:10Z</timestamp>
      <contributor>
        <username>Nickshanks</username>
        <id>20152</id>
      </contributor>
      <comment>must not overlap either.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13954">{{Refimprove|date=February 2012}}
[[Image:XOR Swap.svg|thumb|upright=2|alt=With three XOR operations the binary values 1010 and 0011 are exchanged between variables.|Using the XOR swap algorithm to exchange [[nibble]]s between variables without the use of temporary storage]]

In [[computer programming]], the '''XOR swap''' is an [[algorithm]] that uses the [[exclusive disjunction|XOR]] [[bitwise operation]] to [[swap (computer science)|swap]] values of distinct [[variable (programming)|variable]]s having the same [[data type]] without using a temporary variable. "Distinct" means that the variables are stored at different, non-overlapping, memory addresses; the actual values of the variables do not have to be different.

==The algorithm==
Conventional swapping requires the use of a temporary storage variable. Using the XOR swap algorithm, however, no temporary storage is needed. The algorithm is as follows:&lt;ref&gt;{{cite web|url=http://www.cs.umd.edu/class/sum2003/cmsc311/Notes/BitOp/xor.html |title=The Magic of XOR |publisher=Cs.umd.edu |date= |accessdate=2014-04-02}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://graphics.stanford.edu/~seander/bithacks.html#SwappingValuesXOR|title=Swapping Values with XOR|publisher=graphics.stanford.edu|accessdate=2014-05-02}}&lt;/ref&gt;

&lt;syntaxhighlight lang="pascal"&gt;
X := X XOR Y
Y := Y XOR X
X := X XOR Y
&lt;/syntaxhighlight&gt;

The algorithm typically corresponds to three [[machine code|machine-code]] instructions. Since XOR is a [[commutative operation]], X XOR Y can be replaced with Y XOR X in any of the lines. When coded in assembly language, this commutativity is often exercised in the second line:

{| class="wikitable" style="width: 45em;"
|-
! Pseudocode !! IBM [[System/370]] assembly !! x86 assembly
|-
| {{code|1=X := X XOR Y|2=pascal}} || {{code|1=XR    R1,R2|2=asm}} || {{code|1=xor    eax, ebx|2=asm}}
|-
| {{code|1=Y := Y XOR X|2=pascal}} || {{code|1=XR    R2,R1|2=asm}} || {{code|1=xor    ebx, eax|2=asm}}
|-
| {{code|1=X := X XOR Y|2=pascal}} || {{code|1=XR    R1,R2|2=asm}} || {{code|1=xor    eax, ebx|2=asm}}
|}

In the above System/370 assembly code sample, R1 and R2 are distinct [[processor register|register]]s, and each XR operation leaves its result in the register named in the first argument. Using x86 assembly, values X and Y are in registers eax and ebx (respectively), and {{code|xor|2=asm}} places the result of the operation in the first register.

However, the algorithm fails if ''x'' and ''y'' use the same storage location, since the value stored in that location will be zeroed out by the first XOR instruction, and then remain zero; it will not be "swapped with itself". Note that this is ''not'' the same as if ''x'' and ''y'' have the same values.  The trouble only comes when ''x'' and ''y'' use the same storage location, in which case their values must already be equal. That is, if ''x'' and ''y'' use the same storage location, then the line:
&lt;syntaxhighlight lang="pascal"&gt;
X := X XOR Y
&lt;/syntaxhighlight&gt;
sets ''x'' to zero (because ''x'' = ''y'' so X XOR Y is zero) ''and'' sets ''y'' to zero (since it uses the same storage location), causing ''x'' and ''y'' to lose their original values.

==Proof of correctness==
The [[binary operation]] XOR over bit strings of length &lt;math&gt;N&lt;/math&gt; exhibits the following properties (where &lt;math&gt;\oplus&lt;/math&gt; denotes XOR):{{Efn|The first three properties, along with the existence of an inverse for each element, are the definition of an [[abelian group]]. The last property is the statement that every element is an [[Involution (mathematics)|involution]], that is, having [[Order (group theory)|order]] 2, which is not true of all abelian groups.}}

* '''L1.''' [[Commutative operation|Commutativity]]: &lt;math&gt;A \oplus B = B \oplus A&lt;/math&gt;
* '''L2.''' [[Associativity]]: &lt;math&gt;(A \oplus B) \oplus C = A \oplus (B \oplus C)&lt;/math&gt;
* '''L3.''' [[Identity element|Identity exists]]: there is a bit string, 0, (of length ''N'') such that &lt;math&gt;A \oplus 0 = A&lt;/math&gt; for any &lt;math&gt;A&lt;/math&gt;
* '''L4.''' Each element is its own [[inverse element|inverse]]: for each &lt;math&gt;A&lt;/math&gt;, &lt;math&gt;A \oplus A = 0&lt;/math&gt;.

Suppose that we have two distinct registers &lt;code&gt;R1&lt;/code&gt; and &lt;code&gt;R2&lt;/code&gt; as in the table below, with initial values ''A'' and ''B'' respectively. We perform the operations below in sequence, and reduce our results using the properties listed above.

{| class="wikitable"
|- 
! Step
! Operation
! Register 1
! Register 2
! Reduction
|-
| 0 || Initial value || &lt;math&gt;A&lt;/math&gt; || &lt;math&gt;B&lt;/math&gt; || — 
|-
| 1 || &lt;code&gt;R1 := R1 XOR R2&lt;/code&gt;  || &lt;math&gt;A \oplus B&lt;/math&gt; || &lt;math&gt;\ B&lt;/math&gt; || — 
|- 
| 2 || &lt;code&gt;R2 := R1 XOR R2&lt;/code&gt;  || &lt;math&gt;A \oplus B&lt;/math&gt; || &lt;math&gt;(A \oplus B) \oplus B = A \oplus (B \oplus B)&lt;/math&gt;&lt;br&gt;&lt;math&gt;= A \oplus 0&lt;/math&gt;&lt;br&gt;&lt;math&gt;=A&lt;/math&gt; || '''L2&lt;br&gt; L4&lt;br&gt; L3'''
|-
| 3 || &lt;code&gt;R1 := R1 XOR R2&lt;/code&gt;  || &lt;math&gt;(A \oplus B) \oplus A = A \oplus (A \oplus B)&lt;/math&gt;&lt;br&gt;&lt;math&gt; = (A \oplus A) \oplus B&lt;/math&gt;&lt;br&gt;&lt;math&gt;= 0 \oplus B &lt;/math&gt;&lt;br&gt;&lt;math&gt;= B \oplus 0 &lt;/math&gt;&lt;br&gt;&lt;math&gt; = B &lt;/math&gt; || &lt;math&gt;\ A&lt;/math&gt; || '''L1&lt;br&gt; L2&lt;br&gt; L4&lt;br&gt; L1&lt;br&gt; L3'''
|}

=== Linear algebra interpretation ===
As XOR can be interpreted as binary addition and a pair of values can be interpreted as a point in two-dimensional space, the steps in the algorithm can be interpreted as 2&amp;times;2 matrices with binary values. For simplicity, assume initially that ''x'' and ''y'' are each single bits, not bit vectors.

For example, the step:
&lt;syntaxhighlight lang="pascal"&gt;
X := X XOR Y
&lt;/syntaxhighlight&gt;
which also has the implicit:
&lt;syntaxhighlight lang="pascal"&gt;
Y := Y
&lt;/syntaxhighlight&gt;
corresponds to the matrix &lt;math&gt;\left(\begin{smallmatrix}1 &amp; 1\\0 &amp; 1\end{smallmatrix}\right)&lt;/math&gt; as
:&lt;math&gt;\begin{pmatrix}1 &amp; 1\\0 &amp; 1\end{pmatrix} \begin{pmatrix}x\\y\end{pmatrix}
= \begin{pmatrix}x+y\\y\end{pmatrix}.
&lt;/math&gt;
The sequence of operations is then expressed as:
:&lt;math&gt;
\begin{pmatrix}1 &amp; 1\\0 &amp; 1\end{pmatrix}
\begin{pmatrix}1 &amp; 0\\1 &amp; 1\end{pmatrix}
\begin{pmatrix}1 &amp; 1\\0 &amp; 1\end{pmatrix}
=
\begin{pmatrix}0 &amp; 1\\1 &amp; 0\end{pmatrix}
&lt;/math&gt;
(working with binary values, so &lt;math&gt;1 + 1 = 0&lt;/math&gt;), which expresses the [[elementary matrix]] of switching two rows (or columns) in terms of the [[Shear mapping|transvections]] (shears) of adding one element to the other.

To generalize to where X and Y are not single bits, but instead bit vectors of length ''n'', these 2&amp;times;2 matrices are replaced by 2''n''&amp;times;2''n'' [[block matrices]] such as &lt;math&gt;\left(\begin{smallmatrix}I_n &amp; I_n\\0 &amp; I_n\end{smallmatrix}\right).&lt;/math&gt;

Note that these matrices are operating on ''values,'' not on ''variables'' (with storage locations), hence this interpretation abstracts away from issues of storage location and the problem of both variables sharing the same storage location.

==Code example==
A [[C (programming language)|C]] function that implements the XOR swap algorithm:
&lt;!-- This display template is broken in IE 6, the top half of the pretty bordered box is cut off. --&gt;
&lt;source lang="c"&gt;
 void xorSwap (int *x, int *y) {
     if (x != y) {
         *x ^= *y;
         *y ^= *x;
         *x ^= *y;
     }
 }
&lt;/source&gt;
Note that the code does not swap the integers passed immediately, but first checks if their addresses are distinct. This is because, if the addresses are equal, the algorithm will fold to a triple *x ^= *x resulting in zero.

The code below is an example of overly-concise C code; the behavior of the code is undefined. (Writing overly-concise C code has become unnecessary as modern optimizing compilers will eliminate intermediate results and temporary variables.)
&lt;source lang="c"&gt;
 /* kcc: "Undefined behavior - Error: EIO8
    Description: unsequenced side effect on scalar object with value computation of same object."
    See: https://github.com/kframework/c-semantics and https://runtimeverification.com/match/1.0-SNAPSHOT/docs/runningexamples/
    There are no sequence points to force the execution of (*y=*x) last - see https://en.wikipedia.org/wiki/Sequence_point
 */
 void xorSwap (int *x, int *y) {
     *x ^= *y ^= ( *y ^= *x );
 }
&lt;/source&gt;

The XOR swap algorithm can also be defined with a macro:
&lt;source lang="c"&gt;
#define XORSWAP_UNSAFE(a, b)	((a)^=(b),(b)^=(a),(a)^=(b)) /* Doesn't work when a and b are the same object - assigns zero (0) to the object in that case */
#define XORSWAP(a, b)   ((&amp;(a) == &amp;(b)) ? (a) : ((a)^=(b),(b)^=(a),(a)^=(b))) /* checks that the addresses of a and b are different before XOR-ing */
&lt;/source&gt;

==Reasons for use in practice==
In most practical scenarios, the trivial swap algorithm using a temporary register is more efficient. Limited situations in which XOR swapping may be practical include:

* on a processor where the instruction set encoding permits the XOR swap to be encoded in a smaller number of bytes
* in a region with high [[register pressure]], it may allow the [[register allocator]] to avoid [[spilling a register]]
* in [[microcontrollers]] where available RAM is very limited.
* in cryptographic applications which need constant time functions to prevent time-based side-channel attacks&lt;ref&gt;{{cite book|last1=Schneier|first1=Tadayoshi Kohno, Niels Ferguson, Bruce|title=Cryptography engineering : design principles and practical applications|date=2010|publisher=Wiley Pub., inc.|location=Indianapolis, IN|isbn=978-0-470-47424-2|page=251 ff.}}&lt;/ref&gt;

Because these situations are rare, most optimizing compilers do not generate XOR swap code.

==Reasons for avoidance in practice==
Most modern compilers can optimize away the temporary variable in the native swap, in which case the native swap uses the same amount of memory and the same number of registers as the XOR swap and is at least as fast, and often faster. The XOR swap is also much less readable and completely opaque to anyone unfamiliar with the technique.

On modern [[CPU architecture]]s, the XOR technique can be slower than using a temporary variable to do swapping. One reason is that modern CPUs strive to execute instructions in parallel via [[instruction pipeline]]s. In the XOR technique, the inputs to each operation depend on the results of the previous operation, so they must be executed in strictly sequential order, negating any benefits of [[instruction-level parallelism]].&lt;ref&gt;{{cite web |first1=Saman |last1=Amarasinghe |first2=Charles |last2=Leiserson |title=6.172 Performance Engineering of Software Systems, Lecture 2 |year=2010 |publisher=Massachusetts Institute of Technology |website=MIT OpenCourseWare |url=http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-172-performance-engineering-of-software-systems-fall-2010/video-lectures/lecture-2-bit-hacks/ |accessdate=27 January 2015}}&lt;/ref&gt;

A historical reason was that it used to be patented (US4197590).  Even then, this was only for computer graphics.

===Aliasing===
The XOR swap is also complicated in practice by [[aliasing (computing)|aliasing]]. As noted above, if an attempt is made to XOR-swap the contents of some location with itself, the result is that the location is zeroed out and its value lost. Therefore, XOR swapping must not be used blindly in a high-level language if aliasing is possible.

Similar problems occur with [[call by name]], as in [[Jensen's Device]], where swapping &lt;code&gt;i&lt;/code&gt; and &lt;code&gt;A[i]&lt;/code&gt; via a temporary variable yields incorrect results due to the arguments being related: swapping via &lt;code&gt;temp = i; i = A[i]; A[i] = temp&lt;/code&gt; changes the value for &lt;code&gt;i&lt;/code&gt; in the second statement, which then results in the incorrect i value for &lt;code&gt;A[i]&lt;/code&gt; in the third statement.

==Variations==
The underlying principle of the XOR swap algorithm can be applied to any operation meeting criteria L1 through L4 above. Replacing XOR by addition and subtraction gives a slightly different, but largely equivalent, formulation:

&lt;source lang="c"&gt;
 void addSwap (unsigned int *x, unsigned int *y)
 {
     if (x != y) {
         *x = *x + *y;
         *y = *x - *y;
         *x = *x - *y;
     }
 }
&lt;/source&gt;

Unlike the XOR swap, this variation requires that the underlying processor or programming language uses a method such as [[modular arithmetic]] or [[bignum]]s to guarantee that the computation of &lt;code&gt;X + Y&lt;/code&gt; cannot cause an error due to [[integer overflow]]. Therefore, it is seen even more rarely in practice than the XOR swap.

Note, however, that the implementation of &lt;code&gt;addSwap&lt;/code&gt; above in the C programming language always works even in case of integer overflow, since, according to the C standard, addition and  subtraction of unsigned integers follow the rules of [[modular arithmetic]], i. e. are done in the [[cyclic group]] &lt;math&gt;\mathbb Z/2^s\mathbb Z&lt;/math&gt; where &lt;math&gt;s&lt;/math&gt; is the number of bits of &lt;code&gt;unsigned int&lt;/code&gt;. Indeed, the correctness of the algorithm follows from the fact that the formulas &lt;math&gt;(x + y) - y = x&lt;/math&gt; and &lt;math&gt;(x + y) - ((x + y) - y) = y&lt;/math&gt; hold in any [[abelian group]]. This is actually a generalization of the proof for the XOR swap algorithm: XOR is both the addition and subtraction in the abelian group &lt;math&gt;(\mathbb Z/2\mathbb Z)^{s}&lt;/math&gt;.

Please note that the above doesn't hold when dealing with the &lt;code&gt;signed int&lt;/code&gt; type (the default for &lt;code&gt;int&lt;/code&gt;). Signed integer overflow is an undefined behavior in C and thus modular arithmetic is not guaranteed by the standard (a standard-conforming compiler might optimize out such code, which leads to incorrect results).

== See also ==
* [[Symmetric difference]]
* [[XOR linked list]]
* [[Feistel cipher]] (the XOR swap algorithm is a degenerate form of a Feistel cypher)

== Notes ==
{{Notelist}}

== References ==
{{Reflist}}

[[Category:Algorithms]]
[[Category:Articles with example C code]]
[[Category:Binary arithmetic]]

[[pl:Zamiana wartości zmiennych]]
[[fr:Échange (informatique)#En_utilisant_l.27op.C3.A9ration_XOR]]</text>
      <sha1>m1k74cx9vz95i4221ftv5w0zgx6zgaj</sha1>
    </revision>
  </page>
  <page>
    <title>Young tableau</title>
    <ns>0</ns>
    <id>683368</id>
    <revision>
      <id>833057672</id>
      <parentid>832911096</parentid>
      <timestamp>2018-03-29T12:53:19Z</timestamp>
      <contributor>
        <username>Joel B. Lewis</username>
        <id>13974845</id>
      </contributor>
      <minor/>
      <comment>/* Skew tableaux */ partial cleanup of insane math formatting templates</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20131">In [[mathematics]], a '''Young tableau''' ({{IPAc-en|t|æ|ˈ|b|l|oʊ|,_|ˈ|t|æ|b|l|oʊ}}; plural: '''tableaux''') is a [[combinatorics|combinatorial]] object useful in [[representation theory]] and [[Schubert calculus]]. It provides a convenient way to describe the [[group representation]]s of the [[symmetric group|symmetric]] and [[general linear group|general linear]] groups and to study their properties. Young tableaux were introduced by [[Alfred Young]], a [[mathematician]] at [[University of Cambridge|Cambridge University]], in 1900.&lt;ref&gt;{{citation|title=[[The Art of Computer Programming]], Vol. III: Sorting and Searching|first=Donald E.|last=Knuth|authorlink=Donald Knuth|edition=2nd|publisher=Addison-Wesley|year=1973|page=48|quote=Such arrangements were introduced by Alfred Young in 1900}}.&lt;/ref&gt;&lt;ref&gt;{{citation|title=On quantitative substitutional analysis|first=A.|last=Young|journal=Proceedings of the London Mathematical Society|year=1900|volume=33|series=Ser. 1|issue=1|pages=97–145|doi=10.1112/plms/s1-33.1.97}}. See in particular p.&amp;nbsp;133.&lt;/ref&gt; They were then applied to the study of the symmetric group by [[Georg Frobenius]] in 1903. Their theory was further developed by many mathematicians, including [[Percy MacMahon]], [[W. V. D. Hodge]], [[Gilbert de Beauregard Robinson|G. de B. Robinson]], [[Gian-Carlo Rota]], [[Alain Lascoux]], [[Marcel-Paul Schützenberger]] and [[Richard P. Stanley]].

==Definitions==

''Note: this article uses the English convention for displaying Young diagrams and tableaux''.

=== Diagrams &lt;!-- [[Young diagram]] currently redirects to this section]]--&gt; ===
[[Image:Young diagram for 541 partition.svg|thumb|right|150px|Young diagram of shape (5, 4, 1), English notation]]
[[Image:Young diagram for 541 partition-French.svg|thumb|right|150px|Young diagram of shape (5, 4, 1), French notation]]

A '''Young diagram''' (also called [[Ferrers diagram]], particularly when represented using dots) is a finite collection of boxes, or cells, arranged in left-justified rows, with the row lengths in non-increasing order. Listing the number of boxes in each row gives a [[partition (number theory)|partition]] {{mvar|''λ''}} of a non-negative integer {{mvar|''n''}}, the total number of boxes of the diagram. The Young diagram is said to be of shape {{mvar|''λ''}}, and it carries the same information as that partition. Containment of one Young diagram in another defines a [[partial ordering]] on the set of all partitions, which is in fact a [[lattice (order)|lattice]] structure, known as [[Young's lattice]]. Listing the number of boxes of a Young diagram in each column gives another partition, the '''conjugate''' or ''transpose'' partition of {{mvar|''λ''}}; one obtains a Young diagram of that shape by reflecting the original diagram along its main diagonal.

There is almost universal agreement that in labeling boxes of Young diagrams by pairs of integers, the first index selects the row of the diagram, and the second index selects the box within the row. Nevertheless, two distinct conventions exist to display these diagrams, and consequently tableaux: the first places each row below the previous one, the second stacks each row on top of the previous one. Since the former convention is mainly used by [[English-speaking world|Anglophones]] while the latter is often preferred by [[Francophone]]s, it is customary to refer to these conventions respectively as the ''English notation'' and the ''French notation''; for instance, in his book on [[symmetric function]]s, [[Ian G. Macdonald|Macdonald]] advises readers preferring the French convention to "read this book upside down in a mirror" (Macdonald 1979, p.&amp;nbsp;2). This nomenclature probably started out as jocular. The English notation corresponds to the one universally used for matrices, while the French notation is closer to the convention of [[Cartesian coordinates]]; however, French notation differs from that convention by placing the vertical coordinate first. The figure on the right shows, using the English notation, the Young diagram corresponding to the partition (5, 4, 1) of the number 10. The conjugate partition, measuring the column lengths, is (3, 2, 2, 2, 1).

==== Arm and leg length ====
In many applications, for example when defining [[Jack function]]s, it is convenient to define the '''arm length''' ''a''&lt;sub&gt;λ&lt;/sub&gt;(''s'') of a box ''s'' as the number of boxes to the right of ''s'' in the diagram λ. Similarly, the '''leg length''' ''l''&lt;sub&gt;λ&lt;/sub&gt;(''s'') is the number of boxes below ''s''. This notation assumes that the English notation is used.
For example, the ''hook'' value of a box ''s'' in λ is then simply ''a''&lt;sub&gt;λ&lt;/sub&gt;(''s'')+''l''&lt;sub&gt;λ&lt;/sub&gt;(''s'')+1.

=== Tableaux ===
[[Image:Young tableaux for 541 partition.svg|thumb|right|150px|A standard Young tableau of shape (5, 4, 1)]]

A '''Young tableau''' is obtained by filling in the boxes of the Young diagram with symbols taken from some ''alphabet'', which is usually required to be a [[totally ordered set]]. Originally that alphabet was a set of indexed variables {{mvar|''x''&lt;sub&gt;1&lt;/sub&gt;}}, {{mvar|''x''&lt;sub&gt;2&lt;/sub&gt;}}, {{mvar|''x''&lt;sub&gt;3&lt;/sub&gt;}}..., but now one usually uses a set of numbers for brevity. In their original application to [[representations of the symmetric group]], Young tableaux have {{mvar|''n''}} distinct entries, arbitrarily assigned to boxes of the diagram.  A tableau is called '''standard''' if the entries in each row and each column are increasing. The number of distinct standard Young tableaux on {{mvar|''n''}} entries is given by the [[involution number]]s
:1, 1, 2, 4, 10, 26, 76, 232, 764, 2620, 9496, ... {{OEIS|A000085}}.

In other applications, it is natural to allow the same number to appear more than once (or not at all) in a tableau.  A tableau is called '''semistandard''', or ''column strict'', if the entries weakly increase along each row and strictly increase down each column.  Recording the number of times each number appears in a tableau gives a sequence known as the '''weight''' of the tableau.   Thus the standard Young tableaux are precisely the semistandard tableaux of weight (1,1,...,1), which requires every integer up to {{mvar|''n''}} to occur exactly once.

=== Variations ===

There are several variations of this definition: for example, in a row-strict tableau the entries strictly increase along the rows and weakly increase down the columns. Also, tableaux with ''decreasing'' entries have been considered, notably, in the theory of [[plane partition]]s. There are also generalizations such as domino tableaux or ribbon tableaux, in which several boxes may be grouped together before assigning entries to them.

=== Skew tableaux ===
[[Image:Skew tableau 5422-21.svg|thumb|right|150px|Skew tableau of shape (5, 4, 2, 2) / (2, 1), English notation]]

A '''skew shape''' is a pair of partitions ({{math|''λ''}}, {{math|''μ''}}) such that the Young diagram of {{math|''λ''}} contains the Young diagram of {{math|''μ''}}; it is denoted by {{math|''λ''/''μ''}}.  If {{math|''λ'' {{=}} (''λ''&lt;sub&gt;1&lt;/sub&gt;, ''λ''&lt;sub&gt;2&lt;/sub&gt;, ...)}} and {{math|''μ'' {{=}} (''μ''&lt;sub&gt;1&lt;/sub&gt;, ''μ''&lt;sub&gt;2&lt;/sub&gt;, ...)}}, then the containment of diagrams means that {{math|''μ''&lt;sub&gt;''i''&lt;/sub&gt;&amp;nbsp;≤&amp;nbsp;''λ''&lt;sub&gt;''i''&lt;/sub&gt;}} for all {{mvar|i}}. The '''skew diagram''' of a skew shape {{math|''λ''/''μ''}} is the set-theoretic difference of the Young diagrams of {{mvar|''λ''}} and {{mvar|''μ''}}: the set of squares that belong to the diagram of {{mvar|''λ''}} but not to that of {{mvar|''μ''}}. A '''skew tableau''' of shape {{math|''λ''/''μ''}} is obtained by filling the squares of the corresponding skew diagram; such a tableau is semistandard if entries increase weakly along each row, and increase strictly down each column, and it is standard if moreover all numbers from 1 to the number of squares of the skew diagram occur exactly once. While the map from partitions to their Young diagrams is injective, this is not the case from the map from skew shapes to skew diagrams;&lt;ref&gt;For instance the skew diagram consisting of a single square at position (2,4) can be obtained by removing the diagram of {{math|''μ''&amp;nbsp;{{=}}&amp;nbsp;(5,3,2,1)}} from the one of {{math|''λ'' {{=}} (5,4,2,1)}}, but also in (infinitely) many other ways. In general any skew diagram whose set of non-empty rows (or of non-empty columns) is not contiguous or does not contain the first row (respectively column) will be associated to more than one skew shape.&lt;/ref&gt; therefore the shape of a skew diagram cannot always be determined from the set of filled squares only. Although many properties of skew tableaux only depend on the filled squares, some operations defined on them do require explicit knowledge of {{mvar|''λ''}} and {{mvar|''μ''}}, so it is important that skew tableaux do record this information: two distinct skew tableaux may differ only in their shape, while they occupy the same set of squares, each filled with the same entries.&lt;ref&gt;A somewhat similar situation arises for matrices: the 3-by-0 matrix {{mvar|''A''}} must be distinguished from the 0-by-3 matrix {{mvar|''B''}}, since {{math|''AB''}} is a 3-by-3 (zero) matrix while {{math|''BA''}} is the 0-by-0 matrix, but both {{mvar|''A''}} and {{mvar|''B''}} have the same (empty) set of entries; for skew tableaux however such distinction is necessary even in cases where the set of entries is not empty.&lt;/ref&gt; Young tableaux can be identified with skew tableaux in which {{mvar|''μ''}} is the empty partition (0) (the unique partition of 0).

Any skew semistandard tableau {{mvar|''T''}} of shape {{math|''λ''/''μ''}} with positive integer entries gives rise to a sequence of partitions (or Young diagrams), by starting with {{mvar|''μ''}}, and taking for the partition {{mvar|''i''}} places further in the sequence the one whose diagram is obtained from that of {{mvar|''μ''}} by adding all the boxes that contain a value&amp;nbsp; ≤&amp;nbsp;{{mvar|''i''}} in {{mvar|''T''}}; this partition eventually becomes equal to&amp;nbsp;{{mvar|''λ''}}. Any pair of successive shapes in such a sequence is a skew shape whose diagram contains at most one box in each column; such shapes are called '''horizontal strips'''. This sequence of partitions completely determines {{mvar|''T''}}, and it is in fact possible to define (skew) semistandard tableaux as such sequences, as is done by Macdonald (Macdonald 1979, p.&amp;nbsp;4). This definition incorporates the partitions {{mvar|''λ''}} and {{mvar|''μ''}} in the data comprising the skew tableau.

== Overview of applications ==

Young tableaux have numerous applications in [[combinatorics]], [[representation theory]], and [[algebraic geometry]]. Various ways of counting Young tableaux have been explored and lead to the definition of and identities for [[Schur polynomial|Schur functions]]. Many combinatorial algorithms on tableaux are known, including Schützenberger's [[jeu de taquin]] and the [[Robinson–Schensted–Knuth correspondence]]. Lascoux and Schützenberger studied an [[associative]] product on the set of all semistandard Young tableaux, giving it the structure called the ''[[plactic monoid]]'' (French: ''le monoïde plaxique'').

In representation theory, standard Young tableaux of size {{mvar|''k''}} describe bases in irreducible representations of the [[symmetric group]] on {{mvar|''k''}} letters. The [[standard monomial basis]] in a finite-dimensional [[irreducible representation]] of the [[general linear group]] {{math|''GL''&lt;sub&gt;''n''&lt;/sub&gt;}} are parametrized by the set of semistandard Young tableaux of a fixed shape over the alphabet {1, 2, ..., {{mvar|''n''}}}. This has important consequences for [[invariant theory]], starting from the work of [[W. V. D. Hodge|Hodge]] on the [[homogeneous coordinate ring]] of the [[Grassmannian]] and further explored by [[Gian-Carlo Rota]] with collaborators, [[Corrado de Concini|de Concini]] and [[Claudio Procesi|Procesi]], and [[David Eisenbud|Eisenbud]]. The [[Littlewood–Richardson rule]] describing (among other things) the decomposition of [[tensor product]]s of irreducible representations of {{math|''GL''&lt;sub&gt;''n''&lt;/sub&gt;}} into irreducible components is formulated in terms of certain skew semistandard tableaux.

Applications to algebraic geometry center around [[Schubert calculus]] on Grassmannians and [[flag varieties]]. Certain important [[cohomology class]]es can be represented by [[Schubert polynomial]]s and described in terms of Young tableaux.

==Applications in representation theory==
{{see also|Representation theory of the symmetric group}}
Young diagrams are in one-to-one correspondence with [[irreducible representation]]s of the [[symmetric group]] over the [[complex number]]s. They provide a convenient way of specifying the [[Young symmetrizer]]s from which the [[representation theory of the symmetric group|irreducible representations]] are built. Many facts about a representation can be deduced from the corresponding diagram. Below, we describe two examples: determining the dimension of a representation and restricted representations. In both cases, we will see that some properties of a representation can be determined by using just its diagram.

Young diagrams also parametrize the irreducible polynomial representations of the [[general linear group]] {{math|''GL''&lt;sub&gt;''n''&lt;/sub&gt;}} (when they have at most {{mvar|''n''}} nonempty rows), or the irreducible representations of the [[special linear group]] {{math|''SL''&lt;sub&gt;''n''&lt;/sub&gt;}} (when they have at most {{math|''n'' − 1}} nonempty rows), or the irreducible complex representations of the [[special unitary group]] {{math|''SU''&lt;sub&gt;''n''&lt;/sub&gt;}} (again when they have at most {{math|''n'' − 1}} nonempty rows). In these cases semistandard tableaux with entries up to {{mvar|''n''}} play a central role, rather than standard tableaux; in particular it is the number of those tableaux that determines the dimension of the representation.

===Dimension of a representation===
{{Main|Hook length formula}}
{{Plain image with caption|
Image:Hook length for 541 partition.svg|caption=''Hook-lengths'' of the boxes for the partition 10&amp;nbsp;=&amp;nbsp;5&amp;nbsp;+&amp;nbsp;4&amp;nbsp;+&amp;nbsp;1}}

The dimension of the irreducible representation {{math|{{pi}}&lt;sub&gt;''λ''&lt;/sub&gt;}} of the symmetric group {{math|''S''&lt;sub&gt;''n''&lt;/sub&gt;}} corresponding to a partition {{mvar|''λ''}} of {{mvar|''n''}} is equal to the number of different standard Young tableaux that can be obtained from the diagram of the representation. This number can be calculated by the [[hook length formula]].

A '''hook length''' {{math|hook(''x'')}} of a box {{mvar|''x''}} in Young diagram {{math|''Y''(''λ'')}} of shape {{mvar|''λ''}} is the number of boxes that are in the same row to the right of it plus those boxes in the same column below it, plus one (for the box itself). By the hook-length formula, the dimension of an irreducible representation is {{math|''n''!}} divided by the product of the hook lengths of all boxes in the diagram of the representation:

:&lt;math&gt;\dim\pi_\lambda = \frac{n!}{\prod_{x \in Y(\lambda)} \operatorname{hook}(x)}.&lt;/math&gt;

The figure on the right shows hook-lengths for all boxes in the diagram of the partition 10 = 5 + 4 + 1. Thus

:&lt;math&gt;\dim\pi_\lambda = \frac{10!}{7\cdot5\cdot 4 \cdot 3\cdot 1\cdot 5\cdot 3\cdot 2\cdot 1\cdot1} = 288.&lt;/math&gt;

Similarly, the dimension of the irreducible representation {{math|''W''(''λ'')}} of {{math|GL&lt;sub&gt;''r''&lt;/sub&gt;}} corresponding to the partition ''λ'' of ''n'' (with at most ''r'' parts) is the number of semistandard Young tableaux of shape ''λ'' (containing only the entries from 1 to ''r''), which is given by the hook-length formula:

: &lt;math&gt;\dim W(\lambda) = \prod_{(i,j) \in Y(\lambda)} \frac{r+j-i}{\operatorname{hook}(i,j)},&lt;/math&gt;

where the index ''i'' gives the row and ''j'' the column of a box.&lt;ref&gt;{{cite book|author=[[Predrag Cvitanović]] |year=2008 |title=Group Theory: Birdtracks, Lie's, and Exceptional Groups | publisher=Princeton University Press | url=http://birdtracks.eu/}}, eq. 9.28 and appendix B.4&lt;/ref&gt; For instance, for the partition (5,4,1) we get as dimension of the corresponding irreducible representation of {{math|GL&lt;sub&gt;7&lt;/sub&gt;}} (traversing the boxes by rows):

:&lt;math&gt;\dim W(\lambda) = \frac{7\cdot 8\cdot 9\cdot 10\cdot 11\cdot 6\cdot 7\cdot 8\cdot 9\cdot 5}{7\cdot5\cdot 4 \cdot 3\cdot 1\cdot 5\cdot 3\cdot 2\cdot 1\cdot1} = 66 528.&lt;/math&gt;

===Restricted representations===

A representation of the symmetric group on {{mvar|''n''}} elements, {{math|''S''&lt;sub&gt;''n''&lt;/sub&gt;}} is also a representation of the symmetric group on {{math|''n'' − 1}} elements, {{math|''S''&lt;sub&gt;''n''−1&lt;/sub&gt;}}. However, an irreducible representation of {{math|''S''&lt;sub&gt;''n''&lt;/sub&gt;}} may not be irreducible for {{math|''S''&lt;sub&gt;''n''−1&lt;/sub&gt;}}. Instead, it may be a [[direct sum of representations|direct sum]] of several representations that are irreducible for {{math|''S''&lt;sub&gt;''n''−1&lt;/sub&gt;}}. These representations are then called the factors of the [[restricted representation]] (see also [[induced representation]]).

The question of determining this decomposition of the restricted representation of a given irreducible representation of ''S''&lt;sub&gt;''n''&lt;/sub&gt;, corresponding to a partition {{mvar|''λ''}} of {{mvar|''n''}}, is answered as follows. One forms the set of all Young diagrams that can be obtained from the diagram of shape {{mvar|''λ''}} by removing just one box (which must be at the end both of its row and of its column); the restricted representation then decomposes as a direct sum of the irreducible representations of {{math|''S''&lt;sub&gt;''n''−1&lt;/sub&gt;}} corresponding to those diagrams, each occurring exactly once in the sum.

== See also ==
* [[Robinson–Schensted correspondence]]
* [[Schur–Weyl duality]]
* [[Young's lattice]]

==Notes==
{{Reflist}}

==References==
* [[William Fulton (mathematician)|William Fulton]]. ''Young Tableaux, with Applications to Representation Theory and Geometry''. Cambridge University Press, 1997, {{isbn|0-521-56724-6}}.
* {{Fulton-Harris}} Lecture 4
* Howard Georgi, Lie Algebras in Particle Physics, 2nd Edition - Westview
* [[Ian G. Macdonald|Macdonald, I. G.]] ''Symmetric functions and Hall polynomials.'' Oxford Mathematical Monographs. The Clarendon Press, Oxford University Press, Oxford, 1979. viii+180 pp. {{isbn|0-19-853530-9}} {{MathSciNet|id=553598}}
* Laurent Manivel. ''Symmetric Functions, Schubert Polynomials, and Degeneracy Loci''.  American Mathematical Society.
* Jean-Christophe Novelli, [[Igor Pak]], Alexander V. Stoyanovkii, "[https://dmtcs.episciences.org/239 A direct bijective proof of the Hook-length formula]", ''Discrete Mathematics and Theoretical Computer Science'' '''1''' (1997), pp.&amp;nbsp;53–67.
* [[Bruce Sagan|Bruce E. Sagan]]. ''The Symmetric Group''. Springer, 2001, {{isbn|0-387-95067-2}}
*{{eom|id=Y/y099100|first=E.B.|last= Vinberg| authorlink=Ernest Vinberg}}
* {{cite journal
   | last = Yong
   | first = Alexander
   | title = What is...a Young Tableau?
   | journal = [[Notices of the American Mathematical Society]]
   |date=February 2007
   | volume = 54
   | issue = 2
   | pages =240–241
   | url = http://www.ams.org/notices/200702/whatis-yong.pdf
   | format = [[PDF]]
   | accessdate = 2008-01-16 }}
*[[Predrag Cvitanović]], ''Group Theory: Birdtracks, Lie's, and Exceptional Groups''. Princeton University Press, 2008.

==External links==
* Eric W. Weisstein. "[http://mathworld.wolfram.com/FerrersDiagram.html Ferrers Diagram]". From MathWorld—A Wolfram Web Resource.
* Eric W. Weisstein. "[http://mathworld.wolfram.com/YoungTableau.html Young Tableau]." From MathWorld—A Wolfram Web Resource.
* [http://www.findstat.org/SemistandardTableaux Semistandard tableaux] entry in the [http://www.findstat.org/ FindStat] database
* [http://www.findstat.org/StandardTableaux Standard tableaux] entry in the [http://www.findstat.org/ FindStat] database

[[Category:Representation theory of finite groups]]
[[Category:Symmetric functions]]</text>
      <sha1>pcer93ji5u97okn4irsl4yqk8n49eog</sha1>
    </revision>
  </page>
  <page>
    <title>Łoś–Vaught test</title>
    <ns>0</ns>
    <id>22229525</id>
    <revision>
      <id>854916744</id>
      <parentid>854916570</parentid>
      <timestamp>2018-08-14T17:39:29Z</timestamp>
      <contributor>
        <username>Trovatore</username>
        <id>310173</id>
      </contributor>
      <comment>let's get rid of the {{tl|mvar}} for consistency (admittedly I don't like them anyway)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1855">In model theory, a branch of mathematical logic, the '''Łoś–Vaught test''' is a criterion for a [[Theory (mathematical logic)|theory]] to be [[complete theory|complete]], unable to be augmented without becoming inconsistent. For theories in [[classical logic]], this means that for every sentence the theory contains either the sentence or its negation but not both.

According to this test, if a satisfiable theory is [[&amp;kappa;-categorical]] (there exists an infinite cardinal &amp;kappa; such that it has only one model up to isomorphism of cardinality &amp;kappa;, with &amp;kappa; at least equal to the cardinality of its language) and in addition it has no finite model, then it is complete.

This theorem was proved independently by {{harvs|first=Jerzy|last=Łoś|authorlink=Jerzy Łoś|year=1954|txt}} and {{harvs|first= Robert  L.|last= Vaught |authorlink=Robert Lawson Vaught |year=1954|txt}}, after whom it is named.

==References==
*{{citation
 | last = Enderton | first = Herbert B. | authorlink = Herbert Enderton
 | mr = 0337470
 | page = 147
 | publisher = Academic Press, New York-London
 | title = A mathematical introduction to logic
 | url = https://books.google.com/books?id=LHjNCgAAQBAJ&amp;pg=PA147
 | year = 1972}}.
*{{citation
 | last = Łoś | first = J. | authorlink = Jerzy Łoś
 | journal = Colloquium Math.
 | mr = 0061561
 | pages = 58–62
 | title = On the categoricity in power of elementary deductive systems and some related problems
 | volume = 3
 | year = 1954}}.
*{{citation
 | last = Vaught | first = Robert L. | authorlink = Robert Lawson Vaught
 | journal = [[Indagationes Mathematicae]]
 | mr = 0063993
 | pages = 467–472
 | title = Applications to the Löwenheim-Skolem-Tarski theorem to problems of completeness and decidability
 | volume = 16
 | year = 1954}}.

{{DEFAULTSORT:Los-Vaught test}}
[[Category:Model theory]]</text>
      <sha1>gu5ocqccef3osvj6yb1j0em6a1v301h</sha1>
    </revision>
  </page>
</mediawiki>
