<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>2 × 2 real matrices</title>
    <ns>0</ns>
    <id>9822856</id>
    <revision>
      <id>869526757</id>
      <parentid>869219197</parentid>
      <timestamp>2018-11-19T04:41:03Z</timestamp>
      <contributor>
        <ip>89.107.5.192</ip>
      </contributor>
      <comment>/* Equi-areal mapping */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11509">In [[mathematics]], the [[associative algebra]] of '''{{gaps|2|×|2}} [[real number|real]] [[matrix (mathematics)|matrices]]''' is denoted by M(2,&amp;thinsp;'''R'''). Two matrices ''p'' and ''q'' in M(2,&amp;thinsp;'''R''') have a sum ''p''&amp;nbsp;+&amp;nbsp;''q'' given by [[matrix addition]]. The product matrix {{nowrap|''p&amp;thinsp;q''}} is formed from the [[dot product]] of the rows and columns of its factors through [[matrix multiplication]]. For

: &lt;math&gt;q = \begin{pmatrix} a &amp; b \\ c &amp; d \end{pmatrix}, &lt;/math&gt;

let

: &lt;math&gt;q^* = \begin{pmatrix} d &amp; -b \\ -c &amp; a \end{pmatrix}. &lt;/math&gt;

Then ''q&amp;thinsp;q''{{sup|*}} = ''q''{{sup|*}}&amp;thinsp;''q'' = (''ad'' − ''bc'') {{serif|''I''}}, where {{serif|''I''}} is the {{gaps|2|×|2}} identity matrix. The real number  ''ad''&amp;nbsp;−&amp;nbsp;''bc''  is called the [[determinant]] of ''q''. When  ''ad''&amp;nbsp;−&amp;nbsp;''bc''&amp;nbsp;≠&amp;nbsp;0, ''q'' is an [[invertible matrix]], and then

:&lt;math&gt;q^{-1} = \frac{q^*}{ad - bc}.&lt;/math&gt;

The collection of all such invertible matrices constitutes the [[general linear group]] GL(2,&amp;thinsp;'''R'''). In terms of [[abstract algebra]], M(2,&amp;thinsp;'''R''') with the associated addition and multiplication operations forms a [[ring (mathematics)|ring]], and GL(2,&amp;thinsp;'''R''') is its [[group of units]].  M(2,&amp;thinsp;'''R''') is also a four-dimensional [[vector space]], so it is considered an [[associative algebra]]. It is [[Ring isomorphism|ring-isomorphic]] to the [[coquaternion]]s, but has a different profile.

The '''{{gaps|2|×|2}} real matrices''' are in [[one-one correspondence]] with the [[linear mapping]]s of the [[Cartesian coordinate system#Cartesian coordinates in two dimensions|two-dimensional Cartesian coordinate system]] into itself by the rule

:&lt;math&gt;
  \begin{pmatrix}x \\ y\end{pmatrix} \mapsto
    \begin{pmatrix}a &amp; b \\ c &amp; d\end{pmatrix} \begin{pmatrix}x \\ y\end{pmatrix} = 
    \begin{pmatrix}ax + by \\ cx + dy\end{pmatrix}.
&lt;/math&gt;

==Profile==
Within M(2, '''R'''), the multiples by real numbers of the [[identity matrix]] {{serif|''I''}} may be considered a [[real line]]. This real line is the place where all commutative [[subring]]s come together:

Let ''P''&lt;sub&gt;''m''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;{''x{{serif|I}}''&amp;nbsp;+&amp;nbsp;''ym''&amp;nbsp;:&amp;nbsp;''x'',&amp;nbsp;''y''&amp;nbsp;∈&amp;nbsp;'''R'''} where ''m''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;∈&amp;nbsp;{−{{serif|''I''}},&amp;nbsp;0,&amp;nbsp;{{serif|''I''}}&amp;nbsp;}. Then ''P''&lt;sub&gt;''m''&lt;/sub&gt; is a commutative subring and M(2,&amp;nbsp;'''R''') = ⋃''P''&lt;sub&gt;''m''&lt;/sub&gt;&amp;nbsp; where the union is over all ''m'' such that ''m''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;∈&amp;nbsp;{−{{serif|''I''}},&amp;nbsp;0,&amp;nbsp;{{serif|''I''}}&amp;nbsp;}.

To identify such ''m'', first square the generic matrix:
:&lt;math&gt;\begin{pmatrix}aa + bc &amp; ab + bd \\ ac + cd &amp; bc + dd \end{pmatrix}.&lt;/math&gt;

When ''a'' + ''d'' = 0 this square is a [[diagonal matrix]].

Thus one assumes ''d''&amp;nbsp;=&amp;nbsp;−''a'' when looking for ''m'' to form commutative subrings. When ''mm''&amp;nbsp;=&amp;nbsp;−{{serif|''I''}}, then ''bc''&amp;nbsp;=&amp;nbsp;−1&amp;nbsp;−&amp;nbsp;''aa'', an equation describing a [[hyperbolic paraboloid]] in the space of parameters (''a'',&amp;nbsp;''b'',&amp;nbsp;''c''). Such an ''m'' serves as an [[imaginary unit]]. In this case P&lt;sub&gt;''m''&lt;/sub&gt; is isomorphic to the field of (ordinary) [[complex number]]s.

When ''mm''&amp;nbsp;=&amp;nbsp;+{{serif|''I''}}, ''m'' is an [[involutory matrix]]. Then ''bc''&amp;nbsp;=&amp;nbsp;+1&amp;nbsp;−&amp;nbsp;''aa'', also giving a hyperbolic paraboloid. If a matrix is an [[idempotent matrix]], it must lie in such a P&lt;sub&gt;''m''&lt;/sub&gt; and in this case P&lt;sub&gt;''m''&lt;/sub&gt; is [[ring isomorphism|isomorphic]] to the ring of [[split-complex number]]s.

The case of a [[nilpotent matrix]], ''mm''&amp;nbsp;=&amp;nbsp;0, arises when only one of ''b'' or ''c'' is non-zero, and the commutative subring P&lt;sub&gt;''m''&lt;/sub&gt; is then a copy of the [[dual number]] plane.

When M(2, '''R''') is reconfigured with a [[change of basis]], this profile changes to the [[coquaternion#Profile|profile of split-quaternions]] where the sets of square roots of {{serif|''I''}} and −{{serif|''I''}} take a symmetrical shape as [[hyperboloid]]s.

==Equi-areal mapping==
&lt;!-- This section is linked from [[Area]] --&gt;
{{main|Equiareal map}}
First transform one differential vector into another:
:&lt;math&gt;
  \begin{pmatrix}du \\ dv \end{pmatrix} =
    \begin{pmatrix}p &amp; r\\ q &amp; s \end{pmatrix} \begin{pmatrix}dx \\ dy \end{pmatrix} = 
    \begin{pmatrix}p\, dx + r\, dy \\  q\, dx + s\, dy\end{pmatrix}.
&lt;/math&gt;

[[Area]]s are measured with ''density'' &lt;math&gt;dx \wedge dy&lt;/math&gt;, a [[differential form|differential 2-form]] which involves the use of [[exterior algebra]]. The transformed density is

:&lt;math&gt;\begin{align}
  du \wedge dv &amp;= 0 + ps\ dx \wedge dy + qr\ dy \wedge dx + 0 \\
               &amp;= (ps - qr)\ dx \wedge dy \\
               &amp;= \det(g)\ dx \wedge dy.
\end{align}&lt;/math&gt;

Thus the equi-areal mappings are identified with [[SL2(R)|SL(2,&amp;#8239;R)]]&amp;nbsp;=&amp;nbsp;{''g''&amp;nbsp;∈&amp;nbsp;M(2,&amp;#8239;R)&amp;nbsp;:&amp;nbsp;det(''g'')&amp;nbsp;=&amp;nbsp;1}, the [[special linear group]]. Given the profile above, every such ''g'' lies in a commutative subring P&lt;sub&gt;''m''&lt;/sub&gt; representing a type of complex plane according to the square of ''m''.  Since ''g&amp;#8239;g''{{sup|*}}&amp;nbsp;=&amp;nbsp;{{serif|''I''}}, one of the following three alternatives occurs:
* ''mm'' = −{{serif|''I''}} and ''g'' is on a circle of Euclidean [[rotation (mathematics)|rotations]]; or
* ''mm'' = {{serif|''I''}} and ''g'' is on an hyperbola of [[squeeze mapping]]s; or
* ''mm'' = 0 and ''g'' is on a line of [[shear mapping]]s.

Writing about [[affine group#Planar affine group|planar affine mapping]], [[Rafael Artzy]] made a similar trichotomy of planar, linear mapping in his book ''Linear Geometry'' (1965).

==Functions of 2 × 2 real matrices==
The commutative subrings of M(2, '''R''') determine the function theory; in particular the three types of subplanes have their own algebraic structures which set the value of algebraic expressions. Consideration of the square root function and the logarithm function serves to illustrate the constraints implied by the special properties of each type of subplane P&lt;sub&gt;''m''&lt;/sub&gt; described in the above profile.
The concept of [[identity component]] of the [[group of units]] of P&lt;sub&gt;''m''&lt;/sub&gt; leads to the [[polar decomposition]] of elements of the group of units:
*If ''mm'' = −{{serif|''I''}}, then ''z'' =&amp;nbsp;ρ&amp;nbsp;exp(θ''m'').
*If ''mm'' = 0, then ''z'' =&amp;nbsp;ρ&amp;nbsp;exp(s&amp;nbsp;''m'')  or ''z'' =&amp;nbsp;−ρ&amp;nbsp;exp(s&amp;nbsp;''m'').
*If ''mm'' = &amp;nbsp;{{serif|''I''}}, then ''z'' =&amp;nbsp;ρ&amp;nbsp;exp(''a&amp;nbsp;m'') or ''z'' =&amp;nbsp;−ρ&amp;nbsp;exp(''a&amp;nbsp;m'') or ''z'' =&amp;nbsp;''m''&amp;nbsp;ρ&amp;nbsp;exp(''a&amp;nbsp;m'') or ''z'' =&amp;nbsp;−''m''&amp;nbsp;ρ&amp;nbsp;exp(''a&amp;nbsp;m'').

In the first case exp(θ&amp;nbsp;''m'') =&amp;nbsp;cos(θ)&amp;nbsp;+&amp;nbsp;''m''&amp;nbsp;sin(θ). In the case of the dual numbers exp(''s&amp;nbsp;m'') =&amp;nbsp;1&amp;nbsp;+&amp;nbsp;''s&amp;nbsp;m''. Finally, in the case of split complex numbers there are four components in the group of units. The identity component is parameterized by ρ and exp(''a&amp;nbsp;m'') =&amp;nbsp;cosh(''a'')&amp;nbsp;+&amp;nbsp;''m''&amp;nbsp;sinh(''a'').
 
Now &lt;math display="inline"&gt;\sqrt{\rho\ \exp(am)} = \sqrt{\rho}\ \exp\left(\frac{1}{2}am\right)&lt;/math&gt; regardless of the subplane P&lt;sub&gt;''m''&lt;/sub&gt;, but the argument of the function must be taken from the ''identity component of its group of units''. Half the plane is lost in the case of the dual number structure; three-quarters of the plane must be excluded in the case of the split-complex number structure.

Similarly, if ρ&amp;nbsp;exp(''a&amp;nbsp;m'') is an element of the identity component of the group of units of a plane associated with {{gaps|2|×|2}} matrix&amp;nbsp;''m'', then the logarithm function results in a value log&amp;nbsp;ρ&amp;nbsp;+&amp;nbsp;''a m''. The domain of the logarithm function suffers the same constraints as does the square root function described above: half or three-quarters of P&lt;sub&gt;''m''&lt;/sub&gt; must be excluded in the cases ''mm'' =&amp;nbsp;0 or ''mm'' =&amp;nbsp;{{serif|''I''}}.

Further function theory can be seen in the article [[complex functions]] for the C structure, or in the article [[motor variable]] for the split-complex structure.

== 2 × 2 real matrices as complex numbers ==
{{anchor|2 × 2 real matrices as complex numbers}}&lt;!-- "Dual number" links here --&gt;
Every {{gaps|2|×|2}} real matrix can be interpreted as one of three types of (generalized&lt;ref&gt;Anthony A. Harkin &amp; Joseph B. Harkin (2004) [http://people.rit.edu/harkin/research/articles/generalized_complex_numbers.pdf Geometry of Generalized Complex Numbers], [[Mathematics Magazine]] 77(2):118–29&lt;/ref&gt;) complex numbers: standard [[complex number]]s, [[dual number]]s, and [[split-complex number]]s. Above, the algebra of {{gaps|2|×|2}} matrices is profiled as a union of complex planes, all sharing the same real axis. These planes are presented as [[commutative]] [[subring]]s ''P''&lt;sub&gt;''m''&lt;/sub&gt;. We can determine to which complex plane a given {{gaps|2|×|2}} matrix belongs as follows and classify which kind of complex number that plane represents.

Consider the {{gaps|2|×|2}} matrix
:&lt;math&gt;z = \begin{pmatrix} a &amp; b \\ c &amp; d \end{pmatrix}.&lt;/math&gt;

We seek the complex plane ''P''&lt;sub&gt;''m''&lt;/sub&gt; containing ''z''.

As noted above, the square of the matrix ''z'' is diagonal when ''a'' + ''d'' = 0. The matrix ''z'' must be expressed as the sum of a multiple of the [[identity matrix]] {{serif|''I''}} and a matrix in the [[hyperplane]] ''a'' + ''d'' = 0. [[projection (linear algebra)|Projecting]] ''z'' alternately onto these subspaces of R&lt;sup&gt;4&lt;/sup&gt; yields
:&lt;math&gt;z = xI + n ,\quad x = \frac{a + d}{2}, \quad n = z - xI.&lt;/math&gt;

Furthermore, 
:&lt;math&gt;n^2 = pI&lt;/math&gt; where &lt;math&gt;p = \frac{(a - d)^2}{4} + bc&lt;/math&gt;.

Now ''z'' is one of three types of complex number:
* If ''p'' &lt; 0, then it is an ordinary [[complex number]]:
*: Let &lt;math&gt;q = 1/\sqrt{-p}, \quad m = qn&lt;/math&gt;. Then &lt;math&gt;m^2 = -I, \quad z = xI + m\sqrt{-p}&lt;/math&gt;.
* If ''p'' = 0, then it is the [[dual number]]: 
*: &lt;math&gt;z = xI + n&lt;/math&gt;. 
*If ''p'' &gt; 0, then ''z'' is a [[split-complex number]]:
*: Let &lt;math&gt;q = 1/\sqrt{p}, \quad m = qn&lt;/math&gt;. Then &lt;math&gt;m^2 = +I, \quad z = xI + m\sqrt{p}&lt;/math&gt;.

Similarly, a {{gaps|2|×|2}} matrix can also be expressed in [[polar decomposition#Alternative planar decompositions|polar coordinates]] with the caveat that there are two [[connected space|connected components]] of the group of units in the dual number plane, and four components in the split-complex number plane.

==References==
{{Reflist}}
* [[Rafael Artzy]] (1965) ''Linear Geometry'', Chapter 2-6 Subgroups of the Plane Affine Group over the Real Field, p.&amp;nbsp;94, [[Addison-Wesley]].
* Helmut Karzel &amp; Gunter Kist (1985) "Kinematic Algebras and their Geometries", found in
** ''Rings and Geometry'', R. Kaya, P. Plaumann, and K. Strambach editors, pp.&amp;nbsp;437–509, esp 449,50, [[D. Reidel]] {{isbn|90-277-2112-2}} .
* Svetlana Katok (1992) ''Fuchsian groups'', pp.&amp;nbsp;113ff, [[University of Chicago Press]] {{isbn|0-226-42582-7}} .
* {{cite book|author=Garret Sobczyk|title=New Foundations in Mathematics: The Geometric Concept of Number|year=2012|publisher=Birkhäuser|isbn=978-0-8176-8384-9|chapter=Chapter 2: Complex and Hyperbolic Numbers}}

{{DEFAULTSORT:Real Matrices (2 by 2)}}
[[Category:Affine geometry]]
[[Category:Functions and mappings]]
[[Category:Linear algebra]]
[[Category:Algebras]]
[[Category:Area]]
[[Category:Matrices]]</text>
      <sha1>cr9k73h7s7pfl9zv85hgr9emxldf18o</sha1>
    </revision>
  </page>
  <page>
    <title>Albert Muchnik</title>
    <ns>0</ns>
    <id>22647091</id>
    <revision>
      <id>861298642</id>
      <parentid>782157926</parentid>
      <timestamp>2018-09-26T13:02:49Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3345">'''Albert Abramovich Muchnik''' (born 1934) is a [[Russian people|Russian]] [[mathematician]] who worked in the field of foundations and [[mathematical logic]].

He received his Ph.D from [[Moscow State Pedagogical Institute]] in 1959 under the advisorship of [[Pyotr Novikov]].&lt;ref&gt;[http://genealogy.math.ndsu.nodak.edu/id.php?id=113668 Albert Abramovich Muchnik,] [[Mathematics Genealogy Project]]. Accessed January 26, 2010&lt;/ref&gt;  Muchnik's most significant contribution was on the subject of [[relative computability]]. He and [[Richard Friedberg]], independently introduced the priority method which gave an affirmative answer to Post's Problem regarding the existence of [[recursively enumerable|re]] [[Turing degrees]] between ''' 0 ''' and ''' 0' '''. This groundbreaking result, now known as the '''[[Friedberg-Muchnik Theorem]]''',&lt;ref&gt;Robert I. Soare, [https://books.google.com/books?id=9I7Pl00LU5gC&amp;pg=PA118&amp;dq=%22Friedberg-Muchnik+theorem%22&amp;ei=QPBeS_efBYWyNKSW4IwD&amp;cd=1#v=onepage&amp;q=%22Friedberg-Muchnik%20theorem%22&amp;f=false Recursively Enumberable Sets and Degrees: A Study of Computable Functions and Computably Generated Sets.] [[Springer-Verlag]], 1999, {{ISBN|3-540-15299-7}}; p. 118&lt;/ref&gt;&lt;ref&gt;Nikolai  Vereshchagin, Alexander Shen, [https://books.google.com/books?id=A6uvsks0abgC&amp;pg=PA85&amp;dq=%22Friedberg-Muchnik+theorem%22&amp;ei=QPBeS_efBYWyNKSW4IwD&amp;cd=3#v=onepage&amp;q=%22Friedberg-Muchnik%20theorem%22&amp;f=false Computable functions.] [[American Mathematical Society]], 2003, {{ISBN|0-8218-2732-4}}; p. 85&lt;/ref&gt; opened a wide study of the Turing degrees of the recursively enumerable sets which turned out to possess a very complicated and non-trivial structure. He also has a significant contribution in the subject of [[mass problems]] where he introduced the generalisation of Turing degrees, called "Muchnik degrees" in his work ''On Strong and Weak Reducibilities of Algorithmic Problems'' published in 1963.&lt;ref&gt;A. A. Muchnik, ''On strong and weak reducibility of algorithmic problems''. (Russian) 
[[Siberian Mathematical Journal]], vol. 4 (1963), pp. 1328&amp;ndash;1341&lt;/ref&gt; Muchnik also elaborated [[Kolmogorov]]'s proposal of viewing [[intuitionism]] as "calculus of problems" and proved that the lattice of Muchnik degrees is [[Intuitionism|Brouwerian]].

Muchnik is married to the Russian mathematician Nadezhda Ermolaeva, and their son Andrej, who died in 2007, was also a mathematician working in foundations of mathematics.&lt;ref&gt;S. I. Adian, A. L. Semenov, V. A. Uspenskii, [http://elibrary.ru/item.asp?id=9555845 ''Andrei Albertovich Muchnik'',]{{icon ru}}  [[Uspekhi Matematicheskikh Nauk]], vol. 62 (2007), no. 4, pp. 140&amp;ndash;144&lt;/ref&gt;

==Selected publications==
*A. A. Muchnik, ''On the unsolvability of the problem of reducibility in the theory of algorithms''. {{icon ru}} [[Doklady Akademii Nauk SSSR]] (N.S.), vol. 108 (1956), pp.&amp;nbsp;194&amp;ndash;197

==References==
{{reflist}}

==External links==
*[http://www.keldysh.ru/departments/dpt_10/mu1.html Albert Mucknik's personal webpage,]{{icon ru}} [[Keldysh Institute of Applied Mathematics]]


{{authority control}}

{{DEFAULTSORT:Muchnik, Albert}}
[[Category:1934 births]]
[[Category:Living people]]
[[Category:Mathematical logicians]]
[[Category:Russian mathematicians]]
[[Category:Moscow State Pedagogical University alumni]]


{{russia-mathematician-stub}}</text>
      <sha1>odgufkjd3ydni7o3vthmyh69qdrjehb</sha1>
    </revision>
  </page>
  <page>
    <title>Alfred Kempe</title>
    <ns>0</ns>
    <id>9092767</id>
    <revision>
      <id>824285996</id>
      <parentid>824283256</parentid>
      <timestamp>2018-02-06T13:03:41Z</timestamp>
      <contributor>
        <username>Alfie</username>
        <id>28632037</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/185.3.20.34|185.3.20.34]] ([[User talk:185.3.20.34|talk]]): Addition of [[WP:BLP|negative unsourced content]] to a biographical article ([[WP:HG|HG]]) (3.2.0)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6685">{{EngvarB|date=July 2017}}
{{Use dmy dates|date=July 2017}}
{{Distinguish|Alfred John Kempe}}
{{Infobox scientist
|name              = Sir Alfred Kempe
|image             = Alfred Bray Kempe.jpeg
|image_size       = 
|caption           = 
|birth_date        = {{birth date|df=yes|1849|07|07}}
|birth_place       = [[Kensington]], London, England
|death_date        = {{death date and age|df=yes|1922|04|21|1849|07|06}}
|death_place       = London, England
|residence         = 
|citizenship       = 
|nationality       = 
|ethnicity         = 
|field             = 
|work_institutions = 
|alma_mater        = 
|doctoral_advisor  = 
|doctoral_students = 
|known_for         = 
|author_abbrev_bot = 
|author_abbrev_zoo = 
|influences        = 
|influenced        = [[Charles Sanders Peirce]]
|prizes            = 
|religion          = 
|footnotes         = 
|signature         =
}}

Sir '''Alfred Bray Kempe''' [[Doctor of Canon Law|DCL]] [[Fellow of the Royal Society|FRS]] (6 July 1849, [[Kensington]], London – 21 April 1922, London) was a mathematician best known for his work on [[Linkage (mechanical)|linkages]] and the [[four colour theorem]].

Kempe was the son of the Rector of [[St James's Church, Piccadilly]], the Rev. John Edward Kempe. He was educated at [[St Paul's School, London]] and then studied at [[Trinity College, Cambridge]] where [[Arthur Cayley]] was one of his teachers. He graduated BA (22nd [[wrangler (University of Cambridge)|wrangler]]) in 1872.&lt;ref&gt;{{acad|id=KM867AB|name=Kempe, Alfred Bray}}&lt;/ref&gt; Despite his interest in mathematics he became a [[barrister]], specialising in the [[ecclesiastical law]]. He was knighted in 1913, the same year he became the [[Chancellor (ecclesiastical)|Chancellor]] for the [[Anglican Diocese of London (England)|Diocese of London]]. He was also Chancellor of the dioceses of Newcastle, Southwell, St Albans, Peterborough, Chichester, and Chelmsford. He received the honorary degree [[Doctor of Canon Law|DCL]] from the [[University of Durham]] and he was elected a [[Bencher]] of the [[Inner Temple]] in 1909.

In 1876 he published his article ''On a General Method of describing Plane Curves of the nth degree by Linkwork,''&lt;ref&gt;A. B. Kempe, (1876) [http://plms.oxfordjournals.org/content/s1-7/1/213.extract  On a General Method of describing Plane Curves of the nth degree by Linkwork.] Proceedings of the Royal Society.&lt;/ref&gt; which showed that for an arbitrary algebraic plane curve a linkage can be constructed that draws the curve.  This direct connection between [[Linkage (mechanical)|linkages]] and [[algebraic curves]] was recently named the [[Kempe's Universality Theorem]]&lt;ref&gt;A. Saxena (2011) [http://home.iitk.ac.in/~anupams/me352a_2015_course_folder/Kempe_AS.pdf Kempe’s Linkages and the Universality Theorem], RESONANCE&lt;/ref&gt; that any bounded subset of an [[algebraic curve]] may be traced out by the motion of one of the joints in a suitably chosen linkage. Kempe's proof was flawed, and the first complete proof was provided in 2002, based on his ideas.&lt;ref&gt;M. Kapovich and J. J. Millson (2002), [https://www.math.ucdavis.edu/~kapovich/EPR/KM_2002.pdf Universality theorems for configguration spaces of planar linkages] Topology, Pergamon Press.&lt;/ref&gt;&lt;ref&gt;{{citation|title=Geometric Folding Algorithms|last1=Demaine|first1=Erik|authorlink1=Erik Demaine|last2=O'Rourke|first2=Joseph|authorlink2=Joseph O'Rourke (professor)|publisher=Cambridge University Press|isbn=978-0-521-71522-5|year=2007|contribution=3.2 Kempe's Universality Theorem|pages=31–40}}.&lt;/ref&gt;

In 1877 Kempe discovered new [[Peaucellier-Lipkin linkage|straight line linkages]] and published his influential lectures on the subject.&lt;ref&gt;A. B. Kempe (1877) [https://synthetica.eng.uci.edu/mechanicaldesign101/Kempe-Straight-Line.pdf How to draw a straight line; a lecture on linkages], London: Macmillan and Co.&lt;/ref&gt; In 1879 Kempe wrote his famous "proof" of the [[four colour theorem]], shown incorrect by [[Percy Heawood]] in 1890. Much later, his work led to fundamental concepts such as the [[Kempe chain]] and unavoidable sets.

Kempe (1886) revealed a rather marked philosophical bent, and much influenced [[Charles Sanders Peirce]]. Kempe also discovered what are now called [[multiset]]s, although this fact was not noted until long after his death.&lt;ref&gt;A. B. Kempe, (1886) "A memoir on the theory of mathematical form," ''Philosophical Transactions of the Royal Society of London'' 177: 1–70&lt;/ref&gt;&lt;ref&gt;[[Ivor Grattan-Guinness]] (2000) ''The Search for Mathematical Roots 1870–1940''. Princeton Univ. Press&lt;/ref&gt;

Kempe was elected a [[Fellow of the Royal Society|fellow]] of the [[Royal Society]] in 1881. He was Treasurer and Vice-President of the Royal Society 1899–1919. He was a president of the [[London Mathematical Society]] from 1892 to 1894. He was also a [[Mountaineering|mountain climber]], mostly in [[Switzerland]].
[[File:Quadruplanar_invesor_of_Sylvester_and_Kempe_Alternate.gif|thumb|right|The Sylvester-Kempe Inversor draws a straight line.]]

His first wife was Mary, daughter of [[Sir William Bowman, 1st Baronet]]; she died in 1893. He then married, in 1897, Ida, daughter of His Honour Judge Meadows White, QC. He had two sons and one daughter.

==References==
{{reflist}}
&lt;!-- replaced with references *[[Ivor Grattan-Guinness]] (2000) ''The Search for Mathematical Roots 1870-1940''. Princeton Univ. Press.
*Kempe, A. B. (1886) "A memoir on the theory of mathematical form," ''Philosophical Transactions of the Royal Society of London'' 177: 1–70. --&gt;

==External links==
* {{Internet Archive author |name=Alfred Bray Kempe}}
*{{MacTutor Biography|id=Kempe}}
*From the Cornell University archives:  A. B. Kempe (1877) [https://synthetica.eng.uci.edu/mechanicaldesign101/Kempe-Straight-Line.pdf How to draw a straight line; a lecture on linkages], London: Macmillan and Co.
*Found at Project Gutenberg:  A. B. Kempe (1877) [https://archive.org/details/howtodrawastraig25155gut How to draw a straight line; a lecture on linkages, London: Macmillan and Co.]
*Examples of Kempe's Universality Theorem, [http://mechanicaldesign101.com/2016/08/03/mechanical-computation-and-algebraic-curves/ Mechanical computation and algebraic curves]
*[http://www.a-kobel.de/kempe/ Automatic generation of Kempe Linkages for Algebraic Curves.]
{{Authority control}}

{{DEFAULTSORT:Kempe, Alfred Bray}}
[[Category:19th-century English mathematicians]]
[[Category:20th-century English mathematicians]]
[[Category:1849 births]]
[[Category:1922 deaths]]
[[Category:Graph theorists]]
[[Category:Fellows of the Royal Society]]
[[Category:Alumni of Trinity College, Cambridge]]
[[Category:English mountain climbers]]</text>
      <sha1>7zyuxy1n8iw0guj57lxtk24gh72zeyx</sha1>
    </revision>
  </page>
  <page>
    <title>Algebraic representation</title>
    <ns>0</ns>
    <id>56608952</id>
    <revision>
      <id>848898373</id>
      <parentid>848898332</parentid>
      <timestamp>2018-07-05T03:18:36Z</timestamp>
      <contributor>
        <username>Deville</username>
        <id>364144</id>
      </contributor>
      <comment>removed [[Category:Scheme theory]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1096">{{distinguish|algebra representation}}

In mathematics, an '''algebraic representation''' of a [[group (mathematics)|group]] ''G'' on a [[algebra over a field|''k''-algebra]] ''A'' is a [[linear representation]] &lt;math&gt;\pi: G \to GL(A)&lt;/math&gt; such that, for each ''g'' in ''G'',  &lt;math&gt;\pi(g)&lt;/math&gt; is an [[algebra automorphism]]. Equipped with such a representation, the algebra ''A'' is then called a '''''G''-algebra'''.

For example, if ''V'' is a linear representation of a group ''G'', then the [[tensor product of representations|representation put on]] the [[tensor algebra]] &lt;math&gt;T(A)&lt;/math&gt; is an algebraic represention of ''G''.

If ''A'' is a commutative ''G''-algebra, then &lt;math&gt;\operatorname{Spec}(A)&lt;/math&gt; is an [[affine scheme|affine]] [[group-scheme action|''G''-scheme]].

== References ==
*[[Claudio Procesi]] (2007) ''Lie Groups: an approach through invariants and representation'', Springer, {{isbn|9780387260402}}.&lt;!-- this is probably not the best reference but something for a moment. --&gt;


{{algebra-stub}}



[[Category:Lie groups]]
[[Category:Representation theory]]</text>
      <sha1>axyeply2nyymd3u1j2g9de31g5gr4v2</sha1>
    </revision>
  </page>
  <page>
    <title>Anonymous matching</title>
    <ns>0</ns>
    <id>2791110</id>
    <revision>
      <id>866441051</id>
      <parentid>866440999</parentid>
      <timestamp>2018-10-30T10:42:38Z</timestamp>
      <contributor>
        <username>Onel5969</username>
        <id>10951369</id>
      </contributor>
      <comment>Adding [[Wikipedia:Short description|short description]]: "Matchmaking method" ([[User:Galobtter/Shortdesc helper|Shortdesc helper]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7752">{{short description|Matchmaking method}}
'''Anonymous matching''' is a [[matchmaking]] method facilitated by computer databases, in which each user confidentially selects people they are interested in dating and the computer identifies and reports matches to pairs of users who share a mutual attraction.  Protocols for anonymous matchmaking date back to the 1980s, and one of the earliest papers on the topic is by Baldwin and Gramlich, published in 1985.  From a technical perspective, the problem and solution are trivial and likely predate even this paper. The problem becomes interesting and requires more sophisticated cryptography when the matchmaker (central server) isn't trusted.

The purpose of the protocol is to allow people to initiate [[romantic relationship]]s while avoiding the risk of [[embarrassment]], awkwardness, and other negative consequences associated with unwanted romantic overtures and [[unrequited love|rejection]]. The general concept was patented on September 7, 1999 by David J. Blumberg and [[DoYouDo]] [[chief executive officer]] Gil S. Sudai, but several websites were already employing the methodology by that date, and thus apparently were allowed to continue using it.&lt;ref&gt;{{cite web|url=http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2Fsearch-adv.htm&amp;r=54&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=matchmaking&amp;p=2&amp;OS=matchmaking&amp;RS=matchmaking|archiveurl=https://archive.today/20121214102112/http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2Fsearch-adv.htm&amp;r=54&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=matchmaking&amp;p=2&amp;OS=matchmaking&amp;RS=matchmaking|deadurl=yes|title=United States Patent: 8219498|date=14 December 2012|archivedate=14 December 2012|publisher=}}&lt;/ref&gt; United States Patent 5,950,200 points out several potential flaws in traditional [[courtship]] and in conventional [[Matchmaking systems and services|dating systems]] in which strangers meet online, promoting anonymous matching of [[friendship|friend]]s and [[acquaintance]]s as a better alternative:
{{cquote|Human relationships are often fraught with difficulties. In addition, human beings are risk-averse. Often, even when two people want to initiate first steps in a relationship, neither person takes action because of [[shyness]], fear of rejection, or other societal pressures or constraints. Various systems exist that help people meet each other. For example, [[computer dating service]]s allow people to view video tapes or pictures of prospective partners or to choose common areas of hobbies. Two people are introduced only if both agree with the idea. Unfortunately, in such situations, neither person has actually met the other when they are finally introduced. Neither person has ever met the other, and there is a certain amount of shyness and fear of rejection when they first meet in such a situation. In addition, both persons must initially approach the dating service. For some people, such an action can also be embarrassing. What is needed is a safe, simple, confidential, and non-judgmental way for people to reveal their true feelings and interests without risk of embarrassment or rejection.}}

==Implementations==
{{example farm|date=September 2018}}
Some of the most notable implementations of the idea have been:
*'''Baldwin and Gramlich''', as cited above.
*'''[[eCRUSH]]'''. launched Valentine's Day, 1999, is the most successful implementation of the concept. Targeted to the teen market, it has more than 1.6 million users and claims more than 600,000 legitimate matches [http://www.ecrush.com/faq.phtml?sess_sid=&amp;cobrand=].
*'''DoYOU2.com'''. The website's owner, [[DoYouDo|DoYouDo, Inc.]], was incorporated 23 September 1999 and acquired by [[MatchNet]] in September 2000 in exchange for stock valued at $1,820,000. According to MatchNet's 2003 annual report, "The acquisition was made primarily for the purpose of acquiring the patent on this business model for future development."
*'''The LiveJournal Secret Crush meme'''. In mid-2003, a company named Anonymous Consulting created an online quiz called "Secret Crush Meme,"[https://web.archive.org/web/20051026032929/http://euthanize.us/memes/secret-crush-meme/] which would provide each user with a chart showing who on their LiveJournal friends list had a crush on them, as well as what "kind" of crush they had (public, secret or ex). The quiz was designed to harvest crushes between [[LiveJournal]] users (hence the elaborate disclaimer). In October 2003, a new quiz, called "Secret Crush Meme 2: The Revenge of Secret Crush Meme," was released [https://web.archive.org/web/20051026025856/http://www.euthanize.us/memes/crushmeme/], which showed users how many crushes other users had on them, as well as what kind. There was a catch: For four dollars, the company would tell someone who had crushes on them. This created controversy between couples who listed other users as crushes as well as people getting ex-crushes when they felt they should have gotten public crushes, and much ethics debating. Finally a small PERL script was written and distributed to poison the database. Faced with attempts to poison the database from many different IP addresses, the project was shut down.
*'''SecretAdmirer.com'''. This service claims 100,000 successful matches [https://web.archive.org/web/20051001034946/http://www.secretadmirer.com/]. Salon.com called SecretAdmirer.com "the grandfather of the concept, launched in 1997."  [https://web.archive.org/web/20110606185121/http://dir.salon.com/story/tech/feature/2002/08/07/crushmaster/print.html?pn=2] Its methodology is different from the others in that in order for a match to occur, the recipient must send emails out, rather than simply place names on a confidential list.

These commercial implementations all trust the central server, simplifying the solution and implementation drastically. Baldwin and Gramlich solved this case in 1985, as well as the more notable and challenging case in which the central server isn't trusted.

==Viral marketing==
eCRUSH, DoYOU2.com, the LiveJournal Secret Crush meme, and SecretAdmirer.com are examples of anonymous matching services using [[viral marketing]] to increase their membership. Users are encouraged to send an anonymous email to their crush so that they will visit the site and enter their own crushes, facilitating a match. In the case of SecretAdmirer.com, the email is mandatory; this represents a more aggressive type of viral marketing.

At least one site, CrushLink, was accused by eCRUSH of sending spam emails disguised as crush notifications. According to a Salon article, "What makes SomeoneLikesYou and Crushlink different from the rest of the sites in the genre is this: they bait hopeful visitors to hand over as many e-mail addresses as possible by trading clues for e-mail addresses"[https://web.archive.org/web/20051027044313/http://www.salon.com/tech/feature/2002/08/07/crushmaster/print.html]. Both sites are now defunct.

==References==
{{reflist}}
* R.W. Baldwin and W.C. Gramlich, Cryptographic Protocol for Trustable Match Making, IEEE Security and Privacy, 1985.
*Lester, Amelia A. and Borja, Anais A.: [http://thecrimson.harvard.edu/article.aspx?ref=121750 The Rise and Success of Sparknotes], [[The Harvard Crimson]], 18 October 2001.
*Mieszkowski, Katharine: [https://web.archive.org/web/20051027044313/http://www.salon.com/tech/feature/2002/08/07/crushmaster/print.html The bot who loved me], 7 August 2002.
*[https://patents.google.com/patent/US5950200A/en United States Patent 5,950,200: Method and apparatus for detection of reciprocal interests or feelings and subsequent notification], United States Patent and Trademark Office, 7 September 1999.

[[Category:Matchmaking]]
[[Category:Cryptography]]</text>
      <sha1>b1h9lnhwufbk3lwzj8gzdncg407dosv</sha1>
    </revision>
  </page>
  <page>
    <title>Berkeley Madonna</title>
    <ns>0</ns>
    <id>44127276</id>
    <revision>
      <id>846301953</id>
      <parentid>839999813</parentid>
      <timestamp>2018-06-17T20:49:40Z</timestamp>
      <contributor>
        <ip>83.84.6.183</ip>
      </contributor>
      <comment>Newest release</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5788">{{Infobox Software
| name                   = Berkeley Madonna
| logo                   =
| caption                =
| collapsible            = 
| author                 = Robert Macey and George Oster
| developer              = 
| released               = 
| latest release version = Version 9.1.3
| latest release date    = 2018-05-10
| latest preview version = 
| latest preview date    = 
| programming language   = C, Java
| operating system       = Windows, MacOS
| platform               = PC, Macintosh
| size                   = 
| language               = 
| status                 = 
| genre                  = [[Mathematical software]]
| license                = [[Proprietary software|Proprietary]]
| website                = {{url|http://www.berkeleymadonna.com}}
}}

'''Berkeley Madonna''' is a mathematical modelling software package, developed at the [[University of California at Berkeley]] by [[Robert Macey]] and [[George Oster]].  It numerically solves [[ordinary differential equations]] and [[difference equations]], originally developed to execute [[STELLA (programming language)|STELLA]] programs.&lt;ref&gt;Macey, Robert; Oster. George; Zahnley, Tim (December 28, 2009). [http://www.berkeleymadonna.com/BM%20User%27s%20Guide%208.0.2.pdf Berkeley Madonna User’s Guide] University of California. Department of Molecular and Cellular Biology. Berkeley, California.&lt;/ref&gt;

Berkeley Madonna is arguably the fastest differential equation solver, originally developed for modeling and visualization of chemical reactions.&lt;ref&gt;{{cite book|last1=Dunn|first1=IJ|last2=Heinzle|first2=E|last3=Ingham|first3=J|last4=Přenosil|first4=JE|title=Biological Reaction Engineering: Dynamic Modelling Fundamentals with Simulation Examples|publisher=Wiley-VCH Verlag GmbH &amp; Co. KGaA|year=2000|edition=2|isbn=9783527307593|doi=10.1002/3527603050}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Robeva|first1=RS|last2=Kirkwood|first2=JR|last3=Davies|first3=RL|title=Laboratory Manual of Biomathematics|publisher=Academic Press|year=2008|url=https://books.google.com/books?id=ggECaSl_GgEC&amp;pg=PA3|isbn=9780123740229|pages=3–17}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Ingham|first1=J|last2=Dunn|first2=IJ|last3=Heinzle|first3=E|last4=Přenosil|first4=JE|title=Chemical Engineering Dynamics: Modelling with PC Simulation|publisher=John Wiley &amp; Sons|year=2008}}&lt;/ref&gt;

Its strength lies in a relatively simple syntax to define differential equations coupled with a simple yet powerful user interface. In particular, Berkeley Madonna provides the facility of putting parameters onto a slider that can in turn be moved by a user to change the value. Such visualizations enable quick assessments of whether or not a particular model class is suitable to describe the data to be analyzed and modeled, and, later, communicating models easily to other disciplines such as medical decision makers.

==Uses==
It has become a standard in the development and communication of pharmacometric models describing drug concentration and its effects in drug development
,&lt;ref&gt;{{cite journal|last1=Krause|first1=A|last2=Lowe|first2=PJ|title=Visualization and Communication of Pharmacometric Models With Berkeley Madonna|journal=CPT Pharmacometrics Syst. Pharmacol.|date=2014-05-28|volume=3|page=113|doi=10.1038/psp.2014.13|url=http://onlinelibrary.wiley.com/doi/10.1038/psp.2014.13/full}} pp. 1-20.&lt;/ref&gt; modeling of physiological processes.&lt;ref&gt;{{cite journal|last1=Zhong|first1=H.|last2=Wade|first2=S.M.|last3=Woolf|first3=P.J.|last4=Linderman|first4=J.J.|last5=Traynor|first5=J.R.|last6=Neubig|first6=R.R.|title=REGULATOR OF G PROTEIN SIGNALING (RGS) PROTEIN-MEDIATED KINETIC SCAFFOLDING|journal=Journal of Biological Chemistry|date=2003|volume=278|issue=9|pages=7278–7284|doi=10.1074/jbc.m208819200}}&lt;/ref&gt; 
A user community exists in the form of a LinkedIn user group&lt;ref name=LinkedIn_group&gt;{{cite web |url=https://www.linkedin.com/groups/1781966 |title=LinkedIn group Berkeley Madonna|publisher=LinkedIn.com|accessdate=November 17, 2015}}&lt;/ref&gt; with currently more than 500 members.

The use of [[system dynamics]] modeling has expanded into other areas such as epidemiology,&lt;ref&gt;{{cite book|last1=Vinnycky|first1=Emilia|last2=White|first2=Richard|title=An introduction to infectious disease modelling|date=2010-05-13|publisher=Oxford University Press|isbn=978-0-19-856576-5}}&lt;/ref&gt; environmental health,&lt;ref&gt;{{cite book|last1=Robson|first1=MG|last2=Toscano|first2=WA|title=Risk Assessment for Environmental Health|year=2007|publisher=John Wiley &amp; Sons|isbn=9780787988593}}&lt;/ref&gt; and population ecology.&lt;ref&gt;{{cite journal|title=System dynamics modelling of the Endangered African penguin populations on Dyer and Robben islands, South Africa|first1=Florian|last1=Weller|first2=Richard B.|last2=Sherley|first3=Lauren J.|last3=Waller|first4=Katrin|last4=Ludynia|first5=Deon|last5=Geldenhuys|first6=Lynne J.|last6=Shannon|first7=Astrid|last7=Jarre|journal=Ecological Modelling|volume=327|year=2016|pages=44–56|doi=10.1016/j.ecolmodel.2016.01.011}}&lt;/ref&gt;

==Versions==
There are two versions of Berkeley Madonna: a free version with slightly limited functionality and a licensed version that is registered to individuals.

==References==
{{reflist}}

==Further reading==
* [http://www.naun.org/main/NAUN/ijmmas/mmmas-119.pdf "A System Dynamics Model For The Simulation Of A Non Multi Echelon Supply Chain: Analysis and Optimization Utilizing The Berkeley Madonna Software"] pp.&amp;nbsp;503–512
* [http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=4352357&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D4352357 "Berkeley-Madonna Implementation of Ikeda's Model"]. pp.&amp;nbsp;582–585. {{paywall}}

==External links==
* {{official website|http://www.berkeleymadonna.com}}

[[Category:Mathematical software]]</text>
      <sha1>hrfrtf74nj0kxe9xtwycb6hljl5ii3u</sha1>
    </revision>
  </page>
  <page>
    <title>Blumenthal Award</title>
    <ns>0</ns>
    <id>34421338</id>
    <revision>
      <id>784122193</id>
      <parentid>738904724</parentid>
      <timestamp>2017-06-06T15:49:40Z</timestamp>
      <contributor>
        <username>GoodDay</username>
        <id>589223</id>
      </contributor>
      <comment>Reduce whitespace</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1046">The '''Blumenthal Award''' was founded by the [[American Mathematical Society]] in 1993 in memory of [[Leonard Blumenthal|Leonard M.]] and [[Eleanor B. Blumenthal]]. 
The award was presented to the individual deemed to have made the most substantial contribution in research in the field of pure mathematics, and who was deemed to have the potential for future production of distinguished research in such field. It was awarded every four years for the most substantial Ph.D. thesis produced in the four year interval between awards. The fund that supported the award was discontinued and, thus, the award is no longer being made.

==Winners==
*1993 – [[Zhihong Xia]]
*1997 – [[Loïc Merel]]
*2001 – [[Stephen Bigelow]] and [[Elon Lindenstrauss]]
*2005 – [[Manjul Bhargava]]
*2009 – [[Maryam Mirzakhani]]

==External links==
*[http://www.ams.org/profession/prizes-awards/ams-supported/blumenthal-award Blumenthal Award at AMS website]

[[Category:Mathematics awards]]
[[Category:American awards]]
[[Category:Awards established in 1993]]</text>
      <sha1>6yyuvw7nnn1msfwumk5vhsvmucfv8v5</sha1>
    </revision>
  </page>
  <page>
    <title>Bochner measurable function</title>
    <ns>0</ns>
    <id>27908226</id>
    <revision>
      <id>835985836</id>
      <parentid>769542740</parentid>
      <timestamp>2018-04-12T00:04:30Z</timestamp>
      <contributor>
        <username>Undsoweiter</username>
        <id>8967780</id>
      </contributor>
      <minor/>
      <comment>/* Properties */ added link to Wikipedia page on Borel algebras</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2576">In [[mathematics]] &amp;ndash; specifically, in [[functional analysis]] &amp;ndash; a '''Bochner-measurable function''' taking values in a [[Banach space]] is a [[function (mathematics)|function]] that equals a.e. the limit of a sequence of measurable [[countably-valued function]]s, i.e.,

:&lt;math&gt;f(t) = \lim_{n\rightarrow\infty}f_n(t)\text{ for almost every }t, \, &lt;/math&gt;

where the functions &lt;math&gt;f_n&lt;/math&gt; each have a countable range and for which the pre-image &lt;math&gt;f^{-1}\{x\}&lt;/math&gt; is measurable for each&amp;nbsp;''x''.  The concept is named after [[Salomon Bochner]].

Bochner-measurable functions are sometimes called '''[[strongly measurable]]''', '''&lt;math&gt;\mu&lt;/math&gt;-measurable''' or just '''measurable''' (or '''[[uniformly measurable]]''' in case that the Banach space is the space of continuous [[linear operator]]s between Banach spaces).

==Properties==

The relationship between measurability and weak measurability is given by the following result, known as '''[[B. J. Pettis|Pettis]]' theorem''' or '''Pettis measurability theorem'''.

&lt;blockquote&gt;
Function ''f'' is '''[[almost surely]] separably valued''' (or '''essentially separably valued''') if there exists a subset ''N''&amp;nbsp;&amp;sube;&amp;nbsp;''X'' with ''&amp;mu;''(''N'')&amp;nbsp;=&amp;nbsp;0 such that ''f''(''X''&amp;nbsp;\&amp;nbsp;''N'')&amp;nbsp;&amp;sube;&amp;nbsp;''B'' is separable.
&lt;/blockquote&gt;

&lt;blockquote&gt;
A function f &amp;nbsp;:&amp;nbsp;''X''&amp;nbsp;&amp;rarr;&amp;nbsp;''B'' defined on a [[measure space]] (''X'',&amp;nbsp;&amp;Sigma;,&amp;nbsp;''&amp;mu;'') and taking values in a Banach space ''B'' is (strongly) measurable (with respect to &amp;Sigma; and the [[Borel algebra]] on ''B'') [[if and only if]] it is both weakly measurable and almost surely separably valued. 
&lt;/blockquote&gt;

In the case that ''B'' is separable, since any subset of a separable Banach space is itself separable, one can take ''N'' above to be empty, and it follows that the notions of weak and strong measurability agree when ''B'' is separable.

==See also==
* [[Bochner integral]]
* [[Pettis integral]]
* [[Bochner space]]
* [[Measurable space]]
* [[Vector-valued measure]]
* [[Measurable function]]

==References==

* {{cite book
| last = Showalter
| first = Ralph E.
| title = Monotone operators in Banach space and nonlinear partial differential equations
| series = Mathematical Surveys and Monographs 49
| publisher = American Mathematical Society
| location = Providence, RI
| year = 1997
| page = 103
| isbn = 0-8218-0500-2
| mr = 1422252 
| contribution = Theorem III.1.1}}.

[[Category:Functional analysis]]
[[Category:Measure theory]]
[[Category:Types of functions]]</text>
      <sha1>cfgnjaz933i3ve49zjk9zn02nlwrejn</sha1>
    </revision>
  </page>
  <page>
    <title>Carmichael number</title>
    <ns>0</ns>
    <id>7723</id>
    <revision>
      <id>871143172</id>
      <parentid>871130134</parentid>
      <timestamp>2018-11-29T05:55:44Z</timestamp>
      <contributor>
        <username>Anita5192</username>
        <id>13220696</id>
      </contributor>
      <comment>Undid revision 871130134 by [[Special:Contributions/129.97.125.1|129.97.125.1]] ([[User talk:129.97.125.1|talk]])Reverted unexplained edit.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21318">In [[number theory]], a '''Carmichael number''' is a [[composite number]] &lt;math&gt;n&lt;/math&gt; which satisfies the [[modular arithmetic]] congruence relation:
:&lt;math&gt;b^{n-1}\equiv 1\pmod{n}&lt;/math&gt;
for all integers &lt;math&gt;b&lt;/math&gt; which are [[relatively prime]] to &lt;math&gt;n&lt;/math&gt;.
&lt;ref&gt;{{cite book | last=Riesel | first=Hans | title=Prime Numbers and Computer Methods for Factorization 
| publisher=Birkhäuser | location=Boston, MA | edition=second | year=1994 | isbn=0-8176-3743-5 
| zbl=0821.11001 | series=Progress in Mathematics | volume=126 |author-link=Hans Riesel }}&lt;/ref&gt;
They are named for [[Robert Daniel Carmichael|Robert Carmichael]].
The Carmichael numbers are the subset ''K''&lt;sub&gt;1&lt;/sub&gt; of the [[Knödel number]]s.

Equivalently, a Carmichael number is a composite number &lt;math&gt;n&lt;/math&gt; for which
:&lt;math&gt;b^n\equiv b\pmod{n}&lt;/math&gt;
for all integers &lt;math&gt;b&lt;/math&gt;.
&lt;ref&gt;{{cite book |last1=Crandall|first1=Richard |last2=Pomerance |first2=Carl |date=2005 |title=Prime Numbers: A Computational Perspective |edition=second |location=New York |publisher=Springer |page=133 |isbn=978-0387-25282-7 |author-link1=Richard Crandall |author-link2=Carl Pomerance }}&lt;/ref&gt;

==Overview==
[[Fermat's little theorem]] states that if ''p'' is a [[prime number]], then for any [[integer]] ''b'', the number ''b''&lt;sup&gt;&amp;nbsp;''p''&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;''b'' is an integer multiple of ''p''.  Carmichael numbers are composite numbers which have this property.  Carmichael numbers are also called [[Fermat pseudoprime]]s or '''absolute Fermat pseudoprimes'''. A Carmichael number will pass a [[Fermat primality test]] to every base ''b'' relatively prime to the number, even though it is not actually prime.
This makes tests based on Fermat's Little Theorem less effective than [[strong pseudoprime|strong probable prime]] tests such as the [[Baillie-PSW primality test]] and the [[Miller–Rabin primality test]].

However, no Carmichael number is either an [[Euler pseudoprime|Euler-Jacobi pseudoprime]] or a [[strong pseudoprime]] to every base relatively prime to it
&lt;ref&gt;{{cite journal |author=D. H. Lehmer |author-link=Derrick Henry Lehmer |title=Strong Carmichael numbers |journal=J. Austral. Math. Soc. |date=1976 |volume=21 |pages=508–510 |url=http://journals.cambridge.org/article_S1446788700019364 |doi=10.1017/s1446788700019364}} Lehmer proved that no Carmichael number is an Euler-Jacobi pseudoprime to every base relatively prime to it. He used the term ''strong pseudoprime'', but the terminology has changed since then. Strong pseudoprimes are a subset of Euler-Jacobi pseudoprimes. Therefore, no Carmichael number is a strong pseudoprime to every base relatively prime to it.&lt;/ref&gt;
so, in theory, either an Euler or a strong probable prime test could prove that a Carmichael number is, in fact, composite.

As numbers become larger, Carmichael numbers become increasingly rare. For example, there are 20,138,200 Carmichael numbers between 1 and 10&lt;sup&gt;21&lt;/sup&gt; (approximately one in 50 trillion (5·10&lt;sup&gt;13&lt;/sup&gt;) numbers).&lt;ref name="Pinch2007"&gt;
{{cite conference |url=http://tucs.fi/publications/attachment.php?fname=G46.pdf
 |title=The Carmichael numbers up to 10&lt;sup&gt;21&lt;/sup&gt; |last=Pinch |first=Richard |date=December 2007
 |editor=Anne-Maria Ernvall-Hytönen |volume=46
 |publisher=Turku Centre for Computer Science |pages=129–131 |location=Turku, Finland
 |conference=Proceedings of Conference on Algorithmic Number Theory
 |access-date=2017-06-26}}&lt;/ref&gt;

===Korselt's criterion===
An alternative and equivalent definition of Carmichael numbers is given by '''Korselt's criterion'''.

:'''Theorem''' ([[Alwin Korselt|A. Korselt]] 1899): A positive composite integer &lt;math&gt;n&lt;/math&gt; is a Carmichael number if and only if &lt;math&gt;n&lt;/math&gt; is [[square-free integer|square-free]], and for all [[prime divisor]]s &lt;math&gt;p&lt;/math&gt; of &lt;math&gt;n&lt;/math&gt;, it is true that &lt;math&gt;p - 1 \mid n - 1&lt;/math&gt;.

It follows from this theorem that all Carmichael numbers are [[odd number|odd]], since any even composite number that is square-free (and hence has only one prime factor of two) will have at least one odd prime factor, and thus &lt;math&gt;p - 1  \mid n - 1&lt;/math&gt; results in an even dividing an odd, a contradiction. (The oddness of Carmichael numbers also follows from the fact that &lt;math&gt;-1&lt;/math&gt; is a [[Fermat primality test|Fermat witness]] for any even composite number.)
From the criterion it also follows that Carmichael numbers are [[Cyclic number (group theory)|cyclic]].&lt;ref&gt;[http://www.numericana.com/data/crump.htm Carmichael Multiples of Odd Cyclic Numbers] "Any divisor of a Carmichael number must be an odd cyclic number"&lt;/ref&gt;&lt;ref&gt;Proof sketch: If &lt;math&gt;n&lt;/math&gt; is square-free but not cyclic, &lt;math&gt;p_i \mid p_j - 1&lt;/math&gt; for two prime factors &lt;math&gt;p_i&lt;/math&gt; and &lt;math&gt;p_j&lt;/math&gt; of &lt;math&gt;n&lt;/math&gt;. But if &lt;math&gt;n&lt;/math&gt; satisfies Korselt then &lt;math&gt;p_j - 1  \mid n - 1&lt;/math&gt;, so by transitivity of the "divides" relation &lt;math&gt;p_i  \mid n - 1&lt;/math&gt;. But &lt;math&gt;p_i&lt;/math&gt; is also a factor of &lt;math&gt;n&lt;/math&gt;, a contradiction.&lt;/ref&gt; Additionally, it follows that there are no Carmichael numbers with exactly two prime factors.

==Discovery==
Korselt was the first who observed the basic properties of Carmichael numbers, but he did not give any examples. In 1910, Carmichael&lt;ref name="Carmichael1910"&gt;{{cite journal |author=R. D. Carmichael|title=Note on a new number theory function |journal=Bulletin of the American Mathematical Society |volume=16 |issue=5|year=1910 |pages=232–238 |url=http://www.ams.org/journals/bull/1910-16-05/home.html |doi=10.1090/s0002-9904-1910-01892-9}}&lt;/ref&gt; found the first and smallest such number, 561, which explains the name "Carmichael number".

That 561 is a Carmichael number can be seen with Korselt's criterion. Indeed, &lt;math&gt;561 = 3 \cdot 11 \cdot 17&lt;/math&gt; is square-free and &lt;math&gt;2 \mid 560&lt;/math&gt;, &lt;math&gt;10 \mid 560&lt;/math&gt; and &lt;math&gt;16 \mid 560&lt;/math&gt;.

The next six Carmichael numbers are {{OEIS|id=A002997}}:
:&lt;math&gt;1105 = 5 \cdot 13 \cdot 17 \qquad (4 \mid 1104;\quad 12 \mid 1104;\quad 16 \mid 1104)&lt;/math&gt;
:&lt;math&gt;1729 = 7 \cdot 13 \cdot 19 \qquad (6 \mid 1728;\quad 12 \mid 1728;\quad 18 \mid 1728)&lt;/math&gt;
:&lt;math&gt;2465 = 5 \cdot 17 \cdot 29 \qquad (4 \mid 2464;\quad 16 \mid 2464;\quad 28 \mid 2464)&lt;/math&gt;
:&lt;math&gt;2821 = 7 \cdot 13 \cdot 31 \qquad (6 \mid 2820;\quad 12 \mid 2820;\quad 30 \mid 2820)&lt;/math&gt;
:&lt;math&gt;6601 = 7 \cdot 23 \cdot 41 \qquad (6 \mid 6600;\quad 22 \mid 6600;\quad 40 \mid 6600)&lt;/math&gt;
:&lt;math&gt;8911 = 7 \cdot 19 \cdot 67 \qquad (6 \mid 8910;\quad 18 \mid 8910;\quad 66 \mid 8910).&lt;/math&gt;

These first seven Carmichael numbers, from 561 to 8911, were all found by the Czech mathematician Václav Šimerka in 1885&lt;ref name="Simerka1885"&gt;{{cite journal |author=V. Šimerka|title=Zbytky z arithmetické posloupnosti (On the remainders of an arithmetic progression) |journal=Časopis pro pěstování matematiky a fysiky |volume=14 |issue=5|year=1885 |pages=221–225 |url=http://dml.cz/handle/10338.dmlcz/122245}}&lt;/ref&gt; (thus preceding not just Carmichael but also Korselt, although Šimerka did not find anything like Korselt's criterion).&lt;ref&gt;{{cite journal |last1=Lemmermeyer |first1=F. |title=Václav Šimerka: quadratic forms and factorization |journal=LMS Journal of Computation and Mathematics |date=2013 |volume=16 |pages=118–129 |doi=10.1112/S1461157013000065 |doi-access=free}}&lt;/ref&gt; His work, however, remained unnoticed.

J. Chernick&lt;ref name="Chernick1939"&gt;{{cite journal |author=Chernick, J. |title=On Fermat's simple theorem |journal=Bull. Amer. Math. Soc. |volume=45 |year=1939 |pages=269–274 |doi=10.1090/S0002-9904-1939-06953-X  |url=http://www.ams.org/journals/bull/1939-45-04/S0002-9904-1939-06953-X/S0002-9904-1939-06953-X.pdf}}&lt;/ref&gt; proved a theorem in 1939 which can be used to construct a [[subset]] of Carmichael numbers. The number &lt;math&gt;(6k + 1)(12k + 1)(18k + 1)&lt;/math&gt; is a Carmichael number if its three factors are all prime. Whether this formula produces an infinite quantity of Carmichael numbers is an open question (though it is implied by [[Dickson's conjecture]]).

[[Paul Erdős]] heuristically argued there should be infinitely many Carmichael numbers. In 1994 [[W. R. (Red) Alford]], [[Andrew Granville]] and [[Carl Pomerance]]  used a bound on [[Olson's constant]] to show that there really do exist infinitely many Carmichael numbers. Specifically, they showed that for sufficiently large &lt;math&gt;n&lt;/math&gt;, there are at least &lt;math&gt;n^{2/7}&lt;/math&gt; Carmichael numbers between 1 and &lt;math&gt;n&lt;/math&gt;.&lt;ref name="Alford1994"&gt;{{cite journal |author=[[W. R. (Red) Alford|W. R. Alford]] |author2=[[Andrew Granville]] |author3=[[Carl Pomerance]] |title=There are Infinitely Many Carmichael Numbers |journal=[[Annals of Mathematics]] |volume=139 |year=1994 |pages=703–722 |doi=10.2307/2118576 |url=http://www.math.dartmouth.edu/~carlp/PDF/paper95.pdf}}&lt;/ref&gt;

Löh and Niebuhr in 1992 found some very large Carmichael numbers, including one with 1,101,518 factors and over 16 million digits.

==Properties==

=== Factorizations ===
Carmichael numbers have at least three positive prime factors. For some fixed ''R'', there are infinitely many Carmichael numbers with exactly ''R'' factors; in fact, there are infinitely many such R.&lt;ref&gt;{{cite journal |last=Wright |first=Thomas|date=2016-06-01 |title=Factors of Carmichael numbers and a weak k-tuples conjecture |url=http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=10298704 |journal=[[Journal of the Australian Mathematical Society]] |publisher=Australian Mathematical Publishing Association Inc. |volume=100 |issue=3 |pages=421–429 |doi=10.1017/S1446788715000427|access-date=2016-08-13}}&lt;/ref&gt;

The first Carmichael numbers with &lt;math&gt;k = 3, 4, 5, \ldots&lt;/math&gt; prime factors are {{OEIS|id=A006931}}:

{| class="wikitable"
|-
!''k'' !!&amp;nbsp;
|-
| 3 || &lt;math&gt;561 = 3 \cdot 11 \cdot 17\,&lt;/math&gt;
|-
| 4 || &lt;math&gt;41041 = 7 \cdot 11 \cdot 13 \cdot 41\,&lt;/math&gt;
|-
| 5 || &lt;math&gt;825265 = 5 \cdot 7 \cdot 17 \cdot 19 \cdot 73\,&lt;/math&gt;
|-
| 6 || &lt;math&gt;321197185 = 5 \cdot 19 \cdot 23 \cdot 29 \cdot 37 \cdot 137\,&lt;/math&gt;
|-
| 7 || &lt;math&gt;5394826801 = 7 \cdot 13 \cdot 17 \cdot 23 \cdot 31 \cdot 67 \cdot 73\,&lt;/math&gt;
|-
| 8 || &lt;math&gt;232250619601 = 7 \cdot 11 \cdot 13 \cdot 17 \cdot 31 \cdot 37 \cdot 73 \cdot 163\,&lt;/math&gt;
|-
| 9 || &lt;math&gt;9746347772161 = 7 \cdot 11 \cdot 13 \cdot 17 \cdot 19 \cdot 31 \cdot 37 \cdot 41 \cdot 641\,&lt;/math&gt;
|}

The first Carmichael numbers with 4 prime factors are {{OEIS|id=A074379}}:

{| class="wikitable"
|-
!''i'' !!&amp;nbsp;
|-
| 1 || &lt;math&gt;41041 = 7 \cdot 11 \cdot 13 \cdot 41\,&lt;/math&gt;
|-
| 2 || &lt;math&gt;62745 = 3 \cdot 5 \cdot 47 \cdot 89\,&lt;/math&gt;
|-
| 3 || &lt;math&gt;63973 = 7 \cdot 13 \cdot 19 \cdot 37\,&lt;/math&gt;
|-
| 4 || &lt;math&gt;75361 = 11 \cdot 13 \cdot 17 \cdot 31\,&lt;/math&gt;
|-
| 5 || &lt;math&gt;101101 = 7 \cdot 11 \cdot 13 \cdot 101\,&lt;/math&gt;
|-
| 6 || &lt;math&gt;126217 = 7 \cdot 13 \cdot 19 \cdot 73\,&lt;/math&gt;
|-
| 7 || &lt;math&gt;172081 = 7 \cdot 13 \cdot 31 \cdot 61\,&lt;/math&gt;
|-
| 8 || &lt;math&gt;188461 = 7 \cdot 13 \cdot 19 \cdot 109\,&lt;/math&gt;
|-
| 9 || &lt;math&gt;278545 = 5 \cdot 17 \cdot 29 \cdot 113\,&lt;/math&gt;
|-
| 10 || &lt;math&gt;340561 = 13 \cdot 17 \cdot 23 \cdot 67\,&lt;/math&gt;
|}

The second Carmichael number (1105) can be expressed as the sum of two squares in more ways than any smaller number. The third Carmichael number (1729) is the [[1729 (number)|Hardy-Ramanujan Number]]: the smallest number that can be expressed as the sum of two cubes (of positive numbers) in two different ways.

===Distribution===

Let &lt;math&gt;C(X)&lt;/math&gt; denote the number of Carmichael numbers less than or equal to &lt;math&gt;X&lt;/math&gt;. The distribution of Carmichael numbers by powers of 10 {{OEIS|id=A055553}}:&lt;ref name="Pinch2007"/&gt;

&lt;center&gt;
{| class="wikitable"
|-
! &lt;math&gt;n&lt;/math&gt;
| 1
| 2
| 3
| 4
| 5
| 6
| 7
| 8
| 9
| 10
| 11
| 12
| 13
| 14
| 15
| 16
|17
|18
|19
|20
|21
|-
! &lt;math&gt;C(10^n)&lt;/math&gt;
| 0
| 0
| 1
| 7
| 16
| 43
| 105
| 255
| 646
| 1547
| 3605
| 8241
| 19279
| 44706
| 105212
| 246683
|585355
|1401644
|3381806
|8220777
|20138200
|}
&lt;/center&gt;
In 1953, [[Walter Knödel|Knödel]] proved the [[Upper and lower bounds|upper bound]]:
:&lt;math&gt;C(X) &lt; X \exp\left({-k_1 \left( \log X \log \log X\right)^\frac{1}{2}}\right)&lt;/math&gt;

for some constant &lt;math&gt;k_1&lt;/math&gt;.

In 1956, Erdős improved the bound to&lt;ref name="Erdős1956"&gt;{{cite journal |author=[[Paul Erdős|Erdős, P.]] |year=1956 |title=On pseudoprimes and Carmichael numbers |journal=Publ. Math. Debrecen |volume=4 |pages=201–206 |url=http://www.renyi.hu/~p_erdos/1956-10.pdf |mr=79031 }}&lt;/ref&gt;

:&lt;math&gt;C(X) &lt; X \exp\left(\frac{-k_2 \log X \log \log \log X}{\log \log X}\right)&lt;/math&gt;

for some constant &lt;math&gt;k_2&lt;/math&gt;. He further gave a [[heuristic argument]] suggesting that this upper bound should be close to the true growth rate of &lt;math&gt;C(X)&lt;/math&gt;. The table below gives approximate minimal values for the constant ''k'' in the Erdős bound for &lt;math&gt;X=10^n&lt;/math&gt; as ''n'' grows:

&lt;center&gt;
{| class="wikitable"
|-
! &lt;math&gt;n&lt;/math&gt;
| 4
| 6
| 8
| 10
| 12
| 14
| 16
| 18
| 20
| 21
|-
! ''k''
| 2.19547
| 1.97946
| 1.90495
| 1.86870
| 1.86377
| 1.86293
| 1.86406
| 1.86522
| 1.86598
| 1.86619
|}
&lt;/center&gt;

In the other direction, [[W. R. (Red) Alford|Alford]], [[Andrew Granville|Granville]] and [[Carl Pomerance|Pomerance]] proved in 1994&lt;ref name="Alford1994"/&gt; that for sufficiently large ''X'',
:&lt;math&gt;C(X) &gt; X^\frac{2}{7}.&lt;/math&gt;

In 2005, this bound was further improved by [[Glyn Harman|Harman]]&lt;ref&gt;{{cite journal |author=Glyn Harman |title=On the number of Carmichael numbers up to ''x'' |journal=Bulletin of the London Mathematical Society |volume=37 |year=2005 |pages=641–650 |doi=10.1112/S0024609305004686}}&lt;/ref&gt; to
:&lt;math&gt;C(X) &gt; X^{0.332}&lt;/math&gt;

who subsequently improved the exponent to &lt;math&gt;0.7039 \cdot 0.4736 = 0.33336704 &gt; 1/3 &lt;/math&gt;.
&lt;ref&gt;{{cite journal |last=Harman |first=Glyn
 |date=2008 |title=Watt's mean value theorem and Carmichael numbers
 |doi=10.1142/S1793042108001316 |mr=2404800
 |journal=International Journal of Number Theory |volume=4 |issue=2 |pages=242, 243 }}&lt;/ref&gt;

Regarding the asymptotic distribution of Carmichael numbers, there have been several conjectures. In 1956, Erdős&lt;ref name="Erdős1956"/&gt; conjectured that there were &lt;math&gt;X^{1-o(1)}&lt;/math&gt; Carmichael numbers for ''X'' sufficiently large. In 1981, Pomerance&lt;ref name="Pomerance1981"&gt;{{cite journal |author=[[Carl Pomerance|Pomerance, C.]] |year=1981 |title=On the distribution of pseudoprimes |journal=Math. Comp. |volume=37 |pages=587–593|jstor=2007448 |doi=10.1090/s0025-5718-1981-0628717-0}}&lt;/ref&gt; sharpened Erdős' heuristic arguments to conjecture that there are

:&lt;math&gt;X^{1-{\frac{\{1+o(1)\}\log\log\log X}{\log\log X}}}&lt;/math&gt;

Carmichael numbers up to ''X''. However, inside current computational ranges (such as the counts of Carmichael numbers performed by Pinch&lt;ref name="Pinch2007"/&gt; up to 10&lt;sup&gt;21&lt;/sup&gt;), these conjectures are not yet borne out by the data.

==Generalizations==
The notion of Carmichael number generalizes to a Carmichael ideal in any number field ''K''. For any nonzero prime ideal &lt;math&gt;\mathfrak p&lt;/math&gt; in &lt;math&gt;{\mathcal O}_K&lt;/math&gt;, we have &lt;math&gt;\alpha^{{\rm N}(\mathfrak p)} \equiv \alpha \bmod {\mathfrak p}&lt;/math&gt; for all &lt;math&gt;\alpha&lt;/math&gt; in &lt;math&gt;{\mathcal O}_K&lt;/math&gt;, where &lt;math&gt;{\rm N}(\mathfrak p)&lt;/math&gt; is the norm of the ideal &lt;math&gt;\mathfrak p&lt;/math&gt;. (This generalizes Fermat's little theorem, that &lt;math&gt;m^p \equiv m \bmod p&lt;/math&gt; for all integers ''m'' when ''p'' is prime.) Call a nonzero ideal &lt;math&gt;\mathfrak a&lt;/math&gt; in &lt;math&gt;{\mathcal O}_K&lt;/math&gt; Carmichael if it is not a prime ideal and &lt;math&gt;\alpha^{{\rm N}(\mathfrak a)} \equiv \alpha \bmod {\mathfrak a}&lt;/math&gt; for all &lt;math&gt;\alpha \in {\mathcal O}_K&lt;/math&gt;, where &lt;math&gt;{\rm N}(\mathfrak a)&lt;/math&gt; is the norm of the ideal &lt;math&gt;\mathfrak a&lt;/math&gt;.  When ''K'' is &lt;math&gt;\mathbf Q&lt;/math&gt;, the ideal &lt;math&gt;\mathfrak a&lt;/math&gt; is principal, and if we let ''a'' be its positive generator then the ideal &lt;math&gt;\mathfrak a = (a)&lt;/math&gt; is Carmichael exactly when ''a'' is a Carmichael number in the usual sense.

When ''K'' is larger than the rationals it is easy to write down Carmichael ideals in &lt;math&gt;{\mathcal O}_K&lt;/math&gt;: for any prime number ''p'' that splits completely in ''K'', the principal ideal &lt;math&gt;p{\mathcal O}_K&lt;/math&gt; is a Carmichael ideal. Since infinitely many prime numbers split completely in any number field, there are infinitely many Carmichael ideals in &lt;math&gt;{\mathcal O}_K&lt;/math&gt;. For example, if ''p'' is any prime number that is 1 mod 4, the ideal (''p'') in the Gaussian integers '''Z'''[''i''] is a Carmichael ideal.

Both prime and Carmichael numbers satisfy the following equality:
:&lt;math&gt;\gcd \left(\sum_{x=1}^{n-1} x^{n-1}, n\right)=1&lt;/math&gt;

==Higher-order Carmichael numbers==
Carmichael numbers can be generalized using concepts of [[abstract algebra]].

The above definition states that a composite integer ''n'' is Carmichael
precisely when the ''n''th-power-raising function ''p''&lt;sub&gt;''n''&lt;/sub&gt; from the [[ring (mathematics)|ring]] '''Z'''&lt;sub&gt;''n''&lt;/sub&gt; of integers modulo ''n'' to itself is the identity function. The identity is the only '''Z'''&lt;sub&gt;''n''&lt;/sub&gt;-[[algebra over a field|algebra]] [[endomorphism]] on '''Z'''&lt;sub&gt;''n''&lt;/sub&gt; so we can restate the definition as asking that ''p''&lt;sub&gt;''n''&lt;/sub&gt; be an algebra endomorphism of '''Z'''&lt;sub&gt;''n''&lt;/sub&gt;.
As above, ''p''&lt;sub&gt;''n''&lt;/sub&gt; satisfies the same property whenever ''n'' is prime.

The ''n''th-power-raising function ''p''&lt;sub&gt;''n''&lt;/sub&gt; is also defined on any '''Z'''&lt;sub&gt;''n''&lt;/sub&gt;-algebra '''A'''. A theorem states that ''n'' is prime if and only if all such functions ''p''&lt;sub&gt;''n''&lt;/sub&gt; are algebra endomorphisms.

In-between these two conditions lies the definition of '''Carmichael number of order m''' for any positive integer ''m'' as any composite number ''n'' such that ''p''&lt;sub&gt;''n''&lt;/sub&gt; is an endomorphism on every '''Z'''&lt;sub&gt;''n''&lt;/sub&gt;-algebra that can be generated as '''Z'''&lt;sub&gt;''n''&lt;/sub&gt;-[[module (mathematics)|module]] by ''m'' elements. Carmichael numbers of order 1 are just the ordinary Carmichael numbers.

===An order 2 Carmichael number===
According to Howe, 17 · 31 · 41 · 43 · 89 · 97 · 167 · 331 is an order 2 Carmichael number. This product is equal to 443,372,888,629,441.&lt;ref&gt;{{cite journal |author = Everett W. Howe |title=Higher-order Carmichael numbers |journal=Mathematics of Computation |date=October 2000 |volume=69 |issue=232 |pages=1711–1719 |arxiv=math.NT/9812089 |jstor=2585091 |doi=10.1090/s0025-5718-00-01225-4}}&lt;/ref&gt;

===Properties===
Korselt's criterion can be generalized to higher-order Carmichael numbers, as shown by Howe.

A heuristic argument, given in the same paper, appears to suggest that there are infinitely many Carmichael numbers of order ''m'', for any ''m''. However, not a single Carmichael number of order 3 or above is known.

==Notes==
{{reflist|40em}}

==References==
*{{cite journal |author=Carmichael, R. D.|year=1910|title=Note on a new number theory function |journal=[[Bulletin of the American Mathematical Society]] |volume=16 |issue=5|pages=232–238 |url=http://www.ams.org/journals/bull/1910-16-05/home.html |doi=10.1090/s0002-9904-1910-01892-9}}
*{{cite journal |author=Carmichael, R. D. |year=1912 |title=On composite numbers ''P'' which satisfy the Fermat congruence &lt;math&gt;a^{P-1}\equiv 1\bmod P&lt;/math&gt; |journal=[[American Mathematical Monthly]] |volume=19 |issue=2 |pages=22–27 |doi=10.2307/2972687}}
*{{cite journal |author=Chernick, J. |year=1939 |title=On Fermat's simple theorem |journal=Bull. Amer. Math. Soc. |volume=45 |pages=269–274 |doi=10.1090/S0002-9904-1939-06953-X  |url=http://www.ams.org/journals/bull/1939-45-04/S0002-9904-1939-06953-X/S0002-9904-1939-06953-X.pdf}}
*{{cite journal |author=Korselt, A. R. |year=1899 |title=Problème chinois |journal=[[L'Intermédiaire des Mathématiciens]] |volume=6 |pages=142–143}}
*{{cite journal |author1=Löh, G. |author2=Niebuhr, W. |year=1996 |url=http://www.ams.org/mcom/1996-65-214/S0025-5718-96-00692-8/S0025-5718-96-00692-8.pdf |title=A new algorithm for constructing large Carmichael numbers |journal=Math. Comp. |volume=65 |pages=823–836 |doi=10.1090/S0025-5718-96-00692-8}}
*{{cite book | title = The Book of Prime Number Records | publisher = Springer | year = 1989 | isbn = 978-0-387-97042-4 | author = [[Paulo Ribenboim|Ribenboim, P.]] }}
*{{cite journal |author=Šimerka, V.|year=1885 |title=Zbytky z arithmetické posloupnosti (On the remainders of an arithmetic progression) |journal=Časopis pro pěstování matematiky a fysiky |volume=14 |issue=5 |pages=221–225 |url=http://dml.cz/handle/10338.dmlcz/122245}}

==External links==
*{{springer|title=Carmichael number|id=p/c110100}}
*[http://de.wikibooks.org/wiki/Pseudoprimzahlen:_Tabelle_Carmichael-Zahlen Table of Carmichael numbers]
*[http://www.chalcedon.demon.co.uk/rgep/cartable.html Tables of Carmichael numbers below &lt;math&gt;10^{18}&lt;/math&gt;]
*{{MathPages|id=home/kmath028/kmath028|title=The Dullness of 1729}}
*{{MathWorld | urlname=CarmichaelNumber | title=Carmichael Number}}
*[http://www.numericana.com/answer/modular.htm Final Answers Modular Arithmetic]

{{Classes of natural numbers}}

[[Category:Integer sequences]]
[[Category:Modular arithmetic]]
[[Category:Pseudoprimes]]</text>
      <sha1>nvkrodj563njw2jpmmbmbsh5c5pftfd</sha1>
    </revision>
  </page>
  <page>
    <title>Cat state</title>
    <ns>0</ns>
    <id>39127833</id>
    <revision>
      <id>869551303</id>
      <parentid>853166129</parentid>
      <timestamp>2018-11-19T09:09:51Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: page. Add: year, date, arxiv, pmid, doi, pages, issue, volume, journal, author pars. 1-10. Removed accessdate with no specified URL. Removed parameters. Formatted [[WP:ENDASH|dashes]]. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11014">In [[quantum computing]], the '''cat state''', named after [[Schrödinger's cat]],&lt;ref&gt;John Gribbin (1984), ''In Search of Schrödinger's Cat'',  {{ISBN|0-552-12555-5}}, 22 February 1985, Transworld Publishers, Ltd, 318 pages.&lt;/ref&gt; is a quantum superposition of two macroscopically distinct states. The individual states being superposed could be classical or quantum, but their macroscopicity is an important criterion. A cat state could be of one or more modes or particles, and does not necessarily need entanglement, especially for the single-particle case. This is in contrast to the [[Greenberger–Horne–Zeilinger state]], which by definition consists of multiple distinct particles or modes and their entanglement.

In other [[quantum mechanics]] contexts, according to ''[[The New York Times]]''{{unreliable source?|date=April 2016}} for example, physicists view the cat state as composed of two diametrically opposed conditions ''at the same time'',&lt;ref&gt;[[Dennis Overbye]], "[https://www.nytimes.com/2005/12/27/science/27eins.html?ex=1293339600&amp;en=caf5d835203c3500&amp;ei=5090 Quantum Trickery: Testing Einstein's Strangest Theory]". ''[[New York Times]]'' Tuesday (''Science Times''), December 27, 2005 pages D1,D4.&lt;/ref&gt; such as the possibilities that a cat be alive and dead at the same time. This is  sometimes connected to the [[many worlds hypothesis]] by proponents of the [[many worlds interpretation]] of quantum mechanics. More prosaically, a cat state might be the possibilities that six atoms be ''spin up'' and ''spin down'', as published by a team led by David Wineland at [[NIST]], December 1, 2005.&lt;ref name="fn3"&gt;D. Leibfried, E. Knill, S. Seidelin, J. Britton, R.B. Blakestad, J. Chiaverini, D. Hume, W.M. Itano, J.D. Jost, C. Langer, R. Ozeri, R. Reichle, and D.J. Wineland. "Creation of a six atom '[[Schrödinger cat]]' state". ''[[Nature (journal)|Nature]]''. Dec. 1, 2005, 639–642.&lt;/ref&gt; Large cat states have also been experimentally created using photons by a team led by Jian-Wei Pan at [[University of Science and Technology of China]], for instance, four-photon entanglement,&lt;ref&gt;{{cite journal|title=Phys. Rev. Lett. 91, 180401 (2003) - Experimental Violation of Local Realism by Four-Photon Greenberger-Horne-Zeilinger Entanglement |journal=Physical Review Letters |volume=91 |issue=18 |pages=180401 |date=2003-10-28 |doi=10.1103/PhysRevLett.91.180401 |pmid=14611269 |last1 = Zhao|first1 = Zhi|last2=Yang |first2=Tao |last3=Chen |first3=Yu-Ao |last4=Zhang |first4=An-Ning |last5=Żukowski |first5=Marek |last6=Pan |first6=Jian-Wei |arxiv=quant-ph/0302137 }}&lt;/ref&gt; five-photon entanglement,&lt;ref&gt;{{cite journal|url=http://www.nature.com/nature/journal/v430/n6995/full/nature02643.html|title=Experimental demonstration of five-photon entanglement and open-destination teleportation|journal=Nature|accessdate=2016-12-31 | volume=430|issue=6995|pages=54–58|doi=10.1038/nature02643|pmid=15229594|arxiv = quant-ph/0402096 |bibcode = 2004Natur.430...54Z |date=July 2004|last1=Pan|first1=Jian-Wei|last2=Briegel|first2=Hans J.|last3=Yang|first3=Tao|last4=Zhang|first4=An-Ning|last5=Chen|first5=Yu-Ao|last6=Zhao|first6=Zhi}}&lt;/ref&gt; six-photon entanglement,&lt;ref&gt;{{cite journal|title=Experimental entanglement of six photons in graph states|journal=Nature Physics|volume=3|issue=2|pages=91–95|doi=10.1038/nphys507|year=2007|last1=Lu|first1=Chao-Yang|last2=Zhou|first2=Xiao-Qi|last3=Gühne|first3=Otfried|last4=Gao|first4=Wei-Bo|last5=Zhang|first5=Jin|last6=Yuan|first6=Zhen-Sheng|last7=Goebel|first7=Alexander|last8=Yang|first8=Tao|last9=Pan|first9=Jian-Wei}}&lt;/ref&gt; eight-photon entanglement,&lt;ref&gt;{{cite journal|title=Observation of eight-photon entanglement|journal=Nature Photonics|volume=6|issue=4|pages=225–228|doi=10.1038/nphoton.2011.354|year=2012|last1=Yao|first1=Xing-Can|last2=Wang|first2=Tian-Xiong|last3=Xu|first3=Ping|last4=Lu|first4=He|last5=Pan|first5=Ge-Sheng|last6=Bao|first6=Xiao-Hui|last7=Peng|first7=Cheng-Zhi|last8=Lu|first8=Chao-Yang|last9=Chen|first9=Yu-Ao|last10=Pan|first10=Jian-Wei|arxiv = 1105.6318}}&lt;/ref&gt; and five-photon ten-qubit cat state.&lt;ref&gt;{{cite journal|title=Experimental demonstration of a hyper-entangled ten-qubit Schrödinger cat state|journal=Nature Physics|volume=6|issue=5|pages=331–335|doi=10.1038/nphys1603|year=2010|last1=Gao|first1=Wei-Bo|last2=Lu|first2=Chao-Yang|last3=Yao|first3=Xing-Can|last4=Xu|first4=Ping|last5=Gühne|first5=Otfried|last6=Goebel|first6=Alexander|last7=Chen|first7=Yu-Ao|last8=Peng|first8=Cheng-Zhi|last9=Chen|first9=Zeng-Bing|last10=Pan|first10=Jian-Wei}}&lt;/ref&gt; This spin up/down formulation was proposed by [[David Bohm]], who conceived of [[spin (physics)|spin]] as an [[observable]] in a version of [[thought experiment]]s formulated in the 1935 [[EPR paradox]].&lt;ref&gt;Amir D. Aczel (2001),  ''Entanglement: the unlikely story of how scientists, mathematicians, and philosophers proved Einstein's spookiest theory''. {{ISBN|0-452-28457-0}} Penguin: paperback, 284 pages, index.&lt;/ref&gt;

==In quantum optics==
[[Image:QHO-catstate-even3-animation-color.gif|thumb|right|300px|Time evolution of the probability distribution with quantum phase (color) of a cat state with α=3. The two coherent portions interfere in the center.]]
[[File:Wigner_function_of_a_Schrödinger_cat_state.gif|thumb|400px|Wigner function of a Schrödinger cat state]]
In [[quantum optics]], a cat state is defined as the coherent superposition of two [[coherent state]]s with opposite phase:
:&lt;math&gt;|\mathrm{cat}_e\rangle \propto|\alpha\rangle+|{-}\alpha\rangle
&lt;/math&gt;,
where
:&lt;math&gt;|\alpha\rangle =e^{-{|\alpha|^2\over2}}\sum_{n=0}^{\infty}{\alpha^n\over\sqrt{n!}}|n\rangle
&lt;/math&gt;,
and
:&lt;math&gt;|{-}\alpha\rangle =e^{-{|{-}\alpha|^2\over2}}\sum_{n=0}^{\infty}{({-}\alpha)^n\over\sqrt{n!}}|n\rangle
&lt;/math&gt;,
are coherent states defined in the number ([[Fock state|Fock]]) basis. Notice that if we add the two states together, the resulting cat state only contains even Fock state terms:
:&lt;math&gt;|\mathrm{cat}_e\rangle \propto 2e^{-{|\alpha|^2\over2}}\left({\alpha^0\over\sqrt{0!}}|0\rangle+{\alpha^2\over\sqrt{2!}}|2\rangle+{\alpha^4\over\sqrt{4!}}|4\rangle+\dots\right)
&lt;/math&gt;.
As a result of this property, the above cat state is often referred to as an ''even'' cat state. Alternatively, we can define an ''odd'' cat state as
:&lt;math&gt;|\mathrm{cat}_o\rangle \propto|\alpha\rangle-|{-}\alpha\rangle
&lt;/math&gt;,
which only contains odd Fock states
:&lt;math&gt;|\mathrm{cat}_o\rangle \propto 2e^{-{|\alpha|^2\over2}}\left({\alpha^1\over\sqrt{1!}}|1\rangle+{\alpha^3\over\sqrt{3!}}|3\rangle+{\alpha^5\over\sqrt{5!}}|5\rangle+\dots\right)
&lt;/math&gt;.

Even and odd coherent states were first introduced by Dodonov, Malkin, and Man'ko in 1974.&lt;ref&gt;{{cite journal|url=http://www.sciencedirect.com/science/article/pii/0031891474902158 |author1=V.V. Dodonov|author2=I.A. Malkin|author3=V.I. Man'ko|title= Even and odd coherent states and excitations of a singular oscillator|volume=72|issue=3|date=15 March 1974|pages=597–615|accessdate=2016-12-31|doi=10.1016/0031-8914(74)90215-8|journal=Physica|bibcode = 1974Phy....72..597D }}&lt;/ref&gt;

===Linear superposition of coherent states===
A simple example of a ''cat state'' is a linear superposition of coherent states with opposite phases, when each state has the same weight:&lt;ref&gt;{{cite journal|last1=Souza|first1=L.A.M.|last2=Nemes|first2=M.C.|last3=Santos|first3=M. França|last4=de Faria|first4=J.G. Peixoto|title=Quantifying the decay of quantum properties in single-mode states|journal=Optics Communications|date=2008-09-15|volume=281|issue=18|page=4696–4704|doi=10.1016/j.optcom.2008.06.017|arxiv=0710.5930|bibcode=2008OptCo.281.4696S}}&lt;/ref&gt;
:&lt;math&gt;|\mathrm{cat}_e\rangle = \frac{1}{\sqrt{2(1+e^{-2|\alpha|^2})}}(|\alpha\rangle+|{-}\alpha\rangle)
&lt;/math&gt;
:&lt;math&gt;|\mathrm{cat}_o\rangle = \frac{1}{\sqrt{2(1-e^{-2|\alpha|^2})}}(|\alpha\rangle-|{-}\alpha\rangle)
&lt;/math&gt;
:&lt;math&gt;|\mathrm{cat}_\theta\rangle = \frac{1}{\sqrt{2(1+\cos(\theta)e^{-2|\alpha|^2})}}(|\alpha\rangle+e^{i\theta}|{-}\alpha\rangle)
&lt;/math&gt;
The larger the value of α, the lower the overlap between the two macroscopic classical coherent states exp(-2α&lt;sup&gt;2&lt;/sup&gt;), and the better it approaches an ideal cat state. However, the production of cat states with a large mean photon number (=|α|&lt;sup&gt;2&lt;/sup&gt;) is difficult. A typical way to produce approximate cat states is through photon subtraction from a [[Squeezed coherent state|squeezed vacuum state]].&lt;ref&gt;{{Cite journal|last=Ourjoumtsev|first=Alexei|last2=Tualle-Brouri|first2=Rosa|last3=Laurat|first3=Julien|last4=Grangier|first4=Philippe|date=2006-04-07|title=Generating Optical Schrödinger Kittens for Quantum Information Processing|url=http://science.sciencemag.org/content/312/5770/83|journal=Science|language=en|volume=312|issue=5770|pages=83–86|doi=10.1126/science.1122858|issn=0036-8075|pmid=16527930|via=|bibcode = 2006Sci...312...83O }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Wakui|first=Kentaro|last2=Takahashi|first2=Hiroki|last3=Furusawa|first3=Akira|last4=Sasaki|first4=Masahide|date=2007-03-19|title=Photon subtracted squeezed states generated with periodically poled KTiOPO4|url=https://www.osapublishing.org/abstract.cfm?uri=oe-15-6-3568|journal=Optics Express|language=EN|volume=15|issue=6|pages=3568–3574|doi=10.1364/OE.15.003568|issn=1094-4087|arxiv = quant-ph/0609153 |bibcode = 2007OExpr..15.3568W }}&lt;/ref&gt; This method usually is restricted to small values of α, and such states have been referred to as Schrödinger "kitten" states in the literature. Methods have been proposed to produce larger coherent state superpositions through multiphoton subtraction&lt;ref&gt;{{Cite journal|last=Takeoka|first=Masahiro|last2=Takahashi|first2=Hiroki|last3=Sasaki|first3=Masahide|date=2008-06-12|title=Large-amplitude coherent-state superposition generated by a time-separated two-photon subtraction from a continuous-wave squeezed vacuum|journal=Physical Review A|volume=77|issue=6|pages=062315|arxiv=0804.0464|doi=10.1103/PhysRevA.77.062315|bibcode = 2008PhRvA..77f2315T }}&lt;/ref&gt; or through ancilla-assisted subtraction.&lt;ref&gt;{{Cite journal|last=Takahashi|first=Hiroki|last2=Wakui|first2=Kentaro|last3=Suzuki|first3=Shigenari|last4=Takeoka|first4=Masahiro|last5=Hayasaka|first5=Kazuhiro|last6=Furusawa|first6=Akira|last7=Sasaki|first7=Masahide|date=2008-12-04|title=Generation of Large-Amplitude Coherent-State Superposition via Ancilla-Assisted Photon Subtraction|journal=Physical Review Letters|volume=101|issue=23|pages=233605|arxiv=0806.2965|doi=10.1103/PhysRevLett.101.233605|pmid=19113554|bibcode=2008PhRvL.101w3605T}}&lt;/ref&gt;

Coherent state superpositions have been proposed for quantum computing by Sanders.&lt;ref&gt;{{Cite journal|last=Sanders|first=Barry C.|date=1992-05-01|title=Entangled coherent states|journal=Physical Review A|volume=45|issue=9|pages=6811–6815|doi=10.1103/PhysRevA.45.6811|bibcode = 1992PhRvA..45.6811S }}&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Quantum information science]]
[[Category:Fictional cats]]
[[Category:Schrödinger's cat]]</text>
      <sha1>i60uxcm8s2eie5ajcgeo8n1zvese7m6</sha1>
    </revision>
  </page>
  <page>
    <title>Causal fermion system</title>
    <ns>0</ns>
    <id>42944052</id>
    <revision>
      <id>851687364</id>
      <parentid>851572309</parentid>
      <timestamp>2018-07-23T23:12:25Z</timestamp>
      <contributor>
        <username>John Baez</username>
        <id>233394</id>
      </contributor>
      <comment>There are plenty of books and journal articles on theories of physics that are not proven facts; I could list them for hours.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27600">{{Beyond the Standard Model|expanded=[[Quantum gravity]]}}

The theory of '''causal fermion systems''' is an approach to describe [[fundamental physics]]. Its proponents claim it gives [[quantum mechanics]], [[general relativity]] and [[quantum field theory]] as limiting cases&lt;ref name="PFP"&gt;F. Finster, ''The Principle of the Fermionic Projector'', hep-th/0001048, hep-th/0202059, hep- th/0210121, AMS/IP Studies in Advanced Mathematics, vol. '''35''', American Mathematical Society, Providence, RI, 2006.&lt;/ref&gt;&lt;ref name="cfs"&gt;F. Finster, ''The Continuum Limit of Causal Fermion Systems'', arXiv:1605.04742 [math-ph], Fundamental Theories of Physics, Vol. '''186''',  Springer, 2016.&lt;/ref&gt;&lt;ref name="srev"&gt;F. Finster, ''A formulation of quantum field theory realizing a sea of interacting Dirac particles'', arXiv:0911.2102 [hep-th], Lett. Math. Phys. '''97''' (2011), no. 2, 165–183.&lt;/ref&gt;&lt;ref name="qft"&gt;F. Finster, ''Perturbative quantum field theory in the framework of the fermionic projector'', arXiv:1310.4121 [math-ph], J. Math. Phys. '''55''' (2014), no. 4, 042301.&lt;/ref&gt; and is therefore a candidate for a unified physical theory.

Instead of introducing physical objects on a preexisting [[space-time]] [[manifold]], the general concept is to derive space-time as well as all the objects therein as secondary objects from the structures of an underlying causal fermion system. This concept also makes it possible to generalize notions of [[differential geometry]] to the non-smooth setting.&lt;ref name="lqg"/&gt;&lt;ref name="topology"/&gt; In particular, one can describe situations when space-time no longer has a manifold structure on the microscopic scale (like a space-time lattice or other discrete or continuous structures on the [[Planck scale]]). As a result, the theory of causal fermion systems is a proposal for [[quantum geometry]] and an approach to [[quantum gravity]].

Causal fermion systems were introduced by [[Felix Finster]] and collaborators.

== Motivation and physical concept ==
The physical starting point is the fact that the [[Dirac equation]] in [[Minkowski space]] has solutions of negative energy which are usually associated to the [[Dirac sea]]. Taking the concept seriously that the states of the Dirac sea form an integral part of the physical system, one finds that many structures (like the [[Causality (physics)|causal]] and [[Metric tensor (general relativity)|metric]] structures as well as the bosonic fields) can be recovered from the wave functions of the sea states. This leads to the idea that the wave functions of all occupied states (including the sea states) should be regarded as the basic physical objects, and that all structures in space-time arise as a result of the collective interaction of the sea states with each other and with the additional particles and [[Dirac equation#Hole theory|"holes"]] in the sea. Implementing this picture mathematically leads to the framework of causal fermion systems.

More precisely, the correspondence between the above physical situation and the mathematical framework is obtained as follows. All occupied states span a [[Hilbert space]] of wave functions in Minkowski space &lt;math&gt;\hat{M}&lt;/math&gt;. The observable information on the distribution of the wave functions in space-time is encoded in the ''local correlation operators'' &lt;math&gt;F(x), x \in \hat{M},&lt;/math&gt; which in an [[orthonormal basis]] &lt;math&gt;(\psi_i)&lt;/math&gt; have the matrix representation
:&lt;math&gt; \big( F(x) \big)^i_j = - \overline{\psi_i(x)} \psi_j(x) &lt;/math&gt;
(where &lt;math&gt;\overline{\psi}&lt;/math&gt; is the [[Dirac adjoint|adjoint spinor]]).
In order to make the wave functions into the basic physical objects, one considers the set &lt;math&gt; \{ F(x) \,|\, x \in \hat{M} \} &lt;/math&gt; as a set of [[linear operator]]s on an ''abstract'' Hilbert space. The structures of Minkowski space are all disregarded, except for the volume measure &lt;math&gt;d^4x&lt;/math&gt;, which is transformed to a corresponding [[Measure (mathematics)|measure]] on the linear operators (the ''"universal measure"''). The resulting structures, namely a Hilbert space together with a measure on the linear operators thereon, are the basic ingredients of a causal fermion system.

The above construction can also be carried out in [[causal fermion system#Lorentzian spin geometry of globally hyperbolic space-times|more general space-times]]. Moreover, taking the abstract definition as the starting point, causal fermion systems allow for the description of generalized "quantum space-times." The physical picture is that one causal fermion system describes a space-time together with all structures and objects therein (like the causal and the metric structures, wave functions and quantum fields). In order to single out the physically admissible causal fermion systems, one must formulate physical equations. In analogy to the [[Lagrangian (field theory)|Lagrangian]] formulation of [[classical field theory]], the physical equations for causal fermion systems are formulated via a variational principle, the so-called ''causal action principle''. Since one works with different basic objects, the causal action principle has a novel mathematical structure where one minimizes a positive action under variations of the universal measure. The connection to conventional physical equations is obtained in a certain limiting case (the [[continuum limit]]) in which the interaction can be described effectively by [[gauge field]]s coupled to particles and [[antiparticle]]s, whereas the Dirac sea is no longer apparent.

== General mathematical setting ==
In this section the mathematical framework of causal fermion systems is introduced.

=== Definition of a causal fermion system ===
A '''causal fermion system''' of spin dimension &lt;math&gt;n \in \mathbb{N} &lt;/math&gt; is a triple &lt;math&gt;(\mathcal H, \mathcal F, \rho)&lt;/math&gt; where
* &lt;math&gt;(\mathcal H, \langle .|. \rangle_{\mathcal{H}})&lt;/math&gt; is a complex [[Hilbert space]].
* &lt;math&gt;\mathcal F&lt;/math&gt; is the set of all [[Self-adjoint operator|self-adjoint]] linear operators of [[Finite-rank operator|finite rank]] on &lt;math&gt;\mathcal H&lt;/math&gt; which (counting [[geometric multiplicity|multiplicities]]) have at most &lt;math&gt;n&lt;/math&gt; positive and at most &lt;math&gt;n&lt;/math&gt; negative eigenvalues.
* &lt;math&gt;\rho&lt;/math&gt; is a [[Measure (mathematics)|measure on]] &lt;math&gt;\mathcal F&lt;/math&gt;.
The measure &lt;math&gt;\rho&lt;/math&gt; is referred to as the '''universal measure'''.

As will be outlined below, this definition is rich enough to encode analogs of the mathematical structures needed to formulate physical theories. In particular, a causal fermion system gives rise to a space-time together with additional structures that generalize objects like [[spinors]], the [[Metric tensor (general relativity)|metric]] and [[curvature]]. Moreover, it comprises  quantum objects like [[wave functions]] and a [[fermionic]] [[Fock state]].&lt;ref name="rrev"&gt;F. Finster, A. Grotz, and D. Schiefeneder, ''Causal fermion systems: A quantum space-time emerging from an action principle'', arXiv:1102.2585 [math-ph], Quantum Field Theory and Gravity (F. Finster, O. Müller, M. Nardmann, J. Tolksdorf, and E. Zeidler, eds.), Birkhäuser Verlag, Basel, 2012, pp. 157–182.&lt;/ref&gt;

=== The causal action principle ===
Inspired by the Langrangian formulation of classical field theory, the dynamics on a causal fermion system is described by a variational principle defined as follows.

Given a Hilbert space &lt;math&gt;(\mathcal H, \langle .|. \rangle_{\mathcal{H}})&lt;/math&gt; and the spin dimension &lt;math&gt;n&lt;/math&gt;, the set &lt;math&gt;\mathcal F&lt;/math&gt; is defined as above. Then for any &lt;math&gt;x,y \in {\mathcal{F}}&lt;/math&gt;, the product &lt;math&gt;x y&lt;/math&gt; is an operator of rank at most &lt;math&gt;2n&lt;/math&gt;. It is not necessarily self-adjoint because in general &lt;math&gt;(xy)^* = y x \neq xy&lt;/math&gt;. We denote the non-trivial eigenvalues of the operator &lt;math&gt;x y&lt;/math&gt; (counting [[algebraic multiplicity|algebraic multiplicities]]) by
: &lt;math&gt; \lambda^{xy}_1, \ldots, \lambda^{xy}_{2n} \in {\mathbb{C}} . &lt;/math&gt;
Moreover, the '''spectral weight''' &lt;math&gt;| . |&lt;/math&gt; is defined by
:&lt;math&gt;|xy| = \sum_{i=1}^{2n} |\lambda^{xy}_i| \quad \text{and} \quad
\big| (xy)^2 \big| = \sum_{i=1}^{2n} |\lambda^{xy}_i|^2 {\,}.&lt;/math&gt;
The '''Lagrangian''' is introduced by
:&lt;math&gt;{\mathcal{L}}(x,y) = \big| (xy)^2 \big| - \frac{1}{2n} {\,}|xy|^2
= \frac{1}{4n} \sum_{i,j=1}^{2n} \big( |\lambda^{xy}_i| - |\lambda^{xy}_j| \big)^2 \geq 0 {\,}.&lt;/math&gt;
The '''causal action''' is defined by
:&lt;math&gt;{\mathcal{S}}= \iint_{{\mathcal{F}}\times {\mathcal{F}}} {\mathcal{L}}(x,y){\,}d\rho(x){\,}d\rho(y) {\,}.&lt;/math&gt;

The '''causal action principle''' is to minimize &lt;math&gt;{\mathcal{S}}&lt;/math&gt; under variations of &lt;math&gt;\rho&lt;/math&gt; within the class of (positive) [[Borel measure]]s under the following constraints:
* Boundedness constraint: &lt;math&gt; \iint_{{\mathcal{F}}\times {\mathcal{F}}} |xy|^2 {\,}d\rho(x){\,}d\rho(y) \leq C&lt;/math&gt; for some positive constant &lt;math&gt;C&lt;/math&gt;.
* Trace constraint: &lt;math&gt;\;\;\;\int_{\mathcal{F}} \text{tr}(x) {\,}d\rho(x)&lt;/math&gt; is kept fixed.
* The total volume &lt;math&gt;\rho({\mathcal{F}})&lt;/math&gt; is preserved.
Here on &lt;math&gt;{\mathcal{F}}\subset {\mathrm{L}}({\mathcal{H}})&lt;/math&gt; one considers the [[induced topology|topology induced]] by the &lt;math&gt;\sup&lt;/math&gt;-norm on the bounded linear operators on &lt;math&gt;{\mathcal{H}}&lt;/math&gt;.

The constraints prevent trivial minimizers and ensure existence, provided that &lt;math&gt;{\mathcal{H}}&lt;/math&gt; is finite-dimensional.&lt;ref name="continuum"&gt;F. Finster, ''Causal variational principles on measure spaces'', arXiv:0811.2666 [math-ph], J. Reine Angew. Math. '''646''' (2010), 141–194.&lt;/ref&gt;
This variational principle also makes sense in the case that the total volume &lt;math&gt;\rho({\mathcal{F}})&lt;/math&gt; is infinite if one considers variations &lt;math&gt;\delta \rho&lt;/math&gt; of [[bounded variation#Measures of bounded variation|bounded variation]] with &lt;math&gt;(\delta \rho)({\mathcal{F}})=0&lt;/math&gt;.

== Inherent structures ==
In contemporary physical theories, the word [[space-time]] refers to a [[Lorentzian manifold]] &lt;math&gt;(M,g)&lt;/math&gt;. This means that space-time is a [[set (mathematics)|set]] of points enriched by topological and geometric structures. In the context of causal fermion systems, space-time does not need to have a manifold structure. Instead, space-time &lt;math&gt;M&lt;/math&gt; is a set of operators on a Hilbert space (a subset of &lt;math&gt;\mathcal F&lt;/math&gt;). This implies additional inherent structures that correspond to and generalize usual objects on a space-time manifold.

For a causal fermion system &lt;math&gt;(\mathcal H, \mathcal F, \rho)&lt;/math&gt;,
we define '''space-time''' &lt;math&gt;M&lt;/math&gt; as the [[Support (measure theory)|support]] of the universal measure,
: &lt;math&gt; M := \text{supp} \, \rho \subset \mathcal{F}. &lt;/math&gt;
With the [[induced topology|topology induced]] by &lt;math&gt;\mathcal{F}&lt;/math&gt;,
space-time &lt;math&gt;M&lt;/math&gt; is a [[topological space]].

=== Causal structure ===
For &lt;math&gt;x,y \in M&lt;/math&gt;, we denote the non-trivial eigenvalues of the operator &lt;math&gt;x y&lt;/math&gt; (counting  [[algebraic multiplicity|algebraic multiplicities]]) by &lt;math&gt; \lambda^{xy}_1, \ldots, \lambda^{xy}_{2n} \in {\mathbb{C}} &lt;/math&gt;.
The points &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are defined to be '''spacelike''' separated if all the &lt;math&gt;\lambda^{xy}_j&lt;/math&gt; have the same absolute value. They are '''timelike''' separated if the &lt;math&gt;\lambda^{xy}_j&lt;/math&gt; do not all have the same absolute value and are all real. In all other cases, the points &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are '''lightlike''' separated.

This notion of causality fits together with the "causality" of the above causal action in the sense that if two space-time points &lt;math&gt;x,y \in M&lt;/math&gt; are space-like separated, then the Lagrangian &lt;math&gt;{\mathcal{L}}(x,y)&lt;/math&gt; vanishes. This corresponds to the physical notion of [[Causality (physics)|causality]] that spatially separated space-time points do not interact. This causal structure is the reason for the notion "causal" in causal fermion system and causal action.

Let &lt;math&gt;\pi_x&lt;/math&gt; denote the orthogonal projection on the subspace &lt;math&gt;S_x := x({\mathcal{H}}) \subset {\mathcal{H}}&lt;/math&gt;.  Then the sign of the functional
: &lt;math&gt; i \text{Tr} \big( x\,  y \, \pi_x \, \pi_y - y \, x \, \pi_y \, \pi_x) &lt;/math&gt;
distinguishes the '''future''' from the '''past'''. In contrast to the structure of a [[partially ordered set]], the relation "lies in the future of" is in general not transitive. But it is transitive on the macroscopic scale in typical examples.&lt;ref name="lqg" /&gt;&lt;ref name="topology"&gt;F. Finster and [[Niky Kamran|N. Kamran]], ''Spinors on singular spaces and the topology of causal fermion systems'', arXiv:1403.7885 [math-ph] (2014).&lt;/ref&gt;

=== Spinors and wave functions ===
For every &lt;math&gt;x \in M&lt;/math&gt; the '''spin space''' is defined by &lt;math&gt;S_x = x({\mathcal{H}})&lt;/math&gt;; it is a subspace of &lt;math&gt;{\mathcal{H}}&lt;/math&gt; of dimension at most &lt;math&gt;2n&lt;/math&gt;. The '''spin scalar product''' &lt;math&gt;{\prec} \cdot | \cdot {\succ}_x&lt;/math&gt; defined by
:&lt;math&gt;{\prec}u | v {\succ}_x = -{\langle}u | x v {\rangle}_{\mathcal{H}}\qquad \text{for all } u,v \in S_x&lt;/math&gt;
is an indefinite [[inner product space|inner product]] on &lt;math&gt;S_x&lt;/math&gt; of [[Metric signature|signature]] &lt;math&gt;(p,q)&lt;/math&gt; with &lt;math&gt;p,q \leq n&lt;/math&gt;.

A '''wave function''' &lt;math&gt;\psi&lt;/math&gt; is a mapping
:&lt;math&gt;\psi {\,}:{\,}M \rightarrow {\mathcal{H}}\qquad \text{with} \qquad \psi(x) \in S_x \quad \text{for all } x \in M{\,}.&lt;/math&gt;
On wave functions for which the norm &lt;math&gt;{|\!|\!|}\cdot {|\!|\!|}&lt;/math&gt; defined by
:&lt;math&gt;{|\!|\!|}\psi {|\!|\!|}^2 = \int_M \left\langle\psi(x) \bigg|\, |x|\, \psi(x) \right\rangle_{\mathcal{H}}{\,}d\rho(x)&lt;/math&gt;
is finite (where &lt;math&gt;|x|= \sqrt{x^2}&lt;/math&gt; is the absolute value of the symmetric operator &lt;math&gt;x&lt;/math&gt;), one can define the inner product
:&lt;math&gt;{\mathopen{&lt;}}\psi | \phi {\mathclose{&gt;}}= \int_M {\prec}\psi(x) | \phi(x) {\succ}_x {\,}d\rho(x) {\,}.&lt;/math&gt;
Together with the topology induced by the norm &lt;math&gt;{|\!|\!|}\cdot {|\!|\!|}&lt;/math&gt;, one obtains a [[Krein space]] &lt;math&gt;({{\mathcal{K}}}, {\mathopen{&lt;}}\cdot|\cdot {\mathclose{&gt;}})&lt;/math&gt;.

To any vector &lt;math&gt;u \in \mathcal{H}&lt;/math&gt; we can associate the wave function
:&lt;math&gt;\psi^u(x) := \pi_x u&lt;/math&gt;
(where &lt;math&gt;\pi_x : \mathcal{H} \rightarrow S_x&lt;/math&gt; is again the orthogonal projection to the spin space).
This gives rise to a distinguished family of wave functions, referred to as the
wave functions  of the '''occupied states'''.

=== The fermionic projector ===
The '''kernel of the fermionic projector''' &lt;math&gt;P(x,y)&lt;/math&gt; is defined by
:&lt;math&gt;P(x,y) = \pi_x \,y|_{S_y} {\,}:{\,}S_y \rightarrow S_x&lt;/math&gt;
(where &lt;math&gt;\pi_x : \mathcal{H} \rightarrow S_x&lt;/math&gt; is again the orthogonal projection on the spin space,
and &lt;math&gt;|_{S_y}&lt;/math&gt; denotes the restriction to &lt;math&gt;S_y&lt;/math&gt;). The '''fermionic projector''' &lt;math&gt;P&lt;/math&gt; is the operator
:&lt;math&gt;P {\,}:{\,}{{\mathcal{K}}}\rightarrow {{\mathcal{K}}}{\,},\qquad (P \psi)(x) = \int_M P(x,y)\, \psi(y)\, d\rho(y){\,},&lt;/math&gt;
which has the dense domain of definition given by all vectors &lt;math&gt;\psi \in {{\mathcal{K}}}&lt;/math&gt; satisfying the conditions
:&lt;math&gt;\phi := \int_M x\, \psi(x)\, d\rho(x) {\,}\in {\,}{\mathcal{H}}\quad \text{and} \quad {|\!|\!|}\phi {|\!|\!|}&lt; \infty{\,}.&lt;/math&gt;
As a consequence of the causal action principle, the kernel of the fermionic projector has additional normalization properties&lt;ref&gt;F. Finster and J. Kleiner, ''Noether-like theorems for causal variational principles'', arXiv:1506.09076 [math-ph] (2015).&lt;/ref&gt; which justify the name [[Projection (linear algebra)|projector]].

=== Connection and curvature ===
Being an operator from one spin space to another, the kernel of the fermionic projector gives relations between different space-time points. This fact can be used to introduce a '''spin connection'''
:&lt;math&gt;D_{x,y} \,:\, S_y \rightarrow S_x \quad \text{unitary}\,. &lt;/math&gt;
The basic idea is to take a [[polar decomposition]] of &lt;math&gt;P(x,y)&lt;/math&gt;. The construction becomes more involved by the fact that the spin connection should induce a corresponding '''metric connection'''
:&lt;math&gt;\nabla_{x,y}\,:\, T_y \rightarrow T_x \quad \text{isometric}\,,&lt;/math&gt;
where the tangent space &lt;math&gt;T_x&lt;/math&gt; is a specific subspace of the linear operators on &lt;math&gt;S_x&lt;/math&gt; endowed with a Lorentzian metric.
The '''spin curvature''' is defined as the [[holonomy]] of the spin connection,
:&lt;math&gt;\mathfrak{R}(x,y,z) = D_{x,y} \,D_{y,z} \,D_{z,x} \,:\, S_x \rightarrow S_x\,. &lt;/math&gt;
Similarly, the metric connection gives rise to '''metric curvature'''. These geometric structures give rise to a proposal for a [[quantum geometry]].&lt;ref name="lqg"&gt;F. Finster and A. Grotz, ''A Lorentzian quantum geometry'', arXiv:1107.2026 [math-ph], Adv. Theor. Math. Phys. '''16''' (2012), no. 4, 1197–1290.&lt;/ref&gt;

=== A fermionic Fock state ===
If &lt;math&gt;{\mathcal{H}}&lt;/math&gt; has finite dimension &lt;math&gt;f&lt;/math&gt;, choosing an orthonormal basis &lt;math&gt;u_1, \ldots, u_f&lt;/math&gt; of &lt;math&gt;{\mathcal{H}}&lt;/math&gt; and taking the wedge product of the corresponding wave functions
:&lt;math&gt; \big( \psi^{u_1} \wedge \cdots \wedge \psi^{u_f} \big)(x_1, \ldots, x_f)&lt;/math&gt;
gives a state of an &lt;math&gt;f&lt;/math&gt;-particle fermionic [[Fock space]]. Due to the total anti-symmetrization, this state depends on the choice of the basis of &lt;math&gt;{\mathcal{H}}&lt;/math&gt; only by a phase factor.&lt;ref name="entangle"&gt;F. Finster, ''Entanglement and second quantization in the framework of the fermionic projector'', arXiv:0911.0076 [math-ph], J. Phys. A: Math. Theor. '''43''' (2010), 395302.&lt;/ref&gt; This correspondence explains why the vectors in the particle space are to be interpreted as [[fermion]]s. It also motivates the name causal '''fermion''' system.

== Underlying physical principles ==
Causal fermion systems incorporate several physical principles in a specific way:
* A '''local gauge principle''': In order to represent the wave functions in components, one chooses bases of the spin spaces. Denoting the [[Metric signature|signature]] of the spin scalar product at &lt;math&gt;x&lt;/math&gt; by &lt;math&gt;({\mathfrak{p}}_x, {\mathfrak{q}}_x)&lt;/math&gt;, a pseudo-orthonormal basis &lt;math&gt;(\mathfrak{e}_\alpha(x))_{\alpha=1,\ldots, {\mathfrak{p}}_x+{\mathfrak{q}}_x}&lt;/math&gt; of &lt;math&gt;S_x&lt;/math&gt; is given by
::&lt;math&gt;{\prec}\mathfrak{e}_\alpha | \mathfrak{e}_\beta {\succ}= s_\alpha{\,}\delta_{\alpha \beta}
\quad \text{with} \quad s_1, \ldots, s_{{\mathfrak{p}}_x} = 1,\;\; s_{{\mathfrak{p}}_x+1}, \ldots, s_{{\mathfrak{p}}_x+{\mathfrak{q}}_x} =-1 {\,}.&lt;/math&gt;
:Then a wave function &lt;math&gt;\psi&lt;/math&gt; can be represented with component functions,
::&lt;math&gt;\psi(x) = \sum_{\alpha=1}^{{\mathfrak{p}}_x+{\mathfrak{q}}_x} \psi^\alpha(x){\,}\mathfrak{e}_\alpha(x) {\,}.&lt;/math&gt; 
:The freedom of choosing the bases &lt;math&gt;(\mathfrak{e}_\alpha(x))&lt;/math&gt; independently at every space-time point corresponds to local unitary transformations of the wave functions,
::&lt;math&gt;\psi^\alpha(x) \rightarrow \sum_{\beta=1}^{{\mathfrak{p}}_x+{\mathfrak{q}}_x} U(x)^\alpha_\beta \,\, \psi^\beta(x)
\quad \text{with} \quad U(x)\in \text{U}({\mathfrak{p}}_x, {\mathfrak{q}}_x) {\,}.&lt;/math&gt;
:These transformations have the interpretation as local [[gauge transformation]]s. The gauge group is determined to be the isometry group of the spin scalar product. The causal action is [[Gauge invariance|gauge invariant]] in the sense that it does not depend on the choice of spinor bases.
* The '''equivalence principle''': For an explicit description of space-time one must work with local coordinates. The freedom in choosing such coordinates generalizes the freedom in choosing general reference frames in a space-time manifold. Therefore, the [[equivalence principle]] of [[general relativity]] is respected. The causal action is [[General covariance|generally covariant]] in the sense that it does not depend on the choice of coordinates.
* The '''Pauli exclusion principle''': The fermionic Fock state associated to the causal fermion system makes it possible to describe the many-particle state by a totally antisymmetric wave function. This gives agreement with the [[Pauli exclusion principle]].
* The principle of '''causality''' is incorporated by the form of the causal action in the sense that space-time points with spacelike separation do not interact.

== Limiting cases ==

Causal fermion systems have mathematically sound limiting cases that give a connection to conventional physical structures.

=== Lorentzian spin geometry of globally hyperbolic space-times ===

Starting on any globally hyperbolic [[Lorentzian manifold|Lorentzian]] [[spin structure|spin]] manifold &lt;math&gt;(\hat{M}, g)&lt;/math&gt; with spinor bundle &lt;math&gt;S\hat{M}&lt;/math&gt;, one gets into the framework of causal fermion systems by choosing &lt;math&gt;({\mathcal{H}}, {\langle}.|. {\rangle}_{\mathcal{H}})&lt;/math&gt; as a subspace of the solution space of the [[Dirac equation]]. Defining the so-called '''local correlation operator''' &lt;math&gt;F(p)&lt;/math&gt; for &lt;math&gt;p \in \hat{M}&lt;/math&gt; by
:&lt;math&gt;{\langle}\psi | F(p) \phi {\rangle}_{\mathcal{H}} = -{\prec}\psi | \phi {\succ}_p&lt;/math&gt;
(where &lt;math&gt;{\prec}\psi | \phi {\succ}_p&lt;/math&gt; is the inner product on the fibre &lt;math&gt;S_p \hat{M}&lt;/math&gt;) and introducing the universal measure as the push-forward of the volume measure on &lt;math&gt;\hat{M}&lt;/math&gt;,
:&lt;math&gt;\rho = F_* d\mu {\,},&lt;/math&gt;
one obtains a causal fermion system. For the local correlation operators to be well-defined, &lt;math&gt;{\mathcal{H}}&lt;/math&gt; must consist of continuous sections, typically making it necessary to introduce a [[Regularization (physics)|regularization]] on the microscopic scale &lt;math&gt;\varepsilon&lt;/math&gt;. In the limit &lt;math&gt;\varepsilon \searrow 0&lt;/math&gt;, all the intrinsic structures on the causal fermion system (like the causal structure, connection and curvature) go over to the corresponding structures on the Lorentzian spin manifold.&lt;ref name="lqg" /&gt; Thus the geometry of space-time is encoded completely in the corresponding causal fermion systems.

=== Quantum mechanics and classical field equations ===
The Euler-Lagrange equations corresponding to the causal action principle have a well-defined limit if the space-times &lt;math&gt;M:=\text{supp}\, \rho&lt;/math&gt; of the causal fermion systems go over to [[Minkowski space]]. More specifically, one considers a sequence of causal fermion systems (for example with &lt;math&gt;{\mathcal{H}}&lt;/math&gt; finite-dimensional in order to ensure the existence of the fermionick Fock state as well as of minimizers of the causal action), such that the corresponding wave functions go over to a configuration of interacting Dirac seas involving additional particle states or "holes" in the seas. This procedure, referred to as the [[continuum limit]], gives effective equations having the structure of the [[Dirac equation]] coupled to classical [[field equations]]. For example, for a simplified model involving three elementary fermionic particles
in spin dimension two, one obtains an interaction via a classical axial gauge field &lt;math&gt;A&lt;/math&gt;&lt;ref name="cfs" /&gt; described by the coupled [[Dirac equation|Dirac-]] and [[Yang-Mills equations]]
:&lt;math&gt;\begin{align}
(i \partial \!\!\!/\ + \gamma^5 A \!\!\!/\ - m) \psi &amp;= 0 \\
C_0 (\partial^k_j A^j - \Box A^k) - C_2 A^k &amp;= 12 \pi^2 \bar \psi \gamma^5 \gamma^k \psi \,.
\end{align}&lt;/math&gt;
Taking the non-relativistic limit of the Dirac equation, one obtains the [[Pauli equation]] or the [[Schrödinger equation]], giving the correspondence to [[quantum mechanics]]. Here &lt;math&gt; C_0&lt;/math&gt; and &lt;math&gt; C_2&lt;/math&gt; depend on the regularization and determine the coupling constant as well as the rest mass.

Likewise, for a system involving neutrinos in spin dimension 4, one gets effectively a massive &lt;math&gt;SU(2)&lt;/math&gt; gauge field coupled to the left-handed component of the Dirac spinors.&lt;ref name="cfs" /&gt; The fermion configuration of the standard model can be described in spin dimension 16.&lt;ref name="PFP" /&gt;

=== The Einstein field equations ===
For the just-mentioned system involving neutrinos,&lt;ref name="cfs" /&gt; the continuum limit also yields the [[Einstein field equations]] coupled to the Dirac spinors,
:&lt;math&gt;R_{jk} - \frac{1}{2}\,R\, g_{jk} + \Lambda\, g_{jk} = \kappa\, T_{jk}[\Psi, A] \,,&lt;/math&gt;
up to corrections of higher order in the curvature tensor. Here the cosmological constant &lt;math&gt;\Lambda&lt;/math&gt; is undetermined, and &lt;math&gt;T_{jk}&lt;/math&gt; denotes the energy-momentum tensor of the spinors and the &lt;math&gt;SU(2)&lt;/math&gt; gauge field. The gravitation constant &lt;math&gt;\kappa&lt;/math&gt; depends on the regularization length.

=== Quantum field theory in Minkowski space ===
Starting from the coupled system of equations obtained in the continuum limit and expanding in powers of the coupling constant, one obtains integrals which correspond to [[Feynman diagrams]] on the tree level. Fermionic loop diagrams arise due to the interaction with the sea states, whereas bosonic loop diagrams appear when taking averages over the microscopic (in generally non-smooth) space-time structure of a causal fermion system (method of [[microscopic mixing]]).&lt;ref name="qft" /&gt; The detailed analysis and comparison with standard quantum field theory is work in progress.

== References ==
&lt;!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using &lt;ref&gt;&lt;/ref&gt; tags, these references will then appear here automatically --&gt;
{{Reflist}}

== Further reading ==
* For a non-technical introduction see Finster, Kleiner: Causal fermion systems as a candidate for a unified physical theory, arXiv:1502.03587 [math-ph], 2015, [https://arxiv.org/abs/1502.03587 Online].
* Talk "Causal fermion systems as an approach to quantum theory" at Conference [http://www.uni-regensburg.de/Fakultaeten/nat_Fak_I/qft2014/ Quantum Mathematical Physics - A bridge between Mathematics and Physics], Regensburg, September 2014, [https://mediathek.uni-regensburg.de/playthis/5474545a37eef8.85547250 Video online].
* Recording of a 2016 spring school on the topic: [https://www.youtube.com/watch?v=_gwGsH6kApU&amp;list=PLI-rf4Dw47-pRLd5bOnxgDBOaUWCL5wgS Videos], [http://cfs-school.uni-regensburg.de/ School Website].
* [https://www.springer.com/de/book/9783319420660 The Continuum Limit of Causal Fermion Systems], Fundamental Theories of Physics, Vol. '''186''',  [[Axel Springer AG|Springer]], 2016, {{ISBN|978-3-319-42067-7}}, [https://arxiv.org/abs/1605.04742 Online].
* [http://bookstore.ams.org/amsip-35/ The Principle of the Fermionic Projector], AMS/IP Studies in Advanced Mathematics Series '''35''', [[American Mathematical Society]], Providence, RI; International Press, Cambridge, MA, 2006, {{ISBN|978-0-8218-3974-4}}, [https://arxiv.org/abs/hep-th/0001048 Chapters 0-3] [https://arxiv.org/abs/hep-th/0202059 Chapters 5-8] [https://arxiv.org/abs/hep-th/0210121 Appendices]..
*  Finster, Grotz, Schiefeneder: Causal fermion systems: A quantum space-time emerging from an action principle, in [https://www.springer.com/de/book/9783034800426 "Quantum Field Theory and Gravity"], [[Birkhäuser Verlag|Birkhäuser]], 2012, [https://arxiv.org/abs/1102.2585 Online].
*  A formulation of quantum field theory realizing a sea of interacting Dirac particles, Letters in Mathematical Physics '''97''', [[Axel Springer AG|Springer]], 2011, 165–183, [https://arxiv.org/abs/0911.2102 Online].

&lt;!--- Categories ---&gt;

[[Category:Articles created via the Article Wizard]]
[[Category:Theoretical physics]]
[[Category:Quantum gravity]]
[[Category:Mathematical physics]]
[[Category:Quantum field theory]]</text>
      <sha1>0hsxsdvv1l3sryn9a9xzel6ahqxj5ns</sha1>
    </revision>
  </page>
  <page>
    <title>Charles Loewner</title>
    <ns>0</ns>
    <id>9337483</id>
    <revision>
      <id>850938655</id>
      <parentid>844523238</parentid>
      <timestamp>2018-07-19T00:01:12Z</timestamp>
      <contributor>
        <username>Suslindisambiguator</username>
        <id>12329968</id>
      </contributor>
      <comment>added William J. Firey to list of doctoral students</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6925">{{Infobox scientist
| name              = Charles Loewner
| image             = Loewner63.jpg
| image_size        = 200px
| caption           = Charles Loewner in '63
| birth_date        = {{birth date|1893|05|29|df=y}}
| birth_place       = [[Lány (Kladno District)|Lány]], [[Kingdom of Bohemia|Bohemia]]
| death_date        = {{death date and age|1968|01|08|1893|05|29|df=y}}
| death_place       = [[Stanford, California|Stanford]], [[California]]
| nationality       = American
| fields            = [[Mathematics]]
| workplaces        = [[Stanford University]]&lt;br&gt;[[Syracuse University]]&lt;br&gt;[[Karl-Ferdinands-Universität|University of Prague]]
| alma_mater        = Karl-Ferdinands-Universität
| doctoral_advisor  = [[Georg Alexander Pick]]
| doctoral_students = [[Lipman Bers]]&lt;br&gt;[[William J. Firey]]&lt;br&gt;[[Adriano Garsia]]&lt;br&gt;[[Roger Horn]]&lt;br&gt;[[Pao Ming Pu]]
| known_for         = 
| awards            = 
}}
'''Charles Loewner''' (29 May 1893 – 8 January 1968) was an [[United States|American]] [[mathematician]]. His name was '''Karel Löwner''' in Czech and '''Karl Löwner''' in German.

Karl Loewner was born into a Jewish family in Lany, about 30&amp;nbsp;km from Prague, where his father Sigmund Löwner was a store owner.&lt;ref&gt;[http://www-history.mcs.st-andrews.ac.uk/Biographies/Loewner.html Loewner Biography]&lt;/ref&gt;&lt;ref&gt;[http://www.ams.org/bookstore/pspdf/surv-137-prev.pdf 2.2 Charles Loewner]&lt;/ref&gt;

Loewner received his Ph.D. from the [[Karl-Ferdinands-Universität|University of Prague]] in 1917 under supervision of [[Georg Alexander Pick|Georg Pick]].
One of his central mathematical contributions is the proof of the [[De Branges' theorem|Bieberbach conjecture]] in the first highly nontrivial case of the third coefficient. The technique he introduced, the [[Loewner differential equation]], has had far-reaching implications in [[geometric function theory]]; it was used in the final solution of the Bieberbach conjecture by [[Louis de Branges]] in 1985. Loewner worked at the [[University of Berlin]], [[Karl-Ferdinands-Universität|University of Prague]], [[University of Louisville]], [[Brown University]], [[Syracuse University]] and eventually at [[Stanford University]]. His students include [[Lipman Bers]], [[Roger Horn]], [[Adriano Garsia]], and [[P. M. Pu]].

==Loewner's torus inequality==
In 1949 Loewner proved his [[Loewner's torus inequality|torus inequality]], to the effect that every metric on the 2-torus satisfies the optimal inequality

:&lt;math&gt; \operatorname{sys}^2 \leq \frac{2}{\sqrt{3}} \operatorname{area} (\mathbb T^2),&lt;/math&gt;

where sys is its [[Systolic geometry|systole]]. The boundary case of equality is attained if and only if the metric is flat and homothetic to the so-called ''equilateral torus'', i.e. torus whose group of deck transformations is precisely the [[hexagonal lattice]] spanned by the cube roots of unity in &lt;math&gt;\mathbb C&lt;/math&gt;.

==Loewner matrix theorem==
The '''Loewner matrix''' (in [[linear algebra]]) is a [[square matrix]] or, more specifically, a [[linear operator]] (of real &lt;math&gt;C^1&lt;/math&gt; functions) associated with 2 input parameters consisting of (1) a real [[continuously differentiable]] function on a subinterval of the real numbers and (2) an &lt;math&gt;n&lt;/math&gt;-dimensional [[Vector (mathematics and physics)|vector]] with elements chosen from the subinterval; the 2 input parameters are assigned an output parameter consisting of an &lt;math&gt;n \times n&lt;/math&gt; matrix.&lt;ref name=Hiai&gt;{{cite journal|author=Hiai, Fumio|author2=Sano, Takashi|title=Loewner matrices of matrix convex and monotone functions|journal=Journal of the Mathematical Society of Japan|volume=54|issue=2|year=2012|pages=343–364|doi=10.2969/jmsj/06420343|arxiv=1007.2478}}&lt;/ref&gt;

Let &lt;math&gt;f&lt;/math&gt; be a real-valued function that is continuously differentiable on the [[open interval]] &lt;math&gt;(a,b)&lt;/math&gt;.

For any &lt;math&gt;s, t \in (a, b)&lt;/math&gt; define the '''divided difference''' of &lt;math&gt;f&lt;/math&gt; at &lt;math&gt;s, t&lt;/math&gt; as
:&lt;math&gt;f^{[1]}(s,t)=\frac{f(s)-f(t)}{s-t},&lt;/math&gt; if &lt;math&gt;s \neq t&lt;/math&gt;
:{{spaces|17}}&lt;math&gt;=f'(s)&lt;/math&gt;, if &lt;math&gt;s = t&lt;/math&gt;.
Given &lt;math&gt;t_1, \ldots, t_n \in (a,b)&lt;/math&gt;, the '''Loewner matrix''' &lt;math&gt;L_f (t_1, \ldots, t_n)&lt;/math&gt; associated with &lt;math&gt;f&lt;/math&gt; for &lt;math&gt;(t_1,\ldots,t_n)&lt;/math&gt; is defined as the &lt;math&gt;n \times n&lt;/math&gt; [[Matrix (mathematics)|matrix]] whose &lt;math&gt;(i,j)&lt;/math&gt;-entry is &lt;math&gt;f^{[1]}(t_i,t_j)&lt;/math&gt;.

In his fundamental 1934 paper, Loewner proved that for each positive integer &lt;math&gt;n&lt;/math&gt;, &lt;math&gt;f&lt;/math&gt; is [[Monotone function|&lt;math&gt;n&lt;/math&gt;-monotone]] on &lt;math&gt;(a,b)&lt;/math&gt; if and only if &lt;math&gt;L_f (t_1, \ldots, t_n)&lt;/math&gt; is [[Positive semi-definite matrix|positive semidefinite]] for any choice of &lt;math&gt;t_1,\ldots,t_n \in (a,b)&lt;/math&gt;.&lt;ref name=Hiai/&gt;&lt;ref&gt;{{cite journal|author=Löwner, Karl|title=Über monotone Matrixfunktionen|journal=Mathematische Zeitschrift|year=1934|volume=38|issue=1|pages=177–216|doi=10.1007/BF01170633}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Some classes of functions defined by difference or differential inequalities|author=Loewner, Charles|journal=Bull. Amer. Math. Soc.|volume=56|year=1950|pages=308–319|doi=10.1090/S0002-9904-1950-09405-1}}&lt;/ref&gt;  Most significantly, using this equivalence, he proved that &lt;math&gt;f&lt;/math&gt; is [[Monotone function|&lt;math&gt;n&lt;/math&gt;-monotone]] on &lt;math&gt;(a,b)&lt;/math&gt; for all &lt;math&gt;n&lt;/math&gt; if and only if &lt;math&gt;f&lt;/math&gt; is real analytic with an analytic continuation to the upper half plane that has a positive imaginary part on the upper plane.

==Book by Loewner==
*Loewner, C.: Theory of continuous groups. Notes by H. Flanders and M. Protter. Mathematicians of Our Time 1, The MIT Press, Cambridge, Mass.—London, 1971.
**{{cite book|title=Dover reprint|year=2008|url=https://books.google.com/books/about/Theory_of_Continuous_Groups.html?id=1T92V-3-gZMC}}

==See also==
* [[Loewner differential equation]]
* [[Schramm–Loewner evolution]]
* [[Loop-erased random walk]]
* [[Systolic geometry]]

==References==
*[[Marcel Berger|Berger, Marcel]]: À l'ombre de Loewner. (French) Ann. Sci. École Norm. Sup. (4) 5 (1972), 241–260.
*Loewner, Charles; Nirenberg, Louis: Partial differential equations invariant under conformal or projective transformations. Contributions to analysis (a collection of papers dedicated to Lipman Bers), pp.&amp;nbsp;245–272. Academic Press, New York, 1974.

{{Reflist}}

==External links==
* [https://web.archive.org/web/20070609204638/http://histsoc.stanford.edu/pdfmem/LoewnerC.pdf Stanford memorial resolution] 
*{{MathGenealogy |id=11755}}
*{{MacTutor Biography|id=Loewner}}

{{Authority control}}

{{DEFAULTSORT:Loewner, Charles}}
[[Category:1893 births]]
[[Category:1968 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:Czech mathematicians]]
[[Category:Mathematical analysts]]
[[Category:Jewish scientists]]
[[Category:Stanford University Department of Mathematics faculty]]</text>
      <sha1>tq9vu1ulsng75lke806f09oa0qjfnj8</sha1>
    </revision>
  </page>
  <page>
    <title>Class number problem</title>
    <ns>0</ns>
    <id>596282</id>
    <revision>
      <id>790697716</id>
      <parentid>770187855</parentid>
      <timestamp>2017-07-15T13:54:47Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>LaTeX spacing clean up, replaced: \ &lt;/math&gt; → &lt;/math&gt; (4) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8519">In [[mathematics]], the '''Gauss class number problem''' ('''for imaginary quadratic fields'''), as usually understood, is to provide for each ''n''&amp;nbsp;≥&amp;nbsp;1 a complete list of [[imaginary quadratic field]]s &lt;math&gt;\mathbb{Q}(\sqrt{d})&lt;/math&gt; (for negative integers ''d'') having [[class number (number theory)|class number]] ''n''. It is named after [[Carl Friedrich Gauss]]. It can also be stated in terms of [[Discriminant of an algebraic number field|discriminant]]s. There are related questions for real quadratic fields and for the behavior as &lt;math&gt;d \to -\infty&lt;/math&gt;.

The difficulty is in effective computation of bounds: for a given discriminant, it is easy to compute the class number, and there are several ineffective lower bounds on class number (meaning that they involve a constant that is not computed), but effective bounds (and explicit proofs of completeness of lists) are harder.

==Gauss's original conjectures==
The problems are posed in Gauss's [[Disquisitiones Arithmeticae]] of 1801 (Section V, Articles 303 and 304).&lt;ref&gt;[http://www.claymath.org/publications/Gauss_Dirichlet/stark.pdf The Gauss Class-Number Problems], by H. M. Stark&lt;/ref&gt;

Gauss discusses imaginary quadratic fields in Article 303, stating the first two conjectures, and discusses real quadratic fields in Article 304, stating the third conjecture.
;'''Gauss Conjecture''' ('''Class number tends to infinity'''): &lt;math&gt;h(d) \to \infty\text{ as }d\to -\infty.&lt;/math&gt;
;'''Gauss Class Number Problem''' ('''Low class number lists'''): For given low class number (such as 1, 2, and 3), Gauss gives lists of imaginary quadratic fields with the given class number and believes them to be complete.
;'''Infinitely many real quadratic fields with class number one''': Gauss conjectures that there are infinitely many real quadratic fields with class number one.

The original Gauss class number problem for imaginary quadratic fields is significantly different and easier than the modern statement: he restricted to even discriminants, and allowed non-fundamental discriminants.

==Status==
;'''Gauss Conjecture''': Solved, Heilbronn, 1934.
;'''Low class number lists''': Class number 1: solved, Baker (1966), Stark (1967), Heegner (1952).
:Class number 2: solved, Baker (1971), Stark (1971)&lt;ref name=irelandrosen&gt;{{citation | last1 = Ireland | first1 = K. |last2 = Rosen | first2 = M. | title = A Classical Introduction to Modern Number Theory  | publisher = Springer-Verlag | year = 1993  | location = New York, New York  | pages = 358–361  | isbn = 0-387-97329-X}}&lt;/ref&gt;
:Class number 3: solved, Oesterlé (1985)&lt;ref name=irelandrosen/&gt;
:Class numbers h up to 100: solved, Watkins 2004&lt;ref name=watkins&gt;{{citation | last1 = Watkins | first1 = M. | title = Class numbers of imaginary quadratic fields  | series = Mathematics of Computation | volume = 73 | year = 2004  | pages = 907–938 | url=http://www.ams.org/mcom/2004-73-246/S0025-5718-03-01517-5/home.html}}&lt;/ref&gt;
;'''Infinitely many real quadratic fields with class number one''': Open.

==Lists of discriminants of class number 1==
{{details|Heegner number}}
For imaginary quadratic number fields, the (fundamental) [[Imaginary quadratic field#Discriminant|discriminants]] of class number 1 are:
:&lt;math&gt;d=-3,-4,-7,-8,-11,-19,-43,-67,-163.&lt;/math&gt;
The non-fundamental discriminants of class number 1 are:
:&lt;math&gt;d=-12,-16,-27,-28.&lt;/math&gt;
Thus, the even discriminants of class number 1, fundamental and non-fundamental (Gauss's original question) are:
:&lt;math&gt;d=-4,-8,-12,-16,-28.&lt;/math&gt;

==Modern developments==
In 1934, [[Hans Heilbronn]] proved the Gauss Conjecture. Equivalently, for any given class number, there are only finitely many imaginary quadratic number fields with that class number.

Also in 1934, Heilbronn and [[Edward Linfoot]] showed that there were at most 10 imaginary quadratic number fields with class number 1 (the 9 known ones, and at most one further).
The result was ineffective (see [[effective results in number theory]]): it did not give bounds on the size of the remaining field.

In later developments, the case ''n'' = 1 was first discussed by [[Kurt Heegner]], using [[modular form]]s and [[modular equation]]s to show that no further such field could exist. This work was not initially accepted; only with later work of [[Harold Stark]] and [[Bryan Birch]] was the position clarified, and Heegner's work understood. See [[Stark–Heegner theorem]], [[Heegner number]]. Practically simultaneously, [[Alan Baker (mathematician)|Alan Baker]] proved what we now know as [[Baker's theorem]] on [[linear forms in logarithms]] of [[algebraic number]]s, which resolved the problem by a completely different method.  The case ''n'' = 2 was tackled shortly afterwards, at least in principle, as an application of Baker's work. (see {{harvtxt|Baker|1990}}.)

The complete list of imaginary quadratic fields with class number one is &lt;math&gt;\mathbf{Q}(\sqrt{k})&lt;/math&gt; with ''k'' one of
:&lt;math&gt;-1, -2, -3, -7, -11, -19, -43, -67, -163.&lt;/math&gt;

The general case awaited the discovery of [[Dorian Goldfeld]] that the class number problem could be connected to the [[L-function]]s of [[elliptic curve]]s. This reduced the question, in principle, of effective determination, to one about establishing the existence of a multiple zero of such an L-function. This could be done on the basis of the later [[Gross-Zagier theorem]]. So at that point one could specify a finite calculation, the result of which would be a complete list for a given class number. In fact in practice such lists that are ''probably'' complete can be made by relatively simple methods; what is at issue is certainty. The cases up to ''n'' = 100 have now (2004) been done: see Watkins (2004).

==Real quadratic fields==
The contrasting case of ''real'' quadratic fields is very different, and much less is known. That is because what enters the analytic formula for the class number is not ''h'', the class number, on its own &amp;mdash; but ''h''&amp;nbsp;log&amp;nbsp;''&amp;epsilon;'', where ''&amp;epsilon;'' is a [[fundamental unit (number theory)|fundamental unit]]. This extra factor is hard to control. It may well be the case that class number 1 for real quadratic fields occurs infinitely often.

The Cohen-[[Hendrik Lenstra|Lenstra]] heuristics&lt;ref&gt;Cohen, ch. 5.10&lt;/ref&gt; are a set of more precise conjectures about the structure of class groups of quadratic fields. For real fields they predict that about 75.446% of the fields obtained by adjoining the square root of a prime will have class number 1, a result that agrees with computations.&lt;ref&gt;te Riele &amp; Williams&lt;/ref&gt;

==See also==
*[[List of number fields with class number one]]

==Notes==
{{Reflist}}

==References==
* {{Citation
  | last = Goldfeld  
  | first = Dorian  
  |date=July 1985  
  | title = Gauss' Class Number Problem For Imaginary Quadratic Fields  
  | journal = [[Bulletin of the American Mathematical Society]]  
  | volume = 13
  | issue = 1  
  | pages = 23–37  
  | url = http://www.ams.org/bull/1985-13-01/S0273-0979-1985-15352-2/S0273-0979-1985-15352-2.pdf  
  | format = [[PDF]]  
  | doi = 10.1090/S0273-0979-1985-15352-2}}
*{{citation | last=Heegner | first=Kurt | authorlink=Kurt Heegner | doi=10.1007/BF01174749|mr=0053135 | title=Diophantische Analysis und Modulfunktionen | journal=[[Mathematische Zeitschrift]] | volume=56 | issue=3 | year=1952 | pages=227–253}}
* {{Citation
  | last1 = te Riele
  | first1 = Herman 
  | last2 = Williams 
  | first2 = Hugh  
  | year = 2003  
  | title = New Computations Concerning the Cohen-Lenstra Heuristics
  | journal = Experimental Mathematics
  | volume = 12
  | issue = 1  
  | pages = 99–113
  | url = http://www.emis.de/journals/EM/expmath/volumes/12/12.1/pp99_113.pdf
  | format = [[PDF]]
  | doi=10.1080/10586458.2003.10504715}}
*{{citation
  | last1 = Cohen  | first1 = Henri
  | title = A Course in Computational Algebraic Number Theory
  | publisher = [[Springer Science+Business Media|Springer]]
  | location = Berlin
  | year = 1993
  | isbn = 3-540-55640-0}}
*{{Citation 
  | last1=Baker
  | first1=Alan
  | title=Transcendental number theory
  | url=https://books.google.com/books?isbn=052139791X
  | publisher=[[Cambridge University Press]]
  | edition=2nd | series=Cambridge Mathematical Library
  | isbn=978-0-521-39791-9
  | mr=0422171
  | year=1990}}

==External links==
* {{MathWorld|title=Gauss's Class Number Problem|urlname=GausssClassNumberProblem}}

[[Category:Algebraic number theory]]
[[Category:Mathematical problems]]</text>
      <sha1>jpphqt07j87bjsgk8nptvxr73q3treu</sha1>
    </revision>
  </page>
  <page>
    <title>Complex adaptive system</title>
    <ns>0</ns>
    <id>1428810</id>
    <revision>
      <id>866398206</id>
      <parentid>847886338</parentid>
      <timestamp>2018-10-30T02:28:26Z</timestamp>
      <contributor>
        <username>Hz.cmu</username>
        <id>30546814</id>
      </contributor>
      <comment>Removed dead linkedin link.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23741">{{Use dmy dates|date=July 2013}}
A '''complex adaptive system''' is a system in which a perfect understanding of the individual parts does not automatically convey a perfect understanding of the whole system's behavior.&lt;ref name="Miller, John H., and Scott E. Page"&gt;{{Cite book|url=https://www.worldcat.org/oclc/760073369|title=Complex adaptive systems : an introduction to computational models of social life|last=Miller, John H., and Scott E. Page|date=2007-01-01|publisher=Princeton University Press|isbn=9781400835522|location=|pages=|oclc=760073369}}&lt;/ref&gt; The study of complex adaptive systems, a subset of [[nonlinear dynamical system]]s,&lt;ref name="Lansing 2003 pp. 183–204"&gt;{{cite journal | last=Lansing | first=J. Stephen | title=Complex Adaptive Systems | journal=Annual Review of Anthropology | publisher=Annual Reviews | volume=32 | issue=1 | year=2003 | issn=0084-6570 | doi=10.1146/annurev.anthro.32.061002.093440 | pages=183–204}}&lt;/ref&gt; is highly interdisciplinary and blends insights from the natural and social sciences to develop system-level models and insights that allow for [[heterogeneous agents]], [[phase transition]], and [[emergent behavior]].&lt;ref&gt;{{Cite news|url=http://www.slate.com/articles/technology/bitwise/2016/01/a_crude_look_at_the_whole_looks_at_complexity_theory_which_wants_to_understand.html|title=The Theory of Everything and Then Some|last=Auerbach|first=David|date=2016-01-19|work=Slate|access-date=2017-03-07|language=en-US|issn=1091-2339}}&lt;/ref&gt;

They are ''[[complex system|complex]]'' in that they are [[Dynamic network analysis|dynamic networks of interactions]], and their relationships are not aggregations of the individual static entities, i.e., the behavior of the ensemble is not predicted by the behavior of the components.  They are ''[[adaptive]]'' in that the individual and [[collective behavior]] mutate and [[self-organizing|self-organize]] corresponding to the change-initiating micro-event or collection of events.&lt;ref name=CAS-T-01/&gt;&lt;ref name=CAS-T-02/&gt;&lt;ref name="Miller, John H., and Scott E. Page"/&gt; They are a "complex macroscopic collection" of relatively "similar and partially connected micro-structures" formed in order to [[Adaptive system|adapt]] to the changing environment and increase their survivability as a [[macrostructure (sociology)|macro-structure]].&lt;ref name=CAS-T-01/&gt;&lt;ref name=CAS-T-02/&gt;&lt;ref name=CAS-T-12/&gt;

== Overview ==
The term ''complex adaptive systems'', or ''[[complexity science]]'', is often used to describe the loosely organized academic field that has grown up around the study of such systems.  Complexity science is not a single theory&amp;mdash;it encompasses more than one theoretical framework and is highly interdisciplinary, seeking the answers to some fundamental questions about [[life|living]], adaptable, changeable systems. The study of CAS focuses on complex, emergent and macroscopic properties of the system.&lt;ref name="CAS-T-12" /&gt;&lt;ref name="CAS-T-11" /&gt;&lt;ref name="CAS-T-13" /&gt; [[John Henry Holland|John H. Holland]] said that CAS "are systems that have a large numbers of components, often called agents, that interact and adapt or learn."&lt;ref&gt;{{cite journal|year=2006|title=Studying Complex Adaptive Systems|url=http://hdl.handle.net/2027.42/41486|journal=Journal of Systems Science and Complexity|volume=19|issue=1|pages=1–8|doi=10.1007/s11424-006-0001-z|author=Holland John H}}&lt;/ref&gt;

Typical examples of complex adaptive systems include: climate; cities; firms; markets; governments; industries; ecosystems; social networks; power grids; animal swarms; traffic flows; [[social insect]] (e.g. [[ant]]) colonies;&lt;ref name=AFC-NA-21/&gt; the [[brain]] and the [[immune system]]; and the [[cell (biology)|cell]] and the developing [[embryo]]. Human social group-based endeavors, such as [[political party|political parties]], [[community|communities]], [[geopolitical]] [[organisations|organizations]], [[war]], and [[terrorist network analysis|terrorist networks]] are also considered CAS.&lt;ref name=AFC-NA-21/&gt;&lt;ref name=GT-33/&gt;&lt;ref name=CAS-T-19&gt;{{cite web|first=Samuel|last=Solvit|title=Dimensions of War: Understanding War as a Complex Adaptive System|url=http://dimensionsofwar.com/|publisher=L'Harmattan|year=2012|accessdate=25 August 2013}}&lt;/ref&gt; The [[internet]] and [[cyberspace]]—composed, collaborated, and managed by a complex mix of [[human–computer interaction]]s, is also regarded as a complex adaptive system.&lt;ref name=CAS-T-16/&gt;&lt;ref name=CAS-T-17/&gt;&lt;ref name=CAS-T-18/&gt; CAS can be hierarchical, but more often exhibit aspects of "self-organization."&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/970420200|title=Hidden order : how adaptation builds complexity|last=Holland, John H. (John Henry),|first=|date=1996|publisher=Addison-Wesley|year=|isbn=0201442302|location=|pages=|oclc=970420200}}&lt;/ref&gt;

=== General properties ===
What distinguishes a CAS from a pure [[multi-agent system]] (MAS) is the focus on top-level properties and features like [[self-similarity]], [[complexity]], [[emergence]] and [[self-organization]]. A MAS is defined as a system composed of multiple interacting agents; whereas in CAS, the agents as well as the system are adaptive and the system is [[self-similar]]. A CAS is a complex, self-similar collectivity of interacting, adaptive agents.  Complex Adaptive Systems are characterized by a high degree of [[adaptive capacity]], giving them resilience in the face of [[wikt:perturbation|perturbation]].

Other important properties are adaptation (or [[homeostasis]]), communication, cooperation, specialization, spatial and temporal organization, and reproduction. They can be found on all levels: cells specialize,  adapt and reproduce themselves just like larger organisms do. Communication and cooperation take place on all levels, from the agent to the system level. The forces driving [[co-operation]] between agents in such a system, in some cases, can be analyzed with [[game theory]].

=== Characteristics ===

Some of the most important characteristics of complex systems are:&lt;ref&gt;[[Paul Cilliers]] (1998) ''Complexity and Postmodernism: Understanding Complex Systems''&lt;/ref&gt;

* The number of elements is sufficiently large that conventional descriptions (e.g. a system of [[differential equation]]s) are not only impractical, but cease to assist in understanding the system. Moreover, the elements interact dynamically, and the interactions can be physical or involve the exchange of information
* Such interactions are rich, i.e. any element or sub-system in the system is affected by and affects several other elements or sub-systems
* The interactions are [[non-linear]]: small changes in inputs, physical interactions or stimuli can cause large effects or very significant changes in outputs
* Interactions are primarily but not exclusively with immediate neighbours and the nature of the influence is modulated
* Any interaction can feed back onto itself directly or after a number of intervening stages. Such feedback can vary in quality.  This is known as ''recurrency''
* The overall behavior of the system of elements is not predicted by the behavior of the individual elements 
* Such systems may be open and it may be difficult or impossible to define system boundaries
* Complex systems operate under [[Non-equilibrium thermodynamics|far from equilibrium]] conditions. There has to be a constant flow of energy to maintain the organization of the system
* Complex systems have a history. They evolve and their past is co-responsible for their present behaviour
* Elements in the system may be ignorant of the behaviour of the system as a whole, responding only to the information or physical stimuli available to them locally

[[Robert Axelrod]] &amp; [[Michael D. Cohen (academic)|Michael D. Cohen]]&lt;ref&gt;[[Robert Axelrod]] &amp; [[Michael D. Cohen (academic)|Michael D. Cohen]], ''Harnessing Complexity''. [[Basic Books]], 2001&lt;/ref&gt; identify a series of key terms from a modeling perspective:
* '''Strategy''', a conditional action pattern that indicates what to do in which circumstances
* '''Artifact''', a material resource that has definite location and can respond to the action of agents
* '''Agent''', a collection of properties, strategies &amp; capabilities for interacting with artifacts &amp; other agents
* '''Population''', a collection of agents, or, in some situations, collections of strategies
* '''System''', a larger collection, including one or more populations of agents and possibly also artifacts
* '''Type''', all the agents (or strategies) in a population that have some characteristic in common
* '''Variety''', the diversity of types within a population or system
* '''Interaction pattern''', the recurring regularities of contact among types within a system
* '''Space (physical)''', location in geographical space &amp; time of agents and artifacts
* '''Space (conceptual)''', "location" in a set of categories structured so that "nearby" agents will tend to interact
* '''Selection''', processes that lead to an increase or decrease in the frequency of various types of agent or strategies
* '''Success criteria''' or '''performance measures''', a "score" used by an agent or designer in attributing credit in the selection of relatively successful (or unsuccessful) strategies or agents

== Modeling and simulation ==
CAS are occasionally modeled by means of [[agent-based model]]s and [[complex network]]-based models.&lt;ref&gt;Muaz A. K. Niazi, Towards A Novel Unified Framework for Developing Formal, Network and Validated Agent-Based Simulation Models of Complex Adaptive Systems [https://dspace.stir.ac.uk/handle/1893/3365 PhD Thesis]&lt;/ref&gt; Agent-based models are developed by means of various methods and tools primarily by means of first identifying the different agents inside the model.&lt;ref&gt;John H. Miller &amp; Scott E. Page, Complex Adaptive Systems: An Introduction to Computational Models of Social Life, Princeton University Press [http://press.princeton.edu/titles/8429.html Book page]&lt;/ref&gt; Another method of developing models for CAS involves developing complex network models by means of using interaction data of various CAS components.&lt;ref&gt;Melanie Mitchell, Complexity A Guided Tour, Oxford University Press, [http://www.oup.com/us/catalog/general/subject/LifeSciences/~~/dmlldz11c2EmY2k9OTc4MDE5NTEyNDQxNQ== Book page]&lt;/ref&gt;

In 2013 [[SpringerOpen|SpringerOpen/BioMed Central]] has launched an online open-access journal on the topic of ''complex adaptive systems modeling'' (CASM).&lt;ref&gt;Springer ''[https://casmodeling.springeropen.com/ Complex Adaptive Systems Modeling Journal]'' (CASM)&lt;/ref&gt;

== Evolution of complexity ==
[[File:Evolution of complexity.svg|thumb|300px|Passive versus active trends in the evolution of complexity. CAS at the beginning of the processes are colored red. Changes in the number of systems are shown by the height of the bars, with each set of graphs moving up in a time series.]]

{{Main|Evolution of biological complexity}}

Living organisms are complex adaptive systems. Although complexity is hard to quantify in biology, [[evolution]] has produced some remarkably complex organisms.&lt;ref&gt;{{cite journal |author=Adami C |title=What is complexity? |journal=BioEssays |volume=24 |issue=12 |pages=1085–94 |year=2002 |pmid=12447974 |doi=10.1002/bies.10192}}&lt;/ref&gt; This observation has led to the common misconception of evolution being progressive and leading towards what are viewed as "higher organisms".&lt;ref&gt;{{cite journal |author=McShea D |title=Complexity and evolution: What everybody knows |journal=Biology and Philosophy |volume=6 |issue=3 |pages=303–24 |year=1991 |doi=10.1007/BF00132234}}&lt;/ref&gt;

If this were generally true, evolution would possess an active trend towards complexity. As shown below, in this type of process the value of the most common amount of complexity would increase over time.&lt;ref name=Carroll&gt;{{cite journal |author=Carroll SB |title=Chance and necessity: the evolution of morphological complexity and diversity |journal=Nature |volume=409 |issue=6823 |pages=1102–9 |year=2001 |pmid=11234024 |doi=10.1038/35059227|bibcode = 2001Natur.409.1102C }}&lt;/ref&gt; Indeed, some [[artificial life]] simulations have suggested that the generation of CAS is an inescapable feature of evolution.&lt;ref&gt;{{cite journal |vauthors=Furusawa C, Kaneko K |title=Origin of complexity in multicellular organisms |journal=Phys. Rev. Lett. |volume=84 |issue=26 Pt 1 |pages=6130–3 |year=2000 |pmid=10991141 |doi=10.1103/PhysRevLett.84.6130 |bibcode=2000PhRvL..84.6130F|arxiv = nlin/0009008 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |vauthors=Adami C, Ofria C, Collier TC |title=Evolution of biological complexity |url=http://www.pnas.org/cgi/content/full/97/9/4463 |journal=Proc. Natl. Acad. Sci. U.S.A. |volume=97 |issue=9 |pages=4463–8 |year=2000 |pmid=10781045 |doi=10.1073/pnas.97.9.4463 |pmc=18257|arxiv = physics/0005074 |bibcode = 2000PNAS...97.4463A }}&lt;/ref&gt;

However, the idea of a general trend towards complexity in evolution can also be explained through a passive process.&lt;ref name=Carroll/&gt; This involves an increase in [[variance]] but the most common value, the [[mode (statistics)|mode]], does not change. Thus, the maximum level of complexity increases over time, but only as an indirect product of there being more organisms in total. This type of random process is also called a bounded [[random walk]].

In this hypothesis, the apparent trend towards more complex organisms is an illusion resulting from concentrating on the small number of large, very complex organisms that inhabit the [[Skewness|right-hand tail]] of the complexity distribution and ignoring simpler and much more common organisms. This passive model emphasizes that the overwhelming majority of species are [[microorganism|microscopic]] [[prokaryote]]s,&lt;ref&gt;{{cite journal |author=Oren A |title=Prokaryote diversity and taxonomy: current status and future challenges |pmc=1693353 |journal=Philos. Trans. R. Soc. Lond. B Biol. Sci. |volume=359 |issue=1444 |pages=623–38 |year=2004 |pmid=15253349 |doi=10.1098/rstb.2003.1458}}&lt;/ref&gt; which comprise about half the world's [[biomass]]&lt;ref&gt;{{cite journal |vauthors=Whitman W, Coleman D, Wiebe W | title = Prokaryotes: the unseen majority | url=http://www.pnas.org/cgi/content/full/95/12/6578 | journal = Proc Natl Acad Sci USA | volume = 95 | issue = 12 | pages = 6578–83 | year = 1998 |pmid = 9618454 | doi = 10.1073/pnas.95.12.6578 | pmc = 33863|bibcode = 1998PNAS...95.6578W }}&lt;/ref&gt; and constitute the vast majority of Earth's biodiversity.&lt;ref&gt;{{cite journal |vauthors=Schloss P, Handelsman J |title=Status of the microbial census  |pmc=539005 |url=http://mmbr.asm.org/cgi/pmidlookup?view=long&amp;pmid=15590780 |journal=Microbiol Mol Biol Rev |volume=68 |issue=4 |pages=686–91 |year=2004 |pmid=15590780 |doi=10.1128/MMBR.68.4.686-691.2004}}&lt;/ref&gt; Therefore, simple life remains dominant on Earth, and complex life appears more diverse only because of [[sampling bias]].

If there is a lack of an overall trend towards complexity in biology, this would not preclude the existence of forces driving systems towards complexity in a subset of cases. These minor trends would be balanced by other evolutionary pressures that drive systems towards less complex states.

== See also ==
{{Portal|Systems science}}
{{div col|colwidth=30em}}
* [[Artificial life]]
* [[Chaos theory]]
* [[Cognitive science]]
* [[Command and Control Research Program]]
* [[Complex system]]
* [[Computational economics]]
* [[Computational sociology]]
* [[Dual-phase evolution]]
* [[Enterprise systems engineering]]
* [[Generative sciences]]
* [[Open system (systems theory)]]
* [[Santa Fe Institute]]
* [[Simulated reality]]
* [[Sociology and complexity science]]
* [[Wicked problem|Super wicked problem]]
* [[Swarm Development Group]]
* [[Universal Darwinism]]
{{div col end}}

==References==
{{Reflist|2|refs=
&lt;ref name=CAS-T-01&gt;{{cite web |url=http://tejas.iimb.ac.in/articles/12.php|title=Insights from Complexity Theory: Understanding Organisations better |publisher= by Assoc. Prof. Amit Gupta, Student contributor - S. Anish, IIM Bangalore|date= |accessdate=1 June 2012 }}&lt;/ref&gt;

&lt;ref name=CAS-T-02&gt;{{cite web |url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.3514&amp;rep=rep1&amp;type=pdf|title=Ten Principles of Complexity &amp; Enabling Infrastructures |publisher= by Professor Eve Mitleton-Kelly, Director Complexity Research Programme, London School of Economics |date= |accessdate=1 June 2012 }}&lt;/ref&gt;

&lt;ref name=CAS-T-11&gt;{{cite web|title=A Complex Adaptive Organization Under the Lens of the LIFE Model:The Case of Wikipedia|url=https://otago.academia.edu/JeanBaptisteFaucher/Papers/489796/A_Complex_Adaptive_Organization_Under_the_Lens_of_the_LIFE_Model_The_Case_of_Wikipedia|accessdate=25 August 2012}}&lt;/ref&gt;

&lt;ref name=CAS-T-12&gt;{{cite web|title=Evolutionary Psychology, Complex Systems, and Social Theory|url=http://web.eecs.utk.edu/~mclennan/papers/EPCSST.pdf|work=Bruce MacLennan, Department of Electrical Engineering &amp; Computer Science, University of Tennessee, Knoxville|publisher=eecs.utk.edu|accessdate=25 August 2012}}&lt;/ref&gt;

&lt;ref name=CAS-T-13&gt;{{cite web|title=Complex Adaptive Systems as a Model for Evaluating Organisational : Change Caused by the Introduction of Health Information Systems|url=http://www.uow.edu.au/~kd21/uploads/Diment-complexity.pdf|work=Kieren Diment, Ping Yu, Karin Garrety, Health Informatics Research Lab, Faculty of Informatics, University of Wollongong, School of Management, University of Wollongong, NSW|publisher=uow.edu.au|accessdate=25 August 2012|deadurl=yes|archiveurl=https://web.archive.org/web/20120905170544/http://www.uow.edu.au/~kd21/uploads/Diment-complexity.pdf|archivedate=5 September 2012|df=dmy-all}}&lt;/ref&gt;

&lt;ref name=CAS-T-16&gt;{{cite web|title=The Internet Analyzed as a Complex Adaptive System|url=http://spacecollective.org/aloksubbarao/5730/The-Internet-Analyzed-as-a-Complex-Adaptive-System|accessdate=25 August 2012}}&lt;/ref&gt;

&lt;ref name=CAS-T-17&gt;{{cite web|title=Cyberspace: The Ultimate Complex Adaptive System|url=http://www.dodccrp.org/files/IC2J_v4n2_03_Phister.pdf|publisher=The International C2 Journal
|accessdate=25 August 2012}} by Paul W. Phister Jr&lt;/ref&gt;

&lt;ref name=CAS-T-18&gt;{{cite web|title=Complex Adaptive Systems|url=http://web.mit.edu/esd.83/www/notebook/Complex%20Adaptive%20Systems.pdf|publisher=mit.edu|year=2001|accessdate=25 August 2012}} by Serena Chan, Research Seminar in Engineering Systems&lt;/ref&gt;

&lt;ref name=AFC-NA-21&gt;[[Steven Strogatz]], [[Duncan J. Watts]] and [[Albert-Laszlo Barabasi]] {{cite web |title =  explaining synchronicity  ''(at 6:08)'', network theory, self-adaptation mechanism of complex systems, Six Degrees of separation, Small world phenomenon, events are never isolated as they depend upon each other ''(at 27:07)'' in the BBC / Discovery Documentary |work = BBC / Discovery  |url=http://topdocumentaryfilms.com/six-degrees-of-separation/|publisher= |page =  |date=|accessdate=11 June 2012}} "Unfolding the science behind the idea of six degrees of separation"&lt;/ref&gt;

&lt;ref name=GT-33&gt;{{cite web|title=Toward a Complex Adaptive Intelligence Community The Wiki and the Blog|url=https://www.cia.gov/library/center-for-the-study-of-intelligence/csi-publications/csi-studies/studies/vol49no3/html_files/Wik_and_%20Blog_7.htm|work=D. Calvin Andrus|publisher=cia.gov|accessdate=25 August 2012}}&lt;/ref&gt;

}}

== Literature ==
{{refbegin|2}}
*{{cite journal |vauthors=Ahmed E, Elgazzar AS, Hegazi AS |title=An overview of complex adaptive systems |journal=Mansoura J. Math |volume=32 |pages=6059 |date=28 June 2005 |bibcode=2005nlin......6059A |id=arXiv:nlin/0506059v1 [nlin.AO] |arxiv=nlin/0506059}}
*{{Cite journal |vauthors=Bullock S, Cliff D |title=Complexity and Emergent Behaviour in ICT Systems |publisher=Hewlett-Packard Labs |year=2004 |url=http://www.hpl.hp.com/techreports/2004/HPL-2004-187.html |id=HP-2004-187}}; commissioned as a [https://web.archive.org/web/20090207162407/http://www.foresight.gov.uk/OurWork/CompletedProjects/IIS/Docs/ComplexityandEmergentBehaviour.asp report] by the UK government's [http://www.foresight.gov.uk/ Foresight Programme].
* Dooley, K., ''Complexity in Social Science'' glossary a research training project of the European Commission.
*{{cite book |author1=Edwin E. Olson |author2=Glenda H. Eoyang |title=Facilitating Organization Change |publisher=Jossey-Bass |location=San Francisco |year=2001 |isbn=0-7879-5330-X }}
*{{cite book |author=Gell-Mann, Murray |title=The quark and the jaguar: adventures in the simple and the complex |publisher=W.H. Freeman |location=San Francisco |year=1994 |isbn=0-7167-2581-9 }}
*{{cite book |author=Holland, John H. |title=Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence |publisher=MIT Press |location=Cambridge, Massachusetts |year=1992 |isbn=0-262-58111-6 }}
*{{cite book |author=Holland, John H. |title=Emergence: from chaos to order |publisher=Perseus Books |location=Reading, Mass |year=1999 |isbn=0-7382-0142-1 }}
*{{cite book |author=Solvit, Samuel |title=Dimensions of War: Understanding War as a Complex Adaptive System |publisher=L'Harmattan |location=Paris, France |year=2012 |isbn=978-2-296-99721-9 }}
*{{cite book |author=[[Kevin Kelly (editor)|Kelly, Kevin]] |title=Out of control: the new biology of machines, social systems and the economic world |publisher=Addison-Wesley |location=Boston |year=1994 |isbn=0-201-48340-8 |url=http://www.kk.org/outofcontrol/contents.php |format=Full text available online}}
* {{Not a typo|Pharaoh}}, M.C. (online). [http://homepage.ntlworld.com/m.pharoah/ Looking to systems theory for a reductive explanation of phenomenal experience and evolutionary foundations for higher order thought] Retrieved 15 January 2008.
* Hobbs, George &amp; Scheepers, Rens (2010),"Agility in Information Systems: Enabling Capabilities for the IT Function," ''Pacific Asia Journal of the Association for Information Systems'': Vol. 2: Iss. 4, Article 2. [http://aisel.aisnet.org/pajais/vol2/iss4/2 Link]
*{{cite book |author=Sidney Dekker|authorlink=Sidney Dekker|title=Drift into Failure: From Hunting Broken Components to Understanding Complex Systems|date=2011|publisher=CRC Press}}

{{refend}}

==External links==
{{commons category|Complex adaptive systems}}
*[http://www.cas-group.net/ Complex Adaptive Systems Group] loosely coupled group of scientists and software engineers interested in complex adaptive systems
*[http://www.dnawales.co.uk/ DNA Wales Research Group] Current Research in Organisational change CAS/CES related news and free research data. Also linked to the Business Doctor &amp; BBC documentary series
*[http://pespmc1.vub.ac.be/CAS.html A description] of complex adaptive systems on the Principia Cybernetica Web.
* [http://bactra.org/notebooks/complexity.html Quick reference] single-page description of the 'world' of complexity and related ideas hosted by the Center for the Study of Complex Systems at the University of Michigan.
*[http://www.complexsystems.net.au/ Complex systems research network]
* [https://web.archive.org/web/20090105183805/http://www.openabm.org/site/ The Open Agent-Based Modeling Consortium]
*[https://www.youtube.com/watch?v=jS0zj_dYeBE TEDxRotterdam - Igor Nikolic - Complex adaptive systems], and [https://www.youtube.com/watch?v=AB85AFzqtOY The emergence of universal consciousness: Brendan Hughes at TEDxPretoria ]. Talks discussing various practical examples of complex adaptive systems, including Wikipedia, star galaxies, genetic mutation, and other examples

{{Systems}}

{{DEFAULTSORT:Complex Adaptive System}}
[[Category:Complex systems theory]]
[[Category:Systems]]
[[Category:Organizational theory|*]]</text>
      <sha1>n08culrvliuvqczidq4pn440z9hq8mw</sha1>
    </revision>
  </page>
  <page>
    <title>Continuous linear operator</title>
    <ns>0</ns>
    <id>1802169</id>
    <revision>
      <id>860892933</id>
      <parentid>859176759</parentid>
      <timestamp>2018-09-23T19:42:37Z</timestamp>
      <contributor>
        <ip>23.25.65.18</ip>
      </contributor>
      <comment>/* Definition */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1661">In [[functional analysis]] and related areas of [[mathematics]], a '''continuous linear operator''' or '''continuous linear mapping''' is a [[continuous function (topology)|continuous]] [[linear transformation]] between [[topological vector space]]s.

An operator between two [[normed space]]s is a [[bounded linear operator]] if and only if it is a continuous linear operator.

== Definition ==

If for every &lt;math&gt;\epsilon&gt;0&lt;/math&gt; there exists a &lt;math&gt;\delta &gt; 0&lt;/math&gt; such that
&lt;math&gt;||x - y||&lt;\delta \Rightarrow ||Ax - Ay||&lt;\epsilon&lt;/math&gt;
we say the operator &lt;math&gt;A&lt;/math&gt; is continuous.

== Properties ==

A continuous linear operator maps [[Bounded set (topological vector space)|bounded set]]s into bounded sets. A [[linear functional]] is continuous if and only if its [[Kernel_(linear_operator)|kernel]] is closed. Every linear function on a finite-dimensional space is continuous.

The following are equivalent: given a linear operator ''A'' between topological spaces ''X'' and ''Y'':
# ''A'' is continuous at 0 in ''X''.
# ''A'' is continuous at some point &lt;math&gt;x_0&lt;/math&gt; in ''X''.
# ''A'' is continuous everywhere in ''X''.

The proof uses the facts that the translation of an open set in a linear topological space is again an open set, and the equality
: &lt;math&gt;A^{-1}(D)+x_0=A^{-1}(D+Ax_0) \,\!&lt;/math&gt;
for any set ''D'' in ''Y'' and any ''x''&lt;sub&gt;0&lt;/sub&gt; in ''X'', which is true due to the additivity of ''A''.

==References==
*{{cite book |last=Rudin |first=Walter |title=Functional Analysis |date=January 1991 |publisher=McGraw-Hill Science/Engineering/Math |isbn=0-07-054236-8}}

{{Functional Analysis}}

[[Category:Functional analysis]]</text>
      <sha1>50ne8660g59zsyodmepxuexsccn4s4k</sha1>
    </revision>
  </page>
  <page>
    <title>Convenient vector space</title>
    <ns>0</ns>
    <id>43466503</id>
    <revision>
      <id>860231204</id>
      <parentid>822492681</parentid>
      <timestamp>2018-09-19T07:27:33Z</timestamp>
      <contributor>
        <username>Pwm86</username>
        <id>19361757</id>
      </contributor>
      <minor/>
      <comment>Made note Note 1 more clear.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20994">In mathematics, '''convenient vector spaces''' are  [[locally convex]] vector spaces satisfying a very mild [[Uniform space#Completeness|completeness condition]]. 
 
Traditional [[Multivariable calculus|differential calculus]] is effective in the analysis of finite-dimensional [[vector space]]s and for [[Banach space]]s. Beyond Banach spaces, difficulties begin to arise; in particular, composition of [[Continuous linear operator|continuous linear mappings]] stop being jointly continuous at the level of Banach spaces,{{refn|group=Note|An example of a composition mapping is the evaluation mapping {{math|ev: ''E'' × ''E''{{su|p=∗}} → ℝ}}, where {{math|''E''}} is a [[Locally convex topological vector space|locally convex vector space]], and where  {{math|''E''{{su|p=∗}}}} is its [[Dual space|dual]] of continuous linear functionals equipped with any locally convex topology such that the evaluation mapping is separately continuous. If the evaluation is assumed to be jointly continuous, then there are neighborhoods {{math|''U'' ⊆ ''E''}} and {{math|''V'' ⊆ ''E''{{su|p=∗}}}} of zero such that {{math|ev(''U'' × ''V'') ⊆ [0,1]}}. However, this means that {{math|''U''}} is contained in the [[Polar set|polar]] of the open set {{math|''V''}}; so it is bounded in {{math|''E''}}. Thus {{math|''E''}} admits a bounded neighborhood of zero, and is thus a [[normed vector space]].}} for any compatible topology on the spaces of continuous linear mappings.

Mappings between convenient vector spaces are '''smooth''' or {{math|''C''{{su|p=∞}}}} if they map smooth curves to smooth curves. This leads to a [[Cartesian closed category]] of smooth mappings between {{math|''c''{{su|p=∞}}}}-open subsets of convenient vector spaces (see property 6 below). The corresponding calculus of smooth mappings is called ''convenient calculus''.
It is weaker than any other reasonable notion of differentiability, it is easy to apply, but there are smooth mappings which are not continuous (see Note 1).
This type of calculus alone is not useful in solving equations{{refn|group=Note|In order to be useful for solving equations like nonlinear PDE's, convenient calculus has to be supplemented by, for example,  [[a priori estimate]]s which help to create enough Banach space situation to allow convergence of some iteration procedure; for example, see the [[Nash–Moser theorem]], described in terms of convenient calculus in [KM], section 51.}}.

==The {{math|''c''{{su|p=∞}}}}-topology==
Let {{math|''E''}} be a locally convex vector space. A curve {{math|''c'' : ℝ → ''E''}} is called ''smooth'' or  {{math|''C''{{su|p=∞}}}} if all derivatives exist and are continuous. Let 
{{math|''C''{{su|p=∞}}(ℝ,''E'')}} be the space of smooth curves. It can be shown that the set of smooth curves does not depend entirely on the locally convex 
topology of ''E'', only on its associated [[Bornological space|bornology]] (system of bounded sets); see [KM], 2.11.
The final topologies with respect to the following sets of mappings into {{math|''E''}} coincide; see [KM], 2.13.
* {{math|''C''{{su|p=∞}}(ℝ,''E'')}}.
* The set of all Lipschitz curves (so that {{math|{(''c''(''t'')&amp;nbsp;&amp;minus;&amp;nbsp;''c''(''s''))/(''t''&amp;nbsp;&amp;minus;&amp;nbsp;''s'') : ''t'' ≠ ''s'', {{!}}''t''{{!}},{{!}}''s''{{!}}≤ ''C''}}} is bounded in {{math|''E''}}, for each {{math|''C''}}). 
* The set of injections {{math|''E''{{su|b=''B''}}→ ''E''}} where {{math|''B''}} runs through all bounded [[Absolutely convex set|absolutely convex]] subsets in {{math|''E''}}, and where  {{math|''E''{{su|b=''B''}}}} is the linear span of  {{math|''B''}} equipped with the [[Minkowski functional]] {{math|{{!!}}''x''{{!!}}{{su|b=''B''}} :{{=}} inf {λ &gt; 0 :''x'' ∈  λ ''B''} }}.
* The set of all Mackey-convergent sequences {{math|''x''{{su|b=''n''}} → ''x''}} (there exists a sequence {{math| 0 &lt; λ{{su|b=''n''}} → ∞}} with {{math|λ{{su|b=''n''}}(''x''{{su|b=''n''}}&amp;nbsp;&amp;minus;&amp;nbsp;''x'')}} bounded).
This topology is called the {{math|''c''{{su|p=∞}}}}-''topology'' on {{math|''E''}} and we write 
{{math|''c''{{su|p=∞}}''E''}} for the resulting topological space. 
In general 
(on the space {{math|''D''}} of smooth functions with compact support on the real line, for example) it is finer 
than the given locally convex topology, it is not a vector space 
topology, since addition is no longer jointly continuous. Namely, even 
{{math|''c''{{su|p=∞}}(''D'' × ''D'') ≠ (''c''{{su|p=∞}}''D'') × (''c''{{su|p=∞}}''D'')}}.
The finest among all locally convex topologies on {{math|''E''}} 
which are coarser than {{math|''c''{{su|p=∞}}''E''}} is the bornologification of the 
given locally convex topology. If  {{math|''E''}} is a Fréchet space, then  {{math|''c''{{su|p=∞}}''E'' {{=}} ''E''}}.

==Convenient vector spaces==
A locally convex vector space  {{math|''E''}} is said to be a ''convenient vector space'' if one of the following equivalent conditions holds (called  {{math|''c''{{su|p=∞}}}}-completeness); see [KM], 2.14.
* For any {{math|''c'' ∈ ''C''{{su|p=∞}}(ℝ,''E'')}} the (Riemann-) integral {{math|∫{{su|p=1|b=0}} ''c''(''t'') d''t''}} exists in  {{math|''E''}}.
* Any Lipschitz curve in  {{math|''E''}} is locally Riemann integrable.
* Any ''scalar wise'' {{math|''C''{{su|p=∞}}}} curve is {{math|''C''{{su|p=∞}}}}: A curve  {{math|''c'' : ℝ → ''E''}} is smooth if and only if the composition {{math|λ o ''c'' : ''t'' → λ(''c''(''t''))}}  is in {{math|''C''{{su|p=∞}}(ℝ,ℝ)}} for all {{math|λ ∈ ''E''{{su|p=∗}}}}, where {{math|''E''{{su|p=∗}}}} is the dual of all continuous linear functionals on {{math|''E''}}.   
** Equivalently, for all {{math|λ ∈ ''E''′}}, the dual  of all bounded linear functionals. 
** Equivalently, for all {{math|λ ∈ ''V''}}, where {{math|''V''}} is a subset of {{math|''E''′}} which recognizes bounded subsets in {{math|''E''}}.
* Any Mackey-Cauchy-sequence (i. e.,  {{math|''t''{{su|b=nm}}(''x''{{su|b-n}}&amp;nbsp;&amp;minus;&amp;nbsp;''x''{{su|b=m}}) → 0}} for some  {{math|''t''{{su|b=nm}} → ∞}} in  {{math|'''R'''}}) converges in {{math|''E''}}. This is visibly a mild completeness requirement.
* If  {{math|''B''}} is bounded closed absolutely convex, then  {{math|''E''{{su|b=''B''}}}} is a Banach space.
* If {{math|''f'' : ℝ → ''E''}} is scalar wise {{math|Lip{{su|p=''k''}}}}, then {{math|f}} is {{math|Lip{{su|p=''k''}}}}, for {{math|''k &gt; 1}}.
* If {{math|''f'' : ℝ → ''E''}} is scalarwise {{math|''C''{{su|p=∞}}}} then {{math|''f''}} is differentiable at 0.
Here a mapping {{math|''f'' : ℝ → ''E''}} is called {{math|Lip{{su|p=''k''}}}} if all 
derivatives up to order {{math|''k''}} exist and are Lipschitz, locally on {{math|'''R'''}}.

==Smooth mappings==
Let {{math|''E''}} and {{math|''F''}} be convenient vector spaces, 
and let  {{math|''U'' ⊆ ''E''}} be {{math|''c''{{su|p=∞}}}}-open. 
A mapping {{math|''f'' : ''U'' → ''F''}} is called ''smooth'' or 
{{math|''C''{{su|p=∞}}}}, if the composition {{math|''f'' o ''c'' ∈ ''C''{{su|p=∞}}(ℝ,''F'')}} for all  {{math|''c'' ∈ ''C''{{su|p=∞}}(ℝ,''U'')}}. See[KM], 3.11.

==Main properties of smooth calculus==

1. For maps on Fréchet spaces this notion of smoothness coincides with all other reasonable definitions. On {{math|ℝ{{su|p=2}}}} this is a non-trivial theorem, proved by Boman, 1967. See also [KM], 3.4.

2. Multilinear mappings are smooth if and only if they are bounded ([KM], 5.5).

3. If {{math|''f'': ''E'' ⊇ ''U'' → F}} is smooth then the derivative {{math|d''f'' : ''U'' × ''E'' → ''F''}} is smooth, and also {{math|d''f'' : ''U'' → ''L''(''E'',''F'')}} is smooth where {{math|''L''(''E'',''F'')}} denotes the space of all bounded linear mappings with the topology of uniform convergence on bounded subsets; see [KM], 3.18.

4. The chain rule holds ([KM], 3.18).

5. The space {{math|''C''{{su|p=∞}}(''U'',''F'')}} of all smooth mappings {{math|''U'' → ''F''}} is again a convenient vector space where the structure is given by the following injection,  where  {{math|''C''{{su|p=∞}}(ℝ,ℝ)}} carries the topology of compact convergence in each derivative separately; see [KM], 3.11 and 3.7.
::::&lt;math&gt;
C^\infty(U,F) \to
\prod_{c\in C^\infty(\mathbb R,U), \ell\in F^*} 
C^\infty(\mathbb R,\mathbb R),
\quad f\mapsto (\ell\circ f\circ c)_{c,\ell}\,.
&lt;/math&gt;

6. The ''exponential law'' holds ([KM], 3.12): For {{math|''c''{{su|p=∞}}}}-open {{math|''V'' ⊆ ''F''}} the following mapping is a linear diffeomorphism of convenient vector spaces. 
:::&lt;math&gt;
C^\infty(U,C^\infty(V,G)) \cong C^\infty(U\times V, G),\qquad f \mapsto g,\qquad f(u)(v) = g(u,v).
&lt;/math&gt;
This is the main assumption of variational calculus. Here it is a theorem. This property is the source of the name ''convenient'', which was borrowed from (Steenrod 1967).

7. ''Smooth uniform boundedness theorem'' ([KM], theorem 5.26). 
A linear mapping {{math|''f'' : ''E'' → ''C''{{su|p=∞}}(''V'',''G'')}} is smooth (by (2) equivalent to bounded) if and only if {{math|ev{{su|b=''v''}} o ''f'' : ''V'' → ''G''}} is smooth for each {{math|''v'' ∈ ''V''}}.

8.  The following canonical mappings are smooth. This follows from the exponential law by simple categorical reasonings, see [KM], 3.13.

::&lt;math&gt;
\begin{align}
&amp; \operatorname{ev}: C^\infty(E,F)\times E\to F,\quad \text{ev}(f,x) = f(x) \\[6pt]
&amp; \operatorname{ins}: E\to C^\infty(F,E\times F),\quad\text{ins}(x)(y) = (x,y) \\[6pt]
&amp; (\quad)^\wedge :C^\infty(E,C^\infty(F,G))\to C^\infty(E\times F,G) \\[6pt]
&amp; (\quad)^\vee :C^\infty(E\times F,G)\to C^\infty(E,C^\infty(F,G)) \\[6pt]
&amp; \operatorname{comp}:C^\infty(F,G)\times C^\infty(E,F)\to C^\infty(E,G) \\[6pt]
&amp; C^\infty(\quad,\quad):C^\infty(F,F_1)\times C^\infty(E_1,E)\to C^\infty(C^\infty(E,F),C^\infty(E_1,F_1)),\quad (f,g)\mapsto(h\mapsto f\circ h\circ g) \\ [6pt]
&amp; \prod:\prod C^\infty(E_i,F_i)\to C^\infty \left(\prod E_i,\prod F_i\right)
\end{align}
&lt;/math&gt;

==Related convenient calculi==
Convenient calculus of smooth mappings appeared for the first time in [Fr&amp;ouml;licher,  1981], [Kriegl 1982, 1983].
Convenient calculus (having properties 6 and 7) exists also for:
* Real analytic mappings (Kriegl, Michor, 1990; see also [KM], chapter II). 
* Holomorphic mappings (Kriegl, Nel, 1985; see also [KM], chapter II). The notion of holomorphy is that of [Fantappié, 1930-33].
* Many classes of Denjoy Carleman ultradifferentiable functions, both of Beurling type and of  Roumieu-type [Kriegl, Michor, Rainer, 2009, 2011, 2015].
* With some adaptations, {{math|Lip{{su|p=''k''}}}}, [FK]. 
* With more adaptations, even {{math|C{{su|p=''k'',α}}}}  (i.e., the {{math|''k''}}-th derivative is H&amp;ouml;lder-continuous with index α) ([Faure, 1989], [Faure, These Geneve, 1991]).
The corresponding notion of convenient vector space is the same (for their underlying real vector space in the complex case) for all these theories.

==Application: Manifolds of mappings between finite dimensional manifolds==

The exponential law 6 of convenient calculus allows for very simple proofs of the basic facts about manifolds of mappings. 
Let {{math|''M''}}  and {{math|''N''}} be finite dimensional [[differentiable manifold|smooth manifolds]] where {{math|''M''}} is [[compact space|compact]]. We use an 
auxiliary [[Riemannian manifold|Riemann metric]] &lt;math&gt;\bar g&lt;/math&gt; on {{math|''N''}}. The [[Exponential map (Riemannian geometry)|Riemannian exponential mapping]] of &lt;math&gt;\bar g&lt;/math&gt; is described in the following diagram:
:::[[file:ManifoldOfMappingsDiagram.svg]]
It induces an atlas of charts on the space {{math|''C''{{su|p=∞}}(''M'' , ''N'')}} of all smooth mappings {{math|''M'' → ''N''}} as follows.
A chart centered at {{math|''f'' ∈  ''C''{{su|p=∞}}(''M'',''N'')}}, is:
:::&lt;math&gt;u_f : C^\infty(M,N)\supset U_f =\{g: (f,g)(M)\subset V^{N\times N}\} \to \tilde U_f \subset \Gamma(f^*TN),&lt;/math&gt;
:::&lt;math&gt;u_f(g) = (\pi_N,\exp^{\bar g})^{-1} \circ (f,g),\quad u_f(g)(x) = (\exp^{\bar g}_{f(x)})^{-1}(g(x)),&lt;/math&gt;
:::&lt;math&gt;(u_f)^{-1}(s)  = \exp^{\bar g}_f\circ s, \qquad\quad (u_f)^{-1}(s)(x) = \exp^{\bar g}_{f(x)}(s(x)).&lt;/math&gt;
Now the basics facts follow in easily.
Trivializing the pull back  vector bundle {{math|''f''{{su|p=∗}}''TN''}} and applying the exponential law 6 leads to the diffeomorphism
:::&lt;math&gt;C^\infty(\mathbb R,\Gamma(M;f^*TN)) = \Gamma(\mathbb R\times M; \operatorname{pr_2}^* f^*TN).&lt;/math&gt; 
All chart change mappings are smooth ({{math|''C''{{su|p=∞}}}}) since they map smooth curves to smooth curves:  
:::&lt;math&gt;\tilde U_{f_1}\ni s\mapsto (\pi_N,\exp^{\bar g})\circ s \mapsto (\pi_N,\exp^{\bar g})\circ(f_2,\exp^{\bar g}_{f_1}\circ s).&lt;/math&gt;
Thus  {{math|''C''{{su|p=∞}}(''M'' , ''N'')}} is a smooth manifold modelled on Fréchet spaces. The space of all smooth curves in this manifold is given by
:::&lt;math&gt;C^\infty(\mathbb R,C^\infty(M,N))\cong C^\infty(\mathbb R\times M,N).&lt;/math&gt;
Since it visibly maps smooth curves to smooth curves, ''composition''
:::&lt;math&gt;C^\infty(P,M)\times C^\infty(M,N)\to C^\infty(P,N),\qquad (f,g)\mapsto g\circ f,&lt;/math&gt;  
is smooth. As a consequence of the chart structure, the [[tangent bundle]] of the manifold of mappings is given by 
:::&lt;math&gt;\pi_{C^\infty(M,N)} = C^\infty(M,\pi_N) : TC^\infty(M,N)= C^\infty(M,TN) \to  C^\infty(M,N).&lt;/math&gt;

===Regular Lie groups===
Let  {{math|''G''}} be a connected smooth [[Lie group]] modeled on convenient vector spaces, with Lie algebra 
&lt;math&gt;\mathfrak g=T_eG&lt;/math&gt;. Multiplication and inversion are denoted by:
:::&lt;math&gt; \mu: G\times G\to G,\quad \mu(x,y) = x.y = \mu_x(y) = \mu^y(x), \qquad \nu: G\to G, \nu(x) = x^{-1}.&lt;/math&gt;
The notion of a regular Lie group is originally due to Omori et al. for Fréchet Lie groups, was weakened and made more transparent by J.Milnor, and was then carried over to convenient Lie groups; see [KM], 38.4.

A Lie group {{math|''G''}} is called ''regular''  if the following two conditions hold:
* For each smooth curve &lt;math&gt;X\in C^{\infty}(\mathbb R,\mathfrak g)&lt;/math&gt; in the Lie algebra there exists a smooth curve &lt;math&gt;g\in C^{\infty}(\mathbb R,G)&lt;/math&gt; in the Lie group whose right logarithmic derivative is {{math|''X''}}. It turn out that {{math|''g''}} is uniquely determined by its initial value {{math|''g''(0)}}, if it exists. That is,
:::&lt;math&gt; g(0) = e, \qquad \partial_t g(t) = T_e(\mu^{g(t)})X(t) = X(t).g(t).&lt;/math&gt;
If  {{math|''g''}} is the unique solution for the curve  {{math|''X''}} required above, we denote  
:::&lt;math&gt;\operatorname{evol}^r_G(X)=g(1), \quad \operatorname{Evol}^r_G(X)(t):= g(t) =\operatorname{evol}^r_G(tX).&lt;/math&gt; 
* The following mapping is required to be smooth:
:::&lt;math&gt;\operatorname{evol}^r_G: C^{\infty}(\mathbb R,\mathfrak g)\to G.&lt;/math&gt;
If {{math|''X''}} is a constant curve in the Lie algebra, then {{math|1=evol{{su|p=r|b=''G''}}(X) = exp{{su|p=''G''}}(X)}} is the group exponential mapping.

'''Theorem.''' For each compact manifold {{math|''M''}}, the diffeomorphism group {{math|Diff(''M'')}} is a regular Lie group. Its Lie algebra is the space &lt;math&gt;\mathfrak X(M)&lt;/math&gt; of all smooth vector fields on {{math|''M''}}, with the negative of the usual bracket as Lie bracket.

''Proof:'' The diffeomorphism group {{math|Diff(''M'')}} is a smooth manifold since it is an open subset in {{math|''C''{{su|p=∞}}(''M'' , ''M'')}}.  Composition is smooth by restriction. Inversion is smooth: If {{math|''t'' → ''f''(''t'',&amp;nbsp;&amp;nbsp;)}} is a smooth curve in {{math|Diff(''M'')}}, then {{math|''f''(''t'',&amp;nbsp;&amp;nbsp;){{su|p=−1}}}} satisfies the implicit equation 
&lt;math&gt;f(t,f(t,\quad)^{-1}(x))=x&lt;/math&gt;, so by the finite dimensional implicit function theorem,  {{math|(''t''.''x'') ↦ ''f''(''t'',&amp;nbsp;&amp;nbsp;){{su|p=−1}}(''x'')}} is smooth. So inversion maps smooth curves to smooth curves, and thus inversion is smooth.
Let {{math|''X''(''t'',''x'')}} be a time dependent vector field on {{math|''M''}} (in &lt;math&gt;C^\infty(\mathbb R,\mathfrak X(M))&lt;/math&gt;).
Then the flow operator {{math|Fl}} of the corresponding autonomous vector field &lt;math&gt;\partial_t\times X&lt;/math&gt; on {{math|ℝ × ''M''}} induces the evolution operator via
:::&lt;math&gt;\operatorname{Fl}_s(t,x)=(t+s,\operatorname{Evol}(X)(t,x))&lt;/math&gt; 
which satisfies the ordinary differential equation 
:::&lt;math&gt;\partial_t\operatorname{Evol}(X)(t,x) = X(t,\operatorname{Evol}(X)(t,x)).&lt;/math&gt;
Given a smooth curve in the Lie algebra, &lt;math&gt;X(s,t,x)\in C^\infty(\mathbb R^2,\mathfrak X(M))&lt;/math&gt;,
then the solution of the ordinary differential equation depends smoothly also on the further variable {{math|''s''}},
thus {{math|evol{{su|p=r|b=Diff(''M''}}}} maps smooth curves of time dependent vector fields to smooth curves of 
diffeomorphism. QED.

===The principal bundle of embeddings===
For finite dimensional manifolds {{math|''M''}} and {{math|''N''}} with {{math|''M''}} compact, the space {{math|Emb(''M'',''N'')}} of all smooth embeddings of {{math|''M''}} into {{math|''N''}}, is open in {{math|''C''{{su|p=∞}}(''M'' , ''N'')}}, so it is a smooth manifold. The diffeomorphism group {{math|Diff(''M'')}} acts freely and smoothly from the right on {{math|Emb(''M'',''N'')}}.

'''Theorem:'''  {{math|Emb(''M'',''N'') → Emb(''M'',''N'')/Diff(''M'')}} is a principal fiber bundle with structure group {{math|Diff(''M'')}}.

''Proof:'' One uses again an auxiliary Riemannian metric &lt;math&gt;\bar g&lt;/math&gt; on {{math|''N''}}. Given {{math|''f'' ∈ Emb(''M'',''N'')}}, view {{math|''f''(''M'')}} as a submanifold of {{math|''N''}}, and split the restriction of the tangent bundle {{math|''TN''}} to {{math|''f''(''M'')}} into the subbundle normal to {{math|''f''(''M'')}} and tangential to {{math|''f''(''M'')}} as
&lt;math&gt;TN|_{f(M)}= \operatorname{Nor}(f(M))\oplus Tf(M)&lt;/math&gt;. Choose a tubular neighborhood 
:::&lt;math&gt;p_{f(M)} : \operatorname{Nor}(f(M))\supset  W_{f(M)} \to f(M).&lt;/math&gt;
If {{math|''g'': ''M'' → ''N''}} is {{math|''C''{{su|p=1}}}}-near to {{math|''f''}}, then 
:::&lt;math&gt;\phi(g):=f^{-1}\circ\, p_{f(M)}\circ\, g\in \operatorname{Diff}(M)\quad \text{and}\quad 
g\circ\, \phi(g)^{-1}\in \Gamma(f^*W_{f(M)}) \subset \Gamma(f^*\operatorname{Nor}(f(M))).&lt;/math&gt;
This is the required local splitting. QED

===Further applications===
An overview of applications using geometry of shape spaces and diffeomorphism groups can be found in [Bauer, Bruveris, Michor, 2014].

==Notes==
{{reflist|group=Note}}

==References==
{{reflist}}

* Bauer, M., Bruveris, M., Michor, P.W.: Overview of the Geometries of Shape Spaces and Diffeomorphism Groups. Journal of Mathematical Imaging and Vision, 50, 1-2, 60-97, 2014. [https://arxiv.org/abs/1305.1150 (arXiv:1305.11500)]
* Boman, J.: Differentiability of a function and of its composition with a  function of one variable, Mathematica Scandinavia vol. 20 (1967), 249–268.
* Faure, C.-A.: Sur un théorème de Boman, C. R. Acad. Sci., Paris}, vol. 309 (1989), 1003–1006.
* Faure, C.-A.: Théorie de la différentiation dans les espaces convenables, These, Université de Genève, 1991.
* Fr&amp;ouml;licher, A.: Applications lisses entre espaces et variétés de Fréchet, C. R. Acad. Sci. Paris, vol. 293 (1981), 125–127.
* [FK] Fr&amp;ouml;licher, A., Kriegl, A.: Linear spaces and differentiation theory. Pure and Applied Mathematics,	J. Wiley, Chichester, 1988.
* Kriegl, A.: Die richtigen R&amp;auml;ume f&amp;uuml;r Analysis im Unendlich – Dimensionalen,	Monatshefte f&amp;uuml;r Mathematik vol. 94 (1982) 109–124.
* Kriegl, A.: Eine kartesisch abgeschlossene Kategorie glatter Abbildungen zwischen beliebigen lokalkonvexen Vektorr&amp;auml;umen, Monatshefte f&amp;uuml;r Mathematik vol. 95 (1983) 287–309.
* [KM] Kriegl, A., Michor, P.W.: The Convenient Setting of Global Analysis. Mathematical Surveys and Monographs, Volume: 53, American Mathematical Society, Providence, 1997. [http://www.mat.univie.ac.at/~michor/apbookh-ams.pdf (pdf)]
* Kriegl, A., Michor, P. W., Rainer, A.: The convenient setting for non-quasianalytic Denjoy–Carleman differentiable mappings, Journal of Functional Analysis, vol. 256 (2009), 3510–3544. [https://arxiv.org/abs/0804.2995 (arXiv:0804.2995)]
* Kriegl, A., Michor, P. W., Rainer, A.: The convenient setting for quasianalytic Denjoy–Carleman differentiable mappings, Journal of Functional Analysis, vol. 261 (2011), 1799–1834. [https://arxiv.org/abs/0909.5632 (arXiv:0909.5632)]
* Kriegl, A., Michor, P. W., Rainer, A.: The convenient setting for Denjoy-Carleman differentiable mappings of Beurling and Roumieu type. Revista Matemática Complutense (2015). doi:10.1007/s13163-014-0167-1. [https://arxiv.org/abs/1111.1819 (arXiv:1111.1819)]
* Michor, P.W.: Manifolds of mappings and shapes. [https://arxiv.org/abs/1505.02359 (arXiv:1505.02359)]
* Steenrod, N. E.: A convenient category for topological spaces, Michigan Mathematical Journal, vol. 14 (1967), 133–152.

{{Functional Analysis}}

[[Category:Multivariable calculus]]
[[Category:Differential calculus]]
[[Category:Calculus of variations]]</text>
      <sha1>ficumcb2i7bixi56kfz1ilnx2t9nrq0</sha1>
    </revision>
  </page>
  <page>
    <title>Corner-point grid</title>
    <ns>0</ns>
    <id>23429522</id>
    <revision>
      <id>824111642</id>
      <parentid>761425226</parentid>
      <timestamp>2018-02-05T11:27:54Z</timestamp>
      <contributor>
        <username>Reyk</username>
        <id>378651</id>
      </contributor>
      <comment>rm unreferenced tag, copyedit</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2515">[[Image:TwoCells.png|thumb|A trivial example of a Corner-point grid with only two cells.]]
In [[geometry]], a '''corner-point grid''' is a [[tessellation]] of a [[Euclidean space|Euclidean]] 3D volume where the base cell has 6 [[Face (geometry)|faces]] ([[hexahedron]]).

A set of straight lines defined by their end points define the ''pillars'' of the corner-point grid. The pillars have a lexicographical ordering that determines neighbouring pillars. On each pillar, a constant number of nodes (corner-points) is defined. A corner-point cell is now the volume between 4 neighbouring pillars and two neighbouring points on each pillar. 

Each cell can be identified by integer coordinates &lt;math&gt;(i,j,k)&lt;/math&gt;, where the &lt;math&gt;k&lt;/math&gt; coordinate runs along the pillars, and &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt; span each layer. The cells are ordered naturally, where the index &lt;math&gt;i&lt;/math&gt; runs the fastest and &lt;math&gt;k&lt;/math&gt; the slowest.

Data within the interior of such cells can be computed by [[trilinear interpolation]] from the boundary values at the 8 corners, 12 edges, and 6 faces.

In the special case of all pillars being vertical, the top and bottom face of each corner-point cell are described by [[Bilinear interpolation|bilinear surfaces]] and the side faces are [[plane (geometry)|plane]]s.

Corner-point grids are supported by most [[reservoir simulation]] software, and has become an industry standard.

==Degeneracy==

A main feature of the format is the ability to define [[erosion surface]]s in [[geological modelling]], effectively done by collapsing nodes along each pillar. This means that the corner-point cells degenerate and may have less than 6 faces.

For the corner-point grids non-neighboring connections are supported, meaning that grid cells that are not neighboring in ijk-space can be defined as neighboring. This feature allows for representation of faults with significant throw/displacement. Moreover, the neighboring grid cells do not need to have matching cell faces (just overlap).

==References==
{{Reflist}}

{{Refbegin}}
* Corner Point Grid. [http://wiki.opm-project.org/index.php?title=Corner_point_grid] ''Open Porous Media Initiative''
* Aarnes J, Krogstad S and Lie KA (2006). Multiscale Mixed/Mimetic Methods on Corner Point Grids [http://www.sintef.no/globalassets/project/geoscale/papers/msmfem-cpg.pdf] ''SINTEF ICT, Dept. Applied Mathematics''
{{Refend}} 

[[Category:Tessellation]]
[[Category:Geometry]]
[[Category:Petroleum production]]


{{geometry-stub}}</text>
      <sha1>4uz5hchwjww35ar0s1pdgfq1167ag54</sha1>
    </revision>
  </page>
  <page>
    <title>Cyborg data mining</title>
    <ns>0</ns>
    <id>55906881</id>
    <revision>
      <id>855915214</id>
      <parentid>846299486</parentid>
      <timestamp>2018-08-21T17:46:28Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add pmc identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17655">{{Multiple issues|
{{Orphan|date=June 2018}}
{{technical|date=December 2017}}
}}

'''Cyborg data mining''' is the practice of collecting [[data]] produced by an implantable device that monitors bodily processes for commercial interests. As an [[Android (robot) |android]] is a human-like robot, a [[cyborg]], on the other hand, is an [[organism]] whose physiological functioning is aided by or dependent upon a mechanical/electronic device that relies on some sort of [[feedback]].&lt;ref&gt;{{cite journal |last1=Wittes |first1=Benjamin |last2=Chong |first2=Jane |title=Our Cyborg Future: Law and Policy Implications |journal=Brookings Institution Reports |date=2014 |page=9 |url=https://www.brookings.edu/research/our-cyborg-future-law-and-policy-implications/ |accessdate=November 24, 2017}}&lt;/ref&gt;

Implantable [[cybernetics]] and [[biomechatronics]] are on course to be proliferated among the global population within the twenty-first century as the markets for implantable electronics are already huge and growing. The global market for [[artificial cardiac pacemaker]]s (PMs) and [[implantable cardioverter-defibrillators]] (ICDs) was approximately €8 billion in 2015, and is growing at 10% per year.&lt;ref&gt;{{cite web |first1=Medical Device |last1=Developments |title=The future of implants: smart, electronic implanatables |url=http://www.medicaldevice-developments.com/features/featurethe-future-of-smart-electronic-implants-4787632/ |website=Medical Device Developments |accessdate=November 24, 2017}}&lt;/ref&gt; Over 350 million people worldwide experience endemic diseases, [[diabetes]], cardiac and renal failure, [[hearing]] disorders, and [[neurological disorders]], thus making implantable technologies specific to these uses susceptible to increasingly higher demand.&lt;ref&gt;{{cite web |first1=Medical Device |last1=Developments |title=The future of implants: smart, electronic implanatables |url=http://www.medicaldevice-developments.com/features/featurethe-future-of-smart-electronic-implants-4787632/ |website=Medical Device Developments |accessdate=November 24, 2017}}&lt;/ref&gt; However, for the millions of cyborgs already equipped with body-enhancing technologies, namely PMs and ICDs, the [[data mining]] of these technologies pertains to broader topics of [[data sovereignty]], data ownership rights, [[privacy]] and [[security]], and medical [[research and development]].

== Implantable technologies and their general uses ==
According to European Directive 90/385/EEC, an "active implantable medical device" is any device that is intended to be used for [[human]] beings in the: 1) diagnosis, prevention, monitoring, treatment, or alleviation of [[disease]] or [[injury]]; 2) investigation, replacement, or modification of the anatomy or of a physiological process; and 3) control of [[Fertilisation|conception]].&lt;ref&gt;{{cite web |last1=Union |first1=European |title=Council Directive 90/385/EEC of 20 June 1990 on the approximation of the laws of the Member States relating to active implantable medical devices OJ No. L189 |url=http://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:31990L0385&amp;from=EN |accessdate=November 24, 2017}}&lt;/ref&gt; The implantable device is to be totally or partially introduced, surgically or medically, into the human body, and is intended to remain after the [[Medical procedure |procedure]].&lt;ref&gt;{{cite web |last1=Union |first1=European |title=Council Directive 90/385/EEC of 20 June 1990 on the approximation of the laws of the Member States relating to active implantable medical devices OJ No. L189 |url=http://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:31990L0385&amp;from=EN |accessdate=November 24, 2017}}&lt;/ref&gt;

According to one definition of the term cyborg, basic technologies, such as implantable medical devices, that [[human]]ity has physical attachments with have already made humans into cyborgs.&lt;ref&gt;{{cite book |last1=Haraway |first1=Donna |title=A Cyborg Manifesto: Science, Technology, and Socialist-Feminism in the Late Twentieth Century |date=1984 |publisher=Routledge |location=New York |pages=149 to 181 |url=https://www.sfu.ca/~decaste/OISE/page2/files/HarawayCyborg.pdf}}&lt;/ref&gt; These technologies are responsible for enhancing people’s cognitive abilities, or more importantly, keeping them alive. The three most common implantable technologies are [[cochlear implant]]s, PMs, and ICDs. Cochlear implants aid in the process of hearing, and are used by more than 200,000 patients worldwide.&lt;ref&gt;{{cite web |first1=Medical Device |last1=Developments |title=The future of implants: smart, electronic implanatables |url=http://www.medicaldevice-developments.com/features/featurethe-future-of-smart-electronic-implants-4787632/ |website=Medical Device Developments |accessdate=November 24, 2017}}&lt;/ref&gt; PMs and ICDs keep people alive through the measurement of bodily [[voltage]] levels, measurement of regular and irregular heartbeats, and the delivery of electric impulses when irregularities are sensed in order to keep the person alive. There are about 3 million people worldwide with pacemakers, and each year 600,000 pacemakers are implanted.&lt;ref&gt;{{cite journal |last1=Wood |first1=Mark |last2=Ellenbogen |first2=Kenneth |title=Cardiac Pacemakers from the Patient’s Perspective |journal=American Heart Association (AHA) Journals |date=May 7, 2002 |volume=105 |issue=18 |page=2136 |doi=10.1161/01.CIR.0000016183.07898.90}}&lt;/ref&gt; The data collected from these technologies, however, is not owned by the person whose body the technology is in, but rather the company who owns the intellectual property to that technology, as well as other third-parties.

==Intellectual Property, Data brokerage, and the Third-Party doctrine==
===Intellectual Property and Data brokerage===
Companies are now able to mine the [[data exhaust]] from internet-enabled wearable and implantable technologies, such as medical and fitness tracking devices ([[Fitbit]], [[Apple Watch]] Nike+, etc.), [[sensors]], PMs, [[RFID]] (Radio Frequency Identification) microchips, and so forth. However, consumers in the U.S. do not have agency over their data due to current [[intellectual property]] law and the [[third-party doctrine]]. Intellectual property owners of the software, as well as the patented hardware and processes, of these devices acquire the data from the cyborg’s bodily processes via these implantable devices, which become property of the owner, not the cyborg. Consumers surrender these massive pools of data via an End-User-License-Agreement (EULAs), terms of service agreements, and so forth.&lt;ref&gt;{{cite journal |last1=Thatcher |first1=Jim |last2=O'Sullivan |first2=David |last3=Mahmoudi |first3=Dillon |title=Data colonialism through accumulation by dispossession: New metaphors for daily data |journal=Environment and Planning D: Society and Space |date=2016 |volume=34 |issue=6 |page=993 |doi=10.1177/0263775816633195}}&lt;/ref&gt; Companies then algorithmically arrange data, and consumers lose ownership of their data to the intellectual property owners and data brokerage firms to commodify, thus becoming a part of the larger [[Big Data]] economy. In a $300 billion-a-year industry, currently no legislation specific to the regulation of third-party data broker firms exists.&lt;ref&gt;{{cite journal |last1=Roderick |first1=Leanne |title=Discipline and power in the digital age: The case of the US consumer data broker industry |journal=Critical Sociology |date=January 6, 2014 |volume=40 |issue=5 |page=739 |doi=10.1177/0896920513501350}}&lt;/ref&gt; Third-party data broker firms are not restricted by [[Federal Trade Commission]] regulations, including the [[Fair Credit Reporting Act]], as well as the [[Gramm-Leach-Bliley Act]].&lt;ref&gt;{{cite journal |last1=Roderick |first1=Leanne |title=Discipline and power in the digital age: The case of the US consumer data broker industry |journal=Critical Sociology |date=January 6, 2014 |volume=40 |issue=5 |page=739 |doi=10.1177/0896920513501350}}&lt;/ref&gt;  It is very difficult for consumers to opt-in and out of having data collected about them, whereby their data ownership rights become very limited.

===Third-party doctrine===
Under the [[third-party doctrine]], an individual does not have a reasonable expectation of privacy with respect to information they voluntarily disclose to a third party. In the context of the PM, which monitors a patient’s heartbeat, blood temperature, breathing, and heart electrical activity, this extracted data is voluntarily given to a third party, and thus subject to the third-party doctrine. The five largest PM manufacturers in the world are the U.S.’s [[Medtronic]] ($1.9 billion in global PM sales in 2013), [[St. Jude Medical]] (nearly $1 billion in global PM sales in 2013), and [[Boston Scientific]] ($514 million in global PM sales in 2013), Germany's [[Biotronik]] ($397 million in global PM sales in 2013), and Italy's [[Sorin Group]] ($219 million global PM sales in 2013).&lt;ref&gt;{{cite news |last1=Hollmer |first1=Mark |title=The pacemaker inside me: What I learned about the industry as a cardiac patient |url=https://www.fiercebiotech.com/medical-devices/pacemaker-inside-me-what-i-learned-about-industry-as-a-cardiac-patient |accessdate=November 24, 2017 |agency=Fierce Biotech |date=February 4, 2017}}&lt;/ref&gt; PM users have no agency over their data, nor over who has the ability to access it, and current laws impose no requirement for manufacturers to allow PM users access to their own data.&lt;ref&gt;{{cite journal |last1=Wittes |first1=Benjamin |last2=Chong |first2=Jane |title=Our Cyborg Future: Law and Policy Implications |journal=Brookings Institution Reports |date=2014 |page=16 |url=https://www.brookings.edu/research/our-cyborg-future-law-and-policy-implications/ |accessdate=November 24, 2017}}&lt;/ref&gt;  The notable activist, Hugo Campo, has been fighting for the right to access the data collected by his own defibrillator for years without success due to the logic of PM data being covered by the third-party doctrine.&lt;ref&gt;{{cite journal |last1=Wittes |first1=Benjamin |last2=Chong |first2=Jane |title=Our Cyborg Future: Law and Policy Implications |journal=Brookings Institution Reports |date=2014 |page=17 |url=https://www.brookings.edu/research/our-cyborg-future-law-and-policy-implications/ |accessdate=November 24, 2017}}&lt;/ref&gt;

===EU GDPR and Cyborg data===
In April 2016, the European Union tabled legislation for the [[General Data Protection Regulation]] (GDPR), which will replace the [[Data Protection Directive]] 95/46/EC of 1995, and comes into force on May 25, 2018. Internet-enabled wearable and future implantable technologies will fall under the purview of this legislation. The directive will implement tougher fines for non-compliance and breaches, and gives consumers more control over how their personal data is used.&lt;ref&gt;{{cite web |first1=European |last1=Union |title=GDPR Key Changes |url=http://www.eugdpr.org/key-changes.html |website=EU General Data Protection Regulation Portal |accessdate=November 18, 2017}}&lt;/ref&gt; Some of these consumer rights are, but are not limited to, having the right:

* To request data in monthly intervals;
* To access any information a company holds on them;
* To know why that data is being processed;
* To know how long it is stored for;
* To know who gets to see their data;
* To demand that their data be deleted if it is no longer necessary to the purpose for which it was collected; and so forth&lt;ref&gt;{{cite news |last1=Curtis |first1=Joe |title=What is GDPR? Everything you need to know |url=http://www.itpro.co.uk/it-legislation/27814/what-is-gdpr-everything-you-need-to-know-8 |accessdate=November 15, 2017 |agency=ITPro |date=November 1, 2017}}&lt;/ref&gt;

==Surveillance and Sousveillance==
As cyborgs are comprehensive data subjects, they can also be used as a powerful instrument to facilitate [[surveillance]] and [[sousveillance]] through optical recording technology. Some data collection from cyborgs can be harmless, namely posting pictures to [[Facebook]], or recording one’s life experiences. However, cyborgs can serve as a means of surveillance on the overall populace via sousveillance. Sousveillance is the notion of a populace watching the state from below,&lt;ref&gt;{{cite journal |last1=Mann |first1=Steve |last2=Ferenbok |first2=Joseph |title=New media and the power politics of sousveillance in a surveillance-dominated world |journal=Surveillance and Society |date=2013 |volume=11 |issue=1-2 |page=1 |url=http://www.eyetap.org/papers/docs/Surveillance_and_Society_Mann_Ferenbok_4456-9724-1-PB.pdf |accessdate=November 18, 2017}}&lt;/ref&gt; whereby the notable [[University of Toronto]] professor and cyborg, [[Steve Mann]], has advocated that sousveillant devices can “invert the [[panopticon]]” and challenge and balance the hypocrisy and corruption that is otherwise inherent in a surveillance-only society.&lt;ref&gt;{{cite journal |last1=Mann |first1=Steve |last2=Ferenbok |first2=Joseph |title=New media and the power politics of sousveillance in a surveillance-dominated world |journal=Surveillance and Society |date=2013 |volume=11 |issue=1-2 |page=1 |url=http://www.eyetap.org/papers/docs/Surveillance_and_Society_Mann_Ferenbok_4456-9724-1-PB.pdf |accessdate=November 18, 2017}}&lt;/ref&gt; Sousveillant technologies secure the cyborg and individuals, especially by deterring and documenting crime, but potentially infringes privacy on cyborgs and non-cyborgs as well. [[Google Glass]], for example, is an optical recording device that presents concerns toward privacy in public. The ability for cyborgs to record everyday routines and interactions with others thus present the question of how society and laws are to respond to the advent of cyborgs being subjects and instruments of surveillance and sousveillance.&lt;ref&gt;{{cite journal |last1=Wittes |first1=Benjamin |last2=Chong |first2=Jane |title=Our Cyborg Future: Law and Policy Implications |journal=Brookings Institution Reports |date=2014 |page=18 |url=https://www.brookings.edu/research/our-cyborg-future-law-and-policy-implications/ |accessdate=November 24, 2017}}&lt;/ref&gt;

==Public good==
Data mined from bodily processes are able to help companies in their research and development endeavours in developing better technologies, and conducting invaluable medical research for identifying and managing various conditions. PMs and ICDs offered by major companies come with [[wireless]] capabilities that communicate with home transmitters, which then relay data to the [[physician]], and thus allow for remote patient follow-up and monitoring.&lt;ref&gt;{{cite journal |last1=Burri |first1=Haran |last2=Senouf |first2=David |title=Remote monitoring and follow-up of pacemakers and implantable cardioverter defibrillators |journal=Europace |date=June 1, 2009 |volume=11 |issue=6 |page=701 |doi=10.1093/europace/eup110 |url=https://academic.oup.com/europace/article/11/6/701/479961 |accessdate=November 24, 2017|pmc=2686319 }}&lt;/ref&gt; These systems for remote follow-up are used widely across the U.S. and Europe. Major PM and ICD producers have their own remote monitoring system networks, such as Biotronik’s Home Monitoring, Medtronic’s CareLink Network, Boston Scientific’s Latitude Patient Management system, and St. Jude Medical’s Merlin.net.&lt;ref&gt;{{cite journal |last1=Burri |first1=Haran |last2=Senouf |first2=David |title=Remote monitoring and follow-up of pacemakers and implantable cardioverter defibrillators |journal=Europace |date=June 1, 2009 |volume=11 |issue=6 |page=701 to 702 |doi=10.1093/europace/eup110 |url=https://academic.oup.com/europace/article/11/6/701/479961 |accessdate=November 24, 2017|pmc=2686319 }}&lt;/ref&gt; The benefits of this data collection include a reduction of in-clinic visits, improved patient safety, increased patient satisfaction, and potential cost savings for consumers.&lt;ref&gt;{{cite journal |last1=Burri |first1=Haran |last2=Senouf |first2=David |title=Remote monitoring and follow-up of pacemakers and implantable cardioverter defibrillators |journal=Europace |date=June 1, 2009 |volume=11 |issue=6 |page=705 to 707 |doi=10.1093/europace/eup110 |url=https://academic.oup.com/europace/article/11/6/701/479961 |accessdate=November 24, 2017}}&lt;/ref&gt; The ability to remotely follow up because of PM and ICD data collection allows for tracking product performance in a large number of patients, and may allow earlier identification of issues with specific models.

The data collected from PMs and ICDs have the potential to facilitate critical medical research. Namely, Medtronic collects and analyzes the data generated by its pacemakers and defibrillators via the CareLink system. Medtronic is using the collected PM data and is working with researchers at [[Johns Hopkins Hospital]] and [[Washington University School of Medicine]] in order to help answer specific questions about heart disease, such as whether weak hearts cause arrhythmias or vice versa.&lt;ref&gt;{{cite journal |last1=Evans |first1=Jon |title=Wireless medical devices advance, weather balloons aside |journal=Nature Medicine |date=November 1, 2009 |volume=15 |issue=11 |doi=10.1038/nm1109-1231}}&lt;/ref&gt; Although this aspect of the technology is not widely proliferated yet, scientists and industry developers say that wireless devices could trigger an automatic treatment, which could range from electrical stimulation to the release of drugs.&lt;ref&gt;{{cite journal |last1=Evans |first1=Jon |title=Wireless medical devices advance, weather balloons aside |journal=Nature Medicine |date=November 1, 2009 |volume=15 |issue=11 |doi=10.1038/nm1109-1231}}&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Cybernetics]]
[[Category:Cyborgs]]
[[Category:Data mining]]</text>
      <sha1>ftlrr1k8xjdhrfjh2a0ieuva8f9knac</sha1>
    </revision>
  </page>
  <page>
    <title>Derek Corneil</title>
    <ns>0</ns>
    <id>34794178</id>
    <revision>
      <id>838261178</id>
      <parentid>818234672</parentid>
      <timestamp>2018-04-25T22:41:20Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (5 sources from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9073">{{Infobox philosopher
| region           = 
| era              = 
| image       = 
| image_size       = 
| caption     = 
| name             = Derek G. Corneil
| birth_date       = {{birth date and age|1942|12|27|df=y}}
| birth_place      = [[Quebec]]
| death_date       = 
| death_place      =
| school_tradition = 
| main_interests   = [[Graph theory]]&lt;br /&gt;[[Computer science]] 
| notable_ideas    = 
| influences       = 
| influenced       = 
| signature        = 
}}
'''Derek Gordon Corneil''' is a Canadian [[mathematician]] and [[computer scientist]], a professor ''emeritus'' of computer science at the [[University of Toronto]], and an expert in [[graph algorithm]]s and [[graph theory]].

==Life==
When he was leaving high school, Corneil was told by his English teacher that doing a degree in mathematics and physics was a bad idea, and that the best he could hope for was to go to a technical college. His interest in computer science began when, as an undergraduate student at Queens College, he heard that a computer was purchased by the London Life insurance company in London, Ontario, where his father worked. As a freshman, he took a summer job operating the [[UNIVAC]] Mark II at the company. One of his main responsibilities was to operate a printer. An opportunity for a programming job with the company sponsoring his college scholarship appeared soon after. It was a chance that Corneil jumped at after being denied a similar position at London Life. There was an initial mix-up at his job as his overseer thought that he knew how to program the UNIVAC Mark II, and so he would easily transition to doing the same for the company's newly acquired IBM 1401 machine. However, Corneil did not have the assumed programming background. Thus, in the two-week window that Corneil had been given to learn how to grasp programming the [[IBM 1401]], he learned how to write code from scratch by relying heavily on the instruction manual. This experience pushed him further on his way as did a number of projects he worked on in that position later on.&lt;ref&gt;http://blogs.technet.com/b/cdnitmanagers/archive/2011/06/13/derek-corneil-renowned-and-esteemed-computer-science-professor-emeritus-university-of-toronto.aspx&lt;/ref&gt;

Corneil went on to earn a bachelor's degree in mathematics and physics from [[Queen's University]] in 1964. Initially he had planned to do his graduate studies before becoming a high school teacher, but his acceptance into the brand new graduate program in computer science at the University of Toronto changed that. At the University of Toronto, Corneil earned a master's degree and then in 1968 a doctorate in computer science under the supervision of [[Calvin Gotlieb]].&lt;ref name="bio"&gt;[http://www.cs.toronto.edu/dcs/people-faculty-dgc.html Biography], University of Toronto. Retrieved 1/8 February 2012.&lt;/ref&gt;&lt;ref&gt;{{mathgenealogy|name=Derek Gordon Corneil|id=19546}}&lt;/ref&gt; (His post-doctoral supervisor was Jaap Seidel.) It was during this time that Corneil became interested in graph theory. He and Gotlieb eventually became good friends. After postdoctoral studies at the [[Eindhoven University of Technology]], Corneil returned to Toronto as a faculty member in 1970.&lt;ref name="bio"/&gt; Before his retirement in 2010,&lt;ref&gt;{{citation|url=http://www.cs.toronto.edu/dcs/documents/DCS_2010Newsletter.pdf|journal=@dcs|publisher=University of Toronto Department of Computer Science|page=8|title=Derek Corneil: Retiring after 40 years with DCS|volume=1|issue=3|year=2010}}.&lt;/ref&gt; Corneil held many positions at the University of Toronto, including Department Chair of the Computer Science department (July 1985 to June 1990), Director of Research Initiatives of the Faculty of Arts and Science (July 1991 to March 1998), and Acting Vice President of Research and International Relations (September to December 1993). During his time as a professor, he was also a visiting professor at universities such as the University of British Columbia, Simon Fraser University, the Université de Grenoble and the Université de Montpellier.

==Work==
Corneil did his research in algorithmic graph theory and graph theory in general. He has overseen 49 theses and published over 100 papers on his own or with co-authors. These papers include:

:A proof that recognizing graphs of small [[treewidth]] is [[NP-complete]],&lt;ref&gt;{{citation
 | last1 = Arnborg | first1 = Stefan
 | last2 = Corneil | first2 = Derek G.
 | last3 = Proskurowski | first3 = Andrzej
 | doi = 10.1137/0608024
 | issue = 2
 | journal = SIAM Journal on Algebraic and Discrete Methods
 | mr = 881187
 | pages = 277–284
 | title = Complexity of finding embeddings in a $k$-tree
 | volume = 8
 | year = 1987}}.&lt;/ref&gt;

:The discovery of the cotree representation for [[cograph]]s and of fast recognition algorithms for cographs,&lt;ref&gt;{{citation
 | last1 = Corneil | first1 = D. G.
 | last2 = Lerchs | first2 = H.
 | last3 = Burlingham | first3 = L. Stewart
 | doi = 10.1016/0166-218X(81)90013-5
 | issue = 3
 | journal = Discrete Applied Mathematics
 | mr = 619603
 | pages = 163–174
 | title = Complement reducible graphs
 | volume = 3
 | year = 1981}}.&lt;br&gt;- {{citation
 | last1 = Corneil | first1 = D. G.
 | last2 = Perl | first2 = Y.
 | last3 = Stewart | first3 = L. K.
 | doi = 10.1137/0214065
 | issue = 4
 | journal = SIAM Journal on Computing
 | mr = 807891
 | pages = 926–934
 | title = A linear recognition algorithm for cographs
 | volume = 14
 | year = 1985}}.&lt;/ref&gt;

:Generating algorithms for [[graph isomorphism]].&lt;ref&gt;{{citation
 | last1 = Corneil | first1 = D. G.
 | last2 = Gotlieb | first2 = C. C.
 | doi = 10.1145/321556.321562
 | journal = [[Journal of the ACM]]
 | mr = 0278977
 | pages = 51–64
 | title = An efficient algorithm for graph isomorphism
 | volume = 17
 | year = 1970}}.&lt;br&gt;- {{citation
 | last1 = Read | first1 = Ronald C.
 | last2 = Corneil | first2 = Derek G.
 | issue = 4
 | journal = Journal of Graph Theory
 | mr = 0485586
 | pages = 339–363
 | title = The graph isomorphism disease
 | volume = 1
 | year = 1977
 | doi=10.1002/jgt.3190010410}}.&lt;/ref&gt;

:Algorithmic and structural properties of complement reducible graphs.&lt;ref&gt;{{cite journal | url = http://www.sciencedirect.com/science/article/pii/0166218X81900135# | doi=10.1016/0166-218X(81)90013-5 | volume=3 | title=Complement reducible graphs | journal=Discrete Applied Mathematics | pages=163–174}}&lt;/ref&gt;

:Properties of asteroidal triple-free graphs.&lt;ref&gt;{{cite journal | doi = 10.1137/S0895480193250125 | volume=10 | title=Asteroidal Triple-Free Graphs | journal=SIAM Journal on Discrete Mathematics | pages=399–430}}&lt;/ref&gt;

:An algorithm to solve the problem of determining whether a graph is a partial graph of a k-tree.&lt;ref&gt;{{cite journal | doi = 10.1137/0608024 | volume=8 | title=Complexity of Finding Embeddings in a k -Tree | journal=SIAM Journal on Algebraic Discrete Methods | pages=277–284}}&lt;/ref&gt;

:Results addressing graph theoretic, algorithmic, and complexity issues with regard to [[tree spanner]]s.&lt;ref&gt;{{cite journal | doi = 10.1137/S0895480192237403 | volume=8 | title=Tree Spanners | journal=SIAM Journal on Discrete Mathematics | pages=359–387}}&lt;/ref&gt;

:An explanation of the relationship between tree width and clique-width.&lt;ref&gt;http://epubs.siam.org/doi/abs/10.1137/S0097539701385351&lt;/ref&gt;

:Determining the diameter of restricted graph families.&lt;ref&gt;{{cite journal | url = http://www.sciencedirect.com/science/article/pii/S0166218X0000281X | doi=10.1016/S0166-218X(00)00281-X | volume=113 | title=Diameter determination on restricted graph families | journal=Discrete Applied Mathematics | pages=143–166}}&lt;/ref&gt;

:Outlining the structure of trapezoid graphs.&lt;ref&gt;{{cite journal | url = http://www.sciencedirect.com/science/article/pii/S0166218X1100117X | doi=10.1016/j.dam.2011.03.023 | volume=159 | title=Vertex splitting and the recognition of trapezoid graphs | journal=Discrete Applied Mathematics | pages=1131–1147}}&lt;/ref&gt;

As a professor ''emeritus'', Corneil still does research and is also an editor of several publications such as ''Ars Combinatoria'' and ''SIAM Monographs on Discrete Mathematics and Applications''.

==Awards==
He was inducted as a Fields Institute Fellow in 2004.&lt;ref&gt;[http://www.fields.utoronto.ca/honours/fieldsinstfellows.html Fields Institute Fellows]. Retrieved 18 February 2012.&lt;/ref&gt;

==References==
{{Reflist}}

==External links==
*[http://blogs.technet.com/b/cdnitmanagers/archive/2011/06/13/derek-corneil-renowned-and-esteemed-computer-science-professor-emeritus-university-of-toronto.aspx Interview with Corneil], Stephen Ibaraki, 13 June 2011
*[http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Corneil:Derek_G=.html List of publications] at DBLP

{{Authority control}}

{{DEFAULTSORT:Corneil, Derek Gordon}}
[[Category:1942 births]]
[[Category:Living people]]
[[Category:Canadian mathematicians]]
[[Category:Canadian computer scientists]]
[[Category:Graph theorists]]
[[Category:Queen's University alumni]]
[[Category:University of Toronto alumni]]
[[Category:University of Toronto faculty]]</text>
      <sha1>7ztg6smg3d05w55r0zzt2f09l87bgq1</sha1>
    </revision>
  </page>
  <page>
    <title>Derivative</title>
    <ns>0</ns>
    <id>7921</id>
    <revision>
      <id>867838999</id>
      <parentid>867838993</parentid>
      <timestamp>2018-11-08T09:48:40Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/112.200.44.226|112.200.44.226]] to version by ChamithN. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3535194) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="62749">{{about|the term as used in [[calculus]]|a less technical overview of the subject|differential calculus|other uses|}}
{{good article}}
[[File:Tangent to a curve.svg|thumb|The [[graph of a function]], drawn in black, and a [[tangent line]] to that function, drawn in red.  The [[slope]] of the tangent line is equal to the derivative of the function at the marked point.]]
{{Calculus |differential}}

The '''derivative''' of a [[function of a real variable]] measures the sensitivity to change of the function value (output value) with respect to a change in its argument (input value). Derivatives are a fundamental tool of [[calculus]].  For example, the derivative of the position of a moving object with respect to [[time]] is the object's [[velocity]]: this measures how quickly the position of the object changes when time advances.

The derivative of a function of a single variable at a chosen input value, when it exists, is the [[slope]] of the [[Tangent|tangent line]] to the [[graph of a function|graph of the function]] at that point. The tangent line is the best [[linear approximation]] of the function near that input value.  For this reason, the derivative is often described as the "instantaneous rate of change", the ratio of the instantaneous change in the dependent variable to that of the independent variable.

Derivatives may be generalized to [[function of several real variables|functions of several real variables]]. In this generalization, the derivative is reinterpreted as a [[linear transformation]] whose graph is (after an appropriate translation) the best linear approximation to the graph of the original function. The [[Jacobian matrix]] is the [[matrix (mathematics)|matrix]] that represents this linear transformation with respect to the basis given by the choice of independent and dependent variables.  It can be calculated in terms of the [[partial derivative]]s with respect to the independent variables.  For a [[real-valued function]] of several variables, the Jacobian matrix reduces to the [[gradient vector]].

The process of finding a derivative is called '''differentiation'''. The reverse process is called ''[[antiderivative|antidifferentiation]]''.  The [[fundamental theorem of calculus]] states that antidifferentiation is the same as [[integral|integration]]. Differentiation and integration constitute the two fundamental operations in single-variable calculus.{{#tag:ref|Differential calculus, as discussed in this article, is a very well established mathematical discipline for which there are many sources. See Apostol 1967, Apostol 1969, and Spivak 1994.|group=Note}}

==Differentiation==
''Differentiation'' is the action of computing a derivative. The derivative of a [[function (mathematics)|function]] {{math|1=''y'' = ''f''(''x'')}} of a variable {{math|''x''}} is a measure of the rate at which the value {{math|''y''}} of the function changes with respect to the change of the variable {{math|''x''}}. It is called the ''derivative'' of {{math|''f''}} with respect to {{math|''x''}}. If {{math|''x''}} and {{math|''y''}} are [[real number]]s, and if the [[graph of a function|graph]] of {{math|''f''}} is plotted against {{math|''x''}}, the derivative is the [[slope]] of this graph at each point.

[[File:Wiki slope in 2d.svg|right|thumb|250px|Slope of a linear function: &lt;math&gt;m=\frac{\Delta y}{\Delta x}&lt;/math&gt;]]
The simplest case, apart from the trivial case of a [[constant function]], is when {{math|''y''}} is a [[linear function]] of {{math|''x''}}, meaning that the graph of {{math|''y''}} is a line. In this case, {{math|''y'' {{=}} ''f''(''x'') {{=}} ''mx'' + ''b''}}, for real numbers {{math|''m''}} and {{math|''b''}}, and the slope {{math|''m''}} is given by
:&lt;math&gt;m=\frac{\text{change in } y}{\text{change in } x} = \frac{\Delta y}{\Delta x},&lt;/math&gt;
where the symbol {{math|Δ}} ([[Delta (letter)|Delta]]) is an abbreviation for "change in". This formula is true because
:&lt;math&gt;y+\Delta y=f\left( x+\Delta x\right) 
=m\left( x+\Delta x\right) +b 
=mx +m\,\Delta x +b
= y + m\,\Delta x. &lt;/math&gt;
Thus, since
:&lt;math&gt;y+\Delta y=y+m\,\Delta x, &lt;/math&gt;
it follows that
:&lt;math&gt; \Delta y=m\,\Delta x. &lt;/math&gt;

This gives an exact value for the slope of a line.
If the function {{math|''f''}} is not linear (i.e. its graph is not a straight line), however, then the change in {{math|''y''}} divided by the change in {{math|''x''}} varies: differentiation is a method to find an exact value for this rate of change at any given value of {{math|''x''}}.

{{multiple image
 | align     = right
 | direction = vertical
 | width     = 250
 | header    = Rate of change as a limit value
 | image1    = Tangent-calculus.svg
 | caption1  = '''Figure 1'''. The [[tangent]] line at (''x'', ''f''(''x''))
 | image2    = Secant-calculus.svg
 | caption2  = '''Figure 2.''' The [[Secant line|secant]] to curve ''y''= ''f''(''x'') determined by points (''x'', ''f''(''x'')) and {{nowrap|(''x'' + ''h'', ''f''(''x'' + ''h''))}}
 | image3  = Lim-secant.svg
 | caption3  = '''Figure 3.''' The tangent line as limit of secants
 | image4  = Derivative GIF.gif
 | caption4  = '''Figure 4.''' Animated illustration: the tangent line (derivative) as the limit of secants
 }}

The idea, illustrated by Figures 1 to 3, is to compute the rate of change as the [[limit of a function|limit value]] of the [[difference quotient|ratio of the differences]] {{math|Δ''y'' / Δ''x''}} as {{math|Δ''x''}} becomes infinitely small.

===Notation===
{{main article|Notation for differentiation}}
Two distinct notations are commonly used for the derivative, one deriving from [[Leibniz]] and the other from [[Joseph Louis Lagrange]].

In [[Leibniz's notation]], an [[infinitesimal]] change in {{math|''x''}} is denoted by {{math|''dx''}}, and the derivative of {{math|''y''}} with respect to {{math|''x''}} is written
: &lt;math&gt; \frac{dy}{dx} &lt;/math&gt;
suggesting the ratio of two infinitesimal quantities.  (The above expression is read as "the derivative of ''y'' with respect to ''x''", "''dy'' by ''dx''", or "''dy'' over ''dx''". The oral form "''dy'' ''dx''" is often used conversationally, although it may lead to confusion.)

In [[Lagrange's notation]], the derivative with respect to {{math|''x''}} of a function {{math|''f''(''x'')}} is denoted {{math|''f'''(''x'')}} (read as "''f'' prime of ''x''") or {{math|''f&lt;sub&gt;x&lt;/sub&gt;''′(''x'')}} (read as "''f'' prime ''x'' of ''x''"), in case of ambiguity of the variable implied by the derivation. Lagrange's notation is sometimes incorrectly attributed to [[Isaac Newton|Newton]].

===Rigorous definition===
[[File:Tangent animation.gif|thumb|250px|A secant approaches a tangent when &lt;math&gt;\Delta x \to 0&lt;/math&gt;.]]
The most common approach to turn this intuitive idea into a precise definition is to define the derivative as a [[limit (mathematics)|limit]] of difference quotients of real numbers.&lt;ref&gt;Spivak 1994, chapter 10.&lt;/ref&gt;  This is the approach described below.

Let {{math|''f''}} be a real valued function defined in an [[open neighborhood]] of a real number {{math|''a''}}.  In classical geometry, the tangent line to the graph of the function {{math|''f''}} at {{math|''a''}} was the unique line through the point {{math|(''a'', ''f''(''a''))}} that did ''not'' meet the graph of {{math|''f''}} [[transversality (mathematics)|transversally]], meaning that the line did not pass straight through the graph.  The derivative of {{math|''y''}} with respect to {{math|''x''}} at {{math|''a''}} is, geometrically, the slope of the tangent line to the graph of {{math|''f''}} at {{math|(''a'', ''f''(''a''))}}.  The slope of the tangent line is very close to the slope of the line through {{math|(''a'', ''f''(''a''))}} and a nearby point on the graph, for example {{math|(''a'' + ''h'', ''f''(''a'' + ''h''))}}.  These lines are called [[secant line]]s.  A value of {{math|''h''}} close to zero gives a good approximation to the slope of the tangent line, and smaller values (in [[absolute value]]) of {{math|''h''}} will, in general, give better [[approximation]]s.  The slope {{math|''m''}} of the secant line is the difference between the {{math|''y''}} values of these points divided by the difference between the {{math|''x''}} values, that is, 
:&lt;math&gt;m = \frac{\Delta f(a)}{\Delta a} = \frac{f(a+h)-f(a)}{(a+h)-(a)} = \frac{f(a+h)-f(a)}{h}.&lt;/math&gt;

This expression is [[Isaac Newton|Newton]]'s [[difference quotient]].  Passing from an approximation to an exact answer is done using a [[limit of a function|limit]].  Geometrically, the limit of the secant lines is the tangent line.  Therefore, the limit of the difference quotient as {{math|''h''}} approaches zero, if it exists, should represent the slope of the tangent line to {{math|(''a'', ''f''(''a''))}}.  This limit is defined to be the derivative of the function {{math|''f''}} at {{math|''a''}}:

:&lt;math&gt;f'(a)=\lim_{h\to 0}\frac{f(a+h)-f(a)}{h}.&lt;/math&gt;

When the limit exists, {{math|''f''}} is said to be ''[[differentiable function|differentiable]]'' at {{math|''a''}}.  Here {{math|''f''{{′}}(''a'')}} is one of several common notations for the derivative ([[Derivative#Notations for differentiation|see below]]).

Equivalently, the derivative satisfies the property that
:&lt;math&gt;\lim_{h\to 0}\frac{f(a+h) - (f(a) + f'(a)\cdot h)}{h} = 0,&lt;/math&gt;
which has the intuitive interpretation (see Figure 1) that the tangent line to {{math|''f''}} at {{math|''a''}} gives the ''best [[linear]] approximation''
:&lt;math&gt;f(a+h) \approx f(a) + f'(a)h&lt;/math&gt;
to {{math|''f''}} near {{math|''a''}} (i.e., for small {{math|''h''}}). This interpretation is the easiest to generalize to other settings ([[Derivative#Total derivative, total differential and Jacobian matrix|see below]]).

[[Substitution property of equality|Substituting]] 0 for {{math|''h''}} in the difference quotient causes [[division by zero]], so the slope of the tangent line cannot be found directly using this method.  Instead, define {{math|''Q''(''h'')}} to be the difference quotient as a function of {{math|''h''}}:

:&lt;math&gt;Q(h) = \frac{f(a + h) - f(a)}{h}.&lt;/math&gt;

{{math|''Q''(''h'')}} is the slope of the secant line between {{math|(''a'', ''f''(''a''))}} and {{math|(''a'' + ''h'', ''f''(''a'' + ''h''))}}.  If {{math|''f''}} is a [[continuous function]], meaning that its graph is an unbroken curve with no gaps, then {{math|''Q''}} is a continuous function away from {{math|''h'' {{=}} 0}}.  If the limit {{math|lim{{sub|''h''→0}}''Q''(''h'')}} exists, meaning that there is a way of choosing a value for {{math|''Q''(0)}} that makes {{math|''Q''}} a continuous function, then the function {{math|''f''}} is differentiable at {{math|''a''}}, and its derivative at {{math|''a''}} equals {{math|''Q''(0)}}.

In practice, the existence of a continuous extension of the difference quotient {{math|''Q''(''h'')}} to {{math|''h'' {{=}} 0}} is shown by modifying the numerator to cancel {{math|''h''}} in the denominator. Such manipulations can make the limit value of {{math|''Q''}} for small {{math|''h''}} clear even though {{math|''Q''}} is still not defined at {{math|''h'' {{=}} 0}}. This process can be long and tedious for complicated functions, and many shortcuts are commonly used to simplify the process.

===Definition over the hyperreals===
Relative to a [[hyperreal number|hyperreal]] extension {{math|'''R''' ⊂ &lt;sup&gt;∗&lt;/sup&gt;'''R'''}} of the real numbers, the derivative of a real function {{math|''y'' {{=}} ''f''(''x'')}} at a real point {{math|''x''}} can be defined as the [[shadow (mathematics)|shadow]] of the quotient {{math|{{sfrac|∆''y''|∆''x''}}}} for [[infinitesimal]] {{math|∆''x''}}, where {{math|∆''y'' {{=}} ''f''(''x'' + ∆''x'') − ''f''(''x'')}}. Here the natural extension of {{math|''f''}} to the hyperreals is still denoted {{math|''f''}}. Here the derivative is said to exist if the shadow is independent of the infinitesimal chosen.

===Example===
[[File:Parabola2.svg|thumb|The squaring function]]
The squaring function given by {{math|''f''(''x'') {{=}} ''x''&lt;sup&gt;2&lt;/sup&gt;}} is differentiable at {{math|''x'' {{=}} 3}}, and its derivative there is 6. This result is established by calculating the limit as {{math|''h''}} approaches zero of the difference quotient of {{math|''f''(3)}}:

:&lt;math&gt;
\begin{align}
f'(3) &amp; = \lim_{h\to 0}\frac{f(3+h)-f(3)}{h} = \lim_{h\to 0}\frac{(3+h)^2 - 3^2}{h} \\[10pt]
&amp; = \lim_{h\to 0}\frac{9 + 6h + h^2 - 9}{h} = \lim_{h\to 0}\frac{6h + h^2}{h} = \lim_{h\to 0}{(6 + h)}.
\end{align}
&lt;/math&gt;

The last expression shows that the difference quotient equals {{math|6 + ''h''}} when {{math|''h'' ≠ 0}} and is undefined when {{math|''h'' {{=}} 0}}, because of the definition of the difference quotient.  However, the definition of the limit says the difference quotient does not need to be defined when {{math|''h'' {{=}} 0}}.  The limit is the result of letting {{math|''h''}} go to zero, meaning it is the value that {{math|6 + ''h''}} tends to as {{math|''h''}} becomes very small:

:&lt;math&gt; \lim_{h\to 0}{(6 + h)} = 6 + 0 = 6. &lt;/math&gt;

Hence the slope of the graph of the squaring function at the point {{math|(3, 9)}} is {{math|6}}, and so its derivative at {{math|''x'' {{=}} 3}} is {{math|''f''{{′}}(3) {{=}} 6}}.

More generally, a similar computation shows that the derivative of the squaring function at {{math|''x'' {{=}} ''a''}} is {{math|''f''{{′}}(''a'') {{=}} 2''a''}}:

:&lt;math&gt;\begin{align}
f'(a) &amp; = \lim_{h\to 0}\frac{f(a+h)-f(a)}{h} = \lim_{h\to 0}\frac{(a+h)^2 - a^2}{h} \\[0.3em]
&amp; = \lim_{h\to 0}\frac{a^2 + 2ah + h^2 - a^2}{h} = \lim_{h\to 0}\frac{2ah + h^2}{h} \\[0.3em]
&amp; = \lim_{h\to 0}{(2a + h)} = 2a
\end{align}&lt;/math&gt;

===Continuity and differentiability===

[[File:Right-continuous.svg|thumb|right|This function does not have a derivative at the marked point, as the function is not continuous there (specifically, it has a [[jump discontinuity]]).]]

If {{math|''f''}} is [[differentiable function|differentiable]] at {{math|''a''}}, then {{math|''f''}} must also be [[continuous function|continuous]] at {{math|''a''}}.  As an example, choose a point {{math|''a''}} and let {{math|''f''}} be the [[step function]] that returns the value 1 for all {{math|''x''}} less than {{math|''a''}}, and returns a different value 10 for all {{math|''x''}} greater than or equal to {{math|''a''}}.  {{math|''f''}} cannot have a derivative at {{math|''a''}}.  If {{math|''h''}} is negative, then {{math|''a'' + ''h''}} is on the low part of the step, so the secant line from {{math|''a''}} to {{math|''a'' + ''h''}} is very steep, and as {{math|''h''}} tends to zero the slope tends to infinity.  If {{math|''h''}} is positive, then {{math|''a'' + ''h''}} is on the high part of the step, so the secant line from {{math|''a''}} to {{math|''a'' + ''h''}} has slope zero.  Consequently, the secant lines do not approach any single slope, so the limit of the difference quotient does not exist.{{#tag:ref|Despite this, it is still possible to take the derivative in the sense of [[distribution (mathematics)|distributions]].  The result is nine times the [[Dirac measure]] centered at {{math|''a''}}.{{citation needed|date=June 2016}}|group=Note}}

[[File:Absolute value.svg|right|thumb|The absolute value function is continuous, but fails to be differentiable at {{math|''x'' {{=}} 0}} since the tangent slopes do not approach the same value from the left as they do from the right.]]

However, even if a function is continuous at a point, it may not be differentiable there.  For example, the [[absolute value]] function given by {{math|''f''(''x'') {{=}} {{abs|''x''}} }} is continuous at {{math|''x'' {{=}} 0}}, but it is not differentiable there.  If {{math|''h''}} is positive, then the slope of the secant line from 0 to {{math|''h''}} is one, whereas if {{math|''h''}} is negative, then the slope of the secant line from 0 to {{math|''h''}} is negative one.  This can be seen graphically as a "kink" or a "cusp" in the graph at {{math|''x'' {{=}} 0}}.  Even a function with a smooth graph is not differentiable at a point where its [[Vertical tangent|tangent is vertical]]: For instance, the function given by {{math|''f''(''x'') {{=}} ''x''&lt;sup&gt;1/3&lt;/sup&gt;}} is not differentiable at {{math|''x'' {{=}} 0}}.

In summary: for a function {{math|''f''}} to have a derivative it is ''[[Necessary and sufficient conditions|necessary]]'' for the function {{math|''f''}} to be continuous, but continuity alone is not ''[[Necessary and sufficient conditions|sufficient]]''.

Most functions that occur in practice have derivatives at all points or at [[Almost everywhere|almost every]] point.  Early in the [[history of calculus]], many mathematicians assumed that a continuous function was differentiable at most points.  Under mild conditions, for example if the function is a [[monotone function]] or a [[Lipschitz function]], this is true.  However, in 1872 Weierstrass found the first example of a function that is continuous everywhere but differentiable nowhere.  This example is now known as the [[Weierstrass function]].  In 1931, [[Stefan Banach]] proved that the set of functions that have a derivative at some point is a [[meager set]] in the space of all continuous functions.&lt;ref&gt;{{Citation|author=Banach, S.|title=Uber die Baire'sche Kategorie gewisser Funktionenmengen|journal=Studia. Math.|issue=3|year=1931|pages=174–179|postscript=.}}.  Cited by {{Citation|author1=Hewitt, E |author2=Stromberg, K|title=Real and abstract analysis|publisher=Springer-Verlag|year=1963|pages=Theorem 17.8|nopp=true}}&lt;/ref&gt; Informally, this means that hardly do any random continuous functions have a derivative at even one point.

===The derivative as a function=== &lt;!-- Removing "The derivative as a" completely changes the meaning --&gt;
[[File:Tangent function animation.gif|thumb|The derivative at different points of a differentiable function. In this case, the derivative is equal to:&lt;math&gt;\sin(x^2) + 2x^2 \cos(x^2)&lt;/math&gt;]]
Let {{math|''f''}} be a function that has a derivative at every point in its [[domain of a function|domain]].  We can then define a function that maps every point &lt;math&gt;x&lt;/math&gt; to the value of the derivative of &lt;math&gt;f&lt;/math&gt; at &lt;math&gt;x&lt;/math&gt;.  This function is written {{math|''f''{{′}}}} and is called the ''derivative function'' or the ''derivative of''  {{math|''f''}}.

Sometimes {{math|''f''}} has a derivative at most, but not all, points of its domain.  The function whose value at {{math|''a''}} equals {{math|''f''{{′}}(''a'')}} whenever {{math|''f''{{′}}(''a'')}} is defined and elsewhere is undefined is also called the derivative of {{math|''f''}}.  It is still a function, but its domain is strictly smaller than the domain of {{math|''f''}}.

Using this idea, differentiation becomes a function of functions: The derivative is an [[operator (mathematics)|operator]] whose domain is the set of all functions that have derivatives at every point of their domain and whose range is a set of functions.  If we denote this operator by {{math|''D''}}, then {{math|''D''(''f'')}} is the function {{math|''f''{{′}}}}.  Since {{math|''D''(''f'')}} is a function, it can be evaluated at a point {{math|''a''}}.  By the definition of the derivative function, {{math|''D''(''f'')(''a'') {{=}} ''f''{{′}}(''a'')}}.

For comparison, consider the doubling function given by {{math|''f''(''x'') {{=}} 2''x''}}; {{math|''f''}} is a real-valued function of a real number, meaning that it takes numbers as inputs and has numbers as outputs:
:&lt;math&gt;\begin{align}
 1 &amp;{}\mapsto 2,\\
 2 &amp;{}\mapsto 4,\\
 3 &amp;{}\mapsto 6.
\end{align}&lt;/math&gt;
The operator {{math|''D''}}, however, is not defined on individual numbers.  It is only defined on functions:
:&lt;math&gt;\begin{align}
 D(x \mapsto 1) &amp;= (x \mapsto 0),\\
 D(x \mapsto x) &amp;= (x \mapsto 1),\\
 D(x \mapsto x^2) &amp;= (x \mapsto 2\cdot x).
\end{align}&lt;/math&gt;
Because the output of {{math|''D''}} is a function, the output of {{math|''D''}} can be evaluated at a point.  For instance, when {{math|''D''}} is applied to the squaring function, {{math|''x'' ↦ ''x''&lt;sup&gt;2&lt;/sup&gt;}}, {{math|''D''}} outputs the doubling function {{math|''x'' ↦ 2''x''}}, which we named {{math|''f''(''x'')}}. This output function can then be evaluated to get {{math|''f''(1) {{=}} 2}}, {{math|''f''(2) {{=}} 4}}, and so on.

==={{anchor|order of derivation}} Higher derivatives===

Let {{math|''f''}} be a differentiable function, and let {{math|''f'' ′}} be its derivative. The derivative of {{math|''f'' ′}} (if it has one) is written {{math|''f'' ′′}} and is called the ''[[second derivative]] of {{math|f}}''.  Similarly, the derivative of the second derivative, if it exists, is written {{math|''f'' ′′′}} and is called the ''[[third derivative]] of {{math|f}}''. Continuing this process, one can define, if it exists, the {{math|''n''}}th derivative as the derivative of the {{math|(''n''-1)}}th derivative. These repeated derivatives are called ''higher-order derivatives''. The {{math|''n''}}th derivative is also called the '''derivative of order {{math|''n''}}'''.

If {{math|''x''(''t'')}} represents the position of an object at time {{math|''t''}}, then the higher-order derivatives of {{math|''x''}} have physical interpretations.  The second derivative of {{math|''x''}} is the derivative of {{math|''x''′}}, the velocity, and by definition this is the object's [[acceleration]]. The third derivative of {{math|''x''}} is defined to be the [[jerk (physics)|jerk]], and the fourth derivative is defined to be the [[jounce]].

A function {{math|''f''}} need not have a derivative (for example, if it is not continuous).  Similarly, even if {{math|''f''}} does have a derivative, it may not have a second derivative.  For example, let
:&lt;math&gt;f(x) = \begin{cases} +x^2, &amp; \text{if }x\ge 0 \\ -x^2, &amp; \text{if }x \le 0.\end{cases}&lt;/math&gt;
Calculation shows that {{math|''f''}} is a differentiable function whose derivative at &lt;math&gt;x&lt;/math&gt; is given by
:&lt;math&gt;f'(x) = \begin{cases} +2x, &amp; \text{if }x\ge 0 \\ -2x, &amp; \text{if }x \le 0.\end{cases}&lt;/math&gt;
{{math|''f'''(''x'')}} is twice the absolute value function at &lt;math&gt;x&lt;/math&gt;, and it does not have a derivative at zero. Similar examples show that a function can have a {{math|''k''}}th derivative for each non-negative integer {{math|''k''}} but not a {{math|(''k'' + 1)}}th derivative.  A function that has {{math|''k''}} successive derivatives is called ''{{math|k}} times differentiable''.  If in addition the {{math|''k''}}th derivative is continuous, then the function is said to be of [[differentiability class]] {{math|''C&lt;sup&gt;k&lt;/sup&gt;''}}.  (This is a stronger condition than having {{math|''k''}} derivatives, as shown by the second example of {{slink|Smoothness|Examples}}.)  A function that has infinitely many derivatives is called ''infinitely differentiable'' or ''[[smoothness|smooth]]''.

On the real line, every [[polynomial function]] is infinitely differentiable.  By standard [[differentiation rules]], if a polynomial of degree {{math|''n''}} is differentiated {{math|''n''}} times, then it becomes a [[constant function]].  All of its subsequent derivatives are identically zero.  In particular, they exist, so polynomials are smooth functions.

The derivatives of a function {{math|''f''}} at a point {{math|''x''}} provide polynomial approximations to that function near {{math|''x''}}. For example, if {{math|''f''}} is twice differentiable, then
:&lt;math&gt; f(x+h) \approx f(x) + f'(x)h + \tfrac{1}{2} f''(x) h^2&lt;/math&gt;
in the sense that
:&lt;math&gt; \lim_{h\to 0}\frac{f(x+h) - f(x) - f'(x)h - \frac{1}{2} f''(x) h^2}{h^2}=0.&lt;/math&gt;
If {{math|''f''}} is infinitely differentiable, then this is the beginning of the [[Taylor series]] for {{math|''f''}} evaluated at {{math|''x'' + ''h''}} around {{math|''x''}}.

===Inflection point===
{{Main|Inflection point}}

A point where the second derivative of a function changes sign is called an ''inflection point''.&lt;ref&gt;{{harvnb|Apostol|1967|loc=§4.18}}&lt;/ref&gt; At an inflection point, the second derivative may be zero, as in the case of the inflection point {{math|''x'' {{=}} 0}} of the function given by &lt;math&gt;f(x) = x^3&lt;/math&gt;, or it may fail to exist, as in the case of the inflection point {{math|''x'' {{=}} 0}} of the function given by &lt;math&gt;f(x) = x^\frac{1}{3}&lt;/math&gt;. At an inflection point, a function switches from being a [[convex function]] to being a [[concave function]] or vice versa.

==Notation (details)==
{{Main|Notation for differentiation}}

===Leibniz's notation===
{{Main|Leibniz's notation}}

The symbols &lt;math&gt;dx&lt;/math&gt;, &lt;math&gt;dy&lt;/math&gt;, and &lt;math&gt;\frac{dy}{dx}&lt;/math&gt; were introduced by [[Gottfried Leibniz|Gottfried Wilhelm Leibniz]] in 1675.&lt;ref&gt;Manuscript of November 11, 1675 (Cajori vol. 2, page 204)&lt;/ref&gt; It is still commonly used when the equation {{nowrap|1=''y'' = ''f''(''x'')}} is viewed as a functional relationship between [[dependent and independent variables]]. Then the first derivative is denoted by

: &lt;math&gt;\frac{dy}{dx},\quad\frac{d f}{dx}, \text{  or  }\frac{d}{dx}f,&lt;/math&gt;

and was once thought of as an [[infinitesimal]] quotient.  Higher derivatives are expressed using the notation

&lt;!-- In the following formula, the function is a lower-case f, not an upper case F.  Please do not change it.--&gt;
: &lt;math&gt;\frac{d^ny}{dx^n},
\quad\frac{d^n f}{dx^n},
\text{  or  }
\frac{d^n}{dx^n}f&lt;/math&gt;

for the ''n''th derivative of &lt;math&gt;y = f(x)&lt;/math&gt;. These are abbreviations for multiple applications of the derivative operator. For example,
:&lt;math&gt;\frac{d^2y}{dx^2} = \frac{d}{dx}\left(\frac{dy}{dx}\right).&lt;/math&gt;

With Leibniz's notation, we can write the derivative of &lt;math&gt;y&lt;/math&gt; at the point &lt;math&gt;x = a&lt;/math&gt; in two different ways:

: &lt;math&gt;\left.\frac{dy}{dx}\right|_{x=a} = \frac{dy}{dx}(a).&lt;/math&gt;

Leibniz's notation allows one to specify the variable for differentiation (in the denominator), which is relevant in [[partial derivative|partial differentiation]].  It also makes the [[chain rule]] easier to remember:{{#tag:ref|In the formulation of calculus in terms of limits, the ''du'' symbol has been assigned various meanings by various authors.  Some authors do not assign a meaning to ''du'' by itself, but only as part of the symbol ''du''/''dx''.  Others define ''dx'' as an independent variable, and define ''du'' by {{nowrap|1=''du'' = ''dx''⋅''f''{{′}}(''x'')}}.  In [[non-standard analysis]] ''du'' is defined as an infinitesimal. It is also interpreted as the [[exterior derivative]] of a function ''u''. See [[differential (infinitesimal)]] for further information.|group=Note}}

: &lt;math&gt;\frac{dy}{dx} = \frac{dy}{du} \cdot \frac{du}{dx}.&lt;/math&gt;

===Lagrange's notation===
Sometimes referred to as ''prime notation'',&lt;ref&gt;{{cite web|title=The Notation of Differentiation|url=http://web.mit.edu/wwmath/calculus/differentiation/notation.html|publisher=MIT|accessdate=24 October 2012|year=1998}}&lt;/ref&gt;  one of the most common modern notation for differentiation is due to [[Joseph-Louis Lagrange]] and uses the [[Prime (symbol)|prime mark]], so that the derivative of a function &lt;math&gt;f&lt;/math&gt; is denoted &lt;math&gt;f'&lt;/math&gt;. Similarly, the second and third derivatives are denoted
:&lt;math&gt;(f')'=f''&lt;/math&gt; &amp;emsp; and &amp;emsp; &lt;math&gt;(f'')'=f'''.&lt;/math&gt;
To denote the number of derivatives beyond this point, some authors use Roman numerals in [[Subscript and superscript|superscript]], whereas others place the number in parentheses:
:&lt;math&gt;f^{\mathrm{iv}}&lt;/math&gt; &amp;emsp; or &amp;emsp; &lt;math&gt;f^{(4)}.&lt;/math&gt;
The latter notation generalizes to yield the notation &lt;math&gt;f^{(n)}&lt;/math&gt; for the ''n''th derivative of &lt;math&gt;f&lt;/math&gt; – this notation is most useful when we wish to talk about the derivative as being a function itself, as in this case the Leibniz notation can become cumbersome.

===Newton's notation===
[[Newton's notation]] for differentiation, also called the dot notation, places a dot over the function name to represent a time derivative.  If &lt;math&gt;y = f(t)&lt;/math&gt;, then
:&lt;math&gt;\dot{y}&lt;/math&gt; &amp;emsp; and &amp;emsp; &lt;math&gt;\ddot{y}&lt;/math&gt;
denote, respectively, the first and second derivatives of &lt;math&gt;y&lt;/math&gt;.  This notation is used exclusively for derivatives with respect to time or [[arc length]].  It is very common in [[physics]], [[differential equation]]s, and [[differential geometry]].&lt;ref&gt;{{Cite book|title=Partial Differential Equations|last=Evans|first=Lawrence|publisher=American Mathematical Society|year=1999|isbn=0-8218-0772-2|location=|pages=63}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|title=Differential Geometry|last=Kreyszig|first=Erwin|publisher=Dover|year=1991|isbn=0-486-66721-9|location=New York|pages=1}}&lt;/ref&gt;  While the notation becomes unmanageable for high-order derivatives, in practice only few derivatives are needed.

===Euler's notation===
[[Leonhard Euler|Euler]]'s notation uses a [[differential operator]] &lt;math&gt;D&lt;/math&gt;, which is applied to a function &lt;math&gt;f&lt;/math&gt; to give the first derivative &lt;math&gt;Df&lt;/math&gt;. The ''n''th derivative is denoted &lt;math&gt;D^nf&lt;/math&gt;.

If {{nowrap|1=''y'' = ''f''(''x'')}} is a dependent variable, then often the subscript ''x'' is attached to the ''D'' to clarify the independent variable ''x''.
Euler's notation is then written
:&lt;math&gt;D_x y&lt;/math&gt; &amp;emsp; or &amp;emsp; &lt;math&gt;D_x f(x)&lt;/math&gt;,
although this subscript is often omitted when the variable ''x'' is understood, for instance when this is the only variable present in the expression.

Euler's notation is useful for stating and solving [[linear differential equation]]s.

==Rules of computation==
{{Main|Differentiation rules}}
The derivative of a function can, in principle, be computed from the definition by considering the difference quotient, and computing its limit. In practice, once the derivatives of a few simple functions are known, the derivatives of other functions are more easily computed using ''rules'' for obtaining derivatives of more complicated functions from simpler ones.

===Rules for basic functions===
Most derivative computations eventually require taking the derivative of some common functions. The following incomplete list gives some of the most frequently used functions of a single real variable and their derivatives.

* ''[[Power rule|Derivatives of powers]]'': if

:&lt;math&gt; f(x) = x^r,&lt;/math&gt;

where ''r'' is any [[real number]], then

:&lt;math&gt; f'(x) = rx^{r-1},&lt;/math&gt;

wherever this is defined. For example, if &lt;math&gt;f(x) = x^{1/4}&lt;/math&gt;, then

:&lt;math&gt;f'(x) = (1/4)x^{-3/4},&lt;/math&gt;

and the derivative function is defined only for positive ''x'', not for {{nowrap|1=''x'' = 0}}.  When {{nowrap|1=''r'' = 0}}, this rule implies that ''f''′(''x'') is zero for {{nowrap|''x'' &amp;ne; 0}}, which is almost the constant rule (stated below).

&lt;!--DO NOT ADD TO THIS LIST--&gt;
* ''[[Exponential function|Exponential]] and [[logarithm]]ic functions'':
:&lt;math&gt; \frac{d}{dx}e^x = e^x.&lt;/math&gt;

:&lt;math&gt; \frac{d}{dx}a^x = a^x\ln(a).&lt;/math&gt;

:&lt;math&gt; \frac{d}{dx}\ln(x) = \frac{1}{x},\qquad x &gt; 0.&lt;/math&gt;

:&lt;math&gt; \frac{d}{dx}\log_a(x) = \frac{1}{x\ln(a)}.&lt;/math&gt;
&lt;!--DO NOT ADD TO THIS LIST--&gt;
* ''[[Trigonometric function]]s'':
:&lt;math&gt; \frac{d}{dx}\sin(x) = \cos(x).&lt;/math&gt;

:&lt;math&gt; \frac{d}{dx}\cos(x) = -\sin(x).&lt;/math&gt;

:&lt;math&gt; \frac{d}{dx}\tan(x) = \sec^2(x) = \frac{1}{\cos^2(x)} = 1+\tan^2(x).&lt;/math&gt;
&lt;!--DO NOT ADD TO THIS LIST--&gt;
* ''[[Inverse trigonometric function]]s'':
:&lt;math&gt; \frac{d}{dx}\arcsin(x) = \frac{1}{\sqrt{1-x^2}},\qquad -1&lt;x&lt;1.&lt;/math&gt;
:&lt;math&gt; \frac{d}{dx}\arccos(x)= -\frac{1}{\sqrt{1-x^2}},\qquad -1&lt;x&lt;1.&lt;/math&gt;
:&lt;math&gt; \frac{d}{dx}\arctan(x)= \frac{1}{{1+x^2}}&lt;/math&gt;
&lt;!--DO NOT ADD TO THIS LIST--&gt;

==={{anchor|Rules}}Rules for combined functions===
In many cases, complicated limit calculations by direct application of Newton's difference quotient can be avoided using differentiation rules. Some of the most basic rules are the following.

* ''Constant rule'': if ''f''(''x'') is constant, then
:&lt;math&gt;f'(x) = 0. &lt;/math&gt;
* ''[[Linearity of differentiation|Sum rule]]'':
:&lt;math&gt;(\alpha f + \beta g)' = \alpha f' + \beta g' &lt;/math&gt; for all functions ''f'' and ''g'' and all real numbers ''&lt;math&gt;\alpha&lt;/math&gt;'' and ''&lt;math&gt;\beta&lt;/math&gt;''.
* ''[[Product rule]]'':
:&lt;math&gt;(fg)' = f 'g + fg' &lt;/math&gt; for all functions ''f'' and ''g''. As a special case, this rule includes the fact &lt;math&gt;(\alpha f)' = \alpha f'&lt;/math&gt; whenever &lt;math&gt;\alpha&lt;/math&gt; is a constant, because &lt;math&gt;\alpha' f = 0 \cdot f = 0&lt;/math&gt; by the constant rule.
* ''[[Quotient rule]]'':
:&lt;math&gt;\left(\frac{f}{g} \right)' = \frac{f'g - fg'}{g^2}&lt;/math&gt;  for all functions ''f'' and ''g'' at all inputs where {{nowrap|''g'' ≠ 0}}.
* ''[[Chain rule]]'': If &lt;math&gt;f(x) = h(g(x))&lt;/math&gt;, then
:&lt;math&gt;f'(x) = h'(g(x)) \cdot g'(x). &lt;/math&gt;

===Computation example ===
The derivative of the function given by

: &lt;math&gt;f(x) = x^4 + \sin (x^2) - \ln(x) e^x + 7&lt;/math&gt;

is

: &lt;math&gt;
\begin{align}
f'(x) &amp;= 4 x^{(4-1)}+ \frac{d\left(x^2\right)}{dx}\cos (x^2) - \frac{d\left(\ln {x}\right)}{dx} e^x - \ln(x) \frac{d\left(e^x\right)}{dx} + 0 \\
      &amp;= 4x^3 + 2x\cos (x^2) - \frac{1}{x} e^x - \ln(x) e^x.
\end{align}
&lt;/math&gt;

Here the second term was computed using the [[chain rule]] and third using the [[product rule]]. The known derivatives of the elementary functions ''x''&lt;sup&gt;2&lt;/sup&gt;, ''x''&lt;sup&gt;4&lt;/sup&gt;, sin(''x''), ln(''x'') and {{nowrap|1=exp(''x'') = ''e''&lt;sup&gt;''x''&lt;/sup&gt;}}, as well as the constant 7, were also used.

==In higher dimensions==
{{See also|Vector calculus|Multivariable calculus}}

===Vector-valued functions===
A [[vector-valued function]] '''y''' of a real variable sends real numbers to vectors in some [[vector space]] '''R'''&lt;sup&gt;''n''&lt;/sup&gt;.  A vector-valued function can be split up into its coordinate functions ''y''&lt;sub&gt;1&lt;/sub&gt;(''t''), ''y''&lt;sub&gt;2&lt;/sub&gt;(''t''), …, ''y''&lt;sub&gt;''n''&lt;/sub&gt;(''t''), meaning that {{nowrap|1='''y'''(''t'') = (''y''&lt;sub&gt;1&lt;/sub&gt;(''t''), ..., ''y''&lt;sub&gt;''n''&lt;/sub&gt;(''t''))}}.  This includes, for example, [[parametric curve]]s in '''R'''&lt;sup&gt;2&lt;/sup&gt; or '''R'''&lt;sup&gt;3&lt;/sup&gt;.  The coordinate functions are real valued functions, so the above definition of derivative applies to them.  The derivative of '''y'''(''t'') is defined to be the [[Vector (geometric)|vector]], called the [[Differential geometry of curves|tangent vector]], whose coordinates are the derivatives of the coordinate functions.  That is,
:&lt;math&gt;\mathbf{y}'(t) = (y'_1(t), \ldots, y'_n(t)).&lt;/math&gt;

Equivalently,

:&lt;math&gt;\mathbf{y}'(t)=\lim_{h\to 0}\frac{\mathbf{y}(t+h) - \mathbf{y}(t)}{h},&lt;/math&gt;

if the limit exists.  The subtraction in the numerator is the subtraction of vectors, not scalars.  If the derivative of '''y''' exists for every value of ''t'', then '''y'''′ is another vector-valued function.

If '''e'''&lt;sub&gt;1&lt;/sub&gt;, …, '''e'''&lt;sub&gt;''n''&lt;/sub&gt; is the standard basis for '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, then '''y'''(''t'') can also be written as {{nowrap|''y''&lt;sub&gt;1&lt;/sub&gt;(''t'')'''e'''&lt;sub&gt;1&lt;/sub&gt; + … + ''y''&lt;sub&gt;''n''&lt;/sub&gt;(''t'')'''e'''&lt;sub&gt;''n''&lt;/sub&gt;}}. If we assume that the derivative of a vector-valued function retains the [[linearity of differentiation|linearity]] property, then the derivative of '''y'''(''t'') must be
:&lt;math&gt;y'_1(t)\mathbf{e}_1 + \cdots + y'_n(t)\mathbf{e}_n&lt;/math&gt;
because each of the basis vectors is a constant.

This generalization is useful, for example, if '''y'''(''t'') is the position vector of a particle at time ''t''; then the derivative '''y'''&amp;prime;(''t'') is the [[velocity]] vector of the particle at time ''t''.

===Partial derivatives===
{{Main|Partial derivative}}

Suppose that ''f'' is a function that depends on more than one variable—for instance,
:&lt;math&gt;f(x,y) = x^2 + xy + y^2.&lt;/math&gt;
''f'' can be reinterpreted as a family of functions of one variable indexed by the other variables:
:&lt;math&gt;f(x,y) = f_x(y) = x^2 + xy + y^2.&lt;/math&gt;
In other words, every value of ''x'' chooses a function, denoted ''f&lt;sub&gt;x&lt;/sub&gt;'', which is a function of one real number.{{#tag:ref|This can also be expressed as the operation known as [[currying]].|group=Note}} That is,
:&lt;math&gt;x \mapsto f_x,&lt;/math&gt;
:&lt;math&gt;f_x(y) = x^2 + xy + y^2.&lt;/math&gt;
Once a value of ''x'' is chosen, say ''a'', then {{nowrap|''f''(''x'', ''y'')}} determines a function ''f&lt;sub&gt;a&lt;/sub&gt;'' that sends ''y'' to {{nowrap|''a''&lt;sup&gt;2&lt;/sup&gt; + ay + ''y''&lt;sup&gt;2&lt;/sup&gt;}}:
:&lt;math&gt;f_a(y) = a^2 + ay + y^2.&lt;/math&gt;
In this expression, ''a'' is a ''constant'', not a ''variable'', so ''f&lt;sub&gt;a&lt;/sub&gt;'' is a function of only one real variable.  Consequently, the definition of the derivative for a function of one variable applies:
:&lt;math&gt;f_a'(y) = a + 2y.&lt;/math&gt;
The above procedure can be performed for any choice of ''a''.  Assembling the derivatives together into a function gives a function that describes the variation of ''f'' in the ''y'' direction:
:&lt;math&gt;\frac{\partial f}{\partial y}(x,y) = x + 2y.&lt;/math&gt;
This is the partial derivative of ''f'' with respect to ''y''.  Here [[∂]] is a rounded ''d'' called the '''partial derivative symbol'''.  To distinguish it from the letter ''d'', ∂ is sometimes pronounced "der", "del", or "partial" instead of "dee".

In general, the '''partial derivative''' of a function {{nowrap|''f''(''x''&lt;sub&gt;1&lt;/sub&gt;, …, ''x''&lt;sub&gt;''n''&lt;/sub&gt;)}} in the direction ''x&lt;sub&gt;i&lt;/sub&gt;'' at the point (''a''&lt;sub&gt;1&lt;/sub&gt;, …, ''a''&lt;sub&gt;''n''&lt;/sub&gt;) is defined to be:
:&lt;math&gt;\frac{\partial f}{\partial x_i}(a_1,\ldots,a_n) = \lim_{h \to 0}\frac{f(a_1,\ldots,a_i+h,\ldots,a_n) - f(a_1,\ldots,a_i,\ldots,a_n)}{h}.&lt;/math&gt;
In the above difference quotient, all the variables except ''x&lt;sub&gt;i&lt;/sub&gt;'' are held fixed.  That choice of fixed values determines a function of one variable
:&lt;math&gt;f_{a_1,\ldots,a_{i-1},a_{i+1},\ldots,a_n}(x_i) = f(a_1,\ldots,a_{i-1},x_i,a_{i+1},\ldots,a_n),&lt;/math&gt;
and, by definition,
:&lt;math&gt;\frac{df_{a_1,\ldots,a_{i-1},a_{i+1},\ldots,a_n}}{dx_i}(a_i) = \frac{\partial f}{\partial x_i}(a_1,\ldots,a_n).&lt;/math&gt;
In other words, the different choices of ''a'' index a family of one-variable functions just as in the example above.  This expression also shows that the computation of partial derivatives reduces to the computation of one-variable derivatives.

An important example of a function of several variables is the case of a [[scalar-valued function]] {{nowrap|''f''(''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''n''&lt;/sub&gt;)}} on a domain in Euclidean space '''R'''&lt;sup&gt;''n''&lt;/sup&gt; (e.g., on '''R'''&lt;sup&gt;2&lt;/sup&gt; or '''R'''&lt;sup&gt;3&lt;/sup&gt;). In this case ''f'' has a partial derivative ∂''f''/∂''x''&lt;sub&gt;''j''&lt;/sub&gt; with respect to each variable ''x''&lt;sub&gt;''j''&lt;/sub&gt;. At the point (''a''&lt;sub&gt;1&lt;/sub&gt;, …, ''a''&lt;sub&gt;''n''&lt;/sub&gt;), these partial derivatives define the vector
:&lt;math&gt;\nabla f(a_1, \ldots, a_n) = \left(\frac{\partial f}{\partial x_1}(a_1, \ldots, a_n), \ldots, \frac{\partial f}{\partial x_n}(a_1, \ldots, a_n)\right).&lt;/math&gt;
This vector is called the '''[[gradient]]''' of ''f'' at ''a''.  If ''f'' is differentiable at every point in some domain, then the gradient is a vector-valued function ∇''f'' that takes the point (''a''&lt;sub&gt;1&lt;/sub&gt;, …, ''a''&lt;sub&gt;''n''&lt;/sub&gt;) to the vector ∇''f''(''a''&lt;sub&gt;1&lt;/sub&gt;, …, ''a''&lt;sub&gt;''n''&lt;/sub&gt;).  Consequently, the gradient determines a [[vector field]].

===Directional derivatives===
{{Main|Directional derivative}}

If ''f'' is a real-valued function on '''R'''&lt;sup&gt;n&lt;/sup&gt;, then the partial derivatives of ''f'' measure its variation in the direction of the coordinate axes.  For example, if ''f'' is a function of ''x'' and ''y'', then its partial derivatives measure the variation in ''f'' in the ''x'' direction and the ''y'' direction.  They do not, however, directly measure the variation of ''f'' in any other direction, such as along the diagonal line {{nowrap|1=''y'' = ''x''}}.  These are measured using directional derivatives.  Choose a vector
:&lt;math&gt;\mathbf{v} = (v_1,\ldots,v_n).&lt;/math&gt;
The '''directional derivative''' of ''f'' in the direction of '''v''' at the point '''x''' is the limit
:&lt;math&gt;D_{\mathbf{v}}{f}(\mathbf{x}) = \lim_{h \rightarrow 0}{\frac{f(\mathbf{x} + h\mathbf{v}) - f(\mathbf{x})}{h}}.&lt;/math&gt;
In some cases it may be easier to compute or estimate the directional derivative after changing the length of the vector.  Often this is done to turn the problem into the computation of a directional derivative in the direction of a unit vector.  To see how this works, suppose that {{nowrap|1='''v''' = ''λ'''''u'''}}.  Substitute {{nowrap|1=''h'' = ''k''/''λ''}} into the difference quotient.  The difference quotient becomes:
:&lt;math&gt;\frac{f(\mathbf{x} + (k/\lambda)(\lambda\mathbf{u})) - f(\mathbf{x})}{k/\lambda}
= \lambda\cdot\frac{f(\mathbf{x} + k\mathbf{u}) - f(\mathbf{x})}{k}.&lt;/math&gt;
This is ''λ'' times the difference quotient for the directional derivative of ''f'' with respect to '''u'''. Furthermore, taking the limit as ''h'' tends to zero is the same as taking the limit as ''k'' tends to zero because ''h'' and ''k'' are multiples of each other.  Therefore, {{nowrap|1=''D''&lt;sub&gt;'''v'''&lt;/sub&gt;(''f'') = λ''D''&lt;sub&gt;'''u'''&lt;/sub&gt;(''f'')}}.  Because of this rescaling property, directional derivatives are frequently considered only for unit vectors.

If all the partial derivatives of ''f'' exist and are continuous at '''x''', then they determine the directional derivative of ''f'' in the direction '''v''' by the formula:
:&lt;math&gt;D_{\mathbf{v}}{f}(\boldsymbol{x}) = \sum_{j=1}^n v_j \frac{\partial f}{\partial x_j}.&lt;/math&gt;
This is a consequence of the definition of the [[total derivative]].  It follows that the directional derivative is [[linear map|linear]] in '''v''', meaning that {{nowrap|1=''D''&lt;sub&gt;'''v''' + '''w'''&lt;/sub&gt;(''f'') = ''D''&lt;sub&gt;'''v'''&lt;/sub&gt;(''f'') + ''D''&lt;sub&gt;'''w'''&lt;/sub&gt;(''f'')}}.

The same definition also works when ''f'' is a function with values in '''R'''&lt;sup&gt;''m''&lt;/sup&gt;. The above definition is applied to each component of the vectors.  In this case, the directional derivative is a vector in '''R'''&lt;sup&gt;''m''&lt;/sup&gt;.

===Total derivative, total differential and Jacobian matrix===
{{Main|Total derivative}}

When ''f'' is a function from an open subset of '''R'''&lt;sup&gt;''n''&lt;/sup&gt; to '''R'''&lt;sup&gt;''m''&lt;/sup&gt;, then the directional derivative of ''f'' in a chosen direction is the best linear approximation to ''f'' at that point and in that direction.  But when {{nowrap|''n'' &amp;gt; 1}}, no single directional derivative can give a complete picture of the behavior of ''f''. The total derivative gives a complete picture by considering all directions at once.  That is, for any vector '''v''' starting at '''a''', the linear approximation formula holds:
:&lt;math&gt;f(\mathbf{a} + \mathbf{v}) \approx f(\mathbf{a}) + f'(\mathbf{a})\mathbf{v}.&lt;/math&gt;
Just like the single-variable derivative, {{nowrap|''f''&amp;thinsp;&amp;prime;('''a''')}} is chosen so that the error in this approximation is as small as possible.

If ''n'' and ''m'' are both one, then the derivative {{nowrap|''f''&amp;thinsp;′(''a'')}} is a number and the expression {{nowrap|''f''&amp;thinsp;′(''a'')''v''}} is the product of two numbers. But in higher dimensions, it is impossible for {{nowrap|''f''&amp;thinsp;′('''a''')}} to be a number. If it were a number, then {{nowrap|''f''&amp;thinsp;′('''a''')'''v'''}} would be a vector in '''R'''&lt;sup&gt;''n''&lt;/sup&gt; while the other terms would be vectors in '''R'''&lt;sup&gt;''m''&lt;/sup&gt;, and therefore the formula would not make sense. For the linear approximation formula to make sense, {{nowrap|''f''&amp;thinsp;′('''a''')}} must be a function that sends vectors in '''R'''&lt;sup&gt;''n''&lt;/sup&gt; to vectors in '''R'''&lt;sup&gt;''m''&lt;/sup&gt;, and {{nowrap|''f''&amp;thinsp;′('''a''')'''v'''}} must denote this function evaluated at '''v'''.

To determine what kind of function it is, notice that the linear approximation formula can be rewritten as
:&lt;math&gt;f(\mathbf{a} + \mathbf{v}) - f(\mathbf{a}) \approx f'(\mathbf{a})\mathbf{v}.&lt;/math&gt;
Notice that if we choose another vector '''w''', then this approximate equation determines another approximate equation by substituting '''w''' for '''v'''. It determines a third approximate equation by substituting both '''w''' for '''v''' and {{nowrap|'''a''' + '''v'''}} for '''a'''. By subtracting these two new equations, we get
:&lt;math&gt;f(\mathbf{a} + \mathbf{v} + \mathbf{w}) - f(\mathbf{a} + \mathbf{v}) - f(\mathbf{a} + \mathbf{w}) + f(\mathbf{a})
\approx f'(\mathbf{a} + \mathbf{v})\mathbf{w} - f'(\mathbf{a})\mathbf{w}.&lt;/math&gt;
If we assume that '''v''' is small and that the derivative varies continuously in '''a''', then {{nowrap|''f''&amp;thinsp;′('''a''' + '''v''')}} is approximately equal to {{nowrap|''f''&amp;thinsp;′('''a''')}}, and therefore the right-hand side is approximately zero. The left-hand side can be rewritten in a different way using the linear approximation formula with {{nowrap|'''v''' + '''w'''}} substituted for '''v'''. The linear approximation formula implies:
:&lt;math&gt;\begin{align}
0
&amp;\approx f(\mathbf{a} + \mathbf{v} + \mathbf{w}) - f(\mathbf{a} + \mathbf{v}) - f(\mathbf{a} + \mathbf{w}) + f(\mathbf{a}) \\
&amp;= (f(\mathbf{a} + \mathbf{v} + \mathbf{w}) - f(\mathbf{a})) - (f(\mathbf{a} + \mathbf{v}) - f(\mathbf{a})) - (f(\mathbf{a} + \mathbf{w}) - f(\mathbf{a})) \\
&amp;\approx f'(\mathbf{a})(\mathbf{v} + \mathbf{w}) - f'(\mathbf{a})\mathbf{v} - f'(\mathbf{a})\mathbf{w}.
\end{align}&lt;/math&gt;
This suggests that {{nowrap|''f''&amp;thinsp;′('''a''')}} is a [[linear transformation]] from the vector space '''R'''&lt;sup&gt;''n''&lt;/sup&gt; to the vector space '''R'''&lt;sup&gt;''m''&lt;/sup&gt;. In fact, it is possible to make this a precise derivation by measuring the error in the approximations.  Assume that the error in these linear approximation formula is bounded by a constant times ||'''v'''||, where the constant is independent of '''v''' but depends continuously on '''a'''. Then, after adding an appropriate error term, all of the above approximate equalities can be rephrased as inequalities.  In particular, {{nowrap|''f''&amp;thinsp;′('''a''')}} is a linear transformation up to a small error term.  In the limit as '''v''' and '''w''' tend to zero, it must therefore be a linear transformation. Since we define the total derivative by taking a limit as '''v''' goes to zero, {{nowrap|''f''&amp;thinsp;′('''a''')}} must be a linear transformation.

In one variable, the fact that the derivative is the best linear approximation is expressed by the fact that it is the limit of difference quotients.  However, the usual difference quotient does not make sense in higher dimensions because it is not usually possible to divide vectors. In particular, the numerator and denominator of the difference quotient are not even in the same vector space: The numerator lies in the codomain '''R'''&lt;sup&gt;''m''&lt;/sup&gt; while the denominator lies in the domain '''R'''&lt;sup&gt;''n''&lt;/sup&gt;. Furthermore, the derivative is a linear transformation, a different type of object from both the numerator and denominator.  To make precise the idea that {{nowrap|''f''&amp;thinsp;′('''a''')}} is the best linear approximation, it is necessary to adapt a different formula for the one-variable derivative in which these problems disappear. If {{nowrap|''f'' : '''R''' → '''R'''}}, then the usual definition of the derivative may be manipulated to show that the derivative of ''f'' at ''a'' is the unique number {{nowrap|''f''&amp;thinsp;′(''a'')}} such that
:&lt;math&gt;\lim_{h \to 0} \frac{f(a + h) - (f(a) + f'(a)h)}{h} = 0.&lt;/math&gt;
This is equivalent to
:&lt;math&gt;\lim_{h \to 0} \frac{|f(a + h) - (f(a) + f'(a)h)|}{|h|} = 0&lt;/math&gt;
because the limit of a function tends to zero if and only if the limit of the absolute value of the function tends to zero.  This last formula can be adapted to the many-variable situation by replacing the absolute values with [[norm (mathematics)|norm]]s.

The definition of the '''total derivative''' of ''f'' at '''a''', therefore, is that it is the unique linear transformation {{nowrap|''f''&amp;thinsp;′('''a''') : '''R'''&lt;sup&gt;''n''&lt;/sup&gt; → '''R'''&lt;sup&gt;''m''&lt;/sup&gt;}} such that
:&lt;math&gt;\lim_{\mathbf{h}\to 0} \frac{\lVert f(\mathbf{a} + \mathbf{h}) - (f(\mathbf{a}) + f'(\mathbf{a})\mathbf{h})\rVert}{\lVert\mathbf{h}\rVert} = 0.&lt;/math&gt;
Here '''h''' is a vector in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, so the norm in the denominator is the standard length on '''R'''&lt;sup&gt;''n''&lt;/sup&gt;.  However, ''f''′('''a''')'''h''' is a vector in '''R'''&lt;sup&gt;''m''&lt;/sup&gt;, and the norm in the numerator is the standard length on '''R'''&lt;sup&gt;''m''&lt;/sup&gt;.  If ''v'' is a vector starting at ''a'', then {{nowrap|''f''&amp;thinsp;′('''a''')'''v'''}} is called the [[pushforward (differential)|pushforward]] of '''v''' by ''f'' and is sometimes written {{nowrap|''f''&lt;sub&gt;∗&lt;/sub&gt;'''v'''}}.

If the total derivative exists at '''a''', then all the partial derivatives and directional derivatives of ''f'' exist at '''a''', and for all '''v''', {{nowrap|''f''&amp;thinsp;′('''a''')'''v'''}} is the directional derivative of ''f'' in the direction '''v'''.  If we write ''f'' using coordinate functions, so that {{nowrap|1=''f'' = (''f''&lt;sub&gt;1&lt;/sub&gt;, ''f''&lt;sub&gt;2&lt;/sub&gt;, ..., ''f''&lt;sub&gt;''m''&lt;/sub&gt;)}}, then the total derivative can be expressed using the partial derivatives as a [[matrix (mathematics)|matrix]].  This matrix is called the '''[[Jacobian matrix]]''' of ''f'' at '''a''':

:&lt;math&gt;f'(\mathbf{a}) = \operatorname{Jac}_{\mathbf{a}} = \left(\frac{\partial f_i}{\partial x_j}\right)_{ij}.&lt;/math&gt;

The existence of the total derivative ''f''′('''a''') is strictly stronger than the existence of all the partial derivatives, but if the partial derivatives exist and are continuous, then the total derivative exists, is given by the Jacobian, and depends continuously on '''a'''.

The definition of the total derivative subsumes the definition of the derivative in one variable.  That is, if ''f'' is a real-valued function of a real variable, then the total derivative exists if and only if the usual derivative exists.  The Jacobian matrix reduces to a 1×1 matrix whose only entry is the derivative ''f''&amp;prime;(''x'').  This 1×1 matrix satisfies the property that {{nowrap|''f''(''a'' + ''h'') − (''f''(''a'') + ''f''&amp;thinsp;′(''a'')''h'')}} is approximately zero, in other words that

:&lt;math&gt;f(a+h) \approx f(a) + f'(a)h.&lt;/math&gt;

Up to changing variables, this is the statement that the function &lt;math&gt;x \mapsto f(a) + f'(a)(x-a)&lt;/math&gt; is the best linear approximation to ''f'' at ''a''.

The total derivative of a function does not give another function in the same way as the one-variable case.  This is because the total derivative of a multivariable function has to record much more information than the derivative of a single-variable function.  Instead, the total derivative gives a function from the [[tangent bundle]] of the source to the tangent bundle of the target.

The natural analog of second, third, and higher-order total derivatives is not a linear transformation, is not a function on the tangent bundle, and is not built by repeatedly taking the total derivative. The analog of a higher-order derivative, called a [[jet (mathematics)|jet]], cannot be a linear transformation because higher-order derivatives reflect subtle geometric information, such as concavity, which cannot be described in terms of linear data such as vectors.  It cannot be a function on the tangent bundle because the tangent bundle only has room for the base space and the directional derivatives. Because jets capture higher-order information, they take as arguments additional coordinates representing higher-order changes in direction. The space determined by these additional coordinates is called the [[jet bundle]].  The relation between the total derivative and the partial derivatives of a function is paralleled in the relation between the ''k''th order jet of a function and its partial derivatives of order less than or equal to ''k''.

By repeatedly taking the total derivative, one obtains higher versions of the [[Fréchet derivative]], specialized to '''R'''&lt;sup&gt;''p''&lt;/sup&gt;. The ''k''th order total derivative may be interpreted as a map
:&lt;math&gt;D^k f: \mathbb{R}^n \to L^k(\mathbb{R}^n \times \cdots \times \mathbb{R}^n, \mathbb{R}^m)&lt;/math&gt;
which takes a point '''x''' in '''R'''&lt;sup&gt;''n''&lt;/sup&gt; and assigns to it an element of the space of ''k''-linear maps from '''R'''&lt;sup&gt;''n''&lt;/sup&gt; to '''R'''&lt;sup&gt;''m''&lt;/sup&gt; – the "best" (in a certain precise sense) ''k''-linear approximation to ''f'' at that point. By precomposing it with the [[Diagonal functor|diagonal map]] Δ, {{nowrap|'''x''' → ('''x''', '''x''')}}, a generalized Taylor series may be begun as
:&lt;math&gt;\begin{align}
 f(\mathbf{x}) &amp; \approx f(\mathbf{a}) + (D f)(\mathbf{x-a}) + (D^2 f)(\Delta(\mathbf{x-a})) + \cdots\\
 &amp; = f(\mathbf{a}) + (D f)(\mathbf{x - a}) + (D^2 f)(\mathbf{x - a}, \mathbf{x - a})+ \cdots\\
 &amp; = f(\mathbf{a}) + \sum_i (D f)_i (x_i-a_i) + \sum_{j, k} (D^2 f)_{j k} (x_j-a_j) (x_k-a_k) + \cdots
\end{align}&lt;/math&gt;
where f('''a''') is identified with a constant function, {{nowrap|''x''&lt;sub&gt;''i''&lt;/sub&gt; − ''a''&lt;sub&gt;''i''&lt;/sub&gt;}} are the components of the vector {{nowrap|'''x''' − '''a'''}}, and {{nowrap|(''Df'')&lt;sub&gt;''i''&lt;/sub&gt;}} and {{nowrap|(''D''&lt;sup&gt;2&lt;/sup&gt;''f'')&lt;sub&gt;''jk''&lt;/sub&gt;}} are the components of {{nowrap|''Df''}} and {{nowrap|''D''&lt;sup&gt;2&lt;/sup&gt;''f''}} as linear transformations.

==Generalizations==
{{Main|Derivative (generalizations)}}

The concept of a derivative can be extended to many other settings. The common thread is that the derivative of a function at a point serves as a [[linear approximation]] of the function at that point.
* An important generalization of the derivative concerns [[complex function]]s of [[Complex number|complex variable]]s, such as functions from (a domain in) the complex numbers '''C''' to '''C'''. The notion of the derivative of such a function is obtained by replacing real variables with complex variables in the definition. If '''C''' is identified with '''R'''&lt;sup&gt;2&lt;/sup&gt; by writing a complex number ''z'' as {{nowrap|''x'' + ''iy''}}, then a differentiable function from '''C''' to '''C''' is certainly differentiable as a function from '''R'''&lt;sup&gt;2&lt;/sup&gt; to '''R'''&lt;sup&gt;2&lt;/sup&gt; (in the sense that its partial derivatives all exist), but the converse is not true in general: the complex derivative only exists if the real derivative is ''complex linear'' and this imposes relations between the partial derivatives called the [[Cauchy–Riemann equations]] – see [[holomorphic function]]s.
* Another generalization concerns functions between [[smooth manifold|differentiable or smooth manifolds]]. Intuitively speaking such a manifold ''M'' is a space that can be approximated near each point ''x'' by a vector space called its [[tangent space]]: the prototypical example is a [[smooth surface]] in '''R'''&lt;sup&gt;3&lt;/sup&gt;. The derivative (or differential) of a (differentiable) map {{nowrap|''f'': ''M'' → ''N''}} between manifolds, at a point ''x'' in ''M'', is then a [[linear map]] from the tangent space of ''M'' at ''x'' to the tangent space of ''N'' at ''f''(''x''). The derivative function becomes a map between the [[tangent bundle]]s of ''M'' and ''N''. This definition is fundamental in [[differential geometry]] and has many uses – see [[pushforward (differential)]] and [[pullback (differential geometry)]].
* Differentiation can also be defined for maps between [[Dimension (vector space)|infinite dimensional]] [[vector space]]s such as [[Banach space]]s and [[Fréchet space]]s.  There is a generalization both of the directional derivative, called the [[Gâteaux derivative]], and of the differential, called the [[Fréchet derivative]].
* One deficiency of the classical derivative is that not very many functions are differentiable. Nevertheless, there is a way of extending the notion of the derivative so that all [[continuous function|continuous]] functions and many other functions can be differentiated using a concept known as the [[weak derivative]]. The idea is to embed the continuous functions in a larger space called the space of [[distribution (mathematics)|distributions]] and only require that a function is differentiable "on average".
* The properties of the derivative have inspired the introduction and study of many similar objects in algebra and topology — see, for example, [[differential algebra]].
* The discrete equivalent of differentiation is [[finite difference]]s. The study of differential calculus is unified with the calculus of finite differences in [[time scale calculus]].
* Also see [[arithmetic derivative]].

==History==
{{main|History of calculus}}
[[Calculus]], known in its early history as ''infinitesimal calculus'', is a [[mathematics|mathematical]] discipline focused on [[limit (mathematics)|limits]], [[function (mathematics)|functions]], [[derivative]]s, [[integral]]s, and [[infinite series]]. [[Isaac Newton]] and [[Gottfried Leibniz]] independently discovered calculus in the mid-17th century. However, each inventor claimed the other stole his work in a [[Leibniz–Newton calculus controversy|bitter dispute]] that continued until the end of their lives.

==See also==
{{Portal|Mathematics}}
* [[Differential calculus#Applications of derivatives|Applications of derivatives]]
* [[Automatic differentiation]]
* [[Differentiability class]]
* [[Differentiation rules]]
* [[Differintegral]]
* [[Fractal derivative]]
* [[Generalizations of the derivative]]
* [[Hasse derivative]]
* [[History of calculus]]
* [[Integral]]
* [[Infinitesimal]]
* [[Linearization]]
* [[Mathematical analysis]]
* [[Multiplicative inverse]]
* [[Multiplicative calculus#History|Non-Newtonian calculus]]
* [[Numerical differentiation]]
* [[Rate (mathematics)]]
* [[Radon–Nikodym theorem]]
* [[Symmetric derivative]]
* [[Schwarzian derivative]]

==Notes==
{{reflist|group=Note}}

==References==
{{Reflist}}

==Bibliography==

===Print===
{{Refbegin}}
*{{Citation
 | last = Anton
 | first = Howard
 | last2 = Bivens
 | first2 = Irl
 | last3 = Davis
 | first3 = Stephen
 | date = February 2, 2005
 | title = Calculus: Early Transcendentals Single and Multivariable
 | place = New York
 | publisher = Wiley
 | edition = 8th
 | isbn  = 978-0-471-47244-5
}}
*{{Citation
 | last = Apostol
 | first = Tom M.
 | author-link = Tom M. Apostol
 | date = June 1967
 | title = Calculus, Vol. 1: One-Variable Calculus with an Introduction to Linear Algebra
 | publisher = Wiley
 | edition = 2nd
 | volume = 1
 | isbn  = 978-0-471-00005-1
}}
*{{Citation
 | last = Apostol
 | first = Tom M.
 | date = June 1969
 | title = Calculus, Vol. 2: Multi-Variable Calculus and Linear Algebra with Applications
 | publisher = Wiley
 | edition = 2nd
 | volume = 1
 | isbn  = 978-0-471-00007-5
}}
*{{Citation
 | last = Courant
 | first = Richard
 | last2 = John
 | first2 = Fritz
 | date = December 22, 1998
 | title = Introduction to Calculus and Analysis, Vol. 1
 | publisher = Springer-Verlag
 | isbn  = 978-3-540-65058-4
}}
*{{Citation
 | last = Eves
 | first = Howard
 | date = January 2, 1990
 | title = An Introduction to the History of Mathematics
 | edition = 6th
 | publisher = Brooks Cole
 | isbn  = 978-0-03-029558-4
}}
*{{Citation
 | last = Larson
 | first = Ron
 | last2 = Hostetler
 | first2 = Robert P.
 | last3 = Edwards
 | first3 = Bruce H.
 | date = February 28, 2006
 | title = Calculus: Early Transcendental Functions
 | edition = 4th
 | publisher = Houghton Mifflin Company
 | isbn  = 978-0-618-60624-5
}}
*{{Citation
 | last = Spivak
 | first = Michael
 | author-link = Michael Spivak
 | date = September 1994
 | title = Calculus
 | publisher = Publish or Perish
 | edition = 3rd
 | isbn  = 978-0-914098-89-8
}}
*{{Citation
 | last = Stewart
 | first = James
 | date = December 24, 2002
 | title = Calculus
 | publisher = Brooks Cole
 | edition = 5th
 | isbn  = 978-0-534-39339-7
}}
*{{Citation
 | last = Thompson
 | first = Silvanus P.
 | authorlink = Silvanus P. Thompson
 | date = September 8, 1998
 | title = [[Calculus Made Easy]]
 | edition = Revised, Updated, Expanded
 | place = New York
 | publisher = St. Martin's Press
 | isbn  = 978-0-312-18548-0
}}
{{Refend}}

===Online books===
{{Library resources box 
|by=no 
|onlinebooks=no 
|others=no 
|about=yes 
|label=Derivative}}
{{Refbegin}}
*{{Citation
 | last = Crowell
 | first = Benjamin
 | title = Fundamentals of Calculus
 | year = 2017
 | url = http://www.lightandmatter.com/fund/
}}
*{{Citation
 | last = (Govt. of TN)
 | first = TamilNadu Textbook Corporation
 | title = Mathematics- vol.2
 | year = 2006
 | url = http://www.textbooksonline.tn.nic.in/Books/11/Std11-Maths-EM-2.pdf
}}
*{{Citation
 | last = Garrett
 | first = Paul
 | year = 2004
 | title = Notes on First-Year Calculus
 | url = http://www.math.umn.edu/~garrett/calculus/
 | publisher = [[University of Minnesota]]
}}
*{{Citation
 | last = Hussain
 | first = Faraz
 | year = 2006
 | title = Understanding Calculus
 | url = http://www.understandingcalculus.com/
}}
*{{Citation
 | last = Keisler
 | first = H. Jerome
 | year = 2000
 | title = Elementary Calculus: An Approach Using Infinitesimals
 | url = http://www.math.wisc.edu/~keisler/calc.html
}}
*{{Citation
 |last        = Mauch
 |first       = Sean
 |year        = 2004
 |title       = Unabridged Version of Sean's Applied Math Book
 |url         = http://www.its.caltech.edu/~sean/book/unabridged.html
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20060415161115/http://www.its.caltech.edu/~sean/book/unabridged.html
 |archivedate = 2006-04-15
 |df          = 
}}
*{{Citation
 | last = Sloughter
 | first = Dan
 | year = 2000
 | title = Difference Equations to Differential Equations
 | url = http://synechism.org/drupal/de2de/
}}
*{{Citation
 | last = Strang
 | first = Gilbert
 | year = 1991
 | title = Calculus
 | url = http://ocw.mit.edu/ans7870/resources/Strang/strangtext.htm
}}
*{{Citation
 | last = [[Keith Stroyan|Stroyan]]
 | first = Keith D.
 | year = 1997
 | title = A Brief Introduction to Infinitesimal Calculus
 | url = http://homepage.math.uiowa.edu/~stroyan/Site/Infinitesimals.html
}}
*{{Citation
 | last = Wikibooks
 | title = Calculus
 | url = http://en.wikibooks.org/wiki/Calculus
}}
{{Refend}}

==External links==
{{Sister project links|Derivative|Derivative}}
{{Sister project links|Differentiation|Differentiation}}
*{{springer|title=Derivative|id=p/d031260}}
*[[Khan Academy]]: [https://www.khanacademy.org/math/differential-calculus/taking-derivatives/intro_differential_calc/v/newton-leibniz-and-usain-bolt "Newton, Leibniz, and Usain Bolt"]
*{{MathWorld |title=Derivative |id=Derivative}}
*[http://www.wolframalpha.com/calculators/derivative-calculator/ Online Derivative Calculator] from [[Wolfram Alpha]].

{{good article}}

{{Authority control}}

[[Category:Mathematical analysis]]
[[Category:Differential calculus]]
[[Category:Functions and mappings]]
[[Category:Linear operators in calculus]]
[[Category:Rates]]</text>
      <sha1>sfeqqrmjx501aw6zu9j8c3x0a3v1o0o</sha1>
    </revision>
  </page>
  <page>
    <title>Diagonal morphism</title>
    <ns>0</ns>
    <id>4606682</id>
    <revision>
      <id>862380086</id>
      <parentid>862379791</parentid>
      <timestamp>2018-10-04T00:48:36Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <comment>/* top */ hatnote</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2354">{{for|the particular instance of the notion in algebraic geometry|diagonal embedding}}
{{unreferenced|date=March 2016}}
In [[category theory]], a branch of [[mathematics]], for any object &lt;math&gt;a&lt;/math&gt; in any [[category (mathematics)|category]] &lt;math&gt;\mathcal{C}&lt;/math&gt; where the [[product (category theory)|product]] &lt;math&gt;a\times a&lt;/math&gt; exists, [[there exists]] the '''diagonal morphism''' 

:&lt;math&gt;\delta_a : a \rightarrow a \times a&lt;/math&gt;

satisfying 

:&lt;math&gt;\pi_k \circ \delta_a = id_a&lt;/math&gt; for &lt;math&gt;k \in \{ 1,2 \},&lt;/math&gt;

where &lt;math&gt;\pi_k&lt;/math&gt; is the [[canonical projection morphism]] to the &lt;math&gt;k&lt;/math&gt;-th component. The existence of this morphism is a consequence of the [[universal property]] which [[characterization (mathematics)|characterize]]s the product ([[up to]] [[isomorphism]]). The restriction to binary products here is for ease of notation; diagonal morphisms exist similarly for arbitrary products. The [[image (category theory)|image]] of a diagonal morphism in the [[category of sets]], as a [[subset]] of the [[Cartesian product]], is a [[relation (mathematics)|relation]] on the [[domain of a function|domain]], namely [[equality (mathematics)|equality]].

For [[concrete categories]], the diagonal morphism can be simply described by its action on elements &lt;math&gt;x&lt;/math&gt; of the object &lt;math&gt;a&lt;/math&gt;. Namely, &lt;math&gt;\delta_a(x) = \langle x,x \rangle&lt;/math&gt;, the [[ordered pair]] formed from &lt;math&gt;x&lt;/math&gt;. The reason for the name is that the [[Image (mathematics)|image]] of such a diagonal morphism is diagonal (whenever it makes sense), for example the image of the diagonal morphism &lt;math&gt;\mathbb{R} \rightarrow \mathbb{R}^2&lt;/math&gt; on the [[real line]] is given by the line which is a [[graph of a function|graph]] of the equation &lt;math&gt;y=x&lt;/math&gt;. The diagonal morphism into the [[infinite product]] &lt;math&gt;X^\infty&lt;/math&gt; may provide an [[Injective function|injection]] into the [[space of sequences]] valued in &lt;math&gt;X&lt;/math&gt;; each element maps to the constant [[sequence]] at that element. However, most notions of sequence spaces have [[convergent series|convergence]] restrictions which the image of the diagonal map will fail to satisfy.

==See also==
* [[Diagonal functor]]
* [[Diagonal embedding]]

==References==
{{reflist}}

[[Category:Category theory]]
[[Category:Morphisms]]

{{cattheory-stub}}</text>
      <sha1>httlfurcpk6qlyoaytez0x6vudvlsqt</sha1>
    </revision>
  </page>
  <page>
    <title>Enthought</title>
    <ns>0</ns>
    <id>16300987</id>
    <revision>
      <id>841554906</id>
      <parentid>841554775</parentid>
      <timestamp>2018-05-16T15:05:58Z</timestamp>
      <contributor>
        <username>DMacks</username>
        <id>712163</id>
      </contributor>
      <comment>/* See also */ rm entries used in article ([[WP:SEEALSO]] guideline)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4904">{{Infobox company
| name = Enthought
| logo =Enthought-Logo-Horizontal-2018-Blue-2500x354.png
| logo_size = 
| logo_caption = 
| type = 
| founded = {{Start date and age|2001}}
| founder = Travis Vaught, Eric Jones&lt;ref name=founders1&gt;{{cite web|url=https://www.enthought.com/company/|title=A bit of our story|publisher=Enthought Scientific Computing Solutions}}&lt;/ref&gt;&lt;ref name=founders2&gt;{{cite web|url=http://www.ece.duke.edu/enthought|title=Enthought|publisher=Duke Electrical and Computer Engineering}}&lt;/ref&gt;
| hq_location_city = [[Austin, Texas]]
| hq_location_country = [[United States]]
| area_served = 
| key_people = 
| industry = [[Computer software]]
| products = [[Python (programming language)|Python]] development software, consulting, and training
| revenue = 
| operating_income = 
| net_income = 
| assets = 
| equity = 
| num_employees = 
| website = {{URL|www.enthought.com}}
}}
'''Enthought, Inc.''' is a software company based in [[Austin, Texas]], [[United States]] that develops [[Computational science|scientific and analytic computing]] solutions using primarily the [[Python (programming language)|Python]] programming language. It is best known for the early development and maintenance of the [[SciPy]] library of mathematics, science, and engineering algorithms&lt;ref&gt;{{cite web|url=http://wiki.scipy.org/History_of_SciPy|title=History of SciPy|publisher=scipy.org wiki}}&lt;/ref&gt; and for its Python for scientific computing distribution Enthought Canopy (formerly EPD).&lt;ref&gt;{{cite web|url=https://www.enthought.com/company/news/enthought-introduces-enthought-canopy-a-python-analysis-environment-for-scientific-and-analytic-computing|title=Enthought Introduces Enthought Canopy, a Python Analysis Environment for Scientific and Analytic Computing|date=April 10, 2013}}&lt;/ref&gt;

The company was founded in 2001 by Travis Vaught and Eric Jones.&lt;ref name=founders1 /&gt;&lt;ref name=founders2 /&gt;

==Open source software==
[[File:Enthought_Canopy_Logo.png|thumb|Enthought Canopy Logo|128px]]
Enthought publishes a large portion of the code as [[open-source software]] under a [[BSD-style license]].

'''Enthought Canopy''' is a Python for scientific and analytic computing distribution and analysis environment, available for free and under a commercial license.&lt;ref&gt;{{cite web|url=https://www.enthought.com/products/canopy/|title=Python Distribution and Integrated Analysis Environment|publisher=Enthought Canopy}}&lt;/ref&gt;

The '''Enthought Tool Suite''' open source software projects include:&lt;ref&gt;{{cite web|url=http://code.enthought.com/|title=Open Source Python Software|publisher=Enthought, Inc.}}&lt;/ref&gt;

* '''Traits''': A manifest type definition library for Python that provides initialization, validation, delegation, notification, and visualization. The Traits package is the foundation of the Enthought Tool Suite, underlying almost all other packages.
* '''TraitsUI''': A UI layer that supports the visualization features of Traits. Implementations using wxWidgets and Qt are provided by the TraitsBackendWX and TraitsBackendQt projects
* '''Pyface''': toolkit-independent GUI abstraction layer, which is used to support the "visualization" features of the Traits package.
* '''[[MayaVi]]''': 2-D/3-D scientific data visualization, usable in TraitsUIs as well as an Envisage [[Plug-in (computing)|plug-in]].
* '''Envisage''': An extensible plug-in architecture for scientific applications, inspired by [[Eclipse (software)|Eclipse]] and [[NetBeans]] in the Java world.
* '''Enable''': A multi-platform DisplayPDF drawing engine that supports multiple output backends, including [[Microsoft Windows|Windows]], [[GTK+]], and [[macOS]] native windowing systems, a variety of [[Raster graphics|raster]] image formats, [[PDF]], and [[PostScript]].
* '''BlockCanvas''': Visual environment for creating simulation experiments, where function and data are separated using CodeTools.
* '''GraphCanvas''': library for interacting with visualizations of complex graphs.
* '''SciMath''': Convenience libraries for math, interpolation, and units
* '''Chaco''': An interactive 2-D plotting toolkit for Python.
* '''AppTools: '''General tools for ETS application development: scripting, logging, preferences, ...
* '''Enaml''': Library for creating professional quality user interfaces combining a domain specific declarative language with a constraints based layout.&lt;ref&gt;{{cite web|url=https://github.com/nucleic/enaml|title=nucleic/enaml - GitHub}}&lt;/ref&gt;

==See also==
{{Portal|Free software}}
* [[NumPy]]
* [[matplotlib]]
* [[Anaconda (Python distribution)|Anaconda]]
* [[ActiveState]]'s ActivePython

==References==
{{Reflist}}

==External links==
* {{Official website|www.enthought.com}}

[[Category:Companies based in Austin, Texas]]
[[Category:Computational science]]
[[Category:Free software programmed in Python]]
[[Category:Software companies based in Texas]]

{{US-software-company-stub}}</text>
      <sha1>hikd267ieqm2heeld4bohv9bc95jza0</sha1>
    </revision>
  </page>
  <page>
    <title>Five points determine a conic</title>
    <ns>0</ns>
    <id>26269427</id>
    <revision>
      <id>852202709</id>
      <parentid>829921130</parentid>
      <timestamp>2018-07-27T09:18:16Z</timestamp>
      <contributor>
        <ip>109.13.64.190</ip>
      </contributor>
      <comment>/* Synthetic proof */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13466">In Euclidean and projective [[geometry]], just as two (distinct) points determine a [[line (geometry)|line]] (a degree-1 plane curve), '''five points determine a [[conic]]''' (a degree-2 plane curve). There are additional subtleties for conics that do not exist for lines, and thus the statement and its proof for conics are both more technical than for lines. 

Formally, given any five points in the plane in [[general linear position]], meaning no three [[collinear]], there is a unique conic passing through them, which will be non-degenerate; this is true over both the [[Euclidean plane]] and any [[Pappian plane|pappian projective plane]]. Indeed, given any five points there is a conic passing through them, but if three of the points are collinear the conic will be [[degenerate conic|degenerate]] (reducible, because it contains a line), and may not be unique; see [[Degenerate conic#Points to define|further discussion]].

== Proofs ==
This result can be proven numerous different ways; the dimension counting argument is most direct, and generalizes to higher degree, while other proofs are special to conics.

=== Dimension counting ===
Intuitively, passing through five points in general linear position specifies five independent linear constraints on the (projective) linear space of conics, and hence specifies a unique conic, though this brief statement ignores subtleties.

More precisely, this is seen as follows:
* conics correspond to points in the five-dimensional projective space &lt;math&gt;\mathbf{P}^5;&lt;/math&gt;
* requiring a conic to pass through a point imposes a linear condition on the coordinates: for a fixed &lt;math&gt;(x,y),&lt;/math&gt; the equation &lt;math&gt;Ax^2 + Bxy + Cy^2 +Dx + Ey + F = 0&lt;/math&gt; is a ''linear'' equation in &lt;math&gt;(A,B,C,D,E,F);&lt;/math&gt;
* by [[dimension counting]] five constraints (that the curve passes through five points) are necessary to specify a conic, as each constraint cuts the dimension of possibilities by 1, and one starts with 5 dimensions;
* in 5 dimensions, the intersection of 5 (independent) hyperplanes is a single point (formally, by [[Bézout's theorem]]);
* general linear position of the points means that the constraints are ''independent,'' and thus do specify a unique conic;
* the resulting conic is non-degenerate because it is a curve (since it has more than 1 point), and does not contain a line (else it would split as two lines, at least one of which must contain 3 of the 5 points, by the [[pigeonhole principle]]), so it is irreducible.

The two subtleties in the above analysis are that the resulting point is a quadratic equation (not a linear equation), and that the constraints are independent. The first is simple: if ''A'', ''B'', and ''C'' all vanish, then the equation &lt;math&gt;Dx + Ey + F = 0&lt;/math&gt; defines a line, and any 3 points on this (indeed any number of points) lie on a line – thus general linear position ensures a conic. The second, that the constraints are independent, is significantly subtler: it corresponds to the fact that given five points in general linear position in the plane, their images in &lt;math&gt;\mathbf{P}^5&lt;/math&gt; under the [[Veronese map]] are in general linear position, which is true because the Veronese map is [[biregular]]:  i.e., if the image of five points satisfy a relation, then the relation can be pulled back and the original points must also satisfy a relation. The Veronese map has coordinates &lt;math&gt;[x^2 : xy : y^2 : xz : yz : z^2 ],&lt;/math&gt; and the target &lt;math&gt;\mathbf{P}^5&lt;/math&gt; is ''dual'' to the &lt;math&gt;[A : B : C : D : E : F]&lt;/math&gt; &lt;math&gt;\mathbf{P}^5&lt;/math&gt; of conics. The Veronese map corresponds to "evaluation of a conic at a point", and the statement about independence of constraints is exactly a geometric statement about this map.

=== Synthetic proof ===
That five points determine a conic can be proven by [[synthetic geometry]]&amp;mdash;i.e., in terms of lines and points in the plane&amp;mdash;in addition to the analytic (algebraic) proof given above. Such a proof can be given using a theorem of [[Jakob Steiner]],&lt;ref&gt;[http://www.math.poly.edu/courses/projective_geometry/ Interactive Course on Projective Geometry], Chapter Five: [http://www.math.poly.edu/courses/projective_geometry/chapter_five/chapter_five.html The Projective Geometry of Conics]: Section Four: [http://www.math.poly.edu/courses/projective_geometry/chapter_five/node4.html Conics on the real projective plane], by J.C. Álvarez Paiva; proof follows Exercise 4.6&lt;/ref&gt; which states:
:Given a projective transformation ''f,'' between the pencil of lines passing through a point ''X'' and the pencil of lines passing through a point ''Y,'' the set ''C'' of intersection points between a line ''x'' and its image &lt;math&gt;f(x)&lt;/math&gt; forms a conic.
::Note that ''X'' and ''Y'' are on this conic by considering the preimage and image of the line ''XY'' (which is respectively a line through ''X'' and a line through ''Y'').
This can be shown by taking the points ''X'' and ''Y'' to the standard points &lt;math&gt;[1:0:0]&lt;/math&gt; and &lt;math&gt;[0:1:0]&lt;/math&gt; by a projective transformation, in which case the pencils of lines correspond to the horizontal and vertical lines in the plane, and the intersections of corresponding lines to the graph of a function, which (must be shown) is a hyperbola, hence a conic, hence the original curve ''C'' is a conic.

Now given five points ''X, Y, A, B, C,'' the three lines &lt;math&gt;XA, XB, XC&lt;/math&gt; can be taken to the three lines &lt;math&gt;YA, YB, YC&lt;/math&gt; by a unique projective transform, since projective transforms are [[simply transitive|simply]] 3-transitive on lines (they are simply 3-transitive on points, hence by [[projective duality]] they are 3-transitive on lines). Under this map ''X'' maps to ''Y,'' since these are the unique intersection points of these lines, and thus satisfy the hypothesis of Steiner’s theorem. The resulting conic thus contains all five points, and is the unique such conic, as desired.

[[File:Parabola construction given five points.gif|thumb|right|Parabola construction, given five points]]

== Construction ==
Given five points, one can construct the conic containing them in various ways.

Analytically, given the coordinates of the five points, the equation for the conic can be found by [[linear algebra]], by  writing and solving the five equations in the coefficients, substituting the variables with the values of the coordinates: five equations, six unknowns, but homogeneous so scaling removes one dimension; concretely, setting one of the coefficients to 1 accomplishes this.

Synthetically, the conic can be constructed by the '''{{visible anchor|Braikenridge–Maclaurin construction}}''',&lt;ref&gt;{{Harv|Coxeter|1961|loc=pp. 252–254}}&lt;/ref&gt;&lt;ref&gt;[http://www-personal.umich.edu/~copyrght/image/solstice/win07/MacLaurin.html The Animated Pascal], Sandra Lach Arlinghaus&lt;/ref&gt;&lt;ref&gt;Weisstein, Eric W. "Braikenridge-Maclaurin Construction." From MathWorld--A Wolfram Web Resource. http://mathworld.wolfram.com/Braikenridge-MaclaurinConstruction.html&lt;/ref&gt;&lt;ref&gt;The GNU 3DLDF Conic Sections Page: [https://www.gnu.org/software/3dldf/conicsct.html#Braikenridge Pascal's Theorem and the Braikenridge-Maclaurin Construction], Laurence D. Finston&lt;/ref&gt; by applying the [[Braikenridge–Maclaurin theorem]], which is the converse of [[Pascal's theorem]]. Pascal's theorem states that given ''6'' points on a conic (a hexagon), the lines defined by opposite sides intersect in three collinear points. This can be reversed to construct the possible locations for a 6th point, given 5 existing ones.

== Generalizations ==
The natural generalization is to ask for what value of ''k'' a configuration of ''k'' points (in general position) in ''n''-space determines a variety of degree ''d'' and dimension ''m'', which is a fundamental question in [[enumerative geometry]].

A simple case of this is for a [[hypersurface]] (a [[codimension]] 1 subvariety, the zeros of a single polynomial, the case &lt;math&gt;m = n-1&lt;/math&gt;), of which plane curves are an example.

In the case of a hypersurface, the answer is given in terms of the [[multiset coefficient]], more familiarly the [[binomial coefficient]], or more elegantly the [[rising factorial]], as:
:&lt;math&gt;k = \left(\!\!{n + 1 \choose d}\!\!\right) - 1 = {n+d \choose d} - 1 = \frac{1}{n!}(d+1)^{(n)} - 1.&lt;/math&gt;
This is via the analogous analysis of the [[Veronese map]]: ''k'' points in general position impose ''k'' independent linear conditions on a variety (because the Veronese map is biregular), and the number of monomials of degree ''d'' in &lt;math&gt;n+1&lt;/math&gt; variables (''n''-dimensional projective space has &lt;math&gt;n+1&lt;/math&gt; homogeneous coordinates) is &lt;math&gt;\textstyle{\left(\!\!{n + 1 \choose d}\!\!\right)},&lt;/math&gt; from which 1 is subtracted because of projectivization: multiplying a polynomial by a constant does not change its zeros.

In the above formula, the number of points ''k'' is a polynomial in ''d'' of degree ''n,'' with leading coefficient &lt;math&gt;1/n!&lt;/math&gt;

In the case of plane curves, where &lt;math&gt;n=2,&lt;/math&gt; the formula becomes:
:&lt;math&gt;\textstyle{\frac{1}{2}}(d+1)(d+2) - 1 = \textstyle{\frac{1}{2}}(d^2 + 3d)&lt;/math&gt;
whose values for &lt;math&gt;d=0,1,2,3,4&lt;/math&gt; are &lt;math&gt;0,2,5,9,14&lt;/math&gt; – there are no curves of degree 0 (a single point is determines a point, which is codimension 2), 2 points determine a line, 5 points determine a conic, 9 points determine a cubic, 14 points determine a quartic, and so forth.

== Related results ==
While five points determine a conic, sets of six or more points on a conic are not in general position, that is, they are constrained as is demonstrated in [[Pascal's theorem]].

Similarly, while nine points determine a cubic, if the nine points lie on more than one cubic&amp;mdash;i.e., they are the intersection of two cubics&amp;mdash;then they are not in general position, and indeed satisfy an addition constraint, as stated in the [[Cayley–Bacharach theorem]].

Four points do not determine a conic, but rather a [[pencil (mathematics)|pencil]], the 1-dimensional [[linear system of conics]] which all pass through the four points (formally, have the four points as [[base locus]]). Similarly, three points determine a 2-dimensional linear system (net), two points determine a 3-dimensional linear system (web), one point determines a 4-dimensional linear system, and zero points place no constraints on the 5-dimensional linear system of all conics.

[[File:Apollonian circles.svg|thumb|The [[Apollonian circles]] are two 1-parameter families determined by 2 points.]]
As is well known, three non-collinear points determine a circle in Euclidean geometry and two distinct points determine a [[pencil of circles]] such as the [[Apollonian circles]]. These results seem to run counter the general result since circles are special cases of conics. However, in a pappian [[projective plane]] a conic is a circle only if it passes through two specific points on the [[line at infinity]], so a circle is determined by five non-collinear points, three in the affine plane and these two special points. Similar considerations explain the smaller than expected number of points needed to define pencils of circles.

=== Tangency ===
Instead of passing through points, a different condition on a curve is being tangent to a given line. Being tangent to five given lines also determines a conic, by [[projective duality]], but from the algebraic point of view tangency to a line is a ''quadratic'' constraint, so naive dimension counting yields 2&lt;sup&gt;5&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;32 conics tangent to five given lines, of which 31 must be ascribed to degenerate conics, as described in [[Enumerative geometry#Fudge factors and Hilbert's fifteenth problem|fudge factors in enumerative geometry]]; formalizing this intuition requires significant further development to justify.

Another classic problem in enumerative geometry, of similar vintage to conics, is the [[Problem of Apollonius]]: a circle that is tangent to three circles in general determines eight circles, as each of these is a quadratic condition and 2&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;8. As a question in real geometry, a full analysis involves many special cases, and the actual number of circles may be any number between 0 and 8, except for&amp;nbsp;7.

==See also==

*[[Cramer's theorem (algebraic curves)]], for a generalization to ''n''-th degree planar curves

== References ==
{{reflist}}
{{refbegin}}
* {{ Citation | last = Coxeter | first = H. S. M. | authorlink = Harold Scott MacDonald Coxeter | title = Introduction to Geometry | location = Washington, DC | year = 1961}}
* {{ Citation | last1 = Coxeter | first1 = H. S. M. | authorlink1 = Harold Scott MacDonald Coxeter | last2 = Greitzer | first2 = S. L. | authorlink2 = S. L. Greitzer | title = Geometry Revisited | location = Washington, DC | publisher = [[Mathematical Association of America]] | page = 76 | year = 1967}}
* {{ Citation | title = The Conic through Five Given Points | first = A. C. | last = Dixon | authorlink = Alfred Cardew Dixon | journal = The Mathematical Gazette | volume = 4 | number = 70 |date=March 1908 | pages = 228–230 | publisher = The Mathematical Association | jstor = 3605147 }}
{{refend}}

== External links ==
* [http://demonstrations.wolfram.com/FivePointsDetermineAConicSection/ Five Points Determine a Conic Section], Wolfram interactive demonstration

[[Category:Conic sections]]
[[Category:Theorems in geometry]]
[[Category:Projective geometry]]</text>
      <sha1>4akhakmfygwlnimt6ibw5ml59dzjb4i</sha1>
    </revision>
  </page>
  <page>
    <title>Francois Deruyts Prize</title>
    <ns>0</ns>
    <id>57182888</id>
    <revision>
      <id>852183867</id>
      <parentid>847571683</parentid>
      <timestamp>2018-07-27T06:16:01Z</timestamp>
      <contributor>
        <username>Josvebot</username>
        <id>14967932</id>
      </contributor>
      <minor/>
      <comment>/* top */Fixing [[WP:CHECKWIKI]] #16: unicode contol character (and other minor general edits caused by AWB), replaced: →</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2014">The '''Francois Deruyts Prize''', or '''Prix Francois Deruyts''', is awarded every four years to recognize progress in synthetic or analytic superior geometry.  It was established in 1902 by the [[Academie royale de Belgique|Academie Royale de Belgique]], Classe des Sciences, and carries a monetary award. Originally recipients had to be Belgian, but currently [[European Union|EU]] nationals are eligible.&lt;ref&gt;{{Cite web|url=http://www.academieroyale.be/fr/les-concours-prix-subventions-prix-toutes-classes-detail/objets-de-candidature/prix-francois-deruyts-2018/|title=DETAIL|website=www.academieroyale.be|language=fr|access-date=2018-05-04}}&lt;/ref&gt;

== Recipients ==
The recipients of the Francois Deruyts Prize are:&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/37513025|title=Recognizing excellence in the mathematical sciences : an international compilation of awards, prizes, and recipients|date=1997|publisher=JAI Press|others=Jaguszewski, Janice M.|isbn=0762302356|location=Greenwich, Conn.|oclc=37513025}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.academieroyale.be/fr/les-concours-prix-subventions-laureats-beneficiaires-classe-sciences/|title=Classe des Sciences|website=www.academieroyale.be|language=fr|access-date=2018-05-09}}&lt;/ref&gt;

* 1906: Modeste Stuyvaert
* 1910: Joseph Fairon
* 1914: [[Lucien Godeaux]]
* 1918: No award
* 1926: No award
* 1930: Roland Deaux
* 1934: Augustin Delgleize
* 1938: Pol Burniat
* 1938: Octave Rozet
* 1942: Pierre Defrise
* 1946: François Jongmans
* 1946: Louis Nollet
* 1950: Léon-Élie Derwidué
* 1954: [[Guy Hirsch]]
* 1958: Fernand Backes
* 1962: [[Paul Dedecker]]
* 1962: [[Jacques Tits]]
* 1966: No award
* 1970: J.A. Thas
* 1974: [[Pierre Deligne]]
* 1978: Michel Cahen
* 1982: [[Francis Buekenhout]]
* 1986: Pierre Lecomte
* 1990: Luc Haine
* 1994: Luc Lemaire
* 1998: Simone Gutt
* 2002: Yves Félix
* 2006: Frédéric Bourgeois
* 2010: Lorenz Johannes Schwachhöfer
* 2014: Pascal Lambrechts

==References==
&lt;references /&gt;

[[Category:Mathematics awards]]</text>
      <sha1>gtkuir6lohlsdirqbdjv3zsqsb551ed</sha1>
    </revision>
  </page>
  <page>
    <title>GKM variety</title>
    <ns>0</ns>
    <id>56782000</id>
    <revision>
      <id>849392502</id>
      <parentid>848882143</parentid>
      <timestamp>2018-07-08T17:45:35Z</timestamp>
      <contributor>
        <username>Katharineamy</username>
        <id>2590656</id>
      </contributor>
      <comment>added [[Category:Algebraic geometry]]; removed {{uncategorized}} using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1546">In [[algebraic geometry]], a '''GKM variety''' is a [[complex number|complex]] [[algebraic variety]] equipped with a [[torus action]] that meets certain conditions.&lt;ref name="Gonzales"&gt;{{cite thesis|last=Gonzales|first=Richard Paul |title=GKM theory of rationally smooth group embeddings|url=https://ir.lib.uwo.ca/etd/216 |publisher=[[University of Western Ontario]]|type=PhD |year=2011}}&lt;/ref&gt;{{rp|Def. 1.4.13}} The concept was introduced by [[Mark Goresky]], [[Robert Kottwitz]], and [[Robert MacPherson (mathematician)|Robert MacPherson]] in 1998.&lt;ref name="GKM"&gt;{{cite journal|last1=Goresky|first1=Mark |last2=Kottwitz|first2=Robert |last3=MacPherson |first3=Robert |title=Equivariant cohomology, Koszul duality, and the localization theorem|journal=[[Inventiones mathematicae]] |year=1998 |volume=131 |pages=25–83 |doi=10.1007/s002220050197 |url=http://www.math.ias.edu/~goresky/pdf/equivariant.jour.pdf|author-link1=Mark Goresky |author-link2=Robert Kottwitz |author-link3=Robert MacPherson (mathematician)}}&lt;/ref&gt; The torus action of a GKM variety must be ''skeletal'': both the set of fixed points of the action, and the number of one-dimensional [[orbit (group theory)|orbit]]s of the action, must be finite. In addition, the action must be ''equivariantly formal'', a condition that can be phrased in terms of the torus' [[cohomology|rational cohomology]].&lt;ref name="Gonzales"/&gt;{{rp|Def. 1.4.1}}

== See also ==
*[[equivariant cohomology]]

== References ==
{{Reflist}}


{{algebraic-geometry-stub}}



[[Category:Algebraic geometry]]</text>
      <sha1>6ix8dgq4sbovkpl4nnd74p96j8h927p</sha1>
    </revision>
  </page>
  <page>
    <title>Gentzen's consistency proof</title>
    <ns>0</ns>
    <id>4076831</id>
    <revision>
      <id>861329872</id>
      <parentid>849072637</parentid>
      <timestamp>2018-09-26T17:20:05Z</timestamp>
      <contributor>
        <ip>64.57.49.36</ip>
      </contributor>
      <comment>Fixed typo.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13611">{{short description|mathematical logic concept}}
'''Gentzen's consistency proof''' is a result of [[proof theory]] in [[mathematical logic]], published by [[Gerhard Gentzen]] in 1936. It shows that the [[Peano axioms|Peano axioms of first-order arithmetic]] do not contain a contradiction (i.e. are "[[consistent]]"), as long as a certain other system used in the proof does not contain any contradictions either. This other system, today called "[[primitive recursive arithmetic]] with the additional principle of quantifier-free [[transfinite induction]] up to the [[ordinal number|ordinal]] [[epsilon zero|ε&lt;sub&gt;0&lt;/sub&gt;]]", is neither weaker nor stronger than the system of Peano axioms.  Gentzen argued that it avoids the questionable modes of inference contained in Peano arithmetic and that its consistency is therefore less controversial.

==Gentzen's theorem==
Gentzen's theorem is concerned with first-order arithmetic: the theory of the [[natural number]]s, including their addition and multiplication, axiomatized by the [[Peano_axioms#First-order_theory_of_arithmetic|first-order Peano axioms]]. This is a "first-order" theory: the [[Quantifier (logic)|quantifiers]] extend over natural numbers, but not over sets or functions of natural numbers. The theory is strong enough to describe [[Recursion|recursively defined]] integer functions such as exponentiation, [[factorial]]s or the [[Fibonacci number|Fibonacci sequence]].

Gentzen showed that the consistency of the first-order Peano axioms is provable, over the base theory of [[primitive recursive arithmetic]] with the additional principle of quantifier-free [[transfinite induction]] up to the [[ordinal number|ordinal]] [[epsilon zero|ε&lt;sub&gt;0&lt;/sub&gt;]].  Primitive recursive arithmetic is a much simplified form of arithmetic that is rather uncontroversial.  The additional principle means, informally, that there is a [[well-ordering]] on the set of finite rooted [[tree (mathematics)|trees]].  Formally, ε&lt;sub&gt;0&lt;/sub&gt; is the first [[Ordinal number|ordinal]] &lt;math&gt;\alpha&lt;/math&gt; such that &lt;math&gt;\omega^\alpha = \alpha&lt;/math&gt;, i.e. the limit of the sequence:
:&lt;math&gt;\omega,\ \omega^\omega,\ \omega^{\omega^\omega},\ \ldots&lt;/math&gt;
To express ordinals in the language of arithmetic, an [[ordinal notation]] is needed, i.e. a way to assign natural numbers to ordinals less than ε&lt;sub&gt;0&lt;/sub&gt;. This can be done in various ways, one example provided by [[Ordinal arithmetic#Cantor normal form|Cantor's normal form theorem]]. We require for any quantifier-free formula A(x): if there is an ordinal ''a''&lt; ε&lt;sub&gt;0&lt;/sub&gt; for which A(a) is false, then there is a least such ordinal.

Gentzen defines a notion of "reduction procedure" for proofs in Peano arithmetic. For a given proof, such a procedure produces a tree of proofs, with the given one serving as the root of the tree, and the other proofs being, in a sense, "simpler" than the given one. This increasing simplicity is formalized by attaching an ordinal &lt; ε&lt;sub&gt;0&lt;/sub&gt; to every proof, and showing that, as one moves down the tree, these ordinals get smaller with every step.  He then shows that if there were a proof of a contradiction, the reduction procedure would result in an infinite descending sequence of ordinals smaller than ε&lt;sub&gt;0&lt;/sub&gt; produced by a [[primitive recursive]] operation on proofs corresponding to a quantifier-free formula.&lt;ref&gt;See {{harvtxt|Kleene|2009|pp=476–499}} for a full presentation of Gentzen's proof and various comments on the historic and philosophical significance of the result.&lt;/ref&gt;

It is possible to interpret Gentzen's proof in game-theoretic terms {{Harv|Tait|2005}}.

==Relation to Hilbert's program and Gödel's theorem==
Gentzen's proof highlights one commonly missed aspect of [[Gödel's second incompleteness theorem]]. It is sometimes claimed that the consistency of a theory can only be proved in a stronger theory. Gentzen's theory obtained by adding quantifier-free transfinite induction to primitive recursive arithmetic proves the consistency of first-order Peano arithmetic (PA) but does not contain PA. For example, it does not prove ordinary mathematical induction for all formulae, whereas PA does (since all instance of induction are axioms of PA). Gentzen's theory is not contained in PA, either, however, since it can prove a number-theoretical fact—the consistency of PA—that PA cannot. Therefore, the two theories are, in one sense, [[Comparability|incomparable]].

That said, there are other, more powerful ways to compare the strength of theories, the most important of which is defined in terms of the notion of [[interpretability]]. It can be shown that, if one theory T is interpretable in another B, then T is consistent if B is. (Indeed, this is a large point of the notion of interpretability.) And, assuming that T is not extremely weak, T itself will be able to prove this very conditional: If B is consistent, then so is T. Hence, T cannot prove that B is consistent, by the second incompleteness theorem, whereas B may well be able to prove that T is consistent. This is what motivates the idea of using interpretability to compare theories, i.e., the thought that, if B interprets T, then B is at least as strong (in the sense of 'consistency strength') as T is.

A strong form of the second incompleteness theorem, proved by Pavel Pudlák,&lt;ref&gt;{{Cite journal|last=Pudlak|first=Pavel|date=1985-06-01|title=Cuts, Consistency Statements and Interpretations|url=http://projecteuclid.org/euclid.jsl/1183741849|journal=Journal of Symbolic Logic|volume=50|issue=2|pages=423–441|issn=0022-4812|doi=10.2307/2274231|jstor=2274231}}&lt;/ref&gt; who was building on earlier work by [[Solomon Feferman]],&lt;ref&gt;{{Cite journal|last=Feferman|first=S.|title=Arithmetization of metamathematics in a general setting|url=https://eudml.org/doc/213578|journal=Fundamenta Mathematicae|language=en|volume=49|issue=1|issn=0016-2736}}&lt;/ref&gt; states that no consistent theory T that contains [[Robinson arithmetic]], Q, can interpret Q plus Con(T), the statement that T is consistent. By contrast, Q+Con(T) ''does'' interpret T, by a strong form of the arithmetized [[Gödel's completeness theorem|completeness theorem]]. So Q+Con(T) is always stronger (in one good sense) than T is. But Gentzen's theory trivially interprets Q+Con(PA), since it contains Q and proves Con(PA), and so Gentzen's theory interprets PA. But, by Pudlák's result, PA ''cannot'' interpret Gentzen's theory, since Gentzen's theory (as just said) interprets Q+Con(PA), and interpretability is transitive. That is: If PA did interpret Gentzen's theory, then it would also interpret Q+Con(PA) and so would be inconsistent, by Pudlák's result. So, in the sense of consistency strength, as characterized by interpretability, Gentzen's theory is stronger than Peano arithmetic.

[[Hermann Weyl]] made the following comment in 1946 regarding the significance of Gentzen's consistency result following the devastating impact of Gödel's 1931 incompleteness result on Hilbert's plan to prove the consistency of mathematics.&lt;ref&gt;{{harvtxt|Weyl|2012|p=144}}.&lt;/ref&gt;

: It is likely that all mathematicians ultimately would have accepted Hilbert's approach had he been able to carry it out successfully. The first steps were inspiring and promising. But then Gödel dealt it a terrific blow (1931), from which it has not yet recovered. Gödel enumerated the symbols, formulas, and sequences of formulas in Hilbert's formalism in a certain way, and thus transformed the assertion of consistency into an arithmetic proposition. He could show that this proposition can neither be proved nor disproved within the formalism. This can mean only two things: either the reasoning by which a proof of consistency is given must contain some argument that has no formal counterpart within the system, i.e., we have not succeeded in completely formalizing the procedure of mathematical induction; or hope for a strictly "finitistic" proof of consistency must be given up altogether. When G. Gentzen finally succeeded in proving the consistency of arithmetic he trespassed those limits indeed by claiming as evident a type of reasoning that penetrates into Cantor's "second class of ordinal numbers."

{{harvtxt|Kleene|2009|p=479}} made the following comment in 1952 on the significance of Gentzen's result, particularly in the context of the formalist program which was initiated by Hilbert.

: The original proposals of the formalists to make classical mathematics secure by a consistency proof did not contemplate that such a method as transfinite induction up to ε&lt;sub&gt;0&lt;/sub&gt; would have to be used. To what extent the Gentzen proof can be accepted as securing classical number theory in the sense of that problem formulation is in the present state of affairs a matter for individual judgement, depending on how ready one is to accept induction up to ε&lt;sub&gt;0&lt;/sub&gt; as a finitary method.

== Other consistency proofs of arithmetic ==
Gentzen's first version of his consistency proof was not published during his lifetime because [[Paul Bernays]] had objected to a method implicitly used in the proof. The modified proof, described above, was published in 1936 in the ''[[Annals of Mathematics|Annals]]''. Gentzen went on to publish two more consistency proofs, one in 1938 and one in 1943. All of these are contained in {{Harv|Gentzen|Szabo|1969}}.

In 1940 [[Wilhelm Ackermann]] published another consistency proof for Peano arithmetic, also using the ordinal ε&lt;sub&gt;0&lt;/sub&gt;.

== Work initiated by Gentzen's proof ==
Gentzen's proof is the first example of what is called proof-theoretical [[ordinal analysis]]. In ordinal analysis one gauges the strength of theories by measuring how large the (constructive) ordinals are that can be proven to be well-ordered, or equivalently for how large a (constructive) ordinal can transfinite induction be proven. A constructive ordinal is the order type of a [[recursive set|recursive]] well-ordering of natural numbers.

[[Laurence Kirby]] and [[Jeff Paris (mathematician)|Jeff Paris]] proved in 1982 that [[Goodstein's theorem]] cannot be proven in Peano arithmetic. Their proof was based on Gentzen's theorem.

== Notes ==
{{Reflist}}

==References==
*{{Citation|last1=Gentzen|doi=10.1007/BF01565428|first1=Gerhard|author-link=Gerhard Gentzen|title=Die Widerspruchsfreiheit der reinen Zahlentheorie|journal=Mathematische Annalen|volume=112|year=1936|publisher=|pages=493–565|url=http://gdz.sub.uni-goettingen.de/dms/resolveppn/?PPN=GDZPPN002278391}} – Translated as "The consistency of arithmetic", in {{Harv|Gentzen|Szabo|1969}}.
*{{Citation|last1=Gentzen|first1=Gerhard|author-link=Gerhard Gentzen|title=Neue Fassung des Widerspruchsfreiheitsbeweises für die reine Zahlentheorie|journal=Forschungen zur Logik und zur Grundlegung der exakten Wissenschaften|volume=4|year=1938|publisher=|pages=19–44}} – Translated as "New version of the consistency proof for elementary number theory", in {{Harv|Gentzen|Szabo|1969}}.
*{{Citation|last=Gentzen|first=Gerhard|editor-first=M. E.|editor-last=Szabo|editor-link=M. E. Szabo|year=1969|title=Collected Papers of Gerhard Gentzen|publisher=North-Holland|location=Amsterdam|edition=Hardcover|series=Studies in logic and the foundations of mathematics|isbn=0-7204-2254-X|ref={{Harvid|Gentzen|Szabo|1969}}}} - an English translation of papers.
*{{Citation|last=Gödel|first=K.|author-link=Kurt Gödel|editor1-last=Feferman|editor1-first=Solomon|editor1-link=Solomon Feferman|origyear=1938|year=2001|title=Kurt Gödel: Collected Works|chapter=Lecture at Zilsel's|publisher=Oxford University Press Inc.|pages=87–113|edition=Paperback|volume=vol.III Unpublished Essays and Lectures|isbn=0-19-514722-7|ref={{Harvid|Gödel|Feferman et al.|2001}}|url=https://books.google.com/books/about/Kurt_Gödel_Collected_Works_Volume_III.html?id=gDzbuUwma5MC&amp;pg=PA87}}
*{{Citation|last=Jervell |first=Herman Ruge |author-link=Herman Ruge Jervell |year=1999 |title=A course in proof theory |edition=textbook draft |url=http://folk.uio.no/herman/bevisteori.ps |deadurl=yes |archiveurl=https://web.archive.org/web/20110607104500/http://folk.uio.no/herman/bevisteori.ps |archivedate=2011-06-07 |df= }}
*{{Citation|last1=Kirby|first1=L.|author1-link=Laurie Kirby|last2=Paris|first2=J.|author2-link=Jeff Paris (mathematician)|year=1982|title=Accessible independence results for Peano arithmetic|journal=[[Bull. London Math. Soc.]]|publisher=[[London Mathematical Society|LMS]]|pages=285–293|volume=14|url=http://blms.oxfordjournals.org/content/14/4/285.full.pdf|format=PDF|doi=10.1112/blms/14.4.285}}
*{{cite book|ref=harv|last1=Kleene|first1=Stephen Cole|author1-link=Stephen Cole Kleene|title=Introduction to metamathematics|origyear=1952|year=2009|publisher=Ishi Press International|isbn=978-0-923891-57-2}}
*{{Citation|last=Tait|first=W. W.|author-link=William W. Tait|year=2005|title=Gödel's reformulation of Gentzen's first consistency proof for arithmetic: the no-counterexample interpretation|journal=The Bulletin of Symbolic Logic|volume=11|issue=2|publisher=[[Association for Symbolic Logic|ASL]]|pages=225–238|url=http://home.uchicago.edu/~wwtx/GoedelandNCInew1.pdf|format=PDF|issn=1079-8986|doi=10.2178/bsl/1120231632}}
*{{cite book|ref=harv|last1=Weyl|first1=Hermann|author1-link=Hermann Weyl|title=Levels of infinity: Selected writings on mathematics and philosophy|year=2012|publisher=Dover Publications|location=New York|isbn=978-0-486-48903-2|url=https://books.google.com/books/about/Levels_of_Infinity.html?id=wc4R0BHdo-sC}}

[[Category:Metatheorems]]
[[Category:Proof theory]]</text>
      <sha1>74w4siphm3438fam4deel1skvwvjfkr</sha1>
    </revision>
  </page>
  <page>
    <title>HAKMEM</title>
    <ns>0</ns>
    <id>505526</id>
    <revision>
      <id>698004529</id>
      <parentid>697950031</parentid>
      <timestamp>2016-01-03T11:06:41Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>Some CE</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4071">{{primary sources|date=July 2015}}
{{third-party|date=July 2015}}
'''HAKMEM''', alternatively known as '''AI Memo 239''', is a February 1972 "memo" ([[technical report]]) of the [[MIT AI Lab]] containing a wide variety of [[Hack (technology slang)|hack]]s, including useful and clever [[algorithm]]s for mathematical computation, some [[number theory]] and [[schematic diagram]]s for hardware&lt;ref name="HAKMEM"&gt;{{cite |title=HAKMEM |author-first1=Michael |author-last1=Beeler |author-first2=Ralph William |author-last2=Gosper |author-link2=Bill Gosper |author-first3=Richard C. |author-last3=Schroeppel |author-link3=Richard C. Schroeppel |contribution=compilation |contributor-first1=Richard C. |contributor-last1=Schroeppel |contributor-link1=Richard C. Schroeppel |contributor-last2=Orman |contributor-first2=Hilarie K. |date=1972-02-29 |publisher=[[MIT AI Lab|Artificial Intelligence Laboratory]], [[Massachusetts Institute of Technology]], Cambridge, Massachusetts, USA |id=MIT AI Memo 239 |type=report}}&lt;/ref&gt; — in [[Guy L. Steele]]'s words, "a bizarre and eclectic potpourri of technical trivia".&lt;ref name="Warren_2013"&gt;{{Cite book |title=Hacker's Delight |title-link=Hacker's Delight |author-first=Henry S. |author-last=Warren Jr. |contribution=foreword |contributor-first=Guy L. |contributor-last=Steele |contributor-link=Guy L. Steele |date=2013 |orig-year=2002 |edition=2 |publisher=[[Addison Wesley]] - [[Pearson Education, Inc.]] |isbn=978-0-321-84268-8 |id=0-321-84268-5 |page=xi}} ([http://www.hackersdelight.org/foreword.pdf])&lt;/ref&gt;
Contributors included about two dozen members and associates of the AI Lab. The title of the report is short for "hacks memo", abbreviated to six upper case characters that would fit in a single [[PDP-10]] machine word (using a six-bit character set).&lt;ref name="Warren_2013"/&gt;

== History ==
HAKMEM is notable as an early compendium of [[algorithm]]ic technique, particularly for its practical bent, and as an illustration of the wide-ranging interests of AI Lab people of the time, which included almost anything other than AI research.

HAKMEM contains original work in some fields, notably [[continued fraction]]s.{{Citation needed|date=August 2014}}

== Introduction ==
&lt;blockquote&gt;
:Compiled with the hope that a record of the random things people do around here can save some duplication of effort -- except for fun.

:Here is some little known data which may be of interest to computer [[Hacker (programmer subculture)|hackers]]. The items and examples are so sketchy that to decipher them may require more sincerity and curiosity than a non-hacker can muster. Doubtless, little of this is new, but nowadays it's hard to tell. So we must be content to give you an insight, or save you some cycles, and to welcome further contributions of items, new or used.
&lt;/blockquote&gt;

==See also==
*[[Hacker's Delight]]
*[[AI Memo]]

==References==
{{reflist}}

==External links==
*[http://hdl.handle.net/1721.1/6086 Its official record at the DSpace@MIT's AI Memos collection]
*{{cite |title=HAKMEM |author-first1=Michael |author-last1=Beeler |author-first2=Ralph William |author-last2=Gosper |author-link2=Bill Gosper |author-first3=Richard C. |author-last3=Schroeppel |author-link3=Richard C. Schroeppel |contribution=compilation |contributor-first1=Richard C. |contributor-last1=Schroeppel |contributor-link1=Richard C. Schroeppel |contributor-last2=Orman |contributor-first2=Hilarie K. |date=1972-02-29 |publisher=[[MIT AI Lab|Artificial Intelligence Laboratory]], [[Massachusetts Institute of Technology]], Cambridge, Massachusetts, USA |edition=retyped &amp; converted (April 1995) |editor-first=Henry |editor-last=Baker |id=MIT AI Memo 239 |type=report |url=http://home.pipeline.com/~hbaker1/hakmem/hakmem.html |access-date=2016-01-02}}
*[ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-239.pdf HAKMEM facsimile (PDF)] ([http://w3.pppl.gov/~hammett/work/2009/AIM-239-ocr.pdf searchable version])

[[Category:Algorithms]]
[[Category:Computer science papers]]
[[Category:1972 in Massachusetts]]
[[Category:Memoranda]]</text>
      <sha1>4zgcuxd0wpnwee7d5i4jyncc5skedic</sha1>
    </revision>
  </page>
  <page>
    <title>Hadamard's lemma</title>
    <ns>0</ns>
    <id>15967005</id>
    <revision>
      <id>848131778</id>
      <parentid>790709733</parentid>
      <timestamp>2018-06-30T00:00:14Z</timestamp>
      <contributor>
        <ip>178.16.7.156</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1727">In [[mathematics]], '''Hadamard's lemma''', named after [[Jacques Hadamard]], is essentially a first-order form of [[Taylor's theorem]], in which we can express a smooth, real-valued function exactly in a convenient manner.

==Statement==
Let ƒ be a smooth, real-valued function defined on an open, [[star-convex]] neighborhood ''U'' of a point ''a'' in ''n''-dimensional Euclidean space.  Then ƒ(''x'') can be expressed, for all ''x'' in ''U'', in the form:

:&lt;math&gt;f(x) = f(a) + \sum_{i=1}^n \left(x_i - a_i\right) g_i(x),&lt;/math&gt;

where each ''g&lt;sub&gt;i&lt;/sub&gt;'' is a smooth function on ''U'', ''a'' = (''a''&lt;sub&gt;1&lt;/sub&gt;,{{nbsp}}…,{{nbsp}}''a''&lt;sub&gt;''n''&lt;/sub&gt;), and ''x'' = (''x''&lt;sub&gt;1&lt;/sub&gt;,{{nbsp}}…,{{nbsp}}''x''&lt;sub&gt;''n''&lt;/sub&gt;).

==Proof==
Let ''x'' be in ''U''.  Let ''h'' be the map from [0,1] to the real numbers defined by

:&lt;math&gt;h(t) = f(a + t(x - a)).&lt;/math&gt;

Then since

:&lt;math&gt;h'(t) = \sum_{i=1}^n \frac{\partial f}{\partial x_i}(a + t(x - a)) \left(x_i - a_i\right),&lt;/math&gt;

we have

:&lt;math&gt;h(1) - h(0) = \int_0^1 h'(t)\,dt
  = \int_0^1 \sum_{i=1}^n \frac{\partial f}{\partial x_i}(a + t(x - a)) \left(x_i - a_i\right)\, dt
  = \sum_{i=1}^n \left(x_i - a_i\right)\int_0^1 \frac{\partial f}{\partial x_i}(a + t(x - a))\, dt. &lt;/math&gt;

But, additionally, ''h''(1)&amp;nbsp;&amp;minus;&amp;nbsp;''h''(0) = ''f''(''x'')&amp;nbsp;&amp;minus;&amp;nbsp;''f''(''a''), so if we let

:&lt;math&gt;g_i(x) = \int_0^1 \frac{\partial f}{\partial x_i}(a + t(x - a))\, dt,&lt;/math&gt;

we have proven the theorem.

==References==
*{{cite book |author=Nestruev, Jet |title=Smooth manifolds and observables |publisher=Springer |location=Berlin |year=2002 |pages= |isbn=0-387-95543-7 |oclc= |doi=}}

[[Category:Real analysis]]
[[Category:Theorems in analysis]]</text>
      <sha1>bwehi5lmsd4mylp8ltrun202kx6ky0b</sha1>
    </revision>
  </page>
  <page>
    <title>Hans Lewy</title>
    <ns>0</ns>
    <id>1752415</id>
    <revision>
      <id>871179815</id>
      <parentid>841521528</parentid>
      <timestamp>2018-11-29T13:33:17Z</timestamp>
      <contributor>
        <username>Thatsme314</username>
        <id>31364895</id>
      </contributor>
      <minor/>
      <comment>/* Life */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17544">{{Infobox scientist
| name              = Hans Lewy
| image             = Hans Lewy.jpeg
| image_size        = 
| alt               = 
| caption           = Hans Lewy in 1975 &lt;br&gt;(photo by George Bergman)
| birth_date        = {{Birth date|1904|10|20}}
| birth_place       = [[Breslau]]
| death_date        = {{Death date and age|1988|08|23|1904|10|20}}
| death_place       = [[Berkeley, California]], [[United States of America]]
| nationality       = [[United States of America]]
| fields            = [[Mathematical analysis]], [[partial differential equation]]s, [[several complex variables]]
| workplaces        = 
| alma_mater        = [[University of Göttingen]]
| doctoral_advisor  = [[Richard Courant]]&lt;ref&gt;{{MathGenealogy|id=32892|title=Hans Lewy}}&lt;/ref&gt;
| doctoral_students = [[David Kinderlehrer]]
| known_for         = [[Courant–Friedrichs–Lewy condition]], [[Lewy's example]]
| influences        = 
| influenced        = [[numerical analysis]], [[partial differential equation]]s, [[several complex variables]]
| awards            = [[Wolf prize]] (1986)&lt;ref name="wolf"&gt;{{Citation
  | last = Wolf Foundation
  | first = 
  | author-link = Wolf Foundation
  | title = THE 1984/5 WOLF FOUNDATION PRIZE IN MATHEMATICS
  | language = Hebrew
  | year = 2003
  | url = http://www.wolffund.org.il/index.php?dir=site&amp;page=winners&amp;name=&amp;prize=&amp;year=1984&amp;field=3004
  | accessdate = September 14, 2013}}.&lt;/ref&gt;
| signature         = &lt;!--(filename only)--&gt;
| signature_alt     = 
| footnotes         = 
| spouse            = 
}}
'''Hans Lewy''' (20 October 1904 – 23 August 1988) was a Jewish [[Germany|German born]] American [[mathematician]], known for his work on [[partial differential equation]]s and on the [[Several complex variables|theory of functions of several complex variables]].&lt;ref&gt;{{cite book|editor1=Chern, Shiing-Shen|editorlink1=Shiing-Shen Chern|editor2=Hirzebruch, Friedrich|editorlink2=Friedrich Hirzebruch|chapter="Hans Lewy" prepared by S. Hildebrandt|title=Wolf Prize|volume=vol. 2|year=2001|pages=264–310|publisher=World Scientific|url=https://books.google.com/books?id=GHFtMc9NTkYC&amp;pg=PA264}}&lt;/ref&gt;

==Life==
Lewy was born in [[Breslau]], Germany (now [[Wrocław]], [[Poland]]), on October 20, 1904. He began his studies at the [[University of Göttingen]] in 1922, after being advised to avoid the more local [[University of Wrocław|University of Breslau]] because it was too old-fashioned,&lt;ref name="mmp"/&gt;&lt;ref name="kin"&gt;{{Citation
  | first = David
  | last = Kinderlehrer
  | author-link = David Kinderlehrer
  | editor-last = Kinderlehrer
  | editor-first = David
  | editor-link =  David Kinderlehrer
  | contribution = Hans Lewy. A brief biographical sketch
  | contribution-url = https://books.google.com/books?id=mX8hTcETCc4C&amp;pg=PR15 
  | title = Hans Lewy Selecta. Volume 2
  | place = [[Boston]]-[[Basel]]-[[Stuttgart]]
  | publisher = [[Birkhäuser Verlag]]
  | year = 2002
  | series = Contemporary Mathematicians
  | url = https://books.google.com/books?id=mX8hTcETCc4C&amp;printsec=frontcover#v=onepage&amp;q&amp;f=true
  | isbn = 0-8176-3524-6}}.&lt;/ref&gt; supporting himself during the [[Hyperinflation in the Weimar Republic|Weimar hyperinflation]] by a side job doing railroad track maintenance.&lt;ref name="kin"/&gt; At Göttingen, he studied both mathematics and physics; his teachers there included [[Max Born]], [[Richard Courant]], [[James Franck]], [[David Hilbert]], [[Edmund Landau]], [[Emmy Noether]], and [[Alexander Ostrowski]]. He earned his doctorate in 1926, at which time he and his friend [[Kurt Otto Friedrichs]] both became assistants to Courant and [[privatdozent]]s at Göttingen.&lt;ref name="mmp"&gt;{{citation|contribution=Hans Lewy|title=More Mathematical People|editor1-first=Donald J.|editor1-last=Albers|editor2-first=Gerald L.|editor2-last=Alexanderson|editor2-link=Gerald L. Alexanderson|editor3-first=Constance|editor3-last=Reid|editor3-link=Constance Reid|publisher=Harcourt Brace Jovanovich|year=1990|pages=180–194}}.&lt;/ref&gt;&lt;ref name="kin"/&gt;

At the recommendation of Courant, Lewy was granted a [[Rockefeller Foundation|Rockefeller Fellowship]], which he used in 1929 to travel to Rome and study [[algebraic geometry]] with [[Tullio Levi-Civita]] and [[Federigo Enriques]], and then in 1930 to travel to Paris, where he attended the seminar of [[Jacques Hadamard]]. After [[Hitler]]'s election as chancellor in 1933, Lewy was advised by [[Herbert Busemann]] to leave Germany again. He was offered a position in Madrid, but declined it, fearing for the future there under [[Francisco Franco]]. He revisited Italy and France, but then at the invitation of the [[Emergency Committee in Aid of Displaced Foreign Scholars]] and with the assistance of Hadamard found a two-year position in America at [[Brown University]]. At the end of that term, in 1935, he moved to the [[University of California, Berkeley]].&lt;ref name="mmp"/&gt;&lt;ref name="kin"/&gt;

During [[World War II]], Lewy obtained a pilot's license, but then worked at the [[Aberdeen Proving Ground]]. He married Helen Crosby in 1947.&lt;ref name="kin"/&gt;

In 1950, Lewy was fired from Berkeley for refusing to sign a loyalty oath.&lt;ref name="kin"/&gt;&lt;ref name="nyt"/&gt;&lt;ref name="calyp"/&gt; He taught at [[Harvard University]] and [[Stanford University]] in 1952 and 1953&lt;ref name="kin"/&gt; before being reinstated by the [[California Supreme Court]] case ''[[Tolman v. Underhill]]''.&lt;ref name="nyt"/&gt;&lt;ref name="calyp"&gt;{{citation|contribution=Politics Impinges upon Mathematics|author=Sherri Chasin Calvo|pages=242–244|title=Science and Its Times: Understanding the Social Significance of Scientific Discovery. Vol. VII: 1950 to present|editor=Neil Schlager|publisher=Gale Group|year=2000|isbn=978-0-7876-3939-6|url=http://www.highbeam.com/doc/1G2-3408504264.html|subscription=yes}}.&lt;/ref&gt;

He retired from Berkeley in 1972, and in 1973 became one of two Ordway Professors of Mathematics at the [[University of Minnesota]]. He died on August 23, 1988, in Berkeley.&lt;ref name="kin"/&gt;&lt;ref name="nyt"&gt;{{Citation
  | title = Dr. Hans Lewy, 83, Mathematics Professor
  | newspaper = [[The New York Times]]
  | date = September 2, 1988
  | url = https://www.nytimes.com/1988/09/02/obituaries/dr-hans-lewy-83-mathematics-profesor.html}}&lt;/ref&gt;&lt;ref name="ucinmem"&gt;{{Citation
  | last = Protter
  | first = M.
  | author-link = Murray Protter
  | first2 = Kelley
  | last2 = J. L.
  | author2-link = John_L._Kelley
  | last3 = Kato
  | first3 = T.
  | author3-link = Tosio Kato
  | last4 = Lehmer
  | first4 = D. H.
  | author4-link = Derrick Henry Lehmer
  | editor-last = Krogh
  | editor-first = David
  | editor-link =
  | contribution = Hans Lewy, Mathematics: Berkeley. 1904-1988 Professor Emeritus
  | contribution-url = http://texts.cdlib.org/view?docId=hb967nb5k3&amp;doc.view=frames&amp;chunk.id=div00032&amp;toc.depth=1&amp;toc.id=
  | title = 1988, University of California: In Memoriam
  | year = 1988
  | pages = 85–87
  | place = [[Berkeley, CA]]
  | publisher = [[University of California, Berkeley]]
  | url = http://texts.cdlib.org/view?docId=hb967nb5k3&amp;brand=calisphere&amp;chunk.id=meta
   }}.&lt;/ref&gt;

==Awards and honors==
Lewy was elected to the [[National Academy of Sciences]] in 1964, and was also a member of the [[American Academy of Arts and Sciences]].&lt;ref name="nyt"/&gt; He became a foreign member of the [[Accademia dei Lincei]] in 1972.&lt;ref name="kin"/&gt;
He was awarded a [[Leroy P. Steele Prize]] in 1979,&lt;ref name="kin"/&gt; and a [[Wolf Prize in Mathematics]] in 1986 for his work on partial differential equations.&lt;ref name="wolf"/&gt; In 1986, the [[University of Bonn]] gave him an honorary doctorate.&lt;ref name="ucinmem"/&gt;

==Publications==
*{{cite journal|author=Lewy, Hans|title=A priori limitations for Monge-Ampère equations|journal=Trans. Amer. Math. Soc.|year=1935|volume=37|pages=417–434|mr=1501794|doi=10.1090/s0002-9947-1935-1501794-9}}
*{{cite journal|author=Lewy, Hans|authormask=2|title=On the non-vanishing of the Jacobian in certain one-to-one mappings|journal=Bull. Amer. Math. Soc.|year=1936|volume=42|pages=689–692|mr=1563404|doi=10.1090/s0002-9904-1936-06397-4}}
*{{cite journal|author=Lewy, Hans|authormask=2|title=Generalized integrals and differential equations|journal=Proc Natl Acad Sci U S A|year=1936|volume=22|issue=6|pages=377–381|pmc=1076784|doi=10.1073/pnas.22.6.377|pmid=16588088}}
*{{cite journal|author=Lewy, Hans|authormask=2|title=A priori limitations for Monge-Ampère equations. II|journal=Trans. Amer. Math. Soc.|year=1937|volume=41|pages=365–374|mr=1501906|doi=10.1090/s0002-9947-1937-1501906-9}}
*{{cite journal|author=Lewy, Hans|authormask=2|title=On the existence of a closed convex surface realizing a given Riemannian metric|journal=Proc Natl Acad Sci U S A|year=1938|volume=24|issue=2|pages=104–106|pmc=1077039|doi=10.1073/pnas.24.2.104|pmid=16588189}}
*{{cite journal|author=Lewy, Hans|authormask=2|title=Generalized integrals and differential equations|journal=Trans. Amer. Math. Soc.|year=1938|volume=43|pages=437–464|mr=1501953|doi=10.1090/s0002-9947-1938-1501953-8|pmc=1076784}}
*{{cite journal|author=Lewy, Hans|authormask=2|title=On differential geometry in the large. I. Minkowski's problem|journal=Trans. Amer. Math. Soc.|year=1938|volume=43|pages=258–270|mr=1501942|doi=10.1090/s0002-9947-1938-1501942-3}}
*{{cite book|author=Lewy, Hans|author2=Green, John Willie|title=Aspects of the Calculus of Variations|year=1939|location=Berkeley|publisher=U. of California Press|postscript=; notes by J. W. Green from lectures by Hans Lewy, vi+96 pp.}}&lt;ref&gt;{{cite journal|author=Reid, W. T.|title=Review: ''Aspects of the Calculus of Variations'', notes by J. W. Green from lectures by Hans Lewy|journal=Bull. Amer. Math. Soc.|year=1940|volume=46|issue=7|pages=595–596|url=http://projecteuclid.org/euclid.bams/1183502779|doi=10.1090/s0002-9904-1940-07238-6}}&lt;/ref&gt;
*{{cite journal|author=Lewy, Hans|title=Water waves on sloping beaches|journal=Bull. Amer. Math. Soc.|year=1946|volume=52|pages=737–775|mr=0022134|doi=10.1090/s0002-9904-1946-08643-7}}
*{{cite journal|author=Lewy, Hans|authormask=2|title=On the boundary behavior of minimal surfaces|journal=Proc Natl Acad Sci U S A|year=1951|volume=37|issue=2|pages=103–110|pmc=1063312|pmid=16578356|doi=10.1073/pnas.37.2.103}}
*{{cite journal|author=Lewy, Hans|authormask=2|title=A note on harmonic functions and a hydrodynamical application|journal=Proc. Amer. Math. Soc.|year=1952|volume=3|pages=111–113|mr=0049399|doi=10.1090/s0002-9939-1952-0049399-9}}
*{{cite journal|author=Lewy, Hans|authormask=2|title=On the reflection laws of second order differential equations in two independent variables|journal=Bull. Amer. Math. Soc.|year=1959|volume=65|pages=37–58|mr=0104048|doi=10.1090/s0002-9904-1959-10270-6}}
A selection of his work, edited by [[David Kinderlehrer]] and including his most important works, was published as the two volume work {{harv|Kinderlehrer|2002a}} and {{harv|Kinderlehrer|2002b}}
*{{Citation
| editor-last = Kinderlehrer
| editor-first = David
| editor-link =  David Kinderlehrer
| title = Hans Lewy Selecta. Volume 1
| place = [[Boston]]-[[Basel]]-[[Stuttgart]]
| publisher = [[Birkhäuser Verlag]]
| year = 2002a
| series = Contemporary Mathematicians
| pages = lxvi+357
| url = https://books.google.com/books?id=VDutq5E6CbgC&amp;printsec=frontcover&amp;hl=it#v=onepage&amp;q&amp;f=true
| doi = 
| mr =
| zbl = 1132.01312
| isbn = 0-8176-3523-8
}}. With biographical essays by Helen Lewy and [[Constance Reid]], and commentaries on Lewy's work by [[Erhard Heinz]], [[Peter D. Lax]], [[Jean Leray]], [[Richard MacCamy]], [[Louis Nirenberg]] and [[François Treves]].
*{{Citation
| editor-last = Kinderlehrer
| editor-first = David
| editor-link =  David Kinderlehrer
| title = Hans Lewy Selecta. Volume 2
| place = [[Boston]]-[[Basel]]-[[Stuttgart]]
| publisher = [[Birkhäuser Verlag]]
| year = 2002b
| series = Contemporary Mathematicians
| url = https://books.google.com/books?id=mX8hTcETCc4C&amp;printsec=frontcover#v=onepage&amp;q&amp;f=true
| pages = xviii, 446
| doi = 
| mr =
| zbl = 1147.01335
| isbn = 0-8176-3524-6}}.
The following works are included in his "''Selecta''" in their original language or translated form.
*{{Citation
  | last = Courant
  | first = R.
  | author-link = Richard Courant
  | last2 = Friedrichs
  | first2 = K.
  | author2-link = Kurt Otto Friedrichs
  | last3 = Lewy
  | first3 = H.
  | author3-link = 
  | title = Über die partiellen Differenzengleichungen der mathematischen Physik
  | journal = [[Mathematische Annalen]]
  | volume = 100
  | issue = 1
  | pages = 32–74
  | date = 
  | year = 1928
  | month =
  | language = German
  | url = http://resolver.sub.uni-goettingen.de/purl?GDZPPN002272636
  | doi = 10.1007/BF01448839
  | jfm = 54.0486.01
  | mr = 1512478
 }}. There are also two English translations of the 1928 German original paper: the first one is a translation from the [[German language|German]] by Phyllis Fox, circulated as a research report: {{Citation
  | last = Courant
  | first = R.
  | author-link = Richard Courant
  | last2 = Friedrichs
  | first2 = K.
  | author2-link = Kurt Otto Friedrichs
  | last3 = Lewy
  | first3 = H.
  | author3-link =
  | title = On the partial difference equations of mathematical physics
  | place = New York
  | publisher = AEC Computing and Applied Mathematics Centre – [[Courant Institute of Mathematical Sciences]]
  | series = AEC Research and Development Report
  | volume = NYO-7689
  | origyear = 1928
  |date=September 1956
  | edition = 
  | pages = V + 76
  | url = https://archive.org/details/onpartialdiffere00cour
  | archiveurl = https://archive.org/stream/onpartialdiffere00cour#page/n0/mode/2up
  | archivedate = October 23, 2008
  | doi = 
  | isbn = 
}}. The second one is a typographical improvement of the first, published by [[IBM]] as: {{Citation
  | last = Courant
  | first = R.
  | author-link = Richard Courant
  | last2 = Friedrichs
  | first2 = K.
  | author2-link = Kurt Otto Friedrichs
  | last3 = Lewy
  | first3 = H.
  | author3-link = 
  | title = On the partial difference equations of mathematical physics
  | journal = [http://researchweb.watson.ibm.com/journal/rdindex.html IBM Journal of Research and Development]
  | volume = 11
  | issue = 2
  | pages = 215–234
  | origyear = 1928
  |date=March 1967
  | url = http://domino.research.ibm.com/tchjr/journalindex.nsf/a3807c5b4823c53f85256561006324be/769774a3c9f3685f85256bfa00683f8a!OpenDocument
  | mr = 0213764
  | zbl = 0145.40402
  | doi=10.1147/rd.112.0215
}}. A freely downlodable  version of this one can be found [http://www.stanford.edu/class/cme324/classics/courant-friedrichs-lewy.pdf here]
*{{citation
| last = Lewy
| first = Hans
| author-link =
| title = An example of a smooth linear partial differential equation without solution
| journal = [[Annals of Mathematics]]
| volume = 66
| issue = 1
| year = 1957
| pages = 155–158
| jstor = 1970121
| mr = 0088629
| zbl = 0078.08104
| doi = 10.2307/1970121
}}.
*{{Citation
  | last = Lewy
  | first = Hans
  | author-link = 
  | title = On the boundary behavior of holomorphic mappings (Lezione tenuta il 3 maggio 1976) (Lecture given on May 3, 1976)
  | place = Rome
  | publisher = [[Accademia Nazionale dei Lincei]]
  | year = 1977
  | series = Contributi del Centro Linceo Interdisciplinare di Scienze Matematiche e Loro Applicazioni
  | volume = 35
  | pages = 8
  | url = http://www.lincei.it/pubblicazioni/catalogo/volume.php?rid=33201
  | doi =
  | isbn = 
  | mr =
  | zbl =
}}.

==See also==
*[[Lewy's example]]
*[[Courant–Friedrichs–Lewy condition]]

==References==
{{reflist|30em}}

==External links==
*{{Citation
  | last = The Bancroft Library
  | first = 
  | author-link = The Bancroft Library
  | title = Guide to the Hans Lewy Papers
  | volume = Collection number BANC MSS 91/147 cz
  | date = 
  | year = 2009
  | url = http://www.oac.cdlib.org/findaid/ark:/13030/kt8f59q33c/
  | accessdate = July 9, 2011
}}.
*{{Citation
  | last = Dynkin
  | first = Eugene B.
  | author-link = Eugene B. Dynkin
  | title = Hans Lewy Interview October 7, 1981
  | series = Eugene B. Dynkin Collection of Mathematics Interviews
  | date = October 7, 1981
  | hdl = 1813/17262}}. An [[audio interview]], available at [http://ecommons.cornell.edu/ eCommons@Cornell] from the [Eugene B. Dynkin Collection of Mathematics Interviews Eugene B. Dynkin Collection of Mathematics Interviews ].
*{{Citation
  | last = 
  | first = 
  | author-link = 
  | contribution = Lewy ‹léevi›, Hans
  | title = [[Enciclopedia Treccani]]
  | language = Italian
  | date = 
  | year = 2008
  | contribution-url = http://www.treccani.it/enciclopedia/hans-lewy/
  | accessdate = July 26, 2011}}. The biographical entry about Hans Lewy at the [[Enciclopedia Treccani]].
*{{MacTutor Biography|id=Lewy}}

{{Wolf Prize in Mathematics}}

{{Authority control}}

{{DEFAULTSORT:Lewy, Hans}}
[[Category:1904 births]]
[[Category:1988 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:20th-century German mathematicians]]
[[Category:German Jews]]
[[Category:Complex analysts]]
[[Category:Mathematical analysts]]
[[Category:Rockefeller Fellows]]
[[Category:Wolf Prize in Mathematics laureates]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:University of Göttingen alumni]]
[[Category:University of Göttingen faculty]]
[[Category:Brown University faculty]]
[[Category:University of California, Berkeley faculty]]
[[Category:University of Minnesota faculty]]</text>
      <sha1>ogda05cdo0guylw99mywpaypnhdcmf9</sha1>
    </revision>
  </page>
  <page>
    <title>Herman Goldstine</title>
    <ns>0</ns>
    <id>763708</id>
    <revision>
      <id>869039065</id>
      <parentid>868138280</parentid>
      <timestamp>2018-11-16T00:55:45Z</timestamp>
      <contributor>
        <username>Josvebot</username>
        <id>14967932</id>
      </contributor>
      <minor/>
      <comment>v2.0b - [[WP:WCW]] project (Unicode control characters)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14809">{{more citations needed|date=March 2013}}
[[File:Herman Goldstine.jpg|thumb|Herman Goldstine at Princeton Institute for Advanced Study.]]
'''Herman Heine Goldstine''' (September 13, 1913 &amp;ndash; June 16, 2004) was a [[mathematician]] and [[computer scientist]], who was one of the original developers of [[ENIAC]], the first of the modern electronic digital computers.

==Personal life==
Herman Heine Goldstine was born in Chicago in 1913 to Jewish parents. He attended the [[University of Chicago]], where he joined the [[Phi Beta Kappa]] fraternity, and graduated with a degree in Mathematics in 1933, a master's degree in 1934, and a PhD in 1936. For three years he was a research assistant under [[Gilbert Ames Bliss]], an authority on the mathematical theory of [[external ballistics]]. In 1939 Goldstine began a teaching career at the [[University of Michigan]], until the [[United States]]' entry into [[World War II]], when he joined the U. S. Army. In 1941 he married [[Adele Goldstine|Adele Katz]], who was an [[ENIAC]] programmer and who wrote the technical description for ENIAC. He had a daughter and a son with Adele, who died in 1964. Two years later he married secondly Ellen Watson.

In retirement Goldstine became executive director of the [[American Philosophical Society]] in [[Philadelphia]] between 1985 and 1997, in which capacity he was able to attract many prestigious visitors and speakers.

Goldstine died on June 16, 2004, at his home in [[Bryn Mawr, Pennsylvania|Bryn Mawr]], [[Pennsylvania]], after a long struggle with [[Parkinson's disease]]. His death was announced by the [[Thomas J. Watson Research Center]] in [[Yorktown Heights]], [[New York (state)|New York]], where a [[post-doctoral fellowship]] was renamed in his honor.

==BRL and the Moore School==
As a result of the United States' entering [[World War II]], Goldstine left the [[University of Michigan]] where he was a professor in July, 1942 to enlist in the Army. He was commissioned a [[lieutenant]] and worked as an ordnance mathematician calculating [[firing tables]] at the [[Ballistic Research Laboratory]] (BRL) at [[Aberdeen Proving Ground]],  [[Maryland]]. The firing tables were used in battle to find the appropriate [[elevation (ballistics)|elevation]] and [[azimuth]] for aiming artillery, which had a range of several miles.

The firing table calculations were accomplished by about one hundred women operating [[Calculator#1930s to 1960s|mechanical desk calculators]]. Each combination of gun, round and geographical region required a unique set of firing tables. It took about 750 calculations to compute a single trajectory and each table had about 3,000 trajectories. It took [[human computer]] at least 7 hours to calculate one trajectory.&lt;ref&gt;[http://history.siam.org/pdf/hgoldstine.pdf Herman H. Goldstine, Remembrance of Things Past] from "A History of Scientific Computing"&lt;/ref&gt; To increase production, BRL enlisted the computing facilities of the [[Moore School of Electrical Engineering]] at the [[University of Pennsylvania]] and Goldstine was the liaison between BRL and the university.

===The ENIAC===
While making some adjustments to the Moore School's mechanical [[differential analyzer]], engineer [[Joseph Chapline]] suggested Goldstine visit [[John Mauchly]], a physics instructor at the Moore School, who had distributed a memorandum proposing that the calculations could be done thousands of times faster with an electronic computer using [[vacuum tubes]].  Mauchly wrote a proposal and in June 1943 he and Goldstine secured funding from the Army  for the project. The ENIAC was built in 30 months with 200,000 man hours. The ENIAC was huge, measuring 30 by 60 feet and weighing 30 tons with 18,000 [[vacuum tubes]]. The device could only store 20 numbers and took days to program. It was completed in late 1945 as [[World War II]] was coming to an end.

===The EDVAC===
In spite of disappointment that ENIAC had not contributed to the war effort, interest remained strong in the Army to develop an electronic computer.  Prior even to the ENIAC's completion, the Army procured a second contract from the Moore School to build a successor machine known as the [[EDVAC]].  Goldstine, Mauchly, [[J. Presper Eckert]] and [[Arthur Burks]] began to study the development of the new machine in the hopes of correcting the deficiencies of the ENIAC.

[[File:Julian Bigelow.jpg|thumb|Herman Goldstine at The Princeton Institute for Advanced Study (left to right: [[Julian Bigelow]], Herman Goldstine, [[J. Robert Oppenheimer]], and [[John von Neumann]])]]

===Meeting John von Neumann===
In the summer of 1944 Goldstine had a chance encounter with the prominent mathematician [[John von Neumann]] on a railway platform in [[Aberdeen, Maryland]], and Goldstine described his project at the University of Pennsylvania.  Unknown to Goldstine, von Neumann was then working on the [[Manhattan Project]], which was aiming to build the first [[atomic bomb]].  The calculations needed for this project were also daunting.

===The ''First Draft''===
As a result of his conversations with Goldstine, von Neumann joined the study group and wrote a memo called ''[[First Draft of a Report on the EDVAC]]''.  von Neumann intended this to be a memo to the study group, but Goldstine typed it up into a 101-page document that named von Neumann as the sole author.  On June 25, 1946, Goldstine forwarded 24 copies of the document to those intimately involved in the EDVAC project; dozens or perhaps hundreds of mimeographs of the report were forwarded to von Neumann's colleagues at universities in the United States and in [[Great Britain]] in the weeks that followed.  While incomplete, the paper was very well received and became a blueprint for building electronic digital computers.  Due to von Neumann's prominence as a major American mathematician, the EDVAC architecture became known as the [[von Neumann architecture]].
[[File:Flow chart of Planning and coding of problems for an electronic computing instrument, 1947.jpg|thumb|[[Flow chart]] from "Planning and coding of problems for an electronic computing instrument," 1947]]
One of the key ideas in the "first draft" was that the programmer could store a program in the computer's electronic memory, rather than program the computer using mechanical switches and patch cables. This and other ideas in the paper had been discussed in the EDVAC study group before von Neumann joined the group. The fact that Eckert and Mauchly, the actual inventors and designers of the ENIAC, were not named as co-authors created resentment that led to the group's dissolution at the end of the war.

Eckert and Mauchly went on to form the [[Eckert-Mauchly Computer Corporation]], a company that in part survives today as the [[Unisys]] Corporation, while von Neumann, Goldstine and Burks moved on into academic life at the [[Institute for Advanced Study]].  In Summer 1946, all of them were reunited to give presentations at the first computer course, which has come to be known as the [[Moore School Lectures]]; Goldstine's presentations, given without notes, covered deeply and rigorously numerical mathematical methods useful in programs for digital computers.

==Institute for Advanced Study==
After [[World War II]] Goldstine joined von Neumann and Burks at the [[Institute for Advanced Study]] at [[Princeton, New Jersey|Princeton]], where they built a computer referred to as the [[IAS machine]]. Goldstine was appointed as assistant director of the project and was later its director, after 1954.

The IAS machine influenced the design of [[IBM]]'s early computers through von Neumann, who was a consultant to IBM. When von Neumann died in 1958, the IAS computer project was terminated. Goldstine went on to become the founding director of the Mathematical Sciences Department at IBM's Watson Research Center in Yorktown Heights, New York.

==IBM==
At IBM one of Goldstine's most significant roles was in fostering relations between IBM researchers and the academic community. In 1969 he was appointed an [[IBM Fellow]], the company's most prestigious technical honor, and a consultant to the director of research. As a fellow Goldstine developed an interest in the history of computing and mathematical sciences. He wrote three books on the topic; ''The Computer from Pascal to von Neumann'', ''History of Numerical Analysis from the 16th Through the 19th Century'' and ''History of the Calculus of Variations from the Seventeenth Through the Nineteenth Century''. As the title implies, in ''The Computer from Pascal to von Neumann'', Goldstine leaves little doubt that in his opinion von Neumann played a critical role in developing modern theories of computing.

==Awards and honoraria==
* [[Harry H. Goode Memorial Award]] in 1979
* [[National Medal of Science]] (1985)
* Hall of Fame of the [[Army Ordnance Department]] (1997)
* [[Benjamin Franklin Medal for Distinguished Achievement in the Sciences]] of the [[American Philosophical Society]] (1997).&lt;ref name="franklinscience_recipients"&gt;{{cite web|url=http://www.amphilsoc.org/prizes/franklinscience |title=Benjamin Franklin Medal for Distinguished Achievement in the Sciences Recipients |publisher=[[American Philosophical Society]] |accessdate=November 27, 2011}}&lt;/ref&gt;
* [[IEEE Computer Pioneer Award#Computer Pioneer Charter Recipients|IEEE Computer Society Pioneer Award]] (charter recipient)
* member of the [[National Academy of Science]]
* member of the [[American Academy of Arts and Sciences]]
* member of the [[American Philosophical Society]]

==Publications==
* Arthur W. (Arthur Walter) Burks, Herman Heine Goldstine, John Von Neumann; ''Preliminary Discussion of the Logical Design of an Electronic Computer Instrument''; (Institute for Advanced Study, January 1, 1946) ASIN B0007HW8WE
* {{cite book
 | first = Herman H.
 | last = Goldstine
 |author2=Goldstine, A.
 | chapter = The Electronic Numerical Integrator and Computer (ENIAC)
 | origyear = 1946
 | title = The Origins of Digital Computers: Selected Papers
 | publisher = Springer-Verlag
 | location = New York
 | year = 1982
 | pages = 359–373
 | isbn = 3-540-11319-3
}}
* {{cite book
 |first       = Herman H.
 |last        = Goldstine
 |url         = http://pup.princeton.edu/titles/597.html
 |title       = The Computer from Pascal to von Neumann
 |location    = Princeton, NJ
 |publisher   = Princeton University Press
 |date        = 1980-10-01
 |isbn        = 0-691-02367-0
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20040813111853/http://pup.princeton.edu/titles/597.html
 |archivedate = 2004-08-13
 |df          = 
}}
* {{cite book
 | first = Herman H.
 | last = Goldstine
 | title = New and Full Moons: 1001 B.C. to A.D. 1651
 | location = Philadelphia
 | publisher = American Philosophical Society
 | year = 1973
 | isbn = 0-87169-094-2
}}
* {{cite book
 | first = Herman H.
 | last = Goldstine
 | title = History of Numerical Analysis from the 16th Through the 19th Century (Studies in the History of Mathematics and Physical Sciences, 2)
 | publisher = Springer-Verlag
 | location = New York 
 | year = 1977
 | isbn = 0-387-90277-5
}}
* {{cite book
 | first = Herman H.
 | last = Goldstine
 | title = History of the Calculus of Variations from the Seventeenth Through the Nineteenth Century (Studies in the History of Mathematics and the Physical Sciences)
 | publisher = Springer-Verlag
 | location = New York
 |date=October 1980
 | isbn = 0-387-90521-9
}}
* {{cite book
 | first1 = Jakob
 | last1 = Bernoulli
 | last2 = Bernoulli | first2 = Jean | last3 = Goldstine | first3 =  Herman H. | first4 = P. | last4 = Radelet-de Grave
 | title = Die Streitschritfen Von Jacob Und Johann Bernoulli: Variationsrechnung
 | location = Basel; Boston
 | publisher = Birkhäuser
 | date=September 1991
 | isbn = 3-7643-2348-5 |id={{ISBN|0-8176-2348-5}}
}}

==References==
&lt;references /&gt;

==External links==
* [https://www.nytimes.com/2004/06/26/business/26goldstineobit.html Herman Goldstine, Who Helped Build First Computers, Dies at 90] (Wolfgang Saxon, ''New York Times'', 26 June 2004)
* [http://purl.umn.edu/107333 Oral history interview with Herman H. Goldstine].  [[Charles Babbage Institute]], University of Minnesota. Goldstine discusses his experiences with the [[ENIAC]] computer during World War II. He mentions the [[EDVAC]], the ENIAC's successor, and its innovation of stored programming, for which he credits [[John von Neumann]]. 
* [https://web.archive.org/web/20121016000417/http://www.princeton.edu/~mudd/finding_aids/mathoral/pmc15.htm An interview with Goldstine about his experience at Princeton]
* [http://ftp.arl.army.mil/~mike/comphist/goldstine_obit.htm Herman Goldstine obituary]
* [https://web.archive.org/web/20070926142241/http://www.aps-pub.com/proceedings/1502/1500212.pdf Biographical memoir for American Philosophical Society]
* {{cite book
 |first       = Karl
 |last        = Kempf
 |year        = 1961
 |title       = Electronic Computers Within The Ordnance Corps
 |chapter     = Chapter 2: ENIAC
 |chapterurl  = http://ftp.arl.mil/~mike/comphist/61ordnance/chap2.html
 |location    = Aberdeen Proving Ground, MD
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20040803150905/http://ftp.arl.mil/~mike/comphist/61ordnance/chap2.html
 |archivedate = 2004-08-03
 |df          = 
}}
* [http://domino.research.ibm.com/comm/pr.nsf/pages/news.19980527_goldstine.html IBM Research names mathematics fellowship for computer pioneer Herman Goldstine]
* {{MacTutor Biography|id=Goldstine}}
* {{MathGenealogy|id=6333}}
* {{cite book
 | first = Gina
 | last = DeAngelis
 |author2=Bianco, David J.
 | title = Computers: processing the data
 | publisher = Oliver Press
 | location = Minneapolis
 | year = 2005
 | isbn = 1-881508-87-0
}}

{{Authority control}}
{{Winners of the National Medal of Science|math-stat-comp}}

{{DEFAULTSORT:Goldstine, Herman}}
[[Category:1913 births]]
[[Category:2004 deaths]]
[[Category:Deaths from Parkinson's disease]]
[[Category:American computer scientists]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:National Medal of Science laureates]]
[[Category:University of Chicago alumni]]
[[Category:University of Michigan faculty]]
[[Category:IBM Fellows]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Jewish American scientists]]
[[Category:United States Army officers]]
[[Category:American army personnel of World War II]]
[[Category:Members of the American Philosophical Society]]
[[Category:People from Chicago]]
[[Category:Historians of mathematics]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:Engineers from Illinois]]</text>
      <sha1>4a9bpy5lijwme6wanbod1wb3igof4jt</sha1>
    </revision>
  </page>
  <page>
    <title>John Edensor Littlewood</title>
    <ns>0</ns>
    <id>158371</id>
    <revision>
      <id>870287075</id>
      <parentid>829358123</parentid>
      <timestamp>2018-11-23T19:34:49Z</timestamp>
      <contributor>
        <username>Mathglot</username>
        <id>2544398</id>
      </contributor>
      <minor/>
      <comment>/* With Hardy */ Punct: rendering of single/double-quote together.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11617">{{EngvarB|date=August 2014}}
{{Use dmy dates|date=August 2014}}
{{Infobox scientist
| name = John Edensor Littlewood
| image =
| image_size = 150px
| caption = John E. Littlewood in 1907
| birth_date = {{Birth date|df=yes|1885|6|9}}
| birth_place = [[Rochester, Kent|Rochester]], Kent, England
| death_date = {{death date and age|df=yes|1977|9|6|1885|6|9}}
| death_place = [[Cambridge]], England
| residence = United Kingdom
| nationality = British
| field = Mathematician
| work_institution = [[Trinity College, Cambridge]]
| alma_mater = [[Trinity College, Cambridge]]
| doctoral_advisor = [[Ernest William Barnes]]
| doctoral_students = [[A. O. L. Atkin]]&lt;br /&gt;[[Sarvadaman Chowla]]&lt;br /&gt;[[Harold Davenport]]&lt;br /&gt;[[Srinivasa Ramanujan]]&lt;br /&gt;[[Stanley Skewes]]&lt;br /&gt;[[Donald C. Spencer]]&lt;br /&gt;[[Albert Ingham]]
| known_for  = [[Mathematical analysis]]
| prizes = [[Smith's Prize]] &lt;small&gt;(1908)&lt;/small&gt;&lt;br&gt;[[Royal Medal]] {{small|(1929)}}&lt;br&gt;[[De Morgan Medal]] {{small|(1938)}}&lt;br&gt;[[Sylvester Medal]] &lt;small&gt;(1943)&lt;/small&gt;&lt;br&gt;[[Copley Medal]] {{small|(1958)}}&lt;br&gt;[[Senior Berwick Prize]] &lt;small&gt;(1960)&lt;/small&gt;
| religion =
| footnotes =
}}
'''John Edensor Littlewood''' [[Royal Society of London|FRS]] LLD (9 June 1885 – 6 September 1977){{Sfn|Burkill|1978|p=322}} was an English mathematician. He worked on topics relating to [[Mathematical analysis|analysis]], [[number theory]],
and [[differential equation]]s, and had a lengthy collaboration with [[G. H. Hardy]].

==Biography==
Littlewood was born on 1885 in [[Rochester, Kent]], the eldest son of Edward Thornton Littlewood and Sylvia Maud (nee Ackland). In 1892, his father accepted the headmastership of a school in [[Wynberg, Cape Town]] in South Africa, taking his family there.&lt;ref&gt;{{Harvnb|Burkill|1978|p=324}}: "He later accepted the headmastership of a newly founded school at Wynberg near Cape Town, taking his family there in 1892."&lt;/ref&gt; Littlewood returned to England in 1900 to attend [[St Paul's School, London|St Paul's School]] in London, studying under [[Francis Sowerby Macaulay]], an influential [[algebraic geometry|algebraic geometer]].&lt;ref&gt;{{Harvnb|Bateman|Diamond|1978|p=28}}: "In 1900 he returned to England, where he attended [[St Paul's School, London|St. Paul's School]] and studied with the talented teacher and mathematician [[Francis Sowerby Macaulay|F. S. Macaulay]]."&lt;/ref&gt;

In 1903, Littlewood entered the [[University of Cambridge]], studying in [[Trinity College, Cambridge|Trinity College]]. He spent his first two years preparing for the [[Tripos]] examinations which qualify undergraduates for a bachelor's degree (where he emerged in 1905 as [[Senior Wrangler (University of Cambridge)|Senior Wrangler]], the person who obtained the highest mark in Part 1 of the Tripos). In 1906, after completing the second part of the Tripos, he started his research under [[Ernest Barnes]].&lt;ref&gt;{{Harvnb|Bateman|Diamond|1978|pp=28–29}}: "He began his research later that year on asymptotic formulas for integral functions of order zero, under his tutor and director of studies [[Edward Barnes (mathematician)|E. W. Barnes]]."&lt;/ref&gt; One of the problems that Barnes suggested to Littlewood was to prove the [[Riemann hypothesis]], an assignment at which he did not succeed.&lt;ref&gt;{{Harvnb|Bateman|Diamond|1978|p=29}}: "Barnes proposed to Littlewood the task of proving the Riemann hypothesis ... he did not succeed in that strenuous assignment ..."&lt;/ref&gt; He was elected a Fellow of Trinity College in 1908 and, apart from three years as [[Richardson Chair of Applied Mathematics|Richardson Lecturer]] in the [[School of Mathematics, University of Manchester|University of Manchester]], the balance of his career was spent at the [[University of Cambridge]].  He was appointed [[Rouse Ball]] Professor of Mathematics in 1928, retiring in 1950.  He was elected a [[Fellow of the Royal Society]] in 1916, awarded the [[Royal Medal]] in 1929, the [[Sylvester Medal]] in 1943 and the [[Copley Medal]] in 1958.  He was president of the [[London Mathematical Society]] from 1941 to 1943, and was awarded the [[De Morgan Medal]] in 1938 and the [[Berwick Prizes|Senior Berwick Prize]] in 1960.

==Work==
Most of Littlewood's work was in the field of [[mathematical analysis]]. He began research under the supervision of [[Ernest William Barnes]], who suggested that he attempt to prove the [[Riemann hypothesis]]: Littlewood showed that if the Riemann hypothesis is true then the [[prime number theorem]] follows and obtained the error term.  This work won him his Trinity fellowship. However, the link between the Riemann hypothesis and the prime number theorem had been known before in Continental Europe, and Littlewood wrote later in his book, ''A Mathematician's Miscellany'' that his rediscovery of the result did not shed a positive light on the isolated nature of British mathematics at the time.{{Citation needed|date=December 2013}}

He coined [[Littlewood's law]], which states that individuals can expect "miracles" to happen to them, at the rate of about one per month.

He continued to write papers into his eighties, particularly in analytical areas of what would become the theory of [[dynamical systems]].

Littlewood is also remembered for his book of reminiscences, ''[[A Mathematician's Miscellany]]'' (new edition published in 1986).

Among his own PhD students were [[Sarvadaman Chowla]], [[Harold Davenport]], and [[Donald C. Spencer]]. Spencer reported that in 1941 when he (Spencer) was about to get on the boat that would take him home to the United States, Littlewood reminded him: "''n'', ''n'' alpha, ''n'' beta!" (referring to [[Littlewood's conjecture]]).

Littlewood's collaborative work, carried out by correspondence, covered fields in [[Diophantine approximation]] and [[Waring's problem]], in particular. In his other work, he collaborated with [[Raymond Paley]] on [[Littlewood–Paley theory]] in [[Fourier transform|Fourier theory]], and with [[Cyril Offord]] in combinatorial work on random sums, in developments that opened up fields that are still intensively studied.

He worked with [[Mary Cartwright]] on problems in [[differential equations]] arising out of early research on [[radar]]: their work foreshadowed the modern theory of dynamical systems.  [[Littlewood's 4/3 inequality]] on bilinear forms was a forerunner of the later [[Grothendieck]] [[tensor norm]] theory.

===With Hardy===
Littlewood collaborated for many years with [[G. H. Hardy]]. Together they devised the [[first Hardy–Littlewood conjecture]], a strong form of the [[twin prime conjecture]], and the [[second Hardy–Littlewood conjecture]].

He also, with Hardy, identified the work of the Indian mathematician [[Srinivasa Ramanujan]] as that of a genius, and supported him in travelling to the UK and working at Cambridge.&lt;ref&gt;Hardy (June 1920), pp494–495.&lt;/ref&gt; A self-taught mathematician, Ramanujan later became a [[Fellow of the Royal Society]], Fellow of [[Trinity College, Cambridge]], and widely recognised as on a par with other geniuses such as [[Euler]] and [[Carl Gustav Jacob Jacobi|Jacobi]].

In a 1947 lecture, the Danish mathematician [[Harald Bohr]] said, "To illustrate to what extent Hardy and Littlewood in the course of the years came to be considered as the leaders of recent English mathematical research, I may report what an excellent colleague once jokingly said: 'Nowadays, there are only three really great English mathematicians: Hardy, Littlewood, and Hardy–Littlewood.'{{thin space}}"
&lt;ref&gt;
{{cite book
|last=Bohr
|first=Harald
|authorlink=Harald Bohr
|title=Collected Mathematical Works
|volume=1
|year=1952
|publisher=Dansk Matematisk Forening
|location=Copenhagen
|oclc=3172542
|pages=xiii–xxxiv
|chapter=Looking Backward
|nopp=true
}}
&lt;/ref&gt; {{Rp|xxvii}}

There is a [[apocryphal|story]] (related in the Miscellany) that at a conference Littlewood met a German mathematician who said he was most interested to discover that Littlewood really existed, as he had always assumed that Littlewood was a name used by Hardy for lesser work which he did not want to put out under his own name; Littlewood apparently roared with laughter.{{Citation needed|date=September 2007}} There are versions of this story involving both [[Norbert Wiener]] and [[Edmund Landau]], who, it is claimed, "so doubted the existence of Littlewood that he made a special trip to Great Britain to see the man with his own eyes".&lt;ref&gt;{{Cite book|author=[[Steven G. Krantz]]|title=Mathematical Anecdotes|journal=Mathematical Intelligencer|url=https://books.google.com/books?id=hyz1HDJ6KxIC&amp;printsec=frontcover#PPA47,M1|publisher=Springer|isbn=978-0-387-98686-9|year=2001|postscript=&lt;!--None--&gt;}}&lt;/ref&gt;

==Cultural references==
John Littlewood is depicted in two films covering the life of [[Ramanujan]] - '' [[Ramanujan (film)|Ramanujan]]'' in 2014 portrayed by [[Michael Lieber]] and ''[[The Man Who Knew Infinity (film)|The Man Who Knew Infinity]]'', in 2015 portrayed by [[Toby Jones]].

==See also==
*[[Critical line theorem]]
*[[Hardy–Littlewood circle method]]
*[[Hardy–Littlewood zeta-function conjectures]]
*[[Littlewood's conjecture]]
*[[Littlewood polynomial]]
*[[Littlewood's three principles of real analysis]]
*[[Littlewood–Offord problem]]
*[[Littlewood's Tauberian theorem]]
*[[Hardy–Littlewood tauberian theorem]]
*[[Hardy–Littlewood maximal function]]&lt;ref&gt;{{cite journal|author=Phillips, Keith L.|title=The Maximal Theorems of Hardy and Littlewood|journal=Amer. Math. Monthly|volume=74|issue=6|year=1967|pages=648–660|url=http://www.maa.org/programs/maa-awards/writing-awards/the-maximal-theorems-of-hardy-and-littlewood|doi=10.2307/2314249|jstor=2314249}}&lt;/ref&gt;
*[[Littlewood subordination theorem]]

==References==
{{Reflist|40em}}

===Bibliography===
*{{Cite journal | last1 = Burkill | first1 = J. C. | doi = 10.1098/rsbm.1978.0010 | title = John Edensor Littlewood. 9 June 1885–6 September 1977 | journal = Biographical Memoirs of Fellows of the Royal Society | volume = 24 | pages = 322–326 | year = 1978 | jstor = 769763| ref=harv }}
*{{cite journal | url=https://link.springer.com/article/10.1007%2FBF03023041 | title=John E. Littlewood (1885–1977) An Informal Obituary | last1=Bateman | first1=P | last2=Diamond | first2=P | journal=[[The Mathematical Intelligencer]] | year=1978 | volume=1 | issue=1 | pages=28–33 | doi=10.1007/BF03023041| ref=harv}}

==Further reading==
*''Littlewood's Miscellany'', edited by [[B. Bollobás]], [[Cambridge University Press]]; 1986. {{isbn|0-521-33702-X}} (alternative title for [[A Mathematician's Miscellany]])
and

==External links==
{{Wikiquote|John Littlewood|John Edensor Littlewood}}
* {{MacTutor Biography|id=Littlewood}}
* {{MathGenealogy|id=10463}}
* [http://www.numbertheory.org/obituaries/LMS/littlewood/index.html Papers of Littlewood on Number Theory]
* [https://archive.org/details/mathematiciansmi033496mbp A Mathematicians Miscellany]

{{Copley Medallists 1951–2000}}

{{Authority control}}

{{DEFAULTSORT:Littlewood, John Edensor}}
[[Category:Number theorists]]
[[Category:Mathematical analysts]]
[[Category:20th-century mathematicians]]
[[Category:English mathematicians]]
[[Category:Recipients of the Copley Medal]]
[[Category:Fellows of Trinity College, Cambridge]]
[[Category:Fellows of the Royal Society]]
[[Category:Alumni of Trinity College, Cambridge]]
[[Category:People educated at St Paul's School, London]]
[[Category:People from Rochester, Kent]]
[[Category:1885 births]]
[[Category:1977 deaths]]
[[Category:Royal Medal winners]]
[[Category:Senior Wranglers]]
[[Category:De Morgan Medallists]]</text>
      <sha1>7yrm0waepvpgompg6z4ey3rw6bm6wi4</sha1>
    </revision>
  </page>
  <page>
    <title>Law of thought</title>
    <ns>0</ns>
    <id>1252308</id>
    <revision>
      <id>858804007</id>
      <parentid>856845374</parentid>
      <timestamp>2018-09-09T18:18:50Z</timestamp>
      <contributor>
        <ip>41.244.227.72</ip>
      </contributor>
      <comment>/* The three traditional laws */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="83202">{{About|axiomatic rules due to various logicians and philosophers|[[Boole]]'s book on logic|The Laws of Thought}}
The '''laws of thought''' are fundamental [[axiom]]atic rules upon which rational discourse itself is often considered to be based.  The formulation and clarification of such rules have a long tradition in the history of [[philosophy]] and [[logic]]. Generally they are taken as laws that guide and underlie everyone's thinking, [[thoughts]], expressions, discussions, etc. However, such classical ideas are often questioned or rejected in more recent developments, such as [[intuitionistic logic]], [[dialetheism]] and [[fuzzy logic]].

According to the 1999 Cambridge Dictionary of Philosophy,&lt;ref&gt;"Laws of thought".  Cambridge Dictionary of Philosophy.  [[Robert Audi]], Editor,  Cambridge: Cambridge UP. p. 489.&lt;/ref&gt; laws of thought are laws by which or in accordance with which valid thought proceeds, or that justify valid inference, or to which all valid deduction is reducible. Laws of thought are rules that apply without exception to any subject matter of thought, etc.; sometimes they are said to be the object of logic{{explain|date=July 2018}}. The term, rarely used in exactly the same sense by different authors, has long been associated with three equally ambiguous expressions: the [[law of identity]] (ID), the [[law of contradiction]] (or non-contradiction; NC), and the [[law of excluded middle]] (EM).
Sometimes, these three expressions are taken as [[propositions]] of [[formal ontology]] having the widest possible subject matter, propositions that apply to entities as such: (ID), everything is (i.e., is identical to) itself; (NC) no thing having a given quality also has the negative of that quality (e.g., no even number is non-even); (EM) every thing either has a given quality or has the negative of that quality (e.g., every number is either even or non-even). Equally common in older works is the use of these expressions for principles of [[metalogic]] about propositions: (ID) every proposition implies itself; (NC) no proposition is both true and false; (EM) every proposition is either true or false.

Beginning in the middle to late 1800s, these expressions have been used to denote propositions of [[Boolean Algebra]] about classes: (ID) every class includes itself; (NC) every class is such that its intersection ("product") with its own complement is the null class; (EM) every class is such that its union ("sum") with its own complement is the universal class. More recently, the last two of the three expressions have been used in connection with the classical propositional logic and with the so-called [[protothetic]] or quantified [[propositional logic]]; in both cases the law of non-contradiction involves the negation of the conjunction ("and") of something with its own negation, ¬(A∧¬A), and the law of excluded middle involves the disjunction ("or") of something with its own negation, A∨¬A. In the case of propositional logic, the "something" is a schematic letter serving as a place-holder, whereas in the case of protothetic logic the "something" is a genuine variable. The expressions "law of non-contradiction" and "law of excluded middle" are also used for [[semantic]] principles of [[model theory]] concerning sentences and interpretations: (NC) under no interpretation is a given sentence both true and false, (EM) under any interpretation, a given sentence is either true or false.

The expressions mentioned above all have been used in many other ways. Many other propositions have also been mentioned as laws of thought, including the [[dictum de omni et nullo]] attributed to [[Aristotle]], the substitutivity of identicals (or equals) attributed to [[Euclid]], the so-called [[identity of indiscernibles]] attributed to [[Gottfried Wilhelm Leibniz]], and other "logical truths".

The expression "laws of thought" gained added prominence through its use by [[Boole]] (1815–64) to denote theorems of his "algebra of logic"; in fact, he named his second logic book ''An Investigation of the Laws of Thought on Which are Founded the Mathematical Theories of Logic and Probabilities'' (1854). Modern logicians, in almost unanimous disagreement with Boole, take this expression to be a misnomer; none of the above propositions classed under "laws of thought" are explicitly about thought per se, a mental phenomenon studied by [[psychology]], nor do they involve explicit reference to a thinker or knower as would be the case in [[pragmatics]] or in [[epistemology]]. The distinction between psychology (as a study of mental phenomena) and logic (as a study of valid inference) is widely accepted.

==The three traditional laws==

===History===
[[Sir William Hamilton, 9th Baronet|Hamilton]] offers a history of the three traditional laws that begins with [[Plato]], proceeds through Aristotle, and ends with the [[scholastic logic|schoolmen]] of the [[Middle Ages]]; in addition he offers a fourth law (see entry below, under '''Hamilton'''):

:"'''The principles of Contradiction and Excluded Middle can be traced back to Plato''': The principles of Contradiction and of Excluded Middle can both be traced back to Plato, by whom they were enounced and frequently applied; though it was not till long after, that either of them obtained a distinctive appellation. To take the principle of Contradiction first. This law Plato frequently employs, but the most remarkable passages are found in the Phœdo, in the Sophista, and in the fourth and seventh books of the Republic. [Hamilton LECT. V. LOGIC. 62]

:'''Law of Excluded Middle''': The law of Excluded Middle between two contradictories remounts, as I have said, also to Plato, though the Second Alcibiades, the dialogue in which it is most clearly expressed, must be admitted to be spurious. It is also in the fragments of Pseudo-Archytas, to be found in [[Stobaeus|Stobæus]]. [Hamilton LECT. V. LOGIC. 65]

:Hamilton further observes that "It is explicitly and emphatically enounced by Aristotle in many passages both of his Metaphysics (l. iii. (iv.) c.7.) and of his Analytics, both Prior (l. i. c. 2) and Posterior (1. i. c. 4). In the first of these, he says: "It is impossible that there should exist any medium between contradictory opposites, but it is necessary either to affirm or to deny everything of everything." [Hamilton LECT. V. LOGIC. 65]

:"'''Law of Identity.''' [Hamilton also calls this "The principle of all logical affirmation and definition"] '''Antonius Andreas''': The law of Identity, I stated, was not explicated as a coordinate principle till a comparatively recent period. The earliest author in whom I have found this done, is [[Antonius Andreas]], a scholar of Scotus, who flourished at the end of the thirteenth and beginning of the fourteenth century. The schoolman, in the fourth book of his Commentary of Aristotle's Metaphysics – a commentary which is full of the most ingenious and original views, – not only asserts to the law of Identity a coordinate dignity with the law of Contradiction, but, against Aristotle, he maintains that the principle of Identity, and not the principle of Contradiction, is the one absolutely first. The formula in which Andreas expressed it was ''Ens est ens''. Subsequently to this author, the question concerning the relative priority of the two laws of Identity and of Contradiction became one much agitated in the schools; though there were also found some who asserted to the law of Excluded Middle this supreme rank." [From Hamilton LECT. V. LOGIC. 65-66]

=== Three traditional laws: identity, non-contradiction, excluded middle ===

The following will state the three traditional "laws" in the words of Bertrand Russell (1912):

====The law of identity====

The [[law of identity]]: 'Whatever is, is.'&lt;ref name="Russell 1912:72,1997 edition"&gt;Russell 1912:72,1997 edition.&lt;/ref&gt;

For all a: a = a.

Regarding this law, Aristotle wrote:
{{quote|First then this at least is obviously true, that the word "be" or "not be" has a definite meaning, so that not everything will be "so and not so". Again, if "man" has one meaning, let this be "two-footed animal"; by having one meaning I understand this:—if "man" means "X", then if A is a man "X" will be what "being a man" means for him. (It makes no difference even if one were to say a word has several meanings, if only they are limited in number; for to each definition there might be assigned a different word. For instance, we might say that "man" has not one meaning but several, one of which would have one definition, viz. "two-footed animal", while there might be also several other definitions if only they were limited in number; for a peculiar name might be assigned to each of the definitions. If, however, they were not limited but one were to say that the word has an infinite number of meanings, obviously reasoning would be impossible; for not to have one meaning is to have no meaning, and if words have no meaning our reasoning with one another, and indeed with ourselves, has been annihilated; for it is impossible to think of anything if we do not think of one thing; but if this is possible, one name might be assigned to this thing.)|Aristotle|[[Metaphysics (Aristotle)|Metaphysics]], Book IV, Part 4 (translated by W.D. Ross)&lt;ref name="Metaphysics"&gt;http://www.classicallibrary.org/aristotle/metaphysics/book04.htm&lt;/ref&gt;}}

More than two millennia later, [[George Boole]] alluded to the very same principle as did Aristotle when Boole made the following observation with respect to the nature of [[language]] and those principles that must inhere naturally within them: {{quote|There exist, indeed, certain general principles founded in the very nature of language, by which the use of symbols, which are but the elements of scientific language, is determined. To a certain extent these elements are arbitrary. Their interpretation is purely conventional: we are permitted to employ them in whatever sense we please. But this permission is limited by two indispensable conditions, first, that from the sense once conventionally established we never, in the same process of reasoning, depart; secondly, that the laws by which the process is conducted be founded exclusively upon the above fixed sense or meaning of the symbols employed.|George Boole|[[An Investigation of the Laws of Thought]]}}

====The law of non-contradiction====

The [[law of non-contradiction]] (alternately the 'law of contradiction'&lt;ref name="Russell 1912:72, 1997 edition"&gt;Russell 1912:72, 1997 edition&lt;/ref&gt;): 'Nothing can both be and not be.'&lt;ref name="Russell 1912:72,1997 edition"/&gt;

In other words: "two or more contradictory statements cannot both be true in the same sense at the same time": [[Negation|¬]](A[[Logical conjunction|∧]]¬A).

In the words of Aristotle, that "one cannot say of something that it is and that it is not in the same respect and at the same time". As an illustration of this law, he wrote:
{{quote|It is impossible, then, that "being a man" should mean precisely not being a man, if "man" not only signifies something about one subject but also has one significance ... And it will not be possible to be and not to be the same thing, except in virtue of an ambiguity, just as if one whom we call "man", and others were to call "not-man"; but the point in question is not this, whether the same thing can at the same time be and not be a man in name, but whether it can be in fact.|Aristotle|Metaphysics, Book IV, Part 4 (translated by W.D. Ross)&lt;ref name="Metaphysics" /&gt;}}

====The law of excluded middle====

The law of excluded middle: 'Everything must either be or not be."&lt;ref name="Russell 1912:72,1997 edition"/&gt;

In accordance with the [[law of excluded middle]] or excluded third, for every proposition, either its positive or negative form is true: A[[Logical disjunction|∨]]¬A.

Regarding the [[law of excluded middle]], Aristotle wrote:
{{quote|But on the other hand there cannot be an intermediate between contradictories, but of one subject we must either affirm or deny any one predicate. This is clear, in the first place, if we define what the true and the false are. To say of what is that it is not, or of what is not that it is, is false, while to say of what is that it is, and of what is not that it is not, is true; so that he who says of anything that it is, or that it is not, will say either what is true or what is false|Aristotle|Metaphysics, Book IV, Part 7 (translated by W.D. Ross)&lt;ref name="Metaphysics" /&gt;}}

===Rationale===
As the quotations from Hamilton above indicate, in particular the "law of identity" entry, the rationale for and expression of the "laws of thought" have been fertile ground for philosophic debate since Plato. Today the debate—about how we "come to know" the world of things and our thoughts—continues; for examples of rationales see the entries, below.
&lt;!--That everything be "the same with itself and different from another" (law of identity) is one of the "self-evident logical principles"&lt;ref&gt;"These three laws are samples of self-evident logical principles, but are not really more fundamental or more self-evident than various other similar principles: for instance, the one we considered just now, which states that what follows from a true premiss is true." ([[Bertrand Russell]], ''[[The Problems of Philosophy]]'', Chapter VII)&lt;/ref&gt; upon which all symbolic communication systems (languages) are founded, for it governs the use of those symbols (names, words, pictograms, etc.) which denote the various individual concepts within a language, so as to eliminate ambiguity in the conveyance of those concepts between the users of the language. Such a principle (law) is necessary because symbolic designators have no inherent meaning of their own, but derive their meaning from the language users themselves, who associate each symbol with an individual concept in a manner that has been conventionally prescribed within their linguistic group. The degree to which this law must be obeyed depends upon the kind of language that one is utilizing. In a [[natural language]] there is considerable tolerance for violations since there are other means—such as the context in which the symbol is used—by which one can determine which of a number of different concepts one is intended to call to mind by the use of a given symbol. However, in the language of [[mathematics]] or [[formal logic]] there is no such tolerance. If, for example, the symbol "+" were allowed to denote both the function of addition and some other mathematical function, then we would be unable to evaluate the truth value of a proposition such as "2+2=4", since the truth of such a proposition would be contingent upon which of the possible functions the symbol "+" was intended to denote. The same is true of symbols such as "2" and "4". If these symbols did not denote conventionally prescribed quantities, then one could not attribute proper meaning to them, and the proposition would be rendered unintelligible.--&gt;
&lt;!-- Furthermore, we cannot think [[Conceptual model|conceptually]] without making use of some form of language (symbolic communication), for thinking conceptually entails the manipulation and amalgamation of simpler [[concept]]s in order to form more complex concepts.{{Citation needed|date=August 2013}} Therefore we must have a means of distinguishing these different concepts, namely [[symbol]]s or [[sign]]s. It follows then that the first principle of language (law of identity) is also rightfully called the first principle of thought, and by extension, the first principle of reason (rational thought).{{Citation needed|date=August 2013}}{{original research?|date=January 2014}}--&gt;to originally research?|data=february 2019}}--&gt;

==Plato==
In one of Plato's [[Socratic dialogue]]s, [[Socrates]] described three [[principle]]s derived from [[introspection]]: {{Quotation|First, that nothing can become greater or less, either in number or magnitude, while remaining equal to itself ... Secondly, that without addition or subtraction there is no increase or diminution of anything, but only equality ... Thirdly, that what was not before cannot be afterwards, without becoming and having become.|[[Plato]]|[[Theaetetus (dialogue)|Theaetetus]], 155&lt;ref&gt;{{cite web |url= http://ebooks.adelaide.edu.au/p/plato/p71th/theaetetus.html|title= Theaetetus, by Plato|author=&lt;!--Staff writer(s); no by-line.--&gt; |date= November 10, 2012|publisher= The University of Adelaide Library|accessdate=14 January 2014}}&lt;/ref&gt;}}

==Indian logic==
The [[law of non-contradiction]] is found in ancient [[Indian logic]] as a meta-rule in the ''[[Kalpa (Vedanga)|Shrauta Sutras]]'', the grammar of [[Pāṇini]],&lt;ref&gt;{{citation|author=[[Frits Staal]]|title=Universals: Studies in Indian Logic and Linguistics|publisher=[[Chicago]]|year=1988|pages=109–28}} ([[cf.]] {{citation|title=Seeing Things Hidden|first=Malcolm|last=Bull|publisher=Verso|year=1999|isbn=1-85984-263-1|page=53}})&lt;/ref&gt; and the ''[[Brahma Sutras]]'' attributed to [[Vyasa]]. It was later elaborated on by medieval commentators such as [[Madhvacharya]].&lt;ref&gt;{{citation|title=A History of Indian Philosophy|first=Surendranath|last=Dasgupta|publisher=[[Motilal Banarsidass]]|year=1991|isbn=81-208-0415-5|page=110}}&lt;/ref&gt;

==Locke==
[[John Locke]] claimed that the principles of identity and contradiction (i.e. the law of identity and the law of non-contradiction) were general ideas and only occurred to people after considerable abstract, philosophical thought. He characterized the principle of identity as "Whatsoever is, is." He stated the principle of contradiction as "It is impossible for the same thing to be and not to be." To Locke, these were not innate or ''[[A priori and a posteriori|a priori]]'' principles.&lt;ref&gt;{{cite web |url= http://www.marxists.org/reference/subject/philosophy/works/en/locke.htm|title= An Essay concerning Human Understanding|author=&lt;!--Staff writer(s); no by-line.--&gt; |accessdate=January 14, 2014}}&lt;/ref&gt;

==Leibniz==
[[Gottfried Leibniz]] formulated two additional principles, either or both of which may sometimes be counted as a law of thought:

:* [[principle of sufficient reason]]
:* [[identity of indiscernibles]]

In Leibniz's thought, as well as generally in the approach of [[rationalism]], the latter two principles are regarded as clear and incontestable [[axioms]].  They were widely recognized in [[Europe]]an thought of the 17th, 18th, and 19th centuries, although they were subject to greater debate in the 19th century. As turned out to be the case with the [[law of continuity]], these two laws involve matters which, in contemporary terms, are subject to much debate and analysis (respectively on [[determinism]] and [[extensionality]]{{clarify|date=January 2014}}). Leibniz's principles were particularly influential in German thought. In France, the ''[[Port-Royal Logic]]'' was less swayed by them. [[Hegel]] quarrelled with the [[identity of indiscernibles]] in his ''[[Science of Logic]]'' (1812–1816).

==Schopenhauer==

===Four laws===
"The primary laws of thought, or the conditions of the thinkable, are four: &amp;ndash; 1. The law of identity [A is A]. 2. The law of contradiction. 3. The law of exclusion; or excluded middle. 4. The law of sufficient reason." (Thomas Hughes, ''The Ideal Theory of Berkeley and the Real World'', Part II, Section XV, Footnote, p. [https://archive.org/stream/idealtheoryberk01hughgoog#page/n48/mode/2up 38])

[[Arthur Schopenhauer]] discussed the laws of thought and tried to demonstrate that they are the basis of reason. He listed them in the following way in his ''[[On the Fourfold Root of the Principle of Sufficient Reason]]'', §33:

#A subject is equal to the sum of its predicates, or a = a.
#No predicate can be simultaneously attributed and denied to a subject, or a ≠ ~a.
#Of every two contradictorily opposite predicates one must belong to every subject.
#Truth is the reference of a judgment to something outside it as its sufficient reason or ground.
Also:
{{Quotation|The laws of thought can be ''most intelligibly'' expressed thus:
#Everything that is, exists.
#Nothing can simultaneously be and not be.
#Each and every thing either is or is not.
#Of everything that is, it can be found why it is.
There would then have to be added only the fact that once for all in logic the question is about ''what is thought'' and hence about concepts and not about real things.|Schopenhauer| Manuscript Remains'', Vol. 4, "Pandectae II", §163'}}

To show that they are the foundation of [[reason]], he gave the following explanation:
{{Quotation|Through a reflection, which I might call a self-examination of the faculty of reason, we know that these judgments are the expression of the conditions of all thought and therefore have these as their ground. Thus by making vain attempts to think in opposition to these laws, the faculty of reason recognizes them as the conditions of the possibility of all thought. We then find that it is just as impossible to think in opposition to them as it is to move our limbs in a direction contrary to their joints. If the subject could know itself, we should know those laws ''immediately'', and not first through experiments on objects, that is, representations (mental images).|Schopenhauer| ''[[s:On the Fourfold Root of the Principle of Sufficient Reason#§ 33. Metalogical Truth.|''On the Fourfold Root of the Principle of Sufficient Reason'', §33]]'}}

Schopenhauer's four laws can be schematically presented in the following manner:
#A is A.
#A is not not-A.
#X is either A or not-A.
#If A then B (A implies B).

===Two laws===

Later, in 1844, Schopenhauer claimed that the four laws of thought could be reduced to two. In the ninth chapter of the second volume of ''[[The World as Will and Representation]]'', he wrote:
{{Quotation|It seems to me that the doctrine of the laws of thought could be simplified if we were to set up only two, the law of excluded middle and that of sufficient reason. The former thus: "Every predicate can be either confirmed or denied of every subject." Here it is already contained in the "either, or" that both cannot occur simultaneously, and consequently just what is expressed by the laws of identity and contradiction. Thus these would be added as corollaries of that principle which really says that every two concept-spheres must be thought either as united or as separated, but never as both at once; and therefore, even although words are joined together which express the latter, these words assert a process of thought which cannot be carried out. The consciousness of this infeasibility is the feeling of contradiction. The second law of thought, the principle of sufficient reason, would affirm that the above attributing or refuting must be determined by something different from the judgment itself, which may be a (pure or empirical) perception, or merely another judgment. This other and different thing is then called the ground or reason of the judgment. So far as a judgement satisfies the first law of thought, it is thinkable; so far as it satisfies the second, it is true, or at least in the case in which the ground of a judgement is only another judgement it is logically or formally true.&lt;ref&gt;{{cite web |url= http://www.gutenberg.org/files/40097/40097-h/40097-h.html|title= The Project Gutenberg EBook of The World As Will And Idea (Vol. 2 of 3) by Arthur Schopenhauer|author=&lt;!--Staff writer(s); no by-line.--&gt; |date= June 27, 2012|publisher= Project Gutenberg|accessdate=January 14, 2014}}&lt;/ref&gt;}}

==Boole (1854): From his "laws of the mind" Boole derives Aristotle's "Law of contradiction" ==
The title of [[George Boole]]'s 1854 treatise on logic, ''An Investigation on the Laws of Thought'', indicates an alternate path. The laws are now incorporated into an algebraic representation of his "laws of the mind", honed over the years into modern [[Boolean algebra]].

=== Rationale: How the "laws of the mind" are to be distinguished ===
Boole begins his chapter I "Nature and design of this Work" with a discussion of what characteristic distinguishes, generally, "laws of the mind" from "laws of nature":
: "The general laws of Nature are not, for the most part, immediate objects of perception. They are either inductive inferences from a large body of facts, the common truth in which they express, or, in their origin at least, physical hypotheses of a causal nature. . . . They are in all cases, and in the strictest sense of the term, probable conclusions, approaching, indeed, ever and ever nearer to certainty, as they receive more and more of the confirmation of experience. ...”

Contrasted with this are what he calls "laws of the mind": Boole asserts these are known in their first instance, without need of repetition: 
:“On the other hand, the knowledge of the laws of the mind does not require as its basis any extensive collection of observations. The general truth is seen in the particular instance, and it is not confirmed by the repetition of instances. ... we not only see in the particular example the general truth, but we see it also as a certain truth -- a truth, our confidence in which will not continue to increase with increasing experience of its practical verification.” (Boole 1854:4)

=== Boole's signs and their laws ===
Boole begins with the notion of "signs" representing "classes", "operations" and "identity":
:"All the signs of Language, as an instrument of reasoning may be conducted by a system of signs composed of the following elements
::"1st Literal symbols as x, y, etc representing things as subjects of our conceptions,
::"2nd Signs of operation, as +, −, x standing for those operations of the mind by which conceptions of things are combined or resolved so as to form new conceptions involving the same elements,
::"3rd The sign of identity, =.
:And these symbols of Logic are in their use subject to definite laws, partly agreeing with and partly differing from the laws of the corresponding symbols in the science of Algebra. (Boole 1854:27)

Boole then clarifies what a "literal symbol" e.g. x, y, z,... represents—a name applied to a collection of instances into "classes". For example, "bird" represents the entire class of feathered winged warm-blooded creatures. For his purposes he extends the notion of class to represent membership of "one", or "nothing", or "the universe" i.e. totality of all individuals: 
:"Let us then agree to represent the class of individuals to which a particular name or description is applicable, by a single letter, as z. ... By a class is usually meant a collection of individuals, to each of which a particular name or description may be applied; but in this work the meaning of the term will be extended so as to include the case in which but a single individual exists, answering to the required name or description, as well as the cases denoted by the terms "nothing" and "universe," which as "classes" should be understood to comprise respectively 'no beings,' 'all beings.'" (Boole 1854:28)

He then defines what the string of symbols e.g. xy means [modern logical &amp;, conjunction]:
:"Let it further be agreed, that by the combination xy shall be represented that class of things to which the names or descriptions represented by x and y are simultaneously, applicable. Thus, if x alone stands for "white things," and y for "sheep," let xy stand for 'white Sheep;'" (Boole 1854:28)

Given these definitions he now lists his laws with their justification plus examples (derived from Boole):
* (1) xy = yx [commutative law]
:: "x represents 'estuaries,' and y 'rivers,' the expressions xy and yx will indifferently represent" 'rivers that are estuaries,' or 'estuaries that are rivers,'"
* (2) xx = x, alternately x&lt;sup&gt;2&lt;/sup&gt; = x [Absolute identity of meaning, Boole's "fundamental law of thought" cf page 49]
:: "Thus 'good, good" men, is equivalent to 'good' men".
'''Logical OR''': Boole defines the "collecting of parts into a whole or separate a whole into its parts" (Boole 1854:32). Here the connective "and" is used disjunctively, as is "or"; he presents a commutative law (3) and a distributive law (4) for the notion of "collecting". The notion of ''separating'' a part from the whole he symbolizes with the "-" operation; he defines a commutative (5) and distributive law (6) for this notion:
* (3) y + x = x + y [commutative law]
:: "Thus the expression 'men and women' is . . . equivalent with the expression" women and men. Let x represent 'men,' y, 'women' and let + stand for 'and' and 'or' . . ." 
* (4) z(x + y) = zx + zy [distributive law]
:: z = European, (x = "men, y = women): European men and women = European men and European women
* (5) x - y = -y + x [commutation law: separating a part from the whole] 
:: "All men (x) except Asiatics (y)" is represented by x - y. "All states (x) except monarchical states (y)" is represented by x - y
* (6) z(x - y) = zx - zy [distributive law]
Lastly is a notion of "identity" symbolized by "=". This allows for two axioms: (axiom 1): equals added to equals results in equals, (axiom 2): equals subtracted from equals results in equals.
* (7) Identity ("is", "are") e.g. x = y + z, "stars" = "suns" and "the planets"

'''Nothing "0" and Universe "1"''': He observes that the only two numbers that satisfy xx = x are 0 and 1. He then observes that 0 represents "Nothing" while "1" represents the "Universe" (of discourse).

'''The logical NOT''': Boole defines the contrary (logical NOT) as follows (his Proposition III): 
:"If x represent any class of objects, then will 1 - x represent the contrary or supplementary class of objects, i.e. the class including all objects which are not comprehended in the class x" (Boole 1854:48)
::If x = "men" then "1 - x" represents the "universe" less "men", i.e.  "not-men".

'''The notion of a particular as opposed to a universal''': To represent the notion of "some men", Boole writes the small letter "v" before the predicate-symbol "vx" some men.

'''Exclusive- and inclusive-OR''': Boole does not use these modern names, but he defines these as follows x(1-y) + y(1-x) and x + y(1-x), respectively; these agree with the formulas derived by means of the modern Boolean algebra.&lt;ref&gt;cf Boole 1842:55-57. The modern definition of logical OR(x, y) in terms of logical AND &amp;, and logical NOT ~ is: ~(~x &amp; ~y). In Boolean algebra this is represented by: 1-((1-x)*(1-y)) = 1 - (1 - 1*x - y*1 + x*y) = x + y - x*y = x + y*(1-x), which is Boole's expression. The exclusive-OR can be checked in a similar manner.&lt;/ref&gt;

===Boole derives the law of contradiction ===
Armed with his "system" he derives the "principle of [non]contradiction" starting with his law of identity: x&lt;sup&gt;2&lt;/sup&gt; = x. He subtracts x from both sides (his axiom 2), yielding x&lt;sup&gt;2&lt;/sup&gt; - x = 0. He then factors out the x: x(x - 1) = 0. For example, if x = "men" then 1 - x represents NOT-men. So we have an example of the "Law of Contradiction":
:"Hence: x(1 - x) will represent the class whose members are at once "men," and" not men," and the equation [x(1 - x)=0] thus express the principle, that a class whose members are at the same time men and not men does not exist. In other words, that it is impossible for the same individual to be at the same time a man and not a man. . . . this is identically that "principle of contradiction" which Aristotle has described as the fundamental axiom of all philosophy. . . . what has been commonly regarded as the fundamental axiom of metaphysics is but the consequence of a law of thought, mathematical in its form." (with more explanation about this "dichotomy" comes about cf Boole 1854:49ff)

=== Boole defines the notion "domain (universe) of discourse"===
This notion is found throughout Boole's "Laws of Thought" e.g. 1854:28, where the symbol "1" (the integer 1) is used to represent "Universe" and "0" to represent "Nothing", and in far more detail later (pages 42ff):
:" Now, whatever may be the extent of the field within which all the objects of our discourse are found, that field may properly be termed the universe of discourse. . . . Furthermore, this universe of discourse is in the strictest sense the ultimate subject of the discourse."

In his chapter "The Predicate Calculus" Kleene observes that the specification of the "domain" of discourse is "not a trivial assumption, since it is not always clearly satisfied in ordinary discourse . . . in mathematics likewise, logic can become pretty slippery when no D [domain] has been specified explicitly or implicitly, or the specification of a D [domain] is too vague'' (Kleene 1967:84).

==[[Sir William Hamilton, 9th Baronet|Hamilton]] (1837–38 lectures on Logic, published 1860): a 4th "Law of Reason and Consequent"==
As noted above, Hamilton specifies ''four'' laws—the three traditional plus the fourth "Law of Reason and Consequent"—as follows:
:"XIII. The Fundamental Laws of Thought, or the conditions of the thinkable, as commonly received, are four: -- 1. The Law of Identity; 2. The Law of Contradiction; 3. The Law of Exclusion or of Excluded Middle; and, 4. The Law of Reason and Consequent, or of [[Principle of Sufficient Reason|Sufficient Reason]]."&lt;ref&gt;[[Sir William Hamilton, 9th Baronet|William Hamilton]], ([[Henry L. Mansel]] and [[John Veitch (poet)|John Veitch]], ed.), 1860 ''Lectures on Metaphysics and Logic, in Two Volumes. Vol. II. Logic'', Boston: Gould and Lincoln. Hamilton died in 1856, so this is an effort of his editors Mansel and Veitch. Most of the footnotes are additions and emendations by Mansel and Veitch -- see the preface for background information.&lt;/ref&gt;

===Rationale: "Logic is the science of the Laws of Thought as Thought"===
Hamilton opines that thought comes in two forms: "necessary" and "contingent" (Hamilton 1860:17). With regards the "necessary" form he defines its study as "logic": “Logic is the science of the necessary forms of thought” (Hamilton 1860:17). To define "necessary" he asserts that it implies the following four “qualities”:&lt;ref&gt;Lecture II LOGIC-I. ITS DEFINITION -HISTORICAL NOTICES OF OPINIONS REGARDING ITS OBJECT AND DOMAIN-II. ITS UTILITY Hamilton 1860:17-18&lt;/ref&gt;
:(1) “determined or necessitated by the nature of the thinking subject itself . . . it is subjectively, not objectively, determined;
:(2) “original and not acquired;
:(3) “universal; that is, it cannot be that it necessitates on some occasions, and does not necessitate on others.
:(4) "it must be a law; for a law is that which applies to all cases without exception, and from which a deviation is ever, and everywhere, impossible, or, at least, unallowed.  . . . This last condition, likewise, enables us to give the most explicit enunciation of the object-matter of Logic, in saying that Logic is the science of the Laws of Thought as Thought, or the science of the Formal Laws of Thought, or the science of the Laws of the Form of Thought; for all these are merely various expressions of the same thing."

===Hamilton's 4th law: "Infer nothing without ground or reason"===
Here's Hamilton's fourth law from his LECT. V. LOGIC. 60-61:

:"I now go on to the fourth law.

:"'''Par. XVII. Law of Sufficient Reason, or of Reason and Consequent''':

:"XVII. The thinking of an object, as actually characterized by positive or by negative attributes, is not left to the caprice of Understanding – the faculty of thought; but that faculty must be necessitated to this or that determinate act of thinking by a knowledge of something different from, and independent of; the process of thinking itself. This condition of our understanding is expressed by the law, as it is called, of Sufficient Reason ('''principium Rationis Sufficientis'''); but it is more properly denominated the law of Reason and Consequent ('''principium Rationis et Consecutionis'''). That knowledge by which the mind is necessitated to affirm or posit something else, is called the ''logical reason ground,'' or ''antecedent''; that something else which the mind is necessitated to affirm or posit, is called the ''logical consequent''; and the relation between the reason and consequent, is called the ''logical connection or consequence''. This law is expressed in the formula - Infer nothing without a ground or reason.&lt;sup&gt;1&lt;/sup&gt;

:'''Relations between Reason and Consequent''': The relations between Reason and Consequent, when comprehended in a pure thought, are the following:
:1. When a reason is explicitly or implicitly given, then there must ¶ exist a consequent; and, ''vice versa'', when a consequent is given, there must also exist a reason.

::&lt;sup&gt;1&lt;/sup&gt; See Schulze, ''Logik'', §19, and Krug, ''Logik'', §20, - ED.

:2. Where there is no reason there can be no consequent; and, ''vice versa'', where there is no consequent (either implicitly or explicitly) there can be no reason. That is, the concepts of reason and of consequent, as reciprocally relative, involve and suppose each other.

:'''The logical significance of this law''': The logical significance of the law of Reason and Consequent lies in this, - That in virtue of it, thought is constituted into a series of acts all indissolubly connected; each necessarily inferring the other. Thus it is that the distinction and opposition of possible, actual and necessary matter, which has been introduced into Logic, is a doctrine wholly extraneous to this science.

==Welton==
In the 19th century, the Aristotelian laws of thoughts, as well as sometimes the Leibnizian laws of thought, were standard material in logic textbooks, and J. Welton described them in this way:
{{Quotation|The Laws of Thought, Regulative Principles of Thought, or Postulates of Knowledge, are those fundamental, necessary, formal and a priori mental laws in agreement with which all valid thought must be carried on. They are a priori, that is, they result directly from the processes of reason exercised upon the facts of the real world. They are formal; for as the necessary laws of all thinking, they cannot, at the same time, ascertain the definite properties of any particular class of things, for it is optional whether we think of that class of things or not. They are necessary, for no one ever does, or can, conceive them reversed, or really violate them, because no one ever accepts a contradiction which presents itself to his mind as such.|Welton, ''A Manual of Logic'', 1891, Vol. I, p. 30.}}

==Russell (1903–1927)==
The sequel to [[Bertrand Russell]]'s 1903 "The Principles of Mathematics" became the three volume work named [[Principia Mathematica]] (hereafter PM), written jointly with [[Alfred North Whitehead]]. Immediately after he and Whitehead published PM he wrote his 1912 "The Problems of Philosophy". His "Problems" reflects "the central ideas of Russell's logic".&lt;ref&gt;Commentary by John Perry in Russell 1912, 1997 edition page ix&lt;/ref&gt;

===The Principles of Mathematics (1903)===
In his 1903 "Principles" Russell defines Symbolic or Formal Logic (he uses the terms synonymously) as "the study of the various general types of deduction" (Russell 1903:11). He asserts that "Symbolic Logic is essentially concerned with inference in general" (Russell 1903:12) and with a footnote indicates that he does not distinguish between inference and [[deductive reasoning|deduction]]; moreover he considers [[inductive reasoning|induction]] "to be either disguised deduction or a mere method of making plausible guesses" (Russell 1903:11). This opinion will change by 1912, when he deems his "principle of induction" to be par with the various "logical principles" that include the "Laws of Thought".

In his Part I "The Indefinables of Mathematics" Chapter II "Symbolic Logic" Part A "The Propositional Calculus" Russell reduces deduction ("propositional calculus") to 2 "indefinables" and 10 axioms:
:"17. We require, then, in the propositional calculus, no indefinable except the two kinds of implication [simple aka  "material"&lt;ref&gt;The "simple" type of implication, aka material implication, is the logical connective commonly symbolized by → or ⊃, e.g. p ⊃ q. As a connective it yields the truth value of "falsity" only when the truth value of statement p is "truth" when the truth value of statement q is "falsity"; in 1903 Russell is claiming that "A definition of implication is quite impossible" (Russell 1903:14). He will overcome this problem in PM with the simple definition of (p ⊃ q) =&lt;sub&gt;def&lt;/sub&gt; (NOT-p OR q).&lt;/ref&gt; and "formal"]-- remembering, however, that formal implication is a complex notion, whose analysis remains to be undertaken. As regards our two indefinables, we require certain indemonstrable propositions, which hitherto I have not succeeded in reducing to less ten (Russell 1903:15).

From these he ''claims'' to be able to ''derive'' the '''law of excluded middle''' and the '''law of contradiction''' but does not exhibit his derivations (Russell 1903:17). Subsequently, he and Whitehead honed these "primitive principles" and axioms into the nine found in PM, and here Russell actually ''exhibits'' these two derivations at ❋1.71 and ❋3.24, respectively.

===''The Problems of Philosophy'' (1912)===
By 1912 Russell in his "Problems" pays close attention to "induction" (inductive reasoning) as well as "deduction" (inference), both of which represent just two ''examples'' of "self-evident logical principles" that include the "Laws of Thought."&lt;ref name="Russell 1912:72, 1997 edition"/&gt;

'''Induction principle''': Russell devotes a chapter to his "induction principle". He describes it as coming in two parts: firstly, as a repeated collection of evidence (with no failures of association known) and therefore increasing probability that whenever A happens B follows; secondly, in a fresh instance when indeed A happens, B will indeed follow: i.e. "a sufficient number of cases of association will make the probability of a fresh association nearly a certainty, and will make it approach certainty without limit."&lt;ref&gt;Russell 1912:66, 1997 edition&lt;/ref&gt;

He then collects all the cases (instances) of the induction principle (e.g. case 1: A&lt;sub&gt;1&lt;/sub&gt; = "the rising sun", B&lt;sub&gt;1&lt;/sub&gt; = "the eastern sky"; case 2: A&lt;sub&gt;2&lt;/sub&gt; = "the setting sun", B&lt;sub&gt;2&lt;/sub&gt; = "the western sky"; case 3: etc.) into a "general" law of induction which he expresses as follows:
:"(a) The greater the number of cases in which a thing of the sort A has been found associated with a thing of the sort B, the more probable it is (if cases of failure of association are known) that A is always associated with B;
:"(b) Under the same circumstances, a sufficient number of cases of the association of A with B will make it nearly certain that A is always associated with B, and will make this general law approach certainty without limit."&lt;ref&gt;Russell 1912:67, 1997 edition&lt;/ref&gt;

He makes an argument that this induction principle can neither be disproved or proved by experience,&lt;ref&gt;name="Russell 1912:70, 1997&lt;/ref&gt; the failure of disproof occurring because the law deals with ''probability'' of success rather than certainty; the failure of proof occurring because of unexamined cases that are yet to be experienced, i.e. they will occur (or not) in the future. "Thus we must either accept the inductive principle on the ground of its intrinsic evidence, or forgo all justification of our expectations about the future".&lt;ref&gt;name="Russell 1912:69, 1997&lt;/ref&gt;

In his next chapter ("On Our Knowledge of General Principles") Russell offers other principles that have this similar property: "which cannot be proved or disproved by experience, but are used in arguments which start from what is experienced." He asserts that these "have even greater evidence than the principle of induction . . . the knowledge of them has the same degree of certainty as the knowledge of the existence of sense-data. They constitute the means of drawing inferences from what is given in sensation".&lt;ref name="Russell 1912:70, 1997 edition"&gt;Russell 1912:70, 1997 edition&lt;/ref&gt;

'''Inference principle''': Russell then offers an example that he calls a "logical" principle. Twice previously he has asserted this principle, first as the 4th axiom in his 1903&lt;ref&gt;(4) A true hypothesis in an implication may be dropped, and the consequent asserted. This is a principle incapable of formal symbolic statement . . ." (Russell 1903:16)&lt;/ref&gt; and then as his first "primitive proposition" of PM: "❋1.1 Anything implied by a true elementary proposition is true".&lt;ref&gt;Principia Mathematica 1962 edition:94&lt;/ref&gt; Now he repeats it in his 1912 in a refined form: "Thus our principle states that if this implies that, and this is true, then that is true. In other words, 'anything implied by a true proposition is true', or 'whatever follows from a true proposition is true'.&lt;ref&gt;Russell 1912:71, 1997 edition&lt;/ref&gt; This principle he places great stress upon, stating that "this principle is really involved -- at least, concrete instances of it are involved -- in all demonstrations".&lt;ref name="Russell 1912:72, 1997 edition"/&gt;

He does not call his inference principle ''[[modus ponens]]'', but his formal, symbolic expression of it in PM (2nd edition 1927) is that of ''modus ponens''; modern logic calls this a "rule" as opposed to a "law".&lt;ref&gt;For example, [[Alfred Tarski]] (Tarski 1946:47) distinguishes ''modus ponens'' as one of three "''rules'' of inference" or "''rules'' of proof", and he asserts that these "must not be mistaken for logical laws". The two other such "rules" are that of "definition" and "substitution"; see the entry under '''Tarski'''.&lt;/ref&gt; In the quotation that follows, the symbol "⊦" is the "assertion-sign" (cf PM:92); “⊦" means "it is true that", therefore “⊦p” where "p" is "the sun is rising" means "it is true that the sun is rising", alternately "The statement 'The sun is rising' is true". The "implication" symbol "⊃" is commonly read "if p then q", or "p implies q" (cf PM:7). Embedded in this notion of "implication" are two "primitive ideas", "the Contradictory Function" (symbolized by NOT, "~") and "the Logical Sum or Disjunction" (symbolized by OR, "⋁"); these appear as "primitive propositions" ❋1.7 and ❋1.71 in PM (PM:97). With these two "primitive propositions" Russell defines "p ⊃ q" to have the formal logical equivalence "NOT-p OR q" symbolized by "~p ⋁ q":
:"''Inference''. The process of inference is as follows: a proposition "p" is asserted, and a proposition "p implies q" is asserted, and then as a sequel the proposition "q" is asserted. The trust in inference is the belief that if the two former assertions are not in error, the final assertion is not in error. Accordingly, whenever, in symbols, where p and q have of course special determination
::" “⊦p” and “⊦(p ⊃ q)”
:" have occurred, then “⊦q” will occur if it is desired to put it on record. The process of the inference cannot be reduced to symbols. Its sole record is the occurrence of “⊦q”. . . . An inference is the dropping of a true premiss; it is the dissolution of an implication".&lt;ref&gt;Principia Mathematica 2nd edition (1927), pages 8 and 9.&lt;/ref&gt;

In other words, in a long "string" of inferences, after each inference we can '''detach''' the "consequent" “⊦q” from the symbol string “⊦p, ⊦(p⊃q)” and not carry these symbols forward in an ever-lengthening string of symbols. 
   
'''The three traditional "laws" (principles) of thought''': Russell goes on to assert other principles, of which the above logical principle is "only one". He asserts that "some of these must be granted before any argument or proof becomes possible. When some of them have been granted, others can be proved." Of these various "laws" he asserts that "for no very good reason, three of these principles have been singled out by tradition under the name of 'Laws of Thought'.&lt;ref name="ReferenceA"&gt;Russell 1912:72, 1997 edition.&lt;/ref&gt; And these he lists as follows:
   
: "(1) ''The law of identity'': 'Whatever is, is.'
   
: (2) ''The law of contradiction'': 'Nothing can both be and not be.'
   
: (3) ''The law of excluded middle'': 'Everything must either be or not be.'"&lt;ref name="ReferenceA"/&gt;

'''Rationale''': Russell opines that "the name 'laws of thought' is ... misleading, for what is important is not the fact that we think in accordance with these laws, but the fact that things behave in accordance with them; in other words, the fact that when we think in accordance with them we think ''truly''."&lt;ref&gt;Russell 1997:73 reprint of Russell 1912&lt;/ref&gt; But he rates this a "large question" and expands it in two following chapters where he begins with an investigation of the notion of "a priori" (innate, built-in) knowledge, and ultimately arrives at his acceptance of the Platonic "world of universals". In his investigation he comes back now and then to the three traditional laws of thought, singling out the law of contradiction in particular: "The conclusion that the law of contradiction is a law of ''thought'' is nevertheless erroneous . . . [rather], the law of contradiction is about things, and not merely about thoughts . . . a fact concerning the things in the world."&lt;ref&gt;Russell 1997:88-89 reprint of Russell 1912&lt;/ref&gt;

His argument begins with the statement that the three traditional laws of thought are "samples of self-evident principles". For Russell the matter of "self-evident"&lt;ref&gt;Russell asserts they are "self-evident" a couple times, at Russell 1912, 1967:72&lt;/ref&gt; merely introduces the larger question of how we derive our knowledge of the world. He cites the "historic controversy . . . between the two schools called respectively 'empiricists' [ [[John Locke|Locke]], [[George Berkeley|Berkeley]], and [[David Hume|Hume]] ] and 'rationalists' [ [[Rene Descartes|Descartes]] and [[Gottfried Wilhelm Leibniz|Leibniz]]]" (these philosophers are his examples).&lt;ref name="Russell 1912, 1967:73"&gt;Russell 1912, 1967:73&lt;/ref&gt; Russell asserts that the rationalists "maintained that, in addition to what we know by experience, there are certain 'innate ideas' and 'innate principles', which we know independently of experience";&lt;ref name="Russell 1912, 1967:73"/&gt; to eliminate the possibility of babies having innate knowledge of the "laws of thought", Russell renames this sort of knowledge ''a priori''. And while Russell agrees with the empiricists that "Nothing can be known to ''exist'' except by the help of experience,",&lt;ref&gt;"That is to say, if we wish to prove that something of which we have no direct experience exists, we must have among our premises the existence of one or more things of which we have direct experience"; Russell 1912, 1967:75&lt;/ref&gt; he also agrees with the rationalists that some knowledge is ''a priori'', specifically "the propositions of logic and pure mathematics, as well as the fundamental propositions of ethics".&lt;ref&gt;Russell 1912, 1967:80-81&lt;/ref&gt;

This question of how such ''a priori'' knowledge can exist directs Russell to an investigation into the philosophy of [[Immanuel Kant]], which after careful consideration he rejects as follows:
:". . . there is one main objection which seems fatal to any attempt to deal with the problem of ''a priori'' knowledge by his method. The thing to be accounted for is our certainty that the facts must always conform to logic and arithmetic. . . . Thus Kant's solution unduly limits the scope of ''a priori'' propositions, in addition to failing in the attempt at explaining their certainty''".&lt;ref&gt;Russell 1912, 1967:87,88&lt;/ref&gt;

His objections to Kant then leads Russell to accept the 'theory of ideas' of [[Plato]], "in my opinion . . . one of the most successful attempts hitherto made.";&lt;ref name="Russell 1912, 1967:93"&gt;Russell 1912, 1967:93&lt;/ref&gt; he asserts that " . . . we must examine our knowledge of universals . . . where we shall find that [this consideration] solves the problem of ''a priori'' knowledge.".&lt;ref name="Russell 1912, 1967:93"/&gt;

=== Principia Mathematica ( Part I: 1910 first edition, 1927 2nd edition) ===
Unfortunately, Russell's "Problems" does not offer an example of a "minimum set" of principles that would apply to human reasoning, both inductive and deductive. But PM does at least provide ''an'' example set (but not the minimum; see '''Post''' below) that is sufficient for ''deductive'' reasoning by means of the [[propositional calculus]] (as opposed to reasoning by means of the more-complicated [[predicate calculus]])—a total of 8 principles at the start of "Part I: Mathematical Logic". Each of the formulas :❋1.2 to :❋1.6 is a [[tautology (logic)|tautology]] (true no matter what the truth-value of p, q, r ... is). What is missing in PM's treatment is a formal rule of substitution;&lt;ref&gt;In his 1944 ''Russell's mathematical logic'', [[Kurt Gödel|Gödel]] observes that "What is missing, above all, is a precise statement of the syntax of the formalism. Syntactical considerations are omitted even in cases where they are necessary for the cogency of the proofs . . . The matter is especially doubtful for the rule of substitution and of replacing defined symbols by their ''definiens'' . . . it is chiefly the rule of substitution which would have to be proved" (Gödel 1944:124)&lt;/ref&gt; in his 1921 PhD thesis [[Emil Post]] fixes this deficiency (see '''Post''' below). In what follows the formulas are written in a more modern format than that used in PM; the names are given in PM). 
:❋1.1 Anything implied by a true elementary proposition is true.
:❋1.2 Principle of Tautology: (p ⋁ p) ⊃ p
:❋1.3 Principle of [logical] Addition: q ⊃ (p ⋁ q)
:❋1.4 Principle of Permutation: (p ⋁ q) ⊃ (q ⋁ p)
:❋1.5 Associative Principle: p ⋁ (q ⋁ r) ⊃ q ⋁ (p ⋁ r) [''redundant'']
:❋1.6 Principle of [logical] Summation: (q ⊃ r) ⊃ ((p ⋁ q) ⊃ (p ⋁ r))
:❋1.7 [logical NOT]: If p is an elementary proposition, ~p is an elementary proposition.
:❋1.71 [logical inclusive OR]: If p and q are elementary propositions, (p ⋁ q) is an elementary proposition.
Russell sums up these principles with "This completes the list of primitive propositions required for the theory of deduction as applied to elementary propositions" (PM:97).

Starting from these eight tautologies and a tacit use of the "rule" of substitution, PM then derives over a hundred different formulas, among which are the '''Law of Excluded Middle ❋1.71''', and the '''Law of Contradiction ❋3.24''' (this latter requiring a definition of logical AND symbolized by the modern ⋀: (p ⋀ q) =&lt;sub&gt;def&lt;/sub&gt; ~(~p ⋁ ~q). (PM uses the "dot" symbol &lt;sub&gt;▪&lt;/sub&gt; for logical AND)).

==Ladd-Franklin (1914): "principle of exclusion" and the "principle of exhaustion"==
At about the same time (1912) that Russell and Whitehead were finishing the last volume of their Principia Mathematica, and the publishing of Russell's "The Problems of Philosophy" at least two logicians ([[Louis Couturat]], [[Christine Ladd-Franklin]]) were asserting that two "laws" (principles) of contradiction" and "excluded middle" are necessary to specify "contradictories"; Ladd-Franklin renamed these the principles of [[Mutually exclusive events|exclusion]] and [[Collectively exhaustive events|exhaustion]]. The following appears as a footnote on page 23 of Couturat 1914:
:"As Mrs. LADD·FRANKLlN has truly remarked (BALDWIN, Dictionary of Philosophy and Psychology, article "Laws of Thought"), the principle of contradiction is not sufficient to define contradictories; the principle of excluded middle must be added which equally deserves the name of principle of contradiction. This is why Mrs. LADD-FRANKLIN proposes to call them respectively the principle of exclusion and the principle of exhaustion, inasmuch as, according to the first, two contradictory terms are exclusive (the one of the other); and, according to the second, they are exhaustive (of the universe of discourse)."

In other words, the creation of "contradictories" represents a [[dichotomy]], i.e. the "splitting" of a [[universe of discourse]] into two classes (collections) that have the following two properties: they are (i) mutually exclusive and (ii) (collectively) exhaustive.&lt;ref&gt;Cf Nagel and Newman 1958:110; in their treatment they apply this dichotomy to the collection of "sentences" (formulas) generated by a logical system such as that used by [[Kurt Gödel]] in his paper "On Formally Undecidable Propositions of Principia Mathematical and Related Systems". They call the two classes K&lt;sub&gt;1&lt;/sub&gt; and K&lt;sub&gt;2&lt;/sub&gt; and define logical contradiction ~S as follows: "A formula having the form ~S is placed in [class] K&lt;sub&gt;2&lt;/sub&gt;, if S is in K&lt;sub&gt;1&lt;/sub&gt;; otherwise, it is placed in K&lt;sub&gt;1&lt;/sub&gt;&lt;/ref&gt; In other words, no one thing (drawn from the universe of discourse) can simultaneously be a member of both classes (law of non-contradiction), ''but'' [and] every single thing (in the universe of discourse) must be a member of one class or the other (law of excluded middle).

==Post (1921): The propositional calculus is consistent and complete==
As part of his PhD thesis "Introduction to a general theory of elementary propositions" [[Emil Post]] proved "the system of elementary propositions of Principia [PM]" i.e. its "propositional calculus"&lt;ref&gt;In the introductory comments to Post 1921 written by van Heijenoort page 264, van H observes that "The propositional calculus, carved out of the system of ''Principia Mathematica'', is systematically studied in itself, as a well-defined fragment of logic".&lt;/ref&gt; described by PM's first 8 "primitive propositions" to be ''consistent''. The definition of "consistent" is this: that by means of the deductive "system" at hand (its stated axioms, laws, rules) it is impossible to derive (display) both a formula S and its contradictory ~S (i.e. its logical negation) (Nagel and Newman 1958:50). To demonstrate this formally, Post had to add a primitive proposition to the 8 primitive propositions of PM, a "rule" that specified the notion of "substitution" that was missing in the original PM of 1910.&lt;ref&gt;In a footnote he stated "This operation is not explicitly stated in ''Principia'' but is pointed out to be necessary by Russell (1919, p. 151). Indeed: "The legitimacy of substitutions of this kind has to be insured by means of a non-formal principle of inference.&lt;sup&gt;1&lt;/sup&gt;. This footnote 1 states: "&lt;sup&gt;1&lt;/sup&gt; No such principle is enunciated in Principia Mathematica or in M. Nicod's article mentioned above. But this would seem to be an omission". cf Russell 1919:151 referenced by Post 1921 in van Heijenoort 1967:267)&lt;/ref&gt;

Given PM's tiny set of "primitive propositions" and the proof of their consistency, Post then proves that this system ("propositional calculus" of PM) is ''complete'', meaning every possible [[truth table]] can be generated in the "system":
:". . .every truth system has a representation in the system of Principia while every complete system, that is one having all possible truth tables, is equivalent to it. . . . We thus see that complete systems are equivalent to the system of ''Principia'' not only in the truth table development but also postulationally. As other systems are in a sense degenerate forms of complete systems we can conclude that no new logical systems are introduced."&lt;ref&gt;Post 1921 in van Heijenoort 1967:267)&lt;/ref&gt;

===A minimum set of axioms? The matter of their independence===
Then there is the matter of "independence" of the axioms. In his commentary before Post 1921, [[Jean van Heijenoort|van Heijenoort]] states that [[Paul Bernays]] solved the matter in 1918 (but published in 1926) -- the formula ❋1.5 Associative Principle: p ⋁ (q ⋁ r) ⊃ q ⋁ (p ⋁ r) can be proved with the other four. As to what system of "primitive-propositions" is the minimum, van Heijenoort states that the matter was "investigated by Zylinski (1925), Post himself (1941), and Wernick (1942)" but van Heijenoort does not answer the question.&lt;ref&gt;van Heijenoort's commentary before Post 1921 in van Heijenoort:264-265&lt;/ref&gt;

=== Model theory versus proof theory: Post's proof ===
Kleene (1967:33) observes that "logic" can be "founded" in two ways, first as a "model theory", or second by a formal "proof" or "axiomatic theory"; "the two formulations, that of model theory and that of proof theory, give equivalent results"(Kleene 1967:33). This foundational choice, and their equivalence also applies to ''predicate logic'' (Kleene 1967:318). 
 
In his introduction to Post 1921, van Heijenoort observes that both the "truth-table and the axiomatic approaches are clearly presented".&lt;ref&gt;van Heijenoort:264&lt;/ref&gt; This matter of a proof of consistency both ways (by a model theory, by axiomatic proof theory) comes up in the more-congenial version of Post's consistency proof that can be found in Nagel and Newman 1958 in their chapter V "An Example of a Successful Absolute Proof of Consistency". In the main body of the text they use a model to achieve their consistency proof (they also state that the system is complete but do not offer a proof) (Nagel &amp; Newman 1958:45-56). But their text promises the reader a proof that is axiomatic rather than relying on a model, and in the Appendix they deliver this proof based on the notions of a division of formulas into two classes K&lt;sub&gt;1&lt;/sub&gt; and K&lt;sub&gt;2&lt;/sub&gt; that are '''mutually exclusive''' and '''exhaustive''' (Nagel &amp; Newman 1958:109-113)
&lt;!-- Their proofs adopt the same four axioms as those of Post 1921, minus the axiom ❋1.5 shown to be redundant by Bernays 1926. 
* First they specify the symbols called "variables" (e.g. p, q, r . . .), 
* Second, they assert the symbols they call "sentential connectives":  "~" (NOT), "⋁" (OR), "⊃" (IF . . . THEN . . .), and "▪" (AND), and two "signs of punctuation" "(", and ")". 
* Third they specify the ''Formation Rules'' that specify how to construct "valid" formulas from the variable-, connective- and punctuation-symbol : If S is a formula then ~(S) is a formula, If S&lt;sub&gt;1&lt;/sub&gt; and S&lt;sub&gt;2&lt;/sub&gt; are formulas then (S&lt;sub&gt;1&lt;/sub&gt; ⋁ S&lt;sub&gt;2&lt;/sub&gt;), (S&lt;sub&gt;1&lt;/sub&gt; ⊃ S&lt;sub&gt;2&lt;/sub&gt;), and (S&lt;sub&gt;1&lt;/sub&gt; ▪ S&lt;sub&gt;2&lt;/sub&gt;)is a formula.  
* Fourth are the two "transformation rules", the now-familiar Rules of Substitution and Detachment (''modus ponens''). 
Given this "system" they then propose to prove the "system" consistent. "The actual procedure is elegant", they state. "It consists in finding a characteristic or structural property of formulas [i.e. the 4 axioms and all "valid" logical formulas derived from them via the transformation rules] which satisfies the three following conditions". The property must be (1) common to all four axioms, AND (2) "hereditary" under the Transformation Rules (i.e. every axiom, and every formula derived by means of the ''Transformation'' rules from the axioms must have this property), BUT (3) at least one formula derived by the ''Formation'' rules does not have this property.

The property they pick is "tautologous", meaning the formula's truth value ''always'' evaluates to "true". They exhibit (p ⋁ q) as a properly-formed formula, but one that is not tautologus -- if p's truth value is "falsity" and q's truth value is "falsity" then (p ⋁ q)truth value is "falsity". They offer proof of the inheritability of "tautolgous" in appendices.--&gt;

==Gödel (1930): The first-order predicate calculus is complete==
The (restricted) "first-order predicate calculus" is the "system of logic" that adds to the propositional logic (cf '''Post''', above) the notion of "subject-predicate" i.e. the subject x is drawn from a domain (universe) of discourse and the predicate is a logical function f(x): x as subject and f(x) as predicate (Kleene 1967:74). Although Gödel's proof involves the same notion of "completeness" as does the proof of Post, Gödel's proof is far more difficult; what follows is a discussion of the axiom set.

=== Completeness ===
[[Kurt Gödel]] in his 1930 doctoral dissertation "The completeness of the axioms of the functional calculus of logic" proved that in this "calculus" (i.e. restricted predicate logic with or without equality) that every valid formula is "either refutable or satisfiable"&lt;ref&gt;cf introduction to Gödel 1930 by van Heijenoort 1967:582&lt;/ref&gt; or what amounts to the same thing: every valid formula is provable and therefore the logic is complete. Here is Gödel's definition of whether or not the "restricted functional calculus" is "complete":
:". . . whether it actually suffices for the derivation of ''every'' logico-mathematical proposition, or where, perhaps, it is conceivable that there are true propositions (which may be provable by means of other principles) that cannot be derived in the system under consideration."&lt;ref&gt;Gödel 1930 in van Heijenoort 1967:582&lt;/ref&gt;

===The first-order predicate calculus===
This particular predicate calculus is "restricted to the first order". To the propositional calculus it adds two special symbols that symbolize the generalizations "for all" and "there exists (at least one)" that extend over the domain of discourse. The calculus requires only the first notion "for all", but typically includes both: (1) the notion "for all x" or "for every x" is symbolized in the literature as variously as (x), ∀x, ∏x etc., and the (2) notion of "there exists (at least one x)" variously symbolized as Ex, ∃x.

The '''restriction''' is that the generalization "for all" applies only to the ''variables'' (objects x, y, z etc. drawn from the domain of discourse) and not to functions, in other words the calculus will permit ∀xf(x) ("for all creatures x, x is a bird") but not ∀f∀x(f(x)) [but if "equality" is added to the calculus it will permit ∀f:f(x); see below under '''Tarski'''].  Example:
: Let the predicate "function" f(x) be "x is a mammal", and the subject-domain (or [[universe of discourse]]) (cf Kleene 1967:84) be the category "bats":
: The formula ∀xf(x) yields the truth value "truth" (read: "For all instances x of objects 'bats', 'x is a mammal'" is a truth, i.e. "All bats are mammals"); 
: But if the instances of x are drawn from a domain "winged creatures" then ∀xf(x) yields the truth value "false" (i.e. "For all instances x of 'winged creatures', 'x is a mammal'" has a truth value of "falsity"; "Flying insects are mammals" is false);
: However over the broad domain of discourse "all winged creatures" (e.g. "birds" + "flying insects" + "flying squirrels" + "bats") we ''can'' assert ∃xf(x) (read: "There exists at least one winged creature that is a mammal'"; it yields a truth value of "truth" because the objects x can come from the category "bats" and perhaps "flying squirrels" (depending on how we define "winged"). But the formula yields "falsity" when the domain of discourse is restricted to "flying insects" or "birds" or both "binsects" and "birds".

Kleene remarks that "the predicate calculus (without or with equality) fully accomplishes (for first order theories) what has been conceived to be the role of logic" (Kleene 1967:322).

===A new axiom: Aristotle's dictum – "the maxim of all and none" ===
This first half of this axiom -- "the maxim of all" will appear as the first of two additional axioms in Gödel's axiom set. The "dictum of Aristotle" ([[dictum de omni et nullo]]) is sometimes called "the maxim of all and none" but is really two "maxims" that assert: "What is true of all (members of the domain) is true of some (members of the domain)", and "What is not true of all (members of the domain) is true of none (of the members of the domain)".

The "dictum" appears in Boole 1854 a couple places:
:"It may be a question whether that formula of reasoning, which is called the dictum of Aristotle, ''de Omni et nullo'', expresses a primary law of human reasoning or not; but it is no question that it expresses a general truth in Logic" (1854:4)

But later he seems to argue against it:&lt;ref&gt;cf Boole 1854:226 ARISTOTELIAN LOGIC. CHAPTER XV. [CHAP. XV. THE ARISTOTELIAN LOGIC AND ITS MODERN EXTENSIONS, EXAMINED BY THE METHOD OF THIS TREATISE&lt;/ref&gt;
:"[Some principles of] general principle of an axiomatic nature, such as the "dictum of Aristotle:" Whatsoever is affirmed or denied of the genus may in the same sense be affirmed or denied of any species included under that genus. . . . either state directly, but in an abstract form, the argument which they are supposed to elucidate, and, so stating that argument, affirm its validity; or involve in their expression technical terms which, after definition, conduct us again to the same point, viz. the abstract statement of the supposed allowable forms of inference."

But the first half of this "dictum" (''dictum de omni'') is taken up by Russell and Whitehead in PM, and by [[David Hilbert|Hilbert]] in his version (1927) of the "first order predicate logic"; his (system) includes a principle that Hilbert calls "Aristotle's dictum" &lt;ref&gt;He derives this and a "principle of the excluded middle" ~((x)f(x))→(Ex)~f(x) from his "ε-axiom" cf Hilbert 1927 "The Foundations of Mathematics", cf van Heijenoort 1967:466&lt;/ref&gt; 
:(x)f(x) → f(y)

This axiom also appears in the modern axiom set offered by [[Stephen Cole Kleene|Kleene]] (Kleene 1967:387), as his "∀-schema", one of two axioms (he calls them "postulates") required for the predicate calculus; the other being the "∃-schema" f(y) ⊃ ∃xf(x) that reasons from the particular f(y) to the existence of at least one subject x that satisfies the predicate f(x); both of these requires adherence to a defined domain (universe) of discourse.

=== Gödel's restricted predicate calculus ===
To supplement the four (down from five; see '''Post''') axioms of the propositional calculus, Gödel 1930 adds the ''dictum de omni'' as the first of two additional axioms. Both this "dictum" and the second axiom, he claims in a footnote, derive from ''Principia Mathematica''. Indeed, PM includes both as
:❋10.1 ⊦ ∀xf(x) ⊃ f(y) ["I.e. what is true in all cases is true in any one case"&lt;ref&gt;1962 edition of PM 2nd edition 1927:139&lt;/ref&gt; ("Aristotle's dictum", rewritten in more-modern symbols)]
:❋10.2 ⊦∀x(p ⋁ f(x)) ⊃ (p ⋁ ∀xf(x)) [rewritten in more-modern symbols]
The latter asserts that the logical sum (i.e. ⋁, OR) of a simple proposition p and a predicate ∀xf(x) implies the logical sum of each separately. But PM derives both of these from six primitive propositions of ❋9, which in the second edition of PM is discarded and replaced with four new "Pp" (primitive principles) of ❋8 (see in particular ❋8.2, and Hilbert derives the first from his "logical ε-axiom" in his 1927 and does not mention the second. How Hilbert and Gödel came to adopt these two as axioms is unclear.

Also required are two more "rules" of detachment ("modus ponens") applicable to predicates.

==Tarski (1946): Leibniz's Law==
[[Alfred Tarski]] in his 1946 (2nd edition) "Introduction to Logic and to the Methodology of the Deductive Sciences" cites a number of what he deems "universal laws" of the sentential calculus,  three "rules" of inference, and one fundamental law of identity (from which he derives four more laws). The traditional "laws of thought" are included in his long listing of "laws" and "rules". His treatment is, as the title of his book suggests, limited to the "Methodology of the Deductive Sciences".

'''Rationale''': In his introduction (2nd edition) he observes that what began with an application of logic to mathematics has been widened to "the whole of human knowledge": 
:"[I want to present] a clear idea of that powerful trend of contemporary thought which is concentrated about modern logic. This trend arose originally from the somewhat limited task of stabilizing the foundations of mathematics. In its present phase, however, it has much wider aims. For it seeks to create a unified conceptual apparatus which would supply a common basis for the whole of human knowledge.".&lt;ref&gt;Tarski 1946:ix, 1995 edition&lt;/ref&gt;
&lt;!-- '''Laws of the sentential calculus''': Tarski defines a "law" as follows (cf p.&amp;nbsp;37ff):
:"Every scientific theory is a system of sentences which are accepted as true and which may be called LAWS or ASSERTED STATEMENTS, or, for short, simply STATEMENTS".&lt;ref&gt;Tarski 1946:3, 1995 edition&lt;/ref&gt;

(After the first "law", for brevity he omits the universal qualifier "For any p, q , . . ."). The symbol "~" indicates logical NOT, the symbol ⋀ indicates logical AND, the symbol ⋁ indicates logical OR, the symbol ↔ indicates logical equivalence ("if and only if"). He uses "matrices" (truth tables) to define these symbols; truth tables can then be used to demonstrate that each of these "laws" is a [[tautology (logic)|tautology]] (true no matter what truth value is assigned to each "variable" p, q, r): 
*Law of Simplification for logical multiplication [logical AND]: For any p and q: (p ⋀ q) → p
*'''Law of Identity: p → p'''.
*Law of Simplification for logical addition [logical OR]: p → (q ⋁ p)
*Law of [? logical equivalence]: [(p → q) ⋀ (q → p)] →  p ↔ q.
*Law of the Hypothetical Syllogism: [(p → q) ⋀ (q → r)] → (p → r).
*'''Law of Contradiction: ~[p ⋀ (~p)]'''
*'''Law of Excluded Middle: p ⋁ (~p)'''
*Law of Tautology for logical multiplication [logical AND]: (p ⋀ p) ↔ p
*Law of Tautology for logical addition [logical OR]: (p ⋁ p) ↔ p
*Law of Commutation [for logical AND]: (p ⋀ q) ↔ (q ⋀ p)
*Law of Commutation [for logical OR]: (p ⋁ q) ↔ (q ⋁ p)
*Law of Association [for logical AND]: (p ⋀ (q ⋀ r) ↔ [(p ⋀ q) ⋀ r]
*Law of Association [for logical OR]: (p ⋁ (q ⋁ r) ↔ [(p ⋁ q) ⋁ r]

'''Rules of inference''': Tarski then defines what he calls three "rules of inference" ("rules of proof") with this definition of what a "rule" is as opposed to a "law":
:"These rules, which must not be mistaken for logical laws, amount to directions as to how sentences already known as true may be transformed so as to yield new true sentences".&lt;ref&gt;Tarski 1946:47, 1995 edition&lt;/ref&gt;
*Rule of Definition
*Rule of [[Substitution]]
*Rule of Detachment ("[[modus ponens]] rule") ---&gt;

===Law of identity (Leibniz's Law, equality)===
To add the notion of "equality" to the "propositional calculus" (this new notion not to be confused with ''logical'' equivalence symbolized by ↔, ⇄, "if and only if (iff)", "biconditional", etc.) Tarski (cf p54-57) symbolizes what he calls  "Leibniz's law" with the symbol "=". This extends the domain (universe) of discourse and the types of functions to numbers and mathematical formulas (Kleene 1967:148ff, Tarski 1946:54ff).

In a nutshell: given that "x has every property that y has", we can write "x = y", and this formula will have a truth value of "truth" or "falsity". Tarski states this Leibniz's Law as follows:
* I. Leibniz' Law: x = y, if, and only if, x has every property which y has, and y has every property which x has.
He then derives some other "laws" from this law: 
* II. Law of Reflexivity: Everything is equal to itself: x = x. [Proven at PM ❋13.15]
* III. Law of Symmetry: If x = y, then y = x. [Proven at PM ❋13.16]
* IV. Law of Transitivity: If x = y and y = z, then x = z. [Proven at PM ❋13.17]
* V. If x = z and y = z, then x = y. [Proven at PM ❋13.172]

Principia Mathematica ''defines'' the notion of equality as follows (in modern symbols); note that the generalization "for all" extends over predicate-functions f( ):
:❋13.01. x = y =&lt;sub&gt;def&lt;/sub&gt; ∀f:(f(x) → f(y)) ("This definition states that x and y are to be called identical when every predicate function satisfied by x is satisfied by y"&lt;ref&gt;cf PM ❋13 IDENTITY, "Summary of ❋13" PM 1927 edition 1962:168&lt;/ref&gt;

Hilbert 1927:467 adds only two axioms of equality, the first is x = x, the second is (x = y) → ((f(x) → f(y)); the "for all f" is missing (or implied). Gödel 1930 defines equality similarly to PM :❋13.01. Kleene 1967 adopts the two from Hilbert 1927 plus two more (Kleene 1967:387).

== Contemporary developments ==
All of the above "systems of logic" are considered to be "classical" meaning propositions and predicate expressions are two-valued, with either the truth value "truth" or "falsity" but not both(Kleene 1967:8 and 83). While intuitionistic logic falls into the "classical" category, it objects to extending the "for all" operator to the Law of Excluded Middle; it allows instances of the "Law", but not its generalization to an infinite domain of discourse.

=== Intuitionistic logic ===
'[[Intuitionistic logic]]', sometimes more generally called '''constructive logic''', is a [[paracomplete]] [[Mathematical logic|symbolic logic]] that differs from [[classical logic]] by replacing the traditional concept of truth with the concept of [[constructive proof|constructive provability]].

The ''generalized'' law of the excluded middle is not part of the execution of [[intuitionistic logic]], but neither is it negated. Intuitionistic logic merely forbids the use of the operation as part of what it defines as a "[[constructive proof]]", which is not the same as demonstrating it invalid (this is comparable to the use of a particular building style in which screws are forbidden and only nails are allowed; it does not necessarily disprove or even question the existence or usefulness of screws, but merely demonstrates what can be built without them).

=== Paraconsistent Logic ===
'[[Paraconsistent logic]]' refers to so-called contradiction-tolerant logical systems in which a contradiction does not necessarily result in [[trivialism]]. In other words, the [[principle of explosion]] is not valid in such logics. Some (namely the dialetheists) argue that the law of non-contradiction is denied by [[dialetheic logic]]. They are motivated by certain paradoxes which seem to imply a limit of the law of non-contradiction, namely the [[Liar Paradox]]. In order to avoid a trivial logical system and still allow certain contradictions to be true, dialetheists will employ a paraconsistent logic of some kind.

=== Three-valued Logic ===
{{expand section|date=December 2017}}
TBD cf [[Three-valued logic]]
try this 
A Ternary Arithmetic and Logic - Semantic Scholar
https://pdfs.semanticscholar.org/.../11ef6cfbc237a4655af2eee550e6d...

Oldal lefordítása
Írta: I Profeanu - 2010 - Idézetek száma: 10 - Kapcsolódó cikkek
gradually reveal. For the beginning I propose a ternary arithmetic and logic and I will bring arguments for their use. Index Terms—free energy, ternary arithmetic, ternary logic. I. INTRODUCTION. It is well known that the numeral system used in most if not all modern computer systems is the binary numerical system, as again ...

=== Modal propositional calculi ===
(cf Kleene 1967:49): These "[[modal logic|calculi]]" include the symbols ⎕A, meaning "A is necessary" and ◊A meaning "A is possible". Kleene states that:
:"These notions enter in domains of thinking where there are understood to be two different kinds of "truth", one more universal or compelling than the other . . . A zoologist might declare that it is impossible that salamanders or any other living creatures can survive fire; but possible (though untrue) that unicorns exist, and possible (though improbable) that abominable snowmen exist."

=== Fuzzy logic ===
{{expand section|date=December 2017}}
'[[Fuzzy logic]]' is a form of [[many-valued logic]]; it deals with [[reasoning]] that is approximate rather than fixed and exact.

== See also ==

* [[Fuzzy logic]]
* [[Intuitionistic logic]]

==References==
&lt;references/&gt;
* [[Aristotle]], "The Categories", [[Harold P. Cooke]] (trans.), pp.&amp;nbsp;1–109 in ''Aristotle, Vol. 1'',  [[Loeb Classical Library]], [[Heinemann (book publisher)|William Heinemann]], London, UK, 1938.
* Aristotle, "On Interpretation", Harold P. Cooke (trans.), pp.&amp;nbsp;111–179 in ''Aristotle, Vol. 1'',  Loeb Classical Library, William Heinemann, London, UK, 1938.
* Aristotle, "[[Prior Analytics]]", [[Hugh Tredennick]] (trans.), pp.&amp;nbsp;181–531 in ''Aristotle, Vol. 1'', Loeb Classical Library, William Heinemann, London, UK, 1938.
* [[George Boole|Boole, George]], ''[[The Laws of Thought|An Investigation of the Laws of Thought on Which are Founded the Mathematical Theories of Logic and Probabilities'']], [[Macmillan Publishers|Macmillan]], 1854.  Reprinted with corrections, [[Dover Publications]], New York, NY, 1958.
*[[Louis Couturat]], translated by Lydia Gillingham Robinson, 1914, ''The Algebra of Logic'', The Open Court Publishing Company, Chicago and London. Downloaded via googlebooks.
* Gödel 1944 ''Russell's mathematical logic'' in ''Kurt Gödel: Collected Works Volume II'', Oxford University Press, New York, NY, {{ISBN|978-0-19-514721-6}}
*[[Sir William Hamilton, 9th Baronet]], ([[Henry L. Mansel]] and [[John Veitch (poet)|John Veitch]], ed.), 1860 ''Lectures on Metaphysics and Logic, in Two Volumes. Vol. II. Logic'', Boston: Gould and Lincoln. Downloaded via googlebooks.
*[[Stephen Cole Kleene]], 1967, ''Mathematical Logic'' reprint 2002, Dover Publications, Inc., Mineola, NY, {{ISBN|0-486-42533-9}} (pbk.)
*[[Ernest Nagel]], [[James R. Newman]], 1958, ''Gödel's Proof'', New York University Press, LCCCN: 58-5610.
*[[Bertrand Russell]], ''The Problems of Philosophy'' (1912), Oxford University Press, New York, 1997, {{ISBN|0-19-511552-X}}.
*[[Arthur Schopenhauer]], ''[[The World as Will and Representation]]'', Volume 2, [[Dover Publications]], Mineola, New York, 1966, {{ISBN|0-486-21762-0}}
*[[Alfred Tarski]], 1946 (second edition), republished 1995, ''Introduction to Logic and to the Methodology of Deductive Sciences'' translated by Olaf Helmer, Dover Publications, Inc., New York, {{ISBN|0-486-28462-X}} (pbk.)
*[[Jean van Heijenoort]], 1967, ''From Frege to Gödel: A Source Book in Mathematical Logic, 1879–1931'', Harvard University Press, Cambridge, MA, {{ISBN|978-0-674-32449-7}} (pbk)
:*[[Emil Post]], 1921, ''Introduction to a general theory of elementary propositions'' with commentary by van Heijenoort, pages 264ff
:*[[David Hilbert]], 1927, ''The foundations of mathematics'' with commentary by van Heijenoort, pages 464ff
:*[[Kurt Gödel]], 1930a, ''The completeness of the axioms of the functional calculus of logic'' with commentary by van Heijenoort, pages 592ff.
*[[Alfred North Whitehead]], [[Bertrand Russell]]. ''Principia Mathematica'', 3 vols, Cambridge University Press, 1910, 1912, and 1913. Second edition, 1925 (Vol. 1), 1927 (Vols 2, 3). Abridged as ''Principia Mathematica to *56 (2nd edition)'', Cambridge University Press, 1962, no LCCCN or ISBN

==External links==
* James Danaher, ''"[http://www.the-philosopher.co.uk/2004/05/the-laws-of-thought-2004.html The Laws of Thought]"'', ''The Philosopher'', Volume LXXXXII No. 1
* Peter Suber, ''"[http://www.earlham.edu/~peters/courses/logsys/pnc-pem.htm Non-Contradiction and Excluded Middle]"'', Earlham College

{{DEFAULTSORT:Law Of Thought}}
[[Category:Concepts in logic| ]]
[[Category:Classical logic]]</text>
      <sha1>2zz5auetcjul5ujvncb4m89trnum83z</sha1>
    </revision>
  </page>
  <page>
    <title>List of multivariable calculus topics</title>
    <ns>0</ns>
    <id>534959</id>
    <revision>
      <id>835541873</id>
      <parentid>743830299</parentid>
      <timestamp>2018-04-09T09:35:26Z</timestamp>
      <contributor>
        <username>Diddydoyka</username>
        <id>33454018</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1796">This is a '''list of multivariable calculus topics'''. See also [[multivariable calculus]], [[vector calculus]], [[list of real analysis topics]], [[list of calculus topics]]. 

*[[Closed and exact differential forms]]
*[[Contact (mathematics)]]
*[[Contour integral]]
*[[Contour line]]
*[[Critical point (mathematics)]]
*[[Curl (mathematics)]]
*[[Current (mathematics)]]
*[[Curvature]]
*[[Curvilinear coordinates]]
*[[Del]]
*[[Differential form]]
*[[Differential operator]]
*[[Directional derivative]]
*[[Divergence]]
*[[Divergence theorem]]
*[[Double integral]]
*[[Equipotential surface]]
*[[Euler's theorem on homogeneous functions]]
*[[Exterior derivative]]
*[[Flux]]
*[[Frenet–Serret formulas]]
*[[Gauss's law]]
*[[Gradient]]
*[[Green's theorem]]
*[[Green's identities]]
*[[Harmonic function]]
*[[Helmholtz decomposition]]
*[[Hessian matrix]]
*[[Hodge star operator]]
*[[Inverse function theorem]]
*[[Irrotational vector field]]
*[[Isoperimetry]]
*[[Jacobian matrix]]
*[[Lagrange multiplier]]
*[[Lamellar vector field]]
*[[Laplacian]]
*[[Laplacian vector field]]
*[[Level set]]
*[[Line integral]]
* [[Matrix calculus]]
*[[Mixed derivatives]]
*[[Monkey saddle]]
*[[Multiple integral]]
*[[Newtonian potential]]
*[[Parametric equation]]
*[[Parametric surface]]
*[[Partial derivative]]
*[[Partial differential equation]]
*[[Potential]]
*[[Real coordinate space]]
*[[Saddle point]]
*[[Solenoidal vector field]]
*[[Stokes' theorem]]
*[[Submersion (mathematics)|Submersion]]
*[[Surface integral]]
*[[Symmetry of second derivatives]]
*[[Taylor's theorem]]
*[[Total derivative]]
*[[Vector field]]
*[[Vector operator]]
*[[Vector potential]]

[[Category:Mathematics-related lists|Multivariable calculus]]
[[Category:Multivariable calculus|*list]]
[[Category:Wikipedia outlines|Multivariable calculus]]</text>
      <sha1>klfh8nqzhnzpcy6b9e9bagoohe5bkre</sha1>
    </revision>
  </page>
  <page>
    <title>Matthias Aschenbrenner</title>
    <ns>0</ns>
    <id>44788496</id>
    <revision>
      <id>857400945</id>
      <parentid>851214109</parentid>
      <timestamp>2018-08-31T13:08:50Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* References */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1839">'''Matthias Aschenbrenner''' is an American mathematician. He is a professor of mathematics at the [[University of California, Los Angeles]]. His research interests include [[differential algebra]] and [[model theory]].&lt;ref&gt;[http://www.math.ucla.edu/~matthias/ Matthias Aschenbrenner]&lt;/ref&gt;

==Career==
Aschenbrenner received his Ph.D. from the [[University of Illinois at Urbana-Champaign]] in 2001, where he was a student of [[Lou van den Dries]].&lt;ref&gt;{{MathGenealogy|id=59951|title=Matthias Aschenbrenner}}&lt;/ref&gt; For his dissertation, he was awarded the 2001 Sacks Prize by the [[Association for Symbolic Logic]].&lt;ref&gt;{{cite web|url=https://www.aslonline.org/Sacks_recipients.html|title=Sacks Prize Recipients|author=&lt;!--Not stated--&gt;|publisher=[[Association for Symbolic Logic]]|access-date=September 11, 2017}}&lt;/ref&gt; In 2012, Aschenbrenner became a Fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society]&lt;/ref&gt; He was jointly awarded the 2018 [[Karp Prize]] with [[Lou van den Dries]] and Joris van der Hoeven "for their work in model theory, especially on asymptotic differential algebra and the model theory of transseries."&lt;ref&gt;{{cite web|url=https://www.aslonline.org/files/newsletters/pdfs/April2018newsletter.pdf|title=ASL Newsletter|author=&lt;!--Not stated--&gt;|date=April 2018|publisher=[[Association for Symbolic Logic]]|access-date=July 20, 2018}}&lt;/ref&gt;

==References==
{{Reflist}}


{{authority control}}

{{DEFAULTSORT:Aschenbrenner, Matthias}}
[[Category:Living people]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:University of California, Los Angeles faculty]]
[[Category:University of Illinois at Urbana–Champaign alumni]]
[[Category:21st-century American mathematicians]]


{{US-mathematician-stub}}</text>
      <sha1>fdyswcc0c0ui1m0so9q1y7ious79c79</sha1>
    </revision>
  </page>
  <page>
    <title>Monadic predicate calculus</title>
    <ns>0</ns>
    <id>8015680</id>
    <revision>
      <id>782678778</id>
      <parentid>772738226</parentid>
      <timestamp>2017-05-28T13:44:17Z</timestamp>
      <contributor>
        <ip>82.79.115.90</ip>
      </contributor>
      <comment>link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4640">In [[logic]], the '''monadic predicate calculus''' (also called '''monadic first-order logic''') is the fragment of [[first-order logic]] in which all relation symbols in the [[signature (mathematical logic)|signature]] are [[monadic (arity)|monadic]] (that is, they take only one argument), and there are no function symbols. All [[atomic formula]]s are thus of the form &lt;math&gt;P(x)&lt;/math&gt;, where &lt;math&gt;P&lt;/math&gt; is a relation symbol and &lt;math&gt;x&lt;/math&gt; is a [[Variable (mathematics)|variable]].

Monadic predicate calculus can be contrasted with polyadic predicate calculus, which allows relation symbols that take two or more arguments. 

== Expressiveness ==

The absence of [[polyadic relation]] symbols severely restricts what can be expressed in the monadic predicate calculus. It is so weak that, unlike the full predicate calculus, it is  [[decidability (logic)|decidable]]—there is a [[decision problem|decision procedure]] that determines whether a given formula of monadic predicate calculus is [[logical validity|logically valid]] (true for all nonempty [[Domain of discourse|domain]]s).&lt;ref&gt;[[Heinrich Behmann]], ''Beiträge zur Algebra der Logik, insbesondere zum Entscheidungsproblem'', in ''Mathematische Annalen'' (1922)&lt;/ref&gt;&lt;ref&gt;[[Leopold Löwenheim|Löwenheim]], L. (1915) "Über Möglichkeiten im Relativkalkül," ''Mathematische Annalen'' 76: 447-470. Translated as "On possibilities in the calculus of relatives" in Jean van Heijenoort, 1967. ''A Source Book in Mathematical Logic'', 1879-1931. Harvard Univ. Press: 228-51.&lt;/ref&gt; Adding a single binary relation symbol to monadic logic, however, results in an undecidable logic.

== Relationship with term logic ==

The need to go beyond monadic logic was not appreciated until the work on the logic of [[Relation (mathematics)|relation]]s, by [[Augustus De Morgan]] and [[Charles Sanders Peirce]] in the nineteenth century, and by [[Frege]] in his 1879 ''Begriffsschrifft''. Prior to the work of these three men, [[term logic]] (syllogistic logic) was widely considered adequate for formal deductive reasoning.

Inferences in term logic can all be represented in the monadic predicate calculus. For example the [[syllogism]]
: All dogs are mammals.
: No mammal is a bird.
: Thus, no dog is a bird.
can be notated in the language of monadic predicate calculus as
: &lt;math&gt;(\forall x\,D(x)\Rightarrow M(x))\land \neg(\exists y\,M(y)\land B(y)) \Rightarrow \neg(\exists z\,D(z)\land B(z))&lt;/math&gt;
where &lt;math&gt;D&lt;/math&gt;, &lt;math&gt;M&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; denote the predicates of being, respectively, a dog, a mammal, and a bird.

Conversely, monadic predicate calculus is not significantly more expressive than term logic. Each formula in the monadic predicate calculus is [[logical equivalence|equivalent]] to a formula in which [[Quantifier (logic)|quantifier]]s appear only in closed subformulas of the form
:&lt;math&gt;\forall x\,P_1(x)\lor\cdots\lor P_n(x)\lor\neg P'_1(x)\lor\cdots\lor \neg P'_m(x)&lt;/math&gt;
or
:&lt;math&gt;\exists x\,\neg P_1(x)\land\cdots\land\neg P_n(x)\land P'_1(x)\land\cdots\land P'_m(x),&lt;/math&gt;
These formulas slightly generalize the basic judgements considered in term logic. For example, this form allows statements such as "''Every mammal is either a herbivore or a carnivore (or both)''", &lt;math&gt;(\forall x\,\neg M(x)\lor H(x)\lor C(x))&lt;/math&gt;. Reasoning about such statements can, however, still be handled within the framework of term logic, although not by the 19 classical Aristotelian [[syllogism]]s alone.

Taking [[propositional logic]] as given, every formula in the monadic predicate calculus expresses something that can likewise be formulated in term logic. On the other hand, a modern view of the [[problem of multiple generality]] in traditional logic concludes that quantifiers cannot nest usefully if there are no polyadic predicates to relate the bound variables.

==Variants==

The formal system described above is sometimes called the '''pure''' monadic predicate calculus, where "pure" signifies the absence of function letters. Allowing monadic function letters changes the logic only superficially{{citation needed|reason=Not obvious. Exact meaning unclear|date=August 2014}}, whereas admitting even a single binary function letter results in an undecidable logic. 

Monadic [[second-order logic]] allows predicates of higher [[arity]] in formulas, but restricts second-order quantification to [[unary operation|unary]] predicates, i.e. the only second-order variables allowed are [[subset variables]].

==Footnotes==
{{Portal|Logic}}
&lt;references/&gt;

{{Mathematical logic}}

[[Category:Predicate logic]]
[[Category:Logical calculi]]</text>
      <sha1>kyjth6op7j453ptsmqk50w963cm6h4o</sha1>
    </revision>
  </page>
  <page>
    <title>Order-5 pentagonal tiling</title>
    <ns>0</ns>
    <id>38358615</id>
    <revision>
      <id>786601603</id>
      <parentid>777257875</parentid>
      <timestamp>2017-06-20T12:58:22Z</timestamp>
      <contributor>
        <username>CBM</username>
        <id>1108292</id>
      </contributor>
      <minor/>
      <comment>Manually reviewed edit to replace magic words per [[Special:PermanentLink/772743896#Future_of_magic_links|local rfc]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1959">{{Uniform hyperbolic tiles db|Reg hyperbolic tiling stat table|U55_0}}
In [[geometry]], the '''order-5 pentagonal tiling''' is a [[List_of_regular_polytopes#Hyperbolic_tilings|regular]] tiling of the [[Hyperbolic geometry|hyperbolic plane]]. It has [[Schläfli symbol]] of {5,5}, constructed from five pentagons around every vertex. As such, it is [[Dual polyhedron#Self-dual_polytopes_and_tessellations|self-dual]].

== Related tilings ==
{{Order-5_regular_tilings}}
This tiling is topologically related as a part of sequence of regular polyhedra and tilings with vertex figure (5&lt;sup&gt;n&lt;/sup&gt;).
{{Regular pentagonal tiling table}}

{{Order_5-5_tiling_table}}

==See also==
{{Commonscat|Order-5 pentagonal tiling}}
*[[Square tiling]]
*[[Uniform tilings in hyperbolic plane]]
*[[List of regular polytopes]]

==References==
* [[John Horton Conway|John H. Conway]], Heidi Burgiel, Chaim Goodman-Strass, ''The Symmetries of Things'' 2008, {{isbn|978-1-56881-220-5}} (Chapter 19, The Hyperbolic Archimedean Tessellations)
* {{Cite book|title=The Beauty of Geometry: Twelve Essays|year=1999|publisher=Dover Publications|lccn=99035678|isbn=0-486-40919-8|chapter=Chapter 10: Regular honeycombs in hyperbolic space}}

== External links ==
*{{MathWorld | urlname= HyperbolicTiling | title = Hyperbolic tiling}}
*{{MathWorld | urlname=PoincareHyperbolicDisk | title = Poincaré hyperbolic disk }}
* [http://bork.hampshire.edu/~bernie/hyper/ Hyperbolic and Spherical Tiling Gallery]
* [http://geometrygames.org/KaleidoTile/index.html KaleidoTile 3: Educational software to create spherical, planar and hyperbolic tilings]
* [http://www.plunk.org/~hatch/HyperbolicTesselations Hyperbolic Planar Tessellations, Don Hatch]

{{Tessellation}}

[[Category:Hyperbolic tilings]]
[[Category:Isogonal tilings]]
[[Category:Isohedral tilings]]
[[Category:Order-5 tilings]]
[[Category:Pentagonal tilings]]
[[Category:Regular tilings]]
[[Category:Self-dual tilings]]

{{geometry-stub}}</text>
      <sha1>owxf4u8ze8s1sslcmhsxjvb9k1qsv9e</sha1>
    </revision>
  </page>
  <page>
    <title>Partial permutation</title>
    <ns>0</ns>
    <id>27499693</id>
    <revision>
      <id>851660754</id>
      <parentid>841544278</parentid>
      <timestamp>2018-07-23T19:25:41Z</timestamp>
      <contributor>
        <username>Beland</username>
        <id>57939</id>
      </contributor>
      <minor/>
      <comment>&amp;loz -&gt; ◊</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4654">In [[combinatorics|combinatorial mathematics]], a '''partial permutation''', or '''sequence without repetition''', on a [[finite set]] ''S''
is a [[bijection]] between two specified [[subset]]s of ''S''. That is, it is defined by two subsets ''U'' and ''V'' of equal size, and a one-to-one mapping from ''U'' to ''V''. Equivalently, it is a [[partial function]] on ''S'' that can be extended to a [[permutation]].&lt;ref&gt;{{citation
 | last = Straubing | first = Howard
 | doi = 10.1016/0012-365X(83)90164-4
 | issue = 2-3
 | journal = Discrete Mathematics
 | mr = 685635
 | pages = 273–279
 | title = A combinatorial proof of the Cayley-Hamilton theorem
 | volume = 43
 | year = 1983}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last1 = Ku | first1 = C. Y.
 | last2 = Leader | first2 = I.
 | doi = 10.1016/j.disc.2005.11.007
 | issue = 1
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | mr = 2202076
 | pages = 74–86
 | title = An Erdős-Ko-Rado theorem for partial permutations
 | volume = 306
 | year = 2006}}.&lt;/ref&gt;

==Representation==
It is common to consider the case when the set ''S'' is simply the set {1, 2, ..., ''n''} of the first ''n'' integers.  In this case, a partial permutation may be represented by a [[String (computer science)|string]] of ''n'' symbols, some of which are distinct numbers in the range from 1 to &lt;math&gt;n&lt;/math&gt; and the remaining ones of which are a special "hole" symbol ◊. In this formulation, the [[domain of a function|domain]] ''U'' of the partial permutation consists of the positions in the string that do not contain a hole, and each such position is mapped to the number in that position. For instance, the string "1 ◊ 2" would represent the partial permutation that maps 1 to itself and maps 3 to 2.&lt;ref name="cjjk"&gt;{{citation
 | last1 = Claesson | first1 = Anders
 | last2 = Jelínek | first2 = Vít
 | last3 = Jelínková | first3 = Eva
 | last4 = Kitaev | first4 = Sergey
 | issue = 1
 | journal = Electronic Journal of Combinatorics
 | mr = 2770130
 | page = Paper 25, 41
 | title = Pattern avoidance in partial permutations
 | volume = 18
 | year = 2011}}.&lt;/ref&gt;
The seven partial permutations on two items are
:◊◊, ◊1, ◊2, 1◊, 2◊, 12, 21.


==Combinatorial enumeration==
The number of partial permutations on ''n'' items, for ''n'' = 0, 1, 2, ..., is given by the [[integer sequence]]
:1, 2, 7, 34, 209, 1546, 13327, 130922, 1441729, 17572114, 234662231, ... {{OEIS|A002720}}
where the ''n''th item in the sequence is given by the summation formula
:&lt;math&gt;\sum_{i=0}^n i!\binom{n}{i}^2&lt;/math&gt;
in which the ''i''th term counts the number of partial permutations with support of size ''i'', that is, the number of partial permutations with ''i'' non-hole entries.
Alternatively, it can be computed by a [[recurrence relation]]
:&lt;math&gt;P(n) = 2nP(n-1) - (n-1)^2 P(n-2).&lt;/math&gt;
This is determined as follows:
#&lt;math&gt;P(n-1)&lt;/math&gt; partial permutations where the final elements of each set are omitted:
#&lt;math&gt;P(n-1)&lt;/math&gt; partial permutations where the final elements of each set map to each other.
#&lt;math&gt;(n-1)P(n-1)&lt;/math&gt; partial permutations where the final element of the first set is included, but does not map to the final element of the second set
#&lt;math&gt;(n-1)P(n-1)&lt;/math&gt; partial permutations where the final element of the second set is included, but does not map to the final element of the first set
#&lt;math&gt;-(n-1)^2P(n-2)&lt;/math&gt;, the partial permutations included in both counts 3 and 4, those permutations where the final elements of both sets are included, but do not map to each other.

==Restricted partial permutations==
Some authors restrict partial permutations so that either the domain&lt;ref&gt;{{citation
 | last1 = Burstein | first1 = Alexander
 | last2 = Lankham | first2 = Isaiah
 | contribution = Restricted patience sorting and barred pattern avoidance
 | doi = 10.1017/CBO9780511902499.013
 | location = Cambridge
 | mr = 2732833
 | pages = 233–257
 | publisher = Cambridge Univ. Press
 | series = London Math. Soc. Lecture Note Ser.
 | title = Permutation patterns
 | volume = 376
 | year = 2010| arxiv = math/0512122
 }}.&lt;/ref&gt; 
or the range&lt;ref name="cjjk"/&gt; of the bijection is forced to consist of the first ''k'' items in the set of ''n'' items being permuted, for some ''k''.  In the former case, a partial permutation of length ''k'' from an ''n''-set is just a sequence of ''k'' terms from the ''n''-set without repetition.  (In elementary combinatorics, these objects are sometimes confusingly called "[[K-permutation|''k''-permutation]]s" of the ''n''-set.)

==References==
{{reflist}}

[[Category:Combinatorics]]
[[Category:Functions and mappings]]</text>
      <sha1>6nr1s7fxc319c5crh541oi3eqexsgp9</sha1>
    </revision>
  </page>
  <page>
    <title>Percentile rank</title>
    <ns>0</ns>
    <id>225965</id>
    <revision>
      <id>866196908</id>
      <parentid>866196865</parentid>
      <timestamp>2018-10-28T22:11:44Z</timestamp>
      <contributor>
        <username>LakesideMiners</username>
        <id>30681431</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/2603:9001:1B02:8300:B4CC:5F7B:8DAB:17BD|2603:9001:1B02:8300:B4CC:5F7B:8DAB:17BD]] ([[User talk:2603:9001:1B02:8300:B4CC:5F7B:8DAB:17BD|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2734">[[Image:PR and NCE.gif|thumb|350px|Percentile ranks (PRs or percentiles) compared to [[Normal curve equivalent]]s (NCEs)]]
The '''percentile rank''' of a score is the percentage of scores in its [[frequency distribution]] that are equal to or lower than it. For example, a test score that is greater than 75% of the scores of people taking the test is said to be at the 75th [[percentile]], where 75 is the percentile rank. In educational measurement, a range of percentile ranks, often appearing on a score report, shows the range within which the test taker’s “true” percentile rank probably occurs. The “true” value refers to the rank the test taker would obtain if there were no random errors involved in the testing process. &lt;ref&gt;National Council on Measurement in Education http://www.ncme.org/ncme/NCME/Resource_Center/Glossary/NCME/Resource_Center/Glossary1.aspx?hkey=4bb87415-44dc-4088-9ed9-e8515326a061#anchorP&lt;/ref&gt;


Percentile ranks are commonly used to clarify the interpretation of scores on standardized tests. For the [[test theory]], the percentile rank of a raw score is interpreted as the percentages of examinees in the norm group who scored at or below the score of interest.&lt;ref name="CrockerAlgina1986"&gt;Crocker, L., &amp; Algina, J. (1986). ''Introduction to classical and modern test theory.'' New York: Harcourt Brace Jovanovich College Publishers. {{ISBN|0-03-061634-4}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last=Schultzkie|first=Lisa|title=Percentiles and More Quartiles|url=http://regentsprep.org/REgents/math/ALGEBRA/AD6/quartiles.htm|publisher=Oswego City School District Regents Exam Prep Center|accessdate=26 November 2013}}&lt;/ref&gt; 

Percentile ranks are not on an equal-interval scale; that is, the difference between any two scores is not the same between any other two scores whose difference in percentile ranks is the same. For example, 50&amp;nbsp;−&amp;nbsp;25&amp;nbsp;=&amp;nbsp;25 is not the same distance as 60&amp;nbsp;−&amp;nbsp;35&amp;nbsp;=&amp;nbsp;25 because of the bell-curve shape of the distribution. Some percentile ranks are closer to some than others. Percentile rank 30 is closer on the bell curve to 40 than it is to 20.

The mathematical formula is

:&lt;math&gt;\frac{\text{c}_\ell + 0.5 f_i }{N} \times 100\%&lt;/math&gt;

where c&lt;sub&gt;''ℓ''&lt;/sub&gt; is the count of all scores less than the score of interest, ''ƒ''&lt;sub&gt;''i''&lt;/sub&gt; is the frequency of the score of interest, and ''N'' is the number of examinees in the sample. If the distribution is [[Normal distribution|normally]] distributed, the percentile rank can be inferred from the [[standard score]].

==See also==
{{portal|Statistics}}
*[[Percentile]]
*[[Quantile]]

==References==
{{reflist}}

{{statistics}}

[[Category:Summary statistics]]

{{Statistics-stub}}</text>
      <sha1>toip55201xy41co6hpytk3k92pxaltn</sha1>
    </revision>
  </page>
  <page>
    <title>Peter M. Gruber</title>
    <ns>0</ns>
    <id>35098363</id>
    <revision>
      <id>831493999</id>
      <parentid>810204796</parentid>
      <timestamp>2018-03-20T21:39:47Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4874">[[File:Peter M Gruber.JPG|thumb|Peter M. Gruber]]
'''Peter Manfred Gruber''' (28 August 1941, [[Klagenfurt]] – 7 March 2017, [[Vienna]]) was an Austrian mathematician working in [[geometric number theory]]&lt;ref name=zong&gt;{{cite journal |work= The mathematical intelligencer |volume=31 |issue=3 |pages=25&amp;ndash;31 |doi= 10.1007/s00283-009-9042-1 |title= Geometry of Numbers in Vienna |first= Chuanming |last=Zong }}&lt;/ref&gt; as well as in convex and discrete geometry.&lt;ref name="auto"&gt;[http://www.ams.org/profession/ams-fellows/new-fellows 2014 Class of the Fellows of the AMS], [[American Mathematical Society]], retrieved 2013-11-04.&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.tuwien.ac.at/aktuelles/news_detail/article/124820/|title=Peter M. Gruber – ein Nachruf|work=tuwien.ac.at|accessdate=14 March 2017}}&lt;/ref&gt;

==Biography==

Gruber obtained his PhD at the [[University of Vienna]] in 1966, under the supervision of [[Nikolaus Hofreiter]].&lt;ref name="mg"&gt;{{MathGenealogy|id=55638}}&lt;/ref&gt; From 1971, he was Professor at the [[University of Linz]], and from 1976, at the [[TU Wien]].&lt;ref name=zong/&gt; He was a member of the [[Austrian Academy of Sciences]],&lt;ref name=zong/&gt;&lt;ref&gt;{{cite web|url=http://www.oeaw.ac.at/oeaw_servlet/e_PersonenDetailsGeneric?id=10882|title=Peter M. Gruber|publisher=Austrian Academy of Sciences|deadurl=yes|archiveurl=https://web.archive.org/web/20050802083537/http://www.oeaw.ac.at/oeaw_servlet/e_PersonenDetailsGeneric?id=10882|archivedate=2005-08-02|df=}}&lt;/ref&gt; a foreign member of the Russian Academy of Sciences,&lt;ref name=zong/&gt;&lt;ref&gt;{{cite web|url=http://www.ras.ru/win/db/show_per.asp?P=.id-53786.ln-en|title=Gruber, Peter Manfred|publisher=Russian Academy of Sciences}}&lt;/ref&gt; and a corresponding member of the [[Bavarian Academy of Sciences and Humanities]].&lt;ref name=zong/&gt;&lt;ref&gt;{{cite web|url=http://www.badw.de/mitglieder/k_mit/index.html#g|title=Korrespondierende Mitglieder|publisher=Bavarian Academy of Sciences and Humanities|language=German}}&lt;/ref&gt;

His past doctoral students include [[Monika Ludwig]].&lt;ref name="mg"/&gt;

==Selected publications==

* {{cite book
  | first     = P.M.
  | last      = Gruber
  | title     = Convex and Discrete Geometry
  | publisher = Springer-Verlag
  | location  = Berlin
  | year      = 2007
  | ref       = harv
  }}
* {{cite book
  | first1      = P.M.
  | last1       = Gruber
  | first2      = C.G.
  | last2       = Lekkerkerker
  | authorlink2 = Gerrit Lekkerkerker
  | title       = Geometry of Numbers
  | publisher   = North-Holland
  | location    = Amsterdam
  | year        = 1987
  | ref         = harv
  }}

==Decorations and awards==
* 1967: Prize of the [[Austrian Mathematical Society]]
* 1978, 1980 and 1982: Chairman of the Austrian Mathematical Society
* 1991: Full member of the Austrian Academy of Sciences (Corresponding member since 1988)
* 1996: Medal of the Union of Czech Mathematicians and Physicists
* 2001: [[Austrian Cross of Honour for Science and Art, 1st class]]&lt;ref&gt;{{cite web | url = http://www.parlament.gv.at/PAKT/VHG/XXIV/AB/AB_10542/imfname_251156.pdf | title = Reply to a parliamentary question | language = German | page=1396 |trans-title=| format = pdf | accessdate = 28 February 2013 }}&lt;/ref&gt;
* 2001: Medal of the mathematical and physical faculty of [[Charles University]] in Prague
* 2003: Foreign member of the [[Russian Academy of Sciences]]
* 2008: [[Grand Silver Medal for Services to the Republic of Austria]]&lt;ref&gt;{{cite web | url = http://www.parlament.gv.at/PAKT/VHG/XXIV/AB/AB_10542/imfname_251156.pdf | title = Reply to a parliamentary question | language = German | page=1840 |trans-title=| format = pdf | accessdate = 28 February 2013 }}&lt;/ref&gt;
* 2013: [[Fellow]] of the [[American Mathematical Society]], for "contributions to the geometry of numbers and to convex and discrete geometry".&lt;ref name="auto"/&gt;
* Honorary doctorates from the Universities of [[University of Siegen|Siegen]], [[University of Turin|Turin]] and [[University of Salzburg|Salzburg]]
* Member of the Academies of Sciences in [[Messina]] and [[Modena]]
* Corresponding member of the [[Bavarian Academy of Sciences]]

==Notes==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Gruber, Peter M.}}
[[Category:1941 births]]
[[Category:2017 deaths]]
[[Category:People from Klagenfurt]]
[[Category:Austrian mathematicians]]
[[Category:Geometers]]
[[Category:Number theorists]]
[[Category:University of Vienna alumni]]
[[Category:Johannes Kepler University Linz faculty]]
[[Category:Vienna University of Technology faculty]]
[[Category:Foreign Members of the Russian Academy of Sciences]]
[[Category:Members of the Austrian Academy of Sciences]]
[[Category:Recipients of the Austrian Cross of Honour for Science and Art, 1st class]]
[[Category:Recipients of the Grand Decoration for Services to the Republic of Austria]]
[[Category:Fellows of the American Mathematical Society]]</text>
      <sha1>huq2wguhtajjy1y5q3gvh7pdjhsb9i7</sha1>
    </revision>
  </page>
  <page>
    <title>Pierre Lelong</title>
    <ns>0</ns>
    <id>34789789</id>
    <revision>
      <id>762431155</id>
      <parentid>732957622</parentid>
      <timestamp>2017-01-28T19:48:47Z</timestamp>
      <contributor>
        <username>Tassedethe</username>
        <id>7098284</id>
      </contributor>
      <comment>+hatnote</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1688">{{for|the neo-Impressionist painter|Pierre Emile Lelong}}
[[Image:Pierre Lelong.jpg|thumb|right]]
'''Pierre Lelong'''  (14 March 1912 Paris – 12 October 2011)&lt;ref name="academy"&gt;[http://www.academie-sciences.fr/academie/membre/Lelong_Pierre.htm Pierre Lelong] at the académie des sciences&lt;/ref&gt; was a French mathematician who introduced the [[Poincaré–Lelong equation]], the [[Lelong number]] and the concept of [[plurisubharmonic function]].

Lelong earned his doctorate in 1941 from the [[École Normale Supérieure]], under the supervision of [[Paul Montel]].&lt;ref&gt;{{MathGenealogy|id=24207}}&lt;/ref&gt; On June 5, 1981 Lelong received an [[Honorary degree|honorary doctorate]] from the Faculty of 
Mathematics and Science at [[Uppsala University]], [[Sweden]].&lt;ref&gt;http://www.uu.se/en/about-uu/traditions/prizes/honorary-doctorates/&lt;/ref&gt;
He was a member of the [[French Academy of Sciences]] since 1985.&lt;ref name="academy"/&gt;

He married another mathematician, [[Jacqueline Ferrand]], in 1947; they separated in 1977.&lt;ref&gt;{{citation|title=Women mathematicians in France in the mid-twentieth century|first=Yvette|last=Kosmann-Schwarzbach|doi=10.1080/17498430.2014.976804|journal=BSHM Bulletin: Journal of the British Society for the History of Mathematics|year=2015|arxiv=1502.07597}}.&lt;/ref&gt;

==References==
{{reflist}}

{{Authority control}}
{{DEFAULTSORT:Lelong, Pierre}}
[[Category:École Normale Supérieure alumni]]
[[Category:20th-century French mathematicians]]
[[Category:21st-century French mathematicians]]
[[Category:Members of the French Academy of Sciences]]
[[Category:Complex analysts]]
[[Category:Mathematical analysts]]
[[Category:2011 deaths]]
[[Category:1912 births]]</text>
      <sha1>9wym8tyuo4s6a2vhyyllwtbzm08xfdr</sha1>
    </revision>
  </page>
  <page>
    <title>Proof (play)</title>
    <ns>0</ns>
    <id>166521</id>
    <revision>
      <id>861665377</id>
      <parentid>840582583</parentid>
      <timestamp>2018-09-29T03:00:43Z</timestamp>
      <contributor>
        <ip>73.233.169.0</ip>
      </contributor>
      <comment>/* Production history */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19152">{{About|the play by David Auburn|other uses|Proof (disambiguation)}}
{{Infobox play
| name       = Proof
| image      = Proof, A Play.jpg
| image_size = 160px
| writer     = [[David Auburn]]
| characters = Catherine&lt;br&gt;Robert&lt;br&gt;Hal&lt;br&gt;Claire
| setting    = [[University of Chicago]] [[Chicago, Illinois]]
| premiere   = May 23, 2000
| place      = [[Manhattan Theatre Club]]&lt;br&gt;[[New York City, New York]]
| orig_lang  = English
| subject    = 
| genre      = [[Drama]]
}}
'''''Proof''''' is a 2000 play by the American playwright [[David Auburn]]. ''Proof'' was developed at George Street Playhouse in [[New Brunswick, New Jersey]], during the 1999 Next Stage Series of new plays. The play premiered [[Off-Broadway]] in May 2000 and transferred to [[Broadway theater|Broadway]] in October 2000. The play won the 2001 [[Pulitzer Prize for Drama]] and the [[Tony Award for Best Play]].

==Plot==
The play concerns Catherine, the daughter of Robert, a recently deceased mathematical genius in his fifties and professor at the [[University of Chicago]], and her struggle with mathematical genius and [[mental illness]]. Catherine had cared for her father through a lengthy mental illness. Upon Robert's death, his ex-graduate student Hal discovers a paradigm-shifting [[proof (mathematics)|proof]] about [[prime numbers]] in Robert's office. The title refers both to that proof and to the play's central question: Can Catherine prove the proof's authorship? Along with demonstrating the proof's authenticity, the daughter also finds herself in a relationship with 28-year-old Hal. Throughout, the play explores Catherine's fear of following in her father's footsteps, both mathematically and mentally and her desperate attempts to stay in control.

;Act I

The play opens with Catherine sitting alone in the backyard of her large, old house. Robert, her father, approaches her with a bottle of champagne to celebrate her 25th birthday. Catherine complains that she hasn't done any worthwhile work in the field of [[mathematics]], at least not to the same level as her father, a well-known math genius. He reassures her that she can still do good work as long as she stops lying in bed till all hours and wasting time reading magazines. Catherine confesses she's worried about inheriting Robert's inclination towards mental instability. He begins to comfort her but then alludes to a "bad sign" when he points out that he is, in fact, dead. He died a week ago. Robert disappears as Catherine dozes off. She awakens when Hal, one of Robert's students, exits the house. He's been studying the hundreds of notebooks Robert left behind after his death, looking for any work that could be published. Catherine assures him that the notebooks are filled with scribbles and nonsense since her father wrote them when he was at his most delusional. Hal, attempting to flirt, invites her to go see his band later that night. Catherine becomes suspicious of him and demands to see what's in his backpack. She roots through it to find nothing but becomes infuriated when a notebook falls out of Hal's jacket. She dials the police while accusing him of trying to steal her father's work and pass it off as his own. He admits that he was sneaking it away but only to give it back to her later as a birthday present. He opens to a page that Robert wrote during a time when he was lucid. In it, Robert writes it's a "good day" and thanks to Catherine for taking care of him and expresses hope for the future. Hal leaves Catherine with the notebook. She begins to cry until she hears police sirens.

The next day Claire, Catherine's sister who just flew in from New York, is setting up a large brunch for them in the backyard. Catherine enters and Claire tries to goad her into idle chitchat as Catherine quietly seethes. Claire declares she's getting married and invites Catherine to stay with her and her [[fiance]] in New York. Catherine assures her she'll come in January for the wedding, but Claire keeps pressing her to go earlier. When Catherine demands to know why Claire is inundating her with questions, Claire tells her the police came over earlier to check in on Catherine. Catherine admits to calling the police the previous night and tries to explain her altercation with Hal but only ends up sounding unhinged to the dubious Claire. Hal appears and asks to continue his work sorting the notebooks. Catherine lets him inside and Claire drops a hint for Catherine to try flirting with Hal by offering a bagel. Catherine storms into the house.

Later that night, after the funeral, Claire holds a party in the house for her friends as well as Hal and Robert's students. Catherine escapes to the porch where Hal finds her and offers her a beer. Hal confesses that he's not so sure about his own mathematical abilities since he considers math to be a "young man's game". Catherine tries to reassure him with a quote from Gauss. Hal responds by kissing her, much to Catherine's surprise. He apologizes for trying to steal the notebook and she apologizes for calling the police. They kiss again and Hal asks Catherine if she remembers meeting him years earlier. She says she does and recalls she thought he was "not boring". They continue to kiss.

The next morning Catherine sits outside. Hal exits the house and tells her he'd like to spend the rest of the day with her. Catherine gives him a key to Robert's desk and tells him to look inside. He goes into the house. A moment later, Claire comes into the backyard, extremely hungover. Catherine, now in a good mood, tries to make nice with Claire. Claire takes the opportunity to continue to push Catherine to moving to New York. Catherine asks why she would move to New York to which Claire confesses that she's selling the house. Catherine becomes enraged at the idea and she accuses Claire of abandoning her to take care of their sick father alone. Claire insists that the reason she did so was to keep working to pay for the house as well as Catherine's education. Catherine reveals that she had to quit school to tend to Robert and then accuses Claire of trying to have her committed. Claire admits that she's researched doctors and facilities for Catherine but insists that she wasn't planning on having her committed. In the middle of the row, Hal appears clutching a notebook, barely containing his excitement. He tells Claire that Catherine is in possession of one of Robert's notebooks which holds a very important proof. Claire asks Catherine where she found it and Catherine tells them she didn't find it. She wrote it.

;Act II

We flashback to years earlier, with Robert sitting in the backyard. Catherine tells him she thinks he's getting better and he agrees. She blurts out that she's decided to go to college in a couple months, funded by Claire, but promises she'll be only a short drive away if he were to need her again. Robert protests and demands to know why she waited so long to tell him. When she points out that he hadn't been well until recently and was, at one point, trying to decode [[Extraterrestrial life|extraterrestrial]] messages in library books, he becomes upset. Hal interrupts, much to his embarrassment, to present his final dissertation to Robert. Robert assures him they'll work out the problem points together, then suddenly realizes he's forgotten Catherine's birthday. He apologizes and offers to take her out to dinner. Catherine invites Hal along but he says he can't go. Catherine shows Hal out and Robert sits down to write a notebook entry, declaring it to be a "good day".

We flash forward to where Act I left off. Catherine declares she was the one who wrote the proof and is met with incredulity by both Hal and her sister. The handwriting is very much like Robert's and Hal questions Catherine's mathematical abilities given that she only had a few months' education at Northwestern. Catherine tells him that her real education was living with Robert. When Hal offers to show it to other math experts to confirm the authenticity of the proof, Catherine refuses. She tells Hal she trusted him and then accuses him of having no talent and being past his prime. Hal storms off and Catherine begins to rip the notebook apart. Claire gets it away from her and Catherine runs into the house.

Later, Hal attempts to visit Catherine and apologize for his behavior. Claire stops him and tells him Catherine won't talk to her, let alone Hal. Claire accuses him of sleeping with Catherine despite her being unstable. Hal argues that he had no bad intentions and insists Catherine is stronger than Claire thinks. He requests to have the notebook to verify its authenticity with fellow mathematicians. Claire gives it to him and tells him she's taking Catherine with her to New York the next day. She expresses concern for Catherine's future mental stability.

We flashback to Robert in the backyard, sitting in the cold and writing furiously. Catherine enters and reprimands him for sitting in the cold with no jacket. Robert tells her it's too hot in the house and that the cold is better for helping him work. Catherine is shocked that he's working again and he assures her that he's sharper than ever. She's ecstatic that his previous mental instability has passed and asks to see his work. He says he'd love for her to take a look and asks if she'd like to take time off school to work with him. Before she decides, Robert insists she look at his latest idea and thrusts a notebook into her hands. Catherine glances at it and becomes quiet. She tells him they need to go inside and Robert explodes with fury. He yells at her to read what he's written. She reads aloud, a nonsensical, rambling paragraph about winter and books and the cold. It's obvious that Robert's mind is deteriorating as it had been before. Catherine begins to cry as Robert descends into confusion and begins to shiver uncontrollably. Catherine tries to take him inside when he asks her not to leave. She promises she won't.

We flash forward to Claire in the backyard. Catherine enters with her suitcase. She asks Claire about life in New York. Claire mentions potential schools or jobs for Catherine but Catherine is quick to mock her by making ridiculous demands for a Freudian psychiatrist who will listen as she blames all her problems on Claire. Claire begins to cry and throws Catherine's plane ticket in front of her before storming off. Hal enters and tells Catherine that the proof checks out and apologizes for not believing her. Catherine tells him there's no proof that she wrote it and he can claim it as his own if he wants. Hal tells her he believes she's the one who wrote it and offers to read through it with her. Catherine admits she knows she's like her father but is terrified of becoming like her father. Hal reassures her that maybe she'll be better. Catherine opens the proof and begins to talk through it with Hal.

==Characters==
*Catherine – A young woman, 25 years old, who inherited much of her father's mathematical genius and, she fears, his "instability" as well; she gave up her life and schooling to take care of her father until his recent death.
*Claire – Catherine's older sister, a practical and business-minded woman who has been comfortably successful in her work and relationships.  She left Robert and Catherine behind, distancing herself from the run-down family home of her youth.  She left the family to make a new life for herself in New York City.
*Robert – A recently deceased mathematician praised for his groundbreaking work in his youth, but whose later years were plagued by delusional mental illness; he is seen in Catherine's imagination and in flashbacks.
*Harold (Hal) Dobbs – One of Robert's last Ph.D. students during the one year his idol and mentor's illness went into remission, at least enabling Robert to teach, if not continue his own creative mathematical work.

==Production history==
Originally produced by the [[Manhattan Theatre Club]], opening on May 23, 2000, the play transferred to [[Broadway theatre|Broadway]] at the [[Walter Kerr Theatre]] on October 24, 2000.&lt;ref&gt;{{cite web|last1=Jones|first1=Kenneth|title=Broadway's Proof, of Math, Memories and Mary-Louise Parker, Opens Oct. 24|url=http://www.playbill.com/news/article/broadways-proof-of-math-memories-and-mary-louise-parker-opens-oct.-24-92696|website=Playbill.com|accessdate=31 July 2015}}&lt;/ref&gt; Directed by [[Daniel J. Sullivan]], the production starred [[Mary-Louise Parker]] as Catherine, [[Larry Bryggman]] as Robert, [[Ben Shenkman]] as Hal, and [[Johanna Day]] as Claire.&lt;ref name=vault&gt;[http://www.playbillvault.com/Show/Detail/10041/Proof "'Proof' Listing, Boadway"] {{webarchive|url=https://web.archive.org/web/20150828201755/http://www.playbillvault.com/Show/Detail/10041/Proof |date=2015-08-28 }} playbillvault.com, accessed August 31, 2015&lt;/ref&gt; Later during the Broadway run, [[Jennifer Jason Leigh]] (September 13, 2001, to June 30, 2002)&lt;ref&gt;Jones, Kenneth. [http://www.playbill.com/news/article/jennifer-jason-leigh-adds-its-up-in-bway-proof-beginning-sept.-13-98558# "Jennifer Jason Leigh Adds Its Up in Bway 'Proof'  Beginning Sept. 13"] Playbill, September 13, 2001&lt;/ref&gt; and [[Anne Heche]] (as of July 5, 2002)&lt;ref name=heche&gt;Jones, Kenneth. [http://www.playbill.com/news/article/anne-heche-to-return-to-broadway-proof-for-july-5-evening-show-106896# "Anne Heche to Return to Broadway 'Proof' for July 5 Evening Show"] Playbill, July 5, 2002,&lt;/ref&gt; took over the lead role. [[Josh Hamilton (actor)|Josh Hamilton]]&lt;ref&gt;Jones, Kenneth. [http://www.playbill.com/news/article/josh-hamilton-and-seana-kofoed-join-bway-proof-sept.-11-98162# "Josh Hamilton and Seana Kofoed Join Bway 'Proof' Sept. 11"] Playbill, August 16, 2001&lt;/ref&gt; and [[Neil Patrick Harris]] subsequently played the role of Hal.&lt;ref name=heche/&gt; Mary-Louise Parker won the [[Tony Award]] for her performance, and Daniel Sullivan won the Tony Award, Best Direction of a Play.&lt;ref name=vault/&gt; The play closed on January 5, 2003 after 917 performances.&lt;ref name=vault/&gt;

''Proof'' premiered in the [[West End theatre|West End]] at the Donmar Warehouse in May 2002, to June 15, 2002. Directed by [[John Madden (director)|John Madden]], the cast starred [[Gwyneth Paltrow]] as Catherine, with [[Ronald Pickup]] as Robert, [[Sara Stewart]] as Claire, and [[Richard Coyle]] as Hal.&lt;ref&gt;Billington, Michael. [https://www.theguardian.com/stage/2002/may/16/theatre.artsfeatures2 "review. 'Proof'"] ''The Guaedian'', May 16, 2002,&lt;/ref&gt; London's [[Menier Chocolate Factory]] produced the play from March 13, 2013, to April 27, 2013.&lt;ref&gt;Shenton, Mark. [http://www.playbill.com/news/article/londons-menier-chocolate-factory-to-revive-david-auburns-proof-201482# "London's Menier Chocolate Factory to Revive David Auburn's 'Proof'"] Playbill, January 14, 2013&lt;/ref&gt; It featured [[Mariah Gale]] in the role of Catherine, and [[Polly Findlay]] directed.&lt;ref&gt;{{cite news|url=https://officiallondontheatre.com/news/gale-has-menier-proof-169563/|title=Gale has Menier Proof|author=|first=|date=29 January 2013|newspaper=OfficialLondonTheatre.com|access-date=31 October 2017}}&lt;/ref&gt;

The play premiered in [[Australia]] at the [[Sydney Opera House]] in 2003 starring [[Jacqueline McKenzie|Jacqueline Mckenzie]] and [[Barry Otto]] and directed by [[George Ogilvie]] as a [[Sydney Theatre Company]] production.

In April and May 2013, a new production by the Whitmore Eclectic Theater Group opened in Los Angeles at the [[Hayworth Theatre]] for a limited run. [[James Whitmore Jr.]], son of the award-winning iconic actor [[James Whitmore]], starred; and his daughter Aliah Whitmore directed.{{citation needed|date=August 2015}}

A production in May 2013 opened at [[Carolina Actors Studio Theatre]] in [[Charlotte, North Carolina]].{{citation needed|date=August 2015}}

In September to October 2013, ''Proof'' was directed by [[Emily Mann (director)|Emily Mann]] at the [[McCarter Theatre]] in [[Princeton, New Jersey]].&lt;ref&gt;Gans, Andrew. [http://www.playbill.com/news/article/michael-braun-kristen-bush-jessica-dickey-and-michael-siberry-star-in-mccar-209191# "Michael Braun, Kristen Bush, Jessica Dickey and Michael Siberry Star in McCarter's 'Proof', Beginning Sept. 6"] Playbill, September 6, 2013&lt;/ref&gt;

London's [[Tabard Theatre]] produced  the play from 29 September to 24 October 2015, directed by Sebastien Blanc (son of [[Raymond Blanc]]). It featured Tim Hardy ([[Royal Shakespeare Company]] [[Marat/Sade]]) as Robert, Julia Papp as Catherine, Mary-Ann Cafferkey as Claire and [[Ian Charleson Awards]] nominee Kim Hardy as Hal.&lt;ref&gt;http://www.tabardweb.co.uk/proof.htm&lt;/ref&gt;

A [[Seattle]] production opened in January 2017 at [[Strawberry Theatre Workshop]] with three TPS Gregory Award winning actors, Anastasia Higham, Charles Leggett, and Allison Standley in principal roles. ''Proof'' was directed by [[Greg Carter (theatre director)|Greg Carter]] on the Mainstage at 12th Ave Arts.&lt;ref&gt;http://www.strawshop.org/proof.html&lt;/ref&gt; It was the first professional production in Seattle since 2004.

==Film adaptation==
{{main article|Proof (2005 film)}}
A [[Proof (2005 film)|2005 film adaptation]] was directed by [[John Madden (director)|John Madden]], starring [[Gwyneth Paltrow]] as Catherine, along with [[Anthony Hopkins]], [[Hope Davis]], and [[Jake Gyllenhaal]]. Adapted by [[Rebecca Miller]], the film version added more characters (in minor supporting roles), whereas the play has only four.

==Awards and nominations==
;Awards
* 2001 [[Drama Desk Award for Outstanding Play|Drama Desk Award for Best New Play]]
* 2001 Drama Desk Award, Outstanding Actress in a Play, Mary Louise Parker
* 2001 [[Lucille Lortel Award]] for Outstanding Play
* 2001 New York Drama Critics' Circle Best Play
* 2001 [[Pulitzer Prize for Drama]]&lt;ref&gt;[http://www.pulitzer.org/bycat/Drama "Pulitzer Prize for Drama"] pulitzer.org, accessed August 31, 2015&lt;/ref&gt;
* 2001 [[Tony Award for Best Play]]
*2001 [[Tony Award for Best Actress in a Play]], Mary Louise Parker
*2001 [[Tony Award for Best Direction of a Play]], Daniel Sullivan

==References==
{{reflist}}

==Further reading==
* {{cite book |last=Auburn |first=David |title=Proof: A Play |pages=96 |location=London |publisher=Faber and Faber |year=2001 |isbn=0-571-19997-6}}
* [http://www.uchicago.edu/features/auburn_returns_to_hyde_park_for_proof/ University of Chicago interview with David Auburn about the genesis of Proof]

==External links==
{{Commons category|Proof (play)}}
* {{IBDB show|10304|Proof}}
* {{iobdb title| 33}}
* {{ibdb title|12546|Proof}}
* {{IMDb title|377107|Proof}}

{{Navboxes
| title = Awards for ''Proof''
| list = 
{{DramaDesk Play}}
{{Pulitzer Prize for Drama 2001-2025}}
{{TonyAwardBestPlay 2001-2025}}
}}

[[Category:2000 plays]]
[[Category:Broadway plays]]
[[Category:Plays by David Auburn]]
[[Category:Drama Desk Award-winning plays]]
[[Category:Mathematics and culture]]
[[Category:New York Drama Critics' Circle Award winners]]
[[Category:Off-Broadway plays]]
[[Category:Pulitzer Prize for Drama-winning works]]
[[Category:Tony Award-winning plays]]
[[Category:American plays adapted into films]]</text>
      <sha1>jpsnx4zhwxvg80ftzphxhoddw6ib1ir</sha1>
    </revision>
  </page>
  <page>
    <title>Proof by exhaustion</title>
    <ns>0</ns>
    <id>359970</id>
    <revision>
      <id>849461486</id>
      <parentid>839402551</parentid>
      <timestamp>2018-07-09T05:30:17Z</timestamp>
      <contributor>
        <username>Banedon</username>
        <id>1124632</id>
      </contributor>
      <comment>Undid revision 839402551 by [[Special:Contributions/Cobordism|Cobordism]] ([[User talk:Cobordism|talk]]) Why is this unnecessary?</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5953">{{about|the type of mathematical proof|the method of calculating limits|Method of exhaustion}}
{{redirect|Brute force method|similarly named methods in other disciplines|Brute force (disambiguation)}}
{{redirect|Proof by cases|the concept in propositional logic|Disjunction elimination}}
'''Proof by exhaustion''', also known as '''proof by cases''', '''proof by case analysis''', '''complete induction''', or the '''brute force method''', is a method of [[mathematical proof]] in which the statement to be proved is split into a finite number of cases or sets of equivalent cases and each type of case is checked to see if the proposition in question holds.&lt;ref&gt;{{citation|last1=Reid|first1=D. A|last2=Knipping|first2=C|year=2010|title=Proof in Mathematics Education: Research, Learning, and Teaching|publisher=Sense Publishers|page=133|isbn=978-9460912443}}.&lt;/ref&gt; This is a method of [[direct proof]]. A proof by exhaustion contains two stages:

# A proof that the set of cases is exhaustive; i.e., that each instance of the statement to be proved matches the conditions of (at least) one of the cases.
# A proof of each of the cases.

The prevalence of digital [[Computer|computers]] has greatly increased the convenience of using the method of exhaustion. [[Expert system|Computer expert systems]] can be used to arrive at answers to many of the questions posed to them.  In theory, the proof by exhaustion method can be used whenever the number of cases is finite.  However, because most mathematical sets are infinite, this method is rarely used to derive general mathematical results.&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/970542319|title=Discrete mathematics with applications|last=S.|first=Epp, Susanna|date=2011-01-01|publisher=Brooks/Cole|isbn=0495391328|oclc=970542319}}&lt;/ref&gt;

In the [[Curry&amp;ndash;Howard isomorphism]], proof by exhaustion and case analysis are related to ML-style [[pattern matching]].{{Citation needed|date=March 2017}}

==Example==
To prove that every [[integer]] that is a [[Cube (arithmetic)|perfect cube]] is a multiple of 9, or is 1 more than a multiple of 9, or is 1 less than a multiple of 9.

'''Proof''':
&lt;br&gt;Each cube number is the cube of some integer ''n''. Every integer ''n'' is either a multiple of 3, or 1 more or 1 less than a multiple of 3. So these 3 cases are exhaustive:
*Case 1: If ''n'' = 3''p'', then ''n''&lt;sup&gt;3&lt;/sup&gt; = 27''p''&lt;sup&gt;3&lt;/sup&gt;, which is a multiple of 9.
*Case 2: If ''n'' = 3''p''&amp;nbsp;+&amp;nbsp;1, then ''n''&lt;sup&gt;3&lt;/sup&gt; = 27''p''&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;27''p''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;9''p''&amp;nbsp;+&amp;nbsp;1, which is 1 more than a multiple of 9. For instance, if ''n''&amp;nbsp;=&amp;nbsp;4 then ''n''&lt;sup&gt;3&lt;/sup&gt; = 64 = 9x7&amp;nbsp;+&amp;nbsp;1.
*Case 3: If ''n'' = 3''p''&amp;nbsp;−&amp;nbsp;1, then ''n''&lt;sup&gt;3&lt;/sup&gt; =&amp;nbsp;27''p''&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;27''p''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;9''p''&amp;nbsp;−&amp;nbsp;1, which is 1 less than a multiple of&amp;nbsp;9. For instance, if ''n'' =&amp;nbsp;5 then ''n''&lt;sup&gt;3&lt;/sup&gt; = 125 = 9&amp;times;14&amp;nbsp;−&amp;nbsp;1.[[∎]]

==Elegance==
Mathematicians prefer to avoid proofs by exhaustion with large numbers of cases, which are viewed as [[Mathematical elegance|inelegant]]. An illustration of how such proofs might be inelegant is to prove that every year in which the modern [[Summer Olympic Games]] is held is divisible by 4.

'''Proof''': the first modern Summer Olympics were [[1896 Summer Olympics|held in 1896]], and then every 4 years thereafter (neglecting years in which the games were not held due to World War I and World War II). Since 1896 = 474 × 4 is divisible by 4, the next Olympics would be in year 474 × 4 + 4 = (474 + 1) × 4, which is also divisible by four, and so on (this is a proof by [[mathematical induction]]). Therefore the statement is proved.

The statement can also be proved by exhaustion by listing out every year in which the Summer Olympics were held, and checking that every one of them can be divided by four. With 28 total Summer Olympics as of 2016, this is a proof by exhaustion with 28 cases. In addition to being more elegant, the proof by mathematical induction also proves the statement indefinitely into the future, while after each new Summer Olympics the proof by exhaustion will require an extra case.

==Number of cases==
There is no upper limit to the number of cases allowed in a proof by exhaustion. Sometimes there are only two or three cases. Sometimes there may be thousands or even millions. For example, rigorously solving an [[Chess endgame|endgame]] [[Chess problem|puzzle]] in [[chess]] might involve considering a very large number of possible positions in the [[game tree]] of that problem.

The first proof of the [[four colour theorem]] was a proof by exhaustion with 1,936 cases. This proof was controversial because the majority of the cases were checked by a computer program, not by hand. The shortest known proof of the four colour theorem today still has over 600 cases.

In general the probability of an error in the whole proof increases with the number of cases. A proof with a large number of cases leaves an impression that the theorem is only true by coincidence, and not because of some underlying principle or connection. Other types of proofs—such as proof by induction ([[mathematical induction]])—are considered more [[mathematical beauty|elegant]]. However, there are some important theorems for which no other method of proof has been found, such as
* The proof that there is no finite [[projective plane]] of order 10.
* The [[classification of finite simple groups]].
* The [[Kepler conjecture]].
* The [[Boolean Pythagorean triples problem]].

== See also ==
* [[British Museum algorithm]]
* [[Computer-assisted proof]]
* [[Enumerative induction]]
* [[Mathematical induction]]

== Notes ==
{{Reflist}}

[[Category:Mathematical proofs]]
[[Category:Problem solving methods]]
[[Category:Methods of proof]]

[[de:Beweis (Mathematik)#Vollständige Fallunterscheidung]]</text>
      <sha1>mdj1b9fak5xx34axea05vh5z2913vgu</sha1>
    </revision>
  </page>
  <page>
    <title>Random sample consensus</title>
    <ns>0</ns>
    <id>1089270</id>
    <revision>
      <id>868775538</id>
      <parentid>855630966</parentid>
      <timestamp>2018-11-14T10:39:17Z</timestamp>
      <contributor>
        <ip>78.104.199.110</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23003">'''Random sample consensus''' ('''RANSAC''') is an [[iterative method]] to estimate parameters of a mathematical model from a set of observed data that contains [[outliers]], when outliers are to be accorded no influence on the values of the estimates.  Therefore, it also can be interpreted as an outlier detection method.&lt;ref&gt;Data Fitting and Uncertainty, T. Strutz, Springer Vieweg (2nd edition, 2016)&lt;/ref&gt; It is a non-deterministic algorithm in the sense that it produces a reasonable result only with a certain probability, with this probability increasing as more iterations are allowed.  The algorithm was first published by Fischler and Bolles at [[SRI International]] in 1981. They used RANSAC to solve the Location Determination Problem (LDP), where the goal is to determine the points in the space that project onto an image into a set of landmarks with known locations.

A basic assumption is that the data consists of "inliers", i.e., data whose distribution can be explained by some set of model parameters, though may be subject to noise, and "outliers" which are data that do not fit the model.  The outliers can come, for example, from extreme values of the noise or from erroneous measurements or incorrect hypotheses about the interpretation of data.  RANSAC also assumes that, given a (usually small) set of inliers, there exists a procedure which can estimate the parameters of a model that optimally explains or fits this data.

==Example==
A simple example is [[Regression analysis|fitting a line]] in two dimensions to a set of observations.  Assuming that this set contains both inliers, i.e., points which approximately can be fitted to a line, and outliers, points which cannot be fitted to this line, a [[Ordinary least squares|simple least squares method]] for line fitting will generally produce a line with a bad fit to the inliers.  The reason is that it is optimally fitted to all points, including the outliers.  RANSAC, on the other hand, attempts to exclude the outliers and find a linear model that only uses the inliers in its calculation. This is done by fitting linear models to several random samplings of the data and returning the model that has the best fit to a subset of the data. Since the inliers tend to be more linearly related than a random mixture of inliers and outliers, a random subset that consists entirely of inliers will have the best model fit. In practice, there is no guarantee that a subset of inliers will be randomly sampled, and the probability of the algorithm succeeding depends on the proportion of inliers in the data as well as the choice of several algorithm parameters.

&lt;gallery widths="286" heights="255" perrow="2"&gt;
Image:Line_with_outliers.svg|A data set with many outliers for which a line has to be fitted.
Image:Fitted_line.svg|Fitted line with RANSAC; outliers have no influence on the result.
&lt;/gallery&gt;

==Overview==
The RANSAC algorithm is a learning technique to estimate parameters of a model by random sampling of observed data. Given a dataset whose data elements contain both inliers and outliers, RANSAC uses the voting scheme to find the optimal fitting result. Data elements in the dataset are used to vote for one or multiple models. The implementation of this voting scheme is based on two assumptions: that the noisy features will not vote consistently for any single model (few outliers) and there are enough features to agree on a good model (few missing data).
The RANSAC algorithm is essentially composed of two steps that are iteratively repeated:
# In the first step, a sample subset containing minimal data items is randomly selected from the input dataset. A fitting model and the corresponding model parameters are computed using only the elements of this sample subset. The cardinality of the sample subset is the smallest sufficient to determine the model parameters. 
# In the second step, the algorithm checks which elements of the entire dataset are consistent with the model instantiated by the estimated model parameters obtained from the first step. A data element will be considered as an outlier if it does not fit the fitting model instantiated by the set of estimated model parameters within some error threshold that defines the maximum deviation attributable to the effect of noise. 
The set of inliers obtained for the fitting model is called consensus set. The RANSAC algorithm will iteratively repeat the above two steps until the obtained consensus set in certain iteration has enough inliers.

The input to the RANSAC algorithm is a set of observed data values, a way of fitting some kind of model to the observations, and some [[confidence interval|confidence]] parameters. RANSAC achieves its goal by repeating the following steps:

# Select a random subset of the original data. Call this subset the ''hypothetical inliers''.
# A model is fitted to the set of hypothetical inliers.
# All other data are then tested against the fitted model. Those points that fit the estimated model well, according to some model-specific [[loss function]], are considered as part of the ''consensus set''.
# The estimated model is reasonably good if sufficiently many points have been classified as part of the consensus set.
# Afterwards, the model may be improved by reestimating it using all members of the consensus set.

This procedure is repeated a fixed number of times, each time producing either a model which is rejected because too few points are part of the consensus set, or a refined model together with a corresponding consensus set size. In the latter case, we keep the refined model if its consensus set is larger than the previously saved model.

&lt;gallery widths="286" heights="255" perrow="2"&gt;
Image:RANSAC Inliers and Outliers.png|RANSAC: Inliers and Outliers.
&lt;/gallery&gt;

==Algorithm==

The generic RANSAC algorithm works as follows:

 Given:
     data – a set of observations
     model – a model to explain observed data points
     n – minimum number of data points required to estimate model parameters
     k – maximum number of iterations allowed in the algorithm
     t – threshold value to determine data points that are fit well by model 
     d – number of close data points required to assert that a model fits well to data
 
 Return:
     bestFit – model parameters which best fit the data (or nul if no good model is found)
 
 iterations = 0
 bestFit = nul
 bestErr = something really large
 while iterations &lt; k {
     maybeInliers = n randomly selected values from data
     maybeModel = model parameters fitted to maybeInliers
     alsoInliers = empty set
     for every point in data not in maybeInliers {
         if point fits maybeModel with an error smaller than t
              add point to alsoInliers
     }
     if the number of elements in alsoInliers is &gt; d {
         % this implies that we may have found a good model
         % now test how good it is
         betterModel = model parameters fitted to all points in maybeInliers and alsoInliers
         thisErr = a measure of how well betterModel fits these points
         if thisErr &lt; bestErr {
             bestFit = betterModel
             bestErr = thisErr
         }
     }
     increment iterations
 }
 return bestFit

==Matlab implementation==
A Matlab implementation of 2D line fitting using the RANSAC algorithm:

&lt;source lang="matlab"&gt;

function [bestParameter1,bestParameter2] = ransac_demo(data,num,iter,threshDist,inlierRatio)
 % data: a 2xn dataset with #n data points
 % num: the minimum number of points. For line fitting problem, num=2
 % iter: the number of iterations
 % threshDist: the threshold of the distances between points and the fitting line
 % inlierRatio: the threshold of the number of inliers 
 
 %% Plot the data points
 figure;plot(data(1,:),data(2,:),'o');hold on;
 number = size(data,2); % Total number of points
 bestInNum = 0; % Best fitting line with largest number of inliers
 bestParameter1=0;bestParameter2=0; % parameters for best fitting line
 for i=1:iter
 %% Randomly select 2 points
     idx = randperm(number,num); sample = data(:,idx);   
 %% Compute the distances between all points with the fitting line 
     kLine = sample(:,2)-sample(:,1);% two points relative distance
     kLineNorm = kLine/norm(kLine);
     normVector = [-kLineNorm(2),kLineNorm(1)];%Ax+By+C=0 A=-kLineNorm(2),B=kLineNorm(1)
     distance = normVector*(data - repmat(sample(:,1),1,number));
 %% Compute the inliers with distances smaller than the threshold
     inlierIdx = find(abs(distance)&lt;=threshDist);
     inlierNum = length(inlierIdx);
 %% Update the number of inliers and fitting model if better model is found     
     if inlierNum&gt;=round(inlierRatio*number) &amp;&amp; inlierNum&gt;bestInNum
         bestInNum = inlierNum;
         parameter1 = (sample(2,2)-sample(2,1))/(sample(1,2)-sample(1,1));
         parameter2 = sample(2,1)-parameter1*sample(1,1);
         bestParameter1=parameter1; bestParameter2=parameter2;
     end
 end
 
 %% Plot the best fitting line
 xAxis = -number/2:number/2; 
 yAxis = bestParameter1*xAxis + bestParameter2;
 plot(xAxis,yAxis,'r-','LineWidth',2);
end


%% Generate random data for test
data = 150*(2*rand(2,100)-1); data = data.*rand(2,100);
ransac_demo(data,2,100,10,0.1);

&lt;/source&gt;

== Parameters ==
The threshold value to determine when a data point fits a model {{mvar|t}}, and the number of close data points required to assert that a model fits well to data {{mvar|d}} are determined based on specific requirements of the application and the dataset, and possibly based on experimental evaluation. The number of iterations {{mvar|k}}, however, can be determined as a function of the desired probability of success {{mvar|p}} using a theoretical result.  Let {{mvar|p}} be the desired probability that the RANSAC algorithm provides a useful result after running. RANSAC returns a successful result if in some iteration it selects only inliers from the input data set when it chooses the {{mvar|n}} points from which the model parameters are estimated. Let &lt;math&gt;w&lt;/math&gt; be the probability of choosing an inlier each time a single point is selected, that is,

:&lt;math&gt;w&lt;/math&gt; = number of inliers in data / number of points in data

A common case is that &lt;math&gt;w&lt;/math&gt; is not well known beforehand, but some rough value can be given.  Assuming that the {{mvar|n}} points needed for estimating a model are selected independently, &lt;math&gt;w^{n}&lt;/math&gt; is the probability that all ''n'' points are inliers and &lt;math&gt;1 - w^{n}&lt;/math&gt; is the probability that at least one of the {{mvar|n}} points is an outlier, a case which implies that a bad model will be estimated from this point set.  That probability to the power of {{mvar|k}} is the probability that the algorithm never selects a set of {{mvar|n}} points which all are inliers and this must be the same as &lt;math&gt;1 - p&lt;/math&gt;.  Consequently,

:&lt;math&gt;
1 - p = (1 - w^n)^k \,
&lt;/math&gt;

which, after taking the logarithm of both sides, leads to

:&lt;math&gt;
k = \frac{\log(1 - p)}{\log(1 - w^n)}
&lt;/math&gt;

This result assumes that the {{mvar|n}} data points are selected independently, that is, a point which has been selected once is replaced and can be selected again in the same iteration.  This is often not a reasonable approach and the derived value for {{mvar|k}} should be taken as an upper limit in the case that the points are selected without replacement.  For example, in the case of finding a line which fits the data set illustrated in the above figure, the RANSAC algorithm typically chooses two points in each iteration and computes &lt;code&gt;maybe_model&lt;/code&gt; as the line between the points and it is then critical that the two points are distinct.

To gain additional confidence, the [[standard deviation]] or multiples thereof can be added to {{mvar|k}}. The standard deviation of {{mvar|k}} is defined as

:&lt;math&gt; \operatorname{SD}(k) = \frac{\sqrt{1 - w^n}}{w^n}&lt;/math&gt;

==Advantages and disadvantages==
{{refimprove section|date=September 2014}}
An advantage of RANSAC is its ability to do [[robust statistics|robust estimation]]&lt;ref&gt;Robust Statistics, Peter. J. Huber, Wiley, 1981 (republished in paperback, 2004), page 1.&lt;/ref&gt; of the model parameters, i.e., it can estimate the parameters with a high degree of accuracy even when a significant number of [[outlier]]s are present in the data set.  A disadvantage of RANSAC is that there is no upper bound on the time it takes to compute these parameters (except exhaustion).  When the number of iterations computed is limited the solution obtained may not be optimal, and it may not even be one that fits the data in a good way.  In this way RANSAC offers a trade-off; by computing a greater number of iterations the probability of a reasonable model being produced is increased.  Moreover, RANSAC is not always able to find the optimal set even for moderately contaminated sets and it usually performs badly when the number of inliers is less than 50%. Optimal RANSAC &lt;ref&gt;Anders Hast, Johan Nysjö, Andrea Marchetti (2013). "Optimal RANSAC – Towards a Repeatable Algorithm for Finding the Optimal Set". Journal of WSCG 21 (1): 21–30.&lt;/ref&gt; was proposed to handle both these problems and is capable of finding the optimal set for heavily contaminated sets, even for an inlier ratio under 5%. Another disadvantage of RANSAC is that it requires the setting of problem-specific thresholds.

RANSAC can only estimate one model for a particular data set.  As for any one-model approach when two (or more) model instances exist, RANSAC may fail to find either one. The [[Hough transform]] is one alternative robust estimation technique that may be useful when more than one model instance is present. Another approach for multi model fitting is known as PEARL,&lt;ref&gt;Hossam Isack, Yuri Boykov (2012). "Energy-based Geometric Multi-Model Fitting". International Journal of Computer Vision 97 (2: 1): 23–147. doi:10.1007/s11263-011-0474-7.&lt;/ref&gt; which combines model sampling from data points as in RANSAC with iterative re-estimation of inliers and the multi-model fitting being formulated as an optimization problem with a global energy functional describing the quality of the overall solution.

==Applications==
The RANSAC algorithm is often used in [[computer vision]], e.g., to simultaneously solve the [[correspondence problem]] and estimate the [[fundamental matrix (computer vision)|fundamental matrix]] related to a pair of stereo cameras.

==Development and improvements==
Since 1981 RANSAC has become a fundamental tool in the [[computer vision]] and image processing community. In 2006, for the 25th anniversary of the algorithm, a workshop was organized at the International [[Conference on Computer Vision and Pattern Recognition]] (CVPR) to summarize the most recent contributions and variations to the original algorithm, mostly meant to improve the speed of the algorithm, the robustness and accuracy of the estimated solution and to decrease the dependency from user defined constants.

RANSAC can be sensitive to the choice of the correct noise threshold that defines which data points fit a model instantiated with a certain set of parameters. If such threshold is too large, then all the hypotheses tend to be ranked equally (good). On the other hand, when the noise threshold is too small, the estimated parameters tend to be unstable ( i.e. by simply adding or removing a datum to the set of inliers, the estimate of the parameters may fluctuate). To partially compensate for this undesirable effect, Torr et al. proposed two modification of RANSAC called MSAC (M-estimator SAmple and Consensus) and MLESAC (Maximum Likelihood Estimation SAmple and Consensus).&lt;ref&gt;P.H.S. Torr and A. Zisserman, MLESAC: A new robust estimator with application to estimating image geometry, Journal of Computer Vision and Image Understanding 78 (2000), no. 1, 138–156.&lt;/ref&gt; The main idea is to evaluate the quality of the consensus set ( i.e. the data that fit a model and a certain set of parameters) calculating its likelihood (whereas in the original formulation by Fischler and Bolles the rank was the cardinality of such set). An extension to MLESAC which takes into account the prior probabilities associated to the input dataset is proposed by Tordoff.&lt;ref&gt;B. J. Tordoff and D. W. Murray, Guided-MLESAC: Faster image transform estimation by using matching priors, IEEE Transactions on Pattern Analysis and Machine Intelligence 27 (2005), no. 10, 1523–1535.&lt;/ref&gt;  The resulting algorithm is dubbed Guided-MLESAC. Along similar lines, Chum proposed to guide the sampling procedure if some a priori information regarding the input data is known, i.e. whether a datum is likely to be an inlier or an outlier. The proposed approach is called PROSAC, PROgressive SAmple Consensus.&lt;ref&gt;Matching with PROSAC – progressive sample consensus, Proceedings of Conference on Computer Vision and Pattern Recognition (San Diego), vol. 1, June 2005, pp. 220–226&lt;/ref&gt;

Chum et al. also proposed a randomized version of RANSAC called R-RANSAC &lt;ref&gt;O. Chum and J. Matas, Randomized RANSAC with Td,d test, 13th British Machine Vision Conference, September 2002. http://www.bmva.org/bmvc/2002/papers/50/&lt;/ref&gt; to reduce the computational burden to identify a good CS. The basic idea is to initially evaluate the goodness of the currently instantiated model using only a reduced set of points instead of the entire dataset. A sound strategy will tell with high confidence when it is the case to evaluate the fitting of the entire dataset or when the model can be readily discarded. It is reasonable to think that the impact of this approach is more relevant in cases where the percentage of inliers is large. The type of strategy proposed by Chum et al. is called preemption scheme. Nistér proposed a paradigm called Preemptive RANSAC&lt;ref&gt;D. Nistér, Preemptive RANSAC for live structure and motion estimation, IEEE International Conference on Computer Vision (Nice, France), October 2003, pp. 199–206.&lt;/ref&gt; that allows real time robust estimation of the structure of a scene and of the motion of the camera. The core idea of the approach consists in generating a fixed number of hypothesis so that the
comparison happens with respect to the quality of the generated hypothesis rather than against some absolute quality metric.

Other researchers tried to cope with difficult situations where the noise scale is not known and/or multiple model instances are present. The first problem has been tackled in the work by Wang and Suter.&lt;ref&gt;H. Wang and D. Suter, Robust adaptive-scale parametric model estimation for computer vision., IEEE Transactions on Pattern Analysis and Machine Intelligence 26 (2004), no. 11, 1459–1474&lt;/ref&gt; Toldo et al. represent each datum with the characteristic function of the set of random models that fit the point. Then multiple models are revealed as clusters which group the points supporting the same model. The clustering algorithm, called J-linkage, does not require prior specification of the number of models, nor does it necessitate manual parameters tuning.&lt;ref&gt;R. Toldo and A. Fusiello, Robust multiple structures estimation with jlinkage, European Conference on Computer Vision (Marseille, France), October 2008, pp. 537–547.&lt;/ref&gt;

RANSAC has also been tailored for recursive state estimation applications, where the input measurements are corrupted by outliers and Kalman filter approaches, which rely on a Gaussian distribution of the measurement error, are doomed to fail. Such an approach is dubbed KALMANSAC.&lt;ref&gt;A. Vedaldi, H. Jin, P. Favaro, and S. Soatto, KALMANSAC: Robust filtering by consensus, Proceedings of the International Conference on Computer Vision (ICCV), vol. 1, 2005, pp. 633–640&lt;/ref&gt;

==Related methods==
* [[MLESAC]] (Maximum Likelihood Estimate SAmple Consensus) – [[maximum likelihood estimation|maximizes the likelihood]] that the data was generated from the sample-fitted model, e.g. a [[mixture model]] of inliers and outliers
* [[MAPSAC]] (Maximum A Posterior SAmple Consensus) – extends MLESAC to incorporate a [[prior probability]] of the parameters to be fitted and maximizes the [[posterior probability]]
* [[KALMANSAC]] – [[causal inference]] of the state of a [[dynamical system]]

== Notes ==
{{Reflist}}

==References==

* {{cite journal
|author1=Martin A. Fischler  |author2=Robert C. Bolles
 |lastauthoramp=yes | title=Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography
| journal=Comm. ACM
| volume=24
| pages=381–395
|date=June 1981
| doi=10.1145/358669.358692
| url=http://www.dtic.mil/dtic/tr/fulltext/u2/a460585.pdf
| issue=6
}}
*{{cite book
|author1=David A. Forsyth  |author2=Jean Ponce
 |lastauthoramp=yes | title=Computer Vision, a modern approach
| year=2003
| publisher=Prentice Hall
| isbn= 0-13-085198-1
}}
*{{cite book
| author=Richard Hartley and [[Andrew Zisserman]]
| title=Multiple View Geometry in Computer Vision
| year=2003
| publisher=Cambridge University Press
| edition=2nd
}}
* {{cite book |first=T. |last=Strutz| title=Data Fitting and Uncertainty (A practical introduction to weighted least squares and beyond) |publisher=2nd edition, Springer Vieweg |year=2016 |isbn=978-3-658-11455-8}}
* {{cite journal
|author1=P.H.S. Torr  |author2=D.W. Murray
 |lastauthoramp=yes | title=The Development and Comparison of Robust Methods for Estimating the Fundamental Matrix
| journal=International Journal of Computer Vision
| volume=24
| pages=271–300
| year=1997
| doi=10.1023/A:1007927408552
| issue=3
}}
*{{Cite journal
| author=Ondrej Chum
| title=Two-View Geometry Estimation by Random Sample and Consensus
| year=2005
| url=http://cmp.felk.cvut.cz/~chum/papers/Chum-PhD.pdf
| journal=PhD Thesis
| postscript=&lt;!--None--&gt;
}}
*{{Cite journal
|author1=Sunglok Choi |author2=Taemin Kim |author3=Wonpil Yu  |last-author-amp=yes | title=Performance Evaluation of RANSAC Family
| journal=In Proceedings of the British Machine Vision Conference (BMVC)
| year=2009
| url=http://www.bmva.org/bmvc/2009/Papers/Paper355/Paper355.pdf
}}

*{{Cite journal
|author1=Anders Hast |author2=Johan Nysjö |author3=Andrea Marchetti | title=Optimal RANSAC – Towards a Repeatable Algorithm for Finding the Optimal Set
| journal=Journal of WSCG
| volume=21 | issue = 1
| pages=21–30
| year=2013
| url=http://www.cb.uu.se/~aht/articles/A53-full.pdf
}}
*{{Cite journal
|author1=Hossam Isack |author2=Yuri Boykov | title=Energy-based Geometric Multi-Model Fitting
| journal=International Journal of Computer Vision
| volume=97 | issue = 2: 1
| pages=23–147
| year=2012
| url=http://www.csd.uwo.ca/~yuri/Papers/tr735.pdf
 | doi=10.1007/s11263-011-0474-7
}}



[[Category:Geometry in computer vision]]
[[Category:Statistical algorithms]]
[[Category:Statistical outliers]]
[[Category:Robust statistics]]
[[Category:Articles with example pseudocode]]
[[Category:SRI International]]
[[Category:Articles with example MATLAB/Octave code]]</text>
      <sha1>rws2hurygwmmoxei143hmu8msfshx3h</sha1>
    </revision>
  </page>
  <page>
    <title>Retiming</title>
    <ns>0</ns>
    <id>7770362</id>
    <revision>
      <id>786675589</id>
      <parentid>774962565</parentid>
      <timestamp>2017-06-20T22:16:54Z</timestamp>
      <contributor>
        <ip>80.3.12.4</ip>
      </contributor>
      <comment>/* Minimizing the clock period with network flow */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6797">{{Refimprove|date=November 2010}}
'''Retiming''' is the technique of moving the structural location of [[Latch (electronic)|latches]] or registers in a [[digital circuit]] to improve its performance, area, and/or [[power optimization (EDA)|power]] characteristics in such a way that preserves its functional behavior at its outputs.  Retiming was first described by [[Charles E. Leiserson]] and [[James B. Saxe]] in 1983.&lt;ref&gt;http://citeseer.ist.psu.edu/context/96547/0&lt;/ref&gt;

The technique uses a [[directed graph]] where the vertices represent asynchronous combinational blocks and the directed edges represent a series of registers or latches (the number of registers or latches can be zero). Each vertex has a value corresponding to the delay through the combinational circuit it represents. After doing this, one can attempt to optimize the circuit by pushing registers from output to input and vice versa - much like [[bubble pushing]].  Two operations can be used - deleting a register from each input of a vertex while adding a register to all outputs, and conversely adding a register to each input of vertex and deleting a register from all outputs. In all cases, if the rules are followed, the circuit will have the same functional behavior as it did before retiming.

==Formal description==

The initial formulation of the retiming problem as described by Leiserson and Saxe is as follows. Given a [[directed graph]] &lt;math&gt;G:=(V,E)&lt;/math&gt; whose vertices represent [[logic gates]] or combinational delay elements in a circuit, assume there is a directed edge &lt;math&gt;e:=(u,v)&lt;/math&gt; between two elements that are connected directly or through one or more registers.  Let the ''weight'' of each edge &lt;math&gt;w(e)&lt;/math&gt; be the number of registers present along edge &lt;math&gt;e&lt;/math&gt; in the initial circuit.  Let &lt;math&gt;d(v)&lt;/math&gt; be the [[propagation delay]] through vertex &lt;math&gt;v&lt;/math&gt;.  The goal in retiming is to compute an integer ''lag'' value &lt;math&gt;r(v)&lt;/math&gt; for each vertex such that the retimed weight &lt;math&gt;w_r(e):=w(e)+r(v)-r(u)&lt;/math&gt; of every edge is non-negative. There is a proof that this preserves the output functionality.&lt;ref name="one"&gt;C. E. Leiserson, J. B. Saxe, "Retiming Synchronous Circuitry," Algorithmica, Vol. 6, No. 1, pp. 5-35, 1991.&lt;/ref&gt;

===Minimizing the clock period with network flow===

The most common use of retiming is to minimize the [[clock period]].  A simple technique to optimize the clock period is to search for the minimum feasible period (e.g. using [[binary search]]).

The feasibility of a clock period &lt;math&gt;T&lt;/math&gt; can be checked in one of several ways.  The [[linear program]] below is feasible if and only if &lt;math&gt;T&lt;/math&gt; is a feasible clock period.  Let &lt;math&gt;W(u,v)&lt;/math&gt; be the minimum number of registers along any path from &lt;math&gt;u&lt;/math&gt; to &lt;math&gt;v&lt;/math&gt; (if such a path exists), and &lt;math&gt;D(u,v)&lt;/math&gt; is the maximum delay along any path from &lt;math&gt;u&lt;/math&gt; to &lt;math&gt;v&lt;/math&gt; with W(u,v) registers.  The dual of this program is a [[minimum cost circulation problem]], which can be solved efficiently as a network problem.  The limitations of this approach arise from the enumeration and size of the &lt;math&gt;W&lt;/math&gt; and &lt;math&gt;D&lt;/math&gt; matrices.

{| 
| Given 
| colspan="2" | &lt;math&gt;w(e), W(u,v), D(u,v)&lt;/math&gt; and a target clock period &lt;math&gt;T&lt;/math&gt;
|-
| Find 
| colspan="2" | &lt;math&gt;r(v):V \to \mathbb{Z}&lt;/math&gt;
|-
| Such that
|-
|
| &lt;math&gt;r(u) - r(v)&lt;/math&gt;
| &lt;math&gt;\le w(e)&lt;/math&gt;
|-
|
| &lt;math&gt;r(u) - r(v)&lt;/math&gt;
| &lt;math&gt;\le W(u,v) - 1&lt;/math&gt; if &lt;math&gt;D(u,v) &gt; T&lt;/math&gt;
|}

===Minimizing the clock period with MILP===

Alternatively, feasibility of a clock period &lt;math&gt;T&lt;/math&gt; can be expressed as a mixed-integer [[linear program]] (MILP).  A solution will exist and a valid lag function &lt;math&gt;r(v)&lt;/math&gt; will be returned if and only if the period is feasible.

{| 
| Given 
| colspan="2" | &lt;math&gt;w(e), d(v)&lt;/math&gt; and a target clock period &lt;math&gt;T&lt;/math&gt;
|-
| Find 
| colspan="2" | &lt;math&gt;r(v):V \to \mathbb{Z}&lt;/math&gt; and &lt;math&gt;R(v):V \to \mathcal{R}&lt;/math&gt;
|-
| Such that
|-
|
| &lt;math&gt;r(v) - R(V)&lt;/math&gt;
| &lt;math&gt;\le -d(v)/T&lt;/math&gt;
|-
|
| &lt;math&gt;R(v) - r(v)&lt;/math&gt;
| &lt;math&gt;\le 1&lt;/math&gt;
|-
|
| &lt;math&gt;r(u) - r(v)&lt;/math&gt;
| &lt;math&gt;\le w(e)&lt;/math&gt;
|-
|
| &lt;math&gt;R(u) - R(v)&lt;/math&gt;
| &lt;math&gt;\le w(e) - d(v)/T&lt;/math&gt;
|}

===Other formulations and extensions===

Alternate formulations allow the minimization of the register count and the minimization of the register count under a delay constraint.  The initial paper includes extensions that allow the consideration of fan-out sharing and a more general delay model.  Subsequent work has addressed the inclusion of register delays,&lt;ref name="two"&gt;K. N. Lalgudi, M. C. Papaefthymiou, {{doi-inline|10.1109/43.664222|Retiming edge-triggered circuits under general delay models}}, [[IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems]], vol.16, no.12, pp.1393-1408, Dec. 1997.&lt;/ref&gt; load-dependent delay models,&lt;ref name="two"/&gt; and hold constraints.&lt;ref name="three"&gt;M. C. Papaefthymiou, {{doi-inline|10.1145/288548.289060|Asymptotically efficient retiming under setup and hold constraints}}, IEEE/ACM International Conference on Computer-Aided Design, 1998.&lt;/ref&gt;

==Problems==

Retiming has found industrial use, albeit sporadic.  Its primary drawback is that the state encoding of the circuit is destroyed, making debugging, testing, and verification substantially more difficult.  Some retimings may also require complicated initialization logic to have the circuit start in an identical initial state.  Finally, the changes in the circuit's topology have consequences in other logical and physical synthesis steps that make [[design closure]] difficult.

==Alternatives==

Clock skew scheduling is a related technique for optimizing sequential circuits.  Whereas retiming relocates the structural position of the registers, clock skew scheduling moves their temporal position by scheduling the arrival time of the clock signals.  The lower bound of the achievable minimum clock period of both techniques is the maximum mean cycle time (i.e. the total combinational delay along any path divided by the number of registers along it).

==See also==
* [[Logic Synthesis]]
* [[Electronic Design Automation]]

==Notes==
&lt;references/&gt;

==References==
*{{cite journal|last1=Leiserson|first=1C. E. |first2=J. B. |last2=Saxe|year=1983|title=Optimizing Synchronous Systems|journal=Journal of VLSI and Computer Systems|volume=1|issue=1|pages=41–67}}

==External links==
* [http://people.csail.mit.edu/devadas/6.373/lectures/l10/ Presentation on retiming from MIT]
* [http://sites.google.com/site/mhutton1/2003_IWLS_BA_retime.pdf A Safe and Complete Gate-Level Register Retiming Algorithm]

[[Category:Timing in electronic circuits]]
[[Category:Formal methods]]</text>
      <sha1>fdmqwpvg06kgbh0tn7ke0sdot1fd9m3</sha1>
    </revision>
  </page>
  <page>
    <title>Richart E. Slusher</title>
    <ns>0</ns>
    <id>31717575</id>
    <revision>
      <id>783613858</id>
      <parentid>719978339</parentid>
      <timestamp>2017-06-03T14:09:13Z</timestamp>
      <contributor>
        <username>Chris the speller</username>
        <id>525927</id>
      </contributor>
      <minor/>
      <comment>/* top */replaced: Principal Research Scientist → principal research scientist, etc. using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2902">{{Infobox scientist
|name              = Richart E. Slusher
|image             =
|image_size        =
|alt               =
|caption           =
|birth_date        = 1938 &lt;!--{{birth date|yyyy|mm|dd}}--&gt;
|birth_place       = &lt;!--[[City, State]]--&gt;
|death_date        =
|death_place       =
|residence         =
|citizenship       =
|nationality       = [[People of the United States|American]]
|ethnicity         =
|fields            =
|workplaces        = [[Georgia Tech Research Institute]]&lt;br/&gt;
[[Bell Laboratories]]
|alma_mater        = [[University of California at Berkeley]] (PhD)
|doctoral_advisor  =
|academic_advisors =
|doctoral_students =
|notable_students  =
|known_for         = [[Optics]]&lt;br/&gt;[[Quantum information science]]
|author_abbrev_bot =
|author_abbrev_zoo =
|influences        =
|influenced        =
|awards            =
|footnotes         =
}}

'''Richart Elliott Slusher''' (born 1938) is a regents researcher and a principal research scientist at the [[Georgia Tech Research Institute]], and the director of the [[Georgia Tech Quantum Institute]].

==Education==
Slusher received a Ph.D. in physics from the [[University of California at Berkeley]] in 1965.&lt;ref name="about"&gt;{{cite web|url=http://www.gtqi.gatech.edu/peopleGTRI.shtml?personId=slusher|title=Richart E. Slusher|publisher=[[Georgia Tech Quantum Institute]]|accessdate=2011-05-08}}&lt;/ref&gt;

==Work==
Slusher worked at [[Bell Laboratories]] from 1965 to 2007, where he directed a research department focused on optical and quantum device physics from 1977 to 2005. Since 2005, he has worked at the [[Georgia Tech Research Institute]].&lt;ref name="about"/&gt;

==Awards==
Slusher received the 1989 [[Einstein Prize for Laser Science]], the 1995 [[Arthur L. Schawlow Prize in Laser Science]] from the [[American Physical Society]] and the 2006 [[Max Born Award]] from the [[Optical Society of America]].&lt;ref name="about"/&gt;&lt;ref&gt;{{cite web|url=http://www.aps.org/programs/honors/prizes/prizerecipient.cfm?last_nm=Slusher&amp;first_nm=Richart&amp;year=1995|title=1995 Arthur L. Schawlow Prize in Laser Science Recipient|publisher=[[American Physical Society]]|accessdate=2011-05-08}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.osa.org/awards_and_grants/awards/award_description/maxborn/default.aspx|title=Max Born Award|publisher=[[Optical Society of America]]|accessdate=2011-05-08}}&lt;/ref&gt;

==Publications==
{{Expand section|date=May 2011}}

==References==
{{reflist}}

==External links==
*[http://www.gtqi.gatech.edu/peopleGTRI.shtml Dick Slusher's page at Georgia Tech]
*[http://www.gtri.gatech.edu/ GTRI official website]

{{Authority control}}
{{DEFAULTSORT:Slusher, Richart E.}}
[[Category:University of California, Berkeley alumni]]
[[Category:Georgia Tech Research Institute people]]
[[Category:Georgia Institute of Technology faculty]]
[[Category:Theoretical computer scientists]]
[[Category:Living people]]
[[Category:1938 births]]</text>
      <sha1>l9bz3bfhnawhlumn3h3eb95i7rwec67</sha1>
    </revision>
  </page>
  <page>
    <title>Scott core theorem</title>
    <ns>0</ns>
    <id>1258371</id>
    <revision>
      <id>858405795</id>
      <parentid>690489926</parentid>
      <timestamp>2018-09-06T23:25:28Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: Journal of the London Mathematical Society. Second Series → Journal of the London Mathematical Society |series=Second Series</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1808">In [[mathematics]], the '''Scott core theorem''' is a theorem about the finite presentability of [[fundamental group]]s of [[3-manifold]]s due to [[G. Peter Scott]], {{harv|Scott|1973}}.  The precise statement is as follows:

Given a 3-manifold (not necessarily [[compact manifold|compact]]) with [[finitely generated group|finitely generated]] fundamental group, there is a compact three-dimensional [[submanifold]], called the '''compact core''' or '''Scott core''', such that its [[inclusion map]] induces an [[isomorphism]] on fundamental groups.  In particular, this means a finitely generated 3-manifold group is [[presentation of a group|finitely presentable]].

A simplified proof is given in {{harv|Rubinstein|Swarup|1990}}, and a stronger uniqueness statement is proven in {{harv|Harris|Scott|1996}}.

==References==
*{{Citation | last1=Harris | first1=Luke | last2=Scott | first2=G. Peter | title=The uniqueness of compact cores for 3-manifolds | url=http://projecteuclid.org/getRecord?id=euclid.pjm/1102366188 |mr=1379290 | year=1996 | journal=[[Pacific Journal of Mathematics]] | issn=0030-8730 | volume=172 | issue=1 | pages=139–150 | doi = 10.2140/pjm.1996.172.139 }}
*{{Citation | last1=Rubinstein | first1=J. H. | last2=Swarup | first2=G. A. | title=On Scott's core theorem | doi=10.1112/blms/22.5.495 |mr=1082023 | year=1990 | journal=The Bulletin of the London Mathematical Society | volume=22 | issue=5 | pages=495–498}}
*{{Citation | last1=Scott | first1=G. Peter | title=Compact submanifolds of 3-manifolds | doi=10.1112/jlms/s2-7.2.246 |mr=0326737 | year=1973 | journal=Journal of the London Mathematical Society |series=Second Series | volume=7 | pages=246–250 | issue=2}}

[[Category:3-manifolds]]
[[Category:Group theory]]
[[Category:Theorems in topology]]


{{topology-stub}}</text>
      <sha1>f2lph2hqrfjyg8gdz3lqh1jutm1ahld</sha1>
    </revision>
  </page>
  <page>
    <title>Slope</title>
    <ns>0</ns>
    <id>29368</id>
    <revision>
      <id>871357297</id>
      <parentid>871309166</parentid>
      <timestamp>2018-11-30T14:39:46Z</timestamp>
      <contributor>
        <username>Paul August</username>
        <id>87355</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/2600:8801:2C07:2500:55EE:34DA:1BAD:FCF6|2600:8801:2C07:2500:55EE:34DA:1BAD:FCF6]] ([[User talk:2600:8801:2C07:2500:55EE:34DA:1BAD:FCF6|talk]]) to last version by Philipnelson99</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15539">{{About|the mathematical term}}
{{for|the grade (incline or gradient or pitch or slope) of any physical feature|Grade (slope)}}
[[File:Wiki slope in 2d.svg|right|thumb|Slope: &lt;math&gt;m=\left( \frac{\Delta y}{\Delta x} \right)=\tan( \theta )  ...&lt;/math&gt;]]
In [[mathematics]], the '''slope''' or '''gradient''' of a [[Line (mathematics)|line]] is a number that describes both the ''direction'' and the ''steepness'' of the line.&lt;ref&gt;{{cite web|url=http://web.cortland.edu/matresearch/OxfordDictionaryMathematics.pdf |title=Oxford Concise Dictionary of Mathematics, Gradient |first1=C. |last1=Clapham |first2=J. |last2=Nicholson |publisher=Addison-Wesley |year=2009 |page=348 |accessdate=1 September 2013 |deadurl=yes |archiveurl=https://web.archive.org/web/20131029203826/http://web.cortland.edu/matresearch/OxfordDictionaryMathematics.pdf |archivedate=29 October 2013 |df= }}&lt;/ref&gt; Slope is often denoted by the letter ''m''; there is no clear answer to the question why the letter ''m'' is used for slope, but it might be from the "m for multiple" in the equation of a straight line "y = mx + b" or "y = mx + c".&lt;ref&gt;{{cite web|last=Weisstein|first=Eric W.|title=Slope|publisher=MathWorld--A Wolfram Web Resource|url=http://mathworld.wolfram.com/Slope.html|accessdate=30 October 2016|deadurl=no|archiveurl=https://web.archive.org/web/20161206182915/http://mathworld.wolfram.com/Slope.html|archivedate=6 December 2016|df=}}&lt;/ref&gt;

Slope is calculated by finding the ratio of the "vertical change" to the "horizontal change" between (any) two distinct points on a line.  Sometimes the ratio is expressed as a quotient ("rise over run"), giving the same number for every two distinct points on the same line.  A line that is decreasing has a negative "rise".  The line may be practical - as set by a road surveyor, or in a diagram that models a road or a roof either as a description or as a plan.

The ''steepness'', incline, or grade of a line is measured by the [[absolute value]] of the slope. A slope with a greater absolute value indicates a steeper line. The ''direction'' of a [[Line (mathematics)|line]] is either increasing, decreasing, horizontal or vertical. 
*A line is '''increasing''' if it goes '''up''' from left to right. The slope is '''positive''', i.e. &lt;math&gt;m&gt;0&lt;/math&gt;.
*A line is '''decreasing''' if it goes '''down''' from left to right. The slope is '''negative''', i.e. &lt;math&gt;m&lt;0&lt;/math&gt;.
*If a line is horizontal the slope is '''zero'''. This is a [[constant function]].
*If a line is vertical the slope is ''undefined'' (see below).

The rise of a road between two points is the difference between the altitude of the road at those two points, say ''y''&lt;sub&gt;1&lt;/sub&gt; and ''y''&lt;sub&gt;2&lt;/sub&gt;, or in other words, the rise is (''y''&lt;sub&gt;2&lt;/sub&gt; − ''y''&lt;sub&gt;1&lt;/sub&gt;) = Δ''y''. For relatively short distances - where the earth's curvature may be neglected, the run is the difference in distance from a fixed point measured along a level, horizontal line, or in other words, the run is (''x''&lt;sub&gt;2&lt;/sub&gt; − ''x''&lt;sub&gt;1&lt;/sub&gt;) = Δ''x''. Here the slope of the road between the two points is simply described as the ratio of the altitude change to the horizontal distance between any two points on the line.

In mathematical language, the slope ''m'' of the line is
:&lt;math&gt;m=\frac{y_2-y_1}{x_2-x_1}.&lt;/math&gt;

The concept of slope applies directly to [[grade (slope)|grade]]s or [[gradient]]s in [[geography]] and [[civil engineering]]. Through [[trigonometry]], the slope ''m'' of a line is related to its angle of incline ''θ'' by the [[Trigonometric functions#tangent|tangent function]]
:&lt;math&gt;m = \tan (\theta)&lt;/math&gt;

Thus, a 45° rising line has a slope of +1 and a 45° falling line has a slope of&amp;nbsp;&amp;minus;1.

As a generalization of this practical description, the mathematics of [[differential calculus]] defines the slope of a [[curve]] at a point as the slope of the [[Tangent|tangent line]] at that point. When the curve is given by a series of points in a diagram or in a list of the coordinates of points, the slope may be calculated not at a point but between any two given points. When the curve is given as a continuous function, perhaps as an algebraic formula, then the differential calculus provides rules giving a formula for the slope of the curve at any point in the middle of the curve.

This generalization of the concept of slope allows very complex constructions to be planned and built that go well beyond static structures that are either horizontals or verticals, but can change in time, move in curves, and change depending on the rate of change of other factors. Thereby, the simple idea of slope becomes one of the main basis of the modern world in terms of both technology and the built environment.

== Definition ==

[[File:Slope of lines illustrated.jpg|thumb|400px|right|Slope illustrated for ''y''&amp;nbsp;=&amp;nbsp;(3/2)''x''&amp;nbsp;&amp;minus;&amp;nbsp;1. Click on to enlarge]]
[[File:Gradient of a line in coordinates from -12x+2 to +12x+2.gif|400px|thumbnail|right|Slope of a line in coordinates system, from f(x)=-12x+2 to f(x)=12x+2]]
The slope of a line in the plane containing the ''x'' and ''y'' axes is generally represented by the letter ''m'', and is defined as the change in the ''y'' coordinate divided by the corresponding change in the ''x'' coordinate, between two distinct points on the line. This is described by the following equation:

:&lt;math&gt;m = \frac{\Delta y}{\Delta x} = \frac{\text{vertical} \, \text{change} }{\text{horizontal} \, \text{change} }= \frac{\text{rise}}{\text{run}}.&lt;/math&gt;
(The Greek letter ''[[delta (letter)|delta]]'', Δ, is commonly used in mathematics to mean "difference" or "change".)

Given two points (''x''&lt;sub&gt;1&lt;/sub&gt;,''y''&lt;sub&gt;1&lt;/sub&gt;) and (''x''&lt;sub&gt;2&lt;/sub&gt;,''y''&lt;sub&gt;2&lt;/sub&gt;), the change in ''x'' from one to the other is {{nowrap|''x''&lt;sub&gt;2&lt;/sub&gt; − ''x''&lt;sub&gt;1&lt;/sub&gt;}} (''run''), while the change in ''y'' is {{nowrap|''y''&lt;sub&gt;2&lt;/sub&gt; − ''y''&lt;sub&gt;1&lt;/sub&gt;}} (''rise''). Substituting both quantities into the above equation generates the formula:
:&lt;math&gt;m = \frac{y_2 - y_1}{x_2 - x_1}.&lt;/math&gt;
The formula fails for a vertical line, parallel to the ''y'' axis (see [[Division by zero]]), where the slope can be taken as [[infinity|infinite]], so the slope of a vertical line is considered undefined.

=== Examples ===
Suppose a line runs through two points: ''P''&amp;nbsp;=&amp;nbsp;(1,&amp;nbsp;2) and ''Q''&amp;nbsp;=&amp;nbsp;(13,&amp;nbsp;8). By dividing the difference in ''y''-coordinates by the difference in ''x''-coordinates, one can obtain the slope of the line:
:&lt;math&gt;m = \frac{\Delta y}{\Delta x} = \frac{y_2 - y_1}{x_2 - x_1} = \frac{8 - 2}{13 - 1} = \frac{6}{12} = \frac{1}{2}&lt;/math&gt;. 
:Since the slope is positive, the direction of the line is increasing. Since |m|&amp;lt;1, the incline is not very steep (incline &amp;lt;45&amp;deg;).

As another example, consider a line which runs through the points (4,&amp;nbsp;15) and (3,&amp;nbsp;21). Then, the slope of the line is 
:&lt;math&gt;m = \frac{ 21 - 15}{3 - 4} = \frac{6}{-1} = -6.&lt;/math&gt;
:Since the slope is negative, the direction of the line is decreasing. Since |m|&amp;gt;1, this decline is fairly steep (decline &amp;gt;45&amp;deg;).

==Algebra and geometry==
*If ''y'' is a [[linear function]] of ''x'', then the coefficient of ''x'' is the slope of the line created by plotting the function. Therefore, if the equation of the line is given in the form
::&lt;math&gt;y = mx + k &lt;/math&gt;
:then ''m'' is the slope. This form of a line's equation is called the ''slope-intercept form'', because ''k'' can be interpreted as the [[y-intercept]] of the line, that is, the ''y''-coordinate where the line intersects the ''y''-axis.

*If the slope ''m'' of a line and a point (''x''&lt;sub&gt;1&lt;/sub&gt;,''y''&lt;sub&gt;1&lt;/sub&gt;) on the line are both known, then the equation of the line can be found using the [[Linear equation#Point–slope form|point-slope formula]]:
::&lt;math&gt;y - y_1 = m(x - x_1).&lt;/math&gt;

*The slope of the line defined by the [[linear equation]]
::&lt;math&gt;ax + by +c = 0 &lt;/math&gt;  
:is
::&lt;math&gt;-\frac {a}{b} &lt;/math&gt;.

*Two lines are [[parallel (geometry)|parallel]] if and only if they are not the same line (coincident) and either their slopes are equal or they both are vertical and therefore both have undefined slopes. Two lines are [[perpendicular]] if the product of their slopes is&amp;nbsp;&amp;minus;1 or one has a slope of 0 (a horizontal line) and the other has an undefined slope (a vertical line).
*The angle θ between &amp;minus;90&amp;deg; and 90&amp;deg; that a line makes with the ''x''-axis is related to the slope ''m'' as follows:
::&lt;math&gt;m = \tan (\theta)&lt;/math&gt;  
:and 
::&lt;math&gt;\theta = \arctan (m)&lt;/math&gt;  &amp;nbsp; (this is the inverse function of tangent; see [[inverse trigonometric functions]]).

===Examples===
For example, consider a line running through the points (2,8) and (3,20). This line has a slope, {{math|''m''}}, of 
:&lt;math&gt;\frac {(20 - 8)}{(3 - 2)} \; = 12. &lt;/math&gt;
One can then write the line's equation, in point-slope form:
:&lt;math&gt;y - 8 = 12(x - 2) = 12x - 24 &lt;/math&gt;
or: 
:&lt;math&gt;y = 12x - 16. &lt;/math&gt;
The angle θ between -90&amp;deg; and 90&amp;deg; that this line makes with the {{math|''x''}}-axis is 
:&lt;math&gt;\theta=\arctan (12) \approx 85.2^{\circ} \,.&lt;/math&gt;

Consider the two lines:  {{math|1=''y'' = −3''x'' + 1}}  and {{math|1=''y'' = −3''x'' − 2}}. Both lines have slope {{math|1=''m'' = −3}}. They are not the same line. So they are parallel lines.

Consider the two lines  {{math|1=''y'' = −3''x'' + 1}} and {{math|1=''y'' = {{sfrac|''x''|3}} − 2}}. The slope of the first line is {{math|1=''m''&lt;sub&gt;1&lt;/sub&gt; = −3}}. The slope of the second line is {{math|1=''m''&lt;sub&gt;2&lt;/sub&gt; = {{sfrac|1|3}}}}. The product of these two slopes is −1. So these two lines are perpendicular.

== Statistics ==
In [[Statistics|statistical mathematics]], the gradient of the line of best fit for a given distribution of data which is linear, numerical, and free of outliers, is usually written as &lt;math&gt;b = \frac{rs_y}{s_x}&lt;/math&gt;, where &lt;math&gt;b&lt;/math&gt; is defined as the gradient (in statistics), &lt;math&gt;r&lt;/math&gt; is [[Pearson correlation coefficient|Pearson's correlation coefficient]], &lt;math&gt;s_y&lt;/math&gt; is the [[standard deviation]] of the y-values and &lt;math&gt;s_x&lt;/math&gt; is the [[standard deviation]] of the x-values.&lt;ref&gt;{{Cite book|title=Further Mathematics Units 3&amp;4 VCE (Revised)|last=|first=|publisher=Cambridge Senior Mathematics|year=2016|isbn=9781316616222|location=|pages=|quote=|via=Physical Copy}}&lt;/ref&gt;

In this equation &lt;math&gt;y=a+bx&lt;/math&gt; for the [[Least squares regression|least-squares regression line]], &lt;math&gt;b&lt;/math&gt; is the slope and &lt;math&gt;a&lt;/math&gt; is the intercept.

== Slope of a road or railway ==
:''Main articles: [[Grade (slope)]], [[Grade separation]]''
There are two common ways to describe the steepness of a [[road]] or [[Rail tracks|railroad]]. One is by the angle between 0&amp;deg; and 90&amp;deg; (in degrees), and the other is by the slope in a percentage. See also [[steep grade railway]] and [[rack railway]].

The formulae for converting a slope given as a percentage into an angle in degrees and vice versa are: 
::&lt;math&gt;\text{angle} = \arctan \left( \frac{\text{slope}}{100\%} \right)&lt;/math&gt;  &amp;nbsp;, (this is the inverse function of tangent; see [[trigonometry]])
:and
::&lt;math&gt;\mbox{slope} = 100\% \cdot \tan( \mbox{angle}),&lt;/math&gt;
where ''angle'' is in degrees and the trigonometric functions operate in degrees. For example, a slope of 100[[Percent sign|%]] or 1000[[Per mil|‰]] is an angle of 45°.

A third way is to give one unit of rise in say 10, 20, 50 or 100 horizontal units, e.g. 1:10. 1:20, 1:50 or 1:100 (or ''"1 in 10"'', ''"1 in 20"'' etc.) Note that 1:10 is steeper than 1:20. For example, steepness of 20% means 1:5 or an incline with angle 11,3&amp;deg;.

Roads and railways have both longitudinal slopes and cross slopes.

&lt;gallery&gt;
File:Nederlands verkeersbord J6.svg|Slope warning sign in the [[Netherlands]]
File:Znak A-23.svg|Slope warning sign in [[Poland]]
File:Skloník-klesání.jpg|A 1371-meter distance of a railroad with a 20[[Per mil|‰]] slope. [[Czech Republic]]
File:Railway gradient post.jpg|Steam-age railway gradient post indicating a slope in both directions at [[Meols railway station]], [[United Kingdom]]
&lt;/gallery&gt;

==Calculus==
[[File:Tangent function animation.gif|right|frame|At each point, the [[derivative]] is the slope of a [[Line (geometry)|line]] that is [[tangent]] to the [[curve]] at that point. Note: the derivative at the point A is [[positive number|positive]] where green and dash-dot, [[negative number|negative]] where red and dashed, and [[zero (number)|zero]] where black and solid.]]
The concept of a slope is central to [[differential calculus]]. For non-linear functions, the rate of change varies along the curve. The [[derivative]] of the function at a point is the slope of the line [[tangent]] to the curve at the point, and is thus equal to the rate of change of the function at that point.

If we let Δ''x'' and Δ''y'' be the distances (along the ''x'' and ''y'' axes, respectively) between two points on a curve, then the slope given by the above definition,
:&lt;math&gt;m = \frac{\Delta y}{\Delta x}&lt;/math&gt;,

is the slope of a [[secant line]] to the curve. For a line, the secant between any two points is the line itself, but this is not the case for any other type of curve.

For example, the slope of the secant intersecting ''y'' = ''x''&lt;sup&gt;2&lt;/sup&gt; at (0,0) and (3,9) is 3. (The slope of the tangent at {{nowrap|1=x = {{frac|3|2}}}} is also 3—''a'' consequence of the [[mean value theorem]].)

By moving the two points closer together so that Δ''y'' and Δ''x'' decrease, the secant line more closely approximates a tangent line to the curve, and as such the slope of the secant approaches that of the tangent. Using [[differential calculus]], we can determine the [[limit of a function|limit]], or the value that Δ''y''/Δ''x'' approaches as Δ''y'' and Δ''x'' get closer to [[zero]]; it follows that this limit is the exact slope of the tangent. If ''y'' is dependent on ''x'', then it is sufficient to take the limit where only Δ''x'' approaches zero. Therefore, the slope of the tangent is the limit of Δ''y''/Δ''x'' as Δ''x'' approaches zero, or ''dy''/''dx''. We call this limit the [[derivative (calculus)|derivative]].

:&lt;math&gt;\frac{dy}{dx} = \lim_{\Delta x \to 0}\frac{\Delta y}{\Delta x}&lt;/math&gt;

Its value at a point on the function gives us the slope of the tangent at that point. For example, let ''y''=''x''&lt;sup&gt;2&lt;/sup&gt;. A point on this function is (-2,4). The derivative of this function is &lt;sup&gt;d''y''&lt;/sup&gt;/&lt;sub&gt;d''x''&lt;/sub&gt;=2''x''. So the slope of the line tangent to ''y'' at (-2,4) is 2&amp;middot;(-2) = -4. The equation of this tangent line is: ''y''-4=(-4)(''x''-(-2)) or ''y'' = -4''x'' - 4.

==Other generalizations==
The concept of slope can be generalized to functions of more than one variable and is more often referred to as [[gradient]].

==See also==
* [[Euclidean distance]]
* [[Inclined plane]]
* [[Linear function (calculus)|Linear function]]
* [[Line of greatest slope]]
* [[Trigonometric function#Slope definitions|Slope definitions]]
* [[Theil–Sen estimator]], a line with the [[median]] slope among a set of sample points

==References==
{{reflist}}

== External links ==
{{Wiktionary}}
*{{cite web | url=http://www.mathopenref.com/coordslope.html| title =Slope of a Line (Coordinate Geometry)| publisher =Math Open Reference |year=2009 |accessdate=30 October 2016 }} interactive

[[Category:Elementary mathematics]]
[[Category:Analytic geometry]]
[[Category:Ratios]]</text>
      <sha1>t7idl37hj6nur2m8ujycaf3lqfy1fdy</sha1>
    </revision>
  </page>
  <page>
    <title>The Construction and Principal Uses of Mathematical Instruments</title>
    <ns>0</ns>
    <id>26041032</id>
    <revision>
      <id>832677232</id>
      <parentid>832677186</parentid>
      <timestamp>2018-03-27T11:18:51Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>/* Bibliography */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4611">{{Infobox book
| name             = The Construction and Principal Uses of Mathematical Instruments
| title_orig       = Traité de la construction et des principaux usages des instrumens de mathématique
| translator       = Edmund Stone
| image            = Houghton FC7 B5222 Eg723s - Nicolas Bion.jpg
| caption    = Illustration, labeled plate IX
| author           = Nicholas Bion
| illustrator      = 
| cover_artist     = 
| country          = France
| language         = French
| series           = 
| subject          = Mathematical instruments Early works to 1800
| genre            = 
| publisher        = Paris
| pub_date         = 1709
| english_pub_date = 1723
| media_type       = Print
| pages            = [8] p., 347 p., [5], [28] leaves of plates
| isbn             = 
| oclc             = 48599327
| dewey            = 
| congress         = 
| preceded_by      = 
| followed_by      = 
}}

'''''The Construction and Principal Uses of Mathematical Instruments''''' ({{lang-fr|Traité de la construction et des principaux usages des instrumens de mathématique}}) is a [[book]] by Nicholas Bion, first [[publish]]ed in 1709.&lt;ref name=WorldCat /&gt; It was [[translate]]d into English in 1723 by [[Edmund Stone]].&lt;ref name=EdmundStoneBio /&gt;

It was described as "the most famous book devoted to instruments" by [[History of science|historian of science]] [[David M. Knight]].&lt;ref name=DavidKnight /&gt;

==Nicholas Bion&lt;!--'Nicholas Bion' redirects here--&gt;==

'''Nicholas Bion'''&lt;!--boldface per WP:R#PLA--&gt; ({{lang-fr|Nicolas Bion}} {{IPA-fr|bjɔ̃|}}; 1652–1733)&lt;ref name=BionBio /&gt; was a French [[Scientific instrument|instrument]] maker and [[author]] with [[workshops]] in [[Paris]]. He was king’s [[engineer]] for mathematical instruments. He died in Paris in 1733 aged 81.

===Bibliography===
Bion is [[author]] of the following:&lt;ref name=BionBio /&gt;
*''L'usage des Globes Célestes et Terrestres et des sphères suivant les differents systèmes du Monde'' (Amsterdam, 1700)
*''Usage des Astrolabes''
* ''Traité de la construction et des principaux usages des instrumens de mathématique'' (Paris, 1709) [https://books.google.com/books?id=hCBsMtXEsx4C&amp;dq= (online version)]

==References==
{{reflist|refs=
&lt;ref name=WorldCat&gt;{{cite web|url=http://www.worldcat.org/oclc/48599327?referer=di&amp;ht=edition|title=Traité de la construction et des principaux usages des instrumens de mathematique. : Avec les figures necessaires pour l'intelligence de ce traité ...|work=[[WorldCat]]|publisher=[[OCLC Online Computer Library Center, Inc.]]|accessdate=2010-02-02}}&lt;/ref&gt;
&lt;ref name=EdmundStoneBio&gt;{{cite web|url=http://www-history.mcs.st-and.ac.uk/Biographies/Stone_Edmund.html|title=Stone_Edmund biography|last=Craik|first=Alex D D|date=January 2004|work=[[MacTutor History of Mathematics archive]]|publisher=[[University of St Andrews]] Scotland|accessdate=2010-02-02}}&lt;/ref&gt;
&lt;ref name=DavidKnight&gt;{{cite book|last=Knight|first=David M.|authorlink=David M. Knight|title=Sources for the history of science 1660-1914|page=202|publisher=The Sources of History Ltd|year=1975|location=London|url=https://books.google.com/books?id=aqM5AAAAIAAJ&amp;pg=PA202|accessdate=2009-02-02}}&lt;/ref&gt;
&lt;ref name=BionBio&gt;{{cite book|title=Bibliographical History of Electricity and Magnetism|last=Mottelay|first=Paul Fleury|year=2008|publisher=Read Books|isbn=1-4437-2844-6 |page=148|url=https://books.google.com/books?id=9vzti90Q8i0C&amp;pg=PA148|accessdate=2009-02-02}}&lt;/ref&gt;
}}

== Further reading ==
* {{cite encyclopedia
  | last = 
  | first = 
  | title = 
  | encyclopedia = [[Dictionary of Scientific Biography|Complete Dictionary of Scientific Biography]]
  | volume = 1
  | pages =  
  | publisher = Charles Scribner's Sons
  | location = Detroit
  | year = 2008
  | isbn = 978-0-684-31559-1
 }}

* {{cite book|last=Kern|first=Ralf|title=Wissenschaftliche Instrumente in ihrer Zeit. Vom 15. – 19. Jahrhundert|publisher=Köln: König, Walther|year=2010|ISBN=978-3-86560-772-0}}

==External links==
*[http://research.microsoft.com/en-us/um/people/gbell/cybermuseum_files/bell_book_files/books.htm Bell Book Collection] at the Microsoft Cybermuseum
*[http://www.sil.si.edu/digitalcollections/hst/scientific-identity/fullsize/SIL14-B4-04a.jpg Portrait of Nicholas Bion]

{{authoritycontrol}}
{{DEFAULTSORT:Construction and Principal Uses of Mathematical Instruments}}
[[Category:1709 books]]
[[Category:1709 in science]]
[[Category:French non-fiction books]]
[[Category:Engineering books]]
[[Category:Mathematics books]]
[[Category:18th-century French literature]]


{{engineering-book-stub}}
{{mathematics-lit-stub}}</text>
      <sha1>pdg943myuvk9fg430q3wyqqdcw25s8u</sha1>
    </revision>
  </page>
  <page>
    <title>Trémaux tree</title>
    <ns>0</ns>
    <id>30247317</id>
    <revision>
      <id>847808514</id>
      <parentid>847805142</parentid>
      <timestamp>2018-06-27T22:36:33Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>Undid revision 847805142 by [[Special:Contributions/213.160.107.106|213.160.107.106]] ([[User talk:213.160.107.106|talk]]) important to clarify that the ancestor/descendant relation is defined using the tree not (somehow) from the graph</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15493">In [[graph theory]], a '''Trémaux tree''' of an [[undirected graph]] ''G'' is a [[spanning tree]] of ''G'', rooted at one of its vertices, with the property that every two adjacent vertices in ''G'' are related to each other as an ancestor and descendant in the tree. All [[depth-first search|depth-first search trees]] and all [[Hamiltonian path]]s are Trémaux trees.
Trémaux trees are named after Charles Pierre Trémaux, a 19th-century French author who used a form of depth-first search as a strategy for [[Maze solving algorithm|solving mazes]].&lt;ref&gt;{{citation|title=Graph Algorithms|first=Shimon|last=Even|authorlink=Shimon Even|edition=2nd|publisher=Cambridge University Press|year=2011|isbn=978-0-521-73653-4|pages=46–48|url=https://books.google.com/books?id=m3QTSMYm5rkC&amp;pg=PA46}}.&lt;/ref&gt;&lt;ref&gt;{{citation|title=Algorithms in C++: Graph Algorithms|first=Robert|last=Sedgewick|edition=3rd|publisher=Pearson Education|year=2002|isbn=978-0-201-36118-6|url=https://books.google.com/books?id=0rLN_tcvD-IC&amp;pg=PT149|pages=149–157}}.&lt;/ref&gt; They have also been called '''normal spanning trees''', especially in the context of infinite graphs.&lt;ref name="soukoup"/&gt;

In finite graphs, although depth-first search itself is inherently sequential, Trémaux trees can be constructed by a randomized parallel algorithm in the complexity class [[NC (complexity)|RNC]]. They can be used to define the [[tree-depth]] of a graph, and as part of the [[left-right planarity test]] for testing whether a graph is a [[planar graph]].
A characterization of Trémaux trees in the monadic second-order [[logic of graphs]] allows graph properties involving [[orientation (graph theory)|orientations]] to be recognized efficiently for graphs of bounded [[treewidth]] using [[Courcelle's theorem]].

Not every infinite graph has a Trémaux tree, and the graphs that do have them can be characterized by their [[forbidden graph characterization|forbidden minor]]s.
A Trémaux tree exists in every graph with countably many vertices, even when an infinite form of depth-first search would not succeed in exploring every vertex of the graph.
In an infinite graph, a Trémaux tree must have exactly one infinite path for each [[End (graph theory)|end]] of the graph, and the existence of a Trémaux tree characterizes the graphs whose topological completions, formed by adding a point at infinity for each end, are [[metric space]]s.

==Example==
In the graph shown below, the tree with edges 1–3, 2–3, and 3–4 is a Trémaux tree when it is rooted at vertex&amp;nbsp;1 or vertex&amp;nbsp;2: every edge of the graph belongs to the tree except for the edge 1–2, which (for these choices of root) connects an ancestor-descendant pair.
[[File:Undirected graph.svg|center]]
However, rooting the same tree at vertex&amp;nbsp;3 or vertex&amp;nbsp;4 produces a rooted tree that is not a Trémaux tree, because with this root 1 and 2 are no longer ancestor and descendant.

==In finite graphs==
===Existence===
Every finite [[connected graph|connected]] [[undirected graph]] has at least one Trémaux tree. One can construct such a tree by performing a [[depth-first search]] and connecting each vertex (other than the starting vertex of the search) to the earlier vertex from which it was discovered. The tree constructed in this way is known as a depth-first search tree. If ''uv'' is an arbitrary edge in the graph, and ''u'' is the earlier of the two vertices to be reached by the search, then ''v'' must belong to the subtree descending from ''u'' in the depth-first search tree, because the search will necessarily discover ''v'' while it is exploring this subtree, either from one of the other vertices in the subtree or, failing that, from ''u'' directly. Every finite Trémaux tree can be generated as a depth-first search tree: If ''T'' is a Trémaux tree of a finite graph, and a depth-first search explores the children in ''T'' of each vertex prior to exploring any other vertices, it will necessarily generate ''T'' as its depth-first search tree.

===Parallel construction===
{{unsolved|computer science|Is there a deterministic parallel ''NC'' algorithm for constructing Trémaux trees?}}
It is [[P-complete]] to find the Trémaux tree that would be found by a sequential depth-first search algorithm, in which the neighbors of each vertex are searched in order by their identities.&lt;ref&gt;{{citation
 | last = Reif | first = John H. | authorlink = John Reif
 | doi = 10.1016/0020-0190(85)90024-9
 | issue = 5
 | journal = [[Information Processing Letters]]
 | mr = 801987
 | pages = 229–234
 | title = Depth-first search is inherently sequential
 | volume = 20
 | year = 1985}}.&lt;/ref&gt; Nevertheless it is possible to find a different Trémaux tree by a randomized [[parallel algorithm]], showing that the construction of Trémaux trees belongs to the complexity class [[NC (complexity)|RNC]].&lt;ref&gt;{{citation
 | last1 = Aggarwal | first1 = A.
 | last2 = Anderson | first2 = R. J.
 | doi = 10.1007/BF02122548
 | issue = 1
 | journal = [[Combinatorica]]
 | mr = 951989
 | pages = 1–12
 | title = A random ''NC'' algorithm for depth first search
 | volume = 8
 | year = 1988}}.&lt;/ref&gt; As of 1997, it remained unknown whether Trémaux tree construction could be performed by a deterministic parallel algorithm, in the complexity class [[NC (complexity)|NC]].&lt;ref&gt;{{citation
 | last1 = Karger | first1 = David R. | author1-link = David Karger
 | last2 = Motwani | first2 = Rajeev | author2-link = Rajeev Motwani
 | doi = 10.1137/S0097539794273083
 | issue = 1
 | journal = [[SIAM Journal on Computing]]
 | mr = 1431256
 | pages = 255–272
 | title = An ''NC'' algorithm for minimum cuts
 | volume = 26
 | year = 1997}}.&lt;/ref&gt;

===Logical expression===
It is possible to express the property that a set ''T'' of edges with a choice of root vertex ''r'' forms a Trémaux tree, in the monadic second-order [[logic of graphs]], and more specifically in the form of this logic called MSO&lt;sub&gt;2&lt;/sub&gt;, which allows quantification over both vertex and edge sets. This property can be expressed as the conjunction of the following properties:
*The graph is connected by the edges in ''T''. This can be expressed logically as the statement that, for every non-empty proper subset of the graph's vertices, there exists an edge in ''T'' with exactly one endpoint in the given subset.
*''T'' is acyclic. This can be expressed logically as the statement that there does not exist a nonempty subset ''C'' of ''T'' for which each vertex is incident to either zero or two edges of ''C''.
*Every edge ''e'' not in ''T'' connects an ancestor-descendant pair of vertices in ''T''. This is true when both endpoints of ''e'' belong to a path in ''T''. It can be expressed logically as the statement that, for all edges ''e'', there exists a subset ''P'' of ''T'' such that exactly two vertices, one of them ''r'', are incident to a single edge of ''P'', and such that both endpoints of ''e'' are incident to at least one edge of ''P''.
Once a Trémaux tree has been identified in this way, one can describe an [[orientation (graph theory)|orientation]] of the given graph, also in monadic second-order logic, by specifying the set of edges whose orientation is from the ancestral endpoint to the descendant endpoint. The remaining edges outside this set must be oriented in the other direction. This technique allows graph properties involving orientations to be specified in monadic second order logic, allowing these properties to be tested efficiently on graphs of bounded [[treewidth]] using [[Courcelle's theorem]].&lt;ref&gt;{{citation
 | last = Courcelle | first = Bruno | authorlink = Bruno Courcelle
 | editor1-last = Immerman | editor1-first = Neil | editor1-link = Neil Immerman
 | editor2-last = Kolaitis | editor2-first = Phokion G.
 | contribution = On the expression of graph properties in some fragments of monadic second-order logic
 | contribution-url = http://www.labri.fr/perso/courcell/Textes/DIMACS(1997).pdf
 | mr = 1451381
 | pages = 33–62
 | publisher = Amer. Math. Soc.
 | series = DIMACS
 | title = Proc. Descr. Complex. Finite Models
 | volume = 31
 | year = 1996}}.&lt;/ref&gt;

===Related properties===
If a graph has a [[Hamiltonian path]], then that path (rooted at one of its endpoints) is also a Trémaux tree. The undirected graphs for which every Trémaux tree has this form are the [[cycle graph]]s, [[complete graph]]s, and balanced [[complete bipartite graph]]s.&lt;ref&gt;{{citation
 | last1 = Chartrand | first1 = Gary | author1-link = Gary Chartrand
 | last2 = Kronk | first2 = Hudson V.
 | journal = [[SIAM Journal on Applied Mathematics]]
 | mr = 0234852
 | pages = 696–700
 | title = Randomly traceable graphs
 | volume = 16
 | year = 1968}}.&lt;/ref&gt;

Trémaux trees are closely related to the concept of [[tree-depth]]. The tree-depth of a graph ''G'' can be defined as the smallest number ''d'' such that ''G'' can be embedded as a subgraph of a graph ''H'' that has a Trémaux tree ''T'' of depth ''d''. Bounded tree-depth, in a family of graphs, is equivalent to the existence of a path that cannot occur as a [[graph minor]] of the graphs in the family. Many hard computational problems on graphs have algorithms that are [[parameterized complexity|fixed-parameter tractable]] when parameterized by the tree-depth of their inputs.&lt;ref&gt;{{citation
 | last1 = Nešetřil | first1 = Jaroslav | author1-link = Jaroslav Nešetřil
 | last2 = Ossona de Mendez | first2 = Patrice | author2-link = Patrice Ossona de Mendez
 | contribution = Chapter 6. Bounded height trees and tree-depth
 | doi = 10.1007/978-3-642-27875-4
 | isbn = 978-3-642-27874-7
 | location = Heidelberg
 | mr = 2920058
 | pages = 115–144
 | publisher = Springer
 | series = Algorithms and Combinatorics
 | title = Sparsity: Graphs, Structures, and Algorithms
 | volume = 28
 | year = 2012}}.&lt;/ref&gt;

Trémaux trees also play a key role in the [[Fraysseix–Rosenstiehl planarity criterion]] for testing whether a given graph is [[planar graph|planar]]. According to this criterion, a graph ''G'' is planar if, for a given Trémaux tree ''T'' of ''G'', the remaining edges can be placed in a consistent way to the left or the right of the tree, subject to constraints that prevent edges with the same placement from crossing each other.&lt;ref&gt;{{citation
 | last1 = de Fraysseix | first1 = Hubert
 | last2 = Rosenstiehl | first2 = Pierre | author2-link = Pierre Rosenstiehl
 | contribution = A depth-first-search characterization of planarity
 | location = Amsterdam
 | mr = 671906
 | pages = 75–80
 | publisher = North-Holland
 | series = Ann. Discrete Math.
 | title = Graph theory (Cambridge, 1981)
 | volume = 13
 | year = 1982}}; {{citation
 | last1 = de Fraysseix | first1 = Hubert
 | last2 = Ossona de Mendez | first2 = Patrice | author2-link = Patrice Ossona de Mendez
 | last3 = Rosenstiehl | first3 = Pierre | author3-link = Pierre Rosenstiehl
 | doi = 10.1142/S0129054106004248
 | issue = 5
 | journal = International Journal of Foundations of Computer Science
 | mr = 2270949
 | pages = 1017–1029
 | title = Trémaux trees and planarity
 | volume = 17
 | year = 2006| arxiv = math/0610935}}.&lt;/ref&gt;

==In infinite graphs==
===Existence===
Not every infinite graph has a normal spanning tree. For instance, a [[complete graph]] on an [[uncountable set]] of vertices does not have one: a normal spanning tree in a complete graph can only be a path, but a path has only a countable number of vertices. However, every graph on a [[countable set]] of vertices does have a normal spanning tree.&lt;ref name="soukoup"&gt;{{citation
 | last = Soukup | first = Lajos
 | contribution = Infinite combinatorics: from finite to infinite
 | doi = 10.1007/978-3-540-77200-2_10
 | location = Berlin
 | mr = 2432534
 | pages = 189–213
 | publisher = Springer
 | series = Bolyai Soc. Math. Stud.
 | title = Horizons of combinatorics
 | volume = 17
 | year = 2008| isbn = 978-3-540-77199-9
 }}. See in particular Theorem 3, [https://books.google.com/books?id=kIKW18ENfUMC&amp;pg=PA193 p.&amp;nbsp;193].&lt;/ref&gt;

Even in countable graphs, a depth-first search might not succeed in eventually exploring the entire graph,&lt;ref name="soukoup"/&gt; and not every normal spanning tree can be generated by a depth-first search: to be a depth-first search tree, a countable normal spanning tree must have only one infinite path or one node with infinitely many children (and not both).

===Minors===
If an infinite graph ''G'' has a normal spanning tree, so does every connected [[graph minor]] of ''G''. It follows from this that the graphs that have normal spanning trees have a characterization by [[forbidden graph characterization|forbidden]] [[graph minor|minors]]. One of the two classes of forbidden minors consists of [[bipartite graph]]s in which one side of the bipartition is countable, the other side is uncountable, and every vertex has infinite degree. The other class of forbidden minors consists of certain graphs derived from [[Aronszajn tree]]s.&lt;ref&gt;{{citation
 | last1 = Diestel | first1 = Reinhard
 | last2 = Leader | first2 = Imre | author2-link = Imre Leader
 | doi = 10.1112/S0024610700001708
 | issue = 1
 | journal = Journal of the London Mathematical Society
 | mr = 1801714
 | pages = 16–32
 | series = Second Series
 | title = Normal spanning trees, Aronszajn trees and excluded minors
 | url = http://www.math.uni-hamburg.de/research/papers/hbm/hbm2000105.pdf
 | volume = 63
 | year = 2001}}.&lt;/ref&gt;

The details of this characterization depend on the choice of set-theoretic axiomatization used to formalize mathematics. In particular, in models of set theory for which [[Martin's axiom]] is true and the [[continuum hypothesis]] is false, the class of bipartite graphs in this characterization can be replaced by a single forbidden minor. However, for models in which the continuum hypothesis is true, this class contains graphs which are incomparable with each other in the minor ordering.&lt;ref&gt;{{citation
 | last1 = Bowler | first1 = Nathan
 | last2 = Geschke | first2 = Stefan
 | last3 = Pitz | first3 = Max
 | arxiv = 1609.01042
 | title = Minimal obstructions for normal spanning trees
 | year = 2016| bibcode = 2016arXiv160901042B}}&lt;/ref&gt;

===Ends and metrizability===
Normal spanning trees are also closely related to the [[end (graph theory)|ends]] of an infinite graph, equivalence classes of infinite paths that, intuitively, go to infinity in the same direction. If a graph has a normal spanning tree, this tree must have exactly one infinite path for each of the graph's ends.&lt;ref name="d"/&gt;

An infinite graph can be used to form a [[topological space]] by viewing the graph itself as a [[simplicial complex]] and adding a [[point at infinity]] for each end of the graph. With this topology, a graph has a normal spanning tree if and only if its set of vertices can be decomposed into a countable union of [[closed set]]s. Additionally, this topological space can be represented by a [[metric space]] if and only if the graph has a normal spanning tree.&lt;ref name="d"&gt;{{citation
 | last = Diestel | first = Reinhard
 | doi = 10.1016/j.jctb.2006.02.010
 | issue = 6
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 2274079
 | pages = 846–854
 | series = Series B
 | title = End spaces and spanning trees
 | volume = 96
 | year = 2006}}.&lt;/ref&gt;

==References==
{{reflist}}

{{DEFAULTSORT:Tremaux Tree}}
[[Category:Graph theory objects]]
[[Category:Spanning tree]]
[[Category:Graph minor theory]]
[[Category:Infinite graphs]]</text>
      <sha1>lewmdmp4pjjb5u6zmdt60sjdkvm5rqd</sha1>
    </revision>
  </page>
  <page>
    <title>Zweistein</title>
    <ns>0</ns>
    <id>36267706</id>
    <redirect title="Thomas von Randow" />
    <revision>
      <id>499682962</id>
      <parentid>499681654</parentid>
      <timestamp>2012-06-28T00:38:48Z</timestamp>
      <contributor>
        <username>R.e.b.</username>
        <id>217736</id>
      </contributor>
      <comment>Adding/removing category/ies</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="81">#redirect[[Thomas von Randow]]
[[Category:Pseudonymous mathematicians|Zweistein]]</text>
      <sha1>h5iq4smt5pj32yuhkrt862p0v0kiqli</sha1>
    </revision>
  </page>
</mediawiki>
