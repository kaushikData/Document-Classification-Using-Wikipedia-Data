<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Andrea Bertozzi</title>
    <ns>0</ns>
    <id>37498758</id>
    <revision>
      <id>871469484</id>
      <parentid>864478863</parentid>
      <timestamp>2018-12-01T08:13:18Z</timestamp>
      <contributor>
        <username>Мит Сколов</username>
        <id>29124728</id>
      </contributor>
      <comment>/* External links */ https://www.math.ucla.edu/news/math-faculty-listed-highly-cited-researchers</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6988">{{Infobox scientist
| name              = Andrea Bertozzi
| image             = &lt;!--(as myimage.jpg, no 'File:')--&gt;
| image_size        = 
| alt               = 
| caption           = 
| birth_date        = {{Birth year and age|1965}}
| birth_place       = [[Boston, Massachusetts]]
| death_date        = &lt;!-- {{Death date and age|YYYY|MM|DD|YYYY|MM|DD}} (death date then birth date) --&gt;
| death_place       = 
| residence         = 
| nationality       = [[United States|American]]
| fields            = [[Mathematics]]
| workplaces        = [[University of California, Los Angeles]]
| alma_mater        = [[Princeton University]]
| doctoral_advisor  = [[Andrew Majda]]
| doctoral_students =
| known_for         = 
| awards            = 
}}
'''Andrea Louise Bertozzi''' (born 1965) is an American mathematician.&lt;ref name="google1"&gt;{{cite book|url=https://books.google.com/books?id=uPRB-OED1bcC&amp;pg=PA60&amp;dq=%22andrea+bertozzi%22&amp;hl=en&amp;sa=X&amp;ei=tEeQUKevNPLG0AHU-4G4Bw&amp;ved=0CDsQ6AEwAg#v=onepage&amp;q=%22andrea%20bertozzi%22&amp;f=false |title=Encyclopedia of World Scientists - Elizabeth H. Oakes - Google Books |publisher=Books.google.com |date= |accessdate=2012-10-30}}&lt;/ref&gt; Her research interests are in non-linear partial differential equations and applied mathematics.&lt;ref&gt;{{cite web|url=http://www.math.ucla.edu/~bertozzi/ |title=Personal Webpage of Andrea L. Bertozzi}}&lt;/ref&gt;

==Biography==
She earned her bachelor's and master's degrees from [[Princeton University]], followed by her PhD from Princeton in 1991; her dissertation was titled ''Existence, Uniqueness, and a Characterization of Solutions to the Contour Dynamics Equation''.&lt;ref name="google1"/&gt; Prior to joining UCLA in 2003, Bertozzi was an L. E. Dickson Instructor at the University of Chicago, and then Professor of Mathematics and Physics at Duke University.&lt;ref name="autogenerated1"&gt;{{cite web|url=http://www.siam.org/visiting/speakers/bertozzi.php |title=List of Visiting Speakers: Andrea L. Bertozzi |publisher=SIAM |date= |accessdate=2012-10-30 |deadurl=yes |archiveurl=https://web.archive.org/web/20121018165611/http://www.siam.org/visiting/speakers/bertozzi.php |archivedate=2012-10-18 }}&lt;/ref&gt; At the University of Chicago she first began to study the mathematics of thin films.&lt;ref name="google1"/&gt; She spent one year at Argonne National Laboratory as the [[Maria Goeppert-Mayer]] Distinguished Scholar.&lt;ref name="google1"/&gt; She coauthored the book ''Vorticity and Incompressible Flow'', which was published in 2000.&lt;ref name="google1"/&gt;

She is a member of the faculty of the [[University of California, Los Angeles]], as a Professor of Mathematics (since 2003) and Mechanical and Aerospace Engineering (since 2018) and Director of Applied Mathematics (since 2005).&lt;ref name="autogenerated1"/&gt; She is a member of the California NanoSystems Institute.  At UCLA, among other things, she has worked with [[Jeffrey Brantingham]] and other colleagues to apply mathematics to the patterns of urban crime, research which was the cover feature in the March 2, 2010 issue of Proceedings of the [[National Academy of Sciences]].&lt;ref name="redorbit1"&gt;{{cite web|url=http://www.redorbit.com/news/science/1826185/can_math_and_science_help_solve_crimes/ |title=Can Math And Science Help Solve Crimes? - Science News |publisher=redOrbit |date=2010-02-22 |accessdate=2012-10-30}}&lt;/ref&gt; Bertozzi also spoke about the mathematics of crime at the 2010 annual meeting of the [[American Association for the Advancement of Science]].&lt;ref name="redorbit1"/&gt;

She is the older sister of the chemist [[Carolyn Bertozzi]].&lt;ref&gt;{{cite web|title=UCLA Math Department Faculty|url=http://www.math.ucla.edu/~bertozzi/|accessdate=4 June 2012}}&lt;/ref&gt; Her father, [[William Bertozzi]], was a professor of physics at the [[Massachusetts Institute of Technology]].

==Recognition==
In 1995 Bertozzi received a research fellowship from the [[Sloan Foundation]].&lt;ref name="google1"/&gt; In 1996 she received the [[Presidential Early Career Award]] for Scientists and Engineers from the U.S. Office of Naval Research.&lt;ref name="google1"/&gt;&lt;ref name="google2"&gt;{{cite book |url= https://books.google.com/books?id=uPRB-OED1bcC&amp;dq=%22andrea+bertozzi%22&amp;source=gbs_navlinks_s |title=Encyclopedia of World Scientists - Elizabeth H. Oakes - Google Boeken |publisher=Books.google.com |date= |accessdate=2012-10-30}}&lt;/ref&gt; She is featured in the book ''Encyclopedia of World Scientists'', by Elizabeth H. Oakes, published in 2007.&lt;ref name="google1"/&gt;&lt;ref name="google2"/&gt; She was also awarded the 2009 [[Association for Women in Mathematics]]-[[Society for Industrial and Applied Mathematics]] [[Sonia Kovalevsky]] Lecture, and was elected a [[Society for Industrial and Applied Mathematics]] Fellow in 2010.&lt;ref name="autogenerated1"/&gt;

In 2010 she was elected to the American Academy of Arts and Sciences. 
In 2012 she became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2012-11-10.&lt;/ref&gt;  
In 2013 she was named the Betsy Wood Knapp Chair for Innovation and Creativity at UCLA.&lt;ref&gt;{{Cite web |url=http://newsroom.ucla.edu/portal/ucla/andrea-bertozzi-appointed-to-hold-243181.aspx |title=Andrea Bertozzi named to UCLA's Betsy Wood Knapp Chair for Innovation and Creativity |access-date=2013-06-25 |archive-url=https://web.archive.org/web/20130723085059/http://newsroom.ucla.edu/portal/ucla/andrea-bertozzi-appointed-to-hold-243181.aspx |archive-date=2013-07-23 |dead-url=yes |df= }}&lt;/ref&gt;
In 2014 she won a SIAM Outstanding Paper Prize (joint with Arjuna Flenner).
In 2016 she became a Fellow of the [[American Physical Society]].&lt;ref&gt;[http://www.aps.org/programs/honors/fellowships/ APS Fellowship], American Physical Society&lt;/ref&gt;
In 2015 and 2016 she was named a Thomson-Reuters/Clarivate Analytics 'highly cited' researcher.
In 2017 she became a [[Simons Investigator]].&lt;ref&gt;[https://www.simonsfoundation.org/mathematics-physical-sciences/simons-investigators/simons-investigators-awardees/ Simons Investigators Awardees], The Simons Foundation&lt;/ref&gt;
In 2018 she was elected to the US [[National Academy of Sciences]].

==References==
{{Reflist}}

==External links==
*[http://www.math.ucla.edu/~bertozzi/ Andrea Bertozzi's website at UCLA ]
*{{MathGenealogy |id=18892 }}

{{Authority control}}

{{DEFAULTSORT:Bertozzi, Andrea}}
[[Category:1965 births]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Women mathematicians]]
[[Category:Fluid dynamicists]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Fellows of the Society for Industrial and Applied Mathematics]]
[[Category:Simons Investigator]]
[[Category:People from Boston]]
[[Category:Mathematicians from Massachusetts]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Sloan Research Fellows]]
[[Category:ISI highly cited researchers]]</text>
      <sha1>kagmq2llydwkl31gjcvcw7y6jjjcutr</sha1>
    </revision>
  </page>
  <page>
    <title>Annals of Functional Analysis</title>
    <ns>0</ns>
    <id>31680438</id>
    <revision>
      <id>740605139</id>
      <parentid>643119269</parentid>
      <timestamp>2016-09-22T03:23:55Z</timestamp>
      <contributor>
        <username>Randykitty</username>
        <id>17843555</id>
      </contributor>
      <minor/>
      <comment>tweak</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1222">{{Infobox journal
| title = Annals of Functional Analysis
| cover = 
| abbreviation = Ann. Funct. Anal.
| discipline = [[Functional analysis]], [[operator theory]]
| editor = [[Mohammad Sal Moslehian]]
| publisher = [[Tusi Mathematical Research Group]]
| frequency = Biannual
| history = 2010–present
| impact =
| impact-year =
| url = http://www.emis.de/journals/AFA/
| link1 = http://www.emis.de/journals/AFA/volumes.htm
| link1-name = Online access
| ISSN = 2008-8752
| eISSN = 
| CODEN = 
| LCCN = 
| OCLC = 652359887
}}
The ''''' Annals of Functional Analysis''''' is a [[peer review|peer-reviewed]] [[mathematics journal]] published by the [[Tusi Mathematical Research Group]]. The journal was established in 2009 and covers [[functional analysis]] and [[operator theory]]. It is indexed by [[Science Citation Index Expanded]], ''[[Mathematical Reviews]]'' and ''[[Zentralblatt MATH]]''. The journal has an MCQ-2012 of 0.36 by MathSciNet (All Journal MCQ is 0.35).

==External links==
*{{Official website|http://www.emis.de/journals/AFA/}}

[[Category:Mathematics journals]]
[[Category:Publications established in 2010]]
[[Category:English-language journals]]
[[Category:Biannual journals]]


{{math-journal-stub}}</text>
      <sha1>2nsd5dde7logix6ch71lzttuhy4p1ow</sha1>
    </revision>
  </page>
  <page>
    <title>Bernoulli's triangle</title>
    <ns>0</ns>
    <id>52245438</id>
    <revision>
      <id>862708304</id>
      <parentid>852437814</parentid>
      <timestamp>2018-10-06T05:11:38Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2131">'''Bernoulli's triangle''' is an array of partial sums of the [[binomial coefficients]]. For any non-negative integer ''n'' and for any integer ''k'' included between 0 and ''n'', the component in row ''n'' and column ''k'' is given by:

:&lt;math&gt; \sum_{p=0}^k {n \choose p}, &lt;/math&gt;

i.e., the sum of the first ''k'' ''n''th-order binomial coefficients.&lt;ref&gt;[http://oeis.org/wiki/Bernoulli%27s_triangle On-Line Encyclopedia of Integer Sequences]&lt;/ref&gt; The first rows of Bernoulli's triangle are:

: &lt;math&gt;
\begin{array}{cc|cccccc}
&amp; k &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
n &amp; &amp; \\
\hline
0 &amp; &amp; 1 \\
1 &amp; &amp; 1 &amp; 2 \\
2 &amp; &amp; 1 &amp; 3 &amp; 4 \\
3 &amp; &amp; 1 &amp; 4 &amp; 7 &amp; 8 \\
4 &amp; &amp; 1 &amp; 5 &amp; 11 &amp; 15 &amp; 16 \\
5 &amp; &amp; 1 &amp; 6 &amp; 16 &amp; 26 &amp; 31 &amp; 32
\end{array}
&lt;/math&gt;

Similarly to [[Pascal's triangle]], each component of Bernoulli's triangle is the sum of two components of the previous row, except for the last number of each row, which is double the last number of the previous row.  For example, if &lt;math&gt;B_{n,k}&lt;/math&gt; denotes the component in row ''n'' and column ''k'', then:

:&lt;math&gt;
\begin{align}
B_{n,k}=&amp;B_{n-1,k}+B_{n-1,k-1} &amp;\mbox{  if }&amp;k&lt;n\\
B_{n,k}=&amp;         2B_{n-1,k-1} &amp;\mbox{  if }&amp;k=n
\end{align}
&lt;/math&gt;

As in Pascal's triangle and other similarly constructed triangles,&lt;ref&gt;Hoggatt, Jr, V. E., A new angle on Pascal's triangle, ''Fibonacci Quarterly'' '''6'''(4) (1968) 221–234; Hoggatt, Jr, V. E., Convolution triangles for generalized Fibonacci numbers, ''Fibonacci Quarterly'' '''8'''(2) (1970) 158–171&lt;/ref&gt; sums of components along diagonal paths in Bernoulli's triangle result in the [[Fibonacci number]]s.&lt;ref&gt;Neiter, D. &amp; Proag, A., [https://cs.uwaterloo.ca/journals/JIS/VOL19/Proag/proag3.html Links Between Sums Over Paths in Bernoulli's Triangles and the Fibonacci Numbers], ''Journal of Integer Sequences'', '''19''' (2016) 16.8.3.&lt;/ref&gt;

== References ==
{{Reflist}}

== External links ==
* The sequence of numbers formed by Bernoulli's triangle on the [[On-Line Encyclopedia of Integer Sequences]]: https://oeis.org/A008949.

== Bernoulli's triangle ==

[[Category:Factorial and binomial topics]]
[[Category:Triangles of numbers]]</text>
      <sha1>fo5ok0than4r1dbze9r3v17k7e5zgvg</sha1>
    </revision>
  </page>
  <page>
    <title>Carry operator</title>
    <ns>0</ns>
    <id>9496834</id>
    <revision>
      <id>868848046</id>
      <parentid>532039779</parentid>
      <timestamp>2018-11-14T20:57:51Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="490">{{Refimprove|date=May 2008}}

The '''carry operator''', symbolized by the '''¢''' sign,  is an abstraction of the operation of determining whether a portion of an [[Adder (electronics)|adder]] network generates or propagates a [[carry (arithmetic)|carry]]. It is defined as follows:
:&lt;math&gt;(G_1, P_1) \ &lt;/math&gt; '''¢''' &lt;math&gt;(G_2, P_2) = (G_1 \lor G_2 P_1,  P_2 P_1) &lt;/math&gt;

==External links==
* http://www.aoki.ecei.tohoku.ac.jp/arith/mg/algorithm.html

[[Category:Computer arithmetic]]</text>
      <sha1>4zxy93qrs82gzuivsul3dhrk7j0m28y</sha1>
    </revision>
  </page>
  <page>
    <title>Codimension</title>
    <ns>0</ns>
    <id>525149</id>
    <revision>
      <id>800089874</id>
      <parentid>734526479</parentid>
      <timestamp>2017-09-11T13:11:56Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>/* top */ codimension of an ideal</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6505">In [[mathematics]], '''codimension''' is a basic geometric idea that applies to [[vector subspace|subspaces]] in [[vector space]]s, to [[submanifold]]s in [[manifold]]s, and suitable [[subset]]s of [[algebraic varieties]].

For [[affine variety|affine]] and [[projective algebraic varieties]], the codimension equals the [[height (ring theory)|height]] of the defining [[ideal (ring theory)|ideal]]. For this reason, the height of an ideal is often called its codimension.

The dual concept is [[relative dimension]].

==Definition==
Codimension is a ''relative'' concept: it is only defined for one object ''inside'' another. There is no “codimension of a vector space (in isolation)”, only the codimension of a vector ''sub''space.

If ''W'' is a [[linear subspace]] of a [[finite-dimensional]] [[vector space]] ''V'', then the '''codimension''' of ''W'' in ''V'' is the difference between the dimensions:
:&lt;math&gt;\operatorname{codim}(W) = \dim(V) - \dim(W).&lt;/math&gt;
It is the complement of the dimension of ''W,'' in that, with the dimension of ''W,'' it adds up to the dimension of the [[ambient space]] ''V:''
:&lt;math&gt;\dim(W) + \operatorname{codim}(W) = \dim(V).&lt;/math&gt;

Similarly, if ''N'' is a submanifold or subvariety in ''M'', then the codimension of ''N'' in ''M'' is
:&lt;math&gt;\operatorname{codim}(N) = \dim(M) - \dim(N).&lt;/math&gt;
Just as the dimension of a submanifold is the dimension of the [[tangent bundle]] (the number of dimensions that you can move ''on'' the submanifold), the codimension is the dimension of the [[normal bundle]] (the number of dimensions you can move ''off'' the submanifold).

More generally, if ''W'' is a [[linear subspace]] of a (possibly infinite dimensional) [[vector space]] ''V'' then the codimension of ''W'' in ''V'' is the dimension (possibly infinite) of the [[quotient space (linear algebra)|quotient space]] ''V''/''W'', which is more abstractly known as the [[cokernel]] of the inclusion. For finite-dimensional vector spaces, this agrees with the previous definition
:&lt;math&gt;\operatorname{codim}(W) = \dim(V/W) = \dim \operatorname{coker} ( W \to V ) = \dim(V) - \dim(W),&lt;/math&gt;
and is dual to the relative dimension as the dimension of the [[kernel (algebra)|kernel]].

Finite-codimensional subspaces of infinite-dimensional spaces are often useful in the study of [[topological vector space]]s.

==Additivity of codimension and dimension counting==
The fundamental property of codimension lies in its relation to  [[intersection (set theory)|intersection]]: if ''W''&lt;sub&gt;1&lt;/sub&gt; has codimension ''k''&lt;sub&gt;1&lt;/sub&gt;, and ''W''&lt;sub&gt;2&lt;/sub&gt; has codimension ''k''&lt;sub&gt;2&lt;/sub&gt;, then if ''U'' is their intersection with codimension ''j'' we have

:max (''k''&lt;sub&gt;1&lt;/sub&gt;, ''k''&lt;sub&gt;2&lt;/sub&gt;) &amp;le; ''j'' &amp;le; ''k''&lt;sub&gt;1&lt;/sub&gt; + ''k''&lt;sub&gt;2&lt;/sub&gt;.

In fact ''j'' may take any [[integer]] value in this range. This statement is more perspicuous than the translation in terms of dimensions, because the [[Sides of an equation|RHS]] is just the sum of the codimensions. In words

:''codimensions (at most) add''.
:If the subspaces or submanifolds intersect [[Transversality (mathematics)|transversally]] (which occurs [[General position|generically]]), codimensions add exactly.

This statement is called '''dimension counting,''' particularly in [[intersection theory]].

==Dual interpretation==
In terms of the [[dual space]], it is quite evident why dimensions add. The subspaces can be defined by the vanishing of a certain number of [[linear functional]]s, which if we take to be [[linearly independent]], their number is the codimension. Therefore, we see that ''U'' is defined by taking the [[union (set theory)|union]] of the sets of linear functionals defining the ''W''&lt;sub&gt;i&lt;/sub&gt;. That union may introduce some degree of [[linear dependence]]: the possible values of ''j'' express that dependence, with the RHS sum being the case where there is no dependence.  This definition of codimension in terms of the number of functions needed to cut out a subspace extends to situations in which both the ambient space and subspace are infinite dimensional.

In other language, which is basic for any kind of [[intersection theory]], we are taking the union of a certain number of [[Constraint (mathematics)|constraint]]s. We have two phenomena to look out for:

# the two sets of constraints may not be independent;
# the two sets of constraints may not be compatible.

The first of these is often expressed as the '''principle of counting [[Constraint (mathematics)|constraints]]''': if we have a number ''N'' of [[parameter]]s to adjust (i.e. we have ''N'' [[degrees of freedom (physics and chemistry)|degrees of freedom]]), and a constraint means we have to 'consume' a parameter to satisfy it, then the codimension of the [[solution set]] is ''at most'' the number of constraints. We do not expect to be able to find a solution if the predicted codimension, i.e. the number of ''independent'' constraints, exceeds ''N'' (in the linear algebra case, there is always a ''trivial'', [[null vector]] solution, which is therefore discounted).

The second is a matter of geometry, on the model of [[parallel lines]]; it is something that can be discussed for [[linear problem]]s by methods of linear algebra, and for non-linear problems in [[projective space]], over the [[complex number]] field.

==In geometric topology==
Codimension also has some clear meaning in [[geometric topology]]: on a manifold, codimension 1 is the dimension of topological disconnection by a submanifold, while codimension 2 is the dimension of [[Ramification (mathematics)|ramification]] and [[knot theory]]. In fact, the theory of high-dimensional manifolds, which starts in dimension 5 and above, can alternatively be said to start in codimension 3, because higher codimensions avoid the phenomenon of knots. Since [[surgery theory]] requires working up to the middle dimension, once one is in dimension 5, the middle dimension has codimension greater than 2, and hence one avoids knots.

This quip is not vacuous: the study of embeddings in codimension 2 is knot theory, and difficult, while the study of embeddings in codimension 3 or more is amenable to the tools of high-dimensional geometric topology, and hence considerably easier.

==See also==
*[[glossary of differential geometry and topology]]

==References==
*{{Springer|id=C/c022870|title=Codimension}}

[[Category:Algebraic geometry]]
[[Category:Geometric topology]]
[[Category:Linear algebra]]
[[Category:Dimension]]</text>
      <sha1>ayhkc4hl9p8a28uf92gwdhh9wfts98q</sha1>
    </revision>
  </page>
  <page>
    <title>Combinatorial game theory</title>
    <ns>0</ns>
    <id>292231</id>
    <revision>
      <id>862965803</id>
      <parentid>862074541</parentid>
      <timestamp>2018-10-07T21:19:30Z</timestamp>
      <contributor>
        <username>PJTraill</username>
        <id>522601</id>
      </contributor>
      <comment>/* See also */ [[Cooling and heating (combinatorial game theory)]]. Summarise what the links are about.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22511">{{about|the theory of combinatorial games|the theory that includes games of chance and games of imperfect knowledge|Game theory}}
[[Image:Mathematicians playing Konane.jpg|thumb|Mathematicians playing [[Konane]] at a combinatorial game theory workshop]]

'''Combinatorial game theory''' ('''CGT''') is a branch of [[mathematics]] and [[theoretical computer science]] that typically studies [[sequential game]]s with [[perfect information]]. Study has been largely confined to two-player [[game]]s that have a ''position'' in which the players take turns changing in defined ways or ''moves'' to achieve a defined winning condition. CGT has not traditionally studied [[games of chance]] or those that use imperfect or incomplete information, favoring games that offer [[perfect information]] in which the state of the game and the set of available moves is always known by both players.&lt;ref&gt;Lessons in Play, p. 3&lt;/ref&gt; However, as mathematical techniques advance, the types of game that can be mathematically analyzed expands, thus the boundaries of the field are ever changing.&lt;ref&gt;Thomas S. Fergusson's analysis of poker is an example of CGT expanding into games that include elements of chance.  Research into Three Player NIM is an example of study expanding beyond two player games.  Conway, Guy and Berlekamp's analysis of partisan games is perhaps the most famous expansion of the scope of CGT, taking the field beyond the study of impartial games.&lt;/ref&gt; Scholars will generally define what they mean by a "game" at the beginning of a paper, and these definitions often vary as they are specific to the game being analyzed and are not meant to represent the entire scope of the field.

Combinatorial games include well-known games such as [[chess]], [[Draughts|checkers]], and [[Go (board game)|Go]], which are regarded as non-trivial, and [[tic-tac-toe]], which is considered as trivial in the sense of being "easy to solve". Some combinatorial games may also have an [[Bounded set|unbounded]] playing area, such as [[infinite chess]]. In CGT, the moves in these and other games are represented as a [[game tree]].  

Combinatorial games also include one-player combinatorial puzzles such as [[Sudoku]], and no-player automata, such as [[Conway's Game of Life]], (although in the strictest definition, "games" can be said to require more than one participant, thus the designations of "puzzle" and "automata".&lt;ref name=AlgGameTheory&gt;http://erikdemaine.org/papers/AlgGameTheory_GONC3/paper.pdf&lt;/ref&gt;) 

[[Game theory]] in general includes games of chance, games of imperfect knowledge, and games in which players can move simultaneously, and they tend to represent real-life decision making situations.

CGT has a different emphasis than "traditional" or "economic" game theory, which was initially developed to study games with simple combinatorial structure, but with elements of chance (although it also considers sequential moves, see [[extensive-form game]]). Essentially, CGT has contributed new methods for analyzing game trees, for example using [[surreal numbers]], which are a subclass of all two-player perfect-information games.&lt;ref name=AlgGameTheory/&gt; The type of games studied by CGT is also of interest in [[artificial intelligence]], particularly for [[automated planning and scheduling]]. In CGT there has been less emphasis on refining practical [[search algorithm]]s (such as the [[alpha–beta pruning]] heuristic included in most artificial intelligence textbooks), but more emphasis on descriptive theoretical results (such as measures of [[game complexity]] or proofs of optimal solution existence without necessarily specifying an algorithm, such as the [[strategy-stealing argument]]).

An important notion in CGT is that of the [[solved game]]. For example, [[tic-tac-toe]] is considered a solved game, as it can be proven that any game will result in a draw if both players play optimally. Deriving similar results for games with rich combinatorial structures is difficult. For instance, in 2007 it was announced that [[checkers]] has been [[Solved game#overview|weakly solved]]&amp;mdash;optimal play by both sides also leads to a draw&amp;mdash;but this result was a [[computer-assisted proof]].&lt;ref&gt;{{Cite journal| last1 = Schaeffer | first1 = J.| last2 = Burch | first2 = N.| last3 = Bjornsson | first3 = Y.| last4 = Kishimoto | first4 = A.| last5 = Muller | first5 = M.| last6 = Lake | first6 = R.| last7 = Lu | first7 = P.| last8 = Sutphen | first8 = S.| title = Checkers is solved| journal = [[Science (journal)|Science]]| volume = 317| issue = 5844| pages = 1518–1522| year = 2007| pmid = 17641166| doi = 10.1126/science.1144079| citeseerx = 10.1.1.95.5393| bibcode = 2007Sci...317.1518S}}&lt;/ref&gt; Other real world games are mostly too complicated to allow complete analysis today, although the theory has had some recent successes in analyzing Go endgames. Applying CGT to a ''position'' attempts to determine the optimum sequence of moves for both players until the game ends, and by doing so discover the optimum move in any position. In practice, this process is torturously difficult unless the game is very simple.

It can be helpful to distinguish between combinatorial "mathgames" of interest primarily to mathematicians and scientists to ponder and solve, and combinatorial "playgames" of interest to the general population as a form of entertainment and competition.&lt;ref&gt;{{Cite journal| last1 = Fraenkel | first1 = Aviezri| title = Combinatorial Games: selected bibliography with a succinct gourmet introduction| journal = Games of No Chance 3| volume = 56| pages = 492| year = 2009}}&lt;/ref&gt; However, a number of games fall into both categories.  [[Nim]], for instance, is a playgame instrumental in the foundation of CGT, and one of the first computerized games.&lt;ref&gt;{{Cite news |url=http://www.newyorker.com/archive/1952/08/02/1952_08_02_018_TNY_CARDS_000236053 |title=The Talk of the Town - It |first1=Eugene F. |last1=Grant |first2=Rex |last2=Lardner |date=2 August 1952 |newspaper=[[The New Yorker]]}}&lt;/ref&gt; Tic-tac-toe is still used to teach basic principles of game [[AI]] design to [[computer science]] students.  
==History==
CGT arose in relation to the theory of [[impartial game]]s, in which any play available to one player must be available to the other as well. One such game is [[nim]], which can be solved completely. Nim is an impartial game for two players, and subject to the ''normal play condition'', which means that a player who cannot move loses.  In the 1930s, the [[Sprague–Grundy theorem]] showed that all impartial games are equivalent to heaps in nim, thus showing that major unifications are possible in games considered at a [[combinatorial]] level, in which detailed strategies matter, not just pay-offs.

In the 1960s, [[Elwyn R. Berlekamp]], [[John H. Conway]] and [[Richard K. Guy]] jointly introduced the theory of a [[partisan game]], in which the requirement that a play available to one player be available to both is relaxed. Their results were published in their book ''[[Winning Ways for your Mathematical Plays]]'' in 1982. However, the first work published on the subject was Conway's 1976 book ''[[On Numbers and Games]]'', also known as ONAG, which introduced the concept of [[surreal number]]s and the generalization to games. ''On Numbers and Games'' was also a fruit of the collaboration between Berlekamp, Conway, and Guy.

Combinatorial games are generally, by convention,  put into a form where one player wins when the other has no moves remaining. It is easy to convert any finite game with only two possible results into an equivalent one where this convention applies. One of the most important concepts in the theory of combinatorial games is that of the sum of two games, which is a game where each player may choose to move either in one game or the other at any point in the game, and a player wins when his opponent has no move in either game. This way of combining games leads to a rich and powerful mathematical structure.

John Conway states in ONAG that the inspiration for the theory of partisan games was based on his observation of the play in [[Go (board game)|go]] endgames, which can often be decomposed into sums of simpler endgames isolated from each other in different parts of the board.

==Examples==
The introductory text ''[[Winning Ways]]'' introduced a large number of games, but the following were used as motivating examples for the introductory theory:
* Blue–Red [[Hackenbush]] - At the finite level, this partisan combinatorial game allows constructions of games whose values are [[Dyadic rational|dyadic rational number]]s. At the infinite level, it allows one to construct all real values, as well as many infinite ones that fall within the class of [[surreal numbers]].
* Blue–Red–Green Hackenbush - Allows for additional game values that are not numbers in the traditional sense, for example, [[star (game theory)|star]].
* [[Toads and Frogs]] - Allows various game values. Unlike most other games, a position is easily represented by a short string of characters.
* [[Domineering]] - Various interesting games, such as [[hot game]]s, appear as positions in Domineering, because there is sometimes an incentive to move, and sometimes not.  This allows discussion of a game's [[temperature (game theory)|temperature]].
* [[Nim]] - An [[impartial game]]. This allows for the construction of the [[nimber]]s.  (It can also be seen as a green-only special case of Blue-Red-Green Hackenbush.)

The classic game [[Go (board game)|Go]] was influential on the early combinatorial game theory, and Berlekamp and Wolfe subsequently developed an endgame and ''temperature'' theory for it (see references).  Armed with this they were able to construct plausible Go endgame positions from which they could give expert Go players a choice of sides and then defeat them either way.

Another game studied in the context of combinatorial game theory is [[chess]]. In 1953 [[Alan Turing]] wrote of the game, "If one can explain quite unambiguously in English, with the aid of mathematical symbols if required, how a calculation is to be done, then it is always possible to programme any digital computer to do that calculation, provided the storage capacity is adequate."&lt;ref&gt;{{cite web
 | url=http://www.turingarchive.org/browse.php/B/7
 | title=Digital computers applied to games
 | author=Alan Turing
 | publisher=University of Southampton and King's College Cambridge
 | page=2
}}&lt;/ref&gt; In a 1950 paper, [[Claude Shannon]] estimated the lower bound of the [[game complexity|game-tree complexity]] of chess to be 10&lt;sup&gt;120&lt;/sup&gt;, and today this is referred to as the [[Shannon number]].&lt;ref&gt;{{cite journal | author = [[Claude Shannon]] | title = Programming a Computer for Playing Chess | journal = Philosophical Magazine | volume = 41 | issue = 314 | year = 1950 | page = 4 | url = http://archive.computerhistory.org/projects/chess/related_materials/text/2-0%20and%202-1.Programming_a_computer_for_playing_chess.shannon/2-0%20and%202-1.Programming_a_computer_for_playing_chess.shannon.062303002.pdf | deadurl = yes | archiveurl = https://www.webcitation.org/5oFLE7Mgx?url=http://archive.computerhistory.org/projects/chess/related_materials/text/2-0%20and%202-1.Programming_a_computer_for_playing_chess.shannon/2-0%20and%202-1.Programming_a_computer_for_playing_chess.shannon.062303002.pdf | archivedate = 2010-03-15 | df =  }}&lt;/ref&gt; Chess remains unsolved, although extensive study, including work involving the use of supercomputers has created chess end-game [[Endgame tablebase|tablebases]], which shows the result of perfect play for all end-games with seven pieces or less. [[Infinite chess]] has an even greater combinatorial complexity than chess (unless only limited end-games, or composed positions with a small number of pieces are being studied).

==Overview==
A game, in its simplest terms, is a list of possible "moves" that two players, called ''left'' and ''right'', can make.  The game position resulting from any move can be considered to be another game. This idea of viewing games in terms of their possible moves to other games leads to a [[recursion|recursive]] mathematical definition of games that is standard in combinatorial game theory. In this definition, each game has the notation '''{L|R}'''.  &lt;math&gt;L&lt;/math&gt; is the [[set (mathematics)|set]] of game positions that the left player can move to, and &lt;math&gt;R&lt;/math&gt; is the set of game positions that the right player can move to; each position in L and R is defined as a game using the same notation.

Using [[Domineering]] as an example, label each of the sixteen boxes of the four-by-four board by ''A1'' for the upper leftmost square, ''C2'' for the third box from the left on the second row from the top, and so on. We use e.g. (D3, D4) to stand for the game position in which a vertical domino has been placed in the bottom right corner. Then, the initial position can be described in combinatorial game theory notation as

{| align=center
|&lt;math&gt;\{(A1,A2),(B1,B2),\dots|(A1,B1), (A2,B2),\dots\}.&lt;/math&gt;
|}

In standard Cross-Cram play, the players alternate turns, but this alternation is handled implicitly by the definitions of combinatorial game theory rather than being encoded within the game states.

[[Image:20x20square.png]][[Image:20x20square.png]]&lt;br/&gt;
[[Image:20x20square.png]]

{| align=center
|&lt;math&gt;\{(A1,A2) | (A1,B1)\} = \{ \{|\} | \{|\} \}.&lt;/math&gt;
|}

The above game describes a scenario in which there is only one move left for either player, and if either player makes that move, that player wins. (An irrelevant open square at C3 has been omitted from the diagram.) The &lt;nowiki&gt;{|}&lt;/nowiki&gt; in each player's move list (corresponding to the single leftover square after the move) is called the [[zero game]], and can actually be abbreviated 0.  In the zero game, neither player has any valid moves; thus, the player whose turn it is when the zero game comes up automatically loses.

The type of game in the diagram above also has a simple name; it is called the [[star (game theory)|star game]], which can also be abbreviated *.  In the star game, the only valid move leads to the zero game, which means that whoever's turn comes up during the star game automatically wins.

An additional type of game, not found in Domineering, is a ''loopy'' game, in which a valid move of either ''left'' or ''right'' is a game that can then lead back to the first game.  [[Checkers]], for example, becomes loopy when one of the pieces promotes, as then it can cycle endlessly between two or more squares. A game that does not possess such moves is called ''loopfree''.

==Game abbreviations==

===Numbers===
Numbers represent the number of free moves, or the move advantage of a particular player. By convention positive numbers represent an advantage for Left, while negative numbers represent an advantage for Right. They are defined recursively with 0 being the base case.
: 0 = {|}
: 1 = {0|}, 2 = {1|}, 3 = {2|}
: &lt;nowiki&gt;-1 = {|0}, -2 = {|-1}, -3 = {|-2}&lt;/nowiki&gt;

The [[zero game]] is a loss for the first player.

The sum of number games behaves like the integers, for example 3 + -2 = 1.

===Star===
''[[star (game theory)|Star]]'', written as * or {0|0}, is a first-player win since either player must (if first to move in the game) move to a zero game, and therefore win.

: * + * = 0, because the first player must turn one copy of * to a 0, and then the other player will have to turn the other copy of * to a 0 as well; at this point, the first player would lose, since 0 + 0 admits no moves.

The game * is neither positive nor negative; it and all other games in which the first player wins (regardless of which side the player is on) are said to be ''[[fuzzy game|fuzzy]] with'' or ''confused with'' 0; symbolically, we write * || 0.

===Up===
''Up'', written as ↑, is a position in combinatorial game theory.&lt;ref name=winningways&gt;{{cite book |author1=E. Berlekamp |author2=J. H. Conway |author3=R. Guy | title=[[Winning Ways for your Mathematical Plays]] | volume=I | publisher=Academic Press | year=1982 | isbn=0-12-091101-9}}&lt;br/&gt;{{cite book |author1=E. Berlekamp |author2=J. H. Conway |author3=R. Guy | title=Winning Ways for your Mathematical Plays | volume=II | publisher=Academic Press | year=1982 | isbn=0-12-091102-7}}&lt;/ref&gt; In standard notation, ↑ = {0|*}.

: &amp;minus;↑ = ↓ (''down'')

Up is strictly positive (↑ &gt; 0), but is [[infinitesimal]]. Up is defined in ''[[Winning Ways for your Mathematical Plays]]''.

===Down===
''Down'', written as ↓, is a position in combinatorial game theory.&lt;ref name=winningways /&gt; In standard notation, ↓ = {*|0}.

: &amp;minus;↓ = ↑ (''up'')

Down is strictly negative (↓ &lt; 0), but is [[infinitesimal]]. Down is defined in [[Winning Ways for your Mathematical Plays]].

==="Hot" games===
Consider the game {1|-1}. Both moves in this game are an advantage for the player who makes them; so the game is said to be "hot;" it is greater than any number less than -1, less than any number greater than 1, and fuzzy with any number in between. It is written as ±1. It can be added to numbers, or multiplied by positive ones, in the expected fashion; for example, 4 ± 1 = {5|3}.

==Nimbers==
An [[impartial game]] is one where, at every position of the game, the same moves are available to both players. For instance, [[Nim]] is impartial, as any set of objects that can be removed by one player can be removed by the other. However, [[domineering]] is not impartial, because one player places horizontal dominoes and the other places vertical ones. Likewise Checkers is not impartial, since the players own different colored pieces. For any [[ordinal number]], one can define an impartial game generalizing Nim in which, on each move, either player may replace the number with any smaller ordinal number; the games defined in this way are known as [[nimber]]s. The [[Sprague–Grundy theorem]] states that every impartial game is equivalent to a nimber.

The "smallest" nimbers - the simplest and least under the usual ordering of the ordinals - are 0 and *.

==See also==
* [[Alpha–beta pruning]], an optimised algorithm for searching the game tree
* [[Backward induction]], reasoning backwards from a final situation
* [[Cooling and heating (combinatorial game theory)]], various transformations of games making them more amenable to the theory
* [[Connection game]], a type of game where players attempt to establish connections
* [[Endgame tablebase]], a database saying how to play endgames
* [[Expectiminimax tree]], an adaptation of a minimax game tree to games with an element of chance
* [[Extensive-form game]], a game tree enriched with payoffs and information available to players
* [[Game classification]], an article discussing ways of classifying games
* [[Game complexity]], an article describing ways of measuring the complexity of games
* [[Grundy's game]], a mathematical game in which heaps of objects are split
* [[Multi-agent system]], a type of computer system for tackling complex problems
* [[Solving chess]]
* [[Sylver coinage]], a mathematical game of choosing positive integers that are not the sum of non-negative multiples of previously chosen integers
* [[Wythoff's game]], a mathematical game of taking objects from one or two piles
* [[Topological game]], a type of mathematical game played in a topological space
* [[Zugzwang]], being obliged to play when this is disadvantageous

==Notes==
{{Reflist}}

==References==
*{{cite book
 | last1 = Albert | first1 = Michael H. | author1-link = Michael H. Albert
 | last2 = Nowakowski | first2 = Richard J.
 | last3 = Wolfe | first3 = David
 | isbn = 978-1-56881-277-9
 | publisher = A K Peters Ltd
 | title = Lessons in Play: An Introduction to Combinatorial Game Theory
 | year = 2007}}
*{{cite book
 | last = Beck | first = József | author-link = József Beck
 | isbn = 978-0-521-46100-9
 | publisher = Cambridge University Press
 | title = Combinatorial games: tic-tac-toe theory
 | url = https://books.google.com/books?id=AU4dh_eKNfkC
 | year = 2008}}
*{{cite book
 | last1 = Berlekamp | first1 = E. | author1-link = Elwyn Berlekamp
 | last2 = Conway | first2 = J. H. | author2-link = John Horton Conway
 | last3 = Guy | first3 = R. | author3-link = Richard K. Guy
 | isbn = 0-12-091101-9
 | publisher = Academic Press
 | title = [[Winning Ways for your Mathematical Plays]]: Games in general
 | year = 1982}} 2nd ed., A K Peters Ltd (2001–2004),  {{ISBN|1-56881-130-6}}, {{ISBN|1-56881-142-X}}
* {{cite book
 | last1 = Berlekamp | first1 = E.
 | last2 = Conway | first2 = J. H. 
 | last3 = Guy | first3 = R. | author3-link = Richard K. Guy
 | isbn = 0-12-091102-7
 | publisher = Academic Press
 | title = Winning Ways for your Mathematical Plays: Games in particular
 | year = 1982}} 2nd ed., A K Peters Ltd (2001–2004), {{ISBN|1-56881-143-8}}, {{ISBN|1-56881-144-6}}.
*{{cite book
 | last1 = Berlekamp | first1 = Elwyn | author1-link = Elwyn Berlekamp
 | last2 = Wolfe | first2 = David | author2-link = David Wolfe (mathematician)
 | isbn = 1-56881-032-6
 | publisher = A K Peters Ltd
 | title = Mathematical Go: Chilling Gets the Last Point
 | year = 1997}}
*{{cite book
 | last = Bewersdorff | first = Jörg | author1-link = Jörg Bewersdorff
 | isbn = 1-56881-210-8
 | publisher = A K Peters Ltd
 | title = Luck, Logic and White Lies: The Mathematics of Games
 | year = 2004}} See especially sections 21–26.
*{{cite book
 | last = Conway | first = John Horton | author-link = John Horton Conway
 | isbn = 0-12-186350-6
 | publisher = Academic Press
 | title = [[On Numbers and Games]]
 | year = 1976}} 2nd ed., A K Peters Ltd (2001), {{ISBN|1-56881-127-6}}.
* {{cite book|author1=Robert A. Hearn|author2=Erik D. Demaine|title=Games, Puzzles, and Computation|year=2009|publisher=A K Peters, Ltd.|isbn=978-1-56881-322-6}}

==External links==
*[http://www.ics.uci.edu/~eppstein/cgt/ List of combinatorial game theory links] at the homepage of [[David Eppstein]]
*[https://arxiv.org/pdf/math/0410026 An Introduction to Conway's games and numbers] by Dierk Schleicher and Michael Stoll
*[http://senseis.xmp.net/?CGTPath#toc1 Combinational Game Theory terms summary] by Bill Spight
*[http://www.pims.math.ca/birs/birspages.php?task=displayevent&amp;event_id=05w5048 Combinatorial Game Theory Workshop, Banff International Research Station, June 2005]

{{Game theory}}

{{Authority control}}

[[Category:Combinatorial game theory|*]]</text>
      <sha1>4sujtgai15s212523pgnbg4b5wrom7v</sha1>
    </revision>
  </page>
  <page>
    <title>Connective spectrum</title>
    <ns>0</ns>
    <id>41125081</id>
    <revision>
      <id>747446238</id>
      <parentid>648616478</parentid>
      <timestamp>2016-11-02T12:35:38Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="692">In [[algebraic topology]], a branch of [[mathematics]], a '''connective spectrum''' is a [[spectrum (topology)|spectrum]] whose [[homotopy]] sets &lt;math&gt;\pi_k&lt;/math&gt; of negative degrees are zero.&lt;ref&gt;{{citation|title=Representation Theory and Higher Algebraic K-Theory|first=Aderemi|last=Kuku|publisher=CRC Press|year=2006|isbn=9781584886037|page=96|url=https://books.google.com/books?id=m_35mRPi-KwC&amp;pg=PA96}}.&lt;/ref&gt;

==References==
{{reflist}}

== External links ==
*{{nlab|id=connective+spectrum|title=connective spectrum}}
*http://mathoverflow.net/questions/62086/why-are-connective-spectra-called-connective

[[Category:Algebraic topology]]
[[Category:Homotopy theory]]

{{topology-stub}}</text>
      <sha1>as1gy4mst3h1pmzykzj812rj59if3kn</sha1>
    </revision>
  </page>
  <page>
    <title>David Harel</title>
    <ns>0</ns>
    <id>4321829</id>
    <revision>
      <id>851599274</id>
      <parentid>851599210</parentid>
      <timestamp>2018-07-23T11:21:02Z</timestamp>
      <contributor>
        <ip>132.76.61.52</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6902">{{EngvarB|date=June 2017}}
{{Use dmy dates|date=June 2017}}
{{Infobox scientist
| name                    = David Harel
| image                   = David Harel (FLoC 2006).jpg
| image_size              = 
| caption                 = David Harel (right) with [[Carl Hewitt]] at FLoC 2006
| birth_date              = {{birth date and age|df=yes|1950|04|12}}
| birth_place             = London, England
| death_date              = 
| death_place             = 
| residence               = 
| citizenship             =
| nationality             = Israeli and British
| ethnicity               =
| field                   = [[Computer Science]]
| work_institution        = [[Weizmann Institute]]
| alma_mater              = 
| doctoral_advisor        = 
| doctoral_students       = 
| known_for               = 
| author_abbreviation_bot = 
| author_abbreviation_zoo = 
| prizes                  = {{plainlist|
*[[ACM Software System Award]]
*[[Israel Prize]]
}}
| religion                = 
| footnotes               = 
}}
'''David Harel''' ({{lang-he|דוד הראל}}; born 12 April 1950) is a computer scientist at the [[Weizmann Institute of Science]] in Israel, and holds the William Sussman Professorial Chair of Mathematics. Born in London, England, he was Dean of the Faculty of Mathematics and Computer Science at the institute for seven years. He currently also serves as Vice-President of the [[Israel Academy of Sciences and Humanities]].

==Biography==
Harel is best known for his work on [[Dynamic logic (modal logic)|dynamic logic]], [[computability]], [[database theory]], software engineering and modelling biological systems. In the 1980s he invented the graphical language of [[Statechart]]s for specifying and programming reactive systems, which has been adopted as part of the [[Unified Modeling Language|UML]] standard. Since the late 1990s he has concentrated on a scenario-based approach to programming such systems, launched by his co-invention (with W. Damm) of [[Message sequence chart|Live Sequence Charts]]. He has published expository accounts of computer science, such as his award winning 1987 book "Algorithmics: The Spirit of Computing" and his 2000 book "Computers Ltd.: What They ''Really'' Can’t do", and has presented series on computer science for Israeli radio and television. He has also worked on other diverse topics, such as [[graph layout]], [[Computer science|computer science education]] and the analysis and communication of [[Odour|odors]].

Harel completed his PhD at [[Massachusetts Institute of Technology|MIT]] between 1976 and 1978. In 1987, he co-founded the software company [[I-Logix]], which in 2006 became part of IBM.

He has advocated building a full computer model of the [[Caenorhabditis elegans]] nematode, which was the first multicellular organism to have its genome completely sequenced. The eventual completeness of such a model depends on his updated version of the [[Turing test]].

He is a fellow of the [[Association for Computing Machinery|ACM]], the [[IEEE]], the [[American Association for the Advancement of Science|AAAS]], and EATCS.

Harel is active in several peace and human rights organisations in Israel.

==Awards and honours==
[[File:OO Modeling languages history.jpg|thumb|320px|Diagram showing how Harel's Statecharts contributed to object-oriented methods and notation]]
* 1986 [[Stevens Award]] for Software Development Methods
* 1992 ACM Karlstrom Outstanding Educator Award&lt;ref name="acm"&gt;[http://awards.acm.org/award_winners/harel_1741164.cfm David Harel – Award Winner], ACM. Retrieved 2 January 2015.&lt;/ref&gt;
* 1994 [[List of Fellows of the Association for Computing Machinery|ACM Fellow]]&lt;ref name="acm"/&gt;
* 1995 IEEE Fellow
* 2004 [[Israel Prize]], for computer science&lt;ref&gt;{{Cite web| title = Israel Prize Official Site (in Hebrew) – Recipient's C.V. | url = http://cms.education.gov.il/EducationCMS/Units/PrasIsrael/Tashsad/DavidHarel/}}&lt;/ref&gt;&lt;ref&gt;{{Cite web| title = Israel Prize Official Site (in Hebrew) – Judges' Rationale for Grant to Recipient | url = http://cms.education.gov.il/EducationCMS/Units/PrasIsrael/Tashsad/DavidHarel/NimokyHasoftim.htm}}&lt;/ref&gt;
* 2005 Doctor Honoris Causa, University of Rennes, France
* 2006 ACM SIGSOFT Outstanding Research Award
* 2006 Member of the [[Academia Europaea]]&lt;ref name="ae"&gt;[http://www.ae-info.org/ae/User/Harel_David Member profile], Academia Europaea. Retrieved 2 January 2015.&lt;/ref&gt;
* 2006 Doctor (Laura) Honoris Causa, [[University of Milano-Bicocca]], 18 May 2006&lt;ref&gt;{{Cite web|url=https://www.unimib.it/ateneo/storia/lauree-honoris-causa|title=Lauree honoris causa|access-date=2 April 2018|language=Italian}}&lt;/ref&gt;
* 2006, Fellow Honoris Causa, Open University of Israel
* 2007 [[ACM Software System Award]]&lt;ref name="acm"/&gt;
* 2010 [[Emet Prize]]
* 2010 Member of the [[Israel Academy of Sciences and Humanities]]&lt;ref&gt;[http://academy.mpage.co.il/Branches/Branch.aspx?nodeId=826&amp;branchId=370 Member profile], Israel Academy of Sciences and Humanities.&lt;/ref&gt;
* 2012 Doctor Honoris Causa, Eindhoven University of Technology, The Netherlands
* 2014 Foreign Member of the [[National Academy of Engineering]]&lt;ref name=":0"&gt;[https://www.nae.edu/107905.aspx Member profile], National Academy of Engineering. Retrieved 2 January 2015.&lt;/ref&gt;
* 2014 Foreign Honorary Member of the [[American Academy of Arts and Sciences]]&lt;ref name=":1"&gt;[https://www.amacad.org/multimedia/pdfs/classlist2014.pdf Newly elected members], American Academy of Arts and Sciences, April 2014. Retrieved 2 January 2015.&lt;/ref&gt;

==See also==
*[[List of Israel Prize recipients]]
*[[Israel Academy of Sciences and Humanities#Members|Members of the Israel Academy of Sciences and Humanities]]

==References==
{{reflist|30em}}

==External links==
* [http://www.wisdom.weizmann.ac.il/~harel/ David Harel]'s home page at the Weizmann Institute of Science.
* [http://academy.mpage.co.il/Branches/Branch.aspx?nodeId=826&amp;branchId=370 David Harel]'s page at the Israel Academy of Sciences and Humanities.

{{Authority control}}

{{DEFAULTSORT:Harel, David}}
[[Category:1950 births]]
[[Category:Living people]]
[[Category:People from London]]
[[Category:Israeli computer scientists]]
[[Category:Israel Prize in computer sciences recipients]]
[[Category:Israeli academics]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:Fellows of the American Association for the Advancement of Science]]
[[Category:Fellows of the Association for Computing Machinery]]
[[Category:Fellow Members of the IEEE]]
[[Category:Formal methods people]]
[[Category:Graph drawing people]]
[[Category:Members of Academia Europaea]]
[[Category:Members of the United States National Academy of Engineering]]
[[Category:Systems biologists]]
[[Category:Software engineering researchers]]
[[Category:Unified Modeling Language]]
[[Category:Weizmann Institute faculty]]
[[Category:Jewish inventors]]</text>
      <sha1>gkfyh96iagpjo7k1enffmql0z97bhdd</sha1>
    </revision>
  </page>
  <page>
    <title>Digital root</title>
    <ns>0</ns>
    <id>8286632</id>
    <revision>
      <id>870404730</id>
      <parentid>870404557</parentid>
      <timestamp>2018-11-24T15:49:54Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <comment>consistent terms</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17151">{{no footnotes|date=January 2016}}
The '''digital root''' (also '''repeated digital sum''') of a [[non-negative integer]] is the (single digit) value obtained by an iterative process of [[digit sum|summing digits]], on each iteration using the result from the previous iteration to compute a digit sum. The process continues until a single-digit number is reached.

For example, the digital root of 65,536 is 7, because {{nowrap|1=6 + 5 + 5 + 3 + 6 = 25}} and {{nowrap|1=2 + 5 = 7.}}

Digital roots can be calculated with [[Congruence relation|congruence]]s in [[modular arithmetic#Congruence_relation|modular arithmetic]] rather than by adding up all the digits, a procedure that can save time in the case of very large numbers.

Digital roots can be used as a sort of [[checksum]], to check that a sum has been performed correctly. If it has, then the digital root of the sum of the given numbers will equal the digital root of the sum of the digital roots of the given numbers. This check, which involves only single-digit calculations, can catch many errors in calculation.

Digital roots are used in Western [[numerology]], but certain numbers deemed to have occult significance (such as 11 and 22) are not always completely reduced to a single digit.

The number of times the digits must be summed to reach the digital root is called a number's additive [[Persistence of a number|persistence]]; in the above example, the additive persistence of 65,536 is 2.

== Significance and formula of the digital root ==
It helps to see the digital root of a positive integer as the position it holds with respect to the largest multiple of 9 less than the number itself. For example, the digital root of 11 is 2, which means that 11 is the second number after 9. Likewise, the digital root of 2035 is 1, which means that 2035&amp;nbsp;−&amp;nbsp;1 is a multiple of 9. If a number produces a digital root of exactly 9, then the number is a multiple of 9.

With this in mind the digital root of a positive integer &lt;math&gt;n&lt;/math&gt; may be defined by using [[floor function]] &lt;math&gt;\lfloor x\rfloor &lt;/math&gt;, as
:&lt;math&gt;\operatorname{dr}(n)=n-9\left\lfloor\frac{n-1}{9}\right\rfloor.&lt;/math&gt;

== Abstract multiplication of digital roots ==
The table below shows the digital roots produced by the familiar [[multiplication table]] in the decimal system.
&lt;div align="center"&gt;
{|class="wikitable" style="text-align:center; width:270px; height:270px" border="1"
! &lt;math&gt;\circ&lt;/math&gt; !! 1 !! 2 !! 3 !! 4 !! 5 !! 6 !! 7 !! 8 !! 9
|-
! 1
|style="background-color:#fbb"|1||style="background-color:#EFD7FF"|2||style="background-color:#ffa"|3||style="background-color:#EAFFEF"|4||style="background-color:#A4F0B7"|5||style="background-color:#BBDAFF"|6||style="background-color:#CEFFFD"|7||style="background-color:#EEEEFF"|8||style="background-color:#2FAACE"|9
|-
!2
|style="background-color:#EFD7FF"|2||style="background-color:#EAFFEF"|4||style="background-color:#BBDAFF"|6||style="background-color:#EEEEFF"|8||style="background-color:#fbb"|1||style="background-color:#ffa"|3||style="background-color:#A4F0B7"|5||style="background-color:#CEFFFD"|7||style="background-color:#2FAACE"|9
|-
!3
|style="background-color:#ffa"|3||style="background-color:#BBDAFF"|6||style="background-color:#2FAACE"|9||style="background-color:#ffa"|3||style="background-color:#BBDAFF"|6||style="background-color:#2FAACE"|9||style="background-color:#ffa"|3||style="background-color:#BBDAFF"|6||style="background-color:#2FAACE"|9
|-
!4
|style="background-color:#EAFFEF"|4||style="background-color:#EEEEFF"|8||style="background-color:#ffa"|3||style="background-color:#CEFFFD"|7||style="background-color:#EFD7FF"|2||style="background-color:#BBDAFF"|6||style="background-color:#fbb"|1||style="background-color:#A4F0B7"|5||style="background-color:#2FAACE"|9
|-
!5
|style="background-color:#A4F0B7"|5||style="background-color:#fbb"|1||style="background-color:#BBDAFF"|6||style="background-color:#EFD7FF"|2||style="background-color:#CEFFFD"|7||style="background-color:#ffa"|3||style="background-color:#EEEEFF"|8||style="background-color:#EAFFEF"|4||style="background-color:#2FAACE"|9
|-
!6
|style="background-color:#BBDAFF"|6||style="background-color:#ffa"|3||style="background-color:#2FAACE"|9||style="background-color:#BBDAFF"|6||style="background-color:#ffa"|3||style="background-color:#2FAACE"|9||style="background-color:#BBDAFF"|6||style="background-color:#ffa"|3||style="background-color:#2FAACE"|9
|-
!7
|style="background-color:#CEFFFD"|7||style="background-color:#A4F0B7"|5||style="background-color:#ffa"|3||style="background-color:#fbb"|1||style="background-color:#EEEEFF"|8||style="background-color:#BBDAFF"|6||style="background-color:#EAFFEF"|4||style="background-color:#EFD7FF"|2||style="background-color:#2FAACE"|9
|-
!8
|style="background-color:#EEEEFF"|8||style="background-color:#CEFFFD"|7||style="background-color:#BBDAFF"|6||style="background-color:#A4F0B7"|5||style="background-color:#EAFFEF"|4||style="background-color:#ffa"|3||style="background-color:#EFD7FF"|2||style="background-color:#fbb"|1||style="background-color:#2FAACE"|9
|-
!9
|style="background-color:#2FAACE"|9||style="background-color:#2FAACE"|9||style="background-color:#2FAACE"|9||style="background-color:#2FAACE"|9||style="background-color:#2FAACE"|9||style="background-color:#2FAACE"|9||style="background-color:#2FAACE"|9||style="background-color:#2FAACE"|9||style="background-color:#2FAACE"|9
|}
&lt;/div&gt;

The table shows a number of interesting [[patterns]] and [[symmetries]] and is known as the [[Vedic square]].

== Formal definition ==
Let &lt;math&gt;S(n)&lt;/math&gt; denote the sum of the digits of &lt;math&gt;n&lt;/math&gt; and let the composition of &lt;math&gt;S(n)&lt;/math&gt; be as follows:
:&lt;math&gt;S^{1}(n)=S(n),\ \ S^{m}(n)=S\left(S^{m-1}(n)\right),\ \text{for}\ m\ge2.&lt;/math&gt;
Eventually the sequence &lt;math&gt;S^{1}(n),S^{2}(n),S^{3}(n),\ldots&lt;/math&gt; becomes a one digit number. Let &lt;math&gt;S^{*}(n)&lt;/math&gt; (the digital root of &lt;math&gt;n&lt;/math&gt;) represent this one digit number.

=== Example ===
Let us find the digital root of &lt;math&gt;1853&lt;/math&gt;.

:&lt;math&gt;S(1853)=17&lt;/math&gt;

:&lt;math&gt;S(17)=8&lt;/math&gt;

Thus,

:&lt;math&gt;S^{2}(1853)=8.&lt;/math&gt;

For simplicity let us agree simply that

:&lt;math&gt;S^{*}(1853)=\operatorname{dr}(1853)=8.&lt;/math&gt;

=== Proof that a constant value exists ===
How do we know that the sequence &lt;math&gt;S^{1}(n),S^{2}(n),S^{3}(n),\ldots&lt;/math&gt; eventually becomes a one digit number? Here's a proof:

Let &lt;math&gt;n=d_1+10d_2+\cdots+10^{m-1}d_m&lt;/math&gt;, for all &lt;math&gt;i&lt;/math&gt;, &lt;math&gt;d_i&lt;/math&gt; is an [[integer]] greater than or equal to 0 and less than 10. Then, &lt;math&gt;S(n)=d_1+d_2+\cdots+d_m&lt;/math&gt;. This means that &lt;math&gt;S(n)&lt;n&lt;/math&gt;, unless &lt;math&gt;d_2,d_3,\ldots,d_m=0&lt;/math&gt;, in which case &lt;math&gt;n&lt;/math&gt; is a one digit number. Thus, repeatedly using the &lt;math&gt;S(n)&lt;/math&gt; function would cause &lt;math&gt;n&lt;/math&gt; to decrease by at least 1, until it becomes a one digit number, at which point it will stay constant, as &lt;math&gt;S(d_1)=d_1&lt;/math&gt;.

==Congruence formula==
The formula is:
:&lt;math&gt; \operatorname{dr}(n) = \begin{cases}0 &amp; \mbox{if}\ n = 0, \\ 9 &amp; \mbox{if}\ n \neq 0,\ n\ \equiv 0\pmod{9},\\ n\ {\rm mod}\ 9 &amp; \mbox{if}\ n \not\equiv 0\pmod{9}\end{cases}&lt;/math&gt;
or,
:&lt;math&gt;\operatorname{dr}(n) = 1\ +\ ((n-1)\ {\rm mod}\ 9).&lt;/math&gt;

To generalize the concept of digital roots to other bases ''b'', one can simply change the 9 in the formula to ''b'' - 1.

{{OEIS|id=A010888}}

The digital root is the value modulo 9 because &lt;math&gt;10 \equiv 1\pmod{9},&lt;/math&gt; and thus &lt;math&gt;10^k \equiv 1^k \equiv 1\pmod{9},&lt;/math&gt; so regardless of position, the value mod 9 is the same – &lt;math&gt;a\cdot 100 \equiv a\cdot 10 \equiv a\pmod{9}&lt;/math&gt; – which is why digits can be meaningfully added. Concretely, for a three-digit number,
:&lt;math&gt;\operatorname{dr}(abc) \equiv a\cdot 10^2 + b\cdot 10 + c \cdot 1 \equiv a\cdot 1 + b\cdot 1 + c \cdot 1 \equiv a + b + c \pmod{9}&lt;/math&gt;.

To obtain the modular value with respect to other numbers ''n,'' one can take [[weighted sum]]s, where the weight on the ''k''th digit corresponds to the value of &lt;math&gt;10^k&lt;/math&gt; modulo ''n,'' or analogously for &lt;math&gt;b^k&lt;/math&gt; for different bases. This is simplest for 2, 5, and 10, where higher digits vanish (since 2 and 5 divide 10), which corresponds to the familiar fact that the divisibility of a decimal number with respect to 2, 5, and 10 can be checked by the last digit (even numbers end in 0, 2, 4, 6, or 8).

Also of note is the modulus 11: since &lt;math&gt;10 \equiv -1\pmod{11},&lt;/math&gt; and thus &lt;math&gt;10^2 \equiv (-1)^2 \equiv 1\pmod{11},&lt;/math&gt; taking the ''alternating'' sum of digits yields the value modulo 11.

== Some properties of digital roots ==
The digital root of a number is zero if and only if the number is itself zero.
:&lt;math&gt;\operatorname{dr}(n)=0 \Leftrightarrow n=0.&lt;/math&gt;
The digital root of a number is a positive integer if and only if the number is itself a positive integer.
:&lt;math&gt;\operatorname{dr}(n)&gt;0 \Leftrightarrow n&gt;0.&lt;/math&gt;
The digital root of &lt;math&gt;n&lt;/math&gt; is &lt;math&gt;n&lt;/math&gt; itself if and only if the number has exactly one digit.
:&lt;math&gt;\operatorname{dr}(n)=n \Leftrightarrow n \in \{0,1,2,3,4,5,6,7,8,9\}.&lt;/math&gt;
The digital root of &lt;math&gt;n&lt;/math&gt; is less than &lt;math&gt;n&lt;/math&gt; if and only if the number is greater than or equal to 10.
:&lt;math&gt;\operatorname{dr}(n)&lt;n \Leftrightarrow n \ge 10.&lt;/math&gt;
The digital root of &lt;math&gt;a&lt;/math&gt; + &lt;math&gt;b&lt;/math&gt; is digital root of the sum of the digital root of &lt;math&gt;a&lt;/math&gt; and the digital root of &lt;math&gt;b&lt;/math&gt;.
:&lt;math&gt;\operatorname{dr}(a+b) = \operatorname{dr}(\operatorname{dr}(a)+\operatorname{dr}(b) ).&lt;/math&gt;
The digital root of &lt;math&gt;a&lt;/math&gt; - &lt;math&gt;b&lt;/math&gt; is congruent with the difference of the digital root of &lt;math&gt;a&lt;/math&gt; and the digital root of &lt;math&gt;b&lt;/math&gt; modulo 9.
:&lt;math&gt;\operatorname{dr}(a-b) \equiv \operatorname{dr}(a)-\operatorname{dr}(b) \pmod{9}.&lt;/math&gt;
Especially, we can define the digital root of minus &lt;math&gt;n&lt;/math&gt; as follows:
:&lt;math&gt;\operatorname{dr}(-n) \equiv -\operatorname{dr}(n) \pmod{9}.&lt;/math&gt;
The digital root of &lt;math&gt;a&lt;/math&gt; &amp;times; &lt;math&gt;b&lt;/math&gt; is digital root of the product of the digital root of &lt;math&gt;a&lt;/math&gt; and the digital root of &lt;math&gt;b&lt;/math&gt;.
:&lt;math&gt;\operatorname{dr}(ab) = \operatorname{dr}(\operatorname{dr}(a)\cdot\operatorname{dr}(b) ).&lt;/math&gt;
*The digital root of a nonzero number is 9 if and only if the number is itself a [[multiple (mathematics)|multiple]] of 9.
:&lt;math&gt;\operatorname{dr}(n)=9 \Leftrightarrow n=9m \quad \text{for } m=1,2,3,\ldots.&lt;/math&gt;
*The digital root of a nonzero number is a multiple of 3 if and only if the number is itself a multiple of 3.
:&lt;math&gt;\begin{align} \operatorname{dr}(n) &amp;=3 \Leftrightarrow n=9m+3 &amp; \text{ for } m=0,1,2,\ldots,\\ \operatorname{dr}(n) &amp;=6 \Leftrightarrow n=9m+6 &amp; \ \text{for}\  m=0,1,2,\ldots,\\ \operatorname{dr}(n) &amp;=9 \Leftrightarrow n=9m   &amp; \ \text{for}\  m=1,2,3,\ldots.\end{align}&lt;/math&gt;
*The digital root of a [[factorial]] ≥ 6! is 9.
:&lt;math&gt;\operatorname{dr}(n!)=9 \Leftrightarrow n \ge 6.&lt;/math&gt;
*The digital root of a [[square number|square]] is 1, 4, 7, or 9. Digital roots of square numbers progress in the sequence 1, 4, 9, 7, 7, 9, 4, 1, 9.
*The digital root of a [[perfect cube]] is 1, 8 or 9, and digital roots of perfect cubes progress in that exact sequence.
*The digital root of a [[prime number]] (except 3) is 1, 2, 4, 5, 7, or 8.
*The digital root of a [[power of two|power of 2]] is 1, 2, 4, 5, 7, or 8. Digital roots of the powers of 2 progress in the sequence 1, 2, 4, 8, 7, 5. This even applies to negative powers of 2; for example, 2 to the power of 0 is 1; 2 to the power of -1 (minus one) is .5, with a digital root of 5; 2 to the power of -2 is .25, with a digital root of 7; and so on, ad infinitum in both directions. This is because negative powers of 2 share the same digits (after removing leading zeroes) as corresponding positive powers of 5, whose digital roots progress in the sequence 1, 5, 7, 8, 4, 2.
* The digital root of a power of 5 is 1, 2, 4, 5, 7 or 8. Digital roots of the powers of 5 progress in the sequence 1, 5, 7, 8, 4, 2. This even applies to negative powers of 5; for example, 5 to the power of 0 is 1; 5 to the power of -1 (minus one) is .2, with a digital root of 2; 5 to the power of -2 is .04, with a digital root of 4; and so on, ad infinitum in both directions. This is because the negative powers of 5 share the same digits (after removing leading zeroes) as corresponding positive powers of 2, whose digital roots progress in sequence 1, 2, 4, 8, 7, 5.
* The digital roots of powered numbers progress in sequence (only certain for positive powers, although in for some exceptions it also may occur for negative powers), and this is because of one of the previously shown properties. As the digital root of ''a''  ''b'' is congruent with the multiple of the digital root of ''a'' and the digital root of ''b'' modulo 9, the digital root of ''a''  ''a'' will also do it. So, for example, as shown above, powers of 2 will follows the sequence 1, 2, 4, 8, 7, 5; Powers of 47 (whose digital root is 2) will also follow this sequence. The very sequence follows this rule, and is appliable to any other number.
:&lt;math&gt;\operatorname{dr}(a^n) \equiv \operatorname{dr}(a)^n \pmod{9}.&lt;/math&gt;
*The digital root of an even [[perfect number]] (except 6) is 1.
*The digital root of a centered hexagram, or [[star number]] is 1 or 4. Digital roots of star numbers progress in the sequence 1, 4, 1.
*The digital root of a [[centered hexagonal number]] is 1 or 7, their digital roots progressing in the sequence 1, 7, 1.
*The digital root of a [[triangular number]] is 1, 3, 6 or 9. Digital roots of triangular numbers progress in the sequence 1, 3, 6, 1, 6, 3, 1, 9, 9, which is palindromic after the first eight terms.
*The digital root of [[Fibonacci number]]s is a repeating pattern of 1, 1, 2, 3, 5, 8, 4, 3, 7, 1, 8, 9, 8, 8, 7, 6, 4, 1, 5, 6, 2, 8, 1, 9.
*The digital root of [[Lucas number]]s is a repeating pattern of 2, 1, 3, 4, 7, 2, 9, 2, 2, 4, 6, 1, 7, 8, 6, 5, 2, 7, 9, 7, 7, 5, 3, 8.
*The digital root of the product of [[twin prime]]s, other than 3 and 5, is 8. The digital root of the product of 3 and 5 (twin primes) is 6.

== In other bases ==
This article is about the digital root in [[decimal]] or base ten, hence it is the number mod 9. It is nothing different as the number converted to base 9 and then only the last digit taken.
In other radixes the digital root is number mod (base-1) so in [[duodecimal|base 12]] a digital root of a number is the number mod 11 (Ɛ&lt;sub&gt;duod&lt;/sub&gt;), for example, 1972&lt;sub&gt;duod&lt;/sub&gt; is 1 + 9 + 7 + 2 = 19 = 17&lt;sub&gt;duod&lt;/sub&gt; which is 1 + 7 = 8, while in decimal the root of the same number (3110) is 5; and in [[hexadecimal|base 16]] a digital root of a number is the number mod 15 (0xF), for example, 0x7DF is 7 + 13 + 15 = 35 = 0x23 which is 2 + 3 = 5, while in decimal the root of the same number (2015) is 8.

== In popular culture ==
Digital roots form an important mechanic in the visual novel adventure game [[Nine Hours, Nine Persons, Nine Doors]].

== See also ==
{{Div col}}
*[[Base 9]]
*[[Casting out nines]]
*[[Digit sum]]
*[[Hamming weight]]
*[[Multiplicative digital root]]
*[[Vedic square]]
{{Div col end}}

==References==
*{{Citation|last1=Averbach|first1=Bonnie|author1-link=Bonnie Averbach|last2=Chein|first2=Orin|author2-link=Orin Chein|date=27 May 1999|title=Problem Solving Through Recreational Mathematics|publisher=Courier Dover Publications|location=Mineola, NY|edition=reprinted|series=Dover Books on Mathematics|isbn=0-486-40917-1|pages=125–127}} ({{Google books|qtMoAwAAQBAJ|online copy|page=125}})
*{{Citation|last=Ghannam|first=Talal|author-link=Talal Ghannam|date=4 January 2011|title=The Mystery of Numbers: Revealed Through Their Digital Root|publisher=CreateSpace Publications|isbn=978-1-4776-7841-1|url=https://www.createspace.com/3529186|pages=68–73}} ({{Google books|PN4dzi8eoZQC|online copy|page=68}})
*{{Citation|last=Hall|first=F. M.|author-link=Frederick Michael Hall|year=1980|title=An Introduction into Abstract Algebra|publisher=CUP Archive|location=Cambridge, U.K.|edition=2nd|volume=1|isbn=978-0-521-29861-2|page=101}} ({{Google books|qqs8AAAAIAAJ|online copy|page=101}})
*{{Citation|last=O'Beirne|first=T. H.|author-link=T. H. O'Beirne|date=13 March 1961|title=Puzzles and Paradoxes|journal=New Scientist|publisher=Reed Business Information|volume=10|issue=230|issn=0262-4079|pages=53–54}} ({{Google books|j4VdAP43V7cC|online copy|page=53}})
*{{Citation|last1=Rouse Ball|first1=W. W.|author1-link=Walter William Rouse Ball|last2=Coxeter|first2=H. S. M.|author2-link=Harold Scott Macdonald Coxeter|date=6 May 2010|title=Mathematical Recreations and Essays|publisher=Dover Publications|location=NY|edition=13th|series=Dover Recreational Mathematics|isbn=978-0-486-25357-2}} ({{Google books|9lJqNJhYc9oC|online copy}})

== External links ==
* [http://people.revoledu.com/kardi/tutorial/DigitSum/index.html pattern of digital root using MS Excel]
*{{MathWorld|title=Digital Root|id=DigitalRoot}}

[[Category:Algebra]]
[[Category:Number theory]]

[[de:Quersumme#Einstellige (oder iterierte) Quersumme]]</text>
      <sha1>s5ru4u8tdfjiektphefzdtfrgyedyb3</sha1>
    </revision>
  </page>
  <page>
    <title>Entropy rate</title>
    <ns>0</ns>
    <id>11071463</id>
    <revision>
      <id>869428239</id>
      <parentid>869427909</parentid>
      <timestamp>2018-11-18T15:27:00Z</timestamp>
      <contributor>
        <username>Fvultier</username>
        <id>27814133</id>
      </contributor>
      <comment>/* Entropy rates for Markov chains */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3077">In the mathematical theory of [[probability]], the '''entropy rate''' or '''source information rate''' of a [[stochastic process]] is, informally, the time density of the average information in a stochastic process. For stochastic processes with a [[countable]] index, the [[Entropy (information theory)|entropy]] rate &lt;math&gt;H(X)&lt;/math&gt; is the limit of the [[joint entropy]] of &lt;math&gt;n&lt;/math&gt; members of the process &lt;math&gt;X_k&lt;/math&gt; divided by &lt;math&gt;n&lt;/math&gt;, as &lt;math&gt;n&lt;/math&gt; [[Limit (mathematics)|tends to]] [[infinity]]:

:&lt;math&gt;H(X) = \lim_{n \to \infty} \frac{1}{n} H(X_1, X_2, \dots X_n)&lt;/math&gt;

when the limit exists. An alternative, related quantity is:

:&lt;math&gt;H'(X) = \lim_{n \to \infty} H(X_n|X_{n-1}, X_{n-2}, \dots X_1)&lt;/math&gt;

For [[strongly stationary]] stochastic processes, &lt;math&gt;H(X) = H'(X)&lt;/math&gt;.  The entropy rate can be thought of as a general property of stochastic sources; this is the [[asymptotic equipartition property]]. The entropy rate may be used to estimate the complexity of stochastic processes. It is used in diverse applications ranging from characterizing the complexity of languages, blind source separation, through to optimizing quantizers and data compression algorithms. For example, a maximum entropy rate criterion may be used for [[feature selection]] in [[machine learning]] .&lt;ref&gt;{{cite journal |last1=Einicke |first1=G. A. |title=Maximum-Entropy Rate Selection of Features for Classifying Changes in Knee and Ankle Dynamics During Running |journal=IEEE Journal of Biomedical and Health Informatics |volume=28 |issue=4 |pages=1097–1103 |year=2018 |doi= 10.1109/JBHI.2017.2711487 }}&lt;/ref&gt;

== Entropy rates for Markov chains ==
Since a stochastic process defined by a [[Markov chain]] that is [[Markov chain#Reducibility|irreducible]], [[aperiodic]]
and [[Markov chain#Transience|positive recurrent]] has a [[stationary distribution]], the entropy rate is independent of the initial distribution.

For example, for such a Markov chain &lt;math&gt;Y_k&lt;/math&gt; defined on a [[countable]] number of states, given the [[Stochastic matrix|transition matrix]] &lt;math&gt;P_{ij}&lt;/math&gt;, &lt;math&gt;H(Y)&lt;/math&gt; is given by:

:&lt;math&gt;\displaystyle H(Y) = - \sum_{ij} \mu_i P_{ij} \log P_{ij}&lt;/math&gt;

where &lt;math&gt;\mu_i&lt;/math&gt; is the [[asymptotic distribution]] of the chain.

A simple consequence of this definition is that an [[independent and identically distributed|i.i.d.]] [[stochastic process]] has an entropy rate that is the same as the [[Entropy (information theory)|entropy]] of any individual member of the process.

==See also==
* [[Information source (mathematics)]]
* [[Markov information source]]
* [[Asymptotic equipartition property]]
* [[Maximal Entropy Random Walk]] - chosen to maximize entropy rate

==References==
{{Reflist}}

* Cover, T. and Thomas, J. (1991) Elements of Information Theory, John Wiley and Sons, Inc., {{ISBN|0-471-06259-6}} [http://www3.interscience.wiley.com/cgi-bin/bookhome/110438582?CRETRY=1&amp;SRETRY=0]

[[Category:Information theory]]
[[Category:Entropy]]
[[Category:Markov models]]
[[Category:Temporal rates]]</text>
      <sha1>3cx9jkk7hlq2w22qtbbv8etobmae7hv</sha1>
    </revision>
  </page>
  <page>
    <title>Factorization lemma</title>
    <ns>0</ns>
    <id>4522019</id>
    <revision>
      <id>692586523</id>
      <parentid>692586125</parentid>
      <timestamp>2015-11-26T20:09:57Z</timestamp>
      <contributor>
        <username>Andaouzek</username>
        <id>19271543</id>
      </contributor>
      <comment>/* f takes only positive values */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4050">In [[measure theory]], the '''factorization lemma''' allows us to express a function ''f'' with another function ''T'' if ''f'' is [[measurable]] with respect to ''T''. An application of this is [[regression analysis]].

==Theorem==
Let &lt;math&gt;T:\Omega\rightarrow\Omega'&lt;/math&gt; be a function of a set &lt;math&gt;\Omega&lt;/math&gt; in a [[measure space]] &lt;math&gt;(\Omega',\mathcal{A}')&lt;/math&gt; and let &lt;math&gt;f:\Omega\rightarrow\overline{\mathbb{R}}&lt;/math&gt; be a scalar function on &lt;math&gt;\Omega&lt;/math&gt;. Then &lt;math&gt;f&lt;/math&gt; is measurable with respect to the [[σ-algebra]] &lt;math&gt;\sigma(T)=T^{-1}(\mathcal{A}')&lt;/math&gt; generated by &lt;math&gt;T&lt;/math&gt; in &lt;math&gt;\Omega&lt;/math&gt; if and only if there exists a measurable function &lt;math&gt;g:(\Omega',\mathcal{A}')\rightarrow(\overline{\mathbb{R}},\mathcal{B}(\overline{\mathbb{R}}))&lt;/math&gt; such that &lt;math&gt;f=g\circ T&lt;/math&gt;, where &lt;math&gt;\mathcal{B}(\overline{\mathbb{R}})&lt;/math&gt; denotes the [[Borel set]] of the real numbers. If &lt;math&gt;f&lt;/math&gt; only takes finite values, then &lt;math&gt;g&lt;/math&gt; also only takes finite values.

==Proof==
First, if &lt;math&gt;f=g\circ T&lt;/math&gt;, then ''f'' is &lt;math&gt;\sigma(T)-\mathcal{B}(\overline{\mathbb{R}})&lt;/math&gt; measurable because it is the composition of a &lt;math&gt;\sigma(T)-\mathcal{A}'&lt;/math&gt; and of a &lt;math&gt;\mathcal{A}'-\mathcal{B}(\overline{\mathbb{R}})&lt;/math&gt; measurable function. The proof of the converse falls into four parts: (1)''f'' is a [[step function]], (2)''f'' is a positive function, (3) ''f'' is any scalar function, (4) ''f'' only takes finite values.

===''f'' is a step function===
Suppose &lt;math&gt;f=\sum_{i=1}^n\alpha_i 1_{A_i}&lt;/math&gt; is a step function, i.e. &lt;math&gt;n\in\mathbb{N}^*, \forall i\in[\![1,n]\!], A_i\in\sigma(T)&lt;/math&gt; and &lt;math&gt;\alpha_i\in\mathbb{R}^+&lt;/math&gt;. As ''T'' is a measurable function, for all ''i'', there exists &lt;math&gt;A_i'\in\mathcal{A}'&lt;/math&gt; such that &lt;math&gt;A_i=T^{-1}(A_i')&lt;/math&gt;. &lt;math&gt;g=\sum_{i=1}^n\alpha_i 1_{A_i'}&lt;/math&gt; fulfils the requirements.

===''f'' takes only positive values===
If ''f'' takes only positive values, it is the limit, for [[pointwise convergence]], of a increasing sequence &lt;math&gt;(u_n)_{n\in\mathbb{N}}&lt;/math&gt; of step functions. For each of these, by (1), there exists &lt;math&gt;g_n&lt;/math&gt; such that &lt;math&gt;u_n=g_n\circ T&lt;/math&gt;. The function &lt;math&gt;\lim_{n\rightarrow+\infty}g_n&lt;/math&gt;, which exists on the image of T for [[pointwise convergence]] because &lt;math&gt;(u_n)_{n\in\mathbb{N}}&lt;/math&gt; is monotonic, fulfils the requirements.

===General case===
We can decompose ''f'' in a positive part &lt;math&gt;f^+&lt;/math&gt; and a negative part &lt;math&gt;f^-&lt;/math&gt;. We can then find &lt;math&gt;g_0^+&lt;/math&gt; and &lt;math&gt;g_0^-&lt;/math&gt; such that &lt;math&gt;f^+=g_0^+\circ T&lt;/math&gt; and &lt;math&gt;f^-=g_0^-\circ T&lt;/math&gt;. The problem is that the difference &lt;math&gt;g:=g^+-g^-&lt;/math&gt; is not defined on the set &lt;math&gt;U=\{x:g_0^+(x)=+\infty\}\cap\{x:g_0^-(x)=+\infty\}&lt;/math&gt;. Fortunately, &lt;math&gt;T(\Omega)\cap U=\varnothing&lt;/math&gt; because &lt;math&gt;g_0^+(T(\omega))=f^+(\omega)=+\infty&lt;/math&gt; always implies &lt;math&gt;g_0^-(T(\omega))=f^-(\omega)=0&lt;/math&gt;
We define &lt;math&gt;g^+=1_{\Omega'\backslash U}g_0^+&lt;/math&gt; and &lt;math&gt;g^-=1_{\Omega'\backslash U}g_0^-&lt;/math&gt;. &lt;math&gt;g=g^+-g^-&lt;/math&gt; fulfils the requirements.

===''f'' takes finite values only===
If ''f'' takes finite values only, we will show that ''g'' also only takes finite values. Let &lt;math&gt;U'=\{\omega:|g(\omega)|=+\infty\}&lt;/math&gt;. Then &lt;math&gt;g_0=1_{\Omega'\backslash U'}g&lt;/math&gt; fulfils the requirements because &lt;math&gt;U'\cap T(\Omega)=\varnothing&lt;/math&gt;.

===Importance of the measure space===
If the function &lt;math&gt; f &lt;/math&gt; is not scalar, but takes values in a different measurable space, such as &lt;math&gt;\mathbb{R} &lt;/math&gt; with its trivial σ-algebra (the empty set, and the whole real line) instead of &lt;math&gt;\mathcal{B}(\mathbb{R}) &lt;/math&gt;, then the lemma becomes false (as the restrictions on &lt;math&gt; f &lt;/math&gt; are much weaker).

==References==
* Heinz Bauer, Ed. (1992) ''Maß- und Integrationstheorie''. Walter de Gruyter edition. 11.7 Faktorisierungslemma p.&amp;nbsp;71-72.

[[Category:Measure theory]]
[[Category:Lemmas]]</text>
      <sha1>er7dla20hd318p1mx3bc1ec2o92x0ea</sha1>
    </revision>
  </page>
  <page>
    <title>Fourier-transform spectroscopy</title>
    <ns>0</ns>
    <id>47732</id>
    <revision>
      <id>841212355</id>
      <parentid>800851213</parentid>
      <timestamp>2018-05-14T16:41:17Z</timestamp>
      <contributor>
        <username>DeprecatedFixerBot</username>
        <id>33330201</id>
      </contributor>
      <minor/>
      <comment>Removed deprecated parameter(s) from [[Template:Div col]] using [[User:DeprecatedFixerBot| DeprecatedFixerBot]]. Questions? See [[Template:Div col#Usage of "cols" parameter]] or [[User talk:TheSandDoctor|msg TSD!]] (please mention that this is task #2!))</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14966">'''Fourier-transform spectroscopy''' is a measurement technique whereby spectra are collected based on measurements of the [[coherence (physics)|coherence]] of a [[Radiation|radiative]] source, using [[time-domain]] or space-domain measurements of the [[electromagnetic radiation]] or other type of radiation.
It can be applied to a variety of types of spectroscopy including [[optical spectroscopy]], [[infrared spectroscopy]] ([[Fourier-transform infrared spectroscopy|FTIR]], FT-NIRS), [[Nuclear Magnetic Resonance Spectroscopy|nuclear magnetic resonance]] (NMR) and magnetic resonance spectroscopic imaging (MRSI),&lt;ref&gt;Antoine Abragam. 1968. ''Principles of Nuclear Magnetic Resonance'', Cambridge University Press: Cambridge, UK.&lt;/ref&gt; [[mass spectrometry]] and [[electron spin resonance]] spectroscopy. There are several methods for measuring the temporal [[coherence (physics)|coherence]] of the light (see: [[Optical autocorrelation#Field autocorrelation|field-autocorrelation]]), including the continuous wave ''Michelson'' or ''Fourier-transform'' spectrometer and the pulsed Fourier-transform spectrograph (which is more sensitive and has a much shorter sampling time than conventional spectroscopic techniques, but is only applicable in a laboratory environment).

The term ''Fourier-transform spectroscopy'' reflects the fact that in all these techniques, a [[Fourier transform]] is required to turn the raw data into the actual [[frequency spectrum|spectrum]], and in many of the cases in optics involving interferometers, is based on the [[Wiener–Khinchin theorem]].

==Conceptual introduction==

===Measuring an emission spectrum===
[[File:Spectrum of blue flame.svg|thumb|300 px| An example of a [[spectrum]]: The spectrum of light emitted by the blue flame of a [[butane torch]]. The horizontal axis is the [[wavelength]] of light, and the vertical axis represents how much light is emitted by the torch at that wavelength.]]
One of the most basic tasks in [[spectroscopy]] is to characterize the [[spectrum]] of a light source: how much light is emitted at each different wavelength. The most straightforward way to measure a spectrum is to pass the light through a [[monochromator]], an instrument that blocks all of the light ''except'' the light at a certain wavelength (the un-blocked wavelength is set by a knob on the monochromator). Then the intensity of this remaining (single-wavelength) light is measured. The measured intensity directly indicates how much light is emitted at that wavelength. By varying the monochromator's wavelength setting, the full spectrum can be measured. This simple scheme in fact describes how ''some'' spectrometers work.

Fourier-transform spectroscopy is a less intuitive way to get the same information. Rather than allowing only one wavelength at a time to pass through to the detector, this technique lets through a beam containing many different wavelengths of light at once, and measures the ''total'' beam intensity. Next, the beam is modified to contain a ''different'' combination of wavelengths, giving a second data point. This process is repeated many times. Afterwards, a computer takes all this data and works backwards to infer how much light there is at each wavelength.

To be more specific, between the light source and the detector, there is a certain configuration of mirrors that allows some wavelengths to pass through but blocks others (due to [[wave interference]]). The beam is modified for each new data point by moving one of the mirrors; this changes the set of wavelengths that can pass through.

As mentioned, computer processing is required to turn the raw data (light intensity for each mirror position) into the desired result (light intensity for each wavelength). The processing required turns out to be a common algorithm called the [[Fourier transform]] (hence the name, "Fourier-transform spectroscopy"). The raw data is sometimes called an "interferogram". Because of the existing computer equipment requirements, and the ability of light to analyze very small amounts of substance, it is often beneficial to automate many aspects of the sample preparation. The sample can be better preserved and the results are much easier to replicate. Both of these benefits are important, for instance, in testing situations that may later involve legal action, such as those involving drug specimens.&lt;ref&gt;Semiautomated depositor for infrared microspectrometry
http://www.opticsinfobase.org/viewmedia.cfm?uri=as-57-9-1078&amp;seq=0&lt;/ref&gt;

===Measuring an absorption spectrum===
[[File:FTIR-interferogram.svg|thumb|An "interferogram" from a Fourier-transform spectrometer. This is the "raw data" which can be [[Fourier transform|Fourier-transformed]] into an actual spectrum. The peak at the center is the ZPD position ("zero path difference"): Here, all the light passes through the [[Michelson interferometer|interferometer]] because its two arms have equal length.]]
The method of Fourier-transform spectroscopy can also be used for [[absorption spectroscopy]]. The primary example is "[[Fourier-transform infrared spectroscopy|FTIR Spectroscopy]]", a common technique in chemistry.

In general, the goal of absorption spectroscopy is to measure how well a sample absorbs or transmits light at each different wavelength. Although absorption spectroscopy and emission spectroscopy are different in principle, they are closely related in practice; any technique for emission spectroscopy can also be used for absorption spectroscopy. First, the emission spectrum of a broadband lamp is measured (this is called the "background spectrum"). Second, the emission spectrum of the same lamp ''shining through the sample'' is measured (this is called the "sample spectrum"). The sample will absorb some of the light, causing the spectra to be different. The ratio of the "sample spectrum" to the "background spectrum" is directly related to the sample's absorption spectrum.

Accordingly, the technique of "Fourier-transform spectroscopy" can be used both for measuring emission spectra (for example, the emission spectrum of a star), ''and'' absorption spectra (for example, the absorption spectrum of a liquid).

==Continuous-wave ''Michelson'' or ''Fourier-transform'' spectrograph==
[[File:Fourier transform spectrometer.png|thumb|250px|The Fourier-transform spectrometer is just a Michelson interferometer, but one of the two fully reflecting mirrors is movable, allowing a variable delay (in the travel time of the light) to be included in one of the beams.]]

The Michelson spectrograph is similar to the instrument used in the [[Michelson–Morley experiment]]. Light from the source is split into two beams by a half-silvered mirror, one is reflected off a fixed mirror and one off a movable mirror, which introduces a time delay—the Fourier-transform spectrometer is just a [[Michelson interferometer]] with a movable mirror. The beams interfere, allowing the temporal [[coherence (physics)|coherence]] of the light to be measured at each different time delay setting, effectively converting the time domain into a spatial coordinate. By making measurements of the signal at many discrete positions of the movable mirror, the spectrum can be reconstructed using a Fourier transform of the temporal [[coherence (physics)|coherence]] of the light. Michelson spectrographs are capable of very high spectral resolution observations of very bright sources.
The Michelson or Fourier-transform spectrograph was popular for infra-red applications at a time when infra-red astronomy only had single-pixel detectors. Imaging Michelson spectrometers are a possibility, but in general have been supplanted by imaging [[Fabry–Pérot]] instruments, which are easier to construct.

===Extracting the spectrum===

The intensity as a function of the path length difference (also denoted as retardation) in the interferometer &lt;math&gt;p&lt;/math&gt; and [[wavenumber]] &lt;math&gt;\tilde{\nu} = 1/\lambda&lt;/math&gt; is &lt;ref&gt;Peter Atkins, Julio De Paula. 2006. ''Physical Chemistry'', 8th ed. Oxford University Press: Oxford, UK.&lt;/ref&gt;

:&lt;math&gt;I(p,\tilde{\nu}) = I(\tilde{\nu})[1 + \cos(2\pi\tilde{\nu}p)],&lt;/math&gt;

where &lt;math&gt;I(\tilde{\nu})&lt;/math&gt; is the spectrum to be determined.  Note that it is not necessary for &lt;math&gt;I(\tilde{\nu})&lt;/math&gt; to be modulated by the sample before the interferometer.  In fact, most [[Fourier-transform infrared spectroscopy|FTIR spectrometers]] place the sample after the interferometer in the optical path.  The total intensity at the detector is

: &lt;math&gt;
\begin{align}
I(p) &amp; = \left( p, \int_0^\infty I(p,\tilde{\nu}) d\tilde{\nu} \right) \\
&amp; = \left(p, \int_0^\infty I(\tilde{\nu})[1 + \cos (2\pi\tilde{\nu}p)] \, d\tilde{\nu}\right) \text{ for all desired values of } p.
\end{align}
&lt;/math&gt;

This is just a [[Sine and cosine transforms|Fourier cosine transform]].  The inverse gives us our desired result in terms of the measured quantity &lt;math&gt;I(p)&lt;/math&gt;:
:&lt;math&gt;I(\tilde{\nu}) = 4 \int_0^\infty [I(p) - \tfrac{1}{2} I(p=0)] \cos (2\pi\tilde{\nu}p) \, dp. &lt;/math&gt;

==Pulsed Fourier-transform spectrometer==

A pulsed Fourier-transform spectrometer does not employ transmittance techniques{{definition_needed|reason=What is a transmittance technique?|date=August 2016}}.  In the most general description of pulsed FT spectrometry, a sample is exposed to an energizing event which causes a periodic response.  The frequency of the periodic response, as governed by the field conditions in the spectrometer, is indicative of the measured properties of the analyte.

===Examples of pulsed Fourier-transform spectrometry===

In magnetic spectroscopy ([[Electron paramagnetic resonance|EPR]], [[Nuclear magnetic resonance|NMR]]), a Microwave pulse (EPR) or a radio frequency pulse (NMR) in a strong ambient magnetic field is used as the energizing event.  This turns the magnetic particles at an angle to the ambient field, resulting in gyration.  The gyrating spins then induce a periodic current in a detector coil.  Each spin exhibits a characteristic frequency of gyration (relative to the field strength) which reveals information about the analyte.

In [[Fourier-transform mass spectrometry]], the energizing event is the injection of the charged sample into the strong electromagnetic field of a cyclotron.  These particles travel in circles, inducing a current in a fixed coil on one point in their circle.  Each traveling particle exhibits a characteristic cyclotron frequency-field ratio revealing the masses in the sample.

===Free induction decay===
Pulsed FT spectrometry gives the advantage of requiring a single, time-dependent measurement which can easily deconvolute a set of similar but distinct signals.  The resulting composite signal, is called a ''free induction decay,'' because typically the signal will decay due to inhomogeneities in sample frequency, or simply unrecoverable loss of signal due to entropic loss of the property being measured.

=== Nanoscale spectroscopy with pulsed sources ===
Pulsed sources allow for the utilization of Fourier-transform spectroscopy principles in [[Near-field scanning optical microscope|scanning near-field optical microscopy]] techniques. Particularly in [[nano-FTIR]], where the scattering from a sharp probe-tip is used to perform spectroscopy of samples with nanoscale spatial resolution, a high-power illumination from pulsed infrared lasers makes up for a relatively small [[Scattering cross section|scattering efficiency]] (often &lt; 1%) of the probe.&lt;ref&gt;{{Cite journal|last=Hegenbarth|first=R|last2=Steinmann|first2=A|last3=Mastel|first3=S|last4=Amarie|first4=S|last5=Huber|first5=A J|last6=Hillenbrand|first6=R|last7=Sarkisov|first7=S Y|last8=Giessen|first8=H|title=High-power femtosecond mid-IR sources for s-SNOM applications|url=http://stacks.iop.org/2040-8986/16/i=9/a=094003?key=crossref.3eb2b21f107d58830fc324d0ec18d34e|journal=Journal of Optics|volume=16|issue=9|doi=10.1088/2040-8978/16/9/094003|bibcode=2014JOpt...16i4003H}}&lt;/ref&gt;

==Stationary forms of Fourier-transform spectrometers==
In addition to the scanning forms of Fourier-transform spectrometers, there are a number of stationary or self-scanned forms.&lt;ref&gt;William H. Smith {{US patent|4976542}} Digital Array Scanned Interferometer, issued Dec. 11, 1990&lt;/ref&gt; While the analysis of the interferometric output is similar to that of the typical scanning interferometer, significant differences apply, as shown in the published analyses. Some stationary forms retain the Fellgett multiplex advantage, and their use in the spectral region where detector noise limits apply is similar to the scanning forms of the FTS. In the photon-noise limited region, the application of stationary interferometers is dictated by specific consideration for the spectral region and the application.

==Fellgett advantage==
{{Main article|Fellgett's advantage}}
One of the most important advantages of Fourier-transform spectroscopy was shown by P. B. Fellgett, an early advocate of the method. The Fellgett advantage, also known as the multiplex principle, states that when obtaining a spectrum when measurement noise is dominated by detector noise (which is independent of the power of radiation incident on the detector), a multiplex spectrometer such as a Fourier-transform spectrometer will produce a relative improvement in signal-to-noise ratio, compared to an equivalent scanning [[monochromator]], of the order of the square root of ''m'', where ''m'' is the number of sample points comprising the spectrum. However, if the detector is [[shot-noise]] dominated, the noise will be proportional to the square root of the power, thus for a broad boxcar spectrum (continuous broadband source), the noise is proportional to the square root of ''m'', thus precisely offset the Fellgett's advantage. Shot noise is the main reason Fourier-transform spectrometry was never popular for ultraviolet (UV) and visible spectra.

==See also==
{{div col|colwidth=30em}}
*[[Applied spectroscopy]]
*[[Forensic chemistry]]
*[[Forensic polymer engineering]]
*[[Nuclear magnetic resonance]]
*[[Time stretch dispersive Fourier transform]]
*[[Infrared spectroscopy]]
*[[Infrared spectroscopy of metal carbonyls]]
*[[nano-FTIR]]
{{div col end}}

==References==
{{reflist}}

==External links==
*[http://scienceworld.wolfram.com/physics/FourierTransformSpectrometer.html Description of how a Fourier transform spectrometer works]
*[https://web.archive.org/web/20120204045036/http://www.astro.livjm.ac.uk/courses/phys362/notes/ The Michelson or Fourier transform spectrograph]
*[http://www.ijvs.com/volume5/edition5/section1.html#Feature Internet Journal of Vibrational Spectroscopy – How FTIR works]
*[https://web.archive.org/web/20070520020645/http://www.osa.org/meetings/topicalmeetings/fts/default.aspx Fourier Transform Spectroscopy Topical Meeting and Tabletop Exhibit]

[[Category:Spectroscopy]]
[[Category:Fourier analysis]]
[[Category:Scientific techniques]]</text>
      <sha1>6eys4404peamkseghat3ssq7cnd80rw</sha1>
    </revision>
  </page>
  <page>
    <title>Fundamental frequency</title>
    <ns>0</ns>
    <id>11490</id>
    <revision>
      <id>856440021</id>
      <parentid>852498606</parentid>
      <timestamp>2018-08-25T06:21:18Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta8)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9982">[[File:Harmonic partials on strings.svg|thumb|250px|[[Vibration]] and [[standing wave]]s in a string, The fundamental and the first six [[overtone]]s]]

The '''fundamental frequency''', often referred to simply as the '''fundamental''', is defined as the lowest [[frequency]] of a [[periodic signal|periodic]] [[waveform]]. In music, the fundamental is the musical [[pitch (music)|pitch]] of a note that is perceived as the lowest [[harmonic series (music)#Partial|partial]] present. In terms of a superposition of [[Sine wave|sinusoid]]s (e.g. [[Fourier series]]), the fundamental frequency is the lowest frequency sinusoidal in the sum.  In some contexts, the fundamental is usually abbreviated as '''''f''&lt;sub&gt;0&lt;/sub&gt;''' (or '''FF'''), indicating the lowest frequency [[Zero-based numbering|counting from zero]].&lt;ref&gt;{{cite web |url=http://www.phon.ucl.ac.uk/home/johnm/sid/sidf.htm |title=sidfn |publisher=Phon.ucl.ac.uk |date= |accessdate=2012-11-27 |archive-url=https://web.archive.org/web/20130106050848/http://www.phon.ucl.ac.uk/home/johnm/sid/sidf.htm |archive-date=2013-01-06 |dead-url=yes |df= }}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.acoustics.hut.fi/publications/files/theses/lemmetty_mst/chap3.html |author=Lemmetty, Sami |title=Phonetics and Theory of Speech Production |publisher=Acoustics.hut.fi |date=1999 |accessdate=2012-11-27}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://fourier.eng.hmc.edu/e101/lectures/Fundamental_Frequency.pdf |title=Fundamental Frequency of Continuous Signals |author= |date=2011 |publisher=Fourier.eng.hmc.edu |accessdate=2012-11-27}}&lt;/ref&gt; In other contexts, it is more common to abbreviate it as '''''f''&lt;sub&gt;1&lt;/sub&gt;''', the first [[harmonic]].&lt;ref&gt;{{cite web|url=https://nchsdduncanapphysics.wikispaces.com/file/view/Standing+Waves+in+a+Tube+II.pdf |title=Standing Wave in a Tube II - Finding the Fundamental Frequency |publisher=Nchsdduncanapphysics.wikispaces.com |accessdate=2012-11-27}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://physics.kennesaw.edu/P11_standwaves3.pdf |title=Physics: Standing Waves |publisher=Physics.kennesaw.edu |accessdate=2012-11-27}}{{dead link|date=December 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.colorado.edu/physics/phys1240/phys1240_fa05/notes/lect24_Tu11_22_4up.pdf |title=Phys 1240: Sound and Music |author=Pollock, Steven |publisher=Colorado.edu |date=2005 |accessdate=2012-11-27 |archive-url=https://web.archive.org/web/20140515180200/http://www.colorado.edu/physics/phys1240/phys1240_fa05/notes/lect24_Tu11_22_4up.pdf |archive-date=2014-05-15 |dead-url=yes |df= }}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://hyperphysics.phy-astr.gsu.edu/hbase/waves/string.html |title=Standing Waves on a String |publisher=Hyperphysics.phy-astr.gsu.edu |date= |accessdate=2012-11-27}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://openlearn.open.ac.uk/mod/oucontent/view.php?id=397877&amp;section=5.13.2 |title=Creating musical sounds - OpenLearn - Open University
|publisher=Open University|accessdate=2014-06-04}}&lt;/ref&gt; (The second harmonic is then f&lt;sub&gt;2&lt;/sub&gt; = 2⋅f&lt;sub&gt;1&lt;/sub&gt;, etc.  In this context, the zeroth harmonic would be 0&amp;nbsp;Hz.)

{{Quote|Since the fundamental is the lowest frequency and is also perceived as the loudest, the ear identifies it as the specific pitch of the musical tone &lt;nowiki&gt;[&lt;/nowiki&gt;[[harmonic spectrum]]&lt;nowiki&gt;]&lt;/nowiki&gt;....The individual partials are not heard separately but are blended together by the ear into a single tone.&lt;ref&gt;Benward, Bruce and Saker, Marilyn (1997/2003). ''Music: In Theory and Practice'', Vol. I, p.xiii. Seventh edition. McGraw-Hill. {{ISBN|978-0-07-294262-0}}.&lt;/ref&gt;}}

==Explanation==
All sinusoidal and many non-sinusoidal waveforms are periodic, which is to say they repeat exactly over time. The period of a waveform is the &lt;math&gt; T &lt;/math&gt; for which the following equation is true:
:&lt;math&gt; x(t) = x(t + T)\text{ for all }t \in \mathbb{R} &lt;/math&gt;

Where &lt;math&gt; x(t) &lt;/math&gt; is the value of the waveform at &lt;math&gt; t &lt;/math&gt;. This means that this equation and a definition of the waveforms values over any interval of length &lt;math&gt; T &lt;/math&gt; is all that is required to describe the waveform completely.

Every waveform may be described using any multiple of this period. There exists a smallest period over which the function may be described completely and this period is the fundamental period. The fundamental frequency is defined as its reciprocal:

:&lt;math&gt; f_0 = \frac{1}{T}&lt;/math&gt;

[[File:F0leftclosed.gif|thumb|F0 Left End Closed]]Since the period is measured in units of time, then the units for frequency are 1/time. When the time units are seconds, the frequency is in &lt;math&gt;s^{-1}&lt;/math&gt;, also known as [[Hertz]].[[File:F0rightclosed.gif|thumb|F0 Right End Closed]]

For a tube of length &lt;math&gt; L &lt;/math&gt; with one end closed and the other end open the wavelength of the fundamental harmonic is &lt;math&gt; 4L&lt;/math&gt;, as indicated by the first two animations. Hence,
:&lt;math&gt;\lambda_0 = 4L.&lt;/math&gt;

Therefore, using the relation
:&lt;math&gt; \lambda_0 = \frac{v}{f_0}&lt;/math&gt; ,
where &lt;math&gt; v &lt;/math&gt; is the speed of the wave, we can find the fundamental frequency in terms of the speed of the wave and the length of the tube:
:&lt;math&gt; f_0 = \frac{v}{4L}.&lt;/math&gt;

[[File:F0bothclosed.gif|thumb|F0 Both Ends Closed]][[File:F0bothopen.gif|thumb|F0 Both Ends Open]]If the ends of the same tube are now both closed or both opened as in the last two animations, the wavelength of the fundamental harmonic becomes &lt;math&gt; 2L &lt;/math&gt;. By the same method as above, the fundamental frequency is found to be
:&lt;math&gt; f_0 = \frac{v}{2L}.&lt;/math&gt;

At 20&amp;nbsp;°C (68&amp;nbsp;°F) the [[speed of sound]] in air is 343&amp;nbsp;m/s (1129&amp;nbsp;ft/s). This speed is [[Speed of sound#Practical formula for dry air|temperature dependent]] and increases at a rate of 0.6&amp;nbsp;m/s for each degree Celsius increase in temperature (1.1&amp;nbsp;ft/s for every increase of 1&amp;nbsp;°F).

The velocity of a sound wave at different temperatures:-
*v = 343.2&amp;nbsp;m/s at 20&amp;nbsp;°C
*v = 331.3&amp;nbsp;m/s at 0&amp;nbsp;°C

==In music==
In music, the fundamental is the musical [[pitch (music)|pitch]] of a note that is perceived as the lowest [[harmonic series (music)#Partial|partial]] present. The fundamental may be created by [[vibration]] over the full length of a string or air column, or a higher harmonic chosen by the player. The fundamental is one of the [[harmonic]]s. A harmonic is any member of the harmonic series, an ideal set of frequencies that are positive integer multiples of a common fundamental frequency. The reason a fundamental is also considered a harmonic is because it is 1 times itself.
&lt;ref&gt;{{cite book | title = Music, Cognition, and Computerized Sound | author = [[John R. Pierce|Pierce, John R.]] | chapter = Consonance and Scales | editor = Perry R. Cook | publisher = MIT Press | year = 2001 | isbn = 978-0-262-53190-0 | url = https://books.google.com/books?id=L04W8ADtpQ4C&amp;pg=PA169&amp;dq=musical+tone+harmonic+partial+fundamental+integer}}&lt;/ref&gt;

The fundamental is the frequency at which the entire wave vibrates. Overtones are other sinusoidal components present at frequencies above the fundamental. All of the frequency components that make up the total waveform, including the fundamental and the overtones, are called partials. Together they form the harmonic series. Overtones which are perfect integer multiples of the fundamental are called harmonics. When an overtone is near to being harmonic, but not exact, it is sometimes called a harmonic partial, although they are often referred to simply as harmonics. Sometimes overtones are created that are not anywhere near a harmonic, and are just called partials or inharmonic overtones.

The fundamental frequency is considered the ''first harmonic'' and the ''first partial.''  The numbering of the partials and harmonics is then usually the same; the second partial is the second harmonic, etc.  But if there are inharmonic partials, the numbering no longer coincides. Overtones are numbered as they appear ''above'' the fundamental. So strictly speaking, the ''first'' overtone is the ''second'' partial (and usually the ''second'' harmonic). As this can result in confusion, only harmonics are usually referred to by their numbers, and overtones and partials are described by their relationships to those harmonics.

== Mechanical systems ==
Consider a spring, fixed at one end and having a mass attached to the other; this would be a single degree of freedom (SDoF) oscillator. Once set into motion, it will oscillate at its natural frequency. For a single degree of freedom oscillator, a system in which the motion can be described by a single coordinate, the natural frequency depends on two system properties: mass and stiffness; (providing the system is undamped). The radian frequency, ''ω''&lt;sub&gt;n&lt;/sub&gt;, can be found using the following equation:
:&lt;math&gt; \omega_\mathrm{n}^2 = \frac{k}{m} \, &lt;/math&gt;

Where:&lt;br/&gt;
''k'' = [[stiffness]] of the spring&lt;br/&gt;
''m'' = mass &lt;br/&gt;
''ω''&lt;sub&gt;n&lt;/sub&gt; = radian frequency (radians per second)

From the radian frequency, the natural frequency, ''f''&lt;sub&gt;n&lt;/sub&gt;, can be found by simply dividing ''ω''&lt;sub&gt;n&lt;/sub&gt; by 2''π''. Without first finding the radian frequency, the natural frequency can be found directly using:
:&lt;math&gt;f_\mathrm{n} = \frac{1}{2\pi} \sqrt{\frac{k}{m}} \,&lt;/math&gt;

Where:&lt;br/&gt;
''f''&lt;sub&gt;n&lt;/sub&gt; = natural frequency in hertz (cycles/second)&lt;br/&gt;
''k'' = stiffness of the spring (Newtons/meter or N/m)&lt;br/&gt;
''m'' = mass(kg)  &lt;br/&gt;
while doing the [[modal analysis]] of structures and mechanical equipment, the frequency of 1st mode is called fundamental frequency.

==See also==
*[[Greatest common divisor]]
*[[Hertz]]
*[[Missing fundamental]]
*[[Natural frequency]]
*[[Oscillation]]
*[[Harmonic series (music)#Terminology]]
*[[Pitch detection algorithm]]
*[[Scale of harmonics]]

==References==
{{Reflist}}

{{Acoustics}}
{{Strings (music)}}
{{Timbre}}

{{DEFAULTSORT:Fundamental Frequency}}
[[Category:Musical tuning]]
[[Category:Acoustics]]
[[Category:Fourier analysis]]</text>
      <sha1>q5tmuwou3y26ema908rk7e3ckp3q56m</sha1>
    </revision>
  </page>
  <page>
    <title>Georges Glaeser</title>
    <ns>0</ns>
    <id>37595171</id>
    <revision>
      <id>796220802</id>
      <parentid>757193505</parentid>
      <timestamp>2017-08-19T09:57:35Z</timestamp>
      <contributor>
        <username>Mamu123jan</username>
        <id>31742232</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2026">'''Georges Glaeser''' ( 1918–2002 ) was a [[France|French]] [[mathematician]] who was director of  the IREM of [[University of Strasbourg|Strasbourg]].
He worked in [[Mathematical analysis|analysis]] and [[Mathematics education|mathematical education]] and introduced [[Glaeser's composition theorem]] and [[Glaeser's continuity theorem]].

Glaeser was a Ph.D. student of [[Laurent Schwartz]].&lt;ref&gt;{{MathGenealogy|id=118358}}&lt;/ref&gt;

On July 3, 1973, Glaeser filed a complaint against Vichy collaborator Paul Touvier in the Lyon Court, charging him with crimes against humanity. Glaeser accused Touvier of the 1944 massacre at Rillieux-la-Pape, in which Glaeser's father was murdered. Touvier was eventually imprisoned for life on this charge in 1994.

==Selected publications==
*{{Citation | last1=Glaeser | first1=Georges | authorlink = Georges Glaeser | title=Fonctions composées différentiables | jstor = 1970204 | mr = 0143058 | year=1963 | journal=[[Annals of Mathematics]] | series = Second Series | volume=77 | pages=193–209 | doi=10.2307/1970204}}
*"Etude de quelques algebres tayloriennes"
*"Racine carrée d'une fonction différentiable", ''Annales de l'Institut Fourier'' 13, no. 2 (1963), 203–210
*"Une introduction à la didactique expérimentale des mathématiques"

==References==
{{Reflist}}
*{{Citation | last1=Pluvinage | first1=François | title=In Memoriam — Georges Glaeser (1918–2002) | year=2002 | journal=The International Commission on Mathematical Instruction, Bulletin | volume=51 | pages=63–66 |url=http://www.mathunion.org/fileadmin/ICMI/files/Publications/ICMI_bulletin/51.pdf}}
* {{MathGenealogy|id=118358}}

==External links==
*[http://unesdoc.unesco.org/Ulis/cgi-bin/ulis.pl?catno=68221&amp;set=4F331370_2_173&amp;database=g Glaeser, Georges – The Crisis of geometry teaching]

{{Authority control}}

{{DEFAULTSORT:Glaeser, Georges}}
[[Category:1918 births]]
[[Category:2002 deaths]]
[[Category:French mathematicians]]
[[Category:Mathematical analysts]]


{{France-mathematician-stub}}</text>
      <sha1>qlw54cthypylqjqkit4184jpgv9tyfm</sha1>
    </revision>
  </page>
  <page>
    <title>Greedy algorithm for Egyptian fractions</title>
    <ns>0</ns>
    <id>7277012</id>
    <revision>
      <id>861649831</id>
      <parentid>859859879</parentid>
      <timestamp>2018-09-29T00:03:37Z</timestamp>
      <contributor>
        <username>Graeme Bartlett</username>
        <id>38427</id>
      </contributor>
      <minor/>
      <comment>[[WP:AWB/T|Typo fixing]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14725">In [[mathematics]], the '''greedy algorithm for Egyptian fractions''' is a [[greedy algorithm]], first described by [[Fibonacci]], for transforming [[rational number]]s into [[Egyptian fraction]]s. An Egyptian fraction is a representation of an [[irreducible fraction]] as a sum of distinct [[unit fraction]]s, as e.g. 5/6 = 1/2 + 1/3.  As the name indicates, these representations have been used as long ago as [[Egyptian mathematics|ancient Egypt]], but the first published systematic method for constructing such expansions is described in the [[Liber Abaci]] ([[#{{harvid|Sigler|2002}}|1202]]) of [[Leonardo of Pisa]] (Fibonacci).  It is called a greedy algorithm because at each step the algorithm chooses greedily the largest possible [[unit fraction]] that can be used in any representation of the remaining fraction.

Fibonacci actually lists several different methods for constructing Egyptian fraction representations ({{harvnb|Sigler|2002}}, chapter II.7). He includes the greedy method as a last resort for situations when several simpler methods fail; see [[Egyptian fraction]] for a more detailed listing of these methods. As Salzer (1948) details, the greedy method, and extensions of it for the approximation of irrational numbers, have been rediscovered several times by modern mathematicians, earliest and most notably by {{harvs|authorlink=James Joseph Sylvester|last=Sylvester|first=J. J.|year=1880|txt}}; see for instance {{harvtxt|Cahen|1891}} and {{harvtxt|Spiess|1907}}. A closely related expansion method that produces closer approximations at each step by allowing some unit fractions in the sum to be negative dates back to {{harvtxt|Lambert|1770}}.

The expansion produced by this method for a number ''x'' is called the '''greedy Egyptian expansion''', '''Sylvester expansion''', or '''Fibonacci–Sylvester expansion''' of ''x''. However, the term ''Fibonacci expansion'' usually refers, not to this method, but to representation of integers as sums of [[Fibonacci number]]s.

==Algorithm and examples==
Fibonacci's algorithm expands the fraction ''x''/''y'' to be represented, by repeatedly performing the replacement
:&lt;math&gt;\frac{x}{y}=\frac{1}{\lceil y/x\rceil}+\frac{(-y)\bmod x}{y\lceil y/x\rceil}&lt;/math&gt;
(simplifying the second term in this replacement as necessary).  For instance:
:&lt;math&gt;\frac{7}{15}=\frac{1}{3}+\frac{2}{15}=\frac{1}{3}+\frac{1}{8}+\frac{1}{120}.&lt;/math&gt;
in this expansion, the denominator 3 of the first unit fraction is the result of rounding 15/7 up to the next larger integer, and the remaining fraction 2/15 is the result of simplifying (-15 mod 7)/(15&amp;times;3) = 6/45. The denominator of the second unit fraction, 8, is the result of rounding 15/2 up to the next larger integer, and the remaining fraction 1/120 is what is left from 7/15 after subtracting both 1/3 and 1/8.

As each expansion step reduces the numerator of the remaining fraction to be expanded, this method always terminates with a finite expansion; however, compared to ancient Egyptian expansions or to more modern methods, this method may produce expansions that are quite long, with large denominators. For instance, this method expands
:&lt;math&gt;\frac{5}{121}=\frac{1}{25}+\frac{1}{757}+\frac{1}{763309}+\frac{1}{873960180913}+\frac{1}{1527612795642093418846225},&lt;/math&gt;
while other methods lead to the much better expansion
:&lt;math&gt;\frac{5}{121}=\frac{1}{33}+\frac{1}{121}+\frac{1}{363}.&lt;/math&gt;
{{harvtxt|Wagon|1991}} suggests an even more badly-behaved example, 31/311. The greedy method leads to an expansion with ten terms, the last of which has over 500 digits in its denominator; however, 31/311 has a much shorter non-greedy representation, 1/12 + 1/63 + 1/2799 + 1/8708.

==Sylvester's sequence and closest approximation==
[[Sylvester's sequence]] 2, 3, 7, 43, 1807, ... can be viewed as generated by an infinite greedy expansion of this type for the number one, where at each step we choose the denominator &lt;math&gt;\lfloor y/x\rfloor+1&lt;/math&gt; instead of &lt;math&gt;\lceil y/x\rceil&lt;/math&gt;. Truncating this sequence to ''k'' terms and forming the corresponding Egyptian fraction, e.g. (for ''k'' = 4)
:&lt;math&gt;\frac12+\frac13+\frac17+\frac1{43}=\frac{1805}{1806}&lt;/math&gt;
results in the closest possible underestimate of 1 by any ''k''-term Egyptian fraction ({{harvnb|Curtiss|1922}}; {{harvnb|Soundararajan|2005}}). That is, for example, any Egyptian fraction for a number in the open interval (1805/1806,1) requires at least five terms. {{harvtxt|Curtiss|1922}} describes an application of these closest-approximation results in lower-bounding the number of divisors of a [[perfect number]], while {{harvtxt|Stong|1983}} describes applications in [[group theory]].

==Maximum-length expansions and congruence conditions==
Any fraction ''x''/''y'' requires at most ''x'' terms in its greedy expansion. {{harvtxt|Mays|1987}} and {{harvtxt|Freitag|Phillips|1999}} examine the conditions under which the greedy method produces an expansion of ''x''/''y'' with exactly ''x'' terms; these can be described in terms of congruence conditions on ''y''.

* Every fraction 1/''y'' requires one term in its greedy expansion; the simplest such fraction is 1/1.
* Every fraction 2/''y'' requires two terms in its greedy expansion if and only if ''y'' ≡ 1 (mod 2); the simplest such fraction is 2/3.
* A fraction 3/''y'' requires three terms in its greedy expansion if and only if ''y'' ≡ 1 (mod 6), for then -''y'' mod ''x'' = 2 and y(y+2)/3 is odd, so the  fraction remaining after a single step of the greedy expansion,
::&lt;math&gt;\frac{(-y)\bmod x}{y\lceil y/x\rceil} = \frac2{y(y+2)/3}&lt;/math&gt;
:is in simplest terms. The simplest fraction 3/''y'' with a three-term expansion is 3/7.

* A fraction 4/''y'' requires four terms in its greedy expansion if and only if ''y'' ≡ 1 or 17 (mod 24), for then the numerator -''y'' mod ''x'' of the remaining fraction is 3 and the denominator is 1 (mod 6). The simplest fraction 4/''y'' with a four-term expansion is 4/17. The [[Erdős–Straus conjecture]] states that all fractions 4/''y'' have an expansion with three or fewer terms, but when ''y'' ≡ 1 or 17 (mod 24) such expansions must be found by methods other than the greedy algorithm, with the 17 (mod 24) case being covered by the congruence relationship 2 (mod 3).

More generally the sequence of fractions ''x''/''y'' that have ''x''-term greedy expansions and that have the smallest possible denominator ''y'' for each ''x'' is
:&lt;math&gt;1, \frac{2}{3}, \frac{3}{7}, \frac{4}{17}, \frac{5}{31}, \frac{6}{109}, \frac{7}{253}, \frac{8}{97}, \frac{9}{271}, \dots&lt;/math&gt; {{OEIS|id=A048860}}.

==Approximation of polynomial roots==
{{harvtxt|Stratemeyer|1930}} and {{harvtxt|Salzer|1947}} describe a method of finding an accurate [[Root-finding algorithm|approximation for the roots of a polynomial]] based on the greedy method. Their algorithm computes the greedy expansion of a root; at each step in this expansion it maintains an auxiliary polynomial that has as its root the remaining fraction to be expanded. Consider as an example applying this method to find the greedy expansion of the [[golden ratio]], one of the two solutions of the polynomial equation ''P''&lt;sub&gt;0&lt;/sub&gt;(''x'') = ''x''&lt;sup&gt;2&lt;/sup&gt; - x - 1 = 0. The algorithm of Stratemeyer and Salzer performs the following sequence of steps:

#Since ''P''&lt;sub&gt;0&lt;/sub&gt;(''x'') &lt; 0 for ''x'' = 1, and ''P''&lt;sub&gt;0&lt;/sub&gt;(''x'') &gt; 0 for all ''x'' ≥ 2, there must be a root of ''P''&lt;sub&gt;0&lt;/sub&gt;(''x'') between 1 and 2. That is, the first term of the greedy expansion of the golden ratio is 1/1. If ''x''&lt;sub&gt;1&lt;/sub&gt; is the remaining fraction after the first step of the greedy expansion, it satisfies the equation ''P''&lt;sub&gt;0&lt;/sub&gt;(''x''&lt;sub&gt;1&lt;/sub&gt; + 1) = 0, which can be expanded as ''P''&lt;sub&gt;1&lt;/sub&gt;(''x''&lt;sub&gt;1&lt;/sub&gt;) = ''x''&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; + ''x''&lt;sub&gt;1&lt;/sub&gt; - 1 = 0.
#Since ''P''&lt;sub&gt;1&lt;/sub&gt;(''x'') &lt; 0 for ''x'' = 1/2, and ''P''&lt;sub&gt;1&lt;/sub&gt;(''x'') &gt; 0 for all ''x'' &gt; 1, the root of ''P''&lt;sub&gt;1&lt;/sub&gt; lies between 1/2 and 1, and the first term in its greedy expansion (the second term in the greedy expansion for the golden ratio) is 1/2. If ''x''&lt;sub&gt;2&lt;/sub&gt; is the remaining fraction after this step of the greedy expansion, it satisfies the equation ''P''&lt;sub&gt;1&lt;/sub&gt;(''x''&lt;sub&gt;2&lt;/sub&gt; + 1/2) = 0, which can be expanded as ''P''&lt;sub&gt;2&lt;/sub&gt;(''x''&lt;sub&gt;2&lt;/sub&gt;) = 4''x''&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; + 8''x''&lt;sub&gt;2&lt;/sub&gt; - 1 = 0.
#Since ''P''&lt;sub&gt;2&lt;/sub&gt;(''x'') &lt; 0 for ''x'' = 1/9, and ''P''&lt;sub&gt;2&lt;/sub&gt;(''x'') &gt; 0 for all ''x'' &gt; 1/8, the next term in the greedy expansion is 1/9. If ''x''&lt;sub&gt;3&lt;/sub&gt; is the remaining fraction after this step of the greedy expansion, it satisfies the equation ''P''&lt;sub&gt;2&lt;/sub&gt;(''x''&lt;sub&gt;3&lt;/sub&gt; + 1/9) = 0, which can again be expanded as a polynomial equation with integer coefficients, ''P''&lt;sub&gt;3&lt;/sub&gt;(''x''&lt;sub&gt;3&lt;/sub&gt;) = 324''x''&lt;sub&gt;3&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; + 720''x''&lt;sub&gt;3&lt;/sub&gt; - 5 = 0.

Continuing this approximation process eventually produces the greedy expansion for the golden ratio,

:&lt;math&gt;\varphi = \frac11+\frac12+\frac19+\frac1{145}+\frac1{37986}+\cdots&lt;/math&gt; {{OEIS|id=A117116}}.

==Other integer sequences==
The length, minimum denominator, and maximum denominator of the greedy expansion for all fractions with small numerators and denominators can be found in the [[On-Line Encyclopedia of Integer Sequences]] as sequences {{OEIS2C|A050205}}, {{OEIS2C|A050206}}, and {{OEIS2C|A050210}}, respectively. In addition, the greedy expansion of any [[irrational number]] leads to an infinite increasing sequence of integers, and the OEIS contains [http://oeis.org/search?q=greedy-Egyptian-fraction-expansion expansions of several well known constants]. Some [http://oeis.org/search?q=Egyptian-fraction-for additional entries in the OEIS], though not labeled as being produced by the greedy algorithm, appear to be of the same type.

==Related expansions==
In general, if one wants an Egyptian fraction expansion in which the denominators are constrained in some way, it is possible to define a greedy algorithm in which at each step one chooses the expansion
:&lt;math&gt;\frac{x}{y}=\frac{1}{d}+\frac{xd-y}{yd},&lt;/math&gt;
where ''d'' is chosen, among all possible values satisfying the constraints, as small as possible such that ''xd'' &gt; ''y'' and such that ''d'' is distinct from all previously chosen denominators. For instance, the [[Engel expansion]] can be viewed as an algorithm of this type in which each successive denominator must be a multiple of the previous one. However, it may be difficult to determine whether an algorithm of this type can always succeed in finding a finite expansion. In particular, the [[odd greedy expansion]] of a fraction ''x''/''y'' is formed by a greedy algorithm of this type in which all denominators are constrained to be odd numbers; it is known that, whenever ''y'' is odd, there is a finite Egyptian fraction expansion in which all denominators are odd, but it is not known whether the odd greedy expansion is always finite.

== References ==
{{refbegin|colwidth=30em}}
*{{citation
 | last = Cahen | first = E.
 | journal = Nouvelles Annales des Mathématiques | series = Ser. 3
 | pages = 508–514
 | title = Note sur un développement des quantités numériques, qui presente quelque analogie avec celui en fractions continues
 | volume = 10
 | year = 1891}}.
*{{citation
 | last = Curtiss | first = D. R. | authorlink = David Raymond Curtiss
 | doi = 10.2307/2299023
 | issue = 10
 | journal = [[American Mathematical Monthly]]
 | jstor = 2299023
 | pages = 380–387
 | title = On Kellogg's diophantine problem
 | volume = 29
 | year = 1922}}.
*{{citation
 | last1 = Freitag | first1 = H. T. | author1-link = Herta Freitag
 | last2 = Phillips | first2 = G. M.
 | contribution = Sylvester's algorithm and Fibonacci numbers
 | location = Dordrecht
 | mr = 1737669
 | pages = 155–163
 | publisher = Kluwer Acad. Publ.
 | title = Applications of Fibonacci numbers, Vol. 8 (Rochester, NY, 1998)
 | year = 1999}}.
*{{citation
 | last = Lambert | first = J. H. | author-link = Johann Heinrich Lambert
 | location = Berlin
 | pages = 99–104
 | publisher = Zweyter Theil
 | title = Beyträge zum Gebrauche der Mathematik und deren Anwendung
 | year = 1770}}.
*{{citation
 | last = Mays | first = Michael
 | journal = Journal of Combinatorial Mathematics and Combinatorial Computing
 | mr = 0888838
 | pages = 141–148
 | title = A worst case of the Fibonacci–Sylvester expansion
 | volume = 1
 | year = 1987}}.
*{{citation
 | last = Salzer | first = H. E.
 | doi = 10.2307/2305906
 | issue = 3
 | journal = [[American Mathematical Monthly]]
 | jstor = 2305906
 | mr = 0020339
 | pages = 135–142
 | title = The approximation of numbers as sums of reciprocals
 | volume = 54
 | year = 1947}}.
*{{citation
 | last = Salzer | first = H. E.
 | doi = 10.2307/2304960
 | issue = 6
 | journal = [[American Mathematical Monthly]]
 | jstor = 2304960
 | mr = 0025512
 | pages = 350–356
 | title = Further remarks on the approximation of numbers as sums of reciprocals
 | volume = 55
 | year = 1948}}.
*{{citation
 | last = Sigler | first = Laurence E. (trans.)
 | isbn = 0-387-95419-8
 | publisher = Springer-Verlag
 | title = Fibonacci's Liber Abaci
 | year = 2002}}.
*{{citation
 | last = Soundararajan | first = K.
 | arxiv = math.CA/0502247
 | title = Approximating 1 from below using ''n'' Egyptian fractions
 | year = 2005}}.
*{{citation
 | last = Spiess | first = O.
 | journal = Archiv der Mathematik und Physik |series=Third Series
 | pages = 124–134
 | title = Über eine Klasse unendlicher Reihen
 | volume = 12
 | year = 1907}}.
*{{citation
 | last = Stong | first = R. E. | authorlink = Robert Evert Stong
 | doi = 10.1007/BF01455950
 | issue = 4
 | journal = Mathematische Annalen
 | mr = 0721884
 | pages = 501–512
 | title = Pseudofree actions and the greedy algorithm
 | volume = 265
 | year = 1983}}.
*{{citation
 | last = Stratemeyer | first = G.
 | doi = 10.1007/BF01246446
 | journal = Mathematische Zeitschrift
 | pages = 767–768
 | title = Stammbruchentwickelungen für die Quadratwurzel aus einer rationalen Zahl
 | volume = 31
 | year = 1930}}.
*{{citation
 | last = Sylvester | first = J. J. | author-link = J. J. Sylvester
 | doi = 10.2307/2369261
 | issue = 4
 | journal = [[American Journal of Mathematics]]
 | jstor = 2369261
 | pages = 332–335
 | title = On a point in the theory of vulgar fractions
 | volume = 3
 | year = 1880}}.
*{{citation
 | last = Wagon | first = S. | authorlink = Stan Wagon
 | pages = 271–277
 | publisher = W. H. Freeman
 | title = Mathematica in Action
 | year = 1991}}.
{{refend}}

{{Fibonacci}}

[[Category:Number theory]]
[[Category:Integer sequences]]
[[Category:Egyptian fractions]]</text>
      <sha1>0h6zq5vcd7ztkulgwtvmu0gqktxbr8p</sha1>
    </revision>
  </page>
  <page>
    <title>Group testing</title>
    <ns>0</ns>
    <id>24958527</id>
    <revision>
      <id>866457910</id>
      <parentid>858587583</parentid>
      <timestamp>2018-10-30T13:18:49Z</timestamp>
      <contributor>
        <username>Gehenna1510</username>
        <id>34982813</id>
      </contributor>
      <comment>CS1 error fixed [[WP:UCB|Assisted by Citation bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="58818">{{good article}}
[[File:Group testing lightbulbs.svg|thumb|400px|An illustration of the lightbulb problem, where one is searching for a broken bulb among six lightbulbs. Here, the first three are connected to a power supply, and they light up (A). This indicates that the broken bulb must be one of the last three (B). If instead the bulbs did not light up, one could be sure that the broken bulb was among the first three.]]

In [[statistics]] and [[combinatorics|combinatorial mathematics]], '''group testing''' is any procedure that breaks up the task of identifying certain objects into tests on groups of items, rather than on individual ones. First studied by [[Robert Dorfman]] in 1943, group testing is a relatively new field of applied mathematics that is an active area of research today and is useful for a wide range of practical applications.

A familiar example of group testing involves a string of light bulbs connected in series, where exactly one of the bulbs is known to be broken. The objective is to find the broken bulb using the smallest number of tests (a test is when some of the bulbs are connected to a power supply). A simple approach is to test each bulb individually. However, when there are a large number of bulbs it would be much more efficient to pool the bulbs into groups. For example, in connecting the first half of the bulbs at once, it can be determined which half the broken bulb is in, ruling out half of the bulbs in just one test. When searching among six bulbs connected in series, this allows completion of the test in at worst three, and at best two steps, compared to a worst-case of six and best-case of one tests, when testing each bulb individually.

Schemes for carrying out such group testing can be simple or complex and the tests involved at each stage may be different. Schemes in which the tests for the next stage depend on the results of the previous stages are called ''adaptive procedures'', while schemes designed so that all the tests are known beforehand are called ''non-adaptive procedures''. The structure of the scheme of the tests involved in a non-adaptive procedure is known as a ''pooling design''.

Group testing has many applications, including statistics, biology, computer science, medicine, engineering and cyber security. Modern interest in these testing schemes has been rekindled by the [[Human Genome Project]].&lt;ref&gt;{{citation
|last1=Colbourn|first1=Charles J.
|last2=Dinitz|first2=Jeffrey H.
|title=Handbook of Combinatorial Designs
|year=2007
|publisher=Chapman &amp; Hall/ CRC
|location=Boca Raton
|isbn=978-1-58488-506-1
|edition=2nd
|at= p. 574, Section 46: Pooling Designs}}&lt;/ref&gt;
&lt;!--Old example (might be good to restore somehow): A familiar example of this type of technique is the [[Balance puzzle|false coin problem]] of [[recreational mathematics]]. In this problem there are ''n'' coins and one of them is false, weighing less than a real coin. The objective is to find the false coin, using a [[balance scale]], in the fewest number of weighings. By repeatedly dividing the coins in half and comparing the two halves, the false coin can be found quickly as it is always in the lighter half.{{efn|A bit more precisely – if there are an odd number of coins to be weighed, pick one to put aside and divide the rest into two equal piles. If the two piles have equal weight, the bad coin is the one put aside, otherwise the one put aside was good and no longer has to be tested.}}
[[File:False Coin Problem.gif|thumb|400px|An animation of the false coin problem being solved for 10 coins, where the goal is to find the single coin that is lighter than the others. Many fewer than 10 tests are needed since at each stage, at least half of the 'good' coins are eliminated.]]--&gt;

== Basic description and terms ==
Unlike many areas of mathematics, the origins of group testing can be traced back to a single report&lt;ref name = "Dorfman" /&gt; written by a single person: [[Robert Dorfman]].&lt;ref name = "book" /&gt; The motivation arose during the Second World War when the [[United States Public Health Service]] and the [[Selective Service System|Selective service]] embarked upon a large-scale project to weed out all [[Syphilis|syphilitic]] men called up for induction. Testing an individual for syphilis involves drawing a blood sample from them and then analysing the sample to determine the presence or absence of syphilis. At the time, performing this test was expensive, and testing every soldier individually would have been very expensive and inefficient.&lt;ref name="book" /&gt;

Supposing there are &lt;math&gt;n&lt;/math&gt; soldiers, this method of testing leads to &lt;math&gt;n&lt;/math&gt; separate tests. If a large proportion of the people are infected then this method would be reasonable. However, in the more likely case that only a very small proportion of the men are infected, a much more efficient testing scheme can be achieved. The feasibility of a more effective testing scheme hinges on the following property: the soldiers can be pooled into groups, and in each group the blood samples can be combined together. The combined sample can then be tested to check if at least one soldier in the group has syphilis. This is the central idea behind group testing. If one or more of the soldiers in this group has syphilis, then a test is wasted (more tests need to be performed to find which soldier(s) it was). On the other hand, if no one in the pool has syphilis then many tests are saved, since every soldier in that group can be eliminated with just one test.&lt;ref name="book" /&gt;

The items that cause a group to test positive are generally called ''defective items'' (these are the broken lightbulbs, syphilitic men, etc.). Often, the total number of items is denoted as &lt;math&gt;n&lt;/math&gt; and &lt;math&gt;d&lt;/math&gt; represents the number of defectives if it is assumed to be known.&lt;ref name="book" /&gt;

=== Classification of group-testing problems ===
There are two independent classifications for group-testing problems; every group-testing problem is either adaptive or non-adaptive, and either probabilistic or combinatorial.&lt;ref name="book" /&gt;

In probabilistic models, the defective items are assumed to follow some [[probability distribution]] and the aim is to minimise the [[Expected_value|expected]] number of tests needed to identify the defectiveness of every item. On the other hand, with combinatorial group testing, the goal is to minimise the number of tests needed in a 'worst-case scenario' – that is, create a [[minmax algorithm]] – and no knowledge of the distribution of defectives is assumed.&lt;ref name="book" /&gt;

The other classification, adaptivity, concerns what information can be used when choosing which items to group into a test. In general, the choice of which items to test can depend on the results of previous tests, as in the above lightbulb problem. An [[algorithm]] that proceeds by performing a test, and then using the result (and all past results) to decide which next test to perform, is called adaptive. Conversely, in non-adaptive algorithms, all tests are decided in advance. This idea can be generalised to multistage algorithms, where tests are divided into stages, and every test in the next stage must be decided in advance, with only the knowledge of the results of tests in previous stages.
Although adaptive algorithms offer much more freedom in design, it is known that adaptive group-testing algorithms do not improve upon non-adaptive ones by more than a constant factor in the number of tests required to identify the set of defective items.&lt;ref name = "compressedSensing"&gt;{{Cite journal
|last1=Atia|first1=George Kamal
|last2=Saligrama|first2=Venkatesh
|date = March 2012
|title = Boolean compressed sensing and noisy group testing
|journal = IEEE Transactions on Information Theory
|volume = 58|issue = 3
|pages = 1880–1901
|arxiv = 0907.1061
|doi = 10.1109/TIT.2011.2178156}}
&lt;/ref&gt;&lt;ref name = "book"&gt;{{cite book
|last1=Ding-Zhu|first1= Du
|last2=Hwang|first2=Frank K.
|title=Combinatorial group testing and its applications
|date=1993
|publisher=World Scientific
|location=Singapore
|isbn=978-9810212933}}&lt;/ref&gt; In addition to this, non-adaptive methods are often useful in practice because one can proceed with successive tests without first analysing the results of all previous tests, allowing for the effective distribution of the testing process.

=== Variations and extensions ===
There are many ways to extend the problem of group testing. One of the most important is called ''noisy'' group testing, and deals with a big assumption of the original problem: that testing is error-free. A group-testing problem is called noisy when there is some chance that the result of a group test is erroneous (e.g. comes out positive when the test contained no defectives). The ''Bernoulli noise model'' assumes this probability is some constant, &lt;math&gt;q&lt;/math&gt;, but in general it can depend on the true number of defectives in the test and the number of items tested.&lt;ref name = "comp"/&gt; For example, the effect of dilution can be modelled by saying a positive result is more likely when there are more defectives (or more defectives as a fraction of the number tested), present in the test.&lt;ref&gt;{{cite journal |last1=Hung |first1=M. |last2=Swallow |first2=William H. |title=Robustness of Group Testing in the Estimation of Proportions |journal=Biometrics |date=March 1999 |volume=55 |issue=1 |pages=231–237 |doi=10.1111/j.0006-341X.1999.00231.x}}&lt;/ref&gt; A noisy algorithm will always have a non-zero probability of making an error (that is, mislabeling an item).

Group testing can be extended by considering scenarios in which there are more than two possible outcomes of a test. For example, a test may have the outcomes &lt;math&gt;0, 1&lt;/math&gt; and &lt;math&gt;2^+&lt;/math&gt;, corresponding to there being no defectives, a single defective, or an unknown number of defectives larger than one. More generally, it is possible to consider the outcome-set of a test to be &lt;math&gt;{0, 1, \ldots , k^+}&lt;/math&gt; for some &lt;math&gt;k \in \mathbb{N}&lt;/math&gt;.&lt;ref name="book" /&gt;

Another extension is to consider geometric restrictions on which sets can be tested. The above lightbulb problem is an example of this kind of restriction: only bulbs that appear consecutively can be tested. Similarly, the items my be arranged in a circle, or in general, a net, where the tests are available paths on the graph. Another kind of geometric restriction would be on the maximum number of items that can be tested in a group,{{efn|The original problem that Dorfman studied was of this nature (although he did not account for this), since in practice, only a certain number of blood sera could be pooled before the testing procedure became unreliable. This was the main reason that Dorfman’s procedure was not applied at the time.&lt;ref name = "book" /&gt;}} or the group sizes might have to be even and so on. In a similar way, it may be useful to consider the restriction that any given item can only appear in a certain number of tests.&lt;ref name="book" /&gt;

There are endless ways to continue remixing the basic formula of group testing. The following elaborations will give an idea of some of the more exotic variants. In the 'good–mediocre–bad' model, each item is one of 'good', 'mediocre' or 'bad', and the result of a test is the type of the 'worst' item in the group. In threshold group testing, the result of a test is positive if the number of defective items in the group is greater than some threshold value or proportion.&lt;ref&gt;{{cite journal
|last1 = Chen|first1 = Hong-Bin
|last2 = Fu|first2 = Hung-Lin
|date = April 2009
|title  = Nonadaptive algorithms for threshold group testing
|journal = Discrete Applied Mathematics
|volume = 157|issue = 7
|pages = 1581–1585
|doi = 10.1016/j.dam.2008.06.003
}}
&lt;/ref&gt; Group testing with inhibitors is a variant with applications in molecular biology. Here, there is a third class of items called inhibitors, and the result of a test is positive if it contains at least one defective and no inhibitors.&lt;ref&gt;{{cite journal
|last1 = De Bonis|first1= Annalisa
|date = 20 July 2007
|title = New combinatorial structures with applications to efficient group testing with inhibitors
|journal = Journal of Combinatorial Optimization
|volume=15|issue=1
|pages = 77–94
|doi = 10.1007/s10878-007-9085-1}}&lt;/ref&gt;

== History and development ==

=== Invention and initial progress ===
The concept of group testing was first introduced by Robert Dorfman in 1943 in a short report&lt;ref name = "Dorfman"&gt;{{citation
|last1=Dorfman|first1=Robert
|title=The Detection of Defective Members of Large Populations
|journal=The Annals of Mathematical Statistics
|date=December 1943
|volume=14|issue=4
|pages=436–440
|jstor=2235930
|doi=10.1214/aoms/1177731363}}&lt;/ref&gt; published in the Notes section of ''[[Annals of Mathematical Statistics]]''.&lt;ref name = "book" /&gt;{{efn|However, as is often the case in mathematics, group testing has been subsequently re-invented multiple times since then, often in the context of applications. For example, Hayes independently came up with the idea to query groups of users in the context of multiaccess communication protocols in 1978.&lt;ref name = "Hayes"&gt;{{cite journal
|last1 = Hayes|first1=J.
|date = August 1978
|title = An adaptive technique for local distribution
|journal = IEEE Transactions on Communications
|volume = 26|issue = 8
|pages = 1178–1186
|doi = 10.1109/TCOM.1978.1094204
}}&lt;/ref&gt;}} Dorfman's report – as with all the early work on group testing – focused on the probabilistic problem, and aimed to use the novel idea of group testing to reduce the expected number of tests needed to weed out all syphilitic men in a given pool of soldiers. The method was simple: put the soldiers into groups of a given size, and use individual testing (testing items in groups of size one) on the positive groups to find which were infected. Dorfman tabulated the optimum group sizes for this strategy against the prevalence rate of defectiveness in the population.&lt;ref name = "Dorfman"/&gt;

After 1943, group testing remained largely untouched for a number of years. Then in 1957, Sterrett produced an improvement on Dorfman’s procedure.&lt;ref name = "Sterrett"&gt;{{cite journal
|last1 = Sterrett|first1 = Andrew
|date = December 1957
|title = On the detection of defective members of large populations
|journal = The Annals of Mathematical Statistics
|volume = 28|issue = 4
|pages = 1033–1036
|doi = 10.1214/aoms/1177706807}}&lt;/ref&gt; This newer process starts by again performing individual testing on the positive groups, but stopping as soon as a defective is identified. Then, the remaining items in the group are tested together, since it is very likely that none of them are defective.

The first thorough treatment of group testing was given by Sobel and Groll in their formative 1959 paper on the subject.&lt;ref name = "groll"&gt;{{cite journal
|last1 = Sobel|first1 = Milton;
|last2 = Groll|first2 = Phyllis A.
|date = September 1959
|title = Group testing to eliminate efficiently all defectives in a binomial sample
|journal = Bell System Technical Journal
|volume = 38|issue = 5
|pages = 1179–1252
|doi = 10.1002/j.1538-7305.1959.tb03914.x}}&lt;/ref&gt; They described five new procedures – in addition to generalisations for when the prevalence rate is unknown – and for the most optimal one, they provided an explicit formula for the expected number of tests it would use. The paper also made the connection between group testing and [[information theory]] for the first time, as well as discussing several generalisations of the group-testing problem and providing some new applications of the theory.

=== Combinatorial group testing ===
Group testing was first studied in the combinatorial context by Li in 1962,&lt;ref name = "li"&gt;{{cite journal
|last1=Li|first1=Chou Hsiung
|date = June 1962
|title = A sequential method for screening experimental variables
|journal= Journal of the American Statistical Association
|volume = 57|issue = 298
|pages = 455–477
|doi = 10.1080/01621459.1962.10480672}}&lt;/ref&gt; with the introduction of ''Li’s &lt;math&gt;s&lt;/math&gt;-stage algorithm''.&lt;ref name = "book" /&gt; Li proposed an extension of
Dorfman's '2-stage algorithm' to an arbitrary number of stages that required no more
than &lt;math&gt;t = \frac{e}{\log_2(e)}d \log_2(n)&lt;/math&gt; tests to be guaranteed to find &lt;math&gt;d&lt;/math&gt; or fewer defectives among &lt;math&gt;n&lt;/math&gt; items.
The idea was to remove all the items in negative tests, and divide the remaining items into groups as was done with the initial pool. This was to be done &lt;math&gt;s - 1&lt;/math&gt; times before performing individual testing.

Combinatorial group testing in general was later studied more fully by Katona in 1973.&lt;ref name = "Katona"&gt;{{cite journal
|last1=Katona|first1=Gyula O.H.
|year = 1973
|journal = Combinatorial Search Problems
|title = A survey of combinatorial theory
|pages = 285–308
|place = North-Holland, Amsterdam}}&lt;/ref&gt; Katona introduced the [[#Representation of non-adaptive algorithms|matrix representation]] of non-adaptive group-testing and produced a procedure for finding the defective in the non-adaptive 1-defective case in no more than &lt;math&gt;t =\lceil \log_2(n) \rceil&lt;/math&gt;tests, which he also proved to be optimal.

In general, finding optimal algorithms for adaptive combinatorial group testing is difficult, and although the [[Computational complexity theory|computational complexity]] of group testing has not been determined, it is suspected to be [[Complete (complexity)|hard]] in some complexity class.&lt;ref name = "book" /&gt; However, an important breakthrough occurred in 1972, with the introduction of the [[#Generalised binary-splitting algorithm|generalised binary-splitting algorithm]].&lt;ref name = "Hwang" /&gt; The generalised binary-splitting algorithm works by performing a [[binary search]] on groups that test positive, and is a simple algorithm that finds a single defective in no more than the [[#Information lower bound|information-lower-bound]] number of tests.

In scenarios where there are two or more defectives, the generalised binary-splitting algorithm still produces near-optimal results, requiring at most &lt;math&gt;d - 1&lt;/math&gt; tests above the information lower bound where &lt;math&gt;d&lt;/math&gt; is the number of defectives.&lt;ref name = "Hwang" /&gt; Considerable improvements to this were made in 2013 by Allemann, getting the required number of tests to less than &lt;math&gt;0.187d + 0.5\log_2(d) + 5.5&lt;/math&gt; above the information lower bound when &lt;math&gt;n/d \geq 38&lt;/math&gt; and &lt;math&gt;d \geq 10&lt;/math&gt;.&lt;ref name = "Allemann"&gt;{{cite journal
|last1 = Allemann|first1 = Andreas
|date = 2013
|title = An efficient algorithm for combinatorial group testing
|journal = Information Theory, Combinatorics, and Search Theory
|pages = 569–596
}}&lt;/ref&gt; This was achieved by changing the binary search in the binary-splitting algorithm to a complex set of sub-algorithms with overlapping test groups. As such, the problem of adaptive combinatorial group testing – with a known number or upper bound on the number of defectives – has essentially been solved, with little room for further improvement.

There is an open question as to when individual testing is [[minmax]]. Hu, Hwang and Wang showed in 1981 that individual testing is minmax when &lt;math&gt;n \leq  \lfloor (5d + 1)/2 \rfloor&lt;/math&gt;, and that it is not minmax when &lt;math&gt;n &gt; 3d&lt;/math&gt;.&lt;ref name = "huhwangwang"&gt;{{cite journal
|last1= Hu|first1 = M. C.
|last2 = Hwang|first2 = F. K.
|last3 = Wang|first3 = Ju Kwei
|date = June 1981
|title = A Boundary Problem for Group Testing
|journal = SIAM Journal on Algebraic Discrete Methods
|volume = 2|issue = 2
|pages = 81–87
|doi = 10.1137/0602011}}&lt;/ref&gt; It is currently conjectured that this bound is sharp: that is, individual testing is minmax if and only if &lt;math&gt;n \leq 3d&lt;/math&gt;.&lt;ref&gt;{{cite journal
|last1 = Leu|first1 = Ming-Guang
|date = 28 October 2008
|title = A note on the Hu–Hwang–Wang conjecture for group testing.
|journal = The ANZIAM Journal
|volume = 49|issue = 4
|page = 561
|doi = 10.1017/S1446181108000175}}&lt;/ref&gt;{{efn|This is sometimes referred to as the Hu-Hwang-Wang conjecture.}} Some progress was made in 2000 by Ricccio and Colbourn, who showed that for large &lt;math&gt;n&lt;/math&gt;, individual testing is minmax when &lt;math&gt;d \geq n/\log_{3/2}(3) \approx 0.369n&lt;/math&gt;.&lt;ref name = "Riccio"&gt;{{cite journal
|last1 = Riccio|first1 = Laura
|last2 = Colbourn|first2 = Charles J.
|date = 1 January 2000
|title = Sharper bounds in adaptive group testing
|journal = Taiwanese Journal of Mathematics
|volume = 4|issue = 4
|pages = 669–673}}&lt;/ref&gt;

=== Non-adaptive testing ===
Turning now to non-adaptive group testing, significant gains can be made by not requiring that the group-testing procedure be certain to succeed, but rather to have some non-zero probability of mis-labelling an item. In particular, it is known that zero-error algorithms require significantly more tests (as the number of defective items approaches the total number of items) than algorithms that allow [[Asymptotically optimal algorithm|asymptotically small probabilities]] of error.&lt;ref name = "compressedSensing" /&gt;{{efn|The number of tests, &lt;math&gt;t&lt;/math&gt;, must scale as &lt;math&gt;t = O \left(\frac{d^2 \log_2 n}{\log_2 d} \right)&lt;/math&gt; for deterministic designs, compared to &lt;math&gt;t = O(d\log_2 n)&lt;/math&gt; for designs that allow arbitrarily small probabilities of error (as &lt;math&gt;d \to \infty&lt;/math&gt; and &lt;math&gt;n \to \infty&lt;/math&gt;).&lt;ref name = "compressedSensing" /&gt;}}

In this vein, Chan ''et al.'' introduced [[#Combinatorial Orthogonal Matching Pursuit (COMP)|COMP]] in 2011, a fast, explicit algorithm that requires no more than &lt;math&gt;t = ed(1+\delta)\ln(n)&lt;/math&gt; tests to find up to &lt;math&gt;d&lt;/math&gt; defectives in &lt;math&gt;n&lt;/math&gt; items with a probability of error no more than &lt;math&gt;n^{-\delta}&lt;/math&gt;.&lt;ref name = "comp" /&gt; This is within a constant factor of the &lt;math&gt;t = O(d\log_2 n)&lt;/math&gt; lower bound.&lt;ref name = "compressedSensing" /&gt; They also provided a generalisation of this algorithm to a simple noisy model, and similarly produced an explicit performance bound, which was again only a constant (dependent on the likelihood of a failed test) above the corresponding lower bound.&lt;ref name = "compressedSensing" /&gt;&lt;ref name = "comp" /&gt; In general, the number of tests required in the Bernoulli noise case is a constant factor larger than in the noiseless case.&lt;ref name = "comp" /&gt;

An extension of the COMP algorithm that added additional post-processing steps was produced Aldridge, Baldassini and Johnson in 2014.&lt;ref name = "dd" /&gt; They showed that performance guarantees of this new algorithm, called [[#Definite Defectives (DD)|DD]], strictly exceed those of COMP, and that DD is 'essentially optimal' in scenarios where &lt;math&gt;d^2 \geq n&lt;/math&gt;, by comparing it to a hypothetical algorithm that defines a reasonable optimum. The performance of this hypothetical algorithm suggests that there is possible room for improvement when &lt;math&gt;d^2 &lt; n&lt;/math&gt;, as well as suggesting how much improvement this might be.&lt;ref name = "dd" /&gt;

== Formalisation of combinatorial group testing ==
This section formally defines the notions and terms relating to group testing.

*The ''input vector'', &lt;math&gt;\mathbf{x} = (x_1, x_2, \dots, x_n)&lt;/math&gt;, is defined to be a binary vector of length &lt;math&gt;n&lt;/math&gt; (that is, &lt;math&gt;\mathbf{x} \in \{0,1\}^n&lt;/math&gt;), with the ''j''-th item being called ''defective'' if and only if &lt;math&gt;x_j= 1&lt;/math&gt;. Further, any non-defective item is referred called a 'good' item.

&lt;math&gt;\mathbf{x}&lt;/math&gt; is intended to describe the (unknown) set of defective items. The key property of &lt;math&gt;\mathbf{x}&lt;/math&gt; is that it is an ''implicit input''. That is to say, there is no direct knowledge of what the entries of &lt;math&gt;\mathbf{x}&lt;/math&gt; are, other than that which can be inferred via some series of 'tests'. This leads on to the next definition.

*Let &lt;math&gt;\mathbf{x}&lt;/math&gt; be an input vector. A set, &lt;math&gt;S \subseteq \{ 1, 2, \dots, n \}&lt;/math&gt; is called a ''test''. When testing is ''noiseless'', the result of a test is ''positive'' when there exists &lt;math&gt;j \in S&lt;/math&gt; such that &lt;math&gt;x_j = 1&lt;/math&gt;, and the result is ''negative'' otherwise.

Therefore the goal of group testing is to come up with a method for choosing a 'short' series of tests that allow &lt;math&gt;\mathbf{x}&lt;/math&gt; to be determined, either exactly or with a high degree of certainty.

*A group-testing algorithm is said to make an ''error'' if it incorrectly labels an item (that is, labels any defective item as non-defective or vice versa). This is ''not'' the same thing as the result of a group test being incorrect. An algorithm is called ''zero-error'' if the probability that it makes an error is zero.{{efn|One must be careful to distinguish between when a test reports a false result and when the group-testing procedure fails as a whole. It is both possible to make an error with no incorrect tests and to not make an error with some incorrect tests. Most modern combinatorial algorithms have some non-zero probability of error (even with no erroneous tests), since this significantly decreases the number of tests needed.}}
*&lt;math&gt;t(d, n)&lt;/math&gt; denotes the minimum number of tests required to always find &lt;math&gt;d&lt;/math&gt; defectives among &lt;math&gt;n&lt;/math&gt; items with zero probability of error by any group-testing algorithm. For the same quantity but with the restriction that the algorithm is non-adaptive, the notation &lt;math&gt;\bar{t}(d, n)&lt;/math&gt; is used. &lt;!--The ''Hamming Weight'' of &lt;math&gt;\mathbf{x}&lt;/math&gt; is defined as the number of &lt;math&gt;1&lt;/math&gt;'s in &lt;math&gt;\mathbf{x}&lt;/math&gt;. Hence, &lt;math&gt;|\mathbf{x}| \leq d&lt;/math&gt; where &lt;math&gt;|\mathbf{x}|&lt;/math&gt; is the [[Hamming weight]]. The vector &lt;math&gt;\mathbf{x}&lt;/math&gt; is an implicit input since we do not know the positions of the &lt;math&gt;1&lt;/math&gt;'s. The only way to find out is to run the tests.--&gt;

=== General bounds ===
Since it is always possible to resort to individual testing by setting &lt;math&gt;S_j = \{j\}&lt;/math&gt; for each &lt;math&gt;1 \leq j \leq n&lt;/math&gt;, it must be that that &lt;math&gt;\bar{t}(d, n) \leq n&lt;/math&gt;. Also, since any non-adaptive testing procedure can be written as an adaptive algorithm by simply performing all the tests without regard to their outcome, &lt;math&gt;t(d, n) \leq \bar{t}(d, n)&lt;/math&gt;. Finally, when &lt;math&gt;0 \neq d \neq n&lt;/math&gt;, there is at least one item whose defectiveness must be determined (by at least one test), and so &lt;math&gt;1 \leq t(d, n)&lt;/math&gt;.

In summary (when assuming &lt;math&gt;0 \neq d \neq n&lt;/math&gt;), &lt;math&gt;1 \leq t(d,n) \leq \bar{t}(d, n) \leq n &lt;/math&gt;.{{efn|In fact it is possible to do much better. For example, Li's &lt;math&gt;s&lt;/math&gt;-stage algorithm gives an explicit construction were &lt;math&gt;t \leq \frac{e}{\log_2 e} d \log_2{(n/d)}&lt;/math&gt;.}}

==== Information lower bound ====
A lower bound on the number of tests needed can be described using the notion of ''sample space'', denoted &lt;math&gt;\mathcal{S}&lt;/math&gt;, which is simply the set of possible placements of defectives. For any group testing problem with sample space &lt;math&gt;\mathcal{S}&lt;/math&gt; and any group-testing algorithm, it can be shown that &lt;math&gt;t \geq \lceil \log_2{|\mathcal{S}|} \rceil&lt;/math&gt;, where &lt;math&gt;t&lt;/math&gt; is the minimum number of tests required to identify all defectives with a zero probability of error. This is called the ''information lower bound''.&lt;ref name = "book"/&gt; This bound is derived from the fact that after each test, &lt;math&gt;\mathcal{S}&lt;/math&gt; is split into two disjoint subsets, each corresponding to one of the two possible outcomes of the test.

However, the information lower bound itself is usually unachievable, even for small problems.&lt;ref name = "book" /&gt; This is because the splitting of &lt;math&gt;\mathcal{S}&lt;/math&gt; is not arbitrary, since it must be realisable by some test.

In fact, the information lower bound can be generalised to the case where there is a non-zero probability that the algorithm makes an error. In this form, the theorem gives us an upper bound on the probability of success based on the number of tests. For any group-testing algorithm that performs &lt;math&gt;t&lt;/math&gt; tests, the probability of success, &lt;math&gt;\mathbb{P}(\textrm{success})&lt;/math&gt;, satisfies &lt;math&gt;\mathbb{P}(\textrm{success}) \leq t/\log_2{n \choose d}&lt;/math&gt;. This can be strengthened to: &lt;math&gt;\mathbb{P}(\textrm{success}) \leq \frac{2^t}{{n \choose d}}&lt;/math&gt;.&lt;ref name = "comp" /&gt;&lt;ref name = "Baldassini"&gt;{{citation
|last1 = Baldassini|first1 = L.
|title = 2013 IEEE International Symposium on Information Theory
|last2 = Johnson|first2 = O.
|last3 = Aldridge|first3 = M.
|date = 1 July 2013
|work = IEEE International Symposium on Information Theory
|pages = 2676–2680
|doi = 10.1109/ISIT.2013.6620712|arxiv = 1301.7023|isbn = 978-1-4799-0446-4
|citeseerx = 10.1.1.768.8924
}}&lt;/ref&gt;

=== Representation of non-adaptive algorithms ===
[[File:Nonadaptive Group Testing.svg|400px|thumb|A typical group testing setup. A non-adaptive algorithm first chooses the matrix &lt;math&gt;M&lt;/math&gt;, and is then given the vector '''y'''. The problem is then to find an estimate for '''x'''.|alt=A diagram showing a group testing matrix along with associated vectors, x and y.]]

Algorithms for non-adaptive group testing consist of two distinct phases. First, it is decided how many tests to perform and which items to include in each test.  In the second phase, often called the decoding step, the results of each group test are analysed to determine which items are likely to be defective. The first phase is usually encoded in a matrix as follows.&lt;ref name = "comp"/&gt;

*Suppose a non-adaptive group testing procedure for &lt;math&gt;n&lt;/math&gt; items consists of the tests &lt;math&gt;S_1, S_2, \dots, S_t&lt;/math&gt; for some &lt;math&gt;t \in \mathbb{N}_{\geq 0}&lt;/math&gt;. The ''testing matrix'' for this scheme is the &lt;math&gt;t \times n&lt;/math&gt; binary matrix, &lt;math&gt;M&lt;/math&gt;, where &lt;math&gt;(M)_{ij} = 1&lt;/math&gt; if and only if &lt;math&gt;j \in S_i&lt;/math&gt; (and is zero otherwise).

Thus each column of &lt;math&gt;M&lt;/math&gt; represents an item and each row represents a test, with a &lt;math&gt;1&lt;/math&gt; in the &lt;math&gt;(i,j)\textrm{-th}&lt;/math&gt; entry indicating that the &lt;math&gt;i\textrm{-th}&lt;/math&gt; test included the &lt;math&gt;j\textrm{-th}&lt;/math&gt; item and a &lt;math&gt;0&lt;/math&gt; indicating otherwise.

As well as the vector &lt;math&gt;\mathbf{x}&lt;/math&gt; (of length &lt;math&gt;n&lt;/math&gt;) that describes the unknown defective set, it is common to introduce the result vector, which describes the results of each test.

*Let &lt;math&gt;t&lt;/math&gt; be the number of tests performed by a non-adaptive algorithm. The ''result vector'', &lt;math&gt;\mathbf{y} = (y_1, y_2, \dots, y_t)&lt;/math&gt;, is a binary vector of length &lt;math&gt;t&lt;/math&gt; (that is, &lt;math&gt;\mathbf{y} \in \{0,1\}^t&lt;/math&gt;) such that &lt;math&gt;y_i= 1&lt;/math&gt; if and only if the result of the &lt;math&gt;i\textrm{-th}&lt;/math&gt; test was positive (i.e. contained at least one defective).{{efn|Alternatively &lt;math&gt;\mathbf {y}&lt;/math&gt; can be defined by the equation &lt;math&gt;\mathbf{y} := M\mathbf {x}&lt;/math&gt;, where multiplication is [[logical AND]] (&lt;math&gt;\wedge&lt;/math&gt;) and addition is [[logical OR]] (&lt;math&gt;\vee&lt;/math&gt;). Here, &lt;math&gt;\mathbf {y}&lt;/math&gt; will have a &lt;math&gt;1&lt;/math&gt; in position &lt;math&gt;i&lt;/math&gt; if and only if &lt;math&gt;(M)_{i,j}&lt;/math&gt; and &lt;math&gt;\mathbf {x} _{j}&lt;/math&gt; are both &lt;math&gt;1&lt;/math&gt; for any &lt;math&gt;j&lt;/math&gt;. That is, if and only if at least one defective item was included in the &lt;math&gt;i\textrm{-th}&lt;/math&gt; test.}}

With these definitions, the non-adaptive problem can be reframed as follows: first a testing matrix is chosen, &lt;math&gt;M&lt;/math&gt;, after which the vector &lt;math&gt;\mathbf{y}&lt;/math&gt; is returned. Then the problem is to analyse &lt;math&gt;\mathbf{y}&lt;/math&gt; to find some estimate for &lt;math&gt;\mathbf{x}&lt;/math&gt;.

In the simplest noisy case, where there is a constant probability, &lt;math&gt;q&lt;/math&gt;, that a group test will have an erroneous result, one considers a random binary vector, &lt;math&gt;\mathbf{v}&lt;/math&gt;, where each entry has a probability &lt;math&gt;q&lt;/math&gt; of being &lt;math&gt;1&lt;/math&gt;, and is &lt;math&gt;0&lt;/math&gt; otherwise. The vector that is returned is then &lt;math&gt;\hat{\mathbf{y}} = \mathbf{y} + \mathbf{v}&lt;/math&gt;, with the usual addition on &lt;math&gt;(\mathbb{Z}/2\mathbb{Z})^n&lt;/math&gt; (equivalently this is the element-wise [[XOR]] operation). A noisy algorithm must estimate &lt;math&gt;\mathbf{x}&lt;/math&gt; using &lt;math&gt;\hat{\mathbf{y}}&lt;/math&gt; (that is, without direct knowledge of &lt;math&gt;\mathbf{y}&lt;/math&gt;).&lt;ref name = "comp"/&gt;

=== Bounds for non-adaptive algorithms ===
The matrix representation makes it possible to prove some bounds on non-adaptive group testing. The approach mirrors that of many deterministic designs, where &lt;math&gt;d&lt;/math&gt;-separable matrices are considered, as defined below.&lt;ref name = "book"/&gt;

*A binary matrix, &lt;math&gt;M&lt;/math&gt;, is called ''&lt;math&gt;d&lt;/math&gt;-separable'' if every Boolean sum (logical OR) of any &lt;math&gt;d&lt;/math&gt; of its columns is distinct. Additionally, the notation ''&lt;math&gt;\bar{d}&lt;/math&gt;-separable'' indicates that every sum of any of ''up to'' &lt;math&gt;d&lt;/math&gt; of &lt;math&gt;M&lt;/math&gt;'s columns is distinct. (This is not the same as &lt;math&gt;M&lt;/math&gt; being &lt;math&gt;k&lt;/math&gt;-separable for every &lt;math&gt;k \leq d&lt;/math&gt;.)

When &lt;math&gt;M&lt;/math&gt; is a testing matrix, the property of being &lt;math&gt;d&lt;/math&gt;-separable (&lt;math&gt;\bar{d}&lt;/math&gt;-separable) is equivalent to being able to distinguish between (up to) &lt;math&gt;d&lt;/math&gt; defectives. However, it does not guarantee that this will be straightforward. A stronger property, called ''&lt;math&gt;d&lt;/math&gt;-disjunctness'' does.

*A binary matrix, &lt;math&gt;M&lt;/math&gt; is called ''&lt;math&gt;d&lt;/math&gt;-disjunct'' if the Boolean sum of any &lt;math&gt;d&lt;/math&gt; columns does not contain any other column. (In this context, a column A is said to contain a column B if for every index where B has a 1, A also has a 1.)

A useful property of &lt;math&gt;d&lt;/math&gt;-disjunct testing matrices is that, with up to &lt;math&gt;d&lt;/math&gt; defectives, every non-defective item will appear in at least one test whose outcome is negative. This means there is a simple procedure for finding the defectives: just remove every item that appears in a negative test.

Using the properties of &lt;math&gt;d&lt;/math&gt;-separable and &lt;math&gt;d&lt;/math&gt;-disjunct matrices the following can be shown for the problem of identifying &lt;math&gt;d&lt;/math&gt; defectives among &lt;math&gt;n&lt;/math&gt; total items.&lt;ref name = "compressedSensing" /&gt;
#The number of tests needed for an asymptotically small ''average'' probability of error scales as &lt;math&gt;O(d\log_2 n)&lt;/math&gt;.
#The number of tests needed for an asymptotically small ''maximum'' probability of error scales as &lt;math&gt;O(d^2 \log_2 n)&lt;/math&gt;.
#The number of tests needed for a ''zero'' probability of error scales as &lt;math&gt;O \left(\frac{d^2 \log_2 n}{\log_2 d} \right)&lt;/math&gt;.

== Generalised binary-splitting algorithm ==
[[File:Generalised binary splitting.svg|thumb|300px|An illustration of the generalised binary-splitting algorithm where there are 8 defectives and 135 total items. Here, &lt;math&gt;2^{\alpha_1} = 16&lt;/math&gt;, and the first test gives a negative result so every item is declared non-defective. Hence there are 119 remaining items, so &lt;math&gt;2^{\alpha_2} = 8&lt;/math&gt;. This second group gives a positive result, so a binary search is used to find a defective. Once that is done, the whole process is repeated, calculating a new &lt;math&gt;\alpha&lt;/math&gt; using only those items whose defectiveness has not been determined.]]
The generalised binary-splitting algorithm is an essentially-optimal adaptive group-testing algorithm that finds &lt;math&gt;d&lt;/math&gt; or fewer defectives among &lt;math&gt;n&lt;/math&gt; items as follows:&lt;ref name = "book" /&gt;&lt;ref name = "Hwang"&gt;
{{cite journal
|last1=Hwang|first1=Frank K.
|title=A method for detecting all defective members in a population by group testing
|journal=Journal of the American Statistical Association
|date=September 1972
|volume=67|issue=339
|pages=605–608
|doi=10.2307/2284447
|jstor=2284447}}
&lt;/ref&gt;

# If &lt;math&gt;n \leq 2d - 2&lt;/math&gt;, test the &lt;math&gt;n&lt;/math&gt; items individually. Otherwise, set &lt;math&gt;l = n - d + 1&lt;/math&gt; and &lt;math&gt;\alpha = \lfloor \log_2{l/d} \rfloor&lt;/math&gt;.
# Test a group of size &lt;math&gt;2^\alpha&lt;/math&gt;. If the outcome is negative, every item in the group is declared to be non-defective; set &lt;math&gt;n := n - 2^\alpha&lt;/math&gt; and go to step 1. Otherwise, use a [[binary search]] to identify one defective and an unspecified number, called &lt;math&gt;x&lt;/math&gt;, of non-defective items; set &lt;math&gt;n := n - 1 - x&lt;/math&gt; and &lt;math&gt;d := d - 1&lt;/math&gt;. Go to step 1.

The generalised binary-splitting algorithm requires no more than &lt;math&gt;T&lt;/math&gt; tests where
&lt;math&gt;
T = \begin{cases}
n &amp; n \leq 2d-2\\
(\alpha+2)d + p - 1 &amp; n \geq 2d - 1
\end{cases}
&lt;/math&gt;.&lt;ref name = "book" /&gt;

For &lt;math&gt;n/d&lt;/math&gt; large, it can be shown that &lt;math&gt;T \rightarrow d \log_2(n/d)&lt;/math&gt;,&lt;ref name = "book" /&gt; which compares favorably to the &lt;math&gt;t = \frac{e}{\log_2 e}d\log_2 \left( \frac{n}{d} \right)&lt;/math&gt; tests required for Li's &lt;math&gt;s&lt;/math&gt;-stage algorithm. In fact, the generalised binary-splitting algorithm is close to optimal in the following sense. When &lt;math&gt;d \geq 2&lt;/math&gt; it can be shown that &lt;math&gt;T - B_I(d,n) \leq (d-1)&lt;/math&gt;, where &lt;math&gt;B_I(d,n) = \left\lceil \log_2 \sum_{i=0}^d {n \choose i} \right\rceil&lt;/math&gt; is the information lower bound.&lt;ref name = "book" /&gt;&lt;ref name = "Hwang" /&gt;

== Non-adaptive algorithms ==
Non-adaptive group-testing algorithms tend to assume that the number of defectives, or at least a good upper bound on them, is known.&lt;ref name = "comp"&gt;
{{citation
|arxiv=1107.4540
|author1=Chun Lam Chan
|title=2011 49th Annual Allerton Conference on Communication, Control, and Computing (Allerton)
|author2=Pak Hou Che
|last3=Jaggi|first3=Sidharth
|last4=Saligrama|first4=Venkatesh
|date = 1 September 2011
|pages = 1832–1839
|doi = 10.1109/Allerton.2011.6120391
|work = 49th Annual Allerton Conference on Communication, Control, and Computing|isbn=978-1-4577-1817-5
}}
&lt;/ref&gt; This quantity is denoted &lt;math&gt;d&lt;/math&gt; in this section. If no bounds are known, there are non-adaptive algorithms with low query complexity that can help estimate &lt;math&gt;d&lt;/math&gt;.&lt;ref&gt;{{cite journal
|last1=Sobel|first1=Milton
|last2=Elashoff|first2=R. M.
|title=Group testing with a new goal, estimation|journal=Biometrika
|date=1975
|volume=62
|issue=1
|pages=181–193
|doi=10.1093/biomet/62.1.181}}&lt;/ref&gt;

=== Combinatorial orthogonal matching pursuit (COMP) ===
[[File:COMP Algorithm.svg|thumb|An illustration of the COMP algorithm. COMP identifies item ''a'' as being defective and item ''b'' as being non-defective. However, it incorrectly labels ''c'' as a defective, since it is “hidden” by defective items in every test in which it appears.]]

Combinatorial Orthogonal Matching Pursuit, or COMP, is a simple non-adaptive group-testing algorithm that forms the basis for the more complicated algorithms that follow in this section.

First, each entry of the testing matrix is chosen [[Independent and identically distributed random variables|i.i.d.]] to be &lt;math&gt;1&lt;/math&gt; with probability &lt;math&gt;1/d&lt;/math&gt; and &lt;math&gt;0&lt;/math&gt; otherwise.

The decoding step proceeds column-wise (i.e. by item). If every test in which an item appears is positive, then the item is declared defective; otherwise the item is assumed to be non-defective. Or equivalently, if an item appears in any test whose outcome is negative, the item is declared non-defective; otherwise the item is assumed to be defective. An important property of this algorithm is that it never creates [[false negatives]], though a [[false positive]] occurs when all locations with ones in the ''j''-th column of &lt;math&gt;M&lt;/math&gt; (corresponding to a non-defective item ''j'') are "hidden" by the ones of other columns corresponding to defective items.

The COMP algorithm requires no more than &lt;math&gt;ed(1 + \delta) \ln(n)&lt;/math&gt; tests to have an error probability less than or equal to &lt;math&gt;n^{-\delta}&lt;/math&gt;.&lt;ref name="comp" /&gt; This is within a constant factor of the lower bound for the average probability of error above.

In the noisy case, one relaxes the requirement in the original COMP algorithm that the set of locations of ones in any column of &lt;math&gt;M&lt;/math&gt; corresponding to a positive item be entirely contained in the set of locations of ones in the result vector. Instead, one allows for a certain number of “mismatches” – this number of mismatches depends on both the number of ones in each column, and also the noise parameter, &lt;math&gt;q&lt;/math&gt;. This noisy COMP algorithm requires no more than &lt;math&gt;4.36(\sqrt{\delta} + \sqrt{1 + \delta})^2 (1 - 2q)^{-2}d \log_2{n}&lt;/math&gt; tests to achieve an error probability at most &lt;math&gt;n^{-\delta}&lt;/math&gt;.&lt;ref name = "comp" /&gt;

=== Definite defectives (DD) ===
The definite defectives method (DD) is an extension of the COMP algorithm that attempts to remove any false positives. Performance guarantees for DD have been shown to strictly exceed those of COMP.&lt;ref name = "dd"&gt;{{cite journal
|last1=Aldridge|first1=Matthew
|last2=Baldassini|first2=Leonardo
|last3=Johnson|first3=Oliver
|title=Group Testing Algorithms: Bounds and Simulations
|journal=IEEE Transactions on Information Theory
|date=June 2014
|volume=60|issue=6
|pages=3671–3687
|doi=10.1109/TIT.2014.2314472|arxiv=1306.6438}}&lt;/ref&gt;

The decoding step uses a useful property of the COMP algorithm: that every item that COMP declares non-defective is certainly non-defective (that is, there are no false negatives). It proceeds as follows.

#First the COMP algorithm is run, and any non-defectives that it detects are removed. All remaining items are now "possibly defective".
#Next the algorithm looks at all the positive tests. If an item appears as the only "possible defective" in a test, then it must be defective, so the algorithm declares it to be defective. 
#All other items are assumed to be non-defective. The justification for this last step comes from the assumption that the number of defectives is much smaller than the total number of items.

Note that steps 1 and 2 never make a mistake, so the algorithm can only make a mistake if it declares a defective item to be non-defective. Thus the DD algorithm can only create false negatives.

=== Sequential COMP (SCOMP) ===
SCOMP (Sequential COMP) is an algorithm that makes use of the fact that DD makes no mistakes until the last step, where it is assumed that the remaining items are non-defective. Let the set of declared defectives be &lt;math&gt;K&lt;/math&gt;. A positive test is called ''explained'' by &lt;math&gt;K&lt;/math&gt; if it contains at least one item in &lt;math&gt;K&lt;/math&gt;. The key observation with SCOMP is that the set of defectives found by DD may not explain every positive test, and that every unexplained test must contain a hidden defective.

The algorithm proceeds as follows.
# Carry out steps 1 and 2 of the DD algorithm to obtain &lt;math&gt;K&lt;/math&gt;, an initial estimate for the set of defectives.
# If &lt;math&gt;K&lt;/math&gt; explains every positive test, terminate the algorithm: &lt;math&gt;K&lt;/math&gt; is the final estimate for the set of defectives.
# If there are any unexplained tests, find the "possible defective" that appears in the largest number of unexplained tests, and declare it to be defective (that is, add it to the set &lt;math&gt;K&lt;/math&gt;). Go to step 2.

In simulations, SCOMP has been shown to perform close to optimally.&lt;ref name = "dd" /&gt;

== Example applications ==
The generality of the theory of group testing lends it to many diverse applications, including clone screening, locating electrical shorts;&lt;ref name = "book" /&gt; high speed computer networks;&lt;ref name = "noy"&gt;{{Cite book
|last1 = Bar-Noy|first1 = A.
|last2 = Hwang|first2 = F. K.
|last3 = Kessler|first3 = I.
|last4 = Kutten|first4 = S.
|date = 1 May 1992
|title = A new competitive algorithm for group testing
|journal = Eleventh Annual Joint Conference of the IEEE Computer and Communications Societies
|pages = 786–793
|volume = 2
|doi = 10.1109/INFCOM.1992.263516
|isbn = 978-0-7803-0602-8
}}&lt;/ref&gt; medical examination, quantity searching, statistics;&lt;ref name = "huhwangwang" /&gt; machine learning, DNA sequencing;&lt;ref name = "learning"&gt;{{cite journal
|last1 = Damaschke|first1 = Peter
|year = 2000
|title = Adaptive versus nonadaptive attribute-efficient learning
|journal = Machine Learning
|volume = 41|issue = 2
|pages = 197–215
|doi = 10.1023/A:1007616604496}}&lt;/ref&gt; cryptography;&lt;ref name = "keys"&gt;{{cite journal
|last1 = Stinson|first1 = D. R.
|last2 = van Trung|first2 = Tran
|last3 = Wei|first3 = R
|date = May 2000
|title = Secure frameproof codes, key distribution patterns, group testing algorithms and related structures
|journal = Journal of Statistical Planning and Inference
|volume = 86|issue = 2
|pages = 595–617
|doi = 10.1016/S0378-3758(99)00131-7|citeseerx = 10.1.1.54.6212
}}&lt;/ref&gt;&lt;ref name = "colbourn"&gt;{{cite journal
|last1 = Colbourn|first1 = C. J.
|last2 = Dinitz|first2 = J. H.
|last3 = Stinson|first3 = D. R.
|year = 1999
|title = Communications, Cryptography, and Networking
|journal = Surveys in Combinatorics
|issue = 267
|pages = 37}}&lt;/ref&gt; and data forensics.&lt;ref name = "data"&gt;{{Cite book
|last1 = Goodrich|first1 = Michael T.
|last2 = Atallah|first2 = Mikhail J.
|last3 = Tamassia|first3 = Roberto
|date = 7 June 2005
|title = Indexing information for data forensics
|journal = Applied Cryptography and Network Security
|volume = 3531
|pages = 206–221
|doi = 10.1007/11496137_15|series = Lecture Notes in Computer Science
|isbn = 978-3-540-26223-7
|citeseerx = 10.1.1.158.6036
}}&lt;/ref&gt; This section provides a brief overview of a small selection of these applications.

=== Multiaccess channels ===
[[File:Mutliaccess channel.svg|thumb|An illustration of a multiaccess channel showing a successful message and a message collision.]]
A [[Channel access method|multiaccess channel]] is a communication channel that connects many users at once. Every user can listen and transmit on the channel, but if more than one user transmits at the same time, the signals collide, and are reduced to unintelligible noise. Multiaccess channels are important for various real-world applications, notably wireless computer networks and phone networks.&lt;ref name = "multi"&gt;Chlebus, B. S. (2001). "Randomized communication in radio networks". In: Pardalos, P. M.; Rajasekaran, S.; Reif, J.; Rolim, J. D. P. (Eds.), ''Handbook of Randomized Computing'', Vol. I, p.401–456. Kluwer Academic Publishers, Dordrecht.&lt;/ref&gt;

A prominent problem with multiaccess channels is how to assign transmission times to the users so that their messages do not collide. A simple method is to give each user their own time slot in which to transmit, requiring &lt;math&gt;n&lt;/math&gt; slots. (This is called ''time division multiplexing'', or TDM.) However, this is very inefficient, since it will assign transmission slots to users that may not have a message, and it is usually assumed that only a few users will want to transmit at any given time – otherwise a multiaccess channel is not practical in the first place.

In the context of group testing, this problem is usually tackled by dividing time into 'epochs' in the following way.&lt;ref name = "book" /&gt; A user is called 'active' if they have a message at the start of an epoch. (If a message is generated during an epoch, the user only becomes active at the start of the next one.) An epoch ends when every active user has successfully transmitted their message. The problem is then to find all the active users in a given epoch, and schedule a time for them to transmit (if they have not already done so successfully). Here, a test on a set of users corresponds to those users attempting a transmission. The results of the test are the number of users that attempted to transmit, &lt;math&gt;0, 1,&lt;/math&gt; and &lt;math&gt;2^+&lt;/math&gt;, corresponding respectively to no active users, exactly one active user (message successful) or more than one active user (message collision). Therefore, using an adaptive group testing algorithm with outcomes &lt;math&gt;\{ 0, 1, 2^+\}&lt;/math&gt;, it can be determined which users wish to transmit in the epoch. Then, any user that has not yet made a successful transmission can now be assigned a slot to transmit, without wastefully assigning times to inactive users.

=== Machine learning and compressed sensing ===
[[Machine learning]] is a field of computer science that has many software applications such as DNA classification, fraud detection and targeted advertising. One of the main subfields of machine learning is the 'learning by examples' problem, where the task is to approximate some unknown function when given its value at a number of specific points.&lt;ref name = "book"/&gt; As outlined in this section, this function learning problem can be tackled with a group-testing approach.

In a simple version of the problem, there is some unknown function, &lt;math&gt;f: \{0,1\}^N \to \{0,1\}&lt;/math&gt; where &lt;math&gt;f(\textbf{x}) = \textbf{a} \cdot \textbf{x}&lt;/math&gt;, and &lt;math&gt;\textbf{a} \in \{0,1\}^N&lt;/math&gt; (using logical arithmetic: addition is logical OR and multiplication is logical AND). Here &lt;math&gt;\textbf{a}&lt;/math&gt; is '&lt;math&gt;d&lt;/math&gt; sparse', which means that at most &lt;math&gt;d \ll N&lt;/math&gt; of its entries are &lt;math&gt;1&lt;/math&gt;. The aim is to construct an approximation to &lt;math&gt;f&lt;/math&gt; using &lt;math&gt;t&lt;/math&gt; point evaluations, where &lt;math&gt;t&lt;/math&gt; is as small as possible.&lt;ref name = "compressedSensing"/&gt; (Exactly recovering &lt;math&gt;f&lt;/math&gt; corresponds to zero-error algorithms, whereas &lt;math&gt;f&lt;/math&gt; is approximated by algorithms that have a non-zero probability of error.)

In this problem, recovering &lt;math&gt;f&lt;/math&gt; is equivalent to finding &lt;math&gt;\textbf{a}&lt;/math&gt;. Moreover, &lt;math&gt;f(\textbf{p}) = 1&lt;/math&gt; if and only if there is some index, &lt;math&gt;n&lt;/math&gt;, where &lt;math&gt;\textbf{a}_n = \textbf{p}_n = 1&lt;/math&gt;. Thus this problem is analogous to a group-testing problem with &lt;math&gt;d&lt;/math&gt; defectives and &lt;math&gt;n&lt;/math&gt; total items. The entries of &lt;math&gt;\textbf{a}&lt;/math&gt; are the items, which are defective if they are &lt;math&gt;1&lt;/math&gt;, &lt;math&gt;\textbf{p}&lt;/math&gt; specifies a test, and a test is positive if and only if &lt;math&gt;f(\textbf{p}) = 1&lt;/math&gt;.&lt;ref name = "compressedSensing"/&gt;

In reality, one will often be interested in functions that are more complicated, such as &lt;math&gt;f: \mathbb{C}^N \to \mathbb{C}&lt;/math&gt;, again where &lt;math&gt;f(\textbf{x}) = \textbf{a} \cdot \textbf{x}&lt;/math&gt;. [[Compressed sensing]], which is closely related to group testing, can be used to solve this problem.&lt;ref name = "compressedSensing"/&gt;

In compressed sensing, the goal is to reconstruct a signal, &lt;math&gt;\textbf{v} \in \mathbb{C}^N&lt;/math&gt;, by taking a number of measurements. These measurements are modelled as taking the dot product of &lt;math&gt;\textbf{v}&lt;/math&gt; with a chosen vector.{{efn|This kind of measurement comes up in many applications. For example, certain kinds of digital camera&lt;ref name = "takhar"&gt;{{cite journal
|last1 = Takhar|first1 = D.
|last2 = Laska|first2 = J. N.
|last3 = Wakin|first3 = M. B.
|last4 = Duarte|first4 = M. F.
|last5 = Baron|first5 = D.
|last6 = Sarvotham|first6 = S.
|last7 = Kelly|first7 = K. F.
|last8 = Baraniuk|first8 = R. G.
|date = February 2006
|title = A new compressive imaging camera architecture using optical-domain compression
|journal = Electronic Imaging
|volume = 6065
|pages = 606509–606509–10
|bibcode = 2006SPIE.6065...43T
|doi = 10.1117/12.659602
|series = Computational Imaging IV
|citeseerx = 10.1.1.114.7872
}}&lt;/ref&gt; or MRI machines,&lt;ref name = "candes"&gt;Candès, E. J. (2014). "Mathematics of sparsity (and a few other things)". Proceedings of the International Congress of Mathematicians. Seoul, South Korea.&lt;/ref&gt; where time constraints require that only a small number of measurements are taken.}} The aim is to use a small number of measurements, though this is typically not possible unless something is assumed about the signal. One such assumption (which is common&lt;ref name = "gilbert"&gt;Gilbert, A. C.; Iwen, M. A.; Strauss, M. J. (October 2008). "Group testing and sparse signal recovery". 42nd Asilomar Conference on Signals, Systems and Computers: 1059–1063. Institute of Electrical and Electronics Engineers.&lt;/ref&gt;&lt;ref name = "wright"&gt;{{cite journal
|last1 = Wright|first1 = S. J.
|last2 = Nowak|first2 = R. D.
|last3 = Figueiredo|first3 = M. A. T.
|date = July 2009
|title = Sparse Reconstruction by Separable Approximation
|journal = IEEE Transactions on Signal Processing
|volume = 57|issue = 7
|pages = 2479–2493
|doi = 10.1109/TSP.2009.2016892|bibcode = 2009ITSP...57.2479W|citeseerx = 10.1.1.142.749
}}&lt;/ref&gt;) is that only a small number of entries of &lt;math&gt;\textbf{v}&lt;/math&gt; are ''significant'', meaning that they have a large magnitude. Since the measurements are dot products of &lt;math&gt;\textbf{v}&lt;/math&gt;, the equation &lt;math&gt;M\textbf{v} = \textbf{q}&lt;/math&gt; holds, where &lt;math&gt;M&lt;/math&gt; is a &lt;math&gt;t \times N&lt;/math&gt; matrix that describes the set of measurements that have been chosen and &lt;math&gt;\mathbf{q}&lt;/math&gt; is the set of measurement results. This construction shows that compressed sensing is a kind of 'continuous' group testing.

The primary difficulty in compressed sensing is identifying which entries are significant.&lt;ref name = "gilbert" /&gt; Once that is done, there are a variety of methods to estimate the actual values of the entries.&lt;ref name = "berinde"&gt;{{Cite book
|last1 = Berinde|first1 = R.
|last2 = Gilbert|first2 = A. C.
|last3= Indyk|first3 = P.
|last4 = Karloff|first4 = H.
|last5 = Strauss|first5 = M. J.
|date = September 2008
|title = Combining geometry and combinatorics: A unified approach to sparse signal recovery
|journal = 46th Annual Allerton Conference on Communication, Control, and Computing
|pages = 798–805
|doi = 10.1109/ALLERTON.2008.4797639|arxiv = 0804.4666|isbn = 978-1-4244-2925-7
}}&lt;/ref&gt; This task of identification can be approached with a simple application of group testing. Here a group test produces a complex number: the sum of the entries that are tested. The outcome of a test is called  positive if it produces a complex number with a large magnitude, which, given the assumption that the significant entries are sparse, indicates that at least one significant entry is contained in the test.

There are explicit deterministic constructions for this type of combinatorial search algorithm, requiring &lt;math&gt;d2^{(\log_2 \log_2 N)^{O(1)}}&lt;/math&gt; measurements.&lt;ref name = "poitr"&gt;{{cite journal
|last1 = Indyk|first1 = Piotr
|date = 1 January 2008
|title = Explicit Constructions for Compressed Sensing of Sparse Signals
|journal = Proceedings of the Nineteenth Annual ACM-SIAM Symposium on Discrete Algorithms
|pages = 30–33
}}&lt;/ref&gt; However, as with group-testing, these are sub-optimal, and random constructions (such as COMP) can often recover &lt;math&gt;f&lt;/math&gt; sub-linearly in &lt;math&gt;N&lt;/math&gt;.&lt;ref name = "berinde" /&gt;

=== Data forensics ===

Data forensics is a field dedicated to finding methods for compiling digital evidence of a crime. Such crimes typically involve an adversary modifying the data, documents or databases of a victim, with examples including the altering of tax records, a virus hiding its presence, or an identity thief modifying personal data.&lt;ref name = "data"/&gt;

A common tool in data forensics is the [[Hash function|one-way cryptographic hash]]. This is a function that takes the data, and through a difficult-to-reverse procedure, produces a unique number called a hash.{{efn|More formally hashes have a property called collision resistance, which is that the likelihood of the same hash resulting from different inputs is very low for data of an appropriate size. In practice, the chance that two different inputs might produce the same hash is often ignored.}} Hashes, which are often much shorter than the data, allow us to check if the data has been changed without having to wastefully store complete copies of the information: the hash for the current data can be compared with a past hash to determine if any changes have occurred. An unfortunate property of this method is that, although it is easy to tell if the data has been modified, there is no way of determining how: that is, it is impossible to recover which part of the data has changed.&lt;ref name = "data"/&gt;

One way to get around this limitation is to store more hashes – now of subsets of the data structure – to narrow down where the attack has occurred. However, to find the exact location of the attack with a naive approach, a hash would need to be stored for every datum in the structure, which would defeat the point of the hashes in the first place. (One may as well store a regular copy of the data.) Group testing can be used to dramatically reduce the number of hashes that need to be stored. A test becomes a comparison between the stored and current hashes, which is positive when there is a mismatch. This indicates that at least one edited datum (which is taken as defectiveness in this model) is contained in the group that generated the current hash.&lt;ref name = "data"/&gt;

In fact, the amount of hashes needed is so low that they, along with the testing matrix they refer to, can even be stored within the organisational structure of the data itself. This means that as far as memory is concerned the test can be performed 'for free'. (This is true with the exception of a master-key/password that is used to secretly determine the hashing function.)&lt;ref name = "data"/&gt;

== Notes ==
{{notelist}}

== References ==
=== Citations ===
{{reflist|30em}}

=== General references ===
* {{cite book
|last1=Ding-Zhu|first1= Du
|last2=Hwang|first2=Frank K.
|title=Combinatorial group testing and its applications
|date=1993
|publisher=World Scientific
|location=Singapore
|isbn=978-9810212933}}
* Atri Rudra's course on Error Correcting Codes: Combinatorics, Algorithms, and Applications (Spring 2007), Lectures [http://www.cse.buffalo.edu/~atri/courses/coding-theory/lectures/lect7.pdf 7].
* Atri Rudra's course on Error Correcting Codes: Combinatorics, Algorithms, and Applications (Spring 2010), Lectures [http://www.cse.buffalo.edu/~atri/courses/coding-theory/spr10/lectures/lect10.pdf 10], [http://www.cse.buffalo.edu/~atri/courses/coding-theory/spr10/lectures/lect11.pdf 11], [http://www.cse.buffalo.edu/~atri/courses/coding-theory/spr10/lectures/lect28.pdf 28],  [http://www.cse.buffalo.edu/~atri/courses/coding-theory/spr10/lectures/lect29.pdf 29]
* Du, D., &amp; Hwang, F. (2006). Pooling Designs and Nonadaptive Group Testing. Boston: Twayne Publishers.
* Ely Porat, Amir Rothschild: Explicit Non-adaptive Combinatorial Group Testing Schemes. ICALP (1) 2008: 748–759
*{{citation
|last1=Kagan|first1=Eugene
|last2=Ben-gal|first2=Irad
|title=A group testing algorithm with online informational learning
|journal=IIE Transactions
|year=2014
|volume=46
|issue=2
|pages=164–184
|issn=0740-817X
|doi=10.1080/0740817X.2013.803639
|ref=no}}

== See also ==
* [[Balance puzzle]]

[[Category:Combinatorics]]
[[Category:Design of experiments]]</text>
      <sha1>n2h4bmzbb8fm8jfydiw1l058krwknaw</sha1>
    </revision>
  </page>
  <page>
    <title>Heliographic copier</title>
    <ns>0</ns>
    <id>45088464</id>
    <revision>
      <id>808226135</id>
      <parentid>795181667</parentid>
      <timestamp>2017-11-01T16:52:32Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 2 sources and tagging 0 as dead. #IABot (v1.6)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10397">A ''' heliographic copier''' or ''' heliographic duplicator'''&lt;ref name="Nations1937"&gt;{{cite book|author=League of Nations|title=Economic Committee: Sub-committee of Experts for the Unification of Customs Tariff Nomenclature. Draft Customs Nomenclature|url=https://books.google.es/books?id=9-XmAAAAMAAJ&amp;q=heliographic+duplicator&amp;dq=heliographic+duplicator&amp;hl=ca&amp;sa=X&amp;ved=0ahUKEwj70Y-e3urNAhXG0xQKHTkEDlEQ6AEIUTAI|year=1937}}&lt;/ref&gt; is an apparatus used in the world of [[reprography]] for making contact prints on paper from original drawings made with that purpose on [[tracing paper]], [[parchment paper ]] or any other transparent or translucent material using different procedures. In general terms some type of ''heliographic copier'' is used for making: Hectographic prints, Ferrogallic prints, Gel-lithographs or Silver halide prints. All of them, until a certain size, can be achieved using a [[contact printer]] with an appropriate lamp (ultraviolet, etc...) but for big engineering and architectural plans, the ''heliographic copiers'' used with the [[cyanotype]] and the [[diazotype]] technologies, are of the roller type, which makes them completely different from [[contact printer]]s.

In the "argot" of engineers, architects and designers, the resulting plan copies coming from any type of '' heliographic copier'' no matter they were either blue or white, were traditionally called [[blueprint]]s, name derived from the blue background color of the [[cyanotype]] technique, which was the previous process for obtaining blueprints,  When the [[diazo]] based compounds changed the background color to white, in technical environments, -by tradition-, the name for copies of technical drawings remained [[Blueprint]] , although in English-speaking countries, it was intended, without much success, to change the name from ''[[Blueprint]]'' to ''[[Whiteprint]]''. Depending on the color or the line and background, the appropriate paper may be developed for blueprints (blue background), whiteprints (blue line and white background), black line (white background) and sepia, using the same machine and process. 

Using the right compound some "cyano copiers" could be adapted to be used as "diazo copiers".&lt;ref name = "Taylor2004"&gt;{{cite book | author = David L. Taylor | title = Blueprint Reading for MachineTrades|url=https://books.google.es/books?id=EWE-RK3F6mcC&amp;pg=PA3&amp;dq=Machine+Trades+Blueprint+Reading+David+L.+Taylor+the+term+blueprint+is+still+widely+used&amp;hl=ca&amp;sa=X&amp;ei=kh26VL7bKoHcUtW0g6gG&amp;ved=0CCMQ6AEwAA#v=onepage&amp;q=Machine%20Trades%20Blueprint%20Reading%20David%20L.%20Taylor%20the%20term%20blueprint%20is%20still%20widely%20used&amp;f=false|year=2004|publisher=Cengage Learning | isbn = 1-4018-9998-6 | pages = 3 -}}&lt;/ref&gt;

== History ==

The light sensitivity of certain chemicals used in the cyanotype process, was already known when the English scientist and astronomer Sir [[John Herschel]] discovered the procedure in 1842 and several other related printing processes were patented by the 1890s .&lt;ref&gt;{{cite web|url=http://www.vam.ac.uk/vastatic/microsites/photography/process.php?processid=pr012&amp;row=2 |title=Exploring Photography – Photographic Processes – Cyanotype |website=V&amp;A|date=2012-11-13 |accessdate=2012-12-22}}&lt;/ref&gt;  When Herschel developed the process, he considered it mainly as a means of reproducing notes and diagrams, as its use in [[blueprints]].&lt;ref&gt;{{cite web|url=http://vernacularphotography.com/vpm/v1n1/the_cyanotype.htm |title=The Cyanotype |website=Vernacular Photography|date=2012-12-12 |accessdate=2012-12-22}}&lt;/ref&gt;

==Cyano copier==
{{see also|Cyanotype|Blueprint}}
[[File:Joy Oil gas station blueprints.jpg|right|thumb|300px|Architectural drawing, Canada, 1936]]
This is a simple process for the reproduction of any light transmitting document. [[Engineer]]s and [[architect]]s used to draw their designs on [[cartridge paper]]; these were then traced by hand on to [[tracing paper]] using [[India ink|Indian ink]], which were kept to be reproduced with the ''cyano-copie''r whenever they were needed.

Introduction of the blueprint process eliminated the high expenses of photolithographic reproduction or of hand-tracing of original drawings. By the latter 1890s in American architectural offices, a blueprint was one-tenth the cost of a hand-traced reproduction.&lt;ref&gt;Mary N. Woods ''From Craft to Profession: The Practice of Architecture in Nineteenth-Century America'' University of California Press, 1999 {{ISBN|0520214943}}, page 239-240&lt;/ref&gt; The blueprint process is still used for special artistic and photographic effects, on paper and fabrics.&lt;ref&gt;Gary Fabbri, Malin Fabbri ''Blueprint to Cyanotypes - Exploring a Historical Alternative Photographic Process''Lulu.com, 2006 {{ISBN|141169838X}} page 7&lt;/ref&gt;

=== Features ===
Different blueprint processes based on photosensitive ferric compounds have been used. The best known is probably a process using ammonium ferric citrate and potassium ferricyanide.&lt;ref&gt;{{Citation|title=Blue|url=http://www.pslc.ws/macrog/work/blue.htm|place=WS|publisher=PSLC}}.&lt;/ref&gt; In this procedure a distinctly blue compound is formed and the process is also known as [[cyanotype]]. The paper is impregnated with a solution of ammonium ferric citrate and dried. When the paper is illuminated a photoreaction turns the trivalent (ferric) iron into divalent (ferrous) iron. The image is then developed using a solution of potassium ferricyanide forming insoluble ferroferricyanide ([[Prussian blue|Turnbell's blue]] identical to [[Prussian blue]]) with the divalent iron. Excess ammonium ferric citrate and potassium ferricyanide are then washed away.

==Diazo copier==
{{see also|Diazotype|Whiteprint}}
[[File:Heliographic copy.jpg|thumb | Diazo copies of drawings]]
The process of [[diazotype]] ([[Whiteprint|Whiteprints]]) replaced the  [[cyanotype]]  process ([[blueprint|blueprints]]) for reproducing architectural and [[engineering drawing]]s because the process was simpler and involved fewer toxic chemicals.&lt;ref name="BlueprinReplaced2006"&gt;{{cite book|author1=Eva Zeisel|author2=Robert Sabella|title=Blueprints replaced by whiteprints|url=https://books.google.es/books?id=Myz4kBTPTyQC&amp;pg=PA244&amp;lpg=PA244&amp;dq=Blueprints+replaced+by+whiteprints&amp;source=bl&amp;ots=e3bx52lOXy&amp;sig=COqWtnWs0wLzhJe9zOC7qYAb6zk&amp;hl=ca&amp;sa=X&amp;ved=0ahUKEwjEh7a0nOzNAhVIVhoKHT6hAPsQ6AEITjAF#v=onepage&amp;q=Blueprints%20replaced%20by%20whiteprints&amp;f=false|year=2006|publisher=Que Certification|isbn=978-0-7897-3504-1|pages=244–}}&lt;/ref&gt; 

A blue-line print is not permanent and will fade if exposed to light for weeks or months, but  a drawing print that lasts only a few months is sufficient for many purposes (test prints)

The different names ''blue-line copier'', ''[[whiteprint]] copier'' or '' diazo copier'',&lt;ref name="WijnekusWijnekus2013"&gt;{{cite book|url=https://books.google.es/books?id=VQghBQAAQBAJ&amp;pg=PA844&amp;dq=copiadora+diazo&amp;hl=ca&amp;sa=X&amp;ei=h026VO3kAsH7UKvOg6gE&amp;ved=0CCwQ6AEwAA#v=onepage&amp;q=copiadora%20diazo&amp;f=false|title=Dictionary of the Printing and Allied Industries: In Inglés (with definitions), French, German, Dutch, Spanish andItalian|date=22 October 2013|publisher=Elsevier Science|isbn=978-1-4832-8984-7|pages=844 -|author1=FJM Wijnekus|author2=E.F.P.H. Wijnekus}}&lt;/ref&gt; were given, due to the nature of the process, which consists in exposing to an [[ultraviolet|ultraviolet light]] a previously sensitized paper with a component called [[diazo]], and finally developing it in a bath (a solution of ammonia in water) which converts the parts not exposed to light, to a dark blue colour (blue-line) over an almost white background.

=== Features ===
A little smell of ammonia and a faintly purplish paper colour are the main characteristics of a [[whiteprint]]. The dark lines in the original are converted to a dark violet colour, while the white parts degrade to a light purplish colour. The back of the drawings is a cream colour in which the folds are degraded to a lighter colour.

The diazo copies are of different sizes and for this reason the diazo paper is obtainable in standard sizes that vary from 30&amp;nbsp;cm to 60&amp;nbsp;cm wide, after de process the copied paper can be cut to the desired size.

The paper used for the diazo copies is usually a bond paper or similar type, with a diazo coating sensitive to the [[Ultraviolet|UV]] light.

==Operation ==

The original plan and the [[Photosensitive|sensitized paper]] , are introduced, in perfect contact, within the copier rollers that pull and expose them to a source of ultraviolet light, typically a [[blacklight]] lamp, similar to the manual action to expose both sheets strongly bonded directly to the sunlight, and once exposed:

*In the '' cyano copier'', the copied paper is immersed in a ''developer solution'' made from potassium ferricyanide and the it must be washed with water to eliminate the excess ammonium ferric citrate and potassium ferricyanide. 
*In the '' diazo copier'', the paper is immersed in a ''developer solution'' made from ammonia (or ammonia vapor) converting the parts of the paper not exposed to the light source to a characteristic dark blue colour .

==See also==
* [[Azo compound]]
* [[Blueprint]]
* [[Ozalid]]
* [[Contact copier]]

==References==
{{reflist|2}}

== Bibliography==
* Blacklow, Laura. (2000) ''New Dimensions in Photo Processes: a step by step manual.'' 3rd ed.
* Ware, M. (1999) ''Cyanotype: the history, science and art of photographic printing in Prussian blue.'' Science Museum, UK
*{{cite book|author1=María de los Santos García Felguera|author2=Marie-Loup Sougez|author3=Helena Pérez Gallardo|author4=Carmelo Vega|title=Historia general de la fotografía|url=https://books.google.com/books?id=s1-9AQAACAAJ|year=2007|publisher=Cátedra|isbn=978-84-376-2344-3}}

== External links ==
* [http://www.vintageadbrowser.com/office-ads-1960s/3 Office-ads-1960s]
* [https://web.archive.org/web/20150118014023/http://www.garymeleski.com/blueprints-or-not/#!prettyPhoto Garymeleski.com]
* [http://www.goodly.com.tw/e-q-800.htm DIAZO BLUE PRINTING MACHINE - WHITEPRINTER]
* [https://web.archive.org/web/20141223202628/http://www.scbispl.com/diazo%20developer.htm Diazo developer]
* [http://www.mcu.es/patrimonio/docs/MC/IPHE/PatrimonioCulturalE/N2/19_PCE2_Cianotipias_Planos.pdf Ministerio de cultura]

[[Category:Non-impact printing]]
[[Category:Technical drawing]]
[[Category:Infographics]]</text>
      <sha1>d6m7aupm015pyozcyx943l6whg1lwi6</sha1>
    </revision>
  </page>
  <page>
    <title>Hellenic Mathematical Society</title>
    <ns>0</ns>
    <id>945503</id>
    <revision>
      <id>699691658</id>
      <parentid>543836506</parentid>
      <timestamp>2016-01-13T21:44:56Z</timestamp>
      <contributor>
        <username>Rathfelder</username>
        <id>398607</id>
      </contributor>
      <comment>removed [[Category:Organizations based in Greece]]; added [[Category:Learned societies of Greece]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1057">The '''Hellenic  Mathematical Society (HMS)''' (Greek: Ελληνική Μαθηματική Εταιρεία) is a learned society which promotes the study of [[mathematics]] in [[Greece]]. It was founded in 1918, and published the ''Bulletin of the Greek Mathematical Society''.

It is a member of the [[European Mathematical Society]].&lt;ref&gt;[http://www.emis.de/member-societies.html Member Societies and Institutional Members of the European Mathematical Society]&lt;/ref&gt;	    

== See also ==
*[[European Mathematical Society]]
*[[List of Mathematical Societies]]

==External links== 
*[http://www.hms.gr/ Hellenic  Mathematical Society] Official site.

==References==
&lt;references /&gt;
*[http://www-groups.dcs.st-and.ac.uk/~history/Societies/Hellenic.html The MacTutor History of Mathematics archive - Hellenic Mathematical Society]

{{The European Mathematical Society}}

[[Category:History of mathematics]]
[[Category:Learned societies of Greece]]
[[Category:Mathematical societies]]
[[Category:1918 establishments in Greece]]

{{Math-stub}}
{{Greece-stub}}</text>
      <sha1>4z602aak6ioyayf90v2yooqq731l9l1</sha1>
    </revision>
  </page>
  <page>
    <title>Horst Sachs</title>
    <ns>0</ns>
    <id>15095266</id>
    <revision>
      <id>785767304</id>
      <parentid>727831617</parentid>
      <timestamp>2017-06-15T09:28:42Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2507">{{Use dmy dates|date=July 2016}}
[[File:Horst Sachs.jpg|thumb|220px|Horst Sachs]]
'''Horst Sachs''' (27 March 1927 – 25 April 2016) was a [[Germany|German]] [[mathematician]], an expert in [[graph theory]], a recipient of the [[Euler Medal]] (2000).&lt;ref&gt;{{cite web|url=https://www.tu-ilmenau.de/index.php?id=44015|title=Horst Sachs 1927 - 2016|work=tu-ilmenau.de|accessdate=4 May 2016}}&lt;/ref&gt;

He earned the degree of [[Doctor of Science]] (Dr. rer. nat.) from the [[Martin-Luther-Universität Halle-Wittenberg]] in 1958.&lt;ref&gt;{{MathGenealogy|id=60099}}.&lt;/ref&gt; Following his retirement in 1992, he was [[professor emeritus]] at the Institute of Mathematics of the [[Technische Universität Ilmenau]].&lt;ref&gt;[http://www.tu-ilmenau.de/fakmn/Sachs-Horst.sachs.0.html Faculty profile at Ilmenau], retrieved 2010-08-07.&lt;/ref&gt;

His encyclopedic book in [[spectral graph theory]], ''Spectra of Graphs. Theory and Applications'' (with Dragos Cvetković and Michael Doob) has several editions and was translated in several languages.&lt;ref&gt;[[VEB Deutscher Verlag der Wissenschaften]], Berlin, 1980. Academic Press, 1980. 2nd ed., [[VEB Deutscher Verlag der Wissenschaften]], 1982. 3rd revised and enlarged ed., Johann Ambrosius Barth, Heidelberg, 1995, {{ISBN|978-3-335-00407-3}}. Russian translation ''Spektry grafov. teoriia i primenenie'', Naukova dumka, Kiev, 1984.&lt;/ref&gt;&lt;ref&gt;Review by Lowell W. Beineke (1981), ''SIAM Review'' '''23''' (4): 546–548, {{doi|10.1137/1023115}}.&lt;/ref&gt;&lt;ref&gt;Review by Gordon J. Savage and S. Toida (1981), ''Journal of the Franklin Institute'' '''311''' (6): 403, {{doi|10.1016/0016-0032(81)90029-6}}.&lt;/ref&gt;&lt;ref&gt;Review by [[Bojan Mohar]] (1995), {{Zbl|0824.05046}}.&lt;/ref&gt;&lt;ref&gt;Review by Wessel (1996), [[Journal of Applied Mathematics and Mechanics]] '''76''' (10): 144, {{doi|10.1002/zamm.19960760305}}.&lt;/ref&gt;&lt;ref&gt;Review by P. Rowlinson (1996), ''Proceedings of the Edinburgh Mathematical Society (Series 2)'' '''39''': 188–189, {{doi|10.1017/S0013091500022902}}.&lt;/ref&gt;

Two theorems in graph theory bear his name. One of them relates the coefficients of the [[characteristic polynomial]] of a graph to certain structural features of the graph. Another one is a simple relation between the characteristic polynomials of a graph and its [[line graph]].

==References==
{{Reflist}}

{{Authority control}}
{{DEFAULTSORT:Sachs, Horst}}
[[Category:1927 births]]
[[Category:20th-century mathematicians]]
[[Category:Graph theorists]]
[[Category:2016 deaths]]

{{Germany-mathematician-stub}}</text>
      <sha1>q6qwxnx4j9hki7ujfwd7upnkt1id2gt</sha1>
    </revision>
  </page>
  <page>
    <title>Invariant convex cone</title>
    <ns>0</ns>
    <id>39078438</id>
    <revision>
      <id>748845732</id>
      <parentid>714319697</parentid>
      <timestamp>2016-11-10T18:52:13Z</timestamp>
      <contributor>
        <username>CitationCleanerBot</username>
        <id>15270283</id>
      </contributor>
      <minor/>
      <comment>/* References */clean up, url redundant with jstor, and/or remove accessdate if no url using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24668">In [[mathematics]], an '''invariant convex cone''' is a closed [[convex cone]] in a [[Lie algebra]] of a  connected [[Lie group]] that is invariant under inner automorphisms. The study of such cones was initiated by [[Ernest Vinberg]] and [[Bertram Kostant]].

For a simple Lie algebra, the existence of an invariant convex cone forces the Lie algebra to have a Hermitian structure, i.e. the maximal compact subgroup has center isomorphic to the circle group. The invariant convex cone generated by a generator of the Lie algebra of the center is closed and is the minimal invariant convex cone (up to a sign). The dual cone with respect to the [[Killing form]] is the maximal invariant convex cone. Any intermediate cone is uniquely determined by its intersection with the Lie algebra of a [[maximal torus]] in a maximal compact subgroup. The intersection is invariant under the [[Weyl group]] of the maximal torus and the orbit of every point in the interior of the cone intersects the interior of the Weyl group invariant cone.

For the real [[symplectic group]], the maximal and minimal cone coincide, so there is only one invariant convex cone. When one is properly contained in the other, there is a continuum of intermediate invariant convex cones.

Invariant convex cones arise in the analysis of holomorphic semigroups in the [[complexification (Lie group)|complexification]] of the Lie group, first studied by Grigori Olshanskii. They are naturally associated with [[Hermitian symmetric space]]s and their associated [[holomorphic discrete series]]. The semigroup is made up of those elements in the complexification which, when acting on the Hermitian symmetric space of compact type, leave invariant the bounded domain corresponding to the noncompact dual. The semigroup acts by [[contraction (operator theory)|contraction operators]] on the holomorphic discrete series; its interior acts by [[Hilbert–Schmidt operator]]s.  The unitary part of their [[polar decomposition]] is the operator corresponding to an element in the original real Lie group, while the positive part is the exponential of an imaginary multiple of the infinitesimal operator corresponding to an element in the maximal cone. A similar decomposition already occurs in the semigroup.

The [[oscillator semigroup]] of [[Roger Evans Howe|Roger Howe]] concerns the special case of this theory for the real symplectic group. Historically this has been one of the most important applications and has been generalized to infinite dimensions. This article treats in detail the example of the invariant convex cone for the symplectic group and its use in the study of the symplectic Olshanskii semigroup.

==Invariant convex cone in symplectic Lie algebra==
The Lie algebra of the symplectic group on '''R'''&lt;sup&gt;2''n''&lt;/sup&gt; has a unique invariant convex cone. It is self-dual.&lt;ref&gt;See:
*{{harvnb|Vinberg|1980}}
*{{harvnb|Paneitz|1983}}
&lt;/ref&gt; The cone and its properties can be derived directly using the description of the symplectic Lie algebra provided by the [[Weyl calculus]] in [[quantum mechanics]].&lt;ref&gt;See:
*{{harvnb|Howe|1988}}
*{{harvnb|Folland|1989}}&lt;/ref&gt; Let the variables in '''R'''&lt;sup&gt;2''n''&lt;/sup&gt; be ''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''n''&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;, ..., ''y''&lt;sub&gt;''n''&lt;/sub&gt;. Taking the standard inner product on  '''R'''&lt;sup&gt;2''n''&lt;/sup&gt;, the symplectic form corresponds to the matrix

:&lt;math&gt;\displaystyle{J=\begin{pmatrix} 0 &amp; I \\ -I &amp; 0\end{pmatrix}.}&lt;/math&gt;

The real polynomials on '''R'''&lt;sup&gt;2''n''&lt;/sup&gt; form an infinite-dimensional Lie algebra under the [[Poisson bracket]]

:&lt;math&gt;\displaystyle{\{f,g\}=\sum_i {\partial f\over \partial x_i}{\partial g\over \partial y_i} -
{\partial f\over \partial y_i}{\partial g\over \partial x_i}.}&lt;/math&gt;

The polynomials of degree ≤ 2 form a finite-dimensional Lie algebra with center the constant polynomials. The homogeneous polynomials of degree 2 form a Lie subalgebra isomorphic to the symplectic Lie algebra. The symplectic group acts naturally on this subalgebra by reparametrization and this yields the [[adjoint representation]]. Homogeneous polynomials of degree 2 on the other hand are just symmetric bilinear forms on '''R'''&lt;sub&gt;2''n''&lt;/sub&gt;. They therefore correspond to symmetric 2''n'' × 2''n'' matrices. The [[Killing form]] on the Lie algebra is proportional to the trace form Tr ''AB''. 
The positive definite symmetric bilinear forms give an open invariant convex cone with closure the set ''P'' of positive semi-definite symmetric bilinear forms. Because the Killing form is the trace form, the cone ''P''  is self-dual.
 
Any positive symmetric bilinear form defines a new inner product on '''R'''&lt;sup&gt;2''n''&lt;/sup&gt;. The symplectic from defines an invertible skew-adjoint operator ''T'' with respect to this inner product with –''T''&lt;sup&gt;2&lt;/sup&gt; a positive operator. An orthonormal basis can be chose so that ''T'' has 2 × 2 skew-symmetric matrices down the diagonal. Scaling the orthonormal basis, it follows that there is a symplectic basis for '''R'''&lt;sup&gt;2''n''&lt;/sup&gt; diagonalizing the original positive symmetric bilinear form. Thus every positive symmetric bilinear form lies in the orbit of a diagonal form under the symplectic group.

If ''C'' is any other invariant convex cone then it is invariant under the closed subgroup ''U'' of the symplectic group consisting of orthogonal transformations commuting with ''J''. Identifying '''R'''&lt;sup&gt;2''n''&lt;/sup&gt; with the complex inner product space '''C'''&lt;sup&gt;''n''&lt;/sup&gt; using the complex structure ''J'', ''U'' can be identified with ''U''(''n''). Taking any non-zero point in ''C''. the average over ''U'' with respect to [[Haar measure]] lies in ''C'' and is non-zero. The corresponding quadratic form is a multiple of the standard inner product. Replacing ''C'' by –''C'' this multiple can be taken to be positive. There is a copy of SL(2,'''R''') in the symplectic group acting only on the variables ''x''&lt;sub&gt;''i''&lt;/sub&gt; and ''y''&lt;sub&gt;''i''&lt;/sub&gt;. These operators can be used to transform
{{math|1=(''x''&lt;sub&gt;''i''&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt; + (''y''&lt;sub&gt;''i''&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;}} into
{{math|1=''t''(''x''&lt;sub&gt;''i''&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt; + (2 – ''t'')(''y''&lt;sub&gt;''i''&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;}} with 0 &lt; ''t'' &lt; 2. It follows that ''C'' contains the point {{math|1=(''x''&lt;sub&gt;1&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt; + (''y''&lt;sub&gt;2&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt; + ... + (''y''&lt;sub&gt;''n''&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;}}. Applying diagonal scaling operators in the second and subsequent copies of SL(2,'''R'''), the cone ''C'' must contain the quadratic form  {{math|1=(''x''&lt;sub&gt;1&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;}}. By invariance ''C'' must also contain the
quadratic forms {{math|1=(''x''&lt;sub&gt;''i''&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;}} and {{math|1=(''y''&lt;sub&gt;''i''&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;}}. By convexity it contains all diagonal positive symmetric bilinear forms. Since any positive symmetric bilinear form is in the orbit of a diagonal form, ''C'' contains the cone of non-negative symmetric bilinear forms. By duality the dual cone ''C''* is contained in ''P''. If ''C'' is a proper cone, the previous argument shows that ''C''* = ''P'' and hence that ''C'' = ''P''.

This argument shows that every positive definite symmetric form is in the orbit of a form with corresponding quadratic form

:&lt;math&gt;\displaystyle{Q(x,y)=\sum a_i (x_i^2+y_i^2),}&lt;/math&gt;

with ''a''&lt;sub&gt;''i''&lt;/sub&gt; &gt; 0. This corresponds to a cone in the Lie algebra of the (diagonal) [[maximal torus]] of ''U''.

Since every element of ''P'' is diagonalizable, the stabilizer of a positive element in the symplectic group is contained in a conjugate of ''U''. On the other hand, if ''K'' is another compact subgroup of the symplectic group, averaging over Haar measure shows that it leaves invariant a positive element of ''P''. Thus ''K'' is contained in a conjugate of ''U''. It follows that ''U'' is a [[maximal compact subgroup]] of the symplectic group and that any other such subgroup must be a conjugate of ''U''.

==Decomposition in symplectic Olshanski semigroup==
The complex symplectic group acts by Möbius transformations on ''X'', the complex symmetric matrices with operator norm less than or equal to one. Representing an element as a 2 × 2 block matrix
&lt;math&gt;h = \begin{pmatrix} a &amp; b \\ c &amp; d\end{pmatrix}&lt;/math&gt;, the action is given by

:&lt;math&gt;\displaystyle{h(z)=(az+b)(cz+d)^{-1}.}&lt;/math&gt;

There is a period 2 automorphism σ of the complex symplectic group with fixed point subgroup the real symplectic group. Then ''x''&lt;sup&gt;+&lt;/sup&gt; =  σ(x)^{-1} is an antiautomorphism of ''H'' which induces the inverse on the real symplectic group ''G''. If ''g'' is in the open Olshanski semigroup ''H'', let ''h'' = ''g''&lt;sup&gt;+&lt;/sup&gt;''g''. By [[Brouwer's fixed point theorem]] applied to the compact convex set ''X'', ''g'' has a fixed point in ''X''. Since ''g'' carries ''X'' into its interior, the fixed point is an interior point. Since ''G'' acts transitively on the interior of ''X'', post-multiplying by an element of ''G'' if necessary, it can be assumed that ''h'' fixes 0. Since ''h''&lt;sup&gt;+&lt;/sup&gt; = ''h'', it follows that ''b'' = ''c'' = 0. Conjugating by an element in ''K'' ⊂ SU(1,1), ''a'' and ''d'' can be diagonalized. It has positive eigenvalues, so there is a unique positive diagonal operator ''h''&lt;sub&gt;1&lt;/sub&gt; with square ''h''. By uniqueness (''h''&lt;sub&gt;1&lt;/sub&gt;)&lt;sup&gt;+&lt;/sup&gt; =  ''h''&lt;sub&gt;1&lt;/sub&gt;. Since ''h''&lt;sub&gt;1&lt;/sub&gt; is diagonal, the theory for SU(1,1) and SL(2,'''C''') acting on the unit disk in '''C''' shows that ''h''&lt;sub&gt;1&lt;/sub&gt; lies in exp ''C''. On the other hand, ''k'' = ''g'' (''h''&lt;sub&gt;1&lt;/sub&gt;)&lt;sup&gt;−1&lt;/sup&gt; satisfies ''k''&lt;sup&gt;+&lt;/sup&gt;''k'' = 1 so that σ(''k'') = ''k''. Thus ''k'' lies in ''G'' and therefore, using the invariance of ''C'', ''H'' admits the decomposition

:&lt;math&gt;\displaystyle{H=G\cdot \exp(C) =\exp(C)\cdot G.}&lt;/math&gt;

In fact there is a similar decomposition for the closed Olshanski symplectic semigroup:

:&lt;math&gt;\displaystyle{\overline{H}=G\cdot \exp(\overline{C}) =\exp(\overline{C})\cdot G.}&lt;/math&gt;

Moreover, the map (''g'',''x'') ↦ ''g'' exp ''x'' is a homeomorphism.&lt;ref&gt;See:
*{{harvnb|Olshanskii|1981}}
*{{harvnb|Hilgert|Neeb|1993|pp=197–199}}&lt;/ref&gt;

In fact if ''X'' is in ''C'', it is diagonalizable with real eigenvalues. So that exp ''X'' has strictly positive eigenvalues. By continuity if ''X'' is in the closure of ''C'', it has real eigenvalues and exp ''X'' has strictly positive eigenvalues. Any invertible operator that is a limit of 
such exp ''X'' will also have strictly positive eigenvalues. By the [[holomorphic functional calculus]] the exponential map on the space of operators with real spectrum defines a homeomorphism onto the space of operators with strictly positive spectrum, with an analytic inverse given by the logarithm. It follows that 
&lt;math&gt;\exp \overline{C}&lt;/math&gt; is closed in the complex symplectic group.

If ''g''&lt;sub&gt;''n''&lt;/sub&gt; exp ''X''&lt;sub&gt;''n''&lt;/sub&gt; tends to ''h'', then exp 2''X''&lt;sub&gt;''n''&lt;/sub&gt; tends to ''h''&lt;sup&gt;+&lt;/sup&gt;''h''. Since  &lt;math&gt;\exp \overline{C}&lt;/math&gt; is closed,  ''h''&lt;sup&gt;+&lt;/sup&gt;''h'' = exp 2''X'' for some ''X'' and hence ''h'' exp –''X'' lies in ''G''. So the closure of
&lt;math&gt;G \exp \overline{C}&lt;/math&gt; is closed and coincides with &lt;math&gt;\overline{H}&lt;/math&gt;. Similarly if ''g''&lt;sub&gt;''n''&lt;/sub&gt; exp ''X''&lt;sub&gt;''n''&lt;/sub&gt; tends to ''g'' exp ''X'', then exp 2 ''X''&lt;sub&gt;''n''&lt;/sub&gt; tends to exp 2''X''. Hence ''X''&lt;sub&gt;''n''&lt;/sub&gt; tends to ''X''. But then
exp ''X''&lt;sub&gt;''n''&lt;/sub&gt; tends to exp ''X'', so that ''g''&lt;sub&gt;''n''&lt;/sub&gt; tends to ''g''.

The use of the Brouwer fixed-point theorem can be avoided by applying more direct fixed-point theorems for holomorphic mappings, such as the [[Earle–Hamilton fixed point theorem]] and its variants.&lt;ref&gt;{{harvnb|Hervé|1963|pp=83–84}}&lt;/ref&gt; In fact a Möbius transformation ''f'' taking {''z'': ||''z''|| &lt; 1, ''z''&lt;sup&gt;''t''&lt;/sup&gt; = ''z''} into a compact subset has a unique fixed point ''z''&lt;sub&gt;0&lt;/sub&gt; with ''f''&lt;sup&gt;''n''&lt;/sup&gt;(''z'') → ''z''&lt;sub&gt;0&lt;/sub&gt; for any ''z''.

''Uniqueness'' follows because, if ''f'' has a fixed point, after conjugating by an element of the real symplectic group, it can be assumed to be 0. Then ''f'' has the form ''f''(''z'') = ''az''(1 + ''cz'')&lt;sup&gt;−1&lt;/sup&gt;''a''&lt;sup&gt;''t''&lt;/sup&gt;, where ''c''&lt;sup&gt;''t''&lt;/sup&gt; = ''c'', with iterates
''f''&lt;sup&gt;''m''&lt;/sup&gt;(''z'') = ''a''&lt;sup&gt;''m''&lt;/sup&gt;''z''(1 + ''c''&lt;sub&gt;''m''&lt;/sub&gt;''z'')&lt;sup&gt;−1&lt;/sup&gt;(''a''&lt;sup&gt;''m''&lt;/sup&gt;)&lt;sup&gt;''t''&lt;/sup&gt; with ''c''&lt;sub&gt;''m''&lt;/sub&gt; = ''c'' + ''a''&lt;sup&gt;''t''&lt;/sup&gt;''ca'' + ⋅⋅⋅ + (''a''&lt;sup&gt;''m'' − 1&lt;/sup&gt;)&lt;sup&gt;''t''&lt;/sup&gt;''ca''&lt;sup&gt;''m'' − 1&lt;/sup&gt;. Here ''a'' and ''c''&lt;sub&gt;''m''&lt;/sub&gt; all have operator norm less than one. Thus for ||''z''|| ≤ ''r'' &lt; 1, ''f''&lt;sup&gt;''m''&lt;/sup&gt;(''z'') tends to 0 uniformly, so that in particular 0 is the unique fixed point and it is obtained by applying iterates of ''f''.

''Existence'' of a fixed point for ''f'' follows by noting that is an increasing sequence ''n''&lt;sub&gt;''k''&lt;/sub&gt; such that ''f''&lt;sup&gt;''n''&lt;sub&gt;''k''&lt;/sub&gt;&lt;/sup&gt; and ''f''&lt;sup&gt;''n''&lt;sub&gt;2''k'' + 1&lt;/sub&gt; − ''n''&lt;sub&gt;2''k''&lt;/sub&gt;&lt;/sup&gt; are both uniformly convergent on compacta, to ''h'' and ''g'' respectively. This follows because real symplectic transformations ''g''&lt;sub&gt;''n''&lt;/sub&gt; can be chosen so that ''h''&lt;sub&gt;''n''&lt;/sub&gt; = ''g''&lt;sub&gt;''n''&lt;/sub&gt; ∘ ''f''&lt;sup&gt;''n''&lt;/sup&gt; fixes 0, with a subsequence of ''g''&lt;sub&gt;''n''&lt;/sub&gt;'s convergent precisely when the corresponding subsequence of ''f''&lt;sup&gt;''n''&lt;/sup&gt;(0) is convergent. Since the transformations ''h''&lt;sub&gt;''n''&lt;/sub&gt; can be written as ''h''&lt;sub&gt;''n''&lt;/sub&gt;(''z'') = ''a''&lt;sub&gt;''n''&lt;/sub&gt;''z''(1 + ''b''&lt;sub&gt;''n''&lt;/sub&gt;''z'')&lt;sup&gt;−1&lt;/sup&gt; (''a''&lt;sub&gt;''n''&lt;/sub&gt;)&lt;sup&gt;''t''&lt;/sup&gt;, convergent subsequences can be chosen.  By construction ''g'' ∘ ''h'' = ''h''. So points in the image of ''h'' are fixed by ''g''. Now ''g'' and ''h'' are either constant or have the form ''az''(1 + ''cz'')&lt;sup&gt;−1&lt;/sup&gt;''a''&lt;sup&gt;''t''&lt;/sup&gt; followed by a real symplectic transformation. Since the image of ''h'' is connected and a non-constant map has just one fixed point, the image of ''h'' is a single point ''z''&lt;sub&gt;0&lt;/sub&gt;, fixed by ''g''. Since ''g'' commutes with ''f'',  ''f''(''z''&lt;sub&gt;0&lt;/sub&gt;) is also fixed by ''g'' and hence ''f''(''z''&lt;sub&gt;0&lt;/sub&gt;)= ''z''&lt;sub&gt;0&lt;/sub&gt;, so that ''z''&lt;sub&gt;0&lt;/sub&gt; is a fixed point of ''f''.&lt;ref&gt;{{harvnb|Hervé|1963|pp=83–84}}&lt;/ref&gt;

==Maximality of symplectic Olshanski semigroup==
The symplectic group acts transitively by Möbius transformations on the complex symmetric matrices with operator norm less than one. The open Olshanski semigroup consists of Möbius transformations in the complex symplectic group which take the space complex symmetric matrices of norm ≤ 1 into complex symmetric matrices of norm &lt; 1. Its closure is a maximal proper semigroup in the complex symplectic group.

In two dimensions this follows from [[oscillator representation#Semigroups in SL(2,C)|a general argument]] of {{harvtxt|Lawson|1998}} which also applies in one dimension. Let ''G'' = SL(2,'''R''') act by Möbius transformations on the extended real line and let ''H'' be the open semigroup consisting of transformations carrying [–1,1] into (–1,1). Its closure &lt;math&gt;\overline{H}&lt;/math&gt; is the closed semigroup of transformations carrying [–1,1] into itself. Maximality of &lt;math&gt;\overline{H}&lt;/math&gt; is proved by first showing that any strictly larger semigroup ''S'' contains an element ''g'' sending |''t''| &lt; 1 onto |''t''| &gt; 1. In fact if ''x'' is in ''S'' but not in &lt;math&gt;\overline{H}&lt;/math&gt;, then there is an interval ''I''&lt;sub&gt;1&lt;/sub&gt; in ''I'' = (–1,1) such that ''x'' ''I''&lt;sub&gt;1&lt;/sub&gt; lies in [–1,1]&lt;sup&gt;''c''&lt;/sup&gt;. Then for some ''h'' in ''H'', ''I''&lt;sub&gt;1&lt;/sub&gt; = ''hI''. Similarly ''yxI''&lt;sub&gt;1&lt;/sub&gt; = [–1,1]&lt;sup&gt;''c''&lt;/sup&gt; for some ''y'' in ''H''. So ''g'' = ''yxh'' lies in ''S'' and sends ''I'' onto  [–1,1]&lt;sup&gt;''c''&lt;/sup&gt;. It follows that ''g''&lt;sup&gt;2&lt;/sup&gt; fixes ''I'', so that ''g''&lt;sup&gt;−1&lt;/sup&gt; lies in ''S''. If ''z'' lies in ''H'' then ''z'' ''g'' ''I'' contains ''g'' ''I''. Hence ''g''&lt;sup&gt;−1&lt;/sup&gt;''z''&lt;sup&gt;−1&lt;/sup&gt; ''g'' lies in &lt;math&gt;\overline{H}&lt;/math&gt;. So ''z''&lt;sup&gt;−1&lt;/sup&gt; lies in ''S'' and therefore ''S'' contains an open neighbourhood of ''1''.  Hence ''S'' = SL(2,'''R''').&lt;ref&gt;See:
*{{harvnb|Lawson|1998}}
*{{harvnb|Hilgert|Neeb|1993|pp=48–56}}
&lt;/ref&gt;

Maximality can be deduced for the Olshanski symplectic semigroup in SL(2,'''C''') from the maximality of this semigroup in SL(2,'''R'''). It suffices to show that the closed semigroup contains SL(2,'''R'''), because the scaling transformations lie in the interior of the Olshanski symplectic semigroup. So if their inverses lie in the symplectic semigroup, it contains a neighbourhood of the identity and hence the whole of SL(2,'''C'''). If ''S'' is a semigroup properly containing the symplectic semigroup, it contains an element carrying the closed unit disk outside itself. Pre- and post-composing with elements of SU(1,1), it can be assumed that the element ''g'' of ''S'' carries 0 into ''r'' &gt; 1. Precomposing with a scaling transformation, it can be assumed that ''g'' carries the closed unit disk onto a small neighbourhood of ''r''. Pre-composing with an element of SU(1,1), the inverse image of the real axis can be taken to be the diameter joining –1 and 1. But in that case, ''g'' must lie in SL(2,'''R'''). From the maximality result for semigroups in SL(2,'''R'''), ''S'' must contain SL(2,'''R''') and hence must be the whole of SL(2,'''C''').&lt;ref&gt;See:
*{{harvnb|Lawson|1998}}
*{{harvnb|Hilgert|Neeb|1993|pp=48–56}}
&lt;/ref&gt;

[[Autonne–Takagi factorization]] states that for any complex symmetric matrix ''M'', there is a unitary matrix ''U'' such that ''UMU''&lt;sup&gt;''t''&lt;/sup&gt; is diagonal.&lt;ref&gt;See for example {{harvnb|Siegel|1932|pp=12, 14–15}}&lt;/ref&gt; If''S'' is a semigroup properly containing the closure of the Olshanki semigroup, then it contains an element ''g'' such that ''z'' = ''g''(0) with 1&lt; ||''z''|| &lt; ∞.

Indeed, there is an embedding due to [[Harish-Chandra]] of the space of complex symmetric ''n'' by ''n'' matrices as a dense open subset of the compact Grassmannian of Langrangian subspaces of '''C'''&lt;sup&gt;2''n''&lt;/sup&gt;. Morevoer this embedding is equivariant for the action of the real symplectic group.&lt;ref&gt;{{harvnb|Mok|1989|pp=65–71}}&lt;/ref&gt; In fact, with the standard complex inner product on '''C'''&lt;sup&gt;2''n''&lt;/sup&gt;, the Grassmannian of ''n''-dimensional subspaces has a continuous transitive action of SL(2''n'','''C''') and its maximal compact subpgroup SU(2''n''). It can be identified with the space of orthogonal rank ''n'' projections, a compact subspace of M&lt;sub&gt;2''n''&lt;/sub&gt;('''C''').
Taking coordinates (''z''&lt;sub&gt;1&lt;/sub&gt;,...,''z''&lt;sub&gt;''n''&lt;/sub&gt;,''w''&lt;sub&gt;1&lt;/sub&gt;,...,''w''&lt;sub&gt;''n''&lt;/sub&gt;) on '''C'''&lt;sup&gt;2''n''&lt;/sup&gt;, the symplectic form is given by

:&lt;math&gt;\displaystyle{B((z,w),(z^\prime,w^\prime))=\sum z_iw_i^\prime - w_iz_i^\prime.}&lt;/math&gt;

An ''n''-dimensional subspace ''U'' is called Lagrangian if ''B'' vanishes on ''U''. The Lagrangian subpaces form a closed subset of the Grassmannian on which the complex symplectic group and the unitary symplectic group act transitively. This is the Lagrangian Grassmannian. The subspace ''U''&lt;sub&gt;0&lt;/sub&gt; formed of vectors with ''z''&lt;sub&gt;''i''&lt;/sub&gt; = 0 is Lagrangian. The set of Langrangian subspaces ''U'' for which the restriction of the orthogonal projection onto ''U''&lt;sub&gt;0&lt;/sub&gt; is an isomorphism forms an open dense subset Ω of the Lagrangian Grassmannian. Any such subspace has a canonical basis whose column vectors form a 2''n'' by ''n'' matrix &lt;math&gt;\begin{pmatrix} Z\\ I\end{pmatrix}&lt;/math&gt; where ''Z'' is a complex symmetric ''n'' by ''n'' matrix and ''I'' is the ''n'' by ''n'' identity matrix. Under this correspondence elements of the complex symplectic group, viewed as block matrices 
&lt;math&gt;g = \begin{pmatrix} A &amp; B \\ C &amp; D\end{pmatrix}&lt;/math&gt; act as Möbius transformations,
''g''(''Z'') = (''AZ'' + ''B'')(''CZ'' + ''D'')&lt;sup&gt;−1&lt;/sup&gt;. The unit ball for the operator norm and its closure are left invariant under the corresponding real form of the symplectic group.

If an element ''g'' of the complex symplectic group does not lie in the closure of Olshanski semigroup, it must carry some point ''W'' of the open unit ball into the complement of its closure. If ''g''(''W'') does not lie in Ω then the image of a small ball about ''W'' must contain points with in Ω 
with arbitrarily large operator norm. Precomposing ''g'' with a suitable element in ''G'', it follows that ''Z'' = ''g''(0) will have operator norm greater than 1. If ''g''(''W'') already lies in  Ω, it will also have operator norm greater than 1 and ''W'' can be then be taken to be 0 by precomposing with a suitable element of ''G''.

Pre-composing ''g'' with a scaling transformation and post-composing ''g'' with a unitary transformation, it can be assumed that ''g''(0) is a diagonal matrix with entries λ&lt;sub&gt;''i''&lt;/sub&gt; ≥ 0  with ''r'' = λ&lt;sub&gt;1&lt;/sub&gt; &gt; 0 and that the image of the unit ball is contained in a small ball around this point. The entries λ&lt;sub&gt;''i''&lt;/sub&gt; with ''i'' ≥ 2 can be separately scaled byelements of the Olshanki semigroup so that λ&lt;sub&gt;''i''&lt;/sub&gt; &lt; 1; and then they can be sent to 0 by elements of ''G'' lying in commuting copies of SU(1,1). So ''g''(0) is a diagonal matrix with entries ''r'', 0,...,0, where ''r'' &gt; 1.

==See also==
*[[Oscillator representation]]
*[[Symmetric cone]]

==Notes==
{{reflist|2}}

==References==
*{{citation|first=G. B.|last=Folland|title=Harmonic analysis in phase space|series=Annals of Mathematics Studies|volume=122|year=1989|publisher=Princeton University Press|isbn=9780691085289}}
*{{citation|last=Hervé|first=M.|title=
Several complex variables. Local theory|publisher=Tata Institute of Fundamental Research|year=1963}}
*{{citation|last=Hilgert|first= Joachim|last2= Hofmann|first2= Karl Heinrich|last3= Lawson|first3= Jimmie D. |title=Lie groups, convex cones, and semigroups|series= Oxford Mathematical Monographs|publisher=Oxford University Press|year= 1989|isbn= 0-19-853569-4}}
*{{citation|last=Hilgert|first= Joachim|last2= Neeb|first2=Karl-Hermann|title=
Lie semigroups and their applications|series=Lecture Notes in Mathematics|volume= 1552|publisher= Springer-Verlag|year= 1993|isbn= 3540569545}}
*{{citation|first=R.|last=Howe|year=1988|title=The Oscillator Semigroup|publisher=American Mathematical Society|journal=Proceedings of Symposia in Pure Mathematics |volume=48 |pages=61–132|doi=10.1090/pspum/048/974332}}
*{{citation|last=Kumaresan|first= S.|last2= Ranjan|first2= A.|title=
On invariant convex cones in simple Lie algebras|journal=Proc. Indian Acad. Sci. Math. Sci.|volume= 91| year=1982|pages= 167–182|doi=10.1007/bf02881028}}
*{{citation|journal=Journal of Lie Theory|volume=4|year=1994|title=Maximal Olshanski semigroups|first=
J. D.|last= Lawson|pages=17–29}}
*{{citation|last=Lawson|first=J. D.|title=Semigroups in Möbius and Lorentzian geometry|journal=Geom. Dedicata|volume= 70|year= 1998|pages=139–180}}
* {{citation|first=Ngaiming|last= Mok|title=Metric Rigidity Theorems on Hermitian Locally Symmetric Manifolds|publisher= World Scientific|year=1989|isbn=9971-5-0802-8}}
*{{citation|last= Olshanskii|first= G. I. |title=Invariant cones in Lie algebras, Lie semigroups and the holomorphic discrete series|journal=Funct. Anal. Appl.|volume= 15 |year=1981|pages= 275–285|doi=10.1007/bf01106156}}
*{{citation|last= Paneitz|first= Stephen M.|title= Invariant convex cones and causality in semisimple Lie algebras and groups|journal= J. Funct. Anal.|volume= 43|year=1981|pages= 313–359}}
*{{citation|last=Paneitz|first= Stephen M.|title= Determination of invariant convex cones in simple Lie algebras|journal= Ark. Mat.|volume= 21|year=1983|pages= 217–228|doi=10.1007/bf02384311}}
*{{citation|title=Symplectic Geometry|first=Carl Ludwig|last= Siegel|journal= American Journal of Mathematics|volume= 65|year=1943|pages=1–86|jstor= 2371774|doi=10.2307/2371774}}
*{{citation|last=Vinberg|first= E. B.|title=Invariant convex cones and orderings in Lie groups|journal=
Funct. Anal. Appl.|volume= 14 |year=1980|pages= 1–10}} 
*{{citation|last=Wolf|first= Joseph A.|chapter=Fine structure of Hermitian symmetric spaces|title= Symmetric spaces (Short Courses, Washington University)|pages= 271–357|publisher= Dekker|year= 1972|editor1-first=William|editor1-last=Boothby|editor2-first=Guido|editor2-last=Weiss|series=Pure and Applied Mathematics|volume=8}}

[[Category:Lie algebras]]
[[Category:Lie groups]]
[[Category:Representation theory]]
[[Category:Semigroup theory]]</text>
      <sha1>7la322uo9l8tgpxjnq7808i044lm17a</sha1>
    </revision>
  </page>
  <page>
    <title>Karen Parshall</title>
    <ns>0</ns>
    <id>36594635</id>
    <revision>
      <id>868306889</id>
      <parentid>859332274</parentid>
      <timestamp>2018-11-11T10:26:08Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */recategorize</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9779">'''Karen Hunger Parshall''' (born 1955, [[Virginia]]; ''née'' Karen Virginia Hunger) is an American [[historian of mathematics]].

==Education and career==
Parshall studied Romance languages, such as French, and mathematics at the [[University of Virginia]], where she earned her master's degree in  mathematics in 1978. She earned her PhD in 1982 in the history of mathematics from the [[University of Chicago]] under the direction of the historian [[Allen G. Debus]] (1926–2009) and the mathematician [[Israel Herstein]]. The subject of her dissertation is the history of the  [[Abstract algebra|theory of algebras]], especially the work of [[Joseph Wedderburn]] (''The contributions of J. H. M. Wedderburn to the theory of algebras, 1900–1910'').

From 1982 to 1987 Parshall was an assistant professor at [[Sweet Briar College]] and in 1987/88 at the [[University of Illinois at Urbana-Champaign]]. Since 1988 she has taught the history of mathematics, and also mathematics and the history of science, at the [[University of Virginia]], where she became in 1988 an assistant professor, in 1993 an associate professor and in 1999 a professor. She was a visiting professor at the [[Australian National University]] in [[Canberra]], at the [[School for Advanced Studies in the Social Sciences|École des Hautes Etudes en Sciences Sociales]] (1985 and 2010) and at the [[Pierre and Marie Curie University]] in Paris (2016).

==Work==
Parshall's academic specialty is the development of mathematics in the USA in the late 19th century and early 20th century (particularly the Chicago School).&lt;ref&gt;Karen Parshall: ''The One-Hundredth Anniversary of Mathematics at the University of Chicago,'' The Mathematical Intelligencer 14, 1992, pp. 39–44&lt;/ref&gt; As one example, she has studied the work of [[Leonard Dickson]],&lt;ref&gt;Karen Parshall: ''A Study in Group Theory: Leonard Eugene Dickson's Linear Groups,'' The Mathematical Intelligencer 13, 1991, pp. 7–11&lt;/ref&gt; who was greatly influenced by contact with German mathematicians such as [[Felix Klein]] at the time of the [[World's Columbian Exposition|Columbian Exposition of 1893]].&lt;ref&gt;Karen Parshall, David E. Rowe: ''Embedded in the Culture: Mathematics at the World’s Columbian Exposition'', The Mathematical Intelligencer 15, 1993, pp. 40–45&lt;/ref&gt; She has also focused on the history of algebra. She edited the correspondence of [[James Joseph Sylvester]] published by Oxford University Press and wrote a biography of Sylvester.

==Recognition==
In the academic year 1996/97 Parshall was a Guggenheim Fellow. In 1994 she was an [[list of International Congresses of Mathematicians Plenary and Invited Speakers|invited speaker at the International Congress of Mathematicians]] (ICM) in [[Zürich]] (''Mathematics in National Contexts (1875–1900): An International Overview''). Since 2002 she has been a  corresponding member of the [[International Academy of the History of Science|Académie internationale d’histoire des sciences]] in Paris. From 1996 to 1999, she was editor of the journal ''[[Historia Mathematica]]''. Parshall was in the governing body of the [[History of Science Society]] and from 1998 to 2001 of the [[American Mathematical Society]] (AMS).

In 2012, she became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-05-05.&lt;/ref&gt;
She is the 2018 winner of the [[Albert Leon Whiteman Memorial Prize]] of the [[American Mathematical Society]] "for her outstanding work in the history of mathematics, and in particular, for her work on the evolution of mathematics in the USA and on the history of algebra, as well as for her substantial contribution to the international life of her discipline through students, editorial work, and conferences."&lt;ref&gt;[http://www.ams.org/news?news_id=3849 Karen Hunger Parshall to Receive 2018 Whiteman Prize], American Mathematical Society, retrieved 2017-12-05.&lt;/ref&gt;

==Works==
* ''Eliakim Hastings Moore and the Founding of a Mathematical Community in America, 1892–1902,'' Annals of Science 41, 1984, pp.&amp;nbsp;313–333; also reprinted in Peter Duren (ed.): ''A Century of Mathematics in America. Part II'', AMS History of Mathematics 2, Providence 1989, pp.&amp;nbsp;155–175 ([http://www.ams.org/online_bks/hmath2/ by AMS Books Online]: Part entitled ''Chicago'')
* ''Joseph H. M. Wedderburn and the Structure Theory of Algebras'',  Archive for History of Exact Sciences 32, 1985, pp.&amp;nbsp;223–349
* ''The Art of Algebra from al-Khwarizmi to Viète: a Study in the Natural Selection of Ideas'', History of Science 26, 1988, pp.&amp;nbsp;129–164
* ''Toward a History of Nineteenth-Century Invariant Theory'', in David E. Rowe, John McCleary (eds.): ''The History of Modern Mathematics'' Vol. 1, Academic Press, Boston 1989, pp.&amp;nbsp;157–206&lt;ref&gt;also treated in Karen Parshall: ''The One-Hundredth Anniversary of the Death of Invariant Theory?'', The Mathematical Intelligencer 12, 1990, pp. 10–16&lt;/ref&gt;
* with [[David E. Rowe]]: ''American Mathematics Comes of Age: 1875–1900'', in Peter Duren (ed.): ''A Century of Mathematics in America. Part III'', AMS History of Mathematics 3, 1989, pp.&amp;nbsp;3–28 ([http://www.ams.org/online_bks/hmath3/ bei AMS Books Online]: Part entitled ''The Nineteenth Century''; [https://books.google.com/books?id=cy6juceOQ54C&amp;pg=PA3 from Google Books])
* with David E. Rowe: ''The Emergence of the American Mathematical Research Community 1876–1900: [[James Joseph Sylvester|J. J. Sylvester]], [[Felix Klein]], and [[E. H. Moore]]'', AMS/LMS History of Mathematics 8, Providence/London 1994&lt;ref&gt;{{cite journal|author=Reid, Constance|authorlink=Constance Reid|title=Review of ''The Emergence of the American Mathematical Research Community 1876–1900: J. J. Sylvester, Felix Klein, and E. H. Moore'' by Karen Hunger Parshall and David E. Rowe|journal=Bull. Amer. Math. Soc. (N.S.)|year=1995|volume=32|issue=3|pages=349–351|url=http://www.ams.org/journals/bull/1995-32-03/S0273-0979-1995-00595-1/S0273-0979-1995-00595-1.pdf|doi=10.1090/s0273-0979-1995-00595-1}}&lt;/ref&gt;
* ''James Joseph Sylvester: Life and Work in Letters'', Oxford University Press, 1998&lt;ref&gt;{{cite journal|author=Merzbach, Uta C.|authorlink= Uta Merzbach |title=Review: ''James Joseph Sylvester: Life and work in letters'', by Karen Hunger Parshall|journal=Bull. Amer. Math. Soc. (N.S.)|year=2001|volume=38|issue=1|pages=79–82|url=http://www.ams.org/journals/bull/2001-38-01/S0273-0979-00-00882-X/S0273-0979-00-00882-X.pdf|doi=10.1090/s0273-0979-00-00882-x}}&lt;/ref&gt;
* with Adrian C. Rice (eds.): ''Mathematics Unbound: The Evolution of an International Mathematical Research Community, 1800–1945'', AMS/LMS History of Mathematics 23, 2002&lt;ref&gt;{{cite journal|author=Rowe, David E.|title=Review: ''Mathematics unbound: The evolution of an international mathematical research community, 1800–1945'', by Karen Hunger Parshall and Adrian C. Rice (eds.)|journal=Bull. Amer. Math. Soc. (N.S.)|year=2003|volume=40|issue=4|pages=535–542|url=http://www.ams.org/journals/bull/2003-40-04/S0273-0979-03-00990-X/S0273-0979-03-00990-X.pdf|doi=10.1090/s0273-0979-03-00990-x}}&lt;/ref&gt;
* with [[Jeremy Gray|Jeremy J. Gray]] (eds.): ''Episodes in the History of Modern Algebra (1800–1950)'', AMS/LMS History of Mathematics 32, Providence/London 2007 (Conference at [[MSRI]] 2002)
*2000: [http://www.ams.org/journals/bull/2000-37-04/S0273-0979-00-00873-9/home.html Perspectives on American Mathematics], [[Bulletin of the American Mathematical Society]] 37: 381–405.
*2006: ''James Joseph Sylvester: Jewish Mathematician in a Victorian World'', [[Johns Hopkins University Press]], {{ISBN|0-8018-8291-5}}&lt;ref&gt;{{cite journal|author=Grabiner, Judith|authorlink=Judith Grabiner|title=Review: ''James Joseph Sylvester: Jewish mathematician in a Victorian World'', by Karen Hunger Parshall|journal=Bull. Amer. Math. Soc. (N.S.)|year=2007|volume=44|issue=3|pages=481–485|url=http://www.ams.org/journals/bull/2007-44-03/S0273-0979-07-01145-7/S0273-0979-07-01145-7.pdf|doi=10.1090/s0273-0979-07-01145-7}}&lt;/ref&gt;
*2014: with [[Victor J. Katz]]: ''Taming the Unknown: History of algebra from antiquity to the early twentieth century'', [[Princeton University Press]] {{ISBN|9780691149059}}.

==Sources==
* Florence Fasanelli: ''[https://books.google.com/books?id=u7nqH3RzUusC&amp;pg=PA157 Karen Parshall]''. In: Charlene Morrow, Teri Perl (eds.): ''Notable women in mathematics. A biographical Dictionary''. Greenwood Publishing Group, Westport CT, 1998, {{ISBN|0-313-29131-4}}, pp.&amp;nbsp;157–160.

==References==
{{reflist}}

==External links==
* [http://www.math.virginia.edu/~khp3k/ Karen Parshall. Professor of History and Mathematics] – Homepage at the University of Virginia
* [http://www.beingamathematician.org/Sylvester/index.html Karen Parshall talks about J. J. Sylvester. (website of Being a Professional Mathematician)]
* [https://web.archive.org/web/20121016000307/http://www.princeton.edu/~mudd/finding_aids/mathoral/pmc08.htm The Princetion Mathematics Community in the 1930s (PMC08).] An interview with William L. Duren, [[Nathan Jacobson]], and [[Edward J. McShane]] by Karen Parshall on 10 April 1984 at the U. of Virginia
* {{MathGenealogy|id=16348}}

{{Authority control}}

{{DEFAULTSORT:Parshall, Karen}}
[[Category:Historians of mathematics]]
[[Category:University of Virginia alumni]]
[[Category:University of Virginia faculty]]
[[Category:University of Chicago alumni]]
[[Category:1955 births]]
[[Category:Living people]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Guggenheim Fellows]]
[[Category:21st-century American historians]]
[[Category:American women historians]]
[[Category:Women mathematicians]]</text>
      <sha1>dghb5b3phvdh78cws31j9d692k4qlm5</sha1>
    </revision>
  </page>
  <page>
    <title>Kernel-independent component analysis</title>
    <ns>0</ns>
    <id>48312994</id>
    <revision>
      <id>731905373</id>
      <parentid>731905273</parentid>
      <timestamp>2016-07-28T08:06:16Z</timestamp>
      <contributor>
        <username>Poyupaulchen</username>
        <id>28848457</id>
      </contributor>
      <comment>/* Main idea */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3560">In statistics, '''kernel-independent component analysis (kernel ICA)''' is an efficient algorithm for [[independent component analysis]] which estimates source components by optimizing a ''generalized variance'' contrast function, which is based on representations in a [[reproducing kernel Hilbert space]].&lt;ref name = "Bach Jordan JMLR 2003"&gt;{{Cite journal | last1 = Bach | first1 = Francis R. | last2 = Jordan | first2 = Michael I. | doi = 10.1162/153244303768966085 | title = Kernel independent component analysis | journal = The Journal of Machine Learning Research | volume = 3 | pages = 1–48 | year = 2003 | url = http://www.di.ens.fr/~fbach/kernelICA-jmlr.pdf}}&lt;/ref&gt;&lt;ref name = "Bach Jordan ICASSP 2003"&gt;{{Cite journal | last1 = Bach | first1 = Francis R. | last2 = Jordan | first2 = Michael I. | doi = 10.1109/icassp.2003.1202783 | title = Kernel independent component analysis | journal = IEEE International Conference on Acoustics, Speech, and Signal Processing  | year = 2003 | url = http://www.di.ens.fr/~fbach/kernelICA-icassp03.pdf}}&lt;/ref&gt; Those contrast functions use the notion of mutual information as a [[Independent component analysis#Defining component independence|measure]] of [[Independence (probability theory)|statistical independence]].

==Main idea==
Kernel ICA is based on the idea that correlations between two random variables  can be represented in a [[reproducing kernel Hilbert space|reproducing kernel Hilbert space (RKHS)]], denoted by &lt;math&gt;\mathcal{F}&lt;/math&gt;, associated with a feature map &lt;math&gt;L_x: \mathcal{F} \mapsto \mathbb{R} &lt;/math&gt; defined for a fixed &lt;math&gt;x \in \mathbb{R}&lt;/math&gt;. The &lt;math&gt;\mathcal{F}&lt;/math&gt;-correlation  between two random variables &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; is defined as

: &lt;math&gt; \rho_{\mathcal{F}}(X,Y) = \max_{f, g \in \mathcal{F}} \operatorname{corr}( \langle L_X,f \rangle, \langle L_Y,g \rangle) &lt;/math&gt;

where the functions &lt;math&gt;f,g: \mathbb{R} \to \mathbb{R}&lt;/math&gt; range over &lt;math&gt;\mathcal{F}&lt;/math&gt; and

: &lt;math&gt; \operatorname{corr}( \langle L_X,f \rangle, \langle L_Y,g \rangle) :=  \frac{\operatorname{cov}(f(X), g(Y)) }{\operatorname{var}(f(X))^{1/2} \operatorname{var}(g(Y))^{1/2} } &lt;/math&gt;

for fixed &lt;math&gt;f,g \in \mathcal{F}&lt;/math&gt;.&lt;ref name = "Bach Jordan JMLR 2003" /&gt; Note that the reproducing property implies that &lt;math&gt;f(x) = \langle L_x, f \rangle &lt;/math&gt; for fixed &lt;math&gt;x \in \mathbb{R}&lt;/math&gt; and &lt;math&gt;f \in \mathcal{F}&lt;/math&gt;.&lt;ref name = "Saitoh"&gt;{{cite book |last=Saitoh |first=Saburou | title=Theory of Reproducing Kernels and Its Applications |publisher=Longman |year=1988|isbn = 0582035643}}&lt;/ref&gt; It follows then that the &lt;math&gt;\mathcal{F}&lt;/math&gt;-correlation between two  [[Independence (probability theory)|independent random variables]] is zero.

This notion of &lt;math&gt;\mathcal{F}&lt;/math&gt;-correlations is used for defining ''contrast'' functions that are optimized in the Kernel ICA algorithm. Specifically, if &lt;math&gt;\mathbf{X} := (x_{ij}) \in \mathbb{R}^{n \times m}&lt;/math&gt; is a [[Whitening transformation#Whitening a data matrix|prewhitened data matrix]], that is, the sample mean of each column is zero and the sample covariance of the rows is the &lt;math&gt;m \times m&lt;/math&gt; dimensional identity matrix, Kernel ICA estimates a &lt;math&gt;m \times m&lt;/math&gt; dimensional orthogonal matrix &lt;math&gt;\mathbf{A}&lt;/math&gt; so as to minimize finite-sample &lt;math&gt;\mathcal{F}&lt;/math&gt;-correlations between the columns of &lt;math&gt;\mathbf{S} := \mathbf{X} \mathbf{A}^{\prime}&lt;/math&gt;.

==References==
{{Reflist}}


{{Statistics-stub}}



[[Category:Statistical algorithms]]</text>
      <sha1>i8gnf69nm3nqs0c7filodvrohidgjj4</sha1>
    </revision>
  </page>
  <page>
    <title>Kissing number problem</title>
    <ns>0</ns>
    <id>408555</id>
    <revision>
      <id>868857329</id>
      <parentid>868244191</parentid>
      <timestamp>2018-11-14T22:09:44Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16059">In [[geometry]], a '''kissing number''' is defined as the number of non-overlapping unit [[sphere]]s that can be arranged such that they each touch a common unit sphere. For a [[Lattice (group)|lattice]] packing the kissing number is the same for every sphere, but for an arbitrary [[sphere packing]] the kissing number may vary from one sphere to another. Other names for kissing number that have been used are '''Newton number''' (after the originator of the problem), and '''contact number'''.

In general, the '''kissing number problem''' seeks the maximum possible kissing number for [[n-sphere|''n''-dimensional spheres]] in (''n'' + 1)-dimensional [[Euclidean space]]. Ordinary spheres correspond to two-dimensional closed surfaces in three-dimensional space.

Finding the kissing number when centers of spheres are confined to a line (the one-dimensional case) or a plane (two-dimensional case) is trivial. Proving a solution to the three-dimensional case, despite being easy to conceptualise and model in the physical world, eluded mathematicians until the mid-20th century.&lt;ref name=Conway/&gt;&lt;ref name=Brass/&gt; Solutions in higher dimensions are considerably more challenging, and only a handful of cases have been solved exactly. For others investigations have determined upper and lower bounds, but not exact solutions.&lt;ref name=Mittlemann/&gt;

==Known greatest kissing numbers==

In one dimension, the kissing number is 2:

:[[Image:Kissing-1d.svg]]

In two dimensions, the kissing number is 6:

:[[Image:Kissing-2d.svg]]

'''Proof''': Consider a circle with center ''C'' that is touched by circles with centers ''C''&lt;sub&gt;1&lt;/sub&gt;, ''C''&lt;sub&gt;2&lt;/sub&gt;, .... Consider the rays ''C'' ''C''&lt;sub&gt;''i''&lt;/sub&gt;. These rays all emanate from the same center ''C'', so the sum of angles between adjacent rays is 360°.

Assume by contradiction that there are more than six touching circles. Then at least two adjacent rays, say ''C'' ''C''&lt;sub&gt;1&lt;/sub&gt; and ''C'' ''C''&lt;sub&gt;2&lt;/sub&gt;, are separated by an angle of less than 60°. The segments ''C C&lt;sub&gt;i&lt;/sub&gt;'' have the same length – 2''r'' – for all ''i''. Therefore, the triangle ''C'' ''C''&lt;sub&gt;1&lt;/sub&gt; ''C''&lt;sub&gt;2&lt;/sub&gt; is isosceles, and its third side – ''C''&lt;sub&gt;1&lt;/sub&gt; ''C''&lt;sub&gt;2&lt;/sub&gt; – has a side length of less than 2''r''. Therefore, the circles 1 and 2 intersect – a contradiction.&lt;ref&gt;See also Lemma 3.1 in {{Cite journal | last1 = Marathe | first1 = M. V. | last2 = Breu | first2 = H. | last3 = Hunt | first3 = H. B. | last4 = Ravi | first4 = S. S. | last5 = Rosenkrantz | first5 = D. J. | title = Simple heuristics for unit disk graphs | doi = 10.1002/net.3230250205 | journal = Networks | volume = 25 | issue = 2 | pages = 59 | year = 1995 | pmid =  | pmc = | arxiv = math/9409226 }}&lt;/ref&gt;

[[Image:Kissing-3d.png|thumb|right|250px|A highly symmetrical realization of the kissing number 12 in three dimensions is by aligning the centers of outer spheres with vertices of a [[regular icosahedron]]. This leaves slightly more than 0.1 of the radius between two nearby spheres.]]

In three dimensions, the kissing number is 12, but the correct value was much more difficult to establish than in dimensions one and two. It is easy to arrange 12 spheres so that each touches a central sphere, but there is a lot of space left over, and it is not obvious that there is no way to pack in a 13th sphere. (In fact, there is so much extra space that any two of the 12 outer spheres can exchange places through a continuous movement without any of the outer spheres losing contact with the center one.) This was the subject of a famous disagreement between mathematicians [[Isaac Newton]] and [[David Gregory (mathematician)|David Gregory]]. Newton correctly thought that the limit was 12; Gregory thought that a 13th could fit. Some incomplete proofs that Newton was correct were offered in the nineteenth century, most notably one by [[Reinhold Hoppe]], but the first correct proof (according to Brass, Moser, and Pach) did not appear until 1953.&lt;ref name=Conway&gt;{{cite book |first=John H. |last=Conway |authorlink=John Horton Conway |author2=Neil J.A. Sloane |authorlink2=Neil Sloane  |year=1999 |title=Sphere Packings, Lattices and Groups |edition=3rd |publisher=Springer-Verlag |location=New York |isbn=0-387-98585-9|page=[https://books.google.com/books?id=upYwZ6cQumoC&amp;pg=PA21 21]}}&lt;/ref&gt;&lt;ref  name=Brass&gt;{{cite book |first1=Peter |last1=Brass |first2=W. O. J. |last2=Moser |first3=János |last3=Pach |authorlink3=János Pach |title=Research problems in discrete geometry |publisher=Springer |year=2005 |isbn=978-0-387-23815-9 |page=[https://books.google.com/books?hl=en&amp;id=cT7TB20y3A8C&amp;pg=PA93 93]}}&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Zong | first = Chuanming
 | editor1-last = Goodman | editor1-first = Jacob E.
 | editor2-last = Pach | editor2-first = J├ínos
 | editor3-last = Pollack | editor3-first = Richard
 | contribution = The kissing number, blocking number and covering number of a convex body
 | doi = 10.1090/conm/453/08812
 | location = Providence, RI
 | mr = 2405694
 | pages = 529–548
 | publisher = American Mathematical Society
 | series = Contemporary Mathematics
 | title = Surveys on Discrete and Computational Geometry: Twenty Years Later (AMS-IMS-SIAM Joint Summer Research Conference, June 18ÔÇô22, 2006, Snowbird, Utah)
 | volume = 453
 | year = 2008| isbn = 9780821842393
 }}.&lt;/ref&gt;

The twelve neighbors of the central sphere correspond to the maximum bulk [[coordination number]] of an atom in a [[crystal lattice]] in which all atoms have the same size (as in a chemical element). A coordination number of 12 is found in a [[cubic close-packed]] or a [[hexagonal close-packed]] structure.

In four dimensions, it was known for some time that the answer was either 24 or 25. It is easy to produce a packing of 24 spheres around a central sphere (one can place the spheres at the vertices of a suitably scaled [[24-cell]] centered at the origin). As in the three-dimensional case, there is a lot of space left over—even more, in fact, than for ''n'' = 3—so the situation was even less clear. In 2003, Oleg Musin proved the kissing number for ''n'' = 4 to be 24, using a subtle trick.&lt;ref name="Musin"&gt;{{cite journal |author=O. R. Musin |title=The problem of the twenty-five spheres |year=2003 |journal=Russ. Math. Surv. |volume=58 |pages=794–795 |doi=10.1070/RM2003v058n04ABEH000651 |issue=4|bibcode=2003RuMaS..58..794M }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Pfender|first1=Florian|last2=Ziegler|first2=Günter M.|authorlink2=Günter M. Ziegler|title=Kissing numbers, sphere packings, and some unexpected proofs|journal=Notices of the American Mathematical Society|date=September 2004|pages=873–883|url=http://www.ams.org/notices/200408/fea-pfender.pdf|postscript=&lt;!--None--&gt;}}.&lt;/ref&gt;

The kissing number in ''n'' [[dimension]]s is unknown for ''n'' &gt; 4, except for  ''n'' = 8 (240), and  ''n'' = 24 (196,560).&lt;ref&gt;{{cite journal| last=Levenshtein | first=Vladimir I. | authorlink=Vladimir Levenshtein | year=1979 | title=О границах для упаковок в n-мерном евклидовом пространстве |trans-title=On bounds for packings in ''n''-dimensional Euclidean space | journal=[[Doklady Akademii Nauk SSSR]] | volume=245 | issue=6 | language=Russian | pages=1299–1303}}&lt;/ref&gt;&lt;ref&gt;
[[Andrew Odlyzko|Odlyzko, A. M.]], [[N.J.A. Sloane|Sloane, N. J. A.]] ''New bounds on the number of unit spheres that can touch a unit sphere in n dimensions.'' J. Combin. Theory Ser. A  26  (1979), no. 2, 210—214&lt;/ref&gt; The results in these dimensions stem from the existence of highly symmetrical lattices: the [[E8 lattice|''E''&lt;sub&gt;8&lt;/sub&gt; lattice]] and the [[Leech lattice]].

If arrangements are restricted to ''lattice'' arrangements, in which the centres of the spheres all lie on points in a [[Lattice (group)|lattice]], then this restricted kissing number is known for ''n'' = 1 to 9 and ''n'' = 24 dimensions.&lt;ref&gt;{{MathWorld | urlname=KissingNumber |title=Kissing Number}}&lt;/ref&gt; For 5, 6, and 7 dimensions the arrangement with the highest known kissing number found so far is the optimal lattice arrangement, but the existence of a non-lattice arrangement with a higher kissing number has not been excluded.

==Some known bounds==

The following table lists some known bounds on the kissing number in various dimensions.&lt;ref name=Mittlemann&gt;{{cite journal|last1=Mittelmann|first1=Hans D.|last2=Vallentin|first2=Frank|title=High accuracy semidefinite programming bounds for kissing numbers|year=2009|pages=174–178|volume=19|journal=[[Experimental Mathematics (journal)|Experimental Mathematics]]|arxiv=0902.1105|bibcode=2009arXiv0902.1105M}}&lt;/ref&gt; The dimensions in which the kissing number is known are listed in boldface.

[[Image:Kissing growth.svg|thumb|right|500px|right|Rough volume estimates show that kissing number in ''n'' dimensions [[Exponential growth|grows exponentially]] in ''n''. The base of exponential growth is not known. The grey area in the above plot represents the possible values between known upper and lower bounds.  Circles represent values that are known exactly.]]
{| class="wikitable" style="text-align: center; margin-left: 40pt;"
!Dimension
!Lower&lt;br&gt;bound
!Upper&lt;br&gt;bound
|-
|'''1''' 
|colspan=2 | 2 
|-
|'''2'''
|colspan=2 | [[A2 lattice|6]]
|-
|'''3'''
|colspan=2 | [[A3 lattice|12]]
|-
|'''4'''  
|colspan=2 | [[D4 lattice|24]]&lt;ref name="Musin"/&gt; 
|-
|5  
|[[D5 lattice|40]]
|44
|-
|6  
|[[E6 lattice|72]]
|78
|-
|7  
|[[E7 lattice|126]]
|134
|-
|'''8'''
|colspan=2 | [[E8 lattice|240]]
|-
|9
|306 
|364
|-
|10
|500
|554
|-
|11
|582
|870
|-
|12
|840
|1,357
|-
|13
|1,154&lt;ref name="Zinoviev99"&gt;{{cite journal |author=В. А. Зиновьев, Т. Эриксон |script-title=ru:Новые нижние оценки на контактное число для небольших размерностей |language=Russian |journal=Пробл. Передачи Информ. |volume=35 |issue=4 |year=1999 |pages=3–11 |url=http://mi.mathnet.ru/eng/ppi457}} English translation: {{cite journal |author=V. A. Zinov'ev, T. Ericson |title=New Lower Bounds for Contact Numbers in Small Dimensions |journal=Problems of Information Transmission |year=1999 |volume=35 |issue=4 |pages=287–294 |mr=1737742}}&lt;/ref&gt;
|2,069
|-
|14
|1,606&lt;ref name="Zinoviev99"/&gt;
|3,183
|-
|15
|2,564
|4,866
|-
|16
|4,320
|7,355
|-
|17
|5,346
|11,072
|-
|18
|7,398
|16,572
|-
|19
|10,668
|24,812
|-
|20
|17,400
|36,764
|-
|21
|27,720
|54,584
|-
|22
|49,896
|82,340
|-
|23
|93,150
|124,416
|-
|'''24'''
|colspan=2 | [[Leech lattice|196,560]]
|}

==Generalization==
The kissing number problem can be generalized to the problem of finding the maximum number of non-overlapping [[congruence (geometry)|congruent]] copies of any [[convex body]] that touch a given copy of the body. There are different versions of the problem depending on whether the copies are only required to be congruent to the original body, [[translation (geometry)|translates]] of the original body, or translated by a lattice. For the [[regular tetrahedron]], for example, it is known that both the lattice kissing number and the translative kissing number are equal to 18, whereas the congruent kissing number is at least 56.&lt;ref&gt;{{Cite journal|last1=Lagarias|first1=Jeffrey C.|last2=Zong|first2=Chuanming|title=Mysteries in packing regular tetrahedra|journal=Notices of the American Mathematical Society|date=December 2012|pages=1540–1549|url=http://www.ams.org/notices/201211/rtx121101540p.pdf}}&lt;/ref&gt;

==Algorithms==
There are several [[approximation algorithm]]s on [[intersection graph]]s where the approximation ratio depends on the kissing number.&lt;ref&gt;{{Cite journal|last1=Kammer|first1=Frank|last2=Tholey|first2=Torsten|title=Approximation Algorithms for Intersection Graphs|journal=Algorithmica |volume=68|issue=2|date=July 2012|pages=312–336|doi=10.1007/s00453-012-9671-1}}&lt;/ref&gt; For example, there is 
a polynomial-time 10-approximation algorithm to find a maximum non-intersecting subset of a set of rotated unit squares.

==Mathematical statement==
The kissing number problem can be stated as the existence of a solution to a set of [[Inequality (mathematics)|inequalities]]. Let &lt;math&gt;x_n&lt;/math&gt; be a set of ''N'' ''D''-dimensional position vectors of the centres of the spheres. The condition that this set of spheres can lie round the centre sphere without overlapping is:

:&lt;math&gt; \exist  x\  \left\{ \forall_n \{x_n^Tx_n=1\} \land \forall_{m,n: m \neq n} \{ (x_n-x_m)^T(x_n-x_m) \geq 1\} \right\}&lt;/math&gt;&amp;nbsp;&lt;ref&gt;Numbers ''m'' and ''n'' run from 1 to ''N''. &lt;math&gt;x = (x_n)_N&lt;/math&gt; is the sequence of the ''N'' positional vectors. As the condition behind the second universal quantifier (&lt;math&gt;\forall&lt;/math&gt;) does not change if ''m'' and ''n'' are exchanged, it is sufficient to let this quantor extend just over &lt;math&gt;m,n:m&lt;n&lt;/math&gt;. For simplification the sphere radiuses are assumed to be 1/2.&lt;/ref&gt;

Thus the problem for each dimension can be expressed in the [[existential theory of the reals]]. However, general methods of solving problems in this form take at least [[exponential time]] which is why this problem has only been solved up to 4 dimensions. By adding additional variables, &lt;math&gt;y_{nm}&lt;/math&gt; this can be converted to a single [[Quartic function|quartic equation]] in ''N''(''N''-1)/2 + ''DN'' variables:

:&lt;math&gt; \exist xy\  \left\{ \sum_n (x_n^Tx_n-1)^2 + \sum_{m,n: m&lt;n}\Big( (x_n-x_m)^T(x_n-x_m)-1 - (y_{nm})^2 \Big)^2 = 0 \right\} &lt;/math&gt;&amp;nbsp;&lt;ref&gt;Concerning the matrix &lt;math&gt;y = (y_{mn})_{N\times{N}}&lt;/math&gt; only the entries having ''m''&lt;''n'' are needed. Or, equivalent, the matrix can be assumed to be antisymmetric. Anyway the matrix has just''N''(''N''-1)\2 free scalar variables. In addition, there are ''N'' ''D''-dimensional vectors ''x_n'', which correspondent to a matrix &lt;math&gt;x = (x_{nd})_{N\times{D}}&lt;/math&gt; of ''N'' column vectors.&lt;/ref&gt;

Therefore, to solve the case in ''D'' = 5 dimensions and ''N'' = [[D5 lattice|40]]+1 vectors would be equivalent to determining the existence of real solutions to a quartic polynomial in 1025 variables. For the ''D'' = 24 dimensions and ''N'' = [[Leech lattice|196560]]+1, the quartic would have 19,322,732,544 variables. An alternative statement in terms of [[distance geometry]] is given by the distances squared &lt;math&gt;R_{mn}&lt;/math&gt; between then ''m''&lt;sup&gt;th&lt;/sup&gt; and ''n''&lt;sup&gt;th&lt;/sup&gt; sphere.

:&lt;math&gt; \exist  R\  \{ \forall_n \{R_{0n}=1 \} \land \forall_{m,n: m&lt;n} \{ R_{mn} \geq 1\} \}&lt;/math&gt;

This must be supplemented with the condition that the [[distance geometry|Cayley–Menger Determinant]] is zero for any set of points which forms an (''D''+1) simplex in ''D'' dimensions, since that volume must be zero. Setting &lt;math&gt;R_{mn}= 1+{y_{mn}}^2&lt;/math&gt; gives a set of simultaneous polynomial equations in just ''y'' which must be solved for real values only. The two methods, being entirely equivalent, have various different uses. For example, in the second case one can randomly alter the values of the ''y'' by small amounts to try and minimise the polynomial in terms of the&amp;nbsp;''y''.

==See also==
*[[Equilateral dimension]]
*[[Sphere packing]]
*[[Spherical code]]
*[[Soddy's hexlet]]

==External links==
*{{cite web |last1=Grime |first1=James |title=Kissing Numbers |url=https://www.youtube.com/watch?v=LZ7X_YOfJqY |website=youtube |publisher=[[Brady Haran]] |accessdate=11 October 2018 |format=video}}

==Notes==
{{reflist|2}}

==References==
* T. Aste and [[Denis Weaire|D. Weaire]] "The Pursuit of Perfect Packing" (Institute Of Physics Publishing London 2000) {{isbn|0-7503-0648-3}}
*[http://www.math.rwth-aachen.de/~Gabriele.Nebe/LATTICES/kiss.html Table of the Highest Kissing Numbers Presently Known] maintained by [[Gabriele Nebe]] and [[Neil Sloane]] (lower bounds)
* Christine Bachoc and Frank Vallentin. "[https://arxiv.org/abs/math.MG/0608426 New upper bounds for kissing numbers from semidefinite programming]".

{{Isaac Newton}}
{{Packing problem}}

[[Category:Discrete geometry]]
[[Category:Packing problems]]</text>
      <sha1>0kggcijfcbxtw58dg8pwfplczr86krt</sha1>
    </revision>
  </page>
  <page>
    <title>Lagrange inversion theorem</title>
    <ns>0</ns>
    <id>94158</id>
    <revision>
      <id>836787736</id>
      <parentid>836739867</parentid>
      <timestamp>2018-04-16T21:01:03Z</timestamp>
      <contributor>
        <username>Maxal</username>
        <id>237258</id>
      </contributor>
      <comment>/* Theorem statement */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11741">In [[mathematical analysis]], the '''Lagrange inversion theorem''', also known as the '''Lagrange–Bürmann formula''', gives the [[Taylor series]] expansion of the [[inverse function]] of an [[analytic function]].

==Theorem statement==

Suppose ''z'' is defined as a function of ''w'' by an equation of the form

:&lt;math&gt;z = f(w)&lt;/math&gt;

where ''f'' is analytic at a point ''a'' and {{math|''f'' '(''a'') ≠ 0}}. Then it is possible to ''invert'' or ''solve'' the equation for ''w'', expressing it in the form &lt;math&gt;w=g(z)&lt;/math&gt; given by a power series&lt;ref&gt;{{cite book |editors=M. Abramowitz, I. A. Stegun |title=Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables |chapter=3.6.6. Lagrange's Expansion |place=New York |publisher=Dover |page=14 |year=1972 |url=http://people.math.sfu.ca/~cbm/aands/page_14.htm}}&lt;/ref&gt;
:&lt;math&gt; 
  g(z) = a + \sum_{n=1}^{\infty} g_n \frac{(z - f(a))^n}{n!},
 &lt;/math&gt;
where
:&lt;math&gt;
  g_n = \lim_{w \to a}\left[
\frac{d^{n-1}}{dw^{n-1}}
\left( \frac{w-a}{f(w) - f(a)} \right)^n\right].
 &lt;/math&gt;

The theorem further states that this series has a non-zero radius of convergence, i.e., &lt;math&gt;g(z)&lt;/math&gt; represents an analytic function of ''z'' in a [[neighbourhood (mathematics)|neighbourhood]] of &lt;math&gt;z= f(a)&lt;/math&gt;. This is also called '''reversion of series'''.

If the assertions about analyticity are omitted, the formula is also valid for [[formal power series]] and can be generalized in various ways. It can be formulated for functions of several variables, it can be extended to provide a ready formula for ''F''(''g''(''z'')) for any analytic function ''F'', and it can be generalized to the case ''f''&amp;nbsp;'(''a'') = 0, where the inverse ''g'' is a multivalued function.

The theorem was proved by [[Joseph Louis Lagrange|Lagrange]]&lt;ref&gt;{{cite journal |author=Lagrange, Joseph-Louis |year=1770 |title=Nouvelle méthode pour résoudre les équations littérales par le moyen des séries |journal=Mémoires de l'Académie Royale des Sciences et Belles-Lettres de Berlin |volume=24 |pages=251–326 |url=http://gdz.sub.uni-goettingen.de/no_cache/dms/load/img/?IDDOC=41070}} (Note:  Although Lagrange submitted this article in 1768, it was not published until 1770.)&lt;/ref&gt; and generalized by [[Hans Heinrich Bürmann]],&lt;ref&gt;Bürmann, Hans Heinrich, "Essai de calcul fonctionnaire aux constantes ad-libitum," submitted in 1796 to the Institut National de France. For a summary of this article, see: {{cite book |editor=Hindenburg, Carl Friedrich |title=Archiv der reinen und angewandten Mathematik |trans-title=Archive of pure and applied mathematics |location=Leipzig, Germany |publisher=Schäferischen Buchhandlung |year=1798 |volume=2 |chapter=Versuch einer vereinfachten Analysis; ein Auszug eines Auszuges von Herrn Bürmann |trans-chapter=Attempt at a simplified analysis; an extract of an abridgement by Mr. Bürmann |pages=495–499 |chapterurl=https://books.google.com/books?id=jj4DAAAAQAAJ&amp;pg=495#v=onepage&amp;q&amp;f=false}}&lt;/ref&gt;&lt;ref&gt;Bürmann, Hans Heinrich, "Formules du développement, de retour et d'integration," submitted to the Institut National de France. Bürmann's manuscript survives in the archives of the École Nationale des Ponts et Chaussées [National School of Bridges and Roads] in Paris. (See ms. 1715.)&lt;/ref&gt;&lt;ref&gt;A report on Bürmann's theorem by Joseph-Louis Lagrange and Adrien-Marie Legendre appears in:  [http://gallica.bnf.fr/ark:/12148/bpt6k3217h.image.f22.langFR.pagination "Rapport sur deux mémoires d'analyse du professeur Burmann,"] ''Mémoires de l'Institut National des Sciences et Arts: Sciences Mathématiques et Physiques'', vol. 2, pages 13–17 (1799).&lt;/ref&gt; both in the late 18th century. There is a straightforward derivation using [[complex analysis]] and [[contour integration]];&lt;ref&gt;[[E. T. Whittaker]] and [[G. N. Watson]]. ''A Course of Modern Analysis''. Cambridge University Press; 4th edition (January 2, 1927), pp. 129–130&lt;/ref&gt; the complex formal power series version is a consequence of knowing the formula for [[polynomial]]s, so the theory of [[analytic function]]s may be applied. Actually, the machinery from analytic function theory enters only in a formal way in this proof, in that what is really needed is some property of the [[Formal power series#Formal residue|formal residue]], and a more direct formal [[Formal power series#The Lagrange inversion formula|proof]] is available.

If ''f'' is a formal power series, then the above formula does not give the coefficients of the compositional inverse series ''g'' directly in terms for the coefficients of the series ''f''. If one can express the functions ''f'' and ''g'' in formal power series as

:&lt;math&gt;f(w) = \sum_{k=0}^\infty f_k \frac{w^k}{k!} \qquad \mathrm{and}  \qquad  g(z) = \sum_{k=0}^\infty g_k \frac{z^k}{k!}&lt;/math&gt;

with ''f&lt;sub&gt;0&lt;/sub&gt; = 0'' and ''f&lt;sub&gt;1&lt;/sub&gt; ≠ 0'', then an explicit form of inverse coefficients can be given in term of [[Bell polynomial]]s:&lt;ref&gt;Eqn (11.43), p. 437, C.A. Charalambides, ''Enumerative Combinatorics,'' Chapman &amp; Hall / CRC, 2002&lt;/ref&gt;

:&lt;math&gt; g_n = \frac{1}{f_1^n} \sum_{k=1}^{n-1} (-1)^k n^{(k)} B_{n-1,k}(\hat{f}_1,\hat{f}_2,\ldots,\hat{f}_{n-k}), \quad n \geq 2, &lt;/math&gt;

with &lt;math&gt; \hat{f}_k = \frac{f_{k+1}}{(k+1)f_{1}},&lt;/math&gt; &amp;nbsp;&amp;nbsp; &lt;math&gt; g_1 = \frac{1}{f_{1}},&lt;/math&gt; &amp;nbsp; and &amp;nbsp; &lt;math&gt;n^{(k)} = n(n+1)\cdots (n+k-1), &lt;/math&gt;&amp;nbsp; being the [[rising factorial]]. 

When ''f&lt;sub&gt;1&lt;/sub&gt; = 1'', the last formula can be interpreted in terms of the faces of [[Associahedron|associahedra]]  &lt;ref&gt;{{cite arXiv|eprint=1709.07504|class=math.CO|first=|last=|author-link=|title=Hopf monoids and generalized permutahedra|date=|last1=Aguiar|first1=Marcelo|last2=Ardila|first2=Federico|year=2017}}&lt;/ref&gt;

:&lt;math&gt; g_n = \sum_{F \text{ face of } K_n} (-1)^{n-\dim F} f_F , \quad n \geq 2, &lt;/math&gt; 

where &lt;math&gt; f_{F} = f_{i_{1}} \cdots f_{i_{m}} &lt;/math&gt; for each face &lt;math&gt; F = K_{i_1} \times \cdots \times K_{i_m} &lt;/math&gt; of the associahedron &lt;math&gt; K_n &lt;/math&gt;.

==Example==
For instance, the algebraic equation of degree ''p'' 
:&lt;math&gt; x^p - x + z= 0&lt;/math&gt;
can be solved for ''x'' by means of the Lagrange inversion formula for the function ''f''(''x'') = ''x'' − ''x&lt;sup&gt;p&lt;/sup&gt;'',  yielding to a formal series solution

:&lt;math&gt;  x=\sum_{k=0}^\infty {pk\choose k} \frac{z^{(p-1)k+1} }{(p-1)k+1} . &lt;/math&gt;

By convergence tests, this series is in fact convergent for |''z''| ≤ (''p'' − 1)''p''&lt;sup&gt;−''p''/(''p'' − 1)&lt;/sup&gt;,  which is also the largest disk in which a local inverse to ''f'' can be defined.

==Applications==

===Lagrange–Bürmann formula===

There is a special case of Lagrange inversion theorem that is used in [[combinatorics]] and applies when &lt;math&gt;f(w)=w/\phi(w)&lt;/math&gt; for some analytic &lt;math&gt;\phi(w)&lt;/math&gt; with &lt;math&gt;\phi(0)\ne 0.&lt;/math&gt; Take &lt;math&gt;a=0&lt;/math&gt; to obtain &lt;math&gt;f(a)=f(0)=0.&lt;/math&gt; Then for the inverse &lt;math&gt;g(z)&lt;/math&gt; (satisfying &lt;math&gt;f(g(z))\equiv z&lt;/math&gt;), we have
:&lt;math&gt;
  g(z) =
  \sum_{n=1}^{\infty}
   \left( \lim_{w \to 0}
    \left(  \frac {\mathrm{d}^{n-1}}{\mathrm{d}w^{n-1}}
    \left( \frac{w}{w/\phi(w)} \right)^n
   \right)
  \frac{z^n}{n!}
 \right)
&lt;/math&gt;

:&lt;math&gt;=
  \sum_{n=1}^{\infty}
  \frac{1}{n}
   \left(
   \frac{1}{(n-1)!}
   \lim_{w \to 0} \left(
   \frac{\mathrm{d}^{n-1}}{\mathrm{d}w^{n-1}}
   \phi(w)^n
  \right)
 \right)
 z^n,
&lt;/math&gt;

which can be written alternatively as

:&lt;math&gt;[z^n] g(z) = \frac{1}{n} [w^{n-1}] \phi(w)^n,&lt;/math&gt;

where &lt;math&gt;[w^r]&lt;/math&gt; is an operator which extracts the coefficient of &lt;math&gt;w^r&lt;/math&gt; in the Taylor series of a function of w.

A useful generalization of the formula is known as the '''Lagrange–Bürmann formula''':
:&lt;math&gt;[z^n] H (g(z)) = \frac{1}{n} [w^{n-1}] (H' (w) \phi(w)^n)&lt;/math&gt;

where {{math|''H''}} is an arbitrary analytic function.

Sometimes, the derivative ''H' (w)'' can be quite complicated. A simpler version of the formula replaces ''H' (w)'' with ''H (w)(1-φ'(w)/φ(w))'' to get 

:&lt;math&gt; [z^n] H (g(z)) = [w^n] H(w) \phi(w)^{n-1} (\phi(w) - w \phi'(w)),  &lt;/math&gt;

which involves ''φ'(w)'' instead of ''H' (w)''.

===Lambert ''W'' function===

{{main|Lambert W function}}
The Lambert ''W'' function is the function &lt;math&gt;W(z)&lt;/math&gt; that is implicitly defined by the equation

:&lt;math&gt; W(z) e^{W(z)} = z.\,&lt;/math&gt;

We may use the theorem to compute the [[Taylor series]] of &lt;math&gt;W(z)&lt;/math&gt; at &lt;math&gt;z=0.&lt;/math&gt;
We take &lt;math&gt;f(w) = w \mathrm{e}^w&lt;/math&gt; and &lt;math&gt;a = b = 0.&lt;/math&gt; Recognizing that
:&lt;math&gt;
\frac{\mathrm{d}^n}{\mathrm{d}x^n}\ \mathrm{e}^{\alpha\,x}\,=\,\alpha^n\,\mathrm{e}^{\alpha\,x}
&lt;/math&gt;
this gives
:&lt;math&gt;
  W(z) =
  \sum_{n=1}^{\infty}
  \lim_{w \to 0} \left(
   \frac{\mathrm{d}^{\,n-1}}{\mathrm{d}w^{\,n-1}}\ \mathrm{e}^{-nw}
  \right)
  { \frac{z^n}{n!}}\,=\, \sum_{n=1}^{\infty}
  (-n)^{n-1}\, \frac{z^n}{n!}=z-z^2+\frac{3}{2}z^3-\frac{8}{3}z^4+O(z^5).
&lt;/math&gt;

The [[radius of convergence]] of this series is &lt;math&gt;e^{-1}&lt;/math&gt; (this example refers to the [[principal branch]] of the Lambert function).

A series that converges for larger ''z'' (though not for all ''z'') can also be derived by series inversion.  The function &lt;math&gt;f(z) = W(e^z) - 1\,&lt;/math&gt; satisfies the equation

:&lt;math&gt;1 + f(z) + \ln (1 + f(z)) = z.\,&lt;/math&gt;

Then &lt;math&gt;z + \ln (1 + z)\,&lt;/math&gt; can be expanded into a power series and inverted.  This gives a series for &lt;math&gt;f(z+1) = W(e^{z+1})-1\,&lt;/math&gt;:

:&lt;math&gt;W(e^{1+z}) = 1 + \frac{z}{2} + \frac{z^2}{16}
- \frac{z^3}{192}
- \frac{z^4}{3072}
+ \frac{13 z^5}{61440}
- \frac{47 z^6}{1474560}
- \frac{73 z^7}{41287680}
+ \frac{2447 z^8}{1321205760} + O(z^9).&lt;/math&gt;

&lt;math&gt;W(x)\,&lt;/math&gt; can be computed by substituting &lt;math&gt;\ln x - 1\,&lt;/math&gt; for ''z'' in the above series. For example, substituting −1 for ''z'' gives the value of &lt;math&gt;W(1) = 0.567143\,&lt;/math&gt;.

===Binary trees===

Consider the set &lt;math&gt;\mathcal{B}&lt;/math&gt; of unlabelled [[binary tree]]s.
An element of &lt;math&gt;\mathcal{B}&lt;/math&gt; is either a leaf of size zero, or a root node with two subtrees.  Denote by &lt;math&gt;B_n&lt;/math&gt; the number of binary trees on ''n'' nodes.

Note that removing the root splits a binary tree into two trees of smaller size.  This yields the functional equation on the generating function &lt;math&gt;B(z) = \sum_{n=0}^\infty B_n z^n&lt;/math&gt;:
:&lt;math&gt;B(z) = 1 + z B(z)^2.&lt;/math&gt;

Now let &lt;math&gt;C(z) = B(z) - 1&lt;/math&gt;, one has thus &lt;math&gt;C(z) = z (C(z)+1)^2.&lt;/math&gt; Now apply the theorem with &lt;math&gt;\phi(w) = (w+1)^2:&lt;/math&gt;
:&lt;math&gt; B_n = [z^n] C(z) = \frac{1}{n} [w^{n-1}] (w+1)^{2n}
= \frac{1}{n} {2n \choose n-1} =  \frac{1}{n+1} {2n \choose n}.&lt;/math&gt;

We conclude that &lt;math&gt;B_n&lt;/math&gt; is the [[Catalan number]].

=== Asymptotic approximation of integrals===
In the Laplace-Erdelyi theorem that gives the asymptotic approximation for Laplace-type integrals, the function inversion is taken as a crucial step.

==See also==
*[[Faà di Bruno's formula]] gives coefficients of the composition of two formal power series in terms of the coefficients of those two series.  Equivalently, it is a formula for the ''n''th derivative of a composite function.
*[[Lagrange reversion theorem]] for another theorem sometimes called the inversion theorem
*[[Formal power series#The Lagrange inversion formula]]

==References==
{{reflist}}

==External links==
*{{MathWorld |urlname=BuermannsTheorem |title=Bürmann's Theorem}}
*{{MathWorld |urlname=SeriesReversion |title=Series Reversion}}
*[http://www.encyclopediaofmath.org/index.php/B%C3%BCrmann%E2%80%93Lagrange_series Bürmann–Lagrange series] at [[Encyclopedia of Mathematics|Springer EOM]]

[[Category:Inverse functions]]
[[Category:Theorems in real analysis]]
[[Category:Theorems in complex analysis]]
[[Category:Theorems in combinatorics]]</text>
      <sha1>mcb9jw0swv66fqgqxts5ycxiekgfuxi</sha1>
    </revision>
  </page>
  <page>
    <title>Lia Bronsard</title>
    <ns>0</ns>
    <id>54888506</id>
    <revision>
      <id>854070812</id>
      <parentid>807237471</parentid>
      <timestamp>2018-08-08T19:26:39Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (6 sources from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4211">{{Infobox academic
| name = Lia Bronsard
| title = Professor
| birth_date = {{birth date and age|1963|03|14}}
| nationality = Canada
| discipline = Mathematics
| alma_mater = [[New York University]]
| doctoral_advisor = [[Robert V. Kohn]]
| workplaces = [[McMaster University]]
}}

'''Lia Bronsard''' (b. 14 March 1963{{r|cv}}) is a Canadian mathematician, the 2010 winner of the [[Krieger–Nelson Prize]]{{r|3h}} and the former president of the [[Canadian Mathematical Society]].{{r|mudn}} She is a professor of mathematics at [[McMaster University]]. In her research, she has used [[geometric flow]]s to model the interface dynamics of [[reaction–diffusion system]]s.{{r|profile}}
Other topics in her research include [[pattern formation]], [[grain boundary|grain boundaries]], and [[vortex|vortices]] in [[superfluid]]s.{{r|3h}}

Bronsard is originally from Québec. She did her undergraduate studies at the [[Université de Montréal]], graduating in 1983,{{r|3h}}
and earned her PhD in 1988 from [[New York University]] under the supervision of [[Robert V. Kohn]].{{r|mgp}}
After short-term positions at [[Brown University]], the [[Institute for Advanced Study]], and [[Carnegie Mellon University]], she moved to McMaster in 1992.{{r|3h}} She was president of the Canadian Mathematical Society for 2014–2016.{{r|mudn|pres}}

==Selected publications==
*{{citation
 | last1 = Bronsard | first1 = Lia
 | last2 = Kohn | first2 = Robert V. | author2-link = Robert V. Kohn
 | doi = 10.1002/cpa.3160430804
 | issue = 8
 | journal = [[Communications on Pure and Applied Mathematics]]
 | mr = 1075075
 | pages = 983–997
 | title = On the slowness of phase boundary motion in one space dimension
 | volume = 43
 | year = 1990}}
*{{citation
 | last1 = Bronsard | first1 = Lia
 | last2 = Kohn | first2 = Robert V. | author2-link = Robert V. Kohn
 | doi = 10.1016/0022-0396(91)90147-2
 | issue = 2
 | journal = Journal of Differential Equations
 | mr = 1101239
 | pages = 211–237
 | title = Motion by mean curvature as the singular limit of Ginzburg–Landau dynamics
 | volume = 90
 | year = 1991}}
*{{citation
 | last1 = Bronsard | first1 = Lia
 | last2 = Reitich | first2 = Fernando
 | doi = 10.1007/BF00375607
 | issue = 4
 | journal = [[Archive for Rational Mechanics and Analysis]]
 | mr = 1240580
 | pages = 355–379
 | title = On three-phase boundary motion and the singular limit of a vector-valued Ginzburg–Landau equation
 | volume = 124
 | year = 1993}}

==References==
{{Reflist|refs=

&lt;ref name=cv&gt;{{citation|url=http://ms.mcmaster.ca/~bronsard/wordpress/wp-content/uploads/2012/02/cvlia01_17.pdf|title=Curriculum vitae for Lia Bronsard|accessdate=2017-10-26}}&lt;/ref&gt;

&lt;ref name=3h&gt;{{citation|url=https://cms.math.ca/MediaReleases/2009/res-prizes|title=Three Honoured for Outstanding Research Achievements|publisher=[[Canadian Mathematical Society]]|date=April 3, 2009|accessdate=2017-08-13}}&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=80114}}&lt;/ref&gt;

&lt;ref name=mudn&gt;{{citation|url=http://dailynews.mcmaster.ca/article/im-very-pleased-to-have-been-elected-and-especially-to-have-come-from-mcmaster/|newspaper=Daily News|publisher=McMaster University|first=Andrew|last=Baulcomb|date=December 12, 2013|title='I'm very pleased to have been elected, and especially to have come from McMaster'|accessdate=2017-08-13}}&lt;/ref&gt;

&lt;ref name=pres&gt;{{citation|url=https://cms.math.ca/Historical/presidents.pdf|title=CMS Presidents 1945–2016|publisher=[[Canadian Mathematical Society]]|accessdate=2017-08-13}}&lt;/ref&gt;

&lt;ref name=profile&gt;{{citation|url=https://www.math.mcmaster.ca/index.php/news/65-/professor/255-bronsard-lia.html|title=Bronsard, Lia|work=Faculty profile|publisher=McMaster University Dept. of Mathematics &amp; Statistics|accessdate=2017-08-13}}&lt;/ref&gt;

}}

==External links==
*[http://ms.mcmaster.ca/~bronsard/ Home page]
*{{Google Scholar id|CtWf9iMAAAAJ}}

{{Authority control}}

{{DEFAULTSORT:Bronsard, Lia}}
[[Category:1963 births]]
[[Category:Living people]]
[[Category:Canadian mathematicians]]
[[Category:Canadian women academics]]
[[Category:Women mathematicians]]
[[Category:Université de Montréal alumni]]
[[Category:New York University alumni]]
[[Category:McMaster University faculty]]</text>
      <sha1>1rugxastczji8zywomd950i2699dkqe</sha1>
    </revision>
  </page>
  <page>
    <title>Lusin's separation theorem</title>
    <ns>0</ns>
    <id>30563979</id>
    <revision>
      <id>798848304</id>
      <parentid>786602850</parentid>
      <timestamp>2017-09-04T05:08:10Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2027">{{otheruses4|the separation theorem|the theorem on continuous functions|Lusin's theorem}}

In [[descriptive set theory]] and [[mathematical logic]], '''Lusin's separation theorem''' states that if ''A'' and ''B'' are disjoint [[Analytic set|analytic subsets]] of [[Polish space]], then there is a [[Borel set]] ''C'' in the space such that ''A''&amp;nbsp;&amp;sube;&amp;nbsp;''C'' and ''B''&amp;nbsp;&amp;cap;&amp;nbsp;''C''&amp;nbsp;=&amp;nbsp;&amp;empty;.&lt;ref name="Kecp87" &gt;{{harv|Kechris|1995|p=87}}.&lt;/ref&gt; It is named after [[Nikolai Luzin]], who proved it in 1927.&lt;ref&gt;{{harv|Lusin|1927}}.&lt;/ref&gt;

The theorem can be generalized to show that for each sequence (''A''&lt;sub&gt;''n''&lt;/sub&gt;) of disjoint analytic sets there is a sequence (''B''&lt;sub&gt;''n''&lt;/sub&gt;) of disjoint Borel sets such that ''A''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;&amp;sube;&amp;nbsp;''B''&lt;sub&gt;''n''&lt;/sub&gt; for each ''n''. &lt;ref name="Kecp87" /&gt;

An immediate consequence is Suslin's theorem, which states that if a set and its complement are both analytic, then the set is Borel.

== Notes ==

{{reflist|29em}}

== References ==

*{{Citation
 | last = Kechris 
 | first = Alexander 
 | authorlink = Alexander S. Kechris
 | title = Classical descriptive set theory
 | place = Berlin–Heidelberg–New York
 | publisher = [[Springer-Verlag]]
 | series = [[Graduate texts in mathematics]]
 | volume = 156
 | year = 1995
 | pages = xviii+402
 | url = https://link.springer.com/book/10.1007/978-1-4612-4190-4/page/1
 | doi = 10.1007/978-1-4612-4190-4
 | isbn = 0-387-94374-9
 | mr = 1321597
 | zbl = 0819.04002
}} ({{isbn|3-540-94374-9}} for the European edition) 
*{{Citation
 | last = Lusin
 | first = Nicolas
 | authorlink = Nikolai Luzin
 | title = Sur les ensembles analytiques
 | journal = Fundamenta Mathematicae
 | volume = 10
 | pages = 1–95
 | url = http://matwbn.icm.edu.pl/ksiazki/fm/fm10/fm1011.pdf
 | year = 1927
 | language = French
 | jfm = 53.0171.05 
}}.

[[Category:Descriptive set theory]]
[[Category:Theorems in the foundations of mathematics]]
[[Category:Theorems in topology]]

{{mathlogic-stub}}</text>
      <sha1>ha6qduqt3gvx251jcjxpxkgov4diiy0</sha1>
    </revision>
  </page>
  <page>
    <title>McLaughlin graph</title>
    <ns>0</ns>
    <id>46573575</id>
    <revision>
      <id>852405208</id>
      <parentid>852404974</parentid>
      <timestamp>2018-07-28T19:29:00Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Graphs of radius 2‎ per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 July 21]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1650">{{infobox graph
 | name = McLaughlin graph
 | vertices = 275
 | edges = 15400
 | diameter = 2
 | radius = 2
 | girth = 3
 | automorphisms = 1796256000
}}
In the [[mathematics|mathematical]] field of [[graph theory]], the '''McLaughlin graph''' is a [[strongly regular graph]] with parameters (275,112,30,56), and is the only such graph.

The [[group theory|group theorist]] Jack McLaughlin discovered that the [[automorphism group]] of this graph had a subgroup of index 2 which was a previously undiscovered [[finite simple group]], now called the [[McLaughlin sporadic group]].

The automorphism group has [[rank 3 permutation group|rank 3]], meaning that its [[point stabilizer]] subgroup divides the remaining 274 vertices into two [[orbit (group theory)|orbits]]. Those orbits contain 112 and 162 vertices. The former is the [[Generalized quadrangle#Graphs|colinearity graph of the generalized quadrangle]] GQ(3,9). The latter is a strongly regular graph called the [[local McLaughlin graph]].

== References==

*{{Citation | last1=McLaughlin | first1=Jack  | editor1-last=Brauer | editor1-first=R. | editor1-link=Richard Brauer | editor2-last=Sah | editor2-first=Chih-han | title=Theory of Finite Groups (Symposium, Harvard Univ., Cambridge, Mass., 1968) | publisher=Benjamin, New York | year=1969 | chapter=A simple group of order 898,128,000 | pages=109–111 | mr=0242941}}

== External links ==

*{{cite web
  | author = [[Andries Brouwer]]
  | title = McLaughlin graph
  | publisher= Author's personal site
  | url = http://www.win.tue.nl/~aeb/graphs/McL.html}}

[[Category:Individual graphs]]
[[Category:Regular graphs]]


{{combin-stub}}</text>
      <sha1>pbuq21ex8f05nvp4fx8tnxmcwb3h0fr</sha1>
    </revision>
  </page>
  <page>
    <title>Modular decomposition</title>
    <ns>0</ns>
    <id>28310124</id>
    <revision>
      <id>870243675</id>
      <parentid>864705007</parentid>
      <timestamp>2018-11-23T13:12:56Z</timestamp>
      <contributor>
        <username>Zacchiro</username>
        <id>2329976</id>
      </contributor>
      <minor/>
      <comment>/* Modules */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21449">In [[Graph (discrete mathematics)|graph theory]], the '''modular decomposition''' is a decomposition of a [[Graph (discrete mathematics)|graph]] into subsets of vertices called '''modules.'''  A module is a generalization of a [[Connected component (graph theory)|connected component]] of a graph.  Unlike connected components, however, one module can be a proper subset of another.   Modules therefore lead to a recursive (hierarchical) decomposition of the graph, instead of just a partition.

There are variants of modular decomposition for [[undirected graph]]s and [[directed graph]]s. For each undirected graph, this decomposition is unique.

This notion can be generalized to other structures (for example directed graphs) and is useful to design efficient algorithms for the recognition of some graph classes, for finding transitive orientations of [[comparability graph]]s, for [[Optimization (mathematics)|optimization problems]] on graphs, and for [[graph drawing]].

== Modules ==

As the notion of modules has been rediscovered in many areas, ''modules'' have also been called ''autonomous sets'', ''homogeneous sets'', ''intervals'', and ''partitive sets''.   Perhaps the earliest reference to them, and the first description of modular quotients and the graph decomposition they give rise to appeared in ([[Tibor Gallai|Gallai]] 1967).

A ''module'' of a graph is a generalization of a [[Connected component (graph theory)|connected component]].  A connected component has the property that it is a set &lt;math&gt;X&lt;/math&gt; of vertices such that every member of &lt;math&gt;X&lt;/math&gt; is a [[Neighbourhood (graph theory)|non-neighbor]] of every vertex not in &lt;math&gt;X&lt;/math&gt;.  (It is a union of connected components if and only if it has this property.) More generally, &lt;math&gt;X&lt;/math&gt; is a module if, for each vertex &lt;math&gt;v \not\in X&lt;/math&gt;, either every member of &lt;math&gt;X&lt;/math&gt; is a non-neighbor of &lt;math&gt;v&lt;/math&gt; or every member of &lt;math&gt;X&lt;/math&gt; is a neighbor of &lt;math&gt;v&lt;/math&gt;.

Equivalently, &lt;math&gt;X&lt;/math&gt; is a module if all members of &lt;math&gt;X&lt;/math&gt; have the same set of neighbors among vertices not in &lt;math&gt;X&lt;/math&gt;.

Contrary to the connected components, the modules of a graph are the same as the modules of its [[Complement graph|complement]], and modules can be "nested": one module can be a proper subset of another. Note that the set &lt;math&gt;V&lt;/math&gt; of vertices of a graph is a module, as are its one-element subsets and the empty set;  these are called the '''trivial modules'''.  A graph may or may not have other modules.  A graph is called '''prime''' if all of its modules are trivial.

Despite these differences, modules preserve a desirable property of connected components, which is that many properties of the subgraph &lt;math&gt;G[X]&lt;/math&gt; [[Glossary_of_graph_theory#Subgraphs|induced]] by a connected component &lt;math&gt;X&lt;/math&gt; are independent of the rest of the graph.  A similar phenomenon also applies to the subgraphs induced by modules.

The modules of a graph are therefore of great algorithmic interest.  A set of nested modules, of which the modular decomposition is an example,  can be used to guide the recursive solution of many combinatorial problems on graphs, such as recognizing and transitively orienting [[comparability graph]]s, recognizing and finding permutation representations of [[permutation graph]]s, recognizing whether a graph is a [[cograph]] and finding a certificate of the answer to the question, recognizing [[interval graph]]s and finding interval representations for them, defining [[distance-hereditary graph]]s (Spinrad, 2003) and for [[graph drawing]] (Papadoupoulos, 2006).  They play an important role in Lovász's celebrated proof of the [[perfect graph theorem#Characterizations and the perfect graph theorems|perfect graph theorem]] (Golumbic, 1980).

For recognizing distance-hereditary graphs and [[circle graph]]s, a further generalization of modular decomposition, called the [[split decomposition]], is especially useful (Spinrad, 2003).

To avoid the possibility of ambiguity in the above definitions, we give the following formal definitions of modules. 
&lt;math&gt;G = (V,E)&lt;/math&gt;.
&lt;math&gt;M \subseteq V&lt;/math&gt; is a '''module''' of &lt;math&gt;G&lt;/math&gt; if:
* the vertices of &lt;math&gt;M&lt;/math&gt; cannot be distinguished by any vertex in &lt;math&gt;V \backslash M&lt;/math&gt;, i.e., &lt;math&gt;\forall u,v \in M, \forall x\in V \backslash M&lt;/math&gt;, either &lt;math&gt;x&lt;/math&gt; is adjacent to both &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;v&lt;/math&gt; or &lt;math&gt;x&lt;/math&gt; is not adjacent to both &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;v&lt;/math&gt;.
* the vertices of &lt;math&gt;M&lt;/math&gt; have the same set of outer neighbors, i.e., &lt;math&gt;\forall u,v \in M, N(u) \setminus M = N(v) \setminus M &lt;/math&gt;.

&lt;math&gt;\emptyset&lt;/math&gt;, &lt;math&gt;V&lt;/math&gt; and all the [[Singleton set|singletons]] &lt;math&gt;\{v\}&lt;/math&gt; for &lt;math&gt;v \in V&lt;/math&gt; are modules, and are called '''trivial modules'''. A graph is '''prime''' if all its modules are trivial. [[connected component (graph theory)|Connected components]] of a graph &lt;math&gt;G&lt;/math&gt;, or of its complement graph are also modules of &lt;math&gt;G&lt;/math&gt;.

&lt;math&gt;M&lt;/math&gt; is a '''strong module''' of a graph &lt;math&gt;G&lt;/math&gt; if it does not overlap any other module of &lt;math&gt;G&lt;/math&gt;:
&lt;math&gt;\forall M'&lt;/math&gt; module of &lt;math&gt;G&lt;/math&gt;, either &lt;math&gt;M \cap M' = \emptyset&lt;/math&gt; or &lt;math&gt;M \subseteq M'&lt;/math&gt; or &lt;math&gt;M' \subseteq M&lt;/math&gt;.

== Modular quotients and factors ==

If &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; are disjoint modules, then it is easy to see that either every member of &lt;math&gt;X&lt;/math&gt; is a neighbor of every element of &lt;math&gt;Y&lt;/math&gt;, or no member of &lt;math&gt;X&lt;/math&gt; is adjacent to any member of &lt;math&gt;Y&lt;/math&gt;.  Thus, the relationship between two disjoint modules is either ''adjacent'' or ''nonadjacent''.  No relationship intermediate between these two extremes can exist.

Because of this, '''modular partitions''' of &lt;math&gt;V&lt;/math&gt; where each partition class is a module are of particular interest.  Suppose &lt;math&gt;P&lt;/math&gt; is a modular partition.  Since the partition classes are disjoint, their adjacencies constitute a new graph, a '''[[quotient graph]]''' &lt;math&gt;G/P&lt;/math&gt;, whose vertices are the members of &lt;math&gt;P&lt;/math&gt;.  That is, each vertex of &lt;math&gt;G/P&lt;/math&gt; is a module of G, and the adjacencies of these modules are the edges of &lt;math&gt;G/P&lt;/math&gt;.

In the figure below,   vertex 1, vertices 2 through 4, vertex 5, vertices 6 and 7, and vertices 8 through 11 are a modular partition.  In the upper right diagram, the edges between these sets depict the quotient given by this partition, while the edges internal to the sets depict the corresponding factors.

The partitions &lt;math&gt;\{V\}&lt;/math&gt; and  &lt;math&gt;\{\{x\}|x \in V\}&lt;/math&gt; are the '''trivial modular partitions'''.  &lt;math&gt;G/\{V\} &lt;/math&gt; is just the one-vertex graph, while &lt;math&gt;G/\{\{x\}|x \in V\} = G&lt;/math&gt;.  Suppose &lt;math&gt;X&lt;/math&gt; is a nontrivial module.  Then &lt;math&gt;X&lt;/math&gt; and the one-elements subsets of &lt;math&gt;V \backslash X&lt;/math&gt; are a nontrivial modular partition of &lt;math&gt;V&lt;/math&gt;.  Thus, the existence of ''any'' nontrivial modules implies the existence of nontrivial modular partitions.  In general, many or all members of &lt;math&gt;P&lt;/math&gt; can be nontrivial modules.

If &lt;math&gt;P&lt;/math&gt; is a nontrivial modular partition, then &lt;math&gt;G/P&lt;/math&gt; is a compact representation of all the edges that have endpoints in different partition classes of &lt;math&gt;P&lt;/math&gt;.  For each partition class &lt;math&gt;X&lt;/math&gt; in &lt;math&gt;P&lt;/math&gt;, the subgraph &lt;math&gt;G[X]&lt;/math&gt; induced by &lt;math&gt;X&lt;/math&gt; is called a '''factor''' and gives a representation of all edges with both endpoints in &lt;math&gt;X&lt;/math&gt;.  Therefore, the edges of &lt;math&gt;G&lt;/math&gt; can be reconstructed given only the quotient graph &lt;math&gt;G/P&lt;/math&gt; and its factors.  The term ''prime'' graph comes from the fact that a prime graph has only trivial quotients and factors.

When &lt;math&gt;G[X]&lt;/math&gt; is a factor of a modular quotient &lt;math&gt;G/P&lt;/math&gt;, it is possible that &lt;math&gt;G[X]&lt;/math&gt; can be recursively decomposed into factors and quotients.  Each level of the recursion gives rise to a quotient.  As a base case, the graph has only one vertex.  Collectively, &lt;math&gt;G&lt;/math&gt; can be reconstructed inductively by reconstructing the factors from the bottom up, inverting the steps of the decomposition by combining factors with the quotient at each level.

In the figure below, such a recursive decomposition is represented by a tree that  depicts one way of recursively decomposing factors of an initial modular partition into smaller modular partitions.

A way to recursively decompose a graph into factors and quotients may not be unique.  (For example, all subsets of the vertices of a complete graph are modules, which means that there are many different ways of decomposing it recursively.)  Some ways may be more useful than others.

== The modular decomposition ==

Fortunately, there exists such a recursive decomposition of a graph that implicitly represents all ways of decomposing it; this is the modular decomposition.  It is itself a way of decomposing a graph recursively into quotients, but it subsumes all others.  The decomposition depicted in the figure below is this special decomposition for the given graph.

[[File:ModularDecomposition.png|thumb|300px|A graph, its quotient where "bags" of vertices of the graph correspond to the children of the root of the modular decomposition tree, and its full modular decomposition tree: series nodes are labeled "s", parallel nodes "//" and prime nodes "p".]]

The following is a key observation in understanding the modular decomposition:

'''If &lt;math&gt;X&lt;/math&gt; is a module of &lt;math&gt;G&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; is a subset of &lt;math&gt;X&lt;/math&gt;''', then &lt;math&gt;Y&lt;/math&gt; is a module of &lt;math&gt;G&lt;/math&gt;, if and only if it is a module of &lt;math&gt;G[X]&lt;/math&gt;.

In (Gallai, 1967), Gallai defined the modular decomposition recursively on a graph with vertex set &lt;math&gt;V&lt;/math&gt;, as follows:

# As a base case, if &lt;math&gt;G&lt;/math&gt; only has one vertex, its modular decomposition is a single tree node.
# Gallai showed that if &lt;math&gt;G&lt;/math&gt; is connected and so is its complement, then the maximal modules that are proper subsets of &lt;math&gt;V&lt;/math&gt; are a partition of &lt;math&gt;V&lt;/math&gt;.  They are therefore a modular partition.  The quotient that they define is prime.  The root of the tree is labeled a ''prime'' node, and these modules are assigned as children of &lt;math&gt;V&lt;/math&gt;.  Since they are maximal, every module not represented so far is contained in a child &lt;math&gt;X&lt;/math&gt; of &lt;math&gt;V&lt;/math&gt;.  For each child &lt;math&gt;X&lt;/math&gt; of &lt;math&gt;V&lt;/math&gt;, replacing &lt;math&gt;X&lt;/math&gt; with the modular decomposition tree of &lt;math&gt;G[X]&lt;/math&gt; gives a representation of all modules of &lt;math&gt;G&lt;/math&gt;, by the key observation above.
# If &lt;math&gt;G&lt;/math&gt; is disconnected, its complement is connected.  Every union of connected components is a module of &lt;math&gt;G&lt;/math&gt;.  All other modules are subsets of a single connected component.  This represents all modules, except for subsets of connected components.  For each component &lt;math&gt;X&lt;/math&gt;, replacing &lt;math&gt;X&lt;/math&gt; by the modular decomposition tree of &lt;math&gt;G[X]&lt;/math&gt; gives a representation of all modules of &lt;math&gt;G&lt;/math&gt;, by the key observation above.  The root of the tree is labeled a ''parallel'' node, and it is attached in place of &lt;math&gt;X&lt;/math&gt; as a child of the root.  The quotient defined by the children is the complement of a complete graph.
# If the complement of &lt;math&gt;G&lt;/math&gt; is disconnected, &lt;math&gt;G&lt;/math&gt; is connected.   The subtrees that are children of &lt;math&gt;V&lt;/math&gt; are defined in a way that is symmetric with the case where &lt;math&gt;G&lt;/math&gt; is disconnected, since the modules of a graph are the same as the modules of its complement.  The root of the tree is labeled a ''serial'' node, and the quotient defined by the children is a complete graph.

The final tree has one-element sets of vertices of &lt;math&gt;G&lt;/math&gt; as its leaves, due to the base case.  A set &lt;math&gt;Y&lt;/math&gt; of vertices of &lt;math&gt;G&lt;/math&gt; is a module if and only if it is a node of the tree or a union of children of a series or parallel node.  This implicitly gives all modular partitions of &lt;math&gt;V&lt;/math&gt;.  It is in this sense that the modular decomposition tree "subsumes" all other ways of recursively decomposing &lt;math&gt;G&lt;/math&gt; into quotients.

==Algorithmic issues==

A data structure for representing the modular decomposition tree should support the operation that inputs a node and returns the set of vertices of &lt;math&gt;G&lt;/math&gt; that the node represents.  An obvious way to do this is to assign to each node a list of the &lt;math&gt;k&lt;/math&gt; vertices of &lt;math&gt;G&lt;/math&gt; that it represents.   Given a pointer to a node, this structure could return the set of vertices of &lt;math&gt;G&lt;/math&gt; that it represents in &lt;math&gt;\mathcal{O}(k)&lt;/math&gt; time.  However, this data structure would require &lt;math&gt;\Theta(n^2)&lt;/math&gt; space in the worst case. 
  
[[File:O n ModularDecompRep.pdf|thumb|An &lt;math&gt;\mathcal{O}(n)&lt;/math&gt; representation of the modular decomposition]]

An &lt;math&gt;\mathcal{O}(n)&lt;/math&gt;-space alternative that matches this performance  is obtained by representing the modular decomposition tree using any standard &lt;math&gt;\mathcal{O}(n)&lt;/math&gt; rooted-tree data structure and labeling each leaf with the vertex of &lt;math&gt;G&lt;/math&gt; that it represents.  The set represented by an internal node &lt;math&gt;v&lt;/math&gt; is given by the set of labels of its leaf descendants.  It is well known that any rooted tree with &lt;math&gt;k&lt;/math&gt; leaves has at most &lt;math&gt;k-1&lt;/math&gt; internal nodes.  One can use a depth-first search starting at &lt;math&gt;v&lt;/math&gt; to report the labels of leaf-descendants of &lt;math&gt;v&lt;/math&gt; in &lt;math&gt;\mathcal{O}(k)&lt;/math&gt; time.

[[File:ModDecompQuotients.pdf|thumb|The modular decomposition, augmented with a quotient on the children of each internal node, gives a complete representation of &lt;math&gt;G&lt;/math&gt;.]]

Each node &lt;math&gt;X&lt;/math&gt; is a set of vertices of &lt;math&gt;G&lt;/math&gt; and, if &lt;math&gt;X&lt;/math&gt; is an internal node, the set &lt;math&gt;P&lt;/math&gt; of children of &lt;math&gt;X&lt;/math&gt; is a partition of &lt;math&gt;X&lt;/math&gt; where each partition class is a module.  They therefore induce the quotient &lt;math&gt;G[X]/P&lt;/math&gt; in &lt;math&gt;G[X]&lt;/math&gt;.  The vertices of this quotient are the elements of &lt;math&gt;P&lt;/math&gt;, so &lt;math&gt;G[X]/P&lt;/math&gt; can be represented by installing edges among the children of &lt;math&gt;X&lt;/math&gt;.  If &lt;math&gt;Y&lt;/math&gt; and &lt;math&gt;Z&lt;/math&gt; are two members of &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;u \in Y&lt;/math&gt; and &lt;math&gt;v \in Z&lt;/math&gt;, then &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;v&lt;/math&gt; are adjacent in &lt;math&gt;G&lt;/math&gt; if and only if &lt;math&gt;Y&lt;/math&gt; and &lt;math&gt;Z&lt;/math&gt; are adjacent in this quotient.  For any pair &lt;math&gt;\{u,v\}&lt;/math&gt; of vertices of &lt;math&gt;G&lt;/math&gt;, this is determined by the quotient at children of the least common ancestor of &lt;math&gt;\{u\}&lt;/math&gt; and &lt;math&gt;\{v\}&lt;/math&gt; in the modular decomposition tree.  Therefore, the modular decomposition, labeled in this way with quotients, gives a complete representation of &lt;math&gt;G&lt;/math&gt;.

Many combinatorial problems can be solved on &lt;math&gt;G&lt;/math&gt; by solving the problem separately on each of these quotients.  For example, &lt;math&gt;G&lt;/math&gt; is a comparability graph if and only if each of these quotients is a comparability graph (Gallai, 67; Möhring, 85).  Therefore, to find whether a graph is a comparability graph, one need only find whether each of the quotients is.   In fact, to find a [[comparability graph|transitive orientation]] of a comparability graph, it suffices to transitively orient each of these quotients of its modular decomposition (Gallai, 67; Möhring, 85).  A similar phenomenon applies for permutation graphs, (McConnell and Spinrad '94), interval graphs (Hsu and Ma '99), perfect graphs, and other graph classes.  Some important combinatorial optimization problems on graphs can be solved using a similar strategy (Möhring, 85).

[[Cograph]]s are the graphs that only have parallel or series nodes in their modular decomposition tree.

The first polynomial algorithm to compute the modular decomposition tree of a graph was published in 1972  (James, Stanton &amp; Cowan 1972) and now linear algorithms are available (McConnell &amp; Spinrad 1999, Tedder et al. 2007, Cournier &amp; Habib 1994).

==Generalizations==
Modular decomposition of directed graphs can be done in linear time {{harv|McConnell|de Montgolfier|2005}}.

With a small number of simple exceptions, every graph with a nontrivial modular decomposition also has a [[skew partition]] {{harv|Reed|2008}}.

== References ==
*{{cite journal
  | last = Gallai | first = Tibor | authorlink = Tibor Gallai
  | title = Transitiv orientierbare Graphen
  | journal = Acta Mathematica Academiae Scientiarum Hungaricae
  | volume = 18
  | year = 1967
  | pages = 25–66
  | mr = 0221974
  | doi = 10.1007/BF02020961}}
*{{cite book
  | last1 = James | first1 = Lee O. | last2 = Stanton | first2 = Ralph G. | last3 = Cowan | first3 = Donald D.
  | contribution = Graph decomposition for undirected graphs
  | title = Proc. 3rd Southeastern International Conference on Combinatorics, Graph Theory, and Computing (Florida Atlantic Univ., Boca Raton, Fla., 1972)
  | publisher = [[Florida Atlantic University]]
  | year = 1972
  | pages = 281–290
  | mr = 0351909
}}
*{{cite book
  | last1 = Golumbic | first1=Martin C. 
  | publisher = Academic Press
  | year = 1980
  | title = Algorithmic Graph Theory and Perfect Graphs
  | isbn = 0-444-51530-5}}
*{{cite journal
  | doi = 10.1137/S0097539792224814
  | last1 = Hsu | first1 = W.L. | last2 = Ma | first2 = T.
  | title = Fast and simple algorithms for recognizing chordal comparability graphs and interval graphs
  | journal = SIAM Journal on Computing 
  | volume = 28
  | issue = 3
  | year = 1999
  | pages = 1004–1020| citeseerx = 10.1.1.104.4647}}
*{{cite journal
 | last1 = McConnell | first1 = Ross M.
 | last2 = de Montgolfier | first2 = Fabien
 | doi = 10.1016/j.dam.2004.02.017
 | issue = 2
 | journal = Discrete Applied Mathematics
 | pages = 198–209
 | title = Linear-time modular decomposition of directed graphs
 | volume = 145
 | year = 2005
 | ref = harv}}
*{{cite journal
  | last1 = McConnell | first1 = Ross M. | last2 = Spinrad | first2 = Jeremy P.
  | title = Modular decomposition and transitive orientation
  | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
  | volume = 201
  | year = 1999
  | pages = 189–241
  | url = http://www.cs.colostate.edu/~rmm/linto.pdf
  | mr = 1687819
  | doi = 10.1016/S0012-365X(98)00319-7}}
*{{cite journal
  | last1 = Möhring | first1 = Rolf H.
  | title = Algorithmic aspects of comparability graphs and interval graphs
  | journal = Graphs and Order
  | editor = I. Rival
  | publisher = D. Reidel
  | year = 1985
  | pages = 41–101}}
*{{cite journal
   | doi = 10.1007/BF02022041
   | last1 = Möhring | first1 = Rolf H.
   | title   = Algorithmic aspects of the substitution decomposition in optimization over relations, set systems and Boolean functions
   | journal = Annals of Operations Research
   | volume  = 4
   | year    = 1985
   | pages = 195–225}}
*{{cite book
  | last1 = Papadopoulos | first1 = Charis | last2 = Voglis | first2 = Constantinos
  | contribution = Drawing graphs using modular decomposition
  | title = [[International Symposium on Graph Drawing|Proc. 13th International Symposium on Graph Drawing (GD'05)]]
  | series = Lecture Notes in Computer Science
  | publisher = Springer-Verlag
  | volume = 3843
  | year = 2005
  | pages = 343–354
  | contribution-url = http://www.ii.uib.no/~charis/files/DrawModular.pdf
  | mr = 2229205
  | doi = 10.1007/11618058_31}}
*{{cite journal
 | last = Reed | first = Bruce | authorlink = Bruce Reed (mathematician)
 | doi = 10.1016/j.dam.2007.05.054
 | issue = 7
 | journal = Discrete Applied Mathematics
 | mr = 2404228
 | pages = 1150–1156
 | title = Skew partitions in perfect graphs
 | url = http://cgm.cs.mcgill.ca/~reedbook/papers/SkewPartitionsPerfectGraphs.pdf
 | volume = 156
 | year = 2008
 | ref=harv}}
*{{cite book
  | last1 = Spinrad | first1=Jeremy P. 
  | series = Fields Institute Monographs
  | publisher = American Mathematical Society
  | year = 2003
  | title = Efficient Graph Representations
  | isbn = 0-8218-2815-0}}
*{{cite book
  | last1 = Tedder | first1 = Marc | last2 = Corneil | first2 = Derek | author2-link = Derek Corneil
  | last3 = Habib | first3 = Michel | last4 = Paul | first4 = Christophe
  | contribution = Simpler Linear-Time Modular Decomposition Via Recursive Factorizing Permutations
  | series = Lecture Notes in Computer Science
  | publisher = Springer-Verlag
  | volume = 5125
  | year = 2008
  | pages = 634–645
  | arxiv = 0710.3901
  | doi = 10.1007/978-3-540-70575-8_52
  | title = [[International Colloquium on Automata, Languages and Programming|Proc. 35th International Colloquium on Automata, Languages and Programming (ICALP 2008)]]}}
*{{cite journal
| last1 = Zahedi | first1 = Emad | author1-link = Emad Zahedi | last2 = Smith | first2 = Jason 
 | issue = 7
 | journal = Discrete Applied Mathematics
 | title = Modular Decomposition of Graphs and the Distance Preserving Property
 | url = https://drive.google.com/file/d/1e0hee-GDIGEb30ATgGh-r9vZX1p-cuTK/view
 | year = 2018
 | ref=harv}}

== External links ==
* A [[Perl]] [http://search.cpan.org/~azs/Graph-ModularDecomposition-0.15/ implementation of a modular decomposition algorithm]
* A Java [http://code.google.com/p/bpstruct/ implementation of a modular decomposition algorithm]

[[Category:Graph theory objects]]</text>
      <sha1>tplbvyimnn55opt60y9smbx2uj20xmx</sha1>
    </revision>
  </page>
  <page>
    <title>Nine-point conic</title>
    <ns>0</ns>
    <id>44779201</id>
    <revision>
      <id>799285487</id>
      <parentid>733600867</parentid>
      <timestamp>2017-09-06T19:46:57Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3344">[[File:Nine point conic.svg|right|thumb|400px|Nine point conic]]

In [[geometry]], the '''nine-point conic''' of a [[complete quadrangle]] is a [[conic section|conic]] that passes through the three diagonal points and the six midpoints of sides of the complete quadrangle.

The nine-point [[conic section|conic]] was described by [[Maxime Bôcher]] in 1892. The better-known [[nine-point circle]] is an  instance of Bôcher's conic. The [[nine-point hyperbola]] is another instance.

Bôcher used the four points of the complete quadrangle as three vertices of a triangle with one independent point:
:Given a triangle ''ABC'' and a point ''P'' in its plane, a conic can be drawn through the following nine points:
:: the [[midpoint]]s of the sides of ''ABC'',
:: the midpoints of the lines joining ''P'' to the vertices, and
:: the points where these last named lines cut the sides of the triangle.
The conic is an [[ellipse]] if ''P'' lies in the interior of ''ABC'' or in one of the regions of the plane separated from the interior by two sides of the triangle, otherwise the conic is a [[hyperbola]]. Bôcher notes that when ''P'' is the [[orthocenter]], one obtains the nine-point circle, and when ''P'' is on the [[circumcircle]] of ''ABC'', then the conic is an equilateral hyperbola.

In 1912 Maud Minthorn showed that the nine-point conic is the locus of the center of a conic through four given points.

==References==
* [[Maxime Bôcher]] (1892) [https://www.jstor.org/stable/1967142 Nine-point Conic], [[Annals of Mathematics]], link from [[Jstor]].
* Fanny Gates (1894) [https://www.jstor.org/stable/1967957?seq=1#page_scan_tab_contents Some Considerations on the Nine-point Conic and its Reciprocal], [[Annals of Mathematics]] 8(6):185–8, link from Jstor.
* Maud A. Minthorn (1912) [http://babel.hathitrust.org/cgi/pt?id=uc1.b3808276;view=1up;seq=1 The Nine Point Conic], Master's dissertation at [[University of California, Berkeley]], link from [[HathiTrust]].
* Eric W. Weisstein [http://mathworld.wolfram.com/Nine-PointConic.html Nine-point conic] from [[MathWorld]].
* Michael DeVilliers (2006) [http://www.tandfonline.com/doi/pdf/10.1080/00207390500138025 The nine-point conic: a rediscovery and proof by computer] from ''International Journal of Mathematical Education in Science and Technology'', a [[Taylor &amp; Francis]] publication.
* Christopher Bradley [http://people.bath.ac.uk/masgcs/Article119.pdf The Nine-point Conic and a Pair of Parallel Lines] from [[University of Bath]].

==Further reading==
* W. G. Fraser (1906) "On relations of certain conics to a triangle", [[Proceedings of the Edinburgh Mathematical Society]] 25:38–41.
* Thomas F. Hogate (1894) [https://www.jstor.org/stable/1967883?seq=1#page_scan_tab_contents On the Cone of Second Order which is Analogous to the Nine-point Conic], ''Annals of Mathematics'' 7:73–6.
* P. Pinkerton (1905) "On a nine-point conic, etc.", ''Proceedings of the Edinburgh Mathematical Society'' 24:31–3.
== External links ==
* [http://dynamicmathematicslearning.com/ninepointconic.html Nine-point conic and Euler line generalization] at [http://dynamicmathematicslearning.com/JavaGSPLinks.htm Dynamic Geometry Sketches]

[[Category:Theorems in geometry]]
[[Category:Theorems in plane geometry]]
[[Category:Euclidean plane geometry]]
[[Category:Projective geometry]]</text>
      <sha1>cw3dhzjx0pqbclfo8g6obxevpqy7lfh</sha1>
    </revision>
  </page>
  <page>
    <title>Non-monotonic logic</title>
    <ns>0</ns>
    <id>341086</id>
    <revision>
      <id>838697337</id>
      <parentid>829020864</parentid>
      <timestamp>2018-04-28T18:38:01Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>see MOS:SECTIONORDER</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8006">{{more footnotes|date=June 2008}}
A '''non-monotonic logic''' is a [[formal logic]] whose [[Logical consequence|consequence]] [[Relation (mathematics)|relation]] is not [[Monotonicity of entailment|monotonic]]. In other words, non-monotonic logics are devised to capture and represent defeasible inferences (cf. [[defeasible reasoning]]), i.e., a kind of inference in which reasoners draw tentative conclusions, enabling reasoners to retract their conclusion(s) based on further evidence.&lt;ref&gt;{{cite web|last1=Strasser|first1=Christian|last2=Antonelli|first2=G. Aldo|title=Non-Monotonic Logic|url=http://plato.stanford.edu/entries/logic-nonmonotonic/|website=http://plato.stanford.edu/index.html|publisher=Stanford Encyclopedia of Philosophy|accessdate=19 March 2015|ref=http://plato.stanford.edu/entries/logic-nonmonotonic/}}&lt;/ref&gt;
Most studied formal logics have a monotonic consequence relation, meaning that adding a formula to a theory never produces a reduction of its set of consequences. Intuitively, monotonicity indicates that learning a new piece of knowledge cannot reduce the set of what is known. A monotonic logic cannot handle various reasoning tasks such as [[Default logic|reasoning by default]] (consequences may be derived only because of lack of evidence of the contrary), [[abductive reasoning]] (consequences are only deduced as most likely explanations), some important approaches  to reasoning about knowledge (the ignorance of a consequence must be retracted when the consequence becomes known), and similarly, [[belief revision]] (new  knowledge may contradict old beliefs).

==Abductive reasoning==

[[Abductive reasoning]] is the process of deriving the most likely explanations of the known facts. An abductive logic should not be monotonic because the most likely explanations are not necessarily correct. For example, the most likely explanation for seeing wet grass is that it rained; however, this explanation has to be retracted when learning that the real cause of the grass being wet was a sprinkler. Since the old explanation (it rained) is retracted because of the addition of a piece of knowledge (a sprinkler was active), any logic that models explanations is non-monotonic.

==Reasoning about knowledge==

If a logic includes formulae that mean that something is not known, this logic should not be monotonic. Indeed, learning something that was previously not known leads to the removal of the formula specifying that this piece of knowledge is not known. This second change (a removal caused by an addition) violates the condition of monotonicity. A logic for reasoning about knowledge is the [[autoepistemic logic]].

==Belief revision==

[[Belief revision]] is the process of changing beliefs to accommodate a new belief that might be inconsistent with the old ones. In the assumption that the new belief is correct, some of the old ones have to be retracted in order to maintain consistency. This retraction in response to an addition of a new belief makes any logic for belief revision to be non-monotonic. The belief revision approach is alternative to [[paraconsistent logics]], which tolerate inconsistency rather than attempting to remove it.

==Proof-theoretic versus model-theoretic formalizations of non-monotonic logics==

Proof-theoretic formalization of a non-monotonic logic begins with adoption of certain non-monotonic [[rules of inference]], and then prescribes contexts in which these non-monotonic rules may be applied in admissible deductions. This typically is accomplished by means of fixed-point equations that relate the sets of premises and the sets of their non-monotonic conclusions. [[default logic|Default logic]] and [[autoepistemic logic]] are the most common examples of non-monotonic logics that have been formalized that way.&lt;ref name="Suchenek"&gt;{{citation
 | last1 = Suchenek | first1 = Marek A.
 | title = Notes on Nonmonotonic Autoepistemic Propositional Logic
 | pages = 74–93
 | publisher = Warsaw School of Computer Science
 | journal = Zeszyty Naukowe
 | issue = 6
 | year = 2011
 | url = http://zeszyty-naukowe.wwsi.edu.pl/zeszyty/zeszyt6/NotesonNonmonotonicAutoepistemicPropositionalLogic.pdf}}.&lt;/ref&gt;

Model-theoretic formalization of a non-monotonic logic begins with restriction of the [[semantics]] of a suitable monotonic logic to some special models, for instance, to minimal models, and then derives the set of non-monotonic [[rules of inference]], possibly with some restrictions in which contexts these rules may be applied, so that the resulting deductive system is [[Soundness|sound]] and [[Completeness (logic)|complete]] with respect to the restricted [[semantics]]. Unlike some proof-theoretic formalizations that suffered from well-known paradoxes and were often hard to evaluate with respect of their consistency with the intuitions they were supposed to capture, model-theoretic formalizations were paradox-free and left little, if any, room for confusion about what non-monotonic patterns of reasoning they covered. Examples of proof-theoretic formalizations of non-monotonic reasoning, which revealed some undesirable or paradoxical properties or did not capture the desired intuitive comprehensions, that have been successfully (consistent with respective intuitive comprehensions and with no paradoxical properties, that is) formalized by model-theoretic means include [[Circumscription (logic)|first-order circumscription]], [[closed-world assumption]], and [[autoepistemic logic]].&lt;ref name="Suchenek" /&gt;

==See also==
{{Portal|Logic}}

* [[Logic programming]]
* [[Negation as failure]]
* [[Stable model semantics]]
* [[Rational consequence relation]]

==Notes==
{{reflist}}

==References==
* N. Bidoit and R. Hull (1989) "[http://www.sciencedirect.com/science/article/pii/0022000089900044 Minimalism, justification and non-monotonicity in deductive databases]," ''Journal of Computer and System Sciences 38'': 290-325.
* G. Brewka (1991). ''[https://books.google.com/books?id=S41BSy8Xk44C&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Nonmonotonic Reasoning: Logical Foundations of Commonsense]''. Cambridge University Press.
* G. Brewka, J. Dix, K. Konolige (1997). ''Nonmonotonic Reasoning - An Overview''. CSLI publications, Stanford.
* M. Cadoli and M. Schaerf (1993) "[http://www.sciencedirect.com/science/article/pii/074310669390029G A survey of complexity results for non-monotonic logics]" ''Journal of Logic Programming 17'': 127-60.
* F. M. Donini, M. Lenzerini, D. Nardi, F. Pirri, and M. Schaerf (1990) "Nonmonotonic reasoning," ''Artificial Intelligence Review 4'': 163-210.
* M. L. Ginsberg, ed. (1987) ''Readings in Nonmonotonic Reasoning''. Los Altos CA: Morgan Kaufmann.
*Horty, J. F., 2001, "Nonmonotonic Logic," in Goble, Lou, ed., ''The Blackwell Guide to Philosophical Logic''. Blackwell.
* W. Lukaszewicz (1990) ''Non-Monotonic Reasoning''. Ellis-Horwood, Chichester, West Sussex, England.
* C.G. Lundberg (2000) "[https://pdfs.semanticscholar.org/cce4/b4fa69ed4c7cf997f1fbf38542c247bb19ea.pdf Made sense and remembered sense: Sensemaking through abduction]," ''Journal of Economic Psychology'': 21(6), 691-709.
* D. Makinson (2005) ''[https://www.researchgate.net/profile/David_Makinson3/publication/262934388_Bridges_from_Classical_to_Nonmonotonic_Logic/links/54bfe86a0cf28a6324a00672.pdf Bridges from Classical to Nonmonotonic Logic]'', College Publications.
* W. Marek and M. Truszczynski (1993) ''[https://books.google.com/books?id=W-apCAAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Nonmonotonic Logics: Context-Dependent Reasoning]''. Springer Verlag.
* A. Nait Abdallah (1995) ''The Logic of Partial Information''. Springer Verlag.

==External links==
* {{cite SEP |url-id=logic-nonmonotonic |title=Non-monotonic logic |last=Antonelli |first=G. Aldo}}
* {{PhilPapers|category|nonmonotonic-logic}}
* {{InPho|idea|1208}}

{{Logic}}

[[Category:Belief revision]]
[[Category:Formal epistemology]]
[[Category:Logic]]
[[Category:Non-classical logic]]
[[Category:Reasoning]]</text>
      <sha1>nqoeem63psc1pmnuotv0by5k77zz0kp</sha1>
    </revision>
  </page>
  <page>
    <title>Nonabelian cohomology</title>
    <ns>0</ns>
    <id>40814966</id>
    <revision>
      <id>739451182</id>
      <parentid>723454926</parentid>
      <timestamp>2016-09-14T19:25:03Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <minor/>
      <comment>[[User:Green Cardamom/WaybackMedic 2|WaybackMedic 2]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1271">In mathematics, a '''nonabelian cohomology''' is any [[cohomology]] with coefficients in a [[nonabelian group]], a [[sheaf (mathematics)|sheaf]] of nonabelian groups or even in a [[topological space]].

If [[homology (mathematics)|homology]] is thought of as the [[abelianization]] of [[homotopy]] (cf. [[Hurewicz theorem]]), then the nonabelian cohomology may be thought of as a dual of [[homotopy group]]s.

== Nonabelian Poincaré duality ==
{{expand section|date=October 2013}}
See: [http://www.math.harvard.edu/~lurie/282ynotes/LectureVIII-Poincare.pdf Nonabelian Poincare Duality (Lecture 8)]

== See also ==
*[[Stack (mathematics)|Stacks]]
*[[Group cohomology]]

== References ==
* {{cite web|first=B. |last=Toën |url=http://www.math.univ-montp2.fr/~toen/msri2002.pdf |title=Stacks and non-abelian cohomology |deadurl=yes |archiveurl=https://web.archive.org/web/20140114023724/http://www.math.univ-montp2.fr/~toen/msri2002.pdf |archivedate=January 14, 2014 }}
* {{cite book | last=Lurie | first=Jacob | title=[[Higher Topos Theory]] | zbl=1175.18001 | series=Annals of Mathematics Studies | volume=170 | location=Princeton, NJ | publisher=[[Princeton University Press]] | isbn=978-0-691-14049-0 | year=2009 }}


{{topology-stub}}

[[Category:Cohomology theories]]</text>
      <sha1>bcofeji364wsmxrkufz6yflhcrjpdii</sha1>
    </revision>
  </page>
  <page>
    <title>Numéraire</title>
    <ns>0</ns>
    <id>1457116</id>
    <revision>
      <id>846138291</id>
      <parentid>846138108</parentid>
      <timestamp>2018-06-16T16:02:26Z</timestamp>
      <contributor>
        <ip>142.119.72.223</ip>
      </contributor>
      <comment>/* Change of numéraire */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4353">{{no footnotes|date=October 2011}}
The '''numéraire''' (or '''numeraire''') is a basic standard by which value is computed. In [[mathematical economics]] it is a tradeable economic entity in terms of whose price the [[relative price]]s of all other tradeables are expressed. In a [[monetary economy]],  acting as the numéraire is one of the functions of [[money]], to serve as a [[unit of account]]: to provide a common benchmark relative to which the worths of various [[good (economics)|goods]] and services are measured. Using a numeraire, whether monetary or some consumable good, facilitates value comparisons when only the relative prices are relevant, as in [[general equilibrium theory]]. When economic analysis refers to a particular good as the numéraire, one says that all other prices are '''normalized''' by the price of that good. For example, if a unit of good ''g'' has twice the market value of a unit of the numeraire, then the (relative) price of ''g'' is 2. Since the value of one unit of the numeraire relative to one unit of itself is 1, the price of the numeraire is always 1.

== Change of numéraire ==

:''The notation in this section needs to be defined.''

In a financial market with traded securities, one may use a change of numéraire to price assets.  For instance, if &lt;math&gt;M(t) = \exp\left(\int_0^t r(s) ds\right)&lt;/math&gt; is the price at time &lt;math&gt;t&lt;/math&gt; of $1 that was invested in the money market at time 0, then the [[Fundamental theorem of asset pricing|Fundamental Theorem of Asset Pricing]] says that all assets (say &lt;math&gt;S(t)&lt;/math&gt;), '''priced in terms of the money market''', are [[Martingale (probability theory)|martingales]] with respect to the [[risk-neutral measure]], (say &lt;math&gt;Q&lt;/math&gt;).  That is

: &lt;math&gt;\frac{S(t)}{M(t)} = E_Q\left[\left.\frac{S(T)}{M(T)} \right| \mathcal{F}(t)\right]\qquad \forall\, t \leq T.&lt;/math&gt;

Now, suppose that &lt;math&gt;N\left(t\right) &gt;0 &lt;/math&gt; is another strictly positive traded asset (and hence a martingale when priced in terms of the money market).  Then, we can define a new probability measure &lt;math&gt;Q^N&lt;/math&gt; by the [[Radon–Nikodym derivative]]

: &lt;math&gt;\frac{dQ^N}{dQ} = \frac{M(0)}{M(T)}\frac{N(T)}{N(0)}.&lt;/math&gt;

Then, by using the abstract [[Bayes' Rule]] it can be shown that &lt;math&gt;S(t)&lt;/math&gt; is a martingale under &lt;math&gt;Q^N&lt;/math&gt; when priced in terms of the new numéraire, &lt;math&gt;N(t)&lt;/math&gt;:

: &lt;math&gt;
\begin{align}
&amp; {} \quad E_{Q^N}\left[\left.\frac{S(T)}{N(T)}\right| \mathcal{F}(t)\right] \\
&amp; = E_{Q}\left[\left.\frac{M(0)}{M(T)}\frac{N(T)}{N(0)}\frac{S(T)}{N(T)}\right| \mathcal{F}(t)\right]/ E_Q\left[\left.\frac{M(0)}{M(T)}\frac{N(T)}{N(0)}\right| \mathcal{F}(t)\right] \\
&amp; = \frac{M(t)}{N(t)}E_{Q}\left[\left.\frac{S(T)}{M(T)}\right| \mathcal{F}(t)\right]= \frac{M(t)}{N(t)}\frac{S(t)}{M(t)} = \frac{S(t)}{N(t)}.
\end{align}
&lt;/math&gt;

This technique has many important applications in [[LIBOR]] and [[swap (finance)|swap]] market models, as well as commodity markets. [[Farshid Jamshidian|Jamshidian]] (1989) first used it in the context of the [[Vasicek model]] for interest rates in order to calculate bond options prices. Geman, El Karoui and Rochet (1995) introduced the general formal framework for the change of numéraire technique. See for example Brigo and Mercurio (2001) for a change of numéraire toolkit.

== See also ==
*[[Price index]]
*[[Forward measure]]
*[[Unit of account]]

==References==
*{{cite journal|author=[[Farshid Jamshidian]]|year=1989|title=An Exact Bond Option Pricing Formula|journal=The Journal of Finance|volume=44|pages=205–209|doi=10.1111/j.1540-6261.1989.tb02413.x}}
*{{cite journal|author1=[[Helyette Geman]]|author2=[[Nicole El Karoui]]|author3=J.C. Rochet|year=1995|title=Changes of Numeraire, Changes of Probability Measures and Pricing of Options|journal=Journal of Applied Probability|volume=32|pages=443–458|doi=10.2307/3215299}}
*{{cite book | title = Interest Rate Models &amp;ndash; Theory and Practice with Smile, Inflation and Credit| author1 = [[Damiano Brigo]] | author2 = [[Fabio Mercurio]] | publisher = Springer Verlag | origyear = 2001 | edition = 2 | year = 2006 | isbn = 978-3-540-22149-4}}

{{DEFAULTSORT:Numeraire}}
[[Category:General equilibrium theory]]
[[Category:Mathematical finance]]
[[Category:Stock market]]
[[Category:Finance theories]]
[[Category:Stochastic processes]]</text>
      <sha1>pzw6zaug0qj2xwx5z3iyh89zrlrnaqz</sha1>
    </revision>
  </page>
  <page>
    <title>Octacube (sculpture)</title>
    <ns>0</ns>
    <id>11870817</id>
    <revision>
      <id>858593654</id>
      <parentid>853693784</parentid>
      <timestamp>2018-09-08T08:24:34Z</timestamp>
      <contributor>
        <username>Dimadick</username>
        <id>24198</id>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14751">{{About|the steel sculpture|other uses of the word|Octacube (disambiguation){{!}}Octacube}}
{{italic title}}
[[Image:Ocnacube.jpg|thumb|300px|right|The ''Octacube'' and its designer, Adrian Ocneanu]][[File:Animated Octacube Render.gif|thumb|300x300px|An animated rendering of the ''Octacube'' by Adrian Ocneanu.]]The '''''Octacube''''' is a large, steel sculpture of a mathematical object: the [[24-cell]] or "octacube".  Because a real 24-cell is [[Four-dimensional space|four-dimensional]], the artwork is actually a [[Map projection|projection]] into the three-dimensional world.  ''Octacube'' has very high intrinsic [[symmetry]], which matches features in chemistry ([[molecular symmetry]]) and physics ([[quantum field theory]]).

The sculpture was designed by Adrian Ocneanu, a mathematics professor at [[Pennsylvania State University]].  The university's machine shop spent over a year completing the intricate metal-work.  ''Octacube'' was funded by an alumna in memory of her husband, Kermit Anderson, who died in the [[September 11 attacks]].  The sculpture is displayed in the lobby of Penn State's math department.

==Artwork==

The ''Octacube's'' metal skeleton measures about 6 feet (2 meters) in all three dimensions.  It is a complex arrangement of unpainted, tri-cornered flanges.  The base is a 3-foot (1 meter) high granite block, with some engraving.&lt;ref name="PS1" /&gt;

The artwork was designed by Adrian Ocneanu, a Penn State mathematics professor.  He supplied the specifications for the sculpture's 96 triangular pieces of stainless steel and for their assembly.  Fabrication was done by Penn State's machine shop, led by Jerry Anderson.  The work took over a year, involving bending and welding as well as cutting.  Discussing the construction, Ocneanu said:&lt;ref name="PS1" /&gt; &lt;blockquote&gt;It's very hard to make 12 steel sheets meet perfectly—and conformally—at each of the 23 vertices, with no trace of welding left. The people who built it are really world-class experts and perfectionists—artists in steel.&lt;/blockquote&gt;
Because of the reflective metal at different angles, the appearance is pleasantly strange.  In some cases, the mirror-like surfaces create an illusion of transparency by showing reflections from unexpected sides of the structure.  The sculpture's mathematician creator commented:&lt;ref name="PS1"/&gt; &lt;blockquote&gt;When I saw the actual sculpture, I had quite a shock.  I never imagined the play of light on the surfaces. There are subtle optical effects that you can feel but can't quite put your finger on.&lt;/blockquote&gt;
&lt;gallery class="center" heights="240px" widths="240px" caption="Views of the Octacube from multiple angles"&gt;
File:OctacCrop.jpg
File:OctacCorner.jpg
File:OctacSideFull.jpg
&lt;/gallery&gt;

==Interpretation==

===Regular shapes===

The [[Platonic solids]] are three-dimensional shapes with special, high, [[symmetry]].  They are the next step up in dimension from the two-dimensional [[regular polygons]] (squares, equilateral triangles, etc.).  The five Platonic solids are the [[tetrahedron]] (4 faces), [[cube]] (6 faces), [[octahedron]] (8 faces),  [[dodecahedron]] (12 faces), and [[icosahedron]] (20 faces).  They have been known since the time of the Ancient Greeks and valued for their aesthetic appeal and philosophical, even mystical, import.  (See also the ''[[Timaeus (dialogue)|Timaeus]]'', a [[Plato's dialogues|dialogue of Plato]].)

{| class="wikitable" style="margin: 1em auto 1em auto;" 	
|-
|colspan=5 align=center|'''The Platonic solids'''
|-
|align=center|[[Image:Tetrahedron.jpg|100px]]
|align=center|[[Image:Hexahedron.jpg|100px]]
|align=center|[[Image:Octahedron.svg|100px]]
|align=center|[[Image:POV-Ray-Dodecahedron.svg|100px]]
|align=center|[[Image:Icosahedron.jpg|100px]]
|- align=center
|Tetrahedron||Cube||Octahedron||Dodecahedron||Icosahedron
|}

In higher dimensions, the counterparts of the Platonic solids are the [[regular polytope]]s.  These shapes were first described in the mid-19th century by a Swiss mathematician, [[Ludwig Schläfli]]. In four dimensions, there are [[Convex regular polychoron|six of them]]: the pentachoron ([[5-cell]]), tesseract ([[8-cell]]), hexadecachoron ([[16-cell]]), octacube ([[24-cell]]), hecatonicosachoron ([[120-cell]]), and the hexacosichoron ([[600-cell]]).

The 24-cell consists of 24 [[octahedron]]s, joined in 4-dimensional space.  The 24-cell's [[vertex figure]] (the 3-D shape formed when a 4-D corner is cut off) is a cube.  Despite its suggestive name, the octacube is not the 4-D analog of either the octahedron or the cube.  In fact, it is the only one of the six 4-D regular polytopes that lacks a corresponding Platonic solid.{{#tag:ref|The 4-D analog of the cube is the 8-celled tesseract. (In a similar manner, the cube is the 3-D analog of the square.)  The 4-D analog of the octahedron is the 16-celled hexadecachoron.||group="note"}}

{| class="wikitable" cellpadding="0" cellspacing="0" style="margin:1em auto 1em auto; text-align:center;"
|-
| colspan="3" style="text-align:center; padding-bottom:.6em;"| '''Attempts to picture the 24-cell'''
|-
| style="padding-right:20px;" | [[File:Schlegel wireframe 24-cell.png|254px]]
| style="padding-left:20px;" | [[File:24-cell.gif|240px]]
|- style="text-align:center;"
| style="padding-top:.4em;" | [[Schlegel diagram]]
| style="padding-top:.4em;" | 4-dimensional rotation
|}

===Projections===

[[File:Usgs map stereographic.PNG|thumb|500px|[[Stereographic projection]] of the Earth]]

Ocneanu explains the conceptual challenge in working in the fourth dimension:&lt;ref name="PS1"/&gt;  "Although mathematicians can work with a fourth dimension abstractly by adding a fourth coordinate to the three that we use to describe a point in space, a fourth spatial dimension is difficult to visualize."

Although it is impossible to see or make 4-dimensional objects, it is possible to map them into lower dimensions to get some impressions of them.  An analogy for converting the 4-D 24-cell into its 3-D sculpture is [[map projection|cartographic projection]], where the surface of the 3-D Earth (or a globe) is reduced to a flat 2-D plane (a portable map).  This is done either with light 'casting a shadow' from the globe onto the map or with some mathematical transformation.  Many different types of map projection exist: the familiar rectangular [[Mercator projection|Mercator]] (used for navigation), the circular [[gnomonic projection|gnomonic]] (first projection invented), and several others.  All of them have limitations in that they show some features in a distorted manner—'you can't flatten an orange peel without damaging it'—but they are useful visual aids and convenient references.

[[File:stereographic polytope 24cell faces.png|thumb|Stereographic projection of a 24-cell]]

In the same manner that the exterior of the Earth is a 2-D skin (bent into the third dimension), the exterior of a 4-dimensionsal shape is a 3-D space (but folded through hyperspace, the fourth dimension).  However, just as the surface of Earth's globe can not be mapped onto a plane without some distortions, neither can the exterior 3-D shape of the 24-cell 4-D hyper-shape.  In the image on the right a 24-cell is shown projected into space as a 3-D object (and then the image is a 2-D rendering of it, with [[perspective (art)|perspective]] to aid the eye).  Some of the distortions:
*Curving edge lines:  these are straight in four dimensions, but the projection into a lower dimension makes them appear to curve (similar effects occur when mapping the Earth).
*It is necessary to use semi-transparent faces because of the complexity of the object, so the many "boxes" (octahedral cells) are seen.
*Only 23 cells are clearly seen.  The 24th cell is the "outside in", the whole exterior space around the object as seen in three dimensions.

To map the 24-cell, Ocneanu uses a related projection which he calls ''windowed radial stereographic projection''.  As with the stereographic projection, there are curved lines shown in 3-D space.  Instead of using semitransparent surfaces, "windows" are cut into the faces of the cells so that interior cells can be seen.  Also, only 23 vertices are physically present.  The 24th vertice "occurs at infinity" because of the projection; what one sees is the 8 legs and arms of the sculpture diverging outwards from the center of the 3-D sculpture.&lt;ref name="PS1"/&gt;

===Symmetry===

[[File:Sphere symmetry group oh.png|thumb|Octahedral symmetry diagram showing mirror planes as [[great circle]]s (6 red, 3 blue).  Rotation axes are also shown: 2-fold (pink diamonds), 3-fold (red triangles), and four-fold (blue squares).]]

The ''Octacube'' sculpture has very high symmetry. The stainless steel structure has the same amount of symmetry as a cube or an octahedron. The artwork can be visualized as related to a cube: the arms and legs of the structure extend to the corners. Imagining an octahedron is more difficult; it involves thinking of the faces of the visualized cube forming the corners of an octahedron. The cube and octahedron have the same amount and type of symmetry:  [[octahedral symmetry]], called O&lt;sub&gt;h&lt;/sub&gt; (order 48) in mathematical notation. Some, but not all, of the symmetry elements are
*3 different four-fold rotation axes (one through each pair of opposing faces of the visualized cube): up/down, in/out and left/right as seen in the photograph
*4 different three-fold rotation axes (one through each pair of opposing corners of the cube [along each of the opposing arm/leg pairs])
*6 different two-fold rotation axes (one through the midpoint of each opposing edge of the visualized cube)
*9 mirror planes that bisect the visualized cube
**3 that cut it top/bottom, left/right and front/back. These mirrors represent its reflective [[dihedral symmetry|dihedral subsymmetry]] D&lt;sub&gt;2h&lt;/sub&gt;, order 8 (a subordinate symmetry of any object with octahedral symmetry)
**6 that go along the diagonals of opposing faces of the visualized cube (these go along double sets of arm-leg pairs). These mirrors represent its reflective [[tetrahedral symmetry|tetrahedral subsymmetry]] T&lt;sub&gt;d&lt;/sub&gt;, order 24 (a subordinate symmetry of any object with octahedral symmetry).

===Science allusions===

Many molecules have the same symmetry as the ''Octacube'' sculpture. The organic molecule, [[cubane]] (C&lt;sub&gt;8&lt;/sub&gt;H&lt;sub&gt;8&lt;/sub&gt;) is one example. The arms and legs of the sculpture are similar to the outward projecting hydrogen atoms. [[Sulfur hexafluoride]] (or any molecule with exact [[octahedral molecular geometry]]) also shares the same symmetry although the resemblance is not as similar.

{| class=wikitable align=center
|+ Molecules with the same symmetry
|-
| [[File:Cubane-3D-balls.png|160px]]
| [[File:Sulfur-hexafluoride-3D-balls.png|160px]]
|- align=center
| Cubane
| Sulfur hexafluoride
|}

The ''Octacube'' also shows parallels to concepts in theoretical physics. Creator Ocneanu researches mathematical aspects of [[quantum field theory]] (QFT). The subject has been described by a [[Fields medal]] winner, [[Ed Witten]], as the most difficult area in physics.&lt;ref&gt;{{Cite web|title=Beautiful Minds, Vol. 20: Ed Witten|url=http://temi.repubblica.it/iniziative-beautifulminds/|publisher=[[la Repubblica]]|year=2010|accessdate=22 June 2012}} [https://www.youtube.com/watch?v=zPganhQDnzM&amp;t=2m22s Here].&lt;/ref&gt;  Part of Ocneanu's work is to build theoretical, and even physical, models of the symmetry features in QFT.  Ocneanu cites the relationship of the inner and outer halves of the structure as analogous to the relationship of [[spin 1/2 particles]] (e.g. [[electrons]]) and [[spin 1 particles]] (e.g. [[photons]]).&lt;ref name="PS1"/&gt;

==Memorial==

''Octacube'' was commissioned and funded by Jill Anderson, a 1965 PSU math grad, in memory of her husband, Kermit, another 1965 math grad, who was killed in the [[9-11 terrorist attacks]].&lt;ref name="PS1"/&gt;  Summarizing the memorial, Anderson said:&lt;ref name="PS1"/&gt;  &lt;blockquote&gt;I hope that the sculpture will encourage students, faculty, administrators, alumnae, and friends to ponder and appreciate the wonderful world of mathematics.  I also hope that all who view the sculpture will begin to grasp the sobering fact that everyone is vulnerable to something terrible happening to them and that we all must learn to live one day at a time, making the very best of what has been given to us. It would be great if everyone who views the ''Octacube'' walks away with the feeling that being kind to others is a good way to live.&lt;/blockquote&gt;

Anderson also funded a math scholarship in Kermit's name, at the same time the sculpture project went forward.&lt;ref name="PS1"/&gt;

==Reception==

A more complete explanation of the sculpture, including how it came to be made, how its construction was funded and its role in [[mathematics]] and [[physics]], has been made available by Penn State.&lt;ref name="PS1"&gt;[http://science.psu.edu/news-and-events/2005-news/math10-2005.htm#Sculpture News bulletin on the Octacube], Department of Mathematics, Penn State University, 13 October 2005 (accessed 2013-05-06)&lt;/ref&gt;  In addition, Ocneanu has provided his own commentary.&lt;ref&gt;[http://www.science.psu.edu/alert/OctacubeFacts.pdf The mathematics of the 24-cell], a website maintained by Adrian Ocneanu. {{webarchive |url=https://web.archive.org/web/20060901135336/http://www.science.psu.edu/alert/OctacubeFacts.pdf |date=September 1, 2006 }}&lt;/ref&gt;

==See also==

'''Artists:'''
*[[Salvador Dalí]], painter of fourth dimension allusions
*[[David Smith (sculptor)|David Smith]], a sculptor of abstract, geometric stainless steel
*[[Tony Smith (sculptor)|Tony Smith]], another creator of large abstract geometric sculptures

'''Math:'''
*[[Group theory]], the mathematical discipline that historically encompassed much research into symmetry
*[[Operator algebra]], Ocneanu's area of math research

==References==
'''Notes'''
{{reflist|group="note"}}

'''Citations'''
{{reflist}}

==External links==
*[https://www.youtube.com/watch?v=viKTj78ge-0 Video from Penn State] about the ''Octacube''
*[https://www.youtube.com/watch?v=70JPkK3_Dj0 User created video] on imagining a four dimensional object (but a tesseract).  Note discussion of projections at ~22 minutes and the discussion of the cells in the model at ~35 minutes.

{{Mathematical art}}
{{coord|40|47|51.5|N|77|51|43.7|W|region:US-PA_type:landmark|display=title}}

[[Category:Mathematical artworks]]
[[Category:Quantum field theory]]
[[Category:2005 sculptures]]
[[Category:Mathematics and culture]]
[[Category:Memorials for the September 11 attacks]]
[[Category:Pennsylvania State University]]
[[Category:Steel sculptures in Pennsylvania]]
[[Category:Group theory]]
[[Category:Operator algebras]]</text>
      <sha1>8y5neibf47i71syv2m7r117safw67mq</sha1>
    </revision>
  </page>
  <page>
    <title>Opaque forest problem</title>
    <ns>0</ns>
    <id>41162601</id>
    <revision>
      <id>846705413</id>
      <parentid>829292579</parentid>
      <timestamp>2018-06-20T11:54:18Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10453">In [[computational geometry]], The '''opaque forest problem''' can be stated as follows: "''Given a convex polygon ''C'' in the plane, determine the minimal forest ''T'' of closed, bounded line segments such that every line through ''C'' also intersects ''T". ''T'' is said to be the ''opaque forest'', or ''barrier'' of ''C''. ''C'' is said to be the ''coverage'' of ''T''. While any forest that covers ''C'' is a barrier of ''C'', we wish to find the one with shortest length.

It may be the case that ''T'' is constrained to be strictly interior or exterior to ''C''. In this case, we specifically refer to a barrier as ''interior'' or ''exterior''. Otherwise, the barrier is assumed to have no constraints on its location.

[[File:Unit Square Opaque Forest Solutions.svg|thumb|Several opaque forests for a unit square. Top left: the perimeter of the square, length 4. Top right: The perimeter of the square, less one edge, length 3. Bottom left: the [[Steiner tree]] of the vertices, length 1&amp;nbsp;+&amp;nbsp;{{radic|3}}. Bottom right: the conjectured optimal solution, length {{radic|2}}&amp;nbsp;+&amp;nbsp;{{radic|6}}/2.]]

== History and difficulty ==
The opaque forest problem was originally introduced by [[Stefan Mazurkiewicz|Mazurkiewicz]] in 1916.{{r|m16}} 
Since then, not much progress has been made with respect to the original problem. There does not exist ''any'' verified general solution to the problem. In fact, the optimal solution for even simple fixed inputs such as the unit square or equilateral triangle are unknown. There exist conjectured optimal solutions to both of these instances, but we currently lack the tooling to prove that they are optimal.{{r|djp}}
While general solutions to the problem have been claimed by several individuals,{{r|akman|dublish}}
they either haven't been peer reviewed or have been demonstrated to be incorrect.{{r|shermer|pbtw}}

== Bounding the optimal solution ==

Given a [[convex polygon]] ''C'' with perimeter ''p'' it is possible to bound the value of the optimal solution in terms of ''p''. These bounds are individually tight in general, but due to the various shapes that can be provided, are quite loose with respect to each other.

In general, one can prove that ''p''/2&amp;nbsp;≤&amp;nbsp;|OPT|&amp;nbsp;≤&amp;nbsp;''p''.

=== Upper bound ===

Tracing the perimeter of ''C'' is always sufficient to cover it. Therefore, ''p'' is an upper bound for any ''C''. For internal barriers, this bound is tight in the limiting case of when ''C'' is a circle; every point ''q'' on the perimeter of the circle must be contained in ''T'', or else a tangent of ''C'' can be drawn through ''q'' without intersecting ''T''.  However, for any other convex polygon, this is suboptimal, meaning that this is not a particularly good upper bound for most inputs.

For most inputs, a slightly better upper bound for convex polygons can be found in the length of the perimeter, less the longest edge (which is the [[minimum spanning tree]]). Even better, one can take the [[steiner tree problem|minimum Steiner tree]] of the vertices of the polygon. For internal barriers, the only way to improve this bound is to make a disconnected barrier.

=== Lower bound ===

Various proofs of the lower bound can be found in {{harvtxt|Dumitrescu|Jiang|2014}}.
To see that this is tight in general, one can consider the case of a stretching out a very long and thin rectangle. Any opaque forest for this shape must be at least as long as the rectangle, or else there is a hole through which vertical lines can pass through. As the rectangle becomes longer and thinner, this value approaches ''p''/2. Therefore, this bound is tight in general. However, for any shape that actually has a positive area, some extra length will need to be allocated to span the shape in other directions. Hence this is not a particularly good lower bound for most inputs.

=== Special cases ===

For the unit square, these bounds evaluate to 2 and 4 respectively. However, slightly improved lower bounds of 2 + 10&lt;sup&gt;−12&lt;/sup&gt; for barriers that satisfy a locality constraint, and 2 + 10&lt;sup&gt;−5&lt;/sup&gt; for internal barriers, have been shown.{{r|dj}}

== Approximations ==

Due to the difficulty faced in finding an optimal barrier for even simple examples, it has become very desirable to find a barrier that approximates the optimal within some constant factor.

{{harvtxt|Dumitrescu|Jiang|Pach|2014}} provide several linear-time approximations for the optimal solution. For general barriers, they provide a 1/2&amp;nbsp;+&amp;nbsp;(2&amp;nbsp;+&amp;nbsp;{{radic|2}})/{{pi}} =&amp;nbsp;1.5867... approximation ratio. For connected barriers, they improve this ratio to 1.5716. If the barrier is constrained to a single arc, they achieve a ({{pi}}&amp;nbsp;+&amp;nbsp;5)/({{pi}}&amp;nbsp;+&amp;nbsp;2) =&amp;nbsp;1.5834 approximation ratio.

== Barrier verification and computing the coverage of forests ==

Most barrier constructions are such that the fact that it covers the desired region is guaranteed. However, given an arbitrary barrier ''T'', it would be desirable to confirm that it covers the desired area&amp;nbsp;''C''.

As a simple first pass, one can compare the [[convex hull]]s of ''C'' and ''T''. ''T'' covers at most its convex hull, so if the convex hull of ''T'' does not strictly contain ''C'', then it cannot possibly cover ''T''. This provides a simple O(''n''&amp;nbsp;log&amp;nbsp;''n'') first-pass algorithm for verifying a barrier. If ''T'' consists of a single connected component, then it covers exactly its convex hull, and this algorithm is sufficient. However, If ''T'' contains more than one connected component, it may cover less. So this test is not sufficient in general.

The problem of determining exactly what regions any given forest ''T'' consisting of ''m'' connected components and ''n'' line segments actually covers, can be solved in Θ(''m''&lt;sup&gt;2&lt;/sup&gt;''n''&lt;sup&gt;2&lt;/sup&gt;) time.{{r|bs}}
The basic procedure for doing this is simple: first, simplify each connected component by replacing it with its own convex hull. Then, for vertex ''p'' of each convex hull, perform a circular plane-sweep with a line centered at ''p'', tracking when the line is or isn't piercing a convex hull (not including the point ''p'' itself). The orientations of the sweep-line during which an intersection occurred produce a "sun" shaped set of points (a collection of double-wedges centred at ''p''). The coverage of ''T'' is exactly the intersection of all of these "suns" for all choices of&amp;nbsp;''p''.

While this algorithm is worst-case optimal, it often does a lot of useless work when it doesn't need to. In particular, when the convex hulls are first computed, many of them may overlap. If they do, they can be replaced by their combined convex hull without loss of generality. If after merging all overlapping hulls, a single barrier has resulted, then the more general algorithm need not be run; the coverage of a barrier is at most its convex hull, and we have just determined that its coverage ''is'' its convex hull. The merged hulls can be computed in O(''n''log&lt;sup&gt;2&lt;/sup&gt;''n'') time. Should more than one hull remain, the original algorithm can be run on the new simplified set of hulls, for a reduced running time.{{r|bbbs}}

==See also==
*[[Euclid's orchard]]

== References ==

{{reflist|30em|refs=

&lt;ref name=akman&gt;{{citation
 | last = Akman | first = Varol
 | doi = 10.1016/0020-0190(87)90185-2
 | issue = 3
 | journal = [[Information Processing Letters]]
 | mr = 882227
 | pages = 193–198
 | title = An algorithm for determining an opaque minimal forest of a convex polygon
 | volume = 24
 | year = 1987}}&lt;/ref&gt;

&lt;ref name=bs&gt;{{citation
 | last1 = Beingessner | first1 = Alexis
 | last2 = Smid | first2 = Michiel
 | contribution = Computing the coverage of an opaque forest
 | contribution-url = http://2012.cccg.ca/papers/paper33.pdf
 | pages = 95–100
 | title = Proc. 24th Canadian Conference on Computational Geometry (CCCG'12)
 | year = 2012}}&lt;/ref&gt;

&lt;ref name=bbbs&gt;{{citation
 | last1 = Barba | first1 = Luis
 | last2 = Beingessner | first2 = Alexis
 | last3 = Bose | first3 = Prosenjit | author3-link = Jit Bose
 | last4 = Smid | first4 = Michiel
 | contribution = Computing covers of plane forests
 | contribution-url = http://cccg.ca/proceedings/2013/papers/paper_18.pdf
 | title = Proc. 25th Canadian Conference on Computational Geometry (CCCG'13)
 | year = 2013}}&lt;/ref&gt;

&lt;ref name=dj&gt;{{citation
 | last1 = Dumitrescu | first1 = Adrian
 | last2 = Jiang | first2 = Minghui
 | arxiv = 1311.3323
 | contribution = The opaque square
 | doi = 10.1145/2582112.2582113
 | location = New York
 | mr = 3382335
 | pages = 529–538
 | publisher = Association for Computing Machinery
 | title = Proc. 30th Annual Symposium on Computational Geometry (SoCG'14)
 | year = 2014}}&lt;/ref&gt;

&lt;ref name=djp&gt;{{citation
 | last1 = Dumitrescu | first1 = Adrian
 | last2 = Jiang | first2 = Minghui
 | last3 = Pach | first3 = János | author3-link = János Pach
 | doi = 10.1007/s00453-012-9735-2
 | issue = 2
 | journal = [[Algorithmica]]
 | mr = 3183418
 | pages = 315–334
 | title = Opaque sets
 | volume = 69
 | year = 2014}}&lt;/ref&gt;

&lt;ref name=dublish&gt;{{citation
 | last = Dublish | first = Pratul
 | doi = 10.1016/0020-0190(88)90122-6
 | issue = 5
 | journal = [[Information Processing Letters]]
 | mr = 981078
 | pages = 275–276
 | title = An &lt;math&gt;O(n^3)&lt;/math&gt; algorithm for finding the minimal opaque forest of a convex polygon
 | volume = 29
 | year = 1988}}&lt;/ref&gt;

&lt;ref name=m16&gt;{{citation
 | last = Mazurkiewicz | first = Stefan | authorlink = Stefan Mazurkiewicz
 | journal = Prace Mat.-Fiz.
 | language = Polish with French summary
 | pages = 11–16
 | title = Sur un ensemble fermé, punctiforme, qui rencontre toute droite passant par un certain domaine
 | volume = 27
 | year = 1916}}&lt;/ref&gt;

&lt;ref name=pbtw&gt;{{citation
 | last1 = Provan | first1 = J. Scott
 | last2 = Brazil | first2 = Marcus
 | last3 = Thomas | first3 = Doreen
 | last4 = Weng | first4 = Jia F.
 | arxiv = 1210.8139
 | title = Minimum opaque covers for polygonal regions
 | year = 2012| bibcode = 2012arXiv1210.8139P}}&lt;/ref&gt;

&lt;ref name=shermer&gt;{{citation
 | last = Shermer | first = Thomas
 | doi = 10.1016/S0020-0190(05)80008-0
 | issue = 1
 | journal = [[Information Processing Letters]]
 | mr = 1134007
 | pages = 41–42
 | title = A counterexample to the algorithms for determining opaque minimal forests
 | volume = 40
 | year = 1991}}&lt;/ref&gt;

}}

[[Category:Computational geometry]]</text>
      <sha1>7jyj70fdseq7k97x43th0v7okv8xoe4</sha1>
    </revision>
  </page>
  <page>
    <title>Open Options Corporation</title>
    <ns>0</ns>
    <id>19975724</id>
    <revision>
      <id>799350701</id>
      <parentid>758876187</parentid>
      <timestamp>2017-09-07T04:39:50Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2224">'''Open Options Corporation''' is a privately owned business strategy consulting company that specializes in applied [[game theory]] and [[business war games]] where there are multiple stakeholders who can all influence the final outcome of a particular situation.

Open Options’ original software development was funded by the [[CIA]] through a company called Waterloo Engineering Software. The software was designed to help the American government better anticipate the collapse of the Soviet Union into many different breakaway republics.&lt;ref name= "Globe and Mail"&gt; https://www.theglobeandmail.com/servlet/story/RTGAM.20070125.rmgame0125/BNStory/specialROBmagazine/home &lt;/ref&gt; The software was based on academic research by Dr. Niall Fraser from the [[University of Waterloo]]. Dr. Fraser has written several books on game theory including Mathematical Modeling of Resolutions of Conflict&lt;ref name= "Mathematical Modeling of Resolutions"&gt;  Okada, N, K.W. Hipel, N.M. Fraser and M. Fukushima (1988). Mathematical Modeling of Resolutions of Conflict, Kyoto Japan: Gendai Sugakusha (in Japanese).&lt;/ref&gt; and Conflict Analysis: Models and Resolutions.&lt;ref name= "Conflict Analysis"&gt;  Fraser, N.M. and K.W. Hipel (1984). Conflict Analysis: Models and Resolutions. New York: North-Holland. &lt;/ref&gt;

Open Options uses a type of game theory called Ordinal Non-cooperative Game Theory which is a less well-known sub-section of game theory.&lt;ref name = "Globe and Mail" /&gt; However, this approach and proprietary software enables Open Options to analyze millions of possible outcomes.&lt;ref name = "Globe and Mail" /&gt;&lt;ref name= "Economist"&gt;http://www.economist.com/business/displaystory.cfm?story_id=9257879 &lt;/ref&gt;&lt;ref name= "Risk Management Magazine"&gt; http://www.rmmag.com/MGTemplate.cfm?Section=MagArchive&amp;NavMenuID=304&amp;template=/Magazine/DisplayMagazines.cfm&amp;Archive=1&amp;IssueID=212&amp;AID=2316&amp;Volume=51&amp;ShowArticle=1&lt;/ref&gt;&lt;ref name= "CFO magazine"&gt; http://www.cfo.com/article.cfm/11700044?f=search &lt;/ref&gt;

==References==
{{Reflist}}
[https://pdx.academia.edu/nathanFlow business ideas]

==External links==
*[http://openoptions.com Company website]

[[Category:Game theory]]
[[Category:Business planning]]
[[Category:Consulting firms]]</text>
      <sha1>ryyqeo9jvh0yjvlsnsx8n1oghqs1aue</sha1>
    </revision>
  </page>
  <page>
    <title>Order-7 heptagonal tiling</title>
    <ns>0</ns>
    <id>38707083</id>
    <revision>
      <id>786602944</id>
      <parentid>777260668</parentid>
      <timestamp>2017-06-20T13:08:54Z</timestamp>
      <contributor>
        <username>CBM</username>
        <id>1108292</id>
      </contributor>
      <minor/>
      <comment>Manually reviewed edit to replace magic words per [[Special:PermanentLink/772743896#Future_of_magic_links|local rfc]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1767">{{Uniform hyperbolic tiles db|Reg hyperbolic tiling stat table|U77_0}}
In [[geometry]], the '''order-7 heptagonal tiling''' is a [[List_of_regular_polytopes#Hyperbolic_tilings|regular]] tiling of the [[Hyperbolic geometry|hyperbolic plane]]. It has [[Schläfli symbol]] of {7,7}, constructed from seven heptagons around every vertex. As such, it is [[Dual polyhedron#Self-dual_polytopes_and_tessellations|self-dual]].

== Related tilings ==
{{Order_7-7_tiling_table}}

==See also==
{{Commonscat|Order-7 heptagonal tiling}}
*[[Square tiling]]
*[[Uniform tilings in hyperbolic plane]]
*[[List of regular polytopes]]

==References==
* [[John Horton Conway|John H. Conway]], Heidi Burgiel, Chaim Goodman-Strass, ''The Symmetries of Things'' 2008, {{isbn|978-1-56881-220-5}} (Chapter 19, The Hyperbolic Archimedean Tessellations)
* {{Cite book|title=The Beauty of Geometry: Twelve Essays|year=1999|publisher=Dover Publications|lccn=99035678|isbn=0-486-40919-8|chapter=Chapter 10: Regular honeycombs in hyperbolic space}}

== External links ==
*{{MathWorld | urlname= HyperbolicTiling | title = Hyperbolic tiling}}
*{{MathWorld | urlname=PoincareHyperbolicDisk | title = Poincaré hyperbolic disk }}
* [http://bork.hampshire.edu/~bernie/hyper/ Hyperbolic and Spherical Tiling Gallery]
* [http://geometrygames.org/KaleidoTile/index.html KaleidoTile 3: Educational software to create spherical, planar and hyperbolic tilings]
* [http://www.plunk.org/~hatch/HyperbolicTesselations Hyperbolic Planar Tessellations, Don Hatch]

{{Tessellation}}

[[Category:Heptagonal tilings]]
[[Category:Hyperbolic tilings]]
[[Category:Isogonal tilings]]
[[Category:Isohedral tilings]]
[[Category:Order-7 tilings]]
[[Category:Regular tilings]]
[[Category:Self-dual tilings]]

{{geometry-stub}}</text>
      <sha1>pribp51heyevy4oi2uen84wgvwdjug2</sha1>
    </revision>
  </page>
  <page>
    <title>Parastatistics</title>
    <ns>0</ns>
    <id>872374</id>
    <revision>
      <id>846828669</id>
      <parentid>846822633</parentid>
      <timestamp>2018-06-21T04:05:30Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 1 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8322">{{Statistical mechanics|cTopic=[[Particle statistics|Particle Statistics]]}}

{{More citations needed|date=September 2010}}

In [[quantum mechanics]] and [[statistical mechanics]], '''parastatistics''' is one of several alternatives to the better known [[particle statistics]] models ([[Bose–Einstein statistics]], [[Fermi–Dirac statistics]] and [[Maxwell–Boltzmann statistics]]).  Other alternatives include [[anyonic statistics]] and [[braid statistics]], both of these involving lower spacetime dimensions.

==Formalism==
Consider the [[operator algebra]] of a system of ''N'' identical particles. This is a [[star-algebra|*-algebra]]. There is an ''S&lt;sub&gt;N&lt;/sub&gt;'' group ([[symmetric group]] of order ''N'')  [[group action|acting]] upon the operator algebra with the intended interpretation of [[permutation|permuting]] the ''N'' particles. Quantum mechanics requires focus on [[observable]]s having a physical meaning, and the observables would have to be [[invariant (mathematics)|invariant]] under all possible permutations of the ''N'' particles. For example, in the case ''N''&amp;nbsp;=&amp;nbsp;2, ''R''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;&amp;minus;&amp;nbsp;''R''&lt;sub&gt;1&lt;/sub&gt; cannot be an observable because it changes sign if we switch the two particles, but the distance between the two particles : |''R''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;&amp;minus;&amp;nbsp;''R''&lt;sub&gt;1&lt;/sub&gt;| is a legitimate observable.

In other words, the observable algebra would have to be a *-[[subalgebra]] invariant under the action of ''S&lt;sub&gt;N&lt;/sub&gt;'' (noting that this does not mean that every element of the operator algebra invariant under ''S&lt;sub&gt;N&lt;/sub&gt;'' is an observable). Therefore, we can have different [[superselection sector]]s, each parameterized by a [[Young diagram]] of ''S&lt;sub&gt;N&lt;/sub&gt;''.

In particular:

* If we have ''N'' identical '''parabosons''' of order ''p'' (where ''p'' is a positive integer), then the permissible Young diagrams are all those with ''p'' or fewer rows.
* If we have ''N'' identical '''parafermions''' of order ''p'', then the permissible Young diagrams are all those with ''p'' or fewer columns.
* If ''p'' is 1, we just have the ordinary cases of Bose–Einstein and Fermi–Dirac statistics respectively.
* If ''p'' is infinity (not an integer, but one could also have said arbitrarily large ''p''), we have Maxwell–Boltzmann statistics.

==The quantum field theory of parastatistics==
A paraboson field of order ''p'', &lt;math&gt;\phi(x)=\sum_{i=1}^p \phi^{(i)}(x)&lt;/math&gt; where if ''x'' and ''y'' are [[spacelike]]-separated points, &lt;math&gt;[\phi^{(i)}(x),\phi^{(i)}(y)]=0&lt;/math&gt; and &lt;math&gt;\{\phi^{(i)}(x),\phi^{(j)}(y)\}=0&lt;/math&gt; if &lt;math&gt;i\neq j&lt;/math&gt; where [,] is the [[commutator]] and {,} is the [[anticommutator]]. Note that this disagrees with the [[spin-statistics theorem]], which is for [[boson]]s and not parabosons. There might be a group such as the [[symmetric group]] ''S&lt;sub&gt;p&lt;/sub&gt;'' acting upon the ''φ''&lt;sup&gt;(''i'')&lt;/sup&gt;s. [[Observable]]s would have to be operators which are [[invariant (mathematics)|invariant]] under the group in question. However, the existence of such a symmetry is not essential.

A parafermion field &lt;math&gt;\psi(x)=\sum_{i=1}^p \psi^{(i)}(x)&lt;/math&gt; of order ''p'', where if ''x'' and ''y'' are [[spacelike]]-separated points, &lt;math&gt;\{\psi^{(i)}(x),\psi^{(i)}(y)\}=0&lt;/math&gt; and &lt;math&gt;[\psi^{(i)}(x),\psi^{(j)}(y)]=0&lt;/math&gt; if &lt;math&gt;i\neq j&lt;/math&gt;. The same comment about [[observable]]s would apply together with the requirement that they have even [[Graded algebra|grading]] under the grading where the ''ψ''s have odd grading.

The ''parafermionic and parabosonic algebras'' are generated by elements that obey the commutation and anticommutation relations. They generalize the usual ''fermionic algebra'' and the ''bosonic algebra'' of quantum mechanics.&lt;ref&gt;K. Kanakoglou, C. Daskaloyannis: [https://books.google.com/books?id=KAZL5UBlS4cC&amp;pg=PA207 ''Chapter 18 Bosonisation and Parastatistics'', p. 207 ff.], in: Sergei D. Silvestrov, Eugen Paal, Viktor Abramov, Alexander Stolin (eds.): ''Generalized Lie Theory in Mathematics, Physics and Beyond'', 2008, {{ISBN|978-3-540-85331-2}}&lt;/ref&gt; The [[Dirac algebra]] and the [[Duffin–Kemmer–Petiau algebra]] appear as special cases of the parafermionic algebra for order p=1 and p=2, respectively.&lt;ref&gt;See citations in {{Cite journal|arxiv=hep-th/0001067|last1=Plyushchay|first1=Mikhail S|title=Cubic root of Klein-Gordon equation|journal=Physics Letters B|volume=477|issue=2000|pages=276–284|author2=Michel Rausch de Traubenberg|year=2000|doi=10.1016/S0370-2693(00)00190-8|bibcode=2000PhLB..477..276P}}&lt;/ref&gt;

==Explaining parastatistics==
Note that if ''x'' and ''y'' are spacelike-separated points, ''φ''(''x'') and ''&amp;phi;''(''y'') neither commute nor anticommute unless ''p''=1. The same comment applies to ''ψ''(''x'') and ''&amp;psi;''(''y''). So, if we have ''n'' spacelike separated points ''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''n''&lt;/sub&gt;,

:&lt;math&gt;\phi(x_1)\cdots \phi(x_n)|\Omega\rangle&lt;/math&gt;

corresponds to creating ''n'' identical parabosons at ''x''&lt;sub&gt;1&lt;/sub&gt;,..., ''x''&lt;sub&gt;''n''&lt;/sub&gt;. Similarly,

:&lt;math&gt;\psi(x_1)\cdots \psi(x_n)|\Omega\rangle&lt;/math&gt;

corresponds to creating ''n'' identical parafermions. Because these fields neither commute nor anticommute

:&lt;math&gt;\phi(x_{\pi(1)})\cdots \phi(x_{\pi(n)})|\Omega\rangle&lt;/math&gt;

and

:&lt;math&gt;\psi(x_{\pi(1)})\cdots \psi(x_{\pi(n)})|\Omega\rangle&lt;/math&gt;

gives distinct states for each permutation π in ''[[symmetric group|S&lt;sub&gt;n&lt;/sub&gt;]]''.

We can define a permutation operator &lt;math&gt;\mathcal{E}(\pi)&lt;/math&gt; by

:&lt;math&gt;\mathcal{E}(\pi)\left[\phi(x_1)\cdots \phi(x_n)|\Omega\rangle\right]=\phi(x_{\pi^{-1}(1)})\cdots \phi(x_{\pi^{-1}(n)})|\Omega\rangle&lt;/math&gt;

and

:&lt;math&gt;\mathcal{E}(\pi)\left[\psi(x_1)\cdots \psi(x_n)|\Omega\rangle\right]=\psi(x_{\pi^{-1}(1)})\cdots \psi(x_{\pi^{-1}(n)})|\Omega\rangle&lt;/math&gt;

respectively. This can be shown to be well-defined as long as &lt;math&gt;\mathcal{E}(\pi)&lt;/math&gt; is only restricted to states spanned by the vectors given above (essentially the states with ''n'' identical particles). It is also [[unitary operator|unitary]]. Moreover, &lt;math&gt;\mathcal{E}&lt;/math&gt; is an operator-valued [[group representation|representation]] of the symmetric group ''S&lt;sub&gt;n&lt;/sub&gt;'' and as such, we can interpret it as the action of ''S&lt;sub&gt;n&lt;/sub&gt;'' upon the ''n''-particle Hilbert space itself, turning it into a [[unitary representation]].

[[Quantum chromodynamics|QCD]] can be reformulated using parastatistics with the quarks being parafermions of order 3 and the gluons being parabosons of order 8. Note this is different from the conventional approach where quarks always obey anticommutation relations and gluons commutation relations.&lt;ref&gt;{{cite journal|last1=Aldrovandi|first1=R.|last2=Lima|first2=I.M.|title=Parastatistics and the Equation of State for the Early Universe|journal=Astrophysics and Space Science|date=February 1983|volume=90|issue= 1|pages=179–195|bibcode=1983Ap&amp;SS..90..179A|doi=10.1007/BF00651559}}&lt;/ref&gt;

==History of parastatistics==
H.S. (Bert) Green &lt;ref&gt;{{cite web |url=http://www.physics.adelaide.edu.au/mathphysics/hsg_memorial.html |title=Archived copy |accessdate=2011-10-30 |deadurl=yes |archiveurl=https://web.archive.org/web/20120418185829/http://www.physics.adelaide.edu.au/mathphysics/hsg_memorial.html |archivedate=2012-04-18 |df= }}&lt;/ref&gt; is credited with the invention/discovery of parastatistics in 1953.&lt;ref&gt;H.S. Green, A Generalized Method of Field Quantization. Phys. Rev. 90, 270–273 (1953).(c)&lt;/ref&gt;&lt;ref&gt;{{Cite arxiv|last1=Cattani|first1=M.|last2=Bassalo|first2=J. M. F.|title=Intermediate Statistics, Parastatistics, Fractionary Statistics and Gentilionic Statistics|eprint=0903.4773|class=cond-mat.stat-mech|year=2009}}&lt;/ref&gt;

==See also==
*[[Klein transformation]] on how to convert between parastatistics and the more conventional statistics.&lt;ref&gt;{{cite web|last1=Baker|first1=David John|last2=Halvorson|first2=Hans|last3=Swanson|first3=Noel|title=The Conventionality of Parastatistics|url=http://philsci-archive.pitt.edu/10697/1/Conventionality_of_Parastatistics_Final_Revision.pdf|website=An Archive for Preprints in Philosophy of Science|publisher=University of Pittsburg|accessdate=30 May 2018}}&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Parastatistics|*]]
[[Category:Permutations]]</text>
      <sha1>3r650ilexyqdxvsgh9l2o2as59cr0ib</sha1>
    </revision>
  </page>
  <page>
    <title>Perfect group</title>
    <ns>0</ns>
    <id>585271</id>
    <revision>
      <id>865725764</id>
      <parentid>865725738</parentid>
      <timestamp>2018-10-25T19:05:03Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <comment>/* References */ ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9052">In [[mathematics]], more specifically in the area of [[Abstract algebra|modern algebra]] known as [[group theory]], a [[Group (mathematics)|group]] is said to be '''perfect''' if it equals its own [[commutator subgroup]], or equivalently, if the group has no nontrivial [[abelian group|abelian]] [[quotient group|quotients]] (equivalently, its [[abelianization]], which is the universal abelian quotient, is trivial). In symbols, a perfect group is one such that ''G''&lt;sup&gt;(1)&lt;/sup&gt; = ''G'' (the commutator subgroup equals the group), or equivalently one such that ''G''&lt;sup&gt;ab&lt;/sup&gt; = {1} (its abelianization is trivial).

== Examples ==
The smallest (non-trivial) perfect group is the [[alternating group]] ''A''&lt;sub&gt;5&lt;/sub&gt;. More generally, any non-[[abelian group|abelian]] [[simple group]] is perfect since the commutator subgroup is a [[normal subgroup]] with abelian quotient. Conversely, a perfect group need not be simple; for example, the [[special linear group]] over the field with 5 elements, SL(2,5) (or the [[binary icosahedral group]] which is isomorphic to it) is perfect but not simple (it has a non-trivial [[center (group)|center]] containing &lt;math&gt;\left(\begin{smallmatrix}-1 &amp; 0 \\ 0 &amp; -1\end{smallmatrix}\right) = \left(\begin{smallmatrix}4 &amp; 0 \\ 0 &amp; 4\end{smallmatrix}\right)&lt;/math&gt;).

More generally, a [[quasisimple group]] (a perfect [[Central extension (mathematics)|central extension]] of a simple group) which is a non-trivial extension (i.e., not a simple group itself) is perfect but not simple; this includes all the insoluble non-simple finite special linear groups SL(''n'',''q'') as extensions of the [[projective special linear group]] PSL(''n'',''q'') (SL(2,5) is an extension of PSL(2,5), which is isomorphic to ''A''&lt;sub&gt;5&lt;/sub&gt;). Similarly, the special linear group over the real and complex numbers is perfect, but the general linear group GL is never perfect (except when trivial or over '''F'''&lt;sub&gt;2&lt;/sub&gt;, where it equals the special linear group), as the [[determinant]] gives a non-trivial abelianization and indeed the commutator subgroup is SL.

A non-trivial perfect group, however, is necessarily not [[solvable group|solvable]]; and 4 divides its order (if finite), moreover, if 8 does not divide the order, then 3 does.&lt;ref&gt;{{cite web|url=http://mathoverflow.net/a/210974/34538|title=an answer|website=mathoverflow|date=7 July 2015|accessdate=7 July 2015}}&lt;/ref&gt;

Every [[acyclic group]] is perfect, but the converse is not true: ''A''&lt;sub&gt;5&lt;/sub&gt; is perfect but not acyclic (in fact, not even [[Superperfect group|superperfect]]), see {{harv|Berrick|Hillman|2003}}. In fact, for ''n'' ≥ 5 the alternating group ''A&lt;sub&gt;n&lt;/sub&gt;'' is perfect but not superperfect, with ''H''&lt;sub&gt;2&lt;/sub&gt;(''A&lt;sub&gt;n&lt;/sub&gt;'', '''Z''') = '''Z'''/2 for ''n'' ≥ 8.

Any [[quotient group|quotient]] of a perfect group is perfect. A non-trivial finite perfect group which is not simple must then be an extension of at least one smaller simple non-abelian group. But it can be the extension of more than one simple group. In fact, the direct product of perfect groups is also perfect.

Every perfect group ''G'' determines another perfect group ''E'' (its [[universal central extension]]) together with a surjection ''f:E'' → ''G'' whose kernel is in the center of ''E,''
such that ''f'' is universal with this property. The kernel of ''f'' is called the [[Schur multiplier]] of ''G'' because it was first studied by [[Schur]] in 1904; it is isomorphic to the
homology group ''H&lt;sub&gt;2&lt;/sub&gt;(G)''.

In the '''plus construction''' of [[algebraic K-theory]], if we consider the group &lt;math&gt;GL(A) = \text{colim} GL_n(A)&lt;/math&gt; for a commutative ring &lt;math&gt;A&lt;/math&gt;, then the subgroup of elementary matrices &lt;math&gt;E(R)&lt;/math&gt; forms a perfect subgroup.

== Ore's conjecture ==
As the commutator subgroup is ''generated'' by commutators, a perfect group may contain elements that are products of commutators but not themselves commutators. [[Øystein Ore]] proved in 1951 that the alternating groups on five or more elements contained only commutators, and made the conjecture that this was so for all the finite non-abelian simple groups. Ore's conjecture was finally proven in 2008. The proof relies on the [[classification of finite simple groups|classification theorem]].&lt;ref&gt;{{cite journal|last1=Liebeck|first1=O'Brien|last2=Shalev|first2=Aner|authorlink2=Aner Shalev|title=The Ore conjecture|url=https://www.math.auckland.ac.nz/~obrien/research/ore.pdf|journal=J. European Math. Soc.|volume=12|year=2010|pp=939–1008}}&lt;/ref&gt;

==Grün's lemma==
A basic fact about perfect groups is '''Grün's lemma''' from {{harv|Grün|1935|loc=Satz 4,&lt;ref group="note"&gt;''[[wikt:Satz#German|Satz]]'' is German for "theorem".&lt;/ref&gt; p. 3}}: the [[quotient group|quotient]] of a perfect group by its [[center (group theory)|center]] is centerless (has trivial center).

&lt;blockquote&gt;'''Proof:''' If ''G'' is a perfect group, let ''Z''&lt;sub&gt;1&lt;/sub&gt; and ''Z''&lt;sub&gt;2&lt;/sub&gt; denote the first two terms of the [[Central series#Upper central series|upper central series]] of ''G'' (i.e., ''Z''&lt;sub&gt;1&lt;/sub&gt; is the center of ''G'', and ''Z''&lt;sub&gt;2&lt;/sub&gt;/''Z''&lt;sub&gt;1&lt;/sub&gt; is the center of ''G''/''Z''&lt;sub&gt;1&lt;/sub&gt;). If ''H'' and ''K'' are subgroups of ''G'', denote the [[commutator]] of ''H'' and ''K'' by [''H'', ''K''] and note that [''Z''&lt;sub&gt;1&lt;/sub&gt;, ''G''] = 1 and [''Z''&lt;sub&gt;2&lt;/sub&gt;, ''G''] ⊆ ''Z''&lt;sub&gt;1&lt;/sub&gt;, and consequently (the convention that [''X'', ''Y'', ''Z''] = [[''X'', ''Y''], ''Z''] is followed):

:&lt;math&gt;[Z_2,G,G]=[[Z_2,G],G]\subseteq [Z_1,G]=1&lt;/math&gt;
:&lt;math&gt;[G,Z_2,G]=[[G,Z_2],G]=[[Z_2,G],G]\subseteq [Z_1,G]=1.&lt;/math&gt;

By the [[three subgroups lemma]] (or equivalently, by the [[Commutator#Identities (group theory)|Hall-Witt identity]]), it follows that [''G'', ''Z''&lt;sub&gt;2&lt;/sub&gt;] = [[''G'', ''G''], ''Z''&lt;sub&gt;2&lt;/sub&gt;] = [''G'', ''G'', ''Z''&lt;sub&gt;2&lt;/sub&gt;] = {1}. Therefore, ''Z''&lt;sub&gt;2&lt;/sub&gt; ⊆ ''Z''&lt;sub&gt;1&lt;/sub&gt; = ''Z''(''G''), and the center of the quotient group ''G'' ⁄ ''Z''(''G'') is the [[trivial group]].&lt;/blockquote&gt;

As a consequence, all [[Center (group theory)#Higher centers|higher centers]] (that is, higher terms in the [[upper central series]]) of a perfect group equal the center.

==Group homology==
In terms of [[group homology]], a perfect group is precisely one whose first homology group vanishes: ''H''&lt;sub&gt;1&lt;/sub&gt;(''G'', '''Z''') = 0, as the first homology group of a group is exactly the abelianization of the group, and perfect means trivial abelianization. An advantage of this definition is that it admits strengthening:
* A [[superperfect group]] is one whose first two homology groups vanish: ''H''&lt;sub&gt;1&lt;/sub&gt;(''G'', '''Z''')  = ''H''&lt;sub&gt;2&lt;/sub&gt;(''G'', '''Z''')  = 0.
* An [[acyclic group]] is one ''all'' of whose (reduced) homology groups vanish &lt;math&gt;\tilde H_i(G;\mathbf{Z}) = 0.&lt;/math&gt; (This is equivalent to all homology groups other than ''H''&lt;sub&gt;0&lt;/sub&gt; vanishing.)

==Quasi-perfect group==
Especially in the field of [[algebraic K-theory]], a group is said to be '''quasi-perfect''' if its commutator subgroup is perfect; in symbols, a quasi-perfect group is one such that ''G''&lt;sup&gt;(1)&lt;/sup&gt; = ''G''&lt;sup&gt;(2)&lt;/sup&gt; (the commutator of the commutator subgroup is the commutator subgroup), while a perfect group is one such that ''G''&lt;sup&gt;(1)&lt;/sup&gt; = ''G'' (the commutator subgroup is the whole group). See {{harv|Karoubi|1973|pp=301–411}} and {{harv| Inassaridze | 1995 | p=76}}.

==Notes==
{{reflist | group = note }}

==References==
{{reflist}}
{{refbegin}}
* {{Citation| first1= A. Jon|last1=Berrick|first2=Jonathan A.|last2=Hillman|title=Perfect and acyclic subgroups of finitely presentable groups|journal=Journal of the London Mathematical Society |series=Second Series|volume=68|year=2003|number=3|pages=683-98|ref=harv |mr=2009444}}
* {{Citation | last1=Grün | first1=Otto | title=Beiträge zur Gruppentheorie. I. | url=http://resolver.sub.uni-goettingen.de/purl?GDZPPN002173409 | language=German | zbl=0012.34102 | year=1935 | journal=Journal für die Reine und Angewandte Mathematik | issn=0075-4102 | volume=174 | pages=1–14|ref=harv}}
*{{Citation | last1=Inassaridze | first1=Hvedri | title=Algebraic K-theory | url=https://books.google.com/books?id=rnSE3aoNVY0C | publisher=Kluwer Academic Publishers Group | location=Dordrecht | series=Mathematics and its Applications | isbn=978-0-7923-3185-8 | mr=1368402 | year=1995 | volume=311}}
* {{Citation|last=Karoubi|first=M.|title=Périodicité de la K-théorie hermitienne, Hermitian K-Theory and Geometric Applications|series= Lecture Notes in Math. |volume=343|publisher=Springer-Verlag|year=1973|ref=harv}}
*{{Citation
| last = Rose
| first = John S.
| title = A Course in Group Theory
| publisher = Dover Publications, Inc.
| location = New York
| pages = 61
| year = 1994
| isbn = 0-486-68194-7
| mr = 1298629
}}
{{refend}}

==External links==
* {{MathWorld|urlname=PerfectGroup|title=Perfect Group}}
* {{MathWorld|urlname=GruensLemma|title=Grün's lemma}}

[[Category:Properties of groups]]
[[Category:Lemmas]]</text>
      <sha1>qsjbeziq0138w9ng36a1d1yhe9yzpf6</sha1>
    </revision>
  </page>
  <page>
    <title>Piecewise</title>
    <ns>0</ns>
    <id>404130</id>
    <revision>
      <id>861532075</id>
      <parentid>861520897</parentid>
      <timestamp>2018-09-28T03:33:34Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/2601:644:4400:2BD1:E930:93C9:C634:DE72|2601:644:4400:2BD1:E930:93C9:C634:DE72]] ([[User talk:2601:644:4400:2BD1:E930:93C9:C634:DE72|talk]]) to last revision by Tea2min. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5205">{{Refimprove|date=March 2017}}
In [[mathematics]], a '''piecewise-defined function''' (also called a '''piecewise function''' or a '''hybrid function''') is a [[function (mathematics)|function]] defined by multiple sub-functions, each sub-function applying to a certain interval of the main function's domain, a sub-domain.  Piecewise is actually a way of expressing the function, rather than a characteristic of the function itself, but with additional qualification, it can describe the nature of the function.  For example, a '''piecewise polynomial''' function is a function that is a polynomial on each of its sub-domains, but possibly a different one on each.

The word ''piecewise'' is also used to describe any property of a piecewise-defined function that holds for each piece but not necessarily hold for the whole domain of the function.  A function is '''piecewise differentiable''' or '''piecewise continuously differentiable''' if each piece is [[Differentiable function|differentiable]] throughout its subdomain, even though the whole function may not be differentiable at the points between the pieces.  In [[convex analysis]], the notion of a derivative may be replaced by that of the [[subderivative]] for piecewise functions. Although the "pieces" in a piecewise definition need not be [[Interval (mathematics)|intervals]], a function is not called "piecewise linear" or "piecewise continuous" or "piecewise differentiable" unless the pieces are intervals.

== Notation and interpretation ==

[[Image:Absolute value.svg|thumb|200px|right|Graph of the absolute value function, ''y''&amp;nbsp;=&amp;nbsp;&lt;nowiki&gt;|&lt;/nowiki&gt;''x''&lt;nowiki&gt;|&lt;/nowiki&gt;.]]
Piecewise functions are defined using the common functional notation, where the body of the function is an array of functions and associated subdomains.  Crucially, in most settings, there must only be a ''finite'' number of subdomains, each of which must be an interval, in order for the overall function to be called "piecewise".  For example, consider the piecewise definition of the [[absolute value]] function:
:&lt;math&gt;|x| = \begin{cases}
  -x, &amp; \mbox{if } x &lt; 0 \\
  x,  &amp; \mbox{if } x \ge 0 
\end{cases}
&lt;/math&gt;
For all values of ''x'' less than zero, the first function (−''x'') is used, which negates the sign of the input value, making negative numbers positive.  For all values of ''x'' greater than or equal to zero, the second function (''x'') is used, which evaluates trivially to the input value itself.

Consider the piecewise function ''f''(''x'') evaluated at certain values of ''x'':
{|class="wikitable"
!style="width: 3em" | ''x''
!style="width: 3em" | ''f''(''x'') 
!Function used
|-
|−3  ||3  ||−''x''
|-
|−0.1||0.1||−''x''
|-
|0   ||0  ||''x''
|-
|1/2 ||1/2||''x''
|-
|5   ||5  ||''x''
|-
|}

Thus, in order to evaluate a piecewise function at a given input value, the appropriate subdomain needs to be chosen in order to select the correct function and produce the correct output value.

== Continuity ==
[[Image:Upper semi.svg|thumb|right|A piecewise function comprising different [[quadratic function]]s on either side of &lt;math&gt;x_0&lt;/math&gt;.]]
A piecewise function is [[Continuous function|continuous]] on a given interval if the following conditions are met:
* it is defined throughout that interval,
* its constituent functions are continuous on the corresponding intervals (subdomains),
* there is no discontinuity at each endpoint of the subdomains within that interval.

The pictured function, for example, is piecewise continuous throughout its subdomains, but is not continuous on the entire domain, as it contains a jump discontinuity at &lt;math&gt;x_0&lt;/math&gt;. The filled circle indicates that the value of the right function piece is used in this position.

== Applications ==

In applied mathematical analysis, piecewise functions have been found to be consistent with many [[Visual perception#The cognitive and computational approaches|models of the human visual system]], where images are perceived at a first stage as consisting of smooth regions separated by edges.&lt;ref&gt;{{cite journal |title = Introduction to shearlets |first1 = Gitta |last1 = Kutyniok |first2 = Demetrio |last2 = Labate |journal = Shearlets |pages = 1–38 |year = 2012 |publisher = [[Birkhäuser]] |url = https://www.math.uh.edu/~dlabate/SHBookIntro.pdf }}&lt;/ref&gt;
In particular, [[shearlet]]s have been used as a representation system to provide sparse approximations of this model class in 2D and 3D.

== Common examples ==

Specific instances of piecewise functions include:

* [[Step function]], a piecewise function composed of constant functions
** [[Boxcar function]], 
** [[Heaviside step function]]
** [[Sign function]]
* [[Piecewise linear function]], a piecewise function composed of line segments
** [[Absolute value]]
* [[Broken power law]], a piecewise function composed of power laws
* [[Spline (mathematics)|Spline]], a piecewise function composed of polynomial functions, possessing a high degree of smoothness at the places where the polynomial pieces connect
** [[B-spline]]
* [[PDIFF]]

== See also ==
{{Wikibooks|Gnuplot#Piecewise-defined functions}}

==References==
{{Reflist}}

[[Category:Functions and mappings]]</text>
      <sha1>0hf48dvzbakk1xr7aakw1jalrg1lyuh</sha1>
    </revision>
  </page>
  <page>
    <title>Polynomial decomposition</title>
    <ns>0</ns>
    <id>47164545</id>
    <revision>
      <id>832796884</id>
      <parentid>823962871</parentid>
      <timestamp>2018-03-28T01:47:07Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6241">In mathematics, a '''polynomial decomposition''' expresses a [[polynomial]] ''f'' as the [[functional composition]] &lt;math&gt;g  \circ h&lt;/math&gt; of polynomials ''g'' and ''h'', where ''g'' and ''h'' have [[Degree of a polynomial|degree]] greater than 1.&lt;ref&gt;Composition of polynomials may also be thought of as [[substitution (algebra)|substitution]] of one polynomial as the value of the variable of another.&lt;/ref&gt; [[Algorithms]] are known for decomposing polynomials in [[polynomial time]].

Polynomials which are decomposable in this way are '''composite polynomials'''; those which are not are '''prime''' or '''indecomposable polynomials'''&lt;ref name="ritt"&gt;J.F. Ritt, "Prime and Composite Polynomials", ''Transactions of the American Mathematical Society'' '''23''':1:51–66 (January, 1922) {{doi|10.2307/1988911}} {{jstor|1988911}}&lt;/ref&gt; (not to be confused with [[irreducible polynomial]]s, which cannot be [[Factorization of polynomials|factored into products of polynomials]]).

==Examples==

In the simplest case, one of the polynomials is a [[monomial]]. For example,

:&lt;math&gt;f = x^6 - 3 x^3 + 1&lt;/math&gt;

decomposes into

:&lt;math&gt;g = x^2 - 3 x + 1 \text{ and } h = x^3&lt;/math&gt;

since

:&lt;math&gt;f(x) = (g  \circ h)(x) = g(h(x)) = g(x^3) = (x^3)^2 - 3 (x^3) + 1.&lt;/math&gt;

Less trivially,

: &lt;math&gt;
\begin{align}
&amp; x^6-6 x^5+21 x^4-44 x^3+68 x^2-64 x+41 \\
= {} &amp; (x^3+9 x^2+32 x+41) \circ (x^2-2 x).
\end{align}
&lt;/math&gt;

==Uniqueness==

A polynomial may have distinct decompositions into indecomposable polynomials where &lt;math&gt;f = g_1 \circ g_2 \circ \cdots \circ g_m = h_1 \circ h_2 \circ \cdots\circ h_n&lt;/math&gt; where &lt;math&gt;g_i \neq h_i&lt;/math&gt; for some &lt;math&gt;i&lt;/math&gt;. The restriction in the definition to polynomials of degree greater than one excludes the infinitely many decompositions possible with linear polynomials.

[[Joseph Ritt]] proved that &lt;math&gt;m = n&lt;/math&gt;, and the degrees of the components are the same, but possibly in different order; this is '''Ritt's polynomial decomposition theorem'''.&lt;ref name="ritt"/&gt;&lt;ref&gt;Capi Corrales-Rodrigáñez, "A note on Ritt's theorem on decomposition of polynomials", ''Journal of Pure and Applied Algebra'' '''68''':3:293–296 (6 December 1990) {{doi|10.1016/0022-4049(90)90086-W}}&lt;/ref&gt; For example, &lt;math&gt;x^2 \circ x^3 = x^3 \circ x^2&lt;/math&gt;.

==Applications==

A polynomial decomposition may enable more efficient evaluation of a polynomial. For example,
:&lt;math&gt;
\begin{align}
&amp; x^8 + 4 x^7 + 10 x^6 + 16 x^5 + 19 x^4 + 16 x^3 + 10 x^2 + 4 x - 1 \\
= {} &amp; (x^2 - 2) \circ (x^2) \circ (x^2 + x + 1)
\end{align}
&lt;/math&gt;
can be calculated with only 3 multiplications using the decomposition, while [[Horner's method]] would require 7.

A polynomial decomposition enables calculation of symbolic roots using [[Nth root|radicals]], even for some [[irreducible polynomial]]s. This technique is used in many [[computer algebra systems]].&lt;ref&gt;The examples below were calculated using [[Maxima (software)|Maxima]].&lt;/ref&gt; For example, using the decomposition

:&lt;math&gt;
\begin{align}
&amp; x^6 - 6 x^5 + 15 x^4 - 20 x^3 + 15 x^2 - 6 x - 1 \\
= {} &amp; (x^3 - 2) \circ (x^2 - 2 x + 1),
\end{align}
&lt;/math&gt;

the roots of this irreducible polynomial can be calculated as

:&lt;math&gt;1 \pm 2^{1/6}, 1 \pm \frac{\sqrt{-1 \pm \sqrt{3}i}}{2^{1/3}}&lt;/math&gt;.&lt;ref name="indep"&gt;Where each ± is taken independently.&lt;/ref&gt;

Even in the case of [[quartic polynomial]]s, where there is an explicit formula for the roots, solving using the decomposition often gives a simpler form. For example, the decomposition

:&lt;math&gt;
\begin{align}
&amp; x^4 - 8 x^3 + 18 x^2 - 8 x + 2 \\
= {} &amp; (x^2 + 1) \circ (x^2 - 4 x + 1)
\end{align}
&lt;/math&gt;

gives the roots

:&lt;math&gt; 2 \pm \sqrt{3 \pm i} &lt;/math&gt;&lt;ref name="indep"/&gt;

but straightforward application of the [[Quartic function#General formula for roots|quartic formula]] gives equivalent results but in a form that is difficult to [[Symbolic computation#Simplification|simplify]] and difficult to understand:

:&lt;math&gt; -{ \frac{\sqrt{{{ 9 \left(\frac{8 \sqrt{10} i}{3^{3/2}} + 72\right)^{2/3} + 36 \left(\frac{8 \sqrt{10} i}{3^{3/2}} + 72\right)^{1/3} + 156} \over {\left({\frac{8 \sqrt{10} i}{3^{3/2}}} + 72\right)^{1/3}}}}} 6}-{{\sqrt{-\left(\frac{8 \sqrt{10} i}{3^{3/2}} + 72\right)^{1/3}-{{52}\over{3 \left(\frac{8 \sqrt{10} i}{3^{3/2}} +72\right)^{1/3}}} + 8}}\over 2} + 2. &lt;/math&gt;

==Algorithms==

The first algorithm for polynomial decomposition was published in 1985,&lt;ref name="bz"&gt;David R. Barton, Richard Zippel, "Polynomial Decomposition Algorithms", ''Journal of Symbolic Computation'' '''1''':159–168 (1985)&lt;/ref&gt; though it had been discovered in 1976&lt;ref name="z"&gt;Richard Zippel , "Functional Decomposition" (1996) [http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.3154 full text]&lt;/ref&gt; and implemented in the [[Macsyma]] [[computer algebra system]].&lt;ref&gt;Available in its open-source successor, [[Maxima computer algebra system|Maxima]], see the [http://maxima.sourceforge.net/docs/manual/maxima_14.html#polydecomp ''polydecomp'' function]&lt;/ref&gt; That algorithm took worst-case exponential time but worked independently of the [[characteristic (algebra)|characteristic]] of the underlying [[field (algebra)|field]].

More recent algorithms ran in polynomial time but with restrictions on the characteristic.&lt;ref name="kz"&gt;Dexter Kozen, Susan Landau, "Polynomial Decomposition Algorithms", ''Journal of Symbolic Computation'' '''7''':445–456 (1989)&lt;/ref&gt;

The most recent algorithm calculates a decomposition in polynomial time and without restrictions on the characteristic.&lt;ref&gt;Raoul Blankertz, "A polynomial time algorithm for computing all minimal decompositions of a polynomial", ''ACM Communications in Computer Algebra'' '''48''':1 (Issue 187, March 2014) [http://www.sigsam.org/bulletin/articles/187/Polynomial_time_decomposition_pp13-23.pdf full text] {{webarchive|url=https://web.archive.org/web/20150924101735/http://www.sigsam.org/bulletin/articles/187/Polynomial_time_decomposition_pp13-23.pdf |date=2015-09-24 }}&lt;/ref&gt;

==Notes==
&lt;references/&gt;

==References==

* Joel S. Cohen, "Polynomial Decomposition", Chapter 5 of ''Computer Algebra and Symbolic Computation'', 2003, {{isbn|1-56881-159-4}}

[[Category:Polynomials]]
[[Category:Computer algebra]]</text>
      <sha1>oqvg3dzkiwchzfbcqn6eat8y3dk617m</sha1>
    </revision>
  </page>
  <page>
    <title>Postage stamp problem</title>
    <ns>0</ns>
    <id>5064309</id>
    <revision>
      <id>858877602</id>
      <parentid>841573742</parentid>
      <timestamp>2018-09-10T06:37:21Z</timestamp>
      <contributor>
        <username>Dotyoyo</username>
        <id>9215586</id>
      </contributor>
      <minor/>
      <comment>/* Complexity */ Improve typography: Prevent collision of symbols</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3175">{{refimprove|date=June 2017}}
The '''postage stamp problem''' is a [[mathematical]] riddle that asks what is the smallest postage value which cannot be placed on an envelope, if the latter can hold only a limited number of stamps, and these may only have certain specified face values.&lt;ref name=arxiv&gt;Jeffrey Shallit (2001), [https://arxiv.org/abs/math.NT/0112257 ''The computational complexity of the local postage stamp problem'']. SIGACT News 33 (1) (March 2002), 90-94.  Accessed on 2009-12-30.&lt;/ref&gt;

For example, suppose the envelope can hold only three stamps, and the available stamp values are 1 cent, 2 cents, 5 cents, and 20 cents.  Then the solution is 13 cents; since any smaller value can be obtained with at most three stamps (e.g. 4 = 2 + 2, 8 = 5 + 2 + 1, etc.), but to get 13 cents one must use at least four stamps.

==Mathematical definition==
Mathematically, the problem can be formulated as follows: 
: Given an integer ''m'' and a set ''V'' of positive integers, find the smallest integer ''z'' that cannot be written as the sum ''v''&lt;sub&gt;1&lt;/sub&gt; + ''v''&lt;sub&gt;2&lt;/sub&gt; + ··· + ''v''&lt;sub&gt;''k''&lt;/sub&gt; of some number ''k'' ≤ ''m'' of (not necessarily distinct) elements of ''V''.

==Complexity==
This problem can be solved by [[brute force search]] or [[backtracking]] with maximum time proportional to |''V'' |&lt;sup&gt;''m''&lt;/sup&gt;, where |''V'' | is the number of distinct stamp values allowed.  Therefore, if the capacity of the envelope ''m'' is fixed, it is a [[polynomial time]] problem.  If the capacity ''m'' is arbitrary, the problem is known to be [[NP-hard]].&lt;ref name=arxiv/&gt;

==See also==
* [[Coin problem]]
* [[Knapsack problem]]
* [[Subset sum problem]]

== References ==
{{reflist}}

==External links==
*{{cite article| first1=W. F. | last1=Lunnon| title= A postage stamp problem
  |journal = Comput. J. | number=4 | year= 1969| pages=377-380|volume=12|doi=10.1093/comjnl/12.4.377}}
*{{cite journal| first1=R. | last1=Alter | first2=J. A. | last2=Barnett| title=A postage stamp problem
  |journal = Amer. Math. Monthly | year=1980 | volume=87 | pages=206–210 | doi=10.2307/2321610}}
*{{cite journal|first1=R. L. | last1=Graham | first2=N. J. A. | last2=Sloane
  |title=On additive bases and harmonious graphs| journal=SIAM J. Algebr. Discr. Methods
   |year =1980|volume=1 | pages=382–404|doi=10.1137/0601045|citeseerx=10.1.1.70.5521}}
*{{cite journal|first1=M. F. | last1=Challis| title=Two new techniques for computing extremal ''h''-bases ''A''&lt;sub&gt;''k''&lt;/sub&gt;
  |journal=Comput. J. | volume=36|number=2 | pages=117–126| year=1993 |doi=10.1093/comjnl/36.2.117}}
* {{cite arxiv| first1=J. | last1=Kohonen| first2=J. | last2=Corander | eprint=1310.7090
  |title=Addition chains meet postage stamps: reducing the number of multiplications| year=2013}}
*{{cite arxiv|first1=Jukka | last1=Kohonen| title=A meet-in-the-middle algorithm for finding extremal restricted additive 2-bases
   |year=2014 | eprint=1403.5945}}
* {{MathWorld | urlname=PostageStampProblem | title=Postage Stamp Problem}}

[[Category:Additive number theory]]
[[Category:Recreational mathematics]]
[[Category:Applied mathematics]]
[[Category:Mathematical problems]]</text>
      <sha1>2dtxxps10agg0hx7sbmkxxlens7oo5m</sha1>
    </revision>
  </page>
  <page>
    <title>Proof procedure</title>
    <ns>0</ns>
    <id>1596638</id>
    <revision>
      <id>635471315</id>
      <parentid>635471058</parentid>
      <timestamp>2014-11-26T04:42:17Z</timestamp>
      <contributor>
        <username>Brirush</username>
        <id>17368641</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1470">In [[logic]], and in particular [[proof theory]], a '''proof procedure''' for a given [[logical system|logic]] is a systematic method for producing proofs in some [[proof calculus]] of (provable) statements.

==Types of proof calculi used==
There are several types of proof calculi. The most popular are [[natural deduction]], [[sequent calculus|sequent calculi]] (i.e., [[Gentzen]] type systems), [[Hilbert system]]s, and [[semantic tableau]]x or trees. A given proof procedure will target a specific proof calculus, but can often be reformulated so as to produce proofs in other proof styles.

==Completeness==
A proof procedure for a logic is ''complete'' if it produces a proof for each provable statement. The theorems of logical systems are typically [[recursively enumerable]], which implies the existence of a complete but extremely inefficient proof procedure; however, a proof procedure is only of interest if it is reasonably efficient.

Faced with an unprovable statement, a complete proof procedure may sometimes succeed in detecting and signalling its unprovability. In the general case, where provability is a [[semidecidable]] property, this is not possible, and instead the procedure will diverge (not terminate).

==See also==
* [[Automated theorem proving]]
* [[Proof complexity]]
* [[Proof tableaux]]
* [[Deductive system]]
* [[Proof (truth)]]
==References==
*W. Quine 1982 (1950). ''Methods of Logic''. Harvard Univ. Press.
[[Category:Proof theory]]</text>
      <sha1>izcveud5a38bxnhtbmryatx52ci6pog</sha1>
    </revision>
  </page>
  <page>
    <title>Quantitative psychological research</title>
    <ns>0</ns>
    <id>371317</id>
    <revision>
      <id>749393092</id>
      <parentid>745031057</parentid>
      <timestamp>2016-11-14T02:40:59Z</timestamp>
      <contributor>
        <username>CitationCleanerBot</username>
        <id>15270283</id>
      </contributor>
      <minor/>
      <comment>/* top */clean up, url redundant with jstor, and/or remove accessdate if no url using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3370">{{Refimprove|date=March 2009}}

'''Quantitative psychological research''' is defined as [[psychology|psychological]] research which performs [[mathematical modeling]] and [[statistical estimation]] or [[statistical inference]] or a means for testing objective theories by examining the relationship between variables.&lt;ref name=autogenerated1&gt;{{cite book|last=Creswell|first=J.|title=Research Design: Qualitative, Quantitative, and Mixed Methods Approaches|year=2009|publisher=SAGE Publications, Inc.|pages=12}}&lt;/ref&gt;  The first definition distinguishes it from [[qualitative psychological research]]; however, there has been a long debate on the difference between quantitative and qualitative research. It has been argued that because this debated has not found an end, the differences are enough that both quantitative and qualitative research is valuable in ways that both should be used in the gathering of data.&lt;ref&gt;{{cite journal|last=Smith|first=K.|title=Quantitative versus Qualitative Research: An Attempt to Clarify the Issue|journal=Educational Researcher|date=March 1983|volume=12|issue=3|pages=6–13|jstor=1175144|doi=10.3102/0013189x012003006}}&lt;/ref&gt;

== Examples ==
[[Statistics]] is widely used in quantitative psychological research. Typically a project begins with the collection of data based on a theory or hypothesis, followed by the application of descriptive or inferential statistical methods. Often it is necessary to collect a very large volume of data, which require validating, verifying and recording. Software packages such as [[SPSS]] and [[R (programming language)|R]] are typically used for this purpose, and for subsequent analysis. Causal relationships are studied by manipulating factors thought to influence the phenomena of interest while controlling other variables relevant to the experimental outcomes. Researchers might measure and study the relationship between education and measurable psychological effects, whilst controlling for other key variables. Quantitatively based surveys are widely used by psychologists, and statistics such as the proportion of respondents who display one or more psychological traits reported. In such surveys, respondents are asked a set of structured questions and their responses are tabulated. The software can then perform correlation analysis or other procedures on the data. Surveys are a common example of how statistics and quantitative research are utilized to gather data.&lt;ref name=autogenerated1 /&gt;

Quantitative research falls under the category of [[empirical studies]] (or [[statistical study|statistical studies]]). Research designs include experimental studies, quasi-experimental studies, pretest-postest designs, and others. Randomization, the control of variables, and valid, reliable measures are used to relate the results of the smaller subject pool to the population.&lt;ref&gt;{{cite book|last=Newman, Benz|first=I., C.|title=Qualitative-Quantitative Research Methodology: Exploring the Interactive Continuum|year=1998|publisher=Southern Illinois University|pages=9–10}}&lt;/ref&gt;

== See also ==
*[[Empirical studies]]
*[[Statistics]]
*[[Quantitative psychology]]
*[[Quantitative research]]

== References ==
{{reflist}}

{{Psychology}}

[[Category:Applied statistics]]
[[Category:Experimental psychology]]
[[Category:Quantitative research]]
[[Category:Statistical data types]]</text>
      <sha1>6c1stdniujqbotn5ty2r93ttru0y8gl</sha1>
    </revision>
  </page>
  <page>
    <title>Quantity</title>
    <ns>0</ns>
    <id>691277</id>
    <revision>
      <id>867160928</id>
      <parentid>866759816</parentid>
      <timestamp>2018-11-04T01:45:28Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <minor/>
      <comment>linking</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14536">{{pp|small=yes}}

'''Quantity''' is a property that can exist as a [[Counting|multitude]] or [[Magnitude (mathematics)|magnitude]]. Quantities can be compared in terms of "more", "less", or "equal", or by assigning a numerical value in terms of a unit of measurement. Quantity is among the basic [[Class (philosophy)|classes]] of things along with [[Quality (philosophy)|quality]], [[Substance theory|substance]], [[change (mathematics)|change]], and relation. Some quantities are such by their inner nature (as number), while others are functioning as states (properties, dimensions, attributes) of things such as heavy and light, long and short, broad and narrow, small and great, or much and little. 

Two basic divisions of quantity, magnitude and multitude, imply the principal distinction between continuity ([[continuum (theory)|continuum]]) and [[discontinuity (mathematics)|discontinuity]].

Under the name of multitude comes what is discontinuous and discrete and divisible ultimately into indivisibles, such as: ''army, fleet, flock, government, company, party, people, mess (military), chorus, crowd'', and ''number''; all which are cases of [[collective nouns]]. Under the name of magnitude comes what is continuous and unified and divisible only into smaller divisibles, such as: ''matter, mass, energy, liquid, material''—all cases of non-collective nouns.

Along with analyzing its nature and classification, the issues of quantity involve such closely related topics as the relation of magnitudes and multitudes, dimensionality, equality, proportion, the measurements of quantities, the units of measurements, number and numbering systems, the types of numbers and their relations to each other as numerical ratios.

Thus quantity is a property that exists in a range of magnitudes or multitudes. [[Mass]], [[time]], [[distance]], [[heat]], and angular separation are among the familiar examples of quantitative properties.

==Background==
In mathematics, the concept of quantity is an ancient one extending back to the time of [[Aristotle]] and earlier. Aristotle regarded quantity as a fundamental ontological and scientific category. In Aristotle's [[ontology]], quantity or quantum was classified into two different types, which he characterized as follows:

:'Quantum' means that which is divisible into two or more constituent parts, of which each is by nature a 'one' and a 'this'. A quantum is a plurality if it is numerable, a magnitude if it is measurable. 'Plurality' means that which is divisible potentially into non-continuous parts, magnitude that which is divisible into continuous parts; of magnitude, that which is continuous in one dimension is length; in two breadth, in three depth. Of these, limited plurality is number, limited length is a line, breadth a surface, depth a solid. (Aristotle, book v, chapters 11-14, Metaphysics).

In his [[Euclid's Elements|''Elements'']], [[Euclid]] developed the theory of ratios of magnitudes without studying the nature of magnitudes, as Archimedes, but giving the following significant definitions:

:A magnitude is a ''part'' of a magnitude, the less of the greater, when it measures the greater; A ''ratio'' is a sort of relation in respect of size between two magnitudes of the same kind.

For Aristotle and Euclid, relations were conceived as [[Integer|whole numbers]] (Michell, 1993). [[John Wallis]] later conceived of ratios of magnitudes as [[real numbers]] as reflected in the following:

:When a comparison in terms of ratio is made, the resultant ratio often [namely with the exception of the 'numerical genus' itself] leaves the genus of quantities compared, and passes into the numerical genus, whatever the genus of quantities compared may have been. (John Wallis, ''Mathesis Universalis'')

That is, the ratio of magnitudes of any quantity, whether volume, mass, heat and so on, is a number. Following this, [[Sir Isaac Newton|Newton]] then defined number, and the relationship between quantity and number, in the following terms: "By ''number'' we understand not so much a multitude of unities, as the abstracted ratio of any quantity to another quantity of the same kind, which we take for unity" (Newton, 1728).

==Quantitative structure==
Continuous quantities possess a particular structure that was first explicitly characterized by [[Otto Hölder|Hölder]] (1901) as a set of axioms that define such features as ''identities'' and ''relations'' between magnitudes. In science, quantitative structure is the subject of [[Empirical research|empirical investigation]] and cannot be assumed to exist ''[[A priori and a posteriori|a priori]]'' for any given property. The linear [[continuum (theory)|continuum]] represents the prototype of continuous quantitative structure as characterized by Hölder (1901) (translated in Michell &amp; Ernst, 1996). A fundamental feature of any type of quantity is that the relationships of equality or inequality can in principle be stated in comparisons between particular magnitudes, unlike quality, which is marked by likeness, similarity and difference, diversity. Another fundamental feature is additivity. Additivity may involve concatenation, such as adding two lengths A and B to obtain a third A + B. Additivity is not, however, restricted to extensive quantities but may also entail relations between magnitudes that can be established through experiments that permit tests of hypothesized [[observable]] manifestations of the additive relations of magnitudes. Another feature is continuity, on which Michell (1999, p.&amp;nbsp;51) says of length, as a type of quantitative attribute, "what continuity means is that if any arbitrary length, a, is selected as a unit, then for every positive real number, ''r'', there is a length b such that b = ''r''a". A further generalization is given by the [[theory of conjoint measurement]], independently developed by French economist [[Gérard Debreu]] (1960) and by the American mathematical psychologist [[R. Duncan Luce]] and statistician [[John Tukey]] (1964).

==Quantity in mathematics==
{{Confusing|section|date=March 2012}}
Magnitude (how much) and multitude (how many), the two principal types of quantities, are further divided as mathematical and physical. In formal terms, quantities—their ratios, proportions, order and formal relationships of equality and inequality—are studied by mathematics. The essential part of mathematical quantities consists of having a collection of [[Variable (mathematics)|variables]], each assuming a [[Set (mathematics)|set]] of values. These can be a set of a single quantity, referred to as a [[Scalar (mathematics)|scalar]] when represented by real numbers, or have multiple quantities as do [[Euclidean vector|vectors]] and [[tensor]]s, two kinds of geometric objects.

The mathematical usage of a quantity can then be varied and so is situationally dependent. Quantities can be used as being [[infinitesimal]], [[Argument of a function|arguments of a function]], variables in an [[Expression (mathematics)|expression]] (independent or dependent), or probabilistic as in random and [[stochastic]] quantities. In mathematics, magnitudes and multitudes are also not only two distinct kinds of quantity but furthermore relatable to each other.

[[Number theory]] covers the topics of the [[continuous and discrete variables|discrete quantities]] as numbers: number systems with their kinds and relations. [[Geometry]] studies the issues of spatial magnitudes: straight lines, curved lines, surfaces and solids, all with their respective measurements and relationships.

A traditional [[philosophy of mathematics]], stemming from [[Aristotle]] and remaining popular until the eighteenth century, held that mathematics is the "science of quantity". Quantity was considered to be divided into the discrete (studied by arithmetic) and the continuous (studied by geometry and later [[calculus]]). The theory fits reasonably well elementary or school mathematics but less well the abstract topological and algebraic structures of modern mathematics.&lt;ref&gt;J. Franklin, ''An Aristotelian Realist Philosophy of Mathematics'', Palgrave Macmillan, Basingstoke, 2014, pp. 31-2.&lt;/ref&gt;

==Quantity in physical science==
{{main|Physical quantity}}

Establishing quantitative structure and relationships ''between'' different quantities is the cornerstone of modern physical sciences. Physics is fundamentally a quantitative science. Its progress is chiefly achieved due to rendering the abstract qualities of material entities into physical quantities, by postulating that all material bodies marked by quantitative properties or physical dimensions are subject to some measurements and observations. Setting the units of measurement, physics covers such fundamental quantities as space (length, breadth, and depth) and time, mass and force, temperature, energy, and [[quantum|quanta]].

A distinction has also been made between [[intensive quantity]] and [[extensive quantity]] as two types of quantitative property, state or relation. The magnitude of an ''intensive quantity'' does not depend on the size, or extent, of the object or system of which the quantity is a property, whereas magnitudes of an ''extensive quantity'' are additive for parts of an entity or subsystems. Thus, magnitude does depend on the extent of the entity or system in the case of extensive quantity. Examples of intensive quantities are [[density]] and [[pressure]], while examples of extensive quantities are [[energy]], [[volume]], and [[mass]].

==Quantity in natural language==
In human languages, including [[English language|English]], [[grammatical number|number]] is a [[syntactic category]], along with [[person]] and [[gender]]. The quantity is expressed by identifiers, definite and indefinite, and [[Quantifier_(linguistics)|quantifiers]], definite and indefinite, as well as by three types of [[noun]]s: 1. count unit nouns or countables; 2. [[mass nouns]], uncountables, referring to the indefinite, unidentified amounts; 3. nouns of multitude ([[collective noun]]s). The word ‘number’ belongs to a noun of multitude standing either for a single entity or for the individuals making the whole. An amount in general is expressed by a special class of words called identifiers, indefinite and definite and quantifiers, definite and indefinite.{{clarify|date=October 2017}} The amount may be expressed by: singular form and plural from, ordinal numbers before a count noun singular (first, second, third...), the demonstratives; definite and indefinite numbers and measurements (hundred/hundreds, million/millions), or cardinal numbers before count nouns. The set of language quantifiers covers "a few, a great number, many, several (for count names); a bit of, a little, less, a great deal (amount) of, much (for mass names); all, plenty of, a lot of, enough, more, most, some, any, both, each, either, neither, every, no". For the complex case of unidentified amounts, the parts and examples of a mass are indicated with respect to the following: a measure of a mass (two kilos of rice and twenty bottles of milk or ten pieces of paper); a piece or part of a mass (part, element, atom, item, article, drop); or a shape of a container (a basket, box, case, cup, bottle, vessel, jar).

==Further examples==
Some further examples of quantities are:

* 1.76 litres ([[liter]]s) of milk, a continuous quantity
* 2''πr'' metres, where ''r'' is the length of a [[radius]] of a [[circle]] expressed in metres (or meters), also a continuous quantity
* one apple, two apples, three apples, where the number is an integer representing the count of a denumerable collection of objects (apples)
* 500 people (also a count)
* a ''couple'' conventionally refers to two objects
* ''a few'' usually refers to an indefinite, but usually small number, greater than one.
* ''quite a few'' also refers to an indefinite, but surprisingly (in relation to the context) large number.
* ''several'' refers to an indefinite, but usually small, number - usually indefinitely greater than "a few".
* OPEC has a few members

==See also==
*[[Dimensionless quantity]]
*[[Quantification (science)]]
*[[Observable quantity]]

==References==
{{Reflist}}
{{More footnotes|date=July 2010}}
{{refbegin}}

* Aristotle, Logic (Organon): Categories, in Great Books of the Western World, V.1. ed. by Adler, M.J., [[Encyclopædia Britannica]], Inc., Chicago (1990)
* Aristotle, Physical Treatises: Physics, in Great Books of the Western World, V.1, ed. by Adler, M.J., Encyclopædia Britannica, Inc., Chicago (1990)
* Aristotle, Metaphysics, in Great Books of the Western World, V.1, ed. by Adler, M.J., Encyclopædia Britannica, Inc., Chicago (1990)
* Franklin, J. (2014). [https://books.google.com.au/books?hl=en&amp;lr=&amp;id=2QBgAwAAQBAJ&amp;oi=fnd&amp;pg=PA221&amp;ots=0GJ1XuLXVl&amp;sig=3uVYyPvoaRd2OIelENAXedtCeGA#v=onepage&amp;q&amp;f=false Quantity and number], in ''Neo-Aristotelian Perspectives in Metaphysics'', ed. D.D. Novotny and L. Novak, New York: Routledge, 221-44.
* Hölder, O. (1901). Die Axiome der Quantität und die Lehre vom Mass. ''Berichte über die Verhandlungen der Königlich Sachsischen Gesellschaft der Wissenschaften zu Leipzig'', Mathematische-Physicke Klasse, 53, 1-64.
* Klein, J. (1968). ''Greek Mathematical Thought and the Origin of Algebra. Cambridge''. Mass: [[MIT Press]].
* Laycock, H. (2006). Words without Objects: Oxford, Clarendon Press. [http://www.oxfordscholarship.com/oso/public/content/philosophy/0199281718/toc.html# Oxfordscholarship.com]
* Michell, J. (1993). The origins of the representational theory of measurement: Helmholtz, Hölder, and Russell. ''Studies in History and Philosophy of Science'', 24, 185-206.
* Michell, J. (1999). ''Measurement in Psychology''. Cambridge: [[Cambridge University Press]].
* Michell, J. &amp; Ernst, C. (1996).  The axioms of quantity and the theory of measurement: translated from Part I of Otto Hölder’s German text "Die Axiome der Quantität und die Lehre vom Mass". ''Journal of Mathematical Psychology'', 40, 235-252.
* Newton, I. (1728/1967). Universal Arithmetic: Or, a Treatise of Arithmetical Composition and Resolution. In D.T. Whiteside (Ed.), ''The mathematical Works of Isaac Newton'', Vol. 2 (pp.&amp;nbsp;3–134). New York: Johnson Reprint Corp.
* Wallis, J. ''Mathesis universalis'' (as quoted in Klein, 1968).

{{refend}}

== External links ==
{{Wiktionary|quantity|few}}
{{wikiquote}}

[[Category:Concepts in metaphysics]]
[[Category:Measurement]]
[[Category:Ontology]]
[[Category:Quantity| ]]</text>
      <sha1>f1xpkhzm17wlq9hxd0d92hnogpuur26</sha1>
    </revision>
  </page>
  <page>
    <title>Reciprocal polynomial</title>
    <ns>0</ns>
    <id>1106042</id>
    <revision>
      <id>852750674</id>
      <parentid>846970624</parentid>
      <timestamp>2018-07-31T03:11:57Z</timestamp>
      <contributor>
        <username>Skullturfq</username>
        <id>31034471</id>
      </contributor>
      <minor/>
      <comment>Corrected spelling of surname "Knuth" in references</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11653">In [[algebra]], the '''reciprocal polynomial''', or '''reflected polynomial'''&lt;ref name="concrete"&gt;*{{cite book | last = Graham | first = Ronald |last2=Knuth|first2=Donald E.|last3=Patashnik|first3=Oren | title = [[Concrete mathematics]] : a foundation for computer science | publisher = Addison-Wesley | location = Reading, Mass | year = 1994 | isbn = 978-0201558029 | page= 339}}&lt;/ref&gt;&lt;ref name="Aigner"&gt;{{cite book | last = Aigner | first = Martin | title = A course in enumeration | publisher = Springer | location = Berlin New York | year = 2007 | isbn = 978-3540390329 | page = 94 }}&lt;/ref&gt; {{math|''p''&lt;sup&gt;∗&lt;/sup&gt;}} or {{math|''p''&lt;sup&gt;R&lt;/sup&gt;}},&lt;ref name="Aigner"/&gt;&lt;ref name="concrete"/&gt; of a [[polynomial]] {{math|''p''}} of degree {{math|''n''}} with coefficients from an arbitrary [[Field (mathematics)|field]], such as
:&lt;math&gt;p(x) = a_0 + a_1x + a_2x^2 + \cdots + a_nx^n, \,\!&lt;/math&gt;
is the polynomial&lt;ref&gt;{{harvnb|Roman|1995|loc=pg.37}}&lt;/ref&gt;

: &lt;math&gt;p^*(x) = a_n + a_{n-1}x + \cdots + a_0x^n = x^n p(x^{-1}).&lt;/math&gt;

Essentially, the coefficients are written in reverse order. They arise naturally in [[linear algebra]] as the [[characteristic polynomial]] of the [[inverse of a matrix]].

In the special case that the [[polynomial]] {{math|''p''}} has [[complex number|complex]] coefficients, that is,

:&lt;math&gt;p(z) = a_0 + a_1z + a_2z^2 + \cdots + a_nz^n, \,\!&lt;/math&gt;

the '''conjugate reciprocal polynomial''', {{math|''p''&lt;sup&gt;†&lt;/sup&gt;}} given by,

:&lt;math&gt;p^{\dagger}(z) = \overline{a_n} + \overline{a_{n-1}}z + \cdots + \overline{a_0}z^n = z^n\overline{p(\bar{z}^{-1})},&lt;/math&gt;

where &lt;math&gt;\overline{a_i}&lt;/math&gt; denotes the [[complex conjugate]] of &lt;math&gt;a_i \,\!&lt;/math&gt;, is also called the reciprocal polynomial when no confusion can arise.

A polynomial {{math|''p''}} is called '''self-reciprocal''' or '''palindromic''' if {{math|1=''p''(''x'') = ''p''&lt;sup&gt;∗&lt;/sup&gt;(''x'')}}.
The coefficients of a self-reciprocal polynomial satisfy {{math|1=''a''&lt;sub&gt;''i''&lt;/sub&gt; = ''a''&lt;sub&gt;''n''&amp;minus;''i''&lt;/sub&gt;}}. In the conjugate reciprocal case, the coefficients must be [[Real number|real]] to satisfy the condition.

== Properties ==
Reciprocal polynomials have several connections with their original polynomials, including:
# ''p''(''x'')=''x''&lt;sup&gt;''n''&lt;/sup&gt;''p''&lt;sup&gt;*&lt;/sup&gt;(''x''&lt;sup&gt;−1&lt;/sup&gt;)&lt;ref name="Aigner"/&gt;
# {{math|α}} is a root of polynomial {{math|''p''}} if and only if {{math|α&lt;sup&gt;−1&lt;/sup&gt;}} is a root of {{math|''p''&lt;sup&gt;∗&lt;/sup&gt;}}.&lt;ref name="Pless 1990 loc=pg. 57"&gt;{{harvnb|Pless|1990|loc=pg. 57}}&lt;/ref&gt;
# If {{math|''p''(''x'') ≠ ''x''}} then {{math|''p''}} is [[Irreducible polynomial|irreducible]] if and only if {{math|''p''&lt;sup&gt;∗&lt;/sup&gt;}} is irreducible.&lt;ref name="Roman 1995 loc= pg. 37"&gt;{{harvnb|Roman|1995|loc= pg. 37}}&lt;/ref&gt;
# {{math|''p''}} is [[Primitive polynomial (field theory)|primitive]] if and only if {{math|''p''&lt;sup&gt;∗&lt;/sup&gt;}} is primitive.&lt;ref name="Pless 1990 loc=pg. 57"/&gt;

Other properties of reciprocal polynomials may be obtained, for instance:
* If a polynomial is self-reciprocal and irreducible then it must have even degree.&lt;ref name="Roman 1995 loc= pg. 37"/&gt;

=={{anchor|Palindromic polynomial}} Palindromic and antipalindromic polynomials==
A self-reciprocal polynomial is also called palindromic because its coefficients, when the polynomial is written in the order of ascending or descending powers, form a [[palindrome]]. That is, if
:&lt;math&gt; P(x) = \sum_{i=0}^n a_ix^i&lt;/math&gt; 
is a polynomial of [[Degree of a polynomial|degree]] {{math|''n''}}, then {{math|''P''}} is ''palindromic'' if {{math|1=''a&lt;sub&gt;i&lt;/sub&gt;'' = ''a''&lt;sub&gt;''n'' − ''i''&lt;/sub&gt;}} for {{math|1=''i'' = 0, 1, ..., ''n''}}. Some authors use the terms ''palindromic'' and ''reciprocal'' interchangeably.

Similarly, {{math|''P''}}, a polynomial of degree {{math|''n''}}, is called '''antipalindromic''' if {{math|1=''a&lt;sub&gt;i&lt;/sub&gt;'' = −''a''&lt;sub&gt;''n'' − ''i''&lt;/sub&gt;}} for {{math|1=''i'' = 0, 1, ... ''n''}}. That is, a polynomial {{math|''P''}} is ''antipalindromic'' if {{math|1=''P''(''x'') = – ''P''&lt;sup&gt;∗&lt;/sup&gt;(''x'')}}.

===Examples===
From the properties of the [[binomial coefficient]]s, it follows that the polynomials {{math|1=''P''(''x'') = (''x'' + 1 )&lt;sup&gt;''n''&lt;/sup&gt;}} are palindromic for all positive integers {{math|''n''}}, while the polynomials {{math|1=''Q''(''x'') = (''x'' – 1 )&lt;sup&gt;''n''&lt;/sup&gt;}} are palindromic when {{math|''n''}} is even and antipalindromic when {{math|''n''}} is odd.

Other examples of palindromic polynomials include [[cyclotomic polynomial]]s and [[Eulerian polynomial]]s.

===Properties===
* If {{math|''a''}} is a root of a polynomial that is either palindromic or antipalindromic, then {{sfrac|{{math|''a''}}}} is also a root and has the same [[multiplicity (mathematics)|multiplicity]].&lt;ref&gt;{{harvnb|Pless|1990|loc=pg. 57}} for the palindromic case only&lt;/ref&gt;
* The converse is true: If a polynomial is such that if {{math|''a''}} is a root then {{sfrac|{{math|''a''}}}} is also a root of the same multiplicity, then the polynomial is either palindromic or antipalindromic.
* For any polynomial {{math|''q''}}, the polynomial {{math|''q'' + ''q''&lt;sup&gt;∗&lt;/sup&gt;}} is palindromic and the polynomial {{math|''q'' − ''q''&lt;sup&gt;∗&lt;/sup&gt;}} is antipalindromic.
* Any polynomial {{math|''q''}} can be written as the sum of a palindromic and an antipalindromic polynomial.&lt;ref&gt;{{citation|first=Jonathan Y.|last=Stein|title=Digital Signal Processing: A Computer Science Perspective|publisher=Wiley Interscience|year=2000|page=384|isbn=9780471295464}}&lt;/ref&gt;
* The product of two palindromic or antipalindromic polynomials is palindromic.
* The product of a palindromic polynomial and an antipalindromic polynomial is antipalindromic.
* A palindromic polynomial of odd degree is a multiple of {{math|''x'' + 1}} (it has –1 as a root) and its quotient by {{math|''x'' + 1}} is also palindromic.
* An antipalindromic polynomial is a multiple of {{math|''x'' – 1}} (it has 1 as a root) and its quotient by {{math|''x'' – 1}} is palindromic.
* An antipalindromic polynomial of even degree is a multiple of {{math|''x''&lt;sup&gt;2&lt;/sup&gt; – 1}} (it has -1 and 1 as a roots) and its quotient by {{math|''x''&lt;sup&gt;2&lt;/sup&gt; – 1}} is palindromic. 
* If {{math|''p''(''x'')}} is a palindromic polynomial of even degree {{mvar|2d}}, then there is a polynomial {{math|''q''}} of degree {{math|''d''}} such that {{math|1=''p''(''x'') = ''x''&lt;sup&gt;''d''&lt;/sup&gt;''q''(''x'' + {{sfrac|1|''x''}})}} (Durand 1961).
* If {{math|''p''(''x'')}} is a monic antipalindromic polynomial of even degree {{mvar|2d}} over a field {{mvar|k}} with odd [[Characteristic (field)|characteristic]], then it can be written uniquely as {{math|1=''p''(''x'') = ''x''&lt;sup&gt;''d''&lt;/sup&gt; (''Q''(''x'') − ''Q''({{sfrac|''x''}}))}}, where {{mvar|Q}} is a monic polynomial of degree {{mvar|d}} with no constant term.&lt;ref&gt;{{citation|first=Nicholas M.|last=Katz|title=Convolution and Equidistribution : Sato-Tate Theorems for Finite Field Mellin Transformations|publisher=Princeton University Press|year=2012|isbn=9780691153315|page=146}}&lt;/ref&gt;
* If an antipalindromic polynomial {{math|''P''}} has even degree {{math|2''n''}}, then its "middle" coefficient (of power {{math|''n''}}) is 0 since {{math|1=''a&lt;sub&gt;n&lt;/sub&gt;'' = −''a&lt;sub&gt;2n – n&lt;/sub&gt;''}}.

===Real coefficients===
A polynomial with [[Real number|real]] coefficients all of whose [[Complex number|complex]] roots lie on the unit circle in the [[complex plane]] (all the roots are unimodular) is either palindromic or antipalindromic.&lt;ref&gt;{{citation|first1=Ivan|last1=Markovsky|first2=Shodhan|last2=Rao|title=Palindromic polynomials, time-reversible systems and conserved quantities|journal=Control and Automation|year=2008|doi=10.1109/MED.2008.4602018}}&lt;/ref&gt;

==Conjugate reciprocal polynomials==

A polynomial is '''conjugate reciprocal''' if &lt;math&gt;p(x) \equiv p^{\dagger}(x)&lt;/math&gt; and '''self-inversive''' if &lt;math&gt;p(x) = \omega p^{\dagger}(x)&lt;/math&gt; for a scale factor {{math|ω}} on the [[unit circle]].&lt;ref name=SV08&gt;{{cite book | last1=Sinclair | first1=Christopher D. | last2=Vaaler | first2=Jeffrey D. | chapter=Self-inversive polynomials with all zeros on the unit circle | zbl=1334.11017 | editor1-last=McKee | editor1-first=James | editor2-last=Smyth | editor2-first=C. J. | title=Number theory and polynomials. Proceedings of the workshop, Bristol, UK, April 3–7, 2006 | location=Cambridge | publisher=[[Cambridge University Press]] | isbn=978-0-521-71467-9 | series=London Mathematical Society Lecture Note Series | volume=352 | pages=312–321 | year=2008 }}&lt;/ref&gt;

If {{math|''p''(''z'')}} is the [[Minimal polynomial (field theory)|minimal polynomial]] of {{math|''z''&lt;sub&gt;0&lt;/sub&gt;}} with {{math|1={{abs|''z''&lt;sub&gt;0&lt;/sub&gt;}} = 1, ''z''&lt;sub&gt;0&lt;/sub&gt; ≠ 1}}, and {{math|''p''(''z'')}} has [[real number|real]] coefficients, then {{math|''p''(''z'')}} is self-reciprocal.  This follows because

:&lt;math&gt;z_0^n\overline{p(1/\bar{z_0})} = z_0^n\overline{p(z_0)} = z_0^n\bar{0} = 0.&lt;/math&gt;

So {{math|''z''&lt;sub&gt;0&lt;/sub&gt;}} is a root of the polynomial &lt;math&gt;z^n\overline{p(\bar{z}^{-1})}&lt;/math&gt; which has degree {{math|''n''}}.  But, the minimal polynomial is unique, hence 
:&lt;math&gt;cp(z) = z^n\overline{p(\bar{z}^{-1})}&lt;/math&gt;
for some constant {{math|''c''}}, i.e. &lt;math&gt;ca_i=\overline{a_{n-i}}=a_{n-i}&lt;/math&gt;. Sum from {{math|1=''i'' = 0}} to {{math|''n''}} and note that 1 is not a root of {{math|''p''}}. We conclude that {{math|1=''c'' = 1}}.

A consequence is that the [[cyclotomic polynomial]]s {{math|Φ&lt;sub&gt;''n''&lt;/sub&gt;}} are self-reciprocal for {{math|''n'' &gt; 1}}. This is used in the [[special number field sieve]] to allow numbers of the form {{math|''x''&lt;sup&gt;11&lt;/sup&gt; ± 1, ''x''&lt;sup&gt;13&lt;/sup&gt; ± 1, ''x''&lt;sup&gt;15&lt;/sup&gt; ± 1}} and {{math|''x''&lt;sup&gt;21&lt;/sup&gt; ± 1}} to be factored taking advantage of the algebraic factors by using polynomials of degree 5, 6, 4 and 6 respectively – note that {{math|φ}} ([[Euler's totient function]]) of the exponents are 10, 12, 8 and 12.

==Application in coding theory==

The reciprocal polynomial finds a use in the theory of [[Cyclic code|cyclic error correcting codes]]. Suppose {{math|''x''&lt;sup&gt;''n''&lt;/sup&gt; &amp;minus; 1}} can be factored into the product of two polynomials, say {{math|1=''x''&lt;sup&gt;''n''&lt;/sup&gt; &amp;minus; 1 = ''g''(''x'')''p''(''x'')}}. When {{math|''g''(''x'')}} generates a cyclic code {{math|''C''}}, then the reciprocal polynomial {{math|''p''&lt;sup&gt;∗&lt;/sup&gt;}} generates {{math|''C''&lt;sup&gt;⊥&lt;/sup&gt;}}, the [[orthogonal complement]] of {{math|''C''}}.&lt;ref&gt;{{harvnb|Pless|1990|loc = pg. 75, Theorem 48}}&lt;/ref&gt;
Also, {{math|''C''}} is ''self-orthogonal'' (that is, {{math|''C'' ⊆ ''C''&lt;sup&gt;⊥&lt;/sup&gt;)}}, if and only if  {{math|''p''&lt;sup&gt;∗&lt;/sup&gt;}} divides {{math|''g''(''x'')}}.&lt;ref&gt;{{harvnb|Pless|1990|loc = pg. 77, Theorem 51}}&lt;/ref&gt;

== Notes ==
{{reflist}}

==References==
{{More citations needed|date=June 2008}}
* {{citation|first=Vera|last=Pless|title=Introduction to the Theory of Error Correcting Codes|edition=2nd|publisher=Wiley-Interscience|place=New York|year=1990|isbn=0-471-61884-5}}
* {{citation|first=Steven|last=Roman|title=Field Theory|publisher=Springer-Verlag|place=New York|year=1995|isbn=0-387-94408-7}}
* Émile Durand (1961) Solutions numériques des équations algrébriques I, Masson et Cie: XV - polynômes dont les coefficients sont symétriques ou antisymétriques, p.&amp;nbsp;140-141.

== External links ==
* {{MathPages|id=home/kmath294/kmath294|title=The Fundamental Theorem for Palindromic Polynomials}}
* [http://mathworld.wolfram.com/ReciprocalPolynomial.html Reciprocal Polynomial] (on [[MathWorld]])

[[Category:Polynomials]]</text>
      <sha1>fextr5phxn587r7ke7yazro6nlkzhn1</sha1>
    </revision>
  </page>
  <page>
    <title>Six operations</title>
    <ns>0</ns>
    <id>39560800</id>
    <revision>
      <id>852094307</id>
      <parentid>834021687</parentid>
      <timestamp>2018-07-26T15:51:30Z</timestamp>
      <contributor>
        <ip>145.116.185.219</ip>
      </contributor>
      <comment>/* The operations */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6678">In [[mathematics]], '''Grothendieck's six operations''', named after [[Alexander Grothendieck]], is a formalism in [[homological algebra]].  It originally sprang from the relations in [[étale cohomology]] that arise from a morphism of [[scheme (mathematics)|scheme]]s {{nowrap|''f'' : ''X'' &amp;rarr; ''Y''}}.  The basic insight was that many of the elementary facts relating cohomology on ''X'' and ''Y'' were formal consequences of a small number of axioms.  These axioms hold in many cases completely unrelated to the original context, and therefore the formal consequences also hold.  The six operations formalism has since been shown to apply to contexts such as ''D''-modules on algebraic varieties, sheaves on locally compact topological spaces, and motives.

== The operations ==
The operations are six functors.  Usually these are functors between derived categories and so are actually left and right [[derived functor]]s.

* the [[Direct image functor|direct image]] &lt;math&gt;f_*&lt;/math&gt;
* the [[Inverse image functor|inverse image]] &lt;math&gt;f^*&lt;/math&gt;
* the [[Direct image with compact support|proper (or extraordinary) direct image]] &lt;math&gt;f_!&lt;/math&gt;
* the [[Exceptional inverse image functor|proper (or extraordinary) inverse image]] &lt;math&gt;f^!&lt;/math&gt;
* internal [[tensor product]]
* [[internal Hom]]

The functors &lt;math&gt;f^*&lt;/math&gt; and &lt;math&gt;f_*&lt;/math&gt; form an [[adjoint functor]] pair, as do &lt;math&gt;f_!&lt;/math&gt; and &lt;math&gt;f^!&lt;/math&gt;.&lt;ref name=Fausk2003&gt;{{cite journal|last=Fausk|first=H. |author2=P. Hu |author3=J. P. May|title=Isomorphisms between left and right adjoints|journal=Theory Appl. Categ.|year=2003|pages=107–131|doi=|url=http://www.math.uiuc.edu/K-theory/0573/FormalFeb16.pdf|accessdate=6 June 2013|doi-broken-date=2014-05-06}}&lt;/ref&gt;  Similarly, internal tensor product is left adjoint to internal Hom.

== Six operations in étale cohomology ==

Let {{nowrap|''f'' : ''X'' &amp;rarr; ''Y''}} be a morphism of schemes.  The morphism ''f'' induces several functors.  Specifically, it gives [[adjoint functors]] ''f''&lt;sup&gt;*&lt;/sup&gt; and ''f''&lt;sub&gt;*&lt;/sub&gt; between the categories of sheaves on ''X'' and ''Y'', and it gives the functor ''f''&lt;sub&gt;!&lt;/sub&gt; of direct image with proper support.  In the [[derived category]], ''Rf''&lt;sub&gt;!&lt;/sub&gt; admits a right adjoint ''f''&lt;sup&gt;!&lt;/sup&gt;.  Finally, when working with abelian sheaves, there is a tensor product functor &amp;otimes; and an internal Hom functor, and these are adjoint.  The six operations are the corresponding functors on the derived category: {{nowrap|''Lf''&lt;sup&gt;*&lt;/sup&gt;}}, {{nowrap|''Rf''&lt;sub&gt;*&lt;/sub&gt;}}, {{nowrap|''Rf''&lt;sub&gt;!&lt;/sub&gt;}}, {{nowrap|''f''&lt;sup&gt;!&lt;/sup&gt;}}, {{nowrap|&amp;otimes;&lt;sup&gt;''L''&lt;/sup&gt;}}, and {{nowrap|RHom}}.

Suppose that we restrict ourselves to a category of &lt;math&gt;\ell&lt;/math&gt;-adic torsion sheaves, where &lt;math&gt;\ell&lt;/math&gt; is coprime to the characteristic of ''X'' and of ''Y''.  In SGA 4 III, Grothendieck and Artin proved that if ''f'' is a smooth morphism, then ''Lf''&lt;sup&gt;*&lt;/sup&gt; is isomorphic to {{nowrap|''f''&lt;sup&gt;!&lt;/sup&gt;(&amp;minus;''d'')[&amp;minus;2''d'']}}, where {{nowrap|(&amp;minus;''d'')}} denote the ''d''th inverse [[Tate twist]] and {{nowrap|[&amp;minus;2''d'']}} denotes a shift in degree by {{nowrap|&amp;minus;2''d''}}.  Furthermore, suppose that ''f'' is separated and of finite type.  If {{nowrap|''g'' : ''Y''&amp;prime; &amp;rarr; ''Y''}} is another morphism of schemes, if {{nowrap|''X''&amp;prime;}} denotes the base change of ''X'' by ''g'', and if ''f''&amp;prime; and ''g''&amp;prime; denote the base changes of ''f'' and ''g'' by ''g'' and ''f'', respectively, then there exist natural isomorphisms:
:&lt;math&gt;Lg^* \circ Rf_! \to Rf'_! \circ Lg'^*,&lt;/math&gt;
:&lt;math&gt;Rg'_* \circ f'^! \to f^! \circ Rg_*.&lt;/math&gt;
Again assuming that ''f'' is separated and of finite type, for any objects ''M'' in the derived category of ''X'' and ''N'' in the derived category of ''Y'', there exist natural isomorphisms:
:&lt;math&gt;(Rf_!M) \otimes_Y N \to Rf_!(M \otimes_X Lf^*N),&lt;/math&gt;
:&lt;math&gt;\operatorname{RHom}_Y(Rf_! M, N) \to Rf_*\operatorname{RHom}_X(M, f^!N),&lt;/math&gt;
:&lt;math&gt;f^!\operatorname{RHom}_Y(M, N) \to \operatorname{RHom}_X(Lf^*M, f^!N).&lt;/math&gt;

If ''i'' is a closed immersion of ''Z'' into ''S'' with complementary open immersion ''j'', then there is a distinguished triangle in the derived category:
:&lt;math&gt;Rj_!j^! \to 1 \to Ri_*i^* \to Rj_!j^![1],&lt;/math&gt;
where the first two maps are the counit and unit, respectively of the adjunctions.  If ''Z'' and ''S'' are regular, then there is an isomorphism:
:&lt;math&gt;1_Z(-c)[-2c] \to i^!1_S,&lt;/math&gt;
where {{nowrap|1&lt;sub&gt;''Z''&lt;/sub&gt;}} and {{nowrap|1&lt;sub&gt;''S''&lt;/sub&gt;}} are the units of the tensor product operations (which vary depending on which category of &lt;math&gt;\ell&lt;/math&gt;-adic torsion sheaves is under consideration).

If ''S'' is regular and {{nowrap|''g'' : ''X'' &amp;rarr; ''S''}}, and if ''K'' is an invertible object in the derived category on ''S'' with respect to {{nowrap|&amp;otimes;&lt;sup&gt;''L''&lt;/sup&gt;}}, then define ''D''&lt;sub&gt;''X''&lt;/sub&gt; to be the functor {{nowrap|RHom(—, ''g''&lt;sup&gt;!&lt;/sup&gt;''K'')}}.  Then, for objects ''M'' and ''M''&amp;prime; in the derived category on ''X'', the canonical maps:
:&lt;math&gt;M \to D_X(D_X(M)),&lt;/math&gt;
:&lt;math&gt;D_X(M \otimes D_X(M')) \to \operatorname{RHom}(M, M'),&lt;/math&gt;
are isomorphisms.  Finally, if {{nowrap|''f'' : ''X'' &amp;rarr; ''Y''}} is a morphism of ''S''-schemes, and if ''M'' and ''N'' are objects in the derived categories of ''X'' and ''Y'', then there are natural isomorphisms:
:&lt;math&gt;D_X(f^*N) \cong f^!(D_Y(N)),&lt;/math&gt;
:&lt;math&gt;D_X(f^!N) \cong f^*(D_Y(N)),&lt;/math&gt;
:&lt;math&gt;D_Y(f_!M) \cong f_*(D_X(M)),&lt;/math&gt;
:&lt;math&gt;D_Y(f_*M) \cong f_!(D_X(M)).&lt;/math&gt;

== See also ==
*[[Coherent duality]]
*[[Grothendieck local duality]]
*[[Image functors for sheaves]]
*[[Verdier duality]]
*[[Change of rings]]

== References ==
{{reflist}}

*Laszlo, Yves, and Olsson, Martin, "The six operations for sheaves on Artin stacks I: Finite coefficients", [https://arxiv.org/pdf/math/0512097v2.pdf].
*Ayoub, Joseph, "Les six opérations de Grothendieck et le formalisme des cycles évanescents dans le monde motivique", [http://www.math.uiuc.edu/K-theory/0761/THESE.pdf].
*Cisinski, Denis-Charles, and Déglise, Frédéric, "Triangulated categories of mixed motives", [https://arxiv.org/pdf/0912.2110v3.pdf].
*Mebkhout, Zoghman, ''Le formalisme des six opérations de Grothendieck pour les D&lt;sub&gt;X&lt;/sub&gt;-modules cohérents'', Travaux en Cours, vol. 35, Hermann, Paris (1989).

== External links ==
*{{nlab|id=six+operations|title=six operations}}
*http://mathoverflow.net/questions/170319/what-if-anything-unifies-stable-homotopy-theory-and-grothendiecks-six-functor

[[Category:Sheaf theory]]
[[Category:Homological algebra]]
[[Category:Duality theories]]</text>
      <sha1>75vusgqtsvi21x7tf94hmh0zsmflz4i</sha1>
    </revision>
  </page>
  <page>
    <title>The Art of Mathematics</title>
    <ns>0</ns>
    <id>47243080</id>
    <revision>
      <id>858082628</id>
      <parentid>858082529</parentid>
      <timestamp>2018-09-04T23:06:43Z</timestamp>
      <contributor>
        <ip>75.157.22.136</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2526">{{italic title}}
'''''The Art of Mathematics''''' ({{lang-ko|수학의 정석 suhakui jeongseok}}), written by Hong Sung-Dae ({{lang-ko|홍성대 Hong Seong-Dae}}), is a series of mathematics textbooks for high school students in South Korea. First published in 1966, it is aguably the best-selling mathematics textbook series in South Korea, with about 37 million copies sold as of 2006.&lt;ref&gt;{{cite web|url=http://article.joins.com/article/article.asp?Total_ID=2432384 |title=`정석` 40년 3700만 권 팔려 ... 에베레스트 125개 높이 |publisher=Joongang Daily|accessdate=2015-07-15}}&lt;/ref&gt; In [[Jeongeup]], [[North Jeolla Province]], the hometown of Hong Sung-Dae, a street is named {{lang-ko|수학정석길 Suhakjeongseok-gil}} in honor of the author.'&lt;ref&gt;http://map.naver.com/?dlevel=12&amp;pinType=site&amp;pinId=19651754&amp;x=126.9429375&amp;y=35.6531708&amp;enc=b64&lt;/ref&gt;

==Major topics in the 11th edition&lt;ref&gt;{{cite web|url=http://www.sungji.com/Event/Lecture_2014_Info.aspx |title=2014년도 적용 새 교육 과정 안내 |publisher=Sung Ji Publications|accessdate=2015-07-16}}&lt;/ref&gt;==
Changes in the 11th edition, published 2013-2015, reflect the 2009 revision of South Korea's National Curriculum ([[:ko:2009 개정 교육과정]] icheon-gu gaejeong gyoyuggwajeong). Each of the six volumes consist of two versions, one for average students ({{lang-ko|기본편}} Gibon-pyeon) and one for higher-ability students ({{lang-ko|실력편 silyeok-pyeon}}).

===Mathematics I===
{{lang-ko|수학 I suhak I}}
*Polynomials
*Equations and Inequalities
*Graphs of Equations

===Mathematics II===
{{lang-ko|수학 II suhak II}}
*Sets and Propositions
*Functions
*Sequences
*Exponents and Logarithms

===Probability and Statistics===
{{lang-ko|확률과 통계 hwanglyulgwa tonggye}}
*Permutations and Combinations
*Probability
*Statistics

===Calculus I===
{{lang-ko|미적분 I mijeokbun I}}
*Limits of Sequences
*Limits and Continuity
*Differentiation of Polynomial Functions
*Integration of Polynomial Functions

===Calculus II===
{{lang-ko|미적분 II mijeokbun II}}
*Exponential and Logarithmic Functions
*Trigonometric Functions
*Differentiation
*Integration

===Geometry and Vectors===
{{lang-ko|기하와 벡터 Gihawa Begteo}}
*Plane Curves
*Vectors in the Plane
*Graphs and Vectors in Space

==References==
{{Reflist}}

== External links ==
*{{ko icon}} [http://www.sungji.com/] publisher's website

{{DEFAULTSORT:Art of Mathematics}}
[[Category:Mathematics textbooks]]
[[Category:1966 books]]
[[Category:Korean books]]</text>
      <sha1>nv44kfynhybz26zo41ku906cq9w0y8l</sha1>
    </revision>
  </page>
  <page>
    <title>Thread automaton</title>
    <ns>0</ns>
    <id>37721302</id>
    <revision>
      <id>744883480</id>
      <parentid>724712822</parentid>
      <timestamp>2016-10-18T01:15:49Z</timestamp>
      <contributor>
        <username>Wikid77</username>
        <id>1403682</id>
      </contributor>
      <comment>fix cite for 2nd "url=" by omit 1st as unneeded +access-date</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4462">In [[automata theory]], the '''thread automaton''' (plural: automata) is an extended type of [[finite-state machine|finite-state automata]] that recognizes a [[mildly context-sensitive language class]] above the [[tree-adjoining grammar|tree-adjoining languages]].&lt;ref name="eric"&gt; {{cite journal | last = Villemonte de la Clergerie | first = Éric | year = 2002 | title = Parsing mildly context-sensitive languages with thread automata | journal = COLING '02 Proceedings of the 19th international conference on Computational linguistics | volume = 1 | issue = 3 |pages= 1–7 |url= http://dl.acm.org/ft_gateway.cfm?id=1072256&amp;ftid=256327&amp;dwn=1&amp;CFID=421201372&amp;CFTOKEN=60649649 |access-date= 2016-10-15 |doi= 10.3115/1072228.1072256  }} &lt;/ref&gt; 

==Formal definition==

A '''thread automaton''' consists of
* a set ''N'' of states,&lt;ref group=note&gt;called ''non-terminal symbols'' by Villemonte (2002), p.1r&lt;/ref&gt;
* a set Σ of terminal symbols,
* a start state ''A''&lt;sub&gt;''S''&lt;/sub&gt; ∈ ''N'',
* a final state ''A''&lt;sub&gt;''F''&lt;/sub&gt; ∈ ''N'',
* a set ''U'' of path components,
* a partial function δ: ''N'' → ''U''&lt;sup&gt;⊥&lt;/sup&gt;, where ''U''&lt;sup&gt;⊥&lt;/sup&gt; = ''U'' ∪ {⊥} for ⊥ ∉ ''U'',
* a finite set Θ of transitions.

A '''path''' ''u''&lt;sub&gt;1&lt;/sub&gt;...''u''&lt;sub&gt;''n''&lt;/sub&gt; ∈ ''U''&lt;sup&gt;[[Kleene star|*]]&lt;/sup&gt; is a string of path components ''u''&lt;sub&gt;''i''&lt;/sub&gt; ∈ ''U''; ''n'' may be 0, with the empty path denoted by ε.
A '''thread''' has the form ''u''&lt;sub&gt;1&lt;/sub&gt;...''u''&lt;sub&gt;''n''&lt;/sub&gt;:''A'', where ''u''&lt;sub&gt;1&lt;/sub&gt;...''u''&lt;sub&gt;''n''&lt;/sub&gt; ∈ ''U''&lt;sup&gt;*&lt;/sup&gt; is a path, and ''A'' ∈ ''N'' is a state.
A '''thread store''' ''S'' is a finite set of threads, viewed as a partial function from ''U''&lt;sup&gt;*&lt;/sup&gt; to ''N'', such that ''dom''(''S'') is [[closure (mathematics)|closed]] by [[prefix (computer science)|prefix]].

A thread automaton '''configuration''' is a triple ‹''l'',''p'',''S''›, where ''l'' denotes the current position in the input string, ''p'' is the active thread, and ''S'' is a thread store containing ''p''.
The '''initial configuration''' is ‹0,ε,{ε:''A''&lt;sub&gt;''S''&lt;/sub&gt;}›.
The '''final configuration''' is ‹''n'',''u'',{ε:''A''&lt;sub&gt;''S''&lt;/sub&gt;,''u'':''A''&lt;sub&gt;''F''&lt;/sub&gt;}›, where ''n'' is the length of the input string and ''u'' abbreviates δ(''A''&lt;sub&gt;''S''&lt;/sub&gt;).
A '''transition''' in the set Θ may have one of the following forms, and changes the current automaton configuration in the following way:
* '''SWAP''' ''B'' →&lt;sub&gt;''a''&lt;/sub&gt; ''C'': &amp;nbsp; consumes the input symbol ''a'', and changes the state of the active thread:
: changes the configuration from &amp;nbsp; ‹''l'',''p'',''S''∪{''p'':''B''}› &amp;nbsp; to &amp;nbsp; ‹''l''+1,''p'',''S''∪{''p'':''C''}›
* '''SWAP''' ''B'' →&lt;sub&gt;ε&lt;/sub&gt; ''C'': &amp;nbsp; similar, but consumes no input:
: changes &amp;nbsp; ‹''l'',''p'',''S''∪{''p'':''B''}› &amp;nbsp; to &amp;nbsp; ‹''l'',''p'',''S''∪{''p'':''C''}›
* '''PUSH''' ''C'': &amp;nbsp; creates a new subthread, and suspends its parent thread:
: changes &amp;nbsp; ‹''l'',''p'',''S''∪{''p'':''B''}› &amp;nbsp; to &amp;nbsp; ‹''l'',''pu'',''S''∪{''p'':''B'',''pu'':''C''}› &amp;nbsp; where ''u''=δ(''B'') and ''pu''∉dom(''S'')
* '''POP''' [''B'']''C'': &amp;nbsp; ends the active thread, returning control to its parent:
: changes &amp;nbsp; ‹''l'',''pu'',''S''∪{''p'':''B'',''pu'':''C''}› &amp;nbsp; to &amp;nbsp; ‹''l'',''p'',''S''∪{''p'':''C''}› &amp;nbsp; where δ(''C'')=⊥ and ''pu''∉dom(''S'')
* '''SPUSH''' [''C''] ''D'': &amp;nbsp; resumes a suspended subthread of the active thread:
: changes &amp;nbsp; ‹''l'',''p'',''S''∪{''p'':''B'',''pu'':''C''}› &amp;nbsp; to &amp;nbsp; ‹''l'',''pu'',''S''∪{''p'':''B'',''pu'':''D''}› &amp;nbsp; where ''u''=δ(''B'')
* '''SPOP''' [''B''] ''D'': &amp;nbsp; resumes the parent of the active thread:
: changes &amp;nbsp; ‹''l'',''pu'',''S''∪{''p'':''B'',''pu'':''C''}› &amp;nbsp; to &amp;nbsp; ‹''l'',''p'',''S''∪{''p'':''D'',''pu'':''C''}› &amp;nbsp; where δ(''C'')=⊥
One may prove that δ(''B'')=''u'' for '''POP''' and '''SPOP''' transitions, and δ(''C'')=⊥ for '''SPUSH''' transitions.&lt;ref&gt;Villemonte (2002), p.1r-2r&lt;/ref&gt;

An input string is '''accepted''' by the automaton if there is a sequence of transitions changing the initial into the final configuration.

==Notes==
{{reflist|group=note}}

==References==
{{reflist}}

{{Formal languages and grammars}}
{{comp-sci-stub}}
[[Category:Models of computation]]
[[Category:Automata (computation)]]</text>
      <sha1>6f567qc68z0kbpbyyo2xkkqct2cseje</sha1>
    </revision>
  </page>
  <page>
    <title>Timeline of geometry</title>
    <ns>0</ns>
    <id>19374248</id>
    <revision>
      <id>771848978</id>
      <parentid>741459819</parentid>
      <timestamp>2017-03-23T21:33:39Z</timestamp>
      <contributor>
        <ip>173.64.123.122</ip>
      </contributor>
      <comment>/* 20th century */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10773">{{Use dmy dates|date=September 2010}}
A [[timeline]] of '''[[algebra]]''' and '''[[geometry]]'''

==Before 1000 BC==
* ca. 2000 BC — [[Scotland]], [[Carved Stone Balls]] exhibit a variety of symmetries including all of the symmetries of [[Platonic solid]]s.
* 1800 BC — [[Moscow Mathematical Papyrus]], findings volume of a frustum
* 1650 BC — [[Rhind Mathematical Papyrus]], copy of a lost scroll from around 1850 BC, the scribe [[Ahmes]] presents one of the first known approximate values of [[pi|π]] at 3.16, the first attempt at [[squaring the circle]], earliest known use of a sort of [[cotangent]], and knowledge of solving first order linear equations

==1st millennium BC==
* 800 BC — Baudhayana, author of the Baudhayana [[Sulba Sutras|Sulba Sutra]], a [[Vedic Sanskrit]] geometric text, contains [[quadratic equations]], and calculates the [[square root of 2]] correct to five decimal places
* ca. 600 BC — the other [[Vedic civilization|Vedic]] “[[Sulba Sutras]]” (“rule of chords” in [[Sanskrit]]) use [[Pythagorean triples]], contain of a number of geometrical proofs, and approximate [[pi|π]] at 3.16
* 5th century BC — [[Hippocrates of Chios]] utilizes [[Lune (mathematics)|lunes]] in an attempt to [[squaring the circle|square the circle]]
* 5th century BC — [[Apastamba]], author of the Apastamba [[Sulba Sutras|Sulba Sutra]], another [[Vedic Sanskrit]] geometric text, makes an attempt at [[squaring the circle]] and also calculates the [[square root]] of 2 correct to five decimal places
* 530 BC — [[Pythagoras]] studies propositional [[geometry]] and vibrating lyre strings; his group also discover the [[irrational number|irrationality]] of the [[square root]] of [[two]],
* 370 BC — [[Eudoxus of Cnidus|Eudoxus]] states the [[method of exhaustion]] for [[area]] determination
* 300 BC — [[Euclid]] in his ''[[Euclid's Elements|Elements]]'' studies [[geometry]] as an [[axiomatic system]], proves the [[Infinite set|infinitude]] of [[prime number]]s and presents the [[Euclidean algorithm]]; he states the law of reflection in  ''Catoptrics'', and he proves the [[fundamental theorem of arithmetic]]
* 260 BC — [[Archimedes]] [[method of exhaustion|proved]] that the value of [[pi|π]] lies between 3&amp;nbsp;+&amp;nbsp;1/7 (approx. 3.1429) and 3&amp;nbsp;+&amp;nbsp;10/71 (approx. 3.1408), that the area of a circle was equal to π multiplied by the square of the radius of the circle and that the area enclosed by a parabola and a straight line is 4/3 multiplied by the area of a triangle with equal base and height. He also gave a very accurate estimate of the value of the square root of 3.
* 225 BC — [[Apollonius of Perga]] writes  ''On [[Conic section|Conic Sections]]'' and names the [[ellipse]], [[parabola]], and [[hyperbola]],
* 150 BC — [[Jainism|Jain]] mathematicians in [[History of India|India]] write the “Sthananga Sutra”, which contains work on the theory of numbers, arithmetical operations, [[geometry]], operations with [[fractions]], simple equations, [[cubic equations]], quartic equations, and [[permutations]] and [[combinations]]
* 140 BC — [[Hipparchus]] develops the bases of [[trigonometry]].

==1st millennium==
* ca. 340 — [[Pappus of Alexandria]] states his [[Pappus's hexagon theorem|hexagon theorem]] and his [[Pappus's centroid theorem|centroid theorem]]
* 500 — [[Aryabhata]] writes the “Aryabhata-Siddhanta”, which first introduces the trigonometric functions and methods of calculating their approximate numerical values. It defines the concepts of [[sine]] and [[cosine]], and also contains the [[Aryabhata's sine table|earliest tables of sine]] and cosine values (in 3.75-degree intervals from 0 to 90 degrees)
* 7th century — [[Bhaskara I]] gives a rational approximation of the sine function
* 8th century — [[Virasena]] gives explicit rules for the [[Fibonacci sequence]], gives the derivation of the [[volume]] of a [[frustum]] using an [[Infinity|infinite]] procedure, and also deals with the [[logarithm]] to [[base 2]] and knows its laws
* 8th century — [[Shridhara]] gives the rule for finding the volume of a sphere and also the formula for solving quadratic equations
* 820 — [[Al-Mahani]] conceived the idea of reducing [[Geometry|geometrical]] problems such as [[doubling the cube]] to problems in algebra.
* ca. 900 — [[Abu Kamil]] of Egypt had begun to understand what we would write in symbols as &lt;math&gt;x^n \cdot x^m = x^{m+n}&lt;/math&gt;
* 975 — [[Al-Batani]] — Extended the Indian concepts of sine and cosine to other trigonometrical ratios, like tangent, secant and their inverse functions. Derived the formula: &lt;math&gt; \sin \alpha = \tan \alpha / \sqrt{1+\tan^2 \alpha} &lt;/math&gt; and &lt;math&gt; \cos \alpha = 1 / \sqrt{1 + \tan^2 \alpha}&lt;/math&gt;.

==1000–1500==
*ca. 1000 — [[Law of sines]] is discovered by [[Islamic mathematics|Muslim mathematicians]], but it is uncertain who discovers it first between [[Abu-Mahmud al-Khujandi]], [[Abu Nasr Mansur]], and [[Abū al-Wafā' al-Būzjānī|Abu al-Wafa]].
* ca. 1100 — [[Omar Khayyám]] “gave a complete classification of [[cubic equation]]s with geometric solutions found by means of intersecting [[conic section]]s.” He became the first to find general [[geometry|geometric]] solutions of [[cubic equation]]s and laid the foundations for the development of [[analytic geometry]] and [[non-Euclidean geometry]]. He also extracted [[root of a function|roots]] using the [[decimal]] system ([[Hindu-Arabic numeral system]]).
* 1135 — [[Sharafeddin Tusi]] followed al-Khayyam's application of algebra to geometry, and wrote a treatise on [[cubic equation]]s which “represents an essential contribution to another [[algebra]] which aimed to study [[curve]]s by means of [[equation]]s, thus inaugurating the beginning of [[algebraic geometry]].”&lt;ref name=MacTutor&gt;[http://www-groups.dcs.st-and.ac.uk/~history/HistTopics/Arabic_mathematics.html Arabic mathematics], ''[[MacTutor History of Mathematics archive]]'', [[University of St Andrews]], Scotland&lt;/ref&gt;
* ca. 1250 — [[Nasir Al-Din Al-Tusi]] attempts to develop a form of [[non-Euclidean geometry]].
* 15th century — [[Nilakantha Somayaji]], a [[Kerala school of astronomy and mathematics|Kerala school]] mathematician, writes the “Aryabhatiya Bhasya”, which contains work on infinite-series expansions, problems of algebra, and spherical geometry

==17th century==
* 17th century – Putumana Somayaji writes the "Paddhati", which presents a detailed discussion of various trigonometric series
* 1619 –  [[Johannes Kepler]] discovers two of the [[Kepler-Poinsot polyhedra]].

==18th century==
* 1722 –  [[Abraham de Moivre]] states [[de Moivre's formula]] connecting [[trigonometric function]]s and [[complex number]]s,
* 1733 –  [[Giovanni Gerolamo Saccheri]] studies what geometry would be like if [[parallel postulate|Euclid's fifth postulate]] were false,
* 1796 –  [[Carl Friedrich Gauss]] proves that the [[heptadecagon|regular 17-gon]] can be constructed using only a [[compass and straightedge]]
* 1797 –  [[Caspar Wessel]] associates vectors with [[complex number]]s and studies complex number operations in geometrical terms,
* 1799 –  [[Gaspard Monge]] publishes Géométrie descriptive, in which he introduces [[descriptive geometry]].

==19th century==
* 1806 –  [[Louis Poinsot]] discovers the two remaining [[Kepler-Poinsot polyhedra]].
* 1829 –  [[Bolyai]], [[Carl Friedrich Gauss|Gauss]], and [[Nikolai Ivanovich Lobachevsky|Lobachevsky]] invent hyperbolic [[non-Euclidean geometry]],
* 1837 –  [[Pierre Wantzel]] proves that doubling the cube and [[trisecting the angle]] are impossible with only a compass and straightedge, as well as the full completion of the problem of [[Constructible polygon|constructibility]] of regular polygons
* 1843 –  [[William Rowan Hamilton|William Hamilton]] discovers the calculus of [[quaternion]]s and deduces that they are non-commutative,
* 1854 –  [[Bernhard Riemann]] introduces [[Riemannian geometry]],
* 1854 –  [[Arthur Cayley]] shows that [[quaternion]]s can be used to represent rotations in four-dimensional [[space]],
* 1858 –  [[August Ferdinand Möbius]] invents the [[Möbius strip]],
* 1870 –  [[Felix Klein]] constructs an analytic geometry for Lobachevski's geometry thereby establishing its self-consistency and the logical independence of Euclid's fifth postulate,
* 1873 –  [[Charles Hermite]] proves that [[e (mathematical constant)|e]] is transcendental,
* 1878 – Charles Hermite solves the general quintic equation by means of elliptic and modular functions
* 1882 –  [[Ferdinand von Lindemann]] proves that π is transcendental and that therefore the circle cannot be squared with a compass and straightedge,
* 1882 –  Felix Klein invents the [[Klein bottle]],
* 1899 –  [[David Hilbert]] presents a set of self-consistent geometric axioms in ''Foundations of Geometry''

==20th century==
* 1901 –  [[Élie Cartan]] develops the [[exterior derivative]],
* 1912 –  [[Luitzen Egbertus Jan Brouwer]] presents the [[Brouwer fixed-point theorem]],
* 1916 – [[Albert Einstein|Einstein's]] theory of [[general relativity]].
* 1930 –  [[Casimir Kuratowski]] shows that the [[three-cottage problem]] has no solution,
* 1931 –  [[Georges de Rham]] develops theorems in [[cohomology]] and [[characteristic class]]es,
* 1933 –  [[Karol Borsuk]] and [[Stanislaw Ulam]] present the [[Borsuk-Ulam Theorem|Borsuk-Ulam antipodal-point theorem]],
* 1955 –  [[H. S. M. Coxeter]] et al. publish the complete list of [[uniform polyhedron]],
* 1975 –  [[Benoit Mandelbrot]], [[fractal]]s theory,
* 1981 – [[Mikhail Gromov (mathematician)|Mikhail Gromov]] develops the theory of [[hyperbolic group]]s, revolutionizing both infinite group theory and global differential geometry,
* 1983 –  the [[classification of finite simple groups]], a collaborative work involving some hundred mathematicians and spanning thirty years, is completed,
* 1991 –  [[Alain Connes]] and [[John Lott (mathematician)|John Lott]] develop [[non-commutative geometry]],
* 1998 –  [[Thomas Callister Hales]] proves the [[Kepler conjecture]],

==21st century==
* 2003 – [[Grigori Perelman]] proves the [[Poincaré conjecture]],
* 2007 – a team of researches throughout North America and Europe used networks of computers to map [[E8 (mathematics)]].&lt;ref&gt;Elizabeth A. Thompson, MIT News Office, ''Math research team maps E8'' http://www.huliq.com/15695/mathematicians-map-e8&lt;/ref&gt;

==References==
{{Reflist}}&lt;!--added above categories/infobox footers by script-assisted edit--&gt;

{{DEFAULTSORT:Timeline Of Algebra And Geometry}}
[[Category:Mathematics timelines|Algebra and geometry]]
[[Category:Algebra| Timeline]]
[[Category:Geometry| ]]</text>
      <sha1>ama376rc31cd3eo25qmgk5f5ushd7zx</sha1>
    </revision>
  </page>
  <page>
    <title>Totative</title>
    <ns>0</ns>
    <id>34140027</id>
    <revision>
      <id>814470733</id>
      <parentid>805047312</parentid>
      <timestamp>2017-12-09T00:42:53Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>[[User:JCW-CleanerBot#Logic|task]], replaced: Ann. Math. (2) → Ann. Math. |series=2 using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1894">In [[number theory]], a '''totative''' of a given positive integer {{mvar|n}} is an integer {{mvar|k}} such that {{math|0 &lt; ''k'' ≤ ''n''}} and {{mvar|k}} is [[coprime]] to&amp;nbsp;{{mvar|n}}.  [[Euler's totient function]] φ(''n'') counts the number of totatives of ''n''.  The totatives under multiplication modulo ''n'' form the [[Multiplicative group of integers modulo n|multiplicative group of integers modulo ''n'']].

==Distribution==
The distribution of totatives has been a subject of study.  [[Paul Erdős]] conjectured that, writing the totatives of ''n'' as

:&lt;math&gt; 0 &lt; a_1 &lt; a_2 \cdots &lt; a_{\phi(n)} &lt; n ,&lt;/math&gt;

the mean square gap satisfies

:&lt;math&gt; \sum_{i=1}^{\phi(n)-1} (a_{i+1}-a_i)^2 &lt; C n^2 / \phi(n) &lt;/math&gt;

for some constant ''C'' and this was proven by [[Bob Vaughan]] and [[Hugh Montgomery (mathematician)|Hugh Montgomery]].&lt;ref&gt;{{cite journal | doi=10.2307/1971274 | zbl=0591.10042 | last1=Montgomery | first1=H.L. | author1-link=Hugh Montgomery (mathematician) | last2=Vaughan | first2=R.C. | author2-link=Bob Vaughan | title=On the distribution of reduced residues | journal=Ann. Math. |series=2 | volume=123 | pages=311–333 | year=1986 }}&lt;/ref&gt;

==See also==
*[[Reduced residue system]]

==References==
{{reflist}}
* {{cite book |last=Guy | first=Richard K. | authorlink=Richard K. Guy | title=Unsolved problems in number theory | publisher=[[Springer-Verlag]] |edition=3rd | year=2004 |isbn=978-0-387-20860-2 | zbl=1058.11001 | at=B40 }}

==Further reading==
*{{Citation | last=Sándor | first=Jozsef | last2=Crstici | first2=Borislav | title=Handbook of number theory II | location=Dordrecht | publisher=Kluwer Academic | year=2004 | isbn=1-4020-2546-7 | zbl=1079.11001 | pages=242–250 }}

==External links==
*{{MathWorld |title=Totative |id=Totative}}
*{{PlanetMath |urlname=Totative |title=totative}}

[[Category:Modular arithmetic]]


{{Numtheory-stub}}</text>
      <sha1>8j50saxv39d6mttxieeb1qyfxxkfr05</sha1>
    </revision>
  </page>
</mediawiki>
