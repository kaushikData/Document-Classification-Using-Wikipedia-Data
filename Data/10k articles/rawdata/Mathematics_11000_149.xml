<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Alexandra Bellow</title>
    <ns>0</ns>
    <id>17311242</id>
    <revision>
      <id>870563993</id>
      <parentid>870441950</parentid>
      <timestamp>2018-11-25T17:27:41Z</timestamp>
      <contributor>
        <username>GünniX</username>
        <id>237572</id>
      </contributor>
      <minor/>
      <comment>tags fixed</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22509">{{Infobox scientist
| name        = Alexandra Bellow
| image       = Ionescu tulcea.jpg &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size  = 
| alt         = 
| caption     = 
| birth_date  = {{birth date and age |1935|8|30|df=y}}
| birth_place = [[Bucharest]], [[Romania]]
| death_date  =         &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place = 
| nationality = [[Romanian American]]
| fields      = [[Mathematics]]
| workplaces  = [[University of Pennsylvania]]&lt;br /&gt;[[University of Illinois at Urbana–Champaign]]&lt;br /&gt;[[Northwestern University]]
| alma_mater  = [[University of Bucharest]]&lt;br /&gt; [[Yale University]]
| doctoral_advisor = [[Shizuo Kakutani]] &lt;!--(or  | doctoral_advisors = )--&gt;
| doctoral_students = 
| known_for   = 
| awards      = 
| spouses     = {{Marriage|[[Cassius Ionescu-Tulcea]]|1956|1969|reason=divorced}}&lt;br&gt;{{Marriage|[[Saul Bellow]]|1974|1985|reason=divorced}}&lt;br&gt;{{Marriage|[[Alberto Calderón]]|1989|1998|reason=died}}
}}

'''Alexandra Bellow''' (formerly '''Alexandra Ionescu Tulcea'''; born 30 August 1935) is a mathematician from [[Bucharest]], [[Romania]], who has made contributions to the fields of [[ergodic theory]], [[probability]] and [[analysis]].

==Biography==

Bellow was born in [[Bucharest]], [[Romania]], on August 30, 1935, as Alexandra Bagdasar. Her parents were both physicians. Her mother, [[:ro:Florica Bagdasar|Florica Bagdasar]], was a child [[psychiatrist]]. Her father, [[:ro:Dumitru Bagdasar|Dumitru Bagdasar]], was a [[neurosurgeon]] (in fact, he founded the Romanian school of neurosurgery, after having obtained his training in [[Boston]], at the clinic of the world pioneer of [[neurosurgery]], Dr. [[Harvey Cushing]]).&lt;ref&gt;[http://www.revista22.ro/asclepios-versus-hades-in-romania-i-1098.html Asclepios versus Hades in Romania]; this article appeared in Romanian, in two separate installments of [http://www.revista22.ro Revista22] :Nr. 755  [24–30 August 2004] and Nr.756 [31 August–6 September 2004].&lt;/ref&gt; She received her M.S. in mathematics from the [[University of Bucharest]] in 1957, where she met and married her first husband, [[Cassius Ionescu-Tulcea]]. She accompanied her husband to the United States in 1957 and received her Ph.D from [[Yale University]] in 1959 under the direction of [[Shizuo Kakutani]]. After receiving her degree, she worked as a research associate at Yale from 1959 until 1961, and as an Assistant professor at the [[University of Pennsylvania]] from 1962 to 1964. From 1964 until 1967 she was an Associate professor at the [[University of Illinois at Urbana–Champaign]]. In 1967 she moved to [[Northwestern University]] as a professor of mathematics. She was at Northwestern until her retirement in 1996, when she became Professor Emeritus.

During her marriage to Cassius Ionescu-Tulcea (1956–1969) she and her husband wrote a number of papers together, as well as the research monograph [25] on [[lifting theory]].

Alexandra's second husband was the writer [[Saul Bellow]] who was awarded the [[Nobel Prize]] (1976), during this marriage (1975–1985). Alexandra features in Bellow's writings; she is portrayed lovingly in his memoir ''[http://www.goodreads.com/book/show/52785.To_Jerusalem_and_Back To Jerusalem and Back]'' (1976), and, his novel ''[[The Dean's December]]'' (1982), more critically, satirically in his last novel ''[[Ravelstein]]'' (2000) - which was written many years after their divorce.&lt;ref&gt;[http://partners.nytimes.com/library/books/012700bellow-interview.html A Bellow Novel Eulogizes a Friendship] DINITIA SMITH, ''[[The New York Times]]'', January 27, 2000&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.evz.ro/romania-prin-ochii-unui-scriitor-cu-nobel-796734.html|title=România, prin ochii unui scriitor cu Nobel|publisher=[[Evenimentul zilei]]|date=24 March 2008|language=Romanian|accessdate=7 October 2014}}&lt;/ref&gt; The decade of the nineties was for Alexandra a period of personal and professional fulfillment, brought about by her marriage in 1989 to the mathematician, [[Alberto Calderón|Alberto P. Calderón]]. For more details about her personal and professional life see her autobiographical article.&lt;ref&gt;[http://rinconmatematico.com/biografias/alexandrabellow/alexandrabellow.pdf "Una vida matemática"  ("A mathematical life"]), this article appeared in Spanish in La Gaceta de la Real Sociedad Matematica Española, vol.5, No.1, Enero-Abril 2002, pp. 62–71.&lt;/ref&gt; See also her recent interview.&lt;ref&gt;{{cite journal|url=http://adevarul.ro/cultura/istorie/interviu-alexandra-bellow-matematician-fiica-sotilor-dimitrie-florica-bagdasar-pe-parintii-nu-i-a-interesat-niciodata-mute-vila-sosea-1_544912230d133766a82d3b80/index.html|title=interview with Alexandra Bellow}} (in Romanian). Adevarul. 25 October 2014&lt;/ref&gt;

==Mathematical work==

Some of her early work involved properties and consequences of [[Lifting theory|lifting]]. Lifting theory, which had started with the pioneering papers of [[John von Neumann]] and later [[Dorothy Maharam]], came into its own in the 1960s and 70's with the work of the Ionescu Tulceas and provided the definitive treatment for the [[representation theory]] of [[linear operators]] arising in probability, the process of disintegration of measures. The Ergebnisse monograph&lt;ref&gt;{{cite journal|last1=Ionescu Tulcea|first1=Alexandra|last2=Ionescu Tulcea|first2=C.|year=1969|url=http://www.worldcat.org/title/topics-in-the-theory-of-lifting/oclc/851370324|title=TOPICS IN THE THEORY OF LIFTINGS|journal=Ergebnisse der Mathematik |volume=48}}&lt;/ref&gt; became a standard reference in this area.

By applying a lifting to a [[stochastic process]], A. Ionescu Tulcea and C. Ionescu Tulcea obtained a ‘separable’ process; this gives a rapid proof of [[Joseph Leo Doob|Doob]]'s theorem concerning the existence of a separable modification of a stochastic process (also a ‘canonical’ way of obtaining the separable modification).&lt;ref&gt;{{cite journal|last1=Ionescu Tulcea|first1=Alexandra|last2=Ionescu Tulcea|first2=C.|year=1969|url=https://link.springer.com/article/10.1007/BF00537015#page-1|title=Liftings for abstract-valued functions and separable stochastic processes|journal=Zeitschrift für Wahr.|volume=13|issue=2|doi=10.1007/BF00537015|pages=114–118}}&lt;/ref&gt;

By applying a lifting to a ‘weakly’ measurable function with values in a weakly compact set of a [[Banach space]], one obtains a strongly measurable function; this gives a one line proof of Phillips's classical theorem (also a ‘canonical’ way of obtaining the strongly measurable version).&lt;ref&gt;{{cite journal|last=Ionescu Tulcea|first=Alexandra|year=1973|url=https://link.springer.com/article/10.1007/BF00532722|title=On pointwise convergence, compactness and equicontinuity in the lifting topology I|journal=Zeitschrift für Wahr.|volume=26|issue=3|pages=197–205|doi=10.1007/bf00532722}}&lt;/ref&gt;&lt;ref name="AB2"&gt;{{cite journal|last=Ionescu Tulcea|first=Alexandra|date=March 1974|url=http://projecteuclid.org/download/pdf_1/euclid.bams/1183535388|title=On measurability, pointwise convergence and compactness|journal=Bull. Amer. Math. Soc.|volume=80|issue=2|pages=231–236|doi=10.1090/s0002-9904-1974-13435-x}}&lt;/ref&gt;

We say that a set H of measurable functions satisfies the "separation property" if any two distinct functions in H belong to distinct equivalence classes. The range of a lifting is always a set of measurable functions with the "separation property". The following ‘metrization criterion’ gives some idea why the functions in the range of a lifting are so much better behaved:

Let H be a set of measurable functions with the following properties : (I) H is compact (for the topology of pointwise convergence); (II) H is convex; (III) H satisfies the "separation property". Then H is metrizable.&lt;ref name="AB2" /&gt;&lt;ref&gt;{{cite journal|last=Ionescu Tulcea|first=Alexandra|date=February 1974|url=http://ac.els-cdn.com/S0001870874800022/1-s2.0-S0001870874800022-main.pdf?_tid=34152114-5f0e-11e5-b45a-00000aab0f02&amp;acdnat=1442695211_837b28f90688186eaea53ad7ac82800f|title=On pointwise convergence, compactness and equicontinuity II|journal=Advances in Mathematics|volume=12|issue=2|pages=171–177|doi=10.1016/s0001-8708(74)80002-2}}&lt;/ref&gt;

The proof of the existence of a lifting commuting with the left translations of an arbitrary locally compact group, by A. Ionescu Tulcea and C. Ionescu Tulcea, is highly non-trivial. It makes use of approximation by Lie groups, and martingale-type arguments tailored to the group structure.&lt;ref&gt;{{cite journal|last1=Ionescu Tulcea|first1=Alexandra|last2=Ionescu Tulcea|first2=C.|year=1967|url=http://projecteuclid.org/download/pdf_1/euclid.bsmsp/1200513265|title=On the existence of a lifting commuting with the left translations of an arbitrary locally compact group|issue=Proceedings Fifth Berkeley Symposium on Math. Stat. and Probability, II, University of California Press|pages=63–97}}&lt;/ref&gt;

In the early 1960s she worked with C Ionescu Tulcea on [[Martingale (probability theory)|martingales taking values in a Banach space.]]&lt;ref&gt;{{cite journal|last1=Ionescu Tulcea|first1=Alexandra|last2=Ionescu Tulcea|first2=C.|year=1963|url=http://www.ams.org/journals/tran/1963-107-01/S0002-9947-1963-0150611-8/S0002-9947-1963-0150611-8.pdf|title=Abstract ergodic theorems|journal=Transactions of the American Mathematical Society|volume=107|pages=107–124|doi=10.1090/s0002-9947-1963-0150611-8}}&lt;/ref&gt; In a certain sense paper this work launched the study of vector-valued martingales, with the first proof of the ‘strong’ almost everywhere convergence for martingales taking values in a Banach space with (what later became known as) the [[Radon–Nikodym property]]; this, by the way, opened the doors to a new area of analysis, the "geometry of Banach spaces". These ideas were later extended by Bellow to the theory of ‘uniform amarts’,&lt;ref&gt;{{cite journal|last=Bellow|first=Alexandra|year=1978|url=https://link.springer.com/article/10.1007%2FBF00534238#page-1|title=Uniform amarts: A class of asymptotic martingales for which strong almost sure convergence obtains|journal=Zeitschrift für Wahr.|volume=41|issue=3|pages=177–191|doi=10.1007/bf00534238}}&lt;/ref&gt;(in the context of Banach spaces, uniform amarts are the natural generalization of martingales, quasi-martingales and possess remarkable stability properties, such as optional sampling), now an important chapter in probability theory.

In 1960 [[Donald Samuel Ornstein|D. S. Ornstein]] constructed an example of a non-singular transformation on the [[Standard probability space|Lebesgue space]] of the unit interval, which does not admit a σ&amp;nbsp;– finite invariant measure equivalent to Lebesgue measure, thus solving a long-standing problem in ergodic theory. A few years later, R. V. Chacón gave an example of a positive (linear) isometry of ''L''&lt;sub&gt;1&lt;/sub&gt; for which the individual ergodic theorem fails in ''L''&lt;sub&gt;1&lt;/sub&gt;. Her work&lt;ref&gt;{{cite journal|last=Ionescu Tulcea|first=Alexandra|year=1965|jstor=1994001|title=On the category of certain classes of transformations in ergodic theory|journal=Transactions of the American Mathematical Society|volume=114|pages=262–279|doi=10.1090/s0002-9947-1965-0179327-0}}&lt;/ref&gt; unifies and extends these two remarkable results. It shows, by methods of Baire Category, that the seemingly isolated examples of non-singular transformations first discovered by Ornstein and later by Chacón, were in fact the typical case.

Beginning in the early 1980s Bellow began a series of papers that has brought about a revival of that important area of ergodic theory dealing with limit theorems and the delicate question of pointwise a.e. convergence. This was accomplished by exploiting the interplay with probability and harmonic analysis, in the modern context (the [[Central limit theorem]], transference principles, square functions and other singular integral techniques are now part of the daily arsenal of people working in this area of ergodic theory) and by attracting a number of talented mathematicians who have been very active in this area.

One of the [http://www.worldcat.org/title/measure-theory-oberwolfach-1981-proceedings-of-the-conference-held-at-oberwolfach-germany-june-21-27-1981/oclc/8833848 two problems] that she raised at the Oberwolfach meeting on "Measure Theory" in 1981,&lt;ref&gt;{{cite journal|last=Bellow|first=Alexandra| date=June 1982 |url=http://www.worldcat.org/title/measure-theory-oberwolfach-1981-proceedings-of-the-conference-held-at-oberwolfach-germany-june-21-27-1981/oclc/8833848|title=Two problems|journal=Proceedings Conference on Measure Theory, Oberwolfach, June 1981, Springer-Verlag Lecture Notes Math.|volume=945|pages=429–431}}&lt;/ref&gt; was the question of the validity, for ''ƒ'' in ''L''&lt;sub&gt;1&lt;/sub&gt;, of the pointwise ergodic theorem along the ‘sequence of squares’, and along the ‘sequence of primes’ (A similar question was raised independently, a year later, by H. Furstenberg). This problem was solved several years later by J. Bourgain, for ''f'' in ''L''&lt;sub&gt;''p''&lt;/sub&gt;, ''p''&amp;nbsp;&gt;&amp;nbsp;1 in the case of the ‘squares’ and for ''p'' &gt; (1&amp;nbsp;+&amp;nbsp;{{radic|3}})/2  in the case of the ‘primes’ (the argument was pushed through to  ''p''&amp;nbsp;&gt;&amp;nbsp;1 by M. Wierdl; the case of ''L''&lt;sub&gt;1&lt;/sub&gt; however had remained open). Bourgain was awarded the Fields Medal in 1994, in part for this work in ergodic theory.

It was U. Krengel who first gave, in 1971, an ingenious construction of an increasing sequence of positive integers along which the pointwise ergodic theorem fails in  ''L''&lt;sub&gt;1&lt;/sub&gt; for every ergodic transformation. The existence of such a "bad universal sequence" came as a surprise. Bellow showed&lt;ref&gt;{{cite journal|last=Bellow|first=Alexandra| date=June 1982 |url=https://link.springer.com/chapter/10.1007/BFb0099847|title=On "bad universal" sequences in ergodic theory (II)|journal=Measure theory and its Applications, Proceedings of a Conference held at Université de Sherbrooke, [[Quebec]], Canada, June 1982, Springer-Verlag Lecture Notes Math|volume=1033|pages=74–78|doi=10.1007/BFb0099847|series=Lecture Notes in Mathematics|isbn=978-3-540-12703-1}}&lt;/ref&gt; that every lacunary sequence of integers is in fact a "bad universal sequence" in  ''L''&lt;sub&gt;1&lt;/sub&gt;. Thus lacunary sequences are ‘canonical’ examples of "bad universal sequences".

Later she was able to show&lt;ref&gt;{{cite journal|last=Bellow|first=Alexandra|year=1989|url=http://ac.els-cdn.com/0001870889900303/1-s2.0-0001870889900303-main.pdf?_tid=f7c70ea2-5fda-11e5-9a7a-00000aab0f6c&amp;acdnat=1442783157_78c3b03b535e3acfa124a8a9aff43d73|title=Perturbation of a sequence|journal=Advances in Mathematics|volume=78|issue=2|pages=131–139|doi=10.1016/0001-8708(89)90030-3}}&lt;/ref&gt; that from the point of view of the pointwise ergodic theorem, a sequence of positive integers may be "good universal" in ''L''&lt;sub&gt;''p''&lt;/sub&gt;, but "bad universal" in ''L''&lt;sub&gt;''q''&lt;/sub&gt;, for all 1&amp;nbsp;≤&amp;nbsp;''q''&amp;nbsp;&lt;&amp;nbsp;''p''. This was rather startling and answered a question raised by R. Jones.

A place in this area of research is occupied by the "strong sweeping out property" (that a sequence of linear operators may exhibit). This describes the situation when almost everywhere convergence breaks down even in ''L''&lt;sub&gt;∞&lt;/sub&gt; and in the worst possible way. Instances of this appear in several of her papers, see for example ([http://www.sciencedirect.com/science/article/pii/B9780120855209500071 59], [https://link.springer.com/article/10.1007%2FBF01444724#page-1 61], [https://www.researchgate.net/publication/225266910_Almost_everywhere_convergence_of_weighted_averages 63], [http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=2145876 65], [http://www.sciencedirect.com/science/article/pii/S0001870896900353 66]) in her vita. Paper [http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=2145876 65]  was an extensive and systematic study of the "strong sweeping out" property (s.s.o.), giving various criteria and numerous examples of (s.s.o.). This project involved many authors and a long period of time to complete.

Working with U. Krengel, she was able&lt;ref&gt;{{cite journal|last1=Bellow|first1=Alexandra|first2=U.|last2=Krengel|year=1991|url=https://books.google.com/?id=YbjiBQAAQBAJ&amp;pg=PA41&amp;lpg=PA41&amp;dq=On+Hopf+ergodic+theorem+for+particles+with+different+velocities#v=onepage&amp;q=On%20Hopf%20ergodic%20theorem%20for%20particles%20with%20different%20velocities&amp;f=false|title=On Hopf's ergodic theorem for particles with different velocities|journal=Almost everywhere convergence II, Proceedings Internat. Conference on Almost Everywhere Convergence in Probability and Ergodic Theory, Evanston, October 1989, Academic Press, Inc.|pages=41–47|isbn=9781483265926}}&lt;/ref&gt; to give a negative answer to a long-standing conjecture of E. Hopf. Later, Bellow and Krengel&lt;ref&gt;{{cite journal|last1=Bellow|first1=Alexandra|first2=A. P.|last2=Calderón|first3=U.|last3=Krengel|year=1995|url=http://cms.math.ca/openaccess/cmb/v38/cmb1995v38.0011-0015.pdf|title=Hopf's ergodic theorem for particles with different velocities and the "strong sweeping out property"|journal=Canadian Math. Bulletin|volume=38|issue=1|pages=11–15|doi=10.4153/cmb-1995-002-0}}&lt;/ref&gt; working with A. P. Calderón were able to show that in fact the Hopf operators have the "strong sweeping out" property.

In the study of aperiodic flows, sampling at nearly periodic times, as for example, ''t''&lt;sub&gt;''n''&lt;/sub&gt; = ''n''&amp;nbsp;+&amp;nbsp;''ε''(''n''), where ''ε'' is positive and tends to zero, does not lead to a.e. convergence; in fact strong sweeping out occurs.&lt;ref&gt;{{cite journal|last1=Bellow|first1=Alexandra|first2=M.|last2=Akcoglu|first3=A.|last3=del Junco|first4=R.|last4=Jones|year=1993|url=http://www.ams.org/journals/proc/1993-118-02/S0002-9939-1993-1143221-1/S0002-9939-1993-1143221-1.pdf|title=Divergence of averages obtained by sampling a flow|journal=Proc. Amer. Math. Soc.|volume=118|issue=2|pages=499–505|doi=10.1090/S0002-9939-1993-1143221-1}}&lt;/ref&gt; This shows the possibility of serious errors when using the ergodic theorem for the study of physical systems. Such results can be of practical value for statisticians and other scientists.

In the study of discrete ergodic systems, which can be observed only over certain blocks of time [a,b], one has the following dichotomy of behavior of the corresponding averages: either the averages converge a.e. for all functions in ''L''&lt;sub&gt;1&lt;/sub&gt;, or the strong sweeping out property holds. This depends on the geometric properties of the blocks, see.&lt;ref&gt;{{cite journal|last1=Bellow|first1=Alexandra|first2=R.|last2=Jones|first3=J.|last3=Rosenblatt|year=1990|url=http://journals.cambridge.org/action/displayFulltext?type=1&amp;fid=2236148&amp;jid=ETS&amp;volumeId=10&amp;issueId=01&amp;aid=2142288&amp;bodyId=&amp;membershipNumber=&amp;societyETOCSession=|title=Convergence for moving averages|journal=Ergodic Th. &amp; Dynam. Syst.|volume=10|pages=43–62|doi=10.1017/s0143385700005381}}&lt;/ref&gt;

The following are some examples of the work of A. Bellow with other mathematicians.

Mathematicians, who in their papers, answered questions raised by A. Bellow:

* {{cite journal|first=J.|last=Bourgain|year=1988|url=https://link.springer.com/article/10.1007%2FBF02776301#page-1|title=On the maximal ergodic theorem for certain subsets of the integers|journal=Israel Journal Math.|volume=61|issue=1|pages=39–72|doi=10.1007/bf02776301}}
* {{cite journal|first1=M. A.|last1=Akcoglu|first2=A.|last2=del Junco|first3= W. M. F.|last3=Lee|editors=A. Bellow and R. Jones|year=1991|url=http://www.sciencedirect.com/science/book/9780120855209|title=A solution to a problem of A. Bellow|journal=Almost everywhere convergence II|publisher=Academic Press|pages=1–7}}
* {{ cite journal|first1=Vitaly|last1=Bergelson|first2=J.|last2=Bourgain|first3=M.|last3=Boshernitzan|year=1994|url=https://zbmath.org/?q=an:0803.28011|title=Some results on non-linear recurrence|journal=Journal d'Analyse Math.|volume=62|issue=72|pages=29–46}}

The "strong sweeping out property", a notion formalized by A. Bellow, plays a role in this area of research.&lt;ref&gt;{{cite journal|last1=Bellow|first1=Alexandra|first2=M.|last2=Akcoglu|first3=R.|last3=Jones|first4=V.|last4=Losert|first5=K.|last5=Reinhold-Larsson|first6=M.|last6=Wierdl|year=1996|url=http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=2145876|title=The strong sweeping out property for lacunary sequences, Riemann sums, convolution powers and related matters|journal=Ergodic Th. &amp; Dynam. Syst.|volume=16|pages=207–253}}&lt;/ref&gt;

==Academic honors, awards, recognition==

*1977–80 Member, Visiting Committee, [http://www.math.harvard.edu/ Harvard Mathematics Department]
*1980 Fairchild Distinguished Scholar Award, [[Caltech]], Winter Term
*1987       [[Humboldt Prize]], [[Alexander von Humboldt Foundation]], [[Bonn]], [[Germany]]
*1991       [[Noether Lecture|Emmy Noether Lecture]], [[San Francisco]], Ca., U.S.A
*1997 International Conference in Honor of Alexandra Bellow, on the occasion of her retirement, held at [[Northwestern University]], October 23–26, 1997. A Proceedings of this Conference appeared as a special issue of the ''[http://ijm.math.illinois.edu/ Illinois Journal of Mathematics]'', Fall 1999, Vol. 43, No. 3.
*2017 class of [[Fellow]]s of the [[American Mathematical Society]] "for contributions to analysis, particularly ergodic theory and measure theory, and for exposition".&lt;ref&gt;[http://www.ams.org/profession/ams-fellows/new-fellows 2017 Class of the Fellows of the AMS], [[American Mathematical Society]], retrieved 2016-11-06.&lt;/ref&gt;

==Professional editorial activities==

*1974–77 Editor, ''[http://www.ams.org/publications/journals/journalsframework/tran Transactions of the American Mathematical Society]''
*1980–82 Associate Editor, ''[https://web.archive.org/web/20120203192914/http://imstat.org/aop/ Annals of Probability]''
*1979–   Associate Editor, ''[http://www.journals.elsevier.com/advances-in-mathematics/ Advances in Mathematics]''

==See also==
*[[Saul Bellow]]

==References==
{{Reflist|30em}}

{{Authority control}}

{{DEFAULTSORT:Bellow, Alexandra}}
[[Category:Romanian mathematicians]]
[[Category:Women mathematicians]]
[[Category:1935 births]]
[[Category:Living people]]
[[Category:University of Bucharest alumni]]
[[Category:People from Bucharest]]
[[Category:Fellows of the American Mathematical Society]]</text>
      <sha1>2xwd071iirinxajgu4yyumxphjk9pug</sha1>
    </revision>
  </page>
  <page>
    <title>Andreas Speiser</title>
    <ns>0</ns>
    <id>25371502</id>
    <revision>
      <id>866061170</id>
      <parentid>837077155</parentid>
      <timestamp>2018-10-28T00:35:59Z</timestamp>
      <contributor>
        <username>Filedelinkerbot</username>
        <id>20611691</id>
      </contributor>
      <comment>Bot: Removing [[Commons:File:Andreas Speiser.jpeg]] ([[:File:Andreas Speiser.jpeg|en]]). It was deleted on Commons by [[:Commons:User:JGHowes|JGHowes]] (per [[Commons:Commons:Deletion requests/File:Andreas Speiser.jpeg]]).</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5791">'''Andreas Speiser''' (June 10, 1885 – October 12, 1970) was a [[Swiss]] [[Mathematician]] and [[Philosopher of science]].

==Life and work==
Speiser studied since 1904 in [[Göttingen]] notably with [[David Hilbert]], [[Felix Klein]], [[Hermann Minkowski]]. In 1917 he became full-time professor at the [[University of Zurich]] but later relocated in Basel. During 1924/25 he was president of the Swiss Mathematical Association.

Speiser worked on number theory, group theory, and the theory of Riemann surfaces. He organized the translation of [[Leonard Dickson]]'s seminal 1923 book ''Algebras and Their Arithmetics'' (''Algebren und ihre Zahlentheorie'', 1927), which was heavily influenced by the work on the theory of algebras done by the schools of [[Emmy Noether]] and [[Helmut Hasse]]. Speiser also added an appendix on ideal theory to Dickson's book. Speiser's book ''Theorie der Gruppen endlicher Ordnung'' is a classic, richly illustrated work on group theory. In this book, there are group theoretical applications in Galois theory, elementary number theory, and Platonic solids, as well as extensive studies of ornaments, such as those that Speiser studied on a 1928 trip to Egypt.

Speiser also worked on the history of mathematics and was the chief editor for the [[Euler Commission]]'s edition of [[Leonhard Euler]]'s ''Opera Omnia''&lt;ref&gt;Without the efforts of Speiser and the Swiss mathematician Karl Rudolf Fueter the edition started by [[Ferdinand Rudio]] (director of ETH-Bibliothek Zürich) might not have continued past WW I.&lt;/ref&gt; and the editor of the works of [[Johann Heinrich Lambert]]. As a philosopher Speiser was chiefly concerned with [[Plato]] and wrote a commentary on the [[Parmenides (dialogue)|Parmenides Dialogue]], but he was also an expert of the philosophies of [[Plotinus]] and [[Georg Wilhelm Friedrich Hegel|Hegel]].

==Writings==
*''Die Theorie der Gruppen von endlicher Ordnung – mit Anwendungen auf algebraische Zahlen und Gleichungen sowie auf die Kristallographie.'' Springer 1923, Birkhäuser 1956.&lt;ref&gt;{{cite journal|author=Miller, G. A.|authorlink=George Abram Miller|title=Review: Andreas Speiser, ''Die Theorie der Gruppen von endlicher Ordnung, mit Anwendungen auf algebraische Zahlen und Gleichungen sowie auf die Kristallographie''|journal=Bull. Amer. Math. Soc.|year=1923|volume=29|issue=8|page=372|url=http://projecteuclid.org/euclid.bams/1183485663|doi=10.1090/s0002-9904-1923-03763-4}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=Hall, Marshall|authorlink=Marshall Hall (mathematician)|title=Review: Andreas Speiser, ''Theorie der Gruppen von Endlicher Ordnung''. 3d ed. Berlin, Springer, 1937.|journal=Bull. Amer. Math. Soc.|year=1938|volume=44|pages=313–314|url=http://projecteuclid.org/euclid.bams/1183500454|doi=10.1090/s0002-9904-1938-06722-5}}&lt;/ref&gt;
*''Klassische Stücke der Mathematik.'' Orell Füssli 1925 (mit Abdruck von Quellen, u.a. auch Dante, Rousseau).
*''Leonhard Euler und die Deutsche Philosophie.'' Orell Füssli 1934.
*''Leonhard Euler.'' In: ''Große Schweizer.'' Atlantis Verlag, Zürich 1939, 1940, S.1-6.
*''Die mathematische Denkweise.'' Rascher 1932,&lt;ref&gt;{{cite journal|author=Allen, Edward Switzer|title=Review: ''Die mathematische Denkweise'', by Andreas Speiser|journal=Bull. Amer. Math. Soc.|year=1933|volume=39|issue=7|pages=484–485|url=http://www.ams.org/journals/bull/1933-39-07/S0002-9904-1933-05643-4|doi=10.1090/s0002-9904-1933-05643-4}}&lt;/ref&gt; Birkhäuser 1945, 1952.
*''Leonhard Euler. Vortrag gehalten an der Generalversammlung des S.I.A. in Basel am 11. September 1949''. Schweizerische Bauzeitung, Jg.67, Nr.48. 26. November 1949, Zürich.
*''Elemente der Philosophie und Mathematik.'' Birkhäuser 1952.
*''Die Geistige Arbeit.'' Birkhäuser 1955 (Vorträge).
*''Ein Parmenideskommentar – Studien zur Platonischen Dialektik.'' Koehler, Leipzig, Stuttgart, 1937, 1959.
*[https://gdz.sub.uni-goettingen.de/id/PPN358147735_0002 ''Ueber Riemannsche Flächen.''] Comm.Math.Helvetici (CMH), Bd.2, 1930, S.284-293.
*[https://gdz.sub.uni-goettingen.de/id/PPN235181684_0075 ''Zur Theorie der Substitutionsgruppen.''] Mathematische Annalen, Bd. 75, 1914, S.443-448.
*[https://gdz.sub.uni-goettingen.de/id/PPN266833020_0005 ''Zahlentheoretische Sätze aus der Gruppentheorie.''] Math.Zeitschrift Bd.5, 1919, S. 1-6.
*[https://gdz.sub.uni-goettingen.de/id/PPN243919689_0157 ''Naturphilosophische Untersuchungen von Euler und Riemann.''] Crelle Journal Bd. 157, 1927, S.105-114.
*[https://gdz.sub.uni-goettingen.de/id/PPN358147735_0008 ''Zahlentheorie in rationalen Algebren.''] CMH, Bd.8, 1936, S.391-406.
*[https://gdz.sub.uni-goettingen.de/id/PPN358147735_0010 ''Riemann'sche Flächen vom hyperbolischen Typus.''] CMH Bd.10, 1937, S.232-242.
*[https://gdz.sub.uni-goettingen.de/id/PPN235181684_0110 ''Geometrisches zur Riemannschen Zetafunktion.''] Mathematische Annalen Bd.110, 1934, S.514-521.
*[https://gdz.sub.uni-goettingen.de/id/PPN358147735_0020 ''Einteilung der sämtlichen Werke Leonhard Eulers.''] CMH Bd.20, 1947, S. 288-318.

==See also==
*[[Hilbert–Speiser theorem]]
*[[Jordan–Schur theorem]]

==References==
{{reflist}}
*[[Martin Eichler]], Nachruf in den Verhandlungen der Schweizer Naturforschenden Gesellschaft, Bd.150, 1970, S.325
*J. J. Burckhardt, Nachruf in Vierteljahresschrift der Naturforschenden Gesellschaft Bd.115, 1970, 471
*J. J. Burckhardt: ''Die Mathematik an der Universität Zurich 1916-1950 unter den Professoren R. Fueter, A. Speiser und P. Finsler'', Basel, 1980

==External links==
* {{commons category inline|Andreas Speiser (mathematician)}}

{{Authority control}}

{{DEFAULTSORT:Speiser, Andreas}}
[[Category:Swiss mathematicians]]
[[Category:1885 births]]
[[Category:1970 deaths]]
[[Category:Philosophers of science]]
[[Category:Historians of mathematics]]</text>
      <sha1>g1lj5b86vazsmrzqzsnyi49s27bq71i</sha1>
    </revision>
  </page>
  <page>
    <title>Artin conductor</title>
    <ns>0</ns>
    <id>34170016</id>
    <revision>
      <id>862708112</id>
      <parentid>852434686</parentid>
      <timestamp>2018-10-06T05:10:04Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7213">In [[mathematics]], the '''Artin conductor''' is a number or [[ideal (ring theory)|ideal]] associated to a character of a [[Galois group]] of a [[local field|local]] or [[global field|global]] [[field (mathematics)|field]], introduced by {{harvs|txt|last=Artin|first=Emil|authorlink=Emil Artin|year1=1930|year2=1931}} as an expression appearing in the [[functional equation]] of an [[Artin L-function]].

==Local Artin conductors==

Suppose that ''L'' is a finite [[Galois extension]] of the local field ''K'', with Galois group ''G''. If χ is a character of ''G'', then the Artin conductor of χ is the number
:&lt;math&gt;f(\chi)=\sum_{i\ge 0}\frac{g_i}{g_0}(\chi(1)-\chi(G_i))&lt;/math&gt;
where ''G''&lt;sub&gt;''i''&lt;/sub&gt; is the ''i''-th [[ramification group]] (in [[lower numbering]]), of order ''g''&lt;sub&gt;''i''&lt;/sub&gt;, and χ(''G''&lt;sub&gt;''i''&lt;/sub&gt;) is the average value of χ on ''G''&lt;sub&gt;''i''&lt;/sub&gt;.&lt;ref name=S67158&gt;Serre (1967) p.158&lt;/ref&gt;  By a result of Artin, the local conductor is an integer.&lt;ref name=S67159&gt;Serre (1967) p.159&lt;/ref&gt;&lt;ref name=MP329&gt;{{cite book | first1=Yu. I. | last1=Manin | authorlink1= | first2=A. A. | last2=Panchishkin | title=Introduction to Modern Number Theory | series=Encyclopaedia of Mathematical Sciences | volume=49 | edition=Second | year=2007 | isbn=978-3-540-20364-3 | issn=0938-0396 | page=329 }}&lt;/ref&gt; If χ is unramified, then its Artin conductor is zero. If ''L'' is unramified over ''K'', then the Artin conductors of all χ are zero.

The ''wild invariant''&lt;ref name=MP329/&gt; or ''Swan conductor''&lt;ref name=Sn249&gt;Snaith (1994) p.249&lt;/ref&gt; of the character is

:&lt;math&gt; f(\chi) - (\chi(1)-\chi(G_0)),  &lt;/math&gt;

in other words, the sum of the higher order terms with ''i'' &gt; 0.

==Global Artin conductors==

The '''global Artin conductor''' of a representation χ of the Galois group ''G'' of a finite extension ''L''/''K'' of global fields is an ideal of ''K'', defined to be

:&lt;math&gt;\mathfrak{f}(\chi) = \prod_p p^{f(\chi,p)}&lt;/math&gt;

where the product is over the primes ''p'' of ''K'', and ''f''(χ,''p'') is the local Artin conductor of the restriction of χ to the decomposition group of some prime of ''L'' lying over ''p''.&lt;ref name=S67159/&gt;  Since the local Artin conductor is zero at unramified primes, the above product only need be taken over primes that ramify in ''L''/''K''.

==Artin representation and Artin character==

Suppose that ''L'' is a finite Galois extension of the local field ''K'', with Galois group&amp;nbsp;''G''. The '''Artin character''' ''a''&lt;sub&gt;''G''&lt;/sub&gt; of ''G'' is the character

:&lt;math&gt;a_G=\sum_\chi f(\chi)\chi&lt;/math&gt;

and the '''Artin representation''' ''A''&lt;sub&gt;''G''&lt;/sub&gt; is the complex linear representation of ''G'' with this character.  {{harvtxt|Weil|1946}} asked for a direct construction of the Artin representation. {{harvs|txt|last=Serre|year=1960}} showed that the Artin representation can be realized over the local field '''Q'''&lt;sub&gt;''l''&lt;/sub&gt;, for any prime ''l'' not equal to the residue characteristic ''p''. {{harvtxt|Fontaine|1971}} showed that it can be realized over the corresponding ring of Witt vectors. It cannot in general be realized over the rationals or over the local field '''Q'''&lt;sub&gt;''p''&lt;/sub&gt;, suggesting that there is no easy way to construct the Artin representation explicitly.&lt;ref name=S67160&gt;Serre (1967) p.160&lt;/ref&gt;

==Swan representation==

The Swan character ''sw''&lt;sub&gt;''G''&lt;/sub&gt; is given by

:&lt;math&gt;sw_G= a_G -r_G+1 &lt;/math&gt;

where ''r''&lt;sub&gt;''g''&lt;/sub&gt; is the character of the regular representation and 1 is the character of the trivial representation.&lt;ref name=Sn248&gt;Snaith (1994) p.248&lt;/ref&gt;  The Swan character is the character of a representation of ''G''. {{harvs|txt|authorlink=Richard Swan|last=Swan|year=1963}} showed that there is a unique projective representation of ''G'' over the ''l''-adic integers with character the Swan character.

==Applications==

The Artin conductor appears in the [[conductor-discriminant formula]] for the discriminant of a global field.&lt;ref name=S67160&gt;Serre (1967) p.160&lt;/ref&gt;

The optimal level in the [[Serre modularity conjecture]] is expressed in terms of the Artin conductor.

The Artin conductor appears in the functional equation of the [[Artin L-function]].

The Artin and Swan representations are used to defined the [[conductor of an elliptic curve]] or abelian variety.

==Notes==
{{reflist}}

==References==
*{{Citation | last1=Artin | first1=Emil | author1-link=Emil Artin | title=Zur Theorie der L-Reihen mit allgemeinen Gruppencharakteren. | language=German | doi=10.1007/BF02941010 | jfm=56.0173.02  | year=1930 | journal=Abhandlungen Hamburg | volume=8 | pages=292–306}}
*{{Citation | last1=Artin | first1=Emil | author1-link=Emil Artin | title=Die gruppentheoretische Struktur der Diskriminanten algebraischer Zahlkörper. | url=http://resolver.sub.uni-goettingen.de/purl?GDZPPN002171422 | language=German | doi=10.1515/crll.1931.164.1 | zbl=
0001.00801  | year=1931 | journal=Journal für die Reine und Angewandte Mathematik | issn=0075-4102 | volume=164 | pages=1–11}}
*{{Citation | last1=Fontaine | first1=Jean-Marc | title=Colloque de Théorie des Nombres (Univ. Bordeaux, Bordeaux, 1969) | url=http://www.numdam.org/item?id=MSMF_1971__25__71_0 | publisher=[[Société Mathématique de France]] | location=Paris | series=Mémoires de la Société Mathématique de France | mr=0374106  | year=1971 | volume=25 | chapter=Sur les représentations d'Artin | pages=71–81}}
*{{Citation | last1=Serre | first1=Jean-Pierre | author1-link=Jean-Pierre Serre | title=Sur la rationalité des représentations d'Artin | jstor=1970142 | mr=0171775  | year=1960 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=72 | pages=405–420 | doi=10.2307/1970142}}
* {{citation | last=Serre | first=Jean-Pierre | authorlink=Jean-Pierre Serre | chapter=VI. Local class field theory | pages=128–161 | editor1-last=Cassels | editor1-first=J.W.S. | editor1-link=J. W. S. Cassels | editor2-last=Fröhlich | editor2-first=A. | editor2-link=Albrecht Fröhlich | title=Algebraic number theory. Proceedings of an instructional conference organized by the London Mathematical Society (a NATO Advanced Study Institute) with the support of the International Mathematical Union | location=London | publisher=Academic Press | year=1967 | zbl=0153.07403 }} 
* {{citation | title=Explicit Brauer Induction: With Applications to Algebra and Number Theory | volume=40 | series=Cambridge Studies in Advanced Mathematics | first=V. P. | last=Snaith | authorlink= | publisher=[[Cambridge University Press]] | year=1994 | isbn=0-521-46015-8 | zbl=0991.20005 }}
*{{Citation | last1=Swan | first1=Richard G. | title=The Grothendieck ring of a finite group | doi=10.1016/0040-9383(63)90025-9 | mr=0153722  | year=1963 | journal=[[Topology (journal)|Topology. An International Journal of Mathematics]] | issn=0040-9383 | volume=2 | pages=85–110}}
*{{Citation | last1=Weil | first1=André | author1-link=André Weil | title=L'avenir des mathématiques | mr=0020961  | year=1946 | journal=Bol. Soc. Mat. São Paulo | volume=1 | pages=55–68}}

[[Category:Number theory]]
[[Category:Representation theory]]
[[Category:Zeta and L-functions]]</text>
      <sha1>gvlnpthydoc2qp9cmldvamorv8f68uo</sha1>
    </revision>
  </page>
  <page>
    <title>Beta-dual space</title>
    <ns>0</ns>
    <id>1829970</id>
    <revision>
      <id>785929208</id>
      <parentid>785929144</parentid>
      <timestamp>2017-06-16T07:22:28Z</timestamp>
      <contributor>
        <ip>73.170.171.66</ip>
      </contributor>
      <comment>/* Examples */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1045">In [[functional analysis]] and related areas of [[mathematics]], the '''beta-dual''' or '''{{math|''β''}}-dual''' is a certain linear subspace of the [[algebraic dual]] of a [[sequence space]].

== Definition ==
Given a sequence space {{mvar|X}} the '''{{math|''β''}}-dual''' of {{mvar|X}} is defined as

:&lt;math&gt;X^{\beta}:= \left \{ x \in X \ : \ \sum_{i=1}^{\infty} x_i y_i &lt; \infty \quad \forall y \in X \right \}.&lt;/math&gt;

If {{mvar|X}} is an [[FK-space]] then each {{mvar|y}} in {{math|''X&lt;sup&gt;β&lt;/sup&gt;''}} defines a [[continuous linear form]] on {{mvar|X}} 

:&lt;math&gt;f_y(x) := \sum_{i=1}^{\infty} x_i y_i \qquad x \in X.&lt;/math&gt;

== Examples ==
* &lt;math&gt;c_0^\beta = \ell^1&lt;/math&gt;
* &lt;math&gt;(\ell^1)^\beta = \ell^\infty&lt;/math&gt;
* &lt;math&gt;\omega^\beta = \{0\}&lt;/math&gt;

== Properties ==
The beta-dual of an FK-space {{mvar|E}} is a [[linear subspace]] of the [[continuous dual]] of {{mvar|E}}.  If {{mvar|E}} is an [[FK-AK space]] then the beta dual is linear isomorphic to the continuous dual.

{{mathanalysis-stub}}

[[Category:Functional analysis]]</text>
      <sha1>n3reuic59hsjlhchlqd5orpka2muhqw</sha1>
    </revision>
  </page>
  <page>
    <title>Bird–Meertens formalism</title>
    <ns>0</ns>
    <id>4692157</id>
    <revision>
      <id>835535396</id>
      <parentid>823957605</parentid>
      <timestamp>2018-04-09T08:13:19Z</timestamp>
      <contributor>
        <username>Alexey Muranov</username>
        <id>5808130</id>
      </contributor>
      <comment>/* Basic examples and notations */ map doesn't apply "iself", otherwise it would only be applicable to the empty list and lists thereof, etc., at it wouldn't even be typable</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5871">The '''Bird–Meertens formalism''' ('''BMF''') is a [[calculation|calculus]] for [[program derivation|deriving programs]] from [[program specification|specification]]s (in a [[functional programming|functional-programming]] setting) by a process of equational reasoning. It was devised by [[Richard Bird (computer scientist)|Richard Bird]] and [[Lambert Meertens]] as part of their work within [[IFIP Working Group 2.1]].

It is sometimes referred to in publications as BMF, as a nod to [[Backus–Naur form]]. Facetiously it is also referred to as ''Squiggol'', as a nod to [[ALGOL]], which was also in the remit of WG 2.1, and because of the "squiggly" symbols it uses. A less-used variant name, but actually the first one suggested, is ''SQUIGOL''.

== Basic examples and notations ==

[[Map (higher-order function)|Map]] is a well-known second-order function that applies a given function to every element of a list; in BMF, it is written &lt;math&gt;*&lt;/math&gt;:

:&lt;math&gt;f*[e_1,\dots,e_n] =  [f\ e_1,\dots,f\ e_n].&lt;/math&gt;

Likewise, [[Fold (higher-order function)|reduce]] is a function that collapses a list into a single value by [[Iterated binary operation|repeated application of a binary operator]]. It is written / in BMF.
Taking &lt;math&gt;\oplus&lt;/math&gt; as a suitable binary operator with neutral element ''e'', we have

:&lt;math&gt;\oplus / [e_1,\dots,e_n] =  e \oplus e_1 \oplus \dots \oplus e_n.&lt;/math&gt;

Using those two operators and the primitives &lt;math&gt;+&lt;/math&gt; (as the usual addition), and &lt;math&gt;+\!\!\!+&lt;/math&gt; (for list concatenation), we can easily express the sum of all elements of a list, and the [[flatten (higher-order function)|flatten]] function, as &lt;math&gt;{\rm sum} = + /&lt;/math&gt; and &lt;math&gt;{\rm flatten} = +\!\!\!+ /&lt;/math&gt;, in
[[currying|currified notation]]. We have:

:&lt;math&gt;{\rm sum}\ [e_1,\dots,e_n] = + / [e_1,\dots,e_n] =  0 +  e_1 + \dots+ e_n = \sum_k e_k.&lt;/math&gt;
:&lt;math&gt;{\rm flatten}\  [l_1,\dots,l_n] =+\!\!\!+ / [l_1,\dots,l_n] =  [\,] +\!\!\!+\;  l_1 +\!\!\!+ \dots+\!\!\!+\; l_n = \text{ the concatenation of all lists } l_k.&lt;/math&gt;

Similarly, writing &lt;math&gt;\cdot&lt;/math&gt; for [[functional composition]] and &lt;math&gt;\land&lt;/math&gt; for [[Logical conjunction|conjunction]], it is easy to write a function testing that all elements of a list satisfy a predicate ''p'', simply as &lt;math&gt;{\rm all}\ p = (\land /)\cdot(p*)&lt;/math&gt;:

:&lt;math&gt;
\begin{align}
{\rm all}\ p\ [e_1,\dots,e_n] 
&amp;= (\land /)\cdot(p*)\ [e_1,\dots,e_n] 
\\&amp;= \land /(p* [e_1,\dots,e_n])
\\&amp;= \land /[p\ e_1,\dots,p\ e_n]
\\&amp;= p\ e_1\land \dots \land p\ e_n
\\&amp;= \forall k\ . \ p\ e_k.
\end{align}&lt;/math&gt;

==The homomorphism lemma and its applications to parallel implementations ==

A function ''h'' on lists is a list [[homomorphism]] if there exists an associative binary operator &lt;math&gt;\oplus&lt;/math&gt; and neutral element  &lt;math&gt;e&lt;/math&gt; such that the following holds:

:&lt;math&gt;
\begin{align}
&amp;h\ [\,] &amp;&amp;=\ e \\
&amp;h\ (l +\!\!\!+\; m) &amp;&amp;=\ h\ l \oplus h\ m. 
\end{align}
&lt;/math&gt;

The ''homomorphism lemma'' states that ''h'' is a homomorphism if and only if there exists an operator &lt;math&gt;\oplus&lt;/math&gt; and a function ''f'' such that &lt;math&gt;h = (\oplus/)\cdot(f*)&lt;/math&gt;.

A point of great interest for this lemma is its application to the derivation of highly [[parallel computing|parallel]] implementations of computations. Indeed, it is trivial to see that &lt;math&gt;f*&lt;/math&gt; has a highly parallel implementation, and so does &lt;math&gt;\oplus/&lt;/math&gt; — most obviously as a binary tree. Thus for any list homomorphism ''h'', there exists a parallel implementation. That implementation cuts the list into chunks, which are assigned to different computers; each computes the result on its own chunk. It is those results that transit on the network and are finally combined into one. In any application where the list is enormous and the result is a very simple type – say an integer – the benefits of parallelisation are considerable. This is the basis of the [[map-reduce]] approach.

== See also ==

* [[Catamorphism]]
* [[Anamorphism]]
* [[Paramorphism]]
* [[Hylomorphism (computer science)|Hylomorphism]]

== References ==

* {{cite book
| author = [[Lambert Meertens]]
| year = 1986
| chapter=Algorithmics — Towards programming as a mathematical activity.
| chapter-url=http://www.kestrel.edu/home/people/meertens/publications/papers/Algorithmics.pdf
| editor=J.W. de Bakker |editor2=M. Hazewinkel |editor3=J.K. Lenstra
| title= Mathematics and Computer Science, CWI Monographs Volume 1
| pages=289–334
| publisher=North-Holland
}}
* {{cite article
| author = [[Lambert Meertens]]
| author2 = [[Richard Bird (computer scientist)|Richard Bird]]
| year = 1987
| title = Two Exercises Found in a Book on Algorithmics
| publisher = North-Holland
| url=http://ftp.kestrel.edu/home/people/meertens/publications/papers/Two_exercises_found_in_a_book_on_Algorithmics.pdf
}}
* {{cite journal 
| url=http://comjnl.oxfordjournals.org/content/32/2/122.full.pdf 
| author=Richard S. Bird 
| title=Algebraic Identities for Program Calculation 
| journal=The Computer Journal 
| volume=32 
| number=2 
| pages=122&amp;mdash;126 
| month= 
| year=1989
| doi=10.1093/comjnl/32.2.122
}}
* {{cite book
| author = [[Richard Bird (computer scientist)|Richard Bird]]
|author2=Oege de Moor
| year = 1997
| title = Algebra of Programming, International Series in Computing Science, Vol. 100
| publisher = Prentice Hall
| isbn = 0-13-507245-X
}}

*{{Cite conference| pages = 489–492| last = Cole| first = Murray| title = Parallel Programming, List Homomorphisms and the Maximum Segment Sum Problem| booktitle = Parallel Computing: Trends and Applications, PARCO 1993, Grenoble, France| date = 1993 | url = http://homepages.inf.ed.ac.uk/mic/Pubs/segmentsum.ps.gz}}

{{DEFAULTSORT:Bird-Meertens Formalism}}
[[Category:Functional languages]]
[[Category:Theoretical computer science]]
[[Category:Program derivation]]</text>
      <sha1>tgqojk3ycz70d7dj6yro5axnmqmb2zz</sha1>
    </revision>
  </page>
  <page>
    <title>Bounded quantifier</title>
    <ns>0</ns>
    <id>5824808</id>
    <revision>
      <id>813677232</id>
      <parentid>775922650</parentid>
      <timestamp>2017-12-04T17:59:06Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5867">{{about|bounded quantification in mathematical logic|bounded quantification in type theory|Bounded quantification}}
In the study of formal theories in [[mathematical logic]], '''bounded quantifiers''' are often included in a formal language in addition to the standard quantifiers "∀" and "∃". Bounded quantifiers differ from "∀" and "∃" in that bounded quantifiers restrict the range of the quantified variable. The study of bounded quantifiers is motivated by the fact that determining whether a [[Sentence (mathematical logic)|sentence]] with only bounded quantifiers is true is often not as difficult as determining whether an arbitrary sentence is true.

Examples of bounded quantifiers in the context of real analysis include "∀''x''&gt;0", "∃''y''&lt;0", and "∀''x'' ∊ ℝ". Informally "∀''x''&gt;0" says "for all ''x'' where ''x'' is larger than 0", "∃''y''&lt;0" says "there exists a ''y'' where ''y'' is less than 0" and  "∀''x'' ∊ ℝ" says "for all ''x'' where ''x'' is a real number". For example, {{nowrap|1="∀''x''&gt;0 ∃''y''&lt;0 (''x'' = ''y''&lt;sup&gt;2&lt;/sup&gt;)"}} says "every positive number is the square of a negative number".

== Bounded quantifiers in arithmetic ==

Suppose that ''L'' is the language of [[Peano arithmetic]] (the language of [[second-order arithmetic]] or arithmetic in all finite types would work as well).  There are two types of bounded quantifiers: &lt;math&gt;\forall n &lt; t&lt;/math&gt; and &lt;math&gt;\exists n &lt; t&lt;/math&gt;.
These quantifiers bind the number variable ''n'' and contain a numeric term ''t'' which may not mention ''n'' but which may have other free variables. ("Numeric terms" here means terms such as "1 + 1", "2", "2 × 3", "''m'' + 3", etc.)

These quantifiers are defined by the following rules (&lt;math&gt;\phi&lt;/math&gt; denotes formulas):
:&lt;math&gt;\exists n &lt; t\, \phi \Leftrightarrow \exists n ( n &lt; t \land \phi)&lt;/math&gt;
:&lt;math&gt;\forall n &lt; t\, \phi \Leftrightarrow \forall n ( n &lt; t \rightarrow \phi)&lt;/math&gt;

There are several motivations for these quantifiers.
* In applications of the language to [[recursion theory]], such as the [[arithmetical hierarchy]], bounded quantifiers add no complexity.  If &lt;math&gt;\phi&lt;/math&gt; is a decidable predicate then &lt;math&gt;\exists n &lt; t \, \phi&lt;/math&gt; and &lt;math&gt;\forall n &lt; t\,  \phi&lt;/math&gt; are decidable as well.
* In applications to the study of [[Peano arithmetic]], the fact that a particular set can be defined with only bounded quantifiers can have consequences for the computability of the set. For example, there is a definition of primality using only bounded quantifiers: a number ''n'' is prime if and only if there are not two numbers strictly less than ''n'' whose product is ''n''.  There is no quantifier-free definition of primality in the language &lt;math&gt;\langle 0,1,+,\times, &lt;, =\rangle&lt;/math&gt;, however. The fact that there is a bounded quantifier formula defining primality shows that the primality of each number can be computably decided.

In general, a relation on natural numbers is definable by a bounded formula if and only if it is computable in the linear-time hierarchy, which is defined similarly to the [[polynomial hierarchy]], but with linear time bounds instead of polynomial. Consequently, all predicates definable by a bounded formula are [[ELEMENTARY|Kalmár elementary]], [[context-sensitive grammar|context-sensitive]], and [[primitive recursive]].

In the [[arithmetical hierarchy]], an arithmetical formula which contains only bounded quantifiers is called &lt;math&gt;\Sigma^0_0&lt;/math&gt;, &lt;math&gt;\Delta^0_0&lt;/math&gt;, and &lt;math&gt;\Pi^0_0&lt;/math&gt;. The superscript 0 is sometimes omitted.

== Bounded quantifiers in set theory ==
Suppose that ''L'' is the language &lt;math&gt;\langle \in, \ldots, =\rangle&lt;/math&gt; of the [[Zermelo–Fraenkel set theory]], where the ellipsis may be replaced by term-forming operations such as a symbol for the powerset operation.  There are two bounded quantifiers: &lt;math&gt;\forall x \in t&lt;/math&gt; and &lt;math&gt;\exists x \in t&lt;/math&gt;.  These quantifiers bind the set variable ''x'' and contain a term ''t'' which may not mention ''x'' but which may have other free variables.

The semantics of these quantifiers is determined by the following rules:
:&lt;math&gt;\exists x \in t\ (\phi) \Leftrightarrow \exists x ( x \in  t \land \phi)&lt;/math&gt;
:&lt;math&gt;\forall x \in t\ (\phi) \Leftrightarrow \forall x ( x \in t \rightarrow \phi)&lt;/math&gt;

A ZF formula which contains only bounded quantifiers is called &lt;math&gt;\Sigma_0&lt;/math&gt;, &lt;math&gt;\Delta_0&lt;/math&gt;, and &lt;math&gt;\Pi_0&lt;/math&gt;. This forms the basis of the [[Lévy hierarchy]], which is defined analogously with the arithmetical hierarchy.

Bounded quantifiers are important in [[Kripke–Platek set theory]] and [[constructive set theory]], where only [[axiom schema of predicative separation|&amp;Delta;&lt;sub&gt;0&lt;/sub&gt; separation]] is included. That is, it includes separation for formulas with only bounded quantifiers, but not separation for other formulas. In KP the motivation is the fact that whether a set ''x'' satisfies a bounded quantifier formula only depends on the collection of sets that are close in rank to ''x'' (as the powerset operation can only be applied finitely many times to form a term). In constructive set theory, it is motivated on [[impredicativity|predicative]] grounds.

== See also ==
* [[Subtyping]] — bounded quantification in [[type theory]]
* [[System F-sub|System F&lt;sub&gt;&lt;:&lt;/sub&gt;]] — a [[System F|polymorphic]] [[typed lambda calculus]] with bounded quantification

== References ==
* {{cite book | author = Hinman, P. | title = Fundamentals of Mathematical Logic | publisher = A K Peters | year = 2005 | isbn = 1-56881-262-0}}
* {{cite book | author= Kunen, K. | title = Set theory: An introduction to independence proofs | publisher = Elsevier | year = 1980 | isbn = 0-444-86839-9}}

[[Category:Quantification]]
[[Category:Proof theory]]
[[Category:Computability theory]]</text>
      <sha1>kk19vdhfr4t472h4j0p13y3jm5rtu7r</sha1>
    </revision>
  </page>
  <page>
    <title>Brigitte Servatius</title>
    <ns>0</ns>
    <id>56508282</id>
    <revision>
      <id>860417548</id>
      <parentid>825884458</parentid>
      <timestamp>2018-09-20T15:03:31Z</timestamp>
      <contributor>
        <username>Bservat</username>
        <id>34701092</id>
      </contributor>
      <minor/>
      <comment>/* Education and career */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7888">'''Brigitte Irma Servatius''' (b. 1954){{r|bdate}} is a mathematician specializing in [[matroid]]s and [[structural rigidity]]. She is a professor of mathematics at [[Worcester Polytechnic Institute]],{{r|cant}} and has been the editor-in-chief of the ''[[Pi Mu Epsilon Journal]]'' since 1999.{{r|pme}}

==Education and career==
Servatius is originally from [[Graz]] in [[Austria]].{{r|standard}}
As a student at an all-girl gymnasium in Graz that specialized in language studies rather than mathematics, her interest in mathematics was sparked by her participation in a national [[mathematical olympiad]],{{r|cant}}
and she went on to earn master's degrees in mathematics and physics at the [[University of Graz]].{{r|pme}}

She became a high school mathematics and science teacher in [[Leibnitz]]. {{r|standard}} She moved to the US in 1981, to begin doctoral studies at [[Syracuse University]].{{r|cant}} She completed her Ph.D. in 1987,{{r|mgp}} and joined the [[Worcester Polytechnic Institute]] {{r|standard}}  faculty in the same year.{{r|cant}} Her dissertation, ''Planar Rigidity'', was supervised by Jack Graver.{{r|mgp}}

==Contributions==
While still in Austria, Servatius began working on [[combinatorial group theory]], and her first publication (appearing while she was a graduate student) is in that subject.{{r|cant}}{{ran|Z}}
She switched to the theory of [[structural rigidity]] for her doctoral research,
and later became the author (with Jack Graver and Herman Servatius) of the book ''Combinatorial Rigidity'' (1993).{{r|comb}}{{ran|G}}
Another well-cited paper of hers in this area characterizes the [[planar graph|planar]] [[Laman graph]]s, the minimally rigid graphs that can be embedded without crossings in the plane, as the graphs of [[pseudotriangle|pseudotriangulations]], partitions of a plane region into subregions with three convex corners studied in [[computational geometry]].{{ran|H}}

Servatius is also the co-editor of a book on [[matroid|matroid theory]].{{ran|B}}
With [[Tomaž Pisanski]] she wrote the book ''Configurations from a Graphical Viewpoint'' (2013), on [[Configuration (geometry)|configurations]] of points and lines in the plane with the same number of points touching each two lines and the same number of lines touching each two points.{{r|configs}}{{ran|P}} Other topics in her research include [[dual graph|graph duality]]{{ran|S}} and the [[SPQR tree|triconnected components]] of infinite graphs.{{ran|D}}

==Selected publications==
{{rma|Z|{{citation
 | last = Servatius | first = Brigitte
 | doi = 10.1007/BF01162012
 | issue = 1
 | journal = [[Mathematische Zeitschrift]]
 | mr = 711734
 | pages = 133–137
 | title = A short proof of a theorem of Burns
 | volume = 184
 | year = 1983}}|tw=1.5em}}

{{rma|G|{{citation
 | last1 = Graver | first1 = Jack
 | last2 = Servatius | first2 = Brigitte
 | last3 = Servatius | first3 = Herman
 | doi = 10.1090/gsm/002
 | isbn = 0-8218-3801-6
 | mr = 1251062
 | publisher = American Mathematical Society | location = Providence, RI
 | series = [[Graduate Studies in Mathematics]]
 | title = Combinatorial rigidity
 | volume = 2
 | year = 1993}}|tw=1.5em}}

{{rma|D|{{citation
 | last1 = Droms | first1 = Carl
 | last2 = Servatius | first2 = Brigitte
 | last3 = Servatius | first3 = Herman
 | journal = Electronic Journal of Combinatorics
 | mr = 1346878
 | page = R17
 | title = The structure of locally finite two-connected graphs
 | url = http://www.combinatorics.org/ojs/index.php/eljc/article/view/v2i1r17
 | volume = 2
 | year = 1995}}|tw=1.5em}}

{{rma|S|{{citation
 | last1 = Servatius | first1 = Brigitte
 | last2 = Servatius | first2 = Herman
 | doi = 10.1016/0012-365X(94)00351-I
 | issue = 1-3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | mr = 1375109
 | pages = 223–232
 | title = Self-dual graphs
 | volume = 149
 | year = 1996}}|tw=1.5em}}

{{rma|B|{{citation
 | editor1-last = Bonin | editor1-first = Joseph E.
 | editor2-last  = Oxley | editor2-first = James G. | author2-link = James Oxley
 | editor3-last  = Servatius | editor3-first = Brigitte
 | doi = 10.1090/conm/197
 | isbn = 0-8218-0508-8
 | mr = 1411689
 | publisher = American Mathematical Society | location = Providence, RI
 | series = Contemporary Mathematics
 | title = Matroid Theory: Proceedings of the AMS-IMS-SIAM Joint Summer Research Conference held at the University of Washington, Seattle, Washington, July 2–6, 1995
 | volume = 197
 | year = 1996}}|tw=1.5em}}

{{rma|H|{{citation
 | last1 = Haas | first1 = Ruth | author1-link = Ruth Haas
 | last2 = Orden | first2 = David
 | last3 = Rote | first3 = Günter
 | last4 = Santos | first4 = Francisco | author4-link = Francisco Santos Leal
 | last5 = Servatius | first5 = Brigitte
 | last6 = Servatius | first6 = Herman
 | last7 = Souvaine | first7 = Diane | author7-link = Diane Souvaine
 | last8 = Streinu | first8 = Ileana | author8-link = Ileana Streinu
 | last9 = Whiteley | first9 = Walter | author9-link = Walter Whiteley
 | doi = 10.1016/j.comgeo.2004.07.003
 | issue = 1-2
 | journal = [[Computational Geometry (journal)|Computational Geometry: Theory and Applications]]
 | mr = 2131802
 | pages = 31–61
 | title = Planar minimally rigid graphs and pseudo-triangulations
 | volume = 31
 | year = 2005}}|tw=1.5em}}

{{rma|P|{{citation
 | last1 = Pisanski | first1 = Tomaž | author1-link = Tomaž Pisanski
 | last2 = Servatius | first2 = Brigitte
 | doi = 10.1007/978-0-8176-8364-1
 | isbn = 978-0-8176-8363-4
 | mr = 2978043
 | publisher = Birkhäuser/Springer | location = New York
 | series = Birkhäuser Advanced Texts: Basler Lehrbücher. [Birkhäuser Advanced Texts: Basel Textbooks]
 | title = Configurations from a graphical viewpoint
 | year = 2013}}|tw=1.5em}}

==References==
{{reflist|refs=

&lt;ref name=bdate&gt;Birth date from [https://www.worldcat.org/identities/lccn-n93-081883/ Worldcat]&lt;/ref&gt;

&lt;ref name=cant&gt;{{citation|url=http://www.ostaustria.org/programs-projects-english/40-categories-all/bridges/researchers-network/716-introducing-brigitte-servatius-theres-no-such-thing-as-cant|title=Introducing Brigitte Servatius: There's No Such Thing as Can't|first=Caroline|last=Adenberger |publisher=Office of Science and Technology Austria|accessdate=2018-02-05}}&lt;/ref&gt;

&lt;ref name=comb&gt;Reviews of ''Combinatorial Rigidity'':
*{{citation|title=none|first=Robert|last=Connelly|journal=[[Mathematical Reviews]]|year=1995|mr=1251062}}
*{{citation|title=none|first=Robert|last=Connelly|journal=[[Bulletin of the American Mathematical Society]]|year=1996|volume=33|pages=399–401|doi=10.1090/S0273-0979-96-00670-2}}
&lt;/ref&gt;

&lt;ref name=configs&gt;Review of ''Configurations from a Graphical Viewpoint'':
*{{citation|title=none|last=Tucker|first=Thomas W.|authorlink=Thomas W. Tucker|journal=[[Mathematical Reviews]]|mr=2978043}}
&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=30507}}&lt;/ref&gt;

&lt;ref name=pme&gt;{{citation|url=http://www.pme-math.org/organization/candidates.html|title=2005 Council Candidates|publisher=[[Pi Mu Epsilon]]|accessdate=2018-02-05}}&lt;/ref&gt;

&lt;ref name=standard&gt;{{citation|url=https://derstandard.at/1219725060236/Geistesblitz-Zurueck-zur-Natur|title=Geistesblitz: Zurück zur Natur|date=August 27, 2008|newspaper=[[Der Standard]]|language=German|first=Peter|last=Illetschko}}&lt;/ref&gt;

}}

==External links==
*[http://users.wpi.edu/~bservat/ Home page]
*{{Google Scholar id|jSwfETsAAAAJ}}

{{Authority control}}
{{DEFAULTSORT:Servatius, Brigitte}}
[[Category:1954 births]]
[[Category:Living people]]
[[Category:People from Graz]]
[[Category:Austrian mathematicians]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:American women mathematicians]]
[[Category:Group theorists]]
[[Category:Graph theorists]]
[[Category:University of Graz alumni]]
[[Category:Syracuse University alumni]]
[[Category:Worcester Polytechnic Institute faculty]]</text>
      <sha1>2ylhewh592sxitm1l8mc5chicp9jrop</sha1>
    </revision>
  </page>
  <page>
    <title>Calderón projector</title>
    <ns>0</ns>
    <id>49155297</id>
    <revision>
      <id>706986698</id>
      <parentid>706824300</parentid>
      <timestamp>2016-02-26T11:15:54Z</timestamp>
      <contributor>
        <username>JuPitEer</username>
        <id>5149526</id>
      </contributor>
      <comment>/* Definition */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1613">In applied mathematics, the '''Calderón projector''' is a [[pseudo-differential operator]] used widely in [[boundary element method]]s. It is named after [[Alberto Calderón]].

== Definition ==
The interior Calderón projector is defined to be:&lt;ref&gt;{{cite book |last=Steinbach |first=Olaf |date=2008 |title=Numerical Approximation Methods for Elliptic Boundary Value Problems |publisher=Springer |page=137 |isbn=978-0-387-31312-2}}&lt;/ref&gt;

&lt;math&gt;\mathcal{C}=\left(\begin{array}{cc}(1-\sigma)\mathsf{Id}-\mathsf{K}&amp;\mathsf{V}\\\mathsf{W}&amp;\sigma\mathsf{Id}+\mathsf{K}'\end{array}\right),&lt;/math&gt;

where &lt;math&gt;\sigma&lt;/math&gt; is &lt;math&gt;\tfrac12&lt;/math&gt; almost everywhere, &lt;math&gt;\mathsf{Id}&lt;/math&gt; is the [[identity boundary operator]], &lt;math&gt;\mathsf{K}&lt;/math&gt; is the [[double layer boundary operator]], &lt;math&gt;\mathsf{V}&lt;/math&gt; is the [[single layer boundary operator]], &lt;math&gt;\mathsf{K}'&lt;/math&gt; is the [[adjoint double layer boundary operator]] and &lt;math&gt;\mathsf{W}&lt;/math&gt; is the [[hypersingular boundary operator]].

The exterior Calderón projector is defined to be:&lt;ref&gt;{{cite book |last=Steinbach |first=Olaf |date=2008 |title=Numerical Approximation Methods for Elliptic Boundary Value Problems |publisher=Springer |page=182 |isbn=978-0-387-31312-2}}&lt;/ref&gt;

: &lt;math&gt;\mathcal{C}=\left(\begin{array}{cc}\sigma\mathsf{Id}+\mathsf{K}&amp;-\mathsf{V}\\-\mathsf{W}&amp;(1-\sigma)\mathsf{Id}-\mathsf{K}'\end{array}\right).&lt;/math&gt;

== References ==
&lt;references/&gt;

{{DEFAULTSORT:Calderon projector}}
[[Category:Potential theory]]
[[Category:Partial differential equations]]
[[Category:Complex analysis]]
[[Category:Operator theory]]</text>
      <sha1>4rjgiowd6ar75ngj958adijgwh25mck</sha1>
    </revision>
  </page>
  <page>
    <title>Centrality</title>
    <ns>0</ns>
    <id>1462712</id>
    <revision>
      <id>861906659</id>
      <parentid>861906578</parentid>
      <timestamp>2018-09-30T21:58:50Z</timestamp>
      <contributor>
        <username>Latex-yow</username>
        <id>27692366</id>
      </contributor>
      <minor/>
      <comment>/* PageRank centrality */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="43566">{{for|the statistical concept|Central tendency}}
[[File:6 centrality measures.png|thumb|right|300px|Examples of A) [[Betweenness centrality]], B) [[Closeness centrality]], C) [[Eigenvector centrality]], D) [[Degree centrality]], E) [[Centrality#Harmonic centrality|Harmonic Centrality]] and F) [[Katz centrality]] of the same graph.]]

In [[graph theory]] and [[network theory|network analysis]], indicators of '''centrality''' identify the most important [[vertex (graph theory)|vertices]] within a graph. Applications include identifying the most influential person(s) in a [[social network]], key infrastructure nodes in the [[Internet]] or [[urban network]]s, and [[super-spreader]]s of disease. Centrality concepts were first developed in [[social network analysis]], and many of the terms used to measure centrality reflect their [[sociology|sociological]] origin.&lt;ref name="NewmanNetworks"&gt;Newman, M.E.J. 2010. ''Networks: An Introduction.'' Oxford, UK: Oxford University Press.&lt;/ref&gt;
They should not be confused with [[node influence metric]]s, which seek to quantify the influence of every node in the network.

==Definition and characterization of centrality indices==
Centrality indices are answers to the question "What characterizes an important vertex?" The answer is given in terms of a real-valued function on the vertices of a graph, where the values produced are expected to provide a ranking which identifies the most important nodes.&lt;ref name="Bonacich1987"&gt;{{cite journal |last1= Bonacich |first1= Phillip|year= 1987 |title= Power and Centrality: A Family of Measures | journal=American Journal of Sociology |volume= 92|issue= |pages= 1170–1182|publisher= University of Chicago Press|doi=10.1086/228631 |url= }}&lt;!--|accessdate=July 11, 2014--&gt;&lt;/ref&gt;&lt;ref name="Borgatti2005"&gt;{{cite journal |last1= Borgatti |first1= Stephen P.|year= 2005 |title= Centrality and Network Flow |journal=Social Networks |volume= 27|issue= |pages= 55–71|publisher= Elsevier|doi=10.1016/j.socnet.2004.11.008 |url= }}&lt;!--|accessdate= July 11, 2014--&gt;&lt;/ref&gt;

The word "importance" has a wide number of meanings, leading to many different definitions of centrality. Two categorization schemes have been proposed.
"Importance" can be conceived in relation to a type of flow or transfer across the network. This allows centralities to be classified by the type of flow they consider important.&lt;ref name=Borgatti2005/&gt; "Importance" can alternatively be conceived as involvement in the cohesiveness of the network. This allows centralities to be classified based on how they measure cohesiveness.&lt;ref name="Borgatti2006"&gt;{{cite journal |last1= Borgatti |first1= Stephen P.|last2= Everett |first2= Martin G.|year= 2006 |title= A Graph-Theoretic Perspective on Centrality |journal=Social Networks |volume= 28|issue= |pages= 466–484|publisher= Elsevier|doi=10.1016/j.socnet.2005.11.005 |url= }}&lt;!--|accessdate= July 11, 2014--&gt;&lt;/ref&gt; Both of these approaches divide centralities in distinct categories. A further conclusion is that a centrality which is appropriate for one category will often "get it wrong" when applied to a different category.&lt;ref name=Borgatti2005/&gt;

When centralities are categorized by their approach to cohesiveness, it becomes apparent that the majority of centralities inhabit one category. The count of the number of walks starting from a given vertex differs only in how walks are defined and counted. Restricting consideration to this group allows for a soft characterization which places centralities on a spectrum from walks of length one ([[Centrality#Degree centrality|degree]] centrality) to infinite walks ([[Centrality#Eigenvector centrality|eigenvalue]] centrality).&lt;ref name=Bonacich1987/&gt;&lt;ref name="Benzi2013"&gt;{{cite journal | last1=Benzi | first1=Michele | last2=Klymko| first2=Christine | year=2013 |title= A matrix analysis of different centrality measures |arxiv=1312.6722 | doi=10.1137/130950550 | volume=36 | journal=SIAM Journal on Matrix Analysis and Applications | pages=686–706}}&lt;/ref&gt; The observation that many centralities share this familial relationships perhaps explains the high rank correlations between these indices.

===Characterization by network flows===
A network can be considered a description of the paths along which something flows. This allows a characterization based on the type of flow and the type of path encoded by the centrality. A flow can be based on transfers, where each undivisible item goes from one node to another, like a package delivery which goes from the delivery site to the client's house. A second case is the serial duplication, where this is a replication of the item which goes to the next node, so both the source and the target have it. An example is the propagation of information through gossip, with the information being propagated in a private way and with both the source and the target nodes being informed at the end of the process. The last case is the parallel duplication, with the item being duplicated to several links at the same time, like a radio broadcast which provides the same information to many listeners at once.&lt;ref name=Borgatti2005/&gt;

Likewise, the type of path can be constrained to: Geodesics (shortest paths), [[Walk (graph theory)#Walks|paths]]  (no vertex is visited more than once), [[Walk (graph theory)#Walks|trails]] (vertices can be visited multiple times, no edge is traversed more than once), or [[Walk (graph theory)#Walks|walks]] (vertices and edges can be visited/traversed multiple times).&lt;ref name=Borgatti2005/&gt;

===Characterization by walk structure===
An alternative classification can be derived from how the centrality is constructed. This again splits into two classes. Centralities are either ''Radial'' or ''Medial.''
Radial centralities count walks which start/end from the given vertex. The [[Centrality#Degree centrality|degree]] and [[Centrality#Eigenvector centrality|eigenvalue]] centralities are examples of radial centralities, counting the number of walks of length one or length infinity. Medial centralities count walks which pass through the given vertex. The canonical example is Freeman's [[Centrality#Betweenness centrality|betweenness]] centrality, the number of shortest paths which pass through the given vertex.&lt;ref name=Borgatti2006/&gt;

Likewise, the counting can capture either the ''volume'' or the ''length'' of walks. Volume is the total number of walks of the given type. The three examples from the previous paragraph fall into this category. Length captures the distance from the given vertex to the remaining vertices in the graph. Freeman's [[Centrality#Closeness centrality|closeness]] centrality, the total geodesic distance from a given vertex to all other vertices, is the best known example.&lt;ref name=Borgatti2006/&gt; Note that this classification is independent of the type of walk counted (i.e. walk, trail, path, geodesic).

Borgatti and Everett propose that this typology provides insight into how best to compare centrality measures. Centralities placed in the same box in this 2×2  classification are similar enough to make plausible alternatives; one can reasonably compare which is better for a given application. Measures from different boxes, however, are categorically distinct. Any evaluation of relative fitness can only occur within the context of predetermining which category is more applicable, rendering the comparison moot.&lt;ref name=Borgatti2006/&gt;

===Radial-volume centralities exist on a spectrum===
The characterization by walk structure shows that almost all centralities in wide use are radial-volume measures. These encode the belief that a vertex's centrality is a function of the centrality of the vertices it is associated with. Centralities distinguish themselves on how association is defined.

Bonacich showed that if association is defined in terms of [[Walk (graph theory)#Walks|walks]], then a family of centralities can be defined based on the length of walk considered.&lt;ref name="Bonacich1987"/&gt; The [[Centrality#Degree centrality|degree]] counts walks of length one, the [[Centrality#Eigenvector centrality|eigenvalue]] centrality counts walks of length infinity. Alternative definitions of association are also reasonable. The [[alpha centrality]] allows vertices to have an external source of influence. Estrada's subgraph centrality proposes only counting closed paths (triangles, squares, ...).

The heart of such measures is the observation that powers of the graph's adjacency matrix gives the number of walks of length given by that power.  Similarly, the matrix exponential is also closely related to the number of walks of a given length. An initial transformation of the adjacency matrix allows differing definition of the type of walk counted. Under either approach, the centrality of a vertex can be expressed as an infinite sum, either

:&lt;math&gt;\sum_{k=0}^\infty A_{R}^{k} \beta^k &lt;/math&gt;

for matrix powers or

:&lt;math&gt;\sum_{k=0}^\infty \frac{(A_R \beta)^k}{k!}&lt;/math&gt;

for matrix exponentials, where

* &lt;math&gt;k&lt;/math&gt; is walk length,
* &lt;math&gt;A_R&lt;/math&gt; is the transformed adjacency matrix, and
* &lt;math&gt;\beta&lt;/math&gt; is a discount parameter which ensures convergence of the sum.

Bonacich's family of measures does not transform the adjacency matrix. The [[alpha centrality]] replaces the adjacency matrix with its [[resolvent formalism|resolvent]]. The subgraph centrality replaces the adjacency matrix with its trace. A startling conclusion is that regardless of the initial transformation of the adjacency matrix, all such approaches have common limiting behavior. As &lt;math&gt;\beta&lt;/math&gt; approaches zero, the indices converge to the [[Centrality#Degree centrality|degree]] centrality. As &lt;math&gt;\beta&lt;/math&gt; approaches its maximal value, the indices converge to the [[Centrality#Eigenvector centrality|eigenvalue]] centrality.&lt;ref name=Benzi2013/&gt;

===Game-Theoretic Centrality===
The common feature of most of the aforementioned standard measures is that they assess the
importance of a node by focusing only on the role that a node plays by itself. However,
in many applications such an approach is inadequate because of synergies that may occur
if the functioning of nodes is considered in groups.
[[File:Game-theoretic centrality.png|Example of game-theoretic centrality]]

For example, let's consider problem of stopping epidemic. Looking at above image of network, which nodes should we vaccinate? Based on previously described measures, we want to recognize nodes that are the most important in disease spreading. Approaches based only on centralities, that focuse on indiviudal features of nodes, may not be good idea. Nodes in the red square, individually cannot stop disease spreading, but considering them as a group, we clearly see that they can stop disease if it has started in nodes &lt;math&gt;v_1&lt;/math&gt;,&lt;math&gt;v_4&lt;/math&gt;,&lt;math&gt;v_5&lt;/math&gt;. Game-Theoretic Centralities try to consult described problems and opportunities, using tools from game-theory. Approach proposed in &lt;ref&gt;Michalak, Aadithya, Szczepański, Ravindran, &amp; Jennings https://arxiv.org/pdf/1402.0567.pdf&lt;/ref&gt; uses Shapley Value. Because of time-complexity hardness of Shapley value calculation, most efforts in this domain are driven into implementing new algorithms and methods which rely on peculiar topology of network and special character of problem. Such a approach may lead to reducing time-complexity from exponential to polynomial.

== Important limitations ==
Centrality indices have two important limitations, one obvious and the other subtle. The obvious limitation is that a centrality which is optimal for one application is often sub-optimal for a different application. Indeed, if this were not so, we would not need so many different centralities. An illustration of this phenomenon is provided by the [[Krackhardt kite graph]], for which three different notions of centrality give three different choices of the most central vertex.&lt;ref&gt;{{cite journal|title=Assessing the Political Landscape: Structure, Cognition, and Power in Organizations|first=David|last=Krackhardt|authorlink=David Krackhardt|journal=Administrative Science Quarterly|volume=35|issue=2|date=June 1990|pages=342–369|doi=10.2307/2393394|jstor=2393394}}&lt;/ref&gt;

The more subtle limitation is the commonly held fallacy that vertex centrality indicates the relative importance of vertices. Centrality indices are explicitly designed to produce a ranking which allows indication of the most important vertices.&lt;ref name=Bonacich1987/&gt;&lt;ref name=Borgatti2005/&gt; This they do well, under the limitation just noted. They are not designed to measure the influence of nodes in general. Recently, network physicists have begun developing  [[node influence metric]]s to address this problem.

The error is two-fold. Firstly, a ranking only orders vertices by importance, it does not quantify the difference in importance between different levels of the ranking. This may be mitigated by applying [[Centrality#Freeman Centralization|Freeman centralization]] to the centrality measure in question, which provide some insight to the importance of nodes depending on the differences of their centralization scores. Furthermore, Freeman centralization enables one to compare several networks by comparing their highest centralization scores.&lt;ref name="Freeman1979"/&gt; This approach, however, is seldom seen in practice.{{citation needed|reason=I've come across quite some theoretical studies that indicate otherwise. My suggestion is to remove this sentence, if reasonable citation is not provided.|date=September 2015}}

Secondly, the features which (correctly) identify the most important vertices in a given network/application do not necessarily generalize to the remaining vertices. 
For the majority of other network nodes the rankings may be meaningless.&lt;ref name="Lawyer2015" /&gt;&lt;ref name="daSilva2012"&gt;{{cite journal | last1=da Silva|first1=Renato |last2=Viana|first2=Matheus|last3=da F. Costa |first3=Luciano| title=Predicting epidemic outbreak from individual features of the spreaders| journal=J. Stat Mech Theor Exp | year=2012|volume=2012|pages=P07005|number=07 | doi=10.1088/1742-5468/2012/07/p07005|arxiv=1202.0024|bibcode=2012JSMTE..07..005A}}&lt;/ref&gt;&lt;ref name="Bauer2012"&gt;{{cite journal | last1=Bauer|first1=Frank | last2=Lizier|first2=Joseph|title=Identifying influential spreaders and efficiently estimating infection  numbers in epidemic models: A walk counting approach| journal=Europhys Lett | year=2012| volume=99| pages=68007|number=6 | doi=10.1209/0295-5075/99/68007|arxiv=1203.0502|bibcode=2012EL.....9968007B}}&lt;/ref&gt;&lt;ref name="Sikic2013"&gt;{{ cite journal| last1= Sikic| first1=Mile|last2=Lancic|first2=Alen|last3=Antulov-Fantulin|first3=Nino|last4=Stefanic|first4=Hrvoje| title = Epidemic centrality -- is there an underestimated epidemic impact  of network peripheral nodes? |journal = The European Physical Journal B |volume=86 |number=10 |pages=1–13 |year=2013 | doi=10.1140/epjb/e2013-31025-5|arxiv=1110.2558}}&lt;/ref&gt; This explains why, for example, only the first few results of a Google image search appear in a reasonable order. The pagerank is a highly unstable measure, showing frequent rank reversals after small adjustments of the jump parameter
&lt;ref name="Ghoshal2011"&gt;{{cite journal | last1=Ghoshal | first1= G. | last2= Barabsi |first2= A L | title = Ranking stability and super-stable nodes in complex networks. | journal = Nat Commun | volume =2 | page = 394| year= 2011 | doi=10.1038/ncomms1396 | bibcode=2011NatCo...2E.394G }}&lt;/ref&gt;

While the failure of centrality indices to generalize to the rest of the network may at first seem counter-intuitive, it follows directly from the above definitions.
Complex networks have heterogeneous topology. To the extent that the optimal measure depends on the network structure of the most important vertices, a measure which is optimal for such vertices is sub-optimal for the remainder of the network.&lt;ref name="Lawyer2015"&gt;{{cite journal |last1= Lawyer |first1= Glenn |year= 2015 |title= Understanding the spreading power of all nodes in a network: a continuous-time perspective |journal=Sci Rep |volume=5|pages=8665|doi=10.1038/srep08665 |pmid=25727453 |pmc=4345333|arxiv=1405.6707|bibcode=2015NatSR...5E8665L}}&lt;/ref&gt;

==Degree centrality==
{{Main|Degree (graph theory)}} 
Historically first and conceptually simplest is '''degree centrality''', which is defined as the number of links incident upon a node (i.e., the number of ties that a node has). The degree can be interpreted in terms of the immediate risk of a node for catching whatever is flowing through the network (such as a virus, or some information). In the case of a directed network (where ties have direction), we usually define two separate measures of degree centrality, namely [[indegree]] and [[outdegree]]. Accordingly, indegree is a count of the number of ties directed to the node and outdegree is the number of ties that the node directs to others. When ties are associated to some positive aspects such as friendship or collaboration, indegree is often interpreted as a form of popularity, and outdegree as gregariousness.

The degree centrality of a vertex &lt;math&gt;v&lt;/math&gt;, for a given graph &lt;math&gt;G:=(V,E)&lt;/math&gt; with &lt;math&gt;|V|&lt;/math&gt; vertices and &lt;math&gt;|E|&lt;/math&gt; edges, is defined as

:&lt;math&gt;C_D(v)= \deg(v)&lt;/math&gt;

Calculating degree centrality for all the nodes in a graph takes [[big theta|&lt;math&gt;\Theta(V^2)&lt;/math&gt;]] in a [[dense matrix|dense]] [[adjacency matrix]] representation of the graph, and for edges takes &lt;math&gt;\Theta(E)&lt;/math&gt; in a [[sparse matrix]] representation.

The definition of centrality on the node level can be extended to the whole graph, in which case we are speaking of ''graph centralization''.&lt;ref&gt;Freeman, Linton C. "Centrality in social networks conceptual clarification." Social networks 1.3 (1979): 215–239.&lt;/ref&gt; Let &lt;math&gt;v*&lt;/math&gt; be the node with highest degree centrality in &lt;math&gt;G&lt;/math&gt;. Let &lt;math&gt;X:=(Y,Z)&lt;/math&gt; be the &lt;math&gt;|Y|&lt;/math&gt; node connected graph that maximizes the following quantity (with &lt;math&gt;y*&lt;/math&gt; being the node with highest degree centrality in &lt;math&gt;X&lt;/math&gt;):

:&lt;math&gt;H= \sum^{|Y|}_{j=1} [C_D(y*)-C_D(y_j)]&lt;/math&gt;

Correspondingly, the degree centralization of the graph &lt;math&gt;G&lt;/math&gt; is as follows:

:&lt;math&gt;C_D(G)= \frac{\sum^{|V|}_{i=1} [C_D(v*)-C_D(v_i)]}{H}&lt;/math&gt;

The value of &lt;math&gt;H&lt;/math&gt; is maximized when the graph &lt;math&gt;X&lt;/math&gt; contains one central node to which all other nodes are connected (a [[star graph]]), and in this case 

:&lt;math&gt;H=(n-1)\cdot((n-1)-1)=n^2-3n+2.&lt;/math&gt;

So, for any graph &lt;math&gt;G:=(V,E),&lt;/math&gt;  

:&lt;math&gt;C_D(G)= \frac{\sum^{|V|}_{i=1} [C_D(v*)-C_D(v_i)] }{|V|^2-3|V|+2}&lt;/math&gt;

==Closeness centrality==
{{Main|Closeness centrality}}In a [[Connected component (graph theory)|connected]] [[Graph (discrete mathematics)|graph]], the [[Normalization (statistics)|normalized]] '''closeness centrality''' (or '''closeness''') of a node is the average length of the [[Shortest path problem|shortest path]] between the node and all other nodes in the graph. Thus the more central a node is, the closer it is to all other nodes.

Closeness was defined by Bavelas (1950) as the [[Multiplicative inverse|reciprocal]] of the '''farness''',&lt;ref&gt;Alex Bavelas. Communication patterns in task-oriented groups. ''J. Acoust. Soc. Am'', '''22'''(6):725–730, 1950.&lt;/ref&gt;&lt;ref&gt;{{cite journal|year=1966|title=The centrality index of a graph|url=|journal=Psychometrika|volume=31|issue=|pages=581–603|doi=10.1007/bf02289527|last1=Sabidussi|first1=G}}&lt;/ref&gt; that is:

: &lt;math&gt;C(x)= \frac{1}{\sum_y d(y,x)}&lt;/math&gt;

where &lt;math&gt;d(y,x)&lt;/math&gt; is the [[Distance (graph theory)|distance]] between vertices &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt;. However, when speaking of closeness centrality, people usually refer to its normalized form, generally given by the previous formula multiplied by &lt;math&gt;N-1&lt;/math&gt;, where &lt;math&gt;N&lt;/math&gt; is the number of nodes in the graph. This adjustment allows comparisons between nodes of graphs of different sizes.

Taking distances ''from'' or ''to'' all other nodes is irrelevant in undirected graphs, whereas it can produce totally different results in [[directed graph]]s (e.g. a website can have a high closeness centrality from outgoing link, but low closeness centrality from incoming links).

===Harmonic centrality===
In a (not necessarily connected) graph, the '''harmonic centrality''' reverses the sum and reciprocal operations in the definition of closeness centrality:

: &lt;math&gt;H(x)= \sum_{y \neq x} \frac{1}{d(y,x)}&lt;/math&gt;

where &lt;math&gt;1 / d(y,x) = 0&lt;/math&gt; if there is no path from &lt;math&gt;y&lt;/math&gt; to &lt;math&gt;x&lt;/math&gt;. Harmonic centrality can be normalized by dividing by &lt;math&gt;N-1&lt;/math&gt;, where &lt;math&gt;N&lt;/math&gt; is the number of nodes in the graph.

Harmonic centrality was proposed by [[Massimo Marchiori|Marchiori]] and [[Vito Latora|Latora]] (2000)&lt;ref name="marchiorilatora2000"&gt;{{citation| journal = Physica A: Statistical Mechanics and its Applications  | last1 = Marchiori | first1 = Massimo | last2 = Latora | first2 = Vito | year = 2000 | volume = 285 | issue = 3-4 | pages = 539–546 | title = Harmony in the small-world | url = https://arxiv.org/pdf/cond-mat/0008357.pdf | doi=10.1016/s0378-4371(00)00311-3| arxiv = cond-mat/0008357 | bibcode = 2000PhyA..285..539M }}&lt;/ref&gt; and then independently by Dekker (2005), using the name "valued centrality,"&lt;ref&gt;{{cite journal|first1=Anthony|last1=Dekker|title=Conceptual Distance in Social Network Analysis|journal=Journal of Social Structure|volume=6|issue=3|year=2005|url=http://www.cmu.edu/joss/content/articles/volume6/dekker/index.html}}&lt;/ref&gt; and by Rochat (2009).&lt;ref&gt;{{cite conference  | author = Yannick Rochat  | title = Closeness centrality extended to unconnected graphs: The harmonic centrality index | conference = Applications of Social Network Analysis, ASNA 2009 | url = http://infoscience.epfl.ch/record/200525/files/%5bEN%5dASNA09.pdf }}&lt;/ref&gt;

==Betweenness centrality==
{{Main|Betweenness centrality}}

[[File:Graph betweenness.svg|240px|right|thumb|Hue (from red&amp;nbsp;=&amp;nbsp;0 to blue&amp;nbsp;=&amp;nbsp;max) shows the node betweenness.]]

'''Betweenness''' is a centrality measure of a [[vertex (graph theory)|vertex]] within a [[Graph (discrete mathematics)|graph]] (there is also [[edge (graph theory)|edge]] betweenness, which is not discussed here). Betweenness centrality quantifies the number of times a node acts as a bridge along the shortest path between two other nodes. It was introduced as a measure for quantifying the control of a human on the communication between other humans in a social network by [[Linton Freeman]]&lt;ref name="freeman1977"&gt;{{cite journal |last1 = Freeman |first1 = Linton | year=1977| title = A set of measures of centrality based upon betweenness | journal = Sociometry| volume=40| pages=35–41 | doi=10.2307/3033543}}&lt;/ref&gt; In his conception, vertices that have a high probability to occur on a randomly chosen [[shortest path problem|shortest path]] between two randomly chosen vertices have a high betweenness.

The betweenness of a vertex &lt;math&gt;v&lt;/math&gt; in a graph &lt;math&gt;G:=(V,E)&lt;/math&gt; with &lt;math&gt;V&lt;/math&gt; vertices is computed as follows:

# For each pair of vertices (''s'',''t''), compute the [[Shortest path problem|shortest paths]] between them.
# For each pair of vertices (''s'',''t''), determine the fraction of shortest paths that pass through the vertex in question (here, vertex ''v'').
# Sum this fraction over all pairs of vertices (''s'',''t'').

More compactly the betweenness can be represented as:&lt;ref name="brandes"&gt;{{cite journal |last1 = Brandes |first1 = Ulrik | year=2001 |title = A faster algorithm for betweenness centrality  | journal = Journal of Mathematical Sociology| volume=25| pages=163–177| url = http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.2024 | accessdate = October 11, 2011| format = PDF | doi=10.1080/0022250x.2001.9990249}}&lt;/ref&gt;

:&lt;math&gt;C_B(v)= \sum_{s \neq v \neq t \in V}\frac{\sigma_{st}(v)}{\sigma_{st}}&lt;/math&gt;

where &lt;math&gt;\sigma_{st}&lt;/math&gt; is total number of shortest paths from node &lt;math&gt;s&lt;/math&gt; to node &lt;math&gt;t&lt;/math&gt; and &lt;math&gt;\sigma_{st}(v)&lt;/math&gt; is the number of those paths that pass through &lt;math&gt;v&lt;/math&gt;.  The betweenness may be normalised by dividing through the number of pairs of vertices not including ''v'', which for [[Digraph (mathematics)|directed graphs]] is &lt;math&gt;(n-1)(n-2)&lt;/math&gt; and for undirected graphs is &lt;math&gt;(n-1)(n-2)/2&lt;/math&gt;.  For example, in an undirected [[Star (graph theory)|star graph]], the center vertex (which is contained in every possible shortest path) would have a betweenness of &lt;math&gt;(n-1)(n-2)/2&lt;/math&gt; (1, if normalised) while the leaves (which are contained in no shortest paths) would have a betweenness of 0.

From a calculation aspect, both betweenness and closeness centralities of all vertices in a graph involve calculating the shortest paths between all pairs of vertices on a graph, which requires [[big theta|&lt;math&gt;\Theta(V^3)&lt;/math&gt;]] time with the [[Floyd–Warshall algorithm]]. However, on sparse graphs, [[Johnson's algorithm]] may be more efficient, taking [[Big O notation|&lt;math&gt;O(V^2 \log V + V E)&lt;/math&gt;]] time. In the case of unweighted graphs the calculations can be done with Brandes' algorithm&lt;ref name=brandes/&gt; which takes [[Big O notation|&lt;math&gt;O(V E)&lt;/math&gt;]] time. Normally, these algorithms assume that graphs are undirected and connected with the allowance of loops and multiple edges. When specifically dealing with network graphs, often graphs are without loops or multiple edges to maintain simple relationships (where edges represent connections between two people or vertices). In this case, using Brandes' algorithm will divide final centrality scores by 2 to account for each shortest path being counted twice.&lt;ref name="brandes" /&gt;

==Eigenvector centrality==
{{main|Eigenvector centrality}}
'''Eigenvector centrality''' (also called '''eigencentrality''') is a measure of the influence of a [[node (networking)|node]] in a [[network (mathematics)|network]]. It assigns relative scores to all nodes in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes. [[Google]]'s [[PageRank]] and the [[Katz centrality]] are variants of the eigenvector centrality.&lt;ref name="ams"&gt;http://www.ams.org/samplings/feature-column/fcarc-pagerank&lt;/ref&gt;

=== Using the adjacency matrix to find eigenvector centrality ===
For a given graph &lt;math&gt;G:=(V,E)&lt;/math&gt; with &lt;math&gt;|V|&lt;/math&gt; number of vertices let &lt;math&gt;A = (a_{v,t})&lt;/math&gt; be the [[adjacency matrix]], i.e. &lt;math&gt;a_{v,t} = 1&lt;/math&gt; if vertex &lt;math&gt;v&lt;/math&gt; is linked to vertex &lt;math&gt;t&lt;/math&gt;, and &lt;math&gt;a_{v,t} = 0&lt;/math&gt; otherwise. The relative centrality score of vertex &lt;math&gt;v&lt;/math&gt; can be defined as:

:&lt;math&gt;x_v = \frac{1}{\lambda} \sum_{t \in M(v)}x_t = \frac{1}{\lambda} \sum_{t \in G} a_{v,t}x_t&lt;/math&gt;

where &lt;math&gt;M(v)&lt;/math&gt; is a set of the neighbors of &lt;math&gt;v&lt;/math&gt; and &lt;math&gt;\lambda&lt;/math&gt; is a constant. With a small rearrangement this can be rewritten in vector notation as the [[eigenvector]] equation

:&lt;math&gt;\mathbf{Ax} = {\lambda}\mathbf{x}&lt;/math&gt;

In general, there will be many different [[eigenvalue]]s &lt;math&gt;\lambda&lt;/math&gt; for which a non-zero eigenvector solution exists. Since the entries in the adjacency matrix are non-negative, there is a unique largest eigenvalue, which is real and positive, by the [[Perron–Frobenius theorem]]. This greatest eigenvalue results in the desired centrality measure.&lt;ref&gt;{{cite journal  | author = M. E. J. Newman  | title = The mathematics of networks  | url = http://www-personal.umich.edu/~mejn/papers/palgrave.pdf  | format = PDF  | accessdate = 2006-11-09}}&lt;/ref&gt; The &lt;math&gt;v^{th}&lt;/math&gt; component of the related eigenvector then gives the relative centrality score of the vertex &lt;math&gt;v&lt;/math&gt; in the network. The eigenvector is only defined up to a common factor, so only the ratios of the centralities of the vertices are well defined. To define an absolute score one must normalise the eigen vector e.g. such that the sum over all vertices is 1 or the total number of vertices ''n''. [[Power iteration]] is one of many [[eigenvalue algorithm]]s that may be used to find this dominant eigenvector.&lt;ref name="ams" /&gt; Furthermore, this can be generalized so that the entries in ''A'' can be real numbers representing connection strengths, as in a [[stochastic matrix]].

==Katz centrality==
{{main|Katz centrality}}
'''Katz centrality'''&lt;ref&gt;Katz, L. 1953. A New Status Index Derived from Sociometric Index. Psychometrika, 39–43.&lt;/ref&gt; is a generalization of degree centrality. Degree centrality measures the number of direct neighbors, and Katz centrality measures the number of all nodes that can be connected through a path, while the contributions of distant nodes are penalized. Mathematically, it is defined as 

:&lt;math&gt;x_i = \sum_{k=1}^{\infin}\sum_{j=1}^N \alpha^k (A^k)_{ji}&lt;/math&gt; 

where &lt;math&gt;\alpha&lt;/math&gt; is an attenuation factor in  &lt;math&gt;(0,1)&lt;/math&gt;.

Katz centrality can be viewed as a variant of eigenvector centrality. Another form of Katz centrality is 

:&lt;math&gt;x_i = \alpha \sum_{j =1}^N a_{ij}(x_j+1).&lt;/math&gt; 

Compared to the expression of eigenvector centrality, &lt;math&gt;x_j&lt;/math&gt; is replaced by  &lt;math&gt;x_j+1.&lt;/math&gt;

It is shown that&lt;ref&gt;{{cite journal | last1 = Bonacich | first1 = P | year = 1991 | title = Simultaneous group and individual centralities | url = | journal = Social Networks | volume = 13 | issue = | pages = 155–168 | doi=10.1016/0378-8733(91)90018-o}}&lt;/ref&gt; the principal eigenvector (associated with the largest eigenvalue of &lt;math&gt;A&lt;/math&gt;, the adjacency matrix) is the limit of Katz centrality as &lt;math&gt;\alpha&lt;/math&gt; approaches &lt;math&gt;\tfrac{1}{\lambda}&lt;/math&gt; from below.

== PageRank centrality ==
{{main|PageRank}}'''[[PageRank]]''' satisfies the following equation

:&lt;math&gt;x_i = \alpha \sum_{j } a_{ji}\frac{x_j}{L(j)} + \frac{1-\alpha}{N},&lt;/math&gt; 

where 

:&lt;math&gt;L(j) = \sum_{i} a_{ji}&lt;/math&gt; 

is the number of neighbors of node &lt;math&gt;j&lt;/math&gt; (or number of outbound links in a directed graph). Compared to eigenvector centrality and Katz centrality, one major difference is the scaling factor &lt;math&gt;L(j)&lt;/math&gt;. Another difference between PageRank and eigenvector centrality is that the PageRank vector is a left hand eigenvector (note the factor &lt;math&gt;a_{ji}&lt;/math&gt; has indices reversed).&lt;ref&gt;[http://scenic.princeton.edu/network20q/lectures/Q3_notes.pdf How does Google rank webpages?] {{webarchive | url= https://web.archive.org/web/20120131083328/http://scenic.princeton.edu/network20q/lectures/Q3_notes.pdf |date=January 31, 2012 }} 20Q: About Networked Life&lt;/ref&gt;

==Percolation centrality==
A slew of centrality measures exist to determine the ‘importance’ of a single node in a complex network. However, these measures quantify the importance of a node in purely topological terms, and the value of the node does not depend on the ‘state’ of the node in any way. It remains constant regardless of network dynamics. This is true even for the weighted betweenness measures. However, a node may very well be centrally located in terms of betweenness centrality or another centrality measure, but may not be ‘centrally’ located in the context of a network in which there is percolation. Percolation of a ‘contagion’ occurs in complex networks in a number of scenarios. For example, viral or bacterial infection can spread over social networks of people, known as contact networks. The spread of disease can also be considered at a higher level of abstraction, by contemplating a network of towns or population centres, connected by road, rail or air links. Computer viruses can spread over computer networks. Rumours or news about business offers and deals can also spread via social networks of people. In all of these scenarios, a ‘contagion’ spreads over the links of a complex network, altering the ‘states’ of the nodes as it spreads, either recoverably or otherwise. For example, in an epidemiological scenario, individuals go from ‘susceptible’ to ‘infected’ state as the infection spreads. The states the individual nodes can take in the above examples could be binary (such as received/not received a piece of news), discrete (susceptible/infected/recovered), or even continuous (such as the proportion of infected people in a town), as the contagion spreads. The common feature in all these scenarios is that the spread of contagion results in the change of node states in networks. Percolation centrality (PC) was proposed with this in mind, which specifically measures the importance of nodes in terms of aiding the percolation through the network. This measure was proposed by Piraveenan et al.&lt;ref name="piraveenan2013"&gt;{{cite journal |last1 = Piraveenan |first1 = Mahendra | year=2013| title = Percolation Centrality: Quantifying Graph-Theoretic Impact of Nodes during Percolation in Networks | journal = PLOS ONE | volume=8 | issue=1 | doi=10.1371/journal.pone.0053095 | pages=e53095 | pmid=23349699 | pmc=3551907| bibcode=2013PLoSO...853095P }}&lt;/ref&gt;

The Percolation Centrality is defined for a given node, at a given time, as the proportion of ‘percolated paths’ that go through that node. A ‘percolated path’ is a shortest path between a pair of nodes, where the source node is percolated (e.g., infected). The target node can be percolated or non-percolated, or in a partially percolated state.

:&lt;math&gt;PC^t(v)= \frac{1}{N-2}\sum_{s \neq v \neq r}\frac{\sigma_{sr}(v)}{\sigma_{sr}}\frac{{x^t}_s}{{\sum {[{x^t}_i}]}-{x^t}_v}&lt;/math&gt;

where &lt;math&gt;\sigma_{sr}&lt;/math&gt; is total number of shortest paths from node &lt;math&gt;s&lt;/math&gt; to node &lt;math&gt;r&lt;/math&gt; and &lt;math&gt;\sigma_{sr}(v)&lt;/math&gt; is the number of those paths that pass through &lt;math&gt;v&lt;/math&gt;. The percolation state of the node &lt;math&gt;i&lt;/math&gt; at time &lt;math&gt;t&lt;/math&gt; is denoted by &lt;math&gt;{x^t}_i&lt;/math&gt; and two special cases are when &lt;math&gt;{x^t}_i=0&lt;/math&gt; which indicates a non-percolated state at time &lt;math&gt;t&lt;/math&gt; whereas when &lt;math&gt;{x^t}_i=1&lt;/math&gt; which indicates a fully percolated state at time &lt;math&gt;t&lt;/math&gt;. The values in between indicate partially percolated states ( e.g., in a network of townships, this would be the percentage of people infected in that town).

The attached weights to the percolation paths depend on the percolation levels assigned to the source nodes, based on the premise that the higher the percolation level of a source node is, the more important are the paths that originate from that node. Nodes which lie on shortest paths originating from highly percolated nodes are therefore potentially more important to the percolation. The definition of PC may also be extended to include target node weights as well. Percolation centrality calculations run in [[Big O notation|&lt;math&gt;O(NM)&lt;/math&gt;]] time with an efficient implementation adopted from Brandes' fast algorithm and if the calculation needs to consider target nodes weights, the worst case time is [[Big O notation|&lt;math&gt;O(N^3)&lt;/math&gt;]].

==Cross-clique centrality==
'''Cross-clique''' centrality of a single node, in a complex graph determines the connectivity of a node to different [[clique (graph theory)|clique]]s. A node with high cross-clique connectivity facilitates the propagation of information or disease in a graph. Cliques are subgraphs in which every node is connected to every other node in the clique. The cross-clique connectivity of a node &lt;math&gt;v&lt;/math&gt; for a given graph &lt;math&gt;G:=(V,E)&lt;/math&gt; with &lt;math&gt;|V|&lt;/math&gt; vertices and &lt;math&gt;|E|&lt;/math&gt; edges, is defined as &lt;math&gt;X(v)&lt;/math&gt; where &lt;math&gt;X(v)&lt;/math&gt; is the number of cliques to which vertex &lt;math&gt;v&lt;/math&gt; belongs.  This measure was used in &lt;ref name="xssworms"&gt;{{cite journal |last1 = Faghani|first1 = Mohamamd Reza| year=2013| title = A Study of XSS Worm Propagation and Detection Mechanisms in Online Social Networks | journal = IEEE Trans. Inf. Forensics and Security}}&lt;/ref&gt; but was first proposed by Everett and Borgatti in 1998 where they called it clique-overlap centrality.

==Freeman centralization==
The ''centralization'' of any network is a measure of how central its most central node is in relation to how central all the other nodes are.&lt;ref name="Freeman1979"&gt;{{citation| journal = Social Networks | last1 = Freeman | first1 = Linton C. | year = 1979 | volume = 1 | issue = 3 | pages = 215–239 | title = centrality in social networks: Conceptual clarification | url = http://leonidzhukov.ru/hse/2013/socialnetworks/papers/freeman79-centrality.pdf | doi=10.1016/0378-8733(78)90021-7}}&lt;/ref&gt; Centralization measures then (a) calculate the sum in differences in centrality between the most central node in a network and all other nodes; and (b) divide this quantity by the theoretically largest such sum of differences in any network of the same size.&lt;ref name="Freeman1979"/&gt;  Thus, every centrality measure can have its own centralization measure.  Defined formally, if &lt;math&gt;C_x(p_i)&lt;/math&gt; is any centrality measure of point &lt;math&gt;i&lt;/math&gt;, if &lt;math&gt;C_x(p_*)&lt;/math&gt; is the largest such measure in the network, and if:

:&lt;math&gt;\max \sum_{i=1}^{N} C_x(p_*)-C_x(p_i)&lt;/math&gt; 

is the largest sum of differences in point centrality &lt;math&gt;C_x&lt;/math&gt; for any graph with the same number of nodes, then the centralization of the network is:&lt;ref name="Freeman1979"/&gt; 

:&lt;math&gt;C_x=\frac{\sum_{i=1}^{N} C_x(p_*)-C_x(p_i)}{\max \sum_{i=1}^{N} C_x(p_*)-C_x(p_i)}.&lt;/math&gt;

== Dissimilarity based centrality measures ==
[[File:Srep17095-f1.jpg|thumbnail|In the illustrated network, green and red nodes are the most dissimilar because they do not share neighbors between them. So, the green one contributes more to the centrality of the red one than the gray ones, because the red one can access to the blue ones only through the green, and the gray nodes are redundant for the red one, because it can access directly to each gray node without any intermediary.]]
In order to obtain better results in the ranking of the nodes of a given network,  in&lt;ref&gt;{{Cite journal|title = Eigencentrality based on dissimilarity measures reveals central nodes in complex networks|url = http://www.nature.com/articles/srep17095|journal = Scientific Reports|date = 2015-11-25|pmc = 4658528|pmid = 26603652|volume = 5|doi = 10.1038/srep17095|first = A. J.|last = Alvarez-Socorro|first2 = G. C.|last2 = Herrera-Almarza|first3 = L. A.|last3 = González-Díaz|pages=17095|bibcode = 2015NatSR...517095A}}&lt;/ref&gt; are used dissimilarity measures (specific to the theory of classification and data mining) to enrich the centrality measures in complex networks. This is illustrated with the [[Eigenvector centrality]], calculating the centrality of each node through the solution of the eigenvalue problem

:&lt;math&gt;W\mathbf{c}=\lambda \mathbf{c}&lt;/math&gt;

where &lt;math&gt;W_{ij}=A_{ij}D_{ij}&lt;/math&gt; (coordinate-to-coordinate product) and &lt;math&gt;D_{ij}&lt;/math&gt; is an arbitrary [[Matrix similarity|dissimilarity]] matrix, defined through a dissimilitary measure, e.g., [[Jaccard index|Jaccard]] dissimilarity given by

:&lt;math&gt;D_{ij}=1-\dfrac{|V^{+}(i)\cap V^{+}(j)|}{|V^{+}(i)\cup V^{+}(j)|}&lt;/math&gt;

Where this measure permits us to quantify the topological contribution (which is why is called contribution centrality) of each node to the centrality of a given node, having more weight/relevance those nodes with greater dissimilarity, since these allow to the given node access to nodes that which themselves can not access directly.

Is noteworthy that &lt;math&gt;W&lt;/math&gt; is non-negative because &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;D&lt;/math&gt; are non-negative matrices, so we can use the [[Perron–Frobenius theorem]] to ensure that the above problem has a unique solution for ''λ'' = ''λ&lt;sub&gt;max&lt;/sub&gt;'' with '''c''' non-negative, allowing us to infer the centrality of each node in the network. Therefore, the centrality of the i-th node is

:&lt;math&gt;c_i=\dfrac{1}{n}\sum_{j=1}^{n}W_{ij}c_{j}, \,\,\,\,\,\, j=1,\cdots,n&lt;/math&gt;

where &lt;math&gt;n&lt;/math&gt; is the number of the nodes in the network. Several dissimilarity measures and networks where tested in &lt;ref&gt;{{Cite web|url = http://www.nature.com/article-assets/npg/srep/2015/151125/srep17095/extref/srep17095-s1.pdf|title = Supplementary Information for Eigencentrality based on dissimilarity measures reveals central nodes in complex networks|date = |website = |publisher = Nature Publishing Group|last = Alvarez-Socorro|first = A.J.|last2 = Herrera-Almarza|first3 = L. A.|last3 = González-Díaz}}&lt;/ref&gt; obtaining improved results in the studied cases.

==Extensions==
Empirical and theoretical research have extended the concept of centrality in the context of static networks to dynamic centrality&lt;ref&gt;{{cite journal | last1 = Braha | first1 = D. | last2 = Bar-Yam | first2 = Y. | year = 2006 | title = From Centrality to Temporary Fame: Dynamic Centrality in Complex Networks | url = | journal = Complexity | volume = 12 | issue = | pages = 59–63 | doi=10.1002/cplx.20156| arxiv = physics/0611295 | bibcode = 2006Cmplx..12b..59B }}&lt;/ref&gt; in the context of time-dependent and temporal networks.&lt;ref&gt;{{cite journal | last1 = Hill | first1 = S.A. | last2 = Braha | first2 = D. | year = 2010 | title = Dynamic Model of Time-Dependent Complex Networks | url = | journal = Physical Review E | volume = 82 | issue = | page = 046105 | doi=10.1103/physreve.82.046105| arxiv = 0901.4407 | bibcode = 2010PhRvE..82d6105H }}&lt;/ref&gt;&lt;ref&gt;Gross, T. and Sayama, H. (Eds.). 2009. ''Adaptive Networks: Theory, Models and Applications.'' Springer.&lt;/ref&gt;&lt;ref&gt;Holme, P. and Saramäki, J. 2013. ''Temporal Networks.'' Springer.&lt;/ref&gt;

For generalizations to weighted networks, see Opsahl et al. (2010).&lt;ref&gt;{{cite journal | last1 = Opsahl | first1 = Tore | last2 = Agneessens | first2 = Filip | last3 = Skvoretz | first3 = John | title = Node centrality in weighted networks: Generalizing degree and shortest paths | doi = 10.1016/j.socnet.2010.03.006 | year = 2010 | pages = 245–251 | volume = 32 | journal = Social Networks | url=http://toreopsahl.com/2010/04/21/article-node-centrality-in-weighted-networks-generalizing-degree-and-shortest-paths/ | issue = 3 }}&lt;/ref&gt;

The concept of centrality was extended to a group level as well. For example, '''group betweenness''' centrality shows the proportion of geodesics connecting pairs of non-group members that pass through the group.&lt;ref name="group1"&gt;Everett, M. G. and Borgatti, S. P. (2005). Extending centrality. In P. J. Carrington, J. Scott and S. Wasserman (Eds.), ''Models and methods in social network analysis'' (pp. 57–76). New York: Cambridge University Press.&lt;/ref&gt;&lt;ref name="group2"&gt;Puzis, R., Yagil, D., Elovici, Y., Braha, D. (2009).[http://necsi.edu/affiliates/braha/Internet_Research_Anonimity.pdf Collaborative attack on Internet users’ anonymity], ''Internet Research'' '''19'''(1)&lt;/ref&gt;

==See also==
* [[Alpha centrality]]
* [[Core-Periphery Structures in Networks]]
* [[Distance (graph theory)|Distance in graphs]]

==Notes and references==
{{Reflist}}

==Further reading==
* Koschützki, D.; Lehmann, K. A.; Peeters, L.; Richter, S.; Tenfelde-Podehl, D. and Zlotowski, O. (2005) Centrality Indices. In Brandes, U. and Erlebach, T. (Eds.)  ''Network Analysis: Methodological Foundations'', pp.&amp;nbsp;16–61, LNCS 3418, Springer-Verlag.

[[Category:Graph theory]]
[[Category:Graph algorithms]]
[[Category:Algebraic graph theory]]
[[Category:Networks]]
[[Category:Network analysis]]
[[Category:Network theory]]</text>
      <sha1>bq5uki8rkfuzd8pc6vqnj8ob1cn4w75</sha1>
    </revision>
  </page>
  <page>
    <title>Chetaev instability theorem</title>
    <ns>0</ns>
    <id>4184621</id>
    <revision>
      <id>788951922</id>
      <parentid>788948678</parentid>
      <timestamp>2017-07-04T13:16:27Z</timestamp>
      <contributor>
        <username>Nowak Kowalski</username>
        <id>18891628</id>
      </contributor>
      <comment>[[Category:Stability theory]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1390">{{orphan|date=October 2011}}

The '''Chetaev instability theorem''' for [[dynamical system]]s states that if there exists, for the system &lt;math&gt;\dot{\textbf{x}} = X(\textbf{x})&lt;/math&gt; with an [[equilibrium point]] at the origin, a continuously differentiable function V('''x''') such that
# the origin is a [[Boundary (topology)|boundary point]] of the set &lt;math&gt;G = \{\mathbf{x} \mid V(\mathbf{x})&gt;0\}&lt;/math&gt;;
# there exists a [[neighbourhood (mathematics)|neighborhood]] &lt;math&gt;U&lt;/math&gt; of the origin such that &lt;math&gt;\dot{V}(\textbf{x})&gt;0&lt;/math&gt; for all &lt;math&gt;\mathbf{x} \in G \cap U&lt;/math&gt; 

then the origin is an unstable equilibrium point of the system.

This theorem is somewhat less restrictive than the [[Lyapunov instability theorem]]s, since a complete sphere (circle) around the origin for which V and &lt;math&gt;\dot{V}&lt;/math&gt; both are of the same sign does not have to be produced.

It is named after [[Nicolai Gurevich Chetaev]].
==See also==
* [[Lyapunov function]] — a function whose existence guarantees stability
==References==
*{{SpringerEOM|title=Chetaev theorems|id=Chetaev_theorems&amp;oldid=12645|first=V. V.|last=Rumyantsev}}

==Further reading==
* [http://www.scholarpedia.org/article/Chetaev_function Chetaev function] Emmanuil E. Shnol [[Scholarpedia]] 2(9):4672.  [[doi:10.4249/scholarpedia.4672]]
[[Category:Theorems in dynamical systems]]
[[Category:Stability theory]]</text>
      <sha1>l1w98w5v4fuinpfymp5wf7fqk2juxml</sha1>
    </revision>
  </page>
  <page>
    <title>Continued fraction</title>
    <ns>0</ns>
    <id>46802</id>
    <revision>
      <id>869410688</id>
      <parentid>867844486</parentid>
      <timestamp>2018-11-18T12:23:59Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>/* History */ fixing misspelling</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="57850">{{redirect-distinguish|Recurring fraction|Repeating decimal}}
{{thumb|width=220
|content=&lt;math&gt;a_0 + \cfrac{1}{a_1 + \cfrac{1}{a_2 + \cfrac{1}{ \ddots + \cfrac{1}{a_n} }}}&lt;/math&gt;
|caption=A finite continued fraction, where &lt;math&gt;n&lt;/math&gt; is a non-negative integer, &lt;math&gt;a_0&lt;/math&gt; is an integer, and &lt;math&gt;a_i&lt;/math&gt; is a positive integer, for &lt;math&gt;i=1,\ldots,n&lt;/math&gt;.
}}

In [[mathematics]], a '''continued fraction''' is an [[expression (mathematics)|expression]] obtained through an [[iterative]] process of representing a number as the sum of its [[integer part]] and the [[multiplicative inverse|reciprocal]] of another number, then writing this other number as the sum of its integer part and another reciprocal, and so on.&lt;ref&gt;{{cite web|url=http://www.britannica.com/EBchecked/topic/135043/continued-fraction|title=Continued fraction - mathematics|publisher=}}&lt;/ref&gt; In a '''finite continued fraction''' (or '''terminated continued fraction'''), the iteration/[[recursion]] is terminated after finitely many steps by using an integer in lieu of another continued fraction. In contrast, an '''infinite continued fraction''' is an [[infinite expression (mathematics)|infinite expression]]. In either case, all integers in the sequence, other than the first, must be [[positive number|positive]]. The integers &lt;math&gt;a_i&lt;/math&gt; are called the [[coefficient]]s or [[term (mathematics)|terms]] of the continued fraction.&lt;ref name="Pettofrezzo 1970 150"&gt;{{harvtxt|Pettofrezzo|Byrkit|1970|p=150}}&lt;/ref&gt;

Continued fractions have a number of remarkable properties related to the [[Euclidean algorithm]] for integers or [[real number]]s. Every [[rational number]] {{sfrac|&lt;math&gt;p&lt;/math&gt;|&lt;math&gt;q&lt;/math&gt;}} has two closely related expressions as a finite continued fraction, whose coefficients {{mvar|a&lt;sub&gt;i&lt;/sub&gt;}} can be determined by applying the Euclidean algorithm to &lt;math&gt;(p,q)&lt;/math&gt;. The numerical value of an infinite continued fraction is [[irrational number|irrational]]; it is defined from its infinite sequence of integers as the [[limit (mathematics)|limit]] of a sequence of values for finite continued fractions. Each finite continued fraction of the sequence is obtained by using a finite [[Prefix (computer science)|prefix]] of the infinite continued fraction's defining sequence of integers. Moreover, every irrational number &lt;math&gt;\alpha&lt;/math&gt; is the value of a ''unique'' infinite continued fraction, whose coefficients can be found using the non-terminating version of the Euclidean algorithm applied to the [[Commensurability (mathematics)|incommensurable]] values &lt;math&gt;\alpha&lt;/math&gt; and 1. This way of expressing real numbers (rational and irrational) is called their ''continued fraction representation''.

It is generally assumed that the [[numerator]] of all of the fractions is 1. If arbitrary values and/or [[function (mathematics)|functions]] are used in place of one or more of the numerators or the integers in the denominators, the resulting expression is a '''[[generalized continued fraction]]'''. When it is necessary to distinguish the first form from generalized continued fractions, the former may be called a '''simple''' or '''regular continued fraction''', or said to be in '''canonical form'''.

The term ''continued fraction'' may also refer to representations of [[rational function]]s, arising in their [[analytic function|analytic theory]]. For this use of the term, see [[Padé approximation]] and [[Chebyshev rational functions]].

==Motivation and notation==
Consider, for example, the [[rational number]] {{sfrac|415|93}}, which is around 4.4624. As a first [[approximation]], start with 4, which is the [[Floor and ceiling functions|integer part]]; {{nowrap|1={{sfrac|415|93}} = 4 + {{sfrac|43|93}}}}. Note that the fractional part is the [[Multiplicative inverse|reciprocal]] of {{sfrac|93|43}} which is about 2.1628. Use the integer part, 2, as an approximation for the reciprocal to obtain a second approximation of {{nowrap |1=4 + {{sfrac|1|2}} = 4.5; {{sfrac|93|43}} = 2 + {{sfrac|7|43}}}}.
The remaining fractional part, {{sfrac|7|43}}, is the reciprocal of {{sfrac|43|7}}, and {{sfrac|43|7}} is around 6.1429. Use 6 as an approximation for this to obtain {{nowrap|2 + {{sfrac|1|6}}}} as an approximation for {{sfrac|93|43}} and {{nowrap|4 + {{sfrac|1|2 + {{sfrac|1|6}}}}}}, about 4.4615, as the third approximation; {{nowrap|1={{sfrac|43|7}} = 6 + {{sfrac|1|7}}}}. Finally, the fractional part, {{sfrac|1|7}}, is the reciprocal of 7, so its approximation in this scheme, 7, is exact ({{nowrap|1={{sfrac|7|1}} = 7 + {{sfrac|0|1}}}}) and produces the exact expression {{nowrap|4 + {{sfrac|1|2 + {{sfrac|1|6 + {{sfrac|1|7}}}}}}}} for {{sfrac|415|93}}.

The expression {{nowrap|4 + {{sfrac|1|2 + {{sfrac|1|6 + {{sfrac|1|7}}}}}}}} is called the continued fraction representation of {{sfrac|415|93}}. This can be represented by the abbreviated notation {{sfrac|415|93}} = [4; 2, 6, 7]. (Note that it is customary to replace only the ''first'' comma by a semicolon.) Some older textbooks use all commas in the {{math|(''n'' + 1)}}-tuple, for example, [4, 2, 6, 7].&lt;ref name="Long 1972 173"&gt;{{harvtxt|Long|1972|p=173}}&lt;/ref&gt;&lt;ref name="Pettofrezzo 1970 152"&gt;{{harvtxt|Pettofrezzo|Byrkit|1970|p=152}}&lt;/ref&gt;

If the starting number is rational, then this process exactly parallels the [[Euclidean algorithm]]. In particular, it must terminate and produce a finite continued fraction representation of the number. If the starting number is [[Irrational number|irrational]], then the process continues indefinitely. This produces a sequence of approximations, all of which are rational numbers, and these converge to the starting number as a limit. This is the (infinite) continued fraction representation of the number. Examples of continued fraction representations of irrational numbers are:
* {{math|1={{sqrt|19}} = [4;2,1,3,1,2,8,2,1,3,1,2,8,…]}} {{OEIS|A010124}}. The pattern repeats indefinitely with a period of 6.
* {{math|1=[[e (mathematical constant)|''e'']] = [2;1,2,1,1,4,1,1,6,1,1,8,…]}} {{OEIS|A003417}}. The pattern repeats indefinitely with a period of 3 except that 2 is added to one of the terms in each cycle.
* {{math|1=[[Pi|π]] = [3;7,15,1,292,1,1,1,2,1,3,1,…]}} {{OEIS|A001203}}. The terms in this representation are apparently random.
* {{math|1=[[golden ratio|ϕ]] = [1;1,1,1,1,1,1,1,1,1,1,1,…]}} {{OEIS|A000012}}. The [[golden ratio]], the most difficult irrational number to approximate rationally. See: [[#A property of the golden ratio φ|A property of the golden ratio φ]].

Continued fractions are, in some ways, more "mathematically natural" representations of a [[real number]] than other representations such as [[decimal representation]]s, and they have several desirable properties:
* The continued fraction representation for a rational number is finite and only rational numbers have finite representations. In contrast, the decimal representation of a rational number may be finite, for example {{nowrap|1={{sfrac|137|1600}} = 0.085625}}, or infinite with a repeating cycle, for example {{nowrap|1={{sfrac|4|27}} = 0.148148148148…}}
* Every rational number has an essentially unique continued fraction representation. Each rational can be represented in exactly two ways, since {{math|1=[''a''&lt;sub&gt;0&lt;/sub&gt;;''a''&lt;sub&gt;1&lt;/sub&gt;,… ''a''&lt;sub&gt;''n''−1&lt;/sub&gt;,''a''&lt;sub&gt;''n''&lt;/sub&gt;] = [''a''&lt;sub&gt;0&lt;/sub&gt;;''a''&lt;sub&gt;1&lt;/sub&gt;,… ''a''&lt;sub&gt;''n''−1&lt;/sub&gt;,(''a''&lt;sub&gt;''n''&lt;/sub&gt;−1),1]}}. Usually the first, shorter one is chosen as the [[canonical form|canonical representation]].
* The continued fraction representation of an irrational number is unique.
* The real numbers whose continued fraction eventually repeats are precisely the [[quadratic irrational]]s.&lt;ref&gt;{{MathWorld|title=Periodic Continued Fraction|urlname=PeriodicContinuedFraction}}&lt;/ref&gt; For example, the repeating continued fraction {{nowrap|[1;1,1,1,…]}} is the [[golden ratio]], and the repeating continued fraction {{nowrap|[1;2,2,2,…]}} is the [[square root of 2]]. In contrast, the decimal representations of quadratic irrationals are apparently [[normal number|random]]. The square roots of all (positive) integers, that are not perfect squares, are quadratic irrationals, hence are unique periodic continued fractions.
* The successive approximations generated in finding the continued fraction representation of a number, that is, by truncating the continued fraction representation, are in a certain sense (described below) the "best possible".

== Basic formula ==
A continued fraction is an expression of the form

:&lt;math&gt;a_0 + \cfrac{b_1}{a_1 + \cfrac{b_2}{a_2 + \cfrac{b_3}{a_3 + {_\ddots}}}}&lt;/math&gt;

where a&lt;sub&gt;i&lt;/sub&gt; and b&lt;sub&gt;i&lt;/sub&gt; are either rational numbers, real numbers, or complex numbers.
If b&lt;sub&gt;i&lt;/sub&gt; = 1 for all ''i'' the expression is called a ''simple'' continued fraction.
If the expression contains a finite number of terms, it is called a ''finite'' continued fraction.
If the expression contains an infinite number of terms, it is called an ''infinite'' continued fraction.&lt;ref&gt;{{cite journal |first=Darren C. |last=Collins |title=Continued Fractions |journal=MIT Undergraduate Journal of Mathematics |url=http://www-math.mit.edu/phase2/UJM/vol1/COLLIN~1.PDF |archive-url=https://web.archive.org/web/20011120064343/http://www-math.mit.edu/phase2/UJM/vol1/COLLIN~1.PDF |dead-url=yes |archive-date=2001-11-20 |df= }}&lt;/ref&gt;

Thus, all of the following illustrate valid finite simple continued fractions:

{| class="wikitable"
|+Examples of finite simple continued fractions
!Formula
!Numeric
!Remarks
|-
|&lt;math&gt;\ a_0&lt;/math&gt;
|&lt;math&gt;\ 2&lt;/math&gt;
|All integers are a [[degenerate case]]
|-
|&lt;math&gt;\ a_0 + \cfrac{1}{a_1}&lt;/math&gt;
|&lt;math&gt;\ 2 + \cfrac{1}{3}&lt;/math&gt;
|Simplest possible fractional form
|-
|&lt;math&gt;\ a_0 + \cfrac{1}{a_1 + \cfrac{1}{a_2}}&lt;/math&gt;
|&lt;math&gt;\ -3 + \cfrac{1}{2 + \cfrac{1}{18}}&lt;/math&gt;
|First integer may be negative
|-
|&lt;math&gt;\ a_0 + \cfrac{1}{a_1 + \cfrac{1}{a_2 + \cfrac{1}{a_3}}}&lt;/math&gt;
|&lt;math&gt;\ \cfrac{1}{15 + \cfrac{1}{1 + \cfrac{1}{102}}}&lt;/math&gt;
|First integer may be zero
|}

==Calculating continued fraction representations==
Consider a real number {{mvar|r}}.
Let &lt;math&gt;i=\lfloor r \rfloor &lt;/math&gt; be the [[integer part]] of {{mvar|r}} and let
&lt;math&gt;f = r - i&lt;/math&gt; be the [[fractional part]] of {{mvar|r}}.
Then the continued fraction representation of {{mvar|r}} is
&lt;math&gt;[i;a_1,a_2,\ldots]&lt;/math&gt;, where &lt;math&gt;[a_1;a_2,\ldots]&lt;/math&gt; is the continued fraction representation of &lt;math&gt;1/f&lt;/math&gt;.

To calculate a continued fraction representation of a number {{mvar|r}}, write down the integer part (technically the [[Floor function|floor]]) of {{mvar|r}}. Subtract this integer part from {{mvar|r}}. If the difference is 0, stop; otherwise find the [[multiplicative inverse|reciprocal]] of the difference and repeat. The procedure will halt if and only if {{mvar|r}} is rational. This process can be efficiently implemented using the [[Euclidean algorithm]] when the number is rational.  The table below shows an implementation of this procedure for the number 3.245, resulting in the continued fraction expansion [3; 4,12,4].

:{| class="wikitable"
|-
|+ Find the continued fraction for &lt;math&gt;3.245 = \frac{649}{200} &lt;/math&gt;
|-
!Step
!Real&lt;br/&gt;Number
!Integer&lt;br/&gt;part
!Fractional&lt;br/&gt;part
!Simplified
!Reciprocal&lt;br/&gt;of {{mvar|f}}
|-
!1
|&lt;math&gt;r = \frac{649}{200}&lt;/math&gt;
|&lt;math&gt;i = 3&lt;/math&gt;
|&lt;math&gt;f = \frac{649}{200} - 3 &lt;/math&gt;
|&lt;math&gt;= \frac{49}{200}&lt;/math&gt;
|&lt;math&gt;\frac{1}{f} = \frac{200}{49} &lt;/math&gt;
|-
!2
|&lt;math&gt;r = \frac{200}{49} &lt;/math&gt;
|&lt;math&gt;i = 4&lt;/math&gt;
|&lt;math&gt;f = \frac{200}{49} - 4 &lt;/math&gt;
|&lt;math&gt; = \frac{4}{49} &lt;/math&gt;
|&lt;math&gt; \frac{1}{f} = \frac{49}{4} &lt;/math&gt;
|-
!3
|&lt;math&gt;r = \frac{49}{4} &lt;/math&gt;
|&lt;math&gt;i = 12&lt;/math&gt;
|&lt;math&gt;f = \frac{49}{4} - 12 &lt;/math&gt;
|&lt;math&gt;= \frac{1}{4} &lt;/math&gt;
|&lt;math&gt;\frac{1}{f} = \frac{4}{1} &lt;/math&gt;
|-
!4
|&lt;math&gt;r = 4&lt;/math&gt;
|&lt;math&gt;i = 4 &lt;/math&gt;
|&lt;math&gt;f = 4 - 4 &lt;/math&gt;
|&lt;math&gt;= 0 &lt;/math&gt;
|colspan="2"|{{stop}} '''STOP'''
|-
| colspan="7" style="text-align:right;" | Continued fraction form for &lt;math&gt; 3.245 = \frac{649}{200} = [3; 4, 12, 4]&lt;/math&gt;
= {{math|3 + {{sfrac|1|4 + {{sfrac|1|12 + {{sfrac|1|4}}}}}}}}
|}

==Notations==
The integers &lt;math&gt;a_0&lt;/math&gt;, &lt;math&gt;a_1&lt;/math&gt; etc., are called the ''coefficients'' or ''terms'' of the continued fraction.&lt;ref name="Pettofrezzo 1970 150"/&gt; One can abbreviate the continued fraction

:&lt;math&gt;x = a_0 + \cfrac{1}{a_1 + \cfrac{1}{a_2 + \cfrac{1}{a_3}}}&lt;/math&gt;

in the notation of [[Carl Friedrich Gauss]]
:&lt;math&gt;x = a_0 + \underset{i=1}{\overset{3}{\mathrm K}} ~ \frac{1}{a_i} &lt;/math&gt;

or as

:&lt;math&gt;x = [a_0; a_1, a_2, a_3] &lt;/math&gt;,

or in the notation of [[Alfred Pringsheim|Pringsheim]] as

:&lt;math&gt;x = a_0 + \frac{1 \mid}{\mid a_1} + \frac{1 \mid}{\mid a_2} + \frac{1 \mid}{\mid a_3},&lt;/math&gt;

or in another related notation as

:&lt;math&gt;x = a_0 + {1 \over a_1 + {}} {1 \over a_2 + {}} {1 \over a_3 {}}.&lt;/math&gt;

Sometimes angle brackets are used, like this:

:&lt;math&gt;x = \left \langle a_0; a_1, a_2, a_3 \right \rangle.&lt;/math&gt;

The semicolon in the square and angle bracket notations is sometimes replaced by a comma.&lt;ref name="Long 1972 173"/&gt;&lt;ref name="Pettofrezzo 1970 152"/&gt;

One may also define ''infinite simple continued fractions'' as [[limit of a sequence|limits]]:

:&lt;math&gt;[a_0; a_1, a_2, a_3, \,\ldots ] = \lim_{n \to \infty} [a_0; a_1, a_2, \,\ldots, a_n]. &lt;/math&gt;

This limit exists for any choice of &lt;math&gt;a_0&lt;/math&gt; and positive integers &lt;math&gt;a_1,a_2,\ldots &lt;/math&gt;&lt;ref name="Long 1972 183"&gt;{{harvtxt|Long|1972|p=183}}&lt;/ref&gt;&lt;ref name="Pettofrezzo 1970 158"&gt;{{harvtxt|Pettofrezzo|Byrkit|1970|p=158}}&lt;/ref&gt;

==Finite continued fractions==&lt;!-- This section is linked from [[Continued fraction]] --&gt;
Every finite continued fraction represents a [[rational number]], and every rational number can be represented in precisely two different ways as a finite continued fraction, with the conditions that the first coefficient is an integer and other coefficients being positive integers. These two representations agree except in their final terms. In the longer representation the final term in the continued fraction is 1; the shorter representation drops the final 1, but increases the new final term by 1. The final element in the short representation is therefore always greater than 1, if present. In symbols:

:{{math|[''a''{{sub|0}}; ''a''{{sub|1}}, ''a''{{sub|2}}, &amp;hellip;, ''a''{{sub|''n'' − 1}}, ''a''{{sub|''n''}}, 1] {{=}} [''a''{{sub|0}}; ''a''{{sub|1}}, ''a''{{sub|2}}, &amp;hellip;, ''a''{{sub|''n'' − 1}}, ''a''{{sub|''n''}} + 1]}}.
:{{math|[''a''{{sub|0}}; 1] {{=}} [''a''{{sub|0}} + 1]}}.

==Of reciprocals==
The continued fraction representations of a positive rational number and its [[multiplicative inverse|reciprocal]] are identical except for a shift one place left or right depending on whether the number is less than or greater than one respectively. In other words, the numbers represented by
&lt;math&gt;[a_0;a_1,a_2,\ldots,a_n]&lt;/math&gt; and &lt;math&gt;[0;a_0,a_1,\ldots,a_n]&lt;/math&gt; are reciprocals. For instance if &lt;math&gt;a&lt;/math&gt; is an integer and &lt;math&gt;x &lt; 1&lt;/math&gt; then

:&lt;math&gt;x=0 + \frac{1}{a + \frac{1}{b}}&lt;/math&gt; and &lt;math&gt;\frac{1}{x} = a + \frac{1}{b}&lt;/math&gt;.
If &lt;math&gt;x&gt;1&lt;/math&gt; then
:&lt;math&gt;x = a + \frac{1}{b}&lt;/math&gt; and &lt;math&gt;\frac{1}{x} = 0 + \frac{1}{a + \frac{1}{b}}&lt;/math&gt;.

The last number that generates the remainder of the continued fraction is the same for both &lt;math&gt;x&lt;/math&gt; and its reciprocal.

For example,
:&lt;math&gt;2.25 = \frac{9}{4} = [2;4]&lt;/math&gt; and &lt;math&gt;\frac{1}{2.25} = \frac{4}{9} = [0;2,4]&lt;/math&gt;.

==Infinite continued fractions and convergents==&lt;!-- [[Convergent (continued fraction)]] links here.  Please do not change. --&gt;
Every infinite continued fraction is [[irrational number|irrational]], and every irrational number can be represented in precisely one way as an infinite continued fraction.

An infinite continued fraction representation for an irrational number is useful because its initial segments provide rational approximations to the number. These rational numbers are called the '''convergents''' of the continued fraction.&lt;ref&gt;{{harvtxt|Long|1972|p=177}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Pettofrezzo|Byrkit|1970|pp=162–163}}&lt;/ref&gt; The larger a term is in the continued fraction, the closer the corresponding convergent is to the irrational number being approximated. Numbers like π have occasional large terms in their continued fraction, which makes them easy to approximate with rational numbers. Other numbers like ''e'' have only small terms early in their continued fraction, which makes them more difficult to approximate rationally. The [[golden ratio]] ϕ has terms equal to 1 everywhere—the smallest values possible—which makes ϕ the most difficult number to approximate rationally. In this sense, therefore, it is the "most irrational" of all irrational numbers. Even-numbered convergents are smaller than the original number, while odd-numbered ones are larger.

For a continued fraction {{math|[''a''{{sub|0}}; ''a''{{sub|1}}, ''a''{{sub|2}}, &amp;hellip;]}}, the first four convergents (numbered 0 through 3) are

:{{bigmath|{{sfrac|''a''{{sub|0}}|1}}, {{sfrac|''a''{{sub|1}}''a''{{sub|0}} + 1|''a''{{sub|1}}}}, {{sfrac|''a''{{sub|2}}(''a''{{sub|1}}''a''{{sub|0}} + 1) + ''a''{{sub|0}}|''a''{{sub|2}}''a''{{sub|1}} + 1}}, {{sfrac|''a''{{sub|3}}(''a''{{sub|2}}(''a''{{sub|1}}''a''{{sub|0}} + 1) + ''a''{{sub|0}}) + (''a''{{sub|1}}''a''{{sub|0}} + 1) | ''a''{{sub|3}}(''a''{{sub|2}}''a''{{sub|1}} + 1) + ''a''{{sub|1}}}}}}

In words, the numerator of the third convergent is formed by multiplying the numerator of the second convergent by the third quotient, and adding the numerator of the first convergent. The denominators are formed similarly. Therefore, each convergent can be expressed explicitly in terms of the continued fraction as the ratio of certain [[multivariate polynomial]]s called ''[[Continuant (mathematics)|continuants]]''.

If successive convergents are found, with numerators {{mvar|h}}{{sub|1}}, {{mvar|h}}{{sub|2}}, &amp;hellip; and denominators {{mvar|k}}{{sub|1}}, {{mvar|k}}{{sub|2}}, &amp;hellip; then the relevant recursive relation is:

:{{math|''h''{{sub|''n''}} {{=}} ''a''{{sub|''n''}}''h''{{sub|''n'' − 1}} + ''h''{{sub|''n'' − 2}}}},
:{{math|''k''{{sub|''n''}} {{=}} ''a''{{sub|''n''}}''k''{{sub|''n'' − 1}} + ''k''{{sub|''n'' − 2}}}}.

The successive convergents are given by the formula

:{{bigmath|{{sfrac|''h''{{sub|''n''}}|''k''{{sub|''n''}}}} {{=}} {{sfrac|''a''{{sub|''n''}}''h''{{sub|''n'' − 1}} + ''h''{{sub|''n'' − 2}}|''a''{{sub|''n''}}''k''{{sub|''n'' − 1}} + ''k''{{sub|''n'' − 2}}}}}}

Thus to incorporate a new term into a rational approximation, only the two previous convergents are necessary. The initial "convergents" (required for the first two terms) are &lt;sup&gt;0&lt;/sup&gt;⁄&lt;sub&gt;1&lt;/sub&gt; and &lt;sup&gt;1&lt;/sup&gt;⁄&lt;sub&gt;0&lt;/sub&gt;. For example, here are the convergents for [0;1,5,2,2].

:{| class="wikitable"
|- align="right"
! {{mvar|n}}
| −2|| −1|| 0 || 1 || 2 || 3 || 4
|- align="right"
! {{math|''a''{{sub|''n''}}}}
| &amp;nbsp; || &amp;nbsp; || 0 || 1 || 5 || 2 || 2
|- align="right"
! {{math|''h''{{sub|''n''}}}}
| 0 || 1 || 0 || 1 || 5 || 11 || 27
|- align="right"
! {{math|''k''{{sub|''n''}}}}
| 1 || 0 || 1 || 1 || 6 || 13 || 32
|}

When using the [[Methods of computing square roots#Babylonian method|Babylonian method]] to generate successive approximations to the square root of an integer, if one starts with the lowest integer as first approximant, the rationals generated all appear in the list of convergents for the continued fraction. Specifically, the approximants will appear on the convergents list in positions 0, 1, 3, 7, 15, … , {{math|2&lt;sup&gt;''k''&lt;/sup&gt;−1}}, ... For example, the continued fraction expansion for [[square root of 3|{{sqrt|3}}]] is [1;1,2,1,2,1,2,1,2,…]. Comparing the convergents with the approximants derived from the Babylonian method:

:{| class="wikitable"
|- align="right"
! {{mvar|n}}
| −2|| −1|| '''0''' || '''1''' || 2 || '''3''' || 4 || 5 || 6 || '''7'''
|- align="right"
! {{math|''a''{{sub|''n''}}}}
| &amp;nbsp; || &amp;nbsp; || 1 || 1 || 2 || 1 || 2 || 1 || 2 || 1
|- align="right"
! {{math|''h''{{sub|''n''}}}}
| 0 || 1 || '''1''' || '''2''' || 5 || '''7''' || 19 || 26 || 71 || '''97'''
|- align="right"
! {{math|''k''{{sub|''n''}}}}
| 1 || 0 || '''1''' || '''1''' || 3 || '''4''' || 11 || 15 || 41 || '''56'''
|}

:{{math|''x''{{sub|0}} {{=}} 1 {{=}} {{sfrac|1|1}}}}
:{{math|''x''{{sub|1}} {{=}} {{sfrac|1|2}}(1 + {{sfrac|3|1}}) {{=}} {{sfrac|2|1}} {{=}} 2}}
:{{math|''x''{{sub|2}} {{=}} {{sfrac|1|2}}(2 + {{sfrac|3|2}}) {{=}} {{sfrac|7|4}}}}
:{{math|''x''{{sub|3}} {{=}} {{sfrac|1|2}}({{sfrac|7|4}} + {{sfrac|3|{{sfrac|7|4}}}}) {{=}} {{sfrac|97|56}}}}

===Properties===
[[Baire space (set theory)|Baire space]] is a topological space on infinite sequences of natural numbers. The infinite continued fraction provides a [[homeomorphism]] from Baire space to the space of irrational real numbers (with the subspace topology inherited from the [[Euclidean topology|usual topology]] on the reals). The infinite continued fraction also provides a map between the [[quadratic irrational]]s and the [[dyadic rational]]s, and from other irrationals to the set of infinite strings of binary numbers (i.e. the [[Cantor set]]); this map is called the [[Minkowski question mark]] function. The mapping has interesting self-similar [[fractal]] properties; these are given by the [[modular group]], which is the subgroup of [[Möbius transformation]]s having integer values in the transform. Roughly speaking, continued fraction convergents can be taken to be Möbius transformations acting on the (hyperbolic) [[upper half-plane]]; this is what leads to the fractal self-symmetry.

===Some useful theorems===
If &lt;math&gt;a_0&lt;/math&gt;, &lt;math&gt;a_1&lt;/math&gt;, &lt;math&gt;a_2&lt;/math&gt;, &lt;math&gt;\ldots&lt;/math&gt; is an infinite sequence of positive integers, define the sequences &lt;math&gt;h_n&lt;/math&gt; and &lt;math&gt;k_n&lt;/math&gt; recursively:
{| border="0" cellpadding="5" cellspacing="10" align="none"
|-
|&lt;math&gt;h_{n}=a_nh_{n-1}+h_{n-2}&lt;/math&gt;
|
|
|&lt;math&gt;h_{-1}=1&lt;/math&gt;
|
|&lt;math&gt;h_{-2}=0&lt;/math&gt;
|-
|&lt;math&gt;k_{n}=a_nk_{n-1}+k_{n-2}&lt;/math&gt;
|
|
|&lt;math&gt;k_{-1}=0&lt;/math&gt;
|
|&lt;math&gt;k_{-2}=1&lt;/math&gt;
|}

&lt;blockquote&gt;'''Theorem 1.''' For any positive real number &lt;math&gt;z&lt;/math&gt;

:&lt;math&gt; \left[a_0; a_1, \,\dots, a_{n-1}, z \right]=\frac{z h_{n-1}+h_{n-2}}{z k_{n-1}+k_{n-2}}.&lt;/math&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;'''Theorem 2.''' The convergents of [&lt;math&gt;a_0&lt;/math&gt;; &lt;math&gt;a_1&lt;/math&gt;, &lt;math&gt;a_2&lt;/math&gt;, &lt;math&gt;\ldots&lt;/math&gt;] are given by

:&lt;math&gt;\left[a_0; a_1, \,\dots, a_n\right]=\frac{h_n}{k_n}.&lt;/math&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;'''Theorem 3.''' If the &lt;math&gt;n&lt;/math&gt;th convergent to a continued fraction is &lt;math&gt;h_n&lt;/math&gt;/&lt;math&gt;k_n&lt;/math&gt;, then

:&lt;math&gt;k_nh_{n-1}-k_{n-1}h_n=(-1)^n.&lt;/math&gt;
&lt;/blockquote&gt;

'''Corollary 1:''' Each convergent is in its lowest terms (for if &lt;math&gt;h_n&lt;/math&gt; and &lt;math&gt;k_n&lt;/math&gt; had a nontrivial common divisor it would divide &lt;math&gt;k_n h_{n-1} - k_{n-1} h_n&lt;/math&gt;, which is impossible).

'''Corollary 2:''' The difference between successive convergents is a fraction whose numerator is unity:

:&lt;math&gt;\frac{h_n}{k_n}-\frac{h_{n-1}}{k_{n-1}} = \frac{h_nk_{n-1}-k_nh_{n-1}}{k_nk_{n-1}}= \frac{(-1)^{n+1}}{k_nk_{n-1}}.&lt;/math&gt;

'''Corollary 3:''' The continued fraction is equivalent to a series of alternating terms:

:&lt;math&gt;a_0 + \sum_{n=0}^\infty \frac{(-1)^{n}}{k_{n}k_{n+1}}.&lt;/math&gt;

'''Corollary 4:''' The matrix
:&lt;math&gt;\begin{bmatrix}
h_n &amp; h_{n-1} \\
k_n &amp; k_{n-1}
\end{bmatrix}&lt;/math&gt;
has [[determinant]] plus or minus one, and thus belongs to the group of
&lt;math&gt;2\times 2 &lt;/math&gt; [[unimodular matrix|unimodular matrices]] &lt;math&gt;\mathrm{GL}(2,Z)&lt;/math&gt;.

&lt;blockquote&gt;'''Theorem 4.''' Each (&lt;math&gt;s&lt;/math&gt;th) convergent is nearer to a subsequent (&lt;math&gt;n&lt;/math&gt;th) convergent than any preceding (&lt;math&gt;r&lt;/math&gt;th) convergent is. In symbols, if the &lt;math&gt;n&lt;/math&gt;th convergent is taken to be &lt;math&gt;[a_0;a_1,\ldots,a_n] = x_n&lt;/math&gt;, then
:&lt;math&gt;\left| x_r - x_n \right| &gt; \left| x_s - x_n \right|&lt;/math&gt;
for all &lt;math&gt;r &lt; s &lt; n&lt;/math&gt;.&lt;/blockquote&gt;

'''Corollary 1:''' The even convergents (before the &lt;math&gt;n&lt;/math&gt;th) continually increase, but are always less than &lt;math&gt;x_n&lt;/math&gt;.

'''Corollary 2:''' The odd convergents (before the &lt;math&gt;n&lt;/math&gt;th) continually decrease, but are always greater than &lt;math&gt;x_n&lt;/math&gt;.

&lt;blockquote&gt;'''Theorem 5.'''

:&lt;math&gt;\frac{1}{k_n(k_{n+1}+k_n)}&lt; \left|x-\frac{h_n}{k_n}\right|&lt; \frac{1}{k_nk_{n+1}}. &lt;/math&gt;
&lt;/blockquote&gt;

'''Corollary 1:''' Any convergent is nearer to the continued fraction than any other fraction whose denominator is less than that of the convergent.

'''Corollary 2:''' Any convergent which immediately precedes a large quotient is a near approximation to the continued fraction.

==Semiconvergents==&lt;!-- This section is linked from [[Complete quotient]] --&gt;

If

:&lt;math&gt; \frac{h_{n-1}}{k_{n-1}},\frac{h_n}{k_n} &lt;/math&gt;

are consecutive convergents, then any fractions of the form

: &lt;math&gt; \frac{h_{n-1} + mh_n}{k_{n-1} + mk_n},&lt;/math&gt;

where &lt;math&gt;m&lt;/math&gt; is an integer such that &lt;math&gt;0\leq m\leq a_{n+1}&lt;/math&gt;, are called ''semiconvergents'', ''secondary convergents'', or ''intermediate fractions''. The &lt;math&gt;(m+1)&lt;/math&gt;-st semiconvergent equals the [[Mediant (mathematics)|mediant]] of the &lt;math&gt;m&lt;/math&gt;-th one and the convergent &lt;math&gt;\tfrac{h_n}{k_n}&lt;/math&gt;. It follows that semiconvergents represent a [[monotonic sequence]] of fractions between the convergents &lt;math&gt;\tfrac{h_{n-1}}{k_{n-1}}&lt;/math&gt; (corresponding to &lt;math&gt;m=0&lt;/math&gt;) and &lt;math&gt;\tfrac{h_{n+1}}{k_{n+1}}&lt;/math&gt; (corresponding to &lt;math&gt;m=a_{n+1}&lt;/math&gt;). Sometimes the term is taken to mean that being a semiconvergent excludes the possibility of being a convergent (i.e., &lt;math&gt;0&lt;m&lt;a_{n+1}&lt;/math&gt;), rather than that a convergent is a kind of semiconvergent.

The semiconvergents to the continued fraction expansion of a real number &lt;math&gt;x&lt;/math&gt; include all the rational approximations that are better than any approximation with a smaller denominator. Another useful property is that consecutive semiconvergents &lt;math&gt;\tfrac{a}{b}&lt;/math&gt; and &lt;math&gt;\tfrac{c}{d}&lt;/math&gt; are such that
&lt;math&gt;ad - bc = \pm 1&lt;/math&gt;.

==Best rational approximations==
{{See also|Diophantine approximation|Padé approximant}}

One can choose to define a ''best rational approximation'' to a real number {{mvar|x}} as a rational number {{sfrac|{{mvar|n}}|{{mvar|d}}}}, {{math|''d'' &gt; 0}}, that is closer to {{mvar|x}} than any approximation with a smaller or equal denominator. The simple continued fraction for {{mvar|x}} generates ''all'' of the best rational approximations for {{mvar|x}} according to three rules:

#Truncate the continued fraction, and possibly reduce its last term.
#The reduced term cannot have less than half its original value.
#If the final term is even, half its value is admissible only if the corresponding semiconvergent is better than the previous convergent. (See below.)

For example, 0.84375 has continued fraction [0;1,5,2,2]. Here are all of its best rational approximations.

:{| class="wikitable"
|- align="center"
! Continued fraction
|  [0;1]  ||  [0;1,3]  ||  [0;1,4]  ||  [0;1,5]  ||  [0;1,5,2]  ||  [0;1,5,2,1]  ||  [0;1,5,2,2] 
|- align="center"
! Rational approximation
| 1 || {{sfrac|3|4}} || {{sfrac|4|5}} || {{sfrac|5|6}} || {{sfrac|11|13}} || {{sfrac|16|19}} || {{sfrac|27|32}}
|- align="center"
! Decimal equivalent
| 1 || 0.75 || 0.8 || ~0.83333 || ~0.84615 || ~0.84211 || 0.84375
|- align="center"
! Error
| +18.519% || −11.111% || −5.1852% || −1.2346% || +0.28490% || −0.19493% || 0%
|}

The strictly monotonic increase in the denominators as additional terms are included permits an algorithm to impose a limit, either on size of denominator or closeness of approximation.

The "half rule" mentioned above is that when {{mvar|a}}{{sub|{{mvar|k}}}} is even, the halved term {{mvar|a}}{{sub|{{mvar|k}}}}/2 is admissible if and only if {{math|{{!}}''x'' − [''a''{{sub|0}} ; ''a''{{sub|1}}, &amp;hellip;, ''a''{{sub|''k'' − 1}}]{{!}} &gt; {{!}}''x'' − [''a''{{sub|0}} ; ''a''{{sub|1}}, &amp;hellip;, ''a''{{sub|''k'' − 1}}, ''a''{{sub|''k''}}/2]{{!}}}}&lt;ref name=thill&gt;{{citation |author=M. Thill |title=A more precise rounding algorithm for rational numbers |year=2008 |journal=Computing |volume=82 |pages=189–198 |doi=10.1007/s00607-008-0006-7}}&lt;/ref&gt; This is equivalent&lt;ref name=thill/&gt; to:&lt;ref&gt;{{Citation |editor-last=Paeth |editor-first=Alan W. |first=Ken |last=Shoemake |title=Graphic Gems V |chapter=I.4: Rational Approximation |chapter-url=https://books.google.com/books?id=8CGj9_ZlFKoC&amp;pg=PA25 |pages=25–31 |publisher=Academic Press |year=1995 |location=San Diego, California |isbn=0-12-543455-3}}&lt;/ref&gt;

:{{math|[''a''{{sub|''k''}}; ''a''{{sub|''k'' − 1}}, &amp;hellip;, ''a''{{sub|1}}] &gt; [''a''{{sub|k}}; ''a''{{sub|''k'' + 1}}, &amp;hellip;]}}.

The convergents to {{mvar|x}} are best approximations in an even stronger sense: {{mvar|n}}/{{mvar|d}} is a convergent for {{mvar|x}} if and only if {{math|{{!}}''dx'' − ''n''{{!}}}} is the least among all approximations {{mvar|m}}/{{mvar|c}} with {{math|''c'' ≤ ''d''}}; that is, we have {{math|{{!}}''dx'' − ''n''{{!}} &lt; {{!}}''cx'' − ''m''{{!}}}} so long as {{math|''c'' &lt; ''d''}}. (Note also that {{math|{{!}}''d&lt;sub&gt;k&lt;/sub&gt;x'' − ''n&lt;sub&gt;k&lt;/sub&gt;''{{!}} → 0}} as {{math|''k'' → ∞}}.)

=== Best rational within an interval ===
A rational that falls within the interval {{open-open|''x'', ''y''}}, for {{math|0 &lt; {{mvar|x}} &lt; {{mvar|y}}}}, can be found with the continued fractions for {{mvar|x}} and {{mvar|y}}. When both {{mvar|x}} and {{mvar|y}} are irrational and
:{{math|''x'' {{=}} [''a''{{sub|0}}; ''a''{{sub|1}}, ''a''{{sub|2}}, &amp;hellip;, ''a''{{sub|''k'' − 1}}, ''a''{{sub|''k''}}, ''a''{{sub|''k'' + 1}}, &amp;hellip;]}}
:{{math|''y'' {{=}} [''a''{{sub|0}}; ''a''{{sub|1}}, ''a''{{sub|2}}, &amp;hellip;, ''a''{{sub|''k'' − 1}}, ''b''{{sub|''k''}}, ''b''{{sub|''k'' + 1}}, &amp;hellip;]}}
where {{mvar|x}} and {{mvar|y}} have identical continued fraction expansions up through {{math|''a''&lt;sub&gt;''k''−1&lt;/sub&gt;}}, a rational that falls within the interval {{open-open|''x'', ''y''}} is given by the finite continued fraction,
:{{math|''z''(''x'',''y'') {{=}} [''a''{{sub|0}}; ''a''{{sub|1}}, ''a''{{sub|2}}, &amp;hellip;, ''a''{{sub|''k'' − 1}}, min(''a''{{sub|''k''}}, ''b''{{sub|''k''}}) + 1]}}
This rational will be best in the sense that no other rational in {{open-open|''x'', ''y''}} will have a smaller numerator or a smaller denominator.

If {{mvar|x}} is rational, it will have ''two'' continued fraction representations that are ''finite'', {{math|''x''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''x''&lt;sub&gt;2&lt;/sub&gt;}}, and similarly a rational&amp;nbsp;{{mvar|y}} will have two representations, {{math|''y''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''y''&lt;sub&gt;2&lt;/sub&gt;}}. The coefficients beyond the last in any of these representations should be interpreted as {{math|+∞}}; and the best rational will be one of {{math|''z''(''x''&lt;sub&gt;1&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;)}}, {{math|''z''(''x''&lt;sub&gt;1&lt;/sub&gt;, ''y''&lt;sub&gt;2&lt;/sub&gt;)}}, {{math|''z''(''x''&lt;sub&gt;2&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;)}}, or {{math|''z''(''x''&lt;sub&gt;2&lt;/sub&gt;, ''y''&lt;sub&gt;2&lt;/sub&gt;)}}.

For example, the decimal representation 3.1416 could be rounded from any number in the interval {{closed-closed|3.14155, 3.14165}}. The continued fraction representations of 3.14155 and 3.14165 are
:{{math|3.14155 {{=}} [3; 7, 15, 2, 7, 1, 4, 1, 1] {{=}} [3; 7, 15, 2, 7, 1, 4, 2]}}
:{{math|3.14165 {{=}} [3; 7, 16, 1, 3, 4, 2, 3, 1] {{=}} [3; 7, 16, 1, 3, 4, 2, 4]}}
and the best rational between these two is
:{{math|[3; 7, 16] {{=}} {{sfrac|355|113}} {{=}} 3.1415929....}}
Thus, {{sfrac|355|113}} is the best rational number corresponding to the rounded decimal number 3.1416, in the sense that no other rational number that would be rounded to 3.1416 will have a smaller numerator or a smaller denominator.

=== Interval for a convergent ===
A rational number, which can be expressed as finite continued fraction in two ways,
:{{math|''z'' {{=}} [''a''{{sub|0}}; ''a''{{sub|1}}, &amp;hellip;, ''a''{{sub|''k'' − 1}}, ''a''{{sub|''k''}}, 1] {{=}} [''a''{{sub|0}}; ''a''{{sub|1}}, &amp;hellip;, ''a''{{sub|''k'' − 1}}, ''a''{{sub|''k''}} + 1]}}
will be one of the convergents for the continued fraction expansion of a number, if and only if the number is strictly between
:{{math|''x'' {{=}} [''a''{{sub|0}}; ''a''{{sub|1}}, &amp;hellip;, ''a''{{sub|''k'' − 1}}, ''a''{{sub|''k''}}, 2]}} and
:{{math|''y'' {{=}} [''a''{{sub|0}}; ''a''{{sub|1}}, &amp;hellip;, ''a''{{sub|''k'' − 1}}, ''a''{{sub|''k''}} + 2]}}
The numbers {{mvar|x}} and {{mvar|y}} are formed by incrementing the last coefficient in the two representations for {{mvar|z}}. It is the case that {{math|''x'' &lt; ''y''}} when {{mvar|k}} is even, and {{math|''x'' &gt; ''y''}} when {{mvar|k}} is odd.

For example, the number {{sfrac|355|113}} has the continued fraction representations
:{{sfrac|355|113}} = [3; 7, 15, 1] = [3; 7, 16]
and thus {{sfrac|355|113}} is a convergent of any number strictly between
:{| cellpadding="2" cellspacing="0"
| align="right" | {{math|[3; 7, 15, 2]}} ||{{=}}|| {{math|{{sfrac|688|219}} ≈ 3.1415525}}
|-
| align="right" | {{math|[3; 7, 17]}} ||{{=}}|| {{math|{{sfrac|377|120}} ≈ 3.1416667}}
|}

==Comparison==
Consider {{math|''x'' {{=}} [''a''{{sub|0}}; ''a''{{sub|1}}, &amp;hellip;]}} and {{math|''y'' {{=}} [''b''{{sub|0}}; ''b''{{sub|1}}, &amp;hellip;]}}. If {{mvar|k}} is the smallest index for which {{math|''a''{{sub|''k''}}}} is unequal to {{math|''b''{{sub|''k''}}}} then {{math|''x'' &lt; ''y''}} if {{math|(−1){{sup|''k''}}(''a''{{sub|''k''}} − ''b''{{sub|''k''}}) &lt; 0}} and {{math|''y'' &lt; ''x''}} otherwise.

If there is no such {{mvar|k}}, but one expansion is shorter than the other, say {{math|''x'' {{=}} [''a''{{sub|0}}; ''a''{{sub|1}}, &amp;hellip;, ''a''{{sub|''n''}}]}} and {{math|''y'' {{=}} [''b''{{sub|0}}; ''b''{{sub|1}}, &amp;hellip;, ''b''{{sub|''n''}}, ''b''{{sub|''n'' + 1}}, &amp;hellip;]}} with {{math|''a''{{sub|''i''}} {{=}} ''b''{{sub|''i''}}}} for {{math|0 ≤ ''i'' ≤ ''n''}}, then {{math|''x'' &lt; ''y''}} if {{mvar|n}} is even and {{math|''y'' &lt; ''x''}} if {{mvar|n}} is odd.

==Continued fraction expansions of {{pi}}==
To calculate the convergents of [[pi|{{pi}}]] we may set {{math|''a''{{sub|0}} {{=}} ⌊{{pi}}⌋ {{=}} 3}}, define {{math|''u''{{sub|1}} {{=}} {{sfrac|1|{{pi}} − 3}} ≈ 7.0625}} and {{math|''a''{{sub|1}} {{=}} ⌊''u''{{sub|1}}⌋ {{=}} 7}}, {{math|''u''{{sub|2}} {{=}} {{sfrac|1|''u''{{sub|1}} − 7}} ≈ 15.9966}} and {{math|''a''{{sub|2}} {{=}} ⌊''u''{{sub|2}}⌋ {{=}} 15}}, {{math|''u''{{sub|3}} {{=}} {{sfrac|1|''u''{{sub|2}} − 15}} ≈ 1.0034}}. Continuing like this, one can determine the infinite continued fraction of {{pi}} as
:[3;7,15,1,292,1,1,…] {{OEIS|A001203}}.
The fourth convergent of {{pi}} is [3;7,15,1] = {{sfrac|355|113}} = 3.14159292035..., sometimes called [[Milü]], which is fairly close to the true value of {{pi}}.

Let us suppose that the quotients found are, as above, [3;7,15,1]. The following is a rule by which we can write down at once the convergent fractions which result from these quotients without developing the continued fraction.

The first quotient, supposed divided by unity, will give the first fraction, which will be too small, namely, {{sfrac|3|1}}. Then, multiplying the numerator and denominator of this fraction by the second quotient and adding unity to the numerator, we shall have the second fraction, {{sfrac|22|7}}, which will be too large. Multiplying in like manner the numerator and denominator of this fraction by the third quotient, and adding to the numerator the numerator of the preceding fraction, and to the denominator the denominator of the preceding fraction, we shall have the third fraction, which will be too small. Thus, the third quotient being 15, we have for our numerator {{nowrap|(22 × 15 {{=}} 330) + 3 {{=}} 333}}, and for our denominator, {{nowrap|(7 × 15 {{=}} 105) + 1 {{=}} 106}}. The third convergent, therefore, is {{sfrac|333|106}}. We proceed in the same manner for the fourth convergent. The fourth quotient being 1, we say 333 times 1 is 333, and this plus 22, the numerator of the fraction preceding, is 355; similarly, 106 times 1 is 106, and this plus 7 is 113.

In this manner, by employing the four quotients [3;7,15,1], we obtain the four fractions:

:{{sfrac|3|1}}, {{sfrac|22|7}}, {{sfrac|333|106}}, {{sfrac|355|113}}, &amp;hellip;.

These convergents are alternately smaller and larger than the true value of {{pi}}, and approach nearer and nearer to {{pi}}. The difference between a given convergent and {{pi}} is less than the reciprocal of the product of the denominators of that convergent and the next convergent. For example, the fraction {{sfrac|22|7}} is greater than {{pi}}, but {{sfrac|22|7}} − {{pi}} is less than {{sfrac|1|7 × 106}}&amp;nbsp;=&amp;nbsp;{{sfrac|1|742}} (in fact, {{sfrac|22|7}} − {{pi}} is just more than {{sfrac|1|791}} = {{sfrac|1|7 × 113}}).

The demonstration of the foregoing properties is deduced from the fact that if we seek the difference between one of the convergent fractions and the next adjacent to it we shall obtain a fraction of which the numerator is always unity and the denominator the product of the two denominators. Thus the difference between {{sfrac|22|7}} and {{sfrac|3|1}} is {{sfrac|1|7}}, in excess; between {{sfrac|333|106}} and {{sfrac|22|7}}, {{sfrac|1|742}}, in deficit; between {{sfrac|355|113}} and {{sfrac|333|106}}, {{sfrac|1|11978}}, in excess; and so on. The result being, that by employing this series of differences we can express in another and very simple manner the fractions with which we are here concerned, by means of a second series of fractions of which the numerators are all unity and the denominators successively be the product of every two adjacent denominators. Instead of the fractions written above, we have thus the series:

:{{sfrac|3|1}} + {{sfrac|1|1 × 7}} − {{sfrac|1|7 × 106}} + {{sfrac|1|106 × 113}} − &amp;hellip;

The first term, as we see, is the first fraction; the first and second together give the second fraction, {{sfrac|22|7}}; the first, the second and the third give the third fraction {{sfrac|333|106}}, and so on with the rest; the result being that the series entire is equivalent to the original value.

==Generalized continued fraction==
{{main|Generalized continued fraction}}

A generalized continued fraction is an expression of the form

:&lt;math&gt;x = b_0 + \cfrac{a_1}{b_1 + \cfrac{a_2}{b_2 + \cfrac{a_3}{b_3 + \cfrac{a_4}{b_4 + \ddots\,}}}}&lt;/math&gt;

where the ''a''&lt;sub&gt;''n''&lt;/sub&gt; (''n'' &amp;gt; 0) are the partial numerators, the ''b''&lt;sub&gt;''n''&lt;/sub&gt; are the partial denominators, and the leading term ''b''&lt;sub&gt;0&lt;/sub&gt; is called the ''integer'' part of the continued fraction.

To illustrate the use of generalized continued fractions, consider the following example. The sequence of partial denominators of the simple continued fraction of {{pi}} does not show any obvious pattern:

:&lt;math&gt;\pi=[3;7,15,1,292,1,1,1,2,1,3,1,\ldots]&lt;/math&gt;

or

:&lt;math&gt;\pi=3+\cfrac{1}{7+\cfrac{1}{15+\cfrac{1}{1+\cfrac{1}{292+\cfrac{1}{1+\cfrac{1}{1+\cfrac{1}{1+\cfrac{1}{2+\cfrac{1}{1+\cfrac{1}{3+\cfrac{1}{1+\ddots}}}}}}}}}}}&lt;/math&gt;

However, several generalized continued fractions for {{pi}} have a perfectly regular structure, such as:

:&lt;math&gt;
\pi=\cfrac{4}{1+\cfrac{1^2}{2+\cfrac{3^2}{2+\cfrac{5^2}{2+\cfrac{7^2}{2+\cfrac{9^2}{2+\ddots}}}}}}
=\cfrac{4}{1+\cfrac{1^2}{3+\cfrac{2^2}{5+\cfrac{3^2}{7+\cfrac{4^2}{9+\ddots}}}}}
=3+\cfrac{1^2}{6+\cfrac{3^2}{6+\cfrac{5^2}{6+\cfrac{7^2}{6+\cfrac{9^2}{6+\ddots}}}}}
&lt;/math&gt;

:&lt;math&gt;\displaystyle \pi=2+\cfrac{2}{1+\cfrac{1}{1/2+\cfrac{1}{1/3+\cfrac{1}{1/4+\ddots}}}}=2+\cfrac{2}{1+\cfrac{1\cdot2}{1+\cfrac{2\cdot3}{1+\cfrac{3\cdot4}{1+\ddots}}}}&lt;/math&gt;

:&lt;math&gt; \displaystyle \pi=2+\cfrac{4}{3+\cfrac{1\cdot3}{4+\cfrac{3\cdot5}{4+\cfrac{5\cdot7}{4+\ddots}}}}&lt;/math&gt;

The first two of these are special cases of the [[Inverse trigonometric functions#Variant: Continued fractions for arctangent|arctangent]] function with {{pi}} = 4 arctan (1).

:&lt;math&gt;
\pi=3+\cfrac{1^3}{6+\cfrac{1^3+2^3}{6+\cfrac{1^3+2^3+3^3+4^3}{6+\cfrac{1^3+2^3 +3^3+4^3+5^3+6^3}{6+\cfrac{1^3+2^3+3^3+4^3+5^3+6^3+7^3+8^3}{6+\ddots}}}}}
&lt;/math&gt;

The above continued fraction of pi consisting of cubes uses the Nilakantha series and an exploit from Leonhard Euler.&lt;ref&gt;{{Cite web|url=http://www.theoremoftheday.org/Resources/TheoremNotes.htm|title=Theorem of the Day: Theorem no. 203|last=Foster|first=Tony|date=June 22, 2015|website=|publisher=Robin Whitty|access-date=June 25, 2015}}&lt;/ref&gt;

==Other continued fraction expansions==

===Periodic continued fractions===
{{main|Periodic continued fraction}}
The numbers with periodic continued fraction expansion are precisely the [[quadratic irrational|irrational solutions]] of [[quadratic equation]]s with rational coefficients; rational solutions have finite continued fraction expansions as previously stated. The simplest examples are the [[golden ratio]] φ = [1;1,1,1,1,1,…] and {{sqrt|2}} = [1;2,2,2,2,…], while {{sqrt|14}} = [3;1,2,1,6,1,2,1,6…] and {{sqrt|42}} = [6;2,12,2,12,2,12…]. All irrational square roots of integers have a special form for the period; a symmetrical string, like the empty string (for {{sqrt|2}}) or 1,2,1 (for {{sqrt|14}}), followed by the double of the leading integer.

===A property of the golden ratio φ===
Because the continued fraction expansion for [[golden ratio|φ]] doesn't use any integers greater than 1, φ is one of the most "difficult" real numbers to approximate with rational numbers. [[Hurwitz's theorem (number theory)|Hurwitz's theorem]]&lt;ref&gt;Theorem 193: {{Cite book | last = Hardy | first = G.H. | last2 = Wright | first2 = E.M. | title = An Introduction to the Theory of Numbers | publisher = Oxford | year = 1979 | edition = Fifth}}&lt;/ref&gt; states that any irrational number {{mvar|k}} can be approximated by infinitely many rational {{sfrac|''m''|''n''}} with

:&lt;math&gt;\left| k - {m \over n}\right| &lt; {1 \over n^2 \sqrt 5}.&lt;/math&gt;

While virtually all real numbers {{mvar|k}} will eventually have infinitely many convergents {{sfrac|''m''|''n''}} whose distance from {{mvar|k}} is significantly smaller than this limit, the convergents for φ (i.e., the numbers {{sfrac|5|3}}, {{sfrac|8|5}}, {{sfrac|13|8}}, {{sfrac|21|13}}, etc.) consistently "toe the boundary", keeping a distance of almost exactly &lt;math&gt;{\scriptstyle{1 \over n^2 \sqrt 5}}&lt;/math&gt; away from φ, thus never producing an approximation nearly as impressive as, for example, [[Milü|{{sfrac|355|113}}]] for [[pi|{{pi}}]]. It can also be shown that every real number of the form {{sfrac|''a'' + ''b''φ|''c'' + ''d''φ}}, where {{mvar|a}}, {{mvar|b}}, {{mvar|c}}, and {{mvar|d}} are integers such that {{math|1=''a'' ''d'' − ''b'' ''c'' = ±1}}, shares this property with the golden ratio φ; and that all other real numbers can be more closely approximated.

===Regular patterns in continued fractions===
While there is no discernable pattern in the simple continued fraction expansion of {{pi}}, there is one for {{math|''e''}}, the [[e (mathematical constant)|base of the natural logarithm]]:

:&lt;math&gt;e = e^1 = [2; 1, 2, 1, 1, 4, 1, 1, 6, 1, 1, 8, 1, 1, 10, 1, 1, 12, 1, 1, \dots],&lt;/math&gt;

which is a special case of this general expression for positive integer {{mvar|n}}:

:&lt;math&gt;e^{1/n} = [1; n-1, 1, 1, 3n-1, 1, 1, 5n-1, 1, 1, 7n-1, 1, 1, \dots] \,\!.&lt;/math&gt;

Another, more complex pattern appears in this continued fraction expansion for positive odd {{mvar|n}}:

:&lt;math&gt;e^{2/n} = \left[1; \frac{n-1}{2}, 6n, \frac{5n-1}{2}, 1, 1, \frac{7n-1}{2}, 18n, \frac{11n-1}{2}, 1, 1, \frac{13n-1}{2}, 30n, \frac{17n-1}{2}, 1, 1, \dots \right] \,\!,&lt;/math&gt;

with a special case for {{math|1=''n'' = 1}}:

:&lt;math&gt;e^2 = [7; 2, 1, 1, 3, 18, 5, 1, 1, 6, 30, 8, 1, 1, 9, 42, 11, 1, 1, 12, 54, 14, 1, 1 \dots, 3k, 12k+6, 3k+2, 1, 1 \dots] \,\!.&lt;/math&gt;

Other continued fractions of this sort are

:&lt;math&gt;\tanh(1/n) = [0; n, 3n, 5n, 7n, 9n, 11n, 13n, 15n, 17n, 19n, \dots] &lt;/math&gt;

where {{mvar|n}} is a positive integer; also, for integer {{mvar|n}}:

:&lt;math&gt;\tan(1/n) = [0; n-1, 1, 3n-2, 1, 5n-2, 1, 7n-2, 1, 9n-2, 1, \dots]\,\!,&lt;/math&gt;

with a special case for {{math|1=''n'' = 1}}:

:&lt;math&gt;\tan(1) = [1; 1, 1, 3, 1, 5, 1, 7, 1, 9, 1, 11, 1, 13, 1, 15, 1, 17, 1, 19, 1, \dots]\,\!.&lt;/math&gt;

If {{math|''I''&lt;sub&gt;''n''&lt;/sub&gt;(''x'')}} is the modified, or hyperbolic, [[Bessel function]] of the first kind, we may define a function on the rationals {{sfrac|''p''|''q''}} by

:&lt;math&gt;S(p/q) = \frac{I_{p/q}(2/q)}{I_{1+p/q}(2/q)},&lt;/math&gt;

which is defined for all rational numbers, with {{mvar|p}} and {{mvar|q}} in lowest terms. Then for all nonnegative rationals, we have

:&lt;math&gt;S(p/q) = [p+q; p+2q, p+3q, p+4q, \dots],&lt;/math&gt;

with similar formulas for negative rationals; in particular we have

:&lt;math&gt;S(0) = S(0/1) = [1; 2, 3, 4, 5, 6, 7, \dots].&lt;/math&gt;

Many of the formulas can be proved using [[Gauss's continued fraction]].

===Typical continued fractions===
Most irrational numbers do not have any periodic or regular behavior in their continued fraction expansion. Nevertheless, [[Aleksandr Khinchin|Khinchin]] proved that for [[almost all]] real numbers {{mvar|x}}, the {{math|''a''&lt;sub&gt;''i''&lt;/sub&gt;}} (for {{math|1=''i'' = 1, 2, 3, …}}) have an astonishing property: their [[geometric mean]] is a constant (known as [[Khinchin's constant]], {{math|''K'' ≈ 2.6854520010…}}) independent of the value of {{mvar|x}}. [[Paul Lévy (mathematician)|Paul Lévy]] showed that the {{mvar|n}}th root of the denominator of the {{mvar|n}}th convergent of the continued fraction expansion of almost all real numbers approaches an asymptotic limit, approximately 3.27582, which is known as [[Lévy's constant]]. [[Lochs' theorem]] states that {{mvar|n}}th convergent of the continued fraction expansion of almost all real numbers determines the number to an average accuracy of just over {{mvar|n}} decimal places.

==Applications==
===Square roots===
Generalized continued fractions are used in a [[methods of computing square roots#Continued fraction expansion|method for computing square roots]].

The identity
{{NumBlk|:|&lt;math&gt;\sqrt{x} = 1+\frac{x-1}{1+\sqrt{x}}&lt;/math&gt;|{{EquationRef|1}}}}
leads via recursion to the generalized continued fraction for any square root:&lt;ref&gt;Ben Thurston, [http://benpaulthurstonblog.blogspot.com/2012/05/estimating-square-roots.html "Estimating square roots, generalized continued fraction expression for every square root"], ''The Ben Paul Thurston Blog''&lt;/ref&gt;
{{NumBlk|:|&lt;math&gt;\sqrt{x}=1+\cfrac{x-1}{2 + \cfrac{x-1}{2 + \cfrac{x-1}{2+{\ddots}}}}&lt;/math&gt;|{{EquationRef|2}}}}'''

===Pell's equation===
Continued fractions play an essential role in the solution of [[Pell's equation]]. For example, for positive integers {{mvar|p}} and {{mvar|q}}, and non-square {{mvar|n}}, it is true that {{math|1=''p''&lt;sup&gt;2&lt;/sup&gt; − ''nq''&lt;sup&gt;2&lt;/sup&gt; = ±1}} [[if and only if]] {{math|{{sfrac|''p''|''q''}}}} is a convergent of the regular continued fraction for {{sqrt|{{mvar|n}}}}.

===Dynamical systems===
Continued fractions also play a role in the study of [[dynamical system]]s, where they tie together the [[Farey sequence|Farey fractions]] which are seen in the [[Mandelbrot set]] with [[Minkowski's question mark function]] and the [[modular group]] Gamma.

The backwards [[shift operator]] for continued fractions is the [[map (mathematics)|map]] {{math|''h''(''x'') {{=}} 1/{{mvar|x}} − ⌊1/{{mvar|x}}⌋}} called the '''Gauss map''', which lops off digits of a continued fraction expansion: {{math|''h''([0; ''a''{{sub|1}}, ''a''{{sub|2}}, ''a''{{sub|3}}, &amp;hellip;]) {{=}} [0; ''a''{{sub|2}}, ''a''{{sub|3}}, &amp;hellip;]}}. The [[transfer operator]] of this map is called the [[Gauss–Kuzmin–Wirsing operator]]. The distribution of the digits in continued fractions is given by the zero'th [[eigenvector]] of this operator, and is called the [[Gauss–Kuzmin distribution]].

===Eigenvalues and eigenvectors===
The [[Lanczos algorithm]] uses a continued fraction expansion to iteratively approximate the eigenvalues and eigenvectors of a large sparse matrix.&lt;ref&gt;{{citation|title=Electronic Structure: Basic Theory and Practical Methods|first=Richard M.|last=Martin|publisher=Cambridge University Press|year=2004|isbn=9781139643658|page=557|url=https://books.google.com/books?id=v1YhAwAAQBAJ&amp;pg=PA557}}.&lt;/ref&gt;

=== Networking applications ===
Continued fraction has also been used in modelling optimization problems for wireless [[network virtualization]] to find a route between a source and a destination.&lt;ref&gt;{{Cite journal|last=Afifi|first=Haitham, et al.|date=April 2018|title=MARVELO: Wireless Virtual Network Embedding for Overlay Graphs with Loops|url=|journal=2018 IEEE Wireless Communications and Networking Conference (WCNC)|volume=|pages=|via=}}&lt;/ref&gt;

==Examples of rational and irrational numbers==
{{Continued fraction examples}}

==History==
* 300 BCE ''[[Euclid's Elements]]'' contains an algorithm for the [[greatest common divisor]] which generates a continued fraction as a by-product
* 499 The ''[[Aryabhatiya]]'' contains the solution of indeterminate equations using continued fractions
* 1579 [[Rafael Bombelli]], ''L'Algebra Opera'' – method for the extraction of square roots which is related to continued fractions
* 1613 [[Pietro Cataldi]], ''Trattato del modo brevissimo di trovar la radice quadra delli numeri'' – first notation for continued fractions
:Cataldi represented a continued fraction as &lt;math&gt;a_0&lt;/math&gt; &amp; &lt;math&gt;\frac{n_1}{d_1 \cdot}&lt;/math&gt; &amp; &lt;math&gt;\frac{n_2}{d_2 \cdot}&lt;/math&gt; &amp; &lt;math&gt;\frac{n_3}{d_3 \cdot}&lt;/math&gt; with the dots indicating where the following fractions went.
* 1695 [[John Wallis]], ''Opera Mathematica'' – introduction of the term "continued fraction"
* 1737 [[Leonhard Euler]], ''De fractionibus continuis dissertatio'' – Provided the first then-comprehensive account of the properties of continued fractions, and included the first proof that the number [[e (mathematical constant)|e]] is irrational.&lt;ref name=sandifer&gt;{{cite journal | last = Sandifer | first = Ed | title = How Euler Did It: Who proved e is irrational? | journal = MAA Online |date=February 2006 | url = http://www.maa.org/editorial/euler/How%20Euler%20Did%20It%2028%20e%20is%20irrational.pdf|format=PDF}}&lt;/ref&gt;
* 1748 Euler, ''[[List of important publications in mathematics#Introductio in analysin infinitorum|Introductio in analysin infinitorum]]''. Vol. I, Chapter 18 – proved the equivalence of a certain form of continued fraction and a generalized [[infinite series]], proved that every rational number can be written as a finite continued fraction, and proved that the continued fraction of an irrational number is infinite.&lt;ref name=IntroductioI&gt;{{cite web | title=E101 – Introductio in analysin infinitorum, volume 1|url=http://math.dartmouth.edu/~euler/pages/E101.html| accessdate=2008-03-16}}&lt;/ref&gt;
* 1761 [[Johann Lambert]] – gave the first proof of the irrationality of [[Pi|{{pi}}]] using a continued fraction for [[Trigonometric functions|tan(x)]].
* 1768 [[Joseph-Louis Lagrange]] – provided the general solution to Pell's equation using continued fractions similar to Bombelli's
* 1770 Lagrange – proved that [[quadratic irrational number|quadratic irrationals]] expand to [[periodic continued fraction]]s.
* 1813 [[Carl Friedrich Gauss]], ''Werke'', Vol. 3, pp.&amp;nbsp;134–138 – derived a very general [[Gauss's continued fraction|complex-valued continued fraction]] via a clever identity involving the [[hypergeometric function]]
* 1828 [[Évariste Galois]] proved the periodicity of continued fractions for quadratic irrationals.&lt;ref&gt;{{cite book|last=Wolfram|first=Stephen|title=A New Kind of Science|publisher=Wolfram Media, Inc.|year=2002|page=915|isbn=1-57955-008-8}}&lt;/ref&gt;  
* 1892 [[Henri Padé]] defined [[Padé approximant]]
* 1972 [[Bill Gosper]] – First exact algorithms for continued fraction arithmetic.

==See also==
*[[Complete quotient]]
*[[Methods of computing square roots#Example.2C square root of 114 as a continued fraction|Computing continued fractions of square roots]]
*[[Engel expansion]]
*[[Euler's continued fraction formula]]
*[[Generalized continued fraction]]
*[[Infinite compositions of analytic functions]]
*[[Infinite product]]
*[[Infinite series]]
*[[Iterated binary operation]]
*[[Mathematical constants (sorted by continued fraction representation)]]
*[[Restricted partial quotients]]
*[[Stern–Brocot tree]]
*[[Śleszyński–Pringsheim theorem]]

==Notes==
{{Reflist}}

==References==
* {{cite news|first1=H. | last1=Siebeck | year=1846 | title= Ueber periodische Kettenbr&amp;uuml;che
 |journal= J. Reine Angew. Math. | volume=33 | pages=68–70 | url=http://www.digizeitschriften.de/dms/resolveppn/?PID=PPN243919689_0033&amp;#x7c;log5 }}
* {{cite news|first1=J. B. H. | last1=Heilermann | title=Ueber die Verwandlung von Reihen in Kettenbr&amp;uuml;che
 |journal =J. Reine Angew. Math. | volume=33 | pages=174–188 | url=http://www.digizeitschriften.de/dms/img/?PID=PPN243919689_0033&amp;#x7c;log13 | year=1846}}
* {{cite news| first1=Arne | last1=Magnus | title=Continued fractions associated with the Pad&amp;eacute; Table
 |journal=Math. Z. | volume=78 | pages=361–374 | year=1962}}
* {{cite news | first1=Chen-Fan | last1=Chen |first2=Leang-San | last2=Shieh
 |title=Continued fraction inversion by Routh's Algorithm | journal = IEEE Trans. Circuit Theory
 | volume=16 | number=2 | pages=197–202 | doi=10.1109/TCT.1969.1082925 | year=1969}}
* {{cite news|first1=William B. | last1=Gragg | title=Matrix interpretations and applications of the continued fraction algorithm
 |journal= Rocky Mount. J. Math. | volume=4 | number=2 | doi=10.1216/RJM-1974-4-2-213 | page=213 |year=1974}}
*{{Cite book | last = Jones | first = William B. | last2 = Thron | first2 = W. J. | title = Continued Fractions: Analytic Theory and Applications. Encyclopedia of Mathematics and its Applications. | place= | publisher = Addison-Wesley Publishing Company | year = 1980 | location = Reading. Massachusetts | volume = 11 | edition = | isbn = 0-201-13510-8}}
*{{cite book |title = Continued Fractions | year = 1964 | last1 = Khinchin | first1 = A. Ya. | authorlink = Aleksandr Khinchin | origyear = Originally published in Russian, 1935 | publisher = [[University of Chicago Press]] | ISBN= 0-486-69630-8 }}
* {{citation | first1 = Calvin T. | last1 = Long | year = 1972 | title = Elementary Introduction to Number Theory | edition = 2nd | publisher = [[D. C. Heath and Company]] | location = Lexington | lccn = 77-171950 }}
* {{cite book | first=Oskar | last= Perron | authorlink=Oskar Perron | title =Die Lehre von den Kettenbrüchen | publisher=Chelsea Publishing Company | place=New York, NY | year= 1950}}
* {{citation | first1 = Anthony J. | last1 = Pettofrezzo | first2 = Donald R. | last2 = Byrkit | year = 1970 | title = Elements of Number Theory | publisher = [[Prentice Hall]] | location = Englewood Cliffs | lccn = 77-81766 }}
*{{cite book | title = Continued Fractions | last1 = Rockett | first1 = Andrew M. | last2 = Szüsz | first2 = Peter| year = 1992 | publisher = World Scientific Press | ISBN = 981-02-1047-7 }}
*H. S. Wall, ''Analytic Theory of Continued Fractions'', D. Van Nostrand Company, Inc., 1948 {{isbn|0-8284-0207-8}}
*{{cite book|first1=A. |last1= Cuyt |first2= V. | last2= Brevik Petersen |first3= B. |last3= Verdonk
 |first4= H. |last4= Waadeland |first5 = W. B. |last5=Jones |title =Handbook of Continued fractions for Special functions
 |publisher= Springer Verlag |year=2008 |isbn=978-1-4020-6948-2}}
* {{cite news | last1=Rieger |first1=G. J. | title =A new approach to the real numbers (motivated by continued fractions)
 |journal= Abh. Braunschweig.Wiss. Ges. | volume= 33 |year=1982 |pages=205–217}}

==External links==
* {{springer|title=Continued fraction|id=p/c025540}}
* [http://www.maths.surrey.ac.uk/hosted-sites/R.Knott/Fibonacci/cfINTRO.html An Introduction to the Continued Fraction]
* Linas Vepstas [http://www.linas.org/math/chap-gap/chap-gap.html Continued Fractions and Gaps] (2004) reviews chaotic structures in continued fractions.
* [http://www.cut-the-knot.org/blue/ContinuedFractions.shtml Continued Fractions on the Stern-Brocot Tree] at [[cut-the-knot]]
* [http://www.math.sunysb.edu/~tony/whatsnew/column/antikytheraI-0400/kyth3.html The Antikythera Mechanism I: Gear ratios and continued fractions]
* [http://wims.unice.fr/~wims/en_tool~number~contfrac.en.html Continued fraction calculator], WIMS.
* [https://web.archive.org/web/20030202011209/http://www.tweedledum.com/rwg/cfup.htm Continued Fraction Arithmetic] Gosper's first continued fractions paper, unpublished. Cached on the [[Internet Archive]]'s [[Internet Archive#Wayback Machine|Wayback Machine]]
* {{MathWorld |title=Continued Fraction |urlname=ContinuedFraction}}
* [http://demonstrations.wolfram.com/ContinuedFractions/ Continued Fractions] by [[Stephen Wolfram]] and [http://demonstrations.wolfram.com/ContinuedFractionApproximationsOfTheTangentFunction/ Continued Fraction Approximations of the Tangent Function] by Michael Trott, [[Wolfram Demonstrations Project]].
* {{OEIS el|1=A133593|2="Exact" continued fraction for Pi}}
* [http://go.helms-net.de/math/tetdocs/FracIterAltGeom.htm A view into "fractional interpolation" of a continued fraction {{math|{1; 1, 1, 1, ...}}} ]
* [http://www.ams.org/publicoutreach/feature-column/fcarc-irrational3 Best rational approximation through continued fractions]

{{Wiktionary}}
{{Fractions and ratios}}

{{Authority control}}

{{DEFAULTSORT:Continued Fraction}}
[[Category:Continued fractions|*]]
[[Category:Mathematical analysis]]</text>
      <sha1>ry731k03hwbezkcc4mzuth47uab1w30</sha1>
    </revision>
  </page>
  <page>
    <title>Coxeter decompositions of hyperbolic polygons</title>
    <ns>0</ns>
    <id>52080279</id>
    <revision>
      <id>788362522</id>
      <parentid>782846590</parentid>
      <timestamp>2017-07-01T00:38:34Z</timestamp>
      <contributor>
        <username>Ketiltrout</username>
        <id>202276</id>
      </contributor>
      <comment>ref</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4768">{{Orphan|date=December 2016}}
{{Refimprove|date=June 2017}}
[[File:Hyperbolic-triangle-interior-angles.svg|thumb|A hyperbolic triangle – its interior angles do not sum to 180 degrees.]]

A '''Coxeter decomposition''' of a [[polygon]] is a decomposition into a finite number of polygons in which any two sharing a side are reflections of each other along that side. Hyperbolic polygons are the analogues of Euclidean polygons in [[hyperbolic geometry]]. A hyperbolic ''n''-gon is an area bounded by ''n'' segments, rays, or entire straight lines. The standard model for this geometry is the [[Poincaré disk model]]. A major difference between Euclidean and hyperbolic polygons is that the sum of internal angles of a hyperbolic polygon is not the same as Euclidean polygons. In particular, the sum of the angles of a [[hyperbolic triangle]] is less than 180 degrees. [[File:TriangleGroup.pdf|thumb|A triangle group formed by reflecting a triangle on its sides.]]Coxeter decompositions are named after [[Harold Scott MacDonald Coxeter]], an accomplished 20th century geometer. He introduced the [[Coxeter group]], an abstract group  generated by reflections. These groups have many uses, including producing the rotations of [[Platonic solid]]s and tessellating the plane.

== Coxeter decompositions ==
Given a polygon ''P'', a group ''G'' can be generated by reflecting ''P'' around its sides. If the angles of ''P'' are {{pi}}/''k'' for natural numbers ''k'', then ''G'' will be discrete. A '''Coxeter decomposition''' of a [[polygon]] is a decomposition into a finite number of polygons in which any two sharing a side are reflections of each other along that side.

The goal of a Coxeter decomposition is to break up a polygon into a composition of congruent triangles reflected on its sides.

== Hyperbolic triangles ==
If triangle ABC can undergo Coxeter decomposition and has angles &lt;math&gt;k_i\frac{\pi}{q_i}&lt;/math&gt;, where &lt;math&gt;k_i&lt;/math&gt; is the number of times the &lt;math&gt;i&lt;/math&gt;th angle is broken up, the triangle ABC can be written as &lt;math&gt;\left( \frac{k_1}{q_1}, \frac{k_2}{q_2}, \frac{k_3}{q_3}\right)&lt;/math&gt;. Several properties of these fundamental polygons are known for hyperbolic triangles.
[[File:Coxeterdecompositiontriangle.png|thumb|The decomposition of a triangle with three fundamental angles]]
* The fundamental triangle has a right angle. The proof of this involves two cases dependent on if the angles of the decomposed triangle are fundamental. If they are not, then it follows that since the process of decomposition is finite, eventually a fundamental triangle will be formed with a right angle. If they are, a proof by contradiction based on the area of the fundamental triangle proves that it will have a right angle.
* For a triangle &lt;math&gt;\left( \frac{k_1}{q_1}, \frac{k_2}{q_2}, \frac{k_3}{q_3}\right)&lt;/math&gt;, at least two &lt;math&gt;q_i&lt;/math&gt; are equal. This is also proved by contradiction based on the area of the fundamental polygon found using the [[Gauss–Bonnet theorem]]. We can say the area of the whole triangle is equal to the number of fundamental triangles times their area. This gives us  &lt;math&gt;1 -\sum_{i=1}^3 \frac{k_i}{q_i} = N \left( 1 -\sum_{i=1}^3 \frac 1 {q_i}\right)&lt;/math&gt;. If we assume that &lt;math&gt;q_1&gt;q_2&gt;q_3&lt;/math&gt;, then the previous equality is broken for &lt;math&gt;N&gt;1&lt;/math&gt;.  Therefore, at least two angles are equal.
* Given a triangle where all three angles are fundamental, there is a single decomposition. A nontrivial proof of this can be found in.&lt;ref&gt;{{Cite journal |title=Coxeter Decompositions of Hyperbolic Polygons |journal=[[European J. Combin.]] |volume=19 |issue=7 |pages=801–817 |author=Felikson, A. A. |date=1998 |doi=10.1006/eujc.1998.0238}}&lt;/ref&gt;
* All possible decompositions are known.[[File:Coxeter all possible triangles decompositions.png|thumb|These are all Coxeter decompositions of hyperbolic triangles, excluding the more detailed one above.]]

== Other hyperbolic polygons ==
Quadrilaterals may also have Coxeter decompositions.
* If a quadrilateral in not convex, then there are two possible triangular decompositions. This is done by decomposing it into two triangles are then decomposing those. These two triangles are obtuse. 
*A quadrilateral can be decomposed by quadrilaterals.
* All decompositions of convex quadrilaterals are also known. Showing them all is impractical in this article, but some are pictured here. [[File:Coxeterdecompositionconcavequadrilateral.png|thumb|The decompositions for nonconvex quadrilaterals.]][[File:Quad decompositions of quad.png|thumb|Decompositions of quadrilaterals into quadrilaterals]]
[[File:Somedecompositionsofquadrilaterals.png|thumb|Some of the decompositions of quadrilaterals]]

==References==
{{Reflist}}

[[Category:Geometry]]</text>
      <sha1>72t4mg7ky5zhu4kssxupa6rrjxmlopv</sha1>
    </revision>
  </page>
  <page>
    <title>Detlef Laugwitz</title>
    <ns>0</ns>
    <id>26147867</id>
    <revision>
      <id>763381948</id>
      <parentid>763381296</parentid>
      <timestamp>2017-02-02T22:42:12Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Speedily moving category Technische Universität München alumni to [[:Category:Technical University of Munich alumni]] per [[WP:CFDS|CFDS]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2472">[[File:Detlef Laugwitz.jpg|thumb|Detlef Laugwitz.]]
'''Detlef Laugwitz''' (1932–2000) was a [[German people|German]] [[mathematician]] and historian, who worked in [[differential geometry]], [[history of mathematics]], [[functional analysis]], and [[non-standard analysis]].

==Biography==
He was born on 11 May 1932 in [[Breslau]], [[Weimar Republic|Germany]]. Starting in 1949, he studied mathematics, [[physics]], and [[philosophy]] at the [[University of Göttingen|Georg-August-University]] at [[Göttingen]], where he received his doctorate in 1954.&lt;ref&gt;''Differential geometry without the axiom of dimension'', Mathematische Zeitschrift Bd.61, 1954, p. 100&lt;/ref&gt; Until 1956 he worked in the [[Mathematical Research Institute of Oberwolfach]]. In 1958 he became a lecturer at the [[Technical University of Munich]], where he obtained his Habilitation. In 1958 he moved to the [[Technical University of Darmstadt]], where in 1962 he became a professor, and remained until his retirement. From 1976 to 1984 he was a visiting professor at [[California Institute of Technology|Caltech]].

==Work==
Laugwitz worked in differential geometry of infinite dimensional vector spaces (his dissertation) and in [[Finsler geometry]]. In 1958 he and [[Curt Schmieden]] developed their own approach to [[infinitesimal]]s through field extensions, independently of [[Abraham Robinson]]. They described this as "infinitesimal mathematics" and leading back to the historical roots in [[Gottfried Wilhelm Leibniz|Leibniz]]. In 1996 he published the standard biography of [[Bernhard Riemann]].

==Notes==
{{reflist}}

==Publications==
*{{cite book |last1= Laugwitz |first1= D.| title = Differential and Riemannian Geometry | publisher = Academic Press New York | location = New York |edition= first|year=1965|doi =| isbn=}}
*{{citation|authorlink=Detlef Laugwitz|last=Laugwitz|first=D.|year=1989|title=Definite values of infinite sums: aspects of the foundations of infinitesimal analysis around 1820|journal=[[Archive for History of Exact Sciences]]|volume=39|issue=3|pages=195&amp;ndash;245|doi=10.1007/BF00329867}}.

{{Authority control}}

{{DEFAULTSORT:Laugwitz, Detlef}}
[[Category:20th-century German mathematicians]]
[[Category:Historians of mathematics]]
[[Category:Differential geometers]]
[[Category:Technical University of Munich alumni]]
[[Category:Technical University of Munich faculty]]
[[Category:1932 births]]
[[Category:2000 deaths]]
[[Category:20th-century historians]]</text>
      <sha1>ja89zzy87q182zwh2mml8vq1zi1rhyo</sha1>
    </revision>
  </page>
  <page>
    <title>Dickson's lemma</title>
    <ns>0</ns>
    <id>357371</id>
    <revision>
      <id>846564985</id>
      <parentid>841566102</parentid>
      <timestamp>2018-06-19T14:59:30Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8131">In [[mathematics]], '''Dickson's lemma''' states that every set of &lt;math&gt;n&lt;/math&gt;-tuples of [[natural number]]s has finitely many [[minimal element]]s. This simple fact from [[combinatorics]] has become attributed to the American algebraist [[Leonard Dickson|L. E. Dickson]], who used it to prove a result in [[number theory]] about [[perfect number]]s.&lt;ref name="dickson"/&gt; However, the lemma was certainly known earlier, for example to [[Paul Gordan]] in his research on [[invariant theory]].&lt;ref name="buchberger"&gt;{{citation
 | last1 = Buchberger | first1 = Bruno | author1-link = Bruno Buchberger
 | last2 = Winkler | first2 = Franz
 | isbn = 9780521632980
 | page = 83
 | publisher = Cambridge University Press
 | series = London Mathematical Society Lecture Note Series
 | title = Gröbner Bases and Applications
 | url = https://books.google.com/books?id=tfa7dpQf1OIC&amp;pg=PA83
 | volume = 251
 | year = 1998}}.&lt;/ref&gt;

==Example==
[[File:Dickson hyperbola9.svg|thumb|240px|Infinitely many minimal pairs of real numbers ''x'',''y'' (the black hyperbola) but only five minimal pairs of positive integers (red) have ''xy''&amp;nbsp;≥&amp;nbsp;9.]]
Let &lt;math&gt;K&lt;/math&gt; be a fixed number, and let &lt;math&gt;S = \{(x,y)\mid xy\ge K\}&lt;/math&gt; be the set of pairs of numbers whose product is at least &lt;math&gt;K&lt;/math&gt;. When defined over the positive [[real number]]s, &lt;math&gt;S&lt;/math&gt; has infinitely many minimal elements of the form &lt;math&gt;(x,K/x)&lt;/math&gt;, one for each positive number &lt;math&gt;x&lt;/math&gt;; this set of points forms one of the branches of a [[hyperbola]]. The pairs on this hyperbola are minimal, because it is not possible for a different pair that belongs to &lt;math&gt;S&lt;/math&gt; to be less than or equal to &lt;math&gt;(x,K/x)&lt;/math&gt; in both of its coordinates. However, Dickson's lemma concerns only tuples of natural numbers, and over the natural numbers there are only finitely many minimal pairs. Every minimal pair &lt;math&gt;(x,y)&lt;/math&gt; of natural numbers has &lt;math&gt;x\le K&lt;/math&gt; and &lt;math&gt;y\le K&lt;/math&gt;, for if ''x'' were greater than ''K'' then (''x''&amp;nbsp;&amp;minus;1,''y'') would also belong to ''S'', contradicting the minimality of (''x'',''y''), and symmetrically if ''y'' were greater than ''K'' then (''x'',''y''&amp;nbsp;&amp;minus;1) would also belong to&amp;nbsp;''S''. Therefore, over the natural numbers, &lt;math&gt;S&lt;/math&gt; has at most &lt;math&gt;K^2&lt;/math&gt; minimal elements, a finite number.&lt;ref group=note&gt;With more care, it is possible to show that one of &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; is at most &lt;math&gt;\sqrt K&lt;/math&gt;, and that there is at most one minimal pair for each choice of one of the coordinates, from which it follows that there are at most &lt;math&gt;2\sqrt K&lt;/math&gt; minimal elements.&lt;/ref&gt;

==Formal statement==
Let &lt;math&gt;\mathbb{N}&lt;/math&gt; be the set of non-negative integers ([[natural numbers]]), let ''n'' be any fixed constant, and let &lt;math&gt;\mathbb{N}^n&lt;/math&gt; be the set of &lt;math&gt;n&lt;/math&gt;-tuples of natural numbers. These tuples may be given a [[pointwise]] [[partial order]], the [[product order]], in which &lt;math&gt;(a_1,a_2,\dots,a_n)\le (b_1,b_2,\dots b_n)&lt;/math&gt; if and only if, for every &lt;math&gt;i&lt;/math&gt;, &lt;math&gt;a_i\le b_i&lt;/math&gt;.
The set of tuples that are greater than or equal to some particular tuple &lt;math&gt;(a_1,a_2,\dots,a_n)&lt;/math&gt; forms a positive [[orthant]] with its apex at the given tuple.

With this notation, Dickson's lemma may be stated in several equivalent forms:
*In every subset &lt;math&gt;S\neq\emptyset&lt;/math&gt; of &lt;math&gt;\mathbb{N}^n&lt;/math&gt;, there is at least one but no more than a finite number of elements that are [[minimal element]]s of &lt;math&gt;S&lt;/math&gt; for the pointwise partial order.&lt;ref name="kruskal"&gt;{{cite journal | authorlink = Joseph Kruskal | last=Kruskal |first= Joseph B. | title=The theory of well-quasi-ordering: A frequently discovered concept | journal=[[Journal of Combinatorial Theory]] | series = Series A | year=1972 | volume=13 | page=298 | doi=10.1016/0097-3165(72)90063-5 | issue = 3}}&lt;/ref&gt;
*For every infinite sequence &lt;math&gt;(x_i)_{i\in\mathbb{N}}&lt;/math&gt; of &lt;math&gt;n&lt;/math&gt;-tuples of natural numbers, there exist two indices &lt;math&gt;i&lt;j&lt;/math&gt; such that &lt;math&gt;x_i \leq x_j&lt;/math&gt; holds with respect to the pointwise order.&lt;ref name="ffss"&gt;{{citation
 | last1 = Figueira | first1 = Diego
 | last2 = Figueira | first2 = Santiago
 | last3 = Schmitz | first3 = Sylvain
 | last4 = Schnoebelen | first4 = Philippe
 | arxiv = 1007.2989
 | contribution = Ackermannian and primitive-recursive bounds with Dickson's lemma
 | doi = 10.1109/LICS.2011.39
 | mr = 2858898
 | page = 269
 | publisher = IEEE Computer Soc., Los Alamitos, CA
 | title = 26th Annual IEEE Symposium on Logic in Computer Science (LICS 2011)
 | year = 2011}}.&lt;/ref&gt;
*The partially ordered set &lt;math&gt;(\mathbb{N}^n,\le)&lt;/math&gt; does not contain infinite [[antichain|antichains]] nor [[descending chain condition|infinite (strictly) descending sequences]] of &lt;math&gt;n&lt;/math&gt;-tuples.&lt;ref name="ffss" /&gt;
*The partially ordered set &lt;math&gt;(\mathbb{N}^n,\le)&lt;/math&gt; is a [[well-quasi-ordering|well partial order]].&lt;ref&gt;{{citation
 | last = Onn | first = Shmuel
 | editor1-last = Floudas | editor1-first = Christodoulos A.
 | editor2-last = Pardalos | editor2-first = Panos M.
 | arxiv = math/0703575
 | contribution = Convex Discrete Optimization
 | edition = 2nd
 | isbn = 9780387747583
 | pages = 513–550
 | publisher = Springer
 | title = Encyclopedia of Optimization, Vol. 1
 | year = 2008| bibcode = 2007math......3575O}}.&lt;/ref&gt;
*Every  subset &lt;math&gt;S&lt;/math&gt; of &lt;math&gt;\mathbb{N}^n&lt;/math&gt; may be covered by a finite set of positive orthants, whose apexes all belong to &lt;math&gt;S&lt;/math&gt;.

==Generalizations and applications==
Dickson used his lemma to prove that, for any given number &lt;math&gt;n&lt;/math&gt;, there can exist only a finite number of [[odd number|odd]] [[perfect number]]s that have at most &lt;math&gt;n&lt;/math&gt; [[prime factor]]s.&lt;ref name="dickson"&gt;{{citation
 | last = Dickson | first = L. E. | author-link = Leonard Dickson
 | doi = 10.2307/2370405
 | issue = 4
 | journal = American Journal of Mathematics
 | jstor = 2370405
 | pages = 413–422
 | title = Finiteness of the odd perfect and primitive abundant numbers with ''n'' distinct prime factors
 | volume = 35
 | year = 1913}}.&lt;/ref&gt; However, it remains open whether there exist any odd perfect numbers at all.

The [[divisibility]] relation among the [[smooth number|''P''-smooth numbers]], natural numbers whose prime factors all belong to the [[finite set]] ''P'', gives these numbers the structure of a partially ordered set isomorphic to &lt;math&gt;(\mathbb{N}^{|P|},\le)&lt;/math&gt;. Thus, for any set ''S'' of ''P''-smooth numbers, there is a finite subset of ''S'' such that every element of ''S'' is divisible by one of the numbers in this subset. This fact has been used, for instance, to show that there exists an [[algorithm]] for classifying the winning and losing moves from the initial position in the game of [[Sylver coinage]], even though the algorithm itself remains unknown.&lt;ref&gt;{{citation
 | last1 = Berlekamp | first1 = Elwyn R. | author1-link = Elwyn Berlekamp
 | last2 = Conway | first2 = John H.
 | last3 = Guy | first3 = Richard K.
 | contribution = 18 The Emperor and his Money
 | pages = 609–640
 | publisher = Academic Press
 | title = [[Winning Ways for your Mathematical Plays]], Vol. 3
 | year = 2003}}. See especially "Are outcomes computable", p. 630.&lt;/ref&gt;

The tuples &lt;math&gt;(a_1,a_2,\dots,a_n)&lt;/math&gt; in  &lt;math&gt;\mathbb{N}^n&lt;/math&gt; correspond one-for-one with the [[monomial]]s &lt;math&gt;x_1^{a_1}x_2^{a_2}\dots x_n^{a_n}&lt;/math&gt; over a set of &lt;math&gt;n&lt;/math&gt; variables &lt;math&gt;x_1,x_2,\dots x_n&lt;/math&gt;. Under this correspondence, Dickson's lemma may be seen as a special case of [[Hilbert's basis theorem]] stating that every [[Polynomial ring|polynomial]] [[ideal (ring theory)|ideal]] has a finite basis, for the ideals generated by monomials. Indeed, [[Paul Gordan]] used this restatement of Dickson's lemma in 1899 as part of a proof of Hilbert's basis theorem.&lt;ref name="buchberger"/&gt;

==See also==
*[[Gordan's lemma]]

==Notes==
{{reflist|group=note}}

==References==
{{reflist}}

[[Category:Combinatorics]]
[[Category:Lemmas]]
[[Category:Wellfoundedness]]</text>
      <sha1>dp5sst081q7fii22tmaqtg43r63kq4k</sha1>
    </revision>
  </page>
  <page>
    <title>Diffeomorphometry</title>
    <ns>0</ns>
    <id>55823152</id>
    <revision>
      <id>863182940</id>
      <parentid>858241430</parentid>
      <timestamp>2018-10-09T05:54:43Z</timestamp>
      <contributor>
        <ip>203.109.233.243</ip>
      </contributor>
      <comment>Removed image due to violation watermark/credit policy.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22354">{{Further|Computational anatomy}}

'''Diffeomorphometry''' is the metric study of imagery, shape and form in the discipline of [[computational anatomy]] (CA) in [[medical imaging]]. The study of [[image]]s{{disambiguation needed|date=January 2018}} in [[computational anatomy]] rely on high-dimensional [[diffeomorphism]] [[Group (mathematics)|groups]] &lt;math&gt; \varphi \in \operatorname{Diff}_V &lt;/math&gt; which generate orbits of the form  &lt;math&gt; \mathcal{I} \doteq

\{ \varphi \cdot I \mid \varphi \in \operatorname{Diff}_V \} &lt;/math&gt;, in which images &lt;math&gt; I \in \mathcal{I} &lt;/math&gt; can be dense scalar [[Magnetic resonance imaging|magnetic resonance]] or [[computed axial tomography]] images. For [[Deformable bodies|deformable shapes]] these are the collection of [[manifold]]s &lt;math&gt; \mathcal{M} \doteq

\{ \varphi \cdot M \mid \varphi \in \operatorname{Diff}_V \} &lt;/math&gt;,  points, [[Differential geometry of curves|curves]] and [[Surface (mathematics)|surface]]s. The diffeomorphisms move the images and shapes through the orbit according to &lt;math&gt;(\varphi,I)\mapsto \varphi \cdot I&lt;/math&gt; which are defined as the [[Group actions in computational anatomy|group actions of computational anatomy]].

The orbit of shapes and forms  is made into a metric space by inducing a metric on the group of diffeomorphisms.  &lt;nowiki/&gt;The study of metrics on groups of diffeomorphisms and the study of metrics between manifolds and surfaces has been an area of significant investigation.&lt;ref&gt;{{Cite journal|last=Miller|first=M. I.|last2=Younes|first2=L.|date=2001-01-01|title=Group Actions, Homeomorphisms, and Matching: A General Framework|journal=International Journal of Computer Vision|language=en|volume=41|issue=1–2|pages=61–84|doi=10.1023/A:1011161132514|issn=0920-5691}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Younes|first=L.|date=1998-04-01|title=Computable Elastic Distances Between Shapes|journal=SIAM Journal on Applied Mathematics|volume=58|issue=2|pages=565–586|doi=10.1137/S0036139995287685|citeseerx=10.1.1.45.503}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Mio|first=Washington|last2=Srivastava|first2=Anuj|last3=Joshi|first3=Shantanu|date=2006-09-25|title=On Shape of Plane Elastic Curves|journal=International Journal of Computer Vision|volume=73|issue=3|pages=307–324|doi=10.1007/s11263-006-9968-0|citeseerx=10.1.1.138.2219}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|arxiv=0706.4299|first=Peter W.|last=Michor|first2=David|last2=Mumford|title=A Metric on Shape Space with Explicit Geodesics|journal=Rend. Lincei Mat. Appl.  ()|volume=9|issue=2008|pages=25–57|date=2007-06-28|first3=Jayant|last3=Shah|first4=Laurent|last4=Younes|bibcode=2007arXiv0706.4299M}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Michor|first=Peter W.|last2=Mumford|first2=David|title=An overview of the Riemannian metrics on spaces of curves using the Hamiltonian approach|journal=Applied and Computational Harmonic Analysis|volume=23|issue=1|pages=74–113|arxiv=math/0605009|doi=10.1016/j.acha.2006.07.004|year=2007|bibcode=2010A&amp;CHA..28..171W}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Kurtek|first=Sebastian|last2=Klassen|first2=Eric|last3=Gore|first3=John C.|last4=Ding|first4=Zhaohua|last5=Srivastava|first5=Anuj|date=2012-09-01|title=Elastic geodesic paths in shape space of parameterized surfaces|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=34|issue=9|pages=1717–1730|doi=10.1109/TPAMI.2011.233|pmid=22144521}}&lt;/ref&gt; In Computational anatomy, the diffeomorphometry metric measures how close and far two shapes or images are from each other. Informally, the [[Metric space|metric]]  is constructed by defining a flow of diffemorphisms &lt;math&gt;\dot \phi_t , t \in [0,1], \phi_t \in \operatorname{Diff}_V&lt;/math&gt; which connect the group elements from one to another, so for &lt;math&gt; \varphi,\psi \in \operatorname{Diff}_V &lt;/math&gt; then &lt;math&gt;\phi_0 = \varphi , \phi_1=\psi&lt;/math&gt;.  The metric between two coordinate systems or diffeomorphisms is then the shortest length or [[Geodesic|geodesic flow]] connecting them. The metric on the space associated to the geodesics is given by&lt;math&gt;\rho(\varphi,\psi) = \inf_{\phi: \phi_0=\varphi,\phi_1 = \psi} \int_0^1 \| \dot \phi_t \|_{\phi_t} \, dt&lt;/math&gt;. The metrics on the orbits &lt;math&gt;\mathcal{I},\mathcal{M}&lt;/math&gt;  are inherited from the metric induced on the diffeomorphism group.&lt;nowiki/&gt;

The group &lt;math&gt; \varphi \in \operatorname{Diff}_V &lt;/math&gt; is thusly made into a smooth [[Riemannian manifold]] with Riemannian metric &lt;math&gt; \| \cdot \|_\varphi  &lt;/math&gt;  associated to the tangent spaces at all &lt;math&gt; \varphi \in\operatorname{Diff}_V &lt;/math&gt;. The  &lt;nowiki/&gt;[[Riemannian metric]] satisfies at every point of the manifold &lt;math&gt; \phi \in \operatorname{Diff}_V &lt;/math&gt; there is an  [[Inner product space|inner product]] inducing the norm  on the [[tangent space]] &lt;math&gt; \| \dot \phi_t  \|_{\phi_t} &lt;/math&gt;  that varies smoothly across &lt;math&gt; \operatorname{Diff}_V &lt;/math&gt;.

Oftentimes, the familiar [[Euclidean distance|Euclidean metric]] is not directly applicable because the patterns of shapes and images don't form a [[vector space]]. In the [[Riemannian Metric and Lie-Bracket Interpretation of the Euler Equation on Geodesics|Riemannian orbit model of Computational anatomy]], diffeomorphisms acting on the forms &lt;math&gt;\varphi \cdot I \in \mathcal {I}, \varphi \in \operatorname{Diff}_V, M \in \mathcal{M}&lt;/math&gt; don't act linearly. There are many ways to define metrics, and for the sets associated to shapes the [[Hausdorff metric]] is another. The method used to induce the [[Riemannian metric]] is to induce the metric on the orbit of shapes by defining it in terms of the metric length between diffeomorphic coordinate system transformations of the flows. Measuring the lengths of the geodesic flow between coordinates systems in the orbit of shapes is called '''diffeomorphometry'''.

== The diffeomorphisms group generated as Lagrangian and Eulerian flows ==

The diffeomorphisms in [[computational anatomy]] are generated to satisfy the [[Computational anatomy#Lagrangian and Eulerian flows for generating diffeomorphisms|Lagrangian and Eulerian specification of the flow fields]], &lt;math&gt; \varphi_t,  t \in [0,1] &lt;/math&gt;, generated via the ordinary differential equation{{NumBlk|:|&lt;math&gt;

\frac{d}{dt} \varphi_t = v_t \circ \varphi_t , \ \varphi_0 = \operatorname{id}; &lt;/math&gt;|{{EquationRef|Lagrangian flow}}}}

with the Eulerian vector fields &lt;math&gt; v \doteq (v_1,v_2,v_3) &lt;/math&gt; in &lt;math&gt;  {\mathbb R}^3   &lt;/math&gt;  for &lt;math&gt;v_t = \dot \varphi_t \circ \varphi_t^{-1}, t \in [0,1]&lt;/math&gt;. The inverse for the flow is given by
&lt;math&gt;
 \frac{d}{dt} \varphi_t^{-1} = -(D \varphi_t^{-1}) v_t, \ \varphi_0^{-1} = \operatorname{id}, &lt;/math&gt;
and the &lt;math&gt;3 \times 3&lt;/math&gt; Jacobian matrix for flows in &lt;math&gt;\mathbb{R}^3&lt;/math&gt;  given as &lt;math&gt; \ D\varphi \doteq \left(\frac{\partial \varphi_i}{\partial x_j}\right). &lt;/math&gt;

To ensure smooth flows of diffeomorphisms with inverse,  the vector fields &lt;math&gt;  {\mathbb R}^3   &lt;/math&gt; must be at least 1-time continuously differentiable in space&lt;ref name=":22"&gt;P. Dupuis, U. Grenander, M.I. Miller, Existence of Solutions on Flows of Diffeomorphisms, Quarterly of Applied Math, 1997.&lt;/ref&gt;&lt;ref name=":4"&gt;A. Trouvé. Action de groupe de dimension infinie et reconnaissance de formes. C R Acad Sci Paris Sér I Math, 321(8):1031– 1034, 1995.&lt;/ref&gt; which are modelled as elements of the Hilbert space  &lt;math&gt;(V, \| \cdot \|_V )&lt;/math&gt; using the [[Sobolev space|Sobolev]] embedding theorems so that each element &lt;math&gt;v_i \in H_0^3, i=1,2,3,&lt;/math&gt; has 3-square-integrable derivatives thusly implies &lt;math&gt;(V, \| \cdot \|_V )&lt;/math&gt; embeds smoothly in 1-time continuously differentiable functions.&lt;ref name=":22" /&gt;&lt;ref name=":4" /&gt;  The diffeomorphism group are flows with vector fields absolutely integrable in Sobolev norm:{{NumBlk|:|&lt;math&gt;

\operatorname{Diff}_V \doteq \{\varphi=\varphi_1: \dot \varphi_t = v_t \circ \varphi_t , \varphi_0 = \operatorname{id}, \int_0^1 \|v_t \|_V \,dt &lt; \infty \} \ .

&lt;/math&gt;|{{EquationRef|Diffeomorphism Group}}}}

==The Riemannian orbit model==

Shapes in [[Computational anatomy|Computational Anatomy (CA)]] &lt;nowiki/&gt;are studied via the use of diffeomorphic mapping for establishing correspondences between anatomical coordinate systems. In this setting, 3-dimensional medical images are modelled as diffemorphic transformations of some exemplar, termed the template &lt;math&gt; I_{temp} &lt;/math&gt;, resulting in the observed images to be elements of the random [[Computational anatomy#The deformable template orbit model of CA|orbit model of CA]]. For images these are defined as &lt;math&gt; I \in \mathcal {I}

\doteq \{ I = I_{temp} \circ \varphi, \varphi \in \operatorname{Diff}_V \} &lt;/math&gt;, with for charts representing sub-manifolds denoted as &lt;math&gt;\mathcal{M} \doteq \{ \varphi \cdot M_{temp} : \varphi \in \operatorname{Diff}_V \}&lt;/math&gt;.

===The Riemannian metric===

The orbit of shapes and forms in Computational Anatomy  are generated by the group action &lt;math&gt;\mathcal{I} \doteq \{ \varphi \cdot I : \varphi \in \operatorname{Diff}_V \}&lt;/math&gt; , &lt;math&gt;\mathcal{M} \doteq \{ \varphi \cdot M : \varphi \in \operatorname{Diff}_V \}&lt;/math&gt;.   These are made into a Riemannian orbits by introducing a metric associated to each point and associated tangent space. For this a metric is defined on the group which induces the metric on the orbit. Take as the metric for [[Computational anatomy]] at each element of the tangent space &lt;math&gt;\varphi \in \operatorname{Diff}_V&lt;/math&gt; in the group of diffeomorphisms

:&lt;math&gt; \| \dot \varphi \|_\varphi \doteq \| \dot \varphi \circ \varphi^{-1} \|_V=\| v \|_V, &lt;/math&gt;

with the vector fields modelled to be in a Hilbert space with the norm in the [[Hilbert space]] &lt;math&gt;(V, \| \cdot \|_V )&lt;/math&gt;. We model &lt;math&gt;V&lt;/math&gt; as a [[Reproducing kernel Hilbert space|reproducing kernel Hilbert space (RKHS)]] defined by a 1-1, differential operator &lt;math&gt; A: V \rightarrow V^*  &lt;/math&gt;, where &lt;math&gt; V^*  &lt;/math&gt; is the dual-space. In general,   &lt;math&gt; \sigma \doteq Av \in V^* &lt;/math&gt; is a generalized function or distribution, the linear form  associated to the inner-product and norm for generalized functions are interpreted by integration by parts according to for &lt;math&gt;v,w \in V&lt;/math&gt;,

:&lt;math&gt; \langle v , w \rangle_V \doteq \int_X A v \cdot w \, dx, \ \| v\|_V^2 \doteq \int_X A v \cdot v \, dx, \ v,w \in V \ .
&lt;/math&gt;

When &lt;math&gt; Av \doteq \mu \,dx &lt;/math&gt;, a vector density, &lt;math&gt;\int Av \cdot v \,dx \doteq \int \mu \cdot v \, dx = \sum_{i=1}^3 \mu_i v_i \, dx.&lt;/math&gt;

The differential operator is selected so that the [[Green's function|Green's kernel]] associated to the inverse is sufficiently smooth so that the [[Computational anatomy#The Smoothness Condition on Vector fields as Modelled in a Reproducing kernel Hilbert space|vector fields support 1-continuous derivative]]. The [[Sobolev embedding]] theorem arguments were made in demonstrating that 1-continuous derivative is required for smooth flows. The [[Green's function for the three-variable Laplace equation|Green's]] operator generated from the [[Green's function]](scalar case) associated to the differential operator smooths.

For proper choice of &lt;math&gt;A&lt;/math&gt; then &lt;math&gt; (V,\| \cdot \|_V) &lt;/math&gt; is an RKHS with the operator &lt;math&gt; K = A^{-1}: V^* \rightarrow V &lt;/math&gt;.  The Green's kernels associated to the differential operator smooths since for controlling enough derivatives in the square-integral sense the kernel  &lt;math&gt; k(\cdot,\cdot)

&lt;/math&gt; is continuously differentiable in both variables implying

:&lt;math&gt; K Av (x)_i \doteq \sum_j \int_{{\mathbb R}^3}  k_{ij}(x,y) Av_j(y) \,dy \in V \ .
&lt;/math&gt;

== The diffeomorphometry of the space of shapes and forms ==

===The right-invariant metric on diffeomorphisms===

The metric on the group of diffeomorphisms is defined by the distance as defined on pairs of elements in the group of diffeomorphisms according to
: {{NumBlk||&lt;math&gt;
d_{\mathrm{Diff}_V}(\psi, \varphi) = \inf_{v_t} \left(\int_0^1 \int_X Av_t \cdot v_t \, dx \, dt: \phi_0 = \psi, \phi_1 = \varphi, \dot \phi_t = v_t \circ \phi_t \right)^{1/2} \ .
&lt;/math&gt;|{{EquationRef|metric-diffeomorphisms}}}}This distance provides a right-invariant metric of diffeomorphometry,&lt;ref&gt;{{Cite journal|last=Miller|first=M. I.|last2=Younes|first2=L.|date=2001-01-01|title=Group Actions, Homeomorphisms, And Matching: A General Framework|journal=International Journal of Computer Vision|volume=41|pages=61–84|citeseerx=10.1.1.37.4816}}&lt;/ref&gt;&lt;ref name="pmid24904924" &gt;{{cite journal|pmid=24904924|pmc=4041578|year=2014|author1=Miller|first1=M. I|title=Diffeomorphometry and geodesic positioning systems for human anatomy|journal=Technology|volume=2|issue=1|pages=36|last2=Younes|first2=L|last3=Trouvé|first3=A|doi=10.1142/S2339547814500010}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Miller|first=Michael I.|last2=Trouvé|first2=Alain|last3=Younes|first3=Laurent|date=2015-01-01|title=Hamiltonian Systems and Optimal Control in Computational Anatomy: 100 Years Since D'Arcy Thompson|journal=Annual Review of Biomedical Engineering|volume=17|issue=1|pages=447–509|doi=10.1146/annurev-bioeng-071114-040601|pmid=26643025}}&lt;/ref&gt; invariant to reparameterization of space since for all &lt;math&gt; \phi \in \operatorname{Diff}_V &lt;/math&gt;,

:&lt;math&gt; d_{\operatorname{Diff}_V}(\psi, \varphi) = d_{\operatorname{Diff}_V}(\psi \circ \phi, \varphi \circ \phi).&lt;/math&gt;

===The metric on shapes and forms===

The distance on images,&lt;ref&gt;{{Cite journal|title = Group Actions, Homeomorphisms, And Matching: A General Framework|journal = International Journal of Computer Vision|date = 2001-01-01|pages = 61–84|volume = 41|first = M. I.|last = Miller|first2 = L.|last2 = Younes|citeseerx = 10.1.1.37.4816}}&lt;/ref&gt; &lt;math&gt; d_{\mathcal{I}}:\mathcal{I}  \times \mathcal{I}\rightarrow \R^+ &lt;/math&gt;,

{{NumBlk||&lt;math&gt;

d_{\mathcal{I}}(I,J)=\inf_{\phi \in \operatorname{Diff}_V: \phi \cdot I = J } d_{\operatorname{Diff}_V}(id,\phi) \ ;

&lt;/math&gt;|{{EquationRef|metric-shapes-forms}}}}

The distance on shapes and forms,&lt;ref&gt;{{Cite journal|last=Miller|first=Michael I.|last2=Younes|first2=Laurent|last3=Trouvé|first3=Alain|date=March 2014|title=Diffeomorphometry and geodesic positioning systems for human anatomy|journal=Technology|volume=2|issue=1|pages=36|doi=10.1142/S2339547814500010|issn=2339-5478|pmc=4041578|pmid=24904924}}&lt;/ref&gt; &lt;math&gt; d_{\mathcal{M}}:\mathcal{M}  \times \mathcal{M}\rightarrow \R^+ &lt;/math&gt;,

{{NumBlk||&lt;math&gt;

d_{\mathcal{M}} (M,N) = \inf_{\phi \in \operatorname{Diff}_V: \phi \cdot M = N } d_{\mathrm{Diff}_V}(\operatorname{id},\phi) \ .

&lt;/math&gt;|{{EquationRef|metric-shapes-forms}}}}

==The metric on geodesic flows of landmarks, surfaces, and volumes within the orbit==

For calculating the metric, the geodesics are a dynamical system, the flow of coordinates &lt;math&gt; t \mapsto \phi_t \in \operatorname{Diff}_V &lt;/math&gt; and the control the vector field &lt;math&gt; t \mapsto v_t \in V&lt;/math&gt; related via &lt;math&gt; \dot \phi_t = v_t \cdot \phi_t,\phi_0=\operatorname{id}. &lt;/math&gt;  The Hamiltonian view
&lt;ref name="Miller null2"&gt;{{Cite journal|title = Hamiltonian Systems and Optimal Control in Computational Anatomy: 100 Years Since D'arcy Thompson |journal = Annual Review of Biomedical Engineering|date = 2015-01-01|pages = null|volume = 17|issue = 1|doi = 10.1146/annurev-bioeng-071114-040601|first = Michael I.|last = Miller|first2 = Alain|last2 = Trouvé|first3 = Laurent|last3 = Younes|pmid=26643025}}&lt;/ref&gt;
&lt;ref&gt;Glaunès J, Trouvé A, Younes L. 2006. Modeling planar shape variation via Hamiltonian flows of curves.
In Statistics and Analysis of Shapes, ed. H Krim, A Yezzi Jr, pp. 335–61. Model. Simul. Sci. Eng. Technol.
Boston: Birkhauser
&lt;/ref&gt;
&lt;ref&gt;Arguillère S, Trélat E, Trouvé A, Younes L. 2014. Shape deformation analysis from the optimal control
viewpoint. arXiv:1401.0661 [math.OC]
&lt;/ref&gt;
&lt;ref&gt;Michael I. Miller, Laurent Younes, and Alain Trouvé, Diffeomorphometry and geodesic positioning systems for human anatomy, Technology 02, 36 (2014). {{doi|10.1142/S2339547814500010}}
&lt;/ref&gt;&lt;ref&gt;{{Cite journal|title = An overview of the Riemannian metrics on spaces of curves using the Hamiltonian approach |journal = Applied and Computational Harmonic Analysis|date = 2007-07-01|pages = 74–113|volume = 23|series = Special Issue on Mathematical Imaging|issue = 1|doi = 10.1016/j.acha.2006.07.004|first = Peter W.|last = Michor|first2 = David|last2 = Mumford|bibcode = 2010A&amp;CHA..28..171W}}&lt;/ref&gt; reparameterizes the momentum distribution &lt;math&gt; Av \in V^* &lt;/math&gt; in terms of the '''''Hamiltonian momentum''','' a Lagrange multiplier &lt;math&gt; p: \dot \phi \mapsto (p\mid\dot \phi) &lt;/math&gt; constraining the Lagrangian velocity &lt;math&gt; \dot \phi_t = v_t \circ \phi_t&lt;/math&gt;.accordingly:
:&lt;math&gt;
H(\phi_t,p_t,v_t)=\int_X p_t \cdot (v_t \circ \phi_t) \, dx-\frac{1}{2}\int_X Av_t \cdot v_t \, dx .&lt;/math&gt;
The [[Pontryagin maximum principle]]&lt;ref name="Miller null2" /&gt; gives the Hamiltonian &lt;math&gt; H(\phi_t,p_t) \doteq \max_v H( \phi_t, p_t,v) \ . &lt;/math&gt;
The optimizing vector field &lt;math&gt;v_t \doteq \operatorname{argmax}_v H(\phi_t,p_t,v)&lt;/math&gt; with dynamics &lt;math&gt; 
\dot \phi_t = \frac{\partial H( \phi_t, p_t)}{\partial p},
\dot p_t = -\frac{\partial H(\phi_t,p_t)}{\partial \phi}
&lt;/math&gt;. Along the geodesic the Hamiltonian is constant:&lt;ref&gt;{{Cite journal|title = Hamiltonian Systems and Optimal Control in Computational Anatomy: 100 Years Since D'Arcy Thompson |journal = Annual Review of Biomedical Engineering|date = 2015-01-01|pmid = 26643025|pages = 447–509|volume = 17|issue = 1|doi = 10.1146/annurev-bioeng-071114-040601|first = Michael I.|last = Miller|first2 = Alain|last2 = Trouvé|first3 = Laurent|last3 = Younes}}&lt;/ref&gt;
&lt;math&gt;H(\phi_t,p_t) = H(\operatorname{id},p_0)=\frac{1}{2} \int_X p_0 \cdot v_0 \, dx
 &lt;/math&gt;. The metric distance between coordinate systems connected via the geodesic determined by the induced distance between identity and group element:
:&lt;math&gt;d_{\mathrm{Diff}_V}(\operatorname{id},\varphi) =\| v_0 \|_V = \sqrt{2H(\operatorname{id},p_0)}&lt;/math&gt;

===Landmark or pointset geodesics===

For '''landmarks''', &lt;math&gt; x_i, i=1,\dots,n&lt;/math&gt;, the Hamiltonian momentum

: &lt;math&gt; p(i), i=1,\dots,n&lt;/math&gt;
with Hamiltonian  dynamics taking the form

: &lt;math&gt; H(\phi_t,p_t) =\frac{1}{2}\textstyle \sum_j \sum_i \displaystyle  p_t(i)\cdot K(\phi_t (x_i),\phi_t (x_j)) p_t(j) &lt;/math&gt;
with
:&lt;math&gt;
\begin{cases}
v_t =  \textstyle \sum_i \displaystyle  K(\cdot, \phi_t (x_i)) p_t(i)  , \ \\
\dot p_t (i) = - (Dv_t)^T_{|_{\phi_t(x_i)}} p_t(i), i=1,2,\dots, n
\\
\end{cases}  &lt;/math&gt;
The metric between landmarks &lt;math&gt; 
d^2 =\textstyle \sum_i p_0(i)\cdot \sum_j \displaystyle K(x_i,x_j) p_0(j). &lt;/math&gt;

The dynamics associated to these geodesics is shown in the accompanying figure.

===Surface geodesics===
For '''surfaces''', the Hamiltonian momentum is defined across the surface has Hamiltonian

: &lt;math&gt;H(\phi_t,p_t) =\frac{1}{2} \int_U \int_U p_t(u)\cdot K(\phi_t (m(u)), \phi_t (m(v))) p_t(v) \, du \, dv &lt;/math&gt;
and dynamics
:&lt;math&gt;
\begin{cases}
v_t= \textstyle \int_U \displaystyle K(\cdot, \phi_t ( m(u)))p_t(u)\,du \ ,
\\
\dot p_t(u) = - (Dv_t)^T_{|_{\phi_t(m(u))} } p_t(u), u \in U
\end{cases}  &lt;/math&gt;
:The metric between surface coordinates &lt;math&gt;d^2 = (p_0 \mid v_0) =\int_U p_0(u) \cdot \int_U K(m(u), m(u^\prime)) p_0(u^\prime) \, du \, du^\prime &lt;/math&gt;

===Volume geodesics===
For '''volumes''' the Hamiltonian

: &lt;math&gt; H(\phi_t,p_t) = \frac{1}{2}\int_{{\mathbb R}^3} \int_{{\mathbb R}^3}  p_t(x)\cdot K(\phi_t(x),\phi_t(y)) p_t(y) \, dx \, dy \displaystyle &lt;/math&gt;

with dynamics

: &lt;math&gt;
\begin{cases}
v_t=\textstyle \int_X \displaystyle K(\cdot, \phi_t(x))p_t(x)\,dx \ ,
\\
\dot p_t(x) = - (Dv_t)^T_{|_{\phi_t(x)} } p_t(x), x \in {\mathbb R}^3
\end{cases} &lt;/math&gt; 
:The metric between volumes &lt;math&gt;
\displaystyle d^2  =(p_0\mid v_0) = \int_{\mathbb R^3}   p_0(x)\cdot \int_{{\mathbb R}^3}  K(x,y) p_0(y)\,dy \, dx.&lt;/math&gt;

== Software for diffeomorphic mapping ==
[[Software suite]]s containing a variety of diffeomorphic mapping algorithms include the following:
* Deformetrica&lt;ref&gt;{{cite web|title=Software - Stanley Durrleman|url=https://raweb.inria.fr/rapportsactivite/RA2015/aramis/uid32.html}}&lt;/ref&gt;
* ANTS&lt;ref&gt;{{Cite journal|last=Avants|first=Brian B.|last2=Tustison|first2=Nicholas J.|last3=Song|first3=Gang|last4=Cook|first4=Philip A.|last5=Klein|first5=Arno|last6=Gee|first6=James C.|date=2011-02-01|title=A Reproducible Evaluation of ANTs Similarity Metric Performance in Brain Image Registration|journal=NeuroImage|volume=54|issue=3|pages=2033–2044|doi=10.1016/j.neuroimage.2010.09.025|issn=1053-8119|pmc=3065962|pmid=20851191}}&lt;/ref&gt;
* DARTEL&lt;ref&gt;{{Cite journal|title = A fast diffeomorphic image registration algorithm |journal = NeuroImage|date = 2007-10-15|pmid = 17761438|pages = 95–113|volume = 38|issue = 1|doi = 10.1016/j.neuroimage.2007.07.007|first = John|last = Ashburner}}&lt;/ref&gt; [[Voxel-based morphometry]](VBM)
* DEMONS&lt;ref&gt;{{cite web|title = Software - Tom Vercauteren|url = https://sites.google.com/site/tomvercauteren/software|website = sites.google.com|accessdate = 2015-12-11}}&lt;/ref&gt;
* [[Large deformation diffeomorphic metric mapping|LDDMM]]&lt;ref&gt;{{Cite journal|last=Beg|first=M. Faisal|last2=Miller|first2=Michael I.|last3=Trouvé|first3=Alain|last4=Younes|first4=Laurent|date=2005-02-01|title=Computing Large Deformation Metric Mappings via Geodesic Flows of Diffeomorphisms|journal=International Journal of Computer Vision|language=en|volume=61|issue=2|pages=139–157|doi=10.1023/B:VISI.0000043755.93987.aa|issn=0920-5691}}&lt;/ref&gt;
* StationaryLDDMM&lt;ref&gt;{{Cite web|url=https://www.researchgate.net/publication/33419970|title=Comparing algorithms for diffeomorphic registration: Stationary LDDMM and Diffeomorphic Demons (PDF Download Available)|website=ResearchGate|language=en|access-date=2017-12-02}}&lt;/ref&gt;

=== Cloud software ===
* MRICloud&lt;ref&gt;{{cite web|url=http://www.mricloud.org|title=MRICloud|website=|publisher=The Johns Hopkins University|access-date=1 January 2015}}&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Computational anatomy]]
[[Category:Medical imaging]]
[[Category:Geometry]]
[[Category:Mathematical analysis]]
[[Category:Physics]]
[[Category:Fluid mechanics]]
[[Category:Bayesian estimation]]
[[Category:Neuroscience]]
[[Category:Neural engineering]]
[[Category:Biomedical engineering]]</text>
      <sha1>tdq8pfxh9lhiqji0q81pjd8gs649cm7</sha1>
    </revision>
  </page>
  <page>
    <title>Eleven-point conic</title>
    <ns>0</ns>
    <id>35675213</id>
    <revision>
      <id>746874931</id>
      <parentid>735025605</parentid>
      <timestamp>2016-10-30T02:57:20Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* References */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1305">In geometry, an '''eleven-point conic''' is a [[conic]] associated to four points and a line, containing 11 special points.{{harv|Baker|1922|loc= p. 49}}

==References==
*{{Citation | authorlink=H. F. Baker | last1=Baker | first1=Henry Frederick | title=Principles of geometry. Volume 2. Plane geometry, Conics, circles, non-Euclidean geometry | url=https://archive.org/details/principlesofgeom02bake | publisher=[[Cambridge University Press]] | series=Cambridge Library Collection | isbn=978-1-108-01778-7  | mr=2857757 | year=1922}}. Reprinted in 2010.
*{{Citation | last1=Mulherin | first1=Maria Virginia | title=A Study of the Eleven-point Conic as a General Case of the Nine-point Circle | url=https://books.google.com/books?id=eLKdNwAACAAJ | publisher=Catholic University of America | year=1941}}
*{{Citation | last1=Singh | first1=Kuldip | title=Applications of the Eleven-Point Conic | jstor=2308410 | publisher=[[Mathematical Association of America]] | year=1953 | journal=[[American Mathematical Monthly|The American Mathematical Monthly]] | issn=0002-9890 | volume=60 | issue=7 | pages=468–474}}

==External links==
*[http://www.math.uoc.gr/~pamfilos/eGallery/problems/ElevenPointConic.html Eleven-point conic]

[[Category:Projective geometry]]
[[Category:Conic sections]]


{{geometry-stub}}</text>
      <sha1>ihbat9p6dhr3gan1bqqgj3lccyxau4g</sha1>
    </revision>
  </page>
  <page>
    <title>Euclidean random matrix</title>
    <ns>0</ns>
    <id>34289077</id>
    <revision>
      <id>862708919</id>
      <parentid>853934267</parentid>
      <timestamp>2018-10-06T05:16:57Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8202">{{context|date=May 2012}}
An ''N''×''N'' '''Euclidean random matrix''' Â is defined with the help of an arbitrary deterministic function ''f''('''r''', '''r'''′) and of ''N'' points {'''r'''&lt;sub&gt;i&lt;/sub&gt;} randomly distributed in a region ''V'' of ''d''-dimensional [[Euclidean space]]. The element A&lt;sub&gt;ij&lt;/sub&gt; of the matrix is equal to ''f''('''r'''&lt;sub&gt;i&lt;/sub&gt;, '''r'''&lt;sub&gt;j&lt;/sub&gt;): A&lt;sub&gt;ij&lt;/sub&gt; = ''f''('''r'''&lt;sub&gt;i&lt;/sub&gt;, '''r'''&lt;sub&gt;j&lt;/sub&gt;).

== History ==
Euclidean random matrices were first introduced in 1999.&lt;ref name=mezard99&gt;{{Cite journal | last1 = Mezard | first1 = M.| last2 = Parisi | first2 = G.| last3 = Zee | first3 = A. | title = Spectra of euclidean random matrices | doi = 10.1016/S0550-3213(99)00428-9 | journal = Nuclear Physics B | volume = 559 | issue = 3 | pages = 689–701| year = 1999 | pmid =  | pmc = |arxiv = cond-mat/9906135 |bibcode = 1999NuPhB.559..689M }}&lt;/ref&gt; They studied a special case of functions ''f'' that depend only on the distances between the pairs of points: ''f''('''r''', '''r'''′) = ''f''('''r''' - '''r'''′) and imposed an additional condition on the diagonal elements A&lt;sub&gt;ii&lt;/sub&gt;,

:A&lt;sub&gt;ij&lt;/sub&gt; = ''f''('''r'''&lt;sub&gt;i&lt;/sub&gt; - '''r'''&lt;sub&gt;j&lt;/sub&gt;) - u δ&lt;sub&gt;ij&lt;/sub&gt;∑&lt;sub&gt;k&lt;/sub&gt;''f''('''r'''&lt;sub&gt;i&lt;/sub&gt; - '''r'''&lt;sub&gt;k&lt;/sub&gt;),
 
motivated by the physical context in which they studied the matrix.
A [[Euclidean distance matrix]] is a particular example of Euclidean random matrix with either ''f''('''r'''&lt;sub&gt;i&lt;/sub&gt; - '''r'''&lt;sub&gt;j&lt;/sub&gt;) = |'''r'''&lt;sub&gt;i&lt;/sub&gt; - '''r'''&lt;sub&gt;j&lt;/sub&gt;|&lt;sup&gt;2&lt;/sup&gt; or ''f''('''r'''&lt;sub&gt;i&lt;/sub&gt; - '''r'''&lt;sub&gt;j&lt;/sub&gt;) = |'''r'''&lt;sub&gt;i&lt;/sub&gt; - '''r'''&lt;sub&gt;j&lt;/sub&gt;|.&lt;ref name=bogo03&gt;{{Cite journal | last1 = Bogomolny | first1 = E. | last2 = Bohigas | first2 = O. | last3 = Schmit | first3 = C. | doi = 10.1088/0305-4470/36/12/341 | title = Spectral properties of distance matrices | journal = Journal of Physics A: Mathematical and General | volume = 36 | issue = 12 | pages = 3595–3616 | year = 2003 | pmid =  | pmc = |arxiv = nlin/0301044 |bibcode = 2003JPhA...36.3595B }}&lt;/ref&gt;

For example, in many biological networks, the strength of interaction between two nodes depends on the physical proximity of those nodes. Spatial interactions between nodes can be modelled as a Euclidean random matrix, if nodes are placed randomly in space.&lt;ref&gt;{{cite journal|last1=Muir|first1=Dylan|last2=Mrsic-Flogel|first2=Thomas|title=Eigenspectrum bounds for semirandom matrices with modular and spatial structure for neural networks|journal=Phys. Rev. E|date=2015|volume=91|page=042808|doi=10.1103/PhysRevE.91.042808|url=http://journals.aps.org/pre/abstract/10.1103/PhysRevE.91.042808|bibcode=2015PhRvE..91d2808M}}&lt;/ref&gt;&lt;ref name="Grilli2015"&gt;{{cite journal|last1=Grilli|first1=Jacopo|last2=Barabás|first2=György|last3=Allesina|first3=Stefano|title=Metapopulation Persistence in Random Fragmented Landscapes|journal=PLOS Computational Biology|volume=11|issue=5|year=2015|pages=e1004251|issn=1553-7358|doi=10.1371/journal.pcbi.1004251|bibcode=2015PLSCB..11E4251G}}&lt;/ref&gt;

== Properties ==
Because the positions of the points {'''r'''&lt;sub&gt;i&lt;/sub&gt;} are random, the matrix elements A&lt;sub&gt;ij&lt;/sub&gt; are random too. Moreover, because the ''N''×''N'' elements are completely determined by only ''N'' points and, typically, one is interested in ''N''≫''d'', strong correlations exist between different elements.

[[File:Fig sinc.png|thumb|340px|alt=Example 1 | Example of the probability distribution of eigenvalues Λ of the Euclidean random matrix generated by the function ''f''('''r''', '''r'''′) = sin(''k''&lt;sub&gt;0&lt;/sub&gt;ǀ'''r'''-'''r'''′ǀ)/(''k''&lt;sub&gt;0&lt;/sub&gt;ǀ'''r'''-'''r'''′ǀ), with ''k''&lt;sub&gt;0&lt;/sub&gt; = 2π/λ&lt;sub&gt;0&lt;/sub&gt;. The Marchenko-Pastur distribution (red) is compared with the result of numerical diagonalization of a set of randomly generated matrices of size ''N''×''N''. The density of points is ρλ&lt;sub&gt;0&lt;/sub&gt;&lt;sup&gt;3&lt;/sup&gt; = 0.1.]]

=== Hermitian Euclidean random matrices ===

[[Hermitian matrix|Hermitian]] Euclidean random matrices appear in various physical contexts, including supercooled liquids,&lt;ref name=grigera03&gt;{{Cite journal | last1 = Grigera | first1 = T. S. | last2 = Martín-Mayor | first2 = V. | last3 = Parisi | first3 = G. | last4 = Verrocchio | first4 = P. | title = Phonon interpretation of the 'boson peak' in supercooled liquids | doi = 10.1038/nature01475 | journal = Nature | volume = 422 | issue = 6929 | pages = 289–292 | year = 2003 | pmid =  12646916| pmc = |bibcode = 2003Natur.422..289G }}&lt;/ref&gt; phonons in disordered systems,&lt;ref name=amir10&gt;{{Cite journal | last1 = Amir | first1 = A. | last2 = Oreg | first2 = Y. | last3 = Imry | first3 = Y. | title = Localization, Anomalous Diffusion, and Slow Relaxations: A Random Distance Matrix Approach | doi = 10.1103/PhysRevLett.105.070601 | journal = Physical Review Letters | volume = 105 | issue = 7 | year = 2010 | pmid =  20868026| pmc = |arxiv = 1002.2123 |bibcode = 2010PhRvL.105g0601A | page=070601}}&lt;/ref&gt; and waves in random media.&lt;ref name=skipetrov11&gt;{{Cite journal | last1 = Skipetrov | first1 = S. E. | last2 = Goetschy | first2 = A. | doi = 10.1088/1751-8113/44/6/065102 | title = Eigenvalue distributions of large Euclidean random matrices for waves in random media | journal = Journal of Physics A: Mathematical and Theoretical | volume = 44 | issue = 6 | pages = 065102 | year = 2011 | pmid =  | pmc = |arxiv = 1007.1379 |bibcode = 2011JPhA...44f5102S }}&lt;/ref&gt;

''Example 1:'' Consider the matrix Â generated by the function ''f''('''r''', '''r'''′) = sin(''k''&lt;sub&gt;0&lt;/sub&gt;|'''r'''-'''r'''′|)/(''k''&lt;sub&gt;0&lt;/sub&gt;|'''r'''-'''r'''′|), with ''k''&lt;sub&gt;0&lt;/sub&gt; = 2π/λ&lt;sub&gt;0&lt;/sub&gt;. This matrix is [[Hermitian matrix|Hermitian]] and its [[eigenvalue]]s Λ are [[Real number|real]]. For ''N'' points distributed randomly in a cube of side ''L'' and volume ''V'' = ''L''&lt;sup&gt;3&lt;/sup&gt;, one can show&lt;ref name=skipetrov11/&gt; that the probability distribution of Λ is approximately given by the [[Marchenko–Pastur distribution|Marchenko-Pastur law]], if the density of points ρ = ''N''/''V'' obeys ρλ&lt;sub&gt;0&lt;/sub&gt;&lt;sup&gt;3&lt;/sup&gt; ≤ 1 and 2.8''N''/(''k''&lt;sub&gt;0&lt;/sub&gt; ''L'')&lt;sup&gt;2&lt;/sup&gt; &lt; 1 (see figure).

{{clear}}

[[File:Fig expc.png|thumb|340px|alt=Example 2 | Example of the probability distribution of eigenvalues Λ of the Euclidean random matrix generated by the function ''f''('''r''', '''r'''′) = exp(''ik''&lt;sub&gt;0&lt;/sub&gt;ǀ'''r'''-'''r'''′ǀ)/(''k''&lt;sub&gt;0&lt;/sub&gt;ǀ'''r'''-'''r'''′ǀ), with ''k''&lt;sub&gt;0&lt;/sub&gt; = 2π/λ&lt;sub&gt;0&lt;/sub&gt; and ''f''('''r'''= '''r'''′) = 0.]]

=== Non-Hermitian Euclidean random matrices ===

A theory for the [[eigenvalue]] density of large (''N''≫1) non-Hermitian Euclidean random matrices has been developed&lt;ref name=goetschy11a&gt;{{Cite journal | last1 = Goetschy | first1 = A. | last2 = Skipetrov | first2 = S. | doi = 10.1103/PhysRevE.84.011150 | title = Non-Hermitian Euclidean random matrix theory | journal = Physical Review E | volume = 84 | year = 2011 | pmid =  | pmc = |arxiv = 1102.1850 |bibcode = 2011PhRvE..84a1150G }}&lt;/ref&gt; and has been applied to study the problem of [[random laser]].&lt;ref name=goetschy11b&gt;{{Cite journal | last1 = Goetschy | first1 = A. | last2 = Skipetrov | first2 = S. E. | doi = 10.1209/0295-5075/96/34005 | title = Euclidean matrix theory of random lasing in a cloud of cold atoms | journal = EPL | volume = 96 | issue = 3 | pages = 34005 | year = 2011 | pmid =  | pmc = |arxiv = 1104.2711 |bibcode = 2011EL.....9634005G }}&lt;/ref&gt;

''Example 2:'' Consider the matrix Â generated by the function ''f''('''r''', '''r'''′) = exp(''ik''&lt;sub&gt;0&lt;/sub&gt;|'''r'''-'''r'''′|)/(''k''&lt;sub&gt;0&lt;/sub&gt;|'''r'''-'''r'''′|), with ''k''&lt;sub&gt;0&lt;/sub&gt; = 2π/λ&lt;sub&gt;0&lt;/sub&gt; and ''f''('''r'''= '''r'''′) = 0. This matrix is not Hermitian and its eigenvalues Λ are [[Complex number|complex]]. The probability distribution of Λ can be found analytically&lt;ref name=goetschy11a/&gt; if the density of point ρ = ''N''/''V'' obeys ρλ&lt;sub&gt;0&lt;/sub&gt;&lt;sup&gt;3&lt;/sup&gt; ≤ 1 and 9''N''/(8''k''&lt;sub&gt;0&lt;/sub&gt; ''R'')&lt;sup&gt;2&lt;/sup&gt; &lt; 1 (see figure).

{{clear}}

== References ==
{{reflist}}

[[Category:Random matrices]]
[[Category:Mathematical physics]]</text>
      <sha1>1x1k4hrjntkeoffx5atnabje3v0915m</sha1>
    </revision>
  </page>
  <page>
    <title>Fisher–Yates shuffle</title>
    <ns>0</ns>
    <id>12684962</id>
    <revision>
      <id>871329879</id>
      <parentid>871329518</parentid>
      <timestamp>2018-11-30T09:51:37Z</timestamp>
      <contributor>
        <username>Ratiafak</username>
        <id>21424133</id>
      </contributor>
      <minor/>
      <comment>Add citation to LCG in Pseudorandom generators subsection</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32789">The '''Fisher–Yates shuffle''' is an [[algorithm]] for generating a [[random permutation]] of a finite [[sequence]]—in plain terms, the algorithm [[shuffling|shuffles]] the sequence.  The algorithm effectively puts all the elements into a hat; it continually determines the next element by randomly drawing an element from the hat until no elements remain. The algorithm produces an [[Biased sample|unbiased]] permutation: every permutation is equally likely.  The modern version of the algorithm is efficient: it takes time proportional to the number of items being shuffled and shuffles them [[In-place algorithm|in place]].

The Fisher–Yates shuffle is named after [[Ronald Fisher]] and [[Frank Yates]], who first described it, and is also known as the '''Knuth shuffle''' after [[Donald Knuth]]. A variant of the Fisher–Yates shuffle, known as '''Sattolo's algorithm''', may be used to generate random [[cyclic permutation]]s of length ''n'' instead of random permutations.

== Fisher and Yates' original method ==

The Fisher–Yates shuffle, in its original form, was described in 1938 by [[Ronald Fisher]] and [[Frank Yates]] in their book ''Statistical tables for biological, agricultural and medical research''.&lt;ref name="fisheryates"&gt;
{{cite book
| last=Fisher |first=Ronald A. |author1link=Ronald A. Fisher |last2=Yates |first2=Frank |author2link=Frank Yates
| title = Statistical tables for biological, agricultural and medical research
| origyear = 1938
| edition = 3rd
| year = 1948
| pages = 26–27
| publisher = Oliver &amp; Boyd
| location = London
| oclc = 14222135
}} &lt;!-- TODO: should cite 1st ed., if I could just find it --&gt;
Note: the 6th edition, {{ISBN|0-02-844720-4}}, is [http://hdl.handle.net/2440/10701 available on the web], but gives a different shuffling algorithm by [[C. R. Rao]].
&lt;/ref&gt;  Their description of the algorithm used pencil and paper; a table of random numbers provided the randomness.  The basic method given for generating a random permutation of the numbers 1 through ''N'' goes as follows:

# Write down the numbers from 1 through ''N''.
# Pick a random number ''k'' between one and the number of unstruck numbers remaining (inclusive).
# Counting from the low end, strike out the ''k''th number not yet struck out, and write it down at the end of a separate list.
# Repeat from step 2 until all the numbers have been struck out.
# The sequence of numbers written down in step 3 is now a random permutation of the original numbers.

Provided that the random numbers picked in step 2 above are truly random and unbiased, so will the resulting permutation be.  Fisher and Yates took care to describe how to obtain such random numbers in any desired range from the supplied tables in a manner which avoids any bias.  They also suggested the possibility of using a simpler method — picking random numbers from one to ''N'' and discarding any duplicates—to generate the first half of the permutation, and only applying the more complex algorithm to the remaining half, where picking a duplicate number would otherwise become frustratingly common.

== The modern algorithm ==
The modern version of the Fisher–Yates shuffle, designed for computer use, was introduced by [[Richard Durstenfeld]] in 1964&lt;ref name="cacm"&gt;{{Cite journal | last1 = Durstenfeld |first1 = R. | title = Algorithm 235: Random permutation | doi = 10.1145/364520.364540 | journal = Communications of the ACM | volume = 7 | issue = 7 | pages = 420 | date=July 1964 | pmid =  | pmc = }}&lt;/ref&gt; and popularized by [[Donald E. Knuth]] in ''[[The Art of Computer Programming]]'' as "Algorithm P (Shuffling)".&lt;ref name="knuth"&gt;
{{cite book
| series=The Art of Computer Programming |volume=2 |title=Seminumerical algorithms
| first = Donald E.
| last = Knuth
| pages = 139–140
| year = 1969
| publisher = Addison–Wesley
| location = Reading, MA
| oclc = 85975465
}}
&lt;/ref&gt; Neither Durstenfeld's article nor Knuth's first edition of ''The Art of Computer Programming'' acknowledged the work of Fisher and Yates; they may not have been aware of it.  Subsequent editions of Knuth's ''The Art of Computer Programming'' mention Fisher and Yates' contribution.&lt;ref name="knuth3"&gt;
{{cite book
| series=The Art of Computer Programming |volume=2 |title=Seminumerical algorithms
| last = Knuth
| edition = 3rd
| year = 1998
| pages = 12-15, 145–146
| isbn = 0-201-89684-2
| oclc = 38207978
| publisher = Addison–Wesley
| location = Boston
}}
&lt;/ref&gt;

The algorithm described by Durstenfeld differs from that given by Fisher and Yates in a small but significant way.  Whereas a naive computer implementation of Fisher and Yates' method would spend needless time counting the remaining numbers in step 3 above, Durstenfeld's solution is to move the "struck" numbers to the end of the list by swapping them with the last unstruck number at each iteration.  This reduces the algorithm's [[time complexity]] to ''O''(''n''), compared to ''O''(''n''&lt;sup&gt;2&lt;/sup&gt;) for the naïve implementation.&lt;ref name="nist"&gt;
{{cite web
| first = Paul E.
| last = Black
| work = Dictionary of Algorithms and Data Structures
| title = Fisher–Yates shuffle
| publisher = [[National Institute of Standards and Technology]]
| url = https://xlinux.nist.gov/dads/HTML/fisherYatesShuffle.html
| date = 2005-12-19
| accessdate = 2007-08-09
}}
&lt;/ref&gt;  This change gives the following algorithm (for a zero-based [[Array data structure|array]]).

 -- To shuffle an array ''a'' of ''n'' elements (indices 0..n-1):
 '''for''' ''i'' '''from''' ''n''−1 '''downto''' 1 '''do'''
      ''j'' ← random integer such that 0 ≤ ''j'' ≤ ''i''
      exchange ''a''[''j''] and ''a''[''i'']

An equivalent version which shuffles the array in the opposite direction (from lowest index to highest) is:
 -- To shuffle an array ''a'' of ''n'' elements (indices 0..n-1):
 '''for''' ''i'' '''from''' 0 '''to''' ''n''−2 '''do'''
      ''j'' ← random integer such that i ≤ ''j'' &lt; ''n''
      exchange ''a''[''i''] and ''a''[j]

== Examples ==

=== Pencil-and-paper method ===

As an example, we'll permute the numbers from 1 to 8 using [[#Fisher and Yates' original method|Fisher and Yates' original method]].  We'll start by writing the numbers out on a piece of scratch paper:

{| class="wikitable"
|-
! Range !! Roll !! Scratch !! Result
|-
| &amp;nbsp; || &amp;nbsp; || 1 2 3 4 5 6 7 8 || &amp;nbsp;
|}

Now we roll a random number ''k'' from 1 to 8—let's make it 3—and strike out the ''k''th (i.e. third) number (3, of course) on the scratch pad and write it down as the result:

{| class="wikitable"
|-
! Range !! Roll !! Scratch !! Result
|-
| 1–8 || 3 || 1 2 &lt;s&gt;&lt;span style="color:gray;"&gt;3&lt;/span&gt;&lt;/s&gt; 4 5 6 7 8 || 3
|}

Now we pick a second random number, this time from 1 to 7: it turns out to be 4.  Now we strike out the fourth number ''not yet struck'' off the scratch pad—that's number 5—and add it to the result:

{| class="wikitable"
|-
! Range !! Roll !! Scratch !! Result
|-
| 1–7 || 4 || 1 2 &lt;s&gt;&lt;span style="color:gray;"&gt;3&lt;/span&gt;&lt;/s&gt; 4 &lt;s&gt;&lt;span style="color:gray;"&gt;5&lt;/span&gt;&lt;/s&gt; 6 7 8 || 3 5
|}

Now we pick the next random number from 1 to 6, and then from 1 to 5, and so on, always repeating the strike-out process as above:

{| class="wikitable"
|-
! Range !! Roll !! Scratch !! Result
|-
| 1–6 || 5 || 1 2 &lt;s&gt;&lt;span style="color:gray;"&gt;3&lt;/span&gt;&lt;/s&gt; 4 &lt;s&gt;&lt;span style="color:gray;"&gt;5&lt;/span&gt;&lt;/s&gt; 6 &lt;s&gt;&lt;span style="color:gray;"&gt;7&lt;/span&gt;&lt;/s&gt; 8 || 3 5 7
|-
| 1–5 || 3 || 1 2 &lt;s&gt;&lt;span style="color:gray;"&gt;3&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;4&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;5&lt;/span&gt;&lt;/s&gt; 6 &lt;s&gt;&lt;span style="color:gray;"&gt;7&lt;/span&gt;&lt;/s&gt; 8 || 3 5 7 4
|-
| 1–4 || 4 || 1 2 &lt;s&gt;&lt;span style="color:gray;"&gt;3&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;4&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;5&lt;/span&gt;&lt;/s&gt; 6 &lt;s&gt;&lt;span style="color:gray;"&gt;7&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;8&lt;/span&gt;&lt;/s&gt; || 3 5 7 4 8
|-
| 1–3 || 1 || &lt;s&gt;&lt;span style="color:gray;"&gt;1&lt;/span&gt;&lt;/s&gt; 2 &lt;s&gt;&lt;span style="color:gray;"&gt;3&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;4&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;5&lt;/span&gt;&lt;/s&gt; 6 &lt;s&gt;&lt;span style="color:gray;"&gt;7&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;8&lt;/span&gt;&lt;/s&gt; || 3 5 7 4 8 1
|-
| 1–2 || 2 || &lt;s&gt;&lt;span style="color:gray;"&gt;1&lt;/span&gt;&lt;/s&gt; 2 &lt;s&gt;&lt;span style="color:gray;"&gt;3&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;4&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;5&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;6&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;7&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;8&lt;/span&gt;&lt;/s&gt; || 3 5 7 4 8 1 6
|-
| &amp;nbsp; || &amp;nbsp; || &lt;s&gt;&lt;span style="color:gray;"&gt;1&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;2&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;3&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;4&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;5&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;6&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;7&lt;/span&gt;&lt;/s&gt; &lt;s&gt;&lt;span style="color:gray;"&gt;8&lt;/span&gt;&lt;/s&gt; || 3 5 7 4 8 1 6 2
|}

=== Modern method ===

We'll now do the same thing using [[#The modern algorithm|Durstenfeld's version]] of the algorithm: this time, instead of striking out the chosen numbers and copying them elsewhere, we'll swap them with the last number not yet chosen.  We'll start by writing out the numbers from 1 to 8 as before:

{| class="wikitable"
|-
! Range !! Roll !! Scratch !! Result
|-
| &amp;nbsp; || &amp;nbsp; || 1 2 3 4 5 6 7 8 || &amp;nbsp;
|}

For our first roll, we roll a random number from 1 to 8: this time it is 6, so we swap the 6th and 8th numbers in the list:

{| class="wikitable"
|-
! Range !! Roll !! Scratch !! Result
|-
| 1–8 || 6 || 1 2 3 4 5 '''8''' 7 || '''6'''
|}

The next random number we roll from 1 to 7, and turns out to be 2.  Thus, we swap the 2nd and 7th numbers and move on:

{| class="wikitable"
|-
! Range !! Roll !! Scratch !! Result
|-
| 1–7 || 2 || 1 '''7''' 3 4 5 8 || '''2''' 6
|}

The next random number we roll is from 1 to 6, and just happens to be 6, which means we leave the 6th number in the list (which, after the swap above, is now number 8) in place and just move to the next step.  Again, we proceed the same way until the permutation is complete:

{| class="wikitable"
|-
! Range !! Roll !! Scratch !! Result
|-
| 1–6 || 6 || 1 7 3 4 5 || '''8''' 2 6
|-
| 1–5 || 1 || align="right" | '''5''' 7 3 4 || '''1''' 8 2 6
|-
| 1–4 || 3 || align="right" | 5 7 '''4''' || '''3''' 1 8 2 6
|-
| 1–3 || 3 || align="right" | 5 7 || '''4''' 3 1 8 2 6
|-
| 1–2 || 1 || align="right" | '''7''' || '''5''' 4 3 1 8 2 6
|}

At this point there's nothing more that can be done, so the resulting permutation is 7 5 4 3 1 8 2 6.

== Variants ==

=== The "inside-out" algorithm ===
{{original research|section|date=April 2017}}
The Fisher–Yates shuffle, as implemented by Durstenfeld, is an ''in-place shuffle''. That is, given a preinitialized array, it shuffles the elements of the array in place, rather than producing a shuffled copy of the array. This can be an advantage if the array to be shuffled is large.

To simultaneously initialize and shuffle an array, a bit more efficiency can be attained by doing an "inside-out" version of the shuffle.  In this version, one successively places element number ''i'' into a random position among the first ''i'' positions in the array, after moving the element previously occupying that position to position ''i''.  In case the random position happens to be number ''i'', this "move" (to the same place) involves an uninitialised value, but that does not matter, as the value is then immediately overwritten. No separate initialization is needed, and no exchange is performed. In the common case where ''source'' is defined by some simple function, such as the integers from 0 to ''n''&amp;nbsp;−&amp;nbsp;1, ''source'' can simply be replaced with the function since ''source'' is never altered during execution.

 To initialize an array ''a'' of ''n'' elements to a randomly shuffled copy of ''source'', both 0-based:
   '''for''' ''i'' '''from''' 0 '''to''' ''n'' − 1 '''do'''
       ''j'' ← random integer such that 0 ≤ ''j'' ≤ ''i''
       '''if''' ''j'' ≠ ''i''
           ''a''[''i''] ← ''a''[''j'']
       ''a''[''j''] ← ''source''[''i'']

The inside-out shuffle can be seen to be correct by [[Mathematical_induction|induction]]. Assuming a perfect random number generator, every one of the ''n''! different sequences of random numbers that could be obtained from the calls of ''random'' will produce a different permutation of the values, so all of these are obtained exactly once. The condition that checks if ''j'' ≠ ''i'' may be omitted in languages that have no problems accessing uninitialized array values, and for which assigning is cheaper than comparing.

Another advantage of this technique is that the algorithm can be modified so that even when we do not know "n", the number of elements in ''source'', we can still generate a uniformly distributed random permutation of the ''source'' data. Below the array ''a'' is built iteratively starting from empty, and ''a''.length represents the current number of elements seen.

 To initialize an empty array ''a'' to a randomly shuffled copy of ''source'' whose length is not known:
   '''while''' ''source''.moreDataAvailable
       ''j'' ← random integer such that 0 ≤ ''j'' ≤ ''a''.length
       '''if''' j = ''a''.length
           ''a''.append(''source''.next)
       '''else'''
           ''a''.append(''a''[''j''])
           ''a''[''j''] ← ''source''.next

=== Sattolo's algorithm ===

A very similar algorithm was published in 1986 by [[Sandra Sattolo]] for generating uniformly distributed [[cyclic permutation|cycle]]s of (maximal) length ''n''.&lt;ref name="sattolo"&gt;
{{cite journal
| last = Sattolo
| first = Sandra
| date = 1986-05-30
| title =  An algorithm to generate a random cyclic permutation| journal = Information Processing Letters|  volume = 22
| issue = 6
| pages = 315–3017
| doi=10.1016/0020-0190(86)90073-6
}}
&lt;/ref&gt;&lt;ref name="wilson"&gt;
{{cite conference
| last = Wilson
| first = Mark C.
| date = 2004-06-21
| title = Overview of Sattolo's Algorithm
| url = http://algo.inria.fr/seminars/summary/Wilson2004b.pdf
| conference = Algorithms Seminar 2002–2004
| conferenceurl = http://algo.inria.fr/seminars/allyears.html
| editor = F. Chyzak (ed.)
| others = summary by Éric Fusy.
| booktitle = INRIA Research Report
| volume = 5542
| pages = 105–108
|issn=0249-6399
}}
&lt;/ref&gt; The only difference between Durstenfeld's and Sattolo's algorithms is that in the latter, in step 2 above, the random number ''j'' is chosen from the range between 1 and ''i''−1 (rather than between 1 and ''i'') inclusive.  This simple change modifies the algorithm so that the resulting permutation always consists of a single cycle.

In fact, as described below, it is quite easy to ''accidentally'' implement Sattolo's algorithm when the ordinary Fisher–Yates shuffle is intended.  This will bias the results by causing the permutations to be picked from the smaller set of (''n''−1)! cycles of length ''N'', instead of from the full set of all ''n''! possible permutations.

The fact that Sattolo's algorithm always produces a cycle of length ''n'' can be shown by [[Mathematical_induction|induction]]. Assume by induction that after the initial iteration of the loop, the remaining iterations permute the first ''n''&amp;nbsp;−&amp;nbsp;1 elements according to a cycle of length ''n''&amp;nbsp;−&amp;nbsp;1 (those remaining iterations are just Sattolo's algorithm applied to those first ''n''&amp;nbsp;−&amp;nbsp;1 elements). This means that tracing the initial element to its new position ''p'', then the element originally at position ''p'' to its new position, and so forth, one only gets back to the initial position after having visited all other positions. Suppose the initial iteration swapped the final element with the one at (non-final) position ''k'', and that the subsequent permutation of first ''n''&amp;nbsp;−&amp;nbsp;1 elements then moved it to position&amp;nbsp;''l''; we compare the permutation&amp;nbsp;''π'' of all ''n'' elements with that remaining permutation&amp;nbsp;''σ'' of the first ''n''&amp;nbsp;−&amp;nbsp;1 elements. Tracing successive positions as just mentioned, there is no difference between ''π'' and ''σ'' until arriving at position&amp;nbsp;''k''. But then, under&amp;nbsp;''π'' the element originally at position&amp;nbsp;''k'' is moved to the final position rather than to position&amp;nbsp;''l'', and the element originally at the final position is moved to position&amp;nbsp;''l''. From there on, the sequence of positions for&amp;nbsp;''π'' again follows the sequence for&amp;nbsp;''σ'', and all positions will have been visited before getting back to the initial position, as required.

As for the equal probability of the permutations, it suffices to observe that the modified algorithm involves (''n''−1)! distinct possible sequences of random numbers produced, each of which clearly produces a different permutation, and each of which occurs—assuming the random number source is unbiased—with equal probability.  The (''n''−1)! different permutations so produced precisely exhaust the set of cycles of length ''n'': each such cycle has a unique [[cycle notation]] with the value ''n'' in the final position, which allows for (''n''−1)! permutations of the remaining values to fill the other positions of the cycle notation.

A sample implementation of Sattolo's algorithm in [[Python (programming language)|Python]] is:

&lt;source lang="python"&gt;
from random import randrange

def sattoloCycle(items):
    i = len(items)
    while i &gt; 1:
        i = i - 1
        j = randrange(i)  # 0 &lt;= j &lt;= i-1
        items[j], items[i] = items[i], items[j]
&lt;/source&gt;

== Comparison with other shuffling algorithms ==

The asymptotic time and space complexity of the Fisher–Yates shuffle are optimal.  Combined with a high-quality unbiased random number source, it is also guaranteed to produce unbiased results.  Compared to some other solutions, it also has the advantage that, if only part of the resulting permutation is needed, it can be stopped halfway through, or even stopped and restarted repeatedly, generating the permutation incrementally as needed.

An alternative method assigns a random number to each element of the set to be shuffled and then sorts the set according to the assigned numbers. The sorting method has the same asymptotic time complexity as Fisher–Yates: although general sorting is ''O''(''n''&amp;nbsp;log&amp;nbsp;''n''), numbers are efficiently sorted using [[Radix sort]] in ''O''(''n'') time. Like the Fisher–Yates shuffle, the sorting method produces unbiased results.  However, care must be taken to ensure that the assigned random numbers are never duplicated, since sorting algorithms typically don't order elements randomly in case of a tie.&lt;ref&gt;{{cite web |work=Oleg Kiselyov |title=Provably perfect shuffle algorithms |url=http://okmij.org/ftp/Haskell/perfect-shuffle.txt |date=3 Sep 2001 |accessdate=2013-07-09}}&lt;/ref&gt;  Additionally, this method requires asymptotically larger space: ''O''(''n'') additional storage space for the random numbers, versus ''O''(1) space for the Fisher–Yates shuffle.  Finally, we note that the sorting method has a simple parallel implementation, unlike the Fisher–Yates shuffle, which is sequential.

A variant of the above method that has seen some use in languages that support sorting with user-specified comparison functions is to shuffle a list by sorting it with a comparison function that returns random values.  However, ''this is an extremely bad method'': it is very likely to produce highly non-uniform distributions, which in addition depends heavily on the sorting algorithm used.&lt;ref&gt;
{{cite web
| work = require ‘brain’
| title = A simple shuffle that proved not so simple after all
| url = http://szeryf.wordpress.com/2007/06/19/a-simple-shuffle-that-proved-not-so-simple-after-all/
| date = 2007-06-19
| accessdate = 2007-08-09
}} &lt;!-- TODO: could use a more authoritative reference, although this ought to suffice to demonstrate the point --&gt;
&lt;/ref&gt;&lt;ref&gt;
{{cite web
| work = Rob Weir: An Antic Disposition
| title = Doing the Microsoft Shuffle: Algorithm Fail in Browser Ballot
| url = http://www.robweir.com/blog/2010/02/microsoft-random-browser-ballot.html
| date = 2010-02-27
| accessdate = 2010-02-28
}}
&lt;/ref&gt;
For instance suppose [[quicksort]] is used as sorting algorithm, with a fixed element selected as first [[pivot element]]. The algorithm starts comparing the pivot with all other elements to separate them into those less and those greater than it, and the relative sizes of those groups will determine the final place of the pivot element. For a uniformly distributed [[random permutation]], each possible final position should be equally likely for the pivot element, but if each of the initial comparisons returns "less" or "greater" with equal probability, then that position will have a [[binomial distribution]] for ''p''&amp;nbsp;=&amp;nbsp;1/2, which gives positions near the middle of the sequence with a much higher probability for than positions near the ends. Randomized comparison functions applied to other sorting methods like [[merge sort]] may produce results that appear more uniform, but are not quite so either, since merging two sequences by repeatedly choosing one of them with equal probability (until the choice is forced by the exhaustion of one sequence) does not produce results with a uniform distribution; instead the probability to choose a sequence should be proportional to the number of elements left in it. In fact no method that uses only two-way random events with equal probability ([[Bernoulli process|"coin flipping"]]), repeated a bounded number of times, can produce permutations of a sequence (of more than two elements) with a uniform distribution, because every execution path will have as probability a rational number with as denominator a [[power of 2]], while the required probability 1/''n''! for each possible permutation is not of that form.

In principle this shuffling method can even result in program failures like endless loops or access violations, because the correctness of a sorting algorithm may depend on properties of the order relation (like [[transitive relation|transitivity]]) that a comparison producing random values will certainly not have.&lt;ref&gt;
{{cite web
| work = require ‘brain’
| title = Writing a sort comparison function, redux
| url = http://blogs.msdn.com/oldnewthing/archive/2009/05/08/9595334.aspx
| date = 2009-05-08
| accessdate = 2009-05-08
}}
&lt;/ref&gt;
While this kind of behaviour should not occur with sorting routines that never perform a comparison whose outcome can be predicted with certainty (based on previous comparisons), there can be valid reasons for deliberately making such comparisons. For instance the fact that any element should compare equal to itself allows using them as [[sentinel value]] for efficiency reasons, and if this is the case, a random comparison function would break the sorting algorithm.

== Potential sources of bias ==

Care must be taken when implementing the Fisher–Yates shuffle, both in the implementation of the algorithm itself and in the generation of the random numbers it is built on, otherwise the results may show detectable bias.  A number of common sources of bias have been listed below.

=== Implementation errors ===

A common error when implementing the Fisher–Yates shuffle is to pick the random numbers from the wrong range. The flawed algorithm may appear to work correctly, but it will not produce each possible permutation with equal probability, and it may not produce certain permutations at all.  For example, a common [[off-by-one error]] would be choosing the index ''j'' of the entry to swap in [[#The modern algorithm|the example above]] to be always strictly less than the index ''i'' of the entry it will be swapped with. This turns the Fisher–Yates shuffle into [[#Sattolo's algorithm|Sattolo's algorithm]], which produces only permutations consisting of a single cycle involving all elements: in particular, with this modification, no element of the array can ever end up in its original position.

[[Image:Probabilities7.svg|thumb|Order bias from incorrect implementation]]
[[Image:Orderbias.png|thumb|Order bias from incorrect implementation - n = 1000]]
Similarly, always selecting ''j'' from the entire range of valid array indices on ''every'' iteration also produces a result which is biased, albeit less obviously so.  This can be seen from the fact that doing so yields ''n''&lt;sup&gt;''n''&lt;/sup&gt; distinct possible sequences of swaps, whereas there are only [[factorial|''n''!]] possible permutations of an ''n''-element array.  Since ''n''&lt;sup&gt;''n''&lt;/sup&gt; can never be evenly divisible by ''n''!  when ''n'' &amp;gt; 2 (as the latter is divisible by ''n''−1, which shares no [[prime factor]]s with ''n''), some permutations must be produced by more of the ''n''&lt;sup&gt;''n''&lt;/sup&gt; sequences of swaps than others.  As a concrete example of this bias, observe the distribution of possible outcomes of shuffling a three-element array [1, 2, 3].  There are 6 possible permutations of this array (3! = 6), but the algorithm produces 27 possible shuffles (3&lt;sup&gt;3&lt;/sup&gt; = 27).  In this case, [1, 2, 3], [3, 1, 2], and [3, 2, 1] each result from 4 of the 27 shuffles, while each of the remaining 3 permutations occurs in 5 of the 27 shuffles.

The matrix to the right shows the probability of each element in a list of length 7 ending up in any other position.  Observe that for most elements, ending up in their original position (the matrix's main diagonal) has lowest probability, and moving one slot backwards has highest probability.

=== Modulo bias ===
{{references|section|date=April 2017}}
Doing a Fisher–Yates shuffle involves picking [[uniform distribution (discrete)|uniformly distributed]] random integers from various ranges.  Most [[random number generator]]s, however — whether true or [[pseudorandom]] — will only directly provide numbers in a fixed range from 0 to RAND_MAX, and in some libraries, RAND_MAX may be as low as 32767.&lt;ref&gt;''[https://www.gnu.org/software/libc/manual/html_node/ISO-Random.html The GNU C Library: ISO Random]''&lt;/ref&gt;  A simple and commonly used way to force such numbers into a desired range is to apply the [[modulo operator]]; that is, to divide them by the size of the range and take the remainder.  However, the need in a Fisher–Yates shuffle to generate random numbers in every range from 0–1 to 0–''n'' pretty much guarantees that some of these ranges will not evenly divide the natural range of the random number generator.  Thus, the remainders will not always be evenly distributed and, worse yet, the bias will be systematically in favor of small remainders.

For example, assume that your random number source gives numbers from 0 to 99 (as was the case for Fisher and Yates' original tables), and that you wish to obtain an unbiased random number from 0 to 15.  If you simply divide the numbers by 16 and take the remainder, you'll find that the numbers 0–3 occur about 17% more often than others.  This is because 16 does not evenly divide 100: the largest multiple of 16 less than or equal to 100 is 6×16 = 96, and it is the numbers in the incomplete range 96–99 that cause the bias.  The simplest way to fix the problem is to discard those numbers before taking the remainder and to keep trying again until a number in the suitable range comes up.  While in principle this could, in the worst case, take forever, the [[expected value|expected number]] of retries will always be less than one.

A related problem occurs with implementations that first generate a random [[floating-point]] number—usually in the range [0,1)—and then multiply it by the size of the desired range and round down.  The problem here is that random floating-point numbers, however carefully generated, always have only finite precision.  This means that there are only a finite number of possible floating point values in any given range, and if the range is divided into a number of segments that doesn't divide this number evenly, some segments will end up with more possible values than others.  While the resulting bias will not show the same systematic downward trend as in the previous case, it will still be there.

=== Pseudorandom generators ===
{{references|section|date=April 2017}}
{| class="wikitable" style="margin:0 0 0 1em; text-align:right; float:right;"
|+ Size of PRNG seeds and the largest list where every permutation could be reached
|-
! seed bits
! maximum list length
|-
| 0 || 1
|-
| 1 || 2
|-
| 3 || 3
|-
| 5 || 4
|-
| 7 || 5
|-
| 10 || 6
|-
| 13 || 7
|-
| 16 || 8
|-
| 22 || 10
|-
| 24 || 10
|-
| &lt;!--numerous--&gt; 32 || 12
|-
| &lt;!--java.util.Random--&gt; 48 || 16
|-
| 64 || 20
|-
| 128 || 34
|-
| &lt;!--SHA-1--&gt; 160 || 40
|-
| 226 || &lt;!--deck of cards--&gt; 52
|-
| &lt;!--SHA-256--&gt; 256 || 57
|-
| &lt;!--SHA-512--&gt; 512 || 98
|-
| 1024 || 170
|-
| &lt;!--SHA-3--&gt; 1600 || 245
|-
| &lt;!--MT19937--&gt; 19937 || 2080
|-
| &lt;!--WELL44497--&gt; 44497 || 4199
|}

An additional problem occurs when the Fisher–Yates shuffle is used with a [[pseudorandom number generator]] or PRNG: as the sequence of numbers output by such a generator is entirely determined by its internal state at the start of a sequence, a shuffle driven by such a generator cannot possibly produce more distinct permutations than the generator has distinct possible states.&lt;ref&gt;{{cite book|last1=Arndt|first1=Jörg|title=Generating Random Permutations (PhD Thesis)|date=2009|publisher=Australian National University|page=9|url=https://maths-people.anu.edu.au/~brent/pd/Arndt-thesis.pdf|accessdate=25 April 2018}}&lt;/ref&gt;  Even when the number of possible states exceeds the number of permutations, the irregular nature of the mapping from sequences of numbers to permutations means that some permutations will occur more often than others.  Thus, to minimize bias, the number of states of the PRNG should exceed the number of permutations by at least several orders of magnitude.

For example, the built-in pseudorandom number generator provided by many programming languages and/or libraries may often have only 32 bits of internal state, which means it can only produce 2&lt;sup&gt;32&lt;/sup&gt; different sequences of numbers.  If such a generator is used to shuffle a deck of 52 [[playing card]]s, it can only ever produce a very small fraction of the [[factorial|52!]] ≈ 2&lt;sup&gt;225.6&lt;/sup&gt; possible permutations.  It is impossible for a generator with less than 226 bits of internal state to produce all the possible permutations of a 52-card deck.

No pseudorandom number generator can produce more distinct sequences, starting from the point of initialization, than there are distinct seed values it may be initialized with.  Thus, a generator that has 1024 bits of internal state but which is initialized with a 32-bit seed can still only produce 2&lt;sup&gt;32&lt;/sup&gt; different permutations right after initialization. It can produce more permutations if one exercises the generator a great many times before starting to use it for generating permutations, but this is a very inefficient way of increasing randomness: supposing one can arrange to use the generator a random number of up to a billion, say 2&lt;sup&gt;30&lt;/sup&gt; for simplicity, times between initialization and generating permutations, then the number of possible permutations is still only 2&lt;sup&gt;62&lt;/sup&gt;.

A further problem occurs when a simple [[linear congruential generator|linear congruential]] PRNG is used with the divide-and-take-remainder method of range reduction described above.  The problem here is that the low-order bits of a linear congruential PRNG with modulo 2&lt;sup&gt;''e''&lt;/sup&gt; are less random than the high-order ones &lt;ref name="knuth3" /&gt;: the low ''n'' bits of the generator themselves have a period of at most 2&lt;sup&gt;''n''&lt;/sup&gt;.  When the divisor is a power of two, taking the remainder essentially means throwing away the high-order bits, such that one ends up with a significantly less random value. Different rules apply if the [[linear congruential generator|LCG]] has prime modulo, but such generators are uncommon. This is an example of the general rule that a poor-quality RNG or PRNG will produce poor-quality shuffles.

== See also ==
* [[RC4]], a stream cipher based on shuffling an array
* [[Reservoir sampling]], in particular Algorithm R which is a specialization of the Fisher–Yates shuffle

== References ==
{{reflist|30em}}

==External links==
* [http://bost.ocks.org/mike/shuffle/ An interactive example]

{{Donald Knuth navbox}}

{{DEFAULTSORT:Fisher-Yates shuffle}}
[[Category:Combinatorial algorithms]]
[[Category:Randomized algorithms]]
[[Category:Permutations]]
[[Category:Monte Carlo methods]]
[[Category:Articles with example pseudocode]]</text>
      <sha1>ig5jdp3z63a6s59ja4szz9omy8o5jtf</sha1>
    </revision>
  </page>
  <page>
    <title>Fitness model (network theory)</title>
    <ns>0</ns>
    <id>8370929</id>
    <revision>
      <id>695745357</id>
      <parentid>695618593</parentid>
      <timestamp>2015-12-18T08:05:57Z</timestamp>
      <contributor>
        <username>BG19bot</username>
        <id>14508071</id>
      </contributor>
      <minor/>
      <comment>/* Description of the model */[[WP:CHECKWIKI]] error fix for #61.  Punctuation goes before References. Do [[Wikipedia:GENFIXES|general fixes]] if a problem exists. - using [[Project:AWB|AWB]] (11756)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6417">In [[complex network]] theory, the '''fitness model''' is a model of the evolution of a network: how the links between nodes change over time depends on the '''fitness''' of nodes. Fitter nodes attract more links at the expense of less fit nodes.

It has been used to model the network structure of the [[World Wide Web]].

==Description of the model==
The model is based on the idea of '''fitness,''' an inherent competitive factor that nodes may have, capable of affecting the network's evolution.&lt;ref&gt;Albert R. and Barabási A.-L., "Statistical mechanics of complex networks", ''Reviews of Modern Physics'' 74, 47 (2002)&lt;/ref&gt; According to this idea, the nodes' intrinsic ability to attract links in the network varies from node to node, the most efficient (or "fit") being able to gather more edges in the expense of others. In that sense, not all nodes are identical to each other, and they claim their degree increase according to the fitness they possess every time. The fitness factors of all the nodes composing the network may form a distribution ρ(η) characteristic of the system been studied.

Bianconi and Barabási&lt;ref&gt;Bianconi Ginestra and Barabási A.-L., 2001a, ''Europhys. Lett.'' 54, 436.&lt;/ref&gt; proposed a new model called Bianconi-Barabasi model, a variant to the Barabási-Albert model ([[BA model]]), where the probability for a node to connect to another one is supplied with a term expressing the fitness of the node involved. The fitness parameter is time independent and is multiplicative to the probability

: &lt;math&gt;\Pi_i = \frac{\eta_i  k_i}{\sum_j \eta_{j}k_j}.&lt;/math&gt;

Thus, the system of equations for the time evolution of the degrees &lt;math&gt;k_{i}&lt;/math&gt; according to the continuum theory introduced by the same model will have the form

: &lt;math&gt;\frac{\partial k_{i}}{\partial t} = m\Pi_{i} = m\frac{\eta_{i}k_{i}}{\sum_{j}\eta_{j}k_{j}}&lt;/math&gt;

where ''m'' the number of edges the newly coming node has. If we require the solution to have a similar form to the one it had without the insertion of the fitness factors (to avoid ruining the [[power-law]] [[degree distribution]] of [[scale-free networks]]), then the exponent of the solution has to change and become fitness dependent

: &lt;math&gt;k_{\eta}(t,t_{i}) = m\left(\frac{t}{t_i}\right)^{\beta(\eta_{i})}&lt;/math&gt;

where

: &lt;math&gt;\beta(\eta) = \frac{\eta}{C}\mbox{ and }C = \int\rho(\eta)\frac{\eta}{1-\beta(\eta)}\,d\eta.&lt;/math&gt;

Hence, the more fit nodes increase their degree faster than the less ones. This characteristic attributes the network with a different behavior regarding its evolution. Without the introduction of the fitness property, all nodes had the same exponent in the power-law degree evolution formula. This means that the older nodes in the system would have more edges compared to newcoming ones. After the fitness property is introduced, this exponent, and accordingly, the slope of &lt;math&gt;k(t)&lt;/math&gt; change, giving thus the opportunity to newcoming nodes to dominate the system.

It was seen through this example how can a network's evolution change behavior through the introduction of a new parameter in the model. However, we require the network to preserve its overall scale-free character. By forcing the fitness dependence to be accumulated in the exponent only, the degree-distribution will still be a power-law relationship, composed though by a weighted sum of different power-law in degree-evolution formulas

: &lt;math&gt;P(k) \sim \int\rho(\eta)\frac{C}{\eta}(m/k)^{C/\eta +1}\,d\eta&lt;/math&gt;

where &lt;math&gt;\rho(\eta)&lt;/math&gt; is the fitness distribution depending on the system's composition

The fitness model can be extended to in corporate additional processes, such as internal edges, which affect the exponents.&lt;ref&gt;Ergun, G. and G. J. Rodgers, ''Physica A'' 303 (2002) 261&amp;ndash;272&lt;/ref&gt;

Another model where the fitness is not coupled to preferential attachment has been introduced by Caldarelli et al.&lt;ref&gt;Caldarelli G.,   A. Capocci, P. De Los Rios, M.A. Muñoz, Physical Review Letters 89, 258702 (2002)&lt;/ref&gt; Here a link is created between two vertices &lt;math&gt;i,j&lt;/math&gt; with a probability given by a linking function &lt;math&gt;f(\eta_i,\eta_j)&lt;/math&gt; of the fitnesses of the vertices involved.
The degree of a vertex i is given by &lt;ref&gt;Servedio V.D.P., G. Caldarelli, P. Buttà, Physical Review E 70, 056126 (2004)&lt;/ref&gt;

:&lt;math&gt;k(\eta_i)=N\int_0^\infty \!\!\! f(\eta_i,\eta_j) \rho(\eta_j) d\eta_j &lt;/math&gt;

If &lt;math&gt;k(\eta_i)&lt;/math&gt; is an invertible and increasing function of &lt;math&gt;\eta_i&lt;/math&gt;, then
the probability distribution &lt;math&gt;P(k)&lt;/math&gt; is given by

:&lt;math&gt;P(k)=\rho(\eta(k)) \cdot \eta'(k)&lt;/math&gt;

As a result if the fitnesses &lt;math&gt;\eta&lt;/math&gt; are distributed as a power law, then also the node degree does.

Less intuitively with a fast decaying probability distribution as
&lt;math&gt;\rho(\eta)=e^{-\eta}&lt;/math&gt; together with a linking function of the kind

:&lt;math&gt; f(\eta_i,\eta_j)=\Theta(\eta_i+\eta_j-Z)&lt;/math&gt;

with &lt;math&gt;Z&lt;/math&gt; a constant and &lt;math&gt;\Theta&lt;/math&gt; the Heavyside function, we also obtain
scale-free networks.

Such model has been successfully applied to describe trade between nations by using GDP as fitness for the various nodes &lt;math&gt;i,j&lt;/math&gt; and a linking function of the kind
&lt;ref&gt;Garlaschelli D., M I Loffredo Physical Review Letters 93, 188701 (2004)&lt;/ref&gt;
&lt;ref&gt;Cimini G., T. Squartini, D. Garlaschelli and A. Gabrielli, Scientific Reports 5, 15758 (2015)&lt;/ref&gt;

:&lt;math&gt; \frac{\delta \eta_i\eta_j}{1+ \delta \eta_i\eta_j}&lt;/math&gt;

==Fitness model and the evolution of the Web==

The fitness model has been used to model the network structure of the [[World Wide Web]]. In a [[PNAS]] article,&lt;ref&gt;J.S. Kong, N. Sarshar, V.P. Roychowdhury, "Experience versus Talent Shapes the Structure of the Web", Proceedings of the National Academy of Sciences of the USA, September 16, 2008; 105 (37)&lt;/ref&gt; Kong et al. extended the fitness model to include random node deletion, a common phenomena in the Web. When the deletion rate of the web pages are accounted for, they found that the overall fitness distribution is exponential. Nonetheless, even this small variance in the fitness is amplified through the [[preferential attachment]] mechanism, leading to a [[heavy-tailed distribution]] of incoming links on the Web.

== See also ==
* [[Bose&amp;ndash;Einstein condensation: a network theory approach]]

== References ==

&lt;references/&gt;

[[Category:Network theory]]</text>
      <sha1>lqq6a03c2jwj824u3c6smkjptofyy92</sha1>
    </revision>
  </page>
  <page>
    <title>Fourier algebra</title>
    <ns>0</ns>
    <id>11795634</id>
    <revision>
      <id>798143379</id>
      <parentid>798143252</parentid>
      <timestamp>2017-08-31T07:12:22Z</timestamp>
      <contributor>
        <username>Jon Kolbert</username>
        <id>29727696</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/221.142.126.75|221.142.126.75]] ([[User talk:221.142.126.75|talk]]) to last version by KolbertBot</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5172">{{citation style|date=February 2012}}
'''Fourier''' and related [[Associative algebra|algebras]] occur naturally in the [[harmonic analysis]] of [[locally compact]] [[Group (mathematics)|groups]]. They play an important role in the [[duality theory|duality theories]] of these groups. The Fourier–Stieltjes algebra and the Fourier–Stieltjes transform on the Fourier algebra of a locally compact group were introduced by [[Pierre Eymard]] in 1964.

==Definition==

===Informal===
Let G be a locally compact abelian group, and Ĝ the [[Pontryagin dual|dual group]] of G. Then the Fourier transform of functions in &lt;math&gt; L_1(\widehat{\mathit{G}}) &lt;/math&gt;, the group algebra of &lt;math&gt; (\widehat{\mathit{G}}) &lt;/math&gt;, is a sub-algebra A(G) of CB(G), the space of bounded continuous complex-valued functions on G with pointwise multiplication called the Fourier algebra of
G, and the Fourier-Stieltjes transform of measures in &lt;math&gt; M(\widehat{\mathit{G}}) &lt;/math&gt;, the measure algebra of &lt;math&gt; (\widehat{\mathit{G}}) &lt;/math&gt;, also a subalgebra of CB(G), called the Fourier-Stieltjes algebra of G.

===Formal===
Let &lt;math&gt; B(\mathit{G}) &lt;/math&gt; be a Fourier–Stieltjes algebra and &lt;math&gt; A(\mathit{G}) &lt;/math&gt; be a Fourier algebra such that the locally compact group &lt;math&gt; \mathit{G} &lt;/math&gt; is [[Abelian group|abelian]]. Let &lt;math&gt; M(\widehat{\mathit{G}}) &lt;/math&gt; be the measure algebra of finite measures on &lt;math&gt; \widehat{G} &lt;/math&gt; and let &lt;math&gt; L_1(\widehat{\mathit{G}}) &lt;/math&gt; be the [[Group algebra#The convolution algebra L1.28G.29|convolution algebra]] of [[Haar measure#Haar integral|integrable]] [[Function (mathematics)|function]]s on &lt;math&gt; \widehat{G} &lt;/math&gt;, where &lt;math&gt; \widehat{\mathit{G}} &lt;/math&gt; is the character group of the Abelian group &lt;math&gt; \mathit{G} &lt;/math&gt;.

The Fourier–Stieltjes transform of a finite measure &lt;math&gt; \mu &lt;/math&gt; on &lt;math&gt; \widehat{\mathit{G}} &lt;/math&gt; is the function &lt;math&gt; \widehat{\mu} &lt;/math&gt; on &lt;math&gt; \mathit{G} &lt;/math&gt; defined by

: &lt;math&gt; \widehat{\mu}(x) =  \int_{\widehat{G}} \overline{X(x)} \, d \mu(X), \quad x \in G &lt;/math&gt;

The space &lt;math&gt; B(\mathit{G}) &lt;/math&gt; of these functions is an algebra under pointwise multiplication is isomorphic to the measure algebra &lt;math&gt; M(\widehat{\mathit{G}}) &lt;/math&gt;. Restricted to &lt;math&gt; L_1(\widehat{\mathit{G}}) &lt;/math&gt;, viewed as a subspace of &lt;math&gt; M(\widehat{\mathit{G}}) &lt;/math&gt;, the Fourier–Stieltjes transform is the [[Fourier transform]] on &lt;math&gt; L_1(\widehat{\mathit{G}}) &lt;/math&gt; and its image is, by definition, the Fourier algebra &lt;math&gt; A(\mathit{G}) &lt;/math&gt;. The generalized [[Bochner theorem]] states that a measurable function on &lt;math&gt; \mathit{G} &lt;/math&gt; is equal, [[almost everywhere]], to the Fourier–Stieltjes transform of a non-negative finite measure on &lt;math&gt; \widehat{G} &lt;/math&gt; if and only if it is positive definite. Thus, &lt;math&gt; B(\mathit{G}) &lt;/math&gt; can be defined as the [[linear span]] of the set of continuous positive-definite functions on &lt;math&gt; \mathit{G} &lt;/math&gt;. This definition is still valid when &lt;math&gt; \mathit{G} &lt;/math&gt; is not Abelian.

===Helson–Kahane–Katznelson–Rudin theorem===
Let A(G) be the Fourier algebra of a compact group G. Building upon the work of [[Norbert Wiener|Wiener]], [[Paul Lévy (mathematician)|Lévy]], [[Israel Gelfand|Gelfand]], and [[Arne Beurling|Beurling]], in 1959 [[Henry Helson|Helson]], [[Jean-Pierre Kahane|Kahane]], [[Yitzhak Katznelson|Katznelson]], and [[Walter Rudin|Rudin]] proved that, when G is compact and abelian, a function f defined on a closed convex subset of the plane operates in A(G) if and only if f is real analytic.&lt;ref&gt;{{cite journal|author1=H. Helson |author2=J.-P. Kahane |author3=Y. Katznelson |author4=W. Rudin |title=The functions which operate on Fourier transforms|journal=Acta Mathematica|volume=102|year=1959|pages=135–157|url=http://www.kryakin.com/files/Acta_Mat_(2_55)/acta106_57/102/102_10.pdf|doi=10.1007/bf02559571}}&lt;/ref&gt; In 1969 [[Charles F. Dunkl|Dunkl]] proved the result holds when G is compact and contains an infinite abelian subgroup.

==References==
{{reflist}}

* {{SpringerEOM|id=Fourier-algebra(2)|first=Jean|last=Renault}}
* "Functions that Operate in the Fourier Algebra of a Compact Group" Charles F. Dunkl ''Proceedings of the American Mathematical Society'', Vol. 21, No. 3. (Jun., 1969), pp.&amp;nbsp;540–544. Stable URL:[https://www.jstor.org/stable/2036416]
* "Functions which Operate in the Fourier Algebra of a Discrete Group" Leonede de Michele; Paolo M. Soardi, ''Proceedings of the American Mathematical Society'', Vol. 45, No. 3. (Sep., 1974), pp.&amp;nbsp;389–392. Stable URL:[https://www.jstor.org/stable/2039963]
* "Uniform Closures of Fourier-Stieltjes Algebras", Ching Chou, ''Proceedings of the American Mathematical Society'', Vol. 77, No. 1. (Oct., 1979), pp.&amp;nbsp;99–102.  Stable URL: [https://www.jstor.org/stable/2042723]
* "Centralizers of the Fourier Algebra of an Amenable Group", P. F. Renaud, ''Proceedings of the American Mathematical Society'', Vol. 32, No. 2. (Apr., 1972), pp.&amp;nbsp;539–542.  Stable URL: [https://www.jstor.org/stable/2037854]

[[Category:Harmonic analysis]]
[[Category:Algebras]]</text>
      <sha1>aeqgywjqcppboyzac8m5g9hijvrogcq</sha1>
    </revision>
  </page>
  <page>
    <title>Freivalds' algorithm</title>
    <ns>0</ns>
    <id>4767368</id>
    <revision>
      <id>868856277</id>
      <parentid>861783627</parentid>
      <timestamp>2018-11-14T22:01:10Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7919">'''Freivalds' algorithm''' (named after [[Rūsiņš Mārtiņš Freivalds]]) is a probabilistic [[randomized algorithm]] used to verify [[matrix multiplication]]. Given three ''n''&amp;nbsp;&amp;times;&amp;nbsp;''n'' [[matrix (mathematics)|matrices]] &lt;math&gt;A&lt;/math&gt;, &lt;math&gt;B&lt;/math&gt;, and &lt;math&gt;C&lt;/math&gt;, a general problem is to verify whether &lt;math&gt;A \times B = C&lt;/math&gt;. A naïve [[algorithm]] would compute the product &lt;math&gt;A \times B&lt;/math&gt; explicitly and compare term by term whether this product equals &lt;math&gt;C&lt;/math&gt;. However, the best known matrix multiplication algorithm runs in &lt;math&gt;O(n^{2.3729})&lt;/math&gt; time.&lt;ref name="williams"&gt;{{cite web |url=http://www.cs.berkeley.edu/~virgi/matrixmult-f.pdf |title=Breaking the Coppersmith-Winograd barrier
|author=Virginia Vassilevska Williams|authorlink= Virginia Vassilevska Williams}}&lt;/ref&gt; Freivalds' algorithm utilizes [[randomization]] in order to reduce this time bound to &lt;math&gt;O(n^2)&lt;/math&gt;
&lt;ref&gt;
{{cite journal
|doi=10.1145/234313.234327
|last=Raghavan
|first=Prabhakar
|title=Randomized algorithms
|journal=ACM Computing Surveys
|year=1997
|volume=28
|pages=33
|publisher=
|accessdate=2008-12-16
|url=http://portal.acm.org/citation.cfm?id=234327}}&lt;/ref&gt;
[[with high probability]]. In &lt;math&gt;O(kn^2)&lt;/math&gt; time the algorithm can verify a matrix product with probability of failure less than &lt;math&gt;2^{-k}&lt;/math&gt;.

==The algorithm==

===Input===
Three ''n''&amp;nbsp;&amp;times;&amp;nbsp;''n'' [[matrix (mathematics)|matrices]] &lt;math&gt;A&lt;/math&gt;, &lt;math&gt;B&lt;/math&gt;, and &lt;math&gt;C&lt;/math&gt;.

===Output===
Yes, if &lt;math&gt;A \times B = C&lt;/math&gt;; No, otherwise.

===Procedure===

# Generate an ''n''&amp;nbsp;&amp;times;&amp;nbsp;1 [[random]] 0/1 [[vector (geometric)|vector]] &lt;math&gt;\vec{r}&lt;/math&gt;.
# Compute &lt;math&gt;\vec{P} = A \times (B \vec{r}) - C\vec{r}&lt;/math&gt;.
# Output "Yes" if &lt;math&gt;\vec{P} = (0,0,\ldots,0)^T&lt;/math&gt;; "No," otherwise.

===Error===
If &lt;math&gt;A \times B = C&lt;/math&gt;, then the algorithm always returns "Yes". If &lt;math&gt;A \times B \neq C&lt;/math&gt;, then the probability that the algorithm returns "Yes" is less than or equal to one half. This is called [[one-sided error]].

By iterating the algorithm ''k'' times and returning "Yes" only if all iterations yield "Yes", a runtime of &lt;math&gt;O(kn^2)&lt;/math&gt; and error probability of &lt;math&gt;\leq 1/2^k&lt;/math&gt; is achieved.

==Example==
Suppose one wished to determine whether:
:&lt;math&gt;
AB =
\begin{bmatrix}
 2 &amp; 3 \\
 3 &amp; 4
\end{bmatrix}
\begin{bmatrix}
 1 &amp; 0 \\
 1 &amp; 2
\end{bmatrix}
\stackrel{?}{=}
\begin{bmatrix}
 6 &amp; 5 \\
 8 &amp; 7
\end{bmatrix}
= C.
&lt;/math&gt;
A random two-element vector with entries equal to 0 or 1 is selected &amp;mdash; say &lt;math&gt;\vec{r} = \begin{bmatrix}1 \\ 1\end{bmatrix}&lt;/math&gt; &amp;mdash; and used to compute:
:&lt;math&gt;
\begin{align}
A \times (B \vec{r}) - C\vec{r} &amp; =
\begin{bmatrix}
 2 &amp; 3 \\
 3 &amp; 4
\end{bmatrix}
\left(
\begin{bmatrix}
 1 &amp; 0 \\
 1 &amp; 2
\end{bmatrix}
\begin{bmatrix}1 \\ 1\end{bmatrix}
\right)
-
\begin{bmatrix}
 6 &amp; 5 \\
 8 &amp; 7
\end{bmatrix}
\begin{bmatrix}1 \\ 1\end{bmatrix} \\
&amp; =
\begin{bmatrix}
 2 &amp; 3 \\
 3 &amp; 4
\end{bmatrix}
\begin{bmatrix}1 \\ 3\end{bmatrix}
-
\begin{bmatrix}11 \\ 15\end{bmatrix} \\
&amp; =
\begin{bmatrix}11 \\ 15\end{bmatrix}
-
\begin{bmatrix}11 \\ 15\end{bmatrix} \\
&amp; =
\begin{bmatrix}0 \\ 0\end{bmatrix}.
\end{align}
&lt;/math&gt;
This yields the zero vector, suggesting the possibility that AB = C. However, if in a second trial the vector &lt;math&gt;\vec{r} = \begin{bmatrix}1 \\ 0\end{bmatrix}&lt;/math&gt; is selected, the result becomes:
:&lt;math&gt;
A \times (B \vec{r}) - C\vec{r} =
\begin{bmatrix}
 2 &amp; 3 \\
 3 &amp; 4
\end{bmatrix}
\left(
\begin{bmatrix}
 1 &amp; 0 \\
 1 &amp; 2
\end{bmatrix}
\begin{bmatrix}1 \\ 0\end{bmatrix}
\right)
-
\begin{bmatrix}
 6 &amp; 5 \\
 8 &amp; 7
\end{bmatrix}
\begin{bmatrix}1 \\ 0\end{bmatrix}
=
\begin{bmatrix}-1 \\ -1\end{bmatrix}.
&lt;/math&gt;
The result is nonzero, proving that in fact AB &amp;ne; C.

There are four two-element 0/1 vectors, and half of them give the zero vector in this case (&lt;math&gt;\vec{r} = \begin{bmatrix}0 \\ 0\end{bmatrix}&lt;/math&gt; and &lt;math&gt;\vec{r} = \begin{bmatrix}1 \\ 1\end{bmatrix}&lt;/math&gt;), so the chance of randomly selecting these in two trials (and falsely concluding that AB=C) is 1/2&lt;sup&gt;2&lt;/sup&gt; or 1/4. In the general case, the proportion of ''r'' yielding the zero vector may be less than 1/2, and a larger number of trials (such as 20) would be used, rendering the probability of error very small.

==Error analysis==
Let ''p'' equal the [[probability]] of error. We claim that if ''A''&amp;nbsp;&amp;times;&amp;nbsp;''B'' = ''C'', then ''p'' = 0, and if ''A''&amp;nbsp;&amp;times;&amp;nbsp;''B'' ≠ ''C'', then ''p'' ≤ 1/2.

===Case ''A''&amp;nbsp;&amp;times;&amp;nbsp;''B'' = ''C''===
:&lt;math&gt;
\begin{align}
\vec{P} &amp;= A \times (B \vec{r}) - C \vec{r}\\
&amp;= (A \times B)\vec{r} - C\vec{r}\\
&amp;= (A \times B - C)\vec{r}\\
&amp;= \vec{0}
\end{align}
&lt;/math&gt;

This is regardless of the value of &lt;math&gt;\vec{r}&lt;/math&gt;, since it uses only that &lt;math&gt;A \times B - C = 0&lt;/math&gt;. Hence the probability for error in this case is:

:&lt;math&gt;\Pr[\vec{P} \neq 0] = 0&lt;/math&gt;

===Case ''A''&amp;nbsp;&amp;times;&amp;nbsp;''B'' ≠ ''C''===
Let &lt;math&gt;D&lt;/math&gt; such that

:&lt;math&gt;\vec{P} = D \times \vec{r} = (p_1, p_2, \dots, p_n)^T&lt;/math&gt;

Where

:&lt;math&gt;D = A \times B - C = (d_{ij})&lt;/math&gt;.

Since &lt;math&gt;A \times B \neq C&lt;/math&gt;, we have that some element of &lt;math&gt;D&lt;/math&gt; is nonzero. Suppose that the element &lt;math&gt;d_{ij} \neq 0&lt;/math&gt;. By the definition of [[matrix multiplication]], we have:

:&lt;math&gt;p_i = \sum_{k = 1}^n d_{ik}r_k = d_{i1}r_1 + \cdots + d_{ij}r_j + \cdots + d_{in}r_n = d_{ij}r_j + y&lt;/math&gt;.

For some constant &lt;math&gt;y&lt;/math&gt;.
Using [[Bayes' Theorem]], we can partition over &lt;math&gt;y&lt;/math&gt;:

{{NumBlk|:|&lt;math&gt;\Pr[p_i = 0] = \Pr[p_i = 0 | y = 0]\cdot \Pr[y = 0]\, +\, \Pr[p_i = 0 | y \neq 0] \cdot \Pr[y \neq 0]&lt;/math&gt;|{{EquationRef|1}}}}

We use that:

:&lt;math&gt;\Pr[p_i = 0 | y = 0] = \Pr[r_j = 0] = \frac{1}{2}&lt;/math&gt;
:&lt;math&gt;\Pr[p_i = 0 | y \neq 0] = \Pr[r_j = 1 \land d_{ij}=-y] \leq \Pr[r_j = 1] = \frac{1}{2}&lt;/math&gt;

Plugging these in the equation ({{EquationNote|1}}), we get:

:&lt;math&gt;
\begin{align}
\Pr[p_i = 0] &amp;\leq \frac{1}{2}\cdot \Pr[y = 0] + \frac{1}{2}\cdot \Pr[y \neq 0]\\
 &amp;= \frac{1}{2}\cdot \Pr[y = 0] + \frac{1}{2}\cdot (1 - \Pr[y = 0])\\
 &amp;= \frac{1}{2}
\end{align}
&lt;/math&gt;

Therefore, 
:&lt;math&gt;\Pr[\vec{P} = 0] = \Pr[p_1 = 0 \land \dots \land p_i = 0 \land \dots \land p_n = 0] \leq \Pr[p_i = 0] \leq \frac{1}{2}.&lt;/math&gt;
This completes the proof.

==Ramifications==
Simple algorithmic analysis shows that the running time of this [[algorithm]] is [[Big O notation|O]](''n''&lt;sup&gt;2&lt;/sup&gt;), beating the classical [[deterministic algorithm|deterministic algorithm's]] bound of [[Big O notation|O]](''n''&lt;sup&gt;3&lt;/sup&gt;). The error analysis also shows that if we run our [[algorithm]] ''k'' times, we can achieve an [[error bound]] of less than &lt;math&gt;\frac{1}{2^k}&lt;/math&gt;, an exponentially small quantity. The algorithm is also fast in practice due to wide availability of fast implementations for matrix-vector products. Therefore, utilization of [[randomized algorithms]] can speed up a very slow [[deterministic algorithm]]. In fact, the best known deterministic matrix multiplication algorithm known at the current time is a variant of the [[Coppersmith–Winograd algorithm]] with an asymptotic running time of [[Big O notation|O]](''n''&lt;sup&gt;2.3729&lt;/sup&gt;).&lt;ref name="williams"/&gt;

Freivalds' algorithm frequently arises in introductions to [[probabilistic algorithm]]s due to its simplicity and how it illustrates the superiority of probabilistic algorithms in practice for some problems.

==See also==
* [[Schwartz–Zippel lemma]]

==References==
{{reflist}}
* Freivalds, R. (1977), “Probabilistic Machines Can Use Less Running Time”, IFIP Congress 1977, pp.&amp;nbsp;839–842.

{{Numerical linear algebra}}

{{DEFAULTSORT:Freivald's Algorithm}}
[[Category:Articles containing proofs]]
[[Category:Matrix theory]]
[[Category:Randomized algorithms]]
[[Category:Matrix multiplication algorithms]]</text>
      <sha1>du51bjvq1yq876inbflls17pmhf16da</sha1>
    </revision>
  </page>
  <page>
    <title>G. B. Halsted</title>
    <ns>0</ns>
    <id>3992708</id>
    <revision>
      <id>841535994</id>
      <parentid>829834604</parentid>
      <timestamp>2018-05-16T12:47:34Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8374">{{Infobox scientist
| name        = George Bruce Halsted
| image       = George Bruce Halsted.jpeg
| image_size  = 
| alt         = 
| caption     = G. B. Halsted, geometer
| birth_date  = {{birth date|1853|11|25}}
| birth_place = [[Newark, New Jersey]]
| death_date  = {{death date and age|1922|03|16| 1853|11|25}}
| death_place = [[New York City]]
| death_cause = 
| resting_place = 
| resting_place_coordinates =  &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names = 
| residence   = 
| citizenship = 
| nationality = United States
| fields      = [[Geometry]]
| workplaces  = [[University of Texas, Austin]]&lt;br&gt;[[Kenyon College]]&lt;br&gt;[[University of Northern Colorado|Colorado State Teachers College]]
| patrons     = 
| education   = 
| alma_mater  = [[Princeton University]]&lt;br&gt;[[Johns Hopkins University]]
| thesis_title = Basis for a Dual Logic
| thesis_url  =
| thesis_year = 1879
| doctoral_advisor = [[J. J. Sylvester]]
| academic_advisors = 
| doctoral_students = 
| notable_students = [[R. L. Moore]]&lt;br&gt;[[L. E. Dickson]]
| known_for   = [[Foundations of geometry]]
| influences  = 
| influenced  = [[Alexander Macfarlane]]
| awards      = 
| spouse      = Margaret Swearingen
| signature   =         &lt;!--(filename only)--&gt;
| signature_alt = 
| website     =         &lt;!--{{URL|www.example.com}}--&gt;
| footnotes   = 
}}

'''George Bruce Halsted''' (November 25, 1853 – March 16, 1922), usually cited as '''G. B. Halsted''', was an American [[mathematician]] who explored foundations of [[geometry]] and introduced [[non-Euclidean geometry]] into the United States through his own work and his many important translations. Especially noteworthy were his translations and commentaries relating to non-Euclidean geometry, including works by [[Bolyai]], [[Lobachevski]], [[Saccheri]], and [[Henri Poincaré|Poincaré]]. He wrote an elementary geometry text, ''Rational Geometry'', based on [[Hilbert's axiom]]s, which was translated into French, [[German language|German]], and [[Japanese language|Japanese]].

==Life==
Halsted was a tutor and instructor at [[Princeton University]]. He held a mathematical fellowship while a student at Princeton. Halsted was a fourth generation Princeton graduate, earning his Bachelor's degree in 1875 and his Master's in 1878. He went on to [[Johns Hopkins University]] where he was [[J. J. Sylvester]]'s first student, receiving his Ph.D. in 1879. After graduation, Halsted served as an instructor in mathematics at Princeton until beginning his post at the University of Texas at Austin in 1884.

From 1884 to 1903, Halsted was a member of the [[University of Texas at Austin]] Department of Pure and Applied Mathematics, eventually becoming its chair.  He taught mathematicians [[R. L. Moore]] and [[L. E. Dickson]], among other students, who frequently joked that his primary criterion for the rationality of a geometric system was the simplicity of the terms in which it could express the closed space figure formed by the contours of his mustache.  He explored the foundations of geometry and explored many alternatives to Euclid's development, culminating with his ''Rational Geometry''. 
In the interest of [[hyperbolic geometry]] in 1891 he translated the work of [[Nicolai Lobachevsky]] on theory of parallels.&lt;ref&gt;Nicholaus Lobatschewsky (1840) G.B. Halsted translator (1891) [https://books.google.com/books?id=GJBsAAAAMAAJ Geometrical Researches on the Theory of Parallels], link from [[Google Books]]&lt;/ref&gt; In 1893 in Chicago, Halsted read a paper ''Some salient points in the history of non-Euclidean and hyper-spaces'' at the International Mathematical Congress held in connection with the [[World's Columbian Exposition]].&lt;ref&gt;{{cite book|chapter=''Some salient points in the history of non-Euclidean and hyper-spaces'' by George Bruce Halsted|title=Mathematical papers read at the International Mathematical Congress held in connection with the World's Columbian Exposition|year=1896|pages=92–95|location=NY|publisher=Macmillan as publisher for the AMS|url=http://babel.hathitrust.org/cgi/pt?id=uc1.b3841648;view=1up;seq=114}}&lt;/ref&gt; Halsted frequently contributed to the early [[American Mathematical Monthly]]. In one article&lt;ref&gt;{{cite journal|last1=Halsted|first1=G. B.|title=Duncan M. Y. Sommerville|journal=American Mathematical Monthly|date=1912|volume=19|pages=1–4|doi=10.2307/2973871}}[https://www.jstor.org/stable/2973871]&lt;/ref&gt; he championed the role of [[János Bolyai|J. Bolyai]] in the development of [[non-Euclidean geometry]] and criticized [[Carl Friedrich Gauss|C. F. Gauss]].&lt;ref&gt;{{cite journal|last1=Sondow|first1=J.|title=From the ''Monthly'' Over 100 Years Ago…|journal=American Mathematical Monthly|date=2014|volume=121|pages=963|doi=10.4169/amer.math.monthly.121.10.963|arxiv=1405.4198}}[https://www.jstor.org/stable/10.4169/amer.math.monthly.121.10.963] [https://arxiv.org/abs/math/1405.4198 arXiv] "Gauss and the eccentric Halsted".&lt;/ref&gt; See also [[s:Robert Gauss to Felix Klein - September 3, 1912|the letter from Robert Gauss to Felix Klein]] on 3 September 1912.

In 1903, Halsted was fired from UT Austin after having published several articles that criticized the university for having passed over R. L. Moore, at that time a young and promising mathematician whom Halsted hoped to have as an assistant, for an instructor post in favor of a well-connected but less qualified candidate with roots in the area.&lt;ref&gt;John Parker (2005) [https://books.google.com/books/about/R_L_Moore.html?id=3ovYMlnUPaQC ''R.L. Moore: Mathematician and Teacher''], Mathematical Association of America, Washington, DC, {{isbn|0-88385-550-X}}, pp. 36-37.&lt;/ref&gt; 
He completed his teaching career at St. John's College, Annapolis; [[Kenyon College]], Gambier, Ohio (1903-1906); and the [[University of Northern Colorado|Colorado State Teachers College]], Greeley (1906-1914).

[[File:George Halsted and grandson.gif|right|thumb|George Halsted holding grandson, 1920]]
Halsted was a member of the [[American Mathematical Society]] and served as vice president of the [[American Association for the Advancement of Science]].  He was elected Fellow of the [[Royal Astronomical Society]] in 1905.&lt;ref&gt;[http://mnras.oxfordjournals.org/content/65/3/185.full.pdf+html Meeting of Royal Astronomical Society, January 1905], [[Monthly Notices of the Royal Astronomical Society]] 65(2): 185&lt;/ref&gt;

== Publications ==
* [https://archive.org/details/metricalgeometry00halsuoft Metrical geometry; An elementary treatise on mensuration] (Boston, Ginn, 1890), link from [[Internet Archive]].
* [https://archive.org/details/elementsofgeomet00halsuoft The elements of geometry] (New York, Wiley, 1889), @ Internet Archive.
* (translation): [http://digital.library.yale.edu/cdm/ref/collection/rebooks/id/167460 New Principles of Geometry with a Complete Theory of Parallels] by [[Lobachevsky]], (Austin, Neomon, 1897) link from [[Yale University]]
* [https://archive.org/details/syntheticproject00halsuoft Synthetic projective geometry] (New York, Wiley, 1906), @ Internet Archive.
* [https://archive.org/details/onfoundationtech00halsuoft On the foundation and technic of arithmetic] (Chicago, Open Court, 1912), @ Internet Archive.

==See also==
* [[Foundations of geometry]]

==References==
{{reflist}}
* [http://www-history.mcs.st-and.ac.uk/Biographies/Halsted.html "George Bruce Halsted"], J J O'Connor and E F Robertson, School of Mathematics and Statistics, [[University of St Andrews]], Scotland.
* [[Arthur Hathaway]] (1897) [https://archive.org/details/jstor-1623392 Review: ''Non-Euclidean Geometry, or the Science of Absolute Space''], by Bolyai, translated by Halsted, in [[Science (journal)|Science]], February 19, link from [[Jstor]] Early Content.

==External links==
* {{Gutenberg author | id=Halsted,+George+Bruce | name=George Bruce Halsted}}
* {{Internet Archive author |sname=George Bruce Halsted}}
*{{MathGenealogy|id=36417}}

{{Authority control}}

{{DEFAULTSORT:Halsted}}
[[Category:1853 births]]
[[Category:1922 deaths]]
[[Category:Princeton University alumni]]
[[Category:Johns Hopkins University alumni]]
[[Category:University of Texas at Austin faculty]]
[[Category:19th-century American mathematicians]]
[[Category:20th-century American mathematicians]]
[[Category:Kenyon College faculty]]
[[Category:University of Northern Colorado faculty]]
[[Category:Geometers]]</text>
      <sha1>r1ihts7u5a7gtfn5wv3udf22bkodr9p</sha1>
    </revision>
  </page>
  <page>
    <title>Gauss–Kuzmin–Wirsing operator</title>
    <ns>0</ns>
    <id>1360654</id>
    <revision>
      <id>862709121</id>
      <parentid>852441792</parentid>
      <timestamp>2018-10-06T05:18:33Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11124">In [[mathematics]], the '''Gauss–Kuzmin–Wirsing operator''' is the [[transfer operator]] of the Gauss map. 

==Name==
It is named after:
* [[Carl Gauss]]
* [[Rodion Kuzmin|Rodion Osievich Kuzmin]] 
* [[Eduard Wirsing]]
==Importance==
It occurs in the study of [[continued fractions]]; it is also related to the [[Riemann zeta function]].


==Relationship to the maps and continued fractions==

===The Gauss map === 
[[File:Gauss function.svg|thumb|right|File:Gauss function]]
The Gauss function (map) h is : 

:&lt;math&gt;h(x)=1/x-\lfloor 1/x \rfloor.&lt;/math&gt;

where:
* &lt;math&gt;\lfloor 1/x \rfloor&lt;/math&gt; denotes [[Floor_and_ceiling_functions|floor function]]

It has an infinite number of [[Classification_of_discontinuities#Jump_discontinuity|jump discontinuities]] at x = 1/n, for positive integers n. It is hard to approximate it by a single smooth polynomial.&lt;ref&gt;[https://www.springer.com/us/book/9781461484523 A Graduate Introduction to Numerical Methods From the Viewpoint of Backward Error Analysis by Corless, Robert, Fillion, Nicolas]&lt;/ref&gt;

===operator on the maps ===
The Gauss–Kuzmin–Wirsing [[transfer operator|operator]] &lt;math&gt; G&lt;/math&gt; acts on functions &lt;math&gt;f&lt;/math&gt; as

:&lt;math&gt;[Gf](x) = \sum_{n=1}^\infty \frac {1}{(x+n)^2} f \left(\frac {1}{x+n}\right).&lt;/math&gt;
===Eigenvalues of the operator===


The first [[eigenfunction]] of this operator is

:&lt;math&gt;\frac 1{\ln 2}\ \frac 1{1+x}&lt;/math&gt;

which corresponds to an [[eigenvalue]] of ''λ''&lt;sub&gt;1&lt;/sub&gt;=1. This eigenfunction gives the probability of the occurrence of a given integer in a continued fraction expansion, and is known as the [[Gauss–Kuzmin distribution]].  This follows in part because the Gauss map acts as a truncating [[shift operator]] for the [[continued fraction]]s: if

: &lt;math&gt;x=[0;a_1,a_2,a_3,\dots]&lt;/math&gt;

is the continued fraction representation of a number 0&amp;nbsp;&lt;&amp;nbsp;''x''&amp;nbsp;&lt;&amp;nbsp;1, then

: &lt;math&gt;h(x)=[0;a_2,a_3,\dots].&lt;/math&gt;

Additional eigenvalues can be computed numerically; the next eigenvalue is ''λ''&lt;sub&gt;2&lt;/sub&gt; = −0.3036630029... {{OEIS|A038517}}
and its absolute value is known as the '''Gauss–Kuzmin–Wirsing constant'''. Analytic forms for additional eigenfunctions are not known.  It is not known if the eigenvalues are [[irrational]].



Let us arrange the eigenvalues of the Gauss–Kuzmin–Wirsing operator according to an absolute value:

:&lt;math&gt;1=|\lambda_{1}|\geq |\lambda_{2}|\geq|\lambda_{3}|\geq\cdots.&lt;/math&gt;

It was conjectured in 1995 by [[Philippe Flajolet]] and [[Brigitte Vallée]] that

:&lt;math&gt;\lim\limits_{n\rightarrow\infty}\frac{\lambda_{n}}{\lambda_{n+1}}=-\phi^{2},\text{ where }\phi=\frac{1+\sqrt{5}}{2}.&lt;/math&gt;

In 2014, Giedrius Alkauskas proved this conjecture.&lt;ref&gt;{{cite arxiv |last1=Alkauskas |first1=Giedrius |year=2012 |title=Transfer operator for the Gauss' continued fraction map. I. Structure of the eigenvalues and trace formulas |eprint=1210.4083 |class=math.NT}}&lt;/ref&gt; Moreover, the following asymptotic result holds:

:&lt;math&gt;(-1)^{n+1}\lambda_{n}=\phi^{-2n}
+C\cdot\frac{\phi^{-2n}}{\sqrt{n}}+d(n)\cdot\frac{\phi^{-2n}}{n},
\text{ where }C=\frac{\sqrt[4]{5}\cdot\zeta(3/2)}{2\sqrt{\pi}}=1.1019785625880999_{+};&lt;/math&gt;
here the function &lt;math&gt;d(n)&lt;/math&gt; is bounded, and &lt;math&gt;\zeta(\star)&lt;/math&gt; is the [[Riemann zeta function]].

===Continuous spectrum===
The eigenvalues form a discrete spectrum, when the operator is limited to act on functions on the unit interval of the real number line.  More broadly, since the Gauss map is the shift operator on [[Baire space (set theory)|Baire space]] &lt;math&gt;\mathbb{N}^\omega&lt;/math&gt;, the GKW operator can also be viewed as an operator on the function space &lt;math&gt;\mathbb{N}^\omega\to\mathbb{C}&lt;/math&gt; (considered as a [[Banach space]], with basis functions taken to be the [[indicator function]]s on the [[cylinder set|cylinders]] of the [[product topology]]).  In the later case, it has a continuous spectrum, with eigenvalues in the unit disk &lt;math&gt;|\lambda|&lt;1&lt;/math&gt; of the complex plane.  That is, given the cylinder &lt;math&gt;C_n[b]= \{(a_1,a_2,\cdots) \in \mathbb{N}^\omega : a_n = b \}&lt;/math&gt;, the operator G shifts it to the left: &lt;math&gt;GC_n[b] = C_{n-1}[b]&lt;/math&gt;. Taking &lt;math&gt;r_{n,b}(x)&lt;/math&gt; to be the indicator function which is 1 on the cylinder (when &lt;math&gt;x\in C_n[b]&lt;/math&gt;), and zero otherwise, one has that &lt;math&gt;Gr_{n,b}=r_{n-1,b}&lt;/math&gt;.  The series

:&lt;math&gt;f(x)=\sum_{n=1}^\infty \lambda^{n-1} r_{n,b}(x)&lt;/math&gt;

then is an eigenfunction with eigenvalue &lt;math&gt;\lambda&lt;/math&gt;. That is, one has &lt;math&gt;[Gf](x)=\lambda f(x)&lt;/math&gt; whenever the summation converges: that is, when &lt;math&gt;|\lambda|&lt;1&lt;/math&gt;.

A special case arises when one wishes to consider the [[Haar measure]] of the shift operator, that is, a function that is invariant under shifts.  This is given by the [[Minkowski's question mark function|Minkowski measure]] &lt;math&gt;?^\prime&lt;/math&gt;. That is, one has that &lt;math&gt;G?^\prime = ?^\prime&lt;/math&gt;.&lt;ref&gt;{{cite arxiv |last1=Vepstas |first1=Linas |year=2008 |title=On the Minkowski Measure |eprint=0810.1265 |class=math.DS}}&lt;/ref&gt;

==Relationship to the Riemann zeta==
The GKW operator is related to the [[Riemann zeta function]]. Note that the zeta function can be written as

:&lt;math&gt;\zeta(s)=\frac{1}{s-1}-s\int_0^1 h(x) x^{s-1} \; dx&lt;/math&gt;

which implies that

:&lt;math&gt;\zeta(s)=\frac{s}{s-1}-s\int_0^1 x \left[Gx^{s-1} \right]\, dx &lt;/math&gt;

by change-of-variable.

===Matrix elements===
Consider the [[Taylor series]] expansions at x=1 for a function ''f''(''x'') and &lt;math&gt;g(x)=[Gf](x)&lt;/math&gt;.  That is, let

:&lt;math&gt;f(1-x)=\sum_{n=0}^\infty (-x)^n \frac{f^{(n)}(1)}{n!}&lt;/math&gt;

and write likewise for ''g''(''x'').  The expansion is made about ''x''&amp;nbsp;=&amp;nbsp;1 because the GKW operator is poorly behaved at ''x''&amp;nbsp;=&amp;nbsp;0.  The expansion is made about 1-x so that we can keep ''x'' a positive number, 0&amp;nbsp;&amp;le;&amp;nbsp;''x''&amp;nbsp;&amp;le;&amp;nbsp;1. Then the GKW operator acts on the Taylor coefficients as

:&lt;math&gt;(-1)^m \frac{g^{(m)}(1)}{m!} = \sum_{n=0}^\infty G_{mn} (-1)^n \frac{f^{(n)}(1)}{n!},&lt;/math&gt;

where the matrix elements of the GKW operator are given by

:&lt;math&gt;G_{mn}=\sum_{k=0}^n (-1)^k {n \choose k} {k+m+1 \choose m} \left[ \zeta (k+m+2)- 1\right].&lt;/math&gt;

This operator is extremely well formed, and thus very numerically tractable. The Gauss–Kuzmin constant is easily computed to high precision by numerically diagonalizing the upper-left ''n'' by ''n'' portion.  There is no known closed-form expression that diagonalizes this operator; that is, there are no closed-form expressions known for the eigenvectors.

===Riemann zeta===
The Riemann zeta can be written as

:&lt;math&gt;\zeta(s)=\frac{s}{s-1}-s \sum_{n=0}^\infty (-1)^n {s-1 \choose n} t_n&lt;/math&gt;

where the &lt;math&gt;t_n&lt;/math&gt; are given by the matrix elements above:

:&lt;math&gt;t_n=\sum_{m=0}^\infty \frac{G_{mn}} {(m+1)(m+2)}.&lt;/math&gt;

Performing the summations, one gets:

:&lt;math&gt;t_n=1-\gamma + \sum_{k=1}^n (-1)^k {n \choose k} \left[ \frac{1}{k} - \frac {\zeta(k+1)} {k+1} \right]&lt;/math&gt;

where &lt;math&gt;\gamma&lt;/math&gt; is the [[Euler–Mascheroni constant]]. These &lt;math&gt;t_n&lt;/math&gt; play the analog of the [[Stieltjes constants]], but for the [[falling factorial]] expansion. By writing

:&lt;math&gt;a_n=t_n - \frac{1}{2(n+1)}&lt;/math&gt;

one gets: ''a''&lt;sub&gt;0&lt;/sub&gt; = &amp;minus;0.0772156... and ''a''&lt;sub&gt;1&lt;/sub&gt; = &amp;minus;0.00474863... and so on. The values get small quickly but are oscillatory.  Some explicit sums on these values can be performed.  They can be explicitly related to the Stieltjes constants by re-expressing the falling factorial as a polynomial with [[Stirling number]] coefficients, and then solving. More generally, the Riemann zeta can be re-expressed as an expansion in terms of [[Sheffer sequence]]s of polynomials.

This expansion of the Riemann zeta is investigated in the following references.&lt;ref&gt; {{cite journal  |last1=Yeremin |first1=A. Yu.  |last2=Kaporin |first2=I. E.  |last3=Kerimov |first3=M. K.  |year=1985  |title=The calculation of the Riemann zeta-function in the complex domain  |journal=USSR Comput. Math. and Math. Phys.  |volume=25 |issue=2 |pages=111–119 }}&lt;/ref&gt;&lt;ref&gt; {{cite journal  |last1=Yeremin |first1=A. Yu.  |last2=Kaporin |first2=I. E.  |last3=Kerimov |first3=M. K.  |year=1988  |title=Computation of the derivatives of the Riemann zeta-function in the complex domain  |journal=USSR Comput. Math. and Math. Phys.  |volume=28 |issue=4 |pages=115–124 }}&lt;/ref&gt;&lt;ref&gt; {{cite arxiv  |last1=Báez-Duarte |first1=Luis  |year=2003    |title=A new necessary and sufficient condition for the Riemann hypothesis   |eprint=math.NT/0307215 }}&lt;/ref&gt;&lt;ref&gt; {{cite journal  |last1=Báez-Duarte |first1=Luis  |year=2005  |title=A sequential Riesz-like criterion for the Riemann hypothesis  |journal=International Journal of Mathematics and Mathematical Sciences  |volume=21 |pages=3527–3537 }}&lt;/ref&gt;&lt;ref&gt; {{Cite journal  |last1=Flajolet |first1=Philippe  |last2=Vepstas|first2=Linas  |year=2006  |title=On Differences of Zeta Values  |journal=Journal of Computational and Applied Mathematics  |volume=220 |issue= |pages=58  |arxiv=math.CA/0611332  |bibcode=2008JCoAM.220...58F  |doi=10.1016/j.cam.2007.07.040 }}&lt;/ref&gt; The coefficients are decreasing as
:&lt;math&gt;\left(\frac{2n}{\pi}\right)^{1/4}e^{-\sqrt{4\pi n}}
\cos\left(\sqrt{4\pi n}-\frac{5\pi}{8}\right) +
\mathcal{O} \left(\frac{e^{-\sqrt{4\pi n}}}{n^{1/4}}\right).&lt;/math&gt;

==References==
&lt;references/&gt;

==General references==
* [[Aleksandr Khinchin|A. Ya. Khinchin]], ''Continued Fractions'', 1935, English translation University of Chicago Press,  1961 {{ISBN|0-486-69630-8}} ''(See section 15).''
* K. I. Babenko, ''On a Problem of Gauss'', Soviet Mathematical Doklady '''19''':136–140 (1978) {{MR|472746}}
* K. I. Babenko and S. P. Jur'ev, ''On the Discretization of a Problem of Gauss'', Soviet Mathematical Doklady '''19''':731–735 (1978). {{MR|499751}}
* A. Durner,  ''On a Theorem of Gauss–Kuzmin–Lévy.'' Arch. Math. '''58''', 251–256, (1992). {{MR|1148200 }}
* A. J. MacLeod, ''High-Accuracy Numerical Values of the Gauss–Kuzmin Continued Fraction Problem.'' Computers Math. Appl. '''26''', 37–44, (1993).
* E. Wirsing, ''On the Theorem of Gauss–Kuzmin–Lévy and a Frobenius-Type Theorem for Function Spaces.'' Acta Arith. '''24''', 507–528, (1974). {{MR|337868 }}

==Further reading==
* Keith Briggs, ''[http://keithbriggs.info/documents/wirsing.pdf A precise computation of the Gauss–Kuzmin–Wirsing constant]'' (2003) ''(Contains a very  extensive collection of references.)''
* Phillipe Flajolet and [[Brigitte Vallée]], ''[http://pauillac.inria.fr/algo/flajolet/Publications/gauss-kuzmin.ps On the Gauss–Kuzmin–Wirsing Constant]'' (1995).
* Linas Vepstas [http://www.linas.org/math/gkw.pdf  The Bernoulli Operator, the Gauss–Kuzmin–Wirsing Operator, and the Riemann Zeta] (2004) (PDF)

== External links ==
* {{MathWorld|urlname=Gauss-Kuzmin-WirsingConstant|title=Gauss-Kuzmin-Wirsing Constant}}
* {{OEIS el|1=A038517|2=Decimal expansion of Gauss-Kuzmin-Wirsing constant}}

{{DEFAULTSORT:Gauss-Kuzmin-Wirsing operator}}
[[Category:Continued fractions]]
[[Category:Dynamical systems]]</text>
      <sha1>mpbgq2h776ky6bjlfop80oc0y262vfc</sha1>
    </revision>
  </page>
  <page>
    <title>Gordon–Newell theorem</title>
    <ns>0</ns>
    <id>21256722</id>
    <revision>
      <id>790709631</id>
      <parentid>774268194</parentid>
      <timestamp>2017-07-15T15:42:14Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Theorem */LaTeX spacing clean up, replaced: \, &lt;/math&gt; → &lt;/math&gt; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4127">In [[queueing theory]], a discipline within the mathematical [[probability theory|theory of probability]], the '''Gordon–Newell theorem''' is an extension of [[Jackson's theorem (queueing theory)|Jackson's theorem]] from open queueing networks to closed queueing networks of exponential servers where customers cannot leave the network.&lt;ref&gt;{{Cite journal | last1 = Gordon | first1 = W. J. | last2 = Newell | first2 = G. F. | authorlink2 = Gordon F. Newell| doi = 10.1287/opre.15.2.254 | jstor = 168557| title = Closed Queuing Systems with Exponential Servers | journal = [[Operations Research (journal)|Operations Research]]| volume = 15 | issue = 2 | pages = 254 | year = 1967 | pmid =  | pmc = }}&lt;/ref&gt; Jackson's theorem cannot be applied to closed networks because the queue length at a node in the closed network is limited by the population of the network. The Gordon&amp;ndash;Newell theorem calculates the open network solution and then eliminates the infeasible states by renormalizing the probabilities. Calculation of the [[normalizing constant]] makes the treatment more awkward as the whole state space must be enumerated. [[Buzen's algorithm]] or [[mean value analysis]] can be used to calculate the normalizing constant more efficiently.&lt;ref&gt;{{Cite journal | last1 = Buzen | first1 = J. P. | authorlink = Jeffrey P. Buzen| title = Computational algorithms for closed queueing networks with exponential servers | doi = 10.1145/362342.362345 | url = http://www-unix.ecs.umass.edu/~krishna/ece673/buzen.pdf| journal = Communications of the ACM | volume = 16 | issue = 9 | pages = 527 | year = 1973 | pmid =  | pmc = }}&lt;/ref&gt;

==Definition of a Gordon–Newell network==

A network of ''m'' interconnected queues is known as a '''Gordon–Newell network'''&lt;ref&gt;{{Cite journal | last1 = Daduna | first1 = H. | title = Passage Times for Overtake-Free Paths in Gordon-Newell Networks | journal = Advances in Applied Probability | volume = 14 | issue = 3 | pages = 672–686 | doi = 10.2307/1426680 | year = 1982 | pmid =  | pmc = }}&lt;/ref&gt; or '''closed Jackson network'''&lt;ref&gt;{{Cite journal | last1 = Gong | first1 = Q. | last2 = Lai | first2 = K. K. | last3 = Wang | first3 = S. | doi = 10.1016/j.ijpe.2007.10.013 | title = Supply chain networks: Closed Jackson network models and properties | journal = International Journal of Production Economics | volume = 113 | issue = 2 | pages = 567 | year = 2008 | pmid =  | pmc = }}&lt;/ref&gt; if it meets the following conditions:

# the network is closed (no customers can enter or leave the network),
# all service times are exponentially distributed and the service discipline at all queues is [[FCFS]],
# a customer completing service at queue ''i'' will move to queue ''j'' with probability &lt;math&gt;P_{ij}&lt;/math&gt;, with the &lt;math&gt;P_{ij}&lt;/math&gt; such that &lt;math&gt;\scriptstyle{\sum_{j =1}^m P_{ij} = 1}&lt;/math&gt;,
# the utilization of all of the queues is less than one.

==Theorem==

In a closed Gordon&amp;ndash;Newell network of ''m'' queues, with a total population of ''K'' individuals, write &lt;math&gt;\scriptstyle{(k_1,k_2,\ldots,k_m)}&lt;/math&gt; (where ''k''&lt;sub&gt;''i''&lt;/sub&gt; is the length of queue ''i'') for the state of the network and ''S''(''K'',&amp;nbsp;''m'') for the state space

:&lt;math&gt;S(K,m) = \left\{ \mathbf{k} \in \mathbb{N}^m \text{ such that } \sum_{i=1}^m k_i = K \right\}.&lt;/math&gt;

Then the equilibrium state probability distribution exists and is given by

:&lt;math&gt;\pi (k_1,k_2,\ldots,k_m) = \frac{1}{G(K)} \prod_{i=1}^m \left( \frac{e_i}{\mu_i} \right)^{k_i}&lt;/math&gt;

where service times at queue ''i'' are exponentially distributed with parameter ''μ&lt;sub&gt;i&lt;/sub&gt;''. The normalizing constant ''G''(''K'') is given by

:&lt;math&gt;G(K) = \sum_{\mathbf{k} \in S(K,m)} \prod_{i=1}^{m} \left( \frac{e_i}{\mu_i} \right)^{k_i} ,&lt;/math&gt;

and ''e''&lt;sub&gt;''i''&lt;/sub&gt; is the visit ratio, calculated by solving the simultaneous equations

:&lt;math&gt;e_i = \sum_{j=1}^m e_j p_{ji} \text{ for }1 \leq i \leq m. &lt;/math&gt;

==See also==
*[[BCMP network]]

==References==
{{Reflist}}

{{Queueing theory}}

{{DEFAULTSORT:Gordon-Newell theorem}}
[[Category:Probability theorems]]
[[Category:Queueing theory]]</text>
      <sha1>d4qrehqia2wc99ov8tl19k1bpyu4gs8</sha1>
    </revision>
  </page>
  <page>
    <title>Gårding's inequality</title>
    <ns>0</ns>
    <id>7999626</id>
    <revision>
      <id>772157503</id>
      <parentid>766335936</parentid>
      <timestamp>2017-03-25T17:15:07Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <comment>/* Application: the Laplace operator and the Poisson problem */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4890">In [[mathematics]], '''Gårding's inequality''' is a result that gives a lower bound for the [[bilinear form]] induced by a real [[Elliptic operator|linear elliptic partial differential operator]]. The inequality is named after [[Lars Gårding]].

==Statement of the inequality==

Let Ω be a [[bounded set|bounded]], [[open set|open domain]] in ''n''-[[dimension]]al [[Euclidean space]] and let ''H''&lt;sup&gt;''k''&lt;/sup&gt;(Ω) denote the [[Sobolev space]] of ''k''-times weakly differentiable functions ''u''&amp;nbsp;:&amp;nbsp;Ω&amp;nbsp;→&amp;nbsp;'''R''' with weak derivatives in ''L''&lt;sup&gt;2&lt;/sup&gt;. Assume that Ω satisfies the ''k''-extension property, i.e., that there exists a [[bounded linear operator]] ''E''&amp;nbsp;:&amp;nbsp;''H''&lt;sup&gt;''k''&lt;/sup&gt;(Ω)&amp;nbsp;→&amp;nbsp;''H''&lt;sup&gt;''k''&lt;/sup&gt;('''R'''&lt;sup&gt;''n''&lt;/sup&gt;) such that (''Eu'')|&lt;sub&gt;Ω&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''u'' for all ''u'' in ''H''&lt;sup&gt;''k''&lt;/sup&gt;(Ω).

Let ''L'' be a linear partial differential operator of even order ''2k'', written in divergence form

:&lt;math&gt;(L u)(x) = \sum_{0 \leq | \alpha |, | \beta | \leq k} (-1)^{| \alpha |} \mathrm{D}^{\alpha} \left( A_{\alpha \beta} (x) \mathrm{D}^{\beta} u(x) \right),&lt;/math&gt;

and suppose that ''L'' is uniformly elliptic, i.e., there exists a constant ''&amp;theta;'' &gt; 0 such that

:&lt;math&gt;\sum_{| \alpha |, | \beta | = k} \xi^{\alpha} A_{\alpha \beta} (x) \xi^{\beta} &gt; \theta | \xi |^{2 k} \mbox{ for all } x \in \Omega, \xi \in \mathbb{R}^{n} \setminus \{ 0 \}.&lt;/math&gt;

Finally, suppose that the coefficients ''A&lt;sub&gt;&amp;alpha;&amp;beta;&lt;/sub&gt;'' are [[bounded function|bounded]], [[continuous function]]s on the [[closure (topology)|closure]] of Ω for |''&amp;alpha;''| = |''&amp;beta;''| = ''k'' and that

:&lt;math&gt;A_{\alpha \beta} \in L^{\infty} (\Omega) \mbox{ for all } | \alpha |, | \beta | \leq k.&lt;/math&gt;

Then '''Gårding's inequality''' holds: there exist constants ''C''&amp;nbsp;&gt;&amp;nbsp;0 and ''G''&amp;nbsp;≥&amp;nbsp;0

:&lt;math&gt;B[u, u] + G \| u \|_{L^{2} (\Omega)}^{2} \geq C \| u \|_{H^{k} (\Omega)}^{2} \mbox{ for all } u \in H_{0}^{k} (\Omega),&lt;/math&gt;

where

:&lt;math&gt;B[v, u] = \sum_{0 \leq | \alpha |, | \beta | \leq k} \int_{\Omega} A_{\alpha \beta} (x) \mathrm{D}^{\alpha} u(x) \mathrm{D}^{\beta} v(x) \, \mathrm{d} x&lt;/math&gt;

is the bilinear form associated to the operator ''L''.

==Application: the Laplace operator and the Poisson problem==

'''Be careful, in this application, Garding's Inequality seems useless here as the final result is a direct consequence of Poincaré's Inequality, or Friedrich Inequality. (See talk on the article).''' 

As a simple example, consider the [[Laplace operator]] Δ.  More specifically, suppose that one wishes to solve, for ''f''&amp;nbsp;∈&amp;nbsp;''L''&lt;sup&gt;2&lt;/sup&gt;(Ω) the [[Poisson equation]]

:&lt;math&gt;\begin{cases} - \Delta u(x) = f(x), &amp; x \in \Omega; \\ u(x) = 0, &amp; x \in \partial \Omega; \end{cases}&lt;/math&gt;

where Ω is a bounded [[Lipschitz domain]] in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;.  The corresponding weak form of the problem is to find ''u'' in the Sobolev space ''H''&lt;sub&gt;0&lt;/sub&gt;&lt;sup&gt;1&lt;/sup&gt;(Ω) such that

:&lt;math&gt;B[u, v] = \langle f, v \rangle \mbox{ for all } v \in H_{0}^{1} (\Omega),&lt;/math&gt;

where

:&lt;math&gt;B[u, v] = \int_{\Omega} \nabla u(x) \cdot \nabla v(x) \, \mathrm{d} x,&lt;/math&gt;
:&lt;math&gt;\langle f, v \rangle = \int_{\Omega} f(x) v(x) \, \mathrm{d} x.&lt;/math&gt;

The [[Lax–Milgram lemma]] ensures that if the bilinear form ''B'' is both continuous and elliptic with respect to the norm on ''H''&lt;sub&gt;0&lt;/sub&gt;&lt;sup&gt;1&lt;/sup&gt;(Ω), then, for each ''f''&amp;nbsp;∈&amp;nbsp;''L''&lt;sup&gt;2&lt;/sup&gt;(Ω), a unique solution ''u'' must exist in ''H''&lt;sub&gt;0&lt;/sub&gt;&lt;sup&gt;1&lt;/sup&gt;(Ω).  The hypotheses of Gårding's inequality are easy to verify for the Laplace operator Δ, so there exist constants ''C'' and ''G''&amp;nbsp;≥&amp;nbsp;0

:&lt;math&gt;B[u, u] \geq C \| u \|_{H^{1} (\Omega)}^{2} - G \| u \|_{L^{2} (\Omega)}^{2}  \mbox{ for all } u \in H_{0}^{1} (\Omega).&lt;/math&gt;

Applying the [[Poincaré inequality]] allows the two terms on the right-hand side to be combined, yielding a new constant ''K''&amp;nbsp;&amp;gt;&amp;nbsp;0 with

:&lt;math&gt;B[u, u] \geq K \| u \|_{H^{1} (\Omega)}^{2} \mbox{ for all } u \in H_{0}^{1} (\Omega),&lt;/math&gt;

which is precisely the statement that ''B'' is elliptic.  The continuity of ''B'' is even easier to see:  simply apply the [[Cauchy–Schwarz inequality]] and the fact that the Sobolev norm is controlled by the ''L''&lt;sup&gt;2&lt;/sup&gt; norm of the gradient.

==References==

* {{cite book
|author1=Renardy, Michael  |author2=Rogers, Robert C.
|    title = An introduction to partial differential equations
|   series = Texts in Applied Mathematics 13
|  edition = Second
|publisher = Springer-Verlag
| location = New York
|     year = 2004
|     isbn = 0-387-00444-0
|    page = 356
}} (Theorem 9.17)

{{DEFAULTSORT:Garding's inequality}}
[[Category:Theorems in functional analysis]]
[[Category:Inequalities]]
[[Category:Partial differential equations]]
[[Category:Sobolev spaces]]</text>
      <sha1>gyz3hpbea3lj4une0ywp113x4pjsos7</sha1>
    </revision>
  </page>
  <page>
    <title>Hilbert metric</title>
    <ns>0</ns>
    <id>22154619</id>
    <revision>
      <id>846633463</id>
      <parentid>843195687</parentid>
      <timestamp>2018-06-19T23:56:13Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6466">In [[mathematics]], the '''Hilbert metric''', also known as the '''Hilbert projective metric''', is an explicitly defined [[metric (mathematics)|distance function]] on a bounded [[convex set|convex subset]] of the ''n''-dimensional [[Euclidean space]] '''R'''&lt;sup&gt;''n''&lt;/sup&gt;. It was introduced by {{harvs|txt|authorlink=David Hilbert|first=David |last=Hilbert|year=1895}} as a generalization of the [[Cayley metric|Cayley's formula]] for the distance in the [[Klein model|Cayley–Klein model]] of [[hyperbolic geometry]], where the convex set is the ''n''-dimensional open [[unit ball]]. Hilbert's metric has been applied to [[Perron–Frobenius theorem|Perron–Frobenius theory]] and to constructing [[Gromov hyperbolic space]]s.

== Definition ==

Let &amp;Omega; be a [[convex set|convex]] [[open set|open]] domain in a [[Euclidean space]] that does not contain a line. Given two distinct points ''A'' and ''B'' of &amp;Omega;, let ''X'' and ''Y'' be the points at which the straight line ''AB'' intersects the boundary of &amp;Omega;, where the order of the points is ''X'', ''A'', ''B'', ''Y''. Then the [https://arxiv.org/abs/1704.00454 '''Hilbert distance'''] ''d''(''A'',&amp;nbsp;''B'') is the [[logarithm]] of the [[cross-ratio]] of this quadruple of points:

: &lt;math&gt; d(A,B)=\log\left(\frac{|YA|}{|YB|}\frac{|XB|}{|XA|}\right). &lt;/math&gt;

The function ''d'' is extended to all pairs of points by letting ''d''(''A'',&amp;nbsp;''A'')&amp;nbsp;=&amp;nbsp;0 and defines a [[metric (mathematics)|metric]] on &amp;Omega;. If one of the points ''A'' and ''B'' lies on the boundary of &amp;Omega; then ''d'' can be formally defined to be&amp;nbsp;+∞, corresponding to a limiting case of the above formula 
when one of the denominators is zero.
Hilbert balls in convex polygonal domains have [http://drops.dagstuhl.de/opus/volltexte/2017/7244/pdf/LIPIcs-SoCG-2017-67.pdf varying combinatorial complexity].

A variant of this construction arises for a [[closed set|closed]] [[convex cone]] ''K'' in a [[Banach space]] ''V'' (possibly, infinite-dimensional). In addition, the cone ''K'' is assumed to be ''pointed'', i.e.  ''K''&amp;nbsp;∩&amp;nbsp;(&amp;minus;''K'')&amp;nbsp;=&amp;nbsp;{0} and thus ''K'' determines a [[Convex cone#Partial order defined by a convex cone|partial order]] &lt;math&gt;\leq_K&lt;/math&gt; on ''V''. Given any vectors ''v'' and ''w'' in ''K''&amp;nbsp;\&amp;nbsp;{0}, one first defines

: &lt;math&gt; M(v/w)=\inf\{\lambda:v\leq_K\lambda w\}, \quad m(v/w)=\sup\{\mu:\mu w \leq_K v\}. &lt;/math&gt;
The / notation is to emphasize that  : &lt;math&gt;M(v/w)\not = M(w/v)&lt;/math&gt;.

The '''Hilbert pseudometric''' on ''K''&amp;nbsp;\&amp;nbsp;{0} is then defined by the formula

: &lt;math&gt; d(v,w)=\log\frac{M(v/w)}{m(v/w)}. &lt;/math&gt;

It is invariant under the rescaling of ''v'' and ''w'' by positive constants and so descends to a metric on the space of rays of ''K'', which is interpreted as the [[projectivization]] of ''K'' (in order for ''d'' to be finite, one needs to restrict to the interior of ''K''). Moreover, if ''K''&amp;nbsp;⊂&amp;nbsp;'''R'''&amp;nbsp;&amp;times;&amp;nbsp;''V'' is the cone over a convex set&amp;nbsp;&amp;Omega;,

: &lt;math&gt; K=\{(t,tx): t\in\mathbb{R}, x\in\Omega \},&lt;/math&gt;

then the space of rays of ''K'' is canonically isomorphic to &amp;Omega;. If ''v'' and ''w'' are vectors in rays in ''K'' corresponding to the points ''A'',&amp;nbsp;''B''&amp;nbsp;∈&amp;nbsp;&amp;Omega; then these two formulas for ''d'' yield the same value of the distance.

== Examples ==

* In the case where the domain &amp;Omega; is a unit ball in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, the formula for ''d'' coincides with the expression for the distance between points in the [[Klein model|Cayley–Klein model]] of [[hyperbolic geometry]], up to a multiplicative constant.
* If the cone ''K'' is the positive [[orthant]] in '''R'''&lt;sup&gt;''n''&lt;/sup&gt; then the induced metric on the projectivization of ''K'' is often called simply '''Hilbert's projective metric'''. This cone corresponds to a domain &amp;Omega; which is a regular [[simplex]] of dimension&amp;nbsp;''n''&amp;nbsp;&amp;minus;&amp;nbsp;1.

== Motivation and applications ==

* Hilbert introduced his metric in order to construct an axiomatic metric geometry in which there exist triangles ''ABC'' whose vertices ''A'', ''B'', ''C'' are not [[Line (geometry)|collinear]], yet one of the sides is equal to the sum of the other two — it follows that the shortest path connecting two points is not unique in this geometry. In particular, this happens when the convex set &amp;Omega; is a Euclidean [[triangle]] and the straight line extensions of the segments ''AB'', ''BC'', ''AC'' do not meet the interior of one of the sides of &amp;Omega;.
* [[Garrett Birkhoff]] used Hilbert's metric and the [[Banach contraction principle]] to rederive the [[Perron–Frobenius theorem]] in finite-dimensional linear algebra and its analogues for [[integral operators]] with positive kernels.
* Generalizing earlier results of Anders Karlsson and Guennadi Noskov, Yves Benoist determined a system of necessary and sufficient conditions for a bounded convex domain in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, endowed with its Hilbert metric, to be a [[Gromov hyperbolic space]].

== References ==

* Yves Benoist, ''Convexes hyperboliques et fonctions quasisymétriques'', Publ. Math. Inst. Hautes Études Sci. No. 97 (2003), 181–237
* [[Garrett Birkhoff]], ''Extensions of Jentzsch's theorem'',  Trans. Amer. Math. Soc.  85  (1957), 219–227
* {{Citation | last1=Nielsen | first1=Frank | last2=Sun | first2=Ke | title=Clustering in Hilbert simplex geometry | publisher=arxiv | date=2017 | arxiv=1704.00454 | bibcode=2017arXiv170400454N }}
* {{Citation | last1=Nielsen | first1=Frank | last2=Shao | first2=Laetitia | title=On Balls in a Hilbert Polygonal Geometry | publisher=LIPIcs-Leibniz International Proceedings in Informatics (SoCG) | date=2017 | volume=77 | url=https://www.youtube.com/watch?v=XE5x5rAK8Hk }}
* P. J. Bushell, ''Hilbert's Metric and Positive Contraction Mappings in a Banach Space'', Arch. Rational Mech. Anal. 52  (1973), 330–338
* {{Citation | last1=Hilbert | first1=David | author1-link=David Hilbert | title=Ueber die gerade Linie als kürzeste Verbindung zweier Punkte | doi=10.1007/BF02096204 | publisher=Springer Berlin / Heidelberg | jfm=26.0540.02 | year=1895 | journal=[[Mathematische Annalen]] | issn=0025-5831 | volume=46 | pages=91–96}}
* {{Citation | last1=Papadopoulos | first1=Athanase | last2=Troyanov | first2=Marc | title=Handbook of Hilbert Geometry | publisher=European Mathematical Society | date=2014}}

[[Category:Metric geometry]]</text>
      <sha1>mmkywpinlnmg2wpz8i1iururz9ba6q8</sha1>
    </revision>
  </page>
  <page>
    <title>Hundredth</title>
    <ns>0</ns>
    <id>846733</id>
    <revision>
      <id>847784671</id>
      <parentid>827491564</parentid>
      <timestamp>2018-06-27T19:07:55Z</timestamp>
      <contributor>
        <ip>2600:1700:7A20:2FA0:985E:8C2E:7784:77E7</ip>
      </contributor>
      <comment>changed genre to fit the current sound</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1000">{{for|the band from South Carolina|Hundredth (band)}}
{{unreferenced|date=August 2012}}
In [[arithmetic]], a '''hundredth''' is a single part of something that has been divided equally into a hundred parts.  For example, a hundredth of 675 is 6.75. In this manner it is used with the prefix "centi" such as in [[centimeter]].

A hundredth is the [[multiplicative inverse|reciprocal]] of 100.

A hundredth is written as a [[decimal fraction]] as 0.01, and as a [[vulgar fraction]] as 1/100.

“Hundredth” is also the [[ordinal number]] that follows “ninety-ninth” and precedes “hundred and first.” It is written as 100th.

==See also==
*[[Basis point]]
*[[Cent (currency)]]
*[[Cent (music)]]
*[[Hundredth_(band)|Hundredth]] is an American rock band from [[Myrtle Beach, South Carolina]], that formed in 2008.
*[[Order of magnitude (numbers)]]
*[[Orders of magnitude]]
*[[Percentage]]
*[[Point (gemstone)]]

[[Category:Fractions (mathematics)]]
[[Category:Rational numbers]]

{{number-stub}}</text>
      <sha1>cwgblvtimhmclnl9qfaw2lntartc7tp</sha1>
    </revision>
  </page>
  <page>
    <title>Increment theorem</title>
    <ns>0</ns>
    <id>12144610</id>
    <revision>
      <id>827828908</id>
      <parentid>791138298</parentid>
      <timestamp>2018-02-26T23:56:18Z</timestamp>
      <contributor>
        <username>Toby Bartels</username>
        <id>1078</id>
      </contributor>
      <comment>Standard version (which sadly doesn't seem to have a standard name).</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2101">In [[non-standard analysis]], a field of mathematics, the '''increment theorem''' states the following: Suppose a [[Function (mathematics)|function]] ''y''&amp;nbsp;=&amp;nbsp;''f''(''x'') is [[Differentiable function|differentiable]] at ''x'' and that Δ''x'' is [[infinitesimal]]. Then
:&lt;math&gt;\Delta y = f'(x)\,\Delta x + \varepsilon\, \Delta x&lt;/math&gt;

for some infinitesimal ε, where
: &lt;math&gt;\Delta y=f(x+\Delta x)-f(x).&lt;/math&gt;

If &lt;math&gt;\scriptstyle\Delta x\not=0&lt;/math&gt; then we may write
: &lt;math&gt;\frac{\Delta y}{\Delta x} = f'(x)+\varepsilon,&lt;/math&gt;

which implies that &lt;math&gt;\scriptstyle\frac{\Delta y}{\Delta x}\approx f'(x)&lt;/math&gt;, or in other words that &lt;math&gt;\scriptstyle \frac{\Delta y}{\Delta x}&lt;/math&gt; is infinitely close to &lt;math&gt;\scriptstyle f'(x)&lt;/math&gt;, or &lt;math&gt;\scriptstyle f'(x)&lt;/math&gt; is the [[standard part function|standard part]] of &lt;math&gt;\scriptstyle \frac{\Delta y}{\Delta x}&lt;/math&gt;.

A similar theorem exists in standard Calculus.  Again assume that ''y''&amp;nbsp;=&amp;nbsp;''f''(''x'') is differentiable, but now let Δ''x'' be a nonzero standard real number. Then the same equation
:&lt;math&gt;\Delta y = f'(x)\,\Delta x + \varepsilon\, \Delta x&lt;/math&gt;
holds with the same definition of Δ''y'', but instead of ε being infinitesimal, we have
: &lt;math&gt; \lim_{\Delta x \to 0} \varepsilon = 0 &lt;/math&gt;
(treating ''x'' and ''f'' as given so that ε is a function of Δ''x'' alone).

== See also ==
*[[Non-standard calculus]]
*''[[Elementary Calculus: An Infinitesimal Approach]]''
*[[Abraham Robinson]]

== References ==
* [[Howard Jerome Keisler]]: ''[[Elementary Calculus: An Infinitesimal Approach]]''. First edition 1976; 2nd edition 1986. This book is now out of print. The publisher has reverted the copyright to the author, who has made available the 2nd edition in .pdf format available for downloading at http://www.math.wisc.edu/~keisler/calc.html
*{{cite book|last=Robinson|first=Abraham| title=Non-standard analysis|year=1996| edition=Revised | publisher=Princeton University Press| isbn = 0-691-04490-2}}

{{Infinitesimals}}

[[Category:Calculus]]
[[Category:Non-standard analysis]]</text>
      <sha1>s116gbrng7inzrfucbe788fgplt3dds</sha1>
    </revision>
  </page>
  <page>
    <title>Interdisciplinary Contest in Modeling</title>
    <ns>0</ns>
    <id>15466849</id>
    <revision>
      <id>809256699</id>
      <parentid>658789565</parentid>
      <timestamp>2017-11-08T00:46:56Z</timestamp>
      <contributor>
        <ip>72.174.134.72</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="940">The '''Interdisciplinary Contest in Modeling''' is a multi-day mathematics competition held annually by [[COMAP]] and sponsored by [[Society for Industrial and Applied Mathematics|SIAM]], the [[NSA]], and [[INFORMS]].  It is distinguished from other major mathematical competitions such as [[William Lowell Putnam Mathematical Competition|Putnam]] by its strong focus on research, originality, teamwork, communication and justification of results.

Around 1500 international teams of three undergraduates compete to produce original mathematical papers in response to an interdisciplinary modeling problem. Once the problem is posted, teams are given 96 hours (usually Thursday to Monday) to research and submit solutions.

== See also ==
* [[Mathematical Contest in Modeling]]

== External links ==
* Official contest website [http://www.comap.com/undergraduate/contests/]

[[Category:Mathematics competitions]]


{{math-competition-stub}}</text>
      <sha1>4120qwj2o379c4gb2qr3bik4bcr9em0</sha1>
    </revision>
  </page>
  <page>
    <title>John Wallis</title>
    <ns>0</ns>
    <id>239290</id>
    <revision>
      <id>871748238</id>
      <parentid>871728802</parentid>
      <timestamp>2018-12-03T04:47:31Z</timestamp>
      <contributor>
        <username>Xxanthippe</username>
        <id>1267919</id>
      </contributor>
      <comment>Reverted [[WP:AGF|good faith]] edits by [[Special:Contributions/Okjnla426|Okjnla426]] ([[User talk:Okjnla426|talk]]): Removed ansource editorialising. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26765">{{Other people|John Wallis}}
{{Use British English|date=August 2011}}
{{Use dmy dates|date=August 2011}}
{{Infobox scientist
|name      = John Wallis
|image     = John Wallis by Sir Godfrey Kneller, Bt.jpg
|caption   = 
|birth_date = {{birth date|1616|12|3|df=y}}
|birth_place = [[Ashford, Kent]], England
|death_date  = {{nowrap|{{death date and age|1703|11|8|1616|12|3|df=y}}}}
|death_place = {{nowrap|[[Oxford]], [[Oxfordshire]], England}}
|nationality = English
|field       = [[Mathematics]]
|work_institutions = {{hlist|[[Queens' College, Cambridge]]|[[University of Oxford]]}}
|alma_mater  = {{nowrap|[[Emmanuel College, Cambridge]]}}
|academic_advisors = [[William Oughtred]]
|notable_students = [[William Brouncker, 2nd Viscount Brouncker|William Brouncker]]
|known_for   = [[Wallis product]]&lt;br&gt;[[Infinity|Inventing the symbol {{resize|150%|∞}}]]&lt;br&gt;Extending [[Cavalieri's quadrature formula]]&lt;br/&gt;Coining the term "[[momentum]]"&lt;ref&gt;Joseph Frederick Scott, ''The mathematical work of John Wallis (1616-1703)'', Taylor and Francis, 1938, p. 109.&lt;/ref&gt;
|influences = 
|influenced = 
|prizes = 
|signature = 
|footnotes = 
}}

'''John Wallis''' ({{IPAc-en|ˈ|w|ɒ|l|ɪ|s}};&lt;ref&gt;[http://www.dictionary.com/browse/wallis ''Random House Dictionary''].&lt;/ref&gt; 3 December 1616 – 8 November 1703&lt;ref&gt;[[Old Style and New Style dates|Old Style dates]]: 23 November 1616 – 28 October 1703.&lt;/ref&gt;) was an English clergyman and [[Mathematics|mathematician]] who is given partial credit for the development of [[infinitesimal calculus]]. Between 1643 and 1689 he served as chief [[cryptographer]] for [[Parliament of the United Kingdom|Parliament]] and, later, the royal court.&lt;ref&gt;{{cite journal|author=Smith, David Eugene|authorlink=David Eugene Smith|title=John Wallis As a Cryptographer|journal=Bulletin of the American Mathematical Society|year=1917|volume=24|issue=2|pages=82–96|mr=1560009|doi=10.1090/s0002-9904-1917-03015-7}}&lt;/ref&gt; He is credited with introducing the [[symbol]] ∞ to represent the concept of [[infinity]].&lt;ref name=EB1911/&gt; He similarly used [[1/∞]] for an [[infinitesimal]].

== Life ==
John Wallis was born in [[Ashford, Kent]], the third of five children of Reverend John Wallis and Joanna Chapman. He was initially educated at a school in Ashford but moved to James Movat's school in [[Tenterden]] in 1625 following an outbreak of [[Bubonic plague|plague]]. Wallis was first exposed to mathematics in 1631, at Martin Holbeach's [[Felsted School|school in Felsted]]; he enjoyed maths, but his study was erratic, since "mathematics, at that time with us, were scarce looked on as academical studies, but rather mechanical" ([[#References|Scriba 1970]]).

As it was intended he should be a doctor, he was sent in 1632 to [[Emmanuel College, Cambridge]].&lt;ref&gt;{{acad|id=WLS632J|name=Wallys, John}}&lt;/ref&gt; While there, he kept an ''act'' on the doctrine of the [[circulation of the blood]]; that was said to have been the first occasion in Europe on which this theory was publicly maintained in a disputation. His interests, however, centred on mathematics. He received his Bachelor of Arts degree in 1637 and a Master's in 1640, afterwards entering the priesthood. From 1643 to 1649, he served as a nonvoting scribe at the [[Westminster Assembly]]. He was elected to a fellowship at [[Queens' College, Cambridge]] in 1644, from which he had to resign following his marriage.

Throughout this time, Wallis had been close to the Parliamentarian party, perhaps as a result of his exposure to Holbeach at Felsted School. He rendered them great practical assistance in deciphering Royalist dispatches. The quality of cryptography at that time was mixed; despite the individual successes of mathematicians such as [[François Viète]], the principles underlying cipher design and analysis were very poorly understood. Most ciphers were ad hoc methods relying on a secret [[algorithm]], as opposed to systems based on a variable [[key (cryptography)|key]]. Wallis realised that the latter were far more secure – even describing them as "unbreakable", though he was not confident enough in this assertion to encourage revealing cryptographic algorithms. He was also concerned about the use of ciphers by foreign powers, refusing, for example, [[Gottfried Leibniz]]'s request of 1697 to teach [[Electorate of Hanover|Hanoverian]] students about cryptography.&lt;ref&gt;{{citation|first=David|last=Kahn|title=The Codebreakers: The Story of Secret Writing|year=1967|place=New York|publisher=Macmillan|lccn=63016109|page=169}}&lt;/ref&gt;

Returning to London – he had been made chaplain at [[St Gabriel Fenchurch]] in 1643 – Wallis joined the group of scientists that was later to evolve into the [[Royal Society]]. He was finally able to indulge his mathematical interests, mastering [[William Oughtred]]'s ''Clavis Mathematicae'' in a few weeks in 1647. He soon began to write his own treatises, dealing with a wide range of topics, which he continued for the rest of his life.

Wallis joined the moderate Presbyterians in signing the remonstrance against the execution of [[Charles I of England|Charles I]], by which he incurred the lasting hostility of the Independents. In spite of their opposition he was appointed in 1649 to the [[Savilian Professor of Geometry|Savilian Chair of Geometry]] at Oxford University, where he lived until his death on 28 October 1703 ([[Old Style and New Style dates|O.S.]]). In 1661, he was one of twelve [[Presbyterian]] representatives at the [[Savoy Conference]].

Besides his mathematical works he wrote on [[theology]], [[logic]], [[English grammar]] and philosophy, and he was involved in devising a system for teaching a deaf boy to speak at [[Littlecote House]].&lt;ref&gt;{{cite news|title=Find could end 350-year science dispute|url=http://news.bbc.co.uk/1/hi/health/7511446.stm|accessdate=5 May 2018|publisher=BBC|date=26 July 2008}}&lt;/ref&gt; [[William Holder]] had earlier taught a deaf man, Alexander Popham, to speak "plainly and distinctly, and with a good and graceful tone".&lt;ref&gt;W. Holder, W. (1668). "Of an Experiment, Concerning Deafness". ''Philosophical Transactions of the Royal Society'' 3, pp. 665–668.&lt;/ref&gt; Wallis later claimed credit for this, leading Holder to accuse Wallis of "rifling his Neighbours, and adorning himself with their spoyls".&lt;ref&gt;Holder, ''Philosophical Transactions of the Royal Society'', supplement, 10.&lt;/ref&gt;

== Contributions to mathematics ==
[[File:Wallis - Opera mathematica, 1699 - 4760514 980122 3 00541.tif|thumb|''Opera mathematica'', 1699]]

Wallis made significant contributions to [[trigonometry]], [[calculus]], [[geometry]], and the analysis of [[infinite series]]. In his ''Opera Mathematica'' I (1695) he introduced the term "[[continued fraction]]".

Wallis rejected as absurd the now usual idea of a negative number as being less than nothing, but accepted the view that it is something greater than infinity. (The argument that negative numbers are greater than infinity involves the quotient &lt;math&gt;\frac{1}{x}&lt;/math&gt; and considering what happens as ''x'' approaches and then crosses the point ''x'' = 0 from the positive side.) Despite this he is generally credited as the originator of the idea of the [[number line]], in which numbers are represented geometrically in a line with the negative numbers represented by lengths opposite in direction to lengths of positive numbers.&lt;ref name="Martínez2006"&gt;{{cite book|author=Martínez, Alberto A.|title=Negative Math: How Mathematical Rules Can Be Positively Bent|url=https://books.google.com/books?id=8HSodlYby9MC&amp;pg=PA22|accessdate=9 June 2013|year=2006|publisher=Princeton University Press|isbn=978-0-691-12309-7|page=22}}&lt;/ref&gt;

===Analytical geometry===
In 1655, Wallis published a treatise on [[conic sections]] in which they were defined analytically. This was the earliest book in which these curves are considered and defined as curves of the second degree. It helped to remove some of the perceived difficulty and obscurity of [[René Descartes]]' work on [[analytic geometry]].
In the ''Treatise on the Conic Sections'' Wallis popularised the symbol ∞ for infinity. He wrote, “I suppose any plane (following the ''Geometry of Indivisibles'' of Cavalieri) to be made up of an infinite number of parallel lines, or as I would prefer, of an infinite number of parallelograms of the same altitude; (let the altitude of each one of these be an infinitely small part [[1/∞]] of the whole altitude, and let the symbol ∞ denote Infinity) and the altitude of all to make up the altitude of the figure.”&lt;ref&gt;Scott, J.F. 1981. ‘’The Mathematical Work of John Wallis, D.D., F.R.S. (1616–1703)’’. Chelsea Publishing Co. New York, NY. p. 18.&lt;/ref&gt;

===Integral calculus===

''Arithmetica Infinitorum'', the most important of Wallis's works, was published in 1656. In this treatise the methods of analysis of Descartes and [[Bonaventura Cavalieri|Cavalieri]] were systematised and extended, but some ideas were open to criticism. He began, after a short tract on conic sections, by developing the standard notation for powers, extending them from [[positive integers]] to [[rational numbers]]:

:&lt;math&gt; x^0 = 1 &lt;/math&gt;
:&lt;math&gt; x^{-1} = \frac 1 x &lt;/math&gt;
:&lt;math&gt; x^{-n} = \frac {1} {x^n} \text{ etc.} &lt;/math&gt;
:&lt;math&gt; x^{1/2} = \sqrt{x} &lt;/math&gt;
:&lt;math&gt; x^{2/3} = \sqrt[3]{x^2} \text{ etc.} &lt;/math&gt;
:&lt;math&gt; x^{1/n} = \sqrt[n]{x} &lt;/math&gt;
:&lt;math&gt; x^{p/q} = \sqrt[q]{x^p} &lt;/math&gt;

Leaving the numerous algebraic applications of this discovery, he next proceeded to find, by [[Integral|integration]], the area enclosed between the curve ''y'' = ''x''&lt;sup&gt;''m''&lt;/sup&gt;, the axis of ''x'', and any ordinate ''x'' = ''h'', and he proved that the ratio of this area to that of the parallelogram on the same base and of the same height is 1/(''m'' + 1), extending [[Cavalieri's quadrature formula]]. He apparently assumed that the same result would be true also for the curve ''y'' = ''ax''&lt;sup&gt;''m''&lt;/sup&gt;, where ''a'' is any constant, and ''m'' any number positive or negative, but he discussed only the case of the parabola in which ''m'' = 2 and the hyperbola in which ''m'' = −1. In the latter case, his interpretation of the result is incorrect. He then showed that similar results may be written down for any curve of the form

: &lt;math&gt; y = \sum_{m}^{} ax^{m} &lt;/math&gt;

and hence that, if the ordinate ''y'' of a curve can be expanded in powers of ''x'', its area can be determined: thus he says that if the equation of the curve is ''y'' = ''x''&lt;sup&gt;0&lt;/sup&gt; + ''x''&lt;sup&gt;1&lt;/sup&gt; + ''x''&lt;sup&gt;2&lt;/sup&gt; + ..., its area would be ''x'' + x&lt;sup&gt;2&lt;/sup&gt;/2 + ''x''&lt;sup&gt;3&lt;/sup&gt;/3 + ... He then applied this to the [[Numerical integration|quadrature]] of the curves ''y'' = (''x'' − ''x''&lt;sup&gt;2&lt;/sup&gt;)&lt;sup&gt;0&lt;/sup&gt;, ''y'' = (''x'' − ''x''&lt;sup&gt;2&lt;/sup&gt;)&lt;sup&gt;1&lt;/sup&gt;, ''y'' = (''x'' − ''x''&lt;sup&gt;2&lt;/sup&gt;)&lt;sup&gt;2&lt;/sup&gt;, etc., taken between the limits ''x'' = 0 and ''x'' = 1. He shows that the areas are, respectively, 1, 1/6, 1/30, 1/140, etc. He next considered curves of the form ''y'' = ''x''&lt;sup&gt;1/m&lt;/sup&gt; and established the theorem that the area bounded by this curve and the lines ''x'' = 0 and ''x'' = 1 is equal to the area of the rectangle on the same base and of the same altitude as ''m'' : ''m'' + 1. This is equivalent to computing

:&lt;math&gt;\int_0^1x^{1/m}\,dx.&lt;/math&gt;

He illustrated this by the parabola, in which case ''m'' = 2. He stated, but did not prove, the corresponding result for a curve of the form ''y'' = ''x''&lt;sup&gt;p/q&lt;/sup&gt;.

Wallis showed considerable ingenuity in reducing the equations of curves to the forms given above, but, as he was unacquainted with the [[binomial theorem]], he could not effect the [[quadrature of the circle]], whose equation is &lt;math&gt;y = \sqrt{1 - x^2}&lt;/math&gt;, since he was unable to expand this in powers of ''x''. He laid down, however, the principle of [[interpolation]]. Thus, as the ordinate of the circle &lt;math&gt;y = \sqrt{1 - x^2}&lt;/math&gt; is the [[Geometric mean|geometrical mean]] of the ordinates of the curves &lt;math&gt;y = (1 - x^2)^0&lt;/math&gt; and &lt;math&gt;y = (1 - x^2)^1&lt;/math&gt;, it might be supposed that, as an approximation, the area of the semicircle &lt;math&gt;\int_{0}^{1} \sqrt{1 - x^2}\, dx&lt;/math&gt; which is &lt;math&gt;\begin{matrix} \frac{1}{4} \end{matrix} \pi&lt;/math&gt; might be taken as the geometrical mean of the values of

:&lt;math&gt;\int_{0}^{1} (1 - x^2)^0 \, dx\text{ and }\int_{0}^{1} (1 - x^2)^1 \, dx&lt;/math&gt;

that is, 1 and &lt;math&gt;\begin{matrix} \frac{2}{3} \end{matrix}&lt;/math&gt;; this is equivalent to taking &lt;math&gt;4 \sqrt{\begin{matrix} \frac{2}{3} \end{matrix}}&lt;/math&gt; or 3.26... as the value of π. But, Wallis argued, we have in fact a series &lt;math&gt;1, \begin{matrix} \frac{1}{6} \end{matrix}, \begin{matrix} \frac{1}{30} \end{matrix}, \begin{matrix} \frac{1}{140} \end{matrix},&lt;/math&gt;... and therefore the term interpolated between 1 and &lt;math&gt;\begin{matrix} \frac{1}{6} \end{matrix}&lt;/math&gt; ought to be chosen so as to obey the law of this series{{Clarify|date=July 2010}}. This, by an elaborate method that is not described here in detail, leads to a value for the interpolated term which is equivalent to taking
:&lt;math&gt;\frac{\pi}{2} = \frac21\cdot\frac23\cdot\frac43\cdot\frac45\cdot\frac65\cdot\frac67\cdots&lt;/math&gt;
(which is now known as the [[Wallis product]]).

In this work also the formation and properties of [[continued fraction]]s are discussed, the subject having been brought into prominence by [[William Brouncker, 2nd Viscount Brouncker|Brouncker]]'s use of these fractions.

A few years later, in 1659, Wallis published a tract containing the solution of the problems on the [[cycloid]] which had been proposed by [[Blaise Pascal]]. In this he incidentally explained how the principles laid down in his ''Arithmetica Infinitorum'' could be used for the rectification of algebraic curves and gave a solution of the problem to rectify (i.e., find the length of) the semicubical parabola ''x''&lt;sup&gt;3&lt;/sup&gt; = ''ay''&lt;sup&gt;2&lt;/sup&gt;, which had been discovered in 1657 by his pupil [[William Neile]]. Since all attempts to rectify the ellipse and hyperbola had been (necessarily) ineffectual, it had been supposed that no curves could be rectified, as indeed Descartes had definitely asserted to be the case. The [[logarithmic spiral]] had been rectified by [[Evangelista Torricelli]] and was the first curved line (other than the circle) whose length was determined, but the extension by Neile and Wallis to an algebraic curve was novel. The cycloid was the next curve rectified; this was done by [[Christopher Wren]] in 1658.

Early in 1658 a similar discovery, independent of that of Neile, was made by [[van Heuraët]], and this was published by [[van Schooten]] in his edition of Descartes's ''Geometria'' in 1659. Van Heuraët's method is as follows. He supposes the curve to be referred to rectangular axes; if this be so, and if (''x'', ''y'') be the coordinates of any point on it, and ''n'' be the length of the normal{{Clarify|date=July 2010}}, and if another point whose coordinates are (''x'', η) be taken such that  η : ''h'' = ''n'' : ''y'', where ''h'' is a constant; then, if ''ds'' be the element of the length of the required curve, we have by similar triangles ''ds'' : ''dx'' = ''n'' : ''y''. Therefore, ''h ds'' = η ''dx''. Hence, if the area of the locus of the point (''x'', η) can be found, the first curve can be rectified. In this way van Heuraët effected the rectification of the curve ''y''&lt;sup&gt;3&lt;/sup&gt; = ''ax''&lt;sup&gt;2&lt;/sup&gt; but added that the rectification of the parabola ''y''&lt;sup&gt;2&lt;/sup&gt; = ''ax'' is impossible. since it requires the quadrature of the hyperbola. The solutions given by Neile and Wallis are somewhat similar to that given by van Heuraët, though no general rule is enunciated, and the analysis is clumsy. A third method was suggested by [[Pierre de Fermat|Fermat]] in 1660, but it is inelegant and laborious.

===Collision of bodies===

The theory of the [[collision of bodies]] was propounded by the [[Royal Society]] in 1668 for the consideration of mathematicians. Wallis, [[Christopher Wren]], and [[Christian Huygens]] sent correct and similar solutions, all depending on what is now called the [[conservation of momentum]]; but, while Wren and Huygens confined their theory to perfectly elastic bodies ([[elastic collision]]), Wallis considered also imperfectly elastic bodies ([[inelastic collision]]). This was followed in 1669 by a work on [[statics]] (centres of gravity), and in 1670 by one on [[Analytical dynamics|dynamics]]: these provide a convenient synopsis of what was then known on the subject.

===Algebra===

In 1685 Wallis published ''Algebra'', preceded by a historical account of the development of the subject, which contains a great deal of valuable information. The second edition, issued in 1693 and forming the second volume of his ''Opera'', was considerably enlarged. This algebra is noteworthy as containing the first systematic use of formulae. A given magnitude is here represented by the numerical ratio which it bears to the unit of the same kind of magnitude: thus, when Wallis wants to compare two lengths he regards each as containing so many units of length. This perhaps will be made clearer by noting that the relation between the space described in any time by a particle moving with a uniform velocity is denoted by Wallis by the formula

:''s'' = ''vt'',

where ''s'' is the number representing the ratio of the space described to the unit of length; while the previous writers would have denoted the same relation by stating what is equivalent to the proposition

:''s&lt;sub&gt;1&lt;/sub&gt; : s&lt;sub&gt;2&lt;/sub&gt; = v&lt;sub&gt;1&lt;/sub&gt;t&lt;sub&gt;1&lt;/sub&gt; : v&lt;sub&gt;2&lt;/sub&gt;t&lt;sub&gt;2&lt;/sub&gt;''.

===Geometry===
He is usually credited with the proof of the [[Pythagorean theorem]] using [[similar triangles]]. However, [[Thabit Ibn Qurra]] (AD 901), an Arab mathematician, had produced a generalisation of the Pythagorean theorem applicable to all triangles six centuries earlier. It is a reasonable conjecture that Wallis was aware of Thabit's work.&lt;ref&gt;{{cite book|first=G.G.|last=Joseph|title=The Crest of the Peacock: Non-European Roots of Mathematics|edition=2|publisher=Penguin|year=2000|isbn=0-14-027778-1|page=337}}&lt;/ref&gt;

Wallis was also inspired by the works of Islamic mathematician Sadr al-Tusi, the son of [[Nasir al-Din al-Tusi]], particularly by al-Tusi's book written in AD 1298 on the [[parallel postulate]]. The book was based on his father's thoughts which presented one of the earliest arguments for a non-Euclidean hypothesis equivalent to the parallel postulate. After reading this, Wallis then wrote about his ideas as he developed his own thoughts about the postulate, trying to prove it also with similar triangles.&lt;ref&gt;The Mathematics of Egypt, Mesopotamia, China, India, and Islam:A Sourcebook [http://press.princeton.edu/chapters/i8583.html Victor J. Katz Princeton University Press]&lt;/ref&gt;

He found that [[Parallel postulate|Euclid's fifth postulate]] is equivalent to the one currently named  "Wallis postulate" after him. This postulate states that "On a given finite straight line it is always possible to construct a triangle similar to a given triangle". This result was encompassed in a trend trying to deduce Euclid's fifth from the other four postulates which today is known to be impossible. Unlike other authors, he realised that the unbounded growth of a triangle was not guaranteed by the four first postulates.&lt;ref&gt;{{citation|first=David M.|last=Burton|title=The History of Mathematics / An Introduction|edition=7th|year=2011|publisher=McGraw-Hill|isbn=978-0-07-338315-6|page=566}}&lt;/ref&gt;

===Calculator===

Another aspect of Wallis's mathematical skills was his ability to do mental calculations. He slept badly and often did mental calculations as he lay awake in his bed. One night he calculated in his head the square root of a number with 53 digits. In the morning he dictated the 27-digit square root of the number, still entirely from memory. It was a feat that was considered remarkable, and [[Henry Oldenburg]], the Secretary of the Royal Society, sent a colleague to investigate how Wallis did it. It was considered important enough to merit discussion in the ''Philosophical Transactions'' of the Royal Society of 1685.&lt;ref&gt;Dr. Wallis (1685) "Two extracts of the Journal of the Phil. Soc. of Oxford; one containing a paper, communicated March 31, 1685, by the Reverend Dr. Wallis, president of that society, concerning the strength of memory when applied with due attention; … ", ''Philosophical Transactions of the Royal Society of London'', '''15''' :  1269-1271.  Available on-line at:  
[http://rstl.royalsocietypublishing.org/content/15/167-178/1269.full.pdf+html Royal Society of London]{{dead link|date=March 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;&lt;ref&gt;{{citation|title=The Common Scientist of the Seventeenth Century: A Study of the Dublin Philosophical Society, 1683–1708|volume=15|series=Routledge Library Editions: History &amp; Philosophy of Science|first=K. Theodore|last=Hoppen|publisher=Routledge|year=2013|isbn=9781135028541|url=https://books.google.com/books?id=PHK7ErKBiCEC&amp;pg=PA157|page=157}}.&lt;/ref&gt;

===Controversy with Hobbes===
{{details|Hobbes–Wallis controversy}}

A long-running debate between Wallis and [[Thomas Hobbes]] arose in the mid-1650s, when mathematicians criticised errors in the work ''[[De corpore]]'' by Hobbes. It continued into the 1670s, having gathered in the later claims of Hobbes on [[squaring the circle]], and the wider beliefs on both sides.

== Musical theory ==
Wallis translated into Latin works of [[Ptolemy]], Bryennius, and Porphyrius's commentary on Ptolemy.  He also published three letters to [[Henry Oldenburg]] concerning tuning. He approved of [[equal temperament]] that was being used in England's organs.&lt;ref&gt;David Damschoder and David Russell Williams, ''Music Theory from Zarlino to Schenker: A Bibliography and Guide'' (Stytvesant, NY: Pendragon Press, 1990), p. 374.&lt;/ref&gt;

==Other works==
[[File:Wallis - Opera mathematica, 1657 - 4611280.tif|thumb|''Opera mathematica'', 1657]]His ''Institutio logicae'', published in 1687, was very popular.&lt;ref name=EB1911&gt;{{Cite EB1911 |wstitle=Wallis, John |volume=28 |page=284–285}}&lt;/ref&gt; The ''Grammatica linguae Anglicanae'' was a work on [[English grammar]], that remained in print well into the eighteenth century. He also published on theology.&lt;ref name=EB1911/&gt;

==Family==
On 14 March 1645 he married '''Susanna Glynde''' (16?? – 16 March 1687), They had three children:
#[[Anne Blencoe]] (4 June 1656 – 5 April 1718), married Sir John Blencowe (30 November 1642 – 6 May 1726) in 1675, with issue&lt;ref&gt;Joan Thirsk, ‘Blencowe , Anne, Lady Blencowe (1656–1718)’, Oxford Dictionary of National Biography, Oxford University Press, Oct 2005; online edn, Jan 2007 [http://www.oxforddnb.com/view/article/41326, accessed 16 Nov 2016]&lt;/ref&gt;
#'''John Wallis''' (26 December 1650 – 14 March 1717),&lt;ref&gt;[http://www.historyofparliamentonline.org/volume/1690-1715/member/wallis-john-1650-1717 WALLIS, John (1650-1717), of Soundness, Nettlebed, Oxon. | History of Parliament Online&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; MP for Wallingford 1690–1695, married Elizabeth Harris (d. 1693) on 1 February 1682, with issue: one son and two daughters
#'''Elizabeth Wallis''' (1658–1703&lt;ref&gt;[http://emlo.bodleian.ox.ac.uk/profile/person/e4d46f16-a83a-4375-bbc1-88e939f95622 Early Modern Letters Online : Person&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;), married William Benson (1649–1691) of Towcester, died with no issue

== See also ==
* [[Wallis’s conical edge]]
* [[John Wallis Academy]] – former ChristChurch school in Ashford renamed in 2010
* [[Invisible College]]
* [[Wallis' integrals]]
* [[Asteroid]] [[31982 Johnwallis]] was named after him

==Footnotes==
{{Reflist|30em}}

== References ==
:The initial text of this article was taken from the [[public domain]] resource:
:[[W. W. Rouse Ball]], 1908. ''[http://www.maths.tcd.ie/pub/HistMath/People/Wallis/RouseBall/RB_Wallis.html A Short Account of the History of Mathematics,]'' 4th ed.
*{{cite journal | last1 = Scriba | first1 = C J | authorlink = Christoph Scriba | year = 1970 | title = The autobiography of John Wallis, F.R.S. | url = | journal = Notes and Records Roy. Soc. London | volume = 25 | issue = | pages = 17–46 | doi=10.1098/rsnr.1970.0003}}
*Stedall, Jacqueline, 2005, "Arithmetica Infinitorum" in [[Ivor Grattan-Guinness]], ed., ''Landmark Writings in Western Mathematics''. Elsevier: 23–32.

==External links==
{{wikiquote}}
* [http://emlo.bodleian.ox.ac.uk/forms/advanced?col_cat=Wallis%2C+John The Correspondence] of [http://emlo.bodleian.ox.ac.uk/blog/?catalogue=john-wallis John Wallis]  in [http://emlo.bodleian.ox.ac.uk/home EMLO]
* {{DNB Cite|wstitle=Wallis, John (1616-1703)}}
* {{MacTutor Biography|id=Wallis}}
* [http://galileo.rice.edu/Catalog/NewFiles/wallis.html Galileo Project page]
* {{UK National Archives ID}}
* {{NPG name}}
*{{prdl|74}}
*[http://lhldigital.lindahall.org/cdm/ref/collection/math/id/11231 John Wallis (1685) ''A treatise of algebra''] - digital facsimile, [[Linda Hall Library]]
*{{cite book |first=John |last=Wallis |authorlink=John Wallis |title=A Treatise of Algebra, both Historical and Practical. Shewing the Original, Progress, and Advancement thereof, from time to time, and by what Steps it hath attained to the Heighth at which it now is |publisher=Richard Davis |location=Oxford |date=1685 |url=http://www.e-rara.ch/zut/content/titleinfo/2507537 |doi=10.3931/e-rara-8842}}

{{Savilian Professors of Geometry}}
{{Keeper of the Archives}}

{{Authority control}}

{{DEFAULTSORT:Wallis, John}}
[[Category:1616 births]]
[[Category:1703 deaths]]
[[Category:17th-century English mathematicians]]
[[Category:Fellows of Queens' College, Cambridge]]
[[Category:Alumni of Emmanuel College, Cambridge]]
[[Category:British cryptographers]]
[[Category:English Protestants]]
[[Category:English logicians]]
[[Category:English Presbyterian ministers of the Interregnum (England)]]
[[Category:Participants in the Savoy Conference]]
[[Category:English mathematicians]]
[[Category:Original Fellows of the Royal Society]]
[[Category:People educated at Felsted School]]
[[Category:People from Ashford, Kent]]
[[Category:Savilian Professors of Geometry]]
[[Category:Linguists of English]]
[[Category:English music theorists]]
[[Category:Historians of mathematics]]
[[Category:Keepers of the Archives of the University of Oxford]]
[[Category:English male non-fiction writers]]
[[Category:Calculus]]
[[Category:History of calculus]]
[[Category:Infinity]]
[[Category:History of mathematics]]
[[Category:Mathematics of infinitesimals]]
[[Category:Westminster Divines]]
[[Category:Deaf education]]</text>
      <sha1>2orvow5h06kx5o4pt7qz1loxsur3gfb</sha1>
    </revision>
  </page>
  <page>
    <title>L-attributed grammar</title>
    <ns>0</ns>
    <id>890862</id>
    <revision>
      <id>824650393</id>
      <parentid>824650370</parentid>
      <timestamp>2018-02-08T17:26:11Z</timestamp>
      <contributor>
        <username>Vincent Lextrait</username>
        <id>3128017</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1320">{{Unreferenced|date=December 2009}}
'''L-attributed grammars''' are a special type of [[attribute grammar]]s. They allow the attributes to be evaluated in one depth-first left-to-right traversal of the [[abstract syntax tree]]. As a result, attribute evaluation in L-attributed grammars can be incorporated conveniently in [[top-down parsing]]. 

A syntax-directed definition is L-attributed if each &lt;ins&gt;inherited&lt;/ins&gt; attribute of &lt;math&gt;X_j&lt;/math&gt; on the right side of &lt;math&gt;A \rightarrow X_1, X_2, \dots, X_n &lt;/math&gt; depends only on 

# the attributes of the symbols &lt;math&gt;X_1, X_2, \dots, X_{j-1}&lt;/math&gt;
# the inherited attributes of &lt;math&gt;A&lt;/math&gt;

Every S-attributed syntax-directed definition is also L-attributed.

Implementing L-attributed definitions in Bottom-Up parsers requires rewriting L-attributed definitions into translation schemes.

Many programming languages are L-attributed. Special types of [[compiler]]s, the narrow compilers, are based on some form of L-attributed grammar. These are a strict superset of [[S-attributed grammar]]s. Used for code synthesis.

Either "inherited attributes" or "synthesized attributes" associated with the occurrence of symbol &lt;math&gt;X_1,X_2, \dots, X_n&lt;/math&gt;.

{{DEFAULTSORT:L-Attributed Grammar}}
[[Category:Formal languages]]
[[Category:Compiler construction]]</text>
      <sha1>12tefwz0a3y8t9p9va3tibu064un6gf</sha1>
    </revision>
  </page>
  <page>
    <title>Limiting case (mathematics)</title>
    <ns>0</ns>
    <id>40400729</id>
    <revision>
      <id>864960649</id>
      <parentid>862218973</parentid>
      <timestamp>2018-10-20T19:05:14Z</timestamp>
      <contributor>
        <username>IntegralPython</username>
        <id>33883676</id>
      </contributor>
      <minor/>
      <comment>removed unnecessary spacing</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2294">{{multiple issues|
{{unreferenced|date=September 2013}}
{{prose|date=September 2013}}
}}
In [[mathematics]], a '''limiting case''' of a [[mathematical object]] is a [[special case]] that arises when one or more components of the object take on their most extreme possible values. For example:

* In [[statistics]], the limiting case of the [[binomial distribution]] is the [[Poisson distribution]]. As the number of events tends to infinity in the binomial distribution, the random variable changes from the binomial to the Poisson distribution.
*A [[Circle#Circle as limiting case of other figures|circle is a limiting case]] of various other figures, including the [[Cartesian oval]], the [[ellipse]], the [[superellipse]], and the [[Cassini oval]]. Each type of figure is a circle for certain values of the defining parameters, and the generic figure appears more and more like a circle as the limiting values are approached.
*[[Archimedes]] calculated an approximate value of [[π]] by treating the circle as the limiting case of a [[regular polygon]] with 3 × 2&lt;sup&gt;''n''&lt;/sup&gt; sides, as ''n'' gets large.
*In [[electricity and magnetism]], the [[long wavelength limit]] is the limiting case when the [[wavelength]] is much larger than the system size.
*In [[economics]], two limiting cases of a [[demand curve]] or [[supply curve]] are those in which the [[elasticity (economics)|elasticity]] is zero (the totally inelastic case) or infinity (the infinitely elastic case).
*In [[finance]], [[continuous compounding]] is the limiting case of compound interest in which the compounding period becomes infinitesimally small, achieved by taking the limit as the number of compounding periods per year goes to infinity.

A limiting case is sometimes a [[Degeneracy (mathematics)|degenerate case]] in which some qualitative properties differ from the corresponding [[Generic property|properties of the generic case]]. For example:

*A [[Point (geometry)|point]] is a degenerate [[circle]], namely one with [[radius]] 0.
*A [[parabola]] can degenerate into two distinct or coinciding [[parallel lines]].
*An [[ellipse]] can degenerate into a single point or a [[line segment]].
*A [[hyperbola]] can degenerate into two [[intersecting lines]].

[[Category:Mathematical concepts]]


{{math-stub}}</text>
      <sha1>kewuuqbtrawmxdzm92eokn8dcraw5mk</sha1>
    </revision>
  </page>
  <page>
    <title>List of graphs</title>
    <ns>0</ns>
    <id>8997770</id>
    <revision>
      <id>825173135</id>
      <parentid>743538751</parentid>
      <timestamp>2018-02-11T22:22:36Z</timestamp>
      <contributor>
        <username>Pat Hawks</username>
        <id>4471185</id>
      </contributor>
      <minor/>
      <comment>Use vector version of gear graph</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3857">This partial '''list of [[Graph (discrete mathematics)|graph]]s''' contains definitions of graphs and graph families which are known by particular names, but do not have a Wikipedia article of their own.

For collected definitions of [[graph theory]] terms that do not refer to individual graph types, such as ''vertex'' and ''path'', see [[Glossary of graph theory]]. For links to existing articles about particular kinds of graphs, see [[:Category:Graphs|Category:Graphs]].

==Gear==
[[File:Gear graph.svg|thumb|''G''&lt;sub&gt;''4''&lt;/sub&gt;]]
A '''gear graph''', denoted ''G''&lt;sub&gt;''n''&lt;/sub&gt; is a graph obtained by inserting an extra vertex between each pair of adjacent vertices on the perimeter of a [[wheel graph]] ''W''&lt;sub&gt;''n''&lt;/sub&gt;. Thus, ''G''&lt;sub&gt;''n''&lt;/sub&gt; has 2''n''+1 vertices and 3''n'' edges.&lt;ref&gt;{{mathworld|urlname=GearGraph|title=Gear graph}}&lt;/ref&gt; Gear graphs are examples of [[squaregraph]]s, and play a key role in the [[forbidden graph characterization]] of squaregraphs.&lt;ref&gt;{{citation|title=Combinatorics and geometry of finite and infinite squaregraphs|first1=H.-J.|last1=Bandelt|first2=V.|last2=Chepoi|first3=D.|last3=Eppstein|author3-link=David Eppstein|arxiv=0905.4537|journal=[[SIAM Journal on Discrete Mathematics]]|volume=24|issue=4|pages=1399–1440|year=2010|doi=10.1137/090760301}}&lt;/ref&gt; Gear graphs are also known as '''cogwheels''' and '''bipartite wheels'''.

==Grid==
A '''[[grid graph]]''' is a [[unit distance graph]] corresponding to the [[square lattice]], so that it is [[isomorphism|isomorphic]] to the graph having a vertex corresponding to every pair of integers (''a'', ''b''), and an edge connecting (''a'', ''b'') to (''a''+1, ''b'') and (''a'', ''b''+1). The finite grid graph ''G&lt;sub&gt;m,n&lt;/sub&gt;'' is an ''m''×''n'' rectangular graph isomorphic to the one obtained by restricting the ordered pairs to the range 0 ≤ ''a'' &lt; ''m'', 0 ≤ ''b'' &lt; ''n''. Grid graphs can be obtained as the [[Cartesian product of graphs|Cartesian product]] of two [[path (graph theory)|path]]s: ''G''&lt;sub&gt;''m'',''n''&lt;/sub&gt; = ''P''&lt;sub&gt;''m''&lt;/sub&gt; × ''P''&lt;sub&gt;''n''&lt;/sub&gt;. Every grid graph is a [[median graph]].&lt;ref&gt;{{mathworld|urlname=GridGraph|title=Grid graph}}&lt;/ref&gt;

==Helm==
A '''helm graph''', denoted '''''H&lt;sub&gt;n&lt;/sub&gt;''''' is a graph obtained by attaching a single edge and node to each node of the outer circuit of a [[wheel graph]] '''''W&lt;sub&gt;n&lt;/sub&gt;'''''.&lt;ref&gt;{{mathworld|urlname=HelmGraph|title=Helm graph}}&lt;/ref&gt;&lt;ref name="combinatorics.org"&gt;http://www.combinatorics.org/Surveys/ds6.pdf&lt;/ref&gt;

==Lobster==
A '''lobster''' graph is a [[tree (graph theory)|tree]] in which all the vertices are within distance&amp;nbsp;2 of a central [[path (graph theory)|path]].&lt;ref&gt;{{cite web|url=http://groups.google.com/groups?selm=Pine.LNX.4.44.0303310019440.1408-100000@eva117.cs.ualberta.ca |title=Google Discussiegroepen |publisher=Groups.google.com |date= |accessdate=2014-02-05}}&lt;/ref&gt;&lt;ref&gt;{{mathworld|urlname=Lobster|title=Lobster}}&lt;/ref&gt;  Compare [[Caterpillar tree|''caterpillar'']].

==Web==
[[Image:Cube graph.png|thumb|100px|The web graph ''W''&lt;sub&gt;4,2&lt;/sub&gt; is a [[cube]].]]
The '''web''' graph ''W''&lt;sub&gt;''n'',''r''&lt;/sub&gt; is a graph consisting of ''r'' concentric copies of the [[cycle graph]] ''C''&lt;sub&gt;''n''&lt;/sub&gt;, with corresponding vertices connected by "spokes". Thus ''W''&lt;sub&gt;''n'',1&lt;/sub&gt; is the same graph as ''C''&lt;sub&gt;''n''&lt;/sub&gt;, and ''W''&lt;sub&gt;n,2&lt;/sub&gt; is a [[prism (geometry)|prism]].

A web graph has also been defined as a prism graph '''''Y''&lt;sub&gt;''n''+1, 3&lt;/sub&gt;''', with the edges of the outer cycle removed.&lt;ref name="combinatorics.org"/&gt;&lt;ref&gt;{{mathworld|urlname=WebGraph|title=Web graph}}&lt;/ref&gt;

==See also==

[[Gallery of named graphs]]

==References==
&lt;references/&gt;

{{DEFAULTSORT:List Of Graphs}}
[[Category:Mathematics-related lists|Graphs]]
[[Category:Graphs|*]]
[[Category:Graph families|*]]</text>
      <sha1>4nseue2e64vwp1n7qj8fzyffxs73w3f</sha1>
    </revision>
  </page>
  <page>
    <title>Lobachevsky Prize</title>
    <ns>0</ns>
    <id>9084906</id>
    <revision>
      <id>859231414</id>
      <parentid>811598115</parentid>
      <timestamp>2018-09-12T17:11:12Z</timestamp>
      <contributor>
        <username>T0mpr1c3</username>
        <id>3427765</id>
      </contributor>
      <comment>category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6184">The '''Lobachevsky Prize''', awarded by the [[Russian Academy of Sciences]], and the '''Lobachevsky Medal''',  awarded by the [[Kazan State University]], are mathematical awards in honor of [[Nikolai Ivanovich Lobachevsky]].

==History==
The Lobachevsky Prize was established in 1896 by the Kazan Physical and Mathematical Society, in honor of the famous Russian mathematician [[Nikolai Ivanovich Lobachevsky]], who had been a professor at  [[Kazan State University|Kazan University]] and spent almost all of his mathematical life there.  The prize was first awarded in 1897. 
Between the [[October revolution]] of 1917 and [[World War II]] the Lobachevsky Prize was awarded only twice, by the [[Kazan State University]], in 1927 and 1937.
In 1947, by a decree of the [[Council of Ministers of the USSR]], the jurisdiction over awarding the Lobachevsky Prize was transferred to the [[USSR Academy of Sciences]].&lt;ref name="novikov"&gt;{{Cite journal
  | last1 = Bukhshtaber | first1 = V. M.
  | last2 = Novikov | first2 = S. P.
  | title =  History of the Lobachevskii Prize (on the centenary of the first awarding in 1897)  | language= Russian
  | url = http://www.mathnet.ru/php/getFT.phtml?jrnid=rm&amp;paperid=6&amp;what=fullt
  | journal = Uspekhi Matematicheskikh Nauk
  | volume = 53
  | issue = 1
  | pages = 235–238
  | year = 1998
}}&lt;/ref&gt;&lt;ref name="shapukov"&gt;B. N. Shapukov, [http://www.mathnet.ru/php/getFT.phtml?jrnid=kutgs&amp;paperid=26&amp;what=fullt “On history of Lobachevskii Medal and Lobachevskii Prize”] (in Russian), Tr. Geom. Semin., 24, Kazan Mathematical Society, Kazan, 2003, 11–16&lt;/ref&gt; The 1947 decree specified that there be two prizes, awarded every five years: the main, international, Lobachevsky Prize, for which both Soviet and foreign scientists would be eligible, and an honorable mention prize, for Soviet mathematicians only.
In a 2003 article, B. N. Shapukov, a professor at the [[Kazan State University]], writes that the 1947 decree also specified that awarding of the prize by the USSR Academy of Sciences should be done in consultation with the Kazan State University, but that this condition was not subsequently followed in practice.&lt;ref name="shapukov"/&gt;

Another decree of the  [[Council of Ministers (Soviet Union)|Council of Ministers of the USSR]], in 1956,  specified that there be only one, international, Lobachevsky Prize, to be awarded every three years.&lt;ref name="novikov"/&gt;

With the dissolution of the [[Soviet Union]] at the end of 1991, the [[Russian Academy of Sciences]] became the legatee of the [[USSR Academy of Sciences]]. The Russian Academy of Sciences continued awarding the Lobachevsky Prize, awarding it in 1992, 1996 and 2000. As of January 2010, the Lobachevsky Prize is listed among its awards at the Russian Academy of Sciences website.&lt;ref name="ras"&gt;[http://www.ras.ru/about/awards/awdlist.aspx?awdid=62 Lobachevsky Prize],  [[Russian Academy of Sciences]]. Accessed January 4, 2010&lt;/ref&gt;

In 1990-1991, while preparing the 1992 celebration of Lobachevsky's 200th anniversary, the Kazan State University organizers of this celebration lobbied the Soviet government to establish a special Kazan State University award in honor of Lobachevsky. A June 1991 decree of the [[USSR Council of Ministers|Cabinet of Ministers of the USSR]] established the '''Lobachevsky Medal''', for outstanding contributions to geometry, to be awarded by the [[Kazan State University]]. The Lobachevsky Medal was awarded by the university in 1992, 1997 and 2002. The article of Shapukov mentions that during the 1997 competition for the Lobachevsky Medal, the Mathematics section of the [[Russian Academy of Sciences]] complained about the fact and the process of awarding the Medal.&lt;ref name="shapukov"/&gt;
The Kazan State University website for the Lobachevsky Medal contains a list of recipients of the Lobachesky Prize from 1897 to 1989, which excludes the 1992, 1996 and 2000 Russian Academy of Sciences awards.&lt;ref&gt;[http://www.ksu.ru/news/medal/medal.htm The Lobachevsky Medal], [[Kazan State University]]. Accessed January 3, 2010&lt;/ref&gt;  The Russian Academy of Sciences website for the Lobachevsky Prize contains a list of recipients of the prize from 1897 to 2000 and does not mention Kazan State University's Lobachevsky Medal.&lt;ref name="ras"/&gt;

== Lobachevsky Prize winners ==
===Kazan Physical and Mathematical Society/Kazan University ===
* [[Sophus Lie]], 1897
* [[Wilhelm Killing]], 1900
* [[David Hilbert]], 1903
* [[Ludwig Schlesinger]], 1909 (awarded in 1912)
* [[Friedrich Schur]], 1912
* [[Hermann Weyl]], 1927
* [[Élie Cartan]], 1937 (main, international, prize)
* [[Viktor Wagner|Viktor V. Wagner]], 1937 (special prize for young Soviet mathematicians)

In 1906, [[Beppo Levi]] received an honorable mention. The prize itself was not awarded.

=== Soviet Academy of Sciences ===
* [[Nikolai Efimov]], 1951
* [[Aleksandr Danilovich Aleksandrov|Aleksandr D. Alexandrov]], 1951
* [[Aleksei Pogorelov]], 1959
* [[Lev Pontryagin]], 1966
* [[Heinz Hopf]], 1969
* [[Pavel Alexandrov]], 1972
* [[Boris Delaunay]], 1977
* [[Sergei Novikov (mathematician)|Sergei Novikov]], 1980
* [[Herbert Busemann]], 1983
* [[Andrey Kolmogorov]], 1986
* [[Friedrich Hirzebruch]], 1989

===Russian Academy of Sciences===
* [[Vladimir Arnold]], 1992
* [[Grigory Margulis]], 1996
* [[Yurii Reshetnyak]], 2000

==Lobachevsky Medal winners==
=== Kazan State University ===
* [[Aleksandr Petrovich Norden|Aleksandr P. Norden]], 1992
* [[Boris Komrakov|Boris P. Komrakov]], 1997
* [[Mikhail Gromov (mathematician)|Mikhail Gromov]], 1997
* [[Shiing-Shen Chern]], 2002
* [[Richard Schoen]], 2017

In 1997, Valery N. Berestovsky (Russia), Idjad Kh. Sabitov (Russia) and Boris Rosenfeld (USA) received an honorable mention.

== Notes ==
{{Reflist}}

== References ==
*V. V. Vishnevsky,  (in Russian), [http://www.mathnet.ru/php/getFT.phtml?jrnid=kutgs&amp;paperid=3&amp;what=fullt&amp;option_lang=rus The 200th anniversary of N. I. Lobachevsky, its outcomes and lessons.] Tr. Geom. Semin., 23, Kazan Mathematical Society, Kazan, 1997, 23-32

[[Category:Mathematics awards]]
[[Category:Awards established in 1896]]
[[Category:Awards of the Russian Academy of Sciences]]</text>
      <sha1>9kaqncfu8ne06x1vhxgh6z36hspzynp</sha1>
    </revision>
  </page>
  <page>
    <title>Marcinkiewicz interpolation theorem</title>
    <ns>0</ns>
    <id>1033045</id>
    <revision>
      <id>860305000</id>
      <parentid>838859969</parentid>
      <timestamp>2018-09-19T19:07:43Z</timestamp>
      <contributor>
        <username>Tsirel</username>
        <id>113936</id>
      </contributor>
      <comment>/* Formulation */ disambig: quasilinear</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8737">In [[mathematics]], the '''Marcinkiewicz interpolation theorem''', discovered by {{harvs|txt|authorlink=Józef Marcinkiewicz|first=Józef |last=Marcinkiewicz|year=1939}}, is a result bounding the norms of non-linear operators acting on [[lp space|''L''&lt;sup&gt;p&lt;/sup&gt; spaces]].

Marcinkiewicz' theorem is similar  to the [[Riesz–Thorin theorem]] about [[linear operators]], but also applies to non-linear operators.

==Preliminaries==
Let ''f'' be a [[measurable function]] with real or complex values, defined on a [[measure space]] (''X'',&amp;nbsp;''F'',&amp;nbsp;ω).  The [[cumulative distribution function|distribution function]] of ''f'' is defined by

:&lt;math&gt;\lambda_f(t) = \omega\left\{x\in X\mid |f(x)| &gt; t\right\}.&lt;/math&gt;

Then ''f'' is called '''weak &lt;math&gt;L^1&lt;/math&gt;''' if there exists a constant ''C'' such that the distribution of ''f'' satisfies the following inequality for all ''t''&amp;nbsp;&gt;&amp;nbsp;0:

:&lt;math&gt;\lambda_f(t)\leq \frac{C}{t}.&lt;/math&gt;

The smallest constant ''C'' in the inequality above is called the '''weak &lt;math&gt;L^1&lt;/math&gt; norm''' and is usually denoted by ||''f''||&lt;sub&gt;1,''w''&lt;/sub&gt; or ||''f''||&lt;sub&gt;1,∞&lt;/sub&gt;. Similarly the space is usually denoted by ''L''&lt;sup&gt;1,''w''&lt;/sup&gt; or ''L''&lt;sup&gt;1,∞&lt;/sup&gt;.

(Note: This terminology is a bit misleading since the weak norm does not satisfy the triangle inequality as one can see by considering the sum of the functions on &lt;math&gt; (0,1) &lt;/math&gt; given by &lt;math&gt; 1/x &lt;/math&gt;  and &lt;math&gt; 1/(1-x) &lt;/math&gt;, which has norm 4 not 2.)

Any &lt;math&gt;L^1&lt;/math&gt; function belongs to ''L''&lt;sup&gt;1,''w''&lt;/sup&gt; and in addition one has the inequality

:&lt;math&gt;\|f\|_{1,w}\leq \|f\|_1.&lt;/math&gt;

This is nothing but [[Markov's inequality]] (aka Chebyshev's Inequality). The converse is not true. For example, the function 1/''x'' belongs to ''L''&lt;sup&gt;1,''w''&lt;/sup&gt; but not to ''L''&lt;sup&gt;1&lt;/sup&gt;.

Similarly, one may define the [[Lp space#Weak Lp|'''weak &lt;math&gt;L^p&lt;/math&gt; space''']] as the space of all functions ''f'' such that &lt;math&gt;|f|^p&lt;/math&gt; belong to ''L''&lt;sup&gt;1,''w''&lt;/sup&gt;, and the '''weak &lt;math&gt;L^p&lt;/math&gt; norm''' using

:&lt;math&gt;\|f\|_{p,w}=\|\,|f|^p \|_{1,w}^{1/p}.&lt;/math&gt;

More directly, the ''L''&lt;sup&gt;''p'',''w''&lt;/sup&gt; norm is defined as the best constant ''C'' in the inequality

:&lt;math&gt;\lambda_f(t) \le \frac{C^p}{t^p}&lt;/math&gt;

for all ''t''&amp;nbsp;&gt;&amp;nbsp;0.

==Formulation==
Informally, Marcinkiewicz's theorem is

'''Theorem''': ''Let T be a [[bounded linear operator]] from &lt;math&gt;L^p&lt;/math&gt; to &lt;math&gt;L^{p,w}&lt;/math&gt; and at the same time from &lt;math&gt;L^q&lt;/math&gt; to &lt;math&gt;L^{q,w}&lt;/math&gt;. Then T is also a bounded operator from &lt;math&gt;L^r&lt;/math&gt; to &lt;math&gt;L^r&lt;/math&gt; for any r between p and q.''

In other words, even if you only require weak boundedness on the extremes ''p'' and ''q'', you still get regular boundedness inside. To make this more formal, one has to explain that ''T'' is bounded only on a [[Dense set|dense]] subset and can be completed. See [[Riesz-Thorin theorem]] for these details.

Where Marcinkiewicz's theorem is weaker than the Riesz-Thorin theorem is in the estimates of the norm. The theorem gives bounds for the &lt;math&gt;L^r&lt;/math&gt; norm of ''T'' but this bound increases to infinity as ''r'' converges to either ''p'' or ''q''.  Specifically {{harv|DiBenedetto|2002|loc=Theorem VIII.9.2}}, suppose that
:&lt;math&gt;\|Tf\|_{p,w} \le N_p\|f\|_p,&lt;/math&gt;
:&lt;math&gt;\|Tf\|_{q,w} \le N_q\|f\|_q,&lt;/math&gt;
so that the [[operator norm]] of ''T'' from ''L''&lt;sup&gt;''p''&lt;/sup&gt; to ''L''&lt;sup&gt;''p'',''w''&lt;/sup&gt; is at most ''N''&lt;sub&gt;''p''&lt;/sub&gt;, and the operator norm of ''T'' from ''L''&lt;sup&gt;''q''&lt;/sup&gt; to ''L''&lt;sup&gt;''q'',''w''&lt;/sup&gt; is at most ''N''&lt;sub&gt;''q''&lt;/sub&gt;.  Then the following '''interpolation inequality''' holds for all ''r'' between ''p'' and ''q'' and all ''f''&amp;nbsp;∈&amp;nbsp;''L''&lt;sup&gt;''r''&lt;/sup&gt;:
:&lt;math&gt;\|Tf\|_r\le \gamma N_p^\delta N_q^{1-\delta}\|f\|_r&lt;/math&gt;
where
:&lt;math&gt;\delta=\frac{p(q-r)}{r(q-p)}&lt;/math&gt;
and
:&lt;math&gt;\gamma=2\left(\frac{r(q-p)}{(r-p)(q-r)}\right)^{1/r}.&lt;/math&gt;
The constants δ and γ can also be given for ''q''&amp;nbsp;=&amp;nbsp;∞ by passing to the limit.

A version of the theorem also holds more generally if ''T'' is only assumed to be a quasilinear operator  in the following sense: there exists a constant ''C''&amp;nbsp;&gt;&amp;nbsp;0 such that ''T'' satisfies
:&lt;math&gt;|T(f+g)(x)| \le C(|Tf(x)|+|Tg(x)|)&lt;/math&gt;
for [[almost everywhere|almost every]] ''x''.  The theorem holds precisely as stated, except with γ replaced by
:&lt;math&gt;\gamma=2C\left(\frac{r(q-p)}{(r-p)(q-r)}\right)^{1/r}.&lt;/math&gt;

An operator ''T'' (possibly quasilinear) satisfying an estimate of the form
:&lt;math&gt;\|Tf\|_{q,w}\le C\|f\|_p&lt;/math&gt;
is said to be of '''weak type (''p'',''q'')'''.  An operator is simply of type (''p'',''q'') if ''T'' is a bounded transformation from ''L&lt;sup&gt;p&lt;/sup&gt;'' to ''L&lt;sup&gt;q&lt;/sup&gt;'':
:&lt;math&gt;\|Tf\|_q\le C\|f\|_p.&lt;/math&gt;
A more general formulation of the interpolation theorem is as follows:
* If ''T'' is a quasilinear operator of weak type (''p''&lt;sub&gt;0&lt;/sub&gt;, ''q''&lt;sub&gt;0&lt;/sub&gt;) and of weak type (''p''&lt;sub&gt;1&lt;/sub&gt;, ''q''&lt;sub&gt;1&lt;/sub&gt;) where ''q''&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;≠&amp;nbsp;''q''&lt;sub&gt;1&lt;/sub&gt;, then for each θ&amp;nbsp;∈&amp;nbsp;(0,1), ''T'' is of type (''p'',''q''), for ''p'' and ''q'' with ''p'' ≤ ''q'' of the form
:&lt;math&gt;\frac{1}{p} = \frac{1-\theta}{p_0}+\frac{\theta}{p_1},\quad \frac{1}{q} = \frac{1-\theta}{q_0} + \frac{\theta}{q_1}.&lt;/math&gt;
The latter formulation follows from the former through an application of [[Hölder's inequality]] and a duality argument.{{Citation needed|reason=How to use Hölder's inequality and the special case?|date=June 2016}}

==Applications and examples==
A famous application example is the [[Hilbert transform]]. Viewed as a [[multiplier (Fourier analysis)|multiplier]], the Hilbert transform of a function ''f'' can be computed by first taking the [[Fourier transform]] of ''f'', then multiplying by the [[sign function]], and finally applying the [[inverse Fourier transform]].

Hence [[Parseval's theorem]] easily shows that the Hilbert transform is bounded from &lt;math&gt;L^2&lt;/math&gt; to &lt;math&gt;L^2&lt;/math&gt;. A much less obvious fact is that it is bounded from &lt;math&gt;L^1&lt;/math&gt; to &lt;math&gt;L^{1,w}&lt;/math&gt;. Hence Marcinkiewicz's theorem shows that it is bounded from &lt;math&gt;L^p&lt;/math&gt; to &lt;math&gt;L^p&lt;/math&gt; for any 1 &lt; ''p'' &lt; 2. [[dual space|Duality]] arguments show that it is also bounded for 2 &lt; ''p'' &lt; ∞. In fact, the Hilbert transform is really unbounded for ''p'' equal to 1 or ∞.

Another famous example is the [[Hardy–Littlewood maximal function]], which is only [[sublinear operator]] rather than linear.  While &lt;math&gt;L^p&lt;/math&gt; to &lt;math&gt;L^p&lt;/math&gt; bounds can be derived immediately from the &lt;math&gt;L^1&lt;/math&gt; to weak &lt;math&gt;L^1&lt;/math&gt; estimate by a clever change of variables, Marcinkiewicz interpolation is a more intuitive approach.  Since the Hardy–Littlewood Maximal Function is trivially bounded from &lt;math&gt;L^\infty&lt;/math&gt; to &lt;math&gt;L^\infty&lt;/math&gt;, strong boundedness for all &lt;math&gt;p&gt;1&lt;/math&gt; follows immediately from the weak (1,1) estimate and interpolation. The weak (1,1) estimate can be obtained from the [[Vitali covering lemma]].

==History==
The theorem was first announced by {{harvtxt|Marcinkiewicz|1939}}, who showed this result to [[Antoni Zygmund]] shortly before he died in World War II.  The theorem was almost forgotten by Zygmund, and was absent from his original works on the theory of [[singular integral operator]]s.  Later {{harvtxt|Zygmund|1956}} realized that Marcinkiewicz's result could greatly simplify his work, at which time he published his former student's theorem together with a generalization of his own.

== See also ==
* [[Interpolation space]]

==References==
* {{citation | last=DiBenedetto|first=Emmanuele|title=Real analysis|publisher=Birkhäuser|year=2002|isbn=3-7643-4231-5}}.
* {{citation|title=Elliptic partial differential equations of second order|first1=David|last1=Gilbarg|authorlink1=&lt;!--David Gilbarg--&gt;|first2=Neil S.|last2=Trudinger|authorlink2=Neil Trudinger|publisher=Springer-Verlag|year=2001|isbn=3-540-41160-7}}.
*{{Citation | last1=Marcinkiewicz | first1=J. | title=Sur l'interpolation d'operations | year=1939 | journal=C. R. Acad. Sci. Paris | volume=208 | pages=1272–1273}}
* {{citation|title=Introduction to Fourier analysis on Euclidean spaces|first1=Elias|last1=Stein|authorlink1=Elias Stein|first2=Guido|last2=Weiss|publisher=Princeton University Press|year=1971|isbn=0-691-08078-X}}.
*{{Citation | last1=Zygmund | first1=A. | title=On a theorem of Marcinkiewicz concerning interpolation of operations |mr=0080887 | year=1956 | journal=[[Journal de Mathématiques Pures et Appliquées]]|series= Neuvième Série | issn=0021-7824 | volume=35 | pages=223–248}}

[[Category:Fourier analysis]]
[[Category:Theorems in functional analysis]]</text>
      <sha1>82831wp6jc7q27wekpcuvaj75cad1ai</sha1>
    </revision>
  </page>
  <page>
    <title>Mice problem</title>
    <ns>0</ns>
    <id>8532654</id>
    <revision>
      <id>850063172</id>
      <parentid>693232362</parentid>
      <timestamp>2018-07-13T10:24:58Z</timestamp>
      <contributor>
        <username>Andreas Rejbrand</username>
        <id>962108</id>
      </contributor>
      <minor/>
      <comment>fmt</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1949">[[File:N=2.jpg|thumb|right|n=2]]
[[File:Problema dei topi n=3 animazione.gif|thumb|right|n=3]]
[[File:Problema dei topi n=6 animazione.gif|thumb|right|n=6]]

In mathematics, the '''mice problem''' is a problem in which a number of mice (or insects, dogs, missiles, etc.) are placed at the corners of a [[regular polygon]]. Each mouse begins to move towards its immediate neighbour ([[clockwise]] or [[anticlockwise]]). It must be determined when the mice meet.

The most common version has the mice starting at the corners of a unit square, moving at unit speed. In this case they meet after a time of one unit, because the distance between two neighboring mice always decreases at a speed of one unit. More generally, for a regular polygon of ''n'' sides, the distance between neighboring mice decreases at a speed of 1 &amp;nbsp;&amp;minus;&amp;nbsp;cos(2π/''n''), so they meet after a time of 1/(1&amp;nbsp;&amp;minus;&amp;nbsp;cos(2π/''n'')).&lt;ref&gt;[[George Gamow]], Stern, Marvin (1958), Puzzle math, New York: Viking press, pp. 112–114&lt;/ref&gt;
&lt;ref&gt;[[Édouard Lucas]], (1877), "Problem of the Three Dogs", Nouv. Corresp. Math. 3: 175–176&lt;/ref&gt;

==Path of the mice==

For all regular polygons, the mice trace out a [[logarithmic spiral]], which meets in the center of the polygon (as shown on the right).&lt;ref&gt;{{cite web|title=Mice Problem|url=http://mathworld.wolfram.com/MiceProblem.html|publisher=[[MathWorld]]|accessdate=16 April 2013}}&lt;/ref&gt; When additional mice are added and the mice move towards non-immediate neighbours, the paths they trace become more complex.

[[File:Square+midpoint+3.gif|thumb|center]]

[[File:Square+various displacements.gif|thumb|center]]

==See also==
*[[Pursuit curve]]
*[[Radiodrome]]

==References==
{{Reflist}}

==External links==
* [http://overlordoftheuberferal.wordpress.com/2013/09/12/persecution-complex/ Persecution complex] &amp;mdash; Extensions of the mice problem

[[Category:Recreational mathematics]]


{{geometry-stub}}</text>
      <sha1>i54fvricefqg114ylx4wg16eoje79fe</sha1>
    </revision>
  </page>
  <page>
    <title>Negative flag</title>
    <ns>0</ns>
    <id>5503348</id>
    <revision>
      <id>861931419</id>
      <parentid>821841797</parentid>
      <timestamp>2018-10-01T01:54:56Z</timestamp>
      <contributor>
        <ip>103.232.152.75</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1356">{{Refimprove|date=December 2009}}
In a [[computer]] [[central processing unit|processor]] the '''negative flag''' or '''sign flag''' is a single bit in a system status (flag) register used to indicate whether the result of the last mathematical operation resulted in a value in which the most significant bit was set. In a [[two's complement]] interpretation of the result, the negative flag is set if the result was negative.

For example, in an 8-bit signed number system, -37 will be represented as 1101 1011 in binary (the most significant bit is 1), while +37 will be represented as 0010 0101 (the most significant bit is 0).

The negative flag is set according to the result in the [[x86 architecture|x86]] series processors by the following instructions (referring to the [[Intel 80386]] manual &lt;ref&gt;https://pdos.csail.mit.edu/6.828/2012/readings/i386.pdf&lt;/ref&gt;): 
* All arithmetic operations except multiplication and division;
* compare instructions (equivalent to subtract instructions without storing the result);
* Logical instructions - XOR, AND, OR;
* [[TEST (x86 instruction)|TEST]] instructions (equivalent to AND instructions without storing the result).

==References==
 &lt;references/&gt;

{{DEFAULTSORT:Negative Flag}}
[[Category:Computer arithmetic]]

if result is negative sign flag is set {1}.
if result is positive sign flag is reset {0}</text>
      <sha1>5sweo32w6jgfv8esx1cfayoq0z8lohu</sha1>
    </revision>
  </page>
  <page>
    <title>Operator ideal</title>
    <ns>0</ns>
    <id>47986929</id>
    <revision>
      <id>684198655</id>
      <parentid>684125100</parentid>
      <timestamp>2015-10-05T05:17:24Z</timestamp>
      <contributor>
        <username>BG19bot</username>
        <id>14508071</id>
      </contributor>
      <minor/>
      <comment>[[WP:CHECKWIKI]] error fix for #52.  Do [[Wikipedia:GENFIXES|general fixes]] if a problem exists. - using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2957">In [[functional analysis]], a branch of [[mathematics]], an '''operator ideal''' is a special kind of [[Class (set theory)|class]] of [[continuous linear operator]]s between [[Banach space]]s.  If an operator &lt;math&gt;T&lt;/math&gt; belongs to an operator ideal &lt;math&gt;\mathcal{J}&lt;/math&gt;, then for any operators &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; which can be composed with &lt;math&gt;T&lt;/math&gt; as &lt;math&gt;BTA&lt;/math&gt;, then &lt;math&gt;BTA&lt;/math&gt; is class &lt;math&gt;\mathcal{J}&lt;/math&gt; as well.  Additionally, in order for &lt;math&gt;\mathcal{J}&lt;/math&gt; to be an operator ideal, it must contain the class of all finite-rank Banach space operators.

==Formal definition==

Let &lt;math&gt;\mathcal{L}&lt;/math&gt; denote the class of continuous linear operators acting between two Banach spaces.  For any subclass &lt;math&gt;\mathcal{J}&lt;/math&gt; of &lt;math&gt;\mathcal{L}&lt;/math&gt; and any two Banach spaces &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; over the same field &lt;math&gt;\mathbb{K}&lt;/math&gt;, denote by &lt;math&gt;\mathcal{J}(X,Y)&lt;/math&gt; the set of continuous linear operators of the form &lt;math&gt;T:X\to Y&lt;/math&gt;.  In this case, we say that &lt;math&gt;\mathcal{J}(X,Y)&lt;/math&gt; is a '''component''' of &lt;math&gt;\mathcal{J}&lt;/math&gt;.  An operator ideal is a subclass &lt;math&gt;\mathcal{J}&lt;/math&gt; of &lt;math&gt;\mathcal{L}&lt;/math&gt;, containing every identity operator acting on a 1-dimensional Banach space, such that for any two Banach spaces &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; over the same field &lt;math&gt;\mathbb{K}&lt;/math&gt;, the following two conditions for &lt;math&gt;\mathcal{J}(X,Y)&lt;/math&gt; are satisfied:  (1)  If &lt;math&gt;S,T\in\mathcal{J}(X,Y)&lt;/math&gt; then &lt;math&gt;S+T\in\mathcal{J}(X,Y)&lt;/math&gt;; and (2) if &lt;math&gt;W&lt;/math&gt; and &lt;math&gt;Z&lt;/math&gt; are Banach spaces over &lt;math&gt;\mathbb{K}&lt;/math&gt; with &lt;math&gt;A\in\mathcal{L}(W,X)&lt;/math&gt; and &lt;math&gt;B\in\mathcal{L}(Y,Z)&lt;/math&gt;, and if &lt;math&gt;T\in\mathcal{J}(X,Y)&lt;/math&gt;, then &lt;math&gt;BTA\in\mathcal{J}(W,Z)&lt;/math&gt;.

==Properties and examples==

Operator ideals enjoy the following nice properties.

* Every component &lt;math&gt;\mathcal{J}(X,Y)&lt;/math&gt; of an operator ideal forms a linear subspace of &lt;math&gt;\mathcal{L}(X,Y)&lt;/math&gt;, although in general this need not be norm-closed.
* Every operator ideal contains all finite-rank operators.  In particular, the finite-rank operators form the smallest operator ideal.
* For each operator ideal &lt;math&gt;\mathcal{J}&lt;/math&gt;, every component of the form &lt;math&gt;\mathcal{J}(X):=\mathcal{J}(X,X)&lt;/math&gt; forms an [[Ideal (ring theory)|ideal]] in the algebraic sense.

Furthermore, some very well-known classes are norm-closed operator ideals, i.e., operator ideals whose components are always norm-closed.  These include but are not limited to the following.

* [[Compact operator]]s
* [[Weakly compact operator]]s
* Finitely strictly singular operators
* [[Strictly singular operator]]s
* [[Completely continuous operator]]s

==References==
* Pietsch, Albrecht: ''Operator Ideals'', Volume 16 of ''Mathematische Monographien'', Deutscher Verlag d. Wiss., VEB, 1978.

[[Category:Functional analysis]]</text>
      <sha1>hdx0koye6sxsyd864wspdj60jlved89</sha1>
    </revision>
  </page>
  <page>
    <title>Plus and minus signs</title>
    <ns>0</ns>
    <id>245206</id>
    <revision>
      <id>870164862</id>
      <parentid>870164426</parentid>
      <timestamp>2018-11-22T21:28:06Z</timestamp>
      <contributor>
        <username>Favonian</username>
        <id>7007500</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/31.5.134.129|31.5.134.129]] ([[User talk:31.5.134.129|talk]]) to last version by Favonian</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19594">{{For|these two signs conjoined as the symbol "±"|Plus-minus sign}}
{{Redirect|Minus|the mathematical operation represented by the minus sign|Subtraction|other uses}}
{{Redirect2|Positive sign|Negative sign|uses in astrology|Positive sign (astrology)|and|Negative sign (astrology)}}
{{Punctuation marks|+ −|Plus and minus signs}}
The '''plus and minus signs''' ('''+''' and '''−''') are [[mathematical symbol]]s used to represent the notions of [[sign (mathematics)|positive and negative]] as well as the operations of [[addition]] and [[subtraction]]. Their use has been extended to many other meanings, more or less analogous. ''Plus'' and ''minus'' are [[Latin]] terms meaning "more" and "less", respectively.

== History ==
Though the signs now seem as familiar as the [[alphabet]] or the [[Hindu-Arabic numerals]], they are not of great antiquity. The [[Egyptian hieroglyph]]ic sign for addition, for example, resembled a pair of legs walking in the direction in which the text was written ([[Egyptian language|Egyptian]] could be written either from right to left or left to right), with the reverse sign indicating subtraction:&lt;ref&gt;
{{cite journal
 | last = Karpinski | first = Louis C.
 | doi = 10.2307/2973180
 | issue = 6
 | journal = [[The American Mathematical Monthly]]
 | mr = 1518824
 | pages = 257–265
 | title = Algebraical Developments Among the Egyptians and Babylonians
 | volume = 24
 | year = 1917}}&lt;/ref&gt;
{| align="center"
|&lt;hiero&gt;D54&lt;/hiero&gt; or &lt;hiero&gt;D55&lt;/hiero&gt;
|}

[[Nicole Oresme]]'s manuscripts from the 14th century show what may be one of the earliest uses of the plus sign "+".&lt;ref&gt;[http://educ.ubc.ca/courses/etec540/Sep02/ResearchAssignment/LustigovaZ/ra-LustigovaZ.htm The birth of symbols – Zdena Lustigova, Faculty of Mathematics and Physics Charles University, Prague] {{webarchive|url=https://archive.is/20130708153352/http://educ.ubc.ca/courses/etec540/Sep02/ResearchAssignment/LustigovaZ/ra-LustigovaZ.htm |date=2013-07-08 }}&lt;/ref&gt;

In Europe in the early 15th century the letters "P" and "M" were generally used.&lt;ref name="ley196504"&gt;{{Cite magazine
 |last=Ley
 |first=Willy
 |author=
 |last2=
 |first2=
 |date=April 1965
 |title=Symbolically Speaking
 |department=For Your Information
 |url=https://archive.org/stream/Galaxy_v23n04_1965-04#page/n57/mode/2up
 |magazine=Galaxy Science Fiction
 |pages=57-67
 |type=
}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Stallings|first=Lynn|date=May 2000|title=A brief history of algebraic notation|journal=School Science and Mathematics|url=http://findarticles.com/p/articles/mi_qa3667/is_200005/ai_n8885415/|accessdate=13 April 2009}}&lt;/ref&gt;
The symbols (P with line ''p̄'' for ''più'', i.e., plus, and M with line ''m̄'' for ''meno'', i.e., minus) appeared for the first time in [[Luca Pacioli]]’s mathematics compendium, ''[[Summa de arithmetica|Summa de arithmetica, geometria, proportioni et proportionalità]]'', first printed and published in [[Venice]] in 1494.&lt;ref&gt;{{cite journal |first=Alan |last=Sangster |first2=Greg |last2=Stoner |first3=Patricia |last3=McCarthy |title=The market for Luca Pacioli’s Summa Arithmetica |journal=Accounting Historians Journal |volume=35 |issue=1 |year=2008 |pages=111–134 [p. 115] |url=http://eprints.mdx.ac.uk/3201/1/final_final_proof_Market_paper_050308.pdf }}&lt;/ref&gt; The '''+''' is a simplification of the Latin "et" (comparable to the [[ampersand]] '''&amp;''').&lt;ref&gt;{{cite book|last=Cajori|first=Florian|title=A History of Mathematical Notations, Vol. 1|year=1928|publisher=The Open Court Company, Publishers|chapter=Origin and meanings of the signs + and -}}&lt;/ref&gt; The '''−''' may be derived from a [[tilde]] written over '''m''' when used to indicate subtraction; or it may come from a shorthand version of the letter m itself.&lt;ref&gt;{{cite book|title=Intermediate Algebra|edition=4th|year=2000|first1=D. Franklin|last1=Wright|first2=Bill D.|last2=New|publisher=Thomson Learning|page=1|quote=The minus sign or bar, — , is thought to be derived from the habit of early scribes of using a bar to represent the letter m}}&lt;/ref&gt; In his 1489 treatise [[Johannes Widmann]] referred to the symbols − and + as ''minus'' and ''mer'' (Modern German ''mehr''; "more"): "was − ist, das ist minus, und das + ist das mer".&lt;ref name="OED"&gt;{{OED|plus}}&lt;/ref&gt; They weren't used for addition and subtraction here, but to indicate surplus and deficit; their first use in their modern sense appears in a book by [[Henricus Grammateus]] in 1518.&lt;ref&gt;{{cite book|last=Smith|author-link=David Eugene Smith|first=D.E.|title=History of Mathematics|isbn=0486204308 |publisher=Courier Dover Publications|year=1951|volume=1|pages=258, 330}}&lt;/ref&gt;&lt;ref&gt;[http://jeff560.tripod.com/operation.html Earliest Uses of Various Mathematical Symbols]&lt;/ref&gt;

[[Robert Recorde]], the designer of the [[equals sign]], introduced plus and minus to Britain in 1557 in ''[[The Whetstone of Witte]]'':&lt;ref&gt;{{citation|title=A History of Mathematical Notations|first=Florian|last=Cajori|authorlink=Florian Cajori|publisher=Cosimo|year=2007|isbn=9781602066847|page=164|url=https://books.google.com/books?id=rhEh8jPGQOcC&amp;pg=PA164}}.&lt;/ref&gt; "There be other 2 signes in often use of which the first is made thus + and betokeneth more: the other is thus made – and betokeneth lesse."

== Plus sign ==
{{Redirect|+}}
The plus sign ('''+''') is a [[binary operator]] that indicates [[addition]], as in 2 + 3 = 5. It can also serve as a [[unary operator]] that leaves its [[operand]] [[identity function|unchanged]] (+''x'' means the same as ''x''). This notation may be used when it is desired to emphasize the positiveness of a number, especially when contrasting with the negative (+5 versus −5).

The plus sign can also indicate many other operations, depending on the mathematical system under consideration. Many [[algebraic structure]]s have some operation which is called, or is equivalent to, addition. It is conventional to use the plus sign to only denote [[commutative property|commutative operation]]s.&lt;ref name="Fraleigh"&gt;{{cite book
 | last = Fraleigh
 | first = John B.
 | authorlink =
 | title = A First Course in Abstract Algebra
 | publisher = [[Addison-Wesley]]
 | series =
 | volume =
 | edition = 4
 | year = 1989
 | location = United States
 | pages = 52
 | language =
 | url =
 | doi =
 | id =
 | isbn = 0-201-52821-5
 | mr =
 | zbl =
 | jfm = }}&lt;/ref&gt; Moreover, the symbolism has been extended to very different operations; plus can also mean:
* [[exclusive or]] (usually written ⊕): 1 + 1 = 0, 1 + 0 = 1
* [[logical disjunction]] (usually written ∨): 1 + 1 = 1, 1 + 0 = 1

== Minus sign ==

{{Redirect-distinguish|−|Hyphen|Hyphen-minus|Dash}}
The minus sign ('''−''') has three main uses in mathematics:&lt;ref&gt;{{Cite book|
title= The Algebra Lab | url= https://books.google.com/books?id=nzukMBV6ReoC&amp;pg=PA9 | author=Henri Picciotto | publisher=Creative Publications | page=9 | isbn=978-0-88488-964-9}}&lt;/ref&gt;
# The [[subtraction]] operator: A [[binary operator]] to indicate the operation of subtraction, as in 5&amp;nbsp;−&amp;nbsp;3&amp;nbsp;=&amp;nbsp;2. Subtraction is the inverse of addition.
# Directly [[Sign (mathematics)|in front of]] a number (numeric [[Literal (computer programming)|literal]]) and when it is not a subtraction operator it means a [[negative number]]. For instance −5 is negative 5.
# A [[unary operator]] that acts as an instruction to replace the operand by its [[additive inverse]]. For example, if ''x'' is 3, then −''x'' is −3, but if ''x'' is −3, then −''x'' is 3. Similarly, −(−2) is equal to&amp;nbsp;2. The above is a special case of this.

All three uses can be referred to as "minus" in everyday speech. In most English-speaking countries, −5 (for example) is normally pronounced "minus five", but in modern US usage it is instead usually pronounced "negative five"; here, "minus" may be used by speakers born before 1950, and is still popular in some contexts, but "negative" is usually taught as the only correct reading.&lt;ref&gt;{{Cite book|title=The words of mathematics |first=Steven |last=Schwartzman |year=1994 |publisher=The Mathematical Association of America |page=136}}&lt;/ref&gt; Further, a few textbooks in the United States encourage −''x'' to be read as "the opposite of ''x''" or "the additive inverse of ''x''" to avoid giving the impression that −''x'' is necessarily negative.&lt;ref&gt;{{Cite book|title=Modern Mathematics |first=Ruric E. |last=Wheeler |year=2001 |edition=11 |pages=171}}&lt;/ref&gt;

In some contexts, different glyphs are used for these meanings; for instance in the computer language [[APL (programming language)|APL]] and the expression language used by [[Texas Instruments]] graphing calculators (definitely at least the early models including the [[TI-81]] and [[TI-82]]) a raised minus sign is used in negative numbers (as in 2&amp;nbsp;−&amp;nbsp;5 shows &lt;sup&gt;−&lt;/sup&gt;3), but such usage is uncommon.

In mathematics and most programming languages, the rules for the [[order of operations]] mean that −5&lt;sup&gt;2&lt;/sup&gt; is equal to −25: Powers bind more strongly than the unary minus, which binds more strongly than multiplication or division. However, in some programming languages and [[Microsoft Excel]] in particular, unary operators bind strongest, so in those cases −5^2 is 25 but 0−5^2 is −25.&lt;ref&gt;{{cite web|url=http://office.microsoft.com/en-us/excel/HP100788861033.aspx |title=Microsoft Office Excel Calculation operators and precedence |accessdate=2009-07-29 |deadurl=yes |archiveurl=https://web.archive.org/web/20090811090433/http://office.microsoft.com/en-us/excel/HP100788861033.aspx |archivedate=2009-08-11 |df= }}&lt;/ref&gt;

== Use in elementary education ==

Some elementary teachers use raised plus and minus signs before numbers to show they are positive or negative numbers.&lt;ref&gt;{{cite book|title=Understanding by design|author1=Grant P. Wiggins|author2=Jay McTighe|page=210|year=2005|publisher=ACSD Publications|isbn=1-4166-0035-3}}&lt;/ref&gt; For example, subtracting −5 from 3 might be read as "positive three take away negative 5" and be shown as

:3 − &lt;sup&gt;−&lt;/sup&gt;5 becomes 3 + 5 = 8,
or even as
:&lt;sup&gt;+&lt;/sup&gt;3 − &lt;sup&gt;−&lt;/sup&gt;5 becomes &lt;sup&gt;+&lt;/sup&gt;3 + &lt;sup&gt;+&lt;/sup&gt;5 = &lt;sup&gt;+&lt;/sup&gt;8.

== Use as a qualifier ==

In grading systems (such as examination marks), the plus sign indicates a grade one level higher and the minus sign a grade lower. For example, B− ("B minus") is one grade lower than B. Sometimes this is extended to two plus or minus signs; for example A++ is two grades higher than A.

Positive and negative are sometimes abbreviated as +ve and −ve.&lt;ref&gt;{{cite book|title=Oxford Handbook of Adult Nursing|first1=George|last1=Castledine|first2=Ann|last2=Close|publisher=Oxford University Press|year=2009|isbn=9780191039676|page=xvii|url=https://books.google.com/books?id=R6icAwAAQBAJ&amp;pg=PR17}}.&lt;/ref&gt;

In mathematics the [[one-sided limit]] ''x''→''a''&lt;sup&gt;+&lt;/sup&gt; means ''x'' approaches ''a'' from the right, and ''x''→''a''&lt;sup&gt;−&lt;/sup&gt; means ''x'' approaches ''a'' from the left. For example, when calculating what ''x''&lt;sup&gt;−1&lt;/sup&gt; is when ''x'' approaches 0, because ''x''&lt;sup&gt;−1&lt;/sup&gt;→[[Extended real number line|+∞]] when ''x''→0&lt;sup&gt;+&lt;/sup&gt; but ''x''&lt;sup&gt;−1&lt;/sup&gt;→−∞ when ''x''→0&lt;sup&gt;−&lt;/sup&gt;.

[[Blood types]] are often qualified with a plus or minus to indicate the presence or absence of the [[Rh factor]]; for instance, A+ means [[ABO blood group system|A-type blood]] with the Rh factor present, while B− means B-type blood with the Rh factor absent.

In music, [[Augmented triad#Augmented chord table|augmented chord]]s are symbolized with a plus sign, although this practice is not universal as there are other methods for spelling those chords. For example, "C+" is read "C augmented chord". Also used as [[superscript]].

== Uses in computing ==

As well as the normal mathematical usage plus and minus may be used for a number of other purposes in computing.

Plus and minus signs are often used in [[tree view]] on a computer screen to show if a folder is collapsed or not.

In some programming languages, [[concatenation]] of [[string (computer science)|string]]s is written &lt;code&gt;"a" + "b"&lt;/code&gt;, and results in &lt;code&gt;"ab"&lt;/code&gt;.

In most programming languages, subtraction and negation are indicated with the ASCII [[hyphen-minus]] character, &lt;code&gt;-&lt;/code&gt;. In [[APL (programming language)|APL]] a raised minus sign (Unicode U+00AF) is used to denote a negative number, as in &lt;code&gt;¯3&lt;/code&gt;. While in [[J (programming language)|J]] a negative number is denoted by an [[underscore]], as in &lt;code&gt;_5&lt;/code&gt;.

In [[C (programming language)|C]] and some other computer programming languages, two plus signs indicate the [[Increment operator|increment]] operator and two minus signs a decrement; the position of the operator before or after the variable indicates whether the new or old value is read from it. For example, if x equals 6, then &lt;code&gt;y = x++&lt;/code&gt; increments x to 7 but sets y to 6, whereas &lt;code&gt;y = ++x&lt;/code&gt; would set both x and y to 7. By extension, "++" is sometimes used in computing terminology to signify an improvement, as in the name of the language [[C++]].

In [[regular expression]]s, "+" is often used to indicate "1 or more" in a pattern to be matched. For example, "x+" means "one or more of the letter x".

There is no concept of negative zero in mathematics, but in computing [[−0 (number)|−0]] may have a separate representation from zero. In the [[IEEE floating-point standard]], 1&amp;nbsp;/&amp;nbsp;−0 is [[negative infinity]] (−∞) whereas 1&amp;nbsp;/&amp;nbsp;0 is [[Infinity|positive infinity]] ([[∞]]).

== Other uses ==

In chemistry, superscripted plus and minus signs are used to indicate an ion with a positive or negative charge of 1 (for example, NH&lt;sub&gt;4&lt;/sub&gt;&lt;sup&gt;+&lt;/sup&gt;). If the charge is greater than 1, a number indicating the charge is written before the sign (SO&lt;sub&gt;4&lt;/sub&gt;&lt;sup&gt;2−&lt;/sup&gt;). The minus sign is also used (rather than an [[en dash]]) for a [[covalent bond|single covalent bond]] between two atoms, as in the [[skeletal formula]].

Subscripted plus and minus signs are used as diacritics in the [[International Phonetic Alphabet]] to indicate [[Relative articulation|advanced or retracted articulations]] of speech sounds.

The minus sign is also used as tone letter in the orthographies of [[Dan language|Dan]], [[Krumen language|Krumen]], [[Karaboro languages|Karaboro]], [[Mwan language|Mwan]], [[Wan language|Wan]], [[Yaouré]], [[Wè language|Wè]], [[Nyabwa language|Nyabwa]] and [[Godie language|Godié]].&lt;ref&gt;Hartell, Rhonda L., ed. (1993), ''The Alphabets of Africa''. Dakar: UNESCO and SIL.&lt;/ref&gt; The Unicode character used for the tone letter (U+02D7) is different from the mathematical minus sign.

In the [[Algebraic notation (chess)|algebraic notation]] used to record games of [[chess]], the plus sign (+) is used to denote a move that puts the opponent into [[Check (chess)|check]]. A double plus (++) is sometimes used to denote [[double check]]. Combinations of the plus and minus signs are used to evaluate a move (+/&amp;minus;, +/=, =/+, &amp;minus;/+).

== Character codes ==

[[File:Plus Minus Hyphen-minus.svg|thumb|Plus, minus, and hyphen-minus.]]
{| class="wikitable" style="text-align:center;"
! Read !! Character !! [[Unicode]] !! [[ASCII]] !! in [[Uniform Resource Locator|URL]] !! [[HTML]] notations
|-
|''Plus'' ||&lt;nowiki&gt;+&lt;/nowiki&gt; || U+002B || &lt;code&gt;&amp;amp;#43;&lt;/code&gt; || &lt;code&gt;%2B&lt;/code&gt; || &lt;code&gt;&amp;amp;plus;&lt;/code&gt;
|-
|''Minus'' || &lt;nowiki&gt;−&lt;/nowiki&gt; || U+2212 || || &lt;code&gt;%E2%88%92&lt;/code&gt; || &lt;code&gt;&amp;amp;minus; &amp;amp;#x2212; &amp;amp;#8722;&lt;/code&gt;
|-
|''Hyphen-minus'' || &lt;nowiki&gt;-&lt;/nowiki&gt; || U+002D || &lt;code&gt;&amp;amp;#45;&lt;/code&gt; || &lt;code&gt;%2D&lt;/code&gt; ||
|-
|''Small Hyphen-minus'' || &lt;nowiki&gt;﹣&lt;/nowiki&gt; || U+FE63 || || &lt;code&gt;%EF%B9%A3&lt;/code&gt; || &lt;code&gt;&amp;amp;#xfe63; &amp;amp;#65123;&lt;/code&gt;
|-
|''Full-width Plus'' || &lt;nowiki&gt;＋&lt;/nowiki&gt; || U+FF0B || || &lt;code&gt;%EF%BC%8B&lt;/code&gt; || &lt;code&gt;&amp;amp;#xff0b; &amp;amp;#65291;&lt;/code&gt;
|-
|''Full-width Hyphen-minus'' || &lt;nowiki&gt;－&lt;/nowiki&gt; || U+FF0D || || &lt;code&gt;%EF%BC%8D&lt;/code&gt; || &lt;code&gt;&amp;amp;#xff0d; &amp;amp;#65293;&lt;/code&gt;
|}

The '''hyphen-minus sign''' (-) is the [[ASCII]] alternative/version of the minus sign, and doubles as a [[hyphen]]. It is usually shorter in length than the plus sign and sometimes at a different height. It can be used as a substitute for the true minus sign when the character set is limited to [[ASCII]]. Most programming languages and other computer readable languages do this, since ASCII is generally available as a subset of most character encodings, while U+2212 is a Unicode feature only.

There is a '''commercial minus sign''' (⁒), which looks somewhat like an [[obelus]], at U+2052 (HTML &lt;tt&gt;&amp;amp;#x2052;&lt;/tt&gt;).

The &lt;code&gt;&amp;amp;plus;&lt;/code&gt; entity is HTML 5.{{Clarify|date=November 2018}}

{{Hatnote|For detailed distinctions between minus signs and dashes, see {{section link|Dash|Similar Unicode characters}}.}}

=== Alternative plus sign ===
{{See also|Up tack}}
&lt;div style="float:right; margin: 0 0 10px 10px; padding:40px; font-size:100%; font-family: Georgia; background-color: #ddddff; border: 1px solid #aaaaff;"&gt;[[File:Altplus.svg|50px]]&lt;/div&gt;
A [[Jew]]ish tradition that dates from at least the 19th century is to write ''plus'' using a symbol like an inverted T.&lt;ref name=JE&gt;{{cite book|author=Kaufmann Kohler|editor=[[Cyrus Adler]] et al.|title=Jewish Encyclopedia|chapter=Cross|year=1901–1906|url=http://www.jewishencyclopedia.com/articles/4776-cross}}&lt;/ref&gt; This practice was adopted into [[Israel]]i schools and is still commonplace today in [[elementary school]]s (including [[secular]] schools) but in fewer [[secondary school]]s.&lt;ref name="University of California"&gt;[https://books.google.com/books?id=m8sWAAAAIAAJ&amp;dq=Jewish+plus+sign&amp;q=%22plus+sign+used+in+mathematics%22&amp;pgis=1 Christian-Jewish Dialogue: Theological Foundations By Peter von der Osten-Sacken (1986 – Fortress Press)] {{ISBN|0-8006-0771-6}} "In Israel the plus sign used in mathematics is represented by a horizontal stroke with a vertical hook instead of the sign otherwise used all over the world, because the latter is reminiscent of a cross." (Page 96)&lt;/ref&gt; It is also used occasionally in books by religious authors, but most books for adults use the international symbol "+". The reason for this practice is that it avoids the writing of a symbol "+" that looks like a [[Christian cross]].&lt;ref name=JE/&gt;&lt;ref name="University of California"/&gt; [[Unicode]] has this symbol at position {{Unichar|FB29|HEBREW LETTER ALTERNATIVE PLUS SIGN}}.&lt;ref&gt;[http://www.decodeunicode.org/U+FB29 Unicode U+FB29 reference page] This form of the plus sign is also used on the control buttons at individual seats on board the El Al Israel Airlines aircraft.&lt;/ref&gt;

== See also ==
* [[Graft-chimaera]] for the meaning of + in [[botanical name]]s
* [[List of international call prefixes]] that + can represent the numbers required to dial out of a country as seen in a phone number
* [[Table of mathematical symbols]]
* [[En dash]], a dash that looks similar to the subtraction symbol but is used for different purposes
* [[Asterisk]], the star mark {{angle bracket|&lt;sup&gt;*&lt;/sup&gt;}} denoting unattested [[linguistic reconstruction]]s, is sometimes replaced by a superscript plus {{angle bracket|&lt;sup&gt;+&lt;/sup&gt;}}

== References and footnotes ==
{{Reflist}}

== External links ==
*{{Wiktionary-inline|plus sign}}
*{{Wiktionary-inline|minus sign}}

{{DEFAULTSORT:Plus and minus signs}}
[[Category:Elementary arithmetic]]
[[Category:Mathematical symbols]]
[[Category:Addition]]
[[Category:Subtraction]]</text>
      <sha1>3lo51lz8n6mjuswj7xs7wkwzszew66u</sha1>
    </revision>
  </page>
  <page>
    <title>Proof calculus</title>
    <ns>0</ns>
    <id>1250665</id>
    <revision>
      <id>838655822</id>
      <parentid>822147390</parentid>
      <timestamp>2018-04-28T12:18:54Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>rm obsolete tag</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3188">In [[mathematical logic]],  a '''proof calculus''' or a '''proof system''' is built to prove statements.

==Overview==
A proof system includes the components:&lt;ref&gt;{{Cite web| url=http://www3.cs.stonybrook.edu/~cse541/chapter7.pdf| title=General proof systems |author=Anita Wasilewska}}&lt;/ref&gt;
* Language: The set of formulas admitted by the system, for example, [[propositional logic]] or [[first-order logic]].
* [[Rules of inference]]: List of rules that can be employed to prove theorems from axioms and theorems.
* [[Axioms]]: Formulas in L assumed to be valid. All theorems are derived from axioms.

Usually a given proof calculus encompasses more than a single particular formal system, since many proof calculi are under-determined and can be used for radically different logics. For example, a paradigmatic case is the [[sequent calculus]], which can be used to express the [[consequence relation]]s of both [[intuitionistic logic]] and [[relevance logic]]. Thus, loosely speaking, a proof calculus is a template or [[design pattern]], characterized by a certain style of formal inference, that may be specialized to produce specific formal systems, namely by specifying the actual inference rules for such a system. There is no consensus among logicians on how best to define the term.

==Examples of proof calculi==
The most widely known proof calculi are those classical calculi that are still in widespread use:
*The class of [[Hilbert system]]s, of which the most famous example is the 1928 [[Hilbert-Ackermann system]] of [[first-order logic]];
*[[Gerhard Gentzen]]'s calculus of [[natural deduction]], which is the first formalism of [[structural proof theory]], and which is the cornerstone of the [[formulae-as-types correspondence]] relating logic to [[functional programming]];
*Gentzen's [[sequent calculus]], which is the most studied formalism of structural proof theory.

Many other proof calculi were, or might have been, seminal, but are not widely used today.

*[[Aristotle]]'s  [[syllogistic]] calculus, presented in the ''[[Organon]]'', readily admits formalisation. There is still some modern interest in syllogistic, carried out under the [[aegis]] of [[term logic]].
*[[Gottlob Frege]]'s two-dimensional notation of the ''[[Begriffsschrift]]'' (1879) is usually regarded as introducing the modern concept of [[Quantifier (logic)|quantifier]] to logic.
*[[Charles Sanders Peirce|C.S. Peirce]]'s [[existential graph]] might easily have been seminal, had history worked out differently.

Modern research in logic teems with rival proof calculi:
*Several systems have been proposed which replace the usual textual syntax with some graphical syntax. [[Proof net]]s and [[cirquent calculus]] are among such systems.
*Recently, many logicians interested in [[structural proof theory]] have proposed calculi with [[deep inference]], for instance [[display logic]], [[hypersequent]]s, the [[calculus of structures]], and [[bunched implication]].

== See also ==
* [[Propositional proof system]]
* [[Proof net]]s
* [[Cirquent calculus]]
* [[Calculus of structures]]
* [[Formal proof]]

==References==
{{Reflist}}

[[Category:Proof theory]]
[[Category:Logical calculi]]</text>
      <sha1>1pl0g7cbb0j0i7ika5u8ed7jzb08nr5</sha1>
    </revision>
  </page>
  <page>
    <title>Quantitative psychology</title>
    <ns>0</ns>
    <id>3067624</id>
    <revision>
      <id>860241067</id>
      <parentid>857446951</parentid>
      <timestamp>2018-09-19T09:19:43Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta9) ([[User:Smasongarrison|Smasongarrison]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16629">{{Psychology sidebar|basic}}
'''Quantitative psychology''' is a field of scientific study that focuses on the [[mathematical modeling]], research design and methodology, and [[statistics|statistical analysis]] of human or animal psychological processes. It includes tests and other devices for measuring human abilities.&lt;ref&gt;{{cite web|title=Quantitative Psychology|url=http://www.apa.org/research/tools/quantitative/index.aspx|website=American Psychological Association|accessdate=13 December 2014}}&lt;/ref&gt; Quantitative psychologists develop and analyze a wide variety of research methods, including those of [[psychometrics]], a field concerned with the theory and technique of psychological measurement.&lt;ref&gt;{{cite web|title=Classification of Instructional Programs – Psychometrics and Quantitative Psychology|url=http://nces.ed.gov/ipeds/cipcode/cipdetail.aspx?y=55&amp;cipid=87539|website=The Integrated Postsecondary Education Data System|accessdate=19 January 2015}}&lt;/ref&gt;

Psychologists have long contributed to statistical and mathematical analysis, and quantitative psychology is now a specialty recognized by the [[American Psychological Association]]. Doctoral degrees are awarded in this field in a number of universities in Europe and North America, and quantitative psychologists have been in high demand in industry, government, and academia. Their training in both [[social science]] and quantitative methodology provides a unique skill set for solving both applied and theoretical problems in a variety of areas.

== History ==
[[File:Galton's correlation diagram 1875.jpg|175px|thumbnail|right|[[Francis Galton]]'s [[correlation]] diagram, 1875.]]
Quantitative psychology has its roots in early [[experimental psychology]] when, in the nineteenth century, the scientific method was first systematically applied to psychological phenomena. Notable contributions included E. H. Weber's studies of tactile sensitivity (1930s), [[Gustav Fechner|Fechner's]] development and use of the psychophysical methods (1850-1860), and [[Hermann von Helmholtz|Helmholtz's]] research on vision and audition beginning after 1850. [[Wilhelm Wundt]] is often called the "founder of experimental psychology", because he called himself a psychologist and opened a psychological laboratory in 1879 where many researchers came to study.&lt;ref&gt;E. Hearst (ed) The First Century of Experimental Psychology, 1979, pp. 19-20, Hillsdale, NJ: Earlbaum&lt;/ref&gt; The work of these and many others helped put to rest the assertion, by theorists such as [[Immanuel Kant]], that psychology could not become a science because precise experiments on the human mind were impossible.

=== Intelligence testing ===
{{main|intelligence testing}}
[[Intelligence testing]] has long been an important branch of quantitative psychology. The nineteenth-century English statistician [[Francis Galton]], a pioneer in psychometrics, was the first to create a standardized test of intelligence, and he was among the first to apply   statistical methods to the study of human differences and their inheritance. He came to believe that intelligence is largely determined by heredity, and he also hypothesized that other measures such as the speed of [[reflex]]es, [[muscle]] strength, and head size are correlated with intelligence.&lt;ref&gt;Bulmer, M. (1999). The development of Francis Galton's ideas on the mechanism of heredity. ''Journal of the History of Biology, 32''(3), 263-292. Cowan, R. S. (1972). Francis Galton's contribution to genetics. ''Journal of the History of Biology, 5''(2), 389-412. See also Burbridge, D. (2001). Francis Galton on twins, heredity and social class. ''British Journal for the History of Science, 34''(3), 323-340.&lt;/ref&gt;&lt;ref&gt;Fancher, R. E. (1983). Biographical origins of Francis Galton's psychology. ''Isis, 74''(2), 227-233.&lt;/ref&gt; He established the world's first mental testing center in 1882 in the following year he published his observations and theories in "Inquiries into Human Faculty and Its Development".

=== Statistical techniques ===
[[File:IQ curve.svg|250px|thumbnail|left|[[IQ]] scores represented by a [[normal distribution]].]]
Statistical methods are the quantitative tools most used by psychologists. Pearson introduced the correlation coefficient and the chi-squared test. The 1900–1920 period saw the t-test (Student, 1908), the ANOVA (Fisher, 1925) and a non-parametric correlation coefficient (Spearman, 1904). A large number of tests were developed in the latter half of the 20th century (e.g., all the multivariate tests). Popular techniques (such as Hierarchical Linear Model, Arnold, 1992, Structural Equation Modeling, Byrne, 1996 and Independent Component Analysis, Hyvarinën, Karhunen and Oja, 2001) are relatively recent.&lt;ref&gt;{{cite journal|last1=Cousineau|first1=Denis|title=The rise of quantitative methods in psychology|journal=Tutorial in Quantitative Methods for Psychology|date=2005|volume=1|issue=1|pages=1–3|url=http://doe.concordia.ca/cslp/Downloads/PDF/The%20rise%20of%20..art.pdf|accessdate=1 January 2015|deadurl=yes|archiveurl=https://web.archive.org/web/20160304024719/http://doe.concordia.ca/cslp/Downloads/PDF/The%20rise%20of%20..art.pdf|archivedate=4 March 2016|df=}}&lt;/ref&gt;

In 1946, psychologist [[Stanley Smith Stevens]] organized [[levels of measurement]] into four scales: Nominal, Ordinal, Ratio, and Interval  in a paper that is still often cited.&lt;ref&gt;{{Cite journal |date=June 7, 1946 |last=Stevens |first=Stanley Smith |title=On the Theory of Scales of Measurement |journal=[[Science (journal)|Science]] |volume=103 |issue=2684 |pages=677–680 |doi=10.1126/science.103.2684.677 |pmid=17750512 |url=http://www.mpopa.ro/statistica_licenta/Stevens_Measurement.pdf |archive-url=https://web.archive.org/web/20120906231510/http://www.mpopa.ro/statistica_licenta/Stevens_Measurement.pdf |dead-url=yes |archive-date=September 6, 2012 |accessdate=September 16, 2010 |bibcode=1946Sci...103..677S }}&lt;/ref&gt;  [[Jacob Cohen (statistician)|Jacob Cohen]], a [[New York University]] professor of psychology, analyzed quantitative methods involving statistical power and effect size, which helped to lay foundations for current statistical [[meta-analysis]] and the methods of estimation statistics.&lt;ref&gt;[http://media.wiley.com/product_data/excerpt/04/04708608/0470860804-2.pdf Cohen's entry in Encyclopedia of Statistics in Behavioral Science]&lt;/ref&gt; He gave his name to [[Cohen's kappa]] and [[Cohen's d]].

In 1990, an influential paper titled "Graduate Training in Statistics, Methodology, and Measurement in Psychology" was published in the [[American Psychologist]] journal. This article discussed the need for increased and up-to-date training in quantitative methods for psychology graduate programs in the United States.&lt;ref&gt;{{cite journal|last1=Aiken|first1=Leona S.|last2=West|first2=Stephen G.|title=Graduate Training in Statistics, Methodology, and Measurement in Psychology: A Survey of PhD Programs in North America|journal=American Psychologist|date=June 1990|volume=45|issue=6|pages=721–734|url=http://psych.wustl.edu/memory/Roddy%20article%20PDF%27s/Aiken%20et%20al%20%281990%29_AmPsy.pdf|accessdate=19 January 2015|doi=10.1037/0003-066x.45.6.721|archive-url=https://web.archive.org/web/20150119163608/http://psych.wustl.edu/memory/Roddy%20article%20PDF%27s/Aiken%20et%20al%20%281990%29_AmPsy.pdf|archive-date=2015-01-19|dead-url=yes|df=}}&lt;/ref&gt;

== Education and training ==
{{Main|List of schools for quantitative psychology}}

=== Undergraduate ===
Training for quantitative psychology can begin informally at the undergraduate level. Many graduate schools recommend that students have some coursework in psychology and complete the full college sequence of [[calculus]] (including [[multivariate calculus]]) and a course in [[linear algebra]]. Quantitative coursework in other fields such as [[economics]] and research methods and statistics courses for psychology majors are also helpful. Historically, however, students without all these courses have been accepted if other aspects of their application show promise. Some schools also offer formal minors in areas related to quantitative psychology. For example, the [[University of Kansas]] offers a minor in "Social and Behavioral Sciences Methodology" that provides advanced training in research methodology, applied data analysis, and practical research experience relevant to quantitative psychology.&lt;ref&gt;{{cite web|title=Undergraduate Minor in Social and Behavioral Sciences Methodology|url=http://www2.ku.edu/~distinction/cgi-bin/social-behavioral-sciences|website=University of Kansas|accessdate=13 December 2014}}&lt;/ref&gt; Coursework in computer science is also useful. Mastery of an [[object-oriented programming language]] or learning to write code in [[SPSS]] or [[R (programming language)|R]] is useful for the type of data analysis performed in graduate school.

=== Graduate ===
[[File:Peabodyvu.JPG|250px|thumbnail|right|[[Peabody College]] (''pictured'') at [[Vanderbilt University]] houses their Quantitative Methods program.]]
Quantitative psychologists may possess a doctoral degree or a master's degree. Due to its interdisciplinary nature and depending on the research focus of the university, these programs may be housed in a school's [[college of education]] or in their psychology department. Programs that focus especially in [[educational research]] and psychometrics are often part of education or [[educational psychology]] departments. These programs may therefore have different names mentioning "research methods" or "quantitative methods", such as the "Research and Evaluation Methodology" Ph.D from the [[University of Florida]] or the "Quantitative Methods" degree at the [[University of Pennsylvania]]. However, some universities may have separate programs in their two colleges. For example, the [[University of Washington]] has a "Quantitative psychology" degree in their psychology department and a separate "Measurement &amp; Statistics" Ph.D in their college of education. Others, such as [[Vanderbilt University]]'s Ph.D in Psychological Sciences is jointly housed across its two psychology departments.

Universities with a mathematical focus include [[McGill University]]'s "Quantitative Psychology and Modeling" program and [[Purdue University]]'s "Mathematical and Computational Cognitive Science" degrees. Students with an interest in modeling biological or functional data may go into related fields such as [[biostatistics]] or [[computational neuroscience]].

Doctoral programs typical accept students with only bachelor's degrees, although some schools may require a master's degree before applying. After the first two years of studies, graduate students typically earn a [[Master of Arts]] in Psychology, [[Master of Science]] in Statistics or [[Applied statistics]], or both.

Additionally, several universities offer minor concentrations in quantitative methods, such as New York University.

Companies that produce [[standardized tests]] such as [[College Board]], [[Educational Testing Service]], and [[American College Testing]] are some of the biggest private sector employers of quantitative psychologists. These companies also often provide internships to students in graduate school.

==== Shortage of qualified applicants ====
In August 2005, the American Psychological Association expressed the need for more quantitative psychologists in the industry—for every PhD awarded in the subject, there were about 2.5 quantitative psychologist position openings.&lt;ref&gt;[http://www.apa.org/research/tools/quantitative/quant-task-force-report.pdf Report of the Task Force for Increasing the Number of Quantitative Psychologists], page 1. ''American Psychological Association''. Retrieved February 15, 2012&lt;/ref&gt; Due to a lack of applicants in the field, the APA created a Task Force to study the state of quantitative psychology and predict its future. Domestic U.S. applicants are especially lacking. The majority of international applicants come from [[Asia]]n countries, especially [[South Korea]] and [[China]].&lt;ref name="taskforce"&gt;{{cite web|title=Report of the Task Force for Increasing the Number of Quantitative Psychologists|url=http://www.apa.org/research/tools/quantitative/quant-task-force-report.pdf|website=American Psychological Association|accessdate=13 December 2014}}&lt;/ref&gt; In response to the lack of qualified applicants, the APA Council of Representatives authorized a special task force in 2006.&lt;ref&gt;{{cite web|title=Quantitative Psychology|url=http://www.apa.org/research/tools/quantitative/|website=American Psychological Association|accessdate=19 January 2015}}&lt;/ref&gt; The task force was chaired by Leona S. Aiken from [[Arizona State University]].

== Research areas ==
[[File:Social Red.jpg|200px|thumbnail|left|Example of a [[social network]] diagram.]]
Quantitative psychologists generally have a main area of interest.&lt;ref name="Prinstein2012"&gt;{{cite book|author=Mitchell J. Prinstein|title=The Portable Mentor: Expert Guide to a Successful Career in Psychology|url=https://books.google.com/books?id=CxbWtXF6QAgC&amp;pg=PA24|date=31 August 2012|publisher=Springer Science &amp; Business Media|isbn=978-1-4614-3993-6|page=24}}&lt;/ref&gt; Notable research areas in psychometrics include [[item response theory]] and [[computer adaptive testing]], which focus on education and [[intelligence testing]]. Other research areas include modeling psychological processes through [[time series]] analysis, such as in [[fMRI]] data collection, and [[structural equation modeling]], [[social network analysis]], [[decision theory|human decision science]], and [[statistical genetics]].

Two common types of psychometric tests are: aptitude tests, which are supposed to measure raw intellectual ability, and personality tests that aim to assess your character, temperament, and how you deal with problems.

Item response theory is based on the application of related [[mathematical model]]s to testing data. Because it is generally regarded as superior to [[classical test theory]], it is the preferred method for developing scales in the United States, especially when optimal decisions are demanded, as in so-called [[High-stakes testing|high-stakes tests]], e.g., the [[Graduate Record Examination]] (GRE) and [[Graduate Management Admission Test]] (GMAT).
{{clear}}

== Professional organizations ==
Quantitative psychology is served by several scientific organizations.  These include the Psychometric Society, Division 5 of the [[American Psychological Association]] (Evaluation, Measurement and Statistics), the [[Society of Multivariate Experimental Psychology]], and the European Society for Methodology.  Associated disciplines include statistics, [[mathematics]], educational measurement, educational statistics, sociology, and political science.  Several scholarly journals reflect the efforts of scientists in these areas, notably ''[[Psychometrika]]'', ''Multivariate Behavioral Research'', ''Structural Equation Modeling'' and ''Psychological Methods''.

== Notable people ==
The following is a select list of quantitative psychologists or people who have contributed to the field:
{{Columns-list|colwidth=30em|
* [[Gwyneth Boodoo]]
* [[Jacob Cohen (statistician)|Jacob Cohen]]
* [[Lee Cronbach]]
* [[Louis Guttman]]
* [[Frederic M. Lord]]
* [[Quinn McNemar]]
* [[Jacqueline Meulman]]
* [[Pip Pattison]]
* [[Robert L. Thorndike]]
* [[Louis Leon Thurstone]]
* [[Helen M. Walker]]
}}

== See also ==
* [[List of schools for quantitative psychology]]
* [[Mathematical psychology]]
* ''[[Measuring the Mind]]''
* [[Psychophysics]]
* [[Psychometrics]]
* [[Psychometrika]]
* [[Quantitative psychological research]]
* [[WinBUGS]]

== References ==
{{reflist|30em}}

== Further reading ==
* {{cite web|title=Report of the Task Force for Increasing the Number of Quantitative Psychologists|url=http://www.apa.org/research/tools/quantitative/quant-task-force-report.pdf|website=American Psychological Association|accessdate=13 December 2014}}

== External links ==
* [http://www.apa.org/divisions/div5/ APA Division 5: Evaluation, Measurement and Statistics]
* [http://www.psychometrika.org/ The Psychometric Society]
* [http://www.smep.org/ The Society of Multivariate Experimental Psychology]
* [http://www.smabs.org/ The European Society for Methodology]
* [https://web.archive.org/web/20070829201159/http://www.cogs.indiana.edu/socmathpsych/ Society for Mathematical Psychology]

[[Category:Psychometrics]]
[[Category:Branches of psychology]]
[[Category:Quantitative analysis of behavior]]
[[Category:Quantitative research]]
[[Category:Applied statistics]]</text>
      <sha1>04l4yduh2n4jj33emcilatx8j0jgaqz</sha1>
    </revision>
  </page>
  <page>
    <title>Regular semi-algebraic system</title>
    <ns>0</ns>
    <id>29317092</id>
    <revision>
      <id>814182810</id>
      <parentid>797947308</parentid>
      <timestamp>2017-12-07T09:24:11Z</timestamp>
      <contributor>
        <username>Latex-yow</username>
        <id>27692366</id>
      </contributor>
      <minor/>
      <comment>/* Formal definition */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3217">In [[computer algebra]], a '''regular semi-algebraic system''' is a particular kind of triangular  system  of multivariate polynomials over a real closed field.

== Introduction ==
[[Regular chain]]s and [[triangular decomposition]]s are fundamental and well-developed tools for describing the complex solutions of polynomial systems. The notion of a regular semi-algebraic system is an adaptation of the concept of a regular chain focusing on solutions of the real analogue: semi-algebraic systems.

Any semi-algebraic system &lt;math&gt;S&lt;/math&gt; can be decomposed into finitely many regular semi-algebraic systems &lt;math&gt;S_1, \ldots, S_e&lt;/math&gt; such that a point (with real coordinates) is a solution of &lt;math&gt;S&lt;/math&gt; if and only if it is a solution of one of the systems &lt;math&gt;S_1, \ldots, S_e&lt;/math&gt;.&lt;ref&gt;Changbo Chen, James H. Davenport, John P. May, Marc Moreno-Maza, Bican Xia, Rong Xiao. [http://www.sciencedirect.com/science/article/pii/S0747717111002070/pdf?md5=9344a2f6467b91cc32bcef52f9275ab2&amp;pid=1-s2.0-S0747717111002070-main.pdf&amp;_valck=1 Triangular decomposition of semi-algebraic systems].  Proceedings of 2010 International Symposium on Symbolic and Algebraic Computation (ISSAC 2010), ACM Press, pp. 187–194, 2010.&lt;/ref&gt;

== Formal definition ==

Let &lt;math&gt;T&lt;/math&gt; be a [[regular chain]] of &lt;math&gt;\mathbf{k}[x_1, \ldots, x_n]&lt;/math&gt; for some ordering of the variables &lt;math&gt;\mathbf{x} = x_1, \ldots, x_n&lt;/math&gt; and a [[real closed field]] &lt;math&gt;\mathbf{k}&lt;/math&gt;. Let &lt;math&gt;\mathbf{u} = u_1, \ldots, u_d&lt;/math&gt; and &lt;math&gt;\mathbf{y} = y_1, \ldots, y_{n-d}&lt;/math&gt; designate respectively the variables of &lt;math&gt;\mathbf{x}&lt;/math&gt; that are free and algebraic with respect to &lt;math&gt;T&lt;/math&gt;. Let &lt;math&gt;P \subset \mathbf{k}[\mathbf{x}]&lt;/math&gt; be finite such that each polynomial in &lt;math&gt;P&lt;/math&gt; is regular with respect to the saturated ideal of &lt;math&gt;T&lt;/math&gt;. Define &lt;math&gt;P_{&gt;} :=\{p&gt;0\mid p\in P\}&lt;/math&gt;. Let &lt;math&gt;\mathcal{Q}&lt;/math&gt; be a quantifier-free formula of &lt;math&gt;\mathbf{k}[\mathbf{x}]&lt;/math&gt; involving only the variables of &lt;math&gt;\mathbf{u}&lt;/math&gt;. We say that &lt;math&gt;R := [\mathcal{Q}, T, P_{&gt;}]&lt;/math&gt; is a '''regular semi-algebraic system''' if the following three conditions hold.

* &lt;math&gt;\mathcal{Q}&lt;/math&gt; defines a non-empty open semi-algebraic set &lt;math&gt;S&lt;/math&gt; of &lt;math&gt;\mathbf{k}^d&lt;/math&gt;,
* the regular system &lt;math&gt;[T, P]&lt;/math&gt; specializes well at every point &lt;math&gt;u&lt;/math&gt; of &lt;math&gt;S&lt;/math&gt;,
* at each point &lt;math&gt;u&lt;/math&gt; of &lt;math&gt;S&lt;/math&gt;, the specialized system &lt;math&gt;[T(u), P(u)_{&gt;}]&lt;/math&gt; has at least one real zero.

The zero set of &lt;math&gt;R&lt;/math&gt;, denoted by &lt;math&gt;Z_{\mathbf{k}}(R)&lt;/math&gt;, is defined as the set of points &lt;math&gt;(u, y) \in \mathbf{k}^d \times \mathbf{k}^{n-d}&lt;/math&gt; such that &lt;math&gt;\mathcal{Q}(u)&lt;/math&gt; is true and &lt;math&gt;t(u, y)=0, p(u, y)&gt;0&lt;/math&gt;, for all &lt;math&gt;t\in T&lt;/math&gt;and all &lt;math&gt;p\in P&lt;/math&gt;. Observe that &lt;math&gt;Z_{\mathbf{k}}(R)&lt;/math&gt; has dimension &lt;math&gt;d&lt;/math&gt; in the affine space &lt;math&gt;\mathbf{k}^n&lt;/math&gt;.

== See also ==
*[[RegularChains]]
*[[Real algebraic geometry]]

== References ==
{{Reflist}}

[[Category:Equations]]
[[Category:Algebra]]
[[Category:Polynomials]]
[[Category:Algebraic geometry]]
[[Category:Computer algebra]]</text>
      <sha1>sqjlyt7c95yj2sew4b70btk89m8q7wo</sha1>
    </revision>
  </page>
  <page>
    <title>Richard L. Bishop</title>
    <ns>0</ns>
    <id>43076291</id>
    <revision>
      <id>836899700</id>
      <parentid>724517156</parentid>
      <timestamp>2018-04-17T14:38:21Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3307">{{Infobox scientist
| name        = Richard L. Bishop
| image       =         &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size  = 
| alt         = 
| caption     = 
| birth_date  = {{abbr|c.|circa}} {{birth year and age|1932}} &lt;!--{{birth date |YYYY|MM|DD}}--&gt;
| birth_place = 
| death_date  =         &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place = 
| nationality = [[United States|American]]
| fields      = [[Mathematics]]
| workplaces  = [[University of Illinois at Urbana–Champaign]]
| alma_mater  = [[Massachusetts Institute of Technology]]&lt;br&gt;[[Case Institute of Technology]]
| doctoral_advisor = [[Isadore Singer]] &lt;!--(or  | doctoral_advisors = )--&gt;
| doctoral_students = [[Stephanie B. Alexander]]
| known_for   = 
| awards      = 
}}

'''Richard Lawrence Bishop''' (born {{abbr|c.|circa}} 1932) is an American [[mathematician]], a [[professor emeritus]] of mathematics at the [[University of Illinois at Urbana–Champaign]].&lt;ref&gt;[http://www.math.illinois.edu/People/emeritusfaculty.html Emeritus faculty] {{webarchive|url=https://web.archive.org/web/20140714121653/http://www.math.illinois.edu/People/emeritusfaculty.html |date=2014-07-14 }}, UIUC Mathematics, retrieved 2014-06-16.&lt;/ref&gt; The [[Bishop–Gromov inequality]] in [[Riemannian geometry]] is named after him (with [[Mikhail Leonidovich Gromov|Mikhail Gromov]]).

Bishop went to [[Case Institute of Technology]] as an undergraduate, earning a B.S. in 1954. Next he earned his Ph.D. from the [[Massachusetts Institute of Technology]] in 1959, and immediately joined the UIUC faculty.&lt;ref&gt;[http://www.math.illinois.edu/~bishop/ Information from Bishop's web page at UIUC], retrieved 2014-06-16.&lt;/ref&gt; His thesis, ''On Imbeddings and Holonomy'', was supervised by [[Isadore Singer]].&lt;ref name="mg"&gt;{{mathgenealogy|name=Richard Lawrence Bishop|id=9690}}&lt;/ref&gt; At UIUC, his doctoral students included future UIUC colleague [[Stephanie B. Alexander]].&lt;ref name="mg"/&gt; He is the author of ''Geometry of Manifolds'' (with Richard J. Crittenden, AMS Chelsea Publishing, 1964,&lt;ref&gt;Review of ''Geometry of Manifolds'' by W. Klingenberg, {{MR|0169148}}&lt;/ref&gt; translated into Russian 1967&lt;ref&gt;{{MR|0213981}}&lt;/ref&gt; and reprinted 2001&lt;ref&gt;1852066&lt;/ref&gt;) and ''Tensor Analysis on Manifolds'' (with Samuel I. Goldberg, Macmillan, 1968,&lt;ref&gt;Review of ''Tensor Analysis on Manifolds'' by T. J. Willmore, {{MR|0224010}}&lt;/ref&gt; reprinted by Dover Books on Mathematics, 1980&lt;ref&gt;{{MR|0615912}}&lt;/ref&gt;).

In 2013, Bishop became one of the inaugural [[fellow]]s of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2014-06-16.&lt;/ref&gt;

==References==
{{reflist|30em}}

{{Authority control}}
{{DEFAULTSORT:Bishop, Richard L.}}
[[Category:1930s births]]
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Case Western Reserve University alumni]]
[[Category:Massachusetts Institute of Technology alumni]]
[[Category:University of Illinois at Urbana–Champaign faculty]]
[[Category:Fellows of the American Mathematical Society]]


{{US-mathematician-stub}}</text>
      <sha1>n29yk01olvcnnm25vrgh3y9ftzwtwgm</sha1>
    </revision>
  </page>
  <page>
    <title>Solid of revolution</title>
    <ns>0</ns>
    <id>329400</id>
    <revision>
      <id>841529407</id>
      <parentid>830896243</parentid>
      <timestamp>2018-05-16T11:47:47Z</timestamp>
      <contributor>
        <username>Bear-rings</username>
        <id>28216728</id>
      </contributor>
      <comment>Per as [[WP:NOTBROKEN]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7379">[[File:Rotationskoerper animation.gif|thumb|right|Rotating a curve. The surface formed is a [[surface of revolution]]; it encloses a solid of revolution.]]
[[File:Revolução de poliedros 03.webm|thumb|300px|Solids of revolution ([[:pt:Matemateca_IME-USP|Matemateca Ime-Usp]])]]
In [[mathematics]], [[engineering]], and [[manufacturing]], a '''solid of revolution''' is a [[Shape|solid figure]] obtained by rotating a [[plane curve]] around some [[straight line]] (the ''[[axis of rotation|axis of revolution]]'') that lies on the same plane.

Assuming that the curve does not cross the axis, the solid's [[volume]] is equal to the [[length]] of the [[circle]] described by the figure's [[centroid]] multiplied by the figure's [[area]] ([[Pappus's centroid theorem|Pappus's second centroid Theorem]]).

A '''representative disk''' is a three-[[dimension]]al [[volume element]] of a solid of revolution.  The element is created by [[rotating]] a [[line segment]] (of [[length]] {{mvar|w}}) around some axis (located {{mvar|r}} units away), so that a [[cylinder (geometry)|cylindrical]] [[volume]] of {{math|π''r''&lt;sup&gt;2&lt;/sup&gt;''w''}} units is enclosed.

==Finding the volume==
Two common methods for finding the volume of a solid of revolution are the disc method and the shell method of integration. To apply these methods, it is easiest to draw the graph in question; identify the area that is to be revolved about the axis of revolution; determine the volume of either a disc-shaped slice of the solid, with thickness {{mvar|δx}}, or a cylindrical shell of width {{mvar|δx}}; and then find the limiting sum of these volumes as {{mvar|δx}} approaches 0, a value which may be found by evaluating a suitable integral.

===Disk method===
[[File:Disc integration.svg|thumb|right|Disk integration about the y-axis]]
{{main|Disc integration}}

The disk method is used when the slice that was drawn is ''perpendicular to'' the axis of revolution; i.e. when integrating ''parallel to'' the axis of revolution.

The volume of the solid formed by rotating the area between the curves of {{math|''f''(''x'')}} and {{math|''g''(''x'')}} and the lines {{math|1=''x'' = ''a''}} and {{math|1=''x'' = ''b''}} about the {{mvar|x}}-axis is given by
:&lt;math&gt;V = \pi \int_a^b \left| f(x)^2 - g(x)^2\right|\,dx\, .&lt;/math&gt;
If {{math|1=''g''(''x'') = 0}} (e.g. revolving an area between the curve and the {{mvar|x}}-axis), this reduces to:
:&lt;math&gt;V = \pi \int_a^b f(x)^2 \,dx\, .&lt;/math&gt;

The method can be visualized by considering a thin horizontal rectangle at {{mvar|y}} between {{math|''f''(''y'')}} on top and {{math|''g''(''y'')}} on the bottom, and revolving it about the {{mvar|y}}-axis; it forms a ring (or disc in the case that {{math|1=''g''(''y'') = 0}}), with outer radius {{math|''f''(''y'')}} and inner radius {{math|''g''(''y'')}}.  The area of a ring is {{math|π(''R''&lt;sup&gt;2&lt;/sup&gt; − ''r''&lt;sup&gt;2&lt;/sup&gt;)}}, where {{mvar|R}} is the outer radius (in this case {{math|''f''(''y'')}}), and {{mvar|r}} is the inner radius (in this case {{math|''g''(''y'')}}). The volume of each infinitesimal disc is therefore {{math|π''f''(''y'')&lt;sup&gt;2&lt;/sup&gt; ''dy''}}. The limit of the Riemann sum of the volumes of the discs between {{mvar|a}} and {{mvar|b}} becomes integral (1).

===Cylinder method===
{{main|Shell integration}}
[[File:Shell integration.svg|thumb|right|Shell integration]]
{{multiple image
 | align = right
 | direction = vertical
 | width = 800
 | header = Solid of revolution demonstration
 | image1 = Revolução de poliedros 01.jpg
 | alt1 = five coloured polyhedra mounted on vertical axes
 | caption1 = The shapes at rest
 | image2 = Revolução de poliedros 02.jpg
 | alt2 = five solids of rotation formed by rotating polyhedra
 | caption2 = The shapes in motion, showing the solids of revolution formed by each
}}
The cylinder method is used when the slice that was drawn is ''parallel to'' the axis of revolution; i.e. when integrating ''perpendicular to'' the axis of revolution.

The volume of the solid formed by rotating the area between the curves of {{math|''f''(''x'')}} and {{math|''g''(''x'')}} and the lines {{math|1=''x'' = ''a''}} and {{math|1=''x'' = ''b''}} about the {{mvar|y}}-axis is given by
:&lt;math&gt;V = 2\pi \int_a^b x |f(x) - g(x)|\,dx\, .&lt;/math&gt;
If {{math|1=''g''(''x'') = 0}} (e.g. revolving an area between curve and {{mvar|y}}-axis), this reduces to:
:&lt;math&gt;V = 2\pi \int_a^b x | f(x) | \,dx\, .&lt;/math&gt;

The method can be visualized by considering a thin vertical rectangle at {{mvar|x}} with height {{math|''f''(''x'') − ''g''(''x'')}}, and revolving it about the {{mvar|y}}-axis; it forms a cylindrical shell.  The lateral surface area of a cylinder is {{math|2π''rh''}}, where {{mvar|r}} is the radius (in this case {{mvar|x}}), and {{mvar|h}} is the height (in this case {{math|''f''(''x'') − ''g''(''x'')}}).  Summing up all of the surface areas along the interval gives the total volume.

==Parametric form==
[[File:Paolo uccello, studio di vaso in prospettiva 02.jpg|thumb|[[Mathematics and art]]: study of a vase as a solid of revolution by [[Paolo Uccello]]. 15th century]]

When a curve is defined by its parametric form {{math|(''x''(''t''),''y''(''t''))}} in some interval {{math|[''a'',''b'']}}, the volumes of the solids generated by revolving the curve around the {{mvar|x}}-axis or the {{mvar|y}}-axis are given by&lt;ref&gt;{{cite book
|title=Application Of Integral Calculus
|first=A.&amp;nbsp;K.
|last=Sharma
|publisher=Discovery Publishing House
|year=2005
|isbn=81-7141-967-4
|page=168
|url=https://books.google.com/books?id=V_WxjYMKuUAC&amp;pg=PA168}}&lt;/ref&gt;
:&lt;math&gt;V_x = \int_a^b \pi y^2 \, \frac{dx}{dt} \, dt \, ,&lt;/math&gt;

:&lt;math&gt;V_y = \int_a^b \pi x^2 \, \frac{dy}{dt} \, dt \, .&lt;/math&gt;

Under the same circumstances the areas of the surfaces of the solids generated by revolving the curve around the {{mvar|x}}-axis or the {{mvar|y}}-axis are given by&lt;ref&gt;{{cite book
|title=Engineering Mathematics
|edition=6th
|first=Ravish R.
|last=Singh
|publisher=Tata McGraw-Hill
|year=1993
|isbn=0-07-014615-2
|page=6.90
|url=https://books.google.com/books?id=oQ1y1HCpeowC&amp;pg=SA6-PA90}}&lt;/ref&gt;
:&lt;math&gt;A_x = \int_a^b 2 \pi y \, \sqrt{ \left( \frac{dx}{dt} \right)^2 + \left( \frac{dy}{dt} \right)^2} \, dt \, ,&lt;/math&gt;

:&lt;math&gt;A_y = \int_a^b 2 \pi x \, \sqrt{ \left( \frac{dx}{dt} \right)^2 + \left( \frac{dy}{dt} \right)^2} \, dt \, .&lt;/math&gt;

==See also==
{{commons category|Solids of revolution}}
* [[Gabriel's Horn]]
* [[Guldinus theorem]]
* [[Pseudosphere]]
* [[Surface of revolution]]
* [[Ungula]]

==Notes==
{{reflist}}

== References ==
*{{cite web |website=CliffsNotes.com |title=Volumes of Solids of Revolution |date=12 Apr 2011 |url=http://www.cliffsnotes.com/study_guide/topicArticleId-39909,articleId-39907.html |deadurl=yes |archiveurl=https://web.archive.org/web/20120319195953/http://www.cliffsnotes.com/study_guide/topicArticleId-39909,articleId-39907.html |archivedate=2012-03-19 |df= }} 
*{{cite book|author1-link=Frank J. Ayres |first1=Frank |last1=Ayres |author2-link=Elliott Mendelson |first2=Elliott |last2=Mendelson |series=[[Schaum's Outlines]] |title=Calculus |publisher=McGraw-Hill Professional |date=2008 |ISBN=978-0-07-150861-2 |pages=244–248}} ({{Google books|Ag26M8TII6oC|online copy|page=244}})
*{{MathWorld |id=SolidofRevolution |title=Solid of Revolution}}

{{Authority control}}
[[Category:Integral calculus]]</text>
      <sha1>cczt1j7kzvvoghhbfm3qx1om47k9gyp</sha1>
    </revision>
  </page>
  <page>
    <title>Stability spectrum</title>
    <ns>0</ns>
    <id>15560112</id>
    <revision>
      <id>607169967</id>
      <parentid>435189628</parentid>
      <timestamp>2014-05-05T13:06:33Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>[[WP:CHECKWIKI]] error fixes using [[Project:AWB|AWB]] (10093)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5740">In [[model theory]], a branch of [[mathematical logic]], a complete first-order theory ''T'' is called '''stable in λ''' (an infinite [[cardinal number]]), if the [[Type (model theory)|Stone space]] of every [[structure (mathematical logic)|model]] of ''T'' of size ≤ λ has itself size ≤ λ. ''T'' is called a '''stable theory''' if there is no upper bound for the cardinals κ such that ''T'' is stable in κ. The '''stability spectrum''' of ''T'' is the class of all cardinals κ such that ''T'' is stable in κ.

For countable theories there are only four possible stability spectra. The corresponding [[dividing line (model theory)|dividing line]]s are those for [[totally transcendental theory|total transcendentality]], [[superstable theory|superstability]] and [[stable theory|stability]]. This result is due to [[Saharon Shelah]], who also defined stability and superstability.

== The stability spectrum theorem for countable theories ==

'''Theorem.'''
Every countable complete first-order theory ''T'' falls into one of the following classes:
* ''T'' is stable in λ for all infinite cardinals λ. – ''T'' is totally transcendental.
* ''T'' is stable in λ exactly for all  cardinals λ with λ&amp;nbsp;≥&amp;nbsp;2&lt;sup&gt;ω&lt;/sup&gt;. – ''T'' is superstable but not totally transcendental.
* ''T'' is stable in λ exactly for all cardinals λ that satisfy λ = λ&lt;sup&gt;ω&lt;/sup&gt;. – ''T'' is stable but not superstable.
* ''T'' is not stable in any infinite cardinal λ. – ''T'' is unstable.

The condition on λ in the third case holds for cardinals of the form λ = κ&lt;sup&gt;ω&lt;/sup&gt;, but not for cardinals λ of cofinality ω (because λ&amp;nbsp;&lt;&amp;nbsp;λ&lt;sup&gt;cof&amp;nbsp;λ&lt;/sup&gt;).

=== Totally transcendental theories ===
{{main|Totally transcendental theory}}
A complete first-order theory ''T'' is called '''totally transcendental''' if every formula has bounded [[Morley rank]], i.e. if RM(φ)&amp;nbsp;&lt;&amp;nbsp;∞ for every formula φ(''x'') with parameters in a model of ''T'', where ''x'' may be a tuple of variables. It is sufficient to check that RM(''x''=''x'') &lt; ∞, where ''x'' is a single variable.

For countable theories total transcendence is equivalent to stability in ω, and therefore countable totally transcendental theories are often called '''ω-stable''' for brevity. A totally transcendental theory is stable in every λ&amp;nbsp;≥&amp;nbsp;|''T''|, hence a countable ω-stable theory is stable in all infinite cardinals.

Every [[Morley's categoricity theorem|uncountably categorical]] countable theory is totally transcendental. This includes complete theories of vector spaces or algebraically closed fields. The theories of [[Group of finite Morley rank|groups of finite Morley rank]] are another important example of totally transcendental theories.

=== Superstable theories ===
{{main|Superstable theory}}
A complete first-order theory ''T'' is superstable if there is a rank function on complete types that has essentially the same properties as Morley rank in a totally transcendental theory. Every totally transcendental theory is superstable. A theory ''T'' is superstable if and only if it is stable in all cardinals λ&amp;nbsp;≥&amp;nbsp;2&lt;sup&gt;|''T''|&lt;/sup&gt;.

=== Stable theories ===
{{main|Stable theory}}
A theory that is stable in one cardinal λ&amp;nbsp;≥&amp;nbsp;|''T''| is stable in all cardinals λ that satisfy λ&amp;nbsp;=&amp;nbsp;λ&lt;sup&gt;|''T''|&lt;/sup&gt;. Therefore a theory is stable if and only if it is stable in some cardinal λ&amp;nbsp;≥&amp;nbsp;|''T''|.

=== Unstable theories ===

Most mathematically interesting theories fall into this category, including complicated theories such as any complete extension of ZF set theory, and relatively tame theories such as the theory of real closed fields. This shows that the stability spectrum is a relatively blunt tool. To get somewhat finer results one can look at the exact cardinalities of the Stone spaces over models of size ≤&amp;nbsp;λ, rather than just asking whether they are at most&amp;nbsp;λ.

== The uncountable case ==
For a general stable theory ''T'' in a possibly uncountable language, the stability spectrum is determined by two cardinals κ and λ&lt;sub&gt;0&lt;/sub&gt;, such that ''T'' is stable in λ exactly when λ&amp;nbsp;≥&amp;nbsp;λ&lt;sub&gt;0&lt;/sub&gt; and λ&lt;sup&gt;μ&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;λ for all μ&lt;κ. So  λ&lt;sub&gt;0&lt;/sub&gt; is the smallest infinite cardinal for which ''T'' is stable. These invariants satisfy the inequalities
*κ&amp;nbsp;≤&amp;nbsp;|''T''|&lt;sup&gt;+&lt;/sup&gt;
*κ&amp;nbsp;≤&amp;nbsp;λ&lt;sub&gt;0&lt;/sub&gt;
*λ&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;≤&amp;nbsp;2&lt;sup&gt;|''T''|&lt;/sup&gt;
*If λ&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;&gt;&amp;nbsp;|''T''|, then λ&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;≥&amp;nbsp;2&lt;sup&gt;ω&lt;/sup&gt;

When |''T''| is countable the 4 possibilities for its stability spectrum correspond to the following values of these cardinals:
*κ and λ&lt;sub&gt;0&lt;/sub&gt; are not defined: ''T'' is unstable.
*λ&lt;sub&gt;0&lt;/sub&gt; is 2&lt;sup&gt;ω&lt;/sup&gt;, κ is ω&lt;sub&gt;1&lt;/sub&gt;: ''T'' is stable but not superstable
*λ&lt;sub&gt;0&lt;/sub&gt; is 2&lt;sup&gt;ω&lt;/sup&gt;, κ is ω: ''T'' is superstable but not ω-stable.
* λ&lt;sub&gt;0&lt;/sub&gt; is ω, κ is ω: ''T'' is totally transcendental (or ω-stable)

== See also ==
* [[Spectrum of a theory]]

==References==
*{{citation
|last=Poizat|first= Bruno
|title=A course in model theory. An introduction to contemporary mathematical logic|series= Universitext|publisher=[[Springer Science+Business Media|Springer]]|place= New York|year= 2000|pages=xxxii+443 |isbn= 0-387-98655-3
|mr=1757487 }} Translated from the French
*{{Citation | last1=Shelah | first1=Saharon | author1-link=Saharon Shelah | title=Classification theory and the number of nonisomorphic models | origyear=1978 | publisher=Elsevier | edition=2nd | series=Studies in Logic and the Foundations of Mathematics | isbn=978-0-444-70260-9 | year=1990}}

[[Category:Model theory]]</text>
      <sha1>hxfryw6z4z1w64nms2vzqjspipzdj6l</sha1>
    </revision>
  </page>
  <page>
    <title>Stone's representation theorem for Boolean algebras</title>
    <ns>0</ns>
    <id>604111</id>
    <revision>
      <id>858719525</id>
      <parentid>814898075</parentid>
      <timestamp>2018-09-09T04:46:32Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4588">{{no footnotes|date=June 2015}}
In [[mathematics]], '''Stone's representation theorem for Boolean algebras''' states that every [[Boolean algebra (structure)|Boolean algebra]] is [[isomorphic]] to a certain [[field of sets]]. The theorem is fundamental to the deeper understanding of [[Boolean logic|Boolean algebra]] that emerged in the first half of the 20th century. The theorem was first proved by [[Marshall H. Stone]] (1936). Stone was led to it by his study of the [[spectral theory]] of [[linear operator|operators]] on a [[Hilbert space]].

==Stone spaces==
Each [[Boolean algebra (structure)|Boolean algebra]] ''B'' has an associated topological space, denoted here ''S''(''B''), called its [[Stone space|'''Stone space'''.]] The points in ''S''(''B'') are the [[ultrafilter]]s on ''B'', or equivalently the homomorphisms from ''B'' to the [[two-element Boolean algebra]]. The topology on ''S''(''B'') is generated by a (closed) [[basis (topology)|basis]] consisting of all sets of the form
:&lt;math&gt;\{ x \in S(B) \mid b \in x\},&lt;/math&gt;
where ''b'' is an element of ''B''. This is the topology of pointwise convergence of nets of homomorphisms into the two-element Boolean algebra.

For every Boolean algebra ''B'', ''S''(''B'') is a [[compact space|compact]] [[totally disconnected]] [[Hausdorff space|Hausdorff]] space; such spaces are called '''Stone spaces''' (also ''profinite spaces''). Conversely, given any topological space ''X'', the collection of subsets of ''X'' that are [[clopen set|clopen]] (both closed and open) is a Boolean algebra.

==Representation theorem==

A simple version of '''Stone's representation theorem''' states that every Boolean algebra ''B'' is isomorphic to the algebra of clopen subsets of its Stone space ''S''(''B''). The isomorphism sends an element ''b''&amp;isin;''B'' to the set of all ultrafilters that contain ''b''. This is a clopen set because of the choice of topology on ''S''(''B'') and because ''B'' is a Boolean algebra. 

Restating the theorem using the language of [[category theory]]; the theorem states that there is a [[duality of categories|duality]] between the [[category theory|category]] of [[Boolean algebra (structure)|Boolean algebra]]s  and the category of Stone spaces. This duality means that in addition to the correspondence between Boolean algebras and their Stone spaces, each homomorphism from a Boolean algebra ''A'' to a Boolean algebra ''B'' corresponds in a natural way to a continuous function from ''S''(''B'') to  ''S''(''A''). In other words, there is a [[contravariant functor]] that gives an [[equivalence (category theory)|equivalence]] between the categories. This was an early example of a nontrivial duality of categories.

The theorem is a special case of [[Stone duality]], a more general framework for dualities between [[topological space]]s and [[partially ordered set]]s.

The proof requires either the [[axiom of choice]] or a weakened form of it. Specifically, the theorem is equivalent to the [[Boolean prime ideal theorem]], a weakened choice principle that states that every Boolean algebra has a prime ideal.

An extension of the classical Stone duality to the category of Boolean spaces (= zero-dimensional locally compact Hausdorff spaces) and continuous maps (respectively, perfect maps) was obtained by G. D. Dimov (respectively, by H. P. Doctor) (see the references below).

==See also==
* [[Field of sets]]
* [[List of Boolean algebra topics]]
* [[Stonean space]]
* [[Stone functor]]
* [[Profinite group]]
* [[Representation theorem]]

==References==
* [[Paul Halmos]], and Givant, Steven (1998) ''Logic as Algebra''. Dolciani Mathematical Expositions No. 21. [[The Mathematical Association of America]].
* [[Peter T. Johnstone|Johnstone, Peter T.]] (1982) ''Stone Spaces''. Cambridge University Press. {{isbn|0-521-23893-5}}.
* [[Marshall H. Stone]] (1936) "[https://www.jstor.org/stable/1989664 The Theory of Representations of Boolean Algebras,]" ''Transactions of the American Mathematical Society 40'': 37-111. 
* G. D. Dimov (2012) ''Some generalizations of the Stone Duality Theorem''. ''Publ. Math. Debrecen 80'': 255–293.
* H. P. Doctor (1964) ''The categories of Boolean lattices, Boolean rings and Boolean spaces''. ''Canad. Math. Bulletin 7'': 245–252.
* Burris, Stanley N., and H. P. Sankappanavar, H. P.(1981) ''[http://www.thoralf.uwaterloo.ca/htdocs/ualg.html A Course in Universal Algebra.]''  Springer-Verlag. {{isbn|3-540-90578-2}}.

[[Category:General topology]]
[[Category:Boolean algebra]]
[[Category:Theorems in algebra]]
[[Category:Categorical logic]]</text>
      <sha1>ae6d7qb14e0ow945191u59ycn434im9</sha1>
    </revision>
  </page>
  <page>
    <title>Summation by parts</title>
    <ns>0</ns>
    <id>246188</id>
    <revision>
      <id>866519791</id>
      <parentid>862572140</parentid>
      <timestamp>2018-10-30T20:55:59Z</timestamp>
      <contributor>
        <ip>174.34.207.104</ip>
      </contributor>
      <comment>/* Applications */ added ref to Dirichlet's test, named theorem in third bullet Abel's test and cleaned up mistakes in proof, cleaned up statement of final bullet.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6416">{{Redirect|Abel transformation|another transformation|Abel transform}}

In [[mathematics]], '''summation by parts''' transforms the [[summation]] of products of [[sequences]] into other summations, often simplifying the computation or (especially) estimation of certain types of sums. The summation by parts formula is sometimes called '''[[Niels Henrik Abel|Abel's]] lemma''' or '''Abel transformation'''.

==Statement==
Suppose &lt;math&gt;\{f_k\}&lt;/math&gt; and &lt;math&gt;\{g_k\}&lt;/math&gt; are two [[sequence]]s. Then,
:&lt;math&gt;\sum_{k=m}^n f_k(g_{k+1}-g_k) = \left[f_{n}g_{n+1} - f_m g_m\right] - \sum_{k=m+1}^n g_{k}(f_{k}- f_{k-1}).&lt;/math&gt;

Using the [[forward difference operator]] &lt;math&gt;\Delta&lt;/math&gt;, it can be stated more succinctly as

:&lt;math&gt;\sum_{k=m}^n f_k\Delta g_k = \left[f_{n} g_{n+1} - f_m g_m\right] - \sum_{k=m}^{n-1} g_{k+1}\Delta f_k,&lt;/math&gt;

Note that summation by parts is an analogue to the [[integration by parts]] formula,
:&lt;math&gt;\int f\,dg = f g - \int g\,df.&lt;/math&gt;

An alternative statement is
:&lt;math&gt;f_n g_n - f_m g_m = \sum_{k=m}^{n-1} f_k\Delta g_k + \sum_{k=m}^{n-1} g_k\Delta f_k + \sum_{k=m}^{n-1} \Delta f_k \Delta g_k&lt;/math&gt;
which is analogous to the [[Quadratic variation#Semimartingales|integration by parts formula for semimartingales]].

Note also that although applications almost always deal with convergence of sequences, the statement is purely algebraic and will work in any [[Field (mathematics)|field]].  It will also work when one sequence is in a [[vector space]], and the other is in the relevant field of scalars.

==Newton series==
The formula is sometimes given in one of these - slightly different - forms

:&lt;math&gt;\begin{align}
\sum_{k=0}^n f_k g_k &amp;= f_0 \sum_{k=0}^n g_k+ \sum_{j=0}^{n-1} (f_{j+1}-f_j) \sum_{k=j+1}^n g_k\\
&amp;= f_n \sum_{k=0}^n g_k - \sum_{j=0}^{n-1} \left( f_{j+1}- f_j\right) \sum_{k=0}^j g_k, 
\end{align}&lt;/math&gt;

which represent a special case (&lt;math&gt;M=1&lt;/math&gt;) of the more general rule

:&lt;math&gt;\begin{align}\sum_{k=0}^n f_k g_k &amp;= \sum_{i=0}^{M-1} f_0^{(i)} G_{i}^{(i+1)}+ \sum_{j=0}^{n-M} f^{(M)}_{j} G_{j+M}^{(M)}=\\
&amp;= \sum_{i=0}^{M-1} \left( -1 \right)^i f_{n-i}^{(i)} \tilde{G}_{n-i}^{(i+1)}+ \left( -1 \right) ^{M} \sum_{j=0}^{n-M} f_j^{(M)} \tilde{G}_j^{(M)};\end{align}&lt;/math&gt;

both result from iterated application of the initial formula. The auxiliary quantities are [[Newton series]]:

:&lt;math&gt;f_j^{(M)}:= \sum_{k=0}^M \left(-1 \right)^{M-k} {M \choose k} f_{j+k}&lt;/math&gt;
and 
:&lt;math&gt;G_j^{(M)}:= \sum_{k=j}^n {k-j+M-1 \choose M-1} g_k,&lt;/math&gt;
:&lt;math&gt;\tilde{G}_j^{(M)}:= \sum_{k=0}^j {j-k+M-1 \choose M-1} g_k.&lt;/math&gt;

A remarkable, particular (&lt;math&gt;M=n+1&lt;/math&gt;) result is the noteworthy identity
:&lt;math&gt;\sum_{k=0}^n f_k g_k = \sum_{i=0}^n f_0^{(i)} G_i^{(i+1)} = \sum_{i=0}^n (-1)^i f_{n-i}^{(i)} \tilde{G}_{n-i}^{(i+1)}.&lt;/math&gt;

Here, &lt;math&gt;{n \choose k}&lt;/math&gt; is the [[binomial coefficient]].

==Method==

For two given sequences &lt;math&gt;(a_n) &lt;/math&gt; and &lt;math&gt;(b_n) &lt;/math&gt;, with &lt;math&gt;n \in \N&lt;/math&gt;, one wants to study the sum of the following series:&lt;br&gt;
&lt;math&gt;S_N = \sum_{n=0}^N a_n b_n&lt;/math&gt;

If we define &lt;math&gt;B_n = \sum_{k=0}^n b_k,&lt;/math&gt;&amp;nbsp;
then for every &lt;math&gt;n&gt;0, &lt;/math&gt;&amp;nbsp; &lt;math&gt;b_n = B_n - B_{n-1} &lt;/math&gt;&amp;nbsp; and

:&lt;math&gt;S_N = a_0 b_0 + \sum_{n=1}^N a_n (B_n - B_{n-1}),&lt;/math&gt;

:&lt;math&gt;S_N = a_0 b_0 - a_0 B_0 + a_N B_N + \sum_{n=0}^{N-1} B_n (a_n - a_{n+1}).&lt;/math&gt;

Finally&amp;nbsp; &lt;math&gt;S_N = a_N B_N - \sum_{n=0}^{N-1} B_n (a_{n+1} - a_n).&lt;/math&gt;

This process, called an Abel transformation, can be used to prove several criteria of convergence for &lt;math&gt;S_N &lt;/math&gt; .

==Similarity with an integration by parts==

The formula for an integration by parts is &lt;math&gt;\int_a^b f(x) g'(x)\,dx = \left[ f(x) g(x) \right]_{a}^{b} - \int_a^b  f'(x) g(x)\,dx&lt;/math&gt;&lt;br&gt;
Beside the [[boundary conditions]], we notice that the first integral contains two multiplied functions, one which is integrated in the final integral ( &lt;math&gt;g' &lt;/math&gt; becomes &lt;math&gt;g &lt;/math&gt; ) and one which is differentiated ( &lt;math&gt;f &lt;/math&gt; becomes &lt;math&gt;f' &lt;/math&gt; ).

The process of the ''Abel transformation'' is similar, since one of the two initial sequences is summed ( &lt;math&gt;b_n &lt;/math&gt; becomes &lt;math&gt;B_n &lt;/math&gt; ) and the other one is differenced ( &lt;math&gt;a_n &lt;/math&gt; becomes &lt;math&gt;a_{n+1} - a_n &lt;/math&gt; ).

==Applications==

* It is used to prove [[Kronecker's lemma]], which in turn, is used to prove a version of the strong [[law of large numbers]] under [[variance]] constraints.
* Summation by parts is frequently used to prove [[Abel's theorem]] and [[Dirichlet's test]].
* One can also use this technique to prove [[Abel's test]]:  If &lt;math&gt;\sum b_n&lt;/math&gt; is a [[convergent series]], and &lt;math&gt;a_n&lt;/math&gt; a bounded [[monotone sequence]], then &lt;math&gt;S_N = \sum_{n=0}^N a_n b_n&lt;/math&gt; converges.

Summation by parts gives
:&lt;math&gt;\begin{align}S_M - S_N &amp;= a_M B_M - a_N B_N - \sum_{n=N}^{M-1} B_n (a_{n+1} - a_n)\\&amp;= (a_M-a) B_M - (a_N-a) B_N + a(B_M - B_N) - \sum_{n=N}^{M-1} B_n (a_{n+1} - a_n),\end{align}&lt;/math&gt;
where ''a'' is the limit of &lt;math&gt;a_n&lt;/math&gt;. As &lt;math&gt;\sum b_n&lt;/math&gt; is convergent, &lt;math&gt;B_N&lt;/math&gt; is bounded independently of &lt;math&gt;N&lt;/math&gt;, say by &lt;math&gt;B&lt;/math&gt;. As &lt;math&gt;a_n-a&lt;/math&gt; go to zero, so go the first two terms. The third term goes to zero by the [[Cauchy criterion]] for &lt;math&gt;\sum b_n&lt;/math&gt;. The remaining sum is bounded by

: &lt;math&gt;\sum_{n=N}^{M-1} |B_n| |a_{n+1}-a_n| \le B \sum_{n=N}^{M-1} |a_{n+1}-a_n| = B|a_N - a_M|&lt;/math&gt;

by the monotonicity of &lt;math&gt;a_n&lt;/math&gt;, and also goes to zero as &lt;math&gt;N \to \infty&lt;/math&gt;.

* Using the same proof as above, one can show that if
# the partial sums &lt;math&gt;B_N&lt;/math&gt; form a [[bounded sequence]] independently of &lt;math&gt;N&lt;/math&gt; ;
# &lt;math&gt;\sum_{n=0}^\infty |a_{n+1} - a_n| &lt; \infty&lt;/math&gt; (so that the sum &lt;math&gt;\sum_{n=N}^{M-1} |a_{n+1}-a_n|&lt;/math&gt; goes to zero as &lt;math&gt;N&lt;/math&gt; goes to infinity) 
# &lt;math&gt;\lim a_n = 0&lt;/math&gt;
then &lt;math&gt;S_N = \sum_{n=0}^N a_n b_n&lt;/math&gt; converges.

In both cases, the sum of the series satisfies:
&lt;math&gt; |S| = \left|\sum_{n=0}^\infty a_n b_n \right| \le B \sum_{n=0}^\infty |a_{n+1}-a_n|.&lt;/math&gt;

==See also==
*[[Convergent series]]
*[[Divergent series]]
*[[Integration by parts]]
*[[Cesàro summation]]
*[[Abel's theorem]]
*[[Abel's summation formula|Abel sum formula]]

==References==
*{{planetmathref|id=3843|title=Abel's lemma}}

[[Category:Summability methods]]
[[Category:Real analysis]]
[[Category:Lemmas]]</text>
      <sha1>lpzhililf6nxjmqo9puyy5xjdiopof0</sha1>
    </revision>
  </page>
  <page>
    <title>Universe (mathematics)</title>
    <ns>0</ns>
    <id>296838</id>
    <revision>
      <id>869898085</id>
      <parentid>852963564</parentid>
      <timestamp>2018-11-21T02:43:57Z</timestamp>
      <contributor>
        <username>Volunteer1234</username>
        <id>30845620</id>
      </contributor>
      <comment>/* In ordinary mathematics */ [[wp:noted]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16539">[[File:Probability_venn_event.svg|link=https://zh.wikipedia.org/wiki/File:Probability_venn_event.svg|thumb|320x320px|The relationship between universe and complement.]]
{{bots|deny=AWB}}
In [[mathematics]], and particularly in [[set theory]], [[category theory]], [[type theory]], and the [[foundations of mathematics]], a '''universe''' is a collection that contains all the entities one wishes to consider in a given situation. It is closely related to the concept of a [[domain of discourse]] in [[philosophy]]. 

In set theory, universes are often [[class (set theory)|classes]] that contain (as [[element (set theory)|elements]]) all sets for which one hopes to [[Mathematical proof|prove]] a particular [[theorem]]. These classes can serve as [[Inner model|inner models]] for various axiomatic systems such as [[Zermelo–Fraenkel set theory|ZFC]] or [[Morse–Kelley set theory]]. Universes are of critical importance to formalizing concepts in [[category theory]] inside set-theoretical foundations. For instance, the [[List of mathematical jargon#canonical|canonical]] motivating example of a category is '''[[Category of sets|Set]]''', the category of all sets, which cannot be formalized in a set theory without some notion of a universe.

In type theory, a universe is a type whose elements are types.

==In a specific context==
{{Main|Domain of discourse}}
Perhaps the simplest version is that ''any'' set can be a universe, so long as the object of study is confined to that particular set. If the object of study is formed by the [[real number]]s, then the [[real line]] '''R''', which is the real number set, could be the universe under consideration. Implicitly, this is the universe that [[Georg Cantor]] was using when he first developed modern [[naive set theory]] and [[cardinality]] in the 1870s and 1880s in applications to [[real analysis]]. The only sets that Cantor was originally interested in were [[subset]]s of '''R'''.

This concept of a universe is reflected in the use of [[Venn diagram]]s. In a Venn diagram, the action traditionally takes place inside a large rectangle that represents the universe ''U''. One generally says that sets are represented by circles; but these sets can only be subsets of ''U''. The [[complement (set theory)|complement]] of a set ''A'' is then given by that portion of the rectangle outside of ''A'''s circle. Strictly speaking, this is the [[complement (set theory)|relative complement]] ''U'' \ ''A'' of ''A'' relative to ''U''; but in a context where ''U'' is the universe, it can be regarded as the [[complement (set theory)|absolute complement]] ''A''&lt;sup&gt;C&lt;/sup&gt; of ''A''. Similarly, there is a notion of the [[nullary intersection]], that is the [[intersection (set theory)|intersection]] of [[0 (number)|zero]] sets (meaning no sets, not [[null set]]s).

Without a universe, the nullary intersection would be the set of absolutely everything, which is generally regarded as impossible; but with the universe in mind, the nullary intersection can be treated as the set of everything under consideration, which is simply ''U''. These conventions are quite useful in the algebraic approach to basic set theory, based on [[Boolean lattice]]s. Except in some non-standard forms of [[axiomatic set theory]] (such as [[New Foundations]]), the [[class (set theory)|class]] of all sets is not a Boolean lattice (it is only a [[relatively complemented lattice]]).

In contrast, the class of all subsets of ''U'', called the [[power set]] of ''U'', is a Boolean lattice. The absolute complement described above is the complement operation in the Boolean lattice; and ''U'', as the nullary intersection, serves as the [[Greatest element|top element]] (or nullary [[meet (mathematics)|meet]]) in the Boolean lattice. Then [[De Morgan's laws]], which deal with complements of meets and [[join (mathematics)|join]]s (which are [[union (set theory)|union]]s in set theory) apply, and apply even to the nullary meet and the nullary join (which is the [[empty set]]).

==In ordinary mathematics==
However, once subsets of a given set ''X'' (in Cantor's case, ''X'' = '''R''') are considered, the universe may need to be a set of subsets of ''X''. (For example, a [[topological space|topology]] on ''X'' is a set of subsets of ''X''.) The various sets of subsets of ''X'' will not themselves be subsets of ''X'' but will instead be subsets of '''P'''''X'', the [[power set|power set]] of ''X''. This may be continued; the object of study may next consist of such sets of subsets of ''X'', and so on, in which case the universe will be '''P'''('''P'''''X''). In another direction, the [[binary relation]]s on ''X'' (subsets of the [[Cartesian product]] {{Nowrap|''X'' × ''X'')}} may be considered, or [[function (mathematics)|function]]s from ''X'' to itself, requiring universes like {{Nowrap|'''P'''(''X'' × ''X'')}} or ''X''&lt;sup&gt;''X''&lt;/sup&gt;.

Thus, even if the primary interest is ''X'', the universe may need to be considerably larger than ''X''. Following the above ideas, one may want the '''superstructure''' over ''X'' as the universe. This can be defined by [[structural recursion]] as follows:
* Let '''S'''&lt;sub&gt;0&lt;/sub&gt;''X'' be ''X'' itself.
* Let '''S'''&lt;sub&gt;1&lt;/sub&gt;''X'' be the [[union (set theory)|union]] of ''X'' and '''P'''''X''.
* Let '''S'''&lt;sub&gt;2&lt;/sub&gt;''X'' be the union of '''S'''&lt;sub&gt;1&lt;/sub&gt;''X'' and '''P'''('''S'''&lt;sub&gt;1&lt;/sub&gt;''X'').
* In general, let '''S'''&lt;sub&gt;''n''+1&lt;/sub&gt;''X'' be the union of '''S'''&lt;sub&gt;n&lt;/sub&gt;''X'' and '''P'''('''S'''&lt;sub&gt;''n''&lt;/sub&gt;''X'').
Then the superstructure over ''X'', written '''S'''''X'', is the union of '''S'''&lt;sub&gt;0&lt;/sub&gt;''X'', '''S'''&lt;sub&gt;1&lt;/sub&gt;''X'', '''S'''&lt;sub&gt;2&lt;/sub&gt;''X'', and so on; or
: &lt;math&gt; \mathbf{S}X := \bigcup_{i=0}^{\infty} \mathbf{S}_{i}X \mbox{.} \! &lt;/math&gt;

No matter what set ''X'' is the starting point, the [[empty set]] {} will belong to '''S'''&lt;sub&gt;1&lt;/sub&gt;''X''. The empty set is the [[von Neumann ordinal]] [0].
Then {[0]}, the set whose only element is the empty set, will belong to '''S'''&lt;sub&gt;2&lt;/sub&gt;''X''; this is the von Neumann ordinal [1]. Similarly, {[1]} will belong to '''S'''&lt;sub&gt;3&lt;/sub&gt;''X'', and thus so will {[0],[1]}, as the union of {[0]} and {[1]}; this is the von Neumann ordinal [2]. Continuing this process, every [[natural number]] is represented in the superstructure by its von Neumann ordinal. Next, if ''x'' and ''y'' belong to the superstructure, then so does {{''x''},{''x'',''y''}}, which represents the [[ordered pair]] (''x'',''y''). Thus the superstructure will contain the various desired Cartesian products. Then the superstructure also contains [[function (mathematics)|function]]s and [[relation (mathematics)|relation]]s, since these may be represented as subsets of Cartesian products. The process also gives ordered ''n''-tuples, represented as functions whose domain is the von Neumann ordinal [''n''], and so on.

So if the starting point is just ''X'' = {}, a great deal of the sets needed for mathematics appear as elements of the superstructure over {}. But each of the elements of '''S'''{} will be a [[finite set]]. Each of the natural numbers belongs to it, but the set '''N''' of ''all'' natural numbers does not (although it is a ''subset'' of '''S'''{}). In fact, the superstructure over {} consists of all of the [[hereditarily finite set]]s. As such, it can be considered the ''universe of [[finitist mathematics]]''. Speaking anachronistically, one could suggest that the 19th-century finitist [[Leopold Kronecker]] was working in this universe; he believed that each natural number existed but that the set '''N''' (a "[[completed infinity]]") did not.

However, '''S'''{} is unsatisfactory for ordinary mathematicians (who are not finitists), because even though '''N''' may be available as a subset of '''S'''{}, still the power set of '''N''' is not. In particular, arbitrary sets of real numbers are not available. So it may be necessary to start the process all over again and form '''S'''('''S'''{}). However, to keep things simple, one can take the set '''N''' of natural numbers as given and form '''SN''', the superstructure over '''N'''. This is often considered the ''universe of [[ordinary mathematics]]''. The idea is that all of the mathematics that is ordinarily studied refers to elements of this universe. For example, any of the usual [[constructions of the real numbers]] (say by [[Dedekind cut]]s) belongs to '''SN'''. Even [[non-standard analysis]] can be done in the superstructure over a [[non-standard model]] of the natural numbers.

There is a slight shift in philosophy from the previous section, where the universe was any set ''U'' of interest. There, the sets being studied were ''subset''s of the universe; now, they are ''members'' of the universe. Thus although '''P'''('''S'''''X'') is a Boolean lattice, what is relevant is that '''S'''''X'' itself is not. Consequently, it is rare to apply the notions of Boolean lattices and Venn diagrams directly to the superstructure universe as they were to the power-set universes of the previous section. Instead, one can work with the individual Boolean lattices '''P'''''A'', where ''A'' is any relevant set belonging to '''S'''''X''; then '''P'''''A'' is a subset of '''S'''''X'' (and in fact belongs to '''S'''''X''). In Cantor's case ''X'' = '''R''' in particular, arbitrary sets of real numbers are not available, so there it may indeed be necessary to start the process all over again.

==In set theory==
It is possible to give a precise meaning to the claim that '''SN''' is the universe of ordinary mathematics; it is a [[model theory|model]] of [[Zermelo set theory]], the [[axiomatic set theory]] originally developed by [[Ernst Zermelo]] in 1908. Zermelo set theory was successful precisely because it was capable of axiomatising "ordinary" mathematics, fulfilling the programme begun by Cantor over 30 years earlier. But Zermelo set theory proved insufficient for the further development of axiomatic set theory and other work in the [[foundations of mathematics]], especially [[model theory]].

For a dramatic example, the description of the superstructure process above cannot itself be carried out in Zermelo set theory. The final step, forming '''S''' as an infinitary union, requires the [[axiom of replacement]], which was added to Zermelo set theory in 1922 to form [[Zermelo–Fraenkel set theory]], the set of axioms most widely accepted today. So while ordinary mathematics may be done ''in'' '''SN''', discussion ''of'' '''SN''' goes beyond the "ordinary", into [[metamathematics]].

But if high-powered set theory is brought in, the superstructure process above reveals itself to be merely the beginning of a [[transfinite recursion]].
Going back to ''X'' = {}, the empty set, and introducing the (standard) notation ''V''&lt;sub&gt;''i''&lt;/sub&gt; for '''S'''&lt;sub&gt;''i''&lt;/sub&gt;{}, ''V''&lt;sub&gt;0&lt;/sub&gt; = {}, ''V''&lt;sub&gt;1&lt;/sub&gt; = '''P'''{}, and so on as before. But what used to be called "superstructure" is now just the next item on the list: ''V''&lt;sub&gt;ω&lt;/sub&gt;, where ω is the first [[Infinity|infinite]] [[ordinal number]]. This can be extended to arbitrary [[ordinal number]]s:
: &lt;math&gt; V_{i} := \bigcup_{j&lt;i} \mathbf{P}V_j \! &lt;/math&gt;
defines ''V''&lt;sub&gt;''i''&lt;/sub&gt; for ''any'' ordinal number ''i''.
The union of all of the ''V''&lt;sub&gt;''i''&lt;/sub&gt; is the [[von Neumann universe]] ''V'':
: &lt;math&gt; V := \bigcup_{i} V_{i} \! &lt;/math&gt;.
Every individual ''V''&lt;sub&gt;''i''&lt;/sub&gt; is a set, but their union ''V'' is a [[proper class]]. The [[axiom of foundation]], which was added to [[Zermelo–Fraenkel set theory|ZF]] set theory at around the same time as the axiom of replacement, says that ''every'' set belongs to ''V''.

: ''[[Kurt Gödel]]'s [[constructible universe]] ''L'' and the [[axiom of constructibility]]''
: ''[[Inaccessible cardinal]]s yield models of ZF and sometimes additional axioms, and are equivalent to the existence of the [[Grothendieck universe]] set''

==In category theory==
{{Main|Grothendieck universe}}
There is another approach to universes which is historically connected with [[category theory]].  This is the idea of a [[Grothendieck universe]].  Roughly speaking, a Grothendieck universe is a set inside which all the usual operations of set theory can be performed.  This version of a universe is defined to be any set for which the following axioms hold:&lt;ref&gt;Mac Lane 1998, p. 22&lt;/ref&gt;
# &lt;math&gt;x\in u\in U&lt;/math&gt; implies &lt;math&gt;x\in U&lt;/math&gt;
# &lt;math&gt;u\in U&lt;/math&gt; and &lt;math&gt;v\in U&lt;/math&gt; imply {''u'',''v''}, (''u'',''v''), and &lt;math&gt;u\times v\in U&lt;/math&gt;.
# &lt;math&gt;x\in U&lt;/math&gt; implies &lt;math&gt;\mathcal{P}x\in U&lt;/math&gt; and &lt;math&gt;\cup x\in U&lt;/math&gt;
# &lt;math&gt;\omega\in U&lt;/math&gt; (here &lt;math&gt;\omega=\{0,1,2,...\}&lt;/math&gt; is the set of all [[Ordinal number|finite ordinals]].)
# if &lt;math&gt;f:a\to b&lt;/math&gt; is a surjective function with &lt;math&gt; a\in U&lt;/math&gt; and &lt;math&gt;b\subset U&lt;/math&gt;, then &lt;math&gt;b\in U&lt;/math&gt;.

The advantage of a Grothendieck universe is that it is actually a ''set'', and never a proper class.  The disadvantage is that if one tries hard enough, one can leave a Grothendieck universe.{{citation needed|date=December 2013}}

The most common use of a Grothendieck universe ''U'' is to take ''U'' as a replacement for the category of all sets.  One says that a set ''S'' is '''''U'''''-'''small''' if ''S'' ∈''U'', and '''''U'''''-'''large''' otherwise.  The category ''U''-'''Set''' of all ''U''-small sets has as objects all ''U''-small sets and as morphisms all functions between these sets.  Both the object set and the morphism set are sets, so it becomes possible to discuss the category of "all" sets without invoking proper classes.  Then it becomes possible to define other categories in terms of this new category.  For example, the category of all ''U''-small categories is the category of all categories whose object set and whose morphism set are in ''U''.  Then the usual arguments of set theory are applicable to the category of all categories, and one does not have to worry about accidentally talking about proper classes.  Because Grothendieck universes are extremely large, this suffices in almost all applications.

Often when working with Grothendieck universes, mathematicians assume the [[Tarski–Grothendieck set theory|Axiom of Universes]]: "For any set ''x'', there exists a universe ''U'' such that ''x'' ∈''U''."  The point of this axiom is that any set one encounters is then ''U''-small for some ''U'', so any argument done in a general Grothendieck universe can be applied.  This axiom is closely related to the existence of [[Inaccessible cardinal|strongly inaccessible cardinal]]s.

==In type theory&lt;!--'Russell-style universe', 'Russell-style universes', 'Tarski-style universe', and 'Tarski-style universes' redirect here--&gt;==
In some type theories, especially in systems with [[Dependent type|dependent types]], types themselves can be regarded as [[Term (logic)|terms]]. There is a type called the universe (often denoted &lt;math&gt;\mathcal{U}&lt;/math&gt;) which has types as its elements. To avoid paradoxes such as [[System U#Girard's paradox|Girard's paradox]] (an analogue of [[Russell's paradox]] for type theory), type theories are often equipped with a [[Countable set|countably infinite]] hierarchy of such universes, with each universe being a term of the next one. 

There are at least two kinds of universes that one can consider in type theory: '''Russell-style universes''' (named after [[Bertrand Russell]]) and '''Tarski-style universes''' (named after [[Alfred Tarski]]).&lt;ref name=nLab&gt;[https://ncatlab.org/homotopytypetheory/show/universe "Universe in Homotopy Type Theory"] in [[nLab]]&lt;/ref&gt;&lt;ref&gt;Zhaohui Luo, [http://www.cs.rhul.ac.uk/home/zhaohui/universes.pdf "Notes on Universes in Type Theory"], 2012.&lt;/ref&gt;&lt;ref&gt;[[Per Martin-Löf]], ''Intuitionistic Type Theory'', Bibliopolis, 1984, pp. 88 and 91.&lt;/ref&gt; A Russell-style universe is a type whose terms are types.&lt;ref name=nLab/&gt; A Tarski-style universe is a type together with an interpretation operation allowing us to regard its terms as types.&lt;ref name=nLab/&gt;

==See also==
* [[Domain of discourse]]
* [[Grothendieck universe]]
* [[Herbrand universe]]
* [[Free object]]

==Notes==
{{reflist}}

==References==
*Mac Lane, Saunders (1998). ''Categories for the Working Mathematician''. Springer-Verlag New York, Inc.

==External links==
* {{springer|title=Universe|id=p/u095770}}
* {{MathWorld |title=Universal Set|id=UniversalSet}}

[[Category:Mathematical logic]]
[[Category:Set families]]
[[Category:Set theory]]</text>
      <sha1>n34gu22wd3t9sqika18m9efpw07aomb</sha1>
    </revision>
  </page>
  <page>
    <title>Viviane Baladi</title>
    <ns>0</ns>
    <id>48221297</id>
    <revision>
      <id>842719445</id>
      <parentid>806072314</parentid>
      <timestamp>2018-05-24T06:56:27Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* top */ Dynamical Zeta Functions and Dynamical Determinants for Hyperbolic Maps: A Functional Approach (too new even for MR to mention)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3567">{{Infobox scientist
| name              = Viviane Baladi
| image             = Baladi viviane.jpg
| image_size        = 
| image_upright     = 
| alt               = 
| caption           = Viviane Baladi at [[Oberwolfach]] in 2009
| birth_date        = {{birth date and age |1963|5|23|mf=y}}
| birth_place       = [[Switzerland]]
| death_date        = &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place       = 
| nationality       = [[Switzerland|Swiss]]
| fields            = [[Mathematics]]
| workplaces        = 
| alma_mater        = [[University of Geneva]]
| thesis_title      = &lt;!--(or  | thesis1_title =  and  | thesis2_title = )--&gt;
| thesis_url        = &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year       = &lt;!--(or  | thesis1_year =   and  | thesis2_year =  )--&gt;
| doctoral_advisor  = [[Jean-Pierre Eckmann]]
| doctoral_students = 
| known_for         = 
| awards            = 
}}

'''Viviane Baladi''' (born May 23, 1963) is a mathematician who works as a director of research at the [[Centre national de la recherche scientifique]] (CNRS) in France. Originally Swiss, she has become a naturalized citizen of France.&lt;ref name="cv"&gt;{{citation|url=http://webusers.imj-prg.fr/~viviane.baladi/cv.html|title=Curriculum vitae: Viviane Baladi|publisher=[[Centre national de la recherche scientifique]]|accessdate=2015-10-14}}.&lt;/ref&gt; Her research concerns [[dynamical system]]s.

Baladi earned master's degrees in mathematics and computer science in 1986 from the [[University of Geneva]].&lt;ref name="cv"/&gt; She stayed in Geneva for her doctoral studies, finishing a Ph.D. in 1989 under the supervision of [[Jean-Pierre Eckmann]], with a dissertation concerning the [[Artin–Mazur zeta function|zeta functions of dynamical systems]].&lt;ref&gt;{{mathgenealogy|id=48860}}.&lt;/ref&gt; She worked at CNRS beginning in 1990, with a leave of absence from 1993 to 1999 when she taught at [[ETH Zurich]] and the University of Geneva. She also spent a year as a professor at the [[University of Copenhagen]] in 2012–2013.&lt;ref name="cv"/&gt;

She is the author of the book ''Positive Transfer Operators and Decay of Correlation'' (Advanced Series in Nonlinear Dynamics 16, World Scientific, 2000)&lt;ref&gt;Review of ''Positive Transfer Operators and Decay of Correlation'' by Jérôme Buzzi (2001), {{MR|1793194}}.&lt;/ref&gt; and of ''Dynamical Zeta Functions and Dynamical Determinants for Hyperbolic Maps: A Functional Approach'' ([[Ergebnisse der Mathematik und ihrer Grenzgebiete]] 68, Springer, 2018).

She was an [[list of International Congresses of Mathematicians Plenary and Invited Speakers|invited speaker at the International Congress of Mathematicians]] in 2014, speaking in the section on "Dynamical Systems and Ordinary Differential Equations".&lt;ref&gt;{{citation|url=http://www.mathunion.org/db/ICM/Speakers/SortedByLastname.php|title=ICM Plenary and Invited Speakers since 1897|publisher=[[International Mathematical Union]]|accessdate=2015-10-01}}.&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*[http://webusers.imj-prg.fr/~viviane.baladi/ Home page]
*[https://scholar.google.com/citations?user=Xv9SS1sAAAAJ Google scholar profile]

{{Authority control}}
{{DEFAULTSORT:Baladi, Viviane}}
[[Category:1963 births]]
[[Category:Living people]]
[[Category:French mathematicians]]
[[Category:Swiss mathematicians]]
[[Category:Women mathematicians]]
[[Category:University of Geneva alumni]]
[[Category:University of Geneva faculty]]
[[Category:ETH Zurich faculty]]
[[Category:University of Copenhagen faculty]]</text>
      <sha1>a4bjobgl4ba7zmpd5mzrn1hbffrmfdp</sha1>
    </revision>
  </page>
  <page>
    <title>Vladimir Voevodsky</title>
    <ns>0</ns>
    <id>104482</id>
    <revision>
      <id>867537606</id>
      <parentid>864021345</parentid>
      <timestamp>2018-11-06T10:30:01Z</timestamp>
      <contributor>
        <username>RobertFurber</username>
        <id>34801684</id>
      </contributor>
      <comment>This is a better IPA transcription (though I am fighting somewhat with the IPA for English that won't let me use a j). The oe is pronounced similarly to the way it is in Dostoevsky.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8933">{{Infobox scientist
| name              = Vladimir Voevodsky
| image             = VladimirVoevodsky.jpg
| image_size        = 
| caption           = Voevodsky in 2011
|birth_name=Vladimir Alexandrovich Voevodsky
| birth_date        = {{birth date|1966|06|04|df=y}}
| birth_place       = [[Moscow]], [[Soviet Union]]
| death_date        = {{nowrap|{{death date and age|2017|09|30|1966|06|04|df=y}}}}
| death_place       =[[Princeton, New Jersey]], United States
| nationality       = [[Russia]]n, [[America]]n
| fields            = [[Mathematics]]
| workplaces        = [[Institute for Advanced Study]]
| alma_mater        = [[Moscow State University]]&lt;br/&gt;[[Harvard University]]
| doctoral_advisor  = [[David Kazhdan]]
| doctoral_students = 
| known_for         = 
| awards            = [[Fields Medal]] (2002)
}}
'''Vladimir Alexandrovich Voevodsky''' ({{IPAc-en|v|ɔj|ɛ|ˈ|v|ɒ|d|s|k|i}}; {{lang-ru|Влади́мир Алекса́ндрович Воево́дский}}, 4 June 1966 – 30 September 2017) was a [[Russia]]n-[[America]]n [[mathematician]]. His work in developing a [[homotopy theory]] for [[algebraic varieties]] and formulating [[motivic cohomology]] led to the award of a [[Fields Medal]] in 2002. He is also known for the proof of the [[Milnor conjecture]] and motivic [[Bloch-Kato conjectures]] and for the [[univalent foundations]] of mathematics and [[homotopy type theory]].

== Early life and education ==

Vladimir Voevodsky's father, Aleksander Voevodsky, was head of the Laboratory of High Energy Leptons in the Institute for Nuclear Research at the Russian Academy of Sciences. His mother Tatyana, was a chemist.&lt;ref name=Obit/&gt; Voevodsky attended [[Moscow State University]] for a while, but was forced to leave without a diploma for refusing to attend classes and failing academically.&lt;ref name=Obit/&gt; He received his [[Doctor of Philosophy|Ph.D.]] in mathematics from [[Harvard University]] in 1992 after being recommended without ever applying, following several independent publications;&lt;ref name=Obit/&gt; he was advised there by [[David Kazhdan]].

While he was a first year undergraduate, he was given a copy of [[Esquisse d'un Programme]] (submitted a few months earlier by [[Alexander Grothendieck]] to [[CNRS]]) by his advisor George Shabat. He learned the [[French language]] "with the sole purpose of being able to read this text" and started his research on some of the themes mentioned there.&lt;ref&gt;See the autobiographical story in {{cite web|last1=Voevodsky|first1=Vladimir|title=Univalent Foundations|url=http://www.math.ias.edu/~vladimir/Site3/Univalent_Foundations_files/2014_IAS.pdf|publisher=[[Institute for Advanced Study]]}}&lt;/ref&gt;

== Work ==
Voevodsky's work was in the intersection of [[algebraic geometry]] with [[algebraic topology]]. Along with [[Fabien Morel]], Voevodsky introduced a [[homotopy theory]] for [[Scheme (mathematics)|schemes]]. He also formulated what is now believed to be the correct form of [[motivic cohomology]], and used this new tool to prove [[Milnor's conjecture]] relating the [[Milnor]] [[K-theory]] of a [[field (mathematics)|field]] to its [[étale cohomology]]. For the above, he received the [[Fields Medal]] at the 24th [[International Congress of Mathematicians]] held in [[Beijing]], [[China]].&lt;ref&gt;The second medal at the same congress was received by [[Laurent Lafforgue]]&lt;/ref&gt;

In 1998 he gave a plenary lecture (''A&lt;sup&gt;1&lt;/sup&gt;-Homotopy Theory'') at the International Congress of Mathematicians in [[Berlin]].&lt;ref&gt;{{cite book|author=Voevodsky, Vladimir|chapter=A&lt;sup&gt;1&lt;/sup&gt;-homotopy theory|title=''In:'' Proceedings of the International Congress of Mathematicians|volume=vol. 1|pages=579–604|year=1998|chapter-url=http://www.math.ias.edu/vladimir/files/A1_homotopy_ICM_1998_Berlin_published.pdf}}&lt;/ref&gt; He coauthored (with [[Andrei Suslin]] and [[Eric M. Friedlander]]) ''Cycles, Transfers and Motivic Homology Theories'', which develops the theory of motivic cohomology in some detail.

From 2002, Voevodsky was a professor at the [[Institute for Advanced Study]] in [[Princeton, New Jersey]].

In January 2009, at an anniversary conference in honor of  [[Alexander Grothendieck]], held at the [[Institut des Hautes Études Scientifiques]], Voevodsky announced a proof of the full [[Bloch-Kato conjectures]].

In 2009, he constructed the univalent model of [[Martin-Löf type theory]] in [[simplicial set]]s. This led to important advances in type theory and in the development of new [[Univalent foundations]] of mathematics that Voevodsky worked on in his final years. He worked on a [[Coq]] library ''UniMath'' using univalent ideas.&lt;ref name=Obit /&gt;&lt;ref&gt;{{Citation|title=UniMath: This coq library aims to formalize a substantial body of mathematics using the univalent point of view|date=2017-10-07|url=https://github.com/UniMath/UniMath|publisher=Univalent Mathematics|accessdate=2017-10-07}}&lt;/ref&gt;

In April 2016, the [[University of Gothenburg]] awarded an honorary doctorate to Voevodsky.&lt;ref&gt;{{cite web|url=http://itufak.gu.se/english/current/news/news-detail/fields-medalist-vladimir-voevodsky-new-honorary-doctor-at-the-it-faculty.cid1380718|title=Fields medalist Vladimir Voevodsky new honorary doctor at the IT Faculty}}&lt;/ref&gt;

==Death and legacy ==
Voevodsky died on 30 September 2017 at his home in Princeton, from an [[aneurysm]].&lt;ref name=Obit&gt;{{cite newspaper|author=Rehmeyer, Julie|date=6 October 2017|title=Vladimir Voevodsky, Revolutionary Mathematician, Dies at 51|newspaper=New York Times|url=https://www.nytimes.com/2017/10/06/obituaries/vladimir-voevodsky-revolutionary-mathematician-dies-at-51.html}}&lt;/ref&gt;&lt;ref name=ias&gt;{{cite web | title=IAS: Vladimir Voevodsky, Fields Medalist, Dies at 51|url=https://www.ias.edu/news/2017/vladimir-voevodsky| accessdate=2017-09-30}}&lt;/ref&gt; He is survived by daughters Diana Yasmine Voevodsky and Natalia Dalia Shalaby.&lt;ref name="Obit"/&gt;

==Selected works==
* Voevodsky, Vladimir, Suslin, Andrei, and Friedlander, Eric M. (2000). [https://books.google.com/books/about/Cycles_Transfers_and_Motivic_Homology_Th.html?id=WiDHDgAAQBAJ''Cycles, transfers, and motivic homology theories'']. Annals of Mathematics Studies Vol. 143. Princeton University Press.&lt;ref&gt;{{cite journal|author=Weibel, Charles A.|title=Review of ''Cycles, transfers, and motivic homology theories'' by Vladimir Voevodsky, Andrei Muslin, and Eric M. Friedlander|journal=Bull. Amer. Math. Soc. (N.S.)|year=2002|volume=39|issue=1|pages=137–143|url=http://www.ams.org/journals/bull/2002-39-01/S0273-0979-01-00930-2/S0273-0979-01-00930-2.pdf|doi=10.1090/s0273-0979-01-00930-2}}&lt;/ref&gt;
* Mazza, Carlo, Voevodsky, Vladimir and Weibel, Charles A. [https://books.google.com/books?id=gYSeAwAAQBAJ ''Lecture notes on motivic cohomology'']. [[Clay Mathematics Monographs]], Vol. 2. American Mathematical Soc., 2011&lt;ref&gt;[http://bookstore.ams.org/cmim-2 ''Lecture notes on motivic cohomology'' at AMS Bookstore]&lt;/ref&gt;&lt;ref&gt;[http://euro-math-soc.eu/review/lecture-notes-motivic-cohomology Review: ''Lecture Notes on Motivic Cohomology'', European Mathematical Society]&lt;/ref&gt;

==Notes==
{{Reflist}}

==References==
* {{cite journal | author = Friedlander Eric M., Rapoport Michael, Suslin Andrei | year = 2003 | title = The mathematical work of the 2002 Fields medalists | url = http://www.ams.org/notices/200302/fea-suslin.pdf | format = PDF | journal = Notices Amer. Math. Soc. | volume = 50 | issue = 2| pages = 212–217 }}

==Further reading==
* More information about his work can be found on his [https://www.math.ias.edu/vladimir/home website]

==External links==
{{Sister project links| wikt=no | commons=Category:Vladimir Voevodsky | b=no | n=no | q=Vladimir Voevodsky | s=no | v=no | voy=no | species=no | d=no}}
* [https://github.com/vladimirias Vladimir Voevodsky on GitHub] Contains the slides of many of his recent lectures.
* [http://www.polit.ru/science/2006/08/22/voevod.html По большому филдсовскому счету] Интервью с Владимиром Воеводским и Лораном Лаффоргом
* Julie Rehmeyer, [https://www.nytimes.com/2017/10/06/obituaries/vladimir-voevodsky-revolutionary-mathematician-dies-at-51.html Vladimir Voevodsky, Revolutionary Mathematician, Dies at 51], New York Times, 6 October 2017
* {{MacTutor Biography|id=Voevodsky}}
* {{MathGenealogy|id=28125}}

{{Fields medalists}}

{{Authority control}}

{{DEFAULTSORT:Voevodsky, Vladimir}}
[[Category:1966 births]]
[[Category:2017 deaths]]
[[Category:20th-century mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:Russian mathematicians]]
[[Category:Fields Medalists]]
[[Category:Algebraic geometers]]
[[Category:Topologists]]
[[Category:Harvard University alumni]]
[[Category:Institute for Advanced Study faculty]]
[[Category:Soviet mathematicians]]
[[Category:Sloan Research Fellows]]
[[Category:Harvard Fellows]]
[[Category:Russian expatriates in the United States]]</text>
      <sha1>gjpryhyjis648bdn91k2hr1yoolf3ow</sha1>
    </revision>
  </page>
</mediawiki>
