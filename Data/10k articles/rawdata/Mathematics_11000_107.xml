<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>79 (number)</title>
    <ns>0</ns>
    <id>391888</id>
    <revision>
      <id>862779417</id>
      <parentid>862779117</parentid>
      <timestamp>2018-10-06T17:12:54Z</timestamp>
      <contributor>
        <username>Arthur Rubin</username>
        <id>374195</id>
      </contributor>
      <comment>/* In mathematics */ never mind; 4 strikes ([[WP:EGG]], confusing, unsourced, misplaced) and it's out</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4619">{{Infobox number
| number = 79
| factorization = [[prime]]
| prime = 22nd
| divisor = 1, 79
}}
'''Seventy-nine''' is the [[natural number]] following [[78 (number)|78]] and preceding [[80 (number)|80]].

==In mathematics==
'''79''' is:

* An [[even and odd numbers|odd]] number.
* The smallest number that can not be represented as a sum of fewer than 19 [[fourth power]]s.
* A [[strictly non-palindromic number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A016038|title=Sloane's A016038 : Strictly non-palindromic numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* The 22nd [[prime number]] (between {{num|73}} and {{num|83}})
* The smallest prime number ''p'' for which the [[real quadratic field]] '''Q'''[{{sqrt|''p''}}] has [[Ideal class group|class number]] greater than 1 (namely 3).&lt;ref&gt;H. Cohen, ''A Course in Computational Algebraic Number Theory'', GTM 138, Springer Verlag (1993), Appendix B2, p.507. The table lists fields by [[Real quadratic field#Discriminant|discriminant]], which is 4''p'' for '''Q'''[{{sqrt|''p''}}] when ''p'' is [[modular arithmetic|congruent]] to 3 modulo 4, as is the case for 79, so the entry appears at discriminant 316.&lt;/ref&gt;
* A [[cousin prime]] with 83.
* An [[emirp]], because the reverse of 79, [[97 (number)|97]], is also a prime.&lt;ref&gt;{{Cite web|url=https://oeis.org/A006567|title=Sloane's A006567 : Emirps|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* A [[fortunate prime]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A046066|title=Sloane's A046066 : Fortunate primes|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* A prime number that is also a [[Gaussian prime]] (since it is of the form {{nowrap|4''n'' + 3}}).
* A [[happy prime]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A035497|title=Sloane's A035497 : Happy primes|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* A [[Higgs prime]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A007459|title=Sloane's A007459 : Higgs' primes|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* A [[Kynea number|Kynea prime]] (having the form {{nowrap|(2''n'' + 1){{sup|2}} − 2}}).&lt;ref&gt;{{Cite web|url=https://oeis.org/A091514|title=Primes of the form (2^n + 1)^2 - 2 = 4^n + 2^(n+1) - 1|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* A [[lucky prime]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A031157|title=Sloane's A031157 : Numbers that are both lucky and prime|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* A [[permutable prime]], with [[97 (number)|ninety-seven]].
* A [[Pillai prime]],&lt;ref&gt;{{Cite web|url=https://oeis.org/A063980|title=Sloane's A063980 : Pillai primes|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt; because 23[[Factorial|!]] + 1 is [[divisible]] by 79, but 79 is not one more than a [[Multiple (mathematics)|multiple]] of [[23 (number)|23]].
* A [[regular prime]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A007703|title=Sloane's A007703 : Regular primes|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* A [[right-truncatable prime]], because when the last digit (9) is removed, the remaining number (7) is still prime
* A [[sexy prime]] (with [[73 (number)|73]]).
* The ''n'' value of the [[Wagstaff prime]] 201487636602438195784363.

==In science==
* The [[atomic number]] of the [[chemical element]] [[gold]] (Au) is 79.

===In astronomy===
* [[Messier 79|Messier object 79]] (M79), a [[visual magnitude|magnitude 8.5]] [[globular cluster]] in the [[constellation]] [[Lepus (constellation)|Lepus]]
* [[List of NGC objects (1-999)|New General Catalogue object 79]] (NGC 79), a [[galaxy]] in the constellation [[Andromeda (constellation)|Andromeda]]

==In other fields==
{{Seealso|List of highways numbered 79}}
* [[Live Seventy Nine]], an album by [[Hawkwind]]
* The years [[79 BC]], [[AD 79]] or [[1979]]
* The number of the [[Departments of France|French department]] [[Deux-Sèvres]]

==References==
{{Reflist}}

{{Integers|zero}}

{{DEFAULTSORT:79 (Number)}}
[[Category:Integers]]</text>
      <sha1>kraii7r9ymym8hqpdjrsimnck0i2hsb</sha1>
    </revision>
  </page>
  <page>
    <title>Actuary</title>
    <ns>0</ns>
    <id>43405</id>
    <revision>
      <id>870590615</id>
      <parentid>870589019</parentid>
      <timestamp>2018-11-25T20:49:19Z</timestamp>
      <contributor>
        <username>NSH001</username>
        <id>1647583</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/2A00:23C6:1998:1900:DDE3:48DB:D1D9:5D6C|2A00:23C6:1998:1900:DDE3:48DB:D1D9:5D6C]] ([[User talk:2A00:23C6:1998:1900:DDE3:48DB:D1D9:5D6C|talk]]) to last version by Redrose64</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="57148">{{pp-move-indef}}
{{Use mdy dates|date=January 2014}}{{Use Harvard referencing|date=August 2014}}
{{Infobox Occupation
 | name     = Actuary
 | image    = Hurricane katrina damage gulfport mississippi.jpg
 | caption  = Damage from [[Hurricane Katrina]] in 2005. Actuaries need to estimate long-term levels of such damage in order to accurately price property insurance, set appropriate [[actuarial reserves|reserves]], and design appropriate [[reinsurance]] and capital management strategies.
 |official_names=Actuary
&lt;!------------Details-------------------&gt;
 |type=[[Profession]]
 |activity_sector=[[Insurance]], [[Reinsurance]], [[Pension plan]]s, [[Social security|Social welfare programs]]
 |competencies=[[Mathematics]], [[finance]], analytical skills, business knowledge
 |formation=See [[#Credentialing and exams|Credentialing and exams]]
 |employment_field=Insurance companies, superannuation funds, consulting firms and government
 |related_occupation=[[Insurance underwriter|Underwriter]]
 |average_salary=See [[#Remuneration|Remuneration]]
}}
An '''actuary''' is a business professional who deals with the measurement and management of [[risk]] and uncertainty {{harv|BeAnActuary|2011a}}. The name of the corresponding field is [[actuarial science]]. These risks can affect both sides of the [[balance sheet]] and require [[investment management|asset management]], [[liability (financial accounting)|liability]] management, and valuation skills {{harv|BeAnActuary|2011b}}. Actuaries provide assessments of financial security systems, with a focus on their complexity, their mathematics, and their mechanisms {{harv|Trowbridge|1989|p=7}}.

While the concept of insurance dates to antiquity ({{harvnb|Johnston|1903|loc=§475–§476}}, {{harvnb|Loan|1992}}, {{harvnb|Lewin|2007|loc=pp. 3–4}}), the concepts needed to scientifically measure and mitigate risks have their origins in the 17th century studies of probability and annuities {{harv|Heywood|1985}}. Actuaries of the 21st century require analytical skills, business knowledge, and an understanding of human behavior and information systems to design and manage programs that control risk {{harv|BeAnActuary|2011c}}. The [[Actuarial credentialing and exams|actual steps]] needed to become an actuary are usually country-specific; however, almost all processes share a rigorous schooling or examination structure and take many years to complete ({{harvnb|Feldblum|2001|p=6}}, {{harvnb|Institute and Faculty of Actuaries|2014}}).

The profession has consistently been ranked as one of the most desirable {{harv|Riley|2013}}. In various studies, being an actuary was ranked number one or two multiple times since 2010 ({{harvnb|Thomas|2012}}, {{harvnb|Weber|2013}}, {{harvnb|CareerCast|2015}}).

==Responsibilities==
&lt;!-- BLS 2015(all tabs) and GAD 2015 for UK blurb: start --&gt;Actuaries use skills primarily in mathematics, particularly [[calculus]]-based [[probability]] and [[mathematical statistics]], but also [[economics]], [[computer science]], finance, and business. For this reason, actuaries are essential to the insurance and reinsurance industries, either as staff employees or as consultants; to other businesses, including sponsors of pension plans; and to government agencies such as the [[Government Actuary's Department]] in the United Kingdom or the [[Social Security Administration]] in the United States of America. Actuaries assemble and analyze data to estimate the probability and likely cost of the occurrence of an event such as death, sickness, injury, disability, or loss of property. Actuaries also address financial questions, including those involving the level of pension contributions required to produce a certain retirement income and the way in which a company should invest resources to maximize its return on investments in light of potential risk. Using their broad knowledge, actuaries help design and price insurance policies, pension plans, and other financial strategies in a manner that will help ensure that the plans are maintained on a sound financial basis ({{harvnb|Bureau of Labor Statistics|2015}}, {{harvnb|Government Actuary's Department|2015}})&lt;!-- BLS 2015(all tabs) and GAD 2015 for UK blurb: end --&gt;.

===Disciplines===
Most traditional actuarial disciplines fall into two main categories: life and non-life.

Life actuaries, which include health and [[pension]] actuaries, primarily deal with [[Mortality rate|mortality]] risk, [[morbidity]] risk, and investment risk. Products prominent in their work include [[life insurance]], [[Life annuity|annuities]], pensions, short and long term [[disability insurance]], health insurance, [[health savings account]]s, and [[long-term care]] insurance {{harv|Bureau of Labor Statistics|2015}}. In addition to these risks, social insurance programs are influenced by public opinion, politics, budget constraints, changing [[demographics]], and other factors such as [[medical technology]], [[inflation]], and [[Cost-of-living index|cost of living]] considerations ({{harvnb|GAO|1980}}, {{harvnb|GAO|2008}}).

&lt;!-- Sourced to AIA: start--&gt;Non-life actuaries, also known as property and casualty or general insurance actuaries, deal with both physical and legal risks that affect people or their property. Products prominent in their work include [[auto insurance]], [[home insurance|homeowners insurance]], commercial property insurance, [[workers' compensation]], [[malpractice]] insurance, [[Product liability|product liability insurance]], [[marine insurance]], [[terrorism insurance]], and other types of [[liability insurance]] {{harv|AIA|2014}}&lt;!-- Sourced to AIA: end--&gt;.

Actuaries are also called upon for their expertise in [[enterprise risk management]] {{harv|Bureau of Labor Statistics|2015}}. This can involve [[dynamic financial analysis]], [[stress testing#Financial sector|stress testing]], the formulation of corporate risk policy, and the setting up and running of corporate risk departments {{harv|Institute and Faculty of Actuaries|2011b}}. Actuaries are also involved in other areas of the [[financial services]] industry, such as analysing [[securities offering]]s or [[market research]] {{harv|Bureau of Labor Statistics|2015}}.

===Traditional employment===
On both the life and casualty sides, the classical function of actuaries is to calculate premiums and [[Insurance#Indemnification|reserves]] for insurance policies covering various risks {{harv|Institute and Faculty of Actuaries|2014|pp. = 12–14}}. On the casualty side, this analysis often involves quantifying the probability of a loss event, called the frequency, and the size of that loss event, called the severity. The amount of time that occurs before the loss event is important, as the insurer will not have to pay anything until after the event has occurred. On the life side, the analysis often involves quantifying how much a potential sum of money or a financial liability will be worth at different points in the future. Since neither of these kinds of analysis are purely deterministic processes, stochastic models are often used to determine frequency and severity [[frequency distribution|distributions]] and the [[parameter]]s of these distributions. Forecasting interest yields and currency movements also plays a role in determining future costs, especially on the life side {{harv|Tolley|Hickman|Lew|2012}}.

Actuaries do not always attempt to predict aggregate future events. Often, their work may relate to determining the cost of financial liabilities that have already occurred, called [[Retrocession (Insurance)|retrospective reinsurance]], or the development or re-pricing of new products.

Actuaries also design and maintain products and systems. They are involved in financial reporting of companies' assets and liabilities. They must communicate complex concepts to clients who may not share their language or depth of knowledge. Actuaries work under a code of ethics that covers their communications and work products {{harv|ASB|2013}}.

===Non-traditional employment===
As an outgrowth of their more traditional roles, actuaries also work in the fields of risk management and [[enterprise risk management]] for both financial and non-financial corporations {{harv|D'Arcy|2005}}. Actuaries in traditional roles study and use the tools and data previously in the domain of finance {{harv|Feldblum|2001|p=8}}. The [[Basel II]] accord for financial institutions (2004), and its analogue, the [[Solvency II]] accord for insurance companies (to come into effect in 2016), require institutions to account for [[operational risk]] separately, and in addition to, [[credit risk|credit]], [[Actuarial reserves|reserve]], [[asset]], and [[insolvency]] risk. Actuarial skills are well suited to this environment because of their training in analyzing various forms of risk, and judging the potential for upside gain, as well as downside loss associated with these forms of risk {{harv|D'Arcy|2005}}.

&lt;!-- First two are from Mungan, last two are from Stefan --&gt;Actuaries are also involved in [[investment]] advice and [[asset management]], and can be general business managers and [[chief financial officer]]s&amp;nbsp;({{harvnb|Mungan|2002}}, {{harvnb|Stefan|2010}}). They analyze business prospects with their financial skills in valuing or discounting risky future cash flows, and apply their pricing expertise from insurance to other lines of business. For example, insurance [[securitization]] requires both actuarial and finance skills {{harv|Krutov|2006}}. Actuaries also act as [[expert witness]]es by applying their analysis in court trials to estimate the economic value of losses such as lost profits or lost wages {{harv|Wagner|2006}}.

==History==
[[File:Nathaniel Bowditch (1773-1838), American mathematician and actuary.jpeg|thumb|right|alt=A black and white picture of Nathaniel Bowditch, an eighteenth century American actuary|Mathematician [[Nathaniel Bowditch]] was one of America's first insurance actuaries.]]

===Need for insurance===
The basic requirements of communal interests gave rise to risk sharing since the dawn of civilization. For example, people who lived their entire lives in a camp had the risk of fire, which would leave their band or family without shelter. After [[barter (economics)|barter]] came into existence, more complex risks emerged and new forms of risk manifested. Merchants embarking on trade journeys bore the risk of losing goods entrusted to them, their own possessions, or even their lives. Intermediaries developed to warehouse and trade goods, which exposed them to [[financial risk]]. The primary providers in extended families or households ran the risk of premature death, disability or infirmity, which could leave their dependents to starve. [[Credit (finance)|Credit]] procurement was difficult if the creditor worried about repayment in the event of the borrower's death or infirmity. Alternatively, people sometimes lived too long from a financial perspective, exhausting their savings, if any, or becoming a burden on others in the extended family or society {{harv|Lewin|2007|p=3}}.

===Early attempts===
In the ancient world there was not always room for the sick, suffering, disabled, aged, or the poor—these were often not part of the [[Collective consciousness|cultural consciousness]] of societies {{harv|Perkins|1995}}. Early methods of protection, aside from the normal support of the extended family, involved charity; religious organizations or neighbors would collect for the destitute and needy. By the middle of the 3rd century, 1,500 suffering people were being supported by charitable operations in [[Ancient Rome|Rome]] {{harv|Perkins|1995}}. Charitable protection remains an active form of support in the modern era {{harv|GivingUSA|2009}}, but receiving charity is uncertain and is often accompanied by [[social stigma]]. Elementary [[mutual aid (organization)|mutual aid]] agreements and pensions did arise in antiquity {{harv|Thucydides}}. Early in the [[Roman Empire|Roman empire]], associations were formed to meet the expenses of burial, cremation, and monuments—precursors to [[Burial society|burial insurance]] and [[Friendly society|friendly societies]]. A small sum was paid into a communal fund on a weekly basis, and upon the death of a member, the fund would cover the expenses of rites and burial. These societies sometimes sold shares in the building of [[Columbarium|columbāria]], or burial vaults, owned by the fund {{harv|Johnston|1903|loc=§475–§476}}. Other early examples of mutual [[surety]] and [[Life insurance|assurance]] pacts can be traced back to various forms of fellowship within the Saxon clans of England and their Germanic forebears, and to Celtic society {{harv|Loan|1992}}.

Non-life insurance started as a hedge against loss of cargo during sea travel. Anecdotal reports of such guarantees occur in the writings of [[Demosthenes]], who lived in the 4th century BCE {{harv|Lewin|2007|pp=3–4}}. The earliest records of an official non-life insurance policy come from [[Sicily]], where there is record of a 14th-century contract to insure a shipment of wheat {{harv|Sweeting|2011|p=14}}. In 1350, Lenardo Cattaneo assumed "all risks from act of God, or of man, and from perils of the sea" that may occur to a shipment of wheat from Sicily to Tunis up to a maximum of 300 [[Florin (Italian coin)|florin]]s. For this he was paid a premium of 18% {{harv|Lewin|2007|p=4}}.

===Development of theory===
[[File:Excerpt from CDC 2003 Table 1.pdf|thumb|right|alt=A table of numbers; the first page of the U.S. 2003 mortality table.|2003 U.S. mortality ([[life table|life]]) table, Table 1, Page 1]]
&lt;!-- Sourced to Heywood: start --&gt;During the 17th century, a more scientific basis for [[risk management]] was being developed. In 1662, a London [[draper]] named [[John Graunt]] showed that there were predictable patterns of longevity and death in a defined group, or [[Cohort (statistics)|cohort]], of people, despite the uncertainty about the future longevity or mortality of any one individual. This study became the basis for the original [[life table]]. Combining this idea with that of [[compound interest]] and [[annuity]] valuation, it became possible to set up an insurance scheme to provide life insurance or pensions for a group of people, and to calculate with some degree of accuracy each member's necessary contributions to a common fund, assuming a fixed rate of interest. The first person to correctly calculate these values was [[Edmond Halley]] {{harv|Heywood|1985}}&lt;!-- Sourced to Heywood: end --&gt;. In his work, Halley demonstrated a method of using his life table to calculate the premium someone of a given age should pay to purchase a life-annuity {{harv|Halley|1693}}.

===Early actuaries===
&lt;!-- Ogborn 1956 p. 235: start --&gt;[[James Dodson (mathematician)|James Dodson]]'s pioneering work on the [[Whole life insurance#Level premium system|level premium system]] led to the formation of the Society for Equitable Assurances on Lives and Survivorship (now commonly known as [[The Equitable Life Assurance Society|Equitable Life]]) in London in 1762. This was the first life insurance company to use premium rates that were calculated scientifically for long-term life policies, using Dodson's work. After Dodson's death in 1757, [[Edward Rowe Mores]] took over the leadership of the group that eventually became the Society for Equitable Assurances. It was he who specified that the chief official should be called an ''actuary'' {{harv|Ogborn|1956|p=235}}&lt;!-- Ogborn 1956 p. 235: end --&gt;. Previously, the use of the term had been restricted to an official who recorded the decisions, or ''acts'', of ecclesiastical courts, in ancient times originally the secretary of the [[Roman senate]], responsible for compiling the ''[[Acta Senatus]]'' {{harv|Ogborn|1956|p=233}}. Other companies that did not originally use such mathematical and scientific methods most often failed or were forced to adopt the methods pioneered by Equitable {{harv|Bühlmann|1997|p=166}}.

===Development of the modern profession===
{{main|Actuarial science}}
[[File:Alliance for Health Reform briefing on the individual health insurance market (34370998252).jpg|thumb|upright|Actuary speaking at a health care event]]
In the 18th and 19th centuries, computational complexity was limited to manual calculations. The actual calculations required to compute fair insurance premiums are complex. The actuaries of that time developed methods to construct easily used tables, using sophisticated approximations called [[Actuarial science#Technological advances|commutation function]]s, to facilitate timely, accurate, manual calculations of premiums {{harv|Slud|2006}}. Over time, actuarial organizations were founded to support and further both actuaries and actuarial science, and to protect the public interest by ensuring competency and ethical standards {{harv|Hickman|2004|p=4}}. Since calculations were cumbersome, actuarial shortcuts were commonplace.

Non-life actuaries followed in the footsteps of their life compatriots in the early 20th century. In the United States, the 1920 revision to workers' compensation rates took over two months of around-the-clock work by day and night teams of actuaries {{harv|Michelbacher|1920|pp=224, 230}}. In the 1930s and 1940s, rigorous mathematical foundations for [[stochastic process]]es were developed {{harv|Bühlmann|1997|p=168}}. Actuaries began to forecast losses using models of random events instead of [[Deterministic system|deterministic methods]]. Computers further revolutionized the actuarial profession. From pencil-and-paper to punchcards to microcomputers, the modeling and forecasting ability of the actuary has grown exponentially {{harv|MacGinnitie|1980|pp=50–51}}.

Another modern development is the convergence of modern [[finance theory|financial theory]] with actuarial science {{harv|Bühlmann|1997|pp=169–171}}. In the early 20th century, actuaries were developing techniques that can be found in modern financial theory, but for various historical reasons, these developments did not achieve much recognition {{harv|Whelan|2002}}. In the late 1980s and early 1990s, there was a distinct effort for actuaries to combine financial theory and stochastic methods into their established models {{harv|D'Arcy|1989}}. In the 21st century, the profession, both in practice and in the educational syllabi of many actuarial organizations, combines tables, loss models, stochastic methods, and financial theory {{harv|Feldblum|2001|pp=8–9}}, but is still not completely aligned with modern [[financial economics]] {{harv|Bader|Gold|2003}}.

==Remuneration and ranking==
As there are relatively few actuaries in the world compared to other professions, actuaries are in high demand, and are highly paid for the services they render ({{harvnb|Hennessy|2003}}, {{harvnb|Kurtz|2013}}). {{As of|2016}}, in the United States, newly credentialed actuaries on average earn around $100,000 per year, while more experienced actuaries can earn over $150,000 per year {{harv|Ezra Penland|2016}}. Similarly, {{as of|2014|alt=a 2014}} survey in the United Kingdom indicated a starting salary for a newly credentialed actuary of about [[Pound sterling|£]]50,000; actuaries with more experience can earn well in excess of £100,000 {{harv|Crail|2014}}.

&lt;!-- Following all sourced to Riley --&gt;The actuarial profession has been consistently ranked for decades as one of the most desirable. Actuaries work comparatively reasonable hours, in comfortable conditions, without the need for physical exertion that may lead to injury, are well paid, and the profession consistently has a good hiring outlook {{harv|Riley|2013}}.&lt;!-- End sourcing to Riley --&gt; Not only has the overall profession ranked highly, but it also is considered one of the best professions for women {{harv|Shavin|2014}}, and one of the best recession-proof professions {{harv|Kiviat|2008}}. In the United States, the profession was rated as the best profession by CareerCast, which uses five key criteria to rank jobs—environment, income, employment outlook, physical demands, and stress, in 2010 {{harv|Needleman|2010}}, 2013 {{harv|Weber|2013}}, and 2015 {{harv|CareerCast|2015}}. In other years, it remained in the top 10 ({{harvnb|Thomas|2012}}, {{harvnb|CareerCast|2014}}, {{harvnb|CareerCast|2016}}). In the United Kingdom {{harv|Ugwumadu|2013}}, and around the world {{harv|ESSEC|2014}}, actuaries continue to be highly ranked as a profession.

==Credentialing and exams==
{{Main|Actuarial credentialing and exams}}
Becoming a fully credentialed actuary requires passing a rigorous series of professional examinations, usually taking several years. In some countries, such as Denmark, most study takes place in a university setting {{harv|Norberg|1990|p=407}}. In others, such as the US, most study takes place during employment through a series of examinations ({{harvnb|SOA|2018}}, {{harvnb|CAS|2018}}). In the UK, and countries based on its process, there is a hybrid university-exam structure {{harv|Institute and Faculty of Actuaries|2011a}}.

===Exam support===
As these qualifying exams are extremely rigorous, support is usually available to people progressing through the exams. Often, employers provide paid on-the-job study time and paid attendance at seminars designed for the exams {{harv|BeAnActuary|2011d}}. Also, many companies that employ actuaries have automatic pay raises or promotions when exams are passed. As a result, actuarial students have strong incentives for devoting adequate study time during off-work hours. A common rule of thumb for exam students is that, for the Society of Actuaries examinations, roughly 400&amp;nbsp;hours of study time are necessary for each four-hour exam {{harv|Sieger|1998}}. Thus, thousands of hours of study time should be anticipated over several years, assuming no failures {{harv|Feldblum|2001|p=6}}.

===Pass marks and pass rates===
Historically, the actuarial profession has been reluctant to specify the pass marks for its examinations ({{harvnb|Muckart|2010}}, {{harvnb|Prevosto|2000}}). To address concerns that there are pre-existing pass/fail quotas, a former Chairman of the Board of Examiners of the Institute and Faculty of Actuaries stated, "Although students find it hard to believe, the Board of Examiners does not have fail quotas to achieve. Accordingly pass rates are free to vary (and do). They are determined by the quality of the candidates sitting the examination and in particular how well prepared they are. Fitness to pass is the criterion, not whether you can achieve a mark in the top 40% of candidates sitting." {{harv|Muckart|2010}}. In 2000, the [[Casualty Actuarial Society]] (CAS) decided to start releasing pass marks for the exams it offers {{harv|Prevosto|2000}}. The CAS's policy is also not to grade to specific pass ratios; the CAS board affirmed in 2001 that "the CAS shall use no predetermined pass ratio as a guideline for setting the pass mark for any examination. If the CAS determines that 70% of all candidates have demonstrated sufficient grasp of the syllabus material, then those 70% should pass. Similarly, if the CAS determines that only 30% of all candidates have demonstrated sufficient grasp of the syllabus material, then only those 30% should pass."{{harv|CAS|2001}}.

==Notable actuaries==
{{See also|List of actuaries}}
&lt;!-- This section is for people who are notable and their being an actuary is part and parcel of that notability. For example, early actuaries, actuaries who were involved in groundbreaking analysis or creation of products, etc. It is not for actuaries who are notable for other reasons (e.g. their notability comes from being sports figures, artists, actors, etc.) --&gt;

{{Div col|colwidth = 40em}}
;[[Nathaniel Bowditch]] :Early American mathematician remembered for his work on ocean navigation. In 1804, Bowditch became what was probably the United States of America's second insurance actuary as president of the Essex Fire and Marine Insurance Company in [[Salem, Massachusetts]]&amp;nbsp;{{harv|Seltzer|Alin|1969}}.

;[[Harald Cramér]] :Swedish actuary and probabilist notable for his contributions in mathematical statistics, such as the [[Cramér–Rao bound|Cramér–Rao inequality]] {{harv|Cramér|1946}}. Cramér was an Honorary President of the Swedish Actuarial Society&amp;nbsp;{{harv|Kendall|1983}}.

;[[James Dodson (mathematician)|James Dodson]] :Head of the Royal Mathematical School, and Stone's School, Dodson built on the statistical mortality tables developed by Edmund Halley in 1693&amp;nbsp;{{harv|Lewin|2007|p=38}}.

;[[Edmond Halley]] :While Halley actually predated much of what is now considered the start of the actuarial profession, he was the first to rigorously calculate premiums for a life insurance policy mathematically and statistically&amp;nbsp;{{harv|Halley|1693}}.

;[[James C. Hickman]] :American actuarial educator, researcher, and author&amp;nbsp;{{harv|Chaptman|2006}}.

;[[Oswald Jacoby]] :American actuary best known as a [[contract bridge]] player, he was the youngest person ever to pass four examinations of the [[Society of Actuaries]]&amp;nbsp;{{harv|SOA|1984}}.

;[[David X. Li]] :Canadian qualified actuary who in the first decade of the 21st century pioneered the use of [[Gaussian copula]] models for the pricing of [[collateralized debt obligation]]s (CDOs)&amp;nbsp;{{harv|Salmon|2009}}.

;[[Edward Rowe Mores]] :First person to use the title 'actuary' with respect to a business position&amp;nbsp;{{harv|Ogborn|1956}}.

;[[William Morgan (actuary)|William Morgan]] :Morgan was the appointed Actuary of the Society for Equitable Assurances in 1775. He expanded on Mores's and Dodson's work, and may be considered the father of the actuarial profession in that his title became applied to the field as a whole&amp;nbsp;{{harv|Ogborn|1973}}.

;[[Robert J. Myers]] :American actuary who was instrumental in the creation of the U.S. [[Social Security (United States)|Social Security program]]&amp;nbsp;{{harv|Williams Walsh|2010}}.

;[[Frank Redington]] :British actuary who developed the Redington Immunization Theory {{harv|The Actuary|2003}}.

;[[I. M. Rubinow|Isaac M. Rubinow]] :Founder and first president of the [[Casualty Actuarial Society]] {{harv|CASF|2008}}.

;[[Elizur Wright]] :American actuary and abolitionist, professor of mathematics at Western Reserve College (Ohio). He campaigned for laws that required life insurance companies to hold sufficient reserves to guarantee that policies would be paid {{harv|Stearns|1905}}.
{{Div col end}}

==Fictional actuaries==
{{main|Fictional actuaries}}
Actuaries have appeared in works of fiction including literature, theater, television, and film. &lt;!-- Sourced to Coleman --&gt;At times, they have been portrayed as "math-obsessed, socially disconnected individuals with shockingly bad comb-overs", which has resulted in a mixed response amongst actuaries themselves {{harv|Coleman|2003}}.

==References==
&lt;!-- Note: This article uses author-date citation format, not footnotes. If you have any problems, please ask on the talk page and someone will be happy to help you. Also, please place references in alphabetical order by last name or organizational name. The references have been broken into alphabetical sections to make it easier. Thank you. --&gt;
{{refbegin|3}}
&lt;!-- A --&gt;
*{{Cite report
 | author     = Actuarial Standards Board
 | date       = March 2013
 | title      = Introductory Actuarial Standard of Practice
 | url        = http://www.actuarialstandardsboard.org/wp-content/uploads/2013/10/asop001_170.pdf
 | format     = PDF
 | accessdate = April 27, 2015
 | ref = {{harvid|ASB|2013}}
}}
*{{cite journal
| author     =&lt;!--Staff writer(s); no by-line.--&gt;
| title      = The Greatest British Actuary ever®
| url        = http://www.theactuary.com/archive/old-articles/part-4/the-greatest-british-actuary-ever-26-23174-3B/
| journal    = The Actuary
| publisher  = [[Institute and Faculty of Actuaries]]
| year       = 2003
| accessdate= May 1, 2015
| ref        = {{harvid|The Actuary|2003}}
}}
*{{Cite report
 | author     = American Insurance Association
 | authorlink = American Insurance Association
 | title      = Property-Casualty Insurance Basics
 | year       = 2014
 | url        = http://www.aiadc.org/AIAdotNET/docHandler.aspx?DocID=319988
 | format     = PDF
 | accessdate = April 29, 2015
 | ref      = {{harvid|AIA|2014}}
}}
&lt;!-- B --&gt;
*{{Cite news
 |last1=Bader
 |first1=Lawrence N.
 |last2=Gold
 |first2=Jeremy
 |year=2003
 |title=Reinventing Pension Actuarial Science
 |periodical=Pension Forum
 |volume=14
 |issue=2
 |pages=1–39
 |url=http://users.erols.com/jeremygold/reinventingpensionactuarialscience.pdf
 |format=PDF
 |accessdate=September 14, 2008
 |ref=harv
}}
*{{cite web
 |year=2011
 |url=http://www.beanactuary.com/what/do/?fa=what-do-we-do
 |title=What Do We Do?
 |publisher=BeAnActuary
 |accessdate=April 29, 2015
 |ref={{harvid|BeAnActuary|2011a}}
}}
*{{cite web
 |year=2011
 |url=http://www.beanactuary.com/what/do/?fa=the-problems-actuaries-solve
 |title=The Problems Actuaries Solve
 |publisher=BeAnActuary
 |accessdate=April 29, 2015
 |ref={{harvid|BeAnActuary|2011b}}
}}
*{{cite web
 |year=2011
 |url=http://www.beanactuary.com/what/do/?fa=what-do-we-do
 |title=What is an Actuary?
 |publisher=BeAnActuary
 |accessdate=April 29, 2015
 |ref={{harvid|BeAnActuary|2011c}}
}}
*{{cite web
 |year=2011
 |url=http://www.beanactuary.com/exams/
 |title=About Actuarial Examinations
 |publisher=BeAnActuary
 |accessdate=April 29, 2015
 |ref={{harvid|BeAnActuary|2011d}}
}}
*{{cite journal
 |last=Bühlmann
 |first=Hans
 |date=November 1997
 |title=The actuary: The role and limitations of the profession since the mid-19th century
 |journal=ASTIN Bulletin
 |volume=27
 |issue=2
 |pages=165–171
 |url=http://www.casact.org/library/astin/vol27no2/165.pdf
 |format=PDF
 |accessdate=June 28, 2006
 |ref=harv
 |doi=10.2143/ast.27.2.542046
}}
*{{cite web
 |date= January 8, 2014
 |url=http://www.bls.gov/ooh/math/actuaries.htm
 |title=Actuaries
 |work=Occupational Outlook Handbook, 2014–15 Edition
 |publisher=[[Bureau of Labor Statistics]], [[United States Department of Labor|U.S. Department of Labor]]
 |accessdate=April 29, 2015
 |ref={{harvid|Bureau of Labor Statistics|2015}}
}}
&lt;!-- C --&gt;
*{{cite web
| url        = http://www.careercast.com/slide/best-jobs-2014-4-actuary
| title      = Best Jobs of 2014: 4. Actuary
| last       = CareerCast
| year       = 2014
| publisher  = CareerCast
| accessdate= April 26, 2015
| ref        = harv
}}
*{{cite web
| url        = http://www.careercast.com/jobs-rated/best-jobs-2015
| title      = The Best Jobs of 2015: No. 1 Actuary
| last       = CareerCast
| year       = 2015
| publisher  = CareerCast
| access-date= April 27, 2015
| ref        = harv
}}
*{{cite web
| url        = http://www.careercast.com/jobs-rated/best-jobs-2016?page=9
| title      = The Best Jobs of 2016: 10. Actuary
| last       = CareerCast
| year       = 2016
| publisher  = CareerCast
| access-date= January 10, 2018
| ref        = harv
}}
*{{cite web
 |date=March 2, 2001
 |url=http://www.casact.org/admissions/reports/index.cfm?fa=passmark_policy
 |title=Policy For Setting Pass Marks
 |work=Exams &amp; Admissions
 |publisher=[[Casualty Actuarial Society]]
 |accessdate=June 12, 2013
 |ref={{harvid|CAS|2001}}
}}
*{{cite web
 |year=2008
 |url=http://www.casact.org/about/index.cfm?fa=aboutTheCAS
 |title=History
 |work=CAS Overview
 |publisher=[[Casualty Actuarial Society]]
 |accessdate=August 14, 2011
 |ref={{harvid|CASF|2008}}
}}
*{{cite web
 |url=http://www.casact.org/admissions/syllabus/index.cfm?fa=main
 |title=Syllabus of Basic Education
 |accessdate=January 10, 2018
 |year=2018
 |work=Exams &amp; Admissions
 |publisher=[[Casualty Actuarial Society]]
 |ref={{harvid|CAS|2018}}
}}
*{{cite web
 |url=http://www.news.wisc.edu/12874
 |title=James C. Hickman, former business school dean, dies
 |accessdate=January 11, 2008
 |last=Chaptman
 |first=Dennis
 |date=September 13, 2006
 |work=News
 |publisher=[[University of Wisconsin–Madison]]
 |ref=harv
}}
*{{cite journal
 |last        = Coleman
 |first       = Lynn G.
 |date        = Spring 2003
 |title       = Was "About Schmidt" about actuaries?
 |journal     = The Future Actuary
 |volume      = 12
 |issue       = 1
 |url         = http://www.beanactuary.org/news/futureactuary/2003mar/schmidt.cfm
 |accessdate  = September 24, 2017
 |archiveurl  = https://web.archive.org/web/20060828073431/http://www.beanactuary.org/news/futureactuary/2003mar/schmidt.cfm
 |archivedate = August 28, 2006
 |ref         = harv
 |deadurl     = yes
 |df          = mdy-all
}}
*{{cite web
| url        = http://www.actuaries.org.uk/becoming-actuary/pages/what-can-actuary-earn
| title      = What can an actuary earn?
| last       = Crail
| first      = Mark
| year       = 2014
| publisher  = [[Institute and Faculty of Actuaries]]
| access-date= April 26, 2015
|ref         = harv
}}
*{{cite book
 |last=Cramér
 |first=Harald
 |title=Mathematical Methods of Statistics
 |place=Princeton, NJ
 |publisher=Princeton Univ. Press
 |year=1946
 |isbn=0-691-08004-6
 |oclc=185436716
 |ref=harv
}}
&lt;!-- D --&gt;
*{{cite journal
 |last=D'Arcy
 |first=Stephen P.
 |date=May 1989
 |title=On Becoming An Actuary of the Third Kind
 |journal=Proceedings of the Casualty Actuarial Society
 |volume=LXXVI
 |issue=145
 |pages=45–76
 |url=http://www.casact.org/pubs/proceed/proceed89/89045.pdf
 |format=PDF
 |accessdate=June 28, 2006
 |ref=harv
}}
*{{cite journal
 |last=D'Arcy
 |first=Stephen P.
 |date=November 2005
 |title=On Becoming An Actuary of the Fourth Kind
 |journal=Proceedings of the Casualty Actuarial Society
 |volume=XCII
 |issue=177
 |pages=745–754
 |url=http://www.casact.org/pubs/proceed/proceed05/05755.pdf
 |format=PDF
 |accessdate=July 5, 2007
 |ref=harv
}}
&lt;!-- E --&gt;
*{{cite web
| url            = http://www.essec.edu/news-programs/programs-news-detail/article/actuaire-le-meilleur-metier-du-monde.html
| archiveurl            = https://web.archive.org/web/20151017020830/http://www.essec.edu/news-programs/programs-news-detail/article/actuaire-le-meilleur-metier-du-monde.html
| archivedate            = 2015-10-17
| title          = Actuary, the World's Best Job?
| last1          = &lt;!-- Unnamed Staff writer --&gt;
| date           = February 26, 2014
| publisher      = [[ESSEC Business School]]
| access-date    = May 15, 2015
| ref            = {{harvid|ESSEC|2014}}
}}
* {{cite web
|year=2014
|url=http://www.ezrapenland.com/salary
|title=Actuarial Salary Surveys
|publisher=Ezra Penland
|accessdate=January 10, 2018
|ref={{harvid|Ezra Penland|2016}}
}}
&lt;!-- F --&gt;
*{{cite book
 |last=Feldblum
 |first=Sholom
 |editor=Robert F. Lowe
 |title=Foundations of Casualty Actuarial Science
 |origyear=1990
 |edition=4th
 |year=2001
 |publisher=[[Casualty Actuarial Society]]
 |location=Arlington, Virginia
 |isbn=0-9624762-2-6
 |lccn=2001088378
 |chapter=Introduction
 |ref=harv
}}
&lt;!-- G --&gt;
*{{cite web
 |url         = http://www.aafrc.org/press_releases/gusa/GivingReaches300billion.pdf
 |title       = U.S. charitable giving estimated to be $307.65 billion in 2008
 |work        = Giving USA
 |publisher   = Giving USA Foundation
 |format      = PDF
 |date        = June 10, 2009
 |accessdate  = August 4, 2011
 |archiveurl  = https://web.archive.org/web/20120304192222/http://www.aafrc.org/press_releases/gusa/GivingReaches300billion.pdf
 |archivedate = March 4, 2012
 |ref         = {{harvid|GivingUSA|2009}}
 |deadurl     = yes
 |df          = mdy-all
}}
*{{Cite report
 | author     = Government Accountability Office
 | authorlink = Government Accountability Office
 | date       = February 26, 1980
 | title      = An Actuarial and Economic Analysis of State and Local Government Pension Plans
 | url        = http://www.gao.gov/products/PAD-80-1
 | accessdate = April 29, 2015
 | number     = PAD-80-1
 | ref = {{harvid|GAO|1980}}
}}
*{{Cite report
 | author     = Government Accountability Office
 | authorlink = Government Accountability Office
 | date       = July 10, 2008
 | title      = State and Local Government Pension Plans: Current Structure and Funded Status
 | url        = http://www.gao.gov/products/GAO-08-983T
 | accessdate = April 29, 2015
 | number     = GAO-08-983T
 | ref = {{harvid|GAO|2008}}
}}
*{{cite web
 |url=https://www.gov.uk/government/organisations/government-actuarys-department/about
 |title=About us
 |work=Government Actuary's Department
 |publisher=[[Gov.uk]]
 |year=2015
 |accessdate=April 29, 2015
 |ref={{harvid|Government Actuary's Department|2015}}
}}
&lt;!-- H --&gt;
*{{cite journal
 |last=Halley
 |first=Edmond
 |authorlink=Edmond Halley
 |year=1693
 |title=An Estimate of the Degrees of the Mortality of Mankind, Drawn from Curious Tables of the Births and Funerals at the City of Breslaw; With an Attempt to Ascertain the Price of Annuities upon Lives
 |journal=[[Philosophical Transactions of the Royal Society|Philosophical Transactions of the Royal Society of London]]
 |volume=17
 |pages=596–610
 |url=http://www.york.ac.uk/depts/maths/histstat/halley.pdf
 |format=PDF
 |accessdate=June 21, 2006
 |doi=10.1098/rstl.1693.0007
 |ref=harv
 |issue=192–206
}}
*{{cite news
| last         = Hennessy
| first        = Kathleen
| date         = February 16, 2003
| title        = Actuaries
| url          = https://www.theguardian.com/money/2003/feb/16/wageslaves.careers
| newspaper    = [[The Guardian]]
| department   = Wage slaves: careers profiled
| access-date  = May 4, 2015
| ref          = harv
}}
*{{cite journal
 |last=Heywood 
 |first=Geoffrey 
 |year=1985 
 |title=Edmond Halley: astronomer and actuary 
 |url=http://www.actuaries.org.uk/sites/all/files/documents/pdf/0279-0301.pdf 
 |format=PDF 
 |journal=Journal of the Institute of Actuaries 
 |publisher=[[Institute and Faculty of Actuaries]] 
 |volume=112 
 |issue=2 
 |pages=279–301 
 |doi=10.1017/S002026810004213X 
 |access-date=April 29, 2015 
 |ref=harv 
 |deadurl=bot: unknown 
 |archiveurl=https://web.archive.org/web/20151008222058/http://www.actuaries.org.uk/sites/all/files/documents/pdf/0279-0301.pdf 
 |archivedate=October 8, 2015 
 |df=mdy 
}}
*{{cite web
 |url=http://www.wiley.co.uk/eoas/pdfs/TAH012-.pdf
 |title=History of Actuarial Profession
 |accessdate=2006-06-28
 |last=Hickman
 |first=James
 |year=2004
 |format=PDF
 |work=Encyclopedia of Actuarial Science
 |publisher=John Wiley &amp; Sons, Ltd.
 |page=4
 |ref=harv
 |archiveurl = https://web.archive.org/web/20040804113004/http://www.wiley.co.uk/eoas/pdfs/TAH012-.pdf
 |archivedate = August 4, 2004
}}
&lt;!-- I --&gt;
*{{cite web
 |year=2011
 |url=http://www.actuaries.org.uk/becoming-actuary/pages/our-qualifications
 |title=Our qualifications
 |work=Student
 |publisher=[[Institute and Faculty of Actuaries]]
 |accessdate=February 27, 2012
 |ref={{harvid|Institute and Faculty of Actuaries|2011a}}
}}
*{{cite journal
 |date=May 2011 
 |title=Actuaries in Risk Management Actuarial Profession Survey 2010/2011 
 |publisher=[[Institute and Faculty of Actuaries]] 
 |format=PDF 
 |accessdate=February 27, 2012 
 |url=http://www.actuaries.org.uk/sites/all/files/documents/pdf/acturariesinriskmanagement.pdf 
 |ref={{harvid|Institute and Faculty of Actuaries|2011b}} 
 |deadurl=bot: unknown 
 |archiveurl=https://web.archive.org/web/20120320062438/http://www.actuaries.org.uk/sites/all/files/documents/pdf/acturariesinriskmanagement.pdf 
 |archivedate=March 20, 2012 
 |df=mdy 
}}
*{{cite journal
 |author      = &lt;!--Staff writer(s); no by-line.--&gt;
 |title       = Practice areas
 |url         = http://www.actuaries.org.uk/research-and-resources/documents/ifoas-official-guide-becoming-actuary-2014-2015
 |journal     = The official guide to Becoming an Actuary
 |publisher   = [[Institute and Faculty of Actuaries]]
 |format      = PDF
 |date        = September 26, 2014
 |access-date = September 24, 2017
 |archiveurl  = https://www.liverpool.ac.uk/media/livacuk/maths/IFoA,official,guide,to,Becoming,an,Actuary,2014-2015.pdf
 |archivedate = September 26, 2014
 |ref         = {{harvid|Institute and Faculty of Actuaries|2014}}
}}
&lt;!-- J --&gt;
*{{cite book
 |last=Johnston
 |first=Harold Whetstone
 |authorlink=Harold Whetstone Johnston
 |others=Revised by Mary Johnston
 |title=The Private Life of the Romans
 |origyear=1903
 |url=http://www.forumromanum.org/life/johnston.html
 |accessdate=June 26, 2006
 |year=1932
 |publisher=Scott, Foresman and Company
 |location=Chicago, Atlanta
 |lccn=32007692
 |pages=§475–§476
 |chapter=Burial places and funeral ceremonies
 |chapterurl=http://www.forumromanum.org/life/johnston_14.html
 |quote=Early in the Empire, associations were formed for the purpose of meeting the funeral expenses of their members, whether the remains were to be buried or cremated, or for the purpose of building columbāria, or for both&amp;nbsp;... If the members had provided places for the disposal of their bodies after death, they now provided for the necessary funeral expenses by paying into the common fund weekly a small fixed sum, easily within the reach of the poorest of them. When a member died, a stated sum was drawn from the treasury for his funeral&amp;nbsp;... If the purpose of the society was the building of a columbārium, the cost was first determined and the sum total divided into what we should call shares (sortēs virīlēs), each member taking as many as he could afford and paying their value into the treasury.
 |ref={{harvid|Johnston|1903|loc=§475–§476}}
 |isbn=0-8154-0453-0
}}
&lt;!-- K --&gt;
*{{cite journal
 |last=Kendall
 |first=David
 |authorlink=David George Kendall
 |year=1983
 |title=A Tribute to Harald Cramer
 |journal=[[Journal of the Royal Statistical Society]]. Series A (General)
 |volume=146
 |issue=3
 |pages=211–212
 |publisher=[[Wiley-Blackwell|Blackwell Publishing]]
 |location=[[Oxford]], [[England]]
 |issn=0035-9238
 |jstor=2981652
 |ref=harv
}}
*{{cite journal
| last       = Kiviat
| first      = Barbara
| date       = November 13, 2008
| title      = Where the Recession-Proof Jobs Are
| url        = http://content.time.com/time/business/article/0,8599,1858788,00.html
| journal    = [[Time (magazine)|Time]]
| access-date= May 15, 2015
| ref        = harv
}}
*{{cite journal
 |last=Krutov
 |first=Alex
 |year=2006
 |title=Insurance Linked Securities
 |journal=Financial Engineering News magazine
 |issue=48
 |url=http://www.fenews.com/fen48/one_time_articles/insurance/insurance.html
 |accessdate=November 30, 2006
 |archive-url=https://web.archive.org/web/20070609100011/http://www.fenews.com/fen48/one_time_articles/insurance/insurance.html
 |archive-date=June 9, 2007
 |ref=harv
}}
*{{cite news
| last         = Kurtz
| first        = Annalyn
| date         = April 25, 2013
| title        = The best job you never thought of
| url          = http://money.cnn.com/2013/04/25/news/economy/best-job-actuary/
| newspaper    = [[CNN]]
| department   = Money
| access-date  = May 4, 2015
| ref          = harv
}}
&lt;!-- L --&gt;
*{{cite journal
| last = Lewin
| first = Chris
| date = June 14, 2007
| title = Actuarial History
| publisher = [[Institute and Faculty of Actuaries]]
| accessdate = February 27, 2012
| url = http://www.actuaries.org.uk/research-and-resources/documents/overview-actuarial-history-slides-notes
| ref = {{harvid|Lewin|2007}}
}}
*{{cite journal
 |last=Loan
 |first=Albert
 |date=Winter 1991–1992
 |title=Institutional Bases of the Spontaneous Order: Surety and Assurance
 |journal=Humane Studies Review
 |volume=7
 |issue=1
 |url=http://mason.gmu.edu/~ihs/w91essay.html
 |accessdate=June 26, 2006
 |ref={{harvid|Loan|1992}}
}}
&lt;!-- M --&gt;
*{{cite journal
 |last=MacGinnitie
 |first=James
 |date=November 1980
 |title=The Actuary and his Profession: Growth, Development, Promise
 |journal=Proceedings of the Casualty Actuarial Society
 |volume=LXVII
 |issue=127
 |pages=49–56
 |url=https://www.casact.org/pubs/proceed/proceed80/80049.pdf
 |format=PDF
 |accessdate=July 20, 2015
 |ref=harv
}}
*{{cite journal
 |last=Michelbacher
 |first=Gustav F.
 |year=1920
 |title=The Technique of Rate Making as Illustrated by the 1920 National Revision of Workmen's Compensations Insurance Rates
 |journal=Proceedings of the Casualty Actuarial Society
 |volume=VI
 |issue=14
 |pages=201–249
 |url=http://www.casact.org/pubs/proceed/proceed19/19201.pdf
 |format=PDF
 |accessdate=June 28, 2006
 |ref=harv
}}
*{{cite journal
 |last=Muckart
 |first=Richard
 |year=2010
 |title=Q&amp;A: Making the grade
 |journal=The Actuary
 |volume=
 |issue=
 |url=http://www.theactuary.com/archive/old-articles/part-5/richard-muckart-q-26a-3A-making-the-grade/
 |accessdate=June 13, 2013
 |ref=harv
}}
*{{cite journal
| last1      = Mungan
| first1     = Kenneth P.
| year       = 2002
| title      = The Practicing Investment Actuary
| url        = https://www.soa.org/library/proceedings/record-of-the-society-of-actuaries/2000-09/2002/january/rsa02v28n35pd.pdf
| journal    = The Record
| publisher  = [[Society of Actuaries]]
| volume     = 28
| issue      = 3
| pages      = 1–27
| access-date= May 4, 2015
| ref        = harv
}}
&lt;!-- N --&gt;
*{{cite news
 |last=Needleman
 |first=Sarah E.
 |date=January 5, 2010
 |url=https://www.wsj.com/articles/SB10001424052748703580904574638321841284190
 |title=The Best and Worst Jobs
 |work=[[Wall Street Journal]]
 |accessdate=January 7, 2010
 |ref=harv
}}
*{{cite conference
 |first=Ragnar
 |last=Norberg
 |year=1990
 |title=Actuarial Statistics&amp;nbsp;– The European Perspective
 |work=International Conference on the Teaching of Statistics 3, Dunedin, New Zealand
 |publisher=International Association for Statistical Education
 |location=Auckland, New Zealand
 |pages=405–410
 |url=http://www.stat.auckland.ac.nz/~iase/publications/18/BOOK2/B7-2.pdf
 |format=PDF
 |accessdate=February 27, 2012
 |ref=harv
}}
&lt;!-- O --&gt;
*{{cite journal
 |last=Ogborn 
 |first=M.E. 
 |date=December 1956 
 |title=The Professional Name of Actuary 
 |journal=Journal of the Institute of Actuaries 
 |volume=82 
 |pages=233–246 
 |url=http://www.actuaries.org.uk/sites/all/files/documents/pdf/0233-0246.pdf 
 |format=PDF 
 |accessdate=April 27, 2011 
 |publisher=Faculty and Institute of Actuaries 
 |ref=harv 
 |deadurl=bot: unknown 
 |archiveurl=https://web.archive.org/web/20120320062211/http://www.actuaries.org.uk/sites/all/files/documents/pdf/0233-0246.pdf 
 |archivedate=March 20, 2012 
 |df=mdy 
}}
*{{cite journal
 |last=Ogborn 
 |first=M.E. 
 |date=July 1973 
 |url=http://www.actuaries.org.uk/sites/all/files/documents/pdf/0005-0014.pdf 
 |title=Catalogue of an exhibition illustrating the history of actuarial science in the United Kingdom 
 |journal=Journal of the Institute of Actuaries 
 |volume=100 
 |format=PDF 
 |pages=7–8 
 |publisher=Faculty and Institute of Actuaries 
 |accessdate=April 27, 2011 
 |ref=harv 
 |deadurl=bot: unknown 
 |archiveurl=https://web.archive.org/web/20120320062145/http://www.actuaries.org.uk/sites/all/files/documents/pdf/0005-0014.pdf 
 |archivedate=March 20, 2012 
 |df=mdy 
}}
&lt;!-- P --&gt;
*{{cite book
 |last=Perkins
 |first=Judith
 |title=The Suffering Self; Pain and Narrative Representation in the Early Christian Era
 |date=August 25, 1995
 |publisher=[[Routledge]]
 |location=London, England
 |isbn=0-415-11363-6
 |lccn=94042650
 |ref=harv
}}
*{{cite journal
| last       = Prevosto
| first      = Virgnia R.
| date       = December 2000
| title      = CAS Board of Directors Approves New Pass Mark Disclosure Policy
| url        = http://www.casact.org/newsletter/pdfUpload/ff/dec00.pdf
| format     = PDF
| journal    = Future Fellows
| publisher  = [[Casualty Actuarial Society]]
| access-date=May 4, 2015
| ref        = harv
}}
&lt;!-- Q --&gt;
&lt;!-- R --&gt;
*{{cite web
| url            = http://sites.mediaplanet.com/stem-education/actuaries-in-action-why-its-rated-the-number-one-profession
| title          = Actuaries in action: Why it's rated the number one profession
| last1          = Riley
| first1         = Cindy
| year           = 2013
| series         = STEM Education
| archive-url    = https://web.archive.org/web/20140223044227/http://sites.mediaplanet.com/stem-education/actuaries-in-action-why-its-rated-the-number-one-profession
| archivedate=February 23, 2014| access-date    = July 20, 2015
| ref            = harv
}}
&lt;!-- S --&gt;
*{{cite journal
 |work=[[Wired (magazine)|Wired Magazine]]
 |date=March 2009
 |volume=17
 |issue=3
 |url=http://archive.wired.com/techbiz/it/magazine/17-03/wp_quant
 |title=Recipe for Disaster: The Formula That Killed Wall Street
 |first=Felix
 |last=Salmon
 |access-date=May 1, 2015
 |ref = harv
}}
*{{cite journal
| last       = Seltzer
| first      = Frederic
| last2      = Alin
| first2     = Steven I.
| date       = 1969
| title      = The First American Actuary
| url        = https://www.soa.org/library/newsletters/the-actuary/1969/october/act-1969-vol03-iss08-alin-seltzer.pdf
| journal    = The Actuary
| publisher  = [[Society of Actuaries]]
| volume     = 3
| issue      = 8
| access-date= May 1, 2015
| ref        = harv
}}
*{{cite news
| last         = Shavin
| first        = Naomi
| date         = June 13, 2014
| title        = The 12 Best Jobs For Women In 2014
| url          = https://www.forbes.com/sites/naomishavin/2014/06/13/the-12-best-jobs-for-women-in-2014/
| newspaper    = [[Forbes]]
| access-date  = May 15, 2015
| ref          = harv
}}
*{{cite journal
 |last=Sieger
 |first=Richard
 |date=March 1998
 |title=What is an Actuary?
 |journal=Future Fellows
 |volume=4
 |issue=1
 |url=http://www.casact.org/admissions/futfell/mar98/whatis.htm
 |accessdate=July 20, 2015
 |ref=harv
}}
*{{cite book
 |last=Slud
 |first=Eric V.
 |title=Actuarial Mathematics and Life-Table Statistics
 |origyear=2001
 |url=http://www.math.umd.edu/~slud/s470/BookChaps/01Book.pdf
 |format=PDF
 |accessdate=June 28, 2006
 |year=2006
 |pages=149–150
 |chapter=6: Commutation Functions, Reserves &amp; Select Mortality
 |chapterurl=http://www.math.umd.edu/~evs/s470/BookChaps/Chp6.pdf
 |quote=The Commutation Functions are a computational device to ensure that net single premiums&amp;nbsp;... can all be obtained from a single table lookup. Historically, this idea has been very important in saving calculational labor when arriving at premium quotes. Even now&amp;nbsp;... company employees without quantitative training could calculate premiums in a spreadsheet format with the aid of a life table.
 |ref=harv
}}
*{{cite web
 |url=https://www.soa.org/education/general-info/admin-req/edu-admission-req.aspx
 |title=Admission Requirements to the SOA
 |accessdate=January 10, 2018
 |year=2018
 |work=Education &amp; Exams
 |publisher=[[Society of Actuaries]]
 |ref={{harvid|SOA|2018}}
}}
*{{cite journal
 |date=October 1984
 |title=Oswald Jacoby
 |url=https://www.soa.org/library/research/transactions-of-society-of-actuaries/1980-89/1984/january/tsa84v3622.aspx
 |format=PDF
 |department=Obituary
 |journal=Transactions of the Society of Actuaries
 |publisher=[[Society of Actuaries]]
 |volume=36
 |issue=
 |page=616
 |accessdate=March 5, 2016
 |ref={{harvid|SOA|1984}}
 }}
*{{cite book
 |last=Stearns
 |first=Frank Preston
 |title=Cambridge sketches
 |url=http://www.gutenberg.org/cache/epub/7255/pg7255-images.html
 |format=text
 |accessdate=June 10, 2015
 |edition=1st
 |year=1905
 |publisher=[[J. B. Lippincott &amp; Co.|J. B. Lippincott Company]]
 |location=Philadelphia, Pennsylvania
 |lccn=05011051
 |chapter=Elizur Wright
 |quote=This danger could only be averted by placing their rates of insurance on a scientific basis, which should be the same and unalterable for all companies.&amp;nbsp;... After two or three interviews with Elizur Wright the presidents of the companies came to the conclusion that he was exactly the man that they wanted, and they commissioned him to draw up a revised set of tables and rates which could serve them for a uniform standard.
 |ref=harv
}}
*{{cite journal
| last       = Stefan
| first      = Michael
| year       = 2010
| title      = Careers: Breaking the actuarial ceiling
| url        = http://www.theactuary.com/archive/old-articles/part-6/careers-3A-breaking-the-actuarial-ceiling/
| journal    = The Actuary
| publisher  = [[Institute and Faculty of Actuaries]]
| access-date= April 27, 2015
| ref        = harv
}}
*{{cite book
| last          = Sweeting
| first         = Paul
| title         = Financial Enterprise Risk Management
| series        = International Series on Actuarial Science
| year          = 2011
| publisher     = [[Cambridge University Press]]
| isbn          = 978-0-521-11164-5
| lccn          = 2011025050
| ref           = harv
}}
&lt;!-- T --&gt;
*{{cite web
 |last=Thomas
 |first=David
 |year=2012
 |url=http://www.efinancialnews.com/story/2012-04-12/the-best-and-worst-jobs-in-finance
 |title=Be happy: Become an actuary
 |accessdate=April 18, 2012
 |ref=harv
}}
*{{cite book
 |last=Thucydides
 |authorlink=Thucydides
 |translator=Richard Crawley
 |translator-link=Richard Crawley
 |title=The History of the Peloponnesian War
 |url=http://classics.mit.edu/Thucydides/pelopwar.html
 |accessdate=October 28, 2014
 |origyear=c. 431 [[Common Era|BCE]]
 |year=2009
 |location=Greece
 |chapter=VI&amp;nbsp;– Funeral Oration of Pericles
 |chapterurl=http://classics.mit.edu/Thucydides/pelopwar.2.second.html
 |quote=My task is now finished&amp;nbsp;... those who are here interred have received part of their honours already, and for the rest, their children will be brought up till manhood at the public expense: the state thus offers a valuable prize, as the garland of victory in this race of valour, for the reward both of those who have fallen and their survivors.
 |ref={{harvid|Thucydides}}
 |isbn=0-525-26035-8
}}
*{{cite book
|editor1-last = Manton
|editor1-first = Kenneth G.
|editor2-last =  Singer
|editor2-first = Burton
|editor3-last = Suzman
|editor3-first = Richard M.
|last1= Tolley
|first1=H. Dennis
|last2=Hickman
|first2=James C.
|last3=Lew
|first3=Edward A.
|year= 2012
|chapter= Actuarial and Demographic Forecasting Methods
|title= Forecasting the Health of Elderly Populations
|series=Springer Series in Statistics
|publisher= Springer Science &amp; Business Media
|page= 42
|isbn=978-1-4613-9332-0
|lccn=92048819
|ref= {{harvid|Tolley|Hickman|Lew|2012}}
}}
*{{cite journal
 |last        = Trowbridge
 |first       = Charles L.
 |year        = 1989
 |url         = http://www.actuarialfoundation.org/research_edu/fundamental.pdf
 |format      = PDF
 |title       = Fundamental Concepts of Actuarial Science
 |publisher   = Actuarial Education and Research Fund
 |version     = Revised Edition
 |accessdate  = June 28, 2006
 |ref         = harv
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20060629155610/http://www.actuarialfoundation.org/research_edu/fundamental.pdf
 |archivedate = June 29, 2006
 |df          = mdy-all
}}
&lt;!-- U --&gt;
*{{cite journal
| last       = Ugwumadu
| first      = Judith
| date       = September 12, 2013
| title      = Actuary one of ten best UK jobs, says study
| url        = http://www.theactuary.com/news/2013/09/actuary-one-of-ten-best-uk-jobs-says-study/
| journal    = The Actuary
| publisher  = [[Institute and Faculty of Actuaries]]
| access-date= May 15, 2015
| ref        = harv
}}
&lt;!-- V --&gt;
&lt;!-- W --&gt;
*{{cite web
| url        = https://www.soa.org/library/newsletters/the-actuary-magazine/2006/april/act-serving-expert.aspx#sthash.bSeFX0mq.dr5GdDWS.dpbs
| title      = Is Serving as an Expert Witness in Your Future? You be the Judge
| last       = Wagner
| first      = Darryl G.
| year       = 2006
| publisher  = [[Society of Actuaries]]
| access-date= April 26, 2015
| ref        = harv
}}
*{{cite news
 |last=Weber
 |first=Lauren
 |year=2013
 |url=https://blogs.wsj.com/atwork/2013/04/22/dust-off-your-math-skills-actuary-is-best-job-of-2013/
 |title=Dust Off Your Math Skills: Actuary Is Best Job of 2013
 |accessdate=April 24, 2013
 |ref=harv
 |work=The Wall Street Journal
}}
*{{cite news
 |first=Shane 
 |last=Whelan 
 |url=http://www.the-actuary.org.uk/pdfs/02_12_08.pdf 
 |title=Actuaries' contributions to financial economics 
 |work=The Actuary 
 |publisher=Staple Inn Actuarial Society 
 |pages=34–35 
 |date=December 2002 
 |accessdate=June 28, 2006 
 |format=PDF 
 |ref=harv 
 |archiveurl=https://web.archive.org/web/20060724173342/http://www.the-actuary.org.uk/pdfs/02_12_08.pdf 
 |archivedate=July 24, 2006 
 |deadurl=yes 
 |df= 
}}
*{{cite news
 |first=Mary
 |last=Williams Walsh
 |title=Robert J. Myers, Actuary Who Shaped Social Security Program, Dies at 97
 |url=https://www.nytimes.com/2010/02/26/business/26myers.html?ref=obituaries
 |work=[[The New York Times]]
 |date=February 25, 2010
 |accessdate=August 19, 2015
 |ref = harv
}}
{{refend}}

==External links==
{{Wiktionary}}
* [http://www.beanactuary.com/ Be An Actuary: The SOA and CAS jointly sponsored web site]
* [http://www.actuarialoutpost.com/actuarial_discussion_forum/index.php Global actuarial discussion forum] and [http://www.actuarialoutpost.com/wiki actuarial wiki]

{{Featured article}}

[[Category:Actuarial science]]
[[Category:Mathematical science occupations]]
[[Category:Financial services occupations]]</text>
      <sha1>8fwy5nysq9penqd431z02o3sravu8qd</sha1>
    </revision>
  </page>
  <page>
    <title>Atomic formula</title>
    <ns>0</ns>
    <id>4472066</id>
    <revision>
      <id>869229385</id>
      <parentid>840261394</parentid>
      <timestamp>2018-11-17T06:58:54Z</timestamp>
      <contributor>
        <username>Zargles</username>
        <id>34525848</id>
      </contributor>
      <comment>/* Atomic formula in first-order logic */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3696">{{about|a concept in mathematical logic|the concept from chemistry|chemical formula}}
{{short description|mathematical logic concept}}
In [[mathematical logic]], an '''atomic formula''' (also known simply as an '''atom''') is a [[formula (mathematical logic)|formula]] with no deeper [[proposition]]al structure, that is, a formula that contains no [[logical connective]]s or equivalently a formula that has no strict [[subformula]]s. Atoms are thus the simplest [[well-formed formula]]s of the logic. Compound formulas are formed by combining the atomic formulas using the logical connectives.

The precise form of atomic formulas depends on the logic under consideration; for [[propositional logic]], for example, the atomic formulas are the [[propositional variable]]s. For [[predicate logic]], the atoms are predicate symbols together with their arguments, each argument being a [[first-order logic#Formation rules|term]].  In [[model theory]], atomic formula are merely [[string (computer science)|strings]] of symbols with a given [[signature (logic)|signature]], which may or may not be [[satisfiable]] with respect to a given model.&lt;ref&gt;{{cite book|author1=Wilfrid Hodges|title=A Shorter Model Theory|year=1997|publisher=Cambridge University Press|isbn=0-521-58713-1|pages=11–14}}&lt;/ref&gt;

==Atomic formula in first-order logic==
The well-formed terms and propositions of ordinary [[first-order logic]] have the following [[syntax]]:

[[Term algebra|Terms]]:
*  &lt;math&gt;t \equiv c \mid x \mid f (t_{1},\dotsc, t_{n})&lt;/math&gt;,

that is, a term is [[recursive definition|recursively defined]] to be a constant ''c'' (a named object from the [[domain of discourse]]), or a variable ''x'' (ranging over the objects in the domain of discourse), or an ''n''-ary function ''f'' whose arguments are terms ''t''&lt;sub&gt;''k''&lt;/sub&gt;. Functions map [[tuple]]s of objects to objects.

Propositions:
* &lt;math&gt;A, B, ... \equiv P (t_{1},\dotsc, t_{n}) \mid A \wedge B \mid \top \mid A \vee B \mid \bot \mid A \supset B \mid \forall x.\ A \mid \exists x.\ A &lt;/math&gt;,

that is, a proposition is recursively defined to be an ''n''-ary [[predicate (mathematics)|predicate]] ''P'' whose arguments are terms ''t''&lt;sub&gt;''k''&lt;/sub&gt;, or an expression composed of [[logical connective]]s (and, or) and [[Quantifier (logic)|quantifier]]s (for-all, there-exists) used with other propositions.

An '''atomic formula''' or '''atom''' is simply a predicate applied to a tuple of terms; that is, an atomic formula is a formula of the form ''P'' (''t''&lt;sub&gt;1&lt;/sub&gt; ,…, ''t''&lt;sub&gt;''n''&lt;/sub&gt;) for ''P'' a predicate, and the ''t''&lt;sub&gt;''n''&lt;/sub&gt; terms.

All other well-formed formulae are obtained by composing atoms with logical connectives and quantifiers.

For example, the formula ∀''x. P'' (''x'') ∧ ∃''y. Q'' (''y'', ''f'' (''x'')) ∨ ∃''z. R'' (''z'') contains the atoms
* &lt;math&gt; P (x) &lt;/math&gt;
* &lt;math&gt;Q (y, f (x))&lt;/math&gt;
* &lt;math&gt;R (z)&lt;/math&gt;

When all of the terms in an atom are [[ground term]]s, then the atom is called a [[ground atom]] or ''ground predicate''.

== See also ==

* In [[model theory]], [[Structure (mathematical logic)|structures]] assign an interpretation to the atomic formulas.
* In [[proof theory]], [[Polarity (proof theory)|polarity]] assignment for atomic formulas is an essential component of [[focusing (proof theory)|focusing]].
* [[Atomic sentence]]

== References ==
{{reflist}}

== Further reading ==
* {{cite book | author = Hinman, P. | title = Fundamentals of Mathematical Logic | publisher = A K Peters | year = 2005 | isbn = 1-56881-262-0}}

[[Category:Predicate logic]]
[[Category:Logical expressions]]

[[de:Aussage (Logik)#einfache Aussagen - zusammengesetzte Aussagen]]</text>
      <sha1>1b1gj2oz3mmuinrk2hduaaiz1qaoysr</sha1>
    </revision>
  </page>
  <page>
    <title>Bicategory</title>
    <ns>0</ns>
    <id>545861</id>
    <revision>
      <id>829536410</id>
      <parentid>816510248</parentid>
      <timestamp>2018-03-09T06:55:02Z</timestamp>
      <contributor>
        <username>Siddharthist</username>
        <id>28122572</id>
      </contributor>
      <comment>Add {{category theory}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1993">In [[mathematics]], a '''bicategory''' (or a '''weak 2-category''') is a concept in [[category theory]] used to extend the notion of [[Category (mathematics)|category]] to handle the cases where the composition of morphisms is not (strictly) [[associative]], but only associative ''[[up to]]'' an isomorphism. The notion was introduced in 1967 by [[Jean Bénabou]].

Formally, a bicategory '''B''' consists of:
* objects ''a'', ''b''... called ''0-cells'';
* morphisms ''f'', ''g'', ... with fixed source and target objects called ''1-cells'';
* "morphisms between morphisms" ρ, σ... with fixed source and target morphisms (which should have themselves the same source and the same target), called ''2-cells'';
with some more structure:
* given two objects ''a'' and ''b'' there is a category '''B'''(''a'', ''b'') whose objects are the 1-cells and morphisms are the 2-cells, the composition in this category is called ''vertical composition'';
* given three objects ''a'', ''b'' and ''c'', there is a bifunctor &lt;math&gt;*:\mathbf{B}(b,c)\times\mathbf{B}(a,b)\to\mathbf{B}(a,c)&lt;/math&gt; called ''horizontal composition''.
The horizontal composition is required to be associative up to a natural isomorphism α between morphisms &lt;math&gt;h*(g*f)&lt;/math&gt; and &lt;math&gt;(h*g)*f&lt;/math&gt;. Some more coherence axioms, similar to those needed for [[monoidal category|monoidal categories]], are moreover required to hold.

Bicategories may be considered as a weakening of the definition of [[2-categories]]. A similar process for 3-categories leads to [[tricategory|tricategories]], and more generally to [[weak n-category|weak ''n''-categories]] for [[n-category|''n''-categories]].

== References ==
* J. Bénabou. "Introduction to bicategories, part I". In ''Reports of the Midwest Category Seminar'', Lecture Notes in Mathematics 47, pages 1-77. Springer, 1967.

== External links ==
* {{Nlab|id=bicategory|title=bicategory}}

{{category theory}}

[[Category:Higher category theory]]


{{categorytheory-stub}}</text>
      <sha1>ft3sg1ayqur4doe91gkjpvxw436yr8z</sha1>
    </revision>
  </page>
  <page>
    <title>Cosmos (category theory)</title>
    <ns>0</ns>
    <id>46926054</id>
    <revision>
      <id>718669805</id>
      <parentid>698759260</parentid>
      <timestamp>2016-05-04T22:13:27Z</timestamp>
      <contributor>
        <username>GeoffreyT2000</username>
        <id>21491290</id>
      </contributor>
      <comment>Removed hatnote per [[WP:NAMB]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="508">In the area of mathematics known as [[category theory]], a '''cosmos''' is a [[symmetric monoidal category|symmetric]] [[closed monoidal category]] that is [[complete category|complete]] and [[cocomplete category|cocomplete]].&lt;ref&gt;{{nlab|id=cosmos}}&lt;/ref&gt; [[Enriched category theory]] is often considered over a cosmos.&lt;ref&gt;[http://www.tac.mta.ca/tac/reprints/articles/10/tr10.pdf Basic Concepts of Enriched Category Theory]&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Category theory]]

{{cattheory-stub}}</text>
      <sha1>cjmrtzvsp414fyszysmpcjumqma66yp</sha1>
    </revision>
  </page>
  <page>
    <title>Dirichlet algebra</title>
    <ns>0</ns>
    <id>8984724</id>
    <revision>
      <id>860768406</id>
      <parentid>829840403</parentid>
      <timestamp>2018-09-22T22:52:42Z</timestamp>
      <contributor>
        <username>Nsoum</username>
        <id>19977087</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2515">In [[mathematics]], a '''Dirichlet algebra''' is a particular type of [[C* algebra|algebra]]  associated to a [[compact Hausdorff space]] ''X''.  It is a closed subalgebra of ''C''(''X''), the [[uniform algebra]] of bounded [[continuous functions]] on ''X'', whose real parts are dense in the algebra of bounded continuous real functions on ''X''. The concept was introduced by {{harvs|first=Andrew|last=Gleason|authorlink=Andrew Gleason|year=1957|txt}}.

==Example==

Let &lt;math&gt;\mathcal{R}(X)&lt;/math&gt; be the set of all [[rational function]]s that are continuous on &lt;math&gt;X&lt;/math&gt;; in other words functions that have no [[Pole (complex analysis)|poles]] in &lt;math&gt;X&lt;/math&gt;. Then 

:&lt;math&gt;\mathcal{S} = \mathcal{R}(X) + \bar{\mathcal{R}(X)}&lt;/math&gt;

is a *-subalgebra of &lt;math&gt;C(X)&lt;/math&gt;, and of &lt;math&gt;C\left(\partial X\right)&lt;/math&gt;. If &lt;math&gt;\mathcal{S}&lt;/math&gt; is [[Dense set|dense]] in &lt;math&gt;C\left(\partial X\right)&lt;/math&gt;, we say &lt;math&gt;\mathcal{R}(X)&lt;/math&gt; is a '''Dirichlet algebra'''.

It can be shown that if an operator &lt;math&gt;T&lt;/math&gt; has &lt;math&gt;X&lt;/math&gt; as a [[spectral set]], and &lt;math&gt;\mathcal{R}(X)&lt;/math&gt; is a Dirichlet algebra, then &lt;math&gt;T&lt;/math&gt; has a [[Dilation (operator theory)|normal boundary dilation]]. This generalises [[Sz.-Nagy's dilation theorem]], which can be seen as a consequence of this by letting 

:&lt;math&gt;X=\mathbb{D}.&lt;/math&gt;

==See also==

* [[Subdiagonal algebra]]

==References==

*{{Citation | last1=Gleason | first1=Andrew M. | authorlink = Andrew Gleason | editor1-last=Morse | editor1-first=Marston | editor2-last=Beurling | editor2-first=Arne | editor3-last=Selberg | editor3-first=Atle | title=Seminars on analytic functions: seminar III : Riemann surfaces ; seminar IV : theory of automorphic functions ; seminar V : analytic functions as related to Banach algebras | publisher=Institute for Advanced Study, Princeton | zbl=0095.10103 | year=1957 | volume=2 | chapter=Function algebras | pages=213–226}}
*{{eom|id=d/d120180|title=Dirichlet algebra|first=T. |last=Nakazi}}
*''Completely Bounded Maps and Operator Algebras'' Vern Paulsen, 2002 {{ISBN|0-521-81669-6}}
*{{citation|last=Wermer|first=John|title=Gleason's work on Banach algebras|department=Andrew M. Gleason 1921–2008|editor-first=Ethan D.|editor-last=Bolker|journal=Notices of the American Mathematical Society|volume=56|issue=10|date=November 2009|pages=1248–1251|url=http://www.ams.org/notices/200910/rtx091001236p.pdf}}.

[[Category:Functional analysis]]
[[Category:C*-algebras]]


{{Mathanalysis-stub}}</text>
      <sha1>ddkdp0iubysk37vulzfibmv9tb1t0mu</sha1>
    </revision>
  </page>
  <page>
    <title>Finite-dimensional distribution</title>
    <ns>0</ns>
    <id>6594303</id>
    <revision>
      <id>765889845</id>
      <parentid>724647602</parentid>
      <timestamp>2017-02-17T00:22:01Z</timestamp>
      <contributor>
        <username>Primefac</username>
        <id>11508456</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/Fmadd|Fmadd]] ([[User talk:Fmadd|talk]]) to last version by Kanenas</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3084">{{Unreferenced|date=December 2009}}
In [[mathematics]], '''finite-dimensional distributions''' are a tool in the study of [[Measure theory|measures]] and [[stochastic processes]]. A lot of information can be gained by studying the "projection" of a measure (or process) onto a finite-dimensional [[vector space]] (or finite collection of times).

==Finite-dimensional distributions of a measure==
Let &lt;math&gt;(X, \mathcal{F}, \mu)&lt;/math&gt; be a [[measure space]]. The '''finite-dimensional distributions''' of &lt;math&gt;\mu&lt;/math&gt; are the [[pushforward measure]]s &lt;math&gt;f_{*} (\mu)&lt;/math&gt;, where &lt;math&gt;f : X \to \mathbb{R}^{k}&lt;/math&gt;, &lt;math&gt;k \in \mathbb{N}&lt;/math&gt;, is any measurable function.

==Finite-dimensional distributions of a stochastic process==
Let &lt;math&gt;(\Omega, \mathcal{F}, \mathbb{P})&lt;/math&gt; be a [[probability space]] and let &lt;math&gt;X : I \times \Omega \to \mathbb{X}&lt;/math&gt; be a [[stochastic process]]. The '''finite-dimensional distributions''' of &lt;math&gt;X&lt;/math&gt; are the push forward measures &lt;math&gt;\mathbb{P}_{i_{1} \dots i_{k}}^{X}&lt;/math&gt; on the [[product space]] &lt;math&gt;\mathbb{X}^{k}&lt;/math&gt; for &lt;math&gt;k \in \mathbb{N}&lt;/math&gt; defined by
:&lt;math&gt;\mathbb{P}_{i_{1} \dots i_{k}}^{X} (S) := \mathbb{P} \left\{ \omega \in \Omega \left| \left( X_{i_{1}} (\omega), \dots, X_{i_{k}} (\omega) \right) \in S \right. \right\}.&lt;/math&gt;

Very often, this condition is stated in terms of [[measurable]] [[rectangle]]s:
:&lt;math&gt;\mathbb{P}_{i_{1} \dots i_{k}}^{X} (A_{1} \times \cdots \times A_{k}) := \mathbb{P} \left\{ \omega \in \Omega \left| X_{i_{j}} (\omega) \in A_{j} \mathrm{\,for\,} 1 \leq j \leq k \right. \right\}.&lt;/math&gt;

The definition of the finite-dimensional distributions of a process &lt;math&gt;X&lt;/math&gt; is related to the definition for a measure &lt;math&gt;\mu&lt;/math&gt; in the following way: recall that the [[Law (stochastic processes)|law]] &lt;math&gt;\mathcal{L}_{X}&lt;/math&gt; of &lt;math&gt;X&lt;/math&gt; is a measure on the collection &lt;math&gt;\mathbb{X}^{I}&lt;/math&gt; of all functions from &lt;math&gt;I&lt;/math&gt; into &lt;math&gt;\mathbb{X}&lt;/math&gt;. In general, this is an infinite-dimensional space. The finite dimensional distributions of &lt;math&gt;X&lt;/math&gt; are the push forward measures &lt;math&gt;f_{*} \left( \mathcal{L}_{X} \right)&lt;/math&gt; on the finite-dimensional product space &lt;math&gt;\mathbb{X}^{k}&lt;/math&gt;, where
:&lt;math&gt;f : \mathbb{X}^{I} \to \mathbb{X}^{k} : \sigma \mapsto \left( \sigma (t_{1}), \dots, \sigma (t_{k}) \right)&lt;/math&gt;
is the natural "evaluate at times &lt;math&gt;t_{1}, \dots, t_{k}&lt;/math&gt;" function.

==Relation to tightness==
It can be shown that if a sequence of [[probability measure]]s &lt;math&gt;(\mu_{n})_{n = 1}^{\infty}&lt;/math&gt; is [[Tightness of measures|tight]] and all the finite-dimensional distributions of the &lt;math&gt;\mu_{n}&lt;/math&gt; [[Weak convergence of measures|converge weakly]] to the corresponding finite-dimensional distributions of some probability measure &lt;math&gt;\mu&lt;/math&gt;, then &lt;math&gt;\mu_{n}&lt;/math&gt; converges weakly to &lt;math&gt;\mu&lt;/math&gt;.

==See also==
* [[Law (stochastic processes)]]

{{DEFAULTSORT:Finite-Dimensional Distribution}}
[[Category:Measure theory]]
[[Category:Stochastic processes]]</text>
      <sha1>o0ovtbuoyj3cp37k48rjznnc9ey2fs1</sha1>
    </revision>
  </page>
  <page>
    <title>Fioralba Cakoni</title>
    <ns>0</ns>
    <id>58998821</id>
    <revision>
      <id>867826789</id>
      <timestamp>2018-11-08T07:15:38Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>New article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3398">'''Fioralba Cakoni''' is an Albanian mathematician and an expert on [[inverse scattering theory]]. She is a professor of mathematics at [[Rutgers University]].

==Education and career==
Cakoni earned bachelor's and master's degrees from the [[University of Tirana]] in 1987 and 1990 respectively. She completed her Ph.D. in 1996, jointly between the University of Tirana and [[University of Patras]], supervised by George Dassios.{{r|cv}} Her dissertation was ''Some Results on the Abstract Wave Equation. Problems of the Scattering Theory in Elasticity and Thermoelasticity in Low-Frequency''.{{r|mgp}}

She became a lecturer at the University of Tirana and then, from 1998 to 2000, a Humboldt Research Fellow at the [[University of Stuttgart]]. She came to the US for additional postdoctoral research at the [[University of Delaware]] in 2000, and stayed at Delaware as an assistant professor beginning in 2002. She moved to Rutgers in 2015.{{r|cv}}

==Books==
Cakoni is the author or coauthor of:
*''Qualitative Methods in Inverse Scattering Theory'' (with David Colton,  Springer, 2006){{r|qm}}
*''The Linear Sampling Method in Inverse Electromagnetic Scattering'' (with David Colton and Peter Monk, Society for Industrial and Applied Mathematics, 2011){{r|ls}}
*''A Qualitative Approach to Inverse Scattering Theory'' (with David Colton, Springer, 2014){{r|qa}}
*''Inverse Scattering Theory and Transmission Eigenvalues'' (with David Colton and Houssem Haddar, Society for Industrial and Applied Mathematics, 2016) 

==Recognition==
Cakoni was included in the 2019 class of fellows of the [[American Mathematical Society]] "for contributions to analysis of partial differential equations especially in inverse scattering theory".{{r|fams}}

==References==
{{reflist|refs=

&lt;ref name=cv&gt;{{citation|url=http://sites.math.rutgers.edu/~fc292/Cakoni-CV|title=Curriculum vitae|accessdate=2018-11-07}}&lt;/ref&gt;

&lt;ref name=fams&gt;{{citation|url=https://www.ams.org/profession/ams-fellows/new-fellows|title=2019 Class of the Fellows of the AMS|publisher=[[American Mathematical Society]]|accessdate=2018-11-07}}&lt;/ref&gt;

&lt;ref name=ls&gt;Review of ''The Linear Sampling Method in Inverse Electromagnetic Scattering'':
*{{citation|title=none|journal=Mathematical Reviews|first=Shari L.|last=Moskow|year=2012|mr=2731610}}
&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=26038}}&lt;/ref&gt;

&lt;ref name=qa&gt;Review of ''A Qualitative Approach to Inverse Scattering Theory'':
*{{citation|title=none|journal=Mathematical Reviews|first=Barbara|last=Prinari|mr=3137429}}&lt;/ref&gt;

&lt;ref name=qm&gt;Reviews of ''Qualitative Methods in Inverse Scattering Theory'':
*{{citation|title=none|first=Steven|last=Kusiak|journal=SIAM Review|volume=48|issue=4|date=December 2006|pages=805–807|jstor=20453891}}
*{{citation|title=none|journal=Mathematical Reviews|first=Houssem|last=Haddar|year=2008|mr=2256477}}
&lt;/ref&gt;

}}

==External links==
*[http://sites.math.rutgers.edu/~fc292/ Home page]
*{{Google Scholar id|FApeRDsAAAAJ}}

{{Authority control}}
{{DEFAULTSORT:Cakoni, Fioralba}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:Albanian mathematicians]]
[[Category:American mathematicians]]
[[Category:Women mathematicians]]
[[Category:University of Tirana alumni]]
[[Category:University of Patras alumni]]
[[Category:University of Tirana faculty]]
[[Category:Fellows of the American Mathematical Society]]</text>
      <sha1>3qh6u9cr6m6rwbfrzp15yqgfpka16cc</sha1>
    </revision>
  </page>
  <page>
    <title>Gábor N. Sárközy</title>
    <ns>0</ns>
    <id>31566167</id>
    <revision>
      <id>861375305</id>
      <parentid>787244576</parentid>
      <timestamp>2018-09-26T23:55:12Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2216">'''Gábor N. Sárközy (Gabor Sarkozy)''' is a [[Hungary|Hungarian]]-American mathematician, the son of noted mathematician [[András Sárközy]].  He is currently  on faculty of the Computer Science Department at [[Worcester Polytechnic Institute]], MA, United States and is also a senior research fellow at the [[Alfréd Rényi Institute of Mathematics]] of the [[Hungarian Academy of Sciences]].&lt;ref&gt;[http://www.renyi.hu/~gsarkozy/ Gabor Sarkozy's Renyi Homepage]&lt;/ref&gt;

He obtained a Diploma in Mathematics from [[Eötvös Loránd University]] and a PhD in Computer Science from [[Rutgers University|Rutgers]], under the advisement of [[Endre Szemerédi]].&lt;ref&gt;[http://genealogy.math.ndsu.nodak.edu/id.php?id=70200 The Mathematics Genealogy Project for Endre Szemeredi]&lt;/ref&gt;  
Perhaps his best known result is the [[Blow-Up Lemma]],&lt;ref&gt;J. Komlós, G. N. Sárközy, E. Szemerédi: Blow-up Lemma, "Combinatorica", 17 (1), 1997, pp. 109-123&lt;/ref&gt;&lt;ref&gt;J. Komlós, G. N. Sárközy, E. Szemerédi: An algorithmic version of the Blow-up Lemma, "Random Structures and Algorithms", 12, 1998, pp. 297-312&lt;/ref&gt; in which, together with [[János Komlós (mathematician)|János Komlós]] and [[Endre Szemerédi]] he proved that the regular pairs in [[Szemerédi regularity lemma]] behave like complete bipartite graphs under the correct conditions. The lemma allowed for deeper exploration into the nature of embeddings of large sparse graphs into dense graphs. A hypergraph variant was developed later by [[Peter Keevash]].

He is member of the editorial board of the ''[[European Journal of Combinatorics]]''.&lt;ref&gt;[http://www.elsevier.com/wps/find/journaleditorialboard.cws_home/622824/editorialboard Editorial Board], European Journal of Combinatorics, [[Elsevier]]. Accessed March 31, 2012&lt;/ref&gt;

He also has an [[Erdős number]] of&amp;nbsp;1.&lt;ref&gt;[http://www.emis.ams.org/journals/EJC/Volume_4/PDF/v4i2r08.pdf On Cycles in the Coprime Graph of Integers]&lt;/ref&gt;

==References==
&lt;references/&gt;


{{authority control}}

{{DEFAULTSORT:Sarkozy, Gabor N.}}
[[Category:Combinatorialists]]
[[Category:Theoretical computer scientists]]
[[Category:Hungarian mathematicians]]
[[Category:Living people]]


{{Europe-mathematician-stub}}</text>
      <sha1>d751d2b4arwfl5njczjicacbz9kdw1u</sha1>
    </revision>
  </page>
  <page>
    <title>Hesse's principle of transfer</title>
    <ns>0</ns>
    <id>50664282</id>
    <revision>
      <id>847324261</id>
      <parentid>747516944</parentid>
      <timestamp>2018-06-24T14:24:39Z</timestamp>
      <contributor>
        <username>Ferran Mir</username>
        <id>8381867</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3103">In [[geometry]], '''Hesse's principle of transfer''' ({{lang-de|Uebertragungsprinzip}}) states that if the points of the [[projective line]] '''P'''&lt;sup&gt;1&lt;/sup&gt; are depicted by a [[rational normal curve]] in '''P'''&lt;sup&gt;''n''&lt;/sup&gt;, then the [[Group (mathematics)|group]] of the [[projective transformation]]s of '''P'''&lt;sup&gt;''n''&lt;/sup&gt; that preserve the curve is [[isomorphic]] to the group of the projective transformations of '''P'''&lt;sup&gt;1&lt;/sup&gt; (this is a generalization of the original Hesse's principle, in a form suggested by [[Wilhelm Franz Meyer]]).&lt;ref name="Meyer"&gt;{{cite book|author=W.F. Meyer|title=Apolaritat Und Rationale Curven|url=https://books.google.com/books?id=t-wOAwAAQBAJ|isbn=978-5-87713-744-8}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=_8eaAwAAQBAJ&amp;pg=PA102|title=Elie Cartan (1869–1951)|last=Akivis|first=M. A.|last2=Rosenfeld|first2=B. A.|year=2011|publisher=American Mathematical Soc.|isbn=9780821853559|language=en|pages=102, 107–108}}&lt;/ref&gt; It was originally introduced by [[Otto Hesse]] in 1866, in a more restricted form. It influenced [[Felix Klein]] in the development of the [[Erlangen program]].&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=XTYDCAAAQBAJ&amp;pg=PA111|title=Mathematics of the 19th Century: Geometry, Analytic Function Theory|editor-last=Kolmogorov|editor-first=Andrei N.|editor-last2=Yushkevich|editor-first2=Adolf-Andrei P.|year=2012|publisher=Birkhäuser|isbn=9783034891738|language=en|page=111}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=bvy0aANuhPYC&amp;pg=PA25|title=From a Geometrical Point of View: A Study of the History and Philosophy of Category Theory|last=Marquis|first=Jean-Pierre|year=2008|publisher=Springer Science &amp; Business Media|isbn=9781402093845|language=en|page=25}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=F_NP8Kub2XYC&amp;pg=PA179|title=Perspectives on Projective Geometry: A Guided Tour Through Real and Complex Geometry|last=Richter-Gebert|first=Jürgen|year=2011|publisher=Springer Science &amp; Business Media|isbn=9783642172861|language=en|page=179}}&lt;/ref&gt; Since its original conception, it was generalized by many mathematicians, including [[Felix Klein|Klein]], [[Gino Fano|Fano]], and [[Élie Cartan|Cartan]].&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=QbB7_YOrruoC&amp;pg=PA234|title=Emergence of the Theory of Lie Groups: An Essay in the History of Mathematics 1869–1926|last=Hawkins|first=Thomas|year=2000|publisher=Springer Science &amp; Business Media|isbn=9780387989631|language=en|pages=234 and 294}}&lt;/ref&gt;

==See also==
*[[Rational normal curve]]

==Further reading==
*[[Thomas W. Hawkins Jr.|Hawkins, Thomas]] (1988). "Hesses's principle of transfer and the representation of lie algebras", ''[[Archive for History of Exact Sciences]]'', 39(1), pp. 41–73.

==References==
{{reflist}}

===Original reference===
*Hesse, L. O. (1866). "Ein Uebertragungsprinzip", ''[[Crelle's Journal]]''.

{{geometry-stub}}

[[Category:Projective geometry]]
[[Category:Invariant theory]]
[[Category:Group theory]]
[[Category:Symmetry]]
[[Category:Birational geometry]]</text>
      <sha1>red3e8ciqhvd76zikng2q36o7kqahh4</sha1>
    </revision>
  </page>
  <page>
    <title>Homeotopy</title>
    <ns>0</ns>
    <id>4128810</id>
    <revision>
      <id>590971290</id>
      <parentid>346202558</parentid>
      <timestamp>2014-01-16T14:34:23Z</timestamp>
      <contributor>
        <username>K9re11</username>
        <id>19647483</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1755">{{distinguish|homotopy}}

In [[algebraic topology]], an area of [[mathematics]], a '''homeotopy group''' of a [[topological space]] is a [[homotopy group]] of the group of [[homeomorphism|self-homeomorphism]]s of that space.

==Definition==
The [[homotopy group]] [[functor]]s &lt;math&gt;\pi_k&lt;/math&gt; assign to each [[path-connected]] topological space &lt;math&gt;X&lt;/math&gt; the group &lt;math&gt;\pi_k(X)&lt;/math&gt; of [[homotopy class]]es of continuous maps &lt;math&gt;S^k\to X.&lt;/math&gt;

Another construction on a space &lt;math&gt;X&lt;/math&gt; is the [[Homeomorphism group|group of all self-homeomorphisms]] &lt;math&gt;X \to X&lt;/math&gt;, denoted &lt;math&gt;{\rm Homeo}(X).&lt;/math&gt; If ''X'' is a [[locally compact]], [[locally connected]] [[Hausdorff space]] then a fundamental result of [[R. Arens]] says that &lt;math&gt;{\rm Homeo}(X)&lt;/math&gt; will in fact be a [[topological group]] under the [[compact-open topology]].

Under the above assumptions, the '''homeotopy''' groups for &lt;math&gt;X&lt;/math&gt; are defined to be:

:&lt;math&gt;HME_k(X)=\pi_k({\rm Homeo}(X)).&lt;/math&gt;

Thus &lt;math&gt;HME_0(X)=\pi_0({\rm Homeo}(X))=MCG^*(X)&lt;/math&gt; is the '''extended''' [[mapping class group]] for &lt;math&gt;X.&lt;/math&gt; In other words, the extended mapping class group is the set of connected components of &lt;math&gt;{\rm Homeo}(X)&lt;/math&gt; as specified by the functor &lt;math&gt;\pi_0.&lt;/math&gt;

==Example==
According to the [[Dehn-Nielsen theorem]], if &lt;math&gt;X&lt;/math&gt; is a closed surface then &lt;math&gt;HME_0(X)={\rm Out}(\pi_1(X)),&lt;/math&gt; the [[outer automorphism group]] of its [[fundamental group]].

==References==
*G.S. McCarty. ''Homeotopy groups''. Trans. A.M.S. 106(1963)293-304. 
*R. Arens, ''Topologies for homeomorphism groups'', Amer. J. Math. 68 (1946), 593–610.

[[Category:Algebraic topology]]
[[Category:Homeomorphisms]]

{{topology-stub}}</text>
      <sha1>3y4imaolcqtt2q2ij835zmu9dyh8boa</sha1>
    </revision>
  </page>
  <page>
    <title>Kernel (linear algebra)</title>
    <ns>0</ns>
    <id>1072915</id>
    <revision>
      <id>869491958</id>
      <parentid>869473959</parentid>
      <timestamp>2018-11-18T23:28:35Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>/* External links */ rm per [[WP:ELNO]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21664">{{other uses|Kernel (disambiguation)}}

In [[mathematics]], and more specifically in [[linear algebra]] and [[functional analysis]], the '''kernel''' (also known as '''null space''' or '''nullspace''') of a [[linear map]] {{nowrap|''L'' : ''V'' → ''W''}} between two [[vector space]]s ''V'' and ''W'', is the set of all elements '''v''' of ''V'' for which {{nowrap|1=''L''('''v''') = '''0'''}}, where '''0''' denotes the [[zero vector]] in ''W''.  That is, in [[set-builder notation]],
:&lt;math&gt;\ker(L) = \left\{ \mathbf{v}\in V \mid L(\mathbf{v})=\mathbf{0} \right\}\text{.}&lt;/math&gt;

==Properties==
[[File:KerIm 2015Joz L2.png|thumb|Kernel and image of a map ''L''.|346x346px]]
The kernel of ''L'' is a [[linear subspace]] of the [[Domain of a function|domain]] ''V''.&lt;ref name="textbooks"&gt;Linear algebra, as discussed in this article, is a very well established mathematical discipline for which there are many sources. Almost all of the material in this article can be found in {{harvnb|Lay|2005}}, {{harvnb|Meyer|2001}}, and Strang's lecture.&lt;/ref&gt;
In the linear map {{nowrap|''L'' : ''V'' → ''W''}}, two elements of ''V'' have the same [[image (mathematics)|image]] in ''W'' if and only if their difference lies in the kernel of ''L'':
:&lt;math&gt;L(\mathbf{v}_1) = L(\mathbf{v}_2)\;\Leftrightarrow\;L(\mathbf{v}_1-\mathbf{v}_2)=\mathbf{0}\text{.} &lt;/math&gt;
It follows that the image of ''L'' is [[isomorphism|isomorphic]] to the [[quotient space (linear algebra)|quotient]] of ''V'' by the kernel:
:&lt;math&gt;\mathop{\mathrm{im}}(L) \cong V / \ker(L)\text{.}&lt;/math&gt;
{{anchor|nullity}}This implies the [[rank–nullity theorem]]:
:&lt;math&gt;\dim(\ker L) + \dim(\mathop{\mathrm{im}} L) = \dim(V)\text{.}\,&lt;/math&gt;
where, by ''rank'' we mean the dimension of the image of ''L'', and by ''nullity'' that of the kernel of ''L''.

When ''V'' is an [[inner product space]], the quotient {{nowrap|''V'' / ker(''L'')}} can be identified with the [[orthogonal complement]] in ''V'' of ker(''L'').  This is the generalization to linear operators of the [[row space]], or coimage, of a matrix.

==Application to modules==

{{main|module (mathematics)}}
The notion of kernel applies to the [[homomorphism]]s of modules, the latter being a generalization of the vector space over a [[Field (mathematics)|field]] to that over a [[ring (mathematics)|ring]].
The domain of the mapping is a module, and the kernel constitutes a "[[submodule]]". Here, the concepts of rank and nullity do not necessarily apply.

==In functional analysis==

{{main|topological vector space}}
If ''V'' and ''W'' are [[topological vector space]]s (and ''W'' is finite-dimensional) then a linear operator ''L'':&amp;nbsp;''V''&amp;nbsp;→&amp;nbsp;''W'' is [[continuous linear operator|continuous]] if and only if the kernel of ''L'' is a [[closed set|closed]] subspace of ''V''.

==Representation as matrix multiplication==
Consider a linear map represented as a ''m'' × ''n'' matrix ''A'' with coefficients in a [[field (mathematics)|field]] ''K'' (typically the field of the [[real number]]s or of the [[complex number]]s) and operating on column vectors ''x'' with ''n'' components over ''K''.
The kernel of this linear map is the set of solutions to the equation {{nowrap|1=''A'' '''x''' = '''0'''}}, where '''0''' is understood as the [[zero vector]]. The [[dimension (vector space)|dimension]] of the kernel of ''A'' is called the '''nullity''' of ''A''. In [[set-builder notation]],
:&lt;math&gt;\operatorname{N}(A)=\operatorname{Null}(A)=\operatorname{ker}(A) = \left\{ \mathbf{x}\in K^n | A\mathbf{x} = \mathbf{0} \right\}.&lt;/math&gt;
The matrix equation is equivalent to a homogeneous [[system of linear equations]]:
:&lt;math&gt;A\mathbf{x}=\mathbf{0} \;\;\Leftrightarrow\;\;
\begin{alignat}{7}
a_{11} x_1 &amp;&amp;\; + \;&amp;&amp; a_{12} x_2 &amp;&amp;\; + \;\cdots\; + \;&amp;&amp; a_{1n} x_n &amp;&amp;\; = \;&amp;&amp;&amp; 0      \\
a_{21} x_1 &amp;&amp;\; + \;&amp;&amp; a_{22} x_2 &amp;&amp;\; + \;\cdots\; + \;&amp;&amp; a_{2n} x_n &amp;&amp;\; = \;&amp;&amp;&amp; 0      \\
\vdots\;\;\; &amp;&amp;     &amp;&amp; \vdots\;\;\; &amp;&amp;              &amp;&amp; \vdots\;\;\; &amp;&amp;     &amp;&amp;&amp; \;\vdots \\
a_{m1} x_1 &amp;&amp;\; + \;&amp;&amp; a_{m2} x_2 &amp;&amp;\; + \;\cdots\; + \;&amp;&amp; a_{mn} x_n &amp;&amp;\; = \;&amp;&amp;&amp; 0\text{.}      \\
\end{alignat}&lt;/math&gt;
Thus the kernel of ''A'' is the same as the solution set to the above homogeneous equations.

===Subspace properties===
The kernel of an {{nowrap|''m'' × ''n''}} matrix ''A'' over a field ''K'' is a [[linear subspace]] of '''K'''&lt;sup&gt;''n''&lt;/sup&gt;. That is, the kernel of ''A'', the set Null(''A''), has the following three properties:
# Null(''A'') always contains the [[zero vector]], since {{nowrap|1=''A'''''0''' = '''0'''}}.
# If {{nowrap|'''x''' ∈ Null(''A'')}} and {{nowrap|'''y''' ∈ Null(''A'')}}, then {{nowrap|'''x''' + '''y''' ∈ Null(''A'')}}. This follows from the distributivity of matrix multiplication over addition.
# If {{nowrap|'''x''' ∈ Null(''A'')}} and ''c'' is a [[scalar (mathematics)|scalar]] {{nowrap|''c'' ∈ ''K''}}, then {{nowrap|''c'''''x''' ∈ Null(''A'')}}, since {{nowrap|1=''A''(''c'''''x''') = ''c''(''A'''''x''') = ''c'''''0''' = '''0'''}}.

===The row space of a matrix===
{{main|Rank–nullity theorem}}
The product ''A'''''x''' can be written in terms of the [[dot product]] of vectors as follows:
:&lt;math&gt;A\mathbf{x} = \begin{bmatrix} \mathbf{a}_1 \cdot \mathbf{x} \\ \mathbf{a}_2 \cdot \mathbf{x} \\ \vdots \\ \mathbf{a}_m \cdot \mathbf{x} \end{bmatrix}.&lt;/math&gt;
Here '''a'''&lt;sub&gt;1&lt;/sub&gt;, ... , '''a'''&lt;sub&gt;''m''&lt;/sub&gt; denote the rows of the matrix ''A''. It follows that '''x''' is in the kernel of ''A'' if and only if '''x''' is [[orthogonality|orthogonal]] (or perpendicular) to each of the row vectors of ''A'' (because when the dot product of two vectors is equal to zero, they are by definition orthogonal).

The [[row space]], or coimage, of a matrix ''A'' is the [[linear span|span]] of the row vectors of ''A''. By the above reasoning, the kernel of ''A'' is the [[orthogonal complement]] to the row space. That is, a vector '''x''' lies in the kernel of ''A'' if and only if it is perpendicular to every vector in the row space of ''A''.

The dimension of the row space of ''A'' is called the [[rank (linear algebra)|rank]] of ''A'', and the dimension of the kernel of ''A'' is called the '''nullity''' of ''A''. These quantities are related by the [[rank–nullity theorem]]
:&lt;math&gt;\operatorname{rank}(A) + \operatorname{nullity}(A) = n.&lt;/math&gt;

===[[cokernel|Left null space]]===
The '''left null space''', or cokernel, of a matrix ''A'' consists of all vectors '''x''' such that '''x'''&lt;sup&gt;T&lt;/sup&gt;''A''&amp;nbsp;=&amp;nbsp;'''0'''&lt;sup&gt;T&lt;/sup&gt;, where T denotes the [[transpose]] of a column vector.  The left null space of ''A'' is the same as the kernel of ''A''&lt;sup&gt;T&lt;/sup&gt;.  The left null space of ''A'' is the orthogonal complement to the [[column space]] of ''A'', and is dual to the [[cokernel]] of the associated linear transformation.  The kernel, the row space, the column space, and the left null space of ''A'' are the [[Fundamental theorem of linear algebra|four fundamental subspaces]] associated to the matrix ''A''.

===Nonhomogeneous systems of linear equations===
The kernel also plays a role in the solution to a nonhomogeneous system of linear equations:
:&lt;math&gt;A\mathbf{x}=\mathbf{b}\;\;\;\;\;\;\text{or}\;\;\;\;\;\;\begin{alignat}{7}
a_{11} x_1 &amp;&amp;\; + \;&amp;&amp; a_{12} x_2 &amp;&amp;\; + \;\cdots\; + \;&amp;&amp; a_{1n} x_n &amp;&amp;\; = \;&amp;&amp;&amp; b_1      \\
a_{21} x_1 &amp;&amp;\; + \;&amp;&amp; a_{22} x_2 &amp;&amp;\; + \;\cdots\; + \;&amp;&amp; a_{2n} x_n &amp;&amp;\; = \;&amp;&amp;&amp; b_2      \\
\vdots\;\;\; &amp;&amp;     &amp;&amp; \vdots\;\;\; &amp;&amp;              &amp;&amp; \vdots\;\;\; &amp;&amp;     &amp;&amp;&amp; \;\vdots \\
a_{m1} x_1 &amp;&amp;\; + \;&amp;&amp; a_{m2} x_2 &amp;&amp;\; + \;\cdots\; + \;&amp;&amp; a_{mn} x_n &amp;&amp;\; = \;&amp;&amp;&amp; b_m      \\
\end{alignat}&lt;/math&gt;
If '''u''' and '''v''' are two possible solutions to the above equation, then
:&lt;math&gt;A(\mathbf{u}-\mathbf{v}) = A\mathbf{u} - A\mathbf{v} = \mathbf{b} - \mathbf{b} = \mathbf{0}\,&lt;/math&gt;
Thus, the difference of any two solutions to the equation ''A'''''x'''&amp;nbsp;=&amp;nbsp;'''b''' lies in the kernel of ''A''.

It follows that any solution to the equation ''A'''''x'''&amp;nbsp;=&amp;nbsp;'''b''' can be expressed as the sum of a fixed solution '''v''' and an arbitrary element of the kernel.  That is, the solution set to the equation ''A'''x'''&amp;nbsp;=&amp;nbsp;'''b''' is
:&lt;math&gt;\left\{ \mathbf{v}+\mathbf{x} \mid A \mathbf{v}=\mathbf{b} \land \mathbf{x}\in\operatorname{Null}(A) \right\},&lt;/math&gt;
Geometrically, this says that the solution set to ''A'''''x'''&amp;nbsp;=&amp;nbsp;'''b''' is the [[translation (geometry)|translation]] of the kernel of ''A'' by the vector '''v'''. See also [[Fredholm alternative]] and [[flat (geometry)]].

==Illustration==
We give here a simple illustration of computing the kernel of a matrix (see the section [[#Basis|Basis]] below for methods better suited to more complex calculations.) We also touch on the row space and its relation to the kernel.

Consider the matrix
:&lt;math&gt;A = \begin{bmatrix}\,\,\,2 &amp; 3 &amp; 5 \\ -4 &amp; 2 &amp; 3\end{bmatrix}.&lt;/math&gt;
The kernel of this matrix consists of all vectors (''x'', ''y'', ''z'')&amp;nbsp;∈&amp;nbsp;[[real coordinate space|'''R'''&lt;sup&gt;3&lt;/sup&gt;]] for which
:&lt;math&gt;\begin{bmatrix}\,\,\,2 &amp; 3 &amp; 5 \\ -4 &amp; 2 &amp; 3\end{bmatrix}\begin{bmatrix} x \\ y \\ z\end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix},&lt;/math&gt;
which can be expressed as a homogeneous [[system of linear equations]] involving ''x'', ''y'', and ''z'':
:&lt;math&gt;\begin{alignat}{7}
 2x &amp;&amp;\; + \;&amp;&amp; 3y &amp;&amp;\; + \;&amp;&amp; 5z &amp;&amp;\; = \;&amp;&amp; 0, \\
-4x &amp;&amp;\; + \;&amp;&amp; 2y &amp;&amp;\; + \;&amp;&amp; 3z &amp;&amp;\; = \;&amp;&amp; 0,\\
\end{alignat}&lt;/math&gt;
which can be written in matrix form as:
:&lt;math&gt;
  \left[\begin{array}{ccc|c}
    2 &amp; 3 &amp; 5 &amp; 0 \\
    -4 &amp; 2 &amp; 3 &amp; 0
  \end{array}\right].
&lt;/math&gt;
[[Gauss–Jordan elimination]] reduces this to:
:&lt;math&gt;
  \left[\begin{array}{ccc|c}
    1 &amp; 0 &amp; 1/16 &amp; 0 \\
    0 &amp; 1 &amp; 13/8 &amp; 0
  \end{array}\right].
&lt;/math&gt;
Rewriting yields:
:&lt;math&gt;\begin{alignat}{7}
x = \;&amp;&amp; -\frac{1}{16}z\,\,\, \\
y = \;&amp;&amp; -\frac{13}8z.
\end{alignat}&lt;/math&gt;
Now we can express an element of the kernel:
:&lt;math&gt;\begin{bmatrix} x \\ y \\ z\end{bmatrix} = c \begin{bmatrix} -1/16 \\ -13/8 \\ 1\end{bmatrix}.&lt;/math&gt;
for ''c'' a [[scalar (mathematics)|scalar]].

Since ''c'' is a [[free variable]], this can be expressed equally well as,
:&lt;math&gt;
	\begin{bmatrix}
		x\\
		y\\
		z
	\end{bmatrix} = 
        c \begin{bmatrix}
		 -1\\
		-26\\
		 16
	\end{bmatrix}.
&lt;/math&gt;
The kernel of ''A'' is precisely the solution set to these equations (in this case, a [[line (geometry)|line]] through the origin in '''R'''&lt;sup&gt;3&lt;/sup&gt;); the vector (−1,−26,16)&lt;sup&gt;T&lt;/sup&gt; constitutes a [[Basis (linear algebra)|basis]] of the kernel of ''A''.
Thus, the nullity of ''A'' is 1.

Note also that the following dot products are zero:
:&lt;math&gt;
 \left[\begin{array}{ccc}
    2 &amp; 3 &amp; 5
  \end{array}\right]
 \cdot
 \begin{bmatrix}
		 -1\\
		-26\\
		 16
 \end{bmatrix}
= 0
\quad\mathrm{and}\quad
 \left[\begin{array}{ccc}
    -4 &amp; 2 &amp; 3
 \end{array}\right]
 \cdot
 \begin{bmatrix}
		 -1\\
		-26\\
		 16
 \end{bmatrix}
= 0\mathrm{,}
&lt;/math&gt;
which illustrates that vectors in the kernel of A are orthogonal to each of the row vectors of A.

These two (linearly independent) row vectors span the row space of ''A'', a plane orthogonal to the vector (−1,−26,16)&lt;sup&gt;T&lt;/sup&gt;.

With the rank of ''A'' 2, the nullity of ''A'' 1, and the dimension of ''A'' 3, we have an illustration of the rank-nullity theorem.

==Examples==

* If ''L'':&amp;nbsp;'''R'''&lt;sup&gt;''m''&lt;/sup&gt;&amp;nbsp;→&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt;, then the kernel of ''L'' is the solution set to a homogeneous [[system of linear equations]].  As in the above illustration, if ''L'' is the operator:
::&lt;math&gt;L(x_1,x_2,x_3) = (2x_1 + 3x_2 + 5x_3,\; -4x_1 + 2x_2 + 3x_3)&lt;/math&gt;
:then the kernel of ''L'' is the set of solutions to the equations
::&lt;math&gt;\begin{alignat}{7}
    2x_1 &amp;\;+\;&amp; 3x_2 &amp;\;+\;&amp; 5x_3 &amp;\;=\;&amp; 0 \\
   -4x_1 &amp;\;+\;&amp; 2x_2 &amp;\;+\;&amp; 3x_3 &amp;\;=\;&amp; 0
\end{alignat}&lt;/math&gt;
* Let ''C''[0,1] denote the [[vector space]] of all continuous real-valued functions on the interval [0,1], and define ''L'':&amp;nbsp;''C''[0,1]&amp;nbsp;→&amp;nbsp;'''R''' by the rule
::&lt;math&gt;L(f) = f(0.3)\text{.}\,&lt;/math&gt;
:Then the kernel of ''L'' consists of all functions ''f''&amp;nbsp;∈&amp;nbsp;''C''[0,1] for which ''f''(0.3)&amp;nbsp;=&amp;nbsp;0.
* Let ''C''&lt;sup&gt;∞&lt;/sup&gt;('''R''') be the vector space of all infinitely differentiable functions '''R'''&amp;nbsp;→&amp;nbsp;'''R''', and let ''D'':&amp;nbsp;''C''&lt;sup&gt;∞&lt;/sup&gt;('''R''')&amp;nbsp;→&amp;nbsp;''C''&lt;sup&gt;∞&lt;/sup&gt;('''R''') be the [[differential operator|differentiation operator]]:
::&lt;math&gt;D(f) = \frac{df}{dx}\text{.}&lt;/math&gt;
:Then the kernel of ''D'' consists of all functions in ''C''&lt;sup&gt;∞&lt;/sup&gt;('''R''') whose derivatives are zero, i.e. the set of all [[constant function]]s.
* Let '''R'''&lt;sup&gt;∞&lt;/sup&gt; be the [[direct product]] of infinitely many copies of '''R''', and let ''s'':&amp;nbsp;'''R'''&lt;sup&gt;∞&lt;/sup&gt;&amp;nbsp;→&amp;nbsp;'''R'''&lt;sup&gt;∞&lt;/sup&gt; be the [[shift operator]]
::&lt;math&gt;s(x_1,x_2,x_3,x_4,\ldots) = (x_2,x_3,x_4,\ldots)\text{.}&lt;/math&gt;
:Then the kernel of ''s'' is the one-dimensional subspace consisting of all vectors (''x''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;0,&amp;nbsp;0,&amp;nbsp;...).
* If ''V'' is an [[inner product space]] and ''W'' is a subspace, the kernel of the [[projection (linear algebra)|orthogonal projection]] ''V''&amp;nbsp;→&amp;nbsp;''W'' is the [[orthogonal complement]] to ''W'' in ''V''.

==Computation by Gaussian elimination==
A [[Basis (linear algebra)|basis]] of the kernel of a matrix may be computed by [[Gaussian elimination]].

For this purpose, given an ''m'' × ''n'' matrix ''A'', we construct first the row [[augmented matrix]] &lt;math&gt; \left[\begin{array}{c}A\\\hline I\end{array}\right],&lt;/math&gt; where {{math|''I''}}&lt;!-- necessary to ensure a serif font --&gt; is the ''n'' × ''n'' [[identity matrix]].

Computing its [[column echelon form]] by Gaussian elimination (or any other suitable method), we get a matrix &lt;math&gt; \left[\begin{array}{c}B\\\hline C\end{array}\right].&lt;/math&gt; A basis of the kernel of ''A'' consists in the non-zero columns of ''C'' such that the corresponding column of ''B'' is a [[zero matrix|zero column]].

In fact, the computation may be stopped as soon as the upper matrix is in column echelon form: the remainder of the computation consists in changing the basis of the vector space generated by the columns whose upper part is zero.

For example, suppose that
:&lt;math&gt;A=\left[ \begin{array}{cccccc}
1 &amp; 0 &amp; -3 &amp; 0 &amp;  2 &amp; -8 \\
0 &amp; 1 &amp;  5 &amp; 0 &amp; -1 &amp; 4 \\
0 &amp; 0 &amp;  0 &amp; 1 &amp; 7 &amp; -9 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \end{array} \,\right]. &lt;/math&gt;
Then
:&lt;math&gt; \left[\begin{array}{c}A\\\hline I\end{array}\right]=
\left[\begin{array}{cccccc}
1 &amp; 0 &amp; -3 &amp; 0 &amp;  2 &amp; -8 \\
0 &amp; 1 &amp;  5 &amp; 0 &amp; -1 &amp; 4 \\
0 &amp; 0 &amp;  0 &amp; 1 &amp; 7 &amp; -9 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
\hline
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{array}\right]. &lt;/math&gt;

Putting the upper part in column echelon form by column operations on the whole matrix gives
:&lt;math&gt; \left[\begin{array}{c}B\\\hline C\end{array}\right]=
\left[\begin{array}{cccccc}
1 &amp; 0 &amp;  0 &amp; 0 &amp;  0 &amp; 0 \\
0 &amp; 1 &amp;  0 &amp; 0 &amp;  0 &amp; 0 \\
0 &amp; 0 &amp;  1 &amp; 0 &amp;  0 &amp; 0 \\
0 &amp; 0 &amp;  0 &amp; 0 &amp;  0 &amp; 0 \\
\hline
1 &amp; 0 &amp;  0 &amp; 3 &amp; -2 &amp; 8 \\
0 &amp; 1 &amp;  0 &amp; -5 &amp; 1 &amp; -4 \\
0 &amp; 0 &amp;  0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp;  1 &amp; 0 &amp; -7 &amp; 9 \\
0 &amp; 0 &amp;  0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp;  0 &amp; 0 &amp; 0 &amp; 1
\end{array}\right]. &lt;/math&gt;

The last three columns of ''B'' are zero columns. Therefore, the three last vectors of ''C'',
:&lt;math&gt;\left[\!\! \begin{array}{r} 3 \\ -5 \\ 1 \\ 0 \\ 0 \\ 0 \end{array} \right],\;
\left[\!\! \begin{array}{r} -2 \\ 1 \\ 0 \\ -7 \\ 1 \\ 0 \end{array} \right],\;
\left[\!\! \begin{array}{r} 8 \\ -4 \\ 0 \\ 9 \\ 0 \\ 1 \end{array} \right] &lt;/math&gt;
are a basis of the kernel of ''A''.

Proof that the method computes the kernel: Since column operations correspond to post-multiplication by invertible matrices, the fact that &lt;math&gt; \left[\begin{array}{c}A\\\hline I\end{array}\right]&lt;/math&gt; reduces to &lt;math&gt; \left[\begin{array}{c}B\\\hline C\end{array}\right]&lt;/math&gt; means that there exists an invertible matrix &lt;math&gt;P&lt;/math&gt; such that &lt;math&gt; \left[\begin{array}{c}A\\\hline I\end{array}\right] P = \left[\begin{array}{c}B\\\hline C\end{array}\right], &lt;/math&gt; with &lt;math&gt;B&lt;/math&gt; in column echelon form. Thus &lt;math&gt;AP=B,&lt;/math&gt; &lt;math&gt;IP=C, &lt;/math&gt; and &lt;math&gt; AC=B. &lt;/math&gt; A column vector &lt;math&gt;v&lt;/math&gt; belongs to the kernel of &lt;math&gt;A&lt;/math&gt; (that is &lt;math&gt;Av=0&lt;/math&gt;) if and only &lt;math&gt;Bw=0,&lt;/math&gt; where &lt;math&gt;w=P^{-1}v=C^{-1}v.&lt;/math&gt; As &lt;math&gt;B&lt;/math&gt; is in column echelon form, &lt;math&gt;Bw=0,&lt;/math&gt; if and only if the nonzero entries of &lt;math&gt;w&lt;/math&gt; correspond to the zero columns of &lt;math&gt;B.&lt;/math&gt; By multiplying by &lt;math&gt;C&lt;/math&gt;, one may deduce that this is the case if and only if &lt;math&gt;v=Cw&lt;/math&gt; is a linear combination of the corresponding columns of &lt;math&gt;C.&lt;/math&gt;

==Numerical computation==
The problem of computing the kernel on a computer depends on the nature of the coefficients.

===Exact coefficients===
If the coefficients of the matrix are exactly given numbers, the [[column echelon form]] of the matrix may be computed by [[Bareiss algorithm]] more efficiently than with Gaussian elimination. It is even more efficient to use [[modular arithmetic]] and [[Chinese remainder theorem]], which reduces the problem to several similar ones over [[finite field]]s (this avoids the overhead induced by the non-linearity of the [[computational complexity]] of integer multiplication).{{Citation needed|date=October 2014}}

For coefficients in a finite field, Gaussian elimination works well, but for the large matrices that occur in [[cryptography]] and [[Gröbner basis]] computation, better algorithms are known, which have roughly the same [[Analysis of algorithms|computational complexity]], but are faster and behave better with modern [[computer hardware]].{{Citation needed|date=October 2014}}

===Floating point computation===
For matrices whose entries are [[floating-point number]]s, the problem of computing the kernel makes sense only for matrices such that the number of rows is equal to their rank: because of the [[rounding error]]s, a floating-point matrix has almost always a [[full rank]], even when it is an approximation of a matrix of a much smaller rank. Even for a full-rank matrix, it is possible to compute its kernel only if it is [[well-conditioned problem|well conditioned]], i.e. it has a low [[condition number]].&lt;ref&gt;https://www.math.ohiou.edu/courses/math3600/lecture11.pdf&lt;/ref&gt;

Even for a well conditioned full rank matrix, Gaussian elimination does not behave correctly: it introduces rounding errors that are too large for getting a significant result. As the computation of the kernel of a matrix is a special instance of solving a homogeneous system of linear equations, the kernel may be computed by any of the various algorithms designed to solve homogeneous systems. A state of the art software for this purpose is the [[Lapack]] library.{{Citation needed|date=October 2014}}

==See also==
{{Div col|colwidth=20em}}
* [[Kernel (algebra)]]
* [[Zero set]]
* [[System of linear equations]]
* [[Row and column spaces]]
* [[Row reduction]]
* [[Four fundamental subspaces]]
* [[Vector space]]
* [[Linear subspace]]
* [[Linear operator]]
* [[Function space]]
* [[Fredholm alternative]]
{{div col end}}

==Notes==
{{reflist}}

==References==
{{see also|Linear algebra#Further reading}}
* {{Citation
 | last = Axler
 | first = Sheldon Jay
 | year = 1997
 | title = Linear Algebra Done Right
 | publisher = Springer-Verlag
 | edition = 2nd
 | isbn = 0-387-98259-0
 | postscript = .
}}
* {{Citation
 | last = Lay
 | first = David C.
 | year = 2005
 | title = Linear Algebra and Its Applications
 | publisher = Addison Wesley
 | edition = 3rd
 | isbn = 978-0-321-28713-7
 | postscript = .
}}
* {{Citation
 |last=Meyer 
 |first=Carl D. 
 |year=2001 
 |title=Matrix Analysis and Applied Linear Algebra 
 |publisher=Society for Industrial and Applied Mathematics (SIAM) 
 |isbn=978-0-89871-454-8 
 |url=http://www.matrixanalysis.com/DownloadChapters.html 
 |postscript=. 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20091031193126/http://matrixanalysis.com/DownloadChapters.html 
 |archivedate=2009-10-31 
 |df= 
}}
* {{Citation
 | last = Poole
 | first = David
 | year = 2006
 | title = Linear Algebra: A Modern Introduction
 | publisher = Brooks/Cole
 | edition = 2nd
 | isbn = 0-534-99845-3
 | postscript = .
}}
* {{Citation
 | last = Anton
 | first = Howard
 | year = 2005
 | title = Elementary Linear Algebra (Applications Version)
 | publisher = Wiley International
 | edition = 9th
 | postscript = .
}}
* {{Citation
 | last = Leon
 | first = Steven J.
 | year = 2006
 | title = Linear Algebra With Applications
 | publisher = Pearson Prentice Hall
 | edition = 7th
 | postscript = .
}}
* {{Cite book
 | ref = harv
 | first = Serge
 | last = Lang
 | author-link = Serge Lang
 | title = Linear Algebra
 | publisher = Springer
 | year = 1987
 | isbn = 9780387964126
}}
* {{Citation
 | first1 = Lloyd N.
 | last1 = Trefethen
 | first2 = David III
 | last2 = Bau
 | title = Numerical Linear Algebra
 | publisher = SIAM
 | year = 1997
 | isbn = 978-0-89871-361-9
 | url = http://web.comlab.ox.ac.uk/oucl/work/nick.trefethen/text.html
 | postscript = .
}}

==External links==
{{wikibooks|Linear Algebra/Null Spaces}}
* {{springer|title=Kernel of a matrix|id=p/k110090}}
* [[Khan Academy]], [http://www.khanacademy.org/video/introduction-to-the-null-space-of-a-matrix Introduction to the Null Space of a Matrix]

{{linear algebra}}

{{DEFAULTSORT:Kernel (linear algebra)}}
[[Category:Linear algebra]]
[[Category:Functional analysis]]
[[Category:Matrices]]
[[Category:Numerical linear algebra]]</text>
      <sha1>2skqwz0sneyq7jri20xuooxqb8hni3s</sha1>
    </revision>
  </page>
  <page>
    <title>Kuratowski's free set theorem</title>
    <ns>0</ns>
    <id>9750368</id>
    <revision>
      <id>648947270</id>
      <parentid>626736273</parentid>
      <timestamp>2015-02-26T15:24:23Z</timestamp>
      <contributor>
        <username>K9re11</username>
        <id>19647483</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2120">'''Kuratowski's free set theorem''', named after [[Kazimierz Kuratowski]], is a result of [[set theory]], an area of [[mathematics]]. It is a result which has been largely forgotten for almost 50 years, but has been applied recently in solving several [[lattice theory]] problems, such as the [[congruence lattice problem]].

Denote by &lt;math&gt;[X]^{&lt;\omega}&lt;/math&gt; the [[Set (mathematics)|set]] of all [[Finite set|finite subsets]] of a set &lt;math&gt;X&lt;/math&gt;. Likewise, for a [[positive integer]] &lt;math&gt;n&lt;/math&gt;, denote by &lt;math&gt;[X]^n&lt;/math&gt; the set of all &lt;math&gt;n&lt;/math&gt;-elements subsets of &lt;math&gt;X&lt;/math&gt;. For a [[Map (mathematics)|mapping]] &lt;math&gt;\Phi\colon[X]^n\to[X]^{&lt;\omega}&lt;/math&gt;, we say that a [[subset]] &lt;math&gt;U&lt;/math&gt; of &lt;math&gt;X&lt;/math&gt; is ''free'' (with respect to &lt;math&gt;\Phi&lt;/math&gt;), if for any &lt;math&gt;n&lt;/math&gt;-element subset &lt;math&gt;V&lt;/math&gt; of &lt;math&gt;U&lt;/math&gt; and any &lt;math&gt;u\in U\setminus V&lt;/math&gt;, &lt;math&gt;u\notin\Phi(V)&lt;/math&gt;,. [[Kuratowski]] published in 1951 the following result, which characterizes the [[Infinity|infinite]] [[Cardinal number|cardinals]] of the form &lt;math&gt;\aleph_n&lt;/math&gt;.

The theorem states the following. Let &lt;math&gt;n&lt;/math&gt; be a positive integer and let &lt;math&gt;X&lt;/math&gt; be a set. Then the [[cardinality]] of &lt;math&gt;X&lt;/math&gt; is greater than or equal to &lt;math&gt;\aleph_n&lt;/math&gt; if and only if for every mapping &lt;math&gt;\Phi&lt;/math&gt; from &lt;math&gt;[X]^n&lt;/math&gt; to &lt;math&gt;[X]^{&lt;\omega}&lt;/math&gt;,
there exists an &lt;math&gt;(n+1)&lt;/math&gt;-element free subset of &lt;math&gt;X&lt;/math&gt; with respect to &lt;math&gt;\Phi&lt;/math&gt;.

For &lt;math&gt;n=1&lt;/math&gt;, Kuratowski's free set theorem is superseded by [[Hajnal's set mapping theorem]].

== References ==
* [[Paul Erdős|P. Erdős]], [[András Hajnal|A. Hajnal]], A. Máté, [[Richard Rado|R. Rado]]: ''Combinatorial Set Theory: Partition Relations for Cardinals'', North-Holland, 1984, pp.&amp;nbsp;282–285.  
* [[Kazimierz Kuratowski|C. Kuratowski]], ''Sur une caract&amp;eacute;risation des alephs'', Fund. Math. '''38''' (1951), 14–17.
* John C. Simms (1991) "Sierpiński's theorem",  [[Simon Stevin (journal)|Simon Stevin]]  65: 69–163.

[[Category:Set theory]]


{{settheory-stub}}</text>
      <sha1>hy6b6swed9mb8g45jski56guiptus6y</sha1>
    </revision>
  </page>
  <page>
    <title>L/poly</title>
    <ns>0</ns>
    <id>7192559</id>
    <revision>
      <id>746934780</id>
      <parentid>535473797</parentid>
      <timestamp>2016-10-30T12:38:48Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3927">In [[computational complexity theory]], '''L/poly''' is the [[complexity class]] of [[logarithmic space]] machines with a polynomial amount of [[advice (complexity)|advice]]. L/poly is a [[Circuit complexity|non-uniform]] logarithmic space class, analogous to the non-uniform polynomial time class [[P/poly]].&lt;ref&gt;{{ComplexityZoo|L/poly|L#l.2Fpoly}}.&lt;/ref&gt; 

Formally, for a [[formal language]] {{mvar|L}} to belong to L/poly, there must exist an advice function {{mvar|f}} that maps an integer {{mvar|n}} to a string of length polynomial in {{mvar|n}}, and a [[Turing machine]] M with two read-only input tapes and one read-write tape of size logarithmic in the input size, such that an input {{mvar|x}} of length {{mvar|n}} belongs to {{mvar|L}} if and only if machine M accepts the input {{math|''x'',&amp;nbsp;''f''(''n'')}}.&lt;ref name="t"&gt;{{citation|title=The Computational Complexity of Equivalence and Isomorphism Problems|volume=1852|series=Lecture Notes in Computer Science|first=Thomas|last=Thierauf|publisher=Springer-Verlag|year=2000|isbn=978-3-540-41032-4|page=66|url=https://books.google.com/books?id=e3xOiREJF4EC&amp;pg=PA66}}.&lt;/ref&gt; Alternatively and more simply, {{mvar|L}} is in L/poly if and only if it can be recognized by [[branching program]]s of polynomial size.&lt;ref&gt;{{citation
 | last = Cobham | first = Alan | authorlink = Alan Cobham
 | contribution = The recognition problem for the set of perfect squares
 | doi = 10.1109/SWAT.1966.30
 | pages = 78–87
 | title = [[Symposium on Foundations of Computer Science|Proceedings of the 7th Annual IEEE Symposium on Switching and Automata Theory (SWAT 1966)]]
 | year = 1966}}.&lt;/ref&gt; One direction of the proof that these two models of computation are equivalent in power is the observation that, if a branching program of polynomial size exists, it can be specified by the advice function and simulated by the Turing machine. In the other direction, a Turing machine with logarithmic writable space and a polynomial advice tape may be simulated by a branching program the states of which represent the combination of the configuration of the writable tape and the position of the Turing machine heads on the other two tapes.

In 1979, Aleliunas et al. showed that [[SL (complexity)|symmetric logspace]] is contained in L/poly.&lt;ref&gt;{{citation
 | last1 = Aleliunas | first1 = Romas
 | last2 = Karp | first2 = Richard M. | author2-link = Richard M. Karp
 | last3 = Lipton | first3 = Richard J. | author3-link = Richard J. Lipton
 | last4 = Lovász | first4 = László | author4-link = László Lovász
 | last5 = Rackoff | first5 = Charles | author5-link = Charles Rackoff
 | contribution = Random walks, universal traversal sequences, and the complexity of maze problems
 | doi = 10.1109/SFCS.1979.34
 | location = New York
 | mr = 598110
 | pages = 218–223
 | publisher = IEEE
 | title = [[Symposium on Foundations of Computer Science|Proceedings of 20th Annual Symposium on Foundations of Computer Science]]
 | year = 1979}}.&lt;/ref&gt; However, this result was superseded by [[Omer Reingold]]'s result that SL collapses to uniform logspace.&lt;ref&gt;{{citation
 | last = Reingold | first = Omer | author-link = Omer Reingold
 | doi = 10.1145/1391289.1391291
 | issue = 4
 | journal = [[Journal of the ACM]]
 | mr = 2445014
 | pages = 1–24
 | title = Undirected connectivity in log-space
 | volume = 55
 | year = 2008}}.&lt;/ref&gt;

[[BPL (complexity)|BPL]] is contained in L/poly, which is a variant of [[P/poly#Adleman's theorem|Adleman's theorem]].&lt;ref&gt;{{citation
 | last = Nisan | first = Noam | authorlink = Noam Nisan
 | doi = 10.1016/0304-3975(93)90258-U
 | issue = 1
 | journal = Theoretical Computer Science
 | mr = 1201169
 | pages = 135–144
 | title = On read-once vs. multiple access to randomness in logspace
 | volume = 107
 | year = 1993}}.&lt;/ref&gt;

==References==
{{reflist}}

{{DEFAULTSORT:L Poly}}
[[Category:Complexity classes]]


{{Comp-sci-theory-stub}}</text>
      <sha1>axcs8ay50vtea1v8nyzxygit4kon02m</sha1>
    </revision>
  </page>
  <page>
    <title>Laplacian matrix</title>
    <ns>0</ns>
    <id>1448472</id>
    <revision>
      <id>864816836</id>
      <parentid>864783754</parentid>
      <timestamp>2018-10-19T17:21:36Z</timestamp>
      <contributor>
        <ip>80.65.246.237</ip>
      </contributor>
      <comment>/* Graphs */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="29126">In the [[mathematics|mathematical]] field of [[graph theory]], the '''Laplacian matrix''', sometimes called '''admittance matrix''', '''Kirchhoff matrix''' or '''discrete Laplacian''', is a [[matrix (mathematics)|matrix]] representation of a [[Graph (discrete mathematics)|graph]]. The Laplacian matrix can be used to find many useful properties of a graph. Together with [[Kirchhoff's theorem]], it can be used to calculate the number of [[spanning tree (mathematics)|spanning tree]]s for a given graph.  The [[cut (graph theory)#Sparsest cut|sparsest cut]] of a graph can be approximated through the second smallest eigenvalue of its Laplacian by [[Cheeger constant#Cheeger's inequality|Cheeger's inequality]]. It can also be used to construct [[nonlinear dimensionality reduction#Laplacian eigenmaps|low dimensional embeddings]], which can be useful for a variety of [[machine learning]] applications.

== Definition ==

=== Laplacian matrix for ''simple graphs'' ===

Given a [[simple graph]] ''G'' with ''n'' vertices, its Laplacian matrix &lt;math display="inline"&gt;L_{n \times n}&lt;/math&gt; is 
defined as:&lt;ref name="mathworld"&gt;{{MathWorld |urlname=LaplacianMatrix |title=Laplacian Matrix}}&lt;/ref&gt;
: &lt;math&gt;L = D - A,&lt;/math&gt;

where ''D'' is the [[degree matrix]] and ''A'' is the [[adjacency matrix]] of the graph. Since &lt;math display="inline"&gt;G&lt;/math&gt; is a simple graph, &lt;math display="inline"&gt;A&lt;/math&gt; only contains 1s or 0s and its diagonal elements are all 0s.

In the case of [[directed graph]]s, either the [[degree (graph theory)|indegree or outdegree]] might be used, depending on the application.

The elements of &lt;math display="inline"&gt;L&lt;/math&gt; are given by

: &lt;math&gt;L_{i,j} := \begin{cases}
  \deg(v_i) &amp; \mbox{if}\ i = j \\
         -1 &amp; \mbox{if}\ i \neq j\ \mbox{and}\ v_i \mbox{ is adjacent to } v_j \\
          0 &amp; \mbox{otherwise}
\end{cases}&lt;/math&gt;

where deg(''v&lt;sub&gt;i&lt;/sub&gt;'') is the degree of the vertex ''i''.

==== Symmetric normalized Laplacian ====

The symmetric normalized Laplacian matrix is defined  as:&lt;ref name="mathworld" /&gt;

: &lt;math&gt;L^\text{sym} := D^{-\frac{1}{2}} L D^{-\frac{1}{2}} = I - D^{-\frac{1}{2}} A D^{-\frac{1}{2}}&lt;/math&gt;,

The elements of &lt;math display="inline"&gt;L^\text{sym}&lt;/math&gt; are given by

:&lt;math&gt;L^\text{sym}_{i,j} := \begin{cases}
                                     1 &amp; \mbox{if } i = j \mbox{ and } \deg(v_i) \neq 0\\
  -\frac{1}{\sqrt{\deg(v_i)\deg(v_j)}} &amp; \mbox{if } i \neq j \mbox{ and } v_i \mbox{ is adjacent to } v_j \\
                                     0 &amp; \mbox{otherwise}.
\end{cases}&lt;/math&gt;

==== Random walk normalized Laplacian ====

The random-walk normalized Laplacian matrix is defined as:
: &lt;math&gt;L^\text{rw} := D^{-1}L = I - D^{-1}A&lt;/math&gt;

The elements of &lt;math display="inline"&gt;L^\text{rw}&lt;/math&gt; are given by
:&lt;math&gt;L^\text{rw}_{i,j} := \begin{cases}
                     1 &amp; \mbox{if } i = j \mbox{ and } \deg(v_i) \neq 0\\
  -\frac{1}{\deg(v_i)} &amp; \mbox{if } i \neq j \mbox{ and } v_i \mbox{ is adjacent to } v_j \\
                     0 &amp; \mbox{otherwise}.
\end{cases}&lt;/math&gt;

==== Generalized Laplacian ====

The generalized Laplacian, ''Q'', is defined as&lt;ref&gt;{{cite book |last1= Godsil |first1=C. |last2= Royle |first2=G. |date=2001 |title=Algebraic Graph Theory, Graduate Texts in Mathematics |publisher= Springer-Verlag}}&lt;/ref&gt;:

: &lt;math&gt;\begin{cases}
        Q_{i,j} &lt; 0 &amp; \mbox{if } i \neq j \mbox{ and } v_i \mbox{ is adjacent to } v_j\\
        Q_{i,j} = 0 &amp; \mbox{if } i \neq j \mbox{ and } v_i \mbox{ is not adjacent to } v_j \\
  \mbox{any number} &amp; \mbox{otherwise}.
\end{cases}&lt;/math&gt;

Notice the ordinary Laplacian is a generalized Laplacian.

== Example ==

Here is a simple example of a labeled, undirected graph and its Laplacian matrix.

{|class="wikitable"
! [[Labeled graph]]
! [[Degree matrix]]
! [[Adjacency matrix]]
! Laplacian matrix
|-
| [[image:6n-graf.svg|175px]]
| &lt;math display="inline"&gt;\left(\begin{array}{rrrrrr}
  2 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp;  0\\
  0 &amp;  3 &amp;  0 &amp;  0 &amp;  0 &amp;  0\\
  0 &amp;  0 &amp;  2 &amp;  0 &amp;  0 &amp;  0\\
  0 &amp;  0 &amp;  0 &amp;  3 &amp;  0 &amp;  0\\
  0 &amp;  0 &amp;  0 &amp;  0 &amp;  3 &amp;  0\\
  0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp;  1\\
\end{array}\right)&lt;/math&gt;
| &lt;math display="inline"&gt;\left(\begin{array}{rrrrrr}
  0 &amp;  1 &amp;  0 &amp;  0 &amp;  1 &amp;  0\\
  1 &amp;  0 &amp;  1 &amp;  0 &amp;  1 &amp;  0\\
  0 &amp;  1 &amp;  0 &amp;  1 &amp;  0 &amp;  0\\
  0 &amp;  0 &amp;  1 &amp;  0 &amp;  1 &amp;  1\\
  1 &amp;  1 &amp;  0 &amp;  1 &amp;  0 &amp;  0\\
  0 &amp;  0 &amp;  0 &amp;  1 &amp;  0 &amp;  0\\
\end{array}\right)&lt;/math&gt;
| &lt;math display="inline"&gt;\left(\begin{array}{rrrrrr}
   2 &amp; -1 &amp;  0 &amp;  0 &amp; -1 &amp;  0\\
  -1 &amp;  3 &amp; -1 &amp;  0 &amp; -1 &amp;  0\\
   0 &amp; -1 &amp;  2 &amp; -1 &amp;  0 &amp;  0\\
   0 &amp;  0 &amp; -1 &amp;  3 &amp; -1 &amp; -1\\
  -1 &amp; -1 &amp;  0 &amp; -1 &amp;  3 &amp;  0\\
   0 &amp;  0 &amp;  0 &amp; -1 &amp;  0 &amp;  1\\
\end{array}\right)&lt;/math&gt;
|}

== Properties ==
For an (undirected) graph ''G'' and its Laplacian matrix ''L'' with [[eigenvalues]] &lt;math display="inline"&gt;\lambda_0 \le \lambda_1 \le \cdots \le \lambda_{n-1}&lt;/math&gt;:

* ''L'' is symmetric.
* ''L'' is [[positive-definite matrix|positive-semidefinite]] (that is &lt;math display="inline"&gt;\lambda_i \ge 0&lt;/math&gt; for all &lt;math display="inline"&gt;i&lt;/math&gt;). This is verified in the [[#Incidence matrix|incidence matrix]] section (below). This can also be seen from the fact that the Laplacian is symmetric and [[diagonally dominant matrix#Applications and properties|diagonally dominant]].
* ''L'' is an [[M-matrix]] (its off-diagonal entries are nonpositive, yet the real parts of its eigenvalues are nonnegative).
* Every row sum and column sum of ''L'' is zero. Indeed, in the sum, the degree of the vertex is summed with a "−1" for each neighbor.
* In consequence, &lt;math display="inline"&gt;\lambda_0 = 0&lt;/math&gt;, because the vector &lt;math display="inline"&gt;\mathbf{v}_0 = (1, 1, \dots, 1)&lt;/math&gt; satisfies &lt;math display="inline"&gt;L \mathbf{v}_0 = \mathbf{0} .&lt;/math&gt; This also implies that the Laplacian matrix is singular.
* The number of [[Connected component (graph theory)|connected components]] in the graph is the dimension of the [[kernel (linear algebra)|nullspace]] of the Laplacian and the [[Eigenvalues and eigenvectors#Algebraic multiplicity|algebraic multiplicity]] of the 0 eigenvalue.
* The smallest non-zero eigenvalue of ''L'' is called the [[spectral gap]].
* The second smallest eigenvalue of ''L'' (could be zero) is the [[algebraic connectivity]] (or [[Fiedler value]]) of ''G'' and approximates the [[cut (graph_theory)#Sparsest cut|sparsest cut]] of a graph.
* The [[Laplacian]] is an operator on the n-dimensional vector space of functions &lt;math display="inline"&gt;f : V \to \mathbb{R}&lt;/math&gt;, where &lt;math display="inline"&gt;V&lt;/math&gt; is the vertex set of G, and &lt;math display="inline"&gt;n = |V|&lt;/math&gt;.
* When G is k-regular, the normalized Laplacian is: &lt;math display="inline"&gt;\mathcal{L} = \tfrac{1}{k} L = I - \tfrac{1}{k} A&lt;/math&gt;, where A is the adjacency matrix and I is an identity matrix.
* For a graph with multiple [[Connected component (graph theory)|connected components]], ''L'' is a [[Block matrix#Block diagonal matrices|block diagonal]] matrix, where each block is the respective Laplacian matrix for each component, possibly after reordering the vertices (i.e. ''L'' is permutation-similar to a block diagonal matrix).
* The trace of the Laplacian matrix ''L'' is equal to &lt;math display="inline"&gt;2m&lt;/math&gt; where &lt;math display="inline"&gt;m&lt;/math&gt; is the number of edges of the considered graph.

== Incidence matrix ==

Define an &lt;math display="inline"&gt;|e| \times |v|&lt;/math&gt; oriented [[incidence matrix]] ''M'' with element ''M''&lt;sub&gt;''ev''&lt;/sub&gt; for edge ''e'' (connecting vertex ''i'' and ''j'', with ''i''&amp;nbsp;&gt;&amp;nbsp;''j'') and vertex ''v'' given by
:&lt;math&gt;M_{ev} = \left\{\begin{array}{rl}
   1, &amp; \text{if } v = i\\
  -1, &amp; \text{if } v = j\\
   0, &amp; \text{otherwise}.
\end{array}\right.&lt;/math&gt;

Then the Laplacian matrix ''L'' satisfies
:&lt;math&gt;L = M^\textsf{T} M\,,&lt;/math&gt;

where &lt;math display="inline"&gt;M^\textsf{T}&lt;/math&gt; is the [[transpose|matrix transpose]] of ''M''.

Now consider an eigendecomposition of &lt;math display="inline"&gt;L&lt;/math&gt;, with unit-norm eigenvectors &lt;math display="inline"&gt;\mathbf{v}_i&lt;/math&gt; and corresponding eigenvalues &lt;math display="inline"&gt;\lambda_i&lt;/math&gt;:
:&lt;math&gt;\begin{align}
  \lambda_i &amp; = \mathbf{v}_i^\textsf{T} L \mathbf{v}_i \\
            &amp; = \mathbf{v}_i^\textsf{T} M^\textsf{T} M \mathbf{v}_i \\
            &amp; = \left(M \mathbf{v}_i\right)^\textsf{T} \left(M \mathbf{v}_i\right). \\
\end{align}&lt;/math&gt;

Because &lt;math display="inline"&gt;\lambda_i&lt;/math&gt; can be written as the inner product of the vector &lt;math display="inline"&gt;M \mathbf{v}_i&lt;/math&gt; with itself, this shows that &lt;math display="inline"&gt;\lambda_i \ge 0&lt;/math&gt; and so the eigenvalues of &lt;math display="inline"&gt;L&lt;/math&gt; are all non-negative.

== Deformed Laplacian ==

The '''deformed Laplacian''' is commonly defined as

:&lt;math&gt;\Delta(s) = I - sA + s^2(D - I)&lt;/math&gt;

where ''I'' is the unit matrix, ''A'' is the adjacency matrix, and ''D'' is the degree matrix, and ''s'' is a (complex-valued) number.  Note that the standard Laplacian is just &lt;math display="inline"&gt;\Delta(1)&lt;/math&gt;.&lt;ref&gt;{{cite journal |title=The Deformed Consensus Protocol |first=F. |last=Morbidi |journal=Automatica |volume=49 |number=10 |pages=3049–3055 |year=2013 |doi=10.1016/j.automatica.2013.07.006}}&lt;/ref&gt;

== Symmetric normalized Laplacian ==

The '''(symmetric) normalized Laplacian''' is defined as
: &lt;math&gt;L^\text{sym} := D^{-\frac{1}{2}} L D^{-\frac{1}{2}} = I - D^{-\frac{1}{2}}AD^{-\frac{1}{2}}&lt;/math&gt;

where ''L'' is the (unnormalized) Laplacian, ''A'' is the adjacency matrix and ''D'' is the degree matrix. Since the degree matrix ''D'' is diagonal and positive, its reciprocal square root &lt;math display="inline"&gt;D^{-\frac{1}{2}}&lt;/math&gt; is just the diagonal matrix whose diagonal entries are the reciprocals of the positive square roots of the diagonal entries of ''D''. The symmetric normalized Laplacian is a symmetric matrix.

One has: &lt;math display="inline"&gt;L^\text{sym} = S S^*&lt;/math&gt;, where S is the matrix whose rows are indexed by the vertices and whose columns are indexed by the edges of G such that each column corresponding to an edge e = {u, v} has an entry &lt;math display="inline"&gt;\frac{1}{\sqrt{d_u}}&lt;/math&gt; in the row corresponding to u, an entry &lt;math display="inline"&gt;-\frac{1}{\sqrt{d_v}}&lt;/math&gt; in the row corresponding to v, and has 0 entries elsewhere. (Note: &lt;math display="inline"&gt;S^*&lt;/math&gt; denotes the transpose of S).

All eigenvalues of the normalized Laplacian are real and non-negative. We can see this as follows. Since &lt;math display="inline"&gt;L^\text{sym}&lt;/math&gt; is symmetric, its eigenvalues are real. They are also non-negative: consider an eigenvector &lt;math display="inline"&gt;g&lt;/math&gt; of &lt;math display="inline"&gt;L^\text{sym}&lt;/math&gt; with eigenvalue &amp;lambda; and suppose &lt;math display="inline"&gt;g = D^\frac{1}{2} f&lt;/math&gt;. (We can consider g and f as real functions on the vertices v.) Then:

:&lt;math&gt;
  \lambda \ = \ 
  \frac{\langle g, L^\text{sym}g\rangle}{\langle g, g\rangle} \ = \ 
  \frac{\left\langle g, D^{-\frac{1}{2}} L D^{-\frac{1}{2}} g\right\rangle}{\langle g, g\rangle} \ = \ 
  \frac{\langle f, Lf\rangle}{\left\langle D^\frac{1}{2} f, D^\frac{1}{2} f\right\rangle} \  = \ 
  \frac{\sum_{u \sim v}(f(u) - f(v))^2}{\sum_v f(v)^2 d_v} \ \geq \ 
  0,
&lt;/math&gt;

where we use the inner product &lt;math display="inline"&gt;\langle f,g\rangle = \sum_{v} f(v)g(v)&lt;/math&gt;, a sum over all vertices v, and &lt;math display="inline"&gt;\sum_{u\sim v}&lt;/math&gt; denotes the sum over all unordered pairs  of adjacent vertices {u,v}. The quantity &lt;math display="inline"&gt;\sum_{u,v}(f(u) - f(v))^2&lt;/math&gt; is called the ''Dirichlet sum'' of f, whereas the expression &lt;math display="inline"&gt;\frac{\left\langle g, L^\text{sym}g\right\rangle}{\langle g, g\rangle} &lt;/math&gt; is called the ''Rayleigh quotient'' of g.

Let '''1''' be the function which assumes the value 1 on each vertex. Then &lt;math display="inline"&gt;D^\frac{1}{2} 1&lt;/math&gt; is an eigenfunction of &lt;math display="inline"&gt;L^{\text{sym}}&lt;/math&gt; with eigenvalue 0.&lt;ref&gt;{{cite book|last=Chung|first=Fan R. K.|authorlink=Fan Chung|title=Spectral graph theory|year=1997|publisher=American Math. Soc.|location=Providence, RI|isbn=0-8218-0315-8|edition=Repr. with corr., 2. [pr.]}}&lt;/ref&gt;

In fact, the eigenvalues of the normalized symmetric Laplacian satisfy 0 = μ&lt;sub&gt;0&lt;/sub&gt; ≤ … ≤ μ&lt;sub&gt;n−1&lt;/sub&gt; ≤ 2. These eigenvalues (known as the spectrum of the normalized Laplacian) relate well to other graph invariants for general graphs.&lt;ref&gt;{{cite book
| last                  = Chung
| first                 = Fan
| authorlink            = Fan Chung
| title                 = Spectral Graph Theory
| url                   = http://www.math.ucsd.edu/~fan/research/revised.html
| origyear              = 1992
| year                  = 1997
| publisher             = American Mathematical Society
| isbn                  = 0821803158
}}&lt;/ref&gt;

== Random walk normalized Laplacian ==

The '''random walk normalized Laplacian''' is defined as
: &lt;math&gt;L^\text{rw} := D^{-1} L&lt;/math&gt;

where ''D'' is the degree matrix. Since the degree matrix ''D'' is diagonal, its inverse &lt;math display="inline"&gt;D^{-1}&lt;/math&gt; is simply defined as a diagonal matrix, having diagonal entries which are the reciprocals of the corresponding positive diagonal entries of ''D''.

For the isolated vertices (those with degree 0), a common choice is to set the corresponding element &lt;math display="inline"&gt;L^\text{rw}_{i,i}&lt;/math&gt; to 0.

This convention results in a nice property that the multiplicity of the eigenvalue 0 is equal to the number of connected components in the graph.

The matrix elements of &lt;math display="inline"&gt;L^\text{rw}&lt;/math&gt; are given by
: &lt;math&gt;L^{\text{rw}}_{i,j} := \begin{cases}
                     1 &amp; \mbox{if}\ i = j\ \mbox{and}\ \deg(v_i) \neq 0\\
  -\frac{1}{\deg(v_i)} &amp; \mbox{if}\ i \neq j\ \mbox{and}\ v_i \mbox{ is adjacent to } v_j \\
                     0 &amp; \mbox{otherwise}.
\end{cases}&lt;/math&gt;

The name of the random-walk normalized Laplacian comes from the fact that this matrix is &lt;math display="inline"&gt;L^\text{rw} = I - P&lt;/math&gt;, where &lt;math display="inline"&gt;P = D^{-1}A&lt;/math&gt; is simply the transition matrix
of a random walker on the graph. For example, let &lt;math display="inline"&gt; e_i &lt;/math&gt; denote the i-th [[standard basis]] vector. Then &lt;math display="inline"&gt;x = e_i P &lt;/math&gt; is a [[probability vector]] representing the distribution of a random walker's locations after taking a single step from vertex &lt;math display="inline"&gt;i&lt;/math&gt;; i.e., &lt;math display="inline"&gt;x_j = \mathbb{P}\left(v_i \to v_j\right)&lt;/math&gt;. More generally, if the vector &lt;math display="inline"&gt; x &lt;/math&gt; is a probability distribution of the location of a random walker on the vertices of the graph, then &lt;math display="inline"&gt;x' = x P^t&lt;/math&gt; is the probability distribution of the walker after &lt;math display="inline"&gt;t&lt;/math&gt; steps.

One can check that
: &lt;math&gt;L^\text{rw} = I-D^{-\frac{1}{2}}\left(I - L^\text{sym}\right) D^\frac{1}{2}&lt;/math&gt;,

i.e., &lt;math display="inline"&gt;L^\text{rw}&lt;/math&gt; is similar to the normalized Laplacian &lt;math display="inline"&gt;L^\text{sym}&lt;/math&gt;. For this reason, even if &lt;math display="inline"&gt;L^\text{rw}&lt;/math&gt; is in general not hermitian, it has real eigenvalues. Indeed, its eigenvalues agree with those of &lt;math display="inline"&gt;L^\text{sym}&lt;/math&gt; (which is hermitian). 

=== Graphs ===

As an aside about [[random walk#Random walk on graphs|random walks on graphs]], consider a simple [[graph (discrete mathematics)#Undirected graph|undirected graph]]. Consider the probability that the walker is at the vertex ''i'' at time ''t'', given the probability distribution that he was at vertex ''j'' at time ''t − 1'' (assuming a uniform chance of taking a step along any of the edges attached to a given vertex):
: &lt;math&gt;p_i(t) = \sum_j \frac{A_{ij}}{\deg\left(v_j\right)} p_j(t - 1),&lt;/math&gt;

or in matrix-vector notation:
:&lt;math&gt;p(t) = A D^{-1} p(t - 1).&lt;/math&gt;

(Equilibrium, which sets in as &lt;math display="inline"&gt;t\rightarrow \infty&lt;/math&gt;, is defined by &lt;math display="inline"&gt;p = A D^{-1} p &lt;/math&gt;.)

We can rewrite this relation as
:&lt;math&gt;D^{-\frac{1}{2}} p(t) = \left[D^{-\frac{1}{2}} A D^{-\frac{1}{2}}\right] D^{-\frac{1}{2}} p(t - 1).&lt;/math&gt;

&lt;math display="inline"&gt;A_\text{reduced} \equiv D^{-\frac{1}{2}} A D^{-\frac{1}{2}}&lt;/math&gt; is a symmetric matrix called the '''reduced adjacency matrix'''. So, taking steps on this random walk requires taking powers of &lt;math display="inline"&gt;A_\text{reduced}&lt;/math&gt;, which is a simple operation because &lt;math display="inline"&gt;A_\text{reduced}&lt;/math&gt; is symmetric.

== Interpretation as the discrete Laplace operator ==

The Laplacian matrix can be interpreted as a matrix representation of a particular case of the [[discrete Laplace operator]]. Such an interpretation allows one, e.g., to generalise the Laplacian matrix to the case of graphs with an infinite number of vertices and edges, leading to a Laplacian matrix of an infinite size.

Suppose &lt;math display="inline"&gt;\phi&lt;/math&gt; describes a heat distribution across a [[graph (discrete mathematics)|graph]], where &lt;math display="inline"&gt;\phi_i&lt;/math&gt; is the heat at vertex &lt;math display="inline"&gt;i&lt;/math&gt;. According to [[Newton's law of cooling]], the heat transferred between nodes &lt;math display="inline"&gt;i&lt;/math&gt; and &lt;math display="inline"&gt;j&lt;/math&gt; is proportional to &lt;math display="inline"&gt;\phi_i - \phi_j&lt;/math&gt; if nodes &lt;math display="inline"&gt;i&lt;/math&gt; and &lt;math display="inline"&gt;j&lt;/math&gt; are connected (if they are not connected, no heat is transferred). Then, for heat capacity &lt;math display="inline"&gt;k&lt;/math&gt;,

:&lt;math&gt;\begin{align}
  \frac{d \phi_i}{d t}
    &amp;= -k \sum_j A_{ij} \left( \phi_i - \phi_j \right) \\
    &amp;= -k \left( \phi_i \sum_j A_{ij} - \sum_j A_{ij} \phi_j \right) \\
    &amp;= -k \left( \phi_i \ \deg(v_i) - \sum_j A_{ij} \phi_j \right) \\
    &amp;= -k \sum_j \left( \delta_{ij} \ \deg(v_i) - A_{ij} \right) \phi_j \\
    &amp;= -k \sum_j \left( \ell_{ij} \right) \phi_j.
\end{align}&lt;/math&gt;

In matrix-vector notation,
:&lt;math&gt;\begin{align}
  \frac{d\phi}{dt} &amp;= -k(D - A)\phi \\
                   &amp;= -kL \phi,
\end{align}&lt;/math&gt;

which gives
:&lt;math&gt;\frac{d \phi}{d t} + kL\phi = 0.&lt;/math&gt;

Notice that this equation takes the same form as the [[heat equation]], where the matrix −''L'' is replacing the Laplacian operator &lt;math display="inline"&gt;\nabla^2&lt;/math&gt;; hence, the "graph Laplacian".

To find a solution to this differential equation, apply standard techniques for solving a first-order [[matrix differential equation]].  That is, write &lt;math display="inline"&gt;\phi&lt;/math&gt; as a linear combination of eigenvectors &lt;math display="inline"&gt;\mathbf{v}_i&lt;/math&gt; of ''L'' (so that &lt;math display="inline"&gt;L\mathbf{v}_i = \lambda_i \mathbf{v}_i&lt;/math&gt;), with time-dependent &lt;math display="inline"&gt;\phi = \sum_i c_i \mathbf{v}_i.&lt;/math&gt;

Plugging into the original expression (note that we will use the fact that because ''L'' is a symmetric matrix, its unit-norm eigenvectors &lt;math display="inline"&gt;\mathbf{v}_i&lt;/math&gt; are orthogonal):

:&lt;math&gt;\begin{align}
  \frac{d\left(\sum_i c_i \mathbf{v}_i\right)}{dt} + kL\left(\sum_i c_i \mathbf{v}_i\right) &amp;= 0 \\
                    \sum_i \left[\frac{dc_i}{dt} \mathbf{v}_i + k c_i L \mathbf{v}_i\right] &amp;= \\
            \sum_i \left[\frac{dc_i}{dt} \mathbf{v}_i + k c_i \lambda_i \mathbf{v}_i\right] &amp;= \\
                                                          \frac{dc_i}{dt} + k \lambda_i c_i &amp;= 0, \\
\end{align}&lt;/math&gt;


whose solution is
:&lt;math&gt;c_i(t) = c_i(0) e^{-k \lambda_i t}.&lt;/math&gt;

As shown before, the eigenvalues &lt;math display="inline"&gt;\lambda_i&lt;/math&gt; of ''L'' are non-negative, showing that the solution to the diffusion equation approaches an equilibrium, because it only exponentially decays or remains constant. This also shows that given &lt;math display="inline"&gt;\lambda_i&lt;/math&gt; and the initial condition &lt;math display="inline"&gt;c_i(0)&lt;/math&gt;, the solution at any time ''t'' can be found.&lt;ref&gt;{{cite book
| last                  = Newman
| first                 = Mark
| authorlink            = Mark Newman
| title                 = Networks: An Introduction
| year                  = 2010
| publisher             = Oxford University Press
| isbn                  = 0199206651
}}&lt;/ref&gt;

To find &lt;math display="inline"&gt;c_i(0)&lt;/math&gt; for each &lt;math display="inline"&gt;i&lt;/math&gt; in terms of the overall initial condition &lt;math display="inline"&gt;\phi(0)&lt;/math&gt;, simply project &lt;math display="inline"&gt;\phi(0)&lt;/math&gt; onto the unit-norm eigenvectors &lt;math display="inline"&gt;\mathbf{v}_i&lt;/math&gt;;
: &lt;math&gt;c_i(0) = \left\langle \phi(0), \mathbf{v}_i \right\rangle &lt;/math&gt;.

In the case of undirected graphs, this works because &lt;math display="inline"&gt;L&lt;/math&gt; is symmetric, and by the [[spectral theorem]], its eigenvectors are all orthogonal.  So the projection onto the eigenvectors of &lt;math display="inline"&gt;L&lt;/math&gt; is simply an orthogonal coordinate transformation of the initial condition to a set of coordinates which decay exponentially and independently of each other.

=== Equilibrium behavior ===
To understand &lt;math display="inline"&gt;\lim_{t \to \infty}\phi(t)&lt;/math&gt;, note that the only terms &lt;math display="inline"&gt; c_i(t) = c_i(0) e^{-k \lambda_i t}&lt;/math&gt; that remain are those where &lt;math display="inline"&gt;\lambda_i = 0&lt;/math&gt;, since
: &lt;math&gt;\lim_{t\to\infty} e^{-k \lambda_i t} = \left\{\begin{array}{rlr}
  0 &amp; \text{if} &amp; \lambda_i &gt; 0 \\
  1 &amp; \text{if} &amp; \lambda_i = 0
\end{array}\right\}&lt;/math&gt;

In other words, the equilibrium state of the system is determined completely by the [[Kernel (linear algebra)|kernel]] of &lt;math display="inline"&gt;L&lt;/math&gt;.  

Since by definition, &lt;math display="inline"&gt;\sum_{j}L_{ij} = 0&lt;/math&gt;, the vector &lt;math display="inline"&gt;\mathbf{v}^1&lt;/math&gt; of all ones is in the kernel.  Note also that if there are &lt;math display="inline"&gt;k&lt;/math&gt; disjoint [[Connected component (graph theory)|connected components]] in the graph, then this vector of all ones can be split into the sum of &lt;math display="inline"&gt;k&lt;/math&gt; independent &lt;math display="inline"&gt;\lambda = 0&lt;/math&gt; eigenvectors of ones and zeros, where each connected component corresponds to an eigenvector with ones at the elements in the connected component and zeros elsewhere.

The consequence of this is that for a given initial condition &lt;math display="inline"&gt;c(0)&lt;/math&gt; for a graph with &lt;math display="inline"&gt;N&lt;/math&gt; vertices
: &lt;math&gt;\lim_{t\to\infty}\phi(t) = \left\langle c(0), \mathbf{v^1} \right\rangle \mathbf{v^1}&lt;/math&gt;

where
: &lt;math&gt;\mathbf{v^1} = \frac{1}{\sqrt{N}} [1, 1, ..., 1] &lt;/math&gt;

For each element &lt;math display="inline"&gt;\phi_j&lt;/math&gt; of &lt;math display="inline"&gt;\phi&lt;/math&gt;, i.e. for each vertex &lt;math display="inline"&gt;j&lt;/math&gt; in the graph, it can be rewritten as
: &lt;math&gt;\lim_{t\to\infty}\phi_j(t) = \frac{1}{N} \sum_{i = 1}^N c_i(0) &lt;/math&gt;.

In other words, at steady state, the value of &lt;math display="inline"&gt;\phi&lt;/math&gt; converges to the same value at each of the vertices of the graph, which is the average of the initial values at all of the vertices.  Since this is the solution to the heat diffusion equation, this makes perfect sense intuitively.  We expect that neighboring elements in the graph will exchange energy until that energy is spread out evenly throughout all of the elements that are connected to each other.

=== Example of the operator on a grid ===

[[File:Graph Laplacian Diffusion Example.gif|thumb|This GIF shows the progression of diffusion, as solved by the graph laplacian technique.  A graph is constructed over a grid, where each pixel in the graph is connected to its 8 bordering pixels.  Values in the image then diffuse smoothly to their neighbors over time via these connections.  This particular image starts off with three strong point values which spill over to their neighbors slowly.  The whole system eventually settles out to the same value at equilibrium.]]

This section shows an example of a function &lt;math display="inline"&gt;\phi&lt;/math&gt; diffusing over time through a graph.  The graph in this example is constructed on a 2D discrete grid, with points on the grid connected to their eight neighbors.  Three initial points are specified to have a positive value, while the rest of the values in the grid are zero.  Over time, the exponential decay acts to distribute the values at these points evenly throughout the entire grid.

The complete Matlab source code that was used to generate this animation is provided below.  It shows the process of specifying initial conditions, projecting these initial conditions onto the eigenvalues of the Laplacian Matrix, and simulating the exponential decay of these projected initial conditions.

&lt;source lang=matlab&gt;

N = 20;%The number of pixels along a dimension of the image
A = zeros(N, N);%The image
Adj = zeros(N*N, N*N);%The adjacency matrix

%Use 8 neighbors, and fill in the adjacency matrix
dx = [-1, 0, 1, -1, 1, -1, 0, 1];
dy = [-1, -1, -1, 0, 0, 1, 1, 1];
for x = 1:N
   for y = 1:N
       index = (x-1)*N + y;
       for ne = 1:length(dx)
           newx = x + dx(ne);
           newy = y + dy(ne);
           if newx &gt; 0 &amp;&amp; newx &lt;= N &amp;&amp; newy &gt; 0 &amp;&amp; newy &lt;= N
               index2 = (newx-1)*N + newy;
               Adj(index, index2) = 1;
           end
       end
   end
end

%%%BELOW IS THE KEY CODE THAT COMPUTES THE SOLUTION TO THE DIFFERENTIAL
%%%EQUATION
Deg = diag(sum(Adj, 2));%Compute the degree matrix
L = Deg - Adj;%Compute the laplacian matrix in terms of the degree and adjacency matrices
[V, D] = eig(L);%Compute the eigenvalues/vectors of the laplacian matrix
D = diag(D);

%Initial condition (place a few large positive values around and
%make everything else zero)
C0 = zeros(N, N);
C0(2:5, 2:5) = 5;
C0(10:15, 10:15) = 10;
C0(2:5, 8:13) = 7;
C0 = C0(:);

C0V = V'*C0;%Transform the initial condition into the coordinate system 
%of the eigenvectors
for t = 0:0.05:5
   %Loop through times and decay each initial component
   Phi = C0V.*exp(-D*t);%Exponential decay for each component
   Phi = V*Phi;%Transform from eigenvector coordinate system to original coordinate system
   Phi = reshape(Phi, N, N);
   %Display the results and write to GIF file
   imagesc(Phi);
   caxis([0, 10]);
   title(sprintf('Diffusion t = %3f', t));
   frame = getframe(1);
   im = frame2im(frame);
   [imind, cm] = rgb2ind(im, 256);
   if t == 0
      imwrite(imind, cm, 'out.gif', 'gif', 'Loopcount', inf, 'DelayTime', 0.1); 
   else
      imwrite(imind, cm, 'out.gif', 'gif', 'WriteMode', 'append', 'DelayTime', 0.1);
   end
end

&lt;/source&gt;

== Approximation to the negative continuous Laplacian ==
The graph Laplacian matrix can be further viewed as a matrix form of an approximation to the (positive semi-definite) [[Laplacian]] operator obtained by the [[finite difference method]].&lt;ref&gt;{{citation
 | last1 = Smola | first1 = Alexander J.
 | last2 = Kondor | first2 = Risi
 | contribution = Kernels and regularization on graphs
 | doi = 10.1007/978-3-540-45167-9_12
 | pages = 144–158
 | publisher = Springer
 | series = Lecture Notes in Computer Science
 | title = Learning Theory and Kernel Machines: 16th Annual Conference on Learning Theory and 7th Kernel Workshop, COLT/Kernel 2003, Washington, DC, USA, August 24–27, 2003, Proceedings
 | volume = 2777
 | year = 2003
}}.&lt;/ref&gt; In this interpretation, every graph vertex is treated as a grid point; the local connectivity of the vertex determines the finite difference approximation [[stencil (numerical analysis)|stencil]] at this grid point, the grid size is always one for every edge, and there are no constraints on any grid points, which corresponds to the case of the homogeneous [[Neumann boundary condition]], i.e., free boundary.
 
== Directed multigraphs ==
An analogue of the Laplacian matrix can be defined for directed multigraphs.&lt;ref name="Chaiken1978"&gt;{{cite journal
 | title = Matrix Tree Theorems 
 | author1=Chaiken, S. | author2=Kleitman, D. | authorlink2=Daniel Kleitman
 | journal = Journal of Combinatorial Theory, Series A 
 | volume = 24
 | number = 3
 | pages = 377–381
 | year = 1978
 | issn = 0097-3165
 | url = http://www.sciencedirect.com/science/article/pii/0097316578900675
 | doi=10.1016/0097-3165(78)90067-5
}}&lt;/ref&gt; In this case the Laplacian matrix ''L'' is defined as
:&lt;math&gt;L = D - A&lt;/math&gt;

where ''D'' is a diagonal matrix with ''D''&lt;sub&gt;''i'',''i''&lt;/sub&gt; equal to the outdegree of vertex ''i'' and ''A'' is a matrix with ''A''&lt;sub&gt;''i'',''j''&lt;/sub&gt; equal to the number of edges from ''i'' to ''j'' (including loops).

== See also ==
*[[Stiffness matrix]]
*[[Resistance distance]]
*[[Transition rate matrix]]

== References ==

{{reflist}}
*T. Sunada, "Discrete geometric analysis", ''Proceedings of Symposia in Pure Mathematics,'' (ed. by P. Exner, J. P. Keating, P. Kuchment, T. Sunada, A. Teplyaev), '''77''' (2008), 51–86.
*[[Béla Bollobás|B. Bollobás]], ''Modern Graph Theory'', Springer-Verlag (1998, corrected ed. 2013), {{ISBN|0-387-98488-7}}, Chapters II.3 (Vector Spaces and Matrices  Associated with Graphs), VIII.2 (The Adjacency Matrix and the Laplacian), IX.2 (Electrical Networks and Random Walks).

[[Category:Algebraic graph theory]]
[[Category:Matrices]]</text>
      <sha1>stvaej1fqn5s8d3gz4wgiqgqtum3ap7</sha1>
    </revision>
  </page>
  <page>
    <title>Liber Abaci</title>
    <ns>0</ns>
    <id>167699</id>
    <revision>
      <id>870998230</id>
      <parentid>870998012</parentid>
      <timestamp>2018-11-28T08:12:07Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>Undid revision 870998012 by [[Special:Contributions/UpdateNerd|UpdateNerd]] ([[User talk:UpdateNerd|talk]]) If you don't know Latin please stop trying to translate it. "il" is not latin. "ille" is the word you're looking for, but it means "that, which", not "the". And it would not be used in this context.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11864">{{italic title}}
[[Image:Liber abbaci magliab f124r.jpg|thumb|A page of the ''Liber Abaci'' from the [[National Central Library (Florence)|Biblioteca Nazionale di Firenze]] showing (on right) the numbers of the [[Fibonacci numbers|Fibonacci sequence]]. Note in particular the 2,8, and 9 which resemble [[Arabic numerals]] more than [[Eastern Arabic numerals]] or [[Indian numerals]]]]
'''''Liber Abaci''''' (also spelled as '''''Liber Abbaci''''')&lt;ref&gt;{{cite web|url=https://www.math.utah.edu/~beebe/software/java/fibonacci/liber-abaci.html|title=Fibonacci's Liber Abaci (Book of Calculation)|date=13 December 2009|website=[[The University of Utah]]|accessdate=27 November 2018}}&lt;/ref&gt; ("The Book of Calculation") is a 1202 historic book on [[arithmetic]] by Leonardo of Pisa, posthumously known as [[Fibonacci]].

''Liber Abaci'' was among the first Western books to describe the [[Hindu–Arabic numeral system]] and to use symbols traditionally described as "[[Arabic numerals]]". By addressing the applications of both commercial tradesmen and mathematicians, it contributed to convincing the public of the superiority of the  system, and the use of these glyphs.&lt;ref&gt;{{cite book| title=The Man of Numbers: Fibonacci's Arithmetic Revolution | author=Keith Devlin |date=2012 | publisher=Walker Books | ISBN=978-0802779083}}&lt;/ref&gt;

Although the book's title has also been translated as "The Book of the Abacus", {{harvtxt|Sigler|2002}} writes that this is an error: the intent of the book is to describe methods of doing calculations without aid of an [[abacus]], and as {{harvtxt|Ore|1948}} confirms, for centuries after its publication the [[algorism]]ists (followers of the style of calculation demonstrated in ''Liber Abaci'') remained in conflict with the abacists (traditionalists who continued to use the abacus in conjunction with Roman numerals).

The second version of ''Liber Abaci'' was dedicated to [[Michael Scot]] in 1227 CE.&lt;ref&gt;{{MacTutor|first=T.C.|last=Scott|first2=P.|last2=Marketos|id=Scot|title=Michael Scot}}&lt;/ref&gt;&lt;ref&gt;{{Citation|first1=T.C.|last1=Scott|first2=P.|last2=Marketos| url = http://www-history.mcs.st-andrews.ac.uk/Publications/fibonacci.pdf  | title = On the Origin of the Fibonacci Sequence |  publisher = [[MacTutor History of Mathematics archive]], University of St Andrews| format = PDF | date = March 2014}}&lt;/ref&gt;  No versions of the original 1202 book have been found.&lt;ref&gt;{{Cite web|title = The Man Behind Modern Math|url = http://www.barrons.com/articles/the-man-behind-modern-math-1440227497|access-date=7 June 2016|first = John Steele|last = Gordon|authorlink=John Steele Gordon}}&lt;/ref&gt;

==Summary of sections==
The first section introduces the Hindu–Arabic numeral system, including methods for converting between different representation systems. This section also includes the first known description of [[trial division]] for testing whether a number is [[composite number|composite]] and, if so, [[factorization|factoring]] it.&lt;ref&gt;{{cite journal | last = Mollin | first = Richard A. | doi = 10.2307/3219180 | issue = 1 | journal = Mathematics Magazine | mr = 2107288 | pages = 18–29 | title = A brief history of factoring and primality testing B. C. (before computers) | volume = 75 | year = 2002}} See also Sigler, pp.&amp;nbsp;65–66.&lt;/ref&gt;

The second section presents examples from commerce, such as conversions of [[currency]] and measurements, and calculations of [[Profit (accounting)|profit]] and [[interest]].

The third section discusses a number of mathematical problems; for instance, it includes (ch. II.12) the [[Chinese remainder theorem]], [[perfect number]]s and [[Mersenne prime]]s as well as formulas for [[arithmetic progression|arithmetic series]] and for [[square pyramidal number]]s. Another example in this chapter, describing the growth of a population of rabbits, was the origin of the [[Fibonacci sequence]] for which the author is most famous today.

The fourth section derives approximations, both numerical and geometrical, of [[irrational number]]s such as square roots.

The book also includes proofs in [[Euclidean geometry]]. Fibonacci's method of solving algebraic equations shows the influence of the early 10th-century Egyptian mathematician [[Abū Kāmil Shujāʿ ibn Aslam]].&lt;ref&gt;O'Connor, John J.; Robertson, Edmund F., "[http://www-history.mcs.st-andrews.ac.uk/Biographies/Abu_Kamil.html Abu Kamil Shuja ibn Aslam]", [[MacTutor History of Mathematics archive]].&lt;/ref&gt;

==Fibonacci's notation for fractions==
In reading ''Liber Abaci'', it is helpful to understand Fibonacci's notation for rational numbers, a notation that is intermediate in form between the [[Egyptian fraction]]s commonly used until that time and the [[vulgar fraction]]s still in use today&lt;ref&gt;{{cite journal |last1=Moyon |first1=Marc |last2=Spiesser |first2=Maryvonne |title=L’arithmétique des fractions dans l’œuvre de Fibonacci: fondements &amp; usages |journal=Archive for History of Exact Sciences |date=3 June 2015 |volume=69 |issue=4 |pages=391–427 |doi=10.1007/s00407-015-0155-y}}&lt;/ref&gt;. There are three key differences between Fibonacci's notation and modern fraction notation.
# We generally write a fraction to the right of the whole number to which it is added, for instance &lt;math&gt;\scriptstyle2\,\frac13&lt;/math&gt; for 7/3. Fibonacci instead would write the same fraction to the left, i.e., &lt;math&gt;\scriptstyle\frac13\,2&lt;/math&gt;.
# Fibonacci used a ''composite fraction'' notation in which a sequence of numerators and denominators shared the same fraction bar; each such term represented an additional fraction of the given numerator divided by the product of all the denominators below and to the right of it. That is, &lt;math&gt;\scriptstyle\frac{b\,\,a}{d\,\,c} = \frac{a}{c} + \frac{b}{cd}&lt;/math&gt;, and &lt;math&gt;\scriptstyle\frac{c\,\,b\,\,a}{f\,\,e\,\,d} = \frac{a}{d} + \frac{b}{de} + \frac{c}{def}&lt;/math&gt;.  The notation was read from right to left. For example, 29/30 could be written as &lt;math&gt;\scriptstyle\frac{1\,\,2\,\,4}{2\,\,3\,\,5}&lt;/math&gt;, representing the value &lt;math&gt;\scriptstyle\frac45+\frac2{3\times5}+\frac1{2\times3\times5}&lt;/math&gt;. This can be viewed as a form of [[mixed radix]] notation, and was very convenient for dealing with traditional systems of weights, measures, and currency. For instance, for units of length, a [[foot (length)|foot]] is 1/3 of a [[yard]], and an [[inch]] is 1/12 of a foot, so a quantity of 5 yards, 2 feet, and &lt;math&gt;\scriptstyle 7 \frac34&lt;/math&gt; inches could be represented as a composite fraction: &lt;math&gt;\scriptstyle\frac{3\ \,7\,\,2}{4\,\,12\,\,3}\,5&lt;/math&gt; yards. However, typical notations for traditional measures, while similarly based on mixed radixes, do not write out the denominators explicitly; the explicit denominators in Fibonacci's notation allow him to use different radixes for different problems when convenient. Sigler also points out an instance where Fibonacci uses composite fractions in which all denominators are 10, prefiguring modern decimal notation for fractions.
# Fibonacci sometimes wrote several fractions next to each other, representing a sum of the given fractions. For instance, 1/3+1/4 = 7/12, so a notation like &lt;math&gt;\scriptstyle\frac14\,\frac13\,2&lt;/math&gt; would represent the number that would now more commonly be written as the mixed number &lt;math&gt;\scriptstyle 2\,\frac{7}{12}&lt;/math&gt;, or simply the improper fraction &lt;math&gt;\scriptstyle\frac{31}{12}&lt;/math&gt;. Notation of this form can be distinguished from sequences of numerators and denominators sharing a fraction bar by the visible break in the bar. If all numerators are 1 in a fraction written in this form, and all denominators are different from each other, the result is an Egyptian fraction representation of the number. This notation was also sometimes combined with the composite fraction notation: two composite fractions written next to each other would represent the sum of the fractions.

The complexity of this notation allows numbers to be written in many different ways, and Fibonacci described several methods for converting from one style of representation to another. In particular, chapter II.7 contains a list of methods for converting an improper fraction to an Egyptian fraction, including the [[greedy algorithm for Egyptian fractions]], also known as the Fibonacci–Sylvester expansion.

== ''Modus Indorum'' ==

In the ''Liber Abaci'', Fibonacci says the following introducing the ''Modus Indorum'' or the method of the Indians, today known as [[Hindu–Arabic numerals]] or traditionally, just Arabic numerals.

:As my father was a public official away from our homeland in the [[Béjaïa|Bugia]] customshouse established for the Pisan merchants who frequently gathered there, he had me in my youth brought to him, looking to find for me a useful and comfortable future; there he wanted me to be in the study of mathematics and to be taught for some days. There from a marvelous instruction in the art of the nine Indian figures, the introduction and knowledge of the art pleased me so much above all else, and I learnt from them, whoever was learned in it, from nearby Egypt, Syria, Greece, Sicily and Provence, and their various methods, to which locations of business I travelled considerably afterwards for much study, and I learnt from the assembled disputations. But this, on the whole, the algorithm and even the Pythagorean arcs, I still reckoned almost an error compared to the Indian method. Therefore strictly embracing the Indian method, and attentive to the study of it, from mine own sense adding some, and some more still from the subtle Euclidean geometric art, applying the sum that I was able to perceive to this book, I worked to put it together in xv distinct chapters, showing certain proof for almost everything that I put in, so that further, this method perfected above the rest, this science is instructed to the eager, and to the Italian people above all others, who up to now are found without a minimum. If, by chance, something less or more proper or necessary I omitted, your indulgence for me is entreated, as there is no one who is without fault, and in all things is altogether circumspect.

:The nine Indian figures are: 
:9 8 7 6 5 4 3 2 1 
:With these nine figures, and with the sign 0 which the Arabs call zephir any number whatsoever is written... ({{harvnb|Sigler|2002}}; see {{harvnb|Grimm|1973}} for another translation)

In other words, in his book he advocated the use of the digits 0–9, and of [[place value]]. Until this time Europe used Roman Numerals, making modern mathematics almost impossible.  The book thus made an important contribution to the spread of decimal numerals. The spread of the Hindu-Arabic system, however, as Ore writes, was "long-drawn-out", taking [[History of the Hindu–Arabic numeral system#Adoption in Europe|many more centuries]] to spread widely, and did not become complete until the later part of the 16th century, accelerating dramatically only in the 1500s with the advent of printing.

==Notes==
{{reflist}}

==References==
{{Wikisourcelang|la|Liber abbaci}}
*{{citation
 | first=R. E. | last=Grimm
 | title = The Autobiography of Leonardo Pisano
 | journal = [[The Fibonacci Quarterly]]
 | volume = 11
 | issue = 1
 | year = 1973
 | pages = 99–104
 | url = http://www.fq.math.ca/Scanned/11-1/grimm.pdf}}.
*{{citation
 | title = Fibonacci's Liber Abaci
 | last = Sigler | first = Laurence E. (trans.)
 | publisher = Springer-Verlag
 | year = 2002
 | isbn = 0-387-95419-8}}.
*{{citation
 | title = Number Theory and its History
 | last = Ore | first = Øystein | authorlink = Øystein Ore
 | publisher = McGraw Hill
 | year = 1948}}. Dover version also available, 1988, {{isbn|978-0-486-65620-5}}.

{{Fibonacci}}

[[Category:1202 books]]
[[Category:Mathematics books]]
[[Category:13th-century Latin books]]
[[Category:13th century in science]]</text>
      <sha1>g495vzev6k5ako97v5li1j6jh01rl8n</sha1>
    </revision>
  </page>
  <page>
    <title>Long double</title>
    <ns>0</ns>
    <id>3686118</id>
    <revision>
      <id>828479960</id>
      <parentid>799796899</parentid>
      <timestamp>2018-03-02T20:19:14Z</timestamp>
      <contributor>
        <ip>2.26.39.61</ip>
      </contributor>
      <comment>/* Implementations */ Fix case in link.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8140">{{lowercase title}}
{{floating-point}}

In [[C (programming language)|C]] and related [[programming language]]s, &lt;code&gt;'''long double'''&lt;/code&gt; refers to a [[floating-point]] [[data type]] that is often more precise than [[double-precision]]. As with C's other floating-point types, it may not necessarily map to an [[IEEE floating-point standard|IEEE format]].

==&lt;code&gt;long double&lt;/code&gt; in C==

===History===

The &lt;code&gt;long double&lt;/code&gt; type was present in the original 1989 C standard,&lt;ref&gt;ANSI/ISO 9899-1990 American National Standard for Programming Languages - C, section 6.1.2.5.&lt;/ref&gt; but support was improved by the 1999 revision of the C standard, or [[C99]], which extended the standard [[Library (computer science)|library]] to include functions operating on &lt;code&gt;long double&lt;/code&gt; such as &lt;code&gt;sinl()&lt;/code&gt; and &lt;code&gt;strtold()&lt;/code&gt;.

Long double constants are floating-point constants suffixed with "L" or "l" (lower-case L), e.g., 0.333333333333333333L. Without a suffix, the evaluation depends on [[C99#IEEE.C2.A0754 floating point support|FLT_EVAL_METHOD]].

===Implementations===
On the [[x86 architecture]], most [[C (programming language)|C]] compilers implement &lt;code&gt;long double&lt;/code&gt; as the [[Extended precision#x86 extended precision format|80-bit extended precision]] type supported by x86 hardware (sometimes stored as 12 or 16 bytes to maintain [[data structure alignment]]), as specified in the [[C99]] / [[C11 (C standard revision)|C11]] standards (IEC 60559 floating-point arithmetic (Annex F)). &lt;!-- While not a WP:RS, http://computer-programming-forum.com/47-c-language/ae9c42837f4986aa.htm gives some insight on this. What I would really like is a source listing compilers that do and do not support this -Guy Macon 14:17, 3 May 2013 --&gt; An exception is [[Microsoft Visual C++]] for x86, which makes &lt;code&gt;long double&lt;/code&gt; a synonym for &lt;code&gt;double&lt;/code&gt;.&lt;ref&gt;[http://msdn.microsoft.com/en-us/library/9cx8xs15.aspx MSDN homepage, about Visual C++ compiler]&lt;/ref&gt; The [[Intel C++ compiler]] on Microsoft Windows supports extended precision, but requires the &lt;code&gt;/Qlong&amp;#8209;double&lt;/code&gt; switch for &lt;code&gt;long double&lt;/code&gt; to correspond to the hardware's extended precision format.&lt;ref&gt;[http://software.intel.com/en-us/articles/size-of-long-integer-type-on-different-architecture-and-os/ Intel Developer Site]&lt;/ref&gt;

Compilers may also use &lt;code&gt;long double&lt;/code&gt; for a 128-bit [[quadruple precision]] format. This is the case on [[HP-UX]]&lt;ref&gt;{{cite book|title=HP-UX Portability Guide - HP 9000 Computers|edition=2nd|author=Hewlett Packard|pages=5-3 and 5-37|url=http://www.textfiles.com/bitsavers/pdf/hp/9000_hpux/9.x/B2355-90025_HP-UX_Portability_Guide_Aug92.pdf|chapter=Porting C Programs|year=1992}}&lt;/ref&gt; and on [[Solaris (operating system)|Solaris]]/[[SPARC]]&lt;ref&gt;[http://docs.oracle.com/cd/E19957-01/806-3568/ncg_math.html Sun ''Numerical Computation Guide'', Chapter 2: IEEE Arithmetic]&lt;/ref&gt; machines. This format is currently implemented in software due to lack of [[Quadruple-precision floating-point format#Hardware support|hardware support]].

On some [[PowerPC]] and [[SPARC|SPARCv9]] machines,{{citation needed|date=August 2015}} &lt;code&gt;long double&lt;/code&gt; is implemented as a [[Double-double (arithmetic)|double-double]] arithmetic, where a &lt;code&gt;long double&lt;/code&gt; value is regarded as the exact sum of two double-precision values, giving at least a 106-bit precision; with such a format, the &lt;code&gt;long double&lt;/code&gt; type does not conform to the [[IEEE floating-point standard]]. Otherwise, &lt;code&gt;long double&lt;/code&gt; is simply a synonym for &lt;code&gt;double&lt;/code&gt; (double precision).

With the [[GNU C Compiler]], &lt;code&gt;long double&lt;/code&gt; is 80-bit extended precision on x86 processors regardless of the physical storage used for the type (which can be either 96 or 128 bits),&lt;ref&gt;[https://gcc.gnu.org/onlinedocs/gcc/i386-and-x86-64-Options.html Using the GNU Compiler Collection, i386 and x86-64 Options].&lt;/ref&gt; On some other architectures, &lt;code&gt;long double&lt;/code&gt; can be [[Double-double (arithmetic)|double-double]] (e.g. on [[PowerPC]]&lt;ref&gt;[https://gcc.gnu.org/onlinedocs/gcc/RS_002f6000-and-PowerPC-Options.html Using the GNU Compiler Collection, RS/6000 and PowerPC Options]&lt;/ref&gt;&lt;ref&gt;[https://developer.apple.com/legacy/mac/library/documentation/Performance/Conceptual/Mac_OSX_Numerics/Mac_OSX_Numerics.pdf Inside Macintosh - PowerPC Numerics] {{webarchive|url=https://web.archive.org/web/20121009191824/http://developer.apple.com/legacy/mac/library/documentation/Performance/Conceptual/Mac_OSX_Numerics/Mac_OSX_Numerics.pdf |date=2012-10-09 }}&lt;/ref&gt;&lt;ref&gt;[https://opensource.apple.com/source/gcc/gcc-5646/gcc/config/rs6000/darwin-ldouble.c 128-bit long double support routines for Darwin]&lt;/ref&gt;) or 128-bit [[quadruple precision]] (e.g. on [[SPARC]]&lt;ref&gt;[https://gcc.gnu.org/onlinedocs/gcc/SPARC-Options.html SPARC Options]&lt;/ref&gt;).  As of gcc 4.3, a quadruple precision is also supported on x86, but as the nonstandard type &lt;code&gt;__float128&lt;/code&gt; rather than &lt;code&gt;long double&lt;/code&gt;.&lt;ref&gt;[https://gcc.gnu.org/gcc-4.3/changes.html GCC 4.3 Release Notes]&lt;/ref&gt;

Although the x86 architecture, and specifically the [[x87]] floating-point instructions on x86, supports 80-bit extended-precision operations, it is possible to configure the processor to automatically round operations to double (or even single) precision.  Conversely, in extended-precision mode, extended precision may be used for intermediate compiler-generated calculations even when the final results are stored at a lower precision (i.e. [[C99#IEEE.C2.A0754 floating point support|FLT_EVAL_METHOD == 2]]).  With gcc on [[Linux]], 80-bit extended precision is the default; on several [[BSD]] operating systems ([[FreeBSD]] and [[OpenBSD]]), double-precision mode is the default, and &lt;code&gt;long double&lt;/code&gt; operations are effectively reduced to double precision.&lt;ref name=introgcc&gt;Brian J. Gough and Richard M. Stallman, ''An Introduction to GCC'', section 8.6 [http://www.network-theory.co.uk/docs/gccintro/gccintro_70.html Floating-point issues] (Network Theory Ltd., 2004).&lt;/ref&gt;  ([[NetBSD]] 7.0 and later, however, defaults to 80-bit extended precision &lt;ref&gt;{{cite web|url=https://www.netbsd.org/changes/changes-7.0.html|title=Significant changes from NetBSD 6.0 to 7.0}}&lt;/ref&gt;). However, it is possible to override this within an individual program via the FLDCW "floating-point load control-word" instruction.&lt;ref name=introgcc/&gt; On x86_64 the BSDs default to 80-bit extended precision.  Microsoft Windows with Visual C++ also sets the processor in double-precision mode by default, but this can again be overridden within an individual program (e.g. by the &lt;code&gt;_controlfp_s&lt;/code&gt; function in Visual C++&lt;ref&gt;[http://msdn.microsoft.com/en-us/library/c9676k6h%28v=vs.80%29.aspx _controlfp_s], [[Microsoft Developer Network]] (2/25/2011).&lt;/ref&gt;).  The Intel C++ Compiler for x86, on the other hand, enables extended-precision mode by default.&lt;ref&gt;Intel C++ Compiler Documentation, [http://www.nacad.ufrj.br/online/intel/Documentation/en_US/compiler_c/main_cls/index.htm Using the -fp-model (/fp) Option].&lt;/ref&gt; On OS X, long double is 80-bit extended precision &lt;ref&gt;https://developer.apple.com/library/mac/documentation/DeveloperTools/Conceptual/LowLevelABI/130-IA-32_Function_Calling_Conventions/IA32.html&lt;/ref&gt;
.

==Other specifications==

In [[CORBA]] (from specification of 3.0, which uses "[[IEEE 754-1985|ANSI/IEEE Standard 754-1985]]" as its reference), "the long double data type represents an IEEE double-extended floating-point number, which has an exponent of at least 15 bits in length and a signed fraction of at least 64 bits", with GIOP/IIOP CDR, whose floating-point types "exactly follow the IEEE standard formats for floating point numbers", marshalling this as what seems to be [[IEEE 754-2008]] binary128 a.k.a. quadruple precision without using that name.

==See also==
* [[Quadruple precision]]
* [[Extended precision]]

==References==
&lt;references/&gt;

{{DEFAULTSORT:Long Double}}
[[Category:Computer arithmetic]]
[[Category:Data types]]
[[Category:C (programming language)]]</text>
      <sha1>atzx40s65eqjci0a0bovr4yalffkbh2</sha1>
    </revision>
  </page>
  <page>
    <title>Lyapunov time</title>
    <ns>0</ns>
    <id>1117315</id>
    <revision>
      <id>870042760</id>
      <parentid>862716947</parentid>
      <timestamp>2018-11-22T00:37:43Z</timestamp>
      <contributor>
        <ip>86.0.187.177</ip>
      </contributor>
      <comment>/* Use */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2365">In [[mathematics]], the '''Lyapunov time''' is the characteristic timescale on which a [[dynamical system]] is [[chaos theory|chaotic]]. It is named after the [[Russia]]n [[mathematician]] [[Aleksandr Lyapunov]].  It is defined as the inverse of a system's largest [[Lyapunov exponent]].&lt;ref&gt;Boris P. Bezruchko, Dmitry A. Smirnov, Extracting Knowledge From Time Series: An Introduction to Nonlinear Empirical Modeling, Springer, 2010, pp. 56--57&lt;/ref&gt;

==Use==
The Lyapunov time mirrors the limits of the [[predictability]] of the system. By convention, it is defined as the time for the distance between nearby [[trajectories]] of the system to increase by a factor of ''[[e (mathematical constant)|e]]''. However, measures in terms of 2-foldings and 10-foldings are sometimes found, since they correspond to the loss of one bit of information or one digit of precision respectively.&lt;ref name="gaspard" /&gt;

While it is used in many applications of dynamical systems theory, it has been particularly used in [[celestial mechanics]] where it is important for the [[stability of the Solar System]] question. However, empirical estimation of the Lyapunov time is often associated with computational or inherent uncertainties.&lt;ref&gt;G. Tancredi, A. Sánchez, F. ROIG. A comparison between methods to compute Lyapunov Exponents. The Astronomical Journal, 121:1171-1179, 2001 February&lt;/ref&gt;&lt;ref&gt;E. Gerlach, On the Numerical Computability of Asteroidal Lyapunov Times, https://arxiv.org/abs/0901.4871&lt;/ref&gt;

==Examples==
Typical values are:&lt;ref name="gaspard"&gt;Pierre Gaspard, Chaos, Scattering and Statistical Mechanics, Cambridge University Press, 2005. p. 7&lt;/ref&gt;
{| class="wikitable"
|-
! System !! Lyapunov time
|-
| [[Solar system]] || 5 million years
|-
| [[Pluto]]'s orbit|| 20 million years
|-
| [[Obliquity]] of [[Mars]] || 1–5 million years
|-
| orbit of [[36 Atalante]] || 4,000 years
|-
| Rotation of [[Hyperion (moon)|Hyperion]] || 36 days
|-
| Chemical chaotic oscillations|| 5.4 minutes
|-
| Hydrodynamic chaotic oscillations|| 2 seconds
|-
| 1 cubic cm of [[argon]] at room temperature|| 3.7×10&lt;sup&gt;−11&lt;/sup&gt; seconds
|-
| 1 cubic cm of argon at triple point|| 3.7×10&lt;sup&gt;−16&lt;/sup&gt; seconds
|}

==See also==
* [[Belousov–Zhabotinsky reaction]]
* [[Molecular chaos]]
* [[Three-body problem]]

==References==
{{reflist}}

[[Category:Dynamical systems]]</text>
      <sha1>66tadql8mrz1u1cng81tjqh9cndci8v</sha1>
    </revision>
  </page>
  <page>
    <title>Maria Hasse</title>
    <ns>0</ns>
    <id>56689677</id>
    <revision>
      <id>832917368</id>
      <parentid>827779884</parentid>
      <timestamp>2018-03-28T17:44:01Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>Removed invisible unicode characters + other fixes ([[User:Yobot/55|Task 55]]), replaced: →   (2) using [[Project:AWB|AWB]] (12151)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5671">'''Maria-Viktoria Hasse''' (May 30, 1921 – January 10, 2014) was a German mathematician who became the first female professor in the faculty of mathematics and science at [[TU Dresden]].{{r|voss}} She wrote books on [[set theory]] and [[category theory]],{{r|rostock}} and is known as one of the namesakes of the [[Gallai–Hasse–Roy–Vitaver theorem]] in [[graph coloring]].

==Education and career==
Hasse was born in [[Warnemünde]]. She went to the [[Gymnasium (Germany)|gymnasium]] in [[Rostock]], and after a term in the [[Reich Labour Service]] from 1939 to 1940, studied mathematics, physics, and philosophy at the [[University of Rostock]] and [[University of Tübingen]] from 1940 to 1943, earning a diploma in 1943 from Rostock. She continued at Rostock as an assistant and lecturer, earning a doctorate (Dr. rer. nat.) in 1949 and a [[habilitation]] in 1954.{{r|rostock|voss}} Her doctoral dissertation, ''Über eine singuläre Intergralgleichung 1. Art mit logarithmischer Unstetigkeit'' [On a singular integral equation of the 1st kind with logarithmic discontinuity], was supervised by Hans Schubert;{{r|mgp}} her habilitation thesis was ''Über eine Hillsche Differentialgleichung'' [On [[Hill differential equation|Hill's differential equation]]]. She worked as a professor of algebra at TU Dresden from 1954 until her 1981 retirement.&lt;ref&gt;{{harvtxt|Voss|2016}} The Rostock CPR gives the date of her start at Dresden as 1964, but this would leave a ten-year gap in her work life, and Voss is clear that she arrived before the 1962 start of Lieselott Herforth.&lt;/ref&gt;

==Contributions==
With Lothar Michler, Hasse wrote ''Theorie der Kategorien'' [Category Theory] (Deutscher Verlag, 1966).{{r|isbell}} She also wrote ''Grundbegriffe der Mengenlehre und Logik'' [Basic Concepts of Set Theory and Logic] (Harri Deutsch, 1968).{{r|gml}}

In the theory of [[graph coloring]], the [[Gallai–Hasse–Roy–Vitaver theorem]] provides a duality between colorings of the vertices of a graph and [[Orientation (graph theory)|orientations]] of its edges. It states that the minimum number of colors needed in a coloring equals the number of vertices in a [[longest path]], in an orientation chosen to minimize the length of this path. It was stated in 1958 in a graph theory textbook by [[Claude Berge]], and independently published by Hasse, [[Tibor Gallai]], B. Roy, and L. Vitaver. Hasse's publication of this result was the second chronologically, in 1965.{{r|ghrv}}

==References==
{{reflist|refs=

&lt;ref name=ghrv&gt;Independent publications of the [[Gallai–Hasse–Roy–Vitaver theorem]]:
*{{citation|first=Tibor|last=Gallai|authorlink=Tibor Gallai|contribution=On directed graphs and circuits|title=Theory of Graphs (Proceedings of the Colloquium Tihany 1966)|publisher=Academic Press|location=New York|year=1968|pages=115–118}}
*{{citation
 | last = Витавер | first = Л. М.
 | journal = [[Proceedings of the USSR Academy of Sciences|Doklady Akademii Nauk SSSR]]
 | language = Russian
 | mr = 0145509
 | pages = 758–759
 | title = Нахождение минимальных раскрасок вершин графа с помощью булевых степеней матрицы смежностей [Determination of minimal coloring of vertices of a graph by means of Boolean powers of the incidence matrix]
 | volume = 147
 | year = 1962}}
*{{citation
 | last = Hasse | first = Maria
 | doi = 10.1002/mana.19650280503
 | issue = 5–6
 | journal = [[Mathematische Nachrichten]]
 | language = German
 | mr = 0179105
 | pages = 275–290
 | title = Zur algebraischen Begründung der Graphentheorie. I
 | volume = 28
 | year = 1965}}
*{{citation
 | last = Roy | first = B.
 | issue = 5
 | journal = Rev. Française Informat. Recherche Opérationnelle
 | language = French
 | mr = 0225683
 | pages = 129–132
 | title = Nombre chromatique et plus longs chemins d'un graphe
 | url = http://archive.numdam.org/ARCHIVE/M2AN/M2AN_1967__1_5/M2AN_1967__1_5_129_0/M2AN_1967__1_5_129_0.pdf
 | volume = 1
 | year = 1967}}
For an overview of the theorem and its history, see
{{citation
 | last1 = Nešetřil | first1 = Jaroslav | author1-link = Jaroslav Nešetřil
 | last2 = Ossona de Mendez | first2 = Patrice | author2-link = Patrice Ossona de Mendez
 | contribution = Theorem 3.13
 | doi = 10.1007/978-3-642-27875-4
 | isbn = 978-3-642-27874-7
 | location = Heidelberg
 | mr = 2920058
 | page = 42
 | publisher = Springer
 | series = Algorithms and Combinatorics
 | title = Sparsity: Graphs, Structures, and Algorithms
 | volume = 28
 | year = 2012}}.&lt;/ref&gt;

&lt;ref name=gml&gt;{{MR|0215725}}&lt;/ref&gt;

&lt;ref name=isbell&gt;{{citation|title=Review of ''Theorie der Kategorien''|journal=[[Mathematical Reviews]]|first=J. R.|last=Isbell|authorlink=John R. Isbell|mr=0213411}}&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=37680}}&lt;/ref&gt;

&lt;ref name=rostock&gt;{{citation|url=http://cpr.uni-rostock.de/resolve/id/cpr_person_00002355|title=Hasse, Maria-Viktoria|work=Catalogus professorum rostochienium|publisher=University of Rostock|accessdate=2018-02-25}}&lt;/ref&gt;

&lt;ref name=voss&gt;{{citation|language=German|title=Lieselott Herforth: Die erste Rektorin einer deutschen Universität|first=Waltraud|last=Voss|publisher=transcript Verlag|year=2016|series=Gender studies|isbn=9783839435458|pages=127–128}}&lt;/ref&gt;

}}

{{Authority control}}

{{DEFAULTSORT:Hasse, Maria}}
[[Category:1921 births]]
[[Category:2014 deaths]]
[[Category:German mathematicians]]
[[Category:Women mathematicians]]
[[Category:Graph theorists]]
[[Category:Set theorists]]
[[Category:Category theorists]]
[[Category:University of Rostock alumni]]
[[Category:Dresden University of Technology faculty]]</text>
      <sha1>6454pih6g25n98nmy28pvzl77i9elej</sha1>
    </revision>
  </page>
  <page>
    <title>Michael D. Fried</title>
    <ns>0</ns>
    <id>51171385</id>
    <revision>
      <id>871137549</id>
      <parentid>846679705</parentid>
      <timestamp>2018-11-29T04:47:24Z</timestamp>
      <contributor>
        <username>Alaney2k</username>
        <id>209266</id>
      </contributor>
      <minor/>
      <comment>/* top */US =&gt; Americans</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9351">{{Infobox scientist
|name              = Michael David Fried
|image             = 
|image_size        = 
|caption           = 
|birth_date        = 
|birth_place       = 
|death_date        = 
|death_place       = 
|nationality       = [[Americans|American]]
|fields            = [[Mathematics]]
|workplaces        = [[Stony Brook University]] &lt;br&gt; [[University of California, Irvine]] &lt;br&gt;[[University of Florida]]&lt;br&gt;[[Hebrew University of Jerusalem]]
|alma_mater        = [[University of Michigan]] 
|doctoral_advisor  = [[Donald John Lewis]]
|doctoral_students = Chidambaram Alimoolam&lt;br&gt;Ronald Biggers&lt;br&gt;Castillo Del&lt;br&gt;Paul Bailey&lt;br&gt;Darren Semmen
|known_for  = [[inverse Galois problem]]&lt;br&gt;[[modular tower program]]&lt;br&gt;[[monodromy method]]&lt;br&gt;[[branch cycle lemma]] &lt;br&gt;[[Nielsen class]]&lt;br&gt;[[Galois stratification]] &lt;br&gt; proofs of Schur's conjecture and [[Davenport's problem]] 
|awards      =
}}
'''Michael David Fried'''  is an American mathematician working in the [[geometry]] and [[arithmetic]] of families of nonsingular projective curve covers.  He uses [[Representation theory of finite groups|group representation theory]] to avoid solving equations (the [[monodromy method]]).

Fried's mathematical articles can be roughly divided into four groups: Arithmetic of Covers and Regular Inverse Galois Problem,&lt;ref&gt;{{cite journal | last = Fried | first = M.| year = 1977 | title = Fields of Definition of Function Fields and Hurwitz Families – Groups as Galois Groups| url = https://www.researchgate.net/publication/243044779_Fields_of_definition_of_function_fields_and_Hurwitz_families-groups_as_Galois_groups | journal = Communications in Algebra | volume = 5 | issue = 1| pages = 17–82|doi= 10.1080/00927877708822158}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last = Fried | first = Michael | year = 1978 | title = Galois groups and complex multiplication| url = http://www.ams.org/journals/tran/1978-235-00/S0002-9947-1978-0472917-6/S0002-9947-1978-0472917-6.pdf| journal = Trans. Amer. Math. Soc. | volume = 235 | issue = | pages = 141–163|doi=10.1090/S0002-9947-1978-0472917-6}}&lt;/ref&gt; 
&lt;ref&gt;{{cite journal|last1=Fried|first1=Michael D.|last2= Völklein |first2=Helmut|title= The inverse Galois problem and rational points on moduli spaces |journal=Math. Ann.|volume=290|issue=|year=1991|pages=771–800|url = http://gdz.sub.uni-goettingen.de/dms/load/img/?PID=GDZPPN002335689||doi=10.1007/bf01459271}}&lt;/ref&gt;
&lt;ref&gt;{{cite journal|last1=Fried|first1=Michael D.|last2= Völklein |first2=Helmut|title= The embedding problem over an Hilbertian-PAC field |journal= Annals of Mathematics|volume=136|issue=3|year=1992|pages=469–481|jstor = 2946573  |doi= 10.2307/2946573 }}&lt;/ref&gt;
&lt;ref&gt;{{cite journal | last = Fried | first = Michael D.| year = 2010 | title = Alternating groups and moduli space lifting Invariants | url = https://link.springer.com/article/10.1007%2Fs11856-010-0073-2#page-1| journal = Israel J. Math. | volume = 179 | issue = | pages = 57–125| doi=  10.1007/s11856-010-0073-2| arxiv = math/0611591}}&lt;/ref&gt; 
Hilbert's Irreducibility Theorem,&lt;ref&gt;{{cite journal | last = Fried | first = Michael | year = 1974 | title = On Hilbert's irreducibility theorem | url = | journal = Journal of Number Theory| volume = 6 | issue =3 | pages = 211–232| doi=  10.1016/0022-314X(74)90015-8 | bibcode = 1974JNT.....6..211F}}&lt;/ref&gt;
&lt;ref&gt;{{cite journal | last = Fried | first = M.| year = 1985 | title = On the Sprindzuk-Weissauer approach to universal Hilbert subsets | url = https://zenodo.org/record/1059145 | journal = Israel Journal of Mathematics| volume = 51| issue =4 | pages = 347–363| doi= 10.1007/BF02764725 }}&lt;/ref&gt; Finite fields and Diophantine problems,
&lt;ref&gt;{{cite journal | last = Fried | first = Michael | year = 1970 | title = On a Conjecture of Schur | url = https://projecteuclid.org/download/pdf_1/euclid.mmj/1029000374 | journal = Michigan Math. J.| volume = 17 | issue =1 | pages = 41–55| doi= 10.1307/mmj/1029000374}}&lt;/ref&gt;
&lt;ref&gt;{{cite journal | last = Fried | first = Michael | year = 1973 | title = The field of definition of function fields and a problem in the reducibility of polynomials in two variables | url = http://projecteuclid.org/download/pdf_1/euclid.ijm/1256052044| journal = Illinois J.  Math. | volume = 17 | issue =1 | pages = 128–146| doi= }}&lt;/ref&gt; 
&lt;ref&gt;{{cite journal|last1=Fried|first1=M.|last2= Sacerdote |first2=G.|title= Solving diophantine problems over all residue classes of a number fields and all finite fields | journal=Annals of Mathematics|volume=104|issue=2|year=1976|pages=203–233|url = |doi=10.2307/1971045}}&lt;/ref&gt;&lt;ref&gt;{{cite journal| last = Fried | first = Michael D. | year = 2005 | title =  The place of exceptional covers among all diophantine relations| journal= Finite fields and their applications| volume= 11| issue =3| pages = 367–433|doi= 10.1016/j.ffa.2005.06.005}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last = Fried | first = Michael D.| year = 2012 | title = Variables separated equations: Strikingly different roles for the Branch Cycle Lemma and the Finite Simple Group Classification | url = https://link.springer.com/article/10.1007/s11425-011-4324-4 | journal = Science China Mathematics | volume = 55 | issue = 1| pages = 1–72| doi=  10.1007/s11425-011-4324-4 | arxiv = 1012.5297| bibcode = 2012ScChA..55....1F}}&lt;/ref&gt;   and Modular Towers and Strong Torsion Conjecture
&lt;ref&gt;Michael D.  Fried, Introduction to Modular Towers: Generalizing dihedral group–modular curve connections, Recent Developments in the Inverse Galois Problem (Seattle, WA, 1993), 111–171, Contemp.  Math. , 186, Amer. Math. Soc., Providence, RI, 1995, {{ISBN|978-0-8218-0299-1}}&lt;/ref&gt;
&lt;ref&gt;Michael D.  Fried and Yaacov Kopeliovich, Applying Modular Towers to the Inverse Galois Problem, Geometric Galois Actions, 2, 151–175, London Math. Soc. Lecture Note Ser., 243,Cambridge Univ. Press, Cambridge, 1997, {{ISBN|978-0-521-59641-1}}.&lt;/ref&gt;
&lt;ref&gt;Paul Bailey and Michael D. Fried, Hurwitz monodromy, spin separation and higher levels of a Modular Tower, Arithmetic fundamental groups and noncommutative algebra (Berkeley, CA, 1999), 79–220, Proc. Sympos. Pure Math., 70, Amer. Math. Soc., Providence, RI, 2002, {{ISBN|978-0-8218-2036-0}}.&lt;/ref&gt;
.&lt;ref&gt;Michael D. Fried, The Main Conjecture of Modular Towers and its higher rank generalization,  Groupes de Galois arithmétique et différentiels,  165–233, Sémin. Congr., 13, Soc. Math. France, Paris, 2006,  {{ISBN|978-2-85629-222-8}}.&lt;/ref&gt;

==Career==
Fried got his [[Doctor of Philosophy|PhD]]  from [[University of Michigan]] in [[Mathematics]] (1964–1967); from 1959–1961 he got his [[undergraduate degree]] from  [[Michigan State University]] in [[electrical engineering]]. Between those degrees he worked for three years as an [[Aerospace engineering|aerospace electrical engineer]]. This included work on the [[Apollo Lunar Module|Lunar Excursion Module]] and the [[USS Nautilus (SSN-571)|Nautilus submarine]] .
He chose the two years of [[Postdoctoral researcher|postdoctoral]] at the 
[[Institute for Advanced Study]]  in [[Princeton, New Jersey|Princeton]] (1967–1969). Before living in Montana in 2004, he was a [[Professor]] at   [[Stony Brook University]] (8 years), [[University of California, Irvine|University of California at Irvine]] (26 years), [[University of Florida]] (3 years)  and [[Hebrew University of Jerusalem|Hebrew University]] (2 years). He has been a [[Professors in the United States|visiting professor]] at [[Massachusetts Institute of Technology|MIT]], [[Mathematical Sciences Research Institute|MSRI]],  University of Michigan,   University of Florida,  Hebrew University and [[Tel Aviv University]]. He has been an [[editing|editor]] on several mathematics journals including the Research Announcements of the [[Bulletin of the American Mathematical Society]], and the Journal of Finite Fields and its Applications{{Citation needed|date=May 2018}}. He was included in the inaugural (2013) class of Fellows of the [[American Mathematical Society|AMS]]{{Citation needed|date=May 2018}}.
Frieds fellowships include [[Alfred P. Sloan Foundation]] (1972–1974), [[Lady Davis Fellows|Lady Davis Fellow]] at Hebrew University  (1987–1988), [[Fulbright Program|Fulbright]] spent at [[University of Helsinki|Helsinki University]] (1982–1983), [[Alexander von Humboldt Foundation|Alexander von Humboldt Research Fellowship]]  (1994–1996), and the two periods at the Institute for Advanced Study (Fall, 1967 to Spring 1969 and Spring 1974).

===Arithmetic of covers and regular inverse Galois problem===

=== Hilbert's irreducibility theorem ===

=== Finite fields and Diophantine problems ===

=== Modular towers and strong torsion conjecture ===

===Other work===

==See also==
*[[Field arithmetic]]

==References==
{{reflist}}

==External links==
{{wikiquote}}
* [http://www.math.uci.edu/~mfried/ Michael Fried's Home Page]
* {{MathGenealogy |id=5462 |name=Michael David Fried }}

{{Authority control}}

{{DEFAULTSORT:Fried, Michael D.}}
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Algebraists]]
[[Category:Algebraic geometers]]
[[Category:Number theorists]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:University of Michigan alumni]]
[[Category:Sloan Research Fellows]]</text>
      <sha1>hsd5bu8fu8hahuyhkxrnxo7o833zpsv</sha1>
    </revision>
  </page>
  <page>
    <title>Mixed-data sampling</title>
    <ns>0</ns>
    <id>1508682</id>
    <revision>
      <id>808319100</id>
      <parentid>790734206</parentid>
      <timestamp>2017-11-02T04:10:11Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v475)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2601">'''Mixed-data sampling (MIDAS)''' is an [[econometric]] regression or filtering method developed by Ghysels ''et al.'' There is now a substantial literature on MIDAS regressions and their applications, including Andreou et al. (2010),&lt;ref&gt;Andreou, Elena &amp; Eric Ghysels &amp; Andros Kourtellos "Regression Models with Mixed Sampling Frequencies", Journal of Econometrics, 158, 246-261.&lt;/ref&gt; and especially Andreou et al. (2013).&lt;ref&gt;Andreou, Elena &amp; Eric Ghysels &amp; Andros Kourtellos "Should macroeconomic forecasters use daily financial data and how?",  Journal of Business and Economic Statistics 31, 240-251.
&lt;/ref&gt;

A simple regression example has the [[independent variable]] appearing at a higher frequency than the [[dependent variable]]:

:&lt;math&gt;y_t = \beta_0 + \beta_1 B(L^{1/m};\theta)x_t^{(m)} + \varepsilon_t^{(m)},&lt;/math&gt;

where ''y'' is the dependent variable, ''x'' is the regressor, ''m'' denotes the frequency &amp;ndash; for instance if ''y'' is yearly &lt;math&gt;x_t^{(4)}&lt;/math&gt; is quarterly &amp;ndash; &lt;math&gt;\varepsilon&lt;/math&gt; is the disturbance and &lt;math&gt;B(L^{1/m};\theta)&lt;/math&gt; is a lag distribution, for instance the [[beta function|Beta]] function or the [[Distributed lag#Finite distributed lags|Almon Lag]].

The regression models can be viewed in some cases as substitutes for the [[Kalman filter]] when applied in the context of mixed frequency data. Bai, Ghysels and Wright (2010) examine the relationship between MIDAS regressions and Kalman filter state space models applied to mixed frequency data. In general, the latter involve a system of equations, whereas in contrast MIDAS
regressions involve a (reduced form) single equation. As a consequence, MIDAS regressions might be less efficient, but also less prone to specification errors. In cases where the MIDAS regression is only an approximation, the approximation errors tend to be small.

==See also==
* [[Distributed lag]]
* [[ARMAX]]

==References==
{{Reflist}}
* Bai, J., [[Eric Ghysels]] and Jonathan Wright (2010), State Space Models and MIDAS Regressions, Discussion Paper UNC.
* [[Eric Ghysels]], Sinko, A., Valkanov, R. (2007) ''MIDAS Regressions: Further Results and New Directions''.  [[Econometric Reviews]], 26 (1), 53&amp;ndash;90

==External links==
* [http://www.unc.edu/~eghysels/ Eric Ghysels]
* [https://mpiktas.github.io/midasr// R code for midas regression models]
* [http://www.mathworks.com/matlabcentral/fileexchange/45150-midas-regression/ Matlab code for midas regression models]

[[Category:Econometric modeling]]
[[Category:Time series models]]
[[Category:Statistical forecasting]]


{{econometrics-stub}}</text>
      <sha1>nd9kiywaef8mwqyx6vm0omyw1uu7va7</sha1>
    </revision>
  </page>
  <page>
    <title>Nagata's conjecture</title>
    <ns>0</ns>
    <id>34996922</id>
    <revision>
      <id>808032597</id>
      <parentid>747596341</parentid>
      <timestamp>2017-10-31T13:38:29Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v475)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1590">{{for|the conjecture about curves|Nagata's conjecture on curves}}
In [[algebra]], '''Nagata's conjecture''' states that '''Nagata's automorphism''' of the polynomial ring ''k''[''x'',''y'',''z''] is [[Wild automorphism|wild]]. The conjecture was proposed by {{harvs|txt|last=Nagata|authorlink= Masayoshi Nagata|year=1972}} and proved by {{harvs|txt| last1=Umirbaev | first1=Ualbai U. | last2=Shestakov | first2=Ivan P. | title=The tame and the wild automorphisms of polynomial rings in three variables | url=https://dx.doi.org/10.1090/S0894-0347-03-00440-5 | doi=10.1090/S0894-0347-03-00440-5 |mr=2015334 | year=2004 | journal=[[Journal of the American Mathematical Society]] | issn=0894-0347 | volume=17 | issue=1 | pages=197–227}}.

Nagata's automorphism is given by
:&lt;math&gt;(x,y,z)\mapsto(x-2(xz+y^2)y-(xz+y^2)^2z,y+(xz+y^2)z,z).&lt;/math&gt;

==References==

*{{Citation | last1=Nagata | first1=Masayoshi | author1-link=Masayoshi Nagata | title=&lt;nowiki&gt;On automorphism group of k[x,y]&lt;/nowiki&gt; | url=https://books.google.com/books?id=qvruAAAAMAAJ | publisher=Kinokuniya Book-Store Co. Ltd. | location=Tokyo |mr=0337962 | year=1972}}
*{{Citation | last1=Umirbaev | first1=Ualbai U. | last2=Shestakov | first2=Ivan P. | title=The tame and the wild automorphisms of polynomial rings in three variables | url=https://dx.doi.org/10.1090/S0894-0347-03-00440-5 | doi=10.1090/S0894-0347-03-00440-5 |mr=2015334 | year=2004 | journal=[[Journal of the American Mathematical Society]] | issn=0894-0347 | volume=17 | issue=1 | pages=197–227}}

[[Category:Field theory]]
[[Category:Theorems in algebra]]</text>
      <sha1>5xeycu8f6llzuy4thpe4ngpi0gm73p1</sha1>
    </revision>
  </page>
  <page>
    <title>Normal space</title>
    <ns>0</ns>
    <id>48629</id>
    <revision>
      <id>870971635</id>
      <parentid>811450277</parentid>
      <timestamp>2018-11-28T03:33:26Z</timestamp>
      <contributor>
        <username>Yahya Abdal-Aziz</username>
        <id>313039</id>
      </contributor>
      <comment>/* Relationships to other separation axioms */ copy-edit: replace "normally" by "usually" to avoid confusion</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10765">{{for|normal vector space|normal (geometry)}}
{{Separation axioms}}

In [[topology]] and related branches of [[mathematics]], a '''normal space''' is a [[topological space]] ''X'' that satisfies '''Axiom T&lt;sub&gt;4&lt;/sub&gt;''': every two disjoint [[closed set]]s of ''X'' have disjoint [[open neighborhood]]s. A normal [[Hausdorff space]] is also called a '''T&lt;sub&gt;4&lt;/sub&gt; space'''. These conditions are examples of [[separation axiom]]s and their further strengthenings define '''completely normal Hausdorff spaces''', or '''T&lt;sub&gt;5&lt;/sub&gt; spaces''', and '''perfectly normal Hausdorff spaces''', or '''T&lt;sub&gt;6&lt;/sub&gt; spaces'''.

== Definitions ==

A [[topological space]] ''X'' is a '''normal space''' if, given any [[disjoint sets|disjoint]] [[closed set]]s ''E'' and ''F'', there are [[neighbourhood (topology)|neighbourhoods]] ''U'' of ''E'' and ''V'' of ''F'' that are also disjoint. More intuitively, this condition says that ''E'' and ''F'' can be [[separated set|separated by neighbourhoods]].

[[File:Normal space.svg|thumb|203px|The closed sets E and F, here represented by closed disks on opposite sides of the picture, are separated by their respective neighbourhoods U and V, here represented by larger, but still disjoint, open disks.]]

A '''T&lt;sub&gt;4&lt;/sub&gt; space''' is a [[T1 space|T&lt;sub&gt;1&lt;/sub&gt; space]] ''X'' that is normal; this is equivalent to ''X'' being normal and [[Hausdorff space|Hausdorff]].

A '''completely normal space''' or a '''{{visible anchor|hereditarily normal space}}''' is a topological space ''X'' such that every [[subspace (topology)|subspace]] of ''X'' with subspace topology is a normal space. It turns out that ''X'' is completely normal if and only if every two [[separated set]]s can be separated by neighbourhoods.

A '''completely T&lt;sub&gt;4&lt;/sub&gt; space''', or '''T&lt;sub&gt;5&lt;/sub&gt; space''' is a completely normal [[T1 space|T&lt;sub&gt;1&lt;/sub&gt; space]] topological space ''X'', which implies that ''X'' is [[Hausdorff space|Hausdorff]]; equivalently, every subspace of ''X'' must be a T&lt;sub&gt;4&lt;/sub&gt; space.

A '''perfectly normal space''' is a topological space ''X'' in which every two disjoint closed sets ''E'' and ''F'' can be precisely separated by a [[continuous function]] ''f'' from ''X'' to the [[real line]] '''R''': the [[preimage]]s of {0} and {1} under ''f'' are, respectively, ''E'' and ''F''. (In this definition, the real line can be replaced with the [[unit interval]] [0,1].)

It turns out that ''X'' is perfectly normal if and only if ''X'' is normal and every closed set is a [[G-delta set|''G''&lt;sub&gt;δ&lt;/sub&gt; set]]. Equivalently, ''X'' is perfectly normal if and only if every closed set is a [[zero set]]. Every perfectly normal space is automatically completely normal.&lt;ref name="Munkres p213"&gt;{{harvnb|Munkres|2000|p=213}}&lt;/ref&gt;

A Hausdorff perfectly normal space ''X'' is a '''T&lt;sub&gt;6&lt;/sub&gt; space''', or '''perfectly T&lt;sub&gt;4&lt;/sub&gt; space'''.

Note that the terms "normal space" and "T&lt;sub&gt;4&lt;/sub&gt;" and derived concepts occasionally have a different meaning. (Nonetheless, "T&lt;sub&gt;5&lt;/sub&gt;" always means the same as "completely T&lt;sub&gt;4&lt;/sub&gt;", whatever that may be.) The definitions given here are the ones usually used today. For more on this issue, see [[History of the separation axioms]].

Terms like "normal [[regular space]]" and "normal Hausdorff space" also turn up in the literature&amp;nbsp;– they simply mean that the space both is normal and satisfies the other condition mentioned. In particular, a normal Hausdorff space is the same thing as a T&lt;sub&gt;4&lt;/sub&gt; space. Given the historical confusion of the meaning of the terms, verbal descriptions when applicable are helpful, that is, "normal Hausdorff" instead of "T&lt;sub&gt;4&lt;/sub&gt;", or "completely normal Hausdorff" instead of "T&lt;sub&gt;5&lt;/sub&gt;".

[[Fully normal space]]s and [[paracompact Hausdorff space|fully T&lt;sub&gt;4&lt;/sub&gt; space]]s are discussed elsewhere; they are related to [[paracompactness]].

A [[locally normal space]] is a topological space where every point has an open neighbourhood that is normal. Every normal space is locally normal, but the converse is not true. A classical example of a completely regular locally normal space that is not normal is the [[Nemytskii plane]].

== Examples of normal spaces ==
Most spaces encountered in [[mathematical analysis]] are normal Hausdorff spaces, or at least normal regular spaces:
* All [[metric spaces]] (and hence all [[metrizable space]]s) are perfectly normal Hausdorff;
* All [[pseudometric space]]s (and hence all [[pseudometrisable space]]s) are perfectly normal regular, although not in general Hausdorff;
* All [[compact space|compact]] Hausdorff spaces are normal;
* In particular, the [[Stone–Čech compactification]] of a [[Tychonoff space]] is normal Hausdorff;
* Generalizing the above examples, all [[paracompact]] Hausdorff spaces are normal, and all paracompact regular spaces are normal;
* All paracompact [[topological manifold]]s are perfectly normal Hausdorff. However, there exist non-paracompact manifolds which are not even normal.
* All [[order topology|order topologies]] on [[totally ordered set]]s are hereditarily normal and Hausdorff.
* Every regular [[second-countable space]] is completely normal, and every regular [[Lindelöf space]] is normal.

Also, all [[fully normal space]]s are normal (even if not regular). [[Sierpinski space]] is an example of a normal space that is not regular.

== Examples of non-normal spaces ==
An important example of a non-normal topology is given by the [[Zariski topology]] on an [[algebraic variety]] or on the [[spectrum of a ring]], which is used in [[algebraic geometry]].

A non-normal space of some relevance to analysis is the [[topological vector space]] of all [[function (mathematics)|function]]s from the [[real line]] '''R''' to itself, with the [[topology of pointwise convergence]].
More generally, a theorem of [[A. H. Stone]] states that the [[product topology|product]] of [[uncountable|uncountably many]] non-[[compact space|compact]] metric spaces is never normal.

== Properties ==
Every closed subset of a normal space is normal. The continuous and closed image of a normal space is normal.&lt;ref name=GenTop&gt;{{cite book|last=Willard|first=Stephen|title=General topology.|year=1970|publisher=Addison-Wesley Pub. Co.|location=Reading, Mass.|isbn=0486434796|pages=100–101}}&lt;/ref&gt;

The main significance of normal spaces lies in the fact that they admit "enough" [[continuous function (topology)|continuous]] [[real number|real]]-valued [[function (mathematics)|function]]s, as expressed by the following theorems valid for any normal space ''X''.

[[Urysohn's lemma]]:
If ''A'' and ''B'' are two [[Disjoint sets|disjoint]] closed subsets of ''X'', then there exists a continuous function ''f'' from ''X'' to the real line '''R''' such that ''f''(''x'') = 0 for all ''x'' in ''A'' and ''f''(''x'') = 1 for all ''x'' in ''B''.
In fact, we can take the values of ''f'' to be entirely within the [[unit interval]] [0,1].
(In fancier terms, disjoint closed sets are not only separated by neighbourhoods, but also [[separated by a function]].)

More generally, the [[Tietze extension theorem]]:
If ''A'' is a closed subset of ''X'' and ''f'' is a continuous function from ''A'' to '''R''', then there exists a continuous function ''F'': ''X'' → '''R''' which extends ''f'' in the sense that ''F''(''x'') = ''f''(''x'') for all ''x'' in ''A''.

If '''U''' is a locally finite [[open cover]] of a normal space ''X'', then there is a [[partition of unity]] precisely subordinate to '''U'''.
(This shows the relationship of normal spaces to [[paracompactness]].)

In fact, any space that satisfies any one of these three conditions must be normal.

A [[product space|product]] of normal spaces is not necessarily normal.  This fact was first proved by [[Robert Sorgenfrey]]. An example of this phenomenon is the [[Sorgenfrey plane]]. Also, a subset of a normal space need not be normal (i.e. not every normal Hausdorff space is a completely normal Hausdorff space), since every Tychonoff space is a subset of its Stone–Čech compactification (which is normal Hausdorff).  A more explicit example is the [[Tychonoff plank]]. The only large class of product spaces of normal spaces known to be normal are the products of compact Hausdorff spaces, since both compactness ([[Tychonoff's theorem]]) and the {{math|''T''&lt;sub&gt;2&lt;/sub&gt;}} axiom are preserved under arbitrary products.&lt;ref&gt;{{harvnb|Willard|1970|loc=Section 17.}}&lt;/ref&gt;

== Relationships to other separation axioms ==
If a normal space is [[R0 space|R&lt;sub&gt;0&lt;/sub&gt;]], then it is in fact [[completely regular]].
Thus, anything from "normal R&lt;sub&gt;0&lt;/sub&gt;" to "normal completely regular" is the same as what we usually call ''normal regular''.
Taking [[Kolmogorov quotient]]s, we see that all normal [[T1 space|T&lt;sub&gt;1&lt;/sub&gt; space]]s are [[Tychonoff space|Tychonoff]].
These are what we usually call ''normal Hausdorff'' spaces.

A topological space is said to be [[pseudonormal space|pseudonormal]] if given two disjoint closed sets in it, one of which is countable, there are disjoint open sets containing them. Every normal space is pseudonormal, but not vice versa.

Counterexamples to some variations on these statements can be found in the lists above.
Specifically, [[Sierpinski space]] is normal but not regular, while the space of functions from '''R''' to itself is Tychonoff but not normal.

== Citations ==
{{reflist}}

== References ==
*{{cite encyclopedia | ref= harv | last = Kemoto | first = Nobuyuki | editor = K.P. Hart |editor2=J. Nagata |editor3=J.E. Vaughan | title = Higher Separation Axioms | encyclopedia = Encyclopedia of General Topology | publisher = [[Elsevier Science]] | location = Amsterdam | year = 2004 | isbn=0-444-50355-2}}
*{{cite book |ref= harv | last=Munkres |first=James R. |authorlink=James Munkres|title=Topology |year=2000 |edition=2nd |publisher=[[Prentice-Hall]] |isbn=0-13-181629-2}}
*{{cite journal |ref= harv | last= Sorgenfrey |first= R.H.|year= 1947 |title= On the topological product of paracompact spaces|journal= Bull. Amer. Math. Soc. |volume= 53 |pages= 631–632 | doi=10.1090/S0002-9904-1947-08858-3 |url=https://dx.doi.org/10.1090/S0002-9904-1947-08858-3}}
*{{cite journal |ref= harv | last= Stone |first= A. H. |year= 1948 |title=Paracompactness and product spaces |journal=Bull. Amer. Math. Soc. |volume=54 |pages= 977–982|doi=10.1090/S0002-9904-1948-09118-2 |url=https://dx.doi.org/10.1090/S0002-9904-1948-09118-2}}
*{{cite book |ref= harv |  last = Willard | first = Stephen | title = General Topology | publisher = Addison-Wesley | location = Reading, Massachusetts | year = 1970 | isbn = 0-486-43479-6 }}

[[Category:Topology]]
[[Category:Separation axioms]]
[[Category:Properties of topological spaces]]</text>
      <sha1>5yfm8987b16exthzcdpgchocsxk5xt3</sha1>
    </revision>
  </page>
  <page>
    <title>Oligomorphic group</title>
    <ns>0</ns>
    <id>25092831</id>
    <revision>
      <id>819319962</id>
      <parentid>634852326</parentid>
      <timestamp>2018-01-08T18:43:02Z</timestamp>
      <contributor>
        <username>Lyovushka</username>
        <id>8137218</id>
      </contributor>
      <minor/>
      <comment>/* External links */ Fixed a dead link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1607">In [[group theory]], a branch of [[mathematics]], an '''oligomorphic group''' is a particular kind of [[permutation group]]. If a group ''G'' [[group action|acts]] on a [[set (mathematics)|set]] ''S'' (usually infinite), then ''G'' is said to be oligomorphic if this action has only finitely many [[orbit (group theory)|orbits]] on every [[Cartesian product]] ''S&lt;sup&gt;n&lt;/sup&gt;'' of ''S'' (''n''-tuples of elements of ''S'' for every natural number ''n''). The interest in oligomorphic groups is partly based on their application to [[model theory]], e.g. [[automorphism]]s in [[countably categorical theory|countably categorical theories]].&lt;ref&gt;{{cite book | zbl=0916.20002 | last1=Bhattacharjee | first1=Meenaxi | last2=Macpherson |first2=Dugald | last3=Möller | first3=Rögnvaldur G. | last4=Neumann | first4=Peter M. | title=Notes on infinite permutation groups | series=Lecture Notes in Mathematics | volume=1698 | location=Berlin | publisher=[[Springer-Verlag]] | year=1998 | isbn=3-540-64965-4 | page=83 }}&lt;/ref&gt;

==References==
{{Reflist}}
* {{cite book | last=Cameron | first=Peter J. | authorlink=Peter Cameron (mathematician) | title=Oligomorphic permutation groups | series=London Mathematical Society Lecture Note Series | volume=152 | location=Cambridge | publisher=[[Cambridge University Press]] | year=1990 | isbn=0-521-38836-8 | zbl=0813.20002 }}

==External links==
* [http://www.newton.ac.uk/files/preprints/ni08029.pdf Oligomorphic permutation groups] - Isaac Newton Institute preprint, Peter J. Cameron

{{algebra-stub}}
[[Category:Permutation groups]]
[[Category:Infinite group theory]]</text>
      <sha1>qpicecuvnecvnb580405n5seah50kwb</sha1>
    </revision>
  </page>
  <page>
    <title>Pascal's triangle</title>
    <ns>0</ns>
    <id>49497</id>
    <revision>
      <id>871532771</id>
      <parentid>871522604</parentid>
      <timestamp>2018-12-01T19:09:14Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <comment>Reverted [[WP:AGF|good faith]] edits by [[Special:Contributions/Datolo12|Datolo12]] ([[User talk:Datolo12|talk]]): This is brought up in the history section and there is no need to single out one alternative name from the many that exist. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="49971">[[Image:PascalTriangleAnimated2.gif|thumb|In Pascal's triangle, each number is the sum of the two numbers directly above it.]] 

In [[mathematics]], '''Pascal's triangle''' is a [[triangular array]] of the [[binomial coefficient]]s. In much of the [[Western world]], it is named after the French mathematician [[Blaise Pascal]], although other mathematicians studied it centuries before him in [[India]],&lt;ref&gt;Maurice Winternitz, ''History of Indian Literature'', Vol. III&lt;/ref&gt; [[Iran|Persia]] (Iran)&lt;ref&gt;J. L. Coolidge, ''The Story of the Binomial Theorem'', [[American Mathematical Monthly|Amer. Math. Monthly]], Vol. 56, No. 3 (Mar., 1949), pp. 147–157&lt;/ref&gt;, [[China]], [[Germany]], and [[Italy]].&lt;ref name=roots&gt;{{cite book |author=Peter Fox |title=Cambridge University Library: the great collections |url=https://books.google.com/books?id=xxlgKP5thL8C&amp;pg=PA13 |year=1998 |publisher=Cambridge University Press |isbn=978-0-521-62647-7 |page=13}}&lt;/ref&gt;

The rows of Pascal's triangle are conventionally enumerated starting with row ''n''&amp;nbsp;=&amp;nbsp;0 at the top (the 0th row). The entries in each row are numbered from the left beginning with ''k''&amp;nbsp;=&amp;nbsp;0 and are usually staggered relative to the numbers in the adjacent rows. The triangle may be constructed in the following manner: In row 0 (the topmost row), there is a unique nonzero entry 1.  Each entry of each subsequent row is constructed by adding the number above and to the left with the number above and to the right, treating blank entries as 0. For example, the initial number in the first (or any other) row is 1 (the sum of 0 and 1), whereas the numbers 1 and 3 in the third row are added to produce the number 4 in the fourth row.

== Formula ==
[[File:Pascal triangle small.png|thumb|right|300px|A diagram that shows Pascal's triangle with rows 0 through 7.]]

The entry in the ''n''th row and ''k''th column of Pascal's triangle is denoted &lt;math&gt;\tbinom{n}{k}&lt;/math&gt;.  For example, the unique nonzero entry in the topmost row is &lt;math&gt;\tbinom{0}{0} = 1&lt;/math&gt;.  With this notation, the construction of the previous paragraph may be written as follows:

:&lt;math&gt; {n \choose k} = {n-1 \choose k-1} + {n-1 \choose k}&lt;/math&gt;,

for any non-negative integer ''n'' and any integer ''k'' between 0 and ''n'', inclusive.&lt;ref&gt;The binomial coefficient &lt;math&gt;\scriptstyle {n \choose k}&lt;/math&gt; is conventionally set to zero if ''k'' is either less than zero or greater than ''n''.&lt;/ref&gt;  This recurrence for the binomial coefficients is known as [[Pascal's rule]].

Pascal's triangle has higher [[dimension]]al generalizations. The three-dimensional version is called ''[[Pascal's pyramid]]'' or ''Pascal's tetrahedron'', while the general versions are called ''[[Pascal's simplex|Pascal's simplices]]''.

==History==
[[Image:Yanghui triangle.gif|thumb|right|[[Yang Hui]]'s triangle, as depicted by the Chinese using [[Counting rods|rod numerals]], appears in [[Jade Mirror of the Four Unknowns|a mathematical work]] by [[Zhu Shijie]], dated 1303. The title reads "The Old Method Chart of the Seven Multiplying Squares" (Chinese: 古法七乘方圖; the fourth character 椉 in the image title is archaic).]]
[[Image:TrianguloPascal.jpg|thumb|right|Blaise Pascal's version of the triangle]]

The pattern of numbers that forms Pascal's triangle was known well before Pascal's time. Pascal innovated many previously unattested uses of the triangle's numbers, uses he described comprehensively in what is perhaps the earliest known mathematical [[treatise]] to be specially devoted to the triangle, his ''Traité du triangle arithmétique'' (1653). Centuries before, discussion of the numbers had arisen in the context of [[Ancient India|Indian]] studies of [[combinatorics]] and of binomial numbers and [[Ancient Greece|Greeks]]' study of [[figurate numbers]].&lt;ref&gt;[http://www.bookrags.com/research/pascals-triangle-wom/ Pascal's triangle | World of Mathematics Summary]&lt;/ref&gt;

From later commentary, it appears that the binomial coefficients and the additive formula for generating them, &lt;math&gt;\tbinom{n}{r}=\tbinom{n-1}{r}+\tbinom{n-1}{r-1}&lt;/math&gt;, were known to [[Pingala]] in or before the 2nd century BC.&lt;ref name="edwards"&gt;A. W. F. Edwards. ''Pascal's arithmetical triangle: the story of a mathematical idea.'' JHU Press, 2002. Pages 30–31.&lt;/ref&gt;&lt;ref name="ed-cam"&gt;{{citation|contribution=The arithmetical triangle|first=A. W. F.|last=Edwards|pages=166–180|title=Combinatorics: Ancient and Modern|publisher=Oxford University Press|year=2013|editor1-first=Robin|editor1-last=Wilson|editor2-first=John J.|editor2-last=Watkins}}.&lt;/ref&gt; While Pingala's work only survives in fragments, the commentator [[Varāhamihira]], around 505, gave a clear description of the additive formula,&lt;ref name="ed-cam"/&gt; and a more detailed explanation of the same rule was given by [[Halayudha]], around 975. Halayudha also explained obscure references to ''Meru-prastaara'', the '''Staircase of [[Mount Meru]]''', giving the first surviving description of the arrangement of these numbers into a triangle.&lt;ref name="ed-cam"/&gt;&lt;ref name="ZawairaHitchcock2008p237"&gt;{{cite book|author1=Alexander Zawaira|author2=Gavin Hitchcock|title=A Primer for Mathematics Competitions|url=https://books.google.com/books?id=A21T73sqZ3AC&amp;pg=PA237|year=2008|publisher=Oxford University Press|isbn=978-0-19-156170-2|page=237}}&lt;/ref&gt; In approximately 850, the [[Jain]] mathematician [[Mahāvīra (mathematician)|Mahāvīra]] gave a different formula for the binomial coefficients, using multiplication, equivalent to the modern formula &lt;math&gt;\tbinom{n}{r}=\tfrac{n!}{r!(n-r)!}&lt;/math&gt;.&lt;ref name="ed-cam"/&gt; In 1068, four columns of the first sixteen rows were given by the mathematician [[Bhattotpala]], who was the first recorded mathematician to equate the additive and multiplicative formulas for these numbers.&lt;ref name="ed-cam"/&gt;

At around the same time, the [[Mathematics in medieval Islam|Persian]] mathematician [[Al-Karaji]] (953–1029) wrote a now lost book which contained the first description of Pascal's triangle.&lt;ref&gt;{{Citation|url=https://www.britannica.com/biography/al-Karaji|title=Al-Karajī {{!}} Persian mathematician and engineer|work=Encyclopedia Britannica|access-date=2018-07-19|language=en|quote=Al-Karajī, also known as al-Karkhī, in full, Abū Bakr ibn Muḥammad ibn al-Ḥusayn al-Karajī,  (born c. 980, most likely Karaj, Persia, rather than Karkh, near Baghdad, Iraq—died c. 1030), mathematician and engineer who held an official position in Baghdad (c. 1010–1015), perhaps culminating in the position of vizier, during which time he wrote his three main works, al-Fakhrī fīʾl-jabr wa’l-muqābala (“Glorious on algebra”), al-Badī‘ fī’l-hisāb (“Wonderful on calculation”), and al-Kāfī fī’l-hisāb (“Sufficient on calculation”). A now lost work of his contained the first description of what later became known as Pascal’s triangle}}&lt;/ref&gt;&lt;ref name=Karaji&gt;{{MacTutor|id=Al-Karaji|title=Abu Bekr ibn Muhammad ibn al-Husayn Al-Karaji}}&lt;/ref&gt; It was later repeated by the Persian poet-astronomer-mathematician [[Omar Khayyám]] (1048–1131); thus the triangle is also referred to as the '''Khayyam triangle''' in [[Iran]].&lt;ref&gt;{{cite book |author=Kennedy, E. |title=Omar Khayyam. The Mathematics Teacher 1958 |url=https://www.jstor.org/stable/i27957284|year=1966 |publisher=National Council of Teachers of Mathematics |page=140-142}}&lt;/ref&gt; Several theorems related to the triangle were known, including the [[binomial theorem]]. Khayyam used a method of finding [[nth root|''n''th roots]] based on the binomial expansion, and therefore on the binomial coefficients.&lt;ref&gt;{{citation
 | last = Coolidge | first = J. L. | author-link = Julian Coolidge
 | journal = [[The American Mathematical Monthly]]
 | jstor = 10.2307/2305028
 | mr = 0028222
 | pages = 147–157
 | title = The story of the binomial theorem
 | volume = 56
 | year = 1949}}.&lt;/ref&gt;

Pascal's triangle was known in China in the early 11th century through the work of the Chinese mathematician [[Jia Xian]] (1010–1070). In the 13th century, [[Yang Hui]] (1238–1298) presented the triangle and hence it is still called '''Yang Hui's triangle''' ({{lang-zh|s=杨辉三角|t=楊輝三角|labels=no}}) in [[China]].&lt;ref&gt;Weisstein, Eric W. (2003). ''CRC concise encyclopedia of mathematics'', p. 2169. {{isbn|978-1-58488-347-0}}.&lt;/ref&gt;

In the west, the binomial coefficients were calculated by [[Gersonides]] in the early 14th century, using the multiplicative formula for them.&lt;ref name="ed-cam"/&gt;
[[Petrus Apianus]] (1495–1552) published the full triangle on the [[Book frontispiece|frontispiece]] of his book on business calculations in 1527. This is the first record of the triangle in Europe.&lt;ref&gt;{{citation|title=Nature of Mathematics|first=Karl J.|last=Smith|publisher=Cengage Learning|year=2010|isbn=9780538737586|page=10|url=https://books.google.com/books?id=Di0HyCgDYq8C&amp;pg=PA10}}.&lt;/ref&gt; [[Michael Stifel]] published a portion of the triangle (from the second to the middle column in each row) in 1544, describing it as a table of [[figurate number]]s.&lt;ref name="ed-cam"/&gt; In [[Italy]], Pascal's triangle is referred to as '''Tartaglia's triangle''', named for the Italian [[algebra]]ist [[Niccolò Fontana Tartaglia]] (1500–1577), who published six rows of the triangle in 1556.&lt;ref name="ed-cam"/&gt; 
[[Gerolamo Cardano]], also, published the triangle as well as the additive and multiplicative rules for constructing it in 1570.&lt;ref name="ed-cam"/&gt;

Pascal's ''Traité du triangle arithmétique'' (''Treatise on Arithmetical Triangle'') was published posthumously in 1665. In this, Pascal collected several results then known about the triangle, and employed them to solve problems in [[probability theory]]. The triangle was later named after Pascal by [[Pierre Raymond de Montmort]] (1708) who called it "Table de M. Pascal pour les combinaisons" (French: Table of Mr. Pascal for combinations) and [[Abraham de Moivre]] (1730) who called it "Triangulum Arithmeticum PASCALIANUM" (Latin: Pascal's Arithmetic Triangle), which became the modern Western name.&lt;ref&gt;{{Cite journal | doi = 10.2307/2975209 | title = The Binomial Coefficient Function | first =  David | last = Fowler | authorlink = David Fowler (mathematician) | journal = [[The American Mathematical Monthly]] | volume = 103 | issue = 1 |date=January 1996 | pages = 1–17 | jstor = 2975209 }} See in particular p. 11.&lt;/ref&gt;

==Binomial expansions==
[[Image:binomial_theorem_visualisation.svg|thumb|300px|Visualisation of binomial expansion up to the 4th power]]

Pascal's triangle determines the coefficients which arise in [[binomial expansion]]s. For an example, consider the expansion

:(''x'' + ''y'')&lt;sup&gt;2&lt;/sup&gt; = ''x''&lt;sup&gt;2&lt;/sup&gt; + 2''xy'' + ''y''&lt;sup&gt;2&lt;/sup&gt; = '''1'''''x''&lt;sup&gt;2&lt;/sup&gt;''y''&lt;sup&gt;0&lt;/sup&gt; + '''2'''''x''&lt;sup&gt;1&lt;/sup&gt;''y''&lt;sup&gt;1&lt;/sup&gt; + '''1'''''x''&lt;sup&gt;0&lt;/sup&gt;''y''&lt;sup&gt;2&lt;/sup&gt;.

Notice the coefficients are the numbers in row two of Pascal's triangle: 1,&amp;nbsp;2,&amp;nbsp;1.
In general, when a [[binomial (polynomial)|binomial]] like ''x'' + ''y'' is raised to a positive integer power we have:

:(''x'' + ''y'')&lt;sup&gt;''n''&lt;/sup&gt; = ''a''&lt;sub&gt;0&lt;/sub&gt;''x''&lt;sup&gt;''n''&lt;/sup&gt; + ''a''&lt;sub&gt;1&lt;/sub&gt;''x''&lt;sup&gt;''n''−1&lt;/sup&gt;''y'' + ''a''&lt;sub&gt;2&lt;/sub&gt;''x''&lt;sup&gt;''n''−2&lt;/sup&gt;''y''&lt;sup&gt;2&lt;/sup&gt; + ... + ''a''&lt;sub&gt;''n''−1&lt;/sub&gt;''xy''&lt;sup&gt;''n''−1&lt;/sup&gt; + ''a''&lt;sub&gt;''n''&lt;/sub&gt;''y''&lt;sup&gt;''n''&lt;/sup&gt;,

where the coefficients ''a''&lt;sub&gt;''i''&lt;/sub&gt; in this expansion are precisely the numbers on row ''n'' of Pascal's triangle. In other words,

:&lt;math&gt;a_i = {n \choose i}.&lt;/math&gt;

This is the [[binomial theorem]].

Notice that the entire right diagonal of Pascal's triangle corresponds to the coefficient of ''y''&lt;sup&gt;''n''&lt;/sup&gt; in these binomial expansions, while the next diagonal corresponds to the coefficient of ''xy''&lt;sup&gt;''n''−1&lt;/sup&gt; and so on.

To see how the binomial theorem relates to the simple construction of Pascal's triangle, consider the problem of calculating the coefficients of the expansion of (''x''&amp;nbsp;+&amp;nbsp;1)&lt;sup&gt;''n''+1&lt;/sup&gt;  in terms of the corresponding coefficients of (''x''&amp;nbsp;+&amp;nbsp;1)&lt;sup&gt;''n''&lt;/sup&gt; (setting ''y'' = 1 for simplicity). Suppose then that

:&lt;math&gt;(x+1)^n=\sum_{i=0}^n a_i x^i.&lt;/math&gt;

Now

:&lt;math&gt; (x+1)^{n+1} = (x+1)(x+1)^n = x(x+1)^n + (x+1)^n = \sum_{i=0}^n a_i x^{i+1} + \sum_{i=0}^n a_i x^i.&lt;/math&gt;

[[Image:PascalsTriangleCoefficient.svg|thumb|right|Six rows Pascal's triangle as binomial coefficients]]

The two summations can be reorganized as follows:

:&lt;math&gt;
\begin{align}
&amp; \sum_{i=0}^{n  } a_{i  } x^{i+1} + \sum_{i=0}^n a_i x^i \\
&amp; {} = \sum_{i=1}^{n+1} a_{i-1} x^{i  } + \sum_{i=0}^n a_i x^i \\
&amp; {} = \sum_{i=1}^{n  } a_{i-1} x^{i  } + \sum_{i=1}^n a_i x^i + a_0x^0 + a_{n}x^{n+1} \\
&amp; {} = \sum_{i=1}^{n  } (a_{i-1} + a_i)x^{i  } + a_0x^0 + a_{n}x^{n+1} \\
&amp; {} = \sum_{i=1}^{n  } (a_{i-1} + a_i)x^{i  } + x^0 + x^{n+1}
\end{align}
&lt;/math&gt;

(because of how raising a polynomial to a power works, ''a''&lt;sub&gt;0&lt;/sub&gt; =&amp;nbsp;''a''&lt;sub&gt;''n''&lt;/sub&gt; =&amp;nbsp;1).

We now have an expression for the polynomial (''x''&amp;nbsp;+&amp;nbsp;1)&lt;sup&gt;''n''+1&lt;/sup&gt; in terms of the coefficients of (''x''&amp;nbsp;+&amp;nbsp;1)&lt;sup&gt;''n''&lt;/sup&gt; (these are the ''a''&lt;sub&gt;''i''&lt;/sub&gt;s), which is what we need if we want to express a line in terms of the line above it.  Recall that all the terms in a diagonal going from the upper-left to the lower-right correspond to the same power of ''x'', and that the a-terms are the coefficients of the polynomial (''x''&amp;nbsp;+&amp;nbsp;1)&lt;sup&gt;''n''&lt;/sup&gt;, and we are determining the coefficients of (''x''&amp;nbsp;+&amp;nbsp;1)&lt;sup&gt;''n''+1&lt;/sup&gt;.  Now, for any given ''i'' not 0 or ''n''&amp;nbsp;+&amp;nbsp;1, the coefficient of the ''x''&lt;sup&gt;''i''&lt;/sup&gt; term in the polynomial (''x''&amp;nbsp;+&amp;nbsp;1)&lt;sup&gt;''n''+1&lt;/sup&gt; is equal to ''a''&lt;sub&gt;''i''−1&lt;/sub&gt;(the figure above and to the left of the figure to be determined, since it is on the same diagonal)&amp;nbsp;+&amp;nbsp;''a''&lt;sub&gt;''i''&lt;/sub&gt;  (the figure to the immediate right of the first figure).  This is indeed the simple rule for constructing Pascal's triangle row-by-row.

It is not difficult to turn this argument into a [[proof (mathematics)|proof]] (by [[mathematical induction]]) of the binomial theorem. Since
(''a''&amp;nbsp;+&amp;nbsp;''b'')&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;''b''&lt;sup&gt;''n''&lt;/sup&gt;(''a''/''b''&amp;nbsp;+ &amp;nbsp;1)&lt;sup&gt;''n''&lt;/sup&gt;, the coefficients are identical in the expansion of the general case.

An interesting consequence of the binomial theorem is obtained by setting both variables ''x'' and ''y'' equal to one.  In this case, we know that (1&amp;nbsp;+&amp;nbsp;1)&lt;sup&gt;''n''&lt;/sup&gt; =&amp;nbsp;2&lt;sup&gt;''n''&lt;/sup&gt;, and so

:&lt;math&gt; {n \choose 0} + {n \choose 1} + \cdots +{n \choose n-1} + {n \choose n} = 2^n. &lt;/math&gt;

In other words, the sum of the entries in the ''n''th row of Pascal's triangle is the ''n''th power of&amp;nbsp;2.

==Combinations==

A second useful application of Pascal's triangle is in the calculation of [[combination]]s. For example, the number of combinations of ''n'' things taken ''k'' at a time (called ''[[n choose k]]'') can be found by the equation

:&lt;math&gt; \mathbf{C}(n,k) = \mathbf{C}_k^n= {_nC_k} = {n \choose k} = \frac{n!}{k!(n-k)!}.&lt;/math&gt;

But this is also the formula for a cell of Pascal's triangle. Rather than performing the calculation, one can simply look up the appropriate entry in the triangle. Provided we have the first row and the first entry in a row numbered 0, the answer will be located at entry ''k'' in row ''n''. For example, suppose a basketball team has 10 players and wants to know how many ways there are of selecting 8. The answer is entry 8 in row 10, which is 45; that is, 10 choose 8 is 45.

==Relation to binomial distribution and convolutions==
When divided by 2&lt;sup&gt;''n''&lt;/sup&gt;, the ''n''th row of Pascal's triangle becomes the [[binomial distribution]] in the symmetric case where ''p'' =&amp;nbsp;1/2. By the [[central limit theorem]], this distribution approaches the [[normal distribution]] as ''n'' increases. This can also be seen by applying [[Stirling's formula]] to the factorials involved in the formula for combinations.

This is related to the operation of discrete [[convolution]] in two ways. First, polynomial multiplication exactly corresponds to discrete convolution, so that repeatedly convolving the sequence {...,&amp;nbsp;0,&amp;nbsp;0,&amp;nbsp;1,&amp;nbsp;1,&amp;nbsp;0,&amp;nbsp;0,&amp;nbsp;...} with itself corresponds to taking powers of 1&amp;nbsp;+&amp;nbsp;''x'', and hence to generating the rows of the triangle. Second, repeatedly convolving the distribution function for a [[random variable]] with itself corresponds to calculating the distribution function for a sum of ''n'' independent copies of that variable; this is exactly the situation to which the central limit theorem applies, and hence leads to the normal distribution in the limit.

==Patterns and properties==

Pascal's triangle has many properties and contains many patterns of numbers.
[[File:Pascal's Triangle animated binary rows.gif|thumb|Each frame represents a row in Pascal's triangle. Each column of pixels is a number in binary with the least significant bit at the bottom. Light pixels represent ones and the dark pixels are zeroes.]]

=== Rows ===

*The sum of the elements of a single row is twice the sum of the row preceding it. For example, row&amp;nbsp;0 (the topmost row) has a value of 1, row&amp;nbsp;1 has a value of 2, row&amp;nbsp;2 has a value of 4, and so forth. This is because every item in a row produces two items in the next row: one left and one right. The sum of the elements of row&amp;nbsp;{{mvar|n}} is equal to {{math|2&lt;sup&gt;''n''&lt;/sup&gt;}}.
*Taking the product of the elements in each row, the sequence of products {{OEIS|id=A001142}} is related to the base of the natural logarithm, ''[[E (mathematical constant)|e]]''.&lt;ref&gt;{{citation
 | last = Brothers | first = H. J.
 | doi = 10.4169/math.mag.85.1.51
 | journal = [[Mathematics Magazine]]
 | mr =
 | pages = 51
 | title = Finding e in Pascal’s triangle
 | volume = 85
 | year = 2012}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Brothers | first = H. J.
 | doi =
 | journal = [[The Mathematical Gazette]]
 | mr = 
 | pages = 145–148
 | title = Pascal's triangle: The hidden stor-''e''
 | volume = 96
 | year = 2012}}.&lt;/ref&gt; Specifically, define the sequence ''s''&lt;sub&gt;''n''&lt;/sub&gt; as follows:
::&lt;math&gt;s_n=\prod_{k=0}^{n}\binom{n}{k} = \prod_{k=0}^{n}\frac{n!}{k!(n-k)!}~, ~ n \geq 0.&lt;/math&gt;
:Then, the ratio of successive row products is
::&lt;math&gt;\frac{s_{n+1}}{s_{n}}=\frac{(n+1)!^{(n+2)}\prod_{k=0}^{n+1}{k!^{-2}}}{n!^{(n+1)}\prod_{k=0}^{n}{k!^{-2}}}
=\frac{(n+1)^n}{n!}&lt;/math&gt;
:and the ratio of these ratios is
::&lt;math&gt;\frac{(s_{n+1})(s_{n-1})}{(s_n)^2}=\left(\frac{n+1}{n}\right)^n, ~ n\geq 1.&lt;/math&gt;
:The right-hand side of the above equation takes the form of the limit definition of ''e''
::&lt;math&gt;\textit{e} =\lim_{n\to\infty}\left(1+\frac{1}{n}\right)^{n}.&lt;/math&gt;
* Pi can be found in Pascal's triangle through the [[Nilakantha Somayaji|Nilakantha]] infinite series.&lt;ref&gt;
 {{citation
 | last = Foster | first = T.
 | doi = 10.5951/mathteacher.108.4.0246
 | journal = [[Mathematics Teacher]]
 | mr =
 | pages = 247
 | title = Nilakantha's Footprints in Pascal's Triangle
 | volume = 108
 | year = 2014}}&lt;/ref&gt;
::&lt;math&gt;\pi=3+\sum_{n=1}^\infty(-1)^{n+1}\frac{\binom{2n+1}{1}}{\binom{2n+1}{2}\binom{2n+2}{2}}&lt;/math&gt;
* ''The value of a row'', if each entry is considered a decimal place (and numbers larger than 9 carried over accordingly), is a power of 11 ( {{math|11&lt;sup&gt;''n''&lt;/sup&gt;}}, for row&amp;nbsp;{{mvar|n}}). Thus, in row&amp;nbsp;2, {{math|⟨1, 2, 1⟩}} becomes 11&lt;sup&gt;2&lt;/sup&gt;, while {{math|⟨1, 5, 10, 10, 5, 1⟩}} in row&amp;nbsp;five becomes (after carrying) 161,051, which is 11&lt;sup&gt;5&lt;/sup&gt;. This property is explained by setting {{math|1=''x'' = 10}} in the binomial expansion of {{math|(''x'' + 1)&lt;sup&gt;''n''&lt;/sup&gt;}}, and adjusting values to the decimal system. But {{mvar|x}} can be chosen to allow rows to represent values in [[radix|''any'' base]].
** In [[base 3]]: {{math|1=1 2 1&lt;sub&gt;3&lt;/sub&gt; = 4&lt;sup&gt;2&lt;/sup&gt; (16)}}
** {{math|1=⟨1, 3, 3, 1⟩ → 2 1 0 1&lt;sub&gt;3&lt;/sub&gt; = 4&lt;sup&gt;3&lt;/sup&gt; (64)}}
** In [[base 9]]: {{math|1=1 2 1&lt;sub&gt;9&lt;/sub&gt; = 10&lt;sup&gt;2&lt;/sup&gt; (100)}}
** &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; {{math|1=1 3 3 1&lt;sub&gt;9&lt;/sub&gt; = 10&lt;sup&gt;3&lt;/sup&gt; (1000)}}
** {{math|1=⟨1, 5, 10, 10, 5, 1⟩ → 1 6 2 1 5 1&lt;sub&gt;9&lt;/sub&gt; = 10&lt;sup&gt;5&lt;/sup&gt; (100000)}}
*: In particular (see previous property), for {{math|1=''x'' = 1}} place value remains ''constant'' (1&lt;sup&gt;''place''&lt;/sup&gt;=1). Thus entries can simply be added in interpreting the value of a row.
* Some of the numbers in Pascal's triangle correlate to numbers in [[Lozanić's triangle]].
* The sum of the squares of the elements of row&amp;nbsp;{{mvar|n}} equals the middle element of row&amp;nbsp;{{math|2''n''}}.  For example, 1&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;4&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;6&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;4&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;1&lt;sup&gt;2&lt;/sup&gt; =&amp;nbsp;70.  In general form:
::&lt;math&gt;\sum_{k=0}^n {n \choose k}^2 = {2n \choose n}.&lt;/math&gt;
* On any row&amp;nbsp;{{mvar|n}}, where {{mvar|n}} is even, the middle term minus the term two spots to the left equals a [[Catalan number]], specifically the {{math|(''n''/2 + 1)}}th Catalan number. For example: on row&amp;nbsp;4,  {{math|1=6 − 1 = 5}}, which is the 3rd Catalan number, and {{math|1=4/2 + 1 = 3}}.
* In a row&amp;nbsp;{{mvar|p}} where {{mvar|p}} is a [[prime number]], all the terms in that row except the 1s are [[multiple (mathematics)|multiples]] of&amp;nbsp;{{mvar|p}}. This can be proven easily, since if &lt;math&gt;p\in \mathbb{P}&lt;/math&gt;, then {{mvar|p}} has no factors save for 1 and itself. Every entry in the triangle is an integer, so therefore by definition &lt;math&gt;(p-k)!&lt;/math&gt; and &lt;math&gt;k!&lt;/math&gt; are factors of &lt;math&gt;p!\,&lt;/math&gt;. However, there is no possible way {{mvar|p}} itself can show up in the denominator, so therefore {{mvar|p}} (or some multiple of it) must be left in the numerator, making the entire entry a multiple of {{mvar|p}}.
&lt;!--
[[Image:Exp binomial grey.svg|thumb|300px|left|Binomial matrix as matrix exponential (illustration for 5×5 matrices). All the dots represent 0.]]  Comment: picture hidded since useless rescaling, also wrong paragraph for the pic --&gt;
*''Parity'': To count [[odd number|odd]] terms in row&amp;nbsp;{{mvar|n}}, convert {{mvar|n}} to [[binary numeral system|binary]]. Let {{mvar|x}} be the number of 1s in the binary representation. Then the number of odd terms will be {{math|2&lt;sup&gt;''x''&lt;/sup&gt;}}. These numbers are the values in [[Gould's sequence]].&lt;ref&gt;{{citation
 | last = Fine | first = N. J.
 | doi = 10.2307/2304500
 | journal = [[American Mathematical Monthly]]
 | mr = 0023257
 | pages = 589–592
 | title = Binomial coefficients modulo a prime
 | volume = 54
 | year = 1947}}. See in particular Theorem 2, which gives a generalization of this fact for all prime moduli.&lt;/ref&gt;
*Every entry in row 2&lt;sup&gt;''n''&lt;/sup&gt;-1, ''n'' ≥ 0, is odd.&lt;ref&gt;{{citation
 | last = Hinz | first = Andreas M.
 | doi = 10.2307/2324061
 | issue = 6
 | journal = The American Mathematical Monthly
 | mr = 1166003
 | pages = 538–544
 | title = Pascal's triangle and the Tower of Hanoi
 | volume = 99
 | year = 1992}}. Hinz attributes this observation to an 1891 book by [[Édouard Lucas]], ''Théorie des nombres'' (p.&amp;nbsp;420).&lt;/ref&gt;
*''Polarity'': When the elements of a row of Pascal's triangle are added and subtracted together sequentially, every row with a middle number, meaning rows that have an odd number of integers, gives 0 as the result.  As examples, row 4 is 1   4   6   4  1, so the formula would be 6 – (4+4) + (1+1) = 0; and row 6 is 1  6  15  20  15  6  1, so the formula would be 20 – (15+15) + (6+6) – (1+1) = 0.  So every even row of the Pascal triangle equals 0 when you take the middle number, then subtract the integers directly next to the center, then add the next integers, then subtract, so on and so forth until you reach the end of the row.

=== Diagonals ===
{{Pascal_triangle_simplex_numbers.svg|250px|[[simplex]] numbers}}
The diagonals of Pascal's triangle contain the [[figurate numbers]] of simplices:
* The diagonals going along the left and right edges contain only 1's.
* The diagonals next to the edge diagonals contain the [[natural number]]s in order.
* Moving inwards, the next pair of diagonals contain the [[triangular number]]s in order.
* The next pair of diagonals contain the [[tetrahedral number]]s in order, and the next pair give [[pentatope number]]s.

::&lt;math&gt;\begin{align}
P_0(n) &amp;= P_d(0) = 1, \\
P_d(n) &amp;= P_d(n-1) + P_{d-1}(n) \\
&amp;= \sum_{i=0}^n P_{d-1}(i) = \sum_{i=0}^d P_i(n-1).
\end{align}&lt;/math&gt;

The symmetry of the triangle implies that the ''n''&lt;sup&gt;th&lt;/sup&gt; d-dimensional number is equal to the ''d''&lt;sup&gt;th&lt;/sup&gt; ''n''-dimensional number.

An alternative formula that does not involve recursion is as follows:

::&lt;math&gt;P_d(n)=\frac{1}{d!}\prod_{k=0}^{d-1} (n+k) = {n^{(d)}\over d!} = \binom{n+d-1}{d}&lt;/math&gt;

:where ''n''&lt;sup&gt;(''d'')&lt;/sup&gt; is the [[Pochhammer symbol|rising factorial]].

The geometric meaning of a function P&lt;sub&gt;''d''&lt;/sub&gt; is:  P&lt;sub&gt;''d''&lt;/sub&gt;(1) = 1 for all ''d''.  Construct a ''d''-[[dimensional]] [[triangle]] (a 3-dimensional triangle is a [[tetrahedron]]) by placing additional dots below an initial dot, corresponding to P&lt;sub&gt;''d''&lt;/sub&gt;(1) = 1.  Place these dots in a manner analogous to the placement of numbers in Pascal's triangle.  To find P&lt;sub&gt;''d''&lt;/sub&gt;(''x''), have a total of ''x'' dots composing the target shape.  P&lt;sub&gt;''d''&lt;/sub&gt;(''x'') then equals the total number of dots in the shape.  A 0-dimensional triangle is a point and a 1-dimensional triangle is simply a line, and therefore P&lt;sub&gt;0&lt;/sub&gt;(''x'') = ''1'' and P&lt;sub&gt;1&lt;/sub&gt;(''x'') = ''x'', which is the sequence of natural numbers.  The number of dots in each layer corresponds to P&lt;sub&gt;''d''&amp;nbsp;−&amp;nbsp;1&lt;/sub&gt;(''x'').

=== Calculating a row or diagonal by itself===
There are simple algorithms to compute all the elements in a row or diagonal without computing other elements or factorials.

To compute row &lt;math&gt;n&lt;/math&gt; with the elements &lt;math&gt;\tbinom{n}{0}&lt;/math&gt;, &lt;math&gt;\tbinom{n}{1}&lt;/math&gt;, ..., &lt;math&gt;\tbinom{n}{n}&lt;/math&gt;, begin with &lt;math&gt;\tbinom{n}{0}=1&lt;/math&gt;. For each subsequent element, the value is determined by multiplying the previous value by a fraction with slowly changing numerator and denominator:

:&lt;math&gt; {n\choose k}= {n\choose k-1}\times \frac{n+1-k}{k}.&lt;/math&gt;

For example, to calculate row 5, the fractions are&amp;nbsp; &lt;math&gt;\tfrac{5}{1}&lt;/math&gt;,&amp;nbsp; &lt;math&gt;\tfrac{4}{2}&lt;/math&gt;,&amp;nbsp; &lt;math&gt;\tfrac{3}{3}&lt;/math&gt;,&amp;nbsp; &lt;math&gt;\tfrac{2}{4}&lt;/math&gt; and &lt;math&gt;\tfrac{1}{5}&lt;/math&gt;, and hence the elements are&amp;nbsp; &lt;math&gt;\tbinom{5}{0}=1&lt;/math&gt;, &amp;nbsp; &lt;math&gt;\tbinom{5}{1}=1\times\tfrac{5}{1}=5&lt;/math&gt;, &amp;nbsp; &lt;math&gt;\tbinom{5}{2}=5\times\tfrac{4}{2}=10&lt;/math&gt;, etc. (The remaining elements are most easily obtained by symmetry.)

To compute the diagonal containing the elements &lt;math&gt;\tbinom{n}{0}&lt;/math&gt;, &lt;math&gt;\tbinom{n+1}{1}&lt;/math&gt;, &lt;math&gt;\tbinom{n+2}{2}&lt;/math&gt;, ..., we again begin with &lt;math&gt;\tbinom{n}{0}=1&lt;/math&gt; and obtain subsequent elements by multiplication by certain fractions:

:&lt;math&gt; {n+k\choose k}= {n+k-1\choose k-1}\times \frac{n+k}{k}.&lt;/math&gt;

For example, to calculate the diagonal beginning at &lt;math&gt;\tbinom{5}{0}&lt;/math&gt;, the fractions are&amp;nbsp; &lt;math&gt;\tfrac{6}{1}&lt;/math&gt;,&amp;nbsp; &lt;math&gt;\tfrac{7}{2}&lt;/math&gt;,&amp;nbsp; &lt;math&gt;\tfrac{8}{3}&lt;/math&gt;, ..., and the elements are &lt;math&gt;\tbinom{5}{0}=1&lt;/math&gt;, &amp;nbsp; &lt;math&gt;\tbinom{6}{1}=1\times\tfrac{6}{1}=6&lt;/math&gt;, &amp;nbsp; &lt;math&gt;\tbinom{7}{2}=6\times\tfrac{7}{2}=21&lt;/math&gt;, etc. By symmetry, these elements are equal to &lt;math&gt;\tbinom{5}{5}&lt;/math&gt;, &lt;math&gt;\tbinom{6}{5}&lt;/math&gt;, &lt;math&gt;\tbinom{7}{5}&lt;/math&gt;, etc.

===Overall patterns and properties===
[[File:Sierpinski_Pascal_triangle.svg|thumb|A level-4 approximation to a Sierpinski triangle obtained by shading the first 32 rows of a Pascal triangle white if the binomial coefficient is even and black if it is odd.]]
* The pattern obtained by coloring only the odd numbers in Pascal's triangle closely resembles the [[fractal]] called the [[Sierpinski triangle]]. This resemblance becomes more and more accurate as more rows are considered; in the limit, as the number of rows approaches infinity, the resulting pattern ''is'' the Sierpinski triangle, assuming a fixed perimeter.&lt;ref&gt;{{cite journal |author=Wolfram, S. |title=Computation Theory of Cellular Automata |journal=Comm. Math. Phys. |volume=96 |pages=15–57 |year=1984 |doi=10.1007/BF01217347 |bibcode=1984CMaPh..96...15W }}&lt;/ref&gt; More generally, numbers could be colored differently according to whether or not they are multiples of 3, 4, etc.; this results in other similar patterns.

[[File:Pascal's triangle pathways.svg|thumb|Pascal's triangle overlaid on a grid gives the number of distinct paths to each square, assuming only rightward and downward movements are considered.]]

* In a triangular portion of a grid (as in the images below), the number of shortest grid paths from a given node to the top node of the triangle is the corresponding entry in Pascal's triangle.  On a [[Plinko]] game board shaped like a triangle, this distribution should give the probabilities of winning the various prizes.

[[Image:Pascal's Triangle 4 paths.svg|center|400px]]

* If the rows of Pascal's triangle are left-justified, the diagonal bands (colour-coded below) sum to the [[Fibonacci number]]s.
::{| style="align:center;"
|- align=center
|bgcolor=red|1
|- align=center
| style="background:orange;"|1
| style="background:yellow;"|1
|- align=center
| style="background:yellow;"|1
|bgcolor=lime|2
|bgcolor=aqua|1
|- align=center
|bgcolor=lime|1
|bgcolor=aqua|3
| style="background:violet;"|3
|bgcolor=red|1
|- align=center
|bgcolor=aqua|1
| style="background:violet;"|4
|bgcolor=red|6
| style="background:orange;"|4
| style="background:yellow;"|1
|- align=center
| style="background:violet;"|1
|bgcolor=red|5
| style="background:orange;"|10
| style="background:yellow;"|10
|bgcolor=lime|5
|bgcolor=aqua|1
|- align=center
|bgcolor=red|1
| style="background:orange;"|6
| style="background:yellow;"|15
|bgcolor=lime|20
|bgcolor=aqua|15
| style="background:violet;"|6
|bgcolor=red|1
|- align=center
| style="background:orange; width:40px;"|1
| style="background:yellow; width:40px;"|7
| style="background:lime; width:40px;"|21
| style="background:aqua; width:40px;"|35
| style="background:violet; width:40px;"|35
| style="background:red; width:40px;"|21
| style="background:orange; width:40px;"|7
| style="background:yellow; width:40px;"|1
|}

=== Construction as matrix exponential ===
[[Image:Exp binomial 256 wiki.png|thumb|right|Binomial matrix as matrix exponential. All the dots represent 0.]]
{{See also|Pascal matrix}}
Due to its simple construction by factorials, a very basic representation of Pascal's triangle in terms of the [[matrix exponential]] can be given: Pascal's triangle is the exponential of the matrix which has the sequence 1, 2, 3, 4, … on its subdiagonal and zero everywhere else.
{{Clear}}

=== Connections to geometry of polytopes ===
{{unreferenced section|date=October 2016}}
Pascal's triangle can be used as a [[lookup table]] for the number of elements (such as edges and corners) within a [[polytope]] (such as a triangle, a tetrahedron, a square and a cube).

==== Number of elements of simplices ====

Let's begin by considering the 3rd line of Pascal's triangle, with values 1, 3, 3, 1.  A 2-dimensional triangle has one 2-dimensional element (itself), three 1-dimensional elements (lines, or edges), and three 0-dimensional elements ([[Vertex (graph theory)|vertices]], or corners).  The meaning of the final number (1) is more difficult to explain (but see below).  Continuing with our example, a [[tetrahedron]] has one 3-dimensional element (itself), four 2-dimensional elements (faces), six 1-dimensional elements (edges), and four 0-dimensional elements (vertices).  Adding the final 1 again, these values correspond to the 4th row of the triangle (1, 4, 6, 4, 1).  Line 1 corresponds to a point, and Line 2 corresponds to a line segment (dyad).  This pattern continues to arbitrarily high-dimensioned hyper-tetrahedrons (known as [[simplex|simplices]]).

To understand why this pattern exists, one must first understand that the process of building an ''n''-simplex from an (''n''&amp;nbsp;−&amp;nbsp;1)-simplex consists of simply adding a new vertex to the latter, positioned such that this new vertex lies outside of the space of the original simplex, and connecting it to all original vertices. As an example, consider the case of building a tetrahedron from a triangle, the latter of whose elements are enumerated by row 3 of Pascal's triangle: '''1''' face, '''3''' edges, and '''3''' vertices (the meaning of the final 1 will be explained shortly). To build a tetrahedron from a triangle, we position a new vertex above the plane of the triangle and connect this vertex to all three vertices of the original triangle.

The number of a given dimensional element in the tetrahedron is now the sum of two numbers: first the number of that element found in the original triangle, plus the number of new elements, ''each of which is built upon elements of one fewer dimension from the original triangle''. Thus, in the tetrahedron, the number of [[cell (mathematics)|cells]] (polyhedral elements) is 0 (the original triangle possesses none) + 1 (built upon the single face of the original triangle) = '''1'''; the number of faces is 1 (the original triangle itself) + 3 (the new faces, each built upon an edge of the original triangle) = '''4'''; the number of edges is 3 (from the original triangle) + 3 (the new edges, each built upon a vertex of the original triangle) = '''6'''; the number of new vertices is 3 (from the original triangle) + 1 (the new vertex that was added to create the tetrahedron from the triangle) = '''4'''. This process of summing the number of elements of a given dimension to those of one fewer dimension to arrive at the number of the former found in the next higher simplex is equivalent to the process of summing two adjacent numbers in a row of Pascal's triangle to yield the number below. Thus, the meaning of the final number (1) in a row of Pascal's triangle becomes understood as representing the new vertex that is to be added to the simplex represented by that row to yield the next higher simplex represented by the next row. This new vertex is joined to every element in the original simplex to yield a new element of one higher dimension in the new simplex, and this is the origin of the pattern found to be identical to that seen in Pascal's triangle. The "extra" 1 in a row can be thought of as the -1 simplex, the unique center of the simplex, which ever gives rise to a new vertex and a new dimension, yielding a new simplex with a new center.

==== Number of elements of hypercubes ====

A similar pattern is observed relating to [[square (geometry)|squares]], as opposed to triangles.  To find the pattern, one must construct an analog to Pascal's triangle, whose entries are the coefficients of (''x''&amp;nbsp;+&amp;nbsp;2)&lt;sup&gt;Row Number&lt;/sup&gt;, instead of (''x''&amp;nbsp;+&amp;nbsp;1)&lt;sup&gt;Row Number&lt;/sup&gt;.  There are a couple ways to do this.  The simpler is to begin with Row 0 = 1 and Row 1 = 1, 2.  Proceed to construct the analog triangles according to the following rule:

:&lt;math&gt; {n \choose k} = 2\times{n-1 \choose k-1} + {n-1 \choose k}.&lt;/math&gt;

That is, choose a pair of numbers according to the rules of Pascal's triangle, but double the one on the left before adding.  This results in:

                              1
                          1       2
                      1       4       4
                  1       6       12      8
              1       8       24      32      16
          1       10      40      80      80       32
      1       12      60      160     240     192       64
  1       14      84      280     560     672      448       128

The other way of manufacturing this triangle is to start with Pascal's triangle and multiply each entry by 2&lt;sup&gt;k&lt;/sup&gt;, where k is the position in the row of the given number.  For example, the 2nd value in row 4 of Pascal's triangle is 6 (the slope of 1s corresponds to the zeroth entry in each row).  To get the value that resides in the corresponding position in the analog triangle, multiply 6 by 2&lt;sup&gt;Position Number&lt;/sup&gt; = 6&amp;nbsp;×&amp;nbsp;2&lt;sup&gt;2&lt;/sup&gt; = 6&amp;nbsp;×&amp;nbsp;4 = 24.  Now that the analog triangle has been constructed, the number of elements of any dimension that compose an arbitrarily dimensioned [[cube (geometry)|cube]] (called a [[hypercube]]) can be read from the table in a way analogous to Pascal's triangle.  For example, the number of 2-dimensional elements in a 2-dimensional cube (a square) is one, the number of 1-dimensional elements (sides, or lines) is 4, and the number of 0-dimensional elements (points, or vertices) is 4.  This matches the 2nd row of the table (1, 4, 4).  A cube has 1 cube, 6 faces, 12 edges, and 8 vertices, which corresponds to the next line of the analog triangle (1, 6, 12, 8).  This pattern continues indefinitely.

To understand why this pattern exists, first recognize that the construction of an ''n''-cube from an (''n''&amp;nbsp;−&amp;nbsp;1)-cube is done by simply duplicating the original figure and displacing it some distance (for a regular ''n''-cube, the edge length) [[orthogonal]] to the space of the original figure, then connecting each vertex of the new figure to its corresponding vertex of the original. This initial duplication process is the reason why, to enumerate the dimensional elements of an ''n''-cube, one must double the first of a pair of numbers in a row of this analog of Pascal's triangle before summing to yield the number below. The initial doubling thus yields the number of "original" elements to be found in the next higher ''n''-cube and, as before, new elements are built upon those of one fewer dimension (edges upon vertices, faces upon edges, etc.). Again, the last number of a row represents the number of new vertices to be added to generate the next higher ''n''-cube.

In this triangle, the sum of the elements of row ''m'' is equal to 3&lt;sup&gt;''m''&lt;/sup&gt;.  Again, to use the elements of row 4 as an example: &lt;math&gt;1 + 8 + 24 + 32 + 16 = 81&lt;/math&gt;, which is equal to &lt;math&gt;3^4 = 81&lt;/math&gt;.

==== Counting vertices in a cube by distance ====
Each row of Pascal's triangle gives the number of vertices at each distance from a fixed vertex in an ''n''-dimensional cube.  For example, in three dimensions, the third row (1 3 3 1) corresponds to the usual three-dimensional [[cube]]: fixing a vertex ''V'', there is one vertex at distance 0 from ''V'' (that is, ''V'' itself), three vertices at distance 1, three vertices at distance {{sqrt|2}} and one vertex at distance {{sqrt|3}} (the vertex opposite ''V'').  The second row corresponds to a square, while larger-numbered rows correspond to [[hypercube]]s in each dimension.

=== Fourier transform of sin(''x'')&lt;sup&gt;''n''+1&lt;/sup&gt;/''x'' ===

As stated previously, the coefficients of (''x''&amp;nbsp;+&amp;nbsp;1)&lt;sup&gt;''n''&lt;/sup&gt; are the nth row of the triangle.   Now the coefficients of (''x''&amp;nbsp;−&amp;nbsp;1)&lt;sup&gt;''n''&lt;/sup&gt; are the same, except that the sign alternates from +1 to −1 and back again.  After suitable normalization, the same pattern of numbers occurs in the  [[Fourier transform]] of sin(''x'')&lt;sup&gt;''n''+1&lt;/sup&gt;/''x''. More precisely: if ''n'' is even, take the [[real part]] of the transform, and if ''n'' is odd, take the [[imaginary part]]. Then the result is a [[step function]], whose values (suitably normalized) are given by the ''n''th row of the triangle with alternating signs.&lt;ref&gt;For a similar example, see e.g. {{citation|title=Solvent suppression in Fourier transform nuclear magnetic resonance|first=P. J.|last=Hore|journal=Journal of Magnetic Resonance|year=1983|volume=55|issue=2|pages=283–300|doi=10.1016/0022-2364(83)90240-8|bibcode=1983JMagR..55..283H}}.&lt;/ref&gt; For example, the values of the step function that results from:

:&lt;math&gt;\,\mathfrak{Re}\left(\text{Fourier} \left[  \frac{\sin(x)^5}{x}   \right]\right)&lt;/math&gt;

compose the 4th row of the triangle, with alternating signs.  This is a generalization of the following basic result (often used in [[electrical engineering]]):

:&lt;math&gt;\,\mathfrak{Re}\left(\text{Fourier} \left[ \frac{\sin(x)^1}{x}\right] \right)&lt;/math&gt;

is the [[boxcar function]].&lt;ref&gt;{{citation|title=An Introduction to Digital Signal Processing|first=John H.|last=Karl|publisher=Elsevier|year=2012|isbn=9780323139595|page=110|url=https://books.google.com/books?id=9Dv1PClLZWIC&amp;pg=PA110}}.&lt;/ref&gt;  The corresponding row of the triangle is row 0, which consists of just the number&amp;nbsp;1.

If n is [[congruence relation|congruent]] to 2 or to 3 mod 4, then the signs start with&amp;nbsp;−1. In fact, the sequence of the (normalized) first terms corresponds to the powers of [[imaginary unit|i]], which cycle around the intersection of the axes with the unit circle in the complex plane:

:::&lt;math&gt; \, +i,-1,-i,+1,+i,\ldots \, &lt;/math&gt;

=== Elementary cellular automaton ===
The pattern produced by an [[elementary cellular automaton]] using rule 60 is exactly Pascal's triangle of binomial coefficients reduced modulo 2 (black cells correspond to odd binomial coefficients).&lt;ref&gt;{{cite book |author=Wolfram, S. |title=A New Kind of Science |publisher=Wolfram Media |location=Champaign IL |year=2002 |pages=870, 931–2 }}&lt;/ref&gt; Rule 102 also produces this pattern when trailing zeros are omitted. [[Rule 90]] produces the same pattern but with an empty cell separating each entry in the rows.

== Extensions ==

Pascal's triangle can be extended to negative row numbers.

First write the triangle in the following form:

{|
|-
|  || ''m'' = 0 || ''m'' = 1 || ''m'' = 2 || ''m'' = 3 || ''m'' = 4 || ''m'' = 5 || ...
|-
| ''n'' = 0 || 1 || 0 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = 1 || 1 || 1 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = 2 || 1 || 2 || 1 || 0 || 0 || 0 || ...
|-
| ''n'' = 3 || 1 || 3 || 3 || 1 || 0 || 0 || ...
|-
| ''n'' = 4 || 1 || 4 || 6 || 4 || 1 || 0 || ...
|}

Next, extend the column of 1s upwards:

{|
|-
|  || ''m'' = 0 || ''m'' = 1 || ''m'' = 2 || ''m'' = 3 || ''m'' = 4 || ''m'' = 5 || ...
|-
| ''n'' = −4 || 1 ||  ||  ||  ||  ||  || ...
|-
| ''n'' = −3 || 1 ||  ||  ||  ||  ||  || ...
|-
| ''n'' = −2 || 1 ||  ||  ||  ||  ||  || ...
|-
| ''n'' = −1 || 1 ||  ||  ||  ||  ||  || ...
|-
| ''n'' = 0 || 1 || 0 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = 1 || 1 || 1 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = 2 || 1 || 2 || 1 || 0 || 0 || 0 || ...
|-
| ''n'' = 3 || 1 || 3 || 3 || 1 || 0 || 0 || ...
|-
| ''n'' = 4 || 1 || 4 || 6 || 4 || 1 || 0 || ...
|}

Now the rule:

:&lt;math&gt; {n \choose m} = {n-1 \choose m-1} + {n-1 \choose m}&lt;/math&gt;

can be rearranged to:

:&lt;math&gt; {n-1 \choose m} = {n \choose m} - {n-1 \choose m-1}&lt;/math&gt;

which allows calculation of the other entries for negative rows:

{|
|-
|  || ''m'' = 0 || ''m'' = 1 || ''m'' = 2 || ''m'' = 3 || ''m'' = 4 || ''m'' = 5 || ...
|-
| ''n'' = −4 || 1 || −4 || 10 || −20 || 35 || −56 || ...
|-
| ''n'' = −3 || 1 || −3 || 6 || −10 || 15 || −21 || ...
|-
| ''n'' = −2 || 1 || −2 || 3 || −4 || 5 || −6 || ...
|-
| ''n'' = −1 || 1 || −1 || 1 || −1 || 1 || −1 || ...
|-
| ''n'' = 0 || 1 || 0 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = 1 || 1 || 1 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = 2 || 1 || 2 || 1 || 0 || 0 || 0 || ...
|-
| ''n'' = 3 || 1 || 3 || 3 || 1 || 0 || 0 || ...
|-
| ''n'' = 4 || 1 || 4 || 6 || 4 || 1 || 0 || ...
|}
This extension preserves the property that the values in the ''m''th column viewed as a function of ''n'' are fit by an order ''m'' polynomial, namely
:&lt;math&gt;
{n \choose m} = \frac{1}{m!}\prod_{k=0}^{m-1} (n-k) = \frac{1}{m!}\prod_{k=1}^{m} (n-k+1)
&lt;/math&gt;.

This extension also preserves the property that the values in the ''n''th row correspond to the coefficients of (1&amp;nbsp;+&amp;nbsp;''x'')&lt;sup&gt;''n''&lt;/sup&gt;:
:&lt;math&gt;
(1+x)^n = \sum_{k=0}^\infty {n \choose k} x^k \quad |x| &lt; 1
&lt;/math&gt;
For example:
:&lt;math&gt;
(1+x)^{-2} = 1-2x+3x^2-4x^3+\cdots \quad |x| &lt; 1
&lt;/math&gt;

When viewed as a series, the rows of negative ''n'' diverge.  However, they are still [[Divergent series#Abelian means|Abel summable]], which summation gives the standard values of 2&lt;sup&gt;''n''&lt;/sup&gt;.  (In fact, the ''n''&amp;nbsp;=&amp;nbsp;-1 row results in [[Grandi's series]] which "sums" to 1/2, and the ''n''&amp;nbsp;=&amp;nbsp;-2 row results in [[1 − 2 + 3 − 4 + · · ·|another well-known series]] which has an Abel sum of 1/4.)

Another option for extending Pascal's triangle to negative rows comes from extending the ''other'' line of 1s:
{|
|  || ''m'' = −4 || ''m'' = −3 || ''m'' = −2 || ''m'' = −1 || ''m'' = 0 || ''m'' = 1 || ''m'' = 2 || ''m'' = 3 || ''m'' = 4 || ''m'' = 5 || ...
|-
| ''n'' = −4 || 1 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = −3 ||   || 1 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = −2 ||   ||   || 1 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = −1 ||   ||   ||   || 1 || 0 || 0 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = 0  || 0 || 0 || 0 || 0 || 1 || 0 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = 1  || 0 || 0 || 0 || 0 || 1 || 1 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = 2  || 0 || 0 || 0 || 0 || 1 || 2 || 1 || 0 || 0 || 0 || ...
|-
| ''n'' = 3  || 0 || 0 || 0 || 0 || 1 || 3 || 3 || 1 || 0 || 0 || ...
|-
| ''n'' = 4  || 0 || 0 || 0 || 0 || 1 || 4 || 6 || 4 || 1 || 0 || ...
|}
Applying the same rule as before leads to
{|
|  || ''m'' = −4 || ''m'' = −3 || ''m'' = −2 || ''m'' = −1 || ''m'' = 0 || ''m'' = 1 || ''m'' = 2 || ''m'' = 3 || ''m'' = 4 || ''m'' = 5 || ...
|-
| ''n'' = −4 || 1 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = −3 || −3 || 1 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = −2 || 3 || −2 || 1 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = −1 || −1 || 1 || −1 || 1 || 0 || 0 || 0 || 0 || 0 || 0 || ..
|-
| ''n'' = 0  || 0 || 0 || 0 || 0 || 1 || 0 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = 1  || 0 || 0 || 0 || 0 || 1 || 1 || 0 || 0 || 0 || 0 || ...
|-
| ''n'' = 2  || 0 || 0 || 0 || 0 || 1 || 2 || 1 || 0 || 0 || 0 || ...
|-
| ''n'' = 3  || 0 || 0 || 0 || 0 || 1 || 3 || 3 || 1 || 0 || 0 || ...
|-
| ''n'' = 4  || 0 || 0 || 0 || 0 || 1 || 4 || 6 || 4 || 1 || 0 || ...
|}

Note that this extension also has the properties that just as
:&lt;math&gt;
\exp\begin{pmatrix}
. &amp; . &amp; . &amp; . &amp; . \\
1 &amp; . &amp; . &amp; . &amp; . \\
. &amp; 2 &amp; . &amp; . &amp; . \\
. &amp; . &amp; 3 &amp; . &amp; . \\
. &amp; . &amp; . &amp; 4 &amp; .
\end{pmatrix} =
\begin{pmatrix}
1 &amp; . &amp; . &amp; . &amp; . \\
1 &amp; 1 &amp; . &amp; . &amp; . \\
1 &amp; 2 &amp; 1 &amp; . &amp; . \\
1 &amp; 3 &amp; 3 &amp; 1 &amp; . \\
1 &amp; 4 &amp; 6 &amp; 4 &amp; 1
\end{pmatrix}, &lt;/math&gt;

we have

:&lt;math&gt;
\exp\begin{pmatrix}
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
-4 &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; -3 &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; -2 &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; -1 &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; 0 &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; 1 &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; 2 &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; 3 &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; 4 &amp; .
\end{pmatrix} =
\begin{pmatrix}
1 &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
-4 &amp; 1 &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
6 &amp; -3 &amp; 1 &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
-4 &amp; 3 &amp; -2 &amp; 1 &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
1 &amp; -1 &amp; 1 &amp; -1 &amp; 1 &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; 1 &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; 1 &amp; 1 &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; 1 &amp; 2 &amp; 1 &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; 1 &amp; 3 &amp; 3 &amp; 1 &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; 1 &amp; 4 &amp; 6 &amp; 4 &amp; 1
\end{pmatrix} &lt;/math&gt;

Also, just as summing along the lower-left to upper-right diagonals of the Pascal matrix yields the [[Fibonacci numbers]], this second type of extension still sums to the Fibonacci numbers for negative index.

Either of these extensions can be reached if we define

: &lt;math&gt; {n \choose k} = \frac{n!}{(n-k)! k!} \equiv \frac{\Gamma(n+1)}{\Gamma(n-k+1)\Gamma(k+1)}&lt;/math&gt;

and take certain limits of the [[gamma function]], &lt;math&gt;\Gamma(z)&lt;/math&gt;.

==See also==
* [[Bean machine]], Francis Galton's "quincunx"
* [[Bell triangle]]
* [[Bernoulli's triangle]]
* [[Binomial expansion]]
* [[Euler triangle]]
* [[Floyd's triangle]]
* [[Gaussian binomial coefficient]]
* [[Leibniz harmonic triangle]]
* [[Multiplicities of entries in Pascal's triangle]] (Singmaster's conjecture)
* [[Pascal matrix]]
* [[Pascal's pyramid]]
* [[Pascal's simplex]]
* [[Proton NMR]], one application of Pascal's triangle
* [[(2,1)-Pascal triangle]]
* [[Star of David theorem]]
* [[Trinomial expansion]]
* [[Trinomial triangle]]

==References==
{{Reflist}}

== External links ==
{{Commons category}}
* {{springer|title=Pascal triangle|id=p/p071790}}
* {{MathWorld | urlname=PascalsTriangle | title=Pascal's triangle }}
* [http://www.york.ac.uk/depts/maths/histstat/images/triangle.gif The Old Method Chart of the Seven Multiplying Squares] ''(from the Ssu Yuan Yü Chien of Chu Shi-Chieh, 1303, depicting the first nine rows of Pascal's triangle)''
* [http://www.lib.cam.ac.uk/RareBooks/PascalTraite Pascal's Treatise on the Arithmetic Triangle] ''(page images of Pascal's treatise, 1655; [https://web.archive.org/web/20040803233048/http://www.lib.cam.ac.uk/RareBooks/PascalTraite/pascalintro.pdf summary])''
* [http://jeff560.tripod.com/p.html Earliest Known Uses of Some of the Words of Mathematics (P)]
* [http://www.cut-the-knot.org/Curriculum/Combinatorics/LeibnitzTriangle.shtml Leibniz and Pascal triangles]
* [http://www.cut-the-knot.org/Curriculum/Algebra/DotPatterns.shtml Dot Patterns, Pascal's triangle, and Lucas' Theorem]

{{Blaise Pascal}}

{{DEFAULTSORT:Pascal's triangle}}
[[Category:Factorial and binomial topics]]
[[Category:Blaise Pascal]]
[[Category:Triangles of numbers]]</text>
      <sha1>d9n9fp8fnbil6sxgxk6a69i7b1003rx</sha1>
    </revision>
  </page>
  <page>
    <title>Plug-in principle</title>
    <ns>0</ns>
    <id>50316748</id>
    <revision>
      <id>855014740</id>
      <parentid>855013140</parentid>
      <timestamp>2018-08-15T10:08:29Z</timestamp>
      <contributor>
        <username>AlainD</username>
        <id>1011434</id>
      </contributor>
      <comment>Proposed merging</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2678">{{Merge to | Resampling_(statistics) | discuss=Talk:Resampling_(statistics)#Merger discussion | date=August 2018 }}

In statistics, the '''plug-in principle''' &lt;ref name="Logan"&gt;Logan, J. David and Wolesensky, Willian R. Mathematical methods in biology. Pure and Applied Mathematics: a Wiley-interscience Series of Texts, Monographs, and Tracts. John Wiley&amp; Sons, Inc. 2009. Chapter 6: Statistical inference. Section 6.6: Bootstrap methods &lt;/ref&gt; is the method of [[Estimation statistics|estimation]] of functionals of a population distribution by evaluating the same functionals at the [[Empirical distribution function|empirical distribution]] based on a sample.

[[File:Bootstrapping.jpg|thumb|The best example of the plug-in principle, the bootstrapping method.]]

For example,&lt;ref name="Logan"&gt;Logan, J. David and Wolesensky, Willian R. Mathematical methods in biology. Pure and Applied Mathematics: a Wiley-interscience Series of Texts, Monographs, and Tracts. John Wiley&amp; Sons, Inc. 2009. Chapter 6: Statistical inference. Section 6.6: Bootstrap methods &lt;/ref&gt; when estimating the [[Population statistics|population]] [[mean]], this method uses the [[Sample (statistics)|sample]] mean; to estimate the population [[Median (statistics)|median]], it uses the sample median; to estimate the population [[regression line]], it uses the sample regression line.

It is called a [[principle]] because it is too simple to be otherwise, it is just a guideline, not a [[theorem]].

==References==
{{Reflist}}

==See also==
*[[Bootstrapping (statistics)]]
*[[Resampling (statistics)]]

==Further references==
* Wright, D.B., London, K., Field, A.P. Using Bootstrap Estimation and the Plug-in Principle for Clinical Psychology Data. 2011 Textrum Ltd. Online: https://www.researchgate.net/publication/236647074_Using_Bootstrap_Estimation_and_the_Plug-in_Principle_for_Clinical_Psychology_Data. Retrieved on 25/04/2016.
* An Introduction to the Bootstrap. Monographs on Statistics and applied probability 57. Chapman&amp;Hall/CHC. 1998. Online https://books.google.it/books?id=gLlpIUxRntoC&amp;pg=PA35&amp;lpg=PA35&amp;dq=plug+in+principle&amp;source=bl&amp;ots=A8AsW5K6E2&amp;sig=7WQVzL3ujAnWC8HDNyOzKlKVX0k&amp;hl=en&amp;sa=X&amp;sqi=2&amp;ved=0ahUKEwiU5c-Ho6XMAhUaOsAKHS_PDJMQ6AEIPDAG#v=onepage&amp;q=plug%20in%20principle&amp;f=false. Retrieved on 25 04 2016.

==External links==
* [http://www.stat.ucla.edu/~cocteau/stat105/lectures/lecture11.pdf Lecture notes]. Retrieved on 25 April 2016.
* [http://statweb.stanford.edu/~nzhang/Stat366/lecture13b.pdf Lecture notes 2]. Retrieved on 25 April 2016.

{{Statistics|inference|collapsed}}

[[Category:Computational statistics]]
[[Category:Resampling (statistics)]]


{{statistics-stub}}</text>
      <sha1>hy8ecfx1applru7bjpwx7qwoljkgag7</sha1>
    </revision>
  </page>
  <page>
    <title>Poncelet Prize</title>
    <ns>0</ns>
    <id>20842828</id>
    <revision>
      <id>855828991</id>
      <parentid>832823122</parentid>
      <timestamp>2018-08-21T03:44:55Z</timestamp>
      <contributor>
        <username>TAnthony</username>
        <id>1808194</id>
      </contributor>
      <comment>Fix [[:Category:CS1 maint: Extra text|CS1 cite error]] (extra text in "page" or "edition" parameter), and genfixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7463">{{More citations needed|date=April 2011}}
The '''Poncelet Prize''' ({{lang-fr|Prix Poncelet}}) is awarded by the [[French Academy of Sciences]]. The prize was established in 1868 by the widow of General [[Jean-Victor Poncelet]] for the advancement of the sciences.&lt;ref&gt;Jeremy Gray, "[http://www.claymath.org/library/monographs/MPP.pdf A History of Prizes in Mathematics] {{webarchive|url=https://web.archive.org/web/20131020203334/http://www.claymath.org/library/monographs/MPP.pdf |date=2013-10-20 }}", [[Clay Mathematics Institute]] and [[American Mathematical Society]], 2006.&lt;/ref&gt; It was in the amount of 2,000 [[French franc|francs]] (as of 1868), mostly for the work in [[applied mathematics]]. The precise wording of the announcement by the Academy varied from year to year and required the work be "in [[mechanics]]", or "for work contributing to the progress of pure or applied mathematics", or simply "in applied mathematics", and sometimes included condition that the work must be "done during the ten years preceding the award."

== 19th century&lt;ref&gt;{{cite book|chapter=Prix|title=Comptes rendus hebdomadaires des séances de l'Académie des sciences|year=1900|page=1570|location=Paris|publisher=Gauthier-Villars|volume=Tomes XCII à CXXI, 3 Janvier 1881 à 30 Décembre 1895|url=https://books.google.com/books?id=Y94PAQAAMAAJ&amp;pg=PA1570}}&lt;/ref&gt; ==

* (1868) [[Alfred Clebsch]]
* (1869) [[Julius von Mayer]]
* (1870) [[Camille Jordan]]
* (1871) [[Joseph Valentin Boussinesq|Joseph Boussinesq]]
* (1872) [[Amédée Mannheim]], "for the general excellence of his geometrical disquisitions."
* (1873) [[William Thomson, 1st Baron Kelvin|William Thomson]], "for his magnificent works on the mathematical theory of electricity and magnetism."
* (1874) [[Jacques Antoine Charles Bresse|Jacques Bresse]], "for his work in applied mechanics."
* (1875) [[Jean Gaston Darboux|Gaston Darboux]], "for the ensemble of his mathematical work."
* (1876) [[Xavier Kretz]]
* (1877) [[Edmond Laguerre]], "for his mathematical works."
* (1878) [[Maurice Lévy]]
* (1879) [[Théodore Moutard]]
* (1880) [[Henry Léauté]]
* (1881) [[Charles Auguste Briot]]
* (1882) [[Rudolf Clausius]]
* (1883) [[Georges Henri Halphen]]
* (1884) [[Jules Hoüel]]
* (1885) [[Henri Poincaré]]
* (1886) [[Charles Émile Picard]]
* (1887) [[Paul Émile Appell]]
* (1888) [[Édouard Collignon]]
* (1889) [[Édouard Goursat]]
* (1890) [[:es:Carlos Ibáñez de Ibero|Carlos Ibáñez de Ibero]]
* (1891) [[Marie Georges Humbert]]
* (1892) [[Benjamin Baker (engineer)|Benjamin Baker]] and [[Sir John Fowler, 1st Baronet|John Fowler]]
* (1893) [[Gabriel Xavier Paul Koenigs|Gabriel Koenigs]]
* (1894) [[Paul Matthieu Hermann Laurent|Hermann Laurent]], "for the whole of his mathematical works."
* (1895) [[Victor Gustave Robin|Gustave Robin]]
* (1896) [[Paul Painlevé]], "for all of his mathematical work."
* (1897) [[Roger Liouville]]&lt;!-- (1856–1930) --&gt;
* (1898) [[Jacques Hadamard]]
* (1899) [[Eugène Cosserat]], "for the whole of his contributions to geometry and mechanics."
* (1900) [[Léon Lecornu]]

== 20th century ==

* (1901) [[Émile Borel]]
* (1902) Maurice d'Ocagne
* (1903) [[David Hilbert]]
* (1904) Désiré André
* (1905) Charles Lallemand (1857–1938)&lt;ref&gt;{{cite journal|title=Séance du 18 décembre|journal=Le Moniteur scientifique du Doctor Quesneville|date=February 1906|pages=154–155|url=http://babel.hathitrust.org/cgi/pt?id=uc1.c2557126;view=1up;seq=162}}&lt;/ref&gt;
* (1906) Claude Guichard
* (1907) [[Charles Renard]] (posthumously)
* (1908) [[Erik Ivar Fredholm]], "for his researches on integral equations."
* (1909) Comte de Sparre, "for his studies relating to gunnery and his works on mechanics."&lt;ref&gt;{{cite journal|title=Séance du 20 décembre|journal=Le Moniteur scientifique du Doctor Quesneville|date=February 1910|pages=143–144|url=http://babel.hathitrust.org/cgi/pt?id=uc1.c2557134;view=1up;seq=151}}&lt;/ref&gt;
* (1910) [[Charles Riquier]]&lt;ref&gt;{{cite journal|title=Séance du 19 décembre|journal=Le Moniteur scientifique du Doctor Quesneville|date=February 1911|pages=137–138|url=http://babel.hathitrust.org/cgi/pt?id=uc1.c2557136;view=1up;seq=145}}&lt;/ref&gt;
* (1911) Auguste Rateau&lt;ref&gt;{{cite journal|title=Prix décernés année 1911|journal=Le Moniteur scientifique du Doctor Quesneville|date=February 1912|page=143|url=http://babel.hathitrust.org/cgi/pt?id=uc1.c2557138;view=1up;seq=151}}&lt;/ref&gt;
* (1912) Edmond Maillet
* (1913) [[Maurice Leblanc (engineer)|Maurice Leblanc]],&lt;ref&gt;{{cite journal|title=Prize Awards of the Paris Academy of Sciences for 1913|journal=Nature|date=1 January 1914|pages= 512|url=https://books.google.com/books?id=MxJLAQAAMAAJ&amp;pg=PA512}}&lt;/ref&gt; "for the totality of his researches in mechanics."
* (1914) [[Henri Lebesgue]]
* (1915) Charles Rabut&lt;ref&gt;{{cite journal|title=Séance du 27 décembre|journal=Le Moniteur scientifique du Doctor Quesneville|date=March 1916|pages=65–66|url=http://babel.hathitrust.org/cgi/pt?id=uc1.c2557145;view=1up;seq=73}}&lt;/ref&gt;
* (1916) [[Charles Jean de la Vallée-Poussin|Charles de la Vallée-Poussin]]
* (1917) [[Jules Andrade]], "for his work in applied mechanics, especially that dealing with chronometry."
* (1918) [[Joseph Larmor]]
* (1919) [[Prosper Charbonnier]], "for his work on ballistics"
* (1920) [[Élie Cartan]], "for the whole of his work."
* (1921) [[Émile Jouguet|Jacques Charles Émile Jouguet]]
* (1922) [[Jules Drach]], "for the whole of his work in mathematics."
* (1923) Auguste Boulanger ([[Posthumous recognition|posthumously]]), "for the whole of his scientific work."
* (1924) [[Ernest Vessiot]], "for the whole of his work in mathematics."
* (1925) Denis Eydoux, "for the whole of his work in hydraulics."
* (1926) [[Paul Antoine Aristide Montel|Paul Montel]], "for his mathematical work as a whole."
* (1927) [[Henri Villat]]
* (1929) [[Alfred-Marie Liénard]]
* (1930) [[Arnaud Denjoy]], "for the whole of his mathematical works."
* (1932) [[Raoul Bricard]], "for his work in geometry."
* (1934) [[René Maurice Fréchet]], "for the whole of his mathematical works."
* (1936) [[Paul Lévy (mathematician)|Paul Lévy]], "for the whole of his mathematical works."
* (1937) [[Joseph Bethenod]], " for his work on mechanics and electricity."
* (1938) [[Szolem Mandelbrojt]]
* (1939) [[Henri Bénard]]&lt;ref&gt;À titre posthume ; d'après les ''Comptes Rendus Hebdomadaires des Séances de l'Académie des Sciences'', vol. 209, p. 918 (1939).&lt;/ref&gt;
* (1942) René Garnier
* (1945) Alphonse Demoulin
* (1948) [[Georges Valiron]]
* (1951) [[Joseph Kampé de Fériet]]
* (1954) [[Georges Darmois]]
* (1975) [[Jean Céa]]
* (1978) [[Henri Skoda]]
* (1981) [[Philippe G. Ciarlet]]
* (1987) Pierre Ladeveze
* (1990) [[Jean-Yves Girard]]
* (1993) [[Marie Farge]] "for her work on the application of the [[wavelet transform]] to the study of [[turbulence]]"&lt;ref&gt;{{citation|journal=Comptes rendus de l'Académie des sciences: La vie des sciences|volume=10|issue=5|publisher=Gauthier-Villars|year=1993|page=479|quote=Le prix est décerné à Marie Farge ... pour sa contribution à l'application de la transformée par ondelettes à l'étude de la turbulence|title=none}}.&lt;/ref&gt;
* (1995) [[Yves Le Jan]]

== Notes ==
{{reflist}}

== References ==
* ''[[Nature (journal)|Nature]]'', different years.{{Specify|date=April 2011}}

[[Category:Mathematics awards]]
[[Category:Awards established in 1868]]
[[Category:French Academy of Sciences]]
[[Category:1868 establishments in France]]</text>
      <sha1>0a1lc126ar8djqkfan0vwdz8n6tt0td</sha1>
    </revision>
  </page>
  <page>
    <title>Power diagram</title>
    <ns>0</ns>
    <id>35793286</id>
    <revision>
      <id>834534630</id>
      <parentid>812303633</parentid>
      <timestamp>2018-04-06T06:27:59Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* top */ split long sentence</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9275">[[File:Power diagram.svg|thumb|300px|A power diagram of four circles]]
In [[computational geometry]], a '''power diagram''', also called a '''Laguerre–Voronoi diagram''', '''Dirichlet cell complex''', '''radical Voronoi tesselation''' or a '''sectional Dirichlet tesselation''', is a partition of the [[Euclidean plane]] into [[polygon]]al cells defined from a set of circles. The cell for a given circle ''C'' consists of all the points for which the [[Power of a point|power distance]] to ''C'' is smaller than the power distance to the other circles. The power diagram is a form of generalized [[Voronoi diagram]], and coincides with the Voronoi diagram of the circle centers in the case that all the circles have equal radii.&lt;ref&gt;{{citation
 | last = Linhart | first = J.
 | doi = 10.1007/BF00149360
 | issue = 3
 | journal = Geometriae Dedicata
 | mr = 627538
 | pages = 363–367
 | title = Dirichletsche Zellenkomplexe mit maximaler Eckenzahl
 | volume = 11
 | year = 1981}}.&lt;/ref&gt;&lt;ref name="iim85"&gt;{{citation
 | last1 = Imai | first1 = Hiroshi
 | last2 = Iri | first2 = Masao
 | last3 = Murota | first3 = Kazuo
 | doi = 10.1137/0214006
 | issue = 1
 | journal = [[SIAM Journal on Computing]]
 | mr = 774929
 | pages = 93–105
 | title = Voronoĭ diagram in the Laguerre geometry and its applications
 | volume = 14
 | year = 1985}}.&lt;/ref&gt;&lt;ref name="a87"&gt;{{citation
 | last = Aurenhammer | first = F. | authorlink = Franz Aurenhammer
 | doi = 10.1137/0216006
 | issue = 1
 | journal = [[SIAM Journal on Computing]]
 | mr = 873251
 | pages = 78–96
 | title = Power diagrams: properties, algorithms and applications
 | volume = 16
 | year = 1987}}.&lt;/ref&gt;&lt;ref name="e87"&gt;{{citation
 | last = Edelsbrunner | first = Herbert | author-link = Herbert Edelsbrunner
 | contribution = 13.6 Power Diagrams
 | pages = 327–328
 | publisher = Springer-Verlag
 | series = EATCS Monographs on Theoretical Computer Science
 | title = Algorithms in Combinatorial Geometry
 | volume = 10
 | year = 1987}}.&lt;/ref&gt;

==Definition==
[[File:Valor de la potencia de un punto - caso exterior.svg|thumb|The power of a point ''P'' outside of a given circle]]
If ''C'' is a circle and ''P'' is a point outside ''C'', then the [[Power of a point|power]] of ''P'' with respect to ''C'' is the square of the length of a line segment from ''P'' to a point ''T'' of tangency with ''C''. Equivalently, if ''P'' has distance ''d'' from the center of the circle, and the circle has radius ''r'', then (by the [[Pythagorean theorem]]) the power is ''d''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;''r''&lt;sup&gt;2&lt;/sup&gt;. The same formula ''d''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;''r''&lt;sup&gt;2&lt;/sup&gt; may be extended to all points in the plane, regardless of whether they are inside or outside of ''C'': points on ''C'' have zero power, and points inside ''C'' have negative power.&lt;ref name="iim85"/&gt;&lt;ref name="a87"/&gt;&lt;ref name="e87"/&gt;

The power diagram of a set of ''n'' circles ''C''&lt;sub&gt;''i''&lt;/sub&gt; is a partition of the plane into ''n'' regions ''R''&lt;sub&gt;''i''&lt;/sub&gt; (called cells), such that a point ''P'' belongs to ''R''&lt;sub&gt;''i''&lt;/sub&gt; whenever circle ''C''&lt;sub&gt;''i''&lt;/sub&gt; is the circle minimizing the power of ''P''.&lt;ref name="iim85"/&gt;&lt;ref name="a87"/&gt;&lt;ref name="e87"/&gt;

[[File:Radical axis intersecting circles.svg|thumb|The radical axis of two intersecting circles. The power diagram of the two circles is the partition of the plane into two halfplanes formed by this line.]]
In the case ''n''&amp;nbsp;=&amp;nbsp;2, the power diagram consists of two [[halfplane]]s, separated by a line called the [[radical axis]] or chordale of the two circles. Along the radical axis, both circles have equal power. More generally, in any power diagram, each cell ''R''&lt;sub&gt;''i''&lt;/sub&gt; is a [[convex polygon]], the intersection of the halfspaces bounded by the radical axes of circle ''C''&lt;sub&gt;''i''&lt;/sub&gt; with each other circle. Triples of cells meet at [[vertex (geometry)|vertices]] of the diagram, which are the radical centers of the three circles whose cells meet at the vertex.&lt;ref name="iim85"/&gt;&lt;ref name="a87"/&gt;&lt;ref name="e87"/&gt;

==Related constructions==
The power diagram may be seen as a weighted form of the [[Voronoi diagram]] of a set of point sites, a partition of the plane into cells within which one of the sites is closer than all the other sites. Other forms of [[weighted Voronoi diagram]] include the additively weighted Voronoi diagram, in which each site has a weight that is added to its distance before comparing it to the distances to the other sites, and the multiplicatively weighted Voronoi diagram, in which the weight of a site is multiplied by its distance before comparing it to the distances to the other sites. In contrast, in the power diagram, we may view each circle center as a site, and each circle's squared radius as a weight that is subtracted from the [[quadrance|squared distance]] before comparing it to other squared distances. In the case that all the circle radii are equal, this subtraction makes no difference to the comparison, and the power diagram coincides with the Voronoi diagram.&lt;ref name="a87"/&gt;&lt;ref name="e87"/&gt;

A planar power diagram may also be interpreted as a planar cross-section of an unweighted three-dimensional Voronoi diagram. In this interpretation, the set of circle centers in the cross-section plane are the perpendicular projections of the three-dimensional Voronoi sites, and the squared radius of each circle is a constant ''K'' minus the squared distance of the corresponding site from the cross-section plane, where ''K'' is chosen large enough to make all these radii positive.&lt;ref&gt;{{citation
 | last1 = Ash | first1 = Peter F.
 | last2 = Bolker | first2 = Ethan D.
 | doi = 10.1007/BF00164401
 | issue = 2
 | journal = Geometriae Dedicata
 | mr = 833848
 | pages = 209–243
 | title = Generalized Dirichlet tessellations
 | volume = 20
 | year = 1986}}.&lt;/ref&gt;

Like the Voronoi diagram, the power diagram may be generalized to Euclidean spaces of any dimension. The power diagram of ''n'' spheres in ''d'' dimensions is combinatorially equivalent to the intersection of a set of ''n'' upward-facing halfspaces in ''d''&amp;nbsp;+&amp;nbsp;1 dimensions, and vice versa.&lt;ref name="a87"/&gt;

==Algorithms and applications==
Two-dimensional power diagrams may be constructed by an algorithm that runs in time O(''n''&amp;nbsp;log&amp;nbsp;''n'').&lt;ref name="iim85"/&gt;&lt;ref name="a87"/&gt; More generally, because of the equivalence with higher-dimensional halfspace intersections, ''d''-dimensional power diagrams (for ''d''&amp;nbsp;&gt;&amp;nbsp;2) may be constructed by an algorithm that runs in time &lt;math&gt;O(n^{\lceil d/2\rceil})&lt;/math&gt;.&lt;ref name="a87"/&gt;

The power diagram may be used as part of an efficient algorithm for computing the volume of a union of spheres. Intersecting each sphere with its power diagram cell gives its contribution to the total union, from which the volume may be computed in time proportional to the complexity of the power diagram.&lt;ref name="abi88"&gt;{{citation
 | last1 = Avis | first1 = David | author1-link = David Avis
 | last2 = Bhattacharya | first2 = Binay K.
 | last3 = Imai | first3 = Hiroshi
 | doi = 10.1007/BF01901190
 | issue = 6
 | journal = The Visual Computer
 | pages = 323–328
 | title = Computing the volume of the union of spheres
 | url = http://cgm.cs.mcgill.ca/~avis/doc/avis/ABI88a.pdf
 | volume = 3
 | year = 1988}}.&lt;/ref&gt;

Other applications of power diagrams include [[data structure]]s for testing whether a point belongs to a union of disks,&lt;ref name="iim85"/&gt; algorithms for constructing the boundary of a union of disks,&lt;ref name="iim85"/&gt; and algorithms for finding the closest two balls in a set of balls.&lt;ref&gt;{{citation
 | last1 = Guibas | first1 = Leonidas | author1-link = Leonidas J. Guibas
 | last2 = Zhang | first2 = Li
 | contribution = Euclidean proximity and power diagrams
 | title = 10th Canadian Conference on Computational Geometry
 | url = http://www.cccg.ca/proceedings/1998/cccg98-guibas-euclidean.ps.gz
 | year = 1998}}.&lt;/ref&gt;

==History==
{{harvtxt|Aurenhammer|1987}} traces the definition of the power distance to the work of 19th-century mathematicians [[Edmond Laguerre]] and [[Georgy Voronoy]].&lt;ref name="a87"/&gt; {{harvtxt|Fejes Tóth|1977}} defined power diagrams and used them to show that the boundary of a union of ''n'' circular disks can always be illuminated from at most 2''n'' point light sources.&lt;ref&gt;{{citation
 | last = Fejes Tóth | first = L. | author-link = László Fejes Tóth
 | doi = 10.1007/BF01895856
 | issue = 3-4
 | journal = Acta Mathematica Academiae Scientiarum Hungaricae
 | mr = 0464065
 | pages = 355–360
 | title = Illumination of convex discs
 | volume = 29
 | year = 1977}}.&lt;/ref&gt; Power diagrams have appeared in the literature under other names including the "Laguerre–Voronoi diagram", "Dirichlet cell complex", "radical Voronoi tesselation" and "sectional Dirichlet tesselation".&lt;ref name="ai88"&gt;{{citation
 | last1 = Aurenhammer | first1 = F.
 | last2 = Imai | first2 = H.
 | doi = 10.1007/BF00181613
 | issue = 1
 | journal = Geometriae Dedicata
 | mr = 950323
 | pages = 65–75
 | title = Geometric relations among Voronoĭ diagrams
 | volume = 27
 | year = 1988}}.&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Computational geometry]]
[[Category:Diagrams]]</text>
      <sha1>abx9f1re4ja2ax3c7ino96yn6anykbr</sha1>
    </revision>
  </page>
  <page>
    <title>Projected tolerance zone</title>
    <ns>0</ns>
    <id>15565331</id>
    <revision>
      <id>813780032</id>
      <parentid>786713813</parentid>
      <timestamp>2017-12-05T05:44:31Z</timestamp>
      <contributor>
        <username>BobKilcoyne</username>
        <id>7770027</id>
      </contributor>
      <comment>Tidied up</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="610">[[File:Gd&amp;t projectedtolerancezone.png|thumb|right|Projected tolerance zone symbol (used in a [[feature control frame]])]]
In [[geometric dimensioning and tolerancing]], a '''projected tolerance zone''' is defined to predict the final dimensions and locations of features on a component or assembly subject to [[Tolerance analysis|tolerance stack-up]].

==References==
*[https://www.asme.org/products/codes-standards/y145-1994-dimensioning-and-tolerancing ASME Y14.5M-1994 Dimensioning and Tolerancing]

[[Category:American Society of Mechanical Engineers]]
[[Category:Technical drawing]]

{{engineering-stub}}</text>
      <sha1>ae1glcap28thqtz1rw8odnb79vx63g5</sha1>
    </revision>
  </page>
  <page>
    <title>Propagator</title>
    <ns>0</ns>
    <id>698759</id>
    <revision>
      <id>871360769</id>
      <parentid>868860821</parentid>
      <timestamp>2018-11-30T15:08:10Z</timestamp>
      <contributor>
        <username>Enyokoyama</username>
        <id>16945943</id>
      </contributor>
      <minor/>
      <comment>/* Basic examples: propagator of free particle and harmonic oscillator */ correct link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32307">{{about|time evolution in [[quantum field theory]]|propagation of plants|Plant propagation}}
{{Quantum field theory}}
In [[quantum mechanics]] and [[quantum field theory]], the '''propagator''' is a function that specifies the [[probability amplitude]] for a particle to travel from one place to another in a given time, or to travel with a certain energy and momentum. In [[Feynman diagram]]s, which serve to calculate the rate of collisions in [[quantum field theory]], [[virtual particle]]s contribute their propagator to the rate of the [[scattering]] event described by the respective diagram. These may also be viewed as the [[inverse operation|inverse]] of the [[wave operator]] appropriate to the particle, and are, therefore, often called ''(causal) [[Green's function]]s'' (called "''causal''" to distinguish it from the elliptic Laplacian Green's function).&lt;ref&gt;[http://www.mathtube.org/sites/default/files/lecture-notes/Lamoureux_Michael.pdf The mathematics of PDEs and the wave equation], p 32., Michael P. Lamoureux, University of Calgary, Seismic Imaging Summer School,  August 7–11, 2006, Calgary.&lt;/ref&gt;&lt;ref&gt;[http://www.roe.ac.uk/japwww/teaching/fourier/fourier_lectures_part4.pdf Ch.: 9 Green's functions], p 6., J Peacock, FOURIER ANALYSIS LECTURE COURSE: LECTURE 15.&lt;/ref&gt;

==Non-relativistic propagators==
In non-relativistic quantum mechanics, the propagator gives the probability amplitude for a [[Elementary particle|particle]] to travel from one spatial point at one time to another spatial point at a later time. It is the [[Green's function]] ([[fundamental solution]]) for the [[Schrödinger equation]]. This means that, if a system has [[Hamiltonian (quantum mechanics)|Hamiltonian]] {{mvar|H}}, then the appropriate propagator is a function
:&lt;math&gt;G(x,t;x',t')=\frac{1}{i\hbar}\Theta(t-t')K(x,t;x',t')&lt;/math&gt;
satisfying
:&lt;math&gt;\left( i\hbar \frac{\partial}{\partial t} -H_x \right) G(x,t;x',t') = \delta(x-x')\delta(t-t') ~,&lt;/math&gt;
where {{math|''H&lt;sub&gt;x&lt;/sub&gt;''}} denotes the Hamiltonian written in terms of the {{mvar|x}} coordinates, {{math|''δ''(''x'')}} denotes the [[Dirac delta-function]], {{math|Θ(''t'')}} is the [[Heaviside step function]] and {{math|''K''(''x'', ''t'' ;''x′'', ''t′'')}} is the [[Integral transform|kernel]] of the above Schrödinger differential operator in the big parenthesis, often referred to as the '''''propagator''''' instead of {{mvar|G}} in this context, and henceforth in this article.  (cf. [[Duhamel's principle]].)

This propagator may also be written as the transition amplitude
:&lt;math&gt;K(x,t;x',t') = \left \langle x \mid \hat{U}(t,t') \mid x'\right \rangle,&lt;/math&gt;
where {{math|''Û''(''t'', ''t′'')}} is the [[unitary operator|unitary]] time-evolution operator for the system taking states at time {{mvar|t′}} to states at time {{mvar|t}}. Note that 
&lt;math&gt;   \lim_{t\to t'} K(x,t;x',t') = \delta(x-x')  &lt;/math&gt;.

The quantum mechanical propagator may also be found by using a [[Path integral formulation|path integral]],
:&lt;math&gt;K(x,t;x',t') = \int \exp \left[\frac{i}{\hbar} \int_t^{t'} L(\dot{q},q,t) \, dt\right] D[q(t)]&lt;/math&gt;
where the boundary conditions of the path integral include {{math|''q''(''t'') {{=}} ''x'', ''q''(''t′'') {{=}} ''x′''}}. Here {{mvar|L}} denotes the [[Lagrangian mechanics|Lagrangian]] of the system. The paths that are summed over move only forwards in time, and are integrated with the differential &lt;math&gt;D[q(t)]&lt;/math&gt; which follows the path in time.

In non-relativistic [[quantum mechanics]], the propagator lets you find the wave function of a system given an initial wave function and a time interval. The new wave function is given by the equation

:&lt;math&gt;\psi(x,t) = \int_{-\infty}^\infty \psi(x',t') K(x,t; x', t') \, dx'.&lt;/math&gt;

If {{math|''K''(''x'',''t'';''x''&amp;prime;,''t''&amp;prime;)}} only depends on the difference {{math|''x'' − ''x′''}}, this is a [[convolution]] of the initial wave function and the propagator. This kernel is the kernel of [[integral transform]].

===Basic examples: propagator of free particle and harmonic oscillator===
For a time-translationally invariant system, the propagator only depends on the time difference {{math|''t'' − ''t''′}}, so it may be rewritten as
:&lt;math&gt;K(x,t;x',t')=K(x,x';t-t').&lt;/math&gt;

The [[Wave packet#Free propagator|propagator of a one-dimensional free particle]], with the far-right expression obtained via [[method of steepest descent|saddle-point methods]],  is then
{{Equation box 1
|indent =:
|equation =&lt;math&gt;K(x,x';t)=\frac{1}{2\pi}\int_{-\infty}^{+\infty}dk\,e^{ik(x-x')} e^{-\frac{i\hbar k^2 t}{2m}}=\left(\frac{m}{2\pi i\hbar t}\right)^{\frac{1}{2}}e^{-\frac{m(x-x')^2}{2i\hbar t}}.&lt;/math&gt;
|cellpadding= 6
|border
|border colour = #0073CF
|bgcolor=#F9FFF7}}

Similarly, the propagator of a one-dimensional [[Quantum harmonic oscillator#Natural length and energy scales|quantum harmonic oscillator]] is the [[Mehler kernel]],&lt;ref&gt;E. U. Condon, "Immersion of the Fourier transform in a continuous group of functional transformations", ''Proc. Natl. Acad. Sci. USA''  '''23''',  (1937) 158–164. [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1076889/pdf/pnas01779-0028.pdf online]&lt;/ref&gt;&lt;ref&gt;[[Wolfgang Pauli]],   ''Wave Mechanics: Volume 5 of Pauli Lectures on Physics'' (Dover Books on Physics, 2000) {{ISBN|0486414620}} , cf. Section 44.&lt;/ref&gt; 
{{Equation box 1
|indent =:
|equation =&lt;math&gt;K(x,x';t)=\left(\frac{m\omega}{2\pi i\hbar \sin \omega t}\right)^{\frac{1}{2}}\exp\left(-\frac{m\omega((x^2+x'^2)\cos\omega t-2xx')}{2i\hbar \sin\omega t}\right) ~.&lt;/math&gt;
|cellpadding= 6
|border
|border colour = #0073CF
|bgcolor=#F9FFF7}}
The latter may be obtained from the previous free particle result upon making use of van Kortryk's SU(2) Lie-group identity,
:&lt;math&gt;\exp \left( -\frac{it}{\hbar }\left( \frac{1}{2m}~\mathsf{p}^{2}+\frac{1}{2}~m\omega^{2}\mathsf{x}^{2}\right) \right)&lt;/math&gt;

::&lt;math&gt;=\exp \left( -\frac{im\omega }{2\hbar }~\mathsf{x}^{2}\tan \left( \frac{
\omega t}{2}\right) \right) \exp \left( -\frac{i}{2m\omega \hbar }~\mathsf{p}
^{2}\sin \left( \omega t\right) \right) \exp \left( -\frac{im\omega }{2\hbar 
}~\mathsf{x}^{2}\tan \left( \frac{\omega t}{2}\right) \right) ~,&lt;/math&gt;
valid for operators &lt;math&gt;\mathsf{x}&lt;/math&gt; and &lt;math&gt;\mathsf{p}&lt;/math&gt; satisfying the Heisenberg relation &lt;math&gt;[\mathsf{x},\mathsf{p}]=i\hbar&lt;/math&gt;.

For the {{mvar|N}}-dimensional case, the propagator can be simply obtained by the product
:&lt;math&gt;K(\vec{x},\vec{x}';t)=\prod_{q=1}^N K(x_q,x_q';t)~.&lt;/math&gt;

{{see also|Path integral formulation#Simple harmonic oscillator}}

==Relativistic propagators==
In relativistic quantum mechanics and [[quantum field theory]] the propagators are [[Lorentz invariant]]. They give the amplitude for a [[Elementary particle|particle]] to travel between two [[spacetime]] points.

===Scalar propagator===
In quantum field theory, the theory of a free (non-interacting) [[scalar field]] is a useful and simple example which serves to illustrate the concepts needed for more complicated theories. It describes [[Spin (physics)|spin]] zero particles. There are a number of possible propagators for free scalar field theory. We now describe the most common ones.

=== Position space ===
The position space propagators are [[Green's function]]s for the [[Klein–Gordon equation]]. This means they are functions {{math|''G''(''x'', ''y'')}} which satisfy

:&lt;math&gt;(\square_x + m^2)G(x,y)=-\delta(x-y)&lt;/math&gt;

where:
* {{mvar|x, y}} are two points in [[Minkowski spacetime]].
* &lt;math&gt; \square_x = \tfrac{\partial^2}{\partial t^2} - \nabla^2 &lt;/math&gt; is the [[d'Alembertian]] operator acting on the {{mvar|x}} coordinates.
* {{math|''δ''(''x'' − ''y'')}} is the [[Dirac delta-function]].

(As typical in [[special relativity|relativistic]] quantum field theory calculations, we use units where the [[speed of light]], {{mvar|c}}, and [[Planck's Constant|Planck's reduced constant]], {{mvar|ħ}}, are set to unity.)

We shall restrict attention to 4-dimensional [[Minkowski spacetime]]. We can perform a [[Fourier transform]] of the equation for the propagator, obtaining
:&lt;math&gt;\left(-p^2 + m^2 \right )G(p)=-1.&lt;/math&gt;

This equation can be inverted in the sense of [[Distribution (mathematics)|distributions]] noting that the equation {{math|''xf(x)''{{=}}1}} has the solution, (see [[Sokhotski-Plemelj theorem]])
:&lt;math&gt;f(x)= \frac{1}{x\pm i\varepsilon} = \frac{1}{x}\mp i\pi\delta(x),&lt;/math&gt;
with {{mvar|ε}} implying the limit to zero. Below, we discuss the right choice of the sign arising from causality requirements.

The solution is
{{Equation box 1
|indent =:
|equation = &lt;math&gt;G(x,y) = \frac{1}{(2 \pi)^4} \int d^4p \, \frac{e^{-ip(x-y)}}{p^2 - m^2\pm i\varepsilon}  ~,&lt;/math&gt;
|cellpadding= 6
|border
|border colour = #0073CF
|bgcolor=#F9FFF7}}
where 
:&lt;math&gt;p(x-y):= p_0(x^0-y^0) - \vec{p} \cdot (\vec{x}-\vec{y})&lt;/math&gt; 
is the [[4-vector]] inner product.

The different choices for how to deform the [[Methods of contour integration|integration contour]] in the above expression lead to various forms for the propagator. The choice of contour is usually phrased in terms of the &lt;math&gt;p_0&lt;/math&gt; integral.

The integrand then has two poles at 
:&lt;math&gt;p_0 = \pm \sqrt{\vec{p}^2 + m^2}&lt;/math&gt; 
so different choices of how to avoid these lead to different propagators.

==== Causal propagators ====
=====Retarded propagator=====
[[Image:CausalRetardedPropagatorPath.svg]]

A contour going clockwise over both poles gives the '''causal retarded propagator'''. This is zero if {{mvar|x-y}} is spacelike or if {{math|''x'' ⁰&lt; ''y'' ⁰}} (i.e. if {{mvar|y}} is to the future of {{mvar|x}}).

This choice of contour is equivalent to calculating the [[Limit (mathematics)|limit]],
:&lt;math&gt;G_\text{ret}(x,y) = \lim_{\varepsilon \to 0} \frac{1}{(2 \pi)^4} \int d^4p \, \frac{e^{-ip(x-y)}}{(p_0+i\varepsilon)^2 - \vec{p}^2 - m^2} = -\frac{\Theta(x-y)}{2\pi} \delta(\tau_{xy}^2) + \Theta(x-y)\Theta(\tau_{xy}^2)\frac{m J_1(m \tau_{xy})}{4 \pi \tau_{xy}}&lt;/math&gt;

Here 
:&lt;math&gt;\Theta (x) := \begin{cases} 1 &amp; x \ge 0 \\ 0 &amp; x &lt; 0 \end{cases}&lt;/math&gt;
is the [[Heaviside step function]] and
:&lt;math&gt;\tau_{xy}:= \sqrt{ (x^0 - y^0)^2 - (\vec{x} - \vec{y})^2}&lt;/math&gt;
is the [[proper time]] from {{mvar|x}} to {{mvar|y}} and &lt;math&gt;J_1&lt;/math&gt; is a [[Bessel function of the first kind]]. The expression &lt;math&gt;y \prec x&lt;/math&gt; means {{mvar|y}} [[causal structure|causally precedes]] {{mvar|x}} which, for Minkowski spacetime, means
:&lt;math&gt;y^0 &lt; x^0&lt;/math&gt; and &lt;math&gt;\tau_{xy}^2 \geq 0 ~.&lt;/math&gt;

This expression can be related to the [[vacuum expectation value]] of the [[commutator]] of the free scalar field operator,
:&lt;math&gt;G_\text{ret}(x,y) = i \langle 0| \left[ \Phi(x), \Phi(y) \right] |0\rangle \Theta(x^0 - y^0)&lt;/math&gt;
where 
:&lt;math&gt;\left[\Phi(x),\Phi(y) \right]:= \Phi(x) \Phi(y) - \Phi(y) \Phi(x)&lt;/math&gt;
is the [[commutator]].

=====Advanced propagator=====
[[Image:CausalAdvancedPropagatorPath.svg]]

A contour going anti-clockwise under both poles gives the '''causal advanced propagator'''. This is zero if {{mvar|x-y}} is spacelike or if {{math|''x'' ⁰&gt; ''y'' ⁰}} (i.e. if {{mvar|y}} is to the past of {{mvar|x}}).

This choice of contour is equivalent to calculating the limit&lt;ref&gt;{{cite book |last1=Scharf |first1=Günter |title=Finite Quantum Electrodynamics, The Casual Approach |publisher=Springer |isbn=978-3-642-63345-4 |pages=89}}&lt;/ref&gt;
:&lt;math&gt;
G_\text{adv}(x,y) = \lim_{\varepsilon \to 0} \frac{1}{(2\pi)^4} \int d^4p \, \frac{e^{-ip(x-y)}}{(p_0 - i\varepsilon)^2 - \vec{p}^2 - m^2} = -\frac{\Theta(y-x)}{2\pi}\delta(\tau_{xy}^2) + \Theta(y-x)\Theta(\tau_{xy}^2)\frac{m J_1(m \tau_{xy})}{4 \pi \tau_{xy}}
&lt;/math&gt;

This expression can also be expressed in terms of the [[vacuum expectation value]] of the [[commutator]] of the free scalar field.
In this case,
:&lt;math&gt;G_\text{adv}(x,y) = -i \langle 0|\left[ \Phi(x), \Phi(y) \right]|0\rangle \Theta(y^0 - x^0)~.&lt;/math&gt;

====Feynman propagator====
[[Image:FeynmanPropagatorPath.svg]]

A contour going under the left pole and over the right pole gives the '''Feynman propagator'''.

This choice of contour is equivalent to calculating the limit&lt;ref&gt;Huang, p. &amp;nbsp; 30&lt;/ref&gt;   
:&lt;math&gt;G_F(x,y) = \lim_{\varepsilon \to 0} \frac{1}{(2 \pi)^4} \int d^4p \, \frac{e^{-ip(x-y)}}{p^2 -  m^2 + i\varepsilon} = \begin{cases}
-\frac{1}{4 \pi} \delta(s) + \frac{m}{8 \pi \sqrt{s}} H_1^{(2)}(m \sqrt{s}) &amp; s \geq 0 \\ -\frac{i m}{ 4 \pi^2 \sqrt{-s}} K_1(m \sqrt{-s}) &amp; s &lt; 0.\end{cases} &lt;/math&gt;

Here

:&lt;math&gt;s:= (x^0 - y^0)^2 - (\vec{x} - \vec{y})^2,&lt;/math&gt;

where {{mvar|x}}  and {{mvar|y}} are two points in [[Minkowski spacetime]], and the dot in the exponent is a [[four-vector]] [[inner product]]. {{math|''H&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;(2)&lt;/sup&gt;''}} is a [[Bessel function#Hankel functions: H.CE.B1.281.29.2C H.CE.B1.282.29|Hankel function]] and {{math|''K&lt;sub&gt;1&lt;/sub&gt;''}} is a [[Bessel function#Modified Bessel functions: I.CE.B1.2C K.CE.B1|modified Bessel function]].

This expression can be derived directly from the field theory as the [[vacuum expectation value]] of the ''[[time-ordered]] product'' of the free scalar field, that is, the product always taken such that the time ordering of the spacetime points is the same,

:&lt;math&gt;
\begin{align}
G_F(x-y) &amp; = -i \lang 0|T(\Phi(x) \Phi(y))|0 \rang \\[4pt]
&amp; = -i \left \lang 0| \left [\Theta(x^0 - y^0) \Phi(x)\Phi(y) + \Theta(y^0 - x^0) \Phi(y)\Phi(x) \right] |0 \right \rang.
\end{align}
&lt;/math&gt;

This expression is [[Lorentz invariant]], as long as the field operators commute with one another when the points {{mvar|x}} and {{mvar|y}} are separated by a [[spacelike]] interval.

The usual derivation is to insert a complete set of single-particle momentum states between the fields with Lorentz covariant normalization, and to then show that the {{math|Θ}} functions providing the causal time ordering may be obtained by a [[line integral|contour integral]] along the energy axis, if the integrand is as above (hence the infinitesimal imaginary part), to move the pole off the real line.

The propagator may also be derived using the [[path integral formulation]] of quantum theory.

===Momentum space propagator===
The [[Fourier transform]] of the position space propagators can be thought of as propagators in [[momentum space]]. These take a much simpler form than the position space propagators.

They are often written with an explicit {{mvar|ε}} term although this is understood to be a reminder about which integration contour is appropriate (see above). This {{mvar|ε}} term is included to incorporate boundary conditions and [[causality]] (see below).

For a [[4-momentum]] {{mvar|p}} the causal and Feynman propagators in momentum space are:

:&lt;math&gt;\tilde{G}_\text{ret}(p) = \frac{1}{(p_0+i\varepsilon)^2 - \vec{p}^2 - m^2}&lt;/math&gt;
:&lt;math&gt;\tilde{G}_\text{adv}(p) = \frac{1}{(p_0-i\varepsilon)^2 - \vec{p}^2 - m^2}&lt;/math&gt;
:&lt;math&gt;\tilde{G}_F(p) = \frac{1}{p^2 -  m^2 + i\varepsilon}. &lt;/math&gt;

For purposes of Feynman diagram calculations, it is usually convenient to write these with an additional overall factor of {{mvar|−i}} (conventions vary).

===Faster than light?===
The Feynman propagator has some properties that seem baffling at first. In particular, unlike the commutator, the propagator is ''nonzero'' outside of the [[light cone]], though it falls off rapidly for spacelike intervals. Interpreted as an amplitude for particle motion, this translates to the virtual particle travelling faster than light. It is not immediately obvious how this can be reconciled with causality: can we use faster-than-light virtual particles to send faster-than-light messages?

The answer is no: while in [[classical mechanics]] the intervals along which particles and causal effects can travel are the same, this is no longer true in quantum field theory, where it is [[commutator]]s that determine which operators can affect one another.

So what ''does'' the spacelike part of the propagator represent? In QFT the [[vacuum]] is an active participant, and [[particle number]]s and field values are related by an [[uncertainty principle]]; field values are uncertain even for particle number ''zero''. There is a nonzero [[probability amplitude]] to find a significant fluctuation in the vacuum value of the field {{math|Φ(''x'')}} if one measures it locally (or, to be more precise, if one measures an operator obtained by averaging the field over a small region). Furthermore, the dynamics of the fields tend to favor spatially correlated fluctuations to some extent. The nonzero time-ordered product for spacelike-separated fields then just measures the amplitude for a nonlocal correlation in these vacuum fluctuations, analogous to an [[EPR paradox|EPR correlation]].  Indeed, the propagator is often called a ''two-point correlation function'' for the [[free field]].

Since, by the postulates of quantum field theory, all [[observable]] operators commute with each other at spacelike separation, messages can no more be sent through these correlations than they can through any other EPR correlations; the correlations are in random variables.

Regarding virtual particles, the propagator at spacelike separation can be thought of as a means of calculating the amplitude for creating a virtual particle-[[antiparticle]] pair that eventually disappears into the vacuum, or for detecting a virtual pair emerging from the vacuum.  In [[Richard Feynman|Feynman]]'s language, such creation and annihilation processes are equivalent to a virtual particle wandering backward and forward through time, which can take it outside of the light cone.  However, no signaling back in time is allowed.

====Explanation using limits====
This can be made clearer by writing the propagator in the following form for a massless photon,
:&lt;math&gt; G^\varepsilon_F(x,y) = \frac{\varepsilon}{ (x-y)^2 + i \varepsilon^2 }   ~. &lt;/math&gt;

This is the usual definition but normalised by a factor of &lt;math&gt;\varepsilon&lt;/math&gt;. Then the rule is that one only takes the limit &lt;math&gt;\varepsilon \rightarrow 0&lt;/math&gt; at the end of a calculation.

One sees that 
:&lt;math&gt; G^\varepsilon_F(x,y) = \frac{1}{\varepsilon}&lt;/math&gt;  &amp;nbsp;  if    &amp;nbsp; &lt;math&gt;(x-y)^2=0&lt;/math&gt;
and
:&lt;math&gt; \lim_{\varepsilon \rightarrow 0} G^\varepsilon_F(x,y) = 0 &lt;/math&gt;   &amp;nbsp;   if   &amp;nbsp;  &lt;math&gt;(x-y)^2\neq 0&lt;/math&gt;
Hence this means a single photon will always stay on the light cone. It is also shown that the total probability for a photon at any time must be normalised by the reciprocal of the following factor:
:&lt;math&gt; \lim_{\varepsilon \rightarrow 0}\int \left|G^\varepsilon_F(0,x)  \right|^2 \, dx^3  
=  \lim_{\varepsilon \rightarrow 0}\int \frac{\varepsilon^2}{ (\mathbf{x}^2-t^2)^2 +  \varepsilon^4 } \, dx^3 
= 2 \pi^2 |t|   ~.
&lt;/math&gt;
We see that the parts outside the light cone usually are zero in the limit and only are important in Feynman diagrams.

===Propagators in Feynman diagrams===
The most common use of the propagator is in calculating [[probability amplitude]]s for particle interactions using [[Feynman diagram]]s.  These calculations are usually carried out in momentum space. In general, the amplitude gets a factor of the propagator for every ''internal line'', that is, every line that does not represent an incoming or outgoing particle in the initial or final state. It will also get a factor proportional to, and similar in form to, an interaction term in the theory's [[Lagrangian (field theory)|Lagrangian]] for every internal vertex where lines meet.  These prescriptions are known as ''Feynman rules''.

Internal lines correspond to virtual particles. Since the propagator does not vanish for combinations of energy and momentum disallowed by the classical equations of motion, we say that the virtual particles are allowed to be [[off shell]]. In fact, since the propagator is obtained by inverting the wave equation, in general, it will have singularities on the shell.

The energy carried by the particle in the propagator can even be ''negative''. This can be interpreted simply as the case in which, instead of a particle going one way, its [[antiparticle]] is going the ''other'' way, and therefore carrying an opposing flow of positive energy.  The propagator encompasses both possibilities.  It does mean that one has to be careful about minus signs for the case of [[fermions]], whose propagators are not [[even function]]s in the energy and momentum (see below).

Virtual particles conserve energy and momentum. However, since they can be off the shell, wherever the diagram contains a closed ''loop'', the energies and momenta of the virtual particles participating in the loop will be partly unconstrained, since a change in a quantity for one particle in the loop can be balanced by an equal and opposite change in another. Therefore, every loop in a Feynman diagram requires an integral over a continuum of possible energies and momenta. In general, these integrals of products of propagators can diverge, a situation that must be handled by the process of [[renormalization]].

===Other theories===
==== Spin {{frac|1|2}} ====
If the particle possesses [[Spin (physics)|spin]] then its propagator is in general somewhat more complicated, as it will involve the particle's spin or polarization indices. The differential equation satisfied by the propagator for a spin {{frac|1|2}} particle is given by&lt;ref&gt;{{harvnb|Greiner|Reinhardt|2008|loc=Ch.2}}&lt;/ref&gt;

:&lt;math&gt;(i\not\nabla' - m)S_F(x', x) = I_4\delta^4(x'-x),&lt;/math&gt;

where {{math|''I''&lt;sub&gt;4&lt;/sub&gt;}} is the unit matrix in four dimensions, and employing the [[Feynman slash notation]]. This is the Dirac equation for a delta function source in spacetime. Using the momentum representation,

:&lt;math&gt;S_F(x', x) = \int\frac{d^4p}{(2\pi)^4}\exp{\left[-ip \cdot(x'-x)\right]}\tilde S_F(p),&lt;/math&gt;

the equation becomes

: &lt;math&gt;
\begin{align}
&amp; (i \not \nabla' - m)\int\frac{d^4p}{(2\pi)^4}\tilde S_F(p)\exp{\left[-ip \cdot(x'-x)\right]} \\[6pt]
= {} &amp; \int\frac{d^4p}{(2\pi)^4}(\not p - m)\tilde S_F(p)\exp{\left[-ip \cdot(x'-x)\right]} \\[6pt]
= {} &amp; \int\frac{d^4p}{(2\pi)^4}I_4\exp{\left[-ip \cdot(x'-x)\right]} \\[6pt]
= {} &amp; I_4\delta^4(x'-x),
\end{align}
&lt;/math&gt;

where on the right-hand side an integral representation of the four-dimensional delta function is used. Thus

:&lt;math&gt;(\not p - m I_4)\tilde S_F(p) = I_4.&lt;/math&gt;

By multiplying from the left with

:&lt;math&gt;(\not p + m)&lt;/math&gt;

(dropping unit matrices from the notation) and using properties of the [[gamma matrices]],

: &lt;math&gt;
\begin{align}
\not p \not p &amp; = \frac{1}{2}(\not p \not p + \not p \not p) \\[6pt]
&amp; = \frac{1}{2}(\gamma_\mu p^\mu \gamma_\nu p^\nu + \gamma_\nu p^\nu \gamma_\mu p^\mu) \\[6pt]
&amp; = \frac{1}{2}(\gamma_\mu  \gamma_\nu + \gamma_\nu\gamma_\mu)p^\mu p^\nu \\[6pt]
&amp; = g_{\mu\nu}p^\mu p^\nu = p_\nu p^\nu  = p^2,
\end{align}
&lt;/math&gt;

the momentum-space propagator used in Feynman diagrams for a [[Dirac equation|Dirac]] field representing the [[electron]] in [[quantum electrodynamics]] is found to have form

:&lt;math&gt; \tilde{S}_F(p) = \frac{(\not p + m)}{p^2 - m^2 + i \varepsilon} = \frac{(\gamma^\mu p_\mu + m)}{p^2 - m^2 + i \varepsilon}.&lt;/math&gt;

The {{math|''iε''}} downstairs is a prescription for how to handle the poles in the complex {{math|''p''&lt;sub&gt;0&lt;/sub&gt;}}-plane. It automatically yields the [[Feynman propagator|Feynman contour of integration]] by shifting the poles appropriately. It is sometimes written

:&lt;math&gt;\tilde{S}_F(p) = {1 \over \gamma^\mu p_\mu - m + i\varepsilon} = {1 \over \not p - m + i\varepsilon} &lt;/math&gt;

for short. It should be remembered that this expression is just shorthand notation for {{math|(''γ''&lt;sub&gt;''μ''&lt;/sub&gt;''p''&lt;sup&gt;''μ''&lt;/sup&gt; − ''m'')&lt;sup&gt;−1&lt;/sup&gt;}}. "One over matrix" is otherwise nonsensical. In position space one has
:&lt;math&gt;S_F(x-y) = \int \frac{d^4 p}{(2\pi)^4} \, e^{-i p \cdot (x-y)} \frac{\gamma^\mu p_\mu + m}{p^2 - m^2 + i \varepsilon} = \left( \frac{\gamma^\mu (x-y)_\mu}{|x-y|^5} + \frac{m}{|x-y|^3} \right) J_1(m |x-y|).&lt;/math&gt;

This is related to the Feynman propagator by

:&lt;math&gt;S_F(x-y) = (i \not \partial + m) G_F(x-y)&lt;/math&gt;

where &lt;math&gt;\not \partial := \gamma^\mu \partial_\mu&lt;/math&gt;.

==== Spin 1 ====
The propagator for a [[gauge boson]] in a [[gauge theory]] depends on the choice of convention to fix the gauge. For the gauge used by Feynman and [[Ernst Stueckelberg|Stueckelberg]], the propagator for a [[photon]] is

:&lt;math&gt;{-i g^{\mu\nu} \over p^2 + i\varepsilon }.&lt;/math&gt;

The propagator for a massive vector field can be derived from the Stueckelberg Lagrangian. The general form with gauge parameter {{math|''λ''}} reads

:&lt;math&gt; \frac{g_{\mu\nu} - \frac{k_\mu k_\nu}{m^2}}{k^2-m^2+i\varepsilon}+\frac{\frac{k_\mu k_\nu}{m^2}}{k^2-\frac{m^2}{\lambda}+i\varepsilon}.&lt;/math&gt;

With this general form one obtains the propagator in unitary gauge for {{math|''λ'' {{=}} 0}}, the propagator in Feynman or 't Hooft gauge for {{math|''λ'' {{=}} 1}} and in Landau or Lorenz gauge for {{math|''λ'' {{=}} ∞}}. There are also other notations where the gauge parameter is the inverse of {{mvar|λ}}. The name of the propagator, however, refers to its final form and not necessarily to the value of the gauge parameter.

Unitary gauge:
:&lt;math&gt;\frac{g_{\mu\nu} - \frac{k_\mu k_\nu}{m^2}}{k^2-m^2+i\varepsilon}.&lt;/math&gt;

Feynman ('t Hooft) gauge:
:&lt;math&gt;\frac{g_{\mu\nu}}{k^2-m^2+i\varepsilon}.&lt;/math&gt;

Landau (Lorenz) gauge:
:&lt;math&gt;\frac{g_{\mu\nu} - \frac{k_\mu k_\nu}{k^2}}{k^2-m^2+i\varepsilon}.&lt;/math&gt;

===Graviton propagator===
The graviton propagator for [[Minkowski space]] in [[general relativity]] is 
:&lt;math&gt;G = \frac{\mathcal{P}^2}{k^2} - \frac{\mathcal{P}^0_s}{2k^2},&lt;/math&gt;
where &lt;math&gt;\mathcal{P}^2&lt;/math&gt; is the transverse and traceless [[Spin_(physics)#Spin_projection_quantum_number_and_multiplicity|spin-2 projection operator]] and &lt;math&gt;\mathcal{P}^0_s&lt;/math&gt; is a spin-0 scalar [[multiplet]]. 
The graviton propagator for [[Anti-de Sitter space|(Anti) de Sitter space]] is 
:&lt;math&gt;G = \frac{\mathcal{P}^2}{k^2+2H^2} - \frac{\mathcal{P}^0_s}{2(k^2-4H^2)},&lt;/math&gt;
where &lt;math&gt;H&lt;/math&gt; is the [[Hubble's law|Hubble constant]]. Note that upon taking the limit &lt;math&gt;H \to 0&lt;/math&gt;, the AdS propagator reduces to the Minkowski propagator.&lt;ref&gt;{{cite web|url=http://cds.cern.ch/record/378516/files/9902042.pdf |title=Graviton and gauge boson propagators in AdSd+1}}&lt;/ref&gt;

==Related singular functions==
{{further|Green's function (many-body theory)|Correlation function (quantum field theory)}}
The scalar propagators are Green's functions for the Klein–Gordon equation. There are related singular functions which are important in [[quantum field theory]]. We follow the notation in Bjorken and Drell.&lt;ref name="BD"&gt;Bjorken and Drell, Appendix C&lt;/ref&gt; See also Bogolyubov and Shirkov (Appendix A). These functions are most simply defined in terms of the [[vacuum expectation value]] of products of field operators.

===Solutions to the Klein–Gordon equation===
====Pauli&amp;ndash;Jordan function====
The commutator of two scalar field operators defines the Pauli&amp;ndash;Jordan function &lt;math&gt;\Delta(x-y)&lt;/math&gt; by&lt;ref name="BD"/&gt;

:&lt;math&gt;\langle 0 | \left[ \Phi(x),\Phi(y) \right] | 0 \rangle = i \, \Delta(x-y)&lt;/math&gt;
with
:&lt;math&gt;\,\Delta(x-y) = G_\text{adv} (x-y) - G_\text{ret}(x-y)&lt;/math&gt;

This satisfies 
:&lt;math&gt;\Delta(x-y) = -\Delta(y-x)&lt;/math&gt; 
and is zero if &lt;math&gt;(x-y)^2 &lt; 0&lt;/math&gt;.

====Positive and negative frequency parts (cut propagators)====
We can define the positive and negative frequency parts of &lt;math&gt;\Delta(x-y)&lt;/math&gt;, sometimes called cut propagators,  in a relativistically invariant way.

This allows us to define the positive frequency part:
:&lt;math&gt;\Delta_+(x-y) = \langle 0 | \Phi(x) \Phi(y) |0 \rangle, &lt;/math&gt;

and the negative frequency part:
:&lt;math&gt;\Delta_-(x-y) = \langle 0 | \Phi(y) \Phi(x) |0 \rangle. &lt;/math&gt;

These satisfy&lt;ref name="BD"/&gt; 
:&lt;math&gt;\,i \Delta = \Delta_+ - \Delta_-&lt;/math&gt;

and
:&lt;math&gt;(\Box_x + m^2) \Delta_{\pm}(x-y) = 0.&lt;/math&gt;

====Auxiliary function====
The anti-commutator of two scalar field operators defines &lt;math&gt;\Delta_1(x-y)&lt;/math&gt; function by
:&lt;math&gt;\langle 0 | \left\{ \Phi(x),\Phi(y) \right\} | 0 \rangle = \Delta_1(x-y)&lt;/math&gt;
with
:&lt;math&gt;\,\Delta_1(x-y) = \Delta_+ (x-y) + \Delta_-(x-y).&lt;/math&gt;

This satisfies &lt;math&gt;\,\Delta_1(x-y) = \Delta_1(y-x).&lt;/math&gt;

===Green's functions for the Klein–Gordon equation===
The retarded, advanced and Feynman propagators defined above are all Green's functions for the Klein–Gordon equation.

They are related to the singular functions by&lt;ref name="BD"/&gt;
:&lt;math&gt;G_\text{ret}(x-y) = -\Delta(x-y) \Theta(x_0-y_0) &lt;/math&gt;
:&lt;math&gt;G_\text{adv}(x-y) = \Delta(x-y) \Theta(y_0-x_0) &lt;/math&gt;
:&lt;math&gt;2 G_F(x-y) = -i \,\Delta_1(x-y) + \varepsilon(x_0 - y_0) \,\Delta(x-y) &lt;/math&gt;
where 
:&lt;math&gt;\,\varepsilon(x_0-y_0) = 2 \Theta(x_0-y_0) - 1.&lt;/math&gt;

==Notes==
{{reflist}}

==References==
*{{cite book|ref=harv|last1=Bjorken|first1=J.|authorlink1=James Bjorken|last2=Drell|first2=S.|authorlink2=Sidney Drell|title=Relativistic Quantum Fields|location=New York|publisher=[[McGraw-Hill]]|year=1965|isbn=0-07-005494-0}} (Appendix C.)
*{{cite book|ref=harv|last1=Bogoliubov|first1=N.|authorlink1=Nikolay Bogolyubov|last2=Shirkov|first2=D. V.|authorlink2=Dmitry Shirkov|title=Introduction to the theory of quantized fields|publisher=[[Wiley-Interscience]]|isbn=0-470-08613-0}} (Especially pp.&amp;nbsp;136–156 and Appendix A)
*{{cite book|editor-last1=DeWitt-Morette|editor-first1=C.|editor-link1=Cécile DeWitt-Morette|editor-last2=DeWitt|editor-first2=B.|editor-link2=Bryce DeWitt|title=Relativity, Groups and Topology|publisher=[[Blackie and Son]]|location=Glasgow|isbn=0-444-86858-5}} (section Dynamical Theory of Groups &amp; Fields, Especially pp.&amp;nbsp;615–624)
*{{cite book|ref=harv|title=Quantum Electrodynamics|first1=W.|last1=Greiner|authorlink1=Walter Greiner|first2=J.|last2=Reinhardt|edition=4th|year=2008|isbn=9783540875604|publisher=[[Springer Verlag]]|url=https://books.google.com/books?id=5Kd3dBL8a64C&amp;printsec=frontcover&amp;dq=walter+greiner+Quantum+electrodynamics&amp;hl=en&amp;sa=X&amp;ei=BhVPVZzrNsj6UJKwgMgN&amp;ved=0CCIQ6wEwAA#v=onepage&amp;q=walter%20greiner%20Quantum%20electrodynamics&amp;f=false}}
*{{cite book|ref=harv|title=Field Quantization|first1=W.|last1=Greiner|first2=J.|last2=Reinhardt|year=1996|isbn=9783540591795|publisher=Springer Verlag|url=https://books.google.com/books?id=VvBAvf0wSrIC&amp;printsec=frontcover&amp;dq=walter+greiner+Classical+Mechanics:+Point+Particles+and+Relativity&amp;hl=en&amp;sa=X&amp;ei=phZPVfD-KIf3UqCpgdAG&amp;ved=0CEQQ6wEwBQ#v=onepage&amp;q&amp;f=false}}
*{{cite book|ref=harv|last=Griffiths|first=D. J.|title=Introduction to Elementary Particles|location=New York|publisher=[[John Wiley &amp; Sons]]|year=1987|isbn=0-471-60386-4}}
*{{cite book|ref=harv|last=Griffiths|first=D. J.|title=Introduction to Quantum Mechanics|location=Upper Saddle River|publisher=[[Prentice Hall]]|year=2004|isbn=0-131-11892-7}}
*{{citation|last1=Halliwell|first1=J.J.|last2=Orwitz|first2=M.|title=Sum-over-histories origin of the composition laws of relativistic quantum mechanics and quantum cosmology|arxiv=gr-qc/9211004|bibcode = 1993PhRvD..48..748H |doi = 10.1103/PhysRevD.48.748 }}
*{{cite book|ref=harv|last=Huang|first=Kerson|authorlink=Kerson Huang|title=Quantum Field Theory: From Operators to Path Integrals|location=New York|publisher=John Wiley &amp; Sons|year=1998|isbn=0-471-14120-8}}
*{{cite book|last1=Itzykson|first1=C.|last2=Zuber|first2=J-B.|title=Quantum Field Theory|location=New York|publisher=McGraw-Hill|year=1980|isbn=0-07-032071-3}}
*{{cite book|ref=harv|last=Pokorski|first=S.|title=Gauge Field Theories|location=Cambridge|publisher=[[Cambridge University Press]]|year=1987|isbn=0-521-36846-4}}  ''(Has useful appendices of Feynman diagram rules, including propagators, in the back.)''
*{{cite book|ref=harv|last=Schulman|first=L. S.|title=Techniques &amp; Applications of Path Integration|publisher=John Wiley &amp; Sons|location=New York|year=1981|isbn=0-471-76450-7}}
*Scharf, G. (1995). ''Finite Quantum Electrodynamics, The Casual Approach.'' Springer. {{ISBN|978-3-642-63345-4}}.

== External links ==
* [https://arxiv.org/abs/quant-ph/0205085 Three Methods for Computing the Feynman Propagator]

[[Category:Quantum mechanics]]
[[Category:Quantum field theory]]
[[Category:Theoretical physics]]
[[Category:Mathematical physics]]</text>
      <sha1>oufk66g4ufk55idj6xyf5qpz1s5bjri</sha1>
    </revision>
  </page>
  <page>
    <title>Radius of curvature</title>
    <ns>0</ns>
    <id>18421631</id>
    <revision>
      <id>866612957</id>
      <parentid>863809928</parentid>
      <timestamp>2018-10-31T12:27:41Z</timestamp>
      <contributor>
        <ip>2405:204:A41E:2635:803B:1978:6742:1731</ip>
      </contributor>
      <comment>/* Formula */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11009">{{about|the general mathematical concept|its optical applications|Radius of curvature (optics)}}
[[File:Radius of curvature.svg|thumb|400px|Radius of curvature and [[center of curvature]]]]

In [[differential geometry]], the '''radius of curvature''', {{mvar|R}}, is the reciprocal of the [[curvature]]. For a [[curve]], it equals the [[radius]] of the [[circular arc]] which best approximates the curve at that point. For [[surface (mathematics)|surface]]s, the radius of curvature is the radius of a circle that best fits a [[normal section]] or [[Earth radius#Combinations|combinations]] thereof.&lt;ref&gt;{{Cite web|url=http://mathworld.wolfram.com/RadiusofCurvature.html|title=Radius of Curvature|last=Weisstien|first=Eric|date=|website=Wolfram Mathworld|publisher=|access-date=15 August 2016}}&lt;/ref&gt;&lt;ref name=":0"&gt;{{Cite book|url=https://books.google.com.ph/books?redir_esc=y&amp;id=90mk7qPAvb4C&amp;q=radius+of+curvature#v=snippet&amp;q=page%20210&amp;f=false|title=Differential Calculus|last=Kishan|first=Hari|date=2007|publisher=Atlantic Publishers &amp; Dist|isbn=9788126908202|language=en}}&lt;/ref&gt;&lt;ref name=":1"&gt;{{Cite book|url=https://books.google.com.ph/books/about/Differential_and_Integral_Calculus_Sixth.html?id=QxkUMwEACAAJ&amp;redir_esc=y|title=Differential and Integral Calculus. Sixth Edition|last=David))|first=Clyde Elton LOVE (and RAINVILLE (Earl|date=1962|publisher=New York|language=en}}&lt;/ref&gt;

==Definition==
In the case of a [[space curve]], the radius of curvature is the length of the [[curvature vector]].

In the case of a [[plane curve]], then {{mvar|R}} is the [[absolute value]] of&lt;ref name=":1" /&gt;

: &lt;math&gt;R \equiv \left|\frac{ds}{d\varphi} \right| = \frac{1}{\kappa},&lt;/math&gt;

where {{mvar|s}} is the arc length from a fixed point on the curve, {{mvar|φ}} is the [[tangential angle]] and {{mvar|κ}} is the [[curvature#Curvature|curvature]].

If the curve is given in [[Cartesian coordinates]] as {{math|''y''(''x'')}}, then the radius of curvature is (assuming the curve is differentiable up to order 2):

: &lt;math&gt;R =\left| \frac { \left(1 + y'^{\,2}\right)^\frac32}{y''}\right|, \qquad\mbox{where}\quad y' = \frac{dy}{dx},\quad y'' = \frac{d^2y}{dx^2},&lt;/math&gt; 
and {{math|{{abs|''z''}}}} denotes the absolute value of {{mvar|z}}.

If the curve is given [[parametric equation|parametrically]] by functions {{math|''x''(''t'')}} and {{math|''y''(''t'')}}, then the radius of curvature is
:&lt;math&gt;R = \left|\frac{ds}{d\varphi}\right| = \left|\frac {\left({\dot{x}^2 + \dot{y}^2}\right)^\frac32}{\dot {x}\ddot{y} - \dot{y}\ddot{x}}\right|, \qquad\mbox{where}\quad \dot{x} = \frac{dx}{dt},\quad\ddot{x} = \frac{d^2x}{dt^2},\quad \dot{y} = \frac{dy}{dt},\quad\ddot{y} = \frac{d^2y}{dt^2}.&lt;/math&gt;

Heuristically, this result can be interpreted as&lt;ref name=":0" /&gt;

:&lt;math&gt; R = \frac{\left|\mathbf{v}\right|^3}{\left| \mathbf{v} \times \mathbf{ \dot v} \right|}, \qquad\mbox{where}\quad \left| \mathbf{v} \right| = \big| (\dot x, \dot y) \big| = R \frac{d\varphi}{dt}.&lt;/math&gt;

==Formula==

If {{math|'''y''' : ℝ → ℝ&lt;sup&gt;''n''&lt;/sup&gt;}} is a parametrized curve in {{math|ℝ&lt;sup&gt;''n''&lt;/sup&gt;}} then the radius of curvature at each point of the curve, {{math|''ρ'' : ℝ → ℝ}}, is given by&lt;ref name=":1" /&gt;

:&lt;math&gt;\rho = \frac{\left|\boldsymbol\gamma'\right|^3}{\sqrt{\left|\boldsymbol\gamma'\right|^2 \, \left|\boldsymbol\gamma''\right|^2 - \left(\boldsymbol\gamma' \cdot \boldsymbol\gamma''\right)^2}}&lt;/math&gt;.

As a special case, if {{math|''f''(''t'')}} is a function from {{math|ℝ}} to {{math|ℝ}}, then the radius of curvature of its [[graph of a function|graph]], {{math|'''γ'''(''t'') {{=}} (''t'', ''f''(''t''))}}, is

:&lt;math&gt;\rho(t)=\frac{\left|1+f'^{\,2}(t)\right|^\frac32}{\left|f''(t)\right|}.&lt;/math&gt;

===Derivation===

Let {{math|'''γ'''}} be as above, and fix {{mvar|t}}. We want to find the radius {{mvar|ρ}} of a parametrized circle which matches {{math|γ}} in its zeroth, first, and second derivatives at {{mvar|t}}. Clearly the radius will not depend on the position {{math|'''γ'''(''t'')}}, only on the velocity {{math|'''γ'''′(''t'')}} and acceleration {{math|'''γ'''″(''t'')}}. There are only three independent [[scalar product|scalars]] that can be obtained from two vectors {{math|'''v'''}} and {{math|'''w'''}}, namely {{math|'''v''' · '''v'''}}, {{math|'''v''' · '''w'''}}, and {{math|'''w''' · '''w'''}}. Thus the radius of curvature must be a function of the three scalars {{math|{{abs|'''γ'''′{{isup|2}}(''t'')}}}}, {{math|{{abs|'''γ'''″{{isup|2}}(''t'')}}}} and {{math|'''γ'''′(''t'') · '''γ'''″(''t'')}}.&lt;ref name=":1" /&gt;

The general equation for a parametrized circle in {{math|ℝ&lt;sup&gt;''n''&lt;/sup&gt;}} is
:&lt;math&gt;\mathbf{g}(u) = \mathbf a \cos h(u) + \mathbf b \sin h(u) + \mathbf c&lt;/math&gt;
where {{math|'''c''' ∈ ℝ&lt;sup&gt;''n''&lt;/sup&gt;}} is the center of the circle (irrelevant since it disappears in the derivatives), {{math|'''a''','''b''' ∈ ℝ&lt;sup&gt;''n''&lt;/sup&gt;}} are perpendicular vectors of length {{mvar|ρ}} (that is, {{math|'''a''' · '''a''' {{=}} '''b''' · '''b''' {{=}} ''ρ''{{isup|2}}&lt;sup&gt;&lt;/sup&gt;}} and {{math|'''a''' · '''b''' {{=}} 0}}), and {{math|''h'' : ℝ → ℝ}} is an arbitrary function which is twice differentiable at {{mvar|t}}.

The relevant derivatives of {{math|'''g'''}} work out to be
:&lt;math&gt;\begin{align}
|\mathbf g'|^2 &amp;= \rho^2 (h')^2 \\
\mathbf g' \cdot \mathbf g'' &amp;= \rho^2 h' h'' \\
|\mathbf g''|^2 &amp;= \rho^2 \left((h')^4 + (h'')^2 \right)
\end{align}&lt;/math&gt;

If we now equate these derivatives of {{math|'''g'''}} to the corresponding derivatives of {{math|'''γ'''}} at {{mvar|t}} we obtain

:&lt;math&gt;\begin{align}
|\boldsymbol\gamma'^{\,2}(t)| &amp;= \rho^2 h'^{\,2}(t) \\
\boldsymbol\gamma'(t) \cdot \boldsymbol\gamma''(t) &amp;= \rho^2 h'(t) h''(t) \\
|\boldsymbol\gamma''^{\,2}(t)| &amp;= \rho^2 \left(h'^{\,4}(t) + h''^{\,2}(t)\right)
\end{align}&lt;/math&gt;

These three equations in three unknowns ({{mvar|ρ}}, {{math|''h''′(''t'')}} and {{math|''h''″(''t'')}}) can be solved for {{mvar|ρ}}, giving the formula for the radius of curvature:

:&lt;math&gt;\rho(t) = \frac{\left|\boldsymbol\gamma'^{\,3}(t)\right|}{\sqrt{\left|\boldsymbol\gamma'^{\,2}(t)\right| \, \left|\boldsymbol\gamma''^{\,2}(t)\right| - \big(\boldsymbol\gamma'(t) \cdot \boldsymbol\gamma''(t)\big)^2}}&lt;/math&gt;

or, omitting the parameter {{mvar|t}} for readability,

:&lt;math&gt;\rho = \frac{\left|\boldsymbol\gamma'\right|^3}{\sqrt{\left|\boldsymbol\gamma'\right|^2 \; \left|\boldsymbol\gamma''\right|^2 - \left(\boldsymbol\gamma' \cdot \boldsymbol\gamma''\right)^2}}.&lt;/math&gt;

==Examples==

===Semicircles and circles===

For a [[semi-circle]] of radius {{mvar|a}} in the upper half-plane
:&lt;math&gt;y=\sqrt{a^2-x^2}, \quad y'=\frac{-x}{\sqrt{a^2-x^2}}, \quad y''=\frac{-a^2}{\left(a^2-x^2\right)^\frac32},\quad R=|-a| =a.&lt;/math&gt;

[[Image:Ellipse evolute.svg|right|thumb|240px|An ellipse (red) and its [[evolute]] (blue). The dots are the vertices of the ellipse, at the points of greatest and least curvature.]]

For a semi-circle  of radius {{mvar|a}} in the lower half-plane
:&lt;math&gt; y=-\sqrt{a^2-x^2}, \quad R=|a|=a.&lt;/math&gt;

The [[circle]] of radius {{mvar|a}} has a radius of curvature equal to {{mvar|a}}.

===Ellipses===

In an [[ellipse]] with major axis {{math|2''a''}} and minor axis {{math|2''b''}}, the [[Vertex (curve)|vertices]] on the major axis have the smallest radius of curvature of any points, {{math|''R'' {{=}} {{sfrac|''b''&lt;sup&gt;2&lt;/sup&gt;|''a''}}}}; and the vertices on the minor axis have the largest radius of curvature of any points, {{math|''R'' {{=}} {{sfrac|''a''&lt;sup&gt;2&lt;/sup&gt;|''b''}}}}.

==Applications==
*For the use in [[differential geometry]], see [[Cesàro equation]].
*For the radius of curvature of the earth (approximated by an oblate ellipsoid), see [[Earth radius#Radii of curvature|Radius of curvature of the earth]].
*Radius of curvature is also used in a three part equation for bending of [[Beam (structure)|beams]].
*[[Radius of curvature (optics)]]

===Stress in semiconductor structures===
Stress in the semiconductor structure involving evaporated thin films usually results from the thermal expansion (thermal stress) during the manufacturing process.  Thermal stress occurs because film depositions are usually made above room temperature. Upon cooling from the deposition temperature to room temperature, the difference in the thermal expansion coefficients of the substrate and the film cause thermal stress.&lt;ref&gt;{{cite web|url=http://flipchips.com/tutorial/process/controlling-stress-in-thin-films/ |title=Controlling Stress in Thin Films |website=Flipchips.com |date= |accessdate=2016-04-22}}&lt;/ref&gt;

Intrinsic stress results from the microstructure created in the film as atoms are deposited on the substrate. Tensile stress results from microvoids in the thin film, because of the attractive interaction of atoms across the voids.

The stress in thin film semiconductor structures results in the buckling of the wafers. The radius of the curvature of the stressed structure is related to stress tensor in the structure, and can be described by modified Stoney formula.&lt;ref&gt;{{cite web|url=http://www.qucosa.de/fileadmin/data/qucosa/documents/5126/data/Stoney.pdf |format=PDF |title=On the determination of film stress from substrate bending : Stoney's formula and its limits |website=Qucosa.de |accessdate=2016-04-22}}&lt;/ref&gt; The topography of the stressed structure including radii of curvature can be measured using optical scanner methods. The modern scanner tools have capability to measure full topography of the substrate and to measure both principal radii of curvature, while providing the accuracy of the order of 0.1% for radii of curvature of 90 meters and more.&lt;ref&gt;{{cite web|author=Peter Walecki |url=http://www.zebraoptical.com/ModelX.html |title=Model X |publisher=Zebraoptical.com |date= |accessdate=2016-04-22}}&lt;/ref&gt;

==See also==
{{div col|colwidth=30em}}
*[[AFM probe]]
*[[Base curve radius]]
*[[Bend radius]]
*[[Curve]]
*[[Curvature]]
*[[Degree of curvature]] (civil engineering)
*[[Diameter]]
*[[Minimum railway curve radius]]
*[[Osculating circle]]
*[[Reverse curve]]
*[[Track transition curve]]
*[[Transition curve]]
{{div col end}}

==References==
{{Reflist}}

==Further reading==
* {{cite book |title = Differential Geometry of Curves and Surfaces|first = Manfredo|last = do Carmo|authorlink=Manfredo do Carmo | isbn = 0-13-212589-7 | year = 1976}}

==External links==
* [http://www.geom.uiuc.edu/zoo/diffgeom/surfspace/concepts/curvatures/prin-curv.html The Geometry Center: Principal Curvatures]
* [http://math.mit.edu/classes/18.013A/HTML/chapter15/section03.html 15.3 Curvature and Radius of Curvature]
* {{MathWorld |title=Principal Curvatures |urlname=PrincipalCurvatures }}
* {{MathWorld |title=Principal Radius of Curvature |urlname=PrincipalRadiusofCurvature }}

{{curvature}}

[[Category:Differential geometry]]
[[Category:Curvature (mathematics)]]
[[Category:Curves]]
[[Category:Integral calculus]]
[[Category:Multivariable calculus]]
[[Category:Theoretical physics]]</text>
      <sha1>2hq2wz0z617eh0kbvpd2uuak95gc9kg</sha1>
    </revision>
  </page>
  <page>
    <title>Recursive language</title>
    <ns>0</ns>
    <id>23290990</id>
    <revision>
      <id>858280361</id>
      <parentid>846349574</parentid>
      <timestamp>2018-09-06T02:46:10Z</timestamp>
      <contributor>
        <username>Shenme</username>
        <id>101696</id>
      </contributor>
      <minor/>
      <comment>not a typo|aaabbbccc</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6565">{{About|a class of formal languages as they are studied in mathematics and theoretical computer science|computer languages that allow a function to call itself recursively  |Recursion (computer science)}}

In [[mathematics]], [[logic]] and [[computer science]], a [[formal language]] (a [[set (mathematics)|set]] of finite sequences of [[symbol (formal)|symbol]]s taken from a fixed [[alphabet (computer science)|alphabet]]) is called '''recursive''' if it is a [[recursive set|recursive subset]] of the set of all possible finite sequences over the alphabet of the language. Equivalently, a formal language is recursive if there exists a [[total Turing machine]] (a [[Turing machine]] that halts for every given input) that, when given a finite sequence of symbols as input, accepts it if it belongs to the language and rejects it otherwise. Recursive languages are also called '''decidable'''.

The concept of '''decidability''' may be extended to other [[models of computation]]. For example one may speak of languages decidable on a [[non-deterministic Turing machine]].  Therefore, whenever an ambiguity is possible, the synonym for "recursive language" used is '''Turing-decidable language''', rather than simply ''decidable''.

The class of all recursive languages is often called '''[[R (complexity)|R]]''', although this name is also used for the class [[RP (complexity)|RP]].

This type of language was not defined in the [[Chomsky hierarchy]] of {{Harv|Chomsky|1959}}. All recursive languages are also [[recursively enumerable language|recursively enumerable]]. All [[regular language|regular]], [[context-free language|context-free]] and [[context-sensitive language|context-sensitive]] languages are recursive.

== Definitions ==

There are two equivalent major definitions for the concept of a recursive language:

# A recursive formal language is a [[recursive set|recursive]] [[subset]] in the [[set (mathematics)|set]] of all possible words over the [[alphabet]] of the [[formal language|language]].
# A recursive language is a formal language for which there exists a [[Turing machine]] that, when presented with any finite input [[literal string|string]], halts and accepts if the string is in the language, and halts and rejects otherwise. The Turing machine always halts: it is known as a [[Machine that always halts|decider]] and is said to ''decide'' the recursive language.

By the second definition, any [[decision problem]] can be shown to be decidable by exhibiting an [[algorithm]] for it that terminates on all inputs. An [[undecidable problem]] is a problem that is not decidable.

== Examples ==

As noted above, every context-sensitive language is recursive. Thus, a simple example of a recursive language is the set ''L={abc, {{not a typo|aabbcc}}, {{not a typo|aaabbbccc}}, ...}'';
more formally, the set
: &lt;math&gt;L=\{\,w \in \{a,b,c\}^* \mid w=a^nb^nc^n \mbox{ for some } n\ge 1 \,\}&lt;/math&gt; 
is context-sensitive and therefore recursive.

Examples of decidable languages that are not context-sensitive are more difficult to describe. For one such example, some familiarity with [[mathematical logic]] is required: [[Presburger arithmetic]] is the first-order theory of the natural numbers with addition (but without multiplication). While the set of [[First-order_logic#Formulas|well-formed formulas]] in Presburger arithmetic is context-free, every deterministic Turing machine accepting the set of true statements in Presburger arithmetic has a worst-case runtime of at least &lt;math&gt;2^{2^{cn}}&lt;/math&gt;, for some constant ''c''&gt;0 {{harv|Fischer|Rabin|1974}}. Here, ''n'' denotes the length of the given formula. Since every context-sensitive language can be accepted by a [[linear bounded automaton]], and such an automaton can be simulated by a deterministic Turing machine with worst-case running time at most &lt;math&gt;c^n&lt;/math&gt; for some constant ''c'' {{citation needed|date=March 2015}}, the set of valid formulas in Presburger arithmetic is not context-sensitive. On positive side, it is known that there is a deterministic Turing machine running in time at most triply exponential in ''n'' that decides the set of true formulas in Presburger arithmetic {{harv|Oppen|1978}}. Thus, this is an example of a language that is decidable but not context-sensitive.

== Closure properties ==

Recursive languages are [[closure (mathematics)|closed]] under the following operations. That is, if ''L'' and ''P'' are two recursive languages, then the following languages are recursive as well:
* The [[Kleene star]] &lt;math&gt;L^*&lt;/math&gt;
* The image φ(L) under an [[Homomorphism#Formal language theory|e-free homomorphism]] φ
* The concatenation &lt;math&gt;L \circ P&lt;/math&gt;
* The union &lt;math&gt;L \cup P&lt;/math&gt;
* The intersection &lt;math&gt;L \cap P&lt;/math&gt;
* The complement of &lt;math&gt;L&lt;/math&gt;
* The set difference &lt;math&gt;L - P&lt;/math&gt;

The last property follows from the fact that the set difference can be expressed in terms of intersection and complement.

== See also ==
*[[Recursively enumerable language]]
*[[Recursion]]

== References ==
* {{Cite book|author = [[Michael Sipser]] | year = 1997 | title = Introduction to the Theory of Computation | publisher = PWS Publishing | chapter = Decidability | pages = 151–170 | isbn = 0-534-94728-X|ref = harv|postscript = &lt;!--None--&gt;}}
* {{cite journal | last = Chomsky | first = Noam | year = 1959 | title = On certain formal properties of grammars | journal = Information and Control | volume = 2 | issue = 2 | pages = 137–167 | doi = 10.1016/S0019-9958(59)90362-6 | ref = harv}}
* {{cite journal | first1=Michael J. | last1=Fischer | authorlink1=Michael J. Fischer | first2=Michael O. | last2=Rabin | authorlink2=Michael O. Rabin | date=1974 | title=Super-Exponential Complexity of Presburger Arithmetic | url=http://www.lcs.mit.edu/publications/pubs/ps/MIT-LCS-TM-043.ps | journal=Proceedings of the SIAM-AMS Symposium in Applied Mathematics | volume=7 | pages=27–41 | ref=harv }}
*{{cite journal | last1 = Oppen | first1 = Derek C. | year = 1978 | title = A 2&lt;sup&gt;2&lt;sup&gt;2&lt;sup&gt;''pn''&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt; Upper Bound on the Complexity of Presburger Arithmetic | url = http://www.sciencedirect.com/science/article/pii/0022000078900211/pdf?md5=0415089a2d692fcece18b43b5f63c67d&amp;pid=1-s2.0-0022000078900211-main.pdf | format = PDF | journal = J. Comput. Syst. Sci. | volume = 16 | issue = 3| pages = 323–332 | doi = 10.1016/0022-0000(78)90021-1 }}
{{Formal languages and grammars}}

[[Category:Computability theory]]
[[Category:Formal languages]]
[[Category:Theory of computation]]
[[Category:Recursion]]</text>
      <sha1>thjkn0ce6cyiefckhfgswn3q5lcat49</sha1>
    </revision>
  </page>
  <page>
    <title>Refinement (category theory)</title>
    <ns>0</ns>
    <id>56509649</id>
    <revision>
      <id>832078611</id>
      <parentid>831941942</parentid>
      <timestamp>2018-03-23T18:11:18Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5371">In [[category theory]] and related fields of mathematics, a '''refinement''' is a construction that generalizes the operations of "interior enrichment", like bornologification or saturation of a locally convex space. A dual construction is called [[Envelope (category theory)|envelope]]. 

== Definition ==

Suppose &lt;math&gt;K&lt;/math&gt; is a category, &lt;math&gt;X&lt;/math&gt; an object in &lt;math&gt;K&lt;/math&gt;, and &lt;math&gt;\Gamma&lt;/math&gt; and &lt;math&gt;\Phi&lt;/math&gt; two classes of morphisms in &lt;math&gt;K&lt;/math&gt;. The definition{{sfn|Akbarov|2016|p=52}} of a refinement of &lt;math&gt;X&lt;/math&gt; in the class &lt;math&gt;\Gamma&lt;/math&gt; by means of the class &lt;math&gt;\Phi&lt;/math&gt; consists of two steps.
[[File:Enrichment-2.jpg|thumb|Enrichment]]

* A morphism &lt;math&gt;\sigma:X'\to X&lt;/math&gt; in &lt;math&gt;K&lt;/math&gt; is called an ''enrichment of the object &lt;math&gt;X&lt;/math&gt; in the class of morphisms &lt;math&gt;\Gamma&lt;/math&gt; by means of the class of morphisms &lt;math&gt;\Phi&lt;/math&gt;'', if &lt;math&gt;\sigma\in\Gamma&lt;/math&gt;, and for any morphism &lt;math&gt;\varphi:B\to X&lt;/math&gt; from the class &lt;math&gt;\Phi&lt;/math&gt; there exists a unique morphism &lt;math&gt;\varphi':B\to X'&lt;/math&gt; in &lt;math&gt;K&lt;/math&gt; such that &lt;math&gt;\varphi=\sigma\circ\varphi'&lt;/math&gt;.
[[File:Refinement.jpg|thumb|Refinement]]
 
* An enrichment &lt;math&gt;\rho:E\to X&lt;/math&gt; of the object &lt;math&gt;X&lt;/math&gt; in the class of morphisms &lt;math&gt;\Gamma&lt;/math&gt; by means of the class of morphisms &lt;math&gt;\Phi&lt;/math&gt; is called a ''refinement of &lt;math&gt;X&lt;/math&gt; in &lt;math&gt;\Gamma&lt;/math&gt; by means of &lt;math&gt;\Phi&lt;/math&gt;'', if for any other enrichment &lt;math&gt;\sigma:X'\to X&lt;/math&gt; (of &lt;math&gt;X&lt;/math&gt; in &lt;math&gt;\Gamma&lt;/math&gt; by means of &lt;math&gt;\Phi&lt;/math&gt;) there is a unique morphism &lt;math&gt;\upsilon:E\to X'&lt;/math&gt; in &lt;math&gt;K&lt;/math&gt; such that &lt;math&gt;\rho=\sigma\circ\upsilon&lt;/math&gt;. The object &lt;math&gt;E&lt;/math&gt; is also called a ''refinement of &lt;math&gt;X&lt;/math&gt; in &lt;math&gt;\Gamma&lt;/math&gt; by means of &lt;math&gt;\Phi&lt;/math&gt;''.
 
Notations:

: &lt;math&gt;
\rho=\operatorname{ref}_\Phi^\Gamma X, \qquad 
E=\operatorname{Ref}_\Phi^\Gamma X.
&lt;/math&gt;

In a special case when &lt;math&gt;\Gamma&lt;/math&gt; is a class of all morphisms whose ranges belong to a given class of objects &lt;math&gt;L&lt;/math&gt; in &lt;math&gt;K&lt;/math&gt; it is convenient to replace &lt;math&gt;\Gamma&lt;/math&gt; with &lt;math&gt;L&lt;/math&gt; in the notations (and in the terms):
 
: &lt;math&gt;
\rho=\operatorname{ref}_\Phi^L X, \qquad 
E=\operatorname{Ref}_\Phi^L X.
&lt;/math&gt;

Similarly, if &lt;math&gt;\Phi&lt;/math&gt; is a class of all morphisms whose ranges belong to a given class of objects &lt;math&gt;M&lt;/math&gt; in &lt;math&gt;K&lt;/math&gt; it is convenient to replace &lt;math&gt;\Phi&lt;/math&gt; with &lt;math&gt;M&lt;/math&gt; in the notations (and in the terms):
 
: &lt;math&gt;
\rho=\operatorname{ref}_M^\Gamma X, \qquad 
E=\operatorname{Ref}_M^\Gamma X.
&lt;/math&gt;

For example, one can speak about a ''refinement of &lt;math&gt;X&lt;/math&gt; in the class of objects &lt;math&gt;L&lt;/math&gt; by means of the class of objects &lt;math&gt;M&lt;/math&gt;'':

: &lt;math&gt;
\rho=\operatorname{ref}_M^L X, \qquad 
E=\operatorname{Ref}_M^L X.
&lt;/math&gt;

== Examples ==

# The '''bornologification'''{{sfn|Kriegl|Michor|1997|p=35}}{{sfn|Akbarov|2016|p=57}}  &lt;math&gt;X_{\operatorname{born}}&lt;/math&gt; of a [[locally convex space]] &lt;math&gt;X&lt;/math&gt; is a refinement of &lt;math&gt;X&lt;/math&gt; in the category &lt;math&gt;\operatorname{LCS}&lt;/math&gt; of locally convex spaces by means of the subcategory &lt;math&gt;\operatorname{Norm}&lt;/math&gt; of [[normed space]]s: &lt;math&gt;X_{\operatorname{born}}=\operatorname{Ref}_{\operatorname{Norm}}^{\operatorname{LCS}}X&lt;/math&gt;
# The '''saturation'''{{sfn|Akbarov|2003|p=194}}{{sfn|Akbarov|2016|p=57}} &lt;math&gt;X^\blacktriangle&lt;/math&gt; of a pseudocomplete&lt;ref&gt;A [[topological vector space]] &lt;math&gt;X&lt;/math&gt; is said to be ''pseudocomplete'' if each [[Totally bounded set|totally bounded]] [[Net (mathematics)#Cauchy nets|Cauchy net]] in &lt;math&gt;X&lt;/math&gt; converges.&lt;/ref&gt; [[locally convex space]] &lt;math&gt;X&lt;/math&gt; is a refinement in the category &lt;math&gt;\operatorname{LCS}&lt;/math&gt; of locally convex spaces by means of the subcategory &lt;math&gt;\operatorname{Smi}&lt;/math&gt; of the [[Smith space]]s: &lt;math&gt;X^\blacktriangle=\operatorname{Ref}_{\operatorname{Smi}}^{\operatorname{LCS}}X&lt;/math&gt;

==See also==
*[[Envelope (category theory)|Envelope]]

==Notes==
{{reflist}}

== References ==
&lt;!-- Inline citations added to your article will automatically display here. See https://en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. --&gt;

* {{cite book |last=Kriegl |first=A. | last2=Michor |first2=P.W. |date= 1997 |title= The convenient setting of global analysis |url= https://bookstore.ams.org/surv-53 |location= Providence, Rhode Island |publisher= American Mathematical Society |isbn=0-8218-0780-3| ref = harv}}

*{{cite journal|last=Akbarov|first=S.S.|title=Pontryagin duality in the theory of topological vector spaces and in topological algebra|journal=Journal of Mathematical Sciences|year=2003|volume=113|issue=2|pages=179–349|doi=10.1023/A:1020929201133|url=http://www.springerlink.com/content/k62m72960101g6q2/| ref = harv}}

*{{cite journal|last=Akbarov|first=S.S.|title=Envelopes and refinements in categories, with applications to functional analysis|url=https://www.impan.pl/en/publishing-house/journals-and-series/dissertationes-mathematicae/all/513|journal=Dissertationes Mathematicae|year=2016|volume=513|pages=1–188|arxiv=1110.2013|doi=10.4064/dm702-12-2015| ref = harv}}

{{Functional Analysis}}
{{Category theory}}

[[Category:Category theory]]
[[Category:Duality theories]]
[[Category:Functional analysis]]</text>
      <sha1>7ferpm7nke5ifiqly9v13cgxypzu5p1</sha1>
    </revision>
  </page>
  <page>
    <title>RiskMetrics</title>
    <ns>0</ns>
    <id>8304736</id>
    <revision>
      <id>866803923</id>
      <parentid>840569961</parentid>
      <timestamp>2018-11-01T17:23:57Z</timestamp>
      <contributor>
        <username>Hgrunditz</username>
        <id>35026718</id>
      </contributor>
      <comment>added a reference for the MSCI acquisition</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11753">{{distinguish |text= [[risk metric]], the abstract concept quantified by [[risk measure]]s}}
{{Multiple issues|
{{refimprove|date=June 2007}}
{{notability|date=April 2012}}
}}

The '''RiskMetrics''' [[variance]] [[Statistical model|model]] (also known as '''exponential smoother''') was first established in 1989, when Sir [[Dennis Weatherstone]], the new chairman of [[J.P. Morgan &amp; Co.|J.P. Morgan]], asked for a daily report measuring and explaining the risks of his firm. Nearly four years later in 1992, J.P. Morgan launched the RiskMetrics methodology to the [[marketplace]], making the substantive research and analysis that satisfied Sir Dennis Weatherstone's request freely available to all market participants.

In 1998, as client demand for the group's [[risk management]] expertise exceeded the firm's internal risk management resources, the Corporate Risk Management Department was spun off from J.P. Morgan as RiskMetrics Group with 23 founding employees. The RiskMetrics technical document was revised in 1996. In 2001, it was revised again in ''Return to RiskMetrics''. In 2006, a new method for modeling risk factor returns was introduced (RM2006). On 25 January 2008, RiskMetrics Group listed on the New York Stock Exchange ([[NYSE]]: RISK). In June 2010, RiskMetrics was acquired by [[MSCI]] for $1.55 billion.&lt;ref&gt;{{Cite news|url=https://www.reuters.com/article/us-riskmetrics-msci-idUSTRE62041J20100301|title=MSCI to buy RiskMetrics for $1.55 billion|last=|first=|date=March 1, 2010|work=Reuters|access-date=November 1, 2018}}&lt;/ref&gt;

==Risk measurement process==
Portfolio '''risk measurement''' can be broken down into steps. The first is modeling the market that drives changes in the portfolio's value. The market model must be sufficiently specified so that the portfolio can be revalued using information from the market model. The risk measurements are then extracted from the probability distribution of the changes in portfolio value. The change in value of the portfolio is typically referred to by portfolio managers as profit and loss, or P&amp;L

==Risk factors==
Risk management systems are based on models that describe potential changes in the factors affecting portfolio value. These '''risk factors''' are the building blocks for all pricing functions. In general, the factors driving the prices of financial securities are '''equity prices''', '''foreign exchange rates''', '''commodity prices''', '''interest rates''', [[correlation]] and [[Volatility (finance)|volatility]]. By generating future scenarios for each risk factor, we can infer changes in portfolio value and reprice the portfolio for different "states of the world".

==Portfolio risk measures==

===Standard deviation===

The first widely used portfolio risk measure was the '''[[standard deviation]]''' of portfolio value, as described by [[Harry Markowitz]]. While comparatively easy to calculate, standard deviation is not an ideal risk measure since it penalizes profits as well as losses.

===Value at risk===

The 1994 tech doc popularized '''[[Value at risk|VaR]]''' as the risk measure of choice among investment banks looking to be able to measure their portfolio risk for the benefit of banking regulators. VaR is a [[downside risk]] measure, meaning that it typically focuses on losses.

===Expected shortfall===

A third commonly used risk measure is '''[[expected shortfall]]''', also known variously as expected tail loss, XLoss, conditional VaR, or CVaR.

===Marginal VaR===

The '''Marginal VaR''' of a position with respect to a portfolio can be thought of as the amount of risk that the position is adding to the portfolio. It can be formally defined as the difference between the VaR of the total portfolio and the VaR of the portfolio without the position.

{{quote|To measure the effect of changing positions on portfolio risk, individual VaRs are insufficient. Volatility measures the uncertainty in the return of an asset, taken in isolation. When this asset belongs to a portfolio, however, what matters is the contribution to portfolio risk.|[[Philippe Jorion]] (2007)}}

===Incremental risk===

'''Incremental risk''' statistics provide information regarding the sensitivity of portfolio risk to changes in the position holding sizes in the portfolio.

An important property of incremental risk is subadditivity. That is, the sum of the incremental risks of the positions in a portfolio equals the total risk of the portfolio. This property has important applications in the allocation of risk to different units, where the goal is to keep the sum of the risks equal to the total risk.

Since there are three risk measures covered by RiskMetrics, there are three incremental risk measures: '''Incremental VaR''' (IVaR), '''Incremental Expected Shortfall''' (IES), and '''Incremental Standard Deviation''' (ISD).

Incremental statistics also have applications to portfolio optimization. A portfolio with minimum risk will have incremental risk equal to zero for all positions.  Conversely, if the incremental risk is zero for all positions, the portfolio is guaranteed to have minimum risk only if the risk measure is subadditive.

===Coherent risk measures===

A [[coherent risk measure]] satisfies the following four properties:

'''1. Subadditivity'''

A risk measure is '''subadditive''' if for any portfolios A and B, the risk of A+B is never greater than the risk of A plus the risk of B. In other words, the risk of the sum of subportfolios is smaller than or equal to the sum of their individual risks.

Standard deviation and expected shortfall are subadditive, while VaR is not.

Subadditivity is required in connection with aggregation of risks across desks, business units, accounts, or subsidiary companies. This property is important when different business units calculate their risks independently and we want to get an idea of the total risk involved. Subadditivity could also be a matter of concern for regulators, where firms might be motivated to break up into affiliates to satisfy capital requirements.

'''2. Translation invariance'''

Adding cash to the portfolio decreases its risk by the same amount.

'''3. Positive homogeneity of degree 1'''

If we double the size of every position in a portfolio, the risk of the portfolio will be twice as large.

'''4. Monotonicity'''

If losses in portfolio A are larger than losses in portfolio B for all possible risk factor return scenarios, then the risk of portfolio A is higher than the risk of portfolio B.

===Assessing risk measures===

The estimation process of any risk measure can be wrong by a considerable margin. If from the imprecise estimate we cannot get a good understanding what the true value could be, then the estimate is virtually worthless. A good risk measurement is to supplement any estimated risk measure with some indicator of their precision, or, of the size of its error.

There are various ways to quantify the error of some estimates. One approach is to estimate a confidence interval of the risk measurement.

==Market models==
RiskMetrics describes three models for modeling the risk factors that define financial markets.

===Covariance approach===
The first is very similar to the mean-covariance approach of Markowitz. Markowitz assumed that asset covariance matrix &lt;math&gt;\Sigma&lt;/math&gt; can be observed. The covariance matrix can be used to compute portfolio variance. RiskMetrics assumes that the market is driven by risk factors with observable covariance. The risk factors are represented by time series of prices or levels of stocks, currencies, commodities, and interest rates. Instruments are evaluated from these risk factors via various pricing models. The portfolio itself is assumed to be some linear combination of these instruments.

===Historical simulation===
The second market model assumes that the market only has finitely many possible changes, drawn from a risk factor return sample of a defined historical period. Typically one performs a historical simulation by sampling from past day-on-day risk factor changes, and applying them to the current level of the risk factors to obtain risk factor price scenarios. These perturbed risk factor price scenarios are used to generate a profit (loss) distribution for the portfolio.

This method has the advantage of simplicity, but as a model, it is slow to adapt to changing market conditions. It also suffers from simulation error, as the number of simulations is limited by the historical period (typically between 250 and 500 business days).

===Monte carlo simulation===
The third market model assumes that the logarithm of the return, or, log-return, of any risk factor typically follows a [[normal distribution]]. Collectively, the log-returns of the risk factors are [[Multivariate normal distribution|multivariate normal]]. [[Monte Carlo algorithm]] simulation generates random market scenarios drawn from that multivariate normal distribution. For each scenario, the profit (loss) of the portfolio is computed. This collection of profit (loss) scenarios provides a sampling of the profit (loss) distribution from which one can compute the risk measures of choice.

==Criticism==
[[Nassim Taleb]] in his book ''[[The Black Swan (Taleb book)|The Black Swan]]'' (2007) wrote:
&lt;blockquote&gt;Banks are now more vulnerable to the [[Black swan theory|Black Swan]] than ever before with “scientists” among their staff  taking  care  of [[Market exposure|exposures]]. The  giant firm  [[J. P. Morgan]] put  the  entire  world  at  risk  by introducing  in  the  nineties  RiskMetrics,  a  phony  method  aiming  at  managing  people’s  risks.  A related  method  called  “[[Value-at-Risk]],”  which  relies  on  the  quantitative  measurement  of  risk,  has been spreading.&lt;ref&gt;{{cite book|last1=[[Nassim Taleb]]|title=The Black Swan: The Impact of the Highly Improbable|date=2007}} Cited in {{cite web|last1=Nassim Taleb|title=Report on The Risks of Financia l Modeling, VaR and the Economic Breakdown|url=http://gop.science.house.gov/Media/hearings/oversight09/sept10/taleb.pdf|publisher=U.S. House of Representatives|archiveurl=https://web.archive.org/web/20091104013038/http://gop.science.house.gov/Media/hearings/oversight09/sept10/taleb.pdf|archivedate=Nov 4, 2009|date=Sep 10, 2009}}&lt;/ref&gt;&lt;/blockquote&gt;

==References==
*Harry Markowitz, "Portfolio Selection", ''Journal of Finance'',  Mar., 1952.
*Peter Zangari, [https://web.archive.org/web/20080918215723/http://www.riskmetrics.com/rmcovv.html RiskMetrics Technical Document], 1996.
*Matthew Pritzker, [http://ideas.repec.org/p/fip/fedgfe/2001-27.html The Hidden Dangers of Historical Simulation], Board of Governors of the Federal Reserve System, ''Finance and Economics Discussion Series'', 2001.
*Jeremy Berkowitz and James O'Brien, "How Accurate Are Value-at-Risk Models at Commercial Banks?", ''Journal of Finance'',  Vol. 57, No. 3  (Jun., 2002), pp.&amp;nbsp;1093–1111.
*Jorge Mina and Jerry Xiao. [http://www.riskmetrics.com/publications/techdocs/r2rovv.html Return to RiskMetrics – the Evolution of a Standard], 2001.
*Chris Finger. [https://www.msci.com/www/research-paper/how-historical-simulation-made/018350706 How historical simulation made me lazy], ''RiskMetrics Research Monthly'', April, 2006.
*Gilles Zumbach, [http://www.riskmetrics.com/publications/working_papers/rm2006.html A gentle introduction to the RM 2006 methodology], RiskMetrics Working Paper, November 2006.
*Alan Laubsch, [http://www.riskmetrics.com/publications/techdocs/pracovv.html Risk Management: A Practical Guide], 1999

;Specific
&lt;references /&gt;

==External links==
{{Use dmy dates|date=November 2010}}

{{DEFAULTSORT:Riskmetrics}}
[[Category:Actuarial science]]
[[Category:Financial risk modeling]]</text>
      <sha1>qpi9j3lrlyllhl93inz0f1aarnn3u53</sha1>
    </revision>
  </page>
  <page>
    <title>S. L. Hakimi</title>
    <ns>0</ns>
    <id>22946501</id>
    <revision>
      <id>861385851</id>
      <parentid>838817679</parentid>
      <timestamp>2018-09-27T01:37:12Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* References */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5356">'''Seifollah Louis Hakimi''' (1932 &amp;ndash; June 23, 2005)&lt;ref name="Davis"&gt;{{cite web|url=https://www.ucdavis.edu/news/harold-olmo-pioneering-wine-grape-scientist-and-other-obituaries/|title=Harold Olmo: Pioneering wine, grape scientist, and other obituaries|website=UCDavis|author=Pat Bailey|date=July 21, 2006|access-date=29 August 2017}}&lt;/ref&gt; was an Iranian-American [[mathematician]] born in Iran, a professor emeritus at [[Northwestern University]], where he chaired the department of [[electrical engineering]] from 1973 to 1978.&lt;ref&gt;{{citation|url=http://www.mccormick.northwestern.edu/100/pdfbooks/tech_anthology1/files/tech%20anthology%20i.pdf|title=Tech, the early years: An anthology of the history of the technological institute at Northwestern University from 1939 to 1969|editor-first=Morris E.|editor-last=Fine|page=103|deadurl=yes|archiveurl=https://web.archive.org/web/20131203073111/http://www.mccormick.northwestern.edu/100/pdfbooks/tech_anthology1/files/tech%20anthology%20i.pdf|archivedate=2013-12-03|df=}}.&lt;/ref&gt; He was Chair of the Department of Electrical Engineering at [[University of California, Davis]], from 1986 to 1996.&lt;ref name="Davis"/&gt;

Hakimi received his Ph.D. from the [[University of Illinois at Urbana-Champaign]] in 1959, under the supervision of [[Mac Van Valkenburg]]. He has over 100 academic descendants, most of them via his student [[Narsingh Deo]].&lt;ref&gt;{{MathGenealogy|id=126006}}&lt;/ref&gt;

He is known for characterizing the [[Degree (graph theory)|degree sequences]] of [[undirected graph]]s,&lt;ref&gt;{{citation|title=How to Count: An Introduction to Combinatorics|edition=2nd|series=Discrete Mathematics and Its Applications|first1=R.B.J.T.|last1=Allenby|first2=Alan|last2=Slomson|publisher=CRC Press|year=2011|isbn=9781420082616|page=159|url=https://books.google.com/books?id=1oyMQGHqv_0C&amp;pg=PA159|contribution=Theorem 9.3: the Havel–Hakimi theorem|quote=A proof of this theorem was first published by [[V. J. Havel|Václav Havel]] ... in 1963 another proof was published independently by S. L. Hakimi}}.&lt;/ref&gt; for formulating the [[Steiner tree problem]] on networks,&lt;ref&gt;{{citation|title=The Steiner Tree Problem|series=Annals of Discrete Mathematics|first1=F. K.|last1=Hwang|first2=D. S.|last2=Richards|first3=P.|last3=Winter|publisher=Elsevier|year=1992|isbn=9780080867939|page=94|url=https://books.google.com/books?id=-_yKbY3X_jUC&amp;pg=PA94|quote=The Steiner tree problem in networks was originally formulated by Hakimi and independently by Levin in 1971.}}&lt;/ref&gt; and for his work on [[facility location]] problems on networks.&lt;ref&gt;{{citation|title=Foundations of Location Analysis|volume=155|pages=39–59|series=International series in operations research &amp; management science|editor1-first=Horst A.|editor1-last=Eiselt|editor2-first=Vladimir|editor2-last=Marianov|publisher=Springer|year=2011|isbn=9781441975720|doi=10.1007/978-1-4419-7572-0_3|contribution=Median problems in networks|first1=Vladimir|last1=Marianov|first2=Daniel|last2=Serra}}. On [https://books.google.com/books?id=6bQ8JJ_Rx6sC&amp;pg=PA53 p.&amp;nbsp;53], Marianov and Serra write "The impact of Hakimi's two contributions is hard to overstate. A common opinion among location researchers is that the paper by Hakimi (1964) strongly contributed to trigger the interest in location theory and analysis, and started a long string of related publications that does not seem to be decreasing."&lt;/ref&gt;

==Selected publications==
*{{citation
 | last = Hakimi | first = S. L.
 | journal = J. Soc. Indust. Appl. Math.
 | jstor = 2098770
 | mr = 0153001
 | pages = 135–147
 | title = On realizability of a set of integers as degrees of the vertices of a linear graph. II. Uniqueness
 | volume = 11
 | year = 1963}}.
*{{citation
 | last = Hakimi | first = S. L.
 | doi = 10.1287/opre.12.3.450
 | issue = 3
 | journal = Operations Research
 | pages = 450–459
 | title = Optimum locations of switching centers and the absolute centers and medians of a graph
 | volume = 12
 | year = 1964}}.
*{{citation
 | last = Hakimi | first = S. L.
 | doi = 10.1002/net.3230010203
 | journal = Networks
 | mr = 0295947
 | pages = 113–133
 | title = Steiner's problem in graphs and its implications
 | volume = 1
 | year = 1971}}.
*{{citation
 | last1 = Megiddo | first1 = N. | author1-link = Nimrod Megiddo
 | last2 = Hakimi | first2 = S. L.
 | last3 = Garey | first3 = M. R. | author3-link = Michael R. Garey
 | last4 = Johnson | first4 = D. S. | author4-link = David S. Johnson
 | last5 = Papadimitriou | first5 = C. H. | author5-link = Christos Papadimitriou
 | doi = 10.1145/42267.42268
 | issue = 1
 | journal = [[Journal of the ACM]]
 | pages = 18–44
 | title = The complexity of searching a graph
 | volume = 35
 | year = 1988}}.
*{{citation
 | last1 = Bauer | first1 = D.
 | last2 = Hakimi | first2 = S. L.
 | last3 = Schmeichel | first3 = E.
 | doi = 10.1016/0166-218X(90)90001-S
 | issue = 3
 | journal = Discrete Applied Mathematics
 | mr = 1074858
 | pages = 191–195
 | title = Recognizing tough graphs is NP-hard
 | volume = 28
 | year = 1990}}.

==References==
{{reflist}}


{{authority control}}

{{DEFAULTSORT:Hakimi, S. L.}}
[[Category:1932 births]]
[[Category:2005 deaths]]
[[Category:Northwestern University faculty]]
[[Category:University of Illinois at Urbana–Champaign alumni]]
[[Category:Graph theorists]]


{{US-mathematician-stub}}</text>
      <sha1>pr4tbvzlkzhyorgthrmp7paf2h37r8g</sha1>
    </revision>
  </page>
  <page>
    <title>Schröder–Bernstein property</title>
    <ns>0</ns>
    <id>29972293</id>
    <revision>
      <id>781810637</id>
      <parentid>661542236</parentid>
      <timestamp>2017-05-23T10:44:47Z</timestamp>
      <contributor>
        <username>Jochen Burghardt</username>
        <id>17350134</id>
      </contributor>
      <comment>/* Schröder–Bernstein properties */ typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8139">A '''Schröder–Bernstein property''' is any mathematical property that matches the following pattern
: If, for some mathematical objects ''X'' and ''Y'', both ''X'' is similar to a part of ''Y'' and ''Y'' is similar to a part of ''X'' then ''X'' and ''Y'' are similar (to each other).
The name '''Schröder–Bernstein''' (or Cantor–Schröder–Bernstein, or Cantor–Bernstein) '''property''' is in analogy to the [[Cantor–Bernstein–Schroeder theorem|theorem]] of the same name (from set theory).

==Schröder–Bernstein properties==
{{unreferenced section|date=November 2011}}

{| style="float: right" border=1
|-
| colspan=3 | [[File:Schroder-Bernstein counterexample.jpg|450px]]
|- 
| colspan=3 style="width:450px" | Mirror-in-mirror images as counterexample: The left image can be embedded into the right one and vice versa (below, left/mid); yet, both aren't similar. The Schröder-Bernstein theorem applied to the unstructured pixel sets obtains a noncontinuous bijection (right).
|-
| [[File:Schroder-Bernstein counterexample L in R.jpg|150px]] 
| [[File:Schroder-Bernstein counterexample R in L.jpg|150px]]
| [[File:Schroder-Bernstein counterexample noncontiuous bijection.jpg|150px]]
|}

In order to define a specific Schröder–Bernstein property one should decide
* what kind of mathematical objects are ''X'' and ''Y'',
* what is meant by "a part",
* what is meant by "similar".

In the classical [[(Cantor–)Schröder–Bernstein theorem]],
* objects are [[Set (mathematics)|sets]] (maybe [[infinite set|infinite]]),
* "a part" is interpreted as a [[subset]],
* "similar" is interpreted as [[Bijective function#Bijections and the concept of cardinality|equinumerous]].

Not all statements of this form are true. For example, assume that
* objects are [[triangle]]s,
* "a part" means a triangle inside the given triangle,
* "similar" is interpreted as usual in elementary geometry: triangles related by a dilation (in other words, "triangles with the same shape up to a scale factor", or equivalently "triangles with the same angles").
Then the statement fails badly: every triangle ''X'' evidently is similar to some triangle inside ''Y'', and the other way round; however, ''X'' and ''Y'' need not be similar.

A Schröder–Bernstein property is a joint property of
* a class of objects,
* a [[Relation (mathematics)|binary relation]] "be a part of",
* a binary relation "be similar to" (similarity).
Instead of the relation "be a part of" one may use a binary relation "be embeddable into" (embeddability) interpreted as "be similar to some part of". Then a Schröder–Bernstein property takes the following form.
:If ''X'' is embeddable into ''Y'' and ''Y'' is embeddable into ''X'' then ''X'' and ''Y'' are similar.
The same in the language of [[category theory]]:
:If objects ''X'', ''Y'' are such that ''X'' injects into ''Y'' (more formally, there exists a monomorphism from ''X'' to ''Y'') and also ''Y'' injects into ''X'' then ''X'' and ''Y'' are isomorphic (more formally, there exists an isomorphism from ''X'' to ''Y'').
The relation "injects into" is a [[preorder]] (that is, a reflexive and [[Transitive relation|transitive]] relation), and "be isomorphic" is an [[equivalence relation]]. Also embeddability is usually a preorder, and similarity is usually an equivalence relation (which is natural, but not provable in the absence of formal definitions). Generally, a preorder leads to an equivalence relation and a [[partial order]] between the corresponding [[Equivalence relation|equivalence classes]]. The Schröder–Bernstein property claims that the embeddability preorder (assuming that it is a preorder) leads to the similarity equivalence relation, and a partial order (not just preorder) between classes of similar objects.

==Schröder–Bernstein problems and Schröder–Bernstein theorems==
The problem of deciding whether a Schröder–Bernstein property (for a given class and two relations) holds or not, is called a Schröder–Bernstein problem. A theorem that states a Schröder–Bernstein property (for a given class and two relations), thus solving the Schröder–Bernstein problem in the affirmative, is called a Schröder–Bernstein theorem (for the given class and two relations), not to be confused with the classical (Cantor–)Schröder–Bernstein theorem mentioned above.

The [[Schröder–Bernstein theorem for measurable spaces]]&lt;ref&gt;{{harvnb|Srivastava|1998}}, see Proposition 3.3.6 (on page 96), and the first paragraph of Section 3.3 (on page 94).&lt;/ref&gt; states the Schröder–Bernstein property for the following case:
* objects are measurable spaces,
* "a part" is interpreted as a measurable subset treated as a measurable space,
* "similar" is interpreted as isomorphic.

In the [[Schröder–Bernstein theorem for operator algebras]],&lt;ref&gt;{{harvnb|Kadison|Ringrose|1986}}, see Proposition 6.2.4 (on page 406).&lt;/ref&gt;
* objects are projections in a given von Neumann algebra;
* "a part" is interpreted as a subprojection (that is, ''E'' is a part of ''F'' if ''F'' – ''E'' is a projection);
* "''E'' is similar to ''F''" means that ''E'' and ''F'' are the initial and final projections of some partial isometry in the algebra (that is, ''E'' = ''V*V'' and ''F'' = ''VV*'' for some ''V'' in the algebra).
Taking into account that commutative von Neumann algebras are closely related to measurable spaces,&lt;ref&gt;{{harvnb|Kadison|Ringrose|1986}}, see Theorem 9.4.1 (on page 666).&lt;/ref&gt; one may say that the Schröder–Bernstein theorem for operator algebras is in some sense a noncommutative counterpart of the Schröder–Bernstein theorem for measurable spaces.

The [[Myhill isomorphism theorem]] can be viewed as a Schröder–Bernstein theorem in [[computability theory]].

[[Banach space]]s violate the Schröder–Bernstein property;&lt;ref name=Ca&gt;{{harvnb|Casazza|1989}}&lt;/ref&gt;&lt;ref name=Go&gt;{{harvnb|Gowers|1996}}&lt;/ref&gt; here
* objects are Banach spaces,
* "a part" is interpreted as a subspace&lt;ref name="Ca" /&gt; or a complemented subspace,&lt;ref name=Go /&gt;
* "similar" is interpreted as linearly homeomorphic.

Many other Schröder–Bernstein problems related to various [[space (mathematics)|spaces]] and algebraic structures (groups, rings, fields etc.) are discussed by informal groups of mathematicians (see External Links below).

==Notes==
{{Reflist}}

==See also==
* [[Cantor–Bernstein–Schroeder theorem]]
* [[Schroeder–Bernstein theorem for measurable spaces]]
* [[Schröder–Bernstein theorems for operator algebras]]
* [[Commutative von Neumann algebras]]

==References==
:{{citizendium}}
*{{Citation
 | last = Srivastava
 | first = S.M.
 | title = A Course on Borel Sets
 | year = 1998
 | publisher = Springer
 | isbn = 0-387-98412-7
}}.
*{{Citation
 | last1 = Kadison
 | first1 = Richard V.
 | last2 = Ringrose
 | first2 = John R.
 | title = Fundamentals of the theory of operator algebras
 | volume = II
 | year = 1986
 | publisher = Academic Press
 | isbn = 0-12-393302-1
}}.
*{{Citation
 | last = Gowers
 | first = W.T.
 | year = 1996
 | title = A solution to the Schroeder–Bernstein problem for Banach spaces
 | journal = Bull. London Math. Soc.
 | volume = 28
 | pages = 297–304
 | url = http://blms.oxfordjournals.org/content/28/3/297
 | doi=10.1112/blms/28.3.297
}}.
*{{Citation
 | last = Casazza
 | first = P.G.
 | year = 1989
 | title = The Schroeder–Bernstein property for Banach spaces
 | journal = Contemp. Math.
 | volume = 85
 | pages = 61–78
 | mr = 983381
 | doi=10.1090/conm/085/983381
}}.

==External links==
*[http://sbseminar.wordpress.com/2007/10/30/theme-and-variations-schroeder-bernstein/ Theme and variations: Schroeder-Bernstein] - Various Schröder–Bernstein problems are discussed in a group blog by 8 recent Berkeley mathematics Ph.D.
*[http://mathoverflow.net/questions/1058/when-does-cantor-bernstein-hold When does Cantor Bernstein hold?] - "Mathoverflow" discusses the question in terms of category theory: "Can we characterize Cantor-Bernsteiness in terms of other categorical properties?"

{{DEFAULTSORT:Schroder-Bernstein property}}
[[Category:Mathematical logic]]
[[Category:Set theory]]</text>
      <sha1>k8918l9cn0jb7p7w9b7uwjy831velgg</sha1>
    </revision>
  </page>
  <page>
    <title>Schwarz lemma</title>
    <ns>0</ns>
    <id>1432589</id>
    <revision>
      <id>862692114</id>
      <parentid>810712487</parentid>
      <timestamp>2018-10-06T02:02:44Z</timestamp>
      <contributor>
        <ip>147.65.5.198</ip>
      </contributor>
      <comment>/* Statement */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7604">{{Complex analysis sidebar}}

In [[mathematics]], the '''Schwarz lemma''', named after [[Hermann Amandus Schwarz]], is a result in [[complex analysis]] about [[holomorphic functions]] from the [[open set|open]] [[unit disk]] to itself. The lemma is less celebrated than stronger theorems, such as the [[Riemann mapping theorem]], which it helps to prove. It is, however, one of the simplest results capturing the rigidity of holomorphic functions.

==Statement==
&lt;blockquote&gt;
'''Schwarz Lemma.''' Let &lt;math&gt;\mathbf{D} = \{z : |z| &lt; 1\}&lt;/math&gt; be the open [[unit disk]] in the [[complex number|complex plane]] &lt;math&gt;\mathbb{C}&lt;/math&gt; centered at the [[origin (mathematics)|origin]] and let &lt;math&gt;f : \mathbf{D}\rightarrow \mathbb{C}&lt;/math&gt; be a [[holomorphic map]] such that &lt;math&gt;f(0) = 0&lt;/math&gt; and &lt;math&gt;|f(z)|\leq 1&lt;/math&gt; on &lt;math&gt;\mathbf{D}&lt;/math&gt;.

Then, &lt;math&gt;|f(z)| \leq |z| \ \forall z \in \mathbf{D}&lt;/math&gt; and &lt;math&gt;|f'(0)| \leq 1&lt;/math&gt;.

Moreover, if &lt;math&gt;|f(z)| = |z|&lt;/math&gt; for some non-zero &lt;math&gt;z&lt;/math&gt; or &lt;math&gt;|f'(0)| = 1&lt;/math&gt;, then &lt;math&gt;f(z) = az&lt;/math&gt; for some &lt;math&gt;a \in \mathbb{C}&lt;/math&gt; with &lt;math&gt;|a| = 1&lt;/math&gt;.&lt;ref&gt;Theorem 5.34 in {{cite book|last1=Rodriguez|first1=Jane P. Gilman, Irwin Kra, Rubi E.|title=Complex analysis : in the spirit of Lipman Bers|date=2007|publisher=Springer|location=New York|isbn=978-0-387-74714-9|page=95|edition=[Online]}}&lt;/ref&gt;
&lt;/blockquote&gt;

==Proof==
The proof is a straightforward application of the [[maximum modulus principle]] on the function

:&lt;math&gt;g(z) = \begin{cases}
  \frac{f(z)}{z}\, &amp; \mbox{if } z \neq 0 \\
  f'(0) &amp; \mbox{if } z = 0,
\end{cases}&lt;/math&gt;

which is holomorphic on the whole of '''D''',  including at the origin (because ''f'' is differentiable at the origin and fixes zero). Now if  '''D'''&lt;sub&gt;''r''&lt;/sub&gt; = {''z'' : |''z''| ≤ ''r''} denotes the closed disk of radius ''r'' centered at the origin, then the maximum modulus principle implies that, for ''r'' &lt; 1, given any ''z'' in '''D'''&lt;sub&gt;''r''&lt;/sub&gt;, there exists ''z''&lt;sub&gt;''r''&lt;/sub&gt; on the boundary of '''D'''&lt;sub&gt;''r''&lt;/sub&gt; such that

:&lt;math&gt; |g(z)| \le |g(z_r)| = \frac{|f(z_r)|}{|z_r|} \le \frac{1}{r}.&lt;/math&gt;

As &lt;math&gt;r \rightarrow 1&lt;/math&gt; we get &lt;math&gt;|g(z)| \leq 1&lt;/math&gt;.

Moreover, suppose that |''f''(''z'')| = |''z''| for some non-zero ''z'' in '''D''', or |''f′''(0)| = 1. Then, |''g''(''z'')| = 1 at some point of '''D'''. So by the maximum modulus principle, ''g''(''z'') is equal to a constant ''a'' such that |''a''| = 1. Therefore, ''f''(''z'') = ''az'', as desired.

==Schwarz&amp;ndash;Pick theorem==
A variant of the Schwarz lemma can be stated that is invariant under analytic automorphisms on the unit disk, i.e. [[bijective]] [[holomorphic map]]pings of the unit disc to itself.  This variant is known as the '''Schwarz&amp;ndash;Pick theorem''' (after [[Georg Pick]]):

Let ''f'' : '''D''' → '''D''' be holomorphic.  Then, for all ''z''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''z''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;∈&amp;nbsp;'''D''',

:&lt;math&gt;\left|\frac{f(z_1)-f(z_2)}{1-\overline{f(z_1)}f(z_2)}\right| \le \left|\frac{z_1-z_2}{1-\overline{z_1}z_2}\right|&lt;/math&gt;

and, for all ''z''&amp;nbsp;∈&amp;nbsp;'''D''',

:&lt;math&gt;\frac{\left|f'(z)\right|}{1-\left|f(z)\right|^2} \le \frac{1}{1-\left|z\right|^2}.&lt;/math&gt;

The expression

:&lt;math&gt; d(z_1,z_2)=\tanh^{-1} \left|\frac{z_1-z_2}{1-\overline{z_1}z_2}\right| &lt;/math&gt;

is the distance of the points ''z''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''z''&lt;sub&gt;2&lt;/sub&gt; in the [[Poincaré metric]], i.e. the metric in the Poincaré disc model for [[hyperbolic geometry]] in dimension two. The Schwarz&amp;ndash;Pick theorem then essentially states that a holomorphic map of the unit disk into itself ''decreases'' the distance of points in the Poincaré metric. If equality holds throughout in one of the two inequalities above (which is equivalent to saying that the holomorphic map preserves the distance in the Poincaré metric), then ''f'' must be an analytic automorphism of the unit disc, given by a [[Möbius transformation]] mapping the unit disc to itself.

An analogous statement on the [[upper half-plane]] '''H''' can be made as follows:

&lt;blockquote&gt;Let ''f'' : '''H''' → '''H''' be holomorphic. Then, for all ''z''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''z''&lt;sub&gt;2&lt;/sub&gt; ∈ '''H''',

:&lt;math&gt;\left|\frac{f(z_1)-f(z_2)}{\overline{f(z_1)}-f(z_2)}\right|\le \frac{\left|z_1-z_2\right|}{\left|\overline{z_1}-z_2\right|}.&lt;/math&gt;
&lt;/blockquote&gt;

This is an easy consequence of the Schwarz&amp;ndash;Pick theorem mentioned above: One just needs to remember that the [[Cayley transform]] ''W''(''z'')&amp;nbsp;=&amp;nbsp;(''z''&amp;nbsp;−&amp;nbsp;''i'')/(''z''&amp;nbsp;+&amp;nbsp;''i'') maps the upper half-plane '''H''' conformally onto the unit disc&amp;nbsp;'''D'''. Then, the map ''W''&amp;nbsp;o&amp;nbsp;''f''&amp;nbsp;o&amp;nbsp;''W''&lt;sup&gt;−1&lt;/sup&gt; is a holomorphic map from '''D''' onto&amp;nbsp;'''D'''.  Using the Schwarz&amp;ndash;Pick theorem on this map, and finally simplifying the results by using the formula for ''W'', we get the desired result. Also, for all ''z''&amp;nbsp;∈&amp;nbsp;'''H''',

:&lt;math&gt;\frac{\left|f'(z)\right|}{\text{Im}(f(z))} \le \frac{1}{\text{Im}(z)}. &lt;/math&gt;

If equality holds for either the one or the other expressions, then ''f'' must be a [[Möbius transformation]] with real coefficients.  That is, if equality holds, then

:&lt;math&gt;f(z)=\frac{az+b}{cz+d}&lt;/math&gt;

with ''a'',&amp;nbsp;''b'',&amp;nbsp;''c'',&amp;nbsp;''d'' ∈ '''R''', and ''ad''&amp;nbsp;−&amp;nbsp;''bc''&amp;nbsp;&gt;&amp;nbsp;0.

==Proof of Schwarz&amp;ndash;Pick theorem==
The proof of the Schwarz&amp;ndash;Pick theorem follows from Schwarz's lemma and the fact that a [[Möbius transformation]] of the form

:&lt;math&gt;\frac{z-z_0}{\overline{z_0}z-1}, \qquad |z_0| &lt; 1,&lt;/math&gt;

maps the unit circle to itself. Fix ''z''&lt;sub&gt;1&lt;/sub&gt; and define the Möbius transformations

: &lt;math&gt;M(z)=\frac{z_1-z}{1-\overline{z_1}z}, \qquad \varphi(z)=\frac{f(z_1)-z}{1-\overline{f(z_1)}z}.&lt;/math&gt;

Since ''M''(''z''&lt;sub&gt;1&lt;/sub&gt;)&amp;nbsp;=&amp;nbsp;0 and the Möbius transformation is invertible, the composition φ(''f''(''M''&lt;sup&gt;−1&lt;/sup&gt;(''z''))) maps 0 to 0 and the unit disk is mapped into itself. Thus we can apply Schwarz's lemma, which is to say

:&lt;math&gt;\left |\varphi\left(f(M^{-1}(z))\right) \right|=\left|\frac{f(z_1)-f(M^{-1}(z))}{1-\overline{f(z_1)}f(M^{-1}(z))}\right| \le |z|.&lt;/math&gt;

Now calling ''z''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''M''&lt;sup&gt;−1&lt;/sup&gt;(''z'') (which will still be in the unit disk) yields the desired conclusion

:&lt;math&gt;\left|\frac{f(z_1)-f(z_2)}{1-\overline{f(z_1)}f(z_2)}\right| \le \left|\frac{z_1-z_2}{1-\overline{z_1}z_2}\right|.&lt;/math&gt;

To prove the second part of the theorem, we rearrange the left-hand side into the difference quotient and let ''z''&lt;sub&gt;2&lt;/sub&gt; tend to ''z''&lt;sub&gt;1&lt;/sub&gt;.

==Further generalizations and related results==
The [[Schwarz–Ahlfors–Pick theorem]] provides an analogous theorem for hyperbolic manifolds.

[[De Branges' theorem]], formerly known as the Bieberbach Conjecture, is an important extension of the lemma, giving restrictions on the higher derivatives of ''f'' at 0 in case ''f'' is [[injective]]; that is, [[univalent mapping|univalent]].

The [[Koebe 1/4 theorem]] provides a related estimate in the case that ''f'' is univalent.

==References==
&lt;references/&gt;
* Jurgen Jost, ''Compact Riemann Surfaces'' (2002), Springer-Verlag, New York. {{isbn|3-540-43299-X}} ''(See Section 2.3)''
*{{cite book | author = S. Dineen | title = The Schwarz Lemma | publisher = Oxford | year = 1989 | isbn=0-19-853571-6 }}

{{PlanetMath attribution|title=Schwarz lemma|id=3047}}

[[Category:Riemann surfaces]]
[[Category:Lemmas]]
[[Category:Theorems in complex analysis]]
[[Category:Articles containing proofs]]</text>
      <sha1>46p7f76zmywjq1693oxg3svzxw3jsgh</sha1>
    </revision>
  </page>
  <page>
    <title>Shai Halevi</title>
    <ns>0</ns>
    <id>44938612</id>
    <revision>
      <id>865971925</id>
      <parentid>865836758</parentid>
      <timestamp>2018-10-27T11:36:11Z</timestamp>
      <contributor>
        <username>Ipigott</username>
        <id>2639797</id>
      </contributor>
      <comment>correcting cats</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8760">{{Infobox scientist
| name                    = Shai Halevi
| image                   = 
| birth_date              = 1966
| birth_place             = [[Israel]]
| death_date              = 
| death_place             = 
| residence               = [[U.S]]
| nationality             =
| field                   = [[Computer science]], [[cryptography]]
| work_institution        = [[IBM T.J. Watson Research Center]]
| alma_mater              = {{Plainlist|
* [[Technion – Israel Institute of Technology|Technion (B.A.)]]
* [[Technion - Israel Institute of Technology|Technion (M.Sc.)]]
* [[Massachusetts Institute of Technology|MIT (Ph.D.)]]}}
| doctoral_advisor        = [[Silvio Micali]]&lt;ref name="mathgene"&gt;{{MathGenealogy|id=100587}}&lt;/ref&gt;
| thesis_title = Theory and Practice of Secret Commitment
| thesis_year = 1997
| known_for               = {{Plainlist|
* Cryptographic Obfuscation&lt;ref name="wired"&gt;{{cite news |last=Klarreich |first=Erica |date=2014-02-03 |title=Cryptography Breakthrough Could Make Software Unhackable|url=https://www.wired.com/2014/02/cryptography-breakthrough/|newspaper=Quanta Magazine}}&lt;/ref&gt;
* [[Homomorphic encryption]]
* [[Random oracle]]}}
|website = {{URL|https://alum.mit.edu/www/shaih}}
}}

'''Shai Halevi''' ({{lang-he|שי הלוי}}; born 1966) is a computer scientist who works in the [[cryptography]] research group at [[IBM]]'s [[Thomas J. Watson Research Center]].

Born in [[Israel]] in 1966, Halevi received a B.A. and M.Sc. in computer science from the [[Technion]], Israel Institute of Technology in 1991 and 1993. He received his Ph.D. in Computer Science from MIT in 1997, and then joined [[IBM]]'s [[Thomas J. Watson Research Center]], where he is a Principal Research Staff Member.

==Research==
Shai Halevi's research interests are in cryptography and security. He has published numerous original technical research papers,&lt;ref&gt;{{cite web|url=http://www.informatik.uni-trier.de/~ley/pers/hd/h/Halevi:Shai|title=Shai Halevi's publications at DBLP}}&lt;/ref&gt;&lt;ref&gt;{{cite web | title = Shai Halevi's Google Scholar Profile | url=https://scholar.google.com/scholar?hl=en&amp;q=shai+halevi}}&lt;/ref&gt; three of which were awarded the IBM Pat Goldberg memorial best-paper award&lt;ref&gt;{{cite web | title = Pat Goldberg Memorial Best Papers in CS, EE and Math | url=http://researcher.watson.ibm.com/researcher/view_group.php?id=5434}}&lt;/ref&gt; (in 2004, 2012, and 2013).
Notable contributions by Shai Halevi include:

* '''Obfuscation.''' Halevi is a co-inventor of the first candidate general-purpose cryptographic obfuscation schemes, with security based on a mathematical conjecture.&lt;ref name="GGHRSW"&gt;{{cite journal |author1=Sanjam Garg |author2=Craig Gentry |author3=Shai Halevi |author4=Mariana Raykova |author5=Amit Sahai |author6=Brent Waters | date = 2013 | title = Candidate Indistinguishability Obfuscation and Functional Encryption for all Circuits| journal=FOCS 2013| publisher = IEEE|pages = 40–49| doi=10.1109/FOCS.2013.13|citeseerx=10.1.1.672.1968}}
&lt;/ref&gt; This development generated much interest in the cryptography community and was called "a watershed moment for cryptography."&lt;ref name="wired"/&gt;

* '''Cryptographic Multilinear Maps.''' Halevi is a co-inventor of Cryptographic Multilinear Maps (which constitute the main technical tool behind cryptographic obfuscation and many other applications), solving a long-standing open problem&lt;ref name=GGH13&gt;Sanjam Garg, Craig Gentry, and Shai Halevi. [https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=RBX7SrkAAAAJ&amp;citation_for_view=RBX7SrkAAAAJ:5awf1xo2G04C Candidate Multilinear Maps from Ideal Lattices]. In ''EUROCRYPT 2013'' (Springer)
&lt;/ref&gt;&lt;ref name=MMAPs&gt;{{cite web 
|date=2014-05-13|title=What are Cryptographic Multi-linear Maps?
|url=http://crypto.stackexchange.com/questions/16153/what-are-cryptographic-multi-linear-maps
}}&lt;/ref&gt;

* '''Homomorphic Encryption.''' Halevi is one of the leading researchers on [[homomorphic encryption]]. He authored many articles,&lt;ref name=intHE&gt;M. van Dijk, C. Gentry, S. Halevi, and V. Vaikuntanathan. [http://eprint.iacr.org/2009/616 Fully Homomorphic Encryption over the Integers]. In ''EUROCRYPT 2010'' (Springer)
&lt;/ref&gt;&lt;ref name="GH11a"&gt;C. Gentry and S. Halevi. [http://eprint.iacr.org/2010/520 Implementing Gentry's fully-homomorphic encryption scheme]. In ''EUROCRYPT 2011'' (Springer)
&lt;/ref&gt;&lt;ref name="GH11b"&gt;C. Gentry and S. Halevi. [https://eprint.iacr.org/2011/279 Fully Homomorphic Encryption without Squashing Using Depth-3 Arithmetic Circuits]. In ''FOCS 2011'' (IEEE)
&lt;/ref&gt;&lt;ref name="GHS12a"&gt;C. Gentry, S. Halevi, and N. P. Smart. [http://eprint.iacr.org/2011/566 Fully Homomorphic Encryption with Polylog Overhead]. In ''EUROCRYPT 2012'' (Springer)
&lt;/ref&gt;&lt;ref name="GHS12b"&gt;C. Gentry, S. Halevi, and N. P. Smart. [http://eprint.iacr.org/2011/680 Better Bootstrapping in Fully Homomorphic Encryption]. In ''PKC 2012'' (Springer)
&lt;/ref&gt;&lt;ref name="GHS12c"&gt;C. Gentry, S. Halevi, and N. P. Smart. [http://eprint.iacr.org/2012/099 Homomorphic Evaluation of the AES Circuit]. In ''CRYPTO 2012'' (Springer)
&lt;/ref&gt; gave invited lectures and tutorials on the topic,&lt;ref name=tutorial1&gt;
[https://www.youtube.com/watch?v=R5jaHNC_neI Fully Homomorphic Encryption].
Tutorial in the Winter School on Secure Computation and Efficiency, Bar-Ilan University, 2011.&lt;/ref&gt;&lt;ref name=tutorial2&gt;
[https://www.youtube.com/watch?v=jIWOR2bGC7c Fully Homomorphic Encryption]. Tutorial in CRYPTO 2011, UC Santa-Barbara&lt;/ref&gt;&lt;ref name=tutorial3&gt;
[https://www.youtube.com/watch?v=K6QOaBxdWrY Fully Homomorphic Encryption]. Invited lecture at the UCI Workshop on Lattices with Symmetry
&lt;/ref&gt; and he is also the principal developer (together with [[Victor Shoup]]) of the HElib homormophic-encryption software library.&lt;ref name=HElib&gt;
{{cite web
|title=HElib: An Implementation of homomorphic encryption
|url=https://github.com/shaih/HElib
|author=Shai Halevi|author2=Victor Shoup
|accessdate=31 December 2014}}
&lt;/ref&gt;&lt;ref name=HS14a&gt;S. Halevi and V. Shoup. [https://eprint.iacr.org/2014/106 Algorithms in HElib]. In ''CRYPTO 2014''
&lt;/ref&gt;&lt;ref name=HS14b&gt;S. Halevi and V. Shoup. [https://eprint.iacr.org/2014/106 Bootstrapping for HElib]. In ''Cryptology ePrint Archive''&lt;/ref&gt;

* '''The Random Oracle Model.''' Halevi co-authored the influential work that pointed out for the first time the existence of "structurally flawed" cryptosystems that nonetheless have a proof of security in the [[Random oracle|random-oracle model]].&lt;ref name=CGH98&gt;{{cite journal|last1=Canetti|first1=Ran|last2=Goldreich|first2=Oded|last3=Halevi|first3=Shai|title=The Random Oracle Methodology, Revisited|journal=J ACM|date=July 2004|volume=51|issue=4|pages=557–594|url=https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=RBX7SrkAAAAJ&amp;citation_for_view=RBX7SrkAAAAJ:u5HHmVD_uO8C|publisher=ACM}}&lt;/ref&gt;

Since 2013 Halevi is the chair of the steering committee of the [[Theory of Cryptography Conference]]. He served on the board of directors of the [[International Association for Cryptologic Research]].&lt;ref name=IACR&gt;{{cite web|title=IACR Board of Directors (2013)|publisher=[[International Association for Cryptologic Research]]|accessdate=January 7, 2015|url=https://www.iacr.org/bod.html|archiveurl=https://web.archive.org/web/20130615003316/https://www.iacr.org/bod.html|archivedate=June 15, 2013}}&lt;/ref&gt; He chaired the [[CRYPTO]] conference in 2009 and co-chaired the [[Theory of Cryptography Conference|TCC]] conference in 2006. Halevi also gave many invited talks, including in the [[USENIX Security Symposium]] in 2008 and the [[PKC (conference)|PKC conference]] in 2014.

==Software==
Halevi maintains two open-source software projects: The HElib homomorphic-encryption library,&lt;ref&gt;{{cite web | title = HElib: homomorphic-encryption software library | url=https://github.com/shaih/HElib}}&lt;/ref&gt; and a web-system for submission/review of articles to academic conferences&lt;ref&gt;{{cite web | title = websubrev: Web Submission and Review Software | url=http://sourceforge.net/projects/websubrev/}}&lt;/ref&gt;

==References==
{{Reflist|30em}}

==External links==
* [https://alum.mit.edu/www/shaih Shai Halevi's Home Page]
* [http://researcher.watson.ibm.com/researcher/view_group.php?id=2659 The Cryptography Research Group at the IBM T.J.Watson Research Center]

{{Authority control}}

{{DEFAULTSORT:Halevi, Shai}}
[[Category:Israeli computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:Modern cryptographers]]
[[Category:Public-key cryptographers]]
[[Category:Living people]]
[[Category:Israeli cryptographers]]
[[Category:1966 births]]
[[Category:Massachusetts Institute of Technology alumni]]
[[Category:Technion – Israel Institute of Technology alumni]]
[[Category:IBM employees]]</text>
      <sha1>kbfpic3p5hzaodnsiq37pg6frih9qcm</sha1>
    </revision>
  </page>
  <page>
    <title>Sharkovskii's theorem</title>
    <ns>0</ns>
    <id>87947</id>
    <revision>
      <id>864426158</id>
      <parentid>864425875</parentid>
      <timestamp>2018-10-17T03:53:01Z</timestamp>
      <contributor>
        <username>Mikhail Ryazanov</username>
        <id>13263935</id>
      </contributor>
      <minor/>
      <comment>/* Statement */ punct.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6407">In [[mathematics]], '''Sharkovskii's theorem''', named after [[Oleksandr Mykolaiovych Sharkovsky|Oleksandr Mykolaiovych Sharkovskii]], who published it in 1964, is a result about [[discrete dynamical system]]s.&lt;ref&gt;{{cite journal |first=A. N. |last=Sharkovskii |title=Co-existence of cycles of a continuous mapping of the line into itself |journal=Ukrainian Math. J. |volume=16 |issue= |pages=61–71 |year=1964 }}&lt;/ref&gt; One of the implications of the theorem is that if a discrete dynamical system on the [[real line]] has a [[periodic point]] of period&amp;nbsp;3, then it must have periodic points of every other period.

==Statement==
For some interval &lt;math&gt;I\subset \mathbb{R}&lt;/math&gt;, suppose

:&lt;math&gt;f : I \to I&lt;/math&gt;

is a [[continuous function]]. We say that the number ''x'' is a ''periodic point of period m'' if ''f''&lt;sup&gt;&amp;nbsp;''m''&lt;/sup&gt;(''x'') =&amp;nbsp;''x'' (where ''f''&lt;sup&gt;&amp;nbsp;''m''&lt;/sup&gt; denotes the [[iterated function|composition of ''m'' copies of ''f'']]) and having ''least period m'' if furthermore ''f''&lt;sup&gt;&amp;nbsp;''k''&lt;/sup&gt;(''x'') ≠ ''x'' for all 0&amp;nbsp;&lt;&amp;nbsp;''k''&amp;nbsp;&lt;&amp;nbsp;''m''. We are interested in the possible periods of periodic points of ''f''. Consider the following [[total order|ordering]] of the positive [[integer]]s:
:&lt;math&gt;\begin{array}{cccccccc}
3 &amp; 5 &amp; 7 &amp; 9 &amp; 11 &amp; \ldots &amp; (2n+1)\cdot2^{0} &amp; \ldots\\
3\cdot2 &amp; 5\cdot2 &amp; 7\cdot2 &amp; 9\cdot2 &amp; 11\cdot2 &amp; \ldots &amp; (2n+1)\cdot2^{1} &amp; \ldots\\
3\cdot2^{2} &amp; 5\cdot2^{2} &amp; 7\cdot2^{2} &amp; 9\cdot2^{2} &amp; 11\cdot2^{2} &amp; \ldots &amp; (2n+1)\cdot2^{2} &amp; \ldots\\
3\cdot2^{3} &amp; 5\cdot2^{3} &amp; 7\cdot2^{3} &amp; 9\cdot2^{3} &amp; 11\cdot2^{3} &amp; \ldots &amp; (2n+1)\cdot2^{3} &amp; \ldots\\
 &amp; \vdots\\
\ldots &amp; 2^{n} &amp; \ldots &amp; 2^{4} &amp; 2^{3} &amp; 2^{2} &amp; 2 &amp; 1\end{array}&lt;/math&gt;

It consists of:
* the odd numbers in increasing order,
* 2 times the odds in increasing order,
* 4 times the odds in increasing order,
* 8 times the odds,
* etc.
* at the end we put the powers of two in decreasing order.

Every positive integer appears exactly once somewhere on this list. Note that this ordering is not a [[well-order]]ing.

Sharkovskii's theorem states that if ''f'' has a periodic point of least period ''m'', and ''m'' precedes ''n'' in the above ordering, then ''f'' has also a periodic point of least period ''n''.

As a consequence, we see that if ''f'' has only finitely many periodic points, then they must all have periods that are powers of two. Furthermore, if there is a periodic point of period three, then there are periodic points of all other periods.

Sharkovskii's theorem does not state that there are ''stable'' cycles of those periods, just that there are cycles of those periods. For systems such as the [[logistic map]], the [[bifurcation diagram]] shows a range of parameter values for which apparently the only cycle has period 3. In fact, there must be cycles of all periods there, but they are not stable and therefore not visible on the computer-generated picture.

The assumption of continuity is important, as the discontinuous function &lt;math&gt;f : x \mapsto (1 - x)^{-1}&lt;/math&gt;, for which every non-zero value has period 3, would otherwise be a counterexample.

==Generalizations==

Sharkovskii also proved the converse theorem: every [[upper set]] of the above order is the set of periods for some continuous function from an interval to itself. In fact all such sets of periods are achieved by the family of functions &lt;math&gt;T_h:[0,1]\to[0,1]&lt;/math&gt;, &lt;math&gt;x\mapsto\min(h,1-2|x-1/2|)&lt;/math&gt; for &lt;math&gt;h\in[0,1]&lt;/math&gt;, except for the empty set of periods which is achieved by &lt;math&gt;T:\mathbb R\to\mathbb R&lt;/math&gt;, &lt;math&gt;x\mapsto x+1&lt;/math&gt;.&lt;ref&gt;{{cite book |last=Alsedà |first=L. |last2=Llibre |first2=J. |date=2000 |title=Combinatorial dynamics and entropy in dimension one |publisher=World Scientific Publishing Company |isbn=978-981-02-4053-0 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |first=K. |last=Burns |first2=B. |last2=Hasselblatt |title=The Sharkovsky theorem: A natural direct proof |journal=[[The American Mathematical Monthly]] |volume=118 |issue=3 |pages=229-244 |year=2011}}&lt;/ref&gt;

[[Tien-Yien Li]] and [[James A. Yorke]] showed in 1975 that not only does the existence of a period-3 cycle imply the existence of cycles of all periods, but in addition it implies the existence of an uncountable infinitude of points that never map to any cycle ([[chaos (mathematics)|chaotic points]])—a property known as [[period three implies chaos]].&lt;ref&gt;{{cite journal |first=T. Y. |last=Li |first2=J. A. |last2=Yorke |title=Period Three Implies Chaos |journal=[[American Mathematical Monthly]] |volume=82 |issue= |pages=985 |year=1975 |jstor=2318254 |doi=10.1080/00029890.1975.11994008 }}&lt;/ref&gt;

Sharkovskii's theorem does not immediately apply to dynamical systems on other topological spaces. It is easy to find a [[circle map]] with periodic points of period 3 only: take a rotation by 120 degrees, for example. But some generalizations are possible, typically involving the mapping class group of the space minus a periodic orbit.  For example, [[Peter Kloeden]] showed that Sharkovskii's theorem holds for triangular mappings, i.e., mappings for which the component {{math|''f&lt;sub&gt;i&lt;/sub&gt;''}} depends only on the first {{math|''i''}} components {{math|''x&lt;sub&gt;1&lt;/sub&gt;,..., x&lt;sub&gt;i&lt;/sub&gt;''}}.&lt;ref&gt;{{cite journal |first=P. E. |last=Kloeden |title=On Sharkovsky's cycle coexistence ordering |journal=Bulletin Austral. Math. Soc. |volume=20 |year=1979 |issue= 2|pages=171–178 |doi=10.1017/S0004972700010819 }}&lt;/ref&gt;

==References==
{{reflist}}
* {{mathworld|urlname=SharkovskysTheorem |title=Sharkovskys Theorem}}
* {{planetmathref|id=3751|title=Sharkovskii's theorem}}
* {{cite book| last = Teschl| given = Gerald|authorlink=Gerald Teschl| title = Ordinary Differential Equations and Dynamical Systems| publisher=[[American Mathematical Society]]| place = [[Providence, Rhode Island|Providence]]| year = 2012| isbn= 978-0-8218-8328-0| url = http://www.mat.univie.ac.at/~gerald/ftp/book-ode/}}
* {{cite journal|last = Misiurewicz|given = Michal |title = Remarks on Sharkovsky's Theorem|publisher=[[The American Mathematical Monthly]],Vol. 104, No. 9 (Nov., 1997), pp. 846-847}}

==External links==
* Keith Burns and Boris Hasselblatt, [http://math.arizona.edu/~dwang/BurnsHasselblattRevised-1.pdf The Sharkovsky theorem: a natural direct proof]

[[Category:Theorems in dynamical systems]]
[[Category:Ukrainian inventions]]</text>
      <sha1>4vat8fy1cduman2sexwns8004pjkz5n</sha1>
    </revision>
  </page>
  <page>
    <title>Short five lemma</title>
    <ns>0</ns>
    <id>130280</id>
    <revision>
      <id>742435592</id>
      <parentid>656126763</parentid>
      <timestamp>2016-10-03T18:06:34Z</timestamp>
      <contributor>
        <username>LaQuilla</username>
        <id>1666409</id>
      </contributor>
      <minor/>
      <comment>remove extraneous double-quote</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2068">In [[mathematics]], especially [[homological algebra]] and other applications of [[abelian category]] theory, the '''short five lemma''' is a special case of the [[five lemma]].
It states that for the following [[commutative diagram]] (in any abelian category, or in the category of [[group (mathematics)|group]]s), if the rows are [[exact sequence|short exact sequences]], and if ''g'' and ''h'' are [[isomorphism]]s, then ''f'' is an isomorphism as well.

[[Image:Short_5_lemma.svg]]

It follows immediately from the [[five lemma]].

The essence of the lemma can be summarized as follows: if you have a homomorphism ''f'' from an object ''B'' to an object ''B&amp;prime;'', and this homomorphism induces an isomorphism from a subobject ''A'' of ''B'' to a subobject ''A&amp;prime;'' of ''B&amp;prime;'' and also an isomorphism from the factor object ''B''/''A'' to ''B&amp;prime;''/''A&amp;prime;'', then ''f'' itself is an isomorphism. Note however that the existence of ''f'' (such that the diagram commutes) has to be assumed from the start; two objects ''B'' and ''B&amp;prime;'' that simply have isomorphic sub- and factor objects need not themselves be isomorphic (for example, in the category of abelian groups, ''B'' could be the [[cyclic group]] of order four and ''B&amp;prime;'' the [[Klein four-group]]).

== References ==
*{{cite book |first=Thomas W. |last=Hungerford |author1-link=Thomas W. Hungerford |title=Algebra |publisher=[[Springer-Verlag]] |location=Berlin |year=2003 | origyear=1980 |page=176 |isbn=0-387-90518-9 | series=[[Graduate Texts in Mathematics]] | volume=73 | zbl=0442.00002 }}
* {{cite book | editor1-last=Pedicchio | editor1-first=Maria Cristina | editor2-last=Tholen | editor2-first=Walter | title=Categorical foundations. Special topics in order, topology, algebra, and sheaf theory | series=Encyclopedia of Mathematics and Its Applications | volume=97 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2004 | isbn=0-521-83414-7 | zbl=1034.18001 }}

{{DEFAULTSORT:Short Five Lemma}}
[[Category:Homological algebra]]
[[Category:Lemmas]]</text>
      <sha1>kd9io2h7oe3s0j9kjgrvibctbxiam03</sha1>
    </revision>
  </page>
  <page>
    <title>Sinuosity</title>
    <ns>0</ns>
    <id>20766753</id>
    <revision>
      <id>755118877</id>
      <parentid>705640818</parentid>
      <timestamp>2016-12-16T09:31:52Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* Rivers */clean up; http&amp;rarr;https for [[The Guardian]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7934">[[Image:Sinuosity.png|thumb|250px|Calculation of '''sinuosity''' for an oscillating curve.]]
[[File:LuzArdidien2003.jpg|thumb|Laces on mountain road with high sinuosity at [[Luz Ardiden]]]]
[[Image:rio-cauto-cuba.JPG|thumb|The meandering ''[[Cauto River|Rio Cauto]]'' at Guamo Embarcadero, [[Cuba]], is not taking the shortest path downslope. Therefore, its '''sinuosity index''' is&amp;nbsp;&gt;&amp;nbsp;1.]]
[[File:Traces de ski dans la neige.jpg|thumb|Two ski tracks with different degrees of sinuosity on the same slope]]

'''Sinuosity''', '''sinuosity index''', or '''sinuosity coefficient''' of a [[Geometrical continuity|continuously differentiable]] [[curve]] having at least one [[inflection point]] is the [[ratio]] of the [[curvilinear length]] (along the curve) and the [[Euclidean distance]] ([[straight line]]) between the end points of the curve. This [[dimensionless quantity]] can also be rephrased as the "actual path length" divided by the "shortest path length" of a curve.
The value ranges from 1 (case of straight line) to infinity (case of a closed loop, where the shortest path length is zero) or for an infinitely-long actual path.&lt;ref&gt;Leopold, Luna B., Wolman, M.G., and Miller, J.P., 1964, Fluvial Processes in Geomorphology, San Francisco, W.H. Freeman and Co., 522p.&lt;/ref&gt;

==Interpretation==
The curve must be continuous (no jump) between the two ends. The sinuosity value is really significant when the line is continuously differentiable (no angular point). The distance between both ends can also be evaluated by a plurality of segments according to a broken line passing through the successive inflection points (sinuosity of order 2).

The calculation of the sinuosity is valid in a 3-dimensional space (e.g. for the central axis of the [[small intestine]]), although it is often performed in a plane (with then a possible [[orthogonal projection]] of the curve in the selected plan; "classic" sinuosity on the horizontal plane, longitudinal profile sinuosity on the vertical plane).

The classification of a sinuosity (e.g. strong / weak) often depends on the [[cartographic scale]] of the curve (see the [[coastline paradox]] for further details) and of the object velocity which flowing therethrough (river, avalanche, car, bicycle, bobsleigh, skier, high speed train, etc.): the sinuosity of the same curved line could be considered very strong for a high speed train but low for a river. Nevertheless, it is possible to see a very strong sinuosity in the succession of few river bends, or of laces on some mountain roads.

==Notable values==

The sinuosity ''S'' of:
* 2 inverted continuous semicircles located in the same plane is &lt;math&gt;S = \tfrac{\pi}{2} \approx 1.5708...&lt;/math&gt;. It is independent of the circle radius;
* a [[sine]] function (over a whole number ''n'' of half-periods), which can be calculated by computing the sine curve's [[arclength]] on those periods, is &lt;math&gt;S = \textstyle \tfrac{1}{n\pi} \int_{0}^{n\pi} \sqrt{1 + (\cos x)^2} dx \approx 1.216...&lt;/math&gt;

[[File:Sinuosite 270.jpg|thumb|right|Example with 270° angle]]
With similar opposite arcs joints in the same plane, continuously differentiable:
{| border="1" cellpadding="4" cellspacing="0"
|-----
! style="background:#ffdead;" colspan="2" | [[Central angle]]
! style="background:#ffdead;" colspan="2" | Sinuosity
|-----
| style="background:#efefef;" align="Center" | [[Degree (angle)|Degrees]]
| style="background:#efefef;" align="Center" | [[Radian]]s
| style="background:#efefef;" align="Center" | Exact
| style="background:#efefef;" align="Center" | Decimal
|-----
| align="Center" | 30° || align="Center" | &lt;math&gt;\frac{\pi}{6}&lt;/math&gt;
| align="Center" | &lt;math&gt;\frac{\pi}{3(\sqrt{6}-\sqrt{2})}&lt;/math&gt; || align="Center" | 1.0115
|-----
| align="Center" | 60° || align="Center" | &lt;math&gt;\frac{\pi}{3}&lt;/math&gt;
| align="Center" | &lt;math&gt;\frac{\pi}{3}&lt;/math&gt; || align="Center" | 1.0472
|-----
| align="Center" | 90° || align="Center" | &lt;math&gt;\frac{\pi}{2}&lt;/math&gt;
| align="Center" | &lt;math&gt;\frac{\pi}{2\sqrt{2}}&lt;/math&gt; || align="Center" | 1.1107
|-----
| align="Center" | 120° || align="Center" | &lt;math&gt;\frac{2\cdot\pi}{3}&lt;/math&gt;
| align="Center" | &lt;math&gt;\frac{2\cdot\pi}{3\sqrt{3}}&lt;/math&gt; || align="Center" | 1.2092
|-----
| align="Center" | 150° || align="Center" | &lt;math&gt;\frac{5\cdot\pi}{6}&lt;/math&gt;
| align="Center" | &lt;math&gt;\frac{5\cdot\pi}{3(\sqrt{6}+\sqrt{2})}&lt;/math&gt; || align="Center" | 1.3552
|-----
| align="Center" | 180° || align="Center" | &lt;math&gt;\pi&lt;/math&gt;
| align="Center" | &lt;math&gt;\frac{\pi}{2}&lt;/math&gt; || align="Center" | 1.5708
|-----
| align="Center" | 210° || align="Center" | &lt;math&gt;\frac{7\cdot\pi}{6}&lt;/math&gt;
| align="Center" | &lt;math&gt;\frac{7\cdot\pi}{3(\sqrt{6}+\sqrt{2})}&lt;/math&gt; || align="Center" | 1.8972
|-----
| align="Center" | 240° || align="Center" | &lt;math&gt;\frac{4\cdot\pi}{3}&lt;/math&gt;
| align="Center" | &lt;math&gt;\frac{4\cdot\pi}{3\sqrt{3}}&lt;/math&gt; || align="Center" | 2.4184
|-----
| align="Center" | 270° || align="Center" | &lt;math&gt;\frac{3\cdot\pi}{2}&lt;/math&gt;
| align="Center" | &lt;math&gt;\frac{3\cdot\pi}{2\sqrt{2}}&lt;/math&gt; || align="Center" | 3.3322
|-----
| align="Center" | 300° || align="Center" | &lt;math&gt;\frac{5\cdot\pi}{3}&lt;/math&gt;
| align="Center" | &lt;math&gt;\frac{5\cdot\pi}{3}&lt;/math&gt; || align="Center" | 5.2360
|-----
| align="Center" | 330° || align="Center" | &lt;math&gt;\frac{11\cdot\pi}{6}&lt;/math&gt;
| align="Center" | &lt;math&gt;\frac{11\cdot\pi}{3(\sqrt{6}-\sqrt{2})}&lt;/math&gt; || align="Center" | 11.1267
|}

==Rivers==
In studies of rivers, the sinuosity index is similar but not identical to the general form given above, being given by:

: &lt;math&gt;\text{SI} = \frac{{\text{channel length}}}{{\text{downvalley length}}}&lt;/math&gt;

The difference from the general form happens because the downvalley path is not perfectly straight. The sinuosity index can be explained, then, as the deviations from a path defined by the direction of maximum downslope. For this reason, bedrock streams that flow directly downslope have a sinuosity index of 1, and [[meander]]ing streams have a sinuosity index that is greater than 1.&lt;ref&gt;{{cite journal
 | doi = 10.1111/j.1467-8306.1968.tb00650.x
 | title = An Introduction to the Hydraulic and Topographic Sinuosity Indexes1
 | year = 1968
 | author = Mueller, Jerry
 | journal = Annals of the Association of American Geographers
 | volume = 58
 | issue = 2
 | pages = 371}}&lt;/ref&gt;

It is also possible to distinguish the case where the stream flowing on the line could not physically travel the distance between the ends: in some hydraulic studies, this leads to assign a sinuosity value of 1 for a torrent flowing over rocky bedrock along a horizontal rectilinear projection, even if the slope angle varies.

For rivers, the conventional classes of sinuosity, SI, are:
*            SI &lt;1.05: almost straight
*     1.05 ≤ SI &lt;1.25: winding
*     1.25 ≤ SI &lt;1.50: twisty 
*     1.50 ≤ SI: meandering

It has been claimed that river shapes are governed by a [[Self-organization|self-organizing system]] that causes their average sinuosity (measured in terms of the source-to-mouth distance, not channel length) to be {{pi}},&lt;ref&gt;{{citation|title=River Meandering as a Self-Organization Process|last=Stølum|first=Hans-Henrik|journal=[[Science (journal)|Science]]|volume=271|issue=5256|pages=1710–1713|doi=10.1126/science.271.5256.1710|bibcode=1996Sci...271.1710S}}.&lt;/ref&gt; but this has not been borne out  by later studies, which found an average value less than 2.&lt;ref&gt;{{citation|title=A meandering tale: the truth about pi and rivers|first=James|last=Grime|department=Alex Bellos's Adventures in Numberland|journal=[[The Guardian]]|date=March 14, 2015|url=https://www.theguardian.com/science/alexs-adventures-in-numberland/2015/mar/14/pi-day-2015-pi-rivers-truth-grime}}.&lt;/ref&gt;

==See also==
* [[Curvature]]
* [[Oxbow lake]]

{{River morphology}}

==References==
{{reflist}}

[[Category:Rivers]]
[[Category:Curves]]
[[Category:Ratios]]
[[Category:Curvature (mathematics)]]</text>
      <sha1>t5q899hrxnkzexhmz1edhg3obx3vn0o</sha1>
    </revision>
  </page>
  <page>
    <title>Standardized moment</title>
    <ns>0</ns>
    <id>202713</id>
    <revision>
      <id>859920398</id>
      <parentid>812335047</parentid>
      <timestamp>2018-09-17T04:30:16Z</timestamp>
      <contributor>
        <username>Kri</username>
        <id>253188</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4491">In [[probability theory]] and [[statistics]], a '''standardized moment''' of a [[probability distribution]] is a moment (normally a higher degree [[central moment]]) that is normalized. The normalization is typically a division by an expression of the [[standard deviation]] which renders the moment scale invariant. This has the advantage that such normalized moments differ only in other properties than variability, facilitating e.g. comparison of shape of different probability distributions.&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=q1clOAAACAAJ|title=The Elements of Statistics: With Applications to Economics and the Social Sciences|last=Ramsey|first=James Bernard|last2=Newton|first2=H. Joseph|last3=Harvill|first3=Jane L.|date=2002-01-01|publisher=Duxbury/Thomson Learning|isbn=9780534371111|pages=96|language=en|chapter=CHAPTER 4 MOMENTS AND THE SHAPE OF HISTOGRAMS|chapter-url=http://www.econ.nyu.edu/user/ramseyj/textbook/viewtext.htm}}&lt;/ref&gt;

== Standard normalization ==
Let ''X'' be a [[random variable]] with a probability distribution ''P'' and mean value &lt;math display="inline"&gt;\mu = \mathrm{E}[X]&lt;/math&gt; (i.e. the first [[Raw moments|raw moment or moment about zero]]), the operator E denoting the [[expected value]] of ''X''. Then the '''standardized moment''' of degree ''k'' is &lt;math&gt;\frac{\mu_k}{\sigma^k},&lt;/math&gt;&lt;ref&gt;{{Cite web|url=http://mathworld.wolfram.com/StandardizedMoment.html|title=Standardized Moment|last=W.|first=Weisstein, Eric|website=mathworld.wolfram.com|language=en|access-date=2016-03-30}}&lt;/ref&gt; that is, the ratio of the ''k''th [[moment about the mean]]

:&lt;math&gt;
\mu_k = \operatorname{E} \left[ ( X - \mu )^k \right]  = \int_{-\infty}^{\infty} (x - \mu)^k P(x)\,dx,
&lt;/math&gt;

to the ''k''th power of the [[standard deviation]],

:&lt;math&gt;\sigma^k = \left(\sqrt{\mathrm{E}[(X - \mu)^2]}\right)^k.&lt;/math&gt;

The power of ''k'' is because moments scale as &lt;math&gt;x^k,&lt;/math&gt; meaning that &lt;math&gt;\mu_k(\lambda X) = \lambda^k \mu_k(X):&lt;/math&gt; they are [[homogeneous function]]s of degree ''k'', thus the standardized moment is [[scale invariant]]. This can also be understood as being because moments have dimension; in the above ratio defining standardized moments, the dimensions cancel, so they are [[dimensionless number]]s.

The first four standardized moments can be written as:
{| class="wikitable"
!Degree ''k''
!
!Comment
|-
|1
|&lt;math&gt;
\tilde{\mu}_1 = \frac{\mu_1}{\sigma^1} = \frac{\operatorname{E} \left[ ( X - \mu )^1 \right]}{( \operatorname{E} \left[ ( X - \mu )^2 \right])^{1/2}} = \frac{\mu - \mu}{\sqrt{ \operatorname{E} \left[ ( X - \mu )^2 \right]}} = 0
&lt;/math&gt;
|The first standardized moment is zero, because the first moment about the mean is always zero.
|-
|2
|&lt;math&gt;
\tilde{\mu}_2 = \frac{\mu_2}{\sigma^2} = \frac{\operatorname{E} \left[ ( X - \mu )^2 \right]}{( \operatorname{E} \left[ ( X - \mu )^2 \right])^{2/2}} = 1
&lt;/math&gt;
|The second standardized moment is one, because the second moment about the mean is equal to the [[variance]] σ&lt;sup&gt;2&lt;/sup&gt;.
|-
|3
|&lt;math&gt;
\tilde{\mu}_3 = \frac{\mu_3}{\sigma^3} = \frac{\operatorname{E} \left[ ( X - \mu )^3 \right]}{( \operatorname{E} \left[ ( X - \mu )^2 \right])^{3/2}}
&lt;/math&gt;
|The third standardized moment is a measure of [[skewness]].
|-
|4
|&lt;math&gt;
\tilde{\mu}_4 = \frac{\mu_4}{\sigma^4} = \frac{\operatorname{E} \left[ ( X - \mu )^4 \right]}{( \operatorname{E} \left[ ( X - \mu )^2 \right])^{4/2}}
&lt;/math&gt;
|The fourth standardized moment refers to the [[kurtosis]].
|}
For skewness and kurtosis, alternative definitions exist, which are based on the third and fourth [[cumulant]] respectively.

== Other normalizations ==
{{Details|Normalization (statistics)}}
Another scale invariant, dimensionless measure for characteristics of a distribution is the [[coefficient of variation]], &lt;math&gt;\frac{\sigma}{\mu}&lt;/math&gt;. However, this is not a standardized moment, firstly because it is a reciprocal, and secondly because &lt;math&gt;\mu&lt;/math&gt; is the first moment about zero (the mean), not the first moment about the mean (which is zero).

See [[Normalization (statistics)]] for further normalizing ratios.

== See also ==
*[[Coefficient of variation]]
*[[Moment (mathematics)]]
*[[Central moment]]
*[[Standard score#Other normalizations|Standard score: Other normalizations]]

== References ==
&lt;references /&gt;
{{Statistics}}

{{DEFAULTSORT:Standardized Moment}}
[[Category:Statistical deviation and dispersion]]
[[Category:Statistical ratios]]
[[Category:Moment (mathematics)]]</text>
      <sha1>f1djstr3ib79ys8jea49iavbd9vjukg</sha1>
    </revision>
  </page>
  <page>
    <title>Superadditivity</title>
    <ns>0</ns>
    <id>1464384</id>
    <revision>
      <id>849130188</id>
      <parentid>821103222</parentid>
      <timestamp>2018-07-06T18:59:07Z</timestamp>
      <contributor>
        <ip>4.34.225.130</ip>
      </contributor>
      <comment>reformatted what looked to be commentary. Probably belongs in the talk page.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4134">In mathematics, a [[sequence]] { ''a&lt;sub&gt;n&lt;/sub&gt;'' }, ''n'' ≥ 1, is called '''superadditive''' if it satisfies the [[inequality (mathematics)|inequality]]

: &lt;math&gt;a_{n+m} \geq a_n+a_m&lt;/math&gt;

for all ''m'' and ''n''.  The major reason for the use of superadditive sequences is the following [[lemma (mathematics)|lemma]] due to [[Michael Fekete]].&lt;ref&gt;{{cite journal |last=Fekete |first=M. |title=Über die Verteilung der Wurzeln bei gewissen algebraischen Gleichungen mit ganzzahligen Koeffizienten |journal=Mathematische Zeitschrift |volume=17 |issue=1 |year=1923 |pages=228–249 |doi=10.1007/BF01504345 }}&lt;/ref&gt;

'''Lemma:''' (Fekete) For every superadditive sequence { ''a&lt;sub&gt;n&lt;/sub&gt;'' }, ''n'' ≥ 1, the limit lim ''a&lt;sub&gt;n&lt;/sub&gt;''/''n'' exists and is equal to sup ''a&lt;sub&gt;n&lt;/sub&gt;''/''n''.  (The limit may be positive infinity, for instance, for the sequence ''a&lt;sub&gt;n&lt;/sub&gt;'' = log&amp;nbsp;''n''&lt;nowiki&gt;!&lt;/nowiki&gt;.)

Similarly, a [[function (mathematics)|function]] ''f'' is ''superadditive'' if

: &lt;math&gt;f(x+y) \geq f(x)+f(y)&lt;/math&gt;

for all ''x'' and ''y'' in the [[domain (mathematics)|domain]] of ''f''.

For example, &lt;math&gt;f(x)=x^2&lt;/math&gt; is a superadditive function for nonnegative real numbers because the square of &lt;math&gt;(x+y)&lt;/math&gt; is always greater than or equal to the square of &lt;math&gt;x&lt;/math&gt; plus the square of &lt;math&gt;y&lt;/math&gt;, for nonnegative real numbers &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt;.

The analogue of Fekete's lemma holds for subadditive functions as well.
There are extensions of Fekete's lemma that do not require the definition of superadditivity above to hold for all ''m'' and ''n''.  There are also results that allow one to deduce the rate of convergence to the limit whose existence is stated in Fekete's lemma if some kind of both superadditivity and [[subadditivity]] is present. A good exposition of this topic may be found in Steele (1997).&lt;ref&gt;{{cite book|author=Michael J. Steele|title=Probability theory and combinatorial optimization|publisher=SIAM, Philadelphia|year=1997|isbn=0-89871-380-3}}&lt;/ref&gt;&lt;ref&gt;{{cite video|author=Michael J. Steele|title=CBMS Lectures on Probability Theory and Combinatorial Optimization|publisher=University of Cambridge|year=2011|url=http://sms.cam.ac.uk/collection/1189351}}&lt;/ref&gt;

If ''f'' is a superadditive function, and if 0 is in its domain, then ''f''(0) ≤ 0. To see this, take the inequality at the top. &lt;math&gt;f(x) \le f(x+y) - f(y)&lt;/math&gt;. Hence &lt;math&gt;f(0) \le f(0+y) - f(y) = 0&lt;/math&gt;

The negative of a superadditive function is [[subadditivity|subadditive]].

== Examples of superadditive functions ==
* The determinant is superadditive for nonnegative Hermitian matrices, i.e., If &lt;math&gt;A,B\in\text{Mat}_n(\mathbb{C})&lt;/math&gt; are nonnegative Hermitian then &lt;math&gt;\det(A+B)\geq\det(A)+\det(B)&lt;/math&gt;.
This follows from the Minkowski determinant theorem, which more generally states that &lt;math&gt; \det(\cdot)^{1/n}&lt;/math&gt; is superadditive (equivalently, concave)&lt;ref&gt;M. Marcus, H. Minc (1992). [https://books.google.pt/books?id=hLHKwSNqLOcC ''A survey in matrix theory and matrix inequalities'']. Dover. Theorem 4.1.8, page 115.&lt;/ref&gt; for nonnegative Hermitian matrices of size ''n'': If &lt;math&gt;A,B\in\text{Mat}_n(\mathbb{C})&lt;/math&gt; are nonnegative Hermitian then &lt;math&gt;\det(A+B)^{1/n}\geq\det(A)^{1/n}+\det(B)^{1/n}&lt;/math&gt;.
* [[Mutual information]]. &lt;sup&gt;&lt;nowiki&gt;[[That is not true! This is NOT superadditive (e.g. Nielsen, Chuang)]]&lt;/nowiki&gt;&lt;/sup&gt;
* Horst Alzer proved &lt;ref&gt;{{cite book|author=Horst Alzer|title=A superadditive property of Hadamard's gamma function| publisher=Springer|year=2009| doi=10.1007/s12188-008-0009-5}}&lt;/ref&gt; that [[Hadamard's gamma function]] H(''x'') is superadditive for all real numbers ''x'',''y'' with ''x'', ''y'' &amp;ge; 1.5031.

==See also==
*[[Choquet integral]]
*[[Subadditivity]]

== References ==
{{reflist}}
;Notes
*{{cite book|author=György Polya and Gábor Szegö.|title=Problems and theorems in analysis, volume 1|publisher=Springer-Verlag, New York|year=1976|isbn=0-387-05672-6}}

{{PlanetMath attribution|id=4616|title=Superadditivity}}

[[Category:Mathematical analysis]]
[[Category:Sequences and series]]</text>
      <sha1>4vse2m1ydtjmtttz82kkwme90rtytfn</sha1>
    </revision>
  </page>
  <page>
    <title>Susanna S. Epp</title>
    <ns>0</ns>
    <id>32668461</id>
    <revision>
      <id>870911605</id>
      <parentid>838054473</parentid>
      <timestamp>2018-11-27T19:19:03Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>more ids, birth year</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6827">{{Infobox scientist
| honorific_prefix  =  
| name              = Susanna S. Epp
| honorific_suffix  =
| native_name       = 
| native_name_lang  = 
| image             = &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size        = 
| image_upright     = 
| alt               = 
| caption           = 
| birth_date        = {{birth year|1943}}
| birth_place       = 
| death_date        = &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place       = 
| death_cause       = 
| resting_place     = 
| resting_place_coordinates = &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names       = 
| residence         = 
| citizenship       = 
| nationality       = 
| fields            = 
| workplaces        = 
| patrons           = 
| education         = {{Plainlist|
* Ph.D. (Mathematics) University of Chicago, 1968
* M.S. (Mathematics) University of Chicago, 1965
* B.A. with highest distinction (Mathematics) Northwestern University, 1964
}}
| alma_mater        = 
| thesis_title      = Submodules of Cayley Algebras
| thesis_url        = http://www.sciencedirect.com/science/article/pii/0021869373901567
| thesis_year       = 1971
| doctoral_advisor  = Irving Kaplansky
| academic_advisors = 
| doctoral_students = 
| notable_students  = 
| known_for         = 
| influences        = 
| influenced        = 
| awards            = {{Plainlist|
* Louise Hay Award for Contributions to Mathematics Education (AWM Prizes)&lt;ref&gt;{{cite web|title=Prizes and Awards at the Joint Mathematics Meetings in Atlanta. Mathematical Association of America|url=https://www.maa.org/prizes-and-awards-at-the-joint-mathematics-meetings-in-atlanta|website=www.maa.org}}&lt;/ref&gt;
}}
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse            = &lt;!--(or | spouses = )--&gt;
| partner           = &lt;!--(or | partners = )--&gt;
| children          = 
| signature         = &lt;!--(filename only)--&gt;
| signature_alt     = 
| website           = http://condor.depaul.edu/sepp/
| footnotes         = 
}}
'''Susanna Samuels Epp''' (born 1943)&lt;ref&gt;Birth year from [https://portal.dnb.de/opac.htm?method=simpleSearch&amp;cqlMode=true&amp;query=nid%3D1136686010 German national library catalogue data], retrieved 2018-11-27.&lt;/ref&gt; is an [[author]], [[mathematician]], and [[professor]].  Her interests include [[discrete mathematics]], [[mathematical logic]], [[cognitive psychology]], and [[mathematics education]], and she has written numerous articles, publications, and textbooks.  She is currently professor emerita at [[DePaul University]], where she chaired the Department of Mathematical Sciences and was Vincent de Paul Professor in Mathematics.

Epp holds degrees in mathematics from [[Northwestern University]] and the [[University of Chicago]], where she completed her doctorate in 1968 under the supervision of [[Irving Kaplansky]].&lt;ref&gt;{{mathgenealogy|id=5705}}&lt;/ref&gt; She taught at [[Boston University]] and at the [[University of Illinois at Chicago]] before becoming a professor at DePaul University.&lt;ref name="hay"/&gt;

Initially researching [[commutative algebra]], Epp became interested by cognitive psychology, especially in education of Mathematics, [[Logic]], [[Mathematical proof|Proof]], and the [[Language of mathematics]].  She wrote several articles about teaching logic and proof in ''[[American Mathematical Monthly]]'', and the ''Mathematics Teacher'', a Journal by the [[National Council of Teachers of Mathematics]].

She is the author of several books including ''Discrete Mathematics with Applications'' (4th ed., Brooks/Cole, 2011), the third edition of which earned a Textbook Excellence Award from the [[Textbook and Academic Authors Association]].&lt;ref&gt;{{citation| url=http://www.taaonline.net/past-textbook-award-recipients | title=Discrete Mathematics with Applications, 3rd Ed. Author: Susanna Epp | accessdate=2016-04-04}}&lt;/ref&gt;

"By combining discussion of theory and practice, I have tried to show that mathematics has engaging and important applications as well as being interesting and beautiful in its own right" - Susanna S. Epp wrote in the Preface of the 4th Edition of ''Discrete Mathematics.''

In 2005, she received the [[Louise Hay Award]] from the [[Association for Women in Mathematics]] in recognition for her contributions to mathematics education.&lt;ref name="hay"&gt;{{citation|url=http://www.awm-math.org/hayaward/2005.html|title=Fifteenth Annual Louise Hay Award Citation: Susanna S. Epp|accessdate=2015-08-29}}&lt;/ref&gt;

==Selected publications==
* Epp, S.S., Discrete Mathematics with Applications, 4th ed., Brooks/Cole (Cengage Learning), 2011. {{ISBN|978-0-495-39132-6}}
* Epp, S.S., Variables in Mathematics Education. In Tools for Teaching Logic. Blackburn, P., van Ditmarsch, H., et al., eds. Springer Publishing, 2011. (Reprinted in Best Writing on Mathematics 2012, M. Pitici, Ed. Princeton Univ. Press, Nov. 2012.)
* Epp, S.S., V. Durand-Guerrier, et al. Argumentation and proof in the mathematics classroom. In Proof and Proving in Mathematics Education, G. Hanna &amp; M. de Villiers Eds. Springer Publishing. (co-authors: V. Durand-Guerrier, P. Boero, N. Douek, D. Tanguay), 2012.
* Epp, S.S., V. Durand-Guerrier, et al.  Examining the role of logic in teaching proof. In Proof and Proving in Mathematics Education, G. Hanna &amp; M. de Villiers Eds. Springer Publishing, 2012.
* Epp, S.S., Proof Issues with Existential Quantification. In Proof and Proving in Mathematics Education: ICMI Study 19 Conference Proceedings, F. L. Lin et al. eds., National Taiwan Normal University, 2009.
* Epp, S.S., The Use of Logic in Teaching Proof. In Resources for Teaching Discrete Mathematics. B. Hopkins, ed. Washington, DC: Mathematical Association of America, 2009, pp.&amp;nbsp;313–322. 
* Epp, S.S., The Role of Logic in Teaching Proof, American Mathematical Monthly (110)10, Dec. 2003, 886-899
* Epp, S.S., The Language of Quantification in Mathematics Instruction. In Developing Mathematical Reasoning in Grades K-12. Lee V. Stiff, Ed. Reston, VA: NCTM Publications, 1999, 188-197. 
* Epp, S.S., The Role of Proof in Problem Solving. In Mathematical Thinking and Problem Solving. Alan H. Schoenfeld, Ed. Hillsdale, NJ: Lawrence Erlbaum Associates, Inc., Publishers, 1994, 257-269.

==References==
{{Reflist}}

==External links==
* [http://condor.depaul.edu/sepp/ Susanna Epp's webpage at De Paul]
* [http://www.awm-math.org/hayaward/2005.html Fifteenth Annual Louise Hay Award], contains a brief biography of Susanna S. Epp.

{{Authority control|MGP=5705|LCCN=n88246114|VIAF=111187615|ISNI=000000008303293X}}

{{DEFAULTSORT:Epp, Susanna}}
[[Category:1943 births
[[Category:21st-century American mathematicians]]
[[Category:Women mathematicians]]
[[Category:Living people]]
[[Category:DePaul University faculty]]
[[Category:Mathematical logicians]]</text>
      <sha1>sqamv72e9avorep290gw1rqe396bzau</sha1>
    </revision>
  </page>
  <page>
    <title>Table of simple cubic graphs</title>
    <ns>0</ns>
    <id>28918145</id>
    <revision>
      <id>867377865</id>
      <parentid>863078077</parentid>
      <timestamp>2018-11-05T09:38:40Z</timestamp>
      <contributor>
        <ip>149.217.44.220</ip>
      </contributor>
      <comment>/* References */ corrected broken link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="31321">The connected 3-regular ([[Cubic graph|cubic]]) [[Simple graph#Simple graph|simple]] graphs are listed for small vertex numbers.

==Connectivity==
The number of simple cubic graphs on 4, 6, 8, 10, ... vertices  is  1, 2, 5, 19, ... {{OEIS|A002851}}. A classification according to edge [[Connectivity (graph theory)|connectivity]] is made as follows: the 1-connected and 2-connected graphs are defined as usual. This leaves the other graphs in the 3-connected class because each
3-regular graph can be split by cutting all edges adjacent to any of the vertices. To refine this definition in the light of the algebra of [[Angular momentum coupling|coupling of angular momenta]] (see below), a subdivision of the 3-connected graphs is helpful. We shall call
* Non-trivially 3-connected those that can be split by 3 edge cuts into sub-graphs with at least two vertices remaining in each part
* Cyclically 4-connected&amp;mdash;all those not 1-connected, not 2-connected, and not non-trivially 3-connected
This declares the numbers 3 and 4 in the fourth column of the tables below.

==Pictures==
Ball-and-stick models of the graphs in another column of the
table show the vertices and edges in the style of
images of molecular bonds.
Comments on the individual pictures contain
[[Girth (graph theory)|girth]], [[Distance (graph theory)|diameter]], [[Wiener index]],
[[Estrada index]] and [[Resistance distance|Kirchhoff index]].
A Hamiltonian circuit (where present) is indicated by enumerating vertices
along that path from 1 upwards.
(The positions of the vertices have been defined by minimizing a pair potential defined by the squared difference of the Euclidean and graph theoretic distance, placed in a [[MDL Molfile|Molfile]], then rendered by [[Jmol]].)

==LCF notation==
The '''[[LCF notation]]''' is a notation by [[Joshua Lederberg]], [[Harold Scott MacDonald Coxeter|Coxeter]] and [[Robert Frucht|Frucht]], for the representation of [[cubic graph]]s that are [[Hamiltonian path|Hamiltonian]].

The two edges along the cycle adjacent to any of the vertices are not written down.

Let {{math|v}} be the vertices of the graph and describe the Hamiltonian circle along the {{math|p}} vertices by the edge sequence {{math|v&lt;sub&gt;0&lt;/sub&gt;v&lt;sub&gt;1&lt;/sub&gt;, v&lt;sub&gt;1&lt;/sub&gt;v&lt;sub&gt;2&lt;/sub&gt;, ...,v&lt;sub&gt;p−2&lt;/sub&gt;v&lt;sub&gt;p−1&lt;/sub&gt;, v&lt;sub&gt;p−1&lt;/sub&gt;v&lt;sub&gt;0&lt;/sub&gt;}}. Halting at a vertex {{math|v&lt;sub&gt;i&lt;/sub&gt;}}, there is one unique vertex {{math|v&lt;sub&gt;j&lt;/sub&gt;}} at a [[Distance (graph theory)|distance]] {{math|d&lt;sub&gt;i&lt;/sub&gt;}} joined by a chord with {{math|v&lt;sub&gt;i&lt;/sub&gt;}},
:&lt;math&gt; j=i+d_i\quad (\bmod\, p),\quad 2\le d_i\le p-2.&lt;/math&gt;
The vector {{math|[d&lt;sub&gt;0&lt;/sub&gt;, d&lt;sub&gt;1&lt;/sub&gt;, ..., d&lt;sub&gt;p−1&lt;/sub&gt;]}} of the {{math|p}} integers is a suitable, although not unique, representation of the cubic Hamiltonian graph. This is augmented by two additional rules:
# If a {{math|d&lt;sub&gt;i&lt;/sub&gt; &gt; p/2}}, replace it by {{math|d&lt;sub&gt;i&lt;/sub&gt; − p}};
# avoid repetition of a sequence of {{math|d&lt;sub&gt;i&lt;/sub&gt;}} if these are periodic and replace them by an exponential notation.
Since the starting vertex of the path is of no importance, the numbers in the representation may be cyclically permuted. If a graph contains different Hamiltonian circuits, one may select one of these to accommodate the notation. The same graph may have different LCF notations, depending on precisely how the vertices are arranged.

Often the anti-palindromic representations with
:&lt;math&gt; d_{p-1-i}= -d_i \quad (\bmod\,p), \quad i=0,1,\ldots p/2-1&lt;/math&gt;
are preferred (if they exist), and the redundant part is then replaced by a semicolon and a dash "; –". The LCF notation {{math|[5, −9, 7, −7, 9, −5]&lt;sup&gt;4&lt;/sup&gt;}}, for example, and would at that stage be condensed to {{math|[5, −9, 7; –]&lt;sup&gt;4&lt;/sup&gt;}}.

==Table==
===4 vertices===

{| class="wikitable"
|-
|diam. || girth || Aut. || connect. || LCF || [[Gallery of named graphs|names]] || picture
|-
|1 || 3 || 24 ||4 || [2]&lt;sup&gt;4&lt;/sup&gt;  || [[Complete graph|K&lt;sub&gt;4&lt;/sub&gt;]] || [[File:GraphY4W6EE2118918.jpg|thumb|4 vertices and 6 edges. Yutsis graph of the [[6-j symbol]] ]]
|}

===6 vertices===
{|class="wikitable"
|diam.||girth||Aut.||connect.  || LCF || [[Gallery of named graphs|names]] || picture
|-
|2||3||12||3  || [2, 3, −2]&lt;sup&gt;2&lt;/sup&gt;  || prism graph Y&lt;sub&gt;3&lt;/sub&gt; || [[File:GraphY6W21EE2507449.jpg|thumb|6 vertices and 9 edges]]
|-
|2||4||72||4  || [3]&lt;sup&gt;6&lt;/sup&gt;  || [[Complete bipartite graph|K&lt;sub&gt;3, 3&lt;/sub&gt;]],  [[Water, gas, and electricity|utility graph]]|| [[File:GraphY6W21EE2413532.jpg|thumb|6 vertices and 9 edges. Yutsis graph of the [[9-j symbol]]. ]]
|}

===8 vertices===
{| class="wikitable"
|-
|diam.||girth||Aut.||connect. || LCF || [[Gallery of named graphs|names]] || pictures
|-
|3||3||16 ||2  || [2, 2, −2, −2]&lt;sup&gt;2&lt;/sup&gt;  || || [[File:Y8W50EE3373868.jpg|thumb|8 vertices and 12 edges]]
|-
|3||3||4||3  || [4, −2, 4, 2]&lt;sup&gt;2&lt;/sup&gt; or [2, 3, −2, 3; –] || || [[File:Y8W46EE3097135.jpg|thumb|8 vertices and 12 edges]]
|-
|2||3||12||3  || [2, 4, −2, 3, 3, 4, −3, −3]  || || [[File:Y8W44EE3003607.jpg|thumb|8 vertices and 12 edges]]
|-
|3||4||48||4  || [−3, 3]&lt;sup&gt;4&lt;/sup&gt;  || [[Hypercube graph|cubical graph]] || [[File:GraphY8W48EE2939381.jpg|thumb|8 vertices and 12 edges. Yutsis graph of the 12j-symbol of the second kind.]]
|-
|2||4||16||4  || [4]&lt;sup&gt;8&lt;/sup&gt; or [4, −3, 3, 4]&lt;sup&gt;2&lt;/sup&gt; || [[Wagner graph]] || [[File:GraphY8W44EE2909522.jpg|thumb|8 vertices and 12 edges. Yutsis graph of the 12j-symbol of the first kind.]]
|-
|}

===10 vertices===
{|class="wikitable"
|diam.||girth||Aut.||connect. || LCF || [[Gallery of named graphs|names]] || pictures
|-
|5||3||32||1  ||   || Edge list 0–1, 0–6, 0–9, 1–2, 1–5, 2–3, 2–4, 3–4,  &lt;br&gt; 3–5, 4–5, 6–7, 6–8, 7–8, 7–9, 8–9 || [[File:GraphY10W111EE4260094.jpg|thumb|10 vertices and 15 edges]]
|-
|4||3||4||2  || [4, 2, 3, −2, −4, −3, 2, 2, −2, −2]  || || [[File:GraphY10W91EE3941746.jpg|thumb|]]
|-
|3||3||8||2  || [2, −3, −2, 2, 2; –]  || || [[File:GraphY10W90EE4039508.jpg|thumb|]]
|-
|3||3||16||2  || [−2, −2, 3, 3, 3; –] || || [[File:Y10W90EE3890980.jpg|thumb|]]
|-
|4||3||16||2  || [2, 2, −2, −2, 5]&lt;sup&gt;2&lt;/sup&gt;  || || [[File:GraphY10W93EE4069426.jpg|thumb|]]
|-
|3||3||2||3  || [2, 3, −2, 5, −3]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [3, −2, 4, −3, 4, 2, −4, −2, −4, 2]
 || || [[File:GraphY10W85EE3744960.jpg|thumb|]]
|-
|3||3||12||3  || [2, −4, −2, 5, 2, 4, −2, 4, 5, −4]  || || [[File:GraphY10W81EE3677120.jpg|thumb|10 vertices and 15 edges]]
|-
|3||3||2||3  || [5, 3, 5, −4, −3, 5, 2, 5, −2, 4] &lt;br&gt; [−4, 2, 5, −2, 4, 4, 4, 5, −4, −4] &lt;br&gt; [−3, 2, 4, −2, 4, 4, −4, 3, −4, −4] 
 || || [[File:GraphY10W82EE3600347.jpg|thumb|10 vertices and 15 edges]]
|-
|3||3||4||3  || [−4, 3, 3, 5, −3, −3, 4, 2, 5, −2] &lt;br&gt; [3, −4, −3, −3, 2, 3, −2, 4, −3, 3]
  || || [[File:GraphY10W85EE3668162.jpg|thumb|]]
|-
|3||3||6||3  || [3, −3, 5, −3, 2, 4, −2, 5, 3, −4]  || || [[File:Y10W84EE3625442.jpg|thumb|]]
|-
|3||3||4||3  || [2, 3, −2, 3, −3; –] &lt;br&gt; [−4, 4, 2, 5, −2]&lt;sup&gt;2&lt;/sup&gt;  || || [[File:Y10W87EE3769671.jpg|thumb|]]
|-
|3||3||6||3  || [5, −2, 2, 4, −2, 5, 2, −4, −2, 2]  || || [[File:GraphY10W84EE3801880.jpg|thumb|]]
|-
|3||3||8||3  || [2, 5, −2, 5, 5]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [2, 4, −2, 3, 4; –]
 || || [[File:GraphY10W83EE3701785.jpg|thumb|10 vertices and 15 edges]]
|-
|3||4||48||3  || [5, −3, −3, 3, 3]&lt;sup&gt;2&lt;/sup&gt;  || || [[File:GraphY10W85EE3583204.jpg|thumb|]]
|-
|3||4||8||4  || [5, −4, 4, −4, 4]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [5, −4, −3, 3, 4, 5, −3, 4, −4, 3] 
 || || [[File:GraphY10W79EE3472233.jpg|thumb|Yutsis graph of the 15j-symbol of the third kind.]]
|-
|3||4||4||4  || [5, −4, 4, 5, 5]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [−3, 4, −3, 3, 4; –] &lt;br&gt; [4, −3, 4, 4, −4; –]&lt;br&gt; [−4, 3, 5, 5, −3, 4, 4, 5, 5, −4]
  || || [[File:GraphY10W81EE3497449.jpg|thumb|Yutsis graph of the 15j-symbol of the fourth kind.]]
|-
|3||4||20||4  || [5]&lt;sup&gt;10&lt;/sup&gt; &lt;br&gt; [−3, 3]&lt;sup&gt;5&lt;/sup&gt; &lt;br&gt; [5, 5, −3, 5, 3]&lt;sup&gt;2&lt;/sup&gt;
 || || [[File:GraphY10W85EE3540679.jpg|thumb|Yutsis graph of the 15j-symbol of the first kind.]]
|-
|3||4||20||4  || [−4, 4, −3, 5, 3]&lt;sup&gt;2&lt;/sup&gt;  || G&lt;sub&gt;5, 2&lt;/sub&gt; || [[File:GraphY10W85EE3547908.jpg|thumb|Yutsis graph of the 15j-symbol of the second kind.]]
|-
|2||5||120||4  ||   || [[Petersen graph]] || [[File:Y10W75EE3421829.jpg|thumb|Yutsis graph of the 15j-symbol of the fifth kind.]]
|}

===12 vertices===
{|class="wikitable"
|diam.||girth||Aut.||connect. || LCF ||  [[Gallery of named graphs|names]] || picture
|-
|6 ||3 ||16 || 1   || || Edge list 0–1, 0–2, 0–11, 1–2, 1–6,  &lt;br&gt; 2–3, 3–4, 3–5, 4–5, 4–6,  &lt;br&gt; 5–6, 7–8, 7–9, 7–11, 8–9,  &lt;br&gt; 8–10, 9–10, 10–11 || [[File:GraphY12W184EE4984524.jpg|thumb|]]
|-
|5||3||16||1  ||   || Edge list 0–1, 0–6, 0–11, 1–2, 1–3, &lt;br&gt; 2–3, 2–5, 3–4, 4–5, 4–6,  &lt;br&gt; 5–6, 7–8, 7–9, 7–11, &lt;br&gt; 8–9, 8–10, 9–10, 10–11 || [[File:GraphY12W172EE4845339.jpg|thumb|]]
|-
|6||3||8||1  ||   || Edge list 0–1, 0–3, 0–11, 1–2, 1–6, &lt;br&gt; 2–3, 2–5, 3–4, 4–5, 4–6,  &lt;br&gt; 5–6, 7–8, 7–9, 7–11, 8–9, &lt;br&gt; 8–10, 9–10, 10–11 || [[File:GraphY12W178EE4778916.jpg|thumb|]]
|-
|5||3||32||1  ||   || Edge list 0–1, 0–6, 0–11, 1–2, 1–4,  &lt;br&gt; 2–3, 2–5, 3–4, 3–6, 4–5,  &lt;br&gt; 5–6, 7–8, 7–9, 7–11, 8–9,  &lt;br&gt; 8–10, 9–10, 10–11 ||[[File:GraphY12W172EE4710611.jpg|thumb|]] 
|-
|5||3||4||2  ||  [3, −2, −4, −3, 4, 2]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [4, 2, 3, −2, −4, −3; –] || || [[File:GraphY12W150EE4512486.jpg|thumb|]]
|-
|4||3||8||2  ||  [3, −2, −4, −3, 3, 3, 3, −3, −3, −3, 4, 2] || || [[File:GraphY12W149EE4463116.jpg|thumb|]]
|-
|4||3||4||2  || [4, 2, 3, −2, −4, −3, 2, 3, −2, 2, −3, −2] || || [[File:GraphY12W149EE4612066.jpg|thumb|]]
|-
|4||4||64||2  || [3, 3, 3, −3, −3, −3]&lt;sup&gt;2&lt;/sup&gt; || || [[File:GraphY12W152EE4414446.jpg|thumb|]]
|-
|4||3||16||2  || [2, −3, −2, 3, 3, 3; –] || || [[File:GraphY12W152EE4563732.jpg|thumb|]]
|-
|4||3||16||2  || [2, 3, −2, 2, −3, −2]&lt;sup&gt;2&lt;/sup&gt; || || [[File:GraphY12W152EE4713249.jpg|thumb|]]
|-
|4||3|| 2||2  || [−2, 3, 6, 3, −3, 2, −3, −2, 6, 2, 2, −2] &lt;br&gt; [4, 2, −4, −2, −4, 6, 2, 2, −2, −2, 4, 6] || || [[File:GraphY12W149EE4589062.jpg|thumb|]]
|-
|4||3||8||2  || [6, 3, 3, 4, −3, −3, 6, −4, 2, 2, −2, −2] || || [[File:GraphY12W146EE4494265.jpg|thumb|]]
|-
|5||3||4||2  || [4, 2, 3, −2, −4, −3, 5, 2, 2, −2, −2, −5] || || [[File:GraphY12W154EE4630261.jpg|thumb|]]
|-
| 4|| 3|| 16||2  || [−3, −3, −3, 5, 2, 2; –] || || [[File:GraphY12W153EE4576519.jpg|thumb|]]
|-
|4 || 3|| 8||2  || [2, −3, −2, 5, 2, 2; –] || || [[File:GraphY12W153EE4722986.jpg|thumb|]]
|-
|4 || 3|| 4||2  || [2, 4, −2, 3, −5, −4, −3, 2, 2, −2, −2, 5] &lt;br&gt; [5, 2, −4, −2, −5, −5, 2, 2, −2, −2, 4, 5] || || [[File:GraphY12W143EE4558501.jpg|thumb|]]
|-
|4 || 3|| 4||2  || [−2, −2, 4, 4, 4, 4; –] &lt;br&gt; [3, −4, −4, −3, 2, 2; –] &lt;br&gt; [5, 3, 4, 4, −3, −5, −4, −4, 2, 2, −2, −2] || || [[File:GraphY12W145EE4490052.jpg|thumb|]]
|-
|4 || 3|| 2||2  ||  [4, −2, 4, 2, −4, −2, −4, 2, 2, −2, −2, 2] &lt;br&gt; [5, −2, 2, 3, −2, −5, −3, 2, 2, −2, −2, 2] || || [[File:GraphY12W148EE4695537.jpg|thumb|]]
|-
|5 || 3|| 16||2  || [2, 2, −2, −2, −5, 5]&lt;sup&gt;2&lt;/sup&gt; || || [[File:GraphY12W160EE4772073.jpg|thumb|]]
|- 
|4 || 3|| 8||2  || [−2, −2, 4, 5, 3, 4; –] || || [[File:GraphY12W141EE4463910.jpg|thumb|]]
|-
|4 || 3|| 4||2  || [5, 2, −3, −2, 6, −5, 2, 2, −2, −2, 6, 3] || || [[File:GraphY12W146EE4563214.jpg|thumb|]]
|-
|4 || 3|| 8||2  || [4, −2, 3, 3, −4, −3, −3, 2, 2, −2, −2, 2] || || [[File:GraphY12W150EE4628096.jpg|thumb|]]
|-
|4 || 3|| 8||2  || [−2, −2, 5, 3, 5, 3; –] &lt;br&gt; [−2, −2, 3, 5, 3, −3; –] || || [[File:GraphY12W147EE4505416.jpg|thumb|]]
|-
| 5|| 3|| 32||2  || [2, 2, −2, −2, 6, 6]&lt;sup&gt;2&lt;/sup&gt; || || [[File:GraphY12W158EE4735563.jpg|thumb|]]
|-
|4 || 3|| 8||2  || [−3, 2, −3, −2, 2, 2; –] || || [[File:GraphY12W152EE4739504.jpg|thumb|]]
|-
|4 || 3||| 8||2  || [−2, −2, 5, 2, 5, −2; –] || || [[File:GraphY12W143EE4651523.jpg|thumb|]]
|-
|4 || 3|| 8||2  || [6, −2, 2, 2, −2, −2, 6, 2, 2, −2, −2, 2] || || [[File:GraphY12W153EE4840271.jpg|thumb|]]
|-
|4 || 3|| 48||2  || [−2, −2, 2, 2]&lt;sup&gt;3&lt;/sup&gt; || ||[[File:GraphY12W162EE5042874.jpg|thumb|]] 
|-
|4 || 3|| 4||3  || [2, 3, −2, 3, −3, 3; –] &lt;br&gt; [−4, 6, 4, 2, 6, −2]&lt;sup&gt;2&lt;/sup&gt; || || [[File:GraphY12W144EE4466589.jpg|thumb|]]
|-
|4 || 3|| 4||3  || [−4, 6, 3, 3, 6, −3, −3, 6, 4, 2, 6, −2] &lt;br&gt; [−2, 3, −3, 4, −3, 3, 3, −4, −3, −3, 2, 3] || || [[File:GraphY12W140EE4361888.jpg|thumb|]]
|-
| 4|| 3|| 1||3  || [−5, 2, −3, −2, 6, 4, 2, 5, −2, −4, 6, 3] &lt;br&gt; [−2, 3, −3, 4, −3, 4, 2, −4, −2, −4, 2, 3] &lt;br&gt; [3, −2, 3, −3, 5, −3, 2, 3, −2, −5, −3, 2] || || [[File:GraphY12W142EE4432053.jpg|thumb|]]
|-
| 3|| 3|| 4||3  ||  [−5, −5, 4, 2, 6, −2, −4, 5, 5, 2, 6, −2] &lt;br&gt; [4, −2, 3, 4, −4, −3, 3, −4, 2, −3, −2, 2] || || [[File:GraphY12W136EE4401162.jpg|thumb|]]
|-
| 3|| 3|| 8||3  || [−5, −5, 3, 3, 6, −3, −3, 5, 5, 2, 6, −2] &lt;br&gt; [2, 4, −2, 3, 5, −4, −3, 3, 3, −5, −3, −3] || || [[File:GraphY12W136EE4311500.jpg|thumb|]]
|-
| 4|| 3|| 2||3  || [2, 4, −2, 3, 6, −4, −3, 2, 3, −2, 6, −3] &lt;br&gt; [2, 4, −2, 3, 5, −4, −3, 4, 2, −5, −2, −4] &lt;br&gt; [−5, 2, −3, −2, 5, 5, 2, 5, −2, −5, −5, 3] || ||  [[File:GraphY12W138EE4387324.jpg|thumb|]]
|-
|4 || 3|| 2||3  || [−5, 2, −3, −2, 6, 3, 3, 5, −3, −3, 6, 3] &lt;br&gt; [4, −2, −4, 4, −4, 3, 3, −4, −3, −3, 4, 2] &lt;br&gt; [−3, 3, 3, 4, −3, −3, 5, −4, 2, 3, −2, −5] || || [[File:GraphY12W139EE4330141.jpg|thumb|]]
|-
| 4|| 3|| 2||3  ||  [2, 3, −2, 4, −3, 6, 3, −4, 2, −3, −2, 6] &lt;br&gt; [−4, 5, −4, 2, 3, −2, −5, −3, 4, 2, 4, −2] || || [[File:GraphY12W139EE4405952.jpg|thumb|]]
|-
| 4||3 || 1||3  ||  [6, 3, −4, −4, −3, 3, 6, 2, −3, −2, 4, 4] &lt;br&gt; [−5, −4, 4, 2, 6, −2, −4, 5, 3, 4, 6, −3] &lt;br&gt; [3, 4, 4, −3, 4, −4, −4, 3, −4, 2, −3, −2] &lt;br&gt; [4, 5, −4, −4, −4, 3, −5, 2, −3, −2, 4, 4] &lt;br&gt; [4, 5, −3, −5, −4, 3, −5, 2, −3, −2, 5, 3] || || [[File:GraphY12W136EE4291096.jpg|thumb|]]
|-
|3 || 4|| 4||3  ||  [4, 6, −4, −4, −4, 3, 3, 6, −3, −3, 4, 4] &lt;br&gt; [−5, −4, 3, 3, 6, −3, −3, 5, 3, 4, 6, −3] &lt;br&gt; [4, −3, 5, −4, −4, 3, 3, −5, −3, −3, 3, 4] || || [[File:GraphY12W135EE4208576.jpg|thumb|]]
|-
| 3|| 4|| 16||3  ||  [3, 3, 4, −3, −3, 4; –] &lt;br&gt; [3, 6, −3, −3, 6, 3]&lt;sup&gt;2&lt;/sup&gt; || || [[File:GraphY12W136EE4258760.jpg|thumb|]]
|-
| 4|| 3|| 1||3  ||  [4, −2, 5, 2, −4, −2, 3, −5, 2, −3, −2, 2] &lt;br&gt; [5, −2, 2, 4, −2, −5, 3, −4, 2, −3, −2, 2] &lt;br&gt; [2, −5, −2, −4, 2, 5, −2, 2, 5, −2, −5, 4]  || [[Frucht graph]] || [[File:GraphY12W139EE4495991.jpg|thumb|]]
|-
|4 || 3|| 4||3  || [−2, 6, 2, −4, −2, 3, 3, 6, −3, −3, 2, 4] &lt;br&gt; [−2, 2, 5, −2, −5, 3, 3, −5, −3, −3, 2, 5] || || [[File:GraphY12W139EE4412975.jpg|thumb|]]
|-
|4 || 3|| 2||3  ||  [2, 4, −2, 6, 2, −4, −2, 4, 2, 6, −2, −4] &lt;br&gt; [2, 5, −2, 2, 6, −2, −5, 2, 3, −2, 6, −3] || || [[File:GraphY12W139EE4487532.jpg|thumb|]]
|-
| 4|| 3||2 ||3  ||  [6, 3, −3, −5, −3, 3, 6, 2, −3, −2, 5, 3] &lt;br&gt; [3, 5, 3, −3, 4, −3, −5, 3, −4, 2, −3, −2] &lt;br&gt; [−5, −3, 4, 2, 5, −2, −4, 5, 3, −5, 3, −3] || || [[File:GraphY12W140EE4312097.jpg|thumb|]]
|-
| 4|| 4|| 12||3  ||  [3, −3, 5, −3, −5, 3, 3, −5, −3, −3, 3, 5] || || [[File:GraphY12W142EE4231141.jpg|thumb|]]
|-
| 4|| 3|| 2||3  ||  [4, 2, 4, −2, −4, 4; –] &lt;br&gt; [3, 5, 2, −3, −2, 5; –] &lt;br&gt; [6, 2, −3, −2, 6, 3]&lt;sup&gt;2&lt;/sup&gt; || || [[File:GraphY12W141EE4400528.jpg|thumb|]]
|-
|4 ||3 || 2||3  || [3, 6, 4, −3, 6, 3, −4, 6, −3, 2, 6, −2] &lt;br&gt; [4, −4, 5, 3, −4, 6, −3, −5, 2, 4, −2, 6] &lt;br&gt; [−5, 5, 3, −5, 4, −3, −5, 5, −4, 2, 5, −2] || || [[File:GraphY12W137EE4272638.jpg|thumb|]]
|-
|3 || 3|| 1||3  || [6, −5, 2, 6, −2, 6, 6, 3, 5, 6, −3, 6] &lt;br&gt; [6, 2, −5, −2, 4, 6, 6, 3, −4, 5, −3, 6] &lt;br&gt; [5, 5, 6, 4, 6, −5, −5, −4, 6, 2, 6, −2] &lt;br&gt; [−4, 4, −3, 3, 6, −4, −3, 2, 4, −2, 6, 3] &lt;br&gt; [6, 2, −4, −2, 4, 4, 6, 4, −4, −4, 4, −4] &lt;br&gt; [−3, 2, 5, −2, −5, 3, 4, −5, −3, 3, −4, 5] &lt;br&gt; [−5, 2, −4, −2, 4, 4, 5, 5, −4, −4, 4, −5] || ||[[File:GraphY12W133EE4237675.jpg|thumb|]]
|-
|3 ||3 || 2||3  ||  [2, 6, −2, 5, 6, 4, 5, 6, −5, −4, 6, −5] &lt;br&gt; [5, 6, −4, −4, 5, −5, 2, 6, −2, −5, 4, 4] &lt;br&gt; [2, 4, −2, −5, 4, −4, 3, 4, −4, −3, 5, −4] &lt;br&gt; [2, −5, −2, 4, −5, 4, 4, −4, 5, −4, −4, 5] || || [[File:GraphY12W131EE4219745.jpg|thumb|]]
|-
|4 || 3|| 4||3  ||  [2, 4, −2, −5, 5]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt;  [−5, 2, 4, −2, 6, 3, −4, 5, −3, 2, 6, −2] || || [[File:GraphY12W135EE4348153.jpg|thumb|]]
|-
| 4|| 3|| 2||3  || [−4, −4, 4, 2, 6, −2, −4, 4, 4, 4, 6, −4] &lt;br&gt; [−4, −3, 4, 2, 5, −2, −4, 4, 4, −5, 3, −4] &lt;br&gt; [−3, 5, 3, 4, −5, −3, −5, −4, 2, 3, −2, 5] || || [[File:GraphY12W137EE4285630.jpg|thumb|]]
|-
|3 || 3|| 2||3  ||  [2, 5, −2, 4, 4, 5; –] &lt;br&gt; [2, 4, −2, 4, 4, −4; –] &lt;br&gt; [−5, 5, 6, 2, 6, −2]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [5, −2, 4, 6, 3, −5, −4, −3, 2, 6, −2, 2] || || [[File:GraphY12W134EE4348061.jpg|thumb|]]
|-
|3 || 3|| 2||3  ||  [3, 6, −4, −3, 5, 6, 2, 6, −2, −5, 4, 6] &lt;br&gt; [2, −5, −2, 4, 5, 6, 4, −4, 5, −5, −4, 6] &lt;br&gt; [5, −4, 4, −4, 3, −5, −4, −3, 2, 4, −2, 4] || ||[[File:GraphY12W131EE4211275.jpg|thumb|]]
|-
|4 || 3|| 2||3  || [6, −5, 2, 4, −2, 5, 6, −4, 5, 2, −5, −2] &lt;br&gt; [−2, 4, 5, 6, −5, −4, 2, −5, −2, 6, 2, 5] &lt;br&gt; [5, −2, 4, −5, 4, −5, −4, 2, −4, −2, 5, 2] || || [[File:GraphY12W133EE4316541.jpg|thumb|]]
|-
| 4|| 3|| 1||3  || [2, −5, −2, 6, 3, 6, 4, −3, 5, 6, −4, 6] &lt;br&gt; [6, 3, −3, 4, −3, 4, 6, −4, 2, −4, −2, 3] &lt;br&gt; [5, −4, 6, −4, 2, −5, −2, 3, 6, 4, −3, 4] &lt;br&gt; [5, −3, 5, 6, 2, −5, −2, −5, 3, 6, 3, −3] &lt;br&gt; [−5, 2, −5, −2, 6, 3, 5, 5, −3, 5, 6, −5] &lt;br&gt; [−3, 4, 5, −5, −5, −4, 2, −5, −2, 3, 5, 5] &lt;br&gt; [5, 5, 5, −5, 4, −5, −5, −5, −4, 2, 5, −2] || || [[File:GraphY12W134EE4232276.jpg|thumb|]]
|-
|3 ||3 || 2||3  || [5, −3, 6, 3, −5, −5, −3, 2, 6, −2, 3, 5] &lt;br&gt; [2, 6, −2, −5, 5, 3, 5, 6, −3, −5, 5, −5] &lt;br&gt; [5, 5, 5, 6, −5, −5, −5, −5, 2, 6, −2, 5] &lt;br&gt; [4, −3, 5, 2, −4, −2, 3, −5, 3, −3, 3, −3] &lt;br&gt; [5, 5, −3, −5, 4, −5, −5, 2, −4, −2, 5, 3] || || [[File:GraphY12W135EE4267156.jpg|thumb|]]
|-
| 4|| 3|| 4||3  || [2, 4, −2, 5, 3, −4; –] &lt;br&gt; [5, −3, 2, 5, −2, −5; –] &lt;br&gt; [3, 6, 3, −3, 6, −3, 2, 6, −2, 2, 6, −2] || || [[File:GraphY12W138EE4374286.jpg|thumb|]]
|-
| 4|| 3|| 2||3  ||  [6, 2, −4, −2, −5, 3, 6, 2, −3, −2, 4, 5] &lt;br&gt; [2, 3, −2, 4, −3, 4, 5, −4, 2, −4, −2, −5] &lt;br&gt; [−5, 2, −4, −2, −5, 4, 2, 5, −2, −4, 4, 5] || || [[File:GraphY12W136EE4361258.jpg|thumb|]]
|-
| 3||3 || 2||3  ||  [5, 2, 5, −2, 5, −5; –] &lt;br&gt; [6, 2, −4, −2, 4, 6]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [2, −5, −2, 6, 2, 6, −2, 3, 5, 6, −3, 6] &lt;br&gt; [−5, −2, 6, 6, 2, 5, −2, 5, 6, 6, −5, 2] || || [[File:GraphY12W134EE4334214.jpg|thumb|]]
|-
|3 || 3|| 12||3  || [−5, 3, 3, 5, −3, −3, 4, 5, −5, 2, −4, −2] || || [[File:GraphY12W134EE4279794.jpg|thumb|]]
|-
| 3||3 || 2||3  || [6, −4, 3, 4, −5, −3, 6, −4, 2, 4, −2, 5] &lt;br&gt; [−4, 6, −4, 2, 5, −2, 5, 6, 4, −5, 4, −5] &lt;br&gt; [5, −5, 4, −5, 3, −5, −4, −3, 5, 2, 5, −2] || || [[File:GraphY12W131EE4205815.jpg|thumb|]]
|-
|4 || 3||12 ||3  || [−4, 5, 2, −4, −2, 5; –] || [[Dürer graph]] || [[File:Y12W135EE4325057.jpg|thumb|]]
|-
| 3|| 3|| 4||3  || [2, 5, −2, 5, 3, 5; –] &lt;br&gt; [6, −2, 6, 6, 6, 2]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [5, −2, 6, 6, 2, −5, −2, 3, 6, 6, −3, 2] || || [[File:GraphY12W136EE4360342.jpg|thumb|]]
|-
|3 ||3 || 4||3  ||  [6, −2, 6, 4, 6, 4, 6, −4, 6, −4, 6, 2] &lt;br&gt; [5, 6, −3, 3, 5, −5, −3, 6, 2, −5, −2, 3] || || [[File:GraphY12W133EE4223739.jpg|thumb|]]
|-
| 3|| 3|| 4||3  || [4, −2, 4, 6, −4, 2, −4, −2, 2, 6, −2, 2] &lt;br&gt; [5, −2, 5, 6, 2, −5, −2, −5, 2, 6, −2, 2] || || [[File:GraphY12W135EE4443130.jpg|thumb|]]
|-
| 3||3 ||24 ||3  || [6, −2, 2]&lt;sup&gt;4&lt;/sup&gt; || [[Truncated tetrahedron]] || [[File:GraphY12W138EE4576235.jpg|thumb|]]
|-
|3 || 3||12 ||3  ||   || [[Tietze's Graph]] || [[File:Y12W129EE4170908.jpg|thumb|]]
|-
| 3|| 3||36 ||3  || [2, 6, −2, 6]&lt;sup&gt;3&lt;/sup&gt; || || [[File:GraphY12W135EE4426200.jpg|thumb|]]
|-
|4 || 4|| 24||4  || [−3, 3]&lt;sup&gt;6&lt;/sup&gt;  &lt;br&gt;  [3, −5, 5, −3, −5, 5]&lt;sup&gt;2&lt;/sup&gt; || G&lt;sub&gt;6, 2&lt;/sub&gt;,  Y&lt;sub&gt;6&lt;/sub&gt; || [[File:GraphY12W144EE4227027.jpg|thumb|Yutsis 18j-symbol label: B]]
|-
|3 || 4||4 ||4  ||  [6, −3, 6, 6, 3, 6]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [6, 6, −5, 5, 6, 6]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [3, −3, 4, −3, 3, 4; –] &lt;br&gt; [5, −3, 6, 6, 3, −5]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [5, −3, −5, 4, 4, −5; –] &lt;br&gt; [6, 6, −3, −5, 4, 4, 6, 6, −4, −4, 5, 3] || || [[File:GraphY12W134EE4169366.jpg|thumb|Yutsis 18j-symbol label: L]]
|-
|3 ||4 ||8 ||4  ||  [−4, 4, 4, 6, 6, −4]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [6, −5, 5, −5, 5, 6]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [4, −3, 3, 5, −4, −3; –] &lt;br&gt; [−4, −4, 4, 4, −5, 5]&lt;sup&gt;2&lt;/sup&gt; || || [[File:GraphY12W132EE4128733.jpg|thumb|Yutsis 18j-symbol label: K]]
|-
|3 || 4|| 2||4  || [−4, 6, 3, 6, 6, −3, 5, 6, 4, 6, 6, −5] &lt;br&gt; [−5, 4, 6, 6, 6, −4, 5, 5, 6, 6, 6, −5] &lt;br&gt; [5, −3, 4, 6, 3, −5, −4, −3, 3, 6, 3, −3] &lt;br&gt; [4, −4, 6, 4, −4, 5, 5, −4, 6, 4, −5, −5] &lt;br&gt; [4, −5, −3, 4, −4, 5, 3, −4, 5, −3, −5, 3] || || [[File:GraphY12W132EE4134305.jpg|thumb|Yutsis 18j-symbol label: T]]
|-
| 3||4 ||2 ||4  ||  [3, 4, 5, −3, 5, −4; –] &lt;br&gt; [3, 6, −4, −3, 4, 6]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [−4, 5, 5, −4, 5, 5; –] &lt;br&gt; [3, 6, −4, −3, 4, 4, 5, 6, −4, −4, 4, −5] &lt;br&gt; [4, −5, 5, 6, −4, 5, 5, −5, 5, 6, −5, −5] &lt;br&gt; [4, −4, 5, −4, −4, 3, 4, −5, −3, 4, −4, 4] || || [[File:Y12W130EE4102128.jpg|thumb|Yutsis 18j-symbol label: R]]
|-
|3 ||4 || 8||4  || [4, −4, 6]&lt;sup&gt;4&lt;/sup&gt; &lt;br&gt; [3, 6, 3, −3, 6, −3]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [−3, 6, 4, −4, 6, 3, −4, 6, −3, 3, 6, 4] || [[Bidiakis cube]] || [[File:Y12W134EE4166461.jpg|thumb|Yutsis 18j-symbol label: D]]
|-
|3 || 4|| 16||4  || [6, −5, 5]&lt;sup&gt;4&lt;/sup&gt; &lt;br&gt; [3, 4, −4, −3, 4, −4]&lt;sup&gt;2&lt;/sup&gt; || || [[File:GraphY12W130EE4116056.jpg|thumb|Yutsis 18j-symbol label: G]]
|-
|3 || 4|| 2||4  ||  [−3, 5, −3, 4, 4, 5; –] &lt;br&gt; [4, −5, 5, 6, −4, 6]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [−3, 4, −3, 4, 4, −4; –] &lt;br&gt; [5, 6, −3, −5, 4, −5, 3, 6, −4, −3, 5, 3] &lt;br&gt; [5, 6, 4, −5, 5, −5, −4, 6, 3, −5, 5, −3] || || [[File:GraphY12W132EE4128805.jpg|thumb|Yutsis 18j-symbol label: S]]
|-
| 3||4 ||4 ||4  ||  [4, −3, 4, 5, −4, 4; –] &lt;br&gt; [4, 5, −5, 5, −4, 5; –] &lt;br&gt; [−5, −3, 4, 5, −5, 4; –] || || [[File:GraphY12W128EE4061559.jpg|thumb|Yutsis 18j-symbol label: N]]
|-
|3 || 4|| 2||4  || [6, −4, 6, −4, 3, 5, 6, −3, 6, 4, −5, 4] &lt;br&gt; [6, −4, 3, −4, 4, −3, 6, 3, −4, 4, −3, 4] &lt;br&gt; [5, 6, −4, 3, 5, −5, −3, 6, 3, −5, 4, −3] &lt;br&gt; [5, −5, 4, 6, −5, −5, −4, 3, 5, 6, −3, 5] &lt;br&gt; [5, 5, −4, 4, 5, −5, −5, −4, 3, −5, 4, −3] || || [[File:GraphY12W130EE4093704.jpg|thumb|Yutsis 18j-symbol label: V]]
|-
|3 || 4||4 ||4  || [6, −3, 5, 6, −5, 3, 6, −5, −3, 6, 3, 5] &lt;br&gt; [3, −4, 5, −3, 4, 6, 4, −5, −4, 4, −4, 6] || || [[File:GraphY12W130EE4099207.jpg|thumb|Yutsis 18j-symbol label: P]]
|-
|3 || 4||8 ||4  || [5, 6, 6, −4, 5, −5, 4, 6, 6, −5, −4, 4] || || [[File:GraphY12W128EE4072559.jpg|thumb|Yutsis 18j-symbol label: I]]
|-
|3 || 5||16 ||4  || [4, −5, 4, −5, −4, 4; –] || || [[File:GraphY12W126EE4034891.jpg|thumb|Yutsis 18j-symbol label: F]]
|-
| 3|| 4|| 4||4  || [6, 4, 6, 6, 6, −4]&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt; [−3, 4, −3, 5, 3, −4; –] &lt;br&gt; [−5, 3, 6, 6, −3, 5, 5, 5, 6, 6, −5, −5] &lt;br&gt; [−3, 3, 6, 4, −3, 5, 5, −4, 6, 3, −5, −5] || || [[File:GraphY12W134EE4155455.jpg|thumb|Yutsis 18j-symbol label: M]]
|-
|4 ||4 ||8 ||4  ||  [3, 5, 5, −3, 5, 5; –] &lt;br&gt; [−3, 5, −3, 5, 3, 5; –] &lt;br&gt; [5, −3, 5, 5, 5, −5; –] || || [[File:Y12W136EE4145861.jpg|thumb|Yutsis 18j-symbol label: E]]
|-
|3 ||4 ||48 ||4  || [5, −5, −3, 3]&lt;sup&gt;3&lt;/sup&gt; &lt;br&gt; [−5, 5]&lt;sup&gt;6&lt;/sup&gt;  || [[Franklin graph]] || [[File:Y12W132EE4105212.jpg|thumb|Yutsis 18j-symbol label: C]]
|-
|3 || 4||24 ||4 || [6]&lt;sup&gt;12&lt;/sup&gt; &lt;br&gt; [6, 6, −3, −5, 5, 3]&lt;sup&gt;2&lt;/sup&gt; || || [[File:Y12W138EE4225614.jpg|thumb|Yutsis 18j-symbol label: A]]
|-
|3 ||5 ||18 ||4  || [6, −5, −4, 4, −5, 4, 6, −4, 5, −4, 4, 5] || || [[File:GraphY12W126EE4040388.jpg|thumb|Yutsis 18j-symbol label: H]]
|}

The LCF entries are absent above if the graph has no [[Hamiltonian cycle]],  which is rare (see [[Tait's conjecture]]). In this case a list of edges between pairs of vertices labeled 0 to n−1 in the third column serves as an identifier.

==Vector coupling coefficients==

Each 4-connected (in the above sense) simple cubic graph on {{math|2''n''}} vertices defines a class of quantum mechanical {{math|3''n''}}{{hyphen}}j symbols. Roughly speaking, each vertex represents a [[3-jm symbol]], the graph is converted to a digraph by assigning signs to the angular momentum quantum numbers {{math|j}}, the vertices are labelled with a handedness representing the order of the three {{math|j}} (of the three edges) in the 3{{hyphen}}jm symbol, and the graph represents a sum over the product of all these numbers assigned to the vertices.

There are 1 ([[6-j symbol|6{{hyphen}}j]]), 1 ([[9-j symbol|9{{hyphen}}j]]), 2 (12{{hyphen}}j), 5 (15{{hyphen}}j), 18 (18{{hyphen}}j), 84 (21{{hyphen}}j), 607 (24{{hyphen}}j), 6100 (27{{hyphen}}j), 78824 (30{{hyphen}}j), 1195280 (33{{hyphen}}j), 20297600 (36{{hyphen}}j), 376940415 (39{{hyphen}}j) etc. of these {{OEIS|A175847}}.

If they are equivalent to certain vertex-induced binary trees (cutting one edge and finding a cut that splits the remaining graph into two trees), they are representations of recoupling coefficients, and are then also known as Yutsis graphs {{OEIS|A111916}}.

==See also==
* [[3-jm symbol]]
* [[6-j symbol]]

==References==
* {{cite book
|last1=Yutsis  |first1=A. P.
|authorlink1=Adolfas Jucys
|last2=Levinson |first2=I. B.
|last3=Vanagas |first3=V. V.
|last4=Sen |first4=A.
|year=1962
|title=Mathematical Apparatus of the theory of angular momentum
|url=https://archive.org/details/nasa_techdoc_19630001624
|publisher=Israel program for scientific translations
|bibcode=1962mata.book.....Y
}}
* {{cite journal
|last1=Massot |first1=J.-N.
|last2=El-Baz |first2=E.
|last3=Lafoucriere |first3=J.
|year=1967
|title=A general graphical method for angular momentum
|journal=Reviews of Modern Physics
|volume=39 |issue=2 |pages=288–305
|bibcode=1967RvMp...39..288M
|doi=10.1103/RevModPhys.39.288
}}
* {{cite web
|title=Computer investigations of cubic graphs
|first1=F. C.
|last1=Bussemaker
|first2=S. 
|last2=Cobeljic
|first3=D. M.
|last3=Cvetkovic
|url=http://alexandria.tue.nl/repository/books/252909.pdf
|year=1976
}}
* {{cite journal
|first1=F. C.
|last1=Bussemaker
|first2=S.
|last2=Cobeljic
|first3=D. M.
|last3=Cvetkovic
|first4=J. J.
|last4=Seidel
|journal=J. Combin. Theory Ser. B
|year=1977
|volume=23
|issue=2–3
|pages=234–235
|doi=10.1016/0095-8956(77)90034-X
|title=Cubic graphs on &lt;=14 vertices
}}
* {{cite journal
|last1=Frucht|first1=R.
|year=1977
|title=A canonical representation of trivalent Hamiltonian graphs
|journal=Journal of Graph Theory
|volume=1 |issue=1 |pages=45–60
|doi=10.1002/jgt.3190010111
|mr=0463029
}}
* {{cite journal
|last1=Clark |first1=L.
|last2=Entringer |first2=R.
|year=1983
|title=Smallest maximally non-Hamiltonian graphs
|journal=Per. Mathem. Hungar.
|volume=14 |issue=1|pages=57–68
|doi=10.1007/BF02023582
|mr=0697357
}}
* {{cite journal
|first1=N. C.|last1=Wormald
|year=1985
|title=Enumeration of cyclically 4-connected cubic graphs
|journal=Journal of Graph Theory
|volume=9 |issue=4
|pages=563–573
|doi=10.1002/jgt.3190090418
|mr=0890248
}}
* {{cite journal
|first1=A. |last1=Bar-Shalom
|first2=M. |last2=Klapisch
|year=1988
|title=NJGRAF - an efficient program for calculation of general recoupling coefficients by graphical analysis, compatible with NJSYM
|journal=Comp. Phys. Comm.
|volume=50 |issue=3 |pages=375–393
|bibcode=1988CoPhC..50..375B
|doi=10.1016/0010-4655(88)90192-0
}}
* {{cite journal
|first1=G. |last1=Brinkmann
|year=1996
|title=Fast generation of cubic graphs
|journal=Journal of Graph Theory
|volume=23 |issue=2|pages=139–149
|doi=10.1002/(SICI)1097-0118(199610)23:2&lt;139::AID-JGT5&gt;3.0.CO;2-U
|mr=1408342
}}
* {{cite journal
|first1=V. |last1=Fack
|first2=S. N. |last2=Pitre
|first3=J. |last3= Van der Jeugt
|year=1997
|title=Calculation of general recoupling coefficients using graphical methods
|journal=Comp. Phys. Comm.
|volume=101 |issue=1&amp;ndash;2 |pages=155–170
|doi=10.1016/S0010-4655(96)00170-1
|bibcode=1997CoPhC.101..155F
}}
* {{cite journal
|first1=M. |last1=Danos
|first2=U. |last2=Fano
|year=1998
|title=Graphical analysis of angular momentum for collision products
|journal=Physics Reports
|volume=304 |issue=4 |pages=155–227
|doi=10.1016/S0370-1573(98)00020-9
|bibcode=1998PhR...304..155D
}}
* {{cite journal
|first1=M. |last1=Meringer
|year=1999
|title=Fast generation of regular graphs and construction of cages
|journal=Journal of Graph Theory
|volume=30 |issue=2|pages=137–146
|doi=10.1002/(SICI)1097-0118(199902)30:2&lt;137::AID-JGT7&gt;3.0.CO;2-G
|mr=1665972
}}
* {{cite journal
|first1=D. |last1=Van Dyck
|first2=G. |last2=Brinkmann
|first3=V. |last3=Fack
|first4=B. D. |last4=McKay
|year=2005
|title=To be or not to be Yutsis: Algorithms for the decision problem
|journal=Comp. Phys. Comm.
|volume=173 |issue=1–2 |pages=61–70
|bibcode=2005CoPhC.173...61V
|doi=10.1016/j.cpc.2005.07.008
|mr=2179511
}}
* {{cite journal
|first1=D. |last1=Van Dyck
|first2=V. |last2=Fack
|year=2007
|title=On the reduction of Yutsis graphs
|journal=Discrete Math.
|volume=307 |issue=11–12 |pages=1506–1515
|doi=10.1016/j.disc.2005.11.088
|mr=2311125
}}
* {{cite journal
|first1=R. E. L. |last1=Aldred
|first2=D. |last2=Van Dyck
|first3=G. |last3=Brinkmann
|first4=V. |last4=Fack
|first5=B. D. |last5=McKay
|year=2009
|title=Graph structural properties of non-Yutsis graphs allowing fast recognition
|journal=Discrete Math.
|volume=157 |issue=2 |pages=377–386
|doi=10.1016/j.dam.2008.03.020
|mr=2479811
}}
*{{ cite arxiv | first1=Richard J. |last1=Mathar |title=The Wigner graphs up to 12 Vertices
|eprint=1109.2358 | year=2011|class=math-ph }}


{{DEFAULTSORT:Table Of Simple Cubic Graphs}}
[[Category:Graphs]]
[[Category:Regular graphs]]
[[Category:Graph families]]
[[Category:Mathematical tables]]</text>
      <sha1>bfi63ejw1l001l8dh8oxevs4cjnw6bb</sha1>
    </revision>
  </page>
  <page>
    <title>Texas Math and Science Coaches Association</title>
    <ns>0</ns>
    <id>4313610</id>
    <revision>
      <id>848369430</id>
      <parentid>838181067</parentid>
      <timestamp>2018-07-01T14:14:01Z</timestamp>
      <contributor>
        <username>GünniX</username>
        <id>237572</id>
      </contributor>
      <minor/>
      <comment>v1.43 - [[WP:WCW]] project (Template without correct beginning)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6060">{{Use American English|date=May 2015}}
{{Use mdy dates|date=May 2015}}
{{No footnotes|date=May 2015}}
The '''Texas Math and Science Coaches Association''' or '''TMSCA''' is an organization for coaches of academic [[University Interscholastic League]] teams in [[Texas]] [[middle school]]s and [[high school]]s, specifically those that compete in [[mathematics]] and [[science]]-related tests.

== Events ==

There are four events in the TMSCA at both the middle and high school level: Number Sense, General Mathematics, Calculator Applications, and General Science.

Number Sense is an 80-question exam that students are given only 10 minutes to solve. Additionally, no scratch work or paper calculations are allowed. These questions range from simple calculations such as 99+98 to more complicated operations such as 1001×1938. Each calculation is able to be done with a certain trick or shortcut that makes the calculations easier.
The high school exam includes calculus and other difficult topics in the questions also with the same rules applied as to the middle school version.
It is well known that the grading for this event is particularly stringent as errors such as writing over a line or crossing out potential answers are considered as incorrect answers.{{Citation needed|date=May 2015}}

General Mathematics is a 50-question exam that students are given only 40 minutes to solve. These problems are usually more challenging than questions on the Number Sense test, and the General Mathematics word problems take more thinking to figure out. Every problem correct is worth 5 points, and for every problem incorrect, 2 points are deducted. Tiebreakers are determined by the person that misses the first problem and by percent accuracy.

Calculator Applications is an 80-question exam that students are given only 30 minutes to solve. This test requires practice on the calculator, knowledge of a few crucial formulas, and much speed and intensity. Memorizing formulas, tips, and tricks will not be enough. In this event, plenty of practice is necessary in order to master the locations of the keys and develop the speed necessary. All correct questions are worth 5 points and all incorrect questions or skipped questions that are before the last answered questions will lose 4 points; answers are to be given with three significant figures.

Science is a 50-question exam that is solved in 40 minutes at the middle school level or a 60-question exam that is solved in a 2-hour time limit at the high school level. Tiebreakers are determined by the person that misses the first problem and by percent accuracy. As the name suggests, the test focuses on the science subjects learned in the middle school or high school level depending on the student's grade and the version of the test being taken.

== Competitions ==
Individual schools that are members of TMSCA can host invitational competitions using TMSCA-released tests.  Many schools use this as a fund-raising opportunity for their competitive math program.

TMSCA also hosts two statewide competitions for member schools each year, one at the middle school level and one at the high school level, as well as a qualification competition at the middle school level prior to the state competition, also known as the Regional Qualifier.  These statewide competitions are held at the [[University of Texas at San Antonio]] campus each spring.  These competitions can often serve as practice for statewide UIL tournaments, which occur shortly after, and for middle school students are their only opportunity to compete at the state level (UIL competitions at the middle school level do not go beyond district).

== Grading ==
For the General Mathematics and General Science contests in middle school, 5 points are awarded for each correct answer and 2 points are deducted for each incorrect answer. In the high school contest, 6 points are awarded for each correct answer and 2 points are deducted for each incorrect answer. The real way to calculate it is to multiply the number of questions you did times 5 and subtract 7 from each incorrect question. Unanswered questions do not affect the score.  Thus, competitors are penalized for guessing incorrectly. (For both General Mathematics and General Science a perfect score is a 250.) 

On the Number Sense test, scoring is 5 times the last question answered (so a student answering 32 questions would be awarded 160 points) and after that 9 points are deducted for incorrect answers, problems skipped up to the last attempted question and markovers/erasures, (so if the student above missed one and skipped three questions the student would end up with 124 points).  Number sense tests are also checked for possible scratch work, overwrites, and erasures (bluntly called "markovers"), which if found could result in questions being counted as incorrect or tests being disqualified. (For both Number Sense and Calculator, a perfect score is a 400.)

The Calculator Applications test multiplies 5 times the last question answered and deducts 9 points for incorrect or skipped questions, similar to Number Sense, but scratch work, markovers/erasures, and the use of a calculator is allowed.

== Results ==
At almost all TMSCA competitions, students are ranked against each other in their specific grade level. For example, all eighth graders compete against each other, all seventh graders compete against each other, and so on and so forth. This ensures parity of competition since students in higher grades generally tend to score higher than students in the lower grades. Particularly at the high school level, there is a stark contrast between freshmen with little real math and science experience and seniors, who presumably have taken or are taking [[advanced placement]] science courses and calculus.{{Citation needed|date=May 2015}}

==References==
{{Reflist}}

== External links ==
* {{Official website|http://www.tmsca.org/}}

[[Category:Mathematics competitions]]
[[Category:Organizations based in Texas]]
[[Category:Education in Texas]]</text>
      <sha1>9wvmmxxd8w5i4vab9i66rbkq8a7aa4i</sha1>
    </revision>
  </page>
  <page>
    <title>The First Moderns</title>
    <ns>0</ns>
    <id>54524279</id>
    <revision>
      <id>862867392</id>
      <parentid>808906686</parentid>
      <timestamp>2018-10-07T06:51:07Z</timestamp>
      <contributor>
        <username>Zackmann08</username>
        <id>15881234</id>
      </contributor>
      <comment>Adding image</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5134">{{Infobox book 
| name          = The First Moderns: Profiles in the Origins of Twentieth-Century Thought
| image         = The First Moderns.jpg| image_size    =
| caption = 
| author        = [[William Everdell|William R. Everdell]]
| cover_artist  = 
| country       = United States
| language      = English
| subject       = [[Modernism]], [[Philosophy]], [[Mathematics]], [[History of ideas]], [[Art history]]
| publisher     = [[University of Chicago Press]]
| pub_date      = 1997
| pages         = 501
| isbn          = 0-226-22480-5
}}

'''''The First Moderns: Profiles in the Origins of Twentieth-Century Thought''''' is a book on [[Modernism]] by historian [[William Everdell]], published in 1997 by the [[University of Chicago Press]]. A ''[[New York Times]]'' Notable Book of 1997, ''The First Moderns'' suggests that "the heart of Modernism is the postulate of ontological discontinuity."&lt;ref&gt;[https://www.nytimes.com/1997/12/07/books/notable-books-of-the-year-1997.html, "Notable Books of the Year 1997"], ''The New York Times,'' December 7, 1997. Accessed July 11, 2017.&lt;/ref&gt;&lt;ref&gt;William R. Everdell, ''The First Moderns: Profiles in the Origins of Twentieth-Century Thought'' (Chicago: University of Chicago Press, 1997), 351&lt;/ref&gt;

==Background and overview==
{{unreferenced section|date=July 2017}}
Everdell, Dean of Humanities at [[Saint Ann's School (New York City)|Saint Ann's School]] in Brooklyn Heights,&lt;ref&gt;William R. Everdell, [https://www.nytimes.com/2003/08/17/books/it-s-about-time-it-s-about-space.html "It's About Time. It's About Space."], ''The New York Times,'' August 17, 2003. Accessed July 28 2017.&lt;/ref&gt; posits that Modernism first emerged in the field of mathematics rather than the arts, specifically in the work of German mathematician [[Richard Dedekind]], who, in 1872, demonstrated that mathematicians operate without a continuum; this represents the formalization of Everdell's axiom of "ontological discontinuity," which he goes on to examine in a multiplicity of contexts. He examines this emerging framework of discreteness in science ([[Ludwig Boltzmann]]'s mechanics, [[Santiago Ramón y Cajal|Cajal]]'s neuroscience, [[Hugo de Vries]]'s conception of the gene and [[Max Planck|Planck]]'s quantum work, [[Einstein]]'s physics); mathematics, logic, and philosophy ([[Georg Cantor]], [[Gottlob Frege]], [[Bertrand Russell]] and the linguistic turn, [[Husserl]] and the beginnings of [[Phenomenology (philosophy)|phenomenology]]); in addition to the arts ([[James Joyce]]'s novels, [[Picasso]]'s [[Demoiselles d'Avignon|''Demoiselles D'Avignon'']], [[Schoenberg]]'s twelve-tone music).

==Reviews==

Critics largely reviewed ''The First Moderns'' favorably, appreciating Everdell's interdisciplinary approach, in publications including the [[New york review of books|''New York Review of Books'']], the ''New York Times,'' the [[Los Angeles Times|''Los Angeles Times,'']] and the [[Washington Post Book World|''Washington Post''.]]&lt;ref&gt;[[Jim Holt (philosopher)|Jim Holt]], [http://www.nybooks.com/articles/1999/05/20/infinitesimally-yours/ "Infinitesimally Yours"], review of William R. Everdell, ''The First Moderns: Profiles in the Origins of Twentieth Century Thought,'' ''New York Review of Books,'' May 20, 1999. "Drawing together such disparate manifestations as Seurat's pointillism, Muybridge's stop-motion photography, the poetry of Whitman, Rimbaud, and Laforgue, the tone rows of Schoenberg, and the novels of Joyce, the author [Everdell] makes an engrossing and persuasive case for his claim that 'the heart of Modernism is the postulate of ontological discontinuity'"&lt;/ref&gt;&lt;ref&gt;[[Hugh Kenner]], [https://www.nytimes.com/books/97/06/29/reviews/970629.29kennert.html "A Change of Mind], review of William R. Everdell, ''The First Moderns: Profiles in the Origins of Twentieth Century Thought'', ''The New York Times'', June 29, 1997. "The change started to happen in the 1870's [sic], and not, as William R. Everdell arrestingly demonstrates in ''The First Moderns,'' in painting or in literature but in number theory. He's aware that word-focused people will be startled: ''Everyone who has heard of modernism has heard of Picasso. Most have heard of Joyce. But who has heard of Dedekind?'' Yet it was an 1872 pamphlet of Richard Dedekind's that first, to use the terminology of 19th-century positivism, ''rigorized'' modernism's generic concept -- which, as Everdell reveals, is discontinuity."&lt;/ref&gt;&lt;ref&gt;[[Frederic Morton]], [http://articles.latimes.com/1997/jul/20/books/bk-14342 "Deconstructing Modernism"], review of William R. Everdell, ''The First Moderns: Profiles in the Origins of Twentieth Century Thought,'' ''Los Angeles Times'', July 20, 1997. "''The First Moderns'' brilliantly maps the beginning of a path at whose end loom as many diasporas as there are men."&lt;/ref&gt;

==References==
{{reflist}}

{{DEFAULTSORT:First Moderns}}
[[Category:Modernism]]
[[Category:1997 books]]
[[Category:Art history]]
[[Category:History of ideas]]
[[Category:History of mathematics]]
[[Category:History of philosophy]]
[[Category:History of literature]]
[[Category:Modernity]]</text>
      <sha1>3jq9i8q9txc3t5qv1lf4slqs5uuii16</sha1>
    </revision>
  </page>
  <page>
    <title>Thue–Morse sequence</title>
    <ns>0</ns>
    <id>491903</id>
    <revision>
      <id>870566014</id>
      <parentid>863858018</parentid>
      <timestamp>2018-11-25T17:45:40Z</timestamp>
      <contributor>
        <username>Bubba73</username>
        <id>218586</id>
      </contributor>
      <minor/>
      <comment>/* History */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26246">[[Image:Morse-Thue sequence.gif|frame|right|This graphic demonstrates the repeating and complementary makeup of the Thue–Morse sequence.]]
In [[mathematics]], the '''Thue–Morse sequence''', or '''Prouhet–Thue–Morse sequence''', is the [[binary sequence]] (an infinite sequence of 0s and 1s) obtained by starting with 0 and successively appending the [[Boolean algebra|Boolean complement]] of the sequence obtained thus far.  The first few steps of this procedure yield the strings 0 then 01, 0110, 01101001, 0110100110010110, and so on, which are prefixes of the Thue–Morse sequence. The full sequence begins:

:01101001100101101001011001101001.... {{OEIS|id=A010060}}

== Definition ==
There are several equivalent ways of defining the Thue–Morse sequence.

=== Direct definition ===
To compute the ''n''th element ''t&lt;sub&gt;n&lt;/sub&gt;'', write the number ''n'' in [[Binary number|binary]].  If the [[Hamming weight|number of ones]] in this binary expansion is odd then ''t&lt;sub&gt;n&lt;/sub&gt;''&amp;nbsp;=&amp;nbsp;1, if even then ''t&lt;sub&gt;n&lt;/sub&gt;''&amp;nbsp;=&amp;nbsp;0.&lt;ref name=AS15&gt;{{harvtxt|Allouche|Shallit|2003|p=15}}&lt;/ref&gt;  For this reason [[John H. Conway]] ''et al''. call numbers ''n'' satisfying ''t&lt;sub&gt;n&lt;/sub&gt;''&amp;nbsp;=&amp;nbsp;1 ''odious'' (for ''odd'') numbers and numbers for which ''t&lt;sub&gt;n&lt;/sub&gt;''&amp;nbsp;=&amp;nbsp;0 ''evil'' (for ''even'') numbers. In other words, t&lt;sub&gt;n&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0 if ''n'' is an [[evil number]] and t&lt;sub&gt;n&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;1 if ''n'' is an [[odious number]].

This method leads to a fast method for computing the Thue–Morse sequence: start with ''t&lt;sub&gt;0&lt;/sub&gt;''&amp;nbsp;=&amp;nbsp;0, and then, for each ''n'', find the highest-order bit in the binary representation of ''n'' that is different from the same bit in the representation of ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1. (This bit can be isolated by letting ''x'' be the bitwise exclusive or of  ''n'' and ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1, shifting ''x'' right by one bit, and computing the exclusive or of this shifted value with ''x''.) If this bit is at an even index,  ''t&lt;sub&gt;n&lt;/sub&gt;'' differs from ''t''&lt;sub&gt;''n''&amp;nbsp;&amp;minus;&amp;nbsp;1&lt;/sub&gt;, and otherwise it is the same as ''t''&lt;sub&gt;''n''&amp;nbsp;&amp;minus;&amp;nbsp;1&lt;/sub&gt;. The resulting algorithm takes constant time to generate each sequence element, using only a [[L (complexity)|logarithmic number of bits]] (constant number of words) of memory.{{sfnp|Arndt|2011}}

=== Recurrence relation ===
The Thue–Morse sequence is the sequence ''t&lt;sub&gt;n&lt;/sub&gt;'' satisfying the [[recurrence relation]]

:&lt;math&gt;\begin{align}
   t_0 &amp;= 0,\\
   t_{2n} &amp;= t_n,\\
   t_{2n+1} &amp;= 1 - t_n,
 \end{align}&lt;/math&gt;

for all non-negative integers ''n''.&lt;ref name=AS15/&gt;

=== L-system ===
The Thue–Morse sequence is a [[morphic word]]:&lt;ref&gt;{{harvtxt|Lothaire|2011|p=11}}&lt;/ref&gt; it is the output of the following [[L-system|Lindenmayer system]]:
{| class="wikitable"
|-
! Variables &lt;td&gt; 0, 1 &lt;/td&gt;
|-
! Constants &lt;td&gt; None &lt;/td&gt;
|-
! Start &lt;td&gt; 0 &lt;/td&gt;
|-
! Rules &lt;td&gt; (0 → 01), (1 → 10) &lt;/td&gt;
|}

=== Characterization using bitwise negation ===
The Thue–Morse sequence in the form given above, as a sequence of [[bit]]s, can be defined [[recursion|recursively]] using the operation of [[bitwise negation]].
So, the first element is 0.
Then once the first 2&lt;sup&gt;''n''&lt;/sup&gt; elements have been specified, forming a string ''s'', then the next 2&lt;sup&gt;''n''&lt;/sup&gt; elements must form the bitwise negation of ''s''.
Now we have defined the first 2&lt;sup&gt;''n''+1&lt;/sup&gt; elements, and we recurse.

Spelling out the first few steps in detail:
* We start with 0.
* The bitwise negation of 0 is 1.
* Combining these, the first 2 elements are 01.
* The bitwise negation of 01 is 10.
* Combining these, the first 4 elements are 0110.
* The bitwise negation of 0110 is 1001.
* Combining these, the first 8 elements are 01101001.
* And so on.

So
* ''T''&lt;sub&gt;0&lt;/sub&gt; = 0.
* ''T''&lt;sub&gt;1&lt;/sub&gt; = 01.
* ''T''&lt;sub&gt;2&lt;/sub&gt; = 0110.
* ''T''&lt;sub&gt;3&lt;/sub&gt; = 01101001.
* ''T''&lt;sub&gt;4&lt;/sub&gt; = 0110100110010110.
* ''T''&lt;sub&gt;5&lt;/sub&gt; = 01101001100101101001011001101001.
* ''T''&lt;sub&gt;6&lt;/sub&gt; = 0110100110010110100101100110100110010110011010010110100110010110.
* And so on.

=== Infinite product ===
The sequence can also be defined by:
: &lt;math&gt; \prod_{i=0}^{\infty} \left(1 - x^{2^i}\right) = \sum_{j=0}^{\infty} (-1)^{t_j} x^j,&lt;/math&gt;
where ''t''&lt;sub&gt;''j''&lt;/sub&gt; is the ''j''th element if we start at ''j'' = 0.

== Some properties ==
Because each new block in the Thue–Morse sequence is defined by forming the bitwise negation of the beginning, and this is repeated at the beginning of the next block, the Thue–Morse sequence is filled with ''squares'': consecutive strings that are repeated.
That is, there are many instances of ''XX'', where ''X'' is some string.   Indeed, &lt;math&gt;X &lt;/math&gt;  is such a string if and only if &lt;math&gt;X =A,\, \overline{A},\, A \overline{A}A,&lt;/math&gt; or  &lt;math&gt;\overline{A}A \overline{A}&lt;/math&gt; where &lt;math&gt;A=T_{k}&lt;/math&gt; for some &lt;math&gt;k\ge 0&lt;/math&gt; and &lt;math&gt;\overline{A} &lt;/math&gt; denotes the bitwise negation of &lt;math&gt;A &lt;/math&gt; (interchange 0s and 1s).{{sfnp|Brlek|1989}} For instance, with  &lt;math&gt;k=0&lt;/math&gt;, we have &lt;math&gt;\ A= T_{0}=0 &lt;/math&gt;, and the square  &lt;math&gt;A \overline{A}AA \overline{A}A = 010010 &lt;/math&gt; appears in  &lt;math&gt;T &lt;/math&gt; starting at the 16th bit. (Thus, squares in &lt;math&gt;T&lt;/math&gt; have length either a power of 2 or 3 times a power of 2.)
However, there are no ''cubes'': instances of ''XXX''.
There are also no ''overlapping squares'': instances of 0''X''0''X''0 or 1''X''1''X''1.&lt;ref name=ACOW113&gt;{{harvtxt|Lothaire|2011|p=113}}&lt;/ref&gt;&lt;ref name=PF103&gt;{{harvtxt|Pytheas Fogg|2002|p=103}}&lt;/ref&gt;  The [[Critical exponent of a word|critical exponent]] is 2.{{sfnp|Krieger|2006}}

Notice that ''T''&lt;sub&gt;2''n''&lt;/sub&gt; is  [[Palindromic number|palindrome]] for any ''n'' &gt; 1. Further, let q&lt;sub&gt;''n''&lt;/sub&gt; be a word obtain from ''T''&lt;sub&gt;2''n''&lt;/sub&gt; by counting ones between consecutive zeros. For instance, ''q''&lt;sub&gt;1&lt;/sub&gt; = 2 and ''q''&lt;sub&gt;2&lt;/sub&gt; = 2102012 and so on. The words ''T&lt;sub&gt;n&lt;/sub&gt;'' do not contain ''overlapping squares'' in consequence, the words ''q&lt;sub&gt;n&lt;/sub&gt;'' are palindrome [[squarefree word]]s.

The statement above that the Thue–Morse sequence is "filled with squares" can be made precise:
It is a ''[[uniformly recurrent word]]'', meaning that given any finite string ''X'' in the sequence, there is some length ''n&lt;sub&gt;X&lt;/sub&gt;'' (often much longer than the length of ''X'') such that ''X'' appears in ''every'' block of length ''n&lt;sub&gt;X&lt;/sub&gt;''.&lt;ref name=ACOW30&gt;{{harvtxt|Lothaire|2011|p=30}}&lt;/ref&gt;{{sfnp|Berthé|Rigo|2010}}
The easiest way to make a recurrent sequence is to form a [[periodic sequence]], one where the sequence repeats entirely after a given number ''m'' of steps.
Then ''n&lt;sub&gt;X&lt;/sub&gt;'' can be set to any multiple of ''m'' that is larger than twice the length of ''X''.
But the Morse sequence is uniformly recurrent ''without'' being periodic, not even eventually periodic (meaning periodic after some nonperiodic initial segment).&lt;ref name=ACOW31&gt;{{harvtxt|Lothaire|2011|p=31}}&lt;/ref&gt;

We define the '''Thue–Morse morphism''' to be the [[function (mathematics)|function]] ''f'' from the [[Set (mathematics)|set]] of binary sequences to itself by replacing every 0 in a sequence with 01 and every 1 with 10.&lt;ref name=BLRS70&gt;{{harvtxt|Berstel|Lauve|Reutenauer|Saliola|2009|p=70}}&lt;/ref&gt;  Then if ''T'' is the Thue–Morse sequence, then ''f''(''T'') is ''T'' again; that is, ''T'' is a [[fixed point (mathematics)|fixed point]] of ''f''.  The function ''f'' is a [[prolongable morphism]] on the [[free monoid]] {0,1}&lt;sup&gt;&amp;lowast;&lt;/sup&gt; with ''T'' as fixed point: indeed, ''T'' is essentially the ''only'' fixed point of ''f''; the only other fixed point is the bitwise negation of ''T'', which is simply the Thue–Morse sequence on (1,0) instead of on (0,1).  This property may be generalized to the concept of an [[automatic sequence]].

The ''generating series'' of ''T'' over the [[binary field]] is the [[formal power series]]

:&lt;math&gt;t(Z) = \sum_{n=0}^\infty T(n) Z^n \ . &lt;/math&gt;

This power series is algebraic over the field of formal power series, satisfying the equation&lt;ref name=BLRS80&gt;{{harvtxt|Berstel|Lauve|Reutenauer|Saliola|2009|p=80}}&lt;/ref&gt;

:&lt;math&gt;Z + (1+Z)^2 t + (1+Z)^3 t^2 = 0 &lt;/math&gt;

=== In combinatorial game theory ===
The set of ''evil numbers'' (numbers &lt;math&gt;n&lt;/math&gt; with &lt;math&gt;t_n=0&lt;/math&gt;) forms a subspace of the nonnegative integers under [[nim-addition]] ([[bitwise operation|bitwise]] [[exclusive or]]).  For the game of [[Kayles]], evil [[nim-value]]s occur for few (finitely many) positions in the game, with all remaining positions having odious nim-values.

=== The Prouhet–Tarry–Escott problem === &lt;!-- This section is linked to from [[Prouhet–Tarry–Escott problem]]. --&gt;
The [[Prouhet–Tarry–Escott problem]] can be defined as: given a positive integer ''N'' and a non-negative integer ''k'', [[Partition of a set|partition]] the set ''S'' = { 0, 1, ..., ''N''-1 } into two [[Disjoint sets|disjoint]] subsets ''S''&lt;sub&gt;0&lt;/sub&gt; and ''S''&lt;sub&gt;1&lt;/sub&gt; that have equal sums of powers up to k, that is:
:&lt;math&gt; \sum_{x \in S_0} x^i = \sum_{x \in S_1} x^i&lt;/math&gt; for all integers ''i'' from 1 to ''k''.

This has a solution if ''N'' is a multiple of 2&lt;sup&gt;''k''+1&lt;/sup&gt;, given by:
* ''S''&lt;sub&gt;0&lt;/sub&gt; consists of the integers ''n'' in ''S'' for which ''t&lt;sub&gt;n&lt;/sub&gt;'' = 0,
* ''S''&lt;sub&gt;1&lt;/sub&gt; consists of the integers ''n'' in ''S'' for which ''t&lt;sub&gt;n&lt;/sub&gt;'' = 1.

For example, for ''N'' = 8 and ''k'' = 2,
:{{nowrap|1= 0 + 3 + 5 + 6 = 1 + 2 + 4 + 7,}}
:{{nowrap|1= 0&lt;sup&gt;2&lt;/sup&gt; + 3&lt;sup&gt;2&lt;/sup&gt; + 5&lt;sup&gt;2&lt;/sup&gt; + 6&lt;sup&gt;2&lt;/sup&gt; = 1&lt;sup&gt;2&lt;/sup&gt; + 2&lt;sup&gt;2&lt;/sup&gt; + 4&lt;sup&gt;2&lt;/sup&gt; + 7&lt;sup&gt;2&lt;/sup&gt;.}}

The condition requiring that ''N'' be a multiple of 2&lt;sup&gt;''k''+1&lt;/sup&gt; is not strictly necessary: there are some further cases for which a solution exists. However, it guarantees a stronger property: if the condition is satisfied, then the set of ''k''th powers of any set of ''N'' numbers in [[arithmetic progression]] can be partitioned into two sets with equal sums. This follows directly from the expansion given by the [[binomial theorem]] applied to the binomial representing the ''n''th element of an arithmetic progression.

For generalizations of the Thue–Morse sequence and the Prouhet–Tarry–Escott problem to partitions into more than two parts, see Bolker, Offner, Richman and Zara, "The Prouhet–Tarry–Escott problem and generalized Thue–Morse sequences".&lt;ref&gt;{{cite journal|last1=Bolker|first1=Ethan|last2=Offner|first2=Carl|last3=Richman|first3=Robert|last4=Zara|first4=Catalin|title=The Prouhet–Tarry–Escott problem and generalized Thue–Morse sequences|journal=Journal of Combinatorics|date=2016|volume=7|issue=1|pages=117–133}}&lt;/ref&gt;

=== Fractals and turtle graphics ===
Using [[turtle graphics]], a curve can be generated if an automaton is programmed with a sequence.
When Thue–Morse sequence members are used in order to select program states:

* If ''t''(''n'') = 0, move ahead by one unit,
* If ''t''(''n'') = 1, rotate by an angle of π/3 [[Radian|radians]] (60°)

The resulting curve converges to the [[Koch snowflake|Koch curve]], a fractal curve of
infinite length containing a finite area. This illustrates the fractal nature of the Thue–Morse Sequence.{{sfnp|Ma|Holdener|2005}}

It is also possible to draw the curve precisely using the following instructions:&lt;ref&gt;{{Cite web|url=http://blog.zacharyabel.com/2012/01/thue-morse-navigating-turtles/|title=Thue-Morse Navigating Turtles|last=Abel|first=Zachary|date=January 23, 2012|website=Three-Cornered Things|archive-url=|archive-date=|dead-url=}}&lt;/ref&gt;

*If ''t''(''n'') = 0, rotate by an angle of π radians (180°),
* If ''t''(''n'') = 1, move ahead by one unit, then rotate by an angle of π/3 radians.

===Equitable sequencing===
In their book on the problem of [[fair division]], [[Steven Brams]] and [[Alan D. Taylor|Alan Taylor]] invoked the Thue–Morse sequence but did not identify it as such.  When allocating a contested pile of items between two parties who agree on the items' relative values, Brams and Taylor suggested a method they called ''balanced alternation'', or ''taking turns taking turns taking turns . . . '', as a way to circumvent the favoritism inherent when one party chooses before the other.  An example showed how a divorcing couple might reach a fair settlement in the distribution of jointly-owned items.  The parties would take turns to be the first chooser at different points in the selection process:  Ann chooses one item, then Ben does, then Ben chooses one item, then Ann does.{{sfnp|Brams|Taylor|1999}}

Lionel Levine and Katherine Stange, in their discussion of how to fairly apportion a shared meal such as an [[Ethiopian cuisine|Ethiopian dinner]], proposed the Thue–Morse sequence as a way to reduce the advantage of moving first.  They suggested that “it would be interesting to quantify the intuition that the Thue-Morse order tends to produce a fair outcome.”{{sfnp|Levine|Stange|2012}}

Robert Richman addressed this problem, but he too did not identify the Thue–Morse sequence as such at the time of publication.&lt;ref name="richman"&gt;{{harvtxt|Richman|2001}}&lt;/ref&gt;   He presented the sequences [[#Characterization using bitwise negation|''T&lt;sub&gt;n&lt;/sub&gt;'']] as [[step function]]s on the interval [0,1] and described their relationship to the [[Walsh function|Walsh]] and [[Hans Rademacher|Rademacher]] functions.  He showed that the ''n''th [[derivative]] can be expressed in terms of  ''T&lt;sub&gt;n&lt;/sub&gt;''.  As a consequence, the step function arising from  ''T&lt;sub&gt;n&lt;/sub&gt;'' is [[Orthogonality|orthogonal]] to [[polynomial]]s of [[Degree of a polynomial|order]] ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1.  A consequence of this result is that a resource whose value is expressed as a [[Monotonic function|monotonically]] decreasing [[continuous function]] is most fairly allocated using a sequence that converges to Thue-Morse as the function becomes [[Flat function|flatter]].  An example showed how to pour cups of [[Drip brew|coffee]] of equal strength from a carafe with a [[Nonlinear system|nonlinear]] [[concentration]] [[gradient]], prompting a whimsical article in the popular press.{{sfnp|Abrahams|2010}}

Joshua Cooper and Aaron Dutle showed why the Thue-Morse order provides a fair outcome for discrete events.&lt;ref name="cooper"&gt;{{harvtxt|Cooper|Dutle|2013}}&lt;/ref&gt;  They considered the fairest way to stage a [[Évariste Galois|Galois]] duel, in which each of the shooters has equally poor shooting skills.  Cooper and Dutle postulated that each dueler would demand a chance to fire as soon as the other’s [[a priori probability|''a priori'' probability]] of winning exceeded their own.  They proved that, as the duelers’ hitting probability approaches zero, the firing sequence converges to the Thue–Morse sequence.  In so doing, they demonstrated that the Thue-Morse order produces a fair outcome not only for sequences [[#Characterization using bitwise negation|''T&lt;sub&gt;n&lt;/sub&gt;'']] of length ''2&lt;sup&gt;n&lt;/sup&gt;'', but for sequences of any length.

Thus the mathematics supports using the Thue–Morse sequence instead of alternating turns when the goal is fairness but earlier turns differ monotonically from later turns in some meaningful quality, whether that quality varies continuously&lt;ref name="richman" /&gt; or discretely.&lt;ref name="cooper" /&gt;

Sports competitions form an important class of equitable sequencing problems, because strict alternation often gives an unfair advantage to one team. Ignacio Palacios-Huerta proposed changing the sequential order to Thue-Morse to improve the ''[[ex post]]'' fairness of various tournament competitions, such as the kicking sequence of a [[Penalty shoot-out (association football)#Procedure|penalty shoot-out]] in soccer, the rotation of color of pieces in a  [[Chess tournament#Rules|chess match]], and the serving order in a [[Tennis score#Scoring a tiebreak game|tennis tie-break]].{{sfnp|Palacios-Huerta|2012}} In [[Rowing (sport)|competitive rowing]], ''T''&lt;sub&gt;2&lt;/sub&gt; is the only arrangement of [[Port and starboard|port- and starboard-rowing]] crew members that eliminates transverse forces (and hence sideways wiggle) on a four-membered coxless racing boat, while ''T''&lt;sub&gt;3&lt;/sub&gt; is one of only four [[Boat rigging|rigs]]  to avoid wiggle on an eight-membered boat.{{sfnp|Barrow|2010}}

Fairness is especially important in [[Draft_(sports)|player drafts]]. Many professional sports leagues attempt to achieve [[Parity_(sports)|competitive parity]] by giving earlier selections in each round to weaker teams. By contrast, [[Fantasy football (American)|fantasy football leagues]] have no pre-existing imbalance to correct, so they often use a “snake” draft (forward, backward, etc.; or ''T''&lt;sub&gt;1&lt;/sub&gt;).&lt;ref&gt;http://www.nfl.com/fantasyfootball/help/drafttypes “Fantasy Draft Types”&lt;/ref&gt; Ian Allan argued that a “third-round reversal” (forward, backward, backward, forward, etc.; or ''T''&lt;sub&gt;2&lt;/sub&gt;) would be even more fair. &lt;ref&gt;Ian Allan, https://www.fantasyindex.com/2014/07/16/fantasy-news/third-round-reversal-drafts "Third-Round Reversal Drafts", July 16, 2014&lt;/ref&gt; Richman suggested that the fairest way for “captain A” and “captain B” to choose sides for a [[Streetball|pick-up game of basketball]] mirrors  ''T''&lt;sub&gt;3&lt;/sub&gt;:  captain A has the first, fourth, sixth, and seventh choices, while captain B has the second, third, fifth, and eighth choices.&lt;ref name="richman" /&gt;

== History ==
The Thue–Morse sequence was first studied by Eugène Prouhet in 1851, who applied it to [[number theory]].
However, Prouhet did not mention the sequence explicitly; this was left to [[Axel Thue]] in 1906, who used it to found the study of [[combinatorics on words]].
The sequence was only brought to worldwide attention with the work of [[Marston Morse]] in 1921, when he applied it to [[differential geometry]].
The sequence has been discovered independently many times, not always by professional research mathematicians; for example, [[Max Euwe]], a [[Grandmaster (chess)|chess grandmaster]], who held the World Championship title from 1935 to 1937, and mathematics [[teacher]], discovered it in 1929 in an application to [[chess]]: by using its cube-free property (see above), he showed how to circumvent [[Threefold_repetition|a rule]] aimed at preventing infinitely protracted games by declaring repetition of moves a draw.

==See also==
*[[Dejean's theorem]]
*[[Fabius function]]
*[[Prouhet–Thue–Morse constant]]

==Notes==
{{reflist|30em}}

==References==
{{refbegin|30em}}
*{{cite news|last=Abrahams|first=Marc|title=How to pour the perfect cup of coffee|url=https://www.theguardian.com/education/2010/jul/13/perfect-coffee-improbable-research|newspaper=The Guardian|date=12 July 2010 |ref=harv}}
*{{cite book|last=Arndt|first=Jörg|title=Matters Computational: Ideas, Algorithms, Source Code|publisher=Springer|year=2011|url=http://jjj.de/fxt/fxtbook.pdf|page=44|chapter=1.16.4 The Thue–Morse sequence|ref=harv}}
*{{cite book | last1 = Allouche | first1 = Jean-Paul | last2 = Shallit | first2 = Jeffrey | author2-link = Jeffrey Shallit | isbn = 978-0-521-82332-6 | publisher = [[Cambridge University Press]] | title = Automatic Sequences: Theory, Applications, Generalizations | year = 2003 | zbl=1086.11015 |ref=harv}}
*{{cite book | last1=Berstel | first1=Jean | last2=Lauve | first2=Aaron | last3=Reutenauer | first3=Christophe | last4=Saliola | first4=Franco V. | title=Combinatorics on words. Christoffel words and repetitions in words | series=CRM Monograph Series | volume=27 | location=Providence, RI | publisher=[[American Mathematical Society]] | year=2009 | isbn=978-0-8218-4480-9 | url=http://www.ams.org/bookpages/crmm-27 | zbl=1161.68043 |ref=harv }}
*{{cite book | editor1-last=Berthé | editor1-first=Valérie|editor-link= Valérie Berthé | editor2-last=Rigo | editor2-first=Michel | title=Combinatorics, automata, and number theory | series=Encyclopedia of Mathematics and its Applications | volume=135 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2010 | isbn=978-0-521-51597-9 | zbl=1197.68006 | page=7 |ref=harv }}
*{{cite book| title=The Win-Win Solution: Guaranteeing Fair Shares to Everybody |last1 = Brams | first1 = Steven J. | last2 = Taylor | first2 = Alan D. |pages=36–44 |isbn=0-393-04729-6 |publisher=W. W. Norton &amp; Co., Inc. |year=1999|ref=harv}}
*{{cite journal|last1=Brlek|first1=Srećko|title=Enumeration of Factors in the Thue-Morse Word|journal=[[Discrete Applied Mathematics]]|year=1989| volume=24|pages=83–96|doi=10.1016/0166-218x(92)90274-e |ref=harv}}
*{{cite book | last=Bugeaud | first=Yann | title=Distribution modulo one and Diophantine approximation | series=Cambridge Tracts in Mathematics | volume=193 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2012 | isbn=978-0-521-11169-0 | zbl=1260.11001 |ref=harv }}
*{{cite journal|last1=Cooper|first1=Joshua|last2=Dutle| first2=Aaron|title=Greedy Galois Games|journal=[[American Mathematical Monthly]]|year=2013| volume=120|issue=5|pages=441–451|url=http://www.math.sc.edu/~cooper/ThueMorseDueling.pdf|doi=10.4169/amer.math.monthly.120.05.441 |ref=harv |arxiv=1110.1137}}
*{{cite book | title=Developments in Language Theory: Proceedings 10th International Conference, DLT 2006, Santa Barbara, CA, USA, June 26-29, 2006 | volume=4036 | series=Lecture Notes in Computer Science | editor1-first=Oscar H. | editor1-last=Ibarra | editor2-first=Zhe | editor2-last=Dang | publisher=[[Springer-Verlag]] | year=2006 | isbn=3-540-35428-X | first=Dalia | last=Krieger | chapter=On critical exponents in fixed points of non-erasing morphisms | pages=280–291 | zbl=1227.68074 |ref=harv }}
*{{cite journal|last1=Levine|first1=Lionel|last2=Stange| first2=Katherine E.|title=How to Make the Most of a Shared Meal: Plan the Last Bite First|journal=[[American Mathematical Monthly]]|year=2012| volume=119|issue=7|pages=550–565|url=http://math.colorado.edu/~kstange/papers/EthiopianDinner.pdf|doi=10.4169/amer.math.monthly.119.07.550 |ref=harv |arxiv=1104.0961}}
*{{cite book | last=Lothaire | first=M. | authorlink=M. Lothaire | title=Algebraic combinatorics on words | others=With preface by Jean Berstel and Dominique Perrin | edition=Reprint of the 2002 hardback | series=Encyclopedia of Mathematics and Its Applications | volume=90| publisher=Cambridge University Press | year=2011 | isbn=978-0-521-18071-9 | zbl=1221.68183 |ref=harv }}
*{{cite book | last=Lothaire | first=M. | authorlink=M. Lothaire | title=Applied combinatorics on words | others=A collective work by Jean Berstel, Dominique Perrin, Maxime Crochemore, Eric Laporte, Mehryar Mohri, Nadia Pisanti, Marie-France Sagot, [[Gesine Reinert]], Sophie Schbath, Michael Waterman, Philippe Jacquet, [[Wojciech Szpankowski]], Dominique Poulalhon, Gilles Schaeffer, Roman Kolpakov, Gregory Koucherov, Jean-Paul Allouche and Valérie Berthé| series=Encyclopedia of Mathematics and Its Applications | volume=105 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2005 | isbn=0-521-84802-4 | zbl=1133.68067 |ref=harv }}
*{{cite journal | last1 = Ma | first1 = Jun | last2 = Holdener | first2 = Judy | author2-link = Judy A. Holdener | doi = 10.1142/S0218348X05002908 | issue = 3 | journal = [[Fractals (journal)|Fractals]] | mr = 2166279 | pages = 191–206 | title = When Thue-Morse meets Koch | url = http://www2.kenyon.edu/people/holdenerj/StudentResearch/WhenThueMorsemeetsKochJan222005.pdf | volume = 13 | year = 2005 |ref=harv }}
*{{cite journal|last=Palacios-Huerta|first=Ignacio|title=Tournaments, fairness and the Prouhet–Thue–Morse sequence|journal=Economic inquiry|year=2012| volume=50|issue=3|pages=848–849|url=http://www.palacios-huerta.com/docs/EI-Tournaments_and_PTM_sequence.pdf|doi=10.1111/j.1465-7295.2011.00435.x |ref=harv }}
* {{cite book | last=Pytheas Fogg | first=N. | others=Editors Berthé, Valérie; Ferenczi, Sébastien; Mauduit, Christian; Siegel, A. | title=Substitutions in dynamics, arithmetics and combinatorics | series=Lecture Notes in Mathematics | volume=1794 | location=Berlin | publisher=[[Springer-Verlag]] | year=2002 | isbn=3-540-44141-7 | zbl=1014.11015 |ref=harv }}
*{{cite journal|last=Richman|first=Robert|title=Recursive Binary Sequences of Differences|journal=[[Complex Systems (journal)|Complex Systems]]|year=2001|volume=13|issue=4|pages=381–392|url=http://www.complex-systems.com/pdf/13-4-3.pdf |ref=harv }}
*{{cite journal|last1=Barrow|first1=John D.|title=Rowing and the Same-Sum Problem Have Their Moments|journal=[[American Journal of Physics]]|year=2010| volume=78|issue=7|pages=728–732|url=https://arxiv.org/pdf/0911.3551v1.pdf|doi=10.1119/1.3318808|ref=harv |arxiv=0911.3551|bibcode=2010AmJPh..78..728B}}
{{refend}}

== External links ==
{{Commons category}}
* {{springer|title=Thue-Morse sequence|id=p/t120090}}
* {{MathWorld|urlname=Thue-MorseSequence|title=Thue-Morse Sequence}}
* Allouche, J.-P.; Shallit, J. O. [http://www.cs.uwaterloo.ca/~shallit/Papers/ubiq15.pdf The Ubiquitous Prouhet-Thue-Morse Sequence]. (contains many applications and some history)
* Thue–Morse Sequence over (1,2) {{OEIS|id=A001285}}
* {{OEIS el|1=A000069|2=Odious numbers: numbers with an odd number of 1's in their binary expansion}}
* {{OEIS el|1=A001969|2=Evil numbers: numbers with an even number of 1's in their binary expansion}}
* [https://www.webcitation.org/query?url=http://www.geocities.com/jan.schat/ThueMorse.PDF&amp;date=2009-10-26+00:40:54 Reducing the influence of DC offset drift in analog IPs using the Thue-Morse Sequence]. A technical application of the Thue–Morse Sequence
* [http://reglos.de/musinum MusiNum - The Music in the Numbers]. Freeware to generate self-similar music based on the Thue–Morse Sequence and related number sequences.
* {{cite web|last1=Parker|first1=Matt|authorlink1=Matt Parker|title=The Fairest Sharing Sequence Ever|url=https://www.youtube.com/watch?v=prh72BLNjIk|publisher=standupmaths|accessdate=20 January 2016|format=video}}

{{DEFAULTSORT:Thue-Morse Sequence}}
[[Category:Binary sequences]]
[[Category:Fixed points (mathematics)]]
[[Category:Parity (mathematics)]]</text>
      <sha1>abennqprg958lepm0owwwbjqetxnovz</sha1>
    </revision>
  </page>
  <page>
    <title>Tombstone (typography)</title>
    <ns>0</ns>
    <id>819251</id>
    <revision>
      <id>856178660</id>
      <parentid>740783745</parentid>
      <timestamp>2018-08-23T11:57:49Z</timestamp>
      <contributor>
        <username>Jlundell</username>
        <id>213139</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2202">[[Image:Halmos symbols.png|frame|right|Various forms of the end-of-proof symbol]]
The '''tombstone''', '''Halmos''', '''end of proof''', or '''Q.E.D.''' mark "∎" is used in [[mathematics]] to denote the end of a [[Mathematical proof|proof]], in place of the traditional abbreviation "Q.E.D."  for the Latin phrase "''[[Q.E.D.|quod erat demonstrandum]]''", "which was to be shown". In magazines, it is one of the various symbols used to indicate the end of an article.

In [[Unicode]], it is represented as character {{unichar|220E|End of Proof|html=}}. Its graphic form varies. It may be a hollow or filled rectangle or square.

In [[AMS-LaTeX]], the symbol is automatically appended at the end of a proof environment &lt;tt&gt;\begin{proof}&lt;/tt&gt; ... &lt;tt&gt;\end{proof}&lt;/tt&gt;. It can also be obtained from the commands &lt;tt&gt;\qedsymbol&lt;/tt&gt; or &lt;tt&gt;\qed&lt;/tt&gt; (the latter causes the symbol to be right aligned).

It is sometimes called a halmos after the mathematician [[Paul Halmos]], who first used it in mathematical context. He got the idea of using it from seeing it was being used to indicate the end of articles in [[magazine]]s. In his memoir ''I Want to Be a Mathematician'', he wrote the following:&lt;ref&gt;Paul R. Halmos, ''I Want to Be a Mathematician: An Automathography'', 1985, p. 403.&lt;/ref&gt;
{{quote|The symbol is definitely not my invention&amp;nbsp;— it appeared in popular magazines (not mathematical ones) before I adopted it, but, once again, I seem to have introduced it into mathematics. It is the symbol that sometimes looks like ▯, and is used to indicate an end, usually the end of a proof. It is most frequently called the 'tombstone', but at least one generous author referred to it as the 'halmos'.}}

==See also==
*[[-30-]]
*[[Block Elements]]
*[[End-of-file]]
*[[End-of-transmission character]]

==Notes==
&lt;references/&gt;

==References==
*{{Citation
  | last = Miller
  | first = Jeff
  | author-link = 
  | title = Earliest Uses of Symbols of Set Theory and Logic
  | date = September 29, 2007

  | url = http://jeff560.tripod.com/set.html
  | accessdate = June 26, 2010}}


{{typ-stub}}

[[Category:Mathematical proofs]]
[[Category:Mathematical symbols]]
[[Category:Typography|Tombstone]]</text>
      <sha1>ep3f8q277qfwdlejx12mvpfoorxfapi</sha1>
    </revision>
  </page>
  <page>
    <title>Wehrl entropy</title>
    <ns>0</ns>
    <id>35976444</id>
    <revision>
      <id>854487674</id>
      <parentid>843200887</parentid>
      <timestamp>2018-08-11T18:32:32Z</timestamp>
      <contributor>
        <username>AquaDTRS</username>
        <id>4055378</id>
      </contributor>
      <minor/>
      <comment>/* See also */ +Lieb conjecture</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12751">In [[quantum information]] theory, the '''Wehrl entropy''',&lt;ref name=":0"&gt;{{Cite journal|last=Wehrl|first=A.|year=1979|title=On the relation between classical and quantum-mechanical entropy|journal=Reports on Mathematical Physics|doi=10.1016/0034-4877(79)90070-3|volume=16|issue=3|pages=353|bibcode=1979RpMP...16..353W}}&lt;/ref&gt; named after Alfred Wehrl, is a [[Entropy (information theory)|classical entropy]] of a [[Quantum mechanics|quantum-mechanical]] [[density matrix]]. It is a type of quasi-[[entropy]] defined for the [[Husimi Q representation]] of the phase-space [[quasiprobability distribution]]. See &lt;ref&gt;{{Cite journal|last=Wehrl|first=A.|year=1978|title=General properties of entropy|journal=Reviews of Modern Physics|doi=10.1103/RevModPhys.50.221|volume=50|issue=2|pages=221|bibcode=1978RvMP...50..221W}}&lt;/ref&gt; for a comprehensive review of basic properties of [[Entropy (information theory)|classical]], [[Von Neumann entropy|quantum]] and Wehrl entropies, and their implications in [[statistical mechanics]].

== Definitions ==
The '''Husimi function'''&lt;ref&gt;Kôdi Husimi (1940). "Some Formal Properties of the Density Matrix", ''Proc. Phys. Math. Soc. Jpn.'' '''22''': 264–314 .&lt;/ref&gt; is a "[[Phase space|classical phase-space]]" function of [[Position and momentum space|position]] {{mvar|x}} and [[Position and momentum space|momentum]] {{mvar|p}}, and in one dimension is defined for any quantum-mechanical density matrix {{mvar|ρ }} by 
:&lt;math&gt;Q_\rho(x,p)=\int \phi(x,p | y)^* \rho (y, y')\phi (x,p|y')dy dy',&lt;/math&gt;
where {{mvar|φ}} is a "'''[[Coherent states in mathematical physics|(Glauber) coherent state]]'''", given by
:&lt;math&gt;\phi(x,p|y)=\pi^{-1/4}\exp(-|y-x|^2/2)+i\, px).&lt;/math&gt;
(It can be understood as the [[Weierstrass transform]] of the [[Wigner quasi-probability distribution]].)

The '''Wehrl entropy''' is then defined as
: &lt;math&gt;S_W(\rho) = -\int Q_\rho(x,p) \log Q_\rho(x,p) \, dx \, dp ~.&lt;/math&gt;
The definition can be easily generalized to any finite dimension.

== Properties ==
Such a definition of the entropy relies on the fact that the Husimi Q representation remains non-negative definite,&lt;ref&gt;{{Cite journal|year=1975|title=A non-negative Wigner-type distribution|journal=Physica A: Statistical Mechanics and its Applications|volume=83|pages=210–818|bibcode=1975PhyA...83..210C|doi=10.1016/0378-4371(76)90145-X|pmc=|pmid=|last1=Cartwright|first1=N. D.}}&lt;/ref&gt; unlike other representations of quantum quasiprobability distributions in phase space. The Wehrl entropy has several important properties: 
# It is always positive, &lt;math&gt;S_W(\rho)\geq 0,&lt;/math&gt; like the full quantum von Neumann entropy, but unlike the [[Entropy (information theory)|classical differential entropy]] which can be negative at low temperature. In fact, the minimum value of the Wehrl entropy is 1, i.e. &lt;math&gt;S_W(\rho)\geq 1,&lt;/math&gt; as discussed below in the section "Werhl's conjecture".  
# The entropy for the tensor product of two systems is always greater than the entropy of one system. In other words, for a state &lt;math&gt;\rho&lt;/math&gt; on a Hilbert space &lt;math&gt;\mathcal{H}=\mathcal{H}_1\otimes\mathcal{H}_2&lt;/math&gt;, we have &lt;math&gt;S_W(\rho_1)\leq S_W(\rho)&lt;/math&gt;, where &lt;math&gt;\rho_1=\mathrm{Tr}_2\, \rho&lt;/math&gt;. Note that the quantum [[von Neumann entropy]], &lt;math&gt;S(\rho)&lt;/math&gt;, does not have this property, as can be clearly seen for a pure [[Quantum entanglement|maximally entangled state]]. 
# The Wehrl entropy is strictly lower bounded by a von Neumann entropy, &lt;math&gt;S_W(\rho) &gt; S(\rho)&lt;/math&gt;. There is no known upper or lower bound (other than zero) for the difference &lt;math&gt;S_W(\rho)-S(\rho)&lt;/math&gt;.  
# The Wehrl entropy is not invariant under all unitary transformations, unlike the von Neumann entropy. In other words, &lt;math&gt;S_W(U^* \rho \,U)\neq S_W(\rho)&lt;/math&gt; for a general unitary {{mvar|U}}. It is, however, invariant under certain unitary transformations.&lt;ref name=":0" /&gt;

== Wehrl's conjecture ==
In his original paper &lt;ref name=":0" /&gt; Wehrl posted a conjecture that the smallest possible value of Wehrl entropy is 1, &lt;math&gt;S_W(\rho)\geq 1,&lt;/math&gt; and it occurs if and only if the density matrix &lt;math&gt;\rho&lt;/math&gt; is a pure state projector onto any coherent state, i.e. for all choices of &lt;math&gt;x_0, p_0&lt;/math&gt;,
:&lt;math&gt;\rho_0(y, y')=\phi(x_0,p_0|y)^*\phi(x_0,p_0|y')&lt;/math&gt;.

Soon after the conjecture was posted, [[Elliott H. Lieb|E. H. Lieb]] proved &lt;ref name=":1"&gt;{{Cite journal|last=Lieb|first=E.H.|year=1978|title=Proof of an entropy conjecture of Wehrl|journal=Communications in Mathematical Physics|volume=62}}&lt;/ref&gt; that the minimum of the Wehrl entropy is 1, and it occurs when the state is a projector onto any coherent state.

In 1991 E. Carlen proved &lt;ref&gt;{{Cite journal|last=Carlen|first=E.|year=1991|title=Some integral identities and inequalities for entire functions and their application to the coherent state transform|journal=Journal of Functional Analysis|volume=97|pages=231|doi=10.1016/0022-1236(91)90022-W}}&lt;/ref&gt; the uniqueness of the minimizer, i.e. the minimum of the Wehrl entropy occurs only when the state is a projector onto any coherent state.

== Discussion ==
However, it is not the fully quantum [[von Neumann entropy]] in the Husimi representation in phase space, {{math|− ∫ ''Q'' &lt;small&gt;★&lt;/small&gt;  log&lt;sub&gt;&lt;sub&gt;★&lt;/sub&gt;&lt;/sub&gt;''Q'' &amp;nbsp;''dx''&amp;nbsp;''dp''}}:   all the requisite  star-products &lt;small&gt;★&lt;/small&gt; in that entropy have been dropped here. In the Husimi representation, the star products read
: &lt;math&gt;  \star \equiv     \exp\left( \frac{\hbar}{2} 
({\stackrel{\leftarrow}{\partial}}_x -i {\stackrel{\leftarrow}{\partial}}_p) ({\stackrel{\rightarrow}{\partial}}_x  + i{\stackrel{\rightarrow}{\partial}}_p )   \right)~,&lt;/math&gt;
and are isomorphic&lt;ref&gt;[[Cosmas Zachos|C. Zachos]], D. Fairlie, and [[Thomas Curtright|T. Curtright]], “Quantum Mechanics in Phase Space” (''World Scientific'', Singapore, 2005) {{ISBN|978-981-238-384-6}} .&lt;/ref&gt; to the [[Moyal product]]s of the [[Wigner–Weyl transform|Wigner–Weyl representation]].

The Wehrl entropy, then, may be thought of as a type of heuristic semiclassical approximation to the full quantum von Neumann entropy, since it retains some {{mvar|ħ}} dependence (through ''Q'') but ''not all of it''.

Like all entropies, it reflects some measure of non-localization,&lt;ref&gt;{{cite journal|last=Gnutzmann|first=Sven|year=2001|title=Rényi–Wehrl entropies as measures of localization in phase space|journal=J. Phys. A: Math. Gen.|volume=34|issue=47|pages=10123|arxiv=quant-ph/0106016|bibcode=2001JPhA...3410123G|doi=10.1088/0305-4470/34/47/317|author2=Karol Zyczkowski|authorlink2=Karol Życzkowski}}
&lt;/ref&gt; as the [[Weierstrass transform|Gauss transform]] involved in generating {{mvar|Q}} and the sacrifice of the star operators have effectively discarded information. In general, as indicated, for the same state, the Wehrl entropy exceeds the von Neumann entropy (which vanishes for pure states).

== Wehrl entropy for Bloch coherent states ==
Wehrl entropy can be defined for other kinds of coherent states. For example, it can be defined for Bloch coherent states, that is, for [[Angular momentum operator|angular momentum]] [[Representation theory|representations]] of the group &lt;math&gt;SU(2)&lt;/math&gt; for [[Spin (physics)|quantum spin systems]].

=== Bloch coherent states ===
Consider a space &lt;math&gt;\mathbb{C}^{2J+1}&lt;/math&gt; with &lt;math&gt;J=\frac{1}{2}, 1, \frac{3}{2}, \dots&lt;/math&gt; . We consider a single quantum spin of fixed angular momentum {{mvar|J}}, and shall denote by &lt;math&gt;\mathbf{S}=(S_x, S_y, S_z)&lt;/math&gt; the usual angular momentum operators that satisfy the following commutation relations: &lt;math&gt;[S_x, S_y]=i \,S_z&lt;/math&gt; and cyclic permutations.

Define &lt;math&gt;S_\pm=S_x\pm i\, S_y&lt;/math&gt;, then &lt;math&gt;[S_z, S_\pm]=\pm S_\pm&lt;/math&gt; and &lt;math&gt;[S_+, S_-]=S_z&lt;/math&gt;.

The eigenstates of &lt;math&gt;S_z&lt;/math&gt; are
:&lt;math&gt;S_z|s\rangle=s|s\rangle, s=-J,\dots, J.&lt;/math&gt;

For &lt;math&gt;s=J&lt;/math&gt; the state &lt;math&gt;|J\rangle\in \mathbb{C}^{2J+1}&lt;/math&gt; satisfies: &lt;math&gt;S_z|J\rangle=J|J\rangle, &lt;/math&gt; and &lt;math&gt;S_+|J\rangle=0, S_-|J\rangle=|J-1\rangle&lt;/math&gt;.

Denote the unit sphere in three dimensions by 
:&lt;math&gt;\Xi_2=\{\Omega=(\theta, \phi)\ | \ 0\leq \theta \leq \pi,\ 0\leq \phi\leq 2\pi\}&lt;/math&gt;, 
and by &lt;math&gt;L^2(\Xi)&lt;/math&gt; the space of square integrable function on {{mvar|Ξ}}  with the measure 
:&lt;math&gt;d\Omega=\frac{2J+1}{4\pi}\sin\theta\, d\theta\, d\phi&lt;/math&gt;.

The '''Bloch coherent state''' is defined by 
:&lt;math&gt;|\Omega\rangle\equiv \exp\left\{\frac{1}{2}\theta e^{i\phi}S_--\frac{1}{2}\theta e^{-i\phi}S_+\right\}|J\rangle&lt;/math&gt;.

Taking into account the above properties of the state &lt;math&gt;|J\rangle&lt;/math&gt;, the Bloch coherent state can also be expressed as
:&lt;math&gt;|\Omega\rangle=(1+|z|^2)^{-J}e^{z S_-}|J\rangle=(1+|z|^2)^{-J}\sum_{M=-J}^J z^{J-M}\binom{2J}{J+M}^{1/2}|M\rangle,&lt;/math&gt;
where &lt;math&gt;~~z=e^{i\phi}\tan \frac{\theta}{2}&lt;/math&gt;, and 
:&lt;math&gt;|M\rangle=\binom{2J}{J+M}^{-1/2}\frac{1}{(J-M)!}\, S_-^{J-M}|J\rangle&lt;/math&gt; 
is a normalised eigenstate of &lt;math&gt;S_z&lt;/math&gt; satisfying &lt;math&gt;S_z|M\rangle=M|M\rangle&lt;/math&gt;.

The Bloch coherent state is an eigenstate of the rotated angular momentum operator &lt;math&gt;S_z&lt;/math&gt; with a maximum eigenvalue. In other words, for a rotation operator 
:&lt;math&gt;R_{\theta,\phi}=\exp\left\{\frac{1}{2}\theta e^{i\phi} S_--\frac{1}{2}\theta e^{-i\phi} S_+ \right\}&lt;/math&gt;, 
the Bloch coherent state &lt;math&gt;|\Omega\rangle&lt;/math&gt; satisfies 
:&lt;math&gt;R_{\theta, \phi} S_z R^{-1}_{\theta, \phi} \ |\Omega\rangle=J\,|\Omega\rangle&lt;/math&gt;.

=== Wehrl entropy for Bloch coherent states ===
Given a density matrix   {{mvar|ρ}}, define the semi-classical density distribution 
:&lt;math&gt;\rho^{cl}(\Omega)=\langle \Omega| \rho |\Omega \rangle&lt;/math&gt;. 
The Wehrl entropy of &lt;math&gt;\rho&lt;/math&gt; for Bloch coherent states is defined as a classical entropy of the density distribution &lt;math&gt;\rho^{cl}&lt;/math&gt;,
:&lt;math&gt;S_W^B(\rho)=S^{cl}(\rho^{cl})=-\int \rho^{cl}(\Omega)\ \ln \rho^{cl}(\Omega)\ d\Omega&lt;/math&gt;,
where &lt;math&gt;S^{cl}&lt;/math&gt; is a classical differential entropy.

=== Wehrl's conjecture for Bloch coherent states ===
The analogue of the Wehrl's conjecture for Bloch coherent states was proposed in &lt;ref name=":1" /&gt; in 1978. It suggests the minimum value of the Werhl entropy for Bloch coherent states, 
:&lt;math&gt;S_W^B(\rho)\geq \frac{2J}{2J+1}&lt;/math&gt;,  
and states that the minimum is reached if and only if the state is a pure Bloch coherent state.

In 2012 E. H. Lieb and J. P. Solovej proved &lt;ref name=":2"&gt;{{Cite journal|last=Lieb|first=E.H.|last2=Solovej|first2=J.P.|year=2014|title=Proof of an entropy conjecture for Bloch coherent spin states and its generalizations|journal=Acta Mathematica|volume=212|issue=2|pages=379|doi=10.1007/s11511-014-0113-6|arxiv=1208.3632}}&lt;/ref&gt; a substantial part of this conjecture, confirming the minimum value of the Wehrl entropy for Bloch coherent states, and the fact that it is reached for any pure Bloch coherent state. The problem of the uniqueness of the minimizer remains unresolved.

== Generalized Wehrl's conjecture ==
In &lt;ref name=":2" /&gt; E. H. Lieb and J. P. Solovej proved Wehrl's conjecture for Bloch coherent states by generalizing it in the following manner.

=== Generalized Wehrl's conjecture ===
For any [[Concave function|concave]] function &lt;math&gt;f: [0,1]\rightarrow \mathbb{R}&lt;/math&gt; (e.g. &lt;math&gt;f(x)=-x\log x&lt;/math&gt; as in the definition of the Wehrl entropy), and any density matrix {{mvar|ρ}}, we have
:&lt;math&gt;\int f(Q_\rho(x,p))dx\, dp \geq \int f(Q_{\rho_0}(x,p))dx\, dp&lt;/math&gt;,
where {{mvar|ρ}}&lt;sub&gt;0&lt;/sub&gt; is a pure coherent state defined in the section "Wehrl conjecture".

=== Generalized Wehrl's conjecture for Bloch coherent states ===
Generalized Wehrl's conjecture for Glauber coherent states was proved as a consequence of the similar statement for Bloch coherent states. For any [[Concave function|concave]] function &lt;math&gt;f: [0,1]\rightarrow \mathbb{R}&lt;/math&gt;, and any density matrix {{mvar|ρ}} we have
:&lt;math&gt;\int f(\langle \Omega|\rho|\Omega\rangle)d\Omega \geq \int f(|\langle \Omega|\Omega_0\rangle|^2)d\Omega&lt;/math&gt;,
where &lt;math&gt;\Omega_0\in\Xi_2&lt;/math&gt; is any point on a sphere.

The uniqueness of the minimizers for either statement remains an open problem.

== See also ==
* [[Coherent states in mathematical physics|Coherent state]]
* [[Entropy (information theory)|Entropy]]
* [[Information theory and measure theory]]
* [[Lieb conjecture]]
* [[Quantum information]]
* [[Mathematical formulation of quantum mechanics|Quantum mechanics]]
* [[Spin (physics)|Spin]]
* [[Statistical mechanics]]
* [[Von Neumann entropy]]

== References ==
&lt;references /&gt;

[[Category:Quantum mechanical entropy]]
[[Category:Mathematical physics]]
[[Category:Quantum mechanics]]</text>
      <sha1>kaj8ieatadgpp31l8z9mjxirr8ehrng</sha1>
    </revision>
  </page>
</mediawiki>
