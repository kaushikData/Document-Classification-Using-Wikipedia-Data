{"id": "35113348", "url": "https://en.wikipedia.org/wiki?curid=35113348", "title": "2011 Wisconsin Act 23", "text": "2011 Wisconsin Act 23\n\nThe 2011 Wisconsin Act 23 established a requirement for nearly all voters to present approved photo identification to cast a ballot. It was one of many new voter ID laws in the United States. Act 23 was developed by Republican Governor Scott Walker and the Republican controlled Wisconsin Legislature during a walkout by Democratic lawmakers as part of the 2011 Wisconsin protests.\n\nSection 1 of Act 23 specifies that only the following forms of photo identification are acceptable:\n\nIn July 2011, the Associated Press reported that the Scott Walker administration was planning to close some DMV locations that could issue identification under the voter ID law and increase the hours that other DMVs were available. The changes were made to comply with a requirement that every county have a DMV location open at least 20 hours per week. A Democratic legislator said that the closures would occur in primarily Democratic areas, while the expansions would occur in primarily Republican areas. Two weeks later, the plan was replaced with a plan to maintain all existing DMV offices and create four new ones.\n\nIn July 2011, the Wisconsin Department of Transportation (DOT) sent an internal memo instructing employees that an applicant for an ID card must pay the $28 fee unless the applicant requests that the ID be issued for free. In September 2011, the DMV began posting signs instructing applicants seeking free \"ID cards used for voting\" to check the appropriate box on the application form.\n\nAs initially implemented, an applicant for an identification card was required to present a birth certificate. The Division of Motor Vehicles maintains form MV3002, which allows identification cards to be issued without a birth certificate. The form is not mentioned in publicly available materials published by the DMV, and a high-ranking DMV official was unfamiliar with the form. On September 2014, a procedure was implemented where applicants could supply birth information that would be verified with the State Vital Records Office for free.\n\nOn December 13, 2011, the American Civil Liberties Union (ACLU) filed the lawsuit \"Frank v. Walker\" in the United States District Court for the Eastern District of Wisconsin seeking to block the Act as a violation of the U.S. Constitution. In April 2014, U.S. District Judge Lynn S. Adelman in Milwaukee issued a permanent injunction against the Act, ruling that the Act was unconstitutional as well as a violation of the Voting Rights Act of 1965. Adelman said that it was not shown that voters without acceptable identification could obtain it under the Act and that the state failed to show evidence of recent voter impersonation fraud. Adelman's ruling marked that first time that a voter ID law had been found to violate Section 2 of the Voting Rights Act. Adelman found a violation of Section 2 on the basis of racial minorities not only being more likely to lack acceptable identification, but also facing additional barriers to acquiring acceptable identification.\n\nIn a separate litigation, on July 31, 2014, the Wisconsin Supreme Court rejected a challenge to the Act by giving the Wisconsin Department of Motor Vehicles discretion to waive fees, over dissent by Chief Justice Shirley Abrahamson, and Justices N. Patrick Crooks and Ann Walsh Bradley.\n\nThe state appealed to the United States Court of Appeals for the Seventh Circuit and asked for a stay of Judge Adelman's injunction. On September 12, 2014, the same day oral arguments were held, a Seventh Circuit panel stayed Adelman's injunction, allowing the Act to immediately take effect, and Wisconsin officials announced plans to implement the Act for the November 2014 election. Judge Frank H. Easterbrook was joined by Judges Diane S. Sykes and John Daniel Tinder. On October 10, an equally divided circuit voted 5-5 to deny rehearing en banc, over written dissent by Judge Richard Posner.\n\nOn October 9, 2014, the Supreme Court of the United States vacated the stay imposed by the Seventh Circuit, and thus temporarily barred the state from implementing the voter id law, due to\nthe proximity of the upcoming general election and the fact that absentee ballots were sent out without any notation that proof of photo identification must be submitted, over written dissent by Justice Samuel Alito, joined by Justices Antonin Scalia and Clarence Thomas..\n\nOn March 23, 2015, the Supreme Court denied the plaintiffs' petition for a \"writ of certiorari\".\n\nOn October 19, 2015, Judge Adelman, entered the order denying the injunction. However, on April, 12, 2016, the Seventh Circuit reversed and remanded, with Judge Easterbrook finding the plaintiffs could now challenge the law as it had been applied individually. On July 19, Judge Adelman found that the state was applying the Act unconstitutionally, ordering the state to allow anyone who makes an affidavit of their eligibility to vote in the November general election.\n\nOn July 29, 2016, in a separate trial in the United States District Court for the Western District of Wisconsin in Madison, U.S. District Judge James D. Peterson also found the Act was applied unconstitutionally but ordering more limited oversight. On August 10, 2016, the Seventh Circuit stayed Judge Adelman’s injunction, leaving in place Judge Peterson’s order.\n\nJudge Peterson held a new hearing after reading news reports in \"The Nation\" magazine that the state was ignoring his order. On October 13, 2016, Judge Peterson entered an order expanding his oversight but still not permitting voters to swear eligibility by affidavit. The United States presidential election in Wisconsin, 2016 was held on November 8.\n\nIn unrelated litigation, on November 21, the Seventh Circuit found Wisconsin Legislature’s 2011 redistricting plan was an unconstitutionally partisan gerrymandering, the first successful claim of partisan gerrymandering in the United States in thirty years.\n\n"}
{"id": "22523340", "url": "https://en.wikipedia.org/wiki?curid=22523340", "title": "Alliance for Justice and Democracy/Movement for Renewal", "text": "Alliance for Justice and Democracy/Movement for Renewal\n\nThe Alliance for Justice and Democracy/Movement for Renewal (\"Alliance pour la Justice et la Démocratie/Mouvement pour la Rénovation\", AJD/MR) is a political party in Mauritania. It represents the black minority population of the south of the country, centered on the Senegal River valley, and was formed and is led by rights activist and former presidential candidate Ibrahima Moctar Sarr. The party's colours are black and white, and its symbol is a Zebu bull, livestock being associated with the traditionally pastoralist Fula people who make up much of its constituency.\n\nThe party was founded in August 2007 by a merger of Ibrahima Moctar Sarr's Movement for National Reconciliation and the Alliance for Justice and Democracy (AJD) party, with Sarr elected as the leader of the new party. Sarr, a Serer journalist, had been a high profile activist since the 1980s, and his party defined itself as campaigning for equal rights for Pulaar-speakers, Soninké and Wolof people alongside Moors, and the return of Mauritanian refugees from Senegal. Sarr had stood as an independent in the March 2007 presidential election on an anti-racist platform, came in fifth place with 7.95% in the first round and supported Ahmed Ould Daddah for the second round.\n\nOn May 10, 2008 the AJD/MR announced they would not participate in the government of Prime Minister Yahya Ould Ahmed El Waghef due to policy differences.\n\nFollowing the August 2008 military coup, Sarr and the AJD/MR expressed support for the military junta. But on August 26, 2008, the AJD/MR, along with the Rally of Democratic Forces (RFD) and the Movement for Direct Democracy (MDD) all announced their decision to not participate in the Laghdaf's government because the junta had not clarified whether or not someone serving in the military would be allowed to stand as a presidential candidate and had not specified how long it intended to remain in power. The new government led by Laghdaf was appointed on August 31\n\nSarr announced on 11 April 2009, that he would be the AJD/MR candidate in the controversial June 2009 presidential election, which was being organized by the junta and which opposition parties were planning to boycott. Sarr said that \"the conditions are there for a free poll\" and that Mauritania did not have democracy under Abdallahi's presidency.\n\n"}
{"id": "44466471", "url": "https://en.wikipedia.org/wiki?curid=44466471", "title": "Association internationale des femmes", "text": "Association internationale des femmes\n\nThe Association internationale des femmes (AIF; International Association of Women) was a short-lived feminist and pacifist organization based in Geneva that was active between 1868 and 1872. It demanded full equality between men and women. This was too radical for many feminists at the time.\n\nThe origins of the association may perhaps be traced to the 1854 proposal by the Swedish feminist Fredrika Bremer for a women-only organization dedicated to peace.\nThe Swiss feminist Marie Goegg-Pouchoulin (1826–99) was active in the International Peace and Freedom League when it was founded in 1867, became a member of its central committee and edited the league's journal \"Les États-Unis d'Europe\".\nOn 8 March 1868 the journal published Goegg's proposal to create an international association of women in connection with the league.\nThis became the \"Association Internationale des Femmes\" (AIF).\n\nFoundation of the AIF and of Eugénie Niboyet's feminist and pacifist weekly \"La Paix des Deux Mondes\" mark the start of identification by women with peace work.\nAccording to the historian Sandi Cooper, Goegg was responding to the growing militarism of Prussia and aimed for, \"the re-education of mothers to prevent another generation of boys trained to respect the false idols of national glory through military conquest.\n\nThe AIF was the first transnational women's organization. It was concerned with women's suffrage and with secular education.\nThe association demanded \"equality in salary, in instruction, in the family, and in the law\".\nAn AIF membership card issued to Matilde Bajer of Copenhagen in December 1870 states that its goals were, \"To work for the moral and intellectual advancement of woman, for the gradual amelioration of her position in society by calling for her human, civil, economic and political rights.\"\n\nThe association's position was too extreme for many middle-class women, so the number of members remained relatively small.\nThe association's activities were disrupted by the 1870 Franco-Prussian War, but it was revived by Goegg at the end of 1870.\nThe organization received international coverage in pacifist and feminist publications, such as the journal \"Woman\", edited and published in Italy by Alaide Gualberta Beccari.\nHowever, the association failed to develop a strong organizational foundation. \nBy 1872 the AIF was viewed with suspicion, since the word \"International\" was associated with the Paris Commune. Members were also divided over Goegg's leadership.\n\nIn June 1872 a communique was issued that called for a meeting at the home of Julie von May von Rued in Bern to organize a new association called \"Solidarité: Association pour la défense des droits de la femme\" (Solidarity: Association for the Defense of Women's Rights). \nSignatories included Caroline de Barrau of France, Josephine Butler of England, Christine Lazzati of Milan and the German feminists Rosalie Schönwasser, Marianne Menzzer and Julie Kühne.\nMarie Goegg-Pouchoulin was also active in this organization.\n\n"}
{"id": "14240770", "url": "https://en.wikipedia.org/wiki?curid=14240770", "title": "Bodo League massacre", "text": "Bodo League massacre\n\nThe Bodo League massacre () was a massacre and war crime against communists and suspected sympathizers (many of whom were civilians who had no connection with communism or communists) that occurred in the summer of 1950 during the Korean War. Estimates of the death toll vary. It has been estimated that the number of victims killed is between 100,000 and 200,000. The number of Bodo League members killed in Ulsan, Cheongdo County and Kimhae alone, where the number of confirmed victims was almost exactly 4,934, was 30 to 70 percent of the press alliance members massacred and more than 100 people to more than 1,000 people were killed in each county unit respectively. The massacre was wrongly blamed on the communists. For four decades the South Korean government concealed this massacre. Survivors were forbidden by the government from revealing it, under suspicion of being communist sympathizers. Public revelation carried with it the threat of torture and death. During the 1990s and onwards, several corpses were excavated from mass graves, resulting in public awareness of the massacre.\n\nSouth Korean President Syngman Rhee had about 300,000 suspected communist sympathizers or his political opponents enrolled in an official \"re-education\" movement known as the \"Bodo League\" (or National Rehabilitation and Guidance League, National Guard Alliance, National Guidance Alliance National Bodo League, Bodo Yeonmaeng, Gukmin Bodo Ryeonmaeng, 국민보도연맹, 國民保導聯盟) on the pretext of protecting them from execution. The Bodo League was created by Korean jurists who had collaborated with the Japanese. Non-communist sympathizers and others were also forced into the Bodo League to fill enlistment quotas.\n\nIn June 1949 the South Korean government accused independence activists of being members of the Bodo League. In 1950, just before the outbreak of the Korean War, the first president of South Korea, Syngman Rhee, had about 20,000 alleged communists imprisoned.\n\nUnder the leadership of Kim Il-sung, the Korean People's Army attacked from the north on 25 June 1950, starting the Korean War. According to Kim Mansik, who was a military police superior officer, President Syngman Rhee ordered the execution of people related to either the Bodo League or the South Korean Workers Party on 27 June 1950. The first massacre was started one day later in Hoengseong, Gangwon-do on 28 June. Retreating South Korean forces and anti-communist groups executed the alleged communist prisoners, along with many of the Bodo League members. The executions were performed without any trials or sentencing. Kim Tae Sun, the chief of the Seoul Metropolitan Police, admitted to personally executing at least 12 \"communists and suspected communists\" after the outbreak of the war. When Seoul was recaptured in late September 1950, an estimated 30,000 South Koreans were summarily deemed collaborators with the North Koreans and shot by ROK forces. At least one US lieutenant colonel is known to have approved the executions, when he told a South Korean colonel that he could kill a large number of prisoners in Busan if the North Korean troops approached. A mass execution of 3,400 South Koreans did indeed take place near Busan that summer.\n\nUnited States official documents show that American officers witnessed and photographed the massacre. In one case a US officer is known to have sanctioned the killing of political prisoners so that they would not fall into enemy hands. In another, United States official documents show that John J. Muccio, then United States Ambassador to South Korea, made recommendations to South Korean President Rhee Syngman and Defense Minister Shin Sung-mo that the executions be stopped. American witnesses also reported the scene of the execution of a girl who appeared to be 12 or 13 years old. The massacre was also reported to both Washington and Gen. Douglas MacArthur, who described it as an \"internal matter\". According to one witness, 40 victims had their backs broken with rifle butts and were shot later. Victims in seaside villages were tied together and thrown into the sea to drown. Retired South Korean Adm. Nam Sang-hui confessed that he authorized 200 victims' bodies to be thrown into the sea, saying, \"There was no time for trials for them.\"\n\nThere were also British and Australian witnesses. Great Britain raised this issue with the U.S. at a diplomatic level, causing Dean Rusk, Assistant Secretary of State for Far Eastern Affairs, to inform the British that U.S. commanders were doing \"everything they can to curb such atrocities\". During the massacre, the British protected their allies and saved some citizens.\n\nAfter the UN offensive in which South Korea recovered its occupied territories, the police and militia groups executed suspected North Korean sympathizers. In October 1950, the Goyang Geumjeong Cave Massacre occurred. In December, British troops saved civilians lined up to be shot by South Korean officers and seized one execution site outside Seoul to prevent further massacres. On January 4, 1951, the Ganghwa massacre was committed by South Korean police, who killed 139 civilians in an effort to prevent their collaboration with the North Koreans. According to a South Korean report, South Korea and the U.S. \"aided right-wing civil organizations,\nsuch as the Ganghwa Self-defense Forces, by providing combat equipment and supplies.\"\n\nIn 2008, trenches containing the bodies of children were discovered in Daejeon, South Korea, and other sites. South Korea's Truth and Reconciliation Commission documented testimonies of those still alive and who took part in the executions, including former Daejeon prison guard Lee Joon-young.\n\nBesides photographs of the execution trench sites, the National Archives in Washington D.C. released declassified photographs of U.S. soldiers at execution sites including Daejeon, confirming American military knowledge.\n\n\n"}
{"id": "18482430", "url": "https://en.wikipedia.org/wiki?curid=18482430", "title": "Bourdieu v. Pacific Western Oil Co.", "text": "Bourdieu v. Pacific Western Oil Co.\n\nBourdieu v. Pacific Western Oil Co., 299 U.S. 65 (1936), was a decision by the United States Supreme Court, which held that an inquiry into indispensability would be unnecessary where the complaint did not state a cause of action.\n\nPacific Western Oil Corporation was established by Edward L. Doherty in 1928 before later coming under the control of J. Paul Getty and owned oil and gas drilling rights for large sections of Fresno County, California. An agricultural landowner had \"mining\" rights for the same area and sued. The oil companies asserted that, since their leases were issued by the United States Secretary of State, that they could not be sued without including the U.S. government but the court disagreed.\n\n"}
{"id": "22696716", "url": "https://en.wikipedia.org/wiki?curid=22696716", "title": "Bring Us Together", "text": "Bring Us Together\n\n\"Bring Us Together\" was a political slogan popularized after the election of Republican candidate Richard Nixon as United States President in 1968. The text was derived from a sign which 13-year-old Vicki Lynne Cole stated that she carried at Nixon's rally in her home town of Deshler, Ohio during the campaign.\n\nRichard Moore, a friend of Nixon, told the candidate's speechwriters he had seen a child carrying a sign reading \"Bring Us Together\" at the Deshler rally. The speechwriters, including William Safire, began inserting the phrase into the candidate's speeches. Nixon mentioned the Deshler rally and the sign in his victory speech on November 6, 1968, adopting the phrase as representing his administration's initial goal—to reunify the bitterly divided country. Cole came forward as the person who carried the sign, and was the subject of intense media attention.\n\nNixon invited Cole and her family to the inauguration, and she appeared on a float in the inaugural parade. The phrase \"Bring Us Together\" was used ironically by Democrats when Nixon proposed policies they disagreed with or refused to support. Cole declined to comment on Nixon's 1974 resignation, but subsequently expressed her sympathy for him. In newspaper columns written in his final years before his 2009 death, Safire expressed doubts that Cole's sign ever existed.\n\nThe 1968 presidential campaign was one of the most bitterly fought in the nation's history. Set among national divisions over the Vietnam War, social policy, and against the backdrop of riot and assassination, none of the campaigns made healing divisions a major theme—an early slogan by Democratic candidate Hubert Humphrey, \"United With Humphrey\" had been scrapped. The incumbent President, Democrat Lyndon Baines Johnson (often called L.B.J.) could give Humphrey little support because of his own unpopularity.\n\nBy 1968, candidates were appealing to the electorate through television, rather than through whistle-stop train tours. Nixon had included them in his past national campaigns—he had broken off one such tour in 1952 to make the Checkers speech, and in 1960, had stopped at Deshler. The rural Ohio village, about southwest of Toledo, was popular among whistle-stopping presidential candidates as two main lines of the Baltimore & Ohio Railroad crossed there—other visitors in search of votes had included Al Smith, Harry Truman, and Barry Goldwater. Deshler voters would respond in 1968 by giving Nixon an overwhelming majority of their votes.\n\nCole was an eighth grader in Deshler; her father was the local Methodist minister while her mother taught third grade. On October 22, 1968, the day of Nixon's stop in Deshler, Cole attended class as usual. During the morning session, one of her teachers announced that any girls interested in being \"Nixonettes\" (girls asked to cheer and provide atmosphere at the rally) should report to the fire station after school. Cole did so, along with her friend, Rita Bowman, and the girls were provided with paper red, white, and blue dresses (to be worn over other clothing) and signs. Cole's said, \"L.B.J. Convinced Us—Vote Republican\".\n\nThat afternoon, Cole attended the rally, wearing her dress and holding her sign. The Nixon train pulled in, and the police lowered the rope which kept the crowd clear of the tracks. In interviews, Cole related that as the crowd surged forward, she dropped her sign amidst the pushing and shoving. Cole stated, \"I wanted a sign to wave. I had lost my own placard and as the crowd moved forward as the train approached I saw this sign lying in the street and I just picked it up and held it high, hoping Mr. Nixon would see it.\"\n\nNixon gave a speech from the rear platform of the train. He praised the size of the crowd, stating, \"There are four times as many people here than live in the town and more than the number that were here in 1960.\" The candidate asserted that though his opponent, Vice President Humphrey, claimed that Americans had never had it so good, he should tell that to the farmer. Nixon pledged that he would give special attention to agricultural issues and would make the Secretary of Agriculture a farmer's advocate to the White House. He promised to restore order: \"The most important civil right is the right to be free from [local] violence.\" He noted the many youths in the crowd, stating, \"Young Americans know their future is at stake. They don't want four more years of the same.\" He recalled that his father had hailed from Ohio: \"his roots are here and mine are too!\" As Nixon spoke, Cole observed him, and thought he was a good family man, looking warm and friendly and appearing much as she expected him to. She later stated that she did not even look at the sign until she was teased about it by a classmate, who suggested the sign, \"Bring Us Together Again\" was about boys, not politics. She kept the dress, but told the media she threw away the sign.\n\nNixon speechwriter William Safire had been told of the sign by a friend of Nixon, Richard Moore, who left the train at campaign stops to mingle with the crowd and seek items of local color for the speechwriters to use. Safire stated in his book on the early days of the Nixon administration (originally published in 1975) that at Deshler, \"Moore boarded the train with that mystic look that a writer gets when he has something delicious to work with, some piece of color that could be more than a gimmick.\" According to Safire in a 2007 column, Moore stuck his head into the compartment occupied by Nixon's speechwriters and stated, \"There's a little kid out there with a hand-lettered sign that I think says 'Bring Us Together'.\" Safire wrote in that column that he inserted the phrase into Nixon's remarks for the speech to be given at the next stop.\n\nNixon used the phrase in concluding a rally at New York's Madison Square Garden on October 31, 1968. Recalling the visit to Deshler, the Republican candidate stated, \"There were many signs like those I see here. But one sign held by a teenager said, 'Bring Us Together Again'. My friends, America needs to be brought together.\" However, Nixon's use of the phrase received little coverage until after the election. Deshler school officials heard of the speech, and asked students about the sign, but no one came forward.\n\nSafire included the incident in a draft victory statement, which Nixon looked at before addressing the nation as President-elect. In his victory speech on November 6, Nixon recalled the sign:\nI saw many signs in this campaign, some of them were not friendly; some were very friendly. But the one that touched me the most was one that I saw in Deshler, Ohio, at the end of a long day of whistle-stopping. A little town. I suppose five times the population was there in the dusk. It was almost impossible to see, but a teenager held up a sign, \"Bring Us Together.\" And that will be the great objective of this administration at the outset, to bring the American people together.\n\nReconciliation among the American people was also a theme of Humphrey's concession statement. \"I have done my best. I have lost, Mr. Nixon has won. The democratic process has worked its will, so now let's get on with the urgent task of uniting our country.\"\n\nSchool officials again asked students about the sign after Nixon mentioned his visit to Deshler in the victory speech, and this time Cole came forward. She stated that she had not done so before as she had not written the sign. Reporters interviewed the girl in the principal's office. Cole stated she felt Nixon was the one who could bring the country together again. Being interviewed by reporters from Washington, New York, and Chicago, she indicated, was more fun than sitting in history class. The Toledo \"Blade\" investigated the matter, but could not ascertain who made the sign, or what happened to it after Cole discarded it. John Baer, village chief of police, stated, \"I think this has to be the most important thing that has ever happened around here.\" Paul Scharf, editor of the Deshler \"Flag\", stated he did not believe the mystery of the sign's origin or fate would ever be cleared up. Safire stated he was told by Moore that the sign stood out as obviously handmade and not produced by the local Nixon campaign.\n\nAs early as November 7, the \"Northwest Signal\", local paper for nearby Napoleon, Ohio, reported that Deshler merchants were considering taking up a collection to send Cole to Washington; the following day the paper editorialized that she, along with whoever actually made the sign, be sent to Washington to see the inauguration. On November 19, 1968, campaign special assistant and longtime Nixon advisor Murray Chotiner proposed inviting the Cole family to the inauguration and having Vicki Cole ride the theme float. The President-elect subsequently invited Reverend and Mrs. Cole and their family to attend the inauguration; the family was brought to Washington by the Inaugural Committee. Vicki Cole carried a recreation of her sign on the theme float in the inaugural parade.\n\nCarla Garrity, a fourteen-year-old girl from Burbank, California, objected to Cole's invitation to the inauguration on the ground that Cole had done nothing to deserve it. In a letter to her congressman, Ed Reinecke, Garrity stated she had worked very hard for Nixon and other Republican candidates, \"Therefore, I am very much against that 13-year old girl in Ohio who held up the sign 'Bring us Together' being invited to the inaugural. She didn't even \"read\" or \"write\" it!\" Reinecke forwarded the letter to Nixon aide John Ehrlichman with the comment, \"I suspect that Carla's reaction may be shared by other young people who worked in the Nixon campaign\". Nixon assistant Charles E. Stuart replied to Reinecke, stating, \"Vicki Lynne has been invited to the inauguration not because she carried the sign, or even because she made the sign, but rather because the sign which she did carry proved to be an inspiration to Mr. Nixon\" and expressed his confidence the invitation would be well received by other young Nixon partisans.\n\nThe Inaugural Committee wanted to adopt \"Bring Us Together\" as the inaugural theme, appalling Safire, who said, \"That wasn't the theme of the campaign.\" Safire and other aides felt the administration should seek to advance its agenda, rather than seeking consensus on policy, and White House Chief of Staff-designate H. R. Haldeman was able to change the theme to \"Forward Together.\" Nevertheless, the phrase \"Bring Us Together\" was thrown in the face of the Nixon administration by Democrats each time something divisive was proposed, and was used as the title of a tell-all expose by Leon Panetta after he was fired from the Nixon administration for dissenting from the White House's \"Southern strategy\" on civil rights policy. According to Safire, the use of the phrase against Nixon shows a slogan which evokes emotion can cut both ways.\n\nNixon's advisors denied he had abandoned a desire to bring the American people together. However, they were divided between those who sought national unity, and those, such as campaign manager and Attorney General John N. Mitchell, who felt Nixon should concentrate on keeping the voters who had cast their ballots for him, and should seek to win over the voters who had favored third-party candidate Alabama Governor George Wallace, as the key to reelection in 1972. According to Safire, after taking office, Nixon and his advisors decided he need not bring the country together, but need only work to secure his reelection by appealing to voters who were not hostile to Nixon and his policies—they became known as the Silent Majority. Historian Stanley Kutler suggested in his book on the Nixon administration that Nixon's policies widened divisions in America, but that the nation finally came together late in his presidency—to reject Nixon and demand his removal.\n\nIn late 1970, Vicki Cole indicated in an interview Nixon was doing the best he could. During the 1972 campaign, Cole served as Ohio chair of a future voters organization for the Nixon campaign. She then left politics, devoting her spare time to training and showing horses. In 1974, Cole declined to comment on the resignation of President Nixon in the wake of the Watergate scandal, but stated in 1977 that she felt sympathy for him, though she believed his resignation was necessary.\n\nSafire, in his political dictionary published in 2008, recollected that when he asked Moore, some years after the inauguration, whether he had really seen the girl holding the sign, or whether he had imagined it, \"his eyes took on a faraway look\". In columns written in the final years before his 2009 death, Safire commented that the sign was \"almost too good to be true\", and said of Moore, \"[h]e may have made that up\".\nExplanatory notes\n\nCitations\n"}
{"id": "4945403", "url": "https://en.wikipedia.org/wiki?curid=4945403", "title": "Community economic development", "text": "Community economic development\n\nCommunity economic development (CED) is a field of study that actively elicits community involvement when working with government, and private sectors to build strong communities, industries, and markets.\n\nCommunity economic development encourages using local resources in a way that enhances economic opportunities while improving social conditions in a sustainable way. Often CED initiatives are implemented to overcome crises, and increase opportunities for communities who are disadvantaged. An aspect of “localizing economics,” CED is a community-centered process that blends social and economic development to foster the economic, social, ecological and cultural well-being of communities. For example, neighborhood business organizations target growth in specific commercial areas by lobbying government authorities for special tax rates and real estate developments.\n\nCommunity economic development is an alternative to conventional economic development. Its central tenet is that: “... problems facing communities—unemployment, poverty, job loss, environmental degradation and loss of community control—need to be addressed in a holistic and participatory way.” \n\nEconomic development has existed even at a basic level since the earliest recorded communities. However, in the US and several other countries, the concept of Community economic development emerged \"in response to tenacious poverty and the need for affordable housing, good jobs, affordable health care and quality of life matters needed for human existence.\"\n\nIn the late 19th century reformers discovered less than desirable areas of the country where communities were overcrowded, unhealthy, poor and centered near factories, docks and various other places of employment. In the early twentieth century during the Progressive Era reformers began making connections between the condition of communities and \"social ills\" such as crime and poverty and ways to improve upon them. The Progressive agenda of political, social, and physical reform swept the nation and led to comprehensive antipoverty strategies, embodied by New Deal programs and other grants in the 1930s. Policies during this time were top-down and citizens being affected had very little input to the changes being made. Once communities began to be revitalized, segregation policy followed to determine who was allowed to live where. Housing policy and real estate practices stifled upward mobility for non-whites and their communities developed with unique characteristics and problems as a result. These actions shaped communities until the 1960s, when President LBJ signed into law many anti-discriminatory laws such as the Civil Rights Act of 1964 and also declared a war on poverty which brought renewal and upward mobility for many people. More loan programs, grants and fair housing policies were implemented throughout the 60's and 70's but still failed to be non-discriminatory on the basis of race in some cases thus shaping communities in a particular fashion. Social investment gained momentum once again in the 80's and 90's bringing change to communities across America. Municipal governments become more representative of the communities they serve and the public is more involved and can interact with bureaucracies and elected officials with greater ease. Many initiatives existed at this time to renew inner cities and rural areas while also tackling social issues such as eradicating drugs and improving education. The modern day CED movement is focused on renewing urban and rural communities. Social justice is a key component to policy and conversation about changes to be made. Citizens are engaged with bureaucracies and their elected officials through a variety of mediums such as social media. Input from the people has gained more value due to increased demands for transparency.\n\nIn NIgeria CED is approached with a central focus on sustainability referred to as Sustainable Community Development. This concept combines economic, social and environmental practices and policies that promote sustainability for future generations. Much of this began in the 1980s, 2 decades after gaining independence, when the World Bank declared Nigeria eligible to receive funds from the International Development Association (IDA).\n\nIn Asia for the last 60 years the Asian Foundation has supported Asian initiatives to foster inclusive economic growth and broaden economic opportunities.The Foundation designs and implements economic programs in three core areas business environments for private sector growth, Entrepreneurship Development and Regional Economic Cooperation.\n\nThe most significant aspect of community economic development, aside from the fact that it focuses on economic development in specific localities, is that focuses on the process of community building. This “community” aspect of CED assumes that the community will play a dynamic role in economic development processes and that community development will contribute to sustained economic development and vice versa. In this understanding, the community is considered both as an input and output in this CED equation.\n\nLooking at CED from an economic viewpoint, the initial purpose of such an approach is the creation of local jobs and the stimulation of business activity. Integrally linked to these purposes are strategies to increase access to capital, stimulate asset building, improve the general business climate, and link citywide economic development efforts to specific community development efforts.\n\nIncreasing access to capital is an extremely important strategy for community economic development. Historically, residents in poor neighborhoods have experienced great difficulty finding access to capital because they are traditionally viewed as credit risks. In places where banks do offer services, these residents face other structural barriers such as minimum deposit requirements, high service fees, and complex paperwork. To solve these problems, a community economic development approach would develop alternate neighborhood community development financial institutions such as community development credit unions, community development banks, and community development venture capital funds.\n\nImproving the general business climate is also integral to community economic development. Strategies to do so would include improving the infrastructure and physical appearance of commercial areas, the quality of quantity of residential housing, and the transportation systems in a neighborhood. While these may not directly economic activities, they serve to strengthen the economic well being of an area because it encourages businesses to locate there.\n\nCommunity economic development exists in all developed countries but varies in the way it functions with the different systems of governments around the world. Research makes it apparent that there are common goals and objectives such as economic activities and programs that develop low-income communities. Community Development Corporations, reformers and other agencies have other common initiatives including services to fight homelessness, lack of jobs, drug abuse, violence and crime as well as quality medical and childcare and home ownership opportunities while also bringing economic prosperity. Another increasingly common objective is to preserve the character of communities and strong support for local business.\n\nCountries across the globe participate in reinvestment and development through a bank such as the Community Reinvestment Act, World Bank and the IDA amongst many others. Another commonality for nations international is need to incorporate sustainability and the natural environment into the growth of societies.\n\nEconomic policies of Central governments often do not appear to help economies on a local level. Large free market economies tend to take more out of local communities than they put back into them leaving economic dead zones within these communities. Community economic development policy argues that it is in the social interest of a local economy to be at least partially owned by the community. The locality is responsible for initially coming up with the visions for their economic future; community economic development assists with expanding access to capital and stimulating asset accumulation, increasing local access to consumer goods and services, expanding the local entrepreneurial base, expanding local employment opportunities; giving neighborhoods more control over ownership of local resources and connecting residents and businesses to the regional economy.\n\nSeveral Communities across the United States have successfully crafted policy to create groups and corporations to assist in multiple facets of the communities economy and welfare. The following organizations are examples of Community Economic Development Initiatives.\n\nThe Western Australian Government Department of Commerce and Trade had an active Community Economic Development Branch working within Regional Development during the 1990s. They ran programs in Small Town Economic Planning (STEP) program in which local communities were asked to bring together a cross section of influential groups representative of the community for a one- or two-day community planning event, after which they were given a grant of up to $15,000 for the implementation of initiatives identified, for a considerable number of the state's 158 Local Government Councils. They also ran a Community Auditing initiative and with the Office of the Minister of Agriculture, ran a Community Development Program, training local people in the skills of Community Economic Development. The reorganisation of the Department in 2002 saw the name changed to Community Capacity Building and the Department itself was reorganised as the Department of Regional Development and Local Government until 2007 after which the Community Capacity Building Branch was disbanded.\n\nIn Brazil, the Banco Palmas has established Community Economic Development initiatives through the use and development of a community currency. The community has prospered and has been widely adopted so that by 2011 there were 43 community banks within the country using the Banco Palmas model. The Brazilian government has since encouraged the movement and in 2015 there were more than 100 initiatives in various parts of the country.\n\nIn the US, Community Economic Development projects are often funded by commercial banks within the structure of the Community Reinvestment Act. This Act of Congress took effect in November, 1978. It is administered by banks and other financial institutions and has been instrumental in helping the owners of smaller businesses navigate the steps of obtaining loans for development projects. A bank will operate a separate division within their loan department that focuses its expertise on small business services, as well as training and education.\nBecause projects brought to CRA bank departments are often from areas of lower economic standing and/or unproven consumer markets, they are a larger risk to lenders. This heavier risk brings more stringent underwriting guidelines, in addition to often rigid government requirements. Many financial institutions state that these rules are cumbersome and difficult to comply with.\n\nThere are several CED corporations and nonprofits that employ Community Economic Development Officers to implement development plans.\n\nThose involved in implementing a Community Economic Development Plan – not only the development officers, but also public administrators and small business owners – will serve different functions, as plans vary from community to community. The community economic development officer will create studies to determine what a certain community's goals are and send them to the appropriate municipal offices or economic development committees. A community economic development officer will assist in implementing a development plan by researching local zoning ordinances and laws, helping community partners acquire financing for economic development, acting as a liaison with various local, state, and federal agencies, making recommendations to the appropriate authorities on community economic development, and serving as an advocate within a community.\n\nMost employers require a bachelor's degree in Economics or Community Development as a minimum. For better opportunities, pursuing a Master of Public Planning, Urban Planning, Economic Development, or Community Economic Development is recommended. The annual median salary for a Community Economic Development Officer in the United States is $64,028.\n\n\n"}
{"id": "8935636", "url": "https://en.wikipedia.org/wiki?curid=8935636", "title": "Comprehensive Reviews in Food Science and Food Safety", "text": "Comprehensive Reviews in Food Science and Food Safety\n\nComprehensive Reviews in Food Science and Food Safety is an online peer-reviewed scientific journal published by the Institute of Food Technologists (Chicago, Illinois) that was established in 2002. Its main focus is food science and food safety. This includes nutrition, genetics, food microbiology, food chemistry, history, and food engineering.\n\nIts first editor was David R. Lineback (University of Maryland, College Park), who held the position from 2002 to 2004. From 2004 to 2006, R. Paul Singh (University of California, Davis) served as editor. The journal has been edited by Manfred Kroger (Pennsylvania State University) since 2006.\n\n"}
{"id": "13100713", "url": "https://en.wikipedia.org/wiki?curid=13100713", "title": "Cormack Foundation", "text": "Cormack Foundation\n\nCormack Foundation Pty. Ltd. is an Australian investment company established to raise funds for the Liberal Party of Australia. The company was set up in 1988 and used proceeds from the sale of former Melbourne radio station 3XY.\n\nAustralian Electoral Commission records show that the Foundation is an \"associated entity\" of the Liberal Party. In 2014-2015, the Cormack Foundation received funds of over $12,800 (the disclosure threshold) from (among others) BHP Billiton, Rio Tinto, Telstra, each of the Big Four banks. In 2014-15, it had receipts of A$5,403,207, which were marked as \"other receipts\", indicating that the receipts are not subject to the tax deductibility limits for political donations.\n\nSince 2002-2003, the Cormack Foundation has been the largest single donor to the Liberal Party, donating A$1.8 million in 2002-03. In 2013-2014, it donated $4.26 million. The Foundation donated $4.46 million in 2014-15.\n\nThe Foundation has distributed more than $25 million to the Liberal Party over 22 years to 2007-08 and also in 2008 had investments totaling $58 million spread across 16 blue-chip investments. In 2008 the directors were Charles Goode, Hugh Morgan and John Calvert-Jones.\n\n\n"}
{"id": "27352290", "url": "https://en.wikipedia.org/wiki?curid=27352290", "title": "Corruption in Russia", "text": "Corruption in Russia\n\nCorruption in Russia is perceived to be a significant problem, impacting all aspects of administration, law enforcement, healthcare and education. The phenomenon of corruption is strongly established in the historical model of public governance in Russia and attributed to general weakness of rule of law in Russia. Transparency International's 2017 Corruption Perception Index ranks the country in 135th place out of 176 countries.\n\nA notable worsening of this ranking for Russia—from 90th place to 126th—occurred at the beginning of Vladimir Putin's second term as president: a drop of 36 places in only one year. An equally pessimistic picture emerges from the estimates of the average size of bribes which has substantially increased over the last five years. For example, according to the Interior Ministry's Department for Combating Economic Crimes, the average bribe amounted to 9,000 Rubles in 2008; 23,000 Rubles in 2009; 61,000 rubles in 2010; and 236,000 rubles in 2011. In other words, the average bribe in 2011 was 26 times greater than the average bribe in 2008, many times the inflation rate for the same period.\n\nAccording to Sergei Ivanov, the Kremlin chief of staff, the most corrupt spheres in Russia (in terms of household corruption) are healthcare, education, housing and communal services. In comparison, independent experts from \"RBC magazine\" name law-enforcement agencies (including the State Traffic Safety Inspectorate) as the most corrupt sphere in Russia, which is followed by healthcare, education, housing and communal services, and social security services. At the government level, however, the five top areas for corruption are as follows: Government contracts and purchases; Issuance of permits and certificates; Law-enforcement agencies; Land distribution and land relations; Construction.\n\nThere are many different estimates of the actual cost of corruption. According to official government statistics from Rosstat, the \"shadow economy\" occupied only 15% of Russia's GDP in 2011, and this included unreported salaries (to avoid taxes and social payments) and other types of tax evasion. According to Rosstat's estimates, corruption in 2011 amounted to only 3.5 to 7% of GDP. In comparison, some independent experts maintain that corruption consumes as much of 25% of Russia's GDP. A World Bank report puts this figure at 48%. There is also an interesting shift in the main focus of bribery: whereas previously officials took bribes to shut their eyes to legal infractions, they now take them simply to perform their duties. Many experts admit that in recent years corruption in Russia has become a business. In the 1990s, businessmen had to pay different criminal groups to provide a \"krysha\" (literally, a \"roof\", i.e., protection). Nowadays, this \"protective\" function is performed by officials. Corrupt hierarchies characterize different sectors of the economy, including education.\n\nIn the end, the Russian population pays for this corruption. For example, some experts believe that the rapid increases in tariffs for housing, water, gas and electricity, which significantly outpace the rate of inflation, are a direct result of high volumes of corruption at the highest levels. In the recent years the reaction to corruption has changed: starting from Putin's second term, very few corruption cases have been the subject of outrage. Putin's system is remarkable for its ubiquitous and open merging of the civil service and business, as well as its use of relatives, friends, and acquaintances to benefit from budgetary expenditures and take over state property. Corporate, property, and land raiding is commonplace.\n\nAn anticorruption campaign in modern Russia began on April 4, 1992, when President Boris Yeltsin issued a decree entitled \"The fight against corruption in the public service\". This document prohibited officials from engaging in business activities. Moreover, state employees were required to provide information about their income, personal property and real estate holdings, bank deposits and securities, as well as financial liabilities. The implementation of the decree, which formed the basis of the laws on combating corruption and on civil service, was vested in the presidential control directorate. Russia passed the first package of anti-corruption laws in 2008 in response to its ratification of the UN's Convention against Corruption and the Council of Europe's \"Criminal Law Convention on Corruption\". The decree \"On Anti-Corruption Measures\" was signed by former President and current Prime Minister Medvedev in May of that year. Since then, numerous changes have been implemented to the Russia’s anti-corruption legislation with the purpose of combating bribery and improving its business climate. The Russian anti-corruption campaign is an ongoing effort by the Russian government to curb corruption, which has been recognized as one of Russia's most serious problems. Central documents in the campaign include the National Anti-Corruption Plan, introduced by Medvedev in 2009, and the National Anti-Corruption Strategy, introduced in 2010. The central organ in the campaign is the Anti-Corruption Council, established in 2008. Medvedev has made fighting corruption one of the top agendas of his presidency. In the first meeting of the Council on 30 September 2008, Medvedev said: \"I will repeat one simple, but very painful thing. Corruption in our country has become rampant. It has become commonplace and characterises the life of the Russian society.\"\n\nIn 2012, the government adopted a new law requiring public servants and employees of state organisations to disclose their source of funds and both their and their families’ acquisitions of property, including real estate, securities, stock and vehicles. The legislation has also, for the first time, defined conflict of interest in connection to public officials and extended anti-corruption legislation to the military. The last modification to the Federal Anti-Corruption Law No. 273 was made in December 2012 and it was implemented on January 1, 2013. By upgrading the Anti-Corruption Law with Article 13.3, Russia has made a significant step towards strengthening the framework of its anti-corruption legislation, aligning it with the best practices recognized on the international level, such as the UK Bribery Act and the U.S. Foreign Corrupt Practices Act. This articles 13.3 of the Anti-corruption Law requires organizations to develop and implement anti-corruption measures such as (i) appointing a specific department or an official to be responsible for preventing corruption and related offences; (ii) cooperating with enforcement authorities; (iii) developing and implementing standards and procedures for ethical business practices; (iv) establishing an ethical code of conduct for personnel; (v) preventing and resolving conflicts of interest; and (vi) preventing the filing of false or off-the-record reports and the use of forged documents. Russia also joined the OECD Anti-Bribery Convention in 2012 and has the G20 Presidency in 2013, where fighting corruption is one of three main issues on the agenda. Companies should therefore actively ensure that they stay compliant with the new amendment to the Anti-Corruption Law.\n\nCorruption has an obvious connection with money laundering as the stolen assets of a corrupt public official are useless unless they are placed, layered and integrated into the global financial network in a manner that does not raise suspicion. The proceeds of corruption may be laundered in jurisdictions which have not enacted strict anti-money laundering measures and in countries which uphold very strict bank-secretary laws or regulations. This is the reason why the \"de-offshorization\" policy endorsed by President Putin in 2012 and 2013 (after the Cyprus Affaire) is often considered to be a new anti-corruption measure. The government's recent initiatives for gradually strengthening control over financial operations of organisations and citizens have been the subject of The Russian Federal Financial Monitoring Service (\"Rosfinmonitoring\"). A law has been drafted, which introduced amendments to a number of legal acts and aimed at increasing the transparency of currency transactions and at strengthening anti-money laundering measures in Russia. This respective law, with corresponding amendments, was passed on 30 June 2013. The law introduces changes to a variety of legislative acts and ensures the overall enhancement of control over businesses and citizens with respect to financial operations.\n\nThe most important amendments for businesses are those that modify the regulation of banking activity. The amendments considerably affect credit organizations which would most likely be required to amend their internal anti money laundering policies and procedures for identification of customers. On one hand, they allow the bankers to demand disclosure of the transaction purpose from the client. On the other hand, this might raise substantial risks in terms of optimizing business, including potential delay in completing payments.\n\nRussian President Vladimir Putin approved a new national anti-corruption plan for the period from 2014 to 2015. The president ordered executive and legislative authorities by July 1, 2014 to make relevant amendments to their anti-corruption plans and to ensure control over their execution. A relevant order was included in the National Plan to Counter Corruption for 2014–2015.\n\nThe governor of the Komi republic was arrested for stealing money from state funds.\n\nAnti-Corruption Foundation is a nonprofit organization based in Moscow established in 2011 by activist and politician Alexey Navalny. It's main goal is to investigate and to expose corruption cases among high-ranking Russian government officials, which they have been successfully doing for the last few years.\n\nTransparency International Russia's report from 2012 shows a variety of activities that give citizens a chance to monitor corruption. It collaborated with the Youth Human Rights movement on a large-scale campaign in 20 cities to check police officers' identification tags. This is a proactive exercise to stop petty corruption. If an officer can be identified, he or she is less likely to ask for a bribe. Transparency International Russia also monitors the income statements of Russian public officials with the help of students and publishes the results and monitored the use of 600 million rubles (US$19 million) of public funds to socially oriented NGOs, and found several cases of conflict of interests. It provided analysis and recommendations on making this process more transparent and accountable. the NGO works cooperatively with all individuals and groups, with for-profit and not-for-profit corporations and organisations, and with bodies committed to the fight against corruption. It undertakes professional analysis and papers on corruption-related issues trying to explain the reasons of the spread of corruption, its political and social implications and trying to analyse the possible scenarios for the future.\n\nOn 9 December 2014 Novosti agency reported that the head of the National Anti-Corruption Committee Kirill Kabanov admitted on air that a third of Russian officials were corrupt. As of 2015, Russian officials are periodically accused of spending on luxury cars, mansions or clothes worth significantly more than their declared income.\n\nA 2018 study of state corruption in Russia during the 1750s–1830s found that \"as far as we could tell on the basis of our sample of records, the volume of resources extracted from the population through ‘routine’ corruption appears to have been surprisingly low.\" The authors write, \"every little interaction with state officials involved paying a fee to the clerks, and such fees, although technically illegal, were so common and commonly accepted as to be entered in the account books alongside other operational expenses. On the other hand, these ‘routine’ payments were really quite small, especially if apportioned on a per capita basis among the entire commune ... Such fees appear to have been largely customary in nature, a part of the traditional economy of gift-giving, demonstrating respect, and maintaining informal relationships (‘good disposition’). Yet, even such a low level of per capita extraction would have allowed key district officials to amass significant amounts, at a very minimum tripling their salaries.\"\n\nThe Russian Prosecutor General Office reported that of the persons convicted for corruption in 2017, the number of law enforcement functionaries and parliamentaries (nearly 2,200 persons) constituted over 11%.\n\n\n"}
{"id": "29854799", "url": "https://en.wikipedia.org/wiki?curid=29854799", "title": "David Rowland (property developer)", "text": "David Rowland (property developer)\n\nDavid Rowland (born 1945) is a British property developer.\n\nRowland took over other groups, issuing shares in his own company to pay for acquisitions. Eventually he sold his stake in Fordham for £2.4m in 1970, and moved to France.\n\nIn 1988, Rowland helped fund a lawyer, David Duff, in a takeover of Edinburgh Hibernian, parent company of Scottish Premier Division football club Hibernian. Eventually the company went into receivership.\n\nIn 1991, Rowland sold his controlling interest to Nycal Corporation. Over the following years, Gulf resorted to the American courts to recover company monies they alleged were spent by David Rowland, firstly via the courts and then via their insurance company. One case was settled (though no financial settlement was deemed necessary), while Gulf lost another.\n\nIn 2009, Kaupthing Bank, affected by the global liquidity squeeze was divided into two new entities, a ‘good, healthy’ bank, later Banque Havilland, and a ‘bad’ bank. David Rowland and his son Jonathan, via their investment company Blackfish Capital, acquired and recapitalized the former and now manage the assets, on behalf of the interbank creditors, of the latter.\n\nIn the year before the 2010 United Kingdom general election, Rowland donated £2.8m to the Conservative Party, making him the party’s major donor. In 2010, he was announced as being the next Treasurer of the Conservative Party. After this announcement, the \"Daily Mail\" published a series of articles that were critical of him. After public criticism of his former status as a tax exile, Rowland resigned before taking the position. Rowland had lived in Guernsey, but returned to full United Kingdom residency in order to make donations to the Conservatives. Electoral law in the United Kingdom prohibits foreign donations to political parties. In August 2010, Rowland made another donation of £1 million to the Conservative Party. In May 2017, he gave £200,000 to the Conservative Party.\n\n"}
{"id": "34306714", "url": "https://en.wikipedia.org/wiki?curid=34306714", "title": "Department of Economic Development (South Africa)", "text": "Department of Economic Development (South Africa)\n\nThe Department of Economic Development is the department of the South African government responsible for economic policy, economic planning and economic development. It was established in 2009 after the election of President Jacob Zuma.\n\n"}
{"id": "1796740", "url": "https://en.wikipedia.org/wiki?curid=1796740", "title": "Doctor shopping", "text": "Doctor shopping\n\nDoctor shopping is the practice of visiting multiple physicians to obtain multiple prescriptions for otherwise illegal drugs, or the medical opinion that one wants to hear. It is a common practice of drug addicts, suppliers of drug addicts, hypochondriacs or patients of factitious disorder and factitious disorder imposed on another. A doctor who, for a price, will write prescriptions without the formality of a medical exam or diagnosis is known as a \"writer\" or \"writing doctor\".\n\nA doctor shopper will visit multiple health care providers as a \"new patient\" or \"visiting from out of town,\" and will exaggerate or feign medical problems to obtain prescriptive medications or a wanted medical opinion, diagnosis or treatment with no specific material gain.\n\nFrequently involved in prescription fraud are narcotics, stimulants, barbiturates, benzodiazepines, tranquilizers and other psychoactive substances manufactured for use in legitimate medical treatment. Law enforcement officers spend a significant amount of time investigating cases involving prescription fraud, many of which also involve insurance, Medicare, or Medicaid fraud.\n\nPrescription drug diversion occurs by faking, forging, or altering a prescription; obtaining bogus prescriptions from criminal medical practitioners; or buying drugs diverted from health care facilities by personnel. Pharmacy thefts are increasing throughout the United States to feed the growing demand for prescription drugs. The rising cost of prescription drugs has also enticed senior citizens to join in the diversion and to sell their prescriptions.\n\nDoctor shopping is a kind of malingering with the specific goal of procuring prescription drugs. Malingering is underdiagnosed, often because of the physician's fear of making false accusations. Covert surveillance has indicated that as many as 20% of pain clinic patients misrepresent the extent of their disability. The judgment of the morality of malingering is largely a matter of the observer and circumstances. Most people would regard the defraudment of an insurance company, by a false injury, as an antisocial act. In contrast, the malingering of a prisoner-of-war, who is attempting to manipulate his or her captors, would be seen by most compatriots as a skillful coping mechanism.\n\nDoctor shopping is associated with the ubiquitous medicalization of drug use, as an alternative to criminalization and legalization.\n\nSome patients of hypochondria, factitious disorder and factitious disorder imposed on another will visit multiple health care providers to find a medical opinion, diagnosis or treatment that they feel the need to get, not specifically in search of prescription drugs, for no material benefit and even incurring in significant costs, debts or losses. This kind of doctor shopping lacks intention to commit malingering for material gain and is the result of such mental conditions.\n\n"}
{"id": "41143560", "url": "https://en.wikipedia.org/wiki?curid=41143560", "title": "Dual control (politics)", "text": "Dual control (politics)\n\nDual control is the situation in which a national government agrees to share control of its country with representatives of foreign governments, called \"controllers\", because it is indebted to them.\n\n\n"}
{"id": "10033523", "url": "https://en.wikipedia.org/wiki?curid=10033523", "title": "Durbar Mahila Samanwaya Committee", "text": "Durbar Mahila Samanwaya Committee\n\nThe Durbar Mahila Samanwaya Committee ( \"Durbar Mohila Shômonbôe Shomiti\" \"Unstoppable Women's Synthesis Committee\") or Durbar, is a collective of 65,000 sex workers in West Bengal. Established on 15 February 1992, in Sonagachi, the largest red-light district in Kolkata, West Bengal, India with estimated 11,000 sex workers, Durbar has been working on women's rights and sex workers' rights advocacy, anti-human trafficking and HIV/AIDS prevention. The Durbar states that its aims are the challenging and altering of the barriers that form the everyday reality of sex workers' lives as they relate to their poverty or their ostracism. Durbar runs 51 free clinics for sex workers across West Bengal, with support from organisations such as the Ford Foundation and the National AIDS Control Organisation (NACO), who also help Durbar in its initiatives like networking, rights protection and creating alternative livelihood for sex workers.\n\nThe group is overtly political in its aims of fighting for the recognition of prostitution as legal work and, of sex workers as workers and, for a secure social existence of sex workers and their children. They work for the legalisation of prostitution and seek to reform laws that restrict human rights of sex \n\nOn 15 February 1992, a public health scientist Dr. Smarajit Jana of All India Institute of Hygiene and Public Health, Kolkata, visited the red-light area of Sonagachi for a HIV intervention research study. A peer education team was formed from amongst the sex workers and provided training. Shortly after, studies revealed larger issues amongst sex workers, such as sex workers rights, education of their children, access to financial services and handling of harassment by police and local thugs, along with promoting the use of condoms. Thus in 1995 he formed 'Durbar Mahila Samanwaya Committee' (DMSC) with 12 sex workers as stakeholders, by 2012 DMSC had a membership of 65,000 from 48 branches across the state of West Bengal, and continues to be managed by sex workers, their children and government officials as its board members, and has not just female sex workers as its members but also male and transgender sex workers.\n\nSince its inception, it has been working as an advocacy group for sex workers and over the years, it has worked towards sensitizing general public about rights of sex workers, often initiating debate and discussion in public media and press, besides advocating abolition of 'The Immoral Traffic (Prevention) Act, 1956' (PITA), and legalisation of sex work. Many sex workers now have voters identity cards, health insurance and even bank accounts. In 1995, its consumer cooperative society and micro-credit programme, 'Usha' (literally meaning light), ensured that the Government of West Bengal altered the state's cooperative law to register it as a sex workers cooperative, instead of a 'housewives cooperative' under the prevalent state laws. By 2006-2007, small saving of its 5,000 members lead to an annual turnover to , with loan of distributed amongst its members, which also helped break the monopoly of local moneylenders, who would charge interest rates of up to 300%. The DMSC hosted India's first national convention of sex workers on 14 November 1997 in Kolkata, titled 'Sex Work is Real Work: We Demand Workers Rights'.\n\nDMSC runs 17 non-formal schools for children of sex workers, and two hostels, one at Ultadanga and the other at Baruipur. Its cultural wing, 'Komol Gandhar', teaches dance, drama, mime and music to children, who invited regularly for paid shows.\n\nThe Durbar runs the STD/HIV Intervention Programme (commonly known as the Sonagachi Project) since 1999. The ownership and management of the Sonagachi Project was taken over by DMSC from the All India Institute of Hygiene and Public Health, a central government public health training and research institute based in Kolkata, which had initiated the programme in 1992. After gaining control of the STD/HIV Intervention Programme in 1999, DMSC began replicating the Sonagachi model in other red light areas in West Bengal. DMSC also implements STD/HIV intervention Programme among street-based sex workers and their clients, covering a population of over 20,000 sex workers and migrant labourers. DMSC currently implements and runs STD/HIV intervention programmes in 49 sex work sites in West Bengal.\n\nThe approach of Durbar's programme is based on the \"3 Rs\" - Respect, Reliance and Recognition. Respect towards sex workers, Reliance on the knowledge and wisdom of the community of sex workers and, Recognition of sex work as an occupation, for protecting their occupational and human rights.\n\nDurbar is active in building broader alliances to promote HIV prevention, care and support for HIV infected and affected individuals and families both at the national and regional levels.\n\nThe book \"\" reports investigations revealing, who tried to provide, contrary to stated policy, the DMSC allows sex slavery, trafficking, and underage girls in its brothels.\n\n\n"}
{"id": "44265239", "url": "https://en.wikipedia.org/wiki?curid=44265239", "title": "Eddie and Sol Zakay", "text": "Eddie and Sol Zakay\n\nEddie and Sol Zakay (born July 1950 and June 1952 respectively) are Israeli-born British billionaire brothers. They made their fortune in real estate through their company Topland Group.\n\nEddie Zakay was born in July 1950 and Sol Zakay was born in June 1952. They were both born in Israel \n\nEddie and Sol Zakay started their property business in Britain during the 1980s property boom. They later expanded into the U.S. and Middle Eastern markets. \"The Times\" described the brothers as having made their money principally through sale and leaseback deals with supermarkets, particularly an important deal with Marks & Spencer in 2001.\n\nSol Zakay left Britain to live in Israel. In 2013, he returned to the UK and took over as chairman and CEO of Topland from Eddie, who became deputy chairman.\n\nTopland Group is one of the world's largest privately owned property and investment groups. The company owns property in the UK and in 2013 bought 12 out of the 15 hotels (all in the UK) owned by the bankrupt Menzies Hotels for about $135 million. They own a number of other UK hotels, including Bath’s Royal Crescent Hotel, the Hilton Brighton Metropole, the Glasgow Hilton and several Thistle Hotels, six in central London and one in Edinburgh.\n\nThe brothers are thought to be majority owners of Topland which, according to \"This is Money\" in 2003, is \"ultimately controlled from the British Virgin Islands\". On the \"Forbes\" 2016 list of the world's billionaires, they were ranked #688 with a net worth of US$2.5 billion.\n\nThe company has since diversified into natural resources and renewable energy.\n\nIn 2012, \"The Guardian\" reported that Topland and Eddie Zakay were being sued by the U.K.'s Ministry of Justice for allegedly having \"conspired with a property agent in 2002 to extract inflated rents from the government on one of its central London buildings which houses the main London divorce courts\" and having engaged in \"deceit, fraud by bribery, dishonest assistance and breach of confidence\" and \"unlawful conspiracy\". The case was first lodged by Labour party minister Jack Straw in May 2010. In 2011, the brothers, via Topland, made a £25,000 donation to the British Conservative Party, who by then were in government with the Liberal Democrats. The case was subsequently \"settled out of court on confidential terms\".\n\nIn 2010, Topland held a business lunch at the Grosvenor House Hotel in London in conjunction with Jewish Care, at which £241,000 was raised for the charity's causes.\n"}
{"id": "37540972", "url": "https://en.wikipedia.org/wiki?curid=37540972", "title": "El Calabozo massacre", "text": "El Calabozo massacre\n\nThe El Calabozo massacre was an incident during the Salvadoran Civil War on August 21–22 1982, in which more than two hundred people, including children and elderly, were reportedly killed at El Calabozo by the Atlacatl Battalion of the Salvadoran Army.\n\nIn August 1982, the Salvadoran military attacked the San Vicente Department, an area where the rebel Farabundo Martí National Liberation Front was known to have bases. The department was bombed for several days before ground forces advanced, causing many civilians to flee.\n\nOn the night of August 21, a group of internally displaced people was overtaken beside the Amatitán river by the Atlacatl Battalion, a US-trained counter-insurgency unit. The Atlacatl Battalion had previously been responsible for the El Mozote massacre, in which up to 900 captured civilians had been killed. At a spot called \"El Calabozo\" (\"The Dungeon\"), the battalion surrounded the IDPs and opened fire at close range. The soldiers threw some of the bodies into the river and reportedly threw acid on others, making an exact death toll impossible to confirm, but more than two hundred were reported missing after the incident by surviving family members. The dead included infants and elderly.\n\nThe massacre was first publicly reported in The Boston Globe on September 8, 1982. Minister of Defense José Guillermo García stated that the government had investigated the incident and determined that no massacre had taken place. In 1992, survivors filed a complaint with authorities asking for an investigation. Though the Commission on the Truth for El Salvador documented the massacre's existence, the government closed the case in 1993 without charges. As of 2012, the Salvadoran government had not acknowledged the existence of the massacre or prosecuted those responsible.\n\n"}
{"id": "32934795", "url": "https://en.wikipedia.org/wiki?curid=32934795", "title": "Farmers' Party (Jamaica)", "text": "Farmers' Party (Jamaica)\n\nThe Farmers' Party was a political party in Jamaica. It contested national elections in 1955, receiving 2.7% of the vote, but failed to win a seat. It did not contest any further elections.\n"}
{"id": "22286819", "url": "https://en.wikipedia.org/wiki?curid=22286819", "title": "Federal republicanism", "text": "Federal republicanism\n\nFederal republicanism is an ideology, prevalent mainly in the 19th century Spain, which incorporates republicanism and advocates local associations of citizens and promotes citizen participation in public affairs. An important part being the concept of federalism, looking for the devolution or distribution and management to smaller administrative units to prevent governments with a strong central concentration of power. It was the prelude to cantonalism in the Glorious Revolution (Spain).\n\nAnarchists have tended to feel close to Republican authors, e.g., Benjamin Tucker who wrote, \"Anarchists are simply Jeffersonian democrats till the last consequences and without fear of it. They believe that 'the best government is that which governs least', and that which governs least does not govern at all\", referring to quotes from Thomas Jefferson and Henry David Thoreau. Mikhail Bakunin and Pierre-Joseph Proudhon expressed their sympathies to the ideal of Jeffersonian democracy and proclaimed it to be close to the anarchist idea. Enrique Flores Magon tried to win over the Mexican public by claiming Thomas Jefferson was \"an anarchist of his time\". \n\nFrancisco Pi y Margall was claimed by the Spanish anarchists of his time. It was speculated that he drew his conception of federalism from the work \"Principle of Federation\" of the anarchist Pierre-Joseph Proudhon, although some experts argue that the ideas of Pi Margall were already outlined in his earlier writings prior to Proudhon's work. \n\n"}
{"id": "1720952", "url": "https://en.wikipedia.org/wiki?curid=1720952", "title": "Federation of Canadian Municipalities", "text": "Federation of Canadian Municipalities\n\nThe Federation of Canadian Municipalities (FCM, \"Fédération canadienne des municipalités\") is an advocacy group representing over 2000 Canadian municipalities. It is an organization with no formal power but significant ability to influence debate and policy, as it is a main national lobby group of mayors, councillors and other elected municipal officials. It negotiates with the Government of Canada's departments and agencies on behalf of municipalities, and administers a number of funds.\n\nIn 1901, the Union of Canadian Municipalities was formed to represent the interests of municipal governments. Another association, the Dominion Conference of Mayors was established in 1935. In 1937, these two associations were amalgamated into the Canadian Federation of Mayors and Municipalities which in 1976 would be renamed the Federation of Canadian Municipalities.\n\nFCM was instrumental in negotiating the federal government's 2005 \"New Deal for Cities\" programme, under which Canadian federal gasoline taxes are remitted to municipalities.\n\n• Delivering $2 billion each year to municipalities from a permanent federal Gas Tax Fund. Over the next 20 years, this gas tax transfer will be worth $40 billion to cities and communities.\n\n• Successfully advocating for significant federal funding towards the $123-billion municipal infrastructure deficit. In the 2009 budget, the federal government committed more than $12 billion over two years in new and accelerated infrastructure funding to municipal priorities.\n\n• FCM's Green Municipal Fund (GMF) provides below-market loans and grants, as well as education and training services to support municipal initiatives that improve air, water and soil quality, and protect the climate. This programme was established by the Chrétien government in 2001 with $100 million \"to stimulate investment in innovative municipal infrastructure\", and \"to support municipal government action to cut pollution, reduce greenhouse gases and improve quality of life\".\n\n• Since 1987, FCM's international department has helped more than 200 Canadian municipalities and associations engage in development cooperation in more than 40 countries across Asia, Africa, the Middle East, Latin America and the Caribbean.\n\n! scope=\"col\" | No.\n! scope=\"col\" | Year\n! scope=\"col\" | Name\n! scope=\"col\" | Office\n! scope=\"col\" | Community\n! scope=\"col\" | Province\n\n"}
{"id": "7008327", "url": "https://en.wikipedia.org/wiki?curid=7008327", "title": "Greek Military Police", "text": "Greek Military Police\n\nThe Greek Military Police (), generally known in Greek by the acronym ESA (), was the military police branch of the Greek Army in the years 1951–1974. It developed into a powerful paramilitary organization and a stronghold of right-wing, conservative Army officers. It became the main security (secret police) and intelligence organization during the Greek military junta of 1967–1974. After the fall of the junta and the restoration of democracy in 1974, it was disbanded because of its brutal practices, which included the widespread use of torture.\n\nFrom 1974, the Greek Army maintains a military police section called Stratonomia (), but its powers are far less extensive than those of ESA.\n\nThe ESA was established in 1951, as Greece was preparing to join NATO. Up until then, the Greek Army did not have a specialized military police force. Being posted in the ESA was a major bonus for Army officers because it had very extensive powers within the military, even before the dictatorship. Both the officers and the soldiers who served in ESA were picked for their extreme, almost paranoid, anti-communism. This resulted in making ESA a bastion of the most conservative and anti-democratic members of the Greek officer corps. ESA men wore a distinctive uniform with a royal blue cap (the soldiers wore a beret at the time), golden lanyard on their right shoulder and an armband with the letters ESA around their left arm.\n\nIn April 1967, shortly after seizing power in a coup, junta leader George Papadopoulos appointed Dimitrios Ioannides chief of the ESA, which gradually had been transformed into an internal security army.\n\nWhen Papadopoulos declared Martial law after the 1967 coup, he increased the power of the ESA even further by making it the junta's chief arm of law and order as well as repression. Under Ioannides, ESA rose to a force of more than 20,000 men.\n\nThousands of the junta's political opponents were arrested by the ESA and sent to some of the Aegean's most desolate islands, called the prison islands. Many of the allegations of prisoner torture under the Papadopoulos regime involved the ESA, in particular its Special Investigative Section (, tr. \"Eidikón Anakritikón Tmíma\"), commonly known in its abbreviated form as ΕAT or EAT/ESA ().\n\nUse of torture chambers by ESA during interrogations was reported during the Greek military junta years. Alexandros Panagoulis was one example of a person tortured at the EAT/ESA interrogation cell units. Greek politician Nikos Konstantopoulos is another example. Army Major Spyros Moustaklis was left brain damaged and unable to speak after the torture he endured at EAT/ESA.\n\nAlarmed at moves Papadopoulos was making towards a transition to democratic rule, loannidis used his position and power as ESA chief to oust him from power.\n\nThe ESA was disbanded in 1974 by Constantine Karamanlis and its leading members involved in torture were court-martialled and sentenced during the Greek junta trials, although many served only token prison terms.\n\nResearch based on interviews with 21 former ESA members shows that all had been men had been drafted, first into regular military service and then into the ESA. Carried out by Janice T. Gibson and Mika Haritos-Fatouros, the research also showed that recruits underwent series of rigorous treatments and training over a matter of months in order to prepare them psychologically for the task of torturing detainees.\n\nThe headquarters of the Special Interrogation Sections of the Military Police (EAT-ESA) was in a building which now houses the Eleftherios Venizelos Museum at Eleftherias Park, Vassilissis Sofias Avenue in Athens.\n\nAccording to witnesses at the court martial proceedings, ESA's operating doctrine was:\n\"Those who enter here, exit either as friends or as cripples.\"\n\n\nLaw 276/76 renamed ESA simply to \"Military Police\" (Στρατονομία, \"Stratonomia\").\n\nCorresponding organizations exist also for the other two branches of the Greek armed forces: for the Hellenic Air Force (Αερονομία, \"Aeronomia\"), founded in 1945 as \"Greek Air Force Police\" (Ελληνική Αεροπορική Αστυνομία, EAA), and for the Hellenic Navy (Ναυτονομία, \"Naftonomia\", properly Υπηρεσία Ναυτονομίας or Y.NΑ.).\n\nThese three forces work together often but are independent from each other. Most of the personnel are draftee soldiers undergoing their regular military service.\n\n\n"}
{"id": "54500660", "url": "https://en.wikipedia.org/wiki?curid=54500660", "title": "Hans van Mierlo Foundation", "text": "Hans van Mierlo Foundation\n\nThe Mr. Hans van Mierlo Foundation () is a Dutch policy institute linked to the Democrats 66 (D66) party. The foundation is named after journalist and politician Hans van Mierlo the co-founder of the Democrats 66. The institute was formed on 1972 as the () and was renamed as the () in 2003. On 7 May 2011 the institute was renamed again in honor of co-founder Hans van Mierlo who had died on 11 March 2010.\n\n"}
{"id": "31496748", "url": "https://en.wikipedia.org/wiki?curid=31496748", "title": "Herringbone (formation)", "text": "Herringbone (formation)\n\nA Herringbone is one type of military formation (named after the Herringbone pattern). When in a Herringbone formation, the person at the front of the squad faces forward, while the rest of the squad lines up behind them, facing left and right, alternating as such. The final member of the squad in the herringbone formation faces backwards. When the squad decides to relocate, the person next to the member facing backwards will tap him on the shoulder to make sure he is not left behind. This formation is performed commonly after crossing obstacles.\n\n"}
{"id": "601621", "url": "https://en.wikipedia.org/wiki?curid=601621", "title": "Hubbert peak theory", "text": "Hubbert peak theory\n\nThe Hubbert peak theory says that for any given geographical area, from an individual oil-producing region to the planet as a whole, the rate of petroleum production tends to follow a bell-shaped curve. It is one of the primary theories on peak oil.\n\nChoosing a particular curve determines a point of maximum production based on discovery rates, production rates and cumulative production. Early in the curve (pre-peak), the production rate increases due to the discovery rate and the addition of infrastructure. Late in the curve (post-peak), production declines because of resource depletion.\n\nThe Hubbert peak theory is based on the observation that the amount of oil under the ground in any region is finite, therefore the rate of discovery which initially increases quickly must reach a maximum and decline. In the US, oil extraction followed the discovery curve after a time lag of 32 to 35 years. The theory is named after American geophysicist M. King Hubbert, who created a method of modeling the production curve given an assumed ultimate recovery volume.\n\n\"Hubbert's peak\" can refer to the peaking of production of a particular area, which has now been observed for many fields and regions.\n\nHubbert's peak was thought to have been achieved in the United States contiguous 48 states (that is, excluding Alaska and Hawaii) in the early 1970s. Oil production peaked at and then declined for several years since. Yet, recent advances in extraction technology, particularly those that led to the extraction of tight oil and oil from shale, have drastically changed the picture. A decline in production followed the 1970s peak of more than 10 million barrels. In November of 2017 the United States once again surpassed the 10 million barrel mark for the first time since 1970. \n\nPeak oil as a proper noun, or \"Hubbert's peak\" applied more generally, refers to a predicted event: the peak of the entire planet's oil production. After peak oil, according to the Hubbert Peak Theory, the rate of oil production on Earth would enter a terminal decline. On the basis of his theory, in a paper he presented to the American Petroleum Institute in 1956, Hubbert correctly predicted that production of oil from conventional sources would peak in the continental United States around 1965–1970. His prediction of inevitable decline has been incorrect, but the 1970 peak has yet not been surpassed. Hubbert further predicted a worldwide peak at \"about half a century\" from publication and approximately 12 gigabarrels (GB) a year in magnitude. In a 1976 TV interview Hubbert added that the actions of OPEC might flatten the global production curve but this would only delay the peak for perhaps 10 years. The development of new technologies has provided access to large quantities of unconventional resources, and the boost of production has largely discounted Hubbert's prediction.\n\nIn 1956, Hubbert proposed that fossil fuel production in a given region over time would follow a roughly bell-shaped curve without giving a precise formula; he later used the Hubbert curve, the derivative of the logistic curve, for estimating future production using past observed discoveries.\n\nHubbert assumed that after fossil fuel reserves (oil reserves, coal reserves, and natural gas reserves) are discovered, production at first increases approximately exponentially, as more extraction commences and more efficient facilities are installed. At some point, a peak output is reached, and production begins declining until it approximates an exponential decline.\n\nThe Hubbert curve satisfies these constraints. Furthermore, it is symmetrical, with the peak of production reached when half of the fossil fuel that will ultimately be produced has been produced. It also has a single peak.\n\nGiven past oil discovery and production data, a Hubbert curve that attempts to approximate past discovery data may be constructed and used to provide estimates for future production. In particular, the date of peak oil production or the total amount of oil ultimately produced can be estimated that way. Cavallo defines the Hubbert curve used to predict the U.S. peak as the derivative of:\n\nwhere formula_2 is the total resource available (ultimate recovery of crude oil), formula_3 the cumulative production, and formula_4 and formula_5 are constants. The year of maximum annual production (peak) is:\n\nso now the cumulative production formula_3 reaches the half of the total available resource:\n\nThe sum of multiple Hubbert curves, a technique not developed by Hubbert himself, may be used in order to model more complicated real life scenarios. For example, when new technologies like hydraulic fracing combined with new formations that were not productive before the new technology, this can create a need for multiple curves. These technologies are limited in number, but make a big impact on production and cause a need for a new curve to be added to the old curve and the entire curve to be reworked.\n\nHubbert, in his 1956 paper, presented two scenarios for US crude oil production:\nHubbert's upper-bound estimate, which he regarded as optimistic, accurately predicted that US oil production would peak in 1970, although the actual peak was 17% higher than Hubbert's curve. Production declined, as Hubbert had predicted, and stayed within 10 percent of Hubbert's predicted value from 1974 through 1994; since then, actual production has been significantly greater than the Hubbert curve. The development of new technologies has provided access to large quantities of unconventional resources, and the boost of production has largely discounted Hubbert's prediction.\n\nHubbert's 1956 production curves depended on geological estimates of ultimate recoverable oil resources, but he was dissatisfied by the uncertainty this introduced, given the various estimates ranging from 110 billion to 590 billion barrels for the US. Starting in his 1962 publication, he made his calculations, including that of ultimate recovery, based only on mathematical analysis of production rates, proved reserves, and new discoveries, independent of any geological estimates of future discoveries. He concluded that the ultimate recoverable oil resource of the contiguous 48 states was 170 billion barrels, with a production peak in 1966 or 1967. He considered that because his model incorporated past technical advances, that any future advances would occur at the same rate, and were also incorporated. Hubbert continued to defend his calculation of 170 billion barrels in his publications of 1965 and 1967, although by 1967 he had moved the peak forward slightly, to 1968 or 1969.\n\nA post-hoc analysis of peaked oil wells, fields, regions and nations found that Hubbert's model was the \"most widely useful\" (providing the best fit to the data), though many areas studied had a sharper \"peak\" than predicted.\n\nA 2007 study of oil depletion by the UK Energy Research Centre pointed out that there is no theoretical and no robust practical reason to assume that oil production will follow a logistic curve. Neither is there any reason to assume that the peak will occur when half the ultimate recoverable resource has been produced; and in fact, empirical evidence appears to contradict this idea. An analysis of a 55 post-peak countries found that the average peak was at 25 percent of the ultimate recovery.\n\nHubbert also predicted that natural gas production would follow a logistic curve similar to that of oil. At right is his gas production curve for the United States, published in 1962.\n\nThe ratio of energy extracted to the energy expended in the process is often referred to as the Energy Return on Energy Investment (EROI or EROEI). Should the EROEI drops to one, or equivalently the Net energy gain falls to zero, the oil production is no longer a net energy source.\n\nThere is a difference between a barrel of oil, which is a measure of oil, and a barrel of oil equivalent (BOE), which is a measure of energy. Many sources of energy, such as fission, solar, wind, and coal, are not subject to the same near-term supply restrictions that oil is. Accordingly, even an oil source with an EROEI of 0.5 can be usefully exploited if the energy required to produce that oil comes from a cheap and plentiful energy source. Availability of cheap, but hard to transport, natural gas in some oil fields has led to using natural gas to fuel enhanced oil recovery. Similarly, natural gas in huge amounts is used to power most Athabasca tar sands plants. Cheap natural gas has also led to ethanol fuel produced with a net EROEI of less than 1, although figures in this area are controversial because methods to measure EROEI are in debate.\n\nThe assumption of inevitable declining volumes of oil and gas produced per unit of effort is contrary to recent experience in the US. In the United States, as of 2017, there has been an ongoing decade-long increase in the productivity of oil and gas drilling in all the major tight oil and gas plays. The US Energy Information Administration reports, for instance, that in the Bakken Shale production area of North Dakota, the volume of oil produced per day of drilling rig time in January 2017 was 4 times the oil volume per day of drilling five years previous, in January 2012, and nearly 10 times the oil volume per day of ten years previous, in January 2007. In the Marcellus gas region of the northeast, The volume of gas produced per day of drilling time in January 2017 was 3 times the gas volume per day of drilling five years previous, in January 2012, and 28 times the gas volume per day of drilling ten years previous, in January 2007.\n\nInsofar as economic growth is driven by oil consumption growth, post-peak societies must adapt. Hubbert believed:\n\nSome economists describe the problem as uneconomic growth or a false economy. At the political right, Fred Ikle has warned about \"conservatives addicted to the Utopia of Perpetual Growth\". Brief oil interruptions in 1973 and 1979 markedly slowed—but did not stop—the growth of world GDP.\n\nBetween 1950 and 1984, as the Green Revolution transformed agriculture around the globe, world grain production increased by 250%. The energy for the Green Revolution was provided by fossil fuels in the form of fertilizers (natural gas), pesticides (oil), and hydrocarbon fueled irrigation.\n\nDavid Pimentel, professor of ecology and agriculture at Cornell University, and Mario Giampietro, senior researcher at the National Research Institute on Food and Nutrition (INRAN), place in their study \"Food, Land, Population and the U.S. Economy\" the maximum U.S. population for a sustainable economy at 200 million. To achieve a sustainable economy world population will have to be reduced by two-thirds, says the study. Without population reduction, this study predicts an agricultural crisis beginning in 2020, becoming critical c. 2050. The peaking of global oil along with the decline in regional natural gas production may precipitate this agricultural crisis sooner than generally expected. Dale Allen Pfeiffer claims that coming decades could see spiraling food prices without relief and massive starvation on a global level such as never experienced before.\n\nAlthough Hubbert peak theory receives most attention in relation to peak oil production, it has also been applied to other natural resources.\n\nDoug Reynolds predicted in 2005 that the North American peak would occur in 2007. Bentley predicted a world \"decline in conventional gas production from about 2020\".\n\nAlthough observers believe that peak coal is significantly further out than peak oil, Hubbert studied the specific example of anthracite in the US, a high grade coal, whose production peaked in the 1920s. Hubbert found that anthracite matches a curve closely. Hubbert had recoverable coal reserves worldwide at 2.500 × 10 metric tons and peaking around 2150 (depending on usage).\n\nMore recent estimates suggest an earlier peak. \"Coal: Resources and Future Production\" (PDF 630KB), published on April 5, 2007 by the Energy Watch Group (EWG), which reports to the German Parliament, found that global coal production could peak in as few as 15 years. Reporting on this, Richard Heinberg also notes that the date of peak annual energetic extraction from coal is likely to come earlier than the date of peak in quantity of coal (tons per year) extracted as the most energy-dense types of coal have been mined most extensively. A second study,\n\"The Future of Coal\" by B. Kavalov and S. D. Peteves of the Institute for Energy (IFE), prepared for European Commission Joint Research Centre, reaches similar conclusions and states that\n\"\"coal might not be so abundant, widely available and reliable as an energy source in the future\".\n\nWork by David Rutledge of Caltech predicts that the total of world coal production will amount to only about 450 gigatonnes. This implies that coal is running out faster than usually assumed.\n\nIn a paper in 1956, after a review of US fissionable reserves, Hubbert notes of nuclear power:\n\nAs of 2015, the identified resources of uranium are sufficient to provide more than 135 years of supply at the present rate of consumption. Technologies such as the thorium fuel cycle, reprocessing and fast breeders can, in theory, extend the life of uranium reserves from hundreds to thousands of years.\n\nCaltech physics professor David Goodstein stated in 2004 that\n\nAlmost all helium on Earth is a result of radioactive decay of uranium and thorium. Helium is extracted by fractional distillation from natural gas, which contains up to 7% helium. The world's largest helium-rich natural gas fields are found in the United States, especially in the Hugoton and nearby gas fields in Kansas, Oklahoma, and Texas. The extracted helium is stored underground in the National Helium Reserve near Amarillo, Texas, the self-proclaimed \"Helium Capital of the World\". Helium production is expected to decline along with natural gas production in these areas.\n\nHelium, which is the second-lightest chemical element, will rise to the upper layers of Earth's atmosphere, where it can forever break free from Earth's gravitational attraction. Approximately 1,600 tons of helium are lost per year as a result of atmospheric escape mechanisms.\n\nHubbert applied his theory to \"rock containing an abnormally high concentration of a given metal\" and reasoned that the peak production for metals such as copper, tin, lead, zinc and others would occur in the time frame of decades and iron in the time frame of two centuries like coal. The price of copper rose 500% between 2003 and 2007 and was attributed by some to peak copper. Copper prices later fell, along with many other commodities and stock prices, as demand shrank from fear of a global recession. Lithium availability is a concern for a fleet of Li-ion battery using cars but a paper published in 1996 estimated that world reserves are adequate for at least 50 years. A similar prediction for platinum use in fuel cells notes that the metal could be easily recycled.\n\nIn 2009, Aaron Regent president of the Canadian gold giant Barrick Gold said that global output has been falling by roughly one million ounces a year since the start of the decade. The total global mine supply has dropped by 10pc as ore quality erodes, implying that the roaring bull market of the last eight years may have further to run. \"There is a strong case to be made that we are already at 'peak gold',\" he told The Daily Telegraph at the RBC's annual gold conference in London. \"Production peaked around 2000 and it has been in decline ever since, and we forecast that decline to continue. It is increasingly difficult to find ore,\" he said.\n\nOre grades have fallen from around 12 grams per tonne in 1950 to nearer 3 grams in the US, Canada, and Australia. South Africa's output has halved since peaking in 1970. Output fell a further 14 percent in South Africa in 2008 as companies were forced to dig ever deeper – at greater cost – to replace depleted reserves.\n\nWorld mined gold production has peaked four times since 1900: in 1912, 1940, 1971, and 2001, each peak being higher than previous peaks. The latest peak was in 2001, when production reached 2,600 metric tons, then declined for several years. Production started to increase again in 2009, spurred by high gold prices, and achieved record new highs each year in 2012, 2013, and in 2014, when production reached 2,990 tonnes.\n\nPhosphorus supplies are essential to farming and depletion of reserves is estimated at somewhere from 60 to 130 years. According to a 2008 study, the total reserves of phosphorus are estimated to be approximately 3,200 MT, with a peak production at 28 MT/year in 2034. Individual countries' supplies vary widely; without a recycling initiative America's supply is estimated around 30 years. Phosphorus supplies affect agricultural output which in turn limits alternative fuels such as biodiesel and ethanol. Its increasing price and scarcity (global price of rock phosphate rose 8-fold in the 2 years to mid 2008) could change global agricultural patterns. Lands, perceived as marginal because of remoteness, but with very high phosphorus content, such as the Gran Chaco may get more agricultural development, while other farming areas, where nutrients are a constraint, may drop below the line of profitability.\n\nHubbert's original analysis did not apply to renewable resources. However, over-exploitation often results in a Hubbert peak nonetheless. A modified Hubbert curve applies to any resource that can be harvested faster than it can be replaced.\n\nFor example, a reserve such as the Ogallala Aquifer can be mined at a rate that far exceeds replenishment. This turns much of the world's underground water and lakes into finite resources with peak usage debates similar to oil. These debates usually center around agriculture and suburban water usage but generation of electricity from nuclear energy or coal and tar sands mining mentioned above is also water resource intensive. The term fossil water is sometimes used to describe aquifers whose water is not being recharged.\n\n\nEconomist Michael Lynch argues that the theory behind the Hubbert curve is too simplistic and relies on an overly Malthusian point of view. Lynch claims that Campbell's predictions for world oil production are strongly biased towards underestimates, and that Campbell has repeatedly pushed back the date.\n\nLeonardo Maugeri, vice president of the Italian energy company Eni, argues that nearly all of peak estimates do not take into account unconventional oil even though the availability of these resources is significant and the costs of extraction and processing, while still very high, are falling because of improved technology. He also notes that the recovery rate from existing world oil fields has increased from about 22% in 1980 to 35% today because of new technology and predicts this trend will continue. The ratio between proven oil reserves and current production has constantly improved, passing from 20 years in 1948 to 35 years in 1972 and reaching about 40 years in 2003. These improvements occurred even with low investment in new exploration and upgrading technology because of the low oil prices during the last 20 years. However, Maugeri feels that encouraging more exploration will require relatively high oil prices.\n\nEdward Luttwak, an economist and historian, claims that unrest in countries such as Russia, Iran and Iraq has led to a massive underestimate of oil reserves. The Association for the Study of Peak Oil and Gas (ASPO) responds by claiming neither Russia nor Iran are troubled by unrest currently, but Iraq is.\n\nCambridge Energy Research Associates authored a report that is critical of Hubbert-influenced predictions:\n\nCERA does not believe there will be an endless abundance of oil, but instead believes that global production will eventually follow an \"undulating plateau\" for one or more decades before declining slowly, and that production will reach 40 Mb/d by 2015.\n\nAlfred J. Cavallo, while predicting a conventional oil supply shortage by no later than 2015, does not think Hubbert's peak is the correct theory to apply to world production.\n\nAlthough M. King Hubbert himself made major distinctions between decline in petroleum production versus depletion (or relative lack of it) for elements such as fissionable uranium and thorium, some others have predicted peaks like peak uranium and peak phosphorus soon on the basis of published reserve figures compared to present and future production. According to some economists, though, the amount of proved reserves inventoried at a time may be considered \"a poor indicator of the total future supply of a mineral resource.\"\n\nAs some illustrations, tin, copper, iron, lead, and zinc all had both production from 1950 to 2000 and reserves in 2000 much exceed world reserves in 1950, which would be impossible except for how \"proved reserves are like an inventory of cars to an auto dealer\" at a time, having little relationship to the actual total affordable to extract in the future. In the example of peak phosphorus, additional concentrations exist intermediate between 71,000 Mt of identified reserves (USGS) and the approximately 30,000,000,000 Mt of other phosphorus in Earth's crust, with the average rock being 0.1% phosphorus, so showing decline in human phosphorus production will occur soon would require far more than comparing the former figure to the 190 Mt/year of phosphorus extracted in mines (2011 figure).\n\n"}
{"id": "1745221", "url": "https://en.wikipedia.org/wiki?curid=1745221", "title": "Hungarian irredentism", "text": "Hungarian irredentism\n\nHungarian irredentism or Greater Hungary is a broad umbrella term consisting of irredentist and revisionist political ideas. The idea is associated with Hungarian revisionism. Its goal is to restore the pre-World War I borders of the Kingdom of Hungary, or at least to regain control over Hungarian-populated areas in Hungary's neighbouring countries.\n\nThe Treaty of Trianon defined the borders of the new independent Hungary and, compared against the claims of the pre-war Kingdom, new Hungary had approximately 72% less land stake and about two-thirds fewer inhabitants, almost 5 million of these being of Hungarian ethnicity. However, only the 54% of the inhabitants of the pre-war Kingdom of Hungary were Hungarians before World War I. Following the treaty's instatement, Hungarian leaders became inclined towards revoking some of its terms. This political aim gained greater attention and was a serious national concern up through the second World War.\n\nHungary, supported by the Axis Powers, was successful temporarily in gaining some (primarily ethnic Hungarian) regions of the former Kingdom in the First and Second Vienna Awards of 1938 and 1940, and through military campaign gained regions of Carpathian Ruthenia in 1939 and (ethnically mixed) Bačka, Baranja, Međimurje, and Prekmurje in 1941 (Hungarian occupation of Yugoslav territories). Following the close of World War II, the borders of Hungary as defined by the Treaty of Trianon were restored, except for three Hungarian villages that were transferred to Czechoslovakia. These villages are today administratively a part of Bratislava.\n\nThe independent Kingdom of Hungary was established in 1000 AD, and remained a regional power in Central Europe until Ottoman Empire conquered its central part in 1526 following the Battle of Mohács. In 1541 the territory of the former Kingdom of Hungary was divided into three portions: in the west and north, Habsburg Kingdom of Hungary retained its existence under Habsburg rule; the Ottomans controlled the south-central parts of former Kingdom of Hungary; while in the east, the Eastern Hungarian Kingdom (later the Principality of Transylvania) was formed as a semi-independent entity under Ottoman suzerainty. After the Ottoman conquest in the Kingdom of Hungary, the ethnic structure of the kingdom started to become more multi-ethnic because of immigration to the sparsely populated areas. Between 1683 and 1717, the Habsburg Monarchy conquered all the Ottoman territories that were part of the Kingdom of Hungary before 1526, and incorporated some of these areas into the Habsburg Kingdom of Hungary.\n\nAfter a suppressed uprising in 1848-1849, the Kingdom of Hungary and its diet were dissolved, and territory of the Kingdom of Hungary was divided into 5 districts, which were Pest & Ofen, Ödenburg, Preßburg, Kaschau and Großwardein, directly controlled from Vienna while Croatia, Slavonia, and the Voivodeship of Serbia and Banat of Temeschwar were separated from the Kingdom of Hungary between 1849-1860. This new centralized rule, however, failed to provide stability, and in the wake of military defeats the Austrian Empire was transformed into Austria-Hungary with the Austro-Hungarian Compromise of 1867, by which Kingdom of Hungary became one of two constituent entities of the new dual monarchy with self-rule in its internal affairs.\n\nA considerable number of the figures who are today considered important in Hungarian culture were born in what are today parts of Romania, Slovakia, Poland, Ukraine, and Austria (\"see List of Hungarians who were born outside present-day Hungary\"). Names of Hungarian dishes, common surnames, proverbs, sayings, folk songs etc. also refer to these rich cultural ties. After 1867, the non-Hungarian ethnic groups were subject to assimilation and Magyarization.\n\nAmong the most notable policies was the promotion of the Hungarian language as the country's official language (replacing Latin and German); however, this was often at the expense of West Slavic languages and the Romanian language. The new government of autonomous Kingdom of Hungary took the stance that Kingdom of Hungary should be a Hungarian nation state, and that all other peoples living in the Kingdom of Hungary—Germans, Jews, Romanians, Slovaks, Poles, Ruthenes and other ethnicities—should be assimilated. (The Croats were to some extent an exception to this, as they had a fair degree of self-government within Croatia-Slavonia, a dependent kingdom within the Kingdom of Hungary.)\n\nThe peace treaties signed after the First World War redefined the national borders of Europe. The dissolution of Austria-Hungary, after its defeat in the First World War, gave an opportunity for the subject nationalities of the old Monarchy to all form their own nation states (however, most of the resulting states nevertheless became multi-ethnic states comprising several nationalities). The Treaty of Trianon of 1920 defined borders for the new Hungarian state: in the north, the Slovak and Ruthene areas, including Hungarian majority areas became part of the new state of Czechoslovakia. Transylvania and most of the Banat became part of Romania, while Croatia-Slavonia and the other southern areas became part of the new state of Yugoslavia.\n\nThe arguments of Hungarian revisionists for their goal were: the presence of Hungarian majority areas in the neighboring countries, perceived historical traditions of the Kingdom of Hungary, or the perceived geographical unity and economic symbiosis of the region within the Carpathian Basin, although some Hungarian revisionists preferred to regain only ethnically Hungarian majority areas surrounding Hungary.\n\nPost-Trianon Hungary had about half of the population of the former Kingdom. The population of the territories of the Kingdom of Hungary that were not assigned to the post-Trianon Hungary had, in total, non-Hungarian majority, although they included a sizable proportion of ethnic Hungarians and Hungarian majority areas. According to Karoly Kocsis and Eszter Kocsis-Hodosi the ethnic composition in 1910\n\nTrianon thus defined Hungary's new borders in a way that made ethnic Hungarians the overwhelmingly absolute majority in the country. Almost 3 million ethnic Hungarians remained outside the borders of post-Trianon Hungary. A considerable number of non-Hungarian nationalities remained within the new borders of Hungary, the largest of which were Germans (Schwabs) with 550,062 people (6.9%).\n\nAfter the Treaty of Trianon, a political concept known as Hungarian revisionism became popular in Hungary. The Treaty of Trianon was an injury for the Hungarian people, and Hungarian revisionists have created a nationalistic ideology with the political goal of the restoration of borders of historical pre-Trianon Kingdom of Hungary.\n\nThe justification for this aim usually followed the fact that two-thirds of the country's area was taken by the neighboring countries with approximately 3 million Hungarians living in these territories. Several municipalities that had purely ethnic Hungarian population were excluded from post-Trianon Hungary, which had borders designed to cut most economic regions (Szeged, Pécs, Debrecen etc.) half, and keep railways on the other side.\n\nHungary's government allied itself with Nazi Germany during World War II in exchange for assurances that Greater Hungary's borders would be restored. This goal was partially achieved when Hungary reannexed territories from Czechoslovakia, Romania, and Yugoslavia at the outset of the war. These annexations were affirmed under the Munich Agreement (1938), two Vienna Awards (1938 and 1940), and aggression against Yugoslavia (1941), the latter achieved one week after the German army had already invaded Yugoslavia.\n\nThe percentage of Hungarian speakers was 84% in southern Czechoslovakia and 15% in the Sub-Carpathian Rus.\n\nThe population of Northern Transylvania, according to the Hungarian census from 1941 counted 53.5% Hungarians and 39.1% Romanians.\n\nThe Yugoslav territory occupied by Hungary (including Bačka, Baranja, Međimurje and Prekmurje) had approximately one million inhabitants, including 543,000 Yugoslavs (Serbs, Croats and Slovenes), 301,000 Hungarians, 197,000 Germans, 40,000 Slovaks, 15,000 Rusyns, and 15,000 Jews. In Bačka region only, the 1931 census put the percentage of the speakers of Hungarian at 34.2%, while one of interpretations of later Hungarian census from 1941 states that, 45,4% or 47,2% declared themselves to be Hungarian native speakers or ethnic Hungarians (this interpretation is provided by authors Károly Kocsis and Eszter Kocsisné Hodosi. The 1941 census, however, did not recorded ethnicity of the people, but only mother/native tongue ). Population of entire Bačka numbered 789,705 inhabitants in 1941. This means that from the beginning of the occupation, the number of Hungarian speakers in Bačka increased by 48,550, while the number of Serbian speakers decreased by 75,166.\n\nThe establishment of Hungarian rule met with insurgency on part of the non-Hungarian population in some places and retaliation of the Hungarian forces was labelled war crimes such as Ip and other localities in Northern Transylvania (directed against Romanians) or Bačka, where Hungarian military between 1941 and 1944 deported or killed 19,573 civilians, mainly Serbs and Jews, but also Hungarians who did not collaborate with the new authorities. About 56,000 people were also expelled from Bačka.\n\nThe Jewish population of Hungary and the areas it occupied were partly diminished as part of the Holocaust. Tens of thousands of Romanians fled from Hungarian-ruled Northern Transylvania, and vice versa. After the war the areas were returned to neighboring countries and Hungary's territory was slightly further reduced by ceding three villages south of Bratislava to Slovakia. The reoccupying states exercised genocide on Hungarian civilians, both in Yugoslavia by Yugoslav partisans (the exact number of ethnic Hungarians killed by Yugoslav partisans is not clearly established and estimates range from 4,000 to 40,000; 20,000 is often regarded as most probable), and in Transylvania by the Maniu Guard towards the end of World War II.\n\nThe following table lists areas with Hungarian population in neighboring countries today:\n\nDuring the Communist era, Marxist–Leninist ideology and Stalin's theory on nationalities considered nationalism to be a malady of a bourgeois capitalism. In Hungary, the minorities' question disappeared from the political agenda. Communist hegemony guaranteed a facade of inter-ethnic peace while failing to secure a lasting accommodation of minority interests in unitary states.\n\nThe fall of Communism aroused the expectations of Hungarian minorities in neighboring countries and left Hungary unprepared to deal with the issue. Hungarian politicians campaigned to formalize the rights of Hungarian minorities in neighboring countries, thus causing anxiety in the region. They secured agreements on the necessity for guaranteeing collective rights and formed new Hungarian minority organizations to promote cultural rights and political participation. In Romania, Slovakia, and Yugoslavia (now Serbia), former Communists secured popular legitimacy by accommodating nationalist tendencies that were hostile to minority rights.\n\nThe latest controversy caused by the government of Viktor Orbán is when Hungary took the presidency over the EU in 2011 when the \"historical timeline\" features was presented - among other cultural, historical and scientific symbols or images of Hungary - an 1848 map of Greater Hungary, when Budapest ruled over large swathes of its neighbors.\n\nThe campaign materials of Jobbik contain map of the pre-1920 Greater Hungary.\n\nUnder great pressure from the EU and NATO, Hungary signed a bilateral state treaty with Slovakia on Good Neighborly Relations and Friendly Cooperation in March 1995, aimed at resolving disputes concerning borders and minority rights. Its vague language, though, allows rival interpretations. One cause of conflict was the COE's Recommendation 1201 which stipulates the creation of autonomous self-government based on ethnic principles in areas where ethnic minorities represent a majority of the population.\n\nThe Hungarian Prime Minister insisted that the treaty protected the Hungarian minority as a \"community\". Slovakia accepted the 1201 Recommendation in the treaty, but denounced the concept of collective rights of minorities and political autonomy as \"unacceptable and destabilizing\". Slovakia finally ratified the treaty in March 1996 after the government attached a unilateral declaration that the accord would not provide for collective autonomy for Hungarians. The Hungarian government therefore refused to recognize the validity of the declaration.\n\nAfter World War II, a Hungarian Autonomous Region was created in Transylvania, which encompassed most of the land inhabited by the Székelys. This region lasted until 1964 when the administrative reform divided Romania into the current counties. From 1947 until the 1989 Romanian Revolution and the death of Nicolae Ceauşescu, a systematic Romanianization of Hungarians took place, with several discriminatory provisions, denying them their cultural identity. This tendency started to abate after 1989, the question of Székely autonomy remains a sensitive issue.\n\nOn 16 September 1996, after five years of negotiations, Hungary and Romania also signed a bilateral treaty, which had been stalled over the nature and extent of minority protection that Bucharest should grant to Hungarian citizens. Hungary dropped its demands for autonomy for ethnic minorities; in exchange, Romania accepted a reference to Recommendation 1201 in the treaty, but with a joint interpretive declaration that guarantees individual rights, but excludes collective rights and territorial autonomy based on ethnic criteria. These concessions were made in large measure because both countries recognized the need to improve good neighborly relations as a prerequisite for NATO membership.\n\nThere are five main ethnic Hungarian political parties in Vojvodina:\n\nThese parties are advocating the establishment of the territorial autonomy for Hungarians in the northern part of Vojvodina, which would include the municipalities with Hungarian majority (See Hungarian Regional Autonomy for details).\n\n"}
{"id": "16473858", "url": "https://en.wikipedia.org/wiki?curid=16473858", "title": "Impeach (motion)", "text": "Impeach (motion)\n\nThe motion to impeach is used to bring an accusation against a person. A majority vote is needed to put the accused on trial. A majority vote convicts for a minor offense, and a two-thirds vote for a major offense. A vote of censure or reprimand requires majority vote, and suspension or expulsion a two-thirds vote. \n\nRobert's Rules of Order does not have a motion to impeach. However, this book requires a fair disciplinary process which includes appointing a committee to conduct a confidential investigation, report of the committee and preferral of charges if warranted, formal notification of the accused, and trial; and a two-thirds vote is required to expel.\n\n"}
{"id": "8298797", "url": "https://en.wikipedia.org/wiki?curid=8298797", "title": "International Commission for Central American Recovery and Development", "text": "International Commission for Central American Recovery and Development\n\nEstablished at Duke University (North Carolina, United States) in 1987, the International Commission for Central American Recovery and Development (ICCARD) was a task force composed of thirty-three scholars and leaders (Ford Foundation 1988: 155). The commission published its report, \"Poverty, Conflict, and Hope: A Turning Point in Central America,\" in 1989 with principles for promoting peace, genuine democracy and equitable development in Central America. Also known as the Sanford Commission Report (after U.S. Senator Terry Sanford, \"the principal catalyst of the commission's work\") the plan called for immediate action, regional and international cooperation based on learning from history (Zuvekas 2001: 128). With numerous proposals for Central America over the years, the commission built upon past experiences.\n\nThe commission's recommendations represented the deliberations of an international body for regional democracy and development. With brief historical insights, from lessons learned the report's plan of action for a turning point in Central America is an easy to read guide for sustainable development and democracy. The report itself, released \"on the eve of the fourth meeting of the Central American Presidents\", (Envio 1989) is also a valuable reference for analysis of the region and developments since the time of the commission.\n\nThe report noted that the economic expansion following the Second World War is critical to understanding the historical roots of the crisis that Central America faced during the 1970s and 1980s, after the region's economy nearly collapsed from the inability to adjust to international structural changes. While the region averaged unprecedented growth from 1950 to 1978, the strengths of the economy in Central America did not outweigh the faults of exclusionary politics, flawed economic structures, decline of intra-regional trade, and external economic setbacks that consequently led to social unrest, violence and civil war. While Zuvekas (2001: 128-120) maintains that the report \"does not sufficiently recognize the (admittedly limited) progress\" made throughout the 1980s, the commentator on the commission does believe the \"ICCARD is fundamentally sound.\" From the historical detail on the civil strife that uprooted and caused suffering in the region for over ten years, the international commission then provided an immediate plan for action in order to attend to the social impact of the crisis.\n\nThe immediate plan to aid those in poverty is followed by a strategy for sustainable development, including the revival of productivity and production, assuring the creation of employment, the development of human resources, fiscal and monetary reform as well as strategy to conserve natural resources. In sequencing the plan, fiscal reform is noted as a fundamental step to finance the recovery of human resource development from positive, real returns of hard-earned profit. With recognition of the difficulties in sustaining democratic governance in the region, the report then discusses building democracy as inseparable from development. The plan for building democracy consists of broadening participation in civil society, advocating respect for human rights with tolerance to instill values of democracy and peace. \n\nThe international commission report stresses that the fragile institutions representing the interests of those excluded from political processes, the minimal financial resources for mobilizing to provide for the poorest in society, and the perceptions of those who hold power are obstacles to progressive reform. At this point, the report as it was presented addressed the developmental needs of the region rather than on a country-by-country basis, allowing for the \"development of more comprehensive policies\" (Envivo 1989). The plan to promote democracy thus involves strategy for civilian rule and civil-military relations where: \"security is not achieved by repression and military dominance of government. Continued withdrawal of the military from the political scene, their training in democratic political values, the rejection of authoritarian doctrines of national security, and the development of effective mechanisms of civilian political control,\" is critical Central American societies (ICCARD 1989: 61). The commission's plan advises from the need for economic and social justice with a strong role in developing democracy through nongovernmental organizations and the support of the media.\n\nFor sustainable democracy, the report maintains regional institutions and cooperation are essential, noting The Central American Parliament, The Central American Economic and Social Council, as well as The Central American Court of Justice are vital to facilitating regional integration. The vision of regional economic planning accordingly \"rests on an assumption that political dialogue is the means to resolve both internal and regional conflicts\" (Envio 1989). Historical factions related to integration are detailed, including the central challenges to rebuilding the Free Trade Zone under the \"conditionality\" of World Bank, the International Monetary Fund, and the U.S. Agency for International Development structural adjustment programs. The commission suggests that while there are favorable conditions for regional investment and cooperation, the intra-regional debt also remains a major obstacle.\n\nIf integration is to be sustainable and successful, regional institutions must be strengthened, particularly the Central American Bank for Economic Integration and the Secretariat of the Central American Monetary Council. The strengthening of these institutions is essential to achieving economic cooperation – or \"acting together internationally\" in the words of the report – which requires an institutional coherence that the commission suggests the European Community is, \"with it long experience in developing regional structures, in an excellent position to provide expertise\" (ICCARD 1989: 76). To maintain international cooperation, the report addresses the conditions for any support to promote trade, advance technology in the region and open markets for Central American exports to revive the intra-regional economy. Markets must provide for the modernization of regional technology and financial flows need be devoted to domestic reforms, debt reduction and restructuring. Finally, the report advises for a coordinated diversification of foreign assistance based on performance conditions.\n\nAnticipating a future turning point toward sustainable development and authentic democratic institutions in Central America, the commission concludes with statement that the recommendations documented are drawn from principles of democratic development by understanding problems of the past in light of the recent history of the region. Commentators such as Zuvekas (2001: 125) maintains some of the report (actually, assembled from essays by key Central American scholars) is disappointing, and Envivo (1989) notes issues such as land reform remained untouched. Nonetheless, the report is a reasonable analysis of the difficulties facing the region with authoritative perspectives for the direction domestic governments, international organizations and the overall Central American political economy need undertake to ensure recovery in the region. The Report of the International Commission for Central American Recovery and Development is a valuable guide for case study and application of theory based upon history with hope for the future of the region.\n\n\n\n\n\n"}
{"id": "8971031", "url": "https://en.wikipedia.org/wiki?curid=8971031", "title": "Jim Wells (politician)", "text": "Jim Wells (politician)\n\nJim Wells (born 27 April 1957) is a Northern Ireland politician from the Democratic Unionist Party and formerly Deputy Speaker of the Northern Ireland Assembly. Wells is one of five Assembly members for South Down. He was a councillor on Down District Council from 2001 to 2011.\n\nWells was employed as a manager by the National Trust from 1989 until 1998. In 2017, he resigned his membership of the National Trust over the Trusts support for LGBT rights.\n\nWells was elected to serve as a Councillor in Down District Council in 2001, having previously held a seat on Lisburn Borough Council and Banbridge Borough Council. He served on the Council until stepping down at the 2011 election.\nHe was Assembly Member for the South Down constituency initially from 1982 to 1986. He was re-elected in 1998 and is currently in his fifth term having been re-elected in 2017.\nDuring that time he served as Deputy Chair of the Committee for Health, Social Services and Public Safety before he was appointed as Minister of Health in September 2014 where he served until his removal in May 2015.\n\nWells is a Young Earth creationist. and along with his DUP colleagues, Nelson Mccausland and Gregory Campbell, he lobbied for the creationism dogma to be included in the Giants causeway exhibition. Initially the National Trust acceded to the request but after coming under pressure from the public withdrew the exhibition in 2012. Wells is not alone in his creationist views. in 2013 some 40% of DUP activists believe that creationism should be taught in science classes, a Belfast Telegraph survey found.\n\nWells and his colleagues have been accused of being science deniers. In 2014, DUP ministers tried to oppose proposals to introduce local measures against climate change in Northern Ireland.\n\nAt an event aimed at promoting the rejection of evolution among children and was endorsed by the MLA who wants to see creationism “taught in every school”.\n\nWells had been tipped to become Northern Ireland's Health Minister during a mid term reshuffle of DUP Ministers. However, this failed to be realised as many within his party thought him too gaffe prone to hold the position. He continued to court controversy over his views on abortion, gay rights and Pride marches. Wells stated in 2012 that abortion in Northern Ireland should remain illegal except in medical emergencies, without exception for pregnancies resulting from rape.\n\nMany political commentators and critics had claimed that the gaffe prone MLA would not be offered the role in the near future because of the importance of implementing health reform known as \"Transforming your Care\". It was widely believed that the then Health Minister Edwin Poots was seen by his party as a safer pair of hands to handle the review. However, in an unexpected turn of events, the DUP leader Peter Robinson dismissed Edwin Poots and appointed Wells to the Health role in September 2014.\n\nOn 21 January 2015, Wells said he continues to support a ban on gay men donating blood. Such bans were lifted in the rest of the UK in 2011; Wells's department had spent £39,000 as of January 2015 fighting a legal appeal of the ban.\n\nIn 2015 he also said \"The gay lobby is insatiable, they don’t know when enough is enough\".\n\nOn 6 June 2018, Wells compared abortion rights to the Nazi Holocaust on BBC Radio Ulster's Nolan Show, describing the calls for Westminster to change Northern Ireland's abortion laws as a \"ghastly situation\". He would later go on to clarify that he only meant to make the comparison to the Holocaust in relation to the \"numbers\" involved. Arlene Foster responded to Wells comments by saying \"I think it's the wrong use of language\" when discussing a \"very emotive issue\".\n\nDuring a hustings event on 23 April 2015, Wells was quoted as saying, \"You don't bring a child up in a homosexual relationship. That the child is far more likely to be abused and neglected.\"\n\nIn an transcript released later, it showed that Wells had stated \"All evidence throughout the world says the best way to raise children is in a loving, stable, married relationship; the facts show that, the facts show that certainly you don't bring a child up in a homosexual relationship. That a child is far more likely to be abused or neglected (uproar among audience). I say again, I say again, a child is far more likely to be abused or neglected in a non-stable marriage situation, gay or straight.\"\n\nWells retracted the statement after a backlash from political leaders and the media. He claimed he was under pressure as a result of his wife's serious illness and that his view was not DUP policy. The views attracted strong criticism from other parties and calls for his resignation. On 24 April 2015, the Police Service of Northern Ireland confirmed that they had received a complaint and officers were making enquiries. The Public Prosecution Service later confirmed that Wells would not be charged. By mid October 2015 the Public Prosecution Service said it was decided that the case did not meet the test for prosecution.\n\nOn 25 April 2015, it was alleged that Wells, who was doing door-to-door canvassing, called at a lesbian couple's house and during a conversation was critical of their lifestyle. The PSNI said they had received three complaints regarding the conduct of an individual in Rathfriland near Newry on Saturday evening.\n\nOn Monday 27 April 2015, Wells announced his resignation as Health Minister, citing his wife's ill health. However, even DUP sympathetic press believed the real reason was down to his anti gay views.\n\nBy the end of Wells short tenure as Health minister little had changed and no major health reforms had been progressed. By July 2015, Wells was still stinging from his forced removal from health and stated that \"I should still be a Minister\".\n\nWells remains an MLA but has lost any significant powerbase within the DUP and now promotes his crusade to expose the truth about his resignation, stating on Belfast Live: “After four decades of work and dedication to the public I basically landed on the scrap heap because I felt I had to resign. I was abused and accused and it was all nonsense but for the sake of the DUP, I had to go, I had to sacrifice myself.\" \n\nApproaching the third anniversary of his sacking as Health Minister, Wells made allegations in the Belfast Telegraph in April 2018, that special advisors, the Press office and Leadership of the DUP reneged on a promise to re-instate him as health Minister. On Monday 9 April he appeared on BBC Talkback and lambasted the DUP leadership, Press office and special advisors. As a result of his attacks, the party withdrew the whip from Wells in May 2018. This reduced the DUP to 27 seats in the Assembly, the same number as Sinn Féin.\n"}
{"id": "18657", "url": "https://en.wikipedia.org/wiki?curid=18657", "title": "Labour law", "text": "Labour law\n\nLabour law (also known as labor law or employment law) mediates the relationship between workers, employing entities, trade unions and the government. Collective labour law relates to the tripartite relationship between employee, employer and union. Individual labour law concerns employees' rights at work and through the contract for work. are social norms (in some cases also technical standards) for the minimum socially acceptable conditions under which employees or contractors are allowed to work. Government agencies (such as the former US Employment Standards Administration) enforce labour law (legislative, regulatory, or judicial).\n\nLabour law arose in parallel with the Industrial Revolution as the relationship between worker and employer changed from small-scale production studios to large-scale factories. Workers sought better conditions and the right to join (or avoid joining) a labour union, while employers sought a more predictable, flexible and less costly workforce. The state of labour law at any one time is therefore both the product of, and a component of struggles between various social forces.\n\nAs England was the first country to industrialise, it was also the first to face the often appalling consequences of industrial revolution in a less regulated economic framework. Over the course of the late 18th and early to mid-19th century the foundation for modern labour law was slowly laid, as some of the more egregious aspects of working conditions were steadily ameliorated through legislation. This was largely achieved through the concerted pressure from social reformers, notably Anthony Ashley-Cooper, 7th Earl of Shaftesbury, and others.\n\nA serious outbreak of fever in 1784 in cotton mills near Manchester drew widespread public opinion against the use of children in dangerous conditions. A local inquiry, presided over by Dr Thomas Percival, was instituted by the justices of the peace for Lancashire, and the resulting report recommended the limitation of children's working hours. In 1802, the first major piece of labour legislation was passed − the Health and Morals of Apprentices Act. This was the first, albeit modest, step towards the protection of labour. The act limited working hours to twelve a day and abolished night work. It required the provision of a basic level of education for all apprentices, as well as adequate sleeping accommodation and clothing.\n\nThe rapid industrialisation of manufacturing at the turn of the 19th century led to a rapid increase in child employment, and public opinion was steadily made aware of the terrible conditions these children were forced to endure. The Factory Act of 1819 was the outcome of the efforts of the industrialist Robert Owen and prohibited child labour under nine years of age and limited the working day to twelve. A great milestone in labour law was reached with the Factory Act of 1833, which limited the employment of children under eighteen years of age, prohibited all night work and, crucially, provided for inspectors to enforce the law. Pivotal in the campaigning for and the securing of this legislation were Michael Sadler and the Earl of Shaftesbury. This act was an important step forward, in that it mandated skilled inspection of workplaces and a rigorous enforcement of the law by an independent governmental body.\n\nA lengthy campaign to limit the working day to ten hours was led by Shaftesbury, and included support from the Anglican Church. Many committees were formed in support of the cause and some previously established groups lent their support as well. The campaign finally led to the passage of the Factory Act of 1847, which restricted the working hours of women and children in British factories to effectively 10 hours per day.\n\nThese early efforts were principally aimed at limiting child labour. From the mid-19th century, attention was first paid to the plight of working conditions for the workforce in general. In 1850, systematic reporting of fatal accidents was made compulsory, and basic safeguards for health, life and limb in the mines were put in place from 1855. Further regulations, relating to ventilation, fencing of disused shafts, signalling standards, and proper gauges and valves for steam-boilers and related machinery were also set down.\n\nA series of further Acts, in 1860 and 1872 extended the legal provisions and strengthened safety provisions. Steady development of the coal industry, increasing association among miners, and increased scientific knowledge paved the way for the Coal Mines Act of 1872, which extended the legislation to similar industries. The same Act included the first comprehensive code of regulation to govern legal safeguards for health, life and limb. The presence of a more certified and competent management and increased levels of inspection were also provided for.\n\nBy the end of the century, a comprehensive set of regulations was in place in England that affected all industries. A similar system (with certain national differences) was implemented in other industrializing countries in the latter part of the 19th century and the early 20th century.\n\nThe basic feature of labour law in almost every country is that the rights and obligations of the worker and the employer are mediated through a contract of employment between the two. This has been the case since the collapse of feudalism. Many contract terms and conditions are covered by legislation or common law. In the US for example, the majority of state laws allow for employment to be \"at will\", meaning the employer can terminate an employee from a position for any reason, so long as the reason is not explicitly prohibited, and, conversely, an employee may quit at any time, for any reason (or for no reason), and is not required to give notice.\n\nOne example of employment terms in many countries is the duty to provide written particulars of employment with the \"essentialia negotii\" (Latin for \"essential terms\") to an employee. This aims to allow the employee to know concretely what to expect and what is expected. It covers items including compensation, holiday and illness rights, notice in the event of dismissal and job description.\n\nThe contract is subject to various legal provisions. An employer may not legally offer a contract that pays the worker less than a minimum wage. An employee may not agree to a contract that allows an employer to dismiss them for illegal reasons.\n\nMany jurisdictions define the minimum amount that a worker can be paid per hour. Algeria, Australia, Belgium, Brazil, Canada, China, France, Greece, Hungary, India, Ireland, Japan,South Korea, Luxembourg, the Netherlands, New Zealand, Paraguay, Portugal, Poland, Romania, Spain,Taiwan, the United Kingdom, the United States, Vietnam, Germany (in 2015) and others have laws of this kind. The minimum wage is set usually higher than the lowest wage as determined by the forces of supply and demand in a free market and therefore acts as a price floor. Each country sets its own minimum wage laws and regulations, and while a majority of industrialized countries has a minimum wage, many developing countries do not.\n\nMinimum wages are regulated and stipulated in some countries that lack explicit laws. In Sweden minimum wages are negotiated between the labour market parties (unions and employer organizations) through collective agreements that also cover non-union workers at workplaces with collective agreements. At workplaces without collective agreements there exist no minimum wages. Non-organized employers can sign substitute agreements directly with trade unions but far from all do. The Swedish case illustrates that in countries without statutory regulation will part of the labour market do not have regulated minimum wages, as self-regulation only applies to workplaces and employees covered by collective agreements (in Sweden about 90 per cent of employees).\n\nNational minimum wage laws were first introduced in the United States in 1938, Brazil in 1940 India in 1948, France in 1950 and in the United Kingdom in 1998. In the European Union, 18 out of 28 member states have national minimum wages as of 2011.\n\nThe living wage is higher than the minimum wage and is designed that a full-time worker would be able to support themselves and a small family at that wage.\n\nThe maximum number of hours worked per day or other time interval are set by law in many countries. Such laws also control whether workers who work longer hours must be paid additional compensation.\n\nBefore the Industrial Revolution, the workday varied between 11 and 14 hours. With the growth of industrialism and the introduction of machinery, longer hours became far more common, reaching as high as 16 hours per day.\n\nThe eight-hour movement led to the first law on the length of a working day, passed in 1833 in England. It limited miners to 12 hours and children to 8 hours. The 10-hour day was established in 1848, and shorter hours with the same pay were gradually accepted thereafter. The 1802 Factory Act was the first labour law in the UK.\n\nGermany was the next European country to pass labour laws; Chancellor Otto von Bismarck's main goal was to undermine the Social Democratic Party of Germany. In 1878, Bismarck instituted a variety of anti-socialist measures, but despite this, socialists continued gaining seats in the Reichstag. To appease the working class, he enacted a variety of paternalistic social reforms, which became the first type of social security. In 1883 the Health Insurance Act was passed, which entitled workers to health insurance; the worker paid two-thirds and the employer one-third of the premiums. Accident insurance was provided in 1884, while old age pensions and disability insurance followed in 1889. Other laws restricted the employment of women and children. These efforts, however, were not entirely successful; the working class largely remained unreconciled with Bismarck's conservative government.\n\nIn France, the first labour law was voted in 1841. It limited under-age miners' hours. In the Third Republic labour law was first effectively enforced, in particular after Waldeck-Rousseau 1884 law legalising trade unions. With the Matignon Accords, the Popular Front (1936–38) enacted the laws mandating 12 days each year of paid vacations for workers and the law limiting the standard workweek to 40 hours.\n\nOther labour laws involve safety concerning workers. The earliest English factory law was passed in 1802 and dealt with the safety and health of child textile workers.\n\nSuch laws prohibited discrimination against employees as morally unacceptable and illegal, in particular racial discrimination or gender discrimination.\n\nConvention no. 158 of the International Labour Organization states that an employee \"can't be fired without any legitimate motive\" and \"before offering him the possibility to defend himself\". Thus, on April 28, 2006, after the unofficial repeal of the French First Employment Contract, the Longjumeau (Essonne) \"conseil des prud'hommes\" (labour law court) judged the New Employment Contract contrary to international law and therefore \"illegitimate\" and \"without any juridical value\". The court considered that the two-years period of \"fire at will\" (without any legal motive) was \"unreasonable\", and contrary to convention.\n\nChild labour was not seen as a problem throughout most of history, only disputed with the beginning of universal schooling and the concepts of labourers' and children's rights. Use of child labour was commonplace, often in factories. In England and Scotland in 1788, about two-thirds of persons working in water-powered textile factories were children. Child labour can be factory work, mining or quarrying, agriculture, helping in the parents' business, operating a small business (such as selling food), or doing odd jobs. Children work as guides for tourists, sometimes combined with bringing in business for shops and restaurants (where they may also work). Other children do jobs such as assembling boxes or polishing shoes. However, rather than in factories and sweatshops, most child labour in the twenty-first century occurs in the informal sector, \"selling on the street, at work in agriculture or hidden away in houses — far from the reach of official inspectors and from media scrutiny.\"\n\nCollective labour law concerns the relationship between employer, employee and trade unions. Trade unions (also \"labor unions\" in the US) are organizations which generally aim to promote the interests of their members.\n\nTrade unions are organized groups of workers who engage in collective bargaining with employers. Some countries require unions and/or employers to follow particular procedures in pursuit of their goals. For example, some countries require that unions poll the membership to approve a strike or to approve using members' dues for political projects. Laws may govern the circumstances and procedures under which unions are formed. They may guarantee the right to join a union (banning employer discrimination), or remain silent in this respect. Some legal codes allow unions to obligate their members, such as the requirement to comply with a majority decision in a strike vote. Some restrict this, such as \"right to work\" legislation in parts of the United States.\n\nIn the different organization in the different countries trade union discuses with the employee on behalf of employer. At that time trade union discussed or talk with the manpower of the organization. At that time trade union perform his role like a bridge between the employee and employer.\n\nA legally binding right for workers as a group to participate in workplace management is acknowledged in some form in most developed countries. In a majority of EU member states (for example, Germany, Sweden, and France) the workforce has a right to elect directors on the board of large corporations. This is usually called \"codetermination\" and currently most countries allow for the election of one third of the board, though the workforce can have the right to elect anywhere from a single director, to just under a half in Germany. \nHowever, German company law uses a split board system, in which a \"supervisory board\" appoints an \"executive board\". Under the Mitbestimmunggesetz 1976, shareholders and employees elect the supervisory board in equal numbers, but the head of the supervisory board with a casting vote is a shareholder representative. The first statutes to introduce board level codetermination were in Britain, however most of these measures, except in universities, were removed in 1948 and 1979. The oldest surviving statute is found in the United States, in the Massachusetts Laws on manufacturing corporations, introduced in 1919, however this was always voluntary.\n\nIn the United Kingdom, similar proposals were drawn up, and a command paper produced named the Bullock Report (Industrial democracy) was released in 1977 by the James Callaghan Labour Party government. Unions would have directly elected half of the board. An \"independent\" element would also be added. However, the proposal was not enacted. The European Commission offered proposals for worker participation in the \"fifth company law directive\", which was also not implemented.\n\nIn Sweden, participation is regulated through the \"Law on board representation\". The law covers all private companies with 25 or more employees. In these companies, workers (usually through unions) have a right to appoint two board members and two substitutes. If the company has more than 1,000 employees, this rises to three members and three substitutes. It is common practice to allocate them among the major union coalitions.\n\nWorkplace statutes in many countries require that employers consult their workers on various issues.\n\nStrike action is the worker tactic most associated with industrial disputes. In most countries, strikes are legal under a circumscribed set of conditions. Among them may be that:\n\nA boycott is a refusal to buy, sell, or otherwise trade with an individual or business. Other tactics include go-slow, sabotage, work-to-rule, sit-in or en-masse not reporting to work. Some labour law explicitly bans such activity, none explicitly allows it.\n\nPicketing is often used by workers during strikes. They may congregate near the business they are striking against to make their presence felt, increase worker participation and dissuade (or prevent) strike breakers from entering the workplace. In many countries, this activity is restricted by law, by more general law restricting demonstrations, or by injunctions on particular pickets. For example, labour law may restrict secondary picketing (picketing a business connected with the company not directly with the dispute, such as a supplier), or flying pickets (mobile strikers who travel to join a picket). Laws may prohibit obstructing others from conducting lawful business; outlaw obstructive pickets allow court orders to restrict picketing locations or behaving in particular ways (shouting abuse, for example).\n\nThe labour movement has long been concerned that economic globalization would weaken worker bargaining power, as their employers could hire workers abroad to avoid domestic labour standards. Karl Marx said:\n\nThe International Labour Organization and the World Trade Organization have been a primary focus among international bodies for regulating labour markets. Conflicts arise when people work in more than one country. EU law has a growing body of workplace rules.\n\nFollowing World War One, the Treaty of Versailles contained the first constitution of a new International Labour Organization (ILO) founded on the principle that \"labour is not a commodity\", and for the reason that \"peace can be established only if it is based upon social justice\". ILO's primary role has been to coordinate international labour law by issuing Conventions. ILO members can voluntarily adopt and ratify the Conventions. For instance, the first Hours of Work (Industry) Convention, 1919 required a maximum of a 48-hour week, and has been ratified by 52 out of 185 member states. The UK ultimately refused to ratify the Convention, as did many current EU members, although the Working Time Directive adopts its principles, subject to individual opt-out. ILO's constitution comes from the 1944 Declaration of Philadelphia and under the 1998 Declaration on Fundamental Principles and Rights at Work classified eight conventions as core.\n\nThese require freedom to join a union, bargain collectively and take action (Conventions No. 87 and 98), abolition of forced labour (29 and 105), abolition of labour by children before the end of compulsory school (138 and 182), and no discrimination at work (No. 100 and 111). Member compliance with the core Conventions is obligatory, even if the country has not ratified the Convention in question. To ensure compliance, the ILO is limited to gathering evidence and reporting on member states' progress, relying on publicity to create pressure to reform. Global reports on core standards are produced yearly, while individual reports on countries who have ratified other Conventions are compiled on a bi-annual or less frequent basis.\nBecause the ILO's enforcement mechanisms are weak, incorporating labour standards in the World Trade Organization's (WTO) operation has been proposed. WTO oversees, primarily, the General Agreement on Tariffs and Trade treaty aimed at reducing customs, tariffs and other barriers to import and export of goods, services and capital between its 157 member countries. Unlike for the ILO, contravening WTO rules as recognized by the dispute settlement procedures opens a country to retaliation through trade sanctions. This could include reinstatement of targeted tariffs against the offender.\n\nProponents have called for a \"social clause\" to be inserted into the GATT agreements, for example, by amending Article XX, which provides an exception that allows imposition of sanctions for breaches of human rights. An explicit reference to core labour standards could allow comparable action where a WTO member state breaches ILO standards. Opponents argue that such an approach could undermine labour rights, because industries, and therefore workforces could be harmed with no guarantee of reform. Furthermore, it was argued in the 1996 Singapore Ministerial Declaration 1996 that \"the comparative advantage of countries, particularly low-age developing countries, must in no way be put into question.\" Some countries want to take advantage of low wages and fewer rules as a comparative advantage to boost their economies. Another contested point is whether business moves production from high wage to low wage countries, given potential differences in worker productivity. Since GATT, most trade agreements have been bilateral. Some of these protect core labour standards. Moreover, in domestic tariff regulations, some countries give preference to countries that respect core labour rights, for example under the EC Tariff Preference Regulation, articles 7 and 8.\n\nConflicts of laws (or private international law) issues arise where workers work in multiple jurisdictions. If a US worker performs part of her job in Brazil, China and Denmark (a \"peripatetic\" worker) an employer may seek to characterize the employment contract as governed by the law of the country where labour rights are least favourable to the worker, or seek to argue that the most favourable system of labour rights does not apply. For example, in a UK labour law case, \"Ravat v Halliburton Manufacturing and Services Ltd\" Ravat was from the UK but was employed in Libya by a German company that was part of Halliburton. He was dismissed by a supervisor based in Egypt. He was told he would be hired under UK law terms and conditions, and this was arranged by a staffing department in Aberdeen. Under the UK Employment Rights Act 1996 he would have a right to claim unfair dismissal, but the Act left open the question of the statute's territorial scope. The UK Supreme Court held that the principle would be that an expatriate worker, would be subject to UK rules if the worker could show a \"close connection\" to the UK, which was found in Rabat's case.\n\nThis fits within the general framework in the EU. Under EU Rome I Regulation article 8, workers have employment rights of the country where they habitually work. They may have a claim in another country if they can establish a close connection to it. The Regulation emphasises that the rules should be applied with the purpose of protecting the worker.\n\nIt is also necessary that a court has jurisdiction to hear a claim. Under the Brussels I Regulation article 19, this requires the worker habitually works in the place where the claim is brought, or is engaged there.\n\nThe European Union has extensive labour laws that officially exclude (according to the Treaty on the Functioning of the European Union) matters around direct wage regulation (e.g. setting a minimum wage), fairness of dismissals and collective bargaining. A series of Directives regulate almost all other issues, for instance the Working Time Directive guarantees 28 days of paid holiday, the Equality Framework Directive prohibits all forms of discrimination and the Collective Redundancies Directive requires that proper notice is given and consultation takes place on decisions about economic dismissals.\n\nHowever, the European Court of Justice has recently extended the Treaties provisions via case law. Trade unions have sought to organize across borders in the same way that multinational corporations have organized production globally. Unions have sought to take collective action and strikes internationally. However, this coordination was challenged in the European Union in two controversial decisions. In \"Laval Ltd v Swedish Builders Union\" a group of Latvian workers were sent to a construction site in Sweden. The local union took industrial action to make Laval Ltd sign up to the local collective bargaining agreement. Under the Posted Workers Directive, article 3 lays down minimum standards for foreign workers so that workers receive at least the minimum rights that they would have in their home country in case their place of work has lower minimum rights. Article 3(7) says that this \"shall not prevent application of terms and conditions of employment which are more favourable to workers\". Most people thought this meant that more favourable conditions could be given than the minimum (e.g., in Latvian law) by the host state's legislation or a collective agreement. However the European Court of Justice (ECJ) said that only the local state could raise standards beyond its minimum for foreign workers. Any attempt by the host state, or a collective agreement (unless the collective agreement is declared universal under article 3(8)) would infringe the business' freedom under TFEU article 56. This decision was implicitly reversed by the European Union legislature in the Rome I Regulation, which makes clear in recital 34 that the host state may allow more favourable standards. However, in \"The Rosella\", the ECJ held that a blockade by the International Transport Workers Federation against a business that was using an Estonian flag of convenience (i.e., saying it was operating under Estonian law to avoid labour standards of Finland) infringed the business' right of free establishment under TFEU article 49. The ECJ said that it recognized the workers' \"right to strike\" in accordance with ILO Convention 87, but said that its use must be proportionately to the right of the business' establishment.\n\nThe Fair Work Act of 2009 provides the regulations governing Australian workplaces and employers. Australia has a minimum wage and workplace conditions overseen by the Fair Work Commission.\n\nIn Canadian law, \"labour law\" refers to matters connected with unionized workplaces, while \"employment law\" deals with non-unionized employees.\n\nIn 2017, Premier Brad Wall announced that Saskatchewan's government is to cut 3.5 percent from its workers and officers' wages in 2018. This salary cut includes MLA ministers and the Premier's office staff along all people employed by the government. Unpaid days off, will also be implemented as well as limiting overtime to assist the wage cut.\n\nIn the People's Republic of China the basic labour laws are the \"Labour Law of People's Republic of China\" (promulgated on 5 July 1994) and the \"Labour Contract Law of the People's Republic of China\" (adopted at the 28th Session of the Standing Committee of the 10th National People's Congress on June 29, 2007, effective from January 1, 2008). The administrative regulations enacted by the State Council, the ministerial rules and the judicial explanations of the Supreme People's Court stipulate detailed rules concerning various aspects of employment. The government-controlled All China Federation of Trade Unions is the sole legal labour union. Strikes are formally legal, but in practice are discouraged.\n\nIn France, the first labour laws were Waldeck Rousseau's laws passed in 1884. Between 1936 and 1938 the Popular Front enacted a law mandating 12 days (2 weeks) each year of paid vacation for workers, and a law limited the work week to 40 hours, excluding overtime. The negotiated on May 25 and 26th in the middle of the May 1968 crisis, reduced the working week to 44 hours and created trade union sections in each enterprise. The minimum wage was increased by 25%. In 2000, Lionel Jospin's government enacted the 35-hour workweek, reduced from 39 hours. Five years later, conservative prime minister Dominique de Villepin enacted the New Employment Contract (CNE). Addressing the demands of employers asking for more flexibility in French labour laws, the CNE sparked criticism from trade unions and opponents claiming it favoured contingent work. In 2006, he then attempted to pass the First Employment Contract (CPE) through a vote by emergency procedure, but that was met by students and unions' protests. President Jacques Chirac finally had no choice but to repeal it.\n\nOver fifty national and many more state-level laws govern work in India. So for instance, a permanent worker can be terminated only for proven misconduct or habitual absence. In the Uttam Nakate case, the Bombay High Court held that dismissing an employee for repeated sleeping on the factory floor was illegal – the decision was overturned by the Supreme Court of India two decades later. In 2008, the World Bank criticized the complexity, lack of modernization and flexibility in Indian regulations.\n\nIran has not ratified the two basic Conventions of the International Labour Organization on freedom of association and collective bargaining and one abolishing child labour.\n\nMexican labour law reflects the historic interrelation between the state and the Confederation of Mexican Workers. The confederation is officially aligned with the Institutional Revolutionary Party (the Institutional Revolutionary Party, or PRI). While the law promises workers the right to strike and to organize, in practice it is difficult or impossible for independent unions to organize.\n\nIn Sweden many workplace issues such as working hours, minimum wage and right to overtime compensation are regulated through collective bargaining agreements in accordance with the Swedish model of \"self-regulation\", i.e. regulation by the labour market parties themselves in contrast to \"state regulation\" (labour laws). A notable exception is the Employment Protection act which regulates employment contracts and extensive employees' rights to employment under certain conditions.\n\nThe labour law of Switzerland covers all standards governing the employment of some kind. The regulation of the employment by private employers is largely harmonized at the federal level, while public-sector employment still prevails a variety of cantonal laws. In particular, the civil standardization is distributed to a variety of laws. Of greater importance, particularly the new Federal Constitution of 1999, the Code of Obligations , the Labour Code as well as in the public sector, the Federal Personnel Act.\n\nThe Factory Acts (first one in 1802, then 1833) and the 1823 Master and Servant Act were the first laws regulating labour relations in the United Kingdom. Most employment law before 1960 was based upon the Law of Contract. Since then there has been a significant expansion primarily due to the \"equality movement\" and the European Union. Laws are either Acts of Parliament called Statutes, Statutory Regulations (made by a Secretary of State under an Act of Parliament) or Case Law (developed by various courts).\n\nThe first significant expansion was the Equal Pay Act of 1970. This act was introduced to bring about pay equality for women in the workplace. Since 1997, changes in UK employment law include enhanced maternity and paternity rights, the introduction of a National Minimum Wage and the Working Time Regulations, which covers working time, rest breaks and the right to paid annual leave. Discrimination law has been tightened, with protection from discrimination now available on the grounds of age, religion or belief and sexual orientation as well as gender, race and disability.\n\nThe Fair Labor Standards Act of 1938 set the maximum standard work week to 44 hours. In 1950 this was reduced to 40 hours. A green card entitles immigrants to work, without requirement a separate work permit. Despite the 40-hour standard maximum work week, some lines of work require more than 40 hours. For example, farm workers may work over 72 hours a week, followed by at least 24 hours off. Exceptions to the break period exist for certain harvesting employees, such as those involved in harvesting grapes, tree fruits and cotton.\n\nProfessionals, clerical (administrative assistants), technical, and mechanical employees cannot be terminated for refusing to work more than 72 hours in a work week.\nThese ceilings, combined with a competitive job market, often motivate American workers to work more hours. American workers on average take the fewest days off of any developed country.\n\nThe Fifth and Fourteenth Amendments of the United States Constitution limit the power of the federal and state governments to discriminate. The private sector is not directly constrained by the Constitution, but several laws, particularly the Civil Rights Act of 1964, limit the private sector discrimination against certain groups. The Fifth Amendment has an explicit requirement that the Federal Government not deprive individuals of \"life, liberty, or property\", without due process of law and an implicit guarantee that each person receive equal protection of the law. The Fourteenth Amendment explicitly prohibits states from violating an individual's rights of due process and equal protection. Equal protection limits the State and Federal governments' power to discriminate in their employment practices by treating employees, former employees, or job applicants unequally because of membership in a group, like a race, religion or sex. Due process protection requires that employees have a fair procedural process before they are terminated if the termination is related to a \"liberty\", like the right to free speech, or a property interest.\n\nThe National Labor Relations Act, enacted in 1935 as part of the New Deal legislation, guarantees workers the right to form unions and engage in collective bargaining.\n\nThe Age Discrimination in Employment Act of 1967 prohibits employment discrimination based on age with respect to employees 40 years of age or older.\n\nTitle VII of the Civil Rights Act is the principal federal statute with regard to employment discrimination, prohibiting unlawful employment discrimination by public and private employers, labour organizations, training programmes and employment agencies based on race or colour, religion, sex and national origin. Retaliation is also prohibited by Title VII against any person for opposing any practice forbidden by statute, or for making a charge, testifying, assisting, or participating in a proceeding under the statute. The Civil Rights Act of 1991 expanded the damages available to Title VII cases and granted Title VII plaintiffs the right to jury trial.\n\nThe beginnings of halakhic labour law are in the Bible, in which two commandments refer to this subject: The law against delayed wages (Lev. 19:13; Deut. 24:14-15) and the worker's right to eat the employer's crops (Deut. 23:25-26). The Talmudic law—in which labour law is called \"laws of worker hiring\"—elaborates on many more aspects of employment relations, mainly in Tractate Baba Metzi'a. In some issues the Talamud, following the Tosefta, refers the parties to the customary law: \"All is as the custom of the region [postulates]\". \nModern halakhic labour law developed very slowly. Rabbi Israel Meir Hacohen (the Hafetz Hayim) interprets the worker's right for timely payment in a tendency that clearly favours the employee over the employer, but does not refer to new questions of employment relations. Only in the 1920s we find the first halakhic authority to tackle the questions of trade unions (that could easily be anchored in Talmudic law) and the right of strike (which is quite problematic in terms of Talmudic law). Rabbis A.I Kook and B.M.H. Uziel tend to corporatist settling of labour conflicts, while Rabbi Moshe Feinstein clearly adopts the liberal democratic collective bargaining model. Since the 1940s the halakhic literature on labour law was enriched by books and articles that referred to growing range of questions and basically adopted the liberal democratic approach.\n\n"}
{"id": "40229800", "url": "https://en.wikipedia.org/wiki?curid=40229800", "title": "Legitimacy of Israel", "text": "Legitimacy of Israel\n\nThe legitimacy of the State of Israel has been brought into question, specifically, whether Israel's political authority over the area it claims should be accepted as legitimate political authority. The argument as to the legitimacy of the State of Israel is also couched in terms of Israel's right to exist.\n\nIsrael has been a member of the United Nations since 11 May 1949, but a number of United Nations member states do not recognize Israel and question its legitimacy or right to exist. The campaign against the legitimacy of Israel is a campaign especially by some Palestinian and Arab leaders and groups for countries to deny or withdraw recognition of Israel.\n\nFrom an international relations perspective, Israel meets basic standards for legitimacy as a state.\n\n, 32 United Nations member states did not recognise the State of Israel: 18 of the 21 UN members in the Arab League: Algeria, Bahrain, Comoros, Djibouti, Iraq, Kuwait, Lebanon, Libya, Morocco, Oman, Qatar, Saudi Arabia, Somalia, Sudan, Syria, Tunisia, United Arab Emirates, and Yemen; a further 11 members of Organisation of Islamic Cooperation: Afghanistan, Bangladesh, Brunei, Chad, Guinea, Indonesia, Iran, Malaysia, Mali, Niger, and Pakistan; and Bhutan, Cuba, and North Korea. On the other hand, four members of the Arab League recognise Israel: Egypt, Jordan, Mauritania and Palestine; and most of the non-Arab members of Organisation of Islamic Cooperation also recognise Israel.\nIn the 1990s, Islamic and leftist movements in Jordan attacked the Israel–Jordan Treaty of Peace as legitimization. Significant minorities in Jordan see Israel as an illegitimate state, and reversing the normalization of diplomatic relations was central to Jordanian discourse.\n\nIn 2002 the Arab League unanimously adopted the Arab Peace Initiative at their Beirut summit. The comprehensive peace plan called for full normalization of Arab-Israeli relations in return for full Israeli withdrawal from the territories occupied in June 1967. Turki al-Faisal of Saudi Arabia said that in endorsing the initiative every Arab state had \"made clear that they will pay the price for peace, not only by recognising Israel as a legitimate state in the area, but also to normalise relations with it and end the state of hostilities that had existed since 1948.\"\n\nFollowing the Oslo I Accord, the Palestinian Authority and Israel conditionally recognized each other's right to govern specific areas of the country. This boosted Israel's legal authority and legitimacy on the international stage. Palestinian Authority leader Mahmoud Abbas, said while speaking at the UN regarding Palestinian recognition, \"We did not come here seeking to delegitimize a state established years ago, and that is Israel.\"\n\nHamas, in contrast, does not recognize Israel as a legitimate government. Furthermore, Hamas denies the legitimacy of the Oslo I Accord.\n\nEspecially in recent years, following the Palestinian legislative election of 2006 and Hamas' governance of the Gaza Strip, the term \"delegitimisation\" has been frequently applied to rhetoric surrounding the Israeli–Palestinian conflict.\n\nDelegitimization is seen by some observers to be a double standard which separates Israel from other legitimate nations which have imperfect government. Natan Sharansky, head of the Jewish Agency, discussed a 3D Test for determining new antisemitism. The third of the three D's is delegitimization. He explains \"when Israel's fundamental right to exist is denied – alone among all peoples in the world – this too is anti-Semitism.\"\n\nDore Gold, President of the Israeli Jerusalem Center for Public Affairs, believes there is a \"campaign to delegitimize Israel\" based on three themes, a \"denial of Israel's right to security\", \"portrayal of Israel as a criminal state\", and \"denial of Jewish history\". Elhanan Yakira, professor of philosophy at the Hebrew University of Jerusalem, also considers portrayal of Israel as \"criminal\" and denial of Jewish history, specifically the Holocaust, to be key to a delegitimizing narrative. Alan Dershowitz believes that other standard lines of argument include claims of Israel's \"colonial\" nature, a belief that statehood was not granted \"legally\", the apartheid analogy, and the necessity of a one-state solution. According to Irwin Cotler, the lopsided number of anti-Israel resolutions passed by the UN is an example of delegitimization.\n\nCanadian ex-Foreign Minister John Baird has characterized Israel’s delegitimization as the new antisemitism.\n\nM.J. Rosenberg, writing in the \"Los Angeles Times\", argued that the term \"delegitimization\" is a \"distraction\", whose purpose is to divert attention away from world opposition to the \"illegitimate\" occupation of the West Bank and blockade of the Gaza Strip, from the \"illegal\" settlements, and from \"the ever-louder calls for Israel to grant Palestinians equal rights\". He concludes that \"It's not the Palestinians who are delegitimizing Israel, but the Israeli government, which maintains the occupation. And the leading delegitimizer is Netanyahu, whose contemptuous rejection of peace is turning Israel into an international pariah.\"\n\nAccording to Gerald Steinberg writing for the Jerusalem Center for Public Affairs, attacks on Israel's legitimacy are a barrier to the Israeli–Palestinian peace process. Amos Yadlin, former head of Israeli intelligence said that \"delegitimization of Israel is a graver threat than war.\" Thomas Friedman, writing in the \"New York Times\", says \"for 100 years, through violence and delegitimization, Israelis and Palestinians have made sure that the other was never allowed to really feel at home in Israel.\" Delegitimization of the adversary, among all the psychological themes, is said to be \"one of the major detrimental forces that turns a conflict to be vicious and violent, while preventing its peaceful resolution.\"\nUS President Barack Obama said in a May 2011 speech \"for the Palestinians, efforts to delegitimize Israel will end in failure. Symbolic actions to isolate Israel at the United Nations in September won't create an independent state.\" In 2012, the president said, \"whenever an effort is made to delegitimize the State of Israel, my administration has opposed them.\" Irwin Cotler, former Canadian Attorney General, said that delegitimization is \"masked under the current discourse\". It is hidden in the anti-Israel resolutions passed by the UN, universal jurisdiction is \"often abused\" regarding Israel, it is \"laundered under the cover of human rights\", and is hidden behind the use of accusations of racism and apartheid.\n\nDelegitimization is seen as a threat to Israel's security. Demands for Israel to not enter into Gaza and defeat Hamas during Operation Pillar of Defense are characterized by David Schwartz as a \"delegitimization of Israel's right to defend itself.\" Tzipi Livni said that \"the threat of delegitimization intensifies other threats facing Israel, and limits our ability to protect ourselves.\"\n\nProfessor Emanuel Adler of the University of Toronto considers Israel as willing to accept a situation where its legitimacy may be challenged, because it sees itself as occupying a unique place in the world order. Stacie E. Goddard of Wellesley College argues that the legitimacy of Israeli historical narratives is used as a tool to secure territory.\n\n"}
{"id": "3357748", "url": "https://en.wikipedia.org/wiki?curid=3357748", "title": "Marxist Unification Movement", "text": "Marxist Unification Movement\n\nMarxist Unification Movement (in Catalan: \"Moviment d'Unificació Marxista\") was a political group in Catalonia, Spain. MUM was founded in 1977, during the Spanish transition to democracy, by a group that had left the Socialist Party of National Liberation of the Catalan Countries (PSAN) in 1976 and the \"Col·lectiu Combat\", a splinter group of the Catalan National Front (FNC).\n\nMUM differed from other radical Catalan separatists in its willingness to participate in the Spanish electoral process. In the 1977 elections, MUM formed part of the Popular Unity Candidature for Socialism (\"Candidatura d'Unitat Popular cap el Socialisme\"), which launched Salvador Casanova as its main candidate. After the elections, MUM merged with the Party of Labour of Catalonia (PTC) and formed the Catalan Workers Bloc (BCT).\n\n"}
{"id": "2915521", "url": "https://en.wikipedia.org/wiki?curid=2915521", "title": "NORM-UK", "text": "NORM-UK\n\nNORM-UK, currently operating as 15Square, is an English-registered charity concerned with the health of the human genitals, with a particular focus on the foreskin and the avoidance of unnecessary circumcision. It provides information about conservative treatments for conditions such as phimosis and frenulum breve, as well as advice regarding foreskin restoration for circumcised males. It also hosts and participates in conferences and symposia about genital health and integrity.\n\nThe charity co-operates, but is not affiliated, with other non-profit organisations, and it is a member of the International Coalition for Genital Integrity.\n\nNORM-UK was founded in 1994 by English physician Dr. John Warren. The original aim was to provide information to circumcised men about non-surgical foreskin restoration methods. The organisation quickly expanded its mission to provide information about all aspects of health related to the foreskin, penis, and genital area.\n\nIt is independent of any other organisation and it is regulated by the Charity Commission for England and Wales. It is registered with charity number 1072831 and with the stated objective: To advance the education of the public in all matters relating to circumcision and other forms of surgical alteration of the genitals including alternative treatments and offering information and advice on such matters.\n\nFemale genital mutilation, which is illegal in the United Kingdom, is also a concern of the charity.\n\nThe organisation currently trades under the name 15Square. If unfolded and laid out flat, a typical adult's foreskin would measure about 15 square inches.\n\n15Square publishes a quarterly journal, \"15 Squared\". The charity also publishes a number of pamphlets covering a range of issues such as care of an infant's foreskin, phimosis and tightness of the foreskin in general, and alternatives to circumcision as a remedy. 15Square's vice-chairman, Dr. Peter Ball, also produced a video, \"Restoration in Focus\".\n\nThe organisation's office is located in Stone, Staffordshire. David Smith serves as general manager and is the charity's only paid employee. There are also a number of volunteers who work in the office and remotely.\n\nThe board of trustees includes founder Dr. John Warren (chairman), Dr. Peter Ball (vice-chairman), Margaret Green (treasurer) and John Dalton (lead researcher and archivist).\n\nThe actor Alan Cumming and scientist Jack Cohen serve as patrons of the charity. The late Brian Sewell, art critic and writer, was also a patron.\n\n\n"}
{"id": "344873", "url": "https://en.wikipedia.org/wiki?curid=344873", "title": "Oath of allegiance", "text": "Oath of allegiance\n\nAn oath of allegiance is an oath whereby a subject or citizen acknowledges a duty of allegiance and swears loyalty to monarch or country. In republics, modern oaths specify allegiance to the country in general, or to the country's constitution. For example, officials in the United States, a republic, take an oath of office that includes swearing allegiance to the United States Constitution. However, in a constitutional monarchy, such as in the United Kingdom, Australia and other Commonwealth realms, oaths are sworn to the monarch. Armed forces typically require a military oath.\n\nIn feudal times a person would also swear allegiance to his feudal superiors. To this day the oath sworn by freemen of the City of London contains an oath of obedience to the Lord Mayor of the City of London.\n\nOaths of allegiance are commonly required of newly naturalised citizens (see Oath of Citizenship), members of the armed forces, and those assuming public (particularly parliamentary and judicial) office. Clergy in the Church of England are required to take an Oath of Supremacy acknowledging the authority of the British monarch.\n\nA typical example of an oath of allegiance is that sworn by Members of Parliament in the Netherlands:\n\nIn many Commonwealth realms all that is required is an oath to the monarch, and not the constitution or state. There have been moves in some of the realms to make the oath of citizenship sworn by new citizens refer to the country rather than the monarch. However, the oaths sworn by judges, members of parliament, etc., have not been changed. All of these moves have not succeeded as the Queen is the personification of the Canadian, British, or Australian state (or that of any other Commonwealth realm). Allegiance sworn to the monarch is the same as to the country, its constitution or flag. The New Zealand Oath of Allegiance still refers to the Queen of New Zealand. The European Court of Human Rights ruled in 1999 that the oath of allegiance to a reigning monarch is \"reasonably viewed as an affirmation of loyalty to the constitutional principles which support... the workings of representative democracy in the respondent State.\"\n"}
{"id": "46643279", "url": "https://en.wikipedia.org/wiki?curid=46643279", "title": "Operation Ruben", "text": "Operation Ruben\n\nOperation Ruben () was a police raid operation targeting suspected radical Islamists in the Republika Srpska, an entity of Bosnia and Herzegovina. It commenced on 6 May 2015, following an attack on a police station in Zvornik. Several people were arrested a week after the attack.\n\nOn 27 April 2015, local Nerdin Ibrić (born 1991), a radical Islamist, attacked a police station in Zvornik. He killed one police officer and wounded two others before he was shot dead by other police officers. Soon after Ibrić's two friends were arrested, the police expanded its investigation to include other radical Islamists, some of whom were also veterans of the Syrian Civil War. The police suspect that the village of Dubnica near Kalesija is one of the major gathering points of radical Islamists. Soon after the attack, Dodik met with Serbian President Tomislav Nikolić and Prime Minister Aleksandar Vučić, asking them for intelligence and counter-terrorism assistance.\n\nThe Interior Ministry spokesman Milan Salamandija said that the search was underway in 32 locations within Republika Srpska. Salamandija said those detained were suspected of having \"made supplies of weapons and explosives aimed at committing terrorist acts against the institutions of the Republika Srpska and their representatives\". He added that the suspects \"belong to radical movements, have fought in or returned from Syria, or were recruiters of jihadists. We found a certain amount of arms and ammunition, bulletproof vests, uniforms and propaganda material for recruitment.\"\n\nAt least 30 people, all of whom are ethnic Bosniaks, have been taken into custody by Republika Srpska police for suspected weapons smuggling. The mayor of Srebrenica called the operation a \"form of repression\" against Bosnian Muslims in Republika Srpska.\n\nBakir Izetbegović, incumbent Bosniak member of the Presidency of Bosnia and Herzegovina heavily criticised the Republika Srpska police for the operation, saying that they were proceeding to \"unnecessary\" detentions: \"They are acting excessively. Police have seriously crossed the line.\" Izetbegović also said that the RS Serb police have \"overstepped their authority\".\n\nNermin Nikšić said that the terrorist attack on the police station in Zvornik is being used as justification for the persecution of Bosniak returnees in the Republika Srpska. He added: \"It is scandalous that 20 years after the war, those in power in Republika Srpska act as in the time when Radovan Karadžić criminally created this entity. We in the SDP believe the actions of the Republika Srpska police directly violate the Dayton Peace Agreement, which guarantees free return of all people in the pre-war places of residence.\"\n\nThe Mayor of Srebrenica Ćamil Duraković said that the Serb police stormed the homes of Bosniaks who returned after the war to homes they were expelled from in the war, and carried out arrests without explanation. He called it a \"form of repression.\"\n\n"}
{"id": "8509805", "url": "https://en.wikipedia.org/wiki?curid=8509805", "title": "Oregon Defense of Marriage Coalition", "text": "Oregon Defense of Marriage Coalition\n\nThe Defense of Marriage Coalition (sometimes styled Oregon Defense of Marriage Coalition to distinguish itself from similar organizations in other states) is a citizens' political organization support the definition of marriage as the union of one man and one woman. It was organized in 2004 by the Oregon Family Council as a campaign first to place Oregon Ballot Measure 36 (2004) before the voters by initiative petition, and then once signatures were collected, as a campaign for its passage. The organization formed a coalition of 1,500 churches and collected a record 244,000 signatures to place the amendment on the ballot.\n\n\n"}
{"id": "4801131", "url": "https://en.wikipedia.org/wiki?curid=4801131", "title": "Orwell Prize", "text": "Orwell Prize\n\nThe Orwell Prize, based at University College London, is a British prize for political writing of outstanding quality. Four prizes are awarded each year: one each for a fiction and non-fiction book on politics, one for journalism and one for 'Exposing Britain's Social Evils' (established 2015); between 2009 and 2012, a fifth prize was awarded for blogging. In each case, the winner is the short-listed entry which comes closest to George Orwell's own ambition to \"make political writing into an art\".\n\nIn 2014, the Youth Orwell Prize was launched, targeted at school years 9 to 13 in order to \"support and inspire a new generation of politically engaged young writers\". In 2015, The Orwell Prize for Exposing Britain's Social Evils, sponsored and supported by the Joseph Rowntree Foundation, was launched.\n\nBernard Crick founded the prize in 1993, using money from the royalties of the hardback edition of his biography of Orwell. Its sponsors are Orwell's adopted son Richard Blair, \"The Political Quarterly\", and A. M. Heath & Company. The Prize was formerly sponsored by the Media Standards Trust. Crick remained Chair of the judges until 2006; since 2007, the media historian Professor Jean Seaton has been the Director of the prize.\n\n\n\n\nBeginning with 2019, the Book prize was split into fiction and non-fiction categories.\n\n\n\n\n\n\nIn 2007, BBC's \"Newsnight\" programme was given a special award, the judges noting: \"When we were discussing the many very fine pieces of journalism that were submitted \"Newsnight\" just spontaneously emerged in our deliberations as the most precious and authoritative home for proper reporting of important stories, beautifully and intelligently crafted by journalists of rare distinction.\" In 2008, Clive James was given a special award. In 2009, Tony Judt was given a lifetime achievement award. A posthumous award was made to Christopher Hitchens in 2012, his book \"Arguably\" having been longlisted that year. In 2014, Jonathan Freedland was given a special award, after having been shortlisted for the Journalism Prize that year.\n\nIn 2008 the winner in the Journalism category was Johann Hari. In July 2011 the Orwell Prize Council decided to revoke Hari's award and withdraw the prize. Public announcement was delayed as Hari was then under investigation by \"The Independent\" for professional misconduct. In September 2011 Hari announced that he was returning his prize \"as an act of contrition for the errors I made elsewhere, in my interviews\", although he \"stands by the articles that won the prize\". A few weeks later, the Council of the Orwell Prize confirmed that Hari had returned the plaque but not the £2000 prize money, and issued a statement that one of the articles submitted for the prize, \"How multiculturalism is betraying women\", published by the Independent in April 2007, \"contained inaccuracies and conflated different parts of someone else's story (specifically, a report in Der Spiegel)\".\n\nHari did not initially return the prize money of £2000. He later offered to repay the money, but \"Political Quarterly\", responsible for paying the prize money in 2008, instead invited Hari to make a donation to English PEN, of which George Orwell was a member. Hari arranged with English PEN to make a donation equal to the value of the prize, to be paid in installments once Hari returned to work at The Independent. However, Hari did not return to work at The Independent.\n\n"}
{"id": "480738", "url": "https://en.wikipedia.org/wiki?curid=480738", "title": "Patrons of Industry", "text": "Patrons of Industry\n\nThe Patrons of Industry in Canada were based on the Patrons of Industry of Michigan that had formed in 1889. It was dedicated to upholding and encouraging the moral, social, intellectual, political and financial situation of farmers and to preserve the way of life that existed in farming communities in the late nineteenth century against encroaching industrialization. It cooperated with the urban labour movement to address the political frustrations of both groups with big business.\n\nThe Patrons' first appearance in Canada was The Grand Association of the Patrons of Industry in Ontario, founded in 1890. It declared itself independent of the U.S. group in 1891.\n\nAlthough centred in Ontario, the organization branched out into Manitoba (see Patrons of Industry in Manitoba), Alberta, Quebec and the Maritime provinces. The Patrons' membership exceeded 30,000 at its peak.\n\nIn the Maritimes, Duncan Marshall in 1895 established more than eighty lodges in Prince Edward Island alone. He also edited a Charlottetown weekly newspaper \"The Patron of Industry\". Moving into P.E.I. provincial politics by contesting a by-election seat in 1896 the organization was unable to break into the established two-party alignment in the province and was soundly defeated. Marshal left the province soon after the election (and would go on to be a cabinet minister in Alberta and in Ontario), and the movement in the region collapsed.\n\nThe Patrons ran candidates in the 1894 Ontario provincial election. Three Patrons of Industry candidates were elected, and 13 other members of the Legislative Assembly were elected with Patrons of Industry support—12 Liberals and one Conservative.\n\nThe Patrons of Industry ran 31 candidates (including three in Manitoba and one in Quebec) in the 1896 federal election (see below). Two, David Dickson Rogers and William Varney Pettet, were elected, Rogers by acclamation.\n\nThe party was soon divided on the question of cooperation with the Ontario Liberal Party, and the group was virtually extinct by 1900. Both Rogers and Pettet ran for re-election in the 1900 federal election but not under the Patrons banner.\n\nThe party achieved a few gains for farmers, such as institution of a cooling-off period to ban Ontario defeated politicians from holding office in government for one year after defeat and a cut in tariffs effected in 1894.\n\n\n\n"}
{"id": "53933290", "url": "https://en.wikipedia.org/wiki?curid=53933290", "title": "Pro-Emancipation Movement of Chilean Women", "text": "Pro-Emancipation Movement of Chilean Women\n\nPro-Emancipation Movement of Chilean Women () (often known as MEMCh or MEMCH) was both a historic women's rights organization, which pressed for equality between 1935 and 1953 and a current umbrella organization reorganized in 1983 to organize other women's organizations to provide unity in the struggle for the country to return to democracy. Once the dictatorship was overturned the NGO turned their focus to uniting organizations which pursue a broad spectrum of issues pertaining to women's rights and development.\n\nPro-Emancipation Movement of Chilean Women or MEMCh was created on 28 May 1935 by a group of mostly working class women, many of whom were members of or sympathizers with the Chilean Communist Party; however, their goal was to have broad membership representing all aspects of the nation. It was the first women's group formed in Chile with specific political goals and an organizational strategy to become a national organization, rather than a local club. The journal, \"\" () was created by the organization as a means of publishing their views on feminist issues. Its leadership was composed of some of Chile's pioneering feminists and include Elena Caffarena, Graciela Mandujano, Olga Poblete, and Marta Vergara, among others. Its first General Secretary and founder was Caffrena, who served in that capacity from 1935 to 1941. The organization was considered radical for its era, in that the women wanted full emancipation of their economic, civic and political spheres, recognizing that to attain those goals, radical changes must occur in all structures of society. Because the organization was heavily joined by working class women, they stressed the importance of equal pay and elimination of segregation which barred women's participation in certain jobs based on marital or other status. Related concerns were state-sponsored child care and maternity benefits, as well as the right of women to choose whether they would become mothers. Support for contraception and regulation of clandestine abortions, since therapeutic abortion was already legal, caused some parts of society to accuse MEMCh members of wanting to destroy the traditions of family. In \"memchistas\" (MEMCh members) view, they saw controlling one's biology as a part of women's family rights, including child support, inheritance, legitimacy, pension rights and others. While they strove for women's suffrage, attaining the vote was only one step toward increasing women's participation in the public sphere. MEMCh members focused their efforts on women's issues throughout the social spectrum including the families of the urban poor, middle classes and educated elites. Social issues MEMCh supported were the availability of sanitary, affordable housing; assistance for alcoholism; reform of women's prisons; and equal access to education.\n\nMEMCh was the first women's group to use mass mobilization through public events, held not only in Santiago but also in the provinces. They held rallies for votes and political freedom, and in favor of regulations dealing with the high unemployment and subsistence living; and others against a military pact between Chile and the United States, and sending Chilean troops to participate in the Korean War. MEMch developed an educational work, hosting schools for workers and job training courses, and created social service facilities to provide health care and legal advice. In the 1940s, the organization strongly opposed fascism, but rumors and actual links with communism of some of the feminists led to public defamation of several members and press which was critical of their objectives. MEMch joined the Popular Front and held two congresses (1937, 1940) to gather information from various sectors to create a platform which would address the issues that women faced. When Pedro Aguirre Cerda was elected as president, he agreed to introduce the issue of women's right to vote. In 1941, Caffarena and Flor Heredia drafted a proposal for consideration, but Cerdo died before it was introduced. In 1944, MEMCh organized a meeting held at the University of Chile in celebration of International Women's Day and that was followed by another congress, organized by Felisa Vergara. She brought together women from 200 different women's organizations, who agreed to align in an organization, ().\n\nFECHIF in turn backed the candidacy of María de la Cruz in 1946, but MEMCh adhered to the Popular Front candidate, Gabriel González Videla, believing that though charismatic, de la Cruz's vision was too narrow to support the needs of a wide constituency of women. After González Videla's election to the presidency in 1946, moderate members' relationships were strained by the anti-communist policies ushered in by the Cold War and the leftist leanings of many MEMch members. In 1949, having survived the government decision to outlaw the Communist Party and state harassment aimed at curtailing its activities, Chilean women gained universal suffrage. Membership turned their attention to pacifism and campaigns to protect children. The organization survived until 1953, when it was dissolved. Though specific reasons for the dissolution are unknown, the political polarization and MEMCh's refusal to exclude anyone for their political views and factionalism dividing the focus to interest groups were contributing factors.\n\nIn 1983, MEMCh83, named after the original organization, was founded founded by a broad spectrum of women's groups, some with feminist aims and others without feminist goals. The umbrella organization's purpose was to unite women's efforts in the restoration of democracy during the Chilean dictatorship of Augusto Pinochet. Initially the organization made no demands for women's rights, but when MEMCh83 organized its first mass mobilization on 28 November 1983, they expressed opposition to Pinochet and demanded peace and women's equality. In 1985, the organization was established as MEMch, under a non-governmental organizational structure. Since democracy was restored in 1988, the organization has focused on joining a broad coalition of Chilean NGOs in the advocacy of women's equality, which includes their reproductive and sexual rights, as well as all aspects of development.\n\n"}
{"id": "16939254", "url": "https://en.wikipedia.org/wiki?curid=16939254", "title": "Race in the United States criminal justice system", "text": "Race in the United States criminal justice system\n\nRace in the United States criminal justice system refers to the unique experiences and disparities in the United States in regard to the policing and prosecuting of various races. There have been different outcomes for different racial groups in convicting and sentencing felons in the United States criminal justice system. Experts and analysts have debated the relative importance of different factors that have led to these disparities. Minority defendants are charged with crimes requiring a mandatory minimum prison sentence more often, in both relative and absolute terms (depending on the classification of race, mainly in regards to Hispanics), leading to large racial disparities in correctional facilities.\n\nRace has been a factor in the United States criminal justice system since the system's beginnings, as the nation was founded on Native American soil. It continues to be a factor throughout United States history through the present.\n\nLynching and Lynch-Law date back to the 1700s when the term was first used by the Scotch-Irish in reference to an act pursued by the Quakers toward Native Americans. The law was originally regulatory, providing regulations regarding how lynching could and could not be carried out. Most crimes of and relating to lynching prior to 1830 were frontier crimes and were considered justifiable due to necessity.\n\nIn the construction of the United States Constitution in 1789, slavery and white supremacy were made part of the justice system, as citizens were defined as free white men.\n\nLynch law was renewed with the anti-slavery movement, as several acts of violence towards people of color took place in the early 1830s. In August 1831, Nat Turner led the slave insurrection in Virginia. Turner, an African-American Baptist preacher, believing that the Lord had destined him to free his race, followed through with his plans to conquer Southampton county through the enlistment of other slaves. He did so by traveling from house to house murdering every white person he could find. Due to this act, many innocent slaves were killed by the police.\n\nThe court decision in \"Dred Scott v. Sandford\" made it so that African slaves and their descendants were considered non-citizens, further incorporating racism into the justice system.\n\nWhen slavery was abolished after the Civil War through the ratification of the Thirteenth Amendment to the constitution, violence against African Americans increased tremendously and thousands of African Americans experienced lynching.\n\nDuring the same time period, unequal treaties towards Native Americans led to a large decrease in Native American land holdings, and Native Americans were forced into reservations.\n\nLatin Americans entering the country were also a target for the penal system during this time.\n\nThe Ku Klux Klan, was founded in 1865 in Pulaski, Tennessee as a vigilante organization whose goal was to keep control over freed slaves; It performed acts of lawlessness against negroes and other minorities. This included taking negro prisoners from the custody of officers or breaking into jails to put them to death. Few efforts were made by civil authorities in the South against the Ku Klux Klan.\n\nThe Memphis Riots of 1866 took place after many black men were discharged from the United States Army. The riot broke out when a group of discharged Negro soldiers got into a brawl with a group of Irish police officers in Memphis, Tennessee. Forty-six African Americans and two white people were killed in the riot, and seventy-five people received bullet wounds. At least five African American women were raped by predatory gangs, and the property damage was worth over $100,000.\n\nIn 1868 the Fourteenth Amendment to the United States Constitution overruled the 1857 Dred Scott v. Sandford by establishing that those born or naturalized in the United States are entitled to equal protection under the law, regardless of race.\n\nIn 1882 Congress passed the 1882 Chinese Exclusion Act, prohibiting Chinese laborers from immigrating into the United States. Senator James G. Blaine proposed the idea in 1879 in an effort to prohibit the Chinese from taking over the Pacific slope and avoid the possibility of another civil war.\n\nIn its 1896 ruling, \"Plessy v. Ferguson\", the United States Supreme Court established that segregation was legal in the United States, establishing the doctrine, \"separate but equal\". Homer Adolph Plessy was removed from the East Louisiana Railroad train and arrested for violating the Jim Crow Car Act of 1890 on June 7, 1892. Despite the Supreme Court ruling against him, Plessy's case marked the first use of the 14th Amendment's Equal Protection provision after the Reconstruction Period.\n\nIn 1935 the United States Supreme Court overturned convictions of the Scottsboro Boys in \"Norris v. Alabama\". These were nine African American teenagers who had been previously denied equal protection under the law as stated in the Fourteenth Amendment to the United States Constitution because African Americans were purposely excluded from their cases' juries.\n\nPresident Franklin D. Roosevelt established the Fair Employment Practices Commission with Executive Order 8802, which banned discrimination based on race, color, religion, or national origin in the defense industry.\n\nIn the 1954 \"Brown v. Board of Education\", the United States Supreme Court decision overturned the \"separate but equal\" doctrine implemented in the 1896 Plessy v. Ferguson case in schools and required that schools be integrated. The case was brought before the Court in 1952 after African American Oliver Brown tried to enroll his daughter Linda in a local white elementary school and was refused enrollment. He and other African American parents, with the help of the NAACP sued the Topeka school district, and Thurgood Marshall argued before the Supreme Court in 1952 and 1953 that public school segregation violated the 14th Amendment. The Court decision was unanimous.\n\nEmmett Till, 14-year-old African American boy in Mississippi was murdered for allegedly flirting with a white woman. His mother's insistence on an open-casket funeral led to the publishing of images of his mutilated body in many newspapers and magazines to showcase the scrutiny of the Mississippi criminal justice system in the 1950s and 1960s.\n\nIn the 1960 case of \"Boynton v. Virginia\", the United States Supreme Court ruled that racial segregation in public interstate transportation facilities such as bus or train stations violates the Interstate Commerce Act.\n\nIn 1963 16th Street Baptist Church was bombed, killing four African American girls and bringing attention to the need for increased civil rights protection in the United States Legislature. In 2002, nearly 40 years later, Bobby Frank Cherry was the last person brought to trial for the murder of the four girls.\n\nThe Civil Rights Act of 1964, prohibited discrimination based on race, color, religion, sex, or national origin in employment or public accommodations. It also overruled all state and local laws that mandated such discrimination.\n\nIn the 1965 riot in Watts, Los Angeles, an African American Neighborhood, 16,000 policemen, highway patrolmen, and National Guard troops were forced to restore order. The riot lasted for six days and resulted in property damages worth 40 million dollars. It started when an African American man by the name of Marquette Fry was pulled over by the police for suspicion of driving while under the influence of alcohol, after which tension grew between onlookers and police officers fusing the resulting violence.\n\nIn the Voting Rights Act of 1965, poll taxes, literacy tests, and other impediments formerly used to prevent African Americans from voting were prohibited.\n\nThe first U.S. law that restricted the distribution and use of certain drugs was the Harrison Narcotics Tax Act of 1914. The first local laws came as early as 1860.\n\nThe Federal Bureau of Narcotics was established in the United States Department of the Treasury by an act of June 14, 1930 (46 Stat. 585).\n\nIn 1935, President Franklin D. Roosevelt publicly supported the adoption of the Uniform State Narcotic Drug Act. \"The New York Times\" used the headline \"Roosevelt Asks Narcotic War Aid\".\n\nIn 1937, the Marijuana Transfer Tax Act was passed. Several scholars have claimed that the goal was to destroy the hemp industry, largely as an effort of businessmen Andrew Mellon, Randolph Hearst, and the Du Pont family. These scholars argue that with the invention of the decorticator, hemp became a very cheap substitute for the paper pulp that was used in the newspaper industry. These scholars believe that Hearst felt that this was a threat to his extensive timber holdings. Mellon, United States Secretary of the Treasury and the wealthiest man in America, had invested heavily in the DuPont's new synthetic fiber, nylon, and considered its success to depend on its replacement of the traditional resource, hemp. However, there were circumstances that contradict these claims. One reason for doubts about those claims is that the new decorticators did not perform fully satisfactorily in commercial production. To produce fiber from hemp was a labor-intensive process if you include harvest, transport and processing. Technological developments decreased the labor with hemp but not sufficient to eliminate this disadvantage.\n\nAlthough Nixon declared \"drug abuse\" to be public enemy number one in 1971, the policies that his administration implemented as part of the Comprehensive Drug Abuse Prevention and Control Act of 1970 were a continuation of drug prohibition policies in the U.S., which started in 1914.\n\nIn 1982, the current President of the United States, Ronald Reagan, officially declared war on drugs. The President increased federal spending on anti-drug related programs. He also greatly increased the number of United States federal drug task forces. Ensuring a lasting impact, Reagan also launched a campaign marked by rhetoric that both demonized drugs and drug users. The United States Executive branch employed two types of anti-drug strategies during The War on Drugs: supply-reduction and demand-reduction. Supply-reduction strategies typically involved limiting access to drug sources and employing harsher penalties for drug possession and distribution. Demand-reduction strategies included drug use treatment and prevention. The Reagan administration favored supply-reduction strategies and focused their efforts on the seizure of illegal substances and prosecution of individuals caught in possession of these substances.\n\nThe controversy surrounding The War on Drugs is still widely debated by the academic community. In March 2016, former Nixon domestic policy chief John Ehrlichman told a writer for Harper's magazine that \"the Nixon campaign in 1968, and the Nixon White House after that, had two enemies: the antiwar left and black people\". He then went on to elaborate further, saying: \"knew we couldn't make it illegal to be either against the war or black, but by getting the public to associate the hippies with marijuana and blacks with heroin. And then criminalizing both heavily, we could disrupt those communities\". This recent comment by Ehrlichman made headlines primarily because it was the first instance of any person who was ever affiliated with the Presidential administration publicly framing the drug war as a political tactic to assist Nixon's win.\nMany scholars believe that The War on Drugs had a large impact on minority communities across the nation. In particular, African American communities were affected by the political implications of the new drug policies. It has been noted that throughout The War of Drugs, African Americans were investigated, detained, arrested, and charged with using, possessing, and distributing illegal drugs at a level disproportionate to that of the general population.\n\nWilliam J. Bennett, John J. Dilulio, Jr., and John P. Walters' moral poverty theory counter argues that the increase in juvenile crime and drug use during the 1980s and 1990s is due to children's lack of adult role models in their upbringing, such as parents, teachers, and guardians. They argue that children born out of wedlock are more likely to commit crimes, and they use this argument to explain the higher rate of crime for African American youth compared to that of white youth in the United States.\n\nAccording to the United States Bureau of Justice, in 2014 6% of all black males ages 30 to 39 were in prison, while 2% of Hispanic and 1% of white males in the same age group were in prison. There were 2,724 black male prisoners with sentences over one year per 100,000 black male residents in the United States, and a total of 516,900 black male sentenced prisoners in the United States as of December 31, 2014. This compares to 1,091 Hispanic male prisoners per 100,000 Hispanic male residents, and 465 white male prisoners per 100,000 white male residents in the United States at that time. Black males between the ages of 18 and 19 had a rate of imprisonment 10.5 times that of white males of the same age group in 2014. Studies have found that a decreasing percentage of the overrepresentation of blacks in the U.S. criminal justice system can be explained by racial differences in offending: 80% in 1979, 76% in 1991, and 61% in 2004.\n\nA 2013 study found that the increased likelihood of African American males of being arrested and incarcerated than white males was entirely accounted for by adjusting for both self-reported violence and IQ. According to a report by the National Council of La Raza, research obstacles undermine the census of Latinos in prison, and \"Latinos in the criminal justice system are seriously undercounted.\" A study regarding the Violent Crime Control and Law Enforcement Act concluded due to mandatory sentencing blacks have a 1 in 3 chance of spending some time in prison or jail. Latinos 1 in 6 chance and whites, a 1 in 17.\n\nA 2016 study from the American Psychological Association, \"Discrimination and Instructional Comprehension\", researched how the lack of comprehension of capital penalty jury instructions, relates to death sentencing in America. This study was composed of eligible subjects, who were given the option to sentence a verdict based on their comprehension from the given instructions and their evidence. The study concluded that multiple verdicts who could not comprehend the penalty instructions, had a higher death sentence probability.\n\nVarious scholars have addressed what they perceived as the systemic racial bias present in the administration of capital punishment in the United States. There is also a large disparity between races when it comes to sentencing convicts to Death Row. The federal death penalty data released by the United States Department of Justice between 1995–2000 shows that 682 defendants were sentenced to death. Out of those 682 defendants, the defendant was black in 48% of the cases, Hispanic in 29% of the cases, and white in 20% of the cases. 52.5% of people who committed homicides in the 1980-2005 time period were black.\n\nTwo competing hypotheses exist regarding why racial/ethnic minorities, especially African Americans, are overrepresented in the criminal justice system compared to their share of the general population.. These are the differential offending or differential involvement hypothesis, which proposes that this overrepresentation is a result of African Americans committing more of the crimes that result in criminal justice processing, and the differential selection hypothesis, which proposes that this disproportionality is a result of discrimination by the criminal justice system. Piquero (2008) argues that it is difficult, if not impossible, to determine which of these factors is more important than the other.\n\nThe criminal justice system in the United States has a staggering imbalance in the composition of races, specifically between blacks and whites, incarcerated. Alfred Blumstein states, \"Although blacks comprise roughly one-eighth of the population, they represent about one-half of the prison population. Thus, the race-specific incarceration rates are grossly disproportionate.\" The research done by Alfred Blumstein and the apparent dis-proportionality raise the problem of injustice within the United States criminal justice system. This injustice is alluded to further, but not directly linked to racial injustice, because black males are the victims of having an incarceration rate twenty five times higher than that of the total population.\n\nEducation may also be a factor that plays into this dis-proportionality. Studies done from 1965 to 1969 based on administrative data, surveys, and census data showed that 3 percent of whites and 20 percent of blacks served time in prison by their early thirties. Thirty years later in 1999, risk of incarceration was partially dependent on education with 30 percent of college dropouts and roughly 60 percent of high school dropouts going to prison. Education playing a role in either increasing or decreasing the likelihood of incarceration based upon the education and skill a person possesses.\n\nIn the United States, racial disparities in the juvenile justice system are partly, but not entirely, due to racial differences in offending; differences in treatment by the justice system also appear to play a role.\n\nA 1994 study found that black and Hispanic youths were more likely to be detained at each of the three stages of the juvenile justice system examined (police detention, court intake detention, and preliminary hearing detention), even after controlling for other factors such as offense seriousness. Other studies have reached similar conclusions. A 2014 study looking at juvenile dispositional decisions found that minority juveniles were more likely than their white counterparts to be committed to physical regimen-oriented facilities than their white counterparts were, which the authors suggested was due to court actors using \"a racialized perceptual shorthand of youthful offenders that attributes both higher levels of blame and lower evaluations of reformability to minority youth.\" Research suggests the racial disparities in assessments of juvenile offenders, and the resulting sentence recommendations, result from officials attributing different causes of crime to cases based on the race of the offender. According to a 1982 study, racial bias in juvenile justice decisions is more pronounced in police decisions than in judicial ones.\n\nBlack and Latino juvenile offenders are also vastly more likely to be tried as adults by local prosecutors throughout the US, and are generally likelier to be given harsher, longer sentences by the judges presiding over their trials.\n\nA study of New Jersey juvenile court records for the years 2010-2015 released by WNYC late in 2016 found that black and Latino offenders comprised almost 90% of juveniles tried as adults (849 black youths, 247 Latino out of a total of 1,251 juveniles tried as adults during the five-year period, thereby black/Hispanic teens represented 87.6% of the total cases.) WNYC also surveyed all NJ inmates currently serving sentences which resulted from crimes committed as a minor, and found that 93% of them are black or Latino. These numbers represent a clear racial disparity in sentencing, particularly so, given the fact that during this period New Jersey was only 14.8% Black and 19.7% Hispanic, in comparison to 56.2% of the state's residents being white.\n\"Controlling for nature of offense...for family background...for educational history—all of the things that go into a prosecutor's decision, there are still disparities, significant disparities, that cannot be explained by anything other than race,\" says Laura Cohen, the director of the Criminal and Youth Justice Clinic at Rutgers Law School.\n\nThese numbers are comparable to the juvenile detention and sentencing trends for the country as a whole, analysis of which shows that roughly 60% of all juveniles who received life sentences after being tried as adults are black. Judges, prosecutors, juries, and police/detention officers all commonly perceive black children as less innocent and childlike than white children. Black teens are commonly over-estimated in age by an average of 4.5 years, meaning that black boys as young as 13 could conceivably be seen as fully 18 years old, and thereby easily acceptable for overzealous prosecutors to treat as an adult defendant. This tendency to round black teens up to adults is detailed in a 2014 study by the American Psychological Association entitled: \"The Essence of Innocence: Consequences of Dehumanizing Black Children\".\n\nImmigrants to the United States commit fewer crimes than native-born citizens. The drop in crime rates is due to a greater influx of immigrants. The belief that a third of all federal prisoners are illegal immigrants is inaccurate, as government authorities do not categorize all inmates by immigration status. The higher percentage of undocumented convicted immigrants in federal courts was due to immigration offenses, as opposed to serious crimes such as drug offenses, and US-born citizens have a higher percentages for crimes such as drug offenses. Arresting undocumented immigrants cannot ensure public safety, and some law enforcement authorities state that aggressively enforcing immigration law would jeopardize public safety. To ensure public safety, initiatives should be taken to investigate the causes of crime and implement community-based programs accordingly. The legal system of both past and present United States governments has had to confront issues of enforcing border security and/or deporting illegal immigrants.\n\nOver the past 70 years, researching the impact that racial identity has on sentencing outcomes has been at the forefront of criminology. But, many studies contradict each other. Some studies found that minorities receive harsher sentences than whites, while others found that minorities received lighter punishments.In a study done from 2011-2014, that followed 302 men and women in drug related convictions found that blacks were actually convicted at a lower rate than other ethnicities, but had 2.5 more incarcerations on average. \n\nNumerous studies have been conducted to examine whether race is associated with sentence length or severity. An early study by Joan Petersilia found that in California, Michigan, and Texas, Hispanics and blacks tended to receive harsher sentences than whites convicted of comparable crimes and with similar criminal records. A 1998 meta-analysis found that the relationship between race and sentencing in the U.S. was not statistically significant, but that the use of different methods of classifying race may also mask the true race-sentencing relationship. A study published the same year, which examined sentencing data from Pennsylvania, found that young black men were sentenced more harshly than were members of any other age-race-gender combination. Similarly, a 2005 meta-analysis found that blacks tended to receive harsher sentences than did whites, and that this effect was \"statistically significant but small and highly variable.\"\n\nA 2006 study found that blacks and Hispanics received about 10% longer sentences than whites, even after controlling for all possible relevant characteristics, with regard to final offenses. However, when the researchers examined base offenses instead, the disparity was reversed. A 2010 analysis of U.S. Sentencing Commission data found that blacks received the longest sentences of any ethnicity within each gender group (specifically, their sentence lengths were on average 91 months for men and 36 months for women). A 2011 study found that black women with lighter perceived skin tones tended to receive more lenient sentences and serve less of them behind bars. A 2012 study looking at felony case data from Cook County, Illinois found that the sentencing disparity between blacks and whites varied significantly from judge to judge, which the authors state provides \"support for the model where at least some judges treat defendants differently based on their race.\" A 2013 report by the U.S. Sentencing Commission found that black men's prison sentences were on average almost 20% longer than those of their white counterparts who were convicted of similar crimes. \n\nA 2015 study focusing primarily on black and white men in Georgia uncovered that, on average, black men received sentences that were 4.25% higher than whites for the same type of crime. However, the same study found a larger disparity in sentence length among medium- and dark-skinned blacks, who received 4.8% longer sentences than whites, whereas light-skinned blacks received sentences of about the same average length as those of whites. It is also documented that, in the United States as a whole, Latinos, African Americans, and American Indians are far more frequently convicted than white Americans, and they receive harsher and longer punishments than their white counterparts for committing the same crimes. \n\nA study published by Roland G. Fryer, Jr. a professor at Harvard concluded in 2015, nationwide, white people were more likely to be shot by police than black people in similar situations while black and Hispanic people were more likely to be manhandled, handcuffed or beaten by the police — even if they are compliant and law-abiding. The study looked at 1,332 police shootings between 2000 and 2015 in 10 major police departments, in Texas, Florida and California. The study found that black and white suspects were equally likely to be armed and officers were more likely to fire their weapons before being attacked when the suspects were white. For shootings in Houston, the study looked at incidents in which an officer does not fire but might be expected to. They concluded that officers were about 20 percent less likely to shoot black suspects. When it comes to lethal force the study concluded that police are not racially biased in how they use lethal force. A 2016 study published in the Injury Prevention journal concluded that African Americans, Native Americans and Latinos were more likely to be stopped by police compared to Asians and whites. They found that there was no racial bias in the likelihood of being killed or injured after being stopped. The disparity in how police interact with white people and people of color was a contributing factor to the rise of the Black Lives Matter movement.\n\nA database collected by The Guardian concluded that 1093 people in 2016 were killed by the police. The rate of fatal police shootings per million was 10.13 for Native Americans, 6.66 for Black people, 3.23 for Hispanics; 2.93 for White people and 1.17 for Asians. The database showed by total, Whites were killed by police more than any other race or ethnicity.\n\nPolice behavior depends on the social dynamics of a scenario in a police to citizen interaction. Within scenarios of a police to citizen interaction, different levels of force can be applied to the citizen. A 2017 study found that people of different races are treated differently by police officers throughout the time of their interaction. 62 White, 42 Black, and 35 Latino use-of-force cases were studied from a medium to large sized urban police department in the United States. The studies showed that certain people were treated differently initially when force was used by a police officer, and other races are treated differently when the use of force escalates. The outcomes of the study showed that Black and Latino suspects have more force applied to them early on in the police to citizen interaction, while White citizens receive more violent force as the interaction progresses.\n\nA 2014 study involving computer-based simulations of a police encounter in which one has to decide whether to shoot or not found a greater likelihood to shoot Black targets instead of Whites when the participants were undergraduate students. The same simulation used with police shows the target race affects the police reaction in some ways but they do not generally show a biased pattern of shooting. A majority of police officers' see \"ambiguous behavior as more violent when the actor is Black rather than White.\" Thus, a police officer's judgement of the suspect could be the difference between using force. Another study at Washington State University used realistic police simulators of different scenarios where a police officer might use deadly force. The study concluded that unarmed white suspects were three times more likely to be shot than unarmed black suspects. The study found that \"the participants were experiencing a greater threat response when faced with African Americans instead of white or Hispanic suspects\" but were still \"significantly slower to shoot armed black suspects than armed white suspects, and significantly less likely to mistakenly shoot unarmed black suspects than unarmed white suspects.\" The study concluded that the results could be because officers were more concerned with using deadly force against black suspects for fear of how it would be perceived. A 1977 analysis of reports from major metropolitan departments found officers fired more shots at white suspects than at black suspects, possibly because of \"public sentiment concerning treatment of blacks.\"\n\nA study that considered 34,794 federal offenders took into account the race, risk assessment, and future arrests of all participating members of the sample. Though the use of the Post Conviction Risk Assessment (PCRA), which proved to be highly accurate in predicting whether or not whites and blacks would return to prison after being released, showed that recidivism correlates less with race and more with criminal history.\n\nOther studies suggest that recidivism rates as related to race vary based on state. For example, the Alabama Department of Corrections performed a study where they tracked 2003 releases for 3 years. In that time span, 29% of both African American and white males that were released returned to prison, 20% of African American females that were released returned to prison, and 24% of white females returned to prison. The Florida Department of Corrections performed a similar study; they tracked 2001 releases for 5 years. They found that 45% of African American males were reincarcerated and 28% of non-African American males were reincarcerated.\n\nThere are two main studies that analyze the issue of habitual offenders in regards to race. Both were mostly conducted by Western Michigan University professor Charles Crawford. Published in 1998 and 2000, both studies focused on habitual offenders in the state of Florida. Crawford's studies found that black defendants in Florida were significantly more likely to be sentenced as habitual offenders than were whites, and that this effect was significantly larger for drug offenses and property crimes of which whites are often the victims. \n\nExamining both individual level and county level variables, a new study from 2008 updated and evaluated Crawford's work. It affirmed that sentencing policies are becoming harsher, and habitual offender statutes are currently just another tool that lawmakers use to incarcerate minorities at a higher rate than their white counterparts. The 2008 study concluded that habitual offender statutes can only continue to be used if they are used in a way that completely disregards race and is unbiased.  \n\nBlacks had a higher chance of going to prison especially those who had dropped out of high school. If a Black male dropped out of high school, he had an over 50% chance of being incarcerated in his lifetime, as compared to an 11% chance for White male high school dropouts. Socio-economic, geographic, and educational disparities, as well as alleged unequal treatment in the criminal justice system, contributed to this gap in incarceration rates by race.\n\nFailure to achieve literacy (reading at \"grade level\") by the third or fourth grade makes the likelihood of future incarceration twenty times more likely than other students. Some states use this measurement to predict how much prison space they will require in the future. It appears to be a poverty issue rather than a race issue.\n\nAccording to Dorothy Roberts the current prison system serves as a punitive system in which mass incarceration has become the response to problems in society. Field studies regarding prison conditions describe behavioral changes produced by prolonged incarceration, and conclude that imprisonment undermines the social life of inmates by exacerbating criminality or impairing their capacity for normal social interaction. Roberts further argues this racial disparity in imprisonment, particularly with African Americans, subjects them to political subordination by destroying their positive connection with society. Roberts also aegues that institutional factors – such as the prison industrial complex itself – become enmeshed in everyday lives, so much so that prisons no longer function as \"law enforcement\" systems. It has also been argued thst Latinos have been overlooked in the debate over the criminal justice system. It has also been suggested that differences in the way the criminal justice system treats blacks and whites decreases legitimacy, which, in turn, increases criminal behavior, leading to further increases in racial disparities in interactions with the criminal justice system.\n\nCrime in poorer urban neighborhoods is linked to increased rates of mass incarceration, as job opportunities decline and people turn to crime for survival. Crime among low-education men is often linked to the economic decline among unskilled workers. These economic problems are also tied to reentry into society after incarceration. Data from the Washington State Department of Corrections and Employment Insurance records show how \"the wages of black ex-inmates grow about 21 percent more slowly each quarter after release than the wages of white ex-inmates\". A conviction leads to all sorts of social, political, and economic disadvantages for felons, and has been dubbed the \"new civil death\" (Chin 2012, 179). In the aggregate, these obstacles make it difficult for released inmates to transition to society successfully, which, in turn, makes it difficult for these communities to achieve social stability.\n\nBlack ex-inmates earn 10 percent less than white ex-inmates post incarceration on average.\n\nProblems resulting from mass incarceration extend beyond economic and political aspects to reach community lives as well. According to the U.S. Department of Justice, 46% of black female inmates were likely to have grown up in a home with only their mothers. A study by Bresler and Lewis shows how incarcerated African American women were more likely to have been raised in a single female headed household while incarcerated white women were more likely to be raised in a two parent household. Black women's lives are often shaped by the prison system because they have intersecting familial and community obligations. The \"increase incarceration of black men and the sex ratio imbalance it induces shape the behavior of young black women\".\n\nEducation, fertility, and employment for black women are affected due to increased mass incarceration. Black women's employment rates were increased, shown in Mechoulan's data, due to increased education. Higher rates of black male incarceration lowered the odds of nonmarital teenage motherhood and black women's ability to get an educational degree, thus resulting in early employment. Whether incarcerated themselves or related to someone who was incarcerated, women are often conformed into stereotypes of how they are supposed to behave yet are isolated from society at the same time.\n\nFurthermore, this system can disintegrate familial life and structure. Black and Latino youth are more likely to be incarcerated after coming in contact with the American juvenile justice system. According to a study by Victor Rios, 75% of prison inmates in the United States are Black and Latinos between the ages of 20 and 39. Rios further argued that, societal institutions – such as schools, families, and community centers can impact youth by initiating them into this \"system of criminalization\" from an early age. Rios argues that these institutions, which are traditionally set up to protect the youth, contribute to mass incarceration by mimicking the criminal justice system.\n\nFrom a different perspective, parents in prison face further moral and emotional dilemmas because they are separated from their children. Both black and white women face difficulty with where to place their children while incarcerated and how to maintain contact with them. According to the study by Bresler and Lewis, black women are more likely to leave their children with related kin whereas white women's children are likely to be placed in foster care. In a report by the Bureau of Justice Statistics revealed how in 1999, seven percent of black children had a parent in prison, making them nine times more likely to have an incarcerated parent than white children.\n\nHaving parents in prison can have adverse psychological effects as children are deprived of parental guidance, emotional support, and financial help. Because many prisons are located in remote areas, incarcerated parents face physical barriers in seeing their children and vice versa.\n\nSocietal influences, such as low education among African American men, can also lead to higher rates of incarceration. Imprisonment has become \"disproportionately widespread among low-education black men\" in which the penal system has evolved to be a \"new feature of American race and class inequality\". Scholar Pettit and Western's research has shown how incarceration rates for African Americans are \"about eight times higher than those for whites\", and prison inmates have less than \"12 years of completed schooling\" on average.\n\nThese factors all impact released prisoners who try to reintegrate into society. According to a national study, within three years of release, almost 7 in 10 will have been rearrested. Many released prisoners have difficulty transitioning back into societies and communities from state and federal prisons because the social environment of peers, family, community, and state level policies all impact prison reentry; the process of leaving prison or jail and returning to society. Men eventually released from prison will most likely return to their same communities, putting additional strain on already scarce resources as they attempt to garner the assistance they need to successfully reenter society. They also tend to come from disadvantaged communities as well and due to the lack of resources, these same men will continue along this perpetuating cycle.\n\nA major challenge for prisoners re-entering society is obtaining employment, especially for individuals with a felony on their record. A study utilizing U.S. Census occupational data in New Jersey and Minnesota in 2000 found that \"individuals with felon status would have been disqualified from approximately one out of every 6.5 occupations in New Jersey and one out of every 8.5 positions in Minnesota\". It has also been argued that combination of race and criminal status of an individual will diminish the positive aspects of an individual and intensify stereotypes. From the viewpoint of employers, the racial stereotypes will be confirmed and encourage discrimination in the hiring process. As African Americans and Hispanics are disproportionately affected by felon status, these additional limitations on employment opportunity were shown to exacerbate racial disparities in the labor market.\n\nThere have been minor adjustments to reduce the incarceration rate in the United States on the state level. Some of these efforts include introducing Proposition 47 in 2014, which reclassified specific property and drug crimes, and the Rockefeller drug laws in 2009, which pressed extreme minimum sentences for minor drug offenses. According to The Sentencing Project, there can be other alterations made to lower the incarceration rate. Some changes include reducing the length of some sentences, making resources such as treatment for substance abuse available to all and investing in organizations that promote strong youth development.\n\n\n"}
{"id": "5574320", "url": "https://en.wikipedia.org/wiki?curid=5574320", "title": "Respect agenda", "text": "Respect agenda\n\nThe Respect agenda was launched in September 2005 by Tony Blair in the United Kingdom. Tony Blair described it as being about \"putting the law-abiding majority back in charge of their communities\" . Its aim was to help central government, local agencies, local communities and citizens to work together to tackle anti-social behaviour more effectively.\n\nIn a speech in January 2006, Tony Blair acknowledged the work of sociologist Richard Sennett, particularly his 2003 book \"Respect: The Formation of Character in a World of Inequality\" .\n\nIn late December 2007, it was reported that the government of Gordon Brown had effectively ended the Respect programme by closing down the Respect Task Force and moving its head to another job inside the Cabinet Office . However, much of the Respect Agenda was incorporated into a Youth Taskforce Action Plan in the Department for Children, Schools and Families.\n\nThe agenda was co-ordinated by the Respect Task Force, a cross-governmental unit based at the Home Office. Louise Casey, former director of the Anti-Social Behaviour Unit, headed the Task Force.\n\nThe key policies of the Task Force were published in the Respect Action Plan in January 2006. The report advised tackling the underlying causes of anti-social behaviour, intervening early where problems occur and broadening efforts to address other areas of poor behaviour.\n\nThe agenda promoted a range of tools including Anti-Social Behaviour Orders, Parenting Orders, Family Intervention Projects and Dispersal Orders. The Task Force claimed use of a combination of the available tools can be effective when tackling the problem, although Anti-Social Behaviour Orders have encountered some controversy.\n\n"}
{"id": "25161132", "url": "https://en.wikipedia.org/wiki?curid=25161132", "title": "Simon of Peraea", "text": "Simon of Peraea\n\nSimon of Peraea or Simon son of Joseph was a former slave of Herod the Great who rebelled and was killed by the Romans in between 4 BC and 15 AD. He has been identified as the messiah of Gabriel's Revelation. He is mentioned by Flavius Josephus.\n\nAccording to Josephus:\n\nA tablet, known as the Gabriel's Revelation or The Jeselsohn Stone, was likely found near the Dead Sea some time around the year 2000. It has been associated with the same community which created the Dead Sea scrolls and mentions Simon. Israel Knohl formerly read the inscription as a command from the angel Gabriel \"to rise from the dead within three days\". He took this command to be directed at a 1st-century Jewish rebel called Simon, who was killed by the Romans in 4 BC. Knohl believed that the finding \"calls for a complete reassessment of all previous scholarship on the subject of messianism, Jewish and Christian alike\". In 2009 the National Geographic Channel aired \"The First Jesus?\" which addressed the claims and controversy.\n\nKnohl has eventually abandoned this reading, in favor of Ronald Hendel's reading (followed by Qimron & Yuditsky): \"By three days the sign\". He still maintains the historical background of the inscription to be as mentioned above. He now views Simon's death, according to the inscription, as \"an essential part of the redemptive process. The blood of the slain messiah paves the way for the final salvation\".\n\n"}
{"id": "292285", "url": "https://en.wikipedia.org/wiki?curid=292285", "title": "State religion", "text": "State religion\n\nA state religion (also called an established religion or official religion) is a religious body or creed officially endorsed by the state. A state with an official religion, while not secular, is not necessarily a theocracy, a country whose rulers have both secular and spiritual authority. State religions are official or government-sanctioned establishments of a religion, but the state does not need be under the control of the religion (as in a theocracy) nor is the state-sanctioned religion necessarily under the control of the state.\n\nOfficial religions have been known throughout human history in almost all types of cultures, reaching into the Ancient Near East and prehistory. The relation of religious cult and the state was discussed by Varro, under the term of \"theologia civilis\" (\"civic theology\"). The first state-sponsored Christian church was the Armenian Apostolic Church, established in 301 CE. In Christianity, as the term \"church\" is typically applied to a Christian place of worship or organisations incorporating such ones, the term \"state church\" is associated with Christianity as sanctioned by the government, historically the state church of the Roman Empire in the last centuries of the Empire's existence, and is sometimes used to denote a specific modern national branch of Christianity. Closely related to state churches are ecclesiae, which are similar but carry a more minor connotation.\n\nIn the Middle East, many states with primarily Islamic population have Islam as their state religion, either as the Shiite or Sunni variety, though the degree of religious restrictions on the citizen's everyday life varies by country. Rulers of Saudi Arabia use both secular and religious power, while Iran's secular presidents are supposed to follow the decisions of religious authorities since the revolution of 1979. Turkey, which also has a primarily Muslim population, became a secular country after Atatürk's Reforms, although unlike the Russian Revolution of the same time period, it did not result in the adoption of state atheism.\n\nThe degree to which an official national religion is imposed upon citizens by the state in contemporary society varies considerably; from high as in Saudi Arabia to minimal or none at all as in Denmark, England, Iceland, and Greece.\n\nThe degree and nature of state backing for denomination or creed designated as a state religion can vary. It can range from mere endorsement (with or without financial support) with freedom for other faiths to practice, to prohibiting any competing religious body from operating and to persecuting the followers of other sects. In Europe, competition between Catholic and Protestant denominations for state sponsorship in the 16th century evolved the principle \"Cuius regio, eius religio\" (states follow the religion of the ruler) embodied in the text of the treaty that marked the Peace of Augsburg, 1555. In England, Henry VIII broke with Rome in 1534, being declared the Supreme Head of the Church of England, the official religion of England continued to be \"Catholicism without the Pope\" until after his death in 1547, while in Scotland the Church of Scotland opposed the religion of the ruler.\n\nIn some cases, an administrative region may sponsor and fund a set of religious denominations; such is the case in Alsace-Moselle in France under its local law, following the pre-1905 French concordatry legal system and patterns in Germany.\n\nIn some communist states, notably in North Korea and Cuba, the state sponsors religious organizations, and activities outside those state-sponsored religious organizations are met with various degrees of official disapproval. In these cases, state religions are widely seen as efforts by the state to prevent alternate sources of authority.\n\nThere is also a difference between a \"state church\" and the broader term of \"state religion\". A \"state church\" is a state religion created by a state for use exclusively by that state. An example of a \"state religion\" that is not also a \"state church\" is Roman Catholicism in Costa Rica, which was accepted as the state religion in the 1949 Constitution, despite the lack of a national church. In the case of a \"state church\", the state has absolute control over the church, but in the case of a \"state religion\", the church is ruled by an exterior body; in the case of Catholicism, the Vatican has control over the church. In either case, the official state religion has some influence over the ruling of the state. As of 2012, there are only five state churches left, as most countries that once featured state churches have separated the church from their government.\n\nDisestablishment is the process of repealing a church's status as an organ of the state. Opponents of disestablishment of the Church of England were known as antidisestablishmentarians.\n\nCurrently, the following religions have been established as state religions in some countries. All are versions of Christianity, Islam or Buddhism.\n\nGovernments where Buddhism, either a specific form of, or the whole, has been established as an official religion:\n\nThe following states recognize some form of Christianity as their state or official religion (by denomination):\n\nJurisdictions where Roman Catholicism has been established as a state or official religion:\n\nJurisdictions that give various degrees of recognition in their constitutions to Roman Catholicism without establishing it as the state religion:\n\nThe jurisdictions below give various degrees of recognition in their constitutions to Eastern Orthodoxy, but without establishing it as the state religion:\n\nThe Anglican Church of England is the established church in England as well as all three of the Crown Dependencies.\n\n\nJurisdictions where a Lutheran church has been established as a state religion include the Nordic countries (as of 2012 Norway does not have a public religion).\n\n\nMany Muslim-majority countries have constitutionally established Islam, or a specific form of it, as a state religion. Proselytism (converting people to another religion) is often illegal.\n\nIsrael is defined in several of its laws as a \"Jewish and democratic state\" (\"medina yehudit ve-demokratit\"). However, the term \"Jewish\" is a polyseme that can describe the Jewish people as either an ethnic or a religious group. The debate about the meaning of the term \"Jewish\" and its legal and social applications is one of the most profound issues with which Israeli society deals. The problem of the status of religion in Israel, even though it is relevant to all religions, usually refers to the status of Judaism in Israeli society. Thus, even though from a constitutional point of view Judaism is not the state religion in Israel, its status nevertheless determines relations between religion and state and the extent to which religion influences the political center.\n\nThe State of Israel supports religious institutions, particularly Orthodox Jewish ones, and recognizes the \"religious communities\" as carried over from those recognized under the British Mandate—in turn derived from the pre-1917 Ottoman system of \"millets\". These are: Jewish and Christian (Eastern Orthodox, Latin [Catholic], Gregorian-Armenian, Armenian-Catholic, Syrian [Catholic], Chaldean [Uniate], Greek Catholic Melkite, Maronite, and Syrian Orthodox). The fact that the Muslim population was not defined as a religious community does not affect the rights of the Muslim community to practice their faith. At the end of the period covered by the 2009 U.S. International Religious Freedom Report, several of these denominations were pending official government recognition; however, the Government has allowed adherents of not officially recognized groups freedom to practice. In 1961, legislation gave Muslim Shari'a courts exclusive jurisdiction in matters of personal status. Three additional religious communities have subsequently been recognized by Israeli law: the Druze (prior under Islamic jurisdiction), the Evangelical Episcopal Church, and the Bahá'í. These groups have their own religious courts as official state courts for personal status matters (see millet system).\n\nThe structure and goals of the Chief Rabbinate of Israel are governed by Israeli law, but the law does not say explicitly that it is a state Rabbinate. However, outspoken Israeli secularists such as Shulamit Aloni and Uri Avnery have long maintained that it is that in practice. Non-recognition of other streams of Judaism such as Reform Judaism and Conservative Judaism is the cause of some controversy; rabbis belonging to these currents are not recognized as such by state institutions and marriages performed by them are not recognized as valid. As pointed out by Avnery and Aloni, the essential problem is that Israel carries on the top-down Ottoman \"millet\" system, under which the government reserves the complete discretion of recognizing some religions groups and not recognizing others. marriage in Israel provides no provision for civil marriage, marriage between people of different religions, marriages by people who do not belong to one of nine recognised religious communities, or same-sex marriages, although there is recognition of marriages performed abroad.\n\nIn some countries, there is a political ideology sponsored by the government that may be called political religion.\n\n\nThe concept of state religions was known as long ago as the empires of Egypt and Sumer, when every city state or people had its own god or gods. Many of the early Sumerian rulers were priests of their patron city god. Some of the earliest semi-mythological kings may have passed into the pantheon, like Dumuzid, and some later kings came to be viewed as divine soon after their reigns, like Sargon the Great of Akkad. One of the first rulers to be proclaimed a god during his actual reign was Gudea of Lagash, followed by some later kings of Ur, such as Shulgi. Often, the state religion was integral to the power base of the reigning government, such as in Egypt, where Pharaohs were often thought of as embodiments of the god Horus.\n\nZoroastrianism was the state religion of the Sassanid dynasty which lasted until 651, when Persia was conquered by the Rashidun Caliphate. However, it persisted as the state religion of the independent state of Hyrcania until the 15th century.\n\nThe tiny kingdom of Adiabene in northern Mesopotamia converted to Judaism around 34 CE.\n\nMany of the Greek city-states also had a god or goddess associated with that city. This would not be its only god or goddess, but the one that received special honors. In ancient Greece, the city of Athens had Athena, Sparta had Ares, Delphi had Apollo and Artemis, Olympia had Zeus, Corinth had Poseidon and Thebes had Demeter.\n\nIn Rome, the office of \"Pontifex Maximus\" came to be reserved for the Emperor, who was often declared a god posthumously, or sometimes during his reign. Failure to worship the Emperor as a god was at times punishable by death, as the Roman government sought to link emperor worship with loyalty to the Empire. Many Christians and Jews were subject to persecution, torture and death in the Roman Empire, because it was against their beliefs to worship the Emperor.\n\nIn 311, Emperor Galerius, on his deathbed, declared a religious indulgence to Christians throughout the Roman Empire, focusing on the ending of anti-Christian persecution. Constantine I and Licinius, the two \"Augusti\", by the Edict of Milan of 313, enacted a law allowing religious freedom to everyone within the Roman Empire. Furthermore, the Edict of Milan cited that Christians may openly practice their religion unmolested and unrestricted, and provided that properties taken from Christians be returned to them unconditionally. Although the Edict of Milan allowed religious freedom throughout the Empire, it did not abolish nor disestablish the Roman state cult (Roman polytheistic paganism). The Edict of Milan was written in such a way as to implore the blessings of the deity.\n\nConstantine called up the First Council of Nicaea in 325, although he was not a baptised Christian until years later. Despite enjoying considerable popular support, Christianity was still not the official state religion in Rome, although it was in some neighboring states such as Armenia, Iberia, and Aksum.\n\nRoman Religion (Neoplatonic Hellenism) was restored for a time by the Emperor Julian from 361 to 363. Julian does not appear to have reinstated the persecutions of the earlier Roman emperors.\n\nCatholic Christianity, as opposed to Arianism and other ideologies deemed heretical, was declared to be the state religion of the Roman Empire on 27 February 380 by the decree \"De fide catolica\" of Emperor Theodosius I.\n\nIn China, the Han dynasty (206 BCE – 220 CE) advocated Confucianism as the \"de facto\" state religion, establishing tests based on Confucian texts as an entrance requirement into government service—although, in fact, the \"Confucianism\" advocated by the Han emperors may be more properly termed a sort of Confucian Legalism or \"State Confucianism\". This sort of Confucianism continued to be regarded by the emperors, with a few notable exceptions, as a form of state religion from this time until the overthrow of the imperial system of government in 1911. Note however, there is a debate over whether Confucianism (including Neo-confucianism) is a religion or purely a philosophical system.\n\nDuring the Mongol Yuan dynasty (1271–1368 CE), Tibetan Buddhism was established as the \"de facto\" state religion by the Mongol ruler Kublai Khan, the founder of the Yuan dynasty. The top-level department and government agency known as the Bureau of Buddhist and Tibetan Affairs (Xuanzheng Yuan) was set up in Khanbaliq (modern Beijing) to supervise Buddhist monks throughout the empire. Since Kublai Khan only esteemed the Sakya sect of Tibetan Buddhism, other religions became less important. Before the end of the Yuan dynasty, 14 leader of the Sakya sect had held the post of Imperial Preceptor (Dishi), thereby enjoy special power.\n\nShamanism and Buddhism were once the dominant religions among the ruling class of the Mongol khanates of Golden Horde and Ilkhanate, the two western khanates of the Mongol Empire. In the early days, the rulers of both khanates increasingly adopted Tibetan Buddhism, similar to the Yuan dynasty at that time. However, the Mongol rulers Ghazan of Ilkhanate and Uzbeg of Golden Horde converted to Islam in 1295 CE because of the Muslim Mongol emir Nawruz and in 1313 CE because of Sufi Bukharan sayyid and sheikh Ibn Abdul Hamid respectively. Their official favoring of Islam as the state religion coincided with a marked attempt to bring the regime closer to the non-Mongol majority of the regions they ruled. In Ilkhanate, Christian and Jewish subjects lost their equal status with Muslims and again had to pay the poll tax; Buddhists had the starker choice of conversion or expulsion. In Golden Horde, Buddhism and Shamanism among the Mongols were proscribed, and by 1315, Uzbeg had successfully Islamicized the Horde, killing Jochid princes and Buddhist lamas who opposed his religious policy and succession of the throne.\n\n\n\n\n\nThese areas were disestablished and dissolved, yet their presences were tolerated by the English and later British colonial governments, as Foreign Protestants, whose communities were expected to observe their own ways without causing controversy or conflict for the prevalent colonists. After the Revolution, their ethno-religious backgrounds were chiefly sought as the most compatible non-British Isles immigrants.\n\nThe State of Deseret was a provisional state of the United States, proposed in 1849, by Mormon settlers in Salt Lake City. The provisional state existed for slightly over two years, but attempts to gain recognition by the United States government foundered for various reasons. The Utah Territory which was then founded was under Mormon control, and repeated attempts to gain statehood met resistance, in part due to concerns over the principle of separation of church and state conflicting with the practice of members of The Church of Jesus Christ of Latter-day Saints of placing their highest value on \"following counsel\" in virtually all matters relating to their church-centered lives. The state of Utah was eventually admitted to the union on 4 January 1896, after the various issues had been resolved.\n\n\n"}
{"id": "20791072", "url": "https://en.wikipedia.org/wiki?curid=20791072", "title": "Statement on Chemical and Biological Defense Policies and Programs", "text": "Statement on Chemical and Biological Defense Policies and Programs\n\nThe \"Statement on Chemical and Biological Defense Policies and Programs\" was a speech delivered on November 25, 1969, by U.S. President Richard Nixon. In the speech, Nixon announced the end of the U.S. offensive biological weapons program and reaffirmed a no-first-use policy for chemical weapons. The statement excluded toxins, herbicides and riot-control agents as they were not chemical and biological weapons, though herbicides and toxins were both later banned. The decision to ban biological weapons was influenced by a number of domestic and international issues.\n\nWhen Richard Nixon selected Melvin Laird as his Secretary of Defense in early 1969, Laird directed the Department of Defense to undertake a comprehensive review of U.S. biological warfare (BW) programs. Laird's push for a review of both the chemical and biological programs arose when Congress attempted to push the Pentagon for open, joint Congressional hearings on chemical-biological warfare (CBW). The Pentagon balked and the result was Laird's memo to National Security Advisor Henry Kissinger urging a review of those weapons programs.\n\nLaird hoped to eliminate the U.S. BW program. He saw two reasons to kill the BW program. The first was political—eliminating the program could deflect growing protests over Vietnam. The second was budgetary: As a U.S. Representative, Laird had watched Pentagon BW budgets balloon during the Kennedy and Johnson years. With Laird's impetus, and the concurrence of the National Security Council staff, in late May 1969 Kissinger directed key administration officials to begin a review of CBW \"policies, programs and operational concepts\" with a report to be issued no later than September.\n\nSurprisingly, Laird found the Joint Chiefs of Staff receptive to BW elimination as well. In twice weekly meetings with the Joint Chiefs during 1969 Laird found none of the officers opposed to ending the U.S. BW program. They found the weapons ineffective and militarily useless, especially when compared to the U.S. nuclear arsenal. The Joint Chiefs made two demands, one was to continue defensive germ warfare research and the other was that they be allowed to maintain the U.S. chemical arsenal as a deterrent to the Soviet Union.\n\nIn June 1969 Kissinger asked a former Harvard colleague, Matthew Meselson to prepare a position paper on U.S. chemical and biological weapons programs. Meselson and Paul Doty then organized a private conference to discuss policy issues. The result was a September 1969 paper that not only urged U.S. ratification of the Geneva Protocol but an end to U.S. BW programs. Meselson and his colleagues argued that a biological attack would likely inflict a great toll on civilian populations while remaining largely militarily ineffective.\n\nExecutive action on BW was followed by congressional action on chemical warfare (CW). In August 1969 the Senate passed an amendment to the Military Procurement Bill which unilaterally renounced first-use of chemical weapons. The Senate action also issued a moratorium on the acquisition of new chemical weapons as well as de-emphasizing the need for CW readiness. The bill passed 91-0, although some senators expressed reservations about the CW provisions.\n\nNixon issued his \"Statement on Chemical and Biological Defense Policies and Programs\" on November 25, 1969 in a speech from Fort Detrick. The same day he gave a speech from the Roosevelt Room at the White House further outlining his earlier statement. The statement ended, unconditionally, all U.S. offensive biological weapons programs. Nixon noted that biological weapons were unreliable and stated: The United States shall renounce the use of lethal biological agents and weapons, and all other methods of biological warfare. The United States will confine its biological research to defensive measures such as immunization and safety measures.\n\nIn his speech Nixon called his move \"unprecedented\"; and it was in fact the first review of the U.S. BW program since 1954. Despite the lack of review, the BW program had increased in cost and size since 1961; when Nixon ended the program the budget was $300 million annually. Nixon's statement confined all biological weapons research to defensive-only and ordered the destruction of the existing U.S. biological arsenal.\n\nThe Nixon statement also addressed the topics of chemical warfare and U.S. ratification of the Geneva Protocol, which, at the time, the nation had yet to ratify. On chemical warfare Nixon reaffirmed no-first-use of chemical weapons by the United States. He also announced that the United States would reconsider ratification of the Geneva Protocol, which Nixon recommended to the Senate that year.\n\nThe presidential statement purposely omitted certain agents, while others were simply overlooked. In an exception to the no-first-use policy, which his statement reaffirmed, Nixon made a deference for riot-control agents and herbicides. Both were in use in Vietnam and both had been lightning rods for criticism. Nixon promised later memorandums concerning abolition of both types of agents; herbicide use in Vietnam was discontinued in 1970 but riot-control agent use continued.\n\nThe other major omission from Nixon's statement were toxins. His statement did not specifically address toxins, such as ricin, which tend to blur the line between chemical and biological weapons. As debate within the Army raged over whether toxins were considered chemical or biological weapons concerning the president's order, work on them continued at Fort Detrick, the \"hub\" of U.S. biological weapons programs. For several months following the November order, the Army continued working on staphylococcus enterotoxin type B (SEB). On February 20, 1970 Nixon added toxins, regardless of their means of production - be it chemical or biological, to the U.S. ban on biological weapons.\n\nThe statement immediately led to National Security Decision Memorandum 35 from Nixon, which was also dated November 25, 1969. The memorandum also stated that the U.S. government renounced all \"lethal methods\" and \"all other methods\" of biological warfare, it also stated that the U.S. would only conduct BW research and development for defensive purposes.\n\nU.S. biological weapons stocks were destroyed over the next few years. A $12 million disposal plan was undertaken at Pine Bluff Arsenal, where all U.S. anti-personnel biological agents were stored. That plan was completed in May 1972 and included decontamination of facilities at Pine Bluff. Other agents, including anti-crop agents such as wheat stem rust, were stored at Beale Air Force Base and Rocky Mountain Arsenal. These anti-crop agents, along with agents at Fort Detrick used for research purposes were destroyed in March 1973.\n\nNixon closed his statement, \"Mankind already carries in its own hands too many of the seeds of its own destruction. By the examples we set today, we hope to contribute to an atmosphere of peace and understanding between nations and among men.\" Shortly after Nixon's statement the United States and the Soviet Union began the SALT arms control talks, which eventually resulted in nuclear arms controls as well as the 1972 Antiballistic Missile Treaty. The U.S. commitment to end BW programs helped provide the lead for ongoing talks led by the United Kingdom in Geneva. The Eighteen Nation Disarmament Committee was discussing a British draft of a biological weapons treaty which the United Nations General Assembly approved in 1968 and that NATO supported. These arms control talks would eventually lead to the Biological Weapons Convention, an international treaty outlawing biological warfare.\n\nNixon's renunciation is often overlooked in discussions about his presidency and his presidential legacy. Books about Nixon devote little space to the act and those centered on the topic of arms-control, even less. The abandonment of an entire class of weapons remains unrepeated in U.S. history. In addition, Melvin Laird's role in the elimination of offensive U.S. biological capabilities has been largely overlooked.\n\nScholars and critics have argued that Nixon's decision to ban biological weapons was purely politically motivated. This move was seen as a way to placate national, Congressional, and international concerns. It was also seen as a way to progress arms-control talks, additionally it could have stymied the outcry over the use of non-lethal chemical agents in Vietnam. In reality, the issue was much more complex than even those reasons suggest.\n\nMeselson and others had argued that biological weapons amounted to little more than a cheap version of a nuclear weapon, and were easily attainable. Biological weapons represented a significant threat in the hands of less-well-armed, poorer nations, and Nixon surely recognized this \"asymmetrical\" threat. The administration eventually came to the conclusion that any biological threat could be easily countered with the U.S. nuclear arsenal. \n\nNixon recognized that the BW program was unpopular and decided that there was no real reason to continue these programs. While there were some political considerations involved in Nixon's decision, the end result brought the topic into international forums for years following his declaration. The media characterized Nixon's decision as a sudden awareness of the horrific nature of chemical-biological warfare.\n\nNixon hoped that the move would bolster both the image of his administration and the United States as a whole. He also wanted to score points with the Democratic majority in Congress and he had chosen to do this through various arms control measures. Nixon knew Democrats could not afford to oppose his renunciation of BW programs in light of rising opposition to the use of non-lethal chemicals in Vietnam and other events such as the Skull Valley sheep kill in Utah. Thus, the idealistic language Nixon used in his November statement was only part of the story. Besides the issue of proliferation raised by Meselson, the specter of growing dissent over Vietnam loomed large, as did the fact that the U.S. had never ratified the Geneva Protocol. In the end, Nixon was motivated to ban biological weapons in the United States by a host of issues.\n\n\n\n\n"}
{"id": "2283954", "url": "https://en.wikipedia.org/wiki?curid=2283954", "title": "Sword hunt", "text": "Sword hunt\n\nSeveral times in Japanese history, the new ruler sought to ensure his position by calling a . Armies would scour the entire country, confiscating the weapons of the enemies of the new regime. In this manner, the new ruler sought to ensure that no one could take the country by force as he had just done. The most famous sword hunt was ordered by Toyotomi Hideyoshi in 1588.\n\nPrior to the sword hunt called by Oda Nobunaga towards the end of the 16th century, civilians were free to carry swords for defense or simply for decoration. Nobunaga sought an end to this, and ordered the seizure of swords and a variety of other weapons from civilians, in particular the Ikkō-ikki peasant-monk leagues which sought to overthrow \"samurai\" rule. \n\nIn 1588, Toyotomi Hideyoshi, having become kampaku or \"imperial regent\", ordered a new sword hunt; Hideyoshi, like Nobunaga, sought to solidify separations in the class structure, denying commoners weapons while allowing them to the nobility, the samurai class. In addition, Toyotomi's sword hunt, like Nobunaga's, was intended to prevent peasant uprisings and to deny weapons to his adversaries. This hunt may have been inspired by a peasant uprising in Higo the year prior, but also served to disarm the sōhei of Mount Kōya and Tōnomine. Toyotomi claimed that the confiscated weapons would be melted down and used to create a giant image of the Buddha for the Asuka-dera monastery in Nara.\n\n\"Taikō's Sword Hunt\", as it came to be called, was accompanied by a number of other edicts, including the Expulsion Edict of 1590, by which Toyotomi sought to establish a census and expel from villages any newcomers who arrived in or after 1590. The chief goal of this was to place a check on the threat posed by rōnin, masterless wandering samurai who had the potential not only for crime and violence in general, but for banding together to overthrow Toyotomi rule. Hideyoshi, like most of this period, believed in rule by edict, paying little or no attention to legal principles.\n\nWhile the Sword Hunt ostensibly succeeded in denying weapons to potential rebels, it also created discontent throughout the nation, increasing the number and passion of potential rebels.\n\nThe Meiji Restoration of the 1860s was the beginning of a period of major modernization and Westernization. In 1871, extensive reforms were passed and executed, abolishing the \"han\" system, and thus ending feudalism and the class system.\n\nIn 1876, \"samurai\" were banned from carrying swords. A standing army was created, as was a police force. This \"sword hunt\" was performed for, ostensibly, different reasons, and certainly with different methods than those of several centuries earlier. This sword hunt put an end to the class system while the earlier ones were intended to deepen the distinctions between commoners and nobles. Ultimately, however, the result of this sword hunt was the same as the results of its predecessors; the hunt ensured that the only weapons were in the hands of the ruling government and not available to potential dissenters.\n\nToday, Japan has a Sword and Firearms Law which, much like gun control laws around the world, governs the possession and use of weapons in public. The purchase and ownership of certain swords within Japan is legal if they are properly registered, though the import and export of such items is tightly controlled, particularly in the case of items that might be labeled as national or cultural artifacts. Swords that are not produced by licensed smiths (including all machine-made swords) are prohibited for individuals. Japanese military swords are legal in Japan if they were made with traditional materials and methods.\n\n"}
{"id": "8437153", "url": "https://en.wikipedia.org/wiki?curid=8437153", "title": "Telangana Sadhana Samithi", "text": "Telangana Sadhana Samithi\n\nTelangana Sadhana Samithi, a political party in the Indian state of Andhra Pradesh, working for statehood for the Telangana region. \n\nTSS was formed in 2001 when A. Narendra, an MP from the Medak constituency, broke away from Bharatiya Janata Party. Narendra became the founding president of TSS.\n\nIn February 2002, TSS won one seat (out of 100) in the Municipal Corporation of Hyderabad elections. It had contested all seats.\n\nIn August 2002 TSS merged with Telangana Rashtra Samithi. He became a central minister when TRS joined the UPA in the government.\n"}
{"id": "54881006", "url": "https://en.wikipedia.org/wiki?curid=54881006", "title": "The Perils of \"Privilege\"", "text": "The Perils of \"Privilege\"\n\nThe Perils of \"Privilege\": Why Injustice Can’t Be Solved by Accusing Others of Advantage is a 2017 non-fiction book by Phoebe Maltz Bovy.\n\nA look into the concept of \"privilege\" and how it affects progressive politics and that accusing others of unearned advantages does nothing to address inequality and perhaps only makes things worse.\n\n"}
{"id": "54762816", "url": "https://en.wikipedia.org/wiki?curid=54762816", "title": "The Queer Insurrection and Liberation Army", "text": "The Queer Insurrection and Liberation Army\n\nThe Queer Insurrection and Liberation Army (TQILA) is a queer anarchist armed group and subunit of the International Revolutionary People's Guerrilla Forces formed on 24 July 2017 by LGBT members of the IRPGF. Its formation was announced from Raqqa City along with a statement explaining the purposes of its formation; the systematic persecution of LGBT people by the Daesh was highlighted as a significant motivation for the creation of the group. TQILA is reported to be the first LGBT unit to fight against the Islamic State of Iraq and the Levant, and apparently the first LGBT militia in the Middle East.\n\nThe testimonial image of its formation, in which fighters posed alongside a sign with the motto \"These faggots kill fascists\" and two flags — the flag of the group and an LGBT flag — went viral. Western media reported on the unit extensively.\n\nThe unit, like the rest of the IRPGF, is a member of the International Freedom Battalion. One of the group's testimonial photos is features \"Heval Mahir\", commander of the International Freedom Battalion, and the Marxist-Leninist guerrilla groups, TKP/ML TİKKO, holding the LGBT flag.\n\nDespite being part of the International Freedom Battalion some news outlets erroneously reported that TQILA was an official unit of the Syrian Democratic Forces which caused confusion. In response, Mustafa Bali, media director of the SDF, denied these claims. He stated that there is no LGBT brigade within the coalition. However, he did not deny the existence of an LGBT brigade within the International Freedom Battalion.\n\n\n"}
{"id": "9503511", "url": "https://en.wikipedia.org/wiki?curid=9503511", "title": "Tin Oo", "text": "Tin Oo\n\nGeneral Thura Tin Oo (, ; born 3 March 1927 in Pathein, often referred to as U Tin Oo) is a Burmese politician, activist and retired general in the armed forces of Union of Myanmar who is currently the Patron of the National League for Democracy (NLD) in Myanmar.\n\nTin Oo joined the army on 26 February 1946 as a Second Lieutenant in Burma Rifles Battalion. He reached the ranks of Lieutenant on 7 January 1947, Captain on 27 September 1948 and served as executive officer at Armed Forces Training Headquarters. On 22 June 1949, he was transferred to No.1 Burma Rifles Battalion as Company Commander. He was promoted to the rank of Major on 25 January 1950 and became Deputy Battalion Commander (2IC) of No.1 Burma Rifles Battalion and took over the position of acting Battalion Commander on 27 November 1951.\n\nTin Oo was promoted to Lieutenant Colonel on 21 January 1954 and became Commander of 4th Infantry Brigade on 30 May 1957. He was then transferred to Army Officer Training School as Commandant on 13 September 1957. Throughout 1958 and 1961, Lieutenant Colonel Tin Oo served as Battalion Commander for No. 14 Infantry Battalion (from 18 November 1958), No. 2 Burma Rifle Battalion (from 16 February 1961) and after his promotion as Colonel, he became acting Commander for No. 13 Infantry Brigade (from 20 February 1961).\n\nHe was then given the command of South West Regional Military Command and promoted to the rank of Colonel on 14 February 1963. On 19 September 1964 he became Commander of Central Regional Military Command. He was then promoted to the rank of Brigadier General and became Deputy Chief of Staff (Army) on 20 April 1972. On 8 March 1974 he was promoted to the rank of General and became Commander in Chief of Tatmadaw. He was armed forces Commander in Chief during the bloody crackdown on student protests surrounding the funeral of former UN Secretary General U Thant.\n\nDuring his military career, General Tin Oo was awarded with Thuya medal, prestigious award for gallantry and bravery in the face of the enemy that can be awarded to members of Myanmar Armed Forces. He led both tactical and strategic campaigns against the Karen National Union as well as the Communist Party of Burma and various ethnic armed groups, especially in the north and east of the country.\n\nOn 6 March 1976, As per Order no. 26/76 issued by the Council of State, Tin Oo was forced to retired from his position as Commander in Chief of the Armed Forces of Burma. According to the official explanation released by the then ruling party, Burma Socialist Programme Party, General Tin Oo was forced to retire because Dr. Daw Tin Moe Wai, his wife, broke the rules and regulations laid down for the spouses of commanding officers of the Tatmadaw by accepting numerous bribes, thus affecting General Tin Oo's position as Commander in Chief of the Armed Forces.\n\nAfter his forced retirement, he was accused of high treasons against the armed forces (Tatmadaw), the party (BSPP) and the state. He was subsequently arrested and tried for the alleged withholding of information concerning a failed coup-d'état against General Ne Win and the Council of State. On 11 January 1977, Judge U Ohn Maung, Chairman of Divisional Justice Committee for Yangon Division sentenced him to 7 years hard labour and imprisonment according to Crime Against State and High Treasons Act 124. Tin Oo's subsequent appeal for this judgement on 20 August 1977 was summarily dismissed by Judge Soe Hlaing, of Council of People Justice, the equivalent of the Supreme Court, and upheld the judgement handed out by Yangon Division Justice Committee. Colonel Hla Pe, commander of Northern Regional Command, Colonel Maung Maung, Colonel General Staff and Colonel Myo Aung, commandant of the National Defence College were also dismissed and the former two were imprisoned along with General Tin Oo.\n\nHe was released under general amnesty in 1980, after which he studied and received a degree in Law. On 2 September 1988, he became the Vice President of the National League for Democracy (NLD) and on 20 December, the President of NLD. From 20 July 1989 he was put under house arrest and from 22 December 1989, he was imprisoned for three years.\n\nOn 30 May 2003, Tin Oo, travelling with the caravan of Aung San Suu Kyi, leader of the NLD, was attacked in the northern village of Depayin by a government-sponsored mob, murdering and wounding many of his supporters. Tin Oo was taken into detention along with Aung San Suu Kyi and was initially held in prison in Kalay in northwestern Myanmar. In February 2004 he was brought back to his home in Yangon, where he is actually held under house arrest.\nThe junta extended his detention by one year in February 2007, 2008, and 2009. The last of these extensions was in violation of the rule of Burmese law, but no explanation was given by the junta. He was released from House Arrest on February 13, 2010.\n\n\n"}
{"id": "40629047", "url": "https://en.wikipedia.org/wiki?curid=40629047", "title": "Troubled Families", "text": "Troubled Families\n\nThe Troubled Families programme is a UK Government scheme under the Department for Communities and Local Government with the stated aim of helping troubled families turn their lives around.\n\nThe Troubled Families programme was launched by the Prime Minister in 2011. Louise Casey became Director General, Troubled Families on 1 November 2011. The programme initially intends to change the repeating generational patterns of poor parenting, abuse, violence, drug use, anti-social behaviour and crime in the most troubled families in the UK, with the government investing some £4,000 per family over 3 years, and each family having an assigned family worker. \nTroubled families are defined as those that have problems and cause problems to the community around them, putting high costs on the public sector. The aim is to get 120,000 troubled families in England turn their lives around by 2015 and in particular to:\n\n\nMental health problems are often found in such families. David Cameron summarised the nature of the families in his Oldbury speech (New Statesman, 15.12.11) \nsaying\n\n'...these families are the source of a large proportion of the problems in society. Drug addiction. Alcohol abuse. Crime. A culture of disruption and irresponsibility that cascades down the generations... a small number of these families cost an extraordinary amount of money. Last year £9 billion was spent on 120,000 families'.\n\nAlthough the TFP was supposedly aimed at intensive support the political rhetoric was often pejorative.Louise Casey, the 'Troubled Families Tsar' told the Daily Telegraph (20.07.12)\n\n'We are not running some cuddly social workers programme...we should be talking about things like shame and guilt...we have lost the ability to be judgmental because we worry about being seen as nasty to poor people'.\n\nEric Pickles, communities minister, told the Daily Mail (10.06.12)\n\n'We have sometimes run away from categorising, stigmatising, laying blame. We need a less understanding approach'.\n\nHowever most of the people targeted were not involved in crime or anti-social behaviour; most were not alcohol or drug dependent.Most were poor,unemployed and with very high levels of \nmental / physical illnesses and disabilities in adults and children which resulted in high state support costs (see characteristics section). It is unclear how assertive, non-negotiable intervention and benefit sanctions can eliminate these costs.The evidence for long term success in 'turning around the families' is absent and on 12.06.14 Casey told a meeting at Reform\n\n'As hard as it is to accept,the truth is despite our best efforts over many years -and I include myself in that-we just haven't got it right. We haven't succeeded in getting these families to change or in stopping the transmission of problems from generation to generation-we just haven't.\nMany areas of England and Wales have renamed their local Troubled Families programmes, including Families First in Gloucestershire and Wales, Building Resilient Families and Communities (BRFC) in Staffordshire, and Think Family in Birmingham\n\nThe family-intervention approach used by the programme has been criticised by Stephen Crossley and Michael Lambert, who say that the evidence suggests that the approach does not work well.\n\nTroubled families, according to anecdotal evidence collected by Casey from family interviews, are characterized by inter-generational transmission, large numbers of children, shifting family make-up, dysfunctional relationships and unhelpful family and friends, abuse, institutional care, teenage mothers, early signs of poor behaviour, troubles at school, anti-social behaviour, mental illness (particularly depression, impeding ability to function in life), and drugs & alcohol use.\n\nThe definitive report, 'National Evaluation of the Troubled Families Programme' found that 49% of those in the program were lone parent families. Underage pregnancy was statistically insignificant, with the under-18 conception rate at 2%. 90% of adults had not been convicted of a criminal offence and 93% of adults had no record of anti-social behaviour. Among children, 88% of children had no record of anti-social behaviour. 3% of adults were recorded as treated for alcohol dependency and a further 3% of adults for drug dependency. The families were reported to suffer from high levels of health problems and disabilities. 46% had an adult or adults suffering a mental health problem; 33% of children had mental health problems. 32% of adults and 20% of children had a long-standing physical illness or disability; 39% had a child or children with SEN statements; 46% had a child with school problems; 15% had a child with a temporary exclusion. The families were also poor and in social housing: 74% of households were workless; 83% received out of work benefits; 27% were in rent arrears; 21% were at risk of eviction. The statistical characteristics shared by most families were poverty, unemployment, illness and disability and a high welfare cost to the state.\n\nBy November 2013 some 22,000 families had been 'turned round', based on metrics such as child school attendance and crimes committed, although at least some of these families continue to commit some crimes.\n\nCasey does not believe people undertake behaviours to gain benefits, and that compulsory contraception, whilst reducing the number of children being born into such families, would lead to high-risk teens finding \"something else to get into trouble with. Because they've got trouble in their souls, trouble in their heart, troubles in their head. So even if you brought in some draconian thing like that, they'd find something else to do that would actually be an expression of not having enough love or of having too much pain.\" But consider also Casey's and Pickles' comments in the introduction.\n\nBy March 2015 the Dept. for Communities and Local Government was claiming that 105,671 families of 117,910 processed had been 'turned around', some 89.6%. 8.9% of families had a member who had found a job. It could not be proved that the projects had achieved this. 80.7% had met the 'crime/ASB/education' target. However, only 7% of adults and 12% of children at project entry had an anti-social behaviour intervention.Only 10% of adults at entry had a proved offence (National Evaluation of the TFP, 2014). It must be concluded that most of the 80.7% families\n'turned around' involved reduced truancy, not crime or ASB. According to the Dept. for Communities claims, each family cost the state £26,000 per annum at entry to the programme. The estimated average cost saving at exit was claimed to be £11,200 per family. This implies that although 89.6% of families had been 'turned around', 56.9% of the original family costs were still there (Troubled Families, Green Man Books,2015, ).\n\nThe 120,000 troubled families allegedly cost the state £9 billion per annum according to Cameron, Pickles and Casey at programme start up.However, Pickles told the House of Commons on 15.03.15 that £1.2 billion per annum would be saved. This was a hypothetical number based on assumptions that alleged improvements in behaviour would be sustained and depended on removing the high costs associated with disabled children and chronically sick, unemployed adults (Troubled Families, Green Man Books,2015,). Pickles was challenged about the numbers in the House by Hilary Benn MP. Pickles responded\n\n'The Rt. Hon. gentleman made a number of points on how we can demonstrate success and square the £1.2 billion with the £9 billion...this is notoriously difficult because governments of all types are absolutely terrible at measuring outcomes'\n\nDCLG published that 99% of the troubled families had been turned around by May 2015, with 132 of the 152 local authorities having turned around 100% of local troubled families and only two having a success rate under 90%. However, Louise Casey had stated to the Public Accounts Committee that the programme had worked with more than the stated total number of troubled families in England, which would increase the denominator for the 99% figure.\n\nIn June 2015, Jonathan Portes said of the figure, \"I doubt that the North Korean statistical office would have the cheek.\" The figure was later criticised as misleading by a Public Accounts Committee.\n\nDCLG has published documents to say that the programme saves money for the public sector by preventive action with families who rely heavily on public-sector services. A report in March 2015 claimed that the first programme had saved £1.2 billion, which was quoted in a speech by David Cameron. This figure was criticised as \"unadultered fiction\" by Jonathan Portes as it was based on data from only seven local authorities and were based on gross (rather than net) savings. Similar criticisms were made by Full Fact and the Daily Mirror.\n\nA later costs report, based on data from 67 local authorities, was published in October 2016 to accompany the evaluation. This found a gross saving of £7,050 per family per year for these councils, and did not make any claims on savings for the programme as a whole.\n\nIn June 2013, the UK government announced its intention to extend this intensive help to 400,000 more families, committing £200 million in funding in 2015 to 2016. It expects, for every £4,000 spent on a family, an annual saving of £15,000 in the costs of the police, health and social services in dealing with the family.\n\nAn evaluation of the initial programme led by Ecorys was leaked to the BBC in August 2016. The evaluation stated that the programme had made \"no discernable impact\" on unemployment, truancy or criminality in the treatment families. The BBC said that the report was leaked by a senior civil servant who felt that government officials had suppressed the report because of its negative evaluation. The Department for Communities and Local Government denied this, however. The Guardian also noted the scheme had been set up in the wake of the 2011 England riots and was due to cost 1.3 billion pounds by the end of the expanded programme. The Early Intervention Family called for DCLG to publish the report in full, but the Department replied that the evaluation work was not yet finished.\n\nWriting in the Guardian, Anna Bawden blamed the problems on the use of a \"payment by results\" system during a period when local government budgets were being cut and said, \"The programme was bound to maximise waste.\"\n\nFollowing the leak, the House of Commons's Public Accounts Committee began an investigation and the National Audit Office was asked to provide an update on how money had been spent on the programme.\n\nThe Evaluation by the National Institute for Economic and Social Research was published on 17 October 2016. The report found that there had been \"no significant impact\" of the scheme. A press release from NIESR stated, \"we were unable to find consistent evidence that the programme had any significant or systematic impact\". The Times reported the following day, \"the report was published quietly last night after complaints from Whitehall insiders that it was being suppressed\".\n\nOn the same day, the Channel 4 series Dispatches broadcast an investigation of the programme that was highly critical of the programme. Interviews with critics of the programme such as Stephen Crossley, Jonathan Portes and Gen Maintland Hudson suggested that the 99% success rate was achieved by councils' classifying minor complaints such as noise as evidence of being a troubled family so that they were more likely to turn the families around and by data matching of families previously worked with before the programme. Dispatches suggested that many of the problems targeted by the programme persisted in areas that claimed to have achieved 100% success.\n\nThe Evaluation was published two days before a hearing before the Public Accounts Committee on 19 October. The Public Accounts Committee had expressed concerns to Sajid Javid, the Secretary of State for DCLG, on 5 October that the evaluation documents were not provided to the Committee in advance as were requested. On the date of publication, the Committee tweeted followers to help it review the 765 pages of the Evaluation published late that day before the hearing on 19 October.\n\nIn response to the finding of \"no significant impact\" of the scheme, Dame Casey stated: \"They (NIESR) had not, frankly, put any of the caveats in the public domain\" and that \"they have misrepresented their own research\". NIESR responded that the caveats had been detailed in their press statement and that DCLG had approved of the press statement before its release.\n\nThe PAC published its report on 19 December 2016. They concluded that the delay in publication had been unacceptable, that DCLG had failed to demonstrate that the programme had any significant impact and that the terminology of saying that the families had been \"turned around\" was misleading given that many of the families had continuing problems after a result had been claimed. The PAC chairwoman, Meg Hillier, commented that the report was \"far more serious\" than \"a slap on the wrist\" for ministers.\n\n\n"}
{"id": "7671714", "url": "https://en.wikipedia.org/wiki?curid=7671714", "title": "Ultra-imperialism", "text": "Ultra-imperialism\n\nUltra-imperialism, or occasionally hyperimperialism and formerly super-imperialism, is a potential, comparatively peaceful phase of capitalism, meaning \"after\" or \"beyond\" imperialism. It was described mainly by Karl Kautsky. \"Post-imperialism\" is sometimes used as a synonym of \"ultra-imperialism\", although it can have distinct meanings.\n\nThe suggestion of a possible \"Ultraimperialismus\" is normally attributed to Karl Kautsky, the leading theoretician of the Social Democratic Party of Germany (SPD) in the era of the Kaiserreich. Kautsky coined the term in 1914, but he had speculated on the issue several times in 1912 already. He postulated that in the field of international relations a \"stadium [approaches], in which the competition among states will be disabled by their cartel relationship\". Thus, Kautsky’s \"Ultraimperialismus\" concept was shaped by the idea of cartels made up by states for the purpose of international policy.\n\nThe basic idea of a possible pacification of imperialism did not really originate from Kautsky. The British left-liberal John Atkinson Hobson had written in 1902 in a similar context about a potential \"inter-imperialism\", which could be established by a \"combination\" of great powers (\"combination\" or \"combine\" then being used to designate cartels). In 1907, Karl Liebknecht stated in his brochure \"Militarismus und Antimilitarismus\" that \"a trustification of all actual and potential colonies among the colonial powers, so to speak […] a disabling of the colonial rivalry among the states [could take place in the future], as it occurred to some extent for the private competition among capitalist entrepreneurs in the cartels and trusts\". – On the eve of World War I these peace-loving social-democrats and liberals in Europe hoped that the great powers would – beginning with the British Empire and the Deutsche Reich – unite into a \"states' cartel\" or a \"combination\" of states giving the rivals organization and reconciliation.\n\nIn 1914 Kautsky published an article on imperialism, which subsequently was translated into English and published in the USA. In these he argued, there could be a way out of direful wars among the imperialist powers, a solution now named \"Ultraimperialismus\" or \"super-imperialism\".\n\nKautsky elucidated this thought in the September 1914 issue of \"Die Neue Zeit\". He described the current phase of capitalism as imperialism. In Marxist theory, imperialism consists of capitalist states superexploiting labour in agrarian regions in order to increase both the imperialist nation's productivity and their market. However, imperialism also required capitalist states to introduce protectionist measures and to defend their empires militarily. He believed that this was the ultimate cause of World War I.\n\nKautsky noted that before the War, while industrial accumulation had continued, exports had dropped, as a result of a tendency of industry to expand out of proportion to agriculture. He pointed out that growing nationalism in the more industrially advanced colonies would necessitate a continuation of the arms race after the War, and that should this occur, economic stagnation would worsen.\n\nIn Kautsky's view, the only one way in which capitalists would be able to maintain the basic system, while avoiding this stagnation, would be for the wealthiest nations to form a \"cartel\", in the same manner as which banks had co-operated, agreeing to limit their competition and renounce their arms race, in order to maintain their export markets and their systems of superexploitation. In doing so, he postulated that war and militarism were not essential features of capitalism, and that a peaceful capitalism was possible.\n\nLenin disagreed with Kautsky's approach. In an introduction to Nikolai Bukharin's \"Imperialism and World Economy\", written in 1916, he conceded that \"in the abstract one can think of such a phase. In practice, however, he who denies the sharp tasks of to-day in the name of dreams about soft tasks of the future becomes an opportunist.\"\n\nLenin developed Bukharin's theories of imperialism, and his own arguments formed the core of his work \"\". He wrote that Kautsky's theory supposed \"the rule of finance capital lessens the unevenness and contradictions inherent in the world economy, whereas in reality it increases them.\" He gives examples of disparities in the international economy and discusses how they would develop even under a system of ultra-imperialism. He asks, under the prevailing system, \"what means other than war could there be under capitalism to overcome the disparity between the development of productive forces and the accumulation of capital on the one side, and the division of colonies and spheres of influence for finance capital on the other?\"\n\nSome Marxists have pointed out similarities between the co-operation between the capitalist states during the Cold War and ultra-imperialism. Martin Thomas of Workers Liberty claims that this \"since the collapse of the Stalinist bloc in 1989-91, that 'ultra-imperialism' has extended to cover almost the whole globe\", but that \"rather than being a sharply polarised world of industrial states on one side, agrarian states on the other, with the industrial states joining together to keep the agrarian states un-industrial by force, it is a very unequal but multifarious system, with political independence for the ex-colonies, rapidly-permuting new international divisions of labour, and many poorer states exporting mostly manufactured goods.\"\n\nOther commentators have pointed to similarities between Michael Hardt and Antonio Negri's theory of Empire and Kautsky's theory, although the authors themselves claim their theory is founded in Leninism.\n\nOpponents of the theory of ultra-imperialism argue that, whatever similar forms may have existed during the Cold War, since its end, inter-capitalist competition has tended to increase,\n\nState cartel theory - a new concept in the field of International Relations theory - uses the basic conception of Kautsky's ultra-imperialism, but is not a Marxist theory.\n\n\n"}
