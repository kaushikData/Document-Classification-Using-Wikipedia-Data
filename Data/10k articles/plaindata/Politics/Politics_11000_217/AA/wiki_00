{"id": "1464343", "url": "https://en.wikipedia.org/wiki?curid=1464343", "title": "Agricultural extension", "text": "Agricultural extension\n\nAgricultural extension is the application of scientific research and new knowledge to agricultural practices through farmer education. The field of 'extension' now encompasses a wider range of communication and learning activities organized for rural people by educators from different disciplines, including agriculture, agricultural marketing, health, and business studies.\n\nExtension practitioners can be found throughout the world, usually working for government agencies. They are represented by several professional organizations, networks and extension journals.\n\nAgricultural extension agencies in developing countries receive large amounts of support from international development organizations such as the World Bank and the Food and Agriculture Organization of the United Nations.\n\nModern extension began in Dublin, Ireland in 1847 with Lord Clarendon's itinerant instructors during the great famine. It expanded in Germany in the 1850s, through the itinerant agricultural teachers \"Wanderlehrer\" and later in the USA via the cooperative extension system authorized by the Smith-Lever Act in 1914. The term was later adopted in the United States of America, while in Britain it was replaced with \"advisory service\" in the 20th century. A number of other terms are used in different parts of the world to describe the same or similar concept:\n\n\nIn the US, an extension agent is a university employee who develops and delivers educational programs to assist people in economic and community development, leadership, family issues, agriculture and environment. Another program area provided by extension agents is 4-H and youth activities. Many extension agents work for cooperative extension service programs at land-grant universities. They are sometimes referred to as county agents, or extension educators. Often confused with Extension agents, Extension specialists are subject matter experts usually employed as scientists and university professors in various departments in the land-grant university system. Subjects range from agriculture, life sciences, economics, engineering, food safety, pest management, veterinary medicine, and various other allied disciplines. These subject matter specialists work with agents (usually in a statewide or regional team environment) to support programs within the cooperative extension system.\n\nThere is no widely accepted definition of agricultural extension. The examples given below are taken from a number of books on extension published over a period of more than 50 years:\n\n\nIt is not known where or when the first extension activities took place. It is known, however, that Chinese officials were creating agricultural policies, documenting practical knowledge, and disseminating advice to farmers at least 2,000 years ago. For example, in approximately 800 BC, the minister responsible for agriculture under one of the Zhou dynasty emperors organized the teaching of crop rotation and drainage to farmers. The minister also leased equipment to farmers, built grain stores and supplied free food during times of famine.\n\nThe birth of the modern extension service has been attributed to events that took place in Ireland in the middle of the 19th century. Between 1845–51 the Irish potato crop was destroyed by fungal diseases and a severe famine occurred (see Great Irish Famine). The British Government arranged for \"practical instructors\" to travel to rural areas and teach small farmers how to cultivate alternative crops. This scheme attracted the attention of government officials in Germany, who organized their own system of traveling instructors. By the end of the 19th century, the idea had spread to Denmark, Netherlands, Italy, and France.\n\nThe term \"university extension\" was first used by the Universities of Cambridge and Oxford in 1867 to describe teaching activities that extended the work of the institution beyond the campus. Most of these early activities were not, however, related to agriculture. It was not until the beginning of the 20th century, when colleges in the United States started conducting demonstrations at agricultural shows and giving lectures to farmer’s clubs, that the term \"extension service\" was applied to the type of work that we now recognize by that name.\n\nIn the United States, the Hatch Act of 1887 established a system of agricultural experiment stations in conjunction with each state's land-grant university, and the Smith-Lever Act of 1914 created a system of cooperative extension to be operated by those universities in order to inform people about current developments in agriculture, home economics, and related subjects.\n\nThe development of extension services in modern Asia has differed from country to country. Despite the variations, it is possible to identify a general sequence of four periods or \"generations\":\n\n\nThe fourth generation is well established in some countries, while it has only just begun in other places. While it seems likely that participatory approaches will continue to spread in the next few years, it is impossible to predict the long-term future of extension. Compared to 20 years ago, agricultural extension now receives considerably less support from donor agencies. Among academics working in this field, some have recently argued that agricultural extension needs to be reinvented as a professional practice. Other authors have abandoned the idea of extension as a distinct concept and prefer to think in terms of \"knowledge systems\" in which farmers are seen as experts rather than adopters.\n\nAspects of future extension education:\n\n\nSeveral of the institutional innovations that have come up in response to the weaknesses in public research and extension system have given enough indications of the emergence of an agricultural innovation system in India. This has resulted in the blurring of the clearly demarcated institutional boundaries between research, extension, farmers, farmers' groups, NGOs and private enterprises. Extension should play the role of facilitating the access to and transfer of knowledge among the different entities involved in the innovation system and create competent institutional modes to improve the overall performance of the innovation system. Inability to play this important role would further marginalize extension efforts.\n\nThe term \"extension\" has been used to cover widely differing communication systems. Two particular issues help to define the type of extension: how communication takes place, and why it takes place.\n\nThe related but separate field of agricultural communication has emerged to contribute to in-depth examinations of the communication processes among various actors within and external to the agricultural system. This field refers to the participatory extension model as a form of public relations-rooted two-way symmetric communication based on mutual respect, understanding, and influence between an organization and its stakeholders.\n\nAgricultural communication can take three modes—face-to-face training, training \"products\" such as manuals and videos, or information and communication technologies (ICTs), such as radio and short message system (SMS). The most effective systems facilitate two-way communication and often combine different modes.\n\nAny particular extension system can be described in terms of both how communication takes place and why it takes place. It is not the case that paternalistic systems are always persuasive, nor is it the case that participatory projects are necessarily educational. Instead there are four possible combinations, each of which represents a different extension paradigm, as follows:\n\n\nThere is some disagreement about whether or not the concept and name of 'extension' really encompasses all four paradigms. Some experts believe that the term should be restricted to persuasive approaches, while others believe it should only be used for educational activities. Paulo Freire has argued that the terms ‘extension’ and ‘participation’ are contradictory. There are philosophical reasons behind these disagreements. From a practical point of view, however, communication processes that conform to each of these four paradigms are currently being organized under the name of extension in one part of the world or another. Pragmatically, if not ideologically, all of these activities are considered to be represented in agricultural extension.\n\n\n"}
{"id": "1260747", "url": "https://en.wikipedia.org/wiki?curid=1260747", "title": "Alliance for the Future of Kosovo", "text": "Alliance for the Future of Kosovo\n\nThe Alliance for the Future of Kosovo (, AAK) is a political party in Kosovo. It was formed on 29 April 2001.\n\nThe current president of the party is Ramush Haradinaj. In December 2004 the parliament elected him as Prime Minister of Kosovo and he formed a coalition government with the largest party, the Democratic League of Kosovo (LDK). He resigned as Prime Minister in March 2005 after learning that he had been indicted by the International Criminal Tribunal for the former Yugoslavia, for 37 counts of war crimes. He received a full acquittal from the Tribunal on 3 April 2008. He returned to Kosovo and immediately resumed his duties as president of the party.\n\nThe AAK currently has three deputy presidents: Blerim Shala, Naim Maloku and Ahmet Isufi.\n\nThe current Secretary General is Burim Ramadani and the Secretary of Organisation is Ibrahim Selmanaj.\n\nAt the last legislative elections held on 17 November 2007, the alliance won 9.6% of the popular vote and 10 out of 120 seats in the Assembly of Kosovo, which made it the fifth largest political force. This was a gain on the previous two legislative elections in 2001 and 2004 in which the AAK won 7.8% and 8.4% of the popular vote, respectively.\n\nThe AAK's eleven current members of parliament are: Ardian Gjini, who is the leader of the parliamentary caucus, Ahmet Isufi, Daut Haradinaj, Kimete Bajraktari, Burim Ramadani, Bali Muharremaj, Donika Kadaj, Blerim Shala, Teuta Haxhiu, Ramiz Kelmendi and Time Kadrijaj\nalso serves as the AAK's member of the Assembly Presidency.\n\nAt the municipal elections held on 17 November 2007, the AAK gained control of 3 municipalities in western Kosovo: Peć, Đakovica and Deçan.\n\nAt the municipal elections held on 15 November 2007, the party gained 8 of 37 municipalities of Kosovo.\n\nAAK is located slightly to the right on the political spectrum.\n\nThe party flag is red, black and white. White represents peace; red and black are the national colours of the 96% Albanian majority of Kosovo.\n\nThe choice of the party's name, Alliance for the Future of Kosovo (AAK) is explained in Ramush Haradinaj's second book. Whereas previous Kosovo party acronyms began with consonants, a vowel was chosen for AAK because it seems less harsh and more open. The word \"future\" was chosen to mark a break with the old communist tendency to reflect backwards upon one's history. Finally, \"alliance\" was chosen because of its association with the NATO alliance which is much revered in Kosovo for its intervention in the Kosovo War of 1999, and also because of it evokes the idea of working together to achieve one's aims.\n\nThe alliance was originally formed by several smaller parties:\n\n\n"}
{"id": "2904705", "url": "https://en.wikipedia.org/wiki?curid=2904705", "title": "Azodicarbonamide", "text": "Azodicarbonamide\n\nAzodicarbonamide, or azo(\"bis\")formamide, is a chemical compound with the molecular formula CHON. It is a yellow to orange-red, odorless, crystalline powder. \nIt is prepared in two steps via treatment of urea with hydrazine to form hydroazodicarbonamide, as described in this idealized equation:\n\nOxidation of the resulting hydrazine derivative with chlorine or chromic acid yields the azodicarbonamide:\n\nThe principal use of azodicarbonamide is in the production of foamed plastics as a blowing agent. The thermal decomposition of azodicarbonamide results in the evolution of nitrogen, carbon monoxide, carbon dioxide, and ammonia gases, which are trapped in the polymer as bubbles to form a foamed article\n\nAzodicarbonamide is used in plastics, synthetic leather, and other industries and can be pure or modified. Modification affects the reaction temperatures. Pure azodicarbonamide generally reacts around 200 °C. In the plastic, leather, and other industries, modified azodicarbonamide (average decomposition temperature 170 °C) contains additives that accelerate the reaction or react at lower temperatures.\n\nAn example of the use of azodicarbonamide as a blowing agent is found in the manufacture of vinyl (PVC) and EVA-PE foams, where it forms bubbles upon breaking down into gas at high temperature. Vinyl foam is springy and does not slip on smooth surfaces. It is useful for carpet underlay and floor mats. Commercial yoga mats made of vinyl foam have been available since the 1980s; the first mats were cut from carpet underlay.\n\nAs a food additive, azodicarbonamide is used as a flour bleaching agent and a dough conditioner. It reacts with moist flour as an oxidizing agent. The main reaction product is biurea, a derivative of urea, which is stable during baking. Secondary reaction products include semicarbazide and ethyl carbamate. It is known by the E number E927. Many restaurants in the US fast food industry removed the additive in response to negative publicity.\n\nIn a 1999 report, the World Health Organization has linked exposure to azodicarbonamide at workplaces where it is manufactured or handled in raw form to \"respiratory issues, allergies and asthma\". The available data are restricted to these occupational environments. Exposure of the general public to azodicarbonamide could not be evaluated because of the lack of available data. The WHO concluded, \"The level of risk is uncertain; hence, exposure levels should be reduced as much as possible\".\n\nIn some jurisdictions, the use of azodicarbonamide as a flour bleaching agent has been phased out. For example, it is no longer authorized for use in Australia and the European Union as a food additive. Azodicarbonamide as a blowing agent in plastics has been banned in the European Union since August 2005 for the manufacture of plastic articles that are intended to come into direct contact with food. In the UK, the Health and Safety Executive has identified azodicarbonamide as a respiratory sensitizer (a possible cause of asthma) in workplace settings and determined that containers of it should be labeled with \"May cause sensitisation by inhalation.\" \nIn the United States, azodicarbonamide has a generally recognized as safe (GRAS) status and is allowed to be added to flour at levels up to 45 ppm. However, use in products intended for human consumption is in decline under pressure of the public opinion. In 2014, amid public discomfort with the dual uses of azodicarbonamide, the sandwich franchise Subway and hamburger franchise Wendy's announced that they would no longer use it as a dough conditioner. Currently, the Center for Science in the Public Interest stated azodicarbonamide \"has been poorly tested\" and advocates for reducing the amount of azodicarbonamide that is allowed to be used in food.\n\nAzodicarbonamide was added to the REACH Regulation candidate Substances of Very High Concern list in 2012.\n\n"}
{"id": "38963256", "url": "https://en.wikipedia.org/wiki?curid=38963256", "title": "Barack Obama Democratic Club of Upper Manhattan", "text": "Barack Obama Democratic Club of Upper Manhattan\n\nThe Barack Obama Democratic Club of Upper Manhattan is a reform-oriented political club in New York City focused on progressive activism and electing progressive candidates to local office. The club serves the neighborhoods of Washington Heights, Inwood, and West Harlem/Hamilton Heights.\n\nThe Obama Club was founded in 2009 by Mark Levine, a Democratic District Leader and Northern Manhattan political activist. The group emerged from the grassroots network of Upper Manhattan volunteers which coalesced around the 2008 presidential campaign of Barack Obama.\n\nSince its founding the Obama club has become known for its ethnically diverse membership and its grassroots activism. Issues the club has focused on include immigration, affordable housing, economic justice, and marriage equality. Club volunteers have helped elect a variety of progressive local candidates, including Public Advocate Bill de Blasio, Sen. Adriano Espaillat, Attorney General Eric Schneiderman, Comptroller John Liu, and Assm. Gabriela Rosa.\n\n"}
{"id": "15640458", "url": "https://en.wikipedia.org/wiki?curid=15640458", "title": "Chief strategy officer", "text": "Chief strategy officer\n\nA chief strategy officer (CSO), or chief strategist, is an executive responsible for assisting the chief executive officer (CEO) with developing, communicating, executing, and sustaining corporate strategic initiatives. Some companies give the title Chief Business Officer to its senior executives who are holding the top strategy role.\n\nToday, many CEOs have less time to devote to executing strategy, while at the same time uncertain environments increase the need for professional strategy development. As a result, Chairmen, Presidents, and CEOs in academic, nonprofit and corporate organizations are appointing CSOs. In recent years, the CSO position increased in popularity, which is reflected by the high number of US companies (nearly 50% of S&P 500 firms) who created CSO positions in their top management teams.\n\nThe CSO is a consultative role; part leader and part doer, with the responsibility of ensuring that execution of the strategy supports the strategy elements. This unique background takes a multitude of different operating experiences, and must include being both a creative thinker and influential collaborator. CSOs are often executives who have worn many hats at a variety of companies or agencies before taking on the responsibilities and tasks that come with the job title.\n\nTypical CSO responsibilities include:\n\nIn terms of the CSO’s role, which varies significantly from organization to organization and evolves over time, the two basic roles \"strategy developer\" and \"strategy implementer\" are observable. This dichotomy can be further divided into four CSO archetypes.\n\nA Chief Global Strategist (CGS) is one of the highest-ranking corporate officers, administrators, corporate administrators, executives, or executive officers, in charge of the global strategy and the domestic and international expansion of a corporation, company, organization, or agency.\n\nThe position is relatively new in the private sector, and a reflection of the influence of globalization upon companies and other organizations that seek to expand their influence, whether as a matter of necessity to survive, or the exploration of an opportunity.\n\nA prominent example of a CGS is Howard Schultz of Starbucks Corporation who was Chairman and CEO; however, in 2000 he left the position of CEO to become the Chief Global Strategist. Schultz returned to his previous role as CEO on January 18, 2008.\n"}
{"id": "13545111", "url": "https://en.wikipedia.org/wiki?curid=13545111", "title": "Child and family services", "text": "Child and family services\n\nChild and family services is a government and/or non-profit organisation designed to better the well being of individuals who come from unfortunate situations, \"environmental\" or \"biological\". People who seek or are sought after to participate in these homes have no other resource to turn to. Children might come from abusive or neglectful homes, or live in very poor and dangerous communities. There are also agencies that cater to people who have biological deficiencies. Families that are trying to live in stable lives come to non-profit organisations for hope of a better future. Child and family services cater to many different types of people who are all in different situations. These services might be mandated through the courts via a governmental child protection agency or they might be voluntary. Child and family services may be mandated if:\n\nThe history of the United States' response to child abuse and neglect has been marked by a tension between two missions:\n\nThe legal basis for efforts to protect needy children in colonial times rested on the English Poor Law of 1601. This placed the public responsibility for the poor in the hands of local townspeople. Parents were not held accountable for their children, which lead parent’s to tend to neglect their children and their duties as a parent. The attention of community leaders, philanthropists, and social reformers who were concerned about child abuse and neglect focused primarily on the children of the poorest families and on those who were orphaned, abandoned, or unsupervised.\n\nDuring most of the 19th century, destitute children were sent to institutions operated by private charitable organizations. Many poor or abandoned children were sent to live in almshouses—facilities established in the 19th century in many large cities to house the very poor of all ages. Almshouses provided minimal standard of care to orphaned or needy children and to impoverished, insane, or diseased adults. The almshouses caused the children greater hardships because they were subject to disease and chaos.\n\nThe second half of the 20th century saw increasing criticism of the impacts the unsanitary, chaotic almshouses had on children, especially the very young, who suffered high mortality rates there. Due to this, private charities and religious groups began to establish orphanages or children's asylums to separate needy children from adults and protect them from disease, maltreatment, and such. Many parents were losing custody of their children because the private organizations were able to prove they would be able to take care of the children in need better than their parents could. Children began to feel disconnected from their parents because they had been placed to grow up with other families.\n\nChild and family services have significantly developed over the last few centuries. Many different forms of help for children and families in need were offered throughout the community. Today we have many different agencies to help with the welfare and survival of many children and their families. However, years ago, many people relied on their community and religion to get them through tougher times. The community's investment in the well-being of its children is reflected in the cultural mores and social norms, and in legal frameworks that permit intervention in individual families when children are abused or neglected.\n\nThe formal system through which society responds to child abuse and neglect is now largely a governmental one. Today, primary responsibility for child protection is vested in public child protective services (CPS) agencies, which receive, investigate, and respond to reports of child abuse and neglect. These agencies are usually linked to child welfare departments with broader responsibilities which include foster care and adoption. Usually at this point, the parents lose their right to take care of their children because they are seen to be unfit parents. Today, it is against the law to not report child abuse if evident. Many parents do not realize that they are candidates for the potential loss of their children to government agencies because of their issues, such as poverty, mental illness, or neglect that lead to child abuse.\n\nCensus data shows that in the United States almost half of all children live in low-income families. Research suggests a critical connection between parent well-being and the child’s emotional, physical, and economic well-being; as well as, a connection to the child’s educational and workforce success. Despite the crucial connection between parent and child well-being, many services designed to help low-income families target either the parent or the child, leaving someone behind. Two-generation family programs coordinate services that aid low-income parents and children simultaneously, putting the whole family on a path to success.\n\nTwo generation family services aim to end the inter-generational cycle of poverty by moving families to economic stability and security through education, workforce training, and related support services. Though each two generation program approach is different they all have three intentionally linked components: education and/or job training for parents that leads to family-supporting employment, high quality early childhood education, and family support services.\n\nTwo generation family programs aim to get parents to a place of economic stability and security where they can secure employment that enables them to support their family and improve child outcomes. Programs aid parents in getting to economic security through education and job training opportunities. Two generation program educational opportunities typically involve general educational development (GED) courses, and connections to post-secondary education supports, such as, financial aid or access to full-day childcare. In addition to education services, two generation family programs often utilize sector-based workforce development. This type of workforce development targets job training for specific industries that will meet regional workforce needs, increasing the chances that graduates of the program will be able to find work.\n\nTwo generation family programs include high quality early childhood education that nurtures children's learning and development. Investing in high quality early childhood education that extends from pre-K through third grade improves educational achievement throughout schooling and success in the workforce. Programs can utilize existing early childhood development programs (i.e. Early Start or Head Start) and add two-generation elements such as offering full-day/full-year services to support working parents.\n\nTwo-generation family programs offer comprehensive wraparound services to support families. Examples of these support services include access to physical and mental health services for children, career coaches, case managers, family planning, and food assistance. These services aim to help expand family resources and support networks.\n\nResearch suggests that child care is a critical component of livable communities for many families in urban, suburban, and rural areas, and that local planning policies can play an important role in ensuring adequate child care. The majority of parents who work depend upon formal, organized out-of-home care.\n\nStudies show that families are paying a significant part of their earnings for child care. Between 2011 and 2012, the cost of child care increased at up to eight times the rate of increases in family income. For a four-year-old child, center-based care ranges from about $4,300 in Mississippi to $12,350 in Massachusetts. Lower income families have been disproportionately affected by these increases in child care costs. Working families at or near the poverty line did not receive any or enough child care assistance to be able to stay employed and off welfare, and only 12% to 15% of eligible families were served by a Child Care Development Fund subsidy in 1998–1999.\n\nChild care subsidies is an option used in many states to help parents pay for child care. These subsidies aid low-income families with children under age 13 in paying for child care so that parents can work or participate in training or education activities. Parents typically receive subsidies in the form of vouchers that they can use with a provider (e.g. relative, neighbor, child care center, or after-school program.)\n\nAdditional government programs aim to make child care more affordable. Medium and low income families receive earned income tax credits to compensate for money they allocated to child care arrangements. Individuals may claim up to $3,000 of expenses paid in a year for one qualifying individual (a dependent child age 12 or younger) or $6,000 for two or more qualifying individuals on their tax return. Benefits from the refundable Earned Income Tax Credit (EITC) concentrate on low-income families. In contrast, the dependent exemption and the virtually nonrefundable Child Tax Credit (CTC) benefited higher income families with benefits gradually increasing as a person’s tax liability increased.\n\nUniversal child care is another way to make child care more widely accessible. For example, in Sweden, public childcare is guaranteed to all parents and it operates on a whole-day basis. Parental fees are directly proportional to parents' income and inversely proportional to the number of children in a family.\n\nFinally, another viable option is to increase tax credits for low and medium income families. Currently, President Barack Obama has outlined a plan to triple the child tax care credit to $3,000 per young child.\n\nThe demands that urbanization, industrialization, and immigration placed on poor and working-class families in the late 19th century left many children unattended. Rural states relied on family placements to care for their own homeless or dependent children. This was a precursor for today's foster care system.\n\nAs a general progressive agenda of social reform was adapted in the early years if the 20th century, the approach of assisting parents to care for their children was more widely endorsed. A new policy was issued, stating, \"No child should be removed from the home unless it is impossible to construct family conditions or to build and supplement family resources as to make the home safe for the child...\"\nThere is still evidence from the 19th century of abandoned children. A 137-year-old foundation for children called New York Foundling Asylum has recently discovered letters from the parents who had abandoned their children in front of the agency because they were unable to care for them. New York Foundling Asylum was a family service agency that cared for thousands of children who had no homes and needed help, otherwise they would have been left on the cold street. This foundation saved thousands of lives and set a tone for other private organizations to contribute as well.\n\n\n"}
{"id": "2273310", "url": "https://en.wikipedia.org/wiki?curid=2273310", "title": "Citizens Centre for Freedom and Democracy", "text": "Citizens Centre for Freedom and Democracy\n\nThe Citizens Centre for Freedom and Democracy is a Canadian non-profit organization based in Edmonton, Alberta, promoting responsible government and advocating provincial rights, Senate reform, and judicial restraint.\n\nThe Citizens Centre for Freedom and Democracy was established in 2003, by Link Byfield, a journalist and businessman best known as a writer, editor, and publisher of the \"Alberta Report\" magazine, and one of Alberta's senators-in-waiting. Byfield was the centre's founding chairman. Its operations manager is Craig Docksteader, formerly of the Canadian Taxpayers Federation.\n\nIn October 2006, the Centre hosted the Calgary Congress, which explored Canadian federalism. Attendees included Preston Manning, Ralph Klein, Jason Kenney, and separatist Leon Craig. The congress concluded by advocating a rebalancing of confederation in conformation, making provinces fully responsible for their own internal social and economic affairs, the advocacy of an elected Senate to represent and protect the provinces, and the creation of counterbalances against centralizing tendencies and against expanding influence of Canada's Charter of Rights and Freedoms.\n\nThe Citizens Centre for Freedom and Democracy promotes government that act with the following characteristics.\n\n\nIn June 2007, the Citizens Centre decided to abandon its earlier decision to remain a non-partisan lobby group, and instead to enter the political arena by forming the Wildrose Alliance Party.\n\n"}
{"id": "40132938", "url": "https://en.wikipedia.org/wiki?curid=40132938", "title": "Collective impact", "text": "Collective impact\n\nCollective Impact (CI) is the commitment of a group of actors from different sectors to a common agenda for solving a specific social problem, using a structured form of collaboration. The concept of collective impact was first articulated in the 2011 Stanford Social Innovation Review article \"Collective Impact\", written by John Kania, Managing Director at FSG, and Mark Kramer, Kennedy School at Harvard and Co-founder FSG. Collective impact was chosen as the #2 philanthropy buzzword for 2011, and has been recognized by the White House Council for Community Solutions as an important framework for progress on social issues.\n\nThe concept of collective impact hinges on the idea that in order for organizations to create lasting solutions to social problems on a large-scale, they need to coordinate their efforts and work together around a clearly defined goal. The approach of collective impact is placed in contrast to “isolated impact,” where organizations primarily work alone to solve social problems and draws on earlier works on collaborative leadership, focused on collective goals, strategic partnerships, collective and independent action aligned with those goals, shared accountability, and a backbone \"institutional worrier\". Collective impact is based on organizations forming cross-sector coalitions to make meaningful and sustainable progress on social issues.\n\nHank Rubin (author of \"Collaborative Leadership: Developing Effective Partnerships for Communities and Schools\", Corwin press, 2009) and Leonard Brock (director of the Rochester NY Anti-Poverty Initiative) offer a practical description of collective impact by contrasting it with collaboration: “Collective impact really is much more than collaboration! Collaboration happens when we meet together; collective impact is what we do when we’re alone … Collaboration happens when we choose to sit in the same room and work together on the same project because we share an interest in accomplishing a shared goal … On the other hand, collective impact focuses on change inside each partner organization. It begins when we, as a community, agree to a set of shared outcomes … and then, individually, go back into our home organizations, work with our staffs, boards, and volunteers to figure out what we – individually and organizationally – can best do to achieve those shared goals and then choose to make changes to accomplish this. When each of our organizations chooses to shift and align our own work and priorities in this way, we set changes in motion in all portions of our community. And these changes will last a long time.”\n\nInitiatives must meet five criteria in order to be considered collective impact:\n\nCollective impact initiatives have been employed for a issues including education, health and healthcare, animal welfare, homelessness, poverty reduction, and youth and community development. Examples include: The Strive Partnership educational initiative in Cincinnati, the environmental cleanup of the Elizabeth River in Virginia, the Shape Up Somerville campaign against childhood obesity in Somerville, Mass, and the work of the Calgary Homeless Foundation in Calgary, Canada.\n\nPartners in Progress (PIP), an initiative of the Citi Foundation and the Low Income Investment Fund, supports a broad range of projects that use a collective impact approach to address the issues of poverty and urban transformation. It emphasizes collaborative approaches to these issues, particularly at neighborhood and regional levels, guided by a local community leader (known as a “community quarterback” or “backbone organization”). Its projects are also focused on data collection to show what is or isn’t working. The projects range from engaging hospital, city and community organizations to improve health in an Oakland neighborhood, to uniting city officials, employers, and the community around jobs in Brooklyn, to using transit as a hub for health, housing, and economic development in Dallas.\n\nThe White House Council for Community Solutions has recognized the potential of collective impact to play a major role in transforming the ways in which communities approach their social problems. A 2012 report for the Council found that, among 12 “needle-moving community collaboratives” that had achieved at least 10 percent progress in a community wide metric, all 12 met the conditions of collective impact.\n\nThe White House Council's work in collective impact is being continued today by the Aspen Forum for Community Solutions. In 2014 iit launched the Collective Impact Forum (n partnership with FSG,), an online community to support those practicing collective impact.\n\nThe Promise Neighborhoods Institute is a PolicyLink initiative to unite diverse American communities on improving educational and developmental outcomes of children in underserved areas. More than 50 communities have contributed neighborhood data, mobilized local leaders, launched advocacy campaigns and started multi-sector partnerships to demand federal-level policy changes to fund “cradle to college” programs nationwide.\n\nThe United States Breastfeeding Committee (USBC) is the “backbone organization” for a nationwide coalition of 50 healthcare organizations that support healthy breastfeeding initiatives. Goal #3 of the 2014 USBC Strategic Framework is “engage stakeholders in a collective impact model”. In 2017, the USBC updated its strategy to emphasize its organizational commitment to breastfeeding health equity. This reflects current demands from critics who want a general frame of equity added to the collective impact model framework.\n\nCorporate CEOs, small business leaders, non-profit and social-sector executives, government officials and community service practitioners have made contributions to the evolving concept in the form of insights, feedback and critique.Community psychologist Tom Wolff argues that John Kania and Mark Kramer’s concept of collective impact “fails to adequately acknowledge, understand, and address” the framework in the context of community organizing. He lists the following \"Ten Places Where Collective Impact Gets It Wrong\" \nWolff’s claim that collective impact is a “failed model” has caught the attention of community service practitioners who are also skeptics of the model’s “five conditions”. Calling it a top-down model for excluding community members as key stakeholders and partners of collaboration, Wolff has attracted input from many other non-profit and social-sector critics who also want the model to add elements of diversity and inclusion, civic participation, social justice and equity.\n\nSocial sector leaders echo these critiques in publications like \"The Philanthropist\", calling the five-pillared framework too simple for its intended purpose of tackling complex problems. Drawing similarities between CI and other previously-popular but failed models of collaboration, community activists struggle to believe that CI has what it takes to build long-term, sustainable, conflict-free solutions to social justice issues. Pointing out several well-known case studies that underscore a real need for increased grassroots advocacy efforts, many critics believe Kania & Kramer conducted inadequate research before designing their model.\n\nIn 2015, PolicyLink published a report called \"Equity: the soul of collective impact\", which identified racial and economic equity as the most vital missing pieces of Kania & Kramer’s concept. With no mention of equity in the CI framework, PolicyLink executives argue that CI initiatives fail to address tense power dynamics that continue to polarize American communities and therefore impede progress on social change.\n\nWith high demand for adding a new equity frame to the original framework, Living Cities has partnered with The Collective Impact Forum to work exclusively on reforming the model for this purpose. Founders Kania & Kramer, as well as organizations like PolicyLink, Aspen Forum for Community Solutions and Urban Strategies Council have also joined this effort, signaling that opinions from the field have been taken seriously, helping the concept adapt and grow with transparency and flexibility. Ongoing discussions and updates are viewable at the Collective Impact Forum website where public input and participation is encouraged as CI continues to evolve with increased attention to community needs.\n\nFounding authors Kania and Kramer have responded to critics expressing appreciation for their interest and perspective on the topic, encouraging their continued input throughout the process to refine the model.\n\n“As this movement continues to evolve, we look forward to additional contributions such as Wolff’s published editorial (and the myriad of contributions we list here, as well as many others) that can deepen understanding of how best to practice collective impact in a manner that leads to a more just and equitable world”. \n\nWolff however, believes the model is flawed beyond repair and needs full replacement rather than reform. Suggesting six principles in the NonProfit Quarterly’s 2017 \"Collaborating for Equity and Social Justice Toolkit\", Wolff empowers social innovators and thought leaders to design collaboration models for the future that will “leave the power in the hands of community residents”.\n\n"}
{"id": "28824063", "url": "https://en.wikipedia.org/wiki?curid=28824063", "title": "Commander's Emergency Response Program", "text": "Commander's Emergency Response Program\n\nCommander's Emergency Response Program or CERP is money for military commanders to use for conducting rebuilding and reconstruction during the Iraq and Afghanistan Wars. It was initially money seized during the invasion of Iraq, but later was also U.S. Federally appropriated funds.\nThe military must use the money for the benefit of the Iraqi or Afghan people, such as public roads, schools and medical clinics or humanitarian aid. The funds for CERP come from the Department of Defense. The use of funds in the field can be authorized by military commanders at the brigade level. The rules governing the use of such funds will be based on any Congressional restrictions in the legislation, and will be tailored to the needs of the particular operation.\n"}
{"id": "141924", "url": "https://en.wikipedia.org/wiki?curid=141924", "title": "Common Agricultural Policy", "text": "Common Agricultural Policy\n\nThe Common Agricultural Policy (CAP) is the agricultural policy of the European Union. It implements a system of agricultural subsidies and other programmes. It was introduced in 1962 and has undergone several changes since then to reduce the cost (from 71% of the EU budget in 1984 to 39% in 2013) and to also consider rural development in its aims. It has been criticised on the grounds of its cost, and its environmental and humanitarian impacts.\n\nThe circumstance that led to the development of the CAP occurred in the late 1950s to late 1960s. At the time, there was no example of a successful agricultural integration in Europe. However, two main factors contributed to the creation of this policy. This includes the promise EEC made to France bargaining the integrated agriculture policy in favor of France's part in ratifying the Treaty of Rome and due to a lack of substantial policy in agriculture beyond a few pre-existing legal stipulations that some considered, “weak, vague and highly underdeveloped.” Thus, leading to the creation of article 39 in a set of five social and economic objectives. As part of building a common market, tariffs on agricultural products would have to be removed. However, the political clout of farmers and the sensitivity of the issue made it take many years before the CAP was fully implemented.\n\nThe Spaak Report of 1956 stated that a European common market that excluded agriculture was unthinkable. It argued that security of food supply was paramount and raised a series of questions about agriculture that needed to be answered by policy-makers. The Treaty of Rome, signed in March 1957, established the European Economic Community and it was mainly due to the French pressure that the Treaty included agriculture. However, due to disagreements within the Six over agricultural policy, the articles on agriculture were vague and policy making was left until after the Treaty had been signed.\n\nArticle 39.1 of the Treaty set out the objectives of the CAP: to increase productivity through technical progress and the best use of the factors of production (such as labour); to ensure a fair standard of living for communities employed in agriculture; to stabilise markets; to secure the availability of supplies; and to enforce fair prices. Article 39.2 stated that policy makers must take into account three factors: the circumstances of each agricultural activity due to the social structure of agricultural communities and the inequalities between richer and poorer regions; the need to act gradually to allow agriculture sufficient time to adjust; and to remember that agriculture was heavily integrated in the wider economy.\n\nArticle 40 provided for the common organisation of markets and common prices, along with a fund to pay for it. Article 41 allowed for the introduction of additional measures to implement Article 39, such as the co-ordination of vocational education and research, the \"dissemination of agricultural knowledge\" and the encouragement of consumption of certain goods. Article 42 allowed the Council of the Community to decide how far the regulations on competition could apply to agriculture. This Article also allowed them to grant aid.\n\nDuring 3–12 July 1958 in Stresa, the Community held an agricultural conference attended by agricultural ministers from member states and the President of the European Commission, Walter Hallstein, along with observers representing agriculture. Three working parties at the conference investigated: the current state of agriculture and the agricultural policies of member states; the short-term effects of the implementation of the Rome Treaty; and the long-term aims of the CAP. In a speech to the conference, Hallstein complained of urbanisation that was leading to rural depopulation and he lamented the \"clash of cultures\" in which rural life and rural values were considered inferior. Hallstein also reflected on the Cold War threat from communism:\n\nIt is the core of Europe's achievements which is under threat: a whole civilization which rests on the inalienable freedom and dignity of the individual...this tragedy of liberty is also a tragedy of the rural class. Let us look around us, and, alas, we have not far to look; the rural class is its first victim. It is for this reason that we are convinced that the European rural class will count among the most trustworthy pillars of our unified European market. Because its fate is also at stake, and is one of the first threatened. In this room there is no one whose family tree doesn't reach back, sooner or later, to farming roots. We know what the rural class means to Europe, not only through its economic values, but also by its moral and social values.\n\nThe conference's Final Resolution argued for the vital importance of agriculture in economic and social life and expressed their unanimous wish to preserve the character of European farming, which was predominately based on small-size, family holdings. They agreed that it was necessary to help these farms increase their economic capacity and competitiveness. They also advocated structural changes to rationalise and cheapen production, which was intended to improve productivity. The Resolution also included a commitment to a price policy.\n\nTherefore, during 1958–1959, the Commission drafted the CAP and the Assembly commissioned reports into agriculture. The Commission submitted draft proposals in November 1959 (which were debated in the Assembly and by the Economic and Social Committee) and its final report in June 1960. In December the Council agreed to a system of import levies (for grain, sugar, pork, eggs and poultry) and to commodity regimes for agricultural produce. They also introduced the principle of Community Preference in the implementation of the levies and for the negotiation of commercial treaties with outside countries; this ensured that any trade concession granted to an outside country could not weaken the European producer in the Community market.\n\nIn 1962 the European Agricultural Guidance and Guarantee Fund was founded to provide money for the CAP's market regimes. A year later the Fund was split into two bodies, the Guarantee side implemented market and price support and the Guidance part supplied structural aid. A Community regulation of 1964 provided detailed arrangements for the working of the Fund, including for estimating export refunds, the Community's main tool for controlling the market. Market regimes had been implemented for most agricultural produce by the end of the decade. An agreement in 1966 facilitated the completion of the single market for agriculture (which came into effect a year later), a single price support system and uniform protection against imports from outside countries. Hallstein hailed this agreement as the single most important stage in forging European unity because it helped to complete the CAP.\n\nThe six member states individually strongly intervened in their agricultural sectors, in particular with regard to what was produced, maintaining prices for goods and how farming was organised. The intervention posed an obstacle to free trade in goods while the rules continued to differ from state to state since freedom of trade would contradict the intervention policies. Some members, particularly France, and all farming professional organisations wanted to maintain strong state intervention in agriculture. That could not be achieved unless policies were harmonised and transferred to the European Community level.\n\nBy 1962, three major principles had been established to guide the CAP: market unity, community preference and financial solidarity. Since then, the CAP has been a central element in the European institutional system.\n\nThe CAP is often explained as the result of a political compromise between France and Germany: German industry would have access to the French market; in exchange, Germany would help pay for France's farmers.\n\nThe CAP has always been a difficult area of EU policy to reform; it is a problem that began in the 1960s and one that has continued to the present, albeit less severely. Changes to the CAP are proposed by the European Commission, after a public consultation, which then sends its proposals to the Council and to the European Parliament. Both the Council and the European Parliament have to agree to any changes. The Parliament was involved in the process of change for the first time in 2013. The involvement of the Parliament, which represents the citizens, increases the democratic legitimacy of the CAP. Outside Brussels proper, the farming lobby's power has been a factor determining EU agricultural policy since the earliest days of integration.\n\nIn recent times change has been more forthcoming because of external trade demands and intrusion in agricultural affairs by other parts of the EU policy framework, such as consumer advocate working groups and the environmental departments of the Union. In addition, Euroscepticism in states such as the UK and Denmark is fed in part by the CAP, which Eurosceptics consider detrimental to their economies.\n\nProponents claim that the CAP is an exceptional economic sector as it protects the \"rural way of life\" although it is recognised that it affects world poverty.\n\nOn 21 December 1962, Sicco Mansholt, the European Commissioner for Agriculture, sent a memorandum to the Council of Ministers concerning agricultural reform in the European Community. This long-term plan, also known as the '1980 Agricultural Programme' or the 'Report of the Gaichel Group', named after the village in Luxembourg in which it had been prepared, laid the foundations for a new social and structural policy for European agriculture.\n\nThe Mansholt Plan noted the limits to a policy of price and market support. It predicted the imbalance that would occur in certain markets unless the Community undertook to reduce its land under cultivation by at least five million hectares. Mansholt also noted that the standard of living of farmers had not improved since the implementation of the CAP despite an increase in production and permanent increases in Community expenditure. He, therefore, suggested that production methods should be reformed and modernized and that small farms, which were bound to disappear sooner or later, according to Community experts, should be increased in size. The aim of the Plan was to encourage nearly five million farmers to give up farming. That would make it possible to redistribute their land and increase the size of the remaining family farms. Farms were considered viable if they could guarantee for their owners an average annual income comparable to that of all the other workers in the region. In addition to vocational training measures, Mansholt also provided for welfare programmes to cover retraining and early retirement. Finally, he called on the Member States to limit direct aid to unprofitable farms.\n\nFaced with the increasingly angry reaction of the agricultural community, Mansholt was soon forced to reduce the scope of some of his proposals. Ultimately, the Mansholt Plan was reduced to just three European directives, which, in 1972, concerned the modernization of agricultural holdings, the cessation of certain agricultural activity and the training of farmers.\n\nHurt by the failure of Mansholt, would-be reformers were mostly absent throughout the 1970s, and reform proposals were few and far between. A system called \"Agrimoney\" was introduced as part of the fledgling EMU project but was deemed a failure and did not stimulate further reforms.\n\nThe 1980s was the decade that saw the first true reforms of the CAP, foreshadowing further development from 1992 onwards. The influence of the farming bloc declined, and with it, reformers were emboldened. Environmentalists garnered great support in reforming the CAP, but it was financial matters that ultimately tipped the balance: due to huge overproduction the CAP was becoming expensive and wasteful. There was the introduction of a quota on dairy production in 1984 and, in 1988, a ceiling on EU expenditure to farmers. However, the basis of the CAP remained in place and it was not until 1992 that CAP reformers began to work in earnest.\n\nIn 1992, the MacSharry reforms (named after the European Commissioner for Agriculture, Ray MacSharry) were created to limit rising production, while at the same time adjusting to the trend toward a more free agricultural market. The reforms reduced levels of support by 29% for cereals and 16% for beef. They also created 'set-aside' payments to withdraw land from production, payments to limit stocking levels, and introduced measures to encourage retirement and afforestation.\n\nSince the MacSharry reforms, cereal prices have been closer to the equilibrium level, there is greater transparency in costs of agricultural support and the 'decoupling' of income support from production support has begun. However, the administrative complexity involved invites fraud, and the associated problems of the CAP are far from being corrected.\n\nOne of the factors behind the 1992 reforms was the need to reach agreement with the EU's external trade partners at the Uruguay Round of the General Agreement on Tariffs and Trade (GATT) talks with regards to agricultural subsidies.\n\nThe current reform issues in EU agriculture are: lowering prices, ensuring food safety and quality, and guaranteeing stability of farmers' incomes. Other issues are environmental pollution, animal welfare and finding alternative income opportunities for farmers. Some of these issues are the responsibility of the member states.\n\nThe 'Agenda 2000' reforms divided the CAP into two 'Pillars': production support and rural development. Several rural development measures were introduced including diversification, setting up producer groups and support for young farmers. Agri-environment schemes became compulsory for every Member State (Dinan 2005: 367). The market support prices for cereals, milk and milk products and beef and veal were step-wise reduced while direct coupled payments to farmers were increased. Payments for major arable crops as cereals and oilseeds were harmonised.\n\nThe introduction of the euro in 1999 also ended the use of green exchange rates such as the green pound.\n\nA 2003 report, commissioned by the European Commission, by a group of experts led by Belgian economist André Sapir stated that the budget structure was a \"historical relic\". The report suggested a reconsideration of EU policy, redirecting expenditure towards measures intended to increase wealth creation and cohesion of the EU. As a significant proportion of the budget is currently spent on agriculture and there is little prospect of the budget being increased, that would require reducing CAP expenditure. The report largely concerned itself to discussing alternative measures more useful to the EU, rather than discussing the CAP, but it also suggested that farm aid would be administered more effectively by member countries on an individual basis.\n\nThe report's findings were largely ignored. Instead, CAP spending was kept within the remit of the EU, and France led an effort to agree a fixed arrangement for CAP spending that would not be changed until 2012. It was made possible by advance agreement with Germany. It is that agreement that the UK currently wishes to see reopened, both in its efforts to defend the UK position on the UK rebate and also given that the UK is in favour of lowering barriers to entry for Third World agricultural exporters.\n\nOn 26 June 2003, EU farm ministers adopted a fundamental reform of the CAP, based on \"decoupling\" subsidies from particular crops. (Member states may choose to maintain a limited amount of specific subsidy.) The new \"single farm payments\" are subject to \"cross-compliance\" conditions relating to environmental, food safety and animal welfare standards. Many of them were already either good practice recommendations or separate legal requirements regulating farm activities. The aim is to make more money available for environmental quality or animal welfare programmes. The political scientist Peter Nedergaard has analysed the 2003 reform on the basis of rational choice theory and states that, \"In order to arrive at an adequate explanation, an account of the policy entrepreneurship on the part of Commissioner Franz Fischler must be given.\"\n\nDetails of the UK scheme were still being decided at its introductory date of May 2005. Details of the scheme in each member country may be varied subject to outlines issued by the EU. In England, the Single Payment Scheme provides a single flat rate payment of around £230 per hectare for maintaining land in cultivatable condition. In Scotland, payments are based on a historical basis and can vary widely. The new scheme allows for much wider non-production use of land that may still receive the environmental element of the support. Additional payments are available if land is managed in a prescribed environmental manner.\n\nThe overall EU and national budgets for subsidy have been capped. That prevents a situation in such the EU is required to spend more on the CAP than its limited budget has.\n\nThe reforms enter into force in 2004–2005. (Member states may apply for a transitional period delaying the reform in their country to 2007 and phasing in reforms until 2012)\n\nOne of the crops subsidised by the CAP is sugar produced from sugar beet; the EU is by far the largest sugar beet producer in the world, with annual production at 17 million metric tons. That compares to levels produced by Brazil and India, the two largest producers of sugar from sugar cane.\n\nSugar was not included in the 1992 MacSherry reform or in the 1999 Agenda 2000 decisions; sugar was also subject to a phase in (to 2009) under the Everything But Arms trade deal giving market access to least developed countries. As of 21 February 2006, the EU has decided to reduce the guaranteed price of sugar by 36% over four years, starting in 2006. European production was projected to fall sharply. According to the EU, this is the first serious reform of sugar under the CAP for 40 years. Under the Sugar Protocol to the Lome Convention, nineteen ACP countries export sugar to the EU and will be affected by price reductions on the EU market.\n\nThese proposals followed the WTO Appellate Body, largely upholding on 28 April 2005 the initial decision against the EU sugar regime.\n\nIn the autumn of 2007 the European Commission was reported to be considering a proposal to limit subsidies to individual landowners and factory farms to around £300,000. Some factory farms and large estates would be affected in the UK, as there are over 20 farms/estates receiving £500,000 or more from the EU.\n\nSimilar attempts have been unsuccessful in the past and were opposed in the UK by two strong lobbying organisations the Country Land and Business Association and the National Farmers Union. Germany, which has large collective farms still in operation in what was East Germany, also vigorously opposed changes marketed as \"reforms\". The proposal was reportedly submitted for consultation with EU member states on 20 November 2007.\n\nThe policy has evolved significantly since it was created by the Treaty of Rome (1957). Substantial reforms over the years have moved the CAP away from a production-oriented policy. The 2003 reform has introduced the Single Payment Scheme (SPS) or as it is known as well the Single Farm Payment (SFP). The most recent reform was made in 2013 by Commissioner Dacian Ciolos and applies for the period 2014 to 2020.\n\nEach country can choose if the payment will be established at the farm level or at the regional level. Farmers receiving the SFP have the flexibility to produce any commodity on their land except fruit, vegetables and table potatoes. In addition, they are obliged to keep their land in good agricultural and environmental condition (cross-compliance). Farmers have to respect environmental, food safety, phytosanitary and animal welfare standards. This is a penalty measure, if farmers do not respect these standards, their payment will be reduced.\n\nThe direct aids and market related expenditure made up 31% of the total EU budget in 2010. Together with 11% for Rural Development, the total CAP budget took 42% of the total EU budget The CAP budget has shrunk relatively from 71% in 1984 to an expected 39% of the total EU budget in 2013.\n\nIntervention mechanisms have diminished significantly, for instance the Commission only intervenes on: common wheat, butter, and skimmed milk powder. The Health Check of the CAP agreed in November 2008 has added on a number of measures to help the farmers to respond better to signals from the markets and to face new challenges. Among a range of measures, the agreement abolishes arable set-aside, increases milk quotas gradually leading up to their abolition in 2015, and converts market intervention into a genuine safety net. Ministers also agreed to increase modulation, whereby direct payments to farmers are reduced and the money transferred to the Rural Development Fund.\n\nMilk quotas expired in April 2015. To prepare the dairy farmers for this transition, a 'soft landing' has been ensured by increasing quotas by one percent every year between 2009–10 and 2013–14. For Italy, the 5 percent increase will be introduced immediately in 2009–10. In 2009–10 and 2010–11, farmers who exceed their milk quotas by more than 6 percent will have to pay a levy 50 percent higher than the normal penalty.\n\nSince 2000, the EU Rural Development Policy has been in effect, also known as the \"second pillar\" of the CAP. This policy aims to promote the economic, social and environmental development of the countryside. Its budget, 11% of the total EU budget, is today allocated along three axes. The first axis focuses on improving the competitiveness of the farm and forestry sector through support for restructuring, development and innovation. The second one concerns the improvement of the environment and the countryside through support for land management as well as helping to fight climate change. Such projects could for example concern preserving water quality, sustainable land management, planting trees to prevent erosion and floods. The third axis concerns improving the quality of life in rural areas and encouraging diversification of economic activity. The policy also provides support to the Leader rural development methodology, under which Local Action Groups design and carry out local development strategies for their area. Member States distribute \"second pillar\" funds through Rural Development Programme actions.\n\nThe European Commission discussed the next reform of the CAP, which will coincide with the next financial perspectives package, as from 2014. The Commissioner responsible for Agriculture and Rural Development Dacian Cioloş, has outlined seven major challenges that the future CAP needs to address: food production, globalisation, the environment, economic issues, a territorial approach, diversity and simplification.\n\nOn the 26th of June 2013 agreement was reached between the European Commission, the Council and the EU Parliament on the new CAP.\n\nSectors covered by the CAP\nThe common agricultural policy price intervention covers only certain agricultural products:\n\nThe coverage of products in the external trade regime is more extensive than the coverage of the CAP regime. This is to limit competition between EU products and alternative external goods (for example, lychee juice could potentially compete with orange juice).\n\nThe objectives, set out in Article 39 of the Treaty on the Functioning of the European Union, are as follows:\n\nThe CAP recognised the need to take account of the social structure of agriculture and of the structural and natural disparities between the various agricultural regions and to effect the appropriate adjustments by degrees.\n\nCAP is an integrated system of measures that works by maintaining commodity price levels within the EU and by subsidising production. There are a number of mechanisms:\n\nThe change in subsidies is intended to be completed by 2011, but individual governments have some freedom to decide how the new scheme will be introduced. The UK government has decided to run a dual system of subsidies in England, each year transferring a larger proportion of the total payment to the new scheme. Payments under the old scheme were frozen at their levels averaged over 2002–2003 and reduce each subsequent year. This allows farmers in England a period where their income is maintained, but which they can use to change farm practices to accord with the new regime. Other governments have chosen to wait, and change the system in one go at the latest possible time. Governments also have limited discretion to continue to direct a small proportion of the total subsidy to support specific crops. Alterations to the qualifying rules meant that many small landowners became eligible to apply for grants and the Rural Payments Agency in England received double the previous number of applications (110,000).\n\nThe CAP also aims to promote legislative harmonisation within the Community. Differing laws in member countries can create problems for anyone seeking to trade between countries. Examples are regulations on permitted preservatives or food colouring, labelling regulations, use of hormones or other drugs in livestock intended for human consumption and disease control, animal welfare regulations. The process of removing all hidden legislative barriers to trade is still incomplete.\n\nThe European Agricultural Guidance and Guarantee Fund (EAGGF) of the EU, which used to fund the CAP has been replaced in 2007 with the European Agricultural Guarantee Fund (EAGF) and the European Agricultural Fund for Rural Development (EAFRD). CAP reform has steadily lowered its share of the EU budget but it still accounts for nearly half of the EU expenditure. France is the biggest beneficiary of the policy by around 20%, followed by Germany and Spain (~13% each), Italy (~11%) and the UK (~9%).\n\nThe reformed common agricultural policy came into force in 2014. The Commission launched the CAP reform process with an extensive public debate on the future of the Cap between April and June 2010, followed by a public conference in July 2010, with around 600 participants. The purpose of the debate was to have different sectors of society taking part. \"The Common Agricultural Policy is not just a matter for experts. It's a policy for all Europeans\", said Commissioner Cioloş.\n\nBased on the wide-ranging public debate, on 18 November 2010, the Commission presented a Communication on \"The CAP towards 2020\" The Communication Paper outlined three options for the future CAP and launched a consultation with other institutions and stakeholders. Over 500 contributions were received, 44% of which came from the farming and processing sector. These contributions form an integral part of the Impact Assessment of the legal proposals. The impact assessment evaluates alternative scenarios for the evolution of the policy on the basis of extensive quantitative and qualitative analysis\n\nOn 12 October 2011 the Commission presented a set of legal proposals to reform the common agricultural policy (CAP) after 2013. Its stated aim is to guarantee European citizens healthy and quality food production, while preserving the environment.\n\nAccording to the proposal, the three broad objectives of the future CAP are: \"Viable food production\", \"Sustainable management of natural resources\" and \"Balanced territorial development\", which respond directly to the economic, environmental and territorial balance challenges identified in the Communication and which guide the proposed changes to the CAP instruments.\n\nDirect payments contribute to keeping farming in place throughout the EU territory by supporting and stabilising farmers' income, thereby ensuring the longer term economic viability of farms and making them less vulnerable to fluctuations in prices. They also provide basic public goods through their link with cross compliance.\n\nThe legal proposals aim to move away from the different systems of the Single Payments Scheme in the EU-15 (which allows for historical references, or a payment per hectare, or a \"hybrid\" combination of the two) and the Single Area Payments Scheme (SAPS) in most of the EU-12, a new \"Basic Payment Scheme\" will apply after 2013. This will be subject to \"cross compliance\" (respecting certain environmental, animal welfare & other rules), as at present, although there are various simplifications to the current requirement. It intends to reduce significantly the discrepancies between the levels of payments obtained between farmers, between regions and between Member States. All Member States will be obliged to move towards a uniform payment per hectare at national or regional level by the start of 2019. In line with the Commission proposals within the Multi-Annual Financial Framework, the national envelopes for direct payments will be adjusted so that those that receive less than 90% of the EU average payment per hectare will receive more. The gap between the amounts currently foreseen and 90% of the EU-27 average is reduced by one-third.\n\nThe legal proposals propose new concepts. Among them is the \"greening\" of direct payment. To strengthen the environmental sustainability of agriculture and enhance the efforts of farmers, the Commission is proposing to spend 30% of direct payments specifically for the improved use of natural resources. Farmers would be obliged to fulfil certain criteria such as crop diversification, maintenance of permanent pasture, the preservation of environmental reservoirs and landscapes.\n\nTo attract young people (under 40 years) into the farming business, the Commission is proposing that the Basic Payment to new entrant Young Farmers should be topped up by an additional 25% for the first 5 years of installation.\n\nAny farmer wishing to participate in the Small Farmers Scheme will receive an annual payment fixed by the Member State of between €500 and €1,000, regardless of the farm's size. (The figure will either be linked to the average payment per beneficiary, or the national average payment per hectare for 3 ha.). Participants will face less stringent cross-compliance requirements, and be exempt from greening.\n\nThis new definition is aimed to exclude payments to applicants who exercise no real or tangible agricultural activity on their land. The Commission is proposing that payments would not be granted to applicants whose CAP direct payments are less than 5% of total receipts from all non-agricultural activities This doesn't apply to farmers who receive less than 5 000 Euros in direct payments.\n\nThe amount of support that any individual farm can receive will be limited to €300,000 per year. However, to take employment into account, the holding can deduct the costs of salaries in the previous year (including taxes & social security contributions) before these reductions are applied. The funds \"saved\" will be transferred to the Rural Development envelope in the given country.\n\nAll payments will continue to be linked to the respect of a number of baseline requirements relating to environment, animal welfare and plant & animal health standards. However, cross compliance will be greatly simplified.\n\n\nThe Commission put forward its legislative proposals on 12 October 2011. The European Parliament and the Council, debated the text. The approval of the different regulations and implementing acts was received by mid-2013. The CAP reform came into force as from 1 January 2014.\n\nFor the first time both institutions (European Parliament and the Council) decided on an equal footing on the new agriculture legislative package.\n\nThe Lisbon Treaty, which came into force on 1 December 2009, has extended the legislative powers of the EP. On agricultural matters, now the European Parliament decides together with the Council in a procedure known as the co-decision procedure.\n\nThe CAP has been roundly criticised by many diverse interests since its inception. Criticism has been wide-ranging, and even the European Commission has long been persuaded of the numerous defects of the policy. In May 2007, Sweden became the first EU country to take the position that all EU farm subsidies should be abolished, except those related to environmental protection.\n\nMany developing countries are highly dependent on agriculture. The FAO finds that agriculture provides for the livelihood of 70% of the world's poorest people. As such, the subsidies in the CAP are charged with preventing developing countries from exporting agricultural produce to the EU on a level playing field. The WTO Doha Development Round, which intended to increase global development, has stalled due to the developed countries' refusal to remove agricultural subsidies.\n\nA review of post-2013 proposal by Prof. Alan Matthews underlines the lack of ambition in tackling the issue. \"This CAP reform was not intended to address the trade barriers used to keep some EU market prices higher than world market levels. The EU has reduced the effect of these barriers for a number of developing countries through extending the scope of preferential access under various trade agreements, and a further reduction is being negotiated in the WTO Doha Round. Nonetheless, developing countries will be disappointed that the opportunity was not taken in this reform to set a final date for the ending of export subsidies. A more ambitious CAP reform, in which the targeting of direct payments was pursued more insistently and coupled payments were phased out, would also have a greater effect in removing the remaining distortions caused by the CAP to world markets.\" In another study, Prof. Matthews showed how linking EU farm subsidies to goals such as environmental protection could help farmers in poor countries, although much depends on the size of the payments and how they are made.\n\nAt the same time, however, the EU remains the world's biggest importer of farm products from developing countries. On average, over the period 2006–2008, the EU has imported €53 billion worth of goods. This is more than the US, Japan, Canada, Australia and New Zealand combined. This is further encouraged by a preferential market access agreement for products from developing countries. Today, around 71% of the EU's agricultural imports originate from developing countries. The 'Everything but Arms' programme, gives the world's 49 least-developed countries duty-free and quota-free access to the EU market. Under the Economic Partnership Agreements, countries from the African, Caribbean and Pacific group enjoy full duty-free and quota free access.\n\nTo perpetuate the viability of European agriculture in its current state, the CAP-mandated demand for certain farm produce is set at a high level compared with demand in the free market (see ). This leads to the European Union purchasing millions of tonnes of surplus output every year at the stated guaranteed market price, and storing this produce in large quantities (leading to what critics have called 'butter mountains' and 'milk lakes'), before selling the produce wholesale to developing nations. In 2007 in response to a parliamentary written question the UK government revealed that over the preceding year the EU Public Stock had amassed \"13,476,812 tonnes of cereal, rice, sugar and milk products and 3,529,002 hectolitres of alcohol/wine\", although the EU has claimed this level of oversupply is unlikely to be repeated. This point was actually proven in January 2009, where the EU had a store of 717,810 tonnes of cereals, 41,422 tonnes of sugar and a 2.3 million hectolitre 'wine lake', showing that the stocks had diminished dramatically.\n\nThe food crisis in 2008, which saw the stocks empty out and the prices skyrocket, even introduced a popular demand for the introduction of emergency stocks of agricultural produce in the EU, which would help stabilise prices both on the very volatile markets. In 2010, the European Commission announced its intention to sell out of its cereal stocks to stabilise the situation after a Russian grain export ban had stung world markets, sending wheat prices to two-year highs and sparked worries of a crisis in global food supplies that could spark widespread strains and protests.\n\nIn 2010, the EU decided to use existing intervention stocks (cereals, milk powder and limited quantities of butter) for its \"Food Aid for the Needy\" scheme for 2011. An estimated 13 million poor Europeans benefit from this scheme.\n\nParts of the EU stocks are exported with the use of export subsidies. It is argued that many African and Asian dairy, tomato, grain and poultry farmers cannot keep up with cheap competition from Europe, thus their incomes can no longer provide for their families. At the same time, many urbanised families in the developing world benefit from the relatively cheaper products stemming from Europe.\n\nFor dairy products, export subsidies rose in 2009 after having been stopped in 2008. In 2009, the main recipients of dairy products that benefitted from export subsidies were: Russia, Saudi Arabia, Egypt and Nigeria.\n\nAccording to the 2003 Human Development Report the average dairy cow in the year 2000 under the European Union received $913 in subsidies annually, while an average of $8 per human being was sent in aid to Sub-Saharan Africa.\n\nThe 2005 Human Development Report states \"The basic problem to be addressed in the WTO negotiations on agriculture can be summarised in three words: rich country subsidies. In the last round of world trade negotiations rich countries promised to cut agricultural subsidies. Since then, they have increased them\". Several reports from the latest negotiations in the WTO, however, contradict the theory of the 2005 HDR report. On 29 July 2008, the WTO negotiations in the Doha round finally collapsed because of differences between the US, India and China over agricultural trade.\n\nCAP price intervention has been criticised for creating artificially high food prices throughout the EU. High import tariffs (estimated at 18–28%) have the effect of keeping prices high by restricting competition by non-EU producers. It is estimated that public support for farmers in OECD countries costs a family of four on average nearly 1,000 USD per year in higher prices and taxes. The European Commission has responded that the average EU household today spends 15% of its budget on food, compared to 30% in 1960.\n\nThe recent moves away from intervention buying, subsidies for specific crops, reductions in export subsidies, have changed the situation somewhat. In the past years intervention has been reduced or abolished in all sectors. After two decades of significant CAP reforms, farmers can now respond to market signals and increase production to react to the higher prices. Although the new decoupled payments were aimed at environmental measures, many farmers have found that without these payments their businesses would not be able to survive. With food prices dropping over the past thirty years in real terms, many products have been making less than their cost of production when sold at the farm gate.\n\nPublic health professionals have also levelled criticism at the CAP and its support regimes, arguing that agricultural policy often disregards health. It is evident that supply outputs are generating widespread public health issues of obesity and diet-related non-communicable diseases (NCDs), such as cardio-vascular disease (CVD), cancer and type II diabetes. Diet is one of the major modifiable determinants in promoting or preventing chronic disease, and agricultural products have a major influence on the disease risk factors.\n\nInitial criticism emerged in the early 2000s regarding the production orientation of the CAP and the need for decoupling due to the disjointed nature of agricultural production policy in relation to consumption (and thus nutrition). The arguments were re-enforced at the 2001 European Health Forum Gastein on the CAP, which made explicit – to policy makers – the link between nutrient quality of diets and agricultural policy. The Forum also identified opportunities to align the CAP to health objectives, more specifically by encouraging changes to dietary behaviour through adjusting CAP support.\n\nSince 2008, under the leadership of the European Public Health and Agriculture Consortium (EPHAC), the public health nutrition narrative has gained traction in policy circles. Although agricultural policy-makers are beginning to realise the arguments for upstream health intervention, practical measures remain politically unpalatable. EPHAC maintains that agricultural policies can be used to internalise the health externalities of diet-related ill-health and improve population, society-wide public health nutrition.\n\nHealth groups have become increasingly vocal in their call for agricultural policies to contribute towards resolving the consumption problems of food; such as, excessive intake of saturated fatty acids (FSA), sugar and salt, or under-consumption of vitamins (leading to hypovitaminosis) and minerals. More attention should be paid, it is argued, on intervention policies upstream, at the primary food production and processing stages, to influence nutritional quality and the structural determinants of food choice, including; availability, accessibility and price.\n\nAlthough most policy makers in Europe agree that they want to promote \"family farms\" and smaller scale production, the CAP in fact rewards larger producers . Because the CAP has traditionally rewarded farmers who produce more, larger farms have benefited much more from subsidies than smaller farms. For example, a farm with 1000 hectares, earning an additional €100 per hectare will make an additional €100,000, while a 10 hectare farm will only make an extra €1000, disregarding economies of scale. As a result, most CAP subsidies have made their way to large scale farmers.\n\nSince the 2003 reforms subsidies have been linked to the size of farms, so farmers get the same for a hectare of land regardless of how much land they own. So while subsidies allow small farms to exist, large farms tend to get the larger share of the subsidies. With the 2008 Health Check of the CAP, a first step was taken towards limiting CAP payments to very large landowners.\n\nThe European Commissioner responsible for Agriculture and Rural Development Dacian Cioloş in his Public Hearing upon his nomination has showed his concern in small farms: \"small holdings represent an important share, not only in the new Member States but also in South Europe\". He has emphasised that a structural policy is needed \"to modernise\" small farms and to \"develop existing opportunities in local markets\", where there is \"high demand for local products\".\n\nA common view is that the CAP has traditionally promoted a large expansion in agricultural production. At the same time it has allowed farmers to employ unecological ways of increasing production, such as the indiscriminate use of fertilisers and pesticides, with serious environmental consequences. However, a total re-focusing of the payment scheme in 2004 now puts the environment at the centre of farming policy. By linking the payments to farmers to a number of strict environmental standards (among others) in the so-called cross compliance scheme, farmers will have to face cuts in their subsidy levels if they don't meet the strict environmental requirements.\n\nIn 2010, the EU announced that 31% of the €5 billion that was earmarked the new (mainly environmental) challenges in agriculture would be spent on protecting and promoting biodiversity in the European countryside. This money is part of the EU rural development policy, which is supporting agri-environmental projects throughout the Member States.\n\nThe CAP has furthermore been criticised due to its effect on farmland bird populations. Between 1980 and 2009, the farmland bird population has decreased from 600 million to 300 million, implying a loss of 50%. Among the species that have been hit hardest are the starling and the tree sparrow, which have both declines by 53%. The removal of hedgerows and ploughing over meadows are two significant factors that may have contributed to more efficient farming, but that also caused a decrease in farmland birds' habitats.\n\nIn England, farmers have been lauded by the Royal Society for the Protection of Birds because the five most threatened bumblebees have made a comeback to the English nature due to the agri-environmental schemes. In Germany, support for extensive farming and biotope management helps maintain habitat for rare species such as orchids and butterflies. In Hungary, a special scheme was launched to protect the great bustard, maybe the world's heaviest flying bird, which needs areas with minimal disturbance and an abundant supply of insects to breed. In Cyprus, agri-environment schemes support the maintenance of traditional trees and bushes that are a natural habitat for the island's and likely to be of benefit to farmland birds in Cyprus.\n\nRules instituted in 2015 barring or reducing payments for farmed land above threshold densities of trees or canopy cover have been attacked as having perverse consequences for mature trees, biodiversity, soil erosion and downstream flooding.\n\nSome countries in the EU have larger agricultural sectors than others, notably France and Spain, and consequently receive more money under the CAP. Countries such as the Netherlands and the United Kingdom have particularly urbanised populations and rely very little on agriculture as part of their economy (in the United Kingdom agriculture employs 1.6% of the total workforce and in the Netherlands 2.0%). The UK therefore receives less than half what France gets, despite a similar sized economy and population. Other countries receive more benefit from different areas of the EU budget. Overall, certain countries make net contributions, notably Germany (the largest contribution overall) and the Netherlands (the biggest contribution per person), but also the UK and France. The largest per capita beneficiaries are Greece and Ireland.\n\nAnother aspect is difference between older Western European and newer Central and Eastern member states, due to transitional arrangements the latter received smaller payments. In 2013 payments per hectare were 527 euros in Greece and only 89 euros in Latvia. In compensation the newer members were allowed to provide national farm aid. In March 2018 EU agriculture ministers failed to achieve consensus on a declaration about future of CAP, with ministers of Estonia, Latvia, Lithuania, Poland, and Slovakia demanding fully equal subsidies across the union.\n\nIn spite of these declarations, the EU Commission proposed the continuation of cotton subsidies, coupled to production. The coupling of the subsidy means that they will continue to have significant trade-distorting effect, most notably on West African farmers who are unable to compete with subsidised cotton.\nThe Communication on the future of the CAP does not mention the cotton sector. Nevertheless, the most trade-distorting subsidies to cotton production have already been eliminated in the 2004 reform. The current EU cotton production corresponds to 1% of global cotton production and its effect on the evolution of world market prices is therefore negligible. On the other hand, the EU is by far the largest provider of development assistance to cotton. In the framework of the EU-Africa Partnership on Cotton the EU has made available more than €320 million. The EU market for cotton is already duty-free and quota-free and there are no export subsidies for cotton.\n\nThe UK would have been contributing more money to the EU than any other EU member state, except that the UK government negotiated a special annual UK rebate in 1984. Due to the way the rebate is funded, France pays the largest share of the rebate (31%), followed by Italy (24%) and Spain (14%).\n\nThe discrepancy in CAP funding is a cause of some consternation in the UK. , France received more than double the CAP funds received by the UK (see diagram). This is a net benefit to France of €6.37 billion, compared to the UK. This is largely a reflection of the fact that France has more than double the land area of the UK. In comparison, the UK budget rebate for 2005 is scheduled to be approx €5.5 billion. The popular view in the UK (as, for example, set forth in the tabloid press) is that if the UK rebate were reduced with no change to the CAP, then the UK would be paying money to keep the French farming sector in business – to many people in the UK, this would be seen as unfair.\n\nIf the rebate were removed without changes to the CAP then the UK would pay a net contribution of 14 times that of the French (In 2005 EU budget terms). The UK would make a net contribution of €8.25 billion compared to the current contribution of €2.75 billion, versus a current French net contribution of €0.59 billion.\n\nIn December 2005 the UK agreed to give up approximately 20% of the rebate for the period 2007–2013, on condition that the funds did not contribute to CAP payments, were matched by other countries' contributions and were only for the new member states. Spending on the CAP remained fixed, as had previously been agreed. Overall, this reduced the proportion of the budget spent on the CAP. It was agreed that the European Commission should conduct a full review of all EU spending.\n\nExperts such as Prof. Alan Matthews believed 'greening' measures in the EU's proposed €418-billion post-2013 farm policy could lower the bloc's agricultural production potential by raising farm input costs by €5 billion, or around 2 percent.\n\nOnly 5.4% of EU's population works on farms, and the farming sector is responsible for 1.6% of the GDP of the EU (2005). The number of European farmers is decreasing every year by 2%. Additionally, most Europeans live in cities, towns, and suburbs, not rural areas. \n\nThe 2007-2008 world food price crisis renewed calls for farm subsidies to be removed in light of evidence that farm subsidies contribute to rocketing food prices, which has a particularly detrimental effect on developing countries.\n\n\n\nOpinions\n\n"}
{"id": "43993014", "url": "https://en.wikipedia.org/wiki?curid=43993014", "title": "Context Books", "text": "Context Books\n\nContext Books was an independent publishing house founded by Beau Friedlander that featured often controversial and critically acclaimed titles from authors such as Derrick Jensen, Daniel Quinn, David Means, and William Rivers Pitt which operated from 1998 to 2004.\n\nContext Books originated as Context Media, through which Friedlander provided publishing and packaging services for a variety of clients with the idea in mind of raising enough capital to begin publishing titles that would have had difficulty finding interest from mainstream publishers.\n\n\"I hated big publishing's complete and utter disregard for authors,\" Friedlander said of the impetus. \"...I want to publish the revolution.\"\n\nContext Books first gained national notice with the decision to attempt to publish the memoirs of Theodore Kaczynski, who had written them from imprisonment in a Colorado Penitentiary. The memoir, entitled 'Truth Vs. Lies' did not acknowledge the anti-technological bombing campaign for which he was convicted, but rather to address the testimony from family and acquaintances that he was mentally ill.\n\nWhile developing this manuscript and preparing it for publication, Context released a companion book written by Vermont Law Professor Michael Mello called \"The United States of America Versus Theodore John Kaczynski: Ethics, Power, and the Invention of the Unabomber.\" Rather than an analysis of the Kaczynski's crimes, Mello criticized the legal processes surrounding his prosecution, where he was denied the ability to represent himself and was instead representing as being severely mentally ill. Mello, who had also acted as an adviser to Kaczynski's pretrial defense team drew parallels to the non-trial with John Brown's raid at Harper's Ferry.\n\nDespite the heavy media attention brought both to the case as well as to the fledgling Context Books, Truth Vs. Lies was scrapped pre-publication due to copyright issues and ongoing disagreements between Friedlander and Kaczynski. \"Kaczynski was uncooperative and expressed himself in ways that made it impossible for the book to be published by Context, or by anyone else,\" said Friedlander in a statement to the press.\n\nThe national attention and controversy surrounding \"Truth Vs. Lies\" gave Context Books enough of a spotlight to acquire new authors, starting with environmentalist Derrick Jensen's long-form essay A Language Older Than Words, which went on to be one of the company's most popular titles. The themes of questioning industrial civilization, environmentalism, and humankind's role and responsibilities continued with the publication of author Daniel Quinn's books The Man Who Grew Young and After Dachau in 2001, and The Holy in 2002.\n\nContext Books also began to seek out literary works for publication, including David Means's Assorted Fire Events, a set of short stories which won the Los Angeles Times Book Prize, and was a finalist for the National Book Critics Circle Award, as well as \"Mind the Doors\" by Russian author Zinovy Zinik, and \"Goblin Fruit: Stories\" by David Marshall Chan, which was a Los Angeles Times Book Prize finalist and a NYPL Young Lions finalist.\n\nContext Books once again found national notoriety with the short book / political pamphlet in 2002 by William Rivers Pitt and former UN weapons inspector Scott Ritter, arguing that the claims of Iraq's stockpiles of \"weapons of mass destruction\" were highly suspect. The title was regarded as a stand-out during the widespread debate, argument, and protest surrounding the pending U.S. invasion of Iraq, and was referred to as \"the most comprehensive independent analysis of the state of knowledge about Iraq's weapons programmes until the new team of inspectors went back.\" The title shipped over 100,000 copies, and made many best-seller lists.\n\nFollowing the success of \"War on Iraq\", Context Books followed up with two further books: \"Target Iraq\" written by Norman Solomon, Reese Erlich, and a foreword by Sean Penn, and \"Frontier Justice\" by Scott Ritter.\n\nThe 9/11 attacks and Context Books' office location in lower Manhattan created a massive financial setback for the company, which lost phone access for three months and found two of its titles released in September 2001 to languish. The company never fully recovered from the setback and declared Chapter 11 bankruptcy in November 2002, and then shifted to involuntary Chapter 7 bankruptcy in December 2003.\n"}
{"id": "52693324", "url": "https://en.wikipedia.org/wiki?curid=52693324", "title": "Court of Audit (Romania)", "text": "Court of Audit (Romania)\n\nThe Court of Audit () is the Romanian state authority charged with conducting financial audit over the way the state and public resources are managed and used.\n\nThe court was established by a law of 1864, signed by Alexandru Ioan Cuza. In December 1948, under the nascent communist regime, it was disbanded. Revived in 1973 as the Higher Court of Financial Control (\"Curtea Superioară de Control Financiar\"), this too was abolished in early 1990, following the Romanian Revolution. The Court of Audit was re-established by a law of 1992, and began functioning the following year.\n\n\n"}
{"id": "57785342", "url": "https://en.wikipedia.org/wiki?curid=57785342", "title": "EU-Alert", "text": "EU-Alert\n\nEU-Alert is the generic term for the European Public Warning Service.\nEU-Alert is compatible with Wireless Emergency Alerts (WEA) formerly known as the Commercial Mobile Alert System (CMAS) standard as used in the United States. All mobile phones OS (Android, IOS and Windows) since 2012 by default support EU-Alert/WEA/CMAS via Cell Broadcast for public warning messages.\n\nThe EU-Alert standard (TS 102 900 V1.2.1) as defined by ETSI is the European Public Warning Service using the Cell Broadcast Service as a means of delivering public warning messages to the general public.\n\nSpecific countries using the EU-Alert service are identified by replacing the letters EU with the Country Identification letters in ISO 3166-1 :\n\n\nDependent on the country legislation there are 5 types of Public Warning Service (PWS) messages one can receive on the mobile device. They're grouped into Cell Broadcast headings and channels, and include:\n\nIn countries that have selected Cell Broadcast as the technology to submit public warning messages up to 70%- 80% of the population older than 12 year receive the public warning verification message within seconds after the government authorities have submitted the message see as an example NL-Alert. Cell Broadcast is since 2012 supported by the default messaging app in Android, IOS and Windows 10.\n\nThere are several downloadable mobile applications on the market that often warn on natural catastrophes; however, these are often not of official, but part of private initiatives that replicate information from state agencies .\n\nAll Downloadable Mobile applications have the issue that they are highly affected by traffic load as they required mobile data usage; therefore, especially in case of a disaster when load spikes of Data (Social media, Voice and Mobile app), tend to significantly slowdown mobile networks, as multiple events showed e.g. 2016 Brussels bombings, November 2015 Paris attacks, 2017 London Bridge attack, Manchester Arena bombing, 2017 Stockholm attack and 2016 Munich shooting.\n\nMoreover downloadable Mobile Apps needs to be downloaded by subscribers and the experience over the years in many countries is that only a fraction of the population will take the effort to download and use an Emergency Mobile app that is only activated a few times in a year. Examples are in Germany with 1.500.000 downloads of the Katwarn and NINA mobile application reaching a maximum of 2.5M people in Germany (<3% of the German population) and France only 500.000 downloads of the SAIP mobile application (<1% of the French population) despite large investments in application development and marketing. In France because of the limited success of the downloadable Mobile App SAIP (Système d’Alerte et d’Information des Populations) the service has been stopped as of June 2018 .\n\nThe use of Location Based SMS as an emergency notification service instead of Cell Broadcast is not advised by industry experts.\nLocation based SMS message delivery is not guaranteed, and the implementations provide no mechanism through which a sender can determine whether an SMS message has been delivered in a timely manner especially when network congestion occurs at the time of an emergency .\nBased upon last years experience the Swedish Civil Contingencies Agency concluded in a recent report that in case of serious events it's extremely unlikely that Public Warning Messages via SMS will work. \n\nAdditional disadvantages to use location based SMS in national public warning systems are:\n\n\n\n"}
{"id": "27904054", "url": "https://en.wikipedia.org/wiki?curid=27904054", "title": "Electric vehicle warning sounds", "text": "Electric vehicle warning sounds\n\nElectric vehicle warning sounds are sounds designed to alert pedestrians to the presence of electric drive vehicles such as hybrid electric vehicles (HEVs), plug-in hybrid electric vehicles (PHEVs), and all-electric vehicles (EVs) travelling at low speeds. Warning sound devices were deemed necessary by some government regulators because vehicles operating in all-electric mode produce less noise than traditional combustion engine vehicles and can make it more difficult for pedestrians, the blind, cyclists, and others, to be aware of their presence. Warning sounds may be driver triggered (as in a horn but less urgent) or automatic at low speeds; in type, they vary from clearly artificial (beeps, chimes) to those that mimic engine sounds and those of tires moving over gravel.\n\nJapan issued guidelines for such warning devices in January 2010 and the U.S. approved legislation in December 2010. The U.S. National Highway Traffic Safety Administration issued its final ruling in February 2018, and requires the device to emit warning sounds at speeds less than with compliance by September 2020, but 50% of \"quiet\" vehicles must have the warning sounds by September 2019. The European Parliament approved legislation that requires the mandatory use of \"Acoustic Vehicle Alerting Systems\" for all new electric and hybrid electric vehicles within five years after publication of the final approval of the April 2014 proposal to comply with the regulation.\n\nSeveral automakers have developed electric warning sound devices, and since December 2011 advanced technology cars available in the market with manually activated electric warning sounds include the Nissan Leaf, Chevrolet Volt, Honda FCX Clarity, Nissan Fuga Hybrid/Infiniti M35, Hyundai Sonata Hybrid, and the Toyota Prius (Japan only). Models equipped with automatically activated systems include the 2014 BMW i3 (option not available in the US), 2012 model year Toyota Camry Hybrid, 2012 Lexus CT200h, all EV versions of the Honda Fit, and all Prius family cars recently introduced in the United States, including the standard 2012 model year Prius, the Toyota Prius v, Prius c and the Toyota Prius Plug-in Hybrid. The 2013 Smart electric drive comes with automatically activated sounds in the U.S. and Japan and manually activated in Europe. Tesla Motors and Volkswagen do not currently include warning sounds in their electric drive vehicles, as both of them decided to add artificial sounds only when required by regulation.\n\nAs a result of increased sales of hybrid electric vehicles in several countries, some members of the blind community have raised concerns about the noise reduction when those vehicles operate in all-electric mode, as blind people or the visually impaired consider the noise of combustion engines a helpful aid while crossing streets and feel quiet hybrids could pose an unexpected hazard. Although a 2009 study found no statistically significant difference in pedestrian crashes involving quiet hybrid vehicles when compared to noisier vehicles when both types of vehicles were travelling in a straight line, it found a doubling of hybrid vehicle pedestrian crashes when reversing or parking etc. at slow speeds.\n\nThis problem is not exclusive to electric vehicles. In 2007 research at the Technical University Munich showed that ordinary vehicles in background noise are often detected too late for safe accident avoidance. The researchers measured the distances of 35 approaching vehicles to a pedestrian in the moment when they just got audible in a stationary background noise. These distances were then compared to the stopping distances of the respective cars and an algorithm was proposed to estimate them based on auditory masking.\n\nResearch conducted at the University of California, Riverside in 2008 found that hybrid cars are so quiet when operating in electric mode (EV mode) that they may pose a risk to the blind, small children, the elderly, runners, cyclists, and other pedestrians, as they may have only one or two seconds, depending on the context, to audibly detect the location of approaching hybrid cars when the vehicles operate at very slow speeds. This research project was funded by the National Federation of the Blind.\n\nThe experiment consisted of making audio recordings of a Toyota Prius and combustion engine Honda Accord approaching from two directions at to assure that the hybrid car operated only with its electric motor. Then test subjects in a laboratory listened to the recordings and indicated when they could hear from which direction the cars approached. Subjects could locate the hum of the internal combustion engine car at away, but could not identify the hybrid running in electric mode until it came within , leaving just less than two seconds to react before the vehicle reached their position. In a second trial, the background sounds of two quietly idling combustion engine cars were added to the recordings to simulate the noise of a parking lot. Under this condition, the hybrid needed to be 74 percent closer than the conventional car before the subjects could hear from which direction the cars approached. Subjects could correctly judge the approach of the combustion car when it was about feet away. This result means that under closer to normal environmental noise, a pedestrian would not be able to correctly determine the hybrid's approach until it was one second away.\n\nA separate 2008 study from Western Michigan University found that hybrids and conventional vehicles are equally safe when travelling more than about , because tire and wind noise generate most of the audible cues at those speeds. Hybrid cars were also tested safe when leaving a stoplight and it was found that under this condition they do not pose a risk to pedestrians. All Prius models used in the study engaged their internal combustion engines when accelerating from a standstill and produced enough noise to be detected.\n\nA 2009 study conducted by the U.S. National Highway Traffic Safety Administration found that crashes involving pedestrians and bicyclists have higher incidence rates for hybrid electric vehicles than internal combustion engine (ICE) vehicles in low-speed vehicle maneuvers such as reversing or leaving a parking zone. These accidents commonly occurred in zones with low speed limits, during daytime and in clear weather. The study found that a HEV was two times more likely to be involved in a pedestrian crash than was a conventional ICE vehicle when a vehicle is slowing or stopping, backing up, or entering or leaving a parking space. Vehicle maneuvers were grouped in one category considering those maneuvers that might have occurred at very low speeds where the difference between the sound levels produced by the hybrid versus ICE vehicle is the greatest. Also the study found that the incidence rate of pedestrian crashes in scenarios when vehicles make a turn was significantly higher for HEVs when compared to ICE vehicles. Similarly, The NHTSA study also concluded that the incidence rate of bicyclist crashes involving HEVs for the same kind of maneuvers was significantly higher when compared to conventional vehicles.\n\nIn September 2010, Volvo Cars and Vattenfall, a Swedish energy company, issued a report regarding the results of the first phase of the Volvo V70 Plug-in Hybrid demonstration program. Among other findings, before the trial drivers participating in the field testing were concerned about being a danger to pedestrians and cyclists due to the quietness of the electric-drive vehicle. After the test several of them change their opinion and said that this issue was less of a problem than expected. Nevertheless, some test drivers said they experienced incidents of not being noticed while others said they had taken extra care in their driving with regard to this issue.\n\nSince 2009 the Japanese government, the U.S. Congress and the European Commission are exploring legislation to establish a minimum level of sound for plug-in electric and hybrid electric vehicles when operating in electric mode, so that blind people and other pedestrians and cyclists can hear them coming and detect from which direction they are approaching. Tests have shown that vehicles operating in electric mode can be particularly hard to hear below .\n\nIn 2011 the European Commission drafted a guideline for Acoustic Vehicle Alerting Systems (AVAS). The goal is to present recommendations to manufacturers for a system to be installed in vehicles to provide an audible signal to pedestrians and vulnerable road users. This interim guideline is intended to provide guidance until the completion of on-going research activities and the development of globally harmonized device performance specifications. The guidelines are intended for hybrid electric and pure electric highway-capable vehicles. The guideline recommends that the AVAS shall automatically generate a continuous sound in the minimum range of vehicle speed from start up to approximately and during reversing, if applicable for that vehicle category, and list the types of sounds that are not acceptable. It also states that the AVAS may have a pause switch to stop its operation temporarily.\n\nOn 6 February 2013, the European Parliament approved a draft law to tighten noise limits for cars to protect public health, and also to add alerting sounds to ensure the audibility of hybrid and electric vehicles to improve the safety of vulnerable road users in urban areas, such as blind, visually and auditorily challenged pedestrians, cyclists and children. The draft legislation states a number of tests, standards and measures that must first be developed for an Acoustic Vehicle Alerting Systems (AVAS) to be compulsory in the future. Now an agreement has to be negotiated with European Union countries. The approved amendment establishes that \"the sound to be generated by the AVAS should be a continuous sound that provides information to the pedestrians and vulnerable road users of a vehicle in operation. The sound should be easily indicative of vehicle behaviour and should sound similar to the sound of a vehicle of the same category equipped with an internal combustion engine.\" In April 2014 the European Parliament approved the legislation (Regulation (EU) No 540/2014) that requires the Acoustic Vehicle Alerting Systems, which is mandatory for all new electric and hybrid electric vehicles. The new rule established a transitional period of 5 years after publication of the final approval of the April 2014 proposal to comply with the regulation.\n\nBeginning in July 2009 the Japanese government began assessing possible countermeasures through the Committee for the Consideration of Countermeasures Regarding Quiet Hybrid and Other Vehicles, and in January 2010 the Ministry of Land, Infrastructure, Transport and Tourism issued guidelines for hybrid and other near-silent vehicles.\n\nThe Department for Transport (DfT) commissioned research to gather statistics on accidents involving electric vehicles with pedestrians who are blind or vision impaired to determine whether the perceived accident risk is real and whether electric and hybrid cars are more difficult to detect audibly than conventional internal combustion engine vehicles. The DfT goal was to use the findings to establish what sort of sound should be fitted to electric vehicles.\n\nThe research was conducted by the Transport Research Laboratory, and the findings were published in 2011. The study found little correlation between pedestrian vehicle involvement density and noise level for the majority of vehicles. In addition, the analysis found no evidence of a pattern in pedestrian vehicle involvement densities when only considering those accidents occurring on or slower roads, or where the pedestrian was disabled. A previous study did not find an increased pedestrian vehicle involvement density for electric and hybrid vehicles with respect to their conventional counterparts, which raised the question as to whether added sound is necessarily required. The study also noted that some modern conventional cars are as quiet as their electric counterparts, even at low speeds.\n\nUK organisation The Guide Dogs for the Blind Association lobbied members of the European Parliament to vote in favour of legislation to make the installation of artificial sound generators mandatory on quiet electric and hybrid vehicles.\n\nThe Pedestrian Safety Enhancement Act of 2010 was approved by the U.S. Senate by unanimous consent on December 9, 2010 and passed by the House of Representatives by 379 to 30 on December 16, 2010. The act does not stipulate a specific speed for the simulated noise but requires the U.S. Department of Transportation to study and establish a motor vehicle safety standard that would set requirements for an alert sound that allows blind and other pedestrians to reasonably detect a nearby electric or hybrid vehicle, and the ruling must be finalized within eighteen months. The bill was signed into law by President Barack Obama on January 4, 2011.\n\nA proposed rule was published for comment by the National Highway Traffic Safety Administration (NHTSA) in January, 2013. It would require hybrids and electric vehicles traveling at less than to emit warning sounds that pedestrians must be able to hear over background noises. The agency selected 30 km/h as the limit because according to NHTSA measurements, this is the speed at which the sound levels of the hybrid and electric vehicles approximated the sound levels produced by similar internal combustion vehicles. According to the NHTSA proposal, carmakers would be able to pick the sounds the vehicles make from a range of choices, and similar vehicles would have to make the same sounds. The rules were scheduled to go into effect in September 2014. The NHTSA estimates that the new warning noises would prevent 2,800 pedestrian and cyclist injuries during the life of each model year electric and hybrid vehicle.\n\nIn February 2013, the Association of Global Automakers and the Alliance of Automobile Manufacturers, which submitted a joint comment to the NHTSA, announced their support to the rule, but asked the NHTSA to find a noise level that effectively alerts pedestrians without being excessively loud to others inside and outside of the vehicle. They also commented that the rule is too complicated, unnecessarily prescriptive, and it will cost more than necessary. Some automakers also said there is no need for electric-drive vehicles to play sounds while not in motion, \"since it is not clear that it helps pedestrians to hear cars that are stopped in traffic or parked.\" In addition, the carmakers requested the NHTSA to make the new sound system required by 2018 instead of 2014.\n\nIn January 2015, the NHTSA rescheduled the date for a final ruling to the end of 2015. Since the regulation comes into force three years after being rendered as a final rule, compliance was delayed to 2018. In November 2015, the NHTSA rescheduled one more time because additional coordination is necessary. A final ruling was delayed at least until mid-March 2016. After several additional delays, the National Highway Traffic Safety Administration issued its final ruling in February 2018. It requires hybrids and electric vehicles traveling at less than to emit warning sounds that pedestrians must be able to hear over background noises. The regulation requires full compliance in September 2020, but 50% of \"quiet\" vehicles must have the warning sounds by September 2019.\n\nEnhanced Vehicle Acoustics (EVA), a company based in Silicon Valley, California and founded by two Stanford students with the help of seed money from the National Federation of the Blind, developed an after market technology called \"Vehicular Operations Sound Emitting Systems\" (VOSES). The device makes hybrid electric vehicles sound more like conventional internal combustion engine cars when the vehicle goes into the silent electric mode (EV mode), but at a fraction of the sound level of most vehicles. At speeds higher than between to the sound system shuts off. The system also shuts off when the hybrid combustion engine kicks in.\n\nVOSES uses miniature, all-weather audio speakers that are placed on the hybrid's wheel wells and emit specific sounds based on the direction the car is moving in order to minimize noise pollution and to maximize acoustic information for pedestrians. If the car is moving forward, the sounds are only projected in the forward direction; and if the car is turning left or right, the sound changes on the left or right appropriately. The company argues that \"chirps, beeps and alarms are more distracting than useful\", and that the best sounds for alerting pedestrians are carlike, such as \"the soft purr of an engine or the slow roll of tires across pavement.\" One of the EVA's external sound systems was designed specifically for the Toyota Prius.\nECTunes is developing a system that utilizes directional sound equipment to emit noise when and where it is needed. According to the company, its technology sends audible signals only in the direction of travel, thus allowing the vehicle to be heard by those who may be in the car's path, without disturbing others with unwelcome noise. Insero Horsens, a Danish venture company, has provided a significant investment to help ECTunes fully develop its technology.\n\nThe ECTunes system, and most others so far disclosed, use a control box, with software, digital amplifiers and weather-friendly external speakers. ECTunes' system connects to the car, and reads speed and acceleration, shutting down when the car reaches Cross-over speed as set by existing regulation as well as regulation under development such as Quiet Road Transport Vehicles (QRTV), at which point the tires and wind are making noise of their own. The company is currently selling products to OEM's, mainly small series production, and to the after market, and has also a new mass production unit in prototype stage \n\nSoundRacer AB is a Swedish manufacturer of electronic engine sound devices established 2008 to develop sound technology for improved driving experience in internal combustion engine (ICE) cars. In 2012 the company released their first version of an Electric Vehicle Electronic Engine Sound System, based on the same technology.\n\nSoundRacer EVS use only real engine sound recordings as the base for the sounds, following the legislation guidelines that the sound \"should sound similar to the sound of a vehicle of the same category equipped with an internal combustion engine\". As a result, the sounds will also be less likely to be disturbing compared to adding new types of synthetic sounds into the traffic environment.\n\nThe sound modules are developed to give a realistic ICE sound impression indicating if the vehicle is idling, accelerating, decelerating or cruising. The different sound characters and sound volume is determined from information about the actual speed of the vehicle and rate of speed change.\n\nThe company targets two different applications with the products: 1. EV warning sounds, to make electric vehicles meet the upcoming legislations, and 2. Increased driving experience to make electric vehicles more popular among customer groups that appreciate real engine sounds.\n\nMany manufacturers of electric vehicles like cars, motorcycles and scooters are now in the process of evaluating sound systems for their products. To assist them in the prototyping process the SoundRacer EVS modules have functions that will give EV manufacturers the tools to test different sounds and settings. Several files with sounds and parameter settings, such as the speed for muting the sound, sound levels and simulated gear changing, can be created with a computer program and stored on a MicroSD card. Changing sounds and settings during test drives is then performed with a touch of a button. \nSoundRacer AB delivers complete systems with recorded engine sounds from cars and motorcycles, including V8, V12 and V-Twin, CAN bus, analog and digital speed/rpm input and weather protected, IP68, speakers.\n\nFisker Automotive developed a sound-generator that was incorporated in its Fisker Karma luxury plug-in hybrid electric vehicle, released in 2011. According to the carmaker, the sound is designed to both alert pedestrians and enhance the driver experience, and the warning noise will be emitted automatically. The Fisker Karma emits a sound through a pair of external speakers embedded in the bumper. According to a company spokesman the sound is a mix between a \"Formula One car and a starship\".\n\nThe developing process took between nine months to a year, and three sound companies sent in synthesized WAV file samples that were evaluated by Fisker employees and executives. The prospective sounds were studied in an audio chamber to allow engineers to evaluate the sounds without other noise interfering. After testing the candidate sounds in different locations relative to the vehicle, Fisker fine-tuned the final sound with its own equipment. The warning sound is activated when the car is traveling at less than .\n\nThe 2012 Ford Focus Electric was planned to include warning sounds for pedestrians. Ford Motor Company developed four alternative sounds, and in June 2011 involved the electric car fans by asking them to pick their favorite from the four potential warning sounds through the Focus Electric Facebook page. However, ultimately Ford decided to hold off including warning sounds unless federal legislation required it, and no such system was implemented on the production vehicle.\n\nGeneral Motors' first commercially available plug-in hybrid electric vehicle, the Chevrolet Volt, introduced in December 2010, includes warning sounds for pedestrians. GM's system is called Pedestrian-Friendly Alert System and it is manually activated by the driver, but future generations probably will include an active system.\nThe automaker conducted a test with a group of the visually challenged at Milford Proving Grounds in order to evaluate the audible warning systems on the Volt when a pedestrian is in the car's proximity. The system uses the car's horn to emit a series of warning chirps, like a low tone of a horn, enough to provide an alert but not to startle. According to GM engineers, the biggest challenge is \"developing an active system that can distinguish a pedestrian from another vehicle\"; otherwise, the sound will go off frequently, producing noise pollution instead.\n\nHyundai developed a warning noise for called the Virtual Engine Sound System (VESS). The system, which was introduced in September 2010 on its test fleet of BlueOn electric hatchbacks, provides synthetic audio feedback mimicking the sound of an idling internal combustion engine.\n\nThe 2011 Hyundai Sonata Hybrid is the first mass production car manufactured by Hyundai to include the warning sound system. In 2010 the carmaker decided to have a button on the Sonata Hybrid's instrument panel to turn the VESS on and off, but after the enactment of the Pedestrian Safety Enhancement Act of 2010, signed into law by President Obama in early 2011, and learning that the U.S. National Highway Traffic Safety Administration would not allow such switches to avoid the noise device to be turned off, Hyundai decided not to install the button, and the first Sonata Hybrids destined for the U.S. market had to be altered to remove the switch.\n\nLotus Engineering, a consultancy group of British sports carmaker Lotus Cars, partnered in 2009 with Harman Becker, a producer of audio systems, to develop and commercialize a synthetic automotive audio systems. Lotus has worked on a number of hybrid and electric vehicles and its engineers thought they would be safer if these vehicles made a noise while moving around the factory. Originally developed to cancel out intrusive noises inside a car, the noise canceling system was adapted so that it could also simulate engine sounds that change with speed and use of the throttle, providing audible \"feedback\" to drivers of vehicles with a silent engine. At the same time, and through the addition of external speakers, the sound system allows pedestrians to hear the noise too, but optionally there can be a different sound within the car from the one that is emitted for the outside. Lotus used a Toyota Prius to demonstrate the device but did not reveal if it intended to bring this technology to market.\n\nLotus' synthetic sound system was incorporated in the Lotus Evora 414E Hybrid, a concept plug-in hybrid unveiled at the 2010 Geneva Motor Show. The system, called HALOsonic Internal and External Electronic Sound Synthesis, is a suite of noise solutions that uses patented technologies from Lotus and Harman International. The audio system generates engine sounds inside the vehicle through the audio system. The system also generates the external sound through speakers mounted at the front and rear to provide a warning to increase pedestrian safety. The system comes with four driver-selectable engine sounds, two of which have been designed to have characteristics of a multi-cylinder conventional V6 and V12 engine.\n\nVehicle Sound for Pedestrians or VSP is a Nissan-developed warning sound system in electric vehicles. The Nissan Leaf was the first car manufactured by Nissan to include VSP, and the electric car includes one sound for forward motion and another for reverse. The VSP was also used in the Nissan Fuga hybrid launched in 2011. The system developed makes a noise easy to hear for those outside to be aware of the vehicle approaching, but the warning sounds do not distract the car occupants inside. Nissan explained that during the development of the sound they studied behavioral research of the visually impaired and worked with cognitive and acoustic psychologists, including the National Federation of the Blind, the Detroit Institute of Ophthalmology, experts from the Vanderbilt University Medical Center and a Hollywood sound design studio.\n\nNissan's Vehicle Sound for Pedestrians is a sine-wave sound system that sweeps from 2.5 kHz at the high end to a low of 600 Hz, a range that is easily audible across age groups. Depending on the speed and whether the Leaf is accelerating or decelerating, the sound system will make sweeping, high-low sounds. For example, when the Leaf is started the sound will be louder, and when the car is in reverse, the system will generate an intermittent sound. The sound system ceases operation when the Nissan Leaf reaches and engages again as the car slows to under . For the 2011 Leaf, the driver could turn off sounds temporarily through a switch inside the vehicle, but the system automatically reset to \"On\" at the next ignition cycle. The system is controlled through a computer and synthesizer in the dash panel, and the sound is delivered through a speaker in the front driver's side wheel well. Nissan said that there were six or seven finalist sounds, and that sound testing included driving cars emitting various sounds past testers standing on street corners, who indicated when they first heard the approaching car. Nissan removed the ability to disable the pedestrian alert between model year 2011 and 2012 in anticipation of the U.S. ruling to be issued by the National Highway Traffic Safety Administration.\n\nThe Leaf's electric warning sound had to be removed for cars delivered in the U.K., as the country's law mandates that any hazard warning sound must be capable of being disabled between 11:00 pm and 6:00 am, and the Leaf's audible warning system does not allow for such temporary deactivation. For the 2014 UK model of the car, the VSP system is enabled by default, though a button on the dash permits drivers to disable the system until the next time the car is switched on.\n\nToyota Motor Company teamed up with Fujitsu Ten to develop an automatic warning system for hybrids and electric vehicles to alert pedestrians when the car is propelled by its electric motor. The companies also studied the development of a system that would change the alarm's tune and volume with the assistance of an obstacle-detection radar.\n\nOn August 2010 Toyota began sales of an onboard device designed to automatically emit a synthesized sound of an electric motor when the Prius is operating as an electric vehicle at speeds up to approximately . The device will be available in Japan through authorized Toyota dealers and Toyota genuine parts & accessories distributors for retrofitting on the third-generation Prius at a price of (~) including the consumption tax. The alert sound rises and falls in pitch according to the vehicle's speed, thus helping indicate the vehicle's proximity and movement to nearby pedestrians. Toyota is planning to use other versions of the device for use in gasoline-electric hybrids, plug-in hybrids, electric vehicles as well as fuel-cell hybrid vehicles planned for mass production. The device meets the 2010 government regulations issued for hybrid and other near-silent vehicles.\n\nToyota's Vehicle Proximity Notification System (VPNS) was introduced in the United States in all 2012 model year Prius family vehicles, including the Prius v, Prius Plug-in Hybrid and the standard Prius. The system is being introduced to comply with the Pedestrian Safety Enhancement Act of 2010.\n\nVolkswagen offers a so-called e-Sound module on its electric and hybrid vehicles such as the e-Up, e-Golf and the GTE hybrid range. It provides a pedestrian warning sound up to 30 km/h.\n\nTesla Motors and Think Global, both manufactures of electric cars already in the market, are assessing this safety issue. Ford Motor Company is developing a system for emitting external sounds to future hybrids and electrics, including its Focus BEV, scheduled for 2011, and a next-generation hybrid and plug-in hybrid vehicle planned for 2012. Nancy Gioia, Ford's Director for Global Electrification commented that \"car companies should consider standardizing tones from future hybrids and electrics to avoid a cacophony of confusion on the streets.\"\n\nAfter Nissan's new sounds were publicized, the U.S. National Federation of the Blind issued a statement saying that \"while it was pleased that the alert existed, it was unhappy that the driver was able to turn it off.\" The NFB approves the Nissan Leaf's forward motion sound, but it said the forward noise should also be used for reversing because the \"intermittent sound is not as effective as a continuous sound\" and that the car should emit warning sounds when it is idling, not only when it's moving slowly. Nevertheless, their main complaint is that they don’t think the driver should be able to switch the sound off.\n\nSeveral anti-noise and electric car advocates have opposed the introduction of artificial sounds as warning for pedestrians, as they argue that the proposed system will only increase noise pollution. They also opposed U.S. pending legislation that would require generated warning sounds with no off switch for the driver.\n\nRobert S. Wall Emerson of Western Michigan University has argued that several high-end gasoline-powered luxury cars are already quieter than hybrids, and according to his most recent studies, hybrid SUVs were noisier than many internal-combustion vehicles. He concludes that pedestrian safety is not a hybrid issue but rather \"a quiet car issue\".\"\"\n\n, most of the hybrids and plug-in electric and hybrids sold make warning noises using a speaker system. Tesla Motors, Volkswagen and BMW do not currently include warning sounds in their electric-drive vehicles, as all of them decided to add artificial sounds only when required by regulation.\n\n\n\n"}
{"id": "9120742", "url": "https://en.wikipedia.org/wiki?curid=9120742", "title": "Embassy of Heaven", "text": "Embassy of Heaven\n\nThe Embassy of Heaven is a Christian-based new religious movement based in Stayton, Oregon, that seeks to separate from secular government. Its members profess to be literal citizens of the Kingdom of Heaven and reject any ties to what they refer to as \"worldly governments\". The organization issues its own identity documents (including passports and driver's licenses), business licenses, motor vehicle title certificates and license plates. The group's leader is Craig Douglas Fleshman, a former Oregon state computer systems analyst who goes by the name \"Pastor Paul Revere\". Another individual who has been associated with the organization in the past is Glen Stoll, an individual who \"falsely hold[s] himself out to be a 'lawyer' and claims to have spent considerable time studying the tax laws\" but who \"is not a member of or licensed with any state or federal bar.\"\n\nThe Anti-Defamation League has identified the Embassy of Heaven group as being part of the sovereign citizen movement. Federal authorities have asserted that the organization is set up to avoid paying taxes. Though its leaders refer to themselves as lawyers, none has any education in law nor have they passed the bar exam. The organization has run afoul of tax codes because it does not recognize the authority of the United States. In 1997, sheriff's deputies raided the group's property and seized it for non-payment of taxes. Pastor Revere insisted the taxes were not owed because the property was \"a separate nation\". Several members have been arrested for driving cars with \"Kingdom of Heaven\" license plates and showing similar driver's licenses to law enforcement officers.\n\nIn 2012, Minnesota state insurance regulators ordered the Embassy of Heaven Church to stop making what the regulators called misrepresentations, using the name \"Mutual Assurance\", in connection with the sale of insurance in Minnesota. The regulators asserted that a type of auto insurance promoted by the group is bogus, and that the group had no license to sell insurance in Minnesota. Embassy of Heaven spokesman Paul Revere responded, asserting that the group does not sell insurance. Revere was also quoted as saying, \"We don't operate in Minnesota. ... We operate in the Kingdom of Heaven.\"\n\n"}
{"id": "37104", "url": "https://en.wikipedia.org/wiki?curid=37104", "title": "Emissions trading", "text": "Emissions trading\n\nEmissions trading, or cap and trade, is a market-based approach to controlling pollution by providing economic incentives for achieving reductions in the emissions of pollutants. In contrast to command-and-control environmental regulations such as best available technology (BAT) standards and government subsidies, cap and trade (CAT) programs are a type of flexible environmental regulation that allows organizations to decide how best to meet policy targets. Various countries, states and groups of companies have adopted such trading systems, notably for mitigating climate change.\n\nA central authority (usually a governmental body) allocates or sells a limited number of permits to discharge specific quantities of a specific pollutant per time period. Polluters are required to hold permits in amount equal to their emissions. Polluters that want to increase their emissions must buy permits from others willing to sell them. Financial derivatives of permits can also be traded on secondary markets.\n\nIn theory, polluters who can reduce emissions most cheaply will do so, achieving the emission reduction at the lowest cost to society. Cap and trade is meant to provide the private sector with the flexibility required to reduce emissions while stimulating technological innovation and economic growth.\n\nThere are active trading programs in several air pollutants. For greenhouse gases, which cause climate change, permit units are often called \"carbon credits\". The largest greenhouse gases trading program is the European Union Emission Trading Scheme, which trades primarily in \"European Union Allowances\" (\"EUAs\"); the Californian scheme trades in California Carbon Allowances, the New Zealand scheme in New Zealand Units and the Australian scheme in Australian Units. The United States has a national market to reduce acid rain and several regional markets in nitrogen oxides.\n\nPollution is the prime example of a market externality. An externality is an effect of some activity on an entity (such as a person) that is not party to a market transaction related to that activity. Emissions trading is a market-based approach to address pollution. The overall goal of an emissions trading plan is to minimize the cost of meeting a set emissions target.\n\nIn an emissions trading system, the government sets an overall limit on emissions, and defines permits (also called allowances), or limited authorizations to emit, up to the level of the overall limit. The government may sell the permits, but in many existing schemes, it gives permits to participants (regulated polluters) equal to each participant's baseline emissions. The baseline is determined by reference to the participant's historical emissions. To demonstrate compliance, a participant must hold permits at least equal to the quantity of pollution it actually emitted during the time period. If every participant complies, the total pollution emitted will be at most equal to the sum of individual limits. Because permits can be bought and sold, a participant can choose either to use its permits exactly (by reducing its own emissions); or to emit less than its permits, and perhaps sell the excess permits; or to emit more than its permits, and buy permits from other participants. In effect, the buyer pays a charge for polluting, while the seller gains a reward for having reduced emissions.\n\nIn many schemes, organizations which do not pollute (and therefore have no obligations) may also trade permits and financial derivatives of permits. In some schemes, participants can bank allowances to use in future periods. In some schemes, a proportion of all traded permits must be retired periodically, causing a net reduction in emissions over time. Thus, environmental groups may buy and retire permits, driving up the price of the remaining permits according to the law of demand. In most schemes, permit owners can donate permits to a nonprofit entity and receive a tax deduction. Usually, the government lowers the overall limit over time, with an aim towards a national emissions reduction target.\n\nAccording to the Environmental Defense Fund, cap-and-trade is the most environmentally and economically sensible approach to controlling greenhouse gas emissions, the primary cause of global warming, because it sets a limit on emissions, and the trading encourages companies to innovate in order to emit less.\n\n\"International trade can offer a range of positive and negative incentives to promote international cooperation on climate change (robust evidence, medium agreement). Three issues are key to developing constructive relationships between international trade and climate agreements: how existing trade policies and rules can be modified to be more climate friendly; whether border adjustment measures (BAMs) or other trade measures can be effective in meeting the goals of international climate agreements; whether the UNFCCC, World Trade Organization (WTO), hybrid of the two, or a new institution is the best forum for a trade-and-climate architecture.\"\n\nSome economists have urged the use of market-based instruments such as emissions trading to address environmental problems instead of prescriptive \"command-and-control\" regulation. Command and control regulation is criticized for being insensitive to geographical and technological differences, and therefore inefficient.; however, this is not always so, as shown by the WW-II rationing program in the U.S. in which local and regional boards made adjustments for these differences.\n\nAfter an emissions limit has been set by a government political process, individual companies are free to choose how or whether to reduce their emissions. Failure to report emissions and surrender emission permits is often punishable by a further government regulatory mechanism, such as a fine that increases costs of production. Firms will choose the least-cost way to comply with the pollution regulation, which will lead to reductions where the least expensive solutions exist, while allowing emissions that are more expensive to reduce.\n\nUnder an emissions trading system, each regulated polluter has flexibility to use the most cost-effective combination of buying or selling emission permits, reducing its emissions by installing cleaner technology, or reducing its emissions by reducing production. The most cost-effective strategy depends on the polluter's marginal abatement cost and the market price of permits. In theory, a polluter's decisions should lead to an economically efficient allocation of reductions among polluters, and lower compliance costs for individual firms and for the economy overall, compared to command-and-control mechanisms.\n\nFor emissions trading where greenhouse gases are regulated, one emissions permit is considered equivalent to one metric ton of carbon dioxide (CO) emissions. Other names for emissions permits are carbon credits, Kyoto units, assigned amount units, and Certified Emission Reduction units (CER). These permits can be sold privately or in the international market at the prevailing market price. These trade and settle internationally, and hence allow permits to be transferred between countries. Each international transfer is validated by the United Nations Framework Convention on Climate Change (UNFCCC). Each transfer of ownership within the European Union is additionally validated by the European Commission.\n\nEmissions trading programmes such as the European Union Emissions Trading System (EU ETS) complement the country-to-country trading stipulated in the Kyoto Protocol by allowing private trading of permits. Under such programmes – which are generally co-ordinated with the national emissions targets provided within the framework of the Kyoto Protocol – a national or international authority allocates permits to individual companies based on established criteria, with a view to meeting national and/or regional Kyoto targets at the lowest overall economic cost.\n\nTrading exchanges have been established to provide a spot market in permits, as well as futures and options market to help discover a market price and maintain liquidity. Carbon prices are normally quoted in euros per tonne of carbon dioxide or its equivalent (COe). Other greenhouse gases can also be traded, but are quoted as standard multiples of carbon dioxide with respect to their global warming potential. These features reduce the quota's financial impact on business, while ensuring that the quotas are met at a national and international level.\n\nCurrently, there are six exchanges trading in UNFCCC related carbon credits: the Chicago Climate Exchange (until 2010), European Climate Exchange, NASDAQ OMX Commodities Europe, PowerNext, Commodity Exchange Bratislava and the European Energy Exchange. NASDAQ OMX Commodities Europe listed a contract to trade offsets generated by a CDM carbon project called Certified Emission Reductions. Many companies now engage in emissions abatement, offsetting, and sequestration programs to generate credits that can be sold on one of the exchanges. At least one private electronic market has been established in 2008: CantorCO2e. Carbon credits at Commodity Exchange Bratislava are traded at special platform called Carbon place.\n\nTrading in emission permits is one of the fastest-growing segments in financial services in the City of London with a market estimated to be worth about €30 billion in 2007. Louis Redshaw, head of environmental markets at Barclays Capital, predicts that \"carbon will be the world's biggest commodity market, and it could become the world's biggest market overall.\"\n\nAn emission license directly confers a right to emit pollutants up to a certain rate.\nIn contrast, a pollution license for a given location confers the right to emit pollutants at a rate which will cause no more than a specified increase at the pollution-level. For concreteness, consider the following model.\n\nAs an example, consider three countries along a river (as in the fair river sharing setting).\nSo the matrix formula_7 in this case is a triangular matrix of ones.\n\nEach pollution-license for location formula_13 permits its holder to emit pollutants that will cause at most this level of pollution at location formula_13. Therefore, a polluter that affects water quality at a number of points has to hold a portfolio of licenses covering all relevant monitoring-points. In the above example, if country 2 wants to emit a unit of pollutant, it should purchase two permits: one for location 2 and one for location 3.\n\nMontgomery shows that, while both markets lead to efficient license allocation, the market in pollution-licenses is more widely applicable than the market in emission-licenses.\n\nThe international community began the long process towards building effective international and domestic measures to tackle GHG emissions (carbon dioxide, methane, nitrous oxide, hydroflurocarbons, perfluorocarbons, sulphur hexafluoride) in response to the increasing assertions that global warming is happening due to man-made emissions and the uncertainty over its likely consequences. That process began in Rio in 1992, when 160 countries agreed the UN Framework Convention on Climate Change (UNFCCC). The UNFCCC is, as its title suggests, simply a framework; the necessary detail was left to be settled by the Conference of Parties (CoP) to the UNFCCC.\n\nThe efficiency of what later was to be called the \"cap-and-trade\" approach to air pollution abatement was first demonstrated in a series of micro-economic computer simulation studies between 1967 and 1970 for the National Air Pollution Control Administration (predecessor to the United States Environmental Protection Agency's Office of Air and Radiation) by Ellison Burton and William Sanjour. These studies used mathematical models of several cities and their emission sources in order to compare the cost and effectiveness of various control strategies. Each abatement strategy was compared with the \"least-cost solution\" produced by a computer optimization program to identify the least-costly combination of source reductions in order to achieve a given abatement goal. In each case it was found that the least-cost solution was dramatically less costly than the same amount of pollution reduction produced by any conventional abatement strategy. Burton and later Sanjour along with Edward H. Pechan continued improving and advancing these computer models at the newly created U.S. Environmental Protection Agency. The agency introduced the concept of computer modeling with least-cost abatement strategies (i.e., emissions trading) in its 1972 annual report to Congress on the cost of clean air. This led to the concept of \"cap and trade\" as a means of achieving the \"least-cost solution\" for a given level of abatement.\n\nThe development of emissions trading over the course of its history can be divided into four phases:\n\n\nIn the United States, the \"acid rain\"-related emission trading system was principally conceived by C. Boyden Gray, a G.H.W. Bush administration attorney. Gray worked with the Environmental Defense Fund (EDF), who worked with the EPA to write the bill that became law as part of the Clean Air Act of 1990. The new emissions cap on NO and gases took effect in 1995, and according to \"Smithsonian\" magazine, those acid rain emissions dropped 3 million tons that year. In 1997, the CoP agreed, in what has been described as a watershed in international environmental treaty making, the Kyoto Protocol where 38 developed countries (Annex 1 countries) committed themselves to targets and timetables for the reduction of GHGs. These targets for developed countries are often referred to as Assigned Amounts.\n\nOne important economic reality recognised by many of the countries that signed the Kyoto Protocol is that, if countries have to solely rely on their own domestic measures, the resulting inflexible limitations on GHG growth could entail very large costs, perhaps running into many trillions of dollars globally. As a result, international mechanisms which would allow developed countries flexibility to meet their targets were included in the Kyoto Protocol. The purpose of these mechanisms is to allow the parties to find the most economical ways to achieve their targets. These international mechanisms are outlined under Kyoto Protocol.\n\nOn April 17, 2009, the Environmental Protection Agency (EPA) formally announced that it had found that greenhouse gas (GHG) poses a threat to public health and the environment (EPA 2009a). This announcement was significant because it gives the executive branch the authority to impose carbon regulations on carbon-emitting entities.\n\nA carbon cap-and-trade system is to be introduced nationwide in China in 2016 (China's National Development and Reform Commission proposed that an absolute cap be placed on emission by 2016.)\n\nIn the United States, most polling shows large support for emissions trading (often referred to as cap-and-trade). This majority support can be seen in polls conducted by Washington Post/ABC News, Zogby International and Yale University. A new Washington Post-ABC poll reveals that majorities of the American people believe in climate change, are concerned about it, are willing to change their lifestyles and pay more to address it, and want the federal government to regulate greenhouse gases. They are, however, ambivalent on cap-and-trade.\n\nMore than three-quarters of respondents, 77.0%, reported they “strongly support” (51.0%) or “somewhat support” (26.0%) the EPA's decision to regulate carbon emissions. While 68.6% of respondents reported being “very willing” (23.0%) or “somewhat willing” (45.6%), another 26.8% reported being “somewhat unwilling” (8.8%) or “not at all willing” (18.0%) to pay higher prices for “Green” energy sources to support funding for programs that reduce the effect of global warming.\n\nAccording to PolitiFact, it is a misconception that emissions trading is unpopular in the United States because of earlier polls from Zogby International and Rasmussen which misleadingly include \"new taxes\" in the questions (taxes aren't part of emissions trading) or high energy cost estimates.\n\nCap and trade is the textbook emissions trading program. Other market-based approaches include baseline-and-credit, and pollution tax. They all put a price on pollution (for example, see carbon price), and so provide an economic incentive to reduce pollution beginning with the lowest-cost opportunities. By contrast, in a command-and-control approach, a central authority designates pollution levels each facility is allowed to emit. Cap and trade essentially functions as a tax where the tax rate is variable based on the relative cost of abatement per unit, and the tax base is variable based on the amount of abatement needed.\n\nIn a baseline and credit program, polluters can create permits, called credits or offsets, by reducing their emissions below a baseline level, which is often the historical emissions level from a designated past year. Such credits can be bought by polluters that have a regulatory limit.\n\nEmissions fees or environmental tax is a surcharge on the pollution created while producing goods and services. For example, a carbon tax is a tax on the carbon content of fossil fuels that aims to discourage their use and thereby reduce carbon dioxide emissions. The two approaches are overlapping sets of policy designs. Both can have a range of scopes, points of regulation, and price schedules. They can be fair or unfair, depending on how the revenue is used. Both have the effect of increasing the price of goods (such as fossil fuels) to consumers. A comprehensive, upstream, auctioned cap-and-trade system is very similar to a comprehensive, upstream carbon tax. Yet, many commentators sharply contrast the two approaches.\n\nThe main difference is what is defined and what derived. A tax is a price control, while cap-and-trade method acts is a quantity control instrument. That is, a tax is a unit price for pollution that is set by authorities, and the market determines the quantity emitted; in cap and trade, authorities determine the amount of pollution, and the market determines the price. This difference affects a number of criteria.\n\nResponsiveness to inflation: Cap-and-trade has the advantage that it adjusts to inflation (changes to overall prices) automatically, while emissions fees must be changed by regulators.\n\nResponsiveness to cost changes: It is not clear which approach is better. It is possible to combine the two into a safety valve price: a price set by regulators, at which polluters can buy additional permits beyond the cap.\n\nResponsiveness to recessions: This point is closely related to responsiveness to cost changes, because recessions cause a drop in demand. Under cap and trade, the emissions cost automatically decreases, so a cap-and-trade scheme adds another automatic stabilizer to the economy - in effect, an automatic fiscal stimulus. However, a lower pollution price also results in reduced efforts to reduce pollution. If the government is able to stimulate the economy regardless of the cap-and-trade scheme, an excessively low price causes a missed opportunity to cut emissions faster than planned. Instead, it might be better to have a price floor (a tax). This is especially true when cutting pollution is urgent, as with greenhouse gas emissions. A price floor also provides certainty and stability for investment in emissions reductions: recent experience from the UK shows that nuclear power operators are reluctant to invest on \"un-subsidised\" terms unless there is a guaranteed price floor for carbon (which the EU emissions trading scheme does not presently provide).\n\nResponsiveness to uncertainty: As with cost changes, in a world of uncertainty, it is not clear whether emissions fees or cap-and-trade systems are more efficient—it depends on how fast the marginal social benefits of reducing pollution fall with the amount of cleanup (e.g., whether inelastic or elastic marginal social benefit schedule).\n\nOther: The magnitude of the tax will depend on how sensitive the supply of emissions is to the price. The permit price of cap-and-trade will depend on the pollutant market. A tax generates government revenue, but full-auctioned emissions permits can do the same. A similar upstream cap-and-trade system could be implemented. An upstream carbon tax might be the simplest to administer. Setting up a complex cap-and-trade arrangement that is comprehensive has high institutional needs.\n\nCommand and control is a system of regulation that prescribes emission limits and compliance methods for each facility or source. It is the traditional approach to reducing air pollution.\n\nCommand-and-control regulations are more rigid than incentive-based approaches such as pollution fees and cap and trade. An example of this is a performance standard which sets an emissions goal for each polluter that is fixed and, therefore, the burden of reducing pollution cannot be shifted to the firms that can achieve it more cheaply. As a result, performance standards are likely to be more costly overall. The additional costs would be passed to end consumers.\n\nIt is possible for a country to reduce emissions using a Command-Control approach, such as regulation, direct and indirect taxes. The cost of that approach differs between countries because the Marginal Abatement Cost Curve (MAC) — the cost of eliminating an additional unit of pollution — differs by country. It might cost China $2 to eliminate a ton of CO, but it would probably cost Norway or the U.S. much more. International emissions-trading markets were created precisely to exploit differing MACs.\n\nEmissions trading through \"Gains from Trade\" can be more beneficial for both the buyer and the seller than a simple emissions capping scheme.\n\nConsider two European countries, such as Germany and Sweden. Each can either reduce all the required amount of emissions by itself or it can choose to buy or sell in the market.\nSuppose Germany can abate its CO at a much cheaper cost than Sweden, i.e. MAC > MAC where the MAC curve of Sweden is steeper (higher slope) than that of Germany, and R is the total amount of emissions that need to be reduced by a country.\n\nOn the left side of the graph is the MAC curve for Germany. R is the amount of required reductions for Germany, but at R the MAC curve has not intersected the market emissions permit price of CO (market permit price = P = λ). Thus, given the market price of CO allowances, Germany has potential to profit if it abates more emissions than required.\n\nOn the right side is the MAC curve for Sweden. R is the amount of required reductions for Sweden, but the MAC curve already intersects the market price of CO permits before R has been reached. Thus, given the market price of CO permits, Sweden has potential to make a cost saving if it abates fewer emissions than required internally, and instead abates them elsewhere.\n\nIn this example, Sweden would abate emissions until its MAC intersects with P (at R*), but this would only reduce a fraction of Sweden's total required abatement.\n\nAfter that it could buy emissions credits from Germany for the price \"P\" (per unit). The internal cost of Sweden's own abatement, combined with the permits it buys in the market from Germany, adds up to the total required reductions (R) for Sweden. Thus Sweden can make a saving from buying permits in the market (Δ d-e-f). This represents the \"Gains from Trade\", the amount of additional expense that Sweden would otherwise have to spend if it abated all of its required emissions by itself without trading.\n\nGermany made a profit on its additional emissions abatement, above what was required: it met the regulations by abating all of the emissions that was required of it (R). Additionally, Germany sold its surplus permits to Sweden, and was paid \"P\" for every unit it abated, while spending less than \"P\". Its total revenue is the area of the graph (R 1 2 R*), its total abatement cost is area (R 3 2 R*), and so its net benefit from selling emission permits is the area (Δ 1-2-3) i.e. Gains from Trade\n\nThe two R* (on both graphs) represent the efficient allocations that arise from trading.\n\nIf the total cost for reducing a particular amount of emissions in the \"Command Control\" scenario is called \"X\", then to reduce the same amount of combined pollution in Sweden and Germany, the total abatement cost would be less in the \"Emissions Trading\" scenario i.e. (X — Δ 123 - Δ def).\n\nThe example above applies not just at the national level, but also between two companies in different countries, or between two subsidiaries within the same company.\n\nThe nature of the pollutant plays a very important role when policy-makers decide which framework should be used to control pollution. CO acts globally, thus its impact on the environment is generally similar wherever in the globe it is released. So the location of the originator of the emissions does not matter from an environmental standpoint.\n\nThe policy framework should be different for regional pollutants (e.g. SO and NO, and also mercury) because the impact of these pollutants may differ by location. The same amount of a regional pollutant can exert a very high impact in some locations and a low impact in other locations, so it matters where the pollutant is released. This is known as the \"Hot Spot\" problem.\n\nA Lagrange framework is commonly used to determine the least cost of achieving an objective, in this case the total reduction in emissions required in a year. In some cases, it is possible to use the Lagrange optimization framework to determine the required reductions for each country (based on their MAC) so that the total cost of reduction is minimized. In such a scenario, the Lagrange multiplier represents the market allowance price (P) of a pollutant, such as the current market price of emission permits in Europe and the USA.\n\nCountries face the permit market price that exists in the market that day, so they are able to make individual decisions that would minimize their costs while at the same time achieving regulatory compliance. This is also another version of the Equi-Marginal Principle, commonly used in economics to choose the most economically efficient decision.\n\nThere has been longstanding debate on the relative merits of \"price\" versus \"quantity\" instruments to achieve emission reductions.\n\nAn emission cap and permit trading system is a \"quantity\" instrument because it fixes the overall emission level (quantity) and allows the price to vary. Uncertainty in future supply and demand conditions (market volatility) coupled with a fixed number of pollution permits creates an uncertainty in the future price of pollution permits, and the industry must accordingly bear the cost of adapting to these volatile market conditions. The burden of a volatile market thus lies with the industry rather than the controlling agency, which is generally more efficient. However, under volatile market conditions, the ability of the controlling agency to alter the caps will translate into an ability to pick \"winners and losers\" and thus presents an opportunity for corruption.\n\nIn contrast, an emission tax is a \"price\" instrument because it fixes the price while the emission level is allowed to vary according to economic activity. A major drawback of an emission tax is that the environmental outcome (e.g. a limit on the amount of emissions) is not guaranteed. On one hand, a tax will remove capital from the industry, suppressing possibly useful economic activity, but conversely, the polluter will not need to hedge as much against future uncertainty since the amount of tax will track with profits. The burden of a volatile market will be borne by the controlling (taxing) agency rather than the industry itself, which is generally less efficient. An advantage is that, given a uniform tax rate and a volatile market, the taxing entity will not be in a position to pick \"winners and losers\" and the opportunity for corruption will be less.\n\nAssuming no corruption and assuming that the controlling agency and the industry are equally efficient at adapting to volatile market conditions, the best choice depends on the sensitivity of the costs of emission reduction, compared to the sensitivity of the benefits (i.e., climate damage avoided by a reduction) when the level of emission control is varied.\n\nBecause there is high uncertainty in the compliance costs of firms, some argue that the optimum choice is the price mechanism. However, the burden of uncertainty cannot be eliminated, and in this case it is shifted to the taxing agency itself.\n\nThe overwhelming majority of climate scientists have repeatedly warned of a threshold in atmospheric concentrations of carbon dioxide beyond which a run-away warming effect could take place, with a large possibility of causing irreversible damage. With such a risk, a quantity instrument may be a better choice because the quantity of emissions may be capped with more certainty. However, this may not be true if this risk exists but cannot be attached to a known level of greenhouse gas (GHG) concentration or a known emission pathway.\n\nA third option, known as a \"safety valve\", is a hybrid of the price and quantity instruments. The system is essentially an emission cap and permit trading system but the maximum (or minimum) permit price is capped. Emitters have the choice of either obtaining permits in the marketplace or buying them from the government at a specified trigger price (which could be adjusted over time). The system is sometimes recommended as a way of overcoming the fundamental disadvantages of both systems by giving governments the flexibility to adjust the system as new information comes to light. It can be shown that by setting the trigger price high enough, or the number of permits low enough, the safety valve can be used to mimic either a pure quantity or pure price mechanism.\n\nAll three methods are being used as policy instruments to control greenhouse gas emissions: the EU-ETS is a \"quantity\" system using the cap and trading system to meet targets set by National Allocation Plans; Denmark has a price system using a carbon tax (World Bank, 2010, p. 218), while China uses the CO market price for funding of its Clean Development Mechanism projects, but imposes a \"safety valve\" of a minimum price per tonne of CO.\n\nCarbon leakage is the effect that regulation of emissions in one country/sector has on the emissions in other countries/sectors that are not subject to the same regulation. There is no consensus over the magnitude of long-term carbon leakage.\n\nIn the Kyoto Protocol, Annex I countries are subject to caps on emissions, but non-Annex I countries are not. Barker \"et al.\" (2007) assessed the literature on leakage. The leakage rate is defined as the increase in CO emissions outside the countries taking domestic mitigation action, divided by the reduction in emissions of countries taking domestic mitigation action. Accordingly, a leakage rate greater than 100% means that actions to reduce emissions within countries had the effect of increasing emissions in other countries to a greater extent, i.e., domestic mitigation action had actually led to an increase in global emissions.\n\nEstimates of leakage rates for action under the Kyoto Protocol ranged from 5% to 20% as a result of a loss in price competitiveness, but these leakage rates were considered very uncertain. For energy-intensive industries, the beneficial effects of Annex I actions through technological development were considered possibly substantial. However, this beneficial effect had not been reliably quantified. On the empirical evidence they assessed, Barker \"et al.\" (2007) concluded that the competitive losses of then-current mitigation actions, e.g., the EU ETS, were not significant.\n\nUnder the EU ETS rules Carbon Leakage Exposure Factor is used to determine the volumes of free allocation of emission permits to industrial installations.\n\nTo understand carbon trading, it is important to understand the products that are being traded. The primary product in carbon markets is the trading of GHG emission permits. Under a cap-and-trade system, permits are issued to various entities for the right to emit GHG emissions that meet emission reduction requirement caps.\n\nOne of the controversies about carbon mitigation policy is how to \"level the playing field\" with border adjustments. For example, one component of the American Clean Energy and Security Act (a 2009 bill that did not pass), along with several other energy bills put before US Congress, calls for carbon surcharges on goods imported from countries without cap-and-trade programs. Besides issues of compliance with the General Agreement on Tariffs and Trade, such border adjustments presume that the producing countries bear responsibility for the carbon emissions.\n\nA general perception among developing countries is that discussion of climate change in trade negotiations could lead to \"green protectionism\" by high-income countries (World Bank, 2010, p. 251). Tariffs on imports (\"virtual carbon\") consistent with a carbon price of $50 per ton of CO could be significant for developing countries. World Bank (2010) commented that introducing border tariffs could lead to a proliferation of trade measures where the competitive playing field is viewed as being uneven. Tariffs could also be a burden on low-income countries that have contributed very little to the problem of climate change.\n\nIn 1990, the first Intergovernmental Panel on Climate Change (IPCC) report highlighted the imminent threat of climate change and greenhouse gas emission, and diplomatic efforts began to find an international framework within which such emissions could be regulated. In 1997 the Kyoto Protocol was adopted.\nThe Kyoto Protocol is a 1997 international treaty that came into force in 2005. In the treaty, most developed nations agreed to legally binding targets for their emissions of the six major greenhouse gases. Emission quotas (known as \"Assigned amounts\") were agreed by each participating 'Annex I' country, with the intention of reducing the overall emissions by 5.2% from their 1990 levels by the end of 2012. Between 1990 and 2012 the original Kyoto Protocol parties reduced their CO2 emissions by 12.5%, which is well beyond the 2012 target of 4.7%. The United States is the only industrialized nation under Annex I that has not ratified the treaty, and is therefore not bound by it. The IPCC has projected that the financial effect of compliance through trading within the Kyoto commitment period will be limited at between 0.1-1.1% of GDP among trading countries.\nThe agreement was intended to result in industrialized countries' emissions declining in aggregate by 5.2 percent below 1990 levels by the year of 2012. Despite the failure of the United States and Australia to ratify the protocol, the agreement became effective in 2005, once the requirement that 55 Annex I (predominantly industrialized) countries, jointly accounting for 55 percent of 1990 Annex I emissions, ratify the agreement was met.\n\nThe Protocol defines several mechanisms (\"flexible mechanisms\") that are designed to allow Annex I countries to meet their emission reduction commitments (caps) with reduced economic impact.\n\nUnder Article 3.3 of the Kyoto Protocol, Annex I Parties may use GHG removals, from afforestation and reforestation (forest sinks) and deforestation (sources) since 1990, to meet their emission reduction commitments.\n\nAnnex I Parties may also use International Emissions Trading (IET). Under the treaty, for the 5-year compliance period from 2008 until 2012, nations that emit less than their quota will be able to sell assigned amount units (each AAU\nrepresenting an allowance to emit one metric tonne of CO) to nations that exceed their quotas. It is also possible for Annex I countries to sponsor carbon projects that reduce greenhouse gas emissions in other countries. These projects generate tradable carbon credits that can be used by Annex I countries in meeting their caps. The project-based Kyoto Mechanisms are the Clean Development Mechanism (CDM) and Joint Implementation (JI). There are four such international flexible mechanisms, or Kyoto Mechanism, written in the Kyoto Protocol.\n\nArticle 17 if the Protocol authorizes Annex 1 countries that have agreed to the emissions limitations to take part in emissions trading with other Annex 1 Countries.\n\nArticle 4 authorizes such parties to implement their limitations jointly, as the member states of the EU have chosen to do.\n\nArticle 6 provides that such Annex 1 countries may take part in joint initiatives (JIs) in return for emissions reduction units (ERUs) to be used against their Assigned Amounts.\n\nArt 12 provides for a mechanism known as the clean development mechanism (CDM), under which Annex 1 countries may invest in emissions limitation projects in developing countries and use certified emissions reductions (CERs) generated against their own Assigned Amounts.\n\nThe CDM covers projects taking place in non-Annex I countries, while JI covers projects taking place in Annex I countries. CDM projects are supposed to contribute to sustainable development in developing countries, and also generate \"real\" and \"additional\" emission savings, i.e., savings that only occur thanks to the CDM project in question (Carbon Trust, 2009, p. 14). Whether or not these emission savings are genuine is, however, difficult to prove (World Bank, 2010, pp. 265–267).\n\nIn 2003 the New South Wales (NSW) state government unilaterally established the NSW Greenhouse Gas Abatement Scheme to reduce emissions by requiring electricity generators and large consumers to purchase NSW Greenhouse Abatement Certificates (NGACs). This has prompted the rollout of free energy-efficient compact fluorescent lightbulbs and other energy-efficiency measures, funded by the credits. This scheme has been criticised by the Centre for Energy and Environmental Markets (CEEM) of the UNSW because of its lack of effectiveness in reducing emissions, its lack of transparency and its lack of verification of the additionality of emission reductions.\n\nBoth the incumbent Howard Coalition government and the Rudd Labor opposition promised to implement an emissions trading scheme (ETS) before the 2007 federal election. Labor won the election, with the new government proceeding to implement an ETS. The government introduced the Carbon Pollution Reduction Scheme, which the Liberals supported with Malcolm Turnbull as leader. Tony Abbott questioned an ETS, saying the best way to reduce emissions is with a \"simple tax\". Shortly before the carbon vote, Abbott defeated Turnbull in a leadership challenge, and from there on the Liberals opposed the ETS. This left the government unable to secure passage of the bill and it was subsequently withdrawn.\n\nJulia Gillard defeated Rudd in a leadership challenge and promised not to introduce a carbon tax, but would look to legislate a price on carbon when taking the government to the 2010 election. In the first hung parliament result in 70 years, the government required the support of crossbenchers including the Greens. One requirement for Greens support was a carbon price, which Gillard proceeded with in forming a minority government. A fixed carbon price would proceed to a floating-price ETS within a few years under the plan. The fixed price lent itself to characterisation as a carbon tax and when the government proposed the Clean Energy Bill in February 2011, the opposition claimed it to be a broken election promise.\n\nThe bill was passed by the Lower House in October 2011 and the Upper House in November 2011. The Liberal Party vowed to overturn the bill if elected. The bill thus resulted in passage of the Clean Energy Act, which possessed a great deal of flexibility in its design and uncertainty over its future.\n\nThe Liberal/National coalition government elected in September 2013 has promised to reverse the climate legislation of the previous government. In July 2014, the carbon tax was repealed as well as the Emissions Trading Scheme (ETS) that was to start in 2015.\n\nThe New Zealand Emissions Trading Scheme (NZ ETS) is a partial-coverage all-free allocation uncapped highly internationally linked emissions trading scheme. The NZ ETS was first legislated in the Climate Change Response (Emissions Trading) Amendment Act 2008 in September 2008 under the Fifth Labour Government of New Zealand and then amended in November 2009 and in November 2012 by the Fifth National Government of New Zealand.\n\nThe NZ ETS covers forestry (a net sink), energy (43.4% of total 2010 emissions), industry (6.7% of total 2010 emissions) and waste (2.8% of total 2010 emissions) but not pastoral agriculture (47% of 2010 total emissions). Participants in the NZ ETS must surrender two emissions units (either an international 'Kyoto' unit or a New Zealand-issued unit) for every three tonnes of carbon dioxide equivalent emissions reported or they may choose to buy NZ units from the government at a fixed price of NZ$25.\n\nIndividual sectors of the economy have different entry dates when their obligations to report emissions and surrender emission units take effect. Forestry, which contributed net removals of 17.5 Mts of COe in 2010 (19% of NZ's 2008 emissions,) entered the NZ ETS on 1 January 2008. The stationary energy, industrial processes and liquid fossil fuel sectors entered the NZ ETS on 1 July 2010. The waste sector (landfill operators) entered on 1 January 2013. Methane and nitrous oxide emissions from pastoral agriculture are not included in the NZ ETS. (From November 2009, agriculture was to enter the NZ ETS on 1 January 2015)\n\nThe NZ ETS is highly linked to international carbon markets as it allows the importing of most of the Kyoto Protocol emission units. However, as of June 2015, the scheme will effectively transition into a domestic scheme, with restricted access to international Kyoto units (CERs, ERUs and RMUs). The NZ ETS has a domestic unit; the 'New Zealand Unit' (NZU), which is issued by free allocation to emitters, with no auctions intended in the short term. Free allocation of NZUs varies between sectors. The commercial fishery sector (who are not participants) have a free allocation of units on a historic basis. Owners of pre-1990 forests have received a fixed free allocation of units. Free allocation to emissions-intensive industry, is provided on an output-intensity basis. For this sector, there is no set limit on the number of units that may be allocated. The number of units allocated to eligible emitters is based on the average emissions per unit of output within a defined 'activity'. Bertram and Terry (2010, p 16) state that as the NZ ETS does not 'cap' emissions, the NZ ETS is not a cap and trade scheme as understood in the economics literature.\n\nSome stakeholders have criticized the New Zealand Emissions Trading Scheme for its generous free allocations of emission units and the lack of a carbon price signal (the Parliamentary Commissioner for the Environment), and for being ineffective in reducing emissions (Greenpeace Aotearoa New Zealand).\n\nThe NZ ETS was reviewed in late 2011 by an independent panel, which reported to the Government and public in September 2011.\n\nThe European Union Emission Trading Scheme (or EU ETS) is the largest multi-national, greenhouse gas emissions trading scheme in the world. It is one of the EU's central policy instruments to meet their cap set in the Kyoto Protocol.\n\nAfter voluntary trials in the UK and Denmark, Phase I began operation in January 2005 with all 15 member states of the European Union participating. The program caps the amount of carbon dioxide that can be emitted from large installations with a net heat supply in excess of 20 MW, such as power plants and carbon intensive factories and covers almost half (46%) of the EU's Carbon Dioxide emissions. Phase I permits participants to trade among themselves and in validated credits from the developing world through Kyoto's Clean Development Mechanism. Credits are gained by investing in clean technologies and low-carbon solutions, and by certain types of emission-saving projects around the world to cover a proportion of their emissions.\n\nDuring Phases I and II, allowances for emissions have typically been given free to firms, which has resulted in them getting windfall profits. Ellerman and Buchner (2008) suggested that during its first two years in operation, the EU ETS turned an expected increase in emissions of 1%-2% per year into a small absolute decline. Grubb \"et al.\" (2009) suggested that a reasonable estimate for the emissions cut achieved during its first two years of operation was 50-100 MtCO per year, or 2.5%-5%.\n\nA number of design flaws have limited the effectiveness of the scheme. In the initial 2005-07 period, emission caps were not tight enough to drive a significant reduction in emissions. The total allocation of allowances turned out to exceed actual emissions. This drove the carbon price down to zero in 2007. This oversupply was caused because the allocation of allowances by the EU was based on emissions data from the European Environmental Agency in Copenhagen, which uses a horizontal activity-based emissions definition similar to the United Nations, the EU ETS Transaction log in Brussels, but a vertical installation-based emissions measurement system. This caused an oversupply of 200 million tonnes (10% of market) in the EU ETS in the first phase and collapsing prices.\n\nPhase II saw some tightening, but the use of JI and CDM offsets was allowed, with the result that no reductions in the EU will be required to meet the Phase II cap. For Phase II, the cap is expected to result in an emissions reduction in 2010 of about 2.4% compared to expected emissions without the cap (business-as-usual emissions). For Phase III (2013–20), the European Commission proposed a number of changes, including:\n\nIn January 2008, Norway, Iceland, and Liechtenstein joined the European Union Emissions Trading System (EU ETS), according to a publication from the European Commission. The Norwegian Ministry of the Environment has also released its draft National Allocation Plan which provides a carbon cap-and-trade of 15 million metric tonnes of CO, 8 million of which are set to be auctioned. According to the OECD Economic Survey of Norway 2010, the nation \"has announced a target for 2008-12 10% below its commitment under the Kyoto Protocol and a 30% cut compared with 1990 by 2020.\" In 2012, EU-15 emissions was 15.1% below their base year level. Based on figures for 2012 by the European Environment Agency, EU-15 emissions averaged 11.8% below base-year levels during the 2008-2012 period. This means the EU-15 over-achieved its first Kyoto target by a wide margin.\n\nThe Japanese city of Tokyo is like a country in its own right in terms of its energy consumption and GDP. Tokyo consumes as much energy as \"entire countries in Northern Europe, and its production matches the GNP of the world's 16th largest country\". A scheme to limit carbon emissions launched in April 2010 covers the top 1,400 emitters in Tokyo, and is enforced and overseen by the Tokyo Metropolitan Government. Phase 1, which is similar to Japan's scheme, ran until 2015. (Japan had an ineffective voluntary emissions reductions system for years, but no nationwide cap-and-trade program.) Emitters must cut their emissions by 6% or 8% depending on the type of organization; from 2011, those who exceed their limits must buy matching allowances or invest in renewable-energy certificates or offset credits issued by smaller businesses or branch offices. Polluters that fail to comply will be fined up to 500,000 yen plus credits for 1.3 times excess emissions. In its fourth year, emissions were reduced by 23% compared to base-year emissions. In phase 2, (FY2015-FY2019), the target is expected to increase to 15%-17%. The aim is to cut Tokyo's carbon emissions by 25% from 2000 levels by 2020. These emission limits can be met by using technologies such as solar panels and advanced fuel-saving devices.\n\nAn early example of an emission trading system has been the sulfur dioxide (SO) trading system under the framework of the Acid Rain Program of the 1990 Clean Air Act in the U.S. Under the program, which is essentially a cap-and-trade emissions trading system, SO emissions were reduced by 50% from 1980 levels by 2007. Some experts argue that the cap-and-trade system of SO emissions reduction has reduced the cost of controlling acid rain by as much as 80% versus source-by-source reduction. The SO program was challenged in 2004, which set in motion a series of events that led to the 2011 Cross-State Air Pollution Rule (CSAPR). Under the CSAPR, the national SO trading program was replaced by four separate trading groups for SO and NO.\nSO emissions from Acid Rain Program sources have fallen from 17.3 million tons in 1980 to about 7.6 million tons in 2008, a decrease in emissions of 56 percent. A 2014 EPA analysis estimated that implementation of the Acid Rain Program avoided between 20,000 and 50,000 incidences of premature mortality annually due to reductions of ambient PM2.5 concentrations, and between 430 and 2,000 incidences annually due to reductions of ground-level ozone.\n\nIn 2003, the Environmental Protection Agency (EPA) began to administer the NOx Budget Trading Program (NBP) under the NOx State Implementation Plan (also known as the \"NOx SIP Call\"). The NOx Budget Trading Program was a market-based cap and trade program created to reduce emissions of nitrogen oxides (NO) from power plants and other large combustion sources in the eastern United States. NO is a prime ingredient in the formation of ground-level ozone (smog), a pervasive air pollution problem in many areas of the eastern United States. The NBP was designed to reduce NO emissions during the warm summer months, referred to as the ozone season, when ground-level ozone concentrations are highest. In March 2008, EPA again strengthened the 8-hour ozone standard to 0.075 parts per million (ppm) from its previous 0.08 ppm.\n\nOzone season NOx emissions decreased by 43 percent between 2003 and 2008, even while energy demand remained essentially flat during the same period. CAIR will result in $85 billion to $100 billion in health benefits and nearly $2 billion in visibility benefits per year by 2015 and will substantially reduce premature mortality in the eastern United States.\nNOx reductions due to the NOx Budget Trading Program have led to improvements in ozone and PM2.5, saving an estimated 580 to 1,800 lives in 2008.\n\nA 2017 study in the \"American Economic Review\" found that the NOx Budget Trading Program decreased NOx emissions and ambient ozone concentrations. The program reduced expenditures on medicine by about 1.5% ($800 million annually) and reduced the mortality rate by up to 0.5% (2,200 fewer premature deaths, mainly among individuals 75 and older).\n\nIn the United States the Environmental Protection Agency (EPA) classifies Volatile Organic Compounds (VOCs) as gases emitted from certain solids and liquids that may have adverse health effects. These VOCs include a variety of chemicals that are emitted from a variety of different products. These include products such as gasoline, perfumes, hair spray, fabric cleaners, PVC, and refrigerants; all of which can contain chemicals such as benzene, acetone, methylene chloride, freons, formaldehyde.\n\nVOCs are also monitored by the United States Geological Survey for its presence in groundwater supply. The USGS concluded that many of the nations aquifers are at risk to low-level VOC contamination. The common symptoms of short levels of exposure to VOCs include headaches, nausea, and eye irritation. If exposed for an extended period of time the symptoms include cancer and damage to the central nervous system.\n\nAs of 2017, there is no national emissions trading scheme in the United States. Failing to get Congressional approval for such a scheme, President Barack Obama instead acted through the United States Environmental Protection Agency to attempt to adopt through rulemaking the Clean Power Plan, which does not feature emissions trading. (The plan was subsequently challenged and is under review by the administration of President Donald Trump.)\n\nConcerned at the lack of federal action, several states on the east and west coasts have created sub-national cap-and-trade programs.\n\nIn 2003, New York State proposed and attained commitments from nine Northeast states to form a cap-and-trade carbon dioxide emissions program for power generators, called the Regional Greenhouse Gas Initiative (RGGI). This program launched on January 1, 2009 with the aim to reduce the carbon \"budget\" of each state's electricity generation sector to 10% below their 2009 allowances by 2018.\n\nAlso in 2003, U.S. corporations were able to trade CO emission allowances on the Chicago Climate Exchange under a voluntary scheme. In August 2007, the Exchange announced a mechanism to create emission offsets for projects within the United States that cleanly destroy ozone-depleting substances.\n\nIn 2006, the California Legislature passed the California Global Warming Solutions Act, AB-32, which was signed into law by Governor Arnold Schwarzenegger. Thus far, flexible mechanisms in the form of project based offsets have been suggested for three main project types. The project types include: manure management, forestry, and destruction of ozone-depleted substances. However, a ruling from Judge Ernest H. Goldsmith of San Francisco's Superior Court stated that the rules governing California's cap-and-trade system were adopted without a proper analysis of alternative methods to reduce greenhouse gas emissions. The tentative ruling, issued on 24 January 2011, argued that the California Air Resources Board violated state environmental law by failing to consider such alternatives. If the decision is made final, the state would not be allowed to implement its proposed cap-and-trade system until the California Air Resources Board fully complies with the California Environmental Quality Act. California's cap-and-trade program ranks only second to the ETS (European Trading System) carbon market in the world. In 2012, under the auction, the reserve price, which is the price per ton of CO2 permit is $10. Some of the emitters obtain allowances for free, which is for the electric utilities, industrial facilities and natural gas distributors, whereas some of the others have to go to the auction.\n\nIn 2014, the Texas legislature approved a 10% reduction for the Highly Reactive Volatile Organic Compound (HRVOC) emission limit. This was followed by a 5% reduction for each subsequent year until a total of 25% percent reduction was achieved in 2017.\n\nIn February 2007, five U.S. states and four Canadian provinces joined together to create the Western Climate Initiative (WCI), a regional greenhouse gas emissions trading system. In July 2010, a meeting took place to further outline the cap-and-trade system. In November 2011, Arizona, Montana, New Mexico, Oregon, Utah and Washington withdrew from the WCI.\n\nIn 1997, the State of Illinois adopted a trading program for volatile organic compounds in most of the Chicago area, called the Emissions Reduction Market System. Beginning in 2000, over 100 major sources of pollution in eight Illinois counties began trading pollution credits.\n\nPresident Barack Obama in his proposed 2010 United States federal budget wanted to support clean energy development with a 10-year investment of US$15 billion per year, generated from the sale of greenhouse gas (GHG) emissions credits. Under the proposed cap-and-trade program, all GHG emissions credits would have been auctioned off, generating an estimated $78.7 billion in additional revenue in FY 2012, steadily increasing to $83 billion by FY 2019. The proposal was never made law.\n\nThe American Clean Energy and Security Act (H.R. 2454), a greenhouse gas cap-and-trade bill, was passed on 26 June 2009, in the House of Representatives by a vote of 219-212. The bill originated in the House Energy and Commerce Committee and was introduced by Representatives Henry A. Waxman and Edward J. Markey. The political advocacy organizations FreedomWorks and Americans for Prosperity, funded by brothers David and Charles Koch of Koch Industries, encouraged the Tea Party movement to focus on defeating the legislation. Although cap and trade also gained a significant foothold in the Senate via the efforts of Republican Lindsey Graham, Independent and former Democrat Joe Lieberman, and Democrat John Kerry, the legislation died in the Senate.\n\nSouth Korea's national emissions trading scheme officially launched on 1 January 2015, covering 525 entities from 23 sectors. With a three-year cap of 1.8687 billion tCO2e, it now forms the second largest carbon market in the world following the EU ETS. This amounts to roughly two-thirds of the country's emissions. The Korean emissions trading scheme is part of the Republic of Korea's efforts to reduce greenhouse gas emissions by 30% compared to the business-as-usual scenario by 2020.\n\nIn an effort to reverse the adverse consequences of air pollution, in 2006, China started to consider a national pollution permit trading system in order to use market-based mechanisms to incentivize companies to cut pollution. This has been based on a previous pilot project called the Industrial SO2 emission trading pilot scheme, which was launched in 2002. Four provinces, three municipalities and one business entity was involved in this pilot project (also known as the 4+3+1 project). They are Shandong, Shanxi, Jiangsu, Henan, Shanghai, Tianjin, Liuzhou and China Huaneng Group, a state-owned company in the power industry. This pilot project did not turn into a bigger scale inter-provincial trading system, but it stimulated numerous local trading platforms. \n\nIn 2014, when the Chinese government started considering a national level pollution permit trading system again, there were more than 20 local pollution permit trading platforms. The Yangtze River Delta region as a whole has also run test trading, but the scale was limited. In the same year, the Chinese government proposed establishing a carbon market, focused on CO2 reduction later in the decade, and it is a separate system from the pollution permit trading.\n\nChina currently emits about 30% of global emission, and it became the largest emitter in the world. When the market launched, it will be the largest carbon market in the world. The initial design of the system targets a scope of 3.5 billion tons of carbon dioxide emissions that come from 1700 installations. It has made a voluntary pledge under the UNFCCC to lower CO2 per unit of GDP by 40 to 45% in 2020 when comparing to the 2005 levels.\n\nIn November 2011, China approved pilot tests of carbon trading in seven provinces and cities – Beijing, Chongqing, Shanghai, Shenzhen, Tianjin as well as Guangdong Province and Hubei Province, with different prices in each region. The pilot is intended to test the waters and provide valuable lessons for the design of a national system in the near future. Their successes or failures will, therefore, have far-reaching implications for carbon market development in China in terms of trust in a national carbon trading market. Some of the pilot regions can start trading as early as 2013/2014. National trading is expected to start in 2017, latest in 2020. \n\nThe effort to start a national trading system has faced some problems that took longer than expected to solve, mainly in the complicated process of initial data collection to determine the base level of pollution emission. According to the initial design, there will be eight sectors that are first included in the trading system, chemicals, petrochemicals, iron and steel, non-ferrous metals, building materials, paper, power and aviation, but many of the companies involved lacked consistent data. Therefore, by the end of 2017, the allocation of emission quotas have started but it has been limited to only the power sector and will gradually expand, although the operation of the market is yet to begin. In this system, Companies that are involved will be asked to meet target level of reduction and the level will contract gradually. \n\nTrading is set to begin in 2014 after a three-year rollout period. It is a mandatory energy efficiency trading scheme covering eight sectors responsible for 54 per cent of India's industrial energy consumption. India has pledged a 20 to 25 per cent reduction in emissions intensity from 2005 levels by 2020. Under the scheme, annual efficiency targets will be allocated to firms. Tradable energy-saving permits will be issued depending on the amount of energy saved during a target year.\n\nRenewable Energy Certificates (occasionally referred to as or \"green tags\" [citation required]), are a largely unrelated form of market-based instruments that are used to achieve renewable energy targets, which may be environmentally motivated (like emissions reduction targets), but may also be motivated by other aims, such as energy security or industrial policy.\n\nCarbon emissions trading is emissions trading specifically for carbon dioxide (calculated in tonnes of carbon dioxide equivalent or tCOe) and currently makes up the bulk of emissions trading. It is one of the ways countries can meet their obligations under the Kyoto Protocol to reduce carbon emissions and thereby mitigate global warming.\n\nTrading can be done directly between buyers and sellers, through several organised exchanges or through the many intermediaries active in the carbon market. The price of allowances is determined by supply and demand. As many as 40 million allowances have been traded per day. In 2012, 7.9 billion allowances were traded with a total value of €56 billion. Carbon emissions trading declined in 2013, and is expected to decline in 2014.\n\nAccording to the World Bank's Carbon Finance Unit, 374 million metric tonnes of carbon dioxide equivalent (tCOe) were exchanged through projects in 2005, a 240% increase relative to 2004 (110 mtCOe) which was itself a 41% increase relative to 2003 (78 mtCOe).\n\nGlobal carbon markets have shrunk in value by 60% since 2011, but are expected to rise again in 2014.\n\nIn terms of dollars, the World Bank has estimated that the size of the carbon market was US$11 billion in 2005, $30 billion in 2006, and $64 billion in 2007.\n\nThe Marrakesh Accords of the Kyoto protocol defined the international trading mechanisms and registries needed to support trading between countries (\"sources can buy or sell allowances on the open market. Because the total number of allowances is limited by the cap, emission reductions are assured.\"). Allowance trading now occurs between European countries and Asian countries. However, while the US as a nation did not ratify the protocol, many of its states are developing cap-and-trade systems and considering ways to link them together, nationally and internationally, to find the lowest costs and improve liquidity of the market. However, these states also wish to preserve their individual integrity and unique features. For example, in contrast to other Kyoto-compliant systems, some states propose other types of greenhouse gas sources, different measurement methods, setting a maximum on the price of allowances, or restricting access to CDM projects. Creating instruments that are not fungible (exchangeable) could introduce instability and make pricing difficult. Various proposals for linking these systems across markets are being investigated, and this is being coordinated by the International Carbon Action Partnership (ICAP).\n\nIn 2008, Barclays Capital predicted that the new carbon market would be worth $70 billion worldwide that year. The voluntary offset market, by comparison, is projected to grow to about $4bn by 2010.\n\n23 multinational corporations came together in the G8 Climate Change Roundtable, a business group formed at the January 2005 World Economic Forum. The group included Ford, Toyota, British Airways, BP and Unilever. On June 9, 2005 the Group published a statement stating the need to act on climate change and stressing the importance of market-based solutions. It called on governments to establish \"clear, transparent, and consistent price signals\" through \"creation of a long-term policy framework\" that would include all major producers of greenhouse gases. By December 2007, this had grown to encompass 150 global businesses.\n\nBusiness in the UK have come out strongly in support of emissions trading as a key tool to mitigate climate change, supported by NGOs. However, not all businesses favor a trading approach. On December 11, 2008, Rex Tillerson, the CEO of Exxonmobil, said a carbon tax is \"a more direct, more transparent and more effective approach\" than a cap-and-trade program, which he said, \"inevitably introduces unnecessary cost and complexity\". He also said that he hoped that the revenues from a carbon tax would be used to lower other taxes so as to be revenue neutral.\n\nThe International Air Transport Association, whose 230 member airlines comprise 93% of all international traffic, position is that trading should be based on \"benchmarking\", setting emissions levels based on industry averages, rather than \"grandfathering\", which would use individual companies’ previous emissions levels to set their future permit allowances. They argue grandfathering \"would penalise airlines that took early action to modernise their fleets, while a benchmarking approach, if designed properly, would reward more efficient operations\".\n\nAssuring compliance with an emissions trading scheme requires measuring, reporting and verification (MRV). Measurements are needed at each operator or installation. These measurements are reported to a regulator. For greenhouse gases, all trading countries maintain an inventory of emissions at national and installation level; in addition, trading groups within North America maintain inventories at the state level through The Climate Registry. For trading between regions, these inventories must be consistent, with equivalent units and measurement techniques.\n\nIn some industrial processes, emissions can be physically measured by inserting sensors and flowmeters in chimneys and stacks, but many types of activity rely on theoretical calculations instead of measurement. Depending on local legislation, measurements may require additional checks and verification by government or third party auditors, prior or post submission to the local regulator.\n\nIn contrast to an ordinary market, in a pollution market the amount purchased is not necessarily the amount 'consumed' (= the amount of pollution emitted). A firm might buy a small amount of allowances but emit a much larger amount of pollution. This creates a troublesome moral hazard problem.\n\nThis problem may be solved by a centralized regulator. The regulator should perform Measuring, Reporting and Verification (MRV) of the actual pollution levels, and enforce the allowances. Without effective MRV and enforcement, the value of allowances diminishes. Enforcement methods include fines and sanctions for polluters that have exceeded their allowances. Concerns include the cost of MRV and enforcement, and the risk that facilities may lie about actual emissions. The net effect of a corrupt reporting system or poorly managed or financed regulator may be a discount on emission costs, and a hidden increase in actual emissions.\n\nAccording to Nordhaus, strict enforcement of the Kyoto Protocol is likely to be observed in those countries and industries covered by the EU ETS.\nEllerman and Buchner commented on the European Commission's (EC's) role in enforcing scarcity of permits within the EU ETS.\nThis was done by the EC's reviewing the total number of permits that member states proposed that their industries be allocated. Based on institutional and enforcement considerations, Kruger \"et al.\" suggested that emissions trading within developing countries might not be a realistic goal in the near-term.\nBurniaux \"et al.\" argued that due to the difficulty in enforcing international rules against sovereign states, development of the carbon market would require negotiation and consensus-building.\n\nAn alternative to centralized regulation is distributed regulation, in which the firms themselves are induced to inspect the other firms and report their misbehavior. It is possible to implement such systems in subgame perfect equilibrium. Moore and Repullo present an implementation with unbounded fines; Kahana and Mealem and Nitzan present an implementation with bounded fines. Their work extends the work of Duggan and Roberts by adding a second component which takes care of the moral hazard.\n\nEmissions trading has been criticised for a variety of reasons.\n\nFor example, in the popular science magazine \"New Scientist\", Lohmann (2006) argued that trading pollution allowances should be avoided as a climate stabilization policy for several reasons. First, climate change requires more radical changes than previous pollution trading schemes such as the US SO market. It requires reorganizing society and technology to \"leave most remaining fossil fuels safely underground\". Carbon trading schemes have tended to reward the heaviest polluters with 'windfall profits' when they are granted enough carbon credits to match historic production. Expensive long-term structural changes will not be made if there are cheaper sources of carbon credits which are often available from less developed countries, where they may be generated by local polluters at the expense of local communities.\n\nResearch by Preston Teeter and Jorgen Sandberg has shown that the flexibility, and thus complexity, inherent in cap and trade schemes has resulted in a great deal of policy uncertainty surrounding these schemes. Such uncertainty has beset such schemes in Australia, Canada, China, the EU, India, Japan, New Zealand, and the US. As a result of this uncertainty, organizations have little incentive to innovate and comply, resulting in an ongoing battle of stakeholder contestation for the past two decades.\n\nLohmann (2006b) supported conventional regulation, green taxes, and energy policies that are \"justice-based\" and \"community-driven.\" According to Carbon Trade Watch (2009), carbon trading has had a \"disastrous track record.\" The effectiveness of the EU ETS was criticized, and it was argued that the CDM had routinely favoured \"environmentally ineffective and socially unjust projects.\"\n\nAnnie Leonard's 2009 documentary \"The Story of Cap and Trade\" criticized carbon emissions trading for the free permits to major polluters giving them unjust advantages, cheating in connection with carbon offsets, and as a distraction from the search for other solutions.\n\nForest campaigner Jutta Kill (2006) of European environmental group FERN argued that offsets for emission reductions were not substitute for actual cuts in emissions. Kill stated that \"[carbon] in trees is temporary: Trees can easily release carbon into the atmosphere through fire, disease, climatic changes, natural decay and timber harvesting.\"\n\nRegulatory agencies run the risk of issuing too many emission credits, which can result in a very low price on emission permits. This reduces the incentive that permit-liable firms have to cut back their emissions. On the other hand, issuing too few permits can result in an excessively high permit price. This an argument for a hybrid instrument having a price-floor, i.e., a minimum permit price, and a price-ceiling, i.e., a limit on the permit price. However, a price-ceiling (safety value) removes the certainty of a particular quantity limit of emissions.\n\nIf polluters receive emission permits for free (\"grandfathering\"), this may be a reason for them not to cut their emissions because if they do they will receive fewer permits in the future.\n\nThis perverse incentive can be alleviated if permits are auctioned, i.e., sold to polluters, rather than giving them the permits for free. Auctioning is a method for distributing emission allowances in a cap-and-trade system whereby allowances are sold to the highest bidder. Revenues from auctioning go to the government and can be used for development of sustainable technology or to cut distortionary taxes, thus improving the efficiency of the overall cap policy.\n\nOn the other hand, allocating permits can be used as a measure to protect domestic firms who are internationally exposed to competition. This happens when domestic firms compete against other firms that are not subject to the same regulation. This argument in favor of allocation of permits has been used in the EU ETS, where industries that have been judged to be internationally exposed, e.g., cement and steel production, have been given permits for free).\n\nThis method of distribution may be combined with other forms of allowance distribution.\n\nThe US Congressional Budget Office (CBO, 2009) examined the potential effects of the American Clean Energy and Security Act on US households. This act relies heavily on the free allocation of permits. The Bill was found to protect low-income consumers, but it was recommended that the Bill be made more efficient by reducing welfare provisions for corporations, and more resources be made available for consumer relief.\n\nDistinct cap-and-trade systems can be linked together through the mutual or unilateral recognition of emissions allowances for compliance. Linking systems creates a larger carbon market, which can reduce overall compliance costs, increase market liquidity and generate a more stable carbon market. Linking systems can also be politically symbolic as it shows willingness to undertake a common effort to reduce GHG emissions. Some scholars have argued that linking may provide a starting point for developing a new, bottom-up international climate policy architecture, whereby multiple unique systems successively link their various systems.\n\nIn 2014, the U.S. state of California and the Canadian province of Québec successfully linked their systems. In 2015, the provinces of Ontario and Manitoba agreed to join the linked system between Quebec and California. On 22 September 2017, the premiers of Quebec and Ontario, and the Governor of California, signed the formal agreement establishing the linkage.\n\nThe International Carbon Action Partnership brings together regional, national and sub-national governments and public authorities from around the world to discuss important issues in the design of emissions trading schemes (ETS) and the way forward to a global carbon market. 30 national and subnational jurisdictions have joined ICAP as members since its establishment in 2007.\n\n\n"}
{"id": "401466", "url": "https://en.wikipedia.org/wiki?curid=401466", "title": "Environmentalist Agrarian Party", "text": "Environmentalist Agrarian Party\n\nThe Environmentalist Agrarian Party () is an Albanian political party, founded in 1991.\n\nThe party was founded by Lufter Xhuveli. Initially the party was known as the Agrarian Party of Albania (\"Partia Agrare e Shqipërisë\"), until a name change took place in 2003. It is a reformist party that supports a free market economic system.\n\nIn the 1997 elections the party won one of the single-member constituency seats, but none of the proportional seats. In total the party got 0.65%. In the June 2001 elections, it received 2.6% of the vote and three seats in Parliament, Lufter Xhuveli from Zone 125, Ndue Preka from Zone 126 and Refat Dervina from Zone 127.\n\nIn the 2003 local elections, the first contested under the new name PAA, the party contested in alliance with the Socialist Party of Albania (PSSH) in some areas. The PAA-PSSH combine won in three municipalities.\n\nIn the 2005 parliamentary elections the party received 88,605 votes (6.5%) and 4 seats.\n\nIn 1998 Xhuveli became Minister of Agriculture. Under the Majko government he was made Minister for the Environment in February 2002. In 2003 he was replaced during the reforms of Prime Minister Fatos Nano.\n\nOn 2016 Xhuveli resigned and the current leader of the party is Agron Duka, a former member and MP of the Republican Party of Albania.\n"}
{"id": "20126705", "url": "https://en.wikipedia.org/wiki?curid=20126705", "title": "FERET (facial recognition technology)", "text": "FERET (facial recognition technology)\n\nThe Facial Recognition Technology (FERET) program was a government-sponsored project that aimed to create a large, automatic face-recognition system for intelligence, security, and law enforcement purposes. The program began in 1993 under the combined leadership of Dr. Harry Wechsler at George Mason University (GMU) and Dr. Jonathan Phillips at the Army Research Laboratory (ARL) in Adelphi, Maryland and resulted in the development of the Facial Recognition Technology (FERET) database. The goal of the FERET program was to advance the field of face recognition technology by establishing a common database of facial imagery for researchers to use and setting a performance baseline for face-recognition algorithms.\n\nPotential areas where this face-recognition technology could be used include:\n\n\nThe FERET database has been used by more than 460 research groups and is currently managed by the National Institute of Standards and Technology (NIST). By 2017, the FERET database has been used to train artificial intelligence programs and computer vision algorithms to identify and sort faces.\n\nThe FERET program first began as a way to unify a large body of face-recognition technology research under a standard database. Before the program’s inception, most researchers created their own facial imagery database that was attuned to their own specific area of study. These personal databases were small and usually consisted of images from less than 50 individuals. The only notable exceptions were the following:\n\n\nThe lack of a common database made it difficult to compare the results of face recognition studies in the scientific literature because each report involved different assumptions, scoring methods, and images. Most of the papers that were published did not use images from a common database nor followed a standard testing protocol. As a result, researchers were unable to make informed comparisons between the performances of different face-recognition algorithms. \n\nIn September 1993, the FERET program was spearheaded by Dr. Harry Wechsler and Dr. Jonathan Phillips under the sponsorship of the U.S. Department of Defense Counterdrug Technology Development Program.\n\nThe first facial images for the FERET database were collected from August 1993 to December 1994, a time period known as Phase I. The pictures were initially taken with a 35-mm camera at both GMU and ARL facilities, and the same physical setup was used in each photography session to keep the images consistent. For each individual, the pictures were taken in sets, including two frontal views, a right and left profile, a right and left quarter profile, a right and left half profile, and sometimes at five extra locations. Therefore, a set of images consisted of 5 to 11 images per person. At the end of Phase I, the FERET database had collected 673 sets of images, resulting in over 5000 total images.\n\nAt the end of Phase I, five organizations were given the opportunity to test their face-recognition algorithm on the newly-created FERET database in order to compare how they performed against each other. There five principal investigators were:\n\n\nDuring this evaluation, three different automatic tests were given to the principal investigators without human intervention:\n\n\nFor most of the test trials, the algorithms developed by USC and MIT managed to outperform the other three algorithms for the Phase I evaluation.\n\nPhase II began after Phase I, and during this time, the FERET database acquired more sets of facial images. By the start of the Phase II evaluation in March 1995, the database contained 1109 sets of images for a total of 8525 images of 884 individuals. During the second evaluation, the same algorithms from the Phase I evaluation were given a single test. However, the database now contained significantly more duplicate images (463, compared to the previous 60), making the test more challenging.\n\nAfterwards, the FERET program entered Phase III where another 456 sets of facial images were added to the database. The Phase III evaluation, which took place on September 1996, aimed to not only gauge the progress of the algorithms since the Phase I assessment but also identify the strengths and weaknesses of each algorithm and determine future objectives for research. By the end of 1996, the FERET database had accumulated a total of 14,126 facial images pertaining to 1199 different individuals as well as 365 duplicate sets of images.\n\nAs a result of the FERET program, researchers were able to establish a common baseline for comparing different face-recognition algorithms and create a large standard database of facial images that is open for research.\n\nIn 2003, DARPA released a high-resolution, 24-bit color version of the images in the FERET database (existing reference).\n\n"}
{"id": "16101793", "url": "https://en.wikipedia.org/wiki?curid=16101793", "title": "Golos (election monitor)", "text": "Golos (election monitor)\n\nGOLOS was founded as an association of non-profit organizations in 2000 to support civil monitoring of elections.\n\nSince 2002 GOLOS has monitored elections and referendums of all levels. The Telegraph describes GOLOS as being \"one of the few organisations able to catalogue and publicise [the Kremlin's] attempts at fraud and intimidation\".\n\nThe group publishes a newspaper called \"Grazhdansky Golos\" (Civil Voice).\n\nIn the 2008 presidential election and accompanying local elections, GOLOS representatives found many irregularities, including the following.\n\nDuring the 2011 Russian legislative election, 2,000 monitors coordinated by GOLOS took part in election observation.\n\nGOLOS set up an interactive map of violations to which users could submit reports, video evidence, audio recordings and photographs. It attracted over 4,500 reports alleging illegal campaign tactics, including stories of employers threatening workers with pay cuts and local officials ordering business leaders to pressure subordinates.\n\nCiting the map, Russian prosecutors charged GOLOS with publishing election data during the five days before voting. It also accused Golos of \"dissemination of rumors under the guise of trustworthy reports, with the goal of defaming a party as well as its individual members.” Golos was subsequently fined for these alleged breaches.\n\nDuring the election, the website was subjected to Denial-of-service attacks. The state-owned channel NTV showed reports accusing GOLOS Association of disrupting the elections paid for by the United States.\n\nIn early 2012, Russia introduced legislation which required NGOs receiving foreign donations to present themselves as \"foreign agents\" in outward communication.\n\nThe same year, GOLOS received the Andrei Sakharov Freedom Award of the Norwegian Helsinki Committee. While both Golos and the Helsinki Committee stated that Golos had not accepted the prize money, Russia's Justice Ministry in April 2013 used it as a reason to qualify Golos as the first \"foreign agent\" under the new legislation. After GOLOS refused to register as such, it was suspended in June 2013 for six months. After its suspension in 2013, GOLOS reorganized as civil movement \"Golos\" to continue its work.\n\nOn 7 July 2015, Russian police raided the offices and the homes of several Golos employees and confiscated equipment including computers. Police linked the raids to a tax investigation against the head of the group's branch in Samara. The police raid was accompanied by a TV crew from state-controlled NTV.\n\nIn February 2016, the Justice Ministry asked Moscow's Basmanny District Court to ban GOLOS, citing a failure to present proper documentation.\n\nIn July 2016, a court ordered the liquidation of Golos within six months due to \"serious irremediable breaches of law”. Golos is appealing the decision.\n\nGolos is a member of the \"European Network of Election Monitoring Organizations\" (ENEMO). It is also a member of the \"European Platform for Democratic Elections\" (epde) an association of election monitors in Eastern Europe.\n\nAfter its suspension in 2013, Golos reorganized as a civil movement. It consists of independent organizations such as Golos-Povolzhye (located in Samara) and Golos-Ural (located in Chelyabinsk).\n\nAfter an appeal by the Presidential Human Rights Council, regional organization of Golos received funds from Russia's presidential administration. In April 2013, the head of Golos Grigory Melkonyants announced that it suspended any foreign funding. In addition to the presidential grants, projects of Golos in the past have received donations from the European Commission, USAID as well as NED.\n\nOn November 30, 2011 the board of the \"Memorial International Society\" supported GOLOS against attacks from pro-Kremlin media: \n\n"}
{"id": "1387685", "url": "https://en.wikipedia.org/wiki?curid=1387685", "title": "Greek Financial Audit, 2004", "text": "Greek Financial Audit, 2004\n\nThe Greek Financial Audit was a 2004 investigation into the true extent of Greece's public finances. It examined government revenue, spending and the level of Greek government borrowing.\n\nWithin the European Union, entry into the Eurozone depends on the applicant nation meeting certain economic criteria. Measures such as budget deficits and public debt levels are assessed, as well as the inflation situation and the stability of the national currency exchange rate of a European Union member state. Requirements include a budget deficit below 3% of gross domestic product (GDP), and debt below 60% of GDP, or if above, declining.\n\nUp until 1994, Greece recorded very high deficits, for some years above 10% of GDP. During the late nineties, according to the figures submitted by the Greek government to the European Union, Greece's high budget deficits were significantly lowered. In 2000, given a deficit below 3% of GDP in 1999, Greece was accepted as the 12th member of the European monetary union.\n\nIn March 2002, Eurostat refused to validate data transmitted by the Greek government. In reaction, the NSSG (National Statistical Service of Greece) revised the debt level by several percentage points. In September 2002, Eurostat again refused to validate the data. The debt was revised upwards once again, and the government balance, which the Greek government had presented as a surplus, became a deficit.\n\nIn March 2004, Eurostat refused again to validate the Greek numbers. That was shortly before Greek elections, and a new government by New Democracy was inaugurated.\n\nAfter the March 7 elections, the new government said that it would start an objective financial audit of the government accounts. George Papandreou, of Panhellenic Socialist Movement (PASOK), the main opposition at that time, and the other two smaller parties initially agreed with the need for an audit. The agreement lasted a very short time, and outside auditing firms and the central bank were not asked to carry out such an audit.\n\nInstead, the government produced new estimates while it investigated the years 1997 to 2003, and the resulting data was given to Eurostat, which then went on and published a report. The requirement that the 1999 budget deficit should have been below 3% of GDP was one of the key criteria for Eurozone entry. Its revision to 3.07%, according to Eurostat (AMECO), led to a controversy about Greece's admission.\n\nIn the 2005 OECD report for Greece (p. 47) it was clearly stated that \"the impact of new accounting rules on the fiscal figures for the years 1997 to 1999 ranged from 0.7 to 1 percentage point of GDP; this retroactive change of methodology was responsible for the revised deficit exceeding 3% in 1999, the year of EMU membership qualification\". The above has led the Greek minister of finance to clarify that the 1999 budget deficit was below the prescribed 3% limit when it was calculated with the ESA79 methodology in force at the time of Greece's application. Since the remaining criteria had also been met, was properly accepted into the Eurozone. ESA79 was also the methodology employed to calculate the deficits of all other Eurozone members at the time of their applications.\n\nThe original accounting practice for military expenses was later restored in line with Eurostat recommendations, theoretically lowering even the ESA95-calculated 1999 Greek budget deficit to below 3% (an official Eurostat calculation is still pending for 1999).\n\nAn error frequently made in press reports is the confusion of the discussion regarding Greece’s Eurozone entry with the controversy regarding usage of derivatives’ deals with US banks by Greece and other Eurozone countries to hide their reported budget deficits. A currency swap arranged with Goldman Sachs allowed Greece to 'hide' 2.8 billion euros of debt, but that affected deficit values after 2001 (when Greece had already been admitted into the Eurozone) and is not related to Greece's Eurozone entry.\n\nSeveral arguments have been expressed about the implications of the audit. Some commentators talked about data falsification. Others held a completely different viewpoint. \"Irregularities\" (the word falsification never officially used) in deficit reporting were also revealed for other Eurozone members, most notably Italy and Portugal, with significant revisions imposed. Also, there were arguments about massive \"creative accounting\" employed by many states in order to meet the deficit criterion for entry into the Eurozone.\n\nEven the practice of one-off measures by so many states has been criticised zince in several cases, their deficits rose back over 3% soon after the reference year, but big economies like Germany and France seem to defy the rules for years. Last but not least, changes in accounting method often seriously affected the deficit numbers (Spain and Portugal had, like Greece, marginally exceeded 3% in their reference year for entry, when their deficit was revised according to ESA95). It was argued that New Democracy government simply miscalculated the consequences of its actions, which brought a strong reaction by Eurostat, stronger than that for other violators.\n\nAs a result of the financial audit, Greece fell in the list of the loan creditability and paid more interest on its loans compared with other EU countries. EU Commission warned Greece about future problems if Greece, now with the new data, does not comply with the Eurozone requirements.\n\nNew Democracy's government accused PASOK, and Costas Simitis, the prime minister and president of PASOK at that time, of having falsified Greece's macroeconomic statistics, on the basis of which the European institutions accepted Greece to join the Eurozone. All the opposition parties accused New Democracy's government of making a false audit.\n\nPASOK said that it never falsified any data, and that New Democracy's government just changed the way costs (mostly military expenses) were accounted for through the years and some other accounting techniques, and the way PASOK used to do it was known to the Eurostat, which never opposed it.\n\nCostas Simitis wrote in the \"Financial Times\" that Greece's deficit revision damaged the EU: \"The Commission must design an auditing system that is the same for all EU countries and guarantees objectivity and impartiality, while ruling out domestic political interference\". Some days later, the same newspaper published a Letter to the Editor by the Director General of Eurostat acknowledged the need for monitoring and review of government accounts independent of political cycles, outlining the changes made but taking issue with the portrayal of the Greek account revisions.\n\nIn March 2006, Eurostat made changes to the system of defense expenditure calculation, which seemed to legitimize some of the practices of the previous Costas Simitis government of PASOK. This caused criticism of the Financial Audit of 2004 and the New Democracy government by PASOK and parts of the press. New Democracy responded that the defense expenditures covered by the 2006 changes constituted only a small part of much more substantial expenditures that were fraudulently concealed by the previous PASOK government.\n\n\nEuropean debt crisis:\n"}
{"id": "51973167", "url": "https://en.wikipedia.org/wiki?curid=51973167", "title": "High Council for Human Rights", "text": "High Council for Human Rights\n\nHigh Council for Human rights () is the governmental national human rights institution of Iran, subdivision to the Judiciary of Iran.\n\nThe council rejects and condemns appointment of Special Rapporteur on Human Rights in Iran by United Nations and strongly opposes the western countries' positions about current human rights situation in Iran. It also assumes the “true face” of human rights should be sought through Islam.\n\nThe council has challenged laws against Holocaust denial, spread of Islamophobia, forced unveiling in schools, specifically in France as being against human rights.\n\n"}
{"id": "6190717", "url": "https://en.wikipedia.org/wiki?curid=6190717", "title": "Hot pursuit", "text": "Hot pursuit\n\nHot pursuit (also known as fresh or immediate pursuit) refers to the urgent and direct pursuit of a criminal suspect by law enforcement officers, or by belligerents under international rules of engagement for military forces. Such a situation grants the officers in command powers they otherwise would not have.\n\nHot pursuit has long formed a part of English common law. The principle can be traced back to the doctrine of distress damage feasant, which allowed a property owner to detain animals trespassing on his land to ensure that he was compensated for the damage they had caused. In particular, a case in 1293 held that a property owner could also chase after trespassing animals leaving his land and catch them if he could. Later cases extended this idea to allow a property owner to distrain the goods of a tenant behind on his rent outside his property (in \"Kirkman v. Lelly\" in 1314) and peace officers to make arrests outside their jurisdiction.\n\nIn 1939, Glanville Williams described hot pursuit as a legal fiction that treated an arrest as made at the moment when the chase began rather than when it ended, since a criminal should not be able to benefit from an attempt to escape.\n\nBecause of its pedigree in English law, the principle has been exported to many former colonies of the British Empire, including the United States and Canada.\n\nUnder United States law, hot pursuit is an exigent circumstance that allows police to arrest a criminal suspect on private property without a warrant, which would generally be a violation of the Fourth Amendment prohibition on unreasonable searches, seizures, and arrests. The Supreme Court first articulated this principle in \"Warden v. Hayden\" in 1967.\n\nThe Supreme Court of Canada held in R. v. Macooh in 1993 that the right of a police officer in hot pursuit to make an arrest on private property, which it described as \"well settled at common law\", extended to summary offences as well as indictable offenses.\n\nThe international law principle of hot pursuit is analogous to the common law principle, but was probably conceived independently. It began to coalesce into a general custom of international relations during the early years of the 20th century, although the general principle had been advanced before in national legislation such as the British Hovering Acts. The participating states at the League of Nations Codification Conference of 1930 broadly agreed on the validity of the right of hot pursuit, but the proposed convention on territorial waters in which it was included was never ratified. It was finally codified as Article 23 of the Geneva Convention on the High Seas in 1958.\n\nThe Geneva Convention on the High Seas was eventually folded into the United Nations Convention on the Law of the Sea. Article 111 of the latter treaty grants a coastal state the right to pursue and arrest ships escaping to international waters, as long as:\n\n\nIf the foreign ship is within a contiguous zone, the Exclusive Economic Zone (EEZ), the Continental Shelf, the Safety Zones in the EEZ or the Continental Shelf, then the pursuit may only be undertaken if there has been a violation of the rules and regulations (customs, fiscal, immigration or sanitary laws and regulations of the coastal state) as applicable in the respective regimes (areas, zones).\n\nThe right of hot pursuit ceases as soon as the ship pursued enters the territorial sea of a foreign state.\n\nWhere a coastal state, stopping or arresting a foreign ship outside the territorial sea on the basis of its right of hot pursuit, fails to justify the exercise, it shall be liable to compensate the ship for any loss or damage caused to it due to the exercise of this right.\n\nThis right is particularly relevant to fisheries management, maritime pollution laws, and the seaborne illegal drug trade.\n\nIn addition, some have proposed translating the maritime right of hot pursuit into a comparable right to pursue criminals over land borders. Although it does not form a settled tenet of international law, the principle has been invoked by the United States regarding Taliban militants crossing into Pakistan, by Turkey regarding its attacks on Kurdistan Workers Party bases in northern Iraq, and by Colombia regarding its raid on a Revolutionary Armed Forces of Colombia camp in Ecuador, which led to the 2008 Andean diplomatic crisis.\n\nFor borders between the countries of the Schengen Area, hot pursuit over the borders is allowed. This is described by the Schengen Agreement, although exact details on distance from the border etc. are described by bilateral agreements.\n\n"}
{"id": "385158", "url": "https://en.wikipedia.org/wiki?curid=385158", "title": "Independent Democratic Serb Party", "text": "Independent Democratic Serb Party\n\nThe Independent Democratic Serb Party ( or SDSS, ) is a social democratic political party of Croatian Serbs.\n\nIt was formed in 1997 led by Vojislav Stanimirović. In the Croatian parliamentary election, 2003, it beat its main rival, the Serb People's Party (SNS), taking all three seats reserved for Serb representatives in the Croatian parliament.\n\nAfter the elections, the Independent Democratic Serb Party made an agreement with the winning Croatian Democratic Union led by Ivo Sanader in which they agreed on fulfilling several SDSS demands such as refugee return, strengthening of national equality, judicial reform and cooperation with neighbouring countries. In the Croatian parliamentary election, 2007, they retained their three seats in the Parliament. In the Cabinet of Ivo Sanader II, their member Slobodan Uzelac received the position of vice-president of government. In the Croatian parliamentary election, 2011, they again won their three seats in the Parliament on the Serbian minority electoral list.\n\nThe SDSS is a democratic party of liberal and social democratic orientation, but in the present circumstances, it is also a Serb national party.\n\nPolitical goals:\n\n\n"}
{"id": "21898897", "url": "https://en.wikipedia.org/wiki?curid=21898897", "title": "India Water Portal", "text": "India Water Portal\n\nIndia Water Portal is an open, inclusive website that shares knowledge and resources on water in India. It aims to draw on the rich experience of water experts, packaging their knowledge and then disseminating it to a larger audience through the Internet. India Water Portal's vision is to make water a more visible issue in India by sharing knowledge freely and openly, in order to influence understanding on water issues and to empower action.\n\nThe Portal has grown to cover a wide range of themes and issues related to water, such as sanitation, agriculture, the environment and climate change, to name a few. India Water Portal is a Digital Commons initiative of Arghyam, a grant making foundation set up by Rohini Nilekani to promote safe and sustainable water for all. Endorsed by the National Knowledge Commission, India Water Portal was finally launched in February 2007 by the then Prime Minister of India, Dr. Manmohan Singh.\n\nIndia Water Portal focuses on the issues surrounding water in India, and strives to share practical solutions to these problems. The topics broadly covered in the portal include rainwater harvesting, agriculture, drinking water, urban water management, sanitation, wastewater management and water quality.\n\nFor researchers working in the development sector, India Water Portal offers a wealth of information and data on water. The Portal has an analysis of 100 years worth of meteorological data in India. Users can download the data analyses based on the following parameters:\n\nThe portal also has comprehensive data on the river basins of India, and water policies and laws in India. There is a dedicated section on maps and statistics.\nIndia Water Portal publishes articles, daily news on water, photo essays and videos of stories related to water in India. It is also present on Facebook, Twitter, Flickr, YouTube and Slideshare.\n\nIn 2008, India Water Portal launched regional language portals in Kannada and Hindi. In 2009, a Schools Water Portal was launched specifically targeted at school children. The Schools Water Portal strives to compliment the academic curriculum with practical projects and fun filled ideas to spread awareness related to water. In 2014, a dedicated Sanitation Portal was launched.\n\n"}
{"id": "37598550", "url": "https://en.wikipedia.org/wiki?curid=37598550", "title": "Infrastructure-based development", "text": "Infrastructure-based development\n\nInfrastructure-based economic development, also called infrastructure-driven development, combines key policy characteristics inherited from the Rooseveltian progressivist tradition and Neo-Keynesian economics in the United States, France's Gaullist and Neo-Colbertist centralized economic planning, Scandinavian social democracy as well as Singaporean and Chinese state capitalism : it holds that a substantial proportion of a nation’s resources must be systematically directed towards long term assets such as transportation, energy and social infrastructure (schools, universities, hospitals…) in the name of long term economic efficiency (stimulating growth in economically lagging regions and fostering technological innovation) and social equity (providing free education and affordable healthcare). While the benefits of infrastructure-based development can be debated, the analysis of US economic history shows that at least under some scenarios infrastructure-based investment contributes to economic growth, both nationally and locally, and can be profitable, as measured by higher rates of return. The benefits of infrastructure investment are shown both for old-style economies (ports, highways, railroads) as well as for the new age (airports, telecommunications, internet...).\n\nAccording to a study by D.A. Aschauer, there is a positive and statistically significant correlation between investment in infrastructure and economic performance. Furthermore, the infrastructure investment not only increases the quality of life, but, based on the time series evidence for the post-World War II period in the United States, infrastructure also has positive impact on both labor and multifactor productivity. The multifactor productivity can be defined as the variable in the output function not directly caused by the inputs, private and public capital. Thus, the impact of infrastructure investment on multifactor productivity is important because the higher multifactor productivity implies higher economic output and hence higher growth.\n\nIn addition to Aschauer’s work, Munnell’s paper supports the point that infrastructure investment improves productivity. Munell demonstrates that the decrease in multifactor productivity growth during the 1970s and 1980s relative to the 1950s and 1960s is due to the decrease of public capital stock rather than the decline in technological progress. By showing that public capital plays an important role in private sector production, Munnell helps Aschauer establish that infrastructure investment was a key factor to “the robust performance of the economy in the ‘golden age’ of the 1950s and 1960s.”\n\nTo prove his point, Aschauer builds a model, using the data for the time period from 1953 to 1988, to simulate the effect of higher public investment on the aggregate economy. His simulation shows that, on net, the increased investment in core infrastructure might have greatly improved the performance of the economy.\n\nAschauer uses the production function formula_1, where:\n\nHe estimates the production function relation using the average data from 1965 to 1983 for the 50 states. This enables Aschauer to conclude that the level of per capita output is positively and significantly related to core infrastructure investments, in other words an increase in the core infrastructure investments leads to an increase in the level of per capita output.\n\nHowever, infrastructure has positive impact not just on the national level. By implementing the cross-sectional study of communities in one state, Janet Rives and Michael Heaney confirm “the links identified in national level studies between infrastructure and economic development” are also present locally. Because infrastructure enters the production function and increases the value of urban land by attracting more firms and house construction, the core infrastructure also has a positive effect on economic development locally.\n\nAccording to an overview of multiple studies by Louis Cain, the infrastructure investments have also been profitable. For example, Fogel estimated the private rate of return on the Union Pacific Railroad at 11.6%, whereas the social rate that accounts for social benefits, such as improved firm efficiencies and government subsidies, was estimated at 29.9%. In another study, Heckelman and Wallis estimated that the first 500 miles of railroad in a given state led to major increases in property values between 1850 and 1910. They calculated the revenue gain from the land appreciation to be $33,000-$200,000 per mile, while construction costs were $20,000-$40,000 per mile. Hence, on average the revenue from construction of a new railroad outweighed the costs. While initial construction returns were high, the profitability diminished after the first 500 miles.\n\nEven though the revenue streams on infrastructure construction investment fall due to diminishing returns, Edward Gramlich indicates that the rate of return on new construction projects was estimated at 15%. Furthermore, the rate of return on maintenance of current highways was estimated at 35%. It means that even without further new construction, the investment in the maintenance of the core infrastructure is very profitable.\n\nRoller and Waverman, utilizing data for 21 OECD countries, including US, over a 20-year period, from 1970 to 1990, examined the relationship between telecommunications infrastructure investments and economic performance. They used a supply-demand micro-model for telecommunications investments jointly with the macro production equation, accounting for country-specific fixed effects as well as simultaneity. They conclude that there is a causal relationship between telecommunications infrastructure investment and aggregate output.\n\nShane Greenstein and Pablo T. Spiller examined the effects of telecommunication infrastructure on economic performance in the United States. They conclude that infrastructure investment accounts for a significant fraction of the growth in consumer surplus and business revenue in telecommunications services, both of which indicate the growth in economic performance.\n\nSome European and Asian economists suggest that “infrastructure-savvy economies” such as Norway, Singapore and China have partially rejected the underlying Neoclassical “financial orthodoxy” that used to characterize the ‘Washington Consensus’ and initiated instead a pragmatist development path of their own based on sustained, large-scale, government-funded investments in strategic infrastructure projects: “Successful countries such as Singapore, Indonesia and South Korea still remember the harsh adjustment mechanisms imposed abruptly upon them by the IMF and World Bank during the 1997-1998 ‘Asian Crisis’ […] What they have achieved in the past 10 years is all the more remarkable: they have quietly abandoned the “Washington consensus” by investing massively in infrastructure projects […] this pragmatic approach proved to be very successful.”\n\nResearch conducted by the World Pensions Council (WPC) suggests that while China invested roughly 9% of its GDP in infrastructure in the 1990s and 2000s, most Western and non-Asian emerging economies invested only 2% to 4% of their GDP in infrastructure assets. This considerable investment gap allowed the Chinese economy to grow at near optimal conditions while many South American, South Asian and African economies suffered from various development bottlenecks: poor transportation networks, aging power grids, mediocre schools...\n\nThe Beijing-based Asian Infrastructure Investment Bank (AIIB) established in July 2015 and corollary One Belt, One Road Chinese-led initiative demonstrate the PRC government’s capacity to garner the financial and political resources needed to \"export\" their economic development model, notably by persuading neighboring Asian nations to join AIIB as founding members : “\"as Asia (excluding China) will need up to $900bn in infrastructure investments annually in the next 10 years (which means there’s a 50% shortfall in infra spending in the continent), many\" [Asian] \"heads of state\" […] \"gladly expressed their interest to join this new international financial institution focusing solely on ‘real assets’ and infrastructure-driven economic growth.\"”\n\nIn the West, the notion of pension fund investment in infrastructure has emerged primarily in Australia and Canada in the 1990s notably in Ontario and Quebec and has attracted the interest of policy makers in sophisticated jurisdictions such as California, New York, the Netherlands, Denmark and the UK.\n\nIn the wake of the Great Recession that started after 2007, liberal and Neo-Keynesian economists in the United States have developed renewed arguments in favor of “Rooseveltian” economic policies removed from the ‘Neoclassical’ orthodoxy of the past 30 years- notably a degree of federal stimulus spending across public infrastructures and social services that would “benefit the nation as a whole and put America back on the path to long term growth”.\n\nSimilar ideas have gained traction amongst IMF, World Bank and European Commission policy makers in recent years notably in the last months of 2014/early 2015: Annual Meetings of the International Monetary Fund and the World Bank Group (October 2014) and adoption of the €315 bn European Commission Investment Plan for Europe (December 2014).\n\nThe Nurly Zhol plan or 'New Economic Policy', announced on 11 November 2014 during Kazakhstan President’s State of the Nation Address, introduced a number of measures aimed at developing country's infrastructure in order to sustain economic growth. The Nurly Zhol program applies to such sectors of infrastructure as transport and logistic, tourism, housing and communal services, education, support of export, agriculture, etc.\n\n \nFixing \"America’s crumbling infrastructure\" is a \"pillar\" of President Donald Trump's \"Make America Great Again\" plan.\n\nTrump is depending on private investors to drive his infrastructure plan. On June 20, 2017, at the SelectUSA Investment Summit in Washington, Treasury Secretary Steven Mnuchin said that financial help from foreign investors will probably be necessary in order for President Trump's $1 trillion infrastructure plan to \"upgrade U.S. roads, bridges, airports and other public works\", to succeed.\n\nTrump's successful presidential bid was to a large extent based on an ‘unorthodox’ economic plank bringing together supply-side policies and infrastructure-based development planning: “the deliberate neglect of America’s creaking infrastructure assets (notably public transportation and water sanitation) from the early 1980s on eventually fueled a widespread popular discontent that came back to haunt both Hillary Clinton and the Republican establishment. Donald Trump was quick to seize on the issue to make a broader slap against the laissez-faire complacency of the federal government: ‘when I see the crumbling roads and bridges, or the dilapidated airports or the factories moving overseas to Mexico, or to other countries for that matter, I know these problems can all be fixed’ (June 22, 2016 New York Speech: ‘We Will Build the Greatest Infrastructure on the Planet Earth’).”\n\nThis unconventional (by American standards) policy mix favoring renewed federal government involvement in infrastructure investment and co-investment across the board (at national, state, municipal and local level) is known as Trumponomics.\n\nDonald Trump's policies aim at harnessing private capital to leverage government spending on infrastructure at federal, state and local level. This approach relies on the notion of “infrastructure as an asset class” for institutional investors, which was initially developed in Northern Europe, Canada and Australia\n\nOn May 20, 2017, during President Donald Trump's official state visit to Saudi Arabia, he signed a $110 billion arms deal with Saudi Arabia; Saudi Arabia and the United Arab Emirates announced they would \"donate a combined $100 million to a World Bank fund for women entrepreneurs\", a project inspired by Ivanka Trump; and Saudi Arabia \"joined forces\" with The Blackstone Group, a global private equity firm to \"build a $40 billion war chest to privatize U.S. infrastructure\". Blackstone's CEO is Stephen Schwarzman, leads Trump's business council, \"advising him on \"policy issues ranging from trade to infrastructure\", unveiled a $40 billion fund which will primarily invest in infrastructure in the United States. Blackstone, which has \"$360 billion in assets\" is entering into infrastructure projects in which \"large investors\" plant \"their money into the cogs of the global economy such as toll roads, airports, public works, buildings, ports, wireless infrastructure, pipelines, and railroads\". Saudi Arabia will provide $20 billion from its Private Investment Fund (PIF) towards the Blackstone infrastructure fund. Limited partners will contribute $20 billion. \"With debt financing, Blackstone hopes eventually to bring the total to $100 billion\" in \"total infrastructure investments on a leveraged basis\".\n\nAccording to \"The Guardian\", Trump's dependence on private investments for infrastructure funding, is \"speculative infrastructure\", a form of \"speculative finance\", similar to that which \"led to the financial crisis\". \"What is needed is a vision for the economy that lines up financial market reform with innovation policy, and infrastructure plans.\" At the same time that Trump is privatizing infrastructure, he has plans to cut for deep cuts to the budgets of \"Darpa, a public agency inside the Department of Defense\", the \"engine behind the internet\", and Arpa-E, a \"source of innovation inside the Department of Energy\". These agencies could \"help steer progress in clean energy\" but they may not survive the deep budgetary cuts.\n"}
{"id": "18838179", "url": "https://en.wikipedia.org/wiki?curid=18838179", "title": "Job guarantee", "text": "Job guarantee\n\nA job guarantee (JG) is an economic policy proposal aimed at providing a sustainable solution to the dual problems of inflation and unemployment. Its aim is to create full employment and price stability, by having the state promise to hire unemployed workers as an employer of last resort (ELR).\n\nThe economic policy stance currently dominant around the world uses unemployment as a policy tool to control inflation; when cost pressures rise, the standard monetary policy carried out by the monetary authority (central bank) tightens interest rates, creating a buffer stock of unemployed people, which reduces wage demands, and ultimately inflation. When inflationary expectations subside, these people will get their jobs back. In Marxian terms, the unemployed serve as a reserve army of labor. By contrast, in a job guarantee program, a buffer stock of \"employed\" people (employed in the job guarantee program) provides the same protection against inflation \"without\" the social costs of unemployment, hence potentially fulfilling the dual mandate of full employment and price stability.\n\nThe job guarantee proposal is particularly associated with certain post-Keynesian economists, particularly at the Centre of Full Employment and Equity (University of Newcastle, Australia), at the Levy Economics Institute (Bard College) and at University of Missouri – Kansas City including the affiliated Center for Full Employment and Price Stability.\n\nJG draws from a social justice tradition of right to work, such as the United Nations Universal Declaration of Human Rights and the US Employment Act of 1946, and an early form was proposed by Hyman Minsky.\n\nThe JG proposal was conceived independently by Bill Mitchell (1998) and Warren Mosler (1997–98). It has since been developed further by authors, including L. Randall Wray (1998) and a comprehensive treatment of it appears in Mitchell and Muysken (2008).\n\nThe JG is based on a buffer stock principle whereby the public sector offers a fixed wage job to anyone willing and able to work thereby establishing and maintaining a buffer stock of employed workers. This buffer stock expands when private sector activity declines, and declines when private sector activity expands, much like today's unemployed buffer stocks.\n\nThe JG thus fulfills an absorption function to minimize the real costs associated with the flux of the private sector. When private sector employment declines, public sector employment will automatically react and increase its payrolls. So in a recession, the increase in public employment will increase net government spending, and stimulate aggregate demand and the economy. Conversely, in a boom, the decline of public sector employment and spending caused by workers leaving their JG jobs for higher paid private sector employment will lessen stimulation, so the JG functions as an automatic stabilizer controlling inflation. The nation always remains fully employed, with a changing mix between private and public sector employment. Since the JG wage is open to everyone, it will functionally become the national minimum wage.\n\nUnder the JG, people of working age who are not in full-time education and have less than 35 hours per week of paid employment would be entitled to the balance of 35 hours paid employment, undertaking work of public benefit at the minimum wage. The aim is to replace unemployment and underemployment with paid employment (up to the hours desired by workers), so that those who are at any point in time surplus to the requirements of the private sector (and mainstream public sector) can earn a reasonable living rather than suffer the indignity and insecurity of underemployment, poverty, and social exclusion.\n\nA range of income support arrangements, including a generic work-tested benefit payment, would also be available to unemployed people, depending on their circumstances, as an initial subsistence income while arrangements are made to employ them. This would rarely be necessary once the system was well established, because in most circumstances JG jobs would be immediately available and offered instead of income support.\n\nThe fixed JG wage provides an in-built inflation control mechanism. Mitchell (1998) called the ratio of JG employment to total employment the \"buffer employment ratio\" (BER). The BER conditions the overall rate of wage demands. When the BER is high, real wage demands will be correspondingly lower. If inflation exceeds the government’s announced target, tighter fiscal and monetary policy would be triggered to increase the BER, which entails workers transferring from the inflating sector to the fixed price JG sector. Ultimately this attenuates the inflation spiral. So instead of a buffer stock of unemployed being used to discipline the distributional struggle, the JG policy achieves this via compositional shifts in employment. Replacing the current \"non-accelerating inflation rate of unemployment\" (NAIRU), the BER that results in stable inflation is called the \"non-accelerating inflation buffer employment ratio\" (NAIBER) (Mitchell 1998). It is a full employment steady state JG level, which is dependent on a range of factors including the path of the economy. There is an issue about the validity of an unchanging nominal anchor in an inflationary environment. The JG wage would be adjusted in line with productivity growth to avoid changing real relativities. Its viability as a nominal anchor relies on the fiscal authorities reining in any private wage-price pressures.\n\nThe JG introduces no relative wage effects and the rising demand \"per se\" does not necessarily invoke inflationary pressures because by definition it is satisfying the net savings desire of the private sector (see Mitchell and Muysken, 2008 for more details). Additionally, in today’s demand constrained economies, firms are likely to increase capacity utilisation to meet the higher sales volumes. Given that the demand impulse is less than required in the NAIRU (Non-Accelerating Inflation Rate of Unemployment) economy, it is clear that if there were any demand-pull inflation it would be lower under the JG. There are no new problems faced by employers who wish to hire labour to meet the higher sales levels. Any initial rise in demand will stimulate private sector employment growth while reducing JG employment and spending. However, these demand pressures are unlikely to lead to accelerating inflation while the JG pool contains workers employable by the private sector.\n\nWhile the JG policy frees wage bargaining from the general threat of unemployment, several factors offset this:\n\nA crucial point is that the JG does not rely on the government spending at market prices and then exploiting multipliers to achieve full employment which characterizes traditional Keynesian aggregate demand management. The JG program differs in that it \"would be targeted directly to households. It is a genuine bottom-up approach to economic recovery. It is a program that stabilizes the incomes and purchasing power of individuals at the bottom of the income distribution that trickles up and stabilizes the rest of economic activity. Strong and stable demand means strong and stable profit expectations. A program that stabilizes employment and purchasing power is a program that stabilizes cash flows and earnings. Stable incomes through employment also mean stable repayments of debts and greater overall balance sheet stability\".\nThe JG seeks to reorient labour market policy away from the current OECD emphasis on full employability whereby governments engage in programs to prepare the unemployed for work without guaranteeing that work will be available towards a focus on creating enough work. The full employability agenda has come under fire from a number of sources in recent years (see, for example ILO, 2004).\n\nWorkfare is a scheme where participation in activities is a requirement for obtaining social benefits. Workfare schemes may not cover all of the unemployed, and may not offer the same income as a full-time minimum wage job.\n\nThere are now several countries which have implemented direct job creation schemes to counter the major problems associated with persistent unemployment. For example, the Argentine government introduced the \"Jefes de Hogar\" (Heads of Households) program in 2001 to combat the social malaise that followed the financial crisis in that year.\n\nSimilarly, the Indian Government introduced in 2005 a five-year plan called the National Rural Employment Guarantee Act (NREGA) to bridge the vast rural-urban income disparities that have emerged as India’s information technology and service sector has boomed. The program has successfully empowered women and raised rural wages, but has also attracted the ire of landowners who have to pay farm laborers more due to a higher prevailing wage. The projects tend to be highly labor-intensive and low skill, like dam and road construction, and soil conservation, with modest but positive long-term benefits and mediocre management.\n\nThe South African government has introduced the Expanded Public Works Program (EPWP) to overcome the extremely high unemployment and accompanying poverty in that country. EPWP projects employ workers on a temporary or ongoing basis with government, contractors, or other non-governmental organisations under the Ministerial Conditions of Employment for the EPWP or learnership employment conditions.\n\nIn the United States, the Humphrey-Hawkins Full Employment Act of 1978 allows the government to create a \"reservoir of public employment\" in case private enterprise does not provide sufficient jobs. These jobs are required to be in the lower ranges of skill and pay so as to not draw the workforce away from the private sector. However, the act did not establish such a reservoir (it only \"authorized\" it), and no such program has been implemented in the United States, even though the unemployment rate has generally been above the rate (3%) targeted by the act.\n\nIn the third season of the American political drama \"House of Cards\", a job guarantee program, called \"America Works,\" is a key policy proposal of protagonist Frank Underwood (portrayed by Kevin Spacey) after he becomes President of the United States. Details of the program are sparse, but it is portrayed as involving both public sector employment (in the form of public works programs) and private sector employment (with subsidies for employers who take on new workers), and is intended to be financed with cuts to Social Security and Medicare. America Works is not fully implemented, but a pilot program centered in Washington, D.C. is portrayed as having employed tens of thousands of people before funds are rescinded.\n\nIn 2011, the Institute for Public Policy Research, a UK think tank associated with the Labour Party, advocated a job creation program - with compulsory takeup, on pain of loss of benefits - for the long-term unemployed only. The Labour Party under Ed Miliband subsequently went into the 2015 general election with a promise to implement an even more limited Job Guarantee (specifically, part time jobs with guaranteed training included for long-term unemployed youth) if elected; however, they lost the election. This is still Labour Party policy - however, they are looking at universal basic income as a possible alternative policy.\n\n\n"}
{"id": "53434112", "url": "https://en.wikipedia.org/wiki?curid=53434112", "title": "Klausism", "text": "Klausism\n\nIn Czech politics, Klausism refers to the political positions of Václav Klaus, former prime minister and president of the Czech Republic. It was first used by Mirek Topolánek, who designated Klausism as the ideology of the Civic Democratic Party (ODS). This term was also used by former Prague mayor Jan Kasl. Klaus himself does not take issue with the term. The current usage of the term \"Klausism\" has become distanced from Klaus himself, leading to the phrase \"Klausism without Klaus.\" Though Klausism primarily refers to the political ideology, it is also frequently used as a label for the neologisms invented by Klaus.\n\nKlaus himself used the term \"Mental Scheme of ODS\", which he allegedly invented by chance. This term was also used by Jan Kasl.\n\nKlaus is known for his Euroscepticism, global warming denial, opposition to homosexuality and immigration, and support of free market capitalism. Klaus's stances are often described as liberal conservative combined with national liberalism and Czech nationalism. Jan Pauer described Klaus's political ideology as a combination of \"Friedmanite monetarism, Thatcherite economic libertarianism, Czech national conservatism and leadership pragmatism.\" Klaus described himself as liberal, conservative, and pragmatic.\n\nBohumil Doležal believes that Klausism is about \"fighting against isms,\" including environmentalism, pro-Europeanism, NGOism or \"homosexualism\" (a phrase itself coined by Klaus). It is opposition to perceived trends in Western politics. Klausism is, according to Doležal, a fight for \"realistic policies that solve problems and do not serve dogmatic ideologies\". Doležal stated that Klausism itself became one of these Isms.\n\nIn 2011, \"Ekonom\" Magazine likened Klausism to Gaullism, asserting that the two were very similar. Both ideologies support the strong position of the president, but in the case of Klaus it is informal and balancing at the edge of the Czech constitution.\n\nKlausism without Klaus was a term coined by Mirek Topolánek following conflicts between Václav Klaus and ODS. Bohumil Doležal likened it to \"Socialism with a human face\". It is often characterised as support for Klaus's ideas but not Klaus himself. Topolánek wanted to retain the positive elements of Klaus' legacy and leave out the negatives. Klausism without Klaus was represented by Petr Nečas, Miroslava Němcová and Tomáš Chalupa. Klausism without Klaus supports economic liberalism, political responsibility, a small state, opposition to other ideologies and the rule of common sense.\n\nThe term \"Mental scheme of ODS\" was formulated into the Poděbrady Articles in 1998, proclaiming the four principles that ODS supports, including protection of privacy, a small state, a future without debts, and solidarity of responsibilities.\n\n\nThe term Klausism is also used for neologisms coined by Václav Klaus. Klaus is noted for his use of language and often invents new words to describe things he opposes. For example, Klaus invented the word \"Havlism\", which subsequently entered wider use. Klaus also expressed opposition to \"homosexualism\". Other widely used Klausisms are \"Opposition Agreement\" or \"Sarajevo atentate\".\n\nKlausism has many critics. Jiří Pehe called Klausism deviant, and its own worst enemy, noting Klausism's opposition to modern isms, a category to which Pehe believes it belongs. Pehe believes that Klausism is not what Klaus says but what he did when he was in power. He considers Klaus to be very politically flexible and ignorant of other opinions. Pehe suggested that Klausism would be doom for ODS.\n\nThe leader of the Czech Green Party Ondřej Liška described Klausism as dangerous for democracy. He called Klausism an \"ideology of arbitrariness that threatens democracy\", comparing it to communism due to its, in his opinion, lack of principles.\n"}
{"id": "27600642", "url": "https://en.wikipedia.org/wiki?curid=27600642", "title": "Latma", "text": "Latma\n\nLatma (, translation from Arabic \"slap in the face\") is a right-wing Israeli media criticism website that also produces a weekly satirical news show.\n\nThe website was created in 2008 by a group of journalists claiming that \"the only way to improve the Public discourse is exposing the true face of the news and journalism in whole\". According to the site, the majority of the Israeli media, and especially the satire that is presented in them, lean to the political left. The site contains criticism about media outlets, reporters and journalists. The criticism is mostly directed towards politically biased articles. The site's editor, Caroline Glick, told the \"Jerusalem Post\" that the group was founded with the intention of using comedy to critique the \"egregious leftist slant of news coverage in this country.\"\n\nAccording to \"The New York Times\", Latma \"is an initiative of the Center for Security Policy, a Washington think tank.\" The Latma website editor, Caroline Glick, serves as Adjunct Senior Fellow for Middle Eastern Affairs at the Center for Security Policy.\n\nThe site's editor is Caroline Glick. The regular writers are Shuky Blass and Avishai Ivri. The site's CEO is Shlomo Blass.\n\nLatmaTV is staffed by Tal Gil'ad (screenplay), Avishay Ivri, the editor, directors Aviv and Yoni Karsutzki, writers Noam Jacobson and Yehuda Safra, and the actors. Guest writers include Shlomi Cohen Tzemah (\"Catz\") and Itay Elitzur.\n\nOne of Latma's creations is \"The Tribal Update\", a mock news show, featuring anchors Ronit Shapira (née Avrahamof) and Elchanan Even-Chen. CBS News characterizes the program as \"a parody TV show — kind of like \"Saturday Night Live\"'s Weekend Update.\" According to CBS, the anchor gravely explains, in Hebrew, that \"this is the newscast that reaches conclusions long before the facts are known.\"\n\nFollowing the 2009 Aftonbladet-Israel controversy, in which a writer for Swedish tabloid Aftonbladet alleged that the IDF harvested organs of Palestinians, LatmaTV produced a clip a parody on ABBA's song \"Gimme, Gimme, Gimme a Man After Midnight\" entitled \"Primi Primi Primitive and Phlegmatic\" in which the Swedish foreign minister sings about how primitive and cowardly he is. The clip became a hit after it was quickly picked up by the leading newspaper in Sweden, DN.se, and by Swedish and Norwegian bloggers. Latma website director Shlomo Blass said, \"We were surprised by how quickly the clip took-off, we must have hit a sensitive nerve\".\n\nIn 2010 Latma produced a viral video entitled \"We Con the World\" satirizing the political intentions of activists aboard the MV Mavi Marmara, the Turkish-owned flagship that led the \"blockade busting\" Free Gaza flotilla. The video is a parody of the 1985 song \"We Are the World,\" by Michael Jackson and Lionel Richie. Israeli Government Press Office officials accidentally sent it to a list of journalists, and three hours later sent an apology describing the emailed video as having been \"inadvertently released.\" The clip received over 3 million hits on YouTube.\n\nIn July 2011, while the second flotilla to Gaza was planned, Latma released another parody about the flotilla: a parody of Beach Boys' song and video \"Fun, Fun, Fun\" called \"Guns, Guns, Guns\", where the flotilla sailors sing about their purpose: to bring weapons to Gaza. This video had less success than \"We Con the World\".\n\n\"The Three Terrors\" was produced in June 2010 as a sequel to \"We Con the World.\" It features three tenors who represent Iran, Turkey and Syria and who resemble Mahmoud Ahmadinejad, Recep Tayyip Erdoğan and Bashar Assad singing joyfully about using terrorism to conquer the world \"from Tennessee to Teheran.\"\n\nIn August 2010, Latma release a parody of Tom Jones's song and video \"Sex Bomb\" called \"The Iranian Bomb\", where a fictional Iranian Minister of Destruction sings about his plans to acquire nuclear weapons. The goal of the video is to bring worldwide attention to the Iranian nuclear program.\n\nIn 2015, the show began to air on Channel 1 under the name \"Hakol Shafit\".\n\n\n"}
{"id": "21681162", "url": "https://en.wikipedia.org/wiki?curid=21681162", "title": "Libertas.eu", "text": "Libertas.eu\n\nLibertas was a pan-European political party founded by Declan Ganley that took part in the European Parliament election, 2009 in several member states of the European Union. It won one seat in France.\n\nIn 2008, the Libertas Institute Limited, a lobby group founded by Declan Ganley and others, advocated a \"no\" vote in Lisbon I, the 2008 referendum in Ireland on the Treaty of Lisbon. Lisbon I failed. The referendum was held on 12 June 2008\nand defeated by 53.4% to 46.6%, with a turnout of 53.1%.\n\nLibertas held a post-referendum celebration in the Burlington Hotel in Dublin on the night of Friday, 13 June 2008. Attending that celebration was Danish Eurosceptic and former President of the EUDemocrats and recently retired MEP Jens-Peter Bonde, who had been a \"no\" campaigner during the referendum. Bonde was later cited as one of the main architects of the upgrading of Libertas to a political party at European level.\n\nOn 15 July 2008, RTÉ News on Two covered Ganley's comments at The Heritage Foundation in Washington, D.C., where he stated that Libertas intended running as a political party at European level. The next day Ganley confirmed that Libertas was fundraising in order to run candidates throughout Europe in the 2009 European Parliament elections.\n\nOn 20 September 2008, the Irish Times reported that Bonde and Czech president Václav Klaus pledged to help Ganley to launch Libertas. The two were later amongst the guests at a dinner hosted by Ganley at the Shelbourne Hotel in Dublin on 11 November 2008.\n\nOn 30 October 2008, Ganley registered a company based in Moyne Park, Tuam, County Galway called the \"Libertas Party Limited\". The Irish Times reported that the new party was intended to \"carry on the business of a European political party\". The party was publicly announced in December 2008 with ambitions to field up to 400 candidates and win seats in all 27 EU member states.\n\nIn early 2009 Libertas applied to be recognised by the European Parliament as a political party at European level. The application was briefly successful but then suspended indefinitely amidst controversy.\n\nGanley then travelled around Europe to set up Libertas lists and parties for the European Parliament election, 2009. In November 2008 Libertas opened its Brussels office. Libertas launched in France on 12 February 2009, the Netherlands on 15 April, followed by several other European Union member states. On 1 May 2009, Libertas held its first pan-European party convention in Rome in time for the European Parliament elections in June, when it fielded hundreds of candidates for election.\n\nIn Austria, \"Libertas\" was rejected by both Freedom Party of Austria (FPÖ) and Alliance for the Future of Austria (BZÖ) as well as by the independent Hans-Peter Martin. Martin announced after talks and serious considerations, that he would rather remain independent, which he successfully did. FPÖ harshly rebuffed Ganley's advances associating his activism with an alleged American conspiracy. The initially noncommital BZÖ later also declined, preferring a loose cooperation in the European Parliament.\n\nAn electoral list called \"Libertas: Free Citizens\" () was formed by some 30 national and local Non-governmental organization. Pavel Chernev's Freedom Party that had announced to join the list was repudiated by Libertas.\nHowever, the submitted list was later rejected by the Bulgarian electoral commission. An appeal filed by Nikolay Bliznakov was turned down by Bulgaria's Supreme Administrative Court on the grounds that the list had not proven the required deposit had not given the names of its constituent parties.\nIn the meantime, Bulgarian businessman Hristo Atanassov founded a party under the name Libertas Bulgaria which has no connection to the pan-European Libertas network.\n\nRight after the preliminary rejection of the Lisbon Treaty in Ireland, Declan Ganley, founder of the European \"Libertas.eu\", was guest of Czech President Václav Klaus The Czech eStat.cz civic group had ambitions to replicate Libertas's success and awarded the Irish electorate the Michal Tošovský Prize, picked up by Ganley in Prague on 5 November 2008. During his stay in Ireland after a state visit, Klaus visited Ganley in a private capacity and later attended the Shelbourne Hotel dinner given by Ganley for leading Eurosceptics.\n\nHowever, Ganley's Libertas was later rejected by the new Czech Eurosceptic party, Petr Mach's Party of Free Citizens, which was endorsed by Klaus. Additionally, the Ganley-disavowed new Czech Eurosceptic party by Vladimír Železný usurped the Libertas brand by registering itself as \"Libertas.cz\". Ganley's Libertas later claimed Železný's Libertas as an affiliate.\n\nAfter Manolis Kalligiannis (), President of the Greek Liberal Party had attended Libertas.eu's Rome convention on 1 May 2009. Manolis Kalligiannis (Μανώλης Καλλιγιάννης, sometimes rendered in English as Emmanuel Kalligiannis), Liberal Party run for the 2009 European parliament election under a Libertas-affiliated list with the name “Κόμμα Φιλελευθέρων – Libertas.eu”.\n\nIn Hungary, Libertas.eu searched for candidates in an Internet ad and Károly Lóránt was appointed the Hungarian representative. However, as Hungarian concerns that a disorganized EU would only serve Russian strategic interests could not be dissipated, no list was fielded on behalf of Libertas.\n\nLibertas.eu announced talks with the Pole of Autonomy coalition on 30 April 2009, the day before its Rome convention, which were confirmed the next day by Teodoro Buontempo, the president of The Right. However, in the final candidate lists submitted in May, no candidates were fielded by Libertas.eu, neither did the Pole of Autonomy list refer to Libertas.\n\nGanley arrived in Vilnius on Tuesday 3 March 2009 to discuss terms with prospective candidates, and explore whether to establish a new Libertas party in Lithuania or change the name of an existing Lithuanian party. He did so again on Monday 24 March 2009 at a lecture at Vilnius University's Institute of International Relations and Political Science (IIRPS, or VU Tarptautinių Santykių ir Politikos Mokslų Institutas, VU TSPMI).\n\nOn 31 March 2008, Libertas Lithuania gave a press conference. Attendees at the press conference were Ganley, lawyer , political analyst and Lithuanian presidential advisor , and Tautos Prisikėlimo Partija representative .\n\nIn that press conference it was announced that the Libertas Lithuanian list would be headed by Sutkiene and would include Bielinis, and that candidates from the Tautos Prisikėlimo Partija would stand with them under a common list, although Ganley and Stoma disagreed whether other parties would join them under that list. When asked if he had read the Lisbon Treaty, Bielinis demurred. When asked about Libertas Lithuania's funding, Ganley demurred.\n\nBielinis planned to remain in his presidential advisory post until 7 May 2009 and take unpaid leave thereafter. Lithuanian President Valdas Adamkus disagreed and announced Bielinis' resignation the next day, 1 April 2009.\n\nWhen the lists were published, neither Bielinis nor Sutkiene were on Tautos Prisikėlimo Partija's list. When Libertas named their finalised candidates in May 2009, they did not include any candidates in Lithuania, and the Tautos Prisikėlimo Partija website contained no pledge of allegiance to Libertas.\n\nIn April 2009, the Portuguese ecologist Earth Party (MPT) announced in a joint press conference with Ganley that it would run for the 2009 European Parliament election with an open electoral list under the banner of \"Libertas.eu\".\n\nWhile the vice-president of the EUDemocrats, Peter Kopecký had already announced the foundation of a \"Libertas Slovensko\" branch, he changed his mind in late February and decided to head the list of the small, but already established Agrarian and Countryside Party.\nGanley had to look out to other options and met in Bratislava with leaders of the conservative parties KDS and OKS, and with Richard Sulík, the founder of the new (Sloboda a Solidarita).\nWhile Sulík, whom Ganley had already contacted before, still didn't show much interest, Vladimír Palko (KDS) agreed to bring in their joint list with OKS into the European network.\nHowever, as the two partys didn't want to give up their distinct identities, they used \"Libertas\" only as supplementary brand.\n\nLibertas fielded over 600 candidates (including substitutes), but only one was elected: Phillippe de Villiers. Although Ganley himself polled a respectable number of votes, it was not enough for him to take a seat in his constituency. Ganley requested a recount of his personal vote but still lost. Having made the promise to do so before the election, Ganley retired from politics following his defeat on 8 June 2009: the fate of the party he founded, chaired, owned and governed was left to others. However, the affiliated Libertas Institute did emerge again in the Republic of Ireland when the Irish government launched its re-run of the Lisbon Treaty, despite its defeat the previous year. The Libertas party, along with the other minority political groupings, such as the Socialist Party and Sinn Féin, which opposed the European Constitutional Amending Bill, were outspent and outperformed by the political proponents of the bill who won by a substantial majority. Declan Ganley went on to praise the Irish Prime Minister, or Taoiseach, on 'what was, politically, a masterful campaign…from a masterful politician who has made glove puppets out of the opposition' although Ganley also cited recent economic turmoil in the country as a major deciding factor in the vote.\n\nLibertas's intended structure evolved with time. It was originally intended to be an alliance of national parties, but it was later envisaged as a single pan-European party with candidates running as individual members of Libertas. By the end of April 2009, Libertas's structure had settled into a loose association of national \"member parties\" (either new or pre-existing), with each member party adhering to a set of core principles (see below) but retaining its independence and adding on additional policies as it felt appropriate.\n\nFor the purposes of contending the 2009 European Parliament elections, Libertas candidates ran under \"lists\" (the lists of candidates presented to voters in a European election) branded with the Libertas identity, as exemplified by the French approach. Each list was made up of some combination of the following:\n\n\nNew national member parties established by Libertas had names in the \"Libertas X\" format, e.g. \"Libertas Sweden\" (except in the UK). Pre-existing national member parties were asked to change their names to include the word \"Libertas\" in the title. Members of member parties were members of Libertas automatically unless they chose otherwise.\n\nAffiliate parties retained their original names. Members of affiliate parties were not members of Libertas unless they chose to join as individuals.\n\nGanley stated that following a group conference in Rome in March 2009, (later postponed to 1 May 2009) Libertas would publish a policy document or party manifesto. covering areas such as democracy, the economy, small businesses, the recession, and EU institution accountability.\n\nNo formal manifesto was published at the convention. Instead, Libertas's core principles were displayed on its website and reiterated at its convention, namely accountability, transparency, democracy and rejection of the Lisbon Treaty. Each member party and individual member was obliged to adhere to these core principles, although they could add additional policies as they felt appropriate. Affiliate parties were not obliged to so adhere.\n\nThe core principles were given concrete form when Libertas published the following policies on its website:\n\n\nMember parties were members of Libertas.eu. Members of member parties were automatically members of Libertas.eu unless they chose otherwise.\n\nAffiliate parties were not members of Libertas.eu but cooperated with it electorally under Libertas lists. Members of affiliate parties were not members of Libertas.eu unless they chose to join as individuals.\n\nIndividual members were people who chose to join Libertas.eu as individuals. People with no national party membership who were running under a Libertas list were automatically individual members.\n\n\"Libertas\" didn't manage to present electoral lists in Austria, Belgium, Bulgaria, Cyprus, Denmark, Finland, Hungary, Italy, Luxembourg, Lithuania, Romania and Sweden. In the other European countries, the candidates on \"Libertas.eu\"'s lists were either members of member parties, members of affiliate parties, or individual members.\n\nLibertas was registered at Moyne Park, Tuam, County Galway along with other organisations associated with Libertas and/or Declan Ganley. A list of organizations associated with Libertas.eu and/or Declan Ganley is given here.\n\n\n"}
{"id": "7128959", "url": "https://en.wikipedia.org/wiki?curid=7128959", "title": "Managerialism", "text": "Managerialism\n\nManagerialism, on one level, involves belief in the value of professional managers and of the concepts and methods they use. Contemporary writers on management such as Thomas Diefenbach associate managerialism with hierarchy. But scholars have also linked managerialism to control,\nto accountability\nand measurement, and to an ideologically determined belief in the importance of tightly-managed organizations,\nas opposed to individuals or to groups that do not resemble an organization.\n\nFollowing Enteman's 1993 classic on \"Managerialism: The Emergence of a New Ideology\",\nAmerican management experts Robert Locke and J C Spender see managerialism as an expression of a special group – management – that entrenches itself ruthlessly and systemically in an organization. It deprives owners of decision-making power and workers of their ability to resist managerialism. In fact the rise of managerialism may in itself be a response to people's resistance in society and more specifically to workers' opposition against managerial regimes.\n\nBuilding on Enteman (1993) and Locke/Spender (2011), Thomas Klikauer in “Managerialism – Critique of an Ideology” (2013) defined managerialism thus: \"[...] Managerialism combines management knowledge and ideology to establish itself systemically in organisations and society while depriving owners, employees (organisational-economical) and civil society (social-political) of all decision-making powers. Managerialism justifies the application of managerial techniques to all areas of society on the grounds of superior ideology, expert training, and the exclusive possession of managerial knowledge necessary to efficiently run corporations and societies.\" As the simple management of Henri Fayol (1841-1925) and Frederick Winslow Taylor (1856-1915) mutated into managerialism, managerialism became a full-fledged ideology under the following formula:Management + Ideology + Expansion = Managerialism Two examples of the extension of management into the non-management domain – the not for profit sphere of human existence – are public schools and universities. In both cases, managerialism occurs when public institutions are run “as if” these were for-profit organization even though they remain government institutions funded through state taxes. In these cases, the term new public management has been used. But the ideology of managerialism can even extend into more distant institutions such as, for example, a College of Physicians.\n----Albert A. Anderson summarized managerialism as the ideological principle that sees societies as equivalent to the sum of the decisions and transactions made by the managements of organizations.\nCompare what the historian James Hoopes wrote (2003):\n\"[...] the main genesis of managerialism lay in the human relations movement that took root at the Harvard Business School in the 1920s and 1930s under the guiding hand of Professor Elton Mayo. Mayo, an immigrant from Australia, saw democracy as divisive and lacking in community spirit. He looked to corporate managers to restore the social harmony that he believed the uprooting experiences of immigration and industrialization had destroyed and that democracy was incapable of repairing.\"\nThe managerialist society is not one which responds to the needs, desires, and wishes of a majority of its citizens, but one which is influenced by organizations. The managerialist society responds to the managements of various organizations in relation to their transactions with each other. The needs, desires and wishes of the individual are heard through their membership of an organization. Furthermore, managerialism is both a process and a substantive ideology. Managerialism says that the fundamental social units are not individuals, as capitalism would declare, but rather that the fundamental social units are organizations. Ultimately, managerialism specifically denies that the fundamental nature of society is an aggregation of individuals.\n\nInstead, managerialism sees the core building-block of contemporary society as the modern business company or corporation. To further business, companies, and corporations is the ideological goal of managerialism. How managerialism functions as such an ideology has been perfectly expressed by one of managerialism's main ideological flagships – the \"Harvard Business Review\" - when the \"HBR\"'s former editor Joan Magretta (2012: 80-81) made the following stunning revelation:[i] Business executives are society's leading champions of free markets and competition, words that, for them, evoke a world view and value system that rewards good ideas and hard work, and that fosters innovation and meritocracy. Truth be told, the competition every manager longs for is a lot closer to Microsoft's end of the spectrum than it is to the dairy farmers'. All the talk about the virtues of competition notwithstanding, the aim of business strategy is to move an enterprise away from perfect competition and in the direction of monopoly.\n----[i] Magretta, J. 2012. \"What Management Is: How it works and why it's everyone's business\", London: Profile.\n\nManagerialism in political science is a set of beliefs, attitudes and values which support the view that management is the most essential and desirable element of good administration and government. It follows that in all enterprises and services, both private and public, expertise in management must be taught by training and by incentives to excel. In the political world this may take the form of asserting that much conflict and argument are unnecessary for solving problems. All that is needed is a rational assessment of the problem and this involves gathering and collating information, listing the options, calculating costs of each, evaluating consequences and choosing the best course of action. Recent managerialism has included such devices as \"performance indicators\" (purporting to measure the relative efficiencies of different managers) and \"market testing\" (which compares public sector managers' responsibilities and tasks with those of managers in the private sector in order to assess their pay). Managerialism is criticized for weakening the public-service ethos.\n\nIf one were to conceive of society as a nation, such as the United States, managerialism concludes that there is no single United States and that individual Americans should not be identified as the fundamental nature of the country. Rather, the country is basically composed of numerous groups which collectively make up the country we call the United States. \nThe government is a part of the managerial process. The management of different groups will attempt to influence the direction of government action. Their success or failure will depend upon their ability to pursue their case and upon their ability to blunt the cases of competitors. The success of the subunits depends upon the ability of their managements and other factors such as size, cohesiveness, managerial discretion, and control of resources. Government itself is a collection of governmental units. The government is not state.\n\nEconomically, managerialism is the application of managerial techniques in businesses. Managerialism in this regard has to do with the strategic approach of goal-setting. In order to achieve previously unimagined levels of accumulation and production, businesses within a capitalist economy needed a way of connecting their strategic plan of actions to desired implementations of those plans. Within an organization, the individuals at the top of the organizational hierarchy determine a mission or set of goals, which is then strategically analyzed by individuals lower on the hierarchy (managers) to devise local goals to carry out the overall mission. Put simply, the managerial standard is to receive goals from above and to create new goals for those below.\n\nThere is a belief that in managerialism, organizations have more similarities than differences, and thus the performance of all organizations can be optimized by the application of generic management skills and theory. To a practitioner of managerialism, there is little difference in the skills required to run a college, an advertising agency or an oil rig. Experience and skills pertinent to an organization's core business are considered secondary.\n\nThe term \"managerialism\" can be used disparagingly to describe organizations perceived to have a preponderance or excess of managerial techniques, solutions, rules and personnel, especially if these seem to run counter to the common sense of observers. It is said that the MBA degree is intended to provide generic skills to a new class of managers not wedded to a particular industry or professional sector.\n\nThere have been mixed reviews on the efficacy of managerialism, explored extensively in university studies of the State. Some have accepted the flaws in the theory, building upon it and putting it forth as a valid theory of the State. Others have outright rejected such a proposition, responding that - regardless of the few similarities - such a system could not be successful on a political level.\n\nThe word \"managerialism\" can also be used pejoratively, as in the definition of a management caste. Robert R. Locke defines it accordingly as:\n\"What occurs when a special group, called management, ensconces itself systemically in an organization and deprives owners and employees of their decision-making power (including the distribution of emolument), and justifies that takeover on the grounds of the managing group's education and exclusive possession of the codified bodies of knowledge and know-how necessary to the efficient running of the organization.\"\nManagerialism – also called New Managerialism and New Public Management – is an ideology used for legitimizing the development of new organizational forms and relationships. It has been coined a practical ideology of being 'business-like’ in order to make the new arrangements work for all forms of jobs, organizations, and education systems. The ‘business-like’ indicates what is called “as if” ideologies. Managerialism is conceptualized in that it seeks firstly to explain the socioeconomic and political reasons behind why particular organizations have been developed and, secondly, to describe the ways in which public services are currently being delivered. The idea of Managerialism came to fruition when new organizational forms originated from a view that professional bureaucratic modes of organization were inefficient and could not cope with the challenges rising from increasing globalization. Managerialism, however, has not remained static over the years as it has had many different versions of its implementation. Its linkage to the changing practices associated with an agenda moves away from a purely Neo-liberal framework. While neo-liberalism uses politics (e.g. elections) to achieve its goals, Managerialism is fundamentally anti-democratic following instead management’s command-and-control concept. While using business-like mechanisms to ensure great cost effectiveness is still used as a great technique. There have been movements away from purely market based systems that were in place strictly for efficiency, to contractual mechanisms and performance measurement through audit and review. In practice of Managerialism, consumers are redefined as well. Not only do consumers have choice in regard to where and how they receive their services, but they should be actively involved in determining what services should be provided as well. In new Managerialism consumers are redefined as well. Not only should they have choice regarding where and how they receive their services, but they should be actively involved in determining what services should be provided as well. The Managerialism explains public services not as production functions or firms, but as governance structures. What is at stake is not so much the ethos and practice of management as the culture and structure of governance. Here governance means the organisational culture and structure of the relationship between what Weber called legitimate domination and the self-constitution of those who are subject to it. What Weber meant by legitimate domination was justified by an authority structure, which was, in turn, legitimated by rational authority. Hence, one finds a renewed interest of Managerialism in fostering managerial leadership. But governance through Managerialism was never only dependent for its legitimization on Weber’s notion of legal-rational authority, but more on forms of rationality that depend upon, for example, strategic management, cost-benefit-analysis, efficiency in the market, etc. Although this Managerialism draws on models of corporate Managerialism as well as accounts of New Public Management, it is also imbued with the practices of self in everyday life. What is new here, is recognition of the technologies of self that individuals employ to implicate themselves in their own governance. This creates what became known as “The Entrepreneurial Self”. The way Managerialism achieves this, for example, at university levels is through a re-formulation of research and science, as outlined in the table below.\n\n George Elton Mayo \n\"One friend, one person who is truly understanding, who takes the trouble to listen to us as we consider our problems, can change our whole outlook on the work\"\n\nGeorge Elton Mayo was an Australian psychologist and organizational theorist. A former professor of Industrial Management at the Harvard Business School, Mayo heavily researched the behavior of workers at Western Electric; a manufacturing facet of AT&T. Today he is considered a major contributor to the intellectual thought process and ideas of business management, as well as critical theories of industrial and organizational psychology. His book, \"The Human Problems of an Industrialized Civilization\" articulates his collective thoughts taken from the famous Hawthorne research study conducted while at Harvard University.\n\n\"Society does not consist of individuals but expresses the sum of interrelations, the relations within which these individuals stand.\"\n\nKarl Marx has set many standards in the fields of philosophy, economics, and sociology as one of the worlds most prominent thinkers. Commonly known for his ideas outlined in \"The Communist Manifesto\" and \"\" Marx has exemplified ideas of management and order with his very apparent socialistic views. Sociologically Marx has identified core interrelations between groups of people classified by class structures, and how those relations lead to the success or failures of a collective society.\n\n\"To do great things is difficult; but to command great things is more difficult\"\n\nA 19th century German philosopher, Friedrich Nietzsche heavily contributed to the fields of management and leadership. Focussing in on ideas of morality; particularly distinguishing the differences between what he labeled the, \"master morality,\" and \"slave morality,\" Nietzsche has exemplified the development of managerial practices through the subjections of moral emphasis and control. \"He was especially interested, therefore, in a probing analysis and evaluation of the fundamental cultural values of Western philosophy, religion, and morality, which he characterized as expressions of the ascetic ideal.\"http://www.britannica.com/biography/Friedrich-Nietzsche\n\nThe history of Managerialism is linked to the teachings of Karl Marx. In his collection of books over capitalism appropriately named he writes about how when capitalist merge with other capitalist and two corporations come together, they are more likely to become diluted and when that happens those who were once wise business leaders were to be just aimless managers he stated his belief in his books (only volume 1 was published while he was alive) as follows, \"Transformation of the actually functioning capitalist into a mere manager, an administrator of other people's capital, and of the owners of capital into mere owners, mere money-capitalists.\". Marx is talking about what would later be known as Managerialism which is first used by James Burnham who in his book \"The Managerial Revolution\" expresses his ideas on the difference between Capitalism and Managerialism stating that when the owners of capital are no longer the ones in charge, and managers, relying on only principle are in charge then it is no longer Capitalism, it is now considered Managerialism. Burnham's ideas, in both that book and a subsequent book \"The Machiavellians\" and also in articles which were published in Partisan Review, and elsewhere are thoroughly criticised by George Orwell in his 1946 essay \"Second Thoughts on James Burnham\" (first published in \"Polemic\" (London).\n\nCompare:\n\n"}
{"id": "56816910", "url": "https://en.wikipedia.org/wiki?curid=56816910", "title": "Massachusetts ballot measures, 2018", "text": "Massachusetts ballot measures, 2018\n\nThree ballot measures were certified for the November 6, 2018, general election in the state of Massachusetts.\n\nThe Constitution of Massachusetts can be amended through initiative, and state statutes can be proposed through initiative. The first and second certified measures, \"Nurse-Patient Assignment Limits\" and \"Advisory Commission for Amendments to the U.S. Constitution Regarding Corporate Personhood and Political Spending\", were both initiated state statutes. The third measure, \"Gender Identity and Anti-Discrimination\", was a veto referendum.\n\nIn Massachusetts, after the state determines which measure(s) will appear on the ballot, an official name is assigned to each question. The Secretary of the Commonwealth has discretion over the ordering of questions on the ballot.\n\nVR = veto referendum<br>\nISS = initiated state statute<br>\nVote percentages as of November 8, with 100% reporting\n\nOn October 23, 2018, \"The Boston Globe\" editorial board endorsed a 'no' vote on Question 1, saying the nursing staff ratio is wrong for Massachusetts. On October 26, the \"Boston Herald\" also advocated for a 'no' vote. Governor of Massachusetts Charlie Baker said he would vote 'no', while Mayor of Boston Marty Walsh said he would vote 'yes'. A \"yes\" vote was also advocated by United States Senator for Vermont Bernie Sanders.\n\nA 'yes' vote on Question 3 has been \"wholeheartedly\" endorsed by \"The Boston Globe\" in an October 17, 2018, editorial. Actress and LGBT advocate Laverne Cox also advocated for a 'yes' vote.\n\nA measure titled \"Income Tax for Education and Transportation Amendment\", which sought to create a four percent tax on incomes that exceed $1 million, to be used for education and transportation purposes, was removed after the Massachusetts Supreme Judicial Court ruled in June 2018 that the measure had been incorrectly certified by the Massachusetts Attorney General.\n\nSeveral additional measures received a required number of signatures by December 6, 2017, but ultimately were not added to the ballot:\n\nA new law enacting a majority of content from these three measures was signed into law in late June by Governor of Massachusetts Charlie Baker. Hourly minimum wage will be increased from $11 to $15 by 2023, workers will have paid medical leave of 12 to 20 weeks (depending on circumstance), and there will be an annual August sales tax holiday; the state sales tax was not decreased. Initiative organizers agreed to withdraw the associated ballot initiatives.\n\n\n\n"}
{"id": "36175603", "url": "https://en.wikipedia.org/wiki?curid=36175603", "title": "Mines and Minerals (Development and Regulation) Act", "text": "Mines and Minerals (Development and Regulation) Act\n\nThe Mines and Minerals (Regulation and Development) Act (1957) is an Act of the Parliament of India enacted to regulate the mining sector in India. It was amended in 2015 and 2016. This act forms the basic framework of mining regulation in India.\n\nThis act is applicable to all mineral except coal, minor minerals and atomic minerals. It details the process and conditions for acquiring a mining or prospecting licence in India. Mining minor minerals comes under the purview of state governments. River sand is considered a minor mineral. For mining and prospecting in forest land, prior permission is needed from the Ministry of Environment and Forests.\n\nThe act was amended by The Mines and Minerals (Development and Regulation) Amendment Act, 2015 replacing the ordinance promulgated on 12 January 2015. The amendment was proposed to bring transparency to the allocation of mining licence process by auctions. It was passed in the Lok Sabha on 3 March 2015 and in the Rajya Sabha on 20 March 2015. The bill sought to bring transparency to the allocation of mining licence process by auctions.\n\nIn November 2014, the draft of the bill was released for public comments. On 12 January 2015, Mines and Minerals (Development and Regulation) Amendment Ordinance, 2015, was approved by the President of India. It was the 7th ordinance by the National Democratic Alliance government since it took power in May 2014. The bill to replace the ordinance was introduced in the Parliament on 23 February 2015.\n\nOn 16 May 2014, the Supreme Court of India cancelled licences of 26 mines in Odisha state. These mines were being operating even though the state had not given them renewal leases. The state was given 6 months to resolve the issues. During this period, Odisha renewed 8 leases. On 6 January 2015, the Government of Odisha decided to auction its remaining non-coal mining leases awaiting renewal. The state was granted 2 more months on 23 February to decide. However, introduction of the bill delayed Odisha's plans of auction.\n\nThe amendment seeks to introduce a system of auctions to allocate mining licenses. A fixed percentage to the revenue of any mine will be allocated to development of the area around it, to be called a District Mineral Foundation. The state government will set the rates and it will be in addition to the royalty. A National Mineral Exploration Trust will be set up to explore and promote non-coal minerals. It will have a starting fund of crore and will be funded by a 2% levy from mining license holders.\n\nThe licences will have a validity of 50 years, compared to the previous 30 years. There will be no renewal of licences, only re-auction. The bill contains a new license for prospecting-cum-mining, replacing a two-stage process. The mining and prospecting-cum-mining licences may be transferred to another party by notifying the state government. The state government may charge a fees for such transfers. Notified minerals like iron ore, limestone, manganese, and bauxite, will not require a prospecting licence. The mining licence will be auctioned. For non-notified minerals, a prospecting-cum-mining licence will be required.\n\nThe amendment will make illegal mining, trespassing and violation of norms, cognisable offences punishable by 2 years imprisonment and/or fine. The state government will be allowed to set up special courts for such trials.\n\nIn January 2015, after the ordinance was signed, a mining industry lobby group Society of Geo-scientists and Allied Technologists (SGAT) said that the prospecting-cum-mining was useless as no one would apply for such a licence unless they had found a proven reserve by prospecting first.\n\nIn March 2015, during the session in which the bill was tabled, the central government did accept the changes proposed some opposition members, some of whom staged a walk-out. Biju Janata Dal (BJD) political party of Odisha said that the bill infringes on the rights of state governments. The view was supported by Indian National Congress and All India Trinamool Congress party. Kariya Munda of BJP said that provisions for the tribals displaced by mines should be made. Tathagata Satapathy of BJD also voiced similar concerns. The period of validity of licences was criticised as being too long at 50 years.\n\nThe Union Cabinet of India approved amendments in March 2016. The amendment will allow transfer of captive mining leases not granted through auction. Transfer of captive mining leases, granted otherwise than through auction, would allow mergers and acquisitions of companies and facilitate ease of doing business for companies to improve profitability and decrease costs of the companies' dependent on supply of mineral ore from captive leases. The transfer provisions will also facilitate banks and financial institutions to liquidate stressed assets where a company or its captive mining lease is mortgaged.\n\n"}
{"id": "41576466", "url": "https://en.wikipedia.org/wiki?curid=41576466", "title": "Ministry of Foreign Affairs (Guatemala)", "text": "Ministry of Foreign Affairs (Guatemala)\n\nThe Ministry of Foreign Affairs of Guatemala is the executive office in charge of conducting the international relations of the country. This ministry can give the Guatemalan nationality, enforces the immigration laws of the country, preserves the national limits and boundaries, negotiates international treaties and agreements with other countries and preserves the copies of the ones signed by Guatemala. It is appointed by law to preserve the national interests overseas and to be part of the National Security System.\n\nStarting in the 19th century, right after independence from Spain was signed, the public administration was slowly organized. There was a first stage when Guatemala was a part of the United Provinces of Central America, and a second stage starting in 1847, when Guatemala became an independent, free and sovereign republic to administer its own public affairs. Through that time, the different executive offices were organized as \"secretariats\", following the Spanish nomenclature. This terminology included the Secretariat of Foreign Affairs, which kept its name until after the Revolution of 1944. Decree #47, passed by the Revolutionary Joint on December 27, 1944, still used this category. However, when the new Constitution came into force on March 15, 1945, the Constitutional system created the Ministries of State. For that reason, Congress passed a bill for the organization of the Executive Branch, which first spoke of a Foreign Affairs Ministry, on April 25, 1945.\n\nCurrently, Guatemala holds diplomatic relations with 152 countries. It has 41 embassies throughout the World, and 4 missions in International Organizations.\n\n"}
{"id": "16803425", "url": "https://en.wikipedia.org/wiki?curid=16803425", "title": "Moshava", "text": "Moshava\n\nA moshava (), plural: \"moshavot\" (), was a form of rural Jewish settlement in Ottoman Palestine, established by the members of the Old Yishuv since late 1870s and during the first two waves of Jewish Zionist immigration - the First and Second Aliyah.\nIn a moshava, as opposed to later communal settlements like the kibbutz and the moshav, all the land and property are privately owned. The first moshavot were established by the members of the Jewish community and by pioneers of the First Aliyah arriving to Ottoman Palestine. The economy of the early moshavot was based on agriculture and resembled the grain-growing villages of eastern Europe in layout. Farms were established along both sides of a broad main street. \n\nPetah Tikva, known as the \"Mother of the Moshavot\" (\"Em HaMoshavot\"), was founded in 1878 by members of the Old Yishuv, as well as Gai Oni, which later became Rosh Pinna with the arrival of the First Aliyah. The first four moshavot of the First Aliyah period were Rishon LeZion, Rosh Pinna, Zikhron Ya'akov and Yesud HaMa'ala.\n\nThe driving force behind these early settlements was the Hovevei Zion movement in Europe, whose branches operated as financially-independent settlement societies. \n\nThe moshava was governed by a charter outlining communal principles that established a covenent or bond between the residents.\n\n\nFive colonies were also established in the Hauran by immigrants of the First Aliyah.\n\n\n"}
{"id": "46692335", "url": "https://en.wikipedia.org/wiki?curid=46692335", "title": "National Territorial Commanders Committee", "text": "National Territorial Commanders Committee\n\nThe National Territorial Commanders Committee, or NTCC, is an informal forum for the exchange of information and for the consultation on multinational issues of mutual (military) interest. The NTCC coordinates host nation support and establishes guidelines to facilitate reception, staging and onward movement (RSOM) of transiting or operating allied and partner nation forces; coordinates operational access to national lines of communication; and coordinates delivery of defense and intergovernmental resources for operations, exercises and contingencies of sending nations.\n\nThe NTCC was first established in 1986 by six nations, and today it is composed of senior logistical military commanders and representatives from more than 20 allied and partner nations. The NTCC is staffed with observers from the North Atlantic Treaty Organization (NATO),Supreme Headquarters Allied Powers Europe(SHAPE), the European Union(EU) military staff and the United States European Command (EUCOM). The organization seeks to improve host nation cooperation and enhance NTCC member capabilities to responsively meet allied and partner sending nation support requirements for exercises, contingencies or operations.\n\nThe NTCC mission is to streamline host nation support (HNS) coordination between member nations. The organization's vision is to be the leading multinational network for host nation support.\n\nThrough information sharing and capturing lessons learned, the members of the NTCC seek to transform operational processes to create a system of best practices to govern host nation support procedures and capabilities. \n\nThe primary NTCC focus areas are:\n\nThe NTCC does not replace bilateral or joint agreements between nations, nor does its capabilities supersede those of NATO or other formal documents/organizations.\n\nMembers seek to exchange and share information on issues of common concern, with the end goal of streamlining processes and procedures to ensure rapid response of host nation support during military operations, exercises, crises and in times of peace. The experts of the NTCC facilitate the development and acceptance of bilateral and multilateral logistics arrangements/agreements and liaise with organizations across the spectrum on matters related/adjacent to host nation support matters.\n\nThrough participation in multinational logistics planning conferences, NATO Schools and in allied and joint exercises, the NTCC helps bolster regional and partner confidence in planning, managing and implementing host nation logistics support.\n\nThe Commanders of the NTCC meet annually for the National Territorial Commanders Committee Meeting. During this meeting, the Commanders vote on issues of importance to the organization and affirm/execute the guidance and tasks brought forward by the NTCC Steering Committee.\n\nThe NTCC Steering Committee meets twice annually and is composed of national single points of contact (SPOCs) who liaise on behalf of their commanders/nations on the day-to-day business of host nation support logistics. The steering committee is chaired by a permanent secretary (PERMSEC) who coordinates the issues of the NTCC and SPOCs in accordance with the official NTCC Terms of Reference.\n\nThere are three levels of participation in the NTCC Forum:\n\n"}
{"id": "115820", "url": "https://en.wikipedia.org/wiki?curid=115820", "title": "New Llano, Louisiana", "text": "New Llano, Louisiana\n\nNew Llano is a town in Vernon Parish, Louisiana, United States. The population was 2,415 at the 2000 census. It is part of the Fort Polk South Micropolitan Statistical Area.\n\nOriginally known as Stables, the town was renamed when 200 members of the Socialist commune Llano del Rio Cooperative Colony in California relocated to this site in 1917, giving the town its present name. It continued to function as a socialist commune with citizens pooling and sharing resources and wealth until 1937.\n\nNew Llano is located at (31.114793, -93.279793).\n\nAccording to the United States Census Bureau, the town has a total area of 1.0 square mile (2.5 km²), all land.\n\nThe \"New Llano Cooperative Colony\" was founded in 1917 when Job Harriman relocated, with other commune members of the Llano del Rio colony, to 20,000 acres of cut-over land two miles south of Leesville. The location chosen was the Gulf Lumber Company sawmill town named Stables. The mill had burned in 1913 and again in 1916. After the sawmill burned the second time it was not rebuilt because the stumpage reserves were depleted. The land, was sold on contract to the Cooperative Colony. The colony attempted to achieve self-sufficiency with a national socialist newspaper, a broom factory, sawmill, ice plant, and sheet metal factory. There was also a school, infirmary, hospital, and recreational facilities. The colony closed in 1937.\n\nAs of the census of 2000, there were 2,415 people, 925 households, and 640 families residing in the town. The population density was 2,488.0 people per square mile (961.3/km²). There were 1,037 housing units at an average density of 1,068.3 per square mile (412.8/km²). The racial makeup of the town was 46.09% White, 40.29% African American, 0.83% Native American, 3.77% Asian, 0.29% Pacific Islander, 4.10% from other races, and 4.64% from two or more races. Hispanic or Latino of any race were 8.57% of the population.\n\nThere were 925 households out of which 40.8% had children under the age of 18 living with them, 46.4% were married couples living together, 18.3% had a female householder with no husband present, and 30.8% were non-families. 24.4% of all households were made up of individuals and 5.1% had someone living alone who was 65 years of age or older. The average household size was 2.61 and the average family size was 3.11.\n\nIn the town, the population was spread out with 30.8% under the age of 18, 10.6% from 18 to 24, 33.5% from 25 to 44, 19.7% from 45 to 64, and 5.3% who were 65 years of age or older. The median age was 29 years. For every 100 females, there were 100.9 males. For every 100 females age 18 and over, there were 95.8 males.\n\nThe median income for a household in the town was $35,417, and the median income for a family was $34,271. Males had a median income of $26,563 versus $20,500 for females. The per capita income for the town was $15,902. About 13.5% of families and 15.6% of the population were below the poverty line, including 18.4% of those under age 18 and 13.9% of those age 65 or over.\n\n\n"}
{"id": "8736554", "url": "https://en.wikipedia.org/wiki?curid=8736554", "title": "Popular Unity Candidacy", "text": "Popular Unity Candidacy\n\nThe Popular Unity Candidacy () is a left-wing pro-Catalan independence political party active primarily in Catalonia, where it has political representation, but also in other autonomous communities in Spain it considers to belong to the Catalan Countries. The CUP traditionally has focused on municipal politics, and is made up of a series of autonomous candidatures that run in local elections. Its presence is strongest in Catalonia proper.\n\nIn 2012, the CUP decided for the first time to run for Catalan parliamentary elections, gaining 3 MPs out of 135. In the 2015 elections they obtained 10 MPs.\n\nThe CUP is made up of autonomous local assemblies representing towns or neighbourhoods. These assemblies may have some ideological differences, but their common ground is independence for the Catalan Countries and clear left-wing politics, often in the form of anti-capitalism, socialism, and eco-socialism.\n\nThe different local candidatures are coordinated through the \"Municipal Assembly of the Independentist Left\" (\"AMEI\" in Catalan) where the details regarding their party platform are discussed. On both the local and national level, decisions are made in assembly according to the principles of deliberative democracy.\n\nThe highly decentralised nature of this party stems from a belief in municipalism. The CUP consider municipal government \"the only institutions within the reach of the general populace\". The importance given to municipal assemblies is also meant to avoid the hierarchical organisation of most traditional political parties.\n\nThe CUP website describes the entity as \"an assembly-based political organisation spread throughout the Catalan Countries that works for a country that's independent, socialist, environmentally sustainable and free from the domination of the patriarchy\".\n\nThe CUP defends the unity of the Catalan-speaking areas, or Catalan Countries, which they believe should be allowed to constitute an independent republic, according to the principles of self-determination. The CUP is also strongly in favor of the Catalan language, which should be the \"preferential and common language\" of the areas where it is traditionally spoken. Still, the 2012 CUP program refers to the advantages of multilingualism and encourages debate on the status that an independent Catalonia would grant to French and Spanish.\n\nThe CUP criticise the current political system in place in Spain and France, and defend an alternative brand of participative democracy. It has proposed, for example, that the general public be allowed to vote on important issues in referenda, and have suggested the creation of representative recall (), which would allow the general public to remove elected officials from office before their term expires. As part of its belief in municipalism, it also has defended the creation of an Assembly of Councillors (), made up of municipal councillors, as a national representative body.\n\nThe CUP broadly refers to its economic model as socialist. Its political programme calls for a \"planned economy based on solidarity, aimed towards fulfilling the needs of the people\", and defends the nationalisation of public utilities as well as transport and communication networks. It also calls for a nationalisation of all banks receiving government bailouts and considers the public debt \"illegitimate\".\n\nThe CUP call for an end to nuclear energy, with the use of sustainable energy in its stead. It also calls for a ban on GMOs and the creation of an \"ecological economy\".\n\nThe CUP believe in full civic rights for all inhabitants of the Catalan Countries, including migrants. It also calls for voting rights for everyone over 16 years of age as well as an end to discrimination against women and LGBT people.\n\nSince 2003, the presence of the CUP in Catalan municipal politics has increased steadily.\n\nIn 2003, the CUP ran alone in 10 municipalities in Catalonia, winning four council seats in three towns. In 8 more municipalities, the CUP ran as part of local coalitions.\n\nFrom 2007-2011, the CUP held a total of 26 council seats in 17 different municipalities in Catalonia; these were obtained either under the CUP name alone or in coalition with local political parties. In the 2007 municipal elections, the CUP obtained 18,000 votes, or about 0.65% of the votes cast.\n\nIn the 2011 municipal elections, the CUP ran in 80 of Catalonia's 947 municipalities, winning about 62,000 votes (2.16% of those cast), and coming in as the sixth largest party in terms of vote share. As a result, the CUP won a total of 104 municipal council seats; four towns had CUP mayors. Also, it held 11 seats on different \"comarca\" councils.\n\nIn 2012, after snap elections were declared by Catalan president Artur Mas, different local branches of the CUP organised assemblies open to the general public in order to debate whether the CUP should run. On 13 October, the general assembly of the CUP met in Molins de Rei and decided, with 77% in favour, to run for the first time in the Catalan parliamentary elections. For this purpose, the CUP decided use the name \"Candidatura d'Unitat Popular – Alternativa d'Esquerres\" (Popular Unity Candidacy – Left-Wing Alternative) in order to include independent candidates who chose to run on CUP lists. David Fernàndez, a journalist from Gràcia, was chosen to head the list for Barcelona.\n\nThe CUP promised that, if elected, its candidates only would serve one term, earn no more than €1,600 a month, and base their decisions on the opinions expressed by local assemblies. it also promised not to request any loans from banks, so as to avoid being influenced by \"financial groups and economic élites\".\n\nThe CUP was able to win representation in the Catalan Parliament with three seats, and 126,219 votes. The three CUP seats went to the party's spokesman David Fernàndez, Georgina Rieradevall (number two on the list later on replaced by Isabel Vallet), and Quim Arrufat (number three on the list). These results are historic for the CUP, but its spokesman emphasises that it must keep on working and fighting in the streets for a better future.\n\nIn the 2015 municipal elections, the CUP presented candidatures in 163 different municipalities, more than double the number of candidatures presented in the previous elections. In Catalonia, the CUP obtained 221,746 votes in all (7.12% percent of those cast). This was more than three times what it had won in 2011, earning 372 council seats, an absolute majority on nine town councils, and a relative majority in four more. CUP mayors were chosen in 14 municipalities, whereas previously the CUP only held three mayorships. For the first time, the CUP won the government of the capital of a \"comarca\", Berga.\n\nCoalitions including the CUP won important victories in other municipalities; in Badalona, Catalonia's third most populous city, a coalition including the CUP came in second and won the mayorship with the help of other left-wing parties. The CUP managed to win representation in most major cities in Catalonia, including Barcelona, Girona, Lleida, Tarragona, L'Hospitalet and Terrassa. In the Valencian Community, the CUP ran in four municipalities, and won seats on the municipal councils of two, Pedreguer and Burjassot.\n\nIn the 2015 Parliamentary elections, the CUP formed a coalition called \"Candidatura d'Unitat Popular – Crida Constituent\" (Popular Unity Candidacy - Constituent Call). Antonio Baños, a journalist and writer from the Nou Barris neighbourhood of Barcelona, was chosen to head the list.\n\nThe party won 336,375 votes, almost tripling its previous results, and was awarded 10 seats in the Catalan Parliament. That placed it in the position of kingmaker, with enough seats to form a pro-independence alliance with Together for Yes, which obtained 62 seats. After three months of negotiations in which the CUP rejected the presidency of incumbent Artur Mas, the CUP and Together for Yes reached an agreement by which Carles Puigdemont, mayor of Girona, became president of Catalonia. Nevertheless, while eight CUP MPs voted in favor of Puigdemont's presidency, two abstained to \"express their differences\" with Together for Yes.<ref name=\"http://www.vilaweb.cat/noticies/vuit-dels-diputats-de-la-cup-votaran-a-favor-de-la-investidura-de-puigdemont/?f=rel\"></ref> As part of this agreement, two CUP MPs are to work closely with Together for Yes in order to ensure a pro-independence majority in the Parliament of Catalonia.<ref name=\"http://www.vilaweb.cat/noticies/urgent-artur-mas-dimiteix-per-desbloquejar-lacord-i-avancar-cap-a-la-independencia/\"></ref>\n\n\n"}
{"id": "1600241", "url": "https://en.wikipedia.org/wiki?curid=1600241", "title": "Prisoners' rights", "text": "Prisoners' rights\n\nThe rights of civilian and military prisoners are governed by both national and international law. International conventions include the International Covenant on Civil and Political Rights; the United Nations' Minimum Rules for the Treatment of Prisoners, the European Committee for the Prevention of Torture and Inhuman or Degrading Treatment or Punishment, and the Convention on the Rights of Persons with Disabilities\n\nIn the United States, the Prison Litigation Reform Act, or PLRA, is a federal statute enacted in 1996 with the intent of limiting \"frivolous lawsuits\" by prisoners. Among its provisions, the PLRA requires prisoners to exhaust all possibly executive means of reform before filing for litigation, restricts the normal procedure of having the losing defendant pay legal fees (thus making fewer lawyers willing to represent a prisoner), allows for the courts to dismiss cases as \"frivolous\" or \"malicious\", and requires prisoners to pay their court fees up front if they have three previous instances of a case having been dismissed as \"frivolous.\"\n\n\nOrganizations working for prisoners' rights:\n"}
{"id": "53070387", "url": "https://en.wikipedia.org/wiki?curid=53070387", "title": "Prix Alexis de Tocqueville", "text": "Prix Alexis de Tocqueville\n\nThe Prix Alexis de Tocqueville is an international Prize for political Literature. It is awarded every two years to a person who has demonstrated outstanding humanistic qualities and attachment to public liberties and seeks to perpetuate Alexis de Tocqueville’s ideals.\n\nIt was created in 1979 by Pierre Godefroy, mayor of the nearby town of Valognes and Alain Peyrefitte, a noted author, member of the Académie Francaise and politician.\n\nThe jury of this prestigious award is currently chaired by former French President Valéry Giscard d’Estaing, and includes Sandra day O’Connor, professor Harvey C Mansfield and a number of other eminent members. The last two American recipients of the Prize were General Colin Powell and Mr. Zbigniew Brzezinski.\n\nThe Association organizing the Prize is now headed by the Countess Stéphanie de Tocqueville. The Prize is awarded at the Chateau de Tocqueville.\n\n\n"}
{"id": "52036393", "url": "https://en.wikipedia.org/wiki?curid=52036393", "title": "Reform laws", "text": "Reform laws\n\nThe Reform laws were a set of anticlerical laws enacted in Mexico between 1855 and 1863, during the governments of Juan Alvarez, Ignacio Comonfort and Benito Juárez that were intended to limit the privileges (\"fueros\") of the Roman Catholic Church and the military. The laws also limited the ability of Catholic Church and indigenous communities from collectively holding land. The liberal government sought the revenues from the disentailment of church property, which could fund the civil war against Mexican conservatives and to broaden the base of property ownership in Mexico and encouraging private enterprise. Several of them were raised to constitutional status by the constituent Congress that drafted the liberal Constitution of 1857. Although the laws had a major impact on the Catholic Church in Mexico, liberal proponents were not opposed to the church as a spiritual institution, but rather sought a secular state and a society not dominated religion.\n\nOn March 1, 1854, the Plan of Ayutla was proclaimed against the dictatorship of Antonio Lopez de Santa Anna, indicting him for his sale of the Mesilla Valley to the United States, the Gadsden Purchase; acting as a repressive dictator, and eliminating democratic institutions. The revolution was led by Florencio Villarreal, Juan Alvarez and Ignacio Comonfort spread to many parts of the country, achieving success in October 1855. Juan Alvarez assumed the presidency on an interim basis who in turn convened a congress. An important aspect of Juan Alvarez was taking in his cabinet young liberals, thanks to it so important for the history of Mexico and Melchor Ocampo, Benito Juarez, Guillermo Prieto and Ignacio Comonfort men had the opportunity to have an active political participation. In his administration, Alvarez was dedicated to make laws that keep the country under the ideals of liberalism, as the Juárez Law, and the provision of Melchor Ocampo depriving the right to vote the clergy. For personal reasons Juan Alvarez resigned in December 1855 and left Ignacio Comonfort as responsible for the country's presidency.\n\n\n\n\n\nThrough the issuance of these laws and decrees Mexico was achieved in the separation of church and state. The new constitution polarized society, in December 1857 the Conservatives ignored the government and the new constitution by the Plan of Tacubaya, which began the War of the Reform or Three Years' War. Liberals achieved victory, on January 1, 1861, President Juárez returned to Mexico City. It is for this reason that several of the decrees and laws were issued in the port of Veracruz. But the country's stability was again interrupted, the government had to suspend payments on foreign debt. By the London Convention, the governments of France, Britain and Spain decided to intervene in Mexico. an agreement with the British and the Spanish, but not with the French, who with this pretext and with the help of conservatives began armed intervention and shortly after the Second Mexican Empire was achieved. Juarez was forced to flee the capital holding his itinerant government. It was possible to Restore the Republic\n\n\n"}
{"id": "6685688", "url": "https://en.wikipedia.org/wiki?curid=6685688", "title": "SS7 probe", "text": "SS7 probe\n\nAn SS7 probe is a physical device to obtain signalling and/or bearer information from a telecommunications network, such as the PSTN or a corporate telephone system. The probe passively monitors the E1/T1 or SDH/SONET bearer channels, and extracts the signalling information for onward presentation to an application. A passive probe does not affect the network under observation--this is achieved through use of protected monitor points on the network distribution frames.\n\nThe network application may be lawful interception or a revenue-generating application such as missed call. Probes are also extensively used in operational support systems (OSS).\n\nApplications served by probes include solutions for inter-carrier billing, revenue loss (by-pass/phantom traffic and analysis services), fraud prevention, billing, local number portability, quality of service, surveillance (global call trace), maintenance (protocol analysis), traffic engineering (link and trunk forecasting), alarming and SS7, Sigtran and IS-41 monitoring.\n\nPassive monitoring probes provide a network and switch vendor-independent solution for network applications.\n\nLawful interception concerns the delivery of calls and data to government approved reception centres. Interception is authorized through a legal framework, such as UK RIPA or US CALEA or Russia SORM.\n\nSS7 probe technology provides the correct physical interface to the telecommunications network. Opportunities for probing occur in both traditional TDM infrastructure as well as in ATM and IP networks. The different characteristics and infrastructure used for these interfaces is reflected in the types of interfaces to be monitored. These range from E1 or T1 2Mbit/s or 1.5Mbs to SDH and SONET STM-x OC-x multiplexes.\n"}
{"id": "3331474", "url": "https://en.wikipedia.org/wiki?curid=3331474", "title": "Snoezelen", "text": "Snoezelen\n\nSnoezelen or controlled multisensory environment (MSE) is a therapy for people with autism and other developmental disabilities, dementia or brain injury. It consists of placing the person in a soothing and stimulating environment, called the \"Snoezelen room\". These rooms are specially designed to deliver stimuli to various senses, using lighting effects, color, sounds, music, scents, etc. The combination of different materials on a wall may be explored using tactile senses, and the floor may be adjusted to stimulate the sense of balance. The person is usually accompanied by an aide or therapist.\n\nDeveloped in the Netherlands in the 1970s, Snoezelen rooms have been established in institutions all over the world and are especially common in Germany, where more than 1,200 exist.\n\nThere is no evidence that Snoezelen is effective for the treatment of dementia.\nThe term \"Snoezelen\" (pronounced ) is a neologism formed from a blend of the Dutch \"snuffelen\" (to snuggle, also: to sniff) and \"doezelen\" (to doze, to snooze). It was coined by Jan Hulsegge and Ad Verheul who developed the concept while working at De Hartenberg Institute in the Netherlands.\n\nIdeally, Snoezelen is a non-directive therapy, controlled by the client and not by the therapist. It can be staged to provide a multi-sensory experience or single sensory focus, simply by adapting the lighting, atmosphere, sounds, and textures to the specific needs of the client at the time of use. There is no formal focus on therapeutic outcome—the focus is to assist users to gain the maximum pleasure from the activity in which they and the enabler are involved. An advantage of Snoezelen therapy is that it does not rely on verbal communication and may be beneficial for people with profound autism, as it may provide stimulation for those who would otherwise be almost impossible to reach.\n\nSnoezelen therapy relates to the interdependence of both the space (the physical environment) and the \"client-centered\" approach of the practitioner (the human environment). The specially designed sensory physical environment together with the input of the \"enabling practitioner\" initiates changes in arousal by affecting the relaxation process, reducing anxiety/pain (both physical and emotional). It aims to maximize a person's potential to focus on his own free will and to engage on a motivational stimulus (object, activity or person), and thereby to improve communication and functioning.\n\nThe defining principles of the MSE help the practitioner to focus attention on the basic elements of this approach. The following are the principles.\n\n\nResearch on the benefits of Snoezelen treatment is scarce, with variable study designs.\n\nA small research study carried out in Brussels compared the behavior of nine adult clients with profound autism in both classroom and Snoezelen settings. Though individual results varied, the study claimed a 50% reduction in distress and stereotypical behavior, and seventy-five percent less aggression and self-injury in the Snoezelen environment.\n\n"}
{"id": "14130192", "url": "https://en.wikipedia.org/wiki?curid=14130192", "title": "Social inequality", "text": "Social inequality\n\nSocial inequality occurs when resources in a given society are distributed unevenly, typically through norms of allocation, that engender specific patterns along lines of socially defined categories of persons. It is the differentiation preference of access of social goods in the society brought about by power, religion, kinship, prestige, race, ethnicity, gender, age, sexual orientation, and class. The social rights include labor market, the source of income, health care, and freedom of speech, education, political representation, and participation. Social inequality linked to economic inequality, usually described on the basis of the unequal distribution of income or wealth, is a frequently studied type of social inequality. Though the disciplines of economics and sociology generally use different theoretical approaches to examine and explain economic inequality, both fields are actively involved in researching this inequality. However, social and natural resources other than purely economic resources are also unevenly distributed in most societies and may contribute to social status. Norms of allocation can also affect the distribution of rights and privileges, social power, access to public goods such as education or the judicial system, adequate housing, transportation, credit and financial services such as banking and other social goods and services.\n\nMany societies worldwide claim to be meritocracies—that is, that their societies exclusively distribute resources on the basis of merit. The term \"meritocracy\" was coined by Michael Young in his 1958 dystopian essay \"The Rise of the Meritocracy\" to demonstrate the social dysfunctions that he anticipated arising in societies where the elites believe that they are successful entirely on the basis of merit, so the adoption of this term into English without negative connotations is ironic; Young was concerned that the Tripartite System of education being practiced in the United Kingdom at the time he wrote the essay considered merit to be \"intelligence-plus-effort, its possessors ... identified at an early age and selected for appropriate intensive education\" and that the \"obsession with quantification, test-scoring, and qualifications\" it supported would create an educated middle-class elite at the expense of the education of the working class, inevitably resulting in injustice and – eventually – revolution. A modern representation of the sort of \"meritocracy\" Young feared may be seen in the series \"3%\".\n\nAlthough merit matters to some degree in many societies, research shows that the distribution of resources in societies often follows hierarchical social categorizations of persons to a degree too significant to warrant calling these societies \"meritocratic\", since even exceptional intelligence, talent, or other forms of merit may not be compensatory for the social disadvantages people face. In many cases, social inequality is linked to racial inequality, ethnic inequality, and gender inequality, as well as other social statuses and these forms can be related to corruption.\n\nThe most common metric for comparing social inequality in different nations is the Gini coefficient, which measures the concentration of wealth and income in a nation from 0 (evenly distributed wealth and income) to 1 (one person has all wealth and income). Two nations may have identical Gini coefficients but dramatically different economic (output) and/or quality of life, so the Gini coefficient must be contextualized for meaningful comparisons to be made.\n\nSocial inequality is found in almost every society. Social inequality is shaped by a range of structural factors, such as geographical location or citizenship status, and are often underpinned by cultural discourses and identities defining, for example, whether the poor are 'deserving' or 'undeserving'. In simple societies, those that have few social roles and statuses occupied by its members, social inequality may be very low. In tribal societies, for example, a tribal head or chieftain may hold some privileges, use some tools, or wear marks of office to which others do not have access, but the daily life of the chieftain is very much like the daily life of any other tribal member. Anthropologists identify such highly egalitarian cultures as \"kinship-oriented\", which appear to value social harmony more than wealth or status. These cultures are contrasted with materially oriented cultures in which status and wealth are prized and competition and conflict are common. Kinship-oriented cultures may actively work to prevent social hierarchies from developing because they believe that could lead to conflict and instability. In today's world, most of our population lives in more complex than simple societies. As social complexity increases, inequality tends to increase along with a widening gap between the poorest and the most wealthy members of society.\n\nSocial inequality can be classified into egalitarian societies, ranked society, and stratified society. Egalitarian societies are those communities advocating for social equality through equal opportunities and rights hence no discrimination. People with special skills were not viewed as superior compared to the rest. The leaders do not have the power they only have influence. The norms and the beliefs the egalitarian society holds are for sharing equally and equal participation. Simply there are no classes. Ranked society mostly is agricultural communities who hierarchically grouped from the chief who is viewed to have a status in the society. In this society, people are clustered regarding status and prestige and not by access to power and resources. The chief is the most influential person followed by his family and relative, and those further related to him are less ranked. Stratified society is societies which horizontally ranked into the upper class, middle class, and lower class. The classification is regarding wealth, power, and prestige. The upper class are mostly the leaders and are the most influential in the society. It's possible for a person in the society to move from one stratum to the other. The social status is also hereditable from one generation to the next.\n\nThere are five systems/types of social inequality which include wealth inequality, treatment and responsibility inequality, political inequality, life inequality, and membership inequality. Political inequality is the difference brought about by the ability to access federal resources which therefore have no civic equality. In treatment and responsibility difference some people are more benefited and can quickly receive more privileged than others. In working stations, some are given more responsibilities and hence better compensations and more benefits than the rest even when equally qualified. Membership inequality this is the number of members in a family, nation or of faith. Life inequality is brought about by the disparity of opportunities if presented they improves a person life quality. Finally, the income and wealth inequality is the disparity due to what an individual can earn on a daily basis contributing to their total revenue either monthly or yearly.\n\nThe major examples of social inequality include income gap, gender inequality, health care, and social class. In health care, some individuals receive better and more professional care compared to others. They are also expected to pay more for these services. Social class differential comes evident during the public gathering where upper-class people given the best places to seat, the hospitality they receive and the first priorities they receive.\n\nStatus in society is of two types which are ascribed characteristics and achieved characteristics. Ascribed characteristics are those present at birth or assigned by others and over which an individual has little or no control. Examples include sex, skin colour, eye shape, place of birth, sexuality, gender identity, parentage and social status of parents. Achieved characteristics are those which we earn or choose; examples include level of education, marital status, leadership status and other measures of merit. In most societies, an individual's social status is a combination of ascribed and achieved factors. In some societies, however, only ascribed statuses are considered in determining one's social status and there exists little to no social mobility and, therefore, few paths to more social equality. This type of social inequality is generally referred to as caste inequality.\n\nOne's social location in a society's overall structure of social stratification affects and is affected by almost every aspect of social life and one's life chances. The single best predictor of an individual's future social status is the social status into which they were born. Theoretical approaches to explaining social inequality concentrate on questions about how such social differentiations arise, what types of resources are being allocated (for example, reserves versus resources), what are the roles of human cooperation and conflict in allocating resources, and how do these differing types and forms of inequality affect the overall functioning of a society?\n\nThe variables considered most important in explaining inequality and the manner in which those variables combine to produce the inequities and their social consequences in a given society can change across time and place. In addition to interest in comparing and contrasting social inequality at local and national levels, in the wake of today's globalizing processes, the most interesting question becomes: what does inequality look like on a worldwide scale and what does such global inequality bode for the future? In effect, globalization reduces the distances of time and space, producing a global interaction of cultures and societies and social roles that can increase global inequities.\n\nPhilosophical questions about social ethics and the desirability or inevitability of inequality in human societies have given rise to a spate of ideologies to address such questions. We can broadly classify these ideologies on the basis of whether they justify or legitimize inequality, casting it as desirable or inevitable, or whether they cast equality as desirable and inequality as a feature of society to be reduced or eliminated. One end of this ideological continuum can be called \"Individualist\", the other \"Collectivist\". In Western societies, there is a long history associated with the idea of individual ownership of property and economic liberalism, the ideological belief in organizing the economy on individualist lines such that the greatest possible number of economic decisions are made by individuals and not by collective institutions or organizations. Laissez-faire, free market ideologies—including classical liberalism, neoliberalism, and libertarianism—are formed around the idea that social inequality is a \"natural\" feature of societies, is therefore inevitable and, in some philosophies, even desirable. Inequality provides for differing goods and services to be offered on the open market, spurs ambition, and provides incentive for industriousness and innovation. At the other end of the continuum, collectivists place little to no trust in \"free market\" economic systems, noting widespread lack of access among specific groups or classes of individuals to the costs of entry to the market. Widespread inequalities often lead to conflict and dissatisfaction with the current social order. Such ideologies include Fabianism and socialism. Inequality, in these ideologies, must be reduced, eliminated, or kept under tight control through collective regulation. Furthermore, in some views inequality is natural but shouldn't affect certain fundamental human needs, human rights and the initial chances given to individuals (e.g. by education) and is out of proportions due to various problematic systemic structures.\n\nThough the above discussion is limited to specific Western ideologies, it should be noted that similar thinking can be found, historically, in differing societies throughout the world. While, in general, eastern societies tend toward collectivism, elements of individualism and free market organization can be found in certain regions and historical eras. Classic Chinese society in the Han and Tang dynasties, for example, while highly organized into tight hierarchies of horizontal inequality with a distinct power elite also had many elements of free trade among its various regions and subcultures.\n\nSocial mobility is the movement along social strata or hierarchies by individuals, ethnic group, or nations. There is a change in literacy, income distribution, education and health status. The movement can be vertical or horizontal. Vertical is the upward or downward movement along social strata which occurs due to change of jobs or marriage. Horizontal movement along levels that are equally ranked. Intra-generational mobility is a social status change in a generation (single lifetime). For example, a person moves from a junior staff in an organization to the senior management. The absolute management movement is where a person gains better social status than their parents, and this can be due to improved security, economic development, and better education system. Relative mobility is where some individual are expected to have higher social ranks than their parents.\n\nToday, there is belief held by some that social inequality often creates political conflict and growing consensus that political structures determine the solution for such conflicts. Under this line of thinking, adequately designed social and political institutions are seen as ensuring the smooth functioning of economic markets such that there is political stability, which improves the long-term outlook, enhances labour and capital productivity and so stimulates economic growth. With higher economic growth, net gains are positive across all levels and political reforms are easier to sustain. This may explain why, over time, in more egalitarian societies fiscal performance is better, stimulating greater accumulation of capital and higher growth.\n\nSocioeconomic status (SES) is a combined total measure of a person's work experience and of an individual's or family's economic and social position in relation to others, based on income, education, and occupation. It is often used as synonymous with social class, a set of hierarchical social categories that indicate an individual's or household's relative position in a stratified matrix of social relationships. Social class is delineated by a number of variables, some of which change across time and place. For Karl Marx, there exist two major social classes with significant inequality between the two. The two are delineated by their relationship to the means of production in a given society. Those two classes are defined as the owners of the means of production and those who sell their labour to the owners of the means of production. In capitalistic societies, the two classifications represent the opposing social interests of its members, capital gain for the capitalists and good wages for the labourers, creating social conflict.\n\nMax Weber uses social classes to examine wealth and status. For him, social class is strongly associated with prestige and privileges. It may explain social reproduction, the tendency of social classes to remain stable across generations maintaining most of their inequalities as well. Such inequalities include differences in income, wealth, access to education, pension levels, social status, socioeconomic safety-net. In general, social class can be defined as a large category of similarly ranked people located in a hierarchy and distinguished from other large categories in the hierarchy by such traits as occupation, education, income, and wealth.\n\nIn modern Western societies, inequalities are often broadly classified into three major divisions of social class: upper class, middle class, and lower class. Each of these classes can be further subdivided into smaller classes (e.g. \"upper middle\"). Members of different classes have varied access to financial resources, which affects their placement in the social stratification system.\n\nClass, race, and gender are forms of stratification that bring inequality and determines the difference in allocation of societal rewards. Occupation is the primary determinant of a person class since it affects their lifestyle, opportunities, culture, and kind of people one associates with. Class based families include the lower class who are the poor in the society. They have limited opportunities. Working class are those people in blue-collar jobs and usually, affects the economic level of a nation. The Middle classes are those who rely mostly on wives' employment and depends on credits from the bank and medical coverage. The upper middle class are professionals who are strong because of economic resources and supportive institutions. Additionally, the upper class usually are the wealthy families who have economic power due to accumulative wealth from families but not and not hard earned income.\n\nSocial stratification is the hierarchical arrangement of society about social class, wealth, political influence. A society can be politically stratified based on authority and power, economically stratified based on income level and wealth, occupational stratification about one's occupation. Some roles for examples doctors, engineers, lawyers are highly ranked, and thus they give orders while the rest receive the orders. There are three systems of social stratification which are the caste system, estates system, and class system. Castes system usually ascribed to children during birth whereby one receives the same stratification as of that of their parents. The caste system has been linked to religion and thus permanent. The stratification may be superior or inferior and thus influences the occupation and the social roles assigned to a person. Estate system is a state or society where people in this state were required to work on their land to receive some services like military protection. Communities ranked according to the nobility of their lords. The class system is about income inequality and socio-political status. People can move the classes when they increase their level of income or if they have authority. People are expected to maximize their innate abilities and possessions. Social stratification characteristics include its universal, social, ancient, it’s in diverse forms and also consequential.\n\nThe quantitative variables most often used as an indicator of social inequality are income and wealth. In a given society, the distribution of individual or household accumulation of wealth tells us more about variation in well-being than does income, alone. Gross Domestic Product (GDP), especially \"per capita\" GDP, is sometimes used to describe economic inequality at the international or global level. A better measure at that level, however, is the Gini coefficient, a measure of statistical dispersion used to represent the distribution of a specific quantity, such as income or wealth, at a global level, among a nation's residents, or even within a metropolitan area. Other widely used measures of economic inequality are the percentage of people living with under US$1.25 or $2 a day and the share of national income held by the wealthiest 10% of the population, sometimes called \"the Palma\" measure.\n\nThere are a number of socially defined characteristics of individuals that contribute to social status and, therefore, equality or inequality within a society. When researchers use quantitative variables such as income or wealth to measure inequality, on an examination of the data, patterns are found that indicate these other social variables contribute to income or wealth as intervening variables. Significant inequalities in income and wealth are found when specific socially defined categories of people are compared. Among the most pervasive of these variables are sex/gender, race, and ethnicity. This is not to say, in societies wherein merit is considered to be the primary factor determining one's place or rank in the social order, that merit has no effect on variations in income or wealth. It is to say that these other socially defined characteristics can, and often do, intervene in the valuation of merit.\n\nGender as a social inequality is whereby women and men are treated differently due to masculinity and femininity by dividing labor, assigning roles, and responsibilities and allocating social rewards. Sex- and gender-based prejudice and discrimination, called sexism, are major contributing factors to social inequality. Most societies, even agricultural ones, have some sexual division of labour and gender-based division of labour tends to increase during industrialization. The emphasis on gender inequality is born out of the deepening division in the roles assigned to men and women, particularly in the economic, political and educational spheres. Women are underrepresented in political activities and decision making processes in most states in both the Global North and Global South.\n\nGender discrimination, especially concerning the lower social status of women, has been a topic of serious discussion not only within academic and activist communities but also by governmental agencies and international bodies such as the United Nations. These discussions seek to identify and remedy widespread, institutionalized barriers to access for women in their societies. By making use of gender analysis, researchers try to understand the social expectations, responsibilities, resources and priorities of women and men within a specific context, examining the social, economic and environmental factors which influence their roles and decision-making capacity. By enforcing artificial separations between the social and economic roles of men and women, the lives of women and girls are negatively impacted and this can have the effect of limiting social and economic development.\n\nCultural ideals about women's work can also affect men whose outward gender expression is considered \"feminine\" within a given society. Transgender and gender-variant persons may express their gender through their appearance, the statements they make, or official documents they present. In this context, gender normativity, which is understood as the social expectations placed on us when we present particular bodies, produces widespread cultural/institutional devaluations of trans identities, homosexuality and femininity. Trans persons, in particular, have been defined as socially unproductive and disruptive.\n\nA variety of global issues like HIV/AIDS, illiteracy, and poverty are often seen as \"women's issues\" since women are disproportionately affected. In many countries, women and girls face problems such as lack of access to education, which limit their opportunities to succeed, and further limits their ability to contribute economically to their society. Women are underrepresented in political activities and decision making processes throughout most of the world. As of 2007, around 20 percent of women were below the $1.25/day international poverty line and 40 percent below the $2/day mark. More than one-quarter of females under the age of 25 were below the $1.25/day international poverty line and about half on less than $2/day.\n\nWomen's participation in work has been increasing globally, but women are still faced with wage discrepancies and differences compared to what men earn. This is true globally even in the agricultural and rural sector in developed as well as developing countries. Structural impediments to women's ability to pursue and advance in their chosen professions often result in a phenomenon known as the glass ceiling, which refers to unseen - and often unacknowledged barriers that prevent minorities and women from rising to the upper rungs of the corporate ladder, regardless of their qualifications or achievements. This effect can be seen in the corporate and bureaucratic environments of many countries, lowering the chances of women to excel. It prevents women from succeeding and making the maximum use of their potential, which is at a cost for women as well as the society's development. Ensuring that women's rights are protected and endorsed can promote a sense of belonging that motivates women to contribute to their society. Once able to work, women should be titled to the same job security and safe working environments as men. Until such safeguards are in place, women and girls will continue to experience not only barriers to work and opportunities to earn, but will continue to be the primary victims of discrimination, oppression, and gender-based violence.\n\nWomen and persons whose gender identity does not conform to patriarchal beliefs about sex (only male and female) continue to face violence on global domestic, interpersonal, institutional and administrative scales. While first-wave Liberal Feminist initiatives raised awareness about the lack of fundamental rights and freedoms that women have access to, second-wave feminism (see also Radical Feminism) highlighted the structural forces that underlie gender-based violence. Masculinities are generally constructed so as to subordinate femininities and other expressions of gender that are not heterosexual, assertive and dominant. \nGender sociologist and author, Raewyn Connell, discusses in her 2009 book, Gender, how masculinity is dangerous, heterosexual, violent and authoritative. These structures of masculinity ultimately contribute to the vast amounts of gendered violence, marginalization and suppression that women, queer, transgender, gender variant and gender non-conforming persons face. \nSome scholars suggest that women's underrepresentation in political systems speaks the idea that \"formal citizenship does not always imply full social membership\". Men, male bodies and expressions of masculinity are linked to ideas about work and citizenship. Others point out that patriarchal states tend top scale and claw back their social policies relative to the disadvantage of women. This process ensures that women encounter resistance into meaningful positions of power in institutions, administrations, and political systems and communities.\n\nRacial or ethnic inequality is the result of hierarchical social distinctions between racial and ethnic categories within a society and often established based on characteristics such as skin color and other physical characteristics or an individual's place of origin or culture. Racism is whereby some races are more privileged and are allowed to venture into the labor market and are better compensated than others. Ethnicity is the privilege one enjoys for belonging to a particular ethnic group. Even though race has no biological connection, it has become a socially constructed category capable of restricting or enabling social status.\n\nRacial inequality can also result in diminished opportunities for members of marginalized groups, which in turn can lead to cycles of poverty and political marginalization. Racial and ethnic categories become a minority category in a society. Minority members in such a society are often subjected to discriminatory actions resulting from majority policies, including assimilation, exclusion, oppression, expulsion, and extermination. For example, during the run-up to the 2012 federal elections in the United States, legislation in certain \"battleground states\" that claimed to target voter fraud had the effect of disenfranchising tens of thousands of primarily African American voters. These types of institutional barriers to full and equal social participation have far-reaching effects within marginalized communities, including reduced economic opportunity and output, reduced educational outcomes and opportunities and reduced levels of overall health.\n\nIn the United States, Angela Davis argues that mass incarceration has been a modern tool of the state to impose inequality, repression, and discrimination upon African American and Hispanics. The War on Drugs has been a campaign with disparate effects, ensuring the constant incarceration of poor, vulnerable, and marginalized populations in North America. Over a million African Americans are incarcerated in the US, many of whom have been convicted of a non-violent drug possession charge. With the States of Colorado and Washington having legalized the possession of marijuana, drug reformists and anti-war on drugs lobbyists are hopeful that drug issues will be interpreted and dealt with from a healthcare perspective instead of a matter of criminal law. In Canada, Aboriginal, First Nations, and Indigenous persons represent over a quarter of the federal prison population, even though they only represent 3% of the country's population.\n\nAge discrimination is defined as the unfair treatment of people with regard to promotions, recruitment, resources, or privileges because of their age. It is also known as ageism: the stereotyping of and discrimination against individuals or groups based upon their age. It is a set of beliefs, attitudes, norms, and values used to justify age-based prejudice, discrimination, and subordination. One form of ageism is adultism, which is the discrimination against children and people under the legal adult age. An example of an act of adultism might be the policy of a certain establishment, restaurant, or place of business to not allow those under the legal adult age to enter their premises after a certain time or at all. While some people may benefit or enjoy these practices, some find them offensive and discriminatory. Discrimination against those under the age of 40 however is not illegal under the current U.S. Age Discrimination in Employment Act (ADEA).\n\nAs implied in the definitions above, treating people differently based upon their age is not necessarily discrimination. Virtually every society has age-stratification, meaning that the age structure in a society changes as people begin to live longer and the population becomes older. In most cultures, there are different social role expectations for people of different ages to perform. Every society manages people's ageing by allocating certain roles for different age groups. Age discrimination primarily occurs when age is used as an unfair criterion for allocating more or less resources. Scholars of age inequality have suggested that certain social organizations favor particular age inequalities. For instance, because of their emphasis on training and maintaining productive citizens, modern capitalist societies may dedicate disproportionate resources to training the young and maintaining the middle-aged worker to the detriment of the elderly and the retired (especially those already disadvantaged by income/wealth inequality).\n\nIn modern, technologically advanced societies, there is a tendency for both the young and the old to be relatively disadvantaged. However, more recently, in the United States the tendency is for the young to be most disadvantaged. For example, poverty levels in the U.S. have been decreasing among people aged 65 and older since the early 1970s whereas the number children under 18 in poverty has steadily risen. Sometimes, the elderly have had the opportunity to build their wealth throughout their lives, younger people have the disadvantage of recently entering into or having not yet entered into the economic sphere. The larger contributor to this, however is the increase in the number of people over 65 receiving Social Security and Medicare benefits in the U.S.\n\nWhen we compare income distribution among youth across the globe, we find that about half (48.5 percent) of the world's young people are confined to the bottom two income brackets as of 2007. This means that, out of the three billion persons under the age of 24 in the world as of 2007, approximately 1.5 billion were living in situations in which they and their families had access to just nine percent of global income. Moving up the income distribution ladder, children and youth do not fare much better: more than two-thirds of the world's youth have access to less than 20 percent of global wealth, with 86 percent of all young people living on about one-third of world income. For the just over 400 million youth who are fortunate enough to rank among families or situations at the top of the income distribution, however, opportunities improve greatly with more than 60 percent of global income within their reach.\n\nAlthough this does not exhaust the scope of age discrimination, in modern societies it is often discussed primarily with regards to the work environment. Indeed, non-participation in the labour force and the unequal access to rewarding jobs means that the elderly and the young are often subject to unfair disadvantages because of their age. On the one hand, the elderly are less likely to be involved in the workforce: At the same time, old age may or may not put one at a disadvantage in accessing positions of prestige. Old age may benefit one in such positions, but it may also disadvantage one because of negative ageist stereotyping of old people. On the other hand, young people are often disadvantaged from accessing prestigious or relatively rewarding jobs, because of their recent entry to the work force or because they are still completing their education. Typically, once they enter the labour force or take a part-time job while in school, they start at entry level positions with low level wages. Furthermore, because of their lack of prior work experience, they can also often be forced to take marginal jobs, where they can be taken advantage of by their employers. As a result, many older people have to face obstacles in their lives.\n\nHealth inequalities can be defined as differences in health status or in the distribution of health determinants between different population groups.\n\nHealth inequalities are in many cases related to access to health care. In industrialized nations, health inequalities are most prevalent in countries that have not implemented a universal health care system, such as the United States. Because the US health care system is heavily privatized, access to health care is dependent upon one's economic capital; Health care is not a right, it is a commodity that can be purchased through private insurance companies (or that is sometimes provided through an employer). The way health care is organized in the U.S. contributes to health inequalities based on gender, socioeconomic status and race/ethnicity. As Wright and Perry assert, \"social status differences in health care are a primary mechanism of health inequalities\". In the United States, over 48 million people are without medical care coverage. This means that almost one sixth of the population is without health insurance, mostly people belonging to the lower classes of society.\n\nWhile universal access to health care may not completely eliminate health inequalities, it has been shown that it greatly reduces them. In this context, privatization gives individuals the 'power' to purchase their own health care (through private health insurance companies), but this leads to social inequality by only allowing people who have economic resources to access health care. Citizens are seen as consumers who have a 'choice' to buy the best health care they can afford; in alignment with neoliberal ideology, this puts the burden on the individual rather than the government or the community.\n\nIn countries that have a universal health care system, health inequalities have been reduced. In Canada, for example, equity in the availability of health services has been improved dramatically through Medicare. People don't have to worry about how they will pay health care, or rely on emergency rooms for care, since health care is provided for the entire population. However, inequality issues still remain. For example, not everyone has the same level of access to services. Inequalities in health are not, however, only related to access to health care. Even if everyone had the same level of access, inequalities may still remain. This is because health status is a product of more than just how much medical care people have available to them. While Medicare has equalized access to health care by removing the need for direct payments at the time of services, which improved the health of low status people, inequities in health are still prevalent in Canada. This may be due to the state of the current social system, which bear other types of inequalities such as economic, racial and gender inequality.\n\nA lack of health equity is also evident in the developing world, where the importance of equitable access to healthcare has been cited as crucial to achieving many of the Millennium Development Goals. Health inequalities can vary greatly depending on the country one is looking at. Health equity is needed in order to live a healthier and more sufficient life within society. Inequalities in health lead to substantial effects, that is burdensome or the entire society. Inequalities in health are often associated with socioeconomic status and access to health care. Health inequities can occur when the distribution of public health services is unequal. For example, in Indonesia in 1990, only 12% of government spending for health was for services consumed by the poorest 20% of households, while the wealthiest 20% consumed 29% of the government subsidy in the health sector. Access to health care is heavily influenced by socioeconomic status as well, as wealthier population groups have a higher probability of obtaining care when they need it. A study by Makinen et al. (2000) found that in the majority of developing countries they looked at, there was an upward trend by quintile in health care use for those reporting illness. Wealthier groups are also more likely to be seen by doctors and to receive medicine.\n\nThere has been considerable research in recent years regarding a phenomenon known as food deserts, in which low access to fresh, healthy food in a neighborhood leads to poor consumer choices and options regarding diet. It is widely thought that food deserts are significant contributors to the childhood obesity epidemic in the United States and many other countries.\n\nThe economies of the world have developed unevenly, historically, such that entire geographical regions were left mired in poverty and disease while others began to reduce poverty and disease on a wholesale basis. This was represented by a type of North–South divide that existed after World War II between First world, more developed, industrialized, wealthy countries and Third world countries, primarily as measured by GDP. From around 1980, however, through at least 2011, the GDP gap, while still wide, appeared to be closing and, in some more rapidly developing countries, life expectancies began to rise. However, there are numerous limitations of GDP as an economic indicator of social \"well-being.\"\n\nIf we look at the Gini coefficient for world income, over time, after World War II the global Gini coefficient sat at just under .45. Between around 1959 to 1966, the global Gini increased sharply, to a peak of around .48 in 1966. After falling and leveling off a couple of times during a period from around 1967 to 1984, the Gini began to climb again in the mid-eighties until reaching a high or around .54 in 2000 then jumped again to around .70 in 2002. Since the late 1980s, the gap between some regions has markedly narrowed— between Asia and the advanced economies of the West, for example—but huge gaps remain globally. Overall equality across humanity, considered as individuals, has improved very little. Within the decade between 2003 and 2013, income inequality grew even in traditionally egalitarian countries like Germany, Sweden and Denmark. With a few exceptions—France, Japan, Spain—the top 10 percent of earners in most advanced economies raced ahead, while the bottom 10 percent fell further behind. By 2013, a tiny elite of multibillionaires, 85 to be exact, had amassed wealth equivalent to all the wealth owned by the poorest half (3.5 billion) of the world's total population of 7 billion. Country of citizenship (an ascribed status characteristic) explains 60% of variability in global income; citizenship and parental income class (both ascribed status characteristics) combined explain more than 80% of income variability.\n\nThe concept of economic growth is fundamental in capitalist economies. Productivity must grow as population grows and capital must grow to feed into increased productivity. Investment of capital leads to returns on investment (ROI) and increased capital accumulation. The hypothesis that economic inequality is a necessary precondition for economic growth has been a mainstay of liberal economic theory. Recent research, particularly over the first two decades of the 21st century, has called this basic assumption into question. While growing inequality does have a positive correlation with economic growth under specific sets of conditions, inequality in general is not positively correlated with economic growth and, under some conditions, shows a negative correlation with economic growth.\n\nMilanovic (2011) points out that overall, global inequality between countries is more important to growth of the world economy than inequality within countries. While global economic growth may be a policy priority, recent evidence about regional and national inequalities cannot be dismissed when more local economic growth is a policy objective. The recent financial crisis and global recession hit countries and shook financial systems all over the world. This led to the implementation of large-scale fiscal expansionary interventions and, as a result, to massive public debt issuance in some countries. Governmental bailouts of the banking system further burdened fiscal balances and raises considerable concern about the fiscal solvency of some countries. Most governments want to keep deficits under control but rolling back the expansionary measures or cutting spending and raising taxes implies an enormous wealth transfer from tax payers to the private financial sector. Expansionary fiscal policies shift resources and causes worries about growing inequality within countries. Moreover, recent data confirm an ongoing trend of increasing income inequality since the early nineties. Increasing inequality within countries has been accompanied by a redistribution of economic resources between developed economies and emerging markets. Davtyn, et al. (2014) studied the interaction of these fiscal conditions and changes in fiscal and economic policies with income inequality in the UK, Canada, and the US. They find income inequality has negative effect on economic growth in the case of the UK but a positive effect in the cases of the US and Canada. Income inequality generally reduces government net lending/borrowing for all the countries. Economic growth, they find, leads to an increase of income inequality in the case of the UK and to the decline of inequality in the cases of the US and Canada. At the same time, economic growth improves government net lending/borrowing in all the countries. Government spending leads to the decline in inequality in the UK but to its increase in the US and Canada.\n\nFollowing the results of Alesina and Rodrick (1994), Bourguignon (2004), and Birdsall (2005) show that developing countries with high inequality tend to grow more slowly, Ortiz and Cummings (2011) show that developing countries with high inequality tend to grow more slowly. For 131 countries for which they could estimate the change in Gini index values between 1990 and 2008, they find that those countries that increased levels of inequality experienced slower annual per capita GDP growth over the same time period. Noting a lack of data for national wealth, they build an index using \"Forbes\" list of billionaires by country normalized by GDP and validated through correlation with a Gini coefficient for wealth and the share of wealth going to the top decile. They find that many countries generating low rates of economic growth are also characterized by a high level of wealth inequality with wealth concentration among a class of entrenched elites. They conclude that extreme inequality in the distribution of wealth globally, regionally and nationally, coupled with the negative effects of higher levels of income disparities, should make us question current economic development approaches and examine the need to place equity at the center of the development agenda.\n\nOstry, et al. (2014) reject the hypothesis that there is a major trade-off between a reduction of income inequality (through income redistribution) and economic growth. If that were the case, they hold, then redistribution that reduces income inequality would on average be bad for growth, taking into account both the direct effect of higher redistribution and the effect of the resulting lower inequality. Their research shows rather the opposite: increasing income inequality always has a significant and, in most cases, negative effect on economic growth while redistribution has an overall pro-growth effect (in one sample) or no growth effect. Their conclusion is that increasing inequality, particularly when inequality is already high, results in low growth, if any, and such growth may be unsustainable over long periods.\n\nPiketty and Saez (2014) note that there are important differences between income and wealth inequality dynamics. First, wealth concentration is always much higher than income concentration. The top 10 percent of wealth share typically falls in the 60 to 90 percent range of all wealth, whereas the top 10 percent income share is in the 30 to 50 percent range. The bottom 50 percent wealth share is always less than 5 percent, whereas the bottom 50 percent income share generally falls in the 20 to 30 percent range. The bottom half of the population hardly owns any wealth, but it does earn appreciable income:The inequality of labor income can be high, but it is usually much less extreme. On average, members of the bottom half of the population, in terms of wealth, own less than one-tenth of the average wealth. The inequality of labor income can be high, but it is usually much less extreme. Members of the bottom half of the population in income earn about half the average income. In sum, the concentration of capital ownership is always extreme, so that the very notion of capital is fairly abstract for large segments—if not the majority—of the population. Piketty (2014) finds that wealth-income ratios, today, seem to be returning to very high levels in low economic growth countries, similar to what he calls the \"classic patrimonial\" wealth-based societies of the 19th century wherein a minority lives off its wealth while the rest of the population works for subsistence living. He surmises that wealth accumulation is high because growth is low.\n\n\n"}
{"id": "28000414", "url": "https://en.wikipedia.org/wiki?curid=28000414", "title": "Temporal power", "text": "Temporal power\n\nTemporal power is a term of art in medieval and early modern political philosophy to refer to worldly power, as contrasted with spiritual power.\n\n\nState and Church\n"}
{"id": "46695691", "url": "https://en.wikipedia.org/wiki?curid=46695691", "title": "The Prime Minister's Ironing Board and Other State Secrets", "text": "The Prime Minister's Ironing Board and Other State Secrets\n\nThe Prime Minister's Ironing Board and other State Secrets is a 2013 book by Adam Macqueen, produced with the assistance of the National Archives of the United Kingdom\n\nThe book reveals numerous notes, letters and other documents stamped 'secret' and filed away over the years. From concerned notes on Prince Charles' potential brainwashing by Welsh nationalist terrorists to worries about housemaids 'on the wobble' at Chequers, the book reveals serious matters to comical details of life in the corridors of power. \n\nIn \"The Guardian\" Peter Preston described the book as 'the perfect bedside book...irresistibly, we're invited to look back and laugh' while in \"The Financial Times\" Charlotte McCann praised the book as 'delightfully gossipy' and noted that the author 'offers vignettes of British political life from the whimsical to the downright chilling'.\n\nIn \"The Daily Mail\" the book was described as 'hilarious and troubling' and was also judged a \"Daily Telegraph\" Book of the Year\n"}
{"id": "9759806", "url": "https://en.wikipedia.org/wiki?curid=9759806", "title": "Trevor Lee (architect)", "text": "Trevor Lee (architect)\n\nTrevor Lee is an Australian architect who has directed himself to energy issues in the built environment since his graduation with honours from the University of Melbourne in 1976. From 1985 to 1989, he was the \"Senior Architect for Energy Management\" of Australia's Department of Construction. From 1989 until 1995 he served as editor of \"Solar Progress\", the quarterly journal of the Australian and New Zealand Solar Energy Society, (ANZSES), and from 1996 to 1998 was honorary chair of that organisation.\n\nLee was also a founding Director and later Vice-President of the Sustainable Energy Industry Association which merged with kindred organisations in 2001 to become the Business Council For Sustainable Energy. From 1991 to 2003, he has also served as an executive Director of Australian Ethical Investment Ltd, manager of unit trust and superannuation funds now totalling over $400 million. Lee has been associated with Energy Strategies through their joint firm Energy Partners since 1990.\n\nTrevor Lee is also co-author of the \"Australian Solar Radiation Data Handbook\", which was fully revised in 2005.\n\n\n"}
{"id": "4396462", "url": "https://en.wikipedia.org/wiki?curid=4396462", "title": "Tripartite Consultation (International Labour Standards) Convention, 1976", "text": "Tripartite Consultation (International Labour Standards) Convention, 1976\n\nThe Tripartite Consultation (International Labour Standards) Convention, 1976, officially the Convention concerning tripartite consultations to promote the implementation of international labour standards is an International Labour Organization Convention, which governs the process for implementation of measures regarding ILO conferences. It requires tripartite consultation before ratification, implementing legislation or denouncement of conventions. As of June 2015, the convention had been ratified by 139 member states. The convention is also known as convention number 144 on the List of International Labour Organization Conventions.\n"}
{"id": "50066201", "url": "https://en.wikipedia.org/wiki?curid=50066201", "title": "Women's fear of crime", "text": "Women's fear of crime\n\nWomen's fear of crime refers to women's fear of being a victim of crime, independent of actual victimization. Although fear of crime is a concern for people of all genders, studies consistently find that women around the world tend to have much higher levels of fear of crime than men, despite the fact that in many places, and for most offenses, men's actual victimization rates are higher. Fear of crime is related to perceived risk of victimization, but is not the same; fear of crime may be generalized instead of referring to specific offenses, and perceived risk may also be considered a demographic factor that contributes to fear of crime. Women tend to have higher levels for both perceived risk and fear of crime.\n\nIn women's everyday lives, fear of crime can have negative effects, such as reducing their environmental mobility. Studies have shown that women tend to avoid certain behaviors, such as walking alone at night, because they are fearful of crime, and would feel more comfortable with these behaviors if they felt safer.\n\nSocial scientists have differing views on the causes of women's fear of crime. Some have argued that women's heightened fear of crime is due to women's higher levels physical vulnerability compared to men, although feminist work generally resists this generalization and often tries to relocate the cause to larger societal factors. It is nonetheless important that most women are aware of pervasive cultural view that women are more vulnerable than men, which may make them think they are more likely to be victimized and therefore contribute to their fear; in this way, it would be perceived vulnerability and not actual vulnerability that is the cause of women's fear. Some research has also suggested that women are in fact not much more fearful about crime than men, but that dominant cultural ideas about masculinity may make men reluctant to talk about their fear or report it in surveys.\n\nFeminist discourse on fear of crime tends to explain women's higher levels of fear with the unequal gender structure in most societies, which places women beneath men within the power structure and thus puts them especially at risk for victimization by men. This theory refers to the oppressive social control of women, arguing that some crimes against women (such as rape) and the socialization that women receive to feel vulnerable and fear male violence are used by the patriarchy to assert male dominance and \"keep women in their place.\"\n\nAs rape is by far the most gendered crime by victimization, some feminist scholars have suggested that fear of rape is the most important and most unique element of women's fear of crime, or even that women's fear of crime is in fact a generalized fear of rape. Proponents of this theory, often referred to as the \"shadow of sexual assault hypothesis,\" often note that women tend to fear that rape will co-occur with other crimes, such as burglary, a fear that is not found among men. Some supporters of the theory also note that sexual harassment, which most women will experience in their lifetimes, especially contributes to the fear of rape; in some cases, women's rejection of unwanted sexual advances leads to threats, and even \"benevolent\" harassment may increase women's wariness and fear of men in public spaces.\n\nThe fear of rape, unlike other fears of specific crimes, is almost exclusive to women. Among women, it is also one of the strongest crime-related fears, and is the strongest crime-related fear for young women. Levels of fear of rape vary among women by age, race/ethnicity, residential area, and other factors, but are especially high for women who have been victims of rape in the past or know victims personally (the latter group may include a significant portion of women, with one study estimating that over half of women know rape victims). The fear of rape may also be related to the fear of murder, as women tend to overestimate the proportion of rape victims who are murdered during their attacks. Stigma and blame are also factors: what many feminists refer to as the \"rape myth,\" the popular idea that women can be blamed for their rape and that women are responsible for preventing rape by the regulation of their behavior, often serves to support the fear of rape.\n\nAlthough women as a whole demographic are more fearful of crime, specific subgroups of women may have higher levels of fear or be more likely to change their behavior because of it. In many studies, the demographics found to have the highest generalized fear of crime are single, older, urban, women of color, and of lower socioeconomic class. For fear of victimization for specific crimes, the demographics with the highest levels of fear may be different.\n\nGenerally, research has demonstrated that women from urban areas have higher levels of fear of crime. Even within cities, fear levels may differ from neighborhood to neighborhood. Increased social disorganization in the neighborhood (as measured by homelessness, drug sales, vandalism, prostitution, etc.) and higher rates of neighborhood serious crime lead to higher levels of fear of crime for both men and women, but both factors have a stronger effect on women's fear of crime.\n\nUrban and rural communities tend to have very different levels of fear of crime. Rural areas are almost always perceived by residents and outsiders as safer, so it is often assumed that fear of crime levels will be lower there. Still, 2005 research in New Zealand and the United Kingdom noted that fear of crime levels in rural areas is on the rise, and found that sources of fear of crime among rural women often include perceived encroachment of urban influence (through people or attitudes) into their communities.\n\nTheorists have suggested that Black and Latina women, and women of color in general, in the United States may have higher rates of fear of crime due to increased social vulnerability; because of institutional racism and sexism against women of color, their identities may put them at greater risk of victimization, leading to higher levels of fear.\n\nIn general, proposed solutions to women's fear of crime either place the responsibility on individual women (through preventive strategies) or on official agencies (through infrastructure improvements, anti-rape education, more involved policing, etc.), and are often framed as a combination of both. Of those that expect women to protect themselves from crime, most focus on the dangers for women in public spaces; however, as women usually face their highest rates of victimization in the home or at the hands of known people, these campaigns have been suggested to be particularly ill-equipped to help solve the problem of women's high fear of crime, and to support an untrue picture of women's victimization.\n\nOne of the most common individual strategies for dealing with fear of crime and preventing victimization is simple avoidance, the attempt to stay away from areas (such as dark alleys or public transportation) where it is believed victimization is likely to occur; research has found that women employ avoidance strategies more often than men do. Avoided areas may include neighborhoods with high crime rates, but for many women also include any unfamiliar areas. Women may also employ other isolation strategies by avoiding social interaction with strangers, ignoring them or moving quickly and with purpose to discourage interaction\n\nAnother common method of allaying fear of crime among women is by \"crime-proofing\" homes or possessions. Popular examples include home security systems, locking away valuables, or participating in neighborhood watch programs. These strategies are used by people of all genders, but some are more often employed by women. For example, many women in an American study reported choosing purses with zippers or holding purses protectively to defend against theft and purse-snatching.\n\nAs interest in women's safety and women's fear of crime has increased, so has interest in precautionary strategies; for example, in the past few decades, women's self-defense classes, books, and other self-defense instruction have become increasingly popular. Some women also choose to carry weapons, such as knives or guns, or repellents like pepper spray and Mace to ward off potential attackers.\n\nFeminist commentators usually take the view that the responsibility for reducing women's fear of crime lies with the society, and that fear must be combatted at its source by addressing men's violence against women.\n\nAlthough most research on women's fear of crime has been done in English-speaking countries, with the most done in the United States, similar trends in women's fear of crime have been found around the world.\n\nA 2014 study using data from 20 countries in Sub-Saharan Africa concluded that fear of crime has a stronger negative effect on women's subjective well-being compared to men's, with subjective wellbeing defined as self-reported satisfaction with life. In the study, fear of crime had a statistically significant correlation with subjective wellbeing for females, but no significant correlation for males, suggesting that for the men in the study, fear of crime was not an important factor in determining their happiness and life satisfaction.\n\nA 2013 study of Hong Kong social work students found significant gender differences in fear of crime levels. Consistent with the shadow of sexual assault hypothesis, the study found that the women had the highest levels of fear for rape, and that fear of rape was a predictor for fear of other crimes. Hong Kong has one of the lowest rates of crime and victimization in the world, so this study may suggest that the presence and size of gender differences in fear of crime are not strongly correlated with total crime and victimization rates.\n\nA 1998 study in Glasgow, Scotland, found a gender disparity in fear of crime levels smaller than what is generally accepted. The study also found that men and women with similar fear levels tended to use similar reasoning to explain their fear of crime or lack of fear, although men's and women's fear appeared in different situations (men tended to be more often fearful about property crime, whereas women were more fearful about violent crime).\n\nA 2010 Turkish study using a large nationwide sample confirmed that women expressed significantly higher levels of fear of crime than men. The study also found that previous victimization, a consistent predictor for higher levels of fear in women, was present at close to equal rates in the male and female samples, suggesting that prior victimization has a stronger effect on women's fear of crime than on men's. Also, if the study's sample is representative of the Turkish population, women have slightly higher victimization rates than men, and so their fear does not reflect the \"gender-fear paradox\" of victimization found in many other developed countries.\n"}
{"id": "4044516", "url": "https://en.wikipedia.org/wiki?curid=4044516", "title": "World currency", "text": "World currency\n\nIn the foreign exchange market and international finance, a world currency, supranational currency, or global currency is a currency that is transacted internationally, with no set borders.\n\nIn the 17th and 18th centuries, the use of silver Spanish dollars or \"pieces of eight\" spread from the Spanish territories in the Americas westwards to Asia and eastwards to Europe, forming the first worldwide currency. Spain's political supremacy on the world stage, the importance of Spanish commercial routes across the Atlantic and the Pacific, and the coin's quality and purity of silver helped it become internationally accepted for over two centuries. It was legal tender in Spain's Pacific territories of the Philippines, Micronesia, Guam and the Caroline Islands and later in China and other Southeast Asian countries until the mid-19th century. In the Americas it was legal tender in all of South and Central America (except Brazil) and in the US and Canada until the mid-19th century. In Europe the Spanish dollar was legal tender in the Iberian Peninsula, in most of Italy including: Milan, the Kingdom of Naples, Sicily, Sardinia, the Franche-Comté (France), and in the Spanish Netherlands. It was also used in other European states including the Austrian Habsburg territories.\n\nPrior to and during most of the 19th century, international trade was denominated in terms of currencies that represented weights of gold. Most national currencies at the time were in essence merely different ways of measuring gold weights (much as the yard and the meter both measure length and are related by a constant conversion factor). Hence some assert that gold was the world's first global currency. The emerging collapse of the international gold standard around the time of World War I had significant implications for global trade.\n\nBefore 1944, the world reference currency was the United Kingdom's pound sterling. The transition between pound sterling and United States dollar and its impact for central banks was described recently.\n\nIn the period following the Bretton Woods Conference of 1944, exchange rates around the world were pegged to the United States dollar, which could be exchanged for a fixed amount of gold. This reinforced the dominance of the US dollar as a global currency.\n\nSince the collapse of the fixed exchange rate regime and the gold standard and the institution of floating exchange rates following the Smithsonian Agreement in 1971, most currencies around the world have no longer been pegged to the United States dollar. However, as the United States has the world's largest economy, most international transactions continue to be conducted with the United States dollar, and it has remained the \"de facto\" world currency. According to Robert Gilpin in \"Global Political Economy: Understanding the International Economic Order\" (2001): \"Somewhere between 40 and 60 percent of international financial transactions are denominated in dollars. For decades the dollar has also been the world's principal reserve currency; in 1996, the dollar accounted for approximately two-thirds of the world's foreign exchange reserves\", as compared to about one-quarter held in euros (see Reserve Currency).\n\nSome of the world's currencies are still pegged to the dollar. Some countries, such as Ecuador, El Salvador, and Panama, have gone even further and eliminated their own currency (see dollarization) in favor of the United States dollar.\n\nOnly two serious challengers to the status of the United States dollar as a world currency have arisen. During the 1980s, the Japanese yen became increasingly used as an international currency, but that usage diminished with the Japanese recession in the 1990s. More recently, the euro has increasingly competed with the United States dollar in international finance.\n\nThe euro inherited its status as a major reserve currency from the German mark (DM) and its contribution to official reserves has increased as banks seek to diversify their reserves and trade in the eurozone expands.\n\nAs with the dollar, some of the world's currencies are pegged against the euro. They are usually Eastern European currencies like the Bulgarian lev, plus several west African currencies like the Cape Verdean escudo and the CFA franc. Other European countries, while not being EU members, have adopted the euro due to currency unions with member states, or by unilaterally superseding their own currencies: Andorra, Monaco, Kosovo, Montenegro, San Marino, and Vatican City.\n\n, the euro surpassed the dollar in the combined value of cash in circulation. The value of euro notes in circulation has risen to more than €610 billion, equivalent to US$800 billion at the exchange rates at the time. A 2016 report by the World Trade Organisation shows that the world's energy, food and services trade are made 60% with US dollar and 40% by euro.\n\nAs a result of the rapid internationalization of the renminbi, as of 2013 it was the world's 8th most widely traded currency.\n\nAt the end of November, 2015, the Chinese renminbi was designated as one of the world's global currencies, and became one of the currency in the currency basket known as special drawing rights.\n\nOn 16 March 2009, in connection with the April 2009 G20 summit, the Kremlin called for a supranational reserve currency as part of a reform of the global financial system. In a document containing proposals for the G20 meeting, it suggested that the International Monetary Fund (IMF) (or an Ad Hoc Working Group of G20) should be instructed to carry out specific studies to review the following options:\n\n\nOn 24 March 2009, Zhou Xiaochuan, President of the People's Bank of China, called for \"creative reform of the existing international monetary system towards an international reserve currency,\" believing it would \"significantly reduce the risks of a future crisis and enhance crisis management capability.\" Zhou suggested that the IMF's special drawing rights (a currency basket comprising dollars, euros, renminbi, yen, and sterling) could serve as a super-sovereign reserve currency, not easily influenced by the policies of individual countries. US President Obama, however, rejected the suggestion stating that \"the dollar is extraordinarily strong right now.\"\nAt the G8 summit in July 2009, the Russian president expressed Russia's desire for a new supranational reserve currency by showing off a coin minted with the words \"unity in diversity\". The coin, an example of a future world currency, emphasized his call for creating a mix of regional currencies as a way to address the global financial crisis.\n\nOn 30 March 2009, at the Second South America-Arab League Summit in Qatar, Venezuelan President Hugo Chavez proposed the creation of a petro-currency. It would be backed by the huge oil reserves of the oil producing countries.\n\nAn alternative definition of a world or global currency refers to a hypothetical single global currency or \"supercurrency\", as the proposed terra or the DEY (acronym for Dollar Euro Yen), produced and supported by a central bank which is used for \"all\" transactions around the world, regardless of the nationality of the entities (individuals, corporations, governments, or other organizations) involved in the transaction. No such official currency currently exists.\n\nAdvocates, notably Keynes, of a global currency often argue that such a currency would not suffer from inflation, which, in extreme cases, has had disastrous effects for economies. In addition, many argue that a single global currency would make conducting international business more efficient and would encourage foreign direct investment (FDI).\n\nThere are many different variations of the idea, including a possibility that it would be administered by a global central bank that would define its own monetary standard or that it would be on the gold standard. Supporters often point to the euro as an example of a supranational currency successfully implemented by a union of nations with disparate languages, cultures, and economies.\n\nA limited alternative would be a world reserve currency issued by the International Monetary Fund, as an evolution of the existing special drawing rights and used as reserve assets by all national and regional central banks. On 26 March 2009, a UN panel of expert economists called for a new global currency reserve scheme to replace the current US dollar-based system. The panel's report pointed out that the \"greatly expanded SDR (special drawing rights), with regular or cyclically adjusted emissions calibrated to the size of reserve accumulations, could contribute to global stability, economic strength and global equity.\"\n\nAnother world currency was proposed to use conceptual currency to aid the transaction between countries. The basic idea is to utilize the balance of trade to cancel out the currency actually needed to trade. \n\nIn addition to the idea of a single world currency, some evidence suggests the world may evolve multiple global currencies that exchange on a singular market system. The rise of digital global currencies owned by privately held companies or groups such as Ven suggest that multiple global currencies may offer wider formats for trade as they gain strength and wider acceptance.\n\nBlockchain offers the possibility that a decentralized system that works with little human intervention could eliminate squabbling over who would administer the world central bank.\n\nSome economists argue that a single world currency is unnecessary, because the U.S. dollar is providing many of the benefits of a world currency while avoiding some of the costs. If the world does not form an optimum currency area, then it would be economically inefficient for the world to share one currency.\n\nIn the present world, nations are not able to work together closely enough to be able to produce and support a common currency. There has to be a high level of trust between different countries before a true world currency could be created. A world currency might even undermine national sovereignty of smaller states.\n\nThe interest rate set by the central bank indirectly determines the interest rate customers must pay on their bank loans. This interest rate affects the rate of interest among individuals, investments, and countries. Lending to the poor involves more risk than lending to the rich. As a result of the larger differences in wealth in different areas of the world, a central bank's ability to set interest rate to make the area prosper will be increasingly compromised, since it places wealthiest regions in conflict with the poorest regions in debt.\n\nUsury – the accumulation of interest on loan principal – is prohibited by the texts of some major religions. In Christianity and Judaism, adherents are forbidden to charge interest to other adherents or to the poor (Leviticus 25:35–38; Deuteronomy 23:19). Islam forbids usury, known in Arabic as riba.\n\nSome religious adherents who oppose the paying of interest are currently able to use banking facilities in their countries which regulate interest. An example of this is the Islamic banking system, which is characterized by a nation's central bank setting interest rates for most other transactions.\n\n\n"}
