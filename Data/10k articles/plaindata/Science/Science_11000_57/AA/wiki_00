{"id": "148060", "url": "https://en.wikipedia.org/wiki?curid=148060", "title": "Almagest", "text": "Almagest\n\nThe Almagest () is a 2nd-century Greek-language mathematical and astronomical treatise on the apparent motions of the stars and planetary paths, written by Claudius Ptolemy ( ). One of the most influential scientific texts of all time, its geocentric model was accepted for more than 1200 years from its origin in Hellenistic Alexandria, in the medieval Byzantine and Islamic worlds, and in Western Europe through the Middle Ages and early Renaissance until Copernicus.\n\nThe \"Almagest\" is the critical source of information on ancient Greek astronomy. It has also been valuable to students of mathematics because it documents the ancient Greek mathematician Hipparchus's work, which has been lost. Hipparchus wrote about trigonometry, but because his works appear to have been lost, mathematicians use Ptolemy's book as their source for Hipparchus's work and ancient Greek trigonometry in general.\nPtolemy set up a public inscription at Canopus, Egypt, in 147 or 148. N. T. Hamilton found that the version of Ptolemy's models set out in the \"Canopic Inscription\" was earlier than the version in the \"Almagest\". Hence it cannot have been completed before about 150, a quarter-century after Ptolemy began observing.\n\nThe work was originally titled \"\" (') in Ancient Greek, and also called \"Syntaxis Mathematica\" or \"Almagestum\" in Latin. The treatise was later titled ' (, \"The Great Treatise\"; ), and the superlative form of this (, \"megiste\", \"greatest\") lies behind the Arabic name \"\" (), from which the English name \"Almagest\" derives. The Arabic name is important due to the popularity of a Latin re-translation made in the 12th century from an Arabic translation, which would endure until original Greek copies resurfaced in the 15th century.\n\nThe Arabic form came from Middle Persian \"Magestīg\" (). The Persian name still remains as Nāmagīhā Manōčihr (Letters of Manucher).\n\nThe \"Syntaxis Mathematica\" consists of thirteen sections, called books. As with many medieval manuscripts that were handcopied or, particularly, printed in the early years of printing, there were considerable differences between various editions of the same text, as the process of transcription was highly personal. An example illustrating how the \"Syntaxis\" was organized is given below. It is a Latin edition printed in 1515 at Venice by Petrus Lichtenstein.\n\n\nThe cosmology of the \"Syntaxis\" includes five main points, each of which is the subject of a chapter in Book I. What follows is a close paraphrase of Ptolemy's own words from Toomer's translation.\n\n\nAs mentioned, Ptolemy includes a star catalog containing 1022 stars. He says that he \"observed as many stars as it was possible to perceive, even to the sixth magnitude\", and that the ecliptic longitudes are for the beginning of the reign of Antoninus Pius (138 AD). But calculations show that his ecliptic longitudes correspond more closely to around 58 AD. He states that he found that the longitudes had increased by 2° 40′ since the time of Hipparchos. This is the amount of axial precession that occurred between the time of Hipparchos and 58 AD. It appears therefore that Ptolemy took a star catalog of Hipparchos and simply added 2° 40′ to the longitudes.\n\nMany of the longitudes and latitudes have been corrupted in the various manuscripts. Most of these errors can be explained by similarities in the symbols used for different numbers. For example, the Greek letters Α and Δ were used to mean 1 and 4 respectively, but because these look similar copyists sometimes wrote the wrong one. In Arabic manuscripts, there was confusion between for example 3 and 8 (ج and ح). (At least one translator also introduced errors. Gerard of Cremona, who translated an Arabic manuscript into Latin around 1175, put 300° for the latitude of several stars. He had apparently learned from Moors, who used the letter \"sin\" for 300, but the manuscript he was translating came from the East, where \"sin\" was used for 60.)\n\nEven without the errors introduced by copyists, and even accounting for the fact that the longitudes are more appropriate for 58 AD than for 137 AD, the latitudes and longitudes are not very accurate, with errors of large fractions of a degree. Some errors may be due to atmospheric refraction causing stars that are low in the sky to appear higher than where they really are. A series of stars in Centaurus are off by a couple degrees, including the star we call Alpha Centauri. These were probably measured by a different person or persons from the others, and in an inaccurate way.\n\nPtolemy assigned the following order to the planetary spheres, beginning with the innermost:\n\n\nOther classical writers suggested different sequences. Plato (c. 427 – c. 347 BC) placed the Sun second in order after the Moon. Martianus Capella (5th century AD) put Mercury and Venus in motion around the Sun. Ptolemy's authority was preferred by most medieval Islamic and late medieval European astronomers.\n\nPtolemy inherited from his Greek predecessors a geometrical toolbox and a partial set of models for predicting where the planets would appear in the sky. Apollonius of Perga (c. 262 – c. 190 BC) had introduced the deferent and epicycle and the eccentric deferent to astronomy. Hipparchus (2nd century BC) had crafted mathematical models of the motion of the Sun and Moon. Hipparchus had some knowledge of Mesopotamian astronomy, and he felt that Greek models should match those of the Babylonians in accuracy. He was unable to create accurate models for the remaining five planets.\n\nThe \"Syntaxis\" adopted Hipparchus' solar model, which consisted of a simple eccentric deferent. For the Moon, Ptolemy began with Hipparchus' epicycle-on-deferent, then added a device that historians of astronomy refer to as a \"crank mechanism\": He succeeded in creating models for the other planets, where Hipparchus had failed, by introducing a third device called the equant.\n\nPtolemy wrote the \"Syntaxis\" as a textbook of mathematical astronomy. It explained geometrical models of the planets based on combinations of circles, which could be used to predict the motions of celestial objects. In a later book, the \"Planetary Hypotheses\", Ptolemy explained how to transform his geometrical models into three-dimensional spheres or partial spheres. In contrast to the mathematical \"Syntaxis\", the \"Planetary Hypotheses\" is sometimes described as a book of cosmology.\n\nPtolemy's comprehensive treatise of mathematical astronomy superseded most older texts of Greek astronomy. Some were more specialized and thus of less interest; others simply became outdated by the newer models. As a result, the older texts ceased to be copied and were gradually lost. Much of what we know about the work of astronomers like Hipparchus comes from references in the \"Syntaxis\".\nThe first translations into Arabic were made in the 9th century, with two separate efforts, one sponsored by the caliph Al-Ma'mun. Sahl ibn Bishr is thought to be the first Arabic translator. By this time, the \"Syntaxis\" was lost in Western Europe, or only dimly remembered. Henry Aristippus made the first Latin translation directly from a Greek copy, but it was not as influential as a later translation into Latin made by Gerard of Cremona from the Arabic (finished in 1175). Gerard translated the Arabic text while working at the Toledo School of Translators, although he was unable to translate many technical terms such as the Arabic \"Abrachir\" for Hipparchus. In the 12th century a Spanish version was produced, which was later translated under the patronage of Alfonso X.\nIn the 15th century, a Greek version appeared in Western Europe. The German astronomer Johannes Müller (known, from his birthplace of Königsberg, as Regiomontanus) made an abridged Latin version at the instigation of the Greek churchman Johannes, Cardinal Bessarion. Around the same time, George of Trebizond made a full translation accompanied by a commentary that was as long as the original text. George's translation, done under the patronage of Pope Nicholas V, was intended to supplant the old translation. The new translation was a great improvement; the new commentary was not, and aroused criticism. The Pope declined the dedication of George's work, and Regiomontanus's translation had the upper hand for over 100 years.\n\nDuring the 16th century, Guillaume Postel, who had been on an embassy to the Ottoman Empire, brought back Arabic disputations of the \"Almagest\", such as the works of al-Kharaqī, \"Muntahā al-idrāk fī taqāsīm al-aflāk\" (\"The Ultimate Grasp of the Divisions of Spheres\", 1138/9).\n\nCommentaries on the \"Syntaxis\" were written by Theon of Alexandria (extant), Pappus of Alexandria (only fragments survive), and Ammonius Hermiae (lost).\n\nThe \"Almagest\" was edited by J. L. Heiberg in \"Claudii Ptolemaei opera quae exstant omnia\", vols. 1.1 and 1.2 (1898, 1903).\n\nThree translations of the \"Almagest\" into English have been published. The first, by R. Catesby Taliaferro of St. John's College in Annapolis, Maryland, was included in volume 16 of the \"Great Books of the Western World\" in 1952. The second, by G. J. Toomer, \"Ptolemy's Almagest\" in 1984, with a second edition in 1998. The third was a partial translation by Bruce M. Perry in \"The Almagest: Introduction to the Mathematics of the Heavens\" in 2014.\n\nA direct French translation from the Greek text was published in two volumes in 1813 and 1816 by Nicholas Halma, including detailed historical comments in a 69-page preface. The scanned books are available in full at the \"Gallica\" French national library.\n\n\n\n"}
{"id": "7396781", "url": "https://en.wikipedia.org/wiki?curid=7396781", "title": "Apolista", "text": "Apolista\n\nApolista is a native South American nation of western Bolivia. Sedentary farmers, hunters, gatherers and fishers, they spoke an Arawakan languages now gravely endangered, if not extinct. From 1713, they were gathered at a variety of missions with other nations, and rapidly lost their traditional culture to the point that a realistic census count is no longer possible.\n\nThis was taken from ‘Peoples, Nations and Cultures’ by Professor John Mackenzie\n"}
{"id": "55441516", "url": "https://en.wikipedia.org/wiki?curid=55441516", "title": "Australian Grains Genebank", "text": "Australian Grains Genebank\n\nThe Australian Grains Genebank (AGG) is a national center for storing genetic material for plant breeding and research. The Genebank is in a collaboration with the Australian Seed Bank Partnership on an Australian Crop Wild Relatives project. It is located at Grains Innovation Park, in Horsham, Victoria, Australia.\n\nThe Australian Grains Genebank (AGG) aims to collect and conserve the seeds of Australian crop wild species, that are not yet adequately represented in existing collections. 40 key species of crop wild, 32 of which are endemic to Australia, have been identified as being crucial to increasing Australia's stock of grain crops. Seeds of crop wild relatives (CWR) will be available to plant breeders and researchers in order to develop the plant varieties of the future. The seeds will be stored not only in the Australian Grains Genebank but also in the Australian Seed Bank Partnership member seed banks.:\nThis project will enable research into new plant varieties, that are vital to Australia's agricultural future. Progress can be made in understanding the genetic material contained in the crops.\n\nOne of the main objectives of the Australian Grains Genebank is helping the research; for this reason, this institution distributes about 25,000 packets of seeds to scientists in Australia and overseas. Therefore, they can evaluate this material for characteristics that could be used to breed more productive grain crops. These characteristics include the resistance to heat, frost, drought, pests and diseases.\n\nAnother fact about Australian Grains Genebank is that it uses a DNA-based soil testing service, to assist grain growers in predicting the losses from various diseases before a crop is planted. Growers have the option of changing cultivars or modifying cropping programs, in situations where the risk of crop loss is high. The service was launched in 1997 and the initial focus was on grain and barley, but pathogens of rotation crops are now included.\n\nIn 2009 the Victorian Government provided $3 millions to Sally Norton, leader of the Australian Grains Genebank to make the bank, also promising $600,000 per year for the next five years toward operating costs. The bank was officially opened in March, 2014.The budget is provided by the Government of Victoria and the Grains Research and Development Corporation, a corporation that is supported by the Government of Australia.\n\nThe AGG is a national seed store bank completed by H2o architects, on the Wimmera flatland at the edge of Horsham, Victoria, for the Victorian Department of Environment and Primary Industries. The facility has more than 2.7 kilometres of space to give a secure store for seed specimens. The building is also used for seed development, seed requests and contains a packaging and receiving area, administration areas, drying facilities, freezers working at -20 degrees Celsius and a multipurpose national reception area, or lobby, to accommodate visiting groups.\n\nA double skin freezer design has an inner esky box of isolated panels, used for storing seeds and contained within an outer wood clad weather protecting cover. This design makes certain that the freezers work with less charge, reduce the energy consumption and operating costs of the facility. Efficiency is reached with a robust and environmentally responsible mechanical system.\n\nThe building has a strong presence and provides innovation in design, technology and materials. The exterior layer is very similar to a pergola, with thousands of timber slats, each one 120 centimetres long, creating the top layer.\n\nThe Horsham bank is the biggest of its kind and is designed for long-term storage. The material they conserve includes released crop varieties, breeding materials, and crop wild relatives. It serves not only producers but also processors, marketers, breeders and regional farming communities. Peter Walsh, the Victorian Minister of Agriculture, explained that the bank could contain about 300 million seeds from all around the globe. The bank has the capacity to hold 200,000 packets of seeds and more than 200 different crop species. In 2017 the collection held about 138,016 different seeds (or assessions), and it is growing about 3000 seeds each year.\n\nThe most representative crop names stored are:\n\n\n\n\n\n\nThe seed drying room operates at 15 degrees Celsius and 15% of humidity. Seeds remain in this room form four to six weeks to dry down to around 6% seed moisture before being sealed into foil packets and placed under long-term storage at -20 degrees Celsius.\n\nAGG routinely conduct seed viability monitoring tests because seeds lose their ability to germinate, even under long-term conditions. Once seed germination drops below 85%, and the seed quantity they have in the store is below 500 seeds, the genebank regenerates the seed. They regenerate around 4000 different samples per year under field and greenhouse environments. When they regenerate seeds, they consider the biology of the plants to ensure the right soil mix, temperatures, control pollination for outcrossing species.\n\nIn order to keep the seeds safe, they are stored in 2.7 kilometres of shelf space at -20 degrees Celsius (-4 degrees Fahrenheit) with very low moisture. The seeds can remain viable for 50 or 100 years (depending on the kind of seed), preserving, in this way, the genetic materials.\nThe primary reason for the bank to be created was the extreme temperatures in the area, up to 40 degrees Celsius (104 degrees Fahrenheit) in the summertime. Because of that, they had to ensure the protection of the grains all year around.\n\nThe longevity of seeds differs; some keep well for decades, crops are grown out regularly and new grains assembled to increase the collection. A database carries the information about the origin and characteristics of each seed line (none genetically modified) and features of seed viability and the quantity held.\n\nSeeds are placed in controlled maturing environments with high temperatures and a certain humidity (RH; 45°C and 60 % RH). The Lithium chloride (LiCl) helps to obtain the right RH environment.\n\nThe seed survival curve, that can be acquired from the germination test, is compared with the longevity of ‘marker’ species aged under the same conditions. From here, longevity categories can be distinguished: this is most important for alpine seeds, as recent proofs show that grains from cooler and wetter habitats are shorter lived than seeds from warmer ones.\nLongevity checks can also indicate how seeds should be conserved.\n\nThe main goal of the Australian Seed Bank Partnership is to save about 1700 native species of plant and ecological communities facing extinction due to habitat loss, and the fragmentation and degradation of invasive species. To accomplish this objective, the partnership maintains a safe and sustainable environment, and collects and stores seeds to help research on the subject.\n\nThe Australian Grains Genebank is one of the most important members of the Australian Seed Bank Partnership, which is an alliance between 12 organizations that are trying to deal with the multitude of threats facing Australian biodiversity by working together. The partnership consists of nine seeds banks, that are storing and conserving seeds, and three flora-focused organizations, that have the mission not only to fulfill the gap between policymakers, researcher, and seed collectors, but also to manage the on-ground conservation and restoration activities.\nThe activities related to the Australian Seed Bank Partnership consist of four simple concepts: collecting, research, supporting restoration and sharing knowledge.\n\n\nThe Australian Grains Genebank is related to the Australian Seed Bank Partnership. They are actually collaborating on an Australian Crop Wild Relatives project. Through this project, these two institutions are trying to store all the Australian crop wild relatives, that are not yet represented in the ex-suit collection. The 32 wild crop species will be stored and preserved on the facilities of the Australian Grains Genebank. This project is considered really important, because saving and storing the wild crops will enable researchers into new plant varieties, that will be important for the future and the development of the Australian agriculture.\n\n"}
{"id": "15469195", "url": "https://en.wikipedia.org/wiki?curid=15469195", "title": "Biały Słoń", "text": "Biały Słoń\n\nBiały Słoń (English: \"White Elephant\"; Ukrainian: Білий слон, Bily slon) is a Polish name for an abandoned campus of the former Polish Astronomical and Meteorological Observatory of Warsaw University, located at remote area on the peak of Pip Ivan in the Chornohora range of the Carpathian Mountains, Ukraine. Currently the structure is used as a mountain shelter with a small search and rescue team with some rooms adopted for lodging and recovery. \n\nAlong with that Bialy Slon is recognized as a historical landmark and there are restoration activities on the way since 2012 to restore its original conditions in cooperation with the Ciscarpathian National University and the Warsaw University and scheduled to be finished in 2018. It is considered to be the highest built residential structure in Ukraine.\n\nThe closest settlement today is a village of Zelena in Verkhovyna Raion (Ivano-Frankivsk Oblast) and territorially belongs to the Zelena rural council. Currently the observatory is classified under the registration number three as a monument of cultural heritage that is not considered for privatization. The facility is located with the Carpathian National Nature Park.\n\nThe region was part of the Second Polish Republic when the observatory was established during the interbellum period. Biały Słoń, started in 1937 and completed in the summer of 1938, was the highest-elevated, permanently inhabited, building in Poland. It was located on the international border between the Second Polish Republic and Czechoslovakia that stretched across mountain peaks of the Carpathian Mountains.\n\nAccording to Wladyslaw Midowicz, the first and only director of the observatory, the construction of \"Biały Słoń\" was suggested by a group of influential Warsaw astronomers who managed to convince General Leon Berbecki, director of the influential Airborne and Antigas Defence League, to support it. General Tadeusz Kasprzycki, minister of military affairs, also backed the construction of the observatory.\n\nThe building design was approved sometime in 1935. Construction of this impressive building began in the summer of 1936 with an official ceremony for the placing of the cornerstone. Biały Słoń was a very expensive structure with total costs exceeding one million Polish złoty, a huge burden for the state budget of the time. The design was based on the Przemyśl Castle and shaped like a letter \"L\" with a tower.\n\nThe whole complex consists of three major features that could be considered as separate structure connected together, a tower, a main building, and smaller service attachment. Due to relief, \"Biały Słoń\" had five stories facing the Czechoslovakian side (today Zakarpattia Oblast) and two stories facing the Polish (today Ivano-Frankivsk Oblast). The whole complex was built mostly from local sandstone. Due to lack of roads, the construction materials were brought by horses or either by hand or back of local Hutsuls and soldiers of the 49th Hutsul Rifle Regiment from the Vorokhta train station located some away. The walls of a lower attachment and the semi-basement floor have thickness of , while upper floors - . The roof of a building was covered with copper sheets. At the southern side was located a rotunda on which was located a telescope. The copper dome of the telescope opened automatically. \n\nThe \"Biały Słoń\" had 43 rooms including a conference hall, living quarters, offices, a cafeteria, a battery station, and a boiler room in the basement (the lower structure). The upper floors were occupied by astronomers and meteorologists, most of whom worked for the State Meteorological Institute and Astronomical Observatory of the Warsaw University. Their work was to carry out meteorological observations for the Polish Air Force. In the lower levels, there were lodgings of soldiers of the \"Karpaty\" Regiment of the Border Defence Corps, with headquarters in Stryj. Altogether, the number of inhabitants never exceeded 20. Among those who worked there were professor Wlodzimierz Zonn, doctor Jan Gadomski, and professor Eugeniusz Rybka.\n\nThe opening ceremony of the building took place on July 29, 1938. Its official name was the \"Observatory of the State Meteorological Institute\", but soon it took on the nickname \"Biały Słoń\", due to the color of its walls. The observatory was lavishly equipped, with a custom-made astrograph and refracting telescope made by the renowned British company Grubb Parsons of Newcastle upon Tyne. It had its own power plant with two Diesel motor-generators and central heating fueled by oil, which was transported in iron barrels from the \"Polmin\" company in Borysław (today Boryslav). The military authorities also installed their own equipment, including two radiotelephone prototypes constructed to withstand high altitude.\n\nThe observatory was located in a remote, deserted area, with the nearest store and mail office away (at Żabie, today Verkhovyna), the nearest doctor away, and a rail station in Kolomyia as far as away. The directory of the observatory a local of Mykulychyn Władysław Midowicz wrote that the staff's main problem, however, was water, as no waterworks had been constructed and it had to be carried from a stream away.\n\nFor fourteen months (July 1938-September 1939) the Observatory was the highest-elevated, permanently inhabited, building of interbellum Poland. As entry was permitted only with a special military pass, local Hutsuls made up several legends about the building and its inhabitants. Wladyslaw Midowicz wrote that the Hutsuls thought that the Observatory was in fact a mighty cannon, capable of attacking neighboring countries.\n\nOn September 18, 1939, following the Soviet aggression on eastern part of Poland (see: Kresy), the personnel of the Observatory packed the most important equipment (including the refractor) and left toward the Hungarian border. At first it was taken to the Budapest Konkoly Observatory, and by the end of war to the Vienna Observatory. Within the first years after the war, the equipment returned to Poland. The three-lens objective today is located in the Silesian Planetarium (Katowice).\n\nAt the end of the month, the Red Army captured the building. After the region was united with the Ukrainian SSR, the National Academy of Sciences of Ukraine (NASU) sent an expedition. On 31 December 1939 the first academician-astronomer of the Academy of Sciences of the Ukrainian SSR Oleksandr Orlov ascended to the observatory. He established that the most valuable equipment has been taken out of the building, including five lenses of big diameter, two lenses of smaller diameter, two micrometers, and two chronometers. Based on the Orlov's report, the NASU Presidium declared that the Carpathian Astronomical Observatory (the newly acquired name) is transferred to the Academy of Sciences of the Ukrainian SSR, based on the resolution of the government of the Ukrainian SSR of 2 January 1940. The director of the Carpathian Observatory was appointed academician Oleksandr Orlov. Until June 1941 it was used as a meteorological station. In the summer of 1941 (see: Operation Barbarossa), the Observatory was seized by the Wehrmacht, which in turn was passed to the Hungarian troops, who were stationed there until winter 1941. After that, the deserted building became a ruin, even though it had not been damaged during the war, the locals reused all remaining material. Even the cast iron batteries were taken away.\n\nIt was reported that Germans have taken out metal parts of astrograph to Lviv. Now they are kept indoors of the Lviv University Faculty of Physics.\n\nRecovery of the building started only after the dissolution of the Soviet Union, but very slow. In mid-1990s scientists of the Lviv Polytechnic, led by professor Anatoliy Dultsev, together with their colleagues from Warsaw Polytechnic, brought forward the idea of rebuilding of the Observatory. In October 1996 a special conference took place in Lviv and Yaremche, but according to \"atomnet.pl\" from May 1997 no works have been started. \n\nOn January 24, 2002 another Scientific council took place in Yaremche to renew the rebuilding project of the observatory. In the beginning of October 2002 the head of the Ivano-Frankivsk Oblast administration Mykhailo Vyshyvaniuk sent an official letter to the President of Ukraine Leonid Kuchma about the project. By the end of November of the same year Vyshyvaniuk received an answer from the First Deputy of the President administration Valeriy Khoroshkovskiy stating that the proposition was reviewed and recognized as one for the international discussion for the restoration. In that regard the Ministry of Foreign Affairs was given the required orders. Between 1998 and 2010 there took place some a dozen of summer expeditions which contributed to the historical reconstruction of the building's construction.\n\nIn 2012 the Ministry of Culture of Poland has directed some $70,000 as a grant program which is in partnership with the Ciscarpathian University. Along with Warsaw and Ciscarpathian university, total amount of money allocated for preparation works accounted to $100,000. Since July 2012 there started some preparation work and continued in fall of 2012, having all window openings be sealed with bricks and roof covered. It was decided to enclose the building in order to get rid of moisture. The whole cost of the project is $2 million. Initially the project was to be finished by 28 July 2015.\n\nAt least since 2015, there is a small chapel erected next to the former observatory complex.\n\nIn December 2017 it was reported that the White Elephant will be equipped with a lightning protection system and the Ciscarpathian University already ordered documentation for a projected budget. The lightning prevention system is intended to be installed by the summer of 2018.\n\nSince 2015 within the building is located a mountain rescue post of the Ivano-Frankivsk branch of the State Emergency Service of Ukraine. The post is unique as it is the most high-altitude government institution in Ukraine. The post is insulated and electrified. There is a wifi and separate space for visitors.\n\nThe tourist traffic over Chornohora Ridge is constant and especially in summer exceeds 6,000 people per month according to statistics of the State Emergency Service of Ukraine in 2017. Between summer of 2016 and summer of 2017, the mountain was visited by 4,000 groups with total population exceeding 22,000 people with 9,000 of which were foreigners. Some 420 groups (about 1,500 people) managed to find shelter at the top. The rescue post conducted seven search and rescue missions saving eight people and providing various type of help to 89 others.\n\nIn 2017 there was initiated a creation of a joint Polish-Ukrainian mountain rescue service and a school of mountain rescue. During the actively ongoing restoration activities in 2017, main rooms of mountain shelter are not available, but some provisionally space was created without heating capabilities.\n\n"}
{"id": "8797938", "url": "https://en.wikipedia.org/wiki?curid=8797938", "title": "Calcaneal fracture", "text": "Calcaneal fracture\n\nA calcaneal fracture is a break of the calcaneus (heel bone). Symptoms may include pain, bruising, trouble walking, and deformity of the heel. It may be associated with breaks of the hip or back.\nIt usually occurs when a person lands on their feet following a fall from a height or during a motor vehicle collision. Diagnosis is suspected based on symptoms and confirmed by X-rays or CT scaning.\nIf the bones remain normally aligned treatment may be by casting without weight bearing for around eights weeks. If the bones are not properly aligned surgery is generally required. Returning the bones to their normal position results in better outcomes. Surgery may be delayed a few days as long as the skin remained intact.\nAbout 2% of all fractures are calcaneal fractures, however, they make up 60% of fractures of the mid foot bones. Undisplaced fractures may heal in around three months while more significant fractures can take two years. Difficulties such as arthritis and decreased range of motion of the foot may remain.\n\nThe most common symptom is pain over the heel area, especially when the heel is palpated or squeezed. Patients usually have a history of recent trauma to the area or fall from a height. Other symptoms include: inability to bear weight over the involved foot, limited mobility of the foot, and limping. Upon inspection, the examiner may notice swelling, redness, and hematomas. A hematoma extending to the sole of the foot is called \"Mondor Sign\", and is pathognomonic for calcaneal fracture. The heel may also become widened with associated edema due to displacement of lateral calcaneal border. Involvement of soft tissue (tendons, skin, etc.,) should be evaluated because soft tissue injury has been associated to serious complications (see below).\n\nCalcaneal fractures are often attributed to shearing stress adjoined with compressive forces combined with a rotary direction (Soeur, 1975). These forces are typically linked to injuries in which an individual falls from a height, involvement in an automobile accident, or muscular stress where the resulting forces can lead to the trauma of fracture. Overlooked aspects of what can lead to a calcaneal fracture are the roles of osteoporosis and diabetes.\n\nUnfortunately, the prevention of falls and automobile accidents is limited and applies to unique circumstances that should be avoided. The risk of muscular stress fractures can be reduced through stretching and weight-bearing exercise, such as strength training. In addition, footwear can influence forces that may cause a calcaneal fracture and can prevent them as well. A 2012 study conducted by Salzler showed that the increasing trend toward minimalist footwear or running barefoot can lead to a variety of stress fractures including that of the calcaneus.\n\nBone mineral density decreases with increasing age. Osteoporotic bone loss can be prevented through an adequate intake of vitamin C and vitamin D, coupled with exercise and by being a non-smoker. A study by Cheng et al. in 1997, showed that greater bone density indicated less risk for fractures in the calcaneus.\n\nIn 1991, Kathol conducted a study which showed a correlation between calcaneal insufficiency avulsion fractures (a fracture in which the Achilles tendon removes a portion of the bone as it rescinds) and diabetes mellitus. The diabetic population is more susceptible to the risks of fracture and potential healing complications and infection that may lead to limb amputation. Diabetes can be regulated and prevented through diet and exercise.\n\nConventional radiography is usually the initial assessment tool when a calcaneal fracture is suspected. Recommended x-ray views are (a) axial, (b) anteroposterior, (c) oblique and (d) views with dorsiflexion and internal rotation of the foot. However, conventional radiography is limited for visualization of calcaneal anatomy, especially at the subtalar joint. A CT scan is currently the imaging study of choice for evaluating calcaneal injury and has substituted conventional radiography in the classification of calcaneal fractures. Axial and coronal views are obtained for proper visualization of the calcaneus, subtalar, calcaneocuboid and talonavicular joints.\n\nThe calcaneus, also known as the heel bone, is the largest of the tarsal bones and articulates with the cuboid bone anteriorly and the talus bone superiorly. It is responsible for transmitting the majority of the body's weight from the talus bone to the ground.\n\nCalcaneal fractures are categorized as intra-articular or extra-articular on the basis of subtalar joint involvement. Intra-articular fractures are more common and involve the posterior talar articular facet of the calcaneus. The Sanders classification groups these fractures into four types based on the location of the fracture at the posterior articular surface. Extra-articular fractures are less common and may be located anywhere outside the subtalar joint. Extra-articular fractures are categorized depending on whether the involvement of the calcaneus is anterior (Type A), middle (Type B) or posterior (Type C).\n\nThe Angle of Gissane, or \"Critical Angle\", is the angle formed by the downward and upward slopes of the calcaneal superior surface. On a lateral radiograph, an angle of Gissane > 130° suggests fracture of the posterior subtalar joint surface. Bohler's angle, or the \"Tuber Angle\", is another normal anatomic landmark seen in lateral radiographs. It is formed by the intersection of 1) a line from the highest point of the posterior articular facet to the highest point of the posterior tuberosity, and 2) a line from the former to the highest point on the anterior articular facet. Bohler's angle is normally 25° to 40°. A decreased angle is indicative of a calcaneal fracture.\n\nThe Sanders classification system is the most commonly used system for categorizing intra-articular fractures. There are 4 types:\n\nExtra-articular fractures include all fractures that do not involve the posterior facet of the subtalar joint.\n\n\nNon-surgical treatment is for extra-articular fractures and Sanders Type I intra-articular fractures, provided that the calcaneal weight-bearing surface and foot function are not compromised. Physicians may choose to perform closed reduction with or without fixation (casting), or fixation alone (without reduction), depending on the individual case. Recommendations include no weight-bearing for a few weeks followed by range-of-motion exercises and progressive weight bearing for a period of 2–3 months.\n\nDisplaced intra-articular fractures require surgical intervention within 3 weeks of fracture, before bone consolidation has occurred. Conservative surgery consists of closed reduction with percutaneous fixation. This technique is associated with less wound complications, better soft tissue healing (because of less soft tissue manipulati) and decreased intraoperative time. However, this procedure has increased risk of inadequate calcaneal bone fixation, compared to open procedures. Currently, open reduction with internal fixation (ORIF) is usually the preferred surgical approach when dealing with displaced intra-articular fractures. Newer, more innovative surgical techniques and equipment have decreased the incidence of intra- and post-operative complications.\n\nRehabilitation for a calcaneal fractures is dependent on whether surgery was required or not. Both types of rehabilitation require three phases in which only the first phase is different.\n\nExercises that can be used for the range of motion phase can include eversion and inversion of the ankle, flexion and extension of the ankle, and a combination of the two motions to create a circular foot motion. Exercises that allow slight to full body weight to be used in the final phases include stepping forward then back, side-stepping, and leg stand.\n\nThe first phase of the rehabilitation after surgery includes keeping the foot elevated and iced for the first 2 days after the operation. After those 2 days, using crutches or a wheelchair in which there is no weight applied to the affected foot is recommended to getting around. If no operation was performed, the foot should be submitted to frequent range of motion exercises. The second phase occurs 6 weeks after and consists of keeping the foot elevated and iced while resting and performing exercises in which only slight weight is applied to the affected area for the next two weeks, others recommend six weeks of this phase. In this phase, range of motion exercises should be implemented if surgery was needed for the fracture. The third and final phase of rehabilitation of calcaneal fractures is to allow the full body weight to be used and use crutches or a cane if needed, between 13 weeks to a year the patient is allowed to resume normal activities.\n\nEvaluating soft-tissue involvement is the most important aspect of the clinical examination because of its association with patient outcome. Skin blisters may become infected if medical attention is delayed, which can lead to necrotizing fasciitis or osteomyelitis, causing permanent damage to muscle or bone. Ligament and tendon involvement should also be explored. Achilles tendon injury can be seen with posterior (Type C) fractures. Since calcaneal fractures are related to falls from height, other concomitant injuries should be evaluated. Vertebral compression fractures occur in approximately 10% of these patients. A trauma-focused clinical approach should be implemented; tibial, knee, femur, hip, and head injuries should be ruled out by means of history and physical exam.\n\nThe name \"lover's fracture\" is derived from the fact that a lover may jump from great heights while trying to escape from the lover's spouse.\n"}
{"id": "52039332", "url": "https://en.wikipedia.org/wiki?curid=52039332", "title": "Center for Security Studies", "text": "Center for Security Studies\n\nThe Center for Security Studies (CSS) is a center at the Swiss Federal Institute of Technology in Zurich, which focuses on Swiss and international security.\n\nThe center was founded by Prof. Dr. Kurt Spillmann in 1986 and has been led by Prof. Dr. Andreas Wenger since 2002. It also constitutes as part of the Center for Comparative and International Studies (CIS) along with the political science professorships at the Swiss Federal Institute of Technology in Zurich and the University of Zurich.\n\nThe mission of the CSS is to examine the challenges surrounding security policy development and how to deal with them. It does this by performing research on security-related issues and by training researchers and practitioners. The center also includes an independent think tank, which focuses on Swiss and international security policy as well as furthering peace. Another key aim of the CSS is to serve as a link between academia, practitioners and the public on security matters.\n\nProjects which have been supported by the CSS include the Parallel History Project, an online project which collected together and analyzed declassified and other government documents relating to the Cold War, as well as the International Relations and Security Network, an online information service that provided a range of open access products and resources on international relations. While the International Relations and Security Network was closed in 2016, its extensive digital library as well as other products have been integrated into the CSS and transformed into a new project, CSS Resources.\n\n"}
{"id": "44840838", "url": "https://en.wikipedia.org/wiki?curid=44840838", "title": "Constantin Arnoldi", "text": "Constantin Arnoldi\n\nConstantin Arnoldi was a Russian entomologist.\n\nConstantin was the son of Vladimir Arnoldi.\n"}
{"id": "34997307", "url": "https://en.wikipedia.org/wiki?curid=34997307", "title": "Crespi effect", "text": "Crespi effect\n\nThe Crespi effect is a behavioural contrast phenomenon first observed in rats by US psychologist Leo P. Crespi in 1942. He found that in a repeatedly carried out task such as finding food in a maze, the running speed of the rat is proportional to the size of the reward it obtained on the previous trial. The more food reward that was given to it last time upon completion of the task, the faster it will run when attempting to complete the same task. The effect also works in reverse: when rats were shifted from a larger to a smaller reward, they ran more slowly than the control rats that had always received the small reward.\n\nIt is important to note that the size of the reward has little or no influence on the speed of learning, but that it does have an influence on the performance of tasks already learned.\n\n"}
{"id": "19805906", "url": "https://en.wikipedia.org/wiki?curid=19805906", "title": "Dark current (physics)", "text": "Dark current (physics)\n\nIn physics and in electronic engineering, dark current is the relatively small electric current that flows through photosensitive devices such as a photomultiplier tube, photodiode, or charge-coupled device even when no photons are entering the device; it consists of the charges generated in the detector when no outside radiation is entering the detector. It is referred to as reverse bias leakage current in non-optical devices and is present in all diodes. Physically, dark current is due to the random generation of electrons and holes within the depletion region of the device.\n\nThe charge generation rate is related to specific crystallographic defects within the depletion region. Dark-current spectroscopy can be used to determine the defects present by monitoring the peaks in the dark current histogram's evolution with temperature.\n\nDark current is one of the main sources for noise in image sensors such as charge-coupled devices. The pattern of different dark currents can result in a fixed-pattern noise; dark frame subtraction can remove an estimate of the mean fixed pattern, but there still remains a temporal noise, because the dark current itself has a shot noise.\n"}
{"id": "20932260", "url": "https://en.wikipedia.org/wiki?curid=20932260", "title": "Diagnosis Mercury", "text": "Diagnosis Mercury\n\nDiagnosis Mercury: Money, Politics and Poison is a 2008 book by Jane Hightower. The book explains that mercury is a poison and that the majority of mercury in the environment comes from coal-fired power plants. But the book is mainly concerned with human exposure from the eating of large predatory fish such as swordfish, shark, king mackerel, large tuna, etc. The book also discusses industrial mercury poisonings, such as those in Minamata, Japan, in the 1950s and Ontario, Canada, in the 1970s.\n\n\n"}
{"id": "48195477", "url": "https://en.wikipedia.org/wiki?curid=48195477", "title": "Dixit–Stiglitz model", "text": "Dixit–Stiglitz model\n\nDixit–Stiglitz model is a model of monopolistic competition developed by Avinash Dixit and Joseph Stiglitz (1977). It has been used in many sub-fields of economics including macroeconomics, economic geography and international trade theory.\n"}
{"id": "58005561", "url": "https://en.wikipedia.org/wiki?curid=58005561", "title": "Drive.ai", "text": "Drive.ai\n\nDrive.ai is an American technology company headquartered in Mountain View, California that uses artificial intelligence to make self-driving systems for cars. It is the second company to remove the safety driver from its autonomous vehicles. To date, the company has raised approximately $77 million in funding. Drive.ai's technology can be modified to turn a vehicle autonomous.\n\nIn May 2018, Drive.ai announced a pilot program in Frisco, Texas to test the company's vehicles in its first application of a passenger carrying service available to the general public.\n\nDrive.ai was established in 2015 through Stanford University's Artificial Intelligence Lab by a group of graduate and PhD students. The group initially worked to develop a retrofit kit to add their autonomous driving system to existing cars. In August 2016, the company emerged from stealth mode with $12 million in funding. The company's early funding included investments by Northern Light Venture Capital, Oriza Ventures and InnoSpring Seed Fund.\n\nIn June 2017, Drive.ai raised a $50 million Series B funding round led by New Enterprise Associates with participation from GGV Capital, Northern Light Venture Capital and other previous investors. As part of the funding announcement, the company also announced that scientist Andrew Ng had joined its board of directors. That same month, Lyft announced a partnership with Drive.ai to run a pilot program in San Francisco operating Drive.ai's test fleet through Lyft's platform.\n\nDrive.ai raised an additional $15 million in September 2017 including participation from Grab, a ride-hailing technology company in Southeast Asia.\n\nIn May 2018, it was announced that Drive.ai was working with the Frisco Transportation Management Association and would be releasing an on-demand self-driving passenger carrying car service in Frisco, Texas during the course of an initial 6-month pilot program. It was the first public deployment of self-driving cars in Texas. The pilot program will initially use safety drivers to monitor the car's operation, but will eventually move to driverless operation with remote monitoring. A Drive.ai app will be used by riders to call rides. Initially, the program will operate as a shared service within a fixed area including retail, entertainment and office spaces using designated pickup and drop-off locations. During the trial period, Drive.ai will offer public education about its self-driving technology.\n\nThe company has a fleet of Lincoln MKZs, an Audi A4 and Nissan NV200s for its testing in California.\n\nIn February 2017, Drive.ai released the first video footage of its technology, featuring one of its self-driving Lincoln MKZ cars navigating the streets of Mountain View, CA in the rain after dark. This marked an early recording of a self-driving vehicle operating on a fully autonomous ride at night, or in inclement weather.\n\nIn May 2018, Drive.ai released a video featuring an orange Nissan NV200 driverless vehicle navigating Frisco streets. The video featured private streets as well as busy intersections and a traffic circle. It also featured a display showing the car's sensors and cameras dealing with objects on the road and highlighted operation through low-angle sunlight that would obscure typical sensors. The car's object recognition systems identify and route around other vehicles, pedestrians and cyclists safely. Drive.ai's cars include screens on the outside of the car, one on the hood, one on the back, and one on each side, to communicate with pedestrians. The screens feature prompts such as \"Passengers Entering/Exiting' or \"Waiting for You to Cross.\"\n\nDrive.ai collects data along the routes it will be using to create three-dimensional high-definition maps to support the self-driving technology.\n"}
{"id": "57113916", "url": "https://en.wikipedia.org/wiki?curid=57113916", "title": "ESO 444-46", "text": "ESO 444-46\n\nESO 444-46 is a giant elliptical galaxy located about 640 million light-years away in the constellation Centaurus. It is the brightest member of the galaxy cluster Abell 3558 which lies in the center of the Shapley Supercluster.\n\nESO 444-46 has an estimated population of about 27,000 globular clusters which may be one of the largest populations ever studied. However, this large number may be due to the addition of Intracluster globular clusters since the galaxy lies about 1 arcmin of the center of Abell 3558.\n\n"}
{"id": "4642577", "url": "https://en.wikipedia.org/wiki?curid=4642577", "title": "Electrochemical noise", "text": "Electrochemical noise\n\nElectrochemical noise (ECN) is the generic term given to fluctuations of current and potential. When associated with corrosion, it is the result of stochastic pulses of current generated by sudden film rupture, crack propagation, discrete events involving metal dissolution and hydrogen discharge with gas bubble formation and detachment. The technique of measuring electrochemical noise uses no applied external signal for the collection of experimental data.\n\nThe ECN technique measures the signal perturbations which are low level fluctuations of the corrosion potential between two nominally identical electrodes which can be used in the mechanistic determination of corrosion type and speed. The fluctuations are usually of low amplitude, less than 1 mV and of low frequency bandpass filtered RMS value (DC and high frequency AC components removed). The noise corresponds with the low level frequency noise (differential of the ZRA) signal but has a much lower amplitude when general corrosion is involved. The major source of noise can be ascribed to macroscopic random-stochastic phenomena. They include partial faradaic currents adsorption / desorption, surface coverage, corrosion cracking and mechanical erosion processes. A common feature of this 1/f Poisson spectra is that it differs from the \"white\" Guassian noise in which accuracy increases as the square root of the measurement time. \n\nThe technique considers the reactions occurring at the metal–solution interface and suggests two currents flowing on each electrode as a result of the anodic and cathodic reactions. Once regarded as a source of bias and error that compromised electrochemical measurements it is now regarded as a rich source of information. The technique is widely used within the Corrosion engineering world as a useful Corrosion Monitoring technique. \n\nThe ECN phenomenon belongs to the general category of random low frequency stochastic processes described by either probability density function equations or in statistical terms. These random processes are either stationary or non-stationary. The first moments of a stationary process are invariate with time. \n\n"}
{"id": "25961892", "url": "https://en.wikipedia.org/wiki?curid=25961892", "title": "Frank Winkler", "text": "Frank Winkler\n\nP. Frank Winkler, Jr. is an astronomer and noted subject-matter expert on supernova. He received his doctorate from Harvard and is currently the Gamaliel Painter Bicentennial Professor in Physics at Middlebury College located in Middlebury, Vermont.\n\nDr. Winkler has calculated the distance for the brightest supernova event recorded in human history, SN 1006, as being ~7,200 light years distant.\n\nWinkler is also the recipient of record for a Recovery Act grant for continued research regarding supernova. Frank Winkler is also a member of the International Astronomical Union.\n"}
{"id": "33072775", "url": "https://en.wikipedia.org/wiki?curid=33072775", "title": "François Robert", "text": "François Robert\n\nFrançois Robert, born in Paris, France the 26th of January, 1951, is a French researcher specializing in isotope geochemistry and cosmochemistry. His work on the isotopes of hydrogen has enhanced the understanding of the origin of water and of organic matter in the solar system. He is famous for his work on lithium, beryllium and boron, light elements formed by the irradiation of interstellar matter. He received a Leonard Medal from the Meteoritical Society in 2011 for his work on the isotopic composition of stable nuclei.\n\nHe began his thesis in 1975 in the CEA Saclay under the direction of Marc Javoy and Liliane Merlivat and edited by Samuel Epstein at Caltech, Pasadena, California. He joined the CNRS in 1980 at the Laboratory of stable isotope geochemistry at the University of Jussieu, where he defended his thesis on the isotopic compositions (H, C, N) of carbonaceous meteorites in 1982. Between 1983 and 1990, he worked successively with Liliane Merlivat in Saclay, Samuel Epstein at the California Institute of Technology and Marc Javoy at Jussieu.\n\nIn 1990 he became a Directeur de Recherche in the CNRS.\n\nIn 1992 he worked for a few months in Thiruvananthapuram, India, where he created a laboratory for isotopic analysis.\n\nHe was assigned in 1993 to the Laboratory of Mineralogy of the National Museum of Natural History (MNHN) led by Professor Jacques Fabriès. Between 1993 and 2004, he collaborated with the Research Center for Petrology and Geochemistry in Nancy (CNRS / INPL). Under the leadership of Professor Stephen Roth he participated in the establishment of the French Society for Stable Isotopes of which he became the Senior Vice President in 1999.\n\nIn 1999, he undertook the determination of the molecular structure of the insoluble organic matter of meteorites in collaboration with the Laboratory of Organic and Inorganic Geochemistry of the Environment at the University Pierre et Marie Curie in Paris.\n\nIn 2006, he became responsible for a consortium of French laboratories set up by CNES, which set itself the goal of analysis of samples from the halo of Comet Wild 2 captured by the U.S. Stardust space mission (NASA).\n\nBetween 2003 and 2011, he was successively elected member of the Board of Directors and the Scientific Council of the MNHN and Chairman of the National Program of Planetology (PNP / CNRS-INSU). Since 2004 he has been Director of the Laboratory of Mineralogy and Cosmochemistry of the Museum, in which there is a NanoSims (Cameca) ion probe accessible to national and international researchers as part of the National Analysis Service of the INSU-CNRS.\n\n"}
{"id": "56601", "url": "https://en.wikipedia.org/wiki?curid=56601", "title": "Fuzzy set", "text": "Fuzzy set\n\nIn mathematics, fuzzy sets (aka uncertain sets) are somewhat like sets whose elements have degrees of membership. Fuzzy sets were introduced independently by Lotfi A. Zadeh and Dieter Klaua in 1965 as an extension of the classical notion of set.\nAt the same time, defined a more general kind of structure called an L-relation, which he studied in an abstract algebraic context. Fuzzy relations, which are used now in different areas, such as linguistics , decision-making , and clustering , are special cases of \"L\"-relations when \"L\" is the unit interval [0, 1].\n\nIn classical set theory, the membership of elements in a set is assessed in binary terms according to a bivalent condition — an element either belongs or does not belong to the set. By contrast, fuzzy set theory permits the gradual assessment of the membership of elements in a set; this is described with the aid of a membership function valued in the real unit interval [0, 1]. Fuzzy sets generalize classical sets, since the indicator functions (aka characteristic functions) of classical sets are special cases of the membership functions of fuzzy sets, if the latter only take values 0 or 1. In fuzzy set theory, classical bivalent sets are usually called \"crisp\" sets. The fuzzy set theory can be used in a wide range of domains in which information is incomplete or imprecise, such as bioinformatics.\n\nA fuzzy set is a pair formula_1 where formula_2 is a set and formula_3 a membership function. \nThe reference set formula_2 (sometimes denoted by formula_5 or formula_6) is called universe of discourse, and for each formula_7 the value formula_8 is called the grade of membership of formula_9 in formula_10. \nThe function formula_11 is called the membership function of the fuzzy set formula_12.\n\nFor a finite set formula_13 the fuzzy set formula_1 is often denoted by formula_15\n\nLet formula_16 Then formula_9 is called \nThe (crisp) set of all fuzzy sets on a universe formula_2 is denoted with formula_20 (or sometimes just formula_21).\n\nFor any fuzzy set formula_22 and formula_23 the following crisp sets are defined:\n\nNote that some authors understand 'kernel' in a different way, see below.\n\n\n\n\n\nThe level set of A is the set of all levels α∈[0,1] representing distinct-cuts. It is the target set (aka codomain) of formula_46:\n\n\n\n\n\nIn contrast to the complement of a fuzzy set, for which there is a very common definition, union and intersection do have some ambiguity.\n\n\nAccording to the definitions of t-norms, fuzzy sets inherit laws as Commutativity, Monotonicity, Associativity and for null and identity element (∅ and U, respectively). However, the union of a fuzzy set and its complement may not result in the full universe U, and the intersection of them may not give the empty set ∅. Intersection and union of a finite family of fuzzy sets can be defined by recursion, keeping associativity law in mind.\n\n\n\n\n\n\nIn contrast to the general ambiguity of intersection and union operations, there is clearness for disjoint fuzzy sets:\nTwo fuzzy sets formula_77 are disjoint iff\nwhich is equivalent to\nand also equivalent to \nWe keep in mind that min/max is a t/s-norm pair, and any other will do the job here as well.\n\nFuzzy sets are disjoint, iff their supports are disjoint according to the standard definition for crisp sets.\n\nFor disjoint fuzzy sets formula_77 any intersection will give ∅, and any union will give the same result, which is denoted as\nwith its membership function given by\nNote that only one of both summands is greater than zero.\n\nFor disjoint fuzzy sets formula_77 the following holds true:\n\nThis can be generalized to finite families of fuzzy sets as follows:\nGiven a family formula_112 of fuzzy sets with Index set I (e.g. I = {1,2,3...n}). This family is (pairwise) disjoint iff\n\nA family of fuzzy sets formula_112 is disjoint, iff the family of underlying supports formula_115 is disjoint in the standard sense for families of crisp sets.\n\nIndependend of the t/s-norm pair, intersection of a disjoint family of fuzzy sets will give ∅ again, while the union has no ambiguity:\nwith its membership function given by\nAgain only one of the summands is greater than zero.\n\nFor disjoint families of fuzzy sets formula_112 the following holds true:\n\nFor a fuzzy set formula_33 with finite formula_60 (i. e. a 'finite fuzzy set'), its cardinality (aka scalar cardinality or sigma-count) is given by\nIn case that U itself is a finite set, the relative cardinality is given by \nThis can be generalized for the divisor to be an non-empty fuzzy set: For fuzzy sets formula_124 with G ≠ ∅, we can define the relative cardinality by:\nwhich looks very similar to the expression for conditional probability.\nNote:\n\nFor any fuzzy set formula_33 the membership function formula_129 can be regarded as a family formula_130. The latter is a metric space with several metrics formula_131 known. A metric can be derived from a norm (vector norm) formula_132 via\nFor instance, if formula_2 is finite, i. e. formula_135, such a metric may be defined by: \nFor infinite formula_2, the maximum can be replaced by a supremum. \nBecause fuzzy sets are unambiguously defined by their membership function, this metric can be used to measure distances between fuzzy sets on the same universe:\nwhich becomes in the above sample:\nAgain for infinite formula_2 the maximum must be replaced by a supremum. Other distances (like the canonical 2-norm) may diverge, if infinite fuzzy sets are too different, e .g formula_143 and formula_2.\n\nSimilarity measures (here denoted by formula_145) may then be derived from the distance, e. g. after a proposal by Koczy:\nor after Williams an Steele:\nwhere formula_152 is a steepness parameter and formula_153.\n\nAnother definition for interval valued (rather 'fuzzy') similarity measures formula_154 is provided by Beg and Ashraf as well.\n\nSometimes, more general variants of the notion of fuzzy set are used, with membership functions taking values in a (fixed or variable) algebra or structure formula_155 of a given kind; usually it is required that formula_155 be at least a poset or lattice. These are usually called \"L\"-fuzzy sets, to distinguish them from those valued over the unit interval. The usual membership functions with values in [0, 1] are then called [0, 1]-valued membership functions. These kinds of generalizations were first considered in 1967 by Joseph Goguen, who was a student of Zadeh. A classical corollary may be indicating truth and membership values by {f,t} instead of {0,1}.\n\nAn extension of fuzzy sets has been provided by Atanassov and Baruah. An intuitionistic fuzzy set (IFS) formula_33 is characterized by two functions:\nwith functions formula_160 with formula_161\n\nThis resembles a situation like some person denoted by formula_9 voting \nAfter all, we have a percentage of approvals, a percentage of denials, and a percentage of abstentions.\n\nFor this situation, special 'intuitive fuzzy' negators, t- and s-norms can be provided. \nWith formula_166 and by combining both functions to formula_167 this situation resembles a special kind of L-fuzzy sets.\n\nOnce more, this has been expanded by defining picture fuzzy sets (PFS) as follows: A PFS A is characterized by three functions mapping U to [0, 1]: formula_168, 'degree of positive membership', 'degree of neutral membership', and 'degree of negative membership' respectively and additional condition formula_169\nThis expands the voting sample above by an additional possibility 'refusal of voting'.\n\nWith formula_170 and special 'picture fuzzy' negators, t- and s-norms this resembles just another type of L-fuzzy sets.\n\nAs an extension of the case of multi-valued logic, valuations (formula_171) of propositional variables (formula_172) into a set of membership degrees (formula_173) can be thought of as membership functions mapping predicates into fuzzy sets (or more formally, into an ordered set of fuzzy pairs, called a fuzzy relation). With these valuations, many-valued logic can be extended to allow for fuzzy premises from which graded conclusions may be drawn.\n\nThis extension is sometimes called \"fuzzy logic in the narrow sense\" as opposed to \"fuzzy logic in the wider sense,\" which originated in the engineering fields of automated control and knowledge engineering, and which encompasses many topics involving fuzzy sets and \"approximated reasoning.\"\n\nIndustrial applications of fuzzy sets in the context of \"fuzzy logic in the wider sense\" can be found at fuzzy logic.\n\nA fuzzy number is a convex, normalized fuzzy set formula_174 of real numbers (U ⊆ ℝ) whose membership function is at least segmentally continuous and has the functional value formula_175 at at least one element. Because of the assumed convexity the maximum (of 1) is \n\n\nFuzzy numbers can be likened to the funfair game \"guess your weight,\" where someone guesses the contestant's weight, with closer guesses being more correct, and where the guesser \"wins\" if he or she guesses near enough to the contestant's weight, with the actual weight being completely correct (mapping to 1 by the membership function).\n\nA fuzzy interval is a fuzzy set formula_174 with a core interval, i. e. a mean interval whose elements possess the membership function value formula_175.\nThe latter means that fuzzy intervals are normalized fuzzy sets. As in fuzzy numbers, the membership function must be convex, normalized, at least segmentally continuous. Like crisp intervals, fuzzy intervals may reach infinity. The kernel formula_182 of a fuzzy interval formula_33 is defined as the 'inner' part, without the 'outbound' parts where the membership value is constant ad infinitum. In other words, the smallest subset of formula_184 where formula_158 is constant outside of it, is defined as the kernel.\n\nHowever, there are other concepts of fuzzy numbers and intervals as some authors do not insist on convexity.\n\nThe use of set membership as a key components of category theory can be generalized to fuzzy sets. This approach which initiated in 1968 shortly after the introduction of fuzzy set theory led to the development of \"Goguen categories\" in the 21st century.\n\nThe fuzzy relation equation is an equation of the form , where \"A\" and \"B\" are fuzzy sets, \"R\" is a fuzzy relation, and stands for the composition of \"A\" with \"R\" .\n\nA measure d of fuzzyness for fuzzy sets of universe formula_2 should fulfill the following conditions for all formula_42:\nIn this case formula_191 is called the entropy of the fuzzy set A.\n\nFor finite formula_135 the entropy of a fuzzy set formula_33 is given by\nor just\nwhere formula_205 is Shannon's function (natural entropy function)\nand formula_207 is a constant depending on the measure unit and the logarithm base (here: e) used.\nPhysical interpretation of k is the Boltzmann constant k.\n\nLet formula_33 be a fuzzy set with a continuous membership function (fuzzy variable). Then \nand its entropy is \nThere are many mathematical constructions similar to or more general than fuzzy sets. Since fuzzy sets were introduced in 1965, a lot of new mathematical constructions and theories treating imprecision, inexactness, ambiguity, and uncertainty have been developed. Some of these constructions and theories are extensions of fuzzy set theory, while others try to mathematically model imprecision and uncertainty in a different way (; ; Deschrijver and Kerre, 2003).\n\nThe diversity of such constructions and corresponding theories includes:\n\nWhile most of the above can be generally categorized as truth-based extensions to fuzzy sets, bipolar fuzzy set theory presents a philosophically and logically different, equilibrium-based generalization of fuzzy sets.\n\n\n"}
{"id": "8632578", "url": "https://en.wikipedia.org/wiki?curid=8632578", "title": "Gravitation (book)", "text": "Gravitation (book)\n\nGravitation is a physics book on Einstein's theory of gravity, written by Charles W. Misner, Kip S. Thorne, and John Archibald Wheeler and originally published by W. H. Freeman and Company in 1973. It is frequently abbreviated MTW after its authors' initials. The cover illustration, drawn by Kenneth Gwin, is a line drawing of an apple with cuts in the skin to show geodesics. It contains 10 parts and 44 chapters, each beginning with a quotation. The bibliography has a long list of original sources and other notable books in the field. The level of the book is advanced, with the intended audience at the graduate-level and above.\n\nAfter a brief review of special relativity and flat spacetime, physics in curved spacetime is introduced and many aspects of general relativity are covered; particularly about the Einstein field equations and their implications, experimental confirmations, and alternatives to general relativity. Segments of history are included to summarize the ideas leading up to Einstein's theory. The book concludes by questioning the nature of spacetime and suggesting possible frontiers of research. Although the exposition on linearized gravity is detailed, one topic which is not covered is gravitoelectromagnetism. Some quantum mechanics is mentioned, but quantum field theory in curved spacetime and quantum gravity are not included.\n\nThe topics covered are broadly divided into two \"tracks\", the first contains the core topics while the second has more advanced content. The first track can be read independently of the second track. The main text is supplemented by boxes containing extra information, which can be omitted without loss of continuity. Margin notes are also inserted to annotate the main text.\n\nThe mathematics, primarily tensor calculus and differential forms in curved spacetime, is developed as required. An introductory chapter on spinors near the end is also given. There are numerous illustrations of advanced mathematical ideas such as alternating multilinear forms, parallel transport, and the orientation of the hypercube in spacetime. Mathematical exercises and physical problems are included for the reader to practice.\n\nThe prose in the book is conversational; the authors use plain language and analogies to everyday objects. For example, Lorentz transformed coordinates are described as a \"squashed egg-crate\" with an illustration. Tensors are described as \"machines with slots\" to insert vectors or one-forms, and containing \"gears and wheels that guarantee the output\" of other tensors.\n\n\"MTW\" uses the −+++ metric convention, and dissuades the use of the ++++ metric and imaginary time coordinate \"ict\". In the front endpapers, the sign conventions for the Einstein field equations are established and the conventions used by many other authors are listed.\n\nThe book also uses geometrized units, the gravitational constant \"G\" and speed of light in vacuum \"c\" each set to 1. The back endpapers contain a table of unit conversions.\n\nThe book has been reprinted in English 24 times. Hardback and softcover editions have been published. The original citation is\n\nIt has also been translated into other languages, including Russian (in three volumes), Chinese, and Japanese.\n\nThe book is still considered influential in the physics community, with generally positive reviews, but with some criticism of the book's length and presentation style. To quote Ed Ehrlich\n\nJames Hartle notes in his book\n\nwhile Sean M. Carroll states\n\nand Pankaj Sharan writes\n\nRay D'Inverno suggests\n\nMany texts on general relativity refer to it in their bibliographies or footnotes. In addition to the four given, other modern references include George Efstathiou et al., Bernard F. Schutz, James Foster et al., Robert Wald, and Stephen Hawking et al.\n\nOther prominent physics books also cite it, for example \"Classical Mechanics\" by Herbert Goldstein who comments\n\n\n\n"}
{"id": "8737577", "url": "https://en.wikipedia.org/wiki?curid=8737577", "title": "Harold Kosoff", "text": "Harold Kosoff\n\nHarold Kosoff (November 5, 1930 – March 12, 1995) was an inventor. He is credited with inventing the free piston engine and the battery-powered baby swing. U.S. Pat. No. 4,448,410 Exclusive rights for the battery-powered baby swing were sold to Graco. In addition, Kosoff invented a home air cleaner and chainless bicycle using an arc and pulley system.\n\n"}
{"id": "275328", "url": "https://en.wikipedia.org/wiki?curid=275328", "title": "Iberian lynx", "text": "Iberian lynx\n\nThe Iberian lynx (\"Lynx pardinus\") is a wild cat species native to the Iberian Peninsula in southwestern Europe that is listed as Endangered on the IUCN Red List.\nIt preys almost exclusively on the European rabbit. In the 20th century, the Iberian lynx population declined because of sharp declines in rabbit populations, caused by myxomatosis, rabbit haemorrhagic disease and overhunting, fragmentation of grassland and forest habitats and poaching.\n\nBy the turn of the 21st century, the Iberian lynx was on the verge of extinction, as only about 100 individuals survived in two isolated subpopulations in Andalusia. Conservation measures implemented since 2002 included improving habitat, restocking of rabbits, translocating and re-introducing Iberian lynxes, so that by 2012 the population had increased to 326 individuals. As an attempt to save this species from extinction, projects under the EU LIFE Programme have undertaken habitat preservation, lynx population monitoring, and rabbit population management.\n\nFormerly considered a subspecies of the Eurasian lynx (\"Lynx lynx\"), the Iberian lynx is now classified as a separate species. Both species occurred together in Central Europe in the Pleistocene and evolved as distinct species in the Late Pleistocene. The Iberian lynx is thought to have evolved from \"Lynx issiodorensis\".\n\nThe Iberian lynx has a bright yellowish to tawny colored spotted and short fur, a short body, long legs, a short tail, a small head with tufted ears and facial whiskers, called a ruff. Head and body length of males is with a long tail and a weight of . Males are larger than females who have a head-to-body-length of approximately and can weigh .\n\nThe spot pattern of the fur varies from uniformly and densely distributed small spots to more elongate spots arranged in lines that decrease in size from the back towards the sides.\n\nThe Iberian lynx was once present throughout the Iberian Peninsula and southern France. In the 1950s, the northern population extended from the Mediterranean to Galicia and parts of northern Portugal, and the southern population from central to southern Spain. Populations declined from 15 subpopulations in the 1940s to only two subpopulations in the early 1990s, most noticeably in Montes de Toledo and Sierra Morena. Before 1973, it was present in Sierra de Gata, Montes de Toledo, eastern Sierra Morena, Sierra de Relumbrar and Doñana coastal plains. Between the early 1960s and 2000, it has lost about 80% of its former range. It is now restricted to very limited areas in southern Spain, with breeding only confirmed in Sierra Morena and Doñana coastal plains.\n\nA study of mitochondrial DNA from fossil remains, published in March 2015, suggests the Iberian lynx had a wider range during the Late Pleistocene and Holocene, including northern Italy and southern France.\n\nThe Iberian lynx prefers heterogeneous environments of open grassland mixed with dense shrubs such as strawberry tree, mastic, and juniper, and trees such as holm oak and cork oak. It is now largely restricted to mountainous areas.\n\nThe Iberian lynx preys foremost on the European rabbit (\"Oryctolagus cuniculus\") for the bulk of its diet, supplemented by red-legged partridge, rodents and to a smaller degree also on wild ungulates. It sometimes preys on young fallow deer, roe deer, mouflon, and ducks. A male requires one rabbit per day while a female raising kittens will eat three per day. The Iberian species has low adaptability—it continued to rely heavily on rabbits (75% of its food intake) despite the latter's repeated population crashes due to two diseases: myxomatosis, which spread to Iberia after a physician intentionally introduced it in France in 1952, and rabbit haemorrhagic disease beginning in 1988. There were two major outbreaks of the latter in 2011 and 2012. Recovery has occurred in some areas—in 2013, rabbit overpopulation was reported south of Córdoba, causing damage to transport infrastructure and farms. In December 2013, however, it was reported that wildlife officials were concerned about the spread of a new strain of the hemorraghic disease, affecting mainly young rabbits. Sierra Morena's rabbit population was worst affected, falling from an average of three per hectare to less than one—below the minimum required level of 1.5 to two per hectare. Forced to travel greater distances for food, the lynx became more susceptible to death in road accidents, particularly on Autovía A-4.\n\nIt competes for prey with the red fox, the Egyptian mongoose (\"Herpestes ichneumon\") and the wildcat. Also, it often kills other smaller carnivores such as the red fox, the Egyptian mongoose, and the Common genet (\"Genetta genetta\"). The species is solitary and hunts alone; it will stalk its prey or lie in wait for hours behind a bush or rock until the prey is sufficiently close to pounce in a few strides.\n\nThe Iberian lynx is smaller than its northern relatives, and typically hunts smaller animals, usually no larger than hares. It also differs in habitat choice, with Iberian lynx inhabiting open scrubland and Eurasian lynx inhabiting forests.\n\nA lynx, especially with younger animals, will roam widely, with ranges reaching more than . Its territory (≈) is also dependent on how much food is available. Adult Iberian lynx tend to require a minimum amount of space of , and a population of 50 breeding females requires about of habitat area. Nonetheless, once established, ranges tend to be stable in size over many years, the boundaries often being along man-made roads and trails. The Iberian lynx marks its territory with its urine, droppings left in existing tracks through the vegetation, and scratch marks on the barks of trees.\n\nDuring the mating season the female leaves her territory in search of a male. The typical gestation period is about two months; the kittens are born between March and September, with a peak of births in March and April. A litter consists of two or three (rarely one, four or five) kittens weighing between .\n\nThe kittens become independent at 7 to 10 months old, but remain with the mother until around 20 months old. Survival of the young depends heavily on the availability of prey species. In the wild, both males and females reach sexual maturity at the age of one year, though in practice they rarely breed until a territory becomes vacant; one female was known not to breed until five years old when its mother died. The maximum longevity in the wild is 13 years.\n\nSiblings become violent towards one another between 30 and 60 days, peaking at 45 days. A kitten will frequently kill its littermate in a brutal fight. It is unknown why these episodes of aggression occur, though many scientists believe it is related to a change in hormones when a kitten switches from its mother's milk to meat. Others believe it is related to hierarchy, and \"survival of the fittest\".\n\nDifficulty in finding mates has led to more inbreeding, which results in fewer kittens and a greater rate of non-traumatic death. Inbreeding leads to lower semen quality and greater rates of infertility in males, hindering efforts to increase the species' fitness.\n\nThe Iberian lynx has been downlisted from critically endangered species to endangered species thanks to reintroduction and other conservation actions. Its small population makes the cat especially vulnerable to extinction from sudden random events such as a natural disaster or disease. Conservation measures include restoring its native habitat, maintaining the wild rabbit population, reducing unnatural causes of death, and captive breeding for release. The Spanish National Commission for the Protection of Nature endorsed the Iberian Lynx Ex Situ Conservation Breeding Program to serve as a \"safety net\" by managing the captive population and also to \"help establish new Iberian lynx free-ranging populations through reintroduction programmes.\" Before release of captive-bred cats, their natural habit may be simulated to prepare them for life in the wild. A 2006 study used a non-intrusive monitoring system involving cameras to monitor the demographics of both lynxes and rabbits residing in Sierra Morena. Supplemental food sources could be provided if wild rabbits suffered a decline.\n\nThe Iberian lynx and its habitat are fully protected, and they are no longer legally hunted. Threats include habitat loss, vehicle strikes, poisoning, feral dogs, illegal poaching, and occasional outbreaks of feline leukemia. Chronic renal illness affects some captive animals. Habitat loss is due mainly to infrastructure improvement, urban and resort development and tree monocultivation, which fragments the lynx's distribution. In the 20th century, rabbit diseases such as myxomatosis and hemorrhagic disease resulted in a dramatic decline of its main prey; outbreaks have been reported into the 2010s. Accidental vehicle strikes are the leading cause of unnatural death; The death toll on Spanish roads was 14 in 2013, and 21 in 2014. Illegal traps set for rabbits and foxes are other leading causes for lynx fatality.\n\nIn 2013, it was reported that the Iberian lynx possesses antibiotic resistant bacteria within its digestive tract, which may lead to more dangerous and difficult-to-treat infections and decrease the cat's fitness. A 2013 study suggests climate change may threaten the Iberian lynx species due to their inability to adapt well to new climates or it may lead them to relocate to areas that have a more suitable climate but fewer rabbits, increasing mortality.\n\nManagement efforts are being developed to conserve and restore the animal's native range. Officials intending to release captive-bred lynx look for areas of appropriate habitat, rabbit abundance, and acceptance by the local human population. About 90 million euros was spent on various conservation measures between 1994 and 2013. The European Union contributes up to 61% of funding.\n\nThe Iberian lynx species has declined by about 80% in the last 20 years. The cat was estimated to number 3,000 in 1960, about 400 in 2000, less than 200 in 2002, and possibly as few as 100 in March 2005. Doñana National Park and the Sierra de Andújar, Jaén had the only known breeding populations until the 2007 discovery of a previously unknown population of around 15 individuals in Castile-La Mancha (central Spain). In 2008, the Doñana population was assessed at 24 to 33, while the Sierra Morena group was believed to number 67 to 190 adults. The total population was estimated to be 99 to 158 adults, including the La Mancha population. The Iberian lynx was thus listed as Critically Endangered under C2a(i) on the IUCN Redlist.\n\nBeginning in 2009, the Iberian lynx was reintroduced into Guadalmellato, resulting in a population of 23 in 2013. Since 2010, the species has also been released in Guarrizas. Discussions were held with the Ministry of Environment on plans for releases in the Campanarios de Azaba area near Salamanca. In April 2013, it was reported that Andalusia's total wild population—only 94 in 2002—had tripled to 309 individuals. In July 2013, environmental groups confirmed the presence of a wild-born litter in the Province of Cáceres (Extremadura). A study published in July 2013 in \"Nature Climate Change\" advised that reintroduction programs take place in northern Iberia, suggesting that climate change would threaten rabbits in the south.\n\nOn 26 November 2014, 8 Iberian lynxes were released into Toledo, Spain; one of them traveled near Madrid, the first time in 40 years.\n\nThe presence of Iberian lynxes in Portugal, particularly in the south, has been verified. In 2014, the Institute for Nature Conservation and Forests signed contracts securing 2,000 hectares of land for Portugal's reintroduction project. On 16 December 2014, a pair of Iberian lynx was released into Guadiana Valley Natural Park near Mértola, Portugal. On 7 February 2015, another pair was released into the park, but the female was later found dead on 12 March 2015 after being poisoned in Mértola. The last pair of captive-bred Iberian lynxes were released into Guadiana Valley Nature Reserve on 12 May 2015. By the end of 2015 there were 400 lynx on the Iberian peninsula, the vast majority in Andalusia, in southern Spain, but with smaller new populations in the hills near Toledo, in Extremadura (south-western Spain) and in southern Portugal.\n\nThe reintroduction of Iberian lynx in Portugal has been a success; from 17 animals that were reintroduced, 12 have already established territories.\n\nSince a 2007 outbreak of feline leukemia virus (FeLV), wild lynxes are tested periodically for possible disease. September–December 2013 samples were negative for FeLV but one male became the first of his species to test positive for feline immunodeficiency virus (FIV) and was placed into quarantine.\n\nIn 2002, the Jerez Zoo confirmed it had three females and was developing a plan for a captive breeding program. One of those females was Saliega, captured as a kitten in April 2002. She became the first Iberian lynx to breed in captivity, giving birth to three healthy kittens on 29 March 2005 at the El Acebuche Breeding Center, in the Doñana Nature Park in Huelva, Spain. Over the following years, the number of births grew and additional breeding centers were opened. In March 2009, it was reported that 27 kittens had been born since the beginning of the program. In 2009, the Spanish government planned to build a €5.5 million breeding center in Zarza de Granadilla. In Portugal the Centro Nacional de Reprodução do Lince-Ibérico (CNRLI) established a breeding center in Silves.\n\nThere were 14 surviving kittens in 2008 and 15 in 2009. In 2010, intense rain and health issues resulted in lower reproductive success—14 born, 8 surviving—but the next year, breeding centers recorded 45 births with 26 surviving kittens. In 2012, breeding centers in Portugal and Spain reported a total of 44 survivors from 59 births, while 2013 saw a total of 44 survivors out of 53 born. In 2017, the total population of Iberian lynx reached 475 specimens.\n\nIn March 2013, it was reported that Iberian lynx embryos and oocytes had been collected and preserved for the first time. They were collected from Saliega and another female—both sterilized and retired from the breeding program—by Berlin's Leibniz Institute for Zoo and Wildlife Research and stored in liquid nitrogen at the Museo Nacional de Ciencias Naturales in Madrid for possible future breeding. In July 2014, the MNCN-CSIC announced they had produced sperm cells from the testicular tissue of sexually immature lynx.\n\nIberian lynx can be observed in captivity only at the Jerez Zoo, since December 2014 at the Lisbon Zoo, and since July 2016 at the Madrid Zoo. The Jerez animals integrate the breeding program, the two Lisbon lynxes were formerly in the Portuguese breeding center but are no longer suited for the program (the female had multiple failed pregnancies and the male has a form of epilepsy), and the two Madrid lynxes were equally retired from the breeding program for not being suited for reproduction.\n\nIn August 2012, researchers announced that the genome of the Iberian lynx had been sequenced. They also plan genetic testing of the remains of long-deceased lynx to quantify loss of genetic diversity and improve conservation programs. In December 2012, it was reported that researchers had located remains of 466 Iberian lynx in private and museum collections. However, it is estimated that 40% of specimens were lost over the preceding 20 years.\n\nGenetic diversity in the Iberian lynx is lower than in any other felids known to be genetically impoverished, including the cheetah (\"Acinonyx jubatus\"), Ngorongoro crater lions, and Scandinavia's Eurasian lynx. Researchers believe this may be a consequence of decreasing population sizes and isolation. A study published in 2013 indicated strong genetic differentiation between the Doñana and Andujar populations, due to both allelic frequencies and allelic composition. Doñana lynxes have differentiated more from the ancestral population as a result of their longer isolation and lower population size. The researchers suggested bringing the two groups together in order to lessen the degree of inbreeding.\n\n\n"}
{"id": "14190914", "url": "https://en.wikipedia.org/wiki?curid=14190914", "title": "Infinite Worlds (book)", "text": "Infinite Worlds (book)\n\nInfinite Worlds: An Illustrated Voyage to Planets Beyond Our Sun is a nonfiction book by Ray Villard and Lynette Cook about extrasolar planets, featuring Lynette Cook's artwork. The book covers topics from the Big Bang, to extrasolar planets (the main focus of the book), and the ultimate fate of the universe.\n\nFrom the book's description on the back cover:\nThe newly discovered planets are boggling astronomers' minds with their bizarre characteristics, including an unimagined diversity of sizes and orbits. In Lynette Cook's illustrations - many newly created for this book - we glimpse the landscapes and atmospheres that might adorn these planets. Ray Villard's text describes the state of astronomy today, imagines where it will take us in the coming years, ponders the chances of success for the Search for Extraterrestrial Intelligence (SETI), and explores the survivability of life in the context of an evolving and accelerating universe. Infinite Worlds is a cosmic adventure that brings the drama of creation and the beauty of the universe to anyone who has wondered at the night sky\n"}
{"id": "53170285", "url": "https://en.wikipedia.org/wiki?curid=53170285", "title": "Johann Jacob Bremi-Wolf", "text": "Johann Jacob Bremi-Wolf\n\nJohann Jacob Bremi-Wolf (25 May 1791, Dübendorf – 27 February 1857, Zürich) was a Swiss entomologist and \"Kunsthandwerker\" (art turner) in Zürich. He was deaf due to illness at the age of 11. His entomological herbarium is held by the Museum Wiesbaden. Other parts of his insect collection, especially Diptera are held by the .\n\n\n"}
{"id": "36532309", "url": "https://en.wikipedia.org/wiki?curid=36532309", "title": "John Fulton (instrument maker)", "text": "John Fulton (instrument maker)\n\nJohn Fulton (1803–1853), was originally a cobbler or shoemaker by trade. He built three orrerys in a workshop attached to at his home, now demolished, in the Kirton Brae area of Fenwick and was eventually appointed instrument maker to King William IV, moving to London, but retiring to Fenwick. He is buried in the Fenwick Kirk graveyard.\n\nIt is recorded that John's father, also a cobbler, was a subscribing member to the library set up in the village by the Fenwick Weavers. With access to this library, John pursued his interest in astronomy, mathematics, physics, and other disciplines that led to his career as an instrument maker of outstanding ability and achievement. Largely self-taught, he studied botany, learned several foreign languages, constructed a ‘velocipede’ or early bicycle, and experimented with the production of coal gas. He had left school at the age of only thirteen.\n\nAstronomy held a particular fascination for him, so much so that he was prompted to construct, in his spare time in the years between 1823 and 1833, three working models of the solar system, known as orrerys. The third of these is now on display in Glasgow's Kelvingrove Art Gallery and Museum: it was the most intricate and took him four years to finish. It measured 1000mm x 3000mm x 3000mm. Entirely his own work, it has 175 wheels and more than 200 moving parts and is acknowledged to be one of the best in the world. The Society of Arts, who awarded him a silver medal, calculated that his third orrery was the most perfect built up to that time.\n\nFulton took the orrery on a tour of the United Kingdom. Such was the public interest that in 1869 a group of Glasgow businessmen led by William Walker bought the orrery for the city. It was brought up from London and then toured around Glasgow schools and museums until the 1930s when it found a more permanent home in the Old Glasgow Museum.\n\nA local story relates that Fulton 'borrowed' his grandmother’s candlesticks and melted them down to provide the brass for his first orrery model.\n\nThis is the public meeting hall for Fenwick, maintained by East Ayrshire Council. It was previously the Guthrie Memorial Free Church of 1844, and following a worldwide fund raising campaign sufficient funds had been raised by 1919 and the hall was opened in 1920.\n\n\n"}
{"id": "12083999", "url": "https://en.wikipedia.org/wiki?curid=12083999", "title": "Josef Fahringer", "text": "Josef Fahringer\n\nJosef Fahringer (21 December 1876 – 18 December 1950) was an Austrian entomologist from Baden bei Wien.\n\nHe obtained a doctorate at the University of Vienna in 1904 and taught at a middle school in Vienna from 1904 to 1907. He then taught at Brüx from 1907 to 1910, and at Brünn from 1910 to 1913. Following military service as a captain during the First World War, he returned as a schoolteacher to Vienna, where in 1928 he was named director of the school. During his career, he took research trips to Bosnia-Herzegovina, Dalmatia, Italy and Turkey.\n\nHe published the first modern monograph on Braconidae: \"Opuscula braconolocica\" (4 parts, 1925–37). A specialist of this group, he also made contributions regarding the systematics of other parasitic Hymenoptera.\n\n"}
{"id": "610757", "url": "https://en.wikipedia.org/wiki?curid=610757", "title": "Knowledge level", "text": "Knowledge level\n\nIn artificial intelligence, knowledge-based agents draw on a pool of logical sentences to infer conclusions about the world. At the knowledge level, we only need to specify what the agent knows and what its goals are; a logical abstraction separate from details of implementation.\n\nThis notion of knowledge level was first introduced by Allen Newell in the 1980s, to have a way to rationalize an agent's behavior. The agent takes actions based on knowledge it possesses, in an attempt to reach specific goals. It chooses actions according to the principle of rationality.\n\nBeneath the knowledge level resides the symbol level. Whereas the knowledge level is \"world\" oriented, namely that it concerns the environment in which the agent operates, the symbol level is \"system\" oriented, in that it includes the mechanisms the agent has available to operate. The knowledge level \"rationalizes\" the agent's behavior, while the symbol level \"mechanizes\" the agent's behavior.\n\nFor example, in a computer program, the knowledge level consists of the information contained in its data structures that it uses to perform certain actions. The symbol level consists of the program's algorithms, the data structures themselves, and so on.\n\n\n"}
{"id": "18676955", "url": "https://en.wikipedia.org/wiki?curid=18676955", "title": "Kuhn vs. Popper", "text": "Kuhn vs. Popper\n\nKuhn vs. Popper: The Struggle for the Soul of Science is a 2003 book by sociologist Steve Fuller, in which the author discusses and criticizes the philosophers of science Thomas Kuhn and Karl Popper. The book, published by Columbia University Press, received several negative reviews, but was also made Book of the Month by \"Popular Science\" magazine.\n\nFuller uses the 1965 meeting between Thomas Kuhn and Karl Popper, in which they discussed the philosophy of science, as a point of departure to discuss how their respective philosophies have been received by the media, the public, and scholars.\n\nAcademic Rupert Read called the book worthless, and wrote that it presented an over-simplified and distorted view of both Popper and Kuhn. \"The Economist\" wrote that the book was not thorough enough to be convincing. The mass circulation US magazine \"Popular Science\" made the book Book of the Month in February 2005. A UK-based website, also called 'Popular Science' but bearing no relation to the magazine, wrote that \"Fuller rightly points out some of the flaws in both Popper and Kuhn's approach\", but added that he wasted an opportunity to explain the philosophy of science in a way that ordinary readers would find useful.\n\n\n"}
{"id": "17908103", "url": "https://en.wikipedia.org/wiki?curid=17908103", "title": "Lewis and Clark Landing", "text": "Lewis and Clark Landing\n\nLewis and Clark Landing is a public park located at 515 North Riverfront Drive in Downtown Omaha, Nebraska . This park is situated along the eight-foot-tall (2.4 m) river walk of the Missouri River just north of U.S. Interstate 480.\n\nLewis and Clark Landing is the original landing site of the 1804 Lewis and Clark Expedition. The Lewis and Clark Expedition took place from 1804 to 1806. The purpose of the expedition was to explore the land which the United States had purchased from France through the Louisiana Purchase in 1803. Lewis and Clark Landing now sits on property formerly owned by ASARCO, which maintained a lead refinery there that closed in 1997. HDR Inc. won an award from the United States Environmental Protection Agency for their work on remediation of the Lewis and Clark Landing.\n\nThe park has a number of distinct features including as a walking trail which follows the riverfront and a bike trail which takes riders west to Miller's Landing and another trail which leads to the Heartland of America Park. The Martin Luther King Jr. Pedestrian Bridge, with interpretive exhibits, connects to CenturyLink Center Omaha. The park also includes the Omaha Firefighter's Memorial Monument and the second largest labor monument in the United States. The park contains a walking trail which follows the riverfront and sections of a bike trail that connect to Omaha's bike trail system. The walking trail also connects to the Bob Kerrey Pedestrian Bridge that spans the river and joins Omaha with Council Bluffs, Iowa. There is expansive area for festivals and events and there are a number of tables with umbrellas and chairs that offer a chance to relax and take in the riverfront experience. Additional attractions include a \"Monument to Labor\" sculpture, Lewis and Clark interpretive exhibits, jumping fountains where children can play, and a historical marker on site.\n\nThe park is immediately down the trail from Omaha's new National Park Service Regional Headquarters. The office houses the superintendent of the Lewis and Clark National Historic Trail.\n\nEvery summer the Landing and Heartland of America Park host a free concert series. The Annual Playing with Fire concerts began in 2004.\n\n\n"}
{"id": "41883177", "url": "https://en.wikipedia.org/wiki?curid=41883177", "title": "List of biophysically important macromolecular crystal structures", "text": "List of biophysically important macromolecular crystal structures\n\nCrystal structures of protein and nucleic acid molecules and their complexes are central to the practice of most parts of biophysics, and have shaped much of what we understand scientifically at the atomic-detail level of biology. Their importance is underlined by the United Nations declaring 2014 as the International Year of Crystallography, as the 100th anniversary of Max von Laue's 1914 Nobel prize for discovering the diffraction of X-rays by crystals. This chronological list of biophysically notable protein and nucleic acid structures is loosely based on a review in the Biophysical Journal. The list includes all the first dozen distinct structures, those that broke new ground in subject or method, and those that became model systems for work in future biophysical areas of research.\n\n1960 - Myoglobin was the very first high-resolution crystal structure of a protein molecule. Myoglobin cradles an iron-containing heme group that reversibly binds oxygen for use in powering muscle fibers, and those first crystals were of myoglobin from the sperm whale, whose muscles need copious oxygen storage for deep dives. The myoglobin 3-dimensional structure is made up of 8 alpha-helices, and the crystal structure showed that their conformation was right-handed and very closely matched the geometry proposed by Linus Pauling, with 3.6 residues per turn and backbone hydrogen bonds from the peptide NH of one residue to the peptide CO of residue i+4. Myoglobin is a model system for many types of biophysical studies, especially involving the binding process of small ligands such as oxygen and carbon monoxide.\n\n1960 - The Hemoglobin crystal structure showed a tetramer of two related chain types and was solved at much lower resolution than the monomeric myoglobin, but it clearly had the same basic 8-helix architecture (now called the \"globin fold\"). Further hemoglobin crystal structures at higher resolution [PDB 1MHB, 1DHB) soon showed the coupled change of both local and quaternary conformation between the oxy and deoxy states of hemoglobin, which explains the cooperativity of oxygen binding in the blood and the allosteric effect of factors such as pH and DPG. For decades hemoglobin was the primary teaching example for the concept of allostery, as well as being an intensive focus of research and discussion on allostery. In 1909, hemoglobin crystals from >100 species were used to relate taxonomy to molecular properties. That book was cited by Perutz in the 1938 report of horse hemoglobin crystals that began his long saga to solve the crystal structure. Hemoglobin crystals are pleochroic - dark red in two directions and pale red in the third - because of the orientation of the hemes, and the bright Soret band of the heme porphyrin groups is used in spectroscopic analysis of hemoglobin ligand binding.\n\n1965 - Hen-egg-white lysozyme (PDB file 1lyz). was the first crystal structure of an enzyme (it cleaves small carbohydrates into simple sugars), used for early studies of enzyme mechanism. It contained beta sheet (antiparallel) as well as helices, and was also the first macromolecular structure to have its atomic coordinates refined (in real space). The starting material for preparation can be bought at the grocery store, and hen-egg lysozyme crystallizes very readily in many different space groups; it is the favorite test case for new crystallographic experiments and instruments. Recent examples are nanocrystals of lysozyme for free-electron laser data collection and microcrystals for micro electron diffraction.\n\n1967 - Ribonuclease A (PDB file 2RSA) is an RNA-cleaving enzyme stabilized by 4 disulfide bonds. It was used in Anfinsen's seminal research on protein folding which led to the concept that a protein's 3-dimensional structure was determined by its amino-acid sequence. Ribonuclease S, the cleaved, two-component form studied by Fred Richards, was also enzymatically active, had a nearly identical crystal structure (PDB file 1RNS), and was shown to be catalytically active even in the crystal, helping dispel doubts about the relevance of protein crystal structures to biological function.\n\n1967 - The serine proteases are a historically very important group of enzyme structures, because collectively they illuminated catalytic mechanism (in their case, by the Ser-His-Asp \"catalytic triad\"), the basis of differing substrate specificities, and the activation mechanism by which a controlled enzymatic cleavage buries the new chain end to properly rearrange the active site. The early crystal structures included chymotrypsin (PDB file 2CHA), chymotrypsinogen (PDB file 1CHG), trypsin (PDB file 1PTN), and elastase (PDB file 1EST). They also were the first protein structures that showed two near-identical domains, presumably related by gene duplication. One reason for their wide use as textbook and classroom examples was the insertion-code numbering system (hated by all computer programmers), which made Ser195 and His57 consistent and memorable despite the protein-specific sequence differences.\n\n1968 - Papain\n\n1969 - Carboxypeptidase A is a zinc metalloprotease. Its crystal structure (PDB file 1CPA) showed the first parallel beta structure: a large, twisted, central sheet of 8 strands with the active-site Zn located at the C-terminal end of the middle strands and the sheet flanked on both sides with alpha helices. It is an exopeptidase that cleaves peptides or proteins from the carboxy-terminal end rather than internal to the sequence. Later a small protein inhibitor of carboxypeptidase was solved (PDB file 4CPA) that mechanically stops the catalysis by presenting its C-terminal end just sticking out from between a ring of disulfide bonds with tight structure behind it, preventing the enzyme from sucking in the chain past the first residue.\n\n1969 - Subtilisin\n\n1970 - Lactate dehydrogenase\n\n1970 - Basic pancreatic trypsin inhibitor, or BPTI,\n\n1970 - Rubredoxin\n\n1971 - Insulin (PDB file 1INS) is a hormone central to the metabolism of sugar and fat storage, and important in human diseases such as obesity and diabetes. It is biophysically notable for its Zn binding, its equilibrium between monomer, dimer, and hexamer states, its ability to form crystals in vivo, and its synthesis as a longer \"pro\" form which is then cleaved to fold up as the active 2-chain, SS-linked monomer. Insulin was a success of NASA's crystal-growth program on the space shuttle, producing bulk preparations of very uniform tiny crystals for controlled dosage.\n\n1971 - Staphylococcal nuclease\n\n1971 - Cytochrome C\n\n1974 - T4 phage lysozyme\n\n1974 - Immunoglobulins\n\n1975 - Cu,Zn Superoxide dismutase\n\n1976 - Transfer RNA\n\n1976 - Triose phosphate isomerase\n\n1976 - Rhizopuspepsin\n\n1976 - Endothiapepsin\n\n1976 - Penicillopepsin\n\n1978 - Icosahedral virus\n\n1981 - Dickerson B-form DNA dodecamer\n\n1981 - Crambin\n\n1985 - Calmodulin\n\n1985 - DNA polymerase\n\n1985 - Photosynthetic reaction center\n\n1986 - Repressor/DNA interactions\n\n1987 Major histocompatibility complex'\n\n1987 Ubiquitin\n\n1987 ROP protein\n\n1989 HIV-1 protease\n\n1990 Bacteriorhodopsin\n\n1991 GCN4 coiled coil\n\n1991 HIV-1 reverse transcriptase\n\n1993 Beta helix of Pectate lyase\n\n1994 Collagen\n\n1994 Barnase/barstar complex\n\n1994 F1 ATPase\n\n1995 Heterotrimeric G proteins\n\n1996 Green fluorescent protein\n\n1996 CDK/cyclin complex\n\n1996 - Kinesin motor protein\n\n1997 GroEL/ES chaperone\n\n1997 Nucleosome\n\n1998 Group I self-splicing intron\n\n1998 - DNA topoisomerases perform the biologically important and necessary job of untangling DNA strands or helices that get entwined with each other or twisted too tightly during normal cellular processes such as the transcription of genetic information.\n\n1998 Tubulin alpha/beta dimer\n\n1998 Potassium channel\n\n1998 Holliday junction\n\n2000 Ribosome\n\n2000 AAA+ ATPase\n\n2002 Ankyrin repeats\n\n2003 TOP7 protein design\n\n2004 Cyanobacterial Circadian clock proteins\n\n2004 Riboswitch\n\n2006 Human exosome\n\n2007 G-protein-coupled receptor\n\n2009 The Vault particle is an intriguing new discovery of a large hollow particle common in cells, with several different suggestions for its possible biological function. The crystal structures (PDB files 2zuo, 2zv4, 2zv5 and 4hl8) show that each half of the vault is made up of 39 copies of a long 12-domain protein that swirl together to form the enclosure. Disorder at the very top and bottom ends suggests openings for possible access to the interior of the vault.\n\n2010 - Free-electron laser crystallography\n"}
{"id": "14238840", "url": "https://en.wikipedia.org/wiki?curid=14238840", "title": "List of scientific journals", "text": "List of scientific journals\n\nThe following is a partial list of scientific journals. There are thousands of scientific journals in publication, and many more have been published at various points in the past. The list given here is far from exhaustive, only containing some of the most influential, currently publishing journals in each field. As a rule of thumb, each field should be represented by more or less than ten positions, chosen by their impact factors and other ratings.\n\n\"Note\": there are many science magazines that are not scientific journals, including \"Scientific American\", \"New Scientist\", \"Australasian Science\" and others. They are not listed here.\n\nFor periodicals in the social sciences and humanities, see list of social science journals.\n\n\nThe journals listed below are the 10 highest-ranking chemistry journals that publish papers in all areas of chemistry, ranked according to the total number of references. The comprehensive list referenced above should be consulted for high-ranking journals in specific areas of chemistry.\n\n\n\n\n\n\n\n\nSee List of bioinformatics journals\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "20891413", "url": "https://en.wikipedia.org/wiki?curid=20891413", "title": "Local standard of rest", "text": "Local standard of rest\n\nIn astronomy, the local standard of rest or LSR follows the mean motion of material in the Milky Way in the neighborhood of the Sun. The path of this material is not precisely circular. The Sun follows the solar circle (eccentricity \"e\" < 0.1 ) at a speed of about 255 km/s in a clockwise direction when viewed from the galactic north pole at a radius of ≈ 8.34 kpc about the center of the galaxy near Sgr A*, and has only a slight motion, towards the solar apex, relative to the LSR.\n\nThe LSR velocity is anywhere from 202–241 km/s. In 2014, very-long-baseline interferometry observations of maser emission in high mass star forming regions placed tight constraints on combinations of kinematic parameters such as the circular orbit speed of the Sun (Θ + V = 255.2 ± 5.1 km/s). There is significant correlation between the circular motion of the solar circle, the solar peculiar motion, and the predicted counterrotation of star-forming regions. Additionally, \"local\" estimates of the velocity of the LSR based on stars in the vicinity of the Sun may potentially yield different results than \"global\" estimates derived from motions relative to the Galactic center.\n\n\n"}
{"id": "43523981", "url": "https://en.wikipedia.org/wiki?curid=43523981", "title": "MBillionth Award South Asia", "text": "MBillionth Award South Asia\n\nThe mBillionth Award South Asia is presented each year since 2010 for socially valuable innovations in mobile communications in South Asia. The scheme is run by the Digital Empowerment Foundation, an Indian NGO seeking to improve access to and usage of digital communications.\n\nThe stated mission of the mBillionth Awards is \"to recognise and honor excellence in mobile communications across South Asia... recognising and felicitating mobile innovations, applications and content services delivery.\" Founded in 2010, the awards are directed towards those innovations in mobile communications that make for widespread adoption of the technology, promising empowerment and social gain. The scheme seeks further to facilitate networking among inventors and developers in this field.\n\nThe award is open to governments, individuals, private sector companies, academic institutions, and NGOs in any of the eight SAARC countries: Afghanistan, Bangladesh, Bhutan, India, Maldives, Nepal, Pakistan and Sri Lanka. Entry is by self-nomination.\n\nNominations for the award are pre-filtered and the final selection is carried out by a Grand Jury. In 2016 the number of nominations received was 348; of these 60 were considered by the Grand Jury of 15 members, who selected 25 winners and 6 Special Mentions.\n\nIn the first year of the awards, 2010, the categories were:\n\nSome of the winners of the mBillionth award have been as follows.\n\n"}
{"id": "18902", "url": "https://en.wikipedia.org/wiki?curid=18902", "title": "Mathematician", "text": "Mathematician\n\nA mathematician is someone who uses an extensive knowledge of mathematics in his or her work, typically to solve mathematical problems.\n\nMathematics is concerned with numbers, data, quantity, structure, space, models, and change.\n\nOne of the earliest known mathematicians was Thales of Miletus (c. 624–c.546 BC); he has been hailed as the first true mathematician and the first known individual to whom a mathematical discovery has been attributed. He is credited with the first use of deductive reasoning applied to geometry, by deriving four corollaries to Thales' Theorem.\n\nThe number of known mathematicians grew when Pythagoras of Samos (c. 582–c. 507 BC) established the Pythagorean School, whose doctrine it was that mathematics ruled the universe and whose motto was \"All is number\". It was the Pythagoreans who coined the term \"mathematics\", and with whom the study of mathematics for its own sake begins.\n\nThe first woman mathematician recorded by history was Hypatia of Alexandria (AD 350 - 415). She succeeded her father as Librarian at the Great Library and wrote many works on applied mathematics. Because of a political dispute, the Christian community in Alexandria punished her, presuming she was involved, by stripping her naked and scraping off her skin with clamshells (some say roofing tiles).\n\nScience and mathematics in the Islamic world during the Middle Ages followed various models and modes of funding varied based primarily on scholars. It was extensive patronage and strong intellectual policies implemented by specific rulers that allowed scientific knowledge to develop in many areas. Funding for translation of scientific texts in other languages was ongoing throughout the reign of certain caliphs, and it turned out that certain scholars became experts in the works they translated and in turn received further support for continuing to develop certain sciences. As these sciences received wider attention from the elite, more scholars were invited and funded to study particular sciences. An example of a translator and mathematician who benefited from this type of support was al-Khawarizmi. A notable feature of many scholars working under Muslim rule in medieval times is that they were often polymaths. Examples include the work on optics, maths and astronomy of Ibn al-Haytham.\n\nThe Renaissance brought an increased emphasis on mathematics and science to Europe. During this period of transition from a mainly feudal and ecclesiastical culture to a predominantly secular one, many notable mathematicians had other occupations: Luca Pacioli (founder of accounting); Niccolò Fontana Tartaglia (notable engineer and bookkeeper); Gerolamo Cardano (earliest founder of probability and binomial expansion); Robert Recorde (physician) and François Viète (lawyer).\n\nAs time passed, many mathematicians gravitated towards universities. An emphasis on free thinking and experimentation had begun in Britain's oldest universities beginning in the seventeenth century at Oxford with the scientists Robert Hooke and Robert Boyle, and at Cambridge where Isaac Newton was Lucasian Professor of Mathematics & Physics. Moving into the 19th century, the objective of universities all across Europe evolved from teaching the “regurgitation of knowledge” to “encourag[ing] productive thinking.” In 1810, Humboldt convinced the King of Prussia to build a university in Berlin based on Friedrich Schleiermacher’s liberal ideas; the goal was to demonstrate the process of the discovery of knowledge and to teach students to “take account of fundamental laws of science in all their thinking.” Thus, seminars and laboratories started to evolve.\n\nBritish universities of this period adopted some approaches familiar to the Italian and German universities, but as they already enjoyed substantial freedoms and autonomy the changes there had begun with the Age of Enlightenment, the same influences that inspired Humboldt. The Universities of Oxford and Cambridge emphasized the importance of research, arguably more authentically implementing Humboldt’s idea of a university than even German universities, which were subject to state authority. Overall, science (including mathematics) became the focus of universities in the 19th and 20th centuries. Students could conduct research in seminars or laboratories and began to produce doctoral theses with more scientific content. According to Humboldt, the mission of the University of Berlin was to pursue scientific knowledge. The German university system fostered professional, bureaucratically regulated scientific research performed in well-equipped laboratories, instead of the kind of research done by private and individual scholars in Great Britain and France. In fact, Rüegg asserts that the German system is responsible for the development of the modern research university because it focused on the idea of “freedom of scientific research, teaching and study.”\n\nMathematicians usually cover a breadth of topics within mathematics in their undergraduate education, and then proceed to specialize in topics of their own choice at the graduate level. In some universities, a qualifying exam serves to test both the breadth and depth of a student's understanding of mathematics; the students, who pass, are permitted to work on a doctoral dissertation.\n\nMathematicians involved with solving problems with applications in real life are called applied mathematicians. Applied mathematicians are mathematical scientists who, with their specialized knowledge and professional methodology, approach many of the imposing problems presented in related scientific fields. With professional focus on a wide variety of problems, theoretical systems, and localized constructs, applied mathematicians work regularly in the study and formulation of mathematical models. Mathematicians and applied mathematicians are considered to be two of the STEM (science, technology, engineering, and mathematics) careers.\n\nThe discipline of applied mathematics concerns itself with mathematical methods that are typically used in science, engineering, business, and industry; thus, \"applied mathematics\" is a mathematical science with specialized knowledge. The term \"applied mathematics\" also describes the professional specialty in which mathematicians work on problems, often concrete but sometimes abstract. As professionals focused on problem solving, \"applied mathematicians\" look into the \"formulation, study, and use of mathematical models\" in science, engineering, business, and other areas of mathematical practice.\n\nPure mathematics is mathematics that studies entirely abstract concepts. From the eighteenth century onwards, this was a recognized category of mathematical activity, sometimes characterized as \"speculative mathematics\", and at variance with the trend towards meeting the needs of navigation, astronomy, physics, economics, engineering, and other applications.\n\nAnother insightful view put forth is that \"pure mathematics is not necessarily applied mathematics\": it is possible to study abstract entities with respect to their intrinsic nature, and not be concerned with how they manifest in the real world. Even though the pure and applied viewpoints are distinct philosophical positions, in practice there is much overlap in the activity of pure and applied mathematicians.\n\nTo develop accurate models for describing the real world, many applied mathematicians draw on tools and techniques that are often considered to be \"pure\" mathematics. On the other hand, many pure mathematicians draw on natural and social phenomena as inspiration for their abstract research.\n\nMany professional mathematicians also engage in the teaching of mathematics. Duties may include:\n\nMany careers in mathematics outside of universities involve consulting. For instance, actuaries assemble and analyze data to estimate the probability and likely cost of the occurrence of an event such as death, sickness, injury, disability, or loss of property. Actuaries also address financial questions, including those involving the level of pension contributions required to produce a certain retirement income and the way in which a company should invest resources to maximize its return on investments in light of potential risk. Using their broad knowledge, actuaries help design and price insurance policies, pension plans, and other financial strategies in a manner which will help ensure that the plans are maintained on a sound financial basis.\n\nAs another example, mathematical finance will derive and extend the mathematical or numerical models without necessarily establishing a link to financial theory, taking observed market prices as input. Mathematical consistency is required, not compatibility with economic theory. Thus, for example, while a financial economist might study the structural reasons why a company may have a certain share price, a financial mathematician may take the share price as a given, and attempt to use stochastic calculus to obtain the corresponding value of derivatives of the stock (\"see: Valuation of options; Financial modeling\").\n\nAccording to the Dictionary of Occupational Titles occupations in mathematics include the following.\n\n\nThe following are quotations about mathematicians, or by mathematicians.\n\nThere is no Nobel Prize in mathematics, though sometimes mathematicians have won the Nobel Prize in a different field, such as economics. Prominent prizes in mathematics include the Abel Prize, the Chern Medal, the Fields Medal, the Gauss Prize, the Nemmers Prize, the Balzan Prize, the Crafoord Prize, the Shaw Prize, the Steele Prize, the Wolf Prize, the Schock Prize, and the Nevanlinna Prize.\n\nThe American Mathematical Society, Association for Women in Mathematics, and other mathematical societies offer several prizes aimed at increasing the representation of women and minorities in the future of mathematics.\n\nSeveral well known mathematicians have written autobiographies in part to explain to a general audience what it is about mathematics that has made them want to devote their lives to its study. These provide some of the best glimpses into what it means to be a mathematician. The following list contains some works that are not autobiographies, but rather essays on mathematics and mathematicians with strong autobiographical elements.\n\n\n"}
{"id": "50703881", "url": "https://en.wikipedia.org/wiki?curid=50703881", "title": "National Defense College of the United Arab Emirates", "text": "National Defense College of the United Arab Emirates\n\nThe National Defense College of the United Arab Emirates, or NDC, is an education organization in Abu Dhabi, United Arab Emirates, that provides advanced training for both senior military officers and civilians. It was officially opened in December 2013 by Sheikh Mohammed bin Zayed Al Nahyan, Crown Prince of Abu Dhabi and Deputy Supreme Commander of the UAE Armed Forces. Its first Dean was John R. Ballard, a former US Marine. Its current Dean is Thomas Drohan. Among its faculty is Joel Hayward, a \"noted scholar of war and strategy\", whom the daily newspaper \"Al Kaleej\" calls \"a world authority on international conflict and strategy\".\n"}
{"id": "7820422", "url": "https://en.wikipedia.org/wiki?curid=7820422", "title": "Nivarox", "text": "Nivarox\n\nNivarox (full business name Nivarox - FAR SA) is a Swiss company formed by a merger in 1984 between Nivarox SA and Fabriques d'Assortiments Réunis (FAR). It is currently owned by the Swatch Group. Nivarox is also the trade name of the metallic alloy from which its products are fabricated. Its notable property is that its coefficient of elasticity is remarkably constant with temperature. Nivarox is most famous for producing hairsprings which are attached to the balance wheel inside a mechanical watch movement, as well as mainsprings which provide the motive power for the watch.\n\nThe Nivarox story began in 1933 when Dr. Straumann perfected the process of hairspring manufacturing in his Waldenbourg laboratory. FAR was the corporate name chosen in 1932 for the entity comprising several companies and subsidiaries located in Le Locle, Switzerland, manufacturing various watch components.\n\nAs a trade name, Nivarox is a German acronym for \"Nicht variabel oxydfest\" (G.) or \"Non-Variable Non-Oxidizing\" (E.). The Nivarox alloy is a nickel iron alloy used mainly in the watch industry for hairsprings for balance wheels, but also in other micro-machine industries and in certain medical equipment and surgical instruments, in the same category as Elinvar, Ni-Span, Vibralloy, and other similar alloys. The \"non-variable\" refers to the alloy's most notable property: that it has a low temperature coefficient of elasticity; its elasticity does not change much with temperature, There are several versions of the Nivarox alloy depending upon the intended application: Nivarox-CT, but also with suffixes CTC, M, W. Chemical compositions vary in wt% as follows for all Nivarox alloys : Iron as balance, a wide variation in nickel between 30-40%, beryllium 0.7-1%, some versions have molybdenum at 6-9% while others have instead chromium 8%, titanium is present in some compositions at 1%, manganese at 0.7-0.8%, silicon 0.1-0.2% and carbon in traces up to 0.2%. A typical composition would be for the early version Nivarox-CT (by wt %) : Fe 54%, Ni 38%, Cr 8%, Ti 1%, Si 0.2%, Mn 0.8%, Be 0.9%, C < 0.1%. \n\nWhen used for critical watch components, the alloy reduces errors due to temperature variation. Hairsprings made of this alloy have a spring constant which does not vary with temperature, allowing the watch's balance wheel, its timekeeping element, to keep better time. Along with the earlier alloy Elinvar, this alloy made obsolete the expensive compensation balance used in precision timepieces in the 19th century. Nivarox springs are now used by most watchmakers worldwide, with a global market share of 90%. The alloys also see limited use for specific components of sensitive scientific instruments.\n"}
{"id": "594964", "url": "https://en.wikipedia.org/wiki?curid=594964", "title": "Periodical cicadas", "text": "Periodical cicadas\n\nMagicicada is the genus of the 13-year and 17-year periodical cicadas of eastern North America. Although they are sometimes called \"locusts\", this is a misnomer, as cicadas belong to the taxonomic order Hemiptera (true bugs), suborder Auchenorrhyncha, while locusts are grasshoppers belonging to the order Orthoptera. \"Magicicada\" belongs to the tribe Lamotialnini, a group of cicada genera with representatives in Australia, Africa, and Asia, as well as the Americas.\n\n\"Magicicada\" species spend most of their 13- and 17-year lives underground feeding on xylem fluids from the roots of deciduous forest trees in the eastern United States. After 13 or 17 years, mature cicada nymphs emerge in the springtime at any given locality, synchronously and in tremendous numbers. After such a prolonged developmental phase, the adults are active for about 4 to 6 weeks. The males aggregate into chorus centers and attract mates. Within two months of the original emergence, the lifecycle is complete, the eggs have been laid, and the adult cicadas are gone for another 13 or 17 years.\n\nThe familiar winged imago (adult) periodical cicada has red eyes and a black dorsal thorax. The wings are translucent and have orange veins. The underside of the abdomen may be black, orange, or striped with orange and black, depending on the species.\n\nAdults are typically , depending on species, slightly smaller than most of the annual cicada species found in the same regions of the United States. Mature females are slightly larger than males.\n\n\"Magicicada\" males typically form large aggregations that sing in chorus to attract receptive females. Different species have different characteristic calling songs. The call of decim periodical cicadas is said to resemble someone calling \"weeeee-whoa\" or \"Pharaoh\". The cassini and decula periodic cicadas (including \"M. tredecula\") have songs that intersperse buzzing and ticking sounds.\n\nCicadas do not sting and do not normally bite. Like other Auchenorrhyncha bugs, they have mouthparts used in piercing plants and sucking their sap. A cicada's proboscis can pierce human skin when it is handled, which is painful, but in no other way harmful. These cicadas are not venomous, and no evidence shows they transmit diseases. They pose little threat to mature vegetation, although planting new trees or shrubs is best postponed until after an expected emergence of the periodical cicadas. Mature plants rarely suffer lasting damage, although twig die-off or flagging can result from egg-laying. Young trees or shrubs can be covered with cheesecloth or a similar material to prevent damage during the oviposition period, which begins about a week after the first adults emerge and lasts until the females have died.\n\nNearly all cicadas spend years underground as juveniles, before emerging above ground for a short adult stage of several weeks to a few months. The seven periodical cicada species are so named because, in any one location, all of the members of the population are developmentally synchronized—they emerge as adults all at once in the same year. This periodicity is especially remarkable because their lifecycles are so long—13 or 17 years. Cicadas of all other species (perhaps 3000 worldwide) are not synchronized, so some adults mature each summer and emerge while the rest of the population continues to develop underground. Many people refer to these nonperiodical species as annual cicadas since some are seen every summer. The few known lifecycles of annual species range from two to 10 years, although some could be longer.\n\nThe nymphs of the periodical cicadas live underground, usually within of the surface, feeding on the juices of plant roots. The nymphs of the periodical cicada undergo five instar stages in their development underground. It has been suggested that the difference in the 13- and 17-year lifecycle is the time it takes for the second instar to mature. While underground, the nymphs move deeper below ground, feeding on larger roots.\n\nThe nymphs emerge on a spring evening when the soil temperature at about depth is above . In most years in the United States, this works out to late April or early May in the far south, and late May to early June in the far north. Emerging nymphs climb to a suitable place on the nearby vegetation to complete their transformation into adults. They molt one last time and then spend about six days in the trees waiting for their exoskeletons to harden completely. Just after this final molt, the teneral adults are white, but darken within an hour.\n\nAdult periodical cicadas live only for a few weeks; by mid-July, all have disappeared. Their short adult lives have one purpose: reproduction. The males \"sing\" a species-specific mating song; like other cicadas, they produce loud sounds using their tymbals. Singing males of a single \"Magicicada\" species form aggregations (choruses) that are sexually attractive to females. Males in these choruses alternate bouts of singing with short flights from tree to tree in search of receptive females. Most matings occur in \"chorus\" trees.\n\nReceptive females respond to the calls of conspecific males with timed wing-flicks, which attract the males for mating. The sounds of a \"chorus\"—a group of males—can be deafening and reach 100 dB. In addition to their \"calling\" or \"congregating\" song, males produce a distinctive courtship song when approaching an individual female.\n\nBoth males and females can mate multiple times, although most females seem to mate just once. After mating, the female cuts V-shaped slits in the bark of young twigs and lays about 20 eggs in each, for a total of 600 or more eggs. After about six to 10 weeks, the eggs hatch and the newborn nymphs drop to the ground, where they burrow and begin another 13- or 17-year cycle.\n\nThe nymphs emerge in large numbers about the same time, sometimes more than 1.5 million individuals per acre (>370/m²). Their mass emergence is a survival trait called predator satiation: for the first week after emergence, the periodical cicadas are an easy prey for reptiles, birds, squirrels, cats, and other small and large mammals. Early ideas maintained that the cicadas' overall survival mechanism was simply to overwhelm predators by their sheer numbers, ensuring the survival of most of the individuals. The emergence period of large prime numbers (13 and 17 years) was hypothesized to be a predator avoidance strategy adopted to eliminate the possibility of potential predators receiving periodic population boosts by synchronizing their own generations to divisors of the cicada emergence period. Another viewpoint holds that the prime-numbered developmental times represent an adaptation to prevent hybridization between broods with different cycles during a period of heavy selection pressure brought on by isolated and lowered populations during Pleistocene glacial stadia, and that predator satiation is a short-term maintenance strategy. This hypothesis was subsequently supported through a series of mathematical models, and stands as the most widely accepted explanation of the unusually lengthy and mathematically precise immature period of these insects. The length of the cycle was hypothesized to be controlled by a single gene locus, with the 13-year cycle dominant to the 17-year one, but this interpretation remains controversial and unexplored at the DNA level.\n\nCycles in cicada populations are significant enough to affect other animal and plant populations. For example, tree growth has been observed to decline the year before the emergence of a brood, because of the increased feeding on roots by nymphs. Moles, which feed on nymphs, have been observed to do well during the year before an emergence, but suffer population declines the following year, because of the reduced food source. Wild turkey populations respond favorably to increased nutrition in their food supply from gorging on cicada adults on the ground at the end of their lifecycles. Uneaten carcasses of periodic cicadas decompose on the ground, providing a resource pulse of nutrients to the forest community.\n\nCicada broods may also have a negative impact. Eastern gray squirrel populations have been negatively affected, because the egg-laying activity of female cicadas damaged upcoming mast crops.\n\nPeriodical cicadas are grouped into broods based on the calendar year when they emerge (see chart below and maps on www.magicicada.org). For example, in 2014, the 13-year brood XXII emerged in Louisiana and the 17-year brood III emerged in western Illinois and eastern Iowa.\n\nIn 1898, entomologist C. L. Marlatt assigned Roman numerals to 30 different broods of periodical cicadas: 17 distinct broods with a 17-year lifecycle, to which he assigned brood numbers I through XVII (with emerging years 1893 through 1909); plus 13 broods with a 13-year cycle, to which he assigned brood numbers XVIII through XXX (1893 through 1905).\n\nMany of these hypothetical 30 broods, however, have not been observed. Furthermore, two of the brood numbers assigned by Marlatt (broods XI and XXI) existed at one time, but have become extinct. The Marlatt numbering scheme has been retained for convenience (and because it clearly separates 13- and 17-year lifecycles), although today only 15 broods are known to survive.\n\nSeven recognized species are placed within \"Magicicada\". Three of them follow a 17-year cycle:\n\n\nFour more species follow a 13-year cycle:\n\n\nThese seven species are also sometimes grouped differently into three subgroups, the so-called Decim species group, Cassini species group, and Decula species group, reflecting strong similarities of each 17-year species with one or more species with a 13-year cycle.\n\nNote that while the original and correct spelling for Fisher's 17-year species is \"cassinii\", with two 'i's, a large majority of publications have spelled the name \"cassini\" since the mid-1960s. However, the original spelling has been maintained throughout by taxonomic catalogues, and the rules of nomenclature support the priority of \"cassinii\" (Article 33.4). The correct spelling for the 13-year relative is \"tredecassini\".\n\nThe 17-year periodical cicadas are distributed across the eastern, upper midwestern, and Great Plains states within the U.S., while the 13-year cicadas occur in the southern and Mississippi Valley states, but some may overlap slightly. For example, Broods IV (17-year cycle) and XIX (13-year cycle) overlap in western Missouri and eastern Oklahoma. Their emergences should again coincide in 2219, 2440, 2661, etc., as they did in 1998 (although distributions change slightly from generation to generation and older distribution maps can be unreliable.). An effort is currently underway to generate new distribution maps of all periodical cicada broods. This effort makes use of crowdsourced records and records collected by entomologists.\n\nNot only are the periodical cicada lifecycles curious for their prime numbers 13 or 17, but also their evolution is intricately tied to one- and four-year changes in their lifecycles. One-year changes are less common than four-year changes and are probably tied to variation in local climatic conditions. Four-year early and late emergences are common and involve a much larger proportion of the population than one-year changes.\n\nRecent research suggests, in extant periodical cicadas, the 13- and 17-year lifecycles evolved at least eight different times in the last 4 million years and that different species with identical lifecycles developed their overlapping geographic distribution by synchronization of lifecycle to existing dominant populations. The same study estimates that the Decim species group split from the common ancestor of the Decula plus Cassini species groups around 4 million years ago (Mya). At around 2.5 Mya, the Cassini and Decula groups split from each other.\n\nThe Sota \"et al.\" (2013) paper also calculates that the first separation of extant 13-year cicadas from 17-year cicadas took place in the Decim group about 530,000 years ago when the southern \"M. tredecim\" split from the northern \"M. septendecim\". The second noteworthy event took place about 320,000 years ago with the split of the western Cassini group from its conspecifics to the east. The Decim and the Decula clades experienced similar western splits, but these are estimated to have taken place 270,000 and 230,000 years ago, respectively. The 13- and 17-year splits in Cassini and Decula took place after these events.\n\nThe 17-year cicadas largely occupy formerly glaciated territory, and as a result their phylogeographic relationships, reflect the effects of repeated contraction into glacial refugia (small islands of suitable habitat) and subsequent re-expansion during multiple interglacial periods. In each species group, Decim, Cassini, and Decula, the signature of the glacial periods is manifested today in three phylogeographic genetic subdivisions: one subgroup east of the Appalachians, one midwestern, and one on the far western edge of their range.\n\nThe Sota \"et al.\" data suggest that the founders of the southern 13-year cicada populations seen today originated from the Decim group. These were later joined by Cassini originating from the western Cassini clade and Decula originating from eastern, middle, and western Decula clades. As Cassini and Decula invaded the south, they became synchronized with the resident \"M. tredecim\". Today, these Cassini and Decula are known as \"M. tredecassini\" and \"M. tredecula\". More data is needed to lend support to this hypothesis and others hypotheses related to more recent 13- and 17-year splits involving \"M. neotredecim\" and \"M. tredecim\".\n\nHistorical accounts cite reports of 15- to 17-year recurrences of enormous numbers of noisy emergent cicadas (\"locusts\") written as early as 1733. Pehr Kalm, a Swedish naturalist visiting Pennsylvania and New Jersey in 1749 on behalf of his nation's government, observed in late May one such emergence. When reporting the event in a Swedish academic journal in 1756, Kalm wrote:\n\nKalm then described documents (including one from Benjamin Franklin) that had recorded the emergence from the ground of large numbers of cicadas in Pennsylvania in May 1715 and May 1732. He noted that the people who had prepared these documents had made no such reports in other years. Kalm further noted that others had seen cicadas only occasionally before the large swarms of 1749. He stated that he had not heard any cicadas in Pennsylvania and New Jersey in 1750 in the same months and areas in which he had heard many in 1749.\n\nKalm summarized his findings in a paper translated into English in 1771, stating:\n\nBased on Kalm's account and a specimen that Kalm had provided, in 1758 Carl Linnaeus named the insect \"Cicada septendecim\" in the tenth edition of his \"Systema Naturae\".\n\nIn 1766, Moses Bartram described in his \"Observations on the cicada, or locust of America, which appears periodically once in 16 or 17 years\" the next appearance of the brood that Kalm had observed in 1749. Bartram noted that upon hatching from eggs deposited in the twigs of trees, the young insects ran down to the earth and \"entered the first opening that they could find\". He reported that he had been able to discover them below the surface, but that others had reportedly found them deep.\n\nIn 1775, Thomas Jefferson recorded in his \"Garden Book\" the insect's 17-year periodicity, writing that an acquaintance remembered \"great locust years\" in 1724 and 1741, that he and others recalled another such year in 1754 and that the insects had again emerged from the ground at Monticello in 1775. He noted that the females lay their eggs in the small twigs of trees while above ground.\n\nIn April 1800, Benjamin Banneker, who lived near Ellicott's Mills, Maryland, wrote in his record book that he recalled a \"great locust year\" in 1749, a second in 1766 during which the insects appeared to be \"full as numerous as the first\", and a third in 1783. He predicted that the insects \"may be expected again in the year 1800, which is seventeen years since their third appearance to me\".\n\n\"Magicicada\" species are edible when cooked. They have historically been eaten by Native Americans, who roasted them in hot ovens, stirring them until they were well browned.\n\nCharles Lester Marlatt wrote in 1907:\n\n\n"}
{"id": "19812", "url": "https://en.wikipedia.org/wiki?curid=19812", "title": "Project Mercury", "text": "Project Mercury\n\nProject Mercury was the first human spaceflight program of the United States, running from 1958 through 1963. An early highlight of the Space Race, its goal was to put a man into Earth orbit and return him safely, ideally before the Soviet Union. Taken over from the US Air Force by the newly created civilian space agency NASA, it conducted twenty unmanned developmental flights (some using animals), and six successful flights by astronauts. The program, which took its name from Roman mythology, cost $ adjusted for inflation. The astronauts were collectively known as the \"Mercury Seven\", and each spacecraft was given a name ending with a \"7\" by its pilot.\n\nThe Space Race began with the 1957 launch of the Soviet satellite Sputnik 1. This came as a shock to the American public, and led to the creation of NASA to expedite existing US space exploration efforts, and place most of them under civilian control. After the successful launch of the Explorer 1 satellite in 1958, manned spaceflight became the next goal. The Soviet Union put the first human, cosmonaut Yuri Gagarin, into a single orbit aboard Vostok 1 on April 12, 1961. Shortly after this, on May 5, the US launched its first astronaut, Alan Shepard, on a suborbital flight. Soviet Gherman Titov followed with a day-long orbital flight in August 1961. The US reached its orbital goal on February 20, 1962, when John Glenn made three orbits around the Earth. When Mercury ended in May 1963, both nations had sent six people into space, but the Soviets led the US in total time spent in space.\n\nThe Mercury space capsule was produced by McDonnell Aircraft, and carried supplies of water, food and oxygen for about one day in a pressurized cabin. Mercury flights were launched from Cape Canaveral Air Force Station in Florida, on launch vehicles modified from the Redstone and Atlas D missiles. The capsule was fitted with a launch escape rocket to carry it safely away from the launch vehicle in case of a failure. The flight was designed to be controlled from the ground via the Manned Space Flight Network, a system of tracking and communications stations; back-up controls were outfitted on board. Small retrorockets were used to bring the spacecraft out of its orbit, after which an ablative heat shield protected it from the heat of atmospheric reentry. Finally, a parachute slowed the craft for a water landing. Both astronaut and capsule were recovered by helicopters deployed from a US Navy ship.\n\nThe Mercury project gained popularity, and its missions were followed by millions on radio and TV around the world. Its success laid the groundwork for Project Gemini, which carried two astronauts in each capsule and perfected space docking maneuvers essential for manned lunar landings in the subsequent Apollo program announced a few weeks after the first manned Mercury flight.\n\nProject Mercury was officially approved on October 7, 1958 and publicly announced on December 17. Originally called Project Astronaut, President Dwight Eisenhower felt that gave too much attention to the pilot. Instead, the name \"Mercury\" was chosen from classical mythology, which had already lent names to rockets like the Greek \"Atlas\" and Roman \"Jupiter\" for the SM-65 and PGM-19 missiles. It absorbed military projects with the same aim, such as the Air Force Man In Space Soonest.\n\nFollowing the end of World War II, a nuclear arms race evolved between the US and the Soviet Union (USSR). Since the USSR did not have bases in the western hemisphere from which to deploy bomber planes, Joseph Stalin decided to develop intercontinental ballistic missiles, which drove a missile race. The rocket technology in turn enabled both sides to develop Earth-orbiting satellites for communications, and gathering weather data and intelligence. Americans were shocked when the Soviet Union placed the first satellite into orbit in October 1957, leading to a growing fear that the US was falling into a \"missile gap\". A month later, the Soviets launched Sputnik 2, carrying a dog into orbit. Though the animal was not recovered alive, it was obvious their goal was manned spaceflight. Unable to disclose details of military space projects, President Eisenhower ordered the creation of a civilian space agency in charge of civilian and scientific space exploration. Based on the federal research agency National Advisory Committee for Aeronautics (NACA), it was named the National Aeronautics and Space Administration (NASA). It achieved its first goal, an American satellite in space, in 1958. The next goal was to put a man there.\n\nThe limit of space was defined at the time as a minimum altitude of , and the only way to reach it was by using rocket-powered boosters. This created risks for the pilot, including explosion, high g-forces and vibrations during lift off through a dense atmosphere, and temperatures of more than from air compression during reentry.\n\nIn space, pilots would require pressurized chambers or space suits to supply fresh air. While there, they would experience weightlessness, which could potentially cause disorientation. Further potential risks included radiation and micrometeoroid strikes, both of which would normally be absorbed in the atmosphere. All seemed possible to overcome: experience from satellites suggested micrometeoroid risk was negligible, and experiments in the early 1950s with simulated weightlessness, high g-forces on humans, and sending animals to the limit of space, all suggested potential problems could be overcome by known technologies. Finally, reentry was studied using the nuclear warheads of ballistic missiles, which demonstrated a blunt, forward-facing heat shield could solve the problem of heating.\n\nT. Keith Glennan had been appointed the first Administrator of NASA, with Hugh L. Dryden (last Director of NACA) as his Deputy, at the creation of the agency on October 1, 1958. Glennan would report to the president through the National Aeronautics and Space Council. The group responsible for Project Mercury was NASA's Space Task Group, and the goals of the program were to orbit a manned spacecraft around Earth, investigate the pilot's ability to function in space, and to recover both pilot and spacecraft safely. Existing technology and off-the-shelf equipment would be used wherever practical, the simplest and most reliable approach to system design would be followed, and an existing launch vehicle would be employed, together with a progressive test program. Spacecraft requirements included: a launch escape system to separate the spacecraft and its occupant from the launch vehicle in case of impending failure; attitude control for orientation of the spacecraft in orbit; a retrorocket system to bring the spacecraft out of orbit; drag braking blunt body for atmospheric reentry; and landing on water. To communicate with the spacecraft during an orbital mission, an extensive communications network had to be built. In keeping with his desire to keep from giving the US space program an overly military flavor, President Eisenhower at first hesitated to give the project top national priority (DX rating under the Defense Production Act), which meant that Mercury had to wait in line behind military projects for materials; however, this rating was granted in May 1959, a little more than a year and a half after Sputnik was launched.\n\nTwelve companies bid to build the Mercury spacecraft on a $20 million ($ adjusted for inflation) contract. In January 1959, McDonnell Aircraft Corporation was chosen to be prime contractor for the spacecraft. Two weeks earlier, North American Aviation, based in Los Angeles, was awarded a contract for Little Joe, a small rocket to be used for development of the launch escape system. The World Wide Tracking Network for communication between the ground and spacecraft during a flight was awarded to the Western Electric Company. Redstone rockets for suborbital launches were manufactured in Huntsville, Alabama by the Chrysler Corporation and Atlas rockets by Convair in San Diego, California. For manned launches, the Atlantic Missile Range at Cape Canaveral Air Force Station in Florida was made available by the USAF. This was also the site of the Mercury Control Center while the computing center of the communication network was in Goddard Space Center, Maryland. Little Joe rockets were launched from Wallops Island, Virginia. Astronaut training took place at Langley Research Center in Virginia, Lewis Flight Propulsion Laboratory in Cleveland, Ohio, and Naval Air Development Center Johnsville in Warminster, PA. Langley wind tunnels together with a rocket sled track at Holloman Air Force Base at Alamogordo, New Mexico were used for aerodynamic studies. Both Navy and Air Force aircraft were made available for the development of the spacecraft's landing system, and Navy ships and Navy and Marine Corps helicopters were made available for recovery. South of Cape Canaveral the town of Cocoa Beach boomed. From here, 75,000 people watched the first American orbital flight being launched in 1962.\n\nThe Mercury spacecraft's principal designer was Maxime Faget, who started research for manned spaceflight during the time of the NACA. It was long and wide; with the launch escape system added, the overall length was . With of habitable volume, the capsule was just large enough for a single crew member. Inside were 120 controls: 55 electrical switches, 30 fuses and 35 mechanical levers. The heaviest spacecraft, Mercury-Atlas 9, weighed fully loaded. Its outer skin was made of René 41, a nickel alloy able to withstand high temperatures.\n\nThe spacecraft was cone shaped, with a neck at the narrow end. It had a convex base, which carried a heat shield (Item 2 in the diagram below) consisting of an aluminum honeycomb covered with multiple layers of fiberglass. Strapped to it was a retropack (1) consisting of three rockets deployed to brake the spacecraft during reentry. Between these were three minor rockets for separating the spacecraft from the launch vehicle at orbital insertion. The straps that held the package could be severed when it was no longer needed. Next to the heat shield was the pressurized crew compartment (3). Inside, an astronaut would be strapped to a form-fitting seat with instruments in front of him and with his back to the heat shield. Underneath the seat was the environmental control system supplying oxygen and heat, scrubbing the air of CO, vapor and odors, and (on orbital flights) collecting urine. The recovery compartment (4) at the narrow end of the spacecraft contained three parachutes: a drogue to stabilize free fall and two main chutes, a primary and reserve. Between the heat shield and inner wall of the crew compartment was a landing skirt, deployed by letting down the heat shield before landing. On top of the recovery compartment was the antenna section (5) containing both antennas for communication and scanners for guiding spacecraft orientation. Attached was a flap used to ensure the spacecraft was faced heat shield first during reentry. A launch escape system (6) was mounted to the narrow end of the spacecraft containing three small solid-fueled rockets which could be fired briefly in a launch failure to separate the capsule safely from its booster. It would deploy the capsule's parachute for a landing nearby at sea. (See also Mission profile for details.)\n\nThe Mercury spacecraft did not have an on-board computer, instead relying on all computation for reentry to be calculated by computers on the ground, with their results (retrofire times and firing attitude) then transmitted to the spacecraft by radio while in flight. All computer systems used in the Mercury space program were housed in NASA facilities on Earth. The computer systems were IBM 701 computers. (See also Ground control for details.)\n\nThe astronaut lay in a sitting position with his back to the heat shield, which was found to be the position that best enabled a human to withstand the high g-forces of launch and reentry. A fiberglass seat was custom-molded from each astronaut's space-suited body for maximum support. Near his left hand was a manual abort handle to activate the launch escape system if necessary prior to or during liftoff, in case the automatic trigger failed.\n\nTo supplement the onboard environmental control system, he wore a pressure suit with its own oxygen supply, which would also cool him. A cabin atmosphere of pure oxygen at a low pressure of 5.5 psi (equivalent to an altitude of ) was chosen, rather than one with the same composition as air (nitrogen/oxygen) at sea level. This was easier to control, avoided the risk of decompression sickness (\"the bends\"), and also saved on spacecraft weight. Fires (which never occurred) would have to be extinguished by emptying the cabin of oxygen. In such case, or failure of the cabin pressure for any reason, the astronaut could make an emergency return to Earth, relying on his suit for survival. The astronauts normally flew with their visor up, which meant that the suit was not inflated. With the visor down and the suit inflated, the astronaut could only reach the side and bottom panels, where vital buttons and handles were placed.\n\nThe astronaut also wore electrodes on his chest to record his heart rhythm, a cuff that could take his blood pressure, and a rectal thermometer to record his temperature (this was replaced by an oral thermometer on the last flight). Data from these was sent to the ground during the flight. The astronaut normally drank water and ate food pellets.\n\nOnce in orbit, the spacecraft could be rotated in three directions: along its longitudinal axis (roll), left to right from the astronaut's point of view (yaw), and up or down (pitch). Movement was created by rocket-propelled thrusters which used hydrogen peroxide as a fuel. For orientation, the pilot could look through the window in front of him or he could look at a screen connected to a periscope with a camera which could be turned 360°.\n\nThe Mercury astronauts had taken part in the development of their spacecraft, and insisted that manual control, and a window, be elements of its design. As a result, spacecraft movement and other functions could be controlled three ways: remotely from the ground when passing over a ground station, automatically guided by onboard instruments, or manually by the astronaut, who could replace or override the two other methods. Experience validated the astronauts' insistence on manual controls. Without them, Gordon Cooper's manual reentry during the last flight would not have been possible.\n\nThe Mercury spacecraft design was modified three times by NASA between 1958 and 1959. After bidding by potential contractors had been completed, NASA selected the design submitted as \"C\" in November 1958. After it failed a test flight in July 1959, a final configuration, \"D\", emerged. The heat shield shape had been developed earlier in the 1950s through experiments with ballistic missiles, which had shown a blunt profile would create a shock wave that would lead most of the heat around the spacecraft. To further protect against heat, either a heat sink, or an ablative material, could be added to the shield. The heat sink would remove heat by the flow of the air inside the shock wave, whereas the ablative heat shield would remove heat by a controlled evaporation of the ablative material. After unmanned tests, the latter was chosen for manned flights. Apart from the capsule design, a rocket plane similar to the existing X-15 was considered. This approach was still too far from being able to make a spaceflight, and was consequently dropped. The heat shield and the stability of the spacecraft were tested in wind tunnels, and later in flight. The launch escape system was developed through unmanned flights. During a period of problems with development of the landing parachutes, alternative landing systems such as the Rogallo glider wing were considered, but ultimately scrapped.\n\nThe spacecraft were produced at McDonnell Aircraft, St. Louis, Missouri in clean rooms and tested in vacuum chambers at the McDonnell plant. The spacecraft had close to 600 subcontractors, such as Garrett AiResearch which built the spacecraft's environmental control system. Final quality control and preparations of the spacecraft were made at Hangar S at Cape Canaveral. NASA ordered 20 production spacecraft, numbered 1 through 20. Five of the 20, Nos. 10, 12, 15, 17, and 19, were not flown. Spacecraft No. 3 and No. 4 were destroyed during unmanned test flights. Spacecraft No. 11 sank and was recovered from the bottom of the Atlantic Ocean after 38 years. Some spacecraft were modified after initial production (refurbished after launch abort, modified for longer missions, etc.). A number of Mercury boilerplate spacecraft (made from non-flight materials or lacking production spacecraft systems) were also made by NASA and McDonnell. They were designed and used to test spacecraft recovery systems and the escape tower. McDonnell also built the spacecraft simulators used by the astronauts during training.\n\nA small launch vehicle ( long) called Little Joe was used for unmanned tests of the launch escape system, using a Mercury capsule with an escape tower mounted on it. Its main purpose was to test the system at a point called max-q, at which air pressure against the spacecraft peaked, making separation of the launch vehicle and spacecraft most difficult. It was also the point at which the astronaut was subjected to the heaviest vibrations. The Little Joe rocket used solid-fuel propellant and was originally designed in 1958 by the NACA for suborbital manned flights, but was redesigned for Project Mercury to simulate an Atlas-D launch. It was produced by North American Aviation. It was not able to change direction; instead its flight depended on the angle from which it was launched. Its maximum altitude was fully loaded. A Scout launch vehicle was used for a single flight intended to evaluate the tracking network; however, it failed and was destroyed from the ground shortly after launch.\n\nThe Mercury-Redstone Launch Vehicle, an tall (with capsule and escape system) single-stage launch vehicle used for suborbital (ballistic) flights. It had a liquid-fueled engine that burned alcohol and liquid oxygen producing about 75,000 pounds of thrust, which was not enough for orbital missions. It was a descendant of the German V-2, and developed for the U.S. Army during the early 1950s. It was modified for Project Mercury by removing the warhead and adding a collar for supporting the spacecraft together with material for damping vibrations during launch. Its rocket motor was produced by North American Aviation and its direction could be altered during flight by its fins. They worked in two ways: by directing the air around them, or by directing the thrust by their inner parts (or both at the same time). Both the Atlas-D and Redstone launch vehicles contained an automatic abort sensing system which allowed them to abort a launch by firing the launch escape system if something went wrong. The Jupiter rocket, also developed by Von Braun's team at the Redstone Arsenal in Huntsville, was considered as well for intermediate Mercury suborbital flights at a higher speed and altitude than Redstone, but this plan was dropped when it turned out that man-rating Jupiter for the Mercury program would actually cost more than flying an Atlas due to economics of scale. Jupiter's only use other than as a missile system was for the short-lived Juno II launch vehicle and keeping a full staff of technical personnel around solely to fly a few Mercury capsules would result in excessively high costs.\n\nOrbital missions required use of the Atlas LV-3B, a man-rated version of the Atlas D which was originally developed as the United States' first operational intercontinental ballistic missile (ICBM) by Convair for the Air Force during the mid-1950s. The Atlas was a \"one-and-one-half-stage\" rocket fueled by kerosene and liquid oxygen (LOX). The rocket by itself stood high; total height of the Atlas-Mercury space vehicle at launch was .\n\nThe Atlas first stage was a booster skirt with two engines burning liquid fuel. This together with the larger sustainer second stage gave it sufficient power to launch a Mercury spacecraft into orbit. Both stages fired from lift-off with the thrust from the second stage sustainer engine passing through an opening in the first stage. After separation from the first stage, the sustainer stage continued alone. The sustainer also steered the rocket by thrusters guided by gyroscopes. Smaller vernier rockets were added on its sides for precise control of maneuvers.\n\nNASA announced the following seven astronauts – known as the Mercury Seven – on April 9, 1959:\n\nShepard became the first American in space by making a suborbital flight in May 1961. He went on to fly in the Apollo program and became the only Mercury astronaut to walk on the Moon. Gus Grissom, who became the second American in space, also participated in the Gemini and Apollo programs, but died in January 1967 during a pre-launch test for Apollo 1. Glenn became the first American to orbit the Earth in February 1962, then quit NASA and went into politics, serving as a US Senator from 1974 to 1999, and returned to space in 1998 as a Payload Specialist aboard STS-95. Deke Slayton was grounded in 1962, but remained with NASA and was appointed Chief Astronaut at the beginning of Project Gemini. He remained in the position of senior astronaut, in charge of space crew flight assignments among many other responsibilities, until towards the end of Project Apollo, when he resigned and began training to fly on the Apollo-Soyuz Test Project in 1975, which he successfully did. Gordon Cooper became the last to fly in Mercury and made its longest flight, and also flew a Gemini mission. Carpenter's Mercury flight was his only trip into space. Schirra flew the third orbital Mercury mission, and then flew a Gemini mission. Three years later, he commanded the first manned Apollo mission, becoming the only person to fly in all three of those programs.\n\nOne of the astronauts' tasks was publicity; they gave interviews to the press and visited project manufacturing facilities to speak with those who worked on Project Mercury. To make their travels easier, they requested and got jet fighters for personal use. The press was especially fond of John Glenn, who was considered the best speaker of the seven. They sold their personal stories to \"Life\" magazine which portrayed them as patriotic, God-fearing family men. \"Life\" was also allowed to be at home with the families while the astronauts were in space. During the project, Grissom, Carpenter, Cooper, Schirra and Slayton stayed with their families at or near Langley Air Force Base; Glenn lived at the base and visited his family in Washington DC on weekends. Shepard lived with his family at Naval Air Station Oceana in Virginia.\n\nOther than Grissom, who was killed in the 1967 Apollo 1 fire, the other six survived past retirement and died between 1993 and 2016.\n\nPrior to Project Mercury, there was no protocol for selecting astronauts so NASA would set a far reaching precedent with both their selection process and initial choices for astronaut. At the end of 1958, various ideas for the selection pool were discussed privately within the national government and the civilian space program, and also among the public at large. Initially, there was the idea to issue a widespread public call to volunteers. Thrill seekers such as rock climbers and acrobats would have been allowed to apply but this idea was quickly shot down by NASA officials who understood that an undertaking such as space flight required individuals with professional training and education in flight engineering. By late 1958, NASA officials decided to move forward with test pilots being the heart of their selection pool. On President Eisenhower's insistence, the group was further narrowed down to active duty military test pilots, which set the number of candidates at 508 men. who were either USN or USMC naval aviation pilots (NAPs), or USAF pilots of Senior or Command rating. These men had long military records which would give NASA officials more background information to base their decisions on. Furthermore, these men were adept at flying the most advanced aircraft to date, giving them the best qualifications for the new position of astronaut. However, this selection excluded women since there were no female military test pilots at the time. It also excluded civilian NASA X-15 pilot Neil Armstrong, though he had been selected by the US Air Force in 1958 for its Man In Space Soonest program, which was replaced by Mercury. Although Armstrong had been a combat-experienced NAP during the Korean War, he left active duty in 1952. Armstrong became NASA's first civilian astronaut in 1962 when he was selected for NASA's second group, and became the first man on the Moon in 1969.\n\nIt was further stipulated that candidates should be between 25 and 40 years old, no taller than , and hold a college degree in a STEM subject. The college degree requirement excluded the USAF's X-1 pilot, then-Lt Col (later Brig Gen) Chuck Yeager, the first person to exceed the speed of sound. He later became a critic of the project, ridiculing the civilian space program, labeling astronauts as \"spam in a can.\" John Glenn did not have a college degree either, but used influential friends to make the selection committee accept him. USAF Capt (later Col) Joseph Kittinger, a USAF fighter pilot and stratosphere balloonist, met all the requirements but preferred to stay in his contemporary project. Other potential candidates declined because they did not believe that manned spaceflight had a future beyond Project Mercury. From the original 508, 110 candidates were selected for an interview, and from the interviews, 32 were selected for further physical and mental testing. Their health, vision, and hearing were examined, together with their tolerance to noise, vibrations, g-forces, personal isolation, and heat. In a special chamber, they were tested to see if they could perform their tasks under confusing conditions. The candidates had to answer more than 500 questions about themselves and describe what they saw in different images. Navy Lt (later Capt) Jim Lovell, who was later an astronaut in the Gemini and Apollo programs, did not pass the physical tests. After these tests it was intended to narrow the group down to six astronauts, but in the end it was decided to keep seven.\n\nThe astronauts went through a training program covering some of the same exercises that were used in their selection. They simulated the g-force profiles of launch and reentry in a centrifuge at the Naval Air Development Center, and were taught special breathing techniques necessary when subjected to more than 6 g. Weightlessness training took place in aircraft, first on the rear seat of a two-seater fighter and later inside converted and padded cargo aircraft. They practiced gaining control of a spinning spacecraft in a machine at the Lewis Flight Propulsion Laboratory called the Multi-Axis Spin-Test Inertia Facility (MASTIF), by using an attitude controller handle simulating the one in the spacecraft. A further measure for finding the right attitude in orbit was star and Earth recognition training in planetaria and simulators. Communication and flight procedures were practiced in flight simulators, first together with a single person assisting them and later with the Mission Control Center. Recovery was practiced in pools at Langley, and later at sea with frogmen and helicopter crews.\n\nA Redstone rocket was used to boost the capsule for 2 minutes and 30 seconds to an altitude of ; the capsule continued ascending on a ballistic curve after booster separation. The launch escape system was jettisoned at the same time. At the top of the curve, the spacecraft's retrorockets were fired for testing purposes; they were not necessary for reentry because orbital speed had not been attained. The spacecraft landed in the Atlantic Ocean. The suborbital mission took about 15 minutes, had an apogee altitude of , and a downrange distance of . From the time of booster-spacecraft separation until reentry where air started to slow down the spacecraft, the pilot would experience weightlessness as shown on the image. The recovery procedure would be the same as an orbital mission.\n\nPreparations for a mission started a month in advance with the selection of the primary and back-up astronaut; they would practice together for the mission. For three days prior to launch, the astronaut went through a special diet to minimize his need for defecating during the flight. On the morning of the trip he typically ate a steak breakfast. After having sensors applied to his body and being dressed in the pressure suit, he started breathing pure oxygen to prepare him for the atmosphere of the spacecraft. He arrived at the launch pad, took the elevator up the launch tower and entered the spacecraft two hours before launch. Once the astronaut was secured inside, the hatch was bolted, the launch area evacuated and the mobile tower rolled back. After this, the launch vehicle was filled with liquid oxygen. The entire procedure of preparing for launch and launching the spacecraft followed a time table called the countdown. It started a day in advance with a pre-count, in which all systems of the launch vehicle and spacecraft were checked. After that followed a 15-hour hold, during which pyrotechnics were installed. Then came the main countdown which for orbital flights started 6½ hours before launch (T – 390 min), counted backwards to launch (T = 0) and then forward until orbital insertion (T + 5 min).\n\nOn an orbital mission, the Atlas' rocket engines were ignited four seconds before lift-off. The launch vehicle was held to the ground by clamps and then released when sufficient thrust was built up at lift-off (A). After 30 seconds of flight, the point of maximum dynamic pressure against the vehicle was reached, at which the astronaut felt heavy vibrations. After 2 minutes and 10 seconds, the two outboard booster engines shut down and were released with the aft skirt, leaving the center sustainer engine running (B). At this point, the launch escape system was no longer needed, and was separated from the spacecraft by its jettison rocket (C). The space vehicle moved gradually to a horizontal attitude until, at an altitude of , the sustainer engine shut down and the spacecraft was inserted into orbit (D). This happened after 5 minutes and 10 seconds in a direction pointing east, whereby the spacecraft would gain speed from the rotation of the Earth. Here the spacecraft fired the three posigrade rockets for a second to separate it from the launch vehicle. Just before orbital insertion and sustainer engine cutoff, g-loads peaked at 8 g (6 g for a suborbital flight). In orbit, the spacecraft automatically turned 180°, pointed the retropackage forward and its nose 14.5° downward and kept this attitude for the rest of the orbital phase of the mission, as it was necessary for communication with the ground.\n\nOnce in orbit, it was not possible for the spacecraft to change its trajectory except by initiating reentry. Each orbit would typically take 88 minutes to complete. The lowest point of the orbit, called perigee, was at about altitude, and the highest point, called apogee, was about altitude. When leaving orbit (E), the angle of retrofire was 34° downward from the flight path angle. Retrorockets fired for 10 seconds each (F) in a sequence where one started 5 seconds after the other. During reentry (G), the astronaut would experience about 8 g (11–12 g on a suborbital mission). The temperature around the heat shield rose to and at the same time, there was a two-minute radio blackout due to ionization of the air around the spacecraft.\n\nAfter reentry, a small, drogue parachute (H) was deployed at for stabilizing the spacecraft's descent. The main parachute (I) was deployed at starting with a narrow opening that opened fully in a few seconds to lessen the strain on the lines. Just before hitting the water, the landing bag inflated from behind the heat shield to reduce the force of impact (J). Upon landing the parachutes were released. An antenna (K) was raised and sent out signals that could be traced by ships and helicopters. Further, a green marker dye was spread around the spacecraft to make its location more visible from the air. Frogmen brought in by helicopters inflated a collar around the craft to keep it upright in the water. The recovery helicopter hooked onto the spacecraft and the astronaut blew the escape hatch to exit the capsule. He was then hoisted aboard the helicopter that finally brought both him and the spacecraft to the ship.\n\nThe number of personnel supporting a Mercury mission was typically around 18,000, with about 15,000 people associated with recovery. Most of the others followed the spacecraft from the World Wide Tracking Network, a chain of 18 stations placed around the equator, which was based on a network used for satellites and made ready in 1960. It collected data from the spacecraft and provided two-way communication between the astronaut and the ground. Each station had a range of and a pass typically lasted 7 minutes. Mercury astronauts on the ground would take part of the Capsule Communicator or CAPCOM who communicated with the astronaut in orbit. Data from the spacecraft was sent to the ground, processed at the Goddard Space Center and relayed to the Mercury Control Center at Cape Canaveral. In the Control Center, the data was displayed on boards on each side of a world map, which showed the position of the spacecraft, its ground track and the place it could land in an emergency within the next 30 minutes.\n\nThe World Wide Tracking Network went on to serve subsequent space programs, until it was replaced by a satellite relay system in the 1980s Mission Control Center was moved from Cape Canaveral to Houston in 1965.\n\nOn April 12, 1961 the Soviet cosmonaut Yuri Gagarin became the first person in space on an orbital flight. Alan Shepard became the first American in space on a suborbital flight three weeks later, on May 5, 1961. John Glenn, the third Mercury astronaut to fly, became the first American to reach orbit on February 20, 1962, but only after the Soviets had launched a second cosmonaut, Gherman Titov, into a day-long flight in August 1961. Three more Mercury orbital flights were made, ending on May 16, 1963 with a day-long, 22 orbit flight. However, the Soviet Union ended its Vostok program the next month, with the human spaceflight endurance record set by the 82-orbit, almost 5-day Vostok 5 flight.\n\nAll of the six manned Mercury flights were successful, though some planned flights were canceled during the project (see below). The main medical problems encountered were simple personal hygiene, and post-flight symptoms of low blood pressure. The launch vehicles had been tested through unmanned flights, therefore the numbering of manned missions did not start with 1. Also, there were two separately numbered series: MR for \"Mercury-Redstone\" (suborbital flights), and MA for \"Mercury-Atlas\" (orbital flights). These names were not popularly used, since the astronauts followed a pilot tradition, each giving their spacecraft a name. They selected names ending with a \"7\" to commemorate the seven astronauts. Times given are Universal Coordinated Time, local time + 5 hours. MA = Mercury-Atlas, MR = Mercury-Redstone, LC = Launch Complex. Source:\n\nThe 20 unmanned flights used Little Joe, Redstone, and Atlas launch vehicles. They were used to develop the launch vehicles, launch escape system, spacecraft and tracking network. One flight of a Scout rocket attempted to launch an unmanned satellite for testing the ground tracking network, but failed to reach orbit. The Little Joe program used seven airframes for eight flights, of which three were successful. The second Little Joe flight was named Little Joe 6, because it was inserted into the program after the first 5 airframes had been allocated.\n\nNine of the planned flights were canceled. Suborbital flights were planned for four other astronauts but the number of flights was cut down gradually and finally all remaining were canceled after Titov's flight. Mercury-Atlas 9 was intended to be followed by more one-day flights and even a three-day flight but with the coming of the Gemini Project it seemed unnecessary. The Jupiter booster was, as mentioned above, intended to be used for different purposes.\n\nToday the Mercury program is commemorated as the first manned American space program. It did not win the race against the Soviet Union, but gave back national prestige and was scientifically a successful precursor of later programs such as Gemini, Apollo and Skylab.\n\nDuring the 1950s, some experts doubted that manned spaceflight was possible. Still when John F. Kennedy was elected president, many including he had doubts about the project. As president he chose to support the programs a few months before the launch of \"Freedom 7\", which became a great public success. Afterwards, a majority of the American public supported manned spaceflight, and within a few weeks, Kennedy announced a plan for a manned mission to land on the Moon and return safely to Earth before the end of the 1960s.\n\nThe six astronauts who flew were awarded medals, driven in parades and two of them were invited to address a joint session of the US Congress. As a response to the selection criteria, which ruled out women, a private project was founded in which 13 women pilots successfully underwent the same tests as the men in Project Mercury. It was named Mercury 13 by the media Despite this effort, NASA did not select female astronauts until 1978 for the Space Shuttle.\n\nIn 1964, a monument commemorating Project Mercury was unveiled near Launch Complex 14 at Cape Canaveral, featuring a metal logo combining the symbol of Mercury with the number 7. In 1962, the United States Postal Service honored the Mercury-Atlas 6 flight with a Project Mercury commemorative stamp, the first US postal issue to depict a manned spacecraft. On film, the program was portrayed in \"The Right Stuff\" a 1983 adaptation of Tom Wolfe's 1979 book of the same name. On February 25, 2011, the Institute of Electrical and Electronic Engineers, the world's largest technical professional society, awarded Boeing (the successor company to McDonnell Aircraft) a Milestone Award for important inventions which debuted on the Mercury spacecraft.\n\nThe spacecraft that flew, together with some that did not are on display in the United States. \"Friendship 7\" (capsule No. 13) went on a global tour, popularly known as its \"fourth orbit\". \n\nCommemorative patches were designed by entrepreneurs after the Mercury program to satisfy collectors.\n\n"}
{"id": "25228", "url": "https://en.wikipedia.org/wiki?curid=25228", "title": "Q.E.D.", "text": "Q.E.D.\n\nQ.E.D. (also written QED and in italics: \"QED\") is an initialism of the Latin phrase meaning \"what was to be demonstrated\" or \"what was to be shown.\" Some may also use a less direct translation instead: \"thus it has been demonstrated.\" Traditionally, the phrase is placed in its abbreviated form at the end of a mathematical proof or philosophical argument when the original proposition has been restated exactly, as the conclusion of the demonstration or completion of the proof.\n\nThe phrase, \"quod erat demonstrandum\", is a translation into Latin from the Greek (; abbreviated as \"ΟΕΔ\"). Translating from the Latin into English yields, \"what was to be demonstrated\", however, translating the Greek phrase produces a slightly different meaning. Since the verb also means \"to show\" or \"to prove\", a better translation from the Greek would read, \"The very thing it was required to have shown.\"\n\nThe Greek phrase was used by many early Greek mathematicians, including Euclid and Archimedes.\n\nDuring the European Renaissance, scholars often wrote in Latin, and phrases such as \"Q.E.D.\" were often used to conclude proofs.\nPerhaps the most famous use of \"Q.E.D.\" in a philosophical argument is found in the \"Ethics\" of Baruch Spinoza, published posthumously in 1677. Written in Latin, it is considered by many to be Spinoza's \"magnum opus\". The style and system of the book are, as Spinoza says, \"demonstrated in geometrical order\", with axioms and definitions followed by propositions. For Spinoza, this is a considerable improvement over René Descartes's writing style in the \"Meditations\", which follows the form of a diary.\n\nThere is another Latin phrase with a slightly different meaning, usually shortened similarly, but being less common in use. , originating from the Greek geometers' closing (), meaning \"which had to be done\". Because of the difference in meaning, the two phrases should not be confused.\n\nEuclid used the phrase, Quod Erat Faciendum (Q.E.F.), to close propositions that were not proofs of theorems, but constructions. For example, Euclid's first proposition showing how to construct an equilateral triangle, given one side, is concluded this way.\n\n\"Q.E.D.\" has acquired many translations in various languages, including:\n\nThere is no common formal English equivalent, although the end of a proof may be announced with a simple statement such as \"this completes the proof\", \"as required\", \"hence proved\", \"ergo\", or by using a similar locution. WWWWW or W – an abbreviation of \"Which Was What Was Wanted\" – has been used similarly. Often this is considered to be more tongue-in-cheek than the usual Halmos symbol \"(see below)\" or \"Q.E.D.\"\n\nDue to the paramount importance of proofs in mathematics, mathematicians since the time of Euclid have developed conventions to demarcate the beginning and end of proofs. In printed English language texts, the formal statements of theorems, lemmas, and propositions are set in italics by tradition. The beginning of a proof usually follows immediately thereafter, and is indicated by the word \"proof\" in boldface or italics. On the other hand, several symbolic conventions exist to indicate the end of a proof.\n\nWhile some authors still use the classical abbreviation, Q.E.D., this practice is increasingly viewed as archaic or even pretentious. Paul Halmos pioneered the use of a solid black square at the end of a proof as a Q.E.D symbol, a practice which has become standard, although not universal. Halmos adopted this use of a symbol from magazine typography customs in which simple geometric shapes had been used to indicate the end of an article. This symbol was later called the \"tombstone\" or \"Halmos symbol\" or even a \"halmos\" by mathematicians. Often the Halmos symbol is drawn on chalkboard to signal the end of a proof during a lecture, although this practice is not so common as its use in printed text.\n\nThe tombstone symbol appears in TeX as the character formula_1 (filled square, \\blacksquare) and sometimes, as a formula_2 (hollow square, \\square). In the AMS Theorem Environment for LaTeX, the hollow square is the default end-of-proof symbol. Unicode explicitly provides the \"End of proof\" character, U+220E (∎). Some authors use other Unicode symbols to note the end of a proof, including, ▮ (U+25AE, a black vertical rectangle), and ‣ (U+2023, a triangular bullet). Other authors have adopted two forward slashes (//) or four forward slashes (////). In other cases, authors have elected to segregate proofs typographically by displaying them as indented blocks.\n\nIn Joseph Heller's book \"Catch-22\", the Chaplain, having been told to examine a forged letter allegedly signed by him (which he knew he didn't sign), verified that his \"name\" was in fact there. His investigator replied, \"Then you wrote it. Q.E.D.\" The chaplain said he didn't write it and that it wasn't his handwriting, to which the investigator replied, \"Then you signed your name in somebody else's handwriting again.\"\n\nIn the 1978 science-fiction radio comedy, and later in the television and novel adaptations of \"The Hitchhiker's Guide to the Galaxy\", \"Q.E.D.\" is referred to in the Guide's entry for the babel fish, when it is claimed that the babel fish – which serves the \"mind-bogglingly\" useful purpose of being able to translate any spoken language when inserted into a person's ear – is used as evidence for existence and non-existence of God. The exchange from the novel is as follows: \"'I refuse to prove I exist,' says God, 'for proof denies faith, and without faith I am nothing.' 'But,' says Man, 'The babel fish is a dead giveaway, isn't it? It could not have evolved by chance. It proves you exist, and so therefore, by your own arguments, you don't. QED.' 'Oh dear,' says God, 'I hadn't thought of that,' and promptly vanishes in a puff of logic.\"\n\nIn Neal Stephenson's 1999 novel \"Cryptonomicon\", Q.E.D. is used as a punchline to several humorous anecdotes in which characters go to great lengths to prove something non-mathematical.\n\nSinger-songwriter Thomas Dolby's 1988 song \"Airhead\" includes the lyric, \"Quod erat demonstrandum, baby,\" referring to the self-evident vacuousness of the eponymous subject; and in response, a female voice squeals, delightedly, \"Oooh... you speak French!\" \n\n\n"}
{"id": "52093689", "url": "https://en.wikipedia.org/wiki?curid=52093689", "title": "Quadrans Vetus", "text": "Quadrans Vetus\n\nThe Quadrans Vetus is a medieval astronomical instrument.\n\nKnown as the \"quadrans vetus\" [\"old quadrant\"], the three surviving medieval examples are in the Museo Galileo in Florence, the Museum of the History of Science in Oxford, and the British Museum in London.\n\nThere are two sights on one of the straight sides. The front carries the shadow square, the hour lines, and a mobile zodiacal cursor in its guide, to be positioned for the desired latitude. The back is inscribed with the zodiacal calendar. The instrument displays Gothic characters. Designed to measure heights, distances, and depths, the instrument could also be used as a universal dial. A similar quadrant is documented in a drawing by Antonio da Sangallo the Younger (c. 1520?) at the Gabinetto dei Disegni e delle Stampe (Department of Drawings and Prints) of the Uffizi.\n"}
{"id": "22424", "url": "https://en.wikipedia.org/wiki?curid=22424", "title": "Recapitulation theory", "text": "Recapitulation theory\n\nThe theory of recapitulation, also called the biogenetic law or embryological parallelism—often expressed using Ernst Haeckel's phrase \"ontogeny recapitulates phylogeny\"—is a historical hypothesis that the development of the embryo of an animal, from fertilization to gestation or hatching (ontogeny), goes through stages resembling or representing successive stages in the evolution of the animal's remote ancestors (phylogeny). It was formulated in the 1820s by Étienne Serres based on the work of Johann Friedrich Meckel, after whom it is also known as Meckel–Serres law.\n\nSince embryos also evolve in different ways, the shortcomings of the theory had been recognized by the early 20th century, and it had been relegated to \"biological mythology\" by the mid-20th century.\n\nAnalogies to recapitulation theory have been formulated in other fields, including cognitive development and art criticism.\n\nThe idea of recapitulation was first formulated in biology from the 1790s onwards by the German natural philosophers Johann Friedrich Meckel, Étienne Serres, and Carl Friedrich Kielmeyer, after which, Marcel Danesi states, it soon gained the status of a supposed biogenetic law.\n\nThe embryological theory was formalised by Serres in 1824–26, based on Meckel's work, in what became known as the \"Meckel-Serres Law\". This attempted to link comparative embryology with a \"pattern of unification\" in the organic world. It was supported by Étienne Geoffroy Saint-Hilaire, and became a prominent part of his ideas. It suggested that past transformations of life could have been through environmental causes working on the embryo, rather than on the adult as in Lamarckism. These naturalistic ideas led to disagreements with Georges Cuvier. The theory was widely supported in the Edinburgh and London schools of higher anatomy around 1830, notably by Robert Edmond Grant, but was opposed by Karl Ernst von Baer's ideas of divergence, and attacked by Richard Owen in the 1830s.\n\nErnst Haeckel (1834–1919) attempted to synthesize the ideas of Lamarckism and Goethe's \"Naturphilosophie\" with Charles Darwin's concepts. While often seen as rejecting Darwin's theory of branching evolution for a more linear Lamarckian view of progressive evolution, this is not accurate: Haeckel used the Lamarckian picture to describe the ontogenetic and phylogenetic history of individual species, but agreed with Darwin about the branching of all species from one, or a few, original ancestors. Since early in the twentieth century, Haeckel's \"biogenetic law\" has been refuted on many fronts.\n\nHaeckel formulated his theory as \"Ontogeny recapitulates phylogeny\". The notion later became simply known as the recapitulation theory. Ontogeny is the growth (size change) and development (structure change) of an individual organism; phylogeny is the evolutionary history of a species. Haeckel claimed that the development of advanced species passes through stages represented by adult organisms of more primitive species. Otherwise put, each successive stage in the development of an individual represents one of the adult forms that appeared in its evolutionary history.\n\nFor example, Haeckel proposed that the pharyngeal grooves between the pharyngeal arches in the neck of the human embryo not only roughly resembled gill slits of fish, but directly represented an adult \"fishlike\" developmental stage, signifying a fishlike ancestor. Embryonic pharyngeal slits, which form in many animals when the thin branchial plates separating pharyngeal pouches and pharyngeal grooves perforate, open the pharynx to the outside. Pharyngeal arches appear in all tetrapod embryos: in mammals, the first pharyngeal arch develops into the lower jaw (Meckel's cartilage), the malleus and the stapes. But these embryonic pharyngeal arches, grooves, pouches, and slits in human embryos can not at any stage carry out the same function as the gills of an adult fish.\n\nHaeckel produced several embryo drawings that often overemphasized similarities between embryos of related species. The misinformation was propagated through many biology textbooks, and popular knowledge, even today. Modern biology rejects the literal and universal form of Haeckel's theory, such as its possible application to behavioural ontogeny, i.e. the psychomotor development of young animals and human children.\n\nHaeckel's drawings were such a misrepresentation of observed human embryonic development that he attracted the opposition of several members of the scientific community, including the anatomist Wilhelm His, who had developed a rival \"causal-mechanical theory\" of human embryonic development. His specifically criticised Haeckel's methodology. His argued that the shapes of embryos were caused most immediately by mechanical pressures resulting from local differences in growth. These differences were, in turn, caused by \"heredity\". His compared the shapes of embryonic structures to those of rubber tubes that could be slit and bent, illustrating these comparisons with accurate drawings. Stephen Jay Gould's attack on Haeckel's recapitulation theory was far more fundamental than that of any empirical critic, as it effectively stated that Haeckel's \"biogenetic law\" was irrelevant.\n\nDarwin's view was that embryos resembled each other, since they shared a common ancestor, which presumably had a similar embryo, but that development did not necessarily recapitulate phylogeny: in his view, there was no reason to suppose that an embryo at any stage resembled an adult of any ancestor. Darwin supposed further that embryos were subject to less intense selection pressure than adults, and had therefore changed less.\n\nModern evolutionary developmental biology (evo-devo) follows von Baer, rather than Darwin, in pointing to active evolution of embryonic development as a significant means of changing the morphology of adult bodies. Two of the key principles of evo-devo, namely that changes in the timing (heterochrony) and positioning within the body (heterotopy) of aspects of embryonic development would change the shape of a descendant's body compared to an ancestor's, were however first formulated by Haeckel in the 1870s. These elements of his thinking about development have thus survived, whereas his theory of recapitulation has not.\n\nThe Haeckelian form of recapitulation theory is considered defunct.\nHowever, embryos do undergo a period where their morphology is strongly shaped by their phylogenetic position, rather than selective pressures. The modern view is summarised by the University of California Museum of Paleontology:\n\nThe idea that ontogeny recapitulates phylogeny has been applied to some other areas.\n\nResearch in the late 20th century confirmed that \"both biological evolution and the stages in the child's cognitive development follow much the same progression of evolutionary stages as that suggested in the archaeological record\".\n\nEnglish philosopher Herbert Spencer was one of the most energetic promoters of evolutionary ideas to explain many phenomena. He compactly expressed the basis for a cultural recapitulation theory of education in the following claim, published in 1861, five years before Haeckel first published on the subject: \n\nG. Stanley Hall used Haeckel's theories as the basis for his theories of child development. His most influential work, \"Adolescence: Its Psychology and Its Relations to Physiology, Anthropology, Sociology, Sex, Crime, Religion and Education\" in 1904 suggested that each individual's life course recapitulated humanity's evolution from \"savagery\" to \"civilization\". Though he has influenced later childhood development theories, Hall's conception is now generally considered racist. \nDevelopmental psychologist Jean Piaget favored a weaker version of the formula, according to which ontogeny \"parallels\" phylogeny because the two are subject to similar external constraints.\nThe Austrian pioneer in psychoanalysis, Sigmund Freud, also favored Haeckel's doctrine. He was trained as a biologist under the influence of recapitulation theory at the time of its domination, and retained a Lamarckian outlook with justification from the recapitulation theory. He also distinguished between physical and mental recapitulation, in which the differences would become an essential argument for his .\n\nThe musicologist Richard Taruskin in 2005 applied the term \"ontogeny becomes phylogeny\" to the process of creating and recasting art history, often to assert a perspective or argument. For example, the peculiar development of the works by modernist composer Arnold Schoenberg (here an \"ontogeny\") is generalized in many histories into a \"phylogeny\" – a historical development (\"evolution\") of Western music toward atonal styles of which Schoenberg is a representative. Such historiographies of the \"collapse of traditional tonality\" are faulted by art historians as asserting a rhetorical rather than historical point about tonality's \"collapse\".\n\nTaruskin also developed a variation of the motto into the pun \"ontogeny recapitulates ontology\" to refute the concept of \"absolute music\" advancing the socio-artistic theories of the musicologist Carl Dahlhaus. Ontology is the investigation of what exactly something is, and Taruskin asserts that an art object becomes that which society and succeeding generations made of it. For example, composer Johann Sebastian Bach's \"St. John Passion\", composed in the 1720s, was appropriated by the Nazi regime in the 1930s for propaganda. Taruskin claims the historical development of the \"Passion\" (its ontogeny) as a work with an anti-Semitic message does, in fact, inform the work's identity (its ontology), even though that was an unlikely concern of the composer. Music or even an abstract visual artwork can not be truly autonomous (\"absolute\") because it is defined by its historical and social reception.\n\n\n\n"}
{"id": "31525486", "url": "https://en.wikipedia.org/wiki?curid=31525486", "title": "Reward theory of attraction", "text": "Reward theory of attraction\n\nThe reward theory of attraction states that people like those whose behavior is rewarding to them or whom they associate with rewarding events. More clearly stated this means people are attracted to those who in some way make them feel good, or are attracted to those who remind them of people that they enjoy being around.\n\nWe are attracted to those that we find it satisfying and gratifying to be with. If a relationship gives us more reward and pleasure than cost and pain, we will like that relationship and wish it to continue. Thus, even after a relationship ends, we may find ourselves drawn to people that remind us of the former person.\n\nThis can help explain why no love can feel quite the same as that \"first\". These \"firsts\" can generate sensations so new and unfamiliar that the experience feels almost unreal. Besides emotional engagement, these experiences also have a heavy dose of novelty. Novelty simply driving up dopamine and norepinephrine (brain systems associated with focus and paying attention and rewards). A first romantic relationship is the only time in which an individual is in \"love\" without ever having been hurt from such a relationship. If a person meets someone who reminds them of an ex, whether physically or a similarity in attitudes, gestures, voice, or interests, it may engage the representation in their memory. And since their first love, by result of its novelty and emotional significance, is potentially the most prominent, it may be the representation that is summoned when they meet a potential someone new, which effects the way they see that new relationship. Their old feelings, motivations, and expectations are all transferred into their memory, which can cause them to (if their new found partner reminds them of an ex) begin to repeat behaviors that they engaged in with that ex.\n\nThe fact that people are attracted to those who make them feel good can also explain why people are attracted to those they cannot have. Forbidden love is the most intense. Again, dopamine plays a major role. Beyond pleasure, dopamine is also associated with focus, motivation, and goal-oriented behavior. When a person cannot get somebody, the dopamine system keeps on spitting out hormones, providing the adrenaline, focus and motivation necessary to keep trying.\n\nThe reward theory also helps explain why people are more attracted to people of close proximity, of more attractiveness, more similar, and people who have feelings of mutuality. Proximity is rewarding. It cost less effort to receive friendship's benefits with someone who lives or works closer. People like attractive people because they perceive that attractive people offer other desirable traits, and they benefit from associating with them. If others have similar opinions as ourselves we feel rewarded because we presume that they like us in return. People also like to be liked and love to be loved. Therefore, liking is usually mutual because we like those who like us in return.\n\nConditioning creates positive feelings towards things and people linked with rewarding events. Pawel Lewicki in 1985 tested this liking-by-association principle by conducting an experiment on students at the University of Warsaw. In the experiment students were given the option of choosing which of two pictured women (woman A or woman B) looked friendlier. Students were 50-50 in choosing which was friendlier. Other students, however, before viewing the pictures interacted with a warm and friendly experimenter who resembled woman A, chose woman A at a margin of 6 to 1. In a follow up study, the experimenter acted unfriendly toward half of the participants. When these participants later had to turn in their data to one of the two women, they almost always avoided the one who looked like the \"unfriendly\" experimenter.\n\nIn Griffit's study college students that evaluated strangers in a pleasant room liked them better than students who evaluated strangers in an uncomfortably hot room.\n\nHelen Fisher and colleagues conducted a neuroimaging study on men and women that had just \"fallen madly in love\". Using functional magnetic resonance imaging (fMRI), they collected data on 10 women and 7 men that reported being in love an average of 7.4 months. Each participant was shown a picture of their loved one as well as a photograph of an emotionally neutral person, each viewing was then followed by a distraction task to cleanse the mind of strong emotions. Brain activation with the picture of the loved one was high in the region of the brain that produces and distributes dopamine and also brains \"reward system\", or the neural network associated with pleasure, arousal, focus, and motivation.\n\nIn 2000 animal studies were conducted that supported that attraction is associated with elevated activity in central dopamine. In the experiment a female lab-raised prairie vole was mated with a male, and formed a distinct preference for him associated with a 50% increase of dopamine. When a dopamine antagonist was injected into the reward region of the brain, she no longer had the preference for the male.\n\nIn 2005 Fisher and colleagues conducted a second fMRI study in which participants were still in love with a past partner. The study included 10 women and 5 men. The rejected participants viewed pictures of their ex and of a similar, emotionally neutral individual. Within the participants dopamine was again increased with viewing of the photographs.\n"}
{"id": "58752602", "url": "https://en.wikipedia.org/wiki?curid=58752602", "title": "SWAP (New Horizons)", "text": "SWAP (New Horizons)\n\nSWAP (Solar Wind Around Pluto) is an science instrument aboard the unmanned \"New Horizons\" space probe, which was designed to flyby dwarf planet Pluto. SWAP was designed to record Solar Wind en route, at, and beyond Pluto.At Pluto, SWAP will also record the potential nature between the solar wind and ions and/or material entering space from the atmosphere of Pluto. As early as 1980 there was interest in atmospheric loss from Pluto, with Pluto being compared to losses from comets.\n\nSWAP can detect the sparse solar wind concentration at 32 AU, which is about three orders of magnitude less than near Earth (1 AU). However, at that distance the flow of the Solar Wind is still supersonic, and thus liable to create a bow shock around an obstacle. One of the areas of investigation is the relationship between high altitude atmospheric loss and the solar wind. After the July 2015 flyby of Pluto by \"New Horizons\", data from SWAP was used to study the nature of Pluto's interaction with the solar wind. It was determined that NH entered a Plutopause and passed through a heavy ion tail.\n\nEarlier in the mission SWAP was intended to observe the Solar Wind around Jupiter. SWAP was also designed to be used in conjunction with PEPPSI and REX, to study how the solar wind changes with greater distance from the Sun. \n\nBy the 2010s, only three other spacecraft besides \"New Horizons\" have collected extensive data about the solar wind beyond 10 AU, \"Voyager 2\", \"Pioneer 10\", and \"Pioneer 11\". SWAP took only limited observations before 2012, but after that took a greater amount of data. Starting in 2012, while the rest of the spacecraft was in hibernation most of the time, SWAP was turned on to collect data about the Solar wind as it journeyed out to Pluto at 33 AU.\n\nSWAP is a top-hat electrostatic analyzer. SWAP has a barrier known as the \"Retarding Potential Analyzer\" (RPA) that can be open or shut depending on the conditions. When closed ions must pass through the RPA before reaching the inner detectors. Beyond the orbit of Jupiter, it was not necessary to have the RPA engaged for measurements to protect the sensors from being overloaded. The RPA can protect the sensors from being overloaded by solar wind intensities that are too strong, as the device is also required to measure much fainter solar wind fluxes at 33 AU from Sun where Pluto would be at the time of the flyby, and even beyond. SWAP can detect ions up to 6.5 kiloelectron volts (keV).\n\nSWAP weighs 3.3 kilograms (7.3 pounds) and uses an average of 2.3 watts of spacecraft electrical power.\n\nOverall swap is designed to study the solar wind, including at the distant of 32 AU, and to study atmospheric loss from the atmosphere of Pluto.\n\n\n"}
{"id": "10454425", "url": "https://en.wikipedia.org/wiki?curid=10454425", "title": "Salomon Coster", "text": "Salomon Coster\n\nSalomon Coster (c. 1620–1659) was a Dutch clockmaker of the Hague, who in 1657 was the first to make a pendulum clock, which had been invented by Christiaan Huygens (1629-1695). Coster's earliest pendulum clocks were signed \"Samuel Coster Haghe met privilege\", indicating that he had been authorized by the inventor to make such clocks. John Fromanteel, the son of a London clockmaker, Ahasuerus, went to work for Coster. He was one of many foreign clockmakers to soon make pendulum clocks following the prototype by Huygens and Coster. A contract was signed on 3 September 1657 between Salomon Coster and John Fromanteel which allowed Fromanteel to continue making the clocks. This clock design was heralded as a new beginning in the clockmaking industry, due to its level of timekeeping accuracy which was previously unheard of.\n\nThe oldest extant pendulum clock is signed by Salomon Coster and dated 1657. It is on display at the Boerhaave Museum in Leiden, the Netherlands. Coster died a sudden death in 1659.\n\n\n"}
{"id": "24561779", "url": "https://en.wikipedia.org/wiki?curid=24561779", "title": "School of Convergence", "text": "School of Convergence\n\n9.9 School of Convergence, also known as SoC, is a small media school in New Delhi, India. The school has Pramath Raj Sinha, the founding dean of Indian School of Business, as its dean.\n\nThe School of Convergence (SoC) was set up in October 2001 by Kaleidoscope Entertainment, headed by Bobby Bedi. The school started with a Two Year Post Graduate Diploma Course in Content Creation and Management (PGDCCM) combining print, radio, television, cinema and the Internet. This course offered knowledge and skills in all streams of media and management. It combines the curricula of a journalism school, a film school and a management school.\nThe Media School licensed its brand to 9.9 Mediaworx Pvt. Ltd. to start journalism courses as 9.9 School of Convergence and it starting its first batch in September 2009 with just one course, an eleven-month diploma in Applied Journalism.\n\n\n9.9 School of Convergence offers a Diploma in Applied Journalism. The programme equips aspiring journalists with the core skills required for success in their profession – high-quality and consistent reporting, writing and editing skills.\n\nThe course is primarily taught by practising journalists, who have excelled at their craft and gained enough experience to teach the dos and don’ts of the profession. In fact, the weekly modules have been received with enthusiasm by media practitioners approached by 9.9 SoC because of the high degree of practicality in the syllabus.\n\nThis school has an impressive list of faculty members, including Graham Watts, a journalist and trainer; BV Rao, consulting editor with MoneyLife, a fortnightly magazine, and a columnist on Indian media; Rasheeda Bhagat, associate editor of Hindu Business Line; Edward Henning, a teacher-turned-journalist; Vanita Kohli-Khandekar, independent media consultant and writer.\n\nOther faculty members are Savyasaachi Jain, Mala Bhargava, Jacob Cherian, Radha Hegde, Vinay Kamat, Pooja Kothari, Ranbir Majumdar, Eric Saranovitz and Pramath Raj Sinha himself.\n\n\n the 9.9 SoC has tie-ups with TV and Radio studios for practical sessions.\n\nAddress :-Sri Aurobindo Society, New Mehrauli Road, Adchini, New Delhi - 110 017\n\n9.9 Media is a diversified media company started by former ABP CEO Dr. Pramath Raj Sinha along with four of his other colleagues. It targets consumer, business and professional communities through magazines, websites, events, and peer groups.\n\nOther than SoC, 9.9 Media publishes several other magazines, manages professional institutes and host online platforms.\n\n\n"}
{"id": "2699552", "url": "https://en.wikipedia.org/wiki?curid=2699552", "title": "Shiva laser", "text": "Shiva laser\n\nThe Shiva laser was a powerful 20-beam infrared neodymium glass (silica glass) laser built at Lawrence Livermore National Laboratory in 1977 for the study of inertial confinement fusion (ICF) and long-scale-length laser-plasma interactions. Presumably, the device was named after the multi-armed form of the Hindu god Shiva, due to the laser's multi-beamed structure. Shiva was instrumental in demonstrating a particular problem in compressing targets with lasers, leading to a major new device being constructed to address these problems, the Nova laser.\n\nThe basic idea of any ICF device is to rapidly heat the outer layers of a \"target\", normally a small plastic sphere containing a few milligrams of fusion fuel, typically a mix of deuterium and tritium. The heat burns the plastic into a plasma, which explodes off the surface. Due to Newton's Third Law, the remaining portion of the target is driven inwards, eventually collapsing into a small point of very high density. The rapid blowoff also creates a shock wave that travels towards the center of the compressed fuel. When it meets itself in the center of the fuel, the energy in the shock wave further heats and compresses the tiny volume around it. If the temperature and density of that small spot is raised high enough, fusion reactions will occur.\n\nThe fusion reactions release high-energy particles, which collide with the high density fuel around it and slow down. This heats the fuel further, and can potentially cause that fuel to undergo fusion as well. Given the right overall conditions of the compressed fuel – high enough density and temperature – this heating process can result in a chain reaction, burning outward from the center where the shock wave started the reaction. This is a condition known as \"ignition\", which can lead to a significant portion of the fuel in the target undergoing fusion, and the release of significant amounts of energy.\n\nTo date most ICF experiments have used lasers to heat the targets. Calculations show that the energy must be delivered quickly in order to compress the core before it disassembles, as well as creating a suitable shock wave. The laser beams must also be focussed evenly across the target's outer surface in order to collapse the fuel into a symmetric core. Although other \"drivers\" have been suggested, lasers are currently the only devices with the right combination of features.\n\nShiva incorporated many of the advancements achieved on the earlier Cyclops and Argus lasers, notably the use of amplifiers made of Nd:glass slabs set at the Brewster's angle and the use of long vacuum spatial filters to \"clean\" the resulting laser beams. These features have remained a part of every ICF laser since, which leads to long \"beamlines\". In the case of Shiva, the beamlines were about 30 m long.\n\nPrior to \"firing\", the laser glass of the Shiva was \"pumped\" with light from a series of Xenon flash lamps fed power from a large capacitor bank. Some of this light is absorbed by the neodymium atoms in the glass, raising them to an excited state and leading to a population inversion which readies the lasing medium for amplification of a laser beam. A small amount of laser light, generated externally, was then fed into the beamlines, passing through the glass and becoming amplified through the process of stimulated emission. This is not a particularly efficient process; in total, around ~1% of the electricity used to feed the lamps ends up amplifying the beam on most Nd:glass lasers.\n\nAfter each amplifier module there was a spatial filter, which was used to smooth the beam by removing any nonuniformity or power anisotropy which had accumulated due to nonlinear focussing effects of intense light passage through air and glass. The spatial filter is held under vacuum in order to eliminate the creation of plasma at the focus (pinhole).\n\nAfter the light had passed through the final amplifier and spatial filter it was then used for experiments in the target chamber, lying at one end of the apparatus. Shiva's 20 beamlines each delivered about 500 Joules of energy, which together delivered a ~.5 to 1 nanosecond pulse of 10.2 kJ of infrared light at 1062 nm wavelength, or smaller peak powers over longer times (3 kJ for 3 ns).\n\nBy today's standards, Shiva was fairly inexpensive. The entire device, including test equipment and buildings, cost about $25 million when it was completed in 1977 ($ million today).\n\nShiva was never expected to reach ignition conditions, and was primarily intended as a proof-of-concept system for a larger device that would. Even before Shiva was completed, the design of this successor, then known as Shiva/Nova, was well advanced. Shiva/Nova would emerge as Nova in 1984. Shiva was heavily instrumented, and its target chamber utilized high-resolution, high-speed optical and X-ray instruments for the characterization of the plasmas created during implosion.\n\nWhen experiments with targets started in Shiva in 1978, compression was ramped upward to about 50 to 100 times the original density of the liquid hydrogen, or about 3.5 to 7 g/mL. For comparison, lead has a density of about 11 g/mL. While impressive, this level of compression is far too low to be useful in an attempt to reach ignition, and far lower than simulations had estimated for the system\n\nStudies of the causes of the lower than expected compression led to the realization that the laser was coupling strongly with the hot electrons (~50 keV) in the plasma which formed when the outer layers of the target were heated, via stimulated raman scattering. John Holzrichter, director of the ICF program at the time, said:\n\nThe laser beam generates a dense plasma where it impinges on the target material. The laser light gives up its energy to the electrons in the plasma, which absorb the light. The rate at which that happens depends on the wavelength and the intensity. On Shiva, we were heating up electrons to incredible energies, but the targets were not performing well. We tried a lot of stuff to coax the electrons to transfer more of their energy to the target, with no success.\n\nIt was earlier realized that laser energy absorption on a surface scaled favorably with reduced wavelength, but it was believed at that time that the IR generated in the Shiva Nd:glass laser would be sufficient for adequately performing target implosions. Shiva proved this assumption wrong, showing that irradiating capsules with infrared light would likely never achieve ignition or gain. Thus Shiva's greatest advance was in its failure, a not entirely obvious example of the null result.\n\nICF research turned to using an \"optical frequency multiplier\" to convert the incoming IR light into the ultraviolet at about 351 nm, a technique that was well known at the time but was not efficient enough to be worthwhile. Research on the GDL laser at the Laboratory for Laser Energetics in 1980 first achieved efficient frequency tripling techniques which were then used next (for the first time at LLNL) on Shiva's successor, the Novette laser. Every laser-driven ICF system after Shiva has used this technique.\n\nOn January 24 1980, a 5.8 earthquake (the first in a doublet) shook Livermore and the facility enough to shear fist-sized bolts off Shiva; repairs were made and the laser was subsequently put back online a month later. Many experiments including testing the \"indirect mode\" of compression using hohlraums continued at Shiva until its dismantling in 1981. Shiva's target chamber would be reused on the Novette laser. Maximum fusion yield on Shiva was around 10 to 10 neutrons per shot.\n\n"}
{"id": "29082", "url": "https://en.wikipedia.org/wiki?curid=29082", "title": "Social geography", "text": "Social geography\n\nSocial geography is the branch of human geography that is most closely related to social theory in general and sociology in particular, dealing with the relation of social phenomena and its spatial components. Though the term itself has a tradition of more than 100 years, there is no consensus on its explicit content. In 1968, noted that \"[w]ith some notable exceptions, (...) social geography can be considered a field created and cultivated by a number of individual scholars rather than an academic tradition built up within particular schools\". Since then, despite some calls for convergence centred on the structure and agency debate, its methodological, theoretical and topical diversity has spread even more, leading to numerours definitions of social geography and, therefore, contemporary scholars of the discipline identifying a great variety of different \"social geographies\". However, as Benno Werlen remarked, these different perceptions are nothing else than different answers to the same two (sets of) questions, which refer to the spatial constitution of society on the one hand, and to the spatial expression of social processes on the other.\n\nThe different conceptions of social geography have also been overlapping with other sub-fields of geography and, to a lesser extent, sociology. When the term emerged within the Anglo-American tradition during the 1960s, it was basically applied as a synonym for the search for patterns in the distribution of social groups, thus being closely connected to urban geography and urban sociology. In the 1970s, the focus of debate within American human geography lay on political economic processes (though there also was a considerable number of accounts for a phenomenological perspective on social geography), while in the 1990s, geographical thought was heavily influenced by the \"cultural turn\". Both times, as Neil Smith noted, these approaches \"claimed authority over the 'social'\". In the American tradition, the concept of cultural geography has a much more distinguished history than social geography, and encompasses research areas that would be conceptualized as \"social\" elsewhere. In contrast, within some continental European traditions, social geography was and still is considered an approach to human geography rather than a sub-discipline, or even as identical to human geography in general.\n\nThe term \"social geography\" (or rather \"géographie sociale\") originates from France, where it was used both by geographer Élisée Reclus and by sociologists of the Le Play School, perhaps independently from each other. In fact, the first proven occurrence of the term derives from a review of Reclus' \"Nouvelle géographie universelle\" from 1884, written by Paul de Rousiers, a member of the Le Play School. Reclus himself used the expression in several letters, the first one dating from 1895, and in his last work \"L'Homme et la terre\" from 1905. The first person to employ the term as part of a publication's title was Edmond Demolins, another member of the Le Play School, whose article \"Géographie sociale de la France\" was published in 1896 and 1897. After the death of Reclus as well as the main proponents of Le Play's ideas, and with Émile Durkheim turning away from his early concept of social morphology, Paul Vidal de la Blache, who noted that geography \"is a science of places and not a science of men\", remained the most influential figure of French geography. One of his students, Camille Vallaux, wrote the two-volume book \"Géographie sociale\", published in 1908 and 1911. Jean Brunhes, one of Vidal's most influential disciples, included a level of (spatial) interactions among groups into his fourfold structure of human geography. Until the Second World War, no more theoretical framework for social geography was developed, though, leading to a concentration on rather descriptive rural and regional geography. However, Vidal's works were influential for the historical Annales School, who also shared the rural bias with the contemporary geographers, and Durkheim's concept of social morphology was later developed and set in connection with social geography by sociologists Marcel Mauss and Maurice Halbwachs.\n\nThe first person in the Anglo-American tradition to use the term \"social geography\" was George Wilson Hoke, whose paper \"The Study of Social Geography\" was published in 1907, yet there is no indication it had any academic impact. Le Play's work, however, was taken up in Britain by Patrick Geddes and Andrew John Herbertson. Percy M. Roxby, a former student of Herbertson, in 1930 identified social geography as one of human geography's four main branches. By contrast, the American academic geography of that time was dominated by the Berkeley School of Cultural Geography led by Carl O. Sauer, while the spatial distribution of social groups was already studied by the Chicago School of Sociology. Harlan H. Barrows, a geographer at the University of Chicago, nevertheless regarded social geography as one of the three major divisions of geography.\n\nAnother pre-war concept that combined elements of sociology and geography was the one established by Dutch sociologist Sebald Rudolf Steinmetz and his Amsterdam School of Sociography. However, it lacked a definitive subject, being a combination of geography and ethnography created as the more concrete counterpart to the rather theoretical sociology. In contrast, the Utrecht School of Social geography, which emerged in the early 1930s, sought to study the relationship between social groups and their living spaces.\n\nIn the German-language geography, this focus on the connection between social groups and the landscape was further developed by Hans Bobek and Wolfgang Hartke after the Second World War. For Bobek, groups of \"Lebensformen\" (patterns of life)—influenced by social factors—that formed the landscape, were at the center of his social geographical analysis. In a similar approach, Hartke considered the landscape a source for indices or traces of certain social groups' behaviour. The best-known example of this perspective was the concept of \"Sozialbrache\" (social-fallow), i.e. the abandoning of tillage as an indicator for occupational shifts away from agriculture.\n\nThough the French \"Géographie Sociale\" had been a great influence especially on Hartke's ideas, no such distinct school of thought formed within the French human geography. Nonetheless, Albert Demangeon paved the way for a number of more systematic conceptualizations of the field with his (posthumously published) notion that social groups ought to be within the center of human geographical analysis. That task was carried out by Pierre George and Maximilien Sorre, among others. Then a Marxist, George's stance was dominated by a socio-economic rationale, but without the structuralist interpretations found in the works of some the French sociologists of the time. However, it was another French Marxist, the sociologist Henri Lefebvre, who introduced the concept of the (social) production of space. He had written on that and related topics since the 1930s, but fully expounded it in \"La Production de L'Espace\" as late as 1974. Sorre developed a schema of society related to the ecological idea of habitat, which was applied to an urban context by the sociologist Paul-Henry Chombart de Lauwe. For the Dutch geographer Christiaan van Paassen, the world consisted of socio-spatial entities of different scales formed by what he referred to as a \"syn-ecological complex\", an idea influenced by existentialism.\n\nA more analytical ecological approach on human geography was the one developed by Edgar Kant in his native Estonia in the 1930s and later at Lund University, which he called \"anthropo-ecology\". His awareness of the temporal dimension of social life would lead to the formation of time geography through the works of Torsten Hägerstrand and Sven Godlund. \n\n\n\n"}
{"id": "7049897", "url": "https://en.wikipedia.org/wiki?curid=7049897", "title": "Socio-cognitive", "text": "Socio-cognitive\n\nSocio-cognitive or sociocognitive describes how processes of group formation effect cognition, studied in cognitive sociology. \n\nOthers have used the phrase to refer to the integration of the cognitive and social properties of systems, processes, functions, models, as well as can indicate the branch of science, engineering or technology, such as \"socio-cognitive research\", \"socio-cognitive interactions\". \n\nThis term is especially used when complex cognitive and social properties are reciprocally connected and essential for a given problem. \n\nSocio-cognitive research is human factor and socio-organizational factor based, and assumes an integrated knowledge engineering, environment and business modeling perspective, therefore it is not \"social cognition\" which rather is a branch of psychology focused on \"how people process social information\".\n\nSocio-cognitive engineering (SCE) includes a set of theoretical interdisciplinary frameworks, methodologies, methods and software tools for the design of human centred technologies, as well as, for the improvement of large complex human-technology systems.\n\nBoth above approaches are applicable for the identification and design of a computer-based semi-/proto-Intelligent Decision Support Systems (IDSS), for the operators and managers of large socially critical systems, for high-risk tasks, such as different types of emergency and disaster management, where human errors and socio-cognitive organization vulnerability can be the cause of serious losses.\n\n\n"}
{"id": "21138780", "url": "https://en.wikipedia.org/wiki?curid=21138780", "title": "StarDate", "text": "StarDate\n\nStarDate is a science radio program of the University of Texas at Austin McDonald Observatory, broadcast on over 360 radio stations. It is a daily guide to the night sky and breaking astronomical news. Typically heard without formal introduction, \"StarDate\" is a self-contained science news feature interwoven with routine radio programming. It is the longest-running science outreach program on U.S. radio. Created by KNOW Radio (Austin) News Director Grady Blount in 1977, the short synoptic format of \"StarDate\" was borrowed from a daily radio news feature called \"90 Seconds\", and was intended to invoke the immediate sense of the term \"stardate\" used in the opening monologue of the 1960s television series \"\".\n\nOriginal scripts were written by science journalist Deborah Byrd of the McDonald Observatory. These evolved from a 1976 astronomy telephone message service and a 30-minute-long Sunday morning public service radio program on astronomy taped at the former KNOW studios on North Lamar Street at Martin Luther King Boulevard. Another Austin radio station, KLBJ-FM, aired a broadcast version of similar Byrd-inspired scripts as \"Have You Seen the Stars Tonight?\" With the creation of the \"StarDate\" concept, Byrd secured funding from the National Science Foundation to begin national distribution under the new moniker and brief, immediate format. The niche broadcasting position of \"StarDate\" has always been its quick but relaxed, diary-like delivery which allows it to be interspersed with regular programming. \n\nByrd produced the show and Joel Block hosted it, until 1991, when a change in management at McDonald and effective demotions led both to depart and start another syndicated radio series, \"Earth & Sky\", which aired from 1991 to 2013 and was heard on about 1,000 radio stations.\n\nSince 1991, \"StarDate\" has been produced by Damond Benningfield, and hosted by Sandy Wood, a San Antonio radio personality who was one of the first female disc jockeys in the southwestern United States.\n\nStations that broadcast \"StarDate\" include affiliates and owned stations of CBS Radio and National Public Radio, approximately 300 stations. The program is also available as a downloadable podcast. Universo, the Spanish language version of \"StarDate\", first aired on April 1, 1995.\n\n\"StarDate Magazine\" was first known as \"McDonald Observatory News\" in 1972. It became a bimonthly magazine in 1988.\n\n"}
{"id": "1158652", "url": "https://en.wikipedia.org/wiki?curid=1158652", "title": "Takwin", "text": "Takwin\n\nTakwin () was a goal of certain Muslim alchemists, notably Jabir ibn Hayyan. In the alchemical context, takwin refers to the creation of synthetic life in the laboratory, up to and including human life. Whether Jabir meant this goal to be interpreted literally is unknown.\n\nJabir states in his \"Book of Stones\" (4:12) that \"The purpose is to baffle and lead into error everyone except those whom God loves and provides for!\" The \"Book of Stones\" was deliberately written in a highly esoteric code, so that only those who had been initiated into his alchemical school could understand them. It is therefore difficult at best for the modern reader to discern which aspects of Jabir's work are to be read as symbols (and what those symbols mean), and what is to be taken literally.\n\nKathleen Malone O'Connor writes:\n\nFrom the emic perspective of the alchemist, the act of takwin was an emulation of the divine creative and life-giving powers of Genesis and Resurrection and tapped the physical and spiritual forces in nature. At the same time it was an act through which the alchemist was inwardly transformed and purified, a spiritual regeneration. Such an act highlights the creative and often uneasy interrelationship of Islamic magic and science with Islamic revelation and tradition.\n\n"}
{"id": "13319664", "url": "https://en.wikipedia.org/wiki?curid=13319664", "title": "William Henry Prestele", "text": "William Henry Prestele\n\nWilhelm Heinrich Prestele (or William Henry Prestele) (13 October 1838 – 16 August 1895) was a botanical artist known for his lithographs and watercolor work commissioned by the US Department of Agriculture.\n\nPrestele was born on October 13, 1838, in Hesse-Darmstadt, Germany, to Franz Joseph Martin Prestele and Karoline Russ. The family emigrated to America in 1843, settling first in New York and later in the Amana Colonies in Iowa. His father, known in America as Joseph Prestele, was also a painter and lithographer of flowers and fruits and prior to emigrating had been head gardener for King Ludwig I of Bavaria as well as a staff artist for a time at the Royal Botanical Garden in Munich. From his father he learned the arts of watercolor and lithography.\n\nIn the late 1850s, Prestele moved to New York, and in 1861 he joined the Union Army as a private in a regiment of New York volunteers. He was wounded at the battle of Antietam in 1862 and spent the remainder of his service period recovering in hospital. Sometime around 1863, he married an Irish woman named Anne, and with her he had three children—Margaret (1864), Frances (ca. 1869), and Emma (1870)—before Anne died in 1871 or 1872.\n\nIn 1867, at the age of 29, William was hired to make a series of nurserymen’s plates by Illinois nursery owner Franklin Kelsey Phoenix. He moved his family from New York to Bloomington, Illinois, for this project. No plates from this project are known to have survived, but a write-up in the August 1869 edition of \"Gardener's Monthly and Horticultural Advertiser\" praised them in robust terms: \"We have now before us a fruit piece... prepared by W. H. Prestele. We are in the habit of admiring European art in this line, and have often wished Americans could successfully compete with it. We now have it here. We never saw anything of the kind better executed from any part of the world\".\n\nWhen this relationship ended in 1871, William briefly went into business with L. B. Littlefield, publishing fruit and flower plates. In 1875, he moved his family to Iowa, not far from the Amana community where he was raised, and married his second wife, Susanna Gefaller. With Susanna, who died in 1882, he had a daughter, Lillian. He set up as a lithographer in Iowa City and practiced this trade for a decade or so.\n\nOn August 1, 1887, he was appointed as the first artist on the staff of the recently formed Pomological Division of the United States Department of Agriculture in Washington, D.C. He was assigned to make life-size watercolors of native grapes intended as illustrations for a monograph by Thomas Volney Munson of Denison, Texas, a leading authority on native grapes. He worked from live and dried specimens sent to him by Munson, making color sketches of details that Munson would then review; Prestele would then use these detail drawings would to create a life-size painting of the species. The U.S. Secretary of Agriculture eventually decided the cost of printing the monograph with the illustrations would be prohibitive, so it was never published in its intended form, though Munson went on to use the text he wrote as the foundation for his highly regarded book \"Foundations of American Grape Culture\". Munson's book was illustrated with photographs instead of with Prestele's watercolors, which remained in the collection of the USDA.\n\nPrestele's paintings are noted for their naturalness and attention to botanical accuracy. Over a hundred of his watercolors of grapes and other fruit are held in the National Agricultural Library's Pomological Watercolor Collection.\n\nHe died in Arlington, Virginia on August 16, 1895, and was buried at Arlington National Cemetery. A collection of his papers spanning the years 1887-1891 is held by the USDA National Agricultural Library Special Collections and comprises original watercolors and drawings, plant specimens, and other materials, including work related to the planned Munson monograph.\n\n\n"}
