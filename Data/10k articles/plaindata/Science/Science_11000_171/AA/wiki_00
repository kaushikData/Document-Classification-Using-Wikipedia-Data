{"id": "35045866", "url": "https://en.wikipedia.org/wiki?curid=35045866", "title": "Abell 262", "text": "Abell 262\n\nAbell 262 is a galaxy cluster in the Abell catalogue. It is part of the Perseus-Pisces Supercluster, one of the largest known structures in the universe. Although its central galaxy, NGC 708, is a giant cD galaxy, most of its bright galaxies are spirals, which is unusual for a galaxy cluster. With approximately 200 members it is a comparatively small cluster.\n\n"}
{"id": "29166078", "url": "https://en.wikipedia.org/wiki?curid=29166078", "title": "Agalina Glacier", "text": "Agalina Glacier\n\nAgalina Glacier ( \\'led-nik a-ga-'li-na\\) is a long and wide glacier on Pefaur (Ventimiglia) Peninsula, Danco Coast on the west side of Antarctic Peninsula, situated east of Poduene Glacier and west of Krapets Glacier. It drains northwards, and flows into both Graham Passage and the west arm of Salvesen Cove.\n\nThe glacier is named after Agalina Point on the Bulgarian Black Sea Coast.\n\nAgalina Glacier is centred at . British mapping in 1978.\n\n\n\n"}
{"id": "3255660", "url": "https://en.wikipedia.org/wiki?curid=3255660", "title": "Astropulse", "text": "Astropulse\n\nAstropulse is a distributed computing project that uses volunteers around the globe to lend their unused computing power to search for primordial black holes, pulsars, and extraterrestrial intelligence (ETI). Volunteer resources are harnessed through Berkeley Open Infrastructure for Network Computing (BOINC) platform. In 1999, the Space Sciences Laboratory launched SETI@home, which would rely on massively parallel computation on desktop computers scattered around the world. SETI@home utilizes recorded data from the Arecibo radio telescope and searches for narrow-bandwidth radio signals from space, signifying the presence of extraterrestrial technology. It was soon recognized that this same data might be scoured for other signals of value to the astronomy and physics community.\n\nFor about 6 years, Astropulse existed in an experimental beta testing phase not available to the general community. In July 2008, Astropulse was integrated into SETI@home, so that the massive network of SETI participants could also contribute to the search for other astronomical signals of value. Astropulse also makes contributions to the search for ET: first, project proponents believe it may identify a different type of ET signal not identified by the original SETI@Home algorithm; second, proponents believe it may create additional support for SETI by providing a second possible concrete result from the overall search project.\n\nFinal development of Astropulse has been a two-part endeavor. The first step was to complete the Astropulse C++ core that can successfully identify a target pulse. Upon completion of that program, the team created a trial dataset that contained a hidden pulse, which the completed program successfully found, thus confirming the ability of the Astropulse core to successfully identify target pulses. Since July 2008, research has focused on a series of refinements to the Beta version which are then rolled out to the full universe of SETI participants. At the programming level, developers first seek to assure that new versions are compatible with a variety of platforms, after which the refined version is optimized for greater speed. As of April, 2009, Astropulse is testing Beta version 5.05.\n\nThe future of the project depends on extended funding to SETI@home.\n\nThe BOINC idea is to divide (split) large blocks of data into smaller units, each of which can be distributed to individual participating work stations. To this end, the project then began to embed the Astropulse core into the SETI beta client and began to distribute real data, split into Astropulse work units, to a team of beta testers. The challenge has been to assure that the Astropulse core will work seamlessly on a broad array of operating systems. Current research focuses on implementing algorithm refinements that eliminate or reduce false positives.\n\nAstropulse searches for both single pulses and regularly repeating pulses. This experiment represents a new strategy for SETI, postulating microsecond timescale pulses as opposed to longer pulses or narrowband signals. They may also discover pulsars and exploding primordial black holes, both of which would emit brief wideband pulses. The primary purpose of the core Astropulse algorithm is coherent de-dispersion of the microsecond radio pulses for which Astropulse is searching. Dispersion of a signal occurs as the pulse passes through the interstellar medium (ISM) plasma, because the high frequency radiation goes slightly faster than the lower frequency radiation. Thus, the signal arrives at the radio-telescope dispersed depending upon the amount of ISM plasma between the Earth and the source of the pulse. Dedispersion is computationally intensive, thus lending itself to the distributed computing model.\n\nAstropulse utilizes the distributed computing power of SETI@home, delegating computational sub-tasks to hundreds of thousands of volunteers' computers, to gain advantages in sensitivity and time resolution over previous surveys. Wideband pulses would be \"chirped\" by passage through the interstellar medium; that is, high frequencies would arrive earlier and lower frequencies would arrive later. Thus, for pulses with wideband frequency content, dispersion hints at a signal's extraterrestrial origin. Astropulse searches for pulses with dispersion measures ranging from to (chirp rates of to per microsecond), allowing detection of sources almost anywhere within the Milky Way.\n\nProject proponents believe that Astropulse will either detect exploding black holes, or establish a maximum rate of , a factor of 10 better than any previous survey.\n\nAny radio astronomy project confronts issues arising from interference, and the challenges are especially great when the target signals are weak or of transient duration. Military radar noise which is regularly occurring and of known duration can be \"blanked\" at the radio telescope source. A variety of techniques have been explored in the literature to develop algorithms that detect and account for radar sources that cannot be blanked in this way.\n\nAstropulse started computing in mid-July 2008. , the results have been used in a variety of ways. Development staff, aided by volunteers, have worked to assure that the client works effectively on a broad array of operating systems. Code has been refined and optimized to reduce calculation time on the local work station. Results have been analyzed so that the algorithms can be adjusted to reduce false positives that may result from interference or from random background noise. To date, a target signal has not yet been found.\n\nOne goal of Astropulse is to detect postulated mini black holes that might be evaporating due to \"Hawking radiation\". Such mini black holes are postulated to have been created during the Big Bang, unlike currently known black holes. The Astropulse project hopes that this evaporation would produce radio waves that Astropulse can detect. The evaporation wouldn't create radio waves directly. Instead, it would create an expanding fireball of high-energy gamma rays and particles. This fireball would interact with the surrounding magnetic field, pushing it out and generating radio waves.\n\nRotating radio transients (RRATs) are a type of neutron stars discovered in 2006 by a team led by Maura McLaughlin from the Jodrell Bank Observatory at the University of Manchester in the UK. RRATs are believed to produce radio emissions which are very difficult to locate, because of their transient nature. Early efforts have been able to detect radio emissions (sometimes called RRAT flashes) for less than one second a day, and, like with other single-burst signals, one must take great care to distinguish them from terrestrial radio interference. Distributing computing and the Astropulse algorithm may thus lend itself to further detection of RRATs.\n\nPulses with an apparent extragalactic origin have been observed in archived data. It is suggested that hundreds of similar events could occur every day and, if detected, could serve as cosmological probes. Radio pulsar surveys such as Astropulse-SETI@home offer one of the few opportunities to monitor the radio sky for impulsive burst-like events with millisecond durations. Because of the isolated nature of the observed phenomenon, the nature of the source remains speculative. Possibilities include a black hole-neutron star collision, a neutron star-neutron star collision, a black hole-black hole collision, or some phenomenon not yet considered.\n\nHowever, in 2010 there was a new report of 16 similar pulses from the Parkes Telescope which were clearly of terrestrial origin.\n\nPrevious searches by SETI@home have looked for extraterrestrial communications in the form of narrow-band signals, analogous to our own radio stations. The Astropulse project argues that since we know nothing about how ET might communicate, this might be a bit closed-minded. Thus, the Astropulse survey can be viewed as supplementing the narrow-band SETI@home survey as a by-product of the search for physical phenomena.\n\nRF radiation from outer space was first discovered by Karl G. Jansky (1905–1950), who worked as a radio engineer at the Bell Telephone Laboratories to studying radio frequency interference from thunderstorms for Bell Laboratories. He found \"...a steady hiss type static of unknown origin\", which eventually he concluded had an extraterrestrial origin. Pulsars (rotating neutron stars) and quasars (dense central cores of extremely distant galaxies) were both discovered by radio astronomers. In 2003 astronomers using the Parkes radio telescope discovered two pulsars orbiting each other, the first such system known. Explaining their recent discovery of a powerful bursting radio source, NRL astronomer Dr. Joseph Lazio stated: \"Amazingly, even though the sky is known to be full of transient objects emitting at X- and gamma-ray wavelengths, very little has been done to look for radio bursts, which are often easier for astronomical objects to produce.\" The use of coherent dedispersion algorithms and the computing power provided by the SETI network may lead to discovery of previously undiscovered phenomena.\n\nAstropulse and its older partner, SETI@home, offer a concrete way for secondary school science teachers to involve their students with astronomy and computing. A number of schools maintain distributed computing class projects.\n\n\n"}
{"id": "19463014", "url": "https://en.wikipedia.org/wiki?curid=19463014", "title": "Atomic emission spectroscopy", "text": "Atomic emission spectroscopy\n\nAtomic emission spectroscopy (AES) is a method of chemical analysis that uses the intensity of light emitted from a flame, plasma, arc, or spark at a particular wavelength to determine the quantity of an element in a sample. The wavelength of the atomic spectral line gives the identity of the element while the intensity of the emitted light is proportional to the number of atoms of the element\n\nA sample of a material (analyte) is brought into the flame as a gas, sprayed solution, or directly inserted into the flame by use of a small loop of wire, usually platinum. The heat from the flame evaporates the solvent and breaks chemical bonds to create free atoms. The thermal energy also excites the atoms into excited electronic states that subsequently emit light when they return to the ground electronic state. Each element emits light at a characteristic wavelength, which is dispersed by a grating or prism and detected in the spectrometer.\n\nA frequent application of the emission measurement with the flame is the regulation of alkali metals for pharmaceutical analytics.\n\nInductively coupled plasma atomic emission spectroscopy (ICP-AES) uses an inductively coupled plasma to produce excited atoms and ions that emit electromagnetic radiation at wavelengths characteristic of a particular element.\n\nAdvantages of ICP-AES are excellent limit of detection and linear dynamic range, multi-element capability, low chemical interference and a stable and reproducible signal. Disadvantages are spectral interferences (many emission lines), cost and operating expense and the fact that samples typically must be in a liquid solution.\n\nSpark or arc atomic emission spectroscopy is used for the analysis of metallic elements in solid samples. For non-conductive materials, the sample is ground with graphite powder to make it conductive. In traditional arc spectroscopy methods, a sample of the solid was commonly ground up and destroyed during analysis. An electric arc or spark is passed through the sample, heating it to a high temperature to excite the atoms within it. The excited analyte atoms emit light at characteristic wavelengths that can be dispersed with a monochromator and detected. In the past, the spark or arc conditions were typically not well controlled, the analysis for the elements in the sample were qualitative. However, modern spark sources with controlled discharges can be considered quantitative. Both qualitative and quantitative spark analysis are widely used for production quality control in foundry and metal casting facilities.\n\n\n"}
{"id": "37713215", "url": "https://en.wikipedia.org/wiki?curid=37713215", "title": "Centre for Independent Social Research", "text": "Centre for Independent Social Research\n\nCentre for Independent Social Research (CISR) is a nongovernmental research institute in Russia working in four main areas: Social research projects; professional development of young sociologists; the formation of professional networks in the social sciences; Sociological expertise and consultations. The CISR activities are financed mainly through Russian and international scientific funds and philanthropic organizations. Since 2001, the John D. and Catherine T. MacArthur Foundation has been a key partner of CISR.\n\nThe thought of establishing an independent sociological center first arose in the late 1980s and was the idea of Viktor Voronkov and Oleg Vite, who, at the time, were employees of the Leningrad division of the Academy of Sciences’ Institute of Sociology. Inspired by the rapid social and political changes taking place in the country, they gathered a group of enthusiasts and started conducting their own independent research projects. Edward Fomin, Elena Zdravomyslova, and Ingrid Oswald actively participated in the practical fulfillment of this idea. They all shared a desire to create a flexible, democratic research structure that would be capable of responding to the demands of a quickly changing Russian society and of promoting the integration of Russian sociologists into the international sociological community. The Center actually began working a few years before it was legally registered in 1991.\n\nIn 1994, the Center acquired a converted apartment office on Vasileostrovsky Island. Thanks to the active participation of Ingrid Oswald and the support of Peter Lock and other colleagues and friends of the Center, CISR quickly developed, received more and more grants from international foundations, conducted various research projects, and became a visible actor in the Russian and international sociological communities. In 2000, CISR was able to acquire new office space on Ligovsky Prospect thanks to a grant from the Ford Foundation. The next year (2001), CISR received its first institutional grant from the John D. and Catherine T. MacArthur Foundation.\n\nEmployees of the Center worked hard to ensure that the constructivist approach (marginal for Russia in the 1990s) and qualitative methods were included in Russian researchers’ arsenal. This was made possible by several factors: holding international methodological conferences such as “The Biographical Method of Studying Post-Socialistic Societies (1996),” carrying out educational projects focused on the popularization of qualitative methods for research among young sociologists, and publishing books detailing the results of empirical studies, including “The Construction of Ethnicity: Ethnic Communities in St. Petersburg (1998).” Continuing the tradition of researching relevant social processes, developing new approaches to social research, and integrating into the international community, CISR has organized several conferences: The Social Sciences, Racial Discourse, and Discriminatory Practices (2004); The Biographical Method in the Study of Post-Socialist Societies: 10 Years Later (2006); The Russian Field: A look from Abroad (2009).\n\nIn 2004, CISR initiated the creation of the Convention of Independent Sociological Centers of Russia (CISC) which united around 20 research organizations. Under the direction of the Convention, the first two books of the series Qualitative Methods in Social Research were published: I. Shteinberg, T. Shanin, E. Kovalev, A. Levinson Qualitative Methods. Sociological Field Studies and a collection of articles Leave in Order to Stay: the Sociologist in the Field.\n\nThe Center has always occupied itself with the socialization of young researchers. Since 1998, CISR has been partners with the Heinrich Boell Foundation (Moscow/Berlin) working to create a scholarship program for talented young researchers. In 2000, the German-Russian Forum and the Robert Bosch Foundation awarded CISR a commemorative medal for their “contribution to the training of young researchers.” Since 2003, CISR has organized workshops on qualitative research methods for students of the Center for Sociological Education, Institute for Sociology, Russian Academy of Sciences (Moscow). In 2004 and 2005, an analogous program was opened in partnership with the upper school Osterlens Folkhogskola (Tomelilla, Sweden) for Swedish students.\n\nCISR employs 22 individuals: 12 hold Ph.Ds., several others are working on their dissertations. Professional areas of research include:\n\nApproximately 30 research projects are carried out every year. The researchers’ experiences serve as the basis for academic courses they teach in leading Russian and foreign institutions, including: European University at St. Petersburg, St. Petersburg State University, the Higher School of Economics (St. Petersburg), Free University of Berlin, Humboldt University of Berlin, the University of Freiburg, the University of Eastern Finland, Helsinki University, Johns Hopkins University (USA), Yale University (USA), and others.\n"}
{"id": "16659346", "url": "https://en.wikipedia.org/wiki?curid=16659346", "title": "Cosmo Argento", "text": "Cosmo Argento\n\nCosmo Argento was a series of science fiction books published in Italy by Editrice Nord starting from October 1970. Differently from the similar re-prints collection \"Cosmo Oro\", it usually consisted of translations of US books previously unpublished in the country. Authors included science fiction writers such as Philip J. Farmer, Jack Vance, Frederik Pohl, John Brunner, Gordon R. Dickson, Larry Niven and many others. Original works by Italian authors were regularly published also.\n\nThe series reduced substantially in quality and frequency of publication in the 2000s, and ceased publication with issue #337 in January 2005 (\"The Phoenix Exultant\" by John C. Wright).\n"}
{"id": "24547311", "url": "https://en.wikipedia.org/wiki?curid=24547311", "title": "Covenant of Mayors", "text": "Covenant of Mayors\n\nThe Covenant of Mayors is a European co-operation movement involving local and regional authorities. Signatories of the Covenant of Mayors voluntarily commit to increasing energy efficiency and the use of renewable energy sources on their territories. By their commitment, they support the European Union 20% reduction objective to be reached by 2020.\n\nAfter the European Union climate and energy package was adopted in 2008, the European Commission launched the Covenant of Mayors to endorse and support the efforts deployed by local authorities in the implementation of sustainable energy policies. \n\nEuropean local authorities of all sizes – from small villages to capitals and major metropolitan areas – are eligible to sign up as Covenant of Mayors Signatories.\n\nCities, towns and other urban areas have a crucial role to play in mitigating climate change, as they consume three quarter of the energy produced in the European Union and are responsible for a similar share of emissions. Local authorities are also in a position to change citizens' behaviour and address climate and energy questions in a comprehensive manner, notably by conciliating public and private interests and by integrating sustainable energy issues into overall local development goals.\n\nTo meet the reduction targets they set themselves, signatories commit to a series of steps and accept to report and be monitored on their actions. Within predefined time frames, they formally undertake to fulfil the following:\n\n\nTo comply with the crucial necessity of mobilising local stakeholders in the development of the Sustainable Energy Action Plans, signatories also undertake to:\n\n\nTo reach and try to exceed the European Union energy and climate objectives, Covenant of Mayors signatories commit to develop a Sustainable Energy Action Plan (SEAP), within a year following their adhesion to the initiative. This action plan, approved by the municipal council, outlines the activities and measures foreseen by signatories to fulfil their commitments, with corresponding time frames and assigned responsibilities.\n\nVarious technical and methodological supporting materials (including the \"SEAP Guidebook\" and template, reports on existing methodologies and tools, etc.) offer practical guidance and clear recommendations on the whole SEAP development process. Based on the practical experiences of local authorities and developed in close co-operation with the European Commission Joint Research Centre, this support package provides Covenant signatories with key principles and a clear step-by-step approach. All documents are downloadable on the www.eumayors.eu website library.\n\nCovenant Signatories do not always possess the adequate tools and resources to prepare a Baseline Emission Inventory, draft the related Sustainable Energy Action Plan and finance the actions featured in the latter. In light of this, provinces, regions, networks and groupings of municipalities have a crucial role to play in helping signatories honour their commitments.\n\nCovenant Coordinators are public authorities from different government levels (national, regional, provincial) which provide strategic guidance to signatories, as well as financial and technical support in the development and implementation of their Sustainable Energy Action Plans. The Commission distinguishes between \"Territorial Coordinators\", which are sub-national decentralised authorities – including provinces, regions and public groupings of municipalities -, and \"National Coordinators\", which include national public bodies – such as national energy agencies and ministries of energy.\n\nCovenant Supporters are European, national and regional networks and associations of local authorities which leverage their lobbying, communication and networking activities to promote the Covenant of Mayors initiative and support the commitments of its signatories.\n\nPromotional, technical and administrative assistance is provided on a daily basis to Covenant signatories and stakeholders by the Covenant of Mayors Office (CoMO), managed by a consortium of local and regional authorities' networks, led by Energy Cities and composed of CEMR, Climate Alliance, Eurocities and FEDARENE. Funded by the European Commission, the CoMO is responsible for the overall co-ordination of the initiative.\n\nTo support the elaboration and implementation the signatories' Sustainable Energy Action Plans, the European Commission has contributed to the development of financial facilities particularly targeting Covenant of Mayors signatories, among which the European Local Energy Assistance (ELENA) facility, set up in co-operation with the European Investment Bank, for large-scale projects, and ELENA-KfW which, established in partnership with the German Group KfW, offers a complementary approach to mobilise sustainable investments of small and medium-sized municipalities.\n\nAlongside the European Commission, the Covenant benefits from full institutional support, including from the Committee of the Regions, which has supported the initiative since its inception; the European Parliament, where the two first signing ceremonies were held; and the European Investment Bank, which assists local authorities in unlocking their investment potentials.\n\nThe Joint Research Centre of the European Commission is responsible for providing technical and scientific support to the initiative. It works in close collaboration with the Covenant of Mayors Office to equip signatories with clear technical guidelines and templates to assist delivery of their Covenant of Mayors commitments, as well as to monitor implementation and results.\n\n\n"}
{"id": "31911164", "url": "https://en.wikipedia.org/wiki?curid=31911164", "title": "Deferribacter", "text": "Deferribacter\n\nDeferribacter is a genus in the phylum Deferribacteres (Bacteria).\n\nThe name \"Deferribacter\" derives from:Latin pref. \"de\"-, from; Latin noun \"ferrum\", iron; New Latin masculine gender noun, a rod\"bacter\", nominally meaning \"a rod\", but in effect meaning a bacterium, rod; New Latin masculine gender noun \"Deferribacter\", rod that reduces iron.\n\nThe genus contains 4 species, namely\n\n"}
{"id": "58194011", "url": "https://en.wikipedia.org/wiki?curid=58194011", "title": "Djieien", "text": "Djieien\n\nIn Seneca mythology, Djieien is a monstrous spider six feet tall. It could not be killed because it had hidden its heart underground. The great hero Othegwenhda (Hiawatha) discovered Dijien's heart and so killed it.\n\nDjieien figures in the tale of \"Hagowanen and Ot'hegwenhda\". \n"}
{"id": "1399676", "url": "https://en.wikipedia.org/wiki?curid=1399676", "title": "Edmund Gunter", "text": "Edmund Gunter\n\nEdmund Gunter (1581 – 10 December 1626), was an English clergyman, mathematician, geometer and astronomer of Welsh descent. He is best remembered for his mathematical contributions which include the invention of the Gunter's chain, the Gunter's quadrant, and the Gunter's scale. In 1620, he invented the first successful analogue device which he developed to calculate logarithmic tangents.\n\nHe was mentored in mathematics by Reverend Henry Briggs and eventually became a Gresham Professor of Astronomy, from 1619 until his death.\n\nGunter was born in Hertfordshire in 1581. He was educated at Westminster School, and in 1599 he matriculated at Christ Church, Oxford. He took orders, became a preacher in 1614, and in 1615 proceeded to the degree of bachelor in divinity. He became rector of St. George's Church in Southwark.\n\nMathematics, particularly the relationship between mathematics and the real world, was the one overriding interest throughout his life. In 1619, Sir Henry Savile put up money to fund Oxford University's first two science faculties, the chairs of astronomy and geometry. Gunter applied to become professor of geometry but Savile was famous for distrusting clever people, and Gunter's behaviour annoyed him intensely. As was his habit, Gunter arrived with his sector and quadrant, and began demonstrating how they could be used to calculate the position of stars or the distance of churches, until Savile could stand it no longer. \"Doe you call this reading of Geometric?\" he burst out. \"This is mere showing of tricks, man!\" and, according to a contemporary account, \"dismissed him with scorne.\"\n\nHe was shortly thereafter championed by the far wealthier Earl of Bridgewater, who saw to it that on 6 March 1619 Gunter was appointed professor of astronomy in Gresham College, London. This post he held till his death.\n\nWith Gunter's name are associated several useful inventions, descriptions of which are given in his treatises on the sector, cross-staff, bow, quadrant and other instruments. He contrived his sector about the year 1606, and wrote a description of it in Latin, but it was more than sixteen years afterwards before he allowed the book to appear in English. In 1620 he published his \"Canon triangulorum\".\n\nIn 1624 Gunter published a collection of his mathematical works. It was entitled \"The description and use of sector, the cross-staffe, and other instruments for such as are studious of mathematical practise.\" One of the most remarkable things about this book is that it was written, and published, in English not Latin. \"I am at the last contented that it should come forth in English,\" he wrote resignedly, \"Not that I think it worthy either of my labour or the publique view, but to satisfy their importunity who not understand the Latin yet were at the charge to buy the instrument.\" It was a manual not for cloistered university fellows but for sailors and surveyors in real world.\n\nThere is reason to believe that Gunter was the first to discover (in 1622 or 1625) that the magnetic needle does not retain the same declination in the same place at all times. By desire of James I he published in 1624 \"The Description and Use of His Majesties Dials in Whitehall Garden\", the only one of his works which has not been reprinted. He coined the terms cosine and cotangent, and he suggested to Henry Briggs, his friend and colleague, the use of the arithmetical complement (see Briggs \"Arithmetica Logarithmica\", cap. xv.). His practical inventions are briefly noted below:\n\nGunter's interest in geometry led him to develop a method of sea surveying using triangulation. Linear measurements could be taken between topographical features such as corners of a field, and using triangulation the field or other area could be plotted on a plane, and its area calculated. A chain long, with intermediate measurements indicated, was chosen for the purpose, and is called Gunter's chain.\n\nThe length of the chain chosen, , being called a chain gives a unit easily converted to area. Therefore, a parcel of 10 square chains gives 1 acre. The area of any parcel measured in chains will thereby be easily calculated.\n\nGunter's quadrant is an instrument made of wood, brass or other substance, containing a kind of stereographic projection of the sphere on the plane of the equinoctial, the eye being supposed to be placed in one of the poles, so that the tropic, ecliptic, and horizon form the arcs of circles, but the hour circles are other curves, drawn by means of several altitudes of the sun for some particular latitude every year. This instrument is used to find the hour of the day, the sun's azimuth, etc., and other common problems of the sphere or globe, and also to take the altitude of an object in degrees.\n\nA rare Gunter quadrant, made by Henry Sutton and dated 1657, can be described as follows: It is a conveniently sized and high-performance instrument that has two pin-hole sights, and the plumb line is inserted at the vertex. The front side is designed as a Gunter quadrant and the rear side as a trigonometric quadrant. The side with the astrolabe has hour lines, a calendar, zodiacs, star positions, astrolabe projections, and a vertical dial. The side with the geometric quadrants features several trigonometric functions, rules, a shadow quadrant, and the chorden line.\n\nGunter's scale or Gunter's rule, generally called the \"Gunter\" by seamen, is a large plane scale, usually long by about 1½ inches broad (600 mm by 40 mm), and engraved with various scales, or lines. On one side are placed the natural lines (as the line of chords, the line of sines, tangents, rhumbs, etc.), and on the other side the corresponding artificial or logarithmic ones. By means of this instrument questions in navigation, trigonometry, etc., are solved with the aid of a pair of compasses. It is a predecessor of the slide rule, a calculating aid used from the 17th century until the 1970s.\n\n\"Gunter's line\", or \"line of numbers\" refers to the logarithmically divided scale, like the most common scales used on slide rules for multiplication and division.\n\nA sail rig which resembles a gaff rig, with the gaff nearly vertical, is called a Gunter rig, or \"sliding gunter\" from its resemblance to a Gunter's rule.\n\n\n\n"}
{"id": "2229858", "url": "https://en.wikipedia.org/wiki?curid=2229858", "title": "Ewen Montagu", "text": "Ewen Montagu\n\nCaptain The Hon. Ewen Edward Samuel Montagu, CBE, QC, DL, RNR (19 March 1901 – 19 July 1985) was a British judge, writer and Naval intelligence officer. He is well known for his leading role in Operation Mincemeat, a critical military deception operation which misdirected German forces' attention away from the Allied Invasion of Sicily in Operation Husky.\n\nMontagu was born in 1901, the second son of Louis Montagu, 2nd Baron Swaythling. He was educated at Westminster School before becoming a machine gun instructor during the First World War at a United States Naval Air Station. After the war he studied at Trinity College, Cambridge and at Harvard University before he was called to the bar in 1924. One of his more celebrated cases as a junior barrister was the defence of Alma Rattenbury in 1935 against a charge of murdering her elderly husband at the Villa Madeira in Bournemouth.\n\nMontagu was a keen yachtsman, and enlisted in the Royal Navy Volunteer Reserve in 1938. Because of his legal background he was reassigned to specialized study. From there he was assigned to the Royal Navy's Humberside headquarters at Hull as an assistant staff officer in intelligence. Montagu served in the Naval Intelligence Division of the British Admiralty, rising to the rank of Lieutenant Commander RNVR. He was the Naval Representative on the XX Committee, which oversaw the running of double agents. While Commanding Officer of NID 17M, he and Squadron Leader Charles Cholmondely RAFVR conceived Operation Mincemeat, a major deception operation. Montagu had the idea of having a corpse dressed as a British officer wash ashore in Spain, carrying faked papers revealing plans for invasion of Greece (the real target was Sicily). The location chosen was where pro-German Spanish officials would show the papers to German agents. Montagu also manufactured an entire false identity for the corpse to have in his pockets: military ID, theater ticket stubs, love letters and a photo of his fiancée, bills from a tailor and jeweler.\n\nThe Germans were fooled completely. German documents found after the war showed that the false information went all the way to Hitler's headquarters, and led to German forces being diverted to Greece. The invasion of Sicily was a success. Historian Hugh Trevor-Roper called it the best deception in the history of military deception. For his role in Operation Mincemeat, Montagu was appointed to the Military Division of the Order of the British Empire.\n\nFrom 1945 to 1973 he held the position of Judge Advocate of the Fleet. He wrote \"The Man Who Never Was\" (1953), an account of Operation Mincemeat, which was made into a movie three years later. Montagu himself appeared in the film adaptation of \"The Man Who Never Was\", playing an Air-Vice Marshal who had in real life disparaged his own character (played by Clifton Webb) in a briefing. Montagu also wrote \"Beyond Top Secret Ultra\", which focused more on the information technology and espionage tactics used in World War II.\n\nHe was a governor of a public health project, the Peckham Experiment, in 1949.\n\nMontagu was president of the United Synagogue, 1954–62, and President of the Anglo-Jewish Association from December 1949.\n\nBefore the Courts Act of 1971 he was Chairman of the Quarter Sessions for the Middlesex area of Greater London and Recorder (judge) in the County of Hampshire. He was appointed Deputy Lieutenant of the County of Southampton.\n\nMontagu's youngest brother Ivor Montagu was a film maker and Communist.\n\nEwen Montagu married Iris, the daughter of the painter Solomon J. Solomon, in 1923. They had a son, Jeremy, who became an authority on musical instruments, and a daughter, Jennifer, who became an art historian.\n\n"}
{"id": "12634188", "url": "https://en.wikipedia.org/wiki?curid=12634188", "title": "Exocannibalism", "text": "Exocannibalism\n\nExocannibalism (from Greek \"exo-\", \"from outside\" and cannibalism, \"to eat humans\"), as opposed to endocannibalism, is the consumption of flesh outside one's close social group—for example, eating one's enemy. When done ritually, it has been associated with being a means of imbibing valued qualities of the victim or as an act of final violence against the deceased in the case of sociopathy, as well as a symbolic expression of the domination of an enemy in warfare. Such practices have been documented in cultures including the Aztecs from Mexico, the Carib and the Tupinambá from South America.\n\nHistorically, it has also been used as a practical expediency in especially desperate attritional or guerrilla warfare when the extreme hunger and the abundance of humans being killed coincide to create conditions ripe for cannibalism. Some viewed the practice of exocannibalism as an act of predation tying the action to more of a prey versus predator scenario than one of ceremonial meaning. Exocannibalism has also historically been viewed as a way to acquire the strength and ability of a defeated enemy. It serves as a final act to either intake or extinguish the existence of an enemy. Notably, the cultures that view exocannibalism as a form of predation do not view the act as taboo. \n\nCannibalism is something that has been found wherever and whenever humans have formed societies. Traditionally, accounts of cannibalism were found embedded in myths and folklore as a common motive that indicated people were less than fully human. Exocannibalism in the form of eating enemies is usually done to express hostility and domination toward the victim. The perpetrator eats their victim to inflict ultimate indignity and humiliation. It has also been practiced along with headhunting and scalping to display war trophies. John Kantner, an archaeologist who studied alleged cannibalism in the American Southwest, believes that when resources decrease the competition of societies increased and exocannibalism can ensue. Exocannibalism would generally be considered to be the opposite of endocannibalism, but they are both forms of ritual cannibalism. There have been no previous accounts of a culture practicing both forms of ritual cannibalism, aside from a recent study that confirmed the Wari', an Amazonian tribe in Brazil, practiced both forms.\n\n\nThe Wari people of South America are known for their practice of both endocannibalism and exocannibalism. Endocannibalism had the ability to serve as a form of recognition and respect for the dead. Exocannibalism on the other hand was part of warfare. The Wari had very separate motives behind why they performed each of these modes of cannibalism but both forms had the same basic steps of roasting either flesh or bone and then eating it. Wari warriors would kill enemies such as the Brazilians, Bolivians, and members of enemy tribes. The Wari consumed these enemies as a means of transforming them into a form of prey. They viewed warfare cannibalism as a form of predation or hunting. They used exocannibalism as a means by which to label their enemies as subhuman and make their flesh as unimportant as that of any other animal that was typically killed for food. This practice of cannibalism was continued by the Wari people until the 1960s.\n\nThe people of Fiji are also documented as having participated in exocannibalism as a form of ritualistic behavior, though history of this is typically hidden by European modification. From Fijian legend, the development of the island was due to a god who brought with him cannibalism and warfare. When he arrived on the island, he then married into the single indigenous family. That family then populated the island. This legend along with cannibalism continued into the reality of Fijian people. During wartime, chiefs were able to have their pick of the warriors and soldiers who were killed, seeking out the most famous of those slain. The rest of the soldiers killed that chief did not want would be consumed by the rest of the common people. This form of consumption of the dead was not out of need but instead served as a means by which to assert their power over a conquered people. Consumption of human flesh was not viewed as taboo, but instead was viewed as an act of dining with the gods or dining on the food of gods. Along with consuming the flesh to show domination over slain enemies, cannibalism was also part of both political and religious rituals performed by the Fijian people. Cannibalism persisted in the Fijian culture because of the cultural beliefs regarding it.\n\n\n"}
{"id": "38200354", "url": "https://en.wikipedia.org/wiki?curid=38200354", "title": "Fanaroff-Riley classification", "text": "Fanaroff-Riley classification\n\nThe Fanaroff-Riley classification is a scheme created by B.L. Fanaroff and J.M. Riley in 1974, which is used to distinguish radio galaxies with active nuclei based on their radio luminosity or brightness of their radio emissions in relation to their hosting environment. \"Class I\" (abbreviated FR-I) are sources whose luminosity decreases as the distance from the central galaxy or quasar host increase, while \"Class II\" (FR-II) sources exhibit increasing luminosity in the lobes. These sources are called also \"edge-brightened\". This distinction is important because it presents a direct link between the galaxy's luminosity and the way in which energy is transported from the central region and converted to radio emission in the outer parts.\n\n"}
{"id": "15719685", "url": "https://en.wikipedia.org/wiki?curid=15719685", "title": "Figuring", "text": "Figuring\n\nFiguring is the process of final polishing of an optical surface to remove imperfections or modify the surface curvature to achieve the shape required for a given application. \n\nAn example of figuring is that used in reflecting telescope primary mirrors in a process of converting the smooth spherical mirror produced by earlier stages into the aspherical or parabolic shapes needed to form the correct image. It is done by applying different polishing stroke lengths with different sized and shaped tools. Manual figuring is a very laborious process, since the heat produced by polishing has to be allowed to dissipate before the shape of the mirror can be measured again, and the places for later polishing selected. Testing of the figure is usually done by a Foucault knife-edge test or Ronchi test in amateur telescope making and with very sophisticated null testers on research telescope optics.\n\nFor large mirrors, ion figuring is often used, in which a beam of neutral atoms is used to remove material from the optics in a very controlled way. This is particularly useful in the manufacture of segmented mirrors, since the shape of the optics can be maintained correctly all the way to the edge of the aperture, whilst mechanical polishing techniques tend to have trouble with distortion of the polishing tool when it overhangs the edge. The first major use of ion figuring was in making the mirror segments for the Keck telescope.\n\nThe ultra-high precision requirements for optical surfaces for X-ray astronomy and deep-ultraviolet lithography often require ion figuring.\n"}
{"id": "35111617", "url": "https://en.wikipedia.org/wiki?curid=35111617", "title": "George Kenneth Green", "text": "George Kenneth Green\n\nGeorge Kenneth Green, also called Kenneth Green, (1911 – August 1997) was an American accelerator physicist.\n\nGreen studied at the University of California, Berkeley, where he belonged to the group of Ernest Lawrence. Later, he worked at Brookhaven National Laboratory (BNL) with Milton Stanley Livingston. After the discovery of Strong focusing by Ernest Courant et al., Green implemented the idea into the design of the Alternating Gradient Synchrotron, collaborating with John Blewett.\n\nHe was later working on the proposal for the National Synchrotron Light Source, which construction was begun in 1978.\n\nCollaborating with Renate Chasman, he developed the Chasman-Green lattice, which was later used for storage rings of synchrotron light sources.\n"}
{"id": "21675886", "url": "https://en.wikipedia.org/wiki?curid=21675886", "title": "Germs: Biological Weapons and America's Secret War", "text": "Germs: Biological Weapons and America's Secret War\n\nGerms: Biological Weapons and America's Secret War (2001) describes how humanity has dealt with biological weapons, and the dangers of bioterrorism. It was written by \"The New York Times\" journalists Judith Miller, Stephen Engelberg, and William Broad and was the 2001 \"New York Times\" #1 Non-Fiction Bestseller the weeks of October 28 and November 4.\n\n\"Germs\", is a work of investigative journalism employing biographical and historical narrative to provide context. The three authors interviewed hundreds of scientists and senior U.S. officials, and reviewed recently declassified documents, and reports from the former Soviet Union's bioweapons laboratories.\n\nThe book opens with an account of the 1984 salmonella poisonings in The Dalles, Oregon, caused by followers of Bhagwan Shree Rajneesh who sprayed salmonella onto salad bars. Other research shows how Moscow scientists created an untraceable germ that would induce the body to self-destruct, and reveals that the U.S. military planned for germ warfare on Cuba during the 1960s. Three classified U.S. biodefense projects are detailed: Project Bacchus, Project Clear Vision, and Project Jefferson. \"Germs\" concludes with an assessment of the United States' ability to deter future bio-attack.\n\n\"The New York Times Book Review\" was favorable, though it criticized the book's tone as \"somewhat alarmist\". \"BusinessWeek\" was also generally favorable, except for pointing out some conflicting views on bioterrorism. \"The Guardian\"'s book review by British psychiatrist Simon Wessely, cautioned against panic, stating that biological weapons can cause destruction through fear, effectively giving the biodefense industry \"the equivalent of a blank cheque\".\n\nOn November 13, 2001, the science TV series \"Nova\" aired an episode entitled \"Bioterror\". Two years in the making, it chronicled Miller, Engelberg, and Broad's research and investigation into biological weapons.\n"}
{"id": "13286252", "url": "https://en.wikipedia.org/wiki?curid=13286252", "title": "Graphism thesis", "text": "Graphism thesis\n\nIn sociology of science, the graphism thesis is a proposition of Bruno Latour that graphs are important in science.\n\nResearch has shown that one can distinguish between hard science and soft science disciplines based on the level of graph use, so it can be argued that there is a correlation between scientificity and visuality. Furthermore, natural sciences publications appear to make heavier use of graphs than mathematical and social sciences.\n\nIt has been claimed that an example of a discipline that uses graphs heavily but is not at all scientific is technical analysis.\n\n\n"}
{"id": "15544038", "url": "https://en.wikipedia.org/wiki?curid=15544038", "title": "Hamaker constant", "text": "Hamaker constant\n\nThe Hamaker constant \"A\" can be defined for a Van der Waals (VdW) body–body interaction:\nwhere formula_2 and formula_3 are the number densities of the two interacting kinds of particles, and \"C\" is the coefficient in the particle–particle pair interaction. It is named after H. C. Hamaker.\n\nThe Hamaker constant provides the means to determine the interaction parameter \"C\" from the Van der Waals pair potential, formula_4.\n\nHamaker's method and the associated Hamaker constant ignores the influence of an intervening medium between the two particles of interaction. In the 1950s Lifshitz developed a description of the VdW energy but with consideration of the dielectric properties of this intervening medium (often a continuous phase).\n\nThe Van der Waals forces are effective only up to several hundred angstroms. When the interactions are too far apart, the dispersion potential decays faster than formula_5; this is called the retarded regime, and the result is a Casimir–Polder force.\n\n"}
{"id": "5888364", "url": "https://en.wikipedia.org/wiki?curid=5888364", "title": "Herder Prize", "text": "Herder Prize\n\nThe Herder Prize (), named after the German philosopher Johann Gottfried Herder, was a prestigious international prize awarded every year to scholars and artists from Central and Southeast Europe whose life and work have contributed to the cultural understanding of European countries and their peaceful interrelations. Established in 1963, the first prizes were awarded in 1964.\n\nThe prize jury was composed of German and Austrian universities. Financing for the Prize, which amounted to €15,000, was sponsored by the Alfred Toepfer Foundation based in Hamburg. The awards were traditionally presented in an annual ceremony at the University of Vienna and handed over by the President of Austria. Each prize also included a one-year scholarship at an Austrian university given to a young person nominated by the winning scholar.\n\nThe prize was open to humanities scholars and artists from a wide variety of fields, including ethnographers, writers, architects, composers, poets, folklorists, painters, historians, literary scholars, art historians, archeologists, theatre directors, musicologists, museologists, linguists, playwrights, etc. Several writers who received the Herder Prize went on to later win the Nobel Prize in Literature, such as Wisława Szymborska (in 1995 and 1996), Imre Kertész (in 2000 and 2002), and Svetlana Alexievich (in 1999 and 2015), and many other recipients received other international accolades and were members of their national academies.\n\nSince its inception the prize was open to scholars and artists from seven central and southeast, mostly communist, European countries (Bulgaria, Czechoslovakia, Greece, Hungary, Poland, Romania and Yugoslavia). After the fall of communism in Europe in the late 1980s and the subsequent turmoil which led to the breakup of Yugoslavia, the dissolution of the Soviet Union and the dissolution of Czechoslovakia, scholars from all the succeeding countries remained eligible for the prize. In the early 1990s several ex-Soviet European countries (the Baltic nations of Estonia, Latvia, and Lithuania; Belarus, and Ukraine) as well as Albania were also made eligible.\n\nUsually seven recipients would be announced every year, except in 1964 (four), 1977 (eight), 1993 (nine), and in 2006 (five) — which was also the last edition of the Herder Prize. In 2007 the prize was discontinued and merged with other prize funds sponsored by the Alfred Toepfer Foundation to create a new Europe-wide annual award, the KAIROS Prize, worth €75,000 and given to a single artist every year to encourage their innovative work.\n\n\n"}
{"id": "347322", "url": "https://en.wikipedia.org/wiki?curid=347322", "title": "Holotype", "text": "Holotype\n\nA holotype is a single physical example (or illustration) of an organism, known to have been used when the species (or lower-ranked taxon) was formally described. It is either the single such physical example (or illustration) or one of several such, but explicitly designated as the holotype. Under the International Code of Zoological Nomenclature (ICZN), a holotype is one of several kinds of name-bearing types. In the International Code of Nomenclature for algae, fungi, and plants (ICN) and ICZN the definitions of types are similar in intent but not identical in terminology or underlying concept.\n\nFor example, the holotype for the butterfly \"Lycaeides idas longinus\" is a preserved specimen of that species, held by the Museum of Comparative Zoology at Harvard University. An isotype is a duplicate of the holotype and is often made for plants, where holotype and isotypes are often pieces from the same individual plant or samples from the same gathering.\n\nA holotype is not necessarily \"typical\" of that taxon, although ideally it should be. Sometimes just a fragment of an organism is the holotype, particularly in the case of a fossil. For example, the holotype of \"Pelorosaurus humerocristatus\" (Duriatitan), a large herbivorous dinosaur from the early Jurassic period, is a fossil leg bone stored at the Natural History Museum in London. Even if a better specimen is subsequently found, the holotype is not superseded.\n\nUnder the ICN, an additional and clarifying type could be designated an epitype under Article 9.8, where the original material is demonstrably ambiguous or insufficient.\n\nA conserved type (ICN article 14.3) is sometimes used to correct a problem with a name which has been misapplied; this specimen replaces the original holotype.\n\nIn the absence of a holotype, another type may be selected, out of a range of different kinds of type, depending on the case, a lectotype or a neotype.\n\nFor example, in both the ICN and the ICZN a neotype is a type that was later appointed in the absence of the original holotype. Additionally, under the ICZN the Commission is empowered to replace a holotype with a neotype, when the holotype turns out to lack important diagnostic features needed to distinguish the species from its close relatives. For example, the crocodile-like archosaurian reptile \"Parasuchus hislopi\" Lydekker, 1885 was described based on a premaxillary rostrum (part of the snout), but this is no longer sufficient to distinguish \"Parasuchus\" from its close relatives. This made the name \"Parasuchus hislopi\" a \"nomen dubium\". Texan paleontologist Sankar Chatterjee proposed that a new type specimen, a complete skeleton, be designated. The International Commission on Zoological Nomenclature considered the case and agreed to replace the original type specimen with the proposed neotype.\nThe procedures for the designation of a new type specimen when the original is lost come into play for some recent, high-profile species descriptions in which the specimen designated as the holotype was a living individual that was allowed to remain in the wild (e.g. a new species of capuchin monkey, genus \"Cebus\", \"Marleyimyia xylocopae\", or the Arunachal macaque \"Macaca munzala\"). In such a case, there is no actual type specimen available for study, and the possibility exists that—should there be any perceived ambiguity in the identity of the species—subsequent authors can invoke various clauses in the ICZN Code that allow for the designation of a neotype. Article 75.3.7 of the ICZN requires that the designation of a neotype must be accompanied by \"a statement that the neotype is, or immediately upon publication has become, the property of a recognized scientific or educational institution, cited by name, that maintains a research collection, with proper facilities for preserving name-bearing types, and that makes them accessible for study\", but there is no such requirement for a holotype.\n\n\n"}
{"id": "638740", "url": "https://en.wikipedia.org/wiki?curid=638740", "title": "Institute for Dialectology, Onomastics and Folklore Research in Umeå", "text": "Institute for Dialectology, Onomastics and Folklore Research in Umeå\n\nDAUM, the Institute for Dialectology, Onomastics and Folklore Research in Umeå (), is a Swedish governmental archive bureau which collects, preserves, works up and provides information about dialects, place names, folklore culture and local history. DAUM is part of the Swedish Institute for Language and Folklore.\n\n"}
{"id": "29272654", "url": "https://en.wikipedia.org/wiki?curid=29272654", "title": "Institute for the History of Science, Polish Academy of Sciences", "text": "Institute for the History of Science, Polish Academy of Sciences\n\nThe Institute for the History of Science was established in 1954 as an institution of the Polish Academy of Sciences in Poland.\nThe Institute is located in the Staszic Palace in the center of Warsaw, near the Copernicus monument. Among its founders were professors: Bogdan Suchodolski and Aleksander Birkenmajer. In the mid 1970s, it was renamed to the Institute for the History of Science, Education and Technology. Since 1994, the name has been shortened to the Institute for the History of Science, but with its previous research scope. The head of its present Academic Council is Andrzej Kajetan Wróblewski.\nSince 2011 the Institute has taken the official name of Ludwik Birkenmajer and Aleksander Birkenmajer: \"L & A Birkenmajer Institute for the History of Science\" (Polish: Instytut Historii Nauki PAN imienia Ludwika i Aleksandra Birkenmajerów).\n\nThe Institute consists of two departments: the Department of the History of Social Sciences, History of Education and Scholarly Institutions (Sections: History of Social Sciences, History of Education, History of Scientific Organizations), and the Department of the History of Exact Sciences, Natural Sciences and Technology (Sections: History of Exact Sciences and Technology, History of Medicine, History of Chemistry and Pharmacy, History of Mathematics).\n\nThe Institute conducts research focused on the history of science, both humanities and social sciences as well as natural and exact sciences, and the history of technology. The history of culture and history of education and pedagogical thought are also main research fields, equally with the history of ideas and its philosophical milieu.\n\n\nhttp://bazhum.icm.edu.pl:80/bazhum/element/bwmeta1.element.mhp-d42db18c-a1af-4798-a721-c2eab64b9bcd)\n\n"}
{"id": "50899529", "url": "https://en.wikipedia.org/wiki?curid=50899529", "title": "James Kynvyn", "text": "James Kynvyn\n\nJames Kynvyn (second half 16th-early 17th century) was an English craftsman, active between 1569 and 1610.\n\nAll that is known about him is that his workshop was located near St. Paul's Cathedral in London. He built high-quality mathematical instruments, notably graphometers, compasses, and quadrants.\n"}
{"id": "50820675", "url": "https://en.wikipedia.org/wiki?curid=50820675", "title": "Jenny Greene", "text": "Jenny Greene\n\nJenny Greene (born October 9, 1978) is an Astrophysicist and Professor at Princeton University. She is notable for her work on supermassive black holes and the galaxies in which they reside.\n\nGreene got her B.S degree in 2000 from Yale University, majoring in Astronomy and Physics. She then attended Harvard for her Ph.D in Astronomy, her thesis entitled \"The Growth of Black Holes: From Primordial Seeds to Local Demographics\". After her post-doctoral fellowship at Princeton, she became an Assistant Professor of Astronomy at UT Austin for a year. Since 2011, she has been an Assistant Professor of Astrophysical Sciences at Princeton.\n\nHer broad research interests include measurements of black hole masses, the connection between supermassive black holes and galaxies, stellar and gas kinematics of galactic nuclei, and diffuse light in galaxy clusters.\n\nGreene serves on the Leadership Committee of the Prison Teaching Initiative at Princeton University.\n\n\n"}
{"id": "57923591", "url": "https://en.wikipedia.org/wiki?curid=57923591", "title": "Jupiter LXXI", "text": "Jupiter LXXI\n\nJupiter LXXI, originally known as S/2018 J 1, is an outer natural satellite of Jupiter. It was discovered by Scott S. Sheppard and his team in 2018, and was announced on July 17, 2018, via a Minor Planet Electronic Circular from the Minor Planet Center.\nIt is about in diameter and has an orbit radius of around ; its orbital inclination is about 30.61°. It belongs to the Himalia group.\n"}
{"id": "1191027", "url": "https://en.wikipedia.org/wiki?curid=1191027", "title": "LHC@home", "text": "LHC@home\n\nLHC@home is a distributed computing project for particle physics based on the Berkeley Open Infrastructure for Network Computing (BOINC) platform. \n\nLHC@home consists of two applications: LHC@home Classic, SixTrack, which went live in September 2004 and is used to upgrade and maintain the particle accelerator Large Hadron Collider (LHC) of the European Organization for Nuclear Research (CERN), and LHC@home 2.0, Test4Theory (now is Virtual LHC@home), which went live in August 2011 and is used to simulate high-energy particle collisions to provide a reference to test the measurements performed at the LHC.\n\nThe applications are run with the help of about fifteen thousand active volunteered computers processing at a combined more than 15.5 teraFLOPS on average as of June 2014. LHC@home uses idle computer processing resources from volunteers' computers to perform calculations on individual workunits, which are sent to a central project server upon completion. The project is cross-platform, and runs on a variety of hardware configurations. Virtual LHC@home uses VirtualBox, an x86 virtualization software package.\n\nThe project was first introduced as a beta on 1 September 2004 and a record 1000 users signed up within 24 hours. The project went public, with a 5000 user limit, on September 29 to commemorate CERN's 50th anniversary. Currently there is no user limit and qualification. Data from the project is utilized by engineers to improve the operation and efficiency of the accelerator, and to predict possible problems that could arise from adjustment or modification of the LHC's equipment. The project is administered by volunteers, and receives no funding from CERN. There are currently no plans to use the project to do computation on the data that will be collected by the LHC.\n\nThe project software involves a program called SixTrack, created by Frank Schmidt, downloaded via BOINC onto participant computers running Windows, Linux or Mac OS X. SixTrack simulates particles accelerating through the -long LHC to find their orbit stability.\n\n"}
{"id": "57011961", "url": "https://en.wikipedia.org/wiki?curid=57011961", "title": "Leptolinea", "text": "Leptolinea\n\nLeptolinea is a bacteria genus from the family of Anaerolineaceae with one known species (\"Leptolinea tardivitalis\").\n"}
{"id": "39886133", "url": "https://en.wikipedia.org/wiki?curid=39886133", "title": "List of Estonian scientists", "text": "List of Estonian scientists\n\nThis is a list of Estonian scientists.\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "2680702", "url": "https://en.wikipedia.org/wiki?curid=2680702", "title": "List of compounds with carbon number 6", "text": "List of compounds with carbon number 6\n\nThis is a partial list of molecules that contain 6 carbon atoms.\n\n"}
{"id": "61789", "url": "https://en.wikipedia.org/wiki?curid=61789", "title": "List of diseases (S)", "text": "List of diseases (S)\n\nThis is a list of diseases starting with the letter \"S\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpastic a – Spastic d\nSpastic p\n\n\n\n\n\n\n\n\nSpondyla–Spondyli\nSpondylo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "2012081", "url": "https://en.wikipedia.org/wiki?curid=2012081", "title": "List of prehistoric insects", "text": "List of prehistoric insects\n\nPrehistoric insects are various groups of insects that lived before recorded history. Their study is the field of paleoentomology. Insects inhabited Earth since before the time of the dinosaurs. The earliest identifiable insect is the Devonian \"Rhyniognatha hirsti\", estimated at . Forms similar to many modern insects had already evolved before the dawning of the dinosaur and lived alongside them and beyond up to the present day. Like today, prehistoric insects were an important part of the food chain in their time.\n\nThe differences between modern and prehistoric varieties can be essential, and, like many other creatures of prehistory, the latter tended to be much larger than their contemporary equivalents. This size difference is thought to be due to higher atmospheric oxygen levels (allowing diffusion through spiracles over greater distances), higher temperatures (enhancing metabolism), and the absence of birds as key predators of insect life.\n\nSince insects have chitin exoskeletons rather than mineralized bones, their burial processes differ compared to the fossils of much larger vertebrates such as dinosaurs. Many insect remains are found preserved in the hardened sap of ancient trees (amber).\nIncomplete list of prehistoric insects arranged by extinction date:\n\n\n\n https://www.researchgate.net/publication/233496530_A_new_fossil_genus_and_species_of_snakefly_Raphidioptera_Mesoraphidiidae_from_Lower_Cretaceous_Lebanese_amber_with_a_discussion_of_snakefly_phylogeny_and_fossil_history\n\n"}
{"id": "825390", "url": "https://en.wikipedia.org/wiki?curid=825390", "title": "Luce's choice axiom", "text": "Luce's choice axiom\n\nIn probability theory, Luce's choice axiom, formulated by R. Duncan Luce (1959), states that the probability of selecting one item over another from a pool of many items is not affected by the presence or absence of other items in the pool. Selection of this kind is said to have \"independence from irrelevant alternatives\" (IIA).\n\nMathematically, the axiom states that the probability of selecting item \"i\" from a pool of \"j\" items is given by:\n\nwhere \"w\" indicates the weight (a measure of some typically salient property) of a particular item.\n\nThis function used elsewhere in mathematics and science, where it is known as the \"normalized exponential function\" or softmax, and dates to the Boltzmann distribution in statistical mechanics; see .\n\nThe axiom is often encountered in economics, where it can be used to model a consumer's tendency to choose one brand of product over another. It is also found in psychology, particularly in cognitive science where it is used to model approximately rational decision processes.\n\n\n"}
{"id": "54390625", "url": "https://en.wikipedia.org/wiki?curid=54390625", "title": "Lucianne Walkowicz", "text": "Lucianne Walkowicz\n\nLucianne Walkowicz is an American astronomer based at the Adler Planetarium noted for her research contributions in stellar magnetic activity and its impact on planetary suitability for extraterrestrial life. Since 2008, she has been the chair of the Large Synoptic Survey Telescope (LSST) Transients and Variable Stars collaboration and is the founding director of the LSST Data Science Fellowship program. She is internationally recognized for her advocacy for conservation of dark night skies, and was named a 2011 National Academy of Science Kavli Fellow and a 2012 TED Senior Fellow.\n\nIn 2017, she was named the fifth Baruch S. Blumberg NASA/Library of Congress Chair in Astrobiology in the John W. Kluge Center at the Library of Congress. She began began her tenure October 1, 2017, working on a project titled “Fear of a Green Planet: Inclusive Systems of Thought for Human Exploration of Mars.” Her project aims to create an inclusive framework for human exploration of Mars, encompassing both cutting-edge research on Mars as a place of essential astrobiological significance, while weaving in lessons from the diverse histories of exploration on Earth.\n\nWalkowicz holds a BS in physics and astronomy from Johns Hopkins University, and an MS and PhD in astronomy from the University of Washington. She got her taste for astronomy as an undergrad at Johns Hopkins, testing detectors for the Hubble Space Telescope’s new camera.\n\nShe appeared in Werner Herzog's 2016 documentary \"Lo and Behold\".\n\nShe appeared in National Geographic's series \"MARS\".\n"}
{"id": "53883633", "url": "https://en.wikipedia.org/wiki?curid=53883633", "title": "Mycobacterium phage jeffabunny", "text": "Mycobacterium phage jeffabunny\n\nMycobacterium phage jeffabunny is a bacteriophage known to infect bacterial species of the genus \"Mycobacterium\".\n"}
{"id": "52122213", "url": "https://en.wikipedia.org/wiki?curid=52122213", "title": "Nanohole", "text": "Nanohole\n\nNanoholes are a class of nanostructured material consisting of nanoscale voids in a surface of a material. Not to be confused with nanofoam or nanoporous materials which support a network of voids permeating throughout the material (often in a disordered state), nanohole materials feature a regular hole pattern extending through a single surface. These can be thought of as the inverse of a nanopillar or nanowire structure.\n\nNanohole structures have been used for a variety of applications, ranging from superlenses produced from a metal nanohole array, to structured photovoltaic devices used to improve carrier extraction, and light absorption.\n\nNanohole structures are also extensively utilized for the creation of photonic crystals, particularly for creating photonic crystal waveguides.\n\n"}
{"id": "16618942", "url": "https://en.wikipedia.org/wiki?curid=16618942", "title": "Operation Roller Coaster", "text": "Operation Roller Coaster\n\nOperation Roller Coaster was a series of 4 nuclear tests conducted by the United Kingdom in 1963 at the Nevada Test Site. These tests followed the \"Operation Storax\" series and preceded the \"Operation Niblick\" series.\n"}
{"id": "2871908", "url": "https://en.wikipedia.org/wiki?curid=2871908", "title": "Pohlmeyer charge", "text": "Pohlmeyer charge\n\nIn theoretical physics Pohlmeyer charge, named for , is a conserved charge invariant under the Virasoro algebra or its generalization. It can be obtained by expanding the holonomies (generating functions)\n\nwith respect to the constant matrices \"T\". The gauge field formula_2 is defined as a combination of formula_3 and its conjugate.\n\nAccording to the logic of loop quantum gravity and algebraic quantum field theory, these charges are the right physical quantities that should be used for quantization. This logic is however incompatible with the standard and well-established methods of quantum field theory based on Fock space and perturbation theory.\n"}
{"id": "4302198", "url": "https://en.wikipedia.org/wiki?curid=4302198", "title": "Rebis", "text": "Rebis\n\nThe Rebis (from the Latin \"res bina\", meaning dual or double matter) is the end product of the alchemical \"magnum opus\" or great work. \n\nAfter one has gone through the stages of putrefaction and purification, separating opposing qualities, those qualities are united once more in what is sometimes described as the divine hermaphrodite, a reconciliation of spirit and matter, a being of both male and female qualities as indicated by the male and female head within a single body. The sun and moon correspond to the male and female halves, just as the Red King and White Queen are similarly associated. \n\nThe \"Rebis\" image appeared in the work \"Azoth of the Philosophers\" by Basil Valentine in 1613.\n\n\n\n"}
{"id": "28912406", "url": "https://en.wikipedia.org/wiki?curid=28912406", "title": "Root trainer", "text": "Root trainer\n\nA root pruning container is an aid to the cultivation of young plants and trees in nurseries. Many pot designs train the roots. One example is a truncated plastic cone in which a seedling is planted. There is a drainage hole at the bottom and the main tap root tends to grow towards this.\n\nWhat this achieves is to encourage the roots the grow a denser system of root hairs. How it does this is to have the pots designed so as to air prune the roots. The advantage is when the plant is planted into its home environment it has a stronger root base to start with.\nWhen polythene bags are used instead, this root tends to go through the bag into the ground and is then broken off when the tree is moved for planting. The other roots are insufficiently developed to cope with the shock caused by this and so the tree's chances of survival are reduced. The root trainer is mounted in a stand above ground so that, when the tap root emerges, it is dried by the air. This air pruning causes the root inside the pot to thicken with stored carbohydrates that support vigorous root growth when the plant is put in the ground. The other lateral roots of the plant grow to compensate for this—so a stronger root ball forms, which improves the sapling's chances.\n\nWhen raising multiple seedlings, the root trainers are commonly placed in trays or racks. The size of each trainer depends upon the species but, for broad-leaved trees, the capacity is about a cup. Vertical ribs inside the trainer are positioned to train the roots to grow downwards and so prevent root spiralling.\n\nOwing to numerous problems (stability, restricted growth, etc.), the issue of root circling in root pruning containers had to be addressed. Some, even today, promote cutting, slicing, or shaving root systems of plants grown in conventional containers prior to planting to stop circling. However, this is only partially effective and, like mechanical field pruning, it creates open wounds, allowing pathogens an opportunity to attack.\n\nMost understood the root system is extremely important to its overall performance once planted out. and have tried changing container designs. One of the first designs was simply using an open-bottomed, waxed cardboard milk carton container. The results were promising. When the taproot eventually reached the base, it would become exposed to air, dehydrate and die at the tip, stimulating roots to branch behind this point, much like pruning a hedge. However, all roots were forced downward so there was still plenty of room for improvement to gain side branching.\n\nA container with vertical slots on the side was tested. Surprisingly, the results were poor. Water loss was high and only occasionally would roots find a slot and branch. The majority continued to circle.\n\nInterior ribs were added to deflect roots, but these containers would not stack. Polybags had been tested and root branching occurred where root were trapped in the gusseted bottom. These proved difficult to fill and handle, and still no side branching. The Stairstep container was a design that trapped root tips to force branching and yet could be stacked. However, production costs made this container difficult to manufacture.\n\nOne container designer tried “root suffocation pruning.” When a root grows into a reservoir of water at the bottom, it is suffocated. The death of the root tip causes root branching but as with physically cutting roots, pathogens are a problem.\n\nSome containers even use chemicals to cause root branching. Some herbicides have been uses as well as copper, but copper creates toxicity issues for the plant.\n\nPorous fabric containers have been tried but have high water loss and salt accumulation. Plus, these containers are still passive with root pruning, relying on roots eventually finding an opening.\n\nThe evolution of root pruning containers continues and currently rests in three types.\n\n1. Knit fabric inground containers work well. Roots grow through specifically sized holes but are girdled and cannot expand. The swelling of the root both inside and outside of the girdled point causes branching within the container, yet greatly minimized any open wounds at harvest.\n\n2. Another high-tech fabric container is used above ground. A white laminate (to prevent the lethal temperatures of black containers exposed to sun) coats the outside of a fuzzy, root-tip-trapping interior that stops root circling. When growth of the root tip is inhibited, branching occurs.\n\n3. Finally, millions of trees are grown yearly using the latest design of containers for air-root-pruning. There are several types on the market, but the original root pruning container system uses a design of ribs, ledges, and holes to actively direct roots to openings. These containers range from propagation sizes of a few cubic inches to hundreds of gallons. With timely shifts, the root pruning momentum can be continued throughout production to equip plants with a root system that ultimately gives the best chance to be securely anchored and succeed in the final planting.\n\n"}
{"id": "36231779", "url": "https://en.wikipedia.org/wiki?curid=36231779", "title": "Ross' π lemma", "text": "Ross' π lemma\n\nRoss' lemma, named after I. Michael Ross, is a result in computational optimal control. Based on generating Carathéodory- solutions for feedback control, Ross' -lemma states that there is fundamental time constant within which a control solution must be computed for controllability and stability. This time constant, known as Ross' time constant, is proportional to the inverse of the Lipschitz constant of the vector field that governs the dynamics of a nonlinear control system.\n\nThe proportionality factor in the definition of Ross' time constant is dependent upon the magnitude of the disturbance on the plant and the specifications for feedback control. When there are no disturbances, Ross' -lemma shows that the open-loop optimal solution is the same as the closed-loop one. In the presence of disturbances, the proportionality factor can be written in terms of the Lambert W-function.\n\nIn practical applications, Ross' time constant can be found by numerical experimentation using DIDO. Ross \"et al\" showed that this time constant is connected to the practical implementation of a Caratheodory- solution. That is, Ross \"et al\" showed that if feedback solutions are obtained by zero-order holds only, then a significantly faster sampling rate is needed to achieve controllability and stability. On the other hand, if a feedback solution is implemented by way of a Caratheodory- technique, then a larger sampling rate can be accommodated. This implies that the computational burden on generating feedback solutions is significantly less than the standard implementations. These concepts have been used to generate collision-avoidance manevuers in robotics in the presence of uncertain and incomplete information of the static and dynamic obstacles.\n\n"}
{"id": "15547360", "url": "https://en.wikipedia.org/wiki?curid=15547360", "title": "Siberia, Siberia", "text": "Siberia, Siberia\n\nSiberia, Siberia () is a non-fiction book by the Russian writer Valentin Rasputin. It was originally published in Russian in 1991 by Molodaya Gvardiya Publishers. The second and third editions appeared in 2000 and 2006; an English translation is available as well.\n\nRasputin is a Russian novelist based in Irkutsk in Eastern Siberia, and a master of the genre known as \"village prose\". His fiction centers around the conflict of the traditional Siberian village lifestyle, characterized by its family values, unambiguous morality, and strong connection with one's ancestral culture and natural environment, with the modernizing developments of the post-World War II period. Since the mid-1970s, he has been increasingly involved in writing non-fiction essays and article, protesting against projects he views as environmentally destructive and advocating for the restoration of \"Russian national consciousness\".\n\nHis Siberia, Siberia is both an excursion into the human history of the region, and a diatribe against the industrial developments and infrastructure projects \"of the last three decades\" (i.e. roughly 1960-1990) that he views as wrecking not only the region's natural environments and the rural way of life, but also the very moral fibre of the nation.\n\nBesides an introductory overview chapters and the conclusion, the book consists of several chapters which are dedicated to particular regions: Tobolsk, the old capital of Russian Siberia; Lake Baikal; Irkutsk, the city on the Angara which the author has long made his made home; Altai; Kyakhta, the 18-19th century entrepôt for China tea trade; and the isolated Arctic community of Russkoye Ustye with its archaic customs and dialect. Later Russian editions had additional chapters added.\n\nAs usual in Rasputin's writing, his greatest ire is reserved for the masterminds of the river damming and water export schemes, such as the Siberian river reversal project, which was shelved (not without Rasputin's contribution to its criticism) in 1986.\n\n[W]herever dams are put up and reservoirs swell, a river ceases to be a river and becomes a disfigured beast of burden with the life squeezed out of it. After that, the river contain no fish, no life, no beauty.\nAn English translation by Margaret Winchell and Gerald Mikkelson was published by Northwestern University Press in 1996.\n\nThe third Russian edition of the book, which appeared in 2006, earned the 2007 Book of the Year Award of the Moscow Book Fair in the \"Literary Russian Language\" (\"Русский литературный\") category.\n\nSome Western critics claim that while Rasputin is vocal in defending the Siberia's long-established Russian community against Moscow's central planners and the carpetbaggers brought to the region by the development projects, he disregards the plight of the region's aboriginal people and their intrinsic property rights in the region's natural resources.\n"}
{"id": "51144813", "url": "https://en.wikipedia.org/wiki?curid=51144813", "title": "Staveley Road", "text": "Staveley Road\n\nStaveley Road is a road in Chiswick in the London Borough of Hounslow.\n\nStaveley Road was built between 1927 and 1931 as part of the Chiswick Park Estate.\n\nAt 6.43pm on Friday 8 September 1944, a V-2 missile (\"Aggregat 4\" in German) launched from Wassenaar in Holland landed in Staveley Road, near the junction with Burlington Lane, killing three people (including a three-year-old girl), and injuring nineteen people. The crater was thirty feet deep. The missile had taken seven minutes to reach Chiswick from Holland, travelling at around 3,000mph. This is regarded as the world's first recognised ballistic rocket attack, although another V-2 had previously landed in the outskirts of Paris earlier in the morning. Sixteen seconds after the V-2 attack occurred in Chiswick, another V-2 landed in Epping Forest harmlessly; another V-2 landed in London that day.\n\nEleven houses were completely destroyed, and another fifteen had to be extensively rebuilt. The area at the time had been partly evacuated. The explosion could be heard six miles away in central London. Within an hour of the explosion, government officials were arriving at the scene. The general public was not notified about the existence of V-2 rockets until 10 November 1944.\n\nEach V-2 rocket was forty-six feet long and carried a one tonne warhead. 4,300 V-2 rockets would be launched. The final V-2 to hit England would be on 27 March 1945 in Kent, killing a 34-year-old woman. 517 V-2 rockets would hit London. The most devastating V-2 attack in London would be on 25 November 1944, killing 160 people. \n\n\n"}
{"id": "406348", "url": "https://en.wikipedia.org/wiki?curid=406348", "title": "Teacher in Space Project", "text": "Teacher in Space Project\n\nThe Teacher in Space Project (TISP) was a NASA program announced by Ronald Reagan in 1984 designed to inspire students, honor teachers, and spur interest in mathematics, science, and space exploration. The project would carry teachers into space as Payload Specialists (non-astronaut civilians), who would return to their classrooms to share the experience with their students. \n\nNASA cancelled the program in 1990, following the death of its first participant, Christa McAuliffe, in the Space Shuttle \"Challenger\" disaster (STS-51-L) on January 28, 1986. NASA replaced Teachers in Space in 1998 with the Educator Astronaut Project, which required its participants to become astronaut Mission Specialists. The first Educator Astronauts were selected as part of NASA Astronaut Group 19 in 2004. \n\nBarbara Morgan, who was selected as a Mission Specialist as part of NASA Astronaut Group 17 in 1998, has often been incorrectly referred to as an Educator Astronaut. However, she was selected as a Mission Specialist before the Educator Astronaut Project.\n\nTISP was announced by President Ronald Reagan on August 27, 1984. Not members of NASA's Astronaut Corps, the teachers would fly as Payload Specialists and return to their classrooms after flight. More than 40,000 applications were mailed to interested teachers while 11,000 teachers sent completed applications to NASA. Each application included a potential lesson that would be taught from space while on the Space Shuttle. The applications were sorted and then sent to the various State Departments of Education, who were then responsible for narrowing down their state applicants to a final set of two each. These applicants were notified of their selections and were gathered together for further selection processes down to ten finalists. These were then trained for a time, and in 1985 NASA selected Christa McAuliffe to be the first teacher in space, with Barbara Morgan as her backup. McAuliffe was a high school social studies teacher from Concord, New Hampshire. She planned to teach two 15-minute lessons from the Space Shuttle. \n\nMcAuliffe died in the Space Shuttle \"Challenger\" disaster (STS-51-L) on January 28, 1986. After the accident, Reagan spoke on national television and assured the nation that the Teacher in Space program would continue. \"We'll continue our quest in space\", he said. \"There will be more shuttle flights and more shuttle crews and, yes, more volunteers, more civilians, more teachers in space. Nothing ends here; our hopes and our journeys continue.\" However, NASA decided in 1990 that spaceflight was still too dangerous to risk the lives of civilian teachers, and eliminated the Teacher in Space project. Morgan returned to teaching in Idaho and later became a Mission Specialist on STS-118.\n\nIn January 1998, NASA replaced the Teacher In Space project with the Educator Astronaut Project. Instead of training teachers for five months as Payload Specialists who would return to the classroom, the Educator Astronaut program required selectees to give up their teaching careers, move to Houston, and become Mission Specialists (full-time NASA astronauts).\n\nThe first Educator Astronauts were selected in 2004. The three selected in 2004 were Joseph Acaba, Richard Arnold, and Dorothy Metcalf-Lindenburger. Astronauts Acaba and Arnold flew on mission STS-119 in 2009, and Metcalf-Lindenburger flew aboard mission STS-131 in 2010. \n\nAlthough many sources incorrectly refer to Barbara Morgan as the first Educator Astronaut, in actuality, Morgan was selected as a Mission Specialist six years before the Educator Astronaut Project was put into place.\n\nIn the early 21st Century, the Teacher in Space project was revived in the private sector. The development of reusable, suborbital launch vehicles by commercial companies makes it possible for nonprofit groups to contemplate sending large numbers of teachers into space. The new Teachers in Space program began in 2005. In March 2005, Teacher in Space candidate Pam Leestma, a second-grade teacher and cousin of Space Shuttle astronaut David Leestma, completed a training flight aboard a MiG-21 operated by X-Rocket, LLC.\n\nArmadillo Aerospace, Masten Space Systems, PlanetSpace, Rocketplane Limited, Inc., and XCOR Aerospace pledged flights to the new Teachers in Space project. Advisors to the new Teachers in Space project include SpaceShipOne builder and Ansari X-Prize winner Burt Rutan, X-Prize founder Peter Diamandis, Apollo astronaut Buzz Aldrin, and private astronaut and X-Prize sponsor Anousheh Ansari.\n\nThe United States Rocket Academy partnered with the SFF in 2006, and worked to draft rules for a \"pathfinder\" competition to select the first Teachers in Space. The rules were announced at the Wirefly X PRIZE Cup Competition held at Holloman Air Force Base near Alamogordo, New Mexico in October 2007. Applications were accepted until November 4, 2008. On July 20, 2009, Teachers in Space announced its first group of \"Pathfinders\": astronaut teacher candidates.\n\nOn June 11, 2013, Embry-Riddle Aeronautical University’s new Commercial Space Operations degree program, the first of its kind in the world, announced they will sponsor the Teachers in Space summer workshops for the next five years, indicating their intent toward a continuing long term relationship as well as their sharing a vision to \"...help students, teachers and organizers collaborate in bringing space education to every level, from K-12 to graduate programs.\"\n\nIn 2014, Program director Elizabeth Kennick incorporated the Teachers in Space project as an educational nonprofit in New York, spinning it off from the Space Frontier Foundation. 5 original Pathfinders (James Kuhl, Rachael Manzer, Lanette Oliver, Chantelle Rose, and Michael Schmidt) remain with the program, also Vice President Joe Latrell and several teacher volunteers. Teachers in Space, Inc. has now flown two teacher/student designed experiments to International Space Station (ISS), launched and retrieved several high altitude balloons with data sensors, put teachers through astronaut training experiences including hypobaric chamber and centrifuge, and delivered weeklong professional development workshops for Science, Technology, Engineering and Math (STEM) teachers in California, Florida, Oklahoma, Texas, and Georgia.\n\n\n"}
{"id": "10389193", "url": "https://en.wikipedia.org/wiki?curid=10389193", "title": "Temperature-sensitive mutant", "text": "Temperature-sensitive mutant\n\nTemperature sensitive mutants are variants of genes that allow normal function of the organism at low temperatures, but altered function at higher temperatures.\n\nMost temperature sensitive mutations affect proteins, and cause loss of protein function at the non-permissive temperature. The permissive temperature is one at which the protein typically can fold properly, or remain properly folded. At higher temperatures, the protein is unstable and ceases to function properly. These mutations are usually recessive in diploid organisms.\n\nThe permissive temperature is the temperature at which a temperature sensitive mutant gene product takes on a normal, functional phenotype.\nWhen a temperature sensitive mutant is grown in a permissive condition, the mutated gene product behaves normally (meaning that the phenotype isn't observed), even if there is a mutant allele present. This results in the survival of the cell or organism, as if it were a wild type strain. In contrast, the nonpermissive temperature or restrictive temperature is the temperature at which the mutant phenotype is observed.\n\nTemperature sensitive mutants are useful in biological research. They allow to study essential processes required for the survival of the cell or organism. Mutations to essential genes are generally lethal and hence temperature sensitive mutants enable researchers to induce the phenotype at the restrictive temperatures and study the effects. The temperature sensitive phenotype could be expressed during a specific developmental stage to study the effects.\n\nTemperature sensitive mutants were used by Randy Schekman's group to isolate and identify mutants having impaired secretory pathway. In yeast, secretory vesicles deliver raw materials for the growth of the new bud. Any mutations in the pathway will render the cell dead. So there is a need to selectively induce the phenotype at restrictive temperatures. By using temperature sensitive mutants, Schekman identified 23 genes required for the secretory pathway.\n"}
{"id": "17655421", "url": "https://en.wikipedia.org/wiki?curid=17655421", "title": "Thomas Jessell", "text": "Thomas Jessell\n\nThomas Michael Jessell (born 2 August 1951 in London) was the Claire Tow Professor of biochemistry and molecular biophysics at Columbia University in New York. In 2018, Columbia University announced his termination from his administrative positions along with plans to dissolve his lab after an internal investigation uncovered violations of university policies.\n\nJessell received his Ph.D. in neuroscience from the University of Cambridge and was a post-doctoral fellow at Harvard Medical School with Gerald Fischbach. In 1981 he became an Assistant Professor in the Department of Neurobiology at Harvard Medical School. In 1985 he joined the Columbia University faculty and rose to the ranks to become Claire Tow Professor of Motor Neuron Disorders (in neuroscience). \n\nOn March 7, 2018, Jessell was removed from his post at Columbia University following an investigation that, \"...revealed serious violations of university policies and values governing the behavior of faculty members in an academic environment\". Jessell was an investigator of the Howard Hughes Medical Institute from 1985-2018.\n\nJessell is known for his work on chemical signals that play a role when nerve cells assemble during development to form neuronal circuits. In 1994, he showed that netrin guides commissural axons in the vertebrate spinal cord.\n\nIn 1994 Jessell was awarded the NAS Award for Scientific Reviewing from the National Academy of Sciences. He was a co-recipient, with Pasko Rakic and Sten Grillner, of the inaugural Kavli Prize for Neuroscience in 2008. In 2014, he was awarded the Vilcek Prize in Biomedical Science. He was elected a Fellow of the Royal Society in 1996. He won the Ralph W. Gerard Prize from the Society for Neuroscience in 2016\n\nJessell is the co-editor, with Eric R. Kandel and James Schwartz, of the well-known textbook Principles of Neural Science.\n\n"}
{"id": "24232670", "url": "https://en.wikipedia.org/wiki?curid=24232670", "title": "Traité Élémentaire de Chimie", "text": "Traité Élémentaire de Chimie\n\nTraité élémentaire de chimie (Elementary Treatise of Chemistry) is a textbook written by Antoine Lavoisier published in 1789 and translated into English by Robert Kerr in 1790 under the title Elements of Chemistry in a New Systematic Order containing All the Modern Discoveries. It is considered to be the first modern chemical textbook.\n\nThe book defines an element as a single substance that can't be broken down by chemical analysis and from which all chemical compounds are formed, publishing his discovery that fermentation produces carbon dioxide (carbonic gas) and spirit of wine, saying that it is \"more appropriately called by the Arabic word alcohol since it is formed from cider or fermented sugar as well as wine\", and publishing the first chemical equation \"grape must = carbonic acid + alcohol\", calling this reaction \"one of the most extraordinary in chemistry\", noting \"In these experiments, we have to assume that there is a true balance or equation between the elements of the compounds with which we start and those obtained at the end of the reaction.\"\n\nThe book contains a list of 33 elements, only 23 of which are elements in the modern sense. The elements given by Lavoisier are: light, caloric, oxygen, azote (nitrogen), hydrogen, sulphur, phosphorous (phosphorus), charcoal, muriatic radical (chloride), fluoric radical (fluoride), boracic radical, antimony, arsenic, bismuth, cobalt, copper, gold, iron, lead, manganese, mercury, molybdena (molybdenite), nickel, platina (platinum), silver, tin, tungstein (tungsten), zinc, lime, magnesia (magnesium), barytes (baryte), argill (clay or earth of alum), and silex.\n\n\n\n"}
{"id": "85757", "url": "https://en.wikipedia.org/wiki?curid=85757", "title": "Trans-lunar injection", "text": "Trans-lunar injection\n\nA trans-lunar injection (TLI) is a propulsive maneuver used to set a spacecraft on a trajectory that will cause it to arrive at the Moon.\n\nTypical lunar transfer trajectories approximate Hohmann transfers, although low-energy transfers have also been used in some cases, as with the Hiten probe. For short duration missions without significant perturbations from sources outside the Earth-Moon system, a fast Hohmann transfer is typically more practical.\n\nA spacecraft performs TLI to begin a lunar transfer from a low circular parking orbit around Earth. The large TLI burn, usually performed by a chemical rocket engine, increases the spacecraft's velocity, changing its orbit from a circular low Earth orbit to a highly eccentric orbit. As the spacecraft begins coasting on the lunar transfer arc, its trajectory approximates an elliptical orbit about the Earth with an apogee near to the radius of the Moon's orbit. The TLI burn is sized and timed to precisely target the Moon as it revolves around the Earth. The burn is timed so that the spacecraft nears apogee as the Moon approaches. Finally, the spacecraft enters the Moon's sphere of influence, making a hyperbolic lunar swingby.\n\nTLI targeting and lunar transfers are a specific application of the n body problem, which may be approximated in various ways. The simplest way to explore lunar transfer trajectories is by the method of patched conics. The spacecraft is assumed to accelerate only under classical 2 body dynamics, being dominated by the Earth until it reaches the Moon's sphere of influence. Motion in a patched-conic system is deterministic and simple to calculate, lending itself for rough mission design and \"back of the envelope\" studies.\n\nMore realistically, however, the spacecraft is subject to gravitational forces from many bodies. Gravitation from Earth and Moon dominate the spacecraft's acceleration, and since the spacecraft's own mass is negligible in comparison, the spacecraft's trajectory may be better approximated as a restricted three-body problem. This model is a closer approximation but lacks an analytic solution, requiring numerical calculation via methods such as Runge-Kutta.\n\nMore detailed simulation involves modeling the Moon's true orbital motion; gravitation from other astronomical bodies; the non-uniformity of the Earth's and Moon's gravity; including solar radiation pressure; and so on. Propagating spacecraft motion in such a model is numerically intensive, but necessary for true mission accuracy.\n\nIn some cases it is possible to design a TLI to target a free return trajectory, so that the spacecraft will loop around behind the Moon and return to Earth without need for further propulsive maneuvers. Such free return trajectories add a margin of safety to human spaceflight missions, since the spacecraft will return to Earth \"for free\" after the initial TLI burn.\n\nThe first space probe to successfully perform TLI was the Soviet Union's Luna 1 on January 2, 1959. The first human-crewed mission to successfully perform this procedure, and thus becoming the first humans to leave the Earth's influence, was Apollo 8 on December 21, 1968.\n\nFor the Apollo lunar missions, the restartable J-2 engine in the third (S-IVB) stage of the Saturn V rocket performed TLI. This particular TLI burn lasted approximately 350 seconds, providing 3.05 to 3.25 km/s (10,000 to 10,600 ft/s) of delta-v, at which point the spacecraft was traveling at approximately 10.4 km/s (34150 ft/s) relative to the Earth. The Apollo 8 TLI was spectacularly observed from the Hawaiian Islands in the pre-dawn sky south of Waikiki, photographed and reported in the papers the next day. In 1969, the Apollo 10 pre-dawn TLI was visible from Cloncurry, Australia. It was described as resembling car headlights coming over a hill in fog, with the spacecraft appearing as a bright comet with a greenish tinge.\n\n"}
{"id": "31255544", "url": "https://en.wikipedia.org/wiki?curid=31255544", "title": "Transporter Industry International", "text": "Transporter Industry International\n\nTransporter Industry International GmbH is a conglomerate of companies providing heavy load transportation including Scheuerle, Nicolas and KAMAG Transporttechnik (based in Ulm, Germany). The companies' products provide transportation for extremely heavy, and in some cases, sensitive loads in the steel, shipyard, construction, and aerospace industries as well as airport ground support. The company is affiliated with the Specialized Carriers and Rigging Association and Cargo Equipment Experts.\n\nNASA has been a customer of Kamag vehicles since 1979. Kamag has provided vehicles to move rockets, boosters, and satellite payloads. The Solid Rocket Motor (SRM) Transporter moves the Space Shuttle SRM segments between refurbishment and storage facilities on the Cape Canaveral Air Force Station the Vehicle Assembly Building. It has a capacity of , is equipped with 48 tires and has a turning radius of . Two Payload Canister Transporters are used to move payload canisters between space shuttle payload processing facilities, the vertical processing facility (where the canister is moved to a vertical position, and the launch pad. The PCTs are capable of maneuvering at between and a more careful when fully loaded and features a 340 horsepower turbocharged engine for outdoor operation and 45-kilowatt, 480 VAC electric motors for operation in indoor cleanrooms.\n"}
{"id": "5592570", "url": "https://en.wikipedia.org/wiki?curid=5592570", "title": "Wake Island rail", "text": "Wake Island rail\n\nThe extinct Wake Island rail (\"Gallirallus wakensis\") was a flightless rail and the only native land bird on the Pacific atoll of Wake. It was found on the islands of Wake and Wilkes, but not on Peale, which is separated from the others by a channel of about 100 meters.\n\nThe adult bird had a length of . The wing spread was between 8.5 and . The length of the tail was . The culmen was between 2.5 and and the length of the tarsus was 3.3 to . It was closely related to the buff-banded rail (\"Gallirallus philippensis\") from the Philippines, which is able to fly. Its appearance was dark greyish brown on the upperparts as well as on the crown, the lores and the cheeks. It was also characterized by ash brown underparts with striking narrow white bars on the belly, the breast, and the flanks. The upper throat and the chin were whitish. A grey superciliary was drawn from the chin over the top of the eyes to the bill. The bill, legs and feet had a brown hue.\n\nThe ecology of this species is poorly known, though a review published in 2011 has shed more light on its life and subsequent extinction. It was numerous at the time of Lionel Walter Rothschild's first scientific description in 1903. The Wake Island rail inhabited \"Cordia subcordata\" scrubs and fed on molluscs, insects, worms and seeds which it found by digging up leaves and soil with its bill. Since its habitat offered no natural source of fresh water, it is assumed that the bird was able to subsist without drinking.\n\nThe breeding period started with courtship and copulations in late July, with actual nesting not taking place until mid-August. The nest itself was a simple saucer-shaped depression on the ground. Under favourable conditions it may have managed to rear two broods a year. Small groups nested cooperatively, with prolonged parental care and feeding by the adults, most likely so that they could defend their young from predation by hermit crabs (\"Coenobita\") and the Polynesian rat (\"Rattus exulans\"), with which it was able to co-exist. When ornithologist Alexander Wetmore observed the species in 1923, he described it as very curious, but quick to flee into cover when disturbed. Its call consisted of a gentle cluck or a low chattering sound.\n\nThe Wake Island rail is classified as extinct. Its inability to fly and the island's geographic isolation, combined with the bird's inquisitiveness and lack of fear of humans, made it an easy victim of over-hunting. It is now known that the extinction event occurred specifically between 1942 and 1945. This was a direct result of the presence of thousands of starving Japanese troops stranded on the island after a U.S. blockade of the island took place as a direct result of the Japanese invasion and occupation of Wake Island in December 1941, in addition combined with the inevitable habitat destruction resulting from military altercations and extensive aerial bombardment by the U.S. during World War II.\n\n"}
{"id": "41449605", "url": "https://en.wikipedia.org/wiki?curid=41449605", "title": "Wilhelm Altar", "text": "Wilhelm Altar\n\nWilhelm Altar (August 27, 1900 - 1995), known to family and colleagues as William Altar, was an Austrian-born theoretical physicist whose significant contributions led to the development of the magneto ionic theory. Altar contributed to the mathematical and conceptual underpinnings that were verified by Appleton's research, in collaboration with Dr. Altar. Altar was not credited with his contributions until 1982, decades after Appelton received the Nobel Prize in Physics in 1947. \n\nAltar was born in Vienna in 1900. In 1923 he obtained a doctorate in theoretical physics from the University of Vienna. Due to the poor job market post World War I, Altar, in 1925, moved to his uncle's home in London. In London Professor A. O. Ranking at Imperial College introduced him to Edward Appleton in King's College London.\n\nIn the 1930s he moved to the United States where he joined the physics department of Pennsylvania State University. From 1935 to 1937 he served as a researcher at the Frick Chemical Laboratory at Princeton University, working on a study of optical rotatory power in organic molecules. On several occasions, Dr. Altar had tea and discussions about physics with Dr. Albert Einstein in their native German language.\n\nDuring his time in King's College, Altar and Appleton made slow progress every day. The Appleton-Altar approach was an exercise in Lorentzian magneto-optics.\n"}
