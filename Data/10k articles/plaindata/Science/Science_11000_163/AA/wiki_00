{"id": "1812292", "url": "https://en.wikipedia.org/wiki?curid=1812292", "title": "Aggregat (rocket family)", "text": "Aggregat (rocket family)\n\nThe Aggregat series (German for \"Aggregate') was a set of ballistic missile designs developed in 1933–45 by a research program of Nazi Germany's army (Wehrmacht). Its greatest success was the A4, more commonly known as the V-2.\n\nThe A1 was the first rocket design in the Aggregat series. It was designed in 1933 by Wernher von Braun in a German armed forces research program at Kummersdorf headed by Walter Dornberger. The A1 was the grandfather of most modern rockets. The rocket was long, in diameter, and had a takeoff weight of . The engine, designed by Arthur Rudolph, used a pressure-fed rocket propellant system burning alcohol and liquid oxygen, and produced 300 kgf (660 lbf, 2.9 kN) of thrust for 16 seconds. The rocket was stabilized by a gyroscope in the nose, but there was concern that this might cause problems with the liquid fuels. Although the engine had been successfully test fired, the first flight attempt blew up on the launching pad on 21 December 1933. Since the design was thought to be unstable, no further attempts were made, and efforts moved to the A2 design.\n\nThe A2 was designed in 1934 by von Braun under the program at Kummersdorf headed by Walter Dornberger.\n\nAt a length of and thrust of 3 kN from alcohol and liquid oxygen, it was in outline similar to the A1. However, in contrast to the A1, the A2 had the stabilization gyroscopes in the center of the rocket between the alcohol and oxygen tanks, which made it more stable. The rocket weighed empty, with takeoff weight of . Initial flight testing was done in September 1934 at Kummersdorf.\n\nTwo A2s were built for a full out test, and were named after a Wilhelm Busch cartoon, \"Max and Moritz\". On December 19 and December 20, 1934, they were launched in front of the Army brass on Borkum island in the North Sea. They reached altitudes of and .\n\nDevelopment of the A3 can be traced at least to February 1935 when Major Ernst Ritter von Horstig sent General Karl Becker a budget of almost half a million marks for the construction of two new test stands at Kummersdorf. Included were mobile test rigs, small locomotives, and office and storage space. The A3 plans called for a rocket with an inertial guidance system and a thrust engine.\n\nIn March 1936, Army General Werner von Fritsch witnessed a static firing of an A3 engine at Kummersdorf, and was sufficiently impressed to lend his support to the rocket program. Like the earlier A1 and A2 rockets, the A3 also used a pressure-fed propellant system, and the same liquid oxygen and 75% alcohol mixture as the earlier designs. It generated its for 45 seconds. It used a three-gyroscope system to deflect tungsten alloy jet vanes. The design was finished and secretly patented in the spring of 1936 and further modifications that made the rocket stable at supersonic velocities were finalized in the autumn.\n\nThis was the first of the Aggregat rockets to be launched from the Peenemünde area. As part of Operation Lighthouse the first A3 was launched on 4 December 1937, but suffered problems with both premature parachute deployment and engine failure, and crashed close to the takeoff point. The second launch on 6 December 1937 suffered similar problems. The parachute was disabled in the third and fourth rockets launched on 8 and 11 December 1937, but these, too, experienced engine failures, though the lack of parachute drag allowed them to crash further from the launch site.\n\nAccording to another source, one A3 reached a maximum downrange of and maximum altitude of .\n\nWith each launch a failure, von Braun and Dornberger looked for the cause. At first there was some thought of an electrostatic charge that prematurely set off the parachute, but this was largely disproved. Ultimately, the failures were attributed to the inadequate design of the rocket's experimental inertial guidance system and minor instabilities in the body and fin design.\n\nAfter this unsuccessful series of launches, the A3 was abandoned and redesigned as the A5. In the meantime, work on the A4 continued.\n\nThe A5 was a scaled-down test model of the A4 which replaced the former unsuccessful A3 in this role. It was flown from 1938 to 1942, and played a vital role in testing the aerodynamics and technology of the A4. Its rocket engine was identical to the A3, with a new control system and a shape similar to the A4. 25 were launched, some several times; it was fitted with a parachute recovery system and could float for up to two hours before sinking to allow recovery by boat. Variants were constructed both with no propulsion system and monopropellant engines for air drop testing.\n\nThe A5 was long, with a diameter of and a takeoff weight of , and like the A3 was fueled with alcohol with liquid oxygen as an oxidant. The first launch of the A5 took place in the summer of 1938 at Greifswalder Oie and the first successful guided flights were made in October 1939 in order to test the control systems planned for use in the A4. The A5 reached a ceiling of up to .\n\nThe A4 was a full-sized design with a range of about 322 kilometers (200 mi), an initial peak altitude of 89 kilometers (55 mi) and a payload of about a tonne. Versions of the A4 were used in warfare. They included the first ballistic missile and the first projectile to reach outer space.\n\nThis increase in capability came from a redesign of the A3 engine, now known as the A5, by Walter Thiel. It became clearer that von Braun's designs were turning into useful weapons, and Dornberger moved the team from the artillery testing grounds at Kummersdorf (near Berlin) to a small town, Peenemünde, on the island of Usedom on Germany's Baltic coast, in order to provide more room for testing and greater secrecy. This version was reliable, and by 1941 the team had fired about 70 A5 rockets. The first A4 flew in March 1942, flying about 1.6 kilometers (1 mi) and crashing into the water. The second launch reached an altitude of 11 kilometers (7 mi) before exploding. The third rocket, launched on October 3, 1942, followed its trajectory perfectly. It landed 193 kilometers (120 mi) away, and reached a height of 83 kilometers (52 mi). The highest altitude reached during the war was on 20 June 1944.\n\nProduction started in 1943 on the rocket. The missile testing ground at Blizna was quickly located by the Polish resistance movement, the Armia Krajowa, thanks to reports from local farmers. Armia Krajowa field agents even managed to obtain pieces of the fired rockets, by arriving on the scene before German patrols. In early March 1944, British Intelligence Headquarters received a report of an Armia Krajowa agent (code name: \"‘Makary’\") who had covertly surveyed the Blizna railway line and observed a freight car heavily guarded by SS troops containing \"‘an object which, though covered by a tarpaulin, bore every resemblance to a monstrous torpedo’\". Subsequently, a plan was formed to make an attempt to capture a whole unexploded V-2 rocket and transport it to Britain. Around 20 May 1944, a relatively undamaged V-2 rocket fell on the swampy bank of the Bug River near the village of Sarnaki and local Poles managed to hide it before German arrival. The rocket was then dismantled and smuggled across Poland. In late July 1944, the Polish resistance (Home Army and V1 and V2) secretly transported parts of the rocket out of Poland in Operation Most III (Bridge III), for analysis by British intelligence.\n\nIn late 1943 Deutsche Arbeitsfront Director, Otto Lafferenz, proposed the idea of a towable watertight container which could hold an A4 rocket. This suggestion progressed to the design of a container of 500 tons displacement to be towed behind a U-boat. Once in firing position, the containers would be trimmed to drop their aft end to a vertical position for launch. The project was dubbed \"Projekt Schwimmweste\" and the containers themselves referred to by the codename \"Prüfstand XII\". Work on the containers was carried out by the Vulkanwerft, and a single example was completed by the end of the war, but never tested with a rocket launch.\n\nIn anticipation of the possibility that launch sites might be forced back into the Reich itself, von Braun and his colleagues were put under pressure to develop a longer-range version of the A4 known alternatively as A9 and A4b, the reason for the dual designation being that the A4 series had received \"national priority\"; the A4b designation ensured the availability of scarce resources.\n\nIn June 1939, Kurt Patt of the Peenemünde Design Office, proposed wings for converting rocket speed and altitude into aerodynamic lift and range. As the rocket encountered thicker atmosphere on its descent phase, it would execute a pullout and enter a shallow glide, trading speed for distance. Patt also proposed the \"Flossengeschoss\" (fin projectile). Both concepts were utilized by Walter Dornberger when he drafted a memo for presentation to Hitler regarding the \"America rocket\" on July 31, 1940.\n\nDesign studies on the A9 began in 1940. In addition to its wings, the A9 would have been somewhat larger than the A4 and its engine would have produced about 30% more thrust. Following wind tunnel testing of models, the design was subsequently modified to replace the wings with fuselage strakes, as the tests showed that these provided better lift at supersonic speeds and also solved the problem of transonic shift of the centre of lift.\n\nDevelopment was suspended in 1941, but in 1944 several V-2s were modified to an approximation of the A9 configuration under the designation A4b. It was calculated that by fitting wings, the A4's range would be extended to , allowing targets in Britain to be attacked from launch sites within Germany itself. It was intended that following launch the curve of the A4b's trajectory would become shallower and the rocket would glide toward its target. It was anticipated that interception by enemy aircraft at the end of the glide phase would be virtually impossible as over the target the A-4b was intended to enter a near vertical dive leaving little time for interception.\n\nThe A4b concept was tested by fitting swept back wings to two A4s launched from Blizna. Little development work had been carried out and the first launch on 27 December 1944 was a complete failure. The second launch attempt, on 24 January 1945, was partially successful, in that the wing broke off, but the A4b still managed to become the first winged guided missile to break the sound barrier and attain Mach 4.\n\nA6 was a designation applied to a variant of the A5 test rocket which used different propellants.\n\nSome sources indicate that it was also applied to a speculative proposal for a manned aerial reconnaissance version of the A4b winged variant of the A4. This A6 was initially proposed to the German Air Ministry as an uninterceptable reconnaissance craft. It would be launched vertically by rocket, taking it to an apogee of ; after re-entering the atmosphere it would enter a supersonic glide phase, when its single ramjet would be ignited. It was hoped that this would provide 15 to 20 minutes of cruise at and would allow the aircraft to return to its base and make a conventional runway landing assisted by a drag chute. However, the Air Ministry had no requirement for such an aircraft and the proposal was rejected. Similar concepts (though unmanned) were produced after the war in the form of the USA's SM-64 Navaho missile and the USSR's Burya, both intercontinental cruise missiles with ramjet propulsion.\n\nThe A7 was a winged design that was never fully constructed. It was worked on between 1940 and 1943 at Peenemünde for the Kriegsmarine. The A7 was similar in structure to the A5, but had larger tail unit fins (1.621 m²) in order to obtain greater range in gliding flight. Two unpowered models of the A7 were dropped from airplanes in order to test flight stability; no powered test was ever performed. The finished rocket should have produced a takeoff thrust of 15 kN and a takeoff weight of 1000 kg. The design had a diameter of 0.38 m and a length of 5.91 m.\n\nThe A8 was a proposed \"stretched\" variant of the A4, to use storable rocket propellants (most likely nitric acid & kerosene). The design never reached the prototype stage, but further design work was carried out after the war by a German rocket team in France as the \"Super V-2\". The project was eventually cancelled, but led to the French Véronique and Diamant rocket projects.\n\nIt was proposed to use an advanced version of the A9 to attack targets on the US mainland from launch sites in Europe, for which it would need to be launched atop a booster stage, the A10.\n\nDesign work on the A10 began in 1940, for a projected first flight to take place in 1946. The initial design was carried out by Ludwig Roth und Graupe and was completed on 29 June 1940. Hermann Oberth worked on the design during 1941, and in December 1941 Walter Thiel proposed that the A10 use an engine composed of six bundled A4 engines, which it was thought would give a total thrust of 180 tonnes.\n\nWork on the A10 was resumed in late 1944 under the \"Projekt Amerika\" codename, and the A10's design was amended to incorporate a cluster of 6 A4 combustion chambers feeding into a single expansion nozzle. This was later altered to a massive single chamber and single nozzle. Test stands were constructed at Peenemunde for firings of the 200 tonne (440,920 lbf) thrust motor.\n\nIt was considered that existing guidance systems would not be accurate enough over a distance of 5,000 km, and it was decided to make the A9 piloted. The pilot was to be guided on his terminal glide towards the target by radio beacons on U-boats and by automatic weather stations landed in Greenland and Labrador.\n\nThe final design of the A10 booster was approximately in height. Powered by a thrust rocket burning diesel oil and nitric acid, during its 50-second burn it would have propelled its A9 second stage to a speed of about and an altitude of .\n\nThe A11 (\"Japan Rakete\") was a design concept which would have acted as the first stage of a three-stage rocket, the other two stages being the A9 and A10.\n\nThe A11 design was shown by von Braun to US officers in Garmisch-Partenkirchen; the drawing was later published in 1946 by the US Army. The A11 was shown as using six of the large single-chamber engines proposed for the A10 stage, with a modified A10 second stage nested within the A11. The design also showed the winged A9, indicating a gliding landing or bombing mission. To achieve orbit, either a new \"kick stage\" would have been required, or the A9 would have to have been lightened. In either case, only a payload of approximately could have been placed in a low earth orbit.\n\nThe A12 design was a true orbital rocket. It was proposed as a four-stage vehicle, comprising A12, A11, A10 and A9 stages. Calculations suggested it could place as much as 10 tonnes payload in low Earth orbit.\n\nThe A12 stage itself would have weighed around 3,500 tonnes fully fuelled, and would have stood high. It was to have been propelled by 50 A10 engines, fuelled by liquid oxygen and alcohol.\n\n\n"}
{"id": "49151754", "url": "https://en.wikipedia.org/wiki?curid=49151754", "title": "All Sky Automated Survey for SuperNovae", "text": "All Sky Automated Survey for SuperNovae\n\nThe All Sky Automated Survey for SuperNovae or ASAS-SN is an automated program to search for new supernovae and other astronomical transients. It has robotic telescopes in both the northern and southern hemispheres. Currently, it can survey the entire sky approximately once every day.\n\nInitially, there were four ASAS-SN telescopes at Haleakala and another four at Cerro Tololo, an LCOGT site. Twelve more telescopes were deployed in 2017 in Chile, South Africa and Texas, with funds from the Moore Foundation, the Ohio State University, the Mount Cuba Astronomical Foundation, China, Chile, Denmark, and Germany. All the telescopes (Nikon telephoto f400/2.8 lenses) have a diameter of 14 cm and ProLine PL230 CCD cameras. The pixels in the cameras span 7.8 arc seconds, so follow up observations on other telescopes are usually required to get a more accurate location.\n\nThe main goal of the project is to look for bright supernovae, including the most powerful supernova ever discovered, ASASSN-15lh. However other transient objects are frequently discovered, including nearby tidal disruption events, Galactic novae (e.g., ASASSN-16kt, ASASSN-16ma, and ASASSN-18fv), cataclysmic variables, and stellar flares, including several of the largest flares ever seen. In July 2017 ASAS-SN has discovered its first comet, ASASSN1. It can detect new objects with magnitudes between 18 and 8.\n\nObjects discovered receive designations starting with ASASSN followed by a dash, a two digit year and letters, for example ASASSN-15lh.\n"}
{"id": "47513425", "url": "https://en.wikipedia.org/wiki?curid=47513425", "title": "Amazon Watershed", "text": "Amazon Watershed\n\nAmazon Watershed : the new environmental investigation is a 1991 book by British writer and environmental and political activist, George Monbiot.\n\nThe book is an investigation into the expulsion of peasants from their homes and their forced relocation to the Amazon. Military police attempt to kill Monbiot as he exposes a vast military project opening up the area to logging and deforestation. He tracks timber cut illegally from Indian reserves all the way back to retailers in the United Kingdom. According to the publishers, Monbiot also \"examines the role of the British and American governments in promoting, wittingly or otherwise, this great ecological catastrophe\".\n\nThe book won the Natural World Book Prize, described as \"the premier environmental book prize in the UK\" in 1991.\n"}
{"id": "56617262", "url": "https://en.wikipedia.org/wiki?curid=56617262", "title": "Anatomical terms of microanatomy", "text": "Anatomical terms of microanatomy\n\nAnatomical terminology is used to describe microanatomical (or histological) structures. This helps describe precisely the structure, layout and position of an object, and minimises ambiguity. An internationally accepted lexicon is Terminologia Histologica.\n\n\"Epithelial\" cells line body surfaces, and are described according to their shape, with three principal shapes: squamous, columnar, and cuboidal. \n\n\"Endothelium\" refers to cells that line the interior surface of blood vessels and lymphatic vessels, forming an interface between circulating blood or lymph in the lumen and the rest of the vessel wall. It is a thin layer of simple, or single-layered, squamous cells called endothelial cells. Endothelial cells in direct contact with blood are called vascular endothelial cells, whereas those in direct contact with lymph are known as lymphatic endothelial cells.\n\nEpithelium can be arranged in a single layer of cells described as \"simple\", or more than one layer, described as \"stratified\". By layer, epithelium is classed as either simple epithelium, only one cell thick (unilayered) or stratified epithelium as stratified squamous epithelium, stratified cuboidal epithelium, and stratified columnar epithelium that are two or more cells thick (multi-layered), and both types of layering can be made up of any of the cell shapes. However, when taller simple columnar epithelial cells are viewed in cross section showing several nuclei appearing at different heights, they can be confused with stratified epithelia. This kind of epithelium is therefore described as pseudostratified columnar epithelium.\n\nTransitional epithelium has cells that can change from squamous to cuboidal, depending on the amount of tension on the epithelium.\n\nA mucous membrane or mucosa is a membrane that lines various cavities in the body and covers the surface of internal organs. It consists of one or more layers of epithelial cells overlying a layer of loose connective tissue. It is mostly of endodermal origin and is continuous with the skin at various body openings such as the eyes, ears, inside the nose, inside the mouth, lip, the urethral opening and the anus. Some mucous membranes secrete mucus, a thick protective fluid. The function of the membrane is to stop pathogens and dirt from entering the body and to prevent bodily tissues from becoming dehydrated.\n\nThe submucosa consists of a dense and irregular layer of connective tissue with blood vessels, lymphatics, and nerves branching into the mucosa and muscular layer. It contains the submucous plexus, and enteric nervous plexus, situated on the inner surface of the muscular layer.\n\nThe muscular layer (also known as the \"muscularis propria\" ) consists of two layers of muscle, the inner and outer layer. The muscle of the inner layer is arranged in circular rings around the tract, whereas the muscle of the outer layer is arranged longitudinally. The stomach has an extra layer, an inner oblique muscular layer. Between the two muscle layers are the myenteric or Auerbach's plexus. This controls peristalsis. Activity is initiated by the pacemaker cells (interstitial cells of Cajal). The gut has intrinsic peristaltic activity (basal electrical rhythm) due to its self-contained enteric nervous system. The rate can of course be modulated by the rest of the autonomic nervous system.\n\nThe layers are not truly longitudinal or circular, rather the layers of muscle are helical with different pitches. The inner circular is helical with a steep pitch and the outer longitudinal is helical with a much shallower pitch.\n\n\nThe hollow inner part of a body organ (such as the gastrointestinal tract) or tube (such as an artery) is called the \"lumen\". The side of a cell facing the lumen is called the \"\" surface; the opposite side, facing away from the lumen is the \"basolateral\" surface, which faces instead towards the \"interstitium\", and away from the lumen.\n"}
{"id": "59188575", "url": "https://en.wikipedia.org/wiki?curid=59188575", "title": "Aridibacter nitratireducens", "text": "Aridibacter nitratireducens\n\nAridibacter nitratireducens is a non-motile bacterium from the genus of \"Aridibacter\" which has been isolated from clayey sand from Eikwe in Ghana.\n"}
{"id": "46892477", "url": "https://en.wikipedia.org/wiki?curid=46892477", "title": "BDF-521", "text": "BDF-521\n\nBDF-521 is a remote galaxy with a redshift of z = 7.008 corresponds to a distance traveled by light to come down to Earth of 12.89 billion light years.\n\n"}
{"id": "5843539", "url": "https://en.wikipedia.org/wiki?curid=5843539", "title": "Bisection bandwidth", "text": "Bisection bandwidth\n\nIn computer networking, if the network is bisected into two partitions, the bisection bandwidth of a network topology is the bandwidth available between the two partitions. Bisection should be done in such a way that the bandwidth between two partitions is minimum. Bisection bandwidth gives the true bandwidth available in the entire system. Bisection bandwidth accounts for the bottleneck bandwidth of the entire network. Therefore bisection bandwidth represents bandwidth characteristics of the network better than any other metric.\n\nFor a linear array with n nodes bisection bandwidth is one link bandwidth. For linear array only one link needs to be broken to bisect the network into two partitions. \nFor ring topology with n nodes two links should be broken to bisect the network, so bisection bandwidth becomes bandwidth of two links. \n\nFor tree topology with n nodes can be bisected at the root by breaking one link, so bisection bandwidth is one link bandwidth.\nFor Mesh topology with n nodes, formula_1 links should be broken to bisect the network, so bisection bandwidth is bandwidth of formula_1 links.\nFor Hyper-cube topology with n nodes, n/2 links should be broken to bisect the network, so bisection bandwidth is bandwidth of n/2 links.\nTheoretical support for the importance of this measure of network performance was developed in the PhD research of Clark Thomborson (formerly Clark Thompson). Thomborson proved that important algorithms for sorting, Fast Fourier transformation, and matrix-matrix multiplication become communication-limited—as opposed to CPU-limited or memory-limited—on computers with insufficient bisection width. F. Thomson Leighton's PhD research tightened Thomborson's loose bound on the bisection width of a computationally-important variant of the De Bruijn graph known as the shuffle-exchange graph. Based on Bill Dally's analysis of latency, average case throughput, and hot-spot throughput of m-ary n-cube networks for various m, It can be observed that low-dimensional networks, in comparison to high-dimensional networks (e.g., binary n-cubes) with the same bisection width (e.g., tori), have reduced latency and higher hot-spot throughput.\n"}
{"id": "47408913", "url": "https://en.wikipedia.org/wiki?curid=47408913", "title": "Comoé National Park Research Station", "text": "Comoé National Park Research Station\n\nThe Comoé National Park Research Station, located in the Comoé National Park, Côte d'Ivoire, was founded by Professor Karl Eduard Linsenmair in 1989/90.\n\nThe research station was forced to close after the outbreak of the First Ivorian Civil War in 2002. After the end of the Second Ivorian Civil War in 2011 repairs at the station began and in 2014 the station had achieved again its full working capacity. The focus of the field based research is on conservation, tropical ecology and behaviour.\n\nIn 1989/90 a first research camp was realized with substantial funding provided by the Volkswagen Stiftung, the University of Würzburg and the respective Ministry (Bayerisches Staatsministerium für Bildung und Kultus, Wissenschaft und Kunst). A successful application for a research grant by Linsenmair at the Fritz Thyssen Foundation led to the expansion and transformation into a permanent station, after various bureaucratic hurdles in Germany and Côte d'Ivoire, which delayed the construction of the field station approximately 8 years. Construction started in 2000 and in early 2002 all guesthouses and other buildings apart from the lab were finished and a move from the camp to the new station was possible.\n\nThe outbreak of the First Ivorian Civil War, in September 2002, resulted in the loss of the entire removable and demountable equipment and the closure of the station. Due to the positive development in the country after the Second Ivorian Civil War, the rehabilitation of the station started in 2012 with remaining funds from the Fritz Thyssen Foundation and the University of Würzburg. With the construction of the solar plant, in December 2014, the rehabilitation was finished and the station had achieved its full working capacity again, making it one of the most modern field research stations in Africa.\n\nThe Research of the station focuses on various fields of conservation, tropical ecology and behaviour, e.g. ecophysiology, chemical and evolutionary ecology. In its first 2 decades before the civil war over 20 international research institutions conducted projects at the station with over 100 scientists contributing to the over 200 papers published in peer reviewed journals. Far more students participated in field courses, collecting data for more than 40 diploma, masters, bachelors and Ph.D. theses.\n\nResearch institutions currently working at the station are:\n\nThe research station is also a base for the longterm and large scale monitoring program in the BMBF's WASCAL project (West African Science Service Center on Climate Change and Adapted Land Use) and was one of the headquarters for the BIOTA West project focused in Côte d'Ivoire until the outbreak of the civil war. It also works closely together with the park management (OIPR, Office Ivorien des Parcs et Reserves) on matters of conservation.\n\nThe facilities of the research station allow for completely autonomous working conditions 24 hours a day and include:\n"}
{"id": "2422456", "url": "https://en.wikipedia.org/wiki?curid=2422456", "title": "Contributors to the mathematical background for general relativity", "text": "Contributors to the mathematical background for general relativity\n\nThis is a list of contributors to the mathematical background for general relativity. For ease of readability, the contributions (in brackets) are unlinked but can be found in the contributors' article.\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "40513150", "url": "https://en.wikipedia.org/wiki?curid=40513150", "title": "Corrie Moreau", "text": "Corrie Moreau\n\nCorrie S. Moreau is an evolutionary biologist, and entomologist with a specialty in myrmecology, the study of ants. She is currently a curator at the Field Museum of Natural History and scientific affiliate at the University of Chicago's Committee on Evolutionary Biology.\nMoreau studies the evolution, ecology, biogeography, systematics, and diversification of insects and their microbial gut-symbionts using molecular and genomic tools. She has also been an advocate for increasing women and diversity in the sciences.\n\nMoreau received a PhD in biology from Harvard University (2003 – 2007) under the guidance of Dr. E.O. Wilson and Dr. Naomi E. Pierce.\n\nShe received a MSc from San Francisco State University and the California Academy of Sciences (2000 – 2003) and a Bachelors (1996 – 2000) from San Francisco State University.\n\nMoreau and colleagues were the first to establish the origin of the ants at 140 million years ago using molecular sequence data (40 million years older than previous estimates), and that the diversification of the ants coincided with the rise of the flowering plants (angiosperms). In addition, Moreau and Charles D. Bell showed that the tropics have been and continue to be important for the evolution of the ants. Moreau and colleagues have demonstrated the importance of gut-associated bacteria in the evolutionary and ecological success of ants through targeted bacterial and microbiome sequencing, including showing that bacterial gut symbionts are tightly linked with the evolution of herbivory in ants.\n\nIn 2018 elected a Fellow of the American Association for the Advancement of Science.\n\nFeatured by National Geographic as a Women of Impact in 2018.\n\nIn 2016 Moreau was selected as a Kavli Fellow of the National Academy of Sciences.\n\nIn 2015 Moreau was included in \"15 Brilliant Women Bridging the Gender Gap in Science\" and in 2014 listed as \"10 Women Scientists You Should Follow on Twitter\".\n\nNational Geographic Explorer – National Geographic Society 2014.\n\nMoreau was elected a Miller Fellow of the Miller Institute at the University of California, Berkeley (2007 – 2008).\n\nShe received two \"Excellence and Distinction in Teaching Awards\" from Harvard University’s Derek Bok Center for Teaching and Learning (2004 & 2006).\n\nMoreau was featured in Chapter 13 of Dr. Edward O. Wilson’s 2013 book “Letters to a Young Scientist.” Wilson writes “There was no bravado in Corrie, no trace of overweening pride, no pretension.” Wilson goes on to state “The story of Corrie Saux Moreau’s ambitious undertaking is one I feel especially important to bring to you. It suggest that courage in science born of self-confidence (without arrogance!), a willingness to take a risk but with resilience, a lack of fear of authority, a set of mind that prepares you to take a new direction if thwarted, are of great value – win or lose.\"\n\nMoreau was born in New Orleans, Louisiana. She was the subject of a museum exhibit and graphic novel, \"The Romance of Ants\" .\n\n\n"}
{"id": "1649909", "url": "https://en.wikipedia.org/wiki?curid=1649909", "title": "Deadband", "text": "Deadband\n\nA deadband (sometimes called a neutral zone or dead zone) is a band of input values in the domain of a transfer function in a control system or signal processing system where the output is zero (the output is 'dead' - no action occurs). Deadband regions can be used in control systems such as servoamplifiers to prevent oscillation or repeated activation-deactivation cycles (called 'hunting' in proportional control systems). A form of deadband that occurs in mechanical systems, compound machines such as gear trains is backlash.\n\nIn some power substations there are regulators that keep the voltage within certain predetermined limits, but there is a range of voltage in-between during which no changes are made, such as between 112 and 118 volts (deadband is 6 volts here), or 215 to 225 volts (deadband is 10 volts here).\n\nGear teeth with slop (\"backlash\") exhibit deadband. There is no drive from the input to the output shaft in either direction while the teeth are not meshed. Leadscrews generally also have backlash and hence a deadband, which must be taken into account when making position adjustments, especially with CNC systems. If mechanical backlash eliminators are not available, the control can compensate for backlash by adding the deadband value to the position vector whenever direction is reversed.\n\nDeadband is different from hysteresis. With hysteresis there is no dead zone, and so the output is always in one direction or another. Devices with hysteresis have memory, in that previous system states dictate future states. Examples of devices with hysteresis are single-mode thermostats and smoke alarms.\n\nSimple (single mode) thermostats exhibit hysteresis. For example, the furnace in the basement of a house is adjusted automatically by the thermostat to be switched on as soon as the temperature at the thermostat falls to 18 °C and the furnace is switched off by the thermostat as soon as the temperature at the thermostat reaches 22 °C. There is no temperature at which the house is not being heated or allowed to cool (furnace on or off).\n\nA thermostat which sets a single temperature and automatically controls both heating and cooling systems without a mode change exhibits a deadband range around the target temperature. The low end of the deadband is just above the temperature where the heating system turns on. The high end of the deadband is just below the temperature where the air-conditioning system starts.\n\n\n"}
{"id": "51123208", "url": "https://en.wikipedia.org/wiki?curid=51123208", "title": "Denis Coulthard Graham", "text": "Denis Coulthard Graham\n\nDr Denis Coulthard Graham FRSE FRSC FIB FRSA (1929-2002) was a British biological chemist. He specialised in plant diseases and their treatment.\n\nHe was born in Carlisle in December 1929.\n\nHe went to Durham University graduating BSc. He then undertook postgraduate studies at Edinburgh University gaining a doctorate (PhD). He rose to be Director of Agricultural Scientific Services in the Department of Agriculture and Fisheries within the Scottish Office. Edinburgh University granted him a second, honorary doctorate (DSc) whilst in this role.\n\nFrom the 1970s he lived in Caiystone Gardens in southern Edinburgh.\nIn 1975 he was elected a Fellow of the Royal Society of Edinburgh. His proposers were Mary Noble, .\n\nHe died in Edinburgh on 12 October 2002.\n\nIn 1968 he married Elizabeth (Betty) Fraser, a New Zealander. They had no children.\n\n"}
{"id": "35596359", "url": "https://en.wikipedia.org/wiki?curid=35596359", "title": "ECybermission", "text": "ECybermission\n\neCybermission (stylized as eCYBERMISSION) is a U.S. Army-sponsored online educational science fair for students in grades 6-9 in the United States or at US Army schools across the world. The contest is conducted entirely online—groups of 3-4 students submit \"Mission Folders\", which contain detailed information about their projects choosing either Scientific Inquiry or the Engineering Design Process.\n\nThe competition selects winners on state, regional, and finally national levels for each grade level. All regional winners receive a one-week trip to the Washington, DC area to attend the National Judging and Educational Event (NJ&EE). Students can win up to $9,000 in savings bonds (maturity value). The NJ&EE event includes many opportunities to meet others, physical training, various workshops and panels, as well as the STEM Challenge, which is a day working with scientists and engineers from different sectors of RDECOM, the department of the Army that oversees the events.\n\neCYBERMISSION is part of the Army Educational Outreach Program (AEOP).\n\nThe competition is administered by the National Science Teachers Association (NSTA).\n\n"}
{"id": "21144218", "url": "https://en.wikipedia.org/wiki?curid=21144218", "title": "Electron rest mass", "text": "Electron rest mass\n\nThe electron rest mass (symbol: ) is the mass of a stationary electron. It is one of the fundamental constants of physics and is also very important in chemistry because of its relation to the Avogadro constant. It has a value of about kilograms or about atomic mass units, equivalent to an energy of about joules or about 0.5110 MeV.\n\nThe term \"rest mass\" is used because according to special relativity the mass of an object is increased in a frame of reference that is moving relative to that object. Most practical measurements are carried out on moving electrons. If the electron is moving at a relativistic velocity, the result must therefore be corrected to obtain the rest mass. This correction is only substantial for electrons accelerated by voltages of well over 100 kV.\n\nSince the electron mass determines a number of observed effects in atomic physics, there are potentially many ways to determine its mass from an experiment, if the values of other physical constants are already considered known.\n\nHistorically, the mass of the electron was determined directly from combining two measurements. The mass-to-charge ratio of the electron was first estimated by Arthur Schuster in 1890 by measuring the deflection of \"cathode rays\" due to a known magnetic field in a cathode ray tube. This was before it was even known what cathode rays actually were! It was seven years later that J. J. Thomson showed that cathode rays consist of streams of particles, to be called electrons, and made more precise measurements of their mass-to-charge ratio again using a cathode ray tube.\n\nThe second measurement was of the charge of the electron. This was determined with a precision of better than 1% by Robert A. Millikan in his famous oil drop experiment in 1909. Together with the mass-to-charge ratio, the electron mass was thereby determined with reasonable precision. The value of mass that was found for the electron was initially met with surprise by physicists, since it was so small (less than .1%) compared to the known mass of a hydrogen atom.\n\nThe electron rest mass can be calculated from the Rydberg constant \"R\" and the fine structure constant \"α\" obtained through spectroscopic measurements. Using the definition of the Rydberg constant:\n\nthus\n\nwhere \"c\" is the speed of light and \"h\" is the Planck constant. The relative uncertainty, 5 in the 2006 CODATA recommended value, is due entirely to the uncertainty in the value of the Planck constant.\n\nThe electron relative atomic mass can be measured directly in a Penning trap. It can also be inferred from the spectra of antiprotonic helium atoms (helium atoms where one of the electrons has been replaced by an antiproton) or from measurements of the electron \"g\"-factor in the hydrogenic ions C or O.\n\nThe electron relative atomic mass is an adjusted parameter in the CODATA set of fundamental physical constants, while the electron rest mass in kilograms is calculated from the values of the Planck constant, the fine structure constant and the Rydberg constant, as detailed above. \n\nAs mentioned above, the electron mass is used to calculate the Avogadro constant \"N\":\nHence it is also related to the atomic mass constant \"m\":\nwhere M is molar mass constant (defined in SI) and \"A\"(e) is a directly measured quantity, the relative mass of electron.\n\nNote that \"m\" is defined in terms of \"A\"(e), and not the other way round, and so the name \"electron mass in atomic mass units\" for \"A\"(e) involves a circular definition (at least in terms of practical measurements).\n\nThe electron relative atomic mass also enters into the calculation of all other relative atomic masses. By convention, relative atomic masses are quoted for neutral atoms, but the actual measurements are made on positive ions, either in a mass spectrometer or a Penning trap. Hence the mass of the electrons must be added back on to the measured values before tabulation. A correction must also be made for the mass equivalent of the binding energy \"E\". Taking the simplest case of complete ionization of all electrons, for a nuclide X of atomic number \"Z\",\nAs relative atomic masses are measured as ratios of masses, the corrections must be applied to both ions: the uncertainties in the corrections are negligible, as illustrated below for hydrogen 1 and oxygen 16.\n\nThe principle can be shown by the determination of the electron relative atomic mass by Farnham \"et al.\" at the University of Washington (1995). It involves the measurement of the frequencies of the cyclotron radiation emitted by electrons and by C ions in a Penning trap. The ratio of the two frequencies is equal to six times the inverse ratio of the masses of the two particles (the heavier the particle, the lower the frequency of the cyclotron radiation; the higher the charge on the particle, the higher the frequency):\nAs the relative atomic mass of C ions is very nearly 12, the ratio of frequencies can be used to calculate a first approximation to \"A\"(e), . This approximate value is then used to calculate a first approximation to \"A\"(C), knowing that \"E\"(C)/\"m\"\"c\" (from the sum of the six ionization energies of carbon) is : \"A\"(C) ≈ . This value is then used to calculate a new approximation to \"A\"(e), and the process repeated until the values no longer vary (given the relative uncertainty of the measurement, 2.1): this happens by the fourth cycle of iterations for these results, giving \"A\"(e) = for these data.\n"}
{"id": "19750198", "url": "https://en.wikipedia.org/wiki?curid=19750198", "title": "En echelon veins", "text": "En echelon veins\n\nIn structural geology, en échelon veins or \"en échelon gash fractures\" are structures within rock caused by noncoaxial shear.\n\nThey appear as sets of short, parallel, planar, mineral-filled lenses within a body of a rock. They originate as tension fractures that are parallel to the major stress orientation, σ, in a shear zone. They are subsequently filled by precipitation of a mineral, typically quartz or calcite. As soon as they form, they begin to rotate in the shear zone. Subsequent growth of the fracture therefore causes the vein to take on a sigmoidal shape. They can be used to determine the incremental kinematics of the deformation history of the rock.\n"}
{"id": "51905980", "url": "https://en.wikipedia.org/wiki?curid=51905980", "title": "Environmental Development", "text": "Environmental Development\n\nEnvironmental Development is a quarterly peer-reviewed academic journal covering environmental science and policy published by Elsevier. In January 2018, Natarajan Ishwaran became the new editor-in-chief. He succeeded Eleanor Milne (Colorado State University, now Subject Editor for Climate Change) EIC from July 2015. The founding editor was Theo Beckers (Tilburg University).\n\nThe journal is associated with the Scientific Committee on Problems of the Environment (SCOPE) and is abstracted and indexed in the Emerging Sources Citation Index and Scopus.\n"}
{"id": "22663262", "url": "https://en.wikipedia.org/wiki?curid=22663262", "title": "European Garden Heritage Network", "text": "European Garden Heritage Network\n\nThe European Garden Heritage Network is a nonprofit organization established in 2003 within the EU-Programme INTERREG IIIB NWE to foster transnational co-operation in regional development and cultural heritage. It brings together garden experts, government services, foundations, and tourism agencies to preserve, develop, and promote gardens of historic interest within northwestern Europe.\n\n"}
{"id": "30557885", "url": "https://en.wikipedia.org/wiki?curid=30557885", "title": "Feminism Unmodified", "text": "Feminism Unmodified\n\nFeminism Unmodified: Discourses on Life and Law is a 1987 book by feminist academic Catharine MacKinnon. The book is a collection of essays by MacKinnon delivered during the 1980s, in which she makes a radical feminist critique of pornography and liberal feminism.\n\n\n\n"}
{"id": "92523", "url": "https://en.wikipedia.org/wiki?curid=92523", "title": "Ferrous", "text": "Ferrous\n\nIn chemistry, ferrous (Fe), indicates a divalent iron compound (+2 oxidation state), as opposed to ferric, which indicates a trivalent iron compound (+3 oxidation state). This usage has decreased, with current IUPAC nomenclature having names containing the oxidation state in bracketed Roman numerals instead, such as iron(II) oxide for ferrous oxide (FeO), and iron(III) oxide for ferric oxide (FeO).\n\nOutside chemistry, \"ferrous\" indicates the presence of iron. The word is derived from the Latin word \"\" (\"iron\"). Ferrous metals include steel and pig iron (with a carbon content of a few percent) and alloys of iron with other metals (such as stainless steel). Manipulation of atom-to-atom relationships between iron, carbon, and various alloying elements establishes the specific properties of ferrous metals. Non-ferrous metals and alloys do not contain an appreciable amount of iron.Ferric refers to iron-containing materials or compounds. In chemistry the term is reserved for iron with an oxidation number of +3, also denoted iron(III) or Fe3+. On the other hand, ferrous refers to iron with oxidation number of +2, denoted iron(II) or Fe2+.\n\n"}
{"id": "7877158", "url": "https://en.wikipedia.org/wiki?curid=7877158", "title": "Ghanim (crater)", "text": "Ghanim (crater)\n\nGhanim is an impact crater in the northern hemisphere of Saturn's moon Enceladus. Ghanim was first observed in \"Cassini\" images during that mission's February 2005 flyby of Enceladus. It is located at 38.5° North Latitude, 281.5° West Longitude and is 13.9 kilometers across. The topography of the impact crater appears very subdued, suggesting that the crater has undergone significant viscous relaxation since its formation. Tectonics has also affected this crater, by influencing the final, polygonal shape of the crater as well disrupting the southeastern and northwestern margins of the crater following its formation.\n\nGhanim is named after the title character of the \"Tale of Ghanim Bin Ayyub, the Distraught, the Thrall O’ Love\" in \"The Book of One Thousand and One Nights\". Incidentally, craters named after Ghanim's father, Ayyub, and sister, Fitnah, are found nearby.\n"}
{"id": "50775420", "url": "https://en.wikipedia.org/wiki?curid=50775420", "title": "Glossary of aerospace engineering", "text": "Glossary of aerospace engineering\n\n\"Most of the terms listed in Wikipedia glossaries are already defined and explained within Wikipedia itself. However, glossaries like this one are useful for looking up, comparing and reviewing large numbers of terms together. You can help enhance this page by adding new terms or writing definitions for existing ones.\"\n\nThis glossary of aerospace engineering terms pertains specifically to aerospace engineering and its sub-disciplines. For a broad overview of engineering, see glossary of engineering.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "243441", "url": "https://en.wikipedia.org/wiki?curid=243441", "title": "Inferior and superior planets", "text": "Inferior and superior planets\n\nIn the Solar System, a planet is said to be inferior or interior with respect to another planet if its orbit lies inside the other planet's orbit around the Sun. In this situation, the latter planet is said to be superior to the former. In the reference frame of the Earth, in which the terms were originally used, the inferior planets are Mercury and Venus, while the superior planets are Mars, Jupiter, Saturn, Uranus and Neptune. Dwarf planets like Ceres or Pluto and most asteroids are 'superior' in the sense that they almost all orbit outside the orbit of Earth.\n\nThese terms were originally used in the geocentric cosmology of Claudius Ptolemy to differentiate as inferior those planets (Mercury and Venus) whose epicycle remained co-linear with the Earth and Sun, and as superior those planets (Mars, Jupiter, and Saturn) that did not.\n\nIn the 16th century, the terms were modified by Copernicus, who rejected Ptolemy's geocentric model, to distinguish a planet's orbit's size in relation to the Earth's.\n\nWhen Earth is stated or assumed to be the reference point: \n\nThe terms are sometimes used more generally; for example, Earth is an inferior planet relative to Mars.\n\nInterior planet now seems to be the preferred term for astronomers. Inferior/interior and superior are different from the terms inner planet and outer planet, which designate those planets which lie inside the asteroid belt and those that lie outside it, respectively. Inferior planet is also different from minor planet or dwarf planet. Superior planet is also different from gas giant.\n"}
{"id": "27631070", "url": "https://en.wikipedia.org/wiki?curid=27631070", "title": "Inscribed square problem", "text": "Inscribed square problem\n\nThe inscribed square problem, also known as the square peg problem or the Toeplitz' conjecture, is an unsolved question in geometry: \"Does every plane simple closed curve contain all four vertices of some square?\" This is true if the curve is convex or piecewise smooth and in other special cases. The problem was proposed by Otto Toeplitz in 1911. Some early positive results were obtained by Arnold Emch and Lev Schnirelmann. , the general case remains open.\n\nLet \"C\" be a Jordan curve. A polygon \"P\" is inscribed in \"C\" if all vertices of \"P\" belong to \"C\". The inscribed square problem asks:\n\nIt is \"not\" required that the vertices of the square appear along the curve in any particular order.\n\nSome figures, such as circles and squares, admit infinitely many inscribed squares. If \"C\" is an obtuse triangle then it admits exactly one inscribed square; right triangles admit exactly two, and acute triangles admit exactly three.\n\nIt is tempting to attempt to solve the inscribed square problem by proving that a special class of well-behaved curves always contains an inscribed square, and then to approximate an arbitrary curve by a sequence of well-behaved curves and infer that there still exists an inscribed square as a limit of squares inscribed in the curves of the sequence. One reason this argument has not been carried out to completion is that the limit of a sequence of squares may be a single point rather than itself being a square. Nevertheless, many special cases of curves are now known to have an inscribed square.\n\n showed that piecewise analytic curves always have inscribed squares. In particular this is true for polygons. Emch's proof considers the curves traced out by the midpoints of secant line segments to the curve, parallel to a given line. He shows that, when these curves are intersected with the curves generated in the same way for a perpendicular family of secants, there are an odd number of crossings. Therefore, there always exists at least one crossing, which forms the center of a rhombus inscribed in the given curve. By rotating the two perpendicular lines continuously through a right angle, and applying the intermediate value theorem, he shows that at least one of these rhombi is a square.\n\nStromquist has proved that every \"local monotone\" plane simple curve admits an inscribed square. The condition for the admission to happen is that for any point , the curve should be locally represented as a graph of a function .\n\nIn more precise terms, for any given point on , there is a neighborhood and a fixed direction (the direction of the “-axis”) such that no chord of -in this neighborhood- is parallel to . \n\nLocally monotone curves include all types of polygons, all closed convex curves, and all piecewise \"C\" curves without any cusps.\n\nAn even weaker condition on the curve than local monotonicity is that, for some ε > 0, the curve does not have any inscribed special trapezoids of size ε. A special trapezoid is an isosceles trapezoid with three equal sides, each longer than the fourth side, inscribed in the curve with a vertex ordering consistent with the clockwise ordering of the curve itself. Its size is the length of the part of the curve that extends around the three equal sides. If there are no such trapezoids (or an even number of them), the limiting argument for general curves can be carried to completion, showing that curves with this property always have an inscribed square.\n\nIf a Jordan curve inscribed in an annulus whose outer radius is at most times its inner radius, and it is drawn in such a way that it separates the inner circle of the annulus from the outer circle, then it contains an inscribed square. In this case, if the given curve is approximated by some well-behaved curve, then any large squares that contain the center of the annulus and are inscribed in the approximation are topologically separated from smaller inscribed squares that do not contain the center. The limit of a sequence of large squares must again be a large square, rather than a degenerate point, so the limiting argument may be used.\n\nThe affirmative answer is also known for centrally symmetric curves, even badly-behaved ones such as the Koch snowflake, and curves with reflective symmetry across a line.\n\nOne may ask whether other shapes can be inscribed into an arbitrary Jordan curve. It is known that for any triangle \"T\" and Jordan curve \"C\", there is a triangle similar to \"T\" and inscribed in \"C\". Moreover, the set of the vertices of such triangles is dense in \"C\". In particular, there is always an inscribed equilateral triangle. It is also known that any Jordan curve admits an inscribed rectangle.\n\nSome generalizations of the inscribed square problem consider inscribed polygons for curves and even more general continua in higher dimensional Euclidean spaces. For example, Stromquist proved that every continuous closed curve \"C\" in R satisfying \"Condition A\" that no two chords of \"C\" in a suitable neighborhood of any point are perpendicular admits an inscribed quadrilateral with equal sides and equal diagonals. This class of curves includes all \"C\" curves. Nielsen and Wright proved that any symmetric continuum \"K\" in R contains many inscribed rectangles. H.W. Guggenheimer proved that every hypersurface \"C\"-diffeomorphic to the sphere \"S\" contains 2 vertices of a regular Euclidean \"n\"-cube.\n\n\n"}
{"id": "24653094", "url": "https://en.wikipedia.org/wiki?curid=24653094", "title": "Interdependence liberalism", "text": "Interdependence liberalism\n\nInterdependence liberalism is a strand of liberal international relations thinking which argues that increased interdependence between countries reduces the chance of them engaging in conflict. Interdependence liberals see modernisation as increasing the levels and scope of interdependence between states leading to greater cooperation. Such thinkers also see welfare as the primary concern of states, and the military force becoming less useful.\n\n"}
{"id": "54611650", "url": "https://en.wikipedia.org/wiki?curid=54611650", "title": "Journal of the History of the Behavioral Sciences", "text": "Journal of the History of the Behavioral Sciences\n\nThe Journal of the History of the Behavioral Sciences is a quarterly peer-reviewed academic journal covering the history of social and behavioral sciences. It was established in 1965 and is published by John Wiley & Sons. The editor-in-chief is Ian A. M. Nicholson (St. Thomas University). According to the \"Journal Citation Reports\", the journal has a 2016 impact factor of 0.667, ranking it 11th out of 35 journals in the category \"History of Social Sciences\".\n"}
{"id": "58535501", "url": "https://en.wikipedia.org/wiki?curid=58535501", "title": "LKS (spacecraft)", "text": "LKS (spacecraft)\n\nThe Space Shuttle LKS (Russian: Лёгкий Космический Самолёт, \"Light Cosmos Plane\") was a Soviet Union project led by Vladimir Chelomey in response to the United States Space Shuttle. The \"LKS\" was smaller and cheaper than its American counterpart, but was ultimately discarded in favor of the larger Buran. Claiming that the Buran project was too big, heavy, and expensive for Russia to complete, Chelomey designed the LKS in 1979. He ordered the construction of a full-scale mock-up, as a way to further stimulate interest. The project was never fully sanctioned however, and in 1982, Chelomey was officially ordered by the Soviet government to stop any further development. In March 1983, Chelomey made yet another attempt to obtain permission to build the LKS to repel US Intercontinental ballistic missiles. This too proved futile. In 1991 the mock-up was destroyed, possibly by sabotage. \n\nFrom 1950 to 1964, before the US Space Shuttle in 1972, Chelomey developed two concepts for a spacecraft that would launch vertically and land horizontally. The MP-1 Kosmoplan was planned to complete missions to the Moon, Mars, and Venus. Upon re-entry into the Earth's atmosphere, it would land with the support of turbocharged engines similar to a conventional airplane. The other concept, called Raketoplan or \"rocket plane\", was a space shuttle intended to orbit the Earth and transport passengers, space freight, and weapons. Both concepts were never implemented due to the dis-empowerment of Nikita Khrushchev. \n\nIn 1976, the Soviet government formally authorized the “head-designer” Valentin Glushko to proceed with the Buran project, which was intended to simply copy the Space Shuttle. The Buran project and its massive launch vehicle \"Energia\" were the targets of several critics among Russian space designers and scientists. One of them was Vladimir Chelomey, Glushko’s former ally, who was responsible for the famous OKB-52 NPO Mashinostroyeniya (from which came the Proton rocket, the TKS spacecraft, and the Almaz and Salyut space stations).\n\nIn 1979, Chelomey affirmed that the Buran project was too big, heavy, and expensive for Russia to complete, and designed the \"LKS\", another space shuttle concept, as an alternative to the Buran or Energia. The first concept had two V-type vertical stabilizers, similar to the F/A-18 vertical stabilizer arrangement. This was later changed to the conventional arrangement of a rudder, similar to the Space Shuttle and Buran. \n\nIn 1980, within a month of work, Chelomey ordered the construction of a full-scale mock-up by his team, as a way to further stimulate Soviet authorities in his direction. \n\nIn 1982, Chelomey was officially ordered by the Soviet government to stop any further development of the LKS project. By this point, he was believed to have expended more than 400,000 rubles in a program not formally authorized by the Soviets. When US President Ronald Reagan announced the Strategic Defense Initiative (SDI) in March 1983, Chelomey made yet another attempt to obtain permission to build the LKS to repel US Intercontinental ballistic missiles. However, in September 1983, he was rejected by a government commission. Chelomey died in December 1984, leaving behind his most ambitious project. In 1991 the mock-up was destroyed in a so-called “act of sabotage” by unknown people for unknown reasons. It is believed that if the LKS project was to be approved and completed, it would've been a valid alternative not only to Buran but also to Soyuz itself for Mir and ISS space operations.\n\n\n1. Launch (T = 00:00)\n2. First Stage Separation (T = 02:06)\n3. Second Stage Separation (T = 05:34)\n4. Third Stage Separation (T = 09:49)\n5. LKS OMS Ignition (T = 10:00)\n6. LKS in LEO (T = 13:20)\n\n1. LKS gain the correct asset for burn\n2. LKS OMS ignition & de-orbit burn\n3. Braking maneuverings \n4. LKS re-entry into atmosphere\n\n1. LKS is back into atmosphere\n2. Braking maneuverings\n3. LKS gain the landing alley\n4. LKS assume a steep descent angle\n5. LKS turns to Baikonur Cosmodrome runaway\n6. LKS lands and open thebrake chute\n\n\nHomepage in Russian of Npomash\nEncyclopedia Astronautica: LKS (English)\nrussianspaceweb: Light Space Plane, LKS (English)\n"}
{"id": "5680831", "url": "https://en.wikipedia.org/wiki?curid=5680831", "title": "Leopold Adametz", "text": "Leopold Adametz\n\nLeopold Adametz (11 October 1861, Valtice – 27 January 1941, Vienna) was a Moravia-born Austrian zoologist. The son of a manufacturer, he studied at the Hochschule für Bodenkultur in Vienna and at the University of Leipzig. In 1886, he was awarded his doctorate. He became an assistant of Martin Wickens and in 1888 an assistant professor of zoology. From 1891 he was a professor in Krakau, from 1898 until 1932 he was the professor of animal product studies and the morphology of house pets at the Hochschule für Bodenkultur in Wien. He was a member of the Austrian Academy of Sciences.\n\n\n"}
{"id": "36473908", "url": "https://en.wikipedia.org/wiki?curid=36473908", "title": "List of OEIS sequences", "text": "List of OEIS sequences\n\nThis article provides a list of integer sequences in the On-Line Encyclopedia of Integer Sequences that have their own English Wikipedia entries.\n\n"}
{"id": "6999304", "url": "https://en.wikipedia.org/wiki?curid=6999304", "title": "List of chemical process simulators", "text": "List of chemical process simulators\n\nThis is a list of software used to simulate the material and energy balances of chemical processing plants.\n\n\n"}
{"id": "49316021", "url": "https://en.wikipedia.org/wiki?curid=49316021", "title": "List of fritillaries (butterflies)", "text": "List of fritillaries (butterflies)\n\nThis is a list of butterfly species in diverse genera with the common name fritillary. The term refers to the chequered markings on the wings, usually black on orange, and derives from the Latin \"fritillus\" (meaning dice-box - or, according to some sources, a chequerboard: the fritillary flower, with its chequered markings, has the same derivation). Most fritillaries belong to the family Nymphalidae.\n"}
{"id": "46821559", "url": "https://en.wikipedia.org/wiki?curid=46821559", "title": "List of questionable diagnostic tests", "text": "List of questionable diagnostic tests\n\nThis is a list of medical diagnostic tests that are considered questionable, unverified or refuted.\n\n"}
{"id": "603273", "url": "https://en.wikipedia.org/wiki?curid=603273", "title": "Magnification", "text": "Magnification\n\nMagnification is the process of enlarging the apparent size, not physical size, of something. This enlargement is quantified by a calculated number also called \"magnification\". When this number is less than one, it refers to a reduction in size, sometimes called \"minification\" or \"de-magnification\".\n\nTypically, magnification is related to scaling up visuals or images to be able to see more detail, increasing resolution, using microscope, printing techniques, or digital processing. In all cases, the magnification of the image does not change the perspective of the image.\n\nSome optical instruments provide visual aid by magnifying small or distant subjects.\n\n\nOptical magnification is the ratio between the apparent size of an object (or its size in an image) and its true size, and thus it is a dimensionless number. Optical magnification is sometimes referred to as \"power\" (for example \"10× power\"), although this can lead to confusion with optical power.\n\nFor real images, such as images projected on a screen, \"size\" means a linear dimension (measured, for example, in millimeters or inches).\n\nFor optical instruments with an eyepiece, the linear dimension of the image seen in the eyepiece (virtual image in infinite distance) cannot be given, thus \"size\" means the angle subtended by the object at the focal point (angular size). Strictly speaking, one should take the tangent of that angle (in practice, this makes a difference only if the angle is larger than a few degrees). Thus, angular magnification is given by:\n\nformula_1\n\nwhere formula_2 is the angle subtended by the object at the front focal point of the objective and formula_3 is the angle subtended by the image at the rear focal point of the eyepiece.\n\nFor example, the mean angular size of the Moon's disk as viewed from Earth's surface is about 0.52°. Thus, through binoculars with 10× magnification, the Moon appears to subtend an angle of about 5.2°.\n\nBy convention, for magnifying glasses and optical microscopes, where the size of the object is a linear dimension and the apparent size is an angle, the magnification is the ratio between the apparent (angular) size as seen in the eyepiece and the angular size of the object when placed at the conventional closest distance of distinct vision: 25 cm from the eye.\n\nThe linear magnification of a thin lens is\n\nformula_4\n\nwhere formula_5 is the focal length and formula_6 is the distance from the lens to the object. Note that for real images, formula_7 is negative and the image is inverted. For virtual images, formula_7 is positive and the image is upright.\n\nWith formula_9 being the distance from the lens to the image, formula_10 the height of the image and formula_11 the height of the object, the magnification can also be written as:\n\nformula_12\n\nNote again that a negative magnification implies an inverted image.\n\nThe image recorded by a photographic film or image sensor is always a real image and is usually inverted. When measuring the height of an inverted image using the cartesian sign convention (where the x-axis is the optical axis) the value for \"h\" will be negative, and as a result \"M\" will also be negative. However, the traditional sign convention used in photography is \"real is positive, virtual is negative\". Therefore, in photography: Object height and distance are always \"real\" and positive. When the focal length is positive the image's height, distance and magnification are \"real\" and positive. Only if the focal length is negative, the image's height, distance and magnification are \"virtual\" and negative. Therefore, the \"photographic magnification\" formulae are traditionally presented as:\n\nformula_13\n\nThe angular magnification of an optical telescope is given by\n\nformula_14\n\nin which formula_15 is the focal length of the objective lens in a refractor or of the primary mirror in a reflector, and formula_16 is the focal length of the eyepiece.\n\nThe maximum angular magnification (compared to the naked eye) of a magnifying glass depends on how the glass and the object are held, relative to the eye. If the lens is held at a distance from the object such that its front focal point is on the object being viewed, the relaxed eye (focused to infinity) can view the image with angular magnification\n\nformula_17\n\nHere, formula_18 is the focal length of the lens in centimeters. The constant 25 cm is an estimate of the \"near point\" distance of the eye—the closest distance at which the healthy naked eye can focus. In this case the angular magnification is independent from the distance kept between the eye and the magnifying glass.\n\nIf instead the lens is held very close to the eye and the object is placed closer to the lens than its focal point so that the observer focuses on the near point, a larger angular magnification can be obtained, approaching\n\nformula_19\n\nA different interpretation of the working of the latter case is that the magnifying glass changes the diopter of the eye (making it myopic) so that the object can be placed closer to the eye resulting in a larger angular magnification.\n\nThe angular magnification of a microscope is given by\n\nformula_20\n\nwhere formula_21 is the magnification of the objective and formula_22 the magnification of the eyepiece. The magnification of the objective depends on its focal length formula_15 and on the distance formula_24 between objective back focal plane and the focal plane of the eyepiece (called the tube length):\n\nformula_25\n\nThe magnification of the eyepiece depends upon its focal length formula_16 and is calculated by the same equation as that of a magnifying glass (above).\n\nNote that both astronomical telescopes as well as simple microscopes produce an inverted image, thus the equation for the magnification of a telescope or microscope is often given with a minus sign.\n\nMeasuring the actual angular magnification of a telescope is difficult, but it is possible to use the reciprocal relationship between the linear magnification and the angular magnification, since the linear magnification is constant for all objects.\n\nThe telescope is focused correctly for viewing objects at the distance for which the angular magnification is to be determined and then the object glass is used as an object the image of which is known as the exit pupil. The diameter of this may be measured using an instrument known as a Ramsden dynameter which consists of a Ramsden eyepiece with micrometer hairs in the back focal plane. This is mounted in front of the telescope eyepiece and used to evaluate the diameter of the exit pupil. This will be much smaller than the object glass diameter, which gives the linear magnification (actually a reduction), the angular magnification can be determined from\n\nWith any telescope or microscope, or a lens\na maximum magnification exists beyond which the image looks bigger but shows no more detail. It occurs when the finest detail the instrument can resolve is magnified to match the finest detail the eye can see. Magnification beyond this maximum is sometimes called \"empty magnification\".\n\nFor a good quality telescope operating in good atmospheric conditions, the maximum usable magnification is limited by diffraction. In practice it is considered to be 2× the aperture in millimetres or 50× the aperture in inches; so, a 60mm diameter telescope has a maximum usable magnification of 120×.\n\nWith an optical microscope having a high numerical aperture and using oil immersion, the best possible resolution is 200 nm corresponding to a magnification of around 1200×. Without oil immersion, the maximum usable magnification is around 800×. For details, see limitations of optical microscopes.\n\nSmall, cheap telescopes and microscopes are sometimes supplied with the eyepieces that give magnification far higher than is usable.\n\nMagnification figures on printed pictures can be misleading. Editors of journals and magazines routinely resize images to fit the page, making any magnification number provided in the figure legend incorrect. A scale bar (or micron bar) is a bar of stated length superimposed on a picture. This bar can be used to make accurate measurements on a picture. When a picture is resized the bar will be resized in proportion. If a picture has a scale bar, the actual magnification can easily be calculated. Where the scale (magnification) of an image is important or relevant, including a scale bar is preferable to stating magnification.\n\n"}
{"id": "22577943", "url": "https://en.wikipedia.org/wiki?curid=22577943", "title": "Museum Management and Curatorship", "text": "Museum Management and Curatorship\n\nMuseum Management and Curatorship (MMC) is an international peer-reviewed, journal aimed at museum professionals, consultants, educators, and researchers. Its content is intended to examine current issues in museum practice. The journal covers aspects such as administration, archives, collections management, communications, conservation, diversity, globalization, governance, interpretation, leadership, management, new technology, professional ethics, public service, purpose/mission, and social responsibility.\n\nThe journal is published quarterly by Routledge.\n\n"}
{"id": "51494830", "url": "https://en.wikipedia.org/wiki?curid=51494830", "title": "NGC 169", "text": "NGC 169\n\nNGC 169 is a barred spiral galaxy located in the constellation Andromeda. It was discovered on September 18, 1857 by R. J. Mitchell.\n\nNGC 169 has a smaller companion named NGC 169A. The two are currently interacting, and the pair is included in Halton Arp's Atlas of Peculiar Galaxies.\n"}
{"id": "11883444", "url": "https://en.wikipedia.org/wiki?curid=11883444", "title": "National Centre for e-Social Science", "text": "National Centre for e-Social Science\n\nThe National Centre for e-Social Science (NCeSS) was a UK based centre which aimed to promote e-Social Science. It was founded circa 2003 with funding from the Economic and Social Research Council (ESRC) to investigate how innovative and powerful computer-based infrastructure and tools developed over the previous three years under the UK e-Science programme could benefit social science. The foundation of much of the work was the use of computational infrastructure that was collaboratively provisioned and worked across organisational boundaries. Collaboration was key and the computational approach was commonly known as 'Grid Computing'.\n\ne-Social Science refers to the use of enhanced computer and information technology infrastructure and tools for social science. The role of NCeSS was to investigate specific applications of e-Social Science, develop tools to support them and to advise on the future strategic direction of e-Social Science and e-Science more generally. NCeSS also provided information, training, advice, support and on-line resources to help the social science research community adopt e-Social Science approaches. NCeSS developed a portal based e-Infrastructure based on Sakai to support e-Social Science, but it was short lived due to lack of resources for sustaining it.\n\nNCeSS was coordinated from the University of Manchester, and involved groups from various other UK universities. The NCeSS research programme included applications of e-Science in both quantitative and qualitative social sciences, and studies of issues relevant to promoting the wider adoption of e-Science.\n\nNCeSS gradually stopped functioning and the NCeSS Sakai Portal went off line in around 2011.\n\nBy 2015, little remains online to indicate that NCeSS ever existed, but the Internet Archive Way Back Machine captured something of the Web Site that once was.\n"}
{"id": "56498399", "url": "https://en.wikipedia.org/wiki?curid=56498399", "title": "Neurotree", "text": "Neurotree\n\nNeurotree and Academic Family Tree are web-based databases for the academic genealogies of neuroscientists and of people working in academic settings respectively.\n\nNeurotree and Academic Family Tree are notable because they have been used as sources of information for the history and prospects of various academic fields such as psychology, meteorology, organizational communication, and neuroscience. Neurotree has also been used to address infometrics and to research issues of scientific methodology.\n\nNeurotree and Academic Family Tree are volunteer-run; accuracy is maintained by a group of volunteer editors. Hierarchical connections between parents and children are defined as any meaningful mentoring relationship (research assistant, graduate student, or postdoctoral fellow) between researchers. Continuous records extend well into the Middle Ages and earlier.\nAs of 5 February 2018, Neurotree contained 116,874 people with 135,773 connections among them. As of 5 February 2018, Academic Family Tree contained 689,800 people with 606,600 connections among them. Academic Family Tree encompasses a broad range of disciplines. As of 5 February 2018, there were 55 disciplines spanning science (e.g., human genetics, microbiology, and psychology), mathematics and philosophy, engineering, and the humanities (e.g., economics, law, and theology).\n\nThe two databases are closely linked. A search for a person in Neurotree gives results not only from Neurotree, but also from any of the 54 other trees in Academic Family Tree in which that person appears. The same is true for a search in any of those trees under Academic Family Tree or from the main page of Academic Family Tree.\n\nNeurotree was founded in 2005 by Stephen V. David, an Assistant Professor in the Oregon Hearing Research Center of Oregon Health and Science University, and by Benjamin Y. Hayden, an assistant professor in the Department of Brain and Cognitive Sciences,\nCenter for Visual Science, University of Rochester. Academic Family Tree began shortly after 2005.\n\nIn November 2014, David received funding for Neurotree from the Metaknowledge Network. In November 2016, David received funding for Academic Family Tree from the NSF SciSIP Program.\n\nOne other notable discipline-specific academic genealogy is the Mathematics Genealogy Project. Academic Family Tree has its own mathematics tree, MathTree but it is much less complete than the Mathematics Genealogy Project. As of 6 February 2018, MathTree contained 33,634 people whereas the Mathematics Genealogy Project contained 223,794 people.\n\nOne other general academic genealogy was PhD Tree. PhD Tree ceased functioning some time after June 2017.\n\nMarsh (2017) pointed out that information for Neurotree and Academic Family Tree is provided by volunteers and its not formally peer-reviewed. She cautioned that this can mean their information is inaccurate.\n\n\n"}
{"id": "523973", "url": "https://en.wikipedia.org/wiki?curid=523973", "title": "Operation Castle", "text": "Operation Castle\n\nOperation Castle was a United States series of high-yield (high-energy) nuclear tests by Joint Task Force 7 (JTF-7) at Bikini Atoll beginning in March 1954. It followed \"Operation Upshot–Knothole\" and preceded \"Operation Teapot\".\n\nConducted as a joint venture between the Atomic Energy Commission (AEC) and the Department of Defense (DoD), the ultimate objective of the operation was to test designs for an aircraft-deliverable thermonuclear weapon.\n\nOperation Castle was considered by government officials to be a success as it proved the feasibility of deployable \"dry\" fuel designs for thermonuclear weapons. There were technical difficulties with some of the tests: one device had a yield much lower than predicted (a \"fizzle\"), while two other bombs detonated with over twice their predicted yields. One test in particular, \"Castle Bravo\", resulted in extensive radiological contamination of nearby islands (including inhabitants and U.S. soldiers stationed there), as well as a nearby Japanese fishing boat (the \"Daigo Fukuryū Maru\"), resulting in one direct fatality, and then continued health problems for many of those exposed. Public reaction to the tests and an awareness of the long-range effects of nuclear fallout has been attributed as being part of the motivation for the Partial Test Ban Treaty of 1963.\n\nBikini Atoll had previously hosted nuclear testing in 1946 as part of \"Operation Crossroads\" where the world's fourth and fifth atomic weapons were detonated in Bikini Lagoon. Since then, American nuclear weapons testing had moved to Enewetok Atoll to take advantage of generally larger islands and deeper water. Both atolls were part of the American Pacific Proving Grounds.\n\nThe extremely high yields of the Castle weapons caused concern within the AEC that potential damage to the limited infrastructure already established at Enewetak would delay other operations. Additionally, the cratering from the \"Castle\" weapons was expected to be comparable to that of \"Ivy Mike\", a 10.4 megatons of TNT (Mt) device tested at Enawetak in 1952 leaving a crater approximately in diameter marking the location of the obliterated test island Elugelab.\n\nThe \"Ivy Mike\" test was the world's first \"hydrogen bomb\", producing a full-scale thermonuclear or fusion explosion. The \"Ivy Mike\" device used liquid deuterium, an isotope of hydrogen, making it a \"wet\" bomb. The complex dewar mechanisms needed to store the liquid deuterium at cryogenic temperatures made the device three stories tall and 82 tons in total weight, far too heavy and bulky to be a usable weapon. With the success of \"Ivy Mike\" as proof of the Teller-Ulam bomb concept, research began on using a \"dry\" fuel to make a practical fusion weapon so that the United States could begin production and deployment of thermonuclear weapons in quantity. The final result incorporated lithium deuteride as the fusion fuel in the Teller-Ulam design, vastly reducing size and weight and simplifying the overall design. \"Operation Castle\" was charted to test four dry fuel designs, two wet bombs, and one smaller device. The approval for \"Operation Castle\" was issued to JTF-7 by Major General Kenneth D. Nichols, the General Manager of the AEC, on January 21, 1954.\n\n\"Operation Castle\" was organized into seven experiments, all but one of which were to take place at Bikini Atoll. Below is the original test schedule (as of February 1954).\n\nThe \"Echo\" test was canceled due to the liquid fuel design becoming obsolete with the success of dry-fueled \"Bravo\" as noted above. \"Yankee\" was similarly considered obsolete and the Jughead device was replaced with a \"Runt II\" device (similar to the \"Union device\"), which was hastily completed at Los Alamos and flown to Bikini. With this revision, both of the wet fuel devices were removed from the test schedule.\n\n\"Operation Castle\" was intended to test lithium deuteride (LiD) as a thermonuclear fusion fuel. A solid at room temperature, LiD, if it worked, would be far more practical than the cryogenic liquid deuterium fuel in the Ivy Mike device. The same Teller-Ulam principle would be used as in the \"Ivy Mike\" so-called \"Sausage\" device, but the fusion reactions were different. \"Ivy Mike\" fused deuterium with deuterium, but the LiD devices would fuse deuterium with tritium. The tritium was produced during the explosion by irradiating the lithium with fast neutrons.\n\n\"Bravo\", \"Yankee (II)\", and \"Union\" used lithium enriched in the Li-6 isotope (\"Bravo\" and \"Yankee\" used lithium enriched to 40% Li-6, while the lithium used in \"Union\" was enriched to 95% Li-6), while \"Romeo\" and \"Koon\" were fueled with natural lithium (92% Li-7, 7.5% Li-6). The use of natural lithium would be important to the ability of the US to rapidly expand its nuclear stockpile during the Cold War nuclear arms race, since the so-called \"Alloy Development Plants\" were in an early stage at the time \"Castle\" was carried out. The first plant started production in the fall of 1953.\n\nAs a hedge, development of liquid deuterium weapons continued in parallel. Even though they were much less practical because of the logistical problems dealing with the transport, handling, and storage of a cryogenic device, the Cold War arms race drove the demand for a viable fusion weapon. The \"Ramrod\" and \"Jughead\" devices were liquid fuel designs greatly reduced in size and weight from their so-called \"Sausage\" predecessor. The \"Jughead\" device was eventually weaponized, and it saw limited fielding by the U.S. Air Force until the \"dry\" fuel H-bombs became common.\n\n\"Nectar\" was not a fusion weapon in the same sense as the rest of the \"Castle\" series. Even though it used lithium fuel for fission boosting, the principal reaction material in the second stage was uranium and plutonium. Similar to the Teller-Ulam configuration, a nuclear fission explosion was used to create high temperatures and pressures to compress a second fissionable mass. This would have otherwise been too large to sustain an efficient reaction if it were triggered with conventional explosives. This experiment was intended to develop intermediate yield weapons for expanding the inventory (around 1-2 Mt vs. 4-8).\n\nMany fusion or thermonuclear weapons generate much, or even most, of their yields from fission. Although the U-238 isotope of uranium will not sustain a chain reaction, it still fissions when irradiated by the intense fast neutron flux of a fusion explosion. Because U-238 is plentiful and has no critical mass, it can be added in (in theory) almost unlimited quantities as a tamper around a fusion bomb, helping to contain the fusion reaction and contributing its own fission energy. For example, the fast-fission of the U-238 tamper contributed 77% (8.0 megatons) to the yield of the 10.4 Mt \"Ivy Mike\" explosion.\n\nThe most notable event of \"Operation Castle\" was the \"Castle Bravo\" test. The dry fuel for \"Bravo\" was 40% Li-6 and 60% Li-7. Only the Li-6 was expected to breed tritium for the deuterium-tritium fusion reaction; the Li-7 was expected to be inert. Yet J. Carson Mark, the head of the Los Alamos Theoretical Design Division, had speculated that \"Bravo\" could \"go big\", estimating that the device could produce an explosive yield as much as 20% more than had been originally calculated. It was discovered, because of the unexpected larger yield, that the Li-7 in the device also undergoes breeding that produces tritium. In practice, \"Bravo\" exceeded expectations by 150%, yielding 15 Mt — about 1,000 times more powerful than the \"Little Boy\" weapon used on Hiroshima. \"Castle Bravo\" remains to this day, the largest detonation ever carried out anywhere by the United States, and the fifth largest H-bomb detonation in the world.\n\nBecause \"Castle Bravo\" greatly exceeded its expected yield, JTF-7 was caught unprepared. Much of the permanent infrastructure on Bikini Atoll was heavily damaged. The intense thermal flash ignited a fire at a distance of on the island of Eneu (base island of Bikini Atoll). The ensuing fallout contaminated all of the atoll, so much so, that it could not be approached by JTF-7 for 24 hours after the test, and even then exposure times were limited. As the fallout spread downwind to the east, more atolls were contaminated by radioactive calcium ash from the incinerated underwater coral banks. Although the atolls were evacuated soon after the test, 239 Marshallese on the Utirik, Rongelap, and Ailinginae Atolls were subjected to significant levels of radiation. 28 Americans stationed on the Rongerik Atoll were also exposed. Follow-up studies of the contaminated individuals began soon after the blast as Project 4.1, and though the short-term effects of the radiation exposure for most of the Marshallese were mild and/or hard to correlate, the long-term effects were pronounced. Additionally, 23 Japanese fishermen aboard \"Daigo Fukuryū Maru\" were also exposed to high levels of radiation. They suffered symptoms of radiation poisoning, and one crew member died in September 1954.\n\nThe heavy contamination and extensive damage from \"Bravo\" significantly delayed the rest of the series. The rescheduling after \"Bravo\" was \"officially\" released on April 14, 1954. The \"Castle Romeo\" and \"Koon\" tests were complete by the time that this revision was published.\n\nAs \"Operation Castle\" progressed, the increased yields and fallout caused test locations to be reevaluated. While the majority of the tests were planned for barges near the sand spit of Iroij, some were moved to the craters of \"Bravo\" and \"Union\". In addition, \"Castle Nectar\" was moved from Bikini Atoll to the crater of \"Ivy Mike\" at Eniwetok for expediency, since Bikini was still heavily contaminated from the previous tests.\n\nThe final test in \"Operation Castle\" took place on May 14, 1954.\n\n\"Operation Castle\" was an unqualified success for the implementation of dry fuel devices. The \"Bravo\" design was quickly weaponized and is suspected to be the progenitor of the Mk-21 gravity bomb. The Mk-21 design project began on March 26, 1954 (just three weeks after \"Bravo\") with production of 275 weapons beginning in late 1955. \"Romeo\", relying on natural lithium, was rapidly turned into the Mk-17 bomb, the first deployable US H-bomb, and was available to strategic forces as an Emergency Capability weapon by mid-1954. Most of the \"Castle\" dry fuel devices eventually appeared in the inventory and ultimately grandfathered the majority of thermonuclear configurations.\n\nIn contrast, the Livermore-designed \"Koon\" was a failure. Using natural lithium and a heavily modified Teller-Ulam configuration, the test produced only 110 kiloton of an expected 1.5 megaton yield. While engineers at the Radiation Laboratory had hoped it would lead to a promising new field of weapons, it was eventually determined that the design allowed premature heating of the lithium fuel, thereby disrupting the delicate fusion conditions.\n\n\n"}
{"id": "50901060", "url": "https://en.wikipedia.org/wiki?curid=50901060", "title": "Paolo Del Buono", "text": "Paolo Del Buono\n\nPaolo Del Buono (1625-1659) was an Italian scientific instrument maker.\n\nA Florentine disciple of Famiano Michelini (1604-1665), Paolo Del Buono received his doctorate from the University of Pisa in 1649. In 1655, he went to Germany to enter the service of Ferdinand III (Emperor from 1637 to 1657) and was appointed director of the Imperial Mint. During his stay, with his student Geminiano Montanari (1633-1687), he visited the imperial mines in the Carpathian mountains and invented a method of extracting water. Del Buono performed wide-ranging research in physics and experimental science. Paolo and his brother Candido Del Buono (1618-1676) both belonged to the Accademia del Cimento, with whom Paolo corresponded from Germany.\n\nHe is also noted for an experiment in 1657 which showed the incompessibility of water where water compressed in a gold shell by a screw seeped through pores in the gold, and for introducing into Tuscany an Egyptian method of raising chickens whereby the eggs are hatched by gradually introducing heat to them.\n\n"}
{"id": "7476793", "url": "https://en.wikipedia.org/wiki?curid=7476793", "title": "Psychology and Alchemy", "text": "Psychology and Alchemy\n\nPsychology and Alchemy is Volume 12 in \"The Collected Works of C. G. Jung\", a series of books published by Princeton University Press in the U.S. and Routledge & Kegan Paul in the U.K. It is study of the analogies between alchemy, Christian dogma, and psychological symbolism.\n\nAlchemy is central to Jung's hypothesis of the collective unconscious. This book begins with an outline of the process and aims of psychotherapy as seen by Jung. It then moves on to work out the analogies mentioned above and his own understanding of the analytic process. Jung reminds us of the dual nature of alchemy, comprising both the chemical process and a parallel mystical component. He also discusses the seemingly deliberate mystification of the alchemists. Finally, in using the alchemical process to provide insights into individuation, Jung emphasises the importance of alchemy in relating to us the transcendent nature of the psyche.\n\nDetailed abstracts of each chapter are available online.\n\nIn this book, Jung argues for a reevaluation of the symbolism of Alchemy as being intimately related to the psychoanalytical process. Using a cycle of dreams of one of his patients he shows how the symbols used by the Alchemists occur in the psyche as part of the reservoir of mythological images drawn upon by the individual in their dream states. Jung draws an analogy between the Great Work of the Alchemists and the process of reintegration and individuation of the psyche in the modern psychiatric patient.\n\nIn drawing these parallels Jung reinforces the universal nature of his theory of the archetype and makes an impassioned argument for the importance of spirituality in the psychic health of the modern man. Lavishly illustrated with images, drawings and paintings from Alchemy and other mythological sources including Christianity the book is another example of Jung's immense erudition and fascination with the eso- and exoteric expressions of spirituality and the psyche in religion and mysticism.\n\nInfluenced by pioneering work by Ethan Allen Hitchcock and Herbert Silberer (who was in turn influenced by Jung), \"Psychology and Alchemy\" is a seminal work of reevaluation of a forgotten system of thought which did much to revitalise interest in Alchemy as a serious force in Western philosophical and esoteric culture.\n\nAlso interesting about this book is that the patient whose dreams are being analyzed in the second section is the physicist Wolfgang Pauli, who would go on to collaborate with Jung on such ideas as the acausal connection principle of synchronicity. The dreams are interpreted as a series to elucidate the meanings of recurring motifs and symbols, with the series culminating in the vision of a 'world clock', which is actually several clocks on different planes operating on different scales and colours as a symbol of Pauli's unconscious apprehension of some grand cosmic order. Three of the best of these dreams were also mentioned by Jung in his Terry lectures \"Psychology of Religion\".\n\nThe fundamental thesis Jung is advancing about the relationship between Alchemy and Psychology is that for pre-scientific humans there is not a sharp distinction between subject and object and thus this leads them to unconsciously project their own inner states onto external objects (especially objects that are mostly unknown to them), so a reflective analysis of alchemical symbols becomes revelatory about the unconscious psychic life of this time period. Prior to this rational segregation of experience the world was a totally different one, phenomenologically, as people did not distinguish between the qualities of the object they were perceiving and their own values, emotions, and beliefs. It is partly for this reason that the alchemists cannot say aloud exactly what the philosopher's stone really 'is' and why there are so many different symbols for the work.\n\nFor the alchemist trying to understand matter and develop base metals into their purest form, gold, substances are grouped as being alike based on their perceived value. Jung documents as these alchemists collectively come to understand that they themselves must embody the change they hope to effect within their materials: for instance, if they hope to achieve the philosopher's stone that can redeem 'base' or 'vulgar' metals, then the alchemist too must become a redeemer figure. It became apparent to the alchemists that they were trying to redeem nature as Christ had redeemed man, hence the identification of the \"Lapis Philosophorum\" with Christ the Redeemer. The Opus (work) of alchemy, viewed through this interpretation, becomes a symbolic account of the fundamental process the human psyche undergoes as it re-orients its value system and creates meaning out of chaos. The opus beginning with the nigredo (blackening, akin to depression or nihilistic loss of value) in order to descend back into the manipulable \"prima materia\" and proceeding through a process of spiritual purification that must unite seemingly irreconcilable opposites (the coniunctio) to achieve new levels of consciousness.\n\nJung sets out the central thesis of the book: that Alchemy draws upon a vast array of symbols, images and patterns drawn from the Collective Unconscious of the West. Jung defends his exploration of the Psyche and Soul against various critics who have accused him of being both religious and anti-religious depending on their point of view. He argues for a deeper understanding of the Western spiritual traditions e.g. Esoteric Christianity and Alchemy alongside an examination of the Eastern ones e.g. Buddhism, Hinduism etc. Jung diagnoses the spiritual laziness of the West in not truly embracing the Christian Myth as an inner journey of transformation. Alchemy, he argues, is a 'Western Yoga' which was designed to facilitate this. The book will begin with a description of a whole cycle of dreams described by an unnamed patient (to protect confidentiality) which will be interpreted in their archetypal and mythological sense by Jung. This is designed to illustrate the existence of Jung's theory of the Collective Unconscious and the psychological goal or Great Work of psychic and spiritual integration or wholeness through the individuation process. That affects the mind state.\n\nJung sets out his agenda and explains his method. The text that follows will contain several cycles of dreams recounted by a patient to a student of Jung. Each dream will be described and then analysed and interpreted with reference to Alchemical imagery and psychoanalytic theory. Jung is at pains to explain that the patient knew nothing of Jung's interpretations and so was not influenced in any way during the dream process.\n\nJung details an entire cycle of the patient's dreams, summarising the details of each then interpreting them in terms of their parallels with alchemical imagery to reveal their psychological content.\n\n\nIt is not without importance for us to appreciate the high value set upon the mandala, for it accords very well with the paramount significance of individual mandala symbols which are characterized by the same qualities of a ---so to speak---\"metaphysical\" (fn4 ...the term \"metaphysical:I am only using it figuratively, in the psychological sense, to characterize the peculiar statements made by dreams.) nature. Unless everything deceives us, they signify nothing less than a psychic centre of the personality not to be identified with the ego.\n\n\"The real mystery does not behave mysteriously or secretively; it speaks a secret language, it adumbrates itself by a variety of images which all indicate its true nature. I am not speaking of a secret personally guarded by someone, with a content known to its possessor, but of a mystery, a matter or circumstance which is \"secret,\" i.e., known only through vague hints but essentially unknown. The real nature of matter was unknown to the alchemist: he knew it only in hints. In seeking to explore it he projected the unconscious into the darkness of matter in order to illuminate it. In order to explain the mystery of matter he projected yet another mystery - his own psychic background -into what was to be explained: \"Obscurum per obscurius, ignotum per ignotius!\" This procedure was not, of course, intentional; it was an involuntary occurrence.\" (Part 3, Chapter 2.1)\n\n\"I am therefore inclined to assume that the real root of alchemy is to be sought less in philosophical doctrines than in the projections of individual investigators. I mean by this that while working on his chemical experiments the operator had certain psychic experiences which appeared to him as the particular behaviour of the chemical process. Since it was a question of projection, he was naturally unconscious of the fact that the experience had nothing to do with matter itself (that is, with matter as we know it today). He experienced his projection as a property of matter; but what he was in reality experiencing was his own unconscious. In this way he recapitulated the whole history of mankind's knowledge of nature... Such projections repeat themselves whenever man tries to explore an empty darkness and involuntarily fills it with living form.\" (Part 3, Chapter 2.1).\n\n\"When the alchemist speaks of Mercurius, on the face of it he means quicksilver (mercury), but inwardly he means the world-creating spirit concealed or imprisoned in matter. The dragon is probably the oldest pictoral symbol in alchemy of which we have documentary evidence. It appears as the Ouroboros, the tail-eater, in the Codex Marcianus, which dates from the tenth or eleventh century, together with the legend 'the One, the All'. Time and again the alchemists reiterate that the \"opus\" proceeds from the one and leads back to the one, that it is a sort of circle like a dragon biting its own tail. For this reason the \"opus\" was often called \"circulare\" (circular) or else \"rota\" (the wheel). Mercurius stands at the beginning and end of the work: he is the \"prima materia\", the \"caput corvi\", the \"nigredo\"; as dragon he devours himself and as dragon he dies, to rise again in the \"lapis\". He is the play of colours in the \"cauda pavonis\" and the division into the four elements. He is the hermaphrodite that was in the beginning, that splits into the classical brother-sister duality and is reunited in the \"coniunctio\", to appear once again at the end in the radiant form of the \"lumen novum\", the stone. He is metallic yet liquid, matter yet spirit, cold yet fiery, poison and yet healing draught - a symbol uniting all the opposites.\" (Part 3, Chapter 3.1).\n\n\"Now, all these myth-pictures represent a drama of the human psyche on the further side of consciousness, showing \"man as both the one to be redeemed and the redeemer\". The first formulation is Christian, the second alchemical. In the first case man attributes the need of redemption to himself and leaves the work of redemption, the actual \"opus\", to the autonomous divine figure; in the latter case man takes upon himself the duty of carrying out the redeeming \"opus\", and attributes the state of suffering and consequent need of redemption to the \"anima mundi\" imprisoned in matter. In both cases redemption is a \"work\". In Christianity it is the life and death of the God-man which, by a unique sacrifice, bring about the reconciliation of man, who craves redemption and is sunk in materiality, with God. The mystical effect of the God-man's self-sacrifice extends, broadly speaking, to all men, though it is efficacious only for those who submit through faith or are chosen by divine grace; but in the Pauline acceptance it acts as an apocatastasis and extends also to non-human creation in general, which, in its imperfect state, awaits redemption like the merely natural man.\" (Part 3, Chapter 3.3).\n\n\"From this point of view, alchemy seems like a continuation of Christian mysticism carried on in the subterranean darkness of the unconscious... But this unconscious continuation never reached the surface, where the conscious mind could have dealt with it. All that appeared in consciousness were the symbolic symptoms of the unconscious process. Had the alchemist succeeded in forming any concrete idea of his unconscious contents, he would have been obliged to recognize that he had taken the place of Christ - or, to be more exact, that he, regarded not as ego but as self, had taken over the work of redeeming not man but God. He would then have had to recognize not only himself as the equivalent of Christ, but Christ as a symbol of the self. This tremendous conclusion failed to dawn on the medieval mind.\" (Part 3, Chapter 5.1).\n\n"}
{"id": "3634070", "url": "https://en.wikipedia.org/wiki?curid=3634070", "title": "Rib fracture", "text": "Rib fracture\n\nA rib fracture is a break in a rib bone. This typically results in chest pain that is worse with breathing in. Bruising may occur at the site of the break. When several ribs are broken in several places a flail chest results. Potential complications include a pneumothorax, pulmonary contusion, and pneumonia.\nRib fractures usually occur from a direct blows to the chest such as during a motor vehicle collision or from a crush injury. Coughing or metastatic cancer may also result in a broken rib. The middle ribs are most commonly fractured. Fractures of the first or second ribs are more likely to be associated with complications. Diagnosis can be made based on symptoms and supported by medical imaging.\nPain control is an important part of treatment. This may include the use of paracetamol (acetaminophen), NSAIDs, or opioids. A nerve block may be another option. While fractured ribs have been wrapped, this may increase complications. In those with a flail chest, surgery may improve outcomes. They are a common injury following trauma.\n\nThis typically results in chest pain that is worse with breathing in. Bruising may occur at the site of the break.\n\nWhen several ribs are broken in several places a flail chest results. Potential complications include a pneumothorax, pulmonary contusion, and pneumonia.\n\nRib fractures can occur with or without direct trauma during recreational activity. Cardiopulmonary resuscitation (CPR) has also been known to cause thoracic injury, including but not limited to rib and sternum fractures. They can also occur as a consequence of diseases such as cancer or rheumatoid arthritis. While for elderly individuals a fall can cause a rib fracture, in adults automobile accidents are a common event for such an injury.\n\nSigns of a broken rib may includ:\n\nPlain X-rays often pick up displaced fractures but often miss undisplaced fractures. CT scanning is generally able to pick up both types of fractures.\n\nBecause children have more flexible chest walls than adults do, their ribs are more likely to bend than to break; therefore the presence of rib fractures in children is evidence of a significant amount of force and may indicate severe thoracic injuries such as pulmonary contusion. Rib fractures are also a sign of more serious injury in elderly people.\n\nThere is no specific treatment for rib fractures, but various supportive measures can be taken. In simple rib fractures, pain can lead to reduced movement and cough suppression; this can contribute to formation of secondary chest infection. Flail chest is a potentially life-threatening injury and will often require a period of assisted ventilation. Flail chest and first rib fractures are high-energy injuries and should prompt investigation of damage to underlying viscera (e.g., lung contusion) or remotely (e.g., cervical spine injury). Spontaneous fractures in athletes generally require a cessation of the cause, e.g., time off rowing, while maintaining cardiovascular fitness.\n\nNerve blocks that may be used to help with pain related to rib fractures include epidural anesthesia, paravertebral block, and serratus anterior plane block.\n\nTreatment options for internal fixation/repair of rib fractures include:\n\n"}
{"id": "12121657", "url": "https://en.wikipedia.org/wiki?curid=12121657", "title": "ScienceBlogs", "text": "ScienceBlogs\n\nScienceBlogs is an invitation-only blog network and virtual community that operated initially for a little less than twelve years, from 2006 to 2017. It was created by Seed Media Group to enhance public understanding of science. Each blog had its own theme, speciality and author(s) and was not subject to editorial control. Authors included active scientists working in industry, universities and medical schools as well as college professors, physicians, professional writers, graduate students, and post-docs. On 24 January 2015, 19 of the blogs had seen posting in the past month. 11 of these had been on ScienceBlogs since 2006. ScienceBlogs shut down at the end of October 2017. In late August of 2018, the webiste’s front page displayed a notice suggesting it was about to become active once again.\n\nScienceBlogs was launched in January 2006 with 15 blogs on the network. For the launch blogs, Seed invited some of the best-known independent science bloggers and allowed them to blog about whichever subjects they wished. Revenue was generated through advertisements sold to companies who wished to attract \"bright, curious consumers who buy products like automobiles, books, cellphones, computers, liquor, music and watches.\" \n\nAs a result of the free rein given to bloggers and the incentive to increase traffic, bloggers on the network often discussed hot topics such as politics and religion in addition to science. These topics frequently incited heated arguments in the comment threads and bloggers on the network sometimes got into arguments with each other over a series of posts.\n\nScienceBlogs and Seed received some notable awards at the end of their first year of activity, including the 2006 UTNE Independent Press Award for Best Science/Technology Coverage being granted to Seed, in large part due to the success of ScienceBlogs. Additionally, two blogs on the network received Weblog awards: Pharyngula for Best Science Blog and Respectful Insolence for Best Medical/Health Issues Blog.\n\nThe creators of ScienceBlogs expanded their collection of hosted blogs in three major waves, supplemented by individual additions along the way. Some of the most trafficked blogs included Pharyngula, Respectful Insolence, Good Math Bad Math, Deltoid, Cognitive Daily, Living the Scientific Life (Scientist, Interrupted) and On Becoming a Domestic and Laboratory Goddess.\n\nAccording to Technorati, , ScienceBlogs had an \"authority\" of 9,581 and its number of inbound links ranks it 37th among blogs worldwide. , Quantcast charts it as having over 1.1 million monthly unique visitors, 65% of whom are from the United States.\n\n, ScienceBlogs hosted 75 blogs dedicated to various fields of research. In April 2011, ScienceBlogs was taken over by National Geographic. While Seed would still maintain ownership of the site, National Geographic would acquire editorial control and responsibility for advertising sales on the site.\n\nScienceBlogs launched a German language edition of the site, ScienceBlogs.de, in 2008 in partnership with Hubert Burda Media. As of 7 December 2010, the site hosted 35 blogs. ScienceBlogs Brazil debuted in March 2009 with 23 Portuguese language blogs.\n\nIn June 2010, ScienceBlogs started a blog which was sponsored by PepsiCo and was to be written by their employees. This led to backlash by many of the bloggers on ScienceBlogs who considered this to be an unethical mix of advertising and journalism, and the PepsiCo blog was withdrawn from ScienceBlogs. This affair was informally named \"PepsiGate\". By the middle of July approximately a quarter of the bloggers had left ScienceBlogs. Subsequently, some bloggers such as PZ Myers of Pharyngula announced they were going on strike as part of a general feeling that the people running Seed had failed to respond to concerns surrounding the incident. Seed Media responded by killing off \"Food Frontiers\", the Pepsico sponsored blog, but that didn't stop the defections. According to PZ Myers, \"The ship is sinking\". A writer at the \"New York Times Magazine\" reviewed the incident and commented, \"ScienceBlogs has become Fox News for the religion-baiting, peak-oil crowd.\" Some other science blogging networks were launched, including scientopia.org, scienceseeker.org and one hosted by \"The Guardian\". In early 2015, however, eleven of the network's 2006 founding-generation blogs were still active, including Myers's.\n\nOn 14 October 2017, astrophysics blogger Steinn Sigurðsson publicly revealed that ScienceBlogs was due to be shut down, and David Gorski, author of the \"Respectful Insolence\" blog under his pseudonym Orac, stated that ScienceBlogs had \"barely existed as an entity for a few years\".\n\nIn late August of 2018, a note appeared on the home page which said that ScienceBlogs was now part of the Science 2.0 family and that plans were in place to make the site active once again. \n\n\nScienceBlogs consisted of ten channels, or categories, of blog entries. Each blog author decided what channel his or her individual post belongs in, and each post was indexed accordingly on the main page. The categories were:\n\n\n"}
{"id": "9673027", "url": "https://en.wikipedia.org/wiki?curid=9673027", "title": "Sociologists for Women in Society", "text": "Sociologists for Women in Society\n\nSociologists for Women in Society (SWS) is an international organization of social scientists--students, faculty, practitioners, and researchers--working together to improve the position of women within sociology and society in general.\n\nIn 1969, several hundred women gathered at a \"counter-convention\" at Glide Memorial Church rather than attend the ASA meetings at the Hilton Hotel. Sharing feelings of insecurity and stories of initially mystifying experiences as graduate students and faculty, and encouraging each other with applause, they came to see that some of the stresses in being sociologists were not idiosyncratic, but part of the experience of being women. Later that year, some 20 founding women met to build an organization and network. Although SWS was created to redress the plight of women sociologists, SWS has become an organization that also focuses on improving the social position of women in society through feminist sociological research and writing.\n\nSWS holds annual meetings and publishes the academic journal \"Gender & Society\".\n\n\n\n"}
{"id": "177976", "url": "https://en.wikipedia.org/wiki?curid=177976", "title": "Soyuz 2", "text": "Soyuz 2\n\nSoyuz 2 (, Union 2) was an uncrewed spacecraft in the Soyuz family intended to be the target of a docking maneuver by the manned Soyuz 3 spacecraft. It was intended to be the first docking of a manned spacecraft in the Soviet space program. Although the two craft approached closely, the docking did not take place and the first successful Soviet docking of manned spacecraft took place in the joint Soyuz 4 and Soyuz 5 mission.\n\n\n\n"}
{"id": "21593473", "url": "https://en.wikipedia.org/wiki?curid=21593473", "title": "Swiss 1.2-metre Leonhard Euler Telescope", "text": "Swiss 1.2-metre Leonhard Euler Telescope\n\nLeonhard Euler Telescope, or the Swiss EULER Telescope, is a national, fully automatic reflecting telescope, built and operated by the Geneva Observatory. It is located at an altitude of at ESO's La Silla Observatory site in the Chilean Norte Chico region, about 460 kilometers north of Santiago de Chile. The telescope, which saw its first light on 12 April 1998, is named after Swiss mathematician Leonhard Paul Euler.\n\nThe Euler telescope uses the CORALIE instrument to search for exoplanets. In addition, the telescope uses the multi-purpose EulerCam (ecam), a high precision photometry instrument, and a smaller, piggyback mounted telescope, called \"Pisco\". Its first discovery was a planet in orbit around Gliese 86, determined to be a hot Jupiter with an orbital period of only 15.8 earth days and about four times the mass of Jupiter. Since then, many other exoplanets have been discovered or examined in follow-up observations.\n\nTogether with the Mercator Telescope, Euler was part of the Southern Sky extrasolar Planet search Programme, which has discovered numerous extrasolar planets. It has also been frequently employed for follow-up characterization to determine the mass of exoplanets discovered by the Wide Angle Search for Planets, SuperWASP.\n\nThe \"CORALIE spectrograph\" is an echelle type spectrograph used for astronomy and was commissioned at the Euler Telescope in April 1998. The instrument performs doppler spectroscopy, that is it measures the Doppler effect on a star's electromagnetic spectrum caused by the gravitational tug of an exoplanet orbiting around it. The spectrograph participates in the Southern Sky extrasolar Planet search Programme.\n\nDoppler spectroscopy, also known as \"radial velocity\" or \"wobble\" method, is an indirect detection method as it only observes the star's spectrum and not the planet itself. It differs from the transit method used by the space-based Kepler mission and ground-based SuperWASP and Next-Generation Transit Survey and can therefore be complementary to their observations. This is because the size of an exoplanet can be estimated using the transit method, while Doppler spectroscopy is used to estimate its mass. By combining the measured size and mass from both methods, it can be determined whether the observed exoplanet is gaseous or rocky.\n\nThe ELODIE spectrograph was a device similar to CORALIE\n\nThe resolution of CORALIE is fixed at R = 50,000 with a 3 pixel sampling. The detector CCD is 2k X 2k with a 15 micrometer pixel size.\n\nFive planetary object have been discovered using CORALIE along with several confirmations of discoveries by other programs.\n\n\n"}
{"id": "5712148", "url": "https://en.wikipedia.org/wiki?curid=5712148", "title": "Tehran School of Political Science", "text": "Tehran School of Political Science\n\nThe Tehran School of Political Science ( \"Madraseh-ye olum-e siyasi\"), was one of the first modern institutions of higher education in Iran at the turn of the twentieth century. Most of the nation's political elite graduated from the school.\n\nThe School of Political Science was founded in 1899 by Hassan Pirnia. It was run by the Ministry of Foreign Affairs. It later merged with the School of Law (\"Madreseh-ye alee-e hoquq\"), which had been established in 1918, to form the Faculty of Law and Political Science of the University of Tehran in 1933.\n\nMany of the school's faculty and alumni later became ministers and political figures in Iran. Notable examples are:\n\n"}
{"id": "50628620", "url": "https://en.wikipedia.org/wiki?curid=50628620", "title": "Timothy John O'Brien", "text": "Timothy John O'Brien\n\nTimothy John O'Brien (born 31 March 1964) is a British astronomer, currently working at the University of Manchester as Professor of Astrophysics. He often appears on the BBC.\n\nHe was born in Littleborough, Greater Manchester. He grew up in Castleton, Greater Manchester in the Metropolitan Borough of Rochdale. He has a younger sister (born 1965) and a younger brother (born 1967). He attended school in Rochdale. He studied Physics and Astrophysics at University College London. He studied for a PhD at the University of Manchester from 1985-88.\n\nHe taught at the University of Liverpool in the 1990s. He began working at the University of Manchester in 1999 where he is currently Associate Director of the Jodrell Bank Centre for Astrophysics. He is also Director of Teaching & Learning in the University's School of Physics & Astronomy. From 2009-2015, he taught the first year undergraduate course in Astrophysics.\n\nHis research is primarily in the area of novae (thermonuclear explosions on white dwarf stars in binary star systems) and includes both theoretical work and observations using telescopes around the world and in space working across the electromagnetic spectrum. \n\nHe has appeared on \"Stargazing Live\" on BBC Two and \"The Infinite Monkey Cage\" on BBC Radio 4.\n\nHe is married to Professor Teresa Anderson (born 1 December 1962). He lived for a time in Macclesfield. He lives in south Manchester.\n \n"}
{"id": "20936730", "url": "https://en.wikipedia.org/wiki?curid=20936730", "title": "Veneer theory", "text": "Veneer theory\n\nVeneer theory is a term coined by Dutch primatologist Frans de Waal to label the Hobbesian view of human morality that he criticizes throughout his work. Although he criticizes this view in earlier works, the term in this form is introduced in his 2005 book \"Our Inner Ape\", denoting a concept that he rejects, namely that human morality is \"a cultural overlay, a thin veneer hiding an otherwise selfish and brutish nature\". The idea of the veneer theory goes back to Thomas Henry Huxley and has more recently been advocated by biologists like George C. Williams.\n\nAs evidenced by de Waals' characterisation of this theory as \"Hobbesian\", one of the earliest and most influential thinkers criticized by him for having popularized this view is Thomas Hobbes:\n\nA few centuries later, Thomas Henry Huxley developed the idea that moral tendencies are not part of the human nature, and so our ancestors became moral by choice, not by evolution. Thus it represents a discrepancy in Huxley's Darwinian conviction. Social behavior is explained by this theory as a veneer of morality. This dualistic point of view separates humans from animals by rejecting every connection between human morality and animal social tendencies.\nGeorge C. Williams, as another advocate of the veneer theory, sees morality as \"an accidental capability produced, in its boundless stupidity, by a biological process that is normally opposed to the expression of such a capability\".\n\nPsychologist Abraham Maslow argued that humans no longer have instincts because we have the ability to override them in certain situations. He felt that what is called instinct is often imprecisely defined, and really amounts to strong \"drives\". For Maslow, an instinct is something which cannot be overridden, and therefore while the term may have applied to humans in the past, it no longer does.\n\nRichard Dawkins seems to condone the veneer theory when he writes:\n\nSome argue that veneer theory presents a false dichotomy; the adaptations of a cultural overlay of pseudo morals, and de Waal's biologically-based morals might coexist, and are both evolutionarily advantageous. \n\nDe Waal criticizes the veneer theory and sees our morality as a direct outgrowth of the social instincts human beings share with other animals. He argues that the advocates of the veneer theory don't have any indications or empirical evidence which support the theory, and that it is highly unlikely that humans can deny their genes and improve morality merely by choice. As an example he compares Huxley's theory with a school of piranhas deciding to become vegetarian.\nDe Waal bases his argument against the veneer theory on observations of behavior of humanity's relatives in his long work as primatologist. \"Building blocks of morality\" can be already observed in other primates, and by the principle of parsimony, it is quite possible that some sort of morality is evolutionarily ancient and shared with our ancestors. De Waal assumes that the evolutionary origins lie in emotions we share with other animals, \"e.g.\" empathy.\nHuman morality is according to him a product of social evolution, and instead of Huxley's theory, this point of view a continuity between human morality and animal social tendencies—is unitary and thus more compatible with the evolutionary theory.\nOther critics of the veneer theory are Edward Westermarck and E. O. Wilson.\n\nPsychologist Christopher Ryan and psychiatrist Cacilda Jethá also express similar concerns in their book Sex at Dawn, where they criticize what they call the \"neo-Hobbesian\" narrative of human nature:\n\nThey also cite Stephen Jay Gould as a critic of this view:\n\n"}
{"id": "970600", "url": "https://en.wikipedia.org/wiki?curid=970600", "title": "William H. Dana", "text": "William H. Dana\n\nWilliam Harvey \"Bill\" Dana (November 3, 1930 – May 6, 2014) was an American aeronautical engineer, U.S. Air Force pilot, NASA test pilot, and astronaut in the X-20 Dyna-Soar, and North American X-15 programs.\n\nDana was born in Pasadena, California on November 3, 1930. He received a Bachelor of Science degree from the United States Military Academy in 1952 and served four years as a pilot in the United States Air Force. He joined NASA on October 1, 1958, after receiving a Master of Science degree in Aeronautical Engineering from the University of Southern California.\n\nDana married to his wife, Judi, in 1962, and they had four children.\n\nFrom 1960 through 1962 he was a pilot astronaut in the U.S. Air Force X-20 Dyna-Soar program. That program was canceled before the vehicle flew, but Dana later tested several other lifting-body space vehicle projects. He made one of the earliest flights in the plywood M2-F1, and flew the HL-10, the M2-F3, and the X-24B. He made the highest-ever flight in a lifting body, to 90,303 feet, in the HL-10. He also made the final powered flight of a lifting body, in the X-24B (1975).\n\nDana began as an engineer on the North American X-15 program. He progressed to chase pilot, and finally as project pilot on the hypersonic research aircraft. He flew the rocket-powered vehicle 16 times, reaching a top speed of 3,897 mph. His peak altitude of 307,000 feet (nearly 59 miles high) technically qualified him for the Astronaut Badge, although he was not formally recognized as an astronaut until 2005. He was the pilot on the final (199th) flight of the 10-year program.\n\nIn the late 1960s and in the 1970s, Dana was a project pilot on the manned lifting body program, which flew several versions of the wingless vehicles and produced data that helped in development of the Space Shuttle. He completed one NASA M2-F1, nine Northrop HL-10, nineteen Northrop M2-F3 and two Martin Marietta X-24B flights, for a total of 31 lifting body missions.\n\nDana was Chief Engineer at NASA's Dryden Flight Research Center, Edwards Air Force Base, California, from 1993 until 1998, when he retired after almost 40 years of distinguished service to NASA. Formerly an aerospace research pilot, Dana flew the F-100 variable stability research aircraft and the Advanced Fighter Technology Integration/F-16 aircraft, as well as many others.\n\nBefore his assignment as Chief Engineer, he was Assistant Chief of the Flight Operations Division, a position he assumed after serving since 1986 as Chief Pilot. He was also a project pilot on the F-15 HIDEC (Highly Integrated Digital Electronic Control) research program, and a co-project pilot on the F-18 Hornet High Angle of Attack research program.\n\nAs a research pilot, Dana was involved in some of the most significant aeronautical programs carried out at Dryden. For his service as a flight research pilot, he received NASA Distinguished Service Medal in 1997. In 2000 he was awarded the Milton O. Thompson Lifetime Achievement Award by the Dryden Flight Research Center.\n\nDana died in Phoenix, Arizona, on May 6, 2014, following a long struggle with Parkinson's disease. He was 83 years of age.\n\nFor his contributions to the lifting body program, Dana received the NASA Exceptional Service Medal. In 1976 he received the Haley Space Flight Award from the American Institute of Aeronautics and Astronautics (AIAA) for his research work on the M2-F3 lifting body control systems.\n\nA member of the Society of Experimental Test Pilots, Dana is the author of several technical papers. In 1993, he was inducted into the Aerospace Walk of Honor.\n\nOn August 23, 2005, NASA officially conferred on Dana his Astronaut Wings.\n\n\n"}
{"id": "3524523", "url": "https://en.wikipedia.org/wiki?curid=3524523", "title": "XMD", "text": "XMD\n\nXMD is a classical molecular dynamics software designed to\nsimulate problems related to materials science. The code was\ndeveloped by Jon Rifkin of University of Connecticut and is being\ndistributed under GNU General Public License.\n\nSource code is available in C and can be compiled using POSIX thread\nfunctions to take advantage of multi-CPU computers.\n\n\n\n"}
