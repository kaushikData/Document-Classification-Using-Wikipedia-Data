{"id": "27334606", "url": "https://en.wikipedia.org/wiki?curid=27334606", "title": "Apusiaajik Glacier", "text": "Apusiaajik Glacier\n\nApusiaajik Glacier is a tidewater glacier on the uninhabited Apusiaajik Island in the Sermersooq municipality on the southeastern shore of Greenland. \n\nDuring summer, the glacier edge is a popular tourist destination for boat trips from Tasiilaq and Kulusuk. During winter it is possible to reach the front of the glacier crossing the frozen Torsuut Tunoq sound on foot or on snowmobile.\n"}
{"id": "43790336", "url": "https://en.wikipedia.org/wiki?curid=43790336", "title": "Aqueous geochemistry", "text": "Aqueous geochemistry\n\nAqueous geochemistry studies the role of various elements in watersheds, including copper, sulfur, and mercury. Researchers in this field also study how elemental fluxes are exchanged through interactions between the atmosphere, the earth or soil (terrestrial interactions) and bodies of water (aquatic interactions).\n\nWork in the field of aqueous geochemistry has also studied the prevalence of rare earth elements, nuclear waste products, and hydrocarbons.\n"}
{"id": "10848619", "url": "https://en.wikipedia.org/wiki?curid=10848619", "title": "Arcas (crater)", "text": "Arcas (crater)\n\nArcas is a crater on Jupiter's moon Callisto measuring across. This an example of a central pit impact crater. A smaller crater near Arcas is called Ginandi. The crater is named after Arcas, the son of Callisto in Greek mythology.\n"}
{"id": "39740560", "url": "https://en.wikipedia.org/wiki?curid=39740560", "title": "Beall's List", "text": "Beall's List\n\nBeall's List was a list of predatory open-access publishers maintained by University of Colorado librarian Jeffrey Beall. The list aimed to document open-access publishers who did not perform real peer review, effectively publishing any article as long as the authors pay the open access fee. Originally started as a personal endeavor in 2008, Beall's List became a widely followed piece of work by the mid 2010s. Its influence led some publishers on the list to threaten defamation lawsuits against Beall, as well as lodge official complaints against Beall's work to the University of Colorado. As a result, Beall deactivated his blog and the list in January 2017.\n\nThe death of Beall's List was cited by some as a tragedy, and successors have set out to continue Beall's work.\n\nBeall first became interested in so-called predatory open-access journals (a term he coined) in 2008, when he started to receive numerous requests from dubious journals to serve on their editorial boards. He said that he \"immediately became fascinated because most of the e-mails contained numerous grammatical errors.\" Starting in 2008, he maintained a well-known and regularly updated list of what he stated were \"potential, possible, or probable predatory scholarly open-access publishers\". In 2011, Beall's list had 18 publishers on it; by December 29, 2016, this number had grown to 923.\n\nIn February 2013, the open-access publisher Canadian Center for Science and Education sent a letter to Beall stating that Beall's inclusion of their company on his list of questionable open-access publishers amounted to defamation. The letter also stated that if Beall did not remove this company from his list, they would subject him to \"civil action\".\n\nIn 2013, the OMICS Publishing Group threatened to sue Beall for $1 billion for his \"ridiculous, baseless, [and] impertinent\" inclusion of them on his list, which \"smacks of literal unprofessionalism and arrogance\". An unedited sentence from the letter read: \"Let us at the outset warn you that this is a very perilous journey for you and you will be completely exposing yourself to serious legal implications including criminal cases lunched against you in INDIA and USA.\" Beall responded that the letter was \"poorly written and personally threatening\" and expressed his opinion that the letter \"is an attempt to detract from the enormity of OMICS's editorial practices\". OMICS' lawyers stated that damages were being pursued under section 66A of India's Information Technology Act, 2000, which makes it illegal to use a computer to publish \"any information that is grossly offensive or has menacing character\" or to publish false information. The letter stated that three years in prison was a possible penalty, although a U.S. lawyer said that the threats seemed to be a \"publicity stunt\" that was meant to \"intimidate\".\n\nIn 2013, \"Science\" correspondent John Bohannon submitted 304 fake scientific articles to various open access journals, many of which were published by publishers on Beall's List. Among these publishers that completed the review process, 82% accepted the paper. Bohannon stated \"the results show that Beall is good at spotting publishers with poor quality control\". Beall stated that the results support his claim to be identifying \"predatory\" publishers. However, the remaining 18% of publishers identified by Beall as predatory rejected the fake paper, leading science communicator Phil Davis to state \"That means that Beall is falsely accusing nearly one in five\".\n\nOn January 15, 2017, the entire content of Beall's \"Scholarly Open Access\" website was removed, along with Beall's faculty page on the University of Colorado's website. The removal was first noticed on social media, with speculation on whether the removal was due to migration of the list to the stewardship of Cabell's International. The company later denied any relationship, and its vice president of business development declared that Beall \"was forced to shut down blog due to threats and politics\". The University of Colorado also declared that the decision to take down the list was a personal decision from Beall. Beall later wrote that he had taken down his blog because of pressure from the University of Colorado, which threatened his job security. Beall's supervisor, Shea Swauger, wrote that the university had supported Beall's work and had not threatened his academic freedom. A demand by Frontiers Media to open a research misconduct case against Beall, to which the University of Colorado acquiesced, is reported as the immediate reason for Beall to take down the list. The university's investigation was closed with no findings. Beall has not reactivated the list.\n\nSince \"Beall's List\" closed, similar lists have been started by others, including CSIR-Structural Engineering Research Centre, and an anonymous group at \"Stop Predatory Journals\". Cabell's International, a company that offers scholarly publishing analytics and other scholarly services, has also offered both a black list and a white list for subscription on their website.\n\nBeall applied a diverse set of criteria before including a publisher or journal on his lists. Examples included:\n\nThe list's 82% accuracy rate in the \"Who's Afraid of Peer Review?\" sting operation led Phil Davis to state that \"Beall is falsely accusing nearly one in five as being a 'potential, possible, or probable predatory scholarly open access publisher' on appearances alone.\" He wrote that Beall \"should reconsider listing publishers on his 'predatory' list until he has evidence of wrongdoing. Being mislabeled as a 'potential, possible, or probable predatory publisher' by circumstantial evidence alone is like the sheriff of a Wild West town throwing a cowboy into jail just 'cuz he's a little funny lookin.' Civility requires due process.\"\n\nJoseph Esposito wrote in \"The Scholarly Kitchen\" that he had been following some of Beall's work with \"growing unease\", and that Beall's \"broader critique (really an assault) of Gold OA and those who advocate it\" had \"crossed the line\".\n\nCity University of New York librarians Monica Berger and Jill Cirasella wrote that his views were biased against open-access journals from less economically developed countries. Berger and Cirasella argued that \"imperfect English or a predominantly non-Western editorial board does not make a journal predatory\". They stated that \"the criteria he uses for his list are an excellent starting point for thinking about the hallmarks of predatory publishers and journals,\" and suggested that \"given the fuzziness between low-quality and predatory publishers, whitelisting, or listing publishers and journals that have been vetted and verified as satisfying certain standards, may be a better solution than blacklisting.\"\n\nRick Anderson, associate dean in the J. Willard Marriott Library, University of Utah, challenged the term \"predatory open access publishing\" itself: \"what do we mean when we say 'predatory,' and is that term even still useful?... This question has become relevant because of that common refrain heard among Beall's critics: that he only examines one kind of predation—the kind that naturally crops up in the context of author-pays OA.\" Anderson suggested that the term \"predatory\" be retired in the context of scholarly publishing: \"It's a nice, attention-grabbing word, but I'm not sure it's helpfully descriptive... it generates more heat than light.\" In its place, he proposed the term \"deceptive publishing\".\n\nArchival versions\n\nUpdated versions\n"}
{"id": "52720191", "url": "https://en.wikipedia.org/wiki?curid=52720191", "title": "Bill Blevin", "text": "Bill Blevin\n\nWilliam Roderick \"Bill\" Blevin AM DSc FAA FTSE FAIP FIP (born 31 October 1929, Inverell, New South Wales) is an Australian physicist. He was elected a Fellow of the Australian Academy of Science in 1985 and appointed a Member of the Order of Australia in 1989.\n"}
{"id": "21689101", "url": "https://en.wikipedia.org/wiki?curid=21689101", "title": "Bocas del Toro Research Station", "text": "Bocas del Toro Research Station\n\nThe Bocas del Toro Research Station (BRS) is a field station of the Smithsonian Tropical Research Institute (STRI) on Panama’s western Caribbean coast, is a platform for both marine and terrestrial biodiversity research. The station hosts a diverse group of scientists from more than 20 countries, every year.\n\nActivities at the station contribute to the Smithsonian Institution’s primary mission: the increase and diffusion of knowledge. Visiting scientists are engaged in research on the biodiversity, ecology, paleontology and archaeology of the Bocas del Toro region. Educational and outreach activities range from hosting K-12 school groups, to specialized training for international graduate students. \n\nFounded in 1998, the BRS campus has provided field accommodation since 2002 and a fully operational research laboratory since 2003. The facilities now include a running seawater system, a new dock, boat ramp, and additional support facilities, as well as two houses to accommodate visiting researchers. The BRS is arguably the preeminent field station in the Caribbean.\nVisiting scientists hold lectures that are open to the public.\n\nOutreach and education at the Bocas del Toro Research Station spans a range of programs targeting K-12 students, university undergraduates, graduate students and young professionals. K-12 education includes visits to local schools, some of which are in remote mountainous locations, and student visits to the BRS. The station also offers a training workshop for local K-12 teachers every year, an organized beach clean-up for Earth day, and other activities for local residents.\n\nThey hold an annual Environmental Fair.\n\nThe Bocas biodiversity database provides a list of plants and animals that are known to occur in the Bocas del Toro Archipelago, the Bahía Almirante, Laguna de Chiriquí, and the surrounding mainland. Users can search for a particular term or browse the database by group. Some photographs, videos, maps and audio recordings are available.\n\n\n\n"}
{"id": "28329521", "url": "https://en.wikipedia.org/wiki?curid=28329521", "title": "Characteristic length", "text": "Characteristic length\n\nIn physics, a characteristic length is an important dimension that defines the scale of a physical system. Often, such a length is used as an input to a formula in order to predict some characteristics of the system.\n\nExamples:\n\nIn computational mechanics, a characteristic length is defined to force localization of a stress softening constitutive equation. The length is associated with an integration point. For 2D analysis, it is calculated by taking square root of the area. For 3D analysis, it is calculated by taking cubic root of the volume associated to the integration point.\n\nThe general formula for the characteristic length is the volume of a system divided by its surface:\n\nformula_1\n\nA typical use-case is calculating flow through circular and non-circular tubes, in order to examine flow conditions (i.e. the Reynolds number). In those cases, the characteristic length is the diameter of the pipe, or in case of non-circular tubes its hydraulic diameter formula_2:\n\nformula_3\n\nWhere formula_4is the cross-sectional area of the pipe and p its wetted perimeter. It is defined such that it reduces to a circular diameter of D for circular pipes.\n\nFor flow through a square duct with a side length of a, the hydraulic diameter formula_2is:\n\nformula_6\n\nFor a rectangular duct with side lengths a and b:\n\nformula_7\n\nFor free surfaces (such as in open-channel flow), the wetted perimeter includes only the walls in contact with the fluid.\n"}
{"id": "4172697", "url": "https://en.wikipedia.org/wiki?curid=4172697", "title": "Doping at the Olympic Games", "text": "Doping at the Olympic Games\n\nThis article is about the history of competitors at the Olympic Games using banned athletic performance-enhancing drugs.\n\nThe use of performance-enhancing tactics or more formally known as PEDs, and more broadly, the use of any external device to nefariously influence the outcome of a sporting event has been a part of the Olympics since its inception in Ancient Greece. One speculation as to why men were required to compete naked was to prevent the use of extra accoutrements and to keep women from competing in events specifically designed for men. Athletes were also known to drink \"magic\" potions and eat exotic meats in the hopes of giving them an athletic edge on their competition. If they were caught cheating, their likenesses were often engraved into stone and placed in a pathway that led to the Olympic stadium. In the modern Olympic era, chemically enhancing one's performance has evolved into a sophisticated science, but in the early years of the Modern Olympic movement the use of performance-enhancing drugs was almost as crude as its ancient predecessors. For example, the winner of the marathon at the 1904 Games, Thomas Hicks, was given strychnine and brandy by his coach, even during the race.\n\nDuring the early 20th century, many Olympic athletes discovered ways to improve their athletic abilities by boosting testosterone. As their methods became more extreme, it became increasingly evident that the use of performance-enhancing drugs was not only a threat to the integrity of sport but could also have potentially fatal side effects on the athlete. The only Olympic death linked to athletic drug use occurred at the Rome Games of 1960. During the cycling road race, Danish cyclist Knud Enemark Jensen fell from his bicycle and later died. A coroner's inquiry found that he was under the influence of amphetamine, which had caused him to lose consciousness during the race. Jensen's death exposed to the world how endemic drug use was among elite athletes. By the mid–1960s, sports federations were starting to ban the use of performance-enhancing drugs, and the IOC followed suit in 1967.\n\nThe first Olympic athlete to test positive for the use of performance-enhancing drugs was Hans-Gunnar Liljenwall, a Swedish pentathlete at the 1968 Summer Olympics, who lost his bronze medal for alcohol use, 'two beers to steady his nerves'. Liljenwall was the only athlete to test positive for a banned substance at the 1968 Olympics, as the technology and testing techniques improved, the number of athletes discovered to be chemically enhancing their performance increased as well. \n\nThe most systematic case of drug use for athletic achievement is that of the East German Olympic teams of the 1970s and 1980s. In 1990, documents were discovered that showed many East German female athletes, especially swimmers, had been administered anabolic steroids and other drugs by their coaches and trainers. Girls as young as eleven were started on the drug regimen without consent from their parents. American female swimmers, including Shirley Babashoff, accused the East Germans of using performance-enhancing drugs as early as the 1976 Summer Games. Babashoff's comments were dismissed by the international and domestic media as sour grapes since Babashoff, a clear favorite to win multiple gold medals, won three silver medals - losing all three times to either of the two East Germans Kornelia Ender or Petra Thümer, and one gold medal in a relay. There was no suspicion of cheating on the part of the East German female swimmers even though their medal tally increased from four silvers and one bronze in 1972 to ten golds (out of a possible 12), six silvers, and one bronze in 1976. No clear evidence was discovered until after the fall of the Berlin Wall, when the aforementioned documents proved that East Germany had embarked on a state-sponsored drug regimen to dramatically improve their competitiveness at the Olympic Games and other international sporting events. Many of the East German authorities responsible for this program have been subsequently tried and found guilty of various crimes in the German penal system.\n\nAccording to British journalist Andrew Jennings, a KGB colonel stated that the agency's officers had posed as anti-doping authorities from the International Olympic Committee to undermine doping tests and that Soviet athletes were \"rescued with [these] tremendous efforts\". On the topic of the 1980 Summer Olympics, a 1989 Australian study said \"There is hardly a medal winner at the Moscow Games, certainly not a gold medal winner, who is not on one sort of drug or another: usually several kinds. The Moscow Games might as well have been called the Chemists' Games.\"\n\nDocuments obtained in 2016 revealed the Soviet Union's plans for a statewide doping system in track and field in preparation for the 1984 Summer Olympics in Los Angeles. Dated prior to the country's decision to boycott the Games, the document detailed the existing steroids operations of the program, along with suggestions for further enhancements. The communication, directed to the Soviet Union's head of track and field, was prepared by Dr. Sergei Portugalov of the Institute for Physical Culture. Portugalov was also one of the main figures involved in the implementation of the Russian doping program prior to the 2016 Summer Olympics.\n\nA very publicized steroid-related disqualification at an Olympic Games was the case of Canadian sprinter Ben Johnson, who won the Men's 100 metres at the 1988 Seoul Olympics, but tested positive for stanozolol. His gold medal was subsequently stripped and awarded to runner-up Carl Lewis, who himself had tested positive for banned substances prior to the Olympics, but had not been banned due to a lack of consistency in the application of the rules. At that time National Olympic Committees had leeway to determine whether a specific athlete met the criteria to be banned from Olympic competition.\n\nIn the late 1990s, the IOC took the initiative in a more organized battle against doping, leading to the formation of the World Anti-Doping Agency (WADA) in 1999. The 2000 Summer Olympics and 2002 Winter Olympics have shown that the effort to eliminate performance-enhancing drugs from the Olympics is not over, as several medalists in weightlifting and cross-country skiing were disqualified due to failing a drug test. During the 2006 Winter Olympics, only one athlete failed a drug test and had a medal revoked. The IOC-established drug testing regimen (now known as the \"Olympic Standard\") has set the worldwide benchmark that other sporting federations attempt to emulate. During the Beijing games, 3,667 athletes were tested by the IOC under the auspices of the World Anti-Doping Agency. Both urine and blood testing was used in a coordinated effort to detect banned substances and recent blood transfusions. While several athletes were barred from competition by their National Olympic Committees prior to the Games, six athletes failed drug tests while in competition in Beijing.\n\nWhat follows is a list of all the athletes that have tested positive for a banned substance either during or after an Olympic Games in which they competed. Any medals listed were revoked by the International Olympic Commission (IOC). In 1967 the IOC banned the use of performance-enhancing drugs, instituted a Medical Commission, and created a list of banned substances. Mandatory testing began at the following year's Games. In a few cases the IOC has reversed earlier rulings that stripped athletes of medals.\n\nIn the case of Rick DeMont, the United States Olympic Committee (USOC) has recognized his gold medal performance in the 1972 Summer Olympics in 2001, but only the IOC has the power to restore his medal, and it has as of 2017 refused to do so.\n\nThough no athletes were caught doping at the 1980 Summer Olympics, it has been claimed that athletes had begun using testosterone and other drugs for which tests had not been yet developed. A 1989 report by a committee of the Australian Senate claimed that \"there is hardly a medal winner at the Moscow Games, certainly not a gold medal winner...who is not on one sort of drug or another: usually several kinds. The Moscow Games might well have been called the Chemists' Games\".\n\nA member of the IOC Medical Commission, Manfred Donike, privately ran additional tests with a new technique for identifying abnormal levels of testosterone by measuring its ratio to epitestosterone in urine. Twenty percent of the specimens he tested, including those from sixteen gold medalists would have resulted in disciplinary proceedings had the tests been official. The results of Donike's unofficial tests later convinced the IOC to add his new technique to their testing protocols. The first documented case of \"blood doping\" occurred at the 1980 Summer Olympics as a runner was transfused with two pints of blood before winning medals in the 5000 m and 10,000 m.\n\nThe organizers of the Los Angeles games had refused to provide the IOC doping authorities with a safe prior to the start of the games. Due to a lack of security, medical records were subsequently stolen. A 1994 letter from IOC Medical Commission chair Alexandre de Mérode claimed that Tony Daly, a member of the Los Angeles organizing committee had destroyed the records. Dick Pound later wrote of his frustration that the organizing committee had removed evidence before it could be acted on by the IOC. Pound also claimed that IOC President Juan Antonio Samaranch and Primo Nebiolo, President of the International Association of Athletics Federations (IAAF) had conspired to delay the announcement of positive tests so that the games could pass without controversy.\n\nThe American cyclist Pat McDonough later admitted to \"blood doping\" at the 1984 Los Angeles Games. Following the games it was revealed that one-third of the U.S. cycling team had received blood transfusions before the games, where they won nine medals, their first medal success since the 1912 Summer Olympics. \"Blood doping\" was banned by the IOC in 1985, though no test existed for it at the time.\n\nFive athletes tested positive for the stimulant bromantan and were disqualified by the IOC, but later reinstated after an appeal to the Court of Arbitration for Sport: swimmers Andrey Korneyev and Nina Zhivanevskaya, Greco-Roman wrestler Zafar Guliyev and sprinter Marina Trandenkova, all from Russia, and the Lithuanian track cyclist Rita Razmaitė. Dr. Vitaly Slionssarenko, physician to the Lithuanian cycling team and team coach Boris Vasilyev were expelled from the games. The CAS overturned the IOC decision, because bromantan had only recently been added to the prohibited list, and the athletes and officials were reprimanded. The Russians had argued that bromantans wasn't a stimulant and thus not banned.\n\nThe Irish long-distance runner Marie McMahon (Davenport) got a reprimand after testing positive for the stimulant phenylpropanolamine, and Cuban judoka Estella Rodriguez Villanueva got a reprimand after she tested positive for the diuretic furosemide.\n\nTim Montgomery, who was part of the USA Men's 4 × 100 m relay team which won the gold, in 2008 admitted that he had used Testosterone and HGH before the Sydney Games, and said “I have a gold medal that I’m sitting on that I didn’t get with my own ability”. IOC at the time said they would look into the case, but no action has since been taken by IOC to disqualify Montgomery from the Games.\n\n\"Zero Tolerance for Doping\" was adopted as an official slogan for the Beijing Olympic Games. A number of athletes were already eliminated by testing prior to coming to Beijing.\n\nOut of the 4,500 samples that were collected from participating athletes at the games, six athletes with positive specimens were ousted from the competition. Further positive tests were found in 2016, as samples had been sealed and stored for eight years. The quality of the original testing was questioned when the BBC reported that samples positive for EPO were labeled as negative by Chinese laboratories in July, 2008. The initial rate of positive findings was lower than at Athens in 2004, but the prevalence of doping had not necessarily decreased; the technology for creating and concealing drugs had become more sophisticated, and a number of drugs could not be detected.\n\nIn August 2015, the Turkish Athletics Federation confirmed that an in-competition test of Elvan Abeylegesse at the 2007 IAAF World Championships\nin Athletics had been retested and found to be positive for a controlled substance, and that she had been temporarily suspended. On 29 March 2017, the IAAF confirmed the positive test, announced retroactive disqualifications and voided all of her results from 25 August 2007 until 25 August 2009, including the 2008 Summer Olympics. As a result, she was stripped of two silver medals she had won in the women's 5,000 and 10,000 meter races.\n\nIn May 2016, following the Russian doping scandal, the IOC announced that 32 targeted retests had come back positive for performance-enhancing drugs, of which Russian News Agency TASS announced that 14 were from Russian athletes, 11 of them track and field athletes, including 2012 Olympic champion high jumper Anna Chicherova. Authorities have sent the B-samples for confirmation testing. Those confirmed as having taken doping agents stand to lose records and medals from the 2008 games to 2016 under IOC and WADA rules.\n\nOn 18 June 2016, the IWF reported that as a consequence of the IOC's reanalyses of samples from the 2008 Olympic Games, the samples of the following seven weightlifters had returned positive results: Hripsime Khurshudyan (Armenia), Intigam Zairov (Azerbaijan), Alexandru Dudoglo (Moldova), gold medalist Ilya Ilyin (Kazakhstan), bronze medalist Nadezda Evstyukhina and silver medalist Marina Shainova (both from Russia), and Nurcan Taylan (Turkey). In line with the relevant rules and regulations, the IWF imposed mandatory provisional suspensions upon the athletes. Zairov and Ilyin had been serving previous suspensions. In November 2016, Ilyin was stripped of the gold medal.\n\nOn 22 July 2016, Sibel Özkan (TUR) was disqualified due to an anti-doping rule violation and stripped of her silver medal. Medals have not been reallocated as yet.\n\nOn 28 July 2016, it was announced that retests of samples from the 2008 Summer Olympics detected a positive sample for performance-enhancing drugs from Aksana Miankova of Belarus, who won a gold medal in the women's hammer throw. There have been no decisions about stripping and reallocation of medals as yet.\n\nOn 16 August 2016, the Russian women's 4 × 100 metres relay team was disqualified for doping. Russian teammates were stripped of their gold Olympic medals, as Yuliya Chermoshanskaya had her samples reanalyzed and tested positive for two prohibited substances. The IAAF was requested to modify the results accordingly and to consider any further action within its own competence.\n\nOn 19 August 2016, the Russian women's 4 × 400 metres relay team was disqualified for doping. Russian teammates were stripped of their silver Olympic medals, as Anastasiya Kapachinskaya had her samples reanalyzed and tested positive for the same two prohibited substances as Chermoshanskaya.\n\nOn 24 August 2016, the IWF reported that as a consequence of the IOC's reanalyses of samples from the 2008 Olympic Games, the samples of the following athletes had returned positive results: Nizami Pashayev (Azerbaijan), Iryna Kulesha, Nastassia Novikava, Andrei Rybakou (all from Belarus), Cao Lei, Chen Xiexia, Liu Chunhong (all from China), Mariya Grabovetskaya, Maya Maneza, Irina Nekrassova, Vladimir Sedov (all from Kazakhstan), Khadzhimurat Akkaev, Dmitry Lapikov (both from Russia), and Natalya Davydova and Olha Korobka (both from Ukraine). In line with the relevant rules and regulations, the IWF imposed mandatory provisional suspensions upon the athletes, who remain provisionally suspended in view of potential anti-doping rule violations until their cases are closed.\n\nOn 29 August 2016, some non-official reports indicated that Artur Taymazov of Uzbekistan had been stripped of the 2008 Olympic gold medal in the freestyle wrestling 120 kg event due to a positive test for doping.\n\nOn 31 August 2016, the IOC disqualified six sportspeople for failing doping tests at the 2008 Games. They included three Russian medalists: weightlifters Nadezhda Evstyukhina (bronze medal in the women's 75 kg event), Marina Shainova (silver medal in the women's 58 kg event), and Tatyana Firova, who finished second with teammates in the 4 × 400 m relay. Bronze medal weightlifter Tigran Martirosyan of Armenia (men's 69 kg event) and fellow weightlifters Alexandru Dudoglo (9th place) of Moldova and Intigam Zairov (9th place) of Azerbaijan were also disqualified.\n\nOn 1 September 2016, the IOC disqualified a further two athletes. Cuban discus thrower Yarelys Barrios, who won a silver medal in the women's discus, was disqualified after testing positive for Acetazolamide and ordered to return her medal. Qatari sprinter Samuel Francis, who finished 16th in the 100 meters, was also disqualified after testing positive for Stanozolol.\n\nOn 13 September 2016, four more Russian athletes were disqualified for doping offenses. Two of those were medalists from the 2008 Summer Olympics: silver medalist Mariya Abakumova in the women's javelin throw and Denis Alekseyev, who was part of the bronze medal team in the men's 4 × 400 m relay. Inga Abitova, who finished 6th in the 10,000 meters, and cyclist Ekaterina Gnidenko also tested positive for a banned substance and were disqualified.\nOn 23 September 2016, some non-official reports indicate wrestler Vasyl Fedoryshyn of Ukraine has been stripped of the 2008 Olympic silver medal in the freestyle 60 kg event due to a positive test for doping.\n\nOn 6 October 2016, the IOC disqualified Anna Chicherova of the Russian Federation for testing positive for performance-enhancing drugs. She won a bronze medal in the women's high jump. Russia would likely keep the bronze medal, as the fourth-place athlete in the competition was also from Russia. Through 6 October 2016, the IOC has reported Adverse Analytical Findings for 25 weightlifters from its 2016 retests of samples from the 2008 Beijing Olympic Games, all but three of whom tested positive for anabolic agents (three Chinese weightlifters were positive for growth hormones).\n\nOn 26 October 2016, the IOC disqualified nine more athletes for failing drugs tests at the 2008 Games. Among them were six medal winners: weightlifters Andrei Rybakou and Nastassia Novikava, both from Belarus, and Olha Korobka of Ukraine; women’s steeplechase bronze medalist Ekaterina Volkova of Russia; and freestyle wrestlers Soslan Tigiev of Uzbekistan and Taimuraz Tigiyev of Kazakhstan. The others were men’s 62 kg weightlifter Sardar Hasanov of Azerbaijan, long jumper Wilfredo Martinez of Cuba, and 100m-hurdler Josephine Nnkiruka Onyia of Spain.\n\nOn 17 November 2016, the IOC disqualified 16 more athletes for failing drugs tests at the 2008 games. Among them were 10 medal winners: weightlifters Khadzhimurat Akkayev and Dmitry Lapikov and wrestler Khasan Baroyev from the Russian Federation, weightlifters Mariya Grabovetskaya, Irina Nekrassova and wrestler Asset Mambetov from Kazakhstan, weightlifter Nataliya Davydova and pole vaulter Denys Yurchenko from Ukraine, long/triple jumper Hrysopiyí Devetzí of Greece and wrestler Vitaliy Rahimov of Azerbaijan. The others were women’s 75 kg weightlifter Iryna Kulesha of Belarus, women’s +63 kg weightlifter Maya Maneza of Kazakhstan, women's high jumper Vita Palamar of Ukraine, men’s 94 kg weightlifter Nizami Pashayev of Azerbaijan, men’s 85 kg weightlifter Vladimir Sedov of Kazakhstan, and women’s high jumper Elena Slesarenko of the Russian Federation.\n\nOn 25 November 2016, the IOC disqualified 5 more athletes for failing drugs tests at the 2008 games. Among them were 3 medal winners: gold-medalists 94 kg weightlifter Ilya Ilin of Kazakhstan and hammer thrower Aksana Miankova of Belarus and silver-medalist shot putter Natallia Mikhnevich of Belarus. The others were shot putter Pavel Lyzhyn and 800m runner Sviatlana Usovich, both of Belarus.\n\nOn 12 January 2017, the IOC disqualified five more athletes for failing drug tests at the 2008 Games. These included three Chinese women's weightlifting gold medalists: Lei Cao (75 kg), Xiexia Chen (48 kg) and Chunhong Liu (69 kg). Two women athletes from Belarus were disqualified: bronze medalist shot putter Nadzeya Ostapchuk and hammer thrower Darya Pchelnik, who did not medal.\n\nOn 25 January 2017, the IOC stripped Jamaica of the athletics gold medal in the men's 4 × 100 m relay due to Nesta Carter testing positive for the prohibited substance methylhexaneamine. The IOC also stripped Russian jumper Tatyana Lebedeva of two silver medals in women's triple jump and long jump due to use of turinabol.\n\nOn 1 March 2017, the IOC disqualified Victoria Tereshchuk of Ukraine due to use of turinabol and stripped her of the bronze medal in modern pentathlon.\n\nBy April 2017, the 2008 Summer Olympics has had the most (50) Olympic medals stripped for doping violations. Russia is the leading country with 14 medals stripped.\n\nAthletes who were selected for the Games, but provisionally suspended before competing.\n\nIt was announced prior to the Summer games that half of all competitors would be tested for drugs, with 150 scientists set to take 6,000 samples between the start of the games and the end of the Paralympic games. All medalists would also be tested. The Olympic anti-doping laboratory would test up to 400 samples every day for more than 240 prohibited substances.\n\nThe head of the World Anti-Doping Agency (WADA), John Fahey, announced on 24 July that 107 athletes had been sanctioned for doping offences in the six months to 19 June. The \"In-competition\" period began on 16 July. During the \"In-competition\" period Olympic competitors can be tested at any time without notice or in advance.\n\nBritish sprinter Dwain Chambers, cyclist David Millar and shot putter Carl Myerscough competed in London after the British Olympic Association's policy of punishing drug cheats with lifetime bans was overturned by the Court of Arbitration for Sport.\n\nRussian Darya Pishchalnikova participated in the 2012 Olympics and was awarded a silver medal. However, she tested positive for the anabolic steroid oxandrolone in the samples taken in May 2012. In December 2012, she sent an email to WADA containing details on an alleged state-run doping program in Russia. According to \"The New York Times\", the email reached three top WADA officials but the agency decided not to open an inquiry and instead sent her email to Russian sports officials. In April 2013 Pishchalnikova was banned by the Russian Athletics Federation for ten years, and her results from May 2012 were annulled, meaning she was set on track to lose her Olympic medal. Her ban by the Russian Athletics Federation was likely in retaliation.\n\nGold medalists at the games who had been involved in previous doping offences included Alexander Vinokourov, the winner of the men's road race, Tatyana Lysenko, the winner of the women's hammer throw, Aslı Çakır Alptekin winner of the women's 1500 meters and Sandra Perković, winner of the women's discus throw. Other competitors at the Summer games involved in previous doping cases included American athletes Justin Gatlin and LaShawn Merritt, and Jamaican sprinter Yohan Blake.\n\nSpanish athlete Ángel Mullera was first selected for the 3000 m steeplechase and later removed when emails were published in which he discussed EPO use with a trainer. Mullera appealed to CAS which ordered the Spanish Olympic Committee to allow him to participate.\n\nPrior to the Olympic competition, several prominent track and field athletes were ruled out of the competition due to failed tests. World indoor medallists Dimitrios Chondrokoukis, Debbie Dunn, and Mariem Alaoui Selsouli were withdrawn from their Olympic teams in July for doping, as was 2004 Olympic medallist Zoltán Kővágó. At the Olympic competition, Tameka Williams admitted to taking a banned stimulant and was removed from the games. Ivan Tsikhan did not compete in the hammer throw as a retest of his sample from the 2004 Athens Olympics, where he won silver, was positive. Amine Laâlou, Marina Marghieva, Diego Palomeque, and defending 50 km walk champion Alex Schwazer were also suspended before taking part in their events.\n\nSyrian hurdler Ghfran Almouhamad became the first track-and-field athlete to be suspended following a positive in-competition doping sample. Nadzeya Astapchuk was stripped of the women's shot put title after her sample came back positive for the banned anabolic agent metenolone. Karin Melis Mey was withdrawn before the long jump final when an earlier failed doping test was confirmed.\n\nA WADA report released in 2015 detailed an extensive Russian state-sponsored doping program implicating athletes, coaches, various Russian institutions, doctors and labs. The report stated that the London Olympic Games \"were, in a sense, sabotaged by the admission of athletes who should have not been competing\" and detailed incidents of bribery and bogus urine samples. The report recommended that Russia be barred from track and field events for the 2016 Olympics. It also recommended lifetime bans for five coaches and five athletes from the country, including runners Mariya Savinova, Ekaterina Poistogova, Anastasiya Bazdyreva, Kristina Ugarova, and Tatjana Myazina.\n\nOn 15 June 2016, it was announced that four London 2012 Olympic weightlifting champions had tested positive for performance-enhancing drugs. They include Kazakhstan's Ilya Ilyin (94 kg), Zulfiya Chinshanlo (53 kg), Maiya Maneza (63 kg) and Svetlana Podobedova (75 kg). If confirmed, Kazakhstan would drop from 12th to 23rd in the 2012 medal standings. Six other lifters who competed at the 2012 Games also tested positive after hundreds of samples were reanalysed. Among them are Russia's Apti Aukhadov (silver at 85 kg), Ukraine's Yuliya Kalina (bronze at 58 kg), Belarusian Maryna Shkermankova (bronze at 69 kg), Azerbaijan's Boyanka Kostova and Belarus duo Dzina Sazanavets and Yauheni Zharnasek. On 27 July 2016, IWF has reported in the second wave of re-sampling that three silver medalists from Russia, namely Natalia Zabolotnaya (at 75 kg), Aleksandr Ivanov (at 94 kg) and Svetlana Tsarukayeva (at 63 kg), together with bronze medalists Armenian Hripsime Khurshudyan (at 75+ kg), Belarusian Iryna Kulesha (at 75 kg) and Moldovan Cristina Iovu (at 53 kg) have tested positive for steroid dehydrochlormethyltestosterone. Aukhadov was stripped of his silver medal by the IOC on 18 October 2016. On 27 October 2016 Maiya Maneza was stripped of her gold medal. In November 2016, Ilyin was stripped of the London gold medal.\n\nOn 13 July 2016, the IOC announced that Yuliya Kalina of Ukraine had been disqualified from the 2012 Summer Olympics and ordered to return the bronze medal from the 58 kg weightlifting event. Reanalysis of Kalina's samples from London 2012 resulted in a positive test for the prohibited substance dehydrochlormethyltestosterone (turinabol). The positions were adjusted accordingly.\n\nOn 9 August 2016, the IOC announced that Oleksandr Pyatnytsya of Ukraine would be stripped of his silver medal in the javelin throw after he tested positive for the prohibited substance dehydrochlormethyltestosterone (turinabol). Redistribution of medals has not yet been announced, but the likely case is the silver and bronze medals will be given to Finland and Czech Republic instead.\n\nOn 20 August 2016, the IOC announced that Yevgeniya Kolodko of Russia would be stripped of her silver medal in shot put after she tested positive of dehydrochlormethyltestosterone (turinabol) and ipamorelin. Medals are not reallocated yet.\n\nOn 29 August 2016, a report indicated that a retested sample for Besik Kudukhov of Russia, the silver medalist in the men's 60 kg freestyle wrestling event, had returned a positive result (later disclosed as dehydrochlormethyltestosterone). Kudakhov died in a car crash in December 2013. On 27 October 2016, the IOC dropped all disciplinary proceedings against Kudukhov, stating that such proceedings cannot be conducted against a deceased person. As a result, it said, Olympic results that would have been reviewed will remain uncorrected, which is the unavoidable consequence of the fact that the proceedings cannot move forward.\n\nOn 13 September 2016, the IWF reported that the men's 94 kg weightlifting bronze medalist, Moldova's Anatolie Cîrîcu, had tested positive for the dehydrochlormethyltestosterone.\n\nOn 6 October 2016, the IWF reported that as a consequence of the IOC's reanalyses of samples from the 2012 Olympic Games, a sample of Norayr Vardanyan, who represented Armenia, had returned a positive result. In line with the relevant rules and regulations, the IWF imposed mandatory provisional suspensions upon Vardanyan, who remains provisionally suspended until his case is closed. On 12 January 2017, the IOC disqualified Vardanyan. Through 6 October 2016, the IOC had reported Adverse Analytical Findings for 23 weightlifters from its 2016 retests of samples from the 2012 London Olympic Games, all of whom tested positive for anabolic agents.\n\nOn 11 October 2016, Tatyana Lysenko of the Russian Federation was disqualified from the women's hammer throw, in which she won the gold medal. She had tested positive for a banned substance. The IOC requested the IAAF to modify the results of this event accordingly. The silver medalist Anita Włodarczyk of Poland would likely take the gold medal in her place.\n\nOn 18 October 2016, the IOC disqualified Apti Aukhadov of the Russian Federation for doping and stripped him of the silver medal. The IOC requested the IWF to modify the results of this event accordingly; it has not yet published modified results.\n\nOn 18 October 2016, the IOC reported that Maksym Mazuryk of Ukraine, who competed in the Men’s Pole Vault event, was disqualified from the 2012 London Games, in which he ranked 18th. Re-analysis of Mazuryk’s samples resulted in a positive test for dehydrochlormethyltestosterone.\n\nOn 27 October 2016 the IOC disqualified a further eight athletes for failing doping tests at the games. This included four medal winners in weightlifting: Zulfiya Chinshanlo, Maiya Maneza and Svetlana Podobedova, all from Kazakhstan, and Maryna Shkermankova of Belarus. The others were hammer thrower Kirill Ikonnikov of Russia, women’s 69 kg weightlifter Dzina Sazanavets of Belarus, pole vaulter Dmitry Starodubtsev of Russia, and men’s +105 kg weightlifter Yauheni Zharnasek of Belarus.\n\nOn 21 November 2016 the IOC disqualified a further 12 athletes for failing doping tests at the games. This included 6 medal winners in weightlifting, including Alexandr Ivanov (Russia), Anatoli Ciricu (Moldova), Cristina Iovu (Moldova), Nataliya Zabolotnaya (Russia), Iryna Kulesha (Belarus), and Hripsime Khurshudyan (Armenia). Moldova has lost all its 2012 London medals. The others were hammer thrower Oleksandr Drygol and long jumper Margaryta Tverdokhlib, both of Ukraine, 85 kg weightlifter Rauli Tsirekidze of Georgia, 94 kg weightlifter Almas Uteshov of Kazakhstan, 94 kg weightlifter Andrey Demanov of Russia and 3000m steeplechaser Yuliya Zaripova of Russia, who had previously been sanctioned in March 2016 by the Court of Arbitration for Sport.\n\nOn 25 November 2016, the IOC disqualified 4 more athletes for failing drug tests at the 2012 games. They were gold medalist 94 kg weightlifter Ilya Ilin of Kazakhstan, hammer thrower Aksana Miankova and long jumper Nastassia Mironchyk-Ivanova, both of Belarus, and 58 kg weightlifter Boyanka Kostova of Azerbaijan.\n\nOn 29 November 2016 the Court of Arbitration for Sport issued a decision that all results achieved by 2012 Olympic heptathlon bronze medalist Tatyana Chernova of Russia between 15 August 2011 and 22 July 2013 are annulled. It also annulled all of Yekaterina Sharmina's results between 17 June 2011 and 5 August 2015, including her 33rd-place finish in the 2012 women's 1500m. CAS ruled that they \"have been found to have committed an anti-doping rule violation ... of the International Athletic Association Federation (IAAF) Competition Rules after analysis of their Athlete Biological Passports (ABP) showed evidence of blood doping.\"\n\nOn 12 January 2017, the IOC disqualified three weightlifters for failing drug tests at the 2012 games. Two competed in men's 94 kg weightlifting: Intigam Zairov of Azerbaijan and Norayr Vardanyan of Armenia. Women's 63 kg weightlifter Sibel Simsek of Turkey was disqualified. None was a medalist at these games.\n\nOn 1 February 2017, the IOC disqualified three athletes due to failed doping tests, all of whom tested positive for turinabol. Russian women's discus thrower Vera Ganeeva, who finished 23rd, Turkish boxer Adem Kilicci, who ranked 5th in men's 69–75 kg boxing, and Russian 400m runner Antonina Krivoshapka, who finished 6th, were disqualified. Krivoshapka also was part of the Russian silver medal-winning women’s 4 × 400 m relay team, which was stripped of the silver medals.\n\nIn December 2014, a documentary aired on German TV in which 800m gold medalist Mariya Savinova allegedly admitted to using banned substances on camera. In November 2015, Savinova was one of five Russian runners the World Anti-Doping Agency recommended to receive a lifetime ban for doping during the London Olympics, along with 800m bronze medalist Ekaterina Poistogova. On 10 February 2017, the Court of Arbitration for Sport upheld a four-year ban that effectively stripped Savinova of her Olympic gold and other medals. On 7 April 2017, CAS refused to decide on disqualification from 2012, and disqualify Ekaterina Poistogova from 2015. Thus, Ekaterina Poistogova retained her Olympic 2012 medal at women's 800 metres athletic event.\n\nIn April 2017, the Olympics has had 29 Olympic medals stripped for doping violations. Russia is the leading country with 13 medals stripped.\n\nAthletes who were selected for the Games, but provisionally suspended before competing.\n\nOriginally Russia submitted a list of 389 athletes for competition. On 7 August 2016, the IOC cleared 278 athletes, while 111 were removed because of the state-sponsored doping scandal.\n\nThe Taiwanese weightlifter Lin Tzu-chi was withdrawn from the games hours before her event by her country's delegation for an abnormal drugs test.\n\nThe Kenyan athletics coach John Anzrah, who travelled to Rio independently of his country's delegation was sent home after being caught posing as an athlete during a doping test. This followed the sending home of Kenya's track and field manager Michael Rotich who was filmed by a newspaper offering to give athletes advanced notice of any pending drugs test in return for a one-off payment.\n\nOn 13 October 2016, the IWF reported that weightlifter Gabriel Sincraian of Romania, who won bronze in the men's 85-kg event, tested positive for excess testosterone in a test connected to the Rio Olympics. On 8 December 2016, the CAS affirmed the disqualification of Sincraian and the loss of the bronze medal. The CAS also disqualified silver medalist 52 kg boxer Misha Aloian of Russia.\n\nAthletes who were selected for the Games, but provisionally suspended before competing.\n\nNo athletes were caught doping at these Games.\n\nNo athletes were caught using performance-enhancing drugs at these Games.\n\nThe Finnish cross-country skier Aki Karvonen admitted in 1994 that he'd had blood transfusions for the Sarajevo Games. Blood transfusions weren't formally banned by IOC until 1986. Karvonen won a silver and two bronze at the games.\n\nNo athletes were caught using performance-enhancing drugs at these Games. The Russian biathlete Sergei Tarasov admitted in 2015 that the Russian biathlon team had carried out illegal blood transfusions at the Games. Something went very wrong with his transfusion, and he was rushed to the hospital where they saved his life.\n\nNo athletes were caught using performance-enhancing drugs at these Games\n\nNo athletes were caught using performance-enhancing drugs at these games. The Canadian snowboarder Ross Rebagliati, winner of the men's giant slalom, was initially disqualified and stripped of his gold medal by the International Olympic Committee's Executive Board after testing positive for marijuana. Marijuana was not then on the list of prohibited substances by the IOC, and their decision was reversed by the Court of Arbitration for Sport and Rebagliati's medal reinstated.\n\nOn 25 April 2007, six Austrian athletes were banned for life from the Olympics for their involvement in a doping scandal at the 2006 Turin Olympics, the first time the IOC punished athletes without a positive or missed doping test. The Austrians were found guilty of possessing doping substances and taking part in a conspiracy, based on materials seized by Italian police during a raid on the athletes' living quarters. The Austrians also had their competition results from Turin annulled. A seventh athlete, cross-country skier Christian Hoffmann, had his case referred to the International Ski Federation for further investigation, but IOC charges were dismissed.\n\nThe IOC has retested nearly 500 doping samples that were collected at the 2006 Turin Games. In 2014, the Estonian Olympic Committee was notified by the IOC that a retested sample from cross-country skier Kristina Šmigun had tested positive. On 24 October 2016, the World Anti-Doping Agency Athletes' Commission stated that Šmigun, who won two gold medals at the Turin Games, faces a Court of Arbitration for Sport hearing before the end of October. If Šmigun were to be stripped of her gold medals, Kateřina Neumannová of Czech Republic could be elevated to gold in the 7.5 + 7.5 km double pursuit event. Marit Bjørgen of Norway could acquire a seventh gold medal in the 10 km classical event.\n\nOn 13 February 2006, the Brazilian Olympic Committee announced that Armando dos Santos' preventive antidoping test, which had been done in Brazil on 4 January 2006, was positive for the forbidden substance nandrolone. Santos was ejected from the team, being replaced by former sprinter Claudinei Quirino, the team's substitute athlete.\n\nOn 23 December 2016, the IOC stated that it will re-analyse all samples from Russian athletes at the Olympic Winter Games of Vancouver 2010. In October 2017, the IOC stated that one sole athlete was caught from retests of doping samples from the Vancouver 2010 Winter Olympic Games. Biathlete Teja Gregorin was confirmed as this athlete by the International Biathlon Union. A total of 1195 samples from Vancouver 2010 (70% of the 1700 available) were reanalyzed. This included all medalists and all of the 170 Russian athletes. The IOC requested all Russian samples from the 2010 Games be retested after the publication of the McLaren Report. Russia's disappointing performance at Vancouver (11th in gold medal table with a total of 3 golds) is cited as the reason behind the implementation of a doping scheme alleged to have been in operation at major events such as the 2014 Games at Sochi.\n\nAccording to the director of the country’s antidoping laboratory at the time, Grigory Rodchenkov, dozens of Russian athletes at the 2014 Winter Olympics in Sochi, including at least 15 medal winners, were part of a state-run doping program, meticulously planned for years to ensure dominance at the Games.\n\nIn December 2016, following the release of the McLaren report on Russian doping at the Sochi Olympics, the International Olympic Committee announced the initiation of an investigation of 28 Russian athletes (the number later rose to 46) at the Sochi Olympic Games. \"La Gazzetta dello Sport\" reported the names of 17 athletes, of whom 15 are among the 28 under investigation.\n\nThree female figure skaters were named as being under investigation. They are Adelina Sotnikova, the singles gold medalist, as well as pairs skaters Tatiana Volosozhar and Ksenia Stolbova. Volosozhar and Stolbova won gold and silver medals, respectively, in pairs skating. Both also won gold medals in the team event, which also puts the other eight team medalists at risk of losing their golds. In November 2017 the proceeding against Sotnikova was dropped.\n\nSix cross-country skiers were suspended from competition on the basis of the McLaren Report: Evgeniy Belov, Alexander Legkov, Alexey Petukhov, Maxim Vylegzhanin, Yulia Ivanova and Evgenia Shapovalova. Legkov won a gold and silver medals, and Vylegzhanin won three silver medals. The IOC disqualified all six from Sochi, imposed lifetime bans and, in the process, stripped Legkov and Vylegzhanin of the medals they had won in four events (three individual medals and one team medal). Nikita Kryukov, Alexander Bessmertnykh and Natalya Matveyeva were also disqualified on December 22, 2017.\n\nThe International Biathlon Union suspended two Russian biathletes who were in the Sochi games: Olga Vilukhina and Yana Romanova. Vilukhina won silver in sprint, and both women were on a relay team that won the silver medal. They were disqualified and stripped of their medals on 27 November 2017.\n\nThe International Bobsleigh and Skeleton Federation suspended four Russian skeleton sliders. They were Alexander Tretyakov, Elena Nikitina, Maria Orlova and Olga Potylitsina. Tretyakov won a gold medal, and Nikitina won a bronze. On November 22, 2017, the IOC stripped these medals and imposed lifetime Olympic bans on all four. Skeleton racer Sergei Chudinov was sanctioned on 28 November 2017.\n\nSeven Russian female ice hockey players were to have hearings before the Oswald Commission on November 22, 2017. Two of the seven were accused of submitting samples showing readings that were physically impossible to be held by a woman. The Russian women's ice hockey team finished sixth at Sochi 2014. On December 12, 2017, six of them were disqualified. Tatiana Burina and Anna Shukina were also disqualified ten days later.\n\nOn November 24, 2017, the IOC imposed life bans on bobsledder Alexandr Zubkov and speed skater Olga Fatkulina who won a combined 3 medals (2 gold, 1 silver). All their results were disqualified, meaning that Russia lost its first place in the medal standings. Bobsledders Aleksei Negodaylo and Dmitry Trunenkov were disqualified 3 days later. 3 other Russian athletes who didn't win medals were banned on 29 November 2017. Biathlete Olga Zaitseva and 2 other Russian athletes were banned on December 1, 2017. Bobsledder Alexey Voyevoda who had been already stripped of his gold medals due to the anti-doping violations committed by his teammates was sanctioned on December 18, 2017. Speed skaters Ivan Skobrev and Artyom Kuznetsov, lugers Albert Demchenko and Tatiana Ivanova, and bobsledders Liudmila Udobkina and Maxim Belugin were disqualified on December 22, 2017, bringing the total to 43. Demchenko and Ivanova were also stripped of their silver medals.\n\nAfter the Russian Olympic Committee was barred from competing at the 2018 Winter Olympics, Russian athletes deemed to be clean were allowed to compete under the Olympic flag as an Olympic Athlete from Russia.\n\n\n"}
{"id": "26471190", "url": "https://en.wikipedia.org/wiki?curid=26471190", "title": "Encog", "text": "Encog\n\nEncog is a machine learning framework available for Java and .Net.\nEncog supports different learning algorithms such as Bayesian Networks, Hidden Markov Models and Support Vector Machines.\nHowever, its main strength lies in its neural network algorithms. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using many different techniques. Multithreading is used to allow optimal training performance on multicore machines.\n\nEncog can be used for many tasks, including medical and financial research. A GUI based workbench is also provided to help model and train neural networks. Encog has been in active development since 2008.\n\n\n\n\n"}
{"id": "7324297", "url": "https://en.wikipedia.org/wiki?curid=7324297", "title": "Genome-based peptide fingerprint scanning", "text": "Genome-based peptide fingerprint scanning\n\nGenome-based peptide fingerprint scanning (GFS) is a system in bioinformatics analysis that attempts to identify the genomic origin (that is, what species they come from) of sample proteins by scanning their peptide-mass fingerprint against the theoretical translation and proteolytic digest of an entire genome. This method is an improvement from previous methods because it compares the peptide fingerprints to an entire genome instead of comparing it to an already annotated genome. This improvement has the potential to improve genome annotation and identify proteins with incorrect or missing annotations.\n\nGFS was designed by Michael C. Giddings (University of North Carolina, Chapel Hill) et al., and released in 2003. Giddings expanded the algorithms for GFS from earlier ideas. Two papers were published in 1993 explaining the techniques used to identify proteins in sequence databases. These methods determined the mass of peptides using mass spectrometry, and then used the mass to search protein databases to identify the proteins In 1999 a more complex program was released called Mascot that integrated three types of protein/database searches: peptide molecular weights, tandem mass spectrometry from one or more peptide, and combination mass data with amino acid sequence. The fallback with this widely used program is that it is unable to detect alternative splice sites that are not currently annotated, and it not usually able to find proteins that have not been annotated. Giddings built upon these sources to create GFS which would compare peptide mass data to entire genomes to identify the proteins. Giddings system is able to find new annotations of genes that have not been found, such as undocumented genes and undocumented alternative splice sites.\n\nIn 2012 research was published where genes and proteins were found in a model organism that could not have been found without GFS because they had not been previously annotated. The planarian Schmidtea mediterranea has been used in research for over 100 years. This planarian is capable of regenerating missing body parts and is therefore emerging as potential model organism for stem cell research. Planarians are covered in mucus which aids in locomotion, in protecting them from predation, and in helping their immune system. The genome of \"Schmidtea mediterranea\" is sequenced but mostly un-annotated making it a prime candidate for genome-based peptide fingerprint scanning. When the proteins were analyzed with GFS 1,604 proteins were identified. These proteins had mostly not been annotated before they were found with GFS They were also able to find the mucous subproteome (all the genes associated with mucus production). They found that this proteome was conserved in the sister species \"Schmidtea mansoni\". The mucous subproteome is so conserved that 119 orthologs of planarians are found in humans. Due to the similarity in these genes the planarian can now be used as a model to study mucous protein function in humans. This is relevant for infections and diseases related to mucous aberrancies such as cystic fibrosis, asthma, and other lung diseases. These genes could not have been found without GFS because they had not been previously annotated.\n\nIn February 2013, proteogenomic mapping research was done with ENCODE to identify translational regions in the human genome. They applied peptide fingerprint scanning and MASCOT to the protein data to find regions that may not have been previously annotated as translated in the human genome. This search against the whole genome revealed that approximately 4% of unique peptide that they found were outside of previously annotated regions. Also the comparison of the whole genome revealed 15% more hits than from a protein database search (such as MASCOT) alone. GFS can be used as a complementary method for annotation due to the fact that you can find new genes or splice sites that have not been annotated before. However it is important to remember that the whole genome approach used by GFS can be less sensitive than programs that look only at annotated regions.\n\n"}
{"id": "8033091", "url": "https://en.wikipedia.org/wiki?curid=8033091", "title": "Half-metal", "text": "Half-metal\n\nA half-metal is any substance that acts as a conductor to electrons of one spin orientation, but as an insulator or semiconductor to those of the opposite orientation. Although all half-metals are ferromagnetic (or ferrimagnetic), most ferromagnets are not half-metals. Many of the known examples of half-metals are oxides, sulfides, or Heusler alloys.\n\nIn half-metals, the valence band for one spin orientation is partially filled while there is a gap in the density of states for the other spin orientation. This results in conducting behavior for only electrons in the first spin orientation. In some half-metals, the majority spin channel is the conducting one while in others the minority channel is.\n\nHalf-metals were first described in 1983, as an explanation for the electrical properties of Mn-based Heusler alloys.\n\nSome notable half-metals are chromium(IV) oxide, magnetite, and lanthanum strontium manganite (LSMO), as well as chromium arsenide. Half-metals have attracted some interest for their potential use in spintronics.\n\n"}
{"id": "47294662", "url": "https://en.wikipedia.org/wiki?curid=47294662", "title": "Haulani (crater)", "text": "Haulani (crater)\n\nHaulani is an impact crater located on Ceres that contains \"Spot 1\", one of the bright spots observed by the Dawn spacecraft. The crater was named after Haulani, the Hawaiian goddess of plants. In July 2018, NASA released a comparison of physical features, including Haulani crater, found on Ceres with similar ones present on Earth.\n"}
{"id": "47889207", "url": "https://en.wikipedia.org/wiki?curid=47889207", "title": "Helium-3 surface spin echo", "text": "Helium-3 surface spin echo\n\nHelium-3 surface spin echo (HeSE) is an inelastic scattering technique in surface science that has been used to measure microscopic dynamics at well-defined surfaces in ultra-high vacuum. The information available from HeSE complements and extends that available from other inelastic scattering techniques such as neutron spin echo and traditional helium-4 atom scattering (HAS).\n\nThe experimental principles of the HeSE experiment are analogous to those of neutron spin echo, differing in details such as the nature of the probe/sample interactions that give rise to scattering. In outline, a polarized He beam is created by a supersonic expansion followed by a spin-filtering stage (polariser). The helium scatters from the experimental sample and is detected at the end of the beamline after another spin-filtering stage (analyser). Before and after the scattering process, the beam passes through magnetic fields that precess the probe spins in the usual sense of a spin echo experiment. The raw data of the experiment are the spin-resolved scattered helium intensities as a function of the incoming magnetic field integral, outgoing field integral and any other variable parameters relevant to specific experiments, such as surface orientation and temperature. In the most general kind of scattering-with-precession experiment, the data can be used to construct the 2D 'wavelength intensity matrix' for the surface scattering process, i.e. the probability that a helium atom of a certain incoming wavelength scatters into a state with a certain outgoing wavelength.\n\nConventional 'spin echo' measurements are a common special case of the more general scattering-with-precession measurements, in which the incoming and outgoing magnetic field integrals are constrained to be equal. The polarization of the outgoing beam is measured as a function of the precession field integral by measuring the intensity of the outgoing beam resolved into different spin states. The spin echo case is referred to as a type of 'tilted projection measurement'. Spin echo measurements are an appropriate tilted projection for quasi-elastic measurements of surface dynamics because the raw data are closely related to the intermediate scattering function (ISF), which in many cases can be interpreted in terms of standard dynamical signatures.\n\nThe surface processes that HeSE can measure can be broadly divided into elastic, quasielastic and inelastic processes. Measurements in which the predominant signal is elastically scattered include standard helium diffraction and the measurement of selective adsorption resonances. Quasielastic measurements generally correspond to measurements of microscopic surface diffusion in which the Doppler-like energy gain and loss of the helium atoms is small compared to the beam energy. More strongly inelastic measurements can provide information about energy loss channels on the surface such as surface phonons.\n\nHeSE has been used to study the diffusion rates and mechanisms of atoms and molecules ('adsorbates') at surfaces. A non-exhaustive list of the research themes associated with HeSE diffusion measurements include: \nnuclear quantum effects in the surface diffusion of atomic hydrogen;\nbenchmarking the adsorbate/surface free energy landscape; \nenergy exchange ('friction') between adsorbates and the surface; pairwise and many-body inter-adsorbate interactions.\n\nHeSE has been used to construct empirical helium-surface scattering potentials through the measurement of selective adsorption resonances (bound state resonances) on the clean LiF(001) surface and the hydrogenated Si(111) surface.\n"}
{"id": "23183652", "url": "https://en.wikipedia.org/wiki?curid=23183652", "title": "Homogenization (chemistry)", "text": "Homogenization (chemistry)\n\nHomogenization or homogenisation is any of several processes used to make a mixture of two mutually non-soluble liquids the same throughout. This is achieved by turning one of the liquids into a state consisting of extremely small particles distributed uniformly throughout the other liquid. A typical example is the homogenization of milk, where the milk fat globules are reduced in size and dispersed uniformly through the rest of the milk.\n\nHomogenization (from \"homogeneous;\" Greek, \"homogenes\": \"homos,\" same + \"genos,\" kind) is the process of converting two immiscible liquids (i.e. liquids that are not soluble, in all proportions, one in another) into an emulsion (an emulsion is a type of colloid, which is a substance microscopically dispersed throughout another substance; when both the dispersed and the continuous substances are liquids, the colloid is called an emulsion). Sometimes two types of homogenization are distinguished: primary homogenization, when the emulsion is created directly from separate liquids; and secondary homogenization, when the emulsion is created by the reduction in size of droplets in an existing emulsion.\nHomogenization is achieved by a mechanical device called a \"homogenizer\".\n\nOne of the oldest applications of homogenization is in milk processing. It is normally preceded by \"standardization\" (the mixing of several different milking herds and/or dairies to produce a more consistent raw milk prior to processing and to prevent, reduce and delay natural separation of cream from the rest of the emulsion). The fat in milk normally separates from the water and collects at the top. Homogenization breaks the fat into smaller sizes so it no longer separates, allowing the sale of non-separating milk at any fat specification.\n\nMilk homogenization is accomplished by mixing massive amounts of harvested milk to create a constant, then forcing the milk at high pressure through small holes. Yet another method of homogenization uses extruders, hammermills, or colloid mills to mill (grind) solids. Milk homogenization is an essential tool of the milk food industry to prevent creating various levels of flavor and fat concentration.\n\nAnother application of homogenization is in soft drinks like cola products. The reactant mixture is rendered to intense homogenization, to as much as 35,000 psi, so that various constituents do not separate out during storage or distribution.\n\n\n"}
{"id": "5259450", "url": "https://en.wikipedia.org/wiki?curid=5259450", "title": "Hubble European Space Agency Information Centre", "text": "Hubble European Space Agency Information Centre\n\nThe Hubble European Space Agency Information Centre (HEIC) is a science communication office, established at the Space Telescope - European Coordinating Facility (ST-ECF) in Munich, Germany late in 1999. This initiative was taken so as to fulfil the NASA/ESA Hubble Space Telescope (HST) outreach and education tasks for the European Space Agency (ESA), as outlined in an agreement between NASA and ESA.\n\nOver the past few years HEIC has become a very distinguished communication office of experts using the newest software and techniques. The European Hubble office has produced large amounts of astronomical material suitable both for educational purposes and wider public consumption. HEIC provides a well-assorted archive that is publicly available on its web page.\n\nThe work is centred on the production of news and photo releases that highlight interesting Hubble science results and images. These are often European in origin, and so not only increase the awareness of ESA’s Hubble share (15%), but the contribution of European scientists to the observatory. Furthermore, the group produces video releases, innovative educational material, CD-ROMs, brochures, posters, as well as DVDs and museum information kiosks, and much more.\n\nThe Hubble Information Centre is headed by the science communication specialist Lars Lindberg Christensen and the lead graphic designer is Martin Kornmesser.\n\n"}
{"id": "5938816", "url": "https://en.wikipedia.org/wiki?curid=5938816", "title": "Imagine Cup", "text": "Imagine Cup\n\nImagine Cup is an annual competition sponsored and hosted by Microsoft Corp. which brings together student developers worldwide to help resolve some of the world's toughest challenges. It is considered as \"Olympics of Technology\" by computer science and engineering and is considered one of the top competitions and awards related to technology and software design. All Imagine Cup competitors create projects that address the Imagine Cup theme: \"Imagine a world where technology helps solve the toughest problems\". Started in 2003, it has steadily grown in size, with more than 358,000 competitors representing 183 countries and regions in 2011. The Imagine Cup Worldwide finals have been held all over the globe. The Imagine Cup 2017 Worldwide Finals was held in Seattle, United States.\n\nThe Imagine Cup began in 2003 with approximately 1,000 competitors from 25 countries and regions and has grown to more than 358,000 competitors representing 183 countries and regions in 2011. The Imagine Cup Worldwide finals have been held all over the globe. Since 2014, the Imagine Cup World Finals have been held in Seattle, United States.\n\nAll Imagine Cup competitors create projects that address the Imagine Cup theme: “Imagine a world where technology helps solve the toughest problems.” \n\nCompetitions:\n\nThere are a number of competitions and challenges within the Imagine Cup. The Software Design category is the primary competition in which its winners take home the Imagine Cup trophy.\n\nThe Imagine Cup Innovation Accelerator was a program that, between 2006 and 2008, provided Imagine Cup Software Design teams with direction on the next stage of developing their innovative ideas into a business. Each year, between 2006–2008, six teams were selected for the Innovation Accelerator program. Participants in the Innovation Accelerator program travelled to the Microsoft Mountain View campus in Silicon Valley and received technical support and business coaching to create the must-have technology and communications applications of the future.\nIn 2010, Microsoft began inviting every Imagine Cup team to participate in its new program for startups: Microsoft BizSpark. With this program, startups receive access to current, full-featured software development tools and platforms.\n\nPrevious teams include:\n\n\nA three-year, $3 million competitive grant program was established by Microsoft in 2011 to support a select number of winning teams’ solutions to go to market and realize its potential to solve a critical global problem. The inaugural grant recipients were announced at the World Economic Forum in Davos, Switzerland on January 27, 2012 which included the following teams:\n\n\nThe grant packages include US$75,000 for each team, as well as software, cloud computing services, solution provider support, premium Microsoft BizSpark account benefits and access to local resources such as the Microsoft Innovation Centers. Microsoft will also connect grant recipients with its network of investors, nongovernmental organization partners and business partners.\n\nImagine Cup participants from around the world who won their regional competitions in 2010 have been recognized by their government leaders. \nIn October 2010, two Imagine Cup 2010 United States finalists (Wilson To from the Mobilifeteam and Christian Hood from BeastWare) were invited to participate in the White House Science Fair. \nNew Zealand’s Prime Minister, Hon. John Key sent Team OneBeep from New Zealand a personal letter that congratulated them on their third-place finish.\nTeam Skeek from Thailand, winners of the 2010 Software Design competition, met Dr. Khunying Kalaya Sophonpanich, a member of Parliament and Secretary General of The Rajapruek Institute Foundation.\nMicrosoft Poland and members of the European Parliament hosted the “Pushing the Boundaries of Innovation” conference in Brussels. Imagine Cup teams from Poland (fteams and Mutants), Serbia (TFZR), Germany (Mediator), and Belgium (Nom Nom Productions) were in attendance. \nGreek Imagine Cup winners, Giorgos Karakatsiotis and Vangos Pterneas, of Megadodo, met with the Prime Minister of Greece, George Papandreou, and demonstrated their project that creates personalized descriptions of museum exhibits based on the user's needs.\nTeams Xormis and Educ8 from Jamaica were honored with a special luncheon hosted by the Government of Jamaica that included an address from Hon. Bruce Golding, the prime minister. \nTeam Think Green had the opportunity to meet with Ivo Josipović, President of Croatia.\n\n\n"}
{"id": "38448288", "url": "https://en.wikipedia.org/wiki?curid=38448288", "title": "Index of physics articles (E)", "text": "Index of physics articles (E)\n\nThe index of physics articles is split into multiple pages due to its size.\n\nTo navigate by individual letter use the table of contents below.\n\n"}
{"id": "3341783", "url": "https://en.wikipedia.org/wiki?curid=3341783", "title": "Information processing theory", "text": "Information processing theory\n\nThe information processing theory approach to the study of cognitive development evolved out of the American experimental tradition in psychology. Developmental psychologists who adopt the information-processing perspective account for mental development in terms of maturational changes in basic components of a child’s mind. The theory is based on the idea that humans process the information they receive, rather than merely responding to stimuli. This perspective equates the mind to a computer, which is responsible for analyzing information from the environment. According to the standard information-processing model for mental development, the mind’s machinery includes attention mechanisms for bringing information in, working memory for actively manipulating information, and long-term memory for passively holding information so that it can be used in the future. This theory addresses how as children grow, their brains likewise mature, leading to advances in their ability to process and respond to the information they received through their senses. The theory emphasizes a continuous pattern of development, in contrast with Cognitive Developmental theorists such as Jean Piaget that thought development occurred in stages at a time.\n\nInformation processing as a model for human thinking and learning is part of the resurgence of cognitive perspectives of learning. The cognitive perspective asserts that complex mental states affect human learning and behavior that such mental states can be scientifically investigated. Computers, which process information, include internal states that affect processing. Computers, therefore, provided a model for possible human mental states that provided researchers with clues and direction for understanding human thinking and learning as information processing. Overall, information-processing models helped reestablish mental processes that cannot be directly observed as a legitimate area of scientific research.\n\nWithin this model, humans are routinely compared to computers. This comparison is used as a means of better understanding the way information is processed and stored in the human mind. Therefore, when analyzing what actually develops within this model, the more specific comparison is between the human brain and computers. Computers were introduced to the study of development and provided a new way of studying intelligence (Lachman, 1979) and added further legitimacy to the scientific study of the mind (Goodwin, 2005, p. 411). Information is taken in (or input). Information is encoded to give meaning and compared with stored information. If a person is working on a task, this is where the working memory is enacted. An example of that for a computer is the CPU. In both cases, information is encoded, given meaning, and combined with previously stored information to enact the task. The latter step is where the information is stored where it can later be retrieved when needed. For computers, this would be akin to saving information on a hard drive, where you would then upload the saved data when working on a future task (using your working memory as in step 2).\n\nCognitive processes include perception, recognition, imagining, remembering, thinking, judging, reasoning, problem solving, conceptualizing, and planning. These cognitive processes can emerge from human language, thought, imagery, and symbols.\n\nIn addition to these specific cognitive processes, many cognitive psychologists study language-acquisition, altered states of mind and consciousness, visual perception, auditory perception, short-term memory, long-term memory, storage, retrieval, perceptions of thought and much more.\n\nThis theory views humans as actively inputting, retrieving, processing, and storing information. Context, social content, and social influences on processing are simply viewed as information. Nature provides the hardware of cognitive processing and Information Processing theory explains cognitive functioning based on that hardware. Individuals innately vary in some cognitive abilities, such a memory span, but human cognitive systems function similarly based on a set of memory stores that store information and control processes determine how information is processed. The “Nurture” component provides information input (stimuli) that is processed resulting in behavior and learning. Changes in the contents of the long-term memory store (knowledge) are learning. Prior knowledge affects future processing and thus affects future behavior and learning.\n\nInformation processing theory combines elements of both quantitative and qualitative development. Qualitative development occurs through the emergence of new strategies for information storage and retrieval, developing representational abilities (such as the utilization of language to represent concepts), or obtaining problem-solving rules (Miller, 2011). Increases in the knowledge base or the ability to remember more items in working memory are examples of quantitative changes, as well as increases in the strength of connected cognitive associations (Miller, 2011). The qualitative and quantitative components often interact together to develop new and more efficient strategies within the processing system.\n\nInformation Processing Theory is currently being utilized in the study of computer or artificial intelligence. This theory has also been applied to systems beyond the individual, including families and business organizations. For example, Ariel (1987) applied Information Processing Theory to family systems, with sensing, attending, and encoding of stimuli occurring either within individuals or within the family system itself. Unlike traditional systems theory, where the family system tends to maintain stasis and resists incoming stimuli which would violate the system's rules, the Information Processing family develops individual and mutual schemes which influence what and how information is attended to and processed. Dysfunctions can occur both at the individual level as well as within the family system itself, creating more targets for therapeutic change. Rogers, P. R. et al (1999) utilized Information Processing Theory to describe business organizational behavior, as well as to present a model describing how effective and ineffective business strategies are developed. In their study, components of organizations that \"sense\" market information are identified as well as how organizations attend to this information; which gatekeepers determine what information is relevant/important for the organization, how this is organized into the existing culture (organizational schemas), and whether or not the organization has effective or ineffective processes for their long-term strategy.\n\n"}
{"id": "14220695", "url": "https://en.wikipedia.org/wiki?curid=14220695", "title": "International Journal of Men's Health", "text": "International Journal of Men's Health\n\nThe International Journal of Men's Health was a triannual peer-reviewed academic journal which was published by Men's Studies Press from 2002 until 2016. It covered all aspects of men's health. The editor-in-chief was Steve Robertson (Leeds Metropolitan University). The journal was abstracted and indexed in Scopus.\n"}
{"id": "16075754", "url": "https://en.wikipedia.org/wiki?curid=16075754", "title": "Inverse resolution", "text": "Inverse resolution\n\nInverse resolution is an inductive reasoning technique that involves inverting the resolution operator. \n\nInverse resolution\n"}
{"id": "8845939", "url": "https://en.wikipedia.org/wiki?curid=8845939", "title": "John Robert Anderson (chemist)", "text": "John Robert Anderson (chemist)\n\nJohn Robert Anderson (5 March 1928 – 26 February 2007) was an Australian chemist whose research specialised on materials science. Anderson served as Chief of the Division of Material Sciences at the Commonwealth Scientific and Industrial Research Organisation from 1970 to 1978. He attended Sydney Boys High School from 1940 to 1944.\n\n"}
{"id": "42681393", "url": "https://en.wikipedia.org/wiki?curid=42681393", "title": "Leptolinea tardivitalis", "text": "Leptolinea tardivitalis\n\nLeptolinea tardivitalis is a mesophilic, non-spore-forming, non-motile, Gram-negative, filamentous bacteria with type strain YMTK-2 (=JCM 12579 =DSM 16556), the type species of its genus.\n\n\n"}
{"id": "3275310", "url": "https://en.wikipedia.org/wiki?curid=3275310", "title": "Line of action", "text": "Line of action\n\nIn physics, the line of action of a force \"F\" is a geometric representation of how the force is applied. It is the line through the point at which the force is applied in the same direction as the vector .\n\nThe concept is essential, for instance, for understanding the net effect of multiple forces applied to a body. As an example, if two forces of equal magnitude act upon a rigid body along the same line of action but in opposite directions, then they have no net effect—loosely speaking, they cancel one another out. But if, instead, their lines of action are not identical, but merely parallel, then their effect is to create a moment on the body, which tends to rotate it.\n"}
{"id": "29849848", "url": "https://en.wikipedia.org/wiki?curid=29849848", "title": "List of RNA biologists", "text": "List of RNA biologists\n\nFor related information, see the articles on History of RNA Biology, History of Molecular Biology, and History of Genetics.\n"}
{"id": "913605", "url": "https://en.wikipedia.org/wiki?curid=913605", "title": "List of U.S. state amphibians", "text": "List of U.S. state amphibians\n\nThis is a list of official U.S. state amphibians. State amphibians are designated by tradition or the respective state legislatures.\n\n"}
{"id": "35277745", "url": "https://en.wikipedia.org/wiki?curid=35277745", "title": "List of biogeographical puzzles", "text": "List of biogeographical puzzles\n\nThis is a list of taxa whose location or distribution is notably difficult to explain; e.g., species which came to occupy a range distant from that of their closest relatives by a process or history that is not understood, or is a subject of controversy.\n\n"}
{"id": "43028577", "url": "https://en.wikipedia.org/wiki?curid=43028577", "title": "List of botanists by author abbreviation (B)", "text": "List of botanists by author abbreviation (B)\n\nTo find entries for A, use the table of contents above.\n\n\nTo find entries for C–Z, use the table of contents above.\n"}
{"id": "31320936", "url": "https://en.wikipedia.org/wiki?curid=31320936", "title": "List of cholesterol in foods", "text": "List of cholesterol in foods\n\nThis list consists of common foods with their cholesterol content recorded in milligrams per 100 grams (3.5 ounces) of food.\n\nCholesterol is a sterol, a steroid-like lipid made by animals, including humans. The human body makes one-eighth to one-fourth teaspoons of pure cholesterol daily. A cholesterol level of 5.5 millimoles per litre or below is recommended for an adult. The rise of cholesterol in the body can give a condition in which excessive cholesterol is deposited in artery walls called atherosclerosis. This condition blocks the blood flow to vital organs which can result in high blood pressure or stroke. \nCholesterol is not always bad. It's a vital part of the cell wall and a precursor to substances such as brain matter and some sex hormones. There are some types of cholesterol which are beneficial to the heart and blood vessels. High-density lipoprotein is commonly called \"good\" cholesterol. These lipoproteins help in the removal of cholesterol from the cells, which is then transported back to the liver where it is disintegrated and excreted as waste or broken down into parts.\n\n\n"}
{"id": "1465195", "url": "https://en.wikipedia.org/wiki?curid=1465195", "title": "List of clinically important bacteria", "text": "List of clinically important bacteria\n\nThis is a list of bacteria that are significant in medicine. It is not intended as an exhaustive list of all bacterial species: that should be at List of bacteria. For viruses, see list of viruses.\n\n____\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "39479110", "url": "https://en.wikipedia.org/wiki?curid=39479110", "title": "List of things named after Emil Artin", "text": "List of things named after Emil Artin\n\nThese are things named after Emil Artin, a mathematician.\n\n"}
{"id": "1614365", "url": "https://en.wikipedia.org/wiki?curid=1614365", "title": "Marek Huberath", "text": "Marek Huberath\n\nMarek S. Huberath (pen name, born 1954) is a Polish professor of physics in the Jagiellonian University in Kraków and an award-winning science fiction and fantasy writer. His themes are philosophical, moral, and religious: how people become beasts or remain human in extreme circumstances. Many of his stories focus on death. Winner of the Zajdel Award in 1991 for a short story \"Kara większa\" and in 1997 for his novel \"Gniazdo Światów\".\n\n\n\n\n"}
{"id": "53773838", "url": "https://en.wikipedia.org/wiki?curid=53773838", "title": "Michael G. Burton", "text": "Michael G. Burton\n\nMichael G. Burton is an astronomer who is director of the Armagh Observatory and Planetarium. He was previously director of teaching at the School of Physics, University of New South Wales. He is a member of the International Astronomical Union.\n\nBurton is a fellow of Astronomical Society of Australia (FASA), Australian Institute of Physics (FAIP), and the Royal Society of New South Wales (FRSN).\n"}
{"id": "2386911", "url": "https://en.wikipedia.org/wiki?curid=2386911", "title": "Microcin", "text": "Microcin\n\nMicrocins are very small bacteriocins, composed of relatively few amino acids. For this reason, they are distinct from their larger protein cousins. The classic example is microcin V, of \"Escherichia coli\". Subtilosin A is another bacteriocin from \"Bacillus subtilis\". The peptide has a cyclized backbone and forms three cross-links between the sulphurs of Cys13, Cys7 and Cys4 and the alpha-positions of Phe22,Thr28 and Phe31.\n\nMicrocins produced by commensal \"E. coli\" strains target and eliminate enteric pathogens such as \"Salmonella\" Enterica by mimicking the siderophores the pathogens use for iron scavenging. Microcins also help commensal strains of \"E. coli\" outcompete pathogenic strains.\n\nBACTIBASE database is an open-access database for bacteriocins including microcins.\n"}
{"id": "51301471", "url": "https://en.wikipedia.org/wiki?curid=51301471", "title": "NGC 156", "text": "NGC 156\n\nNGC 156 is a double star located in the Cetus constellation. It was discovered on 1882 by Ernst Wilhelm Leberecht Tempel.\n\n\n\n\n"}
{"id": "20353594", "url": "https://en.wikipedia.org/wiki?curid=20353594", "title": "Obconic", "text": "Obconic\n\nIn botany, an obconic is an inverted cone shape. The term is most frequently applied to certain fruit or hypanthium structures with the apical end attached to the stem; however, less frequently the usage may apply to the pistil structure. In the case of fungi the designation is often made to the ascospore. The use of \"obconic\" in botany dates to at least as early as the nineteenth century; however, some modern usage applies to an entire plant form, such as the shape of a whole shrub. More broadly, in geometry or design, the term can be assigned in an abstract manner to shapes in the natural or man-made world which show an inverted cone design.\n\nThe carnivorous plant \"Nepenthes deaniana\" has pitcher elements that are obconic in shape to capture insects. The hypanthium of the western USA plant \"Heuchera rubescens\" has one subspecies with an obconic structure, while several other subspecies have alternative hypantium geometries, so that the obconic characteristic is a subspecies determinant and diagnostic. The hypanthium of the Toyon shrub is also generally obconic in shape. The Asian tree \"Eriobotrya latifolia\" and several other species within the genus \"Eriobotrya\" have an obconic calyx, although some individuals manifest clavate calices. The basal portion of the pistil of \"Pachypodium baronii exhibits the obconic structural design.\n\nAs a fungal example the species \"Pocillum cesatii\" is noted to have an obconic ascospore.\n\nThe derivation of the word \"obconic\" is based upon the Greek with the common prefix \"ob\", meaning \"inverted\", and the Greek word for angle \"gon\" or \"gonia\", followed by the generic suffix \"ic\". Historically botanists have used the designation \"obconic\" to describe elements of a plant such as the fruit, hypanthium, calyx or pistil base since at least as early as the nineteenth century, and in modern times the term has been generalized to also refer to an entire plant architectural shape.\n\n"}
{"id": "17686503", "url": "https://en.wikipedia.org/wiki?curid=17686503", "title": "Olevi Kull", "text": "Olevi Kull\n\nOlevi Kull (22 June 1955, Rakvere – 31 January 2007, Tartu) was an Estonian professor at the University of Tartu known for his contribution to ecology. Following his death, a memorial fund was established by donations in his memory, which provides travel stipends to students in the fields of plant ecophysiology, forest ecology and ecosystem ecology.\n\nBiosemiotician Kalevi Kull is his older brother.\n\n\n\n"}
{"id": "4478605", "url": "https://en.wikipedia.org/wiki?curid=4478605", "title": "Organization for Women in Science for the Developing World", "text": "Organization for Women in Science for the Developing World\n\nThe Organization for Women in Science for the Developing World (OWSD) (formerly, the Third World Organization for Women in Science (TWOWS) is an international membership organization that provides research training, career development and networking opportunities for women scientists throughout the developing world at different stages in their careers. Its programmes include postgraduate and early career fellowships and annual awards for research excellence.\n\nOWSD was established in 1993. The OWSD Secretariat is based in Trieste, Italy on the campus of the International Center for Theoretical Physics, and is hosted by the World Academy of Sciences (TWAS), a programme unit of UNESCO.\n\nOWSD is governed by an Executive Board, composed of a President, four regional Vice Presidents and four regional Members. The Executive Board is elected by OWSD members at a General Assembly every four years.\n\nThe OWSD Secretariat is headed by the OWSD Programme Coordinator who is given the authority to make decisions and implement operations and programmes according to the direction set by the Executive Board. The Secretariat acts as chief point of contact and liaison between regions and the national chapters, and administers the programmatic activities. \n\nThe idea for OWSD was first raised at a conference on The Role of Women in the Development of Science and Technology in the Third World in 1988, organized by the World Academy of Sciences, where more than 200 leading women scientists from 63 developing countries participated. A study group was formed to explore the possibility of creating an organization that would champion the experience, needs and skills of women scientists in the developing world. At a further meeting in Trieste in 1989, the Third World Organization for Women in Science (TWOWS) was established and a constitution adopted. TWOWS was officially launched four years later in 1993, at the First General Assembly in Cairo, Egypt. \n\nOn June 29 2010, members voted to adopt a new name - the Organization for Women in Science for the Developing World (OWSD) - at the organization’s Fourth General Assembly in Beijing, China.\n\nOWSD is funded by external donors.\n\nThe Swedish International Development Cooperation Agency (Sida) has supported OWSD financially since 1998 and provides full funding for the postgraduate fellowship programme. \n\nSince 2010, the Elsevier Foundation has provided funding for the OWSD-Elsevier Foundation Awards for Early Career Women Scientists, given to five women scientists from the developing world each year. \n\nIn 2017, an agreement was signed with Canada’s International Development Research Centre (IDRC) to fully fund a new OWSD fellowship for Early Career Women Scientists. \n\nOWSD has more than 6,000 members from 137 countries.  Over 90% of OWSD members are women living and working in developing countries who have master's or doctorate degrees in scientific subjects.  \n\nOWSD has three categories of membership:\n\n\nOWSD has national chapters in 20 countries. National chapters organize regional conferences, seminars and workshops, lead national and regional initiatives for women in science, and provide OWSD members with networking opportunities. National chapters have been established in:\n\n\nOWSD postgraduate fellowships are offered to women from selected science and technology-lagging countries in the developing world to undertake PhD research in the natural sciences, including engineering and information technology, at host institutes in another developing country. A small number of fellowships are also available for MSc students. \n\nThese scholarships cover all costs related to undertaking research in a host country that are not covered by the host institute, including travel, visa and health costs, tuition and bench fees as well as a monthly stipend for the awardees' board, accommodation and living expenses. The fellowship also includes additional funding for each PhD fellow to travel to international workshops and conferences of relevance. \n\nThe fellowship is offered as either a full-time (up to 4 years) or sandwich option, in which the fellow is a registered PhD student in her home country and undertakes a maximum of 3 research visits at the host institute for minimum 6 up to 20 months.\n\nMore than 240 women scientists have graduated from the fellowship programme with PhDs since 1998. \n\nThe programme is funded by Sida, the Swedish International Development Cooperation Agency.\n\nThe OWSD Early Career Women Scientists (ECWS) fellowship is a prestigious award of up to USD 50,000 offered to women who have completed their PhDs in science, technology, engineering and mathematics (STEM) subjects and are employed at an academic or scientific research institute in selected science and technology-lagging countries in the developing world. ECWS fellows are supported to continue their research at an international level while based at their home institutes and to build up research groups that will attract international visitors. \n\nThe ECWS fellowship programme is funded by the International Development Research Centre (IDRC) of Canada. \n\nThe first cohort of ECWS fellows will be awarded in 2018. \n\nThe OWSD-Elsevier Foundation Awards are an annual prize given to reward and encourage women scientists working and living in developing countries who are in the early stages of their careers. Initially launched in 2010, the Awards are presented to five scientists each year, one from each of the four OWSD regions plus an additional exceptional winner from any region. The eligible scientific disciplines for the Awards rotate between the biological sciences, physical sciences and engineering. Each winner receives USD 5,000 and presents her research during a special awards ceremony at the American Association for the Advancement of Science (AAAS) annual meeting.\n\nAwardees must have made a demonstrable impact on the research environment both at a regional and international level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "372742", "url": "https://en.wikipedia.org/wiki?curid=372742", "title": "Pathological (mathematics)", "text": "Pathological (mathematics)\n\nIn mathematics, a pathological phenomenon is one whose properties are considered atypically bad or counterintuitive; the opposite is well-behaved.\n\nA classic example of a pathological structure is the Weierstrass function, which is continuous everywhere but differentiable nowhere. The sum of a differentiable function and the Weierstrass function is again continuous but nowhere differentiable; so there are at least as many such functions as differentiable functions. In fact, by the Baire category theorem one can show that continuous functions are typically or \"generically\" nowhere differentiable.\n\nIn layman's terms, the majority of functions are nowhere differentiable, and relatively few can ever be described or studied. In general most useful functions also have some sort of physical basis or practical application, which means that they cannot be pathological at the level of hard mathematics or logic; absent certain limiting cases like the delta distribution, they tend to be quite well-behaved and intuitive. To quote Henri Poincaré:\n\nThis highlights the fact that the term \"pathological\" is subjective, context-dependent, and subject to wearing off. Its meaning in any particular case resides in the community of mathematicians, and not necessarily within mathematics itself. Also, the quotation shows how mathematics often progresses via counter-examples to what is thought intuitive or expected; for instance, the \"lack of derivatives\" mentioned is intimately connected with current study of magnetic reconnection events in solar plasma.\n\nOne of the most notorious pathologies in topology is the Alexander horned sphere, a counterexample showing that topologically embedding the sphere \"S\" in R may fail to separate the space cleanly. As a counter-example, it motivated the extra condition of \"tameness\" which suppresses the kind of \"wild\" behaviour the horned sphere exhibits.\n\nLike many other pathologies, the horned sphere in a sense plays on infinitely fine, recursively generated structure, which in the limit violates ordinary intuition. In this case the topology of an ever-descending chain of interlocking loops of continuous pieces of the sphere in the limit fully reflects that of the common sphere, and we'd expect the outside of it, after an embedding, to work the same. Yet it does not: it fails to be simply connected.\n\nFor the underlying theory, see Jordan–Schönflies theorem.\n\nMathematicians (and those in related sciences) very frequently speak of whether a mathematical object—a function, a set, a space of one sort or another—is \"well-behaved\". The term has no fixed formal definition, and is dependent on context, mathematical interests, fashion, and taste. To ensure that an object is \"well-behaved\" mathematicians introduce further axioms to narrow down the domain of study. This has the benefit of making analysis easier, but cuts down on the generality of any conclusions reached. Concepts like non-Euclidean geometry were once considered ill-behaved, but are now common objects of study.\n\nIn both pure and applied mathematics (optimization, numerical integration, or mathematical physics, for example), \"well-behaved\" also means not violating any assumptions needed to successfully apply whatever analysis is being discussed.\n\nThe opposite case is usually labeled pathological. It is not unusual to have situations in which most cases (in terms of cardinality or measure) are pathological, but the pathological cases will not arise in practice unless constructed deliberately.\n\nThe term \"well-behaved\" is generally applied in an absolute sense—either something is well-behaved or it is not. For example:\n\n\nUnusually, the term could also be applied in a comparative sense:\n\n\nPathological examples often have some undesirable or unusual properties that make it difficult to contain or explain within a theory. Such pathological behaviour often prompts new investigation which leads to new theory and more general results. For example, some important historical examples of this are the following:\n\n\n\nAt the time of their discovery, each of these was considered highly pathological; today, each has been assimilated into modern mathematical theory. These examples prompt their observers to correct their beliefs or intuitions; sometimes they may even necessitate a reassessment of foundational definitions and concepts. Over the course of history, they have led to more correct, more precise, and more powerful mathematics. For example, the Dirichlet function is Lebesgue integrable, and convolution with test functions is used to approximate any locally integrable function by smooth functions. (The approximations converge almost everywhere and in the space of locally integrable functions.)\n\nWhether a behavior is pathological is by definition subject to personal intuition. Pathologies depend on context, training, and experience—what is pathological to one researcher may very well be standard behaviour to another.\n\nPathological examples can show the importance of the assumptions in a theorem. For example, in statistics, the Cauchy distribution does not satisfy the central limit theorem, even though its symmetric bell-shape appears similar to many distributions which do; it fails the requirement to have a mean and standard deviation which exist and are finite.\n\nSome of the best-known paradoxes such as the Banach–Tarski paradox and Hausdorff paradox are based on the existence of non-measurable sets. Mathematicians, unless they take the minority position of denying the axiom of choice, are in general resigned to living with such sets.\n\nIn computer science, \"pathological\" has a slightly different sense with regard to the study of algorithms. Here, an input (or set of inputs) is said to be \"pathological\" if it causes atypical behavior from the algorithm, such as a violation of its average case complexity, or even its correctness. For example, hash tables generally have pathological inputs: sets of keys that collide on hash values. Quicksort normally has O(n log n) time complexity, but deteriorates to O(n) when given input that triggers suboptimal behaviour.\n\nThe term is often used pejoratively, as a way of dismissing such inputs as being specially designed to break a routine that is otherwise sound in practice (compare with \"Byzantine\"). On the other hand, awareness of pathological inputs is important as they can be exploited to mount a denial-of-service attack on a computer system. Also, the term in this sense is a matter of subjective judgment as with its other senses. Given enough run time, a sufficiently large and diverse user community, or other factors, an input which may be dismissed as pathological could in fact occur (as seen in the first test flight of the Ariane 5).\n\nA similar but distinct phenomenon is that of exceptional objects (and exceptional isomorphisms), which occurs when there are a \"small\" number of exceptions to a general pattern—quantitatively, a finite set of exceptions to an otherwise infinite rule. By contrast, in cases of pathology, often most or almost all instances of a phenomenon are pathological, as discussed in prevalence, above—e.g., almost all real numbers are irrational.\n\nSubjectively, exceptional objects (such as the icosahedron or sporadic simple groups) are generally considered \"beautiful\", unexpected examples of a theory, while pathological phenomena are often considered \"ugly\", as the name implies. Accordingly, theories are usually expanded to include exceptional objects – for example, the exceptional Lie algebras are included in the theory of semisimple Lie algebras: the axioms are seen as good, the exceptional objects as unexpected but valid. By contrast, pathological examples are instead taken to point out a shortcoming in the axioms, requiring stronger axioms to rule them out – for example, requiring tameness of an embedding of a sphere in the Schönflies problem. One may study the more general theory, including the pathologies, which may provide its own simplifications (the real numbers have properties very different from the rationals, and likewise continuous maps have very different properties from smooth ones), but will also in general study the narrower theory from which the original examples were drawn.\n\n"}
{"id": "548265", "url": "https://en.wikipedia.org/wiki?curid=548265", "title": "Peak–end rule", "text": "Peak–end rule\n\nThe peak–end rule is a psychological heuristic in which people judge an experience largely based on how they felt at its peak (i.e., its most intense point) and at its end, rather than based on the total sum or average of every moment of the experience. The effect occurs regardless of whether the experience is pleasant or unpleasant. According to the heuristic, other information aside from that of the peak and end of the experience is not lost, but it is not used. This includes net pleasantness or unpleasantness and how long the experience lasted. The peak–end rule is thereby a specific form of the more general extension neglect and duration neglect.\n\nThe peak–end rule is an elaboration on the snapshot model of remembered utility proposed by Barbara Fredrickson and Daniel Kahneman. This model dictates that an event is not judged by the entirety of an experience, but by prototypical moments (or \"snapshots\") as a result of the representativeness heuristic. The remembered value of snapshots dominates the actual value of an experience. Fredrickson and Kahneman theorized that these snapshots are actually the average of the most affectively intense moment of an experience and the feeling experienced at the end. The effects of the duration of an experience upon retrospective evaluation are extremely slight. Fredrickson and Kahneman labeled this phenomenon \"duration neglect\". The peak–end rule is applicable only when an experience has definite beginning and end periods.\n\nA 1993 study titled \"When More Pain Is Preferred to Less: Adding a Better End\" by Kahneman, Fredrickson, Charles Schreiber, and Donald Redelmeier provided groundbreaking evidence for the peak–end rule. Participants were subjected to two different versions of a single unpleasant experience. The first trial had subjects submerge a hand in 14 °C water for 60 seconds. The second trial had subjects submerge the other hand in 14 °C water for 60 seconds, but then keep their hand submerged for an additional 30 seconds, during which the temperature was raised to 15 °C. Subjects were then offered the option of which trial to repeat. Against the law of temporal monotonicity, subjects were more willing to repeat the second trial, despite a prolonged exposure to uncomfortable temperatures. Kahneman et al. concluded that \"subjects chose the long trial simply because they liked the memory of it better than the alternative (or disliked it less).\"\n\nSimilarly, a 1996 study by Kahneman and Redelmeier assessed patients' appraisals of uncomfortable colonoscopy or lithotripsy procedures and correlated the remembered experience with real-time findings. They found that patients consistently evaluated the discomfort of the experience based on the intensity of pain at the worst (peak) and final (end) moments. This occurred regardless of length or variation in intensity of pain within the procedure.\n\nAnother study by Kahneman and Ziv Carmon identified a boundary condition for the peak–end rule. Participants interacted with a computer program that had them wait to be served, while assessing their satisfaction as they were waiting. Kahneman and Carmon found that how participants felt at the final moment of the experience was a good predictor of their responses when they were asked to retrospectively evaluate their experiences. For example, participants who felt very dissatisfied during much of the experience but were satisfied in the final few seconds (because the waiting line moved faster than expected toward the end) summarized the experience as satisfying. Kahneman and Carmon concluded that real time experiences that are based on expectations are discounted after the fact if those expectations are unfulfilled.\n\nA third study by Kahneman, Redelmeier, and Joel Katz corroborated and expanded upon the discoveries made in the 1996 study. Colonoscopy patients were randomly divided into two groups. One underwent a colonoscopy procedure wherein the scope was left in for three extra minutes, but not moved, creating a sensation that was uncomfortable, but not painful. The other group underwent a typical colonoscopy procedure. Kahneman et al. found that, when asked to retrospectively evaluate their experiences, patients who underwent the longer procedure rated their experience as less unpleasant than patients who underwent the typical procedure. Moreover, the patients in the prolonged discomfort group were far more likely to return for subsequent procedures because a less painful end led them to evaluate the procedure more positively than those who faced a shorter procedure.\n\nPeople exhibit better memory for more intensely emotional events than less intensely emotional events. The precise cause of this is unclear, but it has been demonstrated, for decades, across a wide variety of surveys and experiments. In addition, people do not always recognize that the events that they remember are more emotionally intense than the \"average\" event of its kind. This failure to correct for the atypicality of extreme memories can lead people to believe those extreme moments are representative of the \"set\" being judged. Boston Red Sox fans asked to recall any one game they saw when the Red Sox won, for example, tended to recall the best game they could remember. They only realized this game was unrepresentative of past winning games by the Red Sox if they were explicitly asked to recall the best game they could remember, as evidenced by their subsequent \"affective forecasts\". This bias for more intense emotional experiences is evident in \"nostalgic preferences\". People asked to recall a television show or movie from the past tend to recall the most enjoyable show or movie that they can remember, and use this extreme example to rate all shows from its era unless they are also able to spontaneously recall shows or movies that are worse than the first show or movie they remember.\n\nPeople exhibit serial position effects such that they have better memory for \"both\" the beginning and end of sequences, phenomena known as primacy bias and recency bias, respectively. A paper by Garbinsky, Morewedge, and Shiv (2014) found evidence that for extended hedonic experiences, better memory for the end of the experience than the beginning (recency > primacy) can be attributed to memory interference effects. As a person eats potato chips, for example, the formation of a new memory of the most recently eaten chip makes it harder for them to recall how the previously eaten chips tasted. Garbinsky and colleagues found that (1) recency effects better predicted recalled enjoyment of a small meal (e.g., eating 5 or 15 chips) than did primacy effects, (2) that people had a worse memory for the first bite of the meal than the last bite of the meal, but (3) providing people with their ratings of the first bite lead them to use their enjoyment of that first bite as much as their enjoyment of the last bite when rating their overall enjoyment of the meal.\n\nSince most consumer interactions have set beginnings and ends, they fit the peak–end model. As a consequence, negative occurrences in any consumer interaction can be counteracted by establishing a firmly positive peak and end. This can be accomplished through playing music customers enjoy, giving out free samples, or paying a clerk to hold the door for patrons as they leave. As Scott Stratten has suggested, \"A really great salesperson who helps with an exchange can erase negative experiences along the way. The long wait in line and the bad music in the changing room are forgotten\". However, as research by Talya Miron-Shatz suggests, retrospective evaluations of day-long experiences do not appear to follow the peak–end rule, which brings into question the applicability of this rule to approximately day-length consumer–business interactions, such as hotel stays.\n\nIn 2006, a study was carried out at the University of Canterbury in Christchurch, New Zealand, analyzing the implications of the peak–end rule on the perceived happiness experienced on vacations. The study found that participants' remembered overall happiness was approximately predicted by the peak–end rule, although it was actually better predicted by their happiness during the \"most memorable or most unusual 24-h period\". Still, the duration of a vacation appeared to have negligible effects on remembered happiness. The results of the study could be applied to choosing more economical durations for vacations.\n\nThe peak–end rule is particularly salient in regard to medical procedures, since it suggests that it is preferable to have longer procedures that include a period of decreased discomfort than to have shorter procedures. In particular, the rule \"suggests that the memory of a painful medical treatment is likely to be less aversive if relief from the pain is gradual than if relief is abrupt\". Furthermore, the quality of a remembered procedure can drastically influence medical futures. If people recall necessary but onerous procedures more positively, then they are more likely to return for repeat procedures later in life.\nHowever, factoring the effect of the peak–end rule upon evaluations of medical procedures is problematic, since adding a period of decreasing pain to a procedure is still added pain. Even though this certainly yields a better memory of the process, the patient still endures more pain than is strictly necessary. Doctors and patients are forced to confront the choice between objectively less painful forms of treatment and forms of treatment that will be remembered more favorably. Kahneman claims that \"it is safe to assume that few patients will agree to expose themselves to pain for the sole purpose of improving a future memory\".\n\nCritiques of the peak–end rule typically derive from its conflation of a complex mental evaluation into a simplistic framework. A 2008 study found some support for the peak–end rule, but also found that it was \"not an outstandingly good predictor\" of remembered experiential value, and that the happiness of the most memorable part of an experience predicted remembered happiness better than did the happiness of the peak or of the end. Additionally, the extreme effect of peaks fades more rapidly over time, causing peaks to be recalled less positively and troughs recalled less negatively over time. Episodic memory endures for only a few weeks; at some point, mental accounting shifts over to semantic memory, leading to potential over-valuation of the \"end\" and diminished weighting of the peak. Additionally, memories that are available for evaluation may change due to the fading affect associated with memory or differing goals in recall. Goal orientation or initial expectations can also affect the weighting of a peak or an end, causing an end to be over-weighted as the culmination of a goal. Finally, Ariely and Carmon have theorized that evaluations of past events are affected by feelings at the time of evaluation.\n\n\n"}
{"id": "394780", "url": "https://en.wikipedia.org/wiki?curid=394780", "title": "Physics Analysis Workstation", "text": "Physics Analysis Workstation\n\nThe Physics Analysis Workstation (PAW) is an interactive, scriptable computer software tool for data analysis and graphical presentation in High Energy Physics (HEP). \n\nThe development of this software tool started at CERN in 1986, it was optimized for the processing very large amounts of data. It was based on and intended for inter-operation with components of CERNLIB, an extensive collection of Fortran libraries. \n\nPAW had been a standard tool in high energy physics for decades, yet was essentially unmaintained. Despite continuing popularity as of 2008, it has been losing ground to the C++-based ROOT package. Conversion tutorials exist. In 2014, development and support were stopped.\n\nPAW uses its own scripting language. Here's a sample code (with its actual output), which can be used to plot data gathered in files.\n\n"}
{"id": "3602325", "url": "https://en.wikipedia.org/wiki?curid=3602325", "title": "Public transport planning", "text": "Public transport planning\n\nPublic transport planning or transit planning is the professional discipline responsible for developing public transport systems . It is a hybrid discipline involving aspects of transport engineering and traditional urban planning. Indeed, many transit planners find themselves involved in discourse with urban-land-use issues such as transit-oriented development.\n\nTransit planners are responsible for developing routes and networks of routes for urban transit systems. These may follow one or more models depending on the character of the communities they serve. For example, in urban areas, a system may attract enough ridership to support high frequencies of service. At these high frequencies, services can operate at demand service levels where the specific frequency of service in each corridor can be independent and where transfers can reasonably occur at random. In less densely developed areas service may operate somewhat infrequently. To optimize the quality of trips for customers, some systems compensate by operating a timed-transfer system. In this model, routes are designed to bring buses (or trains or ferries) together at a central location at predetermined times. Customers then transfer between the vehicles which leave a few minutes later. In systems committed to this system, routes are designed to take travel time into account.\n\nIn addition to serving customers' transportation needs, transit planners often consider transportation projects' other impacts. Economic impacts, directly on providers and consumers, on local economies, and on the aggregate level in large economic spheres, often feature prominently in deciding between different projects. In recent decades, concerns about environmental quality have produced a growing interest in developing sustainable transportation and transit planning has evolved to reflect these new concerns. Similarly, impacts on social equity have been paid increasing attention by transit planners in recent years.\n"}
{"id": "13020679", "url": "https://en.wikipedia.org/wiki?curid=13020679", "title": "RRS Bransfield", "text": "RRS Bransfield\n\nRRS \"Bransfield\" was an ice-strengthened cargo vessel, purpose-built for the British Antarctic Survey (BAS).\n\nRRS \"Bransfield\" was designed by consultants Graham & Woolnaugh of Liverpool for NERC, and built by Robb Caledon Shipbuilders Ltd, Leith. She was named after Edward Bransfield RN (1785-1852), who discovered the north west coast of the Antarctic Peninsula, roughly surveyed the South Shetland Islands, claiming King George Island and Clarence Island for Great Britain. Bransfield was the first man to chart part of the Antarctic mainland.\n\nThis was the second vessel to be named after Bransfield by BAS or its predecessors. The first was HMS \"Bransfield\", the original expedition ship for Operation Tabarin, a secret British expedition to Antarctica during World War Two. It established the first permanent British bases on the Antarctic Peninsula and became the Falkland Islands Dependencies Survey in 1945 (renamed BAS in 1962). This vessel was a wooden Norwegian sealer built in 1918 as the Veslekari, and renamed for the expedition. Her service with Tabarin was inglorious - she proved to be unseaworthy, and had to be replaced before the expedition left English waters in November 1943.\n\nIn 1993/94, while in the Weddell Sea \"Bransfield\" suffered an engine room fire.\n\nIn May 1999, she was sold to GC Rieber Shipping as part of the contract for the long-term charter of her replacement, . She was subsequently renamed \"Igenpearl\", and was scrapped in Mumbai in 2000.\n\nRRS \"Bransfield\" was BAS's main supply vessel for 29 years, from 1970/71 to 1998/99. She also had limited facilities for on-board research. There was a fully equipped hospital bay on board.\n\nFor much of her career her joint Masters were John Cole and Stewart Laurence. \"Bransfield\" represented NERC in the Review of the Fleet at Spithead in 1977, held to celebrate Queen Elizabeth II's jubilee.\n\n"}
{"id": "5766864", "url": "https://en.wikipedia.org/wiki?curid=5766864", "title": "RV Maurice Ewing", "text": "RV Maurice Ewing\n\nRV \"Maurice Ewing\" was a research vessel operated by the Lamont-Doherty Earth Observatory of Columbia University. It was retired in 2005 and replaced by RV \"Marcus Langseth\" in 2008. Although a multipurpose vessel, \"Maurice Ewing\"s notable capability was to collect multichannel seismic data.\n\n\"Maurice Ewing\" was named for William Maurice \"Doc\" Ewing, geophysicist and first director of Lamont Geological Observatory (now known as Lamont-Doherty Earth Observatory).\n\nThe vessel was later renamed several times: - Scan Resolution, Bergan Resolution, the Reflect Resolution, and the NORDIC BAHARI. Still to this day the vessel operates as a multi-streamer seismic research vessel.\n\n"}
{"id": "18490995", "url": "https://en.wikipedia.org/wiki?curid=18490995", "title": "STEPS Centre", "text": "STEPS Centre\n\nThe STEPS Centre (Social, Technological and Environmental Pathways to Sustainability) is an interdisciplinary global research and policy engagement hub at the University of Sussex. It is funded by the Economic and Social Research Council. The Centre brings together development studies with science and technology studies and was launched at Portcullis House in London on 25 June 2007 \n\nBy acknowledging the interactions between social, technological and environmental factors in diverse local settings the STEPS Centre seeks to help create more sustainable and socially just conditions for poorer people. Based at the Institute of Development Studies (IDS) and the Science Policy Research Unit (SPRU) at the University of Sussex in the UK, the Centre works with partners in Africa, Asia and Latin America.\n\nProfessor Ian Scoones is the director of the STEPS Centre and Professor Andy Stirling its co-director. Professor Melissa Leach stepped down as STEPS Director in 2014 to become Director of the Institute of Development Studies.\n\nThe STEPS Centre Advisory Board is chaired by Mike Hulme (King's College London) with members including Brian Wynne (CESAGEN, University of Lancaster), Carl Folke (Stockholm Resilience Centre), Dipak Gyawali (Nepal Academy of Science and Technology), Fred Pearce (science writer), Sue Hartley (Director, York Environmental Sustainability Institute), Suman Sahai (Convenor, Gene Campaign), and Thomas Lingard (Global External Affairs Director, Unilever).\n\nThe STEPS Centre brings together social scientists and natural scientists to work together to try and achieve a breakthrough in thinking and action for development. The Centre's unique ‘pathways’ approach interweaves social, technological and environmental conditions with dynamic change across three domains - food and agriculture; health and disease; water and sanitation - and three themes - dynamics; governance; designs.\n\nThrough linking across domains and themes in its projects, the STEPS Centre connects new theory with practical approaches in a bid to help provide sustainable opportunities for poor and marginalised people.\n\nThe STEPS Centre's pathways approach aims to understand the complex, non-linear interactions between social, technological and environmental systems. Some pathways may threaten poor peoples’ livelihoods and health while others create opportunities for sustainability.\n\nThe Centre aims to link social scientists, natural scientists and users to develop new tools and methods linking theory with practical solutions. It also offers teaching, in conjunction with IDS and SPRU, to help train a new generation of researchers on MA and PhD courses.\n\nA paper published in 2007 entitled Pathways to Sustainability: an Overview of the STEPS Centre Approach outlined the STEPS Centre approach to understanding dynamic systems and their governance. The paper laid out the ingredients of the STEPS Centre's work, including linking diverse social and natural science perspectives, connecting theory, policy and practice and an engaged, interactive approach to communications. Promoting pathways to Sustainability that meet the perspectives and priorities of poor and marginalised groups is at the heart of the pathways approach.\n\nAmong the STEPS Centre's projects are:\n\n•\"Innovation, Sustainability, Development: A New Manifesto\" (40 years on from the Sussex Manifesto)\n\n• \"Crop, disease and innovation in Kenya - Maize and farming system dynamics in areas affected by climate change\"\n\n• \"Urbanisation in Asia - urbanisation and sustainability on the expanding peri-urban fringe of Delhi, India\"\n\n• \"Rethinking regulation - assumptions and realities of drug and seed regulation in China and Argentina\"\n\n• \"Risk, uncertainty and technology - framing and responses to risks and uncertainties in areas of rapid scientific and technological advance\"\n\n• \"Epidemics, livelihoods and politics\" - HIV-AIDS, SARS, ‘avian flu, BSE - procedures for addressing epidemics that support rather than compromise poor people\n\nBy Leach. M, Scoones, I. and Stirling, A. (2010) \n\nBy Leach. M., Scoones, I. and Stirling, A. (2007) \n\nBy Scoones, I., Leach, M., Smith, A., Stagl, S., Stirling, A. and Thompson, J. (2007) \"\n\nBy Leach, M., Bloom, G., Ely, A., Nightingale, P., Scoones, I., Shah, E. and Smith, A. (2007) – \n\nBy Stirling, A., Leach, M., Mehta, L., Scoones, I., Smith, A., Stagl, S. and Thompson, J. (2007) \n\nBy Thompson, J., Millstone, E., Scoones, I., Ely, A., Marshall, F., Shah, E.and Stagl, S. (2007) \n\nBy Bloom, G., Edström, J., Leach, M., Lucas, H., MacGregor, H., Standing, H. and Waldman, L. (2007) \n\nBy Mehta, L., Marshall, F., Movik, S., Stirling, A., Shah, E., Smith, A. and Thompson, J. (2007) \nBy Krätli, S. (2008) The ISBN printed in the document (978 1 85864 699 5) is invalid, causing a checksum error.\n\nBy Melissa Leach, Ian Scoones (2006) Demos pamphlet \n\n"}
{"id": "12171843", "url": "https://en.wikipedia.org/wiki?curid=12171843", "title": "Soyuz-TMA", "text": "Soyuz-TMA\n\nThe Soyuz-TMA is a revision of the Soyuz spacecraft, superseded in 2010 by the Soyuz TMA-M. \n(T – транспортный – \"Transportnyi\" – meaning transport, M – модифицированный – \"Modifitsirovannyi\" – meaning modified, A – антропометрический, – \"Antropometricheskii\" meaning anthropometric). \nIt is used by the Russian Federal Space Agency for human spaceflight. The spacecraft features several changes to accommodate requirements requested by NASA in order to service the International Space Station, including more latitude in the height and weight of the crew and improved parachute systems. It is also the first expendable vehicle to feature a \"glass cockpit\". Soyuz-TMA looks identical to the earlier Soyuz-TM spacecraft on the outside, but interior differences allow it to accommodate taller occupants with new adjustable crew couches.\n\nA Soyuz spacecraft consists of three parts (from front to back):\n\n\nThe first two portions are habitable living space. By moving as much as possible into the orbital module, which does not have to be shielded or decelerated during atmospheric re-entry, the Soyuz three-part craft is both larger and lighter than the two-part Apollo spacecraft's command module. The Apollo command module had six cubic meters of living space and a mass of 5000 kg; the three-part Soyuz provided the same crew with nine cubic meters of living space, an airlock, and a service module for the mass of the Apollo capsule alone. This does not consider the orbital module, that could be used instead of the Apollo Lunar Module.\n\nSoyuz can carry up to three cosmonauts and provide life support for them for about 30 person days. The life support system provides a nitrogen/oxygen atmosphere at sea level partial pressures. The atmosphere is regenerated through KO cylinders, which absorb most of the CO and water produced by the crew and regenerates the oxygen, and LiOH cylinders which absorb leftover CO.\n\nThe vehicle is protected during launch by a nose fairing, which is jettisoned after passing through the atmosphere. It has an automatic docking system. The ship can be operated automatically, or by a pilot independently of ground control.\n\nThe forepart of the spacecraft is the orbital module (: бытовой отсек (BO), \"Bitovoy otsek\") also known as Habitation section. It houses all the equipment that will not be needed for reentry, such as experiments, cameras or cargo. Commonly, it is used as both eating area and lavatory. At its far end, it also contains the docking port. This module also contains a toilet, docking avionics and communications gear. On the latest Soyuz versions, a small window was introduced, providing the crew with a forward view.\n\nA hatch between it and the descent module can be closed so as to isolate it to act as an airlock if needed, cosmonauts exiting through its side port (at the bottom of this picture, near the descent module) on the launch pad, they have entered the spacecraft through this port.\n\nThis separation also lets the orbital module be customized to the mission with less risk to the life-critical descent module. The convention of orientation in zero gravity differs from that of the descent module, as cosmonauts stand or sit with their heads to the docking port.\n\nThe reentry module (: спускаемый аппарат (СА), \"Spuskaemiy apparat (SA)\") is used for launch and the journey back to Earth. It is covered by a heat-resistant covering to protect it during re-entry. It is slowed initially by the atmosphere, then by a braking parachute, followed by the main parachute which slows the craft for landing. At one meter above the ground, solid-fuel braking engines mounted behind the heat shield are fired to give a soft landing. One of the design requirements for the reentry module was for it to have the highest possible volumetric efficiency (internal volume divided by hull area). The best shape for this is a sphere, but such a shape can provide no lift, which results in a purely ballistic reentry. Ballistic reentries are hard on the occupants due to high deceleration and can't be steered beyond their initial deorbit burn. That is why it was decided to go with the \"headlight\" shape that the Soyuz uses — a hemispherical forward area joined by a barely angled conical section (seven degrees) to a classic spherical section heat shield. This shape allows a small amount of lift to be generated due to the unequal weight distribution. The nickname was coined at a time when nearly every automobile headlight was a circular paraboloid.\n\nAt the back of the vehicle is the service module (: приборно-агрегатный отсек, \"Priborno-Agregatniy Otsek (PAO)\"). It has an instrumentation compartment (: приборный отсек, \"Priborniy Otsek (PO)\"), a pressurized container shaped like a bulging can that contains systems for temperature control, electric power supply, long-range radio communications, radio telemetry, and instruments for orientation and control. The propulsion compartment (: агрегатный отсек, \"Agregatniy Otsek (AO)\"), a non-pressurized part of the service module, contains the main engine and a spare: liquid-fuel propulsion systems for maneuvering in orbit and initiating the descent back to Earth. The ship also has a system of low-thrust engines for orientation, attached to the intermediate compartment (: переходной отсек, \"Perekhodnoi Otsek (PkhO)\"). Outside the service module are the sensors for the orientation system and the solar array, which is oriented towards the sun by rotating the ship.\n\nBecause its modular construction differs from that of previous designs, the Soyuz has an unusual sequence of events prior to re-entry. The spacecraft is turned engine-forward and the main engine is fired for de-orbiting fully 180° ahead of its planned landing site. This requires the least propellant for re-entry, the spacecraft traveling on an elliptical Hohmann orbit to a point where it will be low enough in the atmosphere to re-enter.\n\nEarly Soyuz spacecraft would then have the service and orbital modules detach simultaneously. As they are connected by tubing and electrical cables to the descent module, this would aid in their separation and avoid having the descent module alter its orientation. Later Soyuz spacecraft detach the orbital module before firing the main engine, which saves even more propellant, enabling the descent module to return more payload. In no case can the orbital module remain in orbit as an addition to a space station, for the hatch enabling it to function as an airlock is part of the descent module.\n\nRe-entry firing is typically done on the \"dawn\" side of the Earth, so that the spacecraft can be seen by recovery helicopters as it descends in the evening twilight, illuminated by the sun when it is above the shadow of the Earth. Since the beginning of Soyuz missions to the ISS, only five have performed nighttime landings.\n\n\nThe final planned flight of the baseline Soyuz-TMA design was Soyuz TMA-22, launched November 14, 2011 from the Baikonur Cosmodrome's Gagarin's Start launch pad in Kazakhstan, at 04:14:03 UTC. The new modernized Soyuz TMA-M series was developed and built by RKK Energia as an upgrade of the baseline Soyuz-TMA. Thirty-six obsolete pieces of equipment have been replaced with 19 new-generation devices and the vehicle's total mass has been reduced by 70 kilograms (154 lbs). In particular, the reliable but heavy (70 kg) Argon digital computer and analogue systems, which had been used on Soyuz ships for more than 30 years, has been replaced with a new digital computer, the TsVM-101, and digital avionics. Power consumption has been reduced throughout the ship. There are also changes to the spacecraft's structure, such as replacing the magnesium alloy used in the instrument module frame with aluminium alloy, to make the ship easier to manufacture.\n\nThe modernized Soyuz will also enable engineers to test new equipment which may also be used in Russia's next generation manned space ship that is currently under development.\n\nNASA astronaut Scott Kelly, part of Soyuz TMA-01M's crew, praised the ship's new displays, saying that they make flying easier and less operator intensive.\n\nTwo flight development flights were launched: Soyuz TMA-01M on Oct 7, 2010 and Soyuz TMA-02M on Jun 7, 2011. The third ship, Soyuz TMA-03M, launched on 21 December 2011 and was used for qualification tests. In addition to verifying the nominal operation of the spaceship, the testing included verification of off-nominal modes, such as manual attitude control, issuing of orbital maneuvering pulses using four berthing and attitude thrusters, and flying around the ISS in manual control mode.\n\nThe TMA-M variant flew 20 missions at a cadence of four times a year before being replaced in 2016 by the Soyuz MS. For the launch schedule, see List of Russian manned space missions.\n\n\n"}
{"id": "4517642", "url": "https://en.wikipedia.org/wiki?curid=4517642", "title": "Sunrise equation", "text": "Sunrise equation\n\nThe sunrise equation as follows can be used to derive the time of sunrise and sunset for any solar declination and latitude in terms of local solar time when sunrise and sunset actually occur:\n\nwhere:\n\nThe Earth rotates at an angular velocity of 15°/hour. Therefore, the expression formula_5, or formula_6 to the −0.83° in the numerator's sine term. This corrects for both apparent dip and terrestrial refraction. For example, for an observer at 10,000 feet, add (−115°/60°) or about −1.92° to −0.83°.\n\nwhere:\n\n\n"}
{"id": "30400", "url": "https://en.wikipedia.org/wiki?curid=30400", "title": "Torque", "text": "Torque\n\nTorque, moment, or moment of force is rotational force. Just as a linear force is a push or a pull, a torque can be thought of as a twist to an object. In three dimensions, the torque is a pseudovector; for point particles, it is given by the cross product of the position vector (distance vector) and the force vector.\n\nThe symbol for torque is typically formula_1, the lowercase Greek letter \"tau\". When it is called moment of force, it is commonly denoted by \"M\".\n\nThe magnitude of torque of a rigid body depends on three quantities: the force applied, the \"lever arm vector\" connecting the origin to the point of force application, and the angle between the force and lever arm vectors. In symbols:\n\nwhere\n\nThe SI unit for torque is N⋅m. For more on the units of torque, see Units.\n\nTorque is referred to using different vocabulary depending on geographical location and field of study. This article refers to the definition used in US physics in its usage of the word \"torque\". In the UK and in US mechanical engineering, torque is referred to as \"moment of force\", usually shortened to \"moment\". In US physics and UK physics terminology these terms are interchangeable, unlike in US mechanical engineering, where the term \"torque\" is used for the closely related \"resultant moment of a couple\".\n\n\"Torque\" is defined mathematically as the rate of change of angular momentum of an object. The definition of torque states that one or both of the angular velocity or the moment of inertia of an object are changing. \"Moment\" is the general term used for the tendency of one or more applied forces to rotate an object about an axis, but not necessarily to change the angular momentum of the object (the concept which is called \"torque\" in physics). For example, a rotational force applied to a shaft causing acceleration, such as a drill bit accelerating from rest, results in a moment called a \"torque\". By contrast, a lateral force on a beam produces a moment (called a bending moment), but since the angular momentum of the beam is not changing, this bending moment is not called a \"torque\". Similarly with any force couple on an object that has no change to its angular momentum, such moment is also not called a \"torque\".\n\nThis article follows the US physics terminology by calling all moments by the term \"torque\", whether or not they cause the angular momentum of an object to change.\n\nThe concept of torque, also called moment or couple, originated with the studies of Archimedes on levers. The term \"torque\" was apparently introduced into English scientific literature by James Thomson, the brother of Lord Kelvin, in 1884.\n\nA force applied at a right angle to a lever multiplied by its distance from the lever's fulcrum (the length of the lever arm) is its torque. A force of three newtons applied two metres from the fulcrum, for example, exerts the same torque as a force of one newton applied six metres from the fulcrum. The direction of the torque can be determined by using the right hand grip rule: if the fingers of the right hand are curled from the direction of the lever arm to the direction of the force, then the thumb points in the direction of the torque.\n\nMore generally, the torque on a particle (which has the position r in some reference frame) can be defined as the cross product:\nwhere r is the particle's position vector relative to the fulcrum, and F is the force acting on the particle. The magnitude \"τ\" of the torque is given by\nwhere \"r\" is the distance from the axis of rotation to the particle, \"F\" is the magnitude of the force applied, and \"θ\" is the angle between the position and force vectors. Alternatively,\nwhere \"F\" is the amount of force directed perpendicularly to the position of the particle. Any force directed parallel to the particle's position vector does not produce a torque.\n\nIt follows from the properties of the cross product that the \"torque vector\" is perpendicular to both the \"position\" and \"force\" vectors. The \"torque vector\" points along the axis of the rotation that the \"force vector\" (starting from rest) would initiate. The resulting \"torque vector\" direction is determined by the right-hand rule.\n\nThe unbalanced torque on a body along axis of rotation determines the rate of change of the body's angular momentum,\nwhere L is the angular momentum vector and \"t\" is time. If multiple torques are acting on the body, it is instead the net torque which determines the rate of change of the angular momentum:\n\nFor the motion of a point particle,\nwhere is the moment of inertia and ω is the angular velocity. It follows that\nwhere α is the angular acceleration of the particle, and \"p\" is the radial component of its linear momentum. This equation is the rotational analogue of Newton's Second Law for point particles, and is valid for any type of trajectory. Note that although force and acceleration are always parallel and directly proportional, the torque τ need not be parallel or directly proportional to the angular acceleration α. This arises from the fact that although mass is always conserved, the moment of inertia in general is not.\n\nThe definition of angular momentum for a single particle is:\n\nwhere \"×\" indicates the vector cross product, p is the particle's linear momentum, and r is the displacement vector from the origin (the origin is assumed to be a fixed location anywhere in space). The time-derivative of this is:\n\nThis result can easily be proven by splitting the vectors into components and applying the product rule. Now using the definition of force formula_17 (whether or not mass is constant) and the definition of velocity formula_18\n\nThe cross product of momentum formula_20 with its associated velocity formula_21 is zero because velocity and momentum are parallel, so the second term vanishes.\n\nBy definition, torque τ = r × F. Therefore, torque on a particle is \"equal\" to the\nfirst derivative of its angular momentum with respect to time.\n\nIf multiple forces are applied, Newton's second law instead reads , and it follows that\n\nThis is a general proof.\n\nTorque has dimension force times distance, symbolically . Official SI literature suggests using the unit \"newton metre\" (N⋅m) or the unit \"joule per radian\". The unit \"newton metre\" is properly denoted N⋅m or N m. This avoids ambiguity with mN, millinewtons.\n\nThe SI unit for energy or work is the joule. It is dimensionally equivalent to a force of one newton acting over a distance of one metre, but it is not used for torque. Energy and torque are entirely different concepts, so the practice of using different unit names (i.e., reserving newton metres for torque and using only joules for energy) helps avoid mistakes and misunderstandings. The dimensional equivalence of these units is not simply a coincidence: a torque of 1 N⋅m applied through a full revolution will require an energy of exactly 2π joules. Mathematically,\n\nwhere \"E\" is the energy, \"τ\" is magnitude of the torque, and \"θ\" is the angle moved (in radians). This equation motivates the alternate unit name \"joules per radian\".\n\nIn Imperial units, \"pound-force-feet\" (lbf⋅ft), \"foot-pounds-force\", \"inch-pounds-force\", \"ounce-force-inches\" (ozf⋅in) are used, and other non-SI units of torque includes \"metre-kilograms-force\". For all these units, the word \"force\" is often left out. For example, abbreviating \"pound-force-foot\" to simply \"pound-foot\" (in this case, it would be implicit that the \"pound\" is pound-force and not pound-mass). This is an example of the confusion caused by the use of English units that may be avoided with SI units because of the careful distinction in SI between force (in newtons) and mass (in kilograms).\n\nTorque is sometimes listed with units that do not make dimensional sense, such as the gram-centimeter. In this case, \"gram\" should be understood as the force given by the weight of 1 gram on the surface of the Earth (i.e. 0.00980665 N). The surface of the Earth has a standard gravitational field strength of 9.80665 N/kg.\n\nA very useful special case, often given as the definition of torque in fields other than physics, is as follows:\n\nThe construction of the \"moment arm\" is shown in the figure to the right, along with the vectors r and F mentioned above. The problem with this definition is that it does not give the direction of the torque but only the magnitude, and hence it is difficult to use in three-dimensional cases. If the force is perpendicular to the displacement vector r, the moment arm will be equal to the distance to the centre, and torque will be a maximum for the given force. The equation for the magnitude of a torque, arising from a perpendicular force:\n\nFor example, if a person places a force of 10 N at the terminal end of a wrench that is 0.5 m long (or a force of 10 N exactly 0.5 m from the twist point of a wrench of any length), the torque will be 5 N⋅m – assuming that the person moves the wrench by applying force in the plane of movement and perpendicular to the wrench.\n\nFor an object to be in static equilibrium, not only must the sum of the forces be zero, but also the sum of the torques (moments) about any point. For a two-dimensional situation with horizontal and vertical forces, the sum of the forces requirement is two equations: Σ\"H\" = 0 and Σ\"V\" = 0, and the torque a third equation: Σ\"τ\" = 0. That is, to solve statically determinate equilibrium problems in two-dimensions, three equations are used.\n\nWhen the net force on the system is zero, the torque measured from any point in space is the same. For example, the torque on a current-carrying loop in a uniform magnetic field is the same regardless of your point of reference. If the net force formula_26 is not zero, and formula_27 is the torque measured from formula_28, then the torque measured from formula_29 is …\nformula_30\n\nTorque is part of the basic specification of an engine: the power output of an engine is expressed as its torque multiplied by its rotational speed of the axis. Internal-combustion engines produce useful torque only over a limited range of rotational speeds (typically from around 1,000–6,000 rpm for a small car). The varying torque output over that range can be measured with a dynamometer, and shown as a torque curve.\n\nSteam engines and electric motors tend to produce maximum torque close to zero rpm, with the torque diminishing as rotational speed rises (due to increasing friction and other constraints). Reciprocating steam engines and electric motors can start heavy loads from zero RPM without a clutch.\n\nIf a force is allowed to act through a distance, it is doing mechanical work. Similarly, if torque is allowed to act through a rotational distance, it is doing work. Mathematically, for rotation about a fixed axis through the center of mass,\nwhere \"W\" is work, \"τ\" is torque, and \"θ\" and \"θ\" represent (respectively) the initial and final angular positions of the body.\n\nThe work done by a variable force acting over a finite linear displacement formula_32 is given by integrating the force with respect to an elemental linear displacement formula_33\n\nHowever, the infinitesimal linear displacement formula_33 is related to a corresponding angular displacement formula_36 and the radius vector formula_37 as \n\nSubstitution in the above expression for work gives\n\nThe expression formula_40 is a scalar triple product given by formula_41. An alternate expression for the same scalar triple product is\n\nBut as per the definition of torque,\n\nCorresponding substitution in the expression of work gives,\n\nSince the parameter of integration has been changed from linear displacement to angular displacement, the limits of the integration also change correspondingly, giving\n\nIf the torque and the angular displacement are in the same direction, then the scalar product reduces to a product of magnitudes; i.e., formula_46 giving\n\nIt follows from the work-energy theorem that \"W\" also represents the change in the rotational kinetic energy \"E\" of the body, given by\n\nwhere \"I\" is the moment of inertia of the body and \"ω\" is its angular speed.\n\nPower is the work per unit time, given by\nwhere \"P\" is power, \"τ\" is torque, \"ω\" is the angular velocity, and ⋅ represents the scalar product.\n\nAlgebraically, the equation may be rearranged to compute torque for a given angular speed and power output. Note that the power injected by the torque depends only on the instantaneous angular speed – not on whether the angular speed increases, decreases, or remains constant while the torque is being applied (this is equivalent to the linear case where the power injected by a force depends only on the instantaneous speed – not on the resulting acceleration, if any).\n\nIn practice, this relationship can be observed in bicycles: Bicycles are typically composed of two road wheels, front and rear gears (referred to as sprockets) meshing with a circular chain, and a derailleur mechanism if the bicycle's transmission system allows multiple gear ratios to be used (i.e. multi-speed bicycle), all of which attached to the frame. A cyclist, the person who rides the bicycle, provides the input power by turning pedals, thereby cranking the front sprocket (commonly referred to as chainring). The input power provided by the cyclist is equal to the product of cadence (i.e. the number of pedal revolutions per minute) and the torque on spindle of the bicycle's crankset. The bicycle's drivetrain transmits the input power to the road wheel, which in turn conveys the received power to the road as the output power of the bicycle. Depending on the gear ratio of the bicycle, a (torque, rpm) pair is converted to a (torque, rpm) pair. By using a larger rear gear, or by switching to a lower gear in multi-speed bicycles, angular speed of the road wheels is decreased while the torque is increased, product of which (i.e. power) does not change.\n\nConsistent units must be used. For metric SI units, power is watts, torque is newton metres and angular speed is radians per second (not rpm and not revolutions per second).\n\nAlso, the unit newton metre is dimensionally equivalent to the joule, which is the unit of energy. However, in the case of torque, the unit is assigned to a vector, whereas for energy, it is assigned to a scalar.\n\nA conversion factor may be necessary when using different units of power or torque. For example, if rotational speed (revolutions per time) is used in place of angular speed (radians per time), we multiply by a factor of 2 radians per revolution. In the following formulas, \"P\" is power, \"τ\" is torque, and \"ν\" (Greek letter nu) is rotational speed.\n\nShowing units:\n\nDividing by 60 seconds per minute gives us the following.\n\nwhere rotational speed is in revolutions per minute (rpm).\n\nSome people (e.g., American automotive engineers) use horsepower (imperial mechanical) for power, foot-pounds (lbf⋅ft) for torque and rpm for rotational speed. This results in the formula changing to:\n\nThe constant below (in foot pounds per minute) changes with the definition of the horsepower; for example, using metric horsepower, it becomes approximately 32,550.\n\nUse of other units (e.g., BTU per hour for power) would require a different custom conversion factor.\n\nFor a rotating object, the \"linear distance\" covered at the circumference of rotation is the product of the radius with the angle covered. That is: linear distance = radius × angular distance. And by definition, linear distance = linear speed × time = radius × angular speed × time.\n\nBy the definition of torque: torque = radius × force. We can rearrange this to determine force = torque ÷ radius. These two values can be substituted into the definition of power:\n\nThe radius \"r\" and time \"t\" have dropped out of the equation. However, angular speed must be in radians, by the assumed direct relationship between linear speed and angular speed at the beginning of the derivation. If the rotational speed is measured in revolutions per unit of time, the linear speed and distance are increased proportionately by 2 in the above derivation to give:\n\nIf torque is in newton metres and rotational speed in revolutions per second, the above equation gives power in newton metres per second or watts. If Imperial units are used, and if torque is in pounds-force feet and rotational speed in revolutions per minute, the above equation gives power in foot pounds-force per minute. The horsepower form of the equation is then derived by applying the conversion factor 33,000 ft⋅lbf/min per horsepower:\n\nbecause formula_57\n\nThe Principle of Moments, also known as Varignon's theorem (not to be confused with the geometrical theorem of the same name) states that the sum of torques due to several forces applied to \"a single\" point is equal to the torque due to the sum (resultant) of the forces. Mathematically, this follows from:\n\nTorque can be multiplied via three methods: by locating the fulcrum such that the length of a lever is increased; by using a longer lever; or by the use of a speed reducing gearset or gear box. Such a mechanism multiplies torque, as rotation rate is reduced.\n\n"}
{"id": "479158", "url": "https://en.wikipedia.org/wiki?curid=479158", "title": "USS Sargo (SSN-583)", "text": "USS Sargo (SSN-583)\n\nUSS \"Sargo\" (SSN-583), a \"Skate\"-class nuclear-powered submarine, was the second ship of the United States Navy to be named for the sargo, a food and game fish of the porgy family, inhabiting coastal waters of the southern United States.\n\nThe contract to build her was awarded to Mare Island Naval Shipyard in Vallejo, California, on 29 September 1955 and her keel was laid down on 21 February 1956. She was launched on 10 October 1957, sponsored by the wife of Rear Admiral Frank T. Watkins, and commissioned on 1 October 1958 with Commander Daniel P. Brooks in command.\n\nPrior to completion, \"Sargo\" was designated for an Arctic cruise. She received alterations to strengthen her sail before she left the building yard. Further modifications followed her 19,000-mile (35,200 km) Pacific shakedown cruise. After her arrival at her home port, Pearl Harbor, on 1 October 1959, scientific instruments were installed to assist her in navigating under the shifting polar ice with its potentially hazardous submerged pressure ridges; in locating open leads and thin ice through which to surface, and in gathering oceanographic and hydrographic data. November and December 1959 brought intensive training programs and the embarkation of scientific specialists; and, on 18 January 1960, \"Sargo\", under the command of Lieutenant Commander J.H. Nicholson, cleared Pearl Harbor and headed north to make a submerged exploration of the Arctic Ocean.\n\nBy 25 January, \"Sargo\" had reached the vicinity of St. Matthews Island where she found ice, block and brash and where, after rendezvousing with the United States Navy icebreaker \"USS Staten Island\" (AGB-5) she made her first stationary dive while surrounded by ice. On 29 January, she passed the Diomede Islands and crossed the Arctic Circle; and, on 9 February, she arrived under the North Pole.\n\nMaking her first pass under the pole at 0934, the submarine began a clover-leaf search for thin ice and at 1049 she surfaced, according to her log, 25 feet (8 m) from the pole. Later the same day, the Hawaiian flag was raised at the pole, and, on the morning of 10 February, \"Sargo\" submerged and set a course for the Canadian Arctic Archipelago and a rendezvous with ice island T-3.\n\nCollecting hydrographic data as she progressed, she reached T-3 on 17 February. Thence, after conducting tests in cooperation with scientists on the ice island, she got underway for the Bering Strait, the Aleutian Islands, and Hawaii. On 3 March 1960, \"Sargo\", having covered over 11,000 miles (20,000 km), 6,003 miles (11,118 km) under ice, returned to Pearl Harbor with new data on Arctic ice, Arctic waters, and the physiography of the Arctic Basin. The latter included information on Alpha Ridge and on the presence of deep water areas at the western end of the northwest passage. For this cruise the \"Sargo\" earned the Navy Unit Commendation, the second highest award possible for a ship of the United States Navy.\n\nRepairs took \"Sargo\" into April. At the end of that month, she resumed operations in the Hawaiian area with a demonstration cruise for the King of Nepal.\n\nOn 14 June, the submarine was docked in Pearl Harbor, preparing to take Bhumibol Adulyadej and his wife Mom Rajawongse Sirikit Kitiyakara, the King and Queen of Thailand on a cruise the next day. \"Sargo\" was charging her oxygen tanks when the oxygen line, which entered the submarine through the stern torpedo room hatch, developed a leak and a fire ignited. Two Mark 37 torpedo warheads detonated \"low-order\", and the fire spread dramatically, killing the crewman tending the oxygen line, machinist's mate third class James E. Smallwood. The fire, fed by the pressurized oxygen, shot flames over 100 feet (30 m) in the air through the hatch. When the combined forces of the shipyard and the boat's crew were unable to control the fire, \"Sargo\"'s officers took the submarine a short distance from the dock and dove with the stern room hatch open. The fire was extinguished, and \"Sargo\" bottomed in the channel. A floating crane raised the \"Sargo\", and repairs took three months in drydock.\n\nJames E. Smallwood MM3(SS), lost his life in the fire while taking action to save the ship. He was awarded, posthumously, the Navy and Marine Corps Medal for his heroic actions and other crew members were also awarded medals and letters of commendation for outstanding courage over and above the call of duty. On 15 April 1987, Submarine Base Pearl Harbor opened a new 17-story Bachelor Enlisted Quarters, which was dedicated on 26 February 1988 in the memory of Smallwood and the sacrifice of his life while performing in the service of his country.\n\nFrom October through December 1960, \"Sargo\" again conducted type training exercises.\n\nIn 1961 \"Sargo\" assumed a more regular schedule. On 19 January, she sailed for the Philippines on her first deployment with the Seventh Fleet. In the western Pacific into May, she participated in exercises to enhance the antisubmarine warfare readiness of hunter-killer groups and visited Sydney, for the 19th Annual Coral Sea Celebration. On 25 May, she returned to Pearl Harbor. Upkeep and local operations took her into late July, when she began a two-month training cruise. In November, she moved east, to California, to participate in a demonstration for the Chief of Naval Operations and foreign attaches. She then returned to Pearl Harbor for holiday leave and upkeep. During the late winter and early spring of 1962, \"Sargo\" made another extended cruise in the western Pacific, again earning a Navy Unit Commendation for her effort.\n\nLocal operations and upkeep followed her return to Pearl Harbor; and, in July, she entered the naval shipyard there for an overhaul which lasted through the winter of 1962 and 1963. During the work, she became the first nuclear ship to be refueled at that shipyard. In mid-summer 1963, she commenced an extended cruise to the western Pacific, and, in October she returned to Hawaii for six months of local operations.\n\nFrom April to October 1964, \"Sargo\" once again deployed to the western Pacific; and, during August, she was called on to support operations resulting from the Gulf of Tonkin Incident. After her return to Hawaii, local operations and upkeep took her into the next year. In April 1965, she commenced another cruise in the western Pacific, and, in June, she resumed operations in the eastern Pacific. Five months later, she again moved westward across the Pacific; and, in February 1966, she returned to Hawaii to enter the naval shipyard at Pearl Harbor where she remained for the next two years, undergoing overhaul and refueling. Between 1963 and 1965 \"Sargo\" earned three more Navy Unit Commendations.\n\nOn 5 April 1968, \"Sargo\" left the shipyard. She had been overhauled and her third reactor core had been installed. Refresher training followed and, in June she resumed her previous schedule with an extended cruise in the western Pacific. Since that time, into 1974, she has maintained a schedule of eastern and western Pacific cruises and training operations, including joint British, Australian, and American exercises in the South China Sea in January 1969.\n\nDecommissioned and stricken from the Naval Vessel Register on 21 April 1988, ex-\"Sargo\" entered the Navy's Nuclear-Powered Ship and Submarine Recycling Program on 14 April 1994; recycling was completed on 5 April 1995.\n\nWorks cited\n"}
{"id": "14573316", "url": "https://en.wikipedia.org/wiki?curid=14573316", "title": "Valerie Hall", "text": "Valerie Hall\n\nValerie Hall (1946-2016) was a Professor in Palaeoecology at Queen's University Belfast until her retirement in 2010, after which she remained a Professor Emerita. She gained a 2:2 in botany at Queen's University Belfast in 1968 and a PhD in Palaeoecology in 1989. She has produced a number of publications of which the best known may be Flora Hibernica, which she co-wrote along with J. Pilcher and published in 2001.\n\nShe was the Director of Research in the School of Archaeology-Palaeoecology at Queen's University Belfast.\n\nValerie was Vice President of the INQUA Commission for Tephrochronology and Volcanology and was the Honorary Company Secretary of the Irish Naturalists' Journal Ltd.\n\nShe produced 30 peer-reviewed papers as listed in Scopus. The most cited is \"Dates of Holocene Icelandic volcanic eruptions from tephra layers in Irish peats\" Pilcher, J.R., Hall, V.A., McCormac, F.G. \"Holocene\" 5 (1), pp. 103–110, (1995), which has been cited 85 times by March 2010.\n\n"}
{"id": "1176517", "url": "https://en.wikipedia.org/wiki?curid=1176517", "title": "World Community Grid", "text": "World Community Grid\n\nWorld Community Grid (WCG) is an effort to create the world's largest public computing grid to tackle scientific research projects that benefit humanity. Launched on November 16, 2004, it is co-ordinated by IBM with client software currently available for Windows, Linux, macOS, and Android operating systems.\n\nUsing the idle time of computers around the world, World Community Grid's research projects have analyzed aspects of the human genome, HIV, dengue, muscular dystrophy, cancer, influenza, Ebola, virtual screening, rice crop yields, and clean energy. As of March 2018, the organization has partnered with 449 other companies and organizations to assist in its work, has over 52,000 active registered users, and a combined total run time of over 1.5 million years.\n\nIn 2003, IBM and other research participants sponsored the \"Smallpox Research Grid Project\" to accelerate the discovery of a cure for smallpox. The smallpox study used a massive distributed computing grid to analyze compounds' effectiveness against smallpox. The project allowed scientists to screen 35 million potential drug molecules against several smallpox proteins to identify good candidates for developing into smallpox treatments. In the first 72 hours, 100,000 results were returned. By the end of the project, 44 strong treatment candidates had been identified. Based on the success of the Smallpox study, IBM announced on the creation of World Community Grid on November 16, 2004, with the goal of creating a technical environment where other humanitarian research could be processed.\n\nWorld Community Grid initially only supported Windows, using the proprietary Grid MP software from United Devices which powered the grid.org distributed computing projects. Demand for Linux support led to the addition in November 2005 of open source Berkeley Open Infrastructure for Network Computing (BOINC) grid technology which powers projects such as SETI@home and Climateprediction, and Mac OS X and Linux support was added since the introduction of BOINC. In 2007, the World Community Grid migrated from Grid MP to BOINC for all of its supported platforms.\n\nAs of October 2014, World Community Grid had over 65,000 active user accounts, with over 249,000 active devices. Over the course of the project, more than 1,000,000 cumulative years of computing time have been donated, and over 2 billion workunits have been completed.\n\nThe World Community Grid software uses the idle time of Internet-connected computers to perform research calculations. Users install WCG client software onto their computers. This software works in the background, using spare system resources to process work for WCG. When a piece of work or \"workunit\" is completed, the client software sends it back to WCG over the Internet and downloads a new workunit. To ensure accuracy, the WCG servers send out multiple copies of each workunit. Then, when the results are received, they are collected and validated against each other. \n\nWhile many public computing grids such as SETI@home and Folding@home are devoted to a single project, World Community Grid offers multiple humanitarian projects under a single umbrella.\nUsers are included in a subset of projects by default, but may opt out of projects as they choose.\n\nWhen World Community Grid launched, they used the proprietary Grid MP client from United Devices. After adding support for the open source BOINC client in 2005, World Community Grid eventually discontinued the Grid MP client and consolidated on the BOINC platform in 2008.\n\nEven though WCG makes use of open source client software, the actual applications that perform the scientific calculations may not be. However, several of the science applications are available under a free license, although the source is not available directly from WCG.\n\nThe World Community Grid software increases CPU usage by consuming unused processing time; in the late 1990s and early 2000s, such calculations were meant to reduce \"wasted\" CPU cycles. With modern CPUs, where dynamic frequency scaling is prevalent, increased usage makes the processor run at higher frequency, increasing power usage and heating counter to power management. Additionally, because of an increasing focus on power performance, or performance per watt, connecting old/inefficient computers to the grid will increase the total/average power required to complete the same calculations.\n\nThe BOINC client avoids slowing the computer by using a variety of limits that suspend computation when there are insufficient free resources. Unlike other BOINC projects, World Community Grid set the BOINC defaults conservatively, making the chances of computer damage extremely small. The default CPU throttle is 60%. The throttle is coarse-grained; for example, if usage is set to 60% it will work at 100% for 3 seconds, then at 0% for 2 seconds, resulting in an average decrease of processor use.\n\nAn add-on program for Windows computers – TThrottle – can solve the problem of overheating by directly limiting the BOINC project's use of the host computer. It does this by measuring the CPU and/or the GPU temperature and adjusts the run time accordingly. It also uses a shorter switching time of less than one second, resulting in less temperature change during switching.\n\nThe contributions of each user are recorded and user contribution statistics are publicly available. Due to the fact that the processing time of each workunit varies from computer to computer, depending on the difficulty of the workunit, the speed of the computer, and the amount of idle resources available, contributions are usually measured in terms of \"points\". Points are awarded for each workunit depending on the effort required to process it.\n\nUpon completing a workunit, the BOINC client will request the number of points it thinks it deserves based on software benchmarks (\"see BOINC Credit System#Cobblestones\"). Since multiple computers process the same workunit to ensure accuracy, the World Community Grid servers can look at the points claimed by each of those computers. The WCG servers disregard statistical outliers, average the remaining values and award the resulting number of points to each computer.\n\nWithin the grid, users may join teams that have been created by organizations, groups, or individuals. Teams allow for a heightened sense of community identity and can also inspire competition. As teams compete against each other, more work is done for the grid overall.\n\nWorld Community Grid recognizes companies and organizations as \"partners\" if they promote WCG within their company or organization. As of March 2018, WCG had 449 partners.\n\nAlso, as part of its commitment to improving human health and welfare, the results of all computations completed on World Community Grid are released into the public domain and made available to the scientific community.\n\nSince its launch, more than twenty projects have run in the World Community Grid. Some of the results include:\n\n\nFightAIDS@Home (launched November 19, 2005) was World Community Grid's second project and its first to target a single disease. Each individual computer processes one potential drug molecule and tests how well it would dock with HIV protease, acting as a protease inhibitor. Scripps Research Institute published its first peer-reviewed scientific paper about the results of FightAIDS@Home on April 21, 2007. This paper explains that the results up to that point will primarily be used to improve the efficiency of future FightAIDS@Home calculations.\n\nMapping Cancer Markers (launched November 8, 2013). The project aims to identify the markers associated with various types of cancer, and is analyzing millions of data points collected from thousands of healthy and cancerous patient tissue samples. These include tissues with lung, ovarian, prostate, pancreatic and breast cancers. By comparing these different data points, researchers aim to identify patterns of markers for different cancers and correlate them with different outcomes, including responsiveness to various treatment options. The project is focusing on 4 types of cancer, with the first focus being on lung cancer, and will move on to ovarian cancer, prostate cancer and sarcoma.\n\nOutsmart Ebola Together is a collaboration with the Scripps Research Institute to help find chemical compounds to fight Ebola Virus Disease. It was launched on 3 December 2014. The aim is to block crucial steps in the life cycle of the virus, by finding drugs with high binding affinity with certain of its proteins. There are two targets: a surface protein used by the virus to infect human cells, and \"transformer\" proteins which change shape to carry out different functions.\n\nFightAIDS@Home Phase 2 (launched September 30, 2015) is looking more closely at the results of Phase 1. The project has two goals in the early experiments; the simulation architecture is functioning correctly and giving reliable results, and using BEDAM and AutoDock together provides better results than using just BEDAM or AutoDock.\n\nHelp Stop TB was launched in March 2016 to help combat tuberculosis, a disease caused by a bacterium that is evolving resistance to currently available treatments. The computations of this project target mycolic acids in the bacterium's protective coat, simulating the behavior of these molecules in their many configurations to better understand how they offer protection to the bacteria.\n\nOpenZika was launched on May 18, 2016 to help combat the Zika virus. The project targets proteins that is believed the Zika virus uses to survive and spread in the body, based on known results from similar diseases like the dengue virus and yellow fever. These results will help researchers develop an anti-Zika drug.\n\nStarting January 2017, the Smash Childhood Cancer project builds on the work from the Help Fight Childhood Cancer project by looking for drug candidates targeting additional childhood cancers.\n\nMicrobiome Immunity Project (launched August 2017) is a study of proteins in bacteria located in and on the human body; the human microbiome, which is made of around 3 million separate bacterial genes. By learning bacteria genes, their individual shapes can be known, and each physical shape determines the function of bacteria. Collaborative institutions includes the University of California San Diego, Broad Institute of MIT and Harvard, and the Simons Foundation's Flatiron Institute.\n\nThe first project launched on World Community Grid was the Human Proteome Folding Project, or HPF1, which aims to predict the structure of human proteins. The project was launched on November 16, 2004, and completed on July 18, 2006. This project was unique in that computation was done in tandem with the grid.org distributed computing project. Devised by Richard Bonneau at the Institute for Systems Biology, the project used grid computing to produce the likely structures for each of the proteins using a Rosetta Score. From these predictions, researchers hope to predict the function of the myriad proteins. This increased understanding of the human proteins could prove vital in the search for cures to human diseases. Computing for this project was officially completed on July 18, 2006. Research results for the yeast portion of HPF1 have been published.\n\nHuman Proteome Folding - Phase 2 (HPF2) (launched June 23, 2006) was the third project to run on World Community Grid, and completed in 2013. This project, following on from HPF1, focused on human-secreted proteins, with special focus on biomarkers and the proteins on the surface of cells as well as Plasmodium, the organism that causes malaria. HPF2 generates higher-resolution protein models than HPF1. Though these higher-resolution models are more useful, they also require more processing power to generate.\n\nIn a July 2012 status report, the project scientists reported that the results generated by the WCG calculations are being used by Dr. Markus Landthaler of the Max Delbruch Center for Molecular Medicine (MDC) in Berlin. The HPF2 results helped Dr. Markus Landthaler and his collaborators in writing up a new paper on \"The mRNA-Bound Proteome and Its Global Occupancy Profile on Protein-Coding Transcripts\" \n\nThe Help Defeat Cancer project seeks to improve the ability of medical professionals to determine the best treatment options for patients with breast, head, or neck cancer. The project was launched on July 20, 2006, and completed in April 2007. The project worked by identifying visual patterns in large numbers of tissue microarrays taken from archived tissue samples. By correlating the pattern data with information about treatment and patient outcome, the results of this project could help provide better targeted treatment options.\n\nThe Genome Comparison project is sponsored by the Brazilian research institution Fiocruz. The project was launched on November 21, 2006, and completed on July 21, 2007. The project seeks to compare gene sequences of different organisms against each other in order to find similarities between them. Scientists hope to discover what purpose a particular gene sequence serves in a particular function of one organism, via comparing it to a similar gene sequence of known function in another organism.\n\nHelp Cure Muscular Dystrophy is run by Décrypthon, a collaboration between French Muscular Dystrophy Association, French National Center for Scientific Research and IBM. Phase 1 was launched on December 19, 2006, and completed on June 11, 2007. The project investigated protein–protein interactions for 40,000 proteins whose structures are known, with particular focus on those proteins that play a role in neuromuscular diseases. The database of information produced will help researchers design molecules to inhibit or enhance binding of particular macromolecules, hopefully leading to better treatments for muscular dystrophy and other neuromuscular diseases. This project was available only to agents running the Grid MP client, making it unavailable to users running BOINC.\n\nDiscovering Dengue Drugs – Together was sponsored by scientists at the University of Texas and the University of Chicago and will run in two phases. Phase 1, launched August 21, 2007, used AutoDock 2007 (the same software used for FightAIDS@Home) to test potential antiviral drugs (through NS3 protease inhibition) against viruses from the family flaviviridae and completed on August 11, 2009. Phase 2 \"[uses] a more computationally intensive program to screen the candidates that make it through Phase 1.\" The drug candidates that make it through Phase 2 will then be lab-tested.\n\nThe mission of AfricanClimate@Home was to develop more accurate climate models of specific regions in Africa. It was intended to serve as a basis for understanding how the climate will change in the future so that measures designed to alleviate the adverse effects of climate change could be implemented. World Community Grid's tremendous computing power was used to understand and reduce the uncertainty with which climate processes were simulated over Africa. Phase 1 of African Climate@Home launched on September 3, 2007, and ended in July 2008.\n\nHelp Conquer Cancer project (launched November 1, 2007) is sponsored by the Ontario Cancer Institute (OCI), Princess Margaret Hospital and University Health Network of Toronto, Canada. The project involves X-ray crystallography. The mission of Help Conquer Cancer is to improve the results of protein X-ray crystallography, which helps researchers not only annotate unknown parts of the human proteome, but importantly improves their understanding of cancer initiation, progression and treatment.\n\nThe HCC project was the first WCG project benefiting from graphics processing units (GPU)s which helped finish it a lot earlier than initially projected due to the massive power of GPUs. In the April 2013 status report the scientists report there is still a lot of data to analyze but that they are preparing a new project that will search for prognostic and predictive signatures (sets of genes, proteins, microRNAs, etc.) that help predict patient survival and response to treatment.\nThe project finished in May 2013.\n\nThe Nutritious Rice for the World project is carried out by Ram Samudrala's Computational Biology Research Group at the University of Washington. The project was launched on May 12, 2008, and completed on April 6, 2010. The purpose of this project is to predict the structure of proteins of major strains of rice, in order to help farmers breed better rice strains with higher crop yields, promote greater disease and pest resistance, and utilize a full range of bioavailable nutrients that can benefit people around the world, especially in regions where malnutrition is a critical concern. The project has been covered by more than 200 media outlets since its inception. On April 13, 2010, World Community Grid officially announced that the Nutritious Rice for the World project finished on April 6, 2010.\n\nIn April 2014, an update was posted stating that the research team was able to publish structural information about thousands of proteins, and advance the field of computational protein modeling. These results – which were only possible because of the massive amount of donated computing power they had available – are expected to guide future research and plant science efforts.\n\nThe Clean Energy project is sponsored by the scientists of Harvard University's Department of Chemistry and Chemical Biology. The mission of the Clean Energy Project is to find new materials for the next generation of solar cells and later, energy storage devices. Researchers are employing molecular mechanics and electronic structure calculations to predict the optical and transport properties of molecules that could become the next generation of solar cell materials.\n\nPhase 1 was launched on December 5, 2008, and completed on October 13, 2009. By harnessing the computing power of the World Community Grid, researchers were able to calculate the electronic properties of tens of thousands of organic materials – many more than could ever be tested in a lab – and determine which candidates are most promising for developing affordable solar energy technology.\n\nPhase 2 was launched June 28, 2010, sponsored by the scientists of Harvard University's Department of Chemistry and Chemical Biology. Further calculations about optical, electronic and other physical properties of the candidate materials are being conducted with the Q-Chem quantum chemistry software.Their findings have been submitted to the Energy & Environmental Science journal.\n\nHelp Fight Childhood Cancer project (launched March 13, 2009) is sponsored by the scientists at Chiba Cancer Center Research Institute and Chiba University. The mission of the Help Fight Childhood Cancer project is to find drugs that can disable three particular proteins associated with neuroblastoma, one of the most frequently occurring solid tumors in children. Identifying these drugs could potentially make the disease much more curable when combined with chemotherapy treatment.\n\nInfluenza Antiviral Drug Search project is sponsored by Dr. Stan Watowich and his research team at The University of Texas Medical Branch (Galveston, Texas, USA). The project was launched on May 5, 2009, and completed on October 22, 2009. The mission of the Influenza Antiviral Drug Search project is to find new drugs that can stop the spread of an influenza infection in the body. The research will specifically address the influenza strains that have become drug resistant as well as new strains that are appearing. Identifying the chemical compounds that are the best candidates will accelerate the efforts to develop treatments that would be useful in managing seasonal influenza outbreaks, and future influenza epidemics and even pandemics. Phase 1 of The Influenza Antiviral Drug Search project has already finished on October 22, 2009. Now the researchers are performing post-processing on the results from Phase 1 and are preparing for Phase 2.\n\nIn November 2012, the project's scientists stated that, given the fact that there is no immediate danger of an influenza outbreak, all of the project's results would be posted online and their resources would be refocused on the Dengue Project.\n\nWorld Community Grid and researchers supported by Decrypthon, a partnership between AFM (French Muscular Dystrophy Association), CNRS (French National Center for Scientific Research), Universite Pierre et Marie Curie, and IBM were investigating protein–protein interactions for more than 2,200 proteins whose structures are known, with particular focus on those proteins that play a role in neuromuscular diseases. Phase 2 was launched on May 12, 2009, and completed on September 26, 2012. The database of information produced will help researchers design molecules to inhibit or enhance binding of particular macromolecules, hopefully leading to better treatments for muscular dystrophy and other neuromuscular diseases.\n\nPhase 2 of the Help Cure Muscular Dystrophy project began once the results from the first phase had been analyzed. Phase 2 ran on the BOINC platform.\n\nDiscovering Dengue Drugs – Together – Phase 2 (launched February 17, 2010) is sponsored by The University of Texas Medical Branch (UTMB) in Galveston, Texas, United States and the University of Chicago in Illinois, USA. The mission is to identify promising drug candidates to combat the Dengue, Hepatitis C, West Nile, Yellow Fever, and other related viruses. The extensive computing power of World Community Grid will be used to complete the structure-based drug discovery calculations required to identify these drug candidates.\n\nComputing for Clean Water (launched September 20, 2010) is sponsored by the Center for Nano and Micro Mechanics of Tsinghua University in Beijing. The project's mission is to provide deeper insight on the molecular scale into the origins of the efficient flow of water through a novel class of filter materials. This insight will in turn guide future development of low-cost and more efficient water filters. It is estimated that 1.2 billion people lack access to safe drinking water, and 2.6 billion have little or no sanitation. As a result, millions of people die annually – an estimated 3,900 children a day due to a lack of clean water. On April 25, 2014, the project scientists released an update stating that they had exciting results to report when the paper is submitted and that the project on WCG was finished.\n\nDrug Search for Leishmaniasis (launched September 7, 2011) is spearheaded by the University of Antioquia in Medellín, Colombia, with assistance from researchers at the University of Texas Medical Branch in Galveston, Texas. The mission is to identify potential molecule candidates that could possibly be developed into treatments for Leishmaniasis. The extensive computing power of World Community Grid will be used to perform computer simulations of the interactions between millions of chemical compounds and certain target proteins. This will help find the most promising compounds that may lead to effective treatments for the disease.\n\nThe mission of the GO Fight Against Malaria project (launched November 16, 2011) is to discover promising drug candidates that could be developed into new drugs that cure drug resistant forms of malaria. The computing power of World Community Grid will be used to perform computer simulations of the interactions between millions of chemical compounds and certain target proteins, to predict their ability to eliminate malaria. The best compounds will be tested by scientists at The Scripps Research Institute of La Jolla, California, U.S.A. and further developed into possible treatments for the disease.\n\nSay No to Schistosoma (launched February 22, 2012) was the 20th research project to be launched on World Community Grid. The researchers at Infórium University in Belo Horizonte and FIOCRUZ-Minas, Brazil, ran this project on World Community Grid to perform computer simulations of the interactions between millions of chemical compounds and certain target proteins in the hope of finding effective treatments for schistosomiasis. As of April 2015, subsequent analysis had been performed, and the three most promising candidate substances had been identified for in-vitro testing.\n\nComputing for Sustainable Water was the 21st research project to be launched on World Community Grid. The researchers at the University of Virginia were running this project on World Community Grid to study the effects of human activity on a large watershed and gain deeper insights into what actions can support the restoration, health and sustainability of this important water resource. The project was launched on April 17, 2012, and completed on October 17, 2012.\n\nUncovering Genome Mysteries project launched on October 16, 2014 and is a joint collaboration between Australian and Brazilian scientists. The project aims to examine close to 200 million genes from many life forms and compare them with known genes in order to find out what their function is. The results could have an effect in fields such as medicine and environmental research.\n\n\n"}
