{"id": "28341301", "url": "https://en.wikipedia.org/wiki?curid=28341301", "title": "Agumbe Rainforest Research Station", "text": "Agumbe Rainforest Research Station\n\nThe Agumbe Rainforest Research Station (ARRS) is a field based conservation and research organisation situated inside the Agumbe Reserved Forest at Agumbe in the central Western Ghats of southern India. The Agumbe Reserved Forests receives an annual rainfall in excess of and is at an elevation of about above sea level. It forms a part of the Malnad-Kodagu corridor, which also includes the Someshwara, Mookambika, Bhadra, and Sharavati Wildlife Sanctuaries, Kudremukh National Park, and various other forest tracts and reserve forests around Kundapur, Shankaranarayana, Hosanagara, Sringeri, and Thirthahalli.\n\nARRS was founded in 2005, by leading Indian herpetologist Romulus Whitaker. Whitaker saw his very first king cobra (Ophiophagus hannah) here in 1971. He was also extremely taken by the reverence the people in the region showed for snakes, which was a major factor that drove him to establish a research station in Agumbe (Karnataka ). The land is a revenue land was legally procured, the construction and activities are eco friendly and pose no disturbance to the wildlife.\n\nARRS managed the world’s first radio-telemetry project on the King Cobra (Ophiophagus hannah), which is also the first radio-telemetry study done on any snake in India. Insight gained from this ecological study is being put into practice into king cobra management in the region.\nARRS researchers have witnessed various unique behaviors among the species including a male king cobra killing a possibly pregnant female, a rare behavior even among mammals.\n\nARRS conducts and facilitates a wide variety of research projects, ranging from rainforest ecology, behavioral and population ecology, phenology, geoinformatics and socio economics.\n\nApart from research, ARRS focuses on education and outreach in the local community, schools and colleges. A well-developed volunteer and research intern programme makes the research station an ideal location for those interested in field based research and conservation The research station encourages and provides facilities for graduate and PHD students to conduct projects.\n\n"}
{"id": "1368510", "url": "https://en.wikipedia.org/wiki?curid=1368510", "title": "Basis swap", "text": "Basis swap\n\nA basis swap is an interest rate swap which involves the exchange of two floating rate financial instruments. A basis swap functions as a floating-floating interest rate swap under which the floating rate payments are referenced to different bases.\n\nBasis risk occurs for positions that have at least one paying and one receiving stream of cash flows that are driven by different factors and the correlation between those factors is less than one. Entering into a Basis Swap may offset the effect of gains or losses resulting from changes in the basis, thus reducing basis risk. \n\nIn energy markets, a basis swap is a swap on the price differential for a product and a major index product (e.g. Brent Crude or Henry Hub gas).\n\n"}
{"id": "2054980", "url": "https://en.wikipedia.org/wiki?curid=2054980", "title": "Bonnor beam", "text": "Bonnor beam\n\nIn general relativity, the Bonnor beam is an exact solution which models an infinitely long, straight beam of light. It is an explicit example of a pp-wave spacetime. It is named after William B. Bonnor who first described it.\n\nThe Bonnor beam is obtained by matching together two regions:\n\n\nOn the \"cylinder\" where they meet, the two regions are required to obey matching conditions stating that the metric tensor and extrinsic curvature tensor must agree.\n\nThe interior part of the solution is defined by\n\nThis is a null dust solution and can be interpreted as incoherent electromagnetic radiation.\n\nThe exterior part of the solution is defined by\n\nThe Bonnor beam can be generalized to several parallel beams travelling in the same direction. Perhaps surprisingly, the beams do not curve toward one another. On the other hand, \"anti-parallel\" beams (travelling along parallel trajectories, but in opposite directions) \"do\" attract each other. This reflects a general phenomenon: two pp-waves with parallel wave vectors superimpose linearly, but pp-waves with nonparallel wave vectors (including antiparallel Bonnor beams) do \"not\" superimpose linearly, as we would expect from the nonlinear nature of the Einstein field equation.\n\n"}
{"id": "19557886", "url": "https://en.wikipedia.org/wiki?curid=19557886", "title": "Bunsen–Kirchhoff Award", "text": "Bunsen–Kirchhoff Award\n\nThe Bunsen–Kirchhoff Award is a prize for \"outstanding achievements\" in the field of analytical spectroscopy. It has been awarded since 1990 by the German Working Group for Applied Spectroscopy, and is endowed with by PerkinElmer, Germany. The prize is named in honor of chemist Robert Bunsen and physicist Gustav Kirchhoff.\n\n"}
{"id": "42428380", "url": "https://en.wikipedia.org/wiki?curid=42428380", "title": "Caldilinea aerophila", "text": "Caldilinea aerophila\n\nCaldilinea aerophila is a species of filamentous thermophilic bacteria, and the type species of its genus. It is Gram-negative, non-spore-forming, with type strain STL-6-O1 (=JCM 11388 =DSM 14525).\n\n\n\n"}
{"id": "739891", "url": "https://en.wikipedia.org/wiki?curid=739891", "title": "Canadarm", "text": "Canadarm\n\nThe Shuttle Remote Manipulator System (SRMS), also known as Canadarm (Canadarm 1), is a series of robotic arms that were used on the Space Shuttle orbiters to deploy, maneuver and capture payloads. After the Space Shuttle \"Columbia\" disaster, the Canadarm was always paired with the Orbiter Boom Sensor System (OBSS), which was used to inspect the exterior of the Shuttle for damage to the thermal protection system.\n\nIn 1969, the Canadarm was invited by the National Aeronautics and Space Administration (NASA) to participate in the Space Shuttle program. At the time what that participation would entail had not yet been decided but a manipulator system was identified as an important component. Canadian company DSMA ATCON had developed a robot to load fuel into CANDU nuclear reactors; this robot attracted NASA's attention. In 1975, NASA and the Canadian National Research Council (NRC) signed a memorandum of understanding that Canada would develop and construct the Shuttle Remote Manipulator System.\n\nNRC awarded the manipulator contract to Spar Aerospace. Three systems were constructed within this design, development, test and evaluation contract: an engineering model to assist in the design and testing of the Canadarm, a qualification model that was subjected to environmental testing to qualify the design for use in space, and a flight unit. Anthony \"Tony\" Zubrzycki, a design engineer at DSMA ATCON, while seconded to SPAR, originated the concept for the Canadarm End Effector, inspired by an elastic band around his fingers. Tony formally presented this concept to NASA officials. Frank Mee, head of the SPAR mechanical development laboratory, built the end effector prototype based on Tony's concept and is credited by SPAR as the inventor of the Canadarm End Effector. The three-wire crossover design won over the claw-like mechanisms and others, such as the camera iris model, that were being considered.\n\nThe main controls algorithms were developed by SPAR and by subcontractor Dynacon Inc. of Toronto. CAE Electronics Ltd. in Montreal provided the display and control panel and the hand controllers located in the Shuttle aft flight deck. Other electronic interfaces, servoamplifiers and power conditioners located on the Canadarm were designed and built by SPAR at its Montreal factory. The graphite composite boom that provides the structural connection between the shoulder and the elbow joint and the similar boom that connects the elbow to the wrist were produced by General Dynamics in the United States. Dilworth, Secord, Meagher and Associates, Ltd. in Toronto was contracted to produce the engineering model end effector then SPAR evolved the design and produced the qualification and flight units.The shuttle flight software that monitors and controls the Canadarm was developed in Houston, Texas, by the Federal Systems Division of IBM. Rockwell International's Space Transportation Systems Division designed, developed, tested and built the systems used to attach the Canadarm to the payload bay of the orbiter.\n\nAn acceptance ceremony for NASA was held at Spar's RMS Division in Toronto on the 11th of February 1981. Here Larkin Kerwin, then the head of the NRC, gave the SRMS the informal name, Canadarm.\n\nThe first remote manipulator system was delivered to NASA in April 1981. Astronaut Judith Resnik developed the NASA software and onboard operating procedures for the system. In all, five arms—Nos. 201, 202, 301, 302, and 303—were built and delivered to NASA. Arm 302 was lost in the \"Challenger\" accident.\n\nThe original Canadarm was capable of deploying and retrieving payloads weighing up to in space. In the mid-1990s the arm control system was redesigned to increase the payload capability to in order to support space station assembly operations. While able to maneuver payloads with the mass of a loaded bus in space, the arm motors cannot lift the arm's own weight when on the ground. NASA therefore developed a model of the arm for use at its training facility within the Johnson Space Center located in Houston, Texas. The Canadarm can also retrieve, repair and deploy satellites, provide a mobile extension ladder for extravehicular activity crew members for work stations or foot restraints, and be used as an inspection aid to allow the flight crew members to view the orbiter's or payload's surfaces through a television camera on the Canadarm.\n\nThe basic Canadarm configuration consists of a manipulator arm, a Canadarm display and control panel, including rotational and translational hand controllers at the orbiter aft flight deck flight crew station, and a manipulator controller interface unit that interfaces with the orbiter computer. Most of the time, the arm operators see what they are doing by looking at the Advanced Space Vision System screen next to the controllers.\n\nOne crew member operates the Canadarm from the aft flight deck control station, and a second crew member usually assists with television camera operations. This allows the Canadarm operator to view Canadarm operations through the aft flight deck payload and overhead windows and through the closed-circuit television monitors at the aft flight deck station.\n\nThe Canadarm is outfitted with an explosive-based mechanism to allow the arm to be jettisoned. This safety system allows the Orbiter's payload bay doors to be closed in the event that the arm fails in an extended position and is not able to be retracted.\n\nThe Canadarm is long and diameter with six degrees of freedom. It weighs by itself, and as part of the total system. The Canadarm has six joints that correspond roughly to the joints of the human arm, with shoulder yaw and pitch joints, an elbow pitch joint, and wrist pitch, yaw, and roll joints. The end effector is the unit at the end of the wrist that grapples the payload's grapple fixture. The two lightweight boom segments are called the upper and lower arms. The upper boom connects the shoulder and elbow joints, and the lower boom connects the elbow and wrist joints.\n\nA simulated Canadarm installed on the Space Shuttle \"Enterprise\" was seen when the prototype orbiter's payload bay doors were open to test hangar facilities early in the shuttle program. The Canadarm was first tested in orbit in 1981, on Space Shuttle \"Columbia\"s STS-2 mission. Its first operational use was on STS-3 to deploy and maneuver the Plasma Diagnostics Package. Canadarm has since flown on more than 90 missions with all five orbiters.\n\nSince the installation of the Canadarm2 on the International Space Station (ISS), the two arms have been used to hand over segments of the station for assembly from the Canadarm to the Canadarm2; the use of both elements in tandem has earned the nickname of \"Canadian Handshake\" in the media.\n\nThe Canadarm's 90th and final shuttle mission was in July 2011 on STS-135, delivering the Raffaello MPLM to the ISS and back. \"Discovery's\" Canadarm is displayed next to her in the National Air and Space Museum. \"Endeavour\" left its OBSS at the International Space Station as part of its final mission, while its Canadarm was originally going to be displayed in the headquarters of the Canadian Space Agency. However, \"Endeavour\"s Canadarm is now on permanent display at the Canada Aviation and Space Museum in Ottawa. The last of the Canadarms to fly in space, the SRMS flown aboard \"Atlantis\" on the final space shuttle mission, STS-135 in July 2011, was shipped to NASA's Johnson Space Center in Houston for engineering study and possible reuse on a future mission.\n\nBased on the Canadarm1, the larger Canadarm2 is used for berthing the trusses, the commercial vehicles and inspecting the whole ISS, and the smaller Canadarm3 will be used for berthing the commercial vehicles and inspecting the whole Deep Space Gateway.\n\nThis Canadarm1 will be used for berthing the modules and inspecting the whole Exploration Gateway Platform.\n\n\n\n"}
{"id": "7580037", "url": "https://en.wikipedia.org/wiki?curid=7580037", "title": "Canceled Space Shuttle missions", "text": "Canceled Space Shuttle missions\n\nDuring the Space Shuttle program, several missions were canceled. Many were canceled as a result of the \"Challenger\" and the \"Columbia\" disasters. Many early missions were canceled due to delays in the development of the shuttle. Others were canceled because of changes in payload and missions requirements.\n\nIn 1972, NASA's planners had projected for 570 shuttle missions between 1980 and 1991. Later, this estimate was lowered to 487 launches between 1980 and 1992. The details of the first 23 projected missions, listed in the third edition of \"Manned Spaceflight\" (Reginald Turnill, 1978) and the first edition of the \"STS Flight Assignment Baseline\", an internal NASA document published in October 1977, are presented below.\nLater in the development process, NASA suggested using the first manned space shuttle mission, STS-1, as a sub-orbital test of the Return to Landing Site (RTLS) flight profile devised for emergency abort scenarios. \"Columbia\" would have launched from Kennedy Space Center, then executed a 180-degree turn at a speed of , or 6.7 times the speed of sound, in order to land at the Kennedy Space Center runway. The mission was canceled when astronauts refused to fly it, having deemed the plan to be too dangerous. STS-1 commander John W. Young recalled that \"I said no. I said let's not practice Russian roulette, because you may have a loaded gun there. So we didn't.\"\n"}
{"id": "1694221", "url": "https://en.wikipedia.org/wiki?curid=1694221", "title": "Crown eukaryotes", "text": "Crown eukaryotes\n\nCrown eukaryotes are an artificial group of eukaryotic organisms found at the top of molecular phylogenetic trees including both eukaryotes and prokaryotes. They were originally thought to represent a late step of eukaryotic evolution (somewhat similar to a crown group) because they include multicellular and macroscopic lifeforms that represent the majority of the biomass of the planet while accounting for less than 1% of the genetic diversity. However, they are in fact the result of an artificial clustering of eukaryotic organisms with slowly evolving gene sequences. They are thus not a crown that excludes simpler eukaryotes, but correspond roughly to the initial radiation of eukaryotes. All eukaryotic lineages branching below the \"crown\" in phylogenetic trees are misplaced because of the long branch attraction phenomenon.\n\n\n"}
{"id": "26478508", "url": "https://en.wikipedia.org/wiki?curid=26478508", "title": "Darlene Cavalier", "text": "Darlene Cavalier\n\nDarlene Cavalier is an advocate for public participation in science and science policy, a writer, and an entrepreneur. \n\nShe is a Professor of Practice at Arizona State University, School for the Future of Innovation in Society and the Center for Engagement and Training in Science and Society. She is the founder of SciStarter, an online citizen hotspot that connects people to citizen science projects around the world. \n\nIn 2016, Cavalier co-organized Citizen Science Maker Summit, hosted by ASU. In 2017, Cavalier was appointed to the National Academy of Sciences' Committee on Designing Citizen Science to Support Science Learning to identify and describe existing citizen science projects that support science learning in both formal and informal settings. The committee will develop a set of evidence-based principles to guide the design of citizen science.\n\nCavalier is also the co-founder of the Expert and Citizen Assessment of Science and Technology (ECAST) network, co-editor of The Rightful Place of Science: Citizen Science, author of The Science of Cheerleading, a member of the Environmental Protection Agency’s National Advisory Council for Environmental Policy and Technology and a founding member of the Citizen Science Association, a membership organization dedicated to the dissemination of scholarship related to designing and implementing citizen science.\n\nShe is also the founder of Science Cheerleader, an organization of more than 300 current and former NFL and NBA cheerleaders pursuing careers in science, technology, engineering and math. They playfully challenge stereotypes, inspire young women to consider STEM careers, and help people from all walks of life get involved in science. The organization plays on her former position as a cheerleader for the Philadelphia 76ers basketball team. In 2013, the Science Cheerleaders partnered with the Pop Warner organizations to lead the \"world's largest cheerleading cheer,\" an event that was recognized by Guinness World Records. The Science Cheerleaders have been featured on national and international media outlets and serve as principal investigators in research projects including Project MERCCURI, a study of microbes on the International Space Station. \n\nCavalier earned a bachelor's degree from Temple University and a master's degree from the University of Pennsylvania where she studied the role of citizens in science. She is a Professor of Practice at Arizona State University's Consortium for Science, Policy, & Outcomes, and the Center for Engagement and Training in Science and Society. She lives in Philadelphia with her husband and four children.\n\nShe is a senior advisor and contributor to Discover Magazine. She served on the steering committee of Science Debate 2008.\n\nIn addition to Discover, her writing has appeared in science publications such as the New York Academy of Sciences Magazine and Science Progress\nHer work has been featured on the Today Show, CNN, Fox National Headline News, the Washington Post, Lab Out Loud, and other media outlets.\n\nNew York Academy of Sciences\n\n"}
{"id": "21529260", "url": "https://en.wikipedia.org/wiki?curid=21529260", "title": "Eigencolloid", "text": "Eigencolloid\n\nEigencolloid is a term derived from the German language (\"eigen\": own) and used to designate colloids made of pure phases. Most often such colloids are formed by the hydrolysis of heavy metals cations or radionuclides, such as, \"e.g.\", Tc(OH), Th(OH), U(OH), Pu(OH), or Am(OH). Colloids have been suspected for the long-range transport of plutonium on the Nevada Test Site.\n\n\n"}
{"id": "43156677", "url": "https://en.wikipedia.org/wiki?curid=43156677", "title": "Euclides Danicus", "text": "Euclides Danicus\n\nEuclides Danicus (the Danish Euclid) is one of three books of mathematics written by Georg Mohr. It was published in 1672 simultaneously in Copenhagen and Amsterdam, in Danish and Dutch respectively. It contains the first proof of the Mohr–Mascheroni theorem, which states that every geometric construction that can be performed using a compass and straightedge can also be done with compass alone.\n\nThe book is divided into two parts. In the first part, Mohr shows how to perform all of the constructions of Euclid's \"Elements\" using a compass alone. In the second part, he includes some other specific constructions, including some related to the mathematics of the sundial.\n\n\"Euclides Danicus\" languished in obscurity, possibly caused by its choice of language, until its rediscovery in 1928 in a bookshop in Copenhagen. Until then, the Mohr–Mascheroni theorem had been credited to Lorenzo Mascheroni, who published a proof in 1797, independently of Mohr's work. Soon after the rediscovery of Mohr's book, publications about it by Florian Cajori and Nathan Altshiller Court made its existence much more widely known. The Danish version was republished in facsimile in 1928 by the Royal Danish Academy of Sciences and Letters, with a foreword by Johannes Hjelmslev, and a German translation was published in 1929.\n\nOnly eight copies of the original publication of the book are known to survive. In 2005, one of these original copies was sold at auction, to Fry's Electronics, for what Gerald L. Alexanderson calls a \"ridiculously low price\": US$13,000.\n\nWikicommons has a copy of the original: https://commons.wikimedia.org/wiki/File:Georg_Mohr%27s_Euclides_Danicus.pdf\n"}
{"id": "54051364", "url": "https://en.wikipedia.org/wiki?curid=54051364", "title": "European Microscopy Society", "text": "European Microscopy Society\n\nThe European Microscopy Society is an international learned society which represents the field of microscopy in Europe. It was founded in 1998 following the disbanding of the \"Committee of European Societies of Electron Microscopy\" (which was founded in 1976) as a union of national microscopical societies. The society acts as a regional committee of the International Federation of Societies for Microscopy.\n\nListed below are the bodies which are members of the EMS. All those listed have reciprocal membership agreements. The society has 52 corporate members (ECMA) and 37 individual members, with 28 member countries.\n\n\n\n"}
{"id": "33915069", "url": "https://en.wikipedia.org/wiki?curid=33915069", "title": "Fractionalization", "text": "Fractionalization\n\nIn physics, fractionalization is the phenomenon whereby the quasiparticles of a system cannot be constructed as combinations of its elementary constituents. One of the earliest and most prominent examples is the fractional quantum Hall effect, where the constituent particles are electrons but the quasiparticles carry fractions of the electron charge. Fractionalization can be understood as deconfinement of quasiparticles that together are viewed as comprising the elementary constituents. In the case of spin–charge separation, for example, the electron can be viewed as a bound state of a 'spinon' and a 'chargon', which under certain conditions can become free to move separately.\n\nQuantized Hall conductance was discovered in 1980, related to the electron charge. Laughlin proposed a fluid of fractional charges in 1983, to explain the fractional quantum Hall effect seen in 1982, for which he shared the 1998 Physics Nobel Prize. In 1997, experiments directly observed an electric current of one-third charge. The one-fifth charge was seen in 1999 and various odd fractions have since been detected.\n\nDisordered magnetic materials were later shown to form interesting spin phases. Spin fractionalization was seen in spin ices in 2009 and spin liquids in 2012.\n\nFractional charges continue to be an active topic in condensed matter physics. Studies of these quantum phases impact understanding of superconductivity, and insulators with surface transport for topological quantum computers.\n\nMany-body effects in complicated condensed materials lead to emergent properties that can be described as quasiparticles existing in the substance. Electron behavior in solids can be considered as quasi-particle magnons, excitons, holes, and charges with different effective mass. Spinons, chargons, and anyons cannot be considered elementary particle combinations. Different quantum statistics have been seen; Anyons wavefunctions gain a continuous phase in exchange:\n\nformula_1\n\nIt has been realized many insulators have a conducting surface of 2D quantum electron gas states.\n\nSolitons in 1D, such as polyacetylene, lead to half charges. Spin-charge separation into spinons and holons was detected in electrons in 1D SrCuO. Quantum wires with fractional phase behavior have been studied.\n\nSpin liquids with fractional spin excitations occur in frustrated magnetic crystals, like ZnCu(OH)Cl(herbertsmithite), and in α-RuCl. Spin ice in Dy2Ti2O7 and Ho2Ti2O has fractionalized spin freedom, leading to deconfined magnetic monopoles. They should be contrasted with quasiparticles such as magnons and Cooper pairs, which have quantum numbers that are combinations of the constituents. The most celebrated may be quantum Hall systems, occurring at high magnetic fields in 2D electron gas materials such as GaAs heterostructures. Electrons combined with magnetic flux vortices carry current. Graphene exhibits charge fractionalization.\n\nAttempts have been made to extend fractional behavior to 3D systems. Surface states in topological insulators of various compounds (e.g. tellurium alloys, antimony), and pure metal (bismuth) crystals have been explored for fractionalization signatures.\n"}
{"id": "653323", "url": "https://en.wikipedia.org/wiki?curid=653323", "title": "Frank Hurley", "text": "Frank Hurley\n\nJames Francis Hurley, OBE (15 October 1885 – 16 January 1962) was an Australian photographer and adventurer. He participated in a number of expeditions to Antarctica and served as an official photographer with Australian forces during both world wars.\n\nHis artistic style produced many memorable images. He also used staged scenes, composites and photographic manipulation.\n\nHurley was the third of five children to parents Edward and Margaret Hurley and was raised in Glebe, a suburb of Sydney, Australia. He ran away from home at the age of 13 to work on the Lithgow steel mill, returning home two years later to study at the local technical school and attend science lectures at the University of Sydney. When he was 17 he bought his first camera, a 15-shilling Kodak Box Brownie which he paid for at the rate of a shilling per week. He taught himself photography and set himself up in the postcard business, where he gained a reputation for putting himself in danger in order to produce stunning images, including placing himself in front of an oncoming train to capture it on film.\n\nHurley married Antoinette Rosalind Leighton on 11 April 1918. The couple had four children: three daughters and one son.\n\nWhile living on Collaroy Plateau, (Warringah LGA), Frank became involved with ABC radio. He was a frequent storyteller on the perennial children's program \"The Argonauts\". He enjoyed even more a degree of commercial success by publishing his photos on advertising calendars, postcards and tourist booklets.\n\nHis most successful book was \"Australia: A Camera Study \"published in 1955 and reprinted three times.\n\nHe engaged in aerial photography with Brud Rees on his Piper Cub float plane. He travelled extensively throughout Australia commissioned on various photographic assignments.\n\nOf his lifetime, Frank Hurley spent more than four years in Antarctica. At the age of 23, in 1908, Hurley learned that Australian explorer Douglas Mawson was planning an expedition to Antarctica; fellow Sydney-sider Henri Mallard in 1911, recommended Hurley for the position of official photographer to Mawson's Australasian Antarctic Expedition, ahead of himself. Hurley asserts in his biography that he then cornered Mawson as he was making his way to their interview on a train, using the advantage to talk his way into the job. Mawson was persuaded, while Mallard, who was the manager of Harringtons (a local Kodak franchise) to which Hurley was in debt, provided photographic equipment. The Expedition departed in 1911, returning in 1914. On his return, he edited and released a documentary, \"Home of the Blizzard\", using his footage from the expedition.\n\nHurley was also the official photographer on Ernest Shackleton's Imperial Trans-Antarctic Expedition which set out in 1914 and was marooned until August 1916; Hurley produced many pioneering colour images of the Expedition using the then-popular Paget process of colour photography. He photographed in South Georgia in 1917. He later compiled his records into the documentary film \"South\" in 1919. His footage was also used in the 2001 IMAX film \"Shackleton's Antarctic Adventure\". He returned to the Antarctic in 1929 and 1931 on Mawson's British Australian (and) New Zealand Antarctic Research Expeditions (BANZARE).\n\nIn 1917, Hurley joined the Australian Imperial Force (AIF) as an honorary captain and captured many stunning battlefield scenes during the Third Battle of Ypres. In keeping with his adventurous spirit, he took considerable risks to photograph his subjects, also producing many rare panoramic and colour photographs of the conflict. Hurley kept a diary in 1917-1918 chronicling his time as a war photographer. In it he describes his commitment \"to illustrate to the public the things our fellows do and how war is conducted\", as well as his short-lived resignation in October 1917 when he was ordered not to produce composite images. His period with the AIF ended in March 1918.\n\nFor the 1918 London exhibition \"Australian War Pictures and Photographs \"he employed composites for photomurals to convey drama of the war on a scale otherwise not possible using the technology available. This brought Hurley into conflict with the AIF on the grounds that montage diminished documentary value. Charles Bean, official war historian, labelled Hurley's composite images \"fake\".\n\nHurley also served as a war photographer during World War II.\n\nHurley also used a movie camera to record a range of experiences including the Antarctic expeditions, the building of the Sydney Harbour Bridge, and war in the Middle East during World War II. The camera was a Debrie Parvo L 35mm hand-crank camera made in France. This camera is now in the collection of the National Museum of Australia.\n\nHurley made several documentaries throughout his career, most notably \"Pearls and Savages\" (1921). He wrote and directed several dramatic feature films, including \"Jungle Woman\" (1926) and \"The Hound of the Deep\" (1926). He also worked as cinematographer for Cinesound Productions where his best known film credits include \"The Squatter's Daughter\" (1933), \"The Silence of Dean Maitland\" (1934) and \"Grandad Rudd\" (1935). His 1941 documentary short \"Sagebrush and Silver\" was nominated for an Academy Award at the 14th Academy Awards for Best Short Subject (One-Reel).\n\nPhotographs by Hurley of the Antarctic are held by a number of institutions. Notable collections include the Australian War Memorial, Canberra, National Library of Australia, Canberra, Scott Polar Research Institute, Cambridge, Royal Geographical Society, London, State Records of South Australia, and the South Australian Museum, Adelaide.\n\nNational Library of Australia\nThe collection contains 10,999 glass negatives, gelatin negatives, colour transparencies, lantern slides, and stereographs that have been fully catalogued and digitised.\n\nThe collection covers photographs of Hurley's trips to Antarctica; as official photographer during World War I 1914–1918; later travels in the Middle East and Egypt; as official photographer during World War II 1939–1945; Papua and New Guinea; Australian scenery, industries and social life and customs.\n\nRelated photographic prints can be found in the \"Hurley Collection of Photographic Prints\".\nThe collection contains 1000 photographic prints. 44 prints have been catalogued and digitised.\nThis album contains 60 gelatin silver photographs by Hurley, all of which have been catalogued and digitised.\nThe collection contains 259 photographic prints, all of which have been catalogued and digitised.\n\nState Records of South Australia\n\nAs part of South Australia's Centenary celebration in 1936, Frank Hurley was commissioned to produce images of South Australia for inclusion in an illustrated souvenir booklet. The resulting glass plate negatives are held as part of a series of glass plate negatives produced by or for the South Australian Government for publicity or other purposes.\n\nAt this time, Hurley was also commissioned to produce a couple of promotional films for the South Australian Government, \"Oasis\" and \"Here is Paradise\".\n\n\n\n\n\n\n\n"}
{"id": "34556227", "url": "https://en.wikipedia.org/wiki?curid=34556227", "title": "Graphic medicine", "text": "Graphic medicine\n\nGraphic medicine connotes use of comics in medical education and patient care.\n\nThe phrase was coined by Ian Williams to denote \"the intersection between the medium of comics and the discourse of healthcare\". Comics offer an engaging, powerful, and accessible method of delivering illness narratives. The academic appraisal of graphic fiction is in its infancy, but its examination by academics involved in healthcare-related studies is increasing, with work emerging in journals such as \"Configurations: A Journal of Literature, Science, and Technology\" (2.2) as well as \"Journal of the Medical Humanities\" and \"Literature and Medicine\". It is notable that the Medical Humanities movement in many medical schools (e.g., Penn State University, http://www2.med.psu.edu/humanities/) advocates the framework and use of literature in exploring illness, from practitioner and patient perspectives. A recent entry to the scholarly study of graphic mediciine is the Einstein Foundation funded project at the Freie Universität Berlin (2016-2019) under the direction of Irmela Marei Krüger-Fürhoff and with the collaboration of Susan Merrill Squier, Einstein Visiting Fellow and Brill Professor at the Pennsylvania State University: \"PathoGraphics\", the study of illness narratives or pathographies and works of graphic medicine. \nWilliams set up the Graphic Medicine website in 2007 whilst writing a masters dissertation on medical narrative in comics and graphic novels, during which time he found Susan M. Squier's essays, “Beyond Nescience: the intersectional insights of health humanities.” \"Perspectives in Biology and Medicine\". 50:3 (summer 2007): 334-47, and “So Long as They Grow Out of It: Comics, The Discourse of Developmental Normalcy, and Disability.” Journal of Medical Humanities. 29:2 (June 2008): 71-88. Scholars from around the world who were interested in comics and healthcare began to get in touch, notably Prof Michael Green, who had recently set up a graphic narratives course at Hershey Medical School at Penn State University, and MK Czerwiec, aka \"Comic Nurse\", who had, for many years, been recording her experiences as an HIV hospice nurse in comics form. Green invited his colleagues Kimberley Myers, of the Medical Humanities Program at Penn State Milton Hershey Medical School and Susan M. Squier, Brill Professor of English and Women's, Gender, and Sexuality Studies, who teaches graphic medicine to Ph.D. students at the Penn State University and whose work Williams had encountered earlier, to the discussion group, and Williams introduced Maria Vaccarella, Giskin Day and Columba Quigley. The group decided to hold a conference, in 2010 at The University of London, which led to a series of annual international conferences with presentations that are frequently posted as podcasts after the conference, on http://www.graphicmedicine.org\n\nPenn State University Press published The Graphic Medicine Manifesto in 2015. Authors are MK Czerwiec, Ian Williams, Susan Merrill Squier, Michael J. Green, Kimberly R. Myers, and Scott T. Smith. Content summary: \"Combining scholarly essays with visual narratives and a conclusion in comics form, establishes graphic medicine as a new area of scholarship. Demonstrates that graphic medicine narratives offer patients, family members, and medical caregivers new ways to negotiate the challenges of the medical experience. Discusses comics as visual rhetoric\"—Provided by publisher. ; 195 pages, includes bibliographic references. This was the inaugural volume in the ongoing Graphic Medicine series at Penn State University Press, which is co-edited by Susan M. Squier and Ian Williams. For recent publications in the Graphic Medicine series, see its website:\n\nhttp://www.psupress.org/books/series/book_SeriesGM.html\n\nIn 2014, the first American Library Association Will Eisner Graphic Novel Growth Grant was awarded to Ypsilanti District Library, (Ypsilanti, Michigan) for its proposal to build a collection of graphic medicine narratives. To date, that collection contains over 100 titles, which can be viewed in a subject search Graphic Medicine on the library's website: www.ypsilibrary.org. Author MK Czerwiec lectured in the fall of 2014 at St. Joseph Mercy Hospital (Ypsilanti, Michigan) in support of this grant.\n\nCenter Report 45 (3): 15-19.\n2015. http://www.publicbooks.org/show-me-where-it-hurts-part-1/.\n• Sathyaraj Venkatesan and Sweetha Saji. “(Un)bridgeable Chasms?: Doctor-Patient Interactions in select Graphic Medical Narratives.” Journal of Medical Humanities [Springer]. 2018. https://link.springer.com/article/10.1007/s10912-018-9528-y\n\n\n• Sathyaraj Venkatesan and Anu Mary Peter. “No time to Rest, Vent or Mourn”: Medical Intern Narratives and Graphic Medicine.” 1.2 (2017): 187-205. INKS: The Journal of the Comics Studies Society. Published by The Ohio State University. Project Muse Access: https://muse.jhu.edu/article/668114.\n\n• Sathyaraj Venkatesan and Anu Mary Peter. \"The Cult of Victorianism: Eating Disorders and Graphic Medicine.\" Volume 9, Number 4, 2017. DOI: 10.21659/rupkatha.v9n4.01. <http://rupkatha.com/V9/n4/v9n401.pdf>.\n\n• Sathyaraj Venkatesan and Raghavi Ravi Kasthuri. “Magic and Laughter”: Graphic Medicine, Recasting Alzheimer Narratives and Dana Walrath’s Aliceheimer’s: Alzheimer’s Through the Looking Glass.\" Concentric: Literary and Cultural Studies. 44.1 (2018): 61-84. <http://www.concentric-literature.url.tw/issues/Crip%20World/4.pdf>.\n\n• Sathyaraj Venkatesan and Anu Mary Peter. \"‘I Want to Live, I Want to Draw’: The Poetics of Drawing and Graphic Medicine.\" Volume: 13 issue: 2, page(s): 104-116. Article first published online: March 22, 2018; Issue published: July 1, 2018. https://doi.org/10.1177/0973258618761406\n\n• Sathyaraj Venkatesan and Sweetha Saji. “Rhetorics of the Visual: Graphic Medicine, Comics and Its Affordances.” Rupkatha Journal on Interdisciplinary Studies in Humanities 8.3 (2016): 221-31. http://rupkatha.com/V8/n3/23_Visual_Rhetorics.pdf\n\n• Sathyaraj Venkatesan. Rev. of The Bad Doctor: the Troubled Life and Times of Dr. Iwan James, by Ian Williams. Journal of Graphic Novels and Comics 8.1 (2016): 110-12. https://www.tandfonline.com/doi/full/10.1080/21504857.2016.1149082\n\n• Sathyaraj Venkatesan and Sweetha Saji. “Royal Road to Wisdom: Tarot Cards and Justin Green’s Binky Brown Meets the Holy Virgin Mary.” The Explicator 74.3 (2016): 170-72.\n\n• Sathyaraj Venkatesan. Rev. of Graphic Medicine Manifesto, by M. K. Czerwiec, Ian Williams, Susan Merrill Squier, Michael J. Green, Kimberly R. Myers, and Scott T. Smith. Journal of Graphic Novels and Comics 7.1 (2015): 93-94. https://www.tandfonline.com/doi/full/10.1080/21504857.2015.1108350\n\n• Sathyaraj Venkatesan and Anu Mary Peter. “Life is a game: visual metaphors in Brian Fies’s Mom’s Cancer.” Hektoen International: A Journal of Medical Humanities. Hektoen Institute of Medicine, Fall 2015. http://hekint.org/2017/01/25/life-is-a-game-visual-metaphors-in-brian-fiess-moms-cancer/\n\n• Sathyaraj Venkatesan and Anu Mary Peter. “Journeys into caregiving: lessons from Sarah Leavitt’s “Tangles: A Story About Alzheimer’s, My Mother, and Me.” Research and Humanities in Medical Education 2. University College of Medical Sciences, 6 Oct. 2015. https://www.rhime.in/ojs/index.php?journal=rhime&page=article&op=view&path%5B%5D=18\n\n• Sathyaraj Venkatesan and Anu Mary Peter. Rev. of Billy Me & You: Memoir of Grief and Recovery, by Nicola Streeten. graphicmedicine.org. Graphic Medicine, 3 June 2015. https://www.graphicmedicine.org/comic-reviews/billy-me-you-a-memoir-of-grief-and-recovery-2/\n\n• Raghavi Ravi Kasthuri and Sathyaraj Venkatesan. “Picturing Illness: History, Poetics, and Graphic Medicine.” Research and Humanities in Medical Education 2. University College of Medical Sciences, 31 May 2015.\nhttps://www.rhime.in/ojs/index.php?journal=rhime&page=article&op=view&path%5B%5D=9\n\n• Sathyaraj Venkatesan and Raghavi Ravi Kasthuri. Rev. of Lisa’s Story: The Other Shoe, by\nTom Batuik. graphicmedicine.org. Graphic Medicine, 17 Mar. 2015. https://www.graphicmedicine.org/comic-reviews/lisas-story-the-other-shoe/\n\n• Sathyaraj Venkatesan and Raghavi Ravi Kasthuri. “Humour and Tumour: Breast Cancer, Graphic Memoir and Miriam Engelberg’s Cancer Made Me A Shallower Person: AMemoir in Comics.” Gnosis: An International Journal of English Language and Literature 1.2 (2015): 51-58.\n"}
{"id": "26091193", "url": "https://en.wikipedia.org/wiki?curid=26091193", "title": "Herpetosiphonaceae", "text": "Herpetosiphonaceae\n\nHerpetosiphonaceae is a family of bacteria in the order \"Herpetosiphonales\".\n"}
{"id": "6264576", "url": "https://en.wikipedia.org/wiki?curid=6264576", "title": "Honeycomb mirror", "text": "Honeycomb mirror\n\nA honeycomb mirror is a large mirror usually used as the primary mirror in astronomical reflecting telescopes whose face is supported by a ribbed structure that resembles a honeycomb. The design provides sufficient rigidity for ultra-high precision optics while reducing the weight of the mirror. The reduced weight, in turn, allows smaller, lighter support and control structures, reducing the overall cost of the telescope. The term may also refer to mirrors made up of a coordinated set of individual hexagonal mirrors.\n\nThe development of the honeycomb mirror has allowed the creation of larger instruments than would be feasible with solid mirrors. Solid mirrors are not only mechanically cumbersome, but are also difficult to cast and safely cool into a single, large blocks of glass. Honeycomb designs can reduce the weight of the mirror by as much as eighty percent.\n\n"}
{"id": "375900", "url": "https://en.wikipedia.org/wiki?curid=375900", "title": "Isentropic process", "text": "Isentropic process\n\nIn thermodynamics, an isentropic process is an idealized thermodynamic process that is both adiabatic and reversible. The work transfers of the system are frictionless, and there is no transfer of heat or matter. Such an idealized process is useful in engineering as a model of and basis of comparison for real processes.\n\nThe word \"isentropic\" is occasionally, though not customarily, interpreted in another way, reading it as if its meaning were deducible from its etymology. This is contrary to its original and customarily used definition. In this occasional reading, it means a process in which the entropy of the system remains unchanged. For example, this could occur in a system where the work done on the system includes friction internal to the system, and heat is withdrawn from the system in just the right amount to compensate for the internal friction, so as to leave the entropy unchanged.\n\nThe second law of thermodynamics states that\nwhere formula_2 is the amount of energy the system gains by heating, formula_3 is the temperature of the system, and formula_4 is the change in entropy. The equal sign refers to a reversible process, which is an imagined idealized theoretical limit, never actually occurring in physical reality. For an isentropic process, which by definition is reversible, there is no transfer of energy as heat because the process is adiabatic. In an irreversible process of transfer of energy as work, entropy is produced within the system; consequently, in order to maintain constant entropy within the system, energy must be removed from the system as heat during the process.\n\nFor reversible processes, an isentropic transformation is carried out by thermally \"insulating\" the system from its surroundings. Temperature is the thermodynamic conjugate variable to entropy, thus the conjugate process would be an isothermal process, in which the system is thermally \"connected\" to a constant-temperature heat bath.\n\nThe entropy of a given mass does not change during a process that is internally reversible and adiabatic. A process during which the entropy remains constant is called an isentropic process, written formula_5 or formula_6.\nSome examples of theoretically isentropic thermodynamic devices are pumps, gas compressors, turbines, nozzles, and diffusers.\n\nMost steady-flow devices operate under adiabatic conditions, and the ideal process for these devices is the isentropic process. The parameter that describes how efficiently a device approximates a corresponding isentropic device is called isentropic or adiabatic efficiency.\n\nIsentropic efficiency of turbines:\n\nIsentropic efficiency of compressors:\n\nIsentropic efficiency of nozzles:\n\nFor all the above equations:\n\nNote: The isentropic assumptions are only applicable with ideal cycles. Real cycles have inherent losses due to compressor and turbine inefficiencies and the second law of thermodynamics. Real systems are not truly isentropic, but isentropic behavior is an adequate approximation for many calculation purposes.\n\nIn fluid dynamics, an isentropic flow is a fluid flow that is both adiabatic and reversible. That is, no heat is added to the flow, and no energy transformations occur due to friction or dissipative effects. For an isentropic flow of a perfect gas, several relations can be derived to define the pressure, density and temperature along a streamline.\n\nNote that energy \"can\" be exchanged with the flow in an isentropic transformation, as long as it doesn't happen as heat exchange. An example of such an exchange would be an isentropic expansion or compression that entails work done on or by the flow.\n\nFor an isentropic flow, entropy density can vary between different streamlines. If the entropy density is the same everywhere, then the flow is said to be homentropic.\n\nFor a closed system, the total change in energy of a system is the sum of the work done and the heat added:\nThe reversible work done on a system by changing the volume is\nwhere formula_15 is the pressure, and formula_16 is the volume. The change in enthalpy (formula_17) is given by\n\nThen for a process that is both reversible and adiabatic (i.e. no heat transfer occurs), formula_19, and so formula_20. All reversible adiabatic processes are isentropic. This leads to two important observations:\n\nNext, a great deal can be computed for isentropic processes of an ideal gas. For any transformation of an ideal gas, it is always true that\n\nUsing the general results derived above for formula_25 and formula_26, then\n\nSo for an ideal gas, the heat capacity ratio can be written as\n\nFor an ideal gas formula_30 is constant. Hence on integrating the above equation, assuming a perfect gas, we get\nthat is,\n\nUsing the equation of state for an ideal gas, formula_33,\n\nalso, for constant formula_38 (per mole),\n\nThus for isentropic processes with an ideal gas,\n\nDerived from\nwhere:\n\n\n"}
{"id": "53838091", "url": "https://en.wikipedia.org/wiki?curid=53838091", "title": "Junhan Cho", "text": "Junhan Cho\n\nJunhan Cho is a Chinese physicist, currently at Dankook University and an Elected Fellow of the American Physical Society.\n"}
{"id": "1063811", "url": "https://en.wikipedia.org/wiki?curid=1063811", "title": "Leon Marchlewski", "text": "Leon Marchlewski\n\nLeon Paweł Marchlewski (15 December 1869 in Włocławek – 16 January 1946 in Kraków, Poland) was a Polish chemist.\n\nHe was one of the founders in the field of chlorophyll chemistry.The illustration on the right is of his diplomatic passport he used in 1927 to attend an international conference on chemistry in Paris.\n"}
{"id": "18820886", "url": "https://en.wikipedia.org/wiki?curid=18820886", "title": "Liquid Jungle Lab", "text": "Liquid Jungle Lab\n\nThe Liquid Jungle Lab (LJL) is a tropical marine research station on the island of Canales de Tierra on the western coast of Pacific Panamá along a primary marine biological corridor. The LJL research campus was completed in 2004 and is part of a private 3,500 hectare reserve composed of primary forest, mangroves, tide pools, and a rocky inter-tidal zone that transitions into fringing coral reefs.\n\nThe island laboratory is adjacent to two large coastal bays, Bahia Honda, Veraguas Province and Pixvae Bay, which are important mangrove, estuarine and riparian (stream) habitats. The island and laboratory serve as a strategic base for ecologic research of the Coiba National Park, a UNESCO World Heritage Site and Panama’s largest marine protected area. The tremendous biodiversity of the marine and terrestrial environments surrounding Isla Canales de Tierra allows visiting scientists to conduct multidisciplinary ecologic research in a pristine area and has even inspired a designer perfume fragrance, Fleur de Liane. The LJL was founded by Jean Pigozzi, a Swiss venture capitalist, photographer and art collector.\n\nA multi-disciplinary approach to research in Terrestrial and Marine Tropical Ecology are conducted between a consortium of scientists and researchers from the Woods Hole Oceanographic Institution, the Smithsonian Tropical Research Institute, and Real Jardin Botanico de Madrid. These organizations and visiting scientists and students use the marine lab facilities and experimental farm to conduct primary and applied research in the fields of tropical island ecology, marine biology, physical oceanography, marine biogeochemistry, aquaculture, genetics, molecular biology, herpetology, botany, ornithology, entomology, ecosystem conservation, island biogeography, geology, fisheries management, tropical forest ecology, agro-forestry, veterinary science, and organic agriculture.\n\nCurrent areas of marine research at the Liquid Jungle include plankton community dynamics and marine larval ecology and transport, modeling internal waves and benthic structure, coral community architecture and diversity, synoptic chemical mapping, invasive sessile invertebrate species, mangrove and estuarine watersheds, and the effects of natural and anthropogenic nutrient input on primary production and fisheries along Pacific coastal zones.\n\nThe local fauna includes a long list of avian species such as toucans (\"Ramphastos sulfuratus\"), owls (\"Pulsatrix perspicillata\") humming birds (\"Hylocharys elicieae\", \"Phaetornis superciliosus\"), manakins (\"Chiroxiphia lanceolata\") pelicans and a plethora of other marine birds. Many mammals, unique to Central America inhabit the island such as howler monkeys (\"Allouatta palliata\", and the endemic Coiba species \"Alouatta coibensis\"), capuchin monkeys (\"Cebus capucinus\") coatis (\"Nasua narica\"), raccoons (\"Procyon cancrivorus\"), pacas (\"Agouti paca\"), agoutis or nueques (\"Dasyprocta sp\"), tayras (\"Eira barbara\"), bats (\"Glossophaga soricina\" &\"Carollia castanea\") sloths (\"Bradypus variegatus\") margays (\"Leopardus wiedii\") and white-tailed deer (\"Odocoileus virginianus\"). Besides the thousands of species of plants and insects endemic to this region of the tropical Americas, many reptile and amphibian species are also found on the island. Even occasionally the rare jungle cat (\"Leopardus pardalis\") is spotted in the dense jungle surrounding nearby Bahia Honda and Pixvae. In 2004 botanists, herpetologists, entomologists, ornithologists, and biologists convened to create the first comprehensive catalog of tropical plants, reptiles, insect, birds, and mammal diversity of this Pacific Coastal region.\n\nGeography of Panama\nThe Gulf of Chiriquí contains several prominent, offshore island complexes including Isla Coiba (493 km), Isla Cébaco (80 km) Islas Ladrones, Islas Secas, and Islas Contreras. Other islands like Jicarón, Leones, Gobernadora, Verde, Canales de Afuera, Ranchería, Papagayo, Canales de Tierra, and Jicarita are part of a group of more than forty smaller island clusters scattered near the coast. Coastal areas in the gulf are a mélange of mid to late Tertiary volcanics, and much newer Quaternary period alluvial sedimentary series. Smaller island clusters are predominantly basalt outcrops once associated with the mainland before sea level rise. Coiba Island, the largest in the region, shares geomorphologies similar to the mainland Azuero peninsula.\n\nThe climate of Panamá is largely affected by the position of a low atmospheric pressure zone known as the Intertropical Convergence Zone (ITCZ) which also affects seasonal evolution of geostrophic currents in the Panamá Bight. During the rainy season (December through May), the ITCZ is located to the North of Panamá and produces light and variable winds and ocean circulation in the Panamá Bight is anticyclonic (west) which creates a southerly flowing coastal current. As a result of these punctuated seasonal movements of the ITCZ, Panamá experiences high seasonal rainfall often reaching more than 3000 mm/yr. Starting in October and continuing into the dry season (January to March) the ITCZ moves South of Panamá, producing a dominant period of northeasterly tradewinds known as the Panamá Jet, which results in a reversal of water circulation and becomes a cyclonic gyre with a coastal current flowing to the north. Upwelling develops in the Gulf of Panama during the dry season when northeast tradewinds from the Caribbean blow over to the Pacific through a physiographic gap in the central mountain range which divides the Isthmus. This wind stress creates seasonal Ekman spiral pumping and displaces nutrient-poor coastal surface water with cool, nutrient rich, water masses.\n\nThis nutrient rich upwelling such as occurs in the Gulf of Panama, can stimulate Plankton production leading to blooms of centric, colonial, and penate diatoms and dinoflagellates. Zooplankton populations often respond to this by subsequently increasing growth and reproduction rates. Scientists are now able to quantify the abundance and diversity of these microscopic organisms \"in-situ\" with sensors such as the Video Plankton Recorder (a specialized underwater microscope and imaging system).\n\nIn order to understand oceanic and atmospheric coupling, and the potential effects of these phenomena on ocean life, scientists must collect time series data which measure weather patterns, ocean circulation and sea water chemistry. PLUTO is a fiber-optic cabled observatory deployed in January 2006 in approximately 18 m of water 1.5 km to the south west of Isla de Canales de Tierra. The observatory consists of sensors for salinity, temperature, pressure, water current speed and direction, chlorophyll, turbidity, oxygen, down-welling light at two depths, an array of temperature sensors. A remotely controlled, high definition pan and tilt underwater camera displays rapid image updates of the benthic habitat surrounding the PLUTO sensors. The data are distributed via satellite back to WHOI and made available on the web (http://4dgeo.whoi.edu/panama/).\n\nCoral reefs usually exist in the euphotic zone (shallow areas of the sea where light can penetrate) along coastal or island areas, and require clear, oligotrophic (low nutrient) water in a narrow temperature and salinity range. Littoral areas located along the Southern Isthmus of Panamá demonstrate highly complex ecological interactions and distributions of endemic and migratory marine species due in part to the overlap of continental ecotones, tropical weather patterns and the convergence of powerful sea currents. In the Republic of Panamá, there is estimated 290 km of reefs along both Caribbean and Pacific coasts, however much higher diversity (about 68 hard coral species) occurs in the Caribbean, compared to 33 known species from 11 genera living along the Pacific coast. \nThe Eastern Tropical Pacific (ETP) is a biotope known for intrinsically low coral species diversity which unfortunately enhances the potential threats to these coral reef systems. Besides the direct effects of overfishing, anchor damage, and coral mining, terrestrial land use affects coral reef habitats in more indirect ways. Panamá experiences high seasonal rainfall (3000 mm/yr.) and reefs can be severely impacted if corals are chronically exposed to the runoff of nutrients originating from deforestation and soil erosion, fertilizers, pesticides or untreated sewage. In addition to being a primary area for cattle ranching and agriculture, unregulated construction, septic waste increase and local coastal population expansion poses a tangible threat to the biological integrity of coral reefs surrounding the Coiba Island Marine Protected Area (MPA). Mangrove areas of Bahia Honda, Pixvae, and Puerto Mutis are important for the health of the local reefs, because mangroves not only filter the nutrients emptying onto reefs, but are important nurseries for juvenile fish, epibionts, crustaceans (i.e. shrimp), and other invertebrates that serve as critical food sources and spawning grounds for the offshore marine systems (i.e. Coiba and Cebaco islands). Scientists from around the world use the Liquid Jungle Lab facilities to study these reef systems in greater detail in order to establish ecologic baselines and understand natural and human impacts to the fish and marine life that rely on these habitats.\n\nFamily Agariciidae: \"Pavona clavus, Gardineroseris planulata, Pavona gigantea, Pavona varians, Pavona Chiriquíensis, Pavona frondifera, Pavona maldivensis\" Pocilloporidae: \"Pocillopora elegans, Pocillopora damicornis, Pocillorpora capitata, Pocillorpora eydouxi\"; Poritidae: \"Porites lobata\"; Siderastreidae: \"Psammacora stellata\". Fungiidae: \"Cyclocerus curvata\" Milleporadea: \"Millepora intricata\" Dendrophyllidae: \"Tubastraea coccinea\"\n\nBibliography of scientific research conducted at the Liquid Jungle Lab, Panama\n\nAlmany, G. R., M.L. Berumen, S.R. Thorrold, S. Planes, and G.P. Jones. Larval dispersal, marine reserves and the replenishment of fish populations. (Accepted pending suitable revision) Science\n\nBowen, J.L. and Ivan Valiela (2008) Using δ15N to Assess Coupling between Watersheds and Estuaries in Temperate and Tropical Regions. Journal of Coastal Research Vol 24:3; pp. 804–813.\n\nCamilli, Luis, O. Pizarro, and R. Camilli (2008) Advancing spatial-temporal continuity in coral reef ecosystem pattern detection: The morphology, distribution and chemical environments of coral habitats encompassing Coiba National Park, Panamá. Proceedings of the 11th International Coral Reef Symposium, Ft. Lauderdale, Florida, 7–11 July 2008, Session number 16\n\nCamilli Richard, O. Pizarro, and L. Camilli (2007) Rapid Swath Mapping of Reef Ecology and Associated Water Column Chemistry in the Gulf of Chiriquí, Panamá On the Edge of Tomorrow: MTS/IEEE-OES Oceans Conference.\n\nCarman Mary R., S.J. Molyneaux, R. Ji, and S.M. Sievert (2007) Ascidians of the southern Gulf of Chiriqui, Pacific-Panama: A native fauna at risk to bioinvasion. Fifth International Conference on Marine Bioinvasions.\n\nCarman, Mary, S. Bullard, S. Molyneaux, R. Ji, A. Goodwin, E. Baker, and S. Sievert. Ascidian faunas of the island chain Isla Canales de Tierra to Coiba, southern Gulf of Chiriqui and south entrance to the Panama Canal, Pacific coast of Panama. (in prep)\n\nCastroviejo S., and A. Ibanez (2003) Estudio Sobre la Biodiversidad de la Region de Bahia Honda (Veraguas, Panama) Inventario de Biodiversidad. Real Jardin Botanico(CSIC) (133).\n\nGallager, Scott M., S. Lerner, E. Miller, A.D. York, and A. Girard. Design, installation, and the first two years of operation of an underwater observatory on the western Panamanian shelf. (submitted)\n\nGallager, Scott M., A.D. York, C. Mingione and S. Lerner. Plankton community structure in the Gulf of Chiriqui, Pacific-Panama, as modulated by upwelling and large internal waves. (in prep)\n\nPineda, J., Reyns, N., Starczak, V.R., 2009. Complexity and simplification in understanding recruitment in benthic populations. Popul Ecol 51, 17-32.\n\nThorrold, Simon R., G.P. Jones, S. Planes, and J. A. Hare. (2006) Transgenerational marking of embryonic otoliths in marine fishes using barium stable isotopes. Can. J. Fish. Aquat. Sci. 63: 1193-1197.\n\nStarczak, V., P. Pérez-Brunius, P., J. Pineda, H. Levine and J. Gyory (2011) The role of season and salinity in influencing barnacle distributions in two adjacent mangrove coastal lagoons. Bulletin of Marine Science. 87(3):275–299..\n\n"}
{"id": "13258651", "url": "https://en.wikipedia.org/wiki?curid=13258651", "title": "List of Cascade volcanoes", "text": "List of Cascade volcanoes\n\nThis is a list of Cascade volcanoes, i.e. volcanoes formed as a result of subduction along the Cascadia subduction zone in the Pacific Northwest of North America. The volcanoes are listed from north to south, by province or state: British Columbia, Washington, Oregon, and California.\n\n"}
{"id": "913621", "url": "https://en.wikipedia.org/wiki?curid=913621", "title": "List of U.S. state soils", "text": "List of U.S. state soils\n\nThis is a list of U.S. state soils. A state soil is a soil that has special significance to a particular state. Each state in the United States has selected a state soil, twenty of which have been legislatively established. These official state soils share the same level of distinction as official state flowers and birds. Also, representative soils have been selected for Puerto Rico and the U.S. Virgin Islands.\n\n\n"}
{"id": "31935125", "url": "https://en.wikipedia.org/wiki?curid=31935125", "title": "List of countries with United Nations Associations", "text": "List of countries with United Nations Associations\n\nThis is a list of United Nations Associations.\n\nAccording to World Federation of United Nations Associations there are active United Nations Associations in:\n\n\n china\n\n\n\n"}
{"id": "44252081", "url": "https://en.wikipedia.org/wiki?curid=44252081", "title": "List of largest exoplanets", "text": "List of largest exoplanets\n\nBelow is a list of the largest exoplanets so far discovered, in terms of physical size, ordered by radius.\n\nThe sizes are listed in units of Jupiter radii (, )(71,492km). All planets listed are larger than two times the size of the largest planet in the Solar System, Jupiter. Some planets that are smaller than have been included for comparison.\n\nA few additional examples with radii lower than 1.7 .\n\n"}
{"id": "5825136", "url": "https://en.wikipedia.org/wiki?curid=5825136", "title": "List of most luminous stars", "text": "List of most luminous stars\n\nBelow is a list of stars arranged in order of decreasing luminosity (increasing bolometric magnitude). Accurate measurement of stellar luminosities is quite difficult in practice, even when the apparent magnitude is measured accurately, for four reasons:\n\n\nBecause of all these problems, other references may give \"very\" different lists of the most luminous stars (different ordering or different stars altogether). Data on different stars can be of somewhat different reliability, depending on the attention one particular star has received as well as largely differing physical difficulties in analysis (see the Pistol Star for an example). The last stars in the list are familiar nearby stars put there for comparison, and not among the most luminous known. It may also interest the reader to know that the Sun is more luminous than approximately 95% of all known stars in the local neighborhood (out to, say, a few hundred light years), due to enormous numbers of somewhat less massive stars that are cooler and often much less luminous. For perspective, the overall range of stellar luminosities runs from dwarfs less than 1/10,000th as luminous as the Sun, to supergiants over 1,000,000 times more luminous.\n\nThis list is currently limited mostly to galactic and Magellanic Cloud objects, but a few stars in other local group galaxies can now be examined in enough detail to determine the luminosities. As of mid-2012 the list is more or less complete for stars down to 1,000,000 times the luminosity of the Sun. Some suspected binaries in this magnitude range are excluded because there is insufficient information about the luminosity of the individual components. Selected fainter stars are also shown for comparison.\n\nDespite their extreme luminosity, many of these stars are nevertheless too distant to be observed with the naked eye. Stars that are at least sometimes visible to the unaided eye have their apparent magnitude (6.5 or brighter) highlighted in blue.\n\nNote that even the most luminous stars are much less luminous than the more luminous persistent extragalactic objects, such as quasars. For example, 3C 273 has an average apparent magnitude of 12.8 (when observing with a telescope), but an absolute magnitude of −26.7. If this object were 10 parsecs away from Earth it would appear nearly as bright in the sky as the Sun (apparent magnitude −26.74). This quasar's luminosity is, therefore, about 2 trillion (10) times that of the Sun, or about 100 times that of the total light of average large galaxies like our Milky Way. (Note that quasars often vary somewhat in luminosity.)\n\nIn terms of gamma rays, a magnetar (type of neutron star) called SGR 1806-20, had an extreme burst reach Earth on 27 December 2004. It was the brightest event known to have impacted this planet from an origin outside the Solar System; if these gamma rays were visible, with an absolute magnitude of approx. −29, it would be brighter than the Sun \"(as measured by the Swift spacecraft)\".\n\nThe Gamma-ray burst GRB 971214 measured in 1998 was at the time thought to be the most energetic event in the observable universe, with the equivalent energy of several hundred supernovae. Later studies pointed out that the energy was probably the energy of one supernova which had been \"beamed\" towards Earth by the geometry of a relativistic jet.\n\n\n"}
{"id": "12118737", "url": "https://en.wikipedia.org/wiki?curid=12118737", "title": "List of systems engineering universities", "text": "List of systems engineering universities\n\nThis list of systems engineering at universities gives an overview of the different forms of systems engineering (SE) programs, faculties, and institutes at universities worldwide. Since there is no clear consensus on what constitutes a systems engineering degree, this list simply identifies the college and department offering degrees and the degrees offered.\n\nEducation in systems engineering is often observed to be an extension to the regular engineering courses, reflecting the industry attitude that engineering professionals need a foundational background in one of the traditional engineering disciplines (e.g. civil engineering, electrical engineering, industrial engineering) plus professional, real-world experience to be effective as systems engineers. Undergraduate university programs in systems engineering are rare.\n\nEducation in systems engineering can be viewed as \"systems-centric\" or \"domain-centric\". \nBoth categories strive to educate the systems engineer with capability to oversee interdisciplinary projects with the depth required of a core-engineer.\n\nThe International Council on Systems Engineering (INCOSE) maintains a continuously updated Directory of Systems Engineering Academic Programs worldwide.\n\nAs of 2006, some 75 institutions in United States offer 130 undergraduate and graduate programs in systems engineering.\n\nIn Asia:\nIn Europe:\n\nIn the USA:\n\nIn the Caribbean:\n\n\n"}
{"id": "2803803", "url": "https://en.wikipedia.org/wiki?curid=2803803", "title": "List of theatre personnel", "text": "List of theatre personnel\n\nThis is a list of the many positions involved in theatre, including both personnel employed temporarily for a specific production, permanent staff of a theatrical company and individuals employed in a performance venue.\n\nThese positions are responsible for the development of a production from initial inception till performance. Typically, although there will be \nsignificant involvement in the fabrication and initial development, these positions will not be involved in the performances.\n\nThese positions are responsible for the fabrication of a production \nprior to the initial performance. Although there will be significant \ninvolvement in initial development of a production, some of these \npositions may not be involved once performances before an audience \nbegin.\n\n\nThese staff members are responsible for running a theatre group from year to year. Their objective is to facilitate the success of individual productions. Staff positions help ensure good attendance in safe facilities. They help ensure the theatre remains financially solvent, that it is well run, and that it is perceived as an asset to the community it serves.\n\n\n"}
{"id": "7120167", "url": "https://en.wikipedia.org/wiki?curid=7120167", "title": "List of volcanoes in Panama", "text": "List of volcanoes in Panama\n\nThis is a list of active and extinct volcanoes in Panama. \n\n"}
{"id": "14983834", "url": "https://en.wikipedia.org/wiki?curid=14983834", "title": "Marc Zabeau", "text": "Marc Zabeau\n\nMarc Zabeau (born Lier, 1949) is a Belgian scientist and businessman.\n\nMarc Zabeau graduated in 1971 as a licentiate in zoology at the University of Ghent and obtained a PhD in 1974, studying the genetics of \"Escherichia coli\" in the lab of Jeff Schell.\n\nIn 1976, on an NFWO scholarship as a Fulbright Hayes postdoctoral fellow, he went for two years to the Cold Spring Harbor Laboratory in New York, the United States. From 1978 until 1983 he worked at the European Molecular Biology Laboratory in Heidelberg, Germany. during his stay in Heidelberg, he was appointed as professor of genetic engineering at the Vrije Universiteit Brussel.\n\nIn 1983, he became director of research of Plant Genetic Systems in Ghent, Belgium and in 1986 director of intellectual property and business development. He founded several biotech companies, such as Helix C.V. (Ghent, 1988), KeyeGene N.V. (Wageningen, 1989), GenScope Inc. (United States, 1995) and Methexis (Ghent, 1997). In 1999, he succeeded Marc Van Montagu as scientific director of the Department of Plant Systems Biology at the Flanders Institute for Biotechnology (VIB). In 2002, he was succeeded by Dirk Inzé. In 1999, he was appointed as full-time professor of genome biology and functional genomics at the University of Ghent.\n\nZabeau was formerly CEO of Trinean.\n\nHe is currently managing partner of Qbic Venture Partners.\n\n\n"}
{"id": "52601230", "url": "https://en.wikipedia.org/wiki?curid=52601230", "title": "Mary Budd Rowe", "text": "Mary Budd Rowe\n\nMary Budd Rowe (1925–1996) was an American science educator and education researcher, best known for her work on \"wait time,\" which showed that when teachers wait longer for children to answer a question, learning and inference can dramatically improve. She headed the science education research division of the National Science Foundation, was an advisor to several influential educational television shows, and served on numerous national standards and review committees.\n\nRowe authored over 100 journal articles and several books.\n\nBorn and raised in New Jersey, Rowe attributed her interest and approach to science education to an early encounter with Albert Einstein. On her middle school's annual visit to Princeton, she encountered the physicist gesturing and moving his hands rapidly, looking at a fountain. He asked Rowe, then in seventh grade, if she could stop the water long enough to see the shapes of the droplets. He then showed her how to wave her fingers to create a strobe effect and examine the shapes the water made. Rowe and Einstein experimented together for a few minutes to achieve the best effect. As Rowe would tell the story, as he left her he said \"Never forget that science is just that kind of exploring and fun.\"\n\n\"Nearly half a century later,\" wrote Rowe in 1995, \"I've spent an entire career trying to impart Einstein's words to adults and children all over the world: Science is exploring, and exploring is fun.\"\n\nRowe attended college in New Jersey, graduating with bachelor's degrees in biology and education in 1947. She earned a master's degree in zoology at the University of California, Berkeley in 1954. She earned a doctorate in science education from Stanford University in 1964.\n\nIn the early 1970s, Rowe published research newly describing a variable of teacher behavior, \"wait time,\" to measure the amount of time a teacher waits for a student to start answering a question and the amount of time a teacher waits once the student stops speaking before continuing the lesson or asking another question. Rowe found that a number of student outcomes improved when teachers waited longer for students to answer.\n\nRowe collected hundreds of recordings of classroom talk, and fed the sound from the tapes into a mechanical plotter to allow her to measure the lengths of pauses in conversation. This work found that teachers were waiting an average of less than a second for the student to answer, or for the student to continue his or her answer after pausing.\n\nWhen teachers were coached to wait longer, students use of language and logic improved, as did student and teacher attitudes and expectations. Students' answers increased in length by 300 to 700 percent, contained more inferences and speculative teaching, and shifted the classroom experience to more teacher and student exchanges — relying less on teacher show-and-tell. Moreover, the number of \"I don't know\" and non-responses decreased. Additional studies found consistent results in a variety of educational settings, from elementary to college-age students, and from special educational to gifted and talented classes.\n\nRowe and others' work also found that there was a significant threshold effect: when wait time increased to 2.7 seconds or longer, performance improved, smaller increases yielded significantly smaller benefits.\n\nRowe's classroom conversation studies also examined how teachers responded to student answers. Rose found that \"sanctioning behavior\"—either positive praise or negative feedback—discouraged the quality of student responses. Even when positive praise was consistently offered, student response became questioning (\"the answer is five?\"); in essence, Rowe found, praise led students to be more focused on discovering whether the teacher would approve than on discovering how the scientific phenomenon worked.\n\nRowe proposed that understanding science confers a sense of \"fate control,\" giving the student confidence that they can control outcomes in the world, and that reliance on teacher praise eroded this sense of controlling one's own fate.\n\nAs leader of the science education research division of the National Science Foundation from 1976 to 1980, and later in her career, Rowe advocated improved science education techniques across the United States and internationally. She served on several high-profile commissions, including the National Research Council Committee on Science Education Standards and Assessment.\n\nIn 1993-94, Rowe co-chaired the blue ribbon Federal Coordinating Council for Science, Engineering and Technology, which produced one of the most comprehensive federal reviews of science education programs. The panel recommended overhauling the approach to funding these programs, with far greater emphasis on assessing which programs were effective and coordinating across agencies. After the release of the report, Rowe said \"We're in a competitive, almost life-death kind of struggle with other countries. And I don't think we can afford to invest big amounts in programs that don't work.\"\n\nRowe also brought her expertise in science education to a number of broader forums. She served as a science advisor to educational television shows, \"3-2-1 Contact, Voyage of the Mimi, and Reading Rainbow.\"\n\nRowe's research on wait time has had an lasting impact, influencing how science educators are trained for decades after first publication. Upon Rowe's death in 1996, Richard Shavelson, dean of the Stanford School of Education, lauded Rowe as \"one of the giants in the field of science education and clearly looked upon as a leader.\"\n\n\"Teaching science as continuous inquiry.\" New York, McGraw-Hill, 1978. \n\n\"The process of knowing,\" Washington, D.C., National Science Teachers Association, 1990. .\n\n\"What research says to the science teacher.\" Washington D.C., National Science Teachers Association, 1978 .\n\n\"Education in the 80's--science.\" Washington, D.C., National Education Association, 1982. .\n\n\"Teaching children about life and earth sciences : ideas and activities every teacher and parent can use.\"With Elaine Levenson and Debra L Ellinger. New York : TAB Books, 1994. .\n\nPresident, National Science Teachers Association, 1987-88\n\nRobert H. Carleton Award for National Leadership in Science Education, National Science Teachers Association, 1981\n"}
{"id": "735306", "url": "https://en.wikipedia.org/wiki?curid=735306", "title": "Mercury-Redstone BD", "text": "Mercury-Redstone BD\n\nMercury-Redstone BD was an unmanned booster development flight in the U.S. Mercury program. It was launched on March 24, 1961 from Launch Complex 5 at Cape Canaveral, Florida. The mission used a boilerplate Mercury spacecraft and Redstone MRLV-5.\n\nAfter the problems that developed during the MR-2 mission carrying the chimpanzee Ham, it was apparent that the Redstone needed further development before it could be trusted to carry a human passenger.\n\nDr. Wernher von Braun added Mercury-Redstone BD (\"Booster Development\") to the launch schedule between the MR-2 and MR-3 missions. This went over the protests of some, including astronaut Alan Shepard, who argued that the problems on MR-2 had been quickly identified and easily fixed. Von Braun was adamant that the Redstone could not be considered man-rated until a completely perfect test flight and that the launch vehicle performance on MR-1A and MR-2 had not met acceptable standards for carrying a human passenger.\n\nThe cause of previous Redstone rocket over-accelerations was a servo valve that did not properly regulate the flow of hydrogen peroxide to the steam generator. This in turn overpowered the fuel pumps. The thrust regulator and velocity integrator were modified on the MR-BD and later Mercury-Redstone rockets to prevent them from exceeding the speed limit again. Other modifications were made to prevent engine cutoff from propellant depletion rather than a programmed signal, which had led to an inadvertent abort and LES activation on MR-2.\n\nAnother problem encountered in previous Mercury-Redstone flights were harmonic vibrations induced by aerodynamic stress in the topmost section of the elongated Redstone. To fix this problem, four stiffeners were added to the ballast section and 210 pounds (95 kg) of insulation was applied to the inner skin of the upper part of the Mercury Redstone instrument compartment.\n\nThe mission used a boilerplate Mercury spacecraft with an inert escape rocket. The spacecraft also did not have a retro package or posigrade rockets.\n\nThe MR-BD mission lasted eight minutes and 23 seconds. It reached an apogee of 113.5 miles (183 km) and a range of 307 miles (494 km). The peak velocity was 5,123 mph (8,245 km/h).\nThe spacecraft experienced a peak load of 11 \"g\" (108 m/s²). There was no intention to separate the Redstone rocket and boilerplate Mercury spacecraft and they impacted together 307 miles (494 km) downrange, 5 miles (8 km) short of the plan. They sank to the bottom of the Atlantic Ocean, exploding a sofar bomb en route. Booster performance was excellent other than some vibration issues in the adapter area.\n\nMR-BD was highly successful and led the way to the flight of Alan Shepard aboard MR-3.\n\nIn the USSR, the mission was erroneously recognized as failure:\n"}
{"id": "22131699", "url": "https://en.wikipedia.org/wiki?curid=22131699", "title": "Monolithic HPLC column", "text": "Monolithic HPLC column\n\nA monolithic HPLC column, or monolithic column, is a column used in high-performance liquid chromatography (HPLC). The internal structure of the monolithic column is created in such a way that many channels form inside the column. The material inside the column which separates the channels can be porous and functionalized. In contrast, most HPLC configurations use particulate packed columns; in these configurations, tiny beads of an inert substance, typically a modified silica, are used inside the column.\n\nIn analytical chromatography, the goal is to separate and uniquely identify each of the compounds in a substance. Alternatively, preparative scale chromatography is a method of purification of large batches of material in a production environment. The basic methods of separation in HPLC rely on a mobile phase (water, organic solvents, etc.) being passed through a stationary phase (particulate silica packings, monoliths, etc.) in a closed environment (column); the differences in reactivity among the solvent of interest and the mobile and stationary phases distinguish compounds from one another in a series of adsorption and desorption phenomena. The results are then visually displayed in a resulting chromatogram. Stationary phases are available in many varieties of packing styles as well as chemical structures and can be functionalized for added specificity. Monolithic-style columns, or monoliths, are one of many types of stationary phase structure.\n\nMonoliths, in chromatographic terms, are porous rod structures characterized by mesopores and macropores. These pores provide monoliths with high permeability, a large number of channels, and a high surface area available for reactivity. The backbone of a monolithic column is composed of either an organic or inorganic substrate, and can easily be chemically altered for specific applications. Their unique structure gives them several physico-mechanical properties that enable them to perform competitively against traditionally packed columns.\n\nHistorically, the typical HPLC column consists of high-purity particulate silica compressed into stainless steel tubing. To decrease run times and increase selectivity, smaller diffusion distances have been pursued. To achieve smaller diffusion distances there has been a decrease in the particle sizes. However, as the particle size decreases, the backpressure (for a given column diameter and a given volumetric flow) increases proportionally. Pressure is inversely proportional to the square of the particle size; i.e., when particle size is halved, pressure increases by a factor of four. This is because as the particle sizes get smaller, the interstitial voids (the spaces between the particles) do as well, and it is harder to push the compounds through the smaller spaces. Modern HPLC systems are generally designed to withstand about of backpressure in order to deal with this problem.\n\nMonoliths also have very short diffusion distances, while also providing multiple pathways for solute dispersion. Packed particle columns have pore connectivity values of about 1.5, while monoliths have values ranging from 6 to greater than 10. This means that, in a particulate column, a given analyte may diffuse into and out of the same pore, or enter through one pore and exit through a connected pore. By contrast, an analyte in a monolith is able to enter one channel and exit through any of 6 or more different venues. Little of the surface area in a monolith is inaccessible to compounds in the mobile phase. The high degree of interconnectivity in monoliths confers an advantage seen in the low backpressures and readily achievable high flow rates.\n\nMonoliths are ideally suited for large molecules. As mentioned previously, particle sizes are decreasing in an attempt to achieve higher resolution and faster separations, which led to higher backpressures. When the smaller particle sizes are used to separate biomolecules, backpressures increase further because of the large molecule size. In monoliths, where backpressures are low and channel sizes are large, small molecule separations are less efficient. This is demonstrated by the dynamic binding capacities, a measure of how much sample can bind to the surface of the stationary phase. Dynamic binding capacities of monoliths for large molecules can be an order of ten times greater than that for particulate packings.\n\nMonoliths exhibit no shear forces or eddying effects. High interconnectivity of the mesopores allows for multiple avenues of convective flow through the column. Mass transport of solutes through the column is relatively unaffected by flow rate. This is completely at odds to traditional particulate packings, whereby eddy effects and shear forces contribute greatly to the loss of resolution and capacity, as seen in the vanDeemter curve. Monoliths can, however, suffer from a different flow disadvantage: wall effects. Silica monoliths, especially, have a tendency to pull away from the sides of their column encasing. When this happens, the flow of the mobile phase occurs around the stationary phase as well as through it, decreasing resolution. Wall effects have been reduced greatly by advances in column construction.\n\nOther advantages of monoliths conferred by their individual construction include greater column to column and batch to batch reproducibility. One technique of creating monolith columns is to polymerize the structure in situ. This involves filling the mold or column tubing with a mixture of monomers, a cross-linking agent, a free-radical initiator, and a porogenic solvent, then initiating the polymerization process under carefully controlled thermal or irradiating conditions. Monolithic in situ polymerization avoids the primary source of column to column variability, which is the packing procedure.\n\nAdditionally, packed particle columns must be maintained in a solvent environment and cannot be exposed to air during or after the packing procedure. If exposed to air, the pores dry out and no longer provide adequate surface area for reactivity; the column must be repacked or discarded. Further, because particle compression and packing uniformity are not relevant to monoliths, they exhibit greater mechanical robustness; if particulate columns are dropped, for example, the integrity of the column may be corrupted. Monolithic columns are more physically stable than their particulate counterparts.\n\nThe roots of liquid chromatography extend back over a century ago to 1900, when Russian botanist Mikhail Tsvet began experimenting with plant pigments in chlorophyll. He noted that, when a solvent was applied, distinct bands appeared that migrated at different rates along a stationary phase. For this new observation, he coined the term “chromatography,” a colored picture. His first lecture on the subject was presented in 1903, but his most important contribution occurred three years later, in 1906, when the paper “Adsorption analysis and chromatographic method. Applications on the chemistry of chlorophyll,” was published. Rivalry with a colleague who readily and vocally denounced his work meant that chromatographic analysis was shelved for almost 25 years. The great irony of the matter is that it was his rival’s students who later took up the chromatography banner in their work with carotins.\n\nGreatly unchanged from Tswett’s time until the 1940s, normal phase chromatography was performed by passing a gravity-fed solvent through small glass tubes packed with pellicular adsorbent beads. It was in the 1940s, however, that there was a great revolution in gas chromatography (GC). Although GC was a wonderful technique for analyzing inorganic compounds, less than 20% of organic molecules are able to be separated using this technique. It was Richard Synge, who in 1952 won the Nobel Prize in Chemistry for his work with partition chromatography, who applied the theoretical knowledge gained from his work in GC to LC. From this revolution, the 1950s also saw the advent of paper chromatography, reversed-phase partition chromatography (RPC), and hydrophobic interaction chromatography (HIC). The first gels for use in LC were created using cross-linked dextrans (Sephadex) in an attempt to realize Synge’s prediction that a unique single-piece stationary phase could provide an ideal chromatographic solution.\n\nIn the 1960s, polyacrylamide and agarose gels were created in a further attempt to create a single-piece stationary phase, but the purity of and stability of available components did not prove useful for implementation in the HPLC. In this decade, affinity chromatography was invented, an ultra-violet (UV) detector was used for the first time in conjunction with LC, and, most importantly, the modern HPLC was born. Csaba Horvath led the development of modern HPLC by piecing together laboratory equipment to suit his purposes. In 1968, Picker Nuclear Company marketed the first commercially available HPLC as a “Nucleic Acid Analyzer.” The following year, the first international symposia on HPLC was held, and Kirkland at DuPont was able to functionalize controlled porosity pellicular particles for the first time.\n\nThe 1970s and 1980s witnessed a renewed interest in separations media with reduced interparticular void volumes. Perfusion chromatography showed, for the first time, that chromatography media could support high flow rates without sacrificing resolution. Monoliths aptly fit into this new class of media, as they exhibit no void volume and can withstand flow rates up to 9mL/minute. Polymeric monoliths as they exist today were developed independently by three different labs in the late 1980s led by Hjerten, Svec, and Tennikova. Simultaneously, bioseparations became increasingly important, and monolith technologies proved beneficial in biotechnology separations.\n\nThough industry focus in the 1980s was on biotechnology, focus in the 1990s shifted to process engineering. While mainstream chromatographers were using 3μm particulate columns, sub-2μm columns were in research phase. The smaller particles meant better resolution and shorter run times; there was also an associated increase in backpressure. In order to withstand the pressure, a new field of chromatography came into being: UHPLC or UPLC- ultra high pressure liquid chromatography. The new instruments were able to endure pressures of up to , as opposed to conventional machines, which, as previously state, can hold up to . UPLC is an alternative solution to the same problems monolithic columns solve. Similarly to UPLC, monolith chromatography can help the bottom line by increasing sample throughput, but without the need to spend capital on new equipment.\n\nIn 1996, Nobuo Tanaka, at the Kyoto Institute of Technology, prepared silica monoliths using a colloidal suspension synthesis (aka “sol-gel”) developed by a colleague. The process is different from that used in polymeric monoliths. Polymeric monoliths, as mentioned above, are created in situ, using a mixture of monomers and a porogen within the column tubing. Silica monoliths, on the other hand, are created in a mold, undergo a significant amount of shrinkage, and are then clad in a polymeric shrink tubing like PEEK (polyetheretherketone) to reduce wall effects. This method limits the size of columns that can be produced to less than 15 cm long, and though standard analytical inner diameters are readily achieved, there is currently a trend in developing nanoscale capillary and prep scale silica monoliths.\n\nSilica monoliths have only been commercially available since 2001, when Merck began their Chromolith campaign. The Chromolith technology was licensed from Soga and Nakanishi’s group at Kyoto University. The new product won the PittCon Editors’ Gold Award for Best New Product, as well as an R&D 100 Award, both in 2001.\n\nIndividual monolith columns have a life cycle that generally exceeds that of its particulate competitors. When selecting an HPLC column supplier, column lifetime was second only to column-to-column reproducibility in importance to the purchaser. Chromolith columns, for example, have demonstrated reproducibility of 3,300 sample injections and 50,000 column volumes of mobile phase. Also important to the life cycle of the monolith is its increased mechanical robustness; polymeric monoliths are able to withstand pH ranges from 1 to 14, can endure elevated temperatures, and do not need to be handled delicately. “Monoliths are still teenagers,” affirms Frantisec Svec, a leader in the field of novel stationary phases for LC.\n\nLiquid chromatography as we know it today really got its start in 1969, when the first modern HPLC was designed and marketed as a nucleic acid analyzer. Columns throughout the 1970s were unreliable, pump flow rates were inconsistent, and many biologically active compounds escaped detection by UV and fluorescence detectors. Focus on purification methods in the '70s morphed into faster analyses in the 1980s, when computerized controls were integrated into HPLC equipment. Higher degrees of computerization then led to emphasis on more precise, faster, automated equipment in the 1990s. Atypical of many technologies of the '60s and '70s, the emphasis in improvements was not on “bigger and better,” but on “smaller and better”. At the same time the HPLC user-interface was improving, it was critical to be able to isolate hundreds of peptides or biomarkers from ever decreasing sample sizes.\n\nLaboratory analytical instrumentation has only been recognized as a separate and distinct industry by NAICS and SIC since 1987. This market segmentation includes not only gas and liquid chromatography, but also mass spectrometry and spectrophotometric instruments. Since first recognized as a separate market, sales of analytical laboratory equipment increased from about $3.5 billion in 1987 to more than $26 billion in 2004. Revenues in the world liquid chromatography market, specifically, are expected to grow from $3.4 billion in 2007 to $4.7 billion in 2013, with a slight decrease in spending expected in 2008 and 2009 from the worldwide economic slump and decreased or stagnant spending. The pharmaceutical industry alone accounts for 35% of all the HPLC instruments in use. The main source of growth in LC stems from biosciences and pharmaceutical companies.\n\nIn its earliest form, liquid chromatography was used to separate the pigments of chlorophyll by a Russian botanist. Decades later, other chemists used the procedure for the study of carotins. Liquid chromatography was then used for the isolation of small molecules and organic compounds like amino acids, and most recently has been used in peptide and DNA research. Monolith columns have been instrumental in advancing the field of biomolecular research.\n\nIn recent trade shows and international meetings for HPLC, interest in column monoliths and biomolecular applications has grown steadily, and this correlation is no coincidence. Monoliths have been shown to possess great potential in the “omics” fields- genomics, proteomics, metabolomics, and pharmacogenomics, among others. The reductionist approach to understanding the chemical pathways of the body and reactions to different stimuli, like drugs, are essential to new waves of healthcare like personalized medicine.\n\nPharmacogenomics studies how responses to pharmaceutical products differ in efficacy and toxicity based on variations in the patient’s genome; it is a correlation of drug response to gene expression in a patient. Jeremy K. Nicholson of the Imperial College, London, used a postgenomic viewpoint to understand adverse drug reactions and the molecular basis of human disesase. His group studied gut microbial metabolic profiles and were able to see distinct differences in reactions to drug toxicity and metabolism even among various geographical distributions of the same race. Affinity monolith chromatography provides another approach to drug response measurements. David Hage at the University of Nebraska binds ligands to monolithic supports and measures the equilibrium phenomena of binding interactions between drugs and serum proteins. A monolith-based approach at the University of Bologna, Italy, is currently in use for high-speed screening of drug candidates in the treatment of Alzheimer's. In 2003, Regnier and Liu of Purdue University described a multi-dimensional LC procedure for identifying single nucleotide polymorphisms (SNPs) in proteins. SNPs are alterations in the genetic code that can sometimes cause changes in protein conformation, as is the case with sickle cell anemia. Monoliths are particularly useful in these kinds of separations because of their superior mass transport capabilities, low backpressures coupled with faster flow rates, and relative ease of modification of the support surface.\n\nBioseparations on a production scale are enhanced by monolith column technologies as well. The fast separations and high resolving power of monoliths for large molecules means that real-time analysis on production fermentors is possible. Fermentation is well known for its use in making alcoholic beverages, but is also an essential step in the production of vaccines for rabies and other viruses. Real-time, on-line analysis is critical for monitoring of production conditions, and adjustments can be made if necessary. Boehringer Ingelheim Austria has validated a method with cGMP (commercial good manufacturing practices) for production of pharmaceutical-grade DNA plasmids. They are able to process 200L of fermentation broth on an 800mL monolith. At BIA Separations, processing time of the tomato mosaic virus decreased considerably from the standard five days of manually intensive work to equivalent purity and better recovery in only two hours with a monolith column. Other viruses have been purified on monoliths as well.\n\nAnother area of interest for HPLC is forensics. GC-MS (Gas Chromatography-Mass Spectroscopy) is generally considered the gold standard for forensic analysis. It is used in conjunction with online databases for rapid analysis of compounds in tests for blood alcohol, cause of death, street drugs, and food analysis, especially in poisoning cases. Analysis of buprenorphine, a heroin substitute, demonstrated the potential utility of multidimensional LC as a low-level detection method. HPLC methods can measure this compound at 40 ng/mL, compared to GC-MS at 0.5 ng/mL, but LC-MS-MS can detect buprenorphine at levels as low as 0.02 ng/mL. The sensitivity of multidimensional LC is therefore 2000 times greater than that of conventional HPLC.\n\nThe liquid chromatography marketplace is incredibly diverse. Five to ten firms are consistently market leaders, yet nearly half of the market is made up of small, fragmented companies. This section of the report will focus on the roles that a few companies have had in bringing monolith column technologies to the commercial market.\n\nIn 1998, start-up biotechnology company BIA Separations of Ljubljana, Slovenia, came into being. The technology was originally developed by Tatiana Tennikova and Frantisek Svec during a collaboration between their respective institutes. The patent for these columns was acquired by BIA Separations and Ales Podgornik and Milos Barut developed the first commercially available monolith column in the form of a short disc encapsulated in a plastic housing. Trademarked CIM, BIA Separations has since introduced full lines of reversed-phase, normal-phase, ion-exchange, and affinity polymeric monoliths. Ales Podgornik and Janez Jancar then went on to develop large scale tube monolithic columns for industrial use. The largest column currently available is 8L. In May 2008, LC instrumentation powerhouse Agilent technologies agreed to market BIA Separations’ analytical columns based on monolith technology. Agilent’s commercialized the columns with strong and weak ion exchange phases and Protein A in September 2008 when they unveiled their new Bio-Monolith product line at the BioProcess International conference.\n\nWhile BIA Separations was the first to commercially market polymeric monoliths, Merck KGaA was the first company to market silica monoliths. In 1996, Tanaka and coworkers at the Kyoto Institute of Technology published extensive work on silica monolith technologies. Merck was later issued a license from Kyoto Institute of Technology to develop and produce the silica monoliths. Promptly thereafter, in 2001, Merck introduced its Chromolith line of monolithic HPLC columns at analytical instrumentation trade show PittCon. Initially, says Karin Cabrera, senior scientist at Merck, the high flow rate was the selling point for the Chromolith line. Based on customer feedback, though, Merck soon learned that the columns were more stable and longer-lived than particle-packed columns. The columns were the recipients of various new product awards. Difficulties in production of the silica monoliths and tight patent protection have precluded attempts by other companies at developing a similar product. It has been noted that there are more patents concerning how to encapsulate the silica rod than there are on the manufacture of the silica itself.\n\nHistorically, Merck has been known for its superior chemical products, and, in liquid chromatography, for the purity and reliability of its particulate silica. Merck is not known for its LC columns. Five years after the introduction of its Chromolith line, Merck made a very strategic marketing decision. They granted a worldwide sublicense of the technology to a small (less than $100M in sales), innovative company well known for its cutting-edge column technology: Phenomenex. This was a superior strategic move for two reasons. As mentioned above, Merck is not well known for its column manufacturing. Furthermore, having more than one silica monolith manufacturer serves to better validate the technology. Having sublicensed the technology from Merck, Phenomenex introduced its Onyx product line in January 2005.\n\nOn the other side of monolith technologies are the polymerics. Unlike the inorganic silica columns, the polymer monoliths are made of an organic polymer base. Dionex, traditionally known for its ion chromatography capabilities, has led this side of the field. In the 1990s, Dionex first acquired a license for the polymeric monolith technology developed by leading monolithic chromatography researcher Frantisec Svec while he was at Cornell University. In 2000, they acquired LC Packings, whose competencies were in LC column packings. LC Packings/Dionex revealed their first monolithic capillary column at the Montreux LC-MS Conference. Earlier that year, another company, Isco, introduced a polystyrene divinylbenzene (PS-DVB) monolith column under the brand SWIFT. In January 2005, Dionex was sold the rights to Teledyne Isco’s SWIFT media products, intellectual property, technology, and related assets. Though the core competencies of Dionex have traditionally been in ion chromatography, through strategic acquisitions and technology transfers, it has quickly established itself as the primary producer of polymeric monoliths.\n\nThough the many advances of HPLC and monoliths are highly visible within the confines of the analytical and pharmaceutical industries, it is unlikely that general society is aware of these developments. Currently, consumers may witness technology developments in the analytical sciences industry in the form of a broader array of available pharmaceutical products of higher purity, advanced forensic testing in criminal trials, better environmental monitoring, and faster returns on medical tests. In the future, presumably, this may not be the case. As medicine becomes more individualized over time, consumer awareness that something is improving their quality of care seems more likely. The further thought that monoliths or HPLC are involved is unlikely to concern the general public, however.\n\nThere are two main cost drivers behind technological change in this industry. Though many different analytical areas use LC, including food and beverage industries, forensics labs, and clinical testing facilities, the largest impetus toward technology developments comes from the research and development and production arms of the pharmaceutical industry. The areas in which high-throughput monolithic column technologies are likely to have the largest economic impact are R&D and downstream processing.\n\nFrom the Research and Development field comes the desire for more resolved, faster separations from smaller sample quantities. The only phase of drug development under direct control of a pharmaceutical company is the R&D stage. The goal of analytical work is to obtain as much information as possible from the sample. At this stage, high-throughput and analysis of tiny sample quantities are critical. Pharmaceutical companies are looking for tools that will better enable them to measure and predict the efficacy of candidate drugs in shorter times and with less expensive clinical trials. To this end, nano-scale separations, highly automated HPLC equipment, and multi-dimensional chromatography have become influential.\n\nThe prevailing method to increase the sensitivity of analytical methods has been multi-dimensional chromatography. This practice uses other analysis techniques in conjunction with liquid chromatography. For example, mass spectrometry (MS) has very much gained in popularity as an on-line analytical technique following HPLC. It is limited, however, in that MS, like nuclear magnetic resonance spectroscopy (NMR) or electrospray ionization techniques (ESI), is only feasible when using very small quantities of solute and solvent; LC-MS is used with nano or capillary scale techniques, but cannot be used in prep-scale. Another tactic for increasing selectivity in multi-dimensional chromatography is to use two columns with different selectivity orthogonally; ie… linking an ion exchange column to a C18 endcapped column. In 2007, Karger reported that, through multi-dimensional chromatography and other techniques, starting with only about 12,000 cells containing 1-4μg of protein, he was able to identify 1867 unique proteins. Of those, Karger can isolate 4 that may be of interest as cervical cancer markers. Today, liquid chromatographers using multi-dimensional LC can isolate compounds at the femtomole (10 mole) and attomole (10 mole) levels.\n\nAfter a drug has been approved by the U.S. Food and Drug Administration (FDA), the emphasis at a pharmaceutical company is on getting a product to market. This is where prep or process scale chromatography has a role. In contrast to analytical analysis, preparatory scale chromatography focuses on isolation and purity of compounds. There is a trade-off between the degree of purity of compound and the amount of time required to achieve that purity. Unfortunately, many of the preparatory or process scale solutions used by pharmaceutical companies are proprietary, due to difficulties in patenting a process. Hence, there is not a great deal of literature available. However, some attempts to address the problems of prep scale chromatography include monoliths and simulated moving beds.\n\nA comparison of immunoglobulin protein capture on a conventional column and a monolithic column yields some economically interesting results. If processing times are equivalent, process volumes of IgG, an antibody, are 3,120L for conventional columns versus 5,538L for monolithic columns. This represents a 78% increase in process volume efficiency, while at the same time only a tenth of the media waste volume is generated. Not only is the monolith column more economically prudent when considering the value of product processing times, but, at the same time, less media is used, representing a significant reduction in variable costs.\n\n"}
{"id": "39284981", "url": "https://en.wikipedia.org/wiki?curid=39284981", "title": "Moron (bacteriophage)", "text": "Moron (bacteriophage)\n\nA moron, in the context of bacteriophage genetics, is an extra gene in a prophage genome without a function in the phage's lysogenic cycle. These genes may code for products beneficial to the phage's bacterial host, as with the example of gp15 of phage HK97 serving as a superinfection exclusion protein. The term moron comes from the notion that the additional genes mean that these bacteriophage genomes have \"more on\" them.\n"}
{"id": "873854", "url": "https://en.wikipedia.org/wiki?curid=873854", "title": "Muhammed Faris", "text": "Muhammed Faris\n\nMuhammed Ahmed Faris ( \"Muḥammad ʾAḥmad Fāris\"; born 26 May 1951) is a Syrian military aviator. He was the first Syrian and the second Arab in space.\n\nBorn in Aleppo, Syria, he was a pilot in the Syrian Air Force with the rank of a colonel. He specialized in navigation when he was selected to participate in the Intercosmos spaceflight program on 30 September 1985.\n\nHe flew as Research Cosmonaut in the Interkosmos program on Soyuz TM-3 to the Mir space station in July 1987, spending 7 days 23 hours and 5 minutes in space. He returned to Earth aboard Soyuz TM-2.\n\nFaris was awarded the title Hero of the Soviet Union on 30 July 1987. He was also awarded the Order of Lenin.\n\nAfter his spaceflight, he returned to the Syrian Air Force and lived in Aleppo. He is married and has three children.\n\nOn 4 August 2012, during the Syrian civil war, he defected from and joined the armed opposition.\n\nOn 13 September 2012, made an exclusive interview with Al Aan TV and covered many topics regarding the Syrian civil war.\n\nHe is also part of the Syrian National Coordination Committee for Democratic Change, an anti-Assad grouping.\n\nIn a March 2016 interview as a Syrian refugee in Turkey, Faris stated regarding the ongoing Syrian Civil War \"I tell Europe if you don't want refugees, then you should help us get rid of this regime,\" adding \"I am very sorry about the Russian interference, which has stood on the side of dictator Bashar Assad, and has begun to kill the Syrian people with their planes\".\n\nIn September 2017, Faris was appointed Defense Minister of the Syrian Interim Government, a self-appointed opposition grouping.\n\n\n"}
{"id": "55121627", "url": "https://en.wikipedia.org/wiki?curid=55121627", "title": "Parallel force system", "text": "Parallel force system\n\nIn mechanical engineering, a parallel force system is a situation in which two forces of equal magnitude act in the same direction within the same plane, with the counter force in the middle. An example of this is a see saw. The children are applying the two forces at the ends, and the fulcrum in the middle gives the counter force to maintain the see saw in neutral position. Another example are the major vertical forces on an airplane in flight (see image at right).\n\n"}
{"id": "54366888", "url": "https://en.wikipedia.org/wiki?curid=54366888", "title": "Photomutagenic", "text": "Photomutagenic\n\nPhotomutagenicity is the property of being photomutagenic, in that when irradiated by visible or UV light, a photomutagenic chemical substance (\"e.g\"., umbelliferone) - found in or on an organism - can cause mutation(s) of that particular organism. Other photomutagenic substances include furocoumarins and limettin.\n"}
{"id": "15816225", "url": "https://en.wikipedia.org/wiki?curid=15816225", "title": "Raymond R. Rogers", "text": "Raymond R. Rogers\n\nRaymond Robert Rogers is a professor and chair of geology at Macalester College. He earned his B.S. in geology from Northern Arizona University in 1985, his M.S. from the University of Montana in 1989, and his Ph.D. from the University of Chicago in 1995 Rogers' specializations are as a sedimentary geologist and taphonomist, with a focus on the study of terrestrial and marginal marine depositional systems, particularly those with abundant fossils. He is one of the editors of the book \"Bonebeds: Genesis, Analysis, and Paleobiological Significance\", from the University Of Chicago Press (2008).\n\n\n"}
{"id": "43450635", "url": "https://en.wikipedia.org/wiki?curid=43450635", "title": "Refractive index and extinction coefficient of thin film materials", "text": "Refractive index and extinction coefficient of thin film materials\n\nA. R. Forouhi and I. Bloomer deduced dispersion equations for the refractive index, \"n\", and extinction coefficient, \"k\", which were published in 1986 and 1988. The 1986 publication relates to amorphous materials, while the 1988 publication relates to crystalline. Subsequently, in 1991, their work was included as a chapter in “The Handbook of Optical Constants”. The Forouhi–Bloomer dispersion equations describe how photons of varying energies interact with thin films. When used with a spectroscopic reflectometry tool, the Forouhi–Bloomer dispersion equations specify \"n\" and \"k\" for amorphous and crystalline materials as a function of photon energy \"E\". Values of \"n\" and \"k\" as a function of photon energy, \"E\", are referred to as the spectra of \"n\" and \"k\", which can also be expressed as functions of wavelength of light, λ, since \"E = hc/λ\". The symbol \"h\" represents Planck’s constant and \"c\", the speed of light in vacuum. Together, \"n\" and \"k\" are often referred to as the “optical constants” of a material (though they are not constants since their values depend on photon energy).\n\nThe derivation of the Forouhi–Bloomer dispersion equations is based on obtaining an expression for \"k\" as a function of photon energy, symbolically written as \"k\"(E), starting from first principles quantum mechanics and solid state physics. An expression for \"n\" as a function of photon energy, symbolically written as \"n\"(E), is then determined from the expression for \"k\"(E) in accordance to the Kramers–Kronig relations which states that \"n\"(E) is the Hilbert Transform of \"k\"(E).\n\nThe Forouhi–Bloomer dispersion equations for \"n\"(E) and \"k\"(E) of amorphous materials are given as:\n\nformula_1\n\nformula_2\n\nThe five parameters A, B, C, E, and \"n\"(∞) each have physical significance. E is the optical energy band gap of the material. A, B, and C depend on the band structure of the material. They are positive constants such that 4C-B > 0. Finally, n(∞), a constant greater than unity, represents the value of \"n\" at \"E\" = ∞. The parameters B and C in the equation for \"n\"(E) are not independent parameters, but depend on A, B, C, and E. They are given by:\n\nformula_3\n\nformula_4\n\nwhere\n\nformula_5\n\nThus, for amorphous materials, a total of five parameters are sufficient to fully describe the dependence of both \"n\" and \"k\" on photon energy, E.\n\nFor crystalline materials which have multiple peaks in their \"n\" and \"k\" spectra, the Forouhi–Bloomer dispersion equations can be extended as follows:\n\nformula_6\n\nformula_7\n\nThe number of terms in each sum, q, is equal to the number of peaks in the \"n\" and \"k\" spectra of the material. Every term in the sum has its own values of the parameters A, B, C, E, as well as its own values of B and C. Analogous to the amorphous case, the terms all have physical significance.\n\nThe refractive index (\"n\") and extinction coefficient (\"k\") are related to the interaction between a material and incident light, and are associated with refraction and absorption (respectively). They can be considered as the “fingerprint of the material\". Thin film material coatings on various substrates provide important functionalities for the microfabrication industry, and the \"n\", \"k\", as well as the thickness, \"t\", of these thin film constituents must be measured and controlled to allow for repeatable manufacturing.\n\nThe Forouhi–Bloomer dispersion equations for \"n\" and \"k\" were originally expected to apply to semiconductors and dielectrics, whether in amorphous, polycrystalline, or crystalline states. However, they have been shown to describe the \"n\" and \"k\" spectra of transparent conductors, as well as metallic compounds. The formalism for crystalline materials was found to also apply to polymers, which consist of long chains of molecules that do not form a crystallographic structure in the classical sense.\n\nOther dispersion models that can be used to derive \"n\" and \"k\", such as Tauc-Lorentz, can be found in the literature. Two well-known models—Cauchy and Sellmeier—provide empirical expressions for \"n\" valid over a limited measurement range, and are only useful for non-absorbing films where \"k\"=0. Consequently, the Forouhi–Bloomer formulation has been used for measuring thin films in various applications.\n\nIn the following discussions, all variables of photon energy, \"E\", will be described in terms of wavelength of light, λ, since experimentally variables involving thin films are typically measured over a spectrum of wavelengths. The \"n\" and \"k\" spectra of a thin film cannot be measured directly, but must be determined indirectly from measurable quantities that depend on them. Spectroscopic reflectance, \"R(λ\"), is one such measurable quantity. Another, is spectroscopic transmittance, \"T(λ)\", applicable when the substrate is transparent. Spectroscopic reflectance of a thin film on a substrate represents the ratio of the intensity of light reflected from the sample to the intensity of incident light, measured over a range of wavelengths, whereas spectroscopic transmittance, \"T(λ)\", represents the ratio of the intensity of light transmitted through the sample to the intensity of incident light, measured over a range of wavelengths; typically, there will also be a reflected signal, \"R(λ)\", accompanying \"T(λ)\".\n\nThe measurable quantities, \"R(λ)\" and \"T(λ)\" depend not only on \"n(λ)\" and \"k(λ)\" of the film, but also on film thickness, \"t\", and \"n(λ)\" and \"k(λ)\" of the substrate. For a silicon substrate, the \"n(λ)\" and \"k(λ)\" values are known and are taken as a given input. The challenge of characterizing thin films involves extracting \"t\", \"n(λ)\" and \"k(λ)\" of the film from the measurement of \"R(λ)\" and/or \"T(λ)\". This can be achieved by combining the Forouhi–Bloomer dispersion equations for \"n(λ)\" and \"k(λ)\" with the Fresnel equations for the reflection and transmission of light at an interface to obtain theoretical, physically valid, expressions for reflectance and transmittance. In so doing, the challenge is reduced to extracting the five parameters A, B, C, E, and \"n(∞)\" that constitute \"n(λ)\" and \"k(λ)\", along with film thickness, \"t\", by utilizing a nonlinear least squares regression analysis fitting procedure. The fitting procedure entails an iterative improvement of the values of A, B, C, E, \"n(∞)\", \"t\", in order to reduce the sum of the squares of the errors between the theoretical \"R(λ)\" or theoretical \"T(λ)\" and the measured spectrum of \"R(λ)\" or \"T(λ)\".\nBesides spectroscopic reflectance and transmittance, spectroscopic ellipsometry can also be used in an analogous way to characterize thin films and determine \"t\", \"n(λ)\" and \"k(λ)\".\n\nThe following examples show the versatility of using the Forouhi–Bloomer dispersion equations to characterize thin films utilizing a tool based on near-normal incident spectroscopic reflectance. Near-normal spectroscopic transmittance is also utilized when the substrate is transparent. The \"n(λ)\" and \"k(λ)\" spectra of each film are obtained along with film thickness, over a wide range of wavelengths from deep ultraviolet to near infrared wavelengths (190–1000 nm).\n\nIn the following examples, the notation for theoretical and measured reflectance in the spectral plots is expressed as “R-theor” and “R-meas”, respectively.\n\nBelow are schematics depicting the thin film measurement process:\n\nThe Forouhi–Bloomer dispersion equations in combination with Rigorous Coupled-Wave Analysis (RCWA) have also been used to obtain detailed profile information (depth, CD, sidewall angle) of trench structures. In order to extract structure information, polarized broadband reflectance data, \"Rs\" and \"Rp\", must be collected over a large wavelength range from a periodic structure (grating), and then analyzed with a model that incorporates Forouhi–Bloomer dispersion equations and RCWA. Inputs into the model include grating pitch and \"n\" and \"k\" spectra of all materials within the structure, while outputs can include Depth, CDs at multiple locations, and even sidewall angle. The \"n\" and \"k\" spectra of such materials can be obtained in accordance with the methodology described in this section for thin film measurements.\n\nBelow are schematics depicting the measurement process for trench structures. Examples of trench measurements then follow.\n\nExample 1 shows one broad maximum in the \"n(λ)\" and \"k(λ)\" spectra of the a-Si film, as is expected for amorphous materials. As a material transitions toward crystallinity, the broad maximum gives way to several sharper peaks in its \"n(λ)\" and \"k(λ)\" spectra, as demonstrated in the graphics.\n\nWhen the measurement involves two or more films in a stack of films, the theoretical expression for reflectance must be expanded to include the \"n(λ)\" and \"k(λ)\" spectra, plus thickness, \"t\", of each film. However, the regression may not converge to unique values of the parameters, due to the non-linear nature of the expression for reflectance. So it is helpful to eliminate some of the unknowns . For example, the \"n(λ)\" and \"k(λ)\" spectra of one or more of the films may be known from the literature or previous measurements, and held fixed (not allowed to vary) during the regression. To obtain the results shown in Example 1, the \"n(λ)\" and \"k(λ)\" spectra of the SiO layer was fixed, and the other parameters, \"n(λ)\" and \"k(λ)\" of a-Si, plus thicknesses of both a-Si and SiO were allowed to vary.\n\nPolymers such as photoresist consist of long chains of molecules which do not form a crystallographic structure in the classic sense. However, their \"n(λ)\" and \"k(λ)\" spectra exhibit several sharp peaks rather than a broad maximum expected for non-crystalline materials. Thus, the measurement results for a polymer are based on the Forouhi–Bloomer formulation for crystalline materials. Most of the structure in the \"n(λ)\" and \"k(λ)\" spectra occurs in the deep UV wavelength range and thus to properly characterize a film of this nature, it is necessary that the measured reflectance data in the deep UV range is accurate.\n\nThe figure shows a measurement example of a photoresist (polymer) material used for 248 nm micro-lithography. Six terms were used in the Forouhi–Bloomer equations for crystalline materials to fit the data and achieve the results.\n\nIndium tin oxide (ITO) is a conducting material with the unusual property that it is transparent, so it is widely used in the flat panel display industry. Reflectance and transmittance measurements of the uncoated glass substrate were needed in order to determine the previously unknown \"n(λ)\" and \"k(λ)\" spectra of the glass. The reflectance and transmittance of ITO deposited on the same glass substrate were then measured simultaneously, and analyzed using the Forouhi–Bloomer equations.\n\nAs expected, the \"k(λ)\" spectrum of ITO is zero in the visible wavelength range, since ITO is transparent. The behavior of the \"k(λ)\" spectrum of ITO in the near-infrared (NIR) and infrared (IR) wavelength ranges resembles that of a metal: non-zero in the NIR range of 750–1000 nm (difficult to discern in the graphics since its values are very small) and reaching a maximum value in the IR range (λ>1000 nm). The average \"k\" value of the ITO film in the NIR and IR range is 0.05.\n\nWhen dealing with complex films, in some instances the parameters cannot be resolved uniquely. To constrain the solution to a set of unique values, a technique involving multi-spectral analysis can be used. In the simplest case, this entails depositing the film on two different substrates and then simultaneously analyzing the results using the Forouhi–Bloomer dispersion equations.\n\nFor example, the single measurement of reflectance in 190–1000 nm range of GeSe/Si does not provide unique \"n(λ)\" and \"k(λ)\" spectra of the film. However, this problem can be solved by depositing the same GeSe film on another substrate, in this case oxidized silicon, and then simultaneously analyzing the measured reflectance data to determine:\n\nThe trench structure depicted in the adjacent diagram repeats itself in 160 nm intervals, that is, it has a given pitch of 160 nm. The trench is composed of the following materials:\n\nAccurate \"n\" and \"k\" values of these materials are necessary in order to analyze the structure. Often a blanket area on the trench sample with the film of interest is present for the measurement. In this example, the reflectance spectrum of the poly-silicon was measured on a blanket area containing the poly-silicon, from which its \"n\" and \"k\" spectra were determined in accordance with the methodology described in this article that utilizes the Forouhi–Bloomer dispersion equations. Fixed tables of \"n\" and \"k\" values were used for the SiO and SiN films.\n\nCombining the \"n\" and \"k\" spectra of the films with Rigorous Coupled-Wave Analysis (RCWA) the following critical parameters were determined (with measured results as well):\n"}
{"id": "37603772", "url": "https://en.wikipedia.org/wiki?curid=37603772", "title": "Reinhard Baumeister", "text": "Reinhard Baumeister\n\nReinhard Baumeister (19 March 1833 in Hamburg – 11 February 1917 in Karlsruhe) was a German engineer and urban planner, the author of one of the earliest texts on urban planning \"Stadterweiterungen in technischer, baupolizeilicher und Wirtschaftlicher Beziehung \" (Town extensions: their links with technical and economic concerns and with building regulations) published in 1876. It was used as a textbook at the first urban planning course in Germany, at the college of technology in Aachen in 1880. An early translation of one of his writings into English was \"The Cleaning and Sewerage of Cities\" published in New York in 1891. \n\nBaumeister was a professor of civil engineering with experience in railway construction when he entered the field of planning by winning the 1872 competition for the urban extension of Mannheim. \n"}
{"id": "28442751", "url": "https://en.wikipedia.org/wiki?curid=28442751", "title": "Remote laboratory", "text": "Remote laboratory\n\nRemote laboratory (also known as online laboratory or remote workbench) is the use of telecommunications to remotely conduct real (as opposed to virtual) experiments, at the physical location of the operating technology, whilst the scientist is utilizing technology from a separate geographical location. Remote laboratory comprehends one or more remote experiments.\n\nThe benefits of remote laboratories are predominantly in engineering education:\n\nResearchers from the Labshare describe the advantages as being:\n\nThis allows for economies of scale production.\n\nAnother benefit is that this technology can be integrated into Moodle, which is probably the most used Learning Management System around the world.\n\nThe disadvantages differ depending on the type of remote laboratory and the topic area.\nThe general disadvantages compared to a proximal (hands on) laboratory are:\n\n\nCurrent system capabilities include:\n\n\n"}
{"id": "255244", "url": "https://en.wikipedia.org/wiki?curid=255244", "title": "Seawater", "text": "Seawater\n\nSeawater, or salt water, is water from a sea or ocean. On average, seawater in the world's oceans has a salinity of about 3.5% (35 g/L, 599 mM). This means that every kilogram (roughly one litre by volume) of seawater has approximately of dissolved salts (predominantly sodium () and chloride () ions). Average density at the surface is 1.025 kg/L. Seawater is denser than both fresh water and pure water (density 1.0 kg/L at ) because the dissolved salts increase the mass by a larger proportion than the volume. The freezing point of seawater decreases as salt concentration increases. At typical salinity, it freezes at about . The coldest seawater ever recorded (in a liquid state) was in 2010, in a stream under an Antarctic glacier, and measured . Seawater pH is typically limited to a range between 7.5 and 8.4. However, there is no universally accepted reference pH-scale for seawater and the difference between measurements based on different reference scales may be up to 0.14 units.\n\nAlthough the vast majority of seawater has a salinity of between 31 g/kg and 38 g/kg, that is 3.1-3.8%, seawater is not uniformly saline throughout the world. Where mixing occurs with fresh water runoff from river mouths, near melting glaciers or vast amounts of precipitation (e.g. Monsoon), seawater can be substantially less saline. The most saline open sea is the Red Sea, where high rates of evaporation, low precipitation and low river run-off, and confined circulation result in unusually salty water. The salinity in isolated bodies of water can be considerably greater still - about ten times higher in the case of the Dead Sea. Historically, several salinity scales were used to approximate the absolute salinity of seawater. A popular scale was the \"Practical Salinity Scale\" where salinity was measured in \"practical salinity units (psu)\". The current standard for salinity is the \"Reference Salinity\" scale with the salinity expressed in units of \"g/kg\".\n\nThe density of surface seawater ranges from about 1020 to 1029 kg/m, depending on the temperature and salinity. At a temperature of 25 °C, salinity of 35 g/kg and 1 atm pressure, the density of seawater is 1023.6  kg/m. Deep in the ocean, under high pressure, seawater can reach a density of 1050 kg/m or higher. The density of seawater also changes with salinity. Brines generated by seawater desalination plants can have salinities up to 120 g/kg. The density of typical seawater brine of 120 g/kg salinity at 25 °C and atmospheric pressure is 1088 kg/m. Seawater pH is limited to the range 7.5 to 8.4. The speed of sound in seawater is about 1,500 m/s (whereas speed of sound is usually around 330 m/s in air at roughly 1000hPa pressure, 1 atmosphere), and varies with water temperature, salinity, and pressure. The thermal conductivity of seawater is 0.6 W/mK at 25 °C and a salinity of 35 g/kg.\nThe thermal conductivity decreases with increasing salinity and increases with increasing temperature.\n\nSeawater contains more dissolved ions than all types of freshwater. However, the ratios of solutes differ dramatically. For instance, although seawater contains about 2.8 times more bicarbonate than river water, the percentage of bicarbonate in seawater as a ratio of \"all\" dissolved ions is far lower than in river water. Bicarbonate ions constitute 48% of river water solutes but only 0.14% for seawater. Differences like these are due to the varying residence times of seawater solutes; sodium and chloride have very long residence times, while calcium (vital for carbonate formation) tends to precipitate much more quickly. The most abundant dissolved ions in seawater are sodium, chloride, magnesium, sulfate and calcium. Its osmolarity is about 1000 mOsm/l.\n\nSmall amounts of other substances are found, including amino acids at concentrations of up to 2 micrograms of nitrogen atoms per liter, which are thought to have played a key role in the origin of life.\n\nResearch in 1957 by the Scripps Institution of Oceanography sampled water in both pelagic and neritic locations in the Pacific Ocean. Direct microscopic counts and cultures were used, the direct counts in some cases showing up to 10 000 times that obtained from cultures. These differences were attributed to the occurrence of bacteria in aggregates, selective effects of the culture media, and the presence of inactive cells. A marked reduction in bacterial culture numbers was noted below the thermocline, but not by direct microscopic observation. Large numbers of spirilli-like forms were seen by microscope but not under cultivation. The disparity in numbers obtained by the two methods is well known in this and other fields. In the 1990s, improved techniques of detection and identification of microbes by probing just small snippets of DNA, enabled researchers taking part in the Census of Marine Life to identify thousands of previously unknown microbes usually present only in small numbers. This revealed a far greater diversity than previously suspected, so that a litre of seawater may hold more than 20,000 species. Mitchell Sogin from the Marine Biological Laboratory feels that \"the number of different kinds of bacteria in the oceans could eclipse five to 10 million.\"\n\nBacteria are found at all depths in the water column, as well as in the sediments, some being aerobic, others anaerobic. Most are free-swimming, but some exist as symbionts within other organisms – examples of these being bioluminescent bacteria. Cyanobacteria played an important role in the evolution of ocean processes, enabling the development of stromatolites and oxygen in the atmosphere.\n\nSome bacteria interact with diatoms, and form a critical link in the cycling of silicon in the ocean. One anaerobic species, \"Thiomargarita namibiensis\", plays an important part in the breakdown of hydrogen sulfide eruptions from diatomaceous sediments off the Namibian coast, and generated by high rates of phytoplankton growth in the Benguela Current upwelling zone, eventually falling to the seafloor.\n\nBacteria-like Archaea surprised marine microbiologists by their survival and thriving in extreme environments, such as the hydrothermal vents on the ocean floor. Alkalotolerant marine bacteria such as \"Pseudomonas\" and \"Vibrio\" spp. survive in a pH range of 7.3 to 10.6, while some species will grow only at pH 10 to 10.6. Archaea also exist in pelagic waters and may constitute as much as half the ocean's biomass, clearly playing an important part in oceanic processes. In 2000 sediments from the ocean floor revealed a species of Archaea that breaks down methane, an important greenhouse gas and a major contributor to atmospheric warming. Some bacteria break down the rocks of the sea floor, influencing seawater chemistry. Oil spills, and runoff containing human sewage and chemical pollutants have a marked effect on microbial life in the vicinity, as well as harbouring pathogens and toxins affecting all forms of marine life. The protist dinoflagellates may at certain times undergo population explosions called blooms or red tides, often after human-caused pollution. The process may produce metabolites known as biotoxins, which move along the ocean food chain, tainting higher-order animal consumers.\n\n\"Pandoravirus salinus\", a species of very large virus, with a genome much larger than that of any other virus species, was discovered in 2013. Like the other very large viruses \"Mimivirus\" and \"Megavirus\", \"Pandoravirus\" infects amoebas, but its genome, containing 1.9 to 2.5 megabases of DNA, is twice as large as that of \"Megavirus\", and it differs greatly from the other large viruses in appearance and in genome structure.\n\nIn 2013 researchers from Aberdeen University announced that they were starting a hunt for undiscovered chemicals in organisms that have evolved in deep sea trenches, hoping to find \"the next generation\" of antibiotics, anticipating an \"antibiotic apocalypse\" with a dearth of new infection-fighting drugs. The EU-funded research will start in the Atacama Trench and then move on to search trenches off New Zealand and Antarctica.\n\nThe ocean has a long history of human waste disposal on the assumption that its vast size makes it capable of absorbing and diluting all noxious material.\nWhile this may be true on a small scale, the large amounts of sewage routinely dumped has damaged many coastal ecosystems, and rendered them life-threatening. Pathogenic viruses and bacteria occur in such waters, such as \"Escherichia coli\", \"Vibrio cholerae\" the cause of cholera, hepatitis A, hepatitis E and polio, along with protozoans causing giardiasis and cryptosporidiosis. These pathogens are routinely present in the ballast water of large vessels, and are widely spread when the ballast is discharged.\n\nScientific theories behind the origins of sea salt started with Sir Edmond Halley in 1715, who proposed that salt and other minerals were carried into the sea by rivers after rainfall washed it out of the ground. Upon reaching the ocean, these salts concentrated as more salt arrived over time (see Hydrologic cycle). Halley noted that most lakes that don't have ocean outlets (such as the Dead Sea and the Caspian Sea, see endorheic basin), have high salt content. Halley termed this process \"continental weathering\".\n\nHalley's theory was partly correct. In addition, sodium leached out of the ocean floor when the ocean formed. The presence of salt's other dominant ion, chloride, results from outgassing of chloride (as hydrochloric acid) with other gases from Earth's interior via volcanos and hydrothermal vents. The sodium and chloride ions subsequently became the most abundant constituents of sea salt.\n\nOcean salinity has been stable for billions of years, most likely as a consequence of a chemical/tectonic system which removes as much salt as is deposited; for instance, sodium and chloride sinks include evaporite deposits, pore-water burial, and reactions with seafloor basalts.\n\nClimate change, rising atmospheric carbon dioxide, excess nutrients, and pollution in many forms are altering global oceanic geochemistry. Rates of change for some aspects greatly exceed those in the historical and recent geological record. Major trends include an increasing acidity, reduced subsurface oxygen in both near-shore and pelagic waters, rising coastal nitrogen levels, and widespread increases in mercury and persistent organic pollutants. Most of these perturbations are tied either directly or indirectly to human fossil fuel combustion, fertilizer, and industrial activity. Concentrations are projected to grow in coming decades, with negative impacts on ocean biota and other marine resources.\n\nOne of the most striking features of this is ocean acidification, resulting from increased CO uptake of the oceans related to higher atmospheric concentration of CO and higher temperatures, because it severely affects coral reefs and crustaceans (see coral bleaching).\n\nAccidentally consuming small quantities of clean seawater is not harmful, especially if the seawater is taken along with a larger quantity of fresh water. However, drinking seawater to maintain hydration is counterproductive; more water must be excreted to eliminate the salt (via urine) than the amount of water obtained from the seawater itself.\n\nThe renal system actively regulates sodium chloride in the blood within a very narrow range around 9 g/L (0.9% by weight).\n\nIn most open waters concentrations vary somewhat around typical values of about 3.5%, far higher than the body can tolerate and most beyond what the kidney can process. A point frequently overlooked in claims that the kidney can excrete NaCl in Baltic concentrations of 2% (in arguments to the contrary) is that the gut cannot absorb water at such concentrations, so that there is no benefit in drinking such water. Drinking seawater temporarily increases blood's NaCl concentration. This signals the kidney to excrete sodium, but seawater's sodium concentration is above the kidney's maximum concentrating ability. Eventually the blood's sodium concentration rises to toxic levels, removing water from cells and interfering with nerve conduction, ultimately producing fatal seizure and cardiac arrhythmia.\n\nSurvival manuals consistently advise against drinking seawater. A summary of 163 life raft voyages estimated the risk of death at 39% for those who drank seawater, compared to 3% for those who did not. The effect of seawater intake on rats confirmed the negative effects of drinking seawater when dehydrated.\n\nThe temptation to drink seawater was greatest for sailors who had expended their supply of fresh water, and were unable to capture enough rainwater for drinking. This frustration was described famously by a line from Samuel Taylor Coleridge's \"The Rime of the Ancient Mariner\":\n\nAlthough humans cannot survive on seawater, some people claim that up to two cups a day, mixed with fresh water in a 2:3 ratio, produces no ill effect. The French physician Alain Bombard survived an ocean crossing in a small Zodiak rubber boat using mainly raw fish meat, which contains about 40 percent water (like most living tissues), as well as small amounts of seawater and other provisions harvested from the ocean. His findings were challenged, but an alternative explanation was not given. In his 1948 book, \"Kon-Tiki\", Thor Heyerdahl reported drinking seawater mixed with fresh in a 2:3 ratio during the 1947 expedition. A few years later, another adventurer, William Willis, claimed to have drunk two cups of seawater and one cup of fresh per day for 70 days without ill effect when he lost part of his water supply.\n\nDuring the 18th century, Richard Russell advocated the practice's medical use in the UK, and René Quinton expanded the advocation of the practice other countries, notably France, in the 20th century. Currently, the practice is widely used in Nicaragua and other countries, supposedly taking advantage of the latest medical discoveries.\n\nMost ocean-going vessels desalinate potable water from seawater using processes such as vacuum distillation or multi-stage flash distillation in an evaporator, or, more recently, reverse osmosis. These energy-intensive processes were not usually available during the Age of Sail. Larger sailing warships with large crews, such as Nelson's , were fitted with distilling apparatus in their galleys.\nAnimals such as fish, whales, sea turtles, and seabirds, such as penguins and albatrosses have adapted to living in a high saline habitat. For example, sea turtles and saltwater crocodiles remove excess salt from their bodies through their tear ducts.\n\nASTM International has an international standard for artificial seawater: ASTM D1141-98 (Original Standard ASTM D1141-52). It is used in many research testing labs as a reproducible solution for seawater such as tests on corrosion, oil contamination, and detergency evaluation.\n\n\nTables\n"}
{"id": "52747620", "url": "https://en.wikipedia.org/wiki?curid=52747620", "title": "Shafi Ahmed", "text": "Shafi Ahmed\n\nShafi Ahmed is a surgeon, teacher, futurist, innovator and entrepreneur. \n\nShafi was born on 26 January 1969 in Sylhet District, East Pakistan (now Bangladesh) and came to the United Kingdom as a child. His father, the late Mimbor Ali, was honoured by the Bangladeshi government for his significant contribution to the liberation of Bangladesh.\n\nHe was appointed as a Consultant General, Laparoscopic and Colorectal surgeon to the Royal London Hospital and St Bartholomew's Hospitals,\nBarts Health in 2007.\n\nHe was appointed as an honorary professor at The University of Bradford in May 2017.\n\nShafi attended Chadwell Heath High School (now Chadwell Heath Academy) and then attended Redbridge technical college.\n\nHe studied medicine between 1988 and 1993 at King's College Hospital School of Medicine. At university he was elected President of the Medical and Dental Society from 1989 to 1990 and helped introduce medical ethics into the curriculum. He was awarded the Jelf medal in 1990 for outstanding academic and social achievement at King's College London. He was also won the WG Oakley prize in Diabetes in 1992 for an original dissertation entitled \"Diabetic Neuroarthropathy: the Pathogenesis of the Charcot joint\".\n\nHe played football for the 1st XI between 1988–1993 and the United Hospitals' representative team 1990–1992. He captained the Cricket 1st XI 1991–1993.\n\nShafi completed his basic and higher surgical training in London in general surgery.\n\nDuring his surgical training he undertook a period of research at The Royal London Hospital and Queen Mary University of London and obtained a PhD in 2010 with a thesis entitled \"The role of microarray profiling in predicting outcome in patients with colorectal cancer\".\n\nHe obtained his FRCS(Eng), FRCS(Ed) and FRCSI (Fellowship of the Royal College of Surgeons of England, Edinburgh and Ireland) in 2007–2008. He completed his intercollegiate final FRCS(Gen.Surg) in 2006.\n\nHe also obtained a Certificate in Medical Informatics from the Royal College of Surgeons of Edinburgh in 2005.\n\nHe has been awarded 4 Honorary PhDs (Honoris Causa) from Udabol University Bolivia, SIISDET Colombia, University of Peru of Science and Informatics and EXIBED, Spain.\n\nShafi works in the Academic Centre of Surgery and has established minimally invasive colorectal surgery at the Royal London Hospital, Barts Health NHS Trust.\n\nHis main clinical interest is colorectal cancer and he performs radical pelvic surgery for primary and recurrent disease as well as multi-visceral resections. His other interests include diverticular disease, inflammatory bowel disease and pouch surgery, coloproctology and the modern management of haemorrhoids.\n\nHe has pioneered single incision laparoscopic colorectal surgery (virtual scarless surgery) and also works with liver surgeons to perform simultaneous laparoscopic liver and bowel resections for cancer. His other clinical interest is advanced stage 3/4 endometriosis, performing laparoscopic surgery with gynaecologists. This has led to the development and recognition of a national centre for endometriosis. In addition, he has specialist experience in complex abdominal wall hernias and reconstruction.\n\nFrom 2010 to 2015 he was the lead clinician and multi-disciplinary team lead for colorectal cancer at Barts Health NHS Trust. He is also a CQC specialist advisor in general surgery.\n\nHe undertakes private work at the London Independent Hospital and the Spire Roding Hospital.\n\nShafi is the Associate Dean for Barts and the London undergraduate medical students at the Royal London Hospital and is the module lead for surgery in year 3 and year 5. He was programme director for core surgical trainees for North East London 2012–2013 and Tutor in Surgery for the Royal London Hospital 2011–2013.\n\nShafi is the module lead for an innovative new course at Barts and The London Medical School which aims to teach the 3rd year medical students about future medicine and how to generate ideas to improve clinical care. The students are taught by digital health innovators and those involved in Medtech from the UK and US. BMJ digital and QMUL are supporting a hackathon and taking ideas to market by crowdsource funding.\n\nShafi was elected onto the council of the Royal College of Surgeons of England in 2013. He has numerous roles and leads the International Surgical Training Programme. He was part of the Cancer 2020 5 Year Forward View Task force 2015. He is a member of the court of examiners and is an international convenor of the MRCS for Bangladesh.\n\nShafi has been working on new technologies enhancing surgical education globally. His online videos have been watched hundreds of thousands of times, earning him the accolade of most-watched surgeon in human history.\n\nHis company Virtual Medics has developed the use of wearable technology in education and clinical practice. This has allowed the development of a web-placed platform to stream live and interactive teaching. They have recently released a global surgical curriculum.\n\nIn May 2014, using Google Glass, he performed and streamed a live interactive operation to 14000 students and trainees across 132 countries and 1100 cities.\n\nHe is the cofounder of Medical Realities a group offering surgical training products, specialising in virtual reality, augmented reality and serious games. On 14 April 2016, in collaboration with Barts Health, Medical Realities and Mativision, he performed the world's first virtual reality operation recorded and streamed live in 360 degrees. This was viewed by 55000 people in 140 countries and 4000 cities and reached 4.6 million people on Twitter. This event was covered worldwide on over 400 newspaper/online articles and BBC Click, Sky News, ARD German, TRT News, South American NTN, ABC News, Aljazeera, and Press TV. His work has been featured on \"Wired\", \"The Guardian\", \"The Telegraph\", ABC News, CNET, \"Verge\", \"Huffington Post\", and \"Tech China\". \n\nOn 9 December 2016, he performed the world's first live operation using Snapchat Spectacles where he trained 200 medical students and surgical trainees, which was covered by \"Time\" magazine, BBC, and \"Cosmopolitan\". The operation has been viewed over 100 000 times\n\nHe is a non-executive director of Medic creations and GPDQ. \n\nHe was chosen to curate the @NHS Twitter account from 27 February 2017 to 3 March 2017 and tweeted the world's first live operation via this account.\n\nShafi is a three times TEDx and three times Wired Health and international keynote speaker and is a member of the faculty at Exponential Medicine and Singularity University. He has spoken at many international conferences including TEDx Barts health, TEDx Goodenough College, TEDx Cass Business School, City University, Wired Health, Wired Health Italy, Exponential Medicine Singularity University, Royal Society of Medicine Innovation Summit, Digital Health Summer Summit, MedTech Forum Europe, Belgium, CopenX, Denmark Innovation showcase Dublin, Dubai Health Forum, Tryst Conference, Indian Institute of Technology, Delhi, Webit, Bulgaria, ICEEFest, Romania, Cannes Lions, Krystal Elma, Istanbul, GITEX, Dubai, Knowledge Foundation Dubai and Health 2.0 Barcelona. Digifest \n\nOn 15 March 2017, he delivered the prestigious Cantor Technology Lecture 2017 at the University of Bradford. and also delivered the public lecture to open the Digital Health Enterprise Zone.\n\nHe is the chair of the GIANT (Global Innovation and New Technologies) Health Event in London and also the chair of the Webit.Health conference in Sofia, Bulgaria. which showcase startups, innovation, technology and entrepreneurship.\n\nHe is Vice-President of Proshanti a local charity community project to set up a health programme in Bangladesh and an advisor to Beani Bazaar Cancer Hospital, Bangladesh. He also teaches and trains surgeons in Dhaka, Bangladesh where he is the Dean for education at Rahetid, a postgraduate surgical training centre.\n\n\n\n\n\n\n\n\nShafi has been selected in the British Bangladeshi Power and Inspiration 100 and awarded the honour of the British Bangladeshi Person of the Year 2017.\n\nHe was awarded the Chairman's prize for Outstanding Contribution to HealthTech.\n\nHe received this award from Alternative Doctors.\n\nFuture NHS Award regional winner \n\nHe lives in London. He is married to Farzana Hussain, a General Practitioner, and has two children, Usmaan and Zarina. He has three siblings: Shamim Ahmed, Khatun Sapnara and Jami Ahmed.\n"}
{"id": "26099505", "url": "https://en.wikipedia.org/wiki?curid=26099505", "title": "Tage Erlander Prize", "text": "Tage Erlander Prize\n\nThe Tage Erlander Prize (\"Tage Erlanders pris\") is a prize awarded by the Royal Swedish Academy of Science \"for research in Natural Sciences and Technology\"\nin four fields (Physics, Chemistry, Technology and Biology). The prize is awarded on a rolling schedule: every year the prize is awarded for research in one of these fields.\n\nThe prize commemorates Tage Erlander, who was the prime minister of Sweden from 1946 to 1969.\n"}
{"id": "33901493", "url": "https://en.wikipedia.org/wiki?curid=33901493", "title": "Taxonomy", "text": "Taxonomy\n\nTaxonomy (general) is the practice and science of classification of things or concepts, including the principles that underlie such classification.\n\nSpecific taxonomies include:\n\n\n\n\n\n\n\n\n"}
{"id": "41731445", "url": "https://en.wikipedia.org/wiki?curid=41731445", "title": "The Life Scientific", "text": "The Life Scientific\n\nThe Life Scientific is a BBC Radio 4 science programme, presented by Professor Jim Al-Khalili, in which each episode is dedicated to the biography and work of one living scientist.\nThe programme consists of an interview between Jim al-Khalili and the featured scientist. \nA variety of third parties contribute anecdotes about each programme's subject.\n\nThe programme is broadcast on Tuesday mornings in the United Kingdom, and is available online via iPlayer, as is an archive of past issues.\n\nThe programme's BBC Programme Identifier (PID; a unique identifier) is b015sqc7.\n\nGuests have included:\n"}
{"id": "46893109", "url": "https://en.wikipedia.org/wiki?curid=46893109", "title": "Theodor Friedrich Julius Basiner", "text": "Theodor Friedrich Julius Basiner\n\nTheodor Friedrich Julius Basiner (3 January 1816–14 October 1862) was a Baltic German botanist who lived and worked mainly in Imperial Russia.\n\nTheodor Friedrich Julius Basiner was born in Tartu, present-day Estonia, and studied at Tartu University between 1836 and 1840. In 1843 he became a conservator at the Botanical Garden in Saint Petersburg. He kept this position until 1845, when he became the institution's librarian. In 1849 he moved to a new position in Kiev, present-day Ukraine. In 1842-43 he made a scientific journey to Khiva in present-day Uzbekistan. He died in Vienna, Austria.\n\n"}
{"id": "50555537", "url": "https://en.wikipedia.org/wiki?curid=50555537", "title": "Thermal power station Regina Margherita", "text": "Thermal power station Regina Margherita\n\nThe thermal power station Regina Margherita was a large power station for the production of electricity, preserved at the Museo nazionale della scienza e della tecnologia Leonardo da Vinci in Milan, Italy. The station opened in 1895 and was originally installed in the Egidio e Pio Gavazzi silk factory in Desio (Milan), where it operated until 1954. It supplied electricity for lighting and for the operation of 1,800 looms, generating alternating electric current at a voltage of 200 V.\n\nDesigned at the Polytechnic University of Milan, it was built by combining a steam engine from the Franco Tosi company of Legnano and a pair of alternators from the Brown Boveri company.\n\nThe power station opened on November 9, 1895; the ceremony was attended by King Umberto I and Margherita of Savoy, to whom the plant was dedicated.\n\nIn 1958 Egidio e Pio Gavazzi proposed to donate the power plant to the Museo nazionale della scienza e della tecnologia Leonardo da Vinci. In order to exhibit the large machine, the floor was demolished, a stronger basement was built to support the item and the technical press consultation room was moved. Then the Desio plant was dismantled using maintenance cranes and it was transported with a Riva lorry to the museum, where it was reassembled by hand and connected to an electric motor, coupled with a reduction gear, and set in motion. The furnace and boiler, with their connected steam distribution pipes and pumps, were not transferred to the museum.\n\nThe station contains two parts: thermal, consisting of a steam engine with two horizontal cylinders, and electric, consisting of two alternators and two exciter dynamos. There is also an electric control panel and a lighting system with 8 lamps. The machine is activated by an electric motor, connected to it by a chain which encircles a pulley, and it no longer produces current.\n\nThis machine is an example of a compound steam engine.\n\nAlthough it relied on the finest nineteenth-century technologies, the \"Regina Margherita\" was not a cutting-edge piece of machinery. Ten years before its making, the Englishman Sir Charles Algernon Parsons had already invented the steam turbine. In the latter device the force of the steam acts directly on the blades of the wheel, producing the rotation necessary to operate the alternators. The steam turbine is more efficient than a cylinder and piston system because it reduces energy waste from the transformation of alternating motion into rotary motion and from the transmission of movement through connecting rods, cranks and belts.\n\n"}
{"id": "69838", "url": "https://en.wikipedia.org/wiki?curid=69838", "title": "William Friese-Greene", "text": "William Friese-Greene\n\nWilliam Friese-Greene (born William Edward Green, 7 September 1855 – 5 May 1921) was a prolific English inventor and professional photographer. He is principally known as a pioneer in the field of motion pictures, creating a series of cameras in the period 1888–1891 with which he shot moving pictures in London. He went on to patent an early two-colour filming process in 1905. His inventions in the field of printing – including photo-typesetting and a method of printing without ink – brought him wealth, as did his chain of photographic studios. However, he spent everything he earned on inventing, going bankrupt three times and to jail once, before dying in poverty.\n\nWilliam Edward Green was born on 7 September 1855, in Bristol. He studied at the Queen Elizabeth's Hospital school. In 1871 he was apprenticed to the Bristol photographer Marcus Guttenberg, but later successfully went to court to be freed early from the indentures of his seven-year apprenticeship. He married the Swiss Helena Friese on 24 March 1874, and in a remarkable move for the era, decided to add her maiden name to his surname. In 1877 he set up his own studio in Bath, and by 1881 had expanded his business with more studios in Bath, Bristol and Plymouth.\n\nIn Bath he came into contact with John Arthur Roebuck Rudge. Rudge was a scientific instrument maker who also worked with electricity and magic lanterns to create popular entertainments. Rudge built what he called the Biophantic Lantern, which could display seven photographic slides in rapid succession, producing the illusion of movement. It showed a sequence in which Rudge (with the invisible help of Friese-Greene) apparently took off his head. Friese-Greene was fascinated by the machine and worked with Rudge on a variety of devices over the 1880s, various of which Rudge called the Biophantascope. Moving his base to London in 1885, Friese-Greene realised that glass plates would never be a practical medium for continuously capturing life as it happens and began to experiment with the new Eastman paper roll film, made transparent with castor oil, before turning his attention to experimenting with celluloid as a medium for motion picture cameras.\n\nOn 21 June 1889, Friese-Greene was issued patent no. 10131 for his camera. It was apparently capable of taking up to ten photographs per second using paper and celluloid film. A report on the camera was published in the British \"Photographic News\" on 28 February 1890. On 18 March, Friese-Greene sent a clipping of the story to Thomas Edison, whose laboratory had been developing a motion picture system, with a peephole viewer, christened the Kinetoscope. The report was reprinted in \"Scientific American\" on 19 April. Friese-Greene worked on a series of moving picture cameras until early 1891, but although many individuals recount seeing his projected images privately, he did not ever give a successful public projection of moving pictures. In 1890 he developed a camera with Frederick Varley to shoot stereoscopic moving images. The camera ran at a slower frame rate, and although the 3-D arrangement images worked, there are no records of projection. Friese-Greene's experiments in the field of motion pictures were at the expense of his other business interests and in 1891 he was declared bankrupt. To cover his debts he had already sold the rights to the 1889 moving picture camera patent for £500 (£60,000 in 2016 terms). The renewal fee was never paid and the patent eventually lapsed.\n\nFriese-Greene's later exploits were in the field of colour in motion pictures. From 1903 he lived in Brighton where there were a number of experimenters developing still and moving pictures in colour. Initially working with William Norman Lascelles Davidson, Friese-Greene patented a two-colour moving picture system using prisms in 1905. He and Davidson gave public demonstrations of this in January and July 1906 and Friese-Greene held screenings at his photographic studio.\n\nHe also experimented with a system which he called \"Biocolour\". This process produced the illusion of true colour by exposing each alternate frame of ordinary black-and-white film stock through two or three different coloured filters. Each alternate frame of the monochrome print was then stained red or green (and/or blue). Although the projection of Biocolour prints did provide an impression of true colour, it suffered from noticeable flickering and red and green fringing when the subject was in rapid motion, as did the more popular and famous system, Kinemacolor.\n\nIn 1911, George Albert Smith and Charles Urban filed a lawsuit against Friese-Greene, claiming that the Biocolour process infringed upon Smith's Kinemacolor patents, despite the fact that Friese-Greene had both patented and demonstrated his work before Smith. Urban was granted an injunction against Biocolour in 1912, but the Sussex-based, flamboyant racing driver Selwyn Edge decided to help Friese-Greene by funding an appeal to the High Court. This overturned the original verdict on the grounds that Kinemacolor made claims for itself which it could not deliver. Urban fought back and pushed it up to the House of Lords, who in 1915 upheld the decision of the High Court. The decision benefited nobody. For Urban it was a case of hubris because now he could no longer exercise control over his own system, so it became worthless. For Friese-Greene, the arrival of the war and personal poverty meant there was nothing more to be done with colour for some years.\n\nHis son Claude Friese-Greene continued to develop the system with his father and, after his death, in the early 1920s, now calling it \"The Friese-Greene Natural Colour Process\" and shooting the documentary films \"The Open Road\" with it, which are a rare portrait of 1920s Britain in colour. These were featured in a BBC series The Lost World of Friese-Greene and then issued in a digitally restored form by the BFI on DVD in 2006.\n\nOn 5 May 1921 Friese-Greene – now a largely forgotten figure – attended an important and stormy meeting of the cinema trade at the Connaught Rooms in London. The meeting had been called to discuss the current poor state of British film distribution and was chaired by Lord Beaverbrook. Disturbed by the tone of the proceedings, Friese-Greene got to his feet to speak. The chairman asked him to come forward onto the platform to be heard better, which he did, appealing for the two sides to come together. Shortly after returning to his seat, he collapsed. People came to his aid and took him outside, but he died almost immediately of heart failure.\n\nGiven his dramatic death, surrounded by film industry representatives who had almost entirely forgotten about his role in motion pictures, there was a spasm of collective shock and guilt. A very grand funeral was staged for him, a two minute silence was observed in some cinemas and a fund was raised to commission the famous architect Sir Edwin Lutyens to design a memorial for his grave. This memorial describes him as \"The Inventor of Kinematography\", a term William Friese-Greene never used in talking about his achievements. Indeed, he often spoke generously about other workers in the field of capturing movement. He was buried in the eastern section of London's Highgate Cemetery, just south of the entrance and visible from the street through the railings. His second wife, Edith Jane, died a few months later of cancer and is buried with him.\n\nIn 1951 a biopic was made, starring Robert Donat, as part of the Festival of Britain. The film, \"The Magic Box,\" was not premiered until the festival was nearly over, and only went on full release after it had finished. Despite the all-star cast and a great deal of publicity, it was a costly box office flop. Domankiewicz and Herbert have written, \"He was the subject of a romantic and unreliable biography, \"Friese-Greene, Close-Up of an Inventor\", which was then turned into an even more misleading film, \"The Magic Box\".\" Nonetheless, Martin Scosese has many times cited it as one of his favourite films, and one that inspired him.\n\nDespite a campaign by Bristol photographer Reece Winstone for the retention of Friese-Greene's birthplace for use as a Museum of Cinematography, among other purposes, it was demolished by Bristol Corporation in 1958 to provide parking space for six cars.\n\nPremises in Brighton's Middle Street where Friese-Greene shared workshop space in 1905 are often wrongly described as his home. They bear a plaque in a 1924 design by Eric Gill commemorating Friese-Greene's achievements, wrongly stating that it is the place where he invented cinematography. The plaque was unveiled by Michael Redgrave, who had appeared in \"The Magic Box\", in September 1957. A modern office building a few yards away is named Friese-Greene House. Other plaues include the 1930s Odeon Cinema in Kings Road, Chelsea, London, with its iconic facade, which carries high upon it a large sculpted head-and-shoulders medallion of \"William Friese-Greene\" and his years of birth and death. There is a bronze statue of him at Pinewood Studios.\n\nIn 2006 the BBC ran a series of programmes called \"The Lost World of Friese-Greene\", presented by Dan Cruickshank about Claude Friese-Greene's road trip from Land's End to John o' Groats, entitled \"The Open Road\", which he filmed from 1924 to 1926 using the Biocolour process. Modern television production techniques meant they were able to remove the issues of flickering and colour fringing around moving objects, which Kinemacolor and Biocolour had when projected. The result was a unique view of Britain in colour in the mid-1920s.\n\nWilliam Friese-Greene was more or less banished to obscurity by film historians from the 1960s onwards, but new research is leading to a rehabilitation of his reputation and a better understanding of his achievements and his influence on the technical development of cinema.\n\n"}
{"id": "48963201", "url": "https://en.wikipedia.org/wiki?curid=48963201", "title": "Yojiro Kimura", "text": "Yojiro Kimura\n\nYojiro Kimura (1912 – 2006) was a Japanese botanist, known for his classification of monocotyledons, and of Japanese species of \"Hypericum\".\n\n\nYojiro Kimura is the authority for 58 taxa, such as \"Hypericum hayatae\" \n"}
